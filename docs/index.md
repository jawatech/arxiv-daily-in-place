# arxiv-daily
 Automated deployment @ 2025-01-24 09:04:20 Asia/Taipei
> Welcome to contribute! Add your topics and keywords in [`topic.yml`](https://github.com/jawatech/arxiv-daily-in-place/blob/main/database/topic.yml).
> You can also view historical data through the [storage](https://github.com/jawatech/arxiv-daily-in-place/blob/main/database/storage).

## AI

### Medical explainable AI
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2025-01-19**|**Enhanced Suicidal Ideation Detection from Social Media Using a CNN-BiLSTM Hybrid Model**|Mohaiminul Islam Bhuiyan et.al.|[2501.11094v1](http://arxiv.org/abs/2501.11094v1)|null|
|**2025-01-17**|**SEANN: A Domain-Informed Neural Network for Epidemiological Insights**|Jean-Baptiste Guimbaud et.al.|[2501.10273v1](http://arxiv.org/abs/2501.10273v1)|null|
|**2025-01-16**|**Artificial Intelligence-Driven Clinical Decision Support Systems**|Muhammet Alkan et.al.|[2501.09628v1](http://arxiv.org/abs/2501.09628v1)|null|
|**2025-01-12**|**MedGrad E-CLIP: Enhancing Trust and Transparency in AI-Driven Skin Lesion Diagnosis**|Sadia Kamal et.al.|[2501.06887v1](http://arxiv.org/abs/2501.06887v1)|null|
|**2025-01-06**|**Explaining Humour Style Classifications: An XAI Approach to Understanding Computational Humour Analysis**|Mary Ogbuka Kenneth et.al.|[2501.02891v1](http://arxiv.org/abs/2501.02891v1)|null|
|**2024-12-28**|**The Emotional Spectrum of LLMs: Leveraging Empathy and Emotion-Based Markers for Mental Health Support**|Alessandro De Grandi et.al.|[2412.20068v1](http://arxiv.org/abs/2412.20068v1)|null|
|**2024-12-27**|**A Review on the Integration of Artificial Intelligence and Medical Imaging in IVF Ovarian Stimulation**|Jana Zakall et.al.|[2412.19688v1](http://arxiv.org/abs/2412.19688v1)|null|
|**2024-12-23**|**Enhancing Cancer Diagnosis with Explainable & Trustworthy Deep Learning Models**|Badaru I. Olumuyiwa et.al.|[2412.17527v1](http://arxiv.org/abs/2412.17527v1)|null|
|**2024-12-20**|**Towards Interpretable Radiology Report Generation via Concept Bottlenecks using a Multi-Agentic RAG**|Hasan Md Tusfiqur Alam et.al.|[2412.16086v2](http://arxiv.org/abs/2412.16086v2)|[link](https://github.com/tifat58/irr-with-cbm-rag)|
|**2024-12-20**|**Critique of Impure Reason: Unveiling the reasoning behaviour of medical Large Language Models**|Shamus Sim et.al.|[2412.15748v1](http://arxiv.org/abs/2412.15748v1)|null|
|**2024-12-18**|**Cognition Chain for Explainable Psychological Stress Detection on Social Media**|Xin Wang et.al.|[2412.14009v1](http://arxiv.org/abs/2412.14009v1)|null|
|**2024-11-30**|**2-Factor Retrieval for Improved Human-AI Decision Making in Radiology**|Jim Solomon et.al.|[2412.00372v1](http://arxiv.org/abs/2412.00372v1)|null|
|**2024-11-28**|**Mapping Public Perception of Artificial Intelligence: Expectations, Risk-Benefit Tradeoffs, and Value As Determinants for Societal Acceptance**|Philipp Brauner et.al.|[2411.19356v1](http://arxiv.org/abs/2411.19356v1)|null|
|**2024-11-26**|**Explainable AI for Classifying UTI Risk Groups Using a Real-World Linked EHR and Pathology Lab Dataset**|Yujie Dai et.al.|[2411.17645v2](http://arxiv.org/abs/2411.17645v2)|null|
|**2024-11-18**|**Exploring the Requirements of Clinicians for Explainable AI Decision Support Systems in Intensive Care**|Jeffrey N. Clark et.al.|[2411.11774v1](http://arxiv.org/abs/2411.11774v1)|null|
|**2024-11-15**|**Artificial Intelligence in Pediatric Echocardiography: Exploring Challenges, Opportunities, and Clinical Applications with Explainable AI and Federated Learning**|Mohammed Yaseen Jabarulla et.al.|[2411.10255v1](http://arxiv.org/abs/2411.10255v1)|null|
|**2024-11-01**|**Enhancing Osteoporosis Detection: An Explainable Multi-Modal Learning Framework with Feature Fusion and Variable Clustering**|Mehdi Hosseini Chagahi et.al.|[2411.00916v2](http://arxiv.org/abs/2411.00916v2)|null|
|**2024-10-25**|**A Review of Deep Learning Approaches for Non-Invasive Cognitive Impairment Detection**|Muath Alsuhaibani et.al.|[2410.19898v1](http://arxiv.org/abs/2410.19898v1)|null|
|**2024-10-23**|**An Ontology-Enabled Approach For User-Centered and Knowledge-Enabled Explanations of AI Systems**|Shruthi Chari et.al.|[2410.17504v1](http://arxiv.org/abs/2410.17504v1)|[link](https://github.com/tetherless-world/metaexplainer)|
|**2024-10-22**|**Contrasting Attitudes Towards Current and Future AI Applications for Computerised Interpretation of ECG: A Clinical Stakeholder Interview Study**|Lukas Hughes-Noehrer et.al.|[2410.16879v1](http://arxiv.org/abs/2410.16879v1)|null|
|**2024-10-19**|**Pathologist-like explainable AI for interpretable Gleason grading in prostate cancer**|Gesa Mittmann et.al.|[2410.15012v1](http://arxiv.org/abs/2410.15012v1)|null|
|**2024-10-15**|**Explainable AI Methods for Multi-Omics Analysis: A Survey**|Ahmad Hussein et.al.|[2410.11910v1](http://arxiv.org/abs/2410.11910v1)|null|
|**2024-10-14**|**Study on the Helpfulness of Explainable Artificial Intelligence**|Tobias Labarta et.al.|[2410.11896v1](http://arxiv.org/abs/2410.11896v1)|[link](https://github.com/tlabarta/helpfulnessofxai)|
|**2024-10-12**|**Use of What-if Scenarios to Help Explain Artificial Intelligence Models for Neonatal Health**|Abdullah Mamun et.al.|[2410.09635v1](http://arxiv.org/abs/2410.09635v1)|[link](https://github.com/ab9mamun/aimen)|
|**2024-10-10**|**Artificial intelligence techniques in inherited retinal diseases: A review**|Han Trinh et.al.|[2410.09105v1](http://arxiv.org/abs/2410.09105v1)|null|
|**2024-10-07**|**CasiMedicos-Arg: A Medical Question Answering Dataset Annotated with Explanatory Argumentative Structures**|Ekaterina Sviridova et.al.|[2410.05235v2](http://arxiv.org/abs/2410.05235v2)|[link](https://github.com/ixa-ehu/antidote-casimedicos)|
|**2024-10-01**|**Explainable Diagnosis Prediction through Neuro-Symbolic Integration**|Qiuhao Lu et.al.|[2410.01855v2](http://arxiv.org/abs/2410.01855v2)|null|
|**2024-10-01**|**Easydiagnos: a framework for accurate feature selection for automatic diagnosis in smart healthcare**|Prasenjit Maji et.al.|[2410.00366v1](http://arxiv.org/abs/2410.00366v1)|null|
|**2024-09-20**|**Dermatologist-like explainable AI enhances melanoma diagnosis accuracy: eye-tracking study**|Tirtha Chanda et.al.|[2409.13476v1](http://arxiv.org/abs/2409.13476v1)|null|
|**2024-09-19**|**Explainable AI for Autism Diagnosis: Identifying Critical Brain Regions Using fMRI Data**|Suryansh Vidya et.al.|[2409.15374v1](http://arxiv.org/abs/2409.15374v1)|null|
|**2024-09-19**|**Improving Prototypical Parts Abstraction for Case-Based Reasoning Explanations Designed for the Kidney Stone Type Recognition**|Daniel Flores-Araiza et.al.|[2409.12883v1](http://arxiv.org/abs/2409.12883v1)|null|
|**2024-09-18**|**Towards Interpretable End-Stage Renal Disease (ESRD) Prediction: Utilizing Administrative Claims Data with Explainable AI Techniques**|Yubo Li et.al.|[2409.12087v3](http://arxiv.org/abs/2409.12087v3)|null|
|**2024-09-13**|**Contextual Evaluation of Large Language Models for Classifying Tropical and Infectious Diseases**|Mercy Asiedu et.al.|[2409.09201v3](http://arxiv.org/abs/2409.09201v3)|null|
|**2024-09-09**|**Explainable AI: Definition and attributes of a good explanation for health AI**|Evangelia Kyrimi et.al.|[2409.15338v1](http://arxiv.org/abs/2409.15338v1)|null|
|**2024-08-30**|**Exploring the Effect of Explanation Content and Format on User Comprehension and Trust**|Antonio Rago et.al.|[2408.17401v1](http://arxiv.org/abs/2408.17401v1)|null|
|**2024-08-29**|**A Survey for Large Language Models in Biomedicine**|Chong Wang et.al.|[2409.00133v1](http://arxiv.org/abs/2409.00133v1)|null|
|**2024-08-27**|**Aligning XAI with EU Regulations for Smart Biomedical Devices: A Methodology for Compliance Analysis**|Francesco Sovrano et.al.|[2408.15121v1](http://arxiv.org/abs/2408.15121v1)|null|
|**2024-08-24**|**Towards Case-based Interpretability for Medical Federated Learning**|Laura Latorre et.al.|[2408.13626v1](http://arxiv.org/abs/2408.13626v1)|null|
|**2024-08-22**|**AI in radiological imaging of soft-tissue and bone tumours: a systematic review evaluating against CLAIM and FUTURE-AI guidelines**|Douwe J. Spaanderman et.al.|[2408.12491v1](http://arxiv.org/abs/2408.12491v1)|null|
|**2024-08-14**|**Evaluating Explainable AI Methods in Deep Learning Models for Early Detection of Cerebral Palsy**|Kimji N. Pellano et.al.|[2409.00001v1](http://arxiv.org/abs/2409.00001v1)|null|
|**2024-08-06**|**MicroXercise: A Micro-Level Comparative and Explainable System for Remote Physical Therapy**|Hanchen David Wang et.al.|[2408.11837v1](http://arxiv.org/abs/2408.11837v1)|null|
|**2024-08-05**|**The Literature Review Network: An Explainable Artificial Intelligence for Systematic Literature Reviews, Meta-analyses, and Method Development**|Joshua Morriss et.al.|[2408.05239v1](http://arxiv.org/abs/2408.05239v1)|null|
|**2024-08-05**|**Enhancing Medical Learning and Reasoning Systems: A Boxology-Based Comparative Analysis of Design Patterns**|Chi Him Ng et.al.|[2408.02709v1](http://arxiv.org/abs/2408.02709v1)|null|
|**2024-08-05**|**Bayesian Kolmogorov Arnold Networks (Bayesian_KANs): A Probabilistic Approach to Enhance Accuracy and Interpretability**|Masoud Muhammed Hassan et.al.|[2408.02706v1](http://arxiv.org/abs/2408.02706v1)|null|
|**2024-07-26**|**MLtoGAI: Semantic Web based with Machine Learning for Enhanced Disease Prediction and Personalized Recommendations using Generative AI**|Shyam Dongre et.al.|[2407.20284v1](http://arxiv.org/abs/2407.20284v1)|null|
|**2024-07-25**|**Introducing Î´-XAI: a novel sensitivity-based method for local AI explanations**|Alessandro De Carlo et.al.|[2407.18343v2](http://arxiv.org/abs/2407.18343v2)|null|
|**2024-07-24**|**Enhanced Deep Learning Methodologies and MRI Selection Techniques for Dementia Diagnosis in the Elderly Population**|Nikolaos Ntampakis et.al.|[2407.17324v2](http://arxiv.org/abs/2407.17324v2)|null|
|**2024-07-24**|**Using Large Language Models to Compare Explainable Models for Smart Home Human Activity Recognition**|Michele Fiori et.al.|[2408.06352v1](http://arxiv.org/abs/2408.06352v1)|null|
|**2024-07-21**|**Explainable AI-based Intrusion Detection System for Industry 5.0: An Overview of the Literature, associated Challenges, the existing Solutions, and Potential Research Directions**|Naseem Khan et.al.|[2408.03335v1](http://arxiv.org/abs/2408.03335v1)|null|
|**2024-07-18**|**A Comparative Study on Automatic Coding of Medical Letters with Explainability**|Jamie Glen et.al.|[2407.13638v1](http://arxiv.org/abs/2407.13638v1)|[link](https://github.com/Glenj01/Medical-Coding)|
|**2024-07-09**|**Explainable AI for Enhancing Efficiency of DL-based Channel Estimation**|Abdul Karim Gizzini et.al.|[2407.07009v1](http://arxiv.org/abs/2407.07009v1)|null|
|**2024-07-07**|**Explainable AI: Comparative Analysis of Normal and Dilated ResNet Models for Fundus Disease Classification**|P. N. Karthikayan et.al.|[2407.05440v2](http://arxiv.org/abs/2407.05440v2)|null|
|**2024-07-03**|**A Survey on Trustworthiness in Foundation Models for Medical Image Analysis**|Congzhen Shi et.al.|[2407.15851v2](http://arxiv.org/abs/2407.15851v2)|null|
|**2024-07-01**|**The Impact of an XAI-Augmented Approach on Binary Classification with Scarce Data**|Ximing Wen et.al.|[2407.06206v1](http://arxiv.org/abs/2407.06206v1)|null|
|**2024-06-28**|**Can GPT-4 Help Detect Quit Vaping Intentions? An Exploration of Automatic Data Annotation Approach**|Sai Krishna Revanth Vuruma et.al.|[2407.00167v1](http://arxiv.org/abs/2407.00167v1)|null|
|**2024-06-25**|**Towards Compositional Interpretability for XAI**|Sean Tull et.al.|[2406.17583v1](http://arxiv.org/abs/2406.17583v1)|null|
|**2024-06-17**|**Slicing Through Bias: Explaining Performance Gaps in Medical Image Analysis using Slice Discovery Methods**|Vincent Olesen et.al.|[2406.12142v2](http://arxiv.org/abs/2406.12142v2)|[link](https://github.com/volesen/slicing-through-bias)|
|**2024-06-11**|**Unlocking the Potential of Metaverse in Innovative and Immersive Digital Health**|Fatemeh Ebrahimzadeh et.al.|[2406.07114v2](http://arxiv.org/abs/2406.07114v2)|null|
|**2024-06-10**|**AI-Driven Predictive Analytics Approach for Early Prognosis of Chronic Kidney Disease Using Ensemble Learning and Explainable AI**|K M Tawsik Jawad et.al.|[2406.06728v1](http://arxiv.org/abs/2406.06728v1)|null|
|**2024-06-10**|**Explainable AI for Mental Disorder Detection via Social Media: A survey and outlook**|Yusif Ibrahimov et.al.|[2406.05984v1](http://arxiv.org/abs/2406.05984v1)|null|
|**2024-06-09**|**Methodology and Real-World Applications of Dynamic Uncertain Causality Graph for Clinical Diagnosis with Explainability and Invariance**|Zhan Zhang et.al.|[2406.05746v1](http://arxiv.org/abs/2406.05746v1)|null|
|**2024-06-07**|**Advancing Histopathology-Based Breast Cancer Diagnosis: Insights into Multi-Modality and Explainability**|Faseela Abdullakutty et.al.|[2406.12897v1](http://arxiv.org/abs/2406.12897v1)|null|
|**2024-06-04**|**Using Explainable AI for EEG-based Reduced Montage Neonatal Seizure Detection**|Dinuka Sandun Udayantha et.al.|[2406.16908v3](http://arxiv.org/abs/2406.16908v3)|[link](https://github.com/dinuka-1999/braineocare)|
|**2024-06-01**|**Breast Cancer Diagnosis: A Comprehensive Exploration of Explainable Artificial Intelligence (XAI) Techniques**|Samita Bai et.al.|[2406.00532v1](http://arxiv.org/abs/2406.00532v1)|null|
|**2024-06-01**|**Unveiling Hidden Factors: Explainable AI for Feature Boosting in Speech Emotion Recognition**|Alaa Nfissi et.al.|[2406.01624v2](http://arxiv.org/abs/2406.01624v2)|[link](https://github.com/alaanfissi/unveiling-hidden-factors-explainable-ai-for-feature-boosting-in-speech-emotion-recognition)|
|**2024-05-31**|**The Explanation Necessity for Healthcare AI**|Michail Mamalakis et.al.|[2406.00216v1](http://arxiv.org/abs/2406.00216v1)|null|
|**2024-05-29**|**Interdisciplinary Expertise to Advance Equitable Explainable AI**|Chloe R. Bennett et.al.|[2406.18563v1](http://arxiv.org/abs/2406.18563v1)|null|
|**2024-05-27**|**"It depends": Configuring AI to Improve Clinical Usefulness Across Contexts**|Hubert D. ZajÄc et.al.|[2407.11978v1](http://arxiv.org/abs/2407.11978v1)|null|
|**2024-05-26**|**Improving Health Professionals' Onboarding with AI and XAI for Trustworthy Human-AI Collaborative Decision Making**|Min Hun Lee et.al.|[2405.16424v1](http://arxiv.org/abs/2405.16424v1)|null|
|**2024-05-26**|**Exploring Nutritional Impact on Alzheimer's Mortality: An Explainable AI Approach**|Ziming Liu et.al.|[2405.17502v1](http://arxiv.org/abs/2405.17502v1)|null|
|**2024-05-24**|**Explainable AI Enhances Glaucoma Referrals, Yet the Human-AI Team Still Falls Short of the AI Alone**|Catalina Gomez et.al.|[2407.11974v1](http://arxiv.org/abs/2407.11974v1)|null|
|**2024-05-23**|**Decoding Decision Reasoning: A Counterfactual-Powered Model for Knowledge Discovery**|Yingying Fang et.al.|[2406.18552v1](http://arxiv.org/abs/2406.18552v1)|null|
|**2024-05-21**|**The Role of Emotions in Informational Support Question-Response Pairs in Online Health Communities: A Multimodal Deep Learning Approach**|Mohsen Jozani et.al.|[2405.13099v1](http://arxiv.org/abs/2405.13099v1)|null|
|**2024-05-17**|**ChatGPT in Classrooms: Transforming Challenges into Opportunities in Education**|Harris Bin Munawar et.al.|[2405.10645v1](http://arxiv.org/abs/2405.10645v1)|null|
|**2024-05-13**|**Evaluating the Explainable AI Method Grad-CAM for Breath Classification on Newborn Time Series Data**|Camelia Oprea et.al.|[2405.07590v1](http://arxiv.org/abs/2405.07590v1)|null|
|**2024-05-10**|**XAI4LLM. Let Machine Learning Models and LLMs Collaborate for Enhanced In-Context Learning in Healthcare**|Fatemeh Nazary et.al.|[2405.06270v3](http://arxiv.org/abs/2405.06270v3)|null|
|**2024-05-09**|**To Trust or Not to Trust: Towards a novel approach to measure trust for XAI systems**|Miquel MirÃ³-Nicolau et.al.|[2405.05766v1](http://arxiv.org/abs/2405.05766v1)|null|
|**2024-05-05**|**Region-specific Risk Quantification for Interpretable Prognosis of COVID-19**|Zhusi Zhong et.al.|[2405.02815v1](http://arxiv.org/abs/2405.02815v1)|[link](https://github.com/zzs95/RSP_COVID)|
|**2024-04-26**|**Rad4XCNN: a new agnostic method for post-hoc global explanation of CNN-derived features by means of radiomics**|Francesco Prinzi et.al.|[2405.02334v2](http://arxiv.org/abs/2405.02334v2)|null|
|**2024-04-25**|**Attributing Responsibility in AI-Induced Incidents: A Computational Reflective Equilibrium Framework for Accountability**|Yunfei Ge et.al.|[2404.16957v1](http://arxiv.org/abs/2404.16957v1)|null|
|**2024-04-19**|**Explainable AI for Fair Sepsis Mortality Predictive Model**|Chia-Hsuan Chang et.al.|[2404.13139v1](http://arxiv.org/abs/2404.13139v1)|null|
|**2024-04-19**|**Multi Class Depression Detection Through Tweets using Artificial Intelligence**|Muhammad Osama Nusrat et.al.|[2404.13104v1](http://arxiv.org/abs/2404.13104v1)|[link](https://github.com/mnusrat786/masters-thesis)|
|**2024-04-19**|**COIN: Counterfactual inpainting for weakly supervised semantic segmentation for medical images**|Dmytro Shvetsov et.al.|[2404.12832v2](http://arxiv.org/abs/2404.12832v2)|[link](https://github.com/dmytro-shvetsov/counterfactual-search)|
|**2024-04-15**|**Hybrid Intelligence for Digital Humanities**|Victor de Boer et.al.|[2406.15374v1](http://arxiv.org/abs/2406.15374v1)|null|
|**2024-04-14**|**Ethical Framework for Responsible Foundational Models in Medical Imaging**|Abhijit Das et.al.|[2406.11868v1](http://arxiv.org/abs/2406.11868v1)|null|
|**2024-04-09**|**Advancements in Radiomics and Artificial Intelligence for Thyroid Cancer Diagnosis**|Milad Yousefi et.al.|[2404.07239v1](http://arxiv.org/abs/2404.07239v1)|null|
|**2024-04-06**|**Predictive Modeling for Breast Cancer Classification in the Context of Bangladeshi Patients: A Supervised Machine Learning Approach with Explainable AI**|Taminul Islam et.al.|[2404.04686v1](http://arxiv.org/abs/2404.04686v1)|null|
|**2024-04-05**|**Enhancing Breast Cancer Diagnosis in Mammography: Evaluation and Integration of Convolutional Neural Networks and Explainable AI**|Maryam Ahmed et.al.|[2404.03892v3](http://arxiv.org/abs/2404.03892v3)|null|
|**2024-03-30**|**Advancing Multimodal Data Fusion in Pain Recognition: A Strategy Leveraging Statistical Correlation and Human-Centered Perspectives**|Xingrui Gu et.al.|[2404.00320v2](http://arxiv.org/abs/2404.00320v2)|null|
|**2024-03-26**|**Addressing Social Misattributions of Large Language Models: An HCXAI-based Approach**|Andrea Ferrario et.al.|[2403.17873v1](http://arxiv.org/abs/2403.17873v1)|null|
|**2024-03-26**|**Clinical Domain Knowledge-Derived Template Improves Post Hoc AI Explanations in Pneumothorax Classification**|Han Yuan et.al.|[2403.18871v1](http://arxiv.org/abs/2403.18871v1)|[link](https://github.com/han-yuan-med/template-explanation)|
|**2024-03-03**|**Enhancing Neural Machine Translation of Low-Resource Languages: Corpus Development, Human Evaluation and Explainable AI Architectures**|SÃ©amus Lankford et.al.|[2403.01580v1](http://arxiv.org/abs/2403.01580v1)|null|
|**2024-02-28**|**Cause and Effect: Can Large Language Models Truly Understand Causality?**|Swagata Ashwani et.al.|[2402.18139v3](http://arxiv.org/abs/2402.18139v3)|null|
|**2024-02-28**|**Artificial Intelligence and Diabetes Mellitus: An Inside Look Through the Retina**|Yasin Sadeghi Bazargani et.al.|[2402.18600v1](http://arxiv.org/abs/2402.18600v1)|null|
|**2024-02-22**|**Multi-stakeholder Perspective on Responsible Artificial Intelligence and Acceptability in Education**|A. J. Karran et.al.|[2402.15027v2](http://arxiv.org/abs/2402.15027v2)|null|
|**2024-02-12**|**Deciphering Heartbeat Signatures: A Vision Transformer Approach to Explainable Atrial Fibrillation Detection from ECG Signals**|Aruna Mohan et.al.|[2402.09474v2](http://arxiv.org/abs/2402.09474v2)|null|
|**2024-02-05**|**Illuminate: A novel approach for depression detection with explainable analysis and proactive therapy using prompt engineering**|Aryan Agrawal et.al.|[2402.05127v1](http://arxiv.org/abs/2402.05127v1)|null|
|**2024-01-24**|**Information That Matters: Exploring Information Needs of People Affected by Algorithmic Decisions**|TimothÃ©e Schmude et.al.|[2401.13324v6](http://arxiv.org/abs/2401.13324v6)|null|
|**2024-01-02**|**Evaluating Large Language Models on the GMAT: Implications for the Future of Business Education**|Vahid Ashrafimoghari et.al.|[2401.02985v1](http://arxiv.org/abs/2401.02985v1)|null|
|**2023-12-29**|**XAI for In-hospital Mortality Prediction via Multimodal ICU Data**|Xingqiao Li et.al.|[2312.17624v1](http://arxiv.org/abs/2312.17624v1)|[link](https://github.com/lixingqiao/xai-icu)|

#### Abstracts
##### **Enhanced Suicidal Ideation Detection from Social Media Using a CNN-BiLSTM Hybrid Model**
2501.11094v1 by Mohaiminul Islam Bhuiyan, Nur Shazwani Kamarudin, Nur Hafieza Ismail

Suicidal ideation detection is crucial for preventing suicides, a leading
cause of death worldwide. Many individuals express suicidal thoughts on social
media, offering a vital opportunity for early detection through advanced
machine learning techniques. The identification of suicidal ideation in social
media text is improved by utilising a hybrid framework that integrates
Convolutional Neural Networks (CNN) and Bidirectional Long Short-Term Memory
(BiLSTM), enhanced with an attention mechanism. To enhance the interpretability
of the model's predictions, Explainable AI (XAI) methods are applied, with a
particular focus on SHapley Additive exPlanations (SHAP), are incorporated. At
first, the model managed to reach an accuracy of 92.81%. By applying
fine-tuning and early stopping techniques, the accuracy improved to 94.29%. The
SHAP analysis revealed key features influencing the model's predictions, such
as terms related to mental health struggles. This level of transparency boosts
the model's credibility while helping mental health professionals understand
and trust the predictions. This work highlights the potential for improving the
accuracy and interpretability of detecting suicidal tendencies, making a
valuable contribution to the progress of mental health monitoring systems. It
emphasizes the significance of blending powerful machine learning methods with
explainability to develop reliable and impactful mental health solutions.

æè¦ï¼èªæ®ºæå¿µåµæ¸¬å°æ¼é é²èªæ®ºè³ééè¦ï¼èèªæ®ºæ¯å¨çä¸»è¦çæ­»äº¡åå ãè¨±å¤äººå¨ç¤¾ç¾¤åªé«ä¸è¡¨éèªæ®ºå¿µé ­ï¼éæä¾äºééé²éæ©å¨å­¸ç¿æè¡é²è¡æ©æåµæ¸¬çéè¦æ©æãééæ´åå·ç©ç¥ç¶ç¶²è·¯ (CNN) åéåé·ç­æè¨æ¶ (BiLSTM) çæ··åæ¶æ§ï¼ä¸¦å å¥æ³¨æåæ©å¶ï¼å¯ä»¥æåå¨ç¤¾ç¾¤åªé«æå­ä¸­è¾¨è­èªæ®ºæå¿µçè½åãçºäºå å¼·æ¨¡åé æ¸¬çå¯è§£éæ§ï¼æåæ¡ç¨å¯è§£éäººå·¥æºæ§ (XAI) æ¹æ³ï¼ç¹å¥èéæ¼ SHapley å æ³è§£é (SHAP)ãä¸éå§ï¼æ¨¡åæåéå° 92.81% çæºç¢ºåº¦ãééå¥ç¨å¾®èª¿åæ©æåæ­¢æè¡ï¼æºç¢ºåº¦æåè³ 94.29%ãSHAP åææ­é²äºå½±é¿æ¨¡åé æ¸¬çééµç¹å¾µï¼ä¾å¦èå¿çå¥åº·å°å¢ç¸éçè©å½ãéç¨®éæåº¦æåäºæ¨¡åçå¯ä¿¡åº¦ï¼åæåå©å¿çå¥åº·å°æ¥­äººå¡çè§£åä¿¡è³´é æ¸¬çµæãéé å·¥ä½çªé¡¯äºæååµæ¸¬èªæ®ºå¾åçæºç¢ºåº¦åå¯è§£éæ§çæ½åï¼çºå¿çå¥åº·ç£æ§ç³»çµ±çé²å±ååºå¯¶è²´çè²¢ç»ãå®å¼·èª¿äºå°å¼·å¤§çæ©å¨å­¸ç¿æ¹æ³èå¯è§£éæ§ç¸çµåä»¥éç¼å¯é ä¸æå½±é¿åçå¿çå¥åº·è§£æ±ºæ¹æ¡çéè¦æ§ã

##### **SEANN: A Domain-Informed Neural Network for Epidemiological Insights**
2501.10273v1 by Jean-Baptiste Guimbaud, Marc Plantevit, LÃ©a MaÃ®tre, RÃ©my Cazabet

In epidemiology, traditional statistical methods such as logistic regression,
linear regression, and other parametric models are commonly employed to
investigate associations between predictors and health outcomes. However,
non-parametric machine learning techniques, such as deep neural networks
(DNNs), coupled with explainable AI (XAI) tools, offer new opportunities for
this task. Despite their potential, these methods face challenges due to the
limited availability of high-quality, high-quantity data in this field. To
address these challenges, we introduce SEANN, a novel approach for informed
DNNs that leverages a prevalent form of domain-specific knowledge: Pooled
Effect Sizes (PES). PESs are commonly found in published Meta-Analysis studies,
in different forms, and represent a quantitative form of a scientific
consensus. By direct integration within the learning procedure using a custom
loss, we experimentally demonstrate significant improvements in the
generalizability of predictive performances and the scientific plausibility of
extracted relationships compared to a domain-knowledge agnostic neural network
in a scarce and noisy data setting.

æè¦ï¼å¨æµè¡çå­¸ä¸­ï¼å³çµ±ççµ±è¨æ¹æ³ï¼ä¾å¦éè¼¯è¿´æ­¸ãç·æ§è¿´æ­¸åå¶ä»åæ¸æ¨¡åéå¸¸ç¨æ¼èª¿æ¥é æ¸¬å å­èå¥åº·çµæä¹éçéè¯ãç¶èï¼éåæ¸æ©å¨å­¸ç¿æè¡ï¼ä¾å¦æ·±åº¦ç¥ç¶ç¶²è·¯ (DNN)ï¼çµåå¯è§£éç AI (XAI) å·¥å·ï¼çºéé ä»»åæä¾äºæ°çæ©æãåç®¡éäºæ¹æ³å·ææ½åï¼ä½ç±æ¼è©²é åç¼ºä¹é«åè³ªãé«æ¸éè³æï¼å æ­¤éäºæ¹æ³é¢è¨ææ°ãçºäºæå°éäºææ°ï¼æåå¼å¥äº SEANNï¼éæ¯ä¸ç¨®æ°ç©çæ¹æ³ï¼ç¨æ¼ç²åç¥è­ç DNNï¼å®å©ç¨äºä¸ç¨®æµè¡çé åç¹å®ç¥è­å½¢å¼ï¼å½ç¸½ææé (PES)ãPES éå¸¸ä»¥ä¸åçå½¢å¼åºç¾å¨å·²ç¼è¡¨ç Meta åæç ç©¶ä¸­ï¼ä¸¦ä»£è¡¨ç§å­¸å±è­çéåå½¢å¼ãééä½¿ç¨èªè¨æå¤±å½æ¸ç´æ¥æ´åå¨å­¸ç¿ç¨åºä¸­ï¼æåä»¥å¯¦é©æ¹å¼è­æäºé æ¸¬æè½çæ¦æ¬æ§ä»¥åèå¾ç¼ºä¹é åç¥è­çç¥ç¶ç¶²è·¯ä¸­æåçéä¿ç¸æ¯ï¼ç§å­¸åçæ§çé¡¯èæåï¼ä¸æ¯å¨ç¨å°ä¸æéè¨çè³æè¨­å®ä¸­ã

##### **Artificial Intelligence-Driven Clinical Decision Support Systems**
2501.09628v1 by Muhammet Alkan, Idris Zakariyya, Samuel Leighton, Kaushik Bhargav Sivangi, Christos Anagnostopoulos, Fani Deligianni

As artificial intelligence (AI) becomes increasingly embedded in healthcare
delivery, this chapter explores the critical aspects of developing reliable and
ethical Clinical Decision Support Systems (CDSS). Beginning with the
fundamental transition from traditional statistical models to sophisticated
machine learning approaches, this work examines rigorous validation strategies
and performance assessment methods, including the crucial role of model
calibration and decision curve analysis. The chapter emphasizes that creating
trustworthy AI systems in healthcare requires more than just technical
accuracy; it demands careful consideration of fairness, explainability, and
privacy. The challenge of ensuring equitable healthcare delivery through AI is
stressed, discussing methods to identify and mitigate bias in clinical
predictive models. The chapter then delves into explainability as a cornerstone
of human-centered CDSS. This focus reflects the understanding that healthcare
professionals must not only trust AI recommendations but also comprehend their
underlying reasoning. The discussion advances in an analysis of privacy
vulnerabilities in medical AI systems, from data leakage in deep learning
models to sophisticated attacks against model explanations. The text explores
privacy-preservation strategies such as differential privacy and federated
learning, while acknowledging the inherent trade-offs between privacy
protection and model performance. This progression, from technical validation
to ethical considerations, reflects the multifaceted challenges of developing
AI systems that can be seamlessly and reliably integrated into daily clinical
practice while maintaining the highest standards of patient care and data
protection.

æè¦ï¼é¨èäººå·¥æºæ§ (AI) å¨é«çä¿å¥ä¸­çæç¨æ¥çæ®åï¼æ¬ç« æ¢è¨äºéç¼å¯é ä¸ç¬¦åéå¾·æ¨æºçè¨åºæ±ºç­æ¯æ´ç³»çµ± (CDSS) çééµé¢åãå¾å³çµ±çµ±è¨æ¨¡åå°è¤éæ©å¨å­¸ç¿æ¹æ³çåºæ¬è½è®éå§ï¼éé å·¥ä½å¯©æ¥äºå´è¬¹çé©è­ç­ç¥åæè½è©ä¼°æ¹æ³ï¼åæ¬æ¨¡åæ ¡æºåæ±ºç­æ²ç·åæçééµè§è²ãæ¬ç« å¼·èª¿ï¼å¨é«çä¿å¥ä¸­å»ºç«å¼å¾ä¿¡è³´ç AI ç³»çµ±ä¸åªæ¯æè¡ä¸çæºç¢ºæ§ï¼å®éè¦ä»ç´°èéå¬å¹³æ§ãå¯è§£éæ§åé±ç§æ¬ãæ¬ç« å¼·èª¿äºéé AI ç¢ºä¿å¬å¹³çé«çä¿å¥æåçææ°ï¼ä¸¦è¨è«äºè­å¥åæ¸è¼è¨åºé æ¸¬æ¨¡åä¸­åå·®çæ¹æ³ãæ¥èï¼æ¬ç« æ·±å¥æ¢è¨å¯è§£éæ§ï¼ä½çºä»¥äººçºä¸­å¿ç CDSS çåºç³ãéç¨®éæ³¨åæ äºé«çä¿å¥å°æ¥­äººå¡ä¸åå¿é ä¿¡ä»» AI å»ºè­°ï¼éå¿é çè§£å¶èå¾çæ¨çãè¨è«é²ä¸æ­¥åæäºé«ç AI ç³»çµ±ä¸­çé±ç§æ¼æ´ï¼å¾æ·±åº¦å­¸ç¿æ¨¡åä¸­çè³æå¤æ´©å°éå°æ¨¡åè§£éçè¤éæ»æãæ¬ææ¢è¨äºé±ç§ä¿è­·ç­ç¥ï¼ä¾å¦å·®åé±ç§åè¯åå­¸ç¿ï¼åææ¿èªé±ç§ä¿è­·åæ¨¡åæè½ä¹éçåºæåæ¨ãéç¨®å¾æè¡é©è­å°éå¾·èéçé²å±ï¼åæ äºéç¼ AI ç³»çµ±çå¤é¢åææ°ï¼éäºç³»çµ±å¯ä»¥ç¡ç¸«ä¸å¯é å°æ´åå°æ¥å¸¸è¨åºå¯¦åä¸­ï¼åæç¶­ææé«ççæ£ç§è­·åè³æä¿è­·æ¨æºã

##### **MedGrad E-CLIP: Enhancing Trust and Transparency in AI-Driven Skin Lesion Diagnosis**
2501.06887v1 by Sadia Kamal, Tim Oates

As deep learning models gain attraction in medical data, ensuring transparent
and trustworthy decision-making is essential. In skin cancer diagnosis, while
advancements in lesion detection and classification have improved accuracy, the
black-box nature of these methods poses challenges in understanding their
decision processes, leading to trust issues among physicians. This study
leverages the CLIP (Contrastive Language-Image Pretraining) model, trained on
different skin lesion datasets, to capture meaningful relationships between
visual features and diagnostic criteria terms. To further enhance transparency,
we propose a method called MedGrad E-CLIP, which builds on gradient-based
E-CLIP by incorporating a weighted entropy mechanism designed for complex
medical imaging like skin lesions. This approach highlights critical image
regions linked to specific diagnostic descriptions. The developed integrated
pipeline not only classifies skin lesions by matching corresponding
descriptions but also adds an essential layer of explainability developed
especially for medical data. By visually explaining how different features in
an image relates to diagnostic criteria, this approach demonstrates the
potential of advanced vision-language models in medical image analysis,
ultimately improving transparency, robustness, and trust in AI-driven
diagnostic systems.

æè¦ï¼éçæ·±åº¦å­¦ä¹ æ¨¡åå¨å»å­¦æ°æ®ä¸­è·å¾å³æ³¨ï¼ç¡®ä¿éæä¸å¼å¾ä¿¡èµçå³ç­è³å³éè¦ãå¨ç®è¤çè¯æ­ä¸­ï¼è½ç¶çç¶æ£æµååç±»çè¿æ­¥æé«äºåç¡®æ§ï¼ä½è¿äºæ¹æ³çé»çæ§è´¨å¯¹çè§£å¶å³ç­è¿ç¨ææäºææï¼å¯¼è´å»çä¹é´çä¿¡ä»»é®é¢ãæ¬ç ç©¶å©ç¨å¨ä¸åç®è¤çåæ°æ®éä¸è®­ç»ç CLIPï¼å¯¹æ¯è¯­è¨å¾åé¢è®­ç»ï¼æ¨¡åï¼ä»¥ææè§è§ç¹å¾åè¯æ­æ åæ¯è¯­ä¹é´çææä¹å³ç³»ãä¸ºäºè¿ä¸æ­¥æé«éæåº¦ï¼æä»¬æåºäºä¸ç§åä¸º MedGrad E-CLIP çæ¹æ³ï¼è¯¥æ¹æ³éè¿ç»åä¸ä¸ºç®è¤çåç­å¤æå»å­¦å½±åè®¾è®¡çå æçµæºå¶ï¼å»ºç«å¨åºäºæ¢¯åº¦ç E-CLIP ä¹ä¸ãæ­¤æ¹æ³çªåºäºä¸ç¹å®è¯æ­æè¿°ç¸å³èçå³é®å¾ååºåãå¼åçéæç®¡éä¸ä»éè¿å¹éç¸åºçæè¿°å¯¹ç®è¤çåè¿è¡åç±»ï¼è¿æ·»å äºä¸å±ä¸é¨ä¸ºå»å­¦æ°æ®å¼åçåºæ¬å¯è§£éæ§ãéè¿ç´è§å°è§£éå¾åä¸­ä¸åç¹å¾ä¸è¯æ­æ åçå³ç³»ï¼è¿ç§æ¹æ³å±ç¤ºäºé«çº§è§è§è¯­è¨æ¨¡åå¨å»å­¦å¾ååæä¸­çæ½åï¼æç»æé«äºéæåº¦ãç¨³å¥æ§åå¯¹äººå·¥æºè½é©±å¨çè¯æ­ç³»ç»çä¿¡ä»»ã

##### **Explaining Humour Style Classifications: An XAI Approach to Understanding Computational Humour Analysis**
2501.02891v1 by Mary Ogbuka Kenneth, Foaad Khosmood, Abbas Edalat

Humour styles can have either a negative or a positive impact on well-being.
Given the importance of these styles to mental health, significant research has
been conducted on their automatic identification. However, the automated
machine learning models used for this purpose are black boxes, making their
prediction decisions opaque. Clarity and transparency are vital in the field of
mental health. This paper presents an explainable AI (XAI) framework for
understanding humour style classification, building upon previous work in
computational humour analysis. Using the best-performing single model
(ALI+XGBoost) from prior research, we apply comprehensive XAI techniques to
analyse how linguistic, emotional, and semantic features contribute to humour
style classification decisions. Our analysis reveals distinct patterns in how
different humour styles are characterised and misclassified, with particular
emphasis on the challenges in distinguishing affiliative humour from other
styles. Through detailed examination of feature importance, error patterns, and
misclassification cases, we identify key factors influencing model decisions,
including emotional ambiguity, context misinterpretation, and target
identification. The framework demonstrates significant utility in understanding
model behaviour, achieving interpretable insights into the complex interplay of
features that define different humour styles. Our findings contribute to both
the theoretical understanding of computational humour analysis and practical
applications in mental health, content moderation, and digital humanities
research.

æè¦ï¼å¹½é»é¢¨æ ¼å°å¹¸ç¦æå¯è½ç¢çè² é¢ææ­£é¢çå½±é¿ã
éæ¼éäºé¢¨æ ¼å°å¿çå¥åº·çéè¦æ§ï¼å·²ç¶å°å¶èªåè­å¥é²è¡äºå¤§éç ç©¶ãç¶èï¼ç¨æ¼æ­¤ç®ççèªåæ©å¨å­¸ç¿æ¨¡åæ¯é»çå­ï¼ä½¿å¾å¶é æ¸¬æ±ºç­ä¸éæãæ¸æ°åº¦åéæåº¦å¨å¿çå¥åº·é åè³ééè¦ãæ¬ææåºäºä¸åå¯è§£éç AI (XAI) æ¡æ¶ï¼ç¨æ¼çè§£å¹½é»é¢¨æ ¼åé¡ï¼å»ºç«å¨è¨ç®å¹½é»åæçååå·¥ä½ä¹ä¸ãä½¿ç¨ååç ç©¶ä¸­è¡¨ç¾æå¥½çå®ä¸æ¨¡å (ALI+XGBoost)ï¼æåæç¨å¨é¢ç XAI æè¡ä¾åæèªè¨ãæç·åèªç¾©ç¹å¾µå¦ä½å½±é¿å¹½é»é¢¨æ ¼åé¡æ±ºç­ãæåçåææ­ç¤ºäºä¸åå¹½é»é¢¨æ ¼å¦ä½è¢«è¡¨å¾µåé¯èª¤åé¡çä¸åæ¨¡å¼ï¼ç¹å¥å¼·èª¿äºååè¯å±¬å¹½é»èå¶ä»é¢¨æ ¼çææ°ãééä»ç´°æª¢æ¥ç¹å¾µéè¦æ§ãé¯èª¤æ¨¡å¼åé¯èª¤åé¡æ¡ä¾ï¼æåç¢ºå®äºå½±é¿æ¨¡åæ±ºç­çééµå ç´ ï¼åæ¬æç·æ¨¡ç³ãæå¢èª¤è§£åç®æ¨è­å¥ãè©²æ¡æ¶å±ç¤ºäºå¨çè§£æ¨¡åè¡çºæ¹é¢çé¡¯èæç¨ï¼å¯¦ç¾äºå°å®ç¾©ä¸åå¹½é»é¢¨æ ¼çç¹å¾µä¹éè¤éç¸äºä½ç¨çå¯è§£éè¦è§£ãæåçç¼ç¾æå©æ¼è¨ç®å¹½é»åæççè«çè§£åå¿çå¥åº·ãå§å®¹å¯©æ ¸åæ¸å­äººæç ç©¶ä¸­çå¯¦éæç¨ã

##### **The Emotional Spectrum of LLMs: Leveraging Empathy and Emotion-Based Markers for Mental Health Support**
2412.20068v1 by Alessandro De Grandi, Federico Ravenda, Andrea Raballo, Fabio Crestani

The increasing demand for mental health services has highlighted the need for
innovative solutions, particularly in the realm of psychological conversational
AI, where the availability of sensitive data is scarce. In this work, we
explored the development of a system tailored for mental health support with a
novel approach to psychological assessment based on explainable emotional
profiles in combination with empathetic conversational models, offering a
promising tool for augmenting traditional care, particularly where immediate
expertise is unavailable. Our work can be divided into two main parts,
intrinsecaly connected to each other. First, we present RACLETTE, a
conversational system that demonstrates superior emotional accuracy compared to
state-of-the-art benchmarks in both understanding users' emotional states and
generating empathetic responses during conversations, while progressively
building an emotional profile of the user through their interactions. Second,
we show how the emotional profiles of a user can be used as interpretable
markers for mental health assessment. These profiles can be compared with
characteristic emotional patterns associated with different mental disorders,
providing a novel approach to preliminary screening and support.

æè¦ï¼é¨èå°å¿çå¥åº·æåéæ±çå¢å ï¼å¸é¡¯äºåµæ°è§£æ±ºæ¹æ¡çéæ±ï¼ç¹å¥æ¯å¨å¿çå°è©±å¼äººå·¥æºæ§é åï¼é£è£¡ç¼ºä¹ææè³æãå¨éé å·¥ä½ä¸­ï¼æåæ¢ç´¢äºéç¼ä¸åéå°å¿çå¥åº·æ¯æçç³»çµ±ï¼æ¡ç¨ä¸ç¨®åºæ¼å¯è§£éçæç·ç¹å¾µçæ°æ¹æ³é²è¡å¿çè©ä¼°ï¼çµååçå¿å°è©±æ¨¡å¼ï¼æä¾äºä¸åæåéçå·¥å·ï¼ç¨æ¼æ´åå³çµ±ç§è­·ï¼ç¹å¥æ¯å¨ç¡æ³ç«å³ç²å¾å°æ¥­ç¥è­çææ³ä¸ãæåçå·¥ä½å¯ä»¥åçºå©åä¸»è¦é¨åï¼å½¼æ­¤å§å¨ç¸éãé¦åï¼æåå±ç¤ºäº RACLETTEï¼ä¸åå°è©±ç³»çµ±ï¼èæåé²çåºæºç¸æ¯ï¼å¨çè§£ä½¿ç¨èæç·çæåå¨å°è©±ä¸­ç¢çåçå¿åææ¹é¢è¡¨ç¾åºåªè¶çæç·æºç¢ºæ§ï¼åæééä»åçäºåéæ¼¸å»ºç«ä½¿ç¨èçæç·ç¹å¾µãå¶æ¬¡ï¼æåå±ç¤ºäºä½¿ç¨èçæç·ç¹å¾µå¦ä½å¯ç¨ä½å¿çå¥åº·è©ä¼°çå¯è§£éæ¨è¨ãéäºç¹å¾µå¯ä»¥èèä¸åå¿çç¾çç¸éçå¸åæç·æ¨¡å¼é²è¡æ¯è¼ï¼æä¾äºä¸ç¨®åæ­¥ç¯©é¸åæ¯æçæ°æ¹æ³ã

##### **A Review on the Integration of Artificial Intelligence and Medical Imaging in IVF Ovarian Stimulation**
2412.19688v1 by Jana Zakall, Birgit Pohn, Antonia Graf, Daniel Kovatchki, Arezoo Borji, Ragib Shahriar Islam, Hossam Haick, Heinz Strohmer, Sepideh Hatamikia

Artificial intelligence (AI) has emerged as a powerful tool to enhance
decision-making and optimize treatment protocols in in vitro fertilization
(IVF). In particular, AI shows significant promise in supporting
decision-making during the ovarian stimulation phase of the IVF process. This
review evaluates studies focused on the applications of AI combined with
medical imaging in ovarian stimulation, examining methodologies, outcomes, and
current limitations. Our analysis of 13 studies on this topic reveals that,
reveal that while AI algorithms demonstrated notable potential in predicting
optimal hormonal dosages, trigger timing, and oocyte retrieval outcomes, the
medical imaging data utilized predominantly came from two-dimensional (2D)
ultrasound which mainly involved basic quantifications, such as follicle size
and number, with limited use of direct feature extraction or advanced image
analysis techniques. This points to an underexplored opportunity where advanced
image analysis approaches, such as deep learning, and more diverse imaging
modalities, like three-dimensional (3D) ultrasound, could unlock deeper
insights. Additionally, the lack of explainable AI (XAI) in most studies raises
concerns about the transparency and traceability of AI-driven decisions - key
factors for clinical adoption and trust. Furthermore, many studies relied on
single-center designs and small datasets, which limit the generalizability of
their findings. This review highlights the need for integrating advanced
imaging analysis techniques with explainable AI methodologies, as well as the
importance of leveraging multicenter collaborations and larger datasets.
Addressing these gaps has the potential to enhance ovarian stimulation
management, paving the way for efficient, personalized, and data-driven
treatment pathways that improve IVF outcomes.

æè¦ï¼äººå·¥æºæ§ï¼AIï¼å·²æçºå¢å¼·é«å¤åç²¾ï¼IVFï¼æ±ºç­å¶å®ååªåæ²»çæ¹æ¡çå¼·å¤§å·¥å·ãç¹å¥æ¯ï¼AI å¨æ¯æ IVF éç¨ä¸­åµå·¢åºæ¿éæ®µçæ±ºç­å¶å®æ¹é¢é¡¯ç¤ºåºé¡¯èçåæ¯ãæ¬ç¶è¿°è©ä¼°äºå°æ³¨æ¼ AI çµååµå·¢åºæ¿ä¸­çé«å­¸å½±åæç¨ãæª¢é©æ¹æ³ãçµæåç¶åéå¶çç ç©¶ãæåå° 13 é éæ¼æ­¤ä¸»é¡çç ç©¶åæé¡¯ç¤ºï¼éç¶ AI æ¼ç®æ³å¨é æ¸¬æä½³è·ç¾èåéãè§¸ç¼ææ©ååµå­ååºçµææ¹é¢è¡¨ç¾åºé¡¯èçæ½åï¼ä½æå©ç¨çé«å­¸å½±åæ¸æä¸»è¦ä¾èªæ¼äºæ¬¡åï¼2Dï¼è¶é³æ³¢ï¼èäºæ¬¡åè¶é³æ³¢ä¸»è¦æ¶ååºæ¬éåï¼ä¾å¦æ¿¾æ³¡å¤§å°åæ¸éï¼ä¸æéä½¿ç¨ç´æ¥ç¹å¾µæåæé²éå½±ååææè¡ãéæåä¸åå°æªæ¢ç´¢çæ©æï¼ä¾å¦æ·±åº¦å­¸ç¿ç­é²éå½±ååææ¹æ³ï¼ä»¥åæ´å¤åçå½±åæ¨¡å¼ï¼ä¾å¦ä¸ç¶­ï¼3Dï¼è¶é³æ³¢ï¼å¯ä»¥è§£éæ´æ·±å¥çè¦è§£ãæ­¤å¤ï¼å¤§å¤æ¸ç ç©¶ç¼ºä¹å¯è§£é AIï¼XAIï¼ï¼éå¼èµ·äºäººåå° AI é©åæ±ºç­çéæåº¦åå¯è¿½æº¯æ§çææï¼èéæåº¦åå¯è¿½æº¯æ§æ¯è¨åºæ¡ç¨åä¿¡ä»»çééµå ç´ ãæ­¤å¤ï¼è¨±å¤ç ç©¶ä¾è³´æ¼å®ä¸­å¿è¨­è¨åå°åæ¸æéï¼ééå¶äºå¶ç¼ç¾çæ®éæ§ãæ¬ç¶è¿°å¼·èª¿äºå°é²éå½±ååææè¡èå¯è§£é AI æ¹æ³æ´åèµ·ä¾çå¿è¦æ§ï¼ä»¥åå©ç¨å¤ä¸­å¿åä½åå¤§åæ¸æéçéè¦æ§ãè§£æ±ºéäºå·®è·æå¯è½å¢å¼·åµå·¢åºæ¿ç®¡çï¼çºææãåäººååæ¸æé©åçæ²»çéå¾éªå¹³éè·¯ï¼é²èæ¹å IVF çµæã

##### **Enhancing Cancer Diagnosis with Explainable & Trustworthy Deep Learning Models**
2412.17527v1 by Badaru I. Olumuyiwa, The Anh Han, Zia U. Shamszaman

This research presents an innovative approach to cancer diagnosis and
prediction using explainable Artificial Intelligence (XAI) and deep learning
techniques. With cancer causing nearly 10 million deaths globally in 2020,
early and accurate diagnosis is crucial. Traditional methods often face
challenges in cost, accuracy, and efficiency. Our study develops an AI model
that provides precise outcomes and clear insights into its decision-making
process, addressing the "black box" problem of deep learning models. By
employing XAI techniques, we enhance interpretability and transparency,
building trust among healthcare professionals and patients. Our approach
leverages neural networks to analyse extensive datasets, identifying patterns
for cancer detection. This model has the potential to revolutionise diagnosis
by improving accuracy, accessibility, and clarity in medical decision-making,
possibly leading to earlier detection and more personalised treatment
strategies. Furthermore, it could democratise access to high-quality
diagnostics, particularly in resource-limited settings, contributing to global
health equity. The model's applications extend beyond cancer diagnosis,
potentially transforming various aspects of medical decision-making and saving
millions of lives worldwide.

æè¦ï¼æ¬ç ç©¶æåºäºä¸ååµæ°çççè¨ºæ·åé æ¸¬æ¹æ³ï¼ä½¿ç¨å¯è§£éçäººå·¥æºæ§ (XAI) åæ·±åº¦å­¸ç¿æè¡ãç±æ¼ççå¨ 2020 å¹´é æå¨çè¿ 1,000 è¬äººæ­»äº¡ï¼å æ­¤æ©ææºç¢ºçè¨ºæ·è³ééè¦ãå³çµ±æ¹æ³éå¸¸é¢è¨ææ¬ãæºç¢ºæ§åæçæ¹é¢çææ°ãæåçç ç©¶éç¼äºä¸å AI æ¨¡åï¼å®æä¾ç²¾ç¢ºççµæä¸¦æ¸æ¥å°äºè§£å¶æ±ºç­éç¨ï¼è§£æ±ºäºæ·±åº¦å­¸ç¿æ¨¡åçãé»ç®±ãåé¡ãééæ¡ç¨ XAI æè¡ï¼æåå¢å¼·äºè§£éæ§åéæåº¦ï¼å¨é«çå°æ¥­äººå¡åæ£èä¹éå»ºç«ä¿¡ä»»ãæåçåæ³å©ç¨ç¥ç¶ç¶²è·¯åæå»£æ³çæ¸æéï¼è­å¥ççæª¢æ¸¬æ¨¡å¼ãéåæ¨¡åæå¯è½ééæé«é«çæ±ºç­çæºç¢ºæ§ãå¯åæ§åæ¸æ°åº¦ä¾é©æ°è¨ºæ·ï¼å¯è½å°è´æ´æ©çæª¢æ¸¬åæ´åæ§åçæ²»çç­ç¥ãæ­¤å¤ï¼å®å¯ä»¥ä½¿æ´å¤äººç²å¾é«åè³ªçè¨ºæ·ï¼ç¹å¥æ¯å¨è³æºæéçç°å¢ä¸­ï¼æå©æ¼å¨çå¥åº·å¬å¹³ãè©²æ¨¡åçæç¨ç¯åä¸åéæ¼ççè¨ºæ·ï¼éå¯è½è½è®é«çæ±ºç­çååæ¹é¢ï¼ä¸¦æ¯æå¨çæ¸ç¾è¬äººççå½ã

##### **Towards Interpretable Radiology Report Generation via Concept Bottlenecks using a Multi-Agentic RAG**
2412.16086v2 by Hasan Md Tusfiqur Alam, Devansh Srivastav, Md Abdul Kadir, Daniel Sonntag

Deep learning has advanced medical image classification, but interpretability
challenges hinder its clinical adoption. This study enhances interpretability
in Chest X-ray (CXR) classification by using concept bottleneck models (CBMs)
and a multi-agent Retrieval-Augmented Generation (RAG) system for report
generation. By modeling relationships between visual features and clinical
concepts, we create interpretable concept vectors that guide a multi-agent RAG
system to generate radiology reports, enhancing clinical relevance,
explainability, and transparency. Evaluation of the generated reports using an
LLM-as-a-judge confirmed the interpretability and clinical utility of our
model's outputs. On the COVID-QU dataset, our model achieved 81% classification
accuracy and demonstrated robust report generation performance, with five key
metrics ranging between 84% and 90%. This interpretable multi-agent framework
bridges the gap between high-performance AI and the explainability required for
reliable AI-driven CXR analysis in clinical settings. Our code is available at
https://github.com/tifat58/IRR-with-CBM-RAG.git.

æè¦ï¼æ·±åº¦å­¸ç¿å·²æåé«å­¸å½±ååé¡ï¼ä½å¯è§£éæ§ææ°é»ç¤å¶è¨åºæç¨ãæ¬ç ç©¶ééä½¿ç¨æ¦å¿µç¶é ¸æ¨¡å (CBM) åå¤ä»£çæª¢ç´¢å¢å¼·çæ (RAG) ç³»çµ±é²è¡å ±åçæï¼ä¾å¢å¼·è¸é¨ X å (CXR) åé¡çå¯è§£éæ§ãééå»ºæ¨¡è¦è¦ºç¹å¾µèè¨åºæ¦å¿µä¹éçéä¿ï¼æåå»ºç«å¯è§£éçæ¦å¿µåéï¼å¼å°å¤ä»£ç RAG ç³»çµ±çææ¾å°å ±åï¼å¢å¼·è¨åºç¸éæ§ãå¯è§£éæ§åéæåº¦ãä½¿ç¨ LLM ä½çºè©å¯©å¡å°çæå ±åé²è¡è©ä¼°ï¼ç¢ºèªäºæåæ¨¡åè¼¸åºçå¯è§£éæ§åè¨åºæç¨ãå¨ COVID-QU è³æéä¸ï¼æåçæ¨¡åéå°äº 81% çåé¡æºç¢ºçï¼ä¸¦å±ç¤ºäºç©©å¥çå ±åçææè½ï¼äºé ééµææ¨ä»æ¼ 84% è³ 90% ä¹éãéåå¯è§£éçå¤ä»£çæ¶æ§å½åäºé«æ§è½ AI èè¨åºç°å¢ä¸­å¯é ç AI é©å CXR åææéçè§£éæ§ä¹éçå·®è·ãæåçç¨å¼ç¢¼å¯æ¼ https://github.com/tifat58/IRR-with-CBM-RAG.git åå¾ã

##### **Critique of Impure Reason: Unveiling the reasoning behaviour of medical Large Language Models**
2412.15748v1 by Shamus Sim, Tyrone Chen

Background: Despite the current ubiquity of Large Language Models (LLMs)
across the medical domain, there is a surprising lack of studies which address
their reasoning behaviour. We emphasise the importance of understanding
reasoning behaviour as opposed to high-level prediction accuracies, since it is
equivalent to explainable AI (XAI) in this context. In particular, achieving
XAI in medical LLMs used in the clinical domain will have a significant impact
across the healthcare sector. Results: Therefore, we define the concept of
reasoning behaviour in the specific context of medical LLMs. We then categorise
and discuss the current state of the art of methods which evaluate reasoning
behaviour in medical LLMs. Finally, we propose theoretical frameworks which can
empower medical professionals or machine learning engineers to gain insight
into the low-level reasoning operations of these previously obscure models.
Conclusion: The subsequent increased transparency and trust in medical machine
learning models by clinicians as well as patients will accelerate the
integration, application as well as further development of medical AI for the
healthcare system as a whole

æè¦ï¼èæ¯ï¼åç®¡å¤§åèªè¨æ¨¡å (LLM) ç®åå¨é«çé åç¡æä¸å¨ï¼ä½ä»¤äººé©è¨çæ¯ï¼æ¢è¨å¶æ¨çè¡çºçç ç©¶å»ç¸ç¶ç¼ºä¹ãæåå¼·èª¿äºè§£æ¨çè¡çºèéé«å±¤ç´çé æ¸¬æºç¢ºåº¦éå¸¸éè¦ï¼å çºå¨éç¨®ææ³ä¸ï¼éç­åæ¼å¯è§£é AI (XAI)ãå°¤å¶æ¯å¨è¨åºé åä¸­ä½¿ç¨çé«ç LLM ä¸­å¯¦ç¾ XAIï¼å°å°æ´åé«çä¿å¥ç¢æ¥­ç¢çéå¤§å½±é¿ãçµæï¼å æ­¤ï¼æåå¨é«ç LLM çç¹å®èæ¯ä¸å®ç¾©äºæ¨çè¡çºçæ¦å¿µãæ¥èæååé¡ä¸¦æ¢è¨ç¶åè©ä¼°é«ç LLM ä¸­æ¨çè¡çºçæ¹æ³çææ°æè¡ãæå¾ï¼æåæåºçè«æ¶æ§ï¼è®é«çå°æ¥­äººå¡ææ©å¨å­¸ç¿å·¥ç¨å¸«å¾ä»¥æ·±å¥äºè§£éäºååæ¨¡ç³æ¨¡åçä½å±¤ç´æ¨çéç®ãçµè«ï¼è¨åºé«çåæ£èå°é«çæ©å¨å­¸ç¿æ¨¡åçéæåº¦åä¿¡ä»»åº¦é¨ä¹æåï¼å°å éé«ç AI å¨æ´åé«çä¿å¥ç³»çµ±ä¸­çæ´åãæç¨åé²ä¸æ­¥ç¼å±ã

##### **Cognition Chain for Explainable Psychological Stress Detection on Social Media**
2412.14009v1 by Xin Wang, Boyan Gao, Yi Dai, Lei Cao, Liang Zhao, Yibo Yang, David Clifton

Stress is a pervasive global health issue that can lead to severe mental
health problems. Early detection offers timely intervention and prevention of
stress-related disorders. The current early detection models perform "black
box" inference suffering from limited explainability and trust which blocks the
real-world clinical application. Thanks to the generative properties introduced
by the Large Language Models (LLMs), the decision and the prediction from such
models are semi-interpretable through the corresponding description. However,
the existing LLMs are mostly trained for general purposes without the guidance
of psychological cognitive theory. To this end, we first highlight the
importance of prior theory with the observation of performance boosted by the
chain-of-thoughts tailored for stress detection. This method termed Cognition
Chain explicates the generation of stress through a step-by-step cognitive
perspective based on cognitive appraisal theory with a progress pipeline:
Stimulus $\rightarrow$ Evaluation $\rightarrow$ Reaction $\rightarrow$ Stress
State, guiding LLMs to provide comprehensive reasoning explanations. We further
study the benefits brought by the proposed Cognition Chain format by utilising
it as a synthetic dataset generation template for LLMs instruction-tuning and
introduce CogInstruct, an instruction-tuning dataset for stress detection. This
dataset is developed using a three-stage self-reflective annotation pipeline
that enables LLMs to autonomously generate and refine instructional data. By
instruction-tuning Llama3 with CogInstruct, we develop CogLLM, an explainable
stress detection model. Evaluations demonstrate that CogLLM achieves
outstanding performance while enhancing explainability. Our work contributes a
novel approach by integrating cognitive theories into LLM reasoning processes,
offering a promising direction for future explainable AI research.

æè¦ï¼å£åæ¯ä¸åæ®éçå¨çæ§å¥åº·åé¡ï¼å¯è½æå°è´å´éçç²¾ç¥
å¥åº·åé¡ãæ©æç¼ç¾æä¾åæçå¹²é åé é²
å£åç¸éç¾çãç®åçæ©æç¼ç¾æ¨¡åå·è¡ãé»
çå­ãæ¨è«ï¼å­å¨å¯è§£éæ§åä¿¡ä»»åº¦æéçåé¡ï¼é»ç¤äº
ç¾å¯¦ä¸ççè¨åºæç¨ãå¤è§äºå¤§åèªè¨æ¨¡å (LLM) å¼å¥ççæå±¬æ§ï¼æ­¤é¡
æ¨¡åçæ±ºç­åé æ¸¬ééå°ææè¿°å·æåå¯è§£éæ§ãç¶èï¼
ç¾æç LLM ä¸»è¦éå°ä¸è¬ç¨éé²è¡è¨ç·´ï¼æ²æå¿çèªç¥çè«çæå°ãçºæ­¤ï¼æåé¦åå¼·èª¿
åé©çè«çéè¦æ§ï¼ä¸¦è§å¯å°éå°å£åæª¢æ¸¬éèº«å®å¶çææ³éæåäºæ§è½ãéç¨®æ¹æ³ç¨±çºèªç¥
éééåºæ¼èªç¥è©ä¼°çè«çå¾ªåºæ¼¸é²çèªç¥è¦è§é¡æäºå£åçç¢çï¼ä¸¦å·æé²åº¦ç®¡éï¼
åºæ¿ $\rightarrow$ è©ä¼° $\rightarrow$ åæ $\rightarrow$ å£å
çæï¼æå° LLM æä¾å¨é¢çæ¨çè§£éãæåé²ä¸æ­¥
ééå°å¶ç¨ä½ LLM æä»¤èª¿æ´çåææ¸æéçææ¨¡æ¿ä¾ç ç©¶ææåºçèªç¥éæ ¼å¼å¸¶ä¾çåªé»ï¼ä¸¦ä»ç´¹ CogInstructï¼éæ¯ä¸åéå°å£åæª¢æ¸¬çæä»¤èª¿æ´æ¸æéãéå
æ¸æéæ¯ä½¿ç¨ä¸åä¸éæ®µçèªçæ¨è¨»ç®¡ééç¼çï¼ä½¿ LLM è½å¤ èªä¸»çæååªåæä»¤æ¸æãéé
ä½¿ç¨ CogInstruct å° Llama3 é²è¡æä»¤èª¿æ´ï¼æåéç¼äº CogLLMï¼éæ¯ä¸åå¯è§£éç
å£åæª¢æ¸¬æ¨¡åãè©ä¼°è¡¨æï¼CogLLM å¨æé«å¯è§£éæ§çåæå¯¦ç¾äºåºè²çæ§è½ãæåçç ç©¶ééå°èªç¥çè«æ´åå° LLM æ¨çéç¨ä¸­ï¼æåºäºä¸ç¨®æ°ç©çæ¹æ³ï¼
çºæªä¾çå¯è§£éäººå·¥æºè½ç ç©¶æä¾äºä¸åæå¸æçæ¹åã

##### **2-Factor Retrieval for Improved Human-AI Decision Making in Radiology**
2412.00372v1 by Jim Solomon, Laleh Jalilian, Alexander Vilesov, Meryl Mathew, Tristan Grogan, Arash Bedayat, Achuta Kadambi

Human-machine teaming in medical AI requires us to understand to what degree
a trained clinician should weigh AI predictions. While previous work has shown
the potential of AI assistance at improving clinical predictions, existing
clinical decision support systems either provide no explainability of their
predictions or use techniques like saliency and Shapley values, which do not
allow for physician-based verification. To address this gap, this study
compares previously used explainable AI techniques with a newly proposed
technique termed '2-factor retrieval (2FR)', which is a combination of
interface design and search retrieval that returns similarly labeled data
without processing this data. This results in a 2-factor security blanket
where: (a) correct images need to be retrieved by the AI; and (b) humans should
associate the retrieved images with the current pathology under test. We find
that when tested on chest X-ray diagnoses, 2FR leads to increases in clinician
accuracy, with particular improvements when clinicians are radiologists and
have low confidence in their decision. Our results highlight the importance of
understanding how different modes of human-AI decision making may impact
clinician accuracy in clinical decision support systems.

æè¦ï¼äººæ©åä½å¨é«ç AI ä¸­ï¼éè¦æåçè§£åéè¨ç·´çè¨åºé«çå¨å¤å¤§ç¨åº¦ä¸æéè¦ AI é æ¸¬ãéç¶ååçç ç©¶é¡¯ç¤º AI è¼å©å¨æ¹åè¨åºé æ¸¬æ¹é¢çæ½åï¼ä½ç¾æçè¨åºæ±ºç­æ¯æ´ç³»çµ±ï¼è¦ä¸å°±æ²ææä¾é æ¸¬çå¯è§£éæ§ï¼è¦ä¸å°±æ¯ä½¿ç¨åé¡¯èæ§å Shapley å¼ä¹é¡çæè¡ï¼éäºæè¡ä¸åè¨±åºæ¼é«ççé©è­ãçºäºè§£æ±ºéåå·®è·ï¼æ¬ç ç©¶å°ååä½¿ç¨çå¯è§£é AI æè¡èä¸ç¨®æ°æåºçç¨±çºã2 å å­æª¢ç´¢ (2FR)ãçæè¡é²è¡æ¯è¼ï¼å¾èæ¯ä¸ç¨®ä»é¢è¨­è¨åæå°æª¢ç´¢ççµåï¼å®æå³åæ¨ç±¤ç¸ä¼¼çè³æï¼èä¸æèçéäºè³æãéæç¢çä¸å 2 å å­å®å¨æ©å¶ï¼å¶ä¸­ï¼(a) æ­£ç¢ºçå½±åéè¦ç± AI æª¢ç´¢ï¼(b) äººé¡æå°æª¢ç´¢çå½±åèæ­£å¨æ¸¬è©¦ä¸­çççè¯æ³èµ·ä¾ãæåç¼ç¾ï¼ç¶å¨è¸é¨ X åè¨ºæ·ä¸é²è¡æ¸¬è©¦æï¼2FR ææé«è¨åºé«ççæºç¢ºåº¦ï¼ç¹å¥æ¯å¨è¨åºé«çæ¯æ¾å°ç§é«çä¸å°å¶æ±ºç­ä¿¡å¿ä¸è¶³æï¼ææé¡¯èçæ¹åãæåççµæå¼·èª¿äºçè§£äººæ©æ±ºç­çä¸åæ¨¡å¼å¦ä½å½±é¿è¨åºé«çå¨è¨åºæ±ºç­æ¯æ´ç³»çµ±ä¸­çæºç¢ºæ§çéè¦æ§ã

##### **Mapping Public Perception of Artificial Intelligence: Expectations, Risk-Benefit Tradeoffs, and Value As Determinants for Societal Acceptance**
2411.19356v1 by Philipp Brauner, Felix Glawe, Gian Luca Liehner, Luisa Vervier, Martina Ziefle

Understanding public perception of artificial intelligence (AI) and the
tradeoffs between potential risks and benefits is crucial, as these perceptions
might shape policy decisions, influence innovation trajectories for successful
market strategies, and determine individual and societal acceptance of AI
technologies. Using a representative sample of 1100 participants from Germany,
this study examines mental models of AI. Participants quantitatively evaluated
71 statements about AI's future capabilities (e.g., autonomous driving, medical
care, art, politics, warfare, and societal divides), assessing the expected
likelihood of occurrence, perceived risks, benefits, and overall value. We
present rankings of these projections alongside visual mappings illustrating
public risk-benefit tradeoffs. While many scenarios were deemed likely,
participants often associated them with high risks, limited benefits, and low
overall value. Across all scenarios, 96.4% ($r^2=96.4\%$) of the variance in
value assessment can be explained by perceived risks ($\beta=-.504$) and
perceived benefits ($\beta=+.710$), with no significant relation to expected
likelihood. Demographics and personality traits influenced perceptions of
risks, benefits, and overall evaluations, underscoring the importance of
increasing AI literacy and tailoring public information to diverse user needs.
These findings provide actionable insights for researchers, developers, and
policymakers by highlighting critical public concerns and individual factors
essential to align AI development with individual values.

æè¦ï¼<paragraph>äºè§£å¬ç¾å°äººå·¥æºæ§ (AI) çèªç¥ä»¥åæ½å¨é¢¨éªèå¥½èä¹éçæ¬è¡¡è³ééè¦ï¼å çºéäºèªç¥å¯è½æå½±é¿æ¿ç­æ±ºç­ãå½±é¿æåå¸å ´ç­ç¥çåµæ°è»è·¡ï¼ä¸¦æ±ºå®åäººåç¤¾æå° AI æè¡çæ¥ååº¦ãæ¬ç ç©¶ä½¿ç¨ä¾èªå¾·åç 1100 ååèèçä»£è¡¨æ§æ¨£æ¬ï¼æ¢è¨äº AI çå¿æºæ¨¡åãåèèå° 71 é éæ¼ AI æªä¾è½åçé³è¿°ï¼ä¾å¦ï¼èªåé§é§ãé«çä¿å¥ãèè¡ãæ¿æ²»ãæ°ç­åç¤¾æåæ­§ï¼é²è¡äºå®éè©ä¼°ï¼è©ä¼°é æçç¼çå¯è½æ§ãæç¥é¢¨éªãå¥½èåæ´é«å¹å¼ãæåå±ç¤ºäºéäºé æ¸¬çæåï¼ä¸¦éä¸è¦è¦ºåæ å°ï¼èªªæäºå¬ç¾çé¢¨éªæ¶çæ¬è¡¡ãåç®¡è¨±å¤å ´æ¯è¢«èªçºæ¯å¯è½çï¼ä½åèèéå¸¸å°å®åèé«é¢¨éªãæéçå¥½èåä½æ´é«å¹å¼è¯ç¹«èµ·ä¾ãå¨ææå ´æ¯ä¸­ï¼96.4% ($r^2=96.4\%$) çå¹å¼è©ä¼°å·®ç°å¯ä»¥ç¨æç¥é¢¨éª ($\beta=-.504$) åæç¥å¥½è ($\beta=+.710$) ä¾è§£éï¼èé æçå¯è½æ§æ²æé¡¯èéä¿ãäººå£çµ±è¨åäººæ ¼ç¹è³ªå½±é¿äºå°é¢¨éªãå¥½èåæ´é«è©ä¼°ççæ³ï¼éå¸é¡¯äºæé« AI ç´ é¤åæ ¹æä¸åçä½¿ç¨èéæ±èª¿æ´å¬å±è³è¨çéè¦æ§ãéäºç¼ç¾ééå¼·èª¿ééµçå¬å±éæ³¨åèåäººå¹å¼è§ä¸è´ç AI éç¼å¿ä¸å¯å°çåäººå ç´ ï¼çºç ç©¶äººå¡ãéç¼äººå¡åæ¿ç­å¶å®èæä¾äºå¯è¡çè¦è§£ã</paragraph>

##### **Explainable AI for Classifying UTI Risk Groups Using a Real-World Linked EHR and Pathology Lab Dataset**
2411.17645v2 by Yujie Dai, Brian Sullivan, Axel Montout, Amy Dillon, Chris Waller, Peter Acs, Rachel Denholm, Philip Williams, Alastair D Hay, Raul Santos-Rodriguez, Andrew Dowsey

The use of machine learning and AI on electronic health records (EHRs) holds
substantial potential for clinical insight. However, this approach faces
challenges due to data heterogeneity, sparsity, temporal misalignment, and
limited labeled outcomes. In this context, we leverage a linked EHR dataset of
approximately one million de-identified individuals from Bristol, North
Somerset, and South Gloucestershire, UK, to characterize urinary tract
infections (UTIs). We implemented a data pre-processing and curation pipeline
that transforms the raw EHR data into a structured format suitable for
developing predictive models focused on data fairness, accountability and
transparency. Given the limited availability and biases of ground truth UTI
outcomes, we introduce a UTI risk estimation framework informed by clinical
expertise to estimate UTI risk across individual patient timelines. Pairwise
XGBoost models are trained using this framework to differentiate UTI risk
categories with explainable AI techniques applied to identify key predictors
and support interpretability. Our findings reveal differences in clinical and
demographic predictors across risk groups. While this study highlights the
potential of AI-driven insights to support UTI clinical decision-making,
further investigation of patient sub-strata and extensive validation are needed
to ensure robustness and applicability in clinical practice.

æè¦ï¼é»å­å¥åº·ç´é (EHR) ä¸­æ©å¨å­¸ç¿å AI çä½¿ç¨å°æ¼è¨åºè¦è§£å·æç¸ç¶å¤§çæ½åãç¶èï¼ç±æ¼è³æç°è³ªæ§ãç¨çæ§ãæéé¯ä½åæ¨ç±¤çµææéï¼æ­¤æ¹æ³é¢è¨ææ°ãå¨æ­¤èæ¯ä¸ï¼æåå©ç¨ä¾èªè±åå¸éæ¯æãåè©é»å¡ç¹ååæ ¼æ´æ¯ç¹é¡ç´ä¸ç¾è¬åå»è­å¥åäººé£çµç EHR è³æéï¼ä¾æè¿°å°¿è·¯ææ (UTI)ãæåå¯¦æ½äºå°åå§ EHR è³æè½æçºçµæ§åæ ¼å¼çè³æåèçåæ´çç®¡ç·ï¼é©åéç¼å°æ³¨æ¼è³æå¬å¹³æ§ãåè²¬å¶åéæåº¦çé æ¸¬æ¨¡åãéæ¼ UTI çå¯¦çµæçå¯ç¨æ§æéååå·®ï¼æåå¼å¥äºç±è¨åºå°æ¥­ç¥è­åç¥ç UTI é¢¨éªè©ä¼°æ¶æ§ï¼ä»¥ä¼°è¨åå¥æ£èæéè»¸ä¸ç UTI é¢¨éªãæå°ç XGBoost æ¨¡åä½¿ç¨æ­¤æ¶æ§é²è¡è¨ç·´ï¼ä»¥åå UTI é¢¨éªé¡å¥ï¼ä¸¦æç¨å¯è§£éç AI æè¡ä¾è­å¥ééµé æ¸¬å å­ä¸¦æ¯æå¯è§£éæ§ãæåçç ç©¶çµææ­ç¤ºäºä¸åé¢¨éªç¾¤çµå¨è¨åºåäººå£çµ±è¨é æ¸¬å å­ä¸çå·®ç°ãéç¶éé ç ç©¶å¼·èª¿äº AI é©åè¦è§£å¨æ¯æ´ UTI è¨åºæ±ºç­å¶å®æ¹é¢çæ½åï¼ä½ä»éè¦é²ä¸æ­¥èª¿æ¥æ£èå­ç¾¤é«åå»£æ³é©è­ï¼ä»¥ç¢ºä¿å¨è¨åºå¯¦åä¸­çç©©å¥æ§åé©ç¨æ§ã

##### **Exploring the Requirements of Clinicians for Explainable AI Decision Support Systems in Intensive Care**
2411.11774v1 by Jeffrey N. Clark, Matthew Wragg, Emily Nielsen, Miquel Perello-Nieto, Nawid Keshtmand, Michael Ambler, Shiv Sharma, Christopher P. Bourdeaux, Amberly Brigden, Raul Santos-Rodriguez

There is a growing need to understand how digital systems can support
clinical decision-making, particularly as artificial intelligence (AI) models
become increasingly complex and less human-interpretable. This complexity
raises concerns about trustworthiness, impacting safe and effective adoption of
such technologies. Improved understanding of decision-making processes and
requirements for explanations coming from decision support tools is a vital
component in providing effective explainable solutions. This is particularly
relevant in the data-intensive, fast-paced environments of intensive care units
(ICUs). To explore these issues, group interviews were conducted with seven ICU
clinicians, representing various roles and experience levels. Thematic analysis
revealed three core themes: (T1) ICU decision-making relies on a wide range of
factors, (T2) the complexity of patient state is challenging for shared
decision-making, and (T3) requirements and capabilities of AI decision support
systems. We include design recommendations from clinical input, providing
insights to inform future AI systems for intensive care.

æè¦ï¼é¨èäººå·¥æºæ§ (AI) æ¨¡åè®å¾è¶ä¾è¶è¤éï¼ä¸è¶ä¾è¶é£ä»¥è¢«äººçè§£ï¼äºè§£æ¸ä½ç³»çµ±å¦ä½æ¯æ´è¨åºæ±ºç­çéæ±ä¹æ¥çå¢å ãéç¨®è¤éæ§å¼ç¼äºå°å¯ä¿¡åº¦ççæ®ï¼å½±é¿äºæ­¤é¡æè¡çå®å¨ä¸æææ¡ç¨ãæ¹åå°æ±ºç­å¶å®æµç¨ççè§£ï¼ä»¥åå°æ±ºç­æ¯æ´å·¥å·ææä¾èªªæçè¦æ±ï¼æ¯æä¾ææå¯è§£éè§£æ±ºæ¹æ¡çéè¦çµæé¨åãéå¨è³æå¯éãå¿«ç¯å¥çå è­·çæ¿ (ICU) ç°å¢ä¸­ç¹å¥ç¸éãçºäºæ¢è¨éäºåé¡ï¼å°ä¸ä½ ICU è¨åºé«å¸«é²è¡äºå°çµè¨ªè«ï¼éäºé«å¸«ä»£è¡¨äºä¸åçè§è²åç¶é©å±¤ç´ãä¸»é¡åææ­é²äºä¸åæ ¸å¿ä¸»é¡ï¼(T1) ICU æ±ºç­å¶å®ä¾è³´æ¼å»£æ³çå ç´ ï¼(T2) çæ£çæçè¤éæ§å°å±åæ±ºç­å¶å®æ§æææ°ï¼ä»¥å (T3) AI æ±ºç­æ¯æ´ç³»çµ±çè¦æ±åè½åãæåç´å¥äºè¨åºè¼¸å¥çè¨­è¨å»ºè­°ï¼æä¾è¦è§£ä»¥æä¾è³è¨çµ¦æªä¾ç¨æ¼å è­·ç AI ç³»çµ±ã

##### **Artificial Intelligence in Pediatric Echocardiography: Exploring Challenges, Opportunities, and Clinical Applications with Explainable AI and Federated Learning**
2411.10255v1 by Mohammed Yaseen Jabarulla, Theodor Uden, Thomas Jack, Philipp Beerbaum, Steffen Oeltze-Jafra

Pediatric heart diseases present a broad spectrum of congenital and acquired
diseases. More complex congenital malformations require a differentiated and
multimodal decision-making process, usually including echocardiography as a
central imaging method. Artificial intelligence (AI) offers considerable
promise for clinicians by facilitating automated interpretation of pediatric
echocardiography data. However, adapting AI technologies for pediatric
echocardiography analysis has challenges such as limited public data
availability, data privacy, and AI model transparency. Recently, researchers
have focused on disruptive technologies, such as federated learning (FL) and
explainable AI (XAI), to improve automatic diagnostic and decision support
workflows. This study offers a comprehensive overview of the limitations and
opportunities of AI in pediatric echocardiography, emphasizing the synergistic
workflow and role of XAI and FL, identifying research gaps, and exploring
potential future developments. Additionally, three relevant clinical use cases
demonstrate the functionality of XAI and FL with a focus on (i) view
recognition, (ii) disease classification, (iii) segmentation of cardiac
structures, and (iv) quantitative assessment of cardiac function.

æè¦ï¼å°åå¿èç¾çåç¾åå¤©æ§èå¾å¤©æ§ç¾ççå»£æ³åè­ãè¼è¤éçåå¤©æ§ç¸å½¢éè¦ä¸åå·®ç°åä¸å¤æ¨¡å¼çæ±ºç­éç¨ï¼éå¸¸åæ¬è¶é³æ³¢æª¢æ¥ä½çºä¸»è¦çå½±åæ¹æ³ãäººå·¥æºæ§ (AI) çºè¨åºé«çæä¾äºç¸ç¶å¤§çå¸æï¼å çºå®å¯ä»¥ä¿é²å°åè¶é³æ³¢æª¢æ¥è³æçèªååè§£è®ãç¶èï¼å°äººå·¥æºæ§æè¡æç¨æ¼å°åè¶é³æ³¢æª¢æ¥åææè¨±å¤ææ°ï¼ä¾å¦æéçå¬éè³æå¯ç¨æ§ãè³æé±ç§åäººå·¥æºæ§æ¨¡åéæåº¦ãæè¿ï¼ç ç©¶äººå¡å°æ³¨æ¼ç ´å£æ§æè¡ï¼ä¾å¦è¯åå­¸ç¿ (FL) åå¯è§£éäººå·¥æºæ§ (XAI)ï¼ä»¥æ¹åèªåè¨ºæ·åæ±ºç­æ¯æ´å·¥ä½æµç¨ãæ¬ç ç©¶æä¾äºäººå·¥æºæ§å¨å°åè¶é³æ³¢æª¢æ¥ä¸­çéå¶åæ©æçå¨é¢æ¦è¿°ï¼å¼·èª¿äº XAI å FL çååå·¥ä½æµç¨åè§è²ï¼æ¾åºç ç©¶å·®è·ä¸¦æ¢è¨æ½å¨çæªä¾ç¼å±ãæ­¤å¤ï¼ä¸åç¸éçè¨åºä½¿ç¨æ¡ä¾å±ç¤ºäº XAI å FL çåè½ï¼éé»å¨æ¼ (i) æª¢è¦è¾¨è­ã(ii) ç¾çåé¡ã(iii) å¿èçµæ§åå²å (iv) å¿èåè½çéåè©ä¼°ã

##### **Enhancing Osteoporosis Detection: An Explainable Multi-Modal Learning Framework with Feature Fusion and Variable Clustering**
2411.00916v2 by Mehdi Hosseini Chagahi, Saeed Mohammadi Dashtaki, Niloufar Delfan, Nadia Mohammadi, Alireza Samari, Behzad Moshiri, Md. Jalil Piran, Oliver Faust

Osteoporosis is a common condition that increases fracture risk, especially
in older adults. Early diagnosis is vital for preventing fractures, reducing
treatment costs, and preserving mobility. However, healthcare providers face
challenges like limited labeled data and difficulties in processing medical
images. This study presents a novel multi-modal learning framework that
integrates clinical and imaging data to improve diagnostic accuracy and model
interpretability. The model utilizes three pre-trained networks-VGG19,
InceptionV3, and ResNet50-to extract deep features from X-ray images. These
features are transformed using PCA to reduce dimensionality and focus on the
most relevant components. A clustering-based selection process identifies the
most representative components, which are then combined with preprocessed
clinical data and processed through a fully connected network (FCN) for final
classification. A feature importance plot highlights key variables, showing
that Medical History, BMI, and Height were the main contributors, emphasizing
the significance of patient-specific data. While imaging features were
valuable, they had lower importance, indicating that clinical data are crucial
for accurate predictions. This framework promotes precise and interpretable
predictions, enhancing transparency and building trust in AI-driven diagnoses
for clinical integration.

æè¦ï¼éª¨è³ªçé¬çæ¯ä¸ç¨®å¸¸è¦çç¾çï¼æå¢å éª¨æçé¢¨éªï¼ç¹å¥æ¯èå¹´äººãæ©æè¨ºæ·å°æ¼é é²éª¨æãéä½æ²»çææ¬åç¶­æè¡åè½åè³ééè¦ãç¶èï¼é«çä¿å¥æä¾èé¢è¨èæ¨è¨æ¸ææéåèçé«å­¸å½±åå°é£ç­ææ°ãæ¬ç ç©¶æåºäºä¸åæ°ç©çå¤æ¨¡å¼å­¸ç¿æ¡æ¶ï¼è©²æ¡æ¶æ´åäºè¨åºåå½±åæ¸æï¼ä»¥æé«è¨ºæ·æºç¢ºæ§åæ¨¡åå¯è§£éæ§ãè©²æ¨¡åå©ç¨ä¸åé è¨ç·´çç¶²è·¯ï¼VGG19ãInceptionV3 å ResNet50ï¼å¾ X å°ç·å½±åä¸­æåæ·±åº¦ç¹å¾µãéäºç¹å¾µä½¿ç¨ PCA è½æä»¥éä½ç¶­åº¦ä¸¦å°æ³¨æ¼æç¸éççµæé¨åãåºæ¼èé¡çé¸æéç¨è­å¥åºæå·ä»£è¡¨æ§ççµæé¨åï¼ç¶å¾å°éäºçµæé¨åèé èççè¨åºæ¸æçµåï¼ä¸¦ééå¨é£æ¥ç¶²è·¯ (FCN) é²è¡æçµåé¡ãç¹å¾µéè¦æ§åçªåºäºééµè®æ¸ï¼è¡¨æçå²ãBMI åèº«é«æ¯ä¸»è¦è²¢ç»å ç´ ï¼å¼·èª¿äºæ£èç¹å®æ¸æçéè¦æ§ãéç¶å½±åç¹å¾µå¾æå¹å¼ï¼ä½å®åçéè¦æ§è¼ä½ï¼éè¡¨æè¨åºæ¸æå°æ¼æºç¢ºé æ¸¬è³ééè¦ãæ­¤æ¡æ¶ä¿è¿äºæºç¢ºä¸å¯è§£éçé æ¸¬ï¼æé«äºéæåº¦ï¼ä¸¦å»ºç«äºå° AI é©åè¨ºæ·å¨è¨åºæ´åä¸­çä¿¡ä»»ã

##### **A Review of Deep Learning Approaches for Non-Invasive Cognitive Impairment Detection**
2410.19898v1 by Muath Alsuhaibani, Ali Pourramezan Fard, Jian Sun, Farida Far Poor, Peter S. Pressman, Mohammad H. Mahoor

This review paper explores recent advances in deep learning approaches for
non-invasive cognitive impairment detection. We examine various non-invasive
indicators of cognitive decline, including speech and language, facial, and
motoric mobility. The paper provides an overview of relevant datasets,
feature-extracting techniques, and deep-learning architectures applied to this
domain. We have analyzed the performance of different methods across modalities
and observed that speech and language-based methods generally achieved the
highest detection performance. Studies combining acoustic and linguistic
features tended to outperform those using a single modality. Facial analysis
methods showed promise for visual modalities but were less extensively studied.
Most papers focused on binary classification (impaired vs. non-impaired), with
fewer addressing multi-class or regression tasks. Transfer learning and
pre-trained language models emerged as popular and effective techniques,
especially for linguistic analysis. Despite significant progress, several
challenges remain, including data standardization and accessibility, model
explainability, longitudinal analysis limitations, and clinical adaptation.
Lastly, we propose future research directions, such as investigating
language-agnostic speech analysis methods, developing multi-modal diagnostic
systems, and addressing ethical considerations in AI-assisted healthcare. By
synthesizing current trends and identifying key obstacles, this review aims to
guide further development of deep learning-based cognitive impairment detection
systems to improve early diagnosis and ultimately patient outcomes.

æè¦ï¼æ¬ç¯è©è«æ¢è¨äºæ·±åº¦å­¸ç¿æ¹æ³å¨éä¾µå¥å¼èªç¥åè½éç¤æª¢æ¸¬ä¸çææ°é²å±ãæåæª¢è¦äºåç¨®éä¾µå¥å¼çèªç¥è¡°éææ¨ï¼åæ¬èªè¨åèªè¨ãé¢é¨åéåæ©è½ãæ¬ææ¦è¿°äºèæ­¤é åç¸éçè³æéãç¹å¾µæåæè¡åæ·±åº¦å­¸ç¿æ¶æ§ãæååæäºä¸åæ¹æ³å¨ä¸åæ¹å¼ä¸çè¡¨ç¾ï¼ä¸¦è§å¯å°åºæ¼èªè¨åèªè¨çæ¹æ³éå¸¸è½éå°æé«çæª¢æ¸¬è¡¨ç¾ãçµåè²å­¸åèªè¨ç¹å¾µçç ç©¶å¾å¾åªæ¼ä½¿ç¨å®ä¸æ¹å¼çç ç©¶ãé¢é¨åææ¹æ³é¡¯ç¤ºåºè¦è¦ºæ¹å¼çæ½åï¼ä½ç ç©¶è¼å°ãå¤§å¤æ¸è«æå°æ³¨æ¼äºååé¡ï¼åæèæªåæï¼ï¼è¼å°æ¢è¨å¤é¡æåæ­¸ä»»åãé·ç§»å­¸ç¿åé è¨ç·´èªè¨æ¨¡åå·²æçºæµè¡ä¸ææçæè¡ï¼ç¹å¥æ¯å°æ¼èªè¨åæãåç®¡åå¾äºéå¤§é²å±ï¼ä½ä»å­å¨ä¸äºææ°ï¼åæ¬è³ææ¨æºååå¯åæ§ãæ¨¡åå¯è§£éæ§ãç¸±ååæéå¶åè¨åºé©ææ§ãæå¾ï¼æåæåºäºæªä¾çç ç©¶æ¹åï¼ä¾å¦èª¿æ¥èèªè¨ç¡éçèªé³åææ¹æ³ãéç¼å¤æ¨¡å¼è¨ºæ·ç³»çµ±ï¼ä»¥åè§£æ±ºäººå·¥æºæ§è¼å©é«çä¿å¥ä¸­çå«çèéãééç¶åç®åçè¶¨å¢åæ¾åºééµéç¤ï¼æ¬ç¯è©è«æ¨å¨å¼å°æ·±åº¦å­¸ç¿çºåºç¤çèªç¥åè½éç¤æª¢æ¸¬ç³»çµ±çé²ä¸æ­¥ç¼å±ï¼ä»¥æ¹åæ©æè¨ºæ·ï¼ä¸¦æçµæ¹åæ£èçæ²»ççµæã

##### **An Ontology-Enabled Approach For User-Centered and Knowledge-Enabled Explanations of AI Systems**
2410.17504v1 by Shruthi Chari

Explainable Artificial Intelligence (AI) focuses on helping humans understand
the working of AI systems or their decisions and has been a cornerstone of AI
for decades. Recent research in explainability has focused on explaining the
workings of AI models or model explainability. There have also been several
position statements and review papers detailing the needs of end-users for
user-centered explainability but fewer implementations. Hence, this thesis
seeks to bridge some gaps between model and user-centered explainability. We
create an explanation ontology (EO) to represent literature-derived explanation
types via their supporting components. We implement a knowledge-augmented
question-answering (QA) pipeline to support contextual explanations in a
clinical setting. Finally, we are implementing a system to combine explanations
from different AI methods and data modalities. Within the EO, we can represent
fifteen different explanation types, and we have tested these representations
in six exemplar use cases. We find that knowledge augmentations improve the
performance of base large language models in the contextualized QA, and the
performance is variable across disease groups. In the same setting, clinicians
also indicated that they prefer to see actionability as one of the main foci in
explanations. In our explanations combination method, we plan to use similarity
metrics to determine the similarity of explanations in a chronic disease
detection setting. Overall, through this thesis, we design methods that can
support knowledge-enabled explanations across different use cases, accounting
for the methods in today's AI era that can generate the supporting components
of these explanations and domain knowledge sources that can enhance them.

æè¦ï¼å¯è§£éäººå·¥æºæ§ï¼AIï¼å°æ³¨æ¼åå©äººé¡äºè§£ AI ç³»çµ±éä½æå¶æ±ºç­ï¼æ¸åå¹´ä¾ä¸ç´æ¯ AI çåºç³ãæè¿çå¯è§£éæ§ç ç©¶å°æ³¨æ¼è§£é AI æ¨¡åææ¨¡åå¯è§£éæ§çéä½ãä¹æå¹¾ä»½ç«å ´è²æåè©è«è«æè©³ç´°èªªæäºæçµä½¿ç¨èå°ä»¥ä½¿ç¨èçºä¸­å¿çå¯è§£éæ§çéæ±ï¼ä½å¯¦ä½è¼å°ãå æ­¤ï¼æ¬è«ææ¨å¨å½è£æ¨¡ååä»¥ä½¿ç¨èçºä¸­å¿çå¯è§£éæ§ä¹éçä¸äºå·®è·ãæåå»ºç«ä¸åè§£éæ¬é«ï¼EOï¼ä»¥ééå¶æ¯æ´åä»¶ä¾è¡¨ç¤ºå¾æç»ä¸­è¡ççè§£éé¡åãæåå¯¦ä½ä¸åç¥è­å¢å¼·çåç­ï¼QAï¼ç®¡ç·ï¼ä»¥å¨è¨åºç°å¢ä¸­æ¯æ´æå¢è§£éãæå¾ï¼æåæ­£å¨å¯¦ä½ä¸åç³»çµ±ï¼ä»¥çµåä¾èªä¸å AI æ¹æ³åè³ææ¨¡å¼çè§£éãå¨ EO ä¸­ï¼æåå¯ä»¥è¡¨ç¤º 15 ç¨®ä¸åçè§£éé¡åï¼ä¸¦ä¸æåå·²å¨å­åç¯ä¾ä½¿ç¨æ¡ä¾ä¸­æ¸¬è©¦éäºè¡¨ç¤ºãæåç¼ç¾ï¼ç¥è­å¢å¼·æ¹åäºåºç¤å¤§åèªè¨æ¨¡åå¨æå¢å QA ä¸­çæè½ï¼ä¸¦ä¸æè½å ç¾çç¾¤çµèç°ãå¨ç¸åçç°å¢ä¸­ï¼è¨åºé«çä¹è¡¨ç¤ºä»åå¸æå°å¯æä½æ§è¦çºè§£éä¸­çä¸»è¦ç¦é»ä¹ä¸ãå¨æåçè§£éçµåæ¹æ³ä¸­ï¼æåè¨ç«ä½¿ç¨ç¸ä¼¼æ§ææ¨ä¾ç¢ºå®æ¢æ§çåµæ¸¬ç°å¢ä¸­è§£éçç¸ä¼¼æ§ãç¸½é«èè¨ï¼ééæ¬è«æï¼æåè¨­è¨äºå¯ä»¥å¨ä¸åä½¿ç¨æ¡ä¾ä¸­æ¯æ´ç¥è­åç¨è§£éçæ¹æ³ï¼èéå°ç¶ä» AI æä»£ä¸­å¯ä»¥ç¢çéäºè§£éçæ¯æ´åä»¶åå¯ä»¥å¢å¼·éäºè§£éçé åç¥è­ä¾æºçæ¹æ³ã

##### **Contrasting Attitudes Towards Current and Future AI Applications for Computerised Interpretation of ECG: A Clinical Stakeholder Interview Study**
2410.16879v1 by Lukas Hughes-Noehrer, Leda Channer, Gabriel Strain, Gregory Yates, Richard Body, Caroline Jay

Objectives: To investigate clinicians' attitudes towards current automated
interpretation of ECG and novel AI technologies and their perception of
computer-assisted interpretation. Materials and Methods: We conducted a series
of interviews with clinicians in the UK. Our study: (i) explores the potential
for AI, specifically future 'human-like' computing approaches, to facilitate
ECG interpretation and support clinical decision making, and (ii) elicits their
opinions about the importance of explainability and trustworthiness of AI
algorithms. Results: We performed inductive thematic analysis on interview
transcriptions from 23 clinicians and identified the following themes: (i) a
lack of trust in current systems, (ii) positive attitudes towards future AI
applications and requirements for these, (iii) the relationship between the
accuracy and explainability of algorithms, and (iv) opinions on education,
possible deskilling, and the impact of AI on clinical competencies. Discussion:
Clinicians do not trust current computerised methods, but welcome future 'AI'
technologies. Where clinicians trust future AI interpretation to be accurate,
they are less concerned that it is explainable. They also preferred ECG
interpretation that demonstrated the results of the algorithm visually. Whilst
clinicians do not fear job losses, they are concerned about deskilling and the
need to educate the workforce to use AI responsibly. Conclusion: Clinicians are
positive about the future application of AI in clinical decision-making.
Accuracy is a key factor of uptake and visualisations are preferred over
current computerised methods. This is viewed as a potential means of training
and upskilling, in contrast to the deskilling that automation might be
perceived to bring.

æè¦ï¼<paragraph>ç®çï¼èª¿æ¥è¨åºé«çå°ç®åèªååå¿é»åè§£è®åæ°çäººå·¥æºæ§æè¡çæåº¦ï¼ä»¥åä»åå°é»è¦è¼å©è§£è®ççæ³ãææåæ¹æ³ï¼æåå°è±åçè¨åºé«çé²è¡äºä¸ç³»åè¨ªè«ãæåçç ç©¶ï¼(i) æ¢è¨äººå·¥æºæ§çæ½åï¼ç¹å¥æ¯æªä¾çãé¡äººé¡ãéç®æ¹æ³ï¼ä»¥ä¿é²å¿é»åè§£è®ä¸¦æ¯æè¨åºæ±ºç­å¶å®ï¼ä»¥å (ii) å¾µæ±ä»åå°äººå·¥æºæ§æ¼ç®æ³çå¯è§£éæ§åå¯ä¿¡åº¦ççæ³ãçµæï¼æåå° 23 ä½è¨åºé«ççè¨ªè«è¨éé²è¡äºæ­¸ç´ä¸»é¡åæï¼ä¸¦æ¾åºä»¥ä¸ä¸»é¡ï¼(i) å°ç®åç³»çµ±ç¼ºä¹ä¿¡ä»»ï¼(ii) å°æªä¾äººå·¥æºæ§æç¨åå°éäºæç¨çè¦æ±ææ­£é¢æåº¦ï¼(iii) æ¼ç®æ³çæºç¢ºæ§åå¯è§£éæ§ä¹éçéä¿ï¼ä»¥å (iv) å°æè²ãå¯è½çæè½éåï¼ä»¥åäººå·¥æºæ§å°è¨åºè½åçå½±é¿ççæ³ãè¨è«ï¼è¨åºé«çä¸ä¿¡ä»»ç®åçé»è¦åæ¹æ³ï¼ä½æ­¡è¿æªä¾çãäººå·¥æºæ§ãæè¡ãå¨è¨åºé«çç¸ä¿¡æªä¾ç AI è§£è®æºç¢ºçææ³ä¸ï¼ä»åä¸å¤ªæå¿å®æ¯å¦å¯è§£éãä»åä¹æ¯è¼åæ­¡è½ä»¥è¦è¦ºæ¹å¼åç¾æ¼ç®æ³çµæçå¿é»åè§£è®ãéç¶è¨åºé«çä¸å®³æå¤±æ¥­ï¼ä½ä»åæå¿æè½éåï¼ä»¥åéè¦æè²å¡å·¥è² è²¬ä»»å°ä½¿ç¨äººå·¥æºæ§ãçµè«ï¼è¨åºé«çå°äººå·¥æºæ§å¨è¨åºæ±ºç­å¶å®ä¸­çæªä¾æç¨ææ­£é¢æåº¦ãæºç¢ºæ§æ¯æ¡ç¨äººå·¥æºæ§çä¸åééµå ç´ ï¼èè¦è¦ºåæ¯ç®åçé»è¦åæ¹æ³æ´åéçãéè¢«è¦çºä¸ç¨®æ½å¨çå¹è¨åæåæè½çæ¹æ³ï¼èèªååå¯è½å¸¶ä¾çæè½éåå½¢æå°æ¯ã</paragraph>

##### **Pathologist-like explainable AI for interpretable Gleason grading in prostate cancer**
2410.15012v1 by Gesa Mittmann, Sara Laiouar-Pedari, Hendrik A. Mehrtens, Sarah HaggenmÃ¼ller, Tabea-Clara Bucher, Tirtha Chanda, Nadine T. Gaisa, Mathias Wagner, Gilbert Georg Klamminger, Tilman T. Rau, Christina Neppl, Eva Maria CompÃ©rat, Andreas Gocht, Monika HÃ¤mmerle, Niels J. Rupp, Jula Westhoff, Irene KrÃ¼cken, Maximillian Seidl, Christian M. SchÃ¼rch, Marcus Bauer, Wiebke Solass, Yu Chun Tam, Florian Weber, Rainer Grobholz, Jaroslaw Augustyniak, Thomas Kalinski, Christian HÃ¶rner, Kirsten D. Mertz, Constanze DÃ¶ring, Andreas Erbersdobler, Gabriele Deubler, Felix Bremmer, Ulrich Sommer, Michael Brodhun, Jon Griffin, Maria Sarah L. Lenon, Kiril Trpkov, Liang Cheng, Fei Chen, Angelique Levi, Guoping Cai, Tri Q. Nguyen, Ali Amin, Alessia Cimadamore, Ahmed Shabaik, Varsha Manucha, Nazeel Ahmad, Nidia Messias, Francesca Sanguedolce, Diana Taheri, Ezra Baraban, Liwei Jia, Rajal B. Shah, Farshid Siadat, Nicole Swarbrick, Kyung Park, Oudai Hassan, Siamak Sakhaie, Michelle R. Downes, Hiroshi Miyamoto, Sean R. Williamson, Tim Holland-Letz, Carolin V. Schneider, Jakob Nikolas Kather, Yuri Tolkach, Titus J. Brinker

The aggressiveness of prostate cancer, the most common cancer in men
worldwide, is primarily assessed based on histopathological data using the
Gleason scoring system. While artificial intelligence (AI) has shown promise in
accurately predicting Gleason scores, these predictions often lack inherent
explainability, potentially leading to distrust in human-machine interactions.
To address this issue, we introduce a novel dataset of 1,015 tissue microarray
core images, annotated by an international group of 54 pathologists. The
annotations provide detailed localized pattern descriptions for Gleason grading
in line with international guidelines. Utilizing this dataset, we develop an
inherently explainable AI system based on a U-Net architecture that provides
predictions leveraging pathologists' terminology. This approach circumvents
post-hoc explainability methods while maintaining or exceeding the performance
of methods trained directly for Gleason pattern segmentation (Dice score: 0.713
$\pm$ 0.003 trained on explanations vs. 0.691 $\pm$ 0.010 trained on Gleason
patterns). By employing soft labels during training, we capture the intrinsic
uncertainty in the data, yielding strong results in Gleason pattern
segmentation even in the context of high interobserver variability. With the
release of this dataset, we aim to encourage further research into segmentation
in medical tasks with high levels of subjectivity and to advance the
understanding of pathologists' reasoning processes.

æè¦ï¼ååèºçæ¯å¨çç·æ§æå¸¸è¦çççï¼å¶æ¡æ§ç¨åº¦ä¸»è¦æ ¹æ Gleason è©åç³»çµ±ä½¿ç¨çµç¹ççå­¸æ¸æé²è¡è©ä¼°ãéç¶äººå·¥æºæ§ (AI) å¨æºç¢ºé æ¸¬ Gleason è©åæ¹é¢å·²å±ç¾æ½åï¼ä½éäºé æ¸¬éå¸¸ç¼ºä¹å§å¨çå¯è§£éæ§ï¼å¯è½æå°è´å°äººæ©äºåçä¸ä¿¡ä»»ãçºäºè§£æ±ºéååé¡ï¼æåå¼é²äºä¸åç± 54 ä½ççå­¸å®¶çµæçåéåéè¨»è§£ç 1,015 åçµç¹å¾®é£åæ ¸å¿å½±åçæ°ç©è³æéãéäºè¨»è§£æä¾äºè©³ç´°çå±é¨æ¨¡å¼æè¿°ï¼ç¨æ¼ç¬¦ååéæºåç Gleason åç´ãå©ç¨éåè³æéï¼æåéç¼äºä¸ååºæ¼ U-Net æ¶æ§çå§å¨å¯è§£é AI ç³»çµ±ï¼è©²ç³»çµ±æä¾äºå©ç¨ççå­¸å®¶è¡èªé²è¡é æ¸¬ãéç¨®æ¹æ³è¦é¿äºäºå¾å¯è§£éæ§æ¹æ³ï¼åæç¶­ææè¶è¶äºç´æ¥è¨ç·´ç¨æ¼ Gleason æ¨¡å¼åå²çæ¹æ³çæè½ï¼Dice åæ¸ï¼0.713 Â± 0.003ï¼è¨ç·´æ¼è§£éï¼ç¸å°æ¼ 0.691 Â± 0.010ï¼è¨ç·´æ¼ Gleason æ¨¡å¼ï¼ãééå¨è¨ç·´æéæ¡ç¨è»æ¨ç±¤ï¼æåææäºè³æä¸­çå§å¨ä¸ç¢ºå®æ§ï¼å³ä½¿å¨è§å¯èéè®ç°æ§é«çææ³ä¸ï¼ä¹è½å¨ Gleason æ¨¡å¼åå²ä¸­ç¢çå¼·å¤§ççµæãéééåºéåè³æéï¼æåæ¨å¨é¼åµé²ä¸æ­¥ç ç©¶ä¸»è§æ§é«çé«çä»»åä¸­çåå²ï¼ä¸¦å¢é²å°ççå­¸å®¶æ¨çéç¨ççè§£ã

##### **Explainable AI Methods for Multi-Omics Analysis: A Survey**
2410.11910v1 by Ahmad Hussein, Mukesh Prasad, Ali Braytee

Advancements in high-throughput technologies have led to a shift from
traditional hypothesis-driven methodologies to data-driven approaches.
Multi-omics refers to the integrative analysis of data derived from multiple
'omes', such as genomics, proteomics, transcriptomics, metabolomics, and
microbiomics. This approach enables a comprehensive understanding of biological
systems by capturing different layers of biological information. Deep learning
methods are increasingly utilized to integrate multi-omics data, offering
insights into molecular interactions and enhancing research into complex
diseases. However, these models, with their numerous interconnected layers and
nonlinear relationships, often function as black boxes, lacking transparency in
decision-making processes. To overcome this challenge, explainable artificial
intelligence (xAI) methods are crucial for creating transparent models that
allow clinicians to interpret and work with complex data more effectively. This
review explores how xAI can improve the interpretability of deep learning
models in multi-omics research, highlighting its potential to provide
clinicians with clear insights, thereby facilitating the effective application
of such models in clinical settings.

æè¦ï¼é«ééæè¡çé²æ­¥å°è´å¾å³çµ±çåè¨­é©åæ¹æ³è½è®çºè³æé©åçæ¹æ³ãå¤çµå­¸æ¯ææ´ååæä¾èªå¤åãçµå­¸ãçè³æï¼ä¾å¦åºå çµå­¸ãèç½è³ªçµå­¸ãè½éçµå­¸ãä»£è¬çµå­¸åå¾®çç©çµå­¸ãæ­¤æ¹æ³ééæ·åçç©è³è¨çä¸åå±¤é¢ï¼è½å¨é¢äºè§£çç©ç³»çµ±ãæ·±åº¦å­¸ç¿æ¹æ³æä¾æå¸¸è¢«ç¨æ¼æ´åå¤çµå­¸è³æï¼æä¾åå­äº¤äºä½ç¨çæ´å¯åï¼ä¸¦å å¼·å°è¤éç¾ççç ç©¶ãç¶èï¼éäºæ¨¡åå·æè¨±å¤ç¸äºé£æ¥çå±¤ç´åéç·æ§éä¿ï¼éå¸¸æåé»çå­ä¸æ¨£éä½ï¼ç¼ºä¹æ±ºç­éç¨çéæåº¦ãçºäºåææ­¤ææ°ï¼å¯è§£éäººå·¥æºæ§ (xAI) æ¹æ³å°æ¼å»ºç«éææ¨¡åè³ééè¦ï¼è®è¨åºé«çå¯ä»¥æ´ææå°è§£éåèçè¤éè³æãæ­¤è©è«æ¢è¨ xAI å¦ä½è½æ¹åå¤çµå­¸ç ç©¶ä¸­æ·±åº¦å­¸ç¿æ¨¡åçå¯è§£éæ§ï¼å¼·èª¿å¶æä¾è¨åºé«çæç¢ºè¦è§£çæ½åï¼é²èä¿é²æ­¤é¡æ¨¡åå¨è¨åºç°å¢ä¸­çæææç¨ã

##### **Study on the Helpfulness of Explainable Artificial Intelligence**
2410.11896v1 by Tobias Labarta, Elizaveta Kulicheva, Ronja Froelian, Christian GeiÃler, Xenia Melman, Julian von Klitzing

Explainable Artificial Intelligence (XAI) is essential for building advanced
machine learning-powered applications, especially in critical domains such as
medical diagnostics or autonomous driving. Legal, business, and ethical
requirements motivate using effective XAI, but the increasing number of
different methods makes it challenging to pick the right ones. Further, as
explanations are highly context-dependent, measuring the effectiveness of XAI
methods without users can only reveal a limited amount of information,
excluding human factors such as the ability to understand it. We propose to
evaluate XAI methods via the user's ability to successfully perform a proxy
task, designed such that a good performance is an indicator for the explanation
to provide helpful information. In other words, we address the helpfulness of
XAI for human decision-making. Further, a user study on state-of-the-art
methods was conducted, showing differences in their ability to generate trust
and skepticism and the ability to judge the rightfulness of an AI decision
correctly. Based on the results, we highly recommend using and extending this
approach for more objective-based human-centered user studies to measure XAI
performance in an end-to-end fashion.

æè¦ï¼å¯è§£éäººå·¥æºæ§ (XAI) å°æ¼å»ºæ§åé²çæ©å¨å­¸ç¿é©åæç¨ç¨å¼è³ééè¦ï¼ç¹å¥æ¯å¨é«çè¨ºæ·æèªåé§é§ç­ééµé åãæ³å¾ãåæ¥­åå«çè¦æ±ä¿ä½¿ä½¿ç¨ææç XAIï¼ä½æ¸éæ¥çå¢å çä¸åæ¹æ³ä½¿å¾æé¸æ­£ç¢ºçæ¹æ³å·æææ°æ§ãæ­¤å¤ï¼ç±æ¼è§£éé«åº¦ä¾è³´æ¼èæ¯ï¼å¨æ²æä½¿ç¨èçææ³ä¸è¡¡é XAI æ¹æ³çæææ§åªè½æ­ç¤ºæéçè³è¨ï¼æé¤äººé¡å ç´ ï¼ä¾å¦çè§£å®çè½åãæåå»ºè­°ééä½¿ç¨èæåå·è¡ä»£çä»»åçè½åä¾è©ä¼° XAI æ¹æ³ï¼è¨­è¨ä½¿å¾è¯å¥½çå·è¡è¡¨ç¾æ¯è§£éæä¾æç¨è³è¨çææ¨ãæå¥è©±èªªï¼æåæ¢è¨ XAI å°äººé¡æ±ºç­å¶å®çå¹«å©ãæ­¤å¤ï¼å°æåé²çæ¹æ³é²è¡ä½¿ç¨èç ç©¶ï¼é¡¯ç¤ºåºå®åå¨ç¢çä¿¡ä»»åæ·ççè½åä»¥åæ­£ç¢ºå¤æ· AI æ±ºç­æ¯å¦æ­£ç¢ºçè½åæ¹é¢å­å¨å·®ç°ãæ ¹æçµæï¼æåå¼·çå»ºè­°ä½¿ç¨åæ´åéç¨®æ¹æ³ï¼ä»¥é²è¡æ´å¤ä»¥ç®æ¨çºåºç¤çäººçºä¸­å¿ä½¿ç¨èç ç©¶ï¼ä»¥çµç«¯å°çµç«¯çæ¹å¼è¡¡é XAI æè½ã

##### **Use of What-if Scenarios to Help Explain Artificial Intelligence Models for Neonatal Health**
2410.09635v1 by Abdullah Mamun, Lawrence D. Devoe, Mark I. Evans, David W. Britt, Judith Klein-Seetharaman, Hassan Ghasemzadeh

Early detection of intrapartum risk enables interventions to potentially
prevent or mitigate adverse labor outcomes such as cerebral palsy. Currently,
there is no accurate automated system to predict such events to assist with
clinical decision-making. To fill this gap, we propose "Artificial Intelligence
(AI) for Modeling and Explaining Neonatal Health" (AIMEN), a deep learning
framework that not only predicts adverse labor outcomes from maternal, fetal,
obstetrical, and intrapartum risk factors but also provides the model's
reasoning behind the predictions made. The latter can provide insights into
what modifications in the input variables of the model could have changed the
predicted outcome. We address the challenges of imbalance and small datasets by
synthesizing additional training data using Adaptive Synthetic Sampling
(ADASYN) and Conditional Tabular Generative Adversarial Networks (CTGAN). AIMEN
uses an ensemble of fully-connected neural networks as the backbone for its
classification with the data augmentation supported by either ADASYN or CTGAN.
AIMEN, supported by CTGAN, outperforms AIMEN supported by ADASYN in
classification. AIMEN can predict a high risk for adverse labor outcomes with
an average F1 score of 0.784. It also provides counterfactual explanations that
can be achieved by changing 2 to 3 attributes on average. Resources available:
https://github.com/ab9mamun/AIMEN.

æè¦ï¼ç¢ç¨ä¸­é¢¨éªçæ©æåµæ¸¬æå©æ¼é²è¡å¹²é æªæ½ï¼ä»¥é é²ææ¸è¼ä¸å©ççç¢çµæï¼ä¾å¦è¦æ§éº»çºãç®åï¼æ²ææºç¢ºçèªååç³»çµ±å¯ä»¥é æ¸¬æ­¤é¡äºä»¶ï¼ä»¥åå©è¨åºæ±ºç­ãçºäºå¡«è£éä¸ç©ºç½ï¼æåæåºãç¨æ¼å»ºæ¨¡åè§£éæ°çåå¥åº·çäººå·¥æºæ§ã(AIMEN)ï¼éæ¯ä¸åæ·±åº¦å­¸ç¿æ¶æ§ï¼å®ä¸åå¯ä»¥æ ¹æå­ç¢å©¦ãèåãç¢ç§åç¢ç¨é¢¨éªå ç´ é æ¸¬ä¸å©ççç¢çµæï¼éè½æä¾æ¨¡åååºé æ¸¬èå¾çåå ãå¾èå¯ä»¥æä¾è¦è§£ï¼èªªææ¨¡åè¼¸å¥è®æ¸ä¸­çåªäºä¿®æ¹å¯è½ææ¹è®é æ¸¬çµæãæåééä½¿ç¨é©ææ§åææ½æ¨£ (ADASYN) åæ¢ä»¶è¡¨æ ¼çæå°æç¶²è·¯ (CTGAN) ä¾åæé¡å¤çè¨ç·´è³æï¼ä»¥è§£æ±ºä¸å¹³è¡¡åå°åè³æéçææ°ãAIMEN ä½¿ç¨å¨é£æ¥ç¥ç¶ç¶²è·¯çéåä½çºå¶åé¡çéª¨å¹¹ï¼ä¸¦éé ADASYN æ CTGAN æ¯æ´è³ææ´åãç± CTGAN æ¯æ´ç AIMEN å¨åé¡æ¹é¢åªæ¼ç± ADASYN æ¯æ´ç AIMENãAIMEN å¯ä»¥é æ¸¬ä¸å©ççç¢çµæçé«é¢¨éªï¼å¹³å F1 åæ¸çº 0.784ãå®éæä¾åäºå¯¦è§£éï¼å¯ééå¹³åè®æ´ 2 è³ 3 åå±¬æ§ä¾éæãå¯ç¨è³æºï¼https://github.com/ab9mamun/AIMENã

##### **Artificial intelligence techniques in inherited retinal diseases: A review**
2410.09105v1 by Han Trinh, Jordan Vice, Jason Charng, Zahra Tajbakhsh, Khyber Alam, Fred K. Chen, Ajmal Mian

Inherited retinal diseases (IRDs) are a diverse group of genetic disorders
that lead to progressive vision loss and are a major cause of blindness in
working-age adults. The complexity and heterogeneity of IRDs pose significant
challenges in diagnosis, prognosis, and management. Recent advancements in
artificial intelligence (AI) offer promising solutions to these challenges.
However, the rapid development of AI techniques and their varied applications
have led to fragmented knowledge in this field. This review consolidates
existing studies, identifies gaps, and provides an overview of AI's potential
in diagnosing and managing IRDs. It aims to structure pathways for advancing
clinical applications by exploring AI techniques like machine learning and deep
learning, particularly in disease detection, progression prediction, and
personalized treatment planning. Special focus is placed on the effectiveness
of convolutional neural networks in these areas. Additionally, the integration
of explainable AI is discussed, emphasizing its importance in clinical settings
to improve transparency and trust in AI-based systems. The review addresses the
need to bridge existing gaps in focused studies on AI's role in IRDs, offering
a structured analysis of current AI techniques and outlining future research
directions. It concludes with an overview of the challenges and opportunities
in deploying AI for IRDs, highlighting the need for interdisciplinary
collaboration and the continuous development of robust, interpretable AI models
to advance clinical applications.

æè¦ï¼éºå³æ§è¦ç¶²èç¾ç (IRD) æ¯ä¸çµå¤æ¨£åçéºå³ç¾çï¼
æå°è´è¦åéæ¼¸åªå¤±ï¼æ¯å·¥ä½å¹´é½¡æäººå¤±æçä¸»è¦åå ãIRD çè¤éæ§åç°è³ªæ§å°è¨ºæ·ãé å¾åç®¡çæåºäºéå¤§ææ°ãæè¿äººå·¥æºè½ (AI) çé²æ­¥çºéäºææ°æä¾äºæå¸æçè§£æ±ºæ¹æ¡ã
ç¶èï¼AI æè¡çå¿«éç¼å±åå¶å¤ç¨®æç¨å°è´äºè©²é åçç¥è­åæ£ãæ¬ç¶è¿°æ´åäºç¾æç ç©¶ï¼æ¾åºå·®è·ï¼ä¸¦æ¦è¿°äº AI å¨è¨ºæ·åç®¡ç IRD ä¸­çæ½åãå®æ¨å¨ééæ¢ç´¢æ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿ç­ AI æè¡ï¼ç¹å¥æ¯å¨ç¾çæª¢æ¸¬ãé²ç¨é æ¸¬ååæ§åæ²»çè¨åä¸­ï¼çºæ¨é²è¨åºæç¨æ§å»ºéå¾ãç¹å¥éæ³¨éäºé åä¸­å·ç©ç¥ç¶ç¶²è·¯çæææ§ãæ­¤å¤ï¼è¨è«äºå¯è§£é AI çæ´åï¼å¼·èª¿äºå¶å¨è¨åºç°å¢ä¸­æé«éæåº¦åå°åºæ¼ AI çç³»çµ±çä¿¡ä»»çéè¦æ§ãè©²ç¶è¿°è§£æ±ºäºå½å AI å¨ IRD ä¸­ä½ç¨çéé»ç ç©¶ä¸­ç¾æå·®è·çå¿è¦æ§ï¼æä¾äºå°ç¶å AI æè¡ççµæ§ååæï¼ä¸¦æ¦è¿°äºæªä¾çç ç©¶æ¹åãæå¾æ¦è¿°äºå¨ IRD ä¸­é¨ç½² AI çææ°åæ©éï¼å¼·èª¿äºè·¨å­¸ç§åä½åæçºéç¼å¼·å¤§ãå¯è§£éç AI æ¨¡åä»¥æ¨é²è¨åºæç¨çå¿è¦æ§ã

##### **CasiMedicos-Arg: A Medical Question Answering Dataset Annotated with Explanatory Argumentative Structures**
2410.05235v2 by Ekaterina Sviridova, Anar Yeginbergen, Ainara Estarrona, Elena Cabrio, Serena Villata, Rodrigo Agerri

Explaining Artificial Intelligence (AI) decisions is a major challenge
nowadays in AI, in particular when applied to sensitive scenarios like medicine
and law. However, the need to explain the rationale behind decisions is a main
issue also for human-based deliberation as it is important to justify
\textit{why} a certain decision has been taken. Resident medical doctors for
instance are required not only to provide a (possibly correct) diagnosis, but
also to explain how they reached a certain conclusion. Developing new tools to
aid residents to train their explanation skills is therefore a central
objective of AI in education. In this paper, we follow this direction, and we
present, to the best of our knowledge, the first multilingual dataset for
Medical Question Answering where correct and incorrect diagnoses for a clinical
case are enriched with a natural language explanation written by doctors. These
explanations have been manually annotated with argument components (i.e.,
premise, claim) and argument relations (i.e., attack, support), resulting in
the Multilingual CasiMedicos-Arg dataset which consists of 558 clinical cases
in four languages (English, Spanish, French, Italian) with explanations, where
we annotated 5021 claims, 2313 premises, 2431 support relations, and 1106
attack relations. We conclude by showing how competitive baselines perform over
this challenging dataset for the argument mining task.

æè¦ï¼è§£éäººå·¥æºæ§ (AI) çæ±ºç­æ¯ç¾å¨ AI çä¸é éå¤§ææ°ï¼ç¹å¥æ¯æç¨æ¼åé«å­¸åæ³å¾ç­æææå¢æãç¶èï¼è§£éæ±ºç­èå¾çç±çéæ±ä¹æ¯åºæ¼äººé¡çèéçä¸åä¸»è¦åé¡ï¼å çºæå¿è¦è­æçºä»éº¼ååºæåæ±ºç­ãä¾å¦ï¼ä½é¢é«å¸«ä¸åéè¦æä¾ï¼å¯è½æ¯æ­£ç¢ºçï¼è¨ºæ·ï¼ééè¦è§£éä»åå¦ä½éææåçµè«ãå æ­¤ï¼éç¼æ°çå·¥å·ä¾å¹«å©ä½é¢é«å¸«è¨ç·´ä»åçè§£éæå·§æ¯æè²ä¸­ AI çä¸é æ ¸å¿ç®æ¨ãå¨æ¬æä¸­ï¼æåéµå¾ªéåæ¹åï¼ä¸¦ä¸æ ¹ææåçäºè§£ï¼æåºç¬¬ä¸åå¤èªè¨é«å­¸åç­è³æéï¼å¶ä¸­è¨åºçä¾çæ­£ç¢ºåä¸æ­£ç¢ºè¨ºæ·é½éæç±é«çæ°å¯«çèªç¶èªè¨è§£éãéäºè§£éå·²ä½¿ç¨è«è­çµæï¼å³åæãä¸»å¼µï¼åè«è­éä¿ï¼å³æ»æãæ¯æï¼é²è¡æåè¨»è§£ï¼ç¢çå¤èªè¨ CasiMedicos-Arg è³æéï¼å¶ä¸­åå« 558 åå·æè§£éçåç¨®èªè¨ï¼è±èªãè¥¿ç­çèªãæ³èªãç¾©å¤§å©èªï¼çè¨åºçä¾ï¼æåè¨»è§£äº 5021 åä¸»å¼µã2313 ååæã2431 åæ¯æéä¿å 1106 åæ»æéä¿ãæåæå¾å±ç¤ºäºç«¶ç­åºæºå¦ä½éå°è«è­æ¢åä»»åå·è¡æ­¤å·ææ°æ§çè³æéã

##### **Explainable Diagnosis Prediction through Neuro-Symbolic Integration**
2410.01855v2 by Qiuhao Lu, Rui Li, Elham Sagheb, Andrew Wen, Jinlian Wang, Liwei Wang, Jungwei W. Fan, Hongfang Liu

Diagnosis prediction is a critical task in healthcare, where timely and
accurate identification of medical conditions can significantly impact patient
outcomes. Traditional machine learning and deep learning models have achieved
notable success in this domain but often lack interpretability which is a
crucial requirement in clinical settings. In this study, we explore the use of
neuro-symbolic methods, specifically Logical Neural Networks (LNNs), to develop
explainable models for diagnosis prediction. Essentially, we design and
implement LNN-based models that integrate domain-specific knowledge through
logical rules with learnable thresholds. Our models, particularly
$M_{\text{multi-pathway}}$ and $M_{\text{comprehensive}}$, demonstrate superior
performance over traditional models such as Logistic Regression, SVM, and
Random Forest, achieving higher accuracy (up to 80.52\%) and AUROC scores (up
to 0.8457) in the case study of diabetes prediction. The learned weights and
thresholds within the LNN models provide direct insights into feature
contributions, enhancing interpretability without compromising predictive
power. These findings highlight the potential of neuro-symbolic approaches in
bridging the gap between accuracy and explainability in healthcare AI
applications. By offering transparent and adaptable diagnostic models, our work
contributes to the advancement of precision medicine and supports the
development of equitable healthcare solutions. Future research will focus on
extending these methods to larger and more diverse datasets to further validate
their applicability across different medical conditions and populations.

æè¦ï¼è¨ºæ·é æ¸¬æ¯é«çä¿å¥ä¸­çééµä»»åï¼åæä¸æºç¢ºå°è­å¥é«ççæ³æé¡¯èå½±é¿æ£èççµæãå³çµ±çæ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿æ¨¡åå·²å¨éåé ååå¾é¡¯èæåï¼ä½éå¸¸ç¼ºä¹å¯è§£éæ§ï¼éå¨è¨åºç°å¢ä¸­æ¯ä¸é ééµè¦æ±ãå¨æ¬ç ç©¶ä¸­ï¼æåæ¢è¨äºç¥ç¶ç¬¦èæ¹æ³çæç¨ï¼ç¹å¥æ¯éè¼¯ç¥ç¶ç¶²è·¯ (LNN)ï¼ä»¥éç¼ç¨æ¼è¨ºæ·é æ¸¬çå¯è§£éæ¨¡åãåºæ¬ä¸ï¼æåè¨­è¨ä¸¦å¯¦ä½äºåºæ¼ LNN çæ¨¡åï¼éäºæ¨¡åééå·æå¯å­¸ç¿é¾å¼çéè¼¯è¦åæ´åé åç¹å®ç¥è­ãæåçæ¨¡åï¼ç¹å¥æ¯ $M_{\text{multi-pathway}}$ å $M_{\text{comprehensive}}$ï¼è¡¨ç¾åºåªæ¼å³çµ±æ¨¡åï¼ä¾å¦éè¼¯è¿´æ­¸ãSVM åé¨æ©æ£®æï¼çåªç°æè½ï¼å¨ç³å°¿çé æ¸¬çæ¡ä¾ç ç©¶ä¸­éå°äºæ´é«çæºç¢ºåº¦ï¼é«é 80.52%ï¼å AUROC åæ¸ï¼é«é 0.8457ï¼ãLNN æ¨¡åä¸­å­¸ç¿å°çæ¬éåé¾å¼æä¾äºå°ç¹å¾µè²¢ç»çç´æ¥è¦è§£ï¼å¢å¼·äºå¯è§£éæ§ï¼åæä¸å½±é¿é æ¸¬è½åãéäºç¼ç¾çªé¡¯äºç¥ç¶ç¬¦èæ¹æ³å¨å½åé«çä¿å¥ AI æç¨ä¸­æºç¢ºæ§åå¯è§£éæ§å·®è·æ¹é¢çæ½åãééæä¾éæä¸é©ææ§å¼·çè¨ºæ·æ¨¡åï¼æåçç ç©¶æå©æ¼æ¨é²ç²¾æºé«çï¼ä¸¦æ¯æ´å¬å¹³é«çä¿å¥è§£æ±ºæ¹æ¡çéç¼ãæªä¾çç ç©¶å°å°æ³¨æ¼å°éäºæ¹æ³æ´å±å°æ´å¤§ä¸æ´å¤æ¨£åçè³æéï¼ä»¥é²ä¸æ­¥é©è­å¶å¨ä¸åé«ççæ³åäººç¾¤ä¸­çé©ç¨æ§ã

##### **Easydiagnos: a framework for accurate feature selection for automatic diagnosis in smart healthcare**
2410.00366v1 by Prasenjit Maji, Amit Kumar Mondal, Hemanta Kumar Mondal, Saraju P. Mohanty

The rapid advancements in artificial intelligence (AI) have revolutionized
smart healthcare, driving innovations in wearable technologies, continuous
monitoring devices, and intelligent diagnostic systems. However, security,
explainability, robustness, and performance optimization challenges remain
critical barriers to widespread adoption in clinical environments. This
research presents an innovative algorithmic method using the Adaptive Feature
Evaluator (AFE) algorithm to improve feature selection in healthcare datasets
and overcome problems. AFE integrating Genetic Algorithms (GA), Explainable
Artificial Intelligence (XAI), and Permutation Combination Techniques (PCT),
the algorithm optimizes Clinical Decision Support Systems (CDSS), thereby
enhancing predictive accuracy and interpretability. The proposed method is
validated across three diverse healthcare datasets using six distinct machine
learning algorithms, demonstrating its robustness and superiority over
conventional feature selection techniques. The results underscore the
transformative potential of AFE in smart healthcare, enabling personalized and
transparent patient care. Notably, the AFE algorithm, when combined with a
Multi-layer Perceptron (MLP), achieved an accuracy of up to 98.5%, highlighting
its capability to improve clinical decision-making processes in real-world
healthcare applications.

æè¦ï¼äººå·¥æºæ§ (AI) çå¿«éé²å±å¾¹åºæ¹è®äºæºæ§é«çä¿å¥ï¼æ¨åäºå¯ç©¿æ´æè¡ãæçºç£æ§è£ç½®åæºæ§è¨ºæ·ç³»çµ±çåµæ°ãç¶èï¼å®å¨æ§ãå¯è§£éæ§ãç©©å¥æ§åæè½æä½³åææ°ä»ç¶æ¯è¨åºç°å¢ä¸­å»£æ³æ¡ç¨çééµéç¤ãæ¬ç ç©¶æåºä¸ååµæ°çæ¼ç®æ³æ¹æ³ï¼ä½¿ç¨èªé©æç¹å¾µè©ä¼°å¨ (AFE) æ¼ç®æ³ä¾æ¹åé«çä¿å¥è³æéä¸­çç¹å¾µé¸åä¸¦åæåé¡ãAFE æ´åäºéºå³æ¼ç®æ³ (GA)ãå¯è§£éäººå·¥æºæ§ (XAI) åæåçµåæè¡ (PCT)ï¼è©²æ¼ç®æ³æä½³åäºè¨åºæ±ºç­æ¯æ´ç³»çµ± (CDSS)ï¼å¾èæé«äºé æ¸¬æºç¢ºæ§åå¯è§£éæ§ãææåºçæ¹æ³ä½¿ç¨å­ç¨®ä¸åçæ©å¨å­¸ç¿æ¼ç®æ³é©è­äºä¸åä¸åçé«çä¿å¥è³æéï¼è­æäºå¶ç©©å¥æ§ååªæ¼å³çµ±ç¹å¾µé¸åæè¡ãçµæå¼·èª¿äº AFE å¨æºæ§é«çä¿å¥ä¸­çè½è®æ½åï¼å¯¦ç¾äºåäººååéæçæ£èç§è­·ãå¼å¾æ³¨æçæ¯ï¼AFE æ¼ç®æ³èå¤å±¤æç¥å¨ (MLP) çµåä½¿ç¨æï¼æºç¢ºåº¦é«é 98.5%ï¼çªé¡¯äºå¶æ¹åå¯¦éé«çä¿å¥æç¨ä¸­è¨åºæ±ºç­å¶å®æµç¨çè½åã

##### **Dermatologist-like explainable AI enhances melanoma diagnosis accuracy: eye-tracking study**
2409.13476v1 by Tirtha Chanda, Sarah Haggenmueller, Tabea-Clara Bucher, Tim Holland-Letz, Harald Kittler, Philipp Tschandl, Markus V. Heppt, Carola Berking, Jochen S. Utikal, Bastian Schilling, Claudia Buerger, Cristian Navarrete-Dechent, Matthias Goebeler, Jakob Nikolas Kather, Carolin V. Schneider, Benjamin Durani, Hendrike Durani, Martin Jansen, Juliane Wacker, Joerg Wacker, Reader Study Consortium, Titus J. Brinker

Artificial intelligence (AI) systems have substantially improved
dermatologists' diagnostic accuracy for melanoma, with explainable AI (XAI)
systems further enhancing clinicians' confidence and trust in AI-driven
decisions. Despite these advancements, there remains a critical need for
objective evaluation of how dermatologists engage with both AI and XAI tools.
In this study, 76 dermatologists participated in a reader study, diagnosing 16
dermoscopic images of melanomas and nevi using an XAI system that provides
detailed, domain-specific explanations. Eye-tracking technology was employed to
assess their interactions. Diagnostic performance was compared with that of a
standard AI system lacking explanatory features. Our findings reveal that XAI
systems improved balanced diagnostic accuracy by 2.8 percentage points relative
to standard AI. Moreover, diagnostic disagreements with AI/XAI systems and
complex lesions were associated with elevated cognitive load, as evidenced by
increased ocular fixations. These insights have significant implications for
clinical practice, the design of AI tools for visual tasks, and the broader
development of XAI in medical diagnostics.

æè¦ï¼äººå·¥æºæ§ (AI) ç³»çµ±å·²å¤§å¹æ¹åç®èç§é«å¸«å°é»è²ç´ ç¤çè¨ºæ·æºç¢ºåº¦ï¼èå¯è§£é AI (XAI) ç³»çµ±é²ä¸æ­¥æåè¨åºé«å¸«å° AI é©åæ±ºç­çä¿¡å¿èä¿¡è³´ãåç®¡æéäºé²å±ï¼å°æ¼ç®èç§é«å¸«å¦ä½ä½¿ç¨ AI å XAI å·¥å·ï¼ä»æå®¢è§è©ä¼°çè¿«åéæ±ãå¨éé ç ç©¶ä¸­ï¼76 ä½ç®èç§é«å¸«åèäºä¸é è®èç ç©¶ï¼ä½¿ç¨ XAI ç³»çµ±è¨ºæ· 16 å¼µé»è²ç´ ç¤åç£çç®èé¡å½±åï¼è©²ç³»çµ±æä¾è©³ç´°çé åç¹å®èªªæãæ¡ç¨ç¼çè¿½è¹¤æè¡ä¾è©ä¼°ä»åçäºåãå°è¨ºæ·è¡¨ç¾èç¼ºä¹èªªæåè½çæ¨æº AI ç³»çµ±é²è¡æ¯è¼ãæåçç ç©¶çµæé¡¯ç¤ºï¼XAI ç³»çµ±ç¸è¼æ¼æ¨æº AIï¼å°å¹³è¡¡è¨ºæ·æºç¢ºåº¦æåäº 2.8 åç¾åé»ãæ­¤å¤ï¼è AI/XAI ç³»çµ±çè¨ºæ·åæ­§åè¤éççç¶èèªç¥è² æåé«æéï¼éç±å¢å çç¼çæ³¨è¦æ¬¡æ¸æè­å¯¦ãéäºè¦è§£å°è¨åºå¯¦åãè¦è¦ºä»»å AI å·¥å·çè¨­è¨åé«å­¸è¨ºæ·ä¸­ XAI çå»£æ³ç¼å±å·æéå¤§æç¾©ã

##### **Explainable AI for Autism Diagnosis: Identifying Critical Brain Regions Using fMRI Data**
2409.15374v1 by Suryansh Vidya, Kush Gupta, Amir Aly, Andy Wills, Emmanuel Ifeachor, Rohit Shankar

Early diagnosis and intervention for Autism Spectrum Disorder (ASD) has been
shown to significantly improve the quality of life of autistic individuals.
However, diagnostics methods for ASD rely on assessments based on clinical
presentation that are prone to bias and can be challenging to arrive at an
early diagnosis. There is a need for objective biomarkers of ASD which can help
improve diagnostic accuracy. Deep learning (DL) has achieved outstanding
performance in diagnosing diseases and conditions from medical imaging data.
Extensive research has been conducted on creating models that classify ASD
using resting-state functional Magnetic Resonance Imaging (fMRI) data. However,
existing models lack interpretability. This research aims to improve the
accuracy and interpretability of ASD diagnosis by creating a DL model that can
not only accurately classify ASD but also provide explainable insights into its
working. The dataset used is a preprocessed version of the Autism Brain Imaging
Data Exchange (ABIDE) with 884 samples. Our findings show a model that can
accurately classify ASD and highlight critical brain regions differing between
ASD and typical controls, with potential implications for early diagnosis and
understanding of the neural basis of ASD. These findings are validated by
studies in the literature that use different datasets and modalities,
confirming that the model actually learned characteristics of ASD and not just
the dataset. This study advances the field of explainable AI in medical imaging
by providing a robust and interpretable model, thereby contributing to a future
with objective and reliable ASD diagnostics.

æè¦ï¼èªéçè­ç³»éç¤ (ASD) çæ©æè¨ºæ·åä»å¥å·²è¢«è­å¯¦è½é¡¯èæ¹åèªéçæ£èççæ´»åè³ªãç¶èï¼ASD çè¨ºæ·æ¹æ³ä¾è³´æ¼åºæ¼è¨åºè¡¨ç¾çè©ä¼°ï¼å®¹æç¢çåè¦ï¼ä¸å¯è½é£ä»¥ååºæ©æè¨ºæ·ãæå¿è¦æ¾åº ASD çå®¢è§çç©æ¨è¨ï¼ä»¥å¹«å©æé«è¨ºæ·æºç¢ºæ§ãæ·±åº¦å­¸ç¿ (DL) å¨å¾é«å­¸å½±åè³æè¨ºæ·ç¾çåççæ¹é¢åå¾ååºçè¡¨ç¾ãå·²ç¶éå°å»ºç«ä½¿ç¨éæåè½æ§ç£æ¯é å½± (fMRI) è³æå° ASD é²è¡åé¡çæ¨¡åé²è¡å»£æ³çç ç©¶ãç¶èï¼ç¾æçæ¨¡åç¼ºä¹å¯è§£éæ§ãæ¬ç ç©¶æ¨å¨ééå»ºç«ä¸åä¸åè½æºç¢ºåé¡ ASDï¼éè½æä¾å¯è§£éè¦è§£èªªæå¶éä½åçç DL æ¨¡åï¼ä¾æ¹å ASD è¨ºæ·çæºç¢ºæ§åå¯è§£éæ§ãæä½¿ç¨çè³æéæ¯èªéçå¤§è¦å½±åè³æäº¤æ (ABIDE) çé èççæ¬ï¼åå« 884 åæ¨£æ¬ãæåçç ç©¶çµæé¡¯ç¤ºï¼è©²æ¨¡åè½æºç¢ºåé¡ ASDï¼ä¸¦å¼·èª¿ ASD èå¸åå°ç§çµä¹éå­å¨å·®ç°çééµè¦åï¼å°æ¼ ASD çæ©æè¨ºæ·åç¥ç¶åºç¤ççè§£å·ææ½å¨çæç¾©ãéäºç ç©¶çµæå·²ç±ä½¿ç¨ä¸åè³æéåæ¹å¼çæç»ç ç©¶é©è­ï¼è­å¯¦è©²æ¨¡åå¯¦éä¸å­¸ç¿äº ASD çç¹å¾µï¼èä¸ååæ¯è³æéãæ¬ç ç©¶ééæä¾ä¸åå¼·å¥ä¸å¯è§£éçæ¨¡åï¼æ¨åäºé«å­¸å½±åä¸­å¯è§£é AI çé åï¼å¾èçºæªä¾æä¾å®¢è§ä¸å¯é ç ASD è¨ºæ·ååºè²¢ç»ã

##### **Improving Prototypical Parts Abstraction for Case-Based Reasoning Explanations Designed for the Kidney Stone Type Recognition**
2409.12883v1 by Daniel Flores-Araiza, Francisco Lopez-Tiro, ClÃ©ment Larose, Salvador Hinojosa, Andres Mendez-Vazquez, Miguel Gonzalez-Mendoza, Gilberto Ochoa-Ruiz, Christian Daul

The in-vivo identification of the kidney stone types during an ureteroscopy
would be a major medical advance in urology, as it could reduce the time of the
tedious renal calculi extraction process, while diminishing infection risks.
Furthermore, such an automated procedure would make possible to prescribe
anti-recurrence treatments immediately. Nowadays, only few experienced
urologists are able to recognize the kidney stone types in the images of the
videos displayed on a screen during the endoscopy. Thus, several deep learning
(DL) models have recently been proposed to automatically recognize the kidney
stone types using ureteroscopic images. However, these DL models are of black
box nature whicl limits their applicability in clinical settings. This
contribution proposes a case-based reasoning DL model which uses prototypical
parts (PPs) and generates local and global descriptors. The PPs encode for each
class (i.e., kidney stone type) visual feature information (hue, saturation,
intensity and textures) similar to that used by biologists. The PPs are
optimally generated due a new loss function used during the model training.
Moreover, the local and global descriptors of PPs allow to explain the
decisions ("what" information, "where in the images") in an understandable way
for biologists and urologists. The proposed DL model has been tested on a
database including images of the six most widespread kidney stone types. The
overall average classification accuracy was 90.37. When comparing this results
with that of the eight other DL models of the kidney stone state-of-the-art, it
can be seen that the valuable gain in explanability was not reached at the
expense of accuracy which was even slightly increased with respect to that
(88.2) of the best method of the literature. These promising and interpretable
results also encourage urologists to put their trust in AI-based solutions.

æè¦ï¼å°¿è·¯é¡æª¢æ¥ä¸­èçµç³é¡åçé«å§è­å¥å°æ¯æ³å°¿ç§çä¸é éå¤§é²å±ï¼å çºå®å¯ä»¥æ¸å°ç¹ç£çèçµç³ååºéç¨çæéï¼åæéä½ææé¢¨éªãæ­¤å¤ï¼éç¨®èªååç¨åºå°ä½¿ç«å³éç«æå¾©ç¼æ²»çæçºå¯è½ãå¦ä»ï¼åªæå°æ¸ç¶é©è±å¯çæ³å°¿ç§é«çè½å¤ å¨å§è¦é¡æª¢æ¥æéå±å¹ä¸é¡¯ç¤ºçè¦é »ååä¸­è­å¥èçµç³é¡åãå æ­¤ï¼æè¿å·²æåºå¤ç¨®æ·±åº¦å­¸ç¿ (DL) æ¨¡åï¼ä»¥ä½¿ç¨è¼¸å°¿ç®¡é¡ååèªåè­å¥èçµç³é¡åãç¶èï¼éäº DL æ¨¡åæ¬è³ªä¸æ¯é»çå­ï¼ééå¶äºå®åå¨è¨åºç°å¢ä¸­çæç¨æ§ãæ¬ææåºäºä¸ååºæ¼æ¡ä¾æ¨çç DL æ¨¡åï¼å®ä½¿ç¨ååé¨å (PP) ä¸¦çæå±é¨åå¨å±æè¿°ç¬¦ãPP çºæ¯ç¨®é¡åï¼å³èçµç³é¡åï¼ç·¨ç¢¼è¦è¦ºç¹å¾µä¿¡æ¯ï¼è²èª¿ãé£½ååº¦ãå¼·åº¦åç´çï¼ï¼é¡ä¼¼æ¼çç©å­¸å®¶ä½¿ç¨çä¿¡æ¯ãç±æ¼å¨æ¨¡åè¨ç·´æéä½¿ç¨çæ°æå¤±å½æ¸ï¼PP å¾å°äºæä½³çæãæ­¤å¤ï¼PP çå±é¨åå¨å±æè¿°ç¬¦åè¨±ä»¥çç©å­¸å®¶åæ³å°¿ç§é«çå¯ä»¥çè§£çæ¹å¼è§£éæ±ºç­ï¼âä»éº¼âä¿¡æ¯ï¼âååä¸­çä»éº¼ä½ç½®âï¼ãææåºç DL æ¨¡åå·²å¨ä¸ååå«å­ç¨®æå»£æ³çèçµç³é¡åååçæ¸æåº«ä¸é²è¡äºæ¸¬è©¦ãç¸½é«å¹³ååé¡æºç¢ºççº 90.37ãå°æ­¤çµæèèçµç³æåé²çå«åå¶ä» DL æ¨¡åççµæé²è¡æ¯è¼æï¼å¯ä»¥çåºï¼å¯è§£éæ§çå¯¶è²´å¢çä¸¦æªä»¥æºç¢ºæ§çºä»£å¹ï¼çè³ç¥æå¢å èæç»ä¸­æå¥½çæ¹æ³ (88.2) ç¸æ¯ãéäºæå¸æä¸å¯è§£éççµæä¹é¼åµæ³å°¿ç§é«çç¸ä¿¡åºæ¼äººå·¥æºè½çè§£æ±ºæ¹æ¡ã

##### **Towards Interpretable End-Stage Renal Disease (ESRD) Prediction: Utilizing Administrative Claims Data with Explainable AI Techniques**
2409.12087v3 by Yubo Li, Saba Al-Sayouri, Rema Padman

This study explores the potential of utilizing administrative claims data,
combined with advanced machine learning and deep learning techniques, to
predict the progression of Chronic Kidney Disease (CKD) to End-Stage Renal
Disease (ESRD). We analyze a comprehensive, 10-year dataset provided by a major
health insurance organization to develop prediction models for multiple
observation windows using traditional machine learning methods such as Random
Forest and XGBoost as well as deep learning approaches such as Long Short-Term
Memory (LSTM) networks. Our findings demonstrate that the LSTM model,
particularly with a 24-month observation window, exhibits superior performance
in predicting ESRD progression, outperforming existing models in the
literature. We further apply SHapley Additive exPlanations (SHAP) analysis to
enhance interpretability, providing insights into the impact of individual
features on predictions at the individual patient level. This study underscores
the value of leveraging administrative claims data for CKD management and
predicting ESRD progression.

æè¦ï¼æ¬ç ç©¶æ¢è¨å©ç¨è¡æ¿ç³å ±è³æï¼çµååé²æ©å¨å­¸ç¿èæ·±åº¦å­¸ç¿æè¡ï¼é æ¸¬æ¢æ§èèç (CKD) é²å±è³æ«æèèç¾ç (ESRD) çå¯è½æ§ãæååæä¸å®¶å¤§åå¥åº·ä¿éªçµç¹æä¾ç 10 å¹´ç¶åè³æéï¼ä½¿ç¨å³çµ±æ©å¨å­¸ç¿æ¹æ³ï¼ä¾å¦é¨æ©æ£®æå XGBoostï¼ä»¥åæ·±åº¦å­¸ç¿æ¹æ³ï¼ä¾å¦é·æç­æè¨æ¶ (LSTM) ç¶²è·¯ï¼éç¼å¤åè§å¯è¦çªçé æ¸¬æ¨¡åãæåçç ç©¶çµæé¡¯ç¤ºï¼LSTM æ¨¡åï¼å°¤å¶æ¯ 24 åæè§å¯è¦çªï¼å¨é æ¸¬ ESRD é²å±æ¹é¢è¡¨ç¾åªç°ï¼åªæ¼æç»ä¸­çç¾ææ¨¡åãæåé²ä¸æ­¥æç¨ SHapley å¯å æ§è§£é (SHAP) åæä»¥å¢å¼·å¯è§£éæ§ï¼æ·±å¥äºè§£åå¥ç¹å¾µå°åå¥æ£èå±¤ç´é æ¸¬çå½±é¿ãæ¬ç ç©¶å¼·èª¿äºå©ç¨è¡æ¿ç³å ±è³æé²è¡ CKD ç®¡çåé æ¸¬ ESRD é²å±çå¹å¼ã

##### **Contextual Evaluation of Large Language Models for Classifying Tropical and Infectious Diseases**
2409.09201v3 by Mercy Asiedu, Nenad Tomasev, Chintan Ghate, Tiya Tiyasirichokchai, Awa Dieng, Oluwatosin Akande, Geoffrey Siwo, Steve Adudans, Sylvanus Aitkins, Odianosen Ehiakhamen, Eric Ndombi, Katherine Heller

While large language models (LLMs) have shown promise for medical question
answering, there is limited work focused on tropical and infectious
disease-specific exploration. We build on an opensource tropical and infectious
diseases (TRINDs) dataset, expanding it to include demographic and semantic
clinical and consumer augmentations yielding 11000+ prompts. We evaluate LLM
performance on these, comparing generalist and medical LLMs, as well as LLM
outcomes to human experts. We demonstrate through systematic experimentation,
the benefit of contextual information such as demographics, location, gender,
risk factors for optimal LLM response. Finally we develop a prototype of
TRINDs-LM, a research tool that provides a playground to navigate how context
impacts LLM outputs for health.

æè¦ï¼åç®¡å¤§åèªè¨æ¨¡å (LLM) å¨é«çåé¡è§£ç­æ¹é¢å±ç¾åºåæ¯ï¼ä½å°æ³¨æ¼ç±å¸¶åå³æçç¹å®æ¢ç´¢çç ç©¶æéãæåå»ºç«å¨ä¸åéæ¾åå§ç¢¼ç±å¸¶åå³æç (TRINDs) è³æéä¸ï¼ä¸¦å°å¶æ´å±çºç´å¥äººå£çµ±è¨åèªç¾©è¨åºåæ¶è²»èæ´åï¼ç¢çè¶é 11000 åæç¤ºãæåè©ä¼°äº LLM å¨éäºæ¹é¢çæè½ï¼æ¯è¼äºéæåé«ç LLMï¼ä»¥å LLM çµæèäººé¡å°å®¶çæ¯è¼ãæåééç³»çµ±æ§å¯¦é©è­æäºèæ¯è³è¨ï¼ä¾å¦äººå£çµ±è¨ãä½ç½®ãæ§å¥ãæä½³ LLM åæçé¢¨éªå ç´ ï¼çå¥½èãæå¾ï¼æåéç¼äº TRINDs-LM çååï¼éæ¯ä¸åç ç©¶å·¥å·ï¼æä¾ä¸åæ¢ç´¢èæ¯å¦ä½å½±é¿ LLM å¥åº·è¼¸åºçå¹³å°ã

##### **Explainable AI: Definition and attributes of a good explanation for health AI**
2409.15338v1 by Evangelia Kyrimi, Scott McLachlan, Jared M Wohlgemut, Zane B Perkins, David A. Lagnado, William Marsh, the ExAIDSS Expert Group

Proposals of artificial intelligence (AI) solutions based on increasingly
complex and accurate predictive models are becoming ubiquitous across many
disciplines. As the complexity of these models grows, transparency and users'
understanding often diminish. This suggests that accurate prediction alone is
insufficient for making an AI-based solution truly useful. In the development
of healthcare systems, this introduces new issues related to accountability and
safety. Understanding how and why an AI system makes a recommendation may
require complex explanations of its inner workings and reasoning processes.
Although research on explainable AI (XAI) has significantly increased in recent
years and there is high demand for XAI in medicine, defining what constitutes a
good explanation remains ad hoc, and providing adequate explanations continues
to be challenging. To fully realize the potential of AI, it is critical to
address two fundamental questions about explanations for safety-critical AI
applications, such as health-AI: (1) What is an explanation in health-AI? and
(2) What are the attributes of a good explanation in health-AI? In this study,
we examined published literature and gathered expert opinions through a
two-round Delphi study. The research outputs include (1) a definition of what
constitutes an explanation in health-AI and (2) a comprehensive list of
attributes that characterize a good explanation in health-AI.

æè¦ï¼é¨èè¶ä¾è¶è¤éä¸æºç¢ºçé æ¸¬æ¨¡åï¼åºæ¼äººå·¥æºæ§ (AI) è§£æ±ºæ¹æ¡çææ¡å¨è¨±å¤é åä¸­è®å¾ç¡èä¸å¨ãé¨èéäºæ¨¡åè¤éæ§çå¢å ï¼éæåº¦åä½¿ç¨èççè§£åå¾å¾æéä½ãéè¡¨ç¤ºåææºç¢ºçé æ¸¬ä¸¦ä¸è¶³ä»¥è® AI è§£æ±ºæ¹æ¡çæ­£æç¨ãå¨é«çä¿å¥ç³»çµ±çéç¼ä¸­ï¼éå¼å¥äºèåè²¬å¶åå®å¨æ§ç¸éçæ°åé¡ãç­è§£ AI ç³»çµ±å¦ä½ä»¥åçºä½æåºå»ºè­°å¯è½éè¦å°å¶å§é¨éä½åæ¨çéç¨é²è¡è¤éçèªªæãåç®¡è¿å¹´ä¾å°å¯è§£é AI (XAI) çç ç©¶å·²å¤§å¹å¢å ï¼ä¸é«å­¸é åå° XAI æå¾é«çéæ±ï¼ä½å®ç¾©ä»éº¼æ§æä¸åå¥½çè§£éä»æ¯è¨ææ§çï¼èæä¾é©ç¶çè§£éä»ç¶å·æææ°æ§ãçºäºååç¼æ® AI çæ½åï¼å°æ¼å®å¨ééµå AI æç¨ï¼ä¾å¦å¥åº· AIï¼çè§£éï¼æ¢è¨å©ååºæ¬åé¡è³ééè¦ï¼(1) ä»éº¼æ¯å¥åº· AI ä¸­çè§£éï¼ä»¥å (2) å¥åº· AI ä¸­ä¸åå¥½çè§£éæåªäºå±¬æ§ï¼å¨æ¬ç ç©¶ä¸­ï¼æåæª¢è¦äºå·²ç¼è¡¨çæç»ï¼ä¸¦ééå©è¼ªå¾·ç¾è²ç ç©¶æ¶éäºå°å®¶æè¦ãç ç©¶ææåæ¬ï¼(1) å¥åº· AI ä¸­ä»éº¼æ§æè§£éçå®ç¾©ï¼ä»¥å (2) å¥åº· AI ä¸­ä¸åå¥½è§£éçå±¬æ§æ¸å®ã

##### **Exploring the Effect of Explanation Content and Format on User Comprehension and Trust**
2408.17401v1 by Antonio Rago, Bence Palfi, Purin Sukpanichnant, Hannibal Nabli, Kavyesh Vivek, Olga Kostopoulou, James Kinross, Francesca Toni

In recent years, various methods have been introduced for explaining the
outputs of "black-box" AI models. However, it is not well understood whether
users actually comprehend and trust these explanations. In this paper, we focus
on explanations for a regression tool for assessing cancer risk and examine the
effect of the explanations' content and format on the user-centric metrics of
comprehension and trust. Regarding content, we experiment with two explanation
methods: the popular SHAP, based on game-theoretic notions and thus potentially
complex for everyday users to comprehend, and occlusion-1, based on feature
occlusion which may be more comprehensible. Regarding format, we present SHAP
explanations as charts (SC), as is conventional, and occlusion-1 explanations
as charts (OC) as well as text (OT), to which their simpler nature also lends
itself. The experiments amount to user studies questioning participants, with
two different levels of expertise (the general population and those with some
medical training), on their subjective and objective comprehension of and trust
in explanations for the outputs of the regression tool. In both studies we
found a clear preference in terms of subjective comprehension and trust for
occlusion-1 over SHAP explanations in general, when comparing based on content.
However, direct comparisons of explanations when controlling for format only
revealed evidence for OT over SC explanations in most cases, suggesting that
the dominance of occlusion-1 over SHAP explanations may be driven by a
preference for text over charts as explanations. Finally, we found no evidence
of a difference between the explanation types in terms of objective
comprehension. Thus overall, the choice of the content and format of
explanations needs careful attention, since in some contexts format, rather
than content, may play the critical role in improving user experience.

æè¦ï¼<paragraph>è¿å¹´ä¾ï¼å·²ç¶å¼é²åç¨®æ¹æ³ä¾è§£éãé»ç®±ãAI æ¨¡åçè¼¸åºãç¶èï¼ç®åä¸¦ä¸æ¸æ¥ä½¿ç¨èæ¯å¦å¯¦éçè§£åä¿¡ä»»éäºè§£éãå¨æ¬æä¸­ï¼æåå°æ³¨æ¼è©ä¼°ççé¢¨éªçåæ­¸å·¥å·çè§£éï¼ä¸¦æ¢è¨è§£éçå§å®¹åæ ¼å¼å°ä»¥ä½¿ç¨èçºä¸­å¿ççè§£åä¿¡ä»»ææ¨çå½±é¿ãéæ¼å§å®¹ï¼æåå¯¦é©äºå©ç¨®è§£éæ¹æ³ï¼æµè¡ç SHAPï¼åºæ¼åå¼è«æ¦å¿µï¼å æ­¤å°æ¼æ¥å¸¸ä½¿ç¨èä¾èªªå¯è½å¾è¤éï¼ä»¥ååºæ¼ç¹å¾µé®è½ç occlusion-1ï¼å¯è½æ´ææ¼çè§£ãéæ¼æ ¼å¼ï¼æåå° SHAP è§£éåç¾çºåè¡¨ (SC)ï¼éæ¯æ£ä¾ï¼èå° occlusion-1 è§£éåç¾çºåè¡¨ (OC) ä»¥åæå­ (OT)ï¼å¶è¼çºç°¡å®çæ§è³ªä¹é©ç¨æ¼æ­¤ãéäºå¯¦é©ç­åæ¼ä½¿ç¨èç ç©¶ï¼è©¢ååèèï¼å·æå©ç¨®ä¸åç¨åº¦çå°æ¥­ç¥è­ï¼ä¸è¬æ°ç¾åå·åä¸äºé«å­¸è¨ç·´çäººï¼ï¼ä»åå°åæ­¸å·¥å·è¼¸åºè§£éçä¸»è§åå®¢è§çè§£åä¿¡ä»»ãå¨å©é ç ç©¶ä¸­ï¼æåç¼ç¾ï¼å¨åºæ¼å§å®¹é²è¡æ¯è¼æï¼ä¸è¬ä¾èªªï¼occlusion-1 åªæ¼ SHAP è§£éï¼å¨ä¸»è§çè§£åä¿¡ä»»æ¹é¢ææé¡¯çåå¥½ãç¶èï¼å¨åæ§å¶æ ¼å¼çææ³ä¸ç´æ¥æ¯è¼è§£éï¼å¨å¤§å¤æ¸ææ³ä¸åªé¡¯ç¤º OT åªæ¼ SC è§£éçè­æï¼éè¡¨æ occlusion-1 åªæ¼ SHAP è§£éçä¸»å°å°ä½å¯è½æ¯ç±åå¥½æå­èéåè¡¨ä½çºè§£éæé©åçãæå¾ï¼æåæ²æç¼ç¾è§£éé¡åå¨å®¢è§çè§£æ¹é¢çå·®ç°è­æãå æ­¤ï¼ç¸½é«èè¨ï¼å°è§£éçå§å®¹åæ ¼å¼çé¸æéè¦ä»ç´°æ³¨æï¼å çºå¨æäºææ³ä¸ï¼æ ¼å¼èéå§å®¹ï¼å¯è½å¨æ¹åä½¿ç¨èé«é©æ¹é¢ç¼æ®ééµä½ç¨ã</paragraph>

##### **A Survey for Large Language Models in Biomedicine**
2409.00133v1 by Chong Wang, Mengyao Li, Junjun He, Zhongruo Wang, Erfan Darzi, Zan Chen, Jin Ye, Tianbin Li, Yanzhou Su, Jing Ke, Kaili Qu, Shuxin Li, Yi Yu, Pietro LiÃ², Tianyun Wang, Yu Guang Wang, Yiqing Shen

Recent breakthroughs in large language models (LLMs) offer unprecedented
natural language understanding and generation capabilities. However, existing
surveys on LLMs in biomedicine often focus on specific applications or model
architectures, lacking a comprehensive analysis that integrates the latest
advancements across various biomedical domains. This review, based on an
analysis of 484 publications sourced from databases including PubMed, Web of
Science, and arXiv, provides an in-depth examination of the current landscape,
applications, challenges, and prospects of LLMs in biomedicine, distinguishing
itself by focusing on the practical implications of these models in real-world
biomedical contexts. Firstly, we explore the capabilities of LLMs in zero-shot
learning across a broad spectrum of biomedical tasks, including diagnostic
assistance, drug discovery, and personalized medicine, among others, with
insights drawn from 137 key studies. Then, we discuss adaptation strategies of
LLMs, including fine-tuning methods for both uni-modal and multi-modal LLMs to
enhance their performance in specialized biomedical contexts where zero-shot
fails to achieve, such as medical question answering and efficient processing
of biomedical literature. Finally, we discuss the challenges that LLMs face in
the biomedicine domain including data privacy concerns, limited model
interpretability, issues with dataset quality, and ethics due to the sensitive
nature of biomedical data, the need for highly reliable model outputs, and the
ethical implications of deploying AI in healthcare. To address these
challenges, we also identify future research directions of LLM in biomedicine
including federated learning methods to preserve data privacy and integrating
explainable AI methodologies to enhance the transparency of LLMs.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çææ°çªç ´æä¾äºåææªæçèªç¶èªè¨çè§£åçæè½åãç¶èï¼ç¾æéæ¼çç©é«å­¸ä¸­ LLM çèª¿æ¥éå¸¸å°æ³¨æ¼ç¹å®æç¨ææ¨¡åæ¶æ§ï¼ç¼ºä¹æ´ååç¨®çç©é«å­¸é åææ°é²å±çå¨é¢åæãæ¬ç¶è¿°åºæ¼å°ä¾èª PubMedãWeb of Science å arXiv ç­æ¸æåº«ç 484 ç¯åºçç©çåæï¼æ·±å¥æ¢è¨äºçç©é«å­¸ä¸­ LLM çç¶åç¾æ³ãæç¨ãææ°ååæ¯ï¼å¶ç¹é»æ¯éæ³¨éäºæ¨¡åå¨ç¾å¯¦ä¸ççç©é«å­¸èæ¯ä¸­çå¯¦éæç¨ãé¦åï¼æåæ¢è¨äº LLM å¨å»£æ³ççç©é«å­¸ä»»åä¸­çé¶æ¬¡å­¸ç¿è½åï¼åæ¬è¨ºæ·è¼å©ãè¥ç©ç¼ç¾ååæ§åé«çç­ï¼ä¸¦å¾ 137 é ééµç ç©¶ä¸­æ±²åè¦è§£ãç¶å¾ï¼æåè¨è«äº LLM çé©æç­ç¥ï¼åæ¬å®æ¨¡æåå¤æ¨¡æ LLM çå¾®èª¿æ¹æ³ï¼ä»¥å¢å¼·å®åå¨é¶æ¬¡å­¸ç¿ç¡æ³å¯¦ç¾çå°æ¥­çç©é«å­¸èæ¯ä¸­çæ§è½ï¼ä¾å¦é«çåé¡è§£ç­åçç©é«å­¸æç»çææèçãæå¾ï¼æåè¨è«äº LLM å¨çç©é«å­¸é åé¢è¨çææ°ï¼åæ¬æ¸æé±ç§åé¡ãæ¨¡åå¯è§£éæ§æéãæ¸æéè³ªéåé¡ä»¥åç±æ¼çç©é«å­¸æ¸æçæææ§ãå°é«åº¦å¯é æ¨¡åè¼¸åºçéæ±ä»¥åå¨é«çä¿å¥ä¸­é¨ç½² AI çå«çå½±é¿èç¢ççå«çåé¡ãçºäºæå°éäºææ°ï¼æåéç¢ºå®äºçç©é«å­¸ä¸­ LLM æªä¾çç ç©¶æ¹åï¼åæ¬ç¨æ¼ä¿è­·æ¸æé±ç§çè¯åå­¸ç¿æ¹æ³ä»¥åæ´åå¯è§£é AI æ¹æ³ä»¥å¢å¼· LLM çéæåº¦ã

##### **Aligning XAI with EU Regulations for Smart Biomedical Devices: A Methodology for Compliance Analysis**
2408.15121v1 by Francesco Sovrano, Michael Lognoul, Giulia Vilone

Significant investment and development have gone into integrating Artificial
Intelligence (AI) in medical and healthcare applications, leading to advanced
control systems in medical technology. However, the opacity of AI systems
raises concerns about essential characteristics needed in such sensitive
applications, like transparency and trustworthiness. Our study addresses these
concerns by investigating a process for selecting the most adequate Explainable
AI (XAI) methods to comply with the explanation requirements of key EU
regulations in the context of smart bioelectronics for medical devices. The
adopted methodology starts with categorising smart devices by their control
mechanisms (open-loop, closed-loop, and semi-closed-loop systems) and delving
into their technology. Then, we analyse these regulations to define their
explainability requirements for the various devices and related goals.
Simultaneously, we classify XAI methods by their explanatory objectives. This
allows for matching legal explainability requirements with XAI explanatory
goals and determining the suitable XAI algorithms for achieving them. Our
findings provide a nuanced understanding of which XAI algorithms align better
with EU regulations for different types of medical devices. We demonstrate this
through practical case studies on different neural implants, from chronic
disease management to advanced prosthetics. This study fills a crucial gap in
aligning XAI applications in bioelectronics with stringent provisions of EU
regulations. It provides a practical framework for developers and researchers,
ensuring their AI innovations advance healthcare technology and adhere to legal
and ethical standards.

æè¦ï¼äººå·¥æºæ§ï¼AIï¼å¨é«çåä¿å¥æç¨ä¸­æå¥äºå¤§éçæè³åéç¼ï¼é²èå°è´é«çæè¡ä¸­çåé²æ§å¶ç³»çµ±ãç¶èï¼AI ç³»çµ±çä¸éææ§å¼ç¼äºå°æ­¤é¡æææç¨ä¸­æéåºæ¬ç¹æ§çææï¼ä¾å¦éæåº¦åå¯ä¿¡åº¦ãæåçç ç©¶ééèª¿æ¥ä¸åç¨åºä¾è§£æ±ºéäºåé¡ï¼ç¨æ¼é¸ææååçå¯è§£é AIï¼XAIï¼æ¹æ³ï¼ä»¥ç¬¦åæ­çæ³è¦å¨é«çå¨æçæºæ§åçç©é»å­å­¸ä¸­çèªªæè¦æ±ãæ¡ç¨çæ¹æ³å¾ééå¶æ§å¶æ©å¶ï¼éè¿´è·¯ãéè¿´è·¯ååéè¿´è·¯ç³»çµ±ï¼å°æºæ§åè£ç½®é²è¡åé¡ï¼ä¸¦æ·±å¥æ¢è¨å¶æè¡éå§ãç¶å¾ï¼æååæéäºæ³è¦ä»¥å®ç¾©å¶å°åç¨®è£ç½®åç¸éç®æ¨çå¯è§£éæ§è¦æ±ãåæï¼æåééå¶èªªæç®æ¨å° XAI æ¹æ³é²è¡åé¡ãéåè¨±å°æ³å¾å¯è§£éæ§è¦æ±è XAI èªªæç®æ¨ç¸å¹éï¼ä¸¦ç¢ºå®é©ç¶ç XAI æ¼ç®æ³ä¾éæå®åãæåçç ç©¶çµææä¾äºå°åªäº XAI æ¼ç®æ³æ´ç¬¦åæ­çæ³è¦ä»¥é©ç¨æ¼ä¸åé¡åçé«çå¨æçç´°ç·»çè§£ãæåééä¸åç¥ç¶æ¤å¥ç©çå¯¦éæ¡ä¾ç ç©¶ä¾è­æéä¸é»ï¼å¾æ¢æ§ç¾çç®¡çå°åé²çç¾©è¢ãéé ç ç©¶å¡«è£äºå°çç©é»å­å­¸ä¸­ç XAI æç¨èæ­çæ³è¦çå´æ ¼è¦å®ç¸ç¬¦çéè¦ç©ºç½ãå®çºéç¼äººå¡åç ç©¶äººå¡æä¾äºä¸åå¯¦ç¨çæ¶æ§ï¼ç¢ºä¿å¶ AI åµæ°è½ä¿é²é«çæè¡ä¸¦éµå®æ³å¾åéå¾·æ¨æºã

##### **Towards Case-based Interpretability for Medical Federated Learning**
2408.13626v1 by Laura Latorre, Liliana Petrychenko, Regina Beets-Tan, Taisiya Kopytova, Wilson Silva

We explore deep generative models to generate case-based explanations in a
medical federated learning setting. Explaining AI model decisions through
case-based interpretability is paramount to increasing trust and allowing
widespread adoption of AI in clinical practice. However, medical AI training
paradigms are shifting towards federated learning settings in order to comply
with data protection regulations. In a federated scenario, past data is
inaccessible to the current user. Thus, we use a deep generative model to
generate synthetic examples that protect privacy and explain decisions. Our
proof-of-concept focuses on pleural effusion diagnosis and uses publicly
available Chest X-ray data.

æè¦ï¼æåæ¢ç´¢æ·±åº¦çææ¨¡åï¼å¨é«çè¯é¦å­¸ç¿è¨­ç½®ä¸­çæåºæ¼æ¡ä¾çèªªæãééåºæ¼æ¡ä¾çå¯è§£éæ§ä¾è§£é AI æ¨¡åæ±ºç­ï¼å°æ¼å¢å ä¿¡ä»»ä¸¦åè¨± AI å¨è¨åºå¯¦åä¸­å»£æ³æ¡ç¨è³ééè¦ãç¶èï¼é«ç AI è¨ç·´ç¯ä¾æ­£è½åè¯é¦å­¸ç¿è¨­ç½®ï¼ä»¥ç¬¦åè³æä¿è­·æ³è¦ãå¨è¯é¦æå¢ä¸­ï¼éå»çè³æå°ç®åçä½¿ç¨èèè¨æ¯ç¡æ³åå¾çãå æ­¤ï¼æåä½¿ç¨æ·±åº¦çææ¨¡åä¾ç¢çä¿è­·é±ç§åè§£éæ±ºç­çåæç¯ä¾ãæåçæ¦å¿µé©è­èéæ¼è¸èç©æ¶²è¨ºæ·ï¼ä¸¦ä½¿ç¨å¬éå¯åå¾çè¸é¨ X åè³æã

##### **AI in radiological imaging of soft-tissue and bone tumours: a systematic review evaluating against CLAIM and FUTURE-AI guidelines**
2408.12491v1 by Douwe J. Spaanderman, Matthew Marzetti, Xinyi Wan, Andrew F. Scarsbrook, Philip Robinson, Edwin H. G. Oei, Jacob J. Visser, Robert Hemke, Kirsten van Langevelde, David F. Hanff, Geert J. L. H. van Leenders, Cornelis Verhoef, Dirk J. GruÃ¼hagen, Wiro J. Niessen, Stefan Klein, Martijn P. A. Starmans

Soft-tissue and bone tumours (STBT) are rare, diagnostically challenging
lesions with variable clinical behaviours and treatment approaches. This
systematic review provides an overview of Artificial Intelligence (AI) methods
using radiological imaging for diagnosis and prognosis of these tumours,
highlighting challenges in clinical translation, and evaluating study alignment
with the Checklist for AI in Medical Imaging (CLAIM) and the FUTURE-AI
international consensus guidelines for trustworthy and deployable AI to promote
the clinical translation of AI methods. The review covered literature from
several bibliographic databases, including papers published before 17/07/2024.
Original research in peer-reviewed journals focused on radiology-based AI for
diagnosing or prognosing primary STBT was included. Exclusion criteria were
animal, cadaveric, or laboratory studies, and non-English papers. Abstracts
were screened by two of three independent reviewers for eligibility. Eligible
papers were assessed against guidelines by one of three independent reviewers.
The search identified 15,015 abstracts, from which 325 articles were included
for evaluation. Most studies performed moderately on CLAIM, averaging a score
of 28.9$\pm$7.5 out of 53, but poorly on FUTURE-AI, averaging 5.1$\pm$2.1 out
of 30. Imaging-AI tools for STBT remain at the proof-of-concept stage,
indicating significant room for improvement. Future efforts by AI developers
should focus on design (e.g. define unmet clinical need, intended clinical
setting and how AI would be integrated in clinical workflow), development (e.g.
build on previous work, explainability), evaluation (e.g. evaluating and
addressing biases, evaluating AI against best practices), and data
reproducibility and availability (making documented code and data publicly
available). Following these recommendations could improve clinical translation
of AI methods.

æè¦ï¼è»çµç¹åéª¨éª¼è«ç¤ï¼STBTï¼æ¯ç½è¦ãè¨ºæ·å·æææ°æ§ççç¶ï¼å¶è¨åºè¡çºåæ²»çæ¹æ³åä¸ç¸åãéç¯ç³»çµ±æ§åé¡§æä¾äºä½¿ç¨æ¾å°å½±åé²è¡è¨ºæ·åé å¾çäººå·¥æºæ§ (AI) æ¹æ³çæ¦è§ï¼éé»èªªæäºè¨åºè½è­¯çææ°ï¼ä¸¦è©ä¼°ç ç©¶èé«çå½±å AI æ ¸æ¥è¡¨ (CLAIM) å FUTURE-AI å¯ä¿¡è³´ä¸å¯é¨ç½² AI çåéå±è­æºåçä¸è´æ§ï¼ä»¥ä¿é² AI æ¹æ³çè¨åºè½è­¯ãéç¯åé¡§æ¶µèäºå¹¾åæ¸ç®è³æåº«ä¸­çæç»ï¼åæ¬å¨ 2024 å¹´ 7 æ 17 æ¥ä¹åç¼è¡¨çè«æãç´å¥äºä»¥æ¾å°çºåºç¤ç AI è¨ºæ·æé å¾åç¼æ§ STBT çåè¡è©å¯©æåä¸­çåå§ç ç©¶ãæé¤æ¨æºæ¯åç©ãå±é«æå¯¦é©å®¤ç ç©¶ï¼ä»¥åéè±æè«æãæè¦ç±ä¸ä½ç¨ç«å¯©æ¥å¡ä¸­çå©ä½ç¯©é¸è³æ ¼ãåæ ¼çè«æç±ä¸ä½ç¨ç«å¯©æ¥å¡ä¸­çä¸ä½æ ¹ææºåé²è¡è©ä¼°ãæç´¢è­å¥åº 15,015 ç¯æè¦ï¼å¶ä¸­ 325 ç¯æç« è¢«ç´å¥è©ä¼°ãå¤§å¤æ¸ç ç©¶å¨ CLAIM ä¸­è¡¨ç¾ä¸­ç­ï¼å¹³åå¾åçº 53 åä¸­ç 28.9Â±7.5 åï¼ä½å¨ FUTURE-AI ä¸­è¡¨ç¾ä¸ä½³ï¼å¹³åå¾åçº 30 åä¸­ç 5.1Â±2.1 åãSTBT çå½±å AI å·¥å·ä»èæ¼æ¦å¿µé©è­éæ®µï¼è¡¨ææé¡¯èçæ¹é²ç©ºéãAI éç¼äººå¡æªä¾çåªåæéä¸­å¨è¨­è¨ï¼ä¾å¦å®ç¾©æªæ»¿è¶³çè¨åºéæ±ãé æçè¨åºç°å¢ä»¥å AI å¦ä½æ´åå°è¨åºå·¥ä½æµç¨ä¸­ï¼ãéç¼ï¼ä¾å¦å»ºç«å¨ååçå·¥ä½ãå¯è§£éæ§ï¼ãè©ä¼°ï¼ä¾å¦è©ä¼°åè§£æ±ºåå·®ãè©ä¼° AI èæä½³å¯¦åï¼ãä»¥åæ¸æå¯è¤è£½æ§åå¯ç¨æ§ï¼å¬éæä¾æä»¶åçä»£ç¢¼åæ¸æï¼ãéµå¾ªéäºå»ºè­°å¯ä»¥æ¹å AI æ¹æ³çè¨åºè½è­¯ã

##### **Evaluating Explainable AI Methods in Deep Learning Models for Early Detection of Cerebral Palsy**
2409.00001v1 by Kimji N. Pellano, Inga StrÃ¼mke, Daniel Groos, Lars Adde, Espen Alexander F. Ihlen

Early detection of Cerebral Palsy (CP) is crucial for effective intervention
and monitoring. This paper tests the reliability and applicability of
Explainable AI (XAI) methods using a deep learning method that predicts CP by
analyzing skeletal data extracted from video recordings of infant movements.
Specifically, we use XAI evaluation metrics -- namely faithfulness and
stability -- to quantitatively assess the reliability of Class Activation
Mapping (CAM) and Gradient-weighted Class Activation Mapping (Grad-CAM) in this
specific medical application. We utilize a unique dataset of infant movements
and apply skeleton data perturbations without distorting the original dynamics
of the infant movements. Our CP prediction model utilizes an ensemble approach,
so we evaluate the XAI metrics performances for both the overall ensemble and
the individual models. Our findings indicate that both XAI methods effectively
identify key body points influencing CP predictions and that the explanations
are robust against minor data perturbations. Grad-CAM significantly outperforms
CAM in the RISv metric, which measures stability in terms of velocity. In
contrast, CAM performs better in the RISb metric, which relates to bone
stability, and the RRS metric, which assesses internal representation
robustness. Individual models within the ensemble show varied results, and
neither CAM nor Grad-CAM consistently outperform the other, with the ensemble
approach providing a representation of outcomes from its constituent models.

æè¦ï¼è¦æ§éº»çº (CP) çæ©æåµæ¸¬å°æ¼ææçä»å¥åç£æ¸¬è³ééè¦ãæ¬ææ¸¬è©¦äºå¯è§£é AI (XAI) æ¹æ³çå¯é æ§åé©ç¨æ§ï¼ä½¿ç¨æ·±åº¦å­¸ç¿æ¹æ³ï¼ééåæå¾å¬°ååä½å½±çè¨éä¸­æåçéª¨éª¼è³æä¾é æ¸¬ CPãå·é«ä¾èªªï¼æåä½¿ç¨ XAI è©ä¼°ææ¨ï¼å³å¿ å¯¦åº¦åç©©å®æ§ï¼ä¾éåè©ä¼°é¡å¥æ¿æ´»æ å° (CAM) åæ¢¯åº¦å æ¬é¡å¥æ¿æ´»æ å° (Grad-CAM) å¨éåç¹å®é«çæç¨ä¸­çå¯é æ§ãæåå©ç¨ä¸åç¨ç¹çå¬°ååä½è³æéï¼ä¸¦æç¨éª¨éª¼è³ææ¾åï¼èä¸ææ­æ²å¬°ååä½çåå§ååãæåç CP é æ¸¬æ¨¡åå©ç¨æ´é«æ¹æ³ï¼å æ­¤æåè©ä¼°äºæ´é«æ´é«ååå¥æ¨¡åç XAI ææ¨è¡¨ç¾ãæåçç ç©¶çµæè¡¨æï¼å©ç¨® XAI æ¹æ³é½è½ææè­å¥å½±é¿ CP é æ¸¬çééµèº«é«é¨ä½ï¼ä¸¦ä¸éäºè§£éå°æ¼å¾®å°çè³ææ¾åå·æé­¯æ£æ§ãGrad-CAM å¨ RISv ææ¨ä¸­é¡¯èåªæ¼ CAMï¼è©²ææ¨è¡¡ééåº¦æ¹é¢çç©©å®æ§ãç¸æ¯ä¹ä¸ï¼CAM å¨ RISb ææ¨ä¸­è¡¨ç¾å¾æ´å¥½ï¼è©²ææ¨èéª¨éª¼ç©©å®æ§æéï¼è RRS ææ¨åè©ä¼°å§é¨è¡¨ç¤ºçé­¯æ£æ§ãæ´é«ä¸­çåå¥æ¨¡åé¡¯ç¤ºåºä¸åççµæï¼CAM å Grad-CAM é½ä¸ä¸è´å°åªæ¼å¦ä¸ç¨®ï¼æ´é«æ¹æ³æä¾äºå¶çµææ¨¡åçµæçè¡¨ç¤ºã

##### **MicroXercise: A Micro-Level Comparative and Explainable System for Remote Physical Therapy**
2408.11837v1 by Hanchen David Wang, Nibraas Khan, Anna Chen, Nilanjan Sarkar, Pamela Wisniewski, Meiyi Ma

Recent global estimates suggest that as many as 2.41 billion individuals have
health conditions that would benefit from rehabilitation services. Home-based
Physical Therapy (PT) faces significant challenges in providing interactive
feedback and meaningful observation for therapists and patients. To fill this
gap, we present MicroXercise, which integrates micro-motion analysis with
wearable sensors, providing therapists and patients with a comprehensive
feedback interface, including video, text, and scores. Crucially, it employs
multi-dimensional Dynamic Time Warping (DTW) and attribution-based explainable
methods to analyze the existing deep learning neural networks in monitoring
exercises, focusing on a high granularity of exercise. This synergistic
approach is pivotal, providing output matching the input size to precisely
highlight critical subtleties and movements in PT, thus transforming complex AI
analysis into clear, actionable feedback. By highlighting these micro-motions
in different metrics, such as stability and range of motion, MicroXercise
significantly enhances the understanding and relevance of feedback for
end-users. Comparative performance metrics underscore its effectiveness over
traditional methods, such as a 39% and 42% improvement in Feature Mutual
Information (FMI) and Continuity. MicroXercise is a step ahead in home-based
physical therapy, providing a technologically advanced and intuitively helpful
solution to enhance patient care and outcomes.

æè¦ï¼æè¿çå¨çä¼°è¨è¡¨æï¼å¤é 24.1 åäººæ
å¥åº·çæ³å¯å¾å¾©å¥æåä¸­åçãå±å®¶
ç©çæ²»ç (PT) å¨æä¾äºåå¼
åé¥åææç¾©çè§å¯æ¹é¢é¢è¨éå¤§ææ°ï¼ä¾æ²»çå¸«åæ£èä½¿ç¨ãçºäºå¡«è£é
åç¼ºå£ï¼æåæåº MicroXerciseï¼å®å°å¾®åä½åæè
å¯ç©¿æ´å¼ææ¸¬å¨æ´åå¨ä¸èµ·ï¼çºæ²»çå¸«åæ£èæä¾ä¸åå¨é¢ç
åé¥ä»é¢ï¼åæ¬å½±çãæå­ååæ¸ãè³ééè¦çæ¯ï¼å®æ¡ç¨
å¤ç¶­åææéè¦æ´ (DTW) ååºæ¼æ­¸å çå¯è§£é
æ¹æ³ä¾åæç£æ§éåä¸­ç¾æçæ·±åº¦å­¸ç¿ç¥ç¶ç¶²è·¯ï¼å°æ³¨æ¼éåçé«ç²åº¦ãéç¨®åå
æ¹æ³è³ééè¦ï¼æä¾èè¼¸å¥å¤§å°å¹éçè¼¸åºï¼ä»¥ç²¾ç¢ºå°
çªåº PT ä¸­ééµçç´°å¾®å·®å¥ååä½ï¼å¾èå°è¤éç AI
åæè½æçºæ¸æ°ãå¯æä½çåé¥ãééå¨ä¸åææ¨ä¸­çªé¡¯éäºå¾®åä½ï¼ä¾å¦ç©©å®æ§ååä½ç¯åï¼MicroXercise
é¡¯èæåæçµä½¿ç¨èå°åé¥ççè§£åç¸éæ§ãæ¯è¼æè½ææ¨å¼·èª¿å¶åªæ¼
å³çµ±æ¹æ³çæææ§ï¼ä¾å¦ç¹å¾µäºæ è³è¨ (FMI) åé£çºæ§åå¥æåäº 39% å 42%ãMicroXercise å¨å±å®¶
ç©çæ²»çæ¹é¢æ´é²ä¸æ­¥ï¼æä¾æè¡åé²ä¸ç´è¦ºæç¨ç
è§£æ±ºæ¹æ¡ï¼ä»¥æåæ£èç§è­·åçµæã

##### **The Literature Review Network: An Explainable Artificial Intelligence for Systematic Literature Reviews, Meta-analyses, and Method Development**
2408.05239v1 by Joshua Morriss, Tod Brindle, Jessica Bah RÃ¶sman, Daniel Reibsamen, Andreas Enz

Systematic literature reviews are the highest quality of evidence in
research. However, the review process is hindered by significant resource and
data constraints. The Literature Review Network (LRN) is the first of its kind
explainable AI platform adhering to PRISMA 2020 standards, designed to automate
the entire literature review process. LRN was evaluated in the domain of
surgical glove practices using 3 search strings developed by experts to query
PubMed. A non-expert trained all LRN models. Performance was benchmarked
against an expert manual review. Explainability and performance metrics
assessed LRN's ability to replicate the experts' review. Concordance was
measured with the Jaccard index and confusion matrices. Researchers were
blinded to the other's results until study completion. Overlapping studies were
integrated into an LRN-generated systematic review. LRN models demonstrated
superior classification accuracy without expert training, achieving 84.78% and
85.71% accuracy. The highest performance model achieved high interrater
reliability (k = 0.4953) and explainability metrics, linking 'reduce',
'accident', and 'sharp' with 'double-gloving'. Another LRN model covered 91.51%
of the relevant literature despite diverging from the non-expert's judgments (k
= 0.2174), with the terms 'latex', 'double' (gloves), and 'indication'. LRN
outperformed the manual review (19,920 minutes over 11 months), reducing the
entire process to 288.6 minutes over 5 days. This study demonstrates that
explainable AI does not require expert training to successfully conduct
PRISMA-compliant systematic literature reviews like an expert. LRN summarized
the results of surgical glove studies and identified themes that were nearly
identical to the clinical researchers' findings. Explainable AI can accurately
expedite our understanding of clinical practices, potentially revolutionizing
healthcare research.

æè¦ï¼ç³»çµ±æ§æç»åé¡§æ¯ç ç©¶ä¸­è­æåè³ªæé«çãç¶èï¼åé¡§éç¨åå°é¡¯èè³æºåè³æéå¶çé»ç¤ãæç»åé¡§ç¶²è·¯ (LRN) æ¯ç¬¬ä¸åéµå¾ª PRISMA 2020 æ¨æºçå¯è§£é AI å¹³å°ï¼æ¨å¨èªååæ´åæç»åé¡§éç¨ãLRN å¨å¤ç§æå¥å¯¦åé åä¸­é²è¡è©ä¼°ï¼ä½¿ç¨å°å®¶éç¼ç 3 åæå°å­ä¸²ä¾æ¥è©¢ PubMedãéå°å®¶è¨ç·´ææ LRN æ¨¡åãæè½ä»¥å°å®¶æååé¡§ä½çºåºæºãå¯è§£éæ§åæè½ææ¨è©ä¼° LRN è¤è£½å°å®¶åé¡§çè½åãä¸è´æ§ä»¥ Jaccard ææ¸åæ··æ·ç©é£æ¸¬éãç ç©¶äººå¡å¨ç ç©¶å®æåå°å½¼æ­¤ççµæä¿å¯ãéççç ç©¶æ´åå° LRN çæçç³»çµ±æ§åé¡§ä¸­ãLRN æ¨¡åå¨æ²æå°å®¶è¨ç·´çææ³ä¸å±ç¾åºåªç°çåé¡æºç¢ºçï¼éå° 84.78% å 85.71% çæºç¢ºçãæè½æé«çæ¨¡åéå°äºé«è©åèéä¿¡è³´åº¦ (k = 0.4953) åå¯è§£éæ§ææ¨ï¼å°ãæ¸å°ãããæå¤ãåãé³å©ãèãééæ´æå¥ãé£çµå¨ä¸èµ·ãå¦ä¸å LRN æ¨¡åæ¶µèäº 91.51% çç¸éæç»ï¼åç®¡èéå°å®¶çå¤æ·ä¸å (k = 0.2174)ï¼ä½åå«äºãä¹³è ãããééãï¼æå¥ï¼åãé©æçãç­è©å½ãLRN åªæ¼æååé¡§ï¼11 åæè¶é 19,920 åéï¼ï¼å°æ´åéç¨ç¸®ç­çº 5 å¤©è¶é 288.6 åéãéé ç ç©¶é¡¯ç¤ºï¼å¯è§£éç AI ä¸éè¦å°å®¶è¨ç·´å³å¯æåé²è¡å°å®¶ç­ç´ç PRISMA ç¸å®¹ç³»çµ±æ§æç»åé¡§ãLRN ç¸½çµäºå¤ç§æå¥ç ç©¶ççµæï¼ä¸¦æ¾åºèè¨åºç ç©¶äººå¡ç¼ç¾å¹¾ä¹ç¸åçä¸»é¢ãå¯è§£éç AI å¯ä»¥æºç¢ºå°å å¿«æåå°è¨åºå¯¦åççè§£ï¼ææ½åé©æ°é«çä¿å¥ç ç©¶ã

##### **Enhancing Medical Learning and Reasoning Systems: A Boxology-Based Comparative Analysis of Design Patterns**
2408.02709v1 by Chi Him Ng

This study analyzes hybrid AI systems' design patterns and their
effectiveness in clinical decision-making using the boxology framework. It
categorizes and copares various architectures combining machine learning and
rule-based reasoning to provide insights into their structural foundations and
healthcare applications. Addressing two main questions, how to categorize these
systems againts established design patterns and how to extract insights through
comparative analysis, the study uses design patterns from software engineering
to understand and optimize healthcare AI systems. Boxology helps identify
commonalities and create reusable solutions, enhancing these systems'
scalability, reliability, and performance. Five primary architectures are
examined: REML, MLRB, RBML, RMLT, and PERML. Each has unique strengths and
weaknesses, highlighting the need for tailored approaches in clinical tasks.
REML excels in high-accuracy prediction for datasets with limited data; MLRB in
handling large datasets and complex data integration; RBML in explainability
and trustworthiness; RMLT in managing high-dimensional data; and PERML, though
limited in analysis, shows promise in urgent care scenarios. The study
introduces four new patterns, creates five abstract categorization patterns,
and refines those five further to specific systems. These contributions enhance
Boxlogy's taxonomical organization and offer novel approaches to integrating
expert knowledge with machine learning. Boxology's structured, modular apporach
offers significant advantages in developing and analyzing hybrid AI systems,
revealing commonalities, and promoting reusable solutions. In conclusion, this
study underscores hybrid AI systems' crucial role in advancing healthcare and
Boxology's potential to drive further innovation in AI integration, ultimately
improving clinical decision support and patient outcomes.

æè¦ï¼æ¬ç ç©¶ä½¿ç¨çå­å­¸æ¡æ¶åææ··åäººå·¥æºæ§ç³»çµ±çè¨­è¨æ¨¡å¼åå¶å¨è¨åºæ±ºç­ä¸­çæææ§ãå®åé¡ä¸¦æ¯è¼çµåæ©å¨å­¸ç¿ååºæ¼è¦åçæ¨ççåç¨®æ¶æ§ï¼ä»¥æ·±å¥äºè§£å¶çµæ§åºç¤åé«çä¿å¥æç¨ãéå°å©åä¸»è¦åé¡ï¼å¦ä½æ ¹ææ¢å®çè¨­è¨æ¨¡å¼å°éäºç³»çµ±é²è¡åé¡ï¼ä»¥åå¦ä½ééæ¯è¼åææåè¦è§£ï¼æ¬ç ç©¶ä½¿ç¨è»é«å·¥ç¨ä¸­çè¨­è¨æ¨¡å¼ä¾äºè§£ååªåé«çä¿å¥äººå·¥æºæ§ç³»çµ±ãçå­å­¸æå©æ¼è­å¥å±æ§ä¸¦å»ºç«å¯éè¤ä½¿ç¨çè§£æ±ºæ¹æ¡ï¼å¾èå¢å¼·éäºç³»çµ±çå¯æ´åæ§ãå¯é æ§åæè½ãæª¢æ¥äºäºç¨®ä¸»è¦çæ¶æ§ï¼REMLãMLRBãRBMLãRMLT å PERMLãæ¯ç¨®æ¶æ§é½æç¨ç¹çåªç¼ºé»ï¼å¼·èª¿äºå¨è¨åºä»»åä¸­éè¦éèº«æé çæ¹æ³ãREML å¨è³ææéçè³æéä¸­è¡¨ç¾åºé«ç²¾åº¦çé æ¸¬ï¼MLRB å¨èçå¤§åè³æéåè¤éè³ææ´åæ¹é¢è¡¨ç¾åºè²ï¼RBML å¨å¯è§£éæ§åå¯ä¿¡åº¦æ¹é¢è¡¨ç¾åºè²ï¼RMLT å¨ç®¡çé«ç¶­è³ææ¹é¢è¡¨ç¾åºè²ï¼è PERML åç®¡å¨åææ¹é¢æéï¼ä½å¨ç·æ¥ç§è­·å ´æ¯ä¸­è¡¨ç¾åºæ½åãæ¬ç ç©¶å¼å¥äºåç¨®æ°æ¨¡å¼ï¼å»ºç«äºäºç¨®æ½è±¡åé¡æ¨¡å¼ï¼ä¸¦é²ä¸æ­¥å°éäºç¨®æ¨¡å¼ç´°åçºå·é«çç³»çµ±ãéäºè²¢ç»å¢å¼·äºçå­å­¸çåé¡çµç¹ï¼ä¸¦æä¾äºå°å°å®¶ç¥è­èæ©å¨å­¸ç¿æ´åçæ°æ¹æ³ãçå­å­¸ççµæ§åãæ¨¡çµåæ¹æ³å¨éç¼ååææ··åäººå·¥æºæ§ç³»çµ±ãæ­ç¤ºå±æ§ä»¥åæ¨å»£å¯éè¤ä½¿ç¨çè§£æ±ºæ¹æ¡æ¹é¢å·æé¡¯èåªå¢ãç¸½ä¹ï¼æ¬ç ç©¶å¼·èª¿äºæ··åäººå·¥æºæ§ç³»çµ±å¨æ¨é²é«çä¿å¥ä¸­çééµä½ç¨ï¼ä»¥åçå­å­¸å¨æ¨åäººå·¥æºæ§æ´åé²ä¸æ­¥åµæ°æ¹é¢çæ½åï¼æçµæ¹åè¨åºæ±ºç­æ¯æ´åæ£èçæ²»çææã

##### **Bayesian Kolmogorov Arnold Networks (Bayesian_KANs): A Probabilistic Approach to Enhance Accuracy and Interpretability**
2408.02706v1 by Masoud Muhammed Hassan

Because of its strong predictive skills, deep learning has emerged as an
essential tool in many industries, including healthcare. Traditional deep
learning models, on the other hand, frequently lack interpretability and omit
to take prediction uncertainty into account two crucial components of clinical
decision making. In order to produce explainable and uncertainty aware
predictions, this study presents a novel framework called Bayesian Kolmogorov
Arnold Networks (BKANs), which combines the expressive capacity of Kolmogorov
Arnold Networks with Bayesian inference. We employ BKANs on two medical
datasets, which are widely used benchmarks for assessing machine learning
models in medical diagnostics: the Pima Indians Diabetes dataset and the
Cleveland Heart Disease dataset. Our method provides useful insights into
prediction confidence and decision boundaries and outperforms traditional deep
learning models in terms of prediction accuracy. Moreover, BKANs' capacity to
represent aleatoric and epistemic uncertainty guarantees doctors receive more
solid and trustworthy decision support. Our Bayesian strategy improves the
interpretability of the model and considerably minimises overfitting, which is
important for tiny and imbalanced medical datasets, according to experimental
results. We present possible expansions to further use BKANs in more
complicated multimodal datasets and address the significance of these
discoveries for future research in building reliable AI systems for healthcare.
This work paves the way for a new paradigm in deep learning model deployment in
vital sectors where transparency and reliability are crucial.

æè¦ï¼ç±æ¼å¶å¼·å¤§çé æ¸¬è½åï¼æ·±åº¦å­¸ç¿å·²æçºè¨±å¤ç¢æ¥­ä¸­ä¸å¯æç¼ºçå·¥å·ï¼åæ¬é«çä¿å¥ãç¶èï¼å³çµ±çæ·±åº¦å­¸ç¿æ¨¡åéå¸¸ç¼ºä¹å¯è§£éæ§ï¼ä¸¦ä¸å¿½ç¥äºå°é æ¸¬ä¸ç¢ºå®æ§ç´å¥èéï¼èéå©åå ç´ æ¯è¨åºæ±ºç­å¶å®çééµçµæé¨åãçºäºç¢çå¯è§£éä¸å·æä¸ç¢ºå®æ§æè­çé æ¸¬ï¼æ¬ç ç©¶æåºäºä¸ååçºè²æ°æ¯ç¾è«å¥æ´å¤«é¿è«¾å¾·ç¶²è·¯ (BKAN) çæ°æ¶æ§ï¼å®çµåäºæ¯ç¾è«å¥æ´å¤«é¿è«¾å¾·ç¶²è·¯çè¡¨éè½åèè²æ°æ¨è«ãæåå¨å©åé«å­¸è³æéä¸ä½¿ç¨ BKANï¼éäºè³æéæ¯è©ä¼°æ©å¨å­¸ç¿æ¨¡åå¨é«å­¸è¨ºæ·ä¸­çå»£æ³ä½¿ç¨åºæºï¼ç®é¦¬å°ç¬¬å®äººç³å°¿çè³æéååéå¤«è­å¿èçè³æéãæåçæ¨¡åæä¾äºå°é æ¸¬ä¿¡å¿åæ±ºç­éççæçè¦è§£ï¼ä¸¦ä¸å¨é æ¸¬æºç¢ºåº¦æ¹é¢åªæ¼å³çµ±çæ·±åº¦å­¸ç¿æ¨¡åãæ­¤å¤ï¼BKAN è¡¨ç¾é¨æ©åèªè­ä¸ç¢ºå®æ§çè½åï¼å¯ç¢ºä¿é«çç²å¾æ´å¯é ä¸å¼å¾ä¿¡è³´çæ±ºç­æ¯æ´ãæ ¹æå¯¦é©çµæï¼æåçè²æ°ç­ç¥æé«äºæ¨¡åçå¯è§£éæ§ï¼ä¸¦å¤§å¹æ¸å°äºéåº¦æ¬åï¼éå°æ¼å°åä¸ä¸å¹³è¡¡çé«å­¸è³æééå¸¸éè¦ãæåæåºäºå¯è½çæ´ååè½ï¼ä»¥é²ä¸æ­¥å° BKAN ç¨æ¼æ´è¤éçå¤æ¨¡å¼è³æéï¼ä¸¦æ¢è¨éäºç¼ç¾å°æ¼æªä¾å»ºç«å¯é çé«çä¿å¥ AI ç³»çµ±ç ç©¶çéè¦æ§ãéé å·¥ä½çºæ·±åº¦å­¸ç¿æ¨¡åé¨ç½²å¨éæåº¦åå¯é æ§è³ééè¦çéè¦é åä¸­éåäºä¸åæ°çå¸ç¯ã

##### **MLtoGAI: Semantic Web based with Machine Learning for Enhanced Disease Prediction and Personalized Recommendations using Generative AI**
2407.20284v1 by Shyam Dongre, Ritesh Chandra, Sonali Agarwal

In modern healthcare, addressing the complexities of accurate disease
prediction and personalized recommendations is both crucial and challenging.
This research introduces MLtoGAI, which integrates Semantic Web technology with
Machine Learning (ML) to enhance disease prediction and offer user-friendly
explanations through ChatGPT. The system comprises three key components: a
reusable disease ontology that incorporates detailed knowledge about various
diseases, a diagnostic classification model that uses patient symptoms to
detect specific diseases accurately, and the integration of Semantic Web Rule
Language (SWRL) with ontology and ChatGPT to generate clear, personalized
health advice. This approach significantly improves prediction accuracy and
ensures results that are easy to understand, addressing the complexity of
diseases and diverse symptoms. The MLtoGAI system demonstrates substantial
advancements in accuracy and user satisfaction, contributing to developing more
intelligent and accessible healthcare solutions. This innovative approach
combines the strengths of ML algorithms with the ability to provide
transparent, human-understandable explanations through ChatGPT, achieving
significant improvements in prediction accuracy and user comprehension. By
leveraging semantic technology and explainable AI, the system enhances the
accuracy of disease prediction and ensures that the recommendations are
relevant and easily understood by individual patients. Our research highlights
the potential of integrating advanced technologies to overcome existing
challenges in medical diagnostics, paving the way for future developments in
intelligent healthcare systems. Additionally, the system is validated using 200
synthetic patient data records, ensuring robust performance and reliability.

æè¦ï¼å¨ç¾ä»£é«çä¿å¥ä¸­ï¼è§£æ±ºæºç¢ºç¾çé æ¸¬ååæ§åå»ºè­°çè¤éæ§æ¢è³ééè¦åå·æææ°æ§ãæ¬ç ç©¶å¼å¥äº MLtoGAIï¼å®å°èªç¾©ç¶²è·¯æè¡èæ©å¨å­¸ç¿ (ML) ç¸çµåï¼ä»¥å¢å¼·ç¾çé æ¸¬ä¸¦éé ChatGPT æä¾ä½¿ç¨èååçèªªæãè©²ç³»çµ±åå«ä¸åééµçµæé¨åï¼ä¸åå¯éè¤ä½¿ç¨çç¾çæ¬ä½ï¼å¶ä¸­åå«æéåç¨®ç¾ççè©³ç´°ç¥è­ï¼ä¸åè¨ºæ·åé¡æ¨¡åï¼å®ä½¿ç¨æ£èççä¾æºç¢ºæª¢æ¸¬ç¹å®ç¾çï¼ä»¥åèªç¾©ç¶²è·¯è¦åèªè¨ (SWRL) èæ¬ä½å ChatGPT çæ´åï¼ä»¥ç¢çæ¸æ°ãåæ§åçå¥åº·å»ºè­°ãéç¨®æ¹æ³é¡¯èæé«äºé æ¸¬æºç¢ºæ§ï¼ä¸¦ç¢ºä¿äºææ¼çè§£ççµæï¼è§£æ±ºäºç¾çåä¸åçççè¤éæ§ãMLtoGAI ç³»çµ±å±ç¤ºäºæºç¢ºæ§åä½¿ç¨èæ»¿æåº¦çå¯¦è³ªæ§é²æ­¥ï¼æå©æ¼éç¼æ´æºæ§ä¸æ´ææ¼åå¾çé«çä¿å¥è§£æ±ºæ¹æ¡ãéç¨®åµæ°çæ¹æ³çµåäº ML æ¼ç®æ³çåªé»ï¼ä»¥åéé ChatGPT æä¾éæä¸äººé¡å¯ä»¥çè§£çèªªæçè½åï¼å¨é æ¸¬æºç¢ºæ§åä½¿ç¨èçè§£æ¹é¢åå¾äºé¡¯èçé²æ­¥ãééå©ç¨èªç¾©æè¡åå¯è§£éç AIï¼è©²ç³»çµ±æé«äºç¾çé æ¸¬çæºç¢ºæ§ï¼ä¸¦ç¢ºä¿äºå»ºè­°èåå¥æ£èç¸éä¸ææ¼çè§£ãæåçç ç©¶å¼·èª¿äºæ´ååé²æè¡ä»¥åæé«çè¨ºæ·ä¸­ç¾æææ°çæ½åï¼çºæºæ§é«çä¿å¥ç³»çµ±çæªä¾ç¼å±éªè·¯ãæ­¤å¤ï¼è©²ç³»çµ±ä½¿ç¨ 200 ååææ£èè³æè¨éé²è¡é©è­ï¼ç¢ºä¿äºç©©å¥çæè½åå¯é æ§ã

##### **Introducing Î´-XAI: a novel sensitivity-based method for local AI explanations**
2407.18343v2 by Alessandro De Carlo, Enea Parimbelli, Nicola Melillo, Giovanna Nicora

Explainable Artificial Intelligence (XAI) is central to the debate on
integrating Artificial Intelligence (AI) and Machine Learning (ML) algorithms
into clinical practice. High-performing AI/ML models, such as ensemble learners
and deep neural networks, often lack interpretability, hampering clinicians'
trust in their predictions. To address this, XAI techniques are being developed
to describe AI/ML predictions in human-understandable terms. One promising
direction is the adaptation of sensitivity analysis (SA) and global sensitivity
analysis (GSA), which inherently rank model inputs by their impact on
predictions. Here, we introduce a novel delta-XAI method that provides local
explanations of ML model predictions by extending the delta index, a GSA
metric. The delta-XAI index assesses the impact of each feature's value on the
predicted output for individual instances in both regression and classification
problems. We formalize the delta-XAI index and provide code for its
implementation. The delta-XAI method was evaluated on simulated scenarios using
linear regression models, with Shapley values serving as a benchmark. Results
showed that the delta-XAI index is generally consistent with Shapley values,
with notable discrepancies in models with highly impactful or extreme feature
values. The delta-XAI index demonstrated higher sensitivity in detecting
dominant features and handling extreme feature values. Qualitatively, the
delta-XAI provides intuitive explanations by leveraging probability density
functions, making feature rankings clearer and more explainable for
practitioners. Overall, the delta-XAI method appears promising for robustly
obtaining local explanations of ML model predictions. Further investigations in
real-world clinical settings will be conducted to evaluate its impact on
AI-assisted clinical workflows.

æè¦ï¼å¯è§£éäººå·¥æºæ§ (XAI) æ¯å°äººå·¥æºæ§ (AI) åæ©å¨å­¸ç¿ (ML) æ¼ç®æ³æ´åå°è¨åºå¯¦åä¸­çè¾¯è«æ ¸å¿ãé«å·è¡æè½ç AI/ML æ¨¡åï¼ä¾å¦æ´é«å­¸ç¿å¨åæ·±åº¦ç¥ç¶ç¶²è·¯ï¼éå¸¸ç¼ºä¹å¯è§£éæ§ï¼é»ç¤è¨åºé«çå°å¶é æ¸¬çä¿¡ä»»ãçºäºè§£æ±ºéååé¡ï¼æ­£å¨éç¼ XAI æè¡ï¼ä»¥äººé¡å¯ä»¥çè§£çè¡èªæè¿° AI/ML é æ¸¬ãä¸åæå¸æçæ¹åæ¯æ¡ç¨ææåº¦åæ (SA) åå¨çææåº¦åæ (GSA)ï¼å®åæ¬è³ªä¸æä¾ææ¨¡åè¼¸å¥å°é æ¸¬çå½±é¿ä¾å°å¶é²è¡æåãå¨æ­¤ï¼æåä»ç´¹ä¸ç¨®æ°ç delta-XAI æ¹æ³ï¼ééæ´å GSA ææ¨ delta ææ¸ä¾æä¾ ML æ¨¡åé æ¸¬çå±é¨è§£éãdelta-XAI ææ¸è©ä¼°æ¯åç¹å¾µå¼å°åæ­¸ååé¡åé¡ä¸­åå¥ä¾é çé æ¸¬è¼¸åºä¹å½±é¿ãæåå° delta-XAI ææ¸å½¢å¼åï¼ä¸¦æä¾å¶å¯¦ä½çç¨å¼ç¢¼ãä½¿ç¨ç·æ§åæ­¸æ¨¡åå°æ¨¡æ¬æå¢è©ä¼° delta-XAI æ¹æ³ï¼ä¸¦ä»¥ Shapley å¼ä½çºåºæºãçµæé¡¯ç¤º delta-XAI ææ¸éå¸¸è Shapley å¼ä¸è´ï¼ä½å¨å·æé«åº¦å½±é¿åææ¥µç«¯ç¹å¾µå¼çæ¨¡åä¸­å­å¨é¡¯èå·®ç°ãdelta-XAI ææ¸å¨åµæ¸¬ä¸»è¦ç¹å¾µåèçæ¥µç«¯ç¹å¾µå¼æ¹é¢è¡¨ç¾åºæ´é«çææåº¦ãå®æ§å°ä¾èªªï¼delta-XAI ééå©ç¨æ©çå¯åº¦å½æ¸æä¾ç´è§çè§£éï¼ä½¿ç¹å¾µæåæ´æ¸æ°ä¸å°å¾æ¥­äººå¡ä¾èªªæ´å·å¯è§£éæ§ãç¸½é«èè¨ï¼delta-XAI æ¹æ³å°æ¼ç©©å¥å°åå¾ ML æ¨¡åé æ¸¬çå±é¨è§£éä¼¼ä¹å¾æå¸æãå°å¨çå¯¦ä¸ççè¨åºç°å¢ä¸­é²è¡é²ä¸æ­¥èª¿æ¥ï¼ä»¥è©ä¼°å¶å° AI è¼å©è¨åºå·¥ä½æµç¨çå½±é¿ã

##### **Enhanced Deep Learning Methodologies and MRI Selection Techniques for Dementia Diagnosis in the Elderly Population**
2407.17324v2 by Nikolaos Ntampakis, Konstantinos Diamantaras, Ioanna Chouvarda, Vasileios Argyriou, Panagiotis Sarigianndis

Dementia, a debilitating neurological condition affecting millions worldwide,
presents significant diagnostic challenges. In this work, we introduce a novel
methodology for the classification of demented and non-demented elderly
patients using 3D brain Magnetic Resonance Imaging (MRI) scans. Our approach
features a unique technique for selectively processing MRI slices, focusing on
the most relevant brain regions and excluding less informative sections. This
methodology is complemented by a confidence-based classification committee
composed of three custom deep learning models: Dem3D ResNet, Dem3D CNN, and
Dem3D EfficientNet. These models work synergistically to enhance
decision-making accuracy, leveraging their collective strengths. Tested on the
Open Access Series of Imaging Studies(OASIS) dataset, our method achieved an
impressive accuracy of 94.12%, surpassing existing methodologies. Furthermore,
validation on the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset
confirmed the robustness and generalizability of our approach. The use of
explainable AI (XAI) techniques and comprehensive ablation studies further
substantiate the effectiveness of our techniques, providing insights into the
decision-making process and the importance of our methodology. This research
offers a significant advancement in dementia diagnosis, providing a highly
accurate and efficient tool for clinical applications.

æè¦ï¼å¤±æºçæ¯ä¸ç¨®å½±é¿å¨çæ¸ç¾è¬äººçè¡°å¼±æ§ç¥ç¶ç¾çï¼å¨è¨ºæ·ä¸å·æéå¤§ææ°ãå¨éé å·¥ä½ä¸­ï¼æåæåºäºä¸ç¨®æ°çæ¹æ³ï¼ç¨æ¼å°å¤±æºåéå¤±æºèå¹´æ£èé²è¡åé¡ï¼ä½¿ç¨ 3D å¤§è¦ç£æ¯é å½± (MRI) ææãæåçåæ³æ¡ç¨äºä¸ç¨®ç¨ç¹æè¡ï¼ç¨æ¼é¸ææ§èç MRI åçï¼éé»éæ³¨æç¸éçå¤§è¦ååï¼ä¸¦æé¤ä¿¡æ¯éè¼å°çé¨åãéç¨®æ¹æ³ç±ä¸ååºæ¼ä¿¡å¿çåé¡å§å¡æè£åï¼è©²å§å¡æç±ä¸åèªå®ç¾©æ·±åº¦å­¸ç¿æ¨¡åçµæï¼Dem3D ResNetãDem3D CNN å Dem3D EfficientNetãéäºæ¨¡åååå·¥ä½ä»¥å¢å¼·æ±ºç­çæºç¢ºæ§ï¼å©ç¨å®åçéé«åªå¢ãå¨å½±åç ç©¶éæ¾å­åç³»å (OASIS) è³æéä¸é²è¡æ¸¬è©¦ï¼æåçæ¨¡åéå°äº 94.12% çé©äººæºç¢ºåº¦ï¼è¶éäºç¾ææ¹æ³ãæ­¤å¤ï¼å¨é¿è²æµ·é»çç¥ç¶å½±åå¡è­° (ADNI) è³æéä¸çé©è­è­å¯¦äºæåæ¹æ³çç©©å¥æ§åæ®éæ§ãå¯è§£é AI (XAI) æè¡åå¨é¢çæ¶èç ç©¶é²ä¸æ­¥è­å¯¦äºæåæè¡çæææ§ï¼æä¾äºå°æ±ºç­éç¨åæåæ¹æ³éè¦æ§çè¦è§£ãéé ç ç©¶çºå¤±æºçè¨ºæ·æä¾äºéå¤§é²å±ï¼çºè¨åºæç¨æä¾äºä¸åé«åº¦æºç¢ºä¸é«æçå·¥å·ã

##### **Using Large Language Models to Compare Explainable Models for Smart Home Human Activity Recognition**
2408.06352v1 by Michele Fiori, Gabriele Civitarese, Claudio Bettini

Recognizing daily activities with unobtrusive sensors in smart environments
enables various healthcare applications. Monitoring how subjects perform
activities at home and their changes over time can reveal early symptoms of
health issues, such as cognitive decline. Most approaches in this field use
deep learning models, which are often seen as black boxes mapping sensor data
to activities. However, non-expert users like clinicians need to trust and
understand these models' outputs. Thus, eXplainable AI (XAI) methods for Human
Activity Recognition have emerged to provide intuitive natural language
explanations from these models. Different XAI methods generate different
explanations, and their effectiveness is typically evaluated through user
surveys, that are often challenging in terms of costs and fairness. This paper
proposes an automatic evaluation method using Large Language Models (LLMs) to
identify, in a pool of candidates, the best XAI approach for non-expert users.
Our preliminary results suggest that LLM evaluation aligns with user surveys.

æè¦ï¼èç±æºæ§ç°å¢ä¸­ä¸å¼äººæ³¨ç®çææ¸¬å¨è¾¨è­æ¥å¸¸æ´»åï¼è½åç¨åç¨®é«çä¿å¥æç¨ãç£æ§åè©¦èå¨å®¶ä¸­å¦ä½å·è¡æ´»åï¼ä»¥åå¶é¨èæéçè®åï¼å¯ä»¥æ­ç¤ºå¥åº·åé¡çæ©æççï¼ä¾å¦èªç¥è½åä¸éãæ­¤é åä¸­çå¤§å¤æ¸æ¹æ³é½ä½¿ç¨æ·±åº¦å­¸ç¿æ¨¡åï¼éäºæ¨¡åéå¸¸è¢«è¦çºå°ææ¸¬å¨è³æå°æè³æ´»åçé»çå­ãç¶èï¼éå°å®¶ä½¿ç¨èï¼ä¾å¦è¨åºé«å¸«ï¼éè¦ä¿¡ä»»ä¸¦äºè§£éäºæ¨¡åçè¼¸åºãå æ­¤ï¼äººé¡æ´»åè¾¨è­çå¯è§£é AI (XAI) æ¹æ³æéèçï¼ä»¥æä¾ä¾èªéäºæ¨¡åçç´è¦ºèªç¶èªè¨èªªæãä¸åç XAI æ¹æ³æç¢çä¸åçèªªæï¼èå¶æææ§éå¸¸ééä½¿ç¨èèª¿æ¥ä¾è©ä¼°ï¼éå¨ææ¬åå¬å¹³æ§æ¹é¢éå¸¸å·æææ°æ§ãæ¬ææåºä½¿ç¨å¤§åèªè¨æ¨¡å (LLM) çèªåè©ä¼°æ¹æ³ï¼ä»¥å¨åé¸èä¸­æ¾åºæé©åéå°å®¶ä½¿ç¨èç XAI æ¹æ³ãæåçåæ­¥çµæè¡¨æï¼LLM è©ä¼°èä½¿ç¨èèª¿æ¥ä¸è´ã

##### **Explainable AI-based Intrusion Detection System for Industry 5.0: An Overview of the Literature, associated Challenges, the existing Solutions, and Potential Research Directions**
2408.03335v1 by Naseem Khan, Kashif Ahmad, Aref Al Tamimi, Mohammed M. Alani, Amine Bermak, Issa Khalil

Industry 5.0, which focuses on human and Artificial Intelligence (AI)
collaboration for performing different tasks in manufacturing, involves a
higher number of robots, Internet of Things (IoTs) devices and
interconnections, Augmented/Virtual Reality (AR), and other smart devices. The
huge involvement of these devices and interconnection in various critical
areas, such as economy, health, education and defense systems, poses several
types of potential security flaws. AI itself has been proven a very effective
and powerful tool in different areas of cybersecurity, such as intrusion
detection, malware detection, and phishing detection, among others. Just as in
many application areas, cybersecurity professionals were reluctant to accept
black-box ML solutions for cybersecurity applications. This reluctance pushed
forward the adoption of eXplainable Artificial Intelligence (XAI) as a tool
that helps explain how decisions are made in ML-based systems. In this survey,
we present a comprehensive study of different XAI-based intrusion detection
systems for industry 5.0, and we also examine the impact of explainability and
interpretability on Cybersecurity practices through the lens of Adversarial
XIDS (Adv-XIDS) approaches. Furthermore, we analyze the possible opportunities
and challenges in XAI cybersecurity systems for industry 5.0 that elicit future
research toward XAI-based solutions to be adopted by high-stakes industry 5.0
applications. We believe this rigorous analysis will establish a foundational
framework for subsequent research endeavors within the specified domain.

æè¦ï¼å·¥æ¥­ 5.0 èéæ¼äººé¡èäººå·¥æºæ§ (AI) åä½å·è¡è£½é ä¸­çä¸åä»»åï¼æ¶åæ´å¤æ©å¨äººãç©è¯ç¶² (IoT) è£ç½®åäºé£ãæ´å¢/èæ¬å¯¦å¢ (AR) åå¶ä»æºæ§è£ç½®ãéäºè£ç½®åäºé£å¨ç¶æ¿ãé«çä¿å¥ãæè²ååé²ç³»çµ±ç­åç¨®ééµé åçå»£æ³åèï¼å¼ç¼äºå¤ç¨®é¡åçæ½å¨å®å¨æ¼æ´ãAI æ¬èº«å·²è¢«è­ææ¯ç¶²è·¯å®å¨ä¸åé åä¸­éå¸¸ææä¸å¼·å¤§çå·¥å·ï¼ä¾å¦å¥ä¾µåµæ¸¬ãæ¡æè»é«åµæ¸¬åç¶²è·¯é£é­åµæ¸¬ç­ãå°±åå¨è¨±å¤æç¨é åä¸æ¨£ï¼ç¶²è·¯å®å¨å°æ¥­äººå¡ä¸é¡ææ¥åé»ç ML è§£æ±ºæ¹æ¡ä¾æç¨æ¼ç¶²è·¯å®å¨ãéç¨®ä¸é¡æä¿ä½¿å¯è§£éäººå·¥æºæ§ (XAI) ä½çºä¸ç¨®å·¥å·è¢«æ¡ç¨ï¼æå©æ¼èªªæå¨åºæ¼ ML çç³»çµ±ä¸­å¦ä½ååºæ±ºç­ãå¨éé èª¿æ¥ä¸­ï¼æåå°å·¥æ¥­ 5.0 çä¸ååºæ¼ XAI çå¥ä¾µåµæ¸¬ç³»çµ±é²è¡äºå¨é¢çç ç©¶ï¼ä¸¦ä¸æåä¹ééå°æå¼ XIDS (Adv-XIDS) æ¹æ³çè§é»ä¾æ¢è¨å¯è§£éæ§åå¯è©®éæ§å°ç¶²è·¯å®å¨å¯¦åçå½±é¿ãæ­¤å¤ï¼æååæäºå·¥æ¥­ 5.0 ç XAI ç¶²è·¯å®å¨ç³»çµ±ä¸­å¯è½å­å¨çæ©æåææ°ï¼å¼ç¼äºæªä¾éå° XAI åºç¤è§£æ±ºæ¹æ¡çç ç©¶ï¼ä»¥ä¾é«é¢¨éªçå·¥æ¥­ 5.0 æç¨æ¡ç¨ãæåç¸ä¿¡éé å´è¬¹çåæå°çºæå®é åå§çå¾çºç ç©¶å·¥ä½å»ºç«åºç¤æ¶æ§ã

##### **A Comparative Study on Automatic Coding of Medical Letters with Explainability**
2407.13638v1 by Jamie Glen, Lifeng Han, Paul Rayson, Goran Nenadic

This study aims to explore the implementation of Natural Language Processing
(NLP) and machine learning (ML) techniques to automate the coding of medical
letters with visualised explainability and light-weighted local computer
settings. Currently in clinical settings, coding is a manual process that
involves assigning codes to each condition, procedure, and medication in a
patient's paperwork (e.g., 56265001 heart disease using SNOMED CT code). There
are preliminary research on automatic coding in this field using
state-of-the-art ML models; however, due to the complexity and size of the
models, the real-world deployment is not achieved. To further facilitate the
possibility of automatic coding practice, we explore some solutions in a local
computer setting; in addition, we explore the function of explainability for
transparency of AI models. We used the publicly available MIMIC-III database
and the HAN/HLAN network models for ICD code prediction purposes. We also
experimented with the mapping between ICD and SNOMED CT knowledge bases. In our
experiments, the models provided useful information for 97.98\% of codes. The
result of this investigation can shed some light on implementing automatic
clinical coding in practice, such as in hospital settings, on the local
computers used by clinicians , project page
\url{https://github.com/Glenj01/Medical-Coding}.

æè¦ï¼æ¬ç ç©¶æ¨å¨æ¢è¨å°èªç¶èªè¨èç (NLP) åæ©å¨å­¸ç¿ (ML) æè¡å¯¦ä½æ¼é«çä¿¡å½ç·¨ç¢¼èªååï¼ä¸¦å·åè¦è¦ºåèªªæè½ååè¼éåçæ¬å°é»è¦è¨­å®ãç®åå¨è¨åºç°å¢ä¸­ï¼ç·¨ç¢¼æ¯ä¸ç¨®æåæµç¨ï¼æ¶åçºçæ£æä»¶ä¸­çæ¯é ççãç¨åºåè¥ç©ææ´¾ä»£ç¢¼ (ä¾å¦ï¼ä½¿ç¨ SNOMED CT ä»£ç¢¼ 56265001 è¡¨ç¤ºå¿èç)ãæ­¤é åæä½¿ç¨ææ° ML æ¨¡åé²è¡èªåç·¨ç¢¼çåæ­¥ç ç©¶ï¼ç¶èï¼ç±æ¼æ¨¡åçè¤éæ§åå¤§å°ï¼ä¸¦æªå¯¦ç¾å¯¦éé¨ç½²ãçºäºé²ä¸æ­¥ä¿é²èªåç·¨ç¢¼å¯¦åçå¯è½æ§ï¼æåå¨æ¬å°é»è¦è¨­å®ä¸­æ¢è¨äºä¸äºè§£æ±ºæ¹æ¡ï¼æ­¤å¤ï¼æåæ¢è¨äºèªªæåè½å¨ AI æ¨¡åéæåº¦ä¸­çåè½ãæåä½¿ç¨å¬éç MIMIC-III è³æåº«å HAN/HLAN ç¶²è·¯æ¨¡åé²è¡ ICD ä»£ç¢¼é æ¸¬ãæåéè©¦é©äº ICD å SNOMED CT ç¥è­åº«ä¹éçå°æãå¨æåçå¯¦é©ä¸­ï¼éäºæ¨¡åæä¾äº 97.98% ä»£ç¢¼çæç¨è³è¨ãéé èª¿æ¥çµæå¯ä»¥çºå¯¦åä¸­çèªåè¨åºç·¨ç¢¼å¯¦ä½æä¾ä¸äºè¦è§£ï¼ä¾å¦å¨é«é¢ç°å¢ä¸­ï¼ç±è¨åºé«çä½¿ç¨çæ¬å°é»è¦ï¼å°æ¡é é¢ \url{https://github.com/Glenj01/Medical-Coding}ã

##### **Explainable AI for Enhancing Efficiency of DL-based Channel Estimation**
2407.07009v1 by Abdul Karim Gizzini, Yahia Medjahdi, Ali J. Ghandour, Laurent Clavier

The support of artificial intelligence (AI) based decision-making is a key
element in future 6G networks, where the concept of native AI will be
introduced. Moreover, AI is widely employed in different critical applications
such as autonomous driving and medical diagnosis. In such applications, using
AI as black-box models is risky and challenging. Hence, it is crucial to
understand and trust the decisions taken by these models. Tackling this issue
can be achieved by developing explainable AI (XAI) schemes that aim to explain
the logic behind the black-box model behavior, and thus, ensure its efficient
and safe deployment. Recently, we proposed a novel perturbation-based XAI-CHEST
framework that is oriented toward channel estimation in wireless
communications. The core idea of the XAI-CHEST framework is to identify the
relevant model inputs by inducing high noise on the irrelevant ones. This
manuscript provides the detailed theoretical foundations of the XAI-CHEST
framework. In particular, we derive the analytical expressions of the XAI-CHEST
loss functions and the noise threshold fine-tuning optimization problem. Hence
the designed XAI-CHEST delivers a smart input feature selection methodology
that can further improve the overall performance while optimizing the
architecture of the employed model. Simulation results show that the XAI-CHEST
framework provides valid interpretations, where it offers an improved bit error
rate performance while reducing the required computational complexity in
comparison to the classical DL-based channel estimation.

æè¦ï¼äººå·¥æºè½ (AI) æ¯æçæ±ºç­å¶å®æ¯æªä¾ 6G ç¶²è·¯ä¸­çééµåç´ ï¼å¶ä¸­å°å¼å¥åç AI çæ¦å¿µãæ­¤å¤ï¼AI å»£æ³ç¨æ¼ä¸åçééµæç¨ä¸­ï¼ä¾å¦èªåé§é§åé«çè¨ºæ·ãå¨éäºæç¨ä¸­ï¼ä½¿ç¨ AI ä½çºé»çæ¨¡åæ¯æé¢¨éªä¸å·æææ°æ§çãå æ­¤ï¼çè§£åä¿¡ä»»éäºæ¨¡åååºçæ±ºç­è³ééè¦ãè§£æ±ºæ­¤åé¡çæ¹æ³æ¯éç¼å¯è§£é AI (XAI) æ¶æ§ï¼æ¨å¨è§£éé»çæ¨¡åè¡çºèå¾çéè¼¯ï¼å¾èç¢ºä¿å¶ææä¸å®å¨çé¨ç½²ãæè¿ï¼æåæåºäºä¸åæ°çåºæ¼æ¾åç XAI-CHEST æ¡æ¶ï¼è©²æ¡æ¶é¢åç¡ç·éä¿¡ä¸­çä¿¡éä¼°è¨ãXAI-CHEST æ¡æ¶çæ ¸å¿ææ³æ¯ééå¨ç¡éè¼¸å¥ä¸å¼å¥é«åªè²ä¾è­å¥ç¸éæ¨¡åè¼¸å¥ãéä»½æç¨¿æä¾äº XAI-CHEST æ¡æ¶çè©³ç´°çè«åºç¤ãç¹å¥æ¯ï¼æåæ¨å°äº XAI-CHEST æå¤±å½æ¸ååªè²é¾å¼å¾®èª¿åªååé¡çè§£æè¡¨éå¼ãå æ­¤ï¼è¨­è¨ç XAI-CHEST æä¾äºä¸ç¨®æºè½è¼¸å¥ç¹å¾µé¸ææ¹æ³ï¼å¯ä»¥å¨åªåæç¨æ¨¡åçæ¶æ§çåæé²ä¸æ­¥æé«æ´é«æ§è½ãæ¨¡æ¬çµæè¡¨æï¼XAI-CHEST æ¡æ¶æä¾äºææçè§£éï¼å¨éä½æéçè¨ç®è¤éåº¦çåæï¼æä¾äºæ¹é²çæ¯ç¹é¯èª¤çæ§è½ï¼èéèåºæ¼å³çµ± DL çä¿¡éä¼°è¨ç¸æ¯ã

##### **Explainable AI: Comparative Analysis of Normal and Dilated ResNet Models for Fundus Disease Classification**
2407.05440v2 by P. N. Karthikayan, Yoga Sri Varshan V, Hitesh Gupta Kattamuri, Umarani Jayaraman

This paper presents dilated Residual Network (ResNet) models for disease
classification from retinal fundus images. Dilated convolution filters are used
to replace normal convolution filters in the higher layers of the ResNet model
(dilated ResNet) in order to improve the receptive field compared to the normal
ResNet model for disease classification. This study introduces
computer-assisted diagnostic tools that employ deep learning, enhanced with
explainable AI techniques. These techniques aim to make the tool's
decision-making process transparent, thereby enabling medical professionals to
understand and trust the AI's diagnostic decision. They are particularly
relevant in today's healthcare landscape, where there is a growing demand for
transparency in AI applications to ensure their reliability and ethical use.
The dilated ResNet is used as a replacement for the normal ResNet to enhance
the classification accuracy of retinal eye diseases and reduce the required
computing time. The dataset used in this work is the Ocular Disease Intelligent
Recognition (ODIR) dataset which is a structured ophthalmic database with eight
classes covering most of the common retinal eye diseases. The evaluation
metrics used in this work include precision, recall, accuracy, and F1 score. In
this work, a comparative study has been made between normal ResNet models and
dilated ResNet models on five variants namely ResNet-18, ResNet-34, ResNet-50,
ResNet-101, and ResNet-152. The dilated ResNet model shows promising results as
compared to normal ResNet with an average F1 score of 0.71, 0.70, 0.69, 0.67,
and 0.70 respectively for the above respective variants in ODIR multiclass
disease classification.

æè¦ï¼è¿ç¯è®ºææåºäºç¨äºä»è§ç½èç¼åºå¾åè¿è¡ç¾çåç±»çæ©å¼ æ®å·®ç½ç» (ResNet) æ¨¡åãæ©å¼ å·ç§¯æ»¤æ³¢å¨ç¨äºæ¿æ¢ ResNet æ¨¡åè¾é«å±ä¸­çæ­£å¸¸å·ç§¯æ»¤æ³¢å¨ï¼æ©å¼  ResNetï¼ï¼ä»¥æ¹åæç¥åºï¼ä»èéå¯¹ç¾çåç±»å¯¹æ­£å¸¸ ResNet æ¨¡åè¿è¡æ¹è¿ãæ¬ç ç©¶å¼å¥äºéç¨æ·±åº¦å­¦ä¹ çè®¡ç®æºè¾å©è¯æ­å·¥å·ï¼å¹¶éè¿å¯è§£éç AI ææ¯è¿è¡äºå¢å¼ºãè¿äºææ¯æ¨å¨ä½¿è¯¥å·¥å·çå³ç­è¿ç¨éæåï¼ä»èä½¿å»å­¦ä¸ä¸äººå£«è½å¤çè§£åä¿¡ä»» AI çè¯æ­å³ç­ãå®ä»¬ä¸å½ä»çå»çä¿å¥é¢åå°¤ä¸ºç¸å³ï¼å¨è¯¥é¢åï¼å¯¹ AI åºç¨çéæåº¦éæ±ä¸æ­å¢é¿ï¼ä»¥ç¡®ä¿å¶å¯é æ§ååä¹éå¾·çä½¿ç¨ãæ©å¼  ResNet ç¨ä½æ­£å¸¸ ResNet çæ¿ä»£åï¼ä»¥æé«è§ç½èç¼é¨ç¾ççåç±»åç¡®æ§å¹¶åå°æéçè®¡ç®æ¶é´ãæ¬å·¥ä½ä¸­ä½¿ç¨çæ°æ®éæ¯ç¼ç§ç¾çæºè½è¯å« (ODIR) æ°æ®éï¼è¿æ¯ä¸ä¸ªç»æåçç¼ç§æ°æ®åºï¼åå«å«ç±»æ¶µçå¤§å¤æ°å¸¸è§è§ç½èç¼é¨ç¾çãæ¬å·¥ä½ä¸­ä½¿ç¨çè¯ä¼°ææ åæ¬ç²¾ç¡®åº¦ãå¬åçãåç¡®åº¦å F1 å¾åãå¨è¿é¡¹å·¥ä½ä¸­ï¼å¯¹ ResNet-18ãResNet-34ãResNet-50ãResNet-101 å ResNet-152 äºä¸ªåä½çæ­£å¸¸ ResNet æ¨¡ååæ©å¼  ResNet æ¨¡åè¿è¡äºæ¯è¾ç ç©¶ãä¸æ­£å¸¸ ResNet ç¸æ¯ï¼æ©å¼  ResNet æ¨¡åæ¾ç¤ºåºæå¸æçç»æï¼å¨ ODIR å¤ç±»ç¾çåç±»ä¸­ï¼ä¸è¿°åä¸ªåä½çå¹³å F1 å¾åä¸º 0.71ã0.70ã0.69ã0.67 å 0.70ã

##### **A Survey on Trustworthiness in Foundation Models for Medical Image Analysis**
2407.15851v2 by Congzhen Shi, Ryan Rezai, Jiaxi Yang, Qi Dou, Xiaoxiao Li

The rapid advancement of foundation models in medical imaging represents a
significant leap toward enhancing diagnostic accuracy and personalized
treatment. However, the deployment of foundation models in healthcare
necessitates a rigorous examination of their trustworthiness, encompassing
privacy, robustness, reliability, explainability, and fairness. The current
body of survey literature on foundation models in medical imaging reveals
considerable gaps, particularly in the area of trustworthiness. Additionally,
existing surveys on the trustworthiness of foundation models do not adequately
address their specific variations and applications within the medical imaging
domain. This survey aims to fill that gap by presenting a novel taxonomy of
foundation models used in medical imaging and analyzing the key motivations for
ensuring their trustworthiness. We review current research on foundation models
in major medical imaging applications, focusing on segmentation, medical report
generation, medical question and answering (Q\&A), and disease diagnosis. These
areas are highlighted because they have seen a relatively mature and
substantial number of foundation models compared to other applications. We
focus on literature that discusses trustworthiness in medical image analysis
manuscripts. We explore the complex challenges of building trustworthy
foundation models for each application, summarizing current concerns and
strategies for enhancing trustworthiness. Furthermore, we examine the potential
of these models to revolutionize patient care. Our analysis underscores the
imperative for advancing towards trustworthy AI in medical image analysis,
advocating for a balanced approach that fosters innovation while ensuring
ethical and equitable healthcare delivery.

æè¦ï¼åºç¤æ¨¡åå¨é«å­¸å½±åæ¹é¢çå¿«éé²å±ï¼ä»£è¡¨èå¨å å¼·è¨ºæ·æºç¢ºæ§ååäººåæ²»çæ¹é¢éåºä¸å¤§æ­¥ãç¶èï¼åºç¤æ¨¡åå¨é«çä¿å¥ä¸­çé¨ç½²éè¦å°å¶å¯ä¿¡åº¦é²è¡å´æ ¼çå¯©æ¥ï¼åæ¬é±ç§ãç©©å¥æ§ãå¯é æ§ãå¯è§£éæ§åå¬å¹³æ§ãç®åéæ¼é«å­¸å½±åä¸­åºç¤æ¨¡åçèª¿æ¥æç»ä¸­é¡¯ç¤ºåºç¸ç¶å¤§çå·®è·ï¼ç¹å¥æ¯å¨å¯ä¿¡åº¦æ¹é¢ãæ­¤å¤ï¼ç¾æéæ¼åºç¤æ¨¡åå¯ä¿¡åº¦çèª¿æ¥ä¸¦æªååè§£æ±ºå¶å¨é«å­¸å½±åé åä¸­çç¹å®è®ååæç¨ãæ¬èª¿æ¥æ¨å¨ééæåºé«å­¸å½±åä¸­ä½¿ç¨çåºç¤æ¨¡åçæ°åé¡æ³ä¸¦åæç¢ºä¿å¶å¯ä¿¡åº¦çééµåæ©ï¼ä¾å¡«è£éä¸ç©ºç½ãæååé¡§äºåºç¤æ¨¡åå¨ä¸»è¦é«å­¸å½±åæç¨ä¸­çç¶åç ç©¶ï¼éé»éæ³¨åå²ãé«çå ±åçæãé«çåé¡ååç­ (Q&A) ä»¥åç¾çè¨ºæ·ãéäºé åä¹æä»¥è¢«å¼·èª¿ï¼æ¯å çºèå¶ä»æç¨ç¸æ¯ï¼å®åå·²ç¶çå°ç¸å°æçä¸å¤§éçåºç¤æ¨¡åãæåå°æ³¨æ¼æ¢è¨é«å­¸å½±ååææç¨¿ä¸­å¯ä¿¡åº¦çæç»ãæåæ¢è¨äºçºæ¯åæç¨æ§å»ºå¯ä¿¡åºç¤æ¨¡åçè¤éææ°ï¼ç¸½çµäºç¶åéæ³¨é»åå¢å¼·å¯ä¿¡åº¦çç­ç¥ãæ­¤å¤ï¼æåæ¢è¨äºéäºæ¨¡åå¨é©æ°æ£èè­·çæ¹é¢çæ½åãæåçåæå¼·èª¿äºå¨é«å­¸å½±ååæä¸­æèå¯ä¿¡è³´çäººå·¥æºæ§éé²çå¿è¦æ§ï¼ä¸¦å¡å°ä¸ç¨®å¹³è¡¡çæ¹æ³ï¼æ¢è½ä¿é²åµæ°ï¼åè½ç¢ºä¿éå¾·åå¬å¹³çé«çä¿å¥æåã

##### **The Impact of an XAI-Augmented Approach on Binary Classification with Scarce Data**
2407.06206v1 by Ximing Wen, Rosina O. Weber, Anik Sen, Darryl Hannan, Steven C. Nesbit, Vincent Chan, Alberto Goffi, Michael Morris, John C. Hunninghake, Nicholas E. Villalobos, Edward Kim, Christopher J. MacLellan

Point-of-Care Ultrasound (POCUS) is the practice of clinicians conducting and
interpreting ultrasound scans right at the patient's bedside. However, the
expertise needed to interpret these images is considerable and may not always
be present in emergency situations. This reality makes algorithms such as
machine learning classifiers extremely valuable to augment human decisions.
POCUS devices are becoming available at a reasonable cost in the size of a
mobile phone. The challenge of turning POCUS devices into life-saving tools is
that interpretation of ultrasound images requires specialist training and
experience. Unfortunately, the difficulty to obtain positive training images
represents an important obstacle to building efficient and accurate
classifiers. Hence, the problem we try to investigate is how to explore
strategies to increase accuracy of classifiers trained with scarce data. We
hypothesize that training with a few data instances may not suffice for
classifiers to generalize causing them to overfit. Our approach uses an
Explainable AI-Augmented approach to help the algorithm learn more from less
and potentially help the classifier better generalize.

æè¦ï¼åºéè¶é³æ³¢ (POCUS) æ¯è¨åºé«å¸«å¨æ£èåºéé²è¡åè§£è®è¶é³æ³¢ææçå¯¦åãç¶èï¼è§£è®éäºå½±åæéçå°æ¥­ç¥è­ç¸ç¶å¯è§ï¼èä¸å¨ç·æ¥ææ³ä¸å¯è½ä¸¦éé¨æå·åãéç¨®ç¾å¯¦ææ³ä½¿å¾æ©å¨å­¸ç¿åé¡å¨ç­æ¼ç®æ³å°æ¼å å¼·äººé¡æ±ºç­è®å¾æ¥µçºæå¹å¼ãPOCUS è£ç½®æ­£ä»¥åçææ¬æ¨åºï¼å°ºå¯¸çºææ©å¤§å°ãå° POCUS è£ç½®è½è®çºæçå·¥å·çææ°å¨æ¼ï¼è§£è®è¶é³æ³¢å½±åéè¦å°éè¨ç·´åç¶é©ãä¸å¹¸çæ¯ï¼åå¾æ­£åè¨ç·´å½±åçå°é£åº¦ä»£è¡¨èå»ºç½®ææçä¸æºç¢ºçåé¡å¨çä¸å¤§éç¤ãå æ­¤ï¼æååè©¦æ¢è¨çåé¡æ¯å¦ä½æ¢ç´¢ç­ç¥ï¼ä»¥æé«ä½¿ç¨ç¨çè³æè¨ç·´çåé¡å¨çæºç¢ºåº¦ãæååè¨­ä½¿ç¨å°æ¸è³æå¯¦ä¾é²è¡è¨ç·´å¯è½ä¸è¶³ä»¥è®åé¡å¨æ¦æ¬ï¼å°è´å®åéåº¦æ¬åãæåçåæ³ä½¿ç¨å¯è§£é AI å¢å¼·æ¹æ³ï¼ä»¥åå©æ¼ç®æ³å¾è¼å°çè³æä¸­å­¸ç¿æ´å¤ï¼ä¸¦æ½å¨åå©åé¡å¨æ´å¥½å°æ¦æ¬ã

##### **Can GPT-4 Help Detect Quit Vaping Intentions? An Exploration of Automatic Data Annotation Approach**
2407.00167v1 by Sai Krishna Revanth Vuruma, Dezhi Wu, Saborny Sen Gupta, Lucas Aust, Valerie Lookingbill, Wyatt Bellamy, Yang Ren, Erin Kasson, Li-Shiun Chen, Patricia Cavazos-Rehg, Dian Hu, Ming Huang

In recent years, the United States has witnessed a significant surge in the
popularity of vaping or e-cigarette use, leading to a notable rise in cases of
e-cigarette and vaping use-associated lung injury (EVALI) that caused
hospitalizations and fatalities during the EVALI outbreak in 2019, highlighting
the urgency to comprehend vaping behaviors and develop effective strategies for
cessation. Due to the ubiquity of social media platforms, over 4.7 billion
users worldwide use them for connectivity, communications, news, and
entertainment with a significant portion of the discourse related to health,
thereby establishing social media data as an invaluable organic data resource
for public health research. In this study, we extracted a sample dataset from
one vaping sub-community on Reddit to analyze users' quit-vaping intentions.
Leveraging OpenAI's latest large language model GPT-4 for sentence-level quit
vaping intention detection, this study compares the outcomes of this model
against layman and clinical expert annotations. Using different prompting
strategies such as zero-shot, one-shot, few-shot and chain-of-thought
prompting, we developed 8 prompts with varying levels of detail to explain the
task to GPT-4 and also evaluated the performance of the strategies against each
other. These preliminary findings emphasize the potential of GPT-4 in social
media data analysis, especially in identifying users' subtle intentions that
may elude human detection.

æè¦ï¼è¿å¹´ä¾ï¼ç¾åè¦è­äºé»å­çæé»å­é¦è¸ä½¿ç¨çå¤§å¹æ¿å¢ï¼å°è´é»å­çåé»å­çä½¿ç¨ç¸éèºæå· (EVALI) çä¾é¡¯èå¢å ï¼å¨ 2019 å¹´ EVALI çç¼æéé æä½é¢åæ­»äº¡ï¼å¸é¡¯äºçè§£é»å­çè¡çºåå¶å®æææè¸ç­ç¥çè¿«åæ§ãç±æ¼ç¤¾ç¾¤åªé«å¹³å°çæ®åï¼å¨çè¶é 47 åä½¿ç¨èä½¿ç¨å®åé²è¡é£çµãæºéãæ°èåå¨æ¨ï¼å¶ä¸­å¾å¤§ä¸é¨åèå¥åº·ç¸éï¼å æ­¤å°ç¤¾ç¾¤åªé«è³æå»ºç«çºå¬å±è¡çç ç©¶ä¸­ç¡å¹çææ©è³æè³æºãå¨æ¬ç ç©¶ä¸­ï¼æåå¾ Reddit ä¸ä¸åé»å­çå­ç¤¾ç¾¤ä¸­æåä¸åç¯ä¾è³æéï¼ä»¥åæä½¿ç¨èçæé»å­çæåãå©ç¨ OpenAI ææ°çå¤§åèªè¨æ¨¡å GPT-4 é²è¡å¥å­å±¤ç´çæé»å­çæååµæ¸¬ï¼æ¬ç ç©¶æ¯è¼äºæ­¤æ¨¡åççµæèå¤è¡äººåè¨åºå°å®¶è¨»è§£ãä½¿ç¨ä¸åçæç¤ºç­ç¥ï¼ä¾å¦é¶æ¬¡å­¸ç¿ãä¸æ¬¡å­¸ç¿ãå°æ¬¡å­¸ç¿åæèéæç¤ºï¼æåéç¼äº 8 åæç¤ºï¼è©³ç´°ç¨åº¦ä¸åï¼å GPT-4 è§£éä»»åï¼ä¸¦è©ä¼°éäºç­ç¥å½¼æ­¤ä¹éçæè½ãéäºåæ­¥ç¼ç¾å¼·èª¿äº GPT-4 å¨ç¤¾ç¾¤åªé«è³æåæä¸­çæ½åï¼ç¹å¥æ¯å¨è­å¥äººé¡åµæ¸¬å¯è½ç¡æ³å¯è¦ºçä½¿ç¨èå¾®å¦æåæ¹é¢ã

##### **Towards Compositional Interpretability for XAI**
2406.17583v1 by Sean Tull, Robin Lorenz, Stephen Clark, Ilyas Khan, Bob Coecke

Artificial intelligence (AI) is currently based largely on black-box machine
learning models which lack interpretability. The field of eXplainable AI (XAI)
strives to address this major concern, being critical in high-stakes areas such
as the finance, legal and health sectors.
  We present an approach to defining AI models and their interpretability based
on category theory. For this we employ the notion of a compositional model,
which sees a model in terms of formal string diagrams which capture its
abstract structure together with its concrete implementation. This
comprehensive view incorporates deterministic, probabilistic and quantum
models. We compare a wide range of AI models as compositional models, including
linear and rule-based models, (recurrent) neural networks, transformers, VAEs,
and causal and DisCoCirc models.
  Next we give a definition of interpretation of a model in terms of its
compositional structure, demonstrating how to analyse the interpretability of a
model, and using this to clarify common themes in XAI. We find that what makes
the standard 'intrinsically interpretable' models so transparent is brought out
most clearly diagrammatically. This leads us to the more general notion of
compositionally-interpretable (CI) models, which additionally include, for
instance, causal, conceptual space, and DisCoCirc models.
  We next demonstrate the explainability benefits of CI models. Firstly, their
compositional structure may allow the computation of other quantities of
interest, and may facilitate inference from the model to the modelled
phenomenon by matching its structure. Secondly, they allow for diagrammatic
explanations for their behaviour, based on influence constraints, diagram
surgery and rewrite explanations. Finally, we discuss many future directions
for the approach, raising the question of how to learn such meaningfully
structured models in practice.

æè¦ï¼<paragraph>äººå·¥æºæ§ï¼AIï¼ç®åå¨å¾å¤§ç¨åº¦ä¸ä¾è³´æ¼ç¼ºä¹å¯è§£éæ§çé»çæ©å¨å­¸ç¿æ¨¡åãå¯è§£éæ§äººå·¥æºæ§ï¼XAIï¼é åè´åæ¼è§£æ±ºéåä¸»è¦åé¡ï¼éå¨éèãæ³å¾åå¥åº·ç­é«é¢¨éªé åè³ééè¦ã
æåæåºäºä¸ç¨®åºæ¼ç¯çè«å®ç¾© AI æ¨¡ååå¶å¯è§£éæ§çæ¹æ³ãçºæ­¤ï¼æåæ¡ç¨çµåæ¨¡åçæ¦å¿µï¼å®ä»¥å½¢å¼å¼¦åçå½¢å¼çå¾æ¨¡åï¼éäºå¼¦åæç²äºæ¨¡åçæ½è±¡çµæ§åå¶å·é«å¯¦ç¾ãéç¨®ç¶åè§é»åå«äºç¢ºå®æ§ãæ¦çæ§åéå­æ¨¡åãæåå°åç¨® AI æ¨¡åä½çºçµåæ¨¡åé²è¡æ¯è¼ï¼åæ¬ç·æ§ååºæ¼è¦åçæ¨¡åãï¼éè¿´ï¼ç¥ç¶ç¶²è·¯ãTransformerãVAEï¼ä»¥åå æå DisCoCirc æ¨¡åã
æ¥ä¸ä¾ï¼æåæ ¹ææ¨¡åççµåçµæ§çµ¦åºæ¨¡åè§£éçå®ç¾©ï¼å±ç¤ºå¦ä½åææ¨¡åçå¯è§£éæ§ï¼ä¸¦ä½¿ç¨å®ä¾æ¾æ¸ XAI ä¸­çå¸¸è¦ä¸»é¡ãæåç¼ç¾ï¼è®æ¨æºçãå§å¨å¯è§£éãæ¨¡åå¦æ­¤éæçåå å¨åè¡¨ä¸­è¡¨ç¾å¾æçºæ¸æ¥ãéå¼å°æåå¾åºæ´ä¸è¬ççµåå¯è§£éï¼CIï¼æ¨¡åæ¦å¿µï¼å®å¦å¤éåæ¬å æãæ¦å¿µç©ºéå DisCoCirc æ¨¡åã
æ¥ä¸ä¾ï¼æåå±ç¤ºäº CI æ¨¡åçå¯è§£éæ§åªå¢ãé¦åï¼å®åççµåçµæ§åè¨±è¨ç®å¶ä»æèè¶£çéï¼ä¸¦å¯è½ééå¹éæ¨¡åççµæ§ä¾ä¿é²å¾æ¨¡åå°è¢«å»ºæ¨¡ç¾è±¡çæ¨çãå¶æ¬¡ï¼å®ååè¨±å°å¶è¡çºé²è¡åè§£èªªæï¼éäºèªªæåºæ¼å½±é¿ç´æãåè§£æè¡åéå¯«èªªæãæå¾ï¼æåè¨è«äºéç¨®æ¹æ³çè¨±å¤æªä¾æ¹åï¼æåºäºå¦ä½å¨å¯¦è¸ä¸­å­¸ç¿éç¨®ææç¾©ççµæ§åæ¨¡åçåé¡ã</paragraph>

##### **Slicing Through Bias: Explaining Performance Gaps in Medical Image Analysis using Slice Discovery Methods**
2406.12142v2 by Vincent Olesen, Nina Weng, Aasa Feragen, Eike Petersen

Machine learning models have achieved high overall accuracy in medical image
analysis. However, performance disparities on specific patient groups pose
challenges to their clinical utility, safety, and fairness. This can affect
known patient groups - such as those based on sex, age, or disease subtype - as
well as previously unknown and unlabeled groups. Furthermore, the root cause of
such observed performance disparities is often challenging to uncover,
hindering mitigation efforts. In this paper, to address these issues, we
leverage Slice Discovery Methods (SDMs) to identify interpretable
underperforming subsets of data and formulate hypotheses regarding the cause of
observed performance disparities. We introduce a novel SDM and apply it in a
case study on the classification of pneumothorax and atelectasis from chest
x-rays. Our study demonstrates the effectiveness of SDMs in hypothesis
formulation and yields an explanation of previously observed but unexplained
performance disparities between male and female patients in widely used chest
X-ray datasets and models. Our findings indicate shortcut learning in both
classification tasks, through the presence of chest drains and ECG wires,
respectively. Sex-based differences in the prevalence of these shortcut
features appear to cause the observed classification performance gap,
representing a previously underappreciated interaction between shortcut
learning and model fairness analyses.

æè¦ï¼æ©å¨å­¸ç¿æ¨¡åå¨é«å­¸å½±ååæä¸­å·²éå°æ´é«é«æºç¢ºåº¦ãç¶èï¼ç¹å®æ£èç¾¤é«çæè½å·®ç°å°å¶è¨åºæç¨ãå®å¨æ§èå¬å¹³æ§æ§æææ°ãéå¯è½æå½±é¿å·²ç¥çæ£èç¾¤é«ï¼ä¾å¦åºæ¼æ§å¥ãå¹´é½¡æç¾çäºåï¼ä»¥åååæªç¥ä¸æªæ¨ç±¤çç¾¤é«ãæ­¤å¤ï¼æ­¤é¡è§å¯å°çæè½å·®ç°çæ ¹æ¬åå éå¸¸é£ä»¥ç¼ç¾ï¼é»ç¤äºç·©è§£æªæ½ãå¨æ¬æä¸­ï¼çºäºè§£æ±ºéäºåé¡ï¼æåå©ç¨åçç¼ç¾æ¹æ³ (SDM) ä¾è­å¥å¯è§£éçè³ææè½ä¸ä½³å­éï¼ä¸¦éå°è§å¯å°çæè½å·®ç°åå å¶å®åè¨­ãæåå¼å¥ä¸ç¨®æ°ç SDMï¼ä¸¦å¨è¸é¨ X åçä¸­èºçåèºä¸å¼µåé¡çæ¡ä¾ç ç©¶ä¸­æç¨å®ãæåçç ç©¶è­æäº SDM å¨åè¨­å¶å®ä¸­çæææ§ï¼ä¸¦å°å»£æ³ä½¿ç¨çè¸é¨ X åçè³æéåæ¨¡åä¸­ååè§å¯å°ä½ç¡æ³è§£éçç·æ§åå¥³æ§æ£èä¹éçæè½å·®ç°æä¾äºè§£éãæåçç¼ç¾è¡¨æï¼å¨åé¡ä»»åä¸­ï¼ééè¸èå¼æµç®¡åå¿é»åå°ç·çå­å¨ï¼å­å¨æ·å¾å­¸ç¿ãéäºæ·å¾ç¹å¾µççè¡çå­å¨åºæ¼æ§å¥çå·®ç°ï¼ä¼¼ä¹æå°è´è§å¯å°çåé¡æè½å·®è·ï¼éä»£è¡¨æ·å¾å­¸ç¿åæ¨¡åå¬å¹³æ§åæä¹éååæªåå°éè¦çäº¤äºä½ç¨ã

##### **Unlocking the Potential of Metaverse in Innovative and Immersive Digital Health**
2406.07114v2 by Fatemeh Ebrahimzadeh, Ramin Safa

The concept of Metaverse has attracted a lot of attention in various fields
and one of its important applications is health and treatment. The Metaverse
has enormous potential to transform healthcare by changing patient care,
medical education, and the way teaching/learning and research are done. The
purpose of this research is to provide an introduction to the basic concepts
and fundamental technologies of the Metaverse. This paper examines the pros and
cons of the Metaverse in healthcare context and analyzes its potential from the
technology and AI perspective. In particular, the role of machine learning
methods is discussed; We will explain how machine learning algorithms can be
applied to the Metaverse generated data to gain better insights in healthcare
applications. Additionally, we examine the future visions of the Metaverse in
health delivery, by examining emerging technologies such as blockchain and also
addressing privacy concerns. The findings of this study contribute to a deeper
understanding of the applications of Metaverse in healthcare and its potential
to revolutionize the delivery of medical services.

æè¦ï¼åå®å®çæ¦å¿µå¨ååé åé½ååéæ³¨ï¼å¶éè¦æç¨ä¹ä¸ä¾¿æ¯é«çä¿å¥ãåå®å®æå·¨å¤§çæ½åééæ¹è®çæ£ç§è­·ãé«å­¸æè²ï¼ä»¥åæå­¸/å­¸ç¿åç ç©¶çæ¹å¼ä¾è½åé«çä¿å¥ãæ¬ç ç©¶çç®çæ¯æä¾åå®å®åºæ¬æ¦å¿µååºç¤æè¡çä»ç´¹ãæ¬ææ¢è¨äºåå®å®å¨é«çä¿å¥èæ¯ä¸çåªç¼ºé»ï¼ä¸¦å¾æè¡å AI çè§åº¦åæå¶æ½åãç¹å¥æ¯ï¼è¨è«äºæ©å¨å­¸ç¿æ¹æ³çè§è²ï¼æåå°èªªæå¦ä½å°æ©å¨å­¸ç¿æ¼ç®æ³æç¨æ¼åå®å®ç¢ççè³æï¼ä»¥ç²å¾é«çä¿å¥æç¨æ¹é¢çæ´ä½³è¦è§£ãæ­¤å¤ï¼æåééæ¢è¨åå¡éç­æ°èæè¡ï¼ä¸¦è§£æ±ºé±ç§åé¡ï¼ä¾æ¢è¨åå®å®å¨é«çä¿å¥æ¹é¢çæªä¾é¡æ¯ãæ¬ç ç©¶çç¼ç¾æå©æ¼æ´æ·±å¥å°äºè§£åå®å®å¨é«çä¿å¥ä¸­çæç¨ï¼ä»¥åå¶å¨é«çæåæä¾æ¹é¢ç¼æ®é©å½æ§è®é©çæ½åã

##### **AI-Driven Predictive Analytics Approach for Early Prognosis of Chronic Kidney Disease Using Ensemble Learning and Explainable AI**
2406.06728v1 by K M Tawsik Jawad, Anusha Verma, Fathi Amsaad

Chronic Kidney Disease (CKD) is one of the widespread Chronic diseases with
no known ultimo cure and high morbidity. Research demonstrates that progressive
Chronic Kidney Disease (CKD) is a heterogeneous disorder that significantly
impacts kidney structure and functions, eventually leading to kidney failure.
With the progression of time, chronic kidney disease has moved from a
life-threatening disease affecting few people to a common disorder of varying
severity. The goal of this research is to visualize dominating features,
feature scores, and values exhibited for early prognosis and detection of CKD
using ensemble learning and explainable AI. For that, an AI-driven predictive
analytics approach is proposed to aid clinical practitioners in prescribing
lifestyle modifications for individual patients to reduce the rate of
progression of this disease. Our dataset is collected on body vitals from
individuals with CKD and healthy subjects to develop our proposed AI-driven
solution accurately. In this regard, blood and urine test results are provided,
and ensemble tree-based machine-learning models are applied to predict unseen
cases of CKD. Our research findings are validated after lengthy consultations
with nephrologists. Our experiments and interpretation results are compared
with existing explainable AI applications in various healthcare domains,
including CKD. The comparison shows that our developed AI models, particularly
the Random Forest model, have identified more features as significant
contributors than XgBoost. Interpretability (I), which measures the ratio of
important to masked features, indicates that our XgBoost model achieved a
higher score, specifically a Fidelity of 98\%, in this metric and naturally in
the FII index compared to competing models.

æè¦ï¼æ¢æ§èèçï¼CKDï¼æ¯ä¸ç¨®å»£æ³çæ¢æ§ç¾çï¼æ²æå·²ç¥çæçµçæ³ä¸ç¼ççå¾é«ãç ç©¶è¡¨æï¼é²è¡æ§æ¢æ§èèçï¼CKDï¼æ¯ä¸ç¨®ç°è³ªæ§ç¾çï¼æé¡¯èå½±é¿èèçµæ§ååè½ï¼æçµå°è´èè¡°ç«­ãé¨èæéçæ¨ç§»ï¼æ¢æ§èèçå·²å¾å½±é¿å°æ¸äººçè´å½ç¾çè½è®çºä¸ç¨®å´éç¨åº¦ä¸åçå¸¸è¦ç¾çãæ¬ç ç©¶çç®æ¨æ¯ä½¿ç¨éæå­¸ç¿åå¯è§£éç AI é²è¡æ©æé å¾å CKD æª¢æ¸¬ï¼ä¸¦è¦è¦ºåä¸»å°ç¹å¾µãç¹å¾µåæ¸åè¡¨ç¾åºçå¼ãçºæ­¤ï¼æåºäºä¸ç¨® AI é©åçé æ¸¬åææ¹æ³ï¼ä»¥å¹«å©è¨åºé«ççºåå¥æ£èéå·çæ´»æ¹å¼ä¿®æ¹å»ºè­°ï¼ä»¥éä½éç¨®ç¾ççé²å±éåº¦ãæåçæ¸æéæ¯å¾ CKD æ£èåå¥åº·åè©¦èçèº«é«çå½é«å¾µä¸­æ¶éçï¼ä»¥æºç¢ºéç¼æåæåºç AI é©åçè§£æ±ºæ¹æ¡ãå¨éæ¹é¢ï¼æä¾äºè¡æ¶²åå°¿æ¶²æª¢æ¸¬çµæï¼ä¸¦æç¨åºæ¼éææ¨¹çæ©å¨å­¸ç¿æ¨¡åä¾é æ¸¬æªç¼ç¾ç CKD çä¾ãæåçç ç©¶çµæç¶éèèèç§é«ççé·æè«®è©¢å¾å¾å°é©è­ãæåçå¯¦é©åè§£éçµæèåç¨®é«çä¿å¥é åä¸­ç¾æçå¯è§£é AI æç¨é²è¡äºæ¯è¼ï¼åæ¬ CKDãæ¯è¼è¡¨æï¼æåéç¼ç AI æ¨¡åï¼ç¹å¥æ¯é¨æ©æ£®ææ¨¡åï¼å·²ç¶ç¢ºå®äºæ¯ XgBoost æ´å¤ä½çºéè¦è²¢ç»èçç¹å¾µãå¯è§£éæ§ (I) è¡¡ééè¦ç¹å¾µèæ©èç¹å¾µçæ¯çï¼è¡¨ææåç XgBoost æ¨¡åå¨éåææ¨ä¸­ç²å¾äºæ´é«çåæ¸ï¼ç¹å¥æ¯ 98% çä¿çåº¦ï¼ä¸¦ä¸å¨ FII ææ¸ä¸­èªç¶é«æ¼ç«¶ç­æ¨¡åã

##### **Explainable AI for Mental Disorder Detection via Social Media: A survey and outlook**
2406.05984v1 by Yusif Ibrahimov, Tarique Anwar, Tommy Yuan

Mental health constitutes a complex and pervasive global challenge, affecting
millions of lives and often leading to severe consequences. In this paper, we
conduct a thorough survey to explore the intersection of data science,
artificial intelligence, and mental healthcare, focusing on the recent
developments of mental disorder detection through online social media (OSM). A
significant portion of the population actively engages in OSM platforms,
creating a vast repository of personal data that holds immense potential for
mental health analytics. The paper navigates through traditional diagnostic
methods, state-of-the-art data- and AI-driven research studies, and the
emergence of explainable AI (XAI) models for mental healthcare. We review
state-of-the-art machine learning methods, particularly those based on modern
deep learning, while emphasising the need for explainability in healthcare AI
models. The experimental design section provides insights into prevalent
practices, including available datasets and evaluation approaches. We also
identify key issues and challenges in the field and propose promising future
research directions. As mental health decisions demand transparency,
interpretability, and ethical considerations, this paper contributes to the
ongoing discourse on advancing XAI in mental healthcare through social media.
The comprehensive overview presented here aims to guide researchers,
practitioners, and policymakers in developing the area of mental disorder
detection.

æè¦ï¼å¿çå¥åº·æ§æäºä¸é è¤éä¸æ®éçå¨çææ°ï¼å½±é¿äºæ¸ç¾è¬äººççæ´»ï¼ä¸¦ç¶å¸¸å°è´å´éçå¾æãå¨æ¬æä¸­ï¼æåé²è¡äºä¸é å¾¹åºçèª¿æ¥ï¼ä»¥æ¢ç´¢æ¸æç§å­¸ãäººå·¥æºæ§åå¿çä¿å¥çäº¤éï¼éé»éæ³¨ééç·ä¸ç¤¾äº¤åªé« (OSM) é²è¡å¿çç¾çæª¢æ¸¬çææ°ç¼å±ãå¾å¤§ä¸é¨åäººå£ç©æ¥µåè OSM å¹³å°ï¼åµé äºä¸åé¾å¤§çäººå¡è³æåº«ï¼å°å¿çå¥åº·åæå·æå·¨å¤§çæ½åãæ¬ææ¢è¨äºå³çµ±çè¨ºæ·æ¹æ³ãæåé²çè³æå AI é©åçç ç©¶ï¼ä»¥åå¿çä¿å¥ä¸­å¯è§£é AI (XAI) æ¨¡åçåºç¾ãæååé¡§äºæåé²çæ©å¨å­¸ç¿æ¹æ³ï¼ç¹å¥æ¯é£äºåºæ¼ç¾ä»£æ·±åº¦å­¸ç¿çæ¹æ³ï¼åæå¼·èª¿äºé«çä¿å¥ AI æ¨¡åä¸­å¯è§£éæ§çå¿è¦æ§ãå¯¦é©è¨­è¨é¨åæä¾äºå°æ®éåæ³çè¦è§£ï¼åæ¬å¯ç¨çè³æéåè©ä¼°æ¹æ³ãæåéæ¾åºè©²é åçä¸»è¦åé¡åææ°ï¼ä¸¦æåºäºæå¸æçæªä¾ç ç©¶æ¹åãç±æ¼å¿çå¥åº·æ±ºç­éè¦éæåº¦ãå¯è§£éæ§åéå¾·èéï¼æ¬ææå©æ¼æ¨é²å¿çä¿å¥ä¸­ééç¤¾äº¤åªé«æ¨é² XAI çæçºè¨è«ãéè£¡æåºçå¨é¢æ¦è¿°æ¨å¨å¼å°ç ç©¶äººå¡ãå¾æ¥­äººå¡åæ¿ç­å¶å®èç¼å±å¿çç¾çæª¢æ¸¬é åã

##### **Methodology and Real-World Applications of Dynamic Uncertain Causality Graph for Clinical Diagnosis with Explainability and Invariance**
2406.05746v1 by Zhan Zhang, Qin Zhang, Yang Jiao, Lin Lu, Lin Ma, Aihua Liu, Xiao Liu, Juan Zhao, Yajun Xue, Bing Wei, Mingxia Zhang, Ru Gao, Hong Zhao, Jie Lu, Fan Li, Yang Zhang, Yiming Wang, Lei Zhang, Fengwei Tian, Jie Hu, Xin Gou

AI-aided clinical diagnosis is desired in medical care. Existing deep
learning models lack explainability and mainly focus on image analysis. The
recently developed Dynamic Uncertain Causality Graph (DUCG) approach is
causality-driven, explainable, and invariant across different application
scenarios, without problems of data collection, labeling, fitting, privacy,
bias, generalization, high cost and high energy consumption. Through close
collaboration between clinical experts and DUCG technicians, 46 DUCG models
covering 54 chief complaints were constructed. Over 1,000 diseases can be
diagnosed without triage. Before being applied in real-world, the 46 DUCG
models were retrospectively verified by third-party hospitals. The verified
diagnostic precisions were no less than 95%, in which the diagnostic precision
for every disease including uncommon ones was no less than 80%. After
verifications, the 46 DUCG models were applied in the real-world in China. Over
one million real diagnosis cases have been performed, with only 17 incorrect
diagnoses identified. Due to DUCG's transparency, the mistakes causing the
incorrect diagnoses were found and corrected. The diagnostic abilities of the
clinicians who applied DUCG frequently were improved significantly. Following
the introduction to the earlier presented DUCG methodology, the recommendation
algorithm for potential medical checks is presented and the key idea of DUCG is
extracted.

æè¦ï¼<paragraph>é«çç§è­·ä¸­éè¦ AI è¼å©çè¨åºè¨ºæ·ãç¾æçæ·±åº¦å­¸ç¿æ¨¡åç¼ºä¹å¯è§£éæ§ï¼ä¸¦ä¸ä¸»è¦å°æ³¨æ¼å½±ååæãæè¿éç¼çåæä¸ç¢ºå®å æéä¿å (DUCG) æ¹æ³æ¯å æé©åçãå¯è§£éçï¼ä¸¦ä¸å¨ä¸åçæç¨å ´æ¯ä¸­æ¯ä¸è®çï¼æ²æè³ææ¶éãæ¨è¨ãæ¬åãé±ç§ãåè¦ãæ¦åãé«ææ¬åé«è½èçåé¡ãééè¨åºå°å®¶å DUCG æè¡äººå¡ä¹éçå¯ååä½ï¼æ§å»ºäºæ¶µè 54 åä¸»è¨´ç 46 å DUCG æ¨¡åãå¯ä»¥å¨æ²æåæµçææ³ä¸è¨ºæ·åº 1,000 å¤ç¨®ç¾çãå¨æç¨æ¼å¯¦éä¸çä¹åï¼46 å DUCG æ¨¡åå·²ç±ç¬¬ä¸æ¹é«é¢åæº¯æ§é©è­ãé©è­çè¨ºæ·ç²¾åº¦ä¸ä½æ¼ 95%ï¼å¶ä¸­åæ¬ç½è¦ç¾çå¨å§çæ¯ç¨®ç¾ççè¨ºæ·ç²¾åº¦ä¸ä½æ¼ 80%ãé©è­å¾ï¼46 å DUCG æ¨¡åå·²å¨ä¸­åå¯¦éæç¨ãå·²ç¶å·è¡äºè¶éä¸ç¾è¬åçå¯¦è¨ºæ·æ¡ä¾ï¼åç¼ç¾ 17 åä¸æ­£ç¢ºçè¨ºæ·ãç±æ¼ DUCG çéææ§ï¼ç¼ç¾ä¸¦ç³¾æ­£äºå°è´ä¸æ­£ç¢ºè¨ºæ·çé¯èª¤ãé »ç¹æç¨ DUCG çè¨åºé«ççè¨ºæ·è½åå¾å°äºé¡¯èæé«ãå¨ä»ç´¹äºåé¢æåºç DUCG æ¹æ³è«ä¹å¾ï¼æåºäºæ½å¨å¥åº·æª¢æ¥çæ¨è¦æ¼ç®æ³ï¼ä¸¦æåäº DUCG çééµææ³ã</paragraph>

##### **Advancing Histopathology-Based Breast Cancer Diagnosis: Insights into Multi-Modality and Explainability**
2406.12897v1 by Faseela Abdullakutty, Younes Akbari, Somaya Al-Maadeed, Ahmed Bouridane, Rifat Hamoudi

It is imperative that breast cancer is detected precisely and timely to
improve patient outcomes. Diagnostic methodologies have traditionally relied on
unimodal approaches; however, medical data analytics is integrating diverse
data sources beyond conventional imaging. Using multi-modal techniques,
integrating both image and non-image data, marks a transformative advancement
in breast cancer diagnosis. The purpose of this review is to explore the
burgeoning field of multimodal techniques, particularly the fusion of
histopathology images with non-image data. Further, Explainable AI (XAI) will
be used to elucidate the decision-making processes of complex algorithms,
emphasizing the necessity of explainability in diagnostic processes. This
review utilizes multi-modal data and emphasizes explainability to enhance
diagnostic accuracy, clinician confidence, and patient engagement, ultimately
fostering more personalized treatment strategies for breast cancer, while also
identifying research gaps in multi-modality and explainability, guiding future
studies, and contributing to the strategic direction of the field.

æè¦ï¼ç²¾ç¢ºä¸åæå°åµæ¸¬ä¹³çå°æ¼æ¹åæ£èé å¾è³ééè¦ãè¨ºæ·æ¹æ³å³çµ±ä¸ä¾è³´æ¼å®ä¸æ¨¡å¼æ¹æ³ï¼ç¶èï¼é«çè³æåææ­£å¨æ´åè¶è¶å³çµ±å½±åçåç¨®è³æä¾æºãä½¿ç¨æ´åå½±ååéå½±åè³æçå¤æ¨¡å¼æè¡ï¼æ¨èªèä¹³çè¨ºæ·çè®é©æ§é²å±ãæ¬ç¯ç¶è¿°çç®çæ¯æ¢è¨å¤æ¨¡å¼æè¡çæ°èé åï¼ç¹å¥æ¯å°çµç¹ççå­¸å½±åèéå½±åè³æèåãæ­¤å¤ï¼å¯è§£éäººå·¥æºæ§ (XAI) å°ç¨æ¼é¡æè¤éæ¼ç®æ³çæ±ºç­éç¨ï¼å¼·èª¿è¨ºæ·éç¨ä¸­å¯è§£éæ§çå¿è¦æ§ãæ¬ç¶è¿°å©ç¨å¤æ¨¡å¼è³æä¸¦å¼·èª¿å¯è§£éæ§ï¼ä»¥æé«è¨ºæ·æºç¢ºæ§ãè¨åºé«å¸«çä¿¡å¿åæ£èåèåº¦ï¼æçµä¿é²ä¹³çæ´åäººåçæ²»çç­ç¥ï¼åæä¹æ¾åºå¤æ¨¡å¼åå¯è§£éæ§çç ç©¶å·®è·ï¼å¼å°æªä¾çç ç©¶ï¼ä¸¦çºè©²é åçç­ç¥æ¹åååºè²¢ç»ã

##### **Using Explainable AI for EEG-based Reduced Montage Neonatal Seizure Detection**
2406.16908v3 by Dinuka Sandun Udayantha, Kavindu Weerasinghe, Nima Wickramasinghe, Akila Abeyratne, Kithmin Wickremasinghe, Jithangi Wanigasinghe, Anjula De Silva, Chamira U. S. Edussooriya

The neonatal period is the most vulnerable time for the development of
seizures. Seizures in the immature brain lead to detrimental consequences,
therefore require early diagnosis. The gold-standard for neonatal seizure
detection currently relies on continuous video-EEG monitoring; which involves
recording multi-channel electroencephalogram (EEG) alongside real-time video
monitoring within a neonatal intensive care unit (NICU). However, video-EEG
monitoring technology requires clinical expertise and is often limited to
technologically advanced and resourceful settings. Cost-effective new
techniques could help the medical fraternity make an accurate diagnosis and
advocate treatment without delay. In this work, a novel explainable deep
learning model to automate the neonatal seizure detection process with a
reduced EEG montage is proposed, which employs convolutional nets, graph
attention layers, and fully connected layers. Beyond its ability to detect
seizures in real-time with a reduced montage, this model offers the unique
advantage of real-time interpretability. By evaluating the performance on the
Zenodo dataset with 10-fold cross-validation, the presented model achieves an
absolute improvement of 8.31% and 42.86% in area under curve (AUC) and recall,
respectively.

æè¦ï¼æ°çåææ¯å¤§è¦ç¼è²æèå¼±çææï¼å®¹æåºç¾ç²çç¼ä½ãå¤§è¦ç¼è²ä¸æçæåºç¾ç²çç¼ä½æé æä¸è¯å¾æï¼å æ­¤éè¦åæ©è¨ºæ·ãç®åæ°çåç²çç¼ä½çé»éæ¨æºä¾è³´æ¼é£çºçè¦è¨è¦é»å (EEG) ç£æ¸¬ï¼å¶ä¸­åæ¬å¨æ°çåå è­·çæ¿ (NICU) å§åæé²è¡å¤é »éè¦é»å (EEG) è¨éåå³æè¦è¨ç£æ§ãç¶èï¼è¦è¨è¦é»åç£æ§æè¡éè¦è¨åºå°æ¥­ç¥è­ï¼èä¸éå¸¸åéæ¼æè¡åé²ä¸è³æºè±å¯çç°å¢ãå·ææ¬æççæ°æè¡å¯ä»¥å¹«å©é«ççæºç¢ºè¨ºæ·ä¸¦ç«å³æå¡æ²»çãå¨éé å·¥ä½ä¸­ï¼æåºäºä¸åæ°ç©çå¯è§£éæ·±åº¦å­¸ç¿æ¨¡åï¼ä»¥èªååæ°çåç²çç¼ä½åµæ¸¬éç¨ï¼ä¸¦æ¡ç¨æ¸å°çè¦é»åè£ç½®ï¼å¶ä¸­æ¡ç¨äºå·ç©ç¥ç¶ç¶²è·¯ãåå½¢æ³¨æåå±¤åå¨é£æ¥å±¤ãé¤äºè½å¤ ä½¿ç¨æ¸å°çè£ç½®å³æåµæ¸¬ç²çç¼ä½å¤ï¼æ­¤æ¨¡åéæä¾äºå³æå¯è§£éæ§çç¨ç¹åªå¢ãééå¨ Zenodo è³æéä¸ä½¿ç¨ 10 åäº¤åé©è­è©ä¼°æè½ï¼ææåºçæ¨¡åå¨æ²ç·ä¸é¢ç© (AUC) åå¬åçæ¹é¢åå¥éå°äº 8.31% å 42.86% ççµå°æ¹åã

##### **Breast Cancer Diagnosis: A Comprehensive Exploration of Explainable Artificial Intelligence (XAI) Techniques**
2406.00532v1 by Samita Bai, Sidra Nasir, Rizwan Ahmed Khan, Sheeraz Arif, Alexandre Meyer, Hubert Konik

Breast cancer (BC) stands as one of the most common malignancies affecting
women worldwide, necessitating advancements in diagnostic methodologies for
better clinical outcomes. This article provides a comprehensive exploration of
the application of Explainable Artificial Intelligence (XAI) techniques in the
detection and diagnosis of breast cancer. As Artificial Intelligence (AI)
technologies continue to permeate the healthcare sector, particularly in
oncology, the need for transparent and interpretable models becomes imperative
to enhance clinical decision-making and patient care. This review discusses the
integration of various XAI approaches, such as SHAP, LIME, Grad-CAM, and
others, with machine learning and deep learning models utilized in breast
cancer detection and classification. By investigating the modalities of breast
cancer datasets, including mammograms, ultrasounds and their processing with
AI, the paper highlights how XAI can lead to more accurate diagnoses and
personalized treatment plans. It also examines the challenges in implementing
these techniques and the importance of developing standardized metrics for
evaluating XAI's effectiveness in clinical settings. Through detailed analysis
and discussion, this article aims to highlight the potential of XAI in bridging
the gap between complex AI models and practical healthcare applications,
thereby fostering trust and understanding among medical professionals and
improving patient outcomes.

æè¦ï¼ä¹³ç (BC) æ¯å½±é¿å¨çå¥³æ§æå¸¸è¦çæ¡æ§è«ç¤ä¹ä¸ï¼å æ­¤éè¦é²æ­¥çè¨ºæ·æ¹æ³ï¼ä»¥æ¹åè¨åºçµæãæ¬æå¨é¢æ¢è¨äºå¯è§£éäººå·¥æºæ§ (XAI) æè¡å¨ä¹³çåµæ¸¬åè¨ºæ·ä¸­çæç¨ãé¨èäººå·¥æºæ§ (AI) æè¡æçºæ»²éé«çä¿å¥é åï¼ç¹å¥æ¯å¨è«ç¤å­¸ä¸­ï¼éæä¸å¯è§£éçæ¨¡åéæ±è®å¾å¢å¨å¿è¡ï¼ä»¥å¢å¼·è¨åºæ±ºç­å¶å®åæ£èç§è­·ãæ­¤ç¯è©è«æ¢è¨äºåç¨® XAI æ¹æ³çæ´åï¼ä¾å¦ SHAPãLIMEãGrad-CAM ç­ï¼ä»¥åç¨æ¼ä¹³çåµæ¸¬ååé¡çæ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿æ¨¡åãééæ¢è¨ä¹³çè³æéçæ¨¡å¼ï¼åæ¬ä¹³æ¿æå½±ãè¶é³æ³¢åå¶å¨ AI ä¸­çèçï¼æ¬æéé»èªªæ XAI å¦ä½è½å°è´æ´æºç¢ºçè¨ºæ·ååäººåæ²»çè¨ç«ãå®ä¹æ¢è¨äºå¯¦æ½éäºæè¡çææ°ï¼ä»¥åå¶å®æ¨æºåè©éææ¨ä»¥è©ä¼° XAI å¨è¨åºç°å¢ä¸­çæææ§çéè¦æ§ãééè©³ç´°çåæåè¨è«ï¼æ¬ææ¨å¨å¼·èª¿ XAI å¨ç¸®å°è¤é AI æ¨¡åèå¯¦åé«çä¿å¥æç¨ä¹éå·®è·çæ½åï¼é²èä¿é²é«çå°æ¥­äººå¡ä¹éçä¿¡ä»»èçè§£ï¼ä¸¦æ¹åæ£èççµæã

##### **Unveiling Hidden Factors: Explainable AI for Feature Boosting in Speech Emotion Recognition**
2406.01624v2 by Alaa Nfissi, Wassim Bouachir, Nizar Bouguila, Brian Mishara

Speech emotion recognition (SER) has gained significant attention due to its
several application fields, such as mental health, education, and
human-computer interaction. However, the accuracy of SER systems is hindered by
high-dimensional feature sets that may contain irrelevant and redundant
information. To overcome this challenge, this study proposes an iterative
feature boosting approach for SER that emphasizes feature relevance and
explainability to enhance machine learning model performance. Our approach
involves meticulous feature selection and analysis to build efficient SER
systems. In addressing our main problem through model explainability, we employ
a feature evaluation loop with Shapley values to iteratively refine feature
sets. This process strikes a balance between model performance and
transparency, which enables a comprehensive understanding of the model's
predictions. The proposed approach offers several advantages, including the
identification and removal of irrelevant and redundant features, leading to a
more effective model. Additionally, it promotes explainability, facilitating
comprehension of the model's predictions and the identification of crucial
features for emotion determination. The effectiveness of the proposed method is
validated on the SER benchmarks of the Toronto emotional speech set (TESS),
Berlin Database of Emotional Speech (EMO-DB), Ryerson Audio-Visual Database of
Emotional Speech and Song (RAVDESS), and Surrey Audio-Visual Expressed Emotion
(SAVEE) datasets, outperforming state-of-the-art methods. To the best of our
knowledge, this is the first work to incorporate model explainability into an
SER framework. The source code of this paper is publicly available via this
https://github.com/alaaNfissi/Unveiling-Hidden-Factors-Explainable-AI-for-Feature-Boosting-in-Speech-Emotion-Recognition.

æè¦ï¼èªé³æç·è¾¨è­ (SER) ç±æ¼å¶å¨å¿çå¥åº·ãæè²åäººæ©äºåç­å¤åæç¨é åèååéæ³¨ãç¶èï¼SER ç³»çµ±çæºç¢ºæ§åå°é«ç¶­ç¹å¾µéçé»ç¤ï¼éäºç¹å¾µéå¯è½åå«ä¸ç¸éååé¤çè³è¨ãçºäºåæéåææ°ï¼æ¬ç ç©¶æåºäºä¸ç¨®ç¨æ¼ SER çè¿­ä»£ç¹å¾µæåæ¹æ³ï¼è©²æ¹æ³å¼·èª¿ç¹å¾µç¸éæ§åå¯è§£éæ§ï¼ä»¥å¢å¼·æ©å¨å­¸ç¿æ¨¡åçæè½ãæåçåæ³æ¶åä»ç´°çç¹å¾µé¸æååæï¼ä»¥å»ºç«é«æç SER ç³»çµ±ãçºäºééæ¨¡åå¯è§£éæ§è§£æ±ºæåçæ ¸å¿åé¡ï¼æåæ¡ç¨äºå·æ Shapley å¼çç¹å¾µè©ä¼°è¿´åï¼ä»¥åè¦æ¹åç¹å¾µéãéåéç¨å¨æ¨¡åæè½åéæåº¦ä¹éåå¾å¹³è¡¡ï¼éä½¿å¾æåè½å¤ å¨é¢äºè§£æ¨¡åçé æ¸¬ãææåºçæ¹æ³æä¾äºå¤é åªé»ï¼åæ¬è­å¥åç§»é¤ä¸ç¸éååé¤çç¹å¾µï¼å¾èå»ºç«æ´ææçæ¨¡åãæ­¤å¤ï¼å®ä¿é²äºå¯è§£éæ§ï¼æå©æ¼çè§£æ¨¡åçé æ¸¬ä»¥åè­å¥æç·æ±ºå®çééµç¹å¾µãææåºçæ¹æ³çæææ§å·²å¨å¤å«å¤æç·èªé³é (TESS)ãæææç·èªé³è³æåº« (EMO-DB)ãè³´ç¾æ£®é³è¨è¦è¦ºæç·èªé³åæ­æ²è³æåº« (RAVDESS) åè©éé³è¨è¦è¦ºè¡¨éæç· (SAVEE) è³æéç SER åºæºä¸å¾å°é©è­ï¼å¶æè½åªæ¼ç¾ææ¹æ³ãææåæç¥ï¼éæ¯ç¬¬ä¸åå°æ¨¡åå¯è§£éæ§ç´å¥ SER æ¶æ§çç ç©¶ãæ¬æçåå§ç¢¼å¯ééæ­¤é£çµå¬éåå¾ï¼https://github.com/alaaNfissi/Unveiling-Hidden-Factors-Explainable-AI-for-Feature-Boosting-in-Speech-Emotion-Recognitionã

##### **The Explanation Necessity for Healthcare AI**
2406.00216v1 by Michail Mamalakis, HÃ©loÃ¯se de Vareilles, Graham Murray, Pietro Lio, John Suckling

Explainability is often critical to the acceptable implementation of
artificial intelligence (AI). Nowhere is this more important than healthcare
where decision-making directly impacts patients and trust in AI systems is
essential. This trust is often built on the explanations and interpretations
the AI provides. Despite significant advancements in AI interpretability, there
remains the need for clear guidelines on when and to what extent explanations
are necessary in the medical context. We propose a novel categorization system
with four distinct classes of explanation necessity, guiding the level of
explanation required: patient or sample (local) level, cohort or dataset
(global) level, or both levels. We introduce a mathematical formulation that
distinguishes these categories and offers a practical framework for researchers
to determine the necessity and depth of explanations required in medical AI
applications. Three key factors are considered: the robustness of the
evaluation protocol, the variability of expert observations, and the
representation dimensionality of the application. In this perspective, we
address the question: When does an AI medical application need to be explained,
and at what level of detail?

æè¦ï¼å¯è§£éæ§éå¸¸å¯¹äºäººå·¥æºè½ (AI) çå¯æ¥åå®æ½è³å³éè¦ãå¨å»çä¿å¥é¢åï¼è¿ä¸ç¹å°¤ä¸ºéè¦ï¼å ä¸ºå³ç­ç´æ¥å½±åæ£èï¼å¹¶ä¸å¯¹ AI ç³»ç»çä¿¡ä»»è³å³éè¦ãè¿ç§ä¿¡ä»»éå¸¸å»ºç«å¨ AI æä¾çè§£éåè¯ éä¹ä¸ãå°½ç®¡ AI å¯è§£éæ§åå¾äºéå¤§è¿å±ï¼ä½ä»ç¶éè¦æç¡®çæå¯¼æ¹éï¼è¯´æå¨å»çç¯å¢ä¸­ä½æ¶ä»¥åå¨å¤å¤§ç¨åº¦ä¸éè¦è§£éãæä»¬æåºäºä¸ç§æ°é¢çåç±»ç³»ç»ï¼è¯¥ç³»ç»å·æåç§ä¸åçè§£éå¿è¦æ§ç±»å«ï¼æå¯¼æéçè§£éçº§å«ï¼æ£èææ ·æ¬ï¼å±é¨ï¼çº§å«ãéåææ°æ®éï¼å¨å±ï¼çº§å«ï¼æä¸¤ä¸ªçº§å«ãæä»¬å¼å¥äºä¸ä¸ªæ°å­¦å¬å¼ï¼è¯¥å¬å¼åºåäºè¿äºç±»å«ï¼å¹¶ä¸ºç ç©¶äººåæä¾äºä¸ä¸ªå®ç¨æ¡æ¶ï¼ä»¥ç¡®å®å»ç AI åºç¨ä¸­æéçè§£éçå¿è¦æ§åæ·±åº¦ãèèäºä¸ä¸ªå³é®å ç´ ï¼è¯ä¼°åè®®çç¨³å¥æ§ãä¸å®¶è§å¯çå¯åæ§ä»¥ååºç¨ç¨åºçè¡¨ç¤ºç»´æ°ãä»è¿ä¸ªè§åº¦æ¥çï¼æä»¬è§£å³äºè¿ä¸ªé®é¢ï¼AI å»çåºç¨ä½æ¶éè¦è§£éï¼ä»¥åéè¦è§£éå°ä½ç§ç¨åº¦ï¼

##### **Interdisciplinary Expertise to Advance Equitable Explainable AI**
2406.18563v1 by Chloe R. Bennett, Heather Cole-Lewis, Stephanie Farquhar, Naama Haamel, Boris Babenko, Oran Lang, Mat Fleck, Ilana Traynis, Charles Lau, Ivor Horn, Courtney Lyles

The field of artificial intelligence (AI) is rapidly influencing health and
healthcare, but bias and poor performance persists for populations who face
widespread structural oppression. Previous work has clearly outlined the need
for more rigorous attention to data representativeness and model performance to
advance equity and reduce bias. However, there is an opportunity to also
improve the explainability of AI by leveraging best practices of social
epidemiology and health equity to help us develop hypotheses for associations
found. In this paper, we focus on explainable AI (XAI) and describe a framework
for interdisciplinary expert panel review to discuss and critically assess AI
model explanations from multiple perspectives and identify areas of bias and
directions for future research. We emphasize the importance of the
interdisciplinary expert panel to produce more accurate, equitable
interpretations which are historically and contextually informed.
Interdisciplinary panel discussions can help reduce bias, identify potential
confounders, and identify opportunities for additional research where there are
gaps in the literature. In turn, these insights can suggest opportunities for
AI model improvement.

æè¦ï¼äººå·¥æºæ§ (AI) é åæ­£å¿«éå½±é¿èå¥åº·èé«çä¿å¥ï¼ä½å°æ¼é¢è¨å»£æ³çµæ§æ§å£è¿«çäººç¾¤ä¾èªªï¼åè¦åä¸è¯è¡¨ç¾ä¾ç¶å­å¨ãååçç ç©¶å·²æ¸æ¥èªªæï¼éè¦æ´å´æ ¼å°æ³¨æè³æä»£è¡¨æ§åæ¨¡åæè½ï¼ä»¥ä¿é²å¬å¹³æ§ä¸¦æ¸å°åè¦ãç¶èï¼æåææ©æéééç¨ç¤¾ææµè¡çå­¸åå¥åº·å¬å¹³çæä½³å¯¦åï¼ä¾æ¹å AI çå¯è§£éæ§ï¼ä»¥å¹«å©æåéå°ç¼ç¾çéè¯æ§ï¼ç¼å±åè¨­ãå¨æ¬æä¸­ï¼æåå°æ³¨æ¼å¯è§£é AI (XAI)ï¼ä¸¦æè¿°ä¸åè·¨é åå°å®¶å°çµå¯©æ¥æ¶æ§ï¼ä»¥å¾å¤éè§é»è¨è«åæ¹å¤æ§è©ä¼° AI æ¨¡åçè§£éï¼ä¸¦æ¾åºåè¦é ååæªä¾ç ç©¶çæ¹åãæåå¼·èª¿è·¨é åå°å®¶å°çµå°æ¼ç¢çæ´æºç¢ºãå¬å¹³çè©®éè³ééè¦ï¼èéäºè©®éæ¯æ ¹ææ­·å²åèçµ¡èä¾çãè·¨é åå°çµè¨è«æå©æ¼æ¸å°åè¦ãæ¾åºæ½å¨çæ··æ·å ç´ ï¼ä¸¦å¨æç»ä¸­æç¼ºå£ææ¾åºé¡å¤ç ç©¶çæ©æãåéä¾ï¼éäºè¦è§£å¯ä»¥å»ºè­° AI æ¨¡åæ¹é²çæ©æã

##### **"It depends": Configuring AI to Improve Clinical Usefulness Across Contexts**
2407.11978v1 by Hubert D. ZajÄc, Jorge M. N. Ribeiro, Silvia Ingala, Simona Gentile, Ruth Wanjohi, Samuel N. Gitau, Jonathan F. Carlsen, Michael B. Nielsen, Tariq O. Andersen

Artificial Intelligence (AI) repeatedly match or outperform radiologists in
lab experiments. However, real-world implementations of radiological AI-based
systems are found to provide little to no clinical value. This paper explores
how to design AI for clinical usefulness in different contexts. We conducted 19
design sessions and design interventions with 13 radiologists from 7 clinical
sites in Denmark and Kenya, based on three iterations of a functional AI-based
prototype. Ten sociotechnical dependencies were identified as crucial for the
design of AI in radiology. We conceptualised four technical dimensions that
must be configured to the intended clinical context of use: AI functionality,
AI medical focus, AI decision threshold, and AI Explainability. We present four
design recommendations on how to address dependencies pertaining to the medical
knowledge, clinic type, user expertise level, patient context, and user
situation that condition the configuration of these technical dimensions.

æè¦ï¼äººå·¥æºæ§ï¼AIï¼å¨å¯¦é©å®¤å¯¦é©ä¸­ä¸æ·å°èæ¾å°ç§é«å¸«å¹æµæè¡¨ç¾å¾æ´åºè²ãç¶èï¼ç¼ç¾æ¾å°ç§ AI çºåºç¤ç³»çµ±çå¯¦éå·è¡å¹¾ä¹æ²ææä¾è¨åºå¹å¼ãæ¬ææ¢è¨å¦ä½çº AI è¨­è¨å¨ä¸åæå¢ä¸­è¨åºä¸çæç¨ãæåæ ¹æåè½æ§ AI çºåºç¤ååçä¸æ¬¡è¿­ä»£ï¼å¨ä¸¹éº¥åè¯äºç 7 åè¨åºå ´åè 13 ä½æ¾å°ç§é«å¸«é²è¡äº 19 æ¬¡è¨­è¨æè­°åè¨­è¨ä»å¥ãååç¤¾ææè¡ä¾è³´éä¿è¢«èªçºå°æ¼æ¾å°ç§ä¸­ AI çè¨­è¨è³ééè¦ãæåæ¦å¿µåäºååæè¡é¢åï¼å¿é æ ¹æé æçè¨åºä½¿ç¨æå¢é²è¡è¨­å®ï¼AI åè½ãAI é«çéé»ãAI æ±ºç­éæª»ï¼ä»¥å AI å¯è§£éæ§ãæåæåºåé è¨­è¨å»ºè­°ï¼èªªæå¦ä½èçèé«çç¥è­ãè¨ºæé¡åãä½¿ç¨èå°æ¥­ç¥è­ç­ç´ãæ£èæå¢ï¼ä»¥åå½±é¿éäºæè¡é¢åè¨­å®çä½¿ç¨èæå¢ç¸éçä¾è³´éä¿ã

##### **Improving Health Professionals' Onboarding with AI and XAI for Trustworthy Human-AI Collaborative Decision Making**
2405.16424v1 by Min Hun Lee, Silvana Xin Yi Choo, Shamala D/O Thilarajah

With advanced AI/ML, there has been growing research on explainable AI (XAI)
and studies on how humans interact with AI and XAI for effective human-AI
collaborative decision-making. However, we still have a lack of understanding
of how AI systems and XAI should be first presented to users without technical
backgrounds. In this paper, we present the findings of semi-structured
interviews with health professionals (n=12) and students (n=4) majoring in
medicine and health to study how to improve onboarding with AI and XAI. For the
interviews, we built upon human-AI interaction guidelines to create onboarding
materials of an AI system for stroke rehabilitation assessment and AI
explanations and introduce them to the participants. Our findings reveal that
beyond presenting traditional performance metrics on AI, participants desired
benchmark information, the practical benefits of AI, and interaction trials to
better contextualize AI performance, and refine the objectives and performance
of AI. Based on these findings, we highlight directions for improving
onboarding with AI and XAI and human-AI collaborative decision-making.

æè¦ï¼é¨èåé²ç AI/MLï¼å°å¯è§£é AI (XAI) çç ç©¶ä¸æ·å¢å ï¼ä»¥åéæ¼äººé¡å¦ä½è AI å XAI äºåä»¥é²è¡ææçäººå·¥æºæ§åä½æ±ºç­å¶å®ãç¶èï¼æåä»ç¶ç¼ºä¹å° AI ç³»çµ±å XAI æå¦ä½é¦ååç¾çµ¦æ²ææè¡èæ¯çç¨æ¶çäºè§£ãå¨æ¬æä¸­ï¼æåå±ç¤ºäºèé«çå°æ¥­äººå¡ (n=12) åä¸»ä¿®é«å­¸åå¥åº·çå­¸ç (n=4) é²è¡åçµæ§åè¨ªè«ççµæï¼ä»¥ç ç©¶å¦ä½æ¹å AI å XAI çå¥éãå°æ¼è¨ªè«ï¼æåå»ºç«å¨äººæ©äºåæºåä¹ä¸ï¼çºä¸­é¢¨åº·å¾©è©ä¼°å AI è§£éç AI ç³»çµ±åµå»ºå¥éææï¼ä¸¦å°å®åä»ç´¹çµ¦åèèãæåçç ç©¶çµæè¡¨æï¼é¤äºåç¾å³çµ±ç AI æ§è½ææ¨å¤ï¼åèèéå¸æåºåä¿¡æ¯ãAI çå¯¦éå¥½èä»¥åäº¤äºè©¦é©ï¼ä»¥æ´å¥½å°å° AI æ§è½æå¢åï¼ä¸¦å®å AI çç®æ¨åæ§è½ãæ ¹æéäºç¼ç¾ï¼æåå¼·èª¿äºæ¹é² AI å XAI ä»¥åäººæ©åä½æ±ºç­å¶å®çå¥éæ¹åã

##### **Exploring Nutritional Impact on Alzheimer's Mortality: An Explainable AI Approach**
2405.17502v1 by Ziming Liu, Longjian Liu, Robert E. Heidel, Xiaopeng Zhao

This article uses machine learning (ML) and explainable artificial
intelligence (XAI) techniques to investigate the relationship between
nutritional status and mortality rates associated with Alzheimers disease (AD).
The Third National Health and Nutrition Examination Survey (NHANES III)
database is employed for analysis. The random forest model is selected as the
base model for XAI analysis, and the Shapley Additive Explanations (SHAP)
method is used to assess feature importance. The results highlight significant
nutritional factors such as serum vitamin B12 and glycated hemoglobin. The
study demonstrates the effectiveness of random forests in predicting AD
mortality compared to other diseases. This research provides insights into the
impact of nutrition on AD and contributes to a deeper understanding of disease
progression.

æè¦ï¼æ¬æä½¿ç¨æ©å¨å­¸ç¿ (ML) åå¯è§£éäººå·¥æºæ§ (XAI) æè¡ä¾æ¢è¨çé¤çæ³èé¿è²æµ·é»ç (AD) ç¸éçæ­»äº¡çä¹éçéä¿ãæ¡ç¨ç¬¬ä¸æ¬¡å¨åå¥åº·èçé¤æª¢æ¥èª¿æ¥ (NHANES III) è³æåº«é²è¡åæãé¸æé¨æ©æ£®ææ¨¡åä½çº XAI åæçåºç¤æ¨¡åï¼ä¸¦ä½¿ç¨ Shapley Additive Explanations (SHAP) æ¹æ³ä¾è©ä¼°ç¹å¾µéè¦æ§ãçµæçªé¡¯äºéè¦ççé¤å ç´ ï¼ä¾å¦è¡æ¸ç¶­çç´  B12 åç³åè¡ç´èç½ãè©²ç ç©¶è­æäºé¨æ©æ£®æå¨é æ¸¬ AD æ­»äº¡çæ¹é¢ç¸è¼æ¼å¶ä»ç¾ççæææ§ãæ¬ç ç©¶æä¾äºçé¤å° AD çå½±é¿çè¦è§£ï¼ä¸¦æå©æ¼æ´æ·±å¥å°äºè§£ç¾ççé²å±ã

##### **Explainable AI Enhances Glaucoma Referrals, Yet the Human-AI Team Still Falls Short of the AI Alone**
2407.11974v1 by Catalina Gomez, Ruolin Wang, Katharina Breininger, Corinne Casey, Chris Bradley, Mitchell Pavlak, Alex Pham, Jithin Yohannan, Mathias Unberath

Primary care providers are vital for initial triage and referrals to
specialty care. In glaucoma, asymptomatic and fast progression can lead to
vision loss, necessitating timely referrals to specialists. However, primary
eye care providers may not identify urgent cases, potentially delaying care.
Artificial Intelligence (AI) offering explanations could enhance their referral
decisions. We investigate how various AI explanations help providers
distinguish between patients needing immediate or non-urgent specialist
referrals. We built explainable AI algorithms to predict glaucoma surgery needs
from routine eyecare data as a proxy for identifying high-risk patients. We
incorporated intrinsic and post-hoc explainability and conducted an online
study with optometrists to assess human-AI team performance, measuring referral
accuracy and analyzing interactions with AI, including agreement rates, task
time, and user experience perceptions. AI support enhanced referral accuracy
among 87 participants (59.9%/50.8% with/without AI), though Human-AI teams
underperformed compared to AI alone. Participants believed they included AI
advice more when using the intrinsic model, and perceived it more useful and
promising. Without explanations, deviations from AI recommendations increased.
AI support did not increase workload, confidence, and trust, but reduced
challenges. On a separate test set, our black-box and intrinsic models achieved
an accuracy of 77% and 71%, respectively, in predicting surgical outcomes. We
identify opportunities of human-AI teaming for glaucoma management in primary
eye care, noting that while AI enhances referral accuracy, it also shows a
performance gap compared to AI alone, even with explanations. Human involvement
remains essential in medical decision making, underscoring the need for future
research to optimize collaboration, ensuring positive experiences and safe AI
use.

æè¦ï¼<paragraph>åç´ä¿å¥æä¾èå°æ¼æåçåæµåè½è¨ºå°å°ç§ç§è­·è³ééè¦ãå¨éåç¼çææ³ä¸ï¼ç¡ççä¸å¿«éæ¡åå¯è½å°è´è¦ååªå¤±ï¼å æ­¤éè¦åæè½è¨ºçµ¦å°å®¶ãç¶èï¼åç´ç¼ç§ä¿å¥æä¾èå¯è½ç¡æ³è­å¥ç·æ¥ææ³ï¼å¯è½æå»¶èª¤ç§è­·ãæä¾è§£éçäººå·¥æºæ§ (AI) å¯ä»¥å å¼·ä»åçè½è¨ºæ±ºç­ãæåç ç©¶åç¨® AI è§£éå¦ä½å¹«å©æä¾èååéè¦ç«å³æéç·æ¥å°ç§è½è¨ºçæ£èãæåå»ºç«äºè§£éæ§ AI æ¼ç®æ³ï¼ä»¥å¾ä¾è¡ç¼ç§è­·çè³æé æ¸¬éåç¼æè¡éæ±ï¼ä½çºè­å¥é«é¢¨éªæ£èçä»£çãæåç´å¥äºå§å¨åäºå¾è§£éæ§ï¼ä¸¦èé©åå¸«é²è¡äºä¸é ç·ä¸ç ç©¶ï¼ä»¥è©ä¼°äººæ©åéçè¡¨ç¾ï¼è¡¡éè½è¨ºæºç¢ºåº¦ä¸¦åæè AI çäºåï¼åæ¬åæçãä»»åæéåä½¿ç¨èé«é©æç¥ãå¨ 87 ååèèä¸­ï¼AI æ¯æ´æé«äºè½è¨ºæºç¢ºåº¦ï¼ä½¿ç¨ AI/æªä½¿ç¨çæ¯ä¾çº 59.9%/50.8%ï¼ï¼åç®¡äººæ©åéçè¡¨ç¾ä¸å¦å®ç¨ä½¿ç¨ AIãåèèèªçºä»åå¨ä½¿ç¨å§å¨æ¨¡åææ´å¤å°ç´å¥äº AI å»ºè­°ï¼ä¸¦èªçºå®æ´æç¨ä¸æ´æå¸æãæ²æè§£éï¼AI å»ºè­°çåå·®æå¢å ãAI æ¯æ´ä¸¦æªå¢å å·¥ä½éãä¿¡å¿åä¿¡ä»»ï¼ä½æ¸å°äºææ°ãå¨ä¸åå®ç¨çæ¸¬è©¦éä¸­ï¼æåçé»çå­åå§å¨æ¨¡åå¨é æ¸¬æè¡çµææ¹é¢åå¥éå°äº 77% å 71% çæºç¢ºåº¦ãæåæ¾åºå¨åç´ç¼ç§ä¿å¥ä¸­ï¼äººæ©åéåä½ç®¡çéåç¼çæ©æï¼ä¸¦æ³¨æå°éç¶ AI æé«äºè½è¨ºæºç¢ºåº¦ï¼ä½å³ä½¿æè§£éï¼å®ä¹é¡¯ç¤ºåºèå®ç¨ä½¿ç¨ AI ç¸æ¯çæè½å·®è·ãäººé¡åèå¨é«çæ±ºç­ä¸­ä»ç¶è³ééè¦ï¼éå¼·èª¿äºæªä¾ç ç©¶åªååä½ãç¢ºä¿æ­£é¢ç¶é©åå®å¨ä½¿ç¨ AI çå¿è¦æ§ã</paragraph>

##### **Decoding Decision Reasoning: A Counterfactual-Powered Model for Knowledge Discovery**
2406.18552v1 by Yingying Fang, Zihao Jin, Xiaodan Xing, Simon Walsh, Guang Yang

In medical imaging, particularly in early disease detection and prognosis
tasks, discerning the rationale behind an AI model's predictions is crucial for
evaluating the reliability of its decisions. Conventional explanation methods
face challenges in identifying discernible decisive features in medical image
classifications, where discriminative features are subtle or not immediately
apparent. To bridge this gap, we propose an explainable model that is equipped
with both decision reasoning and feature identification capabilities. Our
approach not only detects influential image patterns but also uncovers the
decisive features that drive the model's final predictions. By implementing our
method, we can efficiently identify and visualise class-specific features
leveraged by the data-driven model, providing insights into the decision-making
processes of deep learning models. We validated our model in the demanding
realm of medical prognosis task, demonstrating its efficacy and potential in
enhancing the reliability of AI in healthcare and in discovering new knowledge
in diseases where prognostic understanding is limited.

æè¦ï¼å¨é«å­¸å½±åä¸­ï¼ç¹å¥æ¯å¨æ©æç¾çæª¢æ¸¬åé å¾ä»»åä¸­ï¼è¾¨å¥ AI æ¨¡åé æ¸¬èå¾çåçå°æ¼è©ä¼°å¶æ±ºç­çå¯é æ§è³ééè¦ãå³çµ±çè§£éæ¹æ³å¨è­å¥é«å­¸å½±ååé¡ä¸­å¯è­å¥çæ±ºå®æ§ç¹å¾µæé¢è¨ææ°ï¼å¶ä¸­åå¥æ§ç¹å¾µå¾å¾®å¦æä¸¦ä¸æé¡¯ãçºäºå½åéä¸å·®è·ï¼æåæåºäºä¸åå¯è§£éçæ¨¡åï¼è©²æ¨¡åå·åæ±ºç­æ¨çåç¹å¾µè­å¥è½åãæåçåæ³ä¸åæª¢æ¸¬æå½±é¿åçå½±åæ¨¡å¼ï¼éæ­ç¤ºäºæ¨åæ¨¡åæçµé æ¸¬çæ±ºå®æ§ç¹å¾µãééå¯¦æ½æåçæ¨¡åï¼æåå¯ä»¥ææè­å¥åè¦è¦ºåç±æ¸æé©åæ¨¡åå©ç¨çé¡ç¹å®ç¹å¾µï¼å¾èæ·±å¥äºè§£æ·±åº¦å­¸ç¿æ¨¡åçæ±ºç­éç¨ãæåå¨è¦æ±å´æ ¼çé«å­¸é å¾ä»»åé åé©è­äºæåçæ¨¡åï¼å±ç¤ºäºå¶å¨æé« AI å¨é«çä¿å¥ä¸­çå¯é æ§åç¼ç¾é å¾çè§£åéç¾ççæ°ç¥è­æ¹é¢çåæåæ½åã

##### **The Role of Emotions in Informational Support Question-Response Pairs in Online Health Communities: A Multimodal Deep Learning Approach**
2405.13099v1 by Mohsen Jozani, Jason A. Williams, Ahmed Aleroud, Sarbottam Bhagat

This study explores the relationship between informational support seeking
questions, responses, and helpfulness ratings in online health communities. We
created a labeled data set of question-response pairs and developed multimodal
machine learning and deep learning models to reliably predict informational
support questions and responses. We employed explainable AI to reveal the
emotions embedded in informational support exchanges, demonstrating the
importance of emotion in providing informational support. This complex
interplay between emotional and informational support has not been previously
researched. The study refines social support theory and lays the groundwork for
the development of user decision aids. Further implications are discussed.

æè¦ï¼æ¬ç ç©¶æ¢è¨ç·ä¸å¥åº·ç¤¾ç¾¤ä¸­å°æ±è³è¨æ¯æçåé¡ãåæï¼ä»¥åæå¹«å©çè©åä¹éçéä¿ãæåå»ºç«äºä¸çµæ¨è¨çåç­éå°è³æéï¼ä¸¦éç¼äºå¤æ¨¡ææ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿æ¨¡åï¼ä»¥å¯é å°é æ¸¬è³è¨æ¯æåé¡ååæãæåæ¡ç¨å¯è§£éç AI ä¾æ­ç¤ºè³è¨æ¯æäº¤æµä¸­èå«çæç·ï¼è­ææç·å¨æä¾è³è¨æ¯æä¸­çéè¦æ§ãéç¨®æç·æ¯æåè³è¨æ¯æä¹éçè¤éäº¤äºä½ç¨ä»¥åä¸¦æªè¢«ç ç©¶éãæ¬ç ç©¶æ¹é²äºç¤¾ææ¯æçè«ï¼ä¸¦çºä½¿ç¨èæ±ºç­è¼å©å·¥å·çéç¼å¥ å®äºåºç¤ãè¨è«äºé²ä¸æ­¥çå½±é¿ã

##### **ChatGPT in Classrooms: Transforming Challenges into Opportunities in Education**
2405.10645v1 by Harris Bin Munawar, Nikolaos Misirlis

In the era of exponential technology growth, one unexpected guest has claimed
a seat in classrooms worldwide, Artificial Intelligence. Generative AI, such as
ChatGPT, promises a revolution in education, yet it arrives with a double-edged
sword. Its potential for personalized learning is offset by issues of cheating,
inaccuracies, and educators struggling to incorporate it effectively into their
lesson design. We are standing on the brink of this educational frontier, and
it is clear that we need to navigate this terrain with a lot of care. This is a
major challenge that could undermine the integrity and value of our educational
process. So, how can we turn these challenges into opportunities? When used
inappropriately, AI tools can become the perfect tool for the cut copy paste
mentality, and quickly begin to corrode critical thinking, creativity, and deep
understanding, the most important skills in our rapidly changing world.
Teachers feel that they are not equipped to leverage this technology, widening
the digital divide among educators and institutions. Addressing these concerns
calls for an in depth research approach. We will employ empirical research,
drawing on the Technology Acceptance Model, to assess the attitudes toward
generative AI among educators and students. Understanding their perceptions,
usage patterns, and hurdles is the first crucial step in creating an effective
solution. The present study will be used as a process manual for future
researchers to apply, running their own data, based on the steps explained here

æè¦ï¼å¨ç§æé£éç¼å±çæä»£ï¼ä¸ä½æå¤çè¨ªå®¢å·²å¨å¨çæå®¤ä¸­ä½æä¸å¸­ä¹å°ï¼é£å°±æ¯äººå·¥æºæ§ãçæå¼ AIï¼ä¾å¦ ChatGPTï¼æ¿è«¾å¨æè²é åæèµ·ä¸å ´é©å½ï¼ä½å®å»æ¯ä¸æéé¢åãå®å¨åäººåå­¸ç¿æ¹é¢çæ½åï¼å»å ä½å¼ãä¸æºç¢ºä»¥åæè²å·¥ä½èé£ä»¥å°å¶ææèå¥æå­¸è¨­è¨ç­åé¡èæµé·ãæåæ­£ç«å¨éæè²åæ²¿çéç·£ï¼é¡¯ç¶æåéè¦éå¸¸å°å¿å°æ¢ç´¢éçé åãéæ¯ä¸åéå¤§çææ°ï¼å¯è½ææå®³æåæè²éç¨çå®æ´æ§åå¹å¼ãé£éº¼ï¼æåå¦ä½å°éäºææ°è½åçºæ©éï¼ç¶ä¸é©ç¶å°ä½¿ç¨æï¼AI å·¥å·å¯è½ææçºè¤è£½è²¼ä¸å¿æçå®ç¾å·¥å·ï¼ä¸¦è¿éèèæ¹å¤æ§æç¶­ãåµé ååæ·±å¥çè§£ï¼éäºé½æ¯æåå¿«éè®åçä¸çä¸­æéè¦çæè½ãæå¸«åè¦ºå¾ä»åæ²æè½åå©ç¨éé æè¡ï¼éæ´å¤§äºæè²å·¥ä½èåæ©æ§ä¹éçæ¸ä½é´»æºãè§£æ±ºéäºåé¡éè¦æ·±å¥çç ç©¶æ¹æ³ãæåå°æ¡ç¨å¯¦è­ç ç©¶ï¼åéæè¡æ¥åæ¨¡åï¼ä¾è©ä¼°æè²å·¥ä½èåå­¸çå°çæå¼ AI çæåº¦ãäºè§£ä»åççæ³ãä½¿ç¨æ¨¡å¼åéç¤æ¯åµé ææè§£æ±ºæ¹æ¡çç¬¬ä¸åééµæ­¥é©ãæ¬ç ç©¶å°ä½çºæªä¾ç ç©¶äººå¡æç¨çæµç¨æåï¼æ ¹ææ­¤èèªªæçæ­¥é©éè¡ä»åèªå·±çæ¸æ

##### **Evaluating the Explainable AI Method Grad-CAM for Breath Classification on Newborn Time Series Data**
2405.07590v1 by Camelia Oprea, Mike GrÃ¼ne, Mateusz Buglowski, Lena Olivier, Thorsten Orlikowsky, Stefan Kowalewski, Mark Schoberer, AndrÃ© Stollenwerk

With the digitalization of health care systems, artificial intelligence
becomes more present in medicine. Especially machine learning shows great
potential for complex tasks such as time series classification, usually at the
cost of transparency and comprehensibility. This leads to a lack of trust by
humans and thus hinders its active usage. Explainable artificial intelligence
tries to close this gap by providing insight into the decision-making process,
the actual usefulness of its different methods is however unclear. This paper
proposes a user study based evaluation of the explanation method Grad-CAM with
application to a neural network for the classification of breaths in time
series neonatal ventilation data. We present the perceived usefulness of the
explainability method by different stakeholders, exposing the difficulty to
achieve actual transparency and the wish for more in-depth explanations by many
of the participants.

æè¦ï¼é¨èé«çä¿å¥ç³»çµ±çæ¸ä½åï¼äººå·¥æºæ§å¨é«å­¸é åä¸­è®å¾æ´å æ®åãç¹å¥æ¯æ©å¨å­¸ç¿å¨æéåºååé¡ç­è¤éä»»åä¸­å±ç¾åºæ¥µå¤§çæ½åï¼ä½éå¸¸æ¯ä»¥éæåº¦åå¯çè§£æ§çºä»£å¹ãéå°è´äººé¡ç¼ºä¹ä¿¡ä»»ï¼å¾èé»ç¤äºå¶ç©æ¥µä½¿ç¨ãå¯è§£éçäººå·¥æºæ§è©¦åééæä¾å°æ±ºç­éç¨çæ´å¯ä¾å½è£éä¸å·®è·ï¼ä½å¶ä¸åæ¹æ³çå¯¦éæç¨å°ä¸æ¸æ¥ãæ¬ææåºäºä¸ååºæ¼ä½¿ç¨èç ç©¶çè©ä¼°ï¼å¶ä¸­åå«äº Grad-CAM è§£éæ¹æ³ï¼ä¸¦å°å¶æç¨æ¼ç¥ç¶ç¶²è·¯ä»¥åé¡æéåºåæ°çåå¼å¸æ¸æä¸­çå¼å¸ãæåå±ç¤ºäºä¸åå©çç¸éèå°å¯è§£éæ§æ¹æ³çæç¥æç¨ï¼æ­ç¤ºäºå¯¦ç¾å¯¦ééæåº¦çé£åº¦ï¼ä»¥åè¨±å¤åèèå¸æç²å¾æ´æ·±å¥çè§£éã

##### **XAI4LLM. Let Machine Learning Models and LLMs Collaborate for Enhanced In-Context Learning in Healthcare**
2405.06270v3 by Fatemeh Nazary, Yashar Deldjoo, Tommaso Di Noia, Eugenio di Sciascio

The integration of Large Language Models (LLMs) into healthcare diagnostics
offers a promising avenue for clinical decision-making. This study outlines the
development of a novel method for zero-shot/few-shot in-context learning (ICL)
by integrating medical domain knowledge using a multi-layered structured
prompt. We also explore the efficacy of two communication styles between the
user and LLMs: the Numerical Conversational (NC) style, which processes data
incrementally, and the Natural Language Single-Turn (NL-ST) style, which
employs long narrative prompts.
  Our study systematically evaluates the diagnostic accuracy and risk factors,
including gender bias and false negative rates, using a dataset of 920 patient
records in various few-shot scenarios. Results indicate that traditional
clinical machine learning (ML) models generally outperform LLMs in zero-shot
and few-shot settings. However, the performance gap narrows significantly when
employing few-shot examples alongside effective explainable AI (XAI) methods as
sources of domain knowledge. Moreover, with sufficient time and an increased
number of examples, the conversational style (NC) nearly matches the
performance of ML models. Most notably, LLMs demonstrate comparable or superior
cost-sensitive accuracy relative to ML models.
  This research confirms that, with appropriate domain knowledge and tailored
communication strategies, LLMs can significantly enhance diagnostic processes.
The findings highlight the importance of optimizing the number of training
examples and communication styles to improve accuracy and reduce biases in LLM
applications.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) èé«çè¨ºæ·æ´å
çºè¨åºæ±ºç­æä¾äºä¸åæåæ¯çéå¾ãæ¬ç ç©¶æ¦è¿°äºä¸ç¨®æ°ç©æ¹æ³çéç¼ï¼ç¨æ¼é¶æ¬¡å­¸ç¿/å°éå­¸ç¿æå¢å­¸ç¿ (ICL)ï¼æ¹æ³æ¯ä½¿ç¨å¤å±¤çµæ§åæç¤ºæ´åé«çé åç¥è­ãæåéæ¢è¨äºä½¿ç¨èè LLM ä¹éå©ç¨®æºéæ¹å¼çåæï¼æ¸å¼å°è©± (NC) æ¹å¼ï¼å®æéæ­¥èçè³æï¼ä»¥åèªç¶èªè¨å®åå (NL-ST) æ¹å¼ï¼å®æä½¿ç¨é·ç¯æäºæç¤ºã
æåçç ç©¶ç³»çµ±æ§å°è©ä¼°äºè¨ºæ·æºç¢ºæ§åé¢¨éªå å­ï¼åæ¬æ§å¥åè¦ååé°æ§çï¼ä½¿ç¨äºä¸ååå« 920 åæ£èè¨éçè³æéï¼æ¡ç¨åç¨®å°éå­¸ç¿æå¢ãçµæè¡¨æï¼å³çµ±çè¨åºæ©å¨å­¸ç¿ (ML) æ¨¡åéå¸¸å¨é¶æ¬¡å­¸ç¿åå°éå­¸ç¿è¨­å®ä¸­è¡¨ç¾åªæ¼ LLMãç¶èï¼ç¶ä½¿ç¨å°éå­¸ç¿ç¯ä¾ä»¥åææçå¯è§£é AI (XAI) æ¹æ³ä½çºé åç¥è­ä¾æºæï¼æè½å·®è·æé¡¯èç¸®å°ãæ­¤å¤ï¼é¨èæéåè¶³åç¯ä¾æ¸éå¢å ï¼å°è©±æ¹å¼ (NC) å¹¾ä¹å¯ä»¥åª²ç¾ ML æ¨¡åçæè½ãæå¼å¾æ³¨æçæ¯ï¼LLM ç¸å°æ¼ ML æ¨¡åå±ç¾åºç¸ç¶ææ´ä½³çææ¬æææºç¢ºåº¦ã
æ¬ç ç©¶è­å¯¦ï¼ééé©ç¶çé åç¥è­åéèº«æé çæºéç­ç¥ï¼LLM å¯ä»¥é¡¯èå¢å¼·è¨ºæ·ç¨åºãéäºç¼ç¾çªé¡¯äºæä½³åè¨ç·´ç¯ä¾æ¸éåæºéæ¹å¼çéè¦æ§ï¼ä»¥æé«æºç¢ºåº¦ä¸¦æ¸å° LLM æç¨ä¸­çåå·®ã

##### **To Trust or Not to Trust: Towards a novel approach to measure trust for XAI systems**
2405.05766v1 by Miquel MirÃ³-Nicolau, Gabriel MoyÃ -Alcover, Antoni Jaume-i-CapÃ³, Manuel GonzÃ¡lez-Hidalgo, Maria Gemma Sempere Campello, Juan Antonio Palmer Sancho

The increasing reliance on Deep Learning models, combined with their inherent
lack of transparency, has spurred the development of a novel field of study
known as eXplainable AI (XAI) methods. These methods seek to enhance the trust
of end-users in automated systems by providing insights into the rationale
behind their decisions. This paper presents a novel approach for measuring user
trust in XAI systems, allowing their refinement. Our proposed metric combines
both performance metrics and trust indicators from an objective perspective. To
validate this novel methodology, we conducted a case study in a realistic
medical scenario: the usage of XAI system for the detection of pneumonia from
x-ray images.

æè¦ï¼é¨èå°æ·±åº¦å­¸ç¿æ¨¡åä¾è³´æ§çå¢å ï¼å ä¸å¶åºæçéæåº¦ä¸è¶³ï¼ä¿ä½¿ä¸åæ°çç ç©¶é åç¼å±ï¼ç¨±çºå¯è§£é AI (XAI) æ¹æ³ãéäºæ¹æ³æ¨å¨ééæ·±å¥äºè§£æ±ºç­èå¾çåçï¼ä¾æåæçµä½¿ç¨èå°èªååç³»çµ±çä¿¡è³´ãæ¬ææåºäºä¸ç¨®è¡¡éä½¿ç¨èå° XAI ç³»çµ±ä¿¡è³´åº¦çæ°ç©æ¹æ³ï¼åè¨±å°å¶é²è¡æ¹é²ãæåæåºçææ¨çµåäºå®¢è§è§é»ä¸çæè½ææ¨åä¿¡è³´ææ¨ãçºäºé©è­éåæ°ç©çæ¹æ³ï¼æåå¨ä¸åçå¯¦çé«çå ´æ¯ä¸­é²è¡äºä¸åæ¡ä¾ç ç©¶ï¼ä½¿ç¨ XAI ç³»çµ±å¾ X åå½±åä¸­åµæ¸¬èºçã

##### **Region-specific Risk Quantification for Interpretable Prognosis of COVID-19**
2405.02815v1 by Zhusi Zhong, Jie Li, Zhuoqi Ma, Scott Collins, Harrison Bai, Paul Zhang, Terrance Healey, Xinbo Gao, Michael K. Atalay, Zhicheng Jiao

The COVID-19 pandemic has strained global public health, necessitating
accurate diagnosis and intervention to control disease spread and reduce
mortality rates. This paper introduces an interpretable deep survival
prediction model designed specifically for improved understanding and trust in
COVID-19 prognosis using chest X-ray (CXR) images. By integrating a large-scale
pretrained image encoder, Risk-specific Grad-CAM, and anatomical region
detection techniques, our approach produces regional interpretable outcomes
that effectively capture essential disease features while focusing on rare but
critical abnormal regions. Our model's predictive results provide enhanced
clarity and transparency through risk area localization, enabling clinicians to
make informed decisions regarding COVID-19 diagnosis with better understanding
of prognostic insights. We evaluate the proposed method on a multi-center
survival dataset and demonstrate its effectiveness via quantitative and
qualitative assessments, achieving superior C-indexes (0.764 and 0.727) and
time-dependent AUCs (0.799 and 0.691). These results suggest that our
explainable deep survival prediction model surpasses traditional survival
analysis methods in risk prediction, improving interpretability for clinical
decision making and enhancing AI system trustworthiness.

æè¦ï¼COVID-19 ç«æå°å¨çå¬å±è¡çé æå£åï¼å¿é é²è¡æºç¢ºçè¨ºæ·åå¹²é ï¼ä»¥æ§å¶ç¾çå³æ­ä¸¦éä½æ­»äº¡çãæ¬æä»ç´¹äºä¸åå¯è§£éçæ·±åº¦çå­é æ¸¬æ¨¡åï¼å°éè¨­è¨ç¨æ¼ééè¸é¨ X å (CXR) å½±åæ¹åå° COVID-19 é å¾ççè§£åä¿¡è³´ãééæ´åå¤§è¦æ¨¡é è¨ç·´å½±åç·¨ç¢¼å¨ãé¢¨éªç¹å® Grad-CAM åè§£ååååµæ¸¬æè¡ï¼æåçåæ³ç¢çååå¯è§£éççµæï¼ææææå¿è¦çç¾çç¹å¾µï¼åæå°æ³¨æ¼ç½è¦ä½ééµçç°å¸¸ååãæåçæ¨¡åé æ¸¬çµæééé¢¨éªååå®ä½æä¾å¢å¼·çæ¸æ°åº¦åéæåº¦ï¼è®è¨åºé«çè½å¤ å¨æ´äºè§£é å¾è¦è§£çææ³ä¸ï¼å°± COVID-19 è¨ºæ·ååºææºçæ±ºç­ãæåå¨å¤ä¸­å¿çå­è³æéä¸è©ä¼°ææåºçæ¹æ³ï¼ä¸¦éééååè³ªåè©ä¼°è­æå¶æææ§ï¼éå°åªç°ç C ææ¸ï¼0.764 å 0.727ï¼åæéç¸é AUCï¼0.799 å 0.691ï¼ãéäºçµæè¡¨æï¼æåå¯è§£éçæ·±åº¦çå­é æ¸¬æ¨¡åå¨é¢¨éªé æ¸¬æ¹é¢è¶è¶å³çµ±ççå­åææ¹æ³ï¼æåè¨åºæ±ºç­çè§£éæ§ï¼ä¸¦å¢å¼· AI ç³»çµ±çä¿¡è³´åº¦ã

##### **Rad4XCNN: a new agnostic method for post-hoc global explanation of CNN-derived features by means of radiomics**
2405.02334v2 by Francesco Prinzi, Carmelo Militello, Calogero Zarcaro, Tommaso Vincenzo Bartolotta, Salvatore Gaglio, Salvatore Vitabile

In recent years, machine learning-based clinical decision support systems
(CDSS) have played a key role in the analysis of several medical conditions.
Despite their promising capabilities, the lack of transparency in AI models
poses significant challenges, particularly in medical contexts where
reliability is a mandatory aspect. However, it appears that explainability is
inversely proportional to accuracy. For this reason, achieving transparency
without compromising predictive accuracy remains a key challenge. This paper
presents a novel method, namely Rad4XCNN, to enhance the predictive power of
CNN-derived features with the inherent interpretability of radiomic features.
Rad4XCNN diverges from conventional methods based on saliency maps, by
associating intelligible meaning to CNN-derived features by means of Radiomics,
offering new perspectives on explanation methods beyond visualization maps.
Using a breast cancer classification task as a case study, we evaluated
Rad4XCNN on ultrasound imaging datasets, including an online dataset and two
in-house datasets for internal and external validation. Some key results are:
i) CNN-derived features guarantee more robust accuracy when compared against
ViT-derived and radiomic features; ii) conventional visualization map methods
for explanation present several pitfalls; iii) Rad4XCNN does not sacrifice
model accuracy for their explainability; iv) Rad4XCNN provides a global
explanation enabling the physician to extract global insights and findings. Our
method can mitigate some concerns related to the explainability-accuracy
trade-off. This study highlighted the importance of proposing new methods for
model explanation without affecting their accuracy.

æè¦ï¼<paragraph>è¿å¹´æ¥ï¼åºäºæºå¨å­¦ä¹ çä¸´åºå³ç­æ¯æç³»ç» (CDSS) å¨å¤ç§ç¾ççåæä¸­æ®æ¼äºå³é®è§è²ãå°½ç®¡å®ä»¬å·æå¹¿éçåæ¯ï¼ä½ AI æ¨¡åç¼ºä¹éæåº¦ï¼å°¤å¶å¨å»çé¢åï¼å¯é æ§æ¯å¼ºå¶æ§æ¹é¢ï¼è¿å¸¦æ¥äºéå¤§ææãç¶èï¼è§£éæ§ä¼¼ä¹ä¸åç¡®æ§æåæ¯ãå æ­¤ï¼å¨ä¸å½±åé¢æµåç¡®æ§çæåµä¸å®ç°éæåº¦ä»ç¶æ¯ä¸ä¸ªå³é®ææãæ¬ææåºäºä¸ç§æ°æ¹æ³ï¼å³ Rad4XCNNï¼ä»¥éè¿æ¾å°ç»å­¦çåå¨å¯è§£éæ§æ¥å¢å¼º CNN è¡çç¹å¾çé¢æµè½åãRad4XCNN éè¿æ¾å°ç»å­¦å°å¯çè§£çå«ä¹ä¸ CNN è¡çç¹å¾å³èèµ·æ¥ï¼ä»èåç¦»äºåºäºæ¾çæ§å¾çä¼ ç»æ¹æ³ï¼ä¸ºè¶è¶å¯è§åå¾çè§£éæ¹æ³æä¾äºæ°çè§è§ãä½¿ç¨ä¹³èºçåç±»ä»»å¡ä½ä¸ºæ¡ä¾ç ç©¶ï¼æä»¬å¨è¶å£°æåæ°æ®éä¸è¯ä¼°äº Rad4XCNNï¼åæ¬ä¸ä¸ªå¨çº¿æ°æ®éåä¸¤ä¸ªç¨äºåé¨åå¤é¨éªè¯çåé¨æ°æ®éãä¸äºå³é®ç»ææ¯ï¼i) ä¸ ViT è¡çåæ¾å°ç»å­¦ç¹å¾ç¸æ¯ï¼CNN è¡çç¹å¾ä¿è¯äºæ´ç¨³å¥çåç¡®æ§ï¼ii) ç¨äºè§£éçä¼ ç»å¯è§åå¾æ¹æ³å­å¨ä¸äºç¼ºé·ï¼iii) Rad4XCNN ä¸ä¼ä¸ºäºå¯è§£éæ§èçºç²æ¨¡ååç¡®æ§ï¼iv) Rad4XCNN æä¾å¨å±è§£éï¼ä½¿å»çè½å¤æåå¨å±è§è§£ååç°ãæä»¬çæ¹æ³å¯ä»¥åè½»ä¸äºä¸å¯è§£éæ§-åç¡®æ§æè¡¡ç¸å³çæå¿§ãæ¬ç ç©¶å¼ºè°äºæåºæ°æ¹æ³æ¥è§£éæ¨¡åèä¸å½±åå¶åç¡®æ§çéè¦æ§ã</paragraph>

##### **Attributing Responsibility in AI-Induced Incidents: A Computational Reflective Equilibrium Framework for Accountability**
2404.16957v1 by Yunfei Ge, Quanyan Zhu

The pervasive integration of Artificial Intelligence (AI) has introduced
complex challenges in the responsibility and accountability in the event of
incidents involving AI-enabled systems. The interconnectivity of these systems,
ethical concerns of AI-induced incidents, coupled with uncertainties in AI
technology and the absence of corresponding regulations, have made traditional
responsibility attribution challenging. To this end, this work proposes a
Computational Reflective Equilibrium (CRE) approach to establish a coherent and
ethically acceptable responsibility attribution framework for all stakeholders.
The computational approach provides a structured analysis that overcomes the
limitations of conceptual approaches in dealing with dynamic and multifaceted
scenarios, showcasing the framework's explainability, coherence, and adaptivity
properties in the responsibility attribution process. We examine the pivotal
role of the initial activation level associated with claims in equilibrium
computation. Using an AI-assisted medical decision-support system as a case
study, we illustrate how different initializations lead to diverse
responsibility distributions. The framework offers valuable insights into
accountability in AI-induced incidents, facilitating the development of a
sustainable and resilient system through continuous monitoring, revision, and
reflection.

æè¦ï¼é¨èäººå·¥æºæ§ (AI) çæ®åæ´åï¼å¨æ¶å AI é©åç³»çµ±çäºæä¸­ï¼è²¬ä»»åç¾©åæ­¸å±¬ç¢çäºè¤éçææ°ãéäºç³»çµ±çäºé£æ§ãAI å¼ç¼äºæçå«çåé¡ï¼å ä¸ AI æè¡çä¸ç¢ºå®æ§åç¼ºä¹ç¸ææ³è¦ï¼ä½¿å¾å³çµ±è²¬ä»»æ­¸å±¬é¢è¨ææ°ãçºæ­¤ï¼æ¬ç ç©¶æåºäºä¸ç¨®è¨ç®åæåè¡¡ (CRE) æ¹æ³ï¼ä»¥å»ºç«ä¸åé£è²«ä¸å¨å«çä¸å¯æ¥åçè²¬ä»»æ­¸å±¬æ¶æ§ï¼é©ç¨æ¼ææå©å®³éä¿äººãè¨ç®æ¹æ³æä¾äºçµæ§åçåæï¼åæäºæ¦å¿µæ¹æ³å¨èçåæä¸å¤é¢åæå¢æçéå¶ï¼å±ç¤ºäºè©²æ¶æ§å¨è²¬ä»»æ­¸å±¬éç¨ä¸­å·åçå¯è§£éæ§ãé£è²«æ§åé©ææ§ãæåæ¢è¨äºèåè¡¡è¨ç®ä¸­ç´¢è³ ç¸éçåå§ååå±¤ç´çééµä½ç¨ãæåä»¥ AI è¼å©é«çæ±ºç­æ¯æ´ç³»çµ±çºæ¡ä¾ç ç©¶ï¼èªªæä¸åçåå§åå¦ä½å°è´ä¸åçè²¬ä»»åéãè©²æ¶æ§æä¾äºå° AI å¼ç¼äºæä¸­åè²¬å¶çå¯¶è²´è¦è§£ï¼ééæçºç£æ§ãä¿®è¨ååæï¼ä¿é²äºæ°¸çºä¸æéæ§çç³»çµ±ç¼å±ã

##### **Explainable AI for Fair Sepsis Mortality Predictive Model**
2404.13139v1 by Chia-Hsuan Chang, Xiaoyang Wang, Christopher C. Yang

Artificial intelligence supports healthcare professionals with predictive
modeling, greatly transforming clinical decision-making. This study addresses
the crucial need for fairness and explainability in AI applications within
healthcare to ensure equitable outcomes across diverse patient demographics. By
focusing on the predictive modeling of sepsis-related mortality, we propose a
method that learns a performance-optimized predictive model and then employs
the transfer learning process to produce a model with better fairness. Our
method also introduces a novel permutation-based feature importance algorithm
aiming at elucidating the contribution of each feature in enhancing fairness on
predictions. Unlike existing explainability methods concentrating on explaining
feature contribution to predictive performance, our proposed method uniquely
bridges the gap in understanding how each feature contributes to fairness. This
advancement is pivotal, given sepsis's significant mortality rate and its role
in one-third of hospital deaths. Our method not only aids in identifying and
mitigating biases within the predictive model but also fosters trust among
healthcare stakeholders by improving the transparency and fairness of model
predictions, thereby contributing to more equitable and trustworthy healthcare
delivery.

æè¦ï¼äººå·¥æºæ§ééé æ¸¬æ¨¡ååå©é«çå°æ¥­äººå¡ï¼å¤§å¹è½è®äºè¨åºæ±ºç­å¶å®ãæ¬ç ç©¶æ¢è¨äºå¨é«çä¿å¥ä¸­ä½¿ç¨äººå·¥æºæ§æç¨ç¨å¼æå¬å¹³æ§åå¯è§£éæ§çééµéæ±ï¼ä»¥ç¢ºä¿å¨ä¸åçæ£èäººå£çµ±è¨è³æä¸­ç²å¾å¬å¹³ççµæãééå°æ³¨æ¼æè¡çç¸éæ­»äº¡ççé æ¸¬æ¨¡åï¼æåæåºäºä¸ç¨®æ¹æ³ï¼è©²æ¹æ³æå­¸ç¿ä¸åæè½æä½³åçé æ¸¬æ¨¡åï¼ç¶å¾æ¡ç¨è½ç§»å­¸ç¿éç¨ä¾ç¢çä¸åå·ææ´å¥½å¬å¹³æ§çæ¨¡åãæåçæ¨¡åéå¼å¥äºä¸ç¨®æ°ç©çåºæ¼æåçç¹å¾µéè¦æ§æ¼ç®æ³ï¼æ¨å¨é¡ææ¯åç¹å¾µå¨å¢å¼·é æ¸¬å¬å¹³æ§æ¹é¢çè²¢ç»ãèç¾æçå¯è§£éæ§æ¹æ³å°æ³¨æ¼è§£éç¹å¾µå°é æ¸¬æè½çè²¢ç»ä¸åï¼æåæåºçæ¹æ³ç¨ç¹å°å½è£äºçè§£æ¯åç¹å¾µå¦ä½æå©æ¼å¬å¹³æ§çå·®è·ãéé é²å±è³ééè¦ï¼å çºæè¡ççæ­»äº¡çå¾é«ï¼ä¸å¨ä¸åä¹ä¸çé«é¢æ­»äº¡ä¸­æ®æ¼èè§è²ãæåçæ¨¡åä¸åæå©æ¼è­å¥åæ¸è¼é æ¸¬æ¨¡åä¸­çåå·®ï¼éè½ééæé«æ¨¡åé æ¸¬çéæåº¦åå¬å¹³æ§ä¾å¹é¤é«çä¿å¥å©çç¸éèä¹éçä¿¡ä»»ï¼é²èæå©æ¼æä¾æ´å¬å¹³ä¸å¼å¾ä¿¡è³´çé«çä¿å¥æåã

##### **Multi Class Depression Detection Through Tweets using Artificial Intelligence**
2404.13104v1 by Muhammad Osama Nusrat, Waseem Shahzad, Saad Ahmed Jamal

Depression is a significant issue nowadays. As per the World Health
Organization (WHO), in 2023, over 280 million individuals are grappling with
depression. This is a huge number; if not taken seriously, these numbers will
increase rapidly. About 4.89 billion individuals are social media users. People
express their feelings and emotions on platforms like Twitter, Facebook,
Reddit, Instagram, etc. These platforms contain valuable information which can
be used for research purposes. Considerable research has been conducted across
various social media platforms. However, certain limitations persist in these
endeavors. Particularly, previous studies were only focused on detecting
depression and the intensity of depression in tweets. Also, there existed
inaccuracies in dataset labeling. In this research work, five types of
depression (Bipolar, major, psychotic, atypical, and postpartum) were predicted
using tweets from the Twitter database based on lexicon labeling. Explainable
AI was used to provide reasoning by highlighting the parts of tweets that
represent type of depression. Bidirectional Encoder Representations from
Transformers (BERT) was used for feature extraction and training. Machine
learning and deep learning methodologies were used to train the model. The BERT
model presented the most promising results, achieving an overall accuracy of
0.96.

æè¦ï¼ç¾ä»ï¼æé¬±çæ¯ä¸åéè¦çè­°é¡ãæ ¹æä¸çè¡ççµç¹ (WHO) çè³æï¼å¨ 2023 å¹´ï¼è¶é 2.8 åäººæ­£å¨èæé¬±çæé¬¥ãéæ¯ä¸åé¾å¤§çæ¸å­ï¼å¦æä¸èªççå¾ï¼éäºæ¸å­å°æå¿«éå¢å ãå¤§ç´æ 48.9 åäººæ¯ç¤¾ç¾¤åªé«ä½¿ç¨èãäººåå¨ TwitterãFacebookãRedditãInstagram ç­å¹³å°ä¸è¡¨éèªå·±çæååæç·ãéäºå¹³å°åå«æå¹å¼çè³è¨ï¼å¯ç¨æ¼ç ç©¶ç®çãå·²ç¶å¨åç¨®ç¤¾ç¾¤åªé«å¹³å°ä¸é²è¡äºå¤§éçç ç©¶ãç¶èï¼éäºåªåä»å­å¨æäºéå¶ãç¹å¥æ¯ï¼ååçç ç©¶åå°æ³¨æ¼åµæ¸¬æ¨æä¸­çæé¬±çåæé¬±ççå¼·åº¦ãæ­¤å¤ï¼è³æéæ¨ç±¤ä¸­å­å¨ä¸æºç¢ºçææ³ãå¨éé ç ç©¶å·¥ä½ä¸­ï¼ä½¿ç¨åºæ¼è©å½æ¨ç±¤ç Twitter è³æåº«ä¸­çæ¨æé æ¸¬äºäºç¨®é¡åçæé¬±çï¼éæ¥µåãéåº¦ãç²¾ç¥çåãéå¸ååç¢å¾ï¼ãå¯è§£éç AI ç¨æ¼ééå¼·èª¿ä»£è¡¨æé¬±çé¡åçæ¨æé¨åä¾æä¾æ¨çãå¾ Transformersï¼BERTï¼ä¸­æåçéåç·¨ç¢¼å¨è¡¨ç¤ºç¨æ¼ç¹å¾µæååè¨ç·´ãæ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿æ¹æ³ç¨æ¼è¨ç·´æ¨¡åãBERT æ¨¡ååç¾åºææå¸æççµæï¼éå° 0.96 çæ´é«æºç¢ºåº¦ã

##### **COIN: Counterfactual inpainting for weakly supervised semantic segmentation for medical images**
2404.12832v2 by Dmytro Shvetsov, Joonas Ariva, Marharyta Domnich, Raul Vicente, Dmytro Fishman

Deep learning is dramatically transforming the field of medical imaging and
radiology, enabling the identification of pathologies in medical images,
including computed tomography (CT) and X-ray scans. However, the performance of
deep learning models, particularly in segmentation tasks, is often limited by
the need for extensive annotated datasets. To address this challenge, the
capabilities of weakly supervised semantic segmentation are explored through
the lens of Explainable AI and the generation of counterfactual explanations.
The scope of this research is development of a novel counterfactual inpainting
approach (COIN) that flips the predicted classification label from abnormal to
normal by using a generative model. For instance, if the classifier deems an
input medical image X as abnormal, indicating the presence of a pathology, the
generative model aims to inpaint the abnormal region, thus reversing the
classifier's original prediction label. The approach enables us to produce
precise segmentations for pathologies without depending on pre-existing
segmentation masks. Crucially, image-level labels are utilized, which are
substantially easier to acquire than creating detailed segmentation masks. The
effectiveness of the method is demonstrated by segmenting synthetic targets and
actual kidney tumors from CT images acquired from Tartu University Hospital in
Estonia. The findings indicate that COIN greatly surpasses established
attribution methods, such as RISE, ScoreCAM, and LayerCAM, as well as an
alternative counterfactual explanation method introduced by Singla et al. This
evidence suggests that COIN is a promising approach for semantic segmentation
of tumors in CT images, and presents a step forward in making deep learning
applications more accessible and effective in healthcare, where annotated data
is scarce.

æè¦ï¼æ·±åº¦å­¦ä¹ æ­£å¤§å¹è½è®é«å­¸å½±ååæ¾å°ç·å­¸é åï¼è½è¾¨è­é«å­¸å½±åä¸­çççï¼åæ¬é»è¦æ·å±¤ææ (CT) å X åææãç¶èï¼æ·±åº¦å­¸ç¿æ¨¡åçæè½ï¼ç¹å¥æ¯å¨åå²ä»»åä¸­ï¼å¸¸å¸¸åå°å»£æ³è¨»è§£è³æééæ±çéå¶ãçºäºæå°æ­¤ææ°ï¼ééå¯è§£é AI ååäºå¯¦è§£éçç¢çï¼æ¢ç´¢å¼±ç£ç£èªæåå²çè½åãæ¬ç ç©¶çç¯åæ¯éç¼ä¸ç¨®æ°çåäºå¯¦å§ææ¹æ³ (COIN)ï¼è©²æ¹æ³ä½¿ç¨çææ¨¡åå°é æ¸¬çåé¡æ¨ç±¤å¾ç°å¸¸ç¿»è½çºæ­£å¸¸ãä¾å¦ï¼å¦æåé¡å¨å°è¼¸å¥çé«å­¸å½±å X è¦çºç°å¸¸ï¼è¡¨ç¤ºå­å¨ççï¼åçææ¨¡åæ¨å¨å§æç°å¸¸ååï¼å¾èéè½åé¡å¨çåå§é æ¸¬æ¨ç±¤ãæ­¤æ¹æ³ä½¿æåè½å¤ ç¢ççççç²¾ç¢ºåå²ï¼èç¡éä¾è³´æ¼é åå­å¨çåå²é®ç½©ãè³ééè¦çæ¯ï¼å©ç¨å½±åå±¤ç´æ¨ç±¤ï¼éæ¯å»ºç«è©³ç´°çåå²é®ç½©å®¹æåå¾ãè©²æ¹æ³çæææ§ééåå²åæç®æ¨åå¾ææ²å°¼äºå¡ç¾åå¤§å­¸é«é¢åå¾ç CT å½±åä¸­çå¯¦éèèè«ç¤ä¾è­æãç ç©¶çµæè¡¨æï¼COIN é é è¶éå·²å»ºç«çæ­¸å æ¹æ³ï¼ä¾å¦ RISEãScoreCAM å LayerCAMï¼ä»¥å Singla ç­äººæåºçå¦ä¸ç¨®åäºå¯¦è§£éæ¹æ³ãæ­¤è­æè¡¨æï¼COIN æ¯ä¸ç¨®å¾æåéç CT å½±åä¸­è«ç¤èªæåå²æ¹æ³ï¼ä¸¦å¨é«çä¿å¥ä¸­è®æ·±åº¦å­¸ç¿æç¨æ´ææ¼åå¾åæ´ææçéé²ä¸æ­¥ï¼å¶ä¸­è¨»è§£è³æå¾ç¨å°ã

##### **Hybrid Intelligence for Digital Humanities**
2406.15374v1 by Victor de Boer, Lise Stork

In this paper, we explore the synergies between Digital Humanities (DH) as a
discipline and Hybrid Intelligence (HI) as a research paradigm. In DH research,
the use of digital methods and specifically that of Artificial Intelligence is
subject to a set of requirements and constraints. We argue that these are
well-supported by the capabilities and goals of HI. Our contribution includes
the identification of five such DH requirements: Successful AI systems need to
be able to 1) collaborate with the (human) scholar; 2) support data criticism;
3) support tool criticism; 4) be aware of and cater to various perspectives and
5) support distant and close reading. We take the CARE principles of Hybrid
Intelligence (collaborative, adaptive, responsible and explainable) as
theoretical framework and map these to the DH requirements. In this mapping, we
include example research projects. We finally address how insights from DH can
be applied to HI and discuss open challenges for the combination of the two
disciplines.

æè¦ï¼å¨æ¬æä¸­ï¼æåæ¢è¨æ¸ä½äººæå­¸ç§ (DH) ä½çºä¸éå­¸ç§èæ··åæºè½ (HI) ä½çºä¸åç ç©¶å¸ç¯ä¹éçååä½ç¨ãå¨ DH ç ç©¶ä¸­ï¼æ¸ä½æ¹æ³çä½¿ç¨ï¼ç¹å¥æ¯äººå·¥æºæ§çä½¿ç¨ï¼åå°ä¸ç³»åè¦æ±åéå¶ãæåèªçºéäºè¦æ±åéå¶ç²å¾ HI çè½ååç®æ¨çååæ¯æãæåçè²¢ç»åæ¬æ¾åºäºåéæ¨£ç DH è¦æ±ï¼æåç AI ç³»çµ±éè¦è½å¤  1) èï¼äººé¡ï¼å­¸èåä½ï¼2) æ¯æ´è³ææ¹è©ï¼3) æ¯æ´å·¥å·æ¹è©ï¼4) å¯è¦ºä¸¦è¿ååç¨®è§é»ï¼5) æ¯æ´é è·åè¿è·é¢é±è®ãæåå°æ··åæºè½ç CARE ååï¼åä½ãé©æãè² è²¬åå¯è§£éï¼ä½çºçè«æ¶æ§ï¼ä¸¦å°éäºååå°æå° DH è¦æ±ãå¨æ­¤å°æä¸­ï¼æåç´å¥ç¯ä¾ç ç©¶å°æ¡ãæå¾ï¼æåæ¢è¨å¦ä½å° DH çè¦è§£æç¨æ¼ HIï¼ä¸¦è¨è«çµåéå©åå­¸ç§çéæ¾ææ°ã

##### **Ethical Framework for Responsible Foundational Models in Medical Imaging**
2406.11868v1 by Abhijit Das, Debesh Jha, Jasmer Sanjotra, Onkar Susladkar, Suramyaa Sarkar, Ashish Rauniyar, Nikhil Tomar, Vanshali Sharma, Ulas Bagci

Foundational models (FMs) have tremendous potential to revolutionize medical
imaging. However, their deployment in real-world clinical settings demands
extensive ethical considerations. This paper aims to highlight the ethical
concerns related to FMs and propose a framework to guide their responsible
development and implementation within medicine. We meticulously examine ethical
issues such as privacy of patient data, bias mitigation, algorithmic
transparency, explainability and accountability. The proposed framework is
designed to prioritize patient welfare, mitigate potential risks, and foster
trust in AI-assisted healthcare.

æè¦ï¼åºç¤æ¨¡å (FM) å·æå¾¹åºæ¹è®é«å­¸å½±åçå·¨å¤§æ½åãç¶èï¼å®åå¨ç¾å¯¦ä¸çè¨åºç°å¢ä¸­çé¨ç½²éè¦å»£æ³çå«çèéãæ¬ææ¨å¨å¼·èª¿è FM ç¸éçå«çåé¡ï¼ä¸¦æåºä¸åæ¡æ¶ä¾æå°å®åå¨é«å­¸ä¸­çè² è²¬ä»»éç¼åå¯¦æ½ãæåä»ç´°å¯©æ¥äºå«çåé¡ï¼ä¾å¦æ£èæ¸æé±ç§ãåå·®ç·©è§£ãæ¼ç®æ³éæåº¦ãå¯è§£éæ§ååè²¬å¶ãææåºçæ¡æ¶æ¨å¨åªåèæ®æ£èç¦å©ãæ¸è¼æ½å¨é¢¨éªï¼ä¸¦å¹é¤å° AI è¼å©é«çä¿å¥çä¿¡ä»»ã

##### **Advancements in Radiomics and Artificial Intelligence for Thyroid Cancer Diagnosis**
2404.07239v1 by Milad Yousefi, Shadi Farabi Maleki, Ali Jafarizadeh, Mahya Ahmadpour Youshanlui, Aida Jafari, Siamak Pedrammehr, Roohallah Alizadehsani, Ryszard Tadeusiewicz, Pawel Plawiak

Thyroid cancer is an increasing global health concern that requires advanced
diagnostic methods. The application of AI and radiomics to thyroid cancer
diagnosis is examined in this review. A review of multiple databases was
conducted in compliance with PRISMA guidelines until October 2023. A
combination of keywords led to the discovery of an English academic publication
on thyroid cancer and related subjects. 267 papers were returned from the
original search after 109 duplicates were removed. Relevant studies were
selected according to predetermined criteria after 124 articles were eliminated
based on an examination of their abstract and title. After the comprehensive
analysis, an additional six studies were excluded. Among the 28 included
studies, radiomics analysis, which incorporates ultrasound (US) images,
demonstrated its effectiveness in diagnosing thyroid cancer. Various results
were noted, some of the studies presenting new strategies that outperformed the
status quo. The literature has emphasized various challenges faced by AI
models, including interpretability issues, dataset constraints, and operator
dependence. The synthesized findings of the 28 included studies mentioned the
need for standardization efforts and prospective multicenter studies to address
these concerns. Furthermore, approaches to overcome these obstacles were
identified, such as advances in explainable AI technology and personalized
medicine techniques. The review focuses on how AI and radiomics could transform
the diagnosis and treatment of thyroid cancer. Despite challenges, future
research on multidisciplinary cooperation, clinical applicability validation,
and algorithm improvement holds the potential to improve patient outcomes and
diagnostic precision in the treatment of thyroid cancer.

æè¦ï¼ç²çèºçæ¯ä¸ç¨®æ¥çå´éçå¨çå¥åº·åé¡ï¼éè¦åé²çè¨ºæ·æ¹æ³ãæ¬ç¯è©è«æ¢è¨äºäººå·¥æºè½èæ¾å°ç¹å¾µåæå¨ç²çèºçè¨ºæ·ä¸­çæç¨ãå¨ç¬¦å PRISMA æåçææ³ä¸ï¼å°å¤åè³æåº«é²è¡äºåé¡§ï¼ç´å° 2023 å¹´ 10 æãééçµåééµå­ï¼ç¼ç¾äºä¸ç¯éæ¼ç²çèºçåç¸éä¸»é¡çè±æå­¸è¡åºçç©ãå¨ç§»é¤ 109 ç¯éè¤æç»å¾ï¼åå§æå°å±åå³ 267 ç¯è«æãå¨æ ¹æé åç¢ºå®çæ¨æºï¼æ·æ±°äº 124 ç¯æç« çæè¦åæ¨é¡å¾ï¼é¸åºäºç¸éç ç©¶ãå¨é²è¡å¨é¢åæå¾ï¼é¡å¤æé¤äºå­é ç ç©¶ãå¨ç´å¥ç 28 é ç ç©¶ä¸­ï¼çµåè¶é³æ³¢ (US) å½±åçæ¾å°ç¹å¾µåæï¼è­æäºå¶å¨è¨ºæ·ç²çèºçæ¹é¢çæææ§ãç ç©¶çµæä¸ä¸ï¼æäºç ç©¶æåºäºåªæ¼ç¾ççæ°ç­ç¥ãæç»å¼·èª¿äºäººå·¥æºè½æ¨¡åé¢è¨çåç¨®ææ°ï¼åæ¬å¯è§£éæ§åé¡ãè³æééå¶åæä½å¡ä¾è³´æ§ã28 é ç´å¥ç ç©¶çç¶åç¼ç¾æå°ï¼éè¦æ¨æºåå·¥ä½ååç»æ§å¤ä¸­å¿ç ç©¶ä¾è§£æ±ºéäºåé¡ãæ­¤å¤ï¼éç¢ºå®äºåæéäºéç¤çæ¹æ³ï¼ä¾å¦å¯è§£éäººå·¥æºè½æè¡ååäººåé«çæè¡çé²æ­¥ãæ¬ç¯è©è«éé»æ¢è¨äºäººå·¥æºè½åæ¾å°ç¹å¾µåæå¦ä½è½è®ç²çèºççè¨ºæ·åæ²»çãåç®¡å­å¨ææ°ï¼ä½æªä¾å°å¤å­¸ç§åä½ãè¨åºé©ç¨æ§é©è­åæ¼ç®æ³æ¹é²çç ç©¶ï¼ä»ææ½åæ¹åç²çèºçæ²»çä¸­çæ£èé å¾åè¨ºæ·ç²¾æºåº¦ã

##### **Predictive Modeling for Breast Cancer Classification in the Context of Bangladeshi Patients: A Supervised Machine Learning Approach with Explainable AI**
2404.04686v1 by Taminul Islam, Md. Alif Sheakh, Mst. Sazia Tahosin, Most. Hasna Hena, Shopnil Akash, Yousef A. Bin Jardan, Gezahign Fentahun Wondmie, Hiba-Allah Nafidi, Mohammed Bourhia

Breast cancer has rapidly increased in prevalence in recent years, making it
one of the leading causes of mortality worldwide. Among all cancers, it is by
far the most common. Diagnosing this illness manually requires significant time
and expertise. Since detecting breast cancer is a time-consuming process,
preventing its further spread can be aided by creating machine-based forecasts.
Machine learning and Explainable AI are crucial in classification as they not
only provide accurate predictions but also offer insights into how the model
arrives at its decisions, aiding in the understanding and trustworthiness of
the classification results. In this study, we evaluate and compare the
classification accuracy, precision, recall, and F-1 scores of five different
machine learning methods using a primary dataset (500 patients from Dhaka
Medical College Hospital). Five different supervised machine learning
techniques, including decision tree, random forest, logistic regression, naive
bayes, and XGBoost, have been used to achieve optimal results on our dataset.
Additionally, this study applied SHAP analysis to the XGBoost model to
interpret the model's predictions and understand the impact of each feature on
the model's output. We compared the accuracy with which several algorithms
classified the data, as well as contrasted with other literature in this field.
After final evaluation, this study found that XGBoost achieved the best model
accuracy, which is 97%.

æè¦ï¼<paragraph>è¿å¹´ä¾ï¼ä¹³çççè¡çè¿éå¢å ï¼ä½¿å¶æçºå¨çä¸»è¦çæ­»äº¡åå ä¹ä¸ãå¨ææççä¸­ï¼ä¹³çè¿ä»çºæ­¢æ¯æå¸¸è¦çãæåè¨ºæ·æ­¤ç¾çéè¦å¤§éçæéåå°æ¥­ç¥è­ãç±æ¼ä¹³ççæª¢æ¸¬éç¨èæï¼å æ­¤ééå»ºç«æ©å¨å­¸ç¿æ¨¡åä¾é æ¸¬ï¼æå©æ¼é²æ­¢å¶é²ä¸æ­¥æ´æ£ãæ©å¨å­¸ç¿åå¯è§£é AI å¨åé¡ä¸­è³ééè¦ï¼å çºå®åä¸åå¯ä»¥æä¾æºç¢ºçé æ¸¬ï¼éå¯ä»¥æ·±å¥äºè§£æ¨¡åå¦ä½ååºæ±ºç­ï¼æå©æ¼çè§£åä¿¡è³´åé¡çµæãå¨æ­¤ç ç©¶ä¸­ï¼æåè©ä¼°ä¸¦æ¯è¼äºäºç¨®ä¸åçæ©å¨å­¸ç¿æ¹æ³çåé¡æºç¢ºåº¦ãç²¾ç¢ºåº¦ãå¬åçå F1 åæ¸ï¼ä½¿ç¨äºä¸åä¸»è¦çè³æéï¼éå¡é«å­¸é¢é«é¢ç 500 åæ£èï¼ãäºç¨®ä¸åçç£ç£å¼æ©å¨å­¸ç¿æè¡ï¼åæ¬æ±ºç­æ¨¹ãé¨æ©æ£®æãéè¼¯è¿´æ­¸ãæ´ç´ è²æ°å XGBoostï¼å·²ç¨æ¼å¨æåçè³æéä¸åå¾æä½³çµæãæ­¤å¤ï¼æ¬ç ç©¶å° SHAP åææç¨æ¼ XGBoost æ¨¡åï¼ä»¥è§£éæ¨¡åçé æ¸¬ä¸¦äºè§£æ¯åç¹å¾µå°æ¨¡åè¼¸åºçå½±é¿ãæåæ¯è¼äºå¹¾ç¨®æ¼ç®æ³å°è³æé²è¡åé¡çæºç¢ºåº¦ï¼ä¸¦èè©²é åçå¶ä»æç»é²è¡å°æ¯ãå¨æå¾è©ä¼°å¾ï¼æ¬ç ç©¶ç¼ç¾ XGBoost éå°äºæä½³çæ¨¡åæºç¢ºåº¦ï¼çº 97%ã</paragraph>

##### **Enhancing Breast Cancer Diagnosis in Mammography: Evaluation and Integration of Convolutional Neural Networks and Explainable AI**
2404.03892v3 by Maryam Ahmed, Tooba Bibi, Rizwan Ahmed Khan, Sidra Nasir

The Deep learning (DL) models for diagnosing breast cancer from mammographic
images often operate as "black boxes", making it difficult for healthcare
professionals to trust and understand their decision-making processes. The
study presents an integrated framework combining Convolutional Neural Networks
(CNNs) and Explainable Artificial Intelligence (XAI) for the enhanced diagnosis
of breast cancer using the CBIS-DDSM dataset. The methodology encompasses an
elaborate data preprocessing pipeline and advanced data augmentation techniques
to counteract dataset limitations and transfer learning using pre-trained
networks such as VGG-16, Inception-V3 and ResNet was employed. A focal point of
our study is the evaluation of XAI's effectiveness in interpreting model
predictions, highlighted by utilizing the Hausdorff measure to assess the
alignment between AI-generated explanations and expert annotations
quantitatively. This approach is critical for XAI in promoting trustworthiness
and ethical fairness in AI-assisted diagnostics. The findings from our research
illustrate the effective collaboration between CNNs and XAI in advancing
diagnostic methods for breast cancer, thereby facilitating a more seamless
integration of advanced AI technologies within clinical settings. By enhancing
the interpretability of AI driven decisions, this work lays the groundwork for
improved collaboration between AI systems and medical practitioners, ultimately
enriching patient care. Furthermore, the implications of our research extended
well beyond the current methodologies. It encourages further research into how
to combine multimodal data and improve AI explanations to meet the needs of
clinical practice.

æè¦ï¼æ·±åº¦å­¸ç¿ (DL) ç¨æ¼å¾ä¹³æ¿æå½±è¡å½±åè¨ºæ·ä¹³ççæ¨¡åéå¸¸ä»¥ãé»çå­ãæ¹å¼éä½ï¼éä½¿å¾é«çä¿å¥å°æ¥­äººå¡é£ä»¥ä¿¡ä»»åçè§£å¶æ±ºç­éç¨ãæ¬ç ç©¶æåºä¸åæ´åæ¶æ§ï¼çµåå·ç©ç¥ç¶ç¶²è·¯ (CNN) åå¯è§£éäººå·¥æºæ§ (XAI)ï¼ä»¥ä½¿ç¨ CBIS-DDSM è³æéå¢å¼·ä¹³ççè¨ºæ·ãæ¹æ³åå«ä¸åç²¾ç´°çè³æåèçç®¡ç·åé²éè³ææ´åæè¡ï¼ä»¥å°æè³æééå¶ï¼ä¸¦æ¡ç¨é åè¨ç·´çç¶²è·¯ï¼ä¾å¦ VGG-16ãInception-V3 å ResNetï¼é²è¡é·ç§»å­¸ç¿ãæåç ç©¶çéé»æ¯è©ä¼° XAI å¨è§£éæ¨¡åé æ¸¬ä¸­çæææ§ï¼éé»å©ç¨è±ªæ¯å¤å¤«æ¸¬åº¦éåè©ä¼° AI çæçè§£éåå°å®¶è¨»è§£ä¹éçä¸è´æ§ãéç¨®æ¹æ³å°æ¼ XAI å¨ä¿é² AI è¼å©è¨ºæ·ä¸­çå¯ä¿¡åº¦åå«çå¬å¹³æ§è³ééè¦ãæåç ç©¶çç¼ç¾èªªæäº CNN å XAI å¨æ¨é²ä¹³çè¨ºæ·æ¹æ³ä¸­çææåä½ï¼å¾èä¿é²äºåé² AI æè¡å¨è¨åºç°å¢ä¸­çæ´é æ¢æ´åãééå¢å¼· AI é©åæ±ºç­çå¯è§£éæ§ï¼éé å·¥ä½çº AI ç³»çµ±åé«çå¾æ¥­äººå¡ä¹éçæ¹ååä½å¥ å®äºåºç¤ï¼æçµè±å¯äºæ£èç§è­·ãæ­¤å¤ï¼æåç ç©¶çå½±é¿é é è¶åºäºç®åçæè¡ãå®é¼åµé²ä¸æ­¥ç ç©¶å¦ä½çµåå¤æ¨¡å¼è³æä¸¦æ¹å AI è§£éï¼ä»¥æ»¿è¶³è¨åºå¯¦åçéæ±ã

##### **Advancing Multimodal Data Fusion in Pain Recognition: A Strategy Leveraging Statistical Correlation and Human-Centered Perspectives**
2404.00320v2 by Xingrui Gu, Zhixuan Wang, Irisa Jin, Zekun Wu

This research presents a novel multimodal data fusion methodology for pain
behavior recognition, integrating statistical correlation analysis with
human-centered insights. Our approach introduces two key innovations: 1)
integrating data-driven statistical relevance weights into the fusion strategy
to effectively utilize complementary information from heterogeneous modalities,
and 2) incorporating human-centric movement characteristics into multimodal
representation learning for detailed modeling of pain behaviors. Validated
across various deep learning architectures, our method demonstrates superior
performance and broad applicability. We propose a customizable framework that
aligns each modality with a suitable classifier based on statistical
significance, advancing personalized and effective multimodal fusion.
Furthermore, our methodology provides explainable analysis of multimodal data,
contributing to interpretable and explainable AI in healthcare. By highlighting
the importance of data diversity and modality-specific representations, we
enhance traditional fusion techniques and set new standards for recognizing
complex pain behaviors. Our findings have significant implications for
promoting patient-centered healthcare interventions and supporting explainable
clinical decision-making.

æè¦ï¼æ¬ç ç©¶æåºäºä¸ç¨®åµæ°çå¤æ¨¡ææ¸æèåæ¹æ³ï¼ç¨æ¼ç¼çè¡çºè­å¥ï¼å°çµ±è¨ç¸éåæèä»¥äººçºä¸­å¿çè¦è§£ç¸çµåãæåçåæ³å¼å¥äºå©é ééµåµæ°ï¼1) å°æ¸æé©åççµ±è¨ç¸éæ¬éæ´åå°èåç­ç¥ä¸­ï¼ä»¥ææå©ç¨ä¾èªç°è³ªæ¨¡æçè£åä¿¡æ¯ï¼ä»¥å 2) å°ä»¥äººçºä¸­å¿çéåç¹å¾µç´å¥å¤æ¨¡æè¡¨ç¤ºå­¸ç¿ä¸­ï¼ä»¥è©³ç´°å»ºæ¨¡ç¼çè¡çºãæåçæ¨¡åå¨åç¨®æ·±åº¦å­¸ç¿æ¶æ§ä¸­å¾å°é©è­ï¼å±ç¤ºäºåè¶çæ§è½åå»£æ³çé©ç¨æ§ãæåæåºäºä¸åå¯èªå®ç¾©çæ¡æ¶ï¼æ ¹æçµ±è¨é¡¯èæ§å°æ¯åæ¨¡æèåé©çåé¡å¨å°é½ï¼æ¨é²åæ§ååææçå¤æ¨¡æèåãæ­¤å¤ï¼æåçæ¨¡åæä¾å°å¤æ¨¡ææ¸æçå¯è§£éåæï¼æå©æ¼é«çä¿å¥ä¸­çå¯è§£éåå¯è§£é AIãééå¼·èª¿æ¸æå¤æ¨£æ§åæ¨¡æç¹å®è¡¨ç¤ºçéè¦æ§ï¼æåå¢å¼·äºå³çµ±çèåæè¡ï¼ä¸¦çºè­å¥è¤éçç¼çè¡çºè¨­å®äºæ°çæ¨æºãæåçç¼ç¾å°ä¿é²ä»¥æ£èçºä¸­å¿çé«çä¿å¥å¹²é åæ¯æå¯è§£éçè¨åºæ±ºç­å¶å®å·æéè¦æç¾©ã

##### **Addressing Social Misattributions of Large Language Models: An HCXAI-based Approach**
2403.17873v1 by Andrea Ferrario, Alberto Termine, Alessandro Facchini

Human-centered explainable AI (HCXAI) advocates for the integration of social
aspects into AI explanations. Central to the HCXAI discourse is the Social
Transparency (ST) framework, which aims to make the socio-organizational
context of AI systems accessible to their users. In this work, we suggest
extending the ST framework to address the risks of social misattributions in
Large Language Models (LLMs), particularly in sensitive areas like mental
health. In fact LLMs, which are remarkably capable of simulating roles and
personas, may lead to mismatches between designers' intentions and users'
perceptions of social attributes, risking to promote emotional manipulation and
dangerous behaviors, cases of epistemic injustice, and unwarranted trust. To
address these issues, we propose enhancing the ST framework with a fifth
'W-question' to clarify the specific social attributions assigned to LLMs by
its designers and users. This addition aims to bridge the gap between LLM
capabilities and user perceptions, promoting the ethically responsible
development and use of LLM-based technology.

æè¦ï¼ä»¥äººä¸ºæ¬çå¯è§£é AI (HCXAI) å¡å¯¼å°ç¤¾ä¼å±é¢æ´åå° AI è§£éä¸­ãHCXAI è¯è¯­çæ ¸å¿æ¯ç¤¾ä¼éæåº¦ (ST) æ¡æ¶ï¼å¶ç®æ æ¯è®© AI ç³»ç»çç¤¾ä¼ç»ç»èæ¯å¯¹ç¨æ·æ¥è¯´æ¯å¯çè§£çãå¨è¿é¡¹å·¥ä½ä¸­ï¼æä»¬å»ºè®®æ©å± ST æ¡æ¶ä»¥è§£å³å¤§åè¯­è¨æ¨¡å (LLM) ä¸­ç¤¾ä¼éè¯¯å½å çé£é©ï¼å°¤å¶æ¯å¨å¿çå¥åº·ç­ææé¢åãäºå®ä¸ï¼LLM è½å¤åºè²å°æ¨¡æè§è²åäººæ ¼ï¼è¿å¯è½å¯¼è´è®¾è®¡èçæå¾åç¨æ·å¯¹ç¤¾ä¼å±æ§çè®¤ç¥ä¹é´åºç°ééï¼ä»èæé£é©ä¿è¿æç»ªæçºµåå±é©è¡ä¸ºãè®¤ç¥ä¸å¬æ­£åä¸åççä¿¡ä»»ãä¸ºäºè§£å³è¿äºé®é¢ï¼æä»¬å»ºè®®ç¨ç¬¬äºä¸ªâW é®é¢âæ¥å¢å¼º ST æ¡æ¶ï¼ä»¥æç¡®è®¾è®¡èåç¨æ·èµäº LLM çå·ä½ç¤¾ä¼å±æ§ãæ­¤è¡¥åæ¨å¨å¼¥å LLM è½ååç¨æ·è®¤ç¥ä¹é´çå·®è·ï¼ä¿è¿åºäº LLM çææ¯å¨éå¾·ä¸è´è´£ä»»å°å¼ååä½¿ç¨ã

##### **Clinical Domain Knowledge-Derived Template Improves Post Hoc AI Explanations in Pneumothorax Classification**
2403.18871v1 by Han Yuan, Chuan Hong, Pengtao Jiang, Gangming Zhao, Nguyen Tuan Anh Tran, Xinxing Xu, Yet Yen Yan, Nan Liu

Background: Pneumothorax is an acute thoracic disease caused by abnormal air
collection between the lungs and chest wall. To address the opaqueness often
associated with deep learning (DL) models, explainable artificial intelligence
(XAI) methods have been introduced to outline regions related to pneumothorax
diagnoses made by DL models. However, these explanations sometimes diverge from
actual lesion areas, highlighting the need for further improvement. Method: We
propose a template-guided approach to incorporate the clinical knowledge of
pneumothorax into model explanations generated by XAI methods, thereby
enhancing the quality of these explanations. Utilizing one lesion delineation
created by radiologists, our approach first generates a template that
represents potential areas of pneumothorax occurrence. This template is then
superimposed on model explanations to filter out extraneous explanations that
fall outside the template's boundaries. To validate its efficacy, we carried
out a comparative analysis of three XAI methods with and without our template
guidance when explaining two DL models in two real-world datasets. Results: The
proposed approach consistently improved baseline XAI methods across twelve
benchmark scenarios built on three XAI methods, two DL models, and two
datasets. The average incremental percentages, calculated by the performance
improvements over the baseline performance, were 97.8% in Intersection over
Union (IoU) and 94.1% in Dice Similarity Coefficient (DSC) when comparing model
explanations and ground-truth lesion areas. Conclusions: In the context of
pneumothorax diagnoses, we proposed a template-guided approach for improving AI
explanations. We anticipate that our template guidance will forge a fresh
approach to elucidating AI models by integrating clinical domain expertise.

æè¦ï¼<paragraph>èæ¯ï¼æ°£è¸æ¯ä¸ç¨®å èºé¨èè¸å£ä¹éç°å¸¸éæ°£æå¼èµ·çæ¥æ§è¸èç¾çãçºäºè§£æ±ºæ·±åº¦å­¸ç¿ï¼DLï¼æ¨¡åç¶å¸¸ä¼´é¨çä¸éææ§ï¼å¯è§£éäººå·¥æºæ§ï¼XAIï¼æ¹æ³å·²è¢«å¼å¥ï¼ç¨æ¼æ¦è¿°è DL æ¨¡åååºçæ°£è¸è¨ºæ·ç¸éçååãç¶èï¼éäºè§£éæææèå¯¦éçç¶ååææåºå¥ï¼çªé¡¯åºé²ä¸æ­¥æ¹é²çå¿è¦æ§ãæ¹æ³ï¼æåæåºäºä¸ç¨®æ¨¡æ¿å¼å°å¼æ¹æ³ï¼å°æ°£è¸çè¨åºç¥è­ç´å¥ XAI æ¹æ³ç¢ççæ¨¡åè§£éä¸­ï¼å¾èæåéäºè§£éçåè³ªãå©ç¨æ¾å°ç§é«å¸«å»ºç«ççç¶æç¹ªï¼æåçåæ³é¦åç¢çä¸åæ¨¡æ¿ï¼ç¨æ¼è¡¨ç¤ºæ°£è¸å¯è½ç¼ççååãç¶å¾å°æ­¤æ¨¡æ¿çå å¨æ¨¡åè§£éä¸ï¼ä»¥ç¯©é¸åºè¶åºæ¨¡æ¿éççç¡éè§£éãçºäºé©è­å¶æåï¼æåå°ä¸ç¨® XAI æ¹æ³é²è¡äºæ¯è¼åæï¼å¨å©åçå¯¦ä¸çè³æéä¸­è§£éå©å DL æ¨¡åæï¼åå¥æ¡ç¨åä¸æ¡ç¨æåçæ¨¡æ¿å¼å°ãçµæï¼ææåºçæ¹æ³å¨å»ºç«æ¼ä¸ç¨® XAI æ¹æ³ãå©å DL æ¨¡ååå©åè³æéçåäºç¨®åºæºæå¢ä¸­ï¼å§çµæ¹åäºåºæº XAI æ¹æ³ãå¨æ¯è¼æ¨¡åè§£éåçå¯¦çç¶ååæï¼ééåºæºæè½çæè½æ¹é²è¨ç®åºçå¹³åå¢éç¾åæ¯çºäº¤éæ¯ï¼IoUï¼ç 97.8% åéª°å­ç¸ä¼¼æ§ä¿æ¸ï¼DSCï¼ç 94.1%ãçµè«ï¼å¨æ°£è¸è¨ºæ·çèæ¯ä¸ï¼æåæåºäºä¸ç¨®æ¨¡æ¿å¼å°å¼æ¹æ³ï¼ç¨æ¼æ¹å AI è§£éãæåé ææåçæ¨¡æ¿å¼å°å°ééæ´åè¨åºé åå°æ¥­ç¥è­ï¼çºé¡æ AI æ¨¡åå»ºç«ä¸ç¨®æ°æ¹æ³ã</paragraph>

##### **Enhancing Neural Machine Translation of Low-Resource Languages: Corpus Development, Human Evaluation and Explainable AI Architectures**
2403.01580v1 by SÃ©amus Lankford

In the current machine translation (MT) landscape, the Transformer
architecture stands out as the gold standard, especially for high-resource
language pairs. This research delves into its efficacy for low-resource
language pairs including both the English$\leftrightarrow$Irish and
English$\leftrightarrow$Marathi language pairs. Notably, the study identifies
the optimal hyperparameters and subword model type to significantly improve the
translation quality of Transformer models for low-resource language pairs.
  The scarcity of parallel datasets for low-resource languages can hinder MT
development. To address this, gaHealth was developed, the first bilingual
corpus of health data for the Irish language. Focusing on the health domain,
models developed using this in-domain dataset exhibited very significant
improvements in BLEU score when compared with models from the LoResMT2021
Shared Task. A subsequent human evaluation using the multidimensional quality
metrics error taxonomy showcased the superior performance of the Transformer
system in reducing both accuracy and fluency errors compared to an RNN-based
counterpart.
  Furthermore, this thesis introduces adaptNMT and adaptMLLM, two open-source
applications streamlined for the development, fine-tuning, and deployment of
neural machine translation models. These tools considerably simplify the setup
and evaluation process, making MT more accessible to both developers and
translators. Notably, adaptNMT, grounded in the OpenNMT ecosystem, promotes
eco-friendly natural language processing research by highlighting the
environmental footprint of model development. Fine-tuning of MLLMs by adaptMLLM
demonstrated advancements in translation performance for two low-resource
language pairs: English$\leftrightarrow$Irish and
English$\leftrightarrow$Marathi, compared to baselines from the LoResMT2021
Shared Task.

æè¦ï¼<paragraph>å¨ç¶åæ©å¨ç¿»è­¯ (MT) é åä¸­ï¼Transformer æ¶æ§è«ç©èåºï¼æçºé»éæ¨æºï¼ç¹å¥æ¯å°æ¼é«è³æºèªè¨å°ãæ¬ç ç©¶æ¢è¨å¶å°ä½è³æºèªè¨å°çæè½ï¼åæ¬è±èªâæç¾è­èªåè±èªâé¦¬æå°èªèªè¨å°ãå¼å¾æ³¨æçæ¯ï¼æ¬ç ç©¶è­å¥åºæä½³è¶åæ¸åå­è©æ¨¡åé¡åï¼ä»¥é¡¯èæé« Transformer æ¨¡åå°ä½è³æºèªè¨å°çç¿»è­¯åè³ªã
ä½è³æºèªè¨çå¹³è¡è³æéçç¨ç¼ºæé»ç¤ MT çç¼å±ãçºäºè§£æ±ºéååé¡ï¼éç¼äº gaHealthï¼éæ¯æç¾è­èªçç¬¬ä¸åéèªå¥åº·è³æèªæåº«ãå°æ³¨æ¼å¥åº·é åï¼ä½¿ç¨æ­¤åå§è³æééç¼çæ¨¡åå¨ BLEU å¾åæ¹é¢è¡¨ç¾åºéå¸¸é¡¯èçé²æ­¥ï¼è LoResMT2021 å±äº«ä»»åä¸­çæ¨¡åç¸æ¯ãé¨å¾ä½¿ç¨å¤ç¶­åè³ªææ¨é¯èª¤åé¡æ³é²è¡çäººå·¥è©ä¼°é¡¯ç¤ºï¼èåºæ¼ RNN çå°ææ¨¡åç¸æ¯ï¼Transformer ç³»çµ±å¨æ¸å°æºç¢ºæ§åæµæ¢æ§é¯èª¤æ¹é¢è¡¨ç¾åºåªç°çæ§è½ã
æ­¤å¤ï¼æ¬è«æä»ç´¹äº adaptNMT å adaptMLLMï¼éå©åéæºæç¨ç¨å¼ç°¡åäºç¥ç¶æ©å¨ç¿»è­¯æ¨¡åçéç¼ãå¾®èª¿åé¨ç½²ãéäºå·¥å·å¤§å¹ç°¡åäºè¨­å®åè©ä¼°æµç¨ï¼è® MT æ´å®¹æè®éç¼äººå¡åç¿»è­¯äººå¡ä½¿ç¨ãå¼å¾æ³¨æçæ¯ï¼adaptNMT ä»¥ OpenNMT çæç³»çµ±çºåºç¤ï¼ééå¼·èª¿æ¨¡åéç¼çç°å¢è¶³è·¡ä¾ä¿é²çæåå¥½çèªç¶èªè¨èçç ç©¶ãè LoResMT2021 å±äº«ä»»åä¸­çåºæºç¸æ¯ï¼adaptMLLM å° MLLM çå¾®èª¿è­æäºè±èªâæç¾è­èªåè±èªâé¦¬æå°èªéå©åä½è³æºèªè¨å°çç¿»è­¯æ§è½é²æ­¥ã</paragraph>

##### **Cause and Effect: Can Large Language Models Truly Understand Causality?**
2402.18139v3 by Swagata Ashwani, Kshiteesh Hegde, Nishith Reddy Mannuru, Mayank Jindal, Dushyant Singh Sengar, Krishna Chaitanya Rao Kathala, Dishant Banga, Vinija Jain, Aman Chadha

With the rise of Large Language Models(LLMs), it has become crucial to
understand their capabilities and limitations in deciphering and explaining the
complex web of causal relationships that language entails. Current methods use
either explicit or implicit causal reasoning, yet there is a strong need for a
unified approach combining both to tackle a wide array of causal relationships
more effectively. This research proposes a novel architecture called Context
Aware Reasoning Enhancement with Counterfactual Analysis(CARE CA) framework to
enhance causal reasoning and explainability. The proposed framework
incorporates an explicit causal detection module with ConceptNet and
counterfactual statements, as well as implicit causal detection through LLMs.
Our framework goes one step further with a layer of counterfactual explanations
to accentuate LLMs understanding of causality. The knowledge from ConceptNet
enhances the performance of multiple causal reasoning tasks such as causal
discovery, causal identification and counterfactual reasoning. The
counterfactual sentences add explicit knowledge of the not caused by scenarios.
By combining these powerful modules, our model aims to provide a deeper
understanding of causal relationships, enabling enhanced interpretability.
Evaluation of benchmark datasets shows improved performance across all metrics,
such as accuracy, precision, recall, and F1 scores. We also introduce
CausalNet, a new dataset accompanied by our code, to facilitate further
research in this domain.

æè¦ï¼é¨èå¤§åèªè¨æ¨¡å (LLM) çèèµ·ï¼äºè§£å®åå¨è§£ç¢¼åè§£éèªè¨æèå«çè¤éå æéä¿ç¶²è·¯ä¸­çè½ååéå¶è®å¾è³ééè¦ãç®åçæè¡ä½¿ç¨æç¢ºæé±å«çå ææ¨çï¼ä½å¼·çéè¦ä¸ç¨®çµ±ä¸çæ¹æ³ï¼çµåå©èä»¥æ´ææå°èçå»£æ³çå æéä¿ãæ¬ç ç©¶æåºäºä¸ç¨®ç¨±çºæå¢æç¥æ¨çå¢å¼·èåäºå¯¦åæ (CARE CA) æ¡æ¶çæ°æ¶æ§ï¼ä»¥å¢å¼·å ææ¨çåå¯è§£éæ§ãæåºçæ¡æ¶çµåäºä½¿ç¨ ConceptNet ååäºå¯¦é³è¿°çæç¢ºå ææª¢æ¸¬æ¨¡çµï¼ä»¥åéé LLM é²è¡çé±å«å ææª¢æ¸¬ãæåçæ¡æ¶æ´é²ä¸æ­¥ï¼å å¥ä¸å±¤åäºå¯¦è§£éï¼ä»¥å¼·èª¿ LLM å°å æéä¿ççè§£ãä¾èª ConceptNet çç¥è­å¢å¼·äºå¤é å ææ¨çä»»åçå·è¡ï¼ä¾å¦å æç¼ç¾ãå æè­å¥ååäºå¯¦æ¨çãåäºå¯¦å¥å å¥äºæªç±æå¢é æçæç¢ºç¥è­ãééçµåéäºå¼·å¤§çæ¨¡çµï¼æåçæ¨¡åæ¨å¨æä¾å°å æéä¿æ´æ·±å¥ççè§£ï¼å¯¦ç¾å¢å¼·çå¯è§£éæ§ãåºæºè³æéçè©ä¼°é¡¯ç¤ºå¨ææææ¨ï¼ä¾å¦æºç¢ºåº¦ãç²¾ç¢ºåº¦ãå¬åçå F1 åæ¸ï¼ä¸é½æææåãæåéå¼å¥äº CausalNetï¼ä¸åæ°çè³æéï¼ä¸¦éä¸äºæåçç¨å¼ç¢¼ï¼ä»¥ä¿é²å¨éåé åçé²ä¸æ­¥ç ç©¶ã

##### **Artificial Intelligence and Diabetes Mellitus: An Inside Look Through the Retina**
2402.18600v1 by Yasin Sadeghi Bazargani, Majid Mirzaei, Navid Sobhi, Mirsaeed Abdollahi, Ali Jafarizadeh, Siamak Pedrammehr, Roohallah Alizadehsani, Ru San Tan, Sheikh Mohammed Shariful Islam, U. Rajendra Acharya

Diabetes mellitus (DM) predisposes patients to vascular complications.
Retinal images and vasculature reflect the body's micro- and macrovascular
health. They can be used to diagnose DM complications, including diabetic
retinopathy (DR), neuropathy, nephropathy, and atherosclerotic cardiovascular
disease, as well as forecast the risk of cardiovascular events. Artificial
intelligence (AI)-enabled systems developed for high-throughput detection of DR
using digitized retinal images have become clinically adopted. Beyond DR
screening, AI integration also holds immense potential to address challenges
associated with the holistic care of the patient with DM. In this work, we aim
to comprehensively review the literature for studies on AI applications based
on retinal images related to DM diagnosis, prognostication, and management. We
will describe the findings of holistic AI-assisted diabetes care, including but
not limited to DR screening, and discuss barriers to implementing such systems,
including issues concerning ethics, data privacy, equitable access, and
explainability. With the ability to evaluate the patient's health status vis a
vis DM complication as well as risk prognostication of future cardiovascular
complications, AI-assisted retinal image analysis has the potential to become a
central tool for modern personalized medicine in patients with DM.

æè¦ï¼ç³å°¿çï¼DMï¼ä½¿æ£èå®¹æåºç¾è¡ç®¡ä½µç¼çã
è¦ç¶²èå½±ååè¡ç®¡åæ èº«é«çå¾®è¡ç®¡åå·¨è¡ç®¡å¥åº·çæ³ãå®åå¯ç¨æ¼è¨ºæ·ç³å°¿çä½µç¼çï¼åæ¬ç³å°¿çè¦ç¶²èçè®ï¼DRï¼ãç¥ç¶çè®ãèçååèç²¥æ¨£ç¡¬åæ§å¿è¡ç®¡ç¾çï¼ä»¥åé æ¸¬å¿è¡ç®¡äºä»¶çé¢¨éªãçºä½¿ç¨æ¸ä½åè¦ç¶²èå½±åé²è¡é«éé DR æª¢æ¸¬èéç¼çäººå·¥æºæ§ï¼AIï¼åç¨ç³»çµ±å·²å¨è¨åºæ¡ç¨ãé¤äº DR ç¯©æª¢å¤ï¼AI æ´åä¹å·æå·¨å¤§çæ½åä¾æå°èç³å°¿çæ£èæ´é«ç§è­·ç¸éçææ°ãå¨éé å·¥ä½ä¸­ï¼æåæ¨å¨å¨é¢åé¡§åºæ¼è¦ç¶²èå½±åç AI æç¨ç¸éç ç©¶çæç»ï¼éäºç ç©¶èç³å°¿ççè¨ºæ·ãé å¾åç®¡çæéãæåå°æè¿°æ´é« AI è¼å©ç³å°¿çç§è­·çç¼ç¾ï¼åæ¬ä½ä¸éæ¼ DR ç¯©æª¢ï¼ä¸¦è¨è«å¯¦æ½æ­¤é¡ç³»çµ±çéç¤ï¼åæ¬èå«çãè³æé±ç§ãå¬å¹³å­ååå¯è§£éæ§æéçåé¡ãééè©ä¼°æ£èçå¥åº·çæ³ï¼åæèéç³å°¿çä½µç¼çä»¥åæªä¾å¿è¡ç®¡ä½µç¼ççé¢¨éªé å¾ï¼AI è¼å©è¦ç¶²èå½±ååæææ½åæçºç³å°¿çæ£èç¾ä»£ååäººåé«ççä¸­å¿å·¥å·ã

##### **Multi-stakeholder Perspective on Responsible Artificial Intelligence and Acceptability in Education**
2402.15027v2 by A. J. Karran, P. Charland, J-T. Martineau, A. Ortiz de Guinea Lopez de Arana, AM. Lesage, S. Senecal, P-M. Leger

This study investigates the acceptability of different artificial
intelligence (AI) applications in education from a multi-stakeholder
perspective, including students, teachers, and parents. Acknowledging the
transformative potential of AI in education, it addresses concerns related to
data privacy, AI agency, transparency, explainability and the ethical
deployment of AI. Through a vignette methodology, participants were presented
with four scenarios where AI's agency, transparency, explainability, and
privacy were manipulated. After each scenario, participants completed a survey
that captured their perceptions of AI's global utility, individual usefulness,
justice, confidence, risk, and intention to use each scenario's AI if
available. The data collection comprising a final sample of 1198
multi-stakeholder participants was distributed through a partner institution
and social media campaigns and focused on individual responses to four AI use
cases. A mediation analysis of the data indicated that acceptance and trust in
AI varies significantly across stakeholder groups. We found that the key
mediators between high and low levels of AI's agency, transparency, and
explainability, as well as the intention to use the different educational AI,
included perceived global utility, justice, and confidence. The study
highlights that the acceptance of AI in education is a nuanced and multifaceted
issue that requires careful consideration of specific AI applications and their
characteristics, in addition to the diverse stakeholders' perceptions.

æè¦ï¼éé ç ç©¶å¾å¤åå©å®³éä¿äººçè§åº¦æ¢è¨ä¸åçäººå·¥æºæ§ (AI) æç¨å¨æè²ä¸çå¯æ¥åæ§ï¼åæ¬å­¸çãèå¸«åå®¶é·ãæ¿èª AI å¨æè²ä¸çè½åæ½åï¼å®è§£æ±ºäºèè³æé±ç§ãAI ä»£çãéæåº¦ãå¯è§£éæ§å AI çéå¾·é¨ç½²ç¸éççæ®ãééå°ææ²æ¹æ³ï¼åèèè¢«åç¾äºåç¨®æå¢ï¼å¶ä¸­ AI çä»£çãéæåº¦ãå¯è§£éæ§åé±ç§åå°æç¸±ãå¨æ¯åæå¢å¾ï¼åèèå®æäºä¸é èª¿æ¥ï¼è©²èª¿æ¥ææäºä»åå° AI çæ´é«æç¨ãåäººæç¨ãæ­£ç¾©ãä¿¡å¿ãé¢¨éªåå¦æå¯ç¨ï¼ä½¿ç¨æ¯åæå¢ç AI çæåççæ³ãè³æèéåå«ä¾èªåä½æ©æ§åç¤¾ç¾¤åªé«æ´»åç 1198 ä½å¤å©å®³éä¿äººåèèçæçµæ¨£æ¬ï¼ä¸¦å°æ³¨æ¼å°åå AI ä½¿ç¨æ¡ä¾çåå¥åæãå°è³æçèª¿è§£åæè¡¨æï¼å° AI çæ¥ååº¦åä¿¡ä»»å¨å©å®³éä¿äººåé«ä¹éæé¡¯èå·®ç°ãæåç¼ç¾ï¼AI çä»£çãéæåº¦åå¯è§£éæ§é«ä½ç¨åº¦ä¹éçééµèª¿è§£èï¼ä»¥åä½¿ç¨ä¸åæè² AI çæåï¼åæ¬æç¥å°çæ´é«æç¨ãæ­£ç¾©åä¿¡å¿ãéé ç ç©¶å¼·èª¿ï¼æ¥å AI å¨æè²ä¸çæç¨æ¯ä¸åå¾®å¦ä¸å¤é¢åçåé¡ï¼é¤äºä¸åçå©å®³éä¿äººççæ³å¤ï¼ééè¦ä»ç´°èæ®å·é«ç AI æç¨åå¶ç¹å¾µã

##### **Deciphering Heartbeat Signatures: A Vision Transformer Approach to Explainable Atrial Fibrillation Detection from ECG Signals**
2402.09474v2 by Aruna Mohan, Danne Elbers, Or Zilbershot, Fatemeh Afghah, David Vorchheimer

Remote patient monitoring based on wearable single-lead electrocardiogram
(ECG) devices has significant potential for enabling the early detection of
heart disease, especially in combination with artificial intelligence (AI)
approaches for automated heart disease detection. There have been prior studies
applying AI approaches based on deep learning for heart disease detection.
However, these models are yet to be widely accepted as a reliable aid for
clinical diagnostics, in part due to the current black-box perception
surrounding many AI algorithms. In particular, there is a need to identify the
key features of the ECG signal that contribute toward making an accurate
diagnosis, thereby enhancing the interpretability of the model. In the present
study, we develop a vision transformer approach to identify atrial fibrillation
based on single-lead ECG data. A residual network (ResNet) approach is also
developed for comparison with the vision transformer approach. These models are
applied to the Chapman-Shaoxing dataset to classify atrial fibrillation, as
well as another common arrhythmia, sinus bradycardia, and normal sinus rhythm
heartbeats. The models enable the identification of the key regions of the
heartbeat that determine the resulting classification, and highlight the
importance of P-waves and T-waves, as well as heartbeat duration and signal
amplitude, in distinguishing normal sinus rhythm from atrial fibrillation and
sinus bradycardia.

æè¦ï¼<paragraph>åºæ¼å¯ç©¿æ´å¼å®å°ç¨å¿é»å (ECG) è£ç½®çé ç«¯çæ£ç£æ¸¬å¨æ©æåµæ¸¬å¿èç¾çæ¹é¢å·æé¡¯èçæ½åï¼ç¹å¥æ¯èç¨æ¼èªååå¿èç¾çåµæ¸¬çäººå·¥æºæ§ (AI) æ¹æ³çµåä½¿ç¨æãååå·²æç ç©¶æç¨åºæ¼æ·±åº¦å­¸ç¿ç AI æ¹æ³é²è¡å¿èç¾çåµæ¸¬ãç¶èï¼éäºæ¨¡åå°æªè¢«å»£æ³æ¥åçºè¨åºè¨ºæ·çå¯é è¼å©å·¥å·ï¼é¨ååå å¨æ¼åç¹è¨±å¤ AI æ¼ç®æ³çç¶åé»ç®±æç¥ãç¹å¥æ¯ï¼æå¿è¦æ¾åºæå©æ¼ååºæºç¢ºè¨ºæ·ç ECG è¨èééµç¹å¾µï¼å¾èå¢å¼·æ¨¡åçå¯è§£éæ§ãå¨æ¬ç ç©¶ä¸­ï¼æåéç¼äºä¸ç¨®è¦è¦ºè½æå¨æ¹æ³ï¼ä»¥æ ¹æå®å°ç¨ ECG è³ææ¾åºå¿æ¿é¡«åãæ®å·®ç¶²è·¯ (ResNet) æ¹æ³ä¹å·²éç¼åºä¾ï¼ä»¥ä¾¿èè¦è¦ºè½æå¨æ¹æ³é²è¡æ¯è¼ãéäºæ¨¡åæç¨æ¼ Chapman-Shaoxing è³æéï¼ä»¥åé¡å¿æ¿é¡«åï¼ä»¥åå¦ä¸ç¨®å¸¸è¦çå¿å¾ä¸æ´ï¼ç«æ§å¿åéç·©ï¼åæ­£å¸¸ç«æ§å¿å¾çå¿è·³ãéäºæ¨¡åè½å¤ æ¾åºæ±ºå®æçµåé¡çå¿è·³ééµååï¼ä¸¦å¼·èª¿ P æ³¢å T æ³¢ï¼ä»¥åå¿è·³æçºæéåè¨èæ¯å¹å¨ååæ­£å¸¸ç«æ§å¿å¾èå¿æ¿é¡«ååç«æ§å¿åéç·©æ¹é¢çéè¦æ§ã</paragraph>

##### **Illuminate: A novel approach for depression detection with explainable analysis and proactive therapy using prompt engineering**
2402.05127v1 by Aryan Agrawal

This paper introduces a novel paradigm for depression detection and treatment
using advanced Large Language Models (LLMs): Generative Pre-trained Transformer
4 (GPT-4), Llama 2 chat, and Gemini. These LLMs are fine-tuned with specialized
prompts to diagnose, explain, and suggest therapeutic interventions for
depression. A unique few-shot prompting method enhances the models' ability to
analyze and explain depressive symptoms based on the DSM-5 criteria. In the
interaction phase, the models engage in empathetic dialogue management, drawing
from resources like PsychDB and a Cognitive Behavioral Therapy (CBT) Guide,
fostering supportive interactions with individuals experiencing major
depressive disorders. Additionally, the research introduces the Illuminate
Database, enriched with various CBT modules, aiding in personalized therapy
recommendations. The study evaluates LLM performance using metrics such as F1
scores, Precision, Recall, Cosine similarity, and Recall-Oriented Understudy
for Gisting Evaluation (ROUGE) across different test sets, demonstrating their
effectiveness. This comprehensive approach blends cutting-edge AI with
established psychological methods, offering new possibilities in mental health
care and showcasing the potential of LLMs in revolutionizing depression
diagnosis and treatment strategies.

æè¦ï¼æ¬æä»ç´¹äºä¸ç¨®ä½¿ç¨åé²å¤§åèªè¨æ¨¡å (LLM) é²è¡æé¬±çåµæ¸¬åæ²»ççæ°æ¨¡å¼ï¼çæå¼é è¨ç·´Transformer 4 (GPT-4)ãLlama 2 èå¤©æ©å¨äººå Geminiãéäº LLM ç¶éå¾®èª¿ï¼å·åå°æ¥­æç¤ºï¼å¯è¨ºæ·ãè§£éä¸¦å»ºè­°æé¬±ççæ²»çä»å¥æ¹æ³ãä¸ç¨®ç¨ç¹çå°æ¬¡æç¤ºæ¹æ³å¢å¼·äºæ¨¡åæ ¹æ DSM-5 æ¨æºåæåè§£éæé¬±çççè½åãå¨äºåéæ®µï¼éäºæ¨¡åæåèåçå¿å°è©±ç®¡çï¼å¾ PsychDB åèªç¥è¡çºçæ³ (CBT) æåç­è³æºä¸­æ±²åï¼ä¿é²èç¶æ­·éåº¦æé¬±ççäººåçæ¯ææ§äºåãæ­¤å¤ï¼éé ç ç©¶éä»ç´¹äº Illuminate è³æåº«ï¼å¶ä¸­åå«åç¨® CBT æ¨¡çµï¼æå©æ¼åæ§åæ²»çå»ºè­°ãéé ç ç©¶ä½¿ç¨ F1 åæ¸ãæºç¢ºçãå¬åçãé¤å¼¦ç¸ä¼¼åº¦åé¢åå¬åçç Gisting è©ä¼°æ¿èº« (ROUGE) ç­ææ¨ï¼å¨ä¸åçæ¸¬è©¦éä¸­è©ä¼° LLM çè¡¨ç¾ï¼è­æäºå®åçæææ§ãéç¨®ç¶åæ¹æ³çµåäºå°ç«¯ç AI èæ¢å®çå¿çæ¹æ³ï¼çºå¿çä¿å¥æä¾äºæ°çå¯è½æ§ï¼ä¸¦å±ç¤ºäº LLM å¨é©æ°æé¬±çè¨ºæ·åæ²»çç­ç¥æ¹é¢çæ½åã

##### **Information That Matters: Exploring Information Needs of People Affected by Algorithmic Decisions**
2401.13324v6 by TimothÃ©e Schmude, Laura Koesten, Torsten MÃ¶ller, Sebastian Tschiatschek

Every AI system that makes decisions about people has a group of stakeholders
that are personally affected by these decisions. However, explanations of AI
systems rarely address the information needs of this stakeholder group, who
often are AI novices. This creates a gap between conveyed information and
information that matters to those who are impacted by the system's decisions,
such as domain experts and decision subjects. To address this, we present the
"XAI Novice Question Bank," an extension of the XAI Question Bank containing a
catalog of information needs from AI novices in two use cases: employment
prediction and health monitoring. The catalog covers the categories of data,
system context, system usage, and system specifications. We gathered
information needs through task-based interviews where participants asked
questions about two AI systems to decide on their adoption and received verbal
explanations in response. Our analysis showed that participants' confidence
increased after receiving explanations but that their understanding faced
challenges. These included difficulties in locating information and in
assessing their own understanding, as well as attempts to outsource
understanding. Additionally, participants' prior perceptions of the systems'
risks and benefits influenced their information needs. Participants who
perceived high risks sought explanations about the intentions behind a system's
deployment, while those who perceived low risks rather asked about the system's
operation. Our work aims to support the inclusion of AI novices in
explainability efforts by highlighting their information needs, aims, and
challenges. We summarize our findings as five key implications that can inform
the design of future explanations for lay stakeholder audiences.

æè¦ï¼<paragraph>æ¯åå°äººååºæ±ºå®ç AI ç³»çµ±é½æä¸ç¾¤å©å®³éä¿äºº
åå°éäºæ±ºå®çè¦ªèº«å½±é¿ãç¶èï¼AI
ç³»çµ±çè§£éå¾å°è½æ»¿è¶³éç¾¤å©å®³éä¿äººçè³è¨éæ±ï¼èä»å
éå¸¸é½æ¯ AI æ°æãéé æäºå³éè³è¨è
åå°ç³»çµ±æ±ºç­å½±é¿çäººå£«ï¼ä¾å¦é åå°å®¶åæ±ºç­ä¸»é«ï¼éè¦çè³è¨ä¹éçè½å·®ãçºäºè§£æ±ºéååé¡ï¼æåæåºäº
ãXAI æ°æåé¡åº«ãï¼å®æ¯ XAI åé¡åº«çå»¶ä¼¸ï¼åå«ä¾èª AI æ°æå¨å©åä½¿ç¨æ¡ä¾ä¸­çè³è¨éæ±ç®éï¼å°±æ¥­
é æ¸¬åå¥åº·ç£æ¸¬ãç®éæ¶µèäºè³æã
ç³»çµ±èæ¯ãç³»çµ±ä½¿ç¨åç³»çµ±è¦æ ¼ç­é¡å¥ãæåééä»»ååè¨ªè«æ¶éè³è¨éæ±ï¼åèèå¨è¨ªè«ä¸­è©¢åäºå©å AI ç³»çµ±çåé¡ï¼ä»¥æ±ºå®æ¯å¦æ¡ç¨å®åï¼ä¸¦æ¶å°å£é ­
è§£éä½çºåæãæåçåæé¡¯ç¤ºï¼åèèå¨æ¶å°è§£éå¾ä¿¡å¿æææåï¼ä½ä»åççè§£å»é¢è¨ææ°ãéäºææ°åæ¬é£ä»¥æ¾å°è³è¨åè©ä¼°èªå·±ççè§£ï¼ä»¥åè©¦åå¤å
çè§£ãæ­¤å¤ï¼åèèå°ç³»çµ±é¢¨éªåå¥½èçåååé¥å½±é¿äºä»åçè³è¨éæ±ãèªçºé¢¨éªé«çåèèå°æ±è§£éç³»çµ±é¨ç½²èå¾çæåï¼èèªçºé¢¨éªä½çäººåè©¢åç³»çµ±ç
æä½ãæåçç ç©¶æ¨å¨ééå¼·èª¿ AI æ°æçè³è¨éæ±ãç®æ¨å
ææ°ï¼ä¾æ¯æå° AI æ°æç´å¥å¯è§£éæ§å·¥ä½ä¸­ãæåå°æåçç ç©¶çµæç¸½çµçºäºåééµåç¤ºï¼éäºåç¤ºå¯ä»¥çºæªä¾éå°éå°æ¥­å©å®³éä¿äººåç¾çè§£éè¨­è¨æä¾åèã</paragraph>

##### **Evaluating Large Language Models on the GMAT: Implications for the Future of Business Education**
2401.02985v1 by Vahid Ashrafimoghari, Necdet GÃ¼rkan, Jordan W. Suchow

The rapid evolution of artificial intelligence (AI), especially in the domain
of Large Language Models (LLMs) and generative AI, has opened new avenues for
application across various fields, yet its role in business education remains
underexplored. This study introduces the first benchmark to assess the
performance of seven major LLMs, OpenAI's models (GPT-3.5 Turbo, GPT-4, and
GPT-4 Turbo), Google's models (PaLM 2, Gemini 1.0 Pro), and Anthropic's models
(Claude 2 and Claude 2.1), on the GMAT, which is a key exam in the admission
process for graduate business programs. Our analysis shows that most LLMs
outperform human candidates, with GPT-4 Turbo not only outperforming the other
models but also surpassing the average scores of graduate students at top
business schools. Through a case study, this research examines GPT-4 Turbo's
ability to explain answers, evaluate responses, identify errors, tailor
instructions, and generate alternative scenarios. The latest LLM versions,
GPT-4 Turbo, Claude 2.1, and Gemini 1.0 Pro, show marked improvements in
reasoning tasks compared to their predecessors, underscoring their potential
for complex problem-solving. While AI's promise in education, assessment, and
tutoring is clear, challenges remain. Our study not only sheds light on LLMs'
academic potential but also emphasizes the need for careful development and
application of AI in education. As AI technology advances, it is imperative to
establish frameworks and protocols for AI interaction, verify the accuracy of
AI-generated content, ensure worldwide access for diverse learners, and create
an educational environment where AI supports human expertise. This research
sets the stage for further exploration into the responsible use of AI to enrich
educational experiences and improve exam preparation and assessment methods.

æè¦ï¼äººå·¥æºæ§ (AI) çå¿«éæ¼é²ï¼å°¤å¶æ¯å¨å¤§åèªè¨æ¨¡å (LLM) åçæå¼ AI çé åï¼çºååé åçæç¨éåäºæ°éå¾ï¼ä½å¶å¨åæ¥­æè²ä¸­çè§è²ä»æªè¢«ååæ¢è¨ãæ¬ç ç©¶é¦æ¬¡å¼å¥äºåºæºï¼ç¨ä»¥è©ä¼°ä¸åä¸»è¦ LLM çæè½ï¼åæ¬ OpenAI çæ¨¡å (GPT-3.5 TurboãGPT-4 å GPT-4 Turbo)ãGoogle çæ¨¡å (PaLM 2ãGemini 1.0 Pro) å Anthropic çæ¨¡å (Claude 2 å Claude 2.1)ï¼éäºæ¨¡åå°ç¨æ¼ç ç©¶çåæ¥­èª²ç¨å¥å­¸ç¨åºä¸­çééµèè©¦ GMATãæåçåæé¡¯ç¤ºï¼å¤§å¤æ¸ LLM çè¡¨ç¾é½åªæ¼äººé¡èçï¼å¶ä¸­ GPT-4 Turbo ä¸ååªæ¼å¶ä»æ¨¡åï¼æ´è¶è¶äºé å°åå­¸é¢çç ç©¶çå¹³ååæ¸ãééæ¡ä¾ç ç©¶ï¼æ¬ç ç©¶æ¢è¨äº GPT-4 Turbo å¨è§£éç­æ¡ãè©ä¼°åæãè¾¨è­é¯èª¤ãèª¿æ´èªªæåç¢çæ¿ä»£æå¢æ¹é¢çè½åãèåä¸ä»£çæ¬ç¸æ¯ï¼ææ°ç LLM çæ¬ GPT-4 TurboãClaude 2.1 å Gemini 1.0 Pro å¨æ¨çä»»åæ¹é¢æé¡¯èçé²æ­¥ï¼å¸é¡¯äºå¶å¨è§£æ±ºè¤éåé¡æ¹é¢çæ½åãåç®¡ AI å¨æè²ãè©éåè¼å°æ¹é¢çæ¿è«¾å¾æç¢ºï¼ä½ä»æææ°å­å¨ãæåçç ç©¶ä¸åé¡æäº LLM çå­¸è¡æ½åï¼ä¹å¼·èª¿äºå¨æè²ä¸­å¯©æéç¼åæç¨ AI çå¿è¦æ§ãé¨è AI æè¡çé²æ­¥ï¼å»ºç« AI äºåçæ¶æ§ååå®ãé©è­ AI çæçå§å®¹çæºç¢ºæ§ãç¢ºä¿å¨çåå°å¤åå­¸ç¿èçå­åæ¬ï¼ä»¥ååµé ä¸å AI æ¯æäººé¡å°æ¥­ç¥è­çæè²ç°å¢è³ééè¦ãæ¬ç ç©¶çºé²ä¸æ­¥æ¢ç´¢è² è²¬ä»»å°ä½¿ç¨ AI ä¾è±å¯æè²é«é©ä¸¦æ¹åèè©¦æºååè©éæ¹æ³å¥ å®äºåºç¤ã

##### **XAI for In-hospital Mortality Prediction via Multimodal ICU Data**
2312.17624v1 by Xingqiao Li, Jindong Gu, Zhiyong Wang, Yancheng Yuan, Bo Du, Fengxiang He

Predicting in-hospital mortality for intensive care unit (ICU) patients is
key to final clinical outcomes. AI has shown advantaged accuracy but suffers
from the lack of explainability. To address this issue, this paper proposes an
eXplainable Multimodal Mortality Predictor (X-MMP) approaching an efficient,
explainable AI solution for predicting in-hospital mortality via multimodal ICU
data. We employ multimodal learning in our framework, which can receive
heterogeneous inputs from clinical data and make decisions. Furthermore, we
introduce an explainable method, namely Layer-Wise Propagation to Transformer,
as a proper extension of the LRP method to Transformers, producing explanations
over multimodal inputs and revealing the salient features attributed to
prediction. Moreover, the contribution of each modality to clinical outcomes
can be visualized, assisting clinicians in understanding the reasoning behind
decision-making. We construct a multimodal dataset based on MIMIC-III and
MIMIC-III Waveform Database Matched Subset. Comprehensive experiments on
benchmark datasets demonstrate that our proposed framework can achieve
reasonable interpretation with competitive prediction accuracy. In particular,
our framework can be easily transferred to other clinical tasks, which
facilitates the discovery of crucial factors in healthcare research.

æè¦ï¼é æ¸¬å è­·çæ¿ (ICU) çæ£çé¢å§æ­»äº¡çæ¯æçµè¨åºçµæçééµãAI å·²å±ç¾åºåªç°çæºç¢ºåº¦ï¼ä½å»ç¼ºä¹å¯è§£éæ§ãçºäºè§£æ±ºéååé¡ï¼æ¬ææåºäºä¸åå¯è§£éçå¤æ¨¡å¼æ­»äº¡çé æ¸¬å¨ (X-MMP)ï¼æ¡ç¨ææä¸å¯è§£éç AI æ¹å¼ï¼èç±å¤æ¨¡å¼ ICU è³æä¾é æ¸¬é¢å§æ­»äº¡çãæåå¨æ¶æ§ä¸­æ¡ç¨å¤æ¨¡å¼å­¸ç¿ï¼å¯ä»¥æ¥æ¶ä¾èªè¨åºè³æçç°è³ªè¼¸å¥ä¸¦ååºæ±ºç­ãæ­¤å¤ï¼æåå¼å¥äºä¸åå¯è§£éçæ¹æ³ï¼ä¹å°±æ¯åå±¤å³æ­è³ Transformerï¼ä½çº LRP æ¹æ³é©ç¶å°å»¶ä¼¸è³ Transformerï¼å°å¤æ¨¡å¼è¼¸å¥ç¢çè§£éï¼ä¸¦æ­é²æ­¸å æ¼é æ¸¬çé¡¯èç¹å¾µãæ­¤å¤ï¼æ¯åæ¨¡å¼å°è¨åºçµæçè²¢ç»å¯ä»¥è¦è¦ºåï¼åå©è¨åºé«å¸«äºè§£æ±ºç­èå¾ççç±ãæåæ ¹æ MIMIC-III å MIMIC-III æ³¢å½¢è³æåº«æ¯å°å­éå»ºæ§äºä¸åå¤æ¨¡å¼è³æéãå¨åºæºè³æéä¸çå¨é¢å¯¦é©è­æï¼æåæåºçæ¶æ§å¯ä»¥éæåççè©®éï¼ä¸¦å·åç«¶ç­åçé æ¸¬æºç¢ºåº¦ãç¹å¥æ¯ï¼æåçæ¶æ§å¯ä»¥è¼é¬å°è½ç§»å°å¶ä»è¨åºä»»åï¼éæå©æ¼å¨é«çä¿å¥ç ç©¶ä¸­ç¼ç¾ééµå ç´ ã


### Knowledge Graphs
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2025-01-21**|**LLM-Assisted Knowledge Graph Completion for Curriculum and Domain Modelling in Personalized Higher Education Recommendations**|Hasan Abu-Rasheed et.al.|[2501.12300v1](http://arxiv.org/abs/2501.12300v1)|null|
|**2025-01-21**|**Divide-Then-Aggregate: An Efficient Tool Learning Method via Parallel Tool Invocation**|Dongsheng Zhu et.al.|[2501.12432v1](http://arxiv.org/abs/2501.12432v1)|null|
|**2025-01-21**|**InsTALL: Context-aware Instructional Task Assistance with Multi-modal Large Language Models**|Pha Nguyen et.al.|[2501.12231v1](http://arxiv.org/abs/2501.12231v1)|null|
|**2025-01-21**|**Leveraging Graph Structures and Large Language Models for End-to-End Synthetic Task-Oriented Dialogues**|Maya Medjad et.al.|[2501.11977v1](http://arxiv.org/abs/2501.11977v1)|null|
|**2025-01-21**|**Bridging Visualization and Optimization: Multimodal Large Language Models on Graph-Structured Combinatorial Optimization**|Jie Zhao et.al.|[2501.11968v1](http://arxiv.org/abs/2501.11968v1)|null|
|**2025-01-21**|**Network-informed Prompt Engineering against Organized Astroturf Campaigns under Extreme Class Imbalance**|Nikos Kanakaris et.al.|[2501.11849v1](http://arxiv.org/abs/2501.11849v1)|[link](https://github.com/nkanak/brag-fake-news-campaigns)|
|**2025-01-20**|**Explainable Lane Change Prediction for Near-Crash Scenarios Using Knowledge Graph Embeddings and Retrieval Augmented Generation**|M. Manzour et.al.|[2501.11560v1](http://arxiv.org/abs/2501.11560v1)|null|
|**2025-01-20**|**Graph-defined Language Learning with LLMs**|Huachi Zhou et.al.|[2501.11478v1](http://arxiv.org/abs/2501.11478v1)|null|
|**2025-01-20**|**Few-shot Policy (de)composition in Conversational Question Answering**|Kyle Erwin et.al.|[2501.11335v1](http://arxiv.org/abs/2501.11335v1)|null|
|**2025-01-20**|**Reasoning Language Models: A Blueprint**|Maciej Besta et.al.|[2501.11223v2](http://arxiv.org/abs/2501.11223v2)|[link](https://github.com/spcl/x1)|
|**2025-01-19**|**IntellAgent: A Multi-Agent Framework for Evaluating Conversational AI Systems**|Elad Levi et.al.|[2501.11067v1](http://arxiv.org/abs/2501.11067v1)|[link](https://github.com/plurai-ai/intellagent)|
|**2025-01-17**|**Agent-as-Judge for Factual Summarization of Long Narratives**|Yeonseok Jeong et.al.|[2501.09993v1](http://arxiv.org/abs/2501.09993v1)|null|
|**2025-01-17**|**FRAG: A Flexible Modular Framework for Retrieval-Augmented Generation based on Knowledge Graphs**|Zengyi Gao et.al.|[2501.09957v2](http://arxiv.org/abs/2501.09957v2)|null|
|**2025-01-16**|**SOP-Agent: Empower General Purpose AI Agent with Domain-Specific SOPs**|Anbang Ye et.al.|[2501.09316v1](http://arxiv.org/abs/2501.09316v1)|null|
|**2025-01-16**|**Text Semantics to Flexible Design: A Residential Layout Generation Method Based on Stable Diffusion Model**|Zijin Qiu et.al.|[2501.09279v1](http://arxiv.org/abs/2501.09279v1)|null|
|**2025-01-16**|**A Simple Graph Contrastive Learning Framework for Short Text Classification**|Yonghao Liu et.al.|[2501.09219v1](http://arxiv.org/abs/2501.09219v1)|[link](https://github.com/keaml-jlu/simstc)|
|**2025-01-16**|**Boosting Short Text Classification with Multi-Source Information Exploration and Dual-Level Contrastive Learning**|Yonghao Liu et.al.|[2501.09214v1](http://arxiv.org/abs/2501.09214v1)|[link](https://github.com/keaml-jlu/mi-delight)|
|**2025-01-15**|**Leveraging Large Language Models as Knowledge-Driven Agents for Reliable Retrosynthesis Planning**|Qinyu Ma et.al.|[2501.08897v1](http://arxiv.org/abs/2501.08897v1)|[link](https://github.com/qinyuma316/retrosynthesisagent)|
|**2025-01-15**|**Knowledge Graph-based Retrieval-Augmented Generation for Schema Matching**|Chuangtao Ma et.al.|[2501.08686v1](http://arxiv.org/abs/2501.08686v1)|[link](https://github.com/machuangtao/kg-rag4sm)|
|**2025-01-15**|**Assessing the Alignment of FOL Closeness Metrics with Human Judgement**|Ramya Keerthy Thatikonda et.al.|[2501.08613v2](http://arxiv.org/abs/2501.08613v2)|[link](https://github.com/ramyakeerthy/alignmentfol)|
|**2025-01-15**|**AutoRestTest: A Tool for Automated REST API Testing Using LLMs and MARL**|Tyler Stennett et.al.|[2501.08600v1](http://arxiv.org/abs/2501.08600v1)|null|
|**2025-01-15**|**LoRS: Efficient Low-Rank Adaptation for Sparse Large Language Model**|Yuxuan Hu et.al.|[2501.08582v1](http://arxiv.org/abs/2501.08582v1)|null|
|**2025-01-14**|**Towards Zero-Shot & Explainable Video Description by Reasoning over Graphs of Events in Space and Time**|Mihai Masala et.al.|[2501.08460v1](http://arxiv.org/abs/2501.08460v1)|null|
|**2025-01-14**|**In-situ graph reasoning and knowledge expansion using Graph-PReFLexOR**|Markus J. Buehler et.al.|[2501.08120v1](http://arxiv.org/abs/2501.08120v1)|[link](https://github.com/lamm-mit/PRefLexOR)|
|**2025-01-14**|**Reasoning with Graphs: Structuring Implicit Knowledge to Enhance LLMs Reasoning**|Haoyu Han et.al.|[2501.07845v1](http://arxiv.org/abs/2501.07845v1)|null|
|**2025-01-14**|**Flow: A Modular Approach to Automated Agentic Workflow Generation**|Boye Niu et.al.|[2501.07834v1](http://arxiv.org/abs/2501.07834v1)|null|
|**2025-01-14**|**Large Language Models for Knowledge Graph Embedding Techniques, Methods, and Challenges: A Survey**|Bingchen Liu et.al.|[2501.07766v1](http://arxiv.org/abs/2501.07766v1)|null|
|**2025-01-13**|**SafePowerGraph-LLM: Novel Power Grid Graph Embedding and Optimization with Large Language Models**|Fabien Bernier et.al.|[2501.07639v1](http://arxiv.org/abs/2501.07639v1)|null|
|**2025-01-13**|**ADKGD: Anomaly Detection in Knowledge Graphs with Dual-Channel Training**|Jiayang Wu et.al.|[2501.07078v1](http://arxiv.org/abs/2501.07078v1)|[link](https://github.com/csjywu1/adkgd)|
|**2025-01-12**|**Causal Claims in Economics**|Prashant Garg et.al.|[2501.06873v1](http://arxiv.org/abs/2501.06873v1)|null|
|**2025-01-12**|**MiniRAG: Towards Extremely Simple Retrieval-Augmented Generation**|Tianyu Fan et.al.|[2501.06713v2](http://arxiv.org/abs/2501.06713v2)|[link](https://github.com/hkuds/minirag)|
|**2025-01-12**|**Large Language Models, Knowledge Graphs and Search Engines: A Crossroads for Answering Users' Questions**|Aidan Hogan et.al.|[2501.06699v1](http://arxiv.org/abs/2501.06699v1)|null|
|**2025-01-11**|**Quantifying Relational Exploration in Cultural Heritage Knowledge Graphs with LLMs: A Neuro-Symbolic Approach**|Mohammed Maree et.al.|[2501.06628v1](http://arxiv.org/abs/2501.06628v1)|null|
|**2025-01-11**|**MedCT: A Clinical Terminology Graph for Generative AI Applications in Healthcare**|Ye Chen et.al.|[2501.06465v2](http://arxiv.org/abs/2501.06465v2)|null|
|**2025-01-10**|**Dynamics of "Spontaneous" Topic Changes in Next Token Prediction with Self-Attention**|Mumin Jia et.al.|[2501.06382v1](http://arxiv.org/abs/2501.06382v1)|null|
|**2025-01-10**|**Network Diffuser for Placing-Scheduling Service Function Chains with Inverse Demonstration**|Zuyuan Zhang et.al.|[2501.05673v1](http://arxiv.org/abs/2501.05673v1)|null|
|**2025-01-08**|**FlairGPT: Repurposing LLMs for Interior Designs**|Gabrielle Littlefair et.al.|[2501.04648v1](http://arxiv.org/abs/2501.04648v1)|null|
|**2025-01-08**|**CGP-Tuning: Structure-Aware Soft Prompt Tuning for Code Vulnerability Detection**|Ruijun Feng et.al.|[2501.04510v1](http://arxiv.org/abs/2501.04510v1)|null|
|**2025-01-08**|**S2 Chunking: A Hybrid Framework for Document Segmentation Through Integrated Spatial and Semantic Analysis**|Prashant Verma et.al.|[2501.05485v1](http://arxiv.org/abs/2501.05485v1)|[link](https://github.com/Vprashant/s2-chunking-lib)|
|**2025-01-08**|**Multimodal Graph Constrastive Learning and Prompt for ChartQA**|Yue Dai et.al.|[2501.04303v1](http://arxiv.org/abs/2501.04303v1)|null|
|**2025-01-07**|**Detection, Retrieval, and Explanation Unified: A Violence Detection System Based on Knowledge Graphs and GAT**|Wen-Dong Jiang et.al.|[2501.06224v1](http://arxiv.org/abs/2501.06224v1)|null|
|**2025-01-07**|**Applying Large Language Models in Knowledge Graph-based Enterprise Modeling: Challenges and Opportunities**|Benedikt Reitemeyer et.al.|[2501.03566v1](http://arxiv.org/abs/2501.03566v1)|null|
|**2025-01-07**|**KG-TRICK: Unifying Textual and Relational Information Completion of Knowledge for Multilingual Knowledge Graphs**|Zelin Zhou et.al.|[2501.03560v1](http://arxiv.org/abs/2501.03560v1)|null|
|**2025-01-06**|**Semantic Captioning: Benchmark Dataset and Graph-Aware Few-Shot In-Context Learning for SQL2Text**|Ali Al-Lawati et.al.|[2501.03166v1](http://arxiv.org/abs/2501.03166v1)|[link](https://github.com/aliwister/ast-icl)|
|**2025-01-06**|**Personalized Fashion Recommendation with Image Attributes and Aesthetics Assessment**|Chongxian Chen et.al.|[2501.03085v1](http://arxiv.org/abs/2501.03085v1)|null|
|**2025-01-06**|**Graph-based Retrieval Augmented Generation for Dynamic Few-shot Text Classification**|Yubo Wang et.al.|[2501.02844v1](http://arxiv.org/abs/2501.02844v1)|null|
|**2025-01-06**|**KG-CF: Knowledge Graph Completion with Context Filtering under the Guidance of Large Language Models**|Zaiyi Zheng et.al.|[2501.02711v1](http://arxiv.org/abs/2501.02711v1)|null|
|**2025-01-04**|**Graph-Aware Isomorphic Attention for Adaptive Dynamics in Transformers**|Markus J. Buehler et.al.|[2501.02393v2](http://arxiv.org/abs/2501.02393v2)|[link](https://github.com/lamm-mit/graph-aware-transformers)|
|**2025-01-04**|**What Kind of Visual Tokens Do We Need? Training-free Visual Token Pruning for Multi-modal Large Language Models from the Perspective of Graph**|Yutao Jiang et.al.|[2501.02268v1](http://arxiv.org/abs/2501.02268v1)|[link](https://github.com/jytmelon/g-prune)|
|**2025-01-04**|**Personalized Graph-Based Retrieval for Large Language Models**|Steven Au et.al.|[2501.02157v1](http://arxiv.org/abs/2501.02157v1)|[link](https://github.com/pgraphrag-benchmark/pgr-llm)|
|**2025-01-03**|**Cold-Start Recommendation towards the Era of Large Language Models (LLMs): A Comprehensive Survey and Roadmap**|Weizhi Zhang et.al.|[2501.01945v2](http://arxiv.org/abs/2501.01945v2)|[link](https://github.com/yuanchenbei/awesome-cold-start-recommendation)|
|**2025-01-03**|**Multimodal Contrastive Representation Learning in Augmented Biomedical Knowledge Graphs**|Tien Dang et.al.|[2501.01644v1](http://arxiv.org/abs/2501.01644v1)|[link](https://github.com/hysonlab/biomedkg)|
|**2025-01-02**|**Enhancing Uncertainty Modeling with Semantic Graph for Hallucination Detection**|Kedi Chen et.al.|[2501.02020v1](http://arxiv.org/abs/2501.02020v1)|null|
|**2025-01-01**|**Unfolding the Headline: Iterative Self-Questioning for News Retrieval and Timeline Summarization**|Weiqi Wu et.al.|[2501.00888v1](http://arxiv.org/abs/2501.00888v1)|[link](https://github.com/Alibaba-NLP/CHRONOS)|
|**2025-01-01**|**Breaking Through the Spike: Spike Window Decoding for Accelerated and Precise Automatic Speech Recognition**|Wei Zhang et.al.|[2501.03257v1](http://arxiv.org/abs/2501.03257v1)|null|
|**2025-01-01**|**SmartSpatial: Enhancing the 3D Spatial Arrangement Capabilities of Stable Diffusion Models and Introducing a Novel 3D Spatial Evaluation Framework**|Mao Xun Huang et.al.|[2501.01998v1](http://arxiv.org/abs/2501.01998v1)|null|
|**2024-12-31**|**Causal Graph Guided Steering of LLM Values via Prompts and Sparse Autoencoders**|Yipeng Kang et.al.|[2501.00581v1](http://arxiv.org/abs/2501.00581v1)|null|
|**2024-12-31**|**CancerKG.ORG A Web-scale, Interactive, Verifiable Knowledge Graph-LLM Hybrid for Assisting with Optimal Cancer Treatment and Care**|Michael Gubanov et.al.|[2501.00223v1](http://arxiv.org/abs/2501.00223v1)|null|
|**2024-12-31**|**The Potential of LLMs in Automating Software Testing: From Generation to Reporting**|Betim Sherifi et.al.|[2501.00217v1](http://arxiv.org/abs/2501.00217v1)|null|
|**2024-12-30**|**Detection-Fusion for Knowledge Graph Extraction from Videos**|Taniya Das et.al.|[2501.00136v1](http://arxiv.org/abs/2501.00136v1)|[link](https://github.com/Taniya-Das/video_annotation)|
|**2024-12-30**|**Machine Learning-Based Security Policy Analysis**|Krish Jain et.al.|[2501.00085v2](http://arxiv.org/abs/2501.00085v2)|null|
|**2024-12-30**|**KARPA: A Training-free Method of Adapting Knowledge Graph as References for Large Language Model's Reasoning Path Aggregation**|Siyuan Fang et.al.|[2412.20995v1](http://arxiv.org/abs/2412.20995v1)|null|
|**2024-12-30**|**Ontology-grounded Automatic Knowledge Graph Construction by LLM under Wikidata schema**|Xiaohan Feng et.al.|[2412.20942v1](http://arxiv.org/abs/2412.20942v1)|null|
|**2024-12-29**|**ICLR: In-Context Learning of Representations**|Core Francisco Park et.al.|[2501.00070v1](http://arxiv.org/abs/2501.00070v1)|null|
|**2024-12-28**|**Topic-Aware Knowledge Graph with Large Language Models for Interoperability in Recommender Systems**|Minhye Jeon et.al.|[2412.20163v2](http://arxiv.org/abs/2412.20163v2)|null|
|**2024-12-28**|**From Generalist to Specialist: A Survey of Large Language Models for Chemistry**|Yang Han et.al.|[2412.19994v1](http://arxiv.org/abs/2412.19994v1)|[link](https://github.com/opendfm/llm4chemistry)|
|**2024-12-27**|**Toward Adaptive Reasoning in Large Language Models with Thought Rollback**|Sijia Chen et.al.|[2412.19707v1](http://arxiv.org/abs/2412.19707v1)|[link](https://github.com/iQua/llmpebase)|
|**2024-12-26**|**Dynamic Skill Adaptation for Large Language Models**|Jiaao Chen et.al.|[2412.19361v1](http://arxiv.org/abs/2412.19361v1)|null|
|**2024-12-26**|**Relation-aware Hierarchical Prompt for Open-vocabulary Scene Graph Generation**|Tao Liu et.al.|[2412.19021v1](http://arxiv.org/abs/2412.19021v1)|null|
|**2024-12-25**|**PhyloGen: Language Model-Enhanced Phylogenetic Inference via Graph Structure Generation**|ChenRui Duan et.al.|[2412.18827v1](http://arxiv.org/abs/2412.18827v1)|null|
|**2024-12-24**|**CypherBench: Towards Precise Retrieval over Full-scale Modern Knowledge Graphs in the LLM Era**|Yanlin Feng et.al.|[2412.18702v1](http://arxiv.org/abs/2412.18702v1)|[link](https://github.com/megagonlabs/cypherbench)|
|**2024-12-24**|**From Hallucinations to Facts: Enhancing Language Models with Curated Knowledge Graphs**|Ratnesh Kumar Joshi et.al.|[2412.18672v1](http://arxiv.org/abs/2412.18672v1)|null|
|**2024-12-24**|**Harnessing Large Language Models for Knowledge Graph Question Answering via Adaptive Multi-Aspect Retrieval-Augmentation**|Derong Xu et.al.|[2412.18537v2](http://arxiv.org/abs/2412.18537v2)|[link](https://github.com/Applied-Machine-Learning-Lab/AMAR)|
|**2024-12-24**|**DynaGRAG: Improving Language Understanding and Generation through Dynamic Subgraph Representation in Graph Retrieval-Augmented Generation**|Karishma Thakrar et.al.|[2412.18644v1](http://arxiv.org/abs/2412.18644v1)|null|
|**2024-12-24**|**Is Large Language Model Good at Triple Set Prediction? An Empirical Study**|Yuan Yuan et.al.|[2412.18443v1](http://arxiv.org/abs/2412.18443v1)|null|
|**2024-12-24**|**Investigating Large Language Models for Code Vulnerability Detection: An Experimental Study**|Xuefeng Jiang et.al.|[2412.18260v2](http://arxiv.org/abs/2412.18260v2)|[link](https://github.com/sakirinn/llm4cvd)|
|**2024-12-24**|**An Automatic Graph Construction Framework based on Large Language Models for Recommendation**|Rong Shan et.al.|[2412.18241v1](http://arxiv.org/abs/2412.18241v1)|[link](https://github.com/lavieenrose365/autograph)|
|**2024-12-23**|**CARL-GT: Evaluating Causal Reasoning Capabilities of Large Language Models**|Ruibo Tu et.al.|[2412.17970v1](http://arxiv.org/abs/2412.17970v1)|[link](https://github.com/turuibo/cautabbench)|
|**2024-12-23**|**Path-of-Thoughts: Extracting and Following Paths for Robust Relational Reasoning with Large Language Models**|Ge Zhang et.al.|[2412.17963v1](http://arxiv.org/abs/2412.17963v1)|null|
|**2024-12-23**|**ResearchTown: Simulator of Human Research Community**|Haofei Yu et.al.|[2412.17767v1](http://arxiv.org/abs/2412.17767v1)|[link](https://github.com/ulab-uiuc/research-town)|
|**2024-12-23**|**RAGONITE: Iterative Retrieval on Induced Databases and Verbalized RDF for Conversational QA over KGs with RAG**|Rishiraj Saha Roy et.al.|[2412.17690v3](http://arxiv.org/abs/2412.17690v3)|null|
|**2024-12-23**|**A Dual-Perspective Metaphor Detection Framework Using Large Language Models**|Yujie Lin et.al.|[2412.17332v2](http://arxiv.org/abs/2412.17332v2)|[link](https://github.com/deeplearnxmu/dmd)|
|**2024-12-22**|**GraphAgent: Agentic Graph Language Assistant**|Yuhao Yang et.al.|[2412.17029v1](http://arxiv.org/abs/2412.17029v1)|null|
|**2024-12-22**|**Enhancing Supply Chain Transparency in Emerging Economies Using Online Contents and LLMs**|Bohan Jin et.al.|[2412.16922v1](http://arxiv.org/abs/2412.16922v1)|null|
|**2024-12-22**|**KG4Diagnosis: A Hierarchical Multi-Agent LLM Framework with Knowledge Graph Enhancement for Medical Diagnosis**|Kaiwen Zuo et.al.|[2412.16833v2](http://arxiv.org/abs/2412.16833v2)|null|
|**2024-12-21**|**Apples to Apples: Establishing Comparability in Knowledge Generation Tasks Involving Users**|Christophe Debruyne et.al.|[2412.16766v1](http://arxiv.org/abs/2412.16766v1)|null|
|**2024-12-21**|**Self-guided Knowledgeable Network of Thoughts: Amplifying Reasoning with Large Language Models**|Chao-Chi Chen et.al.|[2412.16533v1](http://arxiv.org/abs/2412.16533v1)|null|
|**2024-12-21**|**Beyond End-to-End VLMs: Leveraging Intermediate Text Representations for Superior Flowchart Understanding**|Junyi Ye et.al.|[2412.16420v1](http://arxiv.org/abs/2412.16420v1)|[link](https://github.com/junyiye/textflow)|
|**2024-12-20**|**HybGRAG: Hybrid Retrieval-Augmented Generation on Textual and Relational Knowledge Bases**|Meng-Chieh Lee et.al.|[2412.16311v1](http://arxiv.org/abs/2412.16311v1)|null|
|**2024-12-20**|**Logical Consistency of Large Language Models in Fact-checking**|Bishwamittra Ghosh et.al.|[2412.16100v1](http://arxiv.org/abs/2412.16100v1)|null|
|**2024-12-20**|**GraphSeqLM: A Unified Graph Language Framework for Omic Graph Learning**|Heming Zhang et.al.|[2412.15790v1](http://arxiv.org/abs/2412.15790v1)|null|
|**2024-12-20**|**KRAIL: A Knowledge-Driven Framework for Base Human Reliability Analysis Integrating IDHEAS and Large Language Models**|Xingyu Xiao et.al.|[2412.18627v1](http://arxiv.org/abs/2412.18627v1)|null|
|**2024-12-20**|**NGQA: A Nutritional Graph Question Answering Benchmark for Personalized Health-aware Nutritional Reasoning**|Zheyuan Zhang et.al.|[2412.15547v1](http://arxiv.org/abs/2412.15547v1)|null|
|**2024-12-19**|**SKETCH: Structured Knowledge Enhanced Text Comprehension for Holistic Retrieval**|Aakash Mahalingam et.al.|[2412.15443v1](http://arxiv.org/abs/2412.15443v1)|null|
|**2024-12-19**|**Graph-Convolutional Networks: Named Entity Recognition and Large Language Model Embedding in Document Clustering**|Imed Keraghel et.al.|[2412.14867v1](http://arxiv.org/abs/2412.14867v1)|null|
|**2024-12-19**|**Answer Set Networks: Casting Answer Set Programming into Deep Learning**|Arseny Skryagin et.al.|[2412.14814v1](http://arxiv.org/abs/2412.14814v1)|[link](https://github.com/ml-research/answersetnetworks)|
|**2024-12-19**|**IOHunter: Graph Foundation Model to Uncover Online Information Operations**|Marco Minici et.al.|[2412.14663v1](http://arxiv.org/abs/2412.14663v1)|[link](https://github.com/mminici/socgfm)|
|**2024-12-19**|**GraphEQA: Using 3D Semantic Scene Graphs for Real-time Embodied Question Answering**|Saumya Saxena et.al.|[2412.14480v1](http://arxiv.org/abs/2412.14480v1)|null|
|**2024-12-18**|**Discovering maximally consistent distribution of causal tournaments with Large Language Models**|Federico Baldo et.al.|[2412.14019v1](http://arxiv.org/abs/2412.14019v1)|null|
|**2024-12-18**|**DODGE: Ontology-Aware Risk Assessment via Object-Oriented Disruption Graphs**|Stefano M. Nicoletti et.al.|[2412.13964v1](http://arxiv.org/abs/2412.13964v1)|null|

#### Abstracts
##### **LLM-Assisted Knowledge Graph Completion for Curriculum and Domain Modelling in Personalized Higher Education Recommendations**
2501.12300v1 by Hasan Abu-Rasheed, Constance Jumbo, Rashed Al Amin, Christian Weber, Veit Wiese, Roman Obermaisser, Madjid Fathi

While learning personalization offers great potential for learners, modern
practices in higher education require a deeper consideration of domain models
and learning contexts, to develop effective personalization algorithms. This
paper introduces an innovative approach to higher education curriculum
modelling that utilizes large language models (LLMs) for knowledge graph (KG)
completion, with the goal of creating personalized learning-path
recommendations. Our research focuses on modelling university subjects and
linking their topics to corresponding domain models, enabling the integration
of learning modules from different faculties and institutions in the student's
learning path. Central to our approach is a collaborative process, where LLMs
assist human experts in extracting high-quality, fine-grained topics from
lecture materials. We develop a domain, curriculum, and user models for
university modules and stakeholders. We implement this model to create the KG
from two study modules: Embedded Systems and Development of Embedded Systems
Using FPGA. The resulting KG structures the curriculum and links it to the
domain models. We evaluate our approach through qualitative expert feedback and
quantitative graph quality metrics. Domain experts validated the relevance and
accuracy of the model, while the graph quality metrics measured the structural
properties of our KG. Our results show that the LLM-assisted graph completion
approach enhances the ability to connect related courses across disciplines to
personalize the learning experience. Expert feedback also showed high
acceptance of the proposed collaborative approach for concept extraction and
classification.

æè¦ï¼<paragraph>å¨å­¸ç¿åäººåæä¾å­¸ç¿èå·¨å¤§æ½åçåæï¼é«ç­æè²ä¸­çç¾ä»£å¯¦åéè¦æ´æ·±å¥å°èæ®é åæ¨¡ååå­¸ç¿æå¢ï¼ä»¥éç¼ææçåäººåæ¼ç®æ³ãæ¬æä»ç´¹äºä¸ç¨®åµæ°çé«ç­æè²èª²ç¨å»ºæ¨¡æ¹æ³ï¼è©²æ¹æ³å©ç¨å¤§åèªè¨æ¨¡å (LLM) ä¾å®æç¥è­åè­ (KG)ï¼ç®çæ¯å»ºç«åäººåçå­¸ç¿è·¯å¾å»ºè­°ãæåçç ç©¶éé»å¨æ¼å»ºæ¨¡å¤§å­¸ç§ç®ï¼ä¸¦å°å®åçä¸»é¡é£çµå°å°æçé åæ¨¡åï¼å¾èè½å¤ å°ä¾èªä¸åé¢ç³»åæ©æ§çå­¸ç¿æ¨¡çµæ´åå°å­¸ççå­¸ç¿è·¯å¾ä¸­ãæåçåæ³æ ¸å¿æ¯ä¸ååä½æµç¨ï¼å¶ä¸­ LLM åå©äººé¡å°å®¶å¾è¬ç¾©ææä¸­èåé«åè³ªãç´°ç·»çä¸»é¡ãæåçºå¤§å­¸æ¨¡çµåå©å®³éä¿äººéç¼äºé åãèª²ç¨åä½¿ç¨èæ¨¡åãæåå¯¦ä½éåæ¨¡åï¼å¾å©åç ç©¶æ¨¡çµå»ºç« KGï¼åµå¥å¼ç³»çµ±åä½¿ç¨ FPGA çåµå¥å¼ç³»çµ±éç¼ãç¢çç KG å»ºæ§äºèª²ç¨ä¸¦å°å¶é£çµå°é åæ¨¡åãæåééå®æ§å°å®¶åé¥åå®éåå½¢åè³ªææ¨ä¾è©ä¼°æåçåæ³ãé åå°å®¶é©è­äºæ¨¡åçç¸éæ§åæºç¢ºæ§ï¼èåå½¢åè³ªææ¨åæ¸¬éäºæå KG ççµæ§ç¹æ§ãæåççµæé¡¯ç¤ºï¼LLM è¼å©çåå½¢å®ææ¹æ³å¢å¼·äºè·¨å­¸ç§é£çµç¸éèª²ç¨çè½åï¼ä»¥åäººåå­¸ç¿é«é©ãå°å®¶åé¥ä¹é¡¯ç¤ºé«åº¦æ¥åææåºçåä½æ¹æ³ï¼ç¨æ¼æ¦å¿µèåååé¡ã</paragraph>

##### **Divide-Then-Aggregate: An Efficient Tool Learning Method via Parallel Tool Invocation**
2501.12432v1 by Dongsheng Zhu, Weixian Shi, Zhengliang Shi, Zhaochun Ren, Shuaiqiang Wang, Lingyong Yan, Dawei Yin

Although current Large Language Models (LLMs) exhibit impressive
capabilities, performing complex real-world tasks still requires tool learning.
Mainstream methods, such as CoT/ReAct, rely on step-by-step tool invocation to
interact with external environments, but they are limited in perceptual scope
and lack adequate task-planning capability. To address these limitations, other
studies introduce the first Search-based Decision Tree (DFSDT), which still
suffers from the high computational cost. In this paper, we introduce a novel
parallel tool invocation paradigm, DTA-Llama (Divide-Then-Aggregate Llama).
First, we transform traditional tree-based tool search paths into Directed
Acyclic Graph (DAG) structure, generating a high-quality parallel tool
invocation dataset. The DTA-Llama is then trained on the dataset to learn to
iteratively divide the current task into several parallel tool invocation
sub-tasks and aggregate the invocation results to decide the next actions.
Furthermore, we introduce an efficient inference framework inspired by the
Process/Threads mechanism when applying the DTA-Llama to practical tasks.
Experimental results show that our approach substantially enhances task
performance while reducing token consumption and inference time. Llama2-7B,
using our method, is comparable to the official parallel function calling
method of GPT-3.5. The relevant code, dataset, and model weights are available
at https://corn0205.github.io/

æè¦ï¼åç®¡ç®åçå¤§åèªè¨æ¨¡å (LLM) å±ç¾åºä»¤äººå°è±¡æ·±å»çè½åï¼ä½å·è¡è¤éççå¯¦ä¸çä»»åä»éè¦å·¥å·å­¸ç¿ãä¸»æµæ¹æ³ï¼ä¾å¦ CoT/ReActï¼ä¾è³´éæ­¥å·¥å·å¼å«èå¤é¨ç°å¢äºåï¼ä½å®åçæç¥ç¯åæéï¼ä¸ç¼ºä¹è¶³å¤ çä»»åè¦åè½åãçºäºè§£æ±ºéäºéå¶ï¼å¶ä»ç ç©¶å¼å¥äºç¬¬ä¸ååºæ¼æå°çæ±ºç­æ¨¹ (DFSDT)ï¼ä½ä»æå¾é«çéç®ææ¬ãå¨æ¬æä¸­ï¼æåä»ç´¹äºä¸ç¨®æ°ç©çå¹³è¡å·¥å·å¼å«ç¯ä¾ï¼DTA-Llamaï¼åèåä¹ Llamaï¼ãé¦åï¼æåå°å³çµ±çåºæ¼æ¨¹çå·¥å·æå°è·¯å¾è½æçºæåç¡ç°å (DAG) çµæ§ï¼ç¢çé«åè³ªçå¹³è¡å·¥å·å¼å«è³æéãç¶å¾å¨è³æéä¸è¨ç·´ DTA-Llamaï¼å­¸ç¿åè¦å°ç¶åä»»ååæå¹¾åå¹³è¡å·¥å·å¼å«å­ä»»åï¼ä¸¦å½ç¸½å¼å«çµæä»¥æ±ºå®å¾çºåä½ãæ­¤å¤ï¼æåå¨å° DTA-Llama æç¨æ¼å¯¦éä»»åæï¼å¼å¥äºä¸åå Process/Threads æ©å¶åç¼çé«ææ¨è«æ¡æ¶ãå¯¦é©çµæè¡¨æï¼æåçåæ³å¤§å¹æåäºä»»åæè½ï¼åææ¸å°äºç¬¦èæ¶èåæ¨è«æéãä½¿ç¨æåæ¹æ³ç Llama2-7Bï¼å¯è GPT-3.5 çå®æ¹å¹³è¡å½å¼å¼å«æ¹æ³ç¸åª²ç¾ãç¸éç¨å¼ç¢¼ãè³æéåæ¨¡åæ¬éå¯å¨ https://corn0205.github.io/ åå¾

##### **InsTALL: Context-aware Instructional Task Assistance with Multi-modal Large Language Models**
2501.12231v1 by Pha Nguyen, Sailik Sengupta, Girik Malik, Arshit Gupta, Bonan Min

The improved competence of generative models can help building multi-modal
virtual assistants that leverage modalities beyond language. By observing
humans performing multi-step tasks, one can build assistants that have
situational awareness of actions and tasks being performed, enabling them to
cater assistance based on this understanding. In this paper, we develop a
Context-aware Instructional Task Assistant with Multi-modal Large Language
Models (InsTALL) that leverages an online visual stream (e.g. a user's screen
share or video recording) and responds in real-time to user queries related to
the task at hand. To enable useful assistance, InsTALL 1) trains a multi-modal
model on task videos and paired textual data, and 2) automatically extracts
task graph from video data and leverages it at training and inference time. We
show InsTALL achieves state-of-the-art performance across proposed sub-tasks
considered for multimodal activity understanding -- task recognition (TR),
action recognition (AR), next action prediction (AP), and plan prediction (PP)
-- and outperforms existing baselines on two novel sub-tasks related to
automatic error identification.

æè¦ï¼çææ¨¡åè½åçæåæå©äºæå»ºå©ç¨è¯­è¨ä¹å¤çå¤æ¨¡æèæå©æãéè¿è§å¯äººç±»æ§è¡å¤æ­¥éª¤ä»»å¡ï¼å¯ä»¥æå»ºå¯¹æ­£å¨æ§è¡çå¨ä½åä»»å¡ææå¢æç¥çå©æï¼ä½¿ä»ä»¬è½å¤æ ¹æ®è¿ç§çè§£æä¾å¸®å©ãå¨æ¬æä¸­ï¼æä»¬å¼åäºä¸ä¸ªå·æå¤æ¨¡æå¤§è¯­è¨æ¨¡åçä¸ä¸ææç¥æä»¤ä»»å¡å©æ (InsTALL)ï¼è¯¥å©æå©ç¨å¨çº¿è§è§æµï¼ä¾å¦ç¨æ·çå±å¹å±äº«æè§é¢å½å¶ï¼ï¼å¹¶å®æ¶ååºä¸æå¤´ä»»å¡ç¸å³çç¨æ·æ¥è¯¢ãä¸ºäºæä¾æç¨çå¸®å©ï¼InsTALL 1) å¨ä»»å¡è§é¢åéå¯¹ææ¬æ°æ®ä¸è®­ç»å¤æ¨¡ææ¨¡åï¼ä»¥å 2) ä»è§é¢æ°æ®ä¸­èªå¨æåä»»å¡å¾ï¼å¹¶å¨è®­ç»åæ¨çæ¶é´å©ç¨å®ãæä»¬å±ç¤ºäº InsTALL å¨èèç¨äºå¤æ¨¡ææ´»å¨çè§£çæè®®å­ä»»å¡ä¸­å®ç°äºæåè¿çæ§è½ââä»»å¡è¯å« (TR)ãå¨ä½è¯å« (AR)ãä¸ä¸ä¸ªå¨ä½é¢æµ (AP) åè®¡åé¢æµ (PP)ââå¹¶ä¸å¨ä¸èªå¨éè¯¯è¯å«ç¸å³çä¸¤ä¸ªæ°å­ä»»å¡ä¸ä¼äºç°æçåºåã

##### **Leveraging Graph Structures and Large Language Models for End-to-End Synthetic Task-Oriented Dialogues**
2501.11977v1 by Maya Medjad, Hugo Imbert, Bruno Yun, RaphaÃ«l Szymocha, FrÃ©dÃ©ric Armetta

Training task-oriented dialogue systems is both costly and time-consuming,
due to the need for high-quality datasets encompassing diverse intents.
Traditional methods depend on extensive human annotation, while recent
advancements leverage large language models (LLMs) to generate synthetic data.
However, these approaches often require custom prompts or code, limiting
accessibility for non-technical users. We introduce GraphTOD, an end-to-end
framework that simplifies the generation of task-oriented dialogues. Users can
create dialogues by specifying transition graphs in JSON format. Our evaluation
demonstrates that GraphTOD generates high-quality dialogues across various
domains, significantly lowering the cost and complexity of dataset creation.

æè¦ï¼è¨ç·´ä»»åå°åå°è©±ç³»çµ±æ¢æè²´åèæï¼
å çºéè¦åå«åç¨®æåçé«åè³ªè³æéã
å³çµ±æ¹æ³ä¾è³´æ¼å»£æ³çäººå·¥æ¨è¨»ï¼èæè¿
çé²å±å©ç¨å¤§åèªè¨æ¨¡å (LLM) ä¾ç¢çåæè³æã
ç¶èï¼éäºæ¹æ³éå¸¸éè¦èªè¨æç¤ºæç¨å¼ç¢¼ï¼éå¶
éæè¡ä½¿ç¨èçå¯åæ§ãæåä»ç´¹ GraphTODï¼ä¸åç«¯å°ç«¯ç
æ¶æ§ï¼ç°¡åäºä»»åå°åå°è©±çç¢çãä½¿ç¨èå¯ä»¥
ééæå® JSON æ ¼å¼çè½æåè¡¨ä¾å»ºç«å°è©±ãæåçè©ä¼°
è­æ GraphTOD å¨åç¨®é åç¢çé«åè³ªå°è©±ï¼é¡¯èéä½è³æéå»ºç«çææ¬åè¤éæ§ã

##### **Bridging Visualization and Optimization: Multimodal Large Language Models on Graph-Structured Combinatorial Optimization**
2501.11968v1 by Jie Zhao, Kang Hao Cheong, Witold Pedrycz

Graph-structured combinatorial challenges are inherently difficult due to
their nonlinear and intricate nature, often rendering traditional computational
methods ineffective or expensive. However, these challenges can be more
naturally tackled by humans through visual representations that harness our
innate ability for spatial reasoning. In this study, we propose transforming
graphs into images to preserve their higher-order structural features
accurately, revolutionizing the representation used in solving graph-structured
combinatorial tasks. This approach allows machines to emulate human-like
processing in addressing complex combinatorial challenges. By combining the
innovative paradigm powered by multimodal large language models (MLLMs) with
simple search techniques, we aim to develop a novel and effective framework for
tackling such problems. Our investigation into MLLMs spanned a variety of
graph-based tasks, from combinatorial problems like influence maximization to
sequential decision-making in network dismantling, as well as addressing six
fundamental graph-related issues. Our findings demonstrate that MLLMs exhibit
exceptional spatial intelligence and a distinctive capability for handling
these problems, significantly advancing the potential for machines to
comprehend and analyze graph-structured data with a depth and intuition akin to
human cognition. These results also imply that integrating MLLMs with simple
optimization strategies could form a novel and efficient approach for
navigating graph-structured combinatorial challenges without complex
derivations, computationally demanding training and fine-tuning.

æè¦ï¼åå½¢çµæ§ççµåææ°æ¬è³ªä¸å¾å°é£ï¼å çºå®åçéç·æ§åè¤éæ§ï¼éå¸¸æä½¿å³çµ±çè¨ç®æ¹æ³ç¡æææè²´ãç¶èï¼äººé¡å¯ä»¥ééå©ç¨æåå¤©ççç©ºéæ¨çè½åçè¦è¦ºè¡¨å¾µï¼æ´èªç¶å°æå°éäºææ°ãå¨æ¬ç ç©¶ä¸­ï¼æåå»ºè­°å°åå½¢è½æçºå½±åï¼ä»¥æºç¢ºä¿çå®åçé«éçµæ§ç¹å¾µï¼å¾èé©æ°ç¨æ¼è§£æ±ºåå½¢çµæ§çµåä»»åçè¡¨å¾µãéç¨®æ¹æ³åè¨±æ©å¨å¨è§£æ±ºè¤éççµåææ°ææ¨¡æ¬é¡äººçèçãééçµåç±å¤æ¨¡æå¤§åèªè¨æ¨¡å (MLLM) æä¾ååçåµæ°ç¯ä¾èç°¡å®çæå°æè¡ï¼æåæ¨å¨çºè§£æ±ºæ­¤é¡åé¡éç¼ä¸åæ°ç©ä¸ææçæ¶æ§ãæåå° MLLM çç ç©¶æ¶µèäºåç¨®åºæ¼åå½¢çä»»åï¼å¾çµååé¡ï¼å¦å½±é¿åæå¤§åï¼å°ç¶²è·¯æé¤ä¸­çé åºæ±ºç­å¶å®ï¼ä»¥åè§£æ±ºå­ååºæ¬çåå½¢ç¸éåé¡ãæåçç ç©¶çµæè¡¨æï¼MLLM è¡¨ç¾åºéå¡çç©ºéæºè½åèçéäºåé¡çç¨ç¹è½åï¼é¡¯èæåäºæ©å¨ä»¥é¡ä¼¼äººé¡èªç¥çæ·±åº¦åç´è¦ºä¾çè§£ååæåå½¢çµæ§è³æçæ½åãéäºçµæéæç¤ºï¼å° MLLM èç°¡å®çæä½³åç­ç¥æ´åå¨ä¸èµ·ï¼å¯ä»¥å½¢æä¸ç¨®æ°ç©ä¸ææçæ¹æ³ï¼ç¨æ¼å¨æ²æè¤éæ¨å°ãè¨ç®éæ±éå¤§çè¨ç·´åå¾®èª¿çææ³ä¸æå°åå½¢çµæ§ççµåææ°ã

##### **Network-informed Prompt Engineering against Organized Astroturf Campaigns under Extreme Class Imbalance**
2501.11849v1 by Nikos Kanakaris, Heng Ping, Xiongye Xiao, Nesreen K. Ahmed, Luca Luceri, Emilio Ferrara, Paul Bogdan

Detecting organized political campaigns is of paramount importance in
fighting against disinformation on social media. Existing approaches for the
identification of such organized actions employ techniques mostly from network
science, graph machine learning and natural language processing. Their ultimate
goal is to analyze the relationships and interactions (e.g. re-posting) among
users and the textual similarities of their posts. Despite their effectiveness
in recognizing astroturf campaigns, these methods face significant challenges,
notably the class imbalance in available training datasets. To mitigate this
issue, recent methods usually resort to data augmentation or increasing the
number of positive samples, which may not always be feasible or sufficient in
real-world settings. Following a different path, in this paper, we propose a
novel framework for identifying astroturf campaigns based solely on large
language models (LLMs), introducing a Balanced Retrieval-Augmented Generation
(Balanced RAG) component. Our approach first gives both textual information
concerning the posts (in our case tweets) and the user interactions of the
social network as input to a language model. Then, through prompt engineering
and the proposed Balanced RAG method, it effectively detects coordinated
disinformation campaigns on X (Twitter). The proposed framework does not
require any training or fine-tuning of the language model. Instead, by
strategically harnessing the strengths of prompt engineering and Balanced RAG,
it facilitates LLMs to overcome the effects of class imbalance and effectively
identify coordinated political campaigns. The experimental results demonstrate
that by incorporating the proposed prompt engineering and Balanced RAG methods,
our framework outperforms the traditional graph-based baselines, achieving
2x-3x improvements in terms of precision, recall and F1 scores.

æè¦ï¼<paragraph>å¨ç¤¾äº¤åªé«ä¸ææé¯èª¤è³è¨ï¼åµæ¸¬æçµç¹çæ¿æ²»å®£å³è³ééè¦ãç¾æçæ­¤é¡æçµç¹è¡åè­å¥æ¹æ³ï¼ä¸»è¦æ¡ç¨ç¶²è·¯ç§å­¸ãåå½¢æ©å¨å­¸ç¿åèªç¶èªè¨èççæè¡ãå¶æçµç®æ¨æ¯åæä½¿ç¨èä¹éçéä¿åäºåï¼ä¾å¦è½ç¼ï¼ï¼ä»¥åå¶è²¼æçæå­ç¸ä¼¼åº¦ãåç®¡éäºæ¹æ³å¨è¾¨è­åèæ ¹éåå®£å³ä¸å¾ææï¼ä½ä»é¢è¨éå¤§ææ°ï¼ç¹å¥æ¯å¯ç¨è¨ç·´è³æéä¸­çé¡å¥ä¸å¹³è¡¡ãçºäºæ¸è¼éååé¡ï¼æè¿çæ¹æ³éå¸¸è¨´è«¸æ¼è³ææ´åæå¢å æ­£åæ¨£æ¬æ¸éï¼ä½å¨ç¾å¯¦ä¸çä¸­ï¼éä¸¦ä¸ç¸½æ¯å¯è¡æè¶³å¤ çãæ¬ææ¡è¡ä¸åçéå¾ï¼æåæåºä¸ååºæ¼å¤§åèªè¨æ¨¡å (LLM) çæ°åæ¡æ¶ï¼ç¨æ¼è­å¥åèæ ¹éåå®£å³ï¼ä¸¦å¼å¥å¹³è¡¡æª¢ç´¢æ´åçæ (Balanced RAG) åä»¶ãæåçåæ³é¦åå°æéè²¼æï¼å¨æ¬ä¾ä¸­çºæ¨æï¼çæå­è³è¨åç¤¾äº¤ç¶²è·¯çä½¿ç¨èäºåä½çºè¼¸å¥ï¼æä¾çµ¦èªè¨æ¨¡åãç¶å¾ï¼ééæç¤ºå·¥ç¨åæåºçå¹³è¡¡æª¢ç´¢æ´åçææ¹æ³ï¼å®ææå°åµæ¸¬ X (Twitter) ä¸åèª¿çé¯èª¤è³è¨å®£å³ãæåºçæ¡æ¶ä¸éè¦ä»»ä½èªè¨æ¨¡åçè¨ç·´æå¾®èª¿ãç¸åå°ï¼ééç­ç¥æ§å°å©ç¨æç¤ºå·¥ç¨åå¹³è¡¡æª¢ç´¢æ´åçæçåªå¢ï¼å®è½è®å¤§åèªè¨æ¨¡ååæé¡å¥ä¸å¹³è¡¡çå½±é¿ï¼ä¸¦ææè­å¥åèª¿çæ¿æ²»å®£å³ãå¯¦é©çµæè­æï¼ééæ´åæåºçæç¤ºå·¥ç¨åå¹³è¡¡æª¢ç´¢æ´åçææ¹æ³ï¼æåçæ¡æ¶åªæ¼å³çµ±çåºæ¼åå½¢çåºæºï¼å¨ç²¾æºåº¦ãå¬åçå F1 åæ¸æ¹é¢ç²å¾ 2x-3x çæåã</paragraph>

##### **Explainable Lane Change Prediction for Near-Crash Scenarios Using Knowledge Graph Embeddings and Retrieval Augmented Generation**
2501.11560v1 by M. Manzour, A. Ballardini, R. Izquierdo, M. Ã. Sotelo

Lane-changing maneuvers, particularly those executed abruptly or in risky
situations, are a significant cause of road traffic accidents. However, current
research mainly focuses on predicting safe lane changes. Furthermore, existing
accident datasets are often based on images only and lack comprehensive sensory
data. In this work, we focus on predicting risky lane changes using the CRASH
dataset (our own collected dataset specifically for risky lane changes), and
safe lane changes (using the HighD dataset). Then, we leverage KG and Bayesian
inference to predict these maneuvers using linguistic contextual information,
enhancing the model's interpretability and transparency. The model achieved a
91.5% f1-score with anticipation time extending to four seconds for risky lane
changes, and a 90.0% f1-score for predicting safe lane changes with the same
anticipation time. We validate our model by integrating it into a vehicle
within the CARLA simulator in scenarios that involve risky lane changes. The
model managed to anticipate sudden lane changes, thus providing automated
vehicles with further time to plan and execute appropriate safe reactions.
Finally, to enhance the explainability of our model, we utilize RAG to provide
clear and natural language explanations for the given prediction.

æè¦ï¼æè»éåä½ï¼å°¤å¶æ¯çªç¶æå¨é¢¨éªææ³ä¸å·è¡çåä½ï¼æ¯éè·¯äº¤éäºæçéè¦åå ãç¶èï¼ç®åçç ç©¶æä¸»è¦éä¸­å¨é æ¸¬å®å¨çæè»éãæ­¤å¤ï¼ç¾æçäºæè³æééå¸¸ååºæ¼å½±åï¼ä¸ç¼ºä¹å¨é¢çææ¸¬è³æãå¨éé å·¥ä½ä¸­ï¼æåå°æ³¨æ¼ä½¿ç¨ CRASH è³æéï¼æåèªå·±æ¶éçå°ééå°é¢¨éªæè»éè³æéï¼ä¾é æ¸¬é¢¨éªæè»éï¼ä»¥åå®å¨æè»éï¼ä½¿ç¨ HighD è³æéï¼ãç¶å¾ï¼æåå©ç¨ KG åè²æ°æ¨çä¾ä½¿ç¨èªè¨èæ¯è³è¨é æ¸¬éäºåä½ï¼å¢å¼·æ¨¡åçå¯è§£éæ§åéæåº¦ãè©²æ¨¡åå¨é¢¨éªæè»éçé æ¸¬æéå»¶é·è³åç§æï¼éå°äº 91.5% ç f1 åæ¸ï¼å¨é æ¸¬å®å¨æè»éæï¼å¨ç¸åçé æ¸¬æéå§éå°äº 90.0% ç f1 åæ¸ãæåééå°æ¨¡åæ´åå° CARLA æ¨¡æ¬å¨ä¸­çè»è¼ä¸­ï¼å¨æ¶åé¢¨éªæè»éçå ´æ¯ä¸­é©è­æåçæ¨¡åãè©²æ¨¡åè¨­æ³é æ¸¬çªç¶çæè»éï¼å¾èçºèªåé§é§è»è¼æä¾äºæ´å¤æéä¾è¦ååå·è¡é©ç¶çå®å¨åæãæå¾ï¼çºäºå¢å¼·æåæ¨¡åçå¯è§£éæ§ï¼æåå©ç¨ RAG çºçµ¦å®çé æ¸¬æä¾æ¸æ°ä¸èªç¶çèªè¨è§£éã

##### **Graph-defined Language Learning with LLMs**
2501.11478v1 by Huachi Zhou, Jiahe Du, Chuang Zhou, Chang Yang, Yilin Xiao, Yuxuan Xie, Xiao Huang

Recent efforts leverage Large Language Models (LLMs) for modeling
text-attributed graph structures in node classification tasks. These approaches
describe graph structures for LLMs to understand or aggregate LLM-generated
textual attribute embeddings through graph structure. However, these approaches
face two main limitations in modeling graph structures with LLMs. (i) Graph
descriptions become verbose in describing high-order graph structure. (ii)
Textual attributes alone do not contain adequate graph structure information.
It is challenging to model graph structure concisely and adequately with LLMs.
LLMs lack built-in mechanisms to model graph structures directly. They also
struggle with complex long-range dependencies between high-order nodes and
target nodes.
  Inspired by the observation that LLMs pre-trained on one language can achieve
exceptional performance on another with minimal additional training, we propose
\textbf{G}raph-\textbf{D}efined \textbf{L}anguage for \textbf{L}arge
\textbf{L}anguage \textbf{M}odel (GDL4LLM). This novel framework enables LLMs
to transfer their powerful language understanding capabilities to
graph-structured data. GDL4LLM translates graphs into a graph language corpus
instead of graph descriptions and pre-trains LLMs on this corpus to adequately
understand graph structures. During fine-tuning, this corpus describes the
structural information of target nodes concisely with only a few tokens. By
treating graphs as a new language, GDL4LLM enables LLMs to model graph
structures adequately and concisely for node classification tasks. Extensive
experiments on three real-world datasets demonstrate that GDL4LLM outperforms
description-based and textual attribute embeddings-based baselines by
efficiently modeling different orders of graph structure with LLMs.

æè¦ï¼<paragraph>æè¿çç ç©¶å©ç¨å¤§åèªè¨æ¨¡å (LLM) å¨ç¯é»åé¡ä»»åä¸­å°ææ¬å±¬æ§åçµæ§é²è¡å»ºæ¨¡ãéäºæ¹æ³æè¿°åçµæ§ï¼è® LLM äºè§£æå½ç¸½ééåçµæ§çæç LLM ææ¬å±¬æ§åµå¥ãç¶èï¼éäºæ¹æ³å¨ä½¿ç¨ LLM å°åçµæ§é²è¡å»ºæ¨¡æé¢è¨å©åä¸»è¦éå¶ã(i) åæè¿°å¨æè¿°é«éåçµæ§æè®å¾åé·ã(ii) åææ¬å±¬æ§ä¸åå«è¶³å¤ çåçµæ§è³è¨ãä½¿ç¨ LLM å°åçµæ§é²è¡ç°¡æ½ä¸ååçå»ºæ¨¡å·æææ°æ§ãLLM ç¼ºä¹å§å»ºæ©å¶ä¾ç´æ¥å°åçµæ§é²è¡å»ºæ¨¡ãå®åéé£ä»¥èçé«éç¯é»åç®æ¨ç¯é»ä¹éè¤éçé·ç¨ä¾è³´éä¿ã
å LLM å¨ä¸ç¨®èªè¨ä¸é²è¡é è¨ç·´å¾ï¼å©ç¨æå°çé¡å¤è¨ç·´å°±è½å¨å¦ä¸ç¨®èªè¨ä¸åå¾éå¡è¡¨ç¾çè§å¯åç¼ï¼æåæåºäºå¤§åèªè¨æ¨¡åçåå®ç¾©èªè¨ (GDL4LLM)ãéåæ°ç©çæ¡æ¶ä½¿ LLM è½å°å¶å¼·å¤§çèªè¨çè§£è½åè½ç§»å°åçµæ§è³æãGDL4LLM å°åå½¢è½ææåå½¢èªè¨èªæåº«ï¼èä¸æ¯åå½¢æè¿°ï¼ä¸¦å¨éåèªæåº«ä¸å° LLM é²è¡é è¨ç·´ï¼ä»¥ååçè§£åå½¢çµæ§ãå¨å¾®èª¿éç¨ä¸­ï¼éåèªæåº«åä½¿ç¨å°æ¸å¹¾åæ¨è¨ï¼å°±è½ç°¡æ½å°æè¿°ç®æ¨ç¯é»ççµæ§è³è¨ãééå°åå½¢è¦çºä¸ç¨®æ°çèªè¨ï¼GDL4LLM ä½¿ LLM è½å¤ ååä¸ç°¡æ½å°çºç¯é»åé¡ä»»åå°åå½¢çµæ§é²è¡å»ºæ¨¡ãå¨ä¸åçå¯¦ä¸çè³æéä¸é²è¡çå»£æ³å¯¦é©è­æï¼GDL4LLM è½ææå°ä½¿ç¨ LLM å°ä¸åé åºçåå½¢çµæ§é²è¡å»ºæ¨¡ï¼å¾èåªæ¼åºæ¼æè¿°ååºæ¼ææ¬å±¬æ§åµå¥çåºæºã</paragraph>

##### **Few-shot Policy (de)composition in Conversational Question Answering**
2501.11335v1 by Kyle Erwin, Guy Axelrod, Maria Chang, Achille Fokoue, Maxwell Crouse, Soham Dan, Tian Gao, Rosario Uceda-Sosa, Ndivhuwo Makondo, Naweed Khan, Alexander Gray

The task of policy compliance detection (PCD) is to determine if a scenario
is in compliance with respect to a set of written policies. In a conversational
setting, the results of PCD can indicate if clarifying questions must be asked
to determine compliance status. Existing approaches usually claim to have
reasoning capabilities that are latent or require a large amount of annotated
data. In this work, we propose logical decomposition for policy compliance
(LDPC): a neuro-symbolic framework to detect policy compliance using large
language models (LLMs) in a few-shot setting. By selecting only a few exemplars
alongside recently developed prompting techniques, we demonstrate that our
approach soundly reasons about policy compliance conversations by extracting
sub-questions to be answered, assigning truth values from contextual
information, and explicitly producing a set of logic statements from the given
policies. The formulation of explicit logic graphs can in turn help answer
PCDrelated questions with increased transparency and explainability. We apply
this approach to the popular PCD and conversational machine reading benchmark,
ShARC, and show competitive performance with no task-specific finetuning. We
also leverage the inherently interpretable architecture of LDPC to understand
where errors occur, revealing ambiguities in the ShARC dataset and highlighting
the challenges involved with reasoning for conversational question answering.

æè¦ï¼ç­ç¥åè¦åµæ¸¬ (PCD) çä»»åæ¯ç¢ºå®å ´æ¯æ¯å¦ç¬¦åä¸çµæ¸é¢ç­ç¥ãå¨å°è©±è¨­å®ä¸­ï¼PCD ççµæå¯ä»¥æåºæ¯å¦å¿é æåºæ¾æ¸åé¡ä»¥ç¢ºå®åè¦çæãç¾æçæ¹æ³éå¸¸è²ç¨±å·ææ½å¨çæ¨çè½åï¼æéè¦å¤§éçè¨»éè³æãå¨éé å·¥ä½ä¸­ï¼æåæåºç­ç¥åè¦çéè¼¯åè§£ (LDPC)ï¼ä¸ç¨®ä½¿ç¨å¤§åèªè¨æ¨¡å (LLM) å¨å°æ¬¡åè©¦ä¸­åµæ¸¬ç­ç¥åè¦çç¥ç¶ç¬¦èæ¡æ¶ãééåé¸æå°æ¸ç¯ä¾ä»¥åæè¿éç¼çæç¤ºæè¡ï¼æåè­ææåçåæ³ééæåè¦åç­çå­åé¡ãå¾èçµ¡è³è¨ææ´¾çå¼ï¼ä»¥åå¾çµ¦å®çç­ç¥æç¢ºç¢çä¸çµéè¼¯é³è¿°ï¼å°ç­ç¥åè¦å°è©±é²è¡åççæ¨çãæç¢ºéè¼¯åè¡¨çå¶å®åéä¾å¯ä»¥å¹«å©åç­ PCD ç¸éåé¡ï¼ä¸¦æé«éæåº¦åå¯è§£éæ§ãæåå°æ­¤æ¹æ³æç¨æ¼ç±éç PCD åå°è©±å¼æ©å¨é±è®åºæº ShARCï¼ä¸¦å¨æ²æç¹å®ä»»åå¾®èª¿çææ³ä¸å±ç¾åºç«¶ç­åãæåä¹å©ç¨ LDPC åºæçå¯è§£éæ¶æ§ä¾äºè§£é¯èª¤ç¼çå¨åªè£¡ï¼æ­é² ShARC è³æéä¸­çæ­§ç¾©ï¼ä¸¦å¼·èª¿å°è©±å¼åé¡è§£ç­æ¨ççææ°ã

##### **Reasoning Language Models: A Blueprint**
2501.11223v2 by Maciej Besta, Julia Barth, Eric Schreiber, Ales Kubicek, Afonso Catarino, Robert Gerstenberger, Piotr Nyczyk, Patrick Iff, Yueling Li, Sam Houliston, Tomasz Sternal, Marcin Copik, Grzegorz KwaÅniewski, JÃ¼rgen MÃ¼ller, Åukasz Flis, Hannes Eberhard, Hubert Niewiadomski, Torsten Hoefler

Reasoning language models (RLMs), also known as Large Reasoning Models
(LRMs), such as OpenAI's o1 and o3, DeepSeek-V3, and Alibaba's QwQ, have
redefined AI's problem-solving capabilities by extending LLMs with advanced
reasoning mechanisms. Yet, their high costs, proprietary nature, and complex
architectures - uniquely combining Reinforcement Learning (RL), search
heuristics, and LLMs - present accessibility and scalability challenges. To
address these, we propose a comprehensive blueprint that organizes RLM
components into a modular framework, based on a survey and analysis of all RLM
works. This blueprint incorporates diverse reasoning structures (chains, trees,
graphs, and nested forms), reasoning strategies (e.g., Monte Carlo Tree Search,
Beam Search), RL concepts (policy, value models and others), supervision
schemes (Outcome-Based and Process-Based Supervision), and other related
concepts (e.g., Test-Time Compute, Retrieval-Augmented Generation, agent
tools). We provide detailed mathematical formulations and algorithmic
specifications to simplify RLM implementation. By showing how schemes like
LLaMA-Berry, QwQ, Journey Learning, and Graph of Thoughts fit as special cases,
we demonstrate the blueprint's versatility and unifying potential. To
illustrate its utility, we introduce x1, a modular implementation for rapid RLM
prototyping and experimentation. Using x1 and a literature review, we provide
key insights, such as multi-phase training for policy and value models, and the
importance of familiar training distributions. Finally, we discuss scalable RLM
cloud deployments and we outline how RLMs can integrate with a broader LLM
ecosystem. Our work demystifies RLM construction, democratizes advanced
reasoning capabilities, and fosters innovation, aiming to mitigate the gap
between "rich AI" and "poor AI" by lowering barriers to RLM development and
experimentation.

æè¦ï¼æ¨çèªè¨æ¨¡å (RLM)ï¼åç¨±å¤§åæ¨çæ¨¡å (LRM)ï¼ä¾å¦ OpenAI ç o1 å o3ãDeepSeek-V3 åé¿éå·´å·´ç QwQï¼ééåé²çæ¨çæ©å¶æ´å LLMï¼éæ°å®ç¾©äº AI çåé¡è§£æ±ºè½åãç¶èï¼å®åçé«ææ¬ãå°ææ§è³ªåè¤éçæ¶æ§ï¼ç¨ç¹å°çµåäºå¼·åå­¸ç¿ (RL)ãæå°åç¼æ³å LLMï¼å¸¶ä¾äºå¯åæ§åå¯æ´åæ§çææ°ãçºäºè§£æ±ºéäºåé¡ï¼æåæåºäºä¸åå¨é¢çèåï¼æ ¹æå°ææ RLM ä½åçèª¿æ¥ååæï¼å° RLM çµä»¶çµç¹æä¸åæ¨¡çµåæ¶æ§ãæ­¤èååå«äºå¤æ¨£çæ¨ççµæ§ï¼éãæ¨¹ãååå·¢çå½¢å¼ï¼ãæ¨çç­ç¥ï¼ä¾å¦èå°å¡ç¾æ¨¹æå°ãæ³¢ææå°ï¼ãRL æ¦å¿µï¼ç­ç¥ãå¹å¼æ¨¡åç­ï¼ãç£ç£æ¹æ¡ï¼åºæ¼çµæçç£ç£ååºæ¼æµç¨çç£ç£ï¼åå¶ä»ç¸éæ¦å¿µï¼ä¾å¦æ¸¬è©¦æéè¨ç®ãæª¢ç´¢å¢å¼·çæãä»£çå·¥å·ï¼ãæåæä¾äºè©³ç´°çæ¸å­¸å¬å¼åæ¼ç®æ³è¦ç¯ï¼ä»¥ç°¡å RLM çå¯¦ä½ãééå±ç¤º LLaMA-BerryãQwQãæç¨å­¸ç¿åææ³åå¦ä½ä½çºç¹ä¾ï¼æåè­æäºèåçå¤åè½æ§åçµ±ä¸çæ½åãçºäºèªªæå¶æç¨ï¼æåå¼å¥äº x1ï¼ä¸åç¨æ¼å¿«é RLM ååè£½ä½åå¯¦é©çæ¨¡çµåå¯¦ä½ãä½¿ç¨ x1 åæç»åé¡§ï¼æåæä¾äºééµè¦è§£ï¼ä¾å¦ç­ç¥åå¹å¼æ¨¡åçå¤éæ®µè¨ç·´ï¼ä»¥åçæè¨ç·´åä½çéè¦æ§ãæå¾ï¼æåè¨è«äºå¯æ´åç RLM é²ç«¯é¨ç½²ï¼ä¸¦æ¦è¿°äº RLM å¦ä½èæ´å»£æ³ç LLM çæç³»çµ±æ´åãæåçç ç©¶æ­éäº RLM çµæ§çç¥ç§é¢ç´ï¼è®åé²çæ¨çè½åæ°ä¸»åï¼ä¸¦ä¿é²åµæ°ï¼æ¨å¨éééä½ RLM éç¼åå¯¦é©çéç¤ï¼ç¸®å°ãå¯è£ AIãåãè²§çª® AIãä¹éçå·®è·ã

##### **IntellAgent: A Multi-Agent Framework for Evaluating Conversational AI Systems**
2501.11067v1 by Elad Levi, Ilan Kadar

Large Language Models (LLMs) are transforming artificial intelligence,
evolving into task-oriented systems capable of autonomous planning and
execution. One of the primary applications of LLMs is conversational AI
systems, which must navigate multi-turn dialogues, integrate domain-specific
APIs, and adhere to strict policy constraints. However, evaluating these agents
remains a significant challenge, as traditional methods fail to capture the
complexity and variability of real-world interactions. We introduce
IntellAgent, a scalable, open-source multi-agent framework designed to evaluate
conversational AI systems comprehensively. IntellAgent automates the creation
of diverse, synthetic benchmarks by combining policy-driven graph modeling,
realistic event generation, and interactive user-agent simulations. This
innovative approach provides fine-grained diagnostics, addressing the
limitations of static and manually curated benchmarks with coarse-grained
metrics. IntellAgent represents a paradigm shift in evaluating conversational
AI. By simulating realistic, multi-policy scenarios across varying levels of
complexity, IntellAgent captures the nuanced interplay of agent capabilities
and policy constraints. Unlike traditional methods, it employs a graph-based
policy model to represent relationships, likelihoods, and complexities of
policy interactions, enabling highly detailed diagnostics. IntellAgent also
identifies critical performance gaps, offering actionable insights for targeted
optimization. Its modular, open-source design supports seamless integration of
new domains, policies, and APIs, fostering reproducibility and community
collaboration. Our findings demonstrate that IntellAgent serves as an effective
framework for advancing conversational AI by addressing challenges in bridging
research and deployment. The framework is available at
https://github.com/plurai-ai/intellagent

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) æ­£å¨è½è®äººå·¥æºæ§ï¼æ¼è®æå·åèªä¸»è¦ååå·è¡è½åçä»»åå°åç³»çµ±ãLLM çä¸»è¦æç¨ä¹ä¸æ¯å°è©±å¼ AI ç³»çµ±ï¼å®å¿é æå°å¤è¼ªå°è©±ãæ´åç¹å®é åç APIï¼ä¸¦éµå®å´æ ¼çæ¿ç­ç´æãç¶èï¼è©ä¼°éäºä»£çä»ç¶æ¯ä¸é éå¤§ææ°ï¼å çºå³çµ±æ¹æ³ç¡æ³ææç¾å¯¦ä¸çäºåçè¤éæ§åè®ç°æ§ãæåå¼å¥äº IntellAgentï¼ä¸åå¯æ´åãéæ¾åå§ç¢¼çå¤ä»£çæ¶æ§ï¼æ¨å¨å¨é¢è©ä¼°å°è©±å¼ AI ç³»çµ±ãIntellAgent èªååå»ºç«å¤æ¨£åãåæçåºæºï¼æ¹æ³æ¯çµåç­ç¥é©åçåå½¢å»ºæ¨¡ãé¼ççäºä»¶ç¢çåäºåä½¿ç¨èä»£çæ¨¡æ¬ãéç¨®åµæ°æ¹æ³æä¾äºç´°ç·»çè¨ºæ·ï¼è§£æ±ºäºå·æç²ç¥ææ¨çéæåæåç­ååºæºçéå¶ãIntellAgent ä»£è¡¨äºè©ä¼°å°è©±å¼ AI çå¸ç¯è½ç§»ãééæ¨¡æ¬ä¸åå±¤ç´è¤éæ§çé¼çå¤ç­ç¥å ´æ¯ï¼IntellAgent ææå°äºä»£çåè½åç­ç¥ç´æä¹éçç´°å¾®äº¤äºãèå³çµ±æ¹æ³ä¸åï¼å®æ¡ç¨åºæ¼åå½¢çç­ç¥æ¨¡åä¾è¡¨ç¤ºç­ç¥äº¤äºçéä¿ãå¯è½æ§åè¤éæ§ï¼å¾èå¯¦ç¾é«åº¦è©³ç´°çè¨ºæ·ãIntellAgent éè­å¥åºééµæè½å·®è·ï¼æä¾å¯è¡çè¦è§£ï¼ä»¥é²è¡ç®æ¨æä½³åãå¶æ¨¡çµåãéæ¾åå§ç¢¼çè¨­è¨æ¯æ´ç¡ç¸«æ´åæ°çé åãç­ç¥å APIï¼ä¿é²äºå¯è¤è£½æ§åç¤¾ç¾¤åä½ãæåçç ç©¶çµæè¡¨æï¼IntellAgent å¯ä½çºä¸åææçæ¡æ¶ï¼ééè§£æ±ºç ç©¶åé¨ç½²ä¹éçææ°ä¾æ¨é²å°è©±å¼ AIãéåæ¡æ¶å¯å¨ https://github.com/plurai-ai/intellagent åå¾

##### **Agent-as-Judge for Factual Summarization of Long Narratives**
2501.09993v1 by Yeonseok Jeong, Minsoo Kim, Seung-won Hwang, Byung-Hak Kim

Large Language Models (LLMs) have demonstrated near-human performance in
summarization tasks based on traditional metrics such as ROUGE and BERTScore.
However, these metrics do not adequately capture critical aspects of
summarization quality, such as factual accuracy, particularly for long
narratives (>100K tokens). Recent advances, such as LLM-as-a-Judge, address the
limitations of metrics based on lexical similarity but still exhibit factual
inconsistencies, especially in understanding character relationships and
states. In this work, we introduce NarrativeFactScore, a novel
"Agent-as-a-Judge" framework for evaluating and refining summaries. By
leveraging a Character Knowledge Graph (CKG) extracted from input and generated
summaries, NarrativeFactScore assesses the factual consistency and provides
actionable guidance for refinement, such as identifying missing or erroneous
facts. We demonstrate the effectiveness of NarrativeFactScore through a
detailed workflow illustration and extensive validation on widely adopted
benchmarks, achieving superior performance compared to competitive methods. Our
results highlight the potential of agent-driven evaluation systems to improve
the factual reliability of LLM-generated summaries.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨æè¦ä»»åä¸­å±ç¾åºæ¥è¿äººé¡çè¡¨ç¾ï¼æ ¹æå³çµ±ææ¨ï¼ä¾å¦ ROUGE å BERTScoreãç¶èï¼éäºææ¨ä¸¦æªååææ¡æè¦åè³ªçééµé¢åï¼ä¾å¦äºå¯¦æºç¢ºæ§ï¼ç¹å¥æ¯éå°é·ç¯æäº (>100K åç¬¦è)ãæè¿çé²å±ï¼ä¾å¦ LLM-as-a-Judgeï¼è§£æ±ºäºåºæ¼è©å½ç¸ä¼¼æ§çææ¨éå¶ï¼ä½ä»ç¶è¡¨ç¾åºäºå¯¦ä¸çä¸ä¸è´æ§ï¼ç¹å¥æ¯å¨çè§£è§è²éä¿åçææ¹é¢ãå¨éé å·¥ä½ä¸­ï¼æåå¼å¥äº NarrativeFactScoreï¼ä¸ç¨®æ°ç©çãä»£çäººä½çºè©å¯©ãæ¶æ§ï¼ç¨æ¼è©ä¼°åç²¾çæè¦ãééå©ç¨å¾è¼¸å¥åç¢ççæè¦ä¸­èåçè§è²ç¥è­åè­ (CKG)ï¼NarrativeFactScore è©ä¼°äºå¯¦ä¸è´æ§ï¼ä¸¦æä¾å¯è¡çç²¾çæåï¼ä¾å¦è­å¥éºæ¼æé¯èª¤çäºå¯¦ãæåééè©³ç´°çå·¥ä½æµç¨èªªæåå»£æ³é©è­å¨å»£æ³æ¡ç¨çåºæºä¸ï¼è­æäº NarrativeFactScore çæææ§ï¼èç«¶ç­æ¹æ³ç¸æ¯ï¼éå°äºåè¶çè¡¨ç¾ãæåççµæçªé¡¯äºä»£çäººé©åè©ä¼°ç³»çµ±çæ½åï¼ä»¥æ¹å LLM çæçæè¦çäºå¯¦å¯é æ§ã

##### **FRAG: A Flexible Modular Framework for Retrieval-Augmented Generation based on Knowledge Graphs**
2501.09957v2 by Zengyi Gao, Yukun Cao, Hairu Wang, Ao Ke, Yuan Feng, Xike Xie, S Kevin Zhou

To mitigate the hallucination and knowledge deficiency in large language
models (LLMs), Knowledge Graph (KG)-based Retrieval-Augmented Generation (RAG)
has shown promising potential by utilizing KGs as external resource to enhance
LLMs reasoning. However, existing KG-RAG approaches struggle with a trade-off
between flexibility and retrieval quality. Modular methods prioritize
flexibility by avoiding the use of KG-fine-tuned models during retrieval,
leading to fixed retrieval strategies and suboptimal retrieval quality.
Conversely, coupled methods embed KG information within models to improve
retrieval quality, but at the expense of flexibility. In this paper, we propose
a novel flexible modular KG-RAG framework, termed FRAG, which synergizes the
advantages of both approaches. FRAG estimates the hop range of reasoning paths
based solely on the query and classify it as either simple or complex. To match
the complexity of the query, tailored pipelines are applied to ensure efficient
and accurate reasoning path retrieval, thus fostering the final reasoning
process. By using the query text instead of the KG to infer the structural
information of reasoning paths and employing adaptable retrieval strategies,
FRAG improves retrieval quality while maintaining flexibility. Moreover, FRAG
does not require extra LLMs fine-tuning or calls, significantly boosting
efficiency and conserving resources. Extensive experiments show that FRAG
achieves state-of-the-art performance with high efficiency and low resource
consumption.

æè¦ï¼<paragraph>çºäºæ¸è¼å¤§åèªè¨æ¨¡å (LLM) ä¸­çå¹»è¦ºåç¥è­ä¸è¶³ï¼åºæ¼ç¥è­åè­ (KG) çæª¢ç´¢å¢å¼·çæ (RAG) å·²å±ç¾åºå©ç¨ KG ä½çºå¤é¨è³æºä¾å¢å¼· LLM æ¨ççæ½åãç¶èï¼ç¾æç KG-RAG æ¹æ³å¨éæ´»æ§èæª¢ç´¢åè³ªä¹éé¢è¨åæ¨ãæ¨¡çµåæ¹æ³ééé¿åå¨æª¢ç´¢æéä½¿ç¨ KG å¾®èª¿æ¨¡åä¾åªåèæ®éæ´»æ§ï¼å°è´åºå®çæª¢ç´¢ç­ç¥åæ¬¡ä½³çæª¢ç´¢åè³ªãç¸åå°ï¼è¦åæ¹æ³å° KG è³è¨åµå¥æ¨¡åä¸­ä»¥æ¹åæª¢ç´¢åè³ªï¼ä½ç§ç²äºéæ´»æ§ãå¨æ¬æä¸­ï¼æåæåºäºä¸åæ°ç©çéæ´»æ¨¡çµå KG-RAG æ¡æ¶ï¼ç¨±çº FRAGï¼å®ååäºå©ç¨®æ¹æ³çåªé»ãFRAG åæ ¹ææ¥è©¢ä¼°è¨æ¨çè·¯å¾çè·³èºç¯åï¼ä¸¦å°å¶åé¡çºç°¡å®æè¤éãçºäºå¹éæ¥è©¢çè¤éæ§ï¼æç¨å®¢è£½åç®¡éä»¥ç¢ºä¿ææä¸æºç¢ºçæ¨çè·¯å¾æª¢ç´¢ï¼å¾èä¿é²æçµçæ¨çéç¨ãFRAG ä½¿ç¨æ¥è©¢æå­èé KG ä¾æ¨æ·æ¨çè·¯å¾ççµæ§åè³è¨ï¼ä¸¦æ¡ç¨å¯é©æçæª¢ç´¢ç­ç¥ï¼å¾èæ¹åæª¢ç´¢åè³ªï¼åæä¿æéæ´»æ§ãæ­¤å¤ï¼FRAG ä¸éè¦é¡å¤ç LLM å¾®èª¿æå¼å«ï¼é¡¯èæåæçä¸¦ç¯çè³æºãå¤§éçå¯¦é©è¡¨æï¼FRAG ä»¥é«æçåä½è³æºæ¶èå¯¦ç¾äºæåé²çæè½ã</paragraph>

##### **SOP-Agent: Empower General Purpose AI Agent with Domain-Specific SOPs**
2501.09316v1 by Anbang Ye, Qianran Ma, Jia Chen, Muqi Li, Tong Li, Fujiao Liu, Siqi Mai, Meichen Lu, Haitao Bao, Yang You

Despite significant advancements in general-purpose AI agents, several
challenges still hinder their practical application in real-world scenarios.
First, the limited planning capabilities of Large Language Models (LLM)
restrict AI agents from effectively solving complex tasks that require
long-horizon planning. Second, general-purpose AI agents struggle to
efficiently utilize domain-specific knowledge and human expertise. In this
paper, we introduce the Standard Operational Procedure-guided Agent
(SOP-agent), a novel framework for constructing domain-specific agents through
pseudocode-style Standard Operational Procedures (SOPs) written in natural
language. Formally, we represent a SOP as a decision graph, which is traversed
to guide the agent in completing tasks specified by the SOP. We conduct
extensive experiments across tasks in multiple domains, including
decision-making, search and reasoning, code generation, data cleaning, and
grounded customer service. The SOP-agent demonstrates excellent versatility,
achieving performance superior to general-purpose agent frameworks and
comparable to domain-specific agent systems. Additionally, we introduce the
Grounded Customer Service Benchmark, the first benchmark designed to evaluate
the grounded decision-making capabilities of AI agents in customer service
scenarios based on SOPs.

æè¦ï¼åç®¡éç¨ AI ä»£çå¨ä¸è¬ç¨éä¸åå¾é¡¯èé²å±ï¼ä½ä»ææ¸é ææ°é»ç¤å¶å¨å¯¦éå ´æ¯ä¸­çå¯¦ç¨æç¨ã
é¦åï¼å¤§åèªè¨æ¨¡å (LLM) æéçè¦åè½åéå¶äº AI ä»£çææè§£æ±ºéè¦é·æè¦åçè¤éä»»åãå¶æ¬¡ï¼éç¨ AI ä»£çé£ä»¥ææå©ç¨ç¹å®é åçç¥è­åäººé¡å°æ¥­ç¥è­ãå¨æ¬æä¸­ï¼æåä»ç´¹äºæ¨æºæä½ç¨åºå¼å°ä»£ç (SOP-agent)ï¼éæ¯ä¸åééä»¥èªç¶èªè¨æ°å¯«çå½ä»£ç¢¼é¢¨æ ¼æ¨æºæä½ç¨åº (SOP) ä¾å»ºæ§ç¹å®é åä»£ççæ°ç©æ¶æ§ãæ­£å¼ä¾èªªï¼æåå° SOP è¡¨ç¤ºçºæ±ºç­åï¼ä¸¦å¨å¶ä¸­ç©¿æ¢­ä»¥å¼å°ä»£çå®æ SOP æå®çä»»åãæåå¨å¤åé åä¸­çä»»åä¸­é²è¡å»£æ³çå¯¦é©ï¼åæ¬æ±ºç­å¶å®ãæå°åæ¨çãç¨å¼ç¢¼çæãè³ææ¸çååºç¤å®¢æ¶æåãSOP-agent å±ç¤ºåºåè¶çå¤åè½æ§ï¼å¶æè½åªæ¼éç¨ä»£çæ¶æ§ï¼ä¸èç¹å®é åä»£çç³»çµ±ç¸ç¶ãæ­¤å¤ï¼æåä»ç´¹äºåºç¤å®¢æ¶æååºæºï¼éæ¯ç¬¬ä¸ååºæºï¼æ¨å¨è©ä¼° AI ä»£çå¨åºæ¼ SOP çå®¢æ¶æåå ´æ¯ä¸­åºç¤æ±ºç­å¶å®è½åã

##### **Text Semantics to Flexible Design: A Residential Layout Generation Method Based on Stable Diffusion Model**
2501.09279v1 by Zijin Qiu, Jiepeng Liu, Yi Xia, Hongtuo Qi, Pengkun Liu

Flexibility in the AI-based residential layout design remains a significant
challenge, as traditional methods like rule-based heuristics and graph-based
generation often lack flexibility and require substantial design knowledge from
users. To address these limitations, we propose a cross-modal design approach
based on the Stable Diffusion model for generating flexible residential
layouts. The method offers multiple input types for learning objectives,
allowing users to specify both boundaries and layouts. It incorporates natural
language as design constraints and introduces ControlNet to enable stable
layout generation through two distinct pathways. We also present a scheme that
encapsulates design expertise within a knowledge graph and translates it into
natural language, providing an interpretable representation of design
knowledge. This comprehensibility and diversity of input options enable
professionals and non-professionals to directly express design requirements,
enhancing flexibility and controllability. Finally, experiments verify the
flexibility of the proposed methods under multimodal constraints better than
state-of-the-art models, even when specific semantic information about room
areas or connections is incomplete.

æè¦ï¼å¨åºæ¼ AI çä½å®ä½å±è¨­è¨ä¸­ï¼éæ´»æ§ä»æ¯ä¸é éå¤§ææ°ï¼å çºåºæ¼è¦åçåç¼æ³ååºæ¼åå½¢çç¢çç­å³çµ±æ¹æ³éå¸¸ç¼ºä¹éæ´»æ§ï¼ä¸éè¦ä½¿ç¨èå·åå¤§éçè¨­è¨ç¥è­ãçºäºè§£æ±ºéäºéå¶ï¼æåæåºä¸åè·¨æ¨¡æè¨­è¨æ¹æ³ï¼è©²æ¹æ³åºæ¼ Stable Diffusion æ¨¡åï¼ç¨æ¼ç¢çéæ´»çä½å®ä½å±ãæ­¤æ¹æ³æä¾å¤ç¨®è¼¸å¥é¡åä»¥é²è¡å­¸ç¿ç®æ¨ï¼ä½¿ç¨æ¶è½å¤ åææå®éçåä½å±ãå®å°èªç¶èªè¨ä½çºè¨­è¨ç´æï¼ä¸¦å¼å¥ ControlNetï¼ä»¥ééå©åä¸åçè·¯å¾å¯¦ç¾ç©©å®çä½å±ç¢çãæåéæåºäºä¸åå°è¨­è¨å°æ¥­ç¥è­å°è£å¨ç¥è­åå½¢ä¸­çæ¹æ¡ï¼ä¸¦å°å¶è½æçºèªç¶èªè¨ï¼æä¾è¨­è¨ç¥è­çå¯è©®éè¡¨ç¤ºãéç¨®å¯çè§£æ§åè¼¸å¥é¸é çå¤æ¨£æ§ä½¿å°æ¥­äººå£«åéå°æ¥­äººå£«è½å¤ ç´æ¥è¡¨éè¨­è¨éæ±ï¼å¾èå¢å¼·éæ´»æ§èå¯æ§æ§ãæå¾ï¼å¯¦é©é©è­äºææåºçæ¹æ³å¨å¤æ¨¡æç´æä¸çéæ´»æ§åªæ¼æåé²çæ¨¡åï¼å³ä½¿éæ¼æ¿éååæé£æ¥çç¹å®èªç¾©è³è¨ä¸å®æ´æä¹æ¯å¦æ­¤ã

##### **A Simple Graph Contrastive Learning Framework for Short Text Classification**
2501.09219v1 by Yonghao Liu, Fausto Giunchiglia, Lan Huang, Ximing Li, Xiaoyue Feng, Renchu Guan

Short text classification has gained significant attention in the information
age due to its prevalence and real-world applications. Recent advancements in
graph learning combined with contrastive learning have shown promising results
in addressing the challenges of semantic sparsity and limited labeled data in
short text classification. However, existing models have certain limitations.
They rely on explicit data augmentation techniques to generate contrastive
views, resulting in semantic corruption and noise. Additionally, these models
only focus on learning the intrinsic consistency between the generated views,
neglecting valuable discriminative information from other potential views. To
address these issues, we propose a Simple graph contrastive learning framework
for Short Text Classification (SimSTC). Our approach involves performing graph
learning on multiple text-related component graphs to obtain multi-view text
embeddings. Subsequently, we directly apply contrastive learning on these
embeddings. Notably, our method eliminates the need for data augmentation
operations to generate contrastive views while still leveraging the benefits of
multi-view contrastive learning. Despite its simplicity, our model achieves
outstanding performance, surpassing large language models on various datasets.

æè¦ï¼ç­ææ¬åç±»å¨ä¿¡æ¯æ¶ä»£å¾å°äºå¹¿æ³å³æ³¨ï¼å ä¸ºå®å·ææ®éæ§åç°å®ä¸ççåºç¨ãæè¿ï¼å¾å­¦ä¹ ä¸å¯¹æ¯å­¦ä¹ ç¸ç»åçè¿æ­¥å¨è§£å³ç­ææ¬åç±»ä¸­è¯­ä¹ç¨çæ§åæ è®°æ°æ®æéçæææ¹é¢æ¾ç¤ºåºæå¸æçç»æãç¶èï¼ç°æçæ¨¡åå·æä¸å®çå±éæ§ãå®ä»¬ä¾èµäºæ¾å¼çæ°æ®å¢å¼ºææ¯æ¥çæå¯¹æ¯è§å¾ï¼ä»èå¯¼è´è¯­ä¹æåååªå£°ãæ­¤å¤ï¼è¿äºæ¨¡ååªå³æ³¨å­¦ä¹ çæè§å¾ä¹é´çåå¨ä¸è´æ§ï¼èå¿½ç¥äºå¶ä»æ½å¨è§å¾ä¸­æä»·å¼çå¤å«ä¿¡æ¯ãä¸ºäºè§£å³è¿äºé®é¢ï¼æä»¬æåºäºä¸ä¸ªç¨äºç­ææ¬åç±»çç®åå¾å¯¹æ¯å­¦ä¹ æ¡æ¶ (SimSTC)ãæä»¬çæ¹æ³æ¶åå¯¹å¤ä¸ªææ¬ç¸å³ç»ä»¶å¾æ§è¡å¾å­¦ä¹ ä»¥è·å¾å¤è§å¾ææ¬åµå¥ãéåï¼æä»¬ç´æ¥å¯¹è¿äºåµå¥åºç¨å¯¹æ¯å­¦ä¹ ãå¼å¾æ³¨æçæ¯ï¼æä»¬çæ¹æ³æ¶é¤äºçæå¯¹æ¯è§å¾æ¶å¯¹æ°æ®å¢å¼ºæä½çéæ±ï¼åæ¶ä»ç¶å©ç¨äºå¤è§å¾å¯¹æ¯å­¦ä¹ çä¼å¿ãå°½ç®¡å¾ç®åï¼ä½æä»¬çæ¨¡åè·å¾äºåºè²çæ§è½ï¼å¨åç§æ°æ®éä¸è¶è¶äºå¤§åè¯­è¨æ¨¡åã

##### **Boosting Short Text Classification with Multi-Source Information Exploration and Dual-Level Contrastive Learning**
2501.09214v1 by Yonghao Liu, Mengyu Li, Wei Pang, Fausto Giunchiglia, Lan Huang, Xiaoyue Feng, Renchu Guan

Short text classification, as a research subtopic in natural language
processing, is more challenging due to its semantic sparsity and insufficient
labeled samples in practical scenarios. We propose a novel model named
MI-DELIGHT for short text classification in this work. Specifically, it first
performs multi-source information (i.e., statistical information, linguistic
information, and factual information) exploration to alleviate the sparsity
issues. Then, the graph learning approach is adopted to learn the
representation of short texts, which are presented in graph forms. Moreover, we
introduce a dual-level (i.e., instance-level and cluster-level) contrastive
learning auxiliary task to effectively capture different-grained contrastive
information within massive unlabeled data. Meanwhile, previous models merely
perform the main task and auxiliary tasks in parallel, without considering the
relationship among tasks. Therefore, we introduce a hierarchical architecture
to explicitly model the correlations between tasks. We conduct extensive
experiments across various benchmark datasets, demonstrating that MI-DELIGHT
significantly surpasses previous competitive models. It even outperforms
popular large language models on several datasets.

æè¦ï¼ç­ææ¬åé¡ä½çºèªç¶èªè¨èççç ç©¶å­ä¸»é¡ï¼ç±æ¼å¶èªç¾©ç¨çæ§åå¯¦éå ´æ¯ä¸­æ¨è¨æ¨£æ¬ä¸è¶³ï¼å æ­¤æ´å·ææ°æ§ãå¨éé å·¥ä½ä¸­ï¼æåæåºäºä¸ååçº MI-DELIGHT çæ°æ¨¡åï¼ç¨æ¼ç­ææ¬åé¡ãå·é«ä¾èªªï¼å®é¦åå·è¡å¤æºä¿¡æ¯ï¼å³çµ±è¨ä¿¡æ¯ãèªè¨ä¿¡æ¯åäºå¯¦ä¿¡æ¯ï¼æ¢ç´¢ï¼ä»¥ç·©è§£ç¨çæ§åé¡ãç¶å¾ï¼æ¡ç¨åå­¸ç¿æ¹æ³ä¾å­¸ç¿ä»¥åè¡¨å½¢å¼åç¾çç­ææ¬çè¡¨ç¤ºãæ­¤å¤ï¼æåå¼å¥äºä¸åéå±¤ç´ï¼å³å¯¦ä¾å±¤ç´åç¾¤éå±¤ç´ï¼å°æ¯å­¸ç¿è¼å©ä»»åï¼ä»¥æææç²å¤§éæªæ¨è¨æ¸æä¸­çä¸åç²åº¦å°æ¯ä¿¡æ¯ãåæï¼ä»¥åçæ¨¡ååä¸¦è¡å·è¡ä¸»ä»»ååè¼å©ä»»åï¼èæ²æèæ®ä»»åä¹éçéä¿ãå æ­¤ï¼æåå¼å¥äºä¸ååå±¤æ¶æ§ä¾æç¢ºå»ºæ¨¡ä»»åä¹éçç¸éæ§ãæåå¨åç¨®åºæºæ¸æéä¸é²è¡äºå»£æ³çå¯¦é©ï¼è­æ MI-DELIGHT æé¡¯åªæ¼ä»¥åçç«¶ç­æ¨¡åãå®çè³å¨å¹¾åæ¸æéä¸åªæ¼æµè¡çå¤§èªè¨æ¨¡åã

##### **Leveraging Large Language Models as Knowledge-Driven Agents for Reliable Retrosynthesis Planning**
2501.08897v1 by Qinyu Ma, Yuhao Zhou, Jianfeng Li

Identifying reliable synthesis pathways in materials chemistry is a complex
task, particularly in polymer science, due to the intricate and often
non-unique nomenclature of macromolecules. To address this challenge, we
propose an agent system that integrates large language models (LLMs) and
knowledge graphs (KGs). By leveraging LLMs' powerful capabilities for
extracting and recognizing chemical substance names, and storing the extracted
data in a structured knowledge graph, our system fully automates the retrieval
of relevant literatures, extraction of reaction data, database querying,
construction of retrosynthetic pathway trees, further expansion through the
retrieval of additional literature and recommendation of optimal reaction
pathways. A novel Multi-branched Reaction Pathway Search (MBRPS) algorithm
enables the exploration of all pathways, with a particular focus on
multi-branched ones, helping LLMs overcome weak reasoning in multi-branched
paths. This work represents the first attempt to develop a fully automated
retrosynthesis planning agent tailored specially for macromolecules powered by
LLMs. Applied to polyimide synthesis, our new approach constructs a
retrosynthetic pathway tree with hundreds of pathways and recommends optimized
routes, including both known and novel pathways, demonstrating its
effectiveness and potential for broader applications.

æè¦ï¼è¾¨è­ææåå­¸ä¸­å¯é çåæè·¯å¾æ¯ä¸é è¤éçä»»åï¼ç¹å¥æ¯å¨èåç©ç§å­¸ä¸­ï¼å çºå·¨åå­çå½åæ³é¯ç¶è¤éä¸ç¶å¸¸ä¸å¯ä¸ãçºäºæå°éåææ°ï¼æåæåºä¸åæ´åå¤§åèªè¨æ¨¡å (LLM) èç¥è­åè­ (KG) çä»£çç³»çµ±ãééå©ç¨ LLM å¼·å¤§çåå­¸ç©è³ªåç¨±èååè¾¨è­è½åï¼ä¸¦å°èåçè³æå²å­å¨çµæ§åçç¥è­åè­ä¸­ï¼æåçç³»çµ±å¯å®å¨èªååç¸éæç»çæª¢ç´¢ãåæè³æçèåãè³æåº«æ¥è©¢ãéåæè·¯å¾æ¨¹çå»ºæ§ãééæª¢ç´¢é¡å¤æç»é²ä¸æ­¥æ´åï¼ä»¥åæä½³åæè·¯å¾çå»ºè­°ãä¸ç¨®æ°ç©çå¤åæ¯åæè·¯å¾æå° (MBRPS) æ¼ç®æ³è½æ¢ç´¢ææè·¯å¾ï¼ç¹å¥å°æ³¨æ¼å¤åæ¯è·¯å¾ï¼åå© LLM åæå¤åæ¯è·¯å¾ä¸­çå¼±æ¨çãéé å·¥ä½ä»£è¡¨é¦æ¬¡åè©¦éç¼ä¸ç¨®å®å¨èªååçéåæè¦åä»£çï¼å°ééå°ç± LLM é©åçå·¨åå­éèº«æé ãæç¨æ¼èé¯äºèºåæï¼æåçæ°æ¹æ³å»ºæ§äºä¸ååå«æ¸ç¾æ¢è·¯å¾çéåæè·¯å¾æ¨¹ï¼ä¸¦å»ºè­°æä½³åè·¯å¾ï¼åæ¬å·²ç¥åæ°ç©çè·¯å¾ï¼è­æå¶å¨æ´å»£æ³æç¨ä¸­çæè½åæ½åã

##### **Knowledge Graph-based Retrieval-Augmented Generation for Schema Matching**
2501.08686v1 by Chuangtao Ma, Sriom Chakrabarti, Arijit Khan, BÃ¡lint MolnÃ¡r

Traditional similarity-based schema matching methods are incapable of
resolving semantic ambiguities and conflicts in domain-specific complex mapping
scenarios due to missing commonsense and domain-specific knowledge. The
hallucination problem of large language models (LLMs) also makes it challenging
for LLM-based schema matching to address the above issues. Therefore, we
propose a Knowledge Graph-based Retrieval-Augmented Generation model for Schema
Matching, referred to as the KG-RAG4SM. In particular, KG-RAG4SM introduces
novel vector-based, graph traversal-based, and query-based graph retrievals, as
well as a hybrid approach and ranking schemes that identify the most relevant
subgraphs from external large knowledge graphs (KGs). We showcase that KG-based
retrieval-augmented LLMs are capable of generating more accurate results for
complex matching cases without any re-training. Our experimental results show
that KG-RAG4SM outperforms the LLM-based state-of-the-art (SOTA) methods (e.g.,
Jellyfish-8B) by 35.89% and 30.50% in terms of precision and F1 score on the
MIMIC dataset, respectively; KG-RAG4SM with GPT-4o-mini outperforms the
pre-trained language model (PLM)-based SOTA methods (e.g., SMAT) by 69.20% and
21.97% in terms of precision and F1 score on the Synthea dataset, respectively.
The results also demonstrate that our approach is more efficient in end-to-end
schema matching, and scales to retrieve from large KGs. Our case studies on the
dataset from the real-world schema matching scenario exhibit that the
hallucination problem of LLMs for schema matching is well mitigated by our
solution.

æè¦ï¼å³çµ±åºæ¼ç¸ä¼¼åº¦çæ¨¡å¼æ¯å°æ¹æ³ç¡æ³è§£æ±ºç¹å®é åè¤éæ¯å°å ´æ¯ä¸­çèªææ¨¡ç³æ§åè¡çªï¼éæ¯å çºç¼ºä¹å¸¸è­åç¹å®é åç¥è­ãå¤§åèªè¨æ¨¡å (LLM) çå¹»è¦ºåé¡ä¹ä½¿å¾åºæ¼ LLM çæ¨¡å¼æ¯å°é£ä»¥è§£æ±ºä¸è¿°åé¡ãå æ­¤ï¼æåæåºä¸ååºæ¼ç¥è­åè­çæª¢ç´¢å¢å¼·çææ¨¡åï¼ç¨æ¼æ¨¡å¼æ¯å°ï¼ç¨±çº KG-RAG4SMãå·é«èè¨ï¼KG-RAG4SM å¼å¥äºåºæ¼åéçãåºæ¼åå½¢éæ­·çååºæ¼æ¥è©¢çåå½¢æª¢ç´¢ï¼ä»¥åä¸ç¨®æ··åæ¹æ³åæåæ¹æ¡ï¼éäºæ¹æ¡å¾å¤é¨å¤§åç¥è­åè­ (KG) ä¸­è­å¥æç¸éçå­åãæåå±ç¤ºäºåºæ¼ KG çæª¢ç´¢å¢å¼· LLM è½å¤ å¨ä¸é²è¡ä»»ä½éæ°è¨ç·´çææ³ä¸çºè¤éçæ¯å°æ¡ä¾çææ´æºç¢ºççµæãæåçå¯¦é©çµæè¡¨æï¼å¨ MIMIC è³æéä¸ï¼KG-RAG4SM å¨æºç¢ºåº¦å F1 åæ¸æ¹é¢åå¥æ¯åºæ¼ LLM çææ° (SOTA) æ¹æ³ (ä¾å¦ Jellyfish-8B) é«åº 35.89% å 30.50%ï¼å·æ GPT-4o-mini ç KG-RAG4SM å¨æºç¢ºåº¦å F1 åæ¸æ¹é¢åå¥æ¯åºæ¼é åè¨ç·´èªè¨æ¨¡å (PLM) ç SOTA æ¹æ³ (ä¾å¦ SMAT) é«åº 69.20% å 21.97% å¨ Synthea è³æéä¸ãçµæéè¡¨æï¼æåçåæ³å¨ç«¯å°ç«¯æ¨¡å¼æ¯å°ä¸­æ´ææçï¼ä¸¦ä¸å¯ä»¥æ´å±å°å¾å¤§å KG ä¸­æª¢ç´¢ãæåå°ä¾èªç¾å¯¦ä¸çæ¨¡å¼æ¯å°å ´æ¯çè³æéé²è¡çæ¡ä¾ç ç©¶è¡¨æï¼æåçè§£æ±ºæ¹æ¡å¾å¥½å°ç·©è§£äº LLM å¨æ¨¡å¼æ¯å°ä¸­çå¹»è¦ºåé¡ã

##### **Assessing the Alignment of FOL Closeness Metrics with Human Judgement**
2501.08613v2 by Ramya Keerthy Thatikonda, Wray Buntine, Ehsan Shareghi

The recent successful paradigm of solving logical reasoning problems with
tool-augmented large language models (LLMs) leverages translation of natural
language statements into First-Order Logic~(FOL) and external theorem provers.
However, the correctness of FOL statements, comprising operators and text
predicates, often goes unverified due to the lack of a reliable evaluation
metric for comparing generated and ground-truth FOLs. In this paper, we present
a comprehensive study of sensitivity of existing metrics and their alignment
with human judgement on FOL evaluation. Using ground-truth FOLs, we carefully
designed various perturbations on the ground-truth to assess metric
sensitivity. We sample FOL translation candidates for natural language
statements and measure the ranking alignment between automatic metrics and
human annotators. Our empirical findings highlight oversensitivity in the
n-gram metric BLEU for text perturbations, the semantic graph metric Smatch++
for structural perturbations, and FOL metric for operator perturbation. We also
observe a closer alignment between BertScore and human judgement. Additionally,
we show that combining metrics enhances both alignment and sensitivity compared
to using individual metrics.

æè¦ï¼è¿ææåè§£æ±ºéè¼¯æ¨çåé¡çç¯ä¾ï¼å©ç¨äºå·¥å·å¢å¼·å¼å¤§åèªè¨æ¨¡å (LLM)ï¼å°èªç¶èªè¨é³è¿°ç¿»è­¯æä¸ééè¼¯ (FOL) åå¤é¨å®çè­æå¨ã
ç¶èï¼FOL é³è¿°çæ­£ç¢ºæ§åå«éç®å­èæå­è¬è©ï¼ç±æ¼ç¼ºä¹ç¨æ¼æ¯è¼å·²ç¢çèçå¯¦ FOL çå¯é è©ä¼°ææ¨ï¼å æ­¤ç¶å¸¸ç¡æ³é©è­ãå¨æ¬æä¸­ï¼æåæåºå°ç¾æææ¨ææåº¦åå¶èäººé¡å° FOL è©ä¼°å¤æ·ä¸è´æ§çå¨é¢ç ç©¶ãä½¿ç¨çå¯¦ FOLï¼æåä»ç´°è¨­è¨äºçå¯¦ FOL çåç¨®æ¾åï¼ä»¥è©ä¼°ææ¨ææåº¦ãæåå°èªç¶èªè¨é³è¿°åæ¨£ FOL ç¿»è­¯åé¸é ï¼ä¸¦è¡¡éèªåææ¨èäººé¡è¨»è§£èä¹éçæåä¸è´æ§ãæåçç¶é©ç¼ç¾å¼·èª¿ n-gram ææ¨ BLEU å°æå­æ¾åçéåº¦æææ§ï¼èªç¾©åå½¢ææ¨ Smatch++ å°çµæ§æ¾åçéåº¦æææ§ï¼ä»¥å FOL ææ¨å°éç®å­æ¾åçéåº¦æææ§ãæåéè§å¯å° BertScore èäººé¡å¤æ·ä¹éæ´ç·å¯çå°é½ãæ­¤å¤ï¼æåè¡¨æï¼èä½¿ç¨åå¥ææ¨ç¸æ¯ï¼çµåææ¨å¯å¢å¼·å°é½åææåº¦ã

##### **AutoRestTest: A Tool for Automated REST API Testing Using LLMs and MARL**
2501.08600v1 by Tyler Stennett, Myeongsoo Kim, Saurabh Sinha, Alessandro Orso

As REST APIs have become widespread in modern web services, comprehensive
testing of these APIs has become increasingly crucial. Due to the vast search
space consisting of operations, parameters, and parameter values along with
their complex dependencies and constraints, current testing tools suffer from
low code coverage, leading to suboptimal fault detection. To address this
limitation, we present a novel tool, AutoRestTest, which integrates the
Semantic Operation Dependency Graph (SODG) with Multi-Agent Reinforcement
Learning (MARL) and large language models (LLMs) for effective REST API
testing. AutoRestTest determines operation-dependent parameters using the SODG
and employs five specialized agents (operation, parameter, value, dependency,
and header) to identify dependencies of operations and generate operation
sequences, parameter combinations, and values. AutoRestTest provides a
command-line interface and continuous telemetry on successful operation count,
unique server errors detected, and time elapsed. Upon completion, AutoRestTest
generates a detailed report highlighting errors detected and operations
exercised. In this paper, we introduce our tool and present preliminary
results.

æè¦ï¼é¨è REST API å¨ç¾ä»£ç¶²è·¯æåä¸­å»£æ³ä½¿ç¨ï¼å°éäº API é²è¡å¨é¢çæ¸¬è©¦è®å¾è¶ä¾è¶éè¦ãç±æ¼å»£å¤§çæå°ç©ºéåå«æä½ãåæ¸ååæ¸å¼ä»¥åå®åè¤éçä¾è³´éä¿åç´æï¼ç®åçæ¸¬è©¦å·¥å·å­å¨ç¨å¼ç¢¼è¦èçä½çåé¡ï¼å°è´æéåµæ¸¬ä¸ä½³ãçºäºè§£æ±ºéåéå¶ï¼æåæåºä¸åæ°å·¥å· AutoRestTestï¼å®æ´åäºèªç¾©æä½ä¾è³´å (SODG) èå¤æºè½é«å¼·åå­¸ç¿ (MARL) åå¤§åèªè¨æ¨¡å (LLM)ï¼ä»¥é²è¡ææç REST API æ¸¬è©¦ãAutoRestTest ä½¿ç¨ SODG ç¢ºå®ä¾è³´æ¼æä½çåæ¸ï¼ä¸¦ä½¿ç¨äºåå°éçä»£ç (æä½ãåæ¸ãå¼ãä¾è³´éä¿åæ¨é ­) ä¾è­å¥æä½çä¾è³´éä¿ä¸¦ç¢çæä½åºåãåæ¸çµååå¼ãAutoRestTest æä¾å½ä»¤åä»é¢åæçºéæ¸¬ï¼åæ¬æåæä½æ¬¡æ¸ãåµæ¸¬å°çå¯ä¸ä¼ºæå¨é¯èª¤åç¶éæéãå®æå¾ï¼AutoRestTest æç¢çä¸ä»½è©³ç´°å ±åï¼éé»èªªæåµæ¸¬å°çé¯èª¤åå·è¡çæä½ãå¨æ¬æä¸­ï¼æåä»ç´¹æåçå·¥å·ä¸¦æåºåæ­¥çµæã

##### **LoRS: Efficient Low-Rank Adaptation for Sparse Large Language Model**
2501.08582v1 by Yuxuan Hu, Jing Zhang, Xiaodong Chen, Zhe Zhao, Cuiping Li, Hong Chen

Existing low-rank adaptation (LoRA) methods face challenges on sparse large
language models (LLMs) due to the inability to maintain sparsity. Recent works
introduced methods that maintain sparsity by augmenting LoRA techniques with
additional masking mechanisms. Despite these successes, such approaches suffer
from an increased memory and computation overhead, which affects efficiency of
LoRA methods. In response to this limitation, we introduce LoRS, an innovative
method designed to achieve both memory and computation efficiency when
fine-tuning sparse LLMs. To mitigate the substantial memory and computation
demands associated with preserving sparsity, our approach incorporates
strategies of weight recompute and computational graph rearrangement. In
addition, we also improve the effectiveness of LoRS through better adapter
initialization. These innovations lead to a notable reduction in memory and
computation consumption during the fine-tuning phase, all while achieving
performance levels that outperform existing LoRA approaches.

æè¦ï¼ç¾æçä½ç§©é©æ (LoRA) æ¹æ³ç±æ¼ç¡æ³ç¶­æç¨çæ§ï¼å¨ç¨çå¤§åèªè¨æ¨¡å (LLM) ä¸é¢è¨ææ°ãæè¿çä½åå¼å¥äºééä½¿ç¨é¡å¤çé®ç½©æ©å¶ä¾æ´å LoRA æè¡çæ¹æ³ä¾ç¶­æç¨çæ§ãåç®¡æéäºæåï¼ä½éäºæ¹æ³æå¢å è¨æ¶é«åéç®çéé·ï¼éæå½±é¿ LoRA æ¹æ³çæçãçºäºåæéåéå¶ï¼æåå¼å¥äº LoRSï¼éæ¯ä¸ç¨®åµæ°çæ¹æ³ï¼æ¨å¨å¨å¾®èª¿ç¨ç LLM æåæå¯¦ç¾è¨æ¶é«åéç®æçãçºäºæ¸è¼èç¶­æç¨çæ§ç¸éçé¾å¤§è¨æ¶é«åéç®éæ±ï¼æåçåæ³çµåäºæ¬ééæ°è¨ç®åè¨ç®åå½¢éæ°æåçç­ç¥ãæ­¤å¤ï¼æåéééæ´å¥½çé©éå¨åå§åä¾æé« LoRS çæææ§ãéäºåµæ°å¨å¾®èª¿éæ®µé¡¯èæ¸å°äºè¨æ¶é«åéç®æ¶èï¼åæå¯¦ç¾äºåªæ¼ç¾æ LoRA æ¹æ³çæè½ç­ç´ã

##### **Towards Zero-Shot & Explainable Video Description by Reasoning over Graphs of Events in Space and Time**
2501.08460v1 by Mihai Masala, Marius Leordeanu

In the current era of Machine Learning, Transformers have become the de facto
approach across a variety of domains, such as computer vision and natural
language processing. Transformer-based solutions are the backbone of current
state-of-the-art methods for language generation, image and video
classification, segmentation, action and object recognition, among many others.
Interestingly enough, while these state-of-the-art methods produce impressive
results in their respective domains, the problem of understanding the
relationship between vision and language is still beyond our reach. In this
work, we propose a common ground between vision and language based on events in
space and time in an explainable and programmatic way, to connect
learning-based vision and language state of the art models and provide a
solution to the long standing problem of describing videos in natural language.
We validate that our algorithmic approach is able to generate coherent, rich
and relevant textual descriptions on videos collected from a variety of
datasets, using both standard metrics (e.g. Bleu, ROUGE) and the modern
LLM-as-a-Jury approach.

æè¦ï¼å¨æ©å¨å­¸ç¿çç¶ä»£ï¼Transformer å·²æçºåç¨®é åçäºå¯¦æ¨æºæ¹æ³ï¼ä¾å¦é»è¦è¦è¦ºåèªç¶èªè¨èçãåºæ¼ Transformer çè§£æ±ºæ¹æ¡æ¯ç¶åèªè¨çæãå½±ååå½±çåé¡ãåå²ãåä½åç©ä»¶è¾¨è­ç­ææ°æ¹æ³çéª¨å¹¹ãæè¶£çæ¯ï¼éç¶éäºææ°æ¹æ³å¨å¶åèªçé åä¸­ç¢çä»¤äººå°è±¡æ·±å»ççµæï¼ä½çè§£è¦è¦ºåèªè¨ä¹ééä¿çåé¡ä»ç¶è¶åºäºæåççè§£ç¯åãå¨éé å·¥ä½ä¸­ï¼æåä»¥å¯è§£éä¸ä»¥ç¨å¼çºåºç¤çæ¹å¼ï¼å¨æç©ºä¸­çäºä»¶ä¹éæåºäºè¦è¦ºåèªè¨çå±ååºç¤ï¼ä»¥é£æ¥åºæ¼å­¸ç¿çè¦è¦ºåèªè¨ææ°æ¨¡åï¼ä¸¦æä¾æè¿°å½±ççèªç¶èªè¨é·æåé¡çè§£æ±ºæ¹æ¡ãæåé©è­äºæåçæ¼ç®æ³æ¹æ³è½å¤ å¨å¾åç¨®è³æéæ¶éçå½±çä¸­ç¢çé£è²«ãè±å¯ä¸ç¸éçæå­æè¿°ï¼åæä½¿ç¨æ¨æºææ¨ï¼ä¾å¦ BleuãROUGEï¼åç¾ä»£ LLM ä½çºè©å¯©æ¹æ³ã

##### **In-situ graph reasoning and knowledge expansion using Graph-PReFLexOR**
2501.08120v1 by Markus J. Buehler

The pursuit of automated scientific discovery has fueled progress from
symbolic logic to modern AI, forging new frontiers in reasoning and pattern
recognition. Transformers function as potential systems, where every possible
relationship remains latent potentiality until tasks impose constraints, akin
to measurement. Yet, refining their sampling requires more than probabilistic
selection: solutions must conform to specific structures or rules, ensuring
consistency and the invocation of general principles. We present
Graph-PReFLexOR (Graph-based Preference-based Recursive Language Modeling for
Exploratory Optimization of Reasoning), a framework that combines graph
reasoning with symbolic abstraction to dynamically expand domain knowledge.
Inspired by reinforcement learning, Graph-PReFLexOR defines reasoning as a
structured mapping, where tasks yield knowledge graphs, abstract patterns, and
ultimately, final answers. Inspired by category theory, it encodes concepts as
nodes and their relationships as edges, supporting hierarchical inference and
adaptive learning through isomorphic representations. Demonstrations include
hypothesis generation, materials design, and creative reasoning, such as
discovering relationships between mythological concepts like 'thin places' with
materials science. We propose a 'knowledge garden growth' strategy that
integrates insights across domains, promoting interdisciplinary connections.
Results with a 3-billion-parameter Graph-PReFLexOR model show superior
reasoning depth and adaptability, underscoring the potential for transparent,
multidisciplinary AI-driven discovery. It lays the groundwork for general
autonomous reasoning solutions.

æè¦ï¼<paragraph>è¿½æ±èªååç§å­¸ç¼ç¾å·²ç¶æ¨åäºå¾ç¬¦èéè¼¯å°ç¾ä»£ AI çé²å±ï¼å¨æ¨çåæ¨¡å¼è­å¥ä¸­éé¢äºæ°çé åãTransformer ä½çºæ½å¨ç³»çµ±éä½ï¼å¶ä¸­æ¯ç¨®å¯è½çéä¿é½ä¿ææ½å¨æ½åï¼ç´å°ä»»åæ½å ç´æï¼é¡ä¼¼æ¼æ¸¬éãç¶èï¼åªåå¶æ¡æ¨£éè¦çä¸åªæ¯æ©çé¸æï¼è§£æ±ºæ¹æ¡å¿é ç¬¦åç¹å®çµæ§æè¦åï¼ä»¥ç¢ºä¿ä¸è´æ§ä¸¦å¼æä¸è¬ååãæåæåºäº Graph-PReFLexORï¼åºæ¼åå½¢çåºæ¼åå¥½çéè¿´èªè¨å»ºæ¨¡ï¼ç¨æ¼æ¨ççæ¢ç´¢æ§åªåï¼ï¼ä¸åå°åå½¢æ¨çèç¬¦èæ½è±¡ç¸çµåä»¥åææ´å±é åç¥è­çæ¡æ¶ãåå¼·åå­¸ç¿çåç¼ï¼Graph-PReFLexOR å°æ¨çå®ç¾©çºçµæ§åå°æï¼ä»»åç¢çç¥è­åå½¢ãæ½è±¡æ¨¡å¼ä»¥åæçµç­æ¡ãåç¯çè«çåç¼ï¼å®å°æ¦å¿µç·¨ç¢¼çºç¯é»ï¼å°å®åçéä¿ç·¨ç¢¼çºéç·£ï¼ééåæ§è¡¨ç¤ºæ¯æéå±¤å¼æ¨è«åèªé©æå­¸ç¿ãç¤ºç¯åæ¬åè¨­çæãææè¨­è¨ååµé æ§æ¨çï¼ä¾å¦ç¼ç¾ç¥è©±æ¦å¿µï¼å¦ãèå¼±é»ãï¼èææç§å­¸ä¹éçéä¿ãæåæåºäºä¸ç¨®ãç¥è­è±åæé·ãç­ç¥ï¼å®æ´åäºè·¨é åçè¦è§£ï¼ä¿é²äºè·¨å­¸ç§çè¯ç¹«ãä½¿ç¨ 30 ååæ¸ Graph-PReFLexOR æ¨¡åççµæé¡¯ç¤ºåºåªç°çæ¨çæ·±åº¦åé©ææ§ï¼å¼·èª¿äºéæãå¤å­¸ç§ AI é©åç¼ç¾çæ½åãå®çºéç¨çèªä¸»æ¨çè§£æ±ºæ¹æ¡å¥ å®äºåºç¤ã</paragraph>

##### **Reasoning with Graphs: Structuring Implicit Knowledge to Enhance LLMs Reasoning**
2501.07845v1 by Haoyu Han, Yaochen Xie, Hui Liu, Xianfeng Tang, Sreyashi Nag, William Headden, Hui Liu, Yang Li, Chen Luo, Shuiwang Ji, Qi He, Jiliang Tang

Large language models (LLMs) have demonstrated remarkable success across a
wide range of tasks; however, they still encounter challenges in reasoning
tasks that require understanding and inferring relationships between distinct
pieces of information within text sequences. This challenge is particularly
pronounced in tasks involving multi-step processes, such as logical reasoning
and multi-hop question answering, where understanding implicit relationships
between entities and leveraging multi-hop connections in the given context are
crucial. Graphs, as fundamental data structures, explicitly represent pairwise
relationships between entities, thereby offering the potential to enhance LLMs'
reasoning capabilities. External graphs have proven effective in supporting
LLMs across multiple tasks. However, in many reasoning tasks, no pre-existing
graph structure is provided. Can we structure implicit knowledge derived from
context into graphs to assist LLMs in reasoning? In this paper, we propose
Reasoning with Graphs (RwG) by first constructing explicit graphs from the
context and then leveraging these graphs to enhance LLM reasoning performance
on reasoning tasks. Extensive experiments demonstrate the effectiveness of the
proposed method in improving both logical reasoning and multi-hop question
answering tasks.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²å¨åç¨®ä»»åä¸­å±ç¾åºé¡¯èçæåï¼ç¶èï¼å®åå¨æ¨çä»»åä¸­ä»æéå°ææ°ï¼éäºä»»åéè¦çè§£åæ¨è«æå­åºåä¸­ä¸åè³è¨çæ®µä¹éçéä¿ãéåææ°å¨æ¶åå¤æ­¥é©ç¨åºçä»»åä¸­ç¹å¥æé¡¯ï¼ä¾å¦éè¼¯æ¨çåå¤è·³åé¡è§£ç­ï¼å¶ä¸­çè§£å¯¦é«ä¹éçé±å«éä¿ä¸¦å©ç¨çµ¦å®èçµ¡ä¸­çå¤è·³é£æ¥è³ééè¦ãåå½¢ä½çºåºæ¬çè³æçµæ§ï¼æç¢ºè¡¨ç¤ºå¯¦é«ä¹éæå°çéä¿ï¼å¾èæä¾å¢å¼· LLM æ¨çè½åçæ½åãå¤é¨åå½¢å·²è¢«è­æå¯ä»¥æææ¯æ´ LLM å·è¡å¤é ä»»åãç¶èï¼å¨è¨±å¤æ¨çä»»åä¸­ï¼ä¸¦æ²ææä¾é åå­å¨çåå½¢çµæ§ãæåè½å°å¾èçµ¡ä¸­è¡ççé±å«ç¥è­çµæ§æåå½¢ï¼ä»¥åå© LLM é²è¡æ¨çåï¼å¨æ¬æä¸­ï¼æåæåºä½¿ç¨åå½¢é²è¡æ¨ç (RwG)ï¼æ¹æ³æ¯é¦åå¾èçµ¡ä¸­å»ºæ§æç¢ºçåå½¢ï¼ç¶å¾å©ç¨éäºåå½¢ä¾å¢å¼· LLM å¨æ¨çä»»åä¸­çæ¨çæè½ãå»£æ³çå¯¦é©è­æäºææåºçæ¹æ³å¨æ¹é²éè¼¯æ¨çåå¤è·³åé¡è§£ç­ä»»åæ¹é¢çæææ§ã

##### **Flow: A Modular Approach to Automated Agentic Workflow Generation**
2501.07834v1 by Boye Niu, Yiliao Song, Kai Lian, Yifan Shen, Yu Yao, Kun Zhang, Tongliang Liu

Multi-agent frameworks powered by large language models (LLMs) have
demonstrated great success in automated planning and task execution. However,
the effective adjustment of Agentic workflows during execution has not been
well-studied. A effective workflow adjustment is crucial, as in many real-world
scenarios, the initial plan must adjust to unforeseen challenges and changing
conditions in real-time to ensure the efficient execution of complex tasks. In
this paper, we define workflows as an activity-on-vertex (AOV) graphs. We
continuously refine the workflow by dynamically adjusting task allocations
based on historical performance and previous AOV with LLM agents. To further
enhance system performance, we emphasize modularity in workflow design based on
measuring parallelism and dependence complexity. Our proposed multi-agent
framework achieved efficient sub-task concurrent execution, goal achievement,
and error tolerance. Empirical results across different practical tasks
demonstrate dramatic improvements in the efficiency of multi-agent frameworks
through dynamic workflow updating and modularization.

æè¦ï¼å¤§åèªè¨æ¨¡åï¼LLMï¼é©åçå¤ä»£çæ¶æ§å·²å¨èªååè¦ååä»»åå·è¡ä¸­å±ç¾åºå·¨å¤§çæåãç¶èï¼å¨å·è¡æéææèª¿æ´ä»£çå·¥ä½æµç¨å°æªå¾å°ååç ç©¶ãææçå·¥ä½æµç¨èª¿æ´è³ééè¦ï¼å çºå¨è¨±å¤å¯¦éå ´æ¯ä¸­ï¼åå§è¨ç«å¿é å³æèª¿æ´ä»¥æå°ç¡æ³é è¦çææ°åä¸æ·è®åçæ¢ä»¶ï¼ä»¥ç¢ºä¿è¤éä»»åçææå·è¡ãå¨æ¬æä¸­ï¼æåå°å·¥ä½æµç¨å®ç¾©çºé é»ä¸çæ´»åï¼AOVï¼åå½¢ãæåæ ¹ææ­·å²ç¸¾æåååç AOV è LLM ä»£çï¼ééåæèª¿æ´ä»»ååéï¼æçºåªåå·¥ä½æµç¨ãçºäºé²ä¸æ­¥æåç³»çµ±æè½ï¼æåå¼·èª¿åºæ¼æ¸¬éä¸¦è¡æ§åä¾è³´è¤éæ§çå·¥ä½æµç¨è¨­è¨ä¸­çæ¨¡çµåãæåæåºçå¤ä»£çæ¶æ§éå°äºææå­ä»»åä¸¦è¡å·è¡ãç®æ¨éæåå®¹é¯ãè·¨ä¸åå¯¦éä»»åçå¯¦è­çµæè­æï¼ééåæå·¥ä½æµç¨æ´æ°åæ¨¡çµåï¼å¤ä»£çæ¶æ§çæçæäºé¡¯èçæåã

##### **Large Language Models for Knowledge Graph Embedding Techniques, Methods, and Challenges: A Survey**
2501.07766v1 by Bingchen Liu, Xin Li

Large Language Models (LLMs) have attracted a lot of attention in various
fields due to their superior performance, aiming to train hundreds of millions
or more parameters on large amounts of text data to understand and generate
natural language. As the superior performance of LLMs becomes apparent, they
are increasingly being applied to knowledge graph embedding (KGE) related tasks
to improve the processing results. As a deep learning model in the field of
Natural Language Processing (NLP), it learns a large amount of textual data to
predict the next word or generate content related to a given text. However,
LLMs have recently been invoked to varying degrees in different types of KGE
related scenarios such as multi-modal KGE and open KGE according to their task
characteristics. In this paper, we investigate a wide range of approaches for
performing LLMs-related tasks in different types of KGE scenarios. To better
compare the various approaches, we summarize each KGE scenario in a
classification. In addition to the categorization methods, we provide a tabular
overview of the methods and their source code links for a more direct
comparison. In the article we also discuss the applications in which the
methods are mainly used and suggest several forward-looking directions for the
development of this new research area.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) ç±æ¼å¶åªç°çæ§è½ï¼å¨ååé åä¸­å¼èµ·äºè¨±å¤éæ³¨ï¼ç®æ¨æ¯è¨ç·´æ¸åææ´å¤åæ¸ï¼ä»¥çè§£åç¢çå¤§éææ¬è³æä¸­çèªç¶èªè¨ãé¨è LLM åªç°æ§è½çé¡¯ç¾ï¼å®åæ­£è¶ä¾è¶å»£æ³å°æç¨æ¼ç¥è­åè­åµå¥ (KGE) ç¸éä»»åï¼ä»¥æ¹åèççµæãä½çºèªç¶èªè¨èç (NLP) é åä¸­çæ·±åº¦å­¸ç¿æ¨¡åï¼å®å­¸ç¿å¤§éçææ¬è³æï¼ä»¥é æ¸¬ä¸ä¸åå®å­æç¢çèçµ¦å®ææ¬ç¸éçå§å®¹ãç¶èï¼æ ¹æä»»åç¹æ§ï¼LLM æè¿å·²å¨ä¸åé¡åç KGE ç¸éå ´æ¯ï¼ä¾å¦å¤æ¨¡æ KGE åéæ¾å¼ KGEï¼ä¸­ä»¥ä¸åç¨åº¦è¢«æ¡ç¨ãå¨æ¬æä¸­ï¼æåæ¢è¨äºå¨ä¸åé¡åç KGE å ´æ¯ä¸­å·è¡è LLM ç¸éä»»åçåç¨®æ¹æ³ãçºäºæ´å¥½å°æ¯è¼åç¨®æ¹æ³ï¼æåå¨åé¡ä¸­ç¸½çµäºæ¯å KGE å ´æ¯ãé¤äºåé¡æ¹æ³ä¹å¤ï¼æåéæä¾äºæ¹æ³åå¶åå§ç¢¼é£çµçè¡¨æ ¼æ¦è§ï¼ä»¥ä¾¿é²è¡æ´ç´æ¥çæ¯è¼ãå¨æ¬æä¸­ï¼æåéè¨è«äºéäºæ¹æ³ä¸»è¦ç¨æ¼åªäºæç¨ï¼ä¸¦å»ºè­°äºå¹¾åéåæ°ç ç©¶é åç¼å±çåç»æ§æ¹åã

##### **SafePowerGraph-LLM: Novel Power Grid Graph Embedding and Optimization with Large Language Models**
2501.07639v1 by Fabien Bernier, Jun Cao, Maxime Cordy, Salah Ghamizi

Efficiently solving Optimal Power Flow (OPF) problems in power systems is
crucial for operational planning and grid management. There is a growing need
for scalable algorithms capable of handling the increasing variability,
constraints, and uncertainties in modern power networks while providing
accurate and fast solutions. To address this, machine learning techniques,
particularly Graph Neural Networks (GNNs) have emerged as promising approaches.
This letter introduces SafePowerGraph-LLM, the first framework explicitly
designed for solving OPF problems using Large Language Models (LLM)s. The
proposed approach combines graph and tabular representations of power grids to
effectively query LLMs, capturing the complex relationships and constraints in
power systems. A new implementation of in-context learning and fine-tuning
protocols for LLMs is introduced, tailored specifically for the OPF problem.
SafePowerGraph-LLM demonstrates reliable performances using off-the-shelf LLM.
Our study reveals the impact of LLM architecture, size, and fine-tuning and
demonstrates our framework's ability to handle realistic grid components and
constraints.

æè¦ï¼å¨é»åç³»çµ±ä¸­ææè§£æ±ºæä½³é»åæµ (OPF) åé¡å°æ¼éçè¦ååé»ç¶²ç®¡çè³ééè¦ãå°æ¼è½å¤ èçç¾ä»£é»åç¶²è·¯ä¸­æ¥çå¢å çå¯è®æ§ãç´æåä¸ç¢ºå®æ§çå¯æ´åæ¼ç®æ³ï¼åææä¾æºç¢ºä¸å¿«éçè§£æ±ºæ¹æ¡ï¼éæ±èæ¥ä¿±å¢ãçºäºè§£æ±ºæ­¤åé¡ï¼æ©å¨å­¸ç¿æè¡ï¼ç¹å¥æ¯åç¥ç¶ç¶²è·¯ (GNN) å·²æçºæåæ¯çæ¹æ³ãæ¬ä¿¡ä»ç´¹äº SafePowerGraph-LLMï¼éæ¯ç¬¬ä¸åæç¢ºè¨­è¨ç¨æ¼ä½¿ç¨å¤§åèªè¨æ¨¡å (LLM) è§£æ±º OPF åé¡çæ¡æ¶ãææåºçæ¹æ³çµåäºé»åç¶²è·¯çåå½¢åè¡¨æ ¼è¡¨ç¤ºï¼ä»¥æææ¥è©¢ LLMï¼ææé»åç³»çµ±ä¸­çè¤ééä¿åç´æãå¼å¥äºéå° LLM çæå¢å­¸ç¿åå¾®èª¿åå®çæ°å¯¦ä½ï¼å°ééå° OPF åé¡éèº«æé ãSafePowerGraph-LLM ä½¿ç¨ç¾æç LLM å±ç¤ºäºå¯é çæè½ãæåçç ç©¶æ­ç¤ºäº LLM æ¶æ§ãå¤§å°åå¾®èª¿çå½±é¿ï¼ä¸¦å±ç¤ºäºæåçæ¡æ¶èçç¾å¯¦é»ç¶²çµæåç´æçè½åã

##### **ADKGD: Anomaly Detection in Knowledge Graphs with Dual-Channel Training**
2501.07078v1 by Jiayang Wu, Wensheng Gan, Jiahao Zhang, Philip S. Yu

In the current development of large language models (LLMs), it is important
to ensure the accuracy and reliability of the underlying data sources. LLMs are
critical for various applications, but they often suffer from hallucinations
and inaccuracies due to knowledge gaps in the training data. Knowledge graphs
(KGs), as a powerful structural tool, could serve as a vital external
information source to mitigate the aforementioned issues. By providing a
structured and comprehensive understanding of real-world data, KGs enhance the
performance and reliability of LLMs. However, it is common that errors exist in
KGs while extracting triplets from unstructured data to construct KGs. This
could lead to degraded performance in downstream tasks such as
question-answering and recommender systems. Therefore, anomaly detection in KGs
is essential to identify and correct these errors. This paper presents an
anomaly detection algorithm in knowledge graphs with dual-channel learning
(ADKGD). ADKGD leverages a dual-channel learning approach to enhance
representation learning from both the entity-view and triplet-view
perspectives. Furthermore, using a cross-layer approach, our framework
integrates internal information aggregation and context information
aggregation. We introduce a kullback-leibler (KL)-loss component to improve the
accuracy of the scoring function between the dual channels. To evaluate ADKGD's
performance, we conduct empirical studies on three real-world KGs: WN18RR,
FB15K, and NELL-995. Experimental results demonstrate that ADKGD outperforms
the state-of-the-art anomaly detection algorithms. The source code and datasets
are publicly available at https://github.com/csjywu1/ADKGD.

æè¦ï¼<paragraph>å¨å¤§èªè¨æ¨¡åï¼LLMï¼çç¶åç¼å±ä¸­ï¼ç¢ºä¿åºç¤æ¸æä¾æºçæºç¢ºæ§åå¯é æ§éå¸¸éè¦ãLLM å°æ¼åç¨®æç¨è³ééè¦ï¼ä½ç±æ¼è¨ç·´æ¸æä¸­çç¥è­å·®è·ï¼å®åç¶å¸¸æåºç¾å¹»è¦ºåä¸æºç¢ºçææ³ãç¥è­åè­ (KG) ä½çºä¸ç¨®å¼·å¤§ççµæ§åå·¥å·ï¼å¯ä»¥ä½çºä¸åéè¦çå¤é¨ä¿¡æ¯ä¾æºï¼ä»¥æ¸è¼ä¸è¿°åé¡ãééæä¾å°ç¾å¯¦ä¸çæ¸æççµæ§ååå¨é¢çè§£ï¼KG æé«äº LLM çæ§è½åå¯é æ§ãç¶èï¼å¨å¾éçµæ§åæ¸æä¸­æåä¸åçµä»¥æ§å»º KG æï¼KG ä¸­å­å¨é¯èª¤æ¯å¾å¸¸è¦çãéå¯è½æå°è´ä¸æ¸¸ä»»åï¼ä¾å¦åç­åæ¨è¦ç³»çµ±ï¼çæ§è½ä¸éãå æ­¤ï¼KG ä¸­çç°å¸¸æª¢æ¸¬å°æ¼è­å¥åç³¾æ­£éäºé¯èª¤è³ééè¦ãæ¬ææåºäºä¸åå·æéééå­¸ç¿çç¥è­åè­ç°å¸¸æª¢æ¸¬ç®æ³ (ADKGD)ãADKGD å©ç¨éééå­¸ç¿æ¹æ³å¾å¯¦é«è¦è§åä¸åçµè¦è§å¢å¼·è¡¨ç¤ºå­¸ç¿ãæ­¤å¤ï¼æåçæ¡æ¶ä½¿ç¨è·¨å±¤æ¹æ³æ´åäºå§é¨ä¿¡æ¯èååä¸ä¸æä¿¡æ¯èåãæåå¼å¥äº Kullback-Leibler (KL) æå¤±çµä»¶ï¼ä»¥æé«éééä¹éè©åå½æ¸çæºç¢ºæ§ãçºäºè©ä¼° ADKGD çæ§è½ï¼æåå°ä¸åçå¯¦ä¸ç KGï¼WN18RRãFB15K å NELL-995 é²è¡äºå¯¦è­ç ç©¶ãå¯¦é©çµæè¡¨æï¼ADKGD åªæ¼æåé²çç°å¸¸æª¢æ¸¬ç®æ³ãæºä»£ç¢¼åæ¸æéå¯å¨ https://github.com/csjywu1/ADKGD å¬éç²å¾ã</paragraph>

##### **Causal Claims in Economics**
2501.06873v1 by Prashant Garg, Thiemo Fetzer

We analyze over 44,000 NBER and CEPR working papers from 1980 to 2023 using a
custom language model to construct knowledge graphs that map economic concepts
and their relationships. We distinguish between general claims and those
documented via causal inference methods (e.g., DiD, IV, RDD, RCTs). We document
a substantial rise in the share of causal claims-from roughly 4% in 1990 to
nearly 28% in 2020-reflecting the growing influence of the "credibility
revolution." We find that causal narrative complexity (e.g., the depth of
causal chains) strongly predicts both publication in top-5 journals and higher
citation counts, whereas non-causal complexity tends to be uncorrelated or
negatively associated with these outcomes. Novelty is also pivotal for top-5
publication, but only when grounded in credible causal methods: introducing
genuinely new causal edges or paths markedly increases both the likelihood of
acceptance at leading outlets and long-run citations, while non-causal novelty
exhibits weak or even negative effects. Papers engaging with central, widely
recognized concepts tend to attract more citations, highlighting a divergence
between factors driving publication success and long-term academic impact.
Finally, bridging underexplored concept pairs is rewarded primarily when
grounded in causal methods, yet such gap filling exhibits no consistent link
with future citations. Overall, our findings suggest that methodological rigor
and causal innovation are key drivers of academic recognition, but sustained
impact may require balancing novel contributions with conceptual integration
into established economic discourse.

æè¦ï¼<paragraph>æåä½¿ç¨èªè¨èªè¨æ¨¡ååæäº 1980 å¹´è³ 2023 å¹´è¶é 44,000 ä»½ NBER å CEPR å·¥ä½è«æï¼ä»¥å»ºæ§ç¥è­åè­ï¼å°ç¶æ¿æ¦å¿µåå¶éä¿é²è¡å°æãæåååä¸è¬æ§è«è¿°åééå ææ¨è«æ¹æ³ï¼ä¾å¦ DiDãIVãRDDãRCTï¼è¨éçè«è¿°ãæåè¨éå°å æè«è¿°çä»½é¡å¤§å¹ä¸åï¼å¾ 1990 å¹´çç´ 4% ä¸åå° 2020 å¹´çè¿ 28%ï¼åæ äºãå¯ä¿¡åº¦é©å½ãçå½±é¿åæ¥çå¢å¼·ãæåç¼ç¾å ææè¿°çè¤éæ§ï¼ä¾å¦å æéçæ·±åº¦ï¼å¼·çé æ¸¬äºå¨é å° 5 å¤§æåçç¼è¡¨åè¼é«çå¼ç¨æ¬¡æ¸ï¼èéå æè¤éæ§åå¾å¾èéäºçµæç¡éæåè² ç¸éãæ°ç©æ§å°æ¼é å° 5 å¤§æåçç¼è¡¨ä¹è³ééè¦ï¼ä½åææ¯å»ºç«å¨å¯ä¿¡çå ææ¹æ³çåºç¤ä¸ï¼å¼å¥çæ­£æ°çå æéç·£æè·¯å¾é¡¯èå¢å äºå¨é å°åªé«ä¸è¢«æ¥åçå¯è½æ§åé·æå¼ç¨ï¼èéå ææ°ç©æ§åè¡¨ç¾åºå¾®å¼±çè³è² é¢çå½±é¿ãæ¢è¨ä¸­å¿ãå»£æ³èªå¯çæ¦å¿µçè«æå¾å¾æå¸å¼æ´å¤å¼ç¨ï¼çªé¡¯åºæ¨åç¼è¡¨æååé·æå­¸è¡å½±é¿çå ç´ ä¹éçå·®ç°ãæå¾ï¼å¡«è£æ¢ç´¢ä¸è¶³çæ¦å¿µå°æï¼ä¸»è¦æ¯å»ºç«å¨å ææ¹æ³çåºç¤ä¸ï¼ä½éç¨®å·®è·å¡«è£ä¸¦æªè¡¨ç¾åºèæªä¾å¼ç¨çä¸è´éè¯ãç¸½çä¾èªªï¼æåçç ç©¶çµæè¡¨æï¼æ¹æ³è«å´è¬¹æ§åå æåµæ°æ¯å­¸è¡èªå¯çä¸»è¦é©ååï¼ä½æçºçå½±é¿å¯è½éè¦å¹³è¡¡æ°ç©è²¢ç»èèå¥æ¢å®çç¶æ¿è«è¿°ä¸­çæ¦å¿µæ´åã</paragraph>

##### **MiniRAG: Towards Extremely Simple Retrieval-Augmented Generation**
2501.06713v2 by Tianyu Fan, Jingyuan Wang, Xubin Ren, Chao Huang

The growing demand for efficient and lightweight Retrieval-Augmented
Generation (RAG) systems has highlighted significant challenges when deploying
Small Language Models (SLMs) in existing RAG frameworks. Current approaches
face severe performance degradation due to SLMs' limited semantic understanding
and text processing capabilities, creating barriers for widespread adoption in
resource-constrained scenarios. To address these fundamental limitations, we
present MiniRAG, a novel RAG system designed for extreme simplicity and
efficiency. MiniRAG introduces two key technical innovations: (1) a
semantic-aware heterogeneous graph indexing mechanism that combines text chunks
and named entities in a unified structure, reducing reliance on complex
semantic understanding, and (2) a lightweight topology-enhanced retrieval
approach that leverages graph structures for efficient knowledge discovery
without requiring advanced language capabilities. Our extensive experiments
demonstrate that MiniRAG achieves comparable performance to LLM-based methods
even when using SLMs while requiring only 25\% of the storage space.
Additionally, we contribute a comprehensive benchmark dataset for evaluating
lightweight RAG systems under realistic on-device scenarios with complex
queries. We fully open-source our implementation and datasets at:
https://github.com/HKUDS/MiniRAG.

æè¦ï¼é¨èå°é«æä¸è¼éåçæª¢ç´¢å¢å¼·çæ (RAG) ç³»çµ±éæ±çå¢é·ï¼å¨ç¾æ RAG æ¶æ§ä¸­é¨ç½²å°åèªè¨æ¨¡å (SLM) æçªé¡¯äºéå¤§ææ°ãç±æ¼ SLM çèªç¾©çè§£åæå­èçè½åæéï¼ç®åçåæ³é¢è¨å´éçæè½ä¸éï¼çºå¨è³æºåéçææ³ä¸å»£æ³æ¡ç¨è£½é äºéç¤ãçºäºè§£æ±ºéäºæ ¹æ¬æ§çéå¶ï¼æåæåºäº MiniRAGï¼éæ¯ä¸åå°çºæ¥µè´ç°¡æ½åæçèè¨­è¨çæ°å RAG ç³»çµ±ãMiniRAG å°å¥äºå©é ééµæè¡åµæ°ï¼(1) ä¸ç¨®èªç¾©æç¥ç°è³ªåå½¢ç´¢å¼æ©å¶ï¼å®å°æå­åå¡åå½åå¯¦é«çµåå¨ä¸åçµ±ä¸ççµæ§ä¸­ï¼æ¸å°äºå°è¤éèªç¾©çè§£çä¾è³´ï¼ä»¥å (2) ä¸ç¨®è¼éç´ææ²å¢å¼·æª¢ç´¢æ¹æ³ï¼å®å©ç¨åå½¢çµæ§é²è¡ææççç¥è­ç¼ç¾ï¼èä¸éè¦é²éçèªè¨è½åãæåå»£æ³çå¯¦é©è­æï¼å³ä½¿å¨ä½¿ç¨ SLM æï¼MiniRAG ä¹è½éå°èåºæ¼ LLM çæ¹æ³ç¸ç¶çæè½ï¼åæåªéè¦ 25% çå²å­ç©ºéãæ­¤å¤ï¼æåæä¾äºä¸åå¨é¢çåºæºè³æéï¼ç¨æ¼å¨å·æè¤éæ¥è©¢çå¯¦éè£ç½®ææ³ä¸è©ä¼°è¼éç´ RAG ç³»çµ±ãæåå¨ https://github.com/HKUDS/MiniRAG ä¸å®å¨éæºæåçå¯¦ä½åè³æéã

##### **Large Language Models, Knowledge Graphs and Search Engines: A Crossroads for Answering Users' Questions**
2501.06699v1 by Aidan Hogan, Xin Luna Dong, Denny VrandeÄiÄ, Gerhard Weikum

Much has been discussed about how Large Language Models, Knowledge Graphs and
Search Engines can be combined in a synergistic manner. A dimension largely
absent from current academic discourse is the user perspective. In particular,
there remain many open questions regarding how best to address the diverse
information needs of users, incorporating varying facets and levels of
difficulty. This paper introduces a taxonomy of user information needs, which
guides us to study the pros, cons and possible synergies of Large Language
Models, Knowledge Graphs and Search Engines. From this study, we derive a
roadmap for future research.

æè¦ï¼å°æ¼å¤§åèªè¨æ¨¡åãç¥è­åè­åæå°å¼æå¦ä½è½ä»¥ååçæ¹å¼çµåï¼å·²ç¶æè¨±å¤è¨è«ãç®åå­¸è¡è«è¿°ä¸­å¾å¤§ç¨åº¦ä¸å¿½ç¥äºä¸åé¢åï¼é£å°±æ¯ä½¿ç¨èçè§é»ãç¹å¥æ¯ï¼éæ¼å¦ä½æå¥½å°æ»¿è¶³ä½¿ç¨èå¤åçè³è¨éæ±ï¼ä¸¦ç´å¥ä¸åé¢ååé£åº¦å±¤ç´ï¼ä»æè¨±å¤æªè§£æ±ºçåé¡ãæ¬æä»ç´¹äºä¸åä½¿ç¨èè³è¨éæ±çåé¡æ³ï¼å¼å°æåç ç©¶å¤§åèªè¨æ¨¡åãç¥è­åè­åæå°å¼æçåªç¼ºé»åå¯è½çååä½ç¨ãå¾éé ç ç©¶ä¸­ï¼æåè¡çåºæªä¾ç ç©¶çè·¯ç·åã

##### **Quantifying Relational Exploration in Cultural Heritage Knowledge Graphs with LLMs: A Neuro-Symbolic Approach**
2501.06628v1 by Mohammed Maree

This paper introduces a neuro-symbolic approach for relational exploration in
cultural heritage knowledge graphs, leveraging Large Language Models (LLMs) for
explanation generation and a novel mathematical framework to quantify the
interestingness of relationships. We demonstrate the importance of
interestingness measure using a quantitative analysis, by highlighting its
impact on the overall performance of our proposed system, particularly in terms
of precision, recall, and F1-score. Using the Wikidata Cultural Heritage Linked
Open Data (WCH-LOD) dataset, our approach yields a precision of 0.70, recall of
0.68, and an F1-score of 0.69, representing an improvement compared to
graph-based (precision: 0.28, recall: 0.25, F1-score: 0.26) and knowledge-based
baselines (precision: 0.45, recall: 0.42, F1-score: 0.43). Furthermore, our
LLM-powered explanations exhibit better quality, reflected in BLEU (0.52),
ROUGE-L (0.58), and METEOR (0.63) scores, all higher than the baseline
approaches. We show a strong correlation (0.65) between interestingness measure
and the quality of generated explanations, validating its effectiveness. The
findings highlight the importance of LLMs and a mathematical formalization for
interestingness in enhancing the effectiveness of relational exploration in
cultural heritage knowledge graphs, with results that are measurable and
testable. We further show that the system enables more effective exploration
compared to purely knowledge-based and graph-based methods.

æè¦ï¼éç¯è«æä»ç´¹äºä¸ç¨®ç¥ç¶ç¬¦èæ¹æ³ï¼ç¨æ¼æåéºç¢ç¥è­åè­ä¸­çéä¿æ¢ç´¢ï¼å©ç¨å¤§åèªè¨æ¨¡å (LLM) é²è¡è§£éçæï¼ä¸¦å©ç¨ä¸ç¨®æ°ç©çæ¸å­¸æ¡æ¶ä¾éåéä¿çè¶£å³æ§ãæåééå®éåæå±ç¤ºäºè¶£å³æ§æ¸¬éçéè¦æ§ï¼å¼·èª¿å®å°æåææåºçç³»çµ±æ´é«æè½çå½±é¿ï¼ç¹å¥æ¯å¨ç²¾ç¢ºåº¦ãå¬åçå F1 åæ¸æ¹é¢ãä½¿ç¨ Wikidata æåéºç¢é£çµéæ¾è³æ (WCH-LOD) è³æéï¼æåçåæ³ç¢çäº 0.70 çç²¾ç¢ºåº¦ã0.68 çå¬åçå 0.69 ç F1 åæ¸ï¼èåºæ¼åå½¢ (ç²¾ç¢ºåº¦ï¼0.28ãå¬åçï¼0.25ãF1 åæ¸ï¼0.26) ååºæ¼ç¥è­çåºç· (ç²¾ç¢ºåº¦ï¼0.45ãå¬åçï¼0.42ãF1 åæ¸ï¼0.43) ç¸æ¯ï¼éæ¯ä¸åé²æ­¥ãæ­¤å¤ï¼æåç± LLM ä¿æçè§£éå±ç¾åºæ´å¥½çåè³ªï¼åæ å¨ BLEU (0.52)ãROUGE-L (0.58) å METEOR (0.63) åæ¸ä¸ï¼é½é«æ¼åºç·æ¹æ³ãæåé¡¯ç¤ºäºè¶£å³æ§æ¸¬éåç¢ççè§£éåè³ªä¹éå¼·ççç¸éæ§ (0.65)ï¼é©è­äºå®çæææ§ãéäºç¼ç¾çªé¡¯äº LLM åè¶£å³æ§çæ¸å­¸å½¢å¼åå¨å¢å¼·æåéºç¢ç¥è­åè­ä¸­éä¿æ¢ç´¢çæææ§æ¹é¢çéè¦æ§ï¼å¶çµææ¯å¯ä»¥è¡¡éåæ¸¬è©¦çãæåé²ä¸æ­¥è¡¨æï¼èç´ç²¹åºæ¼ç¥è­ååºæ¼åå½¢çæ¹æ³ç¸æ¯ï¼è©²ç³»çµ±è½é²è¡æ´ææçæ¢ç´¢ã

##### **MedCT: A Clinical Terminology Graph for Generative AI Applications in Healthcare**
2501.06465v2 by Ye Chen, Dongdong Huang, Haoyun Xu, Cong Fu, Lin Sheng, Qingli Zhou, Yuqiang Shen, Kai Wang

We introduce the world's first clinical terminology for the Chinese
healthcare community, namely MedCT, accompanied by a clinical foundation model
MedBERT and an entity linking model MedLink. The MedCT system enables
standardized and programmable representation of Chinese clinical data,
successively stimulating the development of new medicines, treatment pathways,
and better patient outcomes for the populous Chinese community. Moreover, the
MedCT knowledge graph provides a principled mechanism to minimize the
hallucination problem of large language models (LLMs), therefore achieving
significant levels of accuracy and safety in LLM-based clinical applications.
By leveraging the LLMs' emergent capabilities of generativeness and
expressiveness, we were able to rapidly built a production-quality terminology
system and deployed to real-world clinical field within three months, while
classical terminologies like SNOMED CT have gone through more than twenty years
development. Our experiments show that the MedCT system achieves
state-of-the-art (SOTA) performance in semantic matching and entity linking
tasks, not only for Chinese but also for English. We also conducted a
longitudinal field experiment by applying MedCT and LLMs in a representative
spectrum of clinical tasks, including electronic health record (EHR)
auto-generation and medical document search for diagnostic decision making. Our
study shows a multitude of values of MedCT for clinical workflows and patient
outcomes, especially in the new genre of clinical LLM applications. We present
our approach in sufficient engineering detail, such that implementing a
clinical terminology for other non-English societies should be readily
reproducible. We openly release our terminology, models and algorithms, along
with real-world clinical datasets for the development.

æè¦ï¼<paragraph>æåçºä¸­æé«çç¤¾ç¾¤å¼å¥äºå¨çé¦åµçè¨åºè¡èªï¼å³ MedCTï¼ä¸¦éå¸¶è¨åºåºç¤æ¨¡å MedBERT åå¯¦é«é£çµæ¨¡å MedLinkãMedCT ç³»çµ±è½æ¨æºåä¸¦ä»¥ç¨å¼è¨­è¨æ¹å¼åç¾ä¸­æè¨åºè³æï¼é²èåºæ¿æ°è¥ãæ²»çéå¾çéç¼ï¼ä¸¦çºäººå£ç¾å¤çè¯äººç¤¾ç¾¤å¸¶ä¾æ´å¥½ççäººæ²»çææãæ­¤å¤ï¼MedCT ç¥è­åè­æä¾ä¸åæååçæ©å¶ï¼ä»¥æå°åå¤§åèªè¨æ¨¡å (LLM) çå¹»è¦ºåé¡ï¼å æ­¤å¨åºæ¼ LLM çè¨åºæç¨ä¸­éå°äºé¡¯èçæºç¢ºæ§åå®å¨æ§ãééå©ç¨ LLM çæåè¡¨éè½åçæ°èåè½ï¼æåå¾ä»¥å¿«éå»ºç½®ä¸åçç¢åè³ªçè¡èªç³»çµ±ï¼ä¸¦å¨ä¸åæå§é¨ç½²å°å¯¦éè¨åºé åï¼èå SNOMED CT éæ¨£çå³çµ±è¡èªç³»çµ±åç¶æ­·äºäºåå¤å¹´çéç¼ãæåçå¯¦é©é¡¯ç¤ºï¼MedCT ç³»çµ±å¨èªç¾©å¹éåå¯¦é«é£çµä»»åä¸­éå°äºæåé² (SOTA) çæè½ï¼ä¸åªé©ç¨æ¼ä¸­æï¼ä¹é©ç¨æ¼è±æãæåéééå¨å·ä»£è¡¨æ§çè¨åºä»»åä¸­æç¨ MedCT å LLM ä¾é²è¡ç¸±åå¯¦å°å¯¦é©ï¼åæ¬é»å­å¥åº·ç´é (EHR) èªåç¢çåç¨æ¼è¨ºæ·æ±ºç­çé«çæä»¶æå°ãæåçç ç©¶é¡¯ç¤º MedCT å°è¨åºå·¥ä½æµç¨åçäººæ²»çæææè¨±å¤å¹å¼ï¼ç¹å¥æ¯å¨æ°åæçè¨åº LLM æç¨ä¸­ãæåä»¥ååçå·¥ç¨ç´°ç¯èªªæäºæåçåæ³ï¼å æ­¤å¯¦ä½å¶ä»éè±èªç¤¾æçè¨åºè¡èªæææ¼è¤è£½ãæåéæ¾éåºæåçè¡èªãæ¨¡ååæ¼ç®æ³ï¼ä»¥åç¨æ¼éç¼çå¯¦éè¨åºè³æéã</paragraph>

##### **Dynamics of "Spontaneous" Topic Changes in Next Token Prediction with Self-Attention**
2501.06382v1 by Mumin Jia, Jairo Diaz-Rodriguez

Human cognition can spontaneously shift conversation topics, often triggered
by emotional or contextual signals. In contrast, self-attention-based language
models depend on structured statistical cues from input tokens for next-token
prediction, lacking this spontaneity. Motivated by this distinction, we
investigate the factors that influence the next-token prediction to change the
topic of the input sequence. We define concepts of topic continuity, ambiguous
sequences, and change of topic, based on defining a topic as a set of token
priority graphs (TPGs). Using a simplified single-layer self-attention
architecture, we derive analytical characterizations of topic changes.
Specifically, we demonstrate that (1) the model maintains the priority order of
tokens related to the input topic, (2) a topic change occurs only if
lower-priority tokens outnumber all higher-priority tokens of the input topic,
and (3) unlike human cognition, longer context lengths and overlapping topics
reduce the likelihood of spontaneous redirection. These insights highlight
differences between human cognition and self-attention-based models in
navigating topic changes and underscore the challenges in designing
conversational AI capable of handling "spontaneous" conversations more
naturally. To our knowledge, this is the first work to address these questions
in such close relation to human conversation and thought.

æè¦ï¼äººé¡èªç¥å¯ä»¥èªç¼å°è½æå°è©±ä¸»é¡ï¼éå¸¸æ¯ç±æç·æèªå¢ä¿¡èè§¸ç¼ãç¸æ¯ä¹ä¸ï¼åºæ¼èªææ³¨æåçèªè¨æ¨¡åä¾è³´æ¼è¼¸å¥ç¬¦èççµæ§åçµ±è¨ç·ç´¢ä¾é æ¸¬ä¸ä¸åç¬¦èï¼ç¼ºä¹éç¨®èªç¼æ§ãåéç¨®åå¥çåç¼ï¼æåæ¢è¨äºå½±é¿ä¸ä¸åç¬¦èé æ¸¬ä»¥æ¹è®è¼¸å¥åºåä¸»é¡çå ç´ ãæåæ ¹æå°ä¸»é¡å®ç¾©çºä¸çµç¬¦èåªåç´åï¼TPGï¼ä¾å®ç¾©ä¸»é¡é£çºæ§ãæ­§ç¾©åºååä¸»é¡è®åçæ¦å¿µãä½¿ç¨ç°¡åçå®å±¤èªæ³¨æåæ¶æ§ï¼æåæ¨å°åºä¸»é¡è®åçåæç¹å¾µãå·é«ä¾èªªï¼æåè­æï¼1ï¼æ¨¡åç¶­è­·èè¼¸å¥ä¸»é¡ç¸éçç¬¦èçåªåé åºï¼ï¼2ï¼åªæç¶è¼ä½åªåé åºçç¬¦èå¤æ¼è¼¸å¥ä¸»é¡çææè¼é«åªåé åºçç¬¦èæï¼ææç¼çä¸»é¡è®åï¼ä»¥åï¼3ï¼èäººé¡èªç¥ä¸åï¼è¼é·çä¸ä¸æé·åº¦åéççä¸»é¡æéä½èªç¼éå®åçå¯è½æ§ãéäºè¦è§£çªåºäºäººé¡èªç¥ååºæ¼èªæ³¨æåçæ¨¡åå¨æå°ä¸»é¡è®åæçå·®ç°ï¼ä¸¦å¼·èª¿äºå¨è¨­è¨è½å¤ æ´èªç¶å°èçãèªç¼ãå°è©±çå°è©±å¼ AI ææé¢è¨çææ°ãææåæç¥ï¼éæ¯ç¬¬ä¸åå¦æ­¤å¯åå°èäººé¡å°è©±åæç¶­ç¸éå°æ¢è¨éäºåé¡çç ç©¶ã

##### **Network Diffuser for Placing-Scheduling Service Function Chains with Inverse Demonstration**
2501.05673v1 by Zuyuan Zhang, Vaneet Aggarwal, Tian Lan

Network services are increasingly managed by considering chained-up virtual
network functions and relevant traffic flows, known as the Service Function
Chains (SFCs). To deal with sequential arrivals of SFCs in an online fashion,
we must consider two closely-coupled problems - an SFC placement problem that
maps SFCs to servers/links in the network and an SFC scheduling problem that
determines when each SFC is executed. Solving the whole SFC problem targeting
these two optimizations jointly is extremely challenging. In this paper, we
propose a novel network diffuser using conditional generative modeling for this
SFC placing-scheduling optimization. Recent advances in generative AI and
diffusion models have made it possible to generate high-quality images/videos
and decision trajectories from language description. We formulate the SFC
optimization as a problem of generating a state sequence for planning and
perform graph diffusion on the state trajectories to enable extraction of SFC
decisions, with SFC optimization constraints and objectives as conditions. To
address the lack of demonstration data due to NP-hardness and exponential
problem space of the SFC optimization, we also propose a novel and somewhat
maverick approach -- Rather than solving instances of this difficult
optimization, we start with randomly-generated solutions as input, and then
determine appropriate SFC optimization problems that render these solutions
feasible. This inverse demonstration enables us to obtain sufficient expert
demonstrations, i.e., problem-solution pairs, through further optimization. In
our numerical evaluations, the proposed network diffuser outperforms learning
and heuristic baselines, by $\sim$20\% improvement in SFC reward and $\sim$50\%
reduction in SFC waiting time and blocking rate.

æè¦ï¼ç¶²è·¯æåè¶ä¾è¶ééèæ®ä¸²é£çèæ¬ç¶²è·¯åè½åç¸éæµéé²è¡ç®¡çï¼ç¨±çºæååè½é (SFC)ãçºäºä»¥ç·ä¸æ¹å¼èç SFC çé åºå°éï¼æåå¿é èæ®å©åç·å¯çµåçåé¡ï¼å° SFC å°æå°ç¶²è·¯ä¸­çä¼ºæå¨/é£çµç SFC éç½®åé¡ï¼ä»¥åæ±ºå®æ¯å SFC ä½æå·è¡ç SFC æç¨åé¡ãåæéå°éå©åæä½³åä¾è§£æ±ºæ´å SFC åé¡æ¥µå·ææ°æ§ãå¨æ¬æä¸­ï¼æåæåºä¸åä½¿ç¨æ¢ä»¶çææ¨¡åçåµæ°ç¶²è·¯æ´æ£å¨ï¼ç¨æ¼æ­¤ SFC éç½®æç¨æä½³åãçæå¼ AI åæ´æ£æ¨¡åçææ°é²å±ä½¿å¾å¾èªè¨æè¿°ä¸­ç¢çé«åè³ªçå½±å/å½±çåæ±ºç­è»è·¡æçºå¯è½ãæåå° SFC æä½³åå¶å®çºç¢çä¸åçæåºåçåé¡ï¼ç¨æ¼è¦åï¼ä¸¦å°çæè»è·¡å·è¡åå½¢æ´æ£ï¼ä»¥æå SFC æ±ºç­ï¼ä¸¦ä»¥ SFC æä½³åç´æåç®æ¨ä½çºæ¢ä»¶ãçºäºè§£æ±ºç±æ¼ NP é£åº¦å SFC æä½³åçææ¸åé¡ç©ºéèå°è´çç¤ºç¯è³æä¸è¶³ï¼æåä¹æåºä¸ååµæ°ä¸æé»ç¹ç«ç¨è¡çåæ³ï¼ä¸æ¯è§£æ±ºéåå°é£æä½³åçå¯¦ä¾ï¼èæ¯å¾é¨æ©ç¢ççè§£ä½çºè¼¸å¥éå§ï¼ç¶å¾æ±ºå®é©ç¶ç SFC æä½³ååé¡ï¼è®éäºè§£å¯è¡ãéåéåç¤ºç¯è®æåè½å¤ ééé²ä¸æ­¥æä½³åï¼ç²å¾è¶³å¤ çå°å®¶ç¤ºç¯ï¼ä¹å°±æ¯åé¡è§£æ±ºéå°ãå¨æåçæ¸å¼è©ä¼°ä¸­ï¼ææåºçç¶²è·¯æ´æ£å¨åªæ¼å­¸ç¿ååç¼å¼åºæºï¼SFC çåµæåäºç´ 20%ï¼SFC ç­å¾æéåå°éçéä½äºç´ 50%ã

##### **FlairGPT: Repurposing LLMs for Interior Designs**
2501.04648v1 by Gabrielle Littlefair, Niladri Shekhar Dutt, Niloy J. Mitra

Interior design involves the careful selection and arrangement of objects to
create an aesthetically pleasing, functional, and harmonized space that aligns
with the client's design brief. This task is particularly challenging, as a
successful design must not only incorporate all the necessary objects in a
cohesive style, but also ensure they are arranged in a way that maximizes
accessibility, while adhering to a variety of affordability and usage
considerations. Data-driven solutions have been proposed, but these are
typically room- or domain-specific and lack explainability in their design
design considerations used in producing the final layout. In this paper, we
investigate if large language models (LLMs) can be directly utilized for
interior design. While we find that LLMs are not yet capable of generating
complete layouts, they can be effectively leveraged in a structured manner,
inspired by the workflow of interior designers. By systematically probing LLMs,
we can reliably generate a list of objects along with relevant constraints that
guide their placement. We translate this information into a design layout
graph, which is then solved using an off-the-shelf constrained optimization
setup to generate the final layouts. We benchmark our algorithm in various
design configurations against existing LLM-based methods and human designs, and
evaluate the results using a variety of quantitative and qualitative metrics
along with user studies. In summary, we demonstrate that LLMs, when used in a
structured manner, can effectively generate diverse high-quality layouts,
making them a viable solution for creating large-scale virtual scenes. Project
webpage at https://flairgpt.github.io/

æè¦ï¼å®¤å§è¨­è¨æ¶åä»ç´°æé¸åå®æç©ä»¶ï¼ä»¥åµé ä¸åç¾è§ãå¯¦ç¨ä¸åè«§çç©ºéï¼ç¬¦åå®¢æ¶çè¨­è¨ç°¡å ±ãéé ä»»åç¹å¥å·æææ°æ§ï¼å çºæåçè¨­è¨ä¸åå¿é ä»¥ä¸è´çé¢¨æ ¼ç´å¥ææå¿è¦çç©ä»¶ï¼éå¿é ç¢ºä¿å®åçæåæ¹å¼è½æå¤§åå¯åæ§ï¼åæç¬¦ååç¨®è² æè½ååä½¿ç¨èéãå·²ç¶æåºäºè³æé©åçè§£æ±ºæ¹æ¡ï¼ä½éäºè§£æ±ºæ¹æ¡éå¸¸æ¯ç¹å®æ¼æ¿éæé åï¼èä¸ç¼ºä¹å¨ç¢çæçµä½å±ææä½¿ç¨çè¨­è¨èéçå¯è§£éæ§ãå¨æ¬æä¸­ï¼æåæ¢è¨å¤§åèªè¨æ¨¡å (LLM) æ¯å¦å¯ä»¥ç´æ¥ç¨æ¼å®¤å§è¨­è¨ãéç¶æåç¼ç¾ LLM å°æªè½å¤ ç¢çå®æ´çä½å±ï¼ä½å®åå¯ä»¥ææå°ä»¥çµæ§åçæ¹å¼å©ç¨ï¼éæä¾èªå®¤å§è¨­è¨å¸«çå·¥ä½æµç¨ãééç³»çµ±æ§å°æ¢æ¥ LLMï¼æåå¯ä»¥å¯é å°ç¢çä¸åç©ä»¶æ¸å®ï¼ä»¥åæå°å®åæ¾ç½®ä½ç½®çç¸å³ç´æãæåå°éäºè³è¨è½ææè¨­è¨ä½å±åï¼ç¶å¾ä½¿ç¨ç¾æçç´æå¼æä½³åè¨­å®ä¾è§£æ±ºï¼ä»¥ç¢çæçµä½å±ãæåå¨åç¨®è¨­è¨éç½®ä¸­å°æåçæ¼ç®æ³èç¾æçåºæ¼ LLM çæ¹æ³åäººé¡è¨­è¨é²è¡åºæºæ¸¬è©¦ï¼ä¸¦ä½¿ç¨åç¨®éååè³ªåææ¨ä»¥åä½¿ç¨èç ç©¶ä¾è©ä¼°çµæãç¸½ä¹ï¼æåè­æäº LLM å¨ä»¥çµæ§åçæ¹å¼ä½¿ç¨æï¼å¯ä»¥ææå°ç¢çå¤æ¨£åçé«åè³ªä½å±ï¼ä½¿å¶æçºåµé å¤§åèæ¬å ´æ¯çå¯è¡è§£æ±ºæ¹æ¡ãå°æ¡ç¶²é å¨ https://flairgpt.github.io/

##### **CGP-Tuning: Structure-Aware Soft Prompt Tuning for Code Vulnerability Detection**
2501.04510v1 by Ruijun Feng, Hammond Pearce, Pietro Liguori, Yulei Sui

Large language models (LLMs) have been proposed as powerful tools for
detecting software vulnerabilities, where task-specific fine-tuning is
typically employed to provide vulnerability-specific knowledge to the LLMs for
this purpose. However, traditional full-parameter fine-tuning is inefficient
for modern, complex LLMs, which contain billions of parameters.
  Soft prompt tuning has been suggested as a more efficient alternative for
fine-tuning LLMs in general cases. However, pure soft prompt tuning treats
source code as plain text, losing structural information inherent in source
code. Meanwhile, graph-enhanced soft prompt tuning methods, which aim to
address this issue, are unable to preserve the rich semantic information within
code graphs, as they are primarily designed for general graph-related tasks and
focus more on adjacency information. They also fail to ensure computational
efficiency while accounting for graph-text interactions.
  This paper, therefore, introduces a new code graph-enhanced, structure-aware
soft prompt tuning method for vulnerability detection, referred to as
CGP-Tuning. It employs innovative type-aware embeddings to capture the rich
semantic information within code graphs, along with a novel and efficient
cross-modal alignment module that achieves linear computational cost while
incorporating graph-text interactions. The proposed CGP-Tuning is evaluated on
the latest DiverseVul dataset and the most recent open-source code LLMs,
CodeLlama and CodeGemma. Experimental results demonstrate that CGP-Tuning
outperforms the best state-of-the-art method by an average of 3.5 percentage
points in accuracy, without compromising its vulnerability detection
capabilities for long source code.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²è¢«æåºç¨æ¼åµæ¸¬è»é«æ¼æ´çå¼·å¤§å·¥å·ï¼å¶ä¸­ä»»åç¹å®å¾®èª¿éå¸¸ç¨æ¼æä¾æ¼æ´ç¹å®ç¥è­çµ¦ LLM ä»¥éå°æ­¤ç®çãç¶èï¼å³çµ±çå®æ´åæ¸å¾®èª¿å°æ¼åå«æ¸ååååæ¸çç¾ä»£è¤é LLM ä¾èªªæçä½ä¸ã
è»æç¤ºå¾®èª¿å·²è¢«å»ºè­°ä½çºä¸è¬ææ³ä¸å¾®èª¿ LLM çæ´æææ¿ä»£æ¹æ¡ãç¶èï¼ç´è»æç¤ºå¾®èª¿å°åå§ç¢¼è¦çºç´æå­ï¼å¤±å»äºåå§ç¢¼ä¸­åºæççµæ§è³è¨ãåæï¼æ¨å¨è§£æ±ºæ­¤åé¡çåå½¢å¢å¼·è»æç¤ºå¾®èª¿æ¹æ³ç¡æ³ä¿çç¨å¼ç¢¼åå½¢ä¸­çè±å¯èªç¾©è³è¨ï¼å çºå®åä¸»è¦è¨­è¨ç¨æ¼ä¸è¬çåå½¢ç¸éä»»åï¼ä¸æ´å°æ³¨æ¼é°æ¥è³è¨ãå®åä¹ç¡æ³å¨èéåå½¢æå­äºåçåæç¢ºä¿éç®æçã
å æ­¤ï¼æ¬æä»ç´¹äºä¸ç¨®æ°çç¨å¼ç¢¼åå½¢å¢å¼·ãçµæ§æç¥è»æç¤ºå¾®èª¿æ¹æ³ä¾åµæ¸¬æ¼æ´ï¼ç¨±çº CGP-Tuningãå®æ¡ç¨åµæ°çé¡åæç¥åµå¥ä¾æ·åç¨å¼ç¢¼åå½¢ä¸­çè±å¯èªç¾©è³è¨ï¼ä»¥åä¸åæ°ç©ä¸ææçè·¨æ¨¡æå°é½æ¨¡çµï¼è©²æ¨¡çµå¨ç´å¥åå½¢æå­äºåçåæå¯¦ç¾ç·æ§éç®ææ¬ãæè­°ç CGP-Tuning å¨ææ°ç DiverseVul è³æéåææ°çéæºç¨å¼ç¢¼ LLMï¼CodeLlama å CodeGemmaï¼ä¸é²è¡è©ä¼°ãå¯¦é©çµæè­æï¼CGP-Tuning å¨æºç¢ºåº¦æ¹é¢å¹³åæ¯æä½³çç¾ææè¡é«åº 3.5 åç¾åé»ï¼åæä¸æå®³å¶å°é·åå§ç¢¼çæ¼æ´åµæ¸¬è½åã

##### **S2 Chunking: A Hybrid Framework for Document Segmentation Through Integrated Spatial and Semantic Analysis**
2501.05485v1 by Prashant Verma

Document chunking is a critical task in natural language processing (NLP)
that involves dividing a document into meaningful segments. Traditional methods
often rely solely on semantic analysis, ignoring the spatial layout of
elements, which is crucial for understanding relationships in complex
documents. This paper introduces a novel hybrid approach that combines layout
structure, semantic analysis, and spatial relationships to enhance the cohesion
and accuracy of document chunks. By leveraging bounding box information (bbox)
and text embeddings, our method constructs a weighted graph representation of
document elements, which is then clustered using spectral clustering.
Experimental results demonstrate that this approach outperforms traditional
methods, particularly in documents with diverse layouts such as reports,
articles, and multi-column designs. The proposed method also ensures that no
chunk exceeds a specified token length, making it suitable for use cases where
token limits are critical (e.g., language models with input size limitations)

æè¦ï¼æä»¶åå¡æ¯èªç¶èªè¨èç (NLP) ä¸­çä¸é ééµä»»åï¼æ¶åå°æä»¶åå²æææç¾©çåå¡ãå³çµ±æ¹æ³éå¸¸åä¾è³´èªç¾©åæï¼å¿½ç¥åç´ çç©ºéä½å±ï¼èéå°æ¼çè§£è¤éæä»¶ä¸­çéä¿è³ééè¦ãæ¬æä»ç´¹ä¸ç¨®æ°ç©çæ··åæ¹æ³ï¼çµåä½å±çµæ§ãèªç¾©åæåç©ºééä¿ï¼ä»¥å¢å¼·æä»¶åå¡çå§èæ§åæºç¢ºæ§ãééå©ç¨éçæ¡è³è¨ (bbox) åæå­åµå¥ï¼æåçæ¨¡åå»ºæ§æä»¶åç´ çå æ¬åè¡¨è¡¨ç¤ºï¼ç¶å¾ä½¿ç¨è­èé¡é²è¡èé¡ãå¯¦é©çµæè¡¨æï¼æ­¤æ¹æ³åªæ¼å³çµ±æ¹æ³ï¼ç¹å¥æ¯å¨å·æä¸åä½å±çæä»¶ä¸­ï¼ä¾å¦å ±åãæç« åå¤æ¬è¨­è¨ãææåºçæ¹æ³éç¢ºä¿æ²æä»»ä½åå¡è¶éæå®çä»¤çé·åº¦ï¼ä½¿å¶é©ç¨æ¼ä»¤çéå¶è³ééè¦çä½¿ç¨æ¡ä¾ï¼ä¾å¦ï¼å·æè¼¸å¥å¤§å°éå¶çèªè¨æ¨¡åï¼

##### **Multimodal Graph Constrastive Learning and Prompt for ChartQA**
2501.04303v1 by Yue Dai, Soyeon Caren Han, Wei Liu

ChartQA presents significant challenges due to the complex distribution of
chart elements and the implicit patterns embedded within the underlying data.
In this chapter, we have developed a joint multimodal scene graph for charts,
explicitly representing the relationships between chart elements and their
associated patterns.
  Our proposed multimodal scene graph consists of two components: a visual
graph and a textual graph, each designed to capture the structural and semantic
information within the chart. To unify representations across these different
modalities, we introduce a multimodal graph contrastive learning approach that
learns unified representations by maximizing similarity between nodes
representing the same object across multimodal graphs. The learned graph
representations can be seamlessly incorporated into a transformer decoder as a
soft prompt.
  Additionally, given the growing need for Multimodal Large Language Models
(MLLMs) in zero-shot scenarios, we have designed Chain-of-Thought (CoT) prompts
for MLLMs to reduce hallucinations. We tested both methods on public benchmarks
such as ChartQA, OpenCQA, and ChartX, demonstrating improved performance and
validating the effectiveness of our proposed methods.

æè¦ï¼ChartQA å åè¡¨åç´ çè¤éåä½ååºç¤è³æä¸­å§åµçé±å«æ¨¡å¼èé¢è¨éå¤§ææ°ã
å¨æ¬ç« ä¸­ï¼æåçºåè¡¨éç¼äºä¸åè¯åå¤æ¨¡æå ´æ¯åå½¢ï¼æç¢ºè¡¨ç¤ºåè¡¨åç´ ä¹éçéä¿åå¶éè¯æ¨¡å¼ã
æåæåºçå¤æ¨¡æå ´æ¯åå½¢åå«å©åçµæé¨åï¼ä¸åè¦è¦ºåå½¢åä¸åææ¬åå½¢ï¼æ¯åçµæé¨åé½æ¨å¨æ·ååè¡¨ä¸­ççµæ§ååèªç¾©è³è¨ã
çºäºçµ±ä¸éäºä¸åæ¨¡æçè¡¨ç¤ºï¼æåå¼å¥äºä¸åå¤æ¨¡æåå½¢å°æ¯å­¸ç¿æ¹æ³ï¼ééæå¤§åè·¨å¤æ¨¡æåå½¢è¡¨ç¤ºç¸åç©ä»¶çç¯é»ä¹éçç¸ä¼¼æ§ä¾å­¸ç¿çµ±ä¸çè¡¨ç¤ºã
å­¸ç¿å°çåå½¢è¡¨ç¤ºå¯ä»¥ç¡ç¸«å°æ´åå°Transformerè§£ç¢¼å¨ä¸­ï¼ä½çºä¸åè»æç¤ºã
æ­¤å¤ï¼éæ¼å¤æ¨¡æå¤§åèªè¨æ¨¡å (MLLM) å¨é¶æ¬¡å­¸ç¿å ´æ¯ä¸­çéæ±æ¥çå¢å ï¼æåçº MLLM è¨­è¨äºæèé (CoT) æç¤ºï¼ä»¥æ¸å°å¹»è¦ºã
æåå¨å¬ç¾åºæºä¸æ¸¬è©¦äºéå©ç¨®æ¹æ³ï¼ä¾å¦ ChartQAãOpenCQA å ChartXï¼è­æäºæè½çæåï¼ä¸¦é©è­äºæåæåºçæ¹æ³çæææ§ã

##### **Detection, Retrieval, and Explanation Unified: A Violence Detection System Based on Knowledge Graphs and GAT**
2501.06224v1 by Wen-Dong Jiang, Chih-Yung Chang, Diptendu Sinha Roy

Recently, violence detection systems developed using unified multimodal
models have achieved significant success and attracted widespread attention.
However, most of these systems face two critical challenges: the lack of
interpretability as black-box models and limited functionality, offering only
classification or retrieval capabilities. To address these challenges, this
paper proposes a novel interpretable violence detection system, termed the
Three-in-One (TIO) System. The TIO system integrates knowledge graphs (KG) and
graph attention networks (GAT) to provide three core functionalities:
detection, retrieval, and explanation. Specifically, the system processes each
video frame along with text descriptions generated by a large language model
(LLM) for videos containing potential violent behavior. It employs ImageBind to
generate high-dimensional embeddings for constructing a knowledge graph, uses
GAT for reasoning, and applies lightweight time series modules to extract video
embedding features. The final step connects a classifier and retriever for
multi-functional outputs. The interpretability of KG enables the system to
verify the reasoning process behind each output. Additionally, the paper
introduces several lightweight methods to reduce the resource consumption of
the TIO system and enhance its efficiency. Extensive experiments conducted on
the XD-Violence and UCF-Crime datasets validate the effectiveness of the
proposed system. A case study further reveals an intriguing phenomenon: as the
number of bystanders increases, the occurrence of violent behavior tends to
decrease.

æè¦ï¼<paragraph>æè¿ï¼ä½¿ç¨çµ±ä¸å¤æ¨¡ææ¨¡åéç¼çæ´ååµæ¸¬ç³»çµ±åå¾é¡¯èæåï¼ä¸¦å¼èµ·å»£æ³éæ³¨ãç¶èï¼éäºç³»çµ±å¤§å¤é¢è¨å©é å´å³»ææ°ï¼ç¼ºä¹é»ç®±æ¨¡åçå¯è§£éæ§ï¼ä»¥ååè½åéï¼åæä¾åé¡ææª¢ç´¢è½åãçºäºè§£æ±ºéäºææ°ï¼æ¬ææåºäºä¸åæ°ç©çå¯è§£éæ´ååµæ¸¬ç³»çµ±ï¼ç¨±çºä¸åä¸ (TIO) ç³»çµ±ãTIO ç³»çµ±æ´åç¥è­åè­ (KG) ååå½¢æ³¨æåç¶²è·¯ (GAT)ï¼ä»¥æä¾ä¸é æ ¸å¿åè½ï¼åµæ¸¬ãæª¢ç´¢åè§£éãå·é«ä¾èªªï¼è©²ç³»çµ±èçæ¯åå½±çå¹ï¼ä»¥åå¤§åèªè¨æ¨¡å (LLM) çºåå«æ½å¨æ´åè¡çºçå½±çç¢ççæå­æè¿°ãå®æ¡ç¨ ImageBind ç¢çé«ç¶­åµå¥ï¼ç¨æ¼å»ºæ§ç¥è­åè­ï¼ä½¿ç¨ GAT é²è¡æ¨çï¼ä¸¦æç¨è¼éç´æéåºåæ¨¡çµä¾æåå½±çåµå¥ç¹å¾µãæå¾ä¸æ­¥é£æ¥åé¡å¨åæª¢ç´¢å¨ï¼ä»¥ç¢çå¤åè½è¼¸åºãKG çå¯è§£éæ§è®ç³»çµ±è½å¤ é©è­æ¯åè¼¸åºèå¾çæ¨çéç¨ãæ­¤å¤ï¼æ¬æä»ç´¹äºå¹¾ç¨®è¼éç´æ¹æ³ï¼ä»¥æ¸å° TIO ç³»çµ±çè³æºæ¶èï¼ä¸¦æåå¶æçãå¨ XD-Violence å UCF-Crime è³æéä¸é²è¡çå»£æ³å¯¦é©é©è­äºææåºç³»çµ±çæææ§ãæ¡ä¾ç ç©¶é²ä¸æ­¥æ­ç¤ºäºä¸åæè¶£çç¾è±¡ï¼é¨èæè§èäººæ¸å¢å ï¼æ´åè¡çºç¼ççæ©çæä¸éã</paragraph>

##### **Applying Large Language Models in Knowledge Graph-based Enterprise Modeling: Challenges and Opportunities**
2501.03566v1 by Benedikt Reitemeyer, Hans-Georg Fill

The role of large language models (LLMs) in enterprise modeling has recently
started to shift from academic research to that of industrial applications.
Thereby, LLMs represent a further building block for the machine-supported
generation of enterprise models. In this paper we employ a knowledge
graph-based approach for enterprise modeling and investigate the potential
benefits of LLMs in this context. In addition, the findings of an expert survey
and ChatGPT-4o-based experiments demonstrate that LLM-based model generations
exhibit minimal variability, yet remain constrained to specific tasks, with
reliability declining for more intricate tasks. The survey results further
suggest that the supervision and intervention of human modeling experts are
essential to ensure the accuracy and integrity of the generated models.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨ä¼æ¥­å»ºæ¨¡ä¸­çè§è²æè¿å·²éå§å¾å­¸è¡ç ç©¶è½è®çºç¢æ¥­æç¨ãå æ­¤ï¼LLM ä»£è¡¨äºæ©å¨æ¯æ´çä¼æ¥­æ¨¡åçæçé²ä¸æ­¥å»ºæ§æ¨¡çµãå¨æ¬æä¸­ï¼æåæ¡ç¨åºæ¼ç¥è­åè¡¨çä¼æ¥­å»ºæ¨¡æ¹æ³ï¼ä¸¦æ¢è¨ LLM å¨æ­¤èçµ¡ä¸­çæ½å¨æçãæ­¤å¤ï¼å°å®¶èª¿æ¥ååºæ¼ ChatGPT-4o çå¯¦é©çµæè¡¨æï¼åºæ¼ LLM çæ¨¡åçæå±ç¾æå°çå¯è®æ§ï¼ä½ä»ä¾·éæ¼ç¹å®ä»»åï¼èå¯é æ§æé¨èä»»åçè¤éæ§èä¸éãèª¿æ¥çµæé²ä¸æ­¥è¡¨æï¼äººé¡å»ºæ¨¡å°å®¶çç£ç£åä»å¥å°æ¼ç¢ºä¿çææ¨¡åçæºç¢ºæ§åå®æ´æ§è³ééè¦ã

##### **KG-TRICK: Unifying Textual and Relational Information Completion of Knowledge for Multilingual Knowledge Graphs**
2501.03560v1 by Zelin Zhou, Simone Conia, Daniel Lee, Min Li, Shenglei Huang, Umar Farooq Minhas, Saloni Potdar, Henry Xiao, Yunyao Li

Multilingual knowledge graphs (KGs) provide high-quality relational and
textual information for various NLP applications, but they are often
incomplete, especially in non-English languages. Previous research has shown
that combining information from KGs in different languages aids either
Knowledge Graph Completion (KGC), the task of predicting missing relations
between entities, or Knowledge Graph Enhancement (KGE), the task of predicting
missing textual information for entities. Although previous efforts have
considered KGC and KGE as independent tasks, we hypothesize that they are
interdependent and mutually beneficial. To this end, we introduce KG-TRICK, a
novel sequence-to-sequence framework that unifies the tasks of textual and
relational information completion for multilingual KGs. KG-TRICK demonstrates
that: i) it is possible to unify the tasks of KGC and KGE into a single
framework, and ii) combining textual information from multiple languages is
beneficial to improve the completeness of a KG. As part of our contributions,
we also introduce WikiKGE10++, the largest manually-curated benchmark for
textual information completion of KGs, which features over 25,000 entities
across 10 diverse languages.

æè¦ï¼å¤èªè¨ç¥è­åè­ (KG) çºåç¨® NLP æç¨ç¨å¼æä¾é«åè³ªçéä¿åæå­è³è¨ï¼ä½å®åéå¸¸æ¯ä¸å®æ´çï¼ç¹å¥æ¯éè±èªèªè¨ãååçç ç©¶é¡¯ç¤ºï¼çµåä¸åèªè¨ä¸­ KG çè³è¨æå©æ¼ç¥è­åè­å®æåè½ (KGC)ï¼å³é æ¸¬å¯¦é«ä¹ééºå¤±çéä¿ï¼æç¥è­åè­å¢å¼· (KGE)ï¼å³é æ¸¬å¯¦é«éºå¤±çæå­è³è¨ãåç®¡ååçåªåå° KGC å KGE è¦çºç¨ç«çä»»åï¼æååè¨­å®åæ¯ç¸äºä¾è³´ä¸äºå©çãçºæ­¤ï¼æåå¼å¥äº KG-TRICKï¼ä¸åæ°ç©çåºåå°åºåæ¶æ§ï¼å®çµ±ä¸äºå¤èªè¨ KG çæå­åéä¿è³è¨å®æä»»åãKG-TRICK è­æï¼i) å¯ä»¥å° KGC å KGE çä»»åçµ±ä¸å°å®ä¸æ¶æ§ä¸­ï¼ä»¥å ii) çµåå¤ç¨®èªè¨çæå­è³è¨æå©æ¼æé« KG çå®æ´æ§ãä½çºæåè²¢ç»çä¸é¨åï¼æåéå¼å¥äº WikiKGE10++ï¼éæ¯ KG æå­è³è¨å®ææå¤§çæåæ´çåºæºï¼å¶ç¹é»æ¯è¶é 10 ç¨®ä¸åèªè¨ä¸­ç 25,000 åå¯¦é«ã

##### **Semantic Captioning: Benchmark Dataset and Graph-Aware Few-Shot In-Context Learning for SQL2Text**
2501.03166v1 by Ali Al-Lawati, Jason Lucas, Prasenjit Mitra

Large Language Models (LLMs) have demonstrated remarkable performance in
various NLP tasks, including semantic parsing, which trans lates natural
language into formal code representations. However, the reverse process,
translating code into natural language, termed semantic captioning, has
received less attention. This task is becoming increasingly important as LLMs
are integrated into platforms for code generation, security analysis, and
educational purposes. In this paper, we focus on the captioning of SQL query
(SQL2Text) to address the critical need for understanding and explaining SQL
queries in an era where LLM-generated code poses potential security risks. We
repurpose Text2SQL datasets for SQL2Text by introducing an iterative ICL prompt
using GPT-4o to generate multiple additional utterances, which enhances the
robustness of the datasets for the reverse task. We conduct our experiments
using in-context learning (ICL) based on different sample selection methods,
emphasizing smaller, more computationally efficient LLMs. Our findings
demonstrate that leveraging the inherent graph properties of SQL for ICL sample
selection significantly outperforms random selection by up to 39% on BLEU score
and provides better results than alternative methods. Dataset and codes are
published: \url{https://github.com/aliwister/ast-icl}.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²å¨åç¨® NLP ä»»åä¸­å±ç¾åºé©äººçæè½ï¼åæ¬èªæåæï¼å®å°èªç¶èªè¨è½æçºæ­£å¼çç¨å¼ç¢¼è¡¨ç¤ºãç¶èï¼ååéç¨ï¼å°ç¨å¼ç¢¼è½æçºèªç¶èªè¨ï¼ç¨±çºèªææ¨é¡ï¼åè¼å°åå°éæ³¨ãé¨è LLM æ´åå°ç¨å¼ç¢¼ç¢çãå®å¨æ§åæåæè²ç®ççå¹³å°ä¸­ï¼éé ä»»åæ­£è®å¾è¶ä¾è¶éè¦ãå¨æ¬æä¸­ï¼æåå°æ³¨æ¼ SQL æ¥è©¢çæ¨é¡ (SQL2Text)ï¼ä»¥æ»¿è¶³å¨ LLM ç¢ççç¨å¼ç¢¼æ§ææ½å¨å®å¨é¢¨éªçæä»£ä¸­ï¼çè§£åè§£é SQL æ¥è©¢çééµéæ±ãæåééä½¿ç¨ GPT-4o å°å¥åè¦ç ICL æç¤ºä¾ç¢çå¤åé¡å¤çèªå¥ï¼éæ°èª¿æ´ Text2SQL è³æéä»¥ç¨æ¼ SQL2Textï¼éå¢å¼·äºè³æéå°ååä»»åçç©©å¥æ§ãæåä½¿ç¨åºæ¼ä¸åç¯ä¾é¸åæ¹æ³çæå¢å­¸ç¿ (ICL) é²è¡å¯¦é©ï¼å¼·èª¿è¼å°ãè¨ç®æçè¼é«ç LLMãæåçç ç©¶çµæè­æï¼å©ç¨ SQL çå§å¨åå½¢å±¬æ§é²è¡ ICL ç¯ä¾é¸åï¼å¨ BLEU åæ¸ä¸é¡¯èåªæ¼é¨æ©é¸åï¼æå¤å¯é 39%ï¼ä¸¦æä¾æ¯å¶ä»æ¹æ³æ´å¥½ççµæãè³æéåç¨å¼ç¢¼å·²ç¼å¸ï¼\url{https://github.com/aliwister/ast-icl}ã

##### **Personalized Fashion Recommendation with Image Attributes and Aesthetics Assessment**
2501.03085v1 by Chongxian Chen, Fan Mo, Xin Fan, Hayato Yamana

Personalized fashion recommendation is a difficult task because 1) the
decisions are highly correlated with users' aesthetic appetite, which previous
work frequently overlooks, and 2) many new items are constantly rolling out
that cause strict cold-start problems in the popular identity (ID)-based
recommendation methods. These new items are critical to recommend because of
trend-driven consumerism. In this work, we aim to provide more accurate
personalized fashion recommendations and solve the cold-start problem by
converting available information, especially images, into two attribute graphs
focusing on optimized image utilization and noise-reducing user modeling.
Compared with previous methods that separate image and text as two components,
the proposed method combines image and text information to create a richer
attributes graph. Capitalizing on the advancement of large language and vision
models, we experiment with extracting fine-grained attributes efficiently and
as desired using two different prompts. Preliminary experiments on the IQON3000
dataset have shown that the proposed method achieves competitive accuracy
compared with baselines.

æè¦ï¼å®¢è£½åæå°æ¨è¦æ¯ä¸é å°é£çä»»åï¼å çº 1) æ±ºç­èä½¿ç¨èçç¾å­¸åå¥½é«åº¦ç¸éï¼èååçç ç©¶ç¶å¸¸å¿½ç¥éä¸é»ï¼ä»¥å 2) è¨±å¤æ°ååä¸æ·æ¨åºï¼éæå¨æµè¡çèº«å (ID) çºåºç¤çæ¨è¦æ¹æ³ä¸­é æå´éçå·åååé¡ãéäºæ°ååå°æ¼æ¨è¦è³ééè¦ï¼å çºå®åæå¼é æ¶è²»è¶¨å¢ãå¨éé ç ç©¶ä¸­ï¼æåæ¨å¨æä¾æ´æºç¢ºçå®¢è£½åæå°æ¨è¦ï¼ä¸¦ééå°å¯ç¨è³è¨ï¼å°¤å¶æ¯åçï¼è½ææå©åå±¬æ§åè¡¨ä¾è§£æ±ºå·åååé¡ï¼éé»å¨æ¼æä½³ååçä½¿ç¨åéä½éè¨çä½¿ç¨èå»ºæ¨¡ãèå°åçåæå­åéçºå©åçµæçååæ¹æ³ç¸æ¯ï¼ææåºçæ¹æ³çµååçåæå­è³è¨ï¼ä»¥å»ºç«æ´è±å¯çå±¬æ§åè¡¨ãå©ç¨å¤§åèªè¨åè¦è¦ºæ¨¡åçé²æ­¥ï¼æååè©¦ä½¿ç¨å©ç¨®ä¸åçæç¤ºææçä¸å¦é æè¬å°èåç´°ç·»çå±¬æ§ãå¨ IQON3000 è³æéä¸çåæ­¥å¯¦é©é¡¯ç¤ºï¼èåºæºç¸æ¯ï¼ææåºçæ¹æ³éå°äºç«¶ç­åçæºç¢ºåº¦ã

##### **Graph-based Retrieval Augmented Generation for Dynamic Few-shot Text Classification**
2501.02844v1 by Yubo Wang, Haoyang Li, Fei Teng, Lei Chen

Text classification is a fundamental task in natural language processing,
pivotal to various applications such as query optimization, data integration,
and schema matching. While neural network-based models, such as CNN and BERT,
have demonstrated remarkable performance in text classification, their
effectiveness heavily relies on abundant labeled training data. This dependency
makes these models less effective in dynamic few-shot text classification,
where labeled data is scarce, and target labels frequently evolve based on
application needs. Recently, large language models (LLMs) have shown promise
due to their extensive pretraining and contextual understanding. Current
approaches provide LLMs with text inputs, candidate labels, and additional side
information (e.g., descriptions) to predict text labels. However, their
effectiveness is hindered by the increased input size and the noise introduced
through side information processing. To address these limitations, we propose a
graph-based online retrieval-augmented generation framework, namely GORAG, for
dynamic few-shot text classification. GORAG constructs and maintains an
adaptive information graph by extracting side information across all target
texts, rather than treating each input independently. It employs a weighted
edge mechanism to prioritize the importance and reliability of extracted
information and dynamically retrieves relevant context using a minimum-cost
spanning tree tailored for each text input. Empirical evaluations demonstrate
that GORAG outperforms existing approaches by providing more comprehensive and
accurate contextual information.

æè¦ï¼ææ¬åé¡æ¯èªç¶èªè¨èçä¸­çåºæ¬ä»»åï¼
å°æ¼åç¨®æç¨è³ééè¦ï¼ä¾å¦æ¥è©¢åªåãè³ææ´åï¼
åæ¨¡å¼å¹éãéç¶åºæ¼ç¥ç¶ç¶²è·¯çæ¨¡åï¼ä¾å¦ CNN å BERTï¼
å¨ææ¬åé¡ä¸­è¡¨ç¾åºè²ï¼ä½å¶
æææ§å¨å¾å¤§ç¨åº¦ä¸ä¾è³´æ¼å¤§éçæ¨ç±¤è¨ç·´è³æãéåä¾è³´æ§
ä½¿å¾éäºæ¨¡åå¨åæå°æ¨£æ¬ææ¬åé¡ä¸­ææè¼å·®ï¼
å¶ä¸­æ¨ç±¤è³æç¨ç¼ºï¼ä¸¦ä¸ç®æ¨æ¨ç±¤ææ ¹æ
æç¨éæ±é »ç¹æ¼è®ãæè¿ï¼å¤§åèªè¨æ¨¡å (LLM) ç±æ¼å¶å»£æ³çé è¨ç·´åä¸ä¸æçè§£èé¡¯ç¤ºåºåæ¯ãç®å
æ¹æ³çº LLM æä¾ææ¬è¼¸å¥ãåé¸æ¨ç±¤åéå å´é
è³è¨ï¼ä¾å¦ï¼æè¿°ï¼ä»¥é æ¸¬ææ¬æ¨ç±¤ãç¶èï¼å¶
æææ§åå°è¼¸å¥å¤§å°å¢å åå´éè³è¨èçå¼å¥çéè¨çé»ç¤ãçºäºè§£æ±ºéäºéå¶ï¼æåæåºä¸å
åºæ¼åè¡¨çç·ä¸æª¢ç´¢å¢å¼·çææ¶æ§ï¼å³ GORAGï¼ç¨æ¼
åæå°æ¨£æ¬ææ¬åé¡ãGORAG ééæåææç®æ¨çå´éè³è¨ä¾å»ºæ§ä¸¦ç¶­è­·ä¸å
èªé©æè³è¨åè¡¨
ææ¬ï¼èä¸æ¯ç¨ç«èçæ¯åè¼¸å¥ãå®æ¡ç¨å æ¬
éç·£æ©å¶ä¾åªåèæ®æåè³è¨çéè¦æ§åå¯é æ§ï¼ä¸¦ä½¿ç¨éå°æ¯åææ¬è¼¸å¥éèº«æé çæå°ææ¬
çææ¨¹åææª¢ç´¢ç¸éçä¸ä¸æãå¯¦è­è©ä¼°è¡¨æ
GORAG ééæä¾æ´å¨é¢ä¸æºç¢ºçä¸ä¸æè³è¨ï¼åªæ¼ç¾ææ¹æ³ã

##### **KG-CF: Knowledge Graph Completion with Context Filtering under the Guidance of Large Language Models**
2501.02711v1 by Zaiyi Zheng, Yushun Dong, Song Wang, Haochen Liu, Qi Wang, Jundong Li

Large Language Models (LLMs) have shown impressive performance in various
tasks, including knowledge graph completion (KGC). However, current studies
mostly apply LLMs to classification tasks, like identifying missing triplets,
rather than ranking-based tasks, where the model ranks candidate entities based
on plausibility. This focus limits the practical use of LLMs in KGC, as
real-world applications prioritize highly plausible triplets. Additionally,
while graph paths can help infer the existence of missing triplets and improve
completion accuracy, they often contain redundant information. To address these
issues, we propose KG-CF, a framework tailored for ranking-based KGC tasks.
KG-CF leverages LLMs' reasoning abilities to filter out irrelevant contexts,
achieving superior results on real-world datasets. The code and datasets are
available at \url{https://anonymous.4open.science/r/KG-CF}.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨åç¨®ä»»åä¸­å±ç¾åºä»¤äººå°è±¡æ·±å»çè¡¨ç¾ï¼åæ¬ç¥è­åè­å®æåè½ (KGC)ãç¶èï¼ç®åçç ç©¶å¤§å¤å° LLM æç¨æ¼åé¡ä»»åï¼ä¾å¦è­å¥éºæ¼çä¸åçµï¼èéåºæ¼æåçä»»åï¼å¶ä¸­æ¨¡åæ ¹æåçæ§å°åé¸å¯¦é«é²è¡æåãéç¨®éé»éå¶äº LLM å¨ KGC ä¸­çå¯¦éæç¨ï¼å çºç¾å¯¦ä¸ççæç¨åªåèæ®é«åº¦åçççä¸åçµãæ­¤å¤ï¼åç®¡åå½¢è·¯å¾æå©æ¼æ¨æ·éºæ¼çä¸åçµçå­å¨ä¸¦æé«å®æçæºç¢ºæ§ï¼ä½å®åéå¸¸åå«åé¤è³è¨ãçºäºè§£æ±ºéäºåé¡ï¼æåæåº KG-CFï¼ä¸åå°ééå°åºæ¼æåç KGC ä»»åçæ¡æ¶ãKG-CF å©ç¨ LLM çæ¨çè½åä¾éæ¿¾ä¸ç¸éçä¸ä¸æï¼å¨ç¾å¯¦ä¸ççè³æéä¸åå¾åè¶çææãç¨å¼ç¢¼åè³æéå¯å¨ \url{https://anonymous.4open.science/r/KG-CF} åå¾ã

##### **Graph-Aware Isomorphic Attention for Adaptive Dynamics in Transformers**
2501.02393v2 by Markus J. Buehler

We present an approach to modifying Transformer architectures by integrating
graph-aware relational reasoning into the attention mechanism, merging concepts
from graph neural networks and language modeling. Building on the inherent
connection between attention and graph theory, we reformulate the Transformer's
attention mechanism as a graph operation and propose Graph-Aware Isomorphic
Attention. This method leverages advanced graph modeling strategies, including
Graph Isomorphism Networks (GIN) and Principal Neighborhood Aggregation (PNA),
to enrich the representation of relational structures. Our approach captures
complex dependencies and generalizes across tasks, as evidenced by a reduced
generalization gap and improved learning performance. Additionally, we expand
the concept of graph-aware attention to introduce Sparse GIN-Attention, a
fine-tuning approach that employs sparse GINs. By interpreting attention
matrices as sparse adjacency graphs, this technique enhances the adaptability
of pre-trained foundational models with minimal computational overhead,
endowing them with graph-aware capabilities. Sparse GIN-Attention fine-tuning
achieves improved training dynamics and better generalization compared to
alternative methods like low-rank adaption (LoRA). We discuss latent graph-like
structures within traditional attention mechanisms, offering a new lens through
which Transformers can be understood. By evolving Transformers as hierarchical
GIN models for relational reasoning. This perspective suggests profound
implications for foundational model development, enabling the design of
architectures that dynamically adapt to both local and global dependencies.
Applications in bioinformatics, materials science, language modeling, and
beyond could benefit from this synthesis of relational and sequential data
modeling, setting the stage for interpretable and generalizable modeling
strategies.

æè¦ï¼<paragraph>æåæåºäºä¸ç¨®ä¿®æ¹ Transformer æ¶æ§çæ¹æ³ï¼æ¹æ³æ¯å°åæç¥éè¯æ¨çæ´åå°æ³¨æåæ©å¶ä¸­ï¼åä½µåç¥ç¶ç¶²è·¯åèªè¨æ¨¡åçæ¦å¿µãåºæ¼æ³¨æåååè«ä¹éçå§å¨è¯ç¹«ï¼æåå° Transformer çæ³¨æåæ©å¶éæ°è¡¨è¿°çºåæä½ï¼ä¸¦æåºåæç¥åæ§æ³¨æåãæ­¤æ¹æ³å©ç¨åé²çåæ¨¡åç­ç¥ï¼åæ¬ååæ§ç¶²è·¯ (GIN) åä¸»é°åèå (PNA)ï¼ä»¥è±å¯éä¿çµæ§çè¡¨ç¤ºãæåçåæ³ææäºè¤éçä¾è³´éä¿ï¼ä¸¦å¨åé ä»»åä¸­é²è¡æ¦æ¬ï¼éå¾ç¸®å°çæ¦æ¬å·®è·åæ¹åçå­¸ç¿è¡¨ç¾ä¸­å¾å°è­æãæ­¤å¤ï¼æåæ´å±äºåæç¥æ³¨æåçæ¦å¿µï¼å¼å¥äºç¨ç GIN æ³¨æåï¼éæ¯ä¸ç¨®æ¡ç¨ç¨ç GIN çå¾®èª¿æ¹æ³ãééå°æ³¨æåç©é£è§£éçºç¨çé°æ¥åï¼æ­¤æè¡ä»¥æå°çè¨ç®éé·å¢å¼·äºé è¨ç·´åºç¤æ¨¡åçé©ææ§ï¼è³¦äºå®ååæç¥è½åãèä½ç§©é©æ (LoRA) ç­æ¿ä»£æ¹æ³ç¸æ¯ï¼ç¨ç GIN æ³¨æåå¾®èª¿å¯¦ç¾äºæ¹é²çè¨ç·´åæåæ´å¥½çæ¦æ¬ãæåè¨è«äºå³çµ±æ³¨æåæ©å¶ä¸­çæ½å¨åå½¢çµæ§ï¼æä¾äºä¸åæ°çè¦è§ï¼ééå®å¯ä»¥çè§£ Transformerãééå° Transformer æ¼åçºç¨æ¼éä¿æ¨ççåå±¤ GIN æ¨¡åãéç¨®è§é»å°åºç¤æ¨¡åçéç¼å·ææ·±é çå½±é¿ï¼å¯ä»¥è¨­è¨åºåæé©æå±é¨åå¨å±ä¾è³´éä¿çæ¶æ§ãçç©è³è¨å­¸ãææç§å­¸ãèªè¨å»ºæ¨¡ç­é åçæç¨å¯ä»¥å¾éç¨®éä¿ååºåè³æå»ºæ¨¡çç¶åä¸­åçï¼çºå¯è§£éåå¯æ¦æ¬çå»ºæ¨¡ç­ç¥å¥ å®åºç¤ã</paragraph>

##### **What Kind of Visual Tokens Do We Need? Training-free Visual Token Pruning for Multi-modal Large Language Models from the Perspective of Graph**
2501.02268v1 by Yutao Jiang, Qiong Wu, Wenhao Lin, Wei Yu, Yiyi Zhou

Recent Multimodal Large Language Models(MLLMs) often use a large number of
visual tokens to compensate their visual shortcoming, leading to excessive
computation and obvious visual redundancy. In this paper, we investigate what
kind of visual tokens are needed for MLLMs, and reveal that both foreground and
background tokens are critical for MLLMs given the varying difficulties of
examples. Based on this observation, we propose a graph-based method towards
training-free visual token pruning, termed G-Prune.In particular, G-Prune
regards visual tokens as nodes, and construct their connections based on their
semantic similarities. Afterwards, the information flow is propagated via
weighted links, and the most important tokens after iterations are kept for
MLLMs, which can be front or background.To validate G-Prune, we apply it to a
recent MLLM called LLaVA-NeXT, and conduct extensive experiments on a set of
benchmarks.The experiment results show that G-Prune can greatly reduce
computation overhead while retaining high performance on both coarse- and
fine-grained tasks. For instance, G-Prune can reduce 63.57\% FLOPs of
LLaVA-NeXT on VQA2.0 and TextVQA with only 0.95\% and 2.34\% accuracy drops,
respectively.

æè¦ï¼æè¿çå¤æ¨¡æå¤§åè¯­è¨æ¨¡å (MLLM) ç»å¸¸ä½¿ç¨å¤§éçè§è§æ è®°æ¥å¼¥è¡¥å¶è§è§ä¸çç¼ºç¹ï¼å¯¼è´è¿åº¦çè®¡ç®åææ¾çè§è§åä½ãå¨æ¬æä¸­ï¼æä»¬è°æ¥äº MLLM éè¦åªç§è§è§æ è®°ï¼å¹¶æ­ç¤ºäºé´äºç¤ºä¾çé¾åº¦ä¸åï¼åæ¯æ è®°åèæ¯æ è®°å¯¹äº MLLM é½æ¯è³å³éè¦çãåºäºæ­¤è§å¯ï¼æä»¬æåºäºä¸ç§åºäºå¾çæ è®­ç»è§è§æ è®°åªææ¹æ³ï¼ç§°ä¸º G-Pruneãç¹å«æ¯ï¼G-Prune å°è§è§æ è®°è§ä¸ºèç¹ï¼å¹¶æ ¹æ®å¶è¯­ä¹ç¸ä¼¼æ§æå»ºå®ä»¬çè¿æ¥ãä¹åï¼ä¿¡æ¯æµéè¿å æé¾æ¥ä¼ æ­ï¼å¹¶ä¸å¨è¿­ä»£åæéè¦çæ è®°ä¿çç¨äº MLLMï¼å®å¯ä»¥æ¯åæ¯æèæ¯ãä¸ºäºéªè¯ G-Pruneï¼æä»¬å°å¶åºç¨äºç§°ä¸º LLaVA-NeXT çææ° MLLMï¼å¹¶å¨ä¸ç»åºåä¸è¿è¡äºå¹¿æ³çå®éªãå®éªç»æè¡¨æï¼G-Prune å¯ä»¥æå¤§å°åå°è®¡ç®å¼éï¼åæ¶å¨ç²ç²åº¦åç»ç²åº¦ä»»å¡ä¸ä¿æé«æ§è½ãä¾å¦ï¼G-Prune å¯ä»¥å° LLaVA-NeXT å¨ VQA2.0 å TextVQA ä¸ç FLOP åå° 63.57%ï¼èåç¡®åº¦åå«ä»ä¸é 0.95% å 2.34%ã

##### **Personalized Graph-Based Retrieval for Large Language Models**
2501.02157v1 by Steven Au, Cameron J. Dimacali, Ojasmitha Pedirappagari, Namyong Park, Franck Dernoncourt, Yu Wang, Nikos Kanakaris, Hanieh Deilamsalehy, Ryan A. Rossi, Nesreen K. Ahmed

As large language models (LLMs) evolve, their ability to deliver personalized
and context-aware responses offers transformative potential for improving user
experiences. Existing personalization approaches, however, often rely solely on
user history to augment the prompt, limiting their effectiveness in generating
tailored outputs, especially in cold-start scenarios with sparse data. To
address these limitations, we propose Personalized Graph-based
Retrieval-Augmented Generation (PGraphRAG), a framework that leverages
user-centric knowledge graphs to enrich personalization. By directly
integrating structured user knowledge into the retrieval process and augmenting
prompts with user-relevant context, PGraphRAG enhances contextual understanding
and output quality. We also introduce the Personalized Graph-based Benchmark
for Text Generation, designed to evaluate personalized text generation tasks in
real-world settings where user history is sparse or unavailable. Experimental
results show that PGraphRAG significantly outperforms state-of-the-art
personalization methods across diverse tasks, demonstrating the unique
advantages of graph-based retrieval for personalization.

æè¦ï¼é¨èå¤§åèªè¨æ¨¡å (LLM) çæ¼é²ï¼å®åæä¾åäººååæå¢æç¥åæçè½åï¼çºæåä½¿ç¨èé«é©æä¾äºè®é©æ½åãç¶èï¼ç¾æçåäººåæ¹æ³éå¸¸åä¾è³´ä½¿ç¨èè¨éä¾æ´åæç¤ºï¼ééå¶äºå®åå¨ç¢çå®¢è£½åè¼¸åºçæè½ï¼ç¹å¥æ¯å¨è³æç¨ççå·ååæå¢ä¸­ãçºäºè§£æ±ºéäºéå¶ï¼æåæåºäºãåäººååå½¢åæª¢ç´¢æ´åç¢çã(PGraphRAG)ï¼ä¸åå©ç¨ä»¥ä½¿ç¨èçºä¸­å¿çç¥è­åå½¢ä¾è±å¯åäººåçæ¶æ§ãééå°çµæ§åçä½¿ç¨èç¥è­ç´æ¥æ´åå°æª¢ç´¢ç¨åºä¸­ï¼ä¸¦ä½¿ç¨èä½¿ç¨èç¸éçå§å®¹æ´åæç¤ºï¼PGraphRAG å¢å¼·äºæå¢çè§£åè¼¸åºåè³ªãæåä¹å¼å¥äºãåäººååå½¢ååºæºææ¬ç¢çãï¼æ¨å¨è©ä¼°å¨ä½¿ç¨èè¨éç¨çæä¸å¯ç¨ççå¯¦ä¸çè¨­å®ä¸­çåäººåææ¬ç¢çä»»åãå¯¦é©çµæé¡¯ç¤ºï¼PGraphRAG å¨åç¨®ä»»åä¸­é¡¯èåªæ¼æåé²çåäººåæ¹æ³ï¼è­æäºåå½¢åæª¢ç´¢å¨åäººåæ¹é¢çç¨ç¹åªå¢ã

##### **Cold-Start Recommendation towards the Era of Large Language Models (LLMs): A Comprehensive Survey and Roadmap**
2501.01945v2 by Weizhi Zhang, Yuanchen Bei, Liangwei Yang, Henry Peng Zou, Peilin Zhou, Aiwei Liu, Yinghui Li, Hao Chen, Jianling Wang, Yu Wang, Feiran Huang, Sheng Zhou, Jiajun Bu, Allen Lin, James Caverlee, Fakhri Karray, Irwin King, Philip S. Yu

Cold-start problem is one of the long-standing challenges in recommender
systems, focusing on accurately modeling new or interaction-limited users or
items to provide better recommendations. Due to the diversification of internet
platforms and the exponential growth of users and items, the importance of
cold-start recommendation (CSR) is becoming increasingly evident. At the same
time, large language models (LLMs) have achieved tremendous success and possess
strong capabilities in modeling user and item information, providing new
potential for cold-start recommendations. However, the research community on
CSR still lacks a comprehensive review and reflection in this field. Based on
this, in this paper, we stand in the context of the era of large language
models and provide a comprehensive review and discussion on the roadmap,
related literature, and future directions of CSR. Specifically, we have
conducted an exploration of the development path of how existing CSR utilizes
information, from content features, graph relations, and domain information, to
the world knowledge possessed by large language models, aiming to provide new
insights for both the research and industrial communities on CSR. Related
resources of cold-start recommendations are collected and continuously updated
for the community in
https://github.com/YuanchenBei/Awesome-Cold-Start-Recommendation.

æè¦ï¼å·åååé¡æ¯æ¨è¦ç³»çµ±ä¸­é·æå­å¨çææ°ä¹ä¸ï¼å°æ³¨æ¼æºç¢ºå»ºæ¨¡æ°çæäºååéçä½¿ç¨èæé ç®ï¼ä»¥æä¾æ´å¥½çå»ºè­°ãç±æ¼ç¶²è·¯å¹³å°çå¤æ¨£åä»¥åä½¿ç¨èåé ç®çææ¸ç´å¢é·ï¼å·ååæ¨è¦ (CSR) çéè¦æ§æ­£è®å¾è¶ä¾è¶æé¡¯ãåæï¼å¤§åèªè¨æ¨¡å (LLM) å·²åå¾å·¨å¤§çæåï¼ä¸¦å·åå»ºæ¨¡ä½¿ç¨èåé ç®è³è¨çå¼·å¤§è½åï¼çºå·ååæ¨è¦æä¾äºæ°çæ½åãç¶èï¼CSR çç ç©¶ç¤¾ç¾¤å¨éåé åä»ç¶ç¼ºä¹å¨é¢çåé¡§ååæãåºæ¼æ­¤ï¼å¨æ¬æä¸­ï¼æåç«å¨å¤§åèªè¨æ¨¡åçæä»£èæ¯ä¸ï¼å° CSR çè·¯ç·åãç¸éæç»åæªä¾æ¹åæä¾å¨é¢çåé¡§åè¨è«ãå·é«ä¾èªªï¼æåå°ç¾æ CSR å¦ä½å©ç¨è³è¨é²è¡äºæ¢ç´¢ï¼å¾å§å®¹ç¹å¾µãåéä¿åé åè³è¨ï¼å°å¤§åèªè¨æ¨¡åæææçä¸çç¥è­ï¼æ¨å¨çºç ç©¶åç¢æ¥­ç¤¾ç¾¤æä¾ CSR çæ°è¦è§£ãå·ååæ¨è¦çç¸éè³æºå·²æ¶éä¸¦æçºæ´æ°ï¼ä¾ç¤¾ç¾¤å¨ https://github.com/YuanchenBei/Awesome-Cold-Start-Recommendation ä¸­ä½¿ç¨ã

##### **Multimodal Contrastive Representation Learning in Augmented Biomedical Knowledge Graphs**
2501.01644v1 by Tien Dang, Viet Thanh Duy Nguyen, Minh Tuan Le, Truong-Son Hy

Biomedical Knowledge Graphs (BKGs) integrate diverse datasets to elucidate
complex relationships within the biomedical field. Effective link prediction on
these graphs can uncover valuable connections, such as potential novel
drug-disease relations. We introduce a novel multimodal approach that unifies
embeddings from specialized Language Models (LMs) with Graph Contrastive
Learning (GCL) to enhance intra-entity relationships while employing a
Knowledge Graph Embedding (KGE) model to capture inter-entity relationships for
effective link prediction. To address limitations in existing BKGs, we present
PrimeKG++, an enriched knowledge graph incorporating multimodal data, including
biological sequences and textual descriptions for each entity type. By
combining semantic and relational information in a unified representation, our
approach demonstrates strong generalizability, enabling accurate link
predictions even for unseen nodes. Experimental results on PrimeKG++ and the
DrugBank drug-target interaction dataset demonstrate the effectiveness and
robustness of our method across diverse biomedical datasets. Our source code,
pre-trained models, and data are publicly available at
https://github.com/HySonLab/BioMedKG

æè¦ï¼çç©å»å­¦ç¥è­åè­ (BKG) æ´åå¤æ¨£åçè³æéï¼ä»¥é¡æçç©é«å­¸é åå§çè¤ééä¿ãå¨éäºåè­ä¸é²è¡ææçé£çµé æ¸¬ï¼å¯ä»¥ç¼ç¾æå¹å¼çé£çµï¼ä¾å¦æ½å¨çæ°è¥ç©-ç¾çéä¿ãæåå¼å¥äºä¸ç¨®æ°ç©çå¤æ¨¡ææ¹æ³ï¼å®å°ä¾èªå°ç¨èªè¨æ¨¡å (LM) çåµå¥èåå½¢å°æ¯å­¸ç¿ (GCL) çµ±ä¸èµ·ä¾ï¼ä»¥å¢å¼·å¯¦é«å§éä¿ï¼åææ¡ç¨ç¥è­åå½¢åµå¥ (KGE) æ¨¡åä¾ææå¯¦é«ééä¿ï¼ä»¥é²è¡ææçé£çµé æ¸¬ãçºäºè§£æ±ºç¾æ BKG ä¸­çéå¶ï¼æåæåºäº PrimeKG++ï¼éæ¯ä¸åè±å¯çç¥è­åå½¢ï¼å®çµåäºå¤æ¨¡ææ¸æï¼åæ¬æ¯ç¨®é¡åå¯¦é«ççç©åºååæå­æè¿°ãééå¨çµ±ä¸è¡¨ç¤ºä¸­çµåèªç¾©åéä¿è³è¨ï¼æåçåæ³å±ç¤ºäºå¼·å¤§çæ¦æ¬æ§ï¼å³ä½¿å°æ¼æªè¦ç¯é»ä¹è½é²è¡æºç¢ºçé£çµé æ¸¬ãå¨ PrimeKG++ å DrugBank è¥ç©-æ¨é¶äº¤äºä½ç¨è³æéä¸çå¯¦é©çµæè­æäºæåçæ¹æ³å¨åç¨®çç©é«å­¸è³æéä¸­çæææ§åç©©å¥æ§ãæåçåå§ç¢¼ãé è¨ç·´æ¨¡ååè³æå¯å¨ https://github.com/HySonLab/BioMedKG å¬éåå¾ã

##### **Enhancing Uncertainty Modeling with Semantic Graph for Hallucination Detection**
2501.02020v1 by Kedi Chen, Qin Chen, Jie Zhou, Xinqi Tao, Bowen Ding, Jingwen Xie, Mingchen Xie, Peilong Li, Feng Zheng, Liang He

Large Language Models (LLMs) are prone to hallucination with non-factual or
unfaithful statements, which undermines the applications in real-world
scenarios. Recent researches focus on uncertainty-based hallucination
detection, which utilizes the output probability of LLMs for uncertainty
calculation and does not rely on external knowledge or frequent sampling from
LLMs. Whereas, most approaches merely consider the uncertainty of each
independent token, while the intricate semantic relations among tokens and
sentences are not well studied, which limits the detection of hallucination
that spans over multiple tokens and sentences in the passage. In this paper, we
propose a method to enhance uncertainty modeling with semantic graph for
hallucination detection. Specifically, we first construct a semantic graph that
well captures the relations among entity tokens and sentences. Then, we
incorporate the relations between two entities for uncertainty propagation to
enhance sentence-level hallucination detection. Given that hallucination occurs
due to the conflict between sentences, we further present a graph-based
uncertainty calibration method that integrates the contradiction probability of
the sentence with its neighbors in the semantic graph for uncertainty
calculation. Extensive experiments on two datasets show the great advantages of
our proposed approach. In particular, we obtain substantial improvements with
19.78% in passage-level hallucination detection.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å®¹æåºç¾éäºå¯¦æ§æä¸å¿ å¯¦çé³è¿°ï¼éæç ´å£ç¾å¯¦ä¸çå ´æ¯ä¸­çæç¨ãæè¿çç ç©¶éé»éæ³¨åºæ¼ä¸ç¢ºå®æ§çå¹»è¦ºæª¢æ¸¬ï¼å®å©ç¨ LLM çè¼¸åºæ©çé²è¡ä¸ç¢ºå®æ§è¨ç®ï¼ä¸¦ä¸ä¸ä¾è³´æ¼å¤é¨ç¥è­æå¾ LLM ä¸­é »ç¹åæ¨£ãç¶èï¼å¤§å¤æ¸æ¹æ³åèæ®æ¯åç¨ç«ç¬¦èçä¸ç¢ºå®æ§ï¼èç¬¦èåå¥å­ä¹éçè¤éèªç¾©éä¿å°æªå¾å°å¾å¥½çç ç©¶ï¼ééå¶äºå°è·¨è¶æ®µè½ä¸­å¤åç¬¦èåå¥å­çå¹»è¦ºçæª¢æ¸¬ãå¨æ¬æä¸­ï¼æåæåºäºä¸ç¨®ä½¿ç¨èªç¾©åå¢å¼·ä¸ç¢ºå®æ§å»ºæ¨¡ä»¥é²è¡å¹»è¦ºæª¢æ¸¬çæ¹æ³ãå·é«ä¾èªªï¼æåé¦åæ§å»ºä¸åèªç¾©åï¼å®å¾å¥½å°ææäºå¯¦é«ç¬¦èåå¥å­ä¹éçéä¿ãç¶å¾ï¼æåå°å©åå¯¦é«ä¹éçéä¿ç´å¥ä¸ç¢ºå®æ§å³æ­ï¼ä»¥å¢å¼·å¥å­ç´å¥çå¹»è¦ºæª¢æ¸¬ãç±æ¼å¹»è¦ºæ¯å å¥å­ä¹éçè¡çªèç¼ççï¼å æ­¤æåé²ä¸æ­¥æåºäºä¸ç¨®åºæ¼åçä¸ç¢ºå®æ§æ ¡æºæ¹æ³ï¼å®å°å¥å­ççç¾æ©çèå¶å¨èªç¾©åä¸­çé°å±çµåèµ·ä¾é²è¡ä¸ç¢ºå®æ§è¨ç®ãå¨å©åæ¸æéä¸çå»£æ³å¯¦é©é¡¯ç¤ºäºæåæåºçæ¹æ³çå·¨å¤§åªå¢ãç¹å¥æ¯ï¼æåå¨æ®µè½ç´å¥çå¹»è¦ºæª¢æ¸¬ä¸­ç²å¾äº 19.78% çé¡¯èæ¹é²ã

##### **Unfolding the Headline: Iterative Self-Questioning for News Retrieval and Timeline Summarization**
2501.00888v1 by Weiqi Wu, Shen Huang, Yong Jiang, Pengjun Xie, Fei Huang, Hai Zhao

In the fast-changing realm of information, the capacity to construct coherent
timelines from extensive event-related content has become increasingly
significant and challenging. The complexity arises in aggregating related
documents to build a meaningful event graph around a central topic. This paper
proposes CHRONOS - Causal Headline Retrieval for Open-domain News Timeline
SummarizatiOn via Iterative Self-Questioning, which offers a fresh perspective
on the integration of Large Language Models (LLMs) to tackle the task of
Timeline Summarization (TLS). By iteratively reflecting on how events are
linked and posing new questions regarding a specific news topic to gather
information online or from an offline knowledge base, LLMs produce and refresh
chronological summaries based on documents retrieved in each round.
Furthermore, we curate Open-TLS, a novel dataset of timelines on recent news
topics authored by professional journalists to evaluate open-domain TLS where
information overload makes it impossible to find comprehensive relevant
documents from the web. Our experiments indicate that CHRONOS is not only adept
at open-domain timeline summarization, but it also rivals the performance of
existing state-of-the-art systems designed for closed-domain applications,
where a related news corpus is provided for summarization.

æè¦ï¼å¨è³è¨å¿«éè®é·çé åä¸­ï¼å¾å¤§éçäºä»¶ç¸éå§å®¹å»ºæ§é£è²«çæéè»¸çè½åè®å¾è¶ä¾è¶éè¦ä¸å·æææ°æ§ãè¤éæ§å¨æ¼å½ç¸½ç¸éæä»¶ï¼ä»¥åç¹ä¸­å¿ä¸»é¡å»ºç«ææç¾©çäºä»¶åãæ¬ææåºäº CHRONOS - éæ¾é åæ°èæéè»¸æè¦çå ææ¨é¡æª¢ç´¢ï¼ééåè¦èªææåï¼æä¾æ´åå¤§åèªè¨æ¨¡å (LLM) ä¾èçæéè»¸æè¦ (TLS) ä»»åçæ°è§é»ãééåè¦æèäºä»¶å¦ä½é£çµï¼ä¸¦å°ç¹å®æ°èä¸»é¡æåºæ°åé¡ï¼ä»¥å¾ç·ä¸æé¢ç·ç¥è­åº«æ¶éè³è¨ï¼LLM ææ ¹ææ¯è¼ªæª¢ç´¢çæä»¶ç¢çä¸¦æ´æ°æéæè¦ãæ­¤å¤ï¼æåç­åäº Open-TLSï¼ä¸åç±å°æ¥­è¨èç·¨å¯«çè¿ææ°èä¸»é¡æéè»¸çæ°ç©è³æéï¼ä»¥è©ä¼°éæ¾é åç TLSï¼å¶ä¸­è³è¨éè¼ä½¿å¾ç¡æ³å¾ç¶²è·¯ä¸æ¾å°å¨é¢çç¸éæä»¶ãæåçå¯¦é©è¡¨æï¼CHRONOS ä¸åæé·éæ¾é åçæéè»¸æè¦ï¼èä¸éèå°çºå°éé åæç¨è¨­è¨çç¾ææåé²ç³»çµ±çæè½ç¸åª²ç¾ï¼å¶ä¸­æä¾äºç¸éçæ°èèªæåº«ç¨æ¼æè¦ã

##### **Breaking Through the Spike: Spike Window Decoding for Accelerated and Precise Automatic Speech Recognition**
2501.03257v1 by Wei Zhang, Tian-Hao Zhang, Chao Luo, Hui Zhou, Chao Yang, Xinyuan Qian, Xu-Cheng Yin

Recently, end-to-end automatic speech recognition has become the mainstream
approach in both industry and academia. To optimize system performance in
specific scenarios, the Weighted Finite-State Transducer (WFST) is extensively
used to integrate acoustic and language models, leveraging its capacity to
implicitly fuse language models within static graphs, thereby ensuring robust
recognition while also facilitating rapid error correction. However, WFST
necessitates a frame-by-frame search of CTC posterior probabilities through
autoregression, which significantly hampers inference speed. In this work, we
thoroughly investigate the spike property of CTC outputs and further propose
the conjecture that adjacent frames to non-blank spikes carry semantic
information beneficial to the model. Building on this, we propose the Spike
Window Decoding algorithm, which greatly improves the inference speed by making
the number of frames decoded in WFST linearly related to the number of spiking
frames in the CTC output, while guaranteeing the recognition performance. Our
method achieves SOTA recognition accuracy with significantly accelerates
decoding speed, proven across both AISHELL-1 and large-scale In-House datasets,
establishing a pioneering approach for integrating CTC output with WFST.

æè¦ï¼è¿å¹´æ¥ï¼ç«¯å°ç«¯çèªå¨è¯­é³è¯å«å·²æä¸ºå·¥ä¸çåå­¦æ¯ççæµè¡æ¹æ³ãä¸ºäºä¼åç¹å®åºæ¯ä¸­çç³»ç»æ§è½ï¼å ææéç¶æè½¬æ¢å¨ (WFST) è¢«å¹¿æ³ç¨äºéæå£°å­¦åè¯­è¨æ¨¡åï¼å©ç¨å¶å¨éæå¾ä¸­éå¼èåè¯­è¨æ¨¡åçè½åï¼ä»èç¡®ä¿ç¨³å¥çè¯å«ï¼åæ¶ä¿è¿å¿«éçº éãç¶èï¼WFST éè¦éè¿èªåå½éå¸§æç´¢ CTC åéªæ¦çï¼è¿æå¤§å°é»ç¢äºæ¨çéåº¦ãå¨è¿é¡¹å·¥ä½ä¸­ï¼æä»¬å½»åºç ç©¶äº CTC è¾åºçå°å³°ç¹æ§ï¼å¹¶è¿ä¸æ­¥æåºä¸ä¸ªçæ³ï¼å³éç©ºç½å°å³°çç¸é»å¸§æºå¸¦å¯¹æ¨¡åæççè¯­ä¹ä¿¡æ¯ãå¨æ­¤åºç¡ä¸ï¼æä»¬æåºäº Spike Window è§£ç ç®æ³ï¼è¯¥ç®æ³éè¿ä½¿ WFST ä¸­è§£ç çå¸§æ°ä¸ CTC è¾åºä¸­å°å³°å¸§æ°çº¿æ§ç¸å³ï¼åæ¶ä¿è¯è¯å«æ§è½ï¼æå¤§å°æé«äºæ¨çéåº¦ãæä»¬çæ¹æ³å¨ AISHELL-1 åå¤§è§æ¨¡åé¨æ°æ®éä¸é½å®ç°äº SOTA è¯å«åç¡®åº¦ï¼å¹¶æ¾èå å¿«äºè§£ç éåº¦ï¼ä¸ºå° CTC è¾åºä¸ WFST éæå»ºç«äºåé©±æ¹æ³ã

##### **SmartSpatial: Enhancing the 3D Spatial Arrangement Capabilities of Stable Diffusion Models and Introducing a Novel 3D Spatial Evaluation Framework**
2501.01998v1 by Mao Xun Huang, Hen-Hsen Huang

Stable Diffusion models have made remarkable strides in generating
photorealistic images from text prompts but often falter when tasked with
accurately representing complex spatial arrangements, particularly involving
intricate 3D relationships. To address this limitation, we introduce
SmartSpatial, an innovative approach that enhances the spatial arrangement
capabilities of Stable Diffusion models through 3D-aware conditioning and
attention-guided mechanisms. SmartSpatial incorporates depth information and
employs cross-attention control to ensure precise object placement, delivering
notable improvements in spatial accuracy metrics. In conjunction with
SmartSpatial, we present SmartSpatialEval, a comprehensive evaluation framework
designed to assess spatial relationships. This framework utilizes
vision-language models and graph-based dependency parsing for performance
analysis. Experimental results on the COCO and SpatialPrompts datasets show
that SmartSpatial significantly outperforms existing methods, setting new
benchmarks for spatial arrangement accuracy in image generation.

æè¦ï¼Stable Diffusion æ¨¡åå¨æ ¹ææå­æç¤ºçæé¼ççå½±åæ¹é¢åå¾äºé¡¯èé²å±ï¼ä½å¨æºç¢ºåç¾è¤éçç©ºééç½®æï¼ç¹å¥æ¯æ¶åè¤éç 3D éä¿æï¼å¸¸å¸¸æå¤±æãçºäºè§£æ±ºéåéå¶ï¼æåå¼å¥äº SmartSpatialï¼éæ¯ä¸ååµæ°çæ¹æ³ï¼éé 3D æç¥æ¢ä»¶åæ³¨æåå¼å°æ©å¶ï¼å¢å¼· Stable Diffusion æ¨¡åçç©ºééç½®è½åãSmartSpatial çµåæ·±åº¦è³è¨ä¸¦æ¡ç¨äº¤åæ³¨æåæ§å¶ï¼ä»¥ç¢ºä¿ç²¾ç¢ºçç©ä»¶æ¾ç½®ï¼å¨ç©ºéæºç¢ºåº¦ææ¨æ¹é¢å¸¶ä¾é¡¯èçæ¹é²ãçµå SmartSpatialï¼æåæåºäº SmartSpatialEvalï¼éæ¯ä¸åå¨é¢çè©ä¼°æ¶æ§ï¼æ¨å¨è©ä¼°ç©ºééä¿ãéåæ¶æ§å©ç¨è¦è¦ºèªè¨æ¨¡åååºæ¼åå½¢çä¾å­åæé²è¡æè½åæãå¨ COCO å SpatialPrompts è³æéä¸çå¯¦é©çµæé¡¯ç¤ºï¼SmartSpatial æé¡¯åªæ¼ç¾ææ¹æ³ï¼çºå½±åçæçç©ºééç½®æºç¢ºåº¦è¨­å®äºæ°çåºæºã

##### **Causal Graph Guided Steering of LLM Values via Prompts and Sparse Autoencoders**
2501.00581v1 by Yipeng Kang, Junqi Wang, Yexin Li, Fangwei Zhong, Xue Feng, Mengmeng Wang, Wenming Tu, Quansen Wang, Hengli Li, Zilong Zheng

As large language models (LLMs) become increasingly integrated into critical
applications, aligning their behavior with human values presents significant
challenges. Current methods, such as Reinforcement Learning from Human Feedback
(RLHF), often focus on a limited set of values and can be resource-intensive.
Furthermore, the correlation between values has been largely overlooked and
remains underutilized. Our framework addresses this limitation by mining a
causal graph that elucidates the implicit relationships among various values
within the LLMs. Leveraging the causal graph, we implement two lightweight
mechanisms for value steering: prompt template steering and Sparse Autoencoder
feature steering, and analyze the effects of altering one value dimension on
others. Extensive experiments conducted on Gemma-2B-IT and Llama3-8B-IT
demonstrate the effectiveness and controllability of our steering methods.

æè¦ï¼é¨èå¤§åèªè¨æ¨¡å (LLM) æ¥çæ´åå°ééµæç¨ç¨å¼ä¸­ï¼è®å¶è¡çºèäººé¡å¹å¼è§ä¸è´æå¸¶ä¾éå¤§ææ°ãç¾æçæ¹æ³ï¼ä¾å¦äººé¡åé¥å¼·åå­¸ç¿ (RLHF)ï¼éå¸¸å°æ³¨æ¼æéçå¹å¼è§ï¼ä¸å¯è½èè²»å¤§éè³æºãæ­¤å¤ï¼å¹å¼è§ä¹éçéè¯æ§å¨å¾å¤§ç¨åº¦ä¸è¢«å¿½è¦ï¼ä¸æªè¢«ååå©ç¨ãæåçæ¶æ§ééæ¢åå æåè¡¨ä¾è§£æ±ºæ­¤éå¶ï¼è©²åè¡¨é¡æäº LLM ä¸­åç¨®å¹å¼è§ä¹éçé±å«éä¿ãå©ç¨å æåè¡¨ï¼æåå¯¦ä½äºå©ç¨®è¼éç´çå¹å¼å¼å°æ©å¶ï¼æç¤ºç¯æ¬å¼å°åç¨çèªç·¨ç¢¼å¨ç¹å¾µå¼å°ï¼ä¸¦åæäºæ¹è®ä¸åå¹å¼ç¶­åº¦å°å¶ä»ç¶­åº¦çå½±é¿ãå¨ Gemma-2B-IT å Llama3-8B-IT ä¸é²è¡çå»£æ³å¯¦é©è­æäºæåçå¼å°æ¹æ³çæææ§åå¯æ§æ§ã

##### **CancerKG.ORG A Web-scale, Interactive, Verifiable Knowledge Graph-LLM Hybrid for Assisting with Optimal Cancer Treatment and Care**
2501.00223v1 by Michael Gubanov, Anna Pyayt, Aleksandra Karolak

Here, we describe one of the first Web-scale hybrid Knowledge Graph
(KG)-Large Language Model (LLM), populated with the latest peer-reviewed
medical knowledge on colorectal Cancer. It is currently being evaluated to
assist with both medical research and clinical information retrieval tasks at
Moffitt Cancer Center, which is one of the top Cancer centers in the U.S. and
in the world. Our hybrid is remarkable as it serves the user needs better than
just an LLM, KG or a search-engine in isolation. LLMs as is are known to
exhibit hallucinations and catastrophic forgetting as well as are trained on
outdated corpora. The state of the art KGs, such as PrimeKG, cBioPortal,
ChEMBL, NCBI, and other require manual curation, hence are quickly getting
stale. CancerKG is unsupervised and is capable of automatically ingesting and
organizing the latest medical findings. To alleviate the LLMs shortcomings, the
verified KG serves as a Retrieval Augmented Generation (RAG) guardrail.
CancerKG exhibits 5 different advanced user interfaces, each tailored to serve
different data modalities better and more convenient for the user.

æè¦ï¼å¨æ­¤ï¼æä»¬æè¿°äºç¬¬ä¸ä¸ª Web çº§æ··åç¥è¯å¾è°± (KG) - å¤§åè¯­è¨æ¨¡å (LLM)ï¼å¶ä¸­åæ¥çæå³ç»ç´è ççææ°åè¡è¯å®¡å»å­¦ç¥è¯ãç®åæ­£å¨è¯ä¼°å®ä»¥åå© Moffitt ççä¸­å¿è¿è¡å»å­¦ç ç©¶åä¸´åºä¿¡æ¯æ£ç´¢ä»»å¡ï¼è¯¥ä¸­å¿æ¯ç¾å½åä¸çé¡¶çº§ççä¸­å¿ä¹ä¸ãæä»¬çæ··åä½éå¸¸åºè²ï¼å ä¸ºå®æ¯å­¤ç«ç LLMãKG ææç´¢å¼ææ´å¥½å°æ»¡è¶³ç¨æ·éæ±ãä¼æå¨ç¥ï¼LLM ä¼åºç°å¹»è§åç¾é¾æ§éå¿ï¼å¹¶ä¸æ¯å¨è¿æ¶çè¯­æåºä¸è¿è¡è®­ç»çãæåè¿ç KGï¼ä¾å¦ PrimeKGãcBioPortalãChEMBLãNCBI ç­éè¦äººå·¥æ´çï¼å æ­¤å¾å¿«å°±ä¼è¿æ¶ãCancerKG æ éçç£ï¼è½å¤èªå¨æååç»ç»ææ°çå»å­¦åç°ãä¸ºäºåè½» LLM çç¼ºç¹ï¼ç»è¿éªè¯ç KG åå½æ£ç´¢å¢å¼ºçæ (RAG) æ¤æ ãCancerKG å±ç¤ºäº 5 ç§ä¸åçé«çº§ç¨æ·çé¢ï¼æ¯ç§çé¢é½éå¯¹æå¡ä¸åçæ°æ®æ¨¡å¼ï¼ä¸ºç¨æ·æä¾æ´å¥½ãæ´æ¹ä¾¿çæå¡ã

##### **The Potential of LLMs in Automating Software Testing: From Generation to Reporting**
2501.00217v1 by Betim Sherifi, Khaled Slhoub, Fitzroy Nembhard

Having a high quality software is essential in software engineering, which
requires robust validation and verification processes during testing
activities. Manual testing, while effective, can be time consuming and costly,
leading to an increased demand for automated methods. Recent advancements in
Large Language Models (LLMs) have significantly influenced software
engineering, particularly in areas like requirements analysis, test automation,
and debugging. This paper explores an agent-oriented approach to automated
software testing, using LLMs to reduce human intervention and enhance testing
efficiency. The proposed framework integrates LLMs to generate unit tests,
visualize call graphs, and automate test execution and reporting. Evaluations
across multiple applications in Python and Java demonstrate the system's high
test coverage and efficient operation. This research underscores the potential
of LLM-powered agents to streamline software testing workflows while addressing
challenges in scalability and accuracy.

æè¦ï¼å¨è»é«å·¥ç¨ä¸­ï¼ææé«åè³ªçè»é«è³ééè¦ï¼ééè¦å¨æ¸¬è©¦æ´»åä¸­é²è¡å¼·å¥çé©è­åé©è­ç¨åºãæåæ¸¬è©¦éç¶ææï¼ä½å¯è½èæä¸ææ¬é«æï¼å°è´å°èªååæ¹æ³çéæ±å¢å ãå¤§åèªè¨æ¨¡å (LLM) çææ°é²å±é¡¯èå½±é¿äºè»é«å·¥ç¨ï¼ç¹å¥æ¯å¨éæ±åæãæ¸¬è©¦èªåååé¤é¯ç­é åãæ¬ææ¢è¨äºä¸ç¨®é¢åä»£ççèªååè»é«æ¸¬è©¦æ¹æ³ï¼ä½¿ç¨ LLM ä¾æ¸å°äººå·¥å¹²é ä¸¦æé«æ¸¬è©¦æçãææåºçæ¡æ¶æ´åäº LLM ä¾ç¢çå®åæ¸¬è©¦ãè¦è¦ºåå¼å«åè¡¨ä»¥åèªååæ¸¬è©¦å·è¡åå ±åãå¨ Python å Java ä¸­çè·¨å¤åæç¨ç¨å¼çè©ä¼°è­æäºç³»çµ±çé«æ¸¬è©¦è¦èçåé«æéä½ãéé ç ç©¶å¼·èª¿äº LLM é©åçä»£çå¨ç°¡åè»é«æ¸¬è©¦å·¥ä½æµç¨æ¹é¢çæ½åï¼åææå°å¯æ´åæ§åæºç¢ºæ§æ¹é¢çææ°ã

##### **Detection-Fusion for Knowledge Graph Extraction from Videos**
2501.00136v1 by Taniya Das, Louis Mahon, Thomas Lukasiewicz

One of the challenging tasks in the field of video understanding is
extracting semantic content from video inputs. Most existing systems use
language models to describe videos in natural language sentences, but this has
several major shortcomings. Such systems can rely too heavily on the language
model component and base their output on statistical regularities in natural
language text rather than on the visual contents of the video. Additionally,
natural language annotations cannot be readily processed by a computer, are
difficult to evaluate with performance metrics and cannot be easily translated
into a different natural language. In this paper, we propose a method to
annotate videos with knowledge graphs, and so avoid these problems.
Specifically, we propose a deep-learning-based model for this task that first
predicts pairs of individuals and then the relations between them.
Additionally, we propose an extension of our model for the inclusion of
background knowledge in the construction of knowledge graphs.

æè¦ï¼å½±ççè§£é åä¸­ä¸é å·æææ°æ§çä»»åï¼æ¯å¾å½±çè¼¸å¥ä¸­èåèªæå§å®¹ãç¾æçå¤§é¨åç³»çµ±ä½¿ç¨èªè¨æ¨¡åä»¥èªç¶èªè¨å¥å­æè¿°å½±çï¼ä½éæå¹¾åä¸»è¦çç¼ºé»ãæ­¤é¡ç³»çµ±å¯è½éåº¦ä¾è³´èªè¨æ¨¡åçµä»¶ï¼ä¸¦æ ¹æèªç¶èªè¨æå­ä¸­ççµ±è¨è¦å¾ï¼èéå½±ççè¦è¦ºå§å®¹ï¼ä¾å»ºæ§å¶è¼¸åºãæ­¤å¤ï¼èªç¶èªè¨è¨»è§£ç¡æ³è¼æå°ç±é»è¦èçï¼é£ä»¥ä½¿ç¨æè½ææ¨é²è¡è©ä¼°ï¼ä¸ç¡æ³è¼æç¿»è­¯æä¸åçèªç¶èªè¨ãå¨æ¬æä¸­ï¼æåæåºä¸åä½¿ç¨ç¥è­åè¡¨çºå½±çå ä¸è¨»è§£çæ¹æ³ï¼ä¸¦èæ­¤é¿åéäºåé¡ãå·é«ä¾èªªï¼æåæåºä¸ååºæ¼æ·±åº¦å­¸ç¿çæ¨¡åä¾å·è¡éé ä»»åï¼å®æåé æ¸¬åé«å°ï¼ç¶å¾åé æ¸¬åé«ä¹éçéä¿ãæ­¤å¤ï¼æåæåºä¸åæ¨¡åå»¶ä¼¸ï¼ä»¥å°èæ¯ç¥è­ç´å¥ç¥è­åè¡¨çå»ºæ§ä¸­ã

##### **Machine Learning-Based Security Policy Analysis**
2501.00085v2 by Krish Jain, Joann Sum, Pranav Kapoor, Amir Eaman

Security-Enhanced Linux (SELinux) is a robust security mechanism that
enforces mandatory access controls (MAC), but its policy language's complexity
creates challenges for policy analysis and management. This research
investigates the automation of SELinux policy analysis using graph-based
techniques combined with machine learning approaches to detect policy
anomalies. The study addresses two key questions: Can SELinux policy analysis
be automated through graph analysis, and how do different anomaly detection
models compare in analyzing SELinux policies? We will be comparing different
machine learning models by evaluating their effectiveness in detecting policy
violations and anomalies. Our approach utilizes Neo4j for graph representation
of policies, with Node2vec transforming these graph structures into meaningful
vector embeddings that can be processed by our machine learning models. In our
results, the MLP Neural Network consistently demonstrated superior performance
across different dataset sizes, achieving 95% accuracy with balanced precision
and recall metrics, while both Random Forest and SVM models showed competitive
but slightly lower performance in detecting policy violations. This combination
of graph-based modeling and machine learning provides a more sophisticated and
automated approach to understanding and analyzing complex SELinux policies
compared to traditional manual analysis methods.

æè¦ï¼SELinuxï¼å®å¨å¼·åå Linuxï¼æ¯ä¸ç¨®å¼·å¤§çå®å¨æ©å¶ï¼å®å¼·å¶å·è¡å¼·å¶è¨ªåæ§å¶ (MAC)ï¼ä½å¶æ¿ç­èªè¨çè¤éæ§å°æ¿ç­åæåç®¡çæåºäºææ°ãæ¬ç ç©¶æ¢è¨äºä½¿ç¨åºæ¼åå½¢æè¡çµåæ©å¨å­¸ç¿æ¹æ³ä¾èªåå SELinux æ¿ç­åæï¼ä»¥æª¢æ¸¬æ¿ç­ç°å¸¸ãæ¬ç ç©¶è§£æ±ºäºå©åééµåé¡ï¼æ¯å¦è½ééåå½¢åæèªåå SELinux æ¿ç­åæï¼ä»¥åä¸åçç°å¸¸æª¢æ¸¬æ¨¡åå¨åæ SELinux æ¿ç­ææä½æ¯è¼ï¼æåå°æ¯è¼ä¸åçæ©å¨å­¸ç¿æ¨¡åï¼è©ä¼°å®åå¨æª¢æ¸¬æ¿ç­éè¦åç°å¸¸æ¹é¢çæææ§ãæåçåæ³å©ç¨ Neo4j é²è¡æ¿ç­çåå½¢è¡¨ç¤ºï¼Node2vec å°éäºåå½¢çµæ§è½ææææç¾©çåéåµå¥ï¼æåçæ©å¨å­¸ç¿æ¨¡åå¯ä»¥èçéäºåµå¥ãå¨æåççµæä¸­ï¼MLP ç¥ç¶ç¶²è·¯å¨ä¸åçè³æéå¤§å°ä¸­å§çµè¡¨ç¾åºåªç°çæè½ï¼å¨å¹³è¡¡çæºç¢ºåº¦ãç²¾ç¢ºåº¦åå¬åçææ¨ä¸éå° 95% çæºç¢ºåº¦ï¼èé¨æ©æ£®æå SVM æ¨¡åå¨æª¢æ¸¬æ¿ç­éè¦æ¹é¢è¡¨ç¾åºç«¶ç­åï¼ä½æè½ç¥ä½ãéç¨®åºæ¼åå½¢å»ºæ¨¡åæ©å¨å­¸ç¿ççµåæä¾äºä¸åæ´ç²¾ç·»ä¸èªååçæ¹å¼ï¼èå³çµ±çæååææ¹æ³ç¸æ¯ï¼å¯ä»¥çè§£ååæè¤éç SELinux æ¿ç­ã

##### **KARPA: A Training-free Method of Adapting Knowledge Graph as References for Large Language Model's Reasoning Path Aggregation**
2412.20995v1 by Siyuan Fang, Kaijing Ma, Tianyu Zheng, Xinrun Du, Ningxuan Lu, Ge Zhang, Qingkun Tang

Large language models (LLMs) demonstrate exceptional performance across a
variety of tasks, yet they are often affected by hallucinations and the
timeliness of knowledge. Leveraging knowledge graphs (KGs) as external
knowledge sources has emerged as a viable solution, but existing methods for
LLM-based knowledge graph question answering (KGQA) are often limited by
step-by-step decision-making on KGs, restricting the global planning and
reasoning capabilities of LLMs, or they require fine-tuning or pre-training on
specific KGs. To address these challenges, we propose Knowledge graph Assisted
Reasoning Path Aggregation (KARPA), a novel framework that harnesses the global
planning abilities of LLMs for efficient and accurate KG reasoning. KARPA
operates in three steps: pre-planning relation paths using the LLM's global
planning capabilities, matching semantically relevant paths via an embedding
model, and reasoning over these paths to generate answers. Unlike existing KGQA
methods, KARPA avoids stepwise traversal, requires no additional training, and
is adaptable to various LLM architectures. Extensive experimental results show
that KARPA achieves state-of-the-art performance in KGQA tasks, delivering both
high efficiency and accuracy. Our code will be available on Github.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨åç¨®ä»»åä¸­è¡¨ç¾åºè²çè¡¨ç¾ï¼ä½å®åç¶å¸¸åå°å¹»è¦ºåç¥è­æææ§çå½±é¿ãå©ç¨ç¥è­åè­ (KG) ä½çºå¤é¨ç¥è­ä¾æºå·²æçºä¸åå¯è¡çè§£æ±ºæ¹æ¡ï¼ä½ç¾æç LLM åºæ¼ç¥è­åè­åç­ (KGQA) çæ¹æ³éå¸¸åå° KG ä¸éæ­¥æ±ºç­çéå¶ï¼éå¶äº LLM çå¨å±è¦ååæ¨çè½åï¼æèå®åéè¦éå°ç¹å® KG é²è¡å¾®èª¿æé è¨ç·´ãçºäºæå°éäºææ°ï¼æåæåºäºç¥è­åè­è¼å©æ¨çè·¯å¾èå (KARPA)ï¼éæ¯ä¸åæ°ç©çæ¡æ¶ï¼å©ç¨ LLM çå¨å±è¦åè½åé²è¡é«æä¸æºç¢ºç KG æ¨çãKARPA åä¸æ­¥æä½ï¼ä½¿ç¨ LLM çå¨å±è¦åè½åé åè¦åéä¿è·¯å¾ãééåµå¥æ¨¡åå¹éèªç¾©ç¸éè·¯å¾ï¼ä»¥åæ¨çéäºè·¯å¾ä»¥ç¢çç­æ¡ãèç¾æç KGQA æ¹æ³ä¸åï¼KARPA é¿åéæ­¥éæ­·ï¼ä¸éè¦é¡å¤çè¨ç·´ï¼ä¸¦ä¸å¯ä»¥é©æåç¨® LLM æ¶æ§ãå¤§éçå¯¦é©çµæè¡¨æï¼KARPA å¨ KGQA ä»»åä¸­å¯¦ç¾äºæåé²çæ§è½ï¼æ¢æä¾äºé«æçåæä¾äºé«æºç¢ºåº¦ãæåçç¨å¼ç¢¼å°å¨ Github ä¸æä¾ã

##### **Ontology-grounded Automatic Knowledge Graph Construction by LLM under Wikidata schema**
2412.20942v1 by Xiaohan Feng, Xixin Wu, Helen Meng

We propose an ontology-grounded approach to Knowledge Graph (KG) construction
using Large Language Models (LLMs) on a knowledge base. An ontology is authored
by generating Competency Questions (CQ) on knowledge base to discover knowledge
scope, extracting relations from CQs, and attempt to replace equivalent
relations by their counterpart in Wikidata. To ensure consistency and
interpretability in the resulting KG, we ground generation of KG with the
authored ontology based on extracted relations. Evaluation on benchmark
datasets demonstrates competitive performance in knowledge graph construction
task. Our work presents a promising direction for scalable KG construction
pipeline with minimal human intervention, that yields high quality and
human-interpretable KGs, which are interoperable with Wikidata semantics for
potential knowledge base expansion.

æè¦ï¼æåæåºä¸åä»¥æ¬ä½çºåºç¤çæ¹æ³ä¾å»ºæ§ç¥è­åè­ï¼KGï¼ï¼æ¹æ³æ¯ä½¿ç¨å¤§åèªè¨æ¨¡åï¼LLMï¼å¨ç¥è­åº«ä¸ãæ¬ä½æ¯ç±å¨ç¥è­åº«ä¸ç¢çè½ååé¡ï¼CQï¼ä¾ç¼ç¾ç¥è­ç¯åï¼å¾ CQ ä¸­æåéä¿ï¼ä¸¦åè©¦ç¨ Wikidata ä¸­çå°æéä¿æ¿æç­æéä¿èç·¨å¯«çãçºäºç¢ºä¿çµæ KG çä¸è´æ§åå¯è§£éæ§ï¼æåæ ¹ææåçéä¿ï¼ä»¥ç·¨å¯«çæ¬ä½çºåºç¤ä¾å»ºç« KG çç¢çãå¨åºæºè³æéä¸çè©ä¼°é¡¯ç¤ºå¨ç¥è­åè­å»ºæ§ä»»åä¸­æç«¶ç­åçæè½ãæåçç ç©¶æåºäºä¸åæå¸æçæ¹åï¼å¯ä»¥ééæ¥µå°çäººå·¥ä»å¥ä¾å»ºæ§å¯æ´åç KG ç®¡ç·ï¼ç¢çé«åè³ªä¸äººé¡å¯è§£éç KGï¼éäº KG è Wikidata èªç¾©å¯ä»¥äºéï¼ä»¥æ´åæ½å¨çç¥è­åº«ã

##### **ICLR: In-Context Learning of Representations**
2501.00070v1 by Core Francisco Park, Andrew Lee, Ekdeep Singh Lubana, Yongyi Yang, Maya Okawa, Kento Nishi, Martin Wattenberg, Hidenori Tanaka

Recent work has demonstrated that semantics specified by pretraining data
influence how representations of different concepts are organized in a large
language model (LLM). However, given the open-ended nature of LLMs, e.g., their
ability to in-context learn, we can ask whether models alter these pretraining
semantics to adopt alternative, context-specified ones. Specifically, if we
provide in-context exemplars wherein a concept plays a different role than what
the pretraining data suggests, do models reorganize their representations in
accordance with these novel semantics? To answer this question, we take
inspiration from the theory of conceptual role semantics and define a toy
"graph tracing" task wherein the nodes of the graph are referenced via concepts
seen during training (e.g., apple, bird, etc.) and the connectivity of the
graph is defined via some predefined structure (e.g., a square grid). Given
exemplars that indicate traces of random walks on the graph, we analyze
intermediate representations of the model and find that as the amount of
context is scaled, there is a sudden re-organization from pretrained semantic
representations to in-context representations aligned with the graph structure.
Further, we find that when reference concepts have correlations in their
semantics (e.g., Monday, Tuesday, etc.), the context-specified graph structure
is still present in the representations, but is unable to dominate the
pretrained structure. To explain these results, we analogize our task to energy
minimization for a predefined graph topology, providing evidence towards an
implicit optimization process to infer context-specified semantics. Overall,
our findings indicate scaling context-size can flexibly re-organize model
representations, possibly unlocking novel capabilities.

æè¦ï¼<paragraph>æè¿çç ç©¶è¡¨æï¼ç±é¢è®­ç»æ°æ®æå®çè¯­ä¹ä¼å½±åå¤§åè¯­è¨æ¨¡å (LLM) ä¸­ä¸åæ¦å¿µçè¡¨å¾ç»ç»æ¹å¼ãç¶èï¼é´äº LLM çå¼æ¾å¼æ¬è´¨ï¼ä¾å¦å®ä»¬å¨è¯­å¢ä¸­å­¦ä¹ çè½åï¼æä»¬å¯ä»¥è¯¢é®æ¨¡åæ¯å¦ä¼æ¹åè¿äºé¢è®­ç»è¯­ä¹ä»¥éç¨æ¿ä»£çãè¯­å¢æå®çè¯­ä¹ãå·ä½æ¥è¯´ï¼å¦ææä»¬å¨è¯­å¢ä¸­æä¾ç¤ºä¾ï¼å¶ä¸­ä¸ä¸ªæ¦å¿µæ®æ¼çè§è²ä¸é¢è®­ç»æ°æ®ææç¤ºçä¸åï¼æ¨¡åæ¯å¦ä¼æ ¹æ®è¿äºæ°è¯­ä¹éæ°ç»ç»å®ä»¬çè¡¨å¾ï¼ä¸ºäºåç­è¿ä¸ªé®é¢ï¼æä»¬ä»æ¦å¿µè§è²è¯­ä¹çè®ºä¸­æ±²åçµæï¼å¹¶å®ä¹äºä¸ä¸ªç©å·âå¾ç¤ºè¿½è¸ªâä»»å¡ï¼å¶ä¸­å¾çèç¹éè¿è®­ç»æé´çå°çæ¦å¿µï¼ä¾å¦ï¼è¹æãé¸ç­ï¼è¿è¡å¼ç¨ï¼å¹¶ä¸å¾çè¿éæ§æ¯éè¿ä¸äºé¢å®ä¹çç»æï¼ä¾å¦ï¼æ­£æ¹å½¢ç½æ ¼ï¼å®ä¹çãç»å®æç¤ºå¨å¾ä¸éæºæ¸¸èµ°çè½¨è¿¹çç¤ºä¾ï¼æä»¬åæäºæ¨¡åçä¸­é´è¡¨å¾ï¼åç°éçè¯­å¢éçå¢å ï¼ä»é¢è®­ç»è¯­ä¹è¡¨å¾å°ä¸å¾ç»æå¯¹é½çè¯­å¢è¡¨å¾çªç¶åçäºéæ°ç»ç»ãæ­¤å¤ï¼æä»¬åç°å½åèæ¦å¿µå¨å¶è¯­ä¹ä¸­å·æç¸å³æ§ï¼ä¾å¦ï¼ææä¸ãææäºç­ï¼æ¶ï¼è¯­å¢æå®çå¾ç»æä»ç¶å­å¨äºè¡¨å¾ä¸­ï¼ä½æ æ³æ¯éé¢è®­ç»ç»æãä¸ºäºè§£éè¿äºç»æï¼æä»¬å°æä»¬çä»»å¡ç±»æ¯ä¸ºé¢å®ä¹å¾ææçè½éæå°åï¼ä¸ºæ¨æ­è¯­å¢æå®è¯­ä¹çéå¼ä¼åè¿ç¨æä¾äºè¯æ®ãæ»ä½èè¨ï¼æä»¬çç ç©¶ç»æè¡¨æï¼æ©å±è¯­å¢å¤§å°å¯ä»¥çµæ´»å°éæ°ç»ç»æ¨¡åè¡¨å¾ï¼æå¯è½è§£éæ°çåè½ã</paragraph>

##### **Topic-Aware Knowledge Graph with Large Language Models for Interoperability in Recommender Systems**
2412.20163v2 by Minhye Jeon, Seokho Ahn, Young-Duk Seo

The use of knowledge graphs in recommender systems has become one of the
common approaches to addressing data sparsity and cold start problems. Recent
advances in large language models (LLMs) offer new possibilities for processing
side and context information within knowledge graphs. However, consistent
integration across various systems remains challenging due to the need for
domain expert intervention and differences in system characteristics. To
address these issues, we propose a consistent approach that extracts both
general and specific topics from both side and context information using LLMs.
First, general topics are iteratively extracted and updated from side
information. Then, specific topics are extracted using context information.
Finally, to address synonymous topics generated during the specific topic
extraction process, a refining algorithm processes and resolves these issues
effectively. This approach allows general topics to capture broad knowledge
across diverse item characteristics, while specific topics emphasize detailed
attributes, providing a more comprehensive understanding of the semantic
features of items and the preferences of users. Experimental results
demonstrate significant improvements in recommendation performance across
diverse knowledge graphs.

æè¦ï¼ç¥è­åè­å¨æ¨è¦ç³»çµ±ä¸­çä½¿ç¨å·²æçºè§£æ±ºè³æç¨çæ§åå·åååé¡çå¸¸è¦æ¹æ³ä¹ä¸ãå¤§åèªè¨æ¨¡å (LLM) çææ°é²å±çºèçç¥è­åè­ä¸­çå´éåèæ¯è³è¨æä¾äºæ°çå¯è½æ§ãç¶èï¼ç±æ¼éè¦é åå°å®¶çä»å¥ä»¥åç³»çµ±ç¹æ§çå·®ç°ï¼è·¨åç¨®ç³»çµ±çä¸è´æ´åä»ç¶å·æææ°æ§ãçºäºè§£æ±ºéäºåé¡ï¼æåæåºäºä¸ç¨®ä¸è´çæ¹æ³ï¼å®ä½¿ç¨ LLM å¾å´éåèæ¯è³è¨ä¸­æåä¸è¬åç¹å®ä¸»é¡ãé¦åï¼å¾å´éè³è¨ä¸­åè¦æååæ´æ°ä¸è¬ä¸»é¡ãç¶å¾ï¼ä½¿ç¨èæ¯è³è¨æåç¹å®ä¸»é¡ãæå¾ï¼çºäºèçå¨ç¹å®ä¸»é¡æåéç¨ä¸­ç¢ççåç¾©ä¸»é¡ï¼ä¸ç¨®ç²¾çæ¼ç®æ³ææå°èçä¸¦è§£æ±ºäºéäºåé¡ãéç¨®æ¹æ³åè¨±ä¸è¬ä¸»é¡æ·ååç¨®é ç®ç¹æ§çå»£æ³ç¥è­ï¼èç¹å®ä¸»é¡åå¼·èª¿è©³ç´°å±¬æ§ï¼å¾èæ´å¨é¢å°äºè§£é ç®çèªç¾©ç¹å¾µåä½¿ç¨èçåå¥½ãå¯¦é©çµæè¡¨æï¼å¨åç¨®ç¥è­åè­ä¸­ï¼æ¨è¦æè½é½æé¡¯èçæåã

##### **From Generalist to Specialist: A Survey of Large Language Models for Chemistry**
2412.19994v1 by Yang Han, Ziping Wan, Lu Chen, Kai Yu, Xin Chen

Large Language Models (LLMs) have significantly transformed our daily life
and established a new paradigm in natural language processing (NLP). However,
the predominant pretraining of LLMs on extensive web-based texts remains
insufficient for advanced scientific discovery, particularly in chemistry. The
scarcity of specialized chemistry data, coupled with the complexity of
multi-modal data such as 2D graph, 3D structure and spectrum, present distinct
challenges. Although several studies have reviewed Pretrained Language Models
(PLMs) in chemistry, there is a conspicuous absence of a systematic survey
specifically focused on chemistry-oriented LLMs. In this paper, we outline
methodologies for incorporating domain-specific chemistry knowledge and
multi-modal information into LLMs, we also conceptualize chemistry LLMs as
agents using chemistry tools and investigate their potential to accelerate
scientific research. Additionally, we conclude the existing benchmarks to
evaluate chemistry ability of LLMs. Finally, we critically examine the current
challenges and identify promising directions for future research. Through this
comprehensive survey, we aim to assist researchers in staying at the forefront
of developments in chemistry LLMs and to inspire innovative applications in the
field.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²é¡¯èæ¹è®æåçæ¥å¸¸çæ´»ï¼ä¸¦å¨èªç¶èªè¨èç (NLP) ä¸­å»ºç«äºä¸åæ°çå¸ç¯ãç¶èï¼LLM å¨å»£æ³çåºæ¼ç¶²è·¯çææ¬ä¸é²è¡ççè¡é è¨ç·´å°æ¼åé²çç§å­¸ç¼ç¾ä»ç¶ä¸è¶³ï¼ç¹å¥æ¯å¨åå­¸é åãå°æ¥­åå­¸æ¸æçç¨ç¼ºï¼å ä¸ 2D åå½¢ã3D çµæ§ååè­ç­å¤æ¨¡ææ¸æçè¤éæ§ï¼æåºäºä¸åçææ°ãåç®¡ä¸äºç ç©¶åé¡§äºåå­¸ä¸­çé è¨ç·´èªè¨æ¨¡å (PLM)ï¼ä½é¡¯èç¼ºä¹å°æ³¨æ¼ä»¥åå­¸çºå°åç LLM çç³»çµ±æ§èª¿æ¥ãå¨æ¬æä¸­ï¼æåæ¦è¿°äºå°ç¹å®é åçåå­¸ç¥è­åå¤æ¨¡æè³è¨ç´å¥ LLM çæ¹æ³ï¼æåéå°åå­¸ LLM æ¦å¿µåçºä½¿ç¨åå­¸å·¥å·çä»£çï¼ä¸¦ç ç©¶å®åå éç§å­¸ç ç©¶çæ½åãæ­¤å¤ï¼æåç¸½çµäºç¾æçåºæºä¾è©ä¼° LLM çåå­¸è½åãæå¾ï¼æåæ¹å¤æ§å°å¯©æ¥äºç¶åçææ°ï¼ä¸¦ç¢ºå®äºæªä¾ç ç©¶çæå¸æçæ¹åãéééé å¨é¢çèª¿æ¥ï¼æåæ¨å¨åå©ç ç©¶äººå¡ææ¡åå­¸ LLM ç¼å±çæåæ²¿ï¼ä¸¦æ¿ç¼è©²é åçåµæ°æç¨ã

##### **Toward Adaptive Reasoning in Large Language Models with Thought Rollback**
2412.19707v1 by Sijia Chen, Baochun Li

Large language models (LLMs) have been routinely used to solve various tasks
using step-by-step reasoning. However, the structure of intermediate reasoning
steps, or thoughts, is rigid and unidirectional, such as chains, trees, or
acyclic-directed graphs. Consequently, the resulting inflexible and
forward-only reasoning may not address challenging tasks and fail when the LLM
frequently gives false responses, i.e., ``hallucinations''. This paper proposes
a new reasoning framework, called Thought Rollback (TR), allowing LLMs to
adaptively build thought structure while maintaining effective reasoning toward
problem-solving under ``hallucinations''. The core mechanism of TR is rolling
back thoughts, which allows LLMs to perform error analysis on thoughts, and
thus roll back to any previously mistaken thought for revision. Subsequently,
by including such trial-and-error in the prompt to guide the LLM, each rollback
leads to one more reliable reasoning path. Therefore, starting with a simple
prompt without human annotations, LLM with TR adaptively and gradually explores
thoughts for a correct solution. Comprehensive experiments on mathematical
problems and multi-task reasoning demonstrate the state-of-the-art performance
of TR in terms of problem-solving rate and interaction cost. For instance, the
solving rate of GPT-4 with TR outperforms the current best by $9\%$ on the MATH
dataset.

æè¦ï¼å¤§åèªè¨æ¨¡åï¼LLMï¼å·²å¸¸è¦ç¨æ¼è§£æ±ºåç¨®ä»»åï¼ä½¿ç¨éæ­¥æ¨çãç¶èï¼ä¸­éæ¨çæ­¥é©ææ³æ³ççµæ§æ¯åµåä¸å®åçï¼ä¾å¦éãæ¨¹æç¡ç°æååãå æ­¤ï¼ç¢ççåµåä¸åååæ¨çå¯è½ç¡æ³è§£æ±ºå·æææ°æ§çä»»åï¼ä¸¦ä¸ç¶ LLM é »ç¹çµ¦åºé¯èª¤çåæï¼å³ãå¹»è¦ºãï¼ææå¤±æãæ¬ææåºäºä¸åæ°çæ¨çæ¡æ¶ï¼ç¨±çº Thought Rollbackï¼TRï¼ï¼åè¨± LLM å¨è§£æ±ºãå¹»è¦ºãåé¡æèªé©æå°æ§å»ºææ³çµæ§ï¼åæä¿æææçæ¨çãTR çæ ¸å¿æ©å¶æ¯åæ»¾ææ³ï¼å®åè¨± LLM å°ææ³å·è¡é¯èª¤åæï¼ä¸¦å æ­¤åæ»¾å°ä»»ä½ååé¯èª¤çææ³é²è¡ä¿®æ¹ãé¨å¾ï¼ééå¨æç¤ºä¸­åå«æ­¤é¡è©¦é¯ä¾æå° LLMï¼æ¯æ¬¡åæ»¾é½æå°è´ä¸æ¢æ´å¯é çæ¨çè·¯å¾ãå æ­¤ï¼å¾ä¸åæ²æäººå·¥è¨»éçç°¡å®æç¤ºéå§ï¼å¸¶æ TR ç LLM èªé©æå°éæ¼¸æ¢ç´¢ææ³ä»¥ç²å¾æ­£ç¢ºçè§£æ±ºæ¹æ¡ãå¨æ¸å­¸åé¡åå¤ä»»åæ¨çä¸çç¶åå¯¦é©è­æäº TR å¨åé¡è§£æ±ºçåäº¤äºææ¬æ¹é¢çæåé²æ§è½ãä¾å¦ï¼å¸¶æ TR ç GPT-4 çæ±è§£çå¨ MATH æ¸æéä¸æ¯ç®åçæä½³æ§è½é«åº 9%ã

##### **Dynamic Skill Adaptation for Large Language Models**
2412.19361v1 by Jiaao Chen, Diyi Yang

We present Dynamic Skill Adaptation (DSA), an adaptive and dynamic framework
to adapt novel and complex skills to Large Language Models (LLMs). Compared
with previous work which learns from human-curated and static data in random
orders, we propose to first automatically generate and organize the training
data by mimicking the learning pathways of human and then dynamically tailor
the training data based on the training dynamics. Specifically, inspired by the
learning structures and teaching strategies in the human education system, we
first construct a skill graph by decomposing complex skills into sub-skills and
arranging them based on their dependencies in human syllables. For every skill,
we utilize LLMs to generate both textbook-like data which contains detailed
descriptions of skills for pre-training and exercise-like data which targets at
explicitly utilizing the skills to solve problems for instruction-tuning.
Furthermore, during the instruction-tuning, we dynamically update the training
data which down-weight easy-to-learn examples, generate more complex examples,
and filter out data with errors. Experiments on large language models such as
LLAMA and Mistral demonstrate the effectiveness of our proposed methods in
adapting math reasoning skills and social study skills.

æè¦ï¼æåæåºåææè½é©æ (DSA)ï¼ä¸ç¨®é©ææ§ååææ¡æ¶ï¼ç¨æ¼å°æ°ç©ä¸è¤éçæè½é©æå°å¤§åèªè¨æ¨¡å (LLM)ãèååå¾äººé¡ç­ååéæè³æä¸­ä»¥é¨æ©é åºå­¸ç¿çå·¥ä½ç¸æ¯ï¼æåå»ºè­°é¦åééæ¨¡æ¬äººé¡çå­¸ç¿è·¯å¾èªåç¢çåçµç¹è¨ç·´è³æï¼ç¶å¾æ ¹æè¨ç·´åæåæèª¿æ´è¨ç·´è³æãå·é«ä¾èªªï¼åå°äººé¡æè²ç³»çµ±ä¸­çå­¸ç¿çµæ§åæå­¸ç­ç¥çåç¼ï¼æåé¦åééå°è¤éæè½åè§£æå­æè½ä¸¦æ ¹æå®åå¨äººé¡é³ç¯ä¸­çä¾è³´æ§ä¾æåå®åä¾æ§å»ºæè½åãå°æ¼æ¯é æè½ï¼æåå©ç¨ LLM ç¢çé¡ä¼¼æç§æ¸çè³æï¼å¶ä¸­åå«æè½çè©³ç´°æè¿°ï¼ç¨æ¼é è¨ç·´åç·´ç¿é¡åçè³æï¼å¶ç®æ¨æ¯æç¢ºå©ç¨æè½è§£æ±ºåé¡ï¼ä»¥é²è¡æä»¤èª¿æ´ãæ­¤å¤ï¼å¨æä»¤èª¿æ´æéï¼æåæåææ´æ°è¨ç·´è³æï¼å¶ä¸­æéä½ææ¼å­¸ç¿ç¯ä¾çæ¬éãç¢çæ´è¤éçç¯ä¾ï¼ä¸¦éæ¿¾ææé¯èª¤çè³æãå¨ LLAMA å Mistral ç­å¤§åèªè¨æ¨¡åä¸é²è¡çå¯¦é©è­æäºæåæåºçæ¹æ³å¨é©ææ¸å­¸æ¨çæè½åç¤¾æç ç©¶æè½æ¹é¢çæææ§ã

##### **Relation-aware Hierarchical Prompt for Open-vocabulary Scene Graph Generation**
2412.19021v1 by Tao Liu, Rongjie Li, Chongyu Wang, Xuming He

Open-vocabulary Scene Graph Generation (OV-SGG) overcomes the limitations of
the closed-set assumption by aligning visual relationship representations with
open-vocabulary textual representations. This enables the identification of
novel visual relationships, making it applicable to real-world scenarios with
diverse relationships. However, existing OV-SGG methods are constrained by
fixed text representations, limiting diversity and accuracy in image-text
alignment. To address these challenges, we propose the Relation-Aware
Hierarchical Prompting (RAHP) framework, which enhances text representation by
integrating subject-object and region-specific relation information. Our
approach utilizes entity clustering to address the complexity of relation
triplet categories, enabling the effective integration of subject-object
information. Additionally, we utilize a large language model (LLM) to generate
detailed region-aware prompts, capturing fine-grained visual interactions and
improving alignment between visual and textual modalities. RAHP also introduces
a dynamic selection mechanism within Vision-Language Models (VLMs), which
adaptively selects relevant text prompts based on the visual content, reducing
noise from irrelevant prompts. Extensive experiments on the Visual Genome and
Open Images v6 datasets demonstrate that our framework consistently achieves
state-of-the-art performance, demonstrating its effectiveness in addressing the
challenges of open-vocabulary scene graph generation.

æè¦ï¼éæ¾è©å½å ´æ¯åçæ (OV-SGG) åæäºå°éå¼åè¨­çéå¶ï¼ééå°è¦è¦ºéä¿è¡¨å¾µèéæ¾è©å½ææ¬è¡¨å¾µå°é½ãéä½¿å¾è½å¤ è­å¥æ°çè¦è¦ºéä¿ï¼ä½¿å¶é©ç¨æ¼å·æå¤æ¨£åéä¿ççå¯¦ä¸çå ´æ¯ãç¶èï¼ç¾æç OV-SGG æ¹æ³åå°åºå®ææ¬è¡¨å¾µçéå¶ï¼éå¶äºååææ¬å°é½çå¤æ¨£æ§åæºç¢ºæ§ãçºäºæå°éäºææ°ï¼æåæåºäºéä¿æç¥éå±¤å¼æç¤º (RAHP) æ¶æ§ï¼ééæ´åä¸»é«å®¢é«åç¹å®ååçéä¿è³è¨ä¾å¢å¼·ææ¬è¡¨å¾µãæåçåæ³å©ç¨å¯¦é«èé¡ä¾è§£æ±ºéä¿ä¸åçµé¡å¥çè¤éæ§ï¼ä½¿ä¸»é«å®¢é«è³è¨è½å¤ æææ´åãæ­¤å¤ï¼æåå©ç¨å¤§åèªè¨æ¨¡å (LLM) ä¾ç¢çè©³ç´°çååæç¥æç¤ºï¼ææç´°å¾®çè¦è¦ºäºåä¸¦æ¹åè¦è¦ºåææ¬æ¨¡å¼ä¹éçå°é½ãRAHP ä¹å¨è¦è¦ºèªè¨æ¨¡å (VLM) ä¸­å¼å¥äºåæé¸ææ©å¶ï¼æ ¹æè¦è¦ºå§å®¹èªé©æå°é¸æç¸éææ¬æç¤ºï¼æ¸å°ä¸ç¸éæç¤ºçéè¨ãå¨ Visual Genome å Open Images v6 è³æéä¸çå¤§éå¯¦é©è­æï¼æåçæ¶æ§æçºéææåé²çæè½ï¼è­æå¶å¨è§£æ±ºéæ¾è©å½å ´æ¯åçæçææ°ä¸å·ææè½ã

##### **PhyloGen: Language Model-Enhanced Phylogenetic Inference via Graph Structure Generation**
2412.18827v1 by ChenRui Duan, Zelin Zang, Siyuan Li, Yongjie Xu, Stan Z. Li

Phylogenetic trees elucidate evolutionary relationships among species, but
phylogenetic inference remains challenging due to the complexity of combining
continuous (branch lengths) and discrete parameters (tree topology).
Traditional Markov Chain Monte Carlo methods face slow convergence and
computational burdens. Existing Variational Inference methods, which require
pre-generated topologies and typically treat tree structures and branch lengths
independently, may overlook critical sequence features, limiting their accuracy
and flexibility. We propose PhyloGen, a novel method leveraging a pre-trained
genomic language model to generate and optimize phylogenetic trees without
dependence on evolutionary models or aligned sequence constraints. PhyloGen
views phylogenetic inference as a conditionally constrained tree structure
generation problem, jointly optimizing tree topology and branch lengths through
three core modules: (i) Feature Extraction, (ii) PhyloTree Construction, and
(iii) PhyloTree Structure Modeling. Meanwhile, we introduce a Scoring Function
to guide the model towards a more stable gradient descent. We demonstrate the
effectiveness and robustness of PhyloGen on eight real-world benchmark
datasets. Visualization results confirm PhyloGen provides deeper insights into
phylogenetic relationships.

æè¦ï¼ç³»çµ±ç¼çæ¨¹é¡æäºç©ç¨®ä¹éçæ¼åéä¿ï¼ä½ç±æ¼é£çºåæ¸ï¼åæ¯é·åº¦ï¼åé¢æ£åæ¸ï¼æ¨¹å½¢çµæ§ï¼çµåçè¤éæ§ï¼ç³»çµ±ç¼çæ¨è«ä»ç¶å·æææ°æ§ãå³çµ±çé¦¬å¯å¤«éèç¹å¡ç¾æ¹æ³é¢è¨æ¶æéåº¦æ¢åè¨ç®è² æéãç¾æçè®åæ¨è«æ¹æ³éè¦é åç¢ççææ²çµæ§ï¼ä¸¦ä¸éå¸¸ç¨ç«èçæ¨¹å½¢çµæ§ååæ¯é·åº¦ï¼å¯è½æå¿½ç¥ééµçåºåç¹å¾µï¼å¾èéå¶å¶æºç¢ºæ§åéæ´»æ§ãæåæåºäº PhyloGenï¼éæ¯ä¸ç¨®æ°ç©çæ¹æ³ï¼å©ç¨é è¨ç·´çåºå çµèªè¨æ¨¡åä¾çæååªåç³»çµ±ç¼çæ¨¹ï¼èä¸éè¦ä¾è³´æ¼åæ¨¡åææ¯å°åºåç´æãPhyloGen å°ç³»çµ±ç¼çæ¨è«è¦çºä¸åæ¢ä»¶ç´æçæ¨¹å½¢çµæ§çæåé¡ï¼ééä¸åæ ¸å¿æ¨¡çµå±ååªåæ¨¹å½¢çµæ§ååæ¯é·åº¦ï¼(i) ç¹å¾µæåã(ii) PhyloTree æ§å»ºï¼ä»¥å (iii) PhyloTree çµæ§å»ºæ¨¡ãåæï¼æåå¼å¥äºè©åå½æ¸ä¾å¼å°æ¨¡åæèæ´ç©©å®çæ¢¯åº¦ä¸éæ¹åç¼å±ãæåå¨å«åçå¯¦ä¸ççåºæºæ¸æéä¸å±ç¤ºäº PhyloGen çæææ§åé­¯æ£æ§ãå¯è¦åçµæè­å¯¦ï¼PhyloGen è½å¤ æ´æ·±å¥å°äºè§£ç³»çµ±ç¼çéä¿ã

##### **CypherBench: Towards Precise Retrieval over Full-scale Modern Knowledge Graphs in the LLM Era**
2412.18702v1 by Yanlin Feng, Simone Papicchio, Sajjadur Rahman

Retrieval from graph data is crucial for augmenting large language models
(LLM) with both open-domain knowledge and private enterprise data, and it is
also a key component in the recent GraphRAG system (edge et al., 2024). Despite
decades of research on knowledge graphs and knowledge base question answering,
leading LLM frameworks (e.g. Langchain and LlamaIndex) have only minimal
support for retrieval from modern encyclopedic knowledge graphs like Wikidata.
In this paper, we analyze the root cause and suggest that modern RDF knowledge
graphs (e.g. Wikidata, Freebase) are less efficient for LLMs due to overly
large schemas that far exceed the typical LLM context window, use of resource
identifiers, overlapping relation types and lack of normalization. As a
solution, we propose property graph views on top of the underlying RDF graph
that can be efficiently queried by LLMs using Cypher. We instantiated this idea
on Wikidata and introduced CypherBench, the first benchmark with 11
large-scale, multi-domain property graphs with 7.8 million entities and over
10,000 questions. To achieve this, we tackled several key challenges, including
developing an RDF-to-property graph conversion engine, creating a systematic
pipeline for text-to-Cypher task generation, and designing new evaluation
metrics.

æè¦ï¼å¾åå½¢è³æä¸­æ·åå°æ¼æ´å¢å¤§åèªè¨æ¨¡å (LLM) éå¸¸éè¦ï¼å®çµåäºéæ¾é åç¥è­åç§äººä¼æ¥­è³æï¼åæä¹æ¯è¿æ GraphRAG ç³»çµ± (edge et al., 2024) çééµçµæé¨åãåç®¡ç¶éæ¸åå¹´çç¥è­åè­åç¥è­åº«åé¡è§£ç­ç ç©¶ï¼ä½é åç LLM æ¡æ¶ï¼ä¾å¦ Langchain å LlamaIndexï¼åè½æä½éåº¦æ¯æ´å¾ç¾ä»£ç¾ç§ç¥è­åè­ï¼ä¾å¦ Wikidataï¼æ·åãå¨æ¬æä¸­ï¼æååæäºæ ¹æ¬åå ï¼ä¸¦æåºç¾ä»£ RDF ç¥è­åè­ï¼ä¾å¦ WikidataãFreebaseï¼å°æ¼ LLM ä¾èªªæçè¼ä½ï¼éæ¯å çºéæ¼é¾å¤§çæ¶æ§é é è¶éå¸åç LLM èæ¯è¦çªãä½¿ç¨è³æºè­å¥ç¢¼ãéççéä¿é¡ååç¼ºä¹æ¨æºåãä½çºè§£æ±ºæ¹æ¡ï¼æåæåºå¨åºå±¤ RDF åå½¢ä¸å»ºç«å±¬æ§åå½¢æª¢è¦ï¼LLM å¯ä»¥ä½¿ç¨ Cypher ææå°æ¥è©¢éäºæª¢è¦ãæåå¨ Wikidata ä¸å¯¦ä¾åäºéåæ³æ³ï¼ä¸¦å¼å¥äº CypherBenchï¼éæ¯ç¬¬ä¸ååºæºï¼åå« 11 åå¤§åãå¤é åçå±¬æ§åå½¢ï¼ææ 780 è¬åå¯¦é«åè¶é 10,000 ååé¡ãçºäºéææ­¤ç®æ¨ï¼æåæå°äºå¹¾åééµææ°ï¼åæ¬éç¼ RDF å°å±¬æ§åå½¢è½æå¼æãå»ºç«æå­å° Cypher ä»»åç¢çç³»çµ±åæµç¨ï¼ä»¥åè¨­è¨æ°çè©ä¼°ææ¨ã

##### **From Hallucinations to Facts: Enhancing Language Models with Curated Knowledge Graphs**
2412.18672v1 by Ratnesh Kumar Joshi, Sagnik Sengupta, Asif Ekbal

Hallucination, a persistent challenge plaguing language models, undermines
their efficacy and trustworthiness in various natural language processing
endeavors by generating responses that deviate from factual accuracy or
coherence. This paper addresses language model hallucination by integrating
curated knowledge graph (KG) triples to anchor responses in empirical data. We
meticulously select and integrate relevant KG triples tailored to specific
contexts, enhancing factual grounding and alignment with input. Our
contribution involves constructing a comprehensive KG repository from Wikipedia
and refining data to spotlight essential information for model training. By
imbuing language models with access to this curated knowledge, we aim to
generate both linguistically fluent responses and deeply rooted in factual
accuracy and context relevance. This integration mitigates hallucinations by
providing a robust foundation of information, enabling models to draw upon a
rich reservoir of factual data during response generation. Experimental
evaluations demonstrate the effectiveness of multiple approaches in reducing
hallucinatory responses, underscoring the role of curated knowledge graphs in
improving the reliability and trustworthiness of language model outputs.

æè¦ï¼å¹»è¦ºï¼ä¸ç¨®æçºå°æ¾èªè¨æ¨¡åçææ°ï¼ç ´å£äºå®åå¨åç¨®èªç¶èªè¨èçå·¥ä½ä¸­çæçåå¯ä¿¡åº¦ï¼å çºå®åç¢ççåæåé¢äºäºå¯¦çæºç¢ºæ§æé£è²«æ§ãæ¬æééæ´åç¶éæ´ççç¥è­åè­ (KG) ä¸åçµä¾é¨å®ç¶é©æ¸æä¸­çåæï¼ä¾è§£æ±ºèªè¨æ¨¡åçå¹»è¦ºãæåä»ç´°å°é¸æä¸¦æ´åèç¹å®èçµ¡ç¸ç¬¦çç¸é KG ä¸åçµï¼å¢å¼·äºå¯¦ä¾æä¸¦èè¼¸å¥ä¿æä¸è´ãæåçè²¢ç»åæ¬å¾ç¶­åºç¾ç§æ§å»ºä¸åå¨é¢ç KG å²å­åº«ï¼ä¸¦ç²¾çæ¸æï¼ä»¥çªé¡¯æ¨¡åè¨ç·´çéè¦è³è¨ãééè®èªè¨æ¨¡åå­åéåç¶éæ´ççç¥è­ï¼æåæ¨å¨ç¢çæ¢èªè¨æµæ¢ï¼åæ·±æ¤æ¼äºå¯¦æºç¢ºæ§åèçµ¡ç¸éæ§çåæãéç¨®æ´åééæä¾ç©©å¥çè³è¨åºç¤ä¾æ¸è¼å¹»è¦ºï¼è®æ¨¡åå¨åæç¢çæéè½å¤ å©ç¨è±å¯çäºå¯¦æ¸æå²åãå¯¦é©è©ä¼°è­æäºå¤ç¨®æ¹æ³å¨æ¸å°å¹»è¦ºåææ¹é¢çæææ§ï¼å¼·èª¿äºç¶éæ´ççç¥è­åè­å¨æ¹åèªè¨æ¨¡åè¼¸åºçå¯é æ§åå¯ä¿¡åº¦æ¹é¢ææ®æ¼çè§è²ã

##### **Harnessing Large Language Models for Knowledge Graph Question Answering via Adaptive Multi-Aspect Retrieval-Augmentation**
2412.18537v2 by Derong Xu, Xinhang Li, Ziheng Zhang, Zhenxi Lin, Zhihong Zhu, Zhi Zheng, Xian Wu, Xiangyu Zhao, Tong Xu, Enhong Chen

Large Language Models (LLMs) demonstrate remarkable capabilities, yet
struggle with hallucination and outdated knowledge when tasked with complex
knowledge reasoning, resulting in factually incorrect outputs. Previous studies
have attempted to mitigate it by retrieving factual knowledge from large-scale
knowledge graphs (KGs) to assist LLMs in logical reasoning and prediction of
answers. However, this kind of approach often introduces noise and irrelevant
data, especially in situations with extensive context from multiple knowledge
aspects. In this way, LLM attention can be potentially mislead from question
and relevant information. In our study, we introduce an Adaptive Multi-Aspect
Retrieval-augmented over KGs (Amar) framework. This method retrieves knowledge
including entities, relations, and subgraphs, and converts each piece of
retrieved text into prompt embeddings. The Amar framework comprises two key
sub-components: 1) a self-alignment module that aligns commonalities among
entities, relations, and subgraphs to enhance retrieved text, thereby reducing
noise interference; 2) a relevance gating module that employs a soft gate to
learn the relevance score between question and multi-aspect retrieved data, to
determine which information should be used to enhance LLMs' output, or even
filtered altogether. Our method has achieved state-of-the-art performance on
two common datasets, WebQSP and CWQ, showing a 1.9\% improvement in accuracy
over its best competitor and a 6.6\% improvement in logical form generation
over a method that directly uses retrieved text as context prompts. These
results demonstrate the effectiveness of Amar in improving the reasoning of
LLMs.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å±ç¤ºäºéå¡çè½åï¼ä½å¨å·è¡è¤éçç¥è­æ¨çæï¼å»æåºç¾å¹»è¦ºåéæçç¥è­ï¼å°è´äºå¯¦ä¸ä¸æ­£ç¢ºçè¼¸åºãååçç ç©¶å·²åè©¦ééå¾å¤§è¦æ¨¡ç¥è­åè­ (KG) ä¸­æ·åäºå¯¦ç¥è­ä¾æ¸è¼éååé¡ï¼ä»¥åå© LLM é²è¡éè¼¯æ¨çåç­æ¡é æ¸¬ãç¶èï¼éç¨®æ¹æ³éå¸¸æå¼å¥éè¨åä¸ç¸éçè³æï¼ç¹å¥æ¯å¨å·æä¾èªå¤åç¥è­é¢åçå»£æ³èçµ¡çææ³ä¸ãéæ¨£ä¸ä¾ï¼LLM çæ³¨æåå¯è½æè¢«åé¡åç¸éè³è¨èª¤å°ãå¨æåçç ç©¶ä¸­ï¼æåä»ç´¹äºä¸åé©ææ§å¤é¢åæ·åå¢å¼·åç¥è­åè­ (Amar) æ¡æ¶ãæ­¤æ¹æ³æ·ååæ¬å¯¦é«ãéä¿åå­åçç¥è­ï¼ä¸¦å°æ¯åæ·åçæå­è½æçºæç¤ºåµå¥ãAmar æ¡æ¶åå«å©åééµå­åä»¶ï¼1) ä¸åèªæå°é½æ¨¡çµï¼ç¨æ¼å°é½å¯¦é«ãéä¿åå­åä¹éçå±æ§ï¼ä»¥å¢å¼·æ·åçæå­ï¼å¾èæ¸å°éè¨å¹²æ¾ï¼2) ä¸åç¸éæ§éæ§æ¨¡çµï¼æ¡ç¨è»éæ§ä¾å­¸ç¿åé¡åå¤é¢åæ·åè³æä¹éçç¸å³æ§åæ¸ï¼ä»¥ç¢ºå®åªäºè³è¨æä½¿ç¨ä¾å¢å¼· LLM çè¼¸åºï¼çè³å®å¨éæ¿¾æãæåçæ¨¡åå¨å©åå¸¸è¦çè³æé WebQSP å CWQ ä¸éå°äºæåé²çæè½ï¼èæä½³ç«¶ç­èç¸æ¯ï¼æºç¢ºåº¦æåäº 1.9%ï¼èç´æ¥ä½¿ç¨æ·åæå­ä½çºèçµ¡æç¤ºçæ¹æ³ç¸æ¯ï¼éè¼¯å½¢å¼çææåäº 6.6%ãéäºçµæè­æäº Amar å¨æ¹å LLM æ¨çæ¹é¢çæææ§ã

##### **DynaGRAG: Improving Language Understanding and Generation through Dynamic Subgraph Representation in Graph Retrieval-Augmented Generation**
2412.18644v1 by Karishma Thakrar

Graph Retrieval-Augmented Generation (GRAG or Graph RAG) architectures aim to
enhance language understanding and generation by leveraging external knowledge.
However, effectively capturing and integrating the rich semantic information
present in textual and structured data remains a challenge. To address this, a
novel GRAG framework is proposed to focus on enhancing subgraph representation
and diversity within the knowledge graph. By improving graph density, capturing
entity and relation information more effectively, and dynamically prioritizing
relevant and diverse subgraphs, the proposed approach enables a more
comprehensive understanding of the underlying semantic structure. This is
achieved through a combination of de-duplication processes, two-step mean
pooling of embeddings, query-aware retrieval considering unique nodes, and a
Dynamic Similarity-Aware BFS (DSA-BFS) traversal algorithm. Integrating Graph
Convolutional Networks (GCNs) and Large Language Models (LLMs) through hard
prompting further enhances the learning of rich node and edge representations
while preserving the hierarchical subgraph structure. Experimental results on
multiple benchmark datasets demonstrate the effectiveness of the proposed GRAG
framework, showcasing the significance of enhanced subgraph representation and
diversity for improved language understanding and generation.

æè¦ï¼åè¡¨æ·åå¢å¼·çæï¼GRAG æ Graph RAGï¼æ¶æ§æ¨å¨
éééç¨å¤é¨ç¥è­ä¾å¢å¼·èªè¨çè§£åçæã
ç¶èï¼æææ·ååæ´åææ¬åçµæ§åè³æä¸­è±å¯çèªç¾©è³è¨ä»ç¶æ¯ä¸é ææ°ãçºäºè§£æ±ºéååé¡ï¼æåºäºä¸åæ°ç GRAG æ¡æ¶ï¼å°æ³¨æ¼å¢å¼·ç¥è­åè­ä¸­çå­åè¡¨ç¤ºåå¤æ¨£æ§ãééæ¹ååå½¢å¯åº¦ãæ´ææå°æ·åå¯¦é«åéä¿è³è¨ï¼ä»¥ååæåªåèæ®ç¸éä¸å¤æ¨£åçå­åï¼ææåºçæ¹æ³è½æ´å¨é¢å°çè§£åºå±¤èªç¾©çµæ§ãéæ¯ééçµåéè¤è³æåªé¤ç¨åºãåµå¥çå©æ­¥é©å¹³åæ± åãèæ®å¯ä¸ç¯é»çæ¥è©¢æç¥æ·åï¼ä»¥ååæç¸ä¼¼åº¦æç¥å»£åº¦åªåæå°ï¼DSA-BFSï¼æ¼ç®æ³ä¾å¯¦ç¾çãééç¡¬æç¤ºæ´ååå½¢å·ç©ç¶²è·¯ï¼GCNï¼åå¤§èªè¨æ¨¡åï¼LLMï¼ï¼é²ä¸æ­¥å¢å¼·è±å¯ç¯é»åéç·£è¡¨ç¤ºçå­¸ç¿ï¼åæä¿çéå±¤å¼å­åçµæ§ãå¨å¤ååºæºè³æéä¸çå¯¦é©çµæè­æäºææåºç GRAG æ¡æ¶çæææ§ï¼å±ç¤ºäºå¢å¼·å­åè¡¨ç¤ºåå¤æ¨£æ§å°æ¼æ¹åèªè¨çè§£åçæçéè¦æ§ã

##### **Is Large Language Model Good at Triple Set Prediction? An Empirical Study**
2412.18443v1 by Yuan Yuan, Yajing Xu, Wen Zhang

The core of the Knowledge Graph Completion (KGC) task is to predict and
complete the missing relations or nodes in a KG. Common KGC tasks are mostly
about inferring unknown elements with one or two elements being known in a
triple. In comparison, the Triple Set Prediction (TSP) task is a more realistic
knowledge graph completion task. It aims to predict all elements of unknown
triples based on the information from known triples. In recent years, large
language models (LLMs) have exhibited significant advancements in language
comprehension, demonstrating considerable potential for KGC tasks. However, the
potential of LLM on the TSP task has not yet to be investigated. Thus in this
paper we proposed a new framework to explore the strengths and limitations of
LLM in the TSP task. Specifically, the framework consists of LLM-based rule
mining and LLM-based triple set prediction. The relation list of KG embedded
within rich semantic information is first leveraged to prompt LLM in the
generation of rules. This process is both efficient and independent of
statistical information, making it easier to mine effective and realistic
rules. For each subgraph, the specified rule is applied in conjunction with the
relevant triples within that subgraph to guide the LLM in predicting the
missing triples. Subsequently, the predictions from all subgraphs are
consolidated to derive the complete set of predicted triples on KG. Finally,
the method is evaluated on the relatively complete CFamily dataset. The
experimental results indicate that when LLMs are required to adhere to a large
amount of factual knowledge to predict missing triples, significant
hallucinations occurs, leading to a noticeable decline in performance. To
further explore the causes of this phenomenon, this paper presents a
comprehensive analysis supported by a detailed case study.

æè¦ï¼ç¥è­åè­å®æ (KGC) ä»»åçæ ¸å¿æ¯é æ¸¬åå®æ KG ä¸­éºå¤±çéä¿æç¯é»ãå¸¸è¦ç KGC ä»»åå¤§å¤æ¯éæ¼æ¨è«æªç¥åç´ ï¼å¶ä¸­ä¸åæå©ååç´ å¨ä¸åçµä¸­å·²ç¥ãç¸æ¯ä¹ä¸ï¼ä¸åçµéåé æ¸¬ (TSP) ä»»åæ¯ä¸åæ´å¯¦éçç¥è­åè­å®æä»»åãå®æ¨å¨æ ¹æå·²ç¥ä¸åçµä¸­çè³è¨é æ¸¬æªç¥ä¸åçµçææåç´ ãè¿å¹´ä¾ï¼å¤§åèªè¨æ¨¡å (LLM) å¨èªè¨çè§£æ¹é¢è¡¨ç¾åºé¡¯èçé²æ­¥ï¼é¡¯ç¤ºåº KGC ä»»åçå·¨å¤§æ½åãç¶èï¼LLM å¨ TSP ä»»åä¸çæ½åå°æªå¾å°æ¢è¨ãå æ­¤ï¼å¨æ¬æä¸­ï¼æåæåºäºä¸åæ°çæ¡æ¶ä¾æ¢ç´¢ LLM å¨ TSP ä»»åä¸­çåªå¢åå±éæ§ãå·é«ä¾èªªï¼è©²æ¡æ¶åå«åºæ¼ LLM çè¦åææååºæ¼ LLM çä¸åçµéåé æ¸¬ãåµå¥è±å¯èªç¾©è³è¨ç KG éä¿æ¸å®é¦åè¢«å©ç¨ä¾æç¤º LLM çæè¦åãéåéç¨æ¢ææçåç¨ç«æ¼çµ±è¨è³è¨ï¼ä½¿å¾ææææä¸å¯¦éçè¦åè®å¾æ´å®¹æãå°æ¼æ¯åå­åï¼æå®è¦åèè©²å­åä¸­ç¸éçä¸åçµçµåä½¿ç¨ï¼ä»¥æå° LLM é æ¸¬éºå¤±çä¸åçµãé¨å¾ï¼åä½µææå­åçé æ¸¬ï¼ä»¥æ¨å° KG ä¸é æ¸¬ä¸åçµçå®æ´éåãæå¾ï¼è©²æ¹æ³å¨ç¸å°å®æ´ç CFamily è³æéä¸é²è¡è©ä¼°ãå¯¦é©çµæè¡¨æï¼ç¶è¦æ± LLM éµå¾ªå¤§éäºå¯¦ç¥è­ä¾é æ¸¬éºå¤±çä¸åçµæï¼æç¼çé¡¯èçå¹»è¦ºï¼å°è´æè½é¡¯èä¸éãçºäºé²ä¸æ­¥æ¢è¨éç¨®ç¾è±¡çåå ï¼æ¬ææåºäºç±è©³ç´°æ¡ä¾ç ç©¶æ¯æ´çå¨é¢åæã

##### **Investigating Large Language Models for Code Vulnerability Detection: An Experimental Study**
2412.18260v2 by Xuefeng Jiang, Lvhua Wu, Sheng Sun, Jia Li, Jingjing Xue, Yuwei Wang, Tingting Wu, Min Liu

Code vulnerability detection (CVD) is essential for addressing and preventing
system security issues, playing a crucial role in ensuring software security.
Previous learning-based vulnerability detection methods rely on either
fine-tuning medium-size sequence models or training smaller neural networks
from scratch. Recent advancements in large pre-trained language models (LLMs)
have showcased remarkable capabilities in various code intelligence tasks
including code understanding and generation. However, the effectiveness of LLMs
in detecting code vulnerabilities is largely under-explored. This work aims to
investigate the gap by fine-tuning LLMs for the CVD task, involving four
widely-used open-source LLMs. We also implement other five previous graph-based
or medium-size sequence models for comparison. Experiments are conducted on
five commonly-used CVD datasets, including both the part of short samples and
long samples. In addition, we conduct quantitative experiments to investigate
the class imbalance issue and the model's performance on samples of different
lengths, which are rarely studied in previous works. To better facilitate
communities, we open-source all codes and resources of this study in
https://github.com/SakiRinn/LLM4CVD and
https://huggingface.co/datasets/xuefen/VulResource.

æè¦ï¼ç¨å¼ç¢¼æ¼æ´åµæ¸¬ (CVD) å°è§£æ±ºåé é²ç³»çµ±å®å¨åé¡è³ééè¦ï¼å¨ç¢ºä¿è»é«å®å¨ä¸æ®æ¼ééµè§è²ã
ååçåºæ¼å­¸ç¿çæ¼æ´åµæ¸¬æ¹æ³ä»°è³´å¾®èª¿ä¸­ååºåæ¨¡åæå¾é ­è¨ç·´è¼å°çç¥ç¶ç¶²è·¯ã
å¤§åé è¨ç·´èªè¨æ¨¡å (LLM) çææ°é²å±å¨åç¨®ç¨å¼ç¢¼æºæ§ä»»åä¸­å±ç¾åºåè¶çè½åï¼åæ¬ç¨å¼ç¢¼çè§£åç¢çã
ç¶èï¼LLM å¨åµæ¸¬ç¨å¼ç¢¼æ¼æ´çæè½å»é®®å°è¢«æ¢è¨ãæ¬ç ç©¶æ¨å¨ééå¾®èª¿ LLM ä¾å¡«è£éåç¼ºå£ï¼æ¶åååå»£æ³ä½¿ç¨çéæº LLMã
æåä¹å¯¦ä½äºå¶ä»äºåååçåºæ¼åå½¢çæä¸­ååºåæ¨¡åé²è¡æ¯è¼ã
å¯¦é©å¨äºåå¸¸ç¨ç CVD è³æéä¸é²è¡ï¼åå«ç­ç¯ä¾åé·ç¯ä¾çé¨åã
æ­¤å¤ï¼æåé²è¡éåå¯¦é©ä¾æ¢è¨é¡å¥ä¸å¹³è¡¡åé¡åæ¨¡åå¨ä¸åé·åº¦ç¯ä¾ä¸çè¡¨ç¾ï¼éäºå¨ååçç ç©¶ä¸­å¾å°è¢«æ¢è¨ã
çºæ´å¥½å°ä¿é²ç¤¾ç¾¤ï¼æåå¨ https://github.com/SakiRinn/LLM4CVD å https://huggingface.co/datasets/xuefen/VulResource éæºæ¬ç ç©¶çææç¨å¼ç¢¼åè³æºã

##### **An Automatic Graph Construction Framework based on Large Language Models for Recommendation**
2412.18241v1 by Rong Shan, Jianghao Lin, Chenxu Zhu, Bo Chen, Menghui Zhu, Kangning Zhang, Jieming Zhu, Ruiming Tang, Yong Yu, Weinan Zhang

Graph neural networks (GNNs) have emerged as state-of-the-art methods to
learn from graph-structured data for recommendation. However, most existing
GNN-based recommendation methods focus on the optimization of model structures
and learning strategies based on pre-defined graphs, neglecting the importance
of the graph construction stage. Earlier works for graph construction usually
rely on speciffic rules or crowdsourcing, which are either too simplistic or
too labor-intensive. Recent works start to utilize large language models (LLMs)
to automate the graph construction, in view of their abundant open-world
knowledge and remarkable reasoning capabilities. Nevertheless, they generally
suffer from two limitations: (1) invisibility of global view (e.g., overlooking
contextual information) and (2) construction inefficiency. To this end, we
introduce AutoGraph, an automatic graph construction framework based on LLMs
for recommendation. Specifically, we first use LLMs to infer the user
preference and item knowledge, which is encoded as semantic vectors. Next, we
employ vector quantization to extract the latent factors from the semantic
vectors. The latent factors are then incorporated as extra nodes to link the
user/item nodes, resulting in a graph with in-depth global-view semantics. We
further design metapath-based message aggregation to effectively aggregate the
semantic and collaborative information. The framework is model-agnostic and
compatible with different backbone models. Extensive experiments on three
real-world datasets demonstrate the efficacy and efffciency of AutoGraph
compared to existing baseline methods. We have deployed AutoGraph in Huawei
advertising platform, and gain a 2.69% improvement on RPM and a 7.31%
improvement on eCPM in the online A/B test. Currently AutoGraph has been used
as the main trafffc model, serving hundreds of millions of people.

æè¦ï¼åç¥ç¶ç¶²è·¯ (GNN) å·²æçºæåé²çæ¹æ³ï¼å¯å¾åå½¢çµæ§åè³æä¸­å­¸ç¿æ¨è¦ãç¶èï¼ç¾æçåºæ¼ GNN çæ¨è¦æ¹æ³å¤§å¤å´éæ¼é å®ç¾©åå½¢ä¸çæ¨¡åçµæ§åå­¸ç¿ç­ç¥çæä½³åï¼å¿½ç¥äºåå½¢å»ºæ§éæ®µçéè¦æ§ãæ©æåå½¢å»ºæ§å·¥ä½éå¸¸ä¾è³´æ¼ç¹å®è¦åæç¾¤ç¾å¤åï¼éäºæ¹æ³éæ¼ç°¡åæéæ¼ååå¯éãæè¿çå·¥ä½éå§å©ç¨å¤§åèªè¨æ¨¡å (LLM) ä¾èªåååå½¢å»ºæ§ï¼å çºå®åå·æè±å¯çéæ¾ä¸çç¥è­ååè¶çæ¨çè½åãåç®¡å¦æ­¤ï¼å®åéå¸¸å­å¨å©åéå¶ï¼(1) å¨åæª¢è¦çä¸å¯è¦æ§ï¼ä¾å¦ï¼å¿½ç¥ä¸ä¸æè³è¨ï¼å (2) å»ºæ§æçä½ä¸ãçºæ­¤ï¼æåå¼å¥äº AutoGraphï¼ä¸ååºæ¼ LLM çèªååå½¢å»ºæ§æ¡æ¶ï¼ç¨æ¼æ¨è¦ãå·é«ä¾èªªï¼æåé¦åä½¿ç¨ LLM æ¨æ·ä½¿ç¨èåå¥½åé ç®ç¥è­ï¼ä¸¦å°å¶ç·¨ç¢¼çºèªç¾©åéãæ¥ä¸ä¾ï¼æåæ¡ç¨åééåå¾èªç¾©åéä¸­æåæ½å¨å å­ãç¶å¾å°æ½å¨å å­ä½çºé¡å¤ç¯é»å å¥ï¼ä»¥é£çµä½¿ç¨è/é ç®ç¯é»ï¼å¾èå½¢æä¸åå·ææ·±å¥å¨åæª¢è¦èªç¾©çåå½¢ãæåé²ä¸æ­¥è¨­è¨äºåºæ¼åè·¯å¾çè¨æ¯èåï¼ä»¥ææèåèªç¾©ååä½è³è¨ãè©²æ¡æ¶èæ¨¡åç¡éï¼ä¸¦èä¸åçä¸»å¹¹æ¨¡åç¸å®¹ãå¨ä¸åçå¯¦ä¸çè³æéä¸é²è¡çå»£æ³å¯¦é©è­æäº AutoGraph èç¾æåºæºæ¹æ³ç¸æ¯çæè½åæçãæåå·²å¨è¯çºå»£åå¹³å°ä¸é¨ç½²äº AutoGraphï¼ä¸¦å¨ç·ä¸ A/B æ¸¬è©¦ä¸­ç²å¾äº RPM æå 2.69% å eCPM æå 7.31%ãç®å AutoGraph å·²è¢«ç¨ä½ä¸»è¦çæµéæ¨¡åï¼æåæ¼æ¸åäººã

##### **CARL-GT: Evaluating Causal Reasoning Capabilities of Large Language Models**
2412.17970v1 by Ruibo Tu, Hedvig KjellstrÃ¶m, Gustav Eje Henter, Cheng Zhang

Causal reasoning capabilities are essential for large language models (LLMs)
in a wide range of applications, such as education and healthcare. But there is
still a lack of benchmarks for a better understanding of such capabilities.
Current LLM benchmarks are mainly based on conversational tasks, academic math
tests, and coding tests. Such benchmarks evaluate LLMs in well-regularized
settings, but they are limited in assessing the skills and abilities to solve
real-world problems. In this work, we provide a benchmark, named by CARL-GT,
which evaluates CAusal Reasoning capabilities of large Language models using
Graphs and Tabular data. The benchmark has a diverse range of tasks for
evaluating LLMs from causal graph reasoning, knowledge discovery, and
decision-making aspects. In addition, effective zero-shot learning prompts are
developed for the tasks. In our experiments, we leverage the benchmark for
evaluating open-source LLMs and provide a detailed comparison of LLMs for
causal reasoning abilities. We found that LLMs are still weak in casual
reasoning, especially with tabular data to discover new insights. Furthermore,
we investigate and discuss the relationships of different benchmark tasks by
analyzing the performance of LLMs. The experimental results show that LLMs have
different strength over different tasks and that their performance on tasks in
different categories, i.e., causal graph reasoning, knowledge discovery, and
decision-making, shows stronger correlation than tasks in the same category.

æè¦ï¼å ææ¨çè½åå¯¹äºå¤§åè¯­è¨æ¨¡å (LLM) è³å³éè¦ï¼éç¨äºå¹¿æ³çåºç¨ï¼ä¾å¦æè²åå»çä¿å¥ãä½å¯¹äºæ´å¥½å°çè§£æ­¤ç±»è½åï¼ä»ç¶ç¼ºä¹åºåãå½åç LLM åºåä¸»è¦åºäºä¼è¯ä»»å¡ãå­¦æ¯æ°å­¦æµè¯åç¼ç æµè¯ãæ­¤ç±»åºåå¨ç»è¿è¯å¥½è§èçç¯å¢ä¸­è¯ä¼° LLMï¼ä½å®ä»¬å¨è¯ä¼°è§£å³å®éé®é¢çè½ååæè½æ¹é¢åå°éå¶ãå¨è¿é¡¹å·¥ä½ä¸­ï¼æä»¬æä¾äºä¸ä¸ªåºåï¼åä¸º CARL-GTï¼å®ä½¿ç¨å¾åè¡¨æ ¼æ°æ®æ¥è¯ä¼°å¤§åè¯­è¨æ¨¡åçå ææ¨çè½åãè¯¥åºåå·æåç§ä»»å¡ï¼ç¨äºä»å æå¾æ¨çãç¥è¯åç°åå³ç­æ¹é¢è¯ä¼° LLMãæ­¤å¤ï¼éå¯¹è¿äºä»»å¡å¼åäºææçé¶æ ·æ¬å­¦ä¹ æç¤ºãå¨æä»¬çå®éªä¸­ï¼æä»¬å©ç¨åºåæ¥è¯ä¼°å¼æº LLMï¼å¹¶å¯¹ LLM çå ææ¨çè½åè¿è¡äºè¯¦ç»æ¯è¾ãæä»¬åç° LLM å¨å ææ¨çæ¹é¢ä»ç¶å¾å¼±ï¼å°¤å¶æ¯å¨ä½¿ç¨è¡¨æ ¼æ°æ®åç°æ°è§è§£æ¶ãæ­¤å¤ï¼æä»¬éè¿åæ LLM çæ§è½æ¥è°æ¥åè®¨è®ºä¸ååºåä»»å¡ä¹é´çå³ç³»ãå®éªç»æè¡¨æï¼LLM å¨ä¸åä»»å¡ä¸å·æä¸åçä¼å¿ï¼å¹¶ä¸å®ä»¬å¨ä¸åç±»å«ä¸­çä»»å¡ä¸çè¡¨ç°ï¼å³å æå¾æ¨çãç¥è¯åç°åå³ç­ï¼æ¯åä¸ç±»å«ä¸­çä»»å¡è¡¨ç°åºæ´å¼ºçç¸å³æ§ã

##### **Path-of-Thoughts: Extracting and Following Paths for Robust Relational Reasoning with Large Language Models**
2412.17963v1 by Ge Zhang, Mohammad Ali Alomrani, Hongjian Gu, Jiaming Zhou, Yaochen Hu, Bin Wang, Qun Liu, Mark Coates, Yingxue Zhang, Jianye Hao

Large language models (LLMs) possess vast semantic knowledge but often
struggle with complex reasoning tasks, particularly in relational reasoning
problems such as kinship or spatial reasoning. In this paper, we present
Path-of-Thoughts (PoT), a novel framework designed to tackle relation reasoning
by decomposing the task into three key stages: graph extraction, path
identification, and reasoning. Unlike previous approaches, PoT efficiently
extracts a task-agnostic graph that identifies crucial entities, relations, and
attributes within the problem context. Subsequently, PoT identifies relevant
reasoning chains within the graph corresponding to the posed question,
facilitating inference of potential answers. Experimental evaluations on four
benchmark datasets, demanding long reasoning chains, demonstrate that PoT
surpasses state-of-the-art baselines by a significant margin (maximum 21.3%)
without necessitating fine-tuning or extensive LLM calls. Furthermore, as
opposed to prior neuro-symbolic methods, PoT exhibits improved resilience
against LLM errors by leveraging the compositional nature of graphs.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) ææå»£æ³çèªç¾©ç¥è­ï¼ä½å¨è¤éçæ¨çä»»åä¸­ç¶å¸¸éå°å°é£ï¼ç¹å¥æ¯å¨éä¿æ¨çåé¡ä¸­ï¼ä¾å¦è¦ªå±¬éä¿æç©ºéæ¨çãå¨æ¬æä¸­ï¼æåæåºæèè·¯å¾ (PoT)ï¼éæ¯ä¸åæ°ç©çæ¡æ¶ï¼æ¨å¨ééå°ä»»ååè§£çºä¸åééµéæ®µä¾è§£æ±ºéä¿æ¨çï¼åå½¢æåãè·¯å¾è­å¥åæ¨çãèä¹åçåæ³ä¸åï¼PoT ææå°æåäºä¸åèä»»åç¡éçåå½¢ï¼è©²åå½¢è­å¥äºåé¡èæ¯ä¸­çééµå¯¦é«ãéä¿åå±¬æ§ãé¨å¾ï¼PoT å¨èææåºçåé¡ç¸æçåå½¢ä¸­è­å¥åºç¸éçæ¨çéï¼å¾èæ¨æ·åºæ½å¨ç­æ¡ãå¨éè¦é·æ¨çéçåååºæºæ¸æéä¸çå¯¦é©è©ä¼°è¡¨æï¼PoT ä»¥é¡¯èçåªå¢ï¼æå¤§ 21.3%ï¼è¶è¶äºæåé²çåºæºï¼èç¡éå¾®èª¿æå»£æ³ç LLM èª¿ç¨ãæ­¤å¤ï¼èååçç¥ç¶ç¬¦èæ¹æ³ç¸åï¼PoT ééå©ç¨åå½¢ççµåç¹æ§è¡¨ç¾åºå° LLM é¯èª¤çå¢å¼·çå½æ§ã

##### **ResearchTown: Simulator of Human Research Community**
2412.17767v1 by Haofei Yu, Zhaochen Hong, Zirui Cheng, Kunlun Zhu, Keyang Xuan, Jinwei Yao, Tao Feng, Jiaxuan You

Large Language Models (LLMs) have demonstrated remarkable potential in
scientific domains, yet a fundamental question remains unanswered: Can we
simulate human research communities with LLMs? Addressing this question can
deepen our understanding of the processes behind idea brainstorming and inspire
the automatic discovery of novel scientific insights. In this work, we propose
ResearchTown, a multi-agent framework for research community simulation. Within
this framework, the human research community is simplified and modeled as an
agent-data graph, where researchers and papers are represented as agent-type
and data-type nodes, respectively, and connected based on their collaboration
relationships. We also introduce TextGNN, a text-based inference framework that
models various research activities (e.g., paper reading, paper writing, and
review writing) as special forms of a unified message-passing process on the
agent-data graph. To evaluate the quality of the research simulation, we
present ResearchBench, a benchmark that uses a node-masking prediction task for
scalable and objective assessment based on similarity. Our experiments reveal
three key findings: (1) ResearchTown can provide a realistic simulation of
collaborative research activities, including paper writing and review writing;
(2) ResearchTown can maintain robust simulation with multiple researchers and
diverse papers; (3) ResearchTown can generate interdisciplinary research ideas
that potentially inspire novel research directions.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨ç§å­¸é åå±ç¾äºéå¡çæ½åï¼ä½ä»æä¸ååºæ¬åé¡å°æªè§£ç­ï¼æåè½ç¨ LLM æ¨¡æ¬äººé¡ç ç©¶ç¤¾ç¾¤åï¼æ¢è¨éååé¡è½å æ·±æåå°è¦åæ¿çªèå¾æµç¨ççè§£ï¼ä¸¦æ¿ç¼èªåç¼ç¾æ°ç§å­¸è¦è§£ãå¨éé å·¥ä½ä¸­ï¼æåæåº ResearchTownï¼ä¸åç¨æ¼ç ç©¶ç¤¾ç¾¤æ¨¡æ¬çå¤ä»£çæ¶æ§ãå¨éåæ¶æ§ä¸­ï¼äººé¡ç ç©¶ç¤¾ç¾¤è¢«ç°¡åä¸¦å»ºæ¨¡çºä»£çè³æåï¼å¶ä¸­ç ç©¶äººå¡åè«æåå¥è¡¨ç¤ºçºä»£çé¡åç¯é»åè³æé¡åç¯é»ï¼ä¸¦æ ¹æä»åçåä½éä¿é²è¡é£æ¥ãæåéä»ç´¹äº TextGNNï¼ä¸ååºæ¼æå­çæ¨è«æ¶æ§ï¼å®å°åç¨®ç ç©¶æ´»åï¼ä¾å¦ï¼é±è®è«æãæ°å¯«è«æåæ°å¯«è©è«ï¼å»ºæ¨¡çºä»£çè³æåä¸çµ±ä¸è¨æ¯å³ééç¨çç¹æ®å½¢å¼ãçºäºè©ä¼°ç ç©¶æ¨¡æ¬çåè³ªï¼æåæåºäº ResearchBenchï¼ä¸åä½¿ç¨ç¯é»é®ç½©é æ¸¬ä»»åé²è¡åºæ¼ç¸ä¼¼æ§çå¯æ´åä¸å®¢è§è©ä¼°çåºæºãæåçå¯¦é©æ­ç¤ºäºä¸åééµç¼ç¾ï¼(1) ResearchTown å¯ä»¥æä¾åä½ç ç©¶æ´»åçé¼çæ¨¡æ¬ï¼åæ¬æ°å¯«è«æåæ°å¯«è©è«ï¼(2) ResearchTown å¯ä»¥ç¶­æå¤ä½ç ç©¶äººå¡åä¸åè«æçç©©å¥æ¨¡æ¬ï¼(3) ResearchTown å¯ä»¥ç¢çè·¨å­¸ç§ç ç©¶æ§æ³ï¼æ½å¨æ¿ç¼æ°çç ç©¶æ¹åã

##### **RAGONITE: Iterative Retrieval on Induced Databases and Verbalized RDF for Conversational QA over KGs with RAG**
2412.17690v3 by Rishiraj Saha Roy, Chris Hinze, Joel Schlotthauer, Farzad Naderi, Viktor Hangya, Andreas Foltyn, Luzian Hahn, Fabian Kuech

Conversational question answering (ConvQA) is a convenient means of searching
over RDF knowledge graphs (KGs), where a prevalent approach is to translate
natural language questions to SPARQL queries. However, SPARQL has certain
shortcomings: (i) it is brittle for complex intents and conversational
questions, and (ii) it is not suitable for more abstract needs. Instead, we
propose a novel two-pronged system where we fuse: (i) SQL-query results over a
database automatically derived from the KG, and (ii) text-search results over
verbalizations of KG facts. Our pipeline supports iterative retrieval: when the
results of any branch are found to be unsatisfactory, the system can
automatically opt for further rounds. We put everything together in a retrieval
augmented generation (RAG) setup, where an LLM generates a coherent response
from accumulated search results. We demonstrate the superiority of our proposed
system over several baselines on a knowledge graph of BMW automobiles.

æè¦ï¼å°è©±å¼åç­ï¼ConvQAï¼æ¯ä¸ç¨®æå° RDF ç¥è­åè­ï¼KGï¼çä¾¿å©æ¹æ³ï¼å¶ä¸­ä¸ç¨®æ®éçæ¹æ³æ¯å°èªç¶èªè¨åé¡è½æçº SPARQL æ¥è©¢ãç¶èï¼SPARQL ææäºç¼ºé»ï¼(i) å°æ¼è¤éçæååå°è©±å¼åé¡èè¨ï¼å®å¾èå¼±ï¼(ii) å®ä¸é©åæ´æ½è±¡çéæ±ãç¸åï¼æåæåºäºä¸åæ°ç©çéç®¡é½ä¸çç³»çµ±ï¼å¶ä¸­æåèåï¼(i) å¾èªåå¾ KG ä¸­æ´¾ççè³æåº«ä¸ç SQL æ¥è©¢çµæï¼ä»¥å (ii) KG äºå¯¦çè¨èªåä¸çæå­æå°çµæãæåçç®¡ç·æ¯æ´åè¦æª¢ç´¢ï¼ç¶ç¼ç¾ä»»ä½åæ¯ççµæä¸ä»¤äººæ»¿ææï¼ç³»çµ±å¯ä»¥èªåé¸æé²ä¸æ­¥çååãæåå°ææå§å®¹æ´åå°æª¢ç´¢æ´åçæï¼RAGï¼è¨­å®ä¸­ï¼å¶ä¸­ LLM å¾ç´¯ç©çæå°çµæä¸­ç¢çé£è²«çåæãæåå¨ BMW æ±½è»çç¥è­åè­ä¸å±ç¤ºäºæåæåºçç³»çµ±åªæ¼å¹¾ååºç·çåªè¶æ§ã

##### **A Dual-Perspective Metaphor Detection Framework Using Large Language Models**
2412.17332v2 by Yujie Lin, Jingyao Liu, Yan Gao, Ante Wang, Jinsong Su

Metaphor detection, a critical task in natural language processing, involves
identifying whether a particular word in a sentence is used metaphorically.
Traditional approaches often rely on supervised learning models that implicitly
encode semantic relationships based on metaphor theories. However, these
methods often suffer from a lack of transparency in their decision-making
processes, which undermines the reliability of their predictions. Recent
research indicates that LLMs (large language models) exhibit significant
potential in metaphor detection. Nevertheless, their reasoning capabilities are
constrained by predefined knowledge graphs. To overcome these limitations, we
propose DMD, a novel dual-perspective framework that harnesses both implicit
and explicit applications of metaphor theories to guide LLMs in metaphor
detection and adopts a self-judgment mechanism to validate the responses from
the aforementioned forms of guidance. In comparison to previous methods, our
framework offers more transparent reasoning processes and delivers more
reliable predictions. Experimental results prove the effectiveness of DMD,
demonstrating state-of-the-art performance across widely-used datasets.

æè¦ï¼é±å»åµæ¸¬æ¯èªç¶èªè¨èçä¸­çä¸é éè¦ä»»åï¼æ¶åè­å¥å¥å­ä¸­ç¹å®å®å­æ¯å¦ä»¥é±å»æ¹å¼ä½¿ç¨ãå³çµ±æ¹æ³éå¸¸ä¾è³´ç£ç£å¼å­¸ç¿æ¨¡åï¼éäºæ¨¡åæ ¹æé±å»çè«é±å«ç·¨ç¢¼èªç¾©éä¿ãç¶èï¼éäºæ¹æ³éå¸¸å¨æ±ºç­éç¨ä¸­ç¼ºä¹éæåº¦ï¼éææå®³å¶é æ¸¬çå¯é æ§ãæè¿çç ç©¶è¡¨æï¼LLMï¼å¤§åèªè¨æ¨¡åï¼å¨é±å»åµæ¸¬ä¸­å±ç¾åºé¡¯èçæ½åãåç®¡å¦æ­¤ï¼å®åçæ¨çè½ååå°é å®ç¾©ç¥è­åè¡¨çéå¶ãçºäºåæéäºéå¶ï¼æåæåºäº DMDï¼éæ¯ä¸ç¨®æ°ç©çééè§é»æ¶æ§ï¼å®å©ç¨é±å»çè«çé±å«åæç¢ºæç¨ä¾å¼å° LLM é²è¡é±å»åµæ¸¬ï¼ä¸¦æ¡ç¨èªæå¤æ·æ©å¶ä¾é©è­ä¸è¿°æå°å½¢å¼çåæãèååçæ¨¡åç¸æ¯ï¼æåçæ¶æ§æä¾äºæ´éæçæ¨çéç¨ï¼ä¸¦æä¾äºæ´å¯é çé æ¸¬ãå¯¦é©çµæè­æäº DMD çæææ§ï¼è­æäºå¨å»£æ³ä½¿ç¨çè³æéä¸­çæåé²æè½ã

##### **GraphAgent: Agentic Graph Language Assistant**
2412.17029v1 by Yuhao Yang, Jiabin Tang, Lianghao Xia, Xingchen Zou, Yuxuan Liang, Chao Huang

Real-world data is represented in both structured (e.g., graph connections)
and unstructured (e.g., textual, visual information) formats, encompassing
complex relationships that include explicit links (such as social connections
and user behaviors) and implicit interdependencies among semantic entities,
often illustrated through knowledge graphs. In this work, we propose
GraphAgent, an automated agent pipeline that addresses both explicit graph
dependencies and implicit graph-enhanced semantic inter-dependencies, aligning
with practical data scenarios for predictive tasks (e.g., node classification)
and generative tasks (e.g., text generation). GraphAgent comprises three key
components: (i) a Graph Generator Agent that builds knowledge graphs to reflect
complex semantic dependencies; (ii) a Task Planning Agent that interprets
diverse user queries and formulates corresponding tasks through agentic
self-planning; and (iii) a Task Execution Agent that efficiently executes
planned tasks while automating tool matching and invocation in response to user
queries. These agents collaborate seamlessly, integrating language models with
graph language models to uncover intricate relational information and data
semantic dependencies. Through extensive experiments on various graph-related
predictive and text generative tasks on diverse datasets, we demonstrate the
effectiveness of our GraphAgent across various settings. We have made our
proposed GraphAgent open-source at: https://github.com/HKUDS/GraphAgent.

æè¦ï¼çå¯¦ä¸ççè³æä»¥çµæ§åï¼ä¾å¦åå½¢é£æ¥ï¼åéçµæ§åï¼ä¾å¦æå­ãè¦è¦ºè³è¨ï¼æ ¼å¼åç¾ï¼åå«è¤éçéä¿ï¼åæ¬æç¢ºçé£çµï¼ä¾å¦ç¤¾äº¤é£çµåä½¿ç¨èè¡çºï¼åèªæå¯¦é«ä¹éçé±å«ç¸äºä¾è³´ï¼éå¸¸ééç¥è­åè¡¨ä¾èªªæãå¨éé å·¥ä½ä¸­ï¼æåæåº GraphAgentï¼ä¸åèªååä»£çç¨å¼ç®¡éï¼å®èçæç¢ºçåå½¢ä¾è³´éä¿åé±å«çåå½¢å¢å¼·èªæç¸äºä¾è³´éä¿ï¼èé æ¸¬ä»»åï¼ä¾å¦ç¯é»åé¡ï¼åçæä»»åï¼ä¾å¦æå­çæï¼çå¯¦éè³ææå¢ä¿æä¸è´ãGraphAgent åå«ä¸åééµçµæé¨åï¼(i) ä¸ååå½¢ç¢çå¨ä»£çç¨å¼ï¼ç¨ä¾å»ºæ§ç¥è­åè¡¨ä»¥åæ è¤éçèªæä¾è³´éä¿ï¼(ii) ä¸åä»»åè¦åä»£çç¨å¼ï¼ç¨ä¾è©®éä¸åçä½¿ç¨èæ¥è©¢ï¼ä¸¦ééä»£çèªè¦åå¶å®ç¸æçä»»åï¼ä»¥å (iii) ä¸åä»»åå·è¡ä»£çç¨å¼ï¼ç¨ä¾å¨åæä½¿ç¨èæ¥è©¢æï¼ææçå°å·è¡å·²è¦åçä»»åï¼åæèªååå·¥å·éå°åå¼å«ãéäºä»£çç¨å¼ç¡ç¸«å°åä½ï¼å°èªè¨æ¨¡åèåå½¢èªè¨æ¨¡åæ´åå¨ä¸èµ·ï¼ä»¥æ­é²è¤éçéä¿è³è¨åè³æèªæä¾è³´éä¿ãééå¨ä¸åè³æéä¸é²è¡åç¨®èåå½¢ç¸éçé æ¸¬åæå­çæä»»åçå»£æ³å¯¦é©ï¼æåè­æäº GraphAgent å¨åç¨®è¨­å®ä¸­çæææ§ãæåå·²å°æåæåºç GraphAgent éæºï¼https://github.com/HKUDS/GraphAgentã

##### **Enhancing Supply Chain Transparency in Emerging Economies Using Online Contents and LLMs**
2412.16922v1 by Bohan Jin, Qianyou Sun, Lihua Chen

In the current global economy, supply chain transparency plays a pivotal role
in ensuring this security by enabling companies to monitor supplier performance
and fostering accountability and responsibility. Despite the advancements in
supply chain relationship datasets like Bloomberg and FactSet, supply chain
transparency remains a significant challenge in emerging economies due to
issues such as information asymmetry and institutional gaps in regulation. This
study proposes a novel approach to enhance supply chain transparency in
emerging economies by leveraging online content and large language models
(LLMs). We develop a Supply Chain Knowledge Graph Mining System that integrates
advanced LLMs with web crawler technology to automatically collect and analyze
supply chain information. The system's effectiveness is validated through a
case study focusing on the semiconductor supply chain, a domain that has
recently gained significant attention due to supply chain risks. Our results
demonstrate that the proposed system provides greater applicability for
emerging economies, such as mainland China, complementing the data gaps in
existing datasets. However, challenges including the accurate estimation of
monetary and material flows, the handling of time series data, synonyms
disambiguation, and mitigating biases from online contents still remains.
Future research should focus on addressing these issues to further enhance the
system's capabilities and broaden its application to other emerging economies
and industries.

æè¦ï¼å¨ç¶ä»å¨çç¶æ¿ä¸­ï¼ä¾æééæåº¦å¨ç¢ºä¿æ­¤å®å¨æ§æ¹é¢ç¼æ®èééµä½ç¨ï¼è®å¬å¸è½å¤ ç£æ§ä¾æåç¸¾æä¸¦ä¿é²åè²¬å¶åè²¬ä»»æãåç®¡å½­åç¤¾å FactSet ç­ä¾æééä¿æ¸æéåå¾é²å±ï¼ä½ç±æ¼è³è¨ä¸å°ç¨±åæ³è¦å¶åº¦å·®è·ç­åé¡ï¼ä¾æééæåº¦å¨éç¼ä¸­åå®¶ä»æ¯ä¸é éå¤§ææ°ãæ¬ç ç©¶æåºäºä¸ç¨®æ°æ¹æ³ï¼å©ç¨ç·ä¸å§å®¹åå¤§åèªè¨æ¨¡å (LLM) ä¾å å¼·éç¼ä¸­åå®¶çä¾æééæåº¦ãæåéç¼äºä¸åä¾æéç¥è­åè­ææç³»çµ±ï¼å°åé²ç LLM èç¶²è·¯ç¬è²æè¡æ´åå¨ä¸èµ·ï¼ä»¥èªåæ¶éååæä¾æéè³è¨ãè©²ç³»çµ±çæææ§å·²éééå°åå°é«ä¾æéçæ¡ä¾ç ç©¶å¾å°é©è­ï¼åå°é«ä¾æéæ¯ä¸åç±æ¼ä¾æéé¢¨éªèæè¿åå°æ¥µå¤§éæ³¨çé åãæåççµæè¡¨æï¼ææåºçç³»çµ±çºéç¼ä¸­åå®¶ï¼ä¾å¦ä¸­åå¤§é¸ï¼æä¾äºæ´å¤§çé©ç¨æ§ï¼è£åäºç¾ææ¸æéä¸­çæ¸æå·®è·ãç¶èï¼åæ¬æºç¢ºä¼°è¨è²¨å¹£åç©ææµãèçæéåºåæ¸æãæ¶é¤åç¾©è©æ­§ç¾©åæ¸è¼ç·ä¸å§å®¹åè¦å¨å§çææ°ä»ç¶å­å¨ãæªä¾çç ç©¶æå°æ³¨æ¼è§£æ±ºéäºåé¡ï¼ä»¥é²ä¸æ­¥å¢å¼·ç³»çµ±çè½åä¸¦æ´å¤§å¶å¨å¶ä»éç¼ä¸­åå®¶åç¢æ¥­çæç¨ã

##### **KG4Diagnosis: A Hierarchical Multi-Agent LLM Framework with Knowledge Graph Enhancement for Medical Diagnosis**
2412.16833v2 by Kaiwen Zuo, Yirui Jiang, Fan Mo, Pietro Lio

Integrating Large Language Models (LLMs) in healthcare diagnosis demands
systematic frameworks that can handle complex medical scenarios while
maintaining specialized expertise. We present KG4Diagnosis, a novel
hierarchical multi-agent framework that combines LLMs with automated knowledge
graph construction, encompassing 362 common diseases across medical
specialties. Our framework mirrors real-world medical systems through a
two-tier architecture: a general practitioner (GP) agent for initial assessment
and triage, coordinating with specialized agents for in-depth diagnosis in
specific domains. The core innovation lies in our end-to-end knowledge graph
generation methodology, incorporating: (1) semantic-driven entity and relation
extraction optimized for medical terminology, (2) multi-dimensional decision
relationship reconstruction from unstructured medical texts, and (3)
human-guided reasoning for knowledge expansion. KG4Diagnosis serves as an
extensible foundation for specialized medical diagnosis systems, with
capabilities to incorporate new diseases and medical knowledge. The framework's
modular design enables seamless integration of domain-specific enhancements,
making it valuable for developing targeted medical diagnosis systems. We
provide architectural guidelines and protocols to facilitate adoption across
medical contexts.

æè¦ï¼æ´åå¤§åèªè¨æ¨¡å (LLM) æ¼é«çè¨ºæ·ä¸­éè¦ç³»çµ±æ§æ¶æ§ï¼æ­¤æ¶æ§å¿é è½èçè¤éçé«çæå¢ï¼åæä¿æå°æ¥­ç¥è­ãæåæåº KG4Diagnosisï¼ä¸åçµå LLM èèªååç¥è­åè¡¨å»ºæ§çæ°åéå±¤å¼å¤éä»£çæ¶æ§ï¼æ¶µè 362 ç¨®å¸¸è¦ç¾çï¼æ©«è·¨ååé«çå°ç§ãæåçæ¶æ§éééå±¤æ¶æ§åæ çå¯¦ä¸ççé«çç³»çµ±ï¼ä¸ä½è² è²¬åæ­¥è©ä¼°ååæµçå®¶åº­é«å¸« (GP) ä»£çï¼åèª¿ååå°ç§ä»£çé²è¡æ·±å¥è¨ºæ·ãæ ¸å¿åµæ°å¨æ¼æåçç«¯å°ç«¯ç¥è­åè¡¨ç¢çæ¹æ³ï¼çµåï¼(1) èªæé©åçå¯¦é«èéä¿èåï¼éå°é«çè¡èªé²è¡æä½³åï¼(2) å¾éçµæ§åé«çææ¬éå»ºå¤ç¶­åº¦æ±ºç­éä¿ï¼ä»¥å (3) äººé¡å¼å°çæ¨çï¼ç¨æ¼ç¥è­æ´åãKG4Diagnosis å¯ä½çºå°éé«çè¨ºæ·ç³»çµ±çå¯å»¶ä¼¸åºç¤ï¼æè½åæ´åæ°çç¾çåé«çç¥è­ãæ­¤æ¶æ§çæ¨¡çµåè¨­è¨è½ç¡ç¸«æ´åç¹å®é åçå¼·ååè½ï¼ä½¿å¶å°æ¼éç¼ç®æ¨å°åçé«çè¨ºæ·ç³»çµ±æ¥µå·å¹å¼ãæåæä¾æ¶æ§æå¼ååå®ï¼ä»¥ä¿é²å¨åç¨®é«çæå¢ä¸­çæ¡ç¨ã

##### **Apples to Apples: Establishing Comparability in Knowledge Generation Tasks Involving Users**
2412.16766v1 by Christophe Debruyne, Ademar Crotti Junior

Knowledge graph construction (KGC) from (semi-)structured data is
challenging, and facilitating user involvement is an issue frequently brought
up within this community. We cannot deny the progress we have made with respect
to (declarative) knowledge generation languages and tools to help build such
mappings. However, it is surprising that no two studies report on similar
protocols. This heterogeneity does not allow for a comparison of KGC languages,
techniques, and tools. This paper first analyses the various studies that
report on studies involving users to identify the points of comparison. These
gaps include a lack of systematic consistency in task design, participant
selection, and evaluation metrics. Moreover, there needs to be a systematic way
of analyzing the data and reporting the findings, which is also lacking. We
thus propose and introduce a user protocol for KGC designed to address this
challenge. Where possible, we draw and take elements from the literature we
deem fit for such a protocol. The protocol, as such, allows for the comparison
of languages and techniques for the RDF Mapping Languages core functionality,
which is covered by most of the other state-of-the-art techniques and tools. We
also propose how the protocol can be amended to compare extensions (of RML).
This protocol provides an important step towards a more comparable evaluation
of KGC user studies.

æè¦ï¼ç¥è­åè­å»ºæ§ (KGC) å¾ (å) çµæ§åè³æä¸­é²è¡éå¸¸å·æææ°æ§ï¼èä¿é²ä½¿ç¨èåèæ¯éåç¤¾ç¾¤ä¸­ç¶å¸¸æåºçè­°é¡ãæåç¡æ³å¦èªæåå¨åå©å»ºæ§æ­¤é¡å°æç (å®£åå¼) ç¥è­ç¢çèªè¨åå·¥å·æ¹é¢æåçé²å±ãç¶èï¼ä»¤äººé©è¨çæ¯ï¼æ²æå©é ç ç©¶å ±åé¡ä¼¼çåå®ãéç¨®ç°è³ªæ§ä¸åè¨±æ¯è¼ KGC èªè¨ãæè¡åå·¥å·ãæ¬æé¦ååæåç¨®ç ç©¶ï¼éäºç ç©¶å ±åæ¶åä½¿ç¨èçç ç©¶ï¼ä»¥æ¾åºæ¯è¼é»ãéäºå·®è·åæ¬ä»»åè¨­è¨ãåèèé¸æåè©éææ¨ç¼ºä¹ç³»çµ±æ§çä¸è´æ§ãæ­¤å¤ï¼éè¦æç³»çµ±çæ¹æ³ä¾åæè³æåå ±åçµæï¼éä¹æ¯æç¼ºä¹çãå æ­¤ï¼æåæåºä¸¦ä»ç´¹ä¸åä½¿ç¨èåå®ï¼ç¨æ¼ KGCï¼æ¨å¨è§£æ±ºéåææ°ãå¨å¯è½çç¯åå§ï¼æåå¾æåèªçºé©åæ­¤é¡åå®çæç»ä¸­æ±²åä¸¦æ¡ç¨åç´ ãå æ­¤ï¼è©²åå®åè¨±æ¯è¼ RDF å°æèªè¨æ ¸å¿åè½çèªè¨åæè¡ï¼èå¤§å¤æ¸å¶ä»æåé²çæè¡åå·¥å·é½æ¶µèäºéä¸é»ãæåéæåºå¦ä½ä¿®æ¹åå®ä»¥æ¯è¼å»¶ä¼¸ (RML)ãæ­¤åå®æä¾äºä¸åéè¦çæ­¥é©ï¼æåæ´å·å¯æ¯è¼æ§ç KGC ä½¿ç¨èç ç©¶è©ééé²ã

##### **Self-guided Knowledgeable Network of Thoughts: Amplifying Reasoning with Large Language Models**
2412.16533v1 by Chao-Chi Chen, Chin-Yuan Yeh, Hsi-Wen Chen, De-Nian Yang, Ming-Syan Chen

We introduce Knowledgeable Network of Thoughts (kNoT): a prompt scheme that
advances the capabilities of large language models (LLMs) beyond existing
paradigms like Chain-of-Thought (CoT), Tree of Thoughts (ToT), and Graph of
Thoughts (GoT). The key innovation of kNoT is the LLM Workflow Template (LWT),
which allows for an executable plan to be specified by LLMs for LLMs. LWT
allows these plans to be arbitrary networks, where single-step LLM operations
are nodes, and edges correspond to message passing between these steps.
Furthermore, LWT supports selection of individual elements through indexing,
facilitating kNoT to produce intricate plans where each LLM operation can be
limited to elementary operations, greatly enhancing reliability over extended
task sequences. We demonstrate that kNoT significantly outperforms the state of
the art on six use cases, while reducing the need for extensive prompt
engineering. For instance, kNoT finds 92% accuracy for sorting 32 numbers over
12% and 31% for ToT and GoT, while utilizing up to 84.4% and 87.3% less
task-specific prompts, respectively.

æè¦ï¼æåå¼å¥äºææ³ç¥è­ç¶²è·¯ (kNoT)ï¼ä¸ç¨®æç¤ºæ¶æ§ï¼å®å°å¤§åèªè¨æ¨¡å (LLM) çè½åæåå°äºè¶è¶ç¾æç¯ä¾çå¢çï¼ä¾å¦ææ³é (CoT)ãææ³æ¨¹ (ToT) åææ³å (GoT)ãkNoT çééµåµæ°æ¯ LLM å·¥ä½æµç¨ç¯æ¬ (LWT)ï¼å®åè¨± LLM çº LLM æå®ä¸åå¯å·è¡çè¨ç«ãLWT åè¨±éäºè¨ç«æçºä»»æç¶²è·¯ï¼å¶ä¸­å®æ­¥ LLM æä½çºç¯é»ï¼èéç·£å°ææ¼éäºæ­¥é©ä¹éçè¨æ¯å³éãæ­¤å¤ï¼LWT æ¯æ´ééç´¢å¼é¸ååå¥åç´ ï¼é²èè® kNoT è½å¤ å¶å®è¤éçè¨ç«ï¼å¶ä¸­æ¯å LLM æä½é½å¯ä»¥éå¶çºåºæ¬æä½ï¼å¤§å¹æåå»¶ä¼¸ä»»ååºåçå¯é æ§ãæåè­æ kNoT å¨å­åç¨ä¾ä¸é¡¯èåªæ¼ç¾ææè¡ï¼åææ¸å°äºå°å»£æ³æç¤ºå·¥ç¨çéæ±ãä¾å¦ï¼kNoT å¨å° 32 åæ¸å­é²è¡æåºæç¼ç¾ 92% çæºç¢ºçï¼è ToT å GoT çº 12% å 31%ï¼åæåå¥å©ç¨äºå°é 84.4% å 87.3% çç¹å®ä»»åæç¤ºã

##### **Beyond End-to-End VLMs: Leveraging Intermediate Text Representations for Superior Flowchart Understanding**
2412.16420v1 by Junyi Ye, Ankan Dash, Wenpeng Yin, Guiling Wang

Flowcharts are typically presented as images, driving the trend of using
vision-language models (VLMs) for end-to-end flowchart understanding. However,
two key challenges arise: (i) Limited controllability--users have minimal
influence over the downstream task, as they can only modify input images, while
the training of VLMs is often out of reach for most researchers. (ii) Lack of
explainability--it is difficult to trace VLM errors to specific causes, such as
failures in visual encoding or reasoning. We propose TextFlow, addressing
aforementioned issues with two stages: (i) Vision Textualizer--which generates
textual representations from flowchart images; and (ii) Textual Reasoner--which
performs question-answering based on the text representations. TextFlow offers
three key advantages: (i) users can select the type of text representations
(e.g., Graphviz, Mermaid, PlantUML), or further convert them into executable
graph object to call tools, enhancing performance and controllability; (ii) it
improves explainability by helping to attribute errors more clearly to visual
or textual processing components; and (iii) it promotes the modularization of
the solution, such as allowing advanced LLMs to be used in the Reasoner stage
when VLMs underperform in end-to-end fashion. Experiments on the FlowVQA and
FlowLearn benchmarks demonstrate TextFlow's state-of-the-art performance as
well as its robustness. All code is publicly available.

æè¦ï¼æµç¨åéå¸¸ä»¥å½±ååç¾ï¼æ¨åäºä½¿ç¨è¦è¦ºèªè¨æ¨¡å (VLM) é²è¡ç«¯å°ç«¯æµç¨åçè§£çè¶¨å¢ãç¶èï¼åºç¾äºå©åééµææ°ï¼(i) å¯æ§æ§æéââä½¿ç¨èå°ä¸æ¸¸ä»»åçå½±é¿å¾å°ï¼å çºä»ååªè½ä¿®æ¹è¼¸å¥å½±åï¼èå¤§å¤æ¸ç ç©¶äººå¡å¾å¾ç¡æ³è¨ç·´ VLMã(ii) ç¼ºä¹å¯è§£éæ§ââé£ä»¥è¿½æº¯ VLM é¯èª¤å°å·é«åå ï¼ä¾å¦è¦è¦ºç·¨ç¢¼ææ¨çå¤±æãæåæåº TextFlowï¼ééå©åéæ®µä¾è§£æ±ºä¸è¿°åé¡ï¼(i) è¦è¦ºæå­åå¨ââå¾æµç¨åå½±åç¢çæå­è¡¨ç¤ºï¼(ii) æå­æ¨çå¨ââæ ¹ææå­è¡¨ç¤ºå·è¡åç­ãTextFlow æä¾äºä¸åä¸»è¦åªé»ï¼(i) ä½¿ç¨èå¯ä»¥é¸ææå­è¡¨ç¤ºçé¡åï¼ä¾å¦ GraphvizãMermaidãPlantUMLï¼ï¼æé²ä¸æ­¥å°å®åè½æçºå¯å·è¡çåå½¢ç©ä»¶ä¾å¼å«å·¥å·ï¼å¢å¼·æè½åå¯æ§æ§ï¼(ii) å®ééå¹«å©æ´æ¸æ¥å°å°é¯èª¤æ­¸å æ¼è¦è¦ºææå­èçåä»¶ä¾æ¹åå¯è§£éæ§ï¼(iii) å®ä¿é²äºè§£æ±ºæ¹æ¡çæ¨¡çµåï¼ä¾å¦åè¨±å¨ VLM å¨ç«¯å°ç«¯æ¨¡å¼ä¸è¡¨ç¾ä¸ä½³æï¼å¨æ¨çå¨éæ®µä½¿ç¨é²é LLMãå¨ FlowVQA å FlowLearn åºæºä¸çå¯¦é©è­æäº TextFlow çæåé²æè½ä»¥åå¶ç©©å¥æ§ãææç¨å¼ç¢¼é½å¬éå¯ç¨ã

##### **HybGRAG: Hybrid Retrieval-Augmented Generation on Textual and Relational Knowledge Bases**
2412.16311v1 by Meng-Chieh Lee, Qi Zhu, Costas Mavromatis, Zhen Han, Soji Adeshina, Vassilis N. Ioannidis, Huzefa Rangwala, Christos Faloutsos

Given a semi-structured knowledge base (SKB), where text documents are
interconnected by relations, how can we effectively retrieve relevant
information to answer user questions? Retrieval-Augmented Generation (RAG)
retrieves documents to assist large language models (LLMs) in question
answering; while Graph RAG (GRAG) uses structured knowledge bases as its
knowledge source. However, many questions require both textual and relational
information from SKB - referred to as "hybrid" questions - which complicates
the retrieval process and underscores the need for a hybrid retrieval method
that leverages both information. In this paper, through our empirical analysis,
we identify key insights that show why existing methods may struggle with
hybrid question answering (HQA) over SKB. Based on these insights, we propose
HybGRAG for HQA consisting of a retriever bank and a critic module, with the
following advantages: (1) Agentic, it automatically refines the output by
incorporating feedback from the critic module, (2) Adaptive, it solves hybrid
questions requiring both textual and relational information with the retriever
bank, (3) Interpretable, it justifies decision making with intuitive refinement
path, and (4) Effective, it surpasses all baselines on HQA benchmarks. In
experiments on the STaRK benchmark, HybGRAG achieves significant performance
gains, with an average relative improvement in Hit@1 of 51%.

æè¦ï¼<paragraph>çµ¦å®ä¸ååçµæ§åç¥è­åº« (SKB)ï¼å¶ä¸­ææ¬æä»¶ç±éä¿ç¸äºé£æ¥ï¼æåå¦ä½ææå°æ·åç¸éè³è¨ä¾åç­ä½¿ç¨èçåé¡ï¼æ·åå¢å¼·çæ (RAG) æ·åæä»¶ä»¥åå©å¤§åèªè¨æ¨¡å (LLM) åç­åé¡ï¼èåå½¢ RAG (GRAG) ä½¿ç¨çµæ§åç¥è­åº«ä½çºå¶ç¥è­ä¾æºãç¶èï¼è¨±å¤åé¡éè¦ä¾èª SKB çæå­åéä¿è³è¨ï¼ç¨±çºãæ··åãåé¡ï¼éä½¿å¾æ·åéç¨è¤éåï¼ä¸¦å¼·èª¿éè¦ä¸ç¨®å©ç¨éå©ç¨®è³è¨çæ··åæ·åæ¹æ³ãå¨æ¬æä¸­ï¼ééæåçå¯¦è­åæï¼æåæ¾åºé¡¯ç¤ºç¾ææ¹æ³å¯è½é£ä»¥å¨ SKB ä¸é²è¡æ··ååé¡è§£ç­ (HQA) çééµè¦è§£ãæ ¹æéäºè¦è§£ï¼æåæåºç±æ·åå¨åº«åæ¹è©æ¨¡çµçµæãå·æä»¥ä¸åªé»ç HQA HybGRAGï¼(1) ä»£çï¼å®ééç´å¥æ¹è©æ¨¡çµçåé¥èªåç²¾çè¼¸åºï¼(2) é©æï¼å®ä½¿ç¨æ·åå¨åº«è§£æ±ºéè¦æå­åéä¿è³è¨çæ··ååé¡ï¼(3) å¯è§£éï¼å®ä»¥ç´è¦ºçç²¾çè·¯å¾è­ææ±ºç­ï¼ä»¥å (4) ææï¼å®è¶è¶äº HQA åºæºçææåºæºãå¨ STaRK åºæºçå¯¦é©ä¸­ï¼HybGRAG éå°äºé¡¯èçæè½æåï¼Hit@1 çå¹³åç¸å°æ¹åçº 51%ã</paragraph>

##### **Logical Consistency of Large Language Models in Fact-checking**
2412.16100v1 by Bishwamittra Ghosh, Sarah Hasan, Naheed Anjum Arafat, Arijit Khan

In recent years, large language models (LLMs) have demonstrated significant
success in performing varied natural language tasks such as language
translation, question-answering, summarizing, fact-checking, etc. Despite LLMs'
impressive ability to generate human-like texts, LLMs are infamous for their
inconsistent responses -- a meaning-preserving change in the input query
results in an inconsistent response and attributes to vulnerabilities of LLMs
such as hallucination, jailbreaking, etc. Consequently, existing research
focuses on simple paraphrasing-based consistency assessment of LLMs, and
ignores complex queries that necessitates an even better understanding of
logical reasoning by an LLM. Our work therefore addresses the logical
inconsistency of LLMs under complex logical queries with primitive logical
operators, e.g., negation, conjunction, and disjunction. As a test bed, we
consider retrieval-augmented LLMs on a fact-checking task involving
propositional logic queries from real-world knowledge graphs (KGs). Our
contributions are three-fold. Benchmark: We introduce three logical
fact-checking datasets over KGs for community development towards logically
consistent LLMs. Assessment: We propose consistency measures of LLMs on
propositional logic queries as input and demonstrate that existing LLMs lack
logical consistency, specially on complex queries. Improvement: We employ
supervised fine-tuning to improve the logical consistency of LLMs on the
complex fact-checking task with KG contexts.

æè¦ï¼è¿å¹´ä¾ï¼å¤§åèªè¨æ¨¡å (LLM) å¨å·è¡åç¨®èªç¶èªè¨ä»»åï¼ä¾å¦èªè¨ç¿»è­¯ãåç­ãæè¦ãäºå¯¦æ¥æ ¸ç­ï¼æ¹é¢å±ç¾åºé¡¯èçæåãåç®¡ LLM è½ç¢çé¡ä¼¼äººé¡çæå­ï¼ä½ LLM ä»¥å¶ä¸ä¸è´çåæèè­åæ­èââè¼¸å¥æ¥è©¢ä¸­ä¸åä¿ææ¹è®æå°è´ä¸ä¸è´çåæï¼ä¸¦æ­¸å æ¼ LLM çæ¼æ´ï¼ä¾å¦å¹»è¦ºãè¶çç­ãå æ­¤ï¼ç¾æçç ç©¶å°æ³¨æ¼ LLM çåºæ¼ç°¡å®æ¹å¯«çä¸è´æ§è©ä¼°ï¼èå¿½ç¥äºéè¦ LLM æ´æ·±å¥çè§£éè¼¯æ¨ççè¤éæ¥è©¢ãå æ­¤ï¼æåçç ç©¶è§£æ±ºäº LLM å¨å·æåºæ¬éè¼¯éç®åï¼ä¾å¦å¦å®ãåååæåï¼çè¤ééè¼¯æ¥è©¢ä¸çéè¼¯ä¸ä¸è´æ§ãä½çºä¸åæ¸¬è©¦å¹³å°ï¼æåèæ®å¨ä¸åæ¶åä¾èªçå¯¦ä¸çç¥è­åè­ (KG) çå½é¡éè¼¯æ¥è©¢çäºå¯¦æ¥æ ¸ä»»åä¸­ï¼æª¢ç´¢å¢å¼·ç LLMãæåçè²¢ç»æä¸æ¹é¢ãåºæºï¼æåå¨ KG ä¸å¼å¥äºä¸åéè¼¯äºå¯¦æ¥æ ¸æ¸æéï¼ä»¥ä¿é²ç¤¾åéç¼éè¼¯ä¸è´ç LLMãè©ä¼°ï¼æåæåºäº LLM å¨å½é¡éè¼¯æ¥è©¢ä½çºè¼¸å¥ä¸çä¸è´æ§æ¸¬éï¼ä¸¦è­æç¾æç LLM ç¼ºä¹éè¼¯ä¸è´æ§ï¼ç¹å¥æ¯å¨è¤éæ¥è©¢ä¸ãæ¹é²ï¼æåæ¡ç¨ç£ç£å¾®èª¿ä¾æé« LLM å¨å·æ KG èæ¯çè¤éäºå¯¦æ¥æ ¸ä»»åä¸çéè¼¯ä¸è´æ§ã

##### **GraphSeqLM: A Unified Graph Language Framework for Omic Graph Learning**
2412.15790v1 by Heming Zhang, Di Huang, Yixin Chen, Fuhai Li

The integration of multi-omic data is pivotal for understanding complex
diseases, but its high dimensionality and noise present significant challenges.
Graph Neural Networks (GNNs) offer a robust framework for analyzing large-scale
signaling pathways and protein-protein interaction networks, yet they face
limitations in expressivity when capturing intricate biological relationships.
To address this, we propose Graph Sequence Language Model (GraphSeqLM), a
framework that enhances GNNs with biological sequence embeddings generated by
Large Language Models (LLMs). These embeddings encode structural and biological
properties of DNA, RNA, and proteins, augmenting GNNs with enriched features
for analyzing sample-specific multi-omic data. By integrating topological,
sequence-derived, and biological information, GraphSeqLM demonstrates superior
predictive accuracy and outperforms existing methods, paving the way for more
effective multi-omic data integration in precision medicine.

æè¦ï¼æ´åå¤çµå­¸è³æå°æ¼çè§£è¤éç¾çè³ééè¦ï¼ä½å¶é«ç¶­åº¦åéè¨æé æé¡¯èçææ°ãåç¥ç¶ç¶²è·¯ (GNN) æä¾äºä¸åå¼·å¥çæ¶æ§ï¼ç¨æ¼åæå¤§è¦æ¨¡ä¿¡èè·¯å¾åèç½è³ª-èç½è³ªäº¤äºç¶²è·¯ï¼ç¶èå®åå¨ææè¤éççç©éä¿æï¼å¨è¡¨ç¾åæ¹é¢é¢è¨éå¶ãçºäºè§£æ±ºéååé¡ï¼æåæåºäºååºåèªè¨æ¨¡å (GraphSeqLM)ï¼ä¸åå¢å¼· GNN çæ¶æ§ï¼ééå¤§åèªè¨æ¨¡å (LLM) çæççç©åºååµå¥ãéäºåµå¥ç·¨ç¢¼äº DNAãRNA åèç½è³ªççµæ§åçç©ç¹æ§ï¼ééè±å¯çç¹æ§æ´å GNNï¼ç¨æ¼åæç¹å®æ¨£æ¬çå¤çµå­¸è³æãééæ´åææ²ãåºåè¡çåçç©è³è¨ï¼GraphSeqLM å±ç¾äºåªè¶çé æ¸¬æºç¢ºåº¦ï¼ä¸¦åªæ¼ç¾ææ¹æ³ï¼çºç²¾æºé«çä¸­æ´ææçå¤çµå­¸è³ææ´åéªè·¯ã

##### **KRAIL: A Knowledge-Driven Framework for Base Human Reliability Analysis Integrating IDHEAS and Large Language Models**
2412.18627v1 by Xingyu Xiao, Peng Chen, Ben Qi, Hongru Zhao, Jingang Liang, Jiejuan Tong, Haitao Wang

Human reliability analysis (HRA) is crucial for evaluating and improving the
safety of complex systems. Recent efforts have focused on estimating human
error probability (HEP), but existing methods often rely heavily on expert
knowledge,which can be subjective and time-consuming. Inspired by the success
of large language models (LLMs) in natural language processing, this paper
introduces a novel two-stage framework for knowledge-driven reliability
analysis, integrating IDHEAS and LLMs (KRAIL). This innovative framework
enables the semi-automated computation of base HEP values. Additionally,
knowledge graphs are utilized as a form of retrieval-augmented generation (RAG)
for enhancing the framework' s capability to retrieve and process relevant data
efficiently. Experiments are systematically conducted and evaluated on
authoritative datasets of human reliability. The experimental results of the
proposed methodology demonstrate its superior performance on base HEP
estimation under partial information for reliability assessment.

æè¦ï¼äººé¡å¯é åº¦åæ (HRA) å°æ¼è©ä¼°åæåè¤éç³»çµ±çå®å¨æ§è³ééè¦ãæè¿çåªåå°æ³¨æ¼ä¼°è¨äººçºé¯èª¤æ©ç (HEP)ï¼ä½ç¾ææ¹æ³éå¸¸é«åº¦ä¾è³´å°å®¶ç¥è­ï¼èéå¯è½æå¸¶æä¸»è§æ§ä¸èæãåå°å¤§åèªè¨æ¨¡å (LLM) å¨èªç¶èªè¨èçä¸­æåçåç¼ï¼æ¬æä»ç´¹äºä¸åæ°ç©çå©éæ®µæ¶æ§ï¼ç¨æ¼ç¥è­é©åçå¯é åº¦åæï¼æ´å IDHEAS å LLM (KRAIL)ãéååµæ°çæ¶æ§è½åèªååè¨ç®åºæ¬ HEP å¼ãæ­¤å¤ï¼ç¥è­åè­è¢«ç¨ä½æª¢ç´¢å¢å¼·çæ (RAG) çä¸ç¨®å½¢å¼ï¼ç¨æ¼å¢å¼·æ¶æ§ææçå°æª¢ç´¢åèçç¸éè³æçè½åãç³»çµ±æ§å°éå°äººé¡å¯é åº¦çæ¬å¨è³æéé²è¡å¯¦é©ä¸¦è©ä¼°ãææåºçæ¹æ³çå¯¦é©çµæè­æäºå¶å¨é¨åè³è¨ä¸é²è¡å¯é åº¦è©ä¼°æï¼å¨åºæ¬ HEP ä¼°è¨ä¸çåªç°æè½ã

##### **NGQA: A Nutritional Graph Question Answering Benchmark for Personalized Health-aware Nutritional Reasoning**
2412.15547v1 by Zheyuan Zhang, Yiyang Li, Nhi Ha Lan Le, Zehong Wang, Tianyi Ma, Vincent Galassi, Keerthiram Murugesan, Nuno Moniz, Werner Geyer, Nitesh V Chawla, Chuxu Zhang, Yanfang Ye

Diet plays a critical role in human health, yet tailoring dietary reasoning
to individual health conditions remains a major challenge. Nutrition Question
Answering (QA) has emerged as a popular method for addressing this problem.
However, current research faces two critical limitations. On one hand, the
absence of datasets involving user-specific medical information severely limits
\textit{personalization}. This challenge is further compounded by the wide
variability in individual health needs. On the other hand, while large language
models (LLMs), a popular solution for this task, demonstrate strong reasoning
abilities, they struggle with the domain-specific complexities of personalized
healthy dietary reasoning, and existing benchmarks fail to capture these
challenges. To address these gaps, we introduce the Nutritional Graph Question
Answering (NGQA) benchmark, the first graph question answering dataset designed
for personalized nutritional health reasoning. NGQA leverages data from the
National Health and Nutrition Examination Survey (NHANES) and the Food and
Nutrient Database for Dietary Studies (FNDDS) to evaluate whether a food is
healthy for a specific user, supported by explanations of the key contributing
nutrients. The benchmark incorporates three question complexity settings and
evaluates reasoning across three downstream tasks. Extensive experiments with
LLM backbones and baseline models demonstrate that the NGQA benchmark
effectively challenges existing models. In sum, NGQA addresses a critical
real-world problem while advancing GraphQA research with a novel
domain-specific benchmark.

æè¦ï¼é£²é£å¨äººé¡å¥åº·ä¸­æ®æ¼èè³ééè¦çè§è²ï¼ç¶èæ ¹æåäººå¥åº·çæ³èª¿æ´é£²é£æ¨çä»ç¶æ¯ä¸é éå¤§çææ°ãçé¤åé¡åç­ (QA) å·²æçºè§£æ±ºæ­¤åé¡çæµè¡æ¹æ³ãä¸éï¼ç®åçç ç©¶é¢è¨å©é éå¤§çéå¶ãä¸æ¹é¢ï¼ç¼ºä¹åå«ä½¿ç¨èç¹å®é«çè³è¨çè³æéå´ééå¶äºãåäººåããéåææ°é²ä¸æ­¥åå°åäººå¥åº·éæ±å»£æ³è®ç°çå½±é¿ãå¦ä¸æ¹é¢ï¼éç¶å¤§åèªè¨æ¨¡å (LLM) æ¯æ­¤ä»»åçç±éè§£æ±ºæ¹æ¡ï¼å±ç¤ºåºå¼·å¤§çæ¨çè½åï¼ä½å®åå¨åäººåå¥åº·é£²é£æ¨ççç¹å®é åè¤éæ§ä¸ä»æå°é£ï¼èç¾æçåºæºä¹ç¡æ³ææéäºææ°ãçºäºè§£æ±ºéäºå·®è·ï¼æåå¼å¥äºçé¤åè¡¨åç­ (NGQA) åºæºï¼éæ¯ç¬¬ä¸åå°çºåäººåçé¤å¥åº·æ¨çè¨­è¨çåè¡¨åç­è³æéãNGQA å©ç¨åå®¶å¥åº·èçé¤æª¢æ¥èª¿æ¥ (NHANES) åé£²é£ç ç©¶é£ç©èçé¤è³æåº« (FNDDS) çè³æï¼è©ä¼°é£ç©æ¯å¦å°ç¹å®ä½¿ç¨èå¥åº·ï¼ä¸¦èªªæä¸»è¦è²¢ç»çé¤ç´ ãæ­¤åºæºç´å¥äºä¸ååé¡è¤éåº¦è¨­å®ï¼ä¸¦è©ä¼°ä¸åä¸æ¸¸ä»»åçæ¨çãä½¿ç¨ LLM ä¸»å¹¹ååºç·æ¨¡åé²è¡çå»£æ³å¯¦é©è­æï¼NGQA åºæºææææ°äºç¾ææ¨¡åãç¸½ä¹ï¼NGQA è§£æ±ºäºä¸åéå¤§çç¾å¯¦ä¸çåé¡ï¼åæééæ°ç©çç¹å®é ååºæºæ¨åäº GraphQA ç ç©¶ã

##### **SKETCH: Structured Knowledge Enhanced Text Comprehension for Holistic Retrieval**
2412.15443v1 by Aakash Mahalingam, Vinesh Kumar Gande, Aman Chadha, Vinija Jain, Divya Chaudhary

Retrieval-Augmented Generation (RAG) systems have become pivotal in
leveraging vast corpora to generate informed and contextually relevant
responses, notably reducing hallucinations in Large Language Models. Despite
significant advancements, these systems struggle to efficiently process and
retrieve information from large datasets while maintaining a comprehensive
understanding of the context. This paper introduces SKETCH, a novel methodology
that enhances the RAG retrieval process by integrating semantic text retrieval
with knowledge graphs, thereby merging structured and unstructured data for a
more holistic comprehension. SKETCH, demonstrates substantial improvements in
retrieval performance and maintains superior context integrity compared to
traditional methods. Evaluated across four diverse datasets: QuALITY, QASPER,
NarrativeQA, and Italian Cuisine-SKETCH consistently outperforms baseline
approaches on key RAGAS metrics such as answer_relevancy, faithfulness,
context_precision and context_recall. Notably, on the Italian Cuisine dataset,
SKETCH achieved an answer relevancy of 0.94 and a context precision of 0.99,
representing the highest performance across all evaluated metrics. These
results highlight SKETCH's capability in delivering more accurate and
contextually relevant responses, setting new benchmarks for future retrieval
systems.

æè¦ï¼æ·åå¢å¼·çæ (RAG) ç³»çµ±å·²æçºå©ç¨é¾å¤§èªæåº«ä¾ç¢çææºä¸èæå¢ç¸éåæçééµï¼ç¹å¥æ¯æ¸å°å¤§åèªè¨æ¨¡åä¸­çå¹»è¦ºãåç®¡æé¡¯èçé²å±ï¼ä½éäºç³»çµ±å¨èçåæ·åä¾èªå¤§åè³æéçè³è¨æä»æå°é£ï¼åæéè¦ç¶­æå°æå¢çå¨é¢çè§£ãæ¬æä»ç´¹ SKETCHï¼ä¸ç¨®ééå°èªææå­æ·åèç¥è­åè¡¨æ´åï¼èæ­¤åä½µçµæ§ååéçµæ§åè³æä»¥ç²å¾æ´å¨é¢ççè§£ï¼ä¾å¢å¼· RAG æ·åç¨åºçåµæ°æ¹æ³ãSKETCH å¨æ·åæè½æ¹é¢å±ç¾åºé¡¯èçé²æ­¥ï¼ä¸¦èå³çµ±æ¹æ³ç¸æ¯ç¶­æè¼ä½³çæå¢å®æ´æ§ãå¨ååä¸åçè³æéï¼QuALITYãQASPERãNarrativeQA å Italian Cuisine ä¸­é²è¡è©ä¼°ï¼SKETCH å¨ééµç RAGAS ææ¨ï¼ä¾å¦ answer_relevancyãfaithfulnessãcontext_precision å context_recallï¼ä¸å§çµåªæ¼åºæºæ¹æ³ãå¼å¾æ³¨æçæ¯ï¼å¨ Italian Cuisine è³æéä¸ï¼SKETCH ç answer relevancy éå° 0.94ï¼context precision éå° 0.99ï¼ä»£è¡¨å¨ææè©ä¼°ææ¨ä¸­è¡¨ç¾æä½³ãéäºçµæçªé¡¯äº SKETCH å¨æä¾æ´æºç¢ºä¸èæå¢ç¸éåæçè½åï¼çºæªä¾çæ·åç³»çµ±æ¨¹ç«äºæ°çåºæºã

##### **Graph-Convolutional Networks: Named Entity Recognition and Large Language Model Embedding in Document Clustering**
2412.14867v1 by Imed Keraghel, Mohamed Nadif

Recent advances in machine learning, particularly Large Language Models
(LLMs) such as BERT and GPT, provide rich contextual embeddings that improve
text representation. However, current document clustering approaches often
ignore the deeper relationships between named entities (NEs) and the potential
of LLM embeddings. This paper proposes a novel approach that integrates Named
Entity Recognition (NER) and LLM embeddings within a graph-based framework for
document clustering. The method builds a graph with nodes representing
documents and edges weighted by named entity similarity, optimized using a
graph-convolutional network (GCN). This ensures a more effective grouping of
semantically related documents. Experimental results indicate that our approach
outperforms conventional co-occurrence-based methods in clustering, notably for
documents rich in named entities.

æè¦ï¼è¿ææ©å¨å­¸ç¿çé²å±ï¼ç¹å¥æ¯å¤§åèªè¨æ¨¡å (LLM)ï¼ä¾å¦ BERT å GPTï¼æä¾äºè±å¯çä¸ä¸æåµå¥ï¼æ¹é²äºææ¬è¡¨å¾µãç¶èï¼ç¶åçæä»¶åç¾¤æ¹æ³éå¸¸å¿½ç¥å½åå¯¦é« (NE) ä¹éæ´æ·±å±¤çéä¿å LLM åµå¥çæ½åãæ¬ææåºäºä¸ç¨®åµæ°çæ¹æ³ï¼å°å½åå¯¦é«è¾¨è­ (NER) å LLM åµå¥æ´åå°åºæ¼åå½¢çæ¶æ§ä¸­ï¼ä»¥é²è¡æä»¶åç¾¤ãè©²æ¹æ³å»ºç«äºä¸ååå½¢ï¼å¶ä¸­ç¯é»ä»£è¡¨æä»¶ï¼éç·£åç±å½åå¯¦é«ç¸ä¼¼æ§å æ¬ï¼ä¸¦ä½¿ç¨åå½¢å·ç©ç¶²è·¯ (GCN) é²è¡æä½³åãéç¢ºä¿äºèªç¾©ç¸éæä»¶æ´ææçåçµãå¯¦é©çµæè¡¨æï¼æåçåæ³åªæ¼å³çµ±çå±ç¾æ¹æ³å¨åç¾¤ä¸­çè¡¨ç¾ï¼ç¹å¥æ¯å°æ¼å¯å«å½åå¯¦é«çæä»¶ã

##### **Answer Set Networks: Casting Answer Set Programming into Deep Learning**
2412.14814v1 by Arseny Skryagin, Daniel Ochs, Phillip Deibert, Simon Kohaut, Devendra Singh Dhami, Kristian Kersting

Although Answer Set Programming (ASP) allows constraining neural-symbolic
(NeSy) systems, its employment is hindered by the prohibitive costs of
computing stable models and the CPU-bound nature of state-of-the-art solvers.
To this end, we propose Answer Set Networks (ASN), a NeSy solver. Based on
Graph Neural Networks (GNN), ASNs are a scalable approach to ASP-based Deep
Probabilistic Logic Programming (DPPL). Specifically, we show how to translate
ASPs into ASNs and demonstrate how ASNs can efficiently solve the encoded
problem by leveraging GPU's batching and parallelization capabilities. Our
experimental evaluations demonstrate that ASNs outperform state-of-the-art
CPU-bound NeSy systems on multiple tasks. Simultaneously, we make the following
two contributions based on the strengths of ASNs. Namely, we are the first to
show the finetuning of Large Language Models (LLM) with DPPLs, employing ASNs
to guide the training with logic. Further, we show the "constitutional
navigation" of drones, i.e., encoding public aviation laws in an ASN for
routing Unmanned Aerial Vehicles in uncertain environments.

æè¦ï¼åç®¡ç­æ¡éç¨å¼è¨­è¨ï¼ASPï¼åè¨±ç´æç¥ç¶ç¬¦èï¼NeSyï¼ç³»çµ±ï¼ä½å¶æç¨åå°è¨ç®ç©©å®æ¨¡åçéé«ææ¬åç¾ææ±è§£å¨å CPU éå¶çæ¬è³ªæé»ç¤ãçºæ­¤ï¼æåæåºç­æ¡éç¶²è·¯ï¼ASNï¼ï¼ä¸å NeSy æ±è§£å¨ãASN åºæ¼åç¥ç¶ç¶²è·¯ï¼GNNï¼ï¼æ¯ä¸ç¨®åºæ¼ ASP çæ·±åº¦æ©çéè¼¯ç¨å¼è¨­è¨ï¼DPPLï¼çå¯æ´åæ¹æ³ãå·é«ä¾èªªï¼æåå±ç¤ºå¦ä½å° ASP è½æçº ASNï¼ä¸¦å±ç¤º ASN å¦ä½ééå©ç¨ GPU çæ¹æ¬¡èçåä¸¦è¡ååè½ææå°è§£æ±ºç·¨ç¢¼åé¡ãæåçå¯¦é©è©ä¼°è¡¨æï¼ASN å¨å¤é ä»»åä¸åªæ¼ç¾æçå CPU éå¶ç NeSy ç³»çµ±ãåæï¼æåæ ¹æ ASN çåªå¢ååºäºä»¥ä¸å©é è²¢ç»ãä¹å°±æ¯èªªï¼æåé¦æ¬¡å±ç¤ºä½¿ç¨ DPPL å°å¤§åèªè¨æ¨¡åï¼LLMï¼é²è¡å¾®èª¿ï¼ä½¿ç¨ ASN ä»¥éè¼¯å¼å°è¨ç·´ãæ­¤å¤ï¼æåå±ç¤ºäºç¡äººæ©çãæ²æ³å°èªãï¼å³å¨ ASN ä¸­ç·¨ç¢¼å¬å±èªç©ºæ³ï¼ä»¥ä¾¿å¨ä¸ç¢ºå®çç°å¢ä¸­å°ç¡äººæ©é²è¡è·¯ç±ã

##### **IOHunter: Graph Foundation Model to Uncover Online Information Operations**
2412.14663v1 by Marco Minici, Luca Luceri, Francesco Fabbri, Emilio Ferrara

Social media platforms have become vital spaces for public discourse, serving
as modern agor\'as where a wide range of voices influence societal narratives.
However, their open nature also makes them vulnerable to exploitation by
malicious actors, including state-sponsored entities, who can conduct
information operations (IOs) to manipulate public opinion. The spread of
misinformation, false news, and misleading claims threatens democratic
processes and societal cohesion, making it crucial to develop methods for the
timely detection of inauthentic activity to protect the integrity of online
discourse. In this work, we introduce a methodology designed to identify users
orchestrating information operations, a.k.a. \textit{IO drivers}, across
various influence campaigns. Our framework, named \texttt{IOHunter}, leverages
the combined strengths of Language Models and Graph Neural Networks to improve
generalization in \emph{supervised}, \emph{scarcely-supervised}, and
\emph{cross-IO} contexts. Our approach achieves state-of-the-art performance
across multiple sets of IOs originating from six countries, significantly
surpassing existing approaches. This research marks a step toward developing
Graph Foundation Models specifically tailored for the task of IO detection on
social media platforms.

æè¦ï¼ç¤¾äº¤åªé«å¹³å°å·²æçºå¬å±è«è¿°çéè¦ç©ºéï¼ä½çºç¾ä»£å»£å ´ï¼åç¨®è²é³å½±é¿èç¤¾ææäºãç¶èï¼å®åçéæ¾æ§ä¹ä½¿å¾å®åå®¹æåå°æ¡æè¡çºèçå©ç¨ï¼åæ¬åå®¶è³å©çå¯¦é«ï¼ä»åå¯ä»¥é²è¡ä¿¡æ¯æä½ (IO) ä»¥æç¸±è¼¿è«ãé¯èª¤ä¿¡æ¯çå³æ­ãèåæ°èåèª¤å°æ§èªªæ³å¨èèæ°ä¸»é²ç¨åç¤¾æåèåï¼å æ­¤å¶å®åææª¢æ¸¬èåæ´»åä»¥ä¿è­·å¨ç·è«è¿°çå®æ´æ§çæ¹æ³è³ééè¦ãå¨éé å·¥ä½ä¸­ï¼æåä»ç´¹äºä¸ç¨®æ¹æ³ï¼æ¨å¨è­å¥å¨åç¨®å½±é¿åéåä¸­ç­åä¿¡æ¯è¡åçç¨æ¶ï¼å³æè¬çãIO é©åç¨åºããæåçæ¡æ¶åçº \texttt{IOHunter}ï¼å®å©ç¨èªè¨æ¨¡åååç¥ç¶ç¶²è·¯çç¶ååªå¢ä¾æ¹åãç£ç£ãããç¨çç£ç£ãåãè·¨ IOãæå¢ä¸­çæ³åè½åãæåçåæ³å¨ä¾èªå­ååå®¶çå¤çµ IO ä¸­å¯¦ç¾äºæåé²çæ§è½ï¼é¡¯èè¶è¶äºç¾ææ¹æ³ãéé ç ç©¶æ¨èªèå°ééå°ç¤¾äº¤åªé«å¹³å°ä¸ç IO æª¢æ¸¬ä»»åéç¼ååºç¤æ¨¡åéåºäºä¸æ­¥ã

##### **GraphEQA: Using 3D Semantic Scene Graphs for Real-time Embodied Question Answering**
2412.14480v1 by Saumya Saxena, Blake Buchanan, Chris Paxton, Bingqing Chen, Narunas Vaskevicius, Luigi Palmieri, Jonathan Francis, Oliver Kroemer

In Embodied Question Answering (EQA), agents must explore and develop a
semantic understanding of an unseen environment in order to answer a situated
question with confidence. This remains a challenging problem in robotics, due
to the difficulties in obtaining useful semantic representations, updating
these representations online, and leveraging prior world knowledge for
efficient exploration and planning. Aiming to address these limitations, we
propose GraphEQA, a novel approach that utilizes real-time 3D metric-semantic
scene graphs (3DSGs) and task relevant images as multi-modal memory for
grounding Vision-Language Models (VLMs) to perform EQA tasks in unseen
environments. We employ a hierarchical planning approach that exploits the
hierarchical nature of 3DSGs for structured planning and semantic-guided
exploration. Through experiments in simulation on the HM-EQA dataset and in the
real world in home and office environments, we demonstrate that our method
outperforms key baselines by completing EQA tasks with higher success rates and
fewer planning steps.

æè¦ï¼å¨å·èº«åç­ (EQA) ä¸­ï¼ä»£çå¿é æ¢ç´¢ä¸¦ç¼å±å°æªè¦éç°å¢çèªç¾©çè§£ï¼æè½æä¿¡å¿å°åç­æå¢åé¡ãç±æ¼é£ä»¥åå¾æç¨çèªç¾©è¡¨ç¤ºãç·ä¸æ´æ°éäºè¡¨ç¤ºï¼ä»¥åå©ç¨ååçä¸çç¥è­é²è¡ææççæ¢ç´¢åè¦åï¼éå¨æ©å¨äººå­¸ä¸­ä»ç¶æ¯ä¸åå·æææ°æ§çåé¡ãçºäºè§£æ±ºéäºéå¶ï¼æåæåº GraphEQAï¼ä¸ç¨®å©ç¨å³æ 3D åº¦éèªç¾©å ´æ¯å (3DSG) åèä»»åç¸éçå½±åä½çºå¤æ¨¡å¼è¨æ¶é«çæ°ç©æ¹æ³ï¼ä»¥æ¥å°è¦è¦ºèªè¨æ¨¡å (VLM) ä¾å·è¡æªè¦éç°å¢ä¸­ç EQA ä»»åãæåæ¡ç¨åå±¤è¦åæ¹æ³ï¼å©ç¨ 3DSG çåå±¤æ§è³ªé²è¡çµæ§åè¦ååèªç¾©å¼å°æ¢ç´¢ãééå¨ HM-EQA è³æéä¸çæ¨¡æ¬å¯¦é©ï¼ä»¥åå¨å®¶åº­åè¾¦å¬å®¤ç°å¢ä¸­ççå¯¦ä¸çä¸­ï¼æåè­ææåçæ¨¡åééä»¥è¼é«çæåçåè¼å°çè¦åæ­¥é©å®æ EQA ä»»åï¼åªæ¼ä¸»è¦çåºç·ã

##### **Discovering maximally consistent distribution of causal tournaments with Large Language Models**
2412.14019v1 by Federico Baldo, Simon Ferreira, Charles K. Assaad

Causal discovery is essential for understanding complex systems, yet
traditional methods often depend on strong, untestable assumptions, making the
process challenging. Large Language Models (LLMs) present a promising
alternative for extracting causal insights from text-based metadata, which
consolidates domain expertise. However, LLMs are prone to unreliability and
hallucinations, necessitating strategies that account for their limitations.
One such strategy involves leveraging a consistency measure to evaluate
reliability. Additionally, most text metadata does not clearly distinguish
direct causal relationships from indirect ones, further complicating the
inference of causal graphs. As a result, focusing on causal orderings, rather
than causal graphs, emerges as a more practical and robust approach. We propose
a novel method to derive a distribution of acyclic tournaments (representing
plausible causal orders) that maximizes a consistency score. Our approach
begins by computing pairwise consistency scores between variables, yielding a
cyclic tournament that aggregates these scores. From this structure, we
identify optimal acyclic tournaments compatible with the original tournament,
prioritizing those that maximize consistency across all configurations. We
tested our method on both classical and well-established bechmarks, as well as
real-world datasets from epidemiology and public health. Our results
demonstrate the effectiveness of our approach in recovering distributions
causal orders with minimal error.

æè¦ï¼å æç¼ç¾å°æ¼çè§£è¤éç³»çµ±è³ééè¦ï¼ä½å³çµ±æ¹æ³éå¸¸ä¾è³´æ¼å¼·èä¸å¯æ¸¬è©¦çåè¨­ï¼éä½¿å¾éåéç¨åæ»¿ææ°ãå¤§åèªè¨æ¨¡å (LLM) æä¾äºä¸åå¾åºæ¼ææ¬çåæ¸æä¸­æåå æè¦è§£çæå¸æçæ¿ä»£æ¹æ¡ï¼å®æ´åäºé åå°æ¥­ç¥è­ãç¶èï¼LLM å®¹æåºç¾ä¸å¯é æ§åå¹»è¦ºï¼ééè¦èæ®å¶éå¶çç­ç¥ãä¸ç¨®éæ¨£çç­ç¥æ¶åå©ç¨ä¸è´æ§åº¦éä¾è©ä¼°å¯é æ§ãæ­¤å¤ï¼å¤§å¤æ¸ææ¬åæ¸æä¸¦æªæ¸æ¥å°ååç´æ¥å æéä¿åéæ¥å æéä¿ï¼éé²ä¸æ­¥è¤éåäºå æåçæ¨è«ãå æ­¤ï¼å°æ³¨æ¼å æé åºï¼èä¸æ¯å æåï¼æçºä¸ç¨®æ´å¯¦ç¨ãæ´ç©©å¥çæ¹æ³ãæåæåºäºä¸ç¨®æ°æ¹æ³ä¾æ¨å°ç¡ç°é¦æ¨è³½çåå¸ï¼è¡¨ç¤ºåççå æé åºï¼ï¼éæå¤§åäºä¸è´æ§åæ¸ãæåçåæ³é¦åè¨ç®è®éä¹éæå°çä¸è´æ§åæ¸ï¼ç¢çä¸åå½ç¸½éäºåæ¸çå¾ªç°é¦æ¨è³½ãå¾éåçµæ§ä¸­ï¼æåè­å¥åºèåå§é¦æ¨è³½ç¸å®¹çæä½³ç¡ç°é¦æ¨è³½ï¼åªåèæ®é£äºå¨ææéç½®ä¸­æå¤§åä¸è´æ§çé¦æ¨è³½ãæåå¨ç¶å¸ä¸å®åçåºæºä»¥åä¾èªæµè¡çå­¸åå¬å±è¡çççå¯¦ä¸çæ¸æéä¸æ¸¬è©¦äºæåçæ¨¡åãæåççµæè­æäºæåçæ¹æ³å¨ä»¥æå°èª¤å·®æ¢å¾©å æé åºåå¸æ¹é¢çæææ§ã

##### **DODGE: Ontology-Aware Risk Assessment via Object-Oriented Disruption Graphs**
2412.13964v1 by Stefano M. Nicoletti, E. Moritz Hahn, Mattia Fumagalli, Giancarlo Guizzardi, MariÃ«lle Stoelinga

When considering risky events or actions, we must not downplay the role of
involved objects: a charged battery in our phone averts the risk of being
stranded in the desert after a flat tyre, and a functional firewall mitigates
the risk of a hacker intruding the network. The Common Ontology of Value and
Risk (COVER) highlights how the role of objects and their relationships remains
pivotal to performing transparent, complete and accountable risk assessment. In
this paper, we operationalize some of the notions proposed by COVER -- such as
parthood between objects and participation of objects in events/actions -- by
presenting a new framework for risk assessment: DODGE. DODGE enriches the
expressivity of vetted formal models for risk -- i.e., fault trees and attack
trees -- by bridging the disciplines of ontology and formal methods into an
ontology-aware formal framework composed by a more expressive modelling
formalism, Object-Oriented Disruption Graphs (ODGs), logic (ODGLog) and an
intermediate query language (ODGLang). With these, DODGE allows risk assessors
to pose questions about disruption propagation, disruption likelihood and risk
levels, keeping the fundamental role of objects at risk always in sight.

æè¦ï¼å¨èéé«é¢¨éªäºä»¶æè¡åæï¼æåä¸è½ä½ä¼°ææ¶ç©ä»¶çè§è²ï¼ææ©ä¸­çåé»é»æ± å¯é¿åå¨çèå¾åå°æ²æ¼ çé¢¨éªï¼èåè½æ­£å¸¸çé²ç«çåå¯éä½é§­å®¢å¥ä¾µç¶²è·¯çé¢¨éªãå¹å¼èé¢¨éªçå±ç¨æ¬ä½è« (COVER) å¼·èª¿ç©ä»¶åå¶éä¿çè§è²ï¼å°æ¼å·è¡éæãå®æ´ä¸è² è²¬ä»»çé¢¨éªè©ä¼°ä»ç¶è³ééè¦ãå¨æ¬æä¸­ï¼æåå° COVER ææåºçé¨åæ¦å¿µï¼ä¾å¦ç©ä»¶ä¹éççµæé¨åéä¿ï¼ä»¥åç©ä»¶åèäºä»¶/è¡åï¼å·é«åï¼èç±æåºä¸åæ°çé¢¨éªè©ä¼°æ¶æ§ï¼DODGEãDODGE ééå°æ¬ä½è«èå½¢å¼åæ¹æ³æ©æ¥è³ä¸åæ¬ä½è«æç¥å½¢å¼åæ¶æ§ä¸­ï¼è±å¯äºé¢¨éªé©è­å½¢å¼åæ¨¡åï¼ä¾å¦æéæ¨¹åæ»ææ¨¹ï¼çè¡¨éåï¼è©²æ¶æ§ç±æ´å·è¡¨éåçå»ºæ¨¡å½¢å¼ä¸»ç¾©ãç©ä»¶å°åä¸­æ·å (ODG)ãéè¼¯ (ODGLog) åä¸åä¸­éæ¥è©¢èªè¨ (ODGLang) çµæãéééäºï¼DODGE è®é¢¨éªè©ä¼°èè½å¤ æåºæéä¸­æ·å³æ­ãä¸­æ·å¯è½æ§åé¢¨éªå±¤ç´çåé¡ï¼åæå§çµä¿æå°é¢¨éªç©ä»¶çåºæ¬è§è²çéæ³¨ã


### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2025-01-22**|**Robust Representation Consistency Model via Contrastive Denoising**|Jiachen Lei et.al.|[2501.13094v1](http://arxiv.org/abs/2501.13094v1)|[link](https://github.com/jiachenlei/rrcm)|
|**2025-01-22**|**Boosting MCTS with Free Energy Minimization**|Mawaba Pascal Dao et.al.|[2501.13083v1](http://arxiv.org/abs/2501.13083v1)|null|
|**2025-01-22**|**Refining Input Guardrails: Enhancing LLM-as-a-Judge Efficiency Through Chain-of-Thought Fine-Tuning and Alignment**|Melissa Kazemi Rad et.al.|[2501.13080v1](http://arxiv.org/abs/2501.13080v1)|null|
|**2025-01-22**|**Autonomy-of-Experts Models**|Ang Lv et.al.|[2501.13074v1](http://arxiv.org/abs/2501.13074v1)|null|
|**2025-01-22**|**AdaWM: Adaptive World Model based Planning for Autonomous Driving**|Hang Wang et.al.|[2501.13072v1](http://arxiv.org/abs/2501.13072v1)|null|
|**2025-01-22**|**Does Table Source Matter? Benchmarking and Improving Multimodal Scientific Table Understanding and Reasoning**|Bohao Yang et.al.|[2501.13042v1](http://arxiv.org/abs/2501.13042v1)|[link](https://github.com/bernard-yang/mmsci_table)|
|**2025-01-22**|**Paper Quality Assessment based on Individual Wisdom Metrics from Open Peer Review**|Andrii Zahorodnii et.al.|[2501.13014v1](http://arxiv.org/abs/2501.13014v1)|null|
|**2025-01-22**|**MONA: Myopic Optimization with Non-myopic Approval Can Mitigate Multi-step Reward Hacking**|Sebastian Farquhar et.al.|[2501.13011v1](http://arxiv.org/abs/2501.13011v1)|null|
|**2025-01-22**|**Pairwise RM: Perform Best-of-N Sampling with Knockout Tournament**|Yantao Liu et.al.|[2501.13007v1](http://arxiv.org/abs/2501.13007v1)|[link](https://github.com/thu-keg/pairwiserm)|
|**2025-01-22**|**Implicit Causality-biases in humans and LLMs as a tool for benchmarking LLM discourse capabilities**|Florian Kankowski et.al.|[2501.12980v1](http://arxiv.org/abs/2501.12980v1)|null|
|**2025-01-22**|**FlanEC: Exploring Flan-T5 for Post-ASR Error Correction**|Moreno La Quatra et.al.|[2501.12979v1](http://arxiv.org/abs/2501.12979v1)|[link](https://github.com/morenolaquatra/flanec)|
|**2025-01-22**|**OnionEval: An Unified Evaluation of Fact-conflicting Hallucination for Small-Large Language Models**|Chongren Sun et.al.|[2501.12975v1](http://arxiv.org/abs/2501.12975v1)|[link](https://github.com/sunchongren/onioneval)|
|**2025-01-22**|**Accessible Smart Contracts Verification: Synthesizing Formal Models with Tamed LLMs**|Jan Corazza et.al.|[2501.12972v1](http://arxiv.org/abs/2501.12972v1)|null|
|**2025-01-22**|**It's complicated. The relationship of algorithmic fairness and non-discrimination regulations in the EU AI Act**|Kristof Meding et.al.|[2501.12962v1](http://arxiv.org/abs/2501.12962v1)|null|
|**2025-01-22**|**Efficient Prompt Compression with Evaluator Heads for Long-Context Transformer Inference**|Weizhi Fei et.al.|[2501.12959v1](http://arxiv.org/abs/2501.12959v1)|null|
|**2025-01-22**|**GANQ: GPU-Adaptive Non-Uniform Quantization for Large Language Models**|Pengxiang Zhao et.al.|[2501.12956v1](http://arxiv.org/abs/2501.12956v1)|null|
|**2025-01-22**|**Multifractal hopscotch in "Hopscotch" by Julio Cortazar**|Jakub Dec et.al.|[2501.12955v1](http://arxiv.org/abs/2501.12955v1)|null|
|**2025-01-22**|**Punctuation patterns in "Finnegans Wake" by James Joyce are largely translation-invariant**|Krzysztof Bartnicki et.al.|[2501.12954v1](http://arxiv.org/abs/2501.12954v1)|null|
|**2025-01-22**|**DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning**|DeepSeek-AI et.al.|[2501.12948v1](http://arxiv.org/abs/2501.12948v1)|null|
|**2025-01-22**|**PreciseCam: Precise Camera Control for Text-to-Image Generation**|Edurne Bernal-Berdun et.al.|[2501.12910v1](http://arxiv.org/abs/2501.12910v1)|null|
|**2025-01-22**|**FilmAgent: A Multi-Agent Framework for End-to-End Film Automation in Virtual 3D Spaces**|Zhenran Xu et.al.|[2501.12909v1](http://arxiv.org/abs/2501.12909v1)|null|
|**2025-01-22**|**Architectural Fusion Through Contextual Partitioning in Large Language Models: A Novel Approach to Parameterized Knowledge Integration**|Offa Kingsleigh et.al.|[2501.12901v1](http://arxiv.org/abs/2501.12901v1)|null|
|**2025-01-22**|**Test-Time Preference Optimization: On-the-Fly Alignment via Iterative Textual Feedback**|Yafu Li et.al.|[2501.12895v1](http://arxiv.org/abs/2501.12895v1)|[link](https://github.com/yafuly/tpo)|
|**2025-01-22**|**Learning Graph Node Embeddings by Smooth Pair Sampling**|Konstantin Kutzkov et.al.|[2501.12884v1](http://arxiv.org/abs/2501.12884v1)|null|
|**2025-01-22**|**WisdomBot: Tuning Large Language Models with Artificial Intelligence Knowledge**|Jingyuan Chen et.al.|[2501.12877v1](http://arxiv.org/abs/2501.12877v1)|null|
|**2025-01-22**|**Mutation-Guided LLM-based Test Generation at Meta**|Christopher Foster et.al.|[2501.12862v1](http://arxiv.org/abs/2501.12862v1)|null|
|**2025-01-22**|**ACEBench: Who Wins the Match Point in Tool Learning?**|Chen Chen et.al.|[2501.12851v1](http://arxiv.org/abs/2501.12851v1)|null|
|**2025-01-22**|**GAMED-Snake: Gradient-aware Adaptive Momentum Evolution Deep Snake Model for Multi-organ Segmentation**|Ruicheng Zhang et.al.|[2501.12844v1](http://arxiv.org/abs/2501.12844v1)|[link](https://github.com/sysuzrc/gamed-snake)|
|**2025-01-22**|**Adaptive Retrieval Without Self-Knowledge? Bringing Uncertainty Back Home**|Viktor Moskvoretskii et.al.|[2501.12835v1](http://arxiv.org/abs/2501.12835v1)|null|
|**2025-01-22**|**Open or Closed LLM for Lesser-Resourced Languages? Lessons from Greek**|John Pavlopoulos et.al.|[2501.12826v1](http://arxiv.org/abs/2501.12826v1)|null|
|**2025-01-22**|**Machine Learning Modeling for Multi-order Human Visual Motion Processing**|Zitang Sun et.al.|[2501.12810v1](http://arxiv.org/abs/2501.12810v1)|[link](https://github.com/anoymized/multi-order-motion-model)|
|**2025-01-22**|**Revisit Self-Debugging with Self-Generated Tests for Code Generation**|Xiancai Chen et.al.|[2501.12793v1](http://arxiv.org/abs/2501.12793v1)|null|
|**2025-01-22**|**Generating Diverse Q&A Benchmarks for RAG Evaluation with DataMorgana**|Simone Filice et.al.|[2501.12789v1](http://arxiv.org/abs/2501.12789v1)|null|
|**2025-01-22**|**Data re-uploading in Quantum Machine Learning for time series: application to traffic forecasting**|Nikolaos Schetakis et.al.|[2501.12776v1](http://arxiv.org/abs/2501.12776v1)|null|
|**2025-01-22**|**Regularization, Semi-supervision, and Supervision for a Plausible Attention-Based Explanation**|Duc Hau Nguyen et.al.|[2501.12775v1](http://arxiv.org/abs/2501.12775v1)|[link](https://github.com/kihansi95/linkmedia_attentionplausibilitybyconstraint)|
|**2025-01-22**|**LLMs as Repositories of Factual Knowledge: Limitations and Solutions**|Seyed Mahed Mousavi et.al.|[2501.12774v1](http://arxiv.org/abs/2501.12774v1)|null|
|**2025-01-22**|**NExtLong: Toward Effective Long-Context Training without Long Documents**|Chaochen Gao et.al.|[2501.12766v1](http://arxiv.org/abs/2501.12766v1)|null|
|**2025-01-22**|**Estimating the Conformal Prediction Threshold from Noisy Labels**|Coby Penso et.al.|[2501.12749v1](http://arxiv.org/abs/2501.12749v1)|[link](https://github.com/cobypenso/noise-aware-conformal-prediction)|
|**2025-01-22**|**EvidenceMap: Unleashing the Power of Small Language Models with Evidence Analysis for Biomedical Question Answering**|Chang Zong et.al.|[2501.12746v1](http://arxiv.org/abs/2501.12746v1)|null|
|**2025-01-22**|**A Call for Critically Rethinking and Reforming Data Analysis in Empirical Software Engineering**|Matteo Esposito et.al.|[2501.12728v1](http://arxiv.org/abs/2501.12728v1)|null|
|**2025-01-22**|**Practical quantum federated learning and its experimental demonstration**|Zhi-Ping Liu et.al.|[2501.12709v1](http://arxiv.org/abs/2501.12709v1)|null|
|**2025-01-22**|**Training Dialogue Systems by AI Feedback for Improving Overall Dialogue Impression**|Kai Yoshida et.al.|[2501.12698v1](http://arxiv.org/abs/2501.12698v1)|null|
|**2025-01-22**|**Growth strategies for arbitrary DAG neural architectures**|Stella Douka et.al.|[2501.12690v1](http://arxiv.org/abs/2501.12690v1)|null|
|**2025-01-22**|**Extracting General-use Transformers for Low-resource Languages via Knowledge Distillation**|Jan Christian Blaise Cruz et.al.|[2501.12660v1](http://arxiv.org/abs/2501.12660v1)|null|
|**2025-01-22**|**The potential -- and the pitfalls -- of using pre-trained language models as cognitive science theories**|Raj Sanjay Shah et.al.|[2501.12651v1](http://arxiv.org/abs/2501.12651v1)|null|
|**2025-01-22**|**Dynamics of Toxicity in Political Podcasts**|Naquee Rizwan et.al.|[2501.12640v1](http://arxiv.org/abs/2501.12640v1)|null|
|**2025-01-22**|**Inverse Reinforcement Learning with Switching Rewards and History Dependency for Characterizing Animal Behaviors**|Jingyang Ke et.al.|[2501.12633v1](http://arxiv.org/abs/2501.12633v1)|null|
|**2025-01-22**|**Towards Robust Multi-tab Website Fingerprinting**|Xinhao Deng et.al.|[2501.12622v1](http://arxiv.org/abs/2501.12622v1)|null|
|**2025-01-22**|**Distillation Quantification for Large Language Models**|Sunbowen Lee et.al.|[2501.12619v1](http://arxiv.org/abs/2501.12619v1)|[link](https://github.com/aegis1863/llms-distillation-quantification)|
|**2025-01-22**|**Deep Learning-Based Identification of Inconsistent Method Names: How Far Are We?**|Taiming Wang et.al.|[2501.12617v1](http://arxiv.org/abs/2501.12617v1)|null|
|**2025-01-22**|**GATE: Adaptive Learning with Working Memory by Information Gating in Multi-lamellar Hippocampal Formation**|Yuechen Liu et.al.|[2501.12615v1](http://arxiv.org/abs/2501.12615v1)|null|
|**2025-01-22**|**T2ISafety: Benchmark for Assessing Fairness, Toxicity, and Privacy in Image Generation**|Lijun Li et.al.|[2501.12612v1](http://arxiv.org/abs/2501.12612v1)|null|
|**2025-01-22**|**BLR-MoE: Boosted Language-Routing Mixture of Experts for Domain-Robust Multilingual E2E ASR**|Guodong Ma et.al.|[2501.12602v1](http://arxiv.org/abs/2501.12602v1)|null|
|**2025-01-22**|**Kimi k1.5: Scaling Reinforcement Learning with LLMs**|Kimi Team et.al.|[2501.12599v1](http://arxiv.org/abs/2501.12599v1)|null|
|**2025-01-22**|**FedGrAINS: Personalized SubGraph Federated Learning with Adaptive Neighbor Sampling**|Emir Ceyani et.al.|[2501.12592v1](http://arxiv.org/abs/2501.12592v1)|null|
|**2025-01-22**|**Leveraging LLMs to Create a Haptic Devices' Recommendation System**|Yang Liu et.al.|[2501.12573v1](http://arxiv.org/abs/2501.12573v1)|null|
|**2025-01-22**|**O1-Pruner: Length-Harmonizing Fine-Tuning for O1-Like Reasoning Pruning**|Haotian Luo et.al.|[2501.12570v1](http://arxiv.org/abs/2501.12570v1)|[link](https://github.com/stardewxxx/o1-pruner)|
|**2025-01-22**|**Understanding the LLM-ification of CHI: Unpacking the Impact of LLMs at CHI through a Systematic Literature Review**|Rock Yuren Pang et.al.|[2501.12557v1](http://arxiv.org/abs/2501.12557v1)|null|
|**2025-01-21**|**Human-like conceptual representations emerge from language prediction**|Ningyu Xu et.al.|[2501.12547v1](http://arxiv.org/abs/2501.12547v1)|null|
|**2025-01-21**|**Comparative Approaches to Sentiment Analysis Using Datasets in Major European and Arabic Languages**|Mikhail Krasitskii et.al.|[2501.12540v1](http://arxiv.org/abs/2501.12540v1)|null|
|**2025-01-21**|**Compositional Instruction Following with Language Models and Reinforcement Learning**|Vanya Cohen et.al.|[2501.12539v1](http://arxiv.org/abs/2501.12539v1)|null|
|**2025-01-21**|**Academic Case Reports Lack Diversity: Assessing the Presence and Diversity of Sociodemographic and Behavioral Factors related with Post COVID-19 Condition**|Juan Andres Medina Florez et.al.|[2501.12538v1](http://arxiv.org/abs/2501.12538v1)|null|
|**2025-01-21**|**Enhancing Privacy in the Early Detection of Sexual Predators Through Federated Learning and Differential Privacy**|Khaoula Chehbouni et.al.|[2501.12537v1](http://arxiv.org/abs/2501.12537v1)|null|
|**2025-01-21**|**Interaction Dataset of Autonomous Vehicles with Traffic Lights and Signs**|Zheng Li et.al.|[2501.12536v1](http://arxiv.org/abs/2501.12536v1)|null|
|**2025-01-21**|**Efficient Lung Ultrasound Severity Scoring Using Dedicated Feature Extractor**|Jiaqi Guo et.al.|[2501.12524v1](http://arxiv.org/abs/2501.12524v1)|null|
|**2025-01-21**|**An Empirically-grounded tool for Automatic Prompt Linting and Repair: A Case Study on Bias, Vulnerability, and Optimization in Developer Prompts**|Dhia Elhaq Rzig et.al.|[2501.12521v1](http://arxiv.org/abs/2501.12521v1)|null|
|**2025-01-21**|**Large-image Object Detection for Fine-grained Recognition of Punches Patterns in Medieval Panel Painting**|Josh Bruegger et.al.|[2501.12489v1](http://arxiv.org/abs/2501.12489v1)|[link](https://github.com/marcozullich/punches-object-detection)|
|**2025-01-21**|**The Journey Matters: Average Parameter Count over Pre-training Unifies Sparse and Dense Scaling Laws**|Tian Jin et.al.|[2501.12486v1](http://arxiv.org/abs/2501.12486v1)|null|
|**2025-01-21**|**fabSAM: A Farmland Boundary Delineation Method Based on the Segment Anything Model**|Yufeng Xie et.al.|[2501.12487v1](http://arxiv.org/abs/2501.12487v1)|null|
|**2025-01-21**|**R2D2: Remembering, Reflecting and Dynamic Decision Making for Web Agents**|Tenghao Huang et.al.|[2501.12485v1](http://arxiv.org/abs/2501.12485v1)|null|
|**2025-01-21**|**Adaptive PII Mitigation Framework for Large Language Models**|Shubhi Asthana et.al.|[2501.12465v1](http://arxiv.org/abs/2501.12465v1)|null|
|**2025-01-21**|**Deploying Privacy Guardrails for LLMs: A Comparative Analysis of Real-World Applications**|Shubhi Asthana et.al.|[2501.12456v1](http://arxiv.org/abs/2501.12456v1)|null|
|**2025-01-21**|**Learning segmentation from point trajectories**|Laurynas Karazija et.al.|[2501.12392v1](http://arxiv.org/abs/2501.12392v1)|null|
|**2025-01-21**|**Physics of Skill Learning**|Ziming Liu et.al.|[2501.12391v1](http://arxiv.org/abs/2501.12391v1)|[link](https://github.com/kindxiaoming/physics_of_skill_learning)|
|**2025-01-21**|**MMVU: Measuring Expert-Level Multi-Discipline Video Understanding**|Yilun Zhao et.al.|[2501.12380v1](http://arxiv.org/abs/2501.12380v1)|[link](https://github.com/yale-nlp/mmvu)|
|**2025-01-21**|**Enhancing Retrosynthesis with Conformer: A Template-Free Method**|Jiaxi Zhuang et.al.|[2501.12434v1](http://arxiv.org/abs/2501.12434v1)|null|
|**2025-01-21**|**Video Depth Anything: Consistent Depth Estimation for Super-Long Videos**|Sili Chen et.al.|[2501.12375v2](http://arxiv.org/abs/2501.12375v2)|null|
|**2025-01-21**|**Expertise elevates AI usage: experimental evidence comparing laypeople and professional artists**|Thomas F. Eisenmann et.al.|[2501.12374v1](http://arxiv.org/abs/2501.12374v1)|[link](https://github.com/andreskarjus/genaiexperiment)|
|**2025-01-21**|**Is Long Context All You Need? Leveraging LLM's Extended Context for NL2SQL**|Yeounoh Chung et.al.|[2501.12372v1](http://arxiv.org/abs/2501.12372v1)|null|
|**2025-01-21**|**Parameters vs FLOPs: Scaling Laws for Optimal Sparsity for Mixture-of-Experts Language Models**|Samira Abnar et.al.|[2501.12370v1](http://arxiv.org/abs/2501.12370v1)|null|
|**2025-01-21**|**InternLM-XComposer2.5-Reward: A Simple Yet Effective Multi-Modal Reward Model**|Yuhang Zang et.al.|[2501.12368v1](http://arxiv.org/abs/2501.12368v1)|[link](https://github.com/internlm/internlm-xcomposer)|
|**2025-01-21**|**Owls are wise and foxes are unfaithful: Uncovering animal stereotypes in vision-language models**|Tabinda Aman et.al.|[2501.12433v1](http://arxiv.org/abs/2501.12433v1)|null|
|**2025-01-21**|**Test-time regression: a unifying framework for designing sequence models with associative memory**|Ke Alexander Wang et.al.|[2501.12352v1](http://arxiv.org/abs/2501.12352v1)|null|
|**2025-01-21**|**Treefix: Enabling Execution with a Tree of Prefixes**|Beatriz Souza et.al.|[2501.12339v1](http://arxiv.org/abs/2501.12339v1)|null|
|**2025-01-21**|**FuocChuVIP123 at CoMeDi Shared Task: Disagreement Ranking with XLM-Roberta Sentence Embeddings and Deep Neural Regression**|Phuoc Duong Huy Chu et.al.|[2501.12336v1](http://arxiv.org/abs/2501.12336v1)|null|
|**2025-01-21**|**Automatic Labelling with Open-source LLMs using Dynamic Label Schema Integration**|Thomas Walshe et.al.|[2501.12332v1](http://arxiv.org/abs/2501.12332v1)|null|
|**2025-01-21**|**UI-TARS: Pioneering Automated GUI Interaction with Native Agents**|Yujia Qin et.al.|[2501.12326v1](http://arxiv.org/abs/2501.12326v1)|[link](https://github.com/bytedance/ui-tars)|
|**2025-01-21**|**LLM-Assisted Knowledge Graph Completion for Curriculum and Domain Modelling in Personalized Higher Education Recommendations**|Hasan Abu-Rasheed et.al.|[2501.12300v1](http://arxiv.org/abs/2501.12300v1)|null|
|**2025-01-21**|**RALAD: Bridging the Real-to-Sim Domain Gap in Autonomous Driving with Retrieval-Augmented Learning**|Jiacheng Zuo et.al.|[2501.12296v1](http://arxiv.org/abs/2501.12296v1)|[link](https://github.com/jiachengzuo/ralad)|
|**2025-01-21**|**Divide-Then-Aggregate: An Efficient Tool Learning Method via Parallel Tool Invocation**|Dongsheng Zhu et.al.|[2501.12432v1](http://arxiv.org/abs/2501.12432v1)|null|
|**2025-01-21**|**Modality Interactive Mixture-of-Experts for Fake News Detection**|Yifan Liu et.al.|[2501.12431v1](http://arxiv.org/abs/2501.12431v1)|null|
|**2025-01-21**|**With Great Backbones Comes Great Adversarial Transferability**|Erik Arakelyan et.al.|[2501.12275v1](http://arxiv.org/abs/2501.12275v1)|null|
|**2025-01-21**|**Condor: Enhance LLM Alignment with Knowledge-Driven Data Synthesis and Refinement**|Maosong Cao et.al.|[2501.12273v1](http://arxiv.org/abs/2501.12273v1)|null|
|**2025-01-21**|**CBVLM: Training-free Explainable Concept-based Large Vision Language Models for Medical Image Classification**|Cristiano PatrÃ­cio et.al.|[2501.12266v1](http://arxiv.org/abs/2501.12266v1)|null|
|**2025-01-21**|**FOCUS: First Order Concentrated Updating Scheme**|Yizhou Liu et.al.|[2501.12243v1](http://arxiv.org/abs/2501.12243v1)|null|
|**2025-01-21**|**InsTALL: Context-aware Instructional Task Assistance with Multi-modal Large Language Models**|Pha Nguyen et.al.|[2501.12231v1](http://arxiv.org/abs/2501.12231v1)|null|
|**2025-01-21**|**SCFCRC: Simultaneously Counteract Feature Camouflage and Relation Camouflage for Fraud Detection**|Xiaocheng Zhang et.al.|[2501.12430v1](http://arxiv.org/abs/2501.12430v1)|null|
|**2025-01-21**|**Fixing Imbalanced Attention to Mitigate In-Context Hallucination of Large Vision-Language Model**|Kazi Hasan Ibn Arif et.al.|[2501.12206v1](http://arxiv.org/abs/2501.12206v1)|null|
|**2025-01-21**|**An End-to-End Approach for Korean Wakeword Systems with Speaker Authentication**|Geonwoo Seo et.al.|[2501.12194v1](http://arxiv.org/abs/2501.12194v1)|[link](https://github.com/gws8820/securewakeword-model)|
|**2025-01-21**|**Fuel Efficiency Analysis of the Public Transportation System Based on the Gaussian Mixture Model Clustering**|Zhipeng Ma et.al.|[2501.12429v1](http://arxiv.org/abs/2501.12429v1)|null|

#### Abstracts
##### **Robust Representation Consistency Model via Contrastive Denoising**
2501.13094v1 by Jiachen Lei, Julius Berner, Jiongxiao Wang, Zhongzhu Chen, Zhongjia Ba, Kui Ren, Jun Zhu, Anima Anandkumar

Robustness is essential for deep neural networks, especially in
security-sensitive applications. To this end, randomized smoothing provides
theoretical guarantees for certifying robustness against adversarial
perturbations. Recently, diffusion models have been successfully employed for
randomized smoothing to purify noise-perturbed samples before making
predictions with a standard classifier. While these methods excel at small
perturbation radii, they struggle with larger perturbations and incur a
significant computational overhead during inference compared to classical
methods. To address this, we reformulate the generative modeling task along the
diffusion trajectories in pixel space as a discriminative task in the latent
space. Specifically, we use instance discrimination to achieve consistent
representations along the trajectories by aligning temporally adjacent points.
After fine-tuning based on the learned representations, our model enables
implicit denoising-then-classification via a single prediction, substantially
reducing inference costs. We conduct extensive experiments on various datasets
and achieve state-of-the-art performance with minimal computation budget during
inference. For example, our method outperforms the certified accuracy of
diffusion-based methods on ImageNet across all perturbation radii by 5.3% on
average, with up to 11.6% at larger radii, while reducing inference costs by
85$\times$ on average. Codes are available at:
https://github.com/jiachenlei/rRCM.

æè¦ï¼å°æ¼æ·±åº¦ç¥ç¶ç¶²è·¯ä¾èªªï¼ç©©å¥æ§è³ééè¦ï¼å°¤å¶æ¯å¨å®å¨ææçæç¨ä¸­ãçºæ­¤ï¼é¨æ©å¹³æ»æä¾äºçè«ä¿è­ï¼å¯ä»¥è­æå°ææ¾åçç©©å¥æ§ãæè¿ï¼æ´æ£æ¨¡åå·²æåç¨æ¼é¨æ©å¹³æ»ï¼ä»¥å¨ä½¿ç¨æ¨æºåé¡å¨é²è¡é æ¸¬ä¹åæ·¨ååéè¨æ¾åçæ¨£æ¬ãåç®¡éäºæ¹æ³å¨å°æ¾ååå¾æ¹é¢è¡¨ç¾åºè²ï¼ä½å®åå¨è¼å¤§çæ¾åä¸­æéå°å°é£ï¼ä¸¦ä¸èå³çµ±æ¹æ³ç¸æ¯ï¼å¨æ¨çéç¨ä¸­æç¢çå¤§éçè¨ç®éé·ãçºäºè§£æ±ºéååé¡ï¼æåå°åç´ ç©ºéä¸­çæ´æ£è»è·¡ä¸ççæå¼å»ºæ¨¡ä»»åéæ°è¡¨è¿°çºæ½å¨ç©ºéä¸­çå¤å¥ä»»åãå·é«ä¾èªªï¼æåä½¿ç¨å¯¦ä¾å¤å¥ä¾ééå°é½æéç¸é°çé»ä¾å¯¦ç¾æ²¿èè»è·¡çä¸è´è¡¨ç¤ºãå¨æ ¹æå­¸ç¿å°çè¡¨ç¤ºé²è¡å¾®èª¿å¾ï¼æåçæ¨¡åè½å¤ ééå®ä¸é æ¸¬å¯¦ç¾é±å¼å»åªç¶å¾åé¡ï¼å¾èå¤§å¹éä½æ¨çææ¬ãæåå¨åç¨®è³æéä¸é²è¡äºå»£æ³çå¯¦é©ï¼ä¸¦å¨æ¨çéç¨ä¸­ä»¥æå°çè¨ç®é ç®å¯¦ç¾äºæåé²çæè½ãä¾å¦ï¼æåçæ¨¡åå¨ ImageNet ä¸æææ¾ååå¾çèªè­æºç¢ºåº¦é½æ¯åºæ¼æ´æ£çæ¹æ³é«åº 5.3%ï¼å¨è¼å¤§åå¾æé«é 11.6%ï¼åæå°æ¨çææ¬å¹³åéä½äº 85 åãç¨å¼ç¢¼å¯å¨ä»¥ä¸ä½ç½®åå¾ï¼
https://github.com/jiachenlei/rRCMã

##### **Boosting MCTS with Free Energy Minimization**
2501.13083v1 by Mawaba Pascal Dao, Adrian Peter

Active Inference, grounded in the Free Energy Principle, provides a powerful
lens for understanding how agents balance exploration and goal-directed
behavior in uncertain environments. Here, we propose a new planning framework,
that integrates Monte Carlo Tree Search (MCTS) with active inference objectives
to systematically reduce epistemic uncertainty while pursuing extrinsic
rewards. Our key insight is that MCTS already renowned for its search
efficiency can be naturally extended to incorporate free energy minimization by
blending expected rewards with information gain. Concretely, the Cross-Entropy
Method (CEM) is used to optimize action proposals at the root node, while tree
expansions leverage reward modeling alongside intrinsic exploration bonuses.
This synergy allows our planner to maintain coherent estimates of value and
uncertainty throughout planning, without sacrificing computational
tractability. Empirically, we benchmark our planner on a diverse set of
continuous control tasks, where it demonstrates performance gains over both
standalone CEM and MCTS with random rollouts.

æè¦ï¼ä¸»åæ¨è«åºæ¼èªç±è½åçï¼æä¾äºä¸åå¼·å¤§çè¦è§ï¼ç¨æ¼çè§£ä»£çå¦ä½å¨ä¸ç¢ºå®çç°å¢ä¸­å¹³è¡¡æ¢ç´¢åç®æ¨å°åè¡çºãå¨æ­¤ï¼æåæåºäºä¸åæ°çè¦åæ¡æ¶ï¼å®å°èå°å¡ç¾æ¨¹æå° (MCTS) èä¸»åæ¨è«ç®æ¨ç¸æ´åï¼ä»¥å¨è¿½æ±å¤å¨çåµçåæç³»çµ±æ§å°æ¸å°èªè­è«çä¸ç¢ºå®æ§ãæåçééµè¦è§£æ¯ï¼MCTS å·²ä»¥å¶æå°æçèèåï¼å®å¯ä»¥ééå°é æçåµèè³è¨ç²åç¸çµåï¼èªç¶å°æ´å±å°ç´å¥èªç±è½æå°åãå·é«ä¾èªªï¼äº¤åçµæ¹æ³ (CEM) ç¨æ¼æä½³åæ ¹ç¯é»çåä½å»ºè­°ï¼èæ¨¹æ´å±åå©ç¨çåµå»ºæ¨¡ä»¥åå§å¨æ¢ç´¢çåµãéç¨®ååä½ç¨ä½¿æåçè¦åå¨è½å¤ å¨æ´åè¦åéç¨ä¸­ç¶­æå°å¹å¼åä¸ç¢ºå®æ§çé£è²«ä¼°è¨ï¼èä¸æç§ç²è¨ç®çå¯è¡æ§ãæ ¹æç¶é©ï¼æåå¨åç¨®é£çºæ§å¶ä»»åä¸å°æåçè¦åå¨é²è¡äºåºæºæ¸¬è©¦ï¼å®å±ç¤ºäºç¸è¼æ¼ç¨ç«ç CEM åå·æé¨æ©æ»¾åç MCTSï¼å®å¨æè½ä¸æææåã

##### **Refining Input Guardrails: Enhancing LLM-as-a-Judge Efficiency Through Chain-of-Thought Fine-Tuning and Alignment**
2501.13080v1 by Melissa Kazemi Rad, Huy Nghiem, Andy Luo, Sahil Wadhwa, Mohammad Sorower, Stephen Rawls

Large Language Models (LLMs) have demonstrated powerful capabilities that
render them valuable in different applications, including conversational AI
products. It is paramount to ensure the security and reliability of these
products by mitigating their vulnerabilities towards malicious user
interactions, which can lead to the exposure of great risks and reputational
repercussions. In this work, we present a comprehensive study on the efficacy
of fine-tuning and aligning Chain-of-Thought (CoT) responses of different LLMs
that serve as input moderation guardrails. We systematically explore various
tuning methods by leveraging a small set of training data to adapt these models
as proxy defense mechanisms to detect malicious inputs and provide a reasoning
for their verdicts, thereby preventing the exploitation of conversational
agents. We rigorously evaluate the efficacy and robustness of different tuning
strategies to generalize across diverse adversarial and malicious query types.
Our experimental results outline the potential of alignment processes tailored
to a varied range of harmful input queries, even with constrained data
resources. These techniques significantly enhance the safety of conversational
AI systems and provide a feasible framework for deploying more secure and
trustworthy AI-driven interactions.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²å±ç¾å¼·å¤§çè½åï¼ä½¿å¶å¨ä¸åçæç¨ç¨å¼ä¸­æå¹å¼ï¼åæ¬å°è©±å¼ AI ç¢åãééæ¸è¼å¶å°æ¡æä½¿ç¨èäºåçæ¼æ´ï¼ç¢ºä¿éäºç¢åçå®å¨æ§åå¯é æ§è³ééè¦ï¼éå¯è½æå°è´éå¤§é¢¨éªååè­½æå®³ãå¨éé å·¥ä½ä¸­ï¼æåå°å¾®èª¿åèª¿æ´ä¸å LLM çæèé (CoT) åæçåæé²è¡å¨é¢ç ç©¶ï¼éäºåæå¯ç¨ä½è¼¸å¥å¯©æ ¸é²è­·æªæ½ãæåç³»çµ±æ§å°æ¢ç´¢åç¨®èª¿æ´æ¹æ³ï¼å©ç¨ä¸å°çµè¨ç·´è³æä¾èª¿æ´éäºæ¨¡åï¼ä½çºä»£çé²ç¦¦æ©å¶ä¾åµæ¸¬æ¡æè¼¸å¥ä¸¦çºå¶å¤æ±ºæä¾çç±ï¼å¾èé²æ­¢å°è©±å¼ä»£ççå©ç¨ãæåå´æ ¼è©ä¼°ä¸åèª¿æ´ç­ç¥çåæåç©©å¥æ§ï¼ä»¥æ¦æ¬åç¨®å°ææ§åæ¡ææ¥è©¢é¡åãæåçå¯¦é©çµææ¦è¿°äºèª¿æ´æµç¨çæ½åï¼éäºæµç¨éå°åç¨®æå®³è¼¸å¥æ¥è©¢é²è¡èª¿æ´ï¼å³ä½¿å¨è³æè³æºåéçææ³ä¸ä¹æ¯å¦æ­¤ãéäºæè¡é¡¯èå¢å¼·äºå°è©±å¼ AI ç³»çµ±çå®å¨æ§ï¼ä¸¦æä¾äºä¸åå¯è¡çæ¡æ¶ï¼ç¨æ¼é¨ç½²æ´å®å¨ä¸å¼å¾ä¿¡è³´ç AI é©åäºåã

##### **Autonomy-of-Experts Models**
2501.13074v1 by Ang Lv, Ruobing Xie, Yining Qian, Songhao Wu, Xingwu Sun, Zhanhui Kang, Di Wang, Rui Yan

Mixture-of-Experts (MoE) models mostly use a router to assign tokens to
specific expert modules, activating only partial parameters and often
outperforming dense models. We argue that the separation between the router's
decision-making and the experts' execution is a critical yet overlooked issue,
leading to suboptimal expert selection and ineffective learning. To address
this, we propose Autonomy-of-Experts (AoE), a novel MoE paradigm in which
experts autonomously select themselves to process inputs. AoE is based on the
insight that an expert is aware of its own capacity to effectively process a
token, an awareness reflected in the scale of its internal activations. In AoE,
routers are removed; instead, experts pre-compute internal activations for
inputs and are ranked based on their activation norms. Only the top-ranking
experts proceed with the forward pass, while the others abort. The overhead of
pre-computing activations is reduced through a low-rank weight factorization.
This self-evaluating-then-partner-comparing approach ensures improved expert
selection and effective learning. We pre-train language models having 700M up
to 4B parameters, demonstrating that AoE outperforms traditional MoE models
with comparable efficiency.

æè¦ï¼æ··åä¸å®¶ (MoE) æ¨¡åä¸»è¦ä½¿ç¨è·¯ç±å¨å°ä»£å¹£åéçµ¦ç¹å®å°å®¶æ¨¡çµï¼åªååé¨ååæ¸ï¼ä¸¦ä¸éå¸¸åªæ¼ç¨ å¯æ¨¡åãæåèªçºè·¯ç±å¨çæ±ºç­å¶å®èå°å®¶çå·è¡ä¹éçåå¥æ¯ä¸åééµä½è¢«å¿½è¦çåé¡ï¼å°è´å°å®¶é¸ææ¬¡ä½³åå­¸ç¿ç¡æãçºäºè§£æ±ºéååé¡ï¼æåæåºå°å®¶èªä¸» (AoE)ï¼ä¸ç¨®æ°ç MoE å¸ç¯ï¼å¶ä¸­å°å®¶èªä¸»é¸æèªå·±ä¾èçè¼¸å¥ãAoE åºæ¼éæ¨£çè¦è§£ï¼å°å®¶ç¥éèªå·±ææèçä»£å¹£çè½åï¼éç¨®æè­åæ å¨å¶å§é¨æ¿æ´»çè¦æ¨¡ä¸­ãå¨ AoE ä¸­ï¼è·¯ç±å¨è¢«ç§»é¤ï¼ç¸åï¼å°å®¶æé åè¨ç®è¼¸å¥çå§é¨æ¿æ´»ï¼ä¸¦æ ¹æå¶æ¿æ´»ç¯æ¸é²è¡æåãåªææåæé«çå°å®¶ææç¹¼çºé²è¡ååå³éï¼èå¶ä»å°å®¶åä¸­æ·ãééä½éæ¬éåè§£ï¼å¯ä»¥æ¸å°é åè¨ç®æ¿æ´»çéé·ãéç¨®èªè©ç¶å¾èåä½å¤¥ä¼´æ¯è¼çæ¹æ³ç¢ºä¿äºæ¹é²çå°å®¶é¸æåææçå­¸ç¿ãæåé åè¨ç·´äºå·æ 700M å° 4B åæ¸çèªè¨æ¨¡åï¼è­æ AoE åªæ¼å·æå¯æ¯æççå³çµ± MoE æ¨¡åã

##### **AdaWM: Adaptive World Model based Planning for Autonomous Driving**
2501.13072v1 by Hang Wang, Xin Ye, Feng Tao, Abhirup Mallik, Burhaneddin Yaman, Liu Ren, Junshan Zhang

World model based reinforcement learning (RL) has emerged as a promising
approach for autonomous driving, which learns a latent dynamics model and uses
it to train a planning policy. To speed up the learning process, the
pretrain-finetune paradigm is often used, where online RL is initialized by a
pretrained model and a policy learned offline. However, naively performing such
initialization in RL may result in dramatic performance degradation during the
online interactions in the new task. To tackle this challenge, we first analyze
the performance degradation and identify two primary root causes therein: the
mismatch of the planning policy and the mismatch of the dynamics model, due to
distribution shift. We further analyze the effects of these factors on
performance degradation during finetuning, and our findings reveal that the
choice of finetuning strategies plays a pivotal role in mitigating these
effects. We then introduce AdaWM, an Adaptive World Model based planning
method, featuring two key steps: (a) mismatch identification, which quantifies
the mismatches and informs the finetuning strategy, and (b) alignment-driven
finetuning, which selectively updates either the policy or the model as needed
using efficient low-rank updates. Extensive experiments on the challenging
CARLA driving tasks demonstrate that AdaWM significantly improves the
finetuning process, resulting in more robust and efficient performance in
autonomous driving systems.

æè¦ï¼åºæ¼ä¸çæ¨¡åçå¼·åå­¸ç¿ (RL) å·²æçºèªåé§é§çæ½åæ¹æ³ï¼å®å­¸ç¿æ½å¨åææ¨¡åä¸¦å©ç¨å®ä¾è¨ç·´è¦åæ¿ç­ãçºäºå éå­¸ç¿éç¨ï¼éå¸¸æä½¿ç¨é è¨ç·´å¾®èª¿ç¯ä¾ï¼å¶ä¸­ç·ä¸ RL ç±é è¨ç·´æ¨¡ååé¢ç·å­¸ç¿çæ¿ç­åå§åãç¶èï¼å¨ RL ä¸­å¤©çå°å·è¡éç¨®åå§åå¯è½æå°è´å¨æ°çä»»åä¸­ç·ä¸äºåæéçæ²åæ§æè½ä¸éãçºäºæå°éåææ°ï¼æåé¦ååææè½ä¸éä¸¦æ¾åºå©åä¸»è¦çæ ¹æ¬åå ï¼è¦åæ¿ç­çä¸å¹éååææ¨¡åçä¸å¹éï¼éæ¯ç±æ¼åä½è½ç§»ãæåé²ä¸æ­¥åæäºéäºå ç´ å°å¾®èª¿æéæè½ä¸éçå½±é¿ï¼æåçç¼ç¾è¡¨æå¾®èª¿ç­ç¥çé¸æå¨æ¸è¼éäºå½±é¿æ¹é¢ç¼æ®äºééµä½ç¨ãç¶å¾æåä»ç´¹ AdaWMï¼ä¸ç¨®åºæ¼èªé©æä¸çæ¨¡åçè¦åæ¹æ³ï¼å·æå©åééµæ­¥é©ï¼(a) ä¸å¹éè­å¥ï¼å®éåä¸å¹éä¸¦åç¥å¾®èª¿ç­ç¥ï¼ä»¥å (b) å°é½é©åå¾®èª¿ï¼å®æ ¹æéè¦ä½¿ç¨ææçä½ç§©æ´æ°é¸ææ§å°æ´æ°æ¿ç­ææ¨¡åãå¨å·æææ°æ§ç CARLA é§é§ä»»åä¸é²è¡çå»£æ³å¯¦é©è¡¨æï¼AdaWM å¤§å¤§æ¹é²äºå¾®èª¿éç¨ï¼å¾èå¨èªåé§é§ç³»çµ±ä¸­ç¢çäºæ´å¼·å¤§ãæ´ææçæè½ã

##### **Does Table Source Matter? Benchmarking and Improving Multimodal Scientific Table Understanding and Reasoning**
2501.13042v1 by Bohao Yang, Yingji Zhang, Dong Liu, AndrÃ© Freitas, Chenghua Lin

Recent large language models (LLMs) have advanced table understanding
capabilities but rely on converting tables into text sequences. While
multimodal large language models (MLLMs) enable direct visual processing, they
face limitations in handling scientific tables due to fixed input image
resolutions and insufficient numerical reasoning capabilities. We present a
comprehensive framework for multimodal scientific table understanding and
reasoning with dynamic input image resolutions. Our framework consists of three
key components: (1) MMSci-Pre, a domain-specific table structure learning
dataset of 52K scientific table structure recognition samples, (2) MMSci-Ins,
an instruction tuning dataset with 12K samples across three table-based tasks,
and (3) MMSci-Eval, a benchmark with 3,114 testing samples specifically
designed to evaluate numerical reasoning capabilities. Extensive experiments
demonstrate that our domain-specific approach with 52K scientific table images
achieves superior performance compared to 150K general-domain tables,
highlighting the importance of data quality over quantity. Our proposed
table-based MLLMs with dynamic input resolutions show significant improvements
in both general table understanding and numerical reasoning capabilities, with
strong generalisation to held-out datasets. Our code and data are publicly
available at https://github.com/Bernard-Yang/MMSci_Table.

æè¦ï¼æè¿çå¤§åèªè¨æ¨¡å (LLM) æåäºè¡¨æ ¼çè§£è½åï¼ä½ä¾è³´æ¼å°è¡¨æ ¼è½æçºæå­åºåãéç¶å¤æ¨¡æå¤§åèªè¨æ¨¡å (MLLM) è½ç´æ¥é²è¡è¦è¦ºèçï¼ä½ç±æ¼åºå®çè¼¸å¥å½±åè§£æåº¦åä¸è¶³çæ¸å­æ¨çè½åï¼å¨èçç§å­¸è¡¨æ ¼æé¢è¨éå¶ãæåæåºä¸åå¤æ¨¡æç§å­¸è¡¨æ ¼çè§£åæ¨ççå¨é¢æ¶æ§ï¼ä¸¦æ¡ç¨åæè¼¸å¥å½±åè§£æåº¦ãæåçæ¶æ§åå«ä¸åééµçµæé¨åï¼(1) MMSci-Preï¼ä¸åç¹å®é åçè¡¨æ ¼çµæ§å­¸ç¿è³æéï¼åå« 52K åç§å­¸è¡¨æ ¼çµæ§è¾¨è­ç¯ä¾ï¼(2) MMSci-Insï¼ä¸åæä»¤èª¿æ´è³æéï¼å¨ä¸é åºæ¼è¡¨æ ¼çä»»åä¸­åå« 12K åç¯ä¾ï¼ä»¥å (3) MMSci-Evalï¼ä¸ååºæºï¼åå« 3,114 åæ¸¬è©¦ç¯ä¾ï¼å°éç¨æ¼è©ä¼°æ¸å­æ¨çè½åãå»£æ³çå¯¦é©è­æï¼æåæ¡ç¨ 52K åç§å­¸è¡¨æ ¼å½±åçç¹å®é åæ¹æ³ï¼è 150K åä¸è¬é åè¡¨æ ¼ç¸æ¯ï¼è½éææ´å¥½çæè½ï¼çªé¡¯è³æåè³ªæ¯æ¸ééè¦çæ¦å¿µãæåæåºçåºæ¼è¡¨æ ¼ç MLLM æ¡ç¨åæè¼¸å¥è§£æåº¦ï¼å¨ä¸è¬è¡¨æ ¼çè§£åæ¸å­æ¨çè½åæ¹é¢é½å±ç¾é¡¯èçé²æ­¥ï¼ä¸¦è½æææ³åå°ä¿ççè³æéãæåçç¨å¼ç¢¼åè³æå·²å¬éç¼å¸æ¼ https://github.com/Bernard-Yang/MMSci_Tableã

##### **Paper Quality Assessment based on Individual Wisdom Metrics from Open Peer Review**
2501.13014v1 by Andrii Zahorodnii, Jasper J. F. van den Bosch, Ian Charest, Christopher Summerfield, Ila R. Fiete

This study proposes a data-driven framework for enhancing the accuracy and
efficiency of scientific peer review through an open, bottom-up process that
estimates reviewer quality. Traditional closed peer review systems, while
essential for quality control, are often slow, costly, and subject to biases
that can impede scientific progress. Here, we introduce a method that evaluates
individual reviewer reliability by quantifying agreement with community
consensus scores and applying Bayesian weighting to refine paper quality
assessments. We analyze open peer review data from two major scientific
conferences, and demonstrate that reviewer-specific quality scores
significantly improve the reliability of paper quality estimation. Perhaps
surprisingly, we find that reviewer quality scores are unrelated to authorship
quality. Our model incorporates incentive structures to recognize high-quality
reviewers and encourage broader coverage of submitted papers, thereby
mitigating the common "rich-get-richer" pitfall of social media. These findings
suggest that open peer review, with mechanisms for estimating and incentivizing
reviewer quality, offers a scalable and equitable alternative for scientific
publishing, with potential to enhance the speed, fairness, and transparency of
the peer review process.

æè¦ï¼æ¬ç ç©¶æåºäºä¸åè³æé©åçæ¶æ§ï¼ééä¸åéæ¾çç±ä¸èä¸çæµç¨ä¾æåç§å­¸åè¡è©å¯©çæºç¢ºåº¦åæçï¼æ­¤æµç¨æè©ä¼°å¯©ç¨¿äººçåè³ªãå³çµ±çå°éå¼åè¡è©å¯©ç³»çµ±å°æ¼åè³ªæ§ç®¡ä¾èªªåºç¶éè¦ï¼ä½éå¸¸å¾ç·©æ¢ãææ¬é«ï¼ä¸å®¹ææåè¦ï¼å¯è½æé»ç¤ç§å­¸é²å±ãå¨æ­¤ï¼æåä»ç´¹ä¸åæ¹æ³ï¼éééåèç¤¾ç¾¤å±è­åæ¸çä¸è´æ§ï¼ä¸¦å¥ç¨è²æ°å æ¬ä¾æ¹åè«æåè³ªè©éï¼ä»¥è©ä¼°åå¥å¯©ç¨¿äººçå¯é æ§ãæååæäºå©å ´å¤§åç§å­¸æè­°çéæ¾å¼åè¡è©å¯©è³æï¼ä¸¦è­æç¹å®å¯©ç¨¿äººçåè³ªåæ¸å¤§å¹æåäºè«æåè³ªè©ä¼°çå¯é æ§ãæè¨±ä»¤äººé©è¨çæ¯ï¼æåç¼ç¾å¯©ç¨¿äººåè³ªåæ¸èä½èåè³ªç¡éãæåçæ¨¡åç´å¥äºæ¿åµæ©å¶ï¼ä»¥è¡¨å½°é«åè³ªå¯©ç¨¿äººï¼ä¸¦é¼åµå°æäº¤è«æé²è¡æ´å»£æ³çæ¶µèï¼å¾èæ¸è¼ç¤¾ç¾¤åªé«å¸¸è¦çãå¯èæå¯ãé·é±ãéäºç¼ç¾è¡¨æï¼éæ¾å¼åè¡è©å¯©ï¼å·åè©ä¼°åæ¿åµå¯©ç¨¿äººåè³ªçæ©å¶ï¼çºç§å­¸åºçæä¾äºä¸åå¯æ´åä¸å¬å¹³çæ¿ä»£æ¹æ¡ï¼ææ½åæååè¡è©å¯©æµç¨çéåº¦ãå¬å¹³æ§åéæåº¦ã

##### **MONA: Myopic Optimization with Non-myopic Approval Can Mitigate Multi-step Reward Hacking**
2501.13011v1 by Sebastian Farquhar, Vikrant Varma, David Lindner, David Elson, Caleb Biddulph, Ian Goodfellow, Rohin Shah

Future advanced AI systems may learn sophisticated strategies through
reinforcement learning (RL) that humans cannot understand well enough to safely
evaluate. We propose a training method which avoids agents learning undesired
multi-step plans that receive high reward (multi-step "reward hacks") even if
humans are not able to detect that the behaviour is undesired. The method,
Myopic Optimization with Non-myopic Approval (MONA), works by combining
short-sighted optimization with far-sighted reward. We demonstrate that MONA
can prevent multi-step reward hacking that ordinary RL causes, even without
being able to detect the reward hacking and without any extra information that
ordinary RL does not get access to. We study MONA empirically in three settings
which model different misalignment failure modes including 2-step environments
with LLMs representing delegated oversight and encoded reasoning and
longer-horizon gridworld environments representing sensor tampering.

æè¦ï¼æªä¾é²éç AI ç³»çµ±å¯è½ééäººé¡ç¡æ³ååçè§£ä»¥å®å¨è©ä¼°çå¼·åå­¸ç¿ (RL) ä¾å­¸ç¿è¤éçç­ç¥ãæåæåºäºä¸ç¨®è¨ç·´æ¹æ³ï¼å¯é¿åä»£çå­¸ç¿å³ä½¿äººé¡ç¡æ³åµæ¸¬å°è¡çºä¸åæ­¡è¿ï¼ä¹æç²å¾é«çåµçéé æå¤æ­¥é©è¨ç«ï¼å¤æ­¥é©ãçåµç ´è§£ãï¼ãéç¨®æ¹æ³ï¼è¿è¦åªåæ­éé è¦çåµ (MONA)ï¼æ¯ééçµåç­è¦åªåèé è¦çåµä¾éä½ãæåç¤ºç¯ MONA å¯ä»¥é²æ­¢ä¸è¬ RL é æçæ­¥é©çåµç ´è§£ï¼å³ä½¿ç¡æ³åµæ¸¬å°çåµç ´è§£ï¼ä¸æ²æä»»ä½ä¸è¬ RL ç¡æ³åå¾çé¡å¤è³è¨ãæåå¨ä¸ç¨®è¨­å®ä¸­ä»¥ç¶é©ç ç©¶ MONAï¼å¶ä¸­å»ºæ¨¡äºä¸åçå¤±æºå¤±ææ¨¡å¼ï¼åæ¬å·æä»£è¡¨å§æ´¾ç£ç£åç·¨ç¢¼æ¨çç LLM ç 2 æ­¥é©ç°å¢ï¼ä»¥åä»£è¡¨ææ¸¬å¨ç ´å£çè¼é·æç¨ç¶²æ ¼ä¸çç°å¢ã

##### **Pairwise RM: Perform Best-of-N Sampling with Knockout Tournament**
2501.13007v1 by Yantao Liu, Zijun Yao, Rui Min, Yixin Cao, Lei Hou, Juanzi Li

Best-of-N (BoN) sampling, a common strategy for test-time scaling of Large
Language Models (LLMs), relies on reward models to select the best candidate
solution from multiple generations. However, traditional reward models often
assign arbitrary and inconsistent scores, limiting their effectiveness. To
address this, we propose a Pairwise Reward Model (Pairwise RM) combined with a
knockout tournament for BoN sampling. Instead of assigning absolute scores,
given one math problem, Pairwise RM evaluates two candidate solutions'
correctness simultaneously. This approach eliminates the need for arbitrary
scoring and enables cross-validation of solutions through parallel comparison.
In the knockout tournament, Pairwise RM conducts pairwise comparisons between
candidate solutions and eliminates the incorrect ones iteratively. We construct
\ourdataset, a large-scale dataset of 443K pairwise comparisons derived from
NumiaMath and annotated using \texttt{gemini-1.5-flash}, and train the Pairwise
RM via supervised fine-tuning. Experiments on MATH-500 and the Olympiad Bench
demonstrate significant improvements over traditional discriminative reward
models. And a 40\% to 60\% relative improvement is achieved on the top 50\%
challenging problems.

æè¦ï¼æä½³ N (BoN) æ½æ¨£ï¼ä¸ç¨®å¤§åèªè¨æ¨¡å (LLM) æ¸¬è©¦æç¸®æ¾çå¸¸è¦ç­ç¥ï¼ä¾è³´æ¼çåµæ¨¡åå¾å¤åä¸ä»£ä¸­é¸åºæä½³åé¸è§£ãç¶èï¼å³çµ±ççåµæ¨¡åéå¸¸æåéä»»æä¸ä¸ä¸è´çåæ¸ï¼éå¶äºå®åçæææ§ãçºäºè§£æ±ºéååé¡ï¼æåæåºäºä¸ç¨®éå°çåµæ¨¡å (éå° RM)ï¼ä¸¦çµåæ·æ±°è³½é²è¡ BoN æ½æ¨£ãéå° RM æ²æåéçµå°åæ¸ï¼èæ¯çµ¦äºä¸åæ¸å­¸åé¡ï¼åæè©ä¼°å©ååé¸è§£çæ­£ç¢ºæ§ãéç¨®æ¹æ³æ¶é¤äºå°ä»»æè¨åçéè¦ï¼ä¸¦è½ééä¸¦è¡æ¯è¼å°è§£é²è¡äº¤åé©è­ãå¨æ·æ±°è³½ä¸­ï¼éå° RM å¨åé¸è§£ä¹éé²è¡éå°æ¯è¼ï¼ä¸¦åè¦æ·æ±°ä¸æ­£ç¢ºçè§£ãæåæ§å»ºäº \ourdatasetï¼ä¸åå¾ NumiaMath è¡çç 443K åéå°æ¯è¼çè¦æ¨¡åè³æéï¼ä¸¦ä½¿ç¨ \texttt{gemini-1.5-flash} é²è¡è¨»è§£ï¼ä¸¦ééç£ç£å¾®èª¿è¨ç·´éå° RMãå¨ MATH-500 åå¥§æå¹ååºæºä¸çå¯¦é©è­æäºç¸è¼æ¼å³çµ±çå¤å¥çåµæ¨¡åæé¡¯èçæ¹é²ãä¸¦ä¸å¨æå·ææ°æ§çåé¡å 50% ä¸­ï¼ç²å¾äº 40% å° 60% çç¸å°æ¹é²ã

##### **Implicit Causality-biases in humans and LLMs as a tool for benchmarking LLM discourse capabilities**
2501.12980v1 by Florian Kankowski, Torgrim Solstad, Sina Zarriess, Oliver Bott

In this paper, we compare data generated with mono- and multilingual LLMs
spanning a range of model sizes with data provided by human participants in an
experimental setting investigating well-established discourse biases. Beyond
the comparison as such, we aim to develop a benchmark to assess the
capabilities of LLMs with discourse biases as a robust proxy for more general
discourse understanding capabilities. More specifically, we investigated
Implicit Causality verbs, for which psycholinguistic research has found
participants to display biases with regard to three phenomena:\ the
establishment of (i) coreference relations (Experiment 1), (ii) coherence
relations (Experiment 2), and (iii) the use of particular referring expressions
(Experiments 3 and 4). With regard to coreference biases we found only the
largest monolingual LLM (German Bloom 6.4B) to display more human-like biases.
For coherence relation, no LLM displayed the explanation bias usually found for
humans. For referring expressions, all LLMs displayed a preference for
referring to subject arguments with simpler forms than to objects. However, no
bias effect on referring expression was found, as opposed to recent studies
investigating human biases.

æè¦ï¼<paragraph>å¨æ¬æä¸­ï¼æä»¬å°æ¯è¾åè¯­è¨åå¤è¯­è¨ LLM çæçèµæï¼è¿äºèµææ¶µçäºä¸ç³»åæ¨¡åè§æ¨¡ï¼å¹¶ä¸äººç±»åä¸èå¨å®éªç¯å¢ä¸­æä¾çèµæè¿è¡æ¯è¾ï¼ä»¥è°æ¥å·²ç¡®ç«çè¯è¯­åå·®ãé¤äºæ¯è¾æ¬èº«ä¹å¤ï¼æä»¬çç®æ æ¯å¶å®ä¸ä¸ªåºåæ¥è¯ä¼° LLM çè½åï¼å¶ä¸­è¯è¯­åå·®ä½ä¸ºæ´ä¸è¬è¯è¯­çè§£è½åçå¯é ä»£çãæ´å·ä½å°è¯´ï¼æä»¬è°æ¥äºéå«å æå³ç³»å¨è¯ï¼å¿çè¯­è¨å­¦ç ç©¶åç°åä¸èå¨ä»¥ä¸ä¸ä¸ªç°è±¡æ¹é¢è¡¨ç°åºåå·®ï¼(i) æç§°å³ç³»çå»ºç«ï¼å®éª 1ï¼ã(ii) è¿è´¯å³ç³»ï¼å®éª 2ï¼å (iii) ç¹å®æç§°è¡¨è¾¾å¼çä½¿ç¨ï¼å®éª 3 å 4ï¼ãå³äºæç§°åå·®ï¼æä»¬åç°åªææå¤§çåè¯­è¨ LLMï¼German Bloom 6.4Bï¼è¡¨ç°åºæ´åäººç±»çåå·®ãå¯¹äºè¿è´¯å³ç³»ï¼æ²¡æ LLM è¡¨ç°åºéå¸¸å¨äººç±»ä¸­åç°çè§£éåå·®ãå¯¹äºæç§°è¡¨è¾¾ï¼ææ LLM é½è¡¨ç°åºæ¯å¯¹è±¡æ´åæ¬¢ä½¿ç¨è¾ç®åçå½¢å¼æ¥æç§°ä¸»è¯­è®ºç¹çåå¥½ãç¶èï¼ä¸æè¿ç ç©¶äººç±»åå·®çç ç©¶ç¸åï¼æ²¡æåç°æç§°è¡¨è¾¾çåå·®æåºã</paragraph>

##### **FlanEC: Exploring Flan-T5 for Post-ASR Error Correction**
2501.12979v1 by Moreno La Quatra, Valerio Mario Salerno, Yu Tsao, Sabato Marco Siniscalchi

In this paper, we present an encoder-decoder model leveraging Flan-T5 for
post-Automatic Speech Recognition (ASR) Generative Speech Error Correction
(GenSEC), and we refer to it as FlanEC. We explore its application within the
GenSEC framework to enhance ASR outputs by mapping n-best hypotheses into a
single output sentence. By utilizing n-best lists from ASR models, we aim to
improve the linguistic correctness, accuracy, and grammaticality of final ASR
transcriptions. Specifically, we investigate whether scaling the training data
and incorporating diverse datasets can lead to significant improvements in
post-ASR error correction. We evaluate FlanEC using the HyPoradise dataset,
providing a comprehensive analysis of the model's effectiveness in this domain.
Furthermore, we assess the proposed approach under different settings to
evaluate model scalability and efficiency, offering valuable insights into the
potential of instruction-tuned encoder-decoder models for this task.

æè¦ï¼å¨æ¬æä¸­ï¼æåæåºäºä¸åç·¨ç¢¼å¨-è§£ç¢¼å¨æ¨¡åï¼å©ç¨ Flan-T5 é²è¡èªåèªé³è¾¨è­ (ASR) å¾ççæå¼èªé³é¯èª¤æ ¡æ­£ (GenSEC)ï¼æåç¨±ä¹çº FlanECãæåå¨ GenSEC æ¡æ¶å§æ¢ç´¢å¶æç¨ï¼ééå° n åæä½³åè¨­æ å°å°ä¸åå®ä¸çè¼¸åºå¥å­ä¾å¢å¼· ASR è¼¸åºãééå©ç¨ ASR æ¨¡åä¸­ç n åæä½³åè¡¨ï¼æåçç®æ¨æ¯æé«æçµ ASR è½éçèªè¨æ­£ç¢ºæ§ãæºç¢ºæ§åèªæ³æ§ãå·é«ä¾èªªï¼æåç ç©¶äºæ´åè¨ç·´æ¸æåç´å¥å¤æ¨£åæ¸æéæ¯å¦æå° ASR å¾é¯èª¤æ ¡æ­£ç¢çé¡¯èçæ¹é²ãæåä½¿ç¨ HyPoradise æ¸æéè©ä¼° FlanECï¼å°æ¨¡åå¨éåé åçæææ§é²è¡äºå¨é¢çåæãæ­¤å¤ï¼æåå¨ä¸åçè¨­ç½®ä¸è©ä¼°ææåºçæ¹æ³ï¼ä»¥è©ä¼°æ¨¡åçå¯æ´å±æ§åæçï¼çºéç¨®ä»»åçæä»¤èª¿æ´ç·¨ç¢¼å¨-è§£ç¢¼å¨æ¨¡åçæ½åæä¾äºå¯¶è²´çè¦è§£ã

##### **OnionEval: An Unified Evaluation of Fact-conflicting Hallucination for Small-Large Language Models**
2501.12975v1 by Chongren Sun, Yuran Li, Di Wu, Benoit Boulet

Large Language Models (LLMs) are highly capable but require significant
computational resources for both training and inference. Within the LLM family,
smaller models (those with fewer than 10 billion parameters) also perform well
across various tasks. However, these smaller models share similar limitations
to their larger counterparts, including the tendency to hallucinate. Despite
the existence of many benchmarks to evaluate hallucination in LLMs, few have
specifically focused on small LLMs (SLLMs). Additionally, SLLMs show widely
varying performance across different benchmarks. In this paper, we introduce
OnionEval, a multi-layer structured framework with a specific metric called the
context-influence score (CI), designed to effectively assess the
fact-conflicting hallucination tendencies of small LLMs across different
contextual levels. Our experimental results reveal a key feature of SLLMs: they
excel in factual analysis but face challenges with context reasoning. Further
investigation shows that a simple Chain-of-Thought strategy can significantly
reduce these limitations, improving the practical usefulness of SLLMs in
real-world applications.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çè½åæ¥µå¼·ï¼ä½ç¡è«æ¯å¨è¨ç·´ææ¨çä¸ï¼é½éè¦å¤§éçéç®è³æºãå¨ LLM å®¶æä¸­ï¼è¼å°çæ¨¡åï¼åæ¸å°æ¼ 100 ååï¼ä¹è½å¨åç¨®ä»»åä¸­è¡¨ç¾è¯å¥½ãç¶èï¼éäºè¼å°çæ¨¡åèè¼å¤§çæ¨¡åä¸æ¨£ï¼æé¡ä¼¼çéå¶ï¼åæ¬åºç¾å¹»è¦ºçå¾åãåç®¡æè¨±å¤åºæºä¾è©ä¼° LLM ä¸­çå¹»è¦ºï¼ä½é®®å°å°æ³¨æ¼å°å LLM (SLLM)ãæ­¤å¤ï¼SLLM å¨ä¸åçåºæºä¸­è¡¨ç¾å·®ç°å¾å¤§ãå¨æ¬æä¸­ï¼æåä»ç´¹äº OnionEvalï¼éæ¯ä¸åå¤å±¤çµæ§æ¡æ¶ï¼æä¸åç¨±çºä¸ä¸æå½±é¿åæ¸ (CI) çç¹å®ææ¨ï¼æ¨å¨ææè©ä¼°ä¸åä¸ä¸æå±¤ç´ä¸­å°å LLM çäºå¯¦è¡çªå¹»è¦ºå¾åãæåçå¯¦é©çµææ­ç¤ºäº SLLM çä¸åééµç¹å¾µï¼å®åå¨äºå¯¦åæä¸­è¡¨ç¾åºè²ï¼ä½å¨ä¸ä¸ææ¨çæ¹é¢é¢è¨ææ°ãé²ä¸æ­¥çèª¿æ¥é¡¯ç¤ºï¼ä¸åç°¡å®çæèéç­ç¥å¯ä»¥é¡¯èæ¸å°éäºéå¶ï¼æé« SLLM å¨å¯¦éæç¨ä¸­çå¯¦ç¨æ§ã

##### **Accessible Smart Contracts Verification: Synthesizing Formal Models with Tamed LLMs**
2501.12972v1 by Jan Corazza, Ivan Gavran, Gabriela Moreira, Daniel Neider

When blockchain systems are said to be trustless, what this really means is
that all the trust is put into software. Thus, there are strong incentives to
ensure blockchain software is correct -- vulnerabilities here cost millions and
break businesses. One of the most powerful ways of establishing software
correctness is by using formal methods. Approaches based on formal methods,
however, induce a significant overhead in terms of time and expertise required
to successfully employ them. Our work addresses this critical disadvantage by
automating the creation of a formal model -- a mathematical abstraction of the
software system -- which is often a core task when employing formal methods. We
perform model synthesis in three phases: we first transpile the code into model
stubs; then we "fill in the blanks" using a large language model (LLM);
finally, we iteratively repair the generated model, on both syntactical and
semantical level. In this way, we significantly reduce the amount of time
necessary to create formal models and increase accessibility of valuable
software verification methods that rely on them. The practical context of our
work was reducing the time-to-value of using formal models for correctness
audits of smart contracts.

æè¦ï¼ç¶åå¡éç³»çµ±è¢«ç¨±ä½ç¡éä¿¡ä»»æï¼éå¯¦éä¸æå³è
ææçä¿¡ä»»é½è³¦äºäºè»é«ãå æ­¤ï¼æå¼·ççèªå ä¾
ç¢ºä¿åå¡éè»é«æ¯æ­£ç¢ºçââæ­¤èçæ¼æ´æé ææ¸ç¾è¬æå¤±ä¸¦
è®ä¼æ¥­ç ´ç¢ãå»ºç«è»é«æ­£ç¢ºæ§çææåçæ¹æ³ä¹ä¸æ¯ä½¿ç¨å½¢å¼åæ¹æ³ã
ç¶èï¼åºæ¼å½¢å¼åæ¹æ³çæ¹æ³æå°è´å¨æéåå°æ¥­ç¥è­æ¹é¢çé¡¯èéé·
æè½æåå°ä½¿ç¨å®åãæåçä½åééèªååå½¢å¼åæ¨¡åçå»ºç«ä¾è§£æ±ºéåéå¤§çç¼ºé»ââè»é«ç³»çµ±çæ¸å­¸æ½è±¡ââééå¸¸æ¯ä½¿ç¨å½¢å¼åæ¹æ³æçæ ¸å¿ä»»åãæå
åä¸åéæ®µå·è¡æ¨¡ååæï¼æåé¦åå°ç¨å¼ç¢¼è½è­¯ææ¨¡åå­æ ¹ï¼ç¶å¾æåä½¿ç¨å¤§åèªè¨æ¨¡å (LLM)ãå¡«è£ç©ºç½ãï¼
æå¾ï¼æåå¨èªæ³åèªç¾©å±¤é¢ä¸åè¦ä¿®å¾©ç¢ççæ¨¡åãéééç¨®æ¹å¼ï¼æåå¤§å¹æ¸å°å»ºç«å½¢å¼åæ¨¡åæéçæéï¼ä¸¦å¢å ä¾è³´å®åçå¯¶è²´è»é«é©è­æ¹æ³çå¯åæ§ãæåå·¥ä½çå¯¦éèæ¯æ¯æ¸å°ä½¿ç¨å½¢å¼åæ¨¡åé²è¡æºæ§åç´æ­£ç¢ºæ§ç¨½æ ¸çæéå¹å¼ã

##### **It's complicated. The relationship of algorithmic fairness and non-discrimination regulations in the EU AI Act**
2501.12962v1 by Kristof Meding

What constitutes a fair decision? This question is not only difficult for
humans but becomes more challenging when Artificial Intelligence (AI) models
are used. In light of discriminatory algorithmic behaviors, the EU has recently
passed the AI Act, which mandates specific rules for AI models, incorporating
both traditional legal non-discrimination regulations and machine learning
based algorithmic fairness concepts. This paper aims to bridge these two
different concepts in the AI Act through: First a high-level introduction of
both concepts targeting legal and computer science-oriented scholars, and
second an in-depth analysis of the AI Act's relationship between legal
non-discrimination regulations and algorithmic fairness. Our analysis reveals
three key findings: (1.), most non-discrimination regulations target only
high-risk AI systems. (2.), the regulation of high-risk systems encompasses
both data input requirements and output monitoring, though these regulations
are often inconsistent and raise questions of computational feasibility. (3.)
Regulations for General Purpose AI Models, such as Large Language Models that
are not simultaneously classified as high-risk systems, currently lack
specificity compared to other regulations. Based on these findings, we
recommend developing more specific auditing and testing methodologies for AI
systems. This paper aims to serve as a foundation for future interdisciplinary
collaboration between legal scholars and computer science-oriented machine
learning researchers studying discrimination in AI systems.

æè¦ï¼ä»éº¼æ§æä¸åå¬å¹³çæ±ºå®ï¼éååé¡ä¸åå°äººé¡ä¾èªªå¾é£ï¼ç¶ä½¿ç¨äººå·¥æºæ§ï¼AIï¼æ¨¡åæï¼éååé¡æè®å¾æ´å·ææ°æ§ãéæ¼æ¼ç®æ³è¡çºå·ææ­§è¦æ§ï¼æ­çæè¿ééäº AI æ³æ¡ï¼è©²æ³æ¡å° AI æ¨¡åå¶å®äºå·é«è¦åï¼çµåäºå³çµ±çæ³å¾åæ­§è¦æ³è¦ååºæ¼æ©å¨å­¸ç¿çæ¼ç®æ³å¬å¹³æ§æ¦å¿µãæ¬ææ¨å¨ééä»¥ä¸æ¹å¼å½å AI æ³æ¡ä¸­çéå©åä¸åæ¦å¿µï¼é¦åï¼éå°æ³å¾åé»è¦ç§å­¸å­¸èçé«å±¤ç´ä»ç´¹ï¼å¶æ¬¡ï¼æ·±å¥åæ AI æ³æ¡å¨æ³å¾åæ­§è¦æ³è¦åæ¼ç®æ³å¬å¹³æ§ä¹éçéä¿ãæåçåææ­ç¤ºäºä¸åééµç¼ç¾ï¼(1.)ï¼å¤§å¤æ¸åæ­§è¦æ³è¦åªéå°é«é¢¨éª AI ç³»çµ±ã(2.)ï¼é«é¢¨éªç³»çµ±çæ³è¦åå«è³æè¼¸å¥éæ±åè¼¸åºç£æ§ï¼åç®¡éäºæ³è¦éå¸¸ä¸ä¸è´ï¼ä¸¦å¼ç¼äºè¨ç®å¯è¡æ§çåé¡ã(3.)ï¼éç¨ AI æ¨¡åçæ³è¦ï¼ä¾å¦æªåææ­¸é¡çºé«é¢¨éªç³»çµ±çå¤§èªè¨æ¨¡åï¼èå¶ä»æ³è¦ç¸æ¯ç®åç¼ºä¹å·é«æ§ãæ ¹æéäºç¼ç¾ï¼æåå»ºè­°çº AI ç³»çµ±éç¼æ´å·é«çç¨½æ ¸åæ¸¬è©¦æ¹æ³ãæ¬ææ¨å¨ä½çºæ³å¾å­¸èåä»¥é»è¦ç§å­¸çºå°åçæ©å¨å­¸ç¿ç ç©¶äººå¡ä¹éæªä¾è·¨å­¸ç§åä½çåºç¤ï¼ç ç©¶ AI ç³»çµ±ä¸­çæ­§è¦ã

##### **Efficient Prompt Compression with Evaluator Heads for Long-Context Transformer Inference**
2501.12959v1 by Weizhi Fei, Xueyan Niu, Guoqing Xie, Yingqing Liu, Bo Bai, Wei Han

Although applications involving long-context inputs are crucial for the
effective utilization of large language models (LLMs), they also result in
increased computational costs and reduced performance. To address this
challenge, we propose an efficient, training-free prompt compression method
that retains key information within compressed prompts. We identify specific
attention heads in transformer-based LLMs, which we designate as evaluator
heads, that are capable of selecting tokens in long inputs that are most
significant for inference. Building on this discovery, we develop EHPC, an
Evaluator Head-based Prompt Compression method, which enables LLMs to rapidly
"skim through" input prompts by leveraging only the first few layers with
evaluator heads during the pre-filling stage, subsequently passing only the
important tokens to the model for inference. EHPC achieves state-of-the-art
results across two mainstream benchmarks: prompt compression and long-context
inference acceleration. Consequently, it effectively reduces the complexity and
costs associated with commercial API calls. We further demonstrate that EHPC
attains competitive results compared to key-value cache-based acceleration
methods, thereby highlighting its potential to enhance the efficiency of LLMs
for long-context tasks.

æè¦ï¼åç®¡æ¶åé·èªå¢è¼¸å¥çæç¨ç¨å¼å°æ¼å¤§èªè¨æ¨¡å (LLM) çææå©ç¨è³ééè¦ï¼ä½å®åä¹å°è´éç®ææ¬å¢å åæè½éä½ãçºäºæå°éåææ°ï¼æåæåºäºä¸ç¨®ææçãç¡éè¨ç·´çæç¤ºå£ç¸®æ¹æ³ï¼å®ä¿çäºå£ç¸®æç¤ºä¸­çééµè³è¨ãæåå¨åºæ¼è½æå¨ç LLM ä¸­è­å¥åºç¹å®çæ³¨æåé ­ï¼æåå°å®åæå®çºè©ä¼°å¨é ­ï¼å®åè½å¤ å¨é·è¼¸å¥ä¸­é¸æå°æ¨è«æéè¦çä»£å¹£ãåºæ¼éåç¼ç¾ï¼æåéç¼äº EHPCï¼ä¸ç¨®åºæ¼è©ä¼°å¨é ­çæç¤ºå£ç¸®æ¹æ³ï¼å®ä½¿ LLM è½å¤ åå©ç¨é å¡«å¥éæ®µä¸­å¸¶æè©ä¼°å¨é ­çåå¹¾å±¤å¿«éãçè¦½ãè¼¸å¥æç¤ºï¼é¨å¾åå°éè¦çä»£å¹£å³éçµ¦æ¨¡åé²è¡æ¨è«ãEHPC å¨å©åä¸»æµåºæºä¸éå°äºæåé²ççµæï¼æç¤ºå£ç¸®åé·èªå¢æ¨è«å éãå æ­¤ï¼å®ææå°éä½äºèåæ¥­ API å¼å«ç¸éçè¤éæ§åææ¬ãæåé²ä¸æ­¥è­æï¼èåºæ¼å¿«åçå éæ¹æ³ç¸æ¯ï¼EHPC éå°äºå·æç«¶ç­åççµæï¼å¾èçªé¡¯äºå®å¢å¼· LLM å¨é·èªå¢ä»»åä¸­çæççæ½åã

##### **GANQ: GPU-Adaptive Non-Uniform Quantization for Large Language Models**
2501.12956v1 by Pengxiang Zhao, Xiaoming Yuan

Large Language Models (LLMs) face significant deployment challenges due to
their substantial resource requirements. While low-bit quantized weights can
reduce memory usage and improve inference efficiency, current hardware lacks
native support for mixed-precision General Matrix Multiplication (mpGEMM),
resulting in inefficient dequantization-based implementations. Moreover,
uniform quantization methods often fail to capture weight distributions
adequately, leading to performance degradation. We propose GANQ (GPU-Adaptive
Non-Uniform Quantization), a layer-wise post-training non-uniform quantization
framework optimized for hardware-efficient lookup table-based mpGEMM. GANQ
achieves superior quantization performance by utilizing a training-free,
GPU-adaptive optimization algorithm to efficiently reduce layer-wise
quantization errors. Extensive experiments demonstrate GANQ's ability to reduce
the perplexity gap from the FP16 baseline compared to state-of-the-art methods
for both 3-bit and 4-bit quantization. Furthermore, when deployed on a single
NVIDIA RTX 4090 GPU, GANQ's quantized models achieve up to 2.57$\times$ speedup
over the baseline, advancing memory and inference efficiency in LLM deployment.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å å¶é¾å¤§çè³æºéæ±èé¢è¨éå¤§çé¨ç½²ææ°ãåç®¡ä½ä½åéåæ¬éå¯ä»¥æ¸å°è¨æ¶é«ä½¿ç¨éä¸¦æåæ¨è«æçï¼ä½ç®åçç¡¬é«ç¼ºä¹å°æ··åç²¾åº¦ä¸è¬ç©é£ä¹æ³ (mpGEMM) çåçæ¯æ´ï¼å°è´ééåçºåºç¤çå¯¦ä½æçä¸å½°ãæ­¤å¤ï¼åå»éåæ¹æ³éå¸¸ç¡æ³ååæ·åæ¬éåä½ï¼å°è´æè½ä¸éãæåæåº GANQ (GPU èªé©æéåå»éå)ï¼ä¸ç¨®éå°ç¡¬é«æææ¥æ¾è¡¨æ ¼å mpGEMM æä½³åçå±¤ç´å¾è¨ç·´éåå»éåæ¶æ§ãGANQ ééå©ç¨ç¡éè¨ç·´ç GPU èªé©ææä½³åæ¼ç®æ³ï¼ææéä½å±¤ç´éåèª¤å·®ï¼éæåªç°çéåæè½ãå»£æ³çå¯¦é©è­æ GANQ éä½å°æåº¦ééçè½åï¼è 3 ä½åå 4 ä½åéåçæåé²æ¹æ³ç¸æ¯ï¼å¾ FP16 åºæºç·éä½å°æåº¦ééãæ­¤å¤ï¼ç¶é¨ç½²å¨å®ä¸ NVIDIA RTX 4090 GPU ä¸æï¼GANQ çéåæ¨¡åå¯éå°æ¯åºæºç·å¿« 2.57 åçéåº¦ï¼æå LLM é¨ç½²ä¸­çè¨æ¶é«åæ¨è«æçã

##### **Multifractal hopscotch in "Hopscotch" by Julio Cortazar**
2501.12955v1 by Jakub Dec, MichaÅ Dolina, StanisÅaw DroÅ¼dÅ¼, JarosÅaw KwapieÅ, Tomasz Stanisz

Punctuation is the main factor introducing correlations in natural language
written texts and it crucially impacts their overall effectiveness,
expressiveness, and readability. Punctuation marks at the end of sentences are
of particular importance as their distribution can determine various complexity
features of written natural language. Here, the sentence length variability
(SLV) time series representing "Hopscotch" by Julio Cortazar are subjected to
quantitative analysis with an attempt to identify their distribution type,
long-memory effects, and potential multiscale patterns. The analyzed novel is
an important and innovative piece of literature whose essential property is
freedom of movement between its building blocks given to a reader by the
author. The statistical consequences of this freedom are closely investigated
in both the original, Spanish version of the novel, and its translations into
English and Polish. Clear evidence of rich multifractality in the SLV dynamics,
with a left-sided asymmetry, however, is observed in all three language
versions as well as in the versions with differently ordered chapters.

æè¦ï¼æ¨é»ç¬¦èæ¯èªç¶èªè¨æ¸é¢ææ¬ä¸­å¼å¥éè¯æ§çä¸»è¦å ç´ ï¼ä¸¦ä¸å®å°å¶æ´é«æææ§ãè¡¨éæ§åå¯è®æ§ç¢çè³ééè¦çå½±é¿ãå¥å­çµå°¾çæ¨é»ç¬¦èç¹å¥éè¦ï¼å çºå®åçåå¸å¯ä»¥æ±ºå®æ¸é¢èªç¶èªè¨çåç¨®è¤éæ§ç¹å¾µãå¨æ­¤ï¼ç±è¡éå¥§Â·ç§å¡è©ç¾æ°å¯«çãè·³æ¿å­ãå¥å­é·åº¦å¯è®æ§ (SLV) æéåºåç¶éå®éåæï¼è©¦åè­å¥å®åçåå¸é¡åãé·è¨æ¶ææåæ½å¨çå¤å°ºåº¦æ¨¡å¼ãæåæçå°èªªæ¯ä¸é¨éè¦ä¸åµæ°çæå­¸ä½åï¼å¶åºæ¬å±¬æ§æ¯ä½èè³¦äºè®èçæ§å»ºæ¨¡çµä¹éçèªç±ç§»åãéç¨®èªç±ççµ±è¨å¾æå¨å°èªªçè¥¿ç­çèªåçåå¶è±æåæ³¢è­æè­¯æ¬ä¸­é½åå°å¯åç ç©¶ãç¶èï¼å¨ä¸ç¨®èªè¨çæ¬ä»¥åç« ç¯é åºä¸åççæ¬ä¸­ï¼é½è§å¯å° SLV ååå­¸ä¸­è±å¯çå¤éåå½¢æ§ï¼å·æå·¦åä¸å°ç¨±æ§ã

##### **Punctuation patterns in "Finnegans Wake" by James Joyce are largely translation-invariant**
2501.12954v1 by Krzysztof Bartnicki, StanisÅaw DroÅ¼dÅ¼, JarosÅaw KwapieÅ, Tomasz Stanisz

The complexity characteristics of texts written in natural languages are
significantly related to the rules of punctuation. In particular, the distances
between punctuation marks measured by the number of words quite universally
follow the family of Weibull distributions known from survival analyses.
However, the values of two parameters marking specific forms of these
distributions distinguish specific languages. This is such a strong constraint
that the punctuation distributions of texts translated from the original
language into another adopt quantitative characteristics of the target
language. All these changes take place within Weibull distributions such that
the corresponding hazard functions are always increasing. Recent previous
research shows that James Joyce's famous "Finnegans Wake" is subject to such
extreme distribution from the Weibull family that the corresponding hazard
function is clearly decreasing. At the same time, the distances of sentence
ending punctuation marks, determining the variability of sentence length, have
an almost perfect multifractal organization, so far to such an extent found
nowhere else in the literature. In the present contribution based on several
available translations (Dutch, French, German, Polish, Russian) of "Finnegans
Wake", it is shown that the punctuation characteristics of this work remain
largely translation invariant, contrary to the common cases. These observations
may constitute further evidence that "Finnegans Wake" is a translinguistic work
in this respect as well, in line with Joyce's original intention.

æè¦ï¼èªç¶èªè¨æ¸å¯«ææ¬çè¤éæ§ç¹å¾µèæ¨é»ç¬¦èè¦åæé¡¯èç¸éæ§ãç¹å¥æ¯ï¼ä»¥å­æ¸æ¸¬éçæ¨é»ç¬¦èä¹éçè·é¢æ®ééµå¾ªå¨å¸ç¾åå¸æï¼éæ¯å¾çå­åæä¸­å¾ç¥çãç¶èï¼æ¨è¨éäºåå¸ç¹å®å½¢å¼çå©ååæ¸çå¼ååäºç¹å®èªè¨ãéæ¯ä¸åå¦æ­¤å¼·ççç´æï¼ä»¥è³æ¼å¾åå§èªè¨ç¿»è­¯æå¦ä¸ç¨®èªè¨çæ¨é»åä½æ¡ç¨ç®æ¨èªè¨çéåç¹å¾µãææéäºè®åé½ç¼çå¨å¨å¸ç¾åä½ä¸­ï¼ä½¿å¾å°æçé¢¨éªå½æ¸å§çµå¢å ãæè¿ååçç ç©¶è¡¨æï¼è©¹å§æ¯Â·å¬ä¼æ¯çèåä½åãè¬å°¼æ ¹çå®éå¤ãåå°å¨å¸ç¾å®¶æçæ¥µç«¯åä½ï¼ä»¥è³æ¼å°æçé¢¨éªå½æ¸æé¡¯ä¸éãèæ­¤åæï¼å¥å­çµææ¨é»ç¬¦èçè·é¢æ±ºå®äºå¥é·çå¯è®æ§ï¼å·æå¹¾ä¹å®ç¾çå¤åå½¢çµç¹ï¼å°ç®åçºæ­¢ï¼å¨å¶ä»æç»ä¸­éæ²æç¼ç¾éç¨®ç¨åº¦ãå¨åºæ¼ãè¬å°¼æ ¹çå®éå¤ãçå¹¾ç¨®å¯ç¨ç¿»è­¯ï¼è·è­èªãæ³èªãå¾·èªãæ³¢è­èªãä¿èªï¼çç¶åè²¢ç»ä¸­ï¼è¡¨æéé¨ä½åçæ¨é»ç¬¦èç¹å¾µå¨å¾å¤§ç¨åº¦ä¸ä¿æç¿»è­¯ä¸è®ï¼éèå¸¸è¦ææ³ç¸åãéäºè§å¯å¯è½æ§æé²ä¸æ­¥çè­æï¼è­æãè¬å°¼æ ¹çå®éå¤ãå¨éåæ¹é¢ä¹æ¯ä¸é¨è·¨èªè¨çä½åï¼éç¬¦åå¬ä¼æ¯çæåæåã

##### **DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning**
2501.12948v1 by DeepSeek-AI, Daya Guo, Dejian Yang, Haowei Zhang, Junxiao Song, Ruoyu Zhang, Runxin Xu, Qihao Zhu, Shirong Ma, Peiyi Wang, Xiao Bi, Xiaokang Zhang, Xingkai Yu, Yu Wu, Z. F. Wu, Zhibin Gou, Zhihong Shao, Zhuoshu Li, Ziyi Gao, Aixin Liu, Bing Xue, Bingxuan Wang, Bochao Wu, Bei Feng, Chengda Lu, Chenggang Zhao, Chengqi Deng, Chenyu Zhang, Chong Ruan, Damai Dai, Deli Chen, Dongjie Ji, Erhang Li, Fangyun Lin, Fucong Dai, Fuli Luo, Guangbo Hao, Guanting Chen, Guowei Li, H. Zhang, Han Bao, Hanwei Xu, Haocheng Wang, Honghui Ding, Huajian Xin, Huazuo Gao, Hui Qu, Hui Li, Jianzhong Guo, Jiashi Li, Jiawei Wang, Jingchang Chen, Jingyang Yuan, Junjie Qiu, Junlong Li, J. L. Cai, Jiaqi Ni, Jian Liang, Jin Chen, Kai Dong, Kai Hu, Kaige Gao, Kang Guan, Kexin Huang, Kuai Yu, Lean Wang, Lecong Zhang, Liang Zhao, Litong Wang, Liyue Zhang, Lei Xu, Leyi Xia, Mingchuan Zhang, Minghua Zhang, Minghui Tang, Meng Li, Miaojun Wang, Mingming Li, Ning Tian, Panpan Huang, Peng Zhang, Qiancheng Wang, Qinyu Chen, Qiushi Du, Ruiqi Ge, Ruisong Zhang, Ruizhe Pan, Runji Wang, R. J. Chen, R. L. Jin, Ruyi Chen, Shanghao Lu, Shangyan Zhou, Shanhuang Chen, Shengfeng Ye, Shiyu Wang, Shuiping Yu, Shunfeng Zhou, Shuting Pan, S. S. Li, Shuang Zhou, Shaoqing Wu, Shengfeng Ye, Tao Yun, Tian Pei, Tianyu Sun, T. Wang, Wangding Zeng, Wanjia Zhao, Wen Liu, Wenfeng Liang, Wenjun Gao, Wenqin Yu, Wentao Zhang, W. L. Xiao, Wei An, Xiaodong Liu, Xiaohan Wang, Xiaokang Chen, Xiaotao Nie, Xin Cheng, Xin Liu, Xin Xie, Xingchao Liu, Xinyu Yang, Xinyuan Li, Xuecheng Su, Xuheng Lin, X. Q. Li, Xiangyue Jin, Xiaojin Shen, Xiaosha Chen, Xiaowen Sun, Xiaoxiang Wang, Xinnan Song, Xinyi Zhou, Xianzu Wang, Xinxia Shan, Y. K. Li, Y. Q. Wang, Y. X. Wei, Yang Zhang, Yanhong Xu, Yao Li, Yao Zhao, Yaofeng Sun, Yaohui Wang, Yi Yu, Yichao Zhang, Yifan Shi, Yiliang Xiong, Ying He, Yishi Piao, Yisong Wang, Yixuan Tan, Yiyang Ma, Yiyuan Liu, Yongqiang Guo, Yuan Ou, Yuduan Wang, Yue Gong, Yuheng Zou, Yujia He, Yunfan Xiong, Yuxiang Luo, Yuxiang You, Yuxuan Liu, Yuyang Zhou, Y. X. Zhu, Yanhong Xu, Yanping Huang, Yaohui Li, Yi Zheng, Yuchen Zhu, Yunxian Ma, Ying Tang, Yukun Zha, Yuting Yan, Z. Z. Ren, Zehui Ren, Zhangli Sha, Zhe Fu, Zhean Xu, Zhenda Xie, Zhengyan Zhang, Zhewen Hao, Zhicheng Ma, Zhigang Yan, Zhiyu Wu, Zihui Gu, Zijia Zhu, Zijun Liu, Zilin Li, Ziwei Xie, Ziyang Song, Zizheng Pan, Zhen Huang, Zhipeng Xu, Zhongyu Zhang, Zhen Zhang

We introduce our first-generation reasoning models, DeepSeek-R1-Zero and
DeepSeek-R1. DeepSeek-R1-Zero, a model trained via large-scale reinforcement
learning (RL) without supervised fine-tuning (SFT) as a preliminary step,
demonstrates remarkable reasoning capabilities. Through RL, DeepSeek-R1-Zero
naturally emerges with numerous powerful and intriguing reasoning behaviors.
However, it encounters challenges such as poor readability, and language
mixing. To address these issues and further enhance reasoning performance, we
introduce DeepSeek-R1, which incorporates multi-stage training and cold-start
data before RL. DeepSeek-R1 achieves performance comparable to OpenAI-o1-1217
on reasoning tasks. To support the research community, we open-source
DeepSeek-R1-Zero, DeepSeek-R1, and six dense models (1.5B, 7B, 8B, 14B, 32B,
70B) distilled from DeepSeek-R1 based on Qwen and Llama.

æè¦ï¼æåä»ç´¹äºæåçç¬¬ä¸ä»£æ¨çæ¨¡åï¼DeepSeek-R1-Zero å DeepSeek-R1ãDeepSeek-R1-Zero æ¯ä¸åééå¤§è¦æ¨¡å¼·åå­¸ç¿ (RL) è¨ç·´çæ¨¡åï¼æ²æç£ç£å¾®èª¿ (SFT) ä½çºé åæ­¥é©ï¼å±ç¤ºäºåè¶çæ¨çè½åãéé RLï¼DeepSeek-R1-Zero èªç¶èç¶å°åºç¾äºè¨±å¤å¼·å¤§èæè¶£çæ¨çè¡çºãç¶èï¼å®éå°äºå¯è®æ§å·®åèªè¨æ··éç­ææ°ãçºäºè§£æ±ºéäºåé¡ä¸¦é²ä¸æ­¥å¢å¼·æ¨çæ§è½ï¼æåå¼å¥äº DeepSeek-R1ï¼å®å¨ RL ä¹åçµåäºå¤éæ®µè¨ç·´åå·ååæ¸æãDeepSeek-R1 å¨æ¨çä»»åä¸éå°äºè OpenAI-o1-1217 ç¸ç¶çæ§è½ãçºäºæ¯æç ç©¶ç¤¾ç¾¤ï¼æåéæ¾äº DeepSeek-R1-ZeroãDeepSeek-R1 åå­ååºæ¼ Qwen å Llama å¾ DeepSeek-R1 æçåºçç¨ å¯æ¨¡å (1.5Bã7Bã8Bã14Bã32Bã70B) çåå§ç¢¼ã

##### **PreciseCam: Precise Camera Control for Text-to-Image Generation**
2501.12910v1 by Edurne Bernal-Berdun, Ana Serrano, Belen Masia, Matheus Gadelha, Yannick Hold-Geoffroy, Xin Sun, Diego Gutierrez

Images as an artistic medium often rely on specific camera angles and lens
distortions to convey ideas or emotions; however, such precise control is
missing in current text-to-image models. We propose an efficient and general
solution that allows precise control over the camera when generating both
photographic and artistic images. Unlike prior methods that rely on predefined
shots, we rely solely on four simple extrinsic and intrinsic camera parameters,
removing the need for pre-existing geometry, reference 3D objects, and
multi-view data. We also present a novel dataset with more than 57,000 images,
along with their text prompts and ground-truth camera parameters. Our
evaluation shows precise camera control in text-to-image generation, surpassing
traditional prompt engineering approaches. Our data, model, and code are
publicly available at https://graphics.unizar.es/projects/PreciseCam2024.

æè¦ï¼å½±åä½çºä¸ç¨®èè¡åªä»ï¼ç¶å¸¸ä¾è³´ç¹å®çç¸æ©è§åº¦åé¡é ­è®å½¢ä¾å³éæ³æ³ææç·ï¼ç¶èï¼éç¨®ç²¾ç¢ºçæ§å¶å¨ç®åçæå­è½å½±åæ¨¡åä¸­å»ä»ä¹éå¦ãæåæåºä¸åææä¸éç¨çè§£æ±ºæ¹æ¡ï¼åè¨±å¨çææå½±åèè¡å½±åæç²¾ç¢ºæ§å¶ç¸æ©ãæå¥æ¼ä¾è³´é åå®ç¾©çé¡é ­çååæ¹æ³ï¼æååä¾è³´ååç°¡å®çå¤å¨åå§å¨ç¸æ©åæ¸ï¼æ¶é¤äºå°é åå­å¨çå¹¾ä½å½¢çãåè 3D ç©ä»¶åå¤è¦åè³æçéæ±ãæåéæä¾äºä¸ååå«è¶é 57,000 å¼µå½±åçæ°ç©è³æéï¼ä»¥åå¶æå­æç¤ºåå°é¢å¯¦æ³ç¸æ©åæ¸ãæåçè©ä¼°é¡¯ç¤ºå¨æå­è½å½±åçæä¸­ç²¾ç¢ºæ§å¶ç¸æ©ï¼è¶è¶å³çµ±çæç¤ºå·¥ç¨æ¹æ³ãæåçè³æãæ¨¡ååç¨å¼ç¢¼å¯å¨ https://graphics.unizar.es/projects/PreciseCam2024 å¬éåå¾ã

##### **FilmAgent: A Multi-Agent Framework for End-to-End Film Automation in Virtual 3D Spaces**
2501.12909v1 by Zhenran Xu, Longyue Wang, Jifang Wang, Zhouyi Li, Senbao Shi, Xue Yang, Yiyu Wang, Baotian Hu, Jun Yu, Min Zhang

Virtual film production requires intricate decision-making processes,
including scriptwriting, virtual cinematography, and precise actor positioning
and actions. Motivated by recent advances in automated decision-making with
language agent-based societies, this paper introduces FilmAgent, a novel
LLM-based multi-agent collaborative framework for end-to-end film automation in
our constructed 3D virtual spaces. FilmAgent simulates various crew roles,
including directors, screenwriters, actors, and cinematographers, and covers
key stages of a film production workflow: (1) idea development transforms
brainstormed ideas into structured story outlines; (2) scriptwriting elaborates
on dialogue and character actions for each scene; (3) cinematography determines
the camera setups for each shot. A team of agents collaborates through
iterative feedback and revisions, thereby verifying intermediate scripts and
reducing hallucinations. We evaluate the generated videos on 15 ideas and 4 key
aspects. Human evaluation shows that FilmAgent outperforms all baselines across
all aspects and scores 3.98 out of 5 on average, showing the feasibility of
multi-agent collaboration in filmmaking. Further analysis reveals that
FilmAgent, despite using the less advanced GPT-4o model, surpasses the
single-agent o1, showing the advantage of a well-coordinated multi-agent
system. Lastly, we discuss the complementary strengths and weaknesses of
OpenAI's text-to-video model Sora and our FilmAgent in filmmaking.

æè¦ï¼èæ¬é»å½±è£½ä½éè¦è¤éçæ±ºç­éç¨ï¼åæ¬ç·¨åãèæ¬é»å½±æå½±ãä»¥åç²¾æºçæ¼å¡å®ä½ååä½ãåå°èªè¨ä»£çäººçºåºç¤çç¤¾æèªåæ±ºç­å¶å®è¿æé²å±çæ¿åµï¼æ¬æä»ç´¹äº FilmAgentï¼ä¸åæ°ç©ç LLM çºåºç¤çå¤éä»£çäººåä½æ¶æ§ï¼ç¨æ¼å¨æåå»ºæ§ç 3D èæ¬ç©ºéä¸­é²è¡ç«¯å°ç«¯çé»å½±èªååãFilmAgent æ¨¡æ¬äºåç¨®åçµè§è²ï¼åæ¬å°æ¼ãç·¨åãæ¼å¡åé»å½±æå½±å¸«ï¼æ¶µèäºé»å½±è£½ä½å·¥ä½æµç¨çä¸»è¦éæ®µï¼(1) æ§æéç¼å°éæå»£ççæ³æ³è½åçºçµæ§åçæäºå¤§ç¶±ï¼(2) ç·¨åçºæ¯åå ´æ¯çå°è©±åè§è²åä½é²è¡è©³ç´°èªªæï¼(3) é»å½±æå½±æ±ºå®æ¯åé¡é ­çæå½±æ©è¨­ç½®ãä¸çµä»£çäººééåè¦çåé¥åä¿®æ¹é²è¡åä½ï¼å¾èé©è­ä¸­éè³æ¬ä¸¦æ¸å°å¹»è¦ºãæåå¨ 15 åæ³æ³å 4 åééµé¢åè©ä¼°ç¢ççå½±çãäººé¡è©ä¼°é¡¯ç¤ºï¼FilmAgent å¨ææé¢åé½åªæ¼ææåºæºï¼å¹³åå¾åçº 5 åä¸­ç 3.98 åï¼é¡¯ç¤ºäºå¤éä»£çäººå¨é»å½±è£½ä½ä¸­åä½çå¯è¡æ§ãé²ä¸æ­¥çåæé¡¯ç¤ºï¼FilmAgent åç®¡ä½¿ç¨äºè¼ä¸åé²ç GPT-4o æ¨¡åï¼ä½è¶è¶äºå®ä¸ä»£çäºº o1ï¼é¡¯ç¤ºäºä¸ååèª¿è¯å¥½çå¤éä»£çäººç³»çµ±çåªå¢ãæå¾ï¼æåè¨è«äº OpenAI çæå­è½å½±çæ¨¡å Sora åæåç FilmAgent å¨é»å½±è£½ä½ä¸­çäºè£åªç¼ºé»ã

##### **Architectural Fusion Through Contextual Partitioning in Large Language Models: A Novel Approach to Parameterized Knowledge Integration**
2501.12901v1 by Offa Kingsleigh, Alfred Abercrombie, David Woolstencroft, Beorhtric Meadowcroft, Marcus Irvin

Contextual Partitioning introduces an innovative approach to enhancing the
architectural design of large-scale computational models through the dynamic
segmentation of parameters into context-aware regions. This methodology
emphasizes the importance of task-specific specialization, achieved through
adaptive parameter allocation mechanisms that align with the linguistic
features of input data. Experimental evaluations demonstrated substantial
improvements in accuracy, perplexity, and contextual coherence across a variety
of linguistic tasks, highlighting the adaptability and scalability of the
proposed framework. By reducing redundancy and enhancing computational
efficiency, Contextual Partitioning not only streamlines model operations but
also expands the scope of applications for advanced language processing
systems. The approach operates autonomously, requiring no external fine-tuning,
thereby addressing a significant limitation in conventional parameter
optimization techniques. Empirical results demonstrate the effectiveness of
gradient-driven segmentation, enabling models to dynamically recalibrate and
specialize in response to task-specific demands. Furthermore, resource
utilization metrics reveal notable reductions in memory usage and training
times, confirming the efficiency of the approach. Observations from qualitative
analyses illustrate improved contextual coherence and logical flow in generated
outputs, reinforcing the practical value of this technique. The findings
collectively demonstrate the potential for Contextual Partitioning to redefine
the scalability and adaptability of computational language architectures in
diverse and complex domains.

æè¦ï¼èªå¢åå²å¼å¥äºä¸ç¨®åµæ°æ¹æ³ï¼ééå°åæ¸åæåéæå·æèªå¢æç¥ååï¼ä¾å¢å¼·å¤§åéç®æ¨¡åçæ¶æ§è¨­è¨ãæ­¤æ¹æ³å¼·èª¿ä»»åç¹å®å°æ¥­åçéè¦æ§ï¼ééèè¼¸å¥è³æçèªè¨ç¹å¾µç¸ç¬¦çèªé©æåæ¸éç½®æ©å¶ä¾éæãå¯¦é©è©ä¼°é¡¯ç¤ºå¨åç¨®èªè¨ä»»åä¸­ï¼æºç¢ºåº¦ãå°æåº¦åèªå¢ä¸è´æ§é½æé¡¯èçæåï¼çªé¡¯äºææåºæ¶æ§çé©ææ§åå¯æ´åæ§ãééæ¸å°åé¤ä¸¦å¢å¼·éç®æçï¼èªå¢åå²ä¸åç°¡åäºæ¨¡åæä½ï¼ä¹æ´å±äºé²éèªè¨èçç³»çµ±çæç¨ç¯åãæ­¤æ¹æ³èªä¸»éä½ï¼ä¸éè¦å¤é¨å¾®èª¿ï¼å¾èè§£æ±ºäºå³çµ±åæ¸æä½³åæè¡ä¸­çä¸é éå¤§éå¶ãç¶é©çµæè­æäºæ¢¯åº¦é©ååå²çæææ§ï¼ä½¿æ¨¡åè½å¤ åæéæ°æ ¡æºä¸¦æ ¹æç¹å®ä»»åçéæ±é²è¡å°æ¥­åãæ­¤å¤ï¼è³æºä½¿ç¨éææ¨é¡¯ç¤ºè¨æ¶é«ä½¿ç¨éåè¨ç·´æéé¡¯èæ¸å°ï¼è­å¯¦äºæ­¤æ¹æ³çæçãå¾åè³ªåæçè§å¯çµæé¡¯ç¤ºï¼çæçè¼¸åºèªå¢ä¸è´æ§åéè¼¯æµç¨ç²å¾æ¹åï¼å¼·åäºæ­¤æè¡çå¯¦ç¨å¹å¼ãéäºç¼ç¾å±åè­æäºèªå¢åå²ææ½åéæ°å®ç¾©éç®èªè¨æ¶æ§å¨å¤åä¸è¤éé åä¸­çå¯æ´åæ§åé©ææ§ã

##### **Test-Time Preference Optimization: On-the-Fly Alignment via Iterative Textual Feedback**
2501.12895v1 by Yafu Li, Xuyang Hu, Xiaoye Qu, Linjie Li, Yu Cheng

Large language models (LLMs) demonstrate impressive performance but lack the
flexibility to adapt to human preferences quickly without retraining. In this
work, we introduce Test-time Preference Optimization (TPO), a framework that
aligns LLM outputs with human preferences during inference, removing the need
to update model parameters. Rather than relying on purely numerical rewards,
TPO translates reward signals into textual critiques and uses them as textual
rewards to iteratively refine its response. Evaluations on benchmarks covering
instruction following, preference alignment, safety, and mathematics reveal
that TPO progressively improves alignment with human preferences. Notably,
after only a few TPO steps, the initially unaligned Llama-3.1-70B-SFT model can
surpass the aligned counterpart, Llama-3.1-70B-Instruct. Furthermore, TPO
scales efficiently with both the search width and depth during inference.
Through case studies, we illustrate how TPO exploits the innate capacity of LLM
to interpret and act upon reward signals. Our findings establish TPO as a
practical, lightweight alternative for test-time preference optimization,
achieving alignment on the fly. Our code is publicly available at
https://github.com/yafuly/TPO.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) è¡¨ç¾åºè²ï¼ä½ç¼ºä¹éæ´»æ§ï¼ç¡æ³å¨ä¸éæ°è¨ç·´çææ³ä¸å¿«éé©æäººé¡åå¥½ãå¨éé å·¥ä½ä¸­ï¼æåå¼å¥äºæ¸¬è©¦æåå¥½æä½³å (TPO)ï¼éæ¯ä¸åå¨æ¨çæéå° LLM è¼¸åºèäººé¡åå¥½å°é½çæ¡æ¶ï¼æ¶é¤äºæ´æ°æ¨¡ååæ¸çéè¦ãTPO æ²æä¾è³´ç´ç²¹çæ¸å­çåµï¼èæ¯å°çåµè¨èè½æçºæå­æ¹è©ï¼ä¸¦å°å®åä½çºæå­çåµä¾åè¦æ¹åå¶åæãå¨æ¶µèæä»¤éµå¾ªãåå¥½å°é½ãå®å¨æ§ä»¥åæ¸å­¸çåºæºæ¸¬è©¦è©ä¼°ä¸­ç¼ç¾ï¼TPO éæ¼¸æ¹åäºèäººé¡åå¥½çå°é½ãå¼å¾æ³¨æçæ¯ï¼åç¶éå¹¾å TPO æ­¥é©å¾ï¼æåæªå°é½ç Llama-3.1-70B-SFT æ¨¡åå°±å¯ä»¥è¶è¶å°é½çå°ææ¨¡å Llama-3.1-70B-Instructãæ­¤å¤ï¼TPO å¨æ¨çæéå¯ä»¥ææå°æ´åæå°å»£åº¦åæ·±åº¦ãééæ¡ä¾ç ç©¶ï¼æåèªªæäº TPO å¦ä½å©ç¨ LLM è§£éåæ ¹æçåµè¨èæ¡åè¡åçå§å¨è½åãæåçç¼ç¾å° TPO å®ä½çºä¸ç¨®å¯¦ç¨çãè¼éç´çæ¸¬è©¦æåå¥½æä½³åæ¿ä»£æ¹æ¡ï¼å¯å³æå¯¦ç¾å°é½ãæåçç¨å¼ç¢¼å¬éæ¼ https://github.com/yafuly/TPOã

##### **Learning Graph Node Embeddings by Smooth Pair Sampling**
2501.12884v1 by Konstantin Kutzkov

Random walk-based node embedding algorithms have attracted a lot of attention
due to their scalability and ease of implementation. Previous research has
focused on different walk strategies, optimization objectives, and embedding
learning models. Inspired by observations on real data, we take a different
approach and propose a new regularization technique. More precisely, the
frequencies of node pairs generated by the skip-gram model on random walk node
sequences follow a highly skewed distribution which causes learning to be
dominated by a fraction of the pairs. We address the issue by designing an
efficient sampling procedure that generates node pairs according to their {\em
smoothed frequency}. Theoretical and experimental results demonstrate the
advantages of our approach.

æè¦ï¼åºæ¼é¨æ©éèµ°çç¯é»åµå¥æ¼ç®æ³ç±æ¼å¶å¯æ´åæ§åææ¼å¯¦ä½èååéæ³¨ãååçç ç©¶å°æ³¨æ¼ä¸åçéèµ°ç­ç¥ãæä½³åç®æ¨ååµå¥å¼å­¸ç¿æ¨¡åãåå°çå¯¦è³æè§å¯çåç¼ï¼æåæ¡åä¸åçæ¹æ³ä¸¦æåºä¸åæ°çæ­£ååæè¡ãæ´ç²¾ç¢ºå°èªªï¼å¨é¨æ©éèµ°ç¯é»åºåä¸ç±è·³èºèªæ³æ¨¡åç¢ççç¯é»å°é »çéµå¾ªä¸åé«åº¦åæçåå¸ï¼éå°è´å­¸ç¿åå°é¨åå°çæ¯éãæåééè¨­è¨ä¸åææççæ½æ¨£ç¨åºä¾è§£æ±ºéååé¡ï¼è©²ç¨åºæ ¹æç¯é»å°çãå¹³æ»é »çãä¾ç¢çç¯é»å°ãçè«åå¯¦é©çµæè­æäºæåæ¹æ³çåªé»ã

##### **WisdomBot: Tuning Large Language Models with Artificial Intelligence Knowledge**
2501.12877v1 by Jingyuan Chen, Tao Wu, Wei Ji, Fei Wu

Large language models (LLMs) have emerged as powerful tools in natural
language processing (NLP), showing a promising future of artificial generated
intelligence (AGI). Despite their notable performance in the general domain,
LLMs have remained suboptimal in the field of education, owing to the unique
challenges presented by this domain, such as the need for more specialized
knowledge, the requirement for personalized learning experiences, and the
necessity for concise explanations of complex concepts. To address these
issues, this paper presents a novel LLM for education named WisdomBot, which
combines the power of LLMs with educational theories, enabling their seamless
integration into educational contexts. To be specific, we harness
self-instructed knowledge concepts and instructions under the guidance of
Bloom's Taxonomy as training data. To further enhance the accuracy and
professionalism of model's response on factual questions, we introduce two key
enhancements during inference, i.e., local knowledge base retrieval
augmentation and search engine retrieval augmentation during inference. We
substantiate the effectiveness of our approach by applying it to several
Chinese LLMs, thereby showcasing that the fine-tuned models can generate more
reliable and professional responses.

æè¦ï¼å¤§åèªè¨æ¨¡åï¼LLMï¼å·²æçºèªç¶èªè¨èçï¼NLPï¼ä¸­çå¼·å¤§å·¥å·ï¼å±ç¤ºäºäººå·¥æºæ§ï¼AGIï¼çæªä¾åæ¯ãåç®¡å¨ä¸è¬é åæé¡¯èçè¡¨ç¾ï¼ä½ LLM å¨æè²é åä»æªéå°æä½³çæï¼éæ¯ç±æ¼è©²é åæåºçç¨ç¹ææ°ï¼ä¾å¦éè¦æ´å¤å°æ¥­ç¥è­ãåæ§åå­¸ç¿é«é©çè¦æ±ï¼ä»¥åå°è¤éæ¦å¿µçç°¡æ½è§£éãçºäºè§£æ±ºéäºåé¡ï¼æ¬ææåºäºä¸ååçº WisdomBot çæè² LLMï¼å®çµåäº LLM çåéåæè²çè«ï¼ä½¿å¶è½å¤ ç¡ç¸«æ´åå°æè²ç°å¢ä¸­ãå·é«ä¾èªªï¼æåå©ç¨å¸é­¯å§åé¡æ³æå°ä¸çèªå­¸ç¥è­æ¦å¿µåèªªæä½çºè¨ç·´è³æãçºäºé²ä¸æ­¥æé«æ¨¡åå°äºå¯¦åé¡çåæçæºç¢ºæ§åå°æ¥­æ§ï¼æåå¨æ¨çéç¨ä¸­å¼å¥äºå©é ééµçæ¹é²ï¼å³ï¼å±é¨ç¥è­åº«æª¢ç´¢æ´ååæç´¢å¼ææª¢ç´¢æ´åãæåééå°å¶æç¨æ¼å¹¾åä¸­æ LLM ä¾é©è­æåæ¹æ³çæææ§ï¼å¾èå±ç¤ºå¾®èª¿æ¨¡åå¯ä»¥ç¢çæ´å¯é åå°æ¥­çåæã

##### **Mutation-Guided LLM-based Test Generation at Meta**
2501.12862v1 by Christopher Foster, Abhishek Gulati, Mark Harman, Inna Harper, Ke Mao, Jillian Ritchey, HervÃ© Robert, Shubho Sengupta

This paper describes Meta's ACH system for mutation-guided LLM-based test
generation. ACH generates relatively few mutants (aka simulated faults),
compared to traditional mutation testing. Instead, it focuses on generating
currently undetected faults that are specific to an issue of concern. From
these currently uncaught faults, ACH generates tests that can catch them,
thereby `killing' the mutants and consequently hardening the platform against
regressions. We use privacy concerns to illustrate our approach, but ACH can
harden code against {\em any} type of regression. In total, ACH was applied to
10,795 Android Kotlin classes in 7 software platforms deployed by Meta, from
which it generated 9,095 mutants and 571 privacy-hardening test cases. ACH also
deploys an LLM-based equivalent mutant detection agent that achieves a
precision of 0.79 and a recall of 0.47 (rising to 0.95 and 0.96 with simple
pre-processing). ACH was used by Messenger and WhatsApp test-a-thons where
engineers accepted 73% of its tests, judging 36% to privacy relevant. We
conclude that ACH hardens code against specific concerns and that, even when
its tests do not directly tackle the specific concern, engineers find them
useful for their other benefits.

æè¦ï¼æ¬ææè¿°äº Meta ç ACH ç³»ç»ï¼ç¨äºåºäº LLM çåå¼å¼å¯¼æµè¯çæãä¸ä¼ ç»çåå¼æµè¯ç¸æ¯ï¼ACH çæçåå¼ä½ï¼åç§°æ¨¡ææéï¼ç¸å¯¹è¾å°ãç¸åï¼å®ä¸æ³¨äºçæç¹å®äºå³æ³¨é®é¢çå½åæªæ£æµå°çæéãä»è¿äºå½åæªæè·çæéä¸­ï¼ACH çæäºå¯ä»¥æè·å®ä»¬çæµè¯ï¼ä»èâææ­»âåå¼ä½ï¼è¿èå¢å¼ºå¹³å°å¯¹åå½çæµæåãæä»¬ä½¿ç¨éç§é®é¢æ¥è¯´ææä»¬çæ¹æ³ï¼ä½ ACH å¯ä»¥éå¯¹ä»»ä½ç±»åçåå½å¼ºåä»£ç ãæ»èè¨ä¹ï¼ACH å·²åºç¨äº Meta é¨ç½²ç 7 ä¸ªè½¯ä»¶å¹³å°ä¸­ç 10,795 ä¸ª Android Kotlin ç±»ï¼ä»ä¸­çæäº 9,095 ä¸ªåå¼ä½å 571 ä¸ªéç§å¼ºåæµè¯ç¨ä¾ãACH è¿é¨ç½²äºåºäº LLM çç­æåå¼ä½æ£æµä»£çï¼å¶ç²¾åº¦è¾¾å° 0.79ï¼å¬åçè¾¾å° 0.47ï¼ä½¿ç¨ç®åçé¢å¤çååå«åè³ 0.95 å 0.96ï¼ãACH è¢« Messenger å WhatsApp çæµè¯é©¬ææ¾ä½¿ç¨ï¼å·¥ç¨å¸æ¥åäºå¶ 73% çæµè¯ï¼å¶ä¸­ 36% è¢«è®¤ä¸ºä¸éç§ç¸å³ãæä»¬å¾åºçç»è®ºæ¯ï¼ACH éå¯¹ç¹å®é®é¢å¼ºåäºä»£ç ï¼å³ä½¿å¶æµè¯æ²¡æç´æ¥è§£å³ç¹å®é®é¢ï¼å·¥ç¨å¸ä¹ä¼åç°å®ä»¬å¯¹å¶ä»å¥½å¤å¾æç¨ã

##### **ACEBench: Who Wins the Match Point in Tool Learning?**
2501.12851v1 by Chen Chen, Xinlong Hao, Weiwen Liu, Xu Huang, Xingshan Zeng, Shuai Yu, Dexun Li, Shuai Wang, Weinan Gan, Yuefeng Huang, Xinzhi Wang, Defu Lian, Baoqun Yin, Yasheng Wang, Wu Liu

Large language models (LLMs) have demonstrated significant potential in
decision-making and reasoning, especially when combined with various tools to
effectively solve complex problems. However, existing evaluation systems for
assessing LLM function calling capabilities have several limitations: (1)
limited evaluation scenarios, lacking assessments in real multi-turn dialogue
contexts; (2) narrow evaluation dimensions, lacking detailed assessments for
fine-grained function calls; (3) relying on LLMs or real API executions for
result evaluation, which introduces significant overhead. To address these
issues, we propose a comprehensive evaluation system named ACEBench. This
system is meticulously designed to encompass a wide spectrum of function
calling scenarios. Moreover, it categorizes these scenarios into three primary
types according to the evaluation methodology: Normal, Special, and Agent.
Normal evaluates function calls in basic scenarios; Special evaluates function
calls in scenarios with vague or incomplete instructions; Agent introduces
multi-agent interactions to simulate function calling evaluation in real-world
multi-turn interactions. We conducted extensive experiments on ACEBench,
analyzing various LLMs in-depth and performing a more granular analysis of
error causes across different data types.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨æ±ºç­åæ¨çæ¹é¢å±ç¾åºé¡¯èçæ½åï¼ç¹å¥æ¯å¨çµååç¨®å·¥å·ä»¥ææè§£æ±ºè¤éåé¡æãç¶èï¼ç¾æçè©ä¼°ç³»çµ±å¨è©ä¼° LLM å½æ¸å¼å«è½åææå¹¾åéå¶ï¼(1) è©ä¼°å ´æ¯æéï¼ç¼ºä¹å¨çå¯¦å¤è¼ªå°è©±æå¢ä¸­çè©ä¼°ï¼(2) è©ä¼°ç¶­åº¦ç¹çªï¼ç¼ºä¹å°ç´°ç²åº¦å½æ¸å¼å«çè©³ç´°è©ä¼°ï¼(3) ä¾è³´ LLM æçå¯¦ API å·è¡ä¾é²è¡çµæè©ä¼°ï¼éæé æé¡¯èçéé·ãçºäºè§£æ±ºéäºåé¡ï¼æåæåºäºä¸ååçº ACEBench çç¶åè©ä¼°ç³»çµ±ãæ­¤ç³»çµ±ç¶éç²¾å¿è¨­è¨ï¼æ¶µèäºå»£æ³çå½æ¸å¼å«å ´æ¯ãæ­¤å¤ï¼å®æ ¹æè©ä¼°æ¹æ³å°éäºå ´æ¯åçºä¸ç¨®é¡åï¼ä¸è¬ãç¹æ®åä»£çãä¸è¬æå¨åºæ¬å ´æ¯ä¸­è©ä¼°å½æ¸å¼å«ï¼ç¹æ®æå¨å·ææ¨¡ç³æä¸å®æ´æä»¤çå ´æ¯ä¸­è©ä¼°å½æ¸å¼å«ï¼ä»£çæå¼å¥å¤ä»£çäºåï¼ä»¥æ¨¡æ¬å¨çå¯¦ä¸çå¤è¼ªäºåä¸­çå½æ¸å¼å«è©ä¼°ãæåå¨ ACEBench ä¸é²è¡äºå»£æ³çå¯¦é©ï¼æ·±å¥åæäºåç¨® LLMï¼ä¸¦å°ä¸åæ¸æé¡åçé¯èª¤åå é²è¡äºæ´ç´°ç·»çåæã

##### **GAMED-Snake: Gradient-aware Adaptive Momentum Evolution Deep Snake Model for Multi-organ Segmentation**
2501.12844v1 by Ruicheng Zhang, Haowei Guo, Zeyu Zhang, Puxin Yan, Shen Zhao

Multi-organ segmentation is a critical yet challenging task due to complex
anatomical backgrounds, blurred boundaries, and diverse morphologies. This
study introduces the Gradient-aware Adaptive Momentum Evolution Deep Snake
(GAMED-Snake) model, which establishes a novel paradigm for contour-based
segmentation by integrating gradient-based learning with adaptive momentum
evolution mechanisms. The GAMED-Snake model incorporates three major
innovations: First, the Distance Energy Map Prior (DEMP) generates a
pixel-level force field that effectively attracts contour points towards the
true boundaries, even in scenarios with complex backgrounds and blurred edges.
Second, the Differential Convolution Inception Module (DCIM) precisely extracts
comprehensive energy gradients, significantly enhancing segmentation accuracy.
Third, the Adaptive Momentum Evolution Mechanism (AMEM) employs cross-attention
to establish dynamic features across different iterations of evolution,
enabling precise boundary alignment for diverse morphologies. Experimental
results on four challenging multi-organ segmentation datasets demonstrate that
GAMED-Snake improves the mDice metric by approximately 2% compared to
state-of-the-art methods. Code will be available at
https://github.com/SYSUzrc/GAMED-Snake.

æè¦ï¼å¤å¨å®åå²æ¯ä¸é ééµä¸å·æææ°æ§çä»»åï¼å¶åå å¨æ¼è¤éçè§£åå­¸èæ¯ãæ¨¡ç³çéçåå¤æ¨£åçå½¢æãæ¬ç ç©¶å¼å¥äºæ¢¯åº¦æç¥èªé©æåéæ¼åæ·±åº¦èæ¨¡å (GAMED-Snake)ï¼å®å»ºç«äºä¸ååºæ¼è¼ªå»çåå²æ°ç¯ä¾ï¼æ¹æ³æ¯å°åºæ¼æ¢¯åº¦çå­¸ç¿èèªé©æåéæ¼åæ©å¶æ´åå¨ä¸èµ·ãGAMED-Snake æ¨¡ååå«ä¸å¤§åµæ°ï¼é¦åï¼è·é¢è½éååé© (DEMP) æç¢çä¸ååç´ ç´åçå ´ï¼å®è½ææå°å¸å¼è¼ªå»é»æåçå¯¦çéçï¼å³ä½¿å¨èæ¯è¤éä¸éç·£æ¨¡ç³çææ³ä¸ä¹è½ç¼æ®ä½ç¨ãå¶æ¬¡ï¼å·®åå·ç©èµ·å§æ¨¡çµ (DCIM) ç²¾ç¢ºå°æåäºå¨é¢çè½éæ¢¯åº¦ï¼é¡¯èå°æé«äºåå²æºç¢ºåº¦ãç¬¬ä¸ï¼èªé©æåéæ¼åæ©å¶ (AMEM) æ¡ç¨äº¤åæ³¨æä¾å»ºç«ä¸åæ¼åè¿­ä»£ä¹éçåæç¹å¾µï¼å¾èå¯¦ç¾å°ä¸åå½¢æçç²¾ç¢ºéçå°é½ãå¨ååå·æææ°æ§çå¤å¨å®åå²è³æéä¸çå¯¦é©çµæè¡¨æï¼èæåé²çæ¹æ³ç¸æ¯ï¼GAMED-Snake å° mDice ææ¨æé«äºå¤§ç´ 2%ãç¨å¼ç¢¼å°å¨ https://github.com/SYSUzrc/GAMED-Snake ä¸æä¾ã

##### **Adaptive Retrieval Without Self-Knowledge? Bringing Uncertainty Back Home**
2501.12835v1 by Viktor Moskvoretskii, Maria Lysyuk, Mikhail Salnikov, Nikolay Ivanov, Sergey Pletenev, Daria Galimzianova, Nikita Krayko, Vasily Konovalov, Irina Nikishina, Alexander Panchenko

Retrieval Augmented Generation (RAG) improves correctness of Question
Answering (QA) and addresses hallucinations in Large Language Models (LLMs),
yet greatly increase computational costs. Besides, RAG is not always needed as
may introduce irrelevant information. Recent adaptive retrieval methods
integrate LLMs' intrinsic knowledge with external information appealing to LLM
self-knowledge, but they often neglect efficiency evaluations and comparisons
with uncertainty estimation techniques. We bridge this gap by conducting a
comprehensive analysis of 35 adaptive retrieval methods, including 8 recent
approaches and 27 uncertainty estimation techniques, across 6 datasets using 10
metrics for QA performance, self-knowledge, and efficiency. Our findings show
that uncertainty estimation techniques often outperform complex pipelines in
terms of efficiency and self-knowledge, while maintaining comparable QA
performance.

æè¦ï¼æª¢ç´¢å¢å¼·çæï¼RAGï¼æ¹åäºåé¡åç­ï¼QAï¼çæ­£ç¢ºæ§ï¼ä¸¦è§£æ±ºäºå¤§åèªè¨æ¨¡åï¼LLMï¼ä¸­çå¹»è¦ºï¼ä½å¤§å¹å¢å äºéç®ææ¬ãæ­¤å¤ï¼RAG ä¸¦éç¸½æ¯éè¦ï¼å çºå¯è½æå¼å¥ç¡éè³è¨ãæè¿çèªé©ææª¢ç´¢æ¹æ³å° LLM çå§å¨ç¥è­èå¤é¨è³è¨æ´åï¼å¸å¼ LLM çèªæç¥è­ï¼ä½å®åå¸¸å¸¸å¿½ç¥æçè©ä¼°åèä¸ç¢ºå®æ§ä¼°è¨æè¡çæ¯è¼ãæåééå° 35 ç¨®èªé©ææª¢ç´¢æ¹æ³é²è¡å¨é¢åæä¾å½è£æ­¤å·®è·ï¼å¶ä¸­åæ¬ 8 ç¨®è¿ææ¹æ³å 27 ç¨®ä¸ç¢ºå®æ§ä¼°è¨æè¡ï¼ä½¿ç¨ 10 ç¨®éåº¦è¡¡é 6 åè³æéç QA æè½ãèªæç¥è­åæçãæåçç ç©¶çµæé¡¯ç¤ºï¼ä¸ç¢ºå®æ§ä¼°è¨æè¡å¨æçåèªæç¥è­æ¹é¢éå¸¸åªæ¼è¤éçç®¡éï¼åæç¶­æç¸ç¶ç QA æè½ã

##### **Open or Closed LLM for Lesser-Resourced Languages? Lessons from Greek**
2501.12826v1 by John Pavlopoulos, Juli Bakagianni, Kanella Pouli, Maria Gavriilidou

Natural Language Processing (NLP) for lesser-resourced languages faces
persistent challenges, including limited datasets, inherited biases from
high-resource languages, and the need for domain-specific solutions. This study
addresses these gaps for Modern Greek through three key contributions. First,
we evaluate the performance of open-source (Llama-70b) and closed-source
(GPT-4o mini) large language models (LLMs) on seven core NLP tasks with dataset
availability, revealing task-specific strengths, weaknesses, and parity in
their performance. Second, we expand the scope of Greek NLP by reframing
Authorship Attribution as a tool to assess potential data usage by LLMs in
pre-training, with high 0-shot accuracy suggesting ethical implications for
data provenance. Third, we showcase a legal NLP case study, where a Summarize,
Translate, and Embed (STE) methodology outperforms the traditional TF-IDF
approach for clustering \emph{long} legal texts. Together, these contributions
provide a roadmap to advance NLP in lesser-resourced languages, bridging gaps
in model evaluation, task innovation, and real-world impact.

æè¦ï¼èªç¶èªè¨èç (NLP) éå°è³æºè¼å°çèªè¨é¢è¨æçºçææ°ï¼åæ¬è³æéæéãç¹¼æ¿èªè³æºè±å¯èªè¨çåè¦ï¼ä»¥åå°ç¹å®é åè§£æ±ºæ¹æ¡çéæ±ãæ¬ç ç©¶ééä¸åééµè²¢ç»è§£æ±ºç¾ä»£å¸èèªçéäºå·®è·ãé¦åï¼æåè©ä¼°éæº (Llama-70b) åéæº (GPT-4o mini) å¤§åèªè¨æ¨¡å (LLM) å¨ä¸é æ ¸å¿ NLP ä»»åä¸çæè½ï¼ä¸¦æä¾è³æéå¯ç¨æ§ï¼æ­é²å¶ä»»åç¹å®çåªå¢ãå£å¢åæè½å¹³å¹ãå¶æ¬¡ï¼æåééå°ä½èæ­¸å éæ°å®ç¾©çºä¸ç¨®è©ä¼° LLM å¨é è¨ç·´ä¸­æ½å¨è³æä½¿ç¨ææ³çå·¥å·ï¼æ´å±å¸èèª NLP çç¯åï¼ä¸¦ä»¥é« 0 æ¬¡å­¸ç¿æºç¢ºåº¦æç¤ºè³æä¾æºçå«çææ¶µãç¬¬ä¸ï¼æåå±ç¤ºä¸åæ³å¾ NLP æ¡ä¾ç ç©¶ï¼å¶ä¸­æè¦ãç¿»è­¯ååµå¥ (STE) æ¹æ³åªæ¼å³çµ± TF-IDF æ¹æ³ï¼ç¨æ¼åç¾¤\emph{é·ç¯}æ³å¾ææ¬ãéäºè²¢ç»å±åæä¾äºä¸ä»½è·¯ç·åï¼ä»¥æ¨åè³æºè¼å°èªè¨ä¸­ç NLPï¼ç¸®å°æ¨¡åè©ä¼°ãä»»ååµæ°åç¾å¯¦ä¸çå½±é¿ä¹éçå·®è·ã

##### **Machine Learning Modeling for Multi-order Human Visual Motion Processing**
2501.12810v1 by Zitang Sun, Yen-Ju Chen, Yung-Hao Yang, Yuan Li, Shin'ya Nishida

Our research aims to develop machines that learn to perceive visual motion as
do humans. While recent advances in computer vision (CV) have enabled DNN-based
models to accurately estimate optical flow in naturalistic images, a
significant disparity remains between CV models and the biological visual
system in both architecture and behavior. This disparity includes humans'
ability to perceive the motion of higher-order image features (second-order
motion), which many CV models fail to capture because of their reliance on the
intensity conservation law. Our model architecture mimics the cortical V1-MT
motion processing pathway, utilizing a trainable motion energy sensor bank and
a recurrent graph network. Supervised learning employing diverse naturalistic
videos allows the model to replicate psychophysical and physiological findings
about first-order (luminance-based) motion perception. For second-order motion,
inspired by neuroscientific findings, the model includes an additional sensing
pathway with nonlinear preprocessing before motion energy sensing, implemented
using a simple multilayer 3D CNN block. When exploring how the brain acquired
the ability to perceive second-order motion in natural environments, in which
pure second-order signals are rare, we hypothesized that second-order
mechanisms were critical when estimating robust object motion amidst optical
fluctuations, such as highlights on glossy surfaces. We trained our
dual-pathway model on novel motion datasets with varying material properties of
moving objects. We found that training to estimate object motion from
non-Lambertian materials naturally endowed the model with the capacity to
perceive second-order motion, as can humans. The resulting model effectively
aligns with biological systems while generalizing to both first- and
second-order motion phenomena in natural scenes.

æè¦ï¼<paragraph>æåçç ç©¶æ¨å¨éç¼åºè½åäººé¡ä¸æ¨£å­¸ç¿æç¥è¦è¦ºéåçæ©å¨ãåç®¡é»è¦è¦è¦º (CV) çææ°é²å±å·²è®åºæ¼æ·±åº¦ç¥ç¶ç¶²è·¯ (DNN) çæ¨¡åè½æºç¢ºä¼°è¨èªç¶å½±åä¸­çåæµï¼ä½ CV æ¨¡åèçç©è¦è¦ºç³»çµ±å¨æ¶æ§åè¡çºä¸ä»æé¡¯èå·®ç°ãéç¨®å·®ç°åæ¬äººé¡æç¥é«éå½±åç¹å¾µï¼äºééåï¼çè½åï¼ç±æ¼ä¾è³´å¼·åº¦å®æå®å¾ï¼è¨±å¤ CV æ¨¡åç¡æ³ææå°éä¸é»ãæåçæ¨¡åæ¶æ§æ¨¡æ¬äºç®è³ª V1-MT éåèçè·¯å¾ï¼å©ç¨å¯è¨ç·´çéåè½éææ¸¬å¨çµåéè¿´åå½¢ç¶²è·¯ãæ¡ç¨å¤æ¨£åèªç¶å½±ççç£ç£å¼å­¸ç¿ï¼è®æ¨¡åè½å¤ è¤è£½éæ¼ä¸éï¼åºæ¼äº®åº¦ï¼éåæç¥çå¿çç©çå­¸åççå­¸ç¼ç¾ãå°æ¼äºééåï¼åç¥ç¶ç§å­¸ç¼ç¾çåç¼ï¼è©²æ¨¡ååå«äºä¸åé¡å¤çææ¸¬è·¯å¾ï¼å¨éåè½éææ¸¬ä¹åé²è¡éç·æ§é èçï¼ä¸¦ä½¿ç¨ç°¡å®çå¤å±¤ 3D CNN å¡é²è¡å¯¦ä½ãå¨æ¢è¨å¤§è¦å¦ä½ç²å¾å¨èªç¶ç°å¢ä¸­æç¥äºééåçè½åæï¼å¶ä¸­ç´äºéè¨èå¾å°è¦ï¼æååè¨­å¨ä¼°è¨åå­¸æ³¢åä¸­çç©©å¥ç©é«éåæï¼äºéæ©å¶è³ééè¦ï¼ä¾å¦åæ»è¡¨é¢ä¸çäº®é»ãæåå¨å·æä¸åç§»åç©é«ææå±¬æ§çæ°éåè³æéä¸è¨ç·´äºæåçéè·¯å¾æ¨¡åãæåç¼ç¾ï¼å¾éæä¼¯é«ææä¼°è¨ç©é«éåçè¨ç·´èªç¶èç¶å°è³¦äºäºæ¨¡åæç¥äºééåçè½åï¼å°±åäººé¡ä¸æ¨£ãç±æ­¤ç¢ççæ¨¡åææå°èçç©ç³»çµ±ä¿æä¸è´ï¼åææ¨å»£å°èªç¶å ´æ¯ä¸­çä¸éåäºééåç¾è±¡ã</paragraph>

##### **Revisit Self-Debugging with Self-Generated Tests for Code Generation**
2501.12793v1 by Xiancai Chen, Zhengwei Tao, Kechi Zhang, Changzhi Zhou, Wanli Gu, Yuanpeng He, Mengdi Zhang, Xunliang Cai, Haiyan Zhao, Zhi Jin

Large language models (LLMs) have shown significant advancements in code
generation, but still face challenges on tasks beyond their basic capabilities.
Recently, the notion of self-debugging has been proposed to boost the
performance of code generation by leveraging execution feedback from tests.
Despite its promise, the availability of high-quality tests in real-world
scenarios is limited. In this context, self-debugging with self-generated tests
is a promising solution but lacks a full exploration of its limitations and
practical potential. Therefore, we investigate its efficacy on diverse
programming problems. To deepen our understanding, we propose two distinct
paradigms for the process: post-execution and in-execution self-debugging.
Within the scope of self-contained Python programming tasks, we find that
post-execution self-debugging struggles on basic problems but shows potential
for improvement on competitive ones, due to the bias introduced by
self-generated tests. On the other hand, in-execution self-debugging enables
LLMs to mitigate the bias by solely leveraging intermediate states during
execution, thereby enhancing code generation.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨ç¨å¼ç¢¼çææ¹é¢å±ç¾åºé¡¯èçé²æ­¥ï¼ä½ä»é¢è¨è¶åºå¶åºæ¬è½åçä»»åææ°ãæè¿ï¼å·²æåºèªæé¤é¯çæ¦å¿µï¼èç±å©ç¨æ¸¬è©¦çå·è¡åé¥ä¾æåç¨å¼ç¢¼çæçæè½ãåç®¡åæ¯çå¥½ï¼ä½å¨å¯¦éææ³ä¸­ï¼é«åè³ªæ¸¬è©¦çåå¾åå°éå¶ãå¨æ­¤èæ¯ä¸ï¼ä½¿ç¨èªæç¢ççæ¸¬è©¦é²è¡èªæé¤é¯æ¯ä¸åæåæ¯çè§£æ±ºæ¹æ¡ï¼ä½ç¼ºä¹å°å¶éå¶åå¯¦éæ½åçå®æ´æ¢è¨ãå æ­¤ï¼æåç ç©¶å¶å¨ä¸åç¨å¼è¨­è¨åé¡ä¸çæè½ãçºäºå æ·±æåççè§£ï¼æåçºæ­¤ç¨åºæåºå©ç¨®ä¸åçå¸ç¯ï¼å·è¡å¾åå·è¡ä¸­èªæé¤é¯ãå¨ç¨ç«ç Python ç¨å¼è¨­è¨ä»»åç¯åå§ï¼æåç¼ç¾å·è¡å¾èªæé¤é¯å¨åºæ¬åé¡ä¸æéå°å°é£ï¼ä½å¨ç«¶ç­æ¿ççåé¡ä¸é¡¯ç¤ºåºæ¹é²çæ½åï¼éæ­¸å æ¼èªæç¢ççæ¸¬è©¦æå¸¶ä¾çåå·®ãå¦ä¸æ¹é¢ï¼å·è¡ä¸­èªæé¤é¯ä½¿ LLM è½å¤ åå©ç¨å·è¡æéçä¸­éçæä¾æ¸è¼åå·®ï¼å¾èå¢å¼·ç¨å¼ç¢¼çæã

##### **Generating Diverse Q&A Benchmarks for RAG Evaluation with DataMorgana**
2501.12789v1 by Simone Filice, Guy Horowitz, David Carmel, Zohar Karnin, Liane Lewin-Eytan, Yoelle Maarek

Evaluating Retrieval-Augmented Generation (RAG) systems, especially in
domain-specific contexts, requires benchmarks that address the distinctive
requirements of the applicative scenario. Since real data can be hard to
obtain, a common strategy is to use LLM-based methods to generate synthetic
data. Existing solutions are general purpose: given a document, they generate a
question to build a Q&A pair. However, although the generated questions can be
individually good, they are typically not diverse enough to reasonably cover
the different ways real end-users can interact with the RAG system. We
introduce here DataMorgana, a tool for generating highly customizable and
diverse synthetic Q&A benchmarks tailored to RAG applications. DataMorgana
enables detailed configurations of user and question categories and provides
control over their distribution within the benchmark. It uses a lightweight
two-stage process, ensuring efficiency and fast iterations, while generating
benchmarks that reflect the expected traffic. We conduct a thorough line of
experiments, showing quantitatively and qualitatively that DataMorgana
surpasses existing tools and approaches in producing lexically, syntactically,
and semantically diverse question sets across domain-specific and
general-knowledge corpora. DataMorgana will be made available to selected teams
in the research community, as first beta testers, in the context of the
upcoming SIGIR'2025 LiveRAG challenge to be announced in early February 2025.

æè¦ï¼éå°æª¢ç´¢å¢å¼·çæ (RAG) ç³»çµ±é²è¡è©ä¼°ï¼ç¹å¥æ¯å¨ç¹å®é åçèçµ¡ä¸­ï¼éè¦åºæºä¾æ»¿è¶³æç¨å ´æ¯çç¨ç¹éæ±ãç±æ¼çå¯¦è³æå¯è½é£ä»¥åå¾ï¼å æ­¤å¸¸è¦çç­ç¥æ¯ä½¿ç¨ LLM çºåºç¤çæ¹æ³ä¾çæåæè³æãç¾æçè§£æ±ºæ¹æ¡æ¯éç¨çï¼çµ¦å®æä»¶å¾ï¼å®åæç¢çä¸ååé¡ä¾å»ºç«åç­éå°ãç¶èï¼åç®¡ç¢ççåé¡å¨åå¥ä¸å¯è½å¾å¥½ï¼ä½éå¸¸ä¸å¤ å¤ååï¼ç¡æ³åçæ¶µèå¯¦éæçµä½¿ç¨èè RAG ç³»çµ±äºåçä¸åæ¹å¼ãæåå¨æ­¤ä»ç´¹ DataMorganaï¼éæ¯ä¸åç¨æ¼çæé«åº¦èªè¨åä¸å¤ååçåæåç­åºæºï¼å°ééå° RAG æç¨ãDataMorgana è½å¤ è©³ç´°è¨­å®ä½¿ç¨èååé¡é¡å¥ï¼ä¸¦æä¾å°åºæºä¸­å¶åä½çæ§å¶ãå®ä½¿ç¨è¼éåçå©éæ®µæµç¨ï¼ç¢ºä¿æçåå¿«éè¿­ä»£ï¼åæç¢çåæ é ææµéçåºæºãæåé²è¡äºä¸ç³»åå¾¹åºçå¯¦é©ï¼å®éåå®æ§å°é¡¯ç¤º DataMorgana å¨ç¢çè·¨ç¹å®é ååä¸è¬ç¥è­èªæåº«çè©å½ãå¥æ³åèªç¾©å¤åååé¡éæ¹é¢åéç¾æçå·¥å·åæ¹æ³ãDataMorgana å°æä¾çµ¦ç ç©¶ç¤¾ç¾¤ä¸­é¸å®çåéï¼ä½çºç¬¬ä¸æ¹æ¸¬è©¦äººå¡ï¼å¨ 2025 å¹´ 2 æåå®£å¸ç SIGIR'2025 LiveRAG ææ°ä¸­ä½¿ç¨ã

##### **Data re-uploading in Quantum Machine Learning for time series: application to traffic forecasting**
2501.12776v1 by Nikolaos Schetakis, Paolo Bonfini, Negin Alisoltani, Konstantinos Blazakis, Symeon I. Tsintzos, Alexis Askitopoulos, Davit Aghamalyan, Panagiotis Fafoutellis, Eleni I. Vlahogianni

Accurate traffic forecasting plays a crucial role in modern Intelligent
Transportation Systems (ITS), as it enables real-time traffic flow management,
reduces congestion, and improves the overall efficiency of urban transportation
networks. With the rise of Quantum Machine Learning (QML), it has emerged a new
paradigm possessing the potential to enhance predictive capabilities beyond
what classical machine learning models can achieve. In the present work we
pursue a heuristic approach to explore the potential of QML, and focus on a
specific transport issue. In particular, as a case study we investigate a
traffic forecast task for a major urban area in Athens (Greece), for which we
possess high-resolution data. In this endeavor we explore the application of
Quantum Neural Networks (QNN), and, notably, we present the first application
of quantum data re-uploading in the context of transport forecasting. This
technique allows quantum models to better capture complex patterns, such as
traffic dynamics, by repeatedly encoding classical data into a quantum state.
Aside from providing a prediction model, we spend considerable effort in
comparing the performance of our hybrid quantum-classical neural networks with
classical deep learning approaches. Our results show that hybrid models achieve
competitive accuracy with state-of-the-art classical methods, especially when
the number of qubits and re-uploading blocks is increased. While the classical
models demonstrate lower computational demands, we provide evidence that
increasing the complexity of the quantum model improves predictive accuracy.
These findings indicate that QML techniques, and specifically the data
re-uploading approach, hold promise for advancing traffic forecasting models
and could be instrumental in addressing challenges inherent in ITS
environments.

æè¦ï¼æºç¢ºçäº¤éé æ¸¬å¨ç¾ä»£æºæ§éè¼¸ç³»çµ± (ITS) ä¸­æ®æ¼èè³ééè¦çè§è²ï¼å çºå®è½é²è¡å³æçäº¤éæµéç®¡çãæ¸å°å£å¡ï¼ä¸¦æåæ´é«çåå¸äº¤ééè¼¸ç¶²çµ¡æçãé¨èéå­æ©å¨å­¸ç¿ (QML) çèèµ·ï¼åºç¾äºä¸ç¨®æ°çå¸ç¯ï¼å®å·åè¶è¶å³çµ±æ©å¨å­¸ç¿æ¨¡åæè½éå°çé æ¸¬è½åçæ½åãå¨ç®åçå·¥ä½ä¸­ï¼æåæ¡ç¨åç¼å¼æ¹æ³ä¾æ¢ç´¢ QML çæ½åï¼ä¸¦å°æ³¨æ¼ç¹å®çäº¤éåé¡ãç¹å¥æ¯ï¼ä½çºä¸åæ¡ä¾ç ç©¶ï¼æåèª¿æ¥äºéå¸ï¼å¸èï¼ä¸åä¸»è¦é½å¸å°åçäº¤éé æ¸¬ä»»åï¼æåææè©²å°åçé«è§£æåº¦è³æãå¨éååªåä¸­ï¼æåæ¢è¨äºéå­ç¥ç¶ç¶²è·¯ (QNN) çæç¨ï¼èä¸ç¹å¥æ¯ï¼æåå±ç¤ºäºéå­è³æéæ°ä¸å³å¨äº¤éé æ¸¬èçµ¡ä¸­çé¦æ¬¡æç¨ãæ­¤æè¡è®éå­æ¨¡åè½éééè¤å°å³çµ±è³æç·¨ç¢¼æéå­æï¼ä¾æ´å¥½å°æ·åè¤éæ¨¡å¼ï¼ä¾å¦äº¤éåæãé¤äºæä¾ä¸åé æ¸¬æ¨¡åä¹å¤ï¼æåè±è²»äºç¸ç¶å¤§çç²¾åä¾æ¯è¼æåçæ··åéå­-å³çµ±ç¥ç¶ç¶²è·¯èå³çµ±æ·±åº¦å­¸ç¿æ¹æ³çæè½ãæåççµæé¡¯ç¤ºï¼æ··åæ¨¡åè½éå°èæåé²çå³çµ±æ¹æ³ç¸åª²ç¾çæºç¢ºåº¦ï¼ç¹å¥æ¯å¨éå­ä½ååéæ°ä¸å³åå¡çæ¸éå¢å æãåç®¡å³çµ±æ¨¡åå±ç¾åºè¼ä½çéç®éæ±ï¼æåæä¾äºè­æè­æå¢å éå­æ¨¡åçè¤éåº¦ææåé æ¸¬æºç¢ºåº¦ãéäºç¼ç¾è¡¨æï¼QML æè¡ï¼ç¹å¥æ¯è³æéæ°ä¸å³æ¹æ³ï¼æææ¨é²äº¤éé æ¸¬æ¨¡åï¼ä¸¦å¯è½æå©æ¼è§£æ±º ITS ç°å¢ä¸­åºæçææ°ã

##### **Regularization, Semi-supervision, and Supervision for a Plausible Attention-Based Explanation**
2501.12775v1 by Duc Hau Nguyen, Cyrielle Mallart, Guillaume Gravier, Pascale SÃ©billot

Attention mechanism is contributing to the majority of recent advances in
machine learning for natural language processing. Additionally, it results in
an attention map that shows the proportional influence of each input in its
decision. Empirical studies postulate that attention maps can be provided as an
explanation for model output. However, it is still questionable to ask whether
this explanation helps regular people to understand and accept the model output
(the plausibility of the explanation). Recent studies show that attention
weights in the RNN encoders are hardly plausible because they spread on input
tokens. We thus propose 3 additional constraints to the learning objective
function to improve the plausibility of the attention map: regularization to
increase the attention weight sparsity, semi-supervision to supervise the map
by a heuristic and supervision by human annotation. Results show that all
techniques can improve the attention map plausibility at some level. We also
observe that specific instructions for human annotation might have a negative
effect on classification performance. Beyond the attention map, the result of
experiments on text classification tasks also shows that no matter how the
constraint brings the gain, the contextualization layer plays a crucial role in
finding the right space for finding plausible tokens.

æè¦ï¼æ³¨æåæºå¶ä¿æäºèªç¶èªè¨èçæ©å¨å­¸ç¿æè¿çå¤§é¨åé²å±ãæ­¤å¤ï¼å®æç¢çä¸åæ³¨æååï¼é¡¯ç¤ºæ¯åè¼¸å¥å¨å¶æ±ºç­ä¸­æä½çæ¯ä¾å½±é¿ãå¯¦è­ç ç©¶åè¨­æ³¨æååå¯ä»¥ä½çºæ¨¡åè¼¸åºçè§£éãç¶èï¼æ¯å¦éç¨®è§£éæå©æ¼ä¸è¬äººçè§£ä¸¦æ¥åæ¨¡åè¼¸åºï¼è§£éçåçæ§ï¼ä»æå¾åæ¦·ãæè¿çç ç©¶è¡¨æï¼RNN ç·¨ç¢¼å¨ä¸­çæ³¨æåæ¬éå¹¾ä¹ä¸åçï¼å çºå®åæ£ä½å¨è¼¸å¥ç¬¦èä¸ãå æ­¤ï¼æåå°å­¸ç¿ç®æ¨å½æ¸æåºäº 3 åé¡å¤çç´æï¼ä»¥æé«æ³¨æååçåçæ§ï¼æ­£ååä»¥å¢å æ³¨æåæ¬éç¨çæ§ãåç£ç£ä»¥ééåç¼å¼ç£ç£åä»¥åééäººå·¥è¨»è§£é²è¡ç£ç£ãçµæè¡¨æï¼æææè¡é½å¯ä»¥å¨æç¨®ç¨åº¦ä¸æé«æ³¨æååçåçæ§ãæåéè§å¯å°ï¼äººå·¥è¨»è§£çå·é«èªªæå¯è½æå°åé¡æ§è½ç¢çè² é¢å½±é¿ãé¤äºæ³¨æååä¹å¤ï¼ææ¬åé¡ä»»åçå¯¦é©çµæéè¡¨æï¼ç¡è«ç´æå¦ä½å¸¶ä¾æ¶çï¼æå¢åå±¤å¨æ¾å°åçç¬¦èçæ­£ç¢ºç©ºéä¸­é½ç¼æ®èè³ééè¦çä½ç¨ã

##### **LLMs as Repositories of Factual Knowledge: Limitations and Solutions**
2501.12774v1 by Seyed Mahed Mousavi, Simone Alghisi, Giuseppe Riccardi

LLMs' sources of knowledge are data snapshots containing factual information
about entities collected at different timestamps and from different media types
(e.g. wikis, social media, etc.). Such unstructured knowledge is subject to
change due to updates through time from past to present. Equally important are
the inconsistencies and inaccuracies occurring in different information
sources. Consequently, the model's knowledge about an entity may be perturbed
while training over the sequence of snapshots or at inference time, resulting
in inconsistent and inaccurate model performance. In this work, we study the
appropriateness of Large Language Models (LLMs) as repositories of factual
knowledge. We consider twenty-four state-of-the-art LLMs that are either
closed-, partially (weights), or fully (weight and training data) open-source.
We evaluate their reliability in responding to time-sensitive factual questions
in terms of accuracy and consistency when prompts are perturbed. We further
evaluate the effectiveness of state-of-the-art methods to improve LLMs'
accuracy and consistency. We then propose "ENtity-Aware Fine-tuning" (ENAF), a
soft neurosymbolic approach aimed at providing a structured representation of
entities during fine-tuning to improve the model's performance.

æè¦ï¼å¤§åèªè¨æ¨¡åçç¥è­ä¾æºæ¯è³æå¿«ç§ï¼å¶ä¸­åå«å¨ä¸åæéæ³åä¸ååªé«é¡åï¼ä¾å¦ wikiãç¤¾ç¾¤åªé«ç­ï¼æ¶éçéæ¼å¯¦é«ççå¯¦è³è¨ãæ­¤é¡éçµæ§åç¥è­æé¨èæéå¾éå»å°ç¾å¨çæ´æ°èæ¹è®ãåæ¨£éè¦çæ¯ï¼ä¸åè³è¨ä¾æºä¸­åºç¾çä¸ä¸è´æ§åä¸æºç¢ºæ§ãå æ­¤ï¼æ¨¡åå¨å¿«ç§åºåææ¨çæéä¸é²è¡è¨ç·´æï¼å°å¯¦é«çç¥è­å¯è½æåå°å¹²æ¾ï¼å°è´æ¨¡åæè½ä¸ä¸è´ä¸ä¸æºç¢ºãå¨éé å·¥ä½ä¸­ï¼æåç ç©¶å¤§åèªè¨æ¨¡å (LLM) ä½çºäºå¯¦ç¥è­å²å­åº«çé©ç¶æ§ãæåèæ®äº 24 åæåé²ç LLMï¼å®åå¯è½æ¯å°éãé¨åï¼æ¬éï¼æå®å¨ï¼æ¬éåè¨ç·´è³æï¼éæºçãæåè©ä¼°äºå®åå¨æç¤ºåå°å¹²æ¾æå°æéææçäºå¯¦åé¡çåæçå¯é æ§ï¼åæ¬æºç¢ºæ§åä¸è´æ§ãæåé²ä¸æ­¥è©ä¼°äºæåé²çæ¹æ³å¨æé« LLM çæºç¢ºæ§åä¸è´æ§æ¹é¢çæææ§ãç¶å¾æåæåºãå¯¦é«æç¥å¾®èª¿ã(ENAF)ï¼éæ¯ä¸ç¨®è»ç¥ç¶ç¬¦èæ¹æ³ï¼æ¨å¨å¨å¾®èª¿éç¨ä¸­æä¾å¯¦é«ççµæ§åè¡¨ç¤ºï¼ä»¥æ¹åæ¨¡åçæè½ã

##### **NExtLong: Toward Effective Long-Context Training without Long Documents**
2501.12766v1 by Chaochen Gao, Xing Wu, Zijia Lin, Debing Zhang, Songlin Hu

Large language models (LLMs) with extended context windows have made
significant strides yet remain a challenge due to the scarcity of long
documents. Existing methods tend to synthesize long-context data but lack a
clear mechanism to reinforce the long-range dependency modeling. To address
this limitation, we propose NExtLong, a novel framework for synthesizing
long-context data through Negative document Extension. NExtLong decomposes a
document into multiple meta-chunks and extends the context by interleaving hard
negative distractors retrieved from pretraining corpora. This approach compels
the model to discriminate long-range dependent context from distracting
content, enhancing its ability to model long-range dependencies. Extensive
experiments demonstrate that NExtLong achieves significant performance
improvements on the HELMET and RULER benchmarks compared to existing
long-context synthesis approaches and leading models, which are trained on
non-synthetic long documents. These findings highlight NExtLong's ability to
reduce reliance on non-synthetic long documents, making it an effective
framework for developing advanced long-context LLMs.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·æå»¶ä¼¸çä¸ä¸æçªå£ï¼å·²åå¾éå¤§é²å±ï¼ä½ç±æ¼ç¼ºä¹é·ç¯æä»¶ï¼å æ­¤ä»ç¶æ¯ä¸åææ°ãç¾ææ¹æ³å¾åæ¼åæé·èªå¢è³æï¼ä½ç¼ºä¹æç¢ºçæ©å¶ä¾å å¼·é·ç¨ä¾è³´æ§å»ºæ¨¡ãçºäºè§£æ±ºéåéå¶ï¼æåæåºäº NExtLongï¼éæ¯ä¸åééè² é¢æä»¶æ´å±ä¾åæé·èªå¢è³æçæ°ç©æ¡æ¶ãNExtLong å°æä»¶åè§£çºå¤ååå¡ï¼ä¸¦ééäº¤é¯å¾é è¨ç·´èªæåº«ä¸­æª¢ç´¢å°çç¡¬è² é¢å¹²æ¾é ä¾æ´å±ä¸ä¸æãéç¨®æ¹æ³è¿«ä½¿æ¨¡åååé·ç¨ä¾è³´ä¸ä¸æåå¹²æ¾å§å®¹ï¼å¢å¼·å¶å»ºæ¨¡é·ç¨ä¾è³´æ§çè½åãå»£æ³çå¯¦é©è¡¨æï¼èç¾æçé·èªå¢åææ¹æ³åå¨éåæé·æä»¶ä¸­è¨ç·´çé åæ¨¡åç¸æ¯ï¼NExtLong å¨ HELMET å RULER åºæºä¸åå¾äºé¡¯èçæ§è½æåãéäºç¼ç¾çªé¡¯äº NExtLong éä½å°éåæé·æä»¶çä¾è³´æ§çè½åï¼ä½¿å¶æçºéç¼åé²é·èªå¢ LLM çæææ¡æ¶ã

##### **Estimating the Conformal Prediction Threshold from Noisy Labels**
2501.12749v1 by Coby Penso, Jacob Goldberger, Ethan Fetaya

Conformal Prediction (CP) is a method to control prediction uncertainty by
producing a small prediction set, ensuring a predetermined probability that the
true class lies within this set. This is commonly done by defining a score,
based on the model predictions, and setting a threshold on this score using a
validation set. In this study, we address the problem of CP calibration when we
only have access to a validation set with noisy labels. We show how we can
estimate the noise-free conformal threshold based on the noisy labeled data.
Our solution is flexible and can accommodate various modeling assumptions
regarding the label contamination process, without needing any information
about the underlying data distribution or the internal mechanisms of the
machine learning classifier. We develop a coverage guarantee for uniform noise
that is effective even in tasks with a large number of classes. We dub our
approach Noise-Aware Conformal Prediction (NACP) and show on several natural
and medical image classification datasets, including ImageNet, that it
significantly outperforms current noisy label methods and achieves results
comparable to those obtained with a clean validation set.

æè¦ï¼å±å½¢é¢æµ (CP) æ¯ä¸ç¨®ééç¢çä¸åå°åé æ¸¬éåä¾æ§å¶é æ¸¬ä¸ç¢ºå®æ§çæ¹æ³ï¼ç¢ºä¿çæ­£çé¡å¥è½å¨éåéåå§çé åç¢ºå®çæ©çãééå¸¸æ¯ééå®ç¾©ä¸ååºæ¼æ¨¡åé æ¸¬çåæ¸ä¾å®æï¼ä¸¦ä½¿ç¨é©è­éåå°éååæ¸è¨­å®ä¸åé¾å¼ãå¨æ¬ç ç©¶ä¸­ï¼æåæ¢è¨äºç¶æååªè½å­åå·æéè¨æ¨ç±¤çé©è­éåæï¼CP æ ¡æ­£çåé¡ãæåå±ç¤ºäºå¦ä½æ ¹æéè¨æ¨ç±¤è³æä¼°è¨ç¡éè¨çå±å½¢é¾å¼ãæåçè§£æ±ºæ¹æ¡å·æå½æ§ï¼ä¸¦ä¸å¯ä»¥é©æéæ¼æ¨ç±¤æ±¡æéç¨çåç¨®å»ºæ¨¡åè¨­ï¼èä¸éè¦ä»»ä½éæ¼åºå±¤è³æåä½ææ©å¨å­¸ç¿åé¡å¨å§é¨æ©å¶çè³è¨ãæåéç¼äºä¸åå°æ¼åå»éè¨çè¦èä¿è­ï¼å³ä½¿å¨å·æå¤§éé¡å¥çä»»åä¸­ä¹å¾ææãæåå°æåçåæ³ç¨±çºéè¨æç¥å±å½¢é æ¸¬ (NACP)ï¼ä¸¦å¨å¹¾åèªç¶åé«å­¸å½±ååé¡è³æéï¼åæ¬ ImageNetï¼ä¸å±ç¤ºäºå®é¡¯èåªæ¼ç®åçéè¨æ¨ç±¤æ¹æ³ï¼ä¸¦ä¸éå°äºèä½¿ç¨ä¹¾æ·¨é©è­éåç²å¾ççµæç¸ç¶ççµæã

##### **EvidenceMap: Unleashing the Power of Small Language Models with Evidence Analysis for Biomedical Question Answering**
2501.12746v1 by Chang Zong, Jian Wan, Lei Zhang

Current LLM-based approaches improve question answering performance by
leveraging the internal reasoning abilities of models or incorporating external
knowledge. However, when humans address professional problems, it is essential
to explicitly analyze the multifaceted relationships from multiple pieces and
diverse sources of evidence to achieve better answers. In this study, we
propose a novel generative question answering framework for the biomedical
domain, named EvidenceMap, which explicitly learns and incorporates evidence
analysis with small language models (SLMs). The framework describes an evidence
map for each question and fully utilizes an SLM to derive the representation of
the supportive evaluation, the logical correlation, and the summarization of
the related evidence, which facilitates an analysis-augmented generation with
another SLM in an autoregressive way. Extensive experiments have shown that
introducing an evidence analysis learning process can significantly outperform
larger models and popular LLM reasoning methods.

æè¦ï¼ç¾æç LLM æ¹æ³ééå©ç¨æ¨¡åçå§é¨æ¨çè½åææ´åå¤é¨ç¥è­ä¾æååé¡è§£ç­æè½ãç¶èï¼ç¶äººé¡é¢å°å°æ¥­åé¡æï¼å¿é æç¢ºåæä¾èªå¤åçæ®µåä¸åè­æä¾æºçå¤é¢åéä¿ï¼æè½ç²å¾æ´å¥½çè§£ç­ãå¨æ¬ç ç©¶ä¸­ï¼æåéå°çç©é«å­¸é åæåºä¸åæ°ç©ççæå¼åé¡è§£ç­æ¶æ§ï¼åçº EvidenceMapï¼æ­¤æ¶æ§æç¢ºå­¸ç¿ä¸¦æ´åè­æåæèå°åèªè¨æ¨¡å (SLM)ãæ­¤æ¶æ§æçºæ¯ååé¡æè¿°ä¸åè­ææ å°ï¼ä¸¦ååå©ç¨ SLM ä¾è¡çæ¯ææ§è©ä¼°ãéè¼¯éè¯åç¸éè­æçæè¦ï¼éæå©æ¼ä»¥èªè¿´æ­¸æ¹å¼ä½¿ç¨å¦ä¸å SLM é²è¡åæå¢å¼·çæãå»£æ³çå¯¦é©é¡¯ç¤ºï¼å¼å¥è­æåæå­¸ç¿æµç¨å¯ä»¥é¡¯èåªæ¼è¼å¤§çæ¨¡ååæµè¡ç LLM æ¨çæ¹æ³ã

##### **A Call for Critically Rethinking and Reforming Data Analysis in Empirical Software Engineering**
2501.12728v1 by Matteo Esposito, Mikel Robredo, Murali Sridharan, Guilherme Horta Travassos, Rafael PeÃ±aloza, Valentina Lenarduzzi

Context: Empirical Software Engineering (ESE) drives innovation in SE through
qualitative and quantitative studies. However, concerns about the correct
application of empirical methodologies have existed since the 2006 Dagstuhl
seminar on SE. Objective: To analyze three decades of SE research, identify
mistakes in statistical methods, and evaluate experts' ability to detect and
address these issues. Methods: We conducted a literature survey of ~27,000
empirical studies, using LLMs to classify statistical methodologies as adequate
or inadequate. Additionally, we selected 30 primary studies and held a workshop
with 33 ESE experts to assess their ability to identify and resolve statistical
issues. Results: Significant statistical issues were found in the primary
studies, and experts showed limited ability to detect and correct these
methodological problems, raising concerns about the broader ESE community's
proficiency in this area. Conclusions. Despite our study's eventual
limitations, its results shed light on recurring issues from promoting
information copy-and-paste from past authors' works and the continuous
publication of inadequate approaches that promote dubious results and
jeopardize the spread of the correct statistical strategies among researchers.
Besides, it justifies further investigation into empirical rigor in software
engineering to expose these recurring issues and establish a framework for
reassessing our field's foundation of statistical methodology application.
Therefore, this work calls for critically rethinking and reforming data
analysis in empirical software engineering, paving the way for our work soon.

æè¦ï¼<paragraph>èçµ¡ï¼ç¶é©è»é«å·¥ç¨ï¼ESEï¼ééè³ªååéåç ç©¶æ¨åè»é«å·¥ç¨ï¼SEï¼çåµæ°ãç¶èï¼èª 2006 å¹´éæ ¼æ¯åç¾ç è¨æéæ¼ SE ä»¥ä¾ï¼å°æ¼ç¶é©æ¹æ³æ­£ç¢ºæç¨ççæ®ä¸ç´å­å¨ãç®æ¨ï¼åæä¸åå¹´ç SE ç ç©¶ï¼æ¾åºçµ±è¨æ¹æ³ä¸­çé¯èª¤ï¼ä¸¦è©ä¼°å°å®¶ç¼ç¾åè§£æ±ºéäºåé¡çè½åãæ¹æ³ï¼æåå°ç´ 27,000 é ç¶é©ç ç©¶é²è¡æç»èª¿æ¥ï¼ä½¿ç¨ LLM å°çµ±è¨æ¹æ³åé¡çºé©ç¶æä¸é©ç¶ãæ­¤å¤ï¼æåæé¸äº 30 é ä¸»è¦ç ç©¶ï¼ä¸¦èè¾¦äºä¸å ´å·¥ä½åï¼éè« 33 ä½ ESE å°å®¶è©ä¼°ä»åæ¾åºåè§£æ±ºçµ±è¨åé¡çè½åãçµæï¼å¨ä¸»è¦ç ç©¶ä¸­ç¼ç¾æé¡¯èççµ±è¨åé¡ï¼èå°å®¶å±ç¾åºæéçè½åä¾ç¼ç¾åä¿®æ­£éäºæ¹æ³å­¸åé¡ï¼éå¼ç¼äºå°æ¼æ´å»£æ³ç ESE ç¤¾ç¾¤å¨æ­¤é åççç·´åº¦çæ®ãçµè«ï¼åç®¡æåçç ç©¶æçµæå¶éå¶ï¼ä½å¶çµææ­é²äºåè¦åºç¾çåé¡ï¼åæ¬å¾éå»ä½èçä½åä¸­æ¨å»£è³è¨è¤è£½è²¼ä¸ï¼ä»¥åæçºç¼è¡¨ä¸é©ç¶çæ¹æ³ï¼éäºæ¹æ³ææ¨å»£å¯çççµæï¼ä¸¦å±å®³æ­£ç¢ºççµ±è¨ç­ç¥å¨ç ç©¶äººå¡ä¹éçå³æ­ãæ­¤å¤ï¼éè­æäºé²ä¸æ­¥èª¿æ¥è»é«å·¥ç¨ä¸­çç¶é©å´è¬¹æ§æ¯åççï¼ä»¥æ­é²éäºåè¦åºç¾çåé¡ï¼ä¸¦å»ºç«ä¸åæ¶æ§ä¾éæ°è©ä¼°æåé åççµ±è¨æ¹æ³æç¨åºç¤ãå æ­¤ï¼éé å·¥ä½å¼ç±²æ¹å¤æ§å°éæ°æèåæ¹é©ç¶é©è»é«å·¥ç¨ä¸­çè³æåæï¼çºæåçå·¥ä½å¨ä¸ä¹çå°ä¾éªè·¯ã</paragraph>

##### **Practical quantum federated learning and its experimental demonstration**
2501.12709v1 by Zhi-Ping Liu, Xiao-Yu Cao, Hao-Wen Liu, Xiao-Ran Sun, Yu Bao, Yu-Shuo Lu, Hua-Lei Yin, Zeng-Bing Chen

Federated learning is essential for decentralized, privacy-preserving model
training in the data-driven era. Quantum-enhanced federated learning leverages
quantum resources to address privacy and scalability challenges, offering
security and efficiency advantages beyond classical methods. However, practical
and scalable frameworks addressing privacy concerns in the quantum computing
era remain undeveloped. Here, we propose a practical quantum federated learning
framework on quantum networks, utilizing distributed quantum secret keys to
protect local model updates and enable secure aggregation with
information-theoretic security. We experimentally validate our framework on a
4-client quantum network with a scalable structure. Extensive numerical
experiments on both quantum and classical datasets show that adding a quantum
client significantly enhances the trained global model's ability to classify
multipartite entangled and non-stabilizer quantum datasets. Simulations further
demonstrate scalability to 200 clients with classical models trained on the
MNIST dataset, reducing communication costs by $75\%$ through advanced model
compression techniques and achieving rapid training convergence. Our work
provides critical insights for building scalable, efficient, and quantum-secure
machine learning systems for the coming quantum internet era.

æè¦ï¼è¯é¦å­¸ç¿å°æ¼è³æé©åæä»£çåæ£å¼ãé±ç§ä¿è­·æ¨¡åè¨ç·´è³ééè¦ãéå­å¢å¼·è¯é¦å­¸ç¿å©ç¨éå­è³æºä¾è§£æ±ºé±ç§åå¯æ´åæ§ææ°ï¼æä¾è¶è¶å³çµ±æ¹æ³çå®å¨æ§åæçåªå¢ãç¶èï¼å¨éå­éç®æä»£è§£æ±ºé±ç§åé¡çå¯¦ç¨ä¸å¯æ´åæ§çæ¡æ¶ä»æªéç¼ãå¨æ­¤ï¼æåæåºä¸åå¨éå­ç¶²è·¯ä¸çå¯¦ç¨éå­è¯é¦å­¸ç¿æ¡æ¶ï¼å©ç¨åæ£å¼éå­å¯é°ä¾ä¿è­·å±é¨æ¨¡åæ´æ°ï¼ä¸¦åç¨å·æè³è¨çè«å®å¨æ§çå®å¨èåãæåå¨å·æå¯æ´åæ§çµæ§ç 4 åç¨æ¶ç«¯éå­ç¶²è·¯ä¸­ï¼ä»¥å¯¦é©æ¹å¼é©è­æåçæ¡æ¶ãå¨éå­åç¶å¸è³æéä¸çå¤§éæ¸å¼å¯¦é©é¡¯ç¤ºï¼å å¥ä¸åéå­ç¨æ¶ç«¯é¡¯èå¢å¼·äºå·²è¨ç·´çå¨çæ¨¡åå°å¤æ¹ç³¾çºåéç©©å®å¨éå­è³æéé²è¡åé¡çè½åãæ¨¡æ¬é²ä¸æ­¥è­æäºå° 200 åç¨æ¶ç«¯çå¯æ´åæ§ï¼éäºç¨æ¶ç«¯ä½¿ç¨å¨ MNIST è³æéä¸è¨ç·´çç¶å¸æ¨¡åï¼ééé²éæ¨¡åå£ç¸®æè¡éä½äº 75% çéè¨ææ¬ï¼ä¸¦å¯¦ç¾äºå¿«éçè¨ç·´æ¶æãæåçç ç©¶çºå»ºæ§å¯æ´åãé«æä¸éå­å®å¨çæ©å¨å­¸ç¿ç³»çµ±ï¼ä»¥è¿æ¥å³å°å°ä¾çéå­ç¶²éç¶²è·¯æä»£ï¼æä¾äºéè¦çè¦è§£ã

##### **Training Dialogue Systems by AI Feedback for Improving Overall Dialogue Impression**
2501.12698v1 by Kai Yoshida, Masahiro Mizukami, Seiya Kawano, Canasai Kruengkrai, Hiroaki Sugiyama, Koichiro Yoshino

To improve user engagement during conversations with dialogue systems, we
must improve individual dialogue responses and dialogue impressions such as
consistency, personality, and empathy throughout the entire dialogue. While
such dialogue systems have been developing rapidly with the help of large
language models (LLMs), reinforcement learning from AI feedback (RLAIF) has
attracted attention to align LLM-based dialogue models for such dialogue
impressions. In RLAIF, a reward model based on another LLM is used to create a
training signal for an LLM-based dialogue model using zero-shot/few-shot
prompting techniques. However, evaluating an entire dialogue only by prompting
LLMs is challenging. In this study, the supervised fine-tuning (SFT) of LLMs
prepared reward models corresponding to 12 metrics related to the impression of
the entire dialogue for evaluating dialogue responses. We tuned our dialogue
models using the reward model signals as feedback to improve the impression of
the system. The results of automatic and human evaluations showed that tuning
the dialogue model using our reward model corresponding to dialogue impression
improved the evaluation of individual metrics and the naturalness of the
dialogue response.

æè¦ï¼çºäºå¨å°è©±ç³»çµ±å°è©±æéæåä½¿ç¨èçåèåº¦ï¼æåå¿é æ¹ååå¥å°è©±åæä»¥åå°è©±å°è±¡ï¼ä¾å¦å¨æ´åå°è©±ä¸­çä¸è´æ§ãåæ§èåçå¿ãéç¶æ­¤é¡å°è©±ç³»çµ±å¨å¤§åèªè¨æ¨¡å (LLM) çåå©ä¸å¿«éç¼å±ï¼ä½ä¾èª AI åé¥çå¼·åå­¸ç¿ (RLAIF) å·²å¼èµ·æ³¨æï¼å¯èª¿æ´åºæ¼ LLM çå°è©±æ¨¡åä»¥ç²å¾æ­¤é¡å°è©±å°è±¡ãå¨ RLAIF ä¸­ï¼åºæ¼å¦ä¸å LLM ççåµæ¨¡åç¨æ¼ä½¿ç¨é¶æ¬¡/å°æ¬¡æç¤ºæè¡çºåºæ¼ LLM çå°è©±æ¨¡åå»ºç«è¨ç·´è¨èãä¸éï¼åééæç¤º LLM å°±è©ä¼°æ´åå°è©±å·æææ°æ§ãå¨éé ç ç©¶ä¸­ï¼LLM çç£ç£å¾®èª¿ (SFT) æºåäºè 12 é ææ¨å°æççåµæ¨¡åï¼éäºææ¨èè©ä¼°å°è©±åæçå°è©±æ´é«å°è±¡æéãæåä½¿ç¨çåµæ¨¡åè¨èä½çºåé¥å¾®èª¿æåçå°è©±æ¨¡åï¼ä»¥æ¹åç³»çµ±çå°è±¡ãèªååäººå·¥è©ä¼°çµæé¡¯ç¤ºï¼ä½¿ç¨èå°è©±å°è±¡å°æççåµæ¨¡åå¾®èª¿å°è©±æ¨¡åï¼æ¹åäºåå¥ææ¨çè©ä¼°ä»¥åå°è©±åæçèªç¶æ§ã

##### **Growth strategies for arbitrary DAG neural architectures**
2501.12690v1 by Stella Douka, Manon Verbockhaven, ThÃ©o Rudkiewicz, StÃ©phane Rivaud, FranÃ§ois P Landes, Sylvain Chevallier, Guillaume Charpiat

Deep learning has shown impressive results obtained at the cost of training
huge neural networks. However, the larger the architecture, the higher the
computational, financial, and environmental costs during training and
inference. We aim at reducing both training and inference durations. We focus
on Neural Architecture Growth, which can increase the size of a small model
when needed, directly during training using information from the
backpropagation. We expand existing work and freely grow neural networks in the
form of any Directed Acyclic Graph by reducing expressivity bottlenecks in the
architecture. We explore strategies to reduce excessive computations and steer
network growth toward more parameter-efficient architectures.

æè¦ï¼æ·±åº¦å­¸ç¿å·²å±ç¾é©äººçææï¼ä½ä»£å¹æ¯è¨ç·´é¾å¤§çç¥ç¶ç¶²è·¯ãç¶èï¼æ¶æ§è¶å¤§ï¼å¨è¨ç·´åæ¨è«æéçéç®ãè²¡ååç°å¢ææ¬å°±è¶é«ãæåçç®æ¨æ¯ç¸®ç­è¨ç·´åæ¨è«æéãæåå°æ³¨æ¼ç¥ç¶æ¶æ§æé·ï¼å®å¯ä»¥å¨éè¦æç´æ¥å¨è¨ç·´æéä½¿ç¨ååå³æ­ä¸­çè³è¨ä¾å¢å å°åæ¨¡åçå¤§å°ãæåæ´å±ç¾æå·¥ä½ï¼ä¸¦ä»¥æåç¡ç°åçå½¢å¼èªç±å°ç¼å±ç¥ç¶ç¶²è·¯ï¼æ¹æ³æ¯æ¸å°æ¶æ§ä¸­çè¡¨éè½åç¶é ¸ãæåæ¢ç´¢ç­ç¥ä»¥æ¸å°éå¤çéç®ï¼ä¸¦å¼å°ç¶²è·¯æé·æåæ´å·åæ¸æççæ¶æ§ã

##### **Extracting General-use Transformers for Low-resource Languages via Knowledge Distillation**
2501.12660v1 by Jan Christian Blaise Cruz, Alham Fikri Aji

In this paper, we propose the use of simple knowledge distillation to produce
smaller and more efficient single-language transformers from Massively
Multilingual Transformers (MMTs) to alleviate tradeoffs associated with the use
of such in low-resource settings. Using Tagalog as a case study, we show that
these smaller single-language models perform on-par with strong baselines in a
variety of benchmark tasks in a much more efficient manner. Furthermore, we
investigate additional steps during the distillation process that improves the
soft-supervision of the target language, and provide a number of analyses and
ablations to show the efficacy of the proposed method.

æè¦ï¼å¨æ¬æä¸­ï¼æåå»ºè­°ä½¿ç¨ç°¡å®çç¥è­è¸é¤¾ï¼å¾å¤§åå¤èªè¨è½æå¨ (MMT) ä¸­ç¢çæ´å°ãæ´ææççå®ä¸èªè¨è½æå¨ï¼ä»¥æ¸è¼å¨è³æºä¸è¶³çç°å¢ä¸­ä½¿ç¨æ­¤é¡è½æå¨ç¸éçæ¬è¡¡ãä»¥ä»å ç¥¿èªçºä¾ï¼æåè¡¨æéäºè¼å°çå®ä¸èªè¨æ¨¡åå¨åç¨®åºæºä»»åä¸­ä»¥æ´ææççæ¹å¼å·è¡èå¼·å¤§åºæºç·ç¸åçæä½ãæ­¤å¤ï¼æåå¨è¸é¤¾éç¨ä¸­ç ç©¶äºæ¹é²ç®æ¨èªè¨è»ç£ç£çéå æ­¥é©ï¼ä¸¦æä¾äºä¸äºåæåæ¶èï¼ä»¥é¡¯ç¤ºææåºæ¹æ³çåæã

##### **The potential -- and the pitfalls -- of using pre-trained language models as cognitive science theories**
2501.12651v1 by Raj Sanjay Shah, Sashank Varma

Many studies have evaluated the cognitive alignment of Pre-trained Language
Models (PLMs), i.e., their correspondence to adult performance across a range
of cognitive domains. Recently, the focus has expanded to the developmental
alignment of these models: identifying phases during training where
improvements in model performance track improvements in children's thinking
over development. However, there are many challenges to the use of PLMs as
cognitive science theories, including different architectures, different
training data modalities and scales, and limited model interpretability. In
this paper, we distill lessons learned from treating PLMs, not as engineering
artifacts but as cognitive science and developmental science models. We review
assumptions used by researchers to map measures of PLM performance to measures
of human performance. We identify potential pitfalls of this approach to
understanding human thinking, and we end by enumerating criteria for using PLMs
as credible accounts of cognition and cognitive development.

æè¦ï¼è¨±å¤ç ç©¶è©ä¼°äºé è¨ç·´èªè¨æ¨¡å (PLM) çèªç¥å°é½ï¼å³å®åå¨åç¨®èªç¥é åä¸­èæäººè¡¨ç¾çå°æéä¿ãæè¿ï¼ç¦é»å·²æ´å±å°éäºæ¨¡åçç¼å±å°é½ï¼è­å¥è¨ç·´æéçéæ®µï¼å¶ä¸­æ¨¡åè¡¨ç¾çé²æ­¥è¿½è¹¤åç«¥æç¶­å¨ç¼å±éç¨ä¸­çé²æ­¥ãç¶èï¼å° PLM ç¨ä½èªç¥ç§å­¸çè«å­å¨è¨±å¤ææ°ï¼åæ¬ä¸åçæ¶æ§ãä¸åçè¨ç·´æ¸ææ¨¡å¼åè¦æ¨¡ï¼ä»¥åæéçæ¨¡åå¯è§£éæ§ãå¨æ¬æä¸­ï¼æåå¾å° PLM è¦çºèªç¥ç§å­¸åç¼å±ç§å­¸æ¨¡åï¼èä¸æ¯å·¥ç¨äººå·¥è£½åä¸­å¸åæè¨ãæååé¡§äºç ç©¶äººå¡ç¨æ¼å° PLM æè½æ¸¬éå°æå°äººé¡æè½æ¸¬éçåè¨­ãæåè­å¥äºéç¨®çè§£äººé¡æç¶­æ¹æ³çæ½å¨ç¼ºé·ï¼ä¸¦æå¾åèäºå° PLM ç¨ä½èªç¥åèªç¥ç¼å±çå¯ä¿¡èªªæçæ¨æºã

##### **Dynamics of Toxicity in Political Podcasts**
2501.12640v1 by Naquee Rizwan, Nayandeep Deb, Sarthak Roy, Vishwajeet Singh Solanki, Kiran Garimella, Animesh Mukherjee

Toxicity in digital media poses significant challenges, yet little attention
has been given to its dynamics within the rapidly growing medium of podcasts.
This paper addresses this gap by analyzing political podcast data to study the
emergence and propagation of toxicity, focusing on conversation
chains-structured reply patterns within podcast transcripts. Leveraging
state-of-the-art transcription models and advanced conversational analysis
techniques, we systematically examine toxic discourse in over 30 popular
political podcasts in the United States. Our key contributions include: (1)
creating a comprehensive dataset of transcribed and diarized political
podcasts, identifying thousands of toxic instances using Google's Perspective
API, (2) uncovering concerning trends where a majority of episodes contain at
least one toxic instance, (3) introducing toxic conversation chains and
analyzing their structural and linguistic properties, revealing characteristics
such as longer durations, repetitive patterns, figurative language, and
emotional cues tied to anger and annoyance, (4) identifying demand-related
words like 'want', 'like', and 'know' as precursors to toxicity, and (5)
developing predictive models to anticipate toxicity shifts based on annotated
change points. Our findings provide critical insights into podcast toxicity and
establish a foundation for future research on real-time monitoring and
intervention mechanisms to foster healthier discourse in this influential
medium.

æè¦ï¼æ¸ä½åªé«ä¸­çæ¯æ§å¸¶ä¾äºéå¤§çææ°ï¼ä½å°æ¼å¨å¿«éæé·çæ­å®¢åªé«ä¸­å¶åææ§å»é®®å°åå°éæ³¨ãæ¬æééåææ¿æ²»æ­å®¢è³æä¾æ¢è¨éåå·®è·ï¼ç ç©¶æ¯æ§çåºç¾èå³æ­ï¼ç¹å¥å°æ³¨æ¼æ­å®¢è¨éä¸­çå°è©±éââçµæ§åçåè¦æ¨¡å¼ãéç¨æåé²çè½éæ¨¡ååé²éçå°è©±åææè¡ï¼æåç³»çµ±æ§å°æª¢è¦ç¾åè¶é 30 åç±éæ¿æ²»æ­å®¢ä¸­çææ¯è¨è«ãæåçééµè²¢ç»åæ¬ï¼(1) å»ºç«ä¸ååå«è½éåæ¥è¨åæ¿æ²»æ­å®¢çç¶åè³æéï¼ä½¿ç¨ Google ç Perspective API æ¾åºæ¸ååææ¯åæ¡ï¼(2) æ­é²ä»¤äººææçè¶¨å¢ï¼å¶ä¸­å¤§é¨åéæ¸é½è³å°åå«ä¸åææ¯åæ¡ï¼(3) æåºææ¯å°è©±éä¸¦åæå¶çµæ§åèªè¨ç¹æ§ï¼æ­é²è«¸å¦è¼é·æçºæéãéè¤æ¨¡å¼ãæ¯å»èªè¨ï¼ä»¥åèæ¤æåç©æ±ç¸éçæç·ç·ç´¢ç­ç¹å¾µï¼(4) æ¾åºèéæ±ç¸éçå­è©ï¼ä¾å¦ãæ³è¦ãããåæ­¡ãåãç¥éãï¼ä½çºæ¯æ§çååï¼ä»¥å (5) æ ¹æè¨»è§£çè®æ´é»éç¼é æ¸¬æ¨¡åï¼ä»¥é æ¸¬æ¯æ§çè½è®ãæåçç ç©¶çµææä¾äºå°æ­å®¢æ¯æ§çéè¦è¦è§£ï¼ä¸¦çºæªä¾å¨éåæå½±é¿åçåªé«ä¸­å»ºç«å³æç£æ§åä»å¥æ©å¶çç¸éç ç©¶å¥ å®åºç¤ï¼ä»¥ä¿é²æ´å¥åº·çè«è¿°ã

##### **Inverse Reinforcement Learning with Switching Rewards and History Dependency for Characterizing Animal Behaviors**
2501.12633v1 by Jingyang Ke, Feiyang Wu, Jiyi Wang, Jeffrey Markowitz, Anqi Wu

Traditional approaches to studying decision-making in neuroscience focus on
simplified behavioral tasks where animals perform repetitive, stereotyped
actions to receive explicit rewards. While informative, these methods constrain
our understanding of decision-making to short timescale behaviors driven by
explicit goals. In natural environments, animals exhibit more complex,
long-term behaviors driven by intrinsic motivations that are often
unobservable. Recent works in time-varying inverse reinforcement learning (IRL)
aim to capture shifting motivations in long-term, freely moving behaviors.
However, a crucial challenge remains: animals make decisions based on their
history, not just their current state. To address this, we introduce SWIRL
(SWitching IRL), a novel framework that extends traditional IRL by
incorporating time-varying, history-dependent reward functions. SWIRL models
long behavioral sequences as transitions between short-term decision-making
processes, each governed by a unique reward function. SWIRL incorporates
biologically plausible history dependency to capture how past decisions and
environmental contexts shape behavior, offering a more accurate description of
animal decision-making. We apply SWIRL to simulated and real-world animal
behavior datasets and show that it outperforms models lacking history
dependency, both quantitatively and qualitatively. This work presents the first
IRL model to incorporate history-dependent policies and rewards to advance our
understanding of complex, naturalistic decision-making in animals.

æè¦ï¼å³çµ±ç ç©¶ç¥ç¶ç§å­¸ä¸­æ±ºç­å¶å®æ¹æ³ï¼å°æ³¨æ¼ç°¡åè¡çºä»»åï¼è®åç©å·è¡éè¤ãå»æ¿çåä½ä»¥ç²å¾æç¢ºçåµãéäºæ¹æ³éç¶æä¾è³è¨ï¼ä½æå°æåå°æ±ºç­å¶å®ççè§£éå¶å¨åæç¢ºç®æ¨é©åçç­æè¡çºãå¨èªç¶ç°å¢ä¸­ï¼åç©è¡¨ç¾åºæ´è¤éãé·æçè¡çºï¼éäºè¡çºæ¯ç±éå¸¸ç¡æ³è§å¯å°çå§å¨åæ©æé©åãæéè®ç°ååå¼·åå­¸ç¿ (IRL) çè¿æç ç©¶æ¨å¨ææé·æãèªç±ç§»åè¡çºä¸­ä¸æ·è®åçåæ©ãç¶èï¼ä¸åééµææ°ä»ç¶å­å¨ï¼åç©æ ¹æå¶æ­·å²ååºæ±ºå®ï¼èä¸ä»ä»æ¯å¶ç¶åçæãçºäºè§£æ±ºéååé¡ï¼æåå¼å¥äº SWIRLï¼SWitching IRLï¼ï¼éæ¯ä¸åæ°çæ¡æ¶ï¼ééæ´åæè®ãèæ­·å²ç¸éççåµå½æ¸ä¾æ´åå³çµ±ç IRLãSWIRL æ¨¡åå°é·è¡çºåºåå»ºæ¨¡çºç­ææ±ºç­å¶å®éç¨ä¹éçè½æï¼æ¯åéç¨é½ç±ä¸åç¨ç¹ççåµå½æ¸ææ§å¶ãSWIRL çµåäºçç©å­¸ä¸åççæ­·å²ä¾è³´æ§ï¼ä»¥ææéå»çæ±ºå®åç°å¢èæ¯å¦ä½å½±é¿è¡çºï¼æä¾åç©æ±ºç­å¶å®æ´æºç¢ºçæè¿°ãæåå° SWIRL æç¨æ¼æ¨¡æ¬åçå¯¦ä¸ççåç©è¡çºæ¸æéï¼ä¸¦è­æå®å¨éååè³ªåæ¹é¢é½åªæ¼ç¼ºä¹æ­·å²ä¾è³´æ§çæ¨¡åãéé å·¥ä½æåºäºç¬¬ä¸åçµåèæ­·å²ç¸éçç­ç¥åçåµç IRL æ¨¡åï¼ä»¥å¢é²æåå°åç©è¤éãèªç¶æ±ºç­å¶å®ççè§£ã

##### **Towards Robust Multi-tab Website Fingerprinting**
2501.12622v1 by Xinhao Deng, Xiyuan Zhao, Qilei Yin, Zhuotao Liu, Qi Li, Mingwei Xu, Ke Xu, Jianping Wu

Website fingerprinting enables an eavesdropper to determine which websites a
user is visiting over an encrypted connection. State-of-the-art website
fingerprinting (WF) attacks have demonstrated effectiveness even against
Tor-protected network traffic. However, existing WF attacks have critical
limitations on accurately identifying websites in multi-tab browsing sessions,
where the holistic pattern of individual websites is no longer preserved, and
the number of tabs opened by a client is unknown a priori. In this paper, we
propose ARES, a novel WF framework natively designed for multi-tab WF attacks.
ARES formulates the multi-tab attack as a multi-label classification problem
and solves it using the novel Transformer-based models. Specifically, ARES
extracts local patterns based on multi-level traffic aggregation features and
utilizes the improved self-attention mechanism to analyze the correlations
between these local patterns, effectively identifying websites. We implement a
prototype of ARES and extensively evaluate its effectiveness using our
large-scale datasets collected over multiple months. The experimental results
illustrate that ARES achieves optimal performance in several realistic
scenarios. Further, ARES remains robust even against various WF defenses.

æè¦ï¼ç¶²ç«æç´è¾¨è­è®ç«è½èå¾ä»¥å¨å å¯é£ç·ä¸­å¤æ·ä½¿ç¨èé è¨ªåªäºç¶²ç«ãæåé²çç¶²ç«æç´è¾¨è­ (WF) æ»æå·²è­æå³ä½¿éå° Tor ä¿è­·çç¶²è·¯æµéä¹è½ç¼æ®æç¨ãç¶èï¼ç¾æç WF æ»æå¨æºç¢ºè¾¨è­å¤æ¨ç±¤çè¦½æè©±ä¸­çç¶²ç«ææå´éçéå¶ï¼å¶ä¸­åå¥ç¶²ç«çæ´é«æ¨¡å¼ä¸åä¿çï¼èä¸ç¡æ³äºåå¾ç¥å®¢æ¶ç«¯éåçæ¨ç±¤æ¸éãå¨æ¬æä¸­ï¼æåæåº ARESï¼ä¸åå°éè¨­è¨ç¨æ¼å¤æ¨ç±¤ WF æ»æçæ°ç© WF æ¡æ¶ãARES å°å¤æ¨ç±¤æ»æå¶å®çºå¤æ¨ç±¤åé¡åé¡ï¼ä¸¦ä½¿ç¨æ°ç©çåºæ¼ Transformer çæ¨¡åè§£æ±ºå®ãå·é«ä¾èªªï¼ARES æ ¹æå¤å±¤ç´æµéå½ç¸½ç¹å¾µèåå±é¨æ¨¡å¼ï¼ä¸¦å©ç¨æ¹é²çèªææ³¨ææ©å¶åæéäºå±é¨æ¨¡å¼ä¹éçéè¯æ§ï¼ææå°è¾¨è­ç¶²ç«ãæåå¯¦ä½ ARES çååï¼ä¸¦ä½¿ç¨æåå¨æ¸åæå§æ¶éçå¤§è¦æ¨¡è³æéå»£æ³è©ä¼°å¶æè½ãå¯¦é©çµæé¡¯ç¤ºï¼ARES å¨å¤ç¨®å¯¦éææ³ä¸é½è½éå°æä½³æè½ãæ­¤å¤ï¼å³ä½¿éå°åç¨® WF é²ç¦¦ï¼ARES ä»ç¶ä¿æç©©å¥ã

##### **Distillation Quantification for Large Language Models**
2501.12619v1 by Sunbowen Lee, Junting Zhou, Chang Ao, Kaige Li, Xinrun Du, Sirui He, Jiaheng Liu, Min Yang, Zhoufutu Wen, Shiwen Ni

Model distillation is a technique for transferring knowledge from large
language models (LLMs) to smaller ones, aiming to create resource-efficient yet
high-performing models. However, excessive distillation can lead to
homogenization, reducing diversity among models and impairing their ability to
robustly handle complex or novel tasks. These limitations underscore the need
to systematically quantify the distillation process and its impact. In this
work, we propose a framework to evaluate and quantify model distillation. Our
method addresses two key aspects: (1) Identifying identity cognition
contradictions to assess discrepancies in how models perceive and represent
identity-related information, and (2) Analyzing multi-granularity response
similarities across models to measure the extent of homogenization.
Experimental results demonstrate two key insights: (1) Well-known closed-source
and open-source LLMs usually exhibit high distillation degrees, except for
Claude, Doubao, and Gemini. (2) Base LLMs show higher distillation degrees
compared to aligned LLMs. By offering a systematic approach to improve the
transparency of LLM data distillation, we call for LLMs with more independent
development and more transparent technical reports to improve LLMs' robustness
and safety. The code and data are available under
https://github.com/Aegis1863/LLMs-Distillation-Quantification.

æè¦ï¼æ¨¡åè¸é¤¾æ¯ä¸ç¨®å°ç¥è­å¾å¤§åèªè¨æ¨¡å (LLM) è½ç§»å°è¼å°æ¨¡åçæè¡ï¼ç®çæ¯å»ºç«è³æºæçé«ä½æè½è¯å¥½çæ¨¡åãç¶èï¼éåº¦çè¸é¤¾å¯è½å°è´åè³ªåï¼æ¸å°æ¨¡åä¹éçå¤æ¨£æ§ï¼ä¸¦æå®³å®åç©©å¥èçè¤éææ°ç©ä»»åçè½åãéäºéå¶å¼·èª¿äºç³»çµ±åéåè¸é¤¾éç¨åå¶å½±é¿çå¿è¦æ§ãå¨éé å·¥ä½ä¸­ï¼æåæåºäºä¸åè©ä¼°åéåæ¨¡åè¸é¤¾çæ¡æ¶ãæåçæ¨¡åæ¢è¨äºå©åééµé¢åï¼(1) è­å¥èº«åèªç¥çç¾ï¼ä»¥è©ä¼°æ¨¡åå¨æç¥ååç¾èº«åç¸éè³è¨çæ¹å¼ä¸çå·®ç°ï¼ä»¥å (2) åææ¨¡åä¹éçå¤ç²åº¦åæç¸ä¼¼æ§ï¼ä»¥è¡¡éåè³ªåçç¨åº¦ãå¯¦é©çµæè­æäºå©åééµè¦è§£ï¼(1) é¤äº ClaudeãDoubao å Gemini ä¹å¤ï¼ç¾æå¨ç¥çéæºåéæº LLM éå¸¸è¡¨ç¾åºé«åº¦çè¸é¤¾ç¨åº¦ã(2) èå°é½ç LLM ç¸æ¯ï¼åºç¤ LLM é¡¯ç¤ºåºæ´é«çè¸é¤¾ç¨åº¦ãééæä¾ä¸ç¨®ç³»çµ±åçæ¹æ³ä¾æé« LLM è³æè¸é¤¾çéæåº¦ï¼æåå¼ç±²éç¼åºæ´ç¨ç«ä¸æè¡å ±åæ´éæç LLMï¼ä»¥æé« LLM çç©©å¥æ§åå®å¨æ§ãç¨å¼ç¢¼åè³æå¯å¨ https://github.com/Aegis1863/LLMs-Distillation-Quantification ä¸åå¾ã

##### **Deep Learning-Based Identification of Inconsistent Method Names: How Far Are We?**
2501.12617v1 by Taiming Wang, Yuxia Zhang, Lin Jiang, Yi Tang, Guangjie Li, Hui Liu

Concise and meaningful method names are crucial for program comprehension and
maintenance. However, method names may become inconsistent with their
corresponding implementations, causing confusion and errors. Several deep
learning (DL)-based approaches have been proposed to identify such
inconsistencies, with initial evaluations showing promising results. However,
these evaluations typically use a balanced dataset, where the number of
inconsistent and consistent names are equal. This setup, along with flawed
dataset construction, leads to false positives, making reported performance
less reliable in real-world scenarios, where most method names are consistent.
In this paper, we present an empirical study that evaluates state-of-the-art
DL-based methods for identifying inconsistent method names. We create a new
benchmark by combining automatic identification from commit histories and
manual developer inspections, reducing false positives. We evaluate five
representative DL approaches (one retrieval-based and four generation-based) on
this benchmark. Our results show that performance drops substantially when
moving from the balanced dataset to the new benchmark. We further conduct
quantitative and qualitative analyses to understand the strengths and
weaknesses of the approaches. Retrieval-based methods perform well on simple
methods and those with popular name sub-tokens but fail due to inefficient
representation techniques. Generation-based methods struggle with inaccurate
similarity calculations and immature name generation. Based on these findings,
we propose improvements using contrastive learning and large language models
(LLMs). Our study suggests that significant improvements are needed before
these DL approaches can be effectively applied to real-world software systems.

æè¦ï¼ç°¡æ½ä¸ææç¾©çæ¹æ³åç¨±å°æ¼ç¨å¼çè§£åç¶­è­·è³ééè¦ãç¶èï¼æ¹æ³åç¨±å¯è½æèå¶å°æçå¯¦ä½ä¸ä¸è´ï¼é ææ··æ·åé¯èª¤ãå·²ç¶æåºäºä¸äºåºæ¼æ·±åº¦å­¸ç¿ (DL) çæ¹æ³ä¾è­å¥æ­¤é¡ä¸ä¸è´ï¼åæ­¥è©ä¼°é¡¯ç¤ºåºæå¸æççµæãç¶èï¼éäºè©ä¼°éå¸¸ä½¿ç¨å¹³è¡¡çè³æéï¼å¶ä¸­ä¸ä¸è´åä¸è´åç¨±çæ¸éç¸ç­ãæ­¤è¨­å®é£åæç¼ºé·çè³æéå»ºæ§å°è´èª¤å ±ï¼ä½¿å¾å ±åçæè½ä¸å¤ªå¯é ï¼å¨ç¾å¯¦ä¸çå ´æ¯ä¸­ï¼å¤§å¤æ¸æ¹æ³åç¨±æ¯ä¸è´çãå¨æ¬æä¸­ï¼æåæåºä¸åç¶é©ç ç©¶ï¼è©ä¼°æåé²çåºæ¼ DL çæ¹æ³ä¾è­å¥ä¸ä¸è´çæ¹æ³åç¨±ãæåééçµåä¾èªæäº¤è¨éçèªåè­å¥åæåéç¼äººå¡æª¢æ¥ä¾å»ºç«ä¸åæ°çåºæºï¼æ¸å°èª¤å ±ãæåå¨æ­¤åºæºä¸è©ä¼°äºç¨®å·æä»£è¡¨æ§ç DL æ¹æ³ï¼ä¸ç¨®åºæ¼æª¢ç´¢ååç¨®åºæ¼çæï¼ãæåççµæé¡¯ç¤ºï¼å¾å¹³è¡¡çè³æéè½ç§»å°æ°çåºæºæï¼æè½å¤§å¹ä¸éãæåé²ä¸æ­¥é²è¡éååè³ªååæï¼ä»¥äºè§£éäºæ¹æ³çåªé»åç¼ºé»ãåºæ¼æª¢ç´¢çæ¹æ³å¨ç°¡å®çæ¹æ³åå·æç±éåç¨±å­ä»£å¹£çæ¹æ³ä¸è¡¨ç¾è¯å¥½ï¼ä½ç±æ¼ä½æççè¡¨ç¤ºæè¡èå¤±æãåºæ¼çæççæ¹æ³é£ä»¥é²è¡ä¸æºç¢ºçç¸ä¼¼æ§è¨ç®åä¸æççåç¨±çæãæ ¹æéäºç¼ç¾ï¼æåæåºä½¿ç¨å°æ¯å­¸ç¿åå¤§èªè¨æ¨¡å (LLM) çæ¹é²ãæåçç ç©¶è¡¨æï¼å¨éäº DL æ¹æ³å¯ä»¥æææç¨æ¼ç¾å¯¦ä¸ççè»é«ç³»çµ±ä¹åï¼éè¦é¡¯èçæ¹é²ã

##### **GATE: Adaptive Learning with Working Memory by Information Gating in Multi-lamellar Hippocampal Formation**
2501.12615v1 by Yuechen Liu, Zishun Wang, Chen Qiao, Zongben Xu

Hippocampal formation (HF) can rapidly adapt to varied environments and build
flexible working memory (WM). To mirror the HF's mechanism on generalization
and WM, we propose a model named Generalization and Associative Temporary
Encoding (GATE), which deploys a 3-D multi-lamellar dorsoventral (DV)
architecture, and learns to build up internally representation from externally
driven information layer-wisely. In each lamella, regions of HF:
EC3-CA1-EC5-EC3 forms a re-entrant loop that discriminately maintains
information by EC3 persistent activity, and selectively readouts the retained
information by CA1 neurons. CA3 and EC5 further provides gating function that
controls these processes. After learning complex WM tasks, GATE forms neuron
representations that align with experimental records, including splitter, lap,
evidence, trace, delay-active cells, as well as conventional place cells.
Crucially, DV architecture in GATE also captures information, range from
detailed to abstract, which enables a rapid generalization ability when cue,
environment or task changes, with learned representations inherited. GATE
promises a viable framework for understanding the HF's flexible memory
mechanisms and for progressively developing brain-inspired intelligent systems.

æè¦ï¼æµ·é¦¬è¿´ï¼HFï¼è½å¿«éé©æåç¨®ç°å¢ä¸¦å»ºç«å½æ§çå·¥ä½è¨æ¶ï¼WMï¼ãçºäºåæ  HF å¨æ¦åå WM ä¸çæ©å¶ï¼æåæåºä¸ååçºæ¦ååè¯æ³æ«æç·¨ç¢¼ï¼GATEï¼çæ¨¡åï¼å®é¨ç½²äºä¸å 3D å¤å±¤èè¹ï¼DVï¼æ¶æ§ï¼ä¸¦å­¸ç¿å¾å¤é¨é©åçä¿¡æ¯éå±¤å»ºç«å§é¨è¡¨å¾µãå¨æ¯åå±¤æ¿ä¸­ï¼HF ååï¼EC3-CA1-EC5-EC3 å½¢æä¸åéå¥è¿´è·¯ï¼éé EC3 æçºæ´»åä¾åå¥æ§å°ç¶­è­·ä¿¡æ¯ï¼ä¸¦éé CA1 ç¥ç¶åé¸ææ§å°è®åä¿ççä¿¡æ¯ãCA3 å EC5 é²ä¸æ­¥æä¾æ§å¶éäºéç¨çéæ§åè½ãå¨å­¸ç¿è¤éç WM ä»»åå¾ï¼GATE å½¢æèå¯¦é©è¨éä¸è´çç¥ç¶åè¡¨å¾µï¼åæ¬åé¢å¨ãè¿´è·¯ãè­æãçè·¡ãå»¶é²æ¿æ´»ç´°èä»¥åå³çµ±ä½ç½®ç´°èãè³ééè¦çæ¯ï¼GATE ä¸­ç DV æ¶æ§éæç²äºå¾å·é«å°æ½è±¡çä¿¡æ¯ï¼ç¶ç·ç´¢ãç°å¢æä»»åç¼çè®åæï¼éä½¿å¾è½å¤ å¿«éæ¦åè½åï¼ä¸¦ç¹¼æ¿å­¸ç¿å°çè¡¨å¾µãGATE çºçè§£ HF çéæ´»è¨æ¶æ©å¶åéæ­¥éç¼åå¤§è¦åç¼çæºè½ç³»çµ±æä¾äºä¸åå¯è¡çæ¡æ¶ã

##### **T2ISafety: Benchmark for Assessing Fairness, Toxicity, and Privacy in Image Generation**
2501.12612v1 by Lijun Li, Zhelun Shi, Xuhao Hu, Bowen Dong, Yiran Qin, Xihui Liu, Lu Sheng, Jing Shao

Text-to-image (T2I) models have rapidly advanced, enabling the generation of
high-quality images from text prompts across various domains. However, these
models present notable safety concerns, including the risk of generating
harmful, biased, or private content. Current research on assessing T2I safety
remains in its early stages. While some efforts have been made to evaluate
models on specific safety dimensions, many critical risks remain unexplored. To
address this gap, we introduce T2ISafety, a safety benchmark that evaluates T2I
models across three key domains: toxicity, fairness, and bias. We build a
detailed hierarchy of 12 tasks and 44 categories based on these three domains,
and meticulously collect 70K corresponding prompts. Based on this taxonomy and
prompt set, we build a large-scale T2I dataset with 68K manually annotated
images and train an evaluator capable of detecting critical risks that previous
work has failed to identify, including risks that even ultra-large proprietary
models like GPTs cannot correctly detect. We evaluate 12 prominent diffusion
models on T2ISafety and reveal several concerns including persistent issues
with racial fairness, a tendency to generate toxic content, and significant
variation in privacy protection across the models, even with defense methods
like concept erasing. Data and evaluator are released under
https://github.com/adwardlee/t2i_safety.

æè¦ï¼ææ¬å°å¾å (T2I) æ¨¡åè¿éåå±ï¼è½å¤æ ¹æ®è·¨è¶åç§é¢åçææ¬æç¤ºçæé«è´¨éå¾åãç¶èï¼è¿äºæ¨¡åæåºäºææ¾çå®å¨æ§é®é¢ï¼åæ¬çææå®³ãæåè§æç§æåå®¹çé£é©ãå½åå¯¹ T2I å®å¨æ§è¯ä¼°çç ç©¶ä»å¤äºæ©æé¶æ®µãè½ç¶å·²ç»ååºäºä¸äºåªåæ¥è¯ä¼°ç¹å®å®å¨ç»´åº¦ä¸çæ¨¡åï¼ä½è®¸å¤å³é®é£é©ä»æªå¾å°æ¢ç´¢ãä¸ºäºè§£å³è¿ä¸å·®è·ï¼æä»¬å¼å¥äº T2ISafetyï¼è¿æ¯ä¸ä¸ªå®å¨åºåï¼ç¨äºè¯ä¼° T2I æ¨¡åå¨ä¸ä¸ªå³é®é¢åï¼æ¯æ§ãå¬å¹³æ§ååè§ãæä»¬åºäºè¿ä¸ä¸ªé¢åæå»ºäºä¸ä¸ªåå« 12 ä¸ªä»»å¡å 44 ä¸ªç±»å«çè¯¦ç»å±æ¬¡ç»æï¼å¹¶ç²¾å¿æ¶éäº 70K ä¸ªç¸åºçæç¤ºãåºäºæ­¤åç±»æ³åæç¤ºéï¼æä»¬æå»ºäºä¸ä¸ªåå« 68K ä¸ªæå¨æ³¨éå¾åçå¤§è§æ¨¡ T2I æ°æ®éï¼å¹¶è®­ç»äºä¸ä¸ªè½å¤æ£æµååå·¥ä½æªè½è¯å«çå³é®é£é©çè¯ä¼°å¨ï¼åæ¬å³ä½¿æ¯ GPT ç­è¶å¤§åä¸ææ¨¡åä¹æ æ³æ­£ç¡®æ£æµçé£é©ãæä»¬å¨ T2ISafety ä¸è¯ä¼°äº 12 ä¸ªçªåºçæ©æ£æ¨¡åï¼å¹¶æ­ç¤ºäºå ä¸ªé®é¢ï¼åæ¬ç§æå¬å¹³æ§çæç»­é®é¢ãçææå®³åå®¹çå¾åï¼ä»¥åå³ä½¿éç¨æ¦å¿µæ¦é¤ç­é²å¾¡æ¹æ³ï¼æ¨¡åä¹é´çéç§ä¿æ¤ä¹å­å¨æ¾çå·®å¼ãæ°æ®åè¯ä¼°å¨å¨ https://github.com/adwardlee/t2i_safety ä¸åå¸ã

##### **BLR-MoE: Boosted Language-Routing Mixture of Experts for Domain-Robust Multilingual E2E ASR**
2501.12602v1 by Guodong Ma, Wenxuan Wang, Lifeng Zhou, Yuting Yang, Yuke Li, Binbin Du

Recently, the Mixture of Expert (MoE) architecture, such as LR-MoE, is often
used to alleviate the impact of language confusion on the multilingual ASR
(MASR) task. However, it still faces language confusion issues, especially in
mismatched domain scenarios. In this paper, we decouple language confusion in
LR-MoE into confusion in self-attention and router. To alleviate the language
confusion in self-attention, based on LR-MoE, we propose to apply attention-MoE
architecture for MASR. In our new architecture, MoE is utilized not only on
feed-forward network (FFN) but also on self-attention. In addition, to improve
the robustness of the LID-based router on language confusion, we propose expert
pruning and router augmentation methods. Combining the above, we get the
boosted language-routing MoE (BLR-MoE) architecture. We verify the
effectiveness of the proposed BLR-MoE in a 10,000-hour MASR dataset.

æè¦ï¼è¿æï¼ä¸å®¶æ··åï¼MoEï¼æ¶æï¼ä¾å¦ LR-MoEï¼éå¸¸ç¨äºåè½»è¯­è¨æ··æ·å¯¹å¤è¯­è¨ ASRï¼MASRï¼ä»»å¡çå½±åãç¶èï¼å®ä»ç¶é¢ä¸´è¯­è¨æ··æ·é®é¢ï¼å°¤å¶æ¯å¨ä¸å¹éçé¢ååºæ¯ä¸­ãå¨æ¬æä¸­ï¼æä»¬å° LR-MoE ä¸­çè¯­è¨æ··æ·è§£è¦ä¸ºèªæ³¨æååè·¯ç±å¨ä¸­çæ··æ·ãä¸ºäºåè½»èªæ³¨æåä¸­çè¯­è¨æ··æ·ï¼åºäº LR-MoEï¼æä»¬æåºä¸º MASR åºç¨æ³¨æå-MoE æ¶æãå¨æä»¬çæ°æ¶æä¸­ï¼MoE ä¸ä»ç¨äºåé¦ç½ç»ï¼FFNï¼ï¼è¿ç¨äºèªæ³¨æåãæ­¤å¤ï¼ä¸ºäºæé«åºäº LID çè·¯ç±å¨å¯¹è¯­è¨æ··æ·çé²æ£æ§ï¼æä»¬æåºäºä¸å®¶åªæåè·¯ç±å¨å¢å¼ºæ¹æ³ãç»åä¸è¿°æ¹æ³ï¼æä»¬å¾å°äºå¢å¼ºè¯­è¨è·¯ç± MoEï¼BLR-MoEï¼æ¶æãæä»¬å¨ä¸ä¸ª 10,000 å°æ¶ç MASR æ°æ®éä¸­éªè¯äºææåºç BLR-MoE çæææ§ã

##### **Kimi k1.5: Scaling Reinforcement Learning with LLMs**
2501.12599v1 by Kimi Team, Angang Du, Bofei Gao, Bowei Xing, Changjiu Jiang, Cheng Chen, Cheng Li, Chenjun Xiao, Chenzhuang Du, Chonghua Liao, Chuning Tang, Congcong Wang, Dehao Zhang, Enming Yuan, Enzhe Lu, Fengxiang Tang, Flood Sung, Guangda Wei, Guokun Lai, Haiqing Guo, Han Zhu, Hao Ding, Hao Hu, Hao Yang, Hao Zhang, Haotian Yao, Haotian Zhao, Haoyu Lu, Haoze Li, Haozhen Yu, Hongcheng Gao, Huabin Zheng, Huan Yuan, Jia Chen, Jianhang Guo, Jianlin Su, Jianzhou Wang, Jie Zhao, Jin Zhang, Jingyuan Liu, Junjie Yan, Junyan Wu, Lidong Shi, Ling Ye, Longhui Yu, Mengnan Dong, Neo Zhang, Ningchen Ma, Qiwei Pan, Qucheng Gong, Shaowei Liu, Shengling Ma, Shupeng Wei, Sihan Cao, Siying Huang, Tao Jiang, Weihao Gao, Weimin Xiong, Weiran He, Weixiao Huang, Wenhao Wu, Wenyang He, Xianghui Wei, Xianqing Jia, Xingzhe Wu, Xinran Xu, Xinxing Zu, Xinyu Zhou, Xuehai Pan, Y. Charles, Yang Li, Yangyang Hu, Yangyang Liu, Yanru Chen, Yejie Wang, Yibo Liu, Yidao Qin, Yifeng Liu, Ying Yang, Yiping Bao, Yulun Du, Yuxin Wu, Yuzhi Wang, Zaida Zhou, Zhaoji Wang, Zhaowei Li, Zhen Zhu, Zheng Zhang, Zhexu Wang, Zhilin Yang, Zhiqi Huang, Zihao Huang, Ziyao Xu, Zonghan Yang

Language model pretraining with next token prediction has proved effective
for scaling compute but is limited to the amount of available training data.
Scaling reinforcement learning (RL) unlocks a new axis for the continued
improvement of artificial intelligence, with the promise that large language
models (LLMs) can scale their training data by learning to explore with
rewards. However, prior published work has not produced competitive results. In
light of this, we report on the training practice of Kimi k1.5, our latest
multi-modal LLM trained with RL, including its RL training techniques,
multi-modal data recipes, and infrastructure optimization. Long context scaling
and improved policy optimization methods are key ingredients of our approach,
which establishes a simplistic, effective RL framework without relying on more
complex techniques such as Monte Carlo tree search, value functions, and
process reward models. Notably, our system achieves state-of-the-art reasoning
performance across multiple benchmarks and modalities -- e.g., 77.5 on AIME,
96.2 on MATH 500, 94-th percentile on Codeforces, 74.9 on MathVista -- matching
OpenAI's o1. Moreover, we present effective long2short methods that use
long-CoT techniques to improve short-CoT models, yielding state-of-the-art
short-CoT reasoning results -- e.g., 60.8 on AIME, 94.6 on MATH500, 47.3 on
LiveCodeBench -- outperforming existing short-CoT models such as GPT-4o and
Claude Sonnet 3.5 by a large margin (up to +550%).

æè¦ï¼èªè¨æ¨¡åé è¨ç·´å ä¸ä¸ä¸åç¬¦èé æ¸¬å·²è­æå°æ¼æ´åéç®ææï¼ä½åéæ¼å¯ç¨çè¨ç·´è³æéãæ´åå¼·åå­¸ç¿ (RL) çºæçºæ¹åäººå·¥æºæ§è§£éäºä¸åæ°è»¸ï¼æ¿è«¾å¤§åèªè¨æ¨¡å (LLM) è½ééå­¸ç¿æ¢ç´¢çåµä¾æ´åä»åçè¨ç·´è³æãç¶èï¼ä¹åç¼å¸çä½åå°æªç¢çæç«¶ç­åççµæãæéæ¼æ­¤ï¼æååå ± Kimi k1.5 çè¨ç·´å¯¦åï¼éæ¯æåææ°çå¤æ¨¡æ LLMï¼ä½¿ç¨ RL è¨ç·´ï¼åæ¬å¶ RL è¨ç·´æå·§ãå¤æ¨¡æè³æé£è­ååºç¤æ¶æ§æä½³åãé·èçµ¡æ´ååæ¹åçç­ç¥æä½³åæ¹æ³æ¯æåæ¹æ³ä¸­çééµè¦ç´ ï¼å»ºç«äºä¸åç°¡æ½ãææç RL æ¶æ§ï¼èä¸ä¾è³´æ¼æ´è¤éçæå·§ï¼ä¾å¦èå°å¡ç¾æ¨¹çæå°ãå¹å¼å½æ¸åèççåµæ¨¡åãå¼å¾æ³¨æçæ¯ï¼æåçç³»çµ±å¨å¤ååºæºåæ¨¡å¼ä¸­éææåé²çæ¨çæè½ââä¾å¦ï¼AIME ä¸­ç 77.5ãMATH 500 ä¸­ç 96.2ãCodeforces ä¸­ç 94 ç¾åä½ãMathVista ä¸­ç 74.9ââå¹é OpenAI ç o1ãæ­¤å¤ï¼æåæåºææç long2short æ¹æ³ï¼ä½¿ç¨ long-CoT æå·§ä¾æ¹å short-CoT æ¨¡åï¼ç¢çæåé²ç short-CoT æ¨ççµæââä¾å¦ï¼AIME ä¸­ç 60.8ãMATH500 ä¸­ç 94.6ãLiveCodeBench ä¸­ç 47.3ââå¤§å¹è¶è¶ç¾æç short-CoT æ¨¡åï¼ä¾å¦ GPT-4o å Claude Sonnet 3.5ï¼é«é +550%ï¼ã

##### **FedGrAINS: Personalized SubGraph Federated Learning with Adaptive Neighbor Sampling**
2501.12592v1 by Emir Ceyani, Han Xie, Baturalp Buyukates, Carl Yang, Salman Avestimehr

Graphs are crucial for modeling relational and biological data. As datasets
grow larger in real-world scenarios, the risk of exposing sensitive information
increases, making privacy-preserving training methods like federated learning
(FL) essential to ensure data security and compliance with privacy regulations.
Recently proposed personalized subgraph FL methods have become the de-facto
standard for training personalized Graph Neural Networks (GNNs) in a federated
manner while dealing with the missing links across clients' subgraphs due to
privacy restrictions. However, personalized subgraph FL faces significant
challenges due to the heterogeneity in client subgraphs, such as degree
distributions among the nodes, which complicate federated training of graph
models. To address these challenges, we propose \textit{FedGrAINS}, a novel
data-adaptive and sampling-based regularization method for subgraph FL.
FedGrAINS leverages generative flow networks (GFlowNets) to evaluate node
importance concerning clients' tasks, dynamically adjusting the message-passing
step in clients' GNNs. This adaptation reflects task-optimized sampling aligned
with a trajectory balance objective. Experimental results demonstrate that the
inclusion of \textit{FedGrAINS} as a regularizer consistently improves the FL
performance compared to baselines that do not leverage such regularization.

æè¦ï¼åå½¢å°æ¼éä¿åçç©è³æå»ºæ¨¡è³ééè¦ãé¨èè³æéå¨å¯¦éææ³ä¸­è¶ä¾è¶å¤§ï¼æ´é²ææè³è¨çé¢¨éªä¹é¨ä¹å¢å ï¼éä½¿å¾åè¯åå­¸ç¿ (FL) éæ¨£çé±ç§ä¿è­·è¨ç·´æ¹æ³å°æ¼ç¢ºä¿è³æå®å¨åç¬¦åé±ç§æ³è¦è³ééè¦ãæè¿æåºçåæ§åå­å FL æ¹æ³å·²æçºè¨ç·´åæ§ååå½¢ç¥ç¶ç¶²è·¯ (GNN) çäºå¯¦æ¨æºï¼åæèçç±æ¼é±ç§éå¶èå°è´å®¢æ¶ç«¯å­åä¸­éºå¤±çé£çµãç¶èï¼åæ§åå­å FL ç±æ¼å®¢æ¶ç«¯å­åä¸­çç°è³ªæ§èé¢è¨éå¤§ææ°ï¼ä¾å¦ç¯é»ä¹éçåº¦æ¸åéï¼éä½¿å¾åå½¢æ¨¡åçè¯åè¨ç·´è¤éåãçºäºæå°éäºææ°ï¼æåæåºäº \textit{FedGrAINS}ï¼ä¸ç¨®ç¨æ¼å­å FL çæ°ç©è³æèªé©æååºæ¼æ½æ¨£çæ­£è¦åæ¹æ³ãFedGrAINS å©ç¨çææµç¶²è·¯ (GFlowNets) ä¾è©ä¼°ç¯é»éè¦æ§ï¼æ¶åå®¢æ¶ç«¯ä»»åï¼åæèª¿æ´å®¢æ¶ç«¯ GNN ä¸­çè¨æ¯å³éæ­¥é©ãéç¨®é©æåæ äºèè»è·¡å¹³è¡¡ç®æ¨ä¸è´çä»»åæä½³åæ½æ¨£ãå¯¦é©çµæè¡¨æï¼å° \textit{FedGrAINS} ä½çºæ­£è¦åé ç´å¥ï¼èä¸å©ç¨æ­¤é¡æ­£è¦åçåºæºç·ç¸æ¯ï¼å§çµæ¹å FL æè½ã

##### **Leveraging LLMs to Create a Haptic Devices' Recommendation System**
2501.12573v1 by Yang Liu, Haiwei Dong, Abdulmotaleb El Saddik

Haptic technology has seen significant growth, yet a lack of awareness of
existing haptic device design knowledge hinders development. This paper
addresses these limitations by leveraging advancements in Large Language Models
(LLMs) to develop a haptic agent, focusing specifically on Grounded Force
Feedback (GFF) devices recommendation. Our approach involves automating the
creation of a structured haptic device database using information from research
papers and product specifications. This database enables the recommendation of
relevant GFF devices based on user queries. To ensure precise and contextually
relevant recommendations, the system employs a dynamic retrieval method that
combines both conditional and semantic searches. Benchmarking against the
established UEQ and existing haptic device searching tools, the proposed haptic
recommendation agent ranks in the top 10\% across all UEQ categories with mean
differences favoring the agent in nearly all subscales, and maintains no
significant performance bias across different user groups, showcasing superior
usability and user satisfaction.

æè¦ï¼è§¸è¦ºæè¡å·²é¡¯èæé·ï¼ä½ç¼ºä¹å°ç¾æè§¸è¦ºè£ç½®è¨­è¨ç¥è­çèªè­é»ç¤äºç¼å±ãéç¯è«æééå©ç¨å¤§åèªè¨æ¨¡å (LLM) çé²å±ä¾éç¼è§¸è¦ºä»£çï¼ç¹å¥èéæ¼åºç¤ååé¥ (GFF) è£ç½®å»ºè­°ï¼ä¾è§£æ±ºéäºéå¶ãæåçåæ³åæ¬ä½¿ç¨ç ç©¶è«æåç¢åè¦æ ¼ä¸­çè³è¨ï¼èªåå»ºç«çµæ§åçè§¸è¦ºè£ç½®è³æåº«ãæ­¤è³æåº«è½æ ¹æä½¿ç¨èæ¥è©¢å»ºè­°ç¸éç GFF è£ç½®ãçºäºç¢ºä¿ç²¾ç¢ºä¸ç¬¦åèçµ¡çå»ºè­°ï¼ç³»çµ±æ¡ç¨åææ·åæ¹æ³ï¼çµåæ¢ä»¶å¼åèªææå°ãæ ¹ææ¢å®ç UEQ åç¾æçè§¸è¦ºè£ç½®æå°å·¥å·é²è¡åºæºæ¸¬è©¦ï¼å»ºè­°çè§¸è¦ºæ¨è¦ä»£çå¨ææ UEQ é¡å¥ä¸­æåå¨å 10%ï¼å¹³åå·®ç°æå©æ¼ä»£çå¨å¹¾ä¹ææå­éè¡¨ä¸­ï¼ä¸¦ä¸å¨ä¸åçä½¿ç¨èç¾¤çµä¸­æ²æé¡¯èçæè½åå·®ï¼å±ç¤ºåºåªç°çå¯ç¨æ§åä½¿ç¨èæ»¿æåº¦ã

##### **O1-Pruner: Length-Harmonizing Fine-Tuning for O1-Like Reasoning Pruning**
2501.12570v1 by Haotian Luo, Li Shen, Haiying He, Yibo Wang, Shiwei Liu, Wei Li, Naiqiang Tan, Xiaochun Cao, Dacheng Tao

Recently, long-thought reasoning LLMs, such as OpenAI's O1, adopt extended
reasoning processes similar to how humans ponder over complex problems. This
reasoning paradigm significantly enhances the model's problem-solving abilities
and has achieved promising results. However, long-thought reasoning process
leads to a substantial increase in inference time. A pressing challenge is
reducing the inference overhead of long-thought LLMs while ensuring accuracy.
In this paper, we experimentally demonstrate that long-thought reasoning models
struggle to effectively allocate token budgets based on problem difficulty and
reasoning redundancies. To address this, we propose Length-Harmonizing
Fine-Tuning (O1-Pruner), aiming at minimizing reasoning overhead while
maintaining accuracy. This effective fine-tuning method first estimates the
LLM's baseline performance through pre-sampling and then uses RL-style
fine-tuning to encourage the model to generate shorter reasoning processes
under accuracy constraints. This allows the model to achieve efficient
reasoning with lower redundancy while maintaining accuracy. Experiments on
various mathematical reasoning benchmarks show that O1-Pruner not only
significantly reduces inference overhead but also achieves higher accuracy,
providing a novel and promising solution to this challenge. Our code is coming
soon at https://github.com/StarDewXXX/O1-Pruner

æè¦ï¼æè¿ï¼äººä»¬é¿ææèçæ¨ç LLMï¼ä¾å¦ OpenAI ç O1ï¼éç¨äºç±»ä¼¼äºäººç±»æèå¤æé®é¢çæ©å±æ¨çè¿ç¨ãè¿ç§æ¨çèå¼æ¾èå¢å¼ºäºæ¨¡åçè§£å³é®é¢çè½åï¼å¹¶åå¾äºå¯åçææãç¶èï¼é¿ææèçæ¨çè¿ç¨å¯¼è´æ¨çæ¶é´å¤§å¹å¢å ãä¸ä¸ªç´§è¿«çæææ¯å¨ç¡®ä¿åç¡®æ§çåæ¶åå°é¿ææèç LLM çæ¨çå¼éãå¨æ¬æä¸­ï¼æä»¬éè¿å®éªè¡¨æï¼é¿ææèçæ¨çæ¨¡åé¾ä»¥æ ¹æ®é®é¢é¾åº¦åæ¨çåä½ææåéæ è®°é¢ç®ãä¸ºäºè§£å³è¿ä¸ªé®é¢ï¼æä»¬æåºäºé¿åº¦åè°å¾®è° (O1-Pruner)ï¼æ¨å¨æå¤§ç¨åº¦åå°æ¨çå¼éï¼åæ¶ä¿æåç¡®æ§ãè¿ç§ææçå¾®è°æ¹æ³é¦åéè¿é¢éæ ·æ¥ä¼°è®¡ LLM çåºçº¿æ§è½ï¼ç¶åä½¿ç¨ RL é£æ ¼çå¾®è°æ¥é¼å±æ¨¡åå¨åç¡®æ§çº¦æä¸çææ´ç­çæ¨çè¿ç¨ãè¿åè®¸æ¨¡åå¨ä¿æåç¡®æ§çåæ¶å®ç°é«ææ¨çï¼å¹¶éä½åä½ãå¨åç§æ°å­¦æ¨çåºåä¸çå®éªè¡¨æï¼O1-Pruner ä¸ä»æ¾çéä½äºæ¨çå¼éï¼èä¸è¿å®ç°äºæ´é«çåç¡®æ§ï¼ä¸ºè¿ä¸æææä¾äºä¸ç§æ°é¢ä¸æåéçè§£å³æ¹æ¡ãæä»¬çä»£ç å³å°å¨ https://github.com/StarDewXXX/O1-Pruner ä¸åå¸

##### **Understanding the LLM-ification of CHI: Unpacking the Impact of LLMs at CHI through a Systematic Literature Review**
2501.12557v1 by Rock Yuren Pang, Hope Schroeder, Kynnedy Simone Smith, Solon Barocas, Ziang Xiao, Emily Tseng, Danielle Bragg

Large language models (LLMs) have been positioned to revolutionize HCI, by
reshaping not only the interfaces, design patterns, and sociotechnical systems
that we study, but also the research practices we use. To-date, however, there
has been little understanding of LLMs' uptake in HCI. We address this gap via a
systematic literature review of 153 CHI papers from 2020-24 that engage with
LLMs. We taxonomize: (1) domains where LLMs are applied; (2) roles of LLMs in
HCI projects; (3) contribution types; and (4) acknowledged limitations and
risks. We find LLM work in 10 diverse domains, primarily via empirical and
artifact contributions. Authors use LLMs in five distinct roles, including as
research tools or simulated users. Still, authors often raise validity and
reproducibility concerns, and overwhelmingly study closed models. We outline
opportunities to improve HCI research with and on LLMs, and provide guiding
questions for researchers to consider the validity and appropriateness of
LLM-related work.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²è¢«å®ä½çºé©å½æ§ç HCIï¼ä¸åéå¡æåç ç©¶çä»é¢ãè¨­è¨æ¨¡å¼åç¤¾ææè¡ç³»çµ±ï¼ééå¡æåä½¿ç¨çç ç©¶å¯¦åãç¶èï¼å°ç®åçºæ­¢ï¼å°æ¼ LLM å¨ HCI ä¸­çæ¡ç¨äºè§£çå°ãæåééç³»çµ±æ§å°åé¡§ 2020-24 å¹´é 153 ç¯è LLM ç¸éç CHI è«æï¼ä¾è§£æ±ºéåå·®è·ãæååé¡ï¼(1) æç¨ LLM çé åï¼(2) LLM å¨ HCI å°æ¡ä¸­çè§è²ï¼(3) è²¢ç»é¡åï¼ä»¥å (4) å·²ç¥çéå¶åé¢¨éªãæåç¼ç¾ LLM çå·¥ä½åä½å¨ 10 åä¸åçé åï¼ä¸»è¦æ¯ééå¯¦è­åäººå·¥è£½åçè²¢ç»ãä½èå¨äºåä¸åçè§è²ä¸­ä½¿ç¨ LLMï¼åæ¬ä½çºç ç©¶å·¥å·ææ¨¡æ¬ä½¿ç¨èãåç®¡å¦æ­¤ï¼ä½èç¶å¸¸æåºæææ§åå¯è¤è£½æ§ççæ®ï¼ä¸¦ä¸çµå¤§å¤æ¸ç ç©¶å°éæ¨¡åãæåæ¦è¿°äºå©ç¨ LLM åç ç©¶ LLM ä¾æ¹å HCI ç ç©¶çæ©æï¼ä¸¦æä¾æå°æ§åé¡ï¼ä¾ç ç©¶äººå¡èéè LLM ç¸éå·¥ä½çæææ§åé©åæ§ã

##### **Human-like conceptual representations emerge from language prediction**
2501.12547v1 by Ningyu Xu, Qi Zhang, Chao Du, Qiang Luo, Xipeng Qiu, Xuanjing Huang, Menghan Zhang

Recent advances in large language models (LLMs) provide a new opportunity to
address the long-standing question of how concepts are represented and
organized in the mind, which is central to unravelling the nature of human
cognition. Here, we reframed the classic reverse dictionary task to simulate
human concept inference in context and investigated the emergence of human-like
conceptual representations within LLMs. We found that LLMs were able to infer
concepts from definitional descriptions and construct representation spaces
that converge towards a shared, context-independent structure. These
representations effectively predicted human behavioural judgments and aligned
well with neural activity patterns in the human brain, offering evidence for
biological plausibility. These findings demonstrate that human-like conceptual
representations and organization can naturally emerge from language prediction,
even without real-world grounding. Our work supports the view that LLMs serve
as valuable tools for understanding complex human cognition and paves the way
for better alignment between artificial and human intelligence.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çææ°é²å±çºæåæä¾äºä¸åæ°çæ©æï¼å¯ä»¥è§£æ±ºæ¦å¿µå¦ä½å¨å¿æºä¸­è¢«è¡¨å¾µåçµç¹éåé·ä¹ä»¥ä¾çåé¡ï¼èéå°æ¼è§£éäººé¡èªç¥çæ¬è³ªè³ééè¦ãå¨æ­¤ï¼æåéæ°å»ºæ§äºç¶å¸çéåå­å¸ä»»åï¼ä»¥æ¨¡æ¬äººé¡å¨ç¹å®æå¢ä¸­çæ¦å¿µæ¨è«ï¼ä¸¦æ¢è¨äººé¡é¡ä¼¼æ¦å¿µè¡¨å¾µå¨ LLM ä¸­åºç¾çç¾è±¡ãæåç¼ç¾ LLM è½å¤ å¾å®ç¾©æè¿°ä¸­æ¨è«æ¦å¿µï¼ä¸¦å»ºæ§æ¶ææ¼å±äº«ãèæå¢ç¡éççµæ§çè¡¨å¾µç©ºéãéäºè¡¨å¾µææå°é æ¸¬äºäººé¡çè¡çºå¤æ·ï¼ä¸¦èäººé¡å¤§è¦ä¸­çç¥ç¶æ´»åæ¨¡å¼éå¸¸å»åï¼çºçç©å­¸ä¸çå¯ä¿¡åº¦æä¾äºè­æãéäºç¼ç¾è¡¨æï¼å³ä½¿æ²æçå¯¦ä¸ççä¾æï¼äººé¡é¡ä¼¼çæ¦å¿µè¡¨å¾µåçµç¹ä¹è½èªç¶å°å¾èªè¨é æ¸¬ä¸­æµ®ç¾ãæåçç ç©¶æ¯æ LLM å¯ä½çºçè§£è¤éäººé¡èªç¥çå¯¶è²´å·¥å·çè§é»ï¼ä¸¦çºäººå·¥æºæ§åäººé¡æºæ§ä¹éæ´å¥½çå°é½éªå¹³äºéè·¯ã

##### **Comparative Approaches to Sentiment Analysis Using Datasets in Major European and Arabic Languages**
2501.12540v1 by Mikhail Krasitskii, Olga Kolesnikova, Liliana Chanona Hernandez, Grigori Sidorov, Alexander Gelbukh

This study explores transformer-based models such as BERT, mBERT, and XLM-R
for multi-lingual sentiment analysis across diverse linguistic structures. Key
contributions include the identification of XLM-R superior adaptability in
morphologically complex languages, achieving accuracy levels above 88%. The
work highlights fine-tuning strategies and emphasizes their significance for
improving sentiment classification in underrepresented languages.

æè¦ï¼æ¬ç ç©¶æ¢è¨äº BERTãmBERT å XLM-R ç­åºæ¼è½æå¨çæ¨¡åï¼ç¨æ¼è·¨è¶ä¸åèªè¨çµæ§çå¤èªè¨ææåæãä¸»è¦è²¢ç»åæ¬è­å¥ XLM-R å¨å½¢æè¤éçèªè¨ä¸­å·æåºè²çé©ææ§ï¼éå° 88% ä»¥ä¸çæºç¢ºåº¦ãéé å·¥ä½éé»ä»ç´¹äºå¾®èª¿ç­ç¥ï¼ä¸¦å¼·èª¿äºå®åå°æ¹åä»£è¡¨æ§ä¸è¶³çèªè¨çææåé¡çéè¦æ§ã

##### **Compositional Instruction Following with Language Models and Reinforcement Learning**
2501.12539v1 by Vanya Cohen, Geraud Nangue Tasse, Nakul Gopalan, Steven James, Matthew Gombolay, Ray Mooney, Benjamin Rosman

Combining reinforcement learning with language grounding is challenging as
the agent needs to explore the environment while simultaneously learning
multiple language-conditioned tasks. To address this, we introduce a novel
method: the compositionally-enabled reinforcement learning language agent
(CERLLA). Our method reduces the sample complexity of tasks specified with
language by leveraging compositional policy representations and a semantic
parser trained using reinforcement learning and in-context learning. We
evaluate our approach in an environment requiring function approximation and
demonstrate compositional generalization to novel tasks. Our method
significantly outperforms the previous best non-compositional baseline in terms
of sample complexity on 162 tasks designed to test compositional
generalization. Our model attains a higher success rate and learns in fewer
steps than the non-compositional baseline. It reaches a success rate equal to
an oracle policy's upper-bound performance of 92%. With the same number of
environment steps, the baseline only reaches a success rate of 80%.

æè¦ï¼å°å¼·åå­¸ç¿èèªè¨åºç¤çµåæ¯ä¸é ææ°ï¼å çºä»£çéè¦å¨åæå­¸ç¿å¤é èªè¨æ¢ä»¶åçä»»åææ¢ç´¢ç°å¢ãçºäºè§£æ±ºéååé¡ï¼æåå¼å¥äºä¸ç¨®æ°æ¹æ³ï¼çµæå¼å¢å¼·å­¸ç¿èªè¨ä»£ç (CERLLA)ãæåçåæ³ééå©ç¨çµæå¼æ¿ç­è¡¨ç¤ºåä½¿ç¨å¼·åå­¸ç¿åæå¢å­¸ç¿è¨ç·´çèªæè§£æå¨ï¼æ¸å°äºèªè¨æå®çä»»åçç¯ä¾è¤éæ§ãæåå¨éè¦å½æ¸é¼è¿çç°å¢ä¸­è©ä¼°æåçåæ³ï¼ä¸¦å±ç¤ºäºå°æ°ä»»åççµæå¼æ¦æ¬ãæåçåæ³å¨ 162 é ç¨æ¼æ¸¬è©¦çµæå¼æ¦æ¬çä»»åä¸­ï¼å¨ç¯ä¾è¤éæ§æ¹é¢é¡¯èåªæ¼ååçæä½³éçµæå¼åºæºãæåçæ¨¡åéå°äºæ´é«çæåçï¼ä¸¦ä¸æ¯éçµæå¼åºæºå­¸ç¿çæ­¥é©æ´å°ãå®éå°äºèç¥è«­æ¿ç­ 92% çä¸éæè½ç¸ç­çæåçãå¨ç¸åçç°å¢æ­¥é©æ¸ä¸ï¼åºæºåéå° 80% çæåçã

##### **Academic Case Reports Lack Diversity: Assessing the Presence and Diversity of Sociodemographic and Behavioral Factors related with Post COVID-19 Condition**
2501.12538v1 by Juan Andres Medina Florez, Shaina Raza, Rashida Lynn, Zahra Shakeri, Brendan T. Smith, Elham Dolatabadi

Understanding the prevalence, disparities, and symptom variations of Post
COVID-19 Condition (PCC) for vulnerable populations is crucial to improving
care and addressing intersecting inequities. This study aims to develop a
comprehensive framework for integrating social determinants of health (SDOH)
into PCC research by leveraging NLP techniques to analyze disparities and
variations in SDOH representation within PCC case reports. Following
construction of a PCC Case Report Corpus, comprising over 7,000 case reports
from the LitCOVID repository, a subset of 709 reports were annotated with 26
core SDOH-related entity types using pre-trained named entity recognition (NER)
models, human review, and data augmentation to improve quality, diversity and
representation of entity types. An NLP pipeline integrating NER, natural
language inference (NLI), trigram and frequency analyses was developed to
extract and analyze these entities. Both encoder-only transformer models and
RNN-based models were assessed for the NER objective.
  Fine-tuned encoder-only BERT models outperformed traditional RNN-based models
in generalizability to distinct sentence structures and greater class sparsity.
Exploratory analysis revealed variability in entity richness, with prevalent
entities like condition, age, and access to care, and underrepresentation of
sensitive categories like race and housing status. Trigram analysis highlighted
frequent co-occurrences among entities, including age, gender, and condition.
The NLI objective (entailment and contradiction analysis) showed attributes
like "Experienced violence or abuse" and "Has medical insurance" had high
entailment rates (82.4%-80.3%), while attributes such as "Is
female-identifying," "Is married," and "Has a terminal condition" exhibited
high contradiction rates (70.8%-98.5%).

æè¦ï¼<paragraph>äºè§£å¼±å¢ç¾¤é«çå¾ COVID-19 çæ³ (PCC) çæµè¡çãå·®ç°åççè®åå°æ¼æ¹åç§è­·åè§£æ±ºäº¤åä¸å¹³ç­è³ééè¦ãæ¬ç ç©¶æ¨å¨ééå©ç¨èªç¶èªè¨èçæè¡åæ PCC çä¾å ±åä¸­ SDOH çè¡¨ç¾å·®ç°åè®åï¼éç¼ä¸åæ´åå¥åº·ç¤¾ææ±ºå®å ç´  (SDOH) é²å¥ PCC ç ç©¶çç¶åæ¶æ§ãå¨å»ºæ§ä¸å PCC çä¾å ±åèªæåº«ï¼åå«ä¾èª LitCOVID è³æåº«ç 7,000 å¤åçä¾å ±åï¼å¾ï¼ä½¿ç¨é åè¨ç·´çåç¨±å¯¦é«è¾¨è­ (NER) æ¨¡åãäººå·¥å¯©æ¥åè³ææ´åå° 709 ä»½å ±åé²è¡è¨»è§£ï¼å¶ä¸­åå« 26 åæ ¸å¿ SDOH ç¸éå¯¦é«é¡åï¼ä»¥æé«å¯¦é«é¡åçåè³ªãå¤æ¨£æ§åè¡¨ç¾ãéç¼äºä¸åæ´å NERãèªç¶èªè¨æ¨è« (NLI)ãä¸åçµåé »çåæç NLP ç®¡ç·ï¼ä»¥èåååæéäºå¯¦é«ãéå° NER ç®æ¨è©ä¼°äºåç·¨ç¢¼å¨è½æå¨æ¨¡åååºæ¼ RNN çæ¨¡åãå¾®èª¿å¾çåç·¨ç¢¼å¨ BERT æ¨¡åå¨ä¸è¬åå°ä¸åçå¥å­çµæ§åæ´å¤§çé¡å¥ç¨çæ§æ¹é¢åªæ¼å³çµ±çåºæ¼ RNN çæ¨¡åãæ¢ç´¢æ§åæé¡¯ç¤ºå¯¦é«è±å¯åº¦å­å¨è®ç°æ§ï¼æ®éçå¯¦é«åæ¬çæ³ãå¹´é½¡ååå¾ç§è­·çç®¡éï¼èç¨®æåå±ä½çæ³ç­ææé¡å¥çè¡¨ç¾åä¸è¶³ãä¸åçµåæå¼·èª¿äºå¯¦é«ä¹éçé »ç¹å±ç¾ï¼åæ¬å¹´é½¡ãæ§å¥åçæ³ãNLI ç®æ¨ï¼èæ¶µåçç¾åæï¼é¡¯ç¤ºãç¶æ­·éæ´åæèå¾ãåãæé«çä¿éªãç­å±¬æ§å·æå¾é«çèæ¶µçï¼82.4%-80.3%ï¼ï¼èãèªåèªå·±æ¯å¥³æ§ãããå·²å©ãåãææ«æç¾çãç­å±¬æ§åè¡¨ç¾åºå¾é«ççç¾çï¼70.8%-98.5%ï¼ã</paragraph>

##### **Enhancing Privacy in the Early Detection of Sexual Predators Through Federated Learning and Differential Privacy**
2501.12537v1 by Khaoula Chehbouni, Martine De Cock, Gilles Caporossi, Afaf Taik, Reihaneh Rabbany, Golnoosh Farnadi

The increased screen time and isolation caused by the COVID-19 pandemic have
led to a significant surge in cases of online grooming, which is the use of
strategies by predators to lure children into sexual exploitation. Previous
efforts to detect grooming in industry and academia have involved accessing and
monitoring private conversations through centrally-trained models or sending
private conversations to a global server. In this work, we implement a
privacy-preserving pipeline for the early detection of sexual predators. We
leverage federated learning and differential privacy in order to create safer
online spaces for children while respecting their privacy. We investigate
various privacy-preserving implementations and discuss their benefits and
shortcomings. Our extensive evaluation using real-world data proves that
privacy and utility can coexist with only a slight reduction in utility.

æè¦ï¼ç±æ¼ COVID-19 ç«æå°è´è¢å¹æéå¢å åéé¢ï¼å°è´ç¶²è·¯èªé¨æ¡ä»¶å¤§å¹å¢å ï¼ç¶²è·¯èªé¨æ¯ææ å¥ªèä½¿ç¨ç­ç¥å¼èªåç«¥é²è¡æ§ååãååç¢æ¥­åå­¸è¡çåµæ¸¬èªé¨çä½æ³ï¼åå«éééä¸­è¨ç·´çæ¨¡åå­ååç£æ§ç§äººå°è©±ï¼æå°ç§äººå°è©±å³éè³å¨çä¼ºæå¨ãå¨éé å·¥ä½ä¸­ï¼æåå¯¦ä½ä¸åæ³¨éé±ç§çç®¡éï¼ç¨æ¼æ©æåµæ¸¬æ§æ å¥ªèãæåå©ç¨è¯çå¼å­¸ç¿åå·®åé±ç§ï¼å¨å°éåç«¥é±ç§çåæï¼çºä»åå»ºç«æ´å®å¨çç¶²è·¯ç©ºéãæåèª¿æ¥åç¨®æ³¨éé±ç§çå¯¦ä½ï¼ä¸¦æ¢è¨å¶åªé»åç¼ºé»ãæåä½¿ç¨çå¯¦ä¸çè³æé²è¡å»£æ³è©ä¼°ï¼è­æé±ç§åæç¨å¯ä»¥å±å­ï¼èæç¨åªæç¥å¾®éä½ã

##### **Interaction Dataset of Autonomous Vehicles with Traffic Lights and Signs**
2501.12536v1 by Zheng Li, Zhipeng Bao, Haoming Meng, Haotian Shi, Qianwen Li, Handong Yao, Xiaopeng Li

This paper presents the development of a comprehensive dataset capturing
interactions between Autonomous Vehicles (AVs) and traffic control devices,
specifically traffic lights and stop signs. Derived from the Waymo Motion
dataset, our work addresses a critical gap in the existing literature by
providing real-world trajectory data on how AVs navigate these traffic control
devices. We propose a methodology for identifying and extracting relevant
interaction trajectory data from the Waymo Motion dataset, incorporating over
37,000 instances with traffic lights and 44,000 with stop signs. Our
methodology includes defining rules to identify various interaction types,
extracting trajectory data, and applying a wavelet-based denoising method to
smooth the acceleration and speed profiles and eliminate anomalous values,
thereby enhancing the trajectory quality. Quality assessment metrics indicate
that trajectories obtained in this study have anomaly proportions in
acceleration and jerk profiles reduced to near-zero levels across all
interaction categories. By making this dataset publicly available, we aim to
address the current gap in datasets containing AV interaction behaviors with
traffic lights and signs. Based on the organized and published dataset, we can
gain a more in-depth understanding of AVs' behavior when interacting with
traffic lights and signs. This will facilitate research on AV integration into
existing transportation infrastructures and networks, supporting the
development of more accurate behavioral models and simulation tools.

æè¦ï¼æ¬æä»ç»äºä¸å¥ç»¼åæ°æ®éçå¼åï¼è¯¥æ°æ®éææäºèªå¨é©¾é©¶æ±½è½¦ (AV) ä¸äº¤éæ§å¶è®¾å¤ï¼ç¹å«æ¯äº¤éä¿¡å·ç¯ååè½¦æ å¿ï¼ä¹é´çäº¤äºãæä»¬çå·¥ä½æºèª Waymo Motion æ°æ®éï¼éè¿æä¾æå³èªå¨é©¾é©¶æ±½è½¦å¦ä½å¯¼èªè¿äºäº¤éæ§å¶è®¾å¤ççå®ä¸çè½¨è¿¹æ°æ®ï¼è§£å³äºç°ææç®ä¸­çä¸ä¸ªå³é®ç©ºç½ãæä»¬æåºäºä¸ç§ä» Waymo Motion æ°æ®éä¸­è¯å«åæåç¸å³äº¤äºè½¨è¿¹æ°æ®çæ¹æ³ï¼å¶ä¸­åå«è¶è¿ 37,000 ä¸ªäº¤éä¿¡å·ç¯å®ä¾å 44,000 ä¸ªåè½¦æ å¿å®ä¾ãæä»¬çæ¹æ³åæ¬å®ä¹è§åä»¥è¯å«åç§äº¤äºç±»åãæåè½¨è¿¹æ°æ®ä»¥ååºç¨åºäºå°æ³¢çå»åªæ¹æ³æ¥å¹³æ»å éåº¦åéåº¦æ²çº¿å¹¶æ¶é¤å¼å¸¸å¼ï¼ä»èæé«è½¨è¿¹è´¨éãè´¨éè¯ä¼°ææ è¡¨æï¼æ¬ç ç©¶ä¸­è·å¾çè½¨è¿¹å¨ææäº¤äºç±»å«ä¸­å°å éåº¦åå å éåº¦æ²çº¿ä¸­çå¼å¸¸æ¯ä¾éä½å°æ¥è¿é¶çæ°´å¹³ãéè¿å¬å¼æ­¤æ°æ®éï¼æä»¬æ¨å¨è§£å³å½ååå«èªå¨é©¾é©¶æ±½è½¦ä¸äº¤éä¿¡å·ç¯åæ å¿äº¤äºè¡ä¸ºçæ°æ®éä¸­å­å¨çç©ºç½ãåºäºç»ç»ååå¸çæ°æ®éï¼æä»¬å¯ä»¥æ´æ·±å¥å°äºè§£èªå¨é©¾é©¶æ±½è½¦å¨ä¸äº¤éä¿¡å·ç¯åæ å¿äº¤äºæ¶çè¡ä¸ºãè¿å°ä¿è¿å¯¹èªå¨é©¾é©¶æ±½è½¦éæå°ç°æäº¤éåºç¡è®¾æ½åç½ç»çç ç©¶ï¼æ¯ææ´åç¡®çè¡ä¸ºæ¨¡ååä»¿çå·¥å·çå¼åã

##### **Efficient Lung Ultrasound Severity Scoring Using Dedicated Feature Extractor**
2501.12524v1 by Jiaqi Guo, Yunnan Wu, Evangelos Kaimakamis, Georgios Petmezas, Vasileios E. Papageorgiou, Nicos Maglaveras, Aggelos K. Katsaggelos

With the advent of the COVID-19 pandemic, ultrasound imaging has emerged as a
promising technique for COVID-19 detection, due to its non-invasive nature,
affordability, and portability. In response, researchers have focused on
developing AI-based scoring systems to provide real-time diagnostic support.
However, the limited size and lack of proper annotation in publicly available
ultrasound datasets pose significant challenges for training a robust AI model.
This paper proposes MeDiVLAD, a novel pipeline to address the above issue for
multi-level lung-ultrasound (LUS) severity scoring. In particular, we leverage
self-knowledge distillation to pretrain a vision transformer (ViT) without
label and aggregate frame-level features via dual-level VLAD aggregation. We
show that with minimal finetuning, MeDiVLAD outperforms conventional
fully-supervised methods in both frame- and video-level scoring, while offering
classification reasoning with exceptional quality. This superior performance
enables key applications such as the automatic identification of critical lung
pathology areas and provides a robust solution for broader medical video
classification tasks.

æè¦ï¼é¨è COVID-19 å¤§æµè¡çå°ä¾ï¼è¶é³æ³¢å½±åå·²æçºä¸ç¨®æåéç COVID-19 æª¢æ¸¬æè¡ï¼å çºå®å·æéä¾µå¥æ§ãå¹æ ¼å¯¦æ ä¸å¯æå¸¶ç­ç¹æ§ãæéæ¼æ­¤ï¼ç ç©¶äººå¡å°æ³¨æ¼éç¼åºæ¼ AI çè©åç³»çµ±ï¼ä»¥æä¾å³æçè¨ºæ·æ¯æ´ãç¶èï¼å¬éå¯ç¨çè¶é³æ³¢è³æéè¦æ¨¡æéä¸ç¼ºä¹é©ç¶çè¨»è§£ï¼éå°è¨ç·´ç©©å¥ç AI æ¨¡åæ§æéå¤§ææ°ãæ¬ææåº MeDiVLADï¼éæ¯ä¸ç¨®æ°ç©çç®¡éï¼ç¨æ¼è§£æ±ºä¸è¿°å¤å±¤ç´èºé¨è¶é³æ³¢ (LUS) å´éåº¦è©åçè­°é¡ãå·é«ä¾èªªï¼æåå©ç¨èªæç¥è­è¸é¤¾æè¡ï¼å¨æ²ææ¨ç±¤çææ³ä¸é è¨ç·´è¦è¦ºè½æå¨ (ViT)ï¼ä¸¦éééå±¤ç´ VLAD èåä¾å½ç¸½å¹ç´ç¹å¾µãæåè­æï¼ééæå°çå¾®èª¿ï¼MeDiVLAD å¨å¹ç´åå½±çç´è©åä¸­é½åªæ¼å³çµ±çå¨ç£ç£å¼æ¹æ³ï¼åææä¾åè³ªæ¥µä½³çåé¡æ¨çãéç¨®åªç°çæè½æ¯æ´äºééµæç¨ï¼ä¾å¦èªåè­å¥èºé¨çç¶ååï¼ä¸¦çºæ´å»£æ³çé«å­¸å½±çåé¡ä»»åæä¾ç©©å¥çè§£æ±ºæ¹æ¡ã

##### **An Empirically-grounded tool for Automatic Prompt Linting and Repair: A Case Study on Bias, Vulnerability, and Optimization in Developer Prompts**
2501.12521v1 by Dhia Elhaq Rzig, Dhruba Jyoti Paul, Kaiser Pister, Jordan Henkel, Foyzul Hassan

The tidal wave of advancements in Large Language Models (LLMs) has led to
their swift integration into application-level logic. Many software systems now
use prompts to interact with these black-box models, combining natural language
with dynamic values interpolated at runtime, to perform tasks ranging from
sentiment analysis to question answering. Due to the programmatic and
structured natural language aspects of these prompts, we refer to them as
Developer Prompts. Unlike traditional software artifacts, Dev Prompts blend
natural language instructions with artificial languages such as programming and
markup languages, thus requiring specialized tools for analysis, distinct from
classical software evaluation methods.
  In response to this need, we introduce PromptDoctor, a tool explicitly
designed to detect and correct issues of Dev Prompts. PromptDoctor identifies
and addresses problems related to bias, vulnerability, and sub-optimal
performance in Dev Prompts, helping mitigate their possible harms. In our
analysis of 2,173 Dev Prompts, selected as a representative sample of 40,573
Dev Prompts, we found that 3.46% contained one or more forms of bias, 10.75%
were vulnerable to prompt injection attacks. Additionally, 3,310 were amenable
to automated prompt optimization. To address these issues, we applied
PromptDoctor to the flawed Dev Prompts we discovered. PromptDoctor de-biased
68.29% of the biased Dev Prompts, hardened 41.81% of the vulnerable Dev
Prompts, and improved the performance of 37.1% sub-optimal Dev Prompts.
Finally, we developed a PromptDoctor VSCode extension, enabling developers to
easily enhance Dev Prompts in their existing development workflows. The data
and source code for this work are available at

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çé²å±æµªæ½®å°è´å®åè¿éæ´åå°æç¨ç¨å¼å±¤ç´éè¼¯ä¸­ãè¨±å¤è»é«ç³»çµ±ç¾å¨ä½¿ç¨æç¤ºèéäºé»çæ¨¡åäºåï¼çµåèªç¶èªè¨èå·è¡æå§æçåæå¼ï¼ä»¥å·è¡å¾æç·åæå°åé¡è§£ç­çåç¨®ä»»åãç±æ¼éäºæç¤ºå·æç¨å¼ååçµæ§åçèªç¶èªè¨æ¹é¢ï¼æåå°å®åç¨±çºéç¼äººå¡æç¤ºãèå³çµ±è»é«äººå·¥è£½åä¸åï¼éç¼äººå¡æç¤ºå°èªç¶èªè¨æä»¤èäººå·¥èªè¨ï¼ä¾å¦ç¨å¼è¨­è¨åæ¨è¨èªè¨ï¼æ··åå¨ä¸èµ·ï¼å æ­¤éè¦å°éçåæå·¥å·ï¼ä¸åæ¼å³çµ±çè»é«è©ä¼°æ¹æ³ã
çºäºæ»¿è¶³éåéæ±ï¼æåå¼å¥äº PromptDoctorï¼éæ¯ä¸åå°éè¨­è¨ç¨æ¼åµæ¸¬åä¿®æ­£éç¼äººå¡æç¤ºåé¡çå·¥å·ãPromptDoctor è­å¥ä¸¦è§£æ±ºèéç¼äººå¡æç¤ºä¸­çåå·®ãæ¼æ´åæ¬¡ä½³æè½ç¸éçåé¡ï¼æå©æ¼æ¸è¼å¶å¯è½çå±å®³ãå¨æåå° 2,173 åéç¼äººå¡æç¤ºçåæä¸­ï¼éäºæç¤ºè¢«é¸çº 40,573 åéç¼äººå¡æç¤ºçä»£è¡¨æ§æ¨£æ¬ï¼æåç¼ç¾ 3.46% åå«ä¸ç¨®æå¤ç¨®å½¢å¼çåå·®ï¼10.75% å®¹æåå°æç¤ºæ³¨å¥æ»æãæ­¤å¤ï¼3,310 åæç¤ºå¯ä»¥é²è¡èªååæç¤ºæä½³åãçºäºè§£æ±ºéäºåé¡ï¼æåå° PromptDoctor æç¨æ¼æåç¼ç¾çé¯èª¤éç¼äººå¡æç¤ºãPromptDoctor æ¶é¤äº 68.29% æåå·®çéç¼äººå¡æç¤ºçåå·®ï¼å¼·åäº 41.81% å®¹æåå°æ»æçéç¼äººå¡æç¤ºï¼ä¸¦æ¹åäº 37.1% æ¬¡ä½³éç¼äººå¡æç¤ºçæè½ãæå¾ï¼æåéç¼äºä¸å PromptDoctor VSCode æ´ååè½ï¼è®éç¼äººå¡å¯ä»¥è¼é¬å°å¨ç¾æçéç¼å·¥ä½æµç¨ä¸­å¢å¼·éç¼äººå¡æç¤ºãéé å·¥ä½çè³æååå§ç¢¼å¯å¨

##### **Large-image Object Detection for Fine-grained Recognition of Punches Patterns in Medieval Panel Painting**
2501.12489v1 by Josh Bruegger, Diana Ioana Catana, Vanja Macovaz, Matias Valdenegro-Toro, Matthia Sabatelli, Marco Zullich

The attribution of the author of an art piece is typically a laborious manual
process, usually relying on subjective evaluations of expert figures. However,
there are some situations in which quantitative features of the artwork can
support these evaluations. The extraction of these features can sometimes be
automated, for instance, with the use of Machine Learning (ML) techniques. An
example of these features is represented by repeated, mechanically impressed
patterns, called punches, present chiefly in 13th and 14th-century panel
paintings from Tuscany. Previous research in art history showcased a strong
connection between the shapes of punches and specific artists or workshops,
suggesting the possibility of using these quantitative cues to support the
attribution. In the present work, we first collect a dataset of large-scale
images of these panel paintings. Then, using YOLOv10, a recent and popular
object detection model, we train a ML pipeline to perform object detection on
the punches contained in the images. Due to the large size of the images, the
detection procedure is split across multiple frames by adopting a
sliding-window approach with overlaps, after which the predictions are combined
for the whole image using a custom non-maximal suppression routine. Our results
indicate how art historians working in the field can reliably use our method
for the identification and extraction of punches.

æè¦ï¼èè¡åä½èçæ­¸å±¬éå¸¸æ¯è²»åçæåéç¨ï¼éå¸¸ä¾è³´æ¼å°å®¶äººç©çä¸»è§è©ä¼°ãç¶èï¼æäºææ³ä¸ï¼èè¡åçéåç¹å¾µå¯ä»¥æ¯æéäºè©ä¼°ãéäºç¹å¾µçæåææå¯ä»¥èªååï¼ä¾å¦ï¼ä½¿ç¨æ©å¨å­¸ç¿ (ML) æè¡ãéäºç¹å¾µçä¸åä¾å­æ¯ç±éè¤çãæ©æ¢°å£å°çåæ¡è¡¨ç¤ºï¼ç¨±çºè¡å£ï¼ä¸»è¦å­å¨æ¼ 13 ä¸ç´å 14 ä¸ç´ææ¯å¡ç´çå¹³æ¿ç«ä¸­ãèè¡å²ä¸­çååç ç©¶å±ç¤ºäºè¡å£å½¢çèç¹å®èè¡å®¶æå·¥ä½å®¤ä¹éçå¯åè¯ç¹«ï¼è¡¨æå¯ä»¥ä½¿ç¨éäºéåç·ç´¢ä¾æ¯ææ­¸å±¬ãå¨ç®åçå·¥ä½ä¸­ï¼æåé¦åæ¶éäºéäºå¹³æ¿ç«çå¤§è¦æ¨¡ååæ¸æéãç¶å¾ï¼ä½¿ç¨ YOLOv10ï¼ä¸åæè¿æµè¡çç®æ¨æª¢æ¸¬æ¨¡åï¼æåè¨ç·´äºä¸åæ©å¨å­¸ç¿ç®¡éå°ååä¸­åå«çè¡å£é²è¡ç®æ¨æª¢æ¸¬ãç±æ¼ååå°ºå¯¸è¼å¤§ï¼æ¡ç¨å¸¶æéççæ»åçªå£æ¹æ³å°æª¢æ¸¬éç¨åä½å¨å¤åå¹ä¸­ï¼ç¶å¾ä½¿ç¨èªå®ç¾©éæ¥µå¤§æå¶ä¾ç¨å°é æ¸¬çµåå°æ´åååä¸­ãæåççµæè¡¨æï¼å¨è©²é åå·¥ä½çèè¡å²å­¸å®¶å¯ä»¥å¯é å°ä½¿ç¨æåçæ¹æ³ä¾è­å¥åæåè¡å£ã

##### **The Journey Matters: Average Parameter Count over Pre-training Unifies Sparse and Dense Scaling Laws**
2501.12486v1 by Tian Jin, Ahmed Imtiaz Humayun, Utku Evci, Suvinay Subramanian, Amir Yazdanbakhsh, Dan Alistarh, Gintare Karolina Dziugaite

Pruning eliminates unnecessary parameters in neural networks; it offers a
promising solution to the growing computational demands of large language
models (LLMs). While many focus on post-training pruning, sparse
pre-training--which combines pruning and pre-training into a single
phase--provides a simpler alternative. In this work, we present the first
systematic exploration of optimal sparse pre-training configurations for LLMs
through an examination of 80 unique pruning schedules across different sparsity
levels and training durations. We find that initiating pruning at 25% of total
training compute and concluding at 75% achieves near-optimal final evaluation
loss. These findings provide valuable insights for efficient and effective
sparse pre-training of LLMs. Furthermore, we propose a new scaling law that
modifies the Chinchilla scaling law to use the average parameter count over
pre-training. Through empirical and theoretical validation, we demonstrate that
this modified scaling law accurately models evaluation loss for both sparsely
and densely pre-trained LLMs, unifying scaling laws across pre-training
paradigms. Our findings indicate that while sparse pre-training achieves the
same final model quality as dense pre-training for equivalent compute budgets,
it provides substantial benefits through reduced model size, enabling
significant potential computational savings during inference.

æè¦ï¼ä¿®åªæ¶é¤äºç¥ç¶ç¶²è·¯ä¸­ä¸å¿è¦çåæ¸ï¼å®çºå¤§åèªè¨æ¨¡å (LLM) ä¸æ·å¢é·çéç®éæ±æä¾äºä¸åæåéçè§£æ±ºæ¹æ¡ãéç¶è¨±å¤äººå°æ³¨æ¼è¨ç·´å¾ä¿®åªï¼ä½ç¨çé è¨ç·´ï¼å°ä¿®åªåé è¨ç·´çµåå°ä¸åéæ®µï¼æä¾äºä¸åæ´ç°¡å®çæ¿ä»£æ¹æ¡ãå¨éé å·¥ä½ä¸­ï¼æåééæª¢æ¥ 80 åä¸åçç¨çåº¦ç´å¥åè¨ç·´æçºæéçç¨ç¹ä¿®åªæéè¡¨ï¼å° LLM çæä½³ç¨çé è¨ç·´éç½®é²è¡äºé¦æ¬¡ç³»çµ±æ§æ¢ç´¢ãæåç¼ç¾ï¼å¾ç¸½è¨ç·´éç®ç 25% éå§ä¿®åªä¸¦å¨ 75% çµæï¼å¯ä»¥éå°æ¥è¿æä½³çæçµè©ä¼°æå¤±ãéäºç¼ç¾çº LLM çé«æä¸ææçç¨çé è¨ç·´æä¾äºå¯¶è²´çè¦è§£ãæ­¤å¤ï¼æåæåºäºæ°çç¸®æ¾å®å¾ï¼è©²å®å¾ä¿®æ¹äº Chinchilla ç¸®æ¾å®å¾ï¼ä»¥ä½¿ç¨é è¨ç·´æéçå¹³ååæ¸è¨æ¸ãééç¶é©åçè«é©è­ï¼æåè­æäºéåä¿®æ¹å¾çç¸®æ¾å®å¾å¯ä»¥æºç¢ºå°æ¨¡æ¬ç¨çåå¯éé è¨ç·´ LLM çè©ä¼°æå¤±ï¼çµ±ä¸äºé è¨ç·´ç¯ä¾ä¸­çç¸®æ¾å®å¾ãæåçç¼ç¾è¡¨æï¼éç¶ç¨çé è¨ç·´å¨ç¸åçéç®é ç®ä¸å¯¦ç¾äºèå¯éé è¨ç·´ç¸åçæçµæ¨¡ååè³ªï¼ä½å®ééæ¸å°æ¨¡åå¤§å°æä¾äºé¡¯èçåªé»ï¼å¾èå¯ä»¥å¨æ¨çæéå¯¦ç¾é¡¯èçæ½å¨éç®ç¯çã

##### **fabSAM: A Farmland Boundary Delineation Method Based on the Segment Anything Model**
2501.12487v1 by Yufeng Xie, Hanzhi Wu, Hongxiang Tong, Lei Xiao, Wenwen Zhou, Ling Li, Thomas Cherico Wanger

Delineating farmland boundaries is essential for agricultural management such
as crop monitoring and agricultural census. Traditional methods using remote
sensing imagery have been efficient but limited in generalisation. The Segment
Anything Model (SAM), known for its impressive zero shot performance, has been
adapted for remote sensing tasks through prompt learning and fine tuning. Here,
we propose a SAM based farmland boundary delineation framework 'fabSAM' that
combines a Deeplabv3+ based Prompter and SAM. Also, a fine tuning strategy was
introduced to enable SAMs decoder to improve the use of prompt information.
Experimental results on the AI4Boundaries and AI4SmallFarms datasets have shown
that fabSAM has a significant improvement in farmland region identification and
boundary delineation. Compared to zero shot SAM, fabSAM surpassed it by 23.5%
and 15.1% in mIOU on the AI4Boundaries and AI4SmallFarms datasets,
respectively. For Deeplabv3+, fabSAM outperformed it by 4.9% and 12.5% in mIOU,
respectively. These results highlight the effectiveness of fabSAM, which also
means that we can more easily obtain the global farmland region and boundary
maps from open source satellite image datasets like Sentinel2.

æè¦ï¼åå®è¾²ç°éçå°æ¼è¾²æ¥­ç®¡çï¼ä¾å¦ä½ç©ç£æ§åè¾²æ¥­æ®æ¥ï¼è³ééè¦ãå³çµ±ä½¿ç¨éæ¸¬å½±åçæ¹æ³æçå¾é«ï¼ä½æ®éæ§æéãä»¥å¶ä»¤äººå°è±¡æ·±å»çé¶æ¬¡å­¸ç¿è¡¨ç¾èèåç Segment Anything Model (SAM) å·²ééæç¤ºå­¸ç¿åå¾®èª¿ï¼æ¹ç·¨çºéæ¸¬ä»»åãå¨æ­¤ï¼æåæåºä¸ååºæ¼ SAM çè¾²ç°éçæç¹ªæ¶æ§ãfabSAMãï¼å®çµåäºåºæ¼ Deeplabv3+ çæç¤ºå¨å SAMãæ­¤å¤ï¼éå¼å¥äºä¸ç¨®å¾®èª¿ç­ç¥ï¼è® SAM è§£ç¢¼å¨è½å¤ æ¹åæç¤ºè³è¨çä½¿ç¨ãå¨ AI4Boundaries å AI4SmallFarms è³æéä¸çå¯¦é©çµæé¡¯ç¤ºï¼fabSAM å¨è¾²ç°ååè­å¥åéçæç¹ªæ¹é¢æé¡¯èçé²æ­¥ãèé¶æ¬¡å­¸ç¿ SAM ç¸æ¯ï¼fabSAM å¨ AI4Boundaries å AI4SmallFarms è³æéä¸ç mIOU åå¥è¶è¶äºå® 23.5% å 15.1%ãè Deeplabv3+ ç¸æ¯ï¼fabSAM å¨ mIOU ä¸åå¥è¶è¶äºå® 4.9% å 12.5%ãéäºçµæçªé¡¯äº fabSAM çæææ§ï¼éä¹æå³èæåå¯ä»¥æ´å®¹æå°å¾ Sentinel2 ç­éæºè¡æå½±åè³æéåå¾å¨çè¾²ç°åååéçå°åã

##### **R2D2: Remembering, Reflecting and Dynamic Decision Making for Web Agents**
2501.12485v1 by Tenghao Huang, Kinjal Basu, Ibrahim Abdelaziz, Pavan Kapanipathi, Jonathan May, Muhao Chen

The proliferation of web agents necessitates advanced navigation and
interaction strategies within complex web environments. Current models often
struggle with efficient navigation and action execution due to limited
visibility and understanding of web structures. Our proposed R2D2 framework
addresses these challenges by integrating two paradigms: Remember and Reflect.
The Remember paradigm utilizes a replay buffer that aids agents in
reconstructing the web environment dynamically, thus enabling the formulation
of a detailed ``map'' of previously visited pages. This helps in reducing
navigational errors and optimizing the decision-making process during web
interactions. Conversely, the Reflect paradigm allows agents to learn from past
mistakes by providing a mechanism for error analysis and strategy refinement,
enhancing overall task performance. We evaluate R2D2 using the WEBARENA
benchmark, demonstrating significant improvements over existing methods,
including a 50% reduction in navigation errors and a threefold increase in task
completion rates. Our findings suggest that a combination of memory-enhanced
navigation and reflective learning promisingly advances the capabilities of web
agents, potentially benefiting various applications such as automated customer
service and personal digital assistants.

æè¦ï¼ç¶²è·¯ä»£ççæ¿å¢éè¦å¨è¤éçç¶²è·¯ç°å¢ä¸­é²éçå°èªåäºåç­ç¥ãç±æ¼å°ç¶²è·¯çµæ§çè½è¦åº¦åçè§£æéï¼ç®åçæ¨¡åå¸¸å¸¸å¨ææå°èªååä½å·è¡ä¸éå°å°é£ãæåæåºç R2D2 æ¶æ§ééæ´åãè¨æ¶ãåãåæãå©åç¯ä¾ä¾è§£æ±ºéäºææ°ãè¨æ¶ç¯ä¾å©ç¨éæ­ç·©è¡åï¼åå©ä»£çåæéå»ºç¶²è·¯ç°å¢ï¼é²èå½¢æååé è¨ªé é¢çè©³ç´°ãå°åããéæå©æ¼æ¸å°å°èªé¯èª¤ï¼ä¸¦å¨ç¶²è·¯äºåä¸­æä½³åæ±ºç­å¶å®éç¨ãç¸åå°ï¼åæç¯ä¾åè¨±ä»£çééæä¾é¯èª¤åæåç­ç¥ç²¾é²çæ©å¶ï¼å¾éå»çé¯èª¤ä¸­å­¸ç¿ï¼é²èæåæ´é«ä»»åå·è¡ãæåä½¿ç¨ WEBARENA åºæºè©ä¼° R2D2ï¼å±ç¤ºåºç¸è¼æ¼ç¾ææ¹æ³çé¡¯èæ¹åï¼åæ¬å°èªé¯èª¤æ¸å° 50%ï¼ä»¥åä»»åå®æçå¢å ä¸åãæåçç¼ç¾é¡¯ç¤ºï¼çµåè¨æ¶å¢å¼·å°èªååæå­¸ç¿ï¼æææåç¶²è·¯ä»£ççè½åï¼é²èé ç¦åç¨®æç¨ï¼ä¾å¦èªååå®¢æ¶æåååäººæ¸ä½å©çã

##### **Adaptive PII Mitigation Framework for Large Language Models**
2501.12465v1 by Shubhi Asthana, Ruchi Mahindru, Bing Zhang, Jorge Sanz

Artificial Intelligence (AI) faces growing challenges from evolving data
protection laws and enforcement practices worldwide. Regulations like GDPR and
CCPA impose strict compliance requirements on Machine Learning (ML) models,
especially concerning personal data use. These laws grant individuals rights
such as data correction and deletion, complicating the training and deployment
of Large Language Models (LLMs) that rely on extensive datasets. Public data
availability does not guarantee its lawful use for ML, amplifying these
challenges.
  This paper introduces an adaptive system for mitigating risk of Personally
Identifiable Information (PII) and Sensitive Personal Information (SPI) in
LLMs. It dynamically aligns with diverse regulatory frameworks and integrates
seamlessly into Governance, Risk, and Compliance (GRC) systems. The system uses
advanced NLP techniques, context-aware analysis, and policy-driven masking to
ensure regulatory compliance.
  Benchmarks highlight the system's effectiveness, with an F1 score of 0.95 for
Passport Numbers, outperforming tools like Microsoft Presidio (0.33) and Amazon
Comprehend (0.54). In human evaluations, the system achieved an average user
trust score of 4.6/5, with participants acknowledging its accuracy and
transparency. Observations demonstrate stricter anonymization under GDPR
compared to CCPA, which permits pseudonymization and user opt-outs. These
results validate the system as a scalable and robust solution for enterprise
privacy compliance.

æè¦ï¼äººå·¥æºæ§ (AI) é¢è¨ä¾èªå¨çä¸æ·æ¼é²çè³æä¿è­·æ³è¦åå·æ³å¯¦åçææ°è¶ä¾è¶å¤§ãGDPR å CCPA ç­æ³è¦å°æ©å¨å­¸ç¿ (ML) æ¨¡åå¯¦æ½å´æ ¼çåè¦è¦æ±ï¼ç¹å¥æ¯éæ¼åäººè³æçä½¿ç¨ãéäºæ³è¦è³¦äºåäººè³ææ´æ­£ååªé¤ç­æ¬å©ï¼éä½¿å¾ä¾è³´æ¼å»£æ³è³æéçå¤§åèªè¨æ¨¡å (LLM) çè¨ç·´åé¨ç½²è®å¾è¤éãå¬å±è³æçå¯ç¨æ§ä¸¦ä¸è½ä¿è­å¶å¨ ML ä¸­çåæ³ä½¿ç¨ï¼éæ¾å¤§äºéäºææ°ã
æ¬æä»ç´¹äºä¸åé©ææ§ç³»çµ±ï¼ç¨æ¼éä½å¤§åèªè¨æ¨¡å (LLM) ä¸­åäººå¯è­å¥è³è¨ (PII) åææåäººè³è¨ (SPI) çé¢¨éªãå®åæå°èä¸åçæ³è¦æ¶æ§ä¿æä¸è´ï¼ä¸¦ç¡ç¸«æ´åå°æ²»çãé¢¨éªååè¦ (GRC) ç³»çµ±ä¸­ãè©²ç³»çµ±ä½¿ç¨åé²ç NLP æè¡ãæå¢æç¥åæåç­ç¥é©åçé®ç½©ä¾ç¢ºä¿æ³è¦éµå¾ªã
åºæºæ¸¬è©¦çªé¡¯äºè©²ç³»çµ±çæææ§ï¼è­·ç§èç¢¼ç F1 åæ¸çº 0.95ï¼åªæ¼ Microsoft Presidio (0.33) å Amazon Comprehend (0.54) ç­å·¥å·ãå¨äººé¡è©ä¼°ä¸­ï¼è©²ç³»çµ±ç²å¾äº 4.6/5 çå¹³åä½¿ç¨èä¿¡ä»»åæ¸ï¼åèèè¯å®äºå¶æºç¢ºæ§åéææ§ãè§å¯çµæè¡¨æï¼èåè¨±ååååä½¿ç¨èé¸æéåºç CCPA ç¸æ¯ï¼GDPR ä¸çå¿ååæ´å å´æ ¼ãéäºçµæé©è­äºè©²ç³»çµ±ä½çºä¼æ¥­é±ç§åè¦çå¯æ´å±ä¸ç©©å¥çè§£æ±ºæ¹æ¡ã

##### **Deploying Privacy Guardrails for LLMs: A Comparative Analysis of Real-World Applications**
2501.12456v1 by Shubhi Asthana, Bing Zhang, Ruchi Mahindru, Chad DeLuca, Anna Lisa Gentile, Sandeep Gopisetty

The adoption of Large Language Models (LLMs) has revolutionized AI
applications but poses significant challenges in safeguarding user privacy.
Ensuring compliance with privacy regulations such as GDPR and CCPA while
addressing nuanced privacy risks requires robust and scalable frameworks. This
paper presents a detailed study of OneShield Privacy Guard, a framework
designed to mitigate privacy risks in user inputs and LLM outputs across
enterprise and open-source settings. We analyze two real-world deployments:(1)
a multilingual privacy-preserving system integrated with Data and Model
Factory, focusing on enterprise-scale data governance; and (2) PR Insights, an
open-source repository emphasizing automated triaging and community-driven
refinements. In Deployment 1, OneShield achieved a 0.95 F1 score in detecting
sensitive entities like dates, names, and phone numbers across 26 languages,
outperforming state-of-the-art tool such as StarPII and Presidio by up to 12\%.
Deployment 2, with an average F1 score of 0.86, reduced manual effort by over
300 hours in three months, accurately flagging 8.25\% of 1,256 pull requests
for privacy risks with enhanced context sensitivity. These results demonstrate
OneShield's adaptability and efficacy in diverse environments, offering
actionable insights for context-aware entity recognition, automated compliance,
and ethical AI adoption. This work advances privacy-preserving frameworks,
supporting user trust and compliance across operational contexts.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çæ¡ç¨å¾¹åºæ¹è®äº AI æç¨ï¼ä½å¨ä¿è­·ä½¿ç¨èé±ç§æ¹é¢å»å¸¶ä¾éå¤§ææ°ãå¨è§£æ±ºç´°å¾®çé±ç§é¢¨éªæï¼ç¢ºä¿ç¬¦å GDPR å CCPA ç­é±ç§æ³è¦ï¼éè¦å¼·å¤§ä¸å¯æ´åçæ¶æ§ãæ¬æè©³ç´°æ¢è¨äº OneShield Privacy Guardï¼éæ¯ä¸åæ¨å¨æ¸è¼ä½¿ç¨èè¼¸å¥å LLM è¼¸åºä¸­é±ç§é¢¨éªçæ¶æ§ï¼é©ç¨æ¼ä¼æ¥­åéæºè¨­å®ãæååæäºå©åå¯¦éé¨ç½²ï¼(1) èè³æåæ¨¡åå·¥å» æ´åçå¤èªè¨é±ç§ä¿è­·ç³»çµ±ï¼å°æ³¨æ¼ä¼æ¥­è¦æ¨¡çè³ææ²»çï¼(2) PR Insightsï¼ä¸åå¼·èª¿èªååæµåç¤¾ç¾¤é©åæ¹è¯çéæºå²å­åº«ãå¨é¨ç½² 1 ä¸­ï¼OneShield å¨åµæ¸¬ 26 ç¨®èªè¨ä¸­æ¥æãå§ååé»è©±èç¢¼ç­ææå¯¦é«æï¼éå°äº 0.95 ç F1 åæ¸ï¼åªæ¼ StarPII å Presidio ç­æåé²çå·¥å·ï¼é«åº 12%ãé¨ç½² 2 çå¹³å F1 åæ¸çº 0.86ï¼å¨ä¸åæå§æ¸å°äºè¶é 300 å°æçå¾æå·¥ä½ï¼æºç¢ºå°æ¨è¨äº 1,256 åæäº¤è«æ±ç 8.25%ï¼æåºé±ç§é¢¨éªä¸¦æé«äºæå¢ææåº¦ãéäºçµæè­æäº OneShield å¨ä¸åç°å¢ä¸­çé©ææ§åæææ§ï¼çºæå¢æç¥å¯¦é«è¾¨è­ãèªåååè¦åéå¾· AI æ¡ç¨æä¾äºå¯è¡çè¦è§£ãéé å·¥ä½æ¨åäºé±ç§ä¿è­·æ¶æ§ï¼æ¯æ´ä½¿ç¨èä¿¡ä»»åè·¨ä½æ¥­æå¢çåè¦æ§ã

##### **Learning segmentation from point trajectories**
2501.12392v1 by Laurynas Karazija, Iro Laina, Christian Rupprecht, Andrea Vedaldi

We consider the problem of segmenting objects in videos based on their motion
and no other forms of supervision. Prior work has often approached this problem
by using the principle of common fate, namely the fact that the motion of
points that belong to the same object is strongly correlated. However, most
authors have only considered instantaneous motion from optical flow. In this
work, we present a way to train a segmentation network using long-term point
trajectories as a supervisory signal to complement optical flow. The key
difficulty is that long-term motion, unlike instantaneous motion, is difficult
to model -- any parametric approximation is unlikely to capture complex motion
patterns over long periods of time. We instead draw inspiration from subspace
clustering approaches, proposing a loss function that seeks to group the
trajectories into low-rank matrices where the motion of object points can be
approximately explained as a linear combination of other point tracks. Our
method outperforms the prior art on motion-based segmentation, which shows the
utility of long-term motion and the effectiveness of our formulation.

æè¦ï¼æåèæ®åºæ¼éååæ²æå¶ä»å½¢å¼çç£ç£ä¾åå²å½±çä¸­çç©é«çåé¡ãååçç ç©¶éå¸¸ééä½¿ç¨å±åå½éçåçä¾æ¢è¨éååé¡ï¼ä¹å°±æ¯å±¬æ¼åä¸åç©é«çé»çéåå·æå¼·éè¯æ§ãç¶èï¼å¤§å¤æ¸ä½èåªèæ®äºåæµçç¬æéåãå¨éé å·¥ä½ä¸­ï¼æåæåºä¸åä½¿ç¨é·æé»è»è·¡ä½çºç£ç£è¨èä¾è¨ç·´åå²ç¶²è·¯çæ¹æ³ï¼ä»¥è£ååæµãééµçé£èå¨æ¼ï¼é·æéåä¸åç¬æéåï¼é£ä»¥å»ºæ¨¡ââä»»ä½åæ¸è¿ä¼¼é½ä¸å¤ªå¯è½ææå°é·ææçè¤ééåæ¨¡å¼ãæåæ¹çºå¾å­ç©ºéèé¡æ¹æ³ä¸­æ±²åéæï¼æåºä¸åæå¤±å½æ¸ï¼ç¨æ¼å°è»è·¡åçµæä½ç§©ç©é£ï¼å¶ä¸­ç©é«é»çéåå¯ä»¥è¿ä¼¼è§£éçºå¶ä»é»è»è·¡çç·æ§çµåãæåçæ¨¡åå¨åºæ¼éåçåå²æ¹é¢åªæ¼ååçæè¡ï¼éé¡¯ç¤ºäºé·æéåçæç¨åæåå¬å¼çæææ§ã

##### **Physics of Skill Learning**
2501.12391v1 by Ziming Liu, Yizhou Liu, Eric J. Michaud, Jeff Gore, Max Tegmark

We aim to understand physics of skill learning, i.e., how skills are learned
in neural networks during training. We start by observing the Domino effect,
i.e., skills are learned sequentially, and notably, some skills kick off
learning right after others complete learning, similar to the sequential fall
of domino cards. To understand the Domino effect and relevant behaviors of
skill learning, we take physicists' approach of abstraction and simplification.
We propose three models with varying complexities -- the Geometry model, the
Resource model, and the Domino model, trading between reality and simplicity.
The Domino effect can be reproduced in the Geometry model, whose resource
interpretation inspires the Resource model, which can be further simplified to
the Domino model. These models present different levels of abstraction and
simplification; each is useful to study some aspects of skill learning. The
Geometry model provides interesting insights into neural scaling laws and
optimizers; the Resource model sheds light on the learning dynamics of
compositional tasks; the Domino model reveals the benefits of modularity. These
models are not only conceptually interesting -- e.g., we show how Chinchilla
scaling laws can emerge from the Geometry model, but also are useful in
practice by inspiring algorithmic development -- e.g., we show how simple
algorithmic changes, motivated by these toy models, can speed up the training
of deep learning models.

æè¦ï¼æåæ¨å¨äºè§£æè½å­¸ç¿çç©çå­¸ï¼å³å¨è¨ç·´éç¨ä¸­å¦ä½å­¸ç¿ç¥ç¶ç¶²è·¯ä¸­çæè½ãæåå¾è§å¯å¤ç±³è«¾éª¨çææéå§ï¼å³æè½æ¯æé åºå­¸ç¿çï¼å¼å¾æ³¨æçæ¯ï¼æäºæè½æå¨å¶ä»æè½å®æå­¸ç¿å¾ç«å³éå§å­¸ç¿ï¼é¡ä¼¼æ¼å¤ç±³è«¾éª¨çæé åºåä¸çææ³ãçºäºäºè§£å¤ç±³è«¾éª¨çææåæè½å­¸ç¿ç¸éè¡çºï¼æåæ¡ç¨ç©çå­¸å®¶çæ½è±¡ååç°¡åæ¹æ³ãæåæåºäºä¸ç¨®å·æä¸åè¤éæ§çæ¨¡åââå¹¾ä½æ¨¡åãè³æºæ¨¡ååå¤ç±³è«¾æ¨¡åï¼å¨ç¾å¯¦åç°¡æ½æ§ä¹éé²è¡æ¬è¡¡ãå¤ç±³è«¾éª¨çææå¯ä»¥å¨å¹¾ä½æ¨¡åä¸­éç¾ï¼å¶è³æºè§£éæ¿ç¼äºè³æºæ¨¡åï¼èè³æºæ¨¡åå¯ä»¥é²ä¸æ­¥ç°¡åçºå¤ç±³è«¾æ¨¡åãéäºæ¨¡ååç¾åºä¸åçæ½è±¡ååç°¡åå±¤ç´ï¼æ¯ä¸åé½å¯ç¨æ¼ç ç©¶æè½å­¸ç¿çæäºæ¹é¢ãå¹¾ä½æ¨¡åæä¾äºå°ç¥ç¶ç¶²è·¯æ´åæ³ååæä½³åå¨çæè¶£è¦è§£ï¼è³æºæ¨¡åé¡æäºçµåä»»åçå­¸ç¿åæï¼å¤ç±³è«¾æ¨¡åæ­ç¤ºäºæ¨¡çµåçåªé»ãéäºæ¨¡åä¸åå¨æ¦å¿µä¸å¾æè¶£ââä¾å¦ï¼æåå±ç¤ºäºæ¬½å¥ææ´åæ³åå¦ä½å¾å¹¾ä½æ¨¡åä¸­åºç¾ï¼èä¸å¨å¯¦åä¸ä¹å¾æç¨ï¼å çºå®æ¿ç¼äºæ¼ç®æ³çéç¼ââä¾å¦ï¼æåå±ç¤ºäºåéäºç©å·æ¨¡ååç¼çç°¡å®æ¼ç®æ³è®æ´å¦ä½è½å éæ·±åº¦å­¸ç¿æ¨¡åçè¨ç·´ã

##### **MMVU: Measuring Expert-Level Multi-Discipline Video Understanding**
2501.12380v1 by Yilun Zhao, Lujing Xie, Haowei Zhang, Guo Gan, Yitao Long, Zhiyuan Hu, Tongyan Hu, Weiyuan Chen, Chuhan Li, Junyang Song, Zhijian Xu, Chengye Wang, Weifeng Pan, Ziyao Shangguan, Xiangru Tang, Zhenwen Liang, Yixin Liu, Chen Zhao, Arman Cohan

We introduce MMVU, a comprehensive expert-level, multi-discipline benchmark
for evaluating foundation models in video understanding. MMVU includes 3,000
expert-annotated questions spanning 27 subjects across four core disciplines:
Science, Healthcare, Humanities & Social Sciences, and Engineering. Compared to
prior benchmarks, MMVU features three key advancements. First, it challenges
models to apply domain-specific knowledge and perform expert-level reasoning to
analyze specialized-domain videos, moving beyond the basic visual perception
typically assessed in current video benchmarks. Second, each example is
annotated by human experts from scratch. We implement strict data quality
controls to ensure the high quality of the dataset. Finally, each example is
enriched with expert-annotated reasoning rationals and relevant domain
knowledge, facilitating in-depth analysis. We conduct an extensive evaluation
of 32 frontier multimodal foundation models on MMVU. The latest
System-2-capable models, o1 and Gemini 2.0 Flash Thinking, achieve the highest
performance among the tested models. However, they still fall short of matching
human expertise. Through in-depth error analyses and case studies, we offer
actionable insights for future advancements in expert-level,
knowledge-intensive video understanding for specialized domains.

æè¦ï¼æåä»ç´¹ MMVUï¼ä¸åå¨é¢çå°å®¶ç´ãå¤é ååºæºï¼ç¨æ¼è©ä¼°å½±ççè§£ä¸­çåºç¤æ¨¡åãMMVU åå« 3,000 åå°å®¶è¨»è§£åé¡ï¼æ¶µèååæ ¸å¿é åç 27 åç§ç®ï¼ç§å­¸ãé«çä¿å¥ãäººæèç¤¾æç§å­¸ä»¥åå·¥ç¨ãèååçåºæºç¸æ¯ï¼MMVU å·åä¸å¤§é²å±ãé¦åï¼å®ææ°æ¨¡åæç¨ç¹å®é åçç¥è­ï¼ä¸¦å·è¡å°å®¶ç´æ¨çï¼ä»¥åæç¹å®é åçå½±çï¼è¶è¶ç¶åå½±çåºæºä¸­éå¸¸è©ä¼°çåºæ¬è¦è¦ºæç¥ãå¶æ¬¡ï¼æ¯åç¯ä¾é½æ¯ç±äººé¡å°å®¶å¾é ­éå§è¨»è§£ãæåå¯¦æ½å´æ ¼çè³æåè³ªæ§ç®¡ï¼ä»¥ç¢ºä¿è³æéçé«åè³ªãæå¾ï¼æ¯åç¯ä¾é½è±å¯äºå°å®¶è¨»è§£çæ¨çåçåç¸éé åç¥è­ï¼ä¿é²æ·±å¥åæãæåå° 32 ååæ²¿å¤æ¨¡æåºç¤æ¨¡åé²è¡äºå»£æ³ç MMVU è©ä¼°ãææ°ç System-2 è½åæ¨¡å o1 å Gemini 2.0 Flash Thinking å¨æ¸¬è©¦æ¨¡åä¸­ç²å¾æé«æè½ãç¶èï¼å®åä»ç¶ç¡æ³èäººé¡å°æ¥­ç¥è­ç¸å¹éãééæ·±å¥çé¯èª¤åæåæ¡ä¾ç ç©¶ï¼æåçºç¹å®é åçå°å®¶ç´ãç¥è­å¯éåå½±ççè§£çæªä¾é²å±æä¾äºå¯è¡çè¦è§£ã

##### **Enhancing Retrosynthesis with Conformer: A Template-Free Method**
2501.12434v1 by Jiaxi Zhuang, Qian Zhang, Ying Qian

Retrosynthesis plays a crucial role in the fields of organic synthesis and
drug development, where the goal is to identify suitable reactants that can
yield a target product molecule. Although existing methods have achieved
notable success, they typically overlook the 3D conformational details and
internal spatial organization of molecules. This oversight makes it challenging
to predict reactants that conform to genuine chemical principles, particularly
when dealing with complex molecular structures, such as polycyclic and
heteroaromatic compounds. In response to this challenge, we introduce a novel
transformer-based, template-free approach that incorporates 3D conformer data
and spatial information. Our approach includes an Atom-align Fusion module that
integrates 3D positional data at the input stage, ensuring correct alignment
between atom tokens and their respective 3D coordinates. Additionally, we
propose a Distance-weighted Attention mechanism that refines the self-attention
process, constricting the model s focus to relevant atom pairs in 3D space.
Extensive experiments on the USPTO-50K dataset demonstrate that our model
outperforms previous template-free methods, setting a new benchmark for the
field. A case study further highlights our method s ability to predict
reasonable and accurate reactants.

æè¦ï¼éåæå¨ææºåæåè¯ç©å¼åé¢åä¸­æ®æ¼çè³å³éè¦çè§è²ï¼å¶ç®æ æ¯è¯å«åºè½å¤äº§çç®æ äº§ç©åå­çåéçååºç©ãè½ç¶ç°æçæ¹æ³å·²ç»åå¾äºæ¾èçæåï¼ä½å®ä»¬éå¸¸å¿½ç¥äºåå­ç 3D æè±¡ç»èååé¨ç©ºé´ç»ç»ãè¿ç§çå¿½ä½¿å¾é¢æµç¬¦åçå®åå­¦åççååºç©åå¾å·ææææ§ï¼å°¤å¶æ¯å¨å¤çå¤æåå­ç»æï¼ä¾å¦å¤ç¯åæè³æååç©ï¼æ¶ãä¸ºäºåºå¯¹è¿ä¸ææï¼æä»¬å¼å¥äºä¸ç§æ°é¢çåºäº Transformer çæ æ¨¡æ¿æ¹æ³ï¼è¯¥æ¹æ³ç»åäº 3D æè±¡æ°æ®åç©ºé´ä¿¡æ¯ãæä»¬çæ¹æ³åæ¬ä¸ä¸ªåå­å¯¹é½èåæ¨¡åï¼è¯¥æ¨¡åå¨è¾å¥é¶æ®µéæäº 3D ä½ç½®æ°æ®ï¼ç¡®ä¿åå­æ è®°ä¸å¶åèªç 3D åæ ä¹é´æ­£ç¡®å¯¹é½ãæ­¤å¤ï¼æä»¬æåºäºä¸ç§è·ç¦»å ææ³¨æåæºå¶ï¼è¯¥æºå¶ä¼åäºèªæ³¨æåè¿ç¨ï¼å°æ¨¡åçç¦ç¹éå¶å¨ 3D ç©ºé´ä¸­çç¸å³åå­å¯¹ä¸ãå¨ USPTO-50K æ°æ®éä¸çå¤§éå®éªè¡¨æï¼æä»¬çæ¨¡åä¼äºä»¥å¾çæ æ¨¡æ¿æ¹æ³ï¼ä¸ºè¯¥é¢åæ ç«äºæ°çåºåãæ¡ä¾ç ç©¶è¿ä¸æ­¥çªåºäºæä»¬æ¹æ³é¢æµåçä¸åç¡®çååºç©çè½åã

##### **Video Depth Anything: Consistent Depth Estimation for Super-Long Videos**
2501.12375v2 by Sili Chen, Hengkai Guo, Shengnan Zhu, Feihu Zhang, Zilong Huang, Jiashi Feng, Bingyi Kang

Depth Anything has achieved remarkable success in monocular depth estimation
with strong generalization ability. However, it suffers from temporal
inconsistency in videos, hindering its practical applications. Various methods
have been proposed to alleviate this issue by leveraging video generation
models or introducing priors from optical flow and camera poses. Nonetheless,
these methods are only applicable to short videos (< 10 seconds) and require a
trade-off between quality and computational efficiency. We propose Video Depth
Anything for high-quality, consistent depth estimation in super-long videos
(over several minutes) without sacrificing efficiency. We base our model on
Depth Anything V2 and replace its head with an efficient spatial-temporal head.
We design a straightforward yet effective temporal consistency loss by
constraining the temporal depth gradient, eliminating the need for additional
geometric priors. The model is trained on a joint dataset of video depth and
unlabeled images, similar to Depth Anything V2. Moreover, a novel
key-frame-based strategy is developed for long video inference. Experiments
show that our model can be applied to arbitrarily long videos without
compromising quality, consistency, or generalization ability. Comprehensive
evaluations on multiple video benchmarks demonstrate that our approach sets a
new state-of-the-art in zero-shot video depth estimation. We offer models of
different scales to support a range of scenarios, with our smallest model
capable of real-time performance at 30 FPS.

æè¦ï¼Depth Anything å¨åç®æ·±åº¦ä¼°è®¡ä¸­åå¾äºæ¾èçæåï¼å·æå¾å¼ºçæ³åè½åãç¶èï¼å®å¨è§é¢ä¸­å­å¨æ¶é´ä¸ä¸è´çé®é¢ï¼é»ç¢äºå¶å®éåºç¨ãå·²ç»æåºäºåç§æ¹æ³æ¥éè¿å©ç¨è§é¢çææ¨¡åæå¼å¥åæµåç¸æºä½å§¿åéªæ¥ç¼è§£è¿ä¸ªé®é¢ãå°½ç®¡å¦æ­¤ï¼è¿äºæ¹æ³ä»éç¨äºç­è§é¢ï¼< 10 ç§ï¼ï¼å¹¶ä¸éè¦å¨è´¨éåè®¡ç®æçä¹é´è¿è¡æè¡¡ãæä»¬æåºäºè§é¢æ·±åº¦ Anythingï¼ç¨äºå¨è¶é¿è§é¢ï¼å åéä»¥ä¸ï¼ä¸­è¿è¡é«è´¨éãä¸è´çæ·±åº¦ä¼°è®¡ï¼èä¸ä¼çºç²æçãæä»¬åºäº Depth Anything V2 æå»ºæä»¬çæ¨¡åï¼å¹¶ç¨ä¸ä¸ªé«æçæ¶ç©ºå¤´é¨æ¿æ¢å®çå¤´é¨ãæä»¬éè¿çº¦ææ¶é´æ·±åº¦æ¢¯åº¦è®¾è®¡äºä¸ä¸ªç®åä½ææçæ¶åºä¸è´æ§æå¤±ï¼æ¶é¤äºå¯¹éå å ä½åéªçéæ±ãè¯¥æ¨¡åå¨ä¸ Depth Anything V2 ç±»ä¼¼çè§é¢æ·±åº¦åæªæ è®°å¾åçèåæ°æ®éä¸è¿è¡è®­ç»ãæ­¤å¤ï¼è¿å¼åäºä¸ç§æ°é¢çå³é®å¸§ç­ç¥ç¨äºé¿è§é¢æ¨çãå®éªè¡¨æï¼æä»¬çæ¨¡åå¯ä»¥åºç¨äºä»»æé¿çè§é¢ï¼èä¸ä¼æå®³è´¨éãä¸è´æ§ææ³åè½åãå¯¹å¤ä¸ªè§é¢åºåçç»¼åè¯ä¼°è¡¨æï¼æä»¬çæ¹æ³å¨é¶éå¤´è§é¢æ·±åº¦ä¼°è®¡ä¸­æ ç«äºæ°çæåè¿æ°´å¹³ãæä»¬æä¾ä¸åè§æ¨¡çæ¨¡åæ¥æ¯æåç§åºæ¯ï¼æä»¬æå°çæ¨¡åè½å¤ä»¥ 30 FPS çéåº¦å®æ¶æ§è¡ã

##### **Expertise elevates AI usage: experimental evidence comparing laypeople and professional artists**
2501.12374v1 by Thomas F. Eisenmann, Andres Karjus, Mar Canet Sola, Levin Brinkmann, Bramantyo Ibrahim Supriyatno, Iyad Rahwan

Novel capacities of generative AI to analyze and generate cultural artifacts
raise inevitable questions about the nature and value of artistic education and
human expertise. Has AI already leveled the playing field between professional
artists and laypeople, or do trained artistic expressive capacity, curation
skills and experience instead enhance the ability to use these new tools? In
this pre-registered study, we conduct experimental comparisons between 50
active artists and a demographically matched sample of laypeople. We designed
two tasks to approximate artistic practice for testing their capabilities in
both faithful and creative image creation: replicating a reference image, and
moving as far away as possible from it. We developed a bespoke platform where
participants used a modern text-to-image model to complete both tasks. We also
collected and compared participants' sentiments towards AI. On average, artists
produced more faithful and creative outputs than their lay counterparts,
although only by a small margin. While AI may ease content creation,
professional expertise is still valuable - even within the confined space of
generative AI itself. Finally, we also explored how well an exemplary
vision-capable large language model (GPT-4o) would complete the same tasks, if
given the role of an image generation agent, and found it performed on par in
copying but outperformed even artists in the creative task. The very best
results were still produced by humans in both tasks. These outcomes highlight
the importance of integrating artistic skills with AI training to prepare
artists and other visual professionals for a technologically evolving
landscape. We see a potential in collaborative synergy with generative AI,
which could reshape creative industries and education in the arts.

æè¦ï¼çæå¼ AI åæåçææåè£½åçæ°ç©è½å
å¼ç¼äºéæ¼èè¡æè²çæ§è³ªåå¹å¼ä»¥å
äººé¡å°å®¶ç¥è­çä¸å¯é¿ååé¡ãAI æ¯å¦å·²ç¶æå¹³äºå°æ¥­
èè¡å®¶åå¤è¡ä¹éçç«¶ç­ç°å¢ï¼æèè¨ç·´æç´ çèè¡è¡¨ç¾è½åãç­å±
æå·§åç¶é©åèå¢å¼·äºä½¿ç¨éäºæ°å·¥å·çè½åï¼å¨
éé é åè¨»åçç ç©¶ä¸­ï¼æåå° 50
ä½æ´»èºèè¡å®¶åäººå£çµ±è¨å¹éçå¤è¡æ¨£æ¬é²è¡äºå¯¦é©æ¯è¼ãæåè¨­è¨
äºå©åä»»åä¾è¿ä¼¼èè¡å¯¦è¸ï¼ä»¥æ¸¬è©¦å®åå¨
å¿ å¯¦ååµé æ§åååµä½ä¸­çè½åï¼è¤è£½åèååï¼ä¸¦
ç¡å¯è½é é¢å®ãæåéç¼äºä¸åè¨è£½å¹³å°ï¼è®
åèèä½¿ç¨ç¾ä»£æå­è½ååæ¨¡åä¾å®æéå©åä»»åãæåé
æ¶éä¸¦æ¯è¼äºåèèå° AI çæç·ãå¹³åèè¨ï¼èè¡å®¶
ç¢ççå¿ å¯¦ä¸æåµæçç¢åºå¤æ¼ä»åçéå°æ¥­å°æï¼
åç®¡åªæ¯ä¸åå¾å°çå·®è·ãéç¶ AI å¯è½ç°¡åäºå§å®¹åµä½ï¼
å°æ¥­ç¥è­ä»ç¶æå¹å¼ - å³ä½¿å¨çæå¼ AI æ¬èº«çåéç©ºéå§ä¹æ¯å¦æ­¤ãæå¾ï¼æåéæ¢è¨äºä¸åç¯ä¾
å·æè¦è¦ºè½åçå¤§èªè¨æ¨¡å (GPT-4o) å¨
åç¶ååçæä»£ççææ³ä¸å®æç¸åä»»åçææå¦ä½ï¼ä¸¦ç¼ç¾å®å¨
è¤è£½ä¸­è¡¨ç¾å¾ç¸ç¶åºè²ï¼ä½å¨åµé æ§ä»»åä¸­çè³åªæ¼èè¡å®¶ãææ£ç
çµæä»ç¶æ¯ç±äººé¡å¨å©åä»»åä¸­ç¢ççãéäºçµæå¼·èª¿äºå°èè¡æè½è AI è¨ç·´ç¸çµåä»¥æºå
èè¡å®¶åå¶ä»è¦è¦ºå°æ¥­äººå£«æå°æè¡ç¼å±
æå¢çéè¦æ§ãæåçå°èçæå¼ AI åä½ååçæ½åï¼
éå¯è½æéå¡åµæç¢æ¥­åèè¡æè²ã

##### **Is Long Context All You Need? Leveraging LLM's Extended Context for NL2SQL**
2501.12372v1 by Yeounoh Chung, Gaurav T. Kakkar, Yu Gan, Brenton Milne, Fatma Ozcan

Large Language Models (LLMs) have demonstrated impressive capabilities across
a range of natural language processing tasks. In particular, improvements in
reasoning abilities and the expansion of context windows have opened new
avenues for leveraging these powerful models. NL2SQL is challenging in that the
natural language question is inherently ambiguous, while the SQL generation
requires a precise understanding of complex data schema and semantics. One
approach to this semantic ambiguous problem is to provide more and sufficient
contextual information.
  In this work, we explore the performance and the latency trade-offs of the
extended context window (a.k.a., long context) offered by Google's
state-of-the-art LLM (\textit{gemini-1.5-pro}). We study the impact of various
contextual information, including column example values, question and SQL query
pairs, user-provided hints, SQL documentation, and schema. To the best of our
knowledge, this is the first work to study how the extended context window and
extra contextual information can help NL2SQL generation with respect to both
accuracy and latency cost. We show that long context LLMs are robust and do not
get lost in the extended contextual information. Additionally, our long-context
NL2SQL pipeline based on Google's \textit{gemini-pro-1.5} achieve a strong
performance with 67.41\% on BIRD benchmark (dev) without finetuning and
expensive self-consistency based techniques.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²å¨åç¨®èªç¶èªè¨èçä»»åä¸­å±ç¤ºåºä»¤äººå°è±¡æ·±å»çè½åãç¹å¥æ¯ï¼æ¨çè½åçæååä¸ä¸æè¦çªçæ´å±çºå©ç¨éäºå¼·å¤§çæ¨¡åéé¢äºæ°éå¾ãNL2SQL å·æææ°æ§ï¼å çºèªç¶èªè¨åé¡æ¬è³ªä¸æ¯æ¨¡ç¨å©å¯çï¼è SQL çæéè¦ç²¾ç¢ºçè§£è¤éçæ¸ææ¨¡å¼åèªç¾©ãè§£æ±ºéåèªç¾©æ¨¡ç³åé¡çä¸ç¨®æ¹æ³æ¯æä¾æ´å¤ä¸ååçä¸ä¸æè³è¨ã
å¨éé å·¥ä½ä¸­ï¼æåæ¢è¨äº Google æåé²ç LLM (\textit{gemini-1.5-pro}) æä¾çæ´å±ä¸ä¸æè¦çªï¼åç¨±é·ä¸ä¸æï¼çæè½åå»¶é²æ¬è¡¡ãæåç ç©¶äºåç¨®ä¸ä¸æè³è¨çå½±é¿ï¼åæ¬æ¬ä½ç¯ä¾å¼ãåé¡å SQL æ¥è©¢éå°ãä½¿ç¨èæä¾çæç¤ºãSQL æä»¶åæ¨¡å¼ãææåæç¥ï¼éæ¯ç¬¬ä¸åç ç©¶æ´å±ä¸ä¸æè¦çªåé¡å¤ä¸ä¸æè³è¨å¦ä½è½å¨æºç¢ºæ§åå»¶é²ææ¬æ¹é¢åå© NL2SQL çæçç ç©¶ãæåå±ç¤ºäºé·ä¸ä¸æ LLM æ¯å¼·å¥çï¼ä¸æè¿·å¤±å¨æ´å±çä¸ä¸æè³è¨ä¸­ãæ­¤å¤ï¼æååºæ¼ Google ç \textit{gemini-pro-1.5} çé·ä¸ä¸æ NL2SQL ç®¡ç·å¨ BIRD åºæºæ¸¬è©¦ (dev) ä¸éå°äº 67.41% çå¼·åæè½ï¼èç¡éå¾®èª¿åæè²´çåºæ¼èªæä¸è´æ§çæè¡ã

##### **Parameters vs FLOPs: Scaling Laws for Optimal Sparsity for Mixture-of-Experts Language Models**
2501.12370v1 by Samira Abnar, Harshay Shah, Dan Busbridge, Alaaeldin Mohamed Elnouby Ali, Josh Susskind, Vimal Thilak

Scaling the capacity of language models has consistently proven to be a
reliable approach for improving performance and unlocking new capabilities.
Capacity can be primarily defined by two dimensions: the number of model
parameters and the compute per example. While scaling typically involves
increasing both, the precise interplay between these factors and their combined
contribution to overall capacity remains not fully understood. We explore this
relationship in the context of sparse Mixture-of-Expert models (MoEs), which
allow scaling the number of parameters without proportionally increasing the
FLOPs per example. We investigate how varying the sparsity level, i.e., the
ratio of non-active to total parameters, affects model performance in terms of
both pretraining and downstream performance. We find that under different
constraints (e.g. parameter size and total training compute), there is an
optimal level of sparsity that improves both training efficiency and model
performance. These results provide a better understanding of the impact of
sparsity in scaling laws for MoEs and complement existing works in this area,
offering insights for designing more efficient architectures.

æè¦ï¼æ´å±èªè¨æ¨¡åçå®¹éä¸ç´è¢«è­ææ¯æ¹åæè½ä¸¦è§£éæ°åè½çå¯é æ¹æ³ãå®¹éä¸»è¦å¯ä»¥ç±å©åé¢åå®ç¾©ï¼æ¨¡ååæ¸æ¸éåæ¯åç¯ä¾çéç®ãéç¶æ´å±éå¸¸åå«å¢å å©èï¼ä½éäºå ç´ ä¹éçç²¾ç¢ºäº¤äºä½ç¨åå¶å°æ´é«å®¹éçå±åè²¢ç»ä»æªå®å¨äºè§£ãæåå¨ç¨çæ··åå°å®¶æ¨¡å (MoE) çèæ¯ä¸æ¢è¨éç¨®éä¿ï¼å®åè¨±æ´å±åæ¸æ¸éï¼èä¸æææ¯ä¾å°å¢å æ¯åç¯ä¾ç FLOPãæåç ç©¶æ¹è®ç¨çç¨åº¦ï¼å³éæ´»ååæ¸èç¸½åæ¸çæ¯çï¼å¦ä½å½±é¿æ¨¡åå¨é è¨ç·´åä¸æ¸¸æè½æ¹é¢çæè½ãæåç¼ç¾ï¼å¨ä¸åçéå¶æ¢ä»¶ï¼ä¾å¦åæ¸å¤§å°åç¸½è¨ç·´éç®ï¼ä¸ï¼å­å¨æä½³ç¨çç¨åº¦ï¼å¯åææ¹åè¨ç·´æçåæ¨¡åæè½ãéäºçµæè®æåå°ç¨çæ§å¨ MoE çæ´å±å®å¾ä¸­çå½±é¿ææ´å¥½çäºè§£ï¼ä¸¦è£åäºéæ¹é¢çç¾æå·¥ä½ï¼æä¾äºè¨­è¨æ´ææççæ¶æ§çè¦è§£ã

##### **InternLM-XComposer2.5-Reward: A Simple Yet Effective Multi-Modal Reward Model**
2501.12368v1 by Yuhang Zang, Xiaoyi Dong, Pan Zhang, Yuhang Cao, Ziyu Liu, Shengyuan Ding, Shenxi Wu, Yubo Ma, Haodong Duan, Wenwei Zhang, Kai Chen, Dahua Lin, Jiaqi Wang

Despite the promising performance of Large Vision Language Models (LVLMs) in
visual understanding, they occasionally generate incorrect outputs. While
reward models (RMs) with reinforcement learning or test-time scaling offer the
potential for improving generation quality, a critical gap remains: publicly
available multi-modal RMs for LVLMs are scarce, and the implementation details
of proprietary models are often unclear. We bridge this gap with
InternLM-XComposer2.5-Reward (IXC-2.5-Reward), a simple yet effective
multi-modal reward model that aligns LVLMs with human preferences. To ensure
the robustness and versatility of IXC-2.5-Reward, we set up a high-quality
multi-modal preference corpus spanning text, image, and video inputs across
diverse domains, such as instruction following, general understanding,
text-rich documents, mathematical reasoning, and video understanding.
IXC-2.5-Reward achieves excellent results on the latest multi-modal reward
model benchmark and shows competitive performance on text-only reward model
benchmarks. We further demonstrate three key applications of IXC-2.5-Reward:
(1) Providing a supervisory signal for RL training. We integrate IXC-2.5-Reward
with Proximal Policy Optimization (PPO) yields IXC-2.5-Chat, which shows
consistent improvements in instruction following and multi-modal open-ended
dialogue; (2) Selecting the best response from candidate responses for
test-time scaling; and (3) Filtering outlier or noisy samples from existing
image and video instruction tuning training data. To ensure reproducibility and
facilitate further research, we have open-sourced all model weights and
training recipes at https://github.com/InternLM/InternLM-XComposer

æè¦ï¼åç®¡å¤§åè¦è¦ºèªè¨æ¨¡å (LVLMs) å¨è¦è¦ºçè§£æ¹é¢è¡¨ç¾åºè²ï¼ä½å®åå¶ç¾æç¢çä¸æ­£ç¢ºçè¼¸åºãéç¶å·æå¼·åå­¸ç¿ææ¸¬è©¦æç¸®æ¾çåé¥æ¨¡å (RMs) æä¾äºæé«çæåè³ªçå¯è½æ§ï¼ä½ä»å­å¨ä¸åééµå·®è·ï¼å¬éçå¤æ¨¡æ LVLMs RMs å¾å°ï¼èä¸å°ææ¨¡åçå¯¦ä½ç´°ç¯å¾å¾ä¸æ¸æ¥ãæåä»¥ InternLM-XComposer2.5-Reward (IXC-2.5-Reward) ä¾å½è£éåå·®è·ï¼éæ¯ä¸åç°¡å®ä½ææçå¤æ¨¡æåé¥æ¨¡åï¼å®å° LVLMs èäººé¡åå¥½ä¿æä¸è´ãçºäºç¢ºä¿ IXC-2.5-Reward çç©©å¥æ§åå¤åè½æ§ï¼æåå»ºç«äºä¸åè·¨è¶ä¸åé åï¼ä¾å¦æä»¤éµå¾ªãä¸è¬çè§£ãæå­è±å¯çæä»¶ãæ¸å­¸æ¨çåå½±ççè§£ï¼çé«åè³ªå¤æ¨¡æåå¥½èªæåº«ï¼å¶ä¸­åå«æå­ãå½±ååå½±çè¼¸å¥ãIXC-2.5-Reward å¨ææ°çå¤æ¨¡æåé¥æ¨¡ååºæºæ¸¬è©¦ä¸­åå¾äºåªç°çææï¼ä¸¦å¨ç´æå­åé¥æ¨¡ååºæºæ¸¬è©¦ä¸­å±ç¾äºç«¶ç­åãæåé²ä¸æ­¥å±ç¤ºäº IXC-2.5-Reward çä¸åééµæç¨ï¼(1) æä¾ RL è¨ç·´çç£ç£è¨èãæåå° IXC-2.5-Reward èè¿ç«¯ç­ç¥æä½³å (PPO) æ´åï¼ç¢ç IXC-2.5-Chatï¼å¨æä»¤éµå¾ªåå¤æ¨¡æéæ¾å¼å°è©±æ¹é¢æçºæ¹åï¼(2) å¾åé¸åæä¸­é¸åºæä½³åæï¼ä»¥é²è¡æ¸¬è©¦æç¸®æ¾ï¼(3) å¾ç¾æçå½±ååå½±çæå­¸èª¿æ´è¨ç·´è³æä¸­éæ¿¾ç°å¸¸å¼æéè¨æ¨£æ¬ãçºäºç¢ºä¿å¯è¤è£½æ§ä¸¦ä¿é²é²ä¸æ­¥ç ç©¶ï¼æåå·²å¨ https://github.com/InternLM/InternLM-XComposer éæ¾åå§ç¢¼çæææ¨¡åæ¬éåè¨ç·´éæ¹

##### **Owls are wise and foxes are unfaithful: Uncovering animal stereotypes in vision-language models**
2501.12433v1 by Tabinda Aman, Mohammad Nadeem, Shahab Saquib Sohail, Mohammad Anas, Erik Cambria

Animal stereotypes are deeply embedded in human culture and language. They
often shape our perceptions and expectations of various species. Our study
investigates how animal stereotypes manifest in vision-language models during
the task of image generation. Through targeted prompts, we explore whether
DALL-E perpetuates stereotypical representations of animals, such as "owls as
wise," "foxes as unfaithful," etc. Our findings reveal significant stereotyped
instances where the model consistently generates images aligned with cultural
biases. The current work is the first of its kind to examine animal
stereotyping in vision-language models systematically and to highlight a
critical yet underexplored dimension of bias in AI-generated visual content.

æè¦ï¼åç©å»æ¿å°è±¡æ·±æ·±æ¤æ ¹æ¼äººé¡æååèªè¨ä¸­ãå®å
éå¸¸å¡é æåå°åç¨®ç©ç¨®ççæ³åææãæåçç ç©¶
æ¢è¨äºå¨å½±åçæä»»åä¸­ï¼åç©å»æ¿å°è±¡å¦ä½å¨è¦è¦ºèªè¨æ¨¡åä¸­é¡¯ç¾ãééæéå°æ§çæç¤ºï¼æåæ¢è¨
DALL-E æ¯å¦å»¶çºäºåç©çå»æ¿å°è±¡ï¼ä¾å¦ãè²é ­é·¹æ¯ææºçãããçç¸æ¯ä¸å¿ èª çãç­ãæåçç¼ç¾æ­ç¤ºäºé¡¯èçå»æ¿å°è±¡ï¼å¶ä¸­è©²æ¨¡åå§çµçæèæå
åè¦ä¸è´çå½±åãç®åçç ç©¶æ¯åé¡åç ç©¶ä¸­ç¬¬ä¸åç³»çµ±æ§å°æª¢è¦è¦è¦ºèªè¨æ¨¡åä¸­çåç©å»æ¿å°è±¡ï¼ä¸¦å¼·èª¿ AI çæçè¦è¦ºå§å®¹ä¸­ä¸åééµä½æªååæ¢è¨çåè¦é¢åã

##### **Test-time regression: a unifying framework for designing sequence models with associative memory**
2501.12352v1 by Ke Alexander Wang, Jiaxin Shi, Emily B. Fox

Sequences provide a remarkably general way to represent and process
information. This powerful abstraction has placed sequence modeling at the
center of modern deep learning applications, inspiring numerous architectures
from transformers to recurrent networks. While this fragmented development has
yielded powerful models, it has left us without a unified framework to
understand their fundamental similarities and explain their effectiveness. We
present a unifying framework motivated by an empirical observation: effective
sequence models must be able to perform associative recall. Our key insight is
that memorizing input tokens through an associative memory is equivalent to
performing regression at test-time. This regression-memory correspondence
provides a framework for deriving sequence models that can perform associative
recall, offering a systematic lens to understand seemingly ad-hoc architectural
choices. We show numerous recent architectures -- including linear attention
models, their gated variants, state-space models, online learners, and softmax
attention -- emerge naturally as specific approaches to test-time regression.
Each architecture corresponds to three design choices: the relative importance
of each association, the regressor function class, and the optimization
algorithm. This connection leads to new understanding: we provide theoretical
justification for QKNorm in softmax attention, and we motivate higher-order
generalizations of softmax attention. Beyond unification, our work unlocks
decades of rich statistical tools that can guide future development of more
powerful yet principled sequence models.

æè¦ï¼åºåæä¾äºä¸åéå¸¸éç¨çæ¹å¼ä¾è¡¨ç¤ºåèçè³è¨ãéç¨®å¼·å¤§çæ½è±¡åå·²å°åºåæ¨¡åç½®æ¼ç¾ä»£æ·±åº¦å­¸ç¿æç¨ç¨å¼çæ ¸å¿ï¼å¾Transformerå°éè¿´ç¶²è·¯æ¿ç¼äºè¨±å¤æ¶æ§ãéç¶éç¨®åæ£çç¼å±ç¢çäºå¼·å¤§çæ¨¡åï¼ä½å®è®æåæ²æçµ±ä¸çæ¶æ§ä¾çè§£å®åçåºæ¬ç¸ä¼¼æ§ä¸¦è§£éå®åçæææ§ãæåæåºäºä¸åç±ç¶é©è§å¯æ¿åµççµ±ä¸æ¶æ§ï¼ææçåºåæ¨¡åå¿é è½å¤ å·è¡éè¯å¼åæ¶ãæåçééµè¦è§£æ¯ï¼ééè¯æ³è¨æ¶é«è¨æ¶è¼¸å¥ä»£å¹£ç­åæ¼å¨æ¸¬è©¦æå·è¡è¿´æ­¸ãéç¨®è¿´æ­¸è¨æ¶å°ææä¾äºä¸åæ¡æ¶ï¼ç¨æ¼æ¨å°å¯ä»¥å·è¡éè¯å¼åæ¶çåºåæ¨¡åï¼æä¾äºä¸åç³»çµ±çéé¡ä¾çè§£çä¼¼è¨æçæ¶æ§é¸æãæåå±ç¤ºäºè¨±å¤æè¿çæ¶æ§ââåæ¬ç·æ§æ³¨æåæ¨¡åãå®åçéæ§è®é«ãçæç©ºéæ¨¡åãç·ä¸å­¸ç¿å¨å softmax æ³¨æåââèªç¶èç¶å°åºç¾ä½çºæ¸¬è©¦æéè¿´æ­¸çå·é«æ¹æ³ãæ¯åæ¶æ§é½å°ææ¼ä¸åè¨­è¨é¸æï¼æ¯åéè¯çç¸å°éè¦æ§ãåæ­¸å½æ¸é¡åæä½³åæ¼ç®æ³ãéç¨®è¯ç¹«å°è´äºæ°ççè§£ï¼æåçº softmax æ³¨æåä¸­ç QKNorm æä¾äºçè«ä¾æï¼ä¸¦ä¸æåæ¿åµäº softmax æ³¨æåçé«éæ¦æ¬ãé¤äºçµ±ä¸ä¹å¤ï¼æåçç ç©¶éè§£éäºæ¸åå¹´çè±å¯çµ±è¨å·¥å·ï¼éäºå·¥å·å¯ä»¥æå°æ´å¼·å¤§ä½æååçåºåæ¨¡åçæªä¾ç¼å±ã

##### **Treefix: Enabling Execution with a Tree of Prefixes**
2501.12339v1 by Beatriz Souza, Michael Pradel

The ability to execute code is a prerequisite for various dynamic program
analyses. Learning-guided execution has been proposed as an approach to enable
the execution of arbitrary code snippets by letting a neural model predict
likely values for any missing variables. Although state-of-the-art
learning-guided execution approaches, such as LExecutor, can enable the
execution of a relative high amount of code, they are limited to predicting a
restricted set of possible values and do not use any feedback from previous
executions to execute even more code. This paper presents Treefix, a novel
learning-guided execution approach that leverages LLMs to iteratively create
code prefixes that enable the execution of a given code snippet. The approach
addresses the problem in a multi-step fashion, where each step uses feedback
about the code snippet and its execution to instruct an LLM to improve a
previously generated prefix. This process iteratively creates a tree of
prefixes, a subset of which is returned to the user as prefixes that maximize
the number of executed lines in the code snippet. In our experiments with two
datasets of Python code snippets, Treefix achieves 25% and 7% more coverage
relative to the current state of the art in learning-guided execution, covering
a total of 84% and 82% of all lines in the code snippets.

æè¦ï¼å·è¡ç¨å¼ç¢¼çè½åæ¯åç¨®åæç¨å¼åæçåæãå­¸ç¿å°åå·è¡å·²è¢«æè­°çºä¸ç¨®æ¹æ³ï¼è®ç¥ç¶æ¨¡åé æ¸¬ä»»ä½éºå¤±è®æ¸çå¯è½å¼ï¼å¾èè½å¤ å·è¡ä»»æç¨å¼ç¢¼çæ®µãåç®¡æåé²çå­¸ç¿å°åå·è¡æ¹æ³ï¼ä¾å¦ LExecutorï¼å¯ä»¥å·è¡ç¸å°å¤§éçç¨å¼ç¢¼ï¼ä½å®ååéæ¼é æ¸¬ä¸çµå¯è½çåéå¼ï¼ä¸¦ä¸ä¸ä½¿ç¨ååå·è¡çä»»ä½åé¥ä¾å·è¡æ´å¤ç¨å¼ç¢¼ãæ¬ææåº Treefixï¼éæ¯ä¸ç¨®æ°ç©çå­¸ç¿å°åå·è¡æ¹æ³ï¼å®å©ç¨ LLM è¿­ä»£å»ºç«ç¨å¼ç¢¼åç¶´ï¼ä»¥å·è¡çµ¦å®çç¨å¼ç¢¼çæ®µãè©²æ¹æ³ä»¥å¤æ­¥é©æ¹å¼è§£æ±ºåé¡ï¼å¶ä¸­æ¯ä¸æ­¥é½ä½¿ç¨éæ¼ç¨å¼ç¢¼çæ®µåå¶å·è¡çåé¥ï¼ä¾æå° LLM æ¹é²ååçæçå­é¦ãæ­¤éç¨åè¦å»ºç«ä¸ååç¶´æ¨¹ï¼å¶ä¸­çä¸é¨åä½çºåç¶´åå³çµ¦ä½¿ç¨èï¼ä»¥æå¤§åç¨å¼ç¢¼çæ®µä¸­å·è¡è¡çæ¸éãå¨æåä½¿ç¨å©å Python ç¨å¼ç¢¼çæ®µè³æéé²è¡çå¯¦é©ä¸­ï¼Treefix å¨å­¸ç¿å°åå·è¡ä¸­åå¾äºæ¯ç®åæåé²çæè¡é«åº 25% å 7% çè¦èçï¼ç¸½å±æ¶µèäºç¨å¼ç¢¼çæ®µä¸­ææè¡ç 84% å 82%ã

##### **FuocChuVIP123 at CoMeDi Shared Task: Disagreement Ranking with XLM-Roberta Sentence Embeddings and Deep Neural Regression**
2501.12336v1 by Phuoc Duong Huy Chu

This paper presents results of our system for CoMeDi Shared Task, focusing on
Subtask 2: Disagreement Ranking. Our system leverages sentence embeddings
generated by the paraphrase-xlm-r-multilingual-v1 model, combined with a deep
neural regression model incorporating batch normalization and dropout for
improved generalization. By predicting the mean of pairwise judgment
differences between annotators, our method explicitly targets disagreement
ranking, diverging from traditional "gold label" aggregation approaches. We
optimized our system with a customized architecture and training procedure,
achieving competitive performance in Spearman correlation against mean
disagreement labels. Our results highlight the importance of robust embeddings,
effective model architecture, and careful handling of judgment differences for
ranking disagreement in multilingual contexts. These findings provide insights
into the use of contextualized representations for ordinal judgment tasks and
open avenues for further refinement of disagreement prediction models.

æè¦ï¼æ¬æå±ç¤ºäºæåå¨ CoMeDi å±äº«ä»»åç³»çµ±ä¸­ççµæï¼éé»å¨
å­ä»»å 2ï¼åæ­§æåãæåçç³»çµ±å©ç¨ paraphrase-xlm-r-multilingual-v1 æ¨¡åç¢ççå¥å­åµå¥ï¼çµåæ·±åº¦
ç¥ç¶è¿´æ­¸æ¨¡åï¼ä¸¦å å¥æ¹æ¬¡æ­£è¦ååä¸­æ·ä»¥æ¹åæ¦åãééé æ¸¬è¨»è§£èä¹éæå°å¤æ·å·®ç°çå¹³åå¼ï¼æåç
æ¹æ³æç¢ºéå°åæ­§æåï¼åé¢å³çµ±çãé»éæ¨ç±¤ãèåæ¹æ³ãæåä½¿ç¨èªè¨æ¶æ§åè¨ç·´ç¨åºåªåç³»çµ±ï¼
å¨èå¹³ååæ­§æ¨ç±¤ç Spearman ç¸éæ§ä¸­ç²å¾ç«¶ç­åè¡¨ç¾ãæåççµæå¼·èª¿äºç©©å¥åµå¥ãæææ¨¡åæ¶æ§å
è¬¹æèçå¤æ·å·®ç°å°æ¼å¨å¤èªè¨ç°å¢ä¸­å°åæ­§é²è¡æåçéè¦æ§ãéäºç¼ç¾æä¾äºä½¿ç¨æå¢åè¡¨å¾µé²è¡åºæ¸å¤æ·ä»»åçè¦è§£ï¼ä¸¦çºé²ä¸æ­¥åªååæ­§é æ¸¬æ¨¡åéé¢äºéè·¯ã

##### **Automatic Labelling with Open-source LLMs using Dynamic Label Schema Integration**
2501.12332v1 by Thomas Walshe, Sae Young Moon, Chunyang Xiao, Yawwani Gunawardana, Fran Silavong

Acquiring labelled training data remains a costly task in real world machine
learning projects to meet quantity and quality requirements. Recently Large
Language Models (LLMs), notably GPT-4, have shown great promises in labelling
data with high accuracy. However, privacy and cost concerns prevent the
ubiquitous use of GPT-4. In this work, we explore effectively leveraging
open-source models for automatic labelling. We identify integrating label
schema as a promising technology but found that naively using the label
description for classification leads to poor performance on high cardinality
tasks. To address this, we propose Retrieval Augmented Classification (RAC) for
which LLM performs inferences for one label at a time using corresponding label
schema; we start with the most related label and iterates until a label is
chosen by the LLM. We show that our method, which dynamically integrates label
description, leads to performance improvements in labelling tasks. We further
show that by focusing only on the most promising labels, RAC can trade off
between label quality and coverage - a property we leverage to automatically
label our internal datasets.

æè¦ï¼å¨å¯¦éæ©å¨å­¸ç¿å°æ¡ä¸­ï¼åå¾æ¨ç±¤è¨ç·´è³æä»ç¶æ¯ä¸é ææ¬é«æçä»»åï¼ä»¥æ»¿è¶³æ¸éååè³ªéæ±ãæè¿ï¼å¤§åèªè¨æ¨¡å (LLM)ï¼å°¤å¶æ¯ GPT-4ï¼å¨æ¨ç±¤è³æä¸å±ç¾åºé«ç²¾æºåº¦çåªç°è¡¨ç¾ãç¶èï¼é±ç§åææ¬èéé»ç¤äº GPT-4 çå»£æ³ä½¿ç¨ãå¨éé å·¥ä½ä¸­ï¼æåæ¢è¨å¦ä½ææå©ç¨éæºæ¨¡åé²è¡èªåæ¨ç±¤ãæåç¼ç¾æ´åæ¨ç±¤æ¶æ§æ¯ä¸é æåéçæè¡ï¼ä½ç¼ç¾å¤©çå°ä½¿ç¨æ¨ç±¤èªªæé²è¡åé¡æå°è´é«åºæ¸ä»»åçæè½ä¸ä½³ãçºäºè§£æ±ºéååé¡ï¼æåæåºäºæª¢ç´¢å¢å¼·åé¡ (RAC)ï¼å¶ä¸­ LLM ä½¿ç¨å°æçæ¨ç±¤æ¶æ§ä¸æ¬¡å°ä¸åæ¨ç±¤å·è¡æ¨è«ï¼æåå¾æç¸éçæ¨ç±¤éå§ï¼ä¸¦åè¦éç®ï¼ç´å° LLM é¸æä¸åæ¨ç±¤ãæåå±ç¤ºäºæåçæ¹æ³ï¼åææ´åæ¨ç±¤èªªæï¼ææåæ¨ç±¤ä»»åçæè½ãæåé²ä¸æ­¥å±ç¤ºï¼ééåå°æ³¨æ¼ææå¸æçæ¨ç±¤ï¼RAC å¯ä»¥æ¬è¡¡æ¨ç±¤åè³ªåæ¶µèç¯åï¼æåå©ç¨éé ç¹æ§èªåæ¨ç±¤æåçå§é¨è³æéã

##### **UI-TARS: Pioneering Automated GUI Interaction with Native Agents**
2501.12326v1 by Yujia Qin, Yining Ye, Junjie Fang, Haoming Wang, Shihao Liang, Shizuo Tian, Junda Zhang, Jiahao Li, Yunxin Li, Shijue Huang, Wanjun Zhong, Kuanye Li, Jiale Yang, Yu Miao, Woyu Lin, Longxiang Liu, Xu Jiang, Qianli Ma, Jingyu Li, Xiaojun Xiao, Kai Cai, Chuang Li, Yaowei Zheng, Chaolin Jin, Chen Li, Xiao Zhou, Minchao Wang, Haoli Chen, Zhaojian Li, Haihua Yang, Haifeng Liu, Feng Lin, Tao Peng, Xin Liu, Guang Shi

This paper introduces UI-TARS, a native GUI agent model that solely perceives
the screenshots as input and performs human-like interactions (e.g., keyboard
and mouse operations). Unlike prevailing agent frameworks that depend on
heavily wrapped commercial models (e.g., GPT-4o) with expert-crafted prompts
and workflows, UI-TARS is an end-to-end model that outperforms these
sophisticated frameworks. Experiments demonstrate its superior performance:
UI-TARS achieves SOTA performance in 10+ GUI agent benchmarks evaluating
perception, grounding, and GUI task execution. Notably, in the OSWorld
benchmark, UI-TARS achieves scores of 24.6 with 50 steps and 22.7 with 15
steps, outperforming Claude (22.0 and 14.9 respectively). In AndroidWorld,
UI-TARS achieves 46.6, surpassing GPT-4o (34.5). UI-TARS incorporates several
key innovations: (1) Enhanced Perception: leveraging a large-scale dataset of
GUI screenshots for context-aware understanding of UI elements and precise
captioning; (2) Unified Action Modeling, which standardizes actions into a
unified space across platforms and achieves precise grounding and interaction
through large-scale action traces; (3) System-2 Reasoning, which incorporates
deliberate reasoning into multi-step decision making, involving multiple
reasoning patterns such as task decomposition, reflection thinking, milestone
recognition, etc. (4) Iterative Training with Reflective Online Traces, which
addresses the data bottleneck by automatically collecting, filtering, and
reflectively refining new interaction traces on hundreds of virtual machines.
Through iterative training and reflection tuning, UI-TARS continuously learns
from its mistakes and adapts to unforeseen situations with minimal human
intervention. We also analyze the evolution path of GUI agents to guide the
further development of this domain.

æè¦ï¼æ¬æä»ç´¹äº UI-TARSï¼ä¸ç¨®åç GUI ä»£çæ¨¡åï¼å®åå°è¢å¹æªåè¦çºè¼¸å¥ï¼ä¸¦å·è¡é¡ä¼¼äººé¡çäºåï¼ä¾å¦ï¼éµç¤åæ»é¼ æä½ï¼ãèä¾è³´æ¼å°å®¶ç²¾å¿è£½ä½çæç¤ºåå·¥ä½æµç¨ççè¡ä»£çæ¶æ§ä¸åï¼UI-TARS æ¯ä¸åç«¯å°ç«¯æ¨¡åï¼å¶æè½åªæ¼éäºè¤éçæ¶æ§ãå¯¦é©è­æäºå¶åè¶çæè½ï¼UI-TARS å¨ 10 å¤å GUI ä»£çåºæºæ¸¬è©¦ä¸­åå¾ SOTA æè½ï¼è©ä¼°æç¥ãåºç¤å GUI ä»»åå·è¡ãå¼å¾æ³¨æçæ¯ï¼å¨ OSWorld åºæºæ¸¬è©¦ä¸­ï¼UI-TARS å¨ 50 åæ­¥é©ä¸­åå¾ 24.6 åï¼å¨ 15 åæ­¥é©ä¸­åå¾ 22.7 åï¼åªæ¼ Claudeï¼åå¥çº 22.0 å 14.9ï¼ãå¨ AndroidWorld ä¸­ï¼UI-TARS åå¾ 46.6 åï¼è¶è¶ GPT-4oï¼34.5ï¼ãUI-TARS èåäºå¤é ééµåµæ°ï¼(1) å¢å¼·æç¥ï¼å©ç¨å¤§è¦æ¨¡ GUI è¢å¹æªåè³æéï¼ä»¥æå¢æç¥çæ¹å¼çè§£ UI åç´ ä¸¦é²è¡ç²¾ç¢ºæ¨é¡èªªæï¼(2) çµ±ä¸åä½å»ºæ¨¡ï¼å°åä½æ¨æºåå°è·¨å¹³å°ççµ±ä¸ç©ºéï¼ä¸¦ééå¤§è¦æ¨¡åä½è¿½è¹¤ï¼å¯¦ç¾ç²¾ç¢ºçåºç¤åäºåï¼(3) ç³»çµ± 2 æ¨çï¼å°æ·±æçæ®çæ¨çç´å¥å¤æ­¥é©æ±ºç­å¶å®ä¸­ï¼æ¶åå¤ç¨®æ¨çæ¨¡å¼ï¼ä¾å¦ä»»ååè§£ãåææèãéç¨ç¢è­å¥ç­ï¼(4) ééåææ§ç·ä¸è¿½è¹¤é²è¡åè¦è¨ç·´ï¼ééå¨æ¸ç¾å°èæ¬æ©å¨ä¸èªåæ¶éãéæ¿¾ååææ§å°ç²¾çæ°çäºåè¿½è¹¤ï¼ä¾è§£æ±ºè³æç¶é ¸åé¡ãééåè¦è¨ç·´ååæèª¿æ´ï¼UI-TARS ä¸æ·å¾å¶é¯èª¤ä¸­å­¸ç¿ï¼ä¸¦å¨æå°çäººçºå¹²é ä¸é©æç¡æ³é è¦çææ³ãæåä¹åæäº GUI ä»£ççæ¼é²è·¯å¾ï¼ä»¥å¼å°æ­¤é åçé²ä¸æ­¥ç¼å±ã

##### **LLM-Assisted Knowledge Graph Completion for Curriculum and Domain Modelling in Personalized Higher Education Recommendations**
2501.12300v1 by Hasan Abu-Rasheed, Constance Jumbo, Rashed Al Amin, Christian Weber, Veit Wiese, Roman Obermaisser, Madjid Fathi

While learning personalization offers great potential for learners, modern
practices in higher education require a deeper consideration of domain models
and learning contexts, to develop effective personalization algorithms. This
paper introduces an innovative approach to higher education curriculum
modelling that utilizes large language models (LLMs) for knowledge graph (KG)
completion, with the goal of creating personalized learning-path
recommendations. Our research focuses on modelling university subjects and
linking their topics to corresponding domain models, enabling the integration
of learning modules from different faculties and institutions in the student's
learning path. Central to our approach is a collaborative process, where LLMs
assist human experts in extracting high-quality, fine-grained topics from
lecture materials. We develop a domain, curriculum, and user models for
university modules and stakeholders. We implement this model to create the KG
from two study modules: Embedded Systems and Development of Embedded Systems
Using FPGA. The resulting KG structures the curriculum and links it to the
domain models. We evaluate our approach through qualitative expert feedback and
quantitative graph quality metrics. Domain experts validated the relevance and
accuracy of the model, while the graph quality metrics measured the structural
properties of our KG. Our results show that the LLM-assisted graph completion
approach enhances the ability to connect related courses across disciplines to
personalize the learning experience. Expert feedback also showed high
acceptance of the proposed collaborative approach for concept extraction and
classification.

æè¦ï¼<paragraph>å¨å­¸ç¿åäººåæä¾å­¸ç¿èå·¨å¤§æ½åçåæï¼é«ç­æè²ä¸­çç¾ä»£å¯¦åéè¦æ´æ·±å¥å°èæ®é åæ¨¡ååå­¸ç¿æå¢ï¼ä»¥éç¼ææçåäººåæ¼ç®æ³ãæ¬æä»ç´¹äºä¸ç¨®åµæ°çé«ç­æè²èª²ç¨å»ºæ¨¡æ¹æ³ï¼è©²æ¹æ³å©ç¨å¤§åèªè¨æ¨¡å (LLM) ä¾å®æç¥è­åè­ (KG)ï¼ç®çæ¯å»ºç«åäººåçå­¸ç¿è·¯å¾å»ºè­°ãæåçç ç©¶éé»å¨æ¼å»ºæ¨¡å¤§å­¸ç§ç®ï¼ä¸¦å°å®åçä¸»é¡é£çµå°å°æçé åæ¨¡åï¼å¾èè½å¤ å°ä¾èªä¸åé¢ç³»åæ©æ§çå­¸ç¿æ¨¡çµæ´åå°å­¸ççå­¸ç¿è·¯å¾ä¸­ãæåçåæ³æ ¸å¿æ¯ä¸ååä½æµç¨ï¼å¶ä¸­ LLM åå©äººé¡å°å®¶å¾è¬ç¾©ææä¸­èåé«åè³ªãç´°ç·»çä¸»é¡ãæåçºå¤§å­¸æ¨¡çµåå©å®³éä¿äººéç¼äºé åãèª²ç¨åä½¿ç¨èæ¨¡åãæåå¯¦ä½éåæ¨¡åï¼å¾å©åç ç©¶æ¨¡çµå»ºç« KGï¼åµå¥å¼ç³»çµ±åä½¿ç¨ FPGA çåµå¥å¼ç³»çµ±éç¼ãç¢çç KG å»ºæ§äºèª²ç¨ä¸¦å°å¶é£çµå°é åæ¨¡åãæåééå®æ§å°å®¶åé¥åå®éåå½¢åè³ªææ¨ä¾è©ä¼°æåçåæ³ãé åå°å®¶é©è­äºæ¨¡åçç¸éæ§åæºç¢ºæ§ï¼èåå½¢åè³ªææ¨åæ¸¬éäºæå KG ççµæ§ç¹æ§ãæåççµæé¡¯ç¤ºï¼LLM è¼å©çåå½¢å®ææ¹æ³å¢å¼·äºè·¨å­¸ç§é£çµç¸éèª²ç¨çè½åï¼ä»¥åäººåå­¸ç¿é«é©ãå°å®¶åé¥ä¹é¡¯ç¤ºé«åº¦æ¥åææåºçåä½æ¹æ³ï¼ç¨æ¼æ¦å¿µèåååé¡ã</paragraph>

##### **RALAD: Bridging the Real-to-Sim Domain Gap in Autonomous Driving with Retrieval-Augmented Learning**
2501.12296v1 by Jiacheng Zuo, Haibo Hu, Zikang Zhou, Yufei Cui, Ziquan Liu, Jianping Wang, Nan Guan, Jin Wang, Chun Jason Xue

In the pursuit of robust autonomous driving systems, models trained on
real-world datasets often struggle to adapt to new environments, particularly
when confronted with corner cases such as extreme weather conditions.
Collecting these corner cases in the real world is non-trivial, which
necessitates the use of simulators for validation. However,the high
computational cost and the domain gap in data distribution have hindered the
seamless transition between real and simulated driving scenarios. To tackle
this challenge, we propose Retrieval-Augmented Learning for Autonomous Driving
(RALAD), a novel framework designed to bridge the real-to-sim gap at a low
cost. RALAD features three primary designs, including (1) domain adaptation via
an enhanced Optimal Transport (OT) method that accounts for both individual and
grouped image distances, (2) a simple and unified framework that can be applied
to various models, and (3) efficient fine-tuning techniques that freeze the
computationally expensive layers while maintaining robustness. Experimental
results demonstrate that RALAD compensates for the performance degradation in
simulated environments while maintaining accuracy in real-world scenarios
across three different models. Taking Cross View as an example, the mIOU and
mAP metrics in real-world scenarios remain stable before and after RALAD
fine-tuning, while in simulated environments,the mIOU and mAP metrics are
improved by 10.30% and 12.29%, respectively. Moreover, the re-training cost of
our approach is reduced by approximately 88.1%. Our code is available at
https://github.com/JiachengZuo/RALAD.git.

æè¦ï¼<paragraph>å¨è¿½æ±ç©©å¥çèªåé§é§ç³»çµ±æï¼ä½¿ç¨çå¯¦ä¸çè³æéè¨ç·´çæ¨¡åéå¸¸é£ä»¥é©ææ°ç°å¢ï¼ç¹å¥æ¯å¨éå°æ¥µç«¯å¤©æ°£æ¢ä»¶ç­æ¥µç«¯ææ³æãå¨ç¾å¯¦ä¸çä¸­æ¶ééäºæ¥µç«¯ææ³ä¸¦éæäºï¼ééè¦ä½¿ç¨æ¨¡æ¬å¨é²è¡é©è­ãç¶èï¼é«è¨ç®ææ¬åè³æåä½ä¸­çé åå·®è·é»ç¤äºçå¯¦åæ¨¡æ¬é§é§å ´æ¯ä¹éçç¡ç¸«éæ¸¡ãçºäºæå°éä¸ææ°ï¼æåæåºäºç¨æ¼èªåé§é§çæª¢ç´¢å¢å¼·å­¸ç¿ (RALAD)ï¼éæ¯ä¸åæ°ç©çæ¡æ¶ï¼æ¨å¨ä»¥ä½ææ¬å½åçå¯¦èæ¨¡æ¬çå·®è·ãRALAD å·æä¸é ä¸»è¦è¨­è¨ï¼åæ¬ (1) ééä¸ç¨®å¢å¼·çæä½³å³è¼¸ (OT) æ¹æ³é²è¡é åé©æï¼è©²æ¹æ³èæ®äºåå¥åç¾¤çµå½±åè·é¢ï¼(2) ä¸åç°¡å®ä¸çµ±ä¸çæ¡æ¶ï¼å¯æç¨æ¼åç¨®æ¨¡åï¼ä»¥å (3) ææçå¾®èª¿æè¡ï¼å¯å¨ç¶­æç©©å¥æ§çåæåçµè¨ç®ææ¬é«çå±¤ãå¯¦é©çµæè¡¨æï¼RALAD è£åäºæ¨¡æ¬ç°å¢ä¸­çæè½ä¸éï¼åæå¨ä¸åä¸åçæ¨¡åä¸­ç¶­æäºçå¯¦ä¸çå ´æ¯ä¸­çæºç¢ºæ§ãä»¥ Cross View çºä¾ï¼RALAD å¾®èª¿åå¾ï¼çå¯¦ä¸çå ´æ¯ä¸­ç mIOU å mAP ææ¨ä¿æç©©å®ï¼èå¨æ¨¡æ¬ç°å¢ä¸­ï¼mIOU å mAP ææ¨åå¥æé«äº 10.30% å 12.29%ãæ­¤å¤ï¼æåçæ¹æ³çéæ°è¨ç·´ææ¬éä½äºå¤§ç´ 88.1%ãæåçç¨å¼ç¢¼å¯å¨ https://github.com/JiachengZuo/RALAD.git ä¸­åå¾ã</paragraph>

##### **Divide-Then-Aggregate: An Efficient Tool Learning Method via Parallel Tool Invocation**
2501.12432v1 by Dongsheng Zhu, Weixian Shi, Zhengliang Shi, Zhaochun Ren, Shuaiqiang Wang, Lingyong Yan, Dawei Yin

Although current Large Language Models (LLMs) exhibit impressive
capabilities, performing complex real-world tasks still requires tool learning.
Mainstream methods, such as CoT/ReAct, rely on step-by-step tool invocation to
interact with external environments, but they are limited in perceptual scope
and lack adequate task-planning capability. To address these limitations, other
studies introduce the first Search-based Decision Tree (DFSDT), which still
suffers from the high computational cost. In this paper, we introduce a novel
parallel tool invocation paradigm, DTA-Llama (Divide-Then-Aggregate Llama).
First, we transform traditional tree-based tool search paths into Directed
Acyclic Graph (DAG) structure, generating a high-quality parallel tool
invocation dataset. The DTA-Llama is then trained on the dataset to learn to
iteratively divide the current task into several parallel tool invocation
sub-tasks and aggregate the invocation results to decide the next actions.
Furthermore, we introduce an efficient inference framework inspired by the
Process/Threads mechanism when applying the DTA-Llama to practical tasks.
Experimental results show that our approach substantially enhances task
performance while reducing token consumption and inference time. Llama2-7B,
using our method, is comparable to the official parallel function calling
method of GPT-3.5. The relevant code, dataset, and model weights are available
at https://corn0205.github.io/

æè¦ï¼åç®¡ç®åçå¤§åèªè¨æ¨¡å (LLM) å±ç¾åºä»¤äººå°è±¡æ·±å»çè½åï¼ä½å·è¡è¤éççå¯¦ä¸çä»»åä»éè¦å·¥å·å­¸ç¿ãä¸»æµæ¹æ³ï¼ä¾å¦ CoT/ReActï¼ä¾è³´éæ­¥å·¥å·å¼å«èå¤é¨ç°å¢äºåï¼ä½å®åçæç¥ç¯åæéï¼ä¸ç¼ºä¹è¶³å¤ çä»»åè¦åè½åãçºäºè§£æ±ºéäºéå¶ï¼å¶ä»ç ç©¶å¼å¥äºç¬¬ä¸ååºæ¼æå°çæ±ºç­æ¨¹ (DFSDT)ï¼ä½ä»æå¾é«çéç®ææ¬ãå¨æ¬æä¸­ï¼æåä»ç´¹äºä¸ç¨®æ°ç©çå¹³è¡å·¥å·å¼å«ç¯ä¾ï¼DTA-Llamaï¼åèåä¹ Llamaï¼ãé¦åï¼æåå°å³çµ±çåºæ¼æ¨¹çå·¥å·æå°è·¯å¾è½æçºæåç¡ç°å (DAG) çµæ§ï¼ç¢çé«åè³ªçå¹³è¡å·¥å·å¼å«è³æéãç¶å¾å¨è³æéä¸è¨ç·´ DTA-Llamaï¼å­¸ç¿åè¦å°ç¶åä»»ååæå¹¾åå¹³è¡å·¥å·å¼å«å­ä»»åï¼ä¸¦å½ç¸½å¼å«çµæä»¥æ±ºå®å¾çºåä½ãæ­¤å¤ï¼æåå¨å° DTA-Llama æç¨æ¼å¯¦éä»»åæï¼å¼å¥äºä¸åå Process/Threads æ©å¶åç¼çé«ææ¨è«æ¡æ¶ãå¯¦é©çµæè¡¨æï¼æåçåæ³å¤§å¹æåäºä»»åæè½ï¼åææ¸å°äºç¬¦èæ¶èåæ¨è«æéãä½¿ç¨æåæ¹æ³ç Llama2-7Bï¼å¯è GPT-3.5 çå®æ¹å¹³è¡å½å¼å¼å«æ¹æ³ç¸åª²ç¾ãç¸éç¨å¼ç¢¼ãè³æéåæ¨¡åæ¬éå¯å¨ https://corn0205.github.io/ åå¾

##### **Modality Interactive Mixture-of-Experts for Fake News Detection**
2501.12431v1 by Yifan Liu, Yaokun Liu, Zelin Li, Ruichen Yao, Yang Zhang, Dong Wang

The proliferation of fake news on social media platforms disproportionately
impacts vulnerable populations, eroding trust, exacerbating inequality, and
amplifying harmful narratives. Detecting fake news in multimodal contexts --
where deceptive content combines text and images -- is particularly challenging
due to the nuanced interplay between modalities. Existing multimodal fake news
detection methods often emphasize cross-modal consistency but ignore the
complex interactions between text and visual elements, which may complement,
contradict, or independently influence the predicted veracity of a post. To
address these challenges, we present Modality Interactive Mixture-of-Experts
for Fake News Detection (MIMoE-FND), a novel hierarchical Mixture-of-Experts
framework designed to enhance multimodal fake news detection by explicitly
modeling modality interactions through an interaction gating mechanism. Our
approach models modality interactions by evaluating two key aspects of modality
interactions: unimodal prediction agreement and semantic alignment. The
hierarchical structure of MIMoE-FND allows for distinct learning pathways
tailored to different fusion scenarios, adapting to the unique characteristics
of each modality interaction. By tailoring fusion strategies to diverse
modality interaction scenarios, MIMoE-FND provides a more robust and nuanced
approach to multimodal fake news detection. We evaluate our approach on three
real-world benchmarks spanning two languages, demonstrating its superior
performance compared to state-of-the-art methods. By enhancing the accuracy and
interpretability of fake news detection, MIMoE-FND offers a promising tool to
mitigate the spread of misinformation, with the potential to better safeguard
vulnerable communities against its harmful effects.

æè¦ï¼ç¤¾ç¾¤åªé«å¹³å°ä¸åæ°èçæ¿å¢å°å¼±å¢æç¾¤é æä¸ææ¯ä¾çå½±é¿ï¼ä¾µèä¿¡ä»»ãå åä¸å¹³ç­ï¼ä¸¦æ´å¤§æå®³çæè¿°ãå¨å¤æ¨¡æèçµ¡ä¸­åµæ¸¬åæ°èï¼å¶ä¸­å·ææ¬ºé¨æ§çå§å®¹çµåæå­åå½±åï¼ç¹å¥å·æææ°æ§ï¼éæ¯å çºä¸åæ¨¡æä¹éçäº¤äºä½ç¨å·æç´°å¾®å·®å¥ãç¾æçå¤æ¨¡æåæ°èåµæ¸¬æ¹æ³éå¸¸å¼·èª¿è·¨æ¨¡æä¸è´æ§ï¼ä½å¿½ç¥äºæå­åè¦è¦ºåç´ ä¹éçè¤éäº¤äºä½ç¨ï¼éäºäº¤äºä½ç¨å¯è½è£åãçç¾æç¨ç«å½±é¿è²¼æçé æ¸¬çå¯¦æ§ãçºäºæå°éäºææ°ï¼æåæåºç¨æ¼åæ°èåµæ¸¬çæ¨¡æäºåå°å®¶æ··åï¼MIMoE-FNDï¼ï¼éæ¯ä¸åæ°ç©çåå±¤å¼å°å®¶æ··åæ¶æ§ï¼æ¨å¨ééäºåéæ§æ©å¶æç¢ºå°å»ºæ¨¡æ¨¡æäº¤äºä½ç¨ï¼ä»¥å¢å¼·å¤æ¨¡æåæ°èåµæ¸¬ãæåçåæ³ééè©ä¼°æ¨¡æäº¤äºä½ç¨çå©åééµé¢åï¼å®æ¨¡æé æ¸¬ä¸è´æ§åèªç¾©å°é½ï¼ä¾å»ºæ¨¡æ¨¡æäº¤äºä½ç¨ãMIMoE-FND çåå±¤çµæ§åè¨±ä¸åçå­¸ç¿è·¯å¾ï¼éå°ä¸åçèåæå¢éèº«æé ï¼é©ææ¯åæ¨¡æäº¤äºä½ç¨çç¨ç¹ç¹å¾µãéééå°ä¸åçæ¨¡æäº¤äºä½ç¨æå¢éèº«æé èåç­ç¥ï¼MIMoE-FND æä¾ä¸ç¨®æ´å¼·å¤§ä¸ç´°ç·»çå¤æ¨¡æåæ°èåµæ¸¬æ¹æ³ãæåå¨æ©«è·¨å©ç¨®èªè¨çä¸åçå¯¦ä¸çåºæºä¸è©ä¼°æåçåæ³ï¼è­æå¶æè½åªæ¼æåé²çæ¹æ³ãééå¢å¼·åæ°èåµæ¸¬çæºç¢ºæ§åå¯è§£éæ§ï¼MIMoE-FND æä¾äºä¸åæå¸æçå·¥å·ä¾æ¸è¼é¯èª¤è¨æ¯çæ£å¸ï¼ä¸¦æå¯è½æ´å¥½å°ä¿è­·å¼±å¢æç¾¤åæ¼å¶æå®³å½±é¿ã

##### **With Great Backbones Comes Great Adversarial Transferability**
2501.12275v1 by Erik Arakelyan, Karen Hambardzumyan, Davit Papikyan, Pasquale Minervini, Albert Gordo, Isabelle Augenstein, Aram H. Markosyan

Advances in self-supervised learning (SSL) for machine vision have improved
representation robustness and model performance, giving rise to pre-trained
backbones like \emph{ResNet} and \emph{ViT} models tuned with SSL methods such
as \emph{SimCLR}. Due to the computational and data demands of pre-training,
the utilization of such backbones becomes a strenuous necessity. However,
employing these backbones may inherit vulnerabilities to adversarial attacks.
While adversarial robustness has been studied under \emph{white-box} and
\emph{black-box} settings, the robustness of models tuned on pre-trained
backbones remains largely unexplored. Additionally, the role of tuning
meta-information in mitigating exploitation risks is unclear. This work
systematically evaluates the adversarial robustness of such models across
$20,000$ combinations of tuning meta-information, including fine-tuning
techniques, backbone families, datasets, and attack types. We propose using
proxy models to transfer attacks, simulating varying levels of target knowledge
by fine-tuning these proxies with diverse configurations. Our findings reveal
that proxy-based attacks approach the effectiveness of \emph{white-box}
methods, even with minimal tuning knowledge. We also introduce a naive
"backbone attack," leveraging only the backbone to generate adversarial
samples, which outperforms \emph{black-box} attacks and rivals \emph{white-box}
methods, highlighting critical risks in model-sharing practices. Finally, our
ablations reveal how increasing tuning meta-information impacts attack
transferability, measuring each meta-information combination.

æè¦ï¼<paragraph>æ©å¨è¦è¦ºçèªç£ç£å­¸ç¿ (SSL) é²æ­¥æåäºè¡¨ç¤ºç©©å¥æ§åæ¨¡åæè½ï¼ç¢çé åè¨ç·´çéª¨å¹¹ï¼ä¾å¦ä½¿ç¨ SSL æ¹æ³ï¼ä¾å¦ SimCLRï¼èª¿æ´ç ResNet å ViT æ¨¡åãç±æ¼é åè¨ç·´çéç®åè³æéæ±ï¼ä½¿ç¨æ­¤é¡éª¨å¹¹è®å¾æ¥µçºå¿è¦ãç¶èï¼æ¡ç¨éäºéª¨å¹¹å¯è½æç¹¼æ¿å°ææ»æçæ¼æ´ãåç®¡å¨ç½çåé»çè¨­å®ä¸å·²ç ç©¶å°æç©©å¥æ§ï¼ä½é åè¨ç·´éª¨å¹¹ä¸èª¿æ´çæ¨¡åçç©©å¥æ§ä»æªå¾å°ååæ¢è¨ãæ­¤å¤ï¼èª¿æ´åè³è¨å¨æ¸è¼å©ç¨é¢¨éªä¸­çä½ç¨å°ä¸æ¸æ¥ãæ¬ç ç©¶ç³»çµ±æ§å°è©ä¼°æ­¤é¡æ¨¡åå¨ 20,000 ç¨®èª¿æ´åè³è¨çµåä¸­çå°æç©©å¥æ§ï¼åæ¬å¾®èª¿æè¡ãéª¨å¹¹ç³»åãè³æéåæ»æé¡åãæåå»ºè­°ä½¿ç¨ä»£çæ¨¡åä¾å³è¼¸æ»æï¼ééä½¿ç¨ä¸åççµæå¾®èª¿éäºä»£çæ¨¡åä¾æ¨¡æ¬ä¸åå±¤ç´çç®æ¨ç¥è­ãæåçç ç©¶çµæé¡¯ç¤ºï¼å³ä½¿èª¿æ´ç¥è­æå°ï¼åºæ¼ä»£ççæ»æä¹æ¥è¿ç½çæ¹æ³çæææ§ãæåéå¼å¥äºä¸åå¤©ççãéª¨å¹¹æ»æãï¼åå©ç¨éª¨å¹¹ç¢çå°ææ¨£æ¬ï¼å¶è¡¨ç¾åªæ¼é»çæ»æï¼ä¸¦èç½çæ¹æ³ç¸æè¡¡ï¼çªé¡¯æ¨¡ååäº«å¯¦åä¸­çééµé¢¨éªãæå¾ï¼æåçæ¶èå¯¦é©æ­ç¤ºäºå¢å èª¿æ´åè³è¨å¦ä½å½±é¿æ»æå¯å³éæ§ï¼ä¸¦è¡¡éæ¯ååè³è¨çµåã</paragraph>

##### **Condor: Enhance LLM Alignment with Knowledge-Driven Data Synthesis and Refinement**
2501.12273v1 by Maosong Cao, Taolin Zhang, Mo Li, Chuyu Zhang, Yunxin Liu, Haodong Duan, Songyang Zhang, Kai Chen

The quality of Supervised Fine-Tuning (SFT) data plays a critical role in
enhancing the conversational capabilities of Large Language Models (LLMs).
However, as LLMs become more advanced, the availability of high-quality
human-annotated SFT data has become a significant bottleneck, necessitating a
greater reliance on synthetic training data. In this work, we introduce Condor,
a novel two-stage synthetic data generation framework that incorporates World
Knowledge Tree and Self-Reflection Refinement to produce high-quality SFT data
at scale. Our experimental results demonstrate that a base model fine-tuned on
only 20K Condor-generated samples achieves superior performance compared to
counterparts. The additional refinement stage in Condor further enables
iterative self-improvement for LLMs at various scales (up to 72B), validating
the effectiveness of our approach. Furthermore, our investigation into the
scaling for synthetic data in post-training reveals substantial unexplored
potential for performance improvements, opening promising avenues for future
research.

æè¦ï¼ç£ç£å¼å¾®èª¿ (SFT) è³æçåè³ªå°æ¼å¢å¼·å¤§åèªè¨æ¨¡å (LLM) çå°è©±è½åç¼æ®ééµä½ç¨ãç¶èï¼é¨è LLM è®å¾è¶ä¾è¶åé²ï¼é«åè³ªäººå·¥æ¨è¨» SFT è³æçå¯ç¨æ§å·²æçºä¸åéå¤§çç¶é ¸ï¼éä½¿å¾å°åæè¨ç·´è³æçä¾è³´æ§è¶ä¾è¶é«ãå¨éé å·¥ä½ä¸­ï¼æåä»ç´¹äº Condorï¼ä¸åæ°ç©çå©éæ®µåæè³æçææ¶æ§ï¼å®çµåäºä¸çç¥è­æ¨¹åèªæåçç²¾çï¼ä»¥å¤§è¦æ¨¡ç¢çé«åè³ªç SFT è³æãæåçå¯¦é©çµæè¡¨æï¼åéå° 20K å Condor çæçç¯ä¾é²è¡å¾®èª¿çåºæ¬æ¨¡åï¼èåé¡åæ¨¡åç¸æ¯ï¼å¯ç²å¾åªè¶çæè½ãCondor ä¸­çé¡å¤ç²¾çéæ®µé²ä¸æ­¥è® LLM è½å¤ å¨åç¨®è¦æ¨¡ï¼æé« 72Bï¼ä¸é²è¡åè¦èªææ¹åï¼é©è­äºæåæ¹æ³çæææ§ãæ­¤å¤ï¼æåå°è¨ç·´å¾åæè³æçæ´å±æ§é²è¡èª¿æ¥ï¼æ­ç¤ºäºæè½æ¹åçå·¨å¤§æªéç¼æ½åï¼çºæªä¾çç ç©¶éé¢äºæåæ¯çéå¾ã

##### **CBVLM: Training-free Explainable Concept-based Large Vision Language Models for Medical Image Classification**
2501.12266v1 by Cristiano PatrÃ­cio, Isabel Rio-Torto, Jaime S. Cardoso, LuÃ­s F. Teixeira, JoÃ£o C. Neves

The main challenges limiting the adoption of deep learning-based solutions in
medical workflows are the availability of annotated data and the lack of
interpretability of such systems. Concept Bottleneck Models (CBMs) tackle the
latter by constraining the final disease prediction on a set of predefined and
human-interpretable concepts. However, the increased interpretability achieved
through these concept-based explanations implies a higher annotation burden.
Moreover, if a new concept needs to be added, the whole system needs to be
retrained. Inspired by the remarkable performance shown by Large
Vision-Language Models (LVLMs) in few-shot settings, we propose a simple, yet
effective, methodology, CBVLM, which tackles both of the aforementioned
challenges. First, for each concept, we prompt the LVLM to answer if the
concept is present in the input image. Then, we ask the LVLM to classify the
image based on the previous concept predictions. Moreover, in both stages, we
incorporate a retrieval module responsible for selecting the best examples for
in-context learning. By grounding the final diagnosis on the predicted
concepts, we ensure explainability, and by leveraging the few-shot capabilities
of LVLMs, we drastically lower the annotation cost. We validate our approach
with extensive experiments across four medical datasets and twelve LVLMs (both
generic and medical) and show that CBVLM consistently outperforms CBMs and
task-specific supervised methods without requiring any training and using just
a few annotated examples. More information on our project page:
https://cristianopatricio.github.io/CBVLM/.

æè¦ï¼éå¶å¨é«çå·¥ä½æµç¨ä¸­æ¡ç¨åºæ¼æ·±åº¦å­¸ç¿çè§£æ±ºæ¹æ¡çä¸»è¦ææ°æ¯æ¨è¨è³æçå¯ç¨æ§ä»¥åæ­¤é¡ç³»çµ±çå¯è§£éæ§ä¸è¶³ãæ¦å¿µç¶é ¸æ¨¡å (CBM) éééå¶ä¸çµé å®ç¾©ä¸äººé¡å¯è§£éçæ¦å¿µå°æçµç¾çé æ¸¬ï¼ä¾è§£æ±ºå¾èãç¶èï¼éééäºåºæ¼æ¦å¿µçè§£éæå¯¦ç¾çå¯è§£éæ§æåï¼æå³èæ´é«çæ¨è¨è² æãæ­¤å¤ï¼å¦æéè¦æ°å¢ä¸åæ°æ¦å¿µï¼åéè¦éæ°è¨ç·´æ´åç³»çµ±ãåå°å¤§åè¦è¦ºèªè¨æ¨¡å (LVLMs) å¨å°æ¨£æ¬è¨­å®ä¸­å±ç¾çåè¶æè½åç¼ï¼æåæåºäºä¸åç°¡å®ä½ææç CBVLM æ¹æ³ï¼ä¾è§£æ±ºä¸è¿°å©åææ°ãé¦åï¼å°æ¼æ¯åæ¦å¿µï¼æåæç¤º LVLM åç­è¼¸å¥å½±åä¸­æ¯å¦åå«è©²æ¦å¿µãç¶å¾ï¼æåè¦æ± LVLM æ ¹æååçæ¦å¿µé æ¸¬å°å½±åé²è¡åé¡ãæ­¤å¤ï¼å¨å©åéæ®µä¸­ï¼æåé½ç´å¥ä¸åæª¢ç´¢æ¨¡çµï¼è² è²¬é¸åºæé©åæ¼æå¢å­¸ç¿çç¯ä¾ãééå°æçµè¨ºæ·å»ºç«å¨é æ¸¬æ¦å¿µä¹ä¸ï¼æåç¢ºä¿äºå¯è§£éæ§ï¼ä¸¦ééå©ç¨ LVLMs çå°æ¨£æ¬è½åï¼æåå¤§å¹éä½äºæ¨è¨ææ¬ãæåééååé«çè³æéååäºå LVLMï¼éç¨åé«çï¼çå»£æ³å¯¦é©é©è­äºæåçä½æ³ï¼ä¸¦é¡¯ç¤º CBVLM å¨ç¡éä»»ä½è¨ç·´ä¸åä½¿ç¨å°æ¸æ¨è¨ç¯ä¾çææ³ä¸ï¼å§çµåªæ¼ CBM åç¹å®æ¼ä»»åçç£ç£å¼æ¹æ³ãæ´å¤è³è¨è«è¦æåçå°æ¡é é¢ï¼https://cristianopatricio.github.io/CBVLM/ã

##### **FOCUS: First Order Concentrated Updating Scheme**
2501.12243v1 by Yizhou Liu, Ziming Liu, Jeff Gore

Large language models (LLMs) demonstrate remarkable performance, and
improving their pre-training process appears to be key to enhancing their
capabilities further. Based on the documented success of Adam, learning rate
decay, and weight decay, we hypothesize that the pre-training loss landscape
features a narrowing valley structure. Through experiments with synthetic loss
functions, we discover that when gradient query noise is high relative to the
valley's sharpness, Adam's performance falls behind that of Signum because Adam
reduces the effective step size too drastically. This observation led us to
develop FOCUS, an optimizer that enhances Signum by incorporating attraction
toward moving averaged parameters, allowing it to handle noise better while
maintaining larger step sizes. In training GPT-2, FOCUS proves to be more
stable than Signum and faster than Adam. These results suggest that gradient
noise may be an underappreciated limiting factor in LLM training, and FOCUS
offers promising solutions.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å±ç¾åºåè¶çæè½ï¼èæ¹åå¶é è¨ç·´ç¨åºä¼¼ä¹æ¯é²ä¸æ­¥æåå¶åè½çééµãæ ¹æ Adamãå­¸ç¿çè¡°æ¸åæ¬éè¡°æ¸çå·²è¨éæåï¼æååè¨­é è¨ç·´æå¤±æ¯è§å·æç¸®å°çè°·å°çµæ§ãééå°åææå¤±å½æ¸çå¯¦é©ï¼æåç¼ç¾ç¶æ¢¯åº¦æ¥è©¢éè¨ç¸å°æ¼è°·å°çé³å©åº¦è¼é«æï¼Adam çæè½æè½å¾æ¼ Signumï¼å çº Adam æéåº¦å¤§å¹åº¦å°æ¸å°æææ­¥é©å¤§å°ãéåè§å¯è®æåéç¼åº FOCUSï¼ä¸ç¨®ééç´å¥å°ç§»åå¹³ååæ¸çå¸å¼åä¾å¢å¼· Signum çæä½³åå¨ï¼è®å®å¯ä»¥å¨ç¶­æè¼å¤§æ­¥é©å¤§å°çåææ´å¥½å°èçéè¨ãå¨è¨ç·´ GPT-2 æï¼FOCUS è­ææ¯ Signum æ´ç©©å®ï¼èä¸æ¯ Adam æ´å¿«ãéäºçµæè¡¨æï¼æ¢¯åº¦éè¨å¯è½æ¯ LLM è¨ç·´ä¸­ä¸åæªè¢«ååéè¦çéå¶å ç´ ï¼è FOCUS æä¾äºæå¸æçè§£æ±ºæ¹æ¡ã

##### **InsTALL: Context-aware Instructional Task Assistance with Multi-modal Large Language Models**
2501.12231v1 by Pha Nguyen, Sailik Sengupta, Girik Malik, Arshit Gupta, Bonan Min

The improved competence of generative models can help building multi-modal
virtual assistants that leverage modalities beyond language. By observing
humans performing multi-step tasks, one can build assistants that have
situational awareness of actions and tasks being performed, enabling them to
cater assistance based on this understanding. In this paper, we develop a
Context-aware Instructional Task Assistant with Multi-modal Large Language
Models (InsTALL) that leverages an online visual stream (e.g. a user's screen
share or video recording) and responds in real-time to user queries related to
the task at hand. To enable useful assistance, InsTALL 1) trains a multi-modal
model on task videos and paired textual data, and 2) automatically extracts
task graph from video data and leverages it at training and inference time. We
show InsTALL achieves state-of-the-art performance across proposed sub-tasks
considered for multimodal activity understanding -- task recognition (TR),
action recognition (AR), next action prediction (AP), and plan prediction (PP)
-- and outperforms existing baselines on two novel sub-tasks related to
automatic error identification.

æè¦ï¼çææ¨¡åè½åçæåæå©äºæå»ºå©ç¨è¯­è¨ä¹å¤çå¤æ¨¡æèæå©æãéè¿è§å¯äººç±»æ§è¡å¤æ­¥éª¤ä»»å¡ï¼å¯ä»¥æå»ºå¯¹æ­£å¨æ§è¡çå¨ä½åä»»å¡ææå¢æç¥çå©æï¼ä½¿ä»ä»¬è½å¤æ ¹æ®è¿ç§çè§£æä¾å¸®å©ãå¨æ¬æä¸­ï¼æä»¬å¼åäºä¸ä¸ªå·æå¤æ¨¡æå¤§è¯­è¨æ¨¡åçä¸ä¸ææç¥æä»¤ä»»å¡å©æ (InsTALL)ï¼è¯¥å©æå©ç¨å¨çº¿è§è§æµï¼ä¾å¦ç¨æ·çå±å¹å±äº«æè§é¢å½å¶ï¼ï¼å¹¶å®æ¶ååºä¸æå¤´ä»»å¡ç¸å³çç¨æ·æ¥è¯¢ãä¸ºäºæä¾æç¨çå¸®å©ï¼InsTALL 1) å¨ä»»å¡è§é¢åéå¯¹ææ¬æ°æ®ä¸è®­ç»å¤æ¨¡ææ¨¡åï¼ä»¥å 2) ä»è§é¢æ°æ®ä¸­èªå¨æåä»»å¡å¾ï¼å¹¶å¨è®­ç»åæ¨çæ¶é´å©ç¨å®ãæä»¬å±ç¤ºäº InsTALL å¨èèç¨äºå¤æ¨¡ææ´»å¨çè§£çæè®®å­ä»»å¡ä¸­å®ç°äºæåè¿çæ§è½ââä»»å¡è¯å« (TR)ãå¨ä½è¯å« (AR)ãä¸ä¸ä¸ªå¨ä½é¢æµ (AP) åè®¡åé¢æµ (PP)ââå¹¶ä¸å¨ä¸èªå¨éè¯¯è¯å«ç¸å³çä¸¤ä¸ªæ°å­ä»»å¡ä¸ä¼äºç°æçåºåã

##### **SCFCRC: Simultaneously Counteract Feature Camouflage and Relation Camouflage for Fraud Detection**
2501.12430v1 by Xiaocheng Zhang, Zhuangzhuang Ye, GuoPing Zhao, Jianing Wang, Xiaohong Su

In fraud detection, fraudsters often interact with many benign users,
camouflaging their features or relations to hide themselves. Most existing work
concentrates solely on either feature camouflage or relation camouflage, or
decoupling feature learning and relation learning to avoid the two camouflage
from affecting each other. However, this inadvertently neglects the valuable
information derived from features or relations, which could mutually enhance
their adversarial camouflage strategies. In response to this gap, we propose
SCFCRC, a Transformer-based fraud detector that Simultaneously Counteract
Feature Camouflage and Relation Camouflage. SCFCRC consists of two components:
Feature Camouflage Filter and Relation Camouflage Refiner. The feature
camouflage filter utilizes pseudo labels generated through label propagation to
train the filter and uses contrastive learning that combines instance-wise and
prototype-wise to improve the quality of features. The relation camouflage
refiner uses Mixture-of-Experts(MoE) network to disassemble the multi-relations
graph into multiple substructures and divide and conquer them to mitigate the
degradation of detection performance caused by relation camouflage.
Furthermore, we introduce a regularization method for MoE to enhance the
robustness of the model. Extensive experiments on two fraud detection benchmark
datasets demonstrate that our method outperforms state-of-the-art baselines.

æè¦ï¼<paragraph>å¨æ¬ºè©åµæ¸¬ä¸­ï¼æ¬ºè©èéå¸¸æèè¨±å¤è¯æ§ä½¿ç¨èäºåï¼å½è£å¶ç¹å¾µæéä¿ä»¥é±èèªå·±ãå¤§å¤æ¸ç¾æå·¥ä½åå°æ³¨æ¼ç¹å¾µå½è£æéä¿å½è£ï¼æè§£è¦ç¹å¾µå­¸ç¿åéä¿å­¸ç¿ï¼ä»¥é¿åå©ç¨®å½è£äºç¸å½±é¿ãç¶èï¼éç¡æä¸­å¿½è¦äºå¾ç¹å¾µæéä¿ä¸­è¡ççæå¹å¼è³è¨ï¼éå¯è½æç¸äºå¢å¼·å¶å°ææ§å½è£ç­ç¥ãçºäºæå°éä¸å·®è·ï¼æåæåºäº SCFCRCï¼éæ¯ä¸ååºæ¼ Transformer çæ¬ºè©æª¢æ¸¬å¨ï¼å¯åæå°æç¹å¾µå½è£åéä¿å½è£ãSCFCRC ç±å©åçµæé¨åçµæï¼ç¹å¾µå½è£æ¿¾æ³¢å¨åéä¿å½è£ç²¾çå¨ãç¹å¾µå½è£æ¿¾æ³¢å¨å©ç¨ééæ¨ç±¤å³æ­ç¢ççå½æ¨ç±¤ä¾è¨ç·´æ¿¾æ³¢å¨ï¼ä¸¦ä½¿ç¨çµåäºå¯¦ä¾ç´åååç´çå°æ¯å­¸ç¿ä¾æé«ç¹å¾µåè³ªãéä¿å½è£ç²¾çå¨ä½¿ç¨ Mixture-of-Experts(MoE) ç¶²è·¯å°å¤éä¿ååè§£æå¤åå­çµæ§ï¼ä¸¦åèæ²»ä¹ï¼ä»¥æ¸è¼éä¿å½è£é æçåµæ¸¬æè½ä¸éãæ­¤å¤ï¼æåçº MoE å¼å¥äºä¸åæ­£è¦åæ¹æ³ï¼ä»¥å¢å¼·æ¨¡åçç©©å¥æ§ãå¨å©åæ¬ºè©åµæ¸¬åºæºè³æéä¸é²è¡çå»£æ³å¯¦é©è­æï¼æåçæ¨¡ååªæ¼æåé²çåºæºã</paragraph>

##### **Fixing Imbalanced Attention to Mitigate In-Context Hallucination of Large Vision-Language Model**
2501.12206v1 by Kazi Hasan Ibn Arif, Sajib Acharjee Dip, Khizar Hussain, Lang Zhang, Chris Thomas

Large Vision Language Models (LVLMs) have demonstrated remarkable
capabilities in understanding and describing visual content, achieving
state-of-the-art performance across various vision-language tasks. However,
these models frequently exhibit hallucination behavior, where they generate
descriptions containing objects or details absent in the input image. Our work
investigates this phenomenon by analyzing attention patterns across transformer
layers and heads, revealing that hallucinations often stem from progressive
degradation of visual grounding in deeper layers. We propose a novel attention
modification approach that combines selective token emphasis and head-specific
modulation to maintain visual grounding throughout the generation process. Our
method introduces two key components: (1) a dual-stream token selection
mechanism that identifies and prioritizes both locally informative and
spatially significant visual tokens, and (2) an attention head-specific
modulation strategy that differentially amplifies visual information processing
based on measured visual sensitivity of individual attention heads. Through
extensive experimentation on the MSCOCO dataset, we demonstrate that our
approach reduces hallucination rates by up to 62.3\% compared to baseline
models while maintaining comparable task performance. Our analysis reveals that
selectively modulating tokens across attention heads with varying levels of
visual sensitivity can significantly improve visual grounding without requiring
model retraining.

æè¦ï¼å¤§åè¦è¦ºèªè¨æ¨¡å (LVLMs) å·²å±ç¾åºå¨çè§£åæè¿°è¦è¦ºå§å®¹æ¹é¢çåè¶è½åï¼å¨åç¨®è¦è¦ºèªè¨ä»»åä¸­åå¾äºæåé²çè¡¨ç¾ãç¶èï¼éäºæ¨¡åç¶å¸¸è¡¨ç¾åºå¹»è¦ºè¡çºï¼å®åæç¢çåå«è¼¸å¥å½±åä¸­ä¸å­å¨çç©ä»¶æç´°ç¯çæè¿°ãæåçç ç©¶ééåæTransformerå±¤åé ­é¨çæ³¨æåæ¨¡å¼ä¾æ¢è¨éç¨®ç¾è±¡ï¼æ­ç¤ºå¹»è¦ºéå¸¸æºæ¼è¼æ·±å±¤çè¦è¦ºåºç¤éæ¼¸éåãæåæåºäºä¸ç¨®æ°ç©çæ³¨æåä¿®æ¹æ¹æ³ï¼çµåé¸ææ§çæ¬æ¨å¼·èª¿åç¹å®æ¼é ­é¨çèª¿è®ï¼ä»¥å¨æ´åçæéç¨ä¸­ç¶­æè¦è¦ºåºç¤ãæåçæè¡å¼å¥äºå©åééµçµæé¨åï¼(1) ä¸ç¨®éä¸²æµæ¬æ¨é¸ææ©å¶ï¼ç¨æ¼è­å¥ååªåèçå±é¨è³è¨æ§åç©ºéé¡¯èæ§çè¦è¦ºæ¬æ¨ï¼ä»¥å (2) ä¸ç¨®æ³¨æåé ­é¨ç¹å®èª¿è®ç­ç¥ï¼æ ¹æåå¥æ³¨æåé ­é¨çæ¸¬éè¦è¦ºææåº¦ï¼å°è¦è¦ºè³è¨èçé²è¡ä¸åçæ¾å¤§ãééå¨ MSCOCO è³æéä¸é²è¡å»£æ³çå¯¦é©ï¼æåè­æäºèåºæºæ¨¡åç¸æ¯ï¼æåçæè¡å°å¹»è¦ºçéä½äºå¤é 62.3%ï¼åæç¶­æäºç¸ç¶çä»»åè¡¨ç¾ãæåçåæé¡¯ç¤ºï¼é¸ææ§å°èª¿è®å·æä¸åè¦è¦ºææåº¦å±¤ç´çæ³¨æåé ­é¨çæ¬æ¨ï¼å¯ä»¥å¨ä¸ééæ°è¨ç·´æ¨¡åçææ³ä¸ï¼é¡¯èæ¹åè¦è¦ºåºç¤ã

##### **An End-to-End Approach for Korean Wakeword Systems with Speaker Authentication**
2501.12194v1 by Geonwoo Seo

Wakeword detection plays a critical role in enabling AI assistants to listen
to user voices and interact effectively. However, for languages other than
English, there is a significant lack of pre-trained wakeword models.
Additionally, systems that merely determine the presence of a wakeword can pose
serious privacy concerns. In this paper, we propose an end-to-end approach that
trains wakewords for Non-English languages, particulary Korean, and uses this
to develop a Voice Authentication model to protect user privacy. Our
implementation employs an open-source platform OpenWakeWord, which performs
wakeword detection using an FCN (Fully-Connected Network) architecture. Once a
wakeword is detected, our custom-developed code calculates cosine similarity
for robust user authentication. Experimental results demonstrate the
effectiveness of our approach, achieving a 16.79% and a 6.6% Equal Error Rate
(EER) each in the Wakeword Detection and the Voice Authentication. These
findings highlight the model's potential in providing secure and accurate
wakeword detection and authentication for Korean users.

æè¦ï¼åéå­åµæ¸¬å¨è® AI å©çèè½ä½¿ç¨èè²é³ä¸¦ææäºåä¸­æ®æ¼ééµè§è²ãç¶èï¼å°æ¼éè±èªèªè¨ä¾èªªï¼é åè¨ç·´çåéå­æ¨¡åå­å¨èé¡¯èçç¼ºä¹ãæ­¤å¤ï¼ååå¤å®åéå­å­å¨çç³»çµ±å¯è½æé æå´éçé±ç§åé¡ãå¨æ¬æä¸­ï¼æåæåºä¸åç«¯å°ç«¯çæ¹æ³ï¼ç¨æ¼è¨ç·´éè±èªèªè¨ï¼ç¹å¥æ¯éèªï¼çåéå­ï¼ä¸¦ä½¿ç¨å®ä¾éç¼ä¸åèªé³é©è­æ¨¡åä»¥ä¿è­·ä½¿ç¨èé±ç§ãæåçå¯¦ä½æ¡ç¨ä¸åéæºå¹³å° OpenWakeWordï¼å®ä½¿ç¨ FCNï¼å¨é£æ¥ç¶²è·¯ï¼æ¶æ§ä¾å·è¡åéå­åµæ¸¬ãä¸æ¦åµæ¸¬å°åéå­ï¼æåèªè¨éç¼çç¨å¼ç¢¼æè¨ç®é¤å¼¦ç¸ä¼¼åº¦ä»¥é²è¡ç©©å¥çä½¿ç¨èé©è­ãå¯¦é©çµæè­æäºæåæ¹æ³çæææ§ï¼å¨åéå­åµæ¸¬åèªé³é©è­ä¸­åå¥éå° 16.79% å 6.6% çç­é¯çï¼EERï¼ãéäºç¼ç¾çªé¡¯äºè©²æ¨¡åå¨çºéèªä½¿ç¨èæä¾å®å¨ä¸æºç¢ºçåéå­åµæ¸¬åé©è­æ¹é¢çæ½åã

##### **Fuel Efficiency Analysis of the Public Transportation System Based on the Gaussian Mixture Model Clustering**
2501.12429v1 by Zhipeng Ma, Bo NÃ¸rregaard JÃ¸rgensen, Zheng Ma

Public transportation is a major source of greenhouse gas emissions,
highlighting the need to improve bus fuel efficiency. Clustering algorithms
assist in analyzing fuel efficiency by grouping data into clusters, but
irrelevant features may complicate the analysis and choosing the optimal number
of clusters remains a challenging task. Therefore, this paper employs the
Gaussian mixture models to cluster the solo fuel-efficiency dataset. Moreover,
an integration method that combines the Silhouette index, Calinski-Harabasz
index, and Davies-Bouldin index is developed to select the optimal cluster
numbers. A dataset with 4006 bus trips in North Jutland, Denmark is utilized as
the case study. Trips are first split into three groups, then one group is
divided further, resulting in four categories: extreme, normal, low, and
extremely low fuel efficiency. A preliminary study using visualization analysis
is conducted to investigate how driving behaviors and route conditions affect
fuel efficiency. The results indicate that both individual driving habits and
route characteristics have a significant influence on fuel efficiency.

æè¦ï¼å¬å±éè¼¸æ¯æº«å®¤æ°£é«ææ¾çä¸»è¦ä¾æºï¼çªé¡¯äºæ¹åå¬è»çæ²¹æççå¿è¦æ§ãåç¾¤æ¼ç®æ³æå©æ¼ééå°è³æåçµæç¾¤éä¾åæçæ²¹æçï¼ä½ç¡éç¹å¾µå¯è½æä½¿åæè¤éåï¼èé¸ææä½³ç¾¤éæ¸éä»ç¶æ¯ä¸é å·æææ°æ§çä»»åãå æ­¤ï¼æ¬ææ¡ç¨é«æ¯æ··åæ¨¡åä¾åç¾¤å®ä¸çæ²¹æçè³æéãæ­¤å¤ï¼ééç¼äºä¸ç¨®çµåè¼ªå»ææ¸ãCalinski-Harabasz ææ¸å Davies-Bouldin ææ¸çæ´åæ¹æ³ä¾é¸ææä½³ç¾¤éæ¸éãä¸¹éº¥åæ¥å¾·è­åå³¶ 4006 æ¬¡å¬è»è¡ç¨çè³æéè¢«ç¨ä½æ¡ä¾ç ç©¶ãè¡ç¨é¦ååæä¸çµï¼ç¶å¾é²ä¸æ­¥å°ä¸çµåéï¼å½¢æååé¡å¥ï¼æ¥µç«¯ãæ­£å¸¸ãä½åæ¥µä½çæ²¹æçãä½¿ç¨è¦è¦ºååæé²è¡åæ­¥ç ç©¶ï¼ä»¥èª¿æ¥é§é§è¡çºåè·¯ç·çæ³å¦ä½å½±é¿çæ²¹æçãçµæè¡¨æï¼åäººçé§é§ç¿æ£åè·¯ç·ç¹å¾µé½å°çæ²¹æçæé¡¯èå½±é¿ã


### Medical
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2025-01-22**|**Estimating the Conformal Prediction Threshold from Noisy Labels**|Coby Penso et.al.|[2501.12749v1](http://arxiv.org/abs/2501.12749v1)|[link](https://github.com/cobypenso/noise-aware-conformal-prediction)|
|**2025-01-21**|**Academic Case Reports Lack Diversity: Assessing the Presence and Diversity of Sociodemographic and Behavioral Factors related with Post COVID-19 Condition**|Juan Andres Medina Florez et.al.|[2501.12538v1](http://arxiv.org/abs/2501.12538v1)|null|
|**2025-01-21**|**Efficient Lung Ultrasound Severity Scoring Using Dedicated Feature Extractor**|Jiaqi Guo et.al.|[2501.12524v1](http://arxiv.org/abs/2501.12524v1)|null|
|**2025-01-21**|**FuocChuVIP123 at CoMeDi Shared Task: Disagreement Ranking with XLM-Roberta Sentence Embeddings and Deep Neural Regression**|Phuoc Duong Huy Chu et.al.|[2501.12336v1](http://arxiv.org/abs/2501.12336v1)|null|
|**2025-01-21**|**CBVLM: Training-free Explainable Concept-based Large Vision Language Models for Medical Image Classification**|Cristiano PatrÃ­cio et.al.|[2501.12266v1](http://arxiv.org/abs/2501.12266v1)|null|
|**2025-01-21**|**Can open source large language models be used for tumor documentation in Germany? -- An evaluation on urological doctors' notes**|Stefan Lenz et.al.|[2501.12106v1](http://arxiv.org/abs/2501.12106v1)|[link](https://github.com/stefan-m-lenz/urollmeval)|
|**2025-01-21**|**Multi-stage intermediate fusion for multimodal learning to classify non-small cell lung cancer subtypes from CT and PET**|Fatih Aksu et.al.|[2501.12425v1](http://arxiv.org/abs/2501.12425v1)|null|
|**2025-01-21**|**Adaptive Class Learning to Screen Diabetic Disorders in Fundus Images of Eye**|Shramana Dey et.al.|[2501.12048v1](http://arxiv.org/abs/2501.12048v1)|null|
|**2025-01-21**|**Tackling Small Sample Survival Analysis via Transfer Learning: A Study of Colorectal Cancer Prognosis**|Yonghao Zhao et.al.|[2501.12421v1](http://arxiv.org/abs/2501.12421v1)|null|
|**2025-01-21**|**Data-driven Detection and Evaluation of Damages in Concrete Structures: Using Deep Learning and Computer Vision**|Saeid Ataei et.al.|[2501.11836v1](http://arxiv.org/abs/2501.11836v1)|null|
|**2025-01-20**|**GL-ICNN: An End-To-End Interpretable Convolutional Neural Network for the Diagnosis and Prediction of Alzheimer's Disease**|Wenjie Kang et.al.|[2501.11715v1](http://arxiv.org/abs/2501.11715v1)|null|
|**2025-01-20**|**Human services organizations and the responsible integration of AI: Considering ethics and contextualizing risk(s)**|Brian E. Perron et.al.|[2501.11705v1](http://arxiv.org/abs/2501.11705v1)|null|
|**2025-01-20**|**Spatially-Delineated Domain-Adapted AI Classification: An Application for Oncology Data**|Majid Farhadloo et.al.|[2501.11695v1](http://arxiv.org/abs/2501.11695v1)|null|
|**2025-01-20**|**Biomedical Knowledge Graph: A Survey of Domains, Tasks, and Real-World Applications**|Yuxing Lu et.al.|[2501.11632v2](http://arxiv.org/abs/2501.11632v2)|null|
|**2025-01-20**|**Training-free Ultra Small Model for Universal Sparse Reconstruction in Compressed Sensing**|Chaoqing Tang et.al.|[2501.11592v1](http://arxiv.org/abs/2501.11592v1)|null|
|**2025-01-20**|**Enhancing Coronary Artery Calcium Scoring via Multi-Organ Segmentation on Non-Contrast Cardiac Computed Tomography**|Jakub Nalepa et.al.|[2501.11428v1](http://arxiv.org/abs/2501.11428v1)|null|
|**2025-01-20**|**RedStar: Does Scaling Long-CoT Data Unlock Better Slow-Reasoning Systems?**|Haotian Xu et.al.|[2501.11284v1](http://arxiv.org/abs/2501.11284v1)|null|
|**2025-01-20**|**Spatiotemporal Air Quality Mapping in Urban Areas Using Sparse Sensor Data, Satellite Imagery, Meteorological Factors, and Spatial Features**|Osama Ahmad et.al.|[2501.11270v1](http://arxiv.org/abs/2501.11270v1)|null|
|**2025-01-19**|**Clinical trial cohort selection using Large Language Models on n2c2 Challenges**|Chi-en Amy Tai et.al.|[2501.11114v1](http://arxiv.org/abs/2501.11114v1)|null|
|**2025-01-19**|**Enhanced Suicidal Ideation Detection from Social Media Using a CNN-BiLSTM Hybrid Model**|Mohaiminul Islam Bhuiyan et.al.|[2501.11094v1](http://arxiv.org/abs/2501.11094v1)|null|
|**2025-01-18**|**No More Sliding Window: Efficient 3D Medical Image Segmentation with Differentiable Top-k Patch Sampling**|Young Seok Jeon et.al.|[2501.10814v1](http://arxiv.org/abs/2501.10814v1)|null|
|**2025-01-18**|**Efficient Auto-Labeling of Large-Scale Poultry Datasets (ALPD) Using Semi-Supervised Models, Active Learning, and Prompt-then-Detect Approach**|Ramesh Bahadur Bist et.al.|[2501.10809v1](http://arxiv.org/abs/2501.10809v1)|null|
|**2025-01-18**|**MedFILIP: Medical Fine-grained Language-Image Pre-training**|Xinjie Liang et.al.|[2501.10775v1](http://arxiv.org/abs/2501.10775v1)|[link](https://github.com/perceptioncomputinglab/medfilip)|
|**2025-01-18**|**Enhancing Diagnostic in 3D COVID-19 Pneumonia CT-scans through Explainable Uncertainty Bayesian Quantification**|Juan Manuel Liscano Fierro et.al.|[2501.10770v1](http://arxiv.org/abs/2501.10770v1)|null|
|**2025-01-18**|**In the Picture: Medical Imaging Datasets, Artifacts, and their Living Review**|Amelia JimÃ©nez-SÃ¡nchez et.al.|[2501.10727v1](http://arxiv.org/abs/2501.10727v1)|null|
|**2025-01-17**|**An Ontology for Social Determinants of Education (SDoEd) based on Human-AI Collaborative Approach**|Navya Martin Kollapally et.al.|[2501.10300v1](http://arxiv.org/abs/2501.10300v1)|null|
|**2025-01-17**|**SEANN: A Domain-Informed Neural Network for Epidemiological Insights**|Jean-Baptiste Guimbaud et.al.|[2501.10273v1](http://arxiv.org/abs/2501.10273v1)|null|
|**2025-01-17**|**Challenges and recommendations for Electronic Health Records data extraction and preparation for dynamic prediction modelling in hospitalized patients -- a practical guide**|Elena Albu et.al.|[2501.10240v1](http://arxiv.org/abs/2501.10240v1)|null|
|**2025-01-17**|**Generative Artificial Intelligence: Implications for Biomedical and Health Professions Education**|William Hersh et.al.|[2501.10186v1](http://arxiv.org/abs/2501.10186v1)|null|
|**2025-01-17**|**CSSDM Ontology to Enable Continuity of Care Data Interoperability**|Subhashis Das et.al.|[2501.10160v1](http://arxiv.org/abs/2501.10160v1)|null|
|**2025-01-17**|**landmarker: a Toolkit for Anatomical Landmark Localization in 2D/3D Images**|Jef Jonkers et.al.|[2501.10098v1](http://arxiv.org/abs/2501.10098v1)|[link](https://github.com/predict-idlab/landmarker)|
|**2025-01-17**|**Deep Learning for Early Alzheimer Disease Detection with MRI Scans**|Mohammad Rafsan et.al.|[2501.09999v1](http://arxiv.org/abs/2501.09999v1)|[link](https://github.com/rafusan/dl-alzheimer)|
|**2025-01-17**|**Aneumo: A Large-Scale Comprehensive Synthetic Dataset of Aneurysm Hemodynamics**|Xigui Li et.al.|[2501.09980v1](http://arxiv.org/abs/2501.09980v1)|[link](https://github.com/xigui-li/aneumo)|
|**2025-01-17**|**Bias in Decision-Making for AI's Ethical Dilemmas: A Comparative Study of ChatGPT and Claude**|Yile Yan et.al.|[2501.10484v1](http://arxiv.org/abs/2501.10484v1)|null|
|**2025-01-16**|**Bridging Language Barriers in Healthcare: A Study on Arabic LLMs**|Nada Saadi et.al.|[2501.09825v1](http://arxiv.org/abs/2501.09825v1)|null|
|**2025-01-16**|**KU AIGEN ICL EDI@BC8 Track 3: Advancing Phenotype Named Entity Recognition and Normalization for Dysmorphology Physical Examination Reports**|Hajung Kim et.al.|[2501.09744v1](http://arxiv.org/abs/2501.09744v1)|null|
|**2025-01-16**|**Electronic Health Records: Towards Digital Twins in Healthcare**|Muhammet Alkan et.al.|[2501.09640v1](http://arxiv.org/abs/2501.09640v1)|null|
|**2025-01-16**|**Artificial Intelligence-Driven Clinical Decision Support Systems**|Muhammet Alkan et.al.|[2501.09628v1](http://arxiv.org/abs/2501.09628v1)|null|
|**2025-01-16**|**IFRA: a machine learning-based Instrumented Fall Risk Assessment Scale derived from Instrumented Timed Up and Go test in stroke patients**|Simone MacciÃ² et.al.|[2501.09595v1](http://arxiv.org/abs/2501.09595v1)|null|
|**2025-01-16**|**Understanding Mental Health Content on Social Media and Its Effect Towards Suicidal Ideation**|Mohaiminul Islam Bhuiyan et.al.|[2501.09309v1](http://arxiv.org/abs/2501.09309v1)|null|
|**2025-01-16**|**Interpretable Droplet Digital PCR Assay for Trustworthy Molecular Diagnostics**|Yuanyuan Wei et.al.|[2501.09218v1](http://arxiv.org/abs/2501.09218v1)|null|
|**2025-01-15**|**AutoLoop: Fast Visual SLAM Fine-tuning through Agentic Curriculum Learning**|Assaf Lahiany et.al.|[2501.09160v1](http://arxiv.org/abs/2501.09160v1)|null|
|**2025-01-15**|**Benchmarking Robustness of Contrastive Learning Models for Medical Image-Report Retrieval**|Demetrio Deanda et.al.|[2501.09134v1](http://arxiv.org/abs/2501.09134v1)|null|
|**2025-01-15**|**Generative Medical Image Anonymization Based on Latent Code Projection and Optimization**|Huiyu Li et.al.|[2501.09114v1](http://arxiv.org/abs/2501.09114v1)|[link](https://github.com/huiyu-li/gmia)|
|**2025-01-15**|**Development and Validation of the Provider Documentation Summarization Quality Instrument for Large Language Models**|Emma Croxford et.al.|[2501.08977v2](http://arxiv.org/abs/2501.08977v2)|null|
|**2025-01-15**|**An analysis of data variation and bias in image-based dermatological datasets for machine learning classification**|Francisco Mauro et.al.|[2501.08962v1](http://arxiv.org/abs/2501.08962v1)|null|
|**2025-01-15**|**Improving the Efficiency of Self-Supervised Adversarial Training through Latent Clustering-Based Selection**|Somrita Ghosh et.al.|[2501.10466v1](http://arxiv.org/abs/2501.10466v1)|null|
|**2025-01-15**|**Digital Phenotyping for Adolescent Mental Health: A Feasibility Study Employing Machine Learning to Predict Mental Health Risk From Active and Passive Smartphone Data**|Balasundaram Kadirvelu et.al.|[2501.08851v1](http://arxiv.org/abs/2501.08851v1)|null|
|**2025-01-15**|**Spatio-Temporal Foundation Models: Vision, Challenges, and Opportunities**|Adam Goodge et.al.|[2501.09045v1](http://arxiv.org/abs/2501.09045v1)|null|
|**2025-01-14**|**ADAM-1: AI and Bioinformatics for Alzheimer's Detection and Microbiome-Clinical Data Integrations**|Ziyuan Huang et.al.|[2501.08324v1](http://arxiv.org/abs/2501.08324v1)|null|
|**2025-01-14**|**A Feature-Level Ensemble Model for COVID-19 Identification in CXR Images using Choquet Integral and Differential Evolution Optimization**|Amir Reza Takhsha et.al.|[2501.08241v1](http://arxiv.org/abs/2501.08241v1)|null|
|**2025-01-14**|**ASTRID -- An Automated and Scalable TRIaD for the Evaluation of RAG-based Clinical Question Answering Systems**|Mohita Chowdhury et.al.|[2501.08208v1](http://arxiv.org/abs/2501.08208v1)|null|
|**2025-01-14**|**Potential and Perils of Large Language Models as Judges of Unstructured Textual Data**|Rewina Bedemariam et.al.|[2501.08167v2](http://arxiv.org/abs/2501.08167v2)|null|
|**2025-01-14**|**FairTTTS: A Tree Test Time Simulation Method for Fairness-Aware Classification**|Nurit Cohen-Inger et.al.|[2501.08155v1](http://arxiv.org/abs/2501.08155v1)|[link](https://github.com/nuritci/fairttts)|
|**2025-01-14**|**Guiding the classification of hepatocellular carcinoma on 3D CT-scans using deep and handcrafted radiological features**|E. Sarfati et.al.|[2501.08097v1](http://arxiv.org/abs/2501.08097v1)|null|
|**2025-01-14**|**Exploring visual language models as a powerful tool in the diagnosis of Ewing Sarcoma**|Alvaro Pastor-Naranjo et.al.|[2501.08042v1](http://arxiv.org/abs/2501.08042v1)|null|
|**2025-01-14**|**Comprehensive Metapath-based Heterogeneous Graph Transformer for Gene-Disease Association Prediction**|Wentao Cui et.al.|[2501.07970v1](http://arxiv.org/abs/2501.07970v1)|null|
|**2025-01-14**|**Advice for Diabetes Self-Management by ChatGPT Models: Challenges and Recommendations**|Waqar Hussain et.al.|[2501.07931v1](http://arxiv.org/abs/2501.07931v1)|null|
|**2025-01-13**|**Large Language Models for Interpretable Mental Health Diagnosis**|Brian Hyeongseok Kim et.al.|[2501.07653v1](http://arxiv.org/abs/2501.07653v1)|null|
|**2025-01-13**|**RadAlign: Advancing Radiology Report Generation with Vision-Language Concept Alignment**|Difei Gu et.al.|[2501.07525v1](http://arxiv.org/abs/2501.07525v1)|[link](https://github.com/difeigu/radalign)|
|**2025-01-13**|**A Survey of Embodied AI in Healthcare: Techniques, Applications, and Opportunities**|Yihao Liu et.al.|[2501.07468v1](http://arxiv.org/abs/2501.07468v1)|null|
|**2025-01-13**|**Diff-Ensembler: Learning to Ensemble 2D Diffusion Models for Volume-to-Volume Medical Image Translation**|Xiyue Zhu et.al.|[2501.07430v1](http://arxiv.org/abs/2501.07430v1)|null|
|**2025-01-13**|**Synthetic Data and Health Privacy**|GwÃ©nolÃ© Abgrall et.al.|[2501.09031v1](http://arxiv.org/abs/2501.09031v1)|null|
|**2025-01-13**|**Natural Language-Assisted Multi-modal Medication Recommendation**|Jie Tan et.al.|[2501.07166v1](http://arxiv.org/abs/2501.07166v1)|[link](https://github.com/jtan1102/nla-mmr_cikm_2024)|
|**2025-01-13**|**CureGraph: Contrastive Multi-Modal Graph Representation Learning for Urban Living Circle Health Profiling and Prediction**|Jinlin Li et.al.|[2501.07157v1](http://arxiv.org/abs/2501.07157v1)|[link](https://github.com/jinlin2021/curegraph)|
|**2025-01-13**|**UNetVL: Enhancing 3D Medical Image Segmentation with Chebyshev KAN Powered Vision-LSTM**|Xuhui Guo et.al.|[2501.07017v2](http://arxiv.org/abs/2501.07017v2)|null|
|**2025-01-13**|**Combining LLM decision and RL action selection to improve RL policy for adaptive interventions**|Karine Karine et.al.|[2501.06980v1](http://arxiv.org/abs/2501.06980v1)|null|
|**2025-01-12**|**Enhancing Patient-Centric Communication: Leveraging LLMs to Simulate Patient Perspectives**|Xinyao Ma et.al.|[2501.06964v1](http://arxiv.org/abs/2501.06964v1)|null|
|**2025-01-12**|**MedGrad E-CLIP: Enhancing Trust and Transparency in AI-Driven Skin Lesion Diagnosis**|Sadia Kamal et.al.|[2501.06887v1](http://arxiv.org/abs/2501.06887v1)|null|
|**2025-01-12**|**A Foundational Generative Model for Breast Ultrasound Image Analysis**|Haojun Yu et.al.|[2501.06869v1](http://arxiv.org/abs/2501.06869v1)|null|
|**2025-01-12**|**A Comprehensive Evaluation of Large Language Models on Mental Illnesses in Arabic Context**|Noureldin Zahran et.al.|[2501.06859v1](http://arxiv.org/abs/2501.06859v1)|null|
|**2025-01-12**|**MEXA-CTP: Mode Experts Cross-Attention for Clinical Trial Outcome Prediction**|Yiqing Zhang et.al.|[2501.06823v1](http://arxiv.org/abs/2501.06823v1)|null|
|**2025-01-12**|**PGP-SAM: Prototype-Guided Prompt Learning for Efficient Few-Shot Medical Image Segmentation**|Zhonghao Yan et.al.|[2501.06692v1](http://arxiv.org/abs/2501.06692v1)|null|
|**2025-01-12**|**Imbalanced Medical Image Segmentation with Pixel-dependent Noisy Labels**|Erjian Guo et.al.|[2501.06678v1](http://arxiv.org/abs/2501.06678v1)|[link](https://github.com/erjian96/clcs)|
|**2025-01-11**|**MedCT: A Clinical Terminology Graph for Generative AI Applications in Healthcare**|Ye Chen et.al.|[2501.06465v2](http://arxiv.org/abs/2501.06465v2)|null|
|**2025-01-11**|**Deep Learning on Hester Davis Scores for Inpatient Fall Prediction**|Hojjat Salehinejad et.al.|[2501.06432v1](http://arxiv.org/abs/2501.06432v1)|null|
|**2025-01-10**|**Gender-Neutral Large Language Models for Medical Applications: Reducing Bias in PubMed Abstracts**|Elizabeth Schaefer et.al.|[2501.06365v1](http://arxiv.org/abs/2501.06365v1)|null|
|**2025-01-10**|**Scale-up Unlearnable Examples Learning with High-Performance Computing**|Yanfan Zhu et.al.|[2501.06080v1](http://arxiv.org/abs/2501.06080v1)|[link](https://github.com/hrlblab/ue_hpc)|
|**2025-01-10**|**AI-powered virtual tissues from spatial proteomics for clinical diagnostics and biomedical discovery**|Johann Wenckstern et.al.|[2501.06039v1](http://arxiv.org/abs/2501.06039v1)|[link](https://github.com/bunnelab/virtues)|
|**2025-01-10**|**DiffuSETS: 12-lead ECG Generation Conditioned on Clinical Text Reports and Patient-Specific Information**|Yongfan Lai et.al.|[2501.05932v1](http://arxiv.org/abs/2501.05932v1)|[link](https://github.com/raiiyf/diffusets_exp)|
|**2025-01-10**|**AI-Driven Diabetic Retinopathy Screening: Multicentric Validation of AIDRSS in India**|Amit Kr Dey et.al.|[2501.05826v2](http://arxiv.org/abs/2501.05826v2)|null|
|**2025-01-10**|**Large Language Models for Bioinformatics**|Wei Ruan et.al.|[2501.06271v1](http://arxiv.org/abs/2501.06271v1)|null|
|**2025-01-09**|**From Simple to Complex Skills: The Case of In-Hand Object Reorientation**|Haozhi Qi et.al.|[2501.05439v1](http://arxiv.org/abs/2501.05439v1)|null|
|**2025-01-09**|**Strategy Masking: A Method for Guardrails in Value-based Reinforcement Learning Agents**|Jonathan Keane et.al.|[2501.05501v2](http://arxiv.org/abs/2501.05501v2)|null|
|**2025-01-09**|**Atlas: A Novel Pathology Foundation Model by Mayo Clinic, CharitÃ©, and Aignostics**|Maximilian Alber et.al.|[2501.05409v2](http://arxiv.org/abs/2501.05409v2)|null|
|**2025-01-09**|**An Algorithmic Approach for Causal Health Equity: A Look at Race Differentials in Intensive Care Unit (ICU) Outcomes**|Drago Plecko et.al.|[2501.05197v1](http://arxiv.org/abs/2501.05197v1)|null|
|**2025-01-09**|**Addressing Domain Shift via Imbalance-Aware Domain Adaptation in Embryo Development Assessment**|Lei Li et.al.|[2501.04958v1](http://arxiv.org/abs/2501.04958v1)|[link](https://github.com/yinghemedical/imbalance-aware_domain_adaptation)|
|**2025-01-09**|**Quantifying Itch and its Impact on Sleep Using Machine Learning and Radio Signals**|Michail Ouroutzoglou et.al.|[2501.04896v1](http://arxiv.org/abs/2501.04896v1)|null|
|**2025-01-08**|**MedCoDi-M: A Multi-Prompt Foundation Model for Multimodal Medical Data Generation**|Daniele Molino et.al.|[2501.04614v2](http://arxiv.org/abs/2501.04614v2)|null|
|**2025-01-08**|**A 65 nm Bayesian Neural Network Accelerator with 360 fJ/Sample In-Word GRNG for AI Uncertainty Estimation**|Zephan M. Enciso et.al.|[2501.04577v2](http://arxiv.org/abs/2501.04577v2)|null|
|**2025-01-08**|**Continual Self-supervised Learning Considering Medical Domain Knowledge in Chest CT Images**|Ren Tasai et.al.|[2501.04217v1](http://arxiv.org/abs/2501.04217v1)|null|
|**2025-01-07**|**Generative Style Transfer for MRI Image Segmentation: A Case of Glioma Segmentation in Sub-Saharan Africa**|Rancy Chepchirchir et.al.|[2501.04734v1](http://arxiv.org/abs/2501.04734v1)|[link](https://github.com/CAMERA-MRI/SPARK2023/tree/main/SPARK_BTS_KIFARU)|
|**2025-01-07**|**Exploring the Potential of Large Language Models in Public Transportation: San Antonio Case Study**|Ramya Jonnala et.al.|[2501.03904v1](http://arxiv.org/abs/2501.03904v1)|null|
|**2025-01-07**|**SCC-YOLO: An Improved Object Detector for Assisting in Brain Tumor Diagnosis**|Runci Bai et.al.|[2501.03836v2](http://arxiv.org/abs/2501.03836v2)|null|
|**2025-01-07**|**SelectiveFinetuning: Enhancing Transfer Learning in Sleep Staging through Selective Domain Alignment**|Siyuan Zhao et.al.|[2501.03764v1](http://arxiv.org/abs/2501.03764v1)|null|
|**2025-01-07**|**Self-adaptive vision-language model for 3D segmentation of pulmonary artery and vein**|Xiaotong Guo et.al.|[2501.03722v1](http://arxiv.org/abs/2501.03722v1)|null|
|**2025-01-07**|**Can Deep Learning Trigger Alerts from Mobile-Captured Images?**|Pritisha Sarkar et.al.|[2501.03499v1](http://arxiv.org/abs/2501.03499v1)|null|
|**2025-01-07**|**Activating Associative Disease-Aware Vision Token Memory for LLM-Based X-ray Report Generation**|Xiao Wang et.al.|[2501.03458v1](http://arxiv.org/abs/2501.03458v1)|[link](https://github.com/event-ahu/medical_image_analysis)|
|**2025-01-06**|**Existential Crisis: A Social Robot's Reason for Being**|Dora Medgyesy et.al.|[2501.03376v1](http://arxiv.org/abs/2501.03376v1)|null|
|**2025-01-06**|**Label-free Concept Based Multiple Instance Learning for Gigapixel Histopathology**|Susu Sun et.al.|[2501.02922v1](http://arxiv.org/abs/2501.02922v1)|null|

#### Abstracts
##### **Estimating the Conformal Prediction Threshold from Noisy Labels**
2501.12749v1 by Coby Penso, Jacob Goldberger, Ethan Fetaya

Conformal Prediction (CP) is a method to control prediction uncertainty by
producing a small prediction set, ensuring a predetermined probability that the
true class lies within this set. This is commonly done by defining a score,
based on the model predictions, and setting a threshold on this score using a
validation set. In this study, we address the problem of CP calibration when we
only have access to a validation set with noisy labels. We show how we can
estimate the noise-free conformal threshold based on the noisy labeled data.
Our solution is flexible and can accommodate various modeling assumptions
regarding the label contamination process, without needing any information
about the underlying data distribution or the internal mechanisms of the
machine learning classifier. We develop a coverage guarantee for uniform noise
that is effective even in tasks with a large number of classes. We dub our
approach Noise-Aware Conformal Prediction (NACP) and show on several natural
and medical image classification datasets, including ImageNet, that it
significantly outperforms current noisy label methods and achieves results
comparable to those obtained with a clean validation set.

æè¦ï¼å±å½¢é¢æµ (CP) æ¯ä¸ç¨®ééç¢çä¸åå°åé æ¸¬éåä¾æ§å¶é æ¸¬ä¸ç¢ºå®æ§çæ¹æ³ï¼ç¢ºä¿çæ­£çé¡å¥è½å¨éåéåå§çé åç¢ºå®çæ©çãééå¸¸æ¯ééå®ç¾©ä¸ååºæ¼æ¨¡åé æ¸¬çåæ¸ä¾å®æï¼ä¸¦ä½¿ç¨é©è­éåå°éååæ¸è¨­å®ä¸åé¾å¼ãå¨æ¬ç ç©¶ä¸­ï¼æåæ¢è¨äºç¶æååªè½å­åå·æéè¨æ¨ç±¤çé©è­éåæï¼CP æ ¡æ­£çåé¡ãæåå±ç¤ºäºå¦ä½æ ¹æéè¨æ¨ç±¤è³æä¼°è¨ç¡éè¨çå±å½¢é¾å¼ãæåçè§£æ±ºæ¹æ¡å·æå½æ§ï¼ä¸¦ä¸å¯ä»¥é©æéæ¼æ¨ç±¤æ±¡æéç¨çåç¨®å»ºæ¨¡åè¨­ï¼èä¸éè¦ä»»ä½éæ¼åºå±¤è³æåä½ææ©å¨å­¸ç¿åé¡å¨å§é¨æ©å¶çè³è¨ãæåéç¼äºä¸åå°æ¼åå»éè¨çè¦èä¿è­ï¼å³ä½¿å¨å·æå¤§éé¡å¥çä»»åä¸­ä¹å¾ææãæåå°æåçåæ³ç¨±çºéè¨æç¥å±å½¢é æ¸¬ (NACP)ï¼ä¸¦å¨å¹¾åèªç¶åé«å­¸å½±ååé¡è³æéï¼åæ¬ ImageNetï¼ä¸å±ç¤ºäºå®é¡¯èåªæ¼ç®åçéè¨æ¨ç±¤æ¹æ³ï¼ä¸¦ä¸éå°äºèä½¿ç¨ä¹¾æ·¨é©è­éåç²å¾ççµæç¸ç¶ççµæã

##### **Academic Case Reports Lack Diversity: Assessing the Presence and Diversity of Sociodemographic and Behavioral Factors related with Post COVID-19 Condition**
2501.12538v1 by Juan Andres Medina Florez, Shaina Raza, Rashida Lynn, Zahra Shakeri, Brendan T. Smith, Elham Dolatabadi

Understanding the prevalence, disparities, and symptom variations of Post
COVID-19 Condition (PCC) for vulnerable populations is crucial to improving
care and addressing intersecting inequities. This study aims to develop a
comprehensive framework for integrating social determinants of health (SDOH)
into PCC research by leveraging NLP techniques to analyze disparities and
variations in SDOH representation within PCC case reports. Following
construction of a PCC Case Report Corpus, comprising over 7,000 case reports
from the LitCOVID repository, a subset of 709 reports were annotated with 26
core SDOH-related entity types using pre-trained named entity recognition (NER)
models, human review, and data augmentation to improve quality, diversity and
representation of entity types. An NLP pipeline integrating NER, natural
language inference (NLI), trigram and frequency analyses was developed to
extract and analyze these entities. Both encoder-only transformer models and
RNN-based models were assessed for the NER objective.
  Fine-tuned encoder-only BERT models outperformed traditional RNN-based models
in generalizability to distinct sentence structures and greater class sparsity.
Exploratory analysis revealed variability in entity richness, with prevalent
entities like condition, age, and access to care, and underrepresentation of
sensitive categories like race and housing status. Trigram analysis highlighted
frequent co-occurrences among entities, including age, gender, and condition.
The NLI objective (entailment and contradiction analysis) showed attributes
like "Experienced violence or abuse" and "Has medical insurance" had high
entailment rates (82.4%-80.3%), while attributes such as "Is
female-identifying," "Is married," and "Has a terminal condition" exhibited
high contradiction rates (70.8%-98.5%).

æè¦ï¼<paragraph>äºè§£å¼±å¢ç¾¤é«çå¾ COVID-19 çæ³ (PCC) çæµè¡çãå·®ç°åççè®åå°æ¼æ¹åç§è­·åè§£æ±ºäº¤åä¸å¹³ç­è³ééè¦ãæ¬ç ç©¶æ¨å¨ééå©ç¨èªç¶èªè¨èçæè¡åæ PCC çä¾å ±åä¸­ SDOH çè¡¨ç¾å·®ç°åè®åï¼éç¼ä¸åæ´åå¥åº·ç¤¾ææ±ºå®å ç´  (SDOH) é²å¥ PCC ç ç©¶çç¶åæ¶æ§ãå¨å»ºæ§ä¸å PCC çä¾å ±åèªæåº«ï¼åå«ä¾èª LitCOVID è³æåº«ç 7,000 å¤åçä¾å ±åï¼å¾ï¼ä½¿ç¨é åè¨ç·´çåç¨±å¯¦é«è¾¨è­ (NER) æ¨¡åãäººå·¥å¯©æ¥åè³ææ´åå° 709 ä»½å ±åé²è¡è¨»è§£ï¼å¶ä¸­åå« 26 åæ ¸å¿ SDOH ç¸éå¯¦é«é¡åï¼ä»¥æé«å¯¦é«é¡åçåè³ªãå¤æ¨£æ§åè¡¨ç¾ãéç¼äºä¸åæ´å NERãèªç¶èªè¨æ¨è« (NLI)ãä¸åçµåé »çåæç NLP ç®¡ç·ï¼ä»¥èåååæéäºå¯¦é«ãéå° NER ç®æ¨è©ä¼°äºåç·¨ç¢¼å¨è½æå¨æ¨¡åååºæ¼ RNN çæ¨¡åãå¾®èª¿å¾çåç·¨ç¢¼å¨ BERT æ¨¡åå¨ä¸è¬åå°ä¸åçå¥å­çµæ§åæ´å¤§çé¡å¥ç¨çæ§æ¹é¢åªæ¼å³çµ±çåºæ¼ RNN çæ¨¡åãæ¢ç´¢æ§åæé¡¯ç¤ºå¯¦é«è±å¯åº¦å­å¨è®ç°æ§ï¼æ®éçå¯¦é«åæ¬çæ³ãå¹´é½¡ååå¾ç§è­·çç®¡éï¼èç¨®æåå±ä½çæ³ç­ææé¡å¥çè¡¨ç¾åä¸è¶³ãä¸åçµåæå¼·èª¿äºå¯¦é«ä¹éçé »ç¹å±ç¾ï¼åæ¬å¹´é½¡ãæ§å¥åçæ³ãNLI ç®æ¨ï¼èæ¶µåçç¾åæï¼é¡¯ç¤ºãç¶æ­·éæ´åæèå¾ãåãæé«çä¿éªãç­å±¬æ§å·æå¾é«çèæ¶µçï¼82.4%-80.3%ï¼ï¼èãèªåèªå·±æ¯å¥³æ§ãããå·²å©ãåãææ«æç¾çãç­å±¬æ§åè¡¨ç¾åºå¾é«ççç¾çï¼70.8%-98.5%ï¼ã</paragraph>

##### **Efficient Lung Ultrasound Severity Scoring Using Dedicated Feature Extractor**
2501.12524v1 by Jiaqi Guo, Yunnan Wu, Evangelos Kaimakamis, Georgios Petmezas, Vasileios E. Papageorgiou, Nicos Maglaveras, Aggelos K. Katsaggelos

With the advent of the COVID-19 pandemic, ultrasound imaging has emerged as a
promising technique for COVID-19 detection, due to its non-invasive nature,
affordability, and portability. In response, researchers have focused on
developing AI-based scoring systems to provide real-time diagnostic support.
However, the limited size and lack of proper annotation in publicly available
ultrasound datasets pose significant challenges for training a robust AI model.
This paper proposes MeDiVLAD, a novel pipeline to address the above issue for
multi-level lung-ultrasound (LUS) severity scoring. In particular, we leverage
self-knowledge distillation to pretrain a vision transformer (ViT) without
label and aggregate frame-level features via dual-level VLAD aggregation. We
show that with minimal finetuning, MeDiVLAD outperforms conventional
fully-supervised methods in both frame- and video-level scoring, while offering
classification reasoning with exceptional quality. This superior performance
enables key applications such as the automatic identification of critical lung
pathology areas and provides a robust solution for broader medical video
classification tasks.

æè¦ï¼é¨è COVID-19 å¤§æµè¡çå°ä¾ï¼è¶é³æ³¢å½±åå·²æçºä¸ç¨®æåéç COVID-19 æª¢æ¸¬æè¡ï¼å çºå®å·æéä¾µå¥æ§ãå¹æ ¼å¯¦æ ä¸å¯æå¸¶ç­ç¹æ§ãæéæ¼æ­¤ï¼ç ç©¶äººå¡å°æ³¨æ¼éç¼åºæ¼ AI çè©åç³»çµ±ï¼ä»¥æä¾å³æçè¨ºæ·æ¯æ´ãç¶èï¼å¬éå¯ç¨çè¶é³æ³¢è³æéè¦æ¨¡æéä¸ç¼ºä¹é©ç¶çè¨»è§£ï¼éå°è¨ç·´ç©©å¥ç AI æ¨¡åæ§æéå¤§ææ°ãæ¬ææåº MeDiVLADï¼éæ¯ä¸ç¨®æ°ç©çç®¡éï¼ç¨æ¼è§£æ±ºä¸è¿°å¤å±¤ç´èºé¨è¶é³æ³¢ (LUS) å´éåº¦è©åçè­°é¡ãå·é«ä¾èªªï¼æåå©ç¨èªæç¥è­è¸é¤¾æè¡ï¼å¨æ²ææ¨ç±¤çææ³ä¸é è¨ç·´è¦è¦ºè½æå¨ (ViT)ï¼ä¸¦éééå±¤ç´ VLAD èåä¾å½ç¸½å¹ç´ç¹å¾µãæåè­æï¼ééæå°çå¾®èª¿ï¼MeDiVLAD å¨å¹ç´åå½±çç´è©åä¸­é½åªæ¼å³çµ±çå¨ç£ç£å¼æ¹æ³ï¼åææä¾åè³ªæ¥µä½³çåé¡æ¨çãéç¨®åªç°çæè½æ¯æ´äºééµæç¨ï¼ä¾å¦èªåè­å¥èºé¨çç¶ååï¼ä¸¦çºæ´å»£æ³çé«å­¸å½±çåé¡ä»»åæä¾ç©©å¥çè§£æ±ºæ¹æ¡ã

##### **FuocChuVIP123 at CoMeDi Shared Task: Disagreement Ranking with XLM-Roberta Sentence Embeddings and Deep Neural Regression**
2501.12336v1 by Phuoc Duong Huy Chu

This paper presents results of our system for CoMeDi Shared Task, focusing on
Subtask 2: Disagreement Ranking. Our system leverages sentence embeddings
generated by the paraphrase-xlm-r-multilingual-v1 model, combined with a deep
neural regression model incorporating batch normalization and dropout for
improved generalization. By predicting the mean of pairwise judgment
differences between annotators, our method explicitly targets disagreement
ranking, diverging from traditional "gold label" aggregation approaches. We
optimized our system with a customized architecture and training procedure,
achieving competitive performance in Spearman correlation against mean
disagreement labels. Our results highlight the importance of robust embeddings,
effective model architecture, and careful handling of judgment differences for
ranking disagreement in multilingual contexts. These findings provide insights
into the use of contextualized representations for ordinal judgment tasks and
open avenues for further refinement of disagreement prediction models.

æè¦ï¼æ¬æå±ç¤ºäºæåå¨ CoMeDi å±äº«ä»»åç³»çµ±ä¸­ççµæï¼éé»å¨
å­ä»»å 2ï¼åæ­§æåãæåçç³»çµ±å©ç¨ paraphrase-xlm-r-multilingual-v1 æ¨¡åç¢ççå¥å­åµå¥ï¼çµåæ·±åº¦
ç¥ç¶è¿´æ­¸æ¨¡åï¼ä¸¦å å¥æ¹æ¬¡æ­£è¦ååä¸­æ·ä»¥æ¹åæ¦åãééé æ¸¬è¨»è§£èä¹éæå°å¤æ·å·®ç°çå¹³åå¼ï¼æåç
æ¹æ³æç¢ºéå°åæ­§æåï¼åé¢å³çµ±çãé»éæ¨ç±¤ãèåæ¹æ³ãæåä½¿ç¨èªè¨æ¶æ§åè¨ç·´ç¨åºåªåç³»çµ±ï¼
å¨èå¹³ååæ­§æ¨ç±¤ç Spearman ç¸éæ§ä¸­ç²å¾ç«¶ç­åè¡¨ç¾ãæåççµæå¼·èª¿äºç©©å¥åµå¥ãæææ¨¡åæ¶æ§å
è¬¹æèçå¤æ·å·®ç°å°æ¼å¨å¤èªè¨ç°å¢ä¸­å°åæ­§é²è¡æåçéè¦æ§ãéäºç¼ç¾æä¾äºä½¿ç¨æå¢åè¡¨å¾µé²è¡åºæ¸å¤æ·ä»»åçè¦è§£ï¼ä¸¦çºé²ä¸æ­¥åªååæ­§é æ¸¬æ¨¡åéé¢äºéè·¯ã

##### **CBVLM: Training-free Explainable Concept-based Large Vision Language Models for Medical Image Classification**
2501.12266v1 by Cristiano PatrÃ­cio, Isabel Rio-Torto, Jaime S. Cardoso, LuÃ­s F. Teixeira, JoÃ£o C. Neves

The main challenges limiting the adoption of deep learning-based solutions in
medical workflows are the availability of annotated data and the lack of
interpretability of such systems. Concept Bottleneck Models (CBMs) tackle the
latter by constraining the final disease prediction on a set of predefined and
human-interpretable concepts. However, the increased interpretability achieved
through these concept-based explanations implies a higher annotation burden.
Moreover, if a new concept needs to be added, the whole system needs to be
retrained. Inspired by the remarkable performance shown by Large
Vision-Language Models (LVLMs) in few-shot settings, we propose a simple, yet
effective, methodology, CBVLM, which tackles both of the aforementioned
challenges. First, for each concept, we prompt the LVLM to answer if the
concept is present in the input image. Then, we ask the LVLM to classify the
image based on the previous concept predictions. Moreover, in both stages, we
incorporate a retrieval module responsible for selecting the best examples for
in-context learning. By grounding the final diagnosis on the predicted
concepts, we ensure explainability, and by leveraging the few-shot capabilities
of LVLMs, we drastically lower the annotation cost. We validate our approach
with extensive experiments across four medical datasets and twelve LVLMs (both
generic and medical) and show that CBVLM consistently outperforms CBMs and
task-specific supervised methods without requiring any training and using just
a few annotated examples. More information on our project page:
https://cristianopatricio.github.io/CBVLM/.

æè¦ï¼éå¶å¨é«çå·¥ä½æµç¨ä¸­æ¡ç¨åºæ¼æ·±åº¦å­¸ç¿çè§£æ±ºæ¹æ¡çä¸»è¦ææ°æ¯æ¨è¨è³æçå¯ç¨æ§ä»¥åæ­¤é¡ç³»çµ±çå¯è§£éæ§ä¸è¶³ãæ¦å¿µç¶é ¸æ¨¡å (CBM) éééå¶ä¸çµé å®ç¾©ä¸äººé¡å¯è§£éçæ¦å¿µå°æçµç¾çé æ¸¬ï¼ä¾è§£æ±ºå¾èãç¶èï¼éééäºåºæ¼æ¦å¿µçè§£éæå¯¦ç¾çå¯è§£éæ§æåï¼æå³èæ´é«çæ¨è¨è² æãæ­¤å¤ï¼å¦æéè¦æ°å¢ä¸åæ°æ¦å¿µï¼åéè¦éæ°è¨ç·´æ´åç³»çµ±ãåå°å¤§åè¦è¦ºèªè¨æ¨¡å (LVLMs) å¨å°æ¨£æ¬è¨­å®ä¸­å±ç¾çåè¶æè½åç¼ï¼æåæåºäºä¸åç°¡å®ä½ææç CBVLM æ¹æ³ï¼ä¾è§£æ±ºä¸è¿°å©åææ°ãé¦åï¼å°æ¼æ¯åæ¦å¿µï¼æåæç¤º LVLM åç­è¼¸å¥å½±åä¸­æ¯å¦åå«è©²æ¦å¿µãç¶å¾ï¼æåè¦æ± LVLM æ ¹æååçæ¦å¿µé æ¸¬å°å½±åé²è¡åé¡ãæ­¤å¤ï¼å¨å©åéæ®µä¸­ï¼æåé½ç´å¥ä¸åæª¢ç´¢æ¨¡çµï¼è² è²¬é¸åºæé©åæ¼æå¢å­¸ç¿çç¯ä¾ãééå°æçµè¨ºæ·å»ºç«å¨é æ¸¬æ¦å¿µä¹ä¸ï¼æåç¢ºä¿äºå¯è§£éæ§ï¼ä¸¦ééå©ç¨ LVLMs çå°æ¨£æ¬è½åï¼æåå¤§å¹éä½äºæ¨è¨ææ¬ãæåééååé«çè³æéååäºå LVLMï¼éç¨åé«çï¼çå»£æ³å¯¦é©é©è­äºæåçä½æ³ï¼ä¸¦é¡¯ç¤º CBVLM å¨ç¡éä»»ä½è¨ç·´ä¸åä½¿ç¨å°æ¸æ¨è¨ç¯ä¾çææ³ä¸ï¼å§çµåªæ¼ CBM åç¹å®æ¼ä»»åçç£ç£å¼æ¹æ³ãæ´å¤è³è¨è«è¦æåçå°æ¡é é¢ï¼https://cristianopatricio.github.io/CBVLM/ã

##### **Can open source large language models be used for tumor documentation in Germany? -- An evaluation on urological doctors' notes**
2501.12106v1 by Stefan Lenz, Arsenij Ustjanzew, Marco Jeray, Torsten Panholzer

Tumor documentation in Germany is largely done manually, requiring reading
patient records and entering data into structured databases. Large language
models (LLMs) could potentially enhance this process by improving efficiency
and reliability. This evaluation tests eleven different open source LLMs with
sizes ranging from 1-70 billion model parameters on three basic tasks of the
tumor documentation process: identifying tumor diagnoses, assigning ICD-10
codes, and extracting the date of first diagnosis. For evaluating the LLMs on
these tasks, a dataset of annotated text snippets based on anonymized doctors'
notes from urology was prepared. Different prompting strategies were used to
investigate the effect of the number of examples in few-shot prompting and to
explore the capabilities of the LLMs in general. The models Llama 3.1 8B,
Mistral 7B, and Mistral NeMo 12 B performed comparably well in the tasks.
Models with less extensive training data or having fewer than 7 billion
parameters showed notably lower performance, while larger models did not
display performance gains. Examples from a different medical domain than
urology could also improve the outcome in few-shot prompting, which
demonstrates the ability of LLMs to handle tasks needed for tumor
documentation. Open source LLMs show a strong potential for automating tumor
documentation. Models from 7-12 billion parameters could offer an optimal
balance between performance and resource efficiency. With tailored fine-tuning
and well-designed prompting, these models might become important tools for
clinical documentation in the future. The code for the evaluation is available
from https://github.com/stefan-m-lenz/UroLlmEval. We also release the dataset
as a new valuable resource that addresses the shortage of authentic and easily
accessible benchmarks in German-language medical NLP.

æè¦ï¼å¾·åçè«ç¤æä»¶è¨éå¤§é¨åæ¯æåå®æï¼éè¦é±è®çæ­·ä¸¦å°è³æè¼¸å¥çµæ§åçè³æåº«ä¸­ãå¤§åèªè¨æ¨¡å (LLM) å¯è½ééæåæçåå¯é æ§ä¾å¢å¼·æ­¤ç¨åºãæ­¤è©éæ¸¬è©¦äº 11 åä¸åçéæº LLMï¼æ¨¡ååæ¸å¤§å°å¾ 10 åå° 700 åä¸ç­ï¼éå°è«ç¤æä»¶è¨éç¨åºçä¸é åºæ¬ä»»åï¼è­å¥è«ç¤è¨ºæ·ãæå® ICD-10 ä»£ç¢¼ï¼ä»¥åæ·åé¦æ¬¡è¨ºæ·æ¥æãçºäºéå°éäºä»»åè©ä¼° LLMï¼æºåäºä¸ååºæ¼æ³å°¿ç§é«çå¿åç­è¨çè¨»è§£æå­çæ®µè³æéãä½¿ç¨ä¸åçæç¤ºç­ç¥ä¾èª¿æ¥å°éæç¤ºä¸­ç¯ä¾æ¸éçå½±é¿ï¼ä¸¦æ¢ç´¢ LLM çä¸è¬è½åãLlama 3.1 8BãMistral 7B å Mistral NeMo 12 B ç­æ¨¡åå¨éäºä»»åä¸­è¡¨ç¾ç¸ç¶å¥½ãè¨ç·´è³æè¼å°æåæ¸å°æ¼ 70 åçæ¨¡åè¡¨ç¾æé¡¯è¼å·®ï¼èè¼å¤§çæ¨¡åä¸¦æªå±ç¾æè½æåãèæ³å°¿ç§ä¸åçé«çé åçç¯ä¾ä¹å¯ä»¥æ¹åå°éæç¤ºççµæï¼éè­æäº LLM èçè«ç¤æä»¶è¨éæéä»»åçè½åãéæº LLM å¨èªååè«ç¤æä»¶è¨éæ¹é¢é¡¯ç¤ºåºå¼·å¤§çæ½åãåæ¸ä»æ¼ 70 åå° 120 åçæ¨¡åå¯ä»¥å¨æè½åè³æºæçä¹éæä¾æä½³å¹³è¡¡ãéééèº«æé å¾®èª¿åç²¾å¿è¨­è¨çæç¤ºï¼éäºæ¨¡åæªä¾å¯è½ææçºè¨åºæä»¶è¨éçéè¦å·¥å·ãè©ä¼°ç¨å¼ç¢¼å¯å¾ https://github.com/stefan-m-lenz/UroLlmEval åå¾ãæåä¹éåºè³æéä½çºä¸åæ°çæå¹å¼è³æºï¼ç¨æ¼è§£æ±ºå¾·èªé«çèªç¶èªè¨èçä¸­çå¯¦ä¸ææ¼åå¾çåºæºç­ç¼ºåé¡ã

##### **Multi-stage intermediate fusion for multimodal learning to classify non-small cell lung cancer subtypes from CT and PET**
2501.12425v1 by Fatih Aksu, Fabrizia Gelardi, Arturo Chiti, Paolo Soda

Accurate classification of histological subtypes of non-small cell lung
cancer (NSCLC) is essential in the era of precision medicine, yet current
invasive techniques are not always feasible and may lead to clinical
complications. This study presents a multi-stage intermediate fusion approach
to classify NSCLC subtypes from CT and PET images. Our method integrates the
two modalities at different stages of feature extraction, using voxel-wise
fusion to exploit complementary information across varying abstraction levels
while preserving spatial correlations. We compare our method against unimodal
approaches using only CT or PET images to demonstrate the benefits of modality
fusion, and further benchmark it against early and late fusion techniques to
highlight the advantages of intermediate fusion during feature extraction.
Additionally, we compare our model with the only existing intermediate fusion
method for histological subtype classification using PET/CT images. Our results
demonstrate that the proposed method outperforms all alternatives across key
metrics, with an accuracy and AUC equal to 0.724 and 0.681, respectively. This
non-invasive approach has the potential to significantly improve diagnostic
accuracy, facilitate more informed treatment decisions, and advance
personalized care in lung cancer management.

æè¦ï¼å¨ç²¾æºé«ççæä»£ï¼æºç¢ºåé¡éå°ç´°èèºç (NSCLC) ççµç¹å­¸äºåè³ééè¦ï¼ä½ç®åçä¾µå¥æ§æè¡ä¸¦ä¸ç¸½æ¯å¯è¡ï¼ä¸å¯è½æå°è´è¨åºä½µç¼çãæ¬ç ç©¶æåºäºä¸ç¨®å¤éæ®µä¸­éèåæ¹æ³ï¼å¾é»è¦æ·å±¤ (CT) åæ­£å­æ·å±¤ææ (PET) å½±åä¸­åé¡ NSCLC äºåãæåçæè¡å¨ç¹å¾µèåçä¸åéæ®µæ´åéå©ç¨®æ¹å¼ï¼å©ç¨éé«ç´ èåä¾å©ç¨ä¸åæ½è±¡å±¤ç´çäºè£è³è¨ï¼åæä¿çç©ºéç¸éæ§ãæåå°æåçæè¡èåä½¿ç¨é»è¦æ·å±¤ææ­£å­æ·å±¤ææå½±åçå®ä¸æ¨¡å¼æ¹æ³é²è¡æ¯è¼ï¼ä»¥è­ææ¨¡å¼èåçåªé»ï¼ä¸¦é²ä¸æ­¥å°å¶èæ©æåææèåæè¡é²è¡æ¯è¼ï¼ä»¥å¼·èª¿ç¹å¾µèåæéä¸­éèåçåªé»ãæ­¤å¤ï¼æåå°æåçæ¨¡åèå¯ä¸ç¾æçä¸­éèåæ¹æ³é²è¡æ¯è¼ï¼è©²æ¹æ³ä½¿ç¨æ­£å­æ·å±¤ææ/é»è¦æ·å±¤ææå½±åé²è¡çµç¹å­¸äºååé¡ãæåççµæè¡¨æï¼ææåºçæ¹æ³å¨æææ¿ä»£æ¹æ¡ä¸­è¡¨ç¾åªç°ï¼æºç¢ºçå AUC åå¥ç­æ¼ 0.724 å 0.681ãéç¨®éä¾µå¥æ§æ¹æ³æå¯è½é¡¯èæé«è¨ºæ·æºç¢ºçï¼ä¿é²æ´ææºçæ²»çæ±ºç­ï¼ä¸¦æ¨é²èºçç®¡çä¸­çåäººåç§è­·ã

##### **Adaptive Class Learning to Screen Diabetic Disorders in Fundus Images of Eye**
2501.12048v1 by Shramana Dey, Pallabi Dutta, Riddhasree Bhattacharyya, Surochita Pal, Sushmita Mitra, Rajiv Raman

The prevalence of ocular illnesses is growing globally, presenting a
substantial public health challenge. Early detection and timely intervention
are crucial for averting visual impairment and enhancing patient prognosis.
This research introduces a new framework called Class Extension with Limited
Data (CELD) to train a classifier to categorize retinal fundus images. The
classifier is initially trained to identify relevant features concerning
Healthy and Diabetic Retinopathy (DR) classes and later fine-tuned to adapt to
the task of classifying the input images into three classes: Healthy, DR, and
Glaucoma. This strategy allows the model to gradually enhance its
classification capabilities, which is beneficial in situations where there are
only a limited number of labeled datasets available. Perturbation methods are
also used to identify the input image characteristics responsible for
influencing the models decision-making process. We achieve an overall accuracy
of 91% on publicly available datasets.

æè¦ï¼å¨çç¼ç¾æ£ççæçºä¸åï¼å°å¬å±è¡çé æéå¤§ææ°ãæ©æç¼ç¾ååæå¹²é å°æ¼é é²è¦åéç¤åæ¹åæ£èé å¾è³ééè¦ãæ¬ç ç©¶æåºäºä¸ååçºæéæ¸æé¡å¥æ´å± (CELD) çæ°æ¡æ¶ï¼ç¨æ¼è¨ç·´åé¡å¨å°è¦ç¶²èç¼åºååé²è¡åé¡ãè©²åé¡å¨æåæ¥åè¨ç·´ä»¥è­å¥èå¥åº·åç³å°¿çè¦ç¶²èçè® (DR) é¡å¥ç¸éçç¹å¾µï¼ç¶å¾é²è¡å¾®èª¿ä»¥é©æå°è¼¸å¥åååé¡çºä¸é¡çä»»åï¼å¥åº·ãDR åéåç¼ãæ­¤ç­ç¥åè¨±æ¨¡åéæ­¥å¢å¼·å¶åé¡è½åï¼éå¨æ¨è¨æ¸æéæ¸éæéçææ³ä¸æ¯æççãæ¾åæ¹æ³ä¹ç¨æ¼è­å¥è² è²¬å½±é¿æ¨¡åæ±ºç­éç¨çè¼¸å¥ååç¹å¾µãæåå¨å¬éæ¸æéä¸å¯¦ç¾äº 91% çæ´é«æºç¢ºåº¦ã

##### **Tackling Small Sample Survival Analysis via Transfer Learning: A Study of Colorectal Cancer Prognosis**
2501.12421v1 by Yonghao Zhao, Changtao Li, Chi Shu, Qingbin Wu, Hong Li, Chuan Xu, Tianrui Li, Ziqiang Wang, Zhipeng Luo, Yazhou He

Survival prognosis is crucial for medical informatics. Practitioners often
confront small-sized clinical data, especially cancer patient cases, which can
be insufficient to induce useful patterns for survival predictions. This study
deals with small sample survival analysis by leveraging transfer learning, a
useful machine learning technique that can enhance the target analysis with
related knowledge pre-learned from other data. We propose and develop various
transfer learning methods designed for common survival models. For parametric
models such as DeepSurv, Cox-CC (Cox-based neural networks), and DeepHit
(end-to-end deep learning model), we apply standard transfer learning
techniques like pretraining and fine-tuning. For non-parametric models such as
Random Survival Forest, we propose a new transfer survival forest (TSF) model
that transfers tree structures from source tasks and fine-tunes them with
target data. We evaluated the transfer learning methods on colorectal cancer
(CRC) prognosis. The source data are 27,379 SEER CRC stage I patients, and the
target data are 728 CRC stage I patients from the West China Hospital. When
enhanced by transfer learning, Cox-CC's $C^{td}$ value was boosted from 0.7868
to 0.8111, DeepHit's from 0.8085 to 0.8135, DeepSurv's from 0.7722 to 0.8043,
and RSF's from 0.7940 to 0.8297 (the highest performance). All models trained
with data as small as 50 demonstrated even more significant improvement.
Conclusions: Therefore, the current survival models used for cancer prognosis
can be enhanced and improved by properly designed transfer learning techniques.
The source code used in this study is available at
https://github.com/YonghaoZhao722/TSF.

æè¦ï¼<paragraph>å­æ´»é æ¸¬å°é«çè³è¨å­¸è³ééè¦ãå¯¦åå·¥ä½èç¶å¸¸é¢å°å°è¦æ¨¡çè¨åºè³æï¼ç¹å¥æ¯çççæ£åæ¡ï¼éäºè³æå¯è½ä¸è¶³ä»¥èªç¼æç¨çæ¨¡å¼ä¾é²è¡å­æ´»é æ¸¬ãæ­¤ç ç©¶ééå©ç¨è½ç§»å­¸ç¿ä¾èçå°æ¨£æ¬å­æ´»åæï¼éæ¯ä¸ç¨®æç¨çæ©å¨å­¸ç¿æè¡ï¼å¯ä»¥ééå¾å¶ä»è³æé åå­¸ç¿å°çç¸éç¥è­ä¾å¢å¼·ç®æ¨åæãæåæåºä¸¦éç¼åç¨®å°çºå¸¸è¦å­æ´»æ¨¡åè¨­è¨çè½ç§»å­¸ç¿æ¹æ³ãå°æ¼åæ¸åæ¨¡åï¼ä¾å¦ DeepSurvãCox-CCï¼åºæ¼ Cox çç¥ç¶ç¶²è·¯ï¼å DeepHitï¼ç«¯å°ç«¯æ·±åº¦å­¸ç¿æ¨¡åï¼ï¼æåæç¨æ¨æºè½ç§»å­¸ç¿æè¡ï¼ä¾å¦é è¨ç·´åå¾®èª¿ãå°æ¼éåæ¸åæ¨¡åï¼ä¾å¦é¨æ©å­æ´»æ£®æï¼æåæåºä¸åæ°çè½ç§»å­æ´»æ£®æï¼TSFï¼æ¨¡åï¼å®å¾ä¾æºä»»åå³è¼¸æ¨¹ççµæ§ï¼ä¸¦ä½¿ç¨ç®æ¨è³æå¾®èª¿å®åãæåå¨çµç´è¸çï¼CRCï¼é å¾ä¸è©ä¼°äºè½ç§»å­¸ç¿æ¹æ³ãä¾æºè³æçº 27,379 å SEER CRC ç¬¬ä¸ææ£èï¼ç®æ¨è³æçºä¾èªä¸­åè¥¿é¨é«é¢ç 728 å CRC ç¬¬ä¸ææ£èãå¨ééè½ç§»å­¸ç¿å¢å¼·å¾ï¼Cox-CC ç $C^{td}$ å¼å¾ 0.7868 æåå° 0.8111ï¼DeepHit çå¾ 0.8085 æåå° 0.8135ï¼DeepSurv çå¾ 0.7722 æåå° 0.8043ï¼RSF çå¾ 0.7940 æåå° 0.8297ï¼æé«æè½ï¼ãææä»¥å°è³ 50 çè³æè¨ç·´çæ¨¡åé½å±ç¤ºåºæ´é¡¯èçé²æ­¥ãçµè«ï¼å æ­¤ï¼ç®åç¨æ¼ççé å¾çå­æ´»æ¨¡åå¯ä»¥ééé©ç¶è¨­è¨çè½ç§»å­¸ç¿æè¡ä¾å¢å¼·åæ¹åãæ¬ç ç©¶ä¸­ä½¿ç¨çåå§ç¢¼å¯å¨ https://github.com/YonghaoZhao722/TSF åå¾ã</paragraph>

##### **Data-driven Detection and Evaluation of Damages in Concrete Structures: Using Deep Learning and Computer Vision**
2501.11836v1 by Saeid Ataei, Saeed Adibnazari, Seyyed Taghi Ataei

Structural integrity is vital for maintaining the safety and longevity of
concrete infrastructures such as bridges, tunnels, and walls. Traditional
methods for detecting damages like cracks and spalls are labor-intensive,
time-consuming, and prone to human error. To address these challenges, this
study explores advanced data-driven techniques using deep learning for
automated damage detection and analysis. Two state-of-the-art instance
segmentation models, YOLO-v7 instance segmentation and Mask R-CNN, were
evaluated using a dataset comprising 400 images, augmented to 10,995 images
through geometric and color-based transformations to enhance robustness. The
models were trained and validated using a dataset split into 90% training set,
validation and test set 10%. Performance metrics such as precision, recall,
mean average precision (mAP@0.5), and frames per second (FPS) were used for
evaluation. YOLO-v7 achieved a superior mAP@0.5 of 96.1% and processed 40 FPS,
outperforming Mask R-CNN, which achieved a mAP@0.5 of 92.1% with a slower
processing speed of 18 FPS. The findings recommend YOLO-v7 instance
segmentation model for real-time, high-speed structural health monitoring,
while Mask R-CNN is better suited for detailed offline assessments. This study
demonstrates the potential of deep learning to revolutionize infrastructure
maintenance, offering a scalable and efficient solution for automated damage
detection.

æè¦ï¼çµæ§å®æ´æ§å°æ¼ç¶­è­·æ©æ¨ãé§éåçå£ç­æ··åååºç¤è¨­æ½çå®å¨æ§åä½¿ç¨å£½å½è³ééè¦ãå³çµ±çæå£æª¢æ¸¬æ¹æ³ï¼ä¾å¦è£ç¸«ååè½ï¼éè¦å¤§éäººå·¥ï¼èæä¸å®¹æåºç¾äººçºé¯èª¤ãçºäºæå°éäºææ°ï¼æ¬ç ç©¶æ¢è¨äºä½¿ç¨æ·±åº¦å­¸ç¿çåé²æ¸æé©åæè¡ï¼ç¨æ¼èªåæå£æª¢æ¸¬ååæãä½¿ç¨åå« 400 å¼µååçæ¸æéè©ä¼°äºå©åæåé²çå¯¦ä¾åå²æ¨¡åï¼YOLO-v7 å¯¦ä¾åå²å Mask R-CNNï¼ééå¹¾ä½ååºæ¼é¡è²çè½ææ´å±å° 10,995 å¼µååï¼ä»¥å¢å¼·é­¯æ£æ§ãä½¿ç¨åçº 90% è¨ç·´éãé©è­åæ¸¬è©¦é 10% çæ¸æéè¨ç·´åé©è­æ¨¡åãä½¿ç¨ç²¾ç¢ºåº¦ãå¬åçãå¹³åå¹³åç²¾ç¢ºåº¦ (mAP@0.5) åæ¯ç§å¹æ¸ (FPS) ç­æ§è½ææ¨é²è¡è©ä¼°ãYOLO-v7 éå°äº 96.1% çåªç° mAP@0.5ï¼ä¸¦èçäº 40 FPSï¼åªæ¼ Mask R-CNNï¼å¾èä»¥ 18 FPS çè¼æ¢èçéåº¦éå°äº 92.1% ç mAP@0.5ãç ç©¶çµææ¨è¦ä½¿ç¨ YOLO-v7 å¯¦ä¾åå²æ¨¡åé²è¡å¯¦æãé«éçµæ§å¥åº·ç£æ¸¬ï¼è Mask R-CNN æ´é©åè©³ç´°çé¢ç·è©ä¼°ãæ¬ç ç©¶å±ç¤ºäºæ·±åº¦å­¸ç¿å¨åºç¤è¨­æ½ç¶­è­·æ¹é¢å·æé©å½æ§çæ½åï¼çºèªåæå£æª¢æ¸¬æä¾äºä¸åå¯æ´å±ä¸é«æçè§£æ±ºæ¹æ¡ã

##### **GL-ICNN: An End-To-End Interpretable Convolutional Neural Network for the Diagnosis and Prediction of Alzheimer's Disease**
2501.11715v1 by Wenjie Kang, Lize Jiskoot, Peter De Deyn, Geert Biessels, Huiberdina Koek, Jurgen Claassen, Huub Middelkoop, Wiesje Flier, Willemijn J. Jansen, Stefan Klein, Esther Bron

Deep learning methods based on Convolutional Neural Networks (CNNs) have
shown great potential to improve early and accurate diagnosis of Alzheimer's
disease (AD) dementia based on imaging data. However, these methods have yet to
be widely adopted in clinical practice, possibly due to the limited
interpretability of deep learning models. The Explainable Boosting Machine
(EBM) is a glass-box model but cannot learn features directly from input
imaging data. In this study, we propose a novel interpretable model that
combines CNNs and EBMs for the diagnosis and prediction of AD. We develop an
innovative training strategy that alternatingly trains the CNN component as a
feature extractor and the EBM component as the output block to form an
end-to-end model. The model takes imaging data as input and provides both
predictions and interpretable feature importance measures. We validated the
proposed model on the Alzheimer's Disease Neuroimaging Initiative (ADNI)
dataset and the Health-RI Parelsnoer Neurodegenerative Diseases Biobank (PND)
as an external testing set. The proposed model achieved an area-under-the-curve
(AUC) of 0.956 for AD and control classification, and 0.694 for the prediction
of conversion of mild cognitive impairment (MCI) to AD on the ADNI cohort. The
proposed model is a glass-box model that achieves a comparable performance with
other state-of-the-art black-box models. Our code is publicly available at:
https://anonymous.4open.science/r/GL-ICNN.

æè¦ï¼<paragraph>åºæ¼å·ç©ç¥ç¶ç¶²è·¯ (CNN) çæ·±åº¦å­¸ç¿æ¹æ³å·²é¡¯ç¤ºåºæ¥µå¤§çæ½åï¼å¯æ ¹æå½±åè³ææ¹åé¿è²æµ·é»ç (AD) å¤±æºççæ©ææºç¢ºè¨ºæ·ãç¶èï¼éäºæ¹æ³å°æªå»£æ³æç¨æ¼è¨åºå¯¦åä¸­ï¼éå¯è½æ¯ç±æ¼æ·±åº¦å­¸ç¿æ¨¡åçå¯è§£éæ§æéãå¯è§£éæåæ© (EBM) æ¯åç»ççæ¨¡åï¼ä½ç¡æ³ç´æ¥å¾è¼¸å¥å½±åè³æä¸­å­¸ç¿ç¹å¾µãå¨éé ç ç©¶ä¸­ï¼æåæåºä¸åçµå CNN å EBM çæ°å¯è§£éæ¨¡åï¼ç¨æ¼è¨ºæ·åé æ¸¬ ADãæåéç¼äºä¸ç¨®åµæ°çè¨ç·´ç­ç¥ï¼äº¤æ¿è¨ç·´ CNN çµä»¶ä½çºç¹å¾µèåå¨ï¼ä¸¦è¨ç·´ EBM çµä»¶ä½çºè¼¸åºåå¡ï¼ä»¥å½¢æç«¯å°ç«¯æ¨¡åãæ­¤æ¨¡åå°å½±åè³æä½çºè¼¸å¥ï¼ä¸¦æä¾é æ¸¬åå¯è§£éçç¹å¾µéè¦æ§æ¸¬éãæåå¨é¿è²æµ·é»çç¥ç¶å½±åå¡è­° (ADNI) è³æéå Health-RI Parelsnoer ç¥ç¶éåç¾ççç©è³æåº« (PND) ä¸é©è­äºææåºçæ¨¡åï¼ä½çºå¤é¨æ¸¬è©¦éãææåºçæ¨¡åå¨ AD åå°ç§åé¡ä¸­éå°äº 0.956 çæ²ç·ä¸é¢ç© (AUC)ï¼ä¸¦å¨ ADNI éåä¸­é æ¸¬è¼åº¦èªç¥éç¤ (MCI) è½åçº AD æéå°äº 0.694ãææåºçæ¨¡åæ¯ä¸åç»ççæ¨¡åï¼å¶æè½èå¶ä»æåé²çé»çæ¨¡åç¸ç¶ãæåçç¨å¼ç¢¼å¯å¨ä»¥ä¸ç¶²åå¬éåå¾ï¼https://anonymous.4open.science/r/GL-ICNNã</paragraph>

##### **Human services organizations and the responsible integration of AI: Considering ethics and contextualizing risk(s)**
2501.11705v1 by Brian E. Perron, Lauri Goldkind, Zia Qi, Bryan G. Victor

This paper examines the responsible integration of artificial intelligence
(AI) in human services organizations (HSOs), proposing a nuanced framework for
evaluating AI applications across multiple dimensions of risk. The authors
argue that ethical concerns about AI deployment -- including professional
judgment displacement, environmental impact, model bias, and data laborer
exploitation -- vary significantly based on implementation context and specific
use cases. They challenge the binary view of AI adoption, demonstrating how
different applications present varying levels of risk that can often be
effectively managed through careful implementation strategies. The paper
highlights promising solutions, such as local large language models, that can
facilitate responsible AI integration while addressing common ethical concerns.
The authors propose a dimensional risk assessment approach that considers
factors like data sensitivity, professional oversight requirements, and
potential impact on client wellbeing. They conclude by outlining a path forward
that emphasizes empirical evaluation, starting with lower-risk applications and
building evidence-based understanding through careful experimentation. This
approach enables organizations to maintain high ethical standards while
thoughtfully exploring how AI might enhance their capacity to serve clients and
communities effectively.

æè¦ï¼æ¬ææ¢è¨äºäººå·¥æºæ§ (AI) å¨äººé¡æåçµç¹ (HSO) ä¸­è² è²¬ä»»çæ´åï¼æåºäºä¸åç´°ç·»çæ¡æ¶ï¼ç¨æ¼è©ä¼° AI æç¨å¨å¤åé¢¨éªç¶­åº¦ãä½èèªçºï¼å° AI é¨ç½²çéå¾·èéââåæ¬å°æ¥­å¤æ·çåä»£ãç°å¢å½±é¿ãæ¨¡ååå·®åè³æå·¥ä½èçååââææ ¹æå¯¦æ½èæ¯åå·é«ä½¿ç¨æ¡ä¾èæé¡¯èçä¸åãä»åææ°äº AI æ¡ç¨äºåè«çè§é»ï¼èªªæäºä¸åçæç¨å¦ä½åç¾ä¸åç¨åº¦çé¢¨éªï¼èéäºé¢¨éªéå¸¸å¯ä»¥ééä»ç´°çå¯¦æ½ç­ç¥ä¾ææç®¡çãæ¬æéé»ä»ç´¹äºæåæ¯çè§£æ±ºæ¹æ¡ï¼ä¾å¦æ¬å°å¤§åèªè¨æ¨¡åï¼å®å¯ä»¥å¨è§£æ±ºå¸¸è¦çéå¾·åé¡çåæï¼ä¿é²è² è²¬ä»»ç AI æ´åãä½èæåºäºä¸ç¨®ç¶­åº¦é¢¨éªè©ä¼°æ¹æ³ï¼è©²æ¹æ³èæ®äºè³æææåº¦ãå°æ¥­ç£ç£éæ±åå°å®¢æ¶ç¦ç¥çæ½å¨å½±é¿ç­å ç´ ãä»åæå¾æ¦è¿°äºä¸æ¢åé²çéè·¯ï¼å¼·èª¿å¯¦è­è©ä¼°ï¼å¾ä½é¢¨éªæç¨éå§ï¼ä¸¦ééä»ç´°çå¯¦é©å»ºç«åºæ¼è­æççè§£ãéç¨®æ¹æ³ä½¿çµç¹è½å¤ å¨æ·±æçæ®å°æ¢è¨ AI å¦ä½å¢å¼·å¶æææåå®¢æ¶åç¤¾ç¾¤çè½åçåæï¼ç¶­æé«éå¾·æ¨æºã

##### **Spatially-Delineated Domain-Adapted AI Classification: An Application for Oncology Data**
2501.11695v1 by Majid Farhadloo, Arun Sharma, Alexey Leontovich, Svetomir N. Markovic, Shashi Shekhar

Given multi-type point maps from different place-types (e.g., tumor regions),
our objective is to develop a classifier trained on the source place-type to
accurately distinguish between two classes of the target place-type based on
their point arrangements. This problem is societally important for many
applications, such as generating clinical hypotheses for designing new
immunotherapies for cancer treatment. The challenge lies in the spatial
variability, the inherent heterogeneity and variation observed in spatial
properties or arrangements across different locations (i.e., place-types).
Previous techniques focus on self-supervised tasks to learn domain-invariant
features and mitigate domain differences; however, they often neglect the
underlying spatial arrangements among data points, leading to significant
discrepancies across different place-types. We explore a novel multi-task
self-learning framework that targets spatial arrangements, such as spatial
mix-up masking and spatial contrastive predictive coding, for
spatially-delineated domain-adapted AI classification. Experimental results on
real-world datasets (e.g., oncology data) show that the proposed framework
provides higher prediction accuracy than baseline methods.

æè¦ï¼å¾ä¸åé¡åçé»åï¼ä¾å¦ï¼è«ç¤ååï¼ä¸­çµ¦å®å¤é¡åé»åï¼
æåçç®æ¨æ¯éç¼ä¸åå¨ä¾æºé¡åä¸è¨ç·´çåé¡å¨ï¼ä»¥
æ ¹æå¶é»æåæºç¢ºååç®æ¨é¡åä¸­çå©é¡ãéååé¡å°æ¼è¨±å¤
æç¨ä¾èªªå·æç¤¾æéè¦æ§ï¼ä¾å¦çºççæ²»çè¨­è¨æ°çåç«çæ³èçæè¨åºåè¨­ãææ°å¨æ¼ç©ºé
è®ç°æ§ãåºæçç°è³ªæ§åå¨ä¸åä½ç½®ï¼å³é¡åï¼ä¸­è§å¯å°çç©ºé
å±¬æ§ææåçè®åãååçæè¡å°æ³¨æ¼èªç£ç£ä»»åä»¥å­¸ç¿ä¸è®é å
ç¹å¾µä¸¦æ¸è¼é åå·®ç°ï¼ç¶èï¼å®åéå¸¸å¿½è¦æ¸æé»ä¹éç
åºå±¤ç©ºéæåï¼å°è´ä¸åé¡åä¹éå­å¨é¡¯èå·®ç°ãæåæ¢ç´¢äºä¸ç¨®æ°ç©çå¤ä»»å
èªå­¸ç¿æ¡æ¶ï¼ä»¥éå°ç©ºéæåï¼ä¾å¦ç©ºéæ··åæ©è½åç©ºéå°æ¯é æ¸¬ç·¨ç¢¼ï¼ç¨æ¼
ç©ºéååçé åé©æ AI åé¡ãå¨
çå¯¦ä¸çæ¸æéï¼ä¾å¦ï¼è«ç¤å­¸æ¸æï¼ä¸çå¯¦é©çµæè¡¨æï¼ææåºçæ¡æ¶
æä¾çé æ¸¬æºç¢ºåº¦é«æ¼åºç·æ¹æ³ã

##### **Biomedical Knowledge Graph: A Survey of Domains, Tasks, and Real-World Applications**
2501.11632v2 by Yuxing Lu, Sin Yee Goi, Xukai Zhao, Jinzhuo Wang

Biomedical knowledge graphs (BKGs) have emerged as powerful tools for
organizing and leveraging the vast and complex data found across the biomedical
field. Yet, current reviews of BKGs often limit their scope to specific domains
or methods, overlooking the broader landscape and the rapid technological
progress reshaping it. In this survey, we address this gap by offering a
systematic review of BKGs from three core perspectives: domains, tasks, and
applications. We begin by examining how BKGs are constructed from diverse data
sources, including molecular interactions, pharmacological datasets, and
clinical records. Next, we discuss the essential tasks enabled by BKGs,
focusing on knowledge management, retrieval, reasoning, and interpretation.
Finally, we highlight real-world applications in precision medicine, drug
discovery, and scientific research, illustrating the translational impact of
BKGs across multiple sectors. By synthesizing these perspectives into a unified
framework, this survey not only clarifies the current state of BKG research but
also establishes a foundation for future exploration, enabling both innovative
methodological advances and practical implementations.

æè¦ï¼çç©å»å­¦ç¥è¯å¾è°±ï¼BKGï¼å·²æä¸ºç»ç»åå©ç¨çç©å»å­¦é¢åä¸­åç°çåºå¤§ä¸å¤ææ°æ®çå¼ºå¤§å·¥å·ãç¶èï¼å½åå¯¹ BKG çå®¡æ¥éå¸¸å°å¶èå´éå¶å¨ç¹å®é¢åææ¹æ³ï¼å¿½è§äºæ´å¹¿æ³çæ ¼å±åæ­£å¨éå¡å®çå¿«éææ¯è¿æ­¥ãå¨è¿é¡¹è°æ¥ä¸­ï¼æä»¬éè¿ä»ä¸ä¸ªæ ¸å¿è§åº¦ï¼é¢åãä»»å¡ååºç¨ï¼å¯¹ BKG è¿è¡ç³»ç»å®¡æ¥æ¥è§£å³è¿ä¸å·®è·ãæä»¬é¦åæ£æ¥å¦ä½ä»åæ¬åå­ç¸äºä½ç¨ãè¯çæ°æ®éåä¸´åºè®°å½å¨åçåç§æ°æ®æºæå»º BKGãæ¥ä¸æ¥ï¼æä»¬è®¨è®º BKG å¯ç¨çåºæ¬ä»»å¡ï¼éç¹å³æ³¨ç¥è¯ç®¡çãæ£ç´¢ãæ¨çåè§£éãæåï¼æä»¬éç¹ä»ç»äºç²¾åå»çãè¯ç©åç°åç§å­¦ç ç©¶ä¸­çå®éåºç¨ï¼è¯´æäº BKG å¨å¤ä¸ªé¢åçè½¬åå½±åãéè¿å°è¿äºè§ç¹ç»¼åå°ä¸ä¸ªç»ä¸çæ¡æ¶ä¸­ï¼æ¬è°æ¥ä¸ä»éæäº BKG ç ç©¶çç°ç¶ï¼è¿ä¸ºæªæ¥çæ¢ç´¢å¥ å®äºåºç¡ï¼æ¢ä¿è¿äºåæ°æ¹æ³çè¿æ­¥ï¼ä¹ä¿è¿äºå®éå®æ½ã

##### **Training-free Ultra Small Model for Universal Sparse Reconstruction in Compressed Sensing**
2501.11592v1 by Chaoqing Tang, Huanze Zhuang, Guiyun Tian, Zhenli Zeng, Yi Ding, Wenzhong Liu, Xiang Bai

Pre-trained large models attract widespread attention in recent years, but
they face challenges in applications that require high interpretability or have
limited resources, such as physical sensing, medical imaging, and
bioinformatics. Compressed Sensing (CS) is a well-proved theory that drives
many recent breakthroughs in these applications. However, as a typical
under-determined linear system, CS suffers from excessively long sparse
reconstruction times when using traditional iterative methods, particularly
with large-scale data. Current AI methods like deep unfolding fail to
substitute them because pre-trained models exhibit poor generality beyond their
training conditions and dataset distributions, or lack interpretability.
Instead of following the big model fervor, this paper proposes ultra-small
artificial neural models called coefficients learning (CL), enabling
training-free and rapid sparse reconstruction while perfectly inheriting the
generality and interpretability of traditional iterative methods, bringing new
feature of incorporating prior knowledges. In CL, a signal of length $n$ only
needs a minimal of $n$ trainable parameters. A case study model called CLOMP is
implemented for evaluation. Experiments are conducted on both synthetic and
real one-dimensional and two-dimensional signals, demonstrating significant
improvements in efficiency and accuracy. Compared to representative iterative
methods, CLOMP improves efficiency by 100 to 1000 folds for large-scale data.
Test results on eight diverse image datasets indicate that CLOMP improves
structural similarity index by 292%, 98%, 45% for sampling rates of 0.1, 0.3,
0.5, respectively. We believe this method can truly usher CS reconstruction
into the AI era, benefiting countless under-determined linear systems that rely
on sparse solution.

æè¦ï¼<paragraph>é¢è®­ç»å¤§åæ¨¡åè¿å¹´æ¥å¤åå³æ³¨ï¼ä½å®ä»¬å¨éè¦é«å¯è§£éæ§æèµæºæéçåºç¨ä¸­é¢ä¸´ææï¼ä¾å¦ç©çä¼ æãå»å­¦å½±ååçç©ä¿¡æ¯å­¦ãåç¼©æç¥ (CS) æ¯ä¸é¡¹ç»è¿ååéªè¯ççè®ºï¼æ¨å¨äºè¿äºåºç¨ä¸­çè®¸å¤ææ°çªç ´ãç¶èï¼ä½ä¸ºå¸åçæ¬ å®çº¿æ§ç³»ç»ï¼CS å¨ä½¿ç¨ä¼ ç»è¿­ä»£æ¹æ³æ¶ä¼äº§çè¿é¿çç¨çéå»ºæ¶é´ï¼å°¤å¶æ¯å¨å¤çå¤§è§æ¨¡æ°æ®æ¶ãå½åçæ·±åº¦å±å¼ç­ AI æ¹æ³æ æ³æ¿ä»£å®ä»¬ï¼å ä¸ºé¢è®­ç»æ¨¡åå¨å¶è®­ç»æ¡ä»¶åæ°æ®éåå¸ä¹å¤è¡¨ç°åºè¾å·®çæ³åæ§ï¼æç¼ºä¹å¯è§£éæ§ãæ¬ææ²¡æè¿½éå¤§åæ¨¡åç­æ½®ï¼èæ¯æåºäºç§°ä¸ºç³»æ°å­¦ä¹  (CL) çè¶å°åäººå·¥ç¥ç»ç½ç»æ¨¡åï¼å®ç°æ è®­ç»ä¸å¿«éçç¨çéå»ºï¼åæ¶å®ç¾ç»§æ¿äºä¼ ç»è¿­ä»£æ¹æ³çæ³åæ§åå¯è§£éæ§ï¼å¸¦æ¥äºèååéªç¥è¯çæ°ç¹æ§ãå¨ CL ä¸­ï¼é¿åº¦ä¸º $n$ çä¿¡å·åªéè¦æå° $n$ ä¸ªå¯è®­ç»åæ°ãå®ç°äºä¸ä¸ªç§°ä¸º CLOMP çæ¡ä¾ç ç©¶æ¨¡åä»¥è¿è¡è¯ä¼°ãå¨åæåçå®çä¸ç»´åäºç»´ä¿¡å·ä¸è¿è¡äºå®éªï¼è¯æäºæçååç¡®æ§çæ¾çæé«ãä¸å·æä»£è¡¨æ§çè¿­ä»£æ¹æ³ç¸æ¯ï¼CLOMP å°å¤§è§æ¨¡æ°æ®çæçæé«äº 100 å° 1000 åãå¨å«ä¸ªä¸åçå¾åæ°æ®éä¸çæµè¯ç»æè¡¨æï¼CLOMP åå«å°éæ ·çä¸º 0.1ã0.3ã0.5 çç»æç¸ä¼¼æ§ææ°æé«äº 292%ã98%ã45%ãæä»¬ç¸ä¿¡è¿ç§æ¹æ³å¯ä»¥çæ­£å° CS éå»ºå¸¦å¥ AI æ¶ä»£ï¼ä½¿ä¾èµç¨çè§£çæ æ°æ¬ å®çº¿æ§ç³»ç»åçã</paragraph>

##### **Enhancing Coronary Artery Calcium Scoring via Multi-Organ Segmentation on Non-Contrast Cardiac Computed Tomography**
2501.11428v1 by Jakub Nalepa, Tomasz Bartczak, Mariusz Bujny, JarosÅaw GoÅliÅski, Katarzyna Jesionek, Wojciech Malara, Filip Malawski, Karol Miszalski-Jamka, Patrycja Rewa, Marcin Kostur

Despite coronary artery calcium scoring being considered a largely solved
problem within the realm of medical artificial intelligence, this paper argues
that significant improvements can still be made. By shifting the focus from
pathology detection to a deeper understanding of anatomy, the novel algorithm
proposed in the paper both achieves high accuracy in coronary artery calcium
scoring and offers enhanced interpretability of the results. This approach not
only aids in the precise quantification of calcifications in coronary arteries,
but also provides valuable insights into the underlying anatomical structures.
Through this anatomically-informed methodology, the paper shows how a nuanced
understanding of the heart's anatomy can lead to more accurate and
interpretable results in the field of cardiovascular health. We demonstrate the
superior accuracy of the proposed method by evaluating it on an open-source
multi-vendor dataset, where we obtain results at the inter-observer level,
surpassing the current state of the art. Finally, the qualitative analyses show
the practical value of the algorithm in such tasks as labeling coronary artery
calcifications, identifying aortic calcifications, and filtering out false
positive detections due to noise.

æè¦ï¼åç®¡å çåèé£åè©åå¨é«å­¸äººå·¥æºæ§é åè¢«èªçºæ¯ä¸åå·²è§£æ±ºçåé¡ï¼ä½æ¬æè«è­ä»æé¡¯èé²æ­¥çç©ºéãééå°ç¦é»å¾ççæª¢æ¸¬è½ç§»å°å°è§£åçµæ§çæ´æ·±å¥çè§£ï¼æ¬ææåºçæ°æ¼ç®æ³å¨å çåèé£åè©åä¸­ç²å¾é«æºç¢ºåº¦ï¼ä¸¦æä¾äºå¢å¼·ççµæå¯è§£éæ§ãéç¨®æ¹æ³ä¸åæå©æ¼ç²¾ç¢ºéåå çåèçé£åï¼éæä¾äºå°åºå±¤è§£åçµæ§çå¯¶è²´è¦è§£ãéééç¨®è§£åå­¸æ¹æ³ï¼æ¬æå±ç¤ºäºå°å¿èè§£åçµæ§çç´°ç·»çè§£å¦ä½è½å°è´å¿è¡ç®¡å¥åº·é åæ´æºç¢ºä¸å¯è§£éççµæãæåééå¨éæ¾åå§ç¢¼çå¤å» åè³æéä¸è©ä¼°ææåºçæ¹æ³ï¼è­æäºå¶åªè¶çæºç¢ºåº¦ï¼æåå¨è§å¯èéå±¤ç´ç²å¾ççµæè¶è¶äºç®åçæè¡æ°´æºãæå¾ï¼å®æ§åæé¡¯ç¤ºäºè©²æ¼ç®æ³å¨æ¨è¨å çåèé£åãè­å¥ä¸»åèé£åä»¥åéæ¿¾æå éè¨èç¢ççåé½æ§åµæ¸¬ç­ä»»åä¸­çå¯¦ç¨å¹å¼ã

##### **RedStar: Does Scaling Long-CoT Data Unlock Better Slow-Reasoning Systems?**
2501.11284v1 by Haotian Xu, Xing Wu, Weinong Wang, Zhongzhi Li, Da Zheng, Boyuan Chen, Yi Hu, Shijia Kang, Jiaming Ji, Yingying Zhang, Zhijiang Guo, Yaodong Yang, Muhan Zhang, Debing Zhang

Can scaling transform reasoning? In this work, we explore the untapped
potential of scaling Long Chain-of-Thought (Long-CoT) data to 1000k samples,
pioneering the development of a slow-thinking model, RedStar. Through extensive
experiments with various LLMs and different sizes, we uncover the ingredients
for specialization and scale for Long-CoT training. Surprisingly, even smaller
models show significant performance gains with limited data, revealing the
sample efficiency of Long-CoT and the critical role of sample difficulty in the
learning process. Our findings demonstrate that Long-CoT reasoning can be
effectively triggered with just a few thousand examples, while larger models
achieve unparalleled improvements. We also introduce reinforcement learning
(RL)-scale training as a promising direction for advancing slow-thinking
systems. RedStar shines across domains: on the MATH-Hard benchmark,
RedStar-code-math boosts performance from 66.2\% to 81.6\%, and on the USA Math
Olympiad (AIME), it solves 46.7\% of problems using only 21k mixed-code-math
datasets. In multimodal tasks like GeoQA and MathVista-GEO, RedStar-Geo
achieves competitive results with minimal Long-CoT data, outperforming other
slow-thinking systems like QvQ-Preview. Compared to QwQ, RedStar strikes the
perfect balance between reasoning and generalizability. Our work highlights
that, with careful tuning, scaling Long-CoT can unlock extraordinary reasoning
capabilities-even with limited dataset and set a new standard for slow-thinking
models across diverse challenges. Our data and models are released at
https://huggingface.co/RedStar-Reasoning.

æè¦ï¼<paragraph>ç¸®æ¾å¯ä»¥è½ææ¨çåï¼å¨éé å·¥ä½ä¸­ï¼æåæ¢ç´¢å°é·éæèï¼Long-CoTï¼è³æç¸®æ¾å° 1000k ç¯ä¾çæªéç¼æ½åï¼çåéç¼æ¢æèæ¨¡å RedStarãééä½¿ç¨åç¨® LLM åä¸åå¤§å°é²è¡å»£æ³å¯¦é©ï¼æåæ­ç¤ºäº Long-CoT è¨ç·´çå°æ¥­ååè¦æ¨¡è¦ç´ ãä»¤äººé©è¨çæ¯ï¼å³ä½¿è¼å°çæ¨¡åå¨è³ææéçææ³ä¸ä¹å±ç¾åºé¡¯èçæè½æåï¼æ­ç¤ºäº Long-CoT çç¯ä¾æçåç¯ä¾é£åº¦å¨å­¸ç¿éç¨ä¸­æ®æ¼çééµè§è²ãæåçç¼ç¾è­æï¼åªè¦ææ¸ååç¯ä¾ï¼å°±å¯ä»¥ææè§¸ç¼ Long-CoT æ¨çï¼èè¼å¤§çæ¨¡ååå¯ç²å¾ç¡èå«æ¯çæ¹é²ãæåéå°å¥å¼·åå­¸ç¿ (RL) è¦æ¨¡è¨ç·´ï¼ä½çºæ¨é²æ¢æèç³»çµ±çä¸åæåéçæ¹åãRedStar å¨ååé åä¸­è¡¨ç¾åºè²ï¼å¨ MATH-Hard åºæºæ¸¬è©¦ä¸­ï¼RedStar-code-math å°æè½å¾ 66.2% æåè³ 81.6%ï¼èå¨ç¾åæ¸å­¸å¥§æå¹åï¼AIMEï¼ä¸­ï¼å®åä½¿ç¨ 21k åæ··åç¨å¼ç¢¼æ¸å­¸è³æéå°±è§£æ±ºäº 46.7% çåé¡ãå¨ GeoQA å MathVista-GEO ç­å¤æ¨¡æä»»åä¸­ï¼RedStar-Geo å¨ Long-CoT è³ææå°çææ³ä¸åå¾ç«¶ç­åççµæï¼åªæ¼å¶ä»æ¢æèç³»çµ±ï¼ä¾å¦ QvQ-Previewãè QwQ ç¸æ¯ï¼RedStar å¨æ¨çåæ¦æ¬æ§ä¹éåå¾äºå®ç¾çå¹³è¡¡ãæåçç ç©¶éé»å¨æ¼ï¼ééä»ç´°èª¿æ´ï¼ç¸®æ¾ Long-CoT å¯ä»¥è§£ééå¡çæ¨çè½åï¼å³ä½¿å¨è³æéæéçææ³ä¸ï¼ä¹è½çºåç¨®ææ°è¨­å®æ¢æèæ¨¡åçæ°æ¨æºãæåçè³æåæ¨¡åå·²æ¼ https://huggingface.co/RedStar-Reasoning ç¼å¸ã</paragraph>

##### **Spatiotemporal Air Quality Mapping in Urban Areas Using Sparse Sensor Data, Satellite Imagery, Meteorological Factors, and Spatial Features**
2501.11270v1 by Osama Ahmad, Zubair Khalid, Muhammad Tahir, Momin Uppal

Monitoring air pollution is crucial for protecting human health from exposure
to harmful substances. Traditional methods of air quality monitoring, such as
ground-based sensors and satellite-based remote sensing, face limitations due
to high deployment costs, sparse sensor coverage, and environmental
interferences. To address these challenges, this paper proposes a framework for
high-resolution spatiotemporal Air Quality Index (AQI) mapping using sparse
sensor data, satellite imagery, and various spatiotemporal factors. By
leveraging Graph Neural Networks (GNNs), we estimate AQI values at unmonitored
locations based on both spatial and temporal dependencies. The framework
incorporates a wide range of environmental features, including meteorological
data, road networks, points of interest (PoIs), population density, and urban
green spaces, which enhance prediction accuracy. We illustrate the use of our
approach through a case study in Lahore, Pakistan, where multi-resolution data
is used to generate the air quality index map at a fine spatiotemporal scale.

æè¦ï¼ç£æ§ç©ºæ°£æ±¡æå°æ¼ä¿è­·äººé¡å¥åº·åæ¼æ¥è§¸æå®³ç©è³ªè³ééè¦ãå³çµ±çç©ºæ°£åè³ªç£æ¸¬æ¹æ³ï¼ä¾å¦å°é¢ææ¸¬å¨åè¡æéæ¸¬ï¼ç±æ¼é¨ç½²ææ¬é«ãææ¸¬å¨è¦èç¯åç¨çä»¥åç°å¢å¹²æ¾èé¢è¨éå¶ãçºäºæå°éäºææ°ï¼æ¬ææåºäºä¸åä½¿ç¨ç¨çææ¸¬å¨è³æãè¡æå½±åååç¨®æç©ºå å­ä¾ç¹ªè£½é«è§£æåº¦æç©ºç©ºæ°£åè³ªææ¸ (AQI) çæ¶æ§ãééå©ç¨åå½¢ç¥ç¶ç¶²è·¯ (GNN)ï¼æåæ ¹æç©ºéåæéä¾è³´æ§ä¾ä¼°è¨æªç£æ§å°é»ç AQI å¼ãè©²æ¶æ§çµåäºå»£æ³çç°å¢ç¹å¾µï¼åæ¬æ°£è±¡è³æãéè·¯ç¶²è·¯ãèè¶£é» (PoI)ãäººå£å¯åº¦ååå¸ç¶ å°ï¼éäºç¹å¾µå¢å¼·äºé æ¸¬æºç¢ºåº¦ãæåééå·´åºæ¯å¦æåç¾çä¸åæ¡ä¾ç ç©¶ä¾èªªææåæ¹æ³çä½¿ç¨ï¼å¶ä¸­ä½¿ç¨å¤è§£æåº¦è³æä¾çæç²¾ç´°æç©ºå°ºåº¦çç©ºæ°£åè³ªææ¸å°åã

##### **Clinical trial cohort selection using Large Language Models on n2c2 Challenges**
2501.11114v1 by Chi-en Amy Tai, Xavier Tannier

Clinical trials are a critical process in the medical field for introducing
new treatments and innovations. However, cohort selection for clinical trials
is a time-consuming process that often requires manual review of patient text
records for specific keywords. Though there have been studies on standardizing
the information across the various platforms, Natural Language Processing (NLP)
tools remain crucial for spotting eligibility criteria in textual reports.
Recently, pre-trained large language models (LLMs) have gained popularity for
various NLP tasks due to their ability to acquire a nuanced understanding of
text. In this paper, we study the performance of large language models on
clinical trial cohort selection and leverage the n2c2 challenges to benchmark
their performance. Our results are promising with regard to the incorporation
of LLMs for simple cohort selection tasks, but also highlight the difficulties
encountered by these models as soon as fine-grained knowledge and reasoning are
required.

æè¦ï¼è¨åºè©¦é©æ¯é«å­¸é åä¸­å¼å¥æ°çæ³ååµæ°çééµéç¨ãç¶èï¼è¨åºè©¦é©çæ£èç¾¤é«é¸ææ¯ä¸åèæçéç¨ï¼éå¸¸éè¦äººå·¥å¯©æ¥çæ£çæå­è¨éï¼ä»¥å°æ¾ç¹å®çééµå­ãåç®¡æç ç©¶éå°ä¸åå¹³å°ä¸çè³è¨é²è¡æ¨æºåï¼èªç¶èªè¨èç (NLP) å·¥å·å°æ¼å¨æå­å ±åä¸­æ¾åºç¬¦åè³æ ¼çæ¨æºä»ç¶è³ééè¦ãæè¿ï¼é åè¨ç·´çå¤§åèªè¨æ¨¡å (LLM) å å¶ç²åç´°ç·»ææ¬çè§£çè½åèå»£ååç¨® NLP ä»»åæ­¡è¿ãå¨æ¬æä¸­ï¼æåç ç©¶å¤§åèªè¨æ¨¡åå¨è¨åºè©¦é©æ£èç¾¤é«é¸æä¸çè¡¨ç¾ï¼ä¸¦å©ç¨ n2c2 ææ°ä¾è©éå¶è¡¨ç¾ãæåççµæå°æ¼å° LLM ç´å¥ç°¡å®çæ£èç¾¤é«é¸æä»»åèè¨æ¯å¾æå¸æçï¼ä½ä¹å¼·èª¿äºéäºæ¨¡åå¨éè¦å·åç´°ç·»ç¥è­åæ¨çè½åææéå°çå°é£ã

##### **Enhanced Suicidal Ideation Detection from Social Media Using a CNN-BiLSTM Hybrid Model**
2501.11094v1 by Mohaiminul Islam Bhuiyan, Nur Shazwani Kamarudin, Nur Hafieza Ismail

Suicidal ideation detection is crucial for preventing suicides, a leading
cause of death worldwide. Many individuals express suicidal thoughts on social
media, offering a vital opportunity for early detection through advanced
machine learning techniques. The identification of suicidal ideation in social
media text is improved by utilising a hybrid framework that integrates
Convolutional Neural Networks (CNN) and Bidirectional Long Short-Term Memory
(BiLSTM), enhanced with an attention mechanism. To enhance the interpretability
of the model's predictions, Explainable AI (XAI) methods are applied, with a
particular focus on SHapley Additive exPlanations (SHAP), are incorporated. At
first, the model managed to reach an accuracy of 92.81%. By applying
fine-tuning and early stopping techniques, the accuracy improved to 94.29%. The
SHAP analysis revealed key features influencing the model's predictions, such
as terms related to mental health struggles. This level of transparency boosts
the model's credibility while helping mental health professionals understand
and trust the predictions. This work highlights the potential for improving the
accuracy and interpretability of detecting suicidal tendencies, making a
valuable contribution to the progress of mental health monitoring systems. It
emphasizes the significance of blending powerful machine learning methods with
explainability to develop reliable and impactful mental health solutions.

æè¦ï¼èªæ®ºæå¿µåµæ¸¬å°æ¼é é²èªæ®ºè³ééè¦ï¼èèªæ®ºæ¯å¨çä¸»è¦çæ­»äº¡åå ãè¨±å¤äººå¨ç¤¾ç¾¤åªé«ä¸è¡¨éèªæ®ºå¿µé ­ï¼éæä¾äºééé²éæ©å¨å­¸ç¿æè¡é²è¡æ©æåµæ¸¬çéè¦æ©æãééæ´åå·ç©ç¥ç¶ç¶²è·¯ (CNN) åéåé·ç­æè¨æ¶ (BiLSTM) çæ··åæ¶æ§ï¼ä¸¦å å¥æ³¨æåæ©å¶ï¼å¯ä»¥æåå¨ç¤¾ç¾¤åªé«æå­ä¸­è¾¨è­èªæ®ºæå¿µçè½åãçºäºå å¼·æ¨¡åé æ¸¬çå¯è§£éæ§ï¼æåæ¡ç¨å¯è§£éäººå·¥æºæ§ (XAI) æ¹æ³ï¼ç¹å¥èéæ¼ SHapley å æ³è§£é (SHAP)ãä¸éå§ï¼æ¨¡åæåéå° 92.81% çæºç¢ºåº¦ãééå¥ç¨å¾®èª¿åæ©æåæ­¢æè¡ï¼æºç¢ºåº¦æåè³ 94.29%ãSHAP åææ­é²äºå½±é¿æ¨¡åé æ¸¬çééµç¹å¾µï¼ä¾å¦èå¿çå¥åº·å°å¢ç¸éçè©å½ãéç¨®éæåº¦æåäºæ¨¡åçå¯ä¿¡åº¦ï¼åæåå©å¿çå¥åº·å°æ¥­äººå¡çè§£åä¿¡è³´é æ¸¬çµæãéé å·¥ä½çªé¡¯äºæååµæ¸¬èªæ®ºå¾åçæºç¢ºåº¦åå¯è§£éæ§çæ½åï¼çºå¿çå¥åº·ç£æ§ç³»çµ±çé²å±ååºå¯¶è²´çè²¢ç»ãå®å¼·èª¿äºå°å¼·å¤§çæ©å¨å­¸ç¿æ¹æ³èå¯è§£éæ§ç¸çµåä»¥éç¼å¯é ä¸æå½±é¿åçå¿çå¥åº·è§£æ±ºæ¹æ¡çéè¦æ§ã

##### **No More Sliding Window: Efficient 3D Medical Image Segmentation with Differentiable Top-k Patch Sampling**
2501.10814v1 by Young Seok Jeon, Hongfei Yang, Huazhu Fu, Mengling Feng

3D models are favored over 2D for 3D medical image segmentation tasks due to
their ability to leverage inter-slice relationship, yielding higher
segmentation accuracy. However, 3D models demand significantly more GPU memory
with increased model size and intermediate tensors. A common solution is to use
patch-based training and make whole-volume predictions with sliding window (SW)
inference. SW inference reduces memory usage but is slower due to equal
resource allocation across patches and less accurate as it overlooks global
features beyond patches.
  We propose NMSW-Net (No-More-Sliding-Window-Net), a novel framework that
enhances efficiency and accuracy of any given 3D segmentation model by
eliminating SW inference and incorporating global predictions when necessary.
NMSW-Net incorporates a differentiable Top-k module to sample only the relevant
patches that enhance segmentation accuracy, thereby minimizing redundant
computations. Additionally, it learns to leverage coarse global predictions
when patch prediction alone is insufficient. NMSW-Net is model-agnostic, making
it compatible with any 3D segmentation model that previously relied on SW
inference.
  Evaluated across 3 tasks with 3 segmentation backbones, NMSW-Net achieves
competitive or sometimes superior accuracy compared to SW, while reducing
computational complexity by 90% (87.5 to 7.95 TFLOPS), delivering 4x faster
inference on the H100 GPU (19.0 to 4.3 sec), and 7x faster inference on the
Intel Xeon Gold CPU (1710 to 230 seconds).

æè¦ï¼<paragraph>3D æ¨¡åå¨ 3D å»å­¦å½±ååå²ä»»å¡ä¸­ä¼äº 2Dï¼å ä¸º
å®ä»¬è½å¤å©ç¨åçé´å³ç³»ï¼ä»èäº§çæ´é«ç
åå²ç²¾åº¦ãç¶èï¼3D æ¨¡åéè¦å¤§é GPU åå­
éçæ¨¡åå¤§å°åä¸­é´å¼ éçå¢å ãä¸ç§å¸¸è§çè§£å³æ¹æ¡æ¯ä½¿ç¨
åºäº patch çè®­ç»å¹¶ä½¿ç¨æ»å¨çªå£ (SW)
æ¨çè¿è¡å¨å·é¢æµãSW æ¨çåå°äºåå­ä½¿ç¨éï¼ä½ç±äº
å¨ patch ä¹é´å¹³ååéèµæºå¹¶ä¸ç±äºå¿½ç¥äº patch ä¹å¤çå¨å±
ç¹å¾èå¯¼è´éåº¦è¾æ¢ä¸åç¡®åº¦è¾ä½ã
æä»¬æåºäº NMSW-Netï¼æ æ»å¨çªå£ç½ç»ï¼ï¼è¿æ¯ä¸ç§æ°é¢çæ¡æ¶ï¼å®
éè¿æ¶é¤ SW æ¨çå¹¶å¨å¿è¦æ¶åå¹¶å¨å±é¢æµæ¥æé«ä»»ä½ç»å® 3D åå²æ¨¡åçæçååç¡®æ§ã
NMSW-Net ç»åäºä¸ä¸ªå¯å¾®åç Top-k æ¨¡åæ¥ä»éæ ·ç¸å³
patchï¼ä»¥æé«åå²ç²¾åº¦ï¼ä»èæå¤§éåº¦å°åå°åä½
è®¡ç®ãæ­¤å¤ï¼å®å­¦ä¼äºå¨ä» patch é¢æµä¸è¶³æ¶å©ç¨ç²ç¥çå¨å±é¢æµãNMSW-Net ä¸æ¨¡åæ å³ï¼ä½¿å¶
ä¸ä»¥åä¾èµ SW çä»»ä½ 3D åå²æ¨¡åå¼å®¹
æ¨çã
å¨ 3 ä¸ªå¸¦æ 3 ä¸ªåå²ä¸»å¹²çä»»å¡ä¸­è¿è¡è¯ä¼°ï¼NMSW-Net å®ç°äº
ä¸ SW ç¸æ¯å·æç«äºåæææ¶æ´é«çåç¡®æ§ï¼åæ¶åå°
è®¡ç®å¤æåº¦éä½äº 90%ï¼87.5 å° 7.95 TFLOPSï¼ï¼å¨ H100 GPU ä¸æä¾ 4 åæ´å¿«ç
æ¨çï¼19.0 å° 4.3 ç§ï¼ï¼ä»¥åå¨
è±ç¹å°è³å¼ºé CPU ä¸æ¨çéåº¦æé« 7 åï¼1710 å° 230 ç§ï¼ã</paragraph>

##### **Efficient Auto-Labeling of Large-Scale Poultry Datasets (ALPD) Using Semi-Supervised Models, Active Learning, and Prompt-then-Detect Approach**
2501.10809v1 by Ramesh Bahadur Bist, Lilong Chai, Shawna Weimer, Hannah Atungulua, Chantel Pennicott, Xiao Yang, Sachin Subedi, Chaitanya Pallerla, Yang Tian, Dongyi Wang

The rapid growth of AI in poultry farming has highlighted the challenge of
efficiently labeling large, diverse datasets. Manual annotation is
time-consuming, making it impractical for modern systems that continuously
generate data. This study explores semi-supervised auto-labeling methods,
integrating active learning, and prompt-then-detect paradigm to develop an
efficient framework for auto-labeling of large poultry datasets aimed at
advancing AI-driven behavior and health monitoring. Viideo data were collected
from broilers and laying hens housed at the University of Arkansas and the
University of Georgia. The collected videos were converted into images,
pre-processed, augmented, and labeled. Various machine learning models,
including zero-shot models like Grounding DINO, YOLO-World, and CLIP, and
supervised models like YOLO and Faster-RCNN, were utilized for broilers, hens,
and behavior detection. The results showed that YOLOv8s-World and YOLOv9s
performed better when compared performance metrics for broiler and hen
detection under supervised learning, while among the semi-supervised model,
YOLOv8s-ALPD achieved the highest precision (96.1%) and recall (99.0%) with an
RMSE of 1.9. The hybrid YOLO-World model, incorporating the optimal YOLOv8s
backbone, demonstrated the highest overall performance. It achieved a precision
of 99.2%, recall of 99.4%, and an F1 score of 98.7% for breed detection,
alongside a precision of 88.4%, recall of 83.1%, and an F1 score of 84.5% for
individual behavior detection. Additionally, semi-supervised models showed
significant improvements in behavior detection, achieving up to 31% improvement
in precision and 16% in F1-score. The semi-supervised models with minimal
active learning reduced annotation time by over 80% compared to full manual
labeling. Moreover, integrating zero-shot models enhanced detection and
behavior identification.

æè¦ï¼<paragraph>å®¶ç¦½å»æ®ä¸­äººå·¥æºè½çå¿«éå¢é¿å¸æ¾äºé«ææ æ³¨å¤§åãå¤æ ·åæ°æ®éçææãæå¨æ æ³¨éå¸¸èæ¶ï¼å¯¹äºæç»­çææ°æ®çç°ä»£ç³»ç»èè¨ä¸åå®éãæ¬ç ç©¶æ¢ç´¢äºåçç£èªå¨æ æ³¨æ¹æ³ï¼éæäºä¸»å¨å­¦ä¹ åæç¤ºåæ£æµèå¼ï¼ä»¥å¼åä¸ä¸ªé«æçæ¡æ¶ï¼ç¨äºèªå¨æ æ³¨å¤§åå®¶ç¦½æ°æ®éï¼æ¨å¨æ¨è¿äººå·¥æºè½é©±å¨çè¡ä¸ºåå¥åº·çæµãè§é¢æ°æ®æ¯ä»é¿è¯è²å¤§å­¦åä½æ²»äºå¤§å­¦é¥²å»çèé¸¡åèé¸¡ä¸­æ¶éçãæ¶éçè§é¢è¢«è½¬æ¢æå¾åï¼ç»è¿é¢å¤çãå¢å¼ºåæ æ³¨ãåç§æºå¨å­¦ä¹ æ¨¡åï¼åæ¬ Grounding DINOãYOLO-World å CLIP ç­é¶æ ·æ¬å­¦ä¹ æ¨¡åï¼ä»¥å YOLO å Faster-RCNN ç­çç£æ¨¡åï¼è¢«ç¨äºèé¸¡ãæ¯é¸¡åè¡ä¸ºæ£æµãç»æè¡¨æï¼å¨çç£å­¦ä¹ ä¸ï¼YOLOv8s-World å YOLOv9s å¨èé¸¡åæ¯é¸¡æ£æµçæ§è½ææ æ¯è¾ä¸­è¡¨ç°å¾æ´å¥½ï¼èå¨åçç£æ¨¡åä¸­ï¼YOLOv8s-ALPD ä»¥ 1.9 ç RMSE å®ç°äºæé«çç²¾åº¦ (96.1%) åå¬åç (99.0%)ãç»åäºæä½³ YOLOv8s ä¸»å¹²ç½ç»çæ··å YOLO-World æ¨¡åå±ç¤ºäºæé«çæ´ä½æ§è½ãå®å¨åç§æ£æµä¸­å®ç°äº 99.2% çç²¾åº¦ã99.4% çå¬åçå 98.7% ç F1 åæ°ï¼å¨ä¸ªä½è¡ä¸ºæ£æµä¸­å®ç°äº 88.4% çç²¾åº¦ã83.1% çå¬åçå 84.5% ç F1 åæ°ãæ­¤å¤ï¼åçç£æ¨¡åå¨è¡ä¸ºæ£æµä¸­æ¾ç¤ºåºæ¾èçæ¹è¿ï¼å¨ç²¾åº¦ä¸æé«äº 31%ï¼å¨ F1 åæ°ä¸æé«äº 16%ãä¸å®å¨æå¨æ æ³¨ç¸æ¯ï¼å·ææå°ä¸»å¨å­¦ä¹ çåçç£æ¨¡åå°æ æ³¨æ¶é´åå°äº 80% ä»¥ä¸ãæ­¤å¤ï¼éæé¶æ ·æ¬å­¦ä¹ æ¨¡åå¢å¼ºäºæ£æµåè¡ä¸ºè¯å«ã</paragraph>

##### **MedFILIP: Medical Fine-grained Language-Image Pre-training**
2501.10775v1 by Xinjie Liang, Xiangyu Li, Fanding Li, Jie Jiang, Qing Dong, Wei Wang, Kuanquan Wang, Suyu Dong, Gongning Luo, Shuo Li

Medical vision-language pretraining (VLP) that leverages naturally-paired
medical image-report data is crucial for medical image analysis. However,
existing methods struggle to accurately characterize associations between
images and diseases, leading to inaccurate or incomplete diagnostic results. In
this work, we propose MedFILIP, a fine-grained VLP model, introduces medical
image-specific knowledge through contrastive learning, specifically: 1) An
information extractor based on a large language model is proposed to decouple
comprehensive disease details from reports, which excels in extracting disease
deals through flexible prompt engineering, thereby effectively reducing text
complexity while retaining rich information at a tiny cost. 2) A knowledge
injector is proposed to construct relationships between categories and visual
attributes, which help the model to make judgments based on image features, and
fosters knowledge extrapolation to unfamiliar disease categories. 3) A semantic
similarity matrix based on fine-grained annotations is proposed, providing
smoother, information-richer labels, thus allowing fine-grained image-text
alignment. 4) We validate MedFILIP on numerous datasets, e.g., RSNA-Pneumonia,
NIH ChestX-ray14, VinBigData, and COVID-19. For single-label, multi-label, and
fine-grained classification, our model achieves state-of-the-art performance,
the classification accuracy has increased by a maximum of 6.69\%. The code is
available in https://github.com/PerceptionComputingLab/MedFILIP.

æè¦ï¼é«å­¸å½±åèªè¨é è¨ç·´ï¼VLPï¼å©ç¨èªç¶éå°çé«å­¸å½±åå ±åæ¸æï¼å°æ¼é«å­¸å½±ååæè³ééè¦ãç¶èï¼ç¾ææ¹æ³é£ä»¥æºç¢ºæè¿°å½±åèç¾çä¹éçéè¯æ§ï¼å°è´è¨ºæ·çµæä¸æºç¢ºæä¸å®æ´ãå¨éé å·¥ä½ä¸­ï¼æåæåº MedFILIPï¼ä¸åç´°ç²åº¦ç VLP æ¨¡åï¼ééå°æ¯å­¸ç¿å¼å¥é«å­¸å½±åç¹å®ç¥è­ï¼å·é«ä¾èªªï¼1) æåºä¸ååºæ¼å¤§åèªè¨æ¨¡åçè³è¨èåå¨ï¼å¾å ±åä¸­è§£è¦å¨é¢çç¾çç´°ç¯ï¼éééæ´»çæç¤ºå·¥ç¨ï¼å¨æåç¾çäº¤ææ¹é¢è¡¨ç¾åºè²ï¼å¾èææéä½æå­è¤éæ§ï¼åæä»¥æ¥µå°çä»£å¹ä¿çè±å¯çè³è¨ã2) æåºä¸åç¥è­æ³¨å¥å¨ï¼ç¨æ¼å»ºæ§é¡å¥èè¦è¦ºå±¬æ§ä¹éçéä¿ï¼éæå©æ¼æ¨¡åæ ¹æå½±åç¹å¾µé²è¡å¤æ·ï¼ä¸¦ä¿é²ç¥è­å¤æ¨å°ä¸çæçç¾çé¡å¥ã3) æåºä¸ååºæ¼ç´°ç²åº¦è¨»è§£çèªç¾©ç¸ä¼¼ç©é£ï¼æä¾æ´å¹³æ»ãè³è¨æ´è±å¯çæ¨ç±¤ï¼å¾èåè¨±é²è¡ç´°ç²åº¦çå½±åæå­å°é½ã4) æåå¨è¨±å¤è³æéä¸é©è­ MedFILIPï¼ä¾å¦ RSNA-PneumoniaãNIH ChestX-ray14ãVinBigData å COVID-19ãå°æ¼å®æ¨ç±¤ãå¤æ¨ç±¤åç´°ç²åº¦åé¡ï¼æåçæ¨¡åéå°äºæåé²çæè½ï¼åé¡æºç¢ºçæé«æé«äº 6.69%ãç¨å¼ç¢¼å¯å¨ https://github.com/PerceptionComputingLab/MedFILIP ä¸­åå¾ã

##### **Enhancing Diagnostic in 3D COVID-19 Pneumonia CT-scans through Explainable Uncertainty Bayesian Quantification**
2501.10770v1 by Juan Manuel Liscano Fierro, Hector J. Hortua

Accurately classifying COVID-19 pneumonia in 3D CT scans remains a
significant challenge in the field of medical image analysis. Although
deterministic neural networks have shown promising results in this area, they
provide only point estimates outputs yielding poor diagnostic in clinical
decision-making. In this paper, we explore the use of Bayesian neural networks
for classifying COVID-19 pneumonia in 3D CT scans providing uncertainties in
their predictions. We compare deterministic networks and their Bayesian
counterpart, enhancing the decision-making accuracy under uncertainty
information. Remarkably, our findings reveal that lightweight architectures
achieve the highest accuracy of 96\% after developing extensive hyperparameter
tuning. Furthermore, the Bayesian counterpart of these architectures via
Multiplied Normalizing Flow technique kept a similar performance along with
calibrated uncertainty estimates. Finally, we have developed a 3D-visualization
approach to explain the neural network outcomes based on SHAP values. We
conclude that explainability along with uncertainty quantification will offer
better clinical decisions in medical image analysis, contributing to ongoing
efforts for improving the diagnosis and treatment of COVID-19 pneumonia.

æè¦ï¼æºç¢ºåé¡ 3D é»è¦æ·å±¤ææä¸­ç COVID-19 èºçå¨é«å­¸å½±ååæé åä¸­ä»æ¯ä¸é éå¤§ææ°ãåç®¡ç¢ºå®æ§ç¥ç¶ç¶²è·¯å·²å¨æ­¤é åä¸­å±ç¾åºä»¤äººæ»¿æççµæï¼ä½å®ååæä¾é»ä¼°è¨è¼¸åºï¼å¨è¨åºæ±ºç­ä¸­ç¢çä¸è¯çè¨ºæ·ãå¨æ¬æä¸­ï¼æåæ¢è¨ä½¿ç¨è²æ°ç¥ç¶ç¶²è·¯ä¾åé¡ 3D é»è¦æ·å±¤ææä¸­ç COVID-19 èºçï¼ä¸¦å¨é æ¸¬ä¸­æä¾ä¸ç¢ºå®æ§ãæåæ¯è¼ç¢ºå®æ§ç¶²è·¯åå¶è²æ°å°æç¶²è·¯ï¼å¨ä¸ç¢ºå®æ§è³è¨ä¸æåæ±ºç­çæºç¢ºæ§ãå¼å¾æ³¨æçæ¯ï¼æåçç¼ç¾é¡¯ç¤ºï¼å¨ç¶éå»£æ³çè¶åæ¸èª¿æ´å¾ï¼è¼éç´æ¶æ§å¯éå° 96% çæé«æºç¢ºåº¦ãæ­¤å¤ï¼éäºæ¶æ§çè²æ°å°æç¶²è·¯ééä¹æ³æ­£è¦åæµæè¡ï¼å¨æ ¡æºä¸ç¢ºå®æ§ä¼°è¨çåæï¼ç¶­æé¡ä¼¼çæè½ãæå¾ï¼æåå·²éç¼åº 3D è¦è¦ºåæ¹æ³ï¼ä»¥æ ¹æ SHAP å¼ä¾è§£éç¥ç¶ç¶²è·¯ççµæãæåå¾åºçµè«ï¼å¯è§£éæ§èä¸ç¢ºå®æ§éåå°å¨é«å­¸å½±ååæä¸­æä¾æ´å¥½çè¨åºæ±ºç­ï¼æå©æ¼æçºæ¹å COVID-19 èºççè¨ºæ·åæ²»çã

##### **In the Picture: Medical Imaging Datasets, Artifacts, and their Living Review**
2501.10727v1 by Amelia JimÃ©nez-SÃ¡nchez, Natalia-Rozalia Avlona, Sarah de Boer, VÃ­ctor M. Campello, Aasa Feragen, Enzo Ferrante, Melanie Ganz, Judy Wawira Gichoya, Camila GonzÃ¡lez, Steff Groefsema, Alessa Hering, Adam Hulman, Leo Joskowicz, Dovile Juodelyte, Melih Kandemir, Thijs Kooi, Jorge del Pozo LÃ©rida, Livie Yumeng Li, Andre Pacheco, Tim RÃ¤dsch, Mauricio Reyes, ThÃ©o Sourget, Bram van Ginneken, David Wen, Nina Weng, Jack Junchi Xu, Hubert Dariusz ZajÄc, Maria A. Zuluaga, Veronika Cheplygina

Datasets play a critical role in medical imaging research, yet issues such as
label quality, shortcuts, and metadata are often overlooked. This lack of
attention may harm the generalizability of algorithms and, consequently,
negatively impact patient outcomes. While existing medical imaging literature
reviews mostly focus on machine learning (ML) methods, with only a few focusing
on datasets for specific applications, these reviews remain static -- they are
published once and not updated thereafter. This fails to account for emerging
evidence, such as biases, shortcuts, and additional annotations that other
researchers may contribute after the dataset is published. We refer to these
newly discovered findings of datasets as research artifacts. To address this
gap, we propose a living review that continuously tracks public datasets and
their associated research artifacts across multiple medical imaging
applications. Our approach includes a framework for the living review to
monitor data documentation artifacts, and an SQL database to visualize the
citation relationships between research artifact and dataset. Lastly, we
discuss key considerations for creating medical imaging datasets, review best
practices for data annotation, discuss the significance of shortcuts and
demographic diversity, and emphasize the importance of managing datasets
throughout their entire lifecycle. Our demo is publicly available at
http://130.226.140.142.

æè¦ï¼<paragraph>è³æéå¨é«å­¸å½±åç ç©¶ä¸­æ®æ¼èè³ééè¦çè§è²ï¼ç¶èæ¨ç±¤åè³ªãæ·å¾ååè³æç­åé¡å»å¸¸å¸¸è¢«å¿½ç¥ãéç¨®ç¼ºä¹éæ³¨çç¾è±¡å¯è½ææå®³æ¼ç®æ³çæ¦æ¬æ§ï¼é²èå°çæ£çæ²»ççµæé æè² é¢å½±é¿ãéç¶ç¾æçé«å­¸å½±åæç»åé¡§å¤§å¤éä¸­æ¼æ©å¨å­¸ç¿ (ML) æ¹æ³ï¼åªæå°æ¸åé¡§èéæ¼ç¹å®æç¨ç¨å¼çè³æéï¼ä½éäºåé¡§ä»ç¶æ¯éæçââå®ååªæç¼è¡¨ä¸æ¬¡ï¼ä¹å¾ä¸æåæ´æ°ãéç¡æ³èéæ°åºç¾çè­æï¼ä¾å¦åèª¤ãæ·å¾åè³æéå¨ç¼è¡¨å¾å¶ä»ç ç©¶äººå¡å¯è½æä¾çé¡å¤è¨»è§£ãæåå°éäºæ°ç¼ç¾çè³æéç¼ç¾ç¨±çºç ç©¶ææãçºäºè§£æ±ºéååé¡ï¼æåæåºä¸åæçºè¿½è¹¤å¬éè³æéåå¶èå¤åé«å­¸å½±åæç¨ç¨å¼ç¸éçç ç©¶ææçåæåé¡§ãæåçåæ³åæ¬ä¸åç¨æ¼ç£æ§è³ææä»¶ææçåæåé¡§æ¶æ§ï¼ä»¥åä¸åç¨æ¼è¦è¦ºåç ç©¶ææèè³æéä¹éå¼ç¨éä¿ç SQL è³æåº«ãæå¾ï¼æåè¨è«å»ºç«é«å­¸å½±åè³æéæçä¸»è¦èéå ç´ ï¼åé¡§è³æè¨»è§£çæä½³å¯¦åï¼æ¢è¨æ·å¾åäººå£çµ±è¨å¤æ¨£æ§çéè¦æ§ï¼ä¸¦å¼·èª¿å¨è³æéçæ´åçå½é±æä¸­ç®¡çè³æéçéè¦æ§ãæåçç¤ºç¯å¯æ¼ http://130.226.140.142 å¬éåå¾ã</paragraph>

##### **An Ontology for Social Determinants of Education (SDoEd) based on Human-AI Collaborative Approach**
2501.10300v1 by Navya Martin Kollapally, James Geller, Patricia Morreale, Daehan Kwak

The use of computational ontologies is well-established in the field of
Medical Informatics. The topic of Social Determinants of Health (SDoH) has also
received extensive attention. Work at the intersection of ontologies and SDoH
has been published. However, a standardized framework for Social Determinants
of Education (SDoEd) is lacking. In this paper, we are closing the gap by
introducing an SDoEd ontology for creating a precise conceptualization of the
interplay between life circumstances of students and their possible educational
achievements. The ontology was developed utilizing suggestions from
ChatGPT-3.5-010422 and validated using peer-reviewed research articles. The
first version of developed ontology was evaluated by human experts in the field
of education and validated using standard ontology evaluation software. This
version of the SDoEd ontology contains 231 domain concepts, 10 object
properties, and 24 data properties

æè¦ï¼å¨é«å­¸è³è¨å­¸é åä¸­ï¼è¨ç®æ¬é«çä½¿ç¨å·²ç¶ç¸ç¶æ®éãç¤¾æå¥åº·æ±ºå®å ç´ ï¼SDoHï¼çä¸»é¡ä¹åå°å»£æ³çéæ³¨ãæ¬é«è SDoH äº¤éèçå·¥ä½å·²ç¶ç¼è¡¨ãç¶èï¼ç¤¾ææè²æ±ºå®å ç´ ï¼SDoEdï¼çæ¨æºåæ¶æ§å»ä»ä¹éå¦ãå¨æ¬æä¸­ï¼æåééå¼å¥ SDoEd æ¬é«ä¾å¡«è£éåç¼ºå£ï¼ä»¥å»ºç«å­¸ççæ´»ç°å¢èå¶å¯è½æè²æå°±ä¹éç¸äºä½ç¨çç²¾ç¢ºæ¦å¿µåãæ¬é«æ¯å©ç¨ ChatGPT-3.5-010422 çå»ºè­°éç¼çï¼ä¸¦ä½¿ç¨åè¡è©å¯©çç ç©¶æç« é²è¡é©è­ãéç¼æ¬é«çç¬¬ä¸åçæ¬ç±æè²é åçäººé¡å°å®¶è©ä¼°ï¼ä¸¦ä½¿ç¨æ¨æºæ¬é«è©ä¼°è»é«é²è¡é©è­ãæ­¤çæ¬ç SDoEd æ¬é«åå« 231 åç¶²åæ¦å¿µã10 åç©ä»¶å±¬æ§å 24 åè³æå±¬æ§

##### **SEANN: A Domain-Informed Neural Network for Epidemiological Insights**
2501.10273v1 by Jean-Baptiste Guimbaud, Marc Plantevit, LÃ©a MaÃ®tre, RÃ©my Cazabet

In epidemiology, traditional statistical methods such as logistic regression,
linear regression, and other parametric models are commonly employed to
investigate associations between predictors and health outcomes. However,
non-parametric machine learning techniques, such as deep neural networks
(DNNs), coupled with explainable AI (XAI) tools, offer new opportunities for
this task. Despite their potential, these methods face challenges due to the
limited availability of high-quality, high-quantity data in this field. To
address these challenges, we introduce SEANN, a novel approach for informed
DNNs that leverages a prevalent form of domain-specific knowledge: Pooled
Effect Sizes (PES). PESs are commonly found in published Meta-Analysis studies,
in different forms, and represent a quantitative form of a scientific
consensus. By direct integration within the learning procedure using a custom
loss, we experimentally demonstrate significant improvements in the
generalizability of predictive performances and the scientific plausibility of
extracted relationships compared to a domain-knowledge agnostic neural network
in a scarce and noisy data setting.

æè¦ï¼å¨æµè¡çå­¸ä¸­ï¼å³çµ±ççµ±è¨æ¹æ³ï¼ä¾å¦éè¼¯è¿´æ­¸ãç·æ§è¿´æ­¸åå¶ä»åæ¸æ¨¡åéå¸¸ç¨æ¼èª¿æ¥é æ¸¬å å­èå¥åº·çµæä¹éçéè¯ãç¶èï¼éåæ¸æ©å¨å­¸ç¿æè¡ï¼ä¾å¦æ·±åº¦ç¥ç¶ç¶²è·¯ (DNN)ï¼çµåå¯è§£éç AI (XAI) å·¥å·ï¼çºéé ä»»åæä¾äºæ°çæ©æãåç®¡éäºæ¹æ³å·ææ½åï¼ä½ç±æ¼è©²é åç¼ºä¹é«åè³ªãé«æ¸éè³æï¼å æ­¤éäºæ¹æ³é¢è¨ææ°ãçºäºæå°éäºææ°ï¼æåå¼å¥äº SEANNï¼éæ¯ä¸ç¨®æ°ç©çæ¹æ³ï¼ç¨æ¼ç²åç¥è­ç DNNï¼å®å©ç¨äºä¸ç¨®æµè¡çé åç¹å®ç¥è­å½¢å¼ï¼å½ç¸½ææé (PES)ãPES éå¸¸ä»¥ä¸åçå½¢å¼åºç¾å¨å·²ç¼è¡¨ç Meta åæç ç©¶ä¸­ï¼ä¸¦ä»£è¡¨ç§å­¸å±è­çéåå½¢å¼ãééä½¿ç¨èªè¨æå¤±å½æ¸ç´æ¥æ´åå¨å­¸ç¿ç¨åºä¸­ï¼æåä»¥å¯¦é©æ¹å¼è­æäºé æ¸¬æè½çæ¦æ¬æ§ä»¥åèå¾ç¼ºä¹é åç¥è­çç¥ç¶ç¶²è·¯ä¸­æåçéä¿ç¸æ¯ï¼ç§å­¸åçæ§çé¡¯èæåï¼ä¸æ¯å¨ç¨å°ä¸æéè¨çè³æè¨­å®ä¸­ã

##### **Challenges and recommendations for Electronic Health Records data extraction and preparation for dynamic prediction modelling in hospitalized patients -- a practical guide**
2501.10240v1 by Elena Albu, Shan Gao, Pieter Stijnen, Frank E. Rademakers, Bas C T van Bussel, Taya Collyer, Tina Hernandez-Boussard, Laure Wynants, Ben Van Calster

Dynamic predictive modeling using electronic health record (EHR) data has
gained significant attention in recent years. The reliability and
trustworthiness of such models depend heavily on the quality of the underlying
data, which is largely determined by the stages preceding the model
development: data extraction from EHR systems and data preparation. We list
over forty challenges encountered during these stages and provide actionable
recommendations for addressing them. These challenges are organized into four
categories: cohort definition, outcome definition, feature engineering, and
data cleaning. This list is designed to serve as a practical guide for data
extraction engineers and researchers, supporting better practices and improving
the quality and real-world applicability of dynamic prediction models in
clinical settings.

æè¦ï¼è¿å¹´ä¾ï¼ä½¿ç¨é»å­å¥åº·è¨é (EHR) è³æçåæé æ¸¬æ¨¡åç²å¾äºæ¥µå¤§çéæ³¨ãæ­¤é¡æ¨¡åçå¯é æ§åå¯ä¿¡åº¦å¨å¾å¤§ç¨åº¦ä¸åæ±ºæ¼åºç¤è³æçåè³ªï¼èéå¨å¾å¤§ç¨åº¦ä¸åæ±ºæ¼æ¨¡åéç¼ä¹åçéæ®µï¼å¾ EHR ç³»çµ±ä¸­æåè³æåè³ææºåãæåååºäºéäºéæ®µä¸­éå°çååå¤é ææ°ï¼ä¸¦æä¾äºå·é«å¯è¡çå»ºè­°ä¾è§£æ±ºéäºææ°ãéäºææ°åçºåé¡ï¼ç¾¤çµå®ç¾©ãçµæå®ç¾©ãç¹å¾µå·¥ç¨åè³ææ¸çãæ­¤æ¸å®æ¨å¨ä½çºè³ææåå·¥ç¨å¸«åç ç©¶äººå¡çå¯¦ç¨æåï¼æ¯æ´æ´å¥½çå¯¦åï¼ä¸¦æ¹ååæé æ¸¬æ¨¡åå¨è¨åºç°å¢ä¸­çåè³ªåå¯¦éæç¨æ§ã

##### **Generative Artificial Intelligence: Implications for Biomedical and Health Professions Education**
2501.10186v1 by William Hersh

Generative AI has had a profound impact on biomedicine and health, both in
professional work and in education. Based on large language models (LLMs),
generative AI has been found to perform as well as humans in simulated
situations taking medical board exams, answering clinical questions, solving
clinical cases, applying clinical reasoning, and summarizing information.
Generative AI is also being used widely in education, performing well in
academic courses and their assessments. This review summarizes the successes of
LLMs and highlights some of their challenges in the context of education, most
notably aspects that may undermines the acquisition of knowledge and skills for
professional work. It then provides recommendations for best practices
overcoming shortcomings for LLM use in education. Although there are challenges
for use of generative AI in education, all students and faculty, in biomedicine
and health and beyond, must have understanding and be competent in its use.

æè¦ï¼çæå¼ AI å°çç©é«å­¸åå¥åº·é åç¢çäºæ·±é çå½±é¿ï¼ç¡è«æ¯å¨å°æ¥­å·¥ä½éæ¯æè²æ¹é¢ãåºæ¼å¤§åèªè¨æ¨¡å (LLM)ï¼ç¼ç¾çæå¼ AI å¨æ¨¡æ¬é«çå§å¡æèè©¦ãåç­è¨åºåé¡ãè§£æ±ºè¨åºæ¡ä¾ãæç¨è¨åºæ¨çåç¸½çµè³è¨ç­ææ³ä¸ï¼è¡¨ç¾å¾èäººé¡ä¸æ¨£å¥½ãçæå¼ AI ä¹å»£æ³æç¨æ¼æè²ä¸­ï¼å¨å­¸è¡èª²ç¨åå¶è©ä¼°ä¸­è¡¨ç¾è¯å¥½ãæ¬ç¯è©è«ç¸½çµäº LLM çæåï¼ä¸¦å¼·èª¿äºå®åå¨æè²èæ¯ä¸çä¸äºææ°ï¼æå¼å¾æ³¨æçæ¯å¯è½æå®³å°æ¥­å·¥ä½ç¥è­åæè½ç¿å¾çæ¹é¢ãç¶å¾ï¼å®éå°åæ LLM å¨æè²ä¸­ä½¿ç¨çç¼ºé»æä¾äºæä½³å¯¦åå»ºè­°ãåç®¡çæå¼ AI å¨æè²ä¸­ä½¿ç¨å­å¨ææ°ï¼ä½çç©é«å­¸åå¥åº·é åä»¥åå¶ä»é åçææå­¸çåæè·å¡å·¥é½å¿é äºè§£ä¸¦çç·´ä½¿ç¨å®ã

##### **CSSDM Ontology to Enable Continuity of Care Data Interoperability**
2501.10160v1 by Subhashis Das, Debashis Naskar, Sara Rodriguez Gonzalez, Pamela Hussey

The rapid advancement of digital technologies and recent global pandemic
scenarios have led to a growing focus on how these technologies can enhance
healthcare service delivery and workflow to address crises. Action plans that
consolidate existing digital transformation programs are being reviewed to
establish core infrastructure and foundations for sustainable healthcare
solutions. Reforming health and social care to personalize home care, for
example, can help avoid treatment in overcrowded acute hospital settings and
improve the experiences and outcomes for both healthcare professionals and
service users. In this information-intensive domain, addressing the
interoperability challenge through standards-based roadmaps is crucial for
enabling effective connections between health and social care services. This
approach facilitates safe and trustworthy data workflows between different
healthcare system providers. In this paper, we present a methodology for
extracting, transforming, and loading data through a semi-automated process
using a Common Semantic Standardized Data Model (CSSDM) to create personalized
healthcare knowledge graph (KG). The CSSDM is grounded in the formal ontology
of ISO 13940 ContSys and incorporates FHIR-based specifications to support
structural attributes for generating KGs. We propose that the CSSDM facilitates
data harmonization and linking, offering an alternative approach to
interoperability. This approach promotes a novel form of collaboration between
companies developing health information systems and cloud-enabled health
services. Consequently, it provides multiple stakeholders with access to
high-quality data and information sharing.

æè¦ï¼æ¸ä½ç§æå¿«éé²æ­¥åæè¿çå¨çå¤§æµè¡çæå¢å·²å°è´è¶ä¾è¶å¤äººå°æ³¨æ¼éäºç§æå¦ä½å¢å¼·é«çä¿å¥æåæä¾åå·¥ä½æµç¨ä»¥æå°å±æ©ãæ´åç¾ææ¸ä½è½åè¨ç«çè¡åè¨ç«æ­£è¢«æª¢è¦ï¼ä»¥å»ºç«æ°¸çºé«çä¿å¥è§£æ±ºæ¹æ¡çæ ¸å¿åºç¤æ¶æ§ååºç¤ãä¾å¦ï¼æ¹é©é«çåç¤¾æç§è­·ä»¥åäººåå±å®¶ç§è­·ï¼æå©æ¼é¿åå¨äººæ»¿çºæ£çæ¥æ§é«é¢ç°å¢ä¸­æ¥åæ²»çï¼ä¸¦æ¹åé«çä¿å¥å°æ¥­äººå¡åæåä½¿ç¨èçç¶é©åçµæãå¨éåè³è¨å¯éçé åï¼ééåºæ¼æ¨æºçè·¯å¾åä¾è§£æ±ºäºéæ§ææ°ï¼å°æ¼ä¿æé«çä¿å¥æååç¤¾æç§è­·æåä¹éçææé£çµè³ééè¦ãæ­¤æ¹æ³ä¿æä¸åé«çä¿å¥ç³»çµ±ä¾æåä¹éå®å¨ä¸å¼å¾ä¿¡è³´çè³æå·¥ä½æµç¨ãå¨æ¬æä¸­ï¼æåæåºä¸åæ¹æ³ï¼ééåèªååæµç¨ä½¿ç¨éç¨èªææ¨æºåè³ææ¨¡å (CSSDM) ä¾èåãè½æåè¼å¥è³æï¼ä»¥å»ºç«åäººåçé«çä¿å¥ç¥è­åè­ (KG)ãCSSDM ä»¥ ISO 13940 ContSys çæ­£å¼æ¬ä½è«çºåºç¤ï¼ä¸¦çµååºæ¼ FHIR çè¦æ ¼ä¾æ¯æ´ç¨æ¼ç¢ç KG ççµæ§å±¬æ§ãæåæåº CSSDM ä¿é²è³æèª¿ååé£çµï¼æä¾ä¸ç¨®äºéæ§çæ¿ä»£æ¹æ³ãæ­¤æ¹æ³ä¿æéç¼é«çè³è¨ç³»çµ±åé²ç«¯é«çæåçå¬å¸ä¹éçä¸ç¨®æ°ååä½å½¢å¼ãå æ­¤ï¼å®æä¾å¤åå©å®³éä¿äººå­åé«åè³ªè³æåè³è¨å±äº«ã

##### **landmarker: a Toolkit for Anatomical Landmark Localization in 2D/3D Images**
2501.10098v1 by Jef Jonkers, Luc Duchateau, Glenn Van Wallendael, Sofie Van Hoecke

Anatomical landmark localization in 2D/3D images is a critical task in
medical imaging. Although many general-purpose tools exist for landmark
localization in classical computer vision tasks, such as pose estimation, they
lack the specialized features and modularity necessary for anatomical landmark
localization applications in the medical domain. Therefore, we introduce
landmarker, a Python package built on PyTorch. The package provides a
comprehensive, flexible toolkit for developing and evaluating landmark
localization algorithms, supporting a range of methodologies, including static
and adaptive heatmap regression. landmarker enhances the accuracy of landmark
identification, streamlines research and development processes, and supports
various image formats and preprocessing pipelines. Its modular design allows
users to customize and extend the toolkit for specific datasets and
applications, accelerating innovation in medical imaging. landmarker addresses
a critical need for precision and customization in landmark localization tasks
not adequately met by existing general-purpose pose estimation tools.

æè¦ï¼å¨ 2D/3D å½±åä¸­é²è¡è§£åæ¨èªå®ä½æ¯é«å­¸å½±åä¸­çä¸é ééµä»»åãåç®¡æè¨±å¤éç¨å·¥å·å¯ç¨æ¼ç¶å¸é»è¦è¦è¦ºä»»åä¸­çæ¨èªå®ä½ï¼ä¾å¦å§¿å¢ä¼°è¨ï¼ä½å®åç¼ºä¹è§£åæ¨èªå®ä½æç¨å¨é«å­¸é åä¸­æéçå°æ¥­åè½åæ¨¡çµåãå æ­¤ï¼æåå¼å¥äº landmarkerï¼ä¸åå»ºç«å¨ PyTorch ä¸ç Python å¥ä»¶ãè©²å¥ä»¶æä¾äºä¸åå¨é¢ä¸éæ´»çå·¥å·åï¼ç¨æ¼éç¼åè©ä¼°æ¨èªå®ä½æ¼ç®æ³ï¼æ¯æ´åç¨®æ¹æ³ï¼åæ¬éæåèªé©æç±ååæ­¸ãlandmarker æåäºæ¨èªè­å¥çæºç¢ºæ§ï¼ç°¡åäºç ç©¶åéç¼æµç¨ï¼ä¸¦æ¯æ´åç¨®å½±åæ ¼å¼ååèçç®¡éãå¶æ¨¡çµåè¨­è¨ä½¿ç¨æ¶è½å¤ èªè¨åå»¶ä¼¸å·¥å·åï¼ä»¥é©ç¨æ¼ç¹å®è³æéåæç¨ï¼å éé«å­¸å½±åçåµæ°ãlandmarker æ»¿è¶³äºç¾æéç¨å§¿å¢ä¼°è¨å·¥å·ç¡æ³ååæ»¿è¶³çæ¨èªå®ä½ä»»åä¸­å°æ¼ç²¾ç¢ºåº¦åèªè¨åçééµéæ±ã

##### **Deep Learning for Early Alzheimer Disease Detection with MRI Scans**
2501.09999v1 by Mohammad Rafsan, Tamer Oraby, Upal Roy, Sanjeev Kumar, Hansapani Rodrigo

Alzheimer's Disease is a neurodegenerative condition characterized by
dementia and impairment in neurological function. The study primarily focuses
on the individuals above age 40, affecting their memory, behavior, and
cognitive processes of the brain. Alzheimer's disease requires diagnosis by a
detailed assessment of MRI scans and neuropsychological tests of the patients.
This project compares existing deep learning models in the pursuit of enhancing
the accuracy and efficiency of AD diagnosis, specifically focusing on the
Convolutional Neural Network, Bayesian Convolutional Neural Network, and the
U-net model with the Open Access Series of Imaging Studies brain MRI dataset.
Besides, to ensure robustness and reliability in the model evaluations, we
address the challenge of imbalance in data. We then perform rigorous evaluation
to determine strengths and weaknesses for each model by considering
sensitivity, specificity, and computational efficiency. This comparative
analysis would shed light on the future role of AI in revolutionizing AD
diagnostics but also paved ways for future innovation in medical imaging and
the management of neurodegenerative diseases.

æè¦ï¼é¿è²æµ·é»çæ¯ä¸ç¨®ç¥ç¶éåæ§ç¾çï¼ç¹å¾µçºå¤±æºåç¥ç¶åè½åæãæ¬ç ç©¶ä¸»è¦éå° 40 æ­²ä»¥ä¸çåäººï¼å½±é¿ä»åçè¨æ¶åãè¡çºåèªç¥éç¨ãé¿è²æµ·é»çéè¦ééè©³ç´°è©ä¼°çæ£ç MRI ææåç¥ç¶å¿çæ¸¬è©¦ä¾è¨ºæ·ãæ¬å°æ¡æ¯è¼ç¾æçæ·±åº¦å­¸ç¿æ¨¡åï¼ä»¥å°æ±æå AD è¨ºæ·çæºç¢ºæ§åæçï¼ç¹å¥èéæ¼å·ç©ç¥ç¶ç¶²è·¯ãè²æ°å·ç©ç¥ç¶ç¶²è·¯å U-net æ¨¡åï¼ä»¥åéæ¾åç¨å½±åç ç©¶ç³»åçè¦é¨ MRI è³æéãæ­¤å¤ï¼çºäºç¢ºä¿æ¨¡åè©ä¼°çç©©å¥æ§åå¯é æ§ï¼æåè§£æ±ºäºè³æä¸å¹³è¡¡çææ°ãæ¥èæåå·è¡å´è¬¹çè©ä¼°ï¼ééèéææåº¦ãç¹ç°åº¦åè¨ç®æçä¾ç¢ºå®æ¯åæ¨¡åçåªç¼ºé»ãæ­¤æ¯è¼åæå°é¡æ AI å¨é©æ° AD è¨ºæ·æ¹é¢çæªä¾è§è²ï¼ä¹çºé«å­¸å½±ååç¥ç¶éåæ§ç¾çç®¡ççæªä¾åµæ°éªè·¯ã

##### **Aneumo: A Large-Scale Comprehensive Synthetic Dataset of Aneurysm Hemodynamics**
2501.09980v1 by Xigui Li, Yuanye Zhou, Feiyang Xiao, Xin Guo, Yichi Zhang, Chen Jiang, Jianchao Ge, Xiansheng Wang, Qimeng Wang, Taiwei Zhang, Chensen Lin, Yuan Cheng, Yuan Qi

Intracranial aneurysm (IA) is a common cerebrovascular disease that is
usually asymptomatic but may cause severe subarachnoid hemorrhage (SAH) if
ruptured. Although clinical practice is usually based on individual factors and
morphological features of the aneurysm, its pathophysiology and hemodynamic
mechanisms remain controversial. To address the limitations of current
research, this study constructed a comprehensive hemodynamic dataset of
intracranial aneurysms. The dataset is based on 466 real aneurysm models, and
10,000 synthetic models were generated by resection and deformation operations,
including 466 aneurysm-free models and 9,534 deformed aneurysm models. The
dataset also provides medical image-like segmentation mask files to support
insightful analysis. In addition, the dataset contains hemodynamic data
measured at eight steady-state flow rates (0.001 to 0.004 kg/s), including
critical parameters such as flow velocity, pressure, and wall shear stress,
providing a valuable resource for investigating aneurysm pathogenesis and
clinical prediction. This dataset will help advance the understanding of the
pathologic features and hemodynamic mechanisms of intracranial aneurysms and
support in-depth research in related fields. Dataset hosted at
https://github.com/Xigui-Li/Aneumo.

æè¦ï¼é¡±å§åèç¤ï¼IAï¼æ¯ä¸ç¨®å¸¸è¦çè¦è¡ç®¡ç¾çï¼éå¸¸ç¡ççï¼ä½å¦æç ´è£å¯è½æå°è´å´éçèç¶²èä¸èåºè¡ï¼SAHï¼ãåç®¡è¨åºå¯¦åéå¸¸åºæ¼åé«å ç´ ååèç¤çå½¢æç¹å¾µï¼ä½å¶ççççå­¸åè¡æµååå­¸æ©å¶ä»å­å¨ç­è­°ãçºäºè§£æ±ºç¶åç ç©¶çéå¶ï¼æ¬ç ç©¶æ§å»ºäºä¸åé¡±å§åèç¤çå¨é¢è¡æµååå­¸æ¸æéãè©²æ¸æéåºæ¼ 466 åçå¯¦åèç¤æ¨¡åï¼ä¸¦ééåé¤åè®å½¢æä½çæäº 10,000 ååææ¨¡åï¼åæ¬ 466 åç¡åèç¤æ¨¡åå 9,534 åè®å½¢åèç¤æ¨¡åãè©²æ¸æééæä¾äºé¡é«å­¸å½±åçåå²é®ç½©æªæ¡ï¼ä»¥æ¯ææ·±å¥åæãæ­¤å¤ï¼è©²æ¸æéåå«å¨å«åç©©ææµéï¼0.001 è³ 0.004 kg/sï¼ä¸æ¸¬éçè¡æµååå­¸æ¸æï¼åæ¬æµéãå£ååå£é¢åªæåç­ééµåæ¸ï¼çºç ç©¶åèç¤ç¼çæ©å¶åè¨åºé æ¸¬æä¾äºå¯¶è²´çè³æºãæ­¤æ¸æéå°æå©æ¼å¢é²å°é¡±å§åèç¤ççç¹å¾µåè¡æµååå­¸æ©å¶çäºè§£ï¼ä¸¦æ¯æç¸éé åçæ·±å¥ç ç©¶ãæ¸æéè¨ç®¡æ¼ https://github.com/Xigui-Li/Aneumoã

##### **Bias in Decision-Making for AI's Ethical Dilemmas: A Comparative Study of ChatGPT and Claude**
2501.10484v1 by Yile Yan, Yuqi Zhu, Wentao Xu

Recent advances in Large Language Models (LLMs) have enabled human-like
responses across various tasks, raising questions about their ethical
decision-making capabilities and potential biases. This study investigates
protected attributes in LLMs through systematic evaluation of their responses
to ethical dilemmas. Using two prominent models - GPT-3.5 Turbo and Claude 3.5
Sonnet - we analyzed their decision-making patterns across multiple protected
attributes including age, gender, race, appearance, and disability status.
Through 11,200 experimental trials involving both single-factor and two-factor
protected attribute combinations, we evaluated the models' ethical preferences,
sensitivity, stability, and clustering of preferences. Our findings reveal
significant protected attributeses in both models, with consistent preferences
for certain features (e.g., "good-looking") and systematic neglect of others.
Notably, while GPT-3.5 Turbo showed stronger preferences aligned with
traditional power structures, Claude 3.5 Sonnet demonstrated more diverse
protected attribute choices. We also found that ethical sensitivity
significantly decreases in more complex scenarios involving multiple protected
attributes. Additionally, linguistic referents heavily influence the models'
ethical evaluations, as demonstrated by differing responses to racial
descriptors (e.g., "Yellow" versus "Asian"). These findings highlight critical
concerns about the potential impact of LLM biases in autonomous decision-making
systems and emphasize the need for careful consideration of protected
attributes in AI development. Our study contributes to the growing body of
research on AI ethics by providing a systematic framework for evaluating
protected attributes in LLMs' ethical decision-making capabilities.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) è¿æçé²å±ï¼è®äººåå¨åç¨®ä»»åä¸­é½è½ååºé¡ä¼¼äººé¡çåæï¼éä¹å¼ç¼äºäººåå°å¶éå¾·æ±ºç­è½ååæ½å¨åè¦çè³ªçãæ¬ç ç©¶ééç³»çµ±æ§å°è©ä¼° LLM å°éå¾·å°å¢çåæï¼ä¾æ¢è¨åä¿è­·å±¬æ§å¨ LLM ä¸­çè¡¨ç¾ãæåä½¿ç¨å©åèåçæ¨¡å - GPT-3.5 Turbo å Claude 3.5 Sonnet - åæäºå®åå¨å¤ååä¿è­·å±¬æ§ï¼åæ¬å¹´é½¡ãæ§å¥ãç¨®æãå¤è²åæ®ç¾çæï¼ä¸çæ±ºç­æ¨¡å¼ãéé 11,200 æ¬¡å¯¦é©è©¦é©ï¼åæ¬å®å ç´ åéå ç´ åä¿è­·å±¬æ§çµåï¼ï¼æåè©ä¼°äºæ¨¡åçéå¾·åå¥½ãææåº¦ãç©©å®æ§ååå¥½ç¾¤éãæåçç ç©¶çµææ­ç¤ºäºéå©åæ¨¡åä¸­é¡¯èçåä¿è­·å±¬æ§ï¼å®åå°æäºç¹å¾µï¼ä¾å¦ãå¥½çãï¼ææçºçåå¥½ï¼ä¸¦ä¸ç³»çµ±æ§å°å¿½ç¥å¶ä»ç¹å¾µãå¼å¾æ³¨æçæ¯ï¼éç¶ GPT-3.5 Turbo è¡¨ç¾åºèå³çµ±æ¬åçµæ§ä¸è´çå¼·çåå¥½ï¼ä½ Claude 3.5 Sonnet åè¡¨ç¾åºæ´å¤æ¨£åçåä¿è­·å±¬æ§é¸æãæåéç¼ç¾ï¼å¨æ¶åå¤ååä¿è­·å±¬æ§çæ´è¤éå ´æ¯ä¸­ï¼éå¾·ææåº¦æé¡¯èéä½ãæ­¤å¤ï¼èªè¨æç¨±æå´éå½±é¿æ¨¡åçéå¾·è©ä¼°ï¼éå¾å°ç¨®ææè¿°ç¬¦ï¼ä¾å¦ãé»è²ãèãäºæ´²äººãï¼çä¸ååæä¸­å¯ä»¥çåºãéäºç¼ç¾çªé¡¯äº LLM åè¦å¨èªä¸»æ±ºç­ç³»çµ±ä¸­æ½å¨å½±é¿çééµåé¡ï¼ä¸¦å¼·èª¿å¨ AI éç¼ä¸­ä»ç´°èæ®åä¿è­·å±¬æ§çå¿è¦æ§ãæåçç ç©¶ééæä¾ä¸åç³»çµ±æ§çæ¶æ§ä¾è©ä¼° LLM éå¾·æ±ºç­è½åä¸­çåä¿è­·å±¬æ§ï¼çº AI å«çé åçç ç©¶ååºäºè²¢ç»ã

##### **Bridging Language Barriers in Healthcare: A Study on Arabic LLMs**
2501.09825v1 by Nada Saadi, Tathagata Raha, ClÃ©ment Christophe, Marco AF Pimentel, Ronnie Rajan, Praveen K Kanithi

This paper investigates the challenges of developing large language models
(LLMs) proficient in both multilingual understanding and medical knowledge. We
demonstrate that simply translating medical data does not guarantee strong
performance on clinical tasks in the target language. Our experiments reveal
that the optimal language mix in training data varies significantly across
different medical tasks. We find that larger models with carefully calibrated
language ratios achieve superior performance on native-language clinical tasks.
Furthermore, our results suggest that relying solely on fine-tuning may not be
the most effective approach for incorporating new language knowledge into LLMs.
Instead, data and computationally intensive pretraining methods may still be
necessary to achieve optimal performance in multilingual medical settings.
These findings provide valuable guidance for building effective and inclusive
medical AI systems for diverse linguistic communities.

æè¦ï¼æ¬ææ¢è¨äºéç¼æ¢ç²¾éå¤èªè¨çè§£åç²¾éé«çç¥è­çå¤§åèªè¨æ¨¡å (LLM) çææ°ãæåè­æï¼åç¿»è­¯é«çè³æä¸¦ä¸è½ä¿è­å¨ç®æ¨èªè¨çè¨åºä»»åä¸­è¡¨ç¾åºè²ãæåçå¯¦é©æ­ç¤ºï¼è¨ç·´è³æä¸­çæä½³èªè¨çµåå ä¸åçé«çä»»åèç°ãæåç¼ç¾ï¼å·æä»ç´°æ ¡æºèªè¨æ¯ä¾çè¼å¤§æ¨¡åå¨æ¯èªè¨åºä»»åä¸­è¡¨ç¾æ´ä½³ãæ­¤å¤ï¼æåççµæè¡¨æï¼åä¾è³´å¾®èª¿å¯è½ä¸æ¯å°æ°çèªè¨ç¥è­ç´å¥ LLM çææææ¹æ³ãç¸åï¼è³æåè¨ç®å¯éåé è¨ç·´æ¹æ³å°æ¼å¨å¤èªè¨é«çç°å¢ä¸­å¯¦ç¾æä½³æè½å¯è½ä»ç¶å¿è¦ãéäºç¼ç¾çºå»ºç«ææä¸åå®¹æ§çé«ç AI ç³»çµ±ï¼ä»¥æåæ¼ä¸åçèªè¨ç¤¾ç¾¤ï¼æä¾äºæå¹å¼çæå°æ¹éã

##### **KU AIGEN ICL EDI@BC8 Track 3: Advancing Phenotype Named Entity Recognition and Normalization for Dysmorphology Physical Examination Reports**
2501.09744v1 by Hajung Kim, Chanhwi Kim, Jiwoong Sohn, Tim Beck, Marek Rei, Sunkyu Kim, T Ian Simpson, Joram M Posma, Antoine Lain, Mujeen Sung, Jaewoo Kang

The objective of BioCreative8 Track 3 is to extract phenotypic key medical
findings embedded within EHR texts and subsequently normalize these findings to
their Human Phenotype Ontology (HPO) terms. However, the presence of diverse
surface forms in phenotypic findings makes it challenging to accurately
normalize them to the correct HPO terms. To address this challenge, we explored
various models for named entity recognition and implemented data augmentation
techniques such as synonym marginalization to enhance the normalization step.
Our pipeline resulted in an exact extraction and normalization F1 score 2.6\%
higher than the mean score of all submissions received in response to the
challenge. Furthermore, in terms of the normalization F1 score, our approach
surpassed the average performance by 1.9\%. These findings contribute to the
advancement of automated medical data extraction and normalization techniques,
showcasing potential pathways for future research and application in the
biomedical domain.

æè¦ï¼BioCreative8 è»é 3 çç®æ¨æ¯å¾é»å­çæ­·ææ¬ä¸­èåè¡¨åééµé«çç¼ç¾ï¼ä¸¦å°éäºç¼ç¾æ¨æºåçºäººé¡è¡¨åæ¬ä½ (HPO) æ¢æ¬¾ãç¶èï¼è¡¨åç¼ç¾ä¸­å­å¨å¤æ¨£åçè¡¨é¢å½¢å¼ï¼éä½¿å¾å°å¶æºç¢ºæ¨æºåçºæ­£ç¢ºç HPO æ¢æ¬¾å·æææ°æ§ãçºäºæå°éä¸ææ°ï¼æåæ¢è¨äºå½åå¯¦é«è­å¥çåç¨®æ¨¡åï¼ä¸¦å¯¦ä½äºè³ææ´åæè¡ï¼ä¾å¦åç¾©è©éç·£åï¼ä»¥å¢å¼·æ¨æºåæ­¥é©ãæåçç®¡éç¢çäºç²¾ç¢ºçèååæ¨æºå F1 åæ¸ï¼æ¯åæææ°ææ¶å°çæææäº¤çå¹³ååæ¸é« 2.6%ãæ­¤å¤ï¼å¨æ¨æºå F1 åæ¸æ¹é¢ï¼æåçåæ³æ¯å¹³åè¡¨ç¾é«åº 1.9%ãéäºç¼ç¾æå©æ¼èªååé«çè³æèååæ¨æºåæè¡çé²å±ï¼å±ç¤ºäºçç©é«å­¸é åæªä¾ç ç©¶åæç¨çæ½å¨éå¾ã

##### **Electronic Health Records: Towards Digital Twins in Healthcare**
2501.09640v1 by Muhammet Alkan, Hester Huijsdens, Yola Jones, Fani Deligianni

The pivotal shift from traditional paper-based records to sophisticated
Electronic Health Records (EHR), enabled systematic collection and analysis of
patient data through descriptive statistics, providing insight into patterns
and trends across patient populations. This evolution continued toward
predictive analytics, allowing healthcare providers to anticipate patient
outcomes and potential complications before they occur. This progression from
basic digital record-keeping to sophisticated predictive modelling and digital
twins reflects healthcare's broader evolution toward more integrated,
patient-centred approaches that combine data-driven insights with personalized
care delivery. This chapter explores the evolution and significance of
healthcare information systems, beginning with an examination of the
implementation of EHR in the UK and the USA. It provides a comprehensive
overview of the International Classification of Diseases (ICD) system, tracing
its development from ICD-9 to ICD-10. Central to this discussion is the
MIMIC-III database, a landmark achievement in healthcare data sharing and
arguably the most comprehensive critical care database freely available to
researchers worldwide. MIMIC-III has democratized access to high-quality
healthcare data, enabling unprecedented opportunities for research and
analysis. The chapter examines its structure, clinical outcome analysis
capabilities, and practical applications through case studies, with a
particular focus on mortality and length of stay metrics, vital signs
extraction, and ICD coding. Through detailed entity-relationship diagrams and
practical examples, the text illustrates MIMIC's complex data structure and
demonstrates how different querying approaches can lead to subtly different
results, emphasizing the critical importance of understanding the database's
architecture for accurate data extraction.

æè¦ï¼å¾å³çµ±ç´æ¬è¨éè½è®çºåé²çé»å­å¥åº·è¨éï¼EHRï¼ï¼ä¿ä½¿ééæè¿°æ§çµ±è¨ç³»çµ±æ§å°æ¶éååæçæ£è³æï¼é²èæ·±å¥äºè§£çæ£æç¾¤çæ¨¡å¼åè¶¨å¢ãéé æ¼é²æçºæåé æ¸¬åæç¼å±ï¼è®é«çä¿å¥æä¾èè½å¤ å¨çæ£åºç¾çµæåæ½å¨ä½µç¼çä¹åé æ¸¬éäºçæ³ãå¾åºæ¬çæ¸ä½è¨éä¿å­é²å±å°åé²çé æ¸¬æ¨¡ååæ¸ä½éèèï¼åæ äºé«çä¿å¥æåæ´æ´åãä»¥çæ£çºä¸­å¿çåæ³æåçæ´å»£æ³æ¼é²ï¼éäºåæ³çµåäºè³æé©åçè¦è§£èåäººåç§è­·æåãæ¬ç« æ¢è¨é«çä¿å¥è³è¨ç³»çµ±çæ¼é²åéè¦æ§ï¼å¾å¯©æ¥è±ååç¾åå¯¦æ½ EHR éå§ãå®æä¾äºç¾çåéåé¡ï¼ICDï¼ç³»çµ±çå¨é¢æ¦è¿°ï¼è¿½æº¯å¶å¾ ICD-9 ç¼å±å° ICD-10 çéç¨ãæ­¤è¨è«çæ ¸å¿æ¯ MIMIC-III è³æåº«ï¼éæ¯é«çä¿å¥è³æå±äº«çä¸é éç¨ç¢å¼æå°±ï¼å¯ä»¥èªªæ¯å¨çç ç©¶äººå¡å¯ä»¥åè²»åå¾çæå¨é¢çéçç§è­·è³æåº«ãMIMIC-III æ°ä¸»åäºå°é«åè³ªé«çä¿å¥è³æçå­åï¼çºç ç©¶ååæåµé äºåææªæçæ©æãæ¬ç« ééæ¡ä¾ç ç©¶æ¢è¨å¶çµæ§ãè¨åºçµæåæè½ååå¯¦éæç¨ï¼ç¹å¥éæ³¨æ­»äº¡çåä½é¢æéææ¨ãçå½å¾µè±¡èåå ICD ç·¨ç¢¼ãééè©³ç´°çå¯¦é«éä¿ååå¯¦åç¯ä¾ï¼æ¬æèªªæäº MIMIC è¤éçè³æçµæ§ï¼ä¸¦å±ç¤ºäºä¸åçæ¥è©¢æ¹æ³å¦ä½å°è´ç´°å¾®ä¸åççµæï¼å¼·èª¿äºäºè§£è³æåº«æ¶æ§å°æ¼æºç¢ºèåè³æè³ééè¦çéè¦æ§ã

##### **Artificial Intelligence-Driven Clinical Decision Support Systems**
2501.09628v1 by Muhammet Alkan, Idris Zakariyya, Samuel Leighton, Kaushik Bhargav Sivangi, Christos Anagnostopoulos, Fani Deligianni

As artificial intelligence (AI) becomes increasingly embedded in healthcare
delivery, this chapter explores the critical aspects of developing reliable and
ethical Clinical Decision Support Systems (CDSS). Beginning with the
fundamental transition from traditional statistical models to sophisticated
machine learning approaches, this work examines rigorous validation strategies
and performance assessment methods, including the crucial role of model
calibration and decision curve analysis. The chapter emphasizes that creating
trustworthy AI systems in healthcare requires more than just technical
accuracy; it demands careful consideration of fairness, explainability, and
privacy. The challenge of ensuring equitable healthcare delivery through AI is
stressed, discussing methods to identify and mitigate bias in clinical
predictive models. The chapter then delves into explainability as a cornerstone
of human-centered CDSS. This focus reflects the understanding that healthcare
professionals must not only trust AI recommendations but also comprehend their
underlying reasoning. The discussion advances in an analysis of privacy
vulnerabilities in medical AI systems, from data leakage in deep learning
models to sophisticated attacks against model explanations. The text explores
privacy-preservation strategies such as differential privacy and federated
learning, while acknowledging the inherent trade-offs between privacy
protection and model performance. This progression, from technical validation
to ethical considerations, reflects the multifaceted challenges of developing
AI systems that can be seamlessly and reliably integrated into daily clinical
practice while maintaining the highest standards of patient care and data
protection.

æè¦ï¼é¨èäººå·¥æºæ§ (AI) å¨é«çä¿å¥ä¸­çæç¨æ¥çæ®åï¼æ¬ç« æ¢è¨äºéç¼å¯é ä¸ç¬¦åéå¾·æ¨æºçè¨åºæ±ºç­æ¯æ´ç³»çµ± (CDSS) çééµé¢åãå¾å³çµ±çµ±è¨æ¨¡åå°è¤éæ©å¨å­¸ç¿æ¹æ³çåºæ¬è½è®éå§ï¼éé å·¥ä½å¯©æ¥äºå´è¬¹çé©è­ç­ç¥åæè½è©ä¼°æ¹æ³ï¼åæ¬æ¨¡åæ ¡æºåæ±ºç­æ²ç·åæçééµè§è²ãæ¬ç« å¼·èª¿ï¼å¨é«çä¿å¥ä¸­å»ºç«å¼å¾ä¿¡è³´ç AI ç³»çµ±ä¸åªæ¯æè¡ä¸çæºç¢ºæ§ï¼å®éè¦ä»ç´°èéå¬å¹³æ§ãå¯è§£éæ§åé±ç§æ¬ãæ¬ç« å¼·èª¿äºéé AI ç¢ºä¿å¬å¹³çé«çä¿å¥æåçææ°ï¼ä¸¦è¨è«äºè­å¥åæ¸è¼è¨åºé æ¸¬æ¨¡åä¸­åå·®çæ¹æ³ãæ¥èï¼æ¬ç« æ·±å¥æ¢è¨å¯è§£éæ§ï¼ä½çºä»¥äººçºä¸­å¿ç CDSS çåºç³ãéç¨®éæ³¨åæ äºé«çä¿å¥å°æ¥­äººå¡ä¸åå¿é ä¿¡ä»» AI å»ºè­°ï¼éå¿é çè§£å¶èå¾çæ¨çãè¨è«é²ä¸æ­¥åæäºé«ç AI ç³»çµ±ä¸­çé±ç§æ¼æ´ï¼å¾æ·±åº¦å­¸ç¿æ¨¡åä¸­çè³æå¤æ´©å°éå°æ¨¡åè§£éçè¤éæ»æãæ¬ææ¢è¨äºé±ç§ä¿è­·ç­ç¥ï¼ä¾å¦å·®åé±ç§åè¯åå­¸ç¿ï¼åææ¿èªé±ç§ä¿è­·åæ¨¡åæè½ä¹éçåºæåæ¨ãéç¨®å¾æè¡é©è­å°éå¾·èéçé²å±ï¼åæ äºéç¼ AI ç³»çµ±çå¤é¢åææ°ï¼éäºç³»çµ±å¯ä»¥ç¡ç¸«ä¸å¯é å°æ´åå°æ¥å¸¸è¨åºå¯¦åä¸­ï¼åæç¶­ææé«ççæ£ç§è­·åè³æä¿è­·æ¨æºã

##### **IFRA: a machine learning-based Instrumented Fall Risk Assessment Scale derived from Instrumented Timed Up and Go test in stroke patients**
2501.09595v1 by Simone MacciÃ², Alessandro CarfÃ¬, Alessio Capitanelli, Peppino Tropea, Massimo Corbo, Fulvio Mastrogiovanni, Michela Picardi

Effective fall risk assessment is critical for post-stroke patients. The
present study proposes a novel, data-informed fall risk assessment method based
on the instrumented Timed Up and Go (ITUG) test data, bringing in many mobility
measures that traditional clinical scales fail to capture. IFRA, which stands
for Instrumented Fall Risk Assessment, has been developed using a two-step
process: first, features with the highest predictive power among those
collected in a ITUG test have been identified using machine learning
techniques; then, a strategy is proposed to stratify patients into low, medium,
or high-risk strata. The dataset used in our analysis consists of 142
participants, out of which 93 were used for training (15 synthetically
generated), 17 for validation and 32 to test the resulting IFRA scale (22
non-fallers and 10 fallers). Features considered in the IFRA scale include gait
speed, vertical acceleration during sit-to-walk transition, and turning angular
velocity, which align well with established literature on the risk of fall in
neurological patients. In a comparison with traditional clinical scales such as
the traditional Timed Up & Go and the Mini-BESTest, IFRA demonstrates
competitive performance, being the only scale to correctly assign more than
half of the fallers to the high-risk stratum (Fischer's Exact test p = 0.004).
Despite the dataset's limited size, this is the first proof-of-concept study to
pave the way for future evidence regarding the use of IFRA tool for continuous
patient monitoring and fall prevention both in clinical stroke rehabilitation
and at home post-discharge.

æè¦ï¼<paragraph>å°ä¸­é¢¨å¾æ£èèè¨ï¼ææçè·åé¢¨éªè©ä¼°è³ééè¦ãæ¬ç ç©¶æåºä¸ååµæ°çãåºæ¼è³æçè·åé¢¨éªè©ä¼°æ¹æ³ï¼è©²æ¹æ³åºæ¼åå¨åçè¨æèµ·èº«åè¡èµ° (ITUG) æ¸¬è©¦è³æï¼ç´å¥äºè¨±å¤å³çµ±è¨åºéè¡¨æªè½ææå°çæ´»åè½åæ¸¬éææ¨ãIFRAï¼ä»£è¡¨åå¨åè·åé¢¨éªè©ä¼°ï¼å·²ä½¿ç¨å©æ­¥é©æµç¨éç¼ï¼é¦åï¼å·²ä½¿ç¨æ©å¨å­¸ç¿æè¡è­å¥åºå¨ ITUG æ¸¬è©¦ä¸­æ¶éçé£äºå·ææé«é æ¸¬è½åçç¹å¾µï¼ç¶å¾ï¼æåºäºä¸é ç­ç¥å°æ£èåå±¤çºä½é¢¨éªãä¸­é¢¨éªæé«é¢¨éªç­ç´ãæåçåæä¸­ä½¿ç¨çè³æéåå« 142 ååèèï¼å¶ä¸­ 93 åç¨æ¼è¨ç·´ï¼15 ååæç¢çï¼ï¼17 åç¨æ¼é©è­ï¼32 åç¨æ¼æ¸¬è©¦ç¢çç IFRA éè¡¨ï¼22 åéè·åèå 10 åè·åèï¼ãIFRA éè¡¨ä¸­èæ®çç¹å¾µåæ¬æ­¥æéåº¦ãåå°èµ°éæ¸¡æéçåç´å éåº¦åè½å½è§éåº¦ï¼éäºç¹å¾µèå·²å»ºç«çç¥ç¶çæ£è·åé¢¨éªæç»éå¸¸å»åãèå³çµ±è¨åºéè¡¨ï¼ä¾å¦å³çµ±çè¨æèµ·èº«åè¡èµ°åè¿·ä½  BESTestï¼ç¸æ¯ï¼IFRA è¡¨ç¾åºç«¶ç­åªå¢ï¼æ¯å¯ä¸å°è¶éä¸åçè·åèæ­£ç¢ºåéå°é«é¢¨éªéå±¤çéè¡¨ï¼Fisher ç²¾ç¢ºæª¢å® p = 0.004ï¼ãåç®¡è³æéè¦æ¨¡æéï¼ä½éæ¯ç¬¬ä¸åæ¦å¿µé©è­ç ç©¶ï¼çºæªä¾éæ¼å¨è¨åºä¸­é¢¨åº·å¾©ååºé¢å¾å±å®¶è·åé é²ä¸­ä½¿ç¨ IFRA å·¥å·çè­æéªè·¯ã</paragraph>

##### **Understanding Mental Health Content on Social Media and Its Effect Towards Suicidal Ideation**
2501.09309v1 by Mohaiminul Islam Bhuiyan, Nur Shazwani Kamarudin, Nur Hafieza Ismail

This review underscores the critical need for effective strategies to
identify and support individuals with suicidal ideation, exploiting
technological innovations in ML and DL to further suicide prevention efforts.
The study details the application of these technologies in analyzing vast
amounts of unstructured social media data to detect linguistic patterns,
keywords, phrases, tones, and contextual cues associated with suicidal
thoughts. It explores various ML and DL models like SVMs, CNNs, LSTM, neural
networks, and their effectiveness in interpreting complex data patterns and
emotional nuances within text data. The review discusses the potential of these
technologies to serve as a life-saving tool by identifying at-risk individuals
through their digital traces. Furthermore, it evaluates the real-world
effectiveness, limitations, and ethical considerations of employing these
technologies for suicide prevention, stressing the importance of responsible
development and usage. The study aims to fill critical knowledge gaps by
analyzing recent studies, methodologies, tools, and techniques in this field.
It highlights the importance of synthesizing current literature to inform
practical tools and suicide prevention efforts, guiding innovation in reliable,
ethical systems for early intervention. This research synthesis evaluates the
intersection of technology and mental health, advocating for the ethical and
responsible application of ML, DL, and NLP to offer life-saving potential
worldwide while addressing challenges like generalizability, biases, privacy,
and the need for further research to ensure these technologies do not
exacerbate existing inequities and harms.

æè¦ï¼éç¯è©è«å¼·èª¿äºææç­ç¥çéè¦éæ±ï¼ä»¥ééå©ç¨æ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿çæè¡åµæ°ä¾è­å¥åæ¯ææèªæ®ºæå¿µçäººï¼é²ä¸æ­¥ä¿é²èªæ®ºé²æ²»å·¥ä½ãéé ç ç©¶è©³ç´°èªªæäºéäºæè¡å¨åæå¤§ééçµæ§åç¤¾ç¾¤åªé«è³æä¸­çæç¨ï¼ä»¥åµæ¸¬èèªæ®ºå¿µé ­ç¸éçèªè¨æ¨¡å¼ãééµå­ãè©çµãèªæ°£åèçµ¡ç·ç´¢ãå®æ¢è¨äºåç¨®æ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿æ¨¡åï¼ä¾å¦æ¯æ´åéæ©ãå·ç©ç¥ç¶ç¶²è·¯ãé·ç­æè¨æ¶ç¶²è·¯ãç¥ç¶ç¶²è·¯ï¼ä»¥åå®åå¨è§£è®æå­è³æä¸­çè¤éè³ææ¨¡å¼åæç·ç´°å¾®å·®å¥æ¹é¢çæè½ãéç¯è©è«è¨è«äºéäºæè¡ä½çºæå½å·¥å·çæ½åï¼ééæ¸ä½è¶³è·¡ä¾è­å¥æé¢¨éªçåäººãæ­¤å¤ï¼å®è©ä¼°äºæ¡ç¨éäºæè¡é²è¡èªæ®ºé²æ²»çå¯¦éæè½ãéå¶åéå¾·èéï¼å¼·èª¿è² è²¬ä»»çéç¼åä½¿ç¨çéè¦æ§ãéé ç ç©¶æ¨å¨ééåæéåé åçè¿æç ç©¶ãæ¹æ³ãå·¥å·åæè¡ï¼å¡«è£éè¦çç¥è­å·®è·ãå®å¼·èª¿äºç¶åç¾ææç»å°æ¼æä¾å¯¦ç¨å·¥å·åèªæ®ºé²æ²»å·¥ä½çéè¦æ§ï¼å¼å°å¨æ©æä»å¥ä¸­å»ºç«å¯é çãç¬¦åéå¾·çç³»çµ±çåµæ°ãéé ç ç©¶ç¶åè©ä¼°äºæè¡åå¿çå¥åº·ä¹éçäº¤éï¼å¡å°éå¾·ä¸è² è²¬ä»»å°æç¨æ©å¨å­¸ç¿ãæ·±åº¦å­¸ç¿åèªç¶èªè¨èçï¼ä»¥æä¾å¨çæ§çæå½æ½åï¼åæè§£æ±ºæ¦æ¬æ§ãåèª¤ãé±ç§ç­ææ°ï¼ä¸¦éè¦é²ä¸æ­¥ç ç©¶ä»¥ç¢ºä¿éäºæè¡ä¸æå åç¾æçä¸å¹³ç­åå·å®³ã

##### **Interpretable Droplet Digital PCR Assay for Trustworthy Molecular Diagnostics**
2501.09218v1 by Yuanyuan Wei, Yucheng Wu, Fuyang Qu, Yao Mu, Yi-Ping Ho, Ho-Pui Ho, Wu Yuan, Mingkun Xu

Accurate molecular quantification is essential for advancing research and
diagnostics in fields such as infectious diseases, cancer biology, and genetic
disorders. Droplet digital PCR (ddPCR) has emerged as a gold standard for
achieving absolute quantification. While computational ddPCR technologies have
advanced significantly, achieving automatic interpretation and consistent
adaptability across diverse operational environments remains a challenge. To
address these limitations, we introduce the intelligent interpretable droplet
digital PCR (I2ddPCR) assay, a comprehensive framework integrating front-end
predictive models (for droplet segmentation and classification) with GPT-4o
multimodal large language model (MLLM, for context-aware explanations and
recommendations) to automate and enhance ddPCR image analysis. This approach
surpasses the state-of-the-art models, affording 99.05% accuracy in processing
complex ddPCR images containing over 300 droplets per image with varying
signal-to-noise ratios (SNRs). By combining specialized neural networks and
large language models, the I2ddPCR assay offers a robust and adaptable solution
for absolute molecular quantification, achieving a sensitivity capable of
detecting low-abundance targets as low as 90.32 copies/{\mu}L. Furthermore, it
improves model's transparency through detailed explanation and troubleshooting
guidance, empowering users to make informed decisions. This innovative
framework has the potential to benefit molecular diagnostics, disease research,
and clinical applications, especially in resource-constrained settings.

æè¦ï¼æºç¢ºçåå­éåå°æ¼æ¨é²å³æçãçççç©å­¸åéºå³ç¾çç­é åçç ç©¶åè¨ºæ·è³ééè¦ãé£æ²«æ¸ä½ PCR (ddPCR) å·²æçºå¯¦ç¾çµå°éåçé»éæ¨æºãåç®¡éç®å¼ ddPCR æè¡å·²å¤§å¹é²æ­¥ï¼ä½å¨ä¸åæä½ç°å¢ä¸­å¯¦ç¾èªååè§£è®åä¸è´çé©ææ§ä»ç¶æ¯ä¸é ææ°ãçºäºè§£æ±ºéäºéå¶ï¼æåå¼å¥äºæºæ§å¯è§£è®é£æ²«æ¸ä½ PCR (I2ddPCR) åæï¼ä¸åæ´ååç»æ§é æ¸¬æ¨¡åï¼ç¨æ¼é£æ²«åå²ååé¡ï¼è GPT-4o å¤æ¨¡æå¤§åèªè¨æ¨¡åï¼MLLMï¼ç¨æ¼æå¢æç¥è§£éåå»ºè­°ï¼çç¶åæ¶æ§ï¼ä»¥èªååä¸¦å¢å¼· ddPCR å½±ååæãæ­¤æ¹æ³è¶è¶äºæåé²çæ¨¡åï¼å¨èçæ¯å¼µå½±åå«æè¶é 300 åé£æ²«ä¸ä¿¡åªæ¯ (SNR) ä¸åçè¤é ddPCR å½±åæï¼æºç¢ºåº¦é«é 99.05%ãééçµåå°éçç¥ç¶ç¶²è·¯åå¤§åèªè¨æ¨¡åï¼I2ddPCR åææä¾äºä¸åå¼·å¥ä¸é©ææ§é«ççµå°åå­éåè§£æ±ºæ¹æ¡ï¼éæåº¦é«ï¼è½åµæ¸¬ä½è³ 90.32 åæ·è²æ¸/{\mu}L çä½è±åº¦ç®æ¨ãæ­¤å¤ï¼å®ééè©³ç´°çèªªæåæéæé¤æåä¾æåæ¨¡åçéæåº¦ï¼ä½¿ç¨æ¶è½å¤ ååºææºçæ±ºç­ãéååµæ°çæ¶æ§ææ½åé ç¦åå­è¨ºæ·ãç¾çç ç©¶åè¨åºæç¨ï¼ç¹å¥æ¯å¨è³æºåéçç°å¢ä¸­ã

##### **AutoLoop: Fast Visual SLAM Fine-tuning through Agentic Curriculum Learning**
2501.09160v1 by Assaf Lahiany, Oren Gal

Current visual SLAM systems face significant challenges in balancing
computational efficiency with robust loop closure handling. Traditional
approaches require careful manual tuning and incur substantial computational
overhead, while learning-based methods either lack explicit loop closure
capabilities or implement them through computationally expensive methods. We
present AutoLoop, a novel approach that combines automated curriculum learning
with efficient fine-tuning for visual SLAM systems. Our method employs a DDPG
(Deep Deterministic Policy Gradient) agent to dynamically adjust loop closure
weights during training, eliminating the need for manual hyperparameter search
while significantly reducing the required training steps. The approach
pre-computes potential loop closure pairs offline and leverages them through an
agent-guided curriculum, allowing the model to adapt efficiently to new
scenarios. Experiments conducted on TartanAir for training and validated across
multiple benchmarks including KITTI, EuRoC, ICL-NUIM and TUM RGB-D demonstrate
that AutoLoop achieves comparable or superior performance while reducing
training time by an order of magnitude compared to traditional approaches.
AutoLoop provides a practical solution for rapid adaptation of visual SLAM
systems, automating the weight tuning process that traditionally requires
multiple manual iterations. Our results show that this automated curriculum
strategy not only accelerates training but also maintains or improves the
model's performance across diverse environmental conditions.

æè¦ï¼ç¶åçè¦è¦º SLAM ç³»çµ±å¨å¹³è¡¡éç®æçèç©©å¥çè¿´è·¯éåèçä¸ï¼é¢è¨éå¤§ææ°ãå³çµ±æ¹æ³éè¦ä»ç´°çæåèª¿æ´ï¼ä¸¦æç¢çå¤§éçéç®è² æï¼èåºæ¼å­¸ç¿çæ¹æ³åç¼ºä¹æç¢ºçè¿´è·¯éååè½ï¼æéééç®ææ¬é«æçæ¹æ³ä¾å¯¦ä½ãæåæåº AutoLoopï¼éæ¯ä¸ç¨®æ°ç©çæ¹æ³ï¼å®çµåäºèªååçèª²ç¨å­¸ç¿èè¦è¦º SLAM ç³»çµ±çææå¾®èª¿ãæåçæ¹æ³æ¡ç¨ DDPGï¼æ·±åº¦ç¢ºå®æ§ç­ç¥æ¢¯åº¦ï¼ä»£çï¼å¨è¨ç·´éç¨ä¸­åæèª¿æ´è¿´è·¯éåæ¬éï¼æ¶é¤äºäººå·¥è¶åæ¸æå°çéè¦ï¼åæå¤§å¹æ¸å°äºæéçè¨ç·´æ­¥é©ãæ­¤æ¹æ³æé¢ç·é åè¨ç®æ½å¨çè¿´è·¯éåå°ï¼ä¸¦ééä»£çå°åçèª²ç¨ä¾å©ç¨å®åï¼è®æ¨¡åè½å¤ ææå°é©ææ°çå ´æ¯ãå¨ TartanAir ä¸é²è¡çå¯¦é©ï¼ç¨æ¼è¨ç·´ä¸¦é©è­è·¨å¤ååºæºï¼åæ¬ KITTIãEuRoCãICL-NUIM å TUM RGB-Dï¼è­æ AutoLoop éå°ç¸ç¶ææ´ä½³çæè½ï¼åæå°è¨ç·´æéæ¸å°äºä¸åæ¸éç´ï¼èå³çµ±æ¹æ³ç¸æ¯ãAutoLoop æä¾äºä¸åå¯¦ç¨çè§£æ±ºæ¹æ¡ï¼ç¨æ¼å¿«éé©æè¦è¦º SLAM ç³»çµ±ï¼èªååå³çµ±ä¸éè¦å¤æ¬¡äººå·¥åè¦éç®çæ¬éèª¿æ´éç¨ãæåççµæè¡¨æï¼éç¨®èªååçèª²ç¨ç­ç¥ä¸åå éäºè¨ç·´ï¼éç¶­æææ¹åäºæ¨¡åå¨åç¨®ç°å¢æ¢ä»¶ä¸çæè½ã

##### **Benchmarking Robustness of Contrastive Learning Models for Medical Image-Report Retrieval**
2501.09134v1 by Demetrio Deanda, Yuktha Priya Masupalli, Jeong Yang, Young Lee, Zechun Cao, Gongbo Liang

Medical images and reports offer invaluable insights into patient health. The
heterogeneity and complexity of these data hinder effective analysis. To bridge
this gap, we investigate contrastive learning models for cross-domain
retrieval, which associates medical images with their corresponding clinical
reports. This study benchmarks the robustness of four state-of-the-art
contrastive learning models: CLIP, CXR-RePaiR, MedCLIP, and CXR-CLIP. We
introduce an occlusion retrieval task to evaluate model performance under
varying levels of image corruption. Our findings reveal that all evaluated
models are highly sensitive to out-of-distribution data, as evidenced by the
proportional decrease in performance with increasing occlusion levels. While
MedCLIP exhibits slightly more robustness, its overall performance remains
significantly behind CXR-CLIP and CXR-RePaiR. CLIP, trained on a
general-purpose dataset, struggles with medical image-report retrieval,
highlighting the importance of domain-specific training data. The evaluation of
this work suggests that more effort needs to be spent on improving the
robustness of these models. By addressing these limitations, we can develop
more reliable cross-domain retrieval models for medical applications.

æè¦ï¼é«çå½±ååå ±åæä¾å¯¶è²´çè¦è§£ï¼æ·±å¥äºè§£æ£èå¥åº·ãéäºæ¸æçç°è³ªæ§åè¤éæ§é»ç¤äºææçåæãçºäºå½è£éåå·®è·ï¼æåç ç©¶å°æ¯å­¸ç¿æ¨¡åé²è¡è·¨é åæª¢ç´¢ï¼å°é«å­¸å½±åèå¶å°æçè¨åºå ±åè¯ç¹«èµ·ä¾ãæ¬ç ç©¶å°åç¨®æåé²çå°æ¯å­¸ç¿æ¨¡åçå¥å£¯æ§é²è¡äºåºæºæ¸¬è©¦ï¼CLIPãCXR-RePaiRãMedCLIP å CXR-CLIPãæåå¼å¥é®ææª¢ç´¢ä»»åï¼ä»¥è©ä¼°æ¨¡åå¨ä¸åç¨åº¦çå½±åæå£ä¸çæ§è½ãæåçç ç©¶çµæè¡¨æï¼ææè©ä¼°çæ¨¡åå°åä½å¤æ¸æé½é«åº¦ææï¼éå¾é¨èé®æç¨åº¦çå¢å èå°è´çæ§è½ææ¯ä¾ä¸éå°±å¯ä»¥è­æãéç¶ MedCLIP è¡¨ç¾åºç¨é«çå¥å£¯æ§ï¼ä½å¶æ´é«æ§è½ä»é é è½å¾æ¼ CXR-CLIP å CXR-RePaiRãCLIP å¨éç¨æ¸æéä¸é²è¡è¨ç·´ï¼å¨é«å­¸å½±åå ±åæª¢ç´¢ä¸­éå°å°é£ï¼çªé¡¯äºç¹å®é åè¨ç·´æ¸æçéè¦æ§ãéé å·¥ä½çè©ä¼°è¡¨æï¼éè¦è±è²»æ´å¤ç²¾åä¾æé«éäºæ¨¡åçå¥å£¯æ§ãééè§£æ±ºéäºéå¶ï¼æåå¯ä»¥çºé«çæç¨éç¼æ´å¯é çè·¨é åæª¢ç´¢æ¨¡åã

##### **Generative Medical Image Anonymization Based on Latent Code Projection and Optimization**
2501.09114v1 by Huiyu Li, Nicholas Ayache, HervÃ© Delingette

Medical image anonymization aims to protect patient privacy by removing
identifying information, while preserving the data utility to solve downstream
tasks. In this paper, we address the medical image anonymization problem with a
two-stage solution: latent code projection and optimization. In the projection
stage, we design a streamlined encoder to project input images into a latent
space and propose a co-training scheme to enhance the projection process. In
the optimization stage, we refine the latent code using two deep loss functions
designed to address the trade-off between identity protection and data utility
dedicated to medical images. Through a comprehensive set of qualitative and
quantitative experiments, we showcase the effectiveness of our approach on the
MIMIC-CXR chest X-ray dataset by generating anonymized synthetic images that
can serve as training set for detecting lung pathologies. Source codes are
available at https://github.com/Huiyu-Li/GMIA.

æè¦ï¼é«å­¸å½±åå¿ååæ¨å¨ééç§»é¤è­å¥è³è¨ä¾ä¿è­·çæ£é±ç§ï¼åæä¿çè³ææç¨ä»¥è§£æ±ºä¸æ¸¸ä»»åãå¨æ¬æä¸­ï¼æåééå©éæ®µè§£æ±ºæ¹æ¡ä¾è§£æ±ºé«å­¸å½±åå¿åååé¡ï¼æ½å¨ç¢¼æå½±åæä½³åãå¨æå½±éæ®µï¼æåè¨­è¨ä¸åç°¡åçç·¨ç¢¼å¨ï¼å°è¼¸å¥å½±åæå½±å°æ½å¨ç©ºéï¼ä¸¦æåºä¸åå±åè¨ç·´æ¶æ§ä¾æåæå½±ç¨åºãå¨æä½³åéæ®µï¼æåä½¿ç¨å©åæ·±åº¦æå¤±å½æ¸ä¾èª¿æ´æ½å¨ç¢¼ï¼éäºå½æ¸æ¨å¨è§£æ±ºèº«åä¿è­·èå°éç¨æ¼é«å­¸å½±åçè³ææç¨ä¹éçæ¬è¡¡ãééä¸çµå¨é¢çå®æ§åå®éå¯¦é©ï¼æåå±ç¤ºäºæåæ¹æ³å¨ MIMIC-CXR è¸é¨ X åå½±åè³æéä¸çæææ§ï¼æ¹æ³æ¯ç¢çå¯ä½çºè¨ç·´éä¾åµæ¸¬èºé¨çççå¿ååæå½±åãåå§ç¢¼å¯æ¼ https://github.com/Huiyu-Li/GMIA åå¾ã

##### **Development and Validation of the Provider Documentation Summarization Quality Instrument for Large Language Models**
2501.08977v2 by Emma Croxford, Yanjun Gao, Nicholas Pellegrino, Karen K. Wong, Graham Wills, Elliot First, Miranda Schnier, Kyle Burton, Cris G. Ebby, Jillian Gorskic, Matthew Kalscheur, Samy Khalil, Marie Pisani, Tyler Rubeor, Peter Stetson, Frank Liao, Cherodeep Goswami, Brian Patterson, Majid Afshar

As Large Language Models (LLMs) are integrated into electronic health record
(EHR) workflows, validated instruments are essential to evaluate their
performance before implementation. Existing instruments for provider
documentation quality are often unsuitable for the complexities of
LLM-generated text and lack validation on real-world data. The Provider
Documentation Summarization Quality Instrument (PDSQI-9) was developed to
evaluate LLM-generated clinical summaries. Multi-document summaries were
generated from real-world EHR data across multiple specialties using several
LLMs (GPT-4o, Mixtral 8x7b, and Llama 3-8b). Validation included Pearson
correlation for substantive validity, factor analysis and Cronbach's alpha for
structural validity, inter-rater reliability (ICC and Krippendorff's alpha) for
generalizability, a semi-Delphi process for content validity, and comparisons
of high-versus low-quality summaries for discriminant validity. Seven physician
raters evaluated 779 summaries and answered 8,329 questions, achieving over 80%
power for inter-rater reliability. The PDSQI-9 demonstrated strong internal
consistency (Cronbach's alpha = 0.879; 95% CI: 0.867-0.891) and high
inter-rater reliability (ICC = 0.867; 95% CI: 0.867-0.868), supporting
structural validity and generalizability. Factor analysis identified a 4-factor
model explaining 58% of the variance, representing organization, clarity,
accuracy, and utility. Substantive validity was supported by correlations
between note length and scores for Succinct (rho = -0.200, p = 0.029) and
Organized ($\rho = -0.190$, $p = 0.037$). Discriminant validity distinguished
high- from low-quality summaries ($p < 0.001$). The PDSQI-9 demonstrates robust
construct validity, supporting its use in clinical practice to evaluate
LLM-generated summaries and facilitate safer integration of LLMs into
healthcare workflows.

æè¦ï¼<paragraph>é¨èå¤§åèªè¨æ¨¡å (LLM) æ´åå°é»å­çæ­·
(EHR) å·¥ä½æµç¨ä¸­ï¼å¨å¯¦æ½ä¹åï¼ç¶éé©è­çåå¨å°æ¼è©ä¼°å¶
æè½è³ééè¦ãç¾æçæä¾èæä»¶åè³ªåå¨éå¸¸ä¸é©å
LLM çæçæå­çè¤éæ§ï¼ä¸ç¼ºä¹å°çå¯¦ä¸çè³æçé©è­ãæä¾è
æä»¶æè¦åè³ªåå¨ (PDSQI-9) æ¯çºäºè©ä¼° LLM çæçè¨åºæè¦è
éç¼çãä½¿ç¨å¤å LLMï¼GPT-4oãMixtral 8x7b å Llama 3-8bï¼ï¼
å¾è·¨å¤åå°ç§ççå¯¦ä¸ç EHR è³æä¸­ç¢çäºå¤æä»¶æè¦ãé©è­åæ¬
ç®ç¾æ£®ç¸éæ§ï¼å¯¦è³ªæåº¦ï¼ãå å­åæååæå·´èµ« Î±ï¼çµæ§æåº¦ï¼ã
è©åèéä¿¡åº¦ï¼ICC å Krippendorff Î±ï¼ï¼æ¦åæ§ï¼ãå§å®¹æåº¦çåå¾·ç¾
è²ç¨åºï¼ä»¥åæ¯è¼é«åè³ªåä½åè³ªæè¦ï¼å¤å¥æåº¦ï¼ãä¸ä½é«å¸«
è©åèè©ä¼°äº 779 ä»½æè¦ä¸¦åç­äº 8,329 ååé¡ï¼è©åèéä¿¡åº¦é
å°äº 80% ä»¥ä¸ãPDSQI-9 è¡¨ç¾åºå¼·å¤§çå§é¨ä¸è´æ§ï¼åæå·´èµ« Î± =
0.879ï¼95% CIï¼0.867-0.891ï¼åé«è©åèéä¿¡åº¦ï¼ICC = 0.867ï¼95%
CIï¼0.867-0.868ï¼ï¼æ¯æçµæ§æåº¦åæ¦åæ§ãå å­åæè­å¥åºä¸å
4 å å­æ¨¡åï¼è§£éäº 58% çè®ç°ï¼ä»£è¡¨çµç¹ãæ¸æ°åº¦ãæºç¢ºæ§åå¯¦ç¨
æ§ãå¯¦è³ªæåº¦åå°åå¿éé·åº¦èç°¡æ½ï¼rho = -0.200ï¼p = 0.029ï¼å
æ¢çï¼$\rho = -0.190$ï¼$p = 0.037$ï¼çåæ¸ä¹éç¸éæ§çæ¯æãå¤å¥
æåº¦ååäºé«åè³ªåä½åè³ªæè¦ï¼$p < 0.001$ï¼ãPDSQI-9 å±ç¤ºäºå¼·å¥
çå»ºæ§æåº¦ï¼æ¯æå¨è¨åºå¯¦åä¸­ä½¿ç¨å®ä¾è©ä¼° LLM çæçæè¦ï¼ä¸¦
ä¿é² LLM æ´å®å¨çæ´åå°é«çä¿å¥å·¥ä½æµç¨ä¸­ã</paragraph>

##### **An analysis of data variation and bias in image-based dermatological datasets for machine learning classification**
2501.08962v1 by Francisco Mauro, Emanoel Thyago, Othon Vinicius, Rodrigo Abreu, Kelvin Cunha, JosÃ© Gabriel, Rafael Barros, Thales Bezerra, Manoel Henriques, Natalia Lopes, Ãrico Moutinho, JÃ©ssica Guido, Tsang Ing Ren, Paulo Borba

AI algorithms have become valuable in aiding professionals in healthcare. The
increasing confidence obtained by these models is helpful in critical decision
demands. In clinical dermatology, classification models can detect malignant
lesions on patients' skin using only RGB images as input. However, most
learning-based methods employ data acquired from dermoscopic datasets on
training, which are large and validated by a gold standard. Clinical models aim
to deal with classification on users' smartphone cameras that do not contain
the corresponding resolution provided by dermoscopy. Also, clinical
applications bring new challenges. It can contain captures from uncontrolled
environments, skin tone variations, viewpoint changes, noises in data and
labels, and unbalanced classes. A possible alternative would be to use transfer
learning to deal with the clinical images. However, as the number of samples is
low, it can cause degradations on the model's performance; the source
distribution used in training differs from the test set. This work aims to
evaluate the gap between dermoscopic and clinical samples and understand how
the dataset variations impact training. It assesses the main differences
between distributions that disturb the model's prediction. Finally, from
experiments on different architectures, we argue how to combine the data from
divergent distributions, decreasing the impact on the model's final accuracy.

æè¦ï¼AI æ¼ç®æ³å·²æçºåå©é«çä¿å¥å°æ¥­äººå¡çå¯¶è²´å·¥å·ãéäºæ¨¡åç²å¾çä¿¡å¿æ¥çæåï¼æå©æ¼ééµæ±ºç­éæ±ãå¨è¨åºç®èç§ï¼åé¡æ¨¡ååä½¿ç¨ RGB å½±åä½çºè¼¸å¥ï¼å³å¯åµæ¸¬æ£èç®èä¸çæ¡æ§çç¶ãç¶èï¼å¤§å¤æ¸åºæ¼å­¸ç¿çæ¹æ³æ¡ç¨å¾ç®èé¡è³æéåå¾çè³æé²è¡è¨ç·´ï¼éäºè³æéé¾å¤§ä¸å·²éééæ¨æºé©è­ãè¨åºæ¨¡åæ¨å¨èçä½¿ç¨èæºæ§åææ©ç¸æ©ä¸çåé¡ï¼éäºç¸æ©ä¸åå«ç®èé¡æä¾çå°æè§£æåº¦ãæ­¤å¤ï¼è¨åºæç¨ç¨å¼å¸¶ä¾æ°çææ°ãå®å¯è½åå«ä¾èªä¸åæ§ç°å¢çæ·åãèè²è®åãè¦é»è®æ´ãè³æåæ¨ç±¤ä¸­çéè¨ï¼ä»¥åä¸å¹³è¡¡çé¡å¥ãä¸ç¨®å¯è½çæ¿ä»£æ¹æ¡æ¯ä½¿ç¨é·ç§»å­¸ç¿ä¾èçè¨åºå½±åãç¶èï¼ç±æ¼æ¨£æ¬æ¸éå°ï¼å¯è½æå°è´æ¨¡åæè½ä¸éï¼è¨ç·´ä¸­ä½¿ç¨çä¾æºåä½èæ¸¬è©¦éä¸åãéé å·¥ä½æ¨å¨è©ä¼°ç®èé¡åè¨åºæ¨£æ¬ä¹éçå·®è·ï¼ä¸¦äºè§£è³æéè®åå¦ä½å½±é¿è¨ç·´ãå®è©ä¼°æå¹²æ¾æ¨¡åé æ¸¬çä¸»è¦åä½å·®ç°ãæå¾ï¼å¾ä¸åæ¶æ§çå¯¦é©ä¸­ï¼æåè«è­å¦ä½çµåä¾èªä¸ååä½çè³æï¼éä½å°æ¨¡åæçµæºç¢ºåº¦çå½±é¿ã

##### **Improving the Efficiency of Self-Supervised Adversarial Training through Latent Clustering-Based Selection**
2501.10466v1 by Somrita Ghosh, Yuelin Xu, Xiao Zhang

Compared with standard learning, adversarially robust learning is widely
recognized to demand significantly more training examples. Recent works propose
the use of self-supervised adversarial training (SSAT) with external or
synthetically generated unlabeled data to enhance model robustness. However,
SSAT requires a substantial amount of extra unlabeled data, significantly
increasing memory usage and model training times. To address these challenges,
we propose novel methods to strategically select a small subset of unlabeled
data essential for SSAT and robustness improvement. Our selection prioritizes
data points near the model's decision boundary based on latent clustering-based
techniques, efficiently identifying a critical subset of unlabeled data with a
higher concentration of boundary-adjacent points. While focusing on
near-boundary data, our methods are designed to maintain a balanced ratio
between boundary and non-boundary data points to avoid overfitting. Our
experiments on image benchmarks show that integrating our selection strategies
into self-supervised adversarial training can largely reduce memory and
computational requirements while achieving high model robustness. In
particular, our latent clustering-based selection method with k-means is the
most effective, achieving nearly identical test-time robust accuracies with 5
to 10 times less external or generated unlabeled data when applied to image
benchmarks. Additionally, we validate the generalizability of our approach
across various application scenarios, including a real-world medical dataset
for COVID-19 chest X-ray classification.

æè¦ï¼èæ¨æºå­¸ç¿ç¸æ¯ï¼å°ææ§ç©©å¥å­¸ç¿å»£æ³è¢«èªçºéè¦æ´å¤è¨ç·´ç¯ä¾ãè¿æç ç©¶æåºä½¿ç¨å·æå¤é¨æåæç¢çæ¨ç±¤è³æçèªç£ç£å°æè¨ç·´ (SSAT) ä¾å¢å¼·æ¨¡åç©©å¥æ§ãç¶èï¼SSAT éè¦å¤§éçé¡å¤æªæ¨ç±¤è³æï¼é¡¯èå¢å è¨æ¶é«ä½¿ç¨éåæ¨¡åè¨ç·´æéãçºäºæå°éäºææ°ï¼æåæåºæ°ç©çæ¹æ³ä¾ç­ç¥æ§å°é¸æä¸å°é¨åæªæ¨ç±¤è³æï¼éå° SSAT åç©©å¥æ§æ¹é²è³ééè¦ãæåçé¸æåºæ¼æ½å¨ç¾¤éæè¡ï¼åªåèæ®æ¨¡åæ±ºç­éçéè¿çè³æé»ï¼ææå°è­å¥åºä¸çµééµçæªæ¨ç±¤è³æå­éï¼å¶ä¸­åå«è¼é«æ¿åº¦çéçç¸é°é»ãéç¶å°æ³¨æ¼è¿éçè³æï¼ä½æåçæ¨¡åæ¨å¨ä¿æéçåééçè³æé»ä¹éçå¹³è¡¡æ¯çï¼ä»¥é¿åéåº¦æ¬åãæåå¨å½±ååºæºä¸çå¯¦é©è¡¨æï¼å°æåçé¸æç­ç¥æ´åå°èªç£ç£å°æè¨ç·´ä¸­ï¼å¯ä»¥å¨å¯¦ç¾é«æ¨¡åç©©å¥æ§çåæï¼å¤§å¹æ¸å°è¨æ¶é«åè¨ç®éæ±ãç¹å¥æ¯ï¼æååºæ¼ k å¹³åå¼çæ½å¨ç¾¤éé¸ææ¹æ³æææï¼å¨æç¨æ¼å½±ååºæºæï¼ä»¥å° 5 å° 10 åçå¤é¨æçææªæ¨ç±¤è³æï¼éå°å¹¾ä¹ç¸åçæ¸¬è©¦æéç©©å¥æºç¢ºåº¦ãæ­¤å¤ï¼æåé©è­äºæåçæ¹æ³å¨åç¨®æç¨å ´æ¯ä¸­çéç¨æ§ï¼åæ¬ç¨æ¼ COVID-19 è¸é¨ X ååé¡ççå¯¦ä¸çé«çè³æéã

##### **Digital Phenotyping for Adolescent Mental Health: A Feasibility Study Employing Machine Learning to Predict Mental Health Risk From Active and Passive Smartphone Data**
2501.08851v1 by Balasundaram Kadirvelu, Teresa Bellido Bel, Aglaia Freccero, Martina Di Simplicio, Dasha Nicholls, A Aldo Faisal

Background: Adolescents are particularly vulnerable to mental disorders, with
over 75% of cases manifesting before the age of 25. Research indicates that
only 18 to 34% of young people experiencing high levels of depression or
anxiety symptoms seek support. Digital tools leveraging smartphones offer
scalable and early intervention opportunities. Objective: Using a novel machine
learning framework, this study evaluated the feasibility of integrating active
and passive smartphone data to predict mental disorders in non-clinical
adolescents. Specifically, we investigated the utility of the Mindcraft app in
predicting risks for internalising and externalising disorders, eating
disorders, insomnia and suicidal ideation. Methods: Participants (N=103; mean
age 16.1 years) were recruited from three London schools. Participants
completed the Strengths and Difficulties Questionnaire, the Eating Disorders-15
Questionnaire, Sleep Condition Indicator Questionnaire and indicated the
presence/absence of suicidal ideation. They used the Mindcraft app for 14 days,
contributing active data via self-reports and passive data from smartphone
sensors. A contrastive pretraining phase was applied to enhance user-specific
feature stability, followed by supervised fine-tuning. The model evaluation
employed leave-one-subject-out cross-validation using balanced accuracy as the
primary metric. Results: The integration of active and passive data achieved
superior performance compared to individual data sources, with mean balanced
accuracies of 0.71 for SDQ-High risk, 0.67 for insomnia, 0.77 for suicidal
ideation and 0.70 for eating disorders. The contrastive learning framework
stabilised daily behavioural representations, enhancing predictive robustness.
This study demonstrates the potential of integrating active and passive
smartphone data with advanced machine-learning techniques for predicting mental
health risks.

æè¦ï¼<paragraph>èæ¯ï¼éå°å¹´ç¹å«å®¹æç½¹æ£ç²¾ç¥ç¾çï¼75% ä»¥ä¸ççä¾å¨ 25 å²ä¹åæ¾ç°ãç ç©¶è¡¨æï¼åªæ 18% å° 34% ç»åé«åº¦æéæç¦èçç¶çå¹´è½»äººå¯»æ±æ¯æãå©ç¨æºè½ææºçæ°ä½å·¥å·æä¾å¯æ©å±çæ©æä»å¥æºä¼ãç®æ ï¼æ¬ç ç©¶ä½¿ç¨æ°é¢çæºå¨å­¦ä¹ æ¡æ¶ï¼è¯ä¼°å°ä¸»å¨åè¢«å¨æºè½ææºæ°æ®æ´åæ¥é¢æµéä¸´åºéå°å¹´ç²¾ç¥ç¾ççå¯è¡æ§ãå·ä½æ¥è¯´ï¼æä»¬è°æ¥äº Mindcraft åºç¨ç¨åºå¨é¢æµåååå¤åéç¢ãé¥®é£å¤±è°ãå¤±ç åèªææå¿µæ¹é¢çæç¨ãæ¹æ³ï¼åä¸èï¼N=103ï¼å¹³åå¹´é¾ 16.1 å²ï¼æ¥èªä¼¦æ¦çä¸æå­¦æ ¡ãåä¸èå®æäºä¼å¿åå°é¾é®å·ãè¿é£éç¢-15 é®å·ãç¡ç ç¶åµææ é®å·ï¼å¹¶æåºäºæ¯å¦å­å¨èªææå¿µãä»ä»¬ä½¿ç¨ Mindcraft åºç¨ç¨åº 14 å¤©ï¼éè¿èªææ¥åæä¾ä¸»å¨æ°æ®ï¼å¹¶ä»æºè½ææºä¼ æå¨æä¾è¢«å¨æ°æ®ãåºç¨å¯¹æ¯é¢è®­ç»é¶æ®µæ¥å¢å¼ºç¹å®ç¨æ·çç¹å¾ç¨³å®æ§ï¼ç¶åè¿è¡çç£å¾®è°ãæ¨¡åè¯ä¼°éç¨çä¸æ³äº¤åéªè¯ï¼ä½¿ç¨å¹³è¡¡åç¡®åº¦ä½ä¸ºä¸»è¦ææ ãç»æï¼ä¸ä¸ªå«æ°æ®æºç¸æ¯ï¼ä¸»å¨åè¢«å¨æ°æ®çæ´åå®ç°äºæ´å¥½çæ§è½ï¼SDQ é«é£é©çå¹³åå¹³è¡¡åç¡®åº¦ä¸º 0.71ï¼å¤±ç ä¸º 0.67ï¼èªææå¿µä¸º 0.77ï¼é¥®é£å¤±è°ä¸º 0.70ãå¯¹æ¯å­¦ä¹ æ¡æ¶ç¨³å®äºæ¯æ¥è¡ä¸ºè¡¨å¾ï¼å¢å¼ºäºé¢æµé²æ£æ§ãæ¬ç ç©¶å±ç¤ºäºå°ä¸»å¨åè¢«å¨æºè½ææºæ°æ®ä¸åè¿æºå¨å­¦ä¹ ææ¯ç¸ç»åä»¥é¢æµå¿çå¥åº·é£é©çæ½åã</paragraph>

##### **Spatio-Temporal Foundation Models: Vision, Challenges, and Opportunities**
2501.09045v1 by Adam Goodge, Wee Siong Ng, Bryan Hooi, See Kiong Ng

Foundation models have revolutionized artificial intelligence, setting new
benchmarks in performance and enabling transformative capabilities across a
wide range of vision and language tasks. However, despite the prevalence of
spatio-temporal data in critical domains such as transportation, public health,
and environmental monitoring, spatio-temporal foundation models (STFMs) have
not yet achieved comparable success. In this paper, we articulate a vision for
the future of STFMs, outlining their essential characteristics and the
generalization capabilities necessary for broad applicability. We critically
assess the current state of research, identifying gaps relative to these ideal
traits, and highlight key challenges that impede their progress. Finally, we
explore potential opportunities and directions to advance research towards the
aim of effective and broadly applicable STFMs.

æè¦ï¼åºç¤æ¨¡åå¾¹åºæ¹è®äºäººå·¥æºæ§ï¼å¨æè½ä¸æ¨¹ç«æ°çåºæºï¼ä¸¦å¨å»£æ³çè¦è¦ºåèªè¨ä»»åä¸­å¯¦ç¾è½åè½åãç¶èï¼åç®¡æç©ºè³ææ®éå­å¨æ¼éè¼¸ãå¬å±è¡çåç°å¢ç£æ§ç­ééµé åï¼ä½æç©ºåºç¤æ¨¡å (STFM) å°æªåå¾åç­æå°±ãå¨æ¬æä¸­ï¼æåé¡è¿°äºå° STFM æªä¾çé¡æ¯ï¼æ¦è¿°äºå¶åºæ¬ç¹å¾µåå»£æ³é©ç¨çå¿è¦æ¦æ¬è½åãæåæ¹å¤æ§å°è©ä¼°äºç¶åç ç©¶ççæï¼æ¾åºç¸å°æ¼éäºçæ³ç¹è³ªçå·®è·ï¼ä¸¦å¼·èª¿é»ç¤å¶é²å±çééµææ°ãæå¾ï¼æåæ¢è¨äºæ¨é²ç ç©¶çæ½å¨æ©æåæ¹åï¼ä»¥å¯¦ç¾ææä¸å»£æ³é©ç¨ç STFMã

##### **ADAM-1: AI and Bioinformatics for Alzheimer's Detection and Microbiome-Clinical Data Integrations**
2501.08324v1 by Ziyuan Huang, Vishaldeep Kaur Sekhon, Ouyang Guo, Mark Newman, Roozbeh Sadeghian, Maria L. Vaida, Cynthia Jo, Doyle Ward, Vanni Bucci, John P. Haran

The Alzheimer's Disease Analysis Model Generation 1 (ADAM) is a multi-agent
large language model (LLM) framework designed to integrate and analyze
multi-modal data, including microbiome profiles, clinical datasets, and
external knowledge bases, to enhance the understanding and detection of
Alzheimer's disease (AD). By leveraging retrieval-augmented generation (RAG)
techniques along with its multi-agent architecture, ADAM-1 synthesizes insights
from diverse data sources and contextualizes findings using literature-driven
evidence. Comparative evaluation against XGBoost revealed similar mean F1
scores but significantly reduced variance for ADAM-1, highlighting its
robustness and consistency, particularly in small laboratory datasets. While
currently tailored for binary classification tasks, future iterations aim to
incorporate additional data modalities, such as neuroimaging and biomarkers, to
broaden the scalability and applicability for Alzheimer's research and
diagnostics.

æè¦ï¼é¿è²æµ·é»çåææ¨¡åçæ 1 (ADAM) æ¯ä¸åå¤ä»£çå¤§åèªè¨æ¨¡å (LLM) æ¶æ§ï¼æ¨å¨æ´åååæå¤æ¨¡å¼æ¸æï¼åæ¬å¾®çç©çµç¹å¾µãè¨åºæ¸æéåå¤é¨ç¥è­åº«ï¼ä»¥å¢é²å°é¿è²æµ·é»ç (AD) ççè§£ååµæ¸¬ãééå©ç¨æ·åå¢å¼·çæ (RAG) æè¡ä»¥åå¶å¤ä»£çæ¶æ§ï¼ADAM-1 å¾ä¸åçæ¸æä¾æºä¸­ç¶åè¦è§£ï¼ä¸¦ä½¿ç¨æç»é©åçè­æå°ç¼ç¾é²è¡æå¢åãè XGBoost çæ¯è¼è©ä¼°é¡¯ç¤ºé¡ä¼¼çå¹³å F1 åæ¸ï¼ä½ ADAM-1 çè®ç°é¡¯èéä½ï¼çªé¡¯å¶ç©©å¥æ§åä¸è´æ§ï¼ç¹å¥æ¯å¨å°åå¯¦é©å®¤æ¸æéä¸­ãéç¶ç®åéå°äºååé¡ä»»åé²è¡èª¿æ´ï¼ä½æªä¾çè¿­ä»£æ¨å¨ç´å¥å¶ä»æ¸ææ¨¡å¼ï¼ä¾å¦ç¥ç¶å½±ååçç©æ¨è¨ï¼ä»¥æ´å¤§é¿è²æµ·é»çç ç©¶åè¨ºæ·çå¯æ´åæ§åé©ç¨æ§ã

##### **A Feature-Level Ensemble Model for COVID-19 Identification in CXR Images using Choquet Integral and Differential Evolution Optimization**
2501.08241v1 by Amir Reza Takhsha, Maryam Rastgarpour, Mozhgan Naderi

The COVID-19 pandemic has profoundly impacted billions globally. It
challenges public health and healthcare systems due to its rapid spread and
severe respiratory effects. An effective strategy to mitigate the COVID-19
pandemic involves integrating testing to identify infected individuals. While
RT-PCR is considered the gold standard for diagnosing COVID-19, it has some
limitations such as the risk of false negatives. To address this problem, this
paper introduces a novel Deep Learning Diagnosis System that integrates
pre-trained Deep Convolutional Neural Networks (DCNNs) within an ensemble
learning framework to achieve precise identification of COVID-19 cases from
Chest X-ray (CXR) images. We combine feature vectors from the final hidden
layers of pre-trained DCNNs using the Choquet integral to capture interactions
between different DCNNs that a linear approach cannot. We employed
Sugeno-$\lambda$ measure theory to derive fuzzy measures for subsets of
networks to enable aggregation. We utilized Differential Evolution to estimate
fuzzy densities. We developed a TensorFlow-based layer for Choquet operation to
facilitate efficient aggregation, due to the intricacies involved in
aggregating feature vectors. Experimental results on the COVIDx dataset show
that our ensemble model achieved 98\% accuracy in three-class classification
and 99.50\% in binary classification, outperforming its components-DenseNet-201
(97\% for three-class, 98.75\% for binary), Inception-v3 (96.25\% for
three-class, 98.50\% for binary), and Xception (94.50\% for three-class, 98\%
for binary)-and surpassing many previous methods.

æè¦ï¼æ°å èºçç«æå·²å¯¹å¨çæ°åäº¿äººäº§çæ·±è¿å½±åãç±äºå¶ä¼ æ­è¿éä¸å¼å¸éçç¶ä¸¥éï¼å®å¯¹å¬å±å«çåå»çä¿å¥ç³»ç»ææææãåè½»æ°å èºçç«æçææç­ç¥åæ¬æ´åæ£æµä»¥è¯å«åææèãè½ç¶ RT-PCR è¢«è®¤ä¸ºæ¯è¯æ­æ°å èºççé»éæ åï¼ä½å®ä¹æä¸äºéå¶ï¼ä¾å¦åé´æ§çé£é©ãä¸ºäºè§£å³è¿ä¸ªé®é¢ï¼æ¬æä»ç»äºä¸ç§æ°é¢çæ·±åº¦å­¦ä¹ è¯æ­ç³»ç»ï¼è¯¥ç³»ç»å°é¢è®­ç»çæ·±åº¦å·ç§¯ç¥ç»ç½ç» (DCNN) éæå°éæå­¦ä¹ æ¡æ¶ä¸­ï¼ä»¥ä»è¸é¨ X å°çº¿ (CXR) å¾åä¸­ç²¾ç¡®è¯å«æ°å èºççä¾ãæä»¬ä½¿ç¨ Choquet ç§¯åç»åæ¥èªé¢è®­ç» DCNN çæåä¸ä¸ªéèå±çç¹å¾åéï¼ä»¥æè·çº¿æ§æ¹æ³æ æ³å®ç°çä¸å DCNN ä¹é´çäº¤äºãæä»¬éç¨ Sugeno-$\lambda$ æµåº¦çè®ºæ¥å¯¼åºç½ç»å­éçæ¨¡ç³æµåº¦ä»¥å®ç°èåãæä»¬å©ç¨å·®åè¿åæ¥ä¼°è®¡æ¨¡ç³å¯åº¦ãç±äºèåç¹å¾åéçå¤ææ§ï¼æä»¬å¼åäºä¸ä¸ªåºäº TensorFlow ç Choquet æä½å±ä»¥ä¿è¿é«æèåãCOVIDx æ°æ®éä¸çå®éªç»æè¡¨æï¼æä»¬çéææ¨¡åå¨ä¸ç±»åç±»ä¸­è¾¾å° 98% çåç¡®çï¼å¨äºååç±»ä¸­è¾¾å° 99.50%ï¼ä¼äºå¶ç»ä»¶ DenseNet-201ï¼ä¸ç±»ä¸º 97%ï¼äºåä¸º 98.75%ï¼ãInception-v3ï¼ä¸ç±»ä¸º 96.25%ï¼äºåä¸º 98.50%ï¼å Xceptionï¼ä¸ç±»ä¸º 94.50%ï¼äºåä¸º 98%ï¼ï¼å¹¶è¶è¶äºè®¸å¤ä»¥åçæ¹æ³ã

##### **ASTRID -- An Automated and Scalable TRIaD for the Evaluation of RAG-based Clinical Question Answering Systems**
2501.08208v1 by Mohita Chowdhury, Yajie Vera He, Aisling Higham, Ernest Lim

Large Language Models (LLMs) have shown impressive potential in clinical
question answering (QA), with Retrieval Augmented Generation (RAG) emerging as
a leading approach for ensuring the factual accuracy of model responses.
However, current automated RAG metrics perform poorly in clinical and
conversational use cases. Using clinical human evaluations of responses is
expensive, unscalable, and not conducive to the continuous iterative
development of RAG systems. To address these challenges, we introduce ASTRID -
an Automated and Scalable TRIaD for evaluating clinical QA systems leveraging
RAG - consisting of three metrics: Context Relevance (CR), Refusal Accuracy
(RA), and Conversational Faithfulness (CF). Our novel evaluation metric, CF, is
designed to better capture the faithfulness of a model's response to the
knowledge base without penalising conversational elements. To validate our
triad, we curate a dataset of over 200 real-world patient questions posed to an
LLM-based QA agent during surgical follow-up for cataract surgery - the highest
volume operation in the world - augmented with clinician-selected questions for
emergency, clinical, and non-clinical out-of-domain scenarios. We demonstrate
that CF can predict human ratings of faithfulness better than existing
definitions for conversational use cases. Furthermore, we show that evaluation
using our triad consisting of CF, RA, and CR exhibits alignment with clinician
assessment for inappropriate, harmful, or unhelpful responses. Finally, using
nine different LLMs, we demonstrate that the three metrics can closely agree
with human evaluations, highlighting the potential of these metrics for use in
LLM-driven automated evaluation pipelines. We also publish the prompts and
datasets for these experiments, providing valuable resources for further
research and development.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨è¨åºåç­ (QA) ä¸­å±ç¾äºä»¤äººå°è±¡æ·±å»çæ½åï¼å¶ä¸­æª¢ç´¢å¢å¼·çæ (RAG) æçºç¢ºä¿æ¨¡ååæäºå¯¦æºç¢ºæ§çé åæ¹æ³ãç¶èï¼ç®åçèªåå RAG ææ¨å¨è¨åºåå°è©±å¼ç¨ä¾ä¸­è¡¨ç¾ä¸ä½³ãä½¿ç¨è¨åºäººé¡å°åæçè©ä¼°æ¢æè²´åä¸å·å¯æ´åæ§ï¼ä¹ä¸å©æ¼ RAG ç³»çµ±çæçºè¿­ä»£éç¼ãçºäºæå°éäºææ°ï¼æåå¼å¥äº ASTRID - ä¸ç¨®ç¨æ¼è©ä¼°å©ç¨ RAG çè¨åº QA ç³»çµ±çèªååä¸å¯æ´åç TRIaD - åå«ä¸åææ¨ï¼èçµ¡ç¸éæ§ (CR)ãæçµæºç¢ºæ§ (RA) åå°è©±å¿ å¯¦åº¦ (CF)ãæåæ°ç©çè©ä¼°ææ¨ CF æ¨å¨æ´å¥½å°æææ¨¡åå°ç¥è­åº«çåæçå¿ å¯¦åº¦ï¼åæä¸æ²ç½°å°è©±åç´ ãçºäºé©è­æåçä¸åçµï¼æåç­åäºä¸åæ¸æéï¼å¶ä¸­åå«å¨ç½å§éæè¡è¡å¾é¨è¨ªæéå LLM åºæ¼ QA çä»£çæåºç 200 å¤åçå¯¦ä¸ççæ£èåé¡ - ä¸çä¸æè¡éæå¤§çæè¡ - ä¸¦å¢å äºè¨åºé«çé¸æçåé¡ï¼ç¨æ¼ç·æ¥ãè¨åºåéè¨åºé åå¤æå¢ãæåè­æï¼èå°è©±å¼ç¨ä¾ç¾æå®ç¾©ç¸æ¯ï¼CF å¯ä»¥æ´å¥½å°é æ¸¬äººé¡å°å¿ å¯¦åº¦çè©åãæ­¤å¤ï¼æåè¡¨æä½¿ç¨ç± CFãRA å CR çµæçä¸åçµé²è¡è©ä¼°èè¨åºé«çå°ä¸é©ç¶ãæå®³æç¡ççåæçè©ä¼°ä¿æä¸è´ãæå¾ï¼ä½¿ç¨ä¹ç¨®ä¸åç LLMï¼æåè­æéä¸åææ¨å¯ä»¥èäººé¡è©ä¼°ç·å¯ä¸è´ï¼çªé¡¯äºéäºææ¨å¨ LLM é©åçèªååè©ä¼°ç®¡éä¸­ä½¿ç¨çæ½åãæåéå¬ä½äºéäºå¯¦é©çæç¤ºåæ¸æéï¼çºé²ä¸æ­¥çç ç©¶åéç¼æä¾äºå¯¶è²´çè³æºã

##### **Potential and Perils of Large Language Models as Judges of Unstructured Textual Data**
2501.08167v2 by Rewina Bedemariam, Natalie Perez, Sreyoshi Bhaduri, Satya Kapoor, Alex Gil, Elizabeth Conjar, Ikkei Itoku, David Theil, Aman Chadha, Naumaan Nayyar

Rapid advancements in large language models have unlocked remarkable
capabilities when it comes to processing and summarizing unstructured text
data. This has implications for the analysis of rich, open-ended datasets, such
as survey responses, where LLMs hold the promise of efficiently distilling key
themes and sentiments. However, as organizations increasingly turn to these
powerful AI systems to make sense of textual feedback, a critical question
arises, can we trust LLMs to accurately represent the perspectives contained
within these text based datasets? While LLMs excel at generating human-like
summaries, there is a risk that their outputs may inadvertently diverge from
the true substance of the original responses. Discrepancies between the
LLM-generated outputs and the actual themes present in the data could lead to
flawed decision-making, with far-reaching consequences for organizations. This
research investigates the effectiveness of LLM-as-judge models to evaluate the
thematic alignment of summaries generated by other LLMs. We utilized an
Anthropic Claude model to generate thematic summaries from open-ended survey
responses, with Amazon's Titan Express, Nova Pro, and Meta's Llama serving as
judges. This LLM-as-judge approach was compared to human evaluations using
Cohen's kappa, Spearman's rho, and Krippendorff's alpha, validating a scalable
alternative to traditional human centric evaluation methods. Our findings
reveal that while LLM-as-judge offer a scalable solution comparable to human
raters, humans may still excel at detecting subtle, context-specific nuances.
Our research contributes to the growing body of knowledge on AI assisted text
analysis. Further, we provide recommendations for future research, emphasizing
the need for careful consideration when generalizing LLM-as-judge models across
various contexts and use cases.

æè¦ï¼å¤§åèªè¨æ¨¡åçå¿«éé²æ­¥ï¼å¨èçåç¸½çµéçµæ§åæå­è³ææ¹é¢ï¼è§£éäºéå¡çè½åãéå°è±å¯ãéæ¾å¼è³æéçåææå½±é¿ï¼ä¾å¦èª¿æ¥åæï¼å¶ä¸­ LLM æ¿è«¾ææå°æçåºééµä¸»é¡åæç·ãç¶èï¼é¨èçµç¹è¶ä¾è¶ä¾è³´éäºå¼·å¤§ç AI ç³»çµ±ä¾çè§£æå­åé¥ï¼ä¸åééµåé¡åºç¾äºï¼æåè½ç¸ä¿¡ LLM è½æºç¢ºå°ä»£è¡¨éäºåºæ¼æå­çè³æéæåå«çè§é»åï¼éç¶ LLM å¨çæé¡ä¼¼äººé¡çæè¦æ¹é¢è¡¨ç¾åºè²ï¼ä½å­å¨å¶è¼¸åºå¯è½ç¡æéåé¢åå§åæççå¯¦å§å®¹çé¢¨éªãLLM çæçè¼¸åºèè³æä¸­å­å¨çå¯¦éä¸»é¡ä¹éçå·®ç°å¯è½å°è´æç¼ºé·çæ±ºç­å¶å®ï¼å°çµç¹ç¢çæ·±é å½±é¿ãæ¬ç ç©¶èª¿æ¥äº LLM ä½çºè©å¯©æ¨¡åè©ä¼°å¶ä» LLM çæçæè¦çä¸»é¡å°é½æ§çæææ§ãæåå©ç¨ Anthropic Claude æ¨¡åå¾éæ¾å¼èª¿æ¥åæä¸­çæä¸»é¡æè¦ï¼è Amazon ç Titan ExpressãNova Pro å Meta ç Llama åä½çºè©å¯©ãéç¨® LLM ä½çºè©å¯©çæ¹æ³ä½¿ç¨ Cohen's kappaãSpearman's rho å Krippendorff's alpha èäººé¡è©ä¼°é²è¡æ¯è¼ï¼é©è­äºå³çµ±ä»¥äººé¡çºä¸­å¿çè©ä¼°æ¹æ³çå¯æ´åæ¿ä»£æ¹æ¡ãæåçç ç©¶çµæè¡¨æï¼éç¶ LLM ä½çºè©å¯©æä¾äºèäººé¡è©åèç¸ç¶çå¯æ´åè§£æ±ºæ¹æ¡ï¼ä½äººé¡å¨æª¢æ¸¬å¾®å¦çãç¹å®æ¼ä¸ä¸æçç´°å¾®å·®å¥æ¹é¢ä»ç¶å¯è½è¡¨ç¾åºè²ãæåçç ç©¶æå©æ¼æ´åéæ¼ AI è¼å©æå­åæçç¥è­é«ç³»ãæ­¤å¤ï¼æåæä¾äºå°æªä¾ç ç©¶çå»ºè­°ï¼å¼·èª¿å¨åç¨®èæ¯åä½¿ç¨æ¡ä¾ä¸­æ¦æ¬ LLM ä½çºè©å¯©æ¨¡åæéè¦ä»ç´°èéã

##### **FairTTTS: A Tree Test Time Simulation Method for Fairness-Aware Classification**
2501.08155v1 by Nurit Cohen-Inger, Lior Rokach, Bracha Shapira, Seffi Cohen

Algorithmic decision-making has become deeply ingrained in many domains, yet
biases in machine learning models can still produce discriminatory outcomes,
often harming unprivileged groups. Achieving fair classification is inherently
challenging, requiring a careful balance between predictive performance and
ethical considerations. We present FairTTTS, a novel post-processing bias
mitigation method inspired by the Tree Test Time Simulation (TTTS) method.
Originally developed to enhance accuracy and robustness against adversarial
inputs through probabilistic decision-path adjustments, TTTS serves as the
foundation for FairTTTS. By building on this accuracy-enhancing technique,
FairTTTS mitigates bias and improves predictive performance. FairTTTS uses a
distance-based heuristic to adjust decisions at protected attribute nodes,
ensuring fairness for unprivileged samples. This fairness-oriented adjustment
occurs as a post-processing step, allowing FairTTTS to be applied to
pre-trained models, diverse datasets, and various fairness metrics without
retraining. Extensive evaluation on seven benchmark datasets shows that
FairTTTS outperforms traditional methods in fairness improvement, achieving a
20.96% average increase over the baseline compared to 18.78% for related work,
and further enhances accuracy by 0.55%. In contrast, competing methods
typically reduce accuracy by 0.42%. These results confirm that FairTTTS
effectively promotes more equitable decision-making while simultaneously
improving predictive performance.

æè¦ï¼æ¼ç®æ³æ±ºç­å¶å®å·²æ·±æ¤æ¼è¨±å¤é åä¸­ï¼ç¶èæ©å¨å­¸ç¿æ¨¡åä¸­çåè¦ä»å¯è½ç¢çæ­§è¦æ§ççµæï¼éå¸¸æå·å®³æªåä¿éçç¾¤é«ãéæå¬å¹³åé¡æ¬è³ªä¸å·æææ°æ§ï¼éè¦å¨é æ¸¬æè½èéå¾·èéä¹éåå¾ä»ç´°çå¹³è¡¡ãæåæåº FairTTTSï¼éæ¯ä¸ç¨®æ°ç©çå¾èçåèª¤ç·©è§£æ¹æ³ï¼å¶éæä¾èªæ¨¹æ¸¬è©¦æéæ¨¡æ¬ (TTTS) æ¹æ³ãTTTS æåæ¯çºäºééæ©çæ±ºç­è·¯å¾èª¿æ´ä¾å¢å¼·éå°å°æè¼¸å¥çæºç¢ºåº¦åç©©å¥æ§èéç¼ï¼ä¸¦ä½çº FairTTTS çåºç¤ãééå»ºç«å¨éç¨®å¢å¼·æºç¢ºåº¦çæè¡ä¹ä¸ï¼FairTTTS å¯ä»¥æ¸è¼åèª¤ä¸¦æ¹åé æ¸¬æè½ãFairTTTS ä½¿ç¨åºæ¼è·é¢çåç¼æ³ä¾èª¿æ´åä¿è­·å±¬æ§ç¯é»çæ±ºç­ï¼ç¢ºä¿æªåä¿éæ¨£æ¬çå¬å¹³æ§ãéç¨®ä»¥å¬å¹³æ§çºå°åçèª¿æ´æå¨å¾èçæ­¥é©ä¸­ç¼çï¼åè¨± FairTTTS å¥ç¨è³é åè¨ç·´çæ¨¡åãå¤æ¨£åçè³æéååç¨®å¬å¹³æ§ææ¨ï¼èç¡ééæ°è¨ç·´ãå¨ä¸ååºæºè³æéä¸çå»£æ³è©ä¼°é¡¯ç¤ºï¼FairTTTS å¨å¬å¹³æ§æ¹åæ¹é¢åªæ¼å³çµ±æ¹æ³ï¼èç¸éå·¥ä½ç 18.78% ç¸æ¯ï¼å¹³åæåäº 20.96%ï¼ä¸¦é²ä¸æ­¥å°æºç¢ºåº¦æåäº 0.55%ãç¸åå°ï¼ç«¶ç­æ¹æ³éå¸¸æå°æºç¢ºåº¦éä½ 0.42%ãéäºçµæè­å¯¦ï¼FairTTTS ææå°ä¿é²äºæ´å¬å¹³çæ±ºç­å¶å®ï¼åæä¹æ¹åäºé æ¸¬æè½ã

##### **Guiding the classification of hepatocellular carcinoma on 3D CT-scans using deep and handcrafted radiological features**
2501.08097v1 by E. Sarfati, A. BÃ´ne, M-M. RohÃ©, C. AubÃ©, M. Ronot, P. Gori, I. Bloch

Hepatocellular carcinoma is the most spread primary liver cancer across the
world ($\sim$80\% of the liver tumors). The gold standard for HCC diagnosis is
liver biopsy. However, in the clinical routine, expert radiologists provide a
visual diagnosis by interpreting hepatic CT-scans according to a standardized
protocol, the LI-RADS, which uses five radiological criteria with an associated
decision tree. In this paper, we propose an automatic approach to predict
histology-proven HCC from CT images in order to reduce radiologists'
inter-variability. We first show that standard deep learning methods fail to
accurately predict HCC from CT-scans on a challenging database, and propose a
two-step approach inspired by the LI-RADS system to improve the performance. We
achieve improvements from 6 to 18 points of AUC with respect to deep learning
baselines trained with different architectures. We also provide clinical
validation of our method, achieving results that outperform non-expert
radiologists and are on par with expert ones.

æè¦ï¼èç´°èçæ¯æå¸¸è¦çåç¼æ§èçï¼éå¸å¨çï¼ç´ä½èèè«ç¤ç 80%ï¼ãHCC è¨ºæ·çé»éæ¨æºæ¯èèæ´»æª¢ãç¶èï¼å¨è¨åºå¸¸è¦ä¸­ï¼å°å®¶æ¾å°ç§é«å¸«ææ ¹ææ¨æºååå® LI-RADS ä¾è§£è®èèé»è¦æ·å±¤ææï¼æä¾è¦è¦ºè¨ºæ·ï¼æ­¤åå®ä½¿ç¨äºé æ¾å°å­¸æ¨æºï¼ä¸¦éæç¸éæ±ºç­æ¨¹ãå¨æ¬æä¸­ï¼æåæåºäºä¸ç¨®èªååæ¹æ³ï¼ç¨æ¼å¾é»è¦æ·å±¤å½±åé æ¸¬çµç¹ççå­¸è­å¯¦ç HCCï¼ä»¥æ¸å°æ¾å°ç§é«å¸«çè®ç°æ§ãæåé¦åè¡¨æï¼æ¨æºæ·±åº¦å­¸ç¿æ¹æ³ç¡æ³æºç¢ºå°å¾å·æææ°æ§çè³æåº«ä¸­çé»è¦æ·å±¤ææé æ¸¬ HCCï¼ä¸¦æåºäºä¸åå LI-RADS ç³»çµ±åç¼çå©æ­¥é©æ¹æ³ä¾æ¹åæè½ãç¸è¼æ¼ä½¿ç¨ä¸åæ¶æ§è¨ç·´çæ·±åº¦å­¸ç¿åºæºï¼æåå¨ AUC ä¸­ç²å¾äº 6 å° 18 åé»çé²æ­¥ãæåä¹æä¾äºæåæ¹æ³çè¨åºé©è­ï¼æç²å¾ççµæåªæ¼éå°å®¶æ¾å°ç§é«å¸«ï¼ä¸èå°å®¶ç¸ç¶ã

##### **Exploring visual language models as a powerful tool in the diagnosis of Ewing Sarcoma**
2501.08042v1 by Alvaro Pastor-Naranjo, Pablo Meseguer, RocÃ­o del Amor, Jose Antonio Lopez-Guerrero, Samuel Navarro, Katia Scotlandi, Antonio Llombart-Bosch, Isidro Machado, Valery Naranjo

Ewing's sarcoma (ES), characterized by a high density of small round blue
cells without structural organization, presents a significant health concern,
particularly among adolescents aged 10 to 19. Artificial intelligence-based
systems for automated analysis of histopathological images are promising to
contribute to an accurate diagnosis of ES. In this context, this study explores
the feature extraction ability of different pre-training strategies for
distinguishing ES from other soft tissue or bone sarcomas with similar
morphology in digitized tissue microarrays for the first time, as far as we
know. Vision-language supervision (VLS) is compared to fully-supervised
ImageNet pre-training within a multiple instance learning paradigm. Our
findings indicate a substantial improvement in diagnostic accuracy with the
adaption of VLS using an in-domain dataset. Notably, these models not only
enhance the accuracy of predicted classes but also drastically reduce the
number of trainable parameters and computational costs.

æè¦ï¼å°¤å æ°èç¤ (ES) çç¹å¾æ¯é«å¯åº¦çæ ç»æç»ç»çå°åå½¢èè²ç»èï¼å¯¹å¥åº·ææéå¤§å¨èï¼å°¤å¶æ¯å¨ 10 è³ 19 å²çéå°å¹´ä¸­ãåºäºäººå·¥æºè½çç»ç»ççå­¦å¾åèªå¨åæç³»ç»æææå©äº ES çåç¡®è¯æ­ãå¨æ­¤èæ¯ä¸ï¼æ¬ç ç©¶é¦æ¬¡æ¢è®¨äºä¸åé¢è®­ç»ç­ç¥çç¹å¾æåè½åï¼ä»¥åºå ES ä¸æ°å­åç»ç»å¾®éµåä¸­å½¢æç¸ä¼¼çå¶ä»è½¯ç»ç»æéª¨èç¤ï¼æ®æä»¬æç¥ãè§è§è¯­è¨çç£ (VLS) ä¸å¤å®ä¾å­¦ä¹ èå¼ä¸­çå®å¨çç£ ImageNet é¢è®­ç»è¿è¡äºæ¯è¾ãæä»¬çç ç©¶ç»æè¡¨æï¼ä½¿ç¨ååæ°æ®éè°æ´ VLS å¯å¤§å¹æé«è¯æ­åç¡®æ§ãå¼å¾æ³¨æçæ¯ï¼è¿äºæ¨¡åä¸ä»æé«äºé¢æµç±»å«çåç¡®æ§ï¼è¿å¤§å¹åå°äºå¯è®­ç»åæ°åè®¡ç®ææ¬ã

##### **Comprehensive Metapath-based Heterogeneous Graph Transformer for Gene-Disease Association Prediction**
2501.07970v1 by Wentao Cui, Shoubo Li, Chen Fang, Qingqing Long, Chengrui Wang, Xuezhi Wang, Yuanchun Zhou

Discovering gene-disease associations is crucial for understanding disease
mechanisms, yet identifying these associations remains challenging due to the
time and cost of biological experiments. Computational methods are increasingly
vital for efficient and scalable gene-disease association prediction.
Graph-based learning models, which leverage node features and network
relationships, are commonly employed for biomolecular predictions. However,
existing methods often struggle to effectively integrate node features,
heterogeneous structures, and semantic information. To address these
challenges, we propose COmprehensive MEtapath-based heterogeneous graph
Transformer(COMET) for predicting gene-disease associations. COMET integrates
diverse datasets to construct comprehensive heterogeneous networks,
initializing node features with BioGPT. We define seven Metapaths and utilize a
transformer framework to aggregate Metapath instances, capturing global
contexts and long-distance dependencies. Through intra- and inter-metapath
aggregation using attention mechanisms, COMET fuses latent vectors from
multiple Metapaths to enhance GDA prediction accuracy. Our method demonstrates
superior robustness compared to state-of-the-art approaches. Ablation studies
and visualizations validate COMET's effectiveness, providing valuable insights
for advancing human health research.

æè¦ï¼ç¼ç¾åºå ç¾çéè¯å°æ¼çè§£ç¾çæ©å¶è³ééè¦ï¼ä½ç±æ¼çç©å¯¦é©çæéåææ¬ï¼è­å¥éäºéè¯ä»ç¶å·æææ°æ§ãè¨ç®æ¹æ³å°æ¼é«æä¸å¯æ´åçåºå ç¾çéè¯é æ¸¬è¶ä¾è¶éè¦ãåºæ¼åçå­¸ç¿æ¨¡åå©ç¨ç¯é»ç¹å¾µåç¶²è·¯éä¿ï¼éå¸¸ç¨æ¼çç©åå­é æ¸¬ãç¶èï¼ç¾ææ¹æ³éå¸¸é£ä»¥æææ´åç¯é»ç¹å¾µãç°è³ªçµæ§åèªç¾©è³è¨ãçºäºæå°éäºææ°ï¼æåæåºäºåºæ¼ç¶ååè·¯å¾çç°è³ªåè½æå¨ (COMET)ï¼ç¨æ¼é æ¸¬åºå ç¾çéè¯ãCOMET æ´åäºä¸åçè³æéä¾æ§å»ºå¨é¢çç°è³ªç¶²è·¯ï¼ä½¿ç¨ BioGPT åå§åç¯é»ç¹å¾µãæåå®ç¾©äºä¸ååè·¯å¾ï¼ä¸¦å©ç¨è½æå¨æ¡æ¶ä¾èååè·¯å¾å¯¦ä¾ï¼æ·åå¨å±ä¸ä¸æåé·è·é¢ä¾è³´éä¿ãééä½¿ç¨æ³¨ææ©å¶é²è¡åè·¯å¾å§é¨ååè·¯å¾éèåï¼COMET èåäºä¾èªå¤ååè·¯å¾çæ½å¨åéï¼ä»¥å¢å¼· GDA é æ¸¬æºç¢ºæ§ãèæåé²çæ¹æ³ç¸æ¯ï¼æåçæ¨¡åå±ç¤ºäºåè¶çç©©å¥æ§ãæ¶èç ç©¶åè¦è¦ºåé©è­äº COMET çæææ§ï¼çºæ¨é²äººé¡å¥åº·ç ç©¶æä¾äºæå¹å¼çè¦è§£ã

##### **Advice for Diabetes Self-Management by ChatGPT Models: Challenges and Recommendations**
2501.07931v1 by Waqar Hussain, John Grundy

Given their ability for advanced reasoning, extensive contextual
understanding, and robust question-answering abilities, large language models
have become prominent in healthcare management research. Despite adeptly
handling a broad spectrum of healthcare inquiries, these models face
significant challenges in delivering accurate and practical advice for chronic
conditions such as diabetes. We evaluate the responses of ChatGPT versions 3.5
and 4 to diabetes patient queries, assessing their depth of medical knowledge
and their capacity to deliver personalized, context-specific advice for
diabetes self-management. Our findings reveal discrepancies in accuracy and
embedded biases, emphasizing the models' limitations in providing tailored
advice unless activated by sophisticated prompting techniques. Additionally, we
observe that both models often provide advice without seeking necessary
clarification, a practice that can result in potentially dangerous advice. This
underscores the limited practical effectiveness of these models without human
oversight in clinical settings. To address these issues, we propose a
commonsense evaluation layer for prompt evaluation and incorporating
disease-specific external memory using an advanced Retrieval Augmented
Generation technique. This approach aims to improve information quality and
reduce misinformation risks, contributing to more reliable AI applications in
healthcare settings. Our findings seek to influence the future direction of AI
in healthcare, enhancing both the scope and quality of its integration.

æè¦ï¼ç±æ¼å¤§åèªè¨æ¨¡åå·æåé²æ¨çè½åãå»£æ³çèæ¯çè§£è½ååå¼·å¤§çåé¡åç­è½åï¼å æ­¤å¨é«çä¿å¥ç®¡çç ç©¶ä¸­è®å¾çªåºãåç®¡éäºæ¨¡åè½çç·´å°èçå»£æ³çé«çä¿å¥æ¥è©¢ï¼ä½å¨æä¾æ¢æ§ç¾çï¼ä¾å¦ç³å°¿çï¼çæºç¢ºä¸å¯¦ç¨çå»ºè­°æ¹é¢ï¼éäºæ¨¡åé¢è¨èéå¤§çææ°ãæåè©ä¼°äº ChatGPT çæ¬ 3.5 å 4 å°ç³å°¿çæ£èæ¥è©¢çåæï¼è©ä¼°äºä»åçé«å­¸ç¥è­æ·±åº¦ä»¥åæä¾éå°ç³å°¿çèªæç®¡ççåæ§åãç¹å®æ¼èæ¯çå»ºè­°çè½åãæåçç ç©¶çµææ­ç¤ºäºæºç¢ºæ§åå§åµåå·®çå·®ç°ï¼å¼·èª¿äºéäºæ¨¡åå¨æªç¶è¤éæç¤ºæè¡åç¨ææä¾å®å¶å»ºè­°çå±éæ§ãæ­¤å¤ï¼æåè§å¯å°éå©åæ¨¡åéå¸¸å¨ä¸å°æ±å¿è¦çæ¾æ¸çææ³ä¸æä¾å»ºè­°ï¼éç¨®åæ³å¯è½æå°è´æ½å¨çå±éªå»ºè­°ãéå¸é¡¯äºéäºæ¨¡åå¨æ²æè¨åºç°å¢ä¸­çäººå·¥ç£ç£çææ³ä¸å¯¦ç¨æææ§æéãçºäºè§£æ±ºéäºåé¡ï¼æåæåºäºä¸åå¸¸è­è©ä¼°å±¤ï¼ç¨æ¼æç¤ºè©ä¼°åä½¿ç¨åé²çæª¢ç´¢å¢å¼·çææè¡æ´åç¹å®ç¾ççå¤é¨è¨æ¶é«ãéç¨®æ¹æ³æ¨å¨æé«è³è¨åè³ªä¸¦éä½é¯èª¤è³è¨é¢¨éªï¼æå©æ¼å¨é«çä¿å¥ç°å¢ä¸­å»ºç«æ´å¯é çäººå·¥æºæ§æç¨ç¨å¼ãæåçç ç©¶çµææ¨å¨å½±é¿äººå·¥æºæ§å¨é«çä¿å¥ä¸­çæªä¾æ¹åï¼åææåå¶æ´åçç¯åååè³ªã

##### **Large Language Models for Interpretable Mental Health Diagnosis**
2501.07653v1 by Brian Hyeongseok Kim, Chao Wang

We propose a clinical decision support system (CDSS) for mental health
diagnosis that combines the strengths of large language models (LLMs) and
constraint logic programming (CLP). Having a CDSS is important because of the
high complexity of diagnostic manuals used by mental health professionals and
the danger of diagnostic errors. Our CDSS is a software tool that uses an LLM
to translate diagnostic manuals to a logic program and solves the program using
an off-the-shelf CLP engine to query a patient's diagnosis based on the encoded
rules and provided data. By giving domain experts the opportunity to inspect
the LLM-generated logic program, and making modifications when needed, our CDSS
ensures that the diagnosis is not only accurate but also interpretable. We
experimentally compare it with two baseline approaches of using LLMs:
diagnosing patients using the LLM-only approach, and using the LLM-generated
logic program but without expert inspection. The results show that, while LLMs
are extremely useful in generating candidate logic programs, these programs
still require expert inspection and modification to guarantee faithfulness to
the official diagnostic manuals. Additionally, ethical concerns arise from the
direct use of patient data in LLMs, underscoring the need for a safer hybrid
approach like our proposed method.

æè¦ï¼<paragraph>æåæåºä¸åç¨æ¼å¿çå¥åº·è¨ºæ·çè¨åºæ±ºç­æ¯æ´ç³»çµ± (CDSS)ï¼å®çµåäºå¤§åèªè¨æ¨¡å (LLM) åç´æéè¼¯ç¨å¼è¨­è¨ (CLP) çåªé»ãææ CDSS å¾éè¦ï¼å çºå¿çå¥åº·å°æ¥­äººå£«ä½¿ç¨çè¨ºæ·æåéå¸¸è¤éï¼èä¸è¨ºæ·é¯èª¤å¾å±éªãæåç CDSS æ¯ä¸åè»é«å·¥å·ï¼å®ä½¿ç¨ LLM å°è¨ºæ·æåè½ææéè¼¯ç¨å¼ï¼ä¸¦ä½¿ç¨ç¾æç CLP å¼æè§£æ±ºç¨å¼ï¼ä»¥æ ¹æç·¨ç¢¼è¦ååæä¾çè³ææ¥è©¢çäººçè¨ºæ·ãééè®é åå°å®¶ææ©ææª¢æ¥ LLM çæçéè¼¯ç¨å¼ï¼ä¸¦å¨éè¦æé²è¡ä¿®æ¹ï¼æåç CDSS å¯ç¢ºä¿è¨ºæ·ä¸åæºç¢ºï¼èä¸å¯è§£è®ãæåä»¥å¯¦é©çæ¹å¼å°å¶èå©ç¨®ä½¿ç¨ LLM çåºç·æ¹æ³é²è¡æ¯è¼ï¼åä½¿ç¨ LLM æ¹æ³è¨ºæ·çäººï¼ä»¥åä½¿ç¨ LLM çæçéè¼¯ç¨å¼ï¼ä½æ²æå°å®¶æª¢æ¥ãçµæé¡¯ç¤ºï¼éç¶ LLM å¨ç¢çåé¸éè¼¯ç¨å¼æ¹é¢éå¸¸æç¨ï¼ä½éäºç¨å¼ä»ç¶éè¦å°å®¶æª¢æ¥åä¿®æ¹ï¼ä»¥ç¢ºä¿å°å®æ¹è¨ºæ·æåçå¿ å¯¦åº¦ãæ­¤å¤ï¼ç´æ¥å¨ LLM ä¸­ä½¿ç¨çäººè³ææå¼ç¼å«çåé¡ï¼éå¼·èª¿äºéè¦ä¸ç¨®æ´å®å¨çæ··åæ¹æ³ï¼ä¾å¦æåæåºçæ¹æ³ã</paragraph>

##### **RadAlign: Advancing Radiology Report Generation with Vision-Language Concept Alignment**
2501.07525v1 by Difei Gu, Yunhe Gao, Yang Zhou, Mu Zhou, Dimitris Metaxas

Automated chest radiographs interpretation requires both accurate disease
classification and detailed radiology report generation, presenting a
significant challenge in the clinical workflow. Current approaches either focus
on classification accuracy at the expense of interpretability or generate
detailed but potentially unreliable reports through image captioning
techniques. In this study, we present RadAlign, a novel framework that combines
the predictive accuracy of vision-language models (VLMs) with the reasoning
capabilities of large language models (LLMs). Inspired by the radiologist's
workflow, RadAlign first employs a specialized VLM to align visual features
with key medical concepts, achieving superior disease classification with an
average AUC of 0.885 across multiple diseases. These recognized medical
conditions, represented as text-based concepts in the aligned visual-language
space, are then used to prompt LLM-based report generation. Enhanced by a
retrieval-augmented generation mechanism that grounds outputs in similar
historical cases, RadAlign delivers superior report quality with a GREEN score
of 0.678, outperforming state-of-the-art methods' 0.634. Our framework
maintains strong clinical interpretability while reducing hallucinations,
advancing automated medical imaging and report analysis through integrated
predictive and generative AI. Code is available at
https://github.com/difeigu/RadAlign.

æè¦ï¼èªååè¸é¨ X åçè§£è®éè¦ç²¾æºçç¾çåé¡åè©³ç´°çæ¾å°ç§å ±åçæï¼éå°è¨åºå·¥ä½æµç¨æ§æéå¤§ææ°ãç®åçåæ³è¦ä¸å°±æ¯ä»¥ç§ç²å¯è§£è®æ§çºä»£å¹å°æ³¨æ¼åé¡æºç¢ºæ§ï¼è¦ä¸å°±æ¯ééå½±åæ¨é¡æè¡ç¢çè©³ç´°ä½å¯è½ä¸å¯é çå ±åãå¨éé ç ç©¶ä¸­ï¼æåæåº RadAlignï¼ä¸åçµåäºè¦è¦ºèªè¨æ¨¡å (VLM) çé æ¸¬æºç¢ºæ§åå¤§åèªè¨æ¨¡å (LLM) çæ¨çè½åçæ°ç©æ¶æ§ãåå°æ¾å°ç§é«å¸«å·¥ä½æµç¨çåç¼ï¼RadAlign é¦åæ¡ç¨å°éç VLM å°è¦è¦ºç¹å¾µèééµé«çæ¦å¿µå°é½ï¼å¨å¤ç¨®ç¾çä¸­éæåªç°çç¾çåé¡ï¼å¹³å AUC çº 0.885ãéäºè­å¥åºçé«ççæ³æå¨å°é½çè¦è¦ºèªè¨ç©ºéä¸­è¡¨ç¤ºçºåºæ¼æå­çæ¦å¿µï¼ç¶å¾ç¨ä¾æç¤ºåºæ¼ LLM çå ±åçæãééä¸ç¨®å°è¼¸åºçµæå»ºç«å¨é¡ä¼¼éå¾æ¡ä¾ä¸­çæª¢ç´¢å¢å¼·çææ©å¶ï¼RadAlign æä¾åªç°çå ±ååè³ªï¼GREEN åæ¸çº 0.678ï¼åªæ¼æåé²æ¹æ³ç 0.634ãæåçæ¶æ§ç¶­æå¼·å¤§çè¨åºå¯è§£è®æ§ï¼åææ¸å°å¹»è¦ºï¼ééæ´åé æ¸¬åçæå¼ AIï¼æ¨é²èªååé«å­¸å½±ååå ±ååæãç¨å¼ç¢¼å¯æ¼ https://github.com/difeigu/RadAlign åå¾ã

##### **A Survey of Embodied AI in Healthcare: Techniques, Applications, and Opportunities**
2501.07468v1 by Yihao Liu, Xu Cao, Tingting Chen, Yankai Jiang, Junjie You, Minghua Wu, Xiaosong Wang, Mengling Feng, Yaochu Jin, Jintai Chen

Healthcare systems worldwide face persistent challenges in efficiency,
accessibility, and personalization. Powered by modern AI technologies such as
multimodal large language models and world models, Embodied AI (EmAI)
represents a transformative frontier, offering enhanced autonomy and the
ability to interact with the physical world to address these challenges. As an
interdisciplinary and rapidly evolving research domain, "EmAI in healthcare"
spans diverse fields such as algorithms, robotics, and biomedicine. This
complexity underscores the importance of timely reviews and analyses to track
advancements, address challenges, and foster cross-disciplinary collaboration.
In this paper, we provide a comprehensive overview of the "brain" of EmAI for
healthcare, wherein we introduce foundational AI algorithms for perception,
actuation, planning, and memory, and focus on presenting the healthcare
applications spanning clinical interventions, daily care & companionship,
infrastructure support, and biomedical research. Despite its promise, the
development of EmAI for healthcare is hindered by critical challenges such as
safety concerns, gaps between simulation platforms and real-world applications,
the absence of standardized benchmarks, and uneven progress across
interdisciplinary domains. We discuss the technical barriers and explore
ethical considerations, offering a forward-looking perspective on the future of
EmAI in healthcare. A hierarchical framework of intelligent levels for EmAI
systems is also introduced to guide further development. By providing
systematic insights, this work aims to inspire innovation and practical
applications, paving the way for a new era of intelligent, patient-centered
healthcare.

æè¦ï¼<paragraph>å¨çé«çä¿å¥ç³»çµ±å¨æçãå¯åæ§ååäººåæ¹é¢æçºé¢è¨ææ°ãé«ç¾å¼ AI (EmAI) ç±å¤æ¨¡æå¤§åèªè¨æ¨¡ååä¸çæ¨¡åç­ç¾ä»£ AI æè¡æä¾æ¯æï¼ä»£è¡¨äºä¸åè½ååæ²¿ï¼æä¾å¢å¼·çèªä¸»æ§ï¼ä»¥åèç©çä¸çäºåä»¥æå°éäºææ°çè½åãä½çºä¸åè·¨å­¸ç§ä¸å¿«éç¼å±çç ç©¶é åï¼ãé«çä¿å¥ä¸­ç EmAIãæ¶µèäºæ¼ç®æ³ãæ©å¨äººåçç©é«å­¸ç­å¤åé åãéç¨®è¤éæ§çªé¡¯äºåæå¯©æ¥ååæçéè¦æ§ï¼ä»¥è¿½è¹¤é²å±ãæå°ææ°ä¸¦ä¿é²è·¨å­¸ç§åä½ãå¨æ¬æä¸­ï¼æåæä¾äº EmAI å¨é«çä¿å¥ä¸­çãå¤§è¦ãçå¨é¢æ¦è¿°ï¼æåå¨å¶ä¸­ä»ç´¹äºæç¥ãå·è¡ãè¦ååè¨æ¶çåºæ¬ AI æ¼ç®æ³ï¼ä¸¦å°æ³¨æ¼åç¾æ¶µèè¨åºå¹²é ãæ¥å¸¸ç§è­·åéªä¼´ãåºç¤è¨­æ½æ¯æ´åçç©é«å­¸ç ç©¶çé«çä¿å¥æç¨ãåç®¡åæ¯çå¥½ï¼ä½ EmAI å¨é«çä¿å¥ä¸­çç¼å±åå°ééµææ°çé»ç¤ï¼ä¾å¦å®å¨åé¡ãæ¨¡æ¬å¹³å°åå¯¦éæç¨ä¹éçå·®è·ãç¼ºä¹æ¨æºååºæºï¼ä»¥åè·¨å­¸ç§é åé²å±ä¸åãæåè¨è«äºæè¡éç¤ä¸¦æ¢è¨äºéå¾·èéï¼å° EmAI å¨é«çä¿å¥ä¸­çæªä¾æä¾äºåç»æ§çè§é»ãéå¼å¥äº EmAI ç³»çµ±çæºæ§å±¤ç´æ¶æ§ï¼ä»¥æå°é²ä¸æ­¥çç¼å±ãééæä¾ç³»çµ±æ§çè¦è§£ï¼éé å·¥ä½æ¨å¨æ¿ç¼åµæ°åå¯¦ç¨æç¨ï¼çºæºæ§ä¸ä»¥æ£èçºä¸­å¿çé«çä¿å¥æ°æä»£éªè·¯ã</paragraph>

##### **Diff-Ensembler: Learning to Ensemble 2D Diffusion Models for Volume-to-Volume Medical Image Translation**
2501.07430v1 by Xiyue Zhu, Dou Hoon Kwark, Ruike Zhu, Kaiwen Hong, Yiqi Tao, Shirui Luo, Yudu Li, Zhi-Pei Liang, Volodymyr Kindratenko

Despite success in volume-to-volume translations in medical images, most
existing models struggle to effectively capture the inherent volumetric
distribution using 3D representations. The current state-of-the-art approach
combines multiple 2D-based networks through weighted averaging, thereby
neglecting the 3D spatial structures. Directly training 3D models in medical
imaging presents significant challenges due to high computational demands and
the need for large-scale datasets. To address these challenges, we introduce
Diff-Ensembler, a novel hybrid 2D-3D model for efficient and effective
volumetric translations by ensembling perpendicularly trained 2D diffusion
models with a 3D network in each diffusion step. Moreover, our model can
naturally be used to ensemble diffusion models conditioned on different
modalities, allowing flexible and accurate fusion of input conditions.
Extensive experiments demonstrate that Diff-Ensembler attains superior accuracy
and volumetric realism in 3D medical image super-resolution and modality
translation. We further demonstrate the strength of our model's volumetric
realism using tumor segmentation as a downstream task.

æè¦ï¼åç®¡å¨é«å­¸å½±åä¸­é«ç©å°é«ç©çç¿»è­¯åå¾æåï¼ä½ç¾æçæ¨¡åå¤§å¤é£ä»¥ææå°ä½¿ç¨ 3D åç¾ä¾æ·ååºæçé«ç©åä½ãç®åæåé²çæ¹æ³æ¯ééå æ¬å¹³åä¾çµåå¤ååºæ¼ 2D çç¶²è·¯ï¼å æ­¤å¿½ç¥äº 3D ç©ºéçµæ§ãå¨é«å­¸å½±åä¸­ç´æ¥è¨ç·´ 3D æ¨¡åæç¢çé¡¯èçææ°ï¼åå å¨æ¼é«éç®éæ±åå¤§è¦æ¨¡è³æéçéæ±ãçºäºæå°éäºææ°ï¼æåå¼å¥äº Diff-Ensemblerï¼éæ¯ä¸åæ°ç©çæ··å 2D-3D æ¨¡åï¼å¯ééå¨æ¯åæ´æ£æ­¥é©ä¸­å°åç´è¨ç·´ç 2D æ´æ£æ¨¡åè 3D ç¶²è·¯çµåï¼ä¾ææçä¸ææå°é²è¡é«ç©è½æãæ­¤å¤ï¼æåçæ¨¡åå¯ä»¥èªç¶å°ç¨æ¼çµååºæ¼ä¸åå½¢å¼çæ´æ£æ¨¡åï¼å¾èéæ´»ä¸æºç¢ºå°èåè¼¸å¥æ¢ä»¶ãå»£æ³çå¯¦é©è­æï¼Diff-Ensembler å¨ 3D é«å­¸å½±åè¶è§£æåº¦åå½¢å¼è½æä¸­éå°äºæ´é«çæºç¢ºåº¦åé«ç©çå¯¦æãæåé²ä¸æ­¥ä½¿ç¨è«ç¤åå²ä½çºä¸æ¸¸ä»»åï¼ä¾è­ææåæ¨¡åçé«ç©çå¯¦æã

##### **Synthetic Data and Health Privacy**
2501.09031v1 by GwÃ©nolÃ© Abgrall, Xavier Monnet, Anmol Arora

This Viewpoint discusses generative artificial intelligence and safeguarding
privacy by using synthetic data as a substitute for private health data.

æè¦ï¼æ­¤è§é»æ¢è¨çæå¼äººå·¥æºæ§ä»¥åä½¿ç¨åæè³æåä»£ç§äººå¥åº·è³æä»¥ä¿è­·é±ç§ã

##### **Natural Language-Assisted Multi-modal Medication Recommendation**
2501.07166v1 by Jie Tan, Yu Rong, Kangfei Zhao, Tian Bian, Tingyang Xu, Junzhou Huang, Hong Cheng, Helen Meng

Combinatorial medication recommendation(CMR) is a fundamental task of
healthcare, which offers opportunities for clinical physicians to provide more
precise prescriptions for patients with intricate health conditions,
particularly in the scenarios of long-term medical care. Previous research
efforts have sought to extract meaningful information from electronic health
records (EHRs) to facilitate combinatorial medication recommendations. Existing
learning-based approaches further consider the chemical structures of
medications, but ignore the textual medication descriptions in which the
functionalities are clearly described. Furthermore, the textual knowledge
derived from the EHRs of patients remains largely underutilized. To address
these issues, we introduce the Natural Language-Assisted Multi-modal Medication
Recommendation(NLA-MMR), a multi-modal alignment framework designed to learn
knowledge from the patient view and medication view jointly. Specifically,
NLA-MMR formulates CMR as an alignment problem from patient and medication
modalities. In this vein, we employ pretrained language models(PLMs) to extract
in-domain knowledge regarding patients and medications, serving as the
foundational representation for both modalities. In the medication modality, we
exploit both chemical structures and textual descriptions to create medication
representations. In the patient modality, we generate the patient
representations based on textual descriptions of diagnosis, procedure, and
symptom. Extensive experiments conducted on three publicly accessible datasets
demonstrate that NLA-MMR achieves new state-of-the-art performance, with a
notable average improvement of 4.72% in Jaccard score. Our source code is
publicly available on https://github.com/jtan1102/NLA-MMR_CIKM_2024.

æè¦ï¼çµåå¼è¥ç©æ¨è¦ (CMR) æ¯é«çä¿å¥çä¸é åºæ¬ä»»åï¼å®çºè¨åºé«çæä¾äºéå°å·æè¤éå¥åº·çæ³çæ£èæä¾æ´ç²¾ç¢ºèæ¹çæ©æï¼ç¹å¥æ¯å¨é·æé«çä¿å¥çææ³ä¸ãååçç ç©¶å·¥ä½è©¦åå¾é»å­å¥åº·è¨é (EHR) ä¸­æåææç¾©çè³è¨ï¼ä»¥ä¿é²çµåå¼è¥ç©æ¨è¦ãç¾æçåºæ¼å­¸ç¿çæ¹æ³é²ä¸æ­¥èæ®äºè¥ç©çåå­¸çµæ§ï¼ä½å¿½ç¥äºåè½æ¸æ¥æè¿°æ¼å¶ä¸­çææ¬è¥ç©èªªæãæ­¤å¤ï¼å¾æ£èç EHR ä¸­è¡ççææ¬ç¥è­å¨å¾å¤§ç¨åº¦ä¸ä»æªå¾å°ååå©ç¨ãçºäºè§£æ±ºéäºåé¡ï¼æåå¼å¥äºèªç¶èªè¨è¼å©å¤æ¨¡å¼è¥ç©æ¨è¦ (NLA-MMR)ï¼éæ¯ä¸åå¤æ¨¡å¼å°é½æ¡æ¶ï¼æ¨å¨å¾æ£èè¦è§åè¥ç©è¦è§å±åå­¸ç¿ç¥è­ãå·é«ä¾èªªï¼NLA-MMR å° CMR æ§å»ºçºæ£èåè¥ç©æ¨¡å¼çå°é½åé¡ãå¨æ­¤èçµ¡ä¸­ï¼æåæ¡ç¨é è¨ç·´èªè¨æ¨¡å (PLM) ä¾æåæéæ£èåè¥ç©çé åå§ç¥è­ï¼ä½çºéå©ç¨®æ¨¡å¼çåºæ¬è¡¨ç¤ºãå¨è¥ç©æ¨¡å¼ä¸­ï¼æåå©ç¨åå­¸çµæ§åææ¬èªªæä¾å»ºç«è¥ç©è¡¨ç¤ºãå¨æ£èæ¨¡å¼ä¸­ï¼æåæ ¹æè¨ºæ·ãç¨åºåçççæå­èªªæä¾çææ£èè¡¨ç¤ºãå¨ä¸åå¬éå­åçè³æéä¸é²è¡çå»£æ³å¯¦é©è¡¨æï¼NLA-MMR éå°äºæ°çæåé²æè½ï¼åå¡å¾·ææ¸å¹³åæ¹é²äº 4.72%ãæåçåå§ç¢¼å¬éæ¼ https://github.com/jtan1102/NLA-MMR_CIKM_2024ã

##### **CureGraph: Contrastive Multi-Modal Graph Representation Learning for Urban Living Circle Health Profiling and Prediction**
2501.07157v1 by Jinlin Li, Xiao Zhou

The early detection and prediction of health status decline among the elderly
at the neighborhood level are of great significance for urban planning and
public health policymaking. While existing studies affirm the connection
between living environments and health outcomes, most rely on single data
modalities or simplistic feature concatenation of multi-modal information,
limiting their ability to comprehensively profile the health-oriented urban
environments. To fill this gap, we propose CureGraph, a contrastive multi-modal
representation learning framework for urban health prediction that employs
graph-based techniques to infer the prevalence of common chronic diseases among
the elderly within the urban living circles of each neighborhood. CureGraph
leverages rich multi-modal information, including photos and textual reviews of
residential areas and their surrounding points of interest, to generate urban
neighborhood embeddings. By integrating pre-trained visual and textual encoders
with graph modeling techniques, CureGraph captures cross-modal spatial
dependencies, offering a comprehensive understanding of urban environments
tailored to elderly health considerations. Extensive experiments on real-world
datasets demonstrate that CureGraph improves the best baseline by $28\%$ on
average in terms of $R^2$ across elderly disease risk prediction tasks.
Moreover, the model enables the identification of stage-wise chronic disease
progression and supports comparative public health analysis across
neighborhoods, offering actionable insights for sustainable urban development
and enhanced quality of life. The code is publicly available at
https://github.com/jinlin2021/CureGraph.

æè¦ï¼å¨é°éå±¤ç´æ©æåµæ¸¬åé æ¸¬èå¹´äººçå¥åº·çæ³ä¸éå°åå¸è¦ååå¬å±è¡çæ¿ç­å¶å®å·æéå¤§æç¾©ãåç®¡ç¾æç ç©¶è¯å®äºçæ´»ç°å¢èå¥åº·çµæä¹éçéè¯æ§ï¼ä½å¤§å¤ä¾è³´å®ä¸è³ææ¨¡å¼æå¤æ¨¡å¼è³è¨çç°¡åç¹å¾µä¸²æ¥ï¼éå¶äºä»åå¨é¢æç¹ªä»¥å¥åº·çºå°åçåå¸ç°å¢çè½åãçºäºå¡«è£éåå·®è·ï¼æåæåºäº CureGraphï¼ä¸åç¨æ¼åå¸å¥åº·é æ¸¬çå°æ¯å¼å¤æ¨¡å¼è¡¨ç¤ºå­¸ç¿æ¶æ§ï¼å®æ¡ç¨åºæ¼åå½¢æè¡ä¾æ¨è«æ¯åé°éåå¸çæ´»åä¸­èå¹´äººå¸¸è¦æ¢æ§ç¾ççæµè¡çãCureGraph å©ç¨è±å¯çå¤æ¨¡å¼è³è¨ï¼åæ¬ä½å®ååå¶å¨åæ¯é»çç§çåæå­è©è«ï¼ä¾ç¢çåå¸é°éåµå¥ãééæ´åé åè¨ç·´çè¦è¦ºåæå­ç·¨ç¢¼å¨èåå½¢å»ºæ¨¡æè¡ï¼CureGraph ææè·¨æ¨¡å¼ç©ºéä¾è³´æ§ï¼æä¾å°åå¸ç°å¢çå¨é¢çè§£ï¼å°ééå°èå¹´äººçå¥åº·èéãå¨çå¯¦ä¸çè³æéä¸çå»£æ³å¯¦é©è­æï¼CureGraph å¨èå¹´äººç¾çé¢¨éªé æ¸¬ä»»åä¸­ï¼å¹³åå¨ R2 æ¹é¢å°æä½³åºæºç·æé«äº 28%ãæ­¤å¤ï¼è©²æ¨¡åè½å¤ è­å¥éæ®µæ§çæ¢æ§ç¾çé²ç¨ï¼ä¸¦æ¯æ´è·¨é°éçæ¯è¼å¬å±è¡çåæï¼çºæ°¸çºçåå¸ç¼å±åæåçæ´»åè³ªæä¾å¯è¡çè¦è§£ãç¨å¼ç¢¼å·²å¬éæ¼ https://github.com/jinlin2021/CureGraphã

##### **UNetVL: Enhancing 3D Medical Image Segmentation with Chebyshev KAN Powered Vision-LSTM**
2501.07017v2 by Xuhui Guo, Tanmoy Dam, Rohan Dhamdhere, Gourav Modanwal, Anant Madabhushi

3D medical image segmentation has progressed considerably due to
Convolutional Neural Networks (CNNs) and Vision Transformers (ViTs), yet these
methods struggle to balance long-range dependency acquisition with
computational efficiency. To address this challenge, we propose UNETVL (U-Net
Vision-LSTM), a novel architecture that leverages recent advancements in
temporal information processing. UNETVL incorporates Vision-LSTM (ViL) for
improved scalability and memory functions, alongside an efficient Chebyshev
Kolmogorov-Arnold Networks (KAN) to handle complex and long-range dependency
patterns more effectively. We validated our method on the ACDC and AMOS2022
(post challenge Task 2) benchmark datasets, showing a significant improvement
in mean Dice score compared to recent state-of-the-art approaches, especially
over its predecessor, UNETR, with increases of 7.3% on ACDC and 15.6% on AMOS,
respectively. Extensive ablation studies were conducted to demonstrate the
impact of each component in UNETVL, providing a comprehensive understanding of
its architecture. Our code is available at https://github.com/tgrex6/UNETVL,
facilitating further research and applications in this domain.

æè¦ï¼3D é«å­¸å½±ååå²ç±æ¼å·ç©ç¥ç¶ç¶²è·¯ (CNN) åè¦è¦ºTransformer (ViT) èé²æ­¥è¨±å¤ï¼ç¶èéäºæ¹æ³é£ä»¥å¹³è¡¡é·ç¨ä¾è³´éä¿æ·åèéç®æçãçºäºæå°éåææ°ï¼æåæåº UNETVL (U-Net è¦è¦º LSTM)ï¼éæ¯ä¸ç¨®æ°ç©çæ¶æ§ï¼å®å©ç¨æéè³è¨èççææ°é²å±ãUNETVL çµåè¦è¦º LSTM (ViL) ä»¥æåå¯æ´åæ§åè¨æ¶åè½ï¼ä¸¦çµåé«æçåæ¯éªå¤« Kolmogorov-Arnold ç¶²è·¯ (KAN) ä»¥æ´ææçå°èçè¤éä¸é·ç¨çä¾è³´éä¿æ¨¡å¼ãæåå¨ ACDC å AMOS2022ï¼ææ°ä»»å 2 ä¹å¾ï¼åºæºè³æéé©è­äºæåçæ¹æ³ï¼èæè¿çææ°æè¡æ¹æ³ç¸æ¯ï¼å¹³å Dice åæ¸æé¡¯èæåï¼ç¹å¥æ¯èå¶åèº« UNETR ç¸æ¯ï¼å¨ ACDC ä¸æåäº 7.3%ï¼å¨ AMOS ä¸æåäº 15.6%ãæåé²è¡äºå»£æ³çæ¶èç ç©¶ï¼ä»¥å±ç¤º UNETVL ä¸­æ¯ååä»¶çå½±é¿ï¼æä¾å°å¶æ¶æ§çå¨é¢çè§£ãæåçç¨å¼ç¢¼å¯å¨ https://github.com/tgrex6/UNETVL åå¾ï¼ä¿é²é²ä¸æ­¥çå¨éæ¹é¢çç ç©¶åæç¨ã

##### **Combining LLM decision and RL action selection to improve RL policy for adaptive interventions**
2501.06980v1 by Karine Karine, Benjamin M. Marlin

Reinforcement learning (RL) is increasingly being used in the healthcare
domain, particularly for the development of personalized health adaptive
interventions. Inspired by the success of Large Language Models (LLMs), we are
interested in using LLMs to update the RL policy in real time, with the goal of
accelerating personalization. We use the text-based user preference to
influence the action selection on the fly, in order to immediately incorporate
the user preference. We use the term "user preference" as a broad term to refer
to a user personal preference, constraint, health status, or a statement
expressing like or dislike, etc. Our novel approach is a hybrid method that
combines the LLM response and the RL action selection to improve the RL policy.
Given an LLM prompt that incorporates the user preference, the LLM acts as a
filter in the typical RL action selection. We investigate different prompting
strategies and action selection strategies. To evaluate our approach, we
implement a simulation environment that generates the text-based user
preferences and models the constraints that impact behavioral dynamics. We show
that our approach is able to take into account the text-based user preferences,
while improving the RL policy, thus improving personalization in adaptive
intervention.

æè¦ï¼å¼·åå­¸ç¿ï¼RLï¼å¨é«çé åçæç¨æ¥çå»£æ³ï¼ç¹å¥æ¯ç¨æ¼éç¼åäººåå¥åº·é©ææ§å¹²é æªæ½ãåå°å¤§åèªè¨æ¨¡åï¼LLMï¼æåçåç¼ï¼æåæèè¶£ä½¿ç¨ LLM å³ææ´æ° RL æ¿ç­ï¼ç®æ¨æ¯å éåäººåãæåä½¿ç¨åºæ¼æå­çä½¿ç¨èåå¥½ä¾å½±é¿è¡åé¸æï¼ä»¥ä¾¿ç«å³ç´å¥ä½¿ç¨èåå¥½ãæåä½¿ç¨ãä½¿ç¨èåå¥½ãä¸è©ä½çºå»£ç¾©è©ï¼ç¨ä¾æä½¿ç¨èçåäººåå¥½ãéå¶ãå¥åº·çæ³æè¡¨éå¥½æ¡çé³è¿°ç­ãæåçæ°ç©æ¹æ³æ¯ä¸ç¨®æ··åæ¹æ³ï¼çµåäº LLM åæå RL è¡åé¸æä»¥æ¹å RL æ¿ç­ãçµ¦å®åå«ä½¿ç¨èåå¥½ç LLM æç¤ºï¼LLM å¨å¸åç RL è¡åé¸æä¸­åç¶éæ¿¾å¨ãæåç ç©¶äºä¸åçæç¤ºç­ç¥åè¡åé¸æç­ç¥ãçºäºè©ä¼°æåçåæ³ï¼æåå¯¦ä½äºä¸åæ¨¡æ¬ç°å¢ï¼ç¨æ¼ç¢çåºæ¼æå­çä½¿ç¨èåå¥½ï¼ä¸¦å°å½±é¿è¡çºåæçéå¶é²è¡å»ºæ¨¡ãæåå±ç¤ºäºæåçåæ³è½å¤ èéåºæ¼æå­çä½¿ç¨èåå¥½ï¼åææ¹å RL æ¿ç­ï¼å¾èæ¹åé©ææ§å¹²é ä¸­çåäººåã

##### **Enhancing Patient-Centric Communication: Leveraging LLMs to Simulate Patient Perspectives**
2501.06964v1 by Xinyao Ma, Rui Zhu, Zihao Wang, Jingwei Xiong, Qingyu Chen, Haixu Tang, L. Jean Camp, Lucila Ohno-Machado

Large Language Models (LLMs) have demonstrated impressive capabilities in
role-playing scenarios, particularly in simulating domain-specific experts
using tailored prompts. This ability enables LLMs to adopt the persona of
individuals with specific backgrounds, offering a cost-effective and efficient
alternative to traditional, resource-intensive user studies. By mimicking human
behavior, LLMs can anticipate responses based on concrete demographic or
professional profiles. In this paper, we evaluate the effectiveness of LLMs in
simulating individuals with diverse backgrounds and analyze the consistency of
these simulated behaviors compared to real-world outcomes. In particular, we
explore the potential of LLMs to interpret and respond to discharge summaries
provided to patients leaving the Intensive Care Unit (ICU). We evaluate and
compare with human responses the comprehensibility of discharge summaries among
individuals with varying educational backgrounds, using this analysis to assess
the strengths and limitations of LLM-driven simulations. Notably, when LLMs are
primed with educational background information, they deliver accurate and
actionable medical guidance 88% of the time. However, when other information is
provided, performance significantly drops, falling below random chance levels.
This preliminary study shows the potential benefits and pitfalls of
automatically generating patient-specific health information from diverse
populations. While LLMs show promise in simulating health personas, our results
highlight critical gaps that must be addressed before they can be reliably used
in clinical settings. Our findings suggest that a straightforward
query-response model could outperform a more tailored approach in delivering
health information. This is a crucial first step in understanding how LLMs can
be optimized for personalized health communication while maintaining accuracy.

æè¦ï¼å¤§åèªè¨æ¨¡åï¼LLMï¼å¨è§è²æ®æ¼å ´æ¯ä¸­å±ç¾äºä»¤äººå°è±¡æ·±å»çè½åï¼ç¹å¥æ¯å¨æ¨¡æ¬ç¹å®é åçå°å®¶æï¼æä½¿ç¨éèº«æé çæç¤ºãéç¨®è½åä½¿ LLM è½å¤ æ¡ç¨å·æç¹å®èæ¯çåäººè§è²ï¼æä¾ä¸ç¨®ç¶æ¿å¯¦æ ä¸ææççæ¿ä»£æ¹æ¡ï¼ç¨æ¼å³çµ±ä¸è³æºå¯éçä½¿ç¨èç ç©¶ãééæ¨¡æ¬äººé¡è¡çºï¼LLM è½å¤ æ ¹æå·é«çäººå£çµ±è¨æå°æ¥­ç¹å¾µé æ¸¬åæãå¨æ¬æä¸­ï¼æåè©ä¼°äº LLM å¨æ¨¡æ¬å·æä¸åèæ¯çåäººæ¹é¢çæææ§ï¼ä¸¦åæäºéäºæ¨¡æ¬è¡çºèå¯¦éçµæç¸æ¯çä¸è´æ§ãç¹å¥æ¯ï¼æåæ¢è¨äº LLM è§£éååææä¾çµ¦é¢éå è­·çæ¿ (ICU) æ£èçåºé¢æè¦çæ½åãæåè©ä¼°ä¸¦èäººé¡çåææ¯è¼äºä¸åæè²èæ¯çåäººå°åºé¢æè¦çå¯çè§£æ§ï¼ä¸¦ä½¿ç¨æ­¤åæä¾è©ä¼° LLM é©åæ¨¡æ¬çåªé»åéå¶ãå¼å¾æ³¨æçæ¯ï¼ç¶ LLM è¢«æ¤å¥æè²èæ¯è³è¨æï¼ä»åå¨ 88% çæéå§é½è½æä¾æºç¢ºä¸å¯è¡çé«çæå°ãä½æ¯ï¼ç¶æä¾å¶ä»è³è¨æï¼æè½æé¡¯èä¸éï¼ä½æ¼é¨æ©æ©æçç­ç´ãéé åæ­¥ç ç©¶é¡¯ç¤ºäºèªåç¢çä¾èªä¸åç¾¤é«çç¹å®æ¼æ£èçå¥åº·è³è¨çæ½å¨å¥½èåç¼ºé»ãåç®¡ LLM å¨æ¨¡æ¬å¥åº·è§è²æ¹é¢é¡¯ç¤ºåºåæ¯ï¼ä½æåççµæçªåºäºå¨è¨åºç°å¢ä¸­å¯é ä½¿ç¨ä¹åå¿é è§£æ±ºçééµå·®è·ãæåçç ç©¶çµæè¡¨æï¼å¨æä¾å¥åº·è³è¨æ¹é¢ï¼ä¸åç´æ¥çæ¥è©¢åææ¨¡åå¯ä»¥åªæ¼ä¸åæ´éèº«æé çæ¹æ³ãéæ¯äºè§£å¦ä½éå°åäººåå¥åº·æºéåªå LLM åæç¶­ææºç¢ºæ§çç¬¬ä¸æ­¥ã

##### **MedGrad E-CLIP: Enhancing Trust and Transparency in AI-Driven Skin Lesion Diagnosis**
2501.06887v1 by Sadia Kamal, Tim Oates

As deep learning models gain attraction in medical data, ensuring transparent
and trustworthy decision-making is essential. In skin cancer diagnosis, while
advancements in lesion detection and classification have improved accuracy, the
black-box nature of these methods poses challenges in understanding their
decision processes, leading to trust issues among physicians. This study
leverages the CLIP (Contrastive Language-Image Pretraining) model, trained on
different skin lesion datasets, to capture meaningful relationships between
visual features and diagnostic criteria terms. To further enhance transparency,
we propose a method called MedGrad E-CLIP, which builds on gradient-based
E-CLIP by incorporating a weighted entropy mechanism designed for complex
medical imaging like skin lesions. This approach highlights critical image
regions linked to specific diagnostic descriptions. The developed integrated
pipeline not only classifies skin lesions by matching corresponding
descriptions but also adds an essential layer of explainability developed
especially for medical data. By visually explaining how different features in
an image relates to diagnostic criteria, this approach demonstrates the
potential of advanced vision-language models in medical image analysis,
ultimately improving transparency, robustness, and trust in AI-driven
diagnostic systems.

æè¦ï¼éçæ·±åº¦å­¦ä¹ æ¨¡åå¨å»å­¦æ°æ®ä¸­è·å¾å³æ³¨ï¼ç¡®ä¿éæä¸å¼å¾ä¿¡èµçå³ç­è³å³éè¦ãå¨ç®è¤çè¯æ­ä¸­ï¼è½ç¶çç¶æ£æµååç±»çè¿æ­¥æé«äºåç¡®æ§ï¼ä½è¿äºæ¹æ³çé»çæ§è´¨å¯¹çè§£å¶å³ç­è¿ç¨ææäºææï¼å¯¼è´å»çä¹é´çä¿¡ä»»é®é¢ãæ¬ç ç©¶å©ç¨å¨ä¸åç®è¤çåæ°æ®éä¸è®­ç»ç CLIPï¼å¯¹æ¯è¯­è¨å¾åé¢è®­ç»ï¼æ¨¡åï¼ä»¥ææè§è§ç¹å¾åè¯æ­æ åæ¯è¯­ä¹é´çææä¹å³ç³»ãä¸ºäºè¿ä¸æ­¥æé«éæåº¦ï¼æä»¬æåºäºä¸ç§åä¸º MedGrad E-CLIP çæ¹æ³ï¼è¯¥æ¹æ³éè¿ç»åä¸ä¸ºç®è¤çåç­å¤æå»å­¦å½±åè®¾è®¡çå æçµæºå¶ï¼å»ºç«å¨åºäºæ¢¯åº¦ç E-CLIP ä¹ä¸ãæ­¤æ¹æ³çªåºäºä¸ç¹å®è¯æ­æè¿°ç¸å³èçå³é®å¾ååºåãå¼åçéæç®¡éä¸ä»éè¿å¹éç¸åºçæè¿°å¯¹ç®è¤çåè¿è¡åç±»ï¼è¿æ·»å äºä¸å±ä¸é¨ä¸ºå»å­¦æ°æ®å¼åçåºæ¬å¯è§£éæ§ãéè¿ç´è§å°è§£éå¾åä¸­ä¸åç¹å¾ä¸è¯æ­æ åçå³ç³»ï¼è¿ç§æ¹æ³å±ç¤ºäºé«çº§è§è§è¯­è¨æ¨¡åå¨å»å­¦å¾ååæä¸­çæ½åï¼æç»æé«äºéæåº¦ãç¨³å¥æ§åå¯¹äººå·¥æºè½é©±å¨çè¯æ­ç³»ç»çä¿¡ä»»ã

##### **A Foundational Generative Model for Breast Ultrasound Image Analysis**
2501.06869v1 by Haojun Yu, Youcheng Li, Nan Zhang, Zihan Niu, Xuantong Gong, Yanwen Luo, Haotian Ye, Siyu He, Quanlin Wu, Wangyan Qin, Mengyuan Zhou, Jie Han, Jia Tao, Ziwei Zhao, Di Dai, Di He, Dong Wang, Binghui Tang, Ling Huo, James Zou, Qingli Zhu, Yong Wang, Liwei Wang

Foundational models have emerged as powerful tools for addressing various
tasks in clinical settings. However, their potential development to breast
ultrasound analysis remains untapped. In this paper, we present BUSGen, the
first foundational generative model specifically designed for breast ultrasound
image analysis. Pretrained on over 3.5 million breast ultrasound images, BUSGen
has acquired extensive knowledge of breast structures, pathological features,
and clinical variations. With few-shot adaptation, BUSGen can generate
repositories of realistic and informative task-specific data, facilitating the
development of models for a wide range of downstream tasks. Extensive
experiments highlight BUSGen's exceptional adaptability, significantly
exceeding real-data-trained foundational models in breast cancer screening,
diagnosis, and prognosis. In breast cancer early diagnosis, our approach
outperformed all board-certified radiologists (n=9), achieving an average
sensitivity improvement of 16.5% (P-value<0.0001). Additionally, we
characterized the scaling effect of using generated data which was as effective
as the collected real-world data for training diagnostic models. Moreover,
extensive experiments demonstrated that our approach improved the
generalization ability of downstream models. Importantly, BUSGen protected
patient privacy by enabling fully de-identified data sharing, making progress
forward in secure medical data utilization. An online demo of BUSGen is
available at https://aibus.bio.

æè¦ï¼åºç¤æ¨¡åå·²æçºè§£æ±ºè¨åºç°å¢ä¸­åç¨®ä»»åçå¼·å¤§å·¥å·ãç¶èï¼å®åå¨ä¹³æ¿è¶é³æ³¢åæçæ½å¨ç¼å±ä»æªéç¼ãå¨æ¬æä¸­ï¼æåæåº BUSGenï¼éæ¯ç¬¬ä¸åå°éè¨­è¨ç¨æ¼ä¹³æ¿è¶é³æ³¢å½±ååæçåºç¤çææ¨¡åãBUSGen å¨è¶é 350 è¬å¼µä¹³æ¿è¶é³æ³¢å½±åä¸é²è¡é è¨ç·´ï¼å·²ç²å¾ä¹³æ¿çµæ§ãççç¹å¾µåè¨åºè®ç°çå»£æ³ç¥è­ãééå°éé©æï¼BUSGen å¯ä»¥ç¢çé¼çä¸å·æè³è¨æ§çç¹å®ä»»åè³æå²å­åº«ï¼ä¿é²éç¼å»£æ³çä¸æ¸¸ä»»åæ¨¡åãå»£æ³çå¯¦é©çªé¡¯äº BUSGen çåºè²é©ææ§ï¼å¨ä¹³çç¯©æª¢ãè¨ºæ·åé å¾æ¹é¢é¡¯èè¶è¶ä»¥çå¯¦è³æè¨ç·´çåºç¤æ¨¡åãå¨ä¹³çæ©æè¨ºæ·ä¸­ï¼æåçåæ³åªæ¼ææééèªè­çæ¾å°ç§é«å¸« (n=9)ï¼å¹³åææåº¦æé«äº 16.5%ï¼P å¼ <0.0001ï¼ãæ­¤å¤ï¼æåæè¿°äºä½¿ç¨çæè³æçè¦æ¨¡ææï¼å¶èæ¶éççå¯¦ä¸çè³æä¸æ¨£ææï¼å¯ç¨æ¼è¨ç·´è¨ºæ·æ¨¡åãæ­¤å¤ï¼å»£æ³çå¯¦é©è­æï¼æåçåæ³æ¹åäºä¸æ¸¸æ¨¡åçæ³åè½åãéè¦çæ¯ï¼BUSGen ä¿è­·äºæ£èé±ç§ï¼å çºå®è½å¤ å®å¨å»è­å¥è³æå±äº«ï¼å¨å®å¨é«çè³æå©ç¨æ¹é¢åå¾é²å±ãBUSGen çç·ä¸ç¤ºç¯å¯å¨ https://aibus.bio åå¾ã

##### **A Comprehensive Evaluation of Large Language Models on Mental Illnesses in Arabic Context**
2501.06859v1 by Noureldin Zahran, Aya E. Fouda, Radwa J. Hanafy, Mohammed E. Fouda

Mental health disorders pose a growing public health concern in the Arab
world, emphasizing the need for accessible diagnostic and intervention tools.
Large language models (LLMs) offer a promising approach, but their application
in Arabic contexts faces challenges including limited labeled datasets,
linguistic complexity, and translation biases. This study comprehensively
evaluates 8 LLMs, including general multi-lingual models, as well as bi-lingual
ones, on diverse mental health datasets (such as AraDepSu, Dreaddit, MedMCQA),
investigating the impact of prompt design, language configuration (native
Arabic vs. translated English, and vice versa), and few-shot prompting on
diagnostic performance. We find that prompt engineering significantly
influences LLM scores mainly due to reduced instruction following, with our
structured prompt outperforming a less structured variant on multi-class
datasets, with an average difference of 14.5\%. While language influence on
performance was modest, model selection proved crucial: Phi-3.5 MoE excelled in
balanced accuracy, particularly for binary classification, while Mistral NeMo
showed superior performance in mean absolute error for severity prediction
tasks. Few-shot prompting consistently improved performance, with particularly
substantial gains observed for GPT-4o Mini on multi-class classification,
boosting accuracy by an average factor of 1.58. These findings underscore the
importance of prompt optimization, multilingual analysis, and few-shot learning
for developing culturally sensitive and effective LLM-based mental health tools
for Arabic-speaking populations.

æè¦ï¼<paragraph>å¿çå¥åº·éç¤å¨é¿æä¼¯ä¸çä¸­æ§ææ¥çå´éçå¬å±è¡çåé¡ï¼å¼·èª¿äºå°å¯åçè¨ºæ·åå¹²é å·¥å·çéæ±ãå¤§åèªè¨æ¨¡å (LLM) æä¾äºä¸ç¨®æåéçæ¹æ³ï¼ä½å®åå¨é¿æä¼¯èªç°å¢ä¸­çæç¨é¢è¨èææ°ï¼åæ¬æ¨è¨è³æéæéãèªè¨è¤éæ§åç¿»è­¯åå·®ãæ¬ç ç©¶å¨é¢è©ä¼°äº 8 å LLMï¼åæ¬ä¸è¬å¤èªè¨æ¨¡ååéèªæ¨¡åï¼å¨ä¸åçå¿çå¥åº·è³æéï¼ä¾å¦ AraDepSuãDreadditãMedMCQAï¼ä¸ï¼æ¢è¨æç¤ºè¨­è¨ãèªè¨éç½®ï¼é¿æä¼¯èªåæèç¿»è­¯å¾çè±èªï¼åä¹äº¦ç¶ï¼åå°æ¬¡æç¤ºå°è¨ºæ·è¡¨ç¾çå½±é¿ãæåç¼ç¾æç¤ºå·¥ç¨é¡¯èå½±é¿ LLM åæ¸ï¼ä¸»è¦æ¯ç±æ¼æ¸å°äºèªªæéµå¾ªï¼æåççµæ§åæç¤ºå¨å¤é¡è³æéä¸åªæ¼çµæ§è¼ä¸å´è¬¹çè®é«ï¼å¹³åå·®ç°çº 14.5%ãéç¶èªè¨å°è¡¨ç¾çå½±é¿ä¸å¤§ï¼ä½æ¨¡åé¸æè¢«è­æè³ééè¦ï¼Phi-3.5 MoE å¨å¹³è¡¡æºç¢ºåº¦æ¹é¢è¡¨ç¾åºè²ï¼ç¹å¥æ¯å¨äºååé¡æ¹é¢ï¼è Mistral NeMo å¨å´éæ§é æ¸¬ä»»åçå¹³åçµå°èª¤å·®æ¹é¢è¡¨ç¾åºåªç°çè¡¨ç¾ãå°æ¬¡æç¤ºå§çµæ¹åè¡¨ç¾ï¼ç¹å¥æ¯å¨ GPT-4o Mini ä¸è§å¯å°å¤é¡åé¡çé¡¯èå¢çï¼å°æºç¢ºåº¦æé«äºå¹³å 1.58 åãéäºç¼ç¾å¼·èª¿äºæç¤ºæä½³åãå¤èªè¨åæåå°æ¬¡å­¸ç¿å°æ¼éç¼é©åæåä¸ææçåºæ¼ LLM çå¿çå¥åº·å·¥å·ä»¥æåé¿æä¼¯èªäººå£çéè¦æ§ã</paragraph>

##### **MEXA-CTP: Mode Experts Cross-Attention for Clinical Trial Outcome Prediction**
2501.06823v1 by Yiqing Zhang, Xiaozhong Liu, Fabricio Murai

Clinical trials are the gold standard for assessing the effectiveness and
safety of drugs for treating diseases. Given the vast design space of drug
molecules, elevated financial cost, and multi-year timeline of these trials,
research on clinical trial outcome prediction has gained immense traction.
Accurate predictions must leverage data of diverse modes such as drug
molecules, target diseases, and eligibility criteria to infer successes and
failures. Previous Deep Learning approaches for this task, such as HINT, often
require wet lab data from synthesized molecules and/or rely on prior knowledge
to encode interactions as part of the model architecture. To address these
limitations, we propose a light-weight attention-based model, MEXA-CTP, to
integrate readily-available multi-modal data and generate effective
representations via specialized modules dubbed "mode experts", while avoiding
human biases in model design. We optimize MEXA-CTP with the Cauchy loss to
capture relevant interactions across modes. Our experiments on the Trial
Outcome Prediction (TOP) benchmark demonstrate that MEXA-CTP improves upon
existing approaches by, respectively, up to 11.3% in F1 score, 12.2% in PR-AUC,
and 2.5% in ROC-AUC, compared to HINT. Ablation studies are provided to
quantify the effectiveness of each component in our proposed method.

æè¦ï¼è¨åºè©¦é©æ¯è©ä¼°æ²»çç¾ççè¥ç©æææ§åå®å¨æ§çé»éæ¨æºãéæ¼è¥ç©åå­çå»£æ³è¨­è¨ç©ºéãé«æçè²¡åææ¬åéäºè©¦é©å¤å¹´çæéè¡¨ï¼è¨åºè©¦é©çµæé æ¸¬çç ç©¶ç²å¾äºå·¨å¤§çéæ³¨ãæºç¢ºçé æ¸¬å¿é å©ç¨è¥ç©åå­ãç®æ¨ç¾çåç¬¦åè³æ ¼æ¨æºç­å¤ç¨®æ¨¡å¼çæ¸æä¾æ¨æ·æååå¤±æãæ­¤ä»»åçååæ·±åº¦å­¸ç¿æ¹æ³ï¼ä¾å¦ HINTï¼éå¸¸éè¦åæåå­çæ¿å¯¦é©å®¤æ¸æå/æä¾è³´æ¼åé©ç¥è­å°äº¤äºç·¨ç¢¼çºæ¨¡åæ¶æ§çä¸é¨åãçºäºè§£æ±ºéäºéå¶ï¼æåæåºäºä¸åè¼éç´çåºæ¼æ³¨æåçæ¨¡å MEXA-CTPï¼ä»¥æ´åç¾æçå¤æ¨¡å¼æ¸æä¸¦ééç¨±çºãæ¨¡å¼å°å®¶ãçå°ç¨æ¨¡çµç¢çææçè¡¨ç¤ºï¼åæé¿åæ¨¡åè¨­è¨ä¸­çäººçºåå·®ãæåä½¿ç¨æ¯è¥¿æå¤±å½æ¸æä½³å MEXA-CTPï¼ä»¥ææè·¨æ¨¡å¼ç¸éçäº¤äºãæåå¨è©¦é©çµæé æ¸¬ (TOP) åºæºä¸çå¯¦é©è¡¨æï¼è HINT ç¸æ¯ï¼MEXA-CTP åå¥å¨ F1 åæ¸ä¸æé«äº 11.3%ãPR-AUC ä¸æé«äº 12.2%ãROC-AUC ä¸æé«äº 2.5%ãæä¾äºæ¶èç ç©¶ä¾éåæåæåºçæ¹æ³ä¸­æ¯åçµä»¶çæææ§ã

##### **PGP-SAM: Prototype-Guided Prompt Learning for Efficient Few-Shot Medical Image Segmentation**
2501.06692v1 by Zhonghao Yan, Zijin Yin, Tianyu Lin, Xiangzhu Zeng, Kongming Liang, Zhanyu Ma

The Segment Anything Model (SAM) has demonstrated strong and versatile
segmentation capabilities, along with intuitive prompt-based interactions.
However, customizing SAM for medical image segmentation requires massive
amounts of pixel-level annotations and precise point- or box-based prompt
designs. To address these challenges, we introduce PGP-SAM, a novel
prototype-based few-shot tuning approach that uses limited samples to replace
tedious manual prompts. Our key idea is to leverage inter- and intra-class
prototypes to capture class-specific knowledge and relationships. We propose
two main components: (1) a plug-and-play contextual modulation module that
integrates multi-scale information, and (2) a class-guided cross-attention
mechanism that fuses prototypes and features for automatic prompt generation.
Experiments on a public multi-organ dataset and a private ventricle dataset
demonstrate that PGP-SAM achieves superior mean Dice scores compared with
existing prompt-free SAM variants, while using only 10\% of the 2D slices.

æè¦ï¼åæ®µä»»ä½æ¨¡å (SAM) å·²å±ç¤ºåºå¼ºå¤§ä¸å¤åè½çåæ®µè½åï¼ä»¥åç´è§çåºäºæç¤ºçäº¤äºã
ç¶èï¼éå¯¹å»å­¦å½±ååæ®µå®å¶ SAM éè¦å¤§éåç´ çº§æ³¨éåç²¾ç¡®çåºäºç¹ææ¡çæç¤ºè®¾è®¡ãä¸ºäºåºå¯¹è¿äºææï¼æä»¬å¼å¥äº PGP-SAMï¼ä¸ç§æ°é¢çåºäºååçå°ééå¤´å¾®è°æ¹æ³ï¼å®ä½¿ç¨æéçæ ·æ¬æ¥æ¿æ¢ç¹ççæå¨æç¤ºãæä»¬çå³é®ææ³æ¯å©ç¨ç±»é´åç±»åååæ¥ææç¹å®äºç±»çç¥è¯åå³ç³»ãæä»¬æåºäºä¸¤ä¸ªä¸»è¦ç»ä»¶ï¼(1) ä¸ä¸ªå³æå³ç¨çä¸ä¸æè°å¶æ¨¡åï¼å®éæäºå¤å°ºåº¦ä¿¡æ¯ï¼ä»¥å (2) ä¸ä¸ªç±»æå¯¼çäº¤åæ³¨ææºå¶ï¼å®èåäºåååç¹å¾ä»¥è¿è¡èªå¨æç¤ºçæãå¨å¬å±å¤å¨å®æ°æ®éåç§äººå¿å®¤æ°æ®éä¸çå®éªè¡¨æï¼PGP-SAM ä¸ç°æçæ æç¤º SAM åä½ç¸æ¯å®ç°äºåè¶çå¹³å Dice åæ°ï¼åæ¶ä»ä½¿ç¨äº 2D åçç 10%ã

##### **Imbalanced Medical Image Segmentation with Pixel-dependent Noisy Labels**
2501.06678v1 by Erjian Guo, Zicheng Wang, Zhen Zhao, Luping Zhou

Accurate medical image segmentation is often hindered by noisy labels in
training data, due to the challenges of annotating medical images. Prior
research works addressing noisy labels tend to make class-dependent
assumptions, overlooking the pixel-dependent nature of most noisy labels.
Furthermore, existing methods typically apply fixed thresholds to filter out
noisy labels, risking the removal of minority classes and consequently
degrading segmentation performance. To bridge these gaps, our proposed
framework, Collaborative Learning with Curriculum Selection (CLCS), addresses
pixel-dependent noisy labels with class imbalance. CLCS advances the existing
works by i) treating noisy labels as pixel-dependent and addressing them
through a collaborative learning framework, and ii) employing a curriculum
dynamic thresholding approach adapting to model learning progress to select
clean data samples to mitigate the class imbalance issue, and iii) applying a
noise balance loss to noisy data samples to improve data utilization instead of
discarding them outright. Specifically, our CLCS contains two modules:
Curriculum Noisy Label Sample Selection (CNS) and Noise Balance Loss (NBL). In
the CNS module, we designed a two-branch network with discrepancy loss for
collaborative learning so that different feature representations of the same
instance could be extracted from distinct views and used to vote the class
probabilities of pixels. Besides, a curriculum dynamic threshold is adopted to
select clean-label samples through probability voting. In the NBL module,
instead of directly dropping the suspiciously noisy labels, we further adopt a
robust loss to leverage such instances to boost the performance.

æè¦ï¼<paragraph>åç¡®çå»å­¦å½±ååå²éå¸¸ä¼åå°è®­ç»æ°æ®ä¸­æ ç­¾æåªå£°çé»ç¢ï¼è¿æ¯å ä¸ºå¯¹å»å­¦å½±åè¿è¡æ³¨éå·ææææ§ãè§£å³æ ç­¾æåªå£°çååç ç©¶å·¥ä½å¾åäºååºç±»ç¸å³çåè®¾ï¼èå¿½ç¥äºå¤§å¤æ°æ ç­¾æåªå£°çåç´ ç¸å³æ§è´¨ãæ­¤å¤ï¼ç°ææ¹æ³éå¸¸åºç¨åºå®éå¼æ¥è¿æ»¤ææ ç­¾æåªå£°ï¼è¿æå°å°æ°ç±»å«çæ ç­¾ç§»é¤çé£é©ï¼ä»èéä½åå²æ§è½ãä¸ºäºå¼¥åè¿äºå·®è·ï¼æä»¬æåºçæ¡æ¶ï¼å³å·æè¯¾ç¨éæ©çåä½å­¦ä¹  (CLCS)ï¼è§£å³äºç±»å«ä¸å¹³è¡¡çåç´ ç¸å³æ ç­¾æåªå£°çé®é¢ãCLCS éè¿ä»¥ä¸æ¹å¼æåäºç°æå·¥ä½ï¼i) å°æ ç­¾æåªå£°è§ä¸ºåç´ ç¸å³ï¼å¹¶éè¿åä½å­¦ä¹ æ¡æ¶è§£å³å®ä»¬ï¼ii) éç¨è¯¾ç¨å¨æéå¼åæ¹æ³ï¼éåºæ¨¡åå­¦ä¹ è¿åº¦ï¼éæ©å¹²åçæ°æ®æ ·æ¬ä»¥åè½»ç±»å«ä¸å¹³è¡¡é®é¢ï¼ä»¥å iii) å¯¹æ ç­¾æåªå£°çæ°æ®æ ·æ¬åºç¨åªå£°å¹³è¡¡æå¤±ï¼ä»¥æé«æ°æ®å©ç¨çï¼èä¸æ¯ç´æ¥ä¸¢å¼å®ä»¬ãå·ä½èè¨ï¼æä»¬ç CLCS åå«ä¸¤ä¸ªæ¨¡åï¼è¯¾ç¨æ ç­¾æåªå£°æ ·æ¬éæ© (CNS) ååªå£°å¹³è¡¡æå¤± (NBL)ãå¨ CNS æ¨¡åä¸­ï¼æä»¬è®¾è®¡äºä¸ä¸ªå·æå·®å¼æå¤±çä¸¤åæ¯ç½ç»ï¼ç¨äºåä½å­¦ä¹ ï¼ä»¥ä¾¿å¯ä»¥ä»ä¸åçè§å¾ä¸­æååä¸å®ä¾çä¸åç¹å¾è¡¨ç¤ºï¼å¹¶ç¨äºæç¥¨åç´ çç±»å«æ¦çãæ­¤å¤ï¼éç¨è¯¾ç¨å¨æéå¼éè¿æ¦çæç¥¨éæ©å¹²åæ ç­¾æ ·æ¬ãå¨ NBL æ¨¡åä¸­ï¼æä»¬æ²¡æç´æ¥ä¸¢å¼å¯ççæ ç­¾æåªå£°ï¼èæ¯è¿ä¸æ­¥éç¨é²æ£æå¤±æ¥å©ç¨æ­¤ç±»å®ä¾ä»¥æåæ§è½ã</paragraph>

##### **MedCT: A Clinical Terminology Graph for Generative AI Applications in Healthcare**
2501.06465v2 by Ye Chen, Dongdong Huang, Haoyun Xu, Cong Fu, Lin Sheng, Qingli Zhou, Yuqiang Shen, Kai Wang

We introduce the world's first clinical terminology for the Chinese
healthcare community, namely MedCT, accompanied by a clinical foundation model
MedBERT and an entity linking model MedLink. The MedCT system enables
standardized and programmable representation of Chinese clinical data,
successively stimulating the development of new medicines, treatment pathways,
and better patient outcomes for the populous Chinese community. Moreover, the
MedCT knowledge graph provides a principled mechanism to minimize the
hallucination problem of large language models (LLMs), therefore achieving
significant levels of accuracy and safety in LLM-based clinical applications.
By leveraging the LLMs' emergent capabilities of generativeness and
expressiveness, we were able to rapidly built a production-quality terminology
system and deployed to real-world clinical field within three months, while
classical terminologies like SNOMED CT have gone through more than twenty years
development. Our experiments show that the MedCT system achieves
state-of-the-art (SOTA) performance in semantic matching and entity linking
tasks, not only for Chinese but also for English. We also conducted a
longitudinal field experiment by applying MedCT and LLMs in a representative
spectrum of clinical tasks, including electronic health record (EHR)
auto-generation and medical document search for diagnostic decision making. Our
study shows a multitude of values of MedCT for clinical workflows and patient
outcomes, especially in the new genre of clinical LLM applications. We present
our approach in sufficient engineering detail, such that implementing a
clinical terminology for other non-English societies should be readily
reproducible. We openly release our terminology, models and algorithms, along
with real-world clinical datasets for the development.

æè¦ï¼<paragraph>æåçºä¸­æé«çç¤¾ç¾¤å¼å¥äºå¨çé¦åµçè¨åºè¡èªï¼å³ MedCTï¼ä¸¦éå¸¶è¨åºåºç¤æ¨¡å MedBERT åå¯¦é«é£çµæ¨¡å MedLinkãMedCT ç³»çµ±è½æ¨æºåä¸¦ä»¥ç¨å¼è¨­è¨æ¹å¼åç¾ä¸­æè¨åºè³æï¼é²èåºæ¿æ°è¥ãæ²»çéå¾çéç¼ï¼ä¸¦çºäººå£ç¾å¤çè¯äººç¤¾ç¾¤å¸¶ä¾æ´å¥½ççäººæ²»çææãæ­¤å¤ï¼MedCT ç¥è­åè­æä¾ä¸åæååçæ©å¶ï¼ä»¥æå°åå¤§åèªè¨æ¨¡å (LLM) çå¹»è¦ºåé¡ï¼å æ­¤å¨åºæ¼ LLM çè¨åºæç¨ä¸­éå°äºé¡¯èçæºç¢ºæ§åå®å¨æ§ãééå©ç¨ LLM çæåè¡¨éè½åçæ°èåè½ï¼æåå¾ä»¥å¿«éå»ºç½®ä¸åçç¢åè³ªçè¡èªç³»çµ±ï¼ä¸¦å¨ä¸åæå§é¨ç½²å°å¯¦éè¨åºé åï¼èå SNOMED CT éæ¨£çå³çµ±è¡èªç³»çµ±åç¶æ­·äºäºåå¤å¹´çéç¼ãæåçå¯¦é©é¡¯ç¤ºï¼MedCT ç³»çµ±å¨èªç¾©å¹éåå¯¦é«é£çµä»»åä¸­éå°äºæåé² (SOTA) çæè½ï¼ä¸åªé©ç¨æ¼ä¸­æï¼ä¹é©ç¨æ¼è±æãæåéééå¨å·ä»£è¡¨æ§çè¨åºä»»åä¸­æç¨ MedCT å LLM ä¾é²è¡ç¸±åå¯¦å°å¯¦é©ï¼åæ¬é»å­å¥åº·ç´é (EHR) èªåç¢çåç¨æ¼è¨ºæ·æ±ºç­çé«çæä»¶æå°ãæåçç ç©¶é¡¯ç¤º MedCT å°è¨åºå·¥ä½æµç¨åçäººæ²»çæææè¨±å¤å¹å¼ï¼ç¹å¥æ¯å¨æ°åæçè¨åº LLM æç¨ä¸­ãæåä»¥ååçå·¥ç¨ç´°ç¯èªªæäºæåçåæ³ï¼å æ­¤å¯¦ä½å¶ä»éè±èªç¤¾æçè¨åºè¡èªæææ¼è¤è£½ãæåéæ¾éåºæåçè¡èªãæ¨¡ååæ¼ç®æ³ï¼ä»¥åç¨æ¼éç¼çå¯¦éè¨åºè³æéã</paragraph>

##### **Deep Learning on Hester Davis Scores for Inpatient Fall Prediction**
2501.06432v1 by Hojjat Salehinejad, Ricky Rojas, Kingsley Iheasirim, Mohammed Yousufuddin, Bijan Borah

Fall risk prediction among hospitalized patients is a critical aspect of
patient safety in clinical settings, and accurate models can help prevent
adverse events. The Hester Davis Score (HDS) is commonly used to assess fall
risk, with current clinical practice relying on a threshold-based approach. In
this method, a patient is classified as high-risk when their HDS exceeds a
predefined threshold. However, this approach may fail to capture dynamic
patterns in fall risk over time. In this study, we model the threshold-based
approach and propose two machine learning approaches for enhanced fall
prediction: One-step ahead fall prediction and sequence-to-point fall
prediction. The one-step ahead model uses the HDS at the current timestamp to
predict the risk at the next timestamp, while the sequence-to-point model
leverages all preceding HDS values to predict fall risk using deep learning. We
compare these approaches to assess their accuracy in fall risk prediction,
demonstrating that deep learning can outperform the traditional threshold-based
method by capturing temporal patterns and improving prediction reliability.
These findings highlight the potential for data-driven approaches to enhance
patient safety through more reliable fall prevention strategies.

æè¦ï¼ä½é¢æ£èçè·åé¢¨éªé æ¸¬æ¯è¨åºç°å¢ä¸­æ£èå®å¨çéè¦é¢åï¼ç²¾ç¢ºçæ¨¡åæå©æ¼é é²ä¸è¯äºä»¶ãHester Davis è©å (HDS) å¸¸ç¨æ¼è©ä¼°è·åé¢¨éªï¼ç®åçè¨åºå¯¦åä¾è³´æ¼åºæ¼é¾å¼çè©ä¼°æ¹å¼ãå¨æ­¤æ¹æ³ä¸­ï¼ç¶æ£èç HDS è¶éé åå®ç¾©çé¾å¼æï¼æå°å¶æ­¸é¡çºé«é¢¨éªãç¶èï¼æ­¤æ¹æ³å¯è½ç¡æ³ææé¨èæéæ¨ç§»èç¢ççåæè·åé¢¨éªæ¨¡å¼ãå¨æ¬ç ç©¶ä¸­ï¼æåå°åºæ¼é¾å¼çè©ä¼°æ¹å¼é²è¡å»ºæ¨¡ï¼ä¸¦æåºå©ç¨®æ©å¨å­¸ç¿è©ä¼°æ¹å¼ä»¥å å¼·è·åé æ¸¬ï¼å®æ­¥åç»è·åé æ¸¬ååºåå°é»è·åé æ¸¬ãå®æ­¥åç»æ¨¡åä½¿ç¨ç¶åæéæ³è¨ç HDS é æ¸¬ä¸ä¸åæéæ³è¨çé¢¨éªï¼èåºåå°é»æ¨¡ååå©ç¨ææåä¸å HDS å¼ä½¿ç¨æ·±åº¦å­¸ç¿ä¾é æ¸¬è·åé¢¨éªãæåæ¯è¼éäºè©ä¼°æ¹å¼ä»¥è©ä¼°å¶å¨è·åé¢¨éªé æ¸¬ä¸­çæºç¢ºæ§ï¼è­ææ·±åº¦å­¸ç¿å¯ä»¥ééæææéæ¨¡å¼åæåé æ¸¬å¯é æ§ï¼åªæ¼å³çµ±çåºæ¼é¾å¼çè©ä¼°æ¹å¼ãéäºç¼ç¾å¼·èª¿äºè³æé©åè©ä¼°æ¹å¼å¨ééæ´å¯é çè·åé é²ç­ç¥ä¾å å¼·æ£èå®å¨æ¹é¢çæ½åã

##### **Gender-Neutral Large Language Models for Medical Applications: Reducing Bias in PubMed Abstracts**
2501.06365v1 by Elizabeth Schaefer, Kirk Roberts

This paper presents a pipeline for mitigating gender bias in large language
models (LLMs) used in medical literature by neutralizing gendered occupational
pronouns. A dataset of 379,000 PubMed abstracts from 1965-1980 was processed to
identify and modify pronouns tied to professions. We developed a BERT-based
model, ``Modern Occupational Bias Elimination with Refined Training,'' or
``MOBERT,'' trained on these neutralized abstracts, and compared its
performance with ``1965Bert,'' trained on the original dataset. MOBERT achieved
a 70\% inclusive replacement rate, while 1965Bert reached only 4\%. A further
analysis of MOBERT revealed that pronoun replacement accuracy correlated with
the frequency of occupational terms in the training data. We propose expanding
the dataset and refining the pipeline to improve performance and ensure more
equitable language modeling in medical applications.

æè¦ï¼æ¬ææåºäºä¸åç®¡éï¼ç¨æ¼ç·©è§£å¤§åèªè¨æ¨¡å (LLM) ä¸­çæ§å¥åè¦ï¼éäºæ¨¡åééä¸­åæ§å¥è·æ¥­ä»£åè©ï¼ç¨æ¼é«å­¸æç»ä¸­ãæåèçäº 1965 å¹´è³ 1980 å¹´é 379,000 ç¯ PubMed ææçè³æéï¼ä»¥è­å¥åä¿®æ¹èè·æ¥­ç¸éçä»£åè©ãæåéç¼äºä¸å BERT-based æ¨¡åï¼ç¨±çºãæ¡ç¨ç²¾ç·»è¨ç·´çç¾ä»£è·æ¥­åè¦æ¶é¤ãæãMOBERTãï¼ä¸¦å¨éäºä¸­åçææä¸é²è¡è¨ç·´ï¼ä¸¦å°å¶æè½èå¨åå§è³æéä¸è¨ç·´çã1965Bertãé²è¡æ¯è¼ãMOBERT éå°äº 70% çåå®¹æ§æ¿æçï¼è 1965Bert åéå° 4%ãé²ä¸æ­¥åæ MOBERT é¡¯ç¤ºï¼ä»£åè©æ¿æçæºç¢ºæ§èè¨ç·´è³æä¸­è·æ¥­è¡èªçé »çç¸éãæåå»ºè­°æ´åè³æéä¸¦ç²¾ç·»åç®¡éï¼ä»¥æåæè½ä¸¦ç¢ºä¿å¨é«å­¸æç¨ä¸­é²è¡æ´å¬å¹³çèªè¨å»ºæ¨¡ã

##### **Scale-up Unlearnable Examples Learning with High-Performance Computing**
2501.06080v1 by Yanfan Zhu, Issac Lyngaas, Murali Gopalakrishnan Meena, Mary Ellen I. Koran, Bradley Malin, Daniel Moyer, Shunxing Bao, Anuj Kapadia, Xiao Wang, Bennett Landman, Yuankai Huo

Recent advancements in AI models are structured to retain user interactions,
which could inadvertently include sensitive healthcare data. In the healthcare
field, particularly when radiologists use AI-driven diagnostic tools hosted on
online platforms, there is a risk that medical imaging data may be repurposed
for future AI training without explicit consent, spotlighting critical privacy
and intellectual property concerns around healthcare data usage. Addressing
these privacy challenges, a novel approach known as Unlearnable Examples (UEs)
has been introduced, aiming to make data unlearnable to deep learning models. A
prominent method within this area, called Unlearnable Clustering (UC), has
shown improved UE performance with larger batch sizes but was previously
limited by computational resources. To push the boundaries of UE performance
with theoretically unlimited resources, we scaled up UC learning across various
datasets using Distributed Data Parallel (DDP) training on the Summit
supercomputer. Our goal was to examine UE efficacy at high-performance
computing (HPC) levels to prevent unauthorized learning and enhance data
security, particularly exploring the impact of batch size on UE's
unlearnability. Utilizing the robust computational capabilities of the Summit,
extensive experiments were conducted on diverse datasets such as Pets,
MedMNist, Flowers, and Flowers102. Our findings reveal that both overly large
and overly small batch sizes can lead to performance instability and affect
accuracy. However, the relationship between batch size and unlearnability
varied across datasets, highlighting the necessity for tailored batch size
strategies to achieve optimal data protection. Our results underscore the
critical role of selecting appropriate batch sizes based on the specific
characteristics of each dataset to prevent learning and ensure data security in
deep learning applications.

æè¦ï¼<paragraph>æè¿å¨ AI æ¨¡åä¸­çé²å±è¢«å»ºæ§çºä¿çä½¿ç¨èäºåï¼
éå¯è½ç¡æéåå«ææçé«çä¿å¥è³æãå¨é«çä¿å¥
é åï¼ç¹å¥æ¯ç¶æ¾å°ç§é«å¸«ä½¿ç¨ç·ä¸å¹³å°ä¸æä¾ç AI é©åè¨ºæ·å·¥å·æï¼æé¢¨éªæ¯é«çå½±åè³æå¯è½æè¢«éæ°ç¨æ¼æªä¾ç AI è¨ç·´ï¼èæªç¶æç¢ºåæï¼éçªé¡¯äºèé«çä¿å¥è³æä½¿ç¨ç¸éçé±ç§åæºæ§è²¡ç¢æ¬åé¡ãçºäºæå°
éäºé±ç§ææ°ï¼å·²å°å¥ä¸ç¨®ç¨±çºä¸å¯å­¸ç¿ç¯ä¾ (UE) çæ°æ¹æ³ï¼æ¨å¨è®è³æå°æ·±åº¦å­¸ç¿æ¨¡åä¸å¯å­¸ç¿ãéåé åå§ä¸ç¨®èåçç¨±çºä¸å¯å­¸ç¿èé¡ (UC) çæ¹æ³ï¼å·²é¡¯ç¤ºåºå¨è¼å¤§çæ¹æ¬¡å¤§å°ä¸ææ¹åç UE æè½ï¼ä½åååå°éç®è³æºçéå¶ãçºäºå¨çè«ä¸ç¡éå¶è³æºçææ³ä¸æ¨å UE æè½ççç·ï¼æåå¨ Summit è¶ç´é»è¦ä¸ä½¿ç¨åæ£å¼è³æå¹³è¡ (DDP) è¨ç·´ï¼æ´å¤§äºåç¨®è³æéç UC å­¸ç¿ãæåçç®æ¨æ¯æª¢æ¥ UE å¨é«æè½éç® (HPC) å±¤ç´çæè½ï¼ä»¥é²æ­¢æªç¶ææ¬çå­¸ç¿ï¼ä¸¦å¢å¼·è³æå®å¨æ§ï¼ç¹å¥æ¯æ¢è¨æ¹æ¬¡å¤§å°å° UE ä¸å¯å­¸ç¿æ§çå½±é¿ãå©ç¨ Summit å¼·å¤§çéç®è½åï¼å¨åç¨®è³æéä¸é²è¡äºå»£æ³çå¯¦é©ï¼ä¾å¦ PetsãMedMNistãFlowers å Flowers102ãæåçç ç©¶çµæé¡¯ç¤ºï¼éå¤§æéå°çæ¹æ¬¡å¤§å°é½å¯è½å°è´æè½ä¸ç©©å®ï¼ä¸¦å½±é¿æºç¢ºåº¦ãç¶èï¼æ¹æ¬¡å¤§å°èä¸å¯å­¸ç¿æ§ä¹éçéä¿å¨ååè³æéä¹éææä¸åï¼éçªé¡¯äºæ ¹æç¹å®è³æéçç¹å¾µéèº«æé æ¹æ¬¡å¤§å°ç­ç¥ä»¥éææä½³è³æä¿è­·çå¿è¦æ§ãæåççµæå¼·èª¿äºæ ¹ææ¯åè³æéçç¹å®ç¹å¾µé¸æé©ç¶æ¹æ¬¡å¤§å°ä»¥é²æ­¢å­¸ç¿ï¼ä¸¦ç¢ºä¿æ·±åº¦å­¸ç¿æç¨ç¨å¼ä¸­è³æå®å¨æ§çééµä½ç¨ã</paragraph>

##### **AI-powered virtual tissues from spatial proteomics for clinical diagnostics and biomedical discovery**
2501.06039v1 by Johann Wenckstern, Eeshaan Jain, Kiril Vasilev, Matteo Pariset, Andreas Wicki, Gabriele Gut, Charlotte Bunne

Spatial proteomics technologies have transformed our understanding of complex
tissue architectures by enabling simultaneous analysis of multiple molecular
markers and their spatial organization. The high dimensionality of these data,
varying marker combinations across experiments and heterogeneous study designs
pose unique challenges for computational analysis. Here, we present Virtual
Tissues (VirTues), a foundation model framework for biological tissues that
operates across the molecular, cellular and tissue scale. VirTues introduces
innovations in transformer architecture design, including a novel tokenization
scheme that captures both spatial and marker dimensions, and attention
mechanisms that scale to high-dimensional multiplex data while maintaining
interpretability. Trained on diverse cancer and non-cancer tissue datasets,
VirTues demonstrates strong generalization capabilities without task-specific
fine-tuning, enabling cross-study analysis and novel marker integration. As a
generalist model, VirTues outperforms existing approaches across clinical
diagnostics, biological discovery and patient case retrieval tasks, while
providing insights into tissue function and disease mechanisms.

æè¦ï¼ç©ºéèç½è³ªçµå­¸æè¡ééåæåæå¤ååå­æ¨è¨åå¶ç©ºéçµç¹ï¼è½è®äºæåå°è¤éçµç¹çµæ§ççè§£ãéäºæ¸æçé«ç¶­åº¦ãå¯¦é©ä¸­ä¸åçæ¨è¨çµååç°è³ªçç ç©¶è¨­è¨ï¼å°è¨ç®åææ§æäºç¨ç¹çææ°ãå¨æ­¤ï¼æåæåºèæ¬çµç¹ (VirTues)ï¼ä¸åé©ç¨æ¼åå­ãç´°èåçµç¹å±¤ç´ççç©çµç¹åºç¤æ¨¡åæ¶æ§ãVirTues å¨Transformeræ¶æ§è¨­è¨ä¸­å¼é²åµæ°ï¼åæ¬ä¸ç¨®æ°çæ¨è¨åæ¶æ§ï¼å®ææç©ºéåæ¨è¨ç¶­åº¦ï¼ä»¥åå¨ç¶­æå¯è§£éæ§çåææ´å±å°é«ç¶­åº¦å¤éæ¸æçæ³¨æåæ©å¶ãVirTues å¨å¤æ¨£åçççåéçççµç¹æ¸æéä¸è¨ç·´ï¼å±ç¤ºäºå¼·å¤§çæ³åè½åï¼ç¡éç¹å®ä»»åå¾®èª¿ï¼å¾èå¯¦ç¾è·¨ç ç©¶åæåæ°çæ¨è¨æ´åãä½çºä¸åéææ¨¡åï¼VirTues å¨è¨åºè¨ºæ·ãçç©ç¼ç¾åæ£èçä¾æª¢ç´¢ä»»åä¸­åªæ¼ç¾ææ¹æ³ï¼åææä¾äºçµç¹åè½åç¾çæ©å¶çè¦è§£ã

##### **DiffuSETS: 12-lead ECG Generation Conditioned on Clinical Text Reports and Patient-Specific Information**
2501.05932v1 by Yongfan Lai, Jiabo Chen, Deyun Zhang, Yue Wang, Shijia Geng, Hongyan Li, Shenda Hong

Heart disease remains a significant threat to human health. As a non-invasive
diagnostic tool, the electrocardiogram (ECG) is one of the most widely used
methods for cardiac screening. However, the scarcity of high-quality ECG data,
driven by privacy concerns and limited medical resources, creates a pressing
need for effective ECG signal generation. Existing approaches for generating
ECG signals typically rely on small training datasets, lack comprehensive
evaluation frameworks, and overlook potential applications beyond data
augmentation. To address these challenges, we propose DiffuSETS, a novel
framework capable of generating ECG signals with high semantic alignment and
fidelity. DiffuSETS accepts various modalities of clinical text reports and
patient-specific information as inputs, enabling the creation of clinically
meaningful ECG signals. Additionally, to address the lack of standardized
evaluation in ECG generation, we introduce a comprehensive benchmarking
methodology to assess the effectiveness of generative models in this domain.
Our model achieve excellent results in tests, proving its superiority in the
task of ECG generation. Furthermore, we showcase its potential to mitigate data
scarcity while exploring novel applications in cardiology education and medical
knowledge discovery, highlighting the broader impact of our work.

æè¦ï¼å¿èçä»ç¶æ¯äººç±»å¥åº·çä¸å¤§å¨èãä½ä¸ºä¸ç§éä¾µå¥æ§è¯æ­å·¥å·ï¼å¿çµå¾ (ECG) æ¯å¿èç­æ¥æå¹¿æ³ä½¿ç¨çæ¹æ³ä¹ä¸ãç¶èï¼ç±äºéç§é®é¢åå»çèµæºæéï¼é«è´¨é ECG æ°æ®çç¨ç¼ºå¯¹ææç ECG ä¿¡å·çææåºäºè¿«åéæ±ãç°æç¨äºçæ ECG ä¿¡å·çæ¹æ³éå¸¸ä¾èµäºå°åè®­ç»æ°æ®éï¼ç¼ºä¹å¨é¢çè¯ä¼°æ¡æ¶ï¼å¹¶ä¸å¿½è§äºæ°æ®å¢å¼ºä¹å¤çæ½å¨åºç¨ãä¸ºäºåºå¯¹è¿äºææï¼æä»¬æåºäº DiffuSETSï¼è¿æ¯ä¸ä¸ªè½å¤çæå·æé«åº¦è¯­ä¹å¯¹é½åä¿çåº¦ç ECG ä¿¡å·çæ°æ¡æ¶ãDiffuSETS æ¥ååç§å½¢å¼çä¸´åºææ¬æ¥ååæ£èç¹å®ä¿¡æ¯ä½ä¸ºè¾å¥ï¼ä»èè½å¤åå»ºå·æä¸´åºæä¹ç ECG ä¿¡å·ãæ­¤å¤ï¼ä¸ºäºè§£å³ ECG çæä¸­ç¼ºä¹æ ååè¯ä¼°çé®é¢ï¼æä»¬å¼å¥äºä¸ç§å¨é¢çåºåæµè¯æ¹æ³æ¥è¯ä¼°çææ¨¡åå¨æ­¤é¢åçæææ§ãæä»¬çæ¨¡åå¨æµè¯ä¸­åå¾äºä¼å¼çææï¼è¯æäºå¶å¨ ECG çæä»»å¡ä¸­çä¼è¶æ§ãæ­¤å¤ï¼æä»¬å±ç¤ºäºå¶å¨ç¼è§£æ°æ®ç¨ç¼ºçåæ¶å¨å¿èçå­¦æè²åå»å­¦ç¥è¯åç°ä¸­æ¢ç´¢æ°åºç¨çæ½åï¼çªåºäºæä»¬å·¥ä½çæ´å¹¿æ³å½±åã

##### **AI-Driven Diabetic Retinopathy Screening: Multicentric Validation of AIDRSS in India**
2501.05826v2 by Amit Kr Dey, Pradeep Walia, Girish Somvanshi, Abrar Ali, Sagarnil Das, Pallabi Paul, Minakhi Ghosh

Purpose: Diabetic retinopathy (DR) is a major cause of vision loss,
particularly in India, where access to retina specialists is limited in rural
areas. This study aims to evaluate the Artificial Intelligence-based Diabetic
Retinopathy Screening System (AIDRSS) for DR detection and prevalence
assessment, addressing the growing need for scalable, automated screening
solutions in resource-limited settings.
  Approach: A multicentric, cross-sectional study was conducted in Kolkata,
India, involving 5,029 participants and 10,058 macula-centric retinal fundus
images. The AIDRSS employed a deep learning algorithm with 50 million trainable
parameters, integrated with Contrast Limited Adaptive Histogram Equalization
(CLAHE) preprocessing for enhanced image quality. DR was graded using the
International Clinical Diabetic Retinopathy (ICDR) Scale, categorizing disease
into five stages (DR0 to DR4). Statistical metrics including sensitivity,
specificity, and prevalence rates were evaluated against expert retina
specialist assessments.
  Results: The prevalence of DR in the general population was 13.7%, rising to
38.2% among individuals with elevated random blood glucose levels. The AIDRSS
achieved an overall sensitivity of 92%, specificity of 88%, and 100%
sensitivity for detecting referable DR (DR3 and DR4). These results demonstrate
the system's robust performance in accurately identifying and grading DR in a
diverse population.
  Conclusions: AIDRSS provides a reliable, scalable solution for early DR
detection in resource-constrained environments. Its integration of advanced AI
techniques ensures high diagnostic accuracy, with potential to significantly
reduce the burden of diabetes-related vision loss in underserved regions.

æè¦ï¼<paragraph>ç®çï¼ç³å°¿çè§ç½èçå (DR) æ¯è§åä¸§å¤±çä¸»è¦åå ï¼ç¹å«æ¯å¨å°åº¦ï¼é£éçåæå°åºç¼ç§ä¸å®¶æ°éæéãæ¬ç ç©¶æ¨å¨è¯ä¼°åºäºäººå·¥æºè½çç³å°¿çè§ç½èçåç­æ¥ç³»ç» (AIDRSS) ç DR æ£æµåæµè¡æåµè¯ä¼°ï¼ä»¥æ»¡è¶³èµæºæéçç¯å¢ä¸­å¯¹å¯æ©å±èªå¨åç­æ¥è§£å³æ¹æ¡ä¸æ­å¢é¿çéæ±ã
æ¹æ³ï¼å¨å°åº¦å å°åç­è¿è¡äºä¸é¡¹å¤ä¸­å¿æ¨ªæ­é¢ç ç©¶ï¼æ¶å 5,029 ååä¸èå 10,058 å¼ é»æä¸­å¿è§ç½èç¼åºå¾åãAIDRSS éç¨äºä¸ä¸ªæ·±åº¦å­¦ä¹ ç®æ³ï¼å·æ 5000 ä¸ä¸ªå¯è®­ç»åæ°ï¼å¹¶éæäºå¯¹æ¯åº¦éå¶èªéåºç´æ¹å¾åè¡¡å (CLAHE) é¢å¤çï¼ä»¥æé«å¾åè´¨éãDR ä½¿ç¨å½éä¸´åºç³å°¿çè§ç½èçå (ICDR) éè¡¨è¿è¡åçº§ï¼å°ç¾çåä¸ºäºä¸ªé¶æ®µï¼DR0 è³ DR4ï¼ãéå¯¹ä¸å®¶è§ç½èä¸å®¶è¯ä¼°ï¼è¯ä¼°äºåæ¬æææ§ãç¹å¼æ§åæ£ççå¨åçç»è®¡ææ ã
ç»æï¼ä¸è¬äººç¾¤ä¸­ DR çæ£ççä¸º 13.7%ï¼å¨éæºè¡ç³æ°´å¹³åé«çä¸ªä½ä¸­ä¸åè³ 38.2%ãAIDRSS çæ»ä½æææ§è¾¾å° 92%ï¼ç¹å¼æ§è¾¾å° 88%ï¼æ£æµå¯è½¬è¯ DRï¼DR3 å DR4ï¼çæææ§è¾¾å° 100%ãè¿äºç»æè¡¨æè¯¥ç³»ç»å¨åç¡®è¯å«ååçº§ä¸åäººç¾¤ä¸­ç DR æ¹é¢å·æå¼ºå¤§çæ§è½ã
ç»è®ºï¼AIDRSS ä¸ºèµæºåéç¯å¢ä¸­çæ©æ DR æ£æµæä¾äºä¸ç§å¯é ä¸å¯æ©å±çè§£å³æ¹æ¡ãå®éæäºåè¿çäººå·¥æºè½ææ¯ï¼ç¡®ä¿äºè¾é«çè¯æ­åç¡®æ§ï¼æå¯è½æ¾èåå°æå¡ä¸è¶³å°åºä¸ç³å°¿çç¸å³çè§åä¸§å¤±è´æã</paragraph>

##### **Large Language Models for Bioinformatics**
2501.06271v1 by Wei Ruan, Yanjun Lyu, Jing Zhang, Jiazhang Cai, Peng Shu, Yang Ge, Yao Lu, Shang Gao, Yue Wang, Peilong Wang, Lin Zhao, Tao Wang, Yufang Liu, Luyang Fang, Ziyu Liu, Zhengliang Liu, Yiwei Li, Zihao Wu, Junhao Chen, Hanqi Jiang, Yi Pan, Zhenyuan Yang, Jingyuan Chen, Shizhe Liang, Wei Zhang, Terry Ma, Yuan Dou, Jianli Zhang, Xinyu Gong, Qi Gan, Yusong Zou, Zebang Chen, Yuanxin Qian, Shuo Yu, Jin Lu, Kenan Song, Xianqiao Wang, Andrea Sikora, Gang Li, Xiang Li, Quanzheng Li, Yingfeng Wang, Lu Zhang, Yohannes Abate, Lifang He, Wenxuan Zhong, Rongjie Liu, Chao Huang, Wei Liu, Ye Shen, Ping Ma, Hongtu Zhu, Yajun Yan, Dajiang Zhu, Tianming Liu

With the rapid advancements in large language model (LLM) technology and the
emergence of bioinformatics-specific language models (BioLMs), there is a
growing need for a comprehensive analysis of the current landscape,
computational characteristics, and diverse applications. This survey aims to
address this need by providing a thorough review of BioLMs, focusing on their
evolution, classification, and distinguishing features, alongside a detailed
examination of training methodologies, datasets, and evaluation frameworks. We
explore the wide-ranging applications of BioLMs in critical areas such as
disease diagnosis, drug discovery, and vaccine development, highlighting their
impact and transformative potential in bioinformatics. We identify key
challenges and limitations inherent in BioLMs, including data privacy and
security concerns, interpretability issues, biases in training data and model
outputs, and domain adaptation complexities. Finally, we highlight emerging
trends and future directions, offering valuable insights to guide researchers
and clinicians toward advancing BioLMs for increasingly sophisticated
biological and clinical applications.

æè¦ï¼é¨èå¤§åèªè¨æ¨¡åï¼LLMï¼æè¡çå¿«éé²å±åçç©è³è¨å­¸ç¹å®èªè¨æ¨¡åï¼BioLMï¼çåºç¾ï¼å°æ¼ç¶åæå¢ãè¨ç®ç¹å¾µåå¤åæç¨é²è¡å¨é¢åæçéæ±æ¥çå¢å ãæ¬èª¿æ¥æ¨å¨ééæä¾å° BioLM çå¨é¢æª¢è¦ï¼èéæ¼å¶æ¼é²ãåé¡ååå¥ç¹å¾µï¼ä»¥åå°è¨ç·´æ¹æ³ãè³æéåè©ä¼°æ¶æ§çè©³ç´°æ¢è¨ï¼ä¾æ»¿è¶³æ­¤éæ±ãæåæ¢è¨ BioLM å¨ç¾çè¨ºæ·ãè¥ç©ç¼ç¾åç«èéç¼ç­ééµé åçå»£æ³æç¨ï¼å¼·èª¿å¶å¨çç©è³è¨å­¸ä¸­çå½±é¿åè½åæ½åãæåæ¾åº BioLM åºæçééµææ°åéå¶ï¼åæ¬è³æé±ç§åå®å¨æ§åé¡ãå¯è§£éæ§åé¡ãè¨ç·´è³æåæ¨¡åè¼¸åºçåå·®ï¼ä»¥åé åé©æçè¤éæ§ãæå¾ï¼æåéé»ä»ç´¹æ°èè¶¨å¢åæªä¾æ¹åï¼æä¾æå¹å¼çè¦è§£ï¼ä»¥æå°ç ç©¶äººå¡åè¨åºé«çå° BioLM æç¨æ¼æ¥çè¤éççç©åè¨åºæç¨ã

##### **From Simple to Complex Skills: The Case of In-Hand Object Reorientation**
2501.05439v1 by Haozhi Qi, Brent Yi, Mike Lambeta, Yi Ma, Roberto Calandra, Jitendra Malik

Learning policies in simulation and transferring them to the real world has
become a promising approach in dexterous manipulation. However, bridging the
sim-to-real gap for each new task requires substantial human effort, such as
careful reward engineering, hyperparameter tuning, and system identification.
In this work, we present a system that leverages low-level skills to address
these challenges for more complex tasks. Specifically, we introduce a
hierarchical policy for in-hand object reorientation based on previously
acquired rotation skills. This hierarchical policy learns to select which
low-level skill to execute based on feedback from both the environment and the
low-level skill policies themselves. Compared to learning from scratch, the
hierarchical policy is more robust to out-of-distribution changes and transfers
easily from simulation to real-world environments. Additionally, we propose a
generalizable object pose estimator that uses proprioceptive information,
low-level skill predictions, and control errors as inputs to estimate the
object pose over time. We demonstrate that our system can reorient objects,
including symmetrical and textureless ones, to a desired pose.

æè¦ï¼å¨æ¨¡æ¬ä¸­å­¸ç¿ç­ç¥ä¸¦å°å¶è½ç§»å°ç¾å¯¦ä¸çå·²æçºéå·§æä½ä¸­ä¸ç¨®æåæ¯çæ¹æ³ãç¶èï¼å°æ¼æ¯é æ°ä»»åä¾èªªï¼å½åæ¨¡æ¬å°ç¾å¯¦çå·®è·éè¦å¤§éçäººåï¼ä¾å¦ä»ç´°ççåµå·¥ç¨ãè¶åæ¸èª¿æ´åç³»çµ±è­å¥ãå¨éé å·¥ä½ä¸­ï¼æåæåºäºä¸åå©ç¨ä½å±¤æè½ä¾æå°æ´è¤éä»»åçææ°çç³»çµ±ãå·é«ä¾èªªï¼æåå¼å¥äºä¸ååºæ¼ååç²å¾çæè½æè½çæä¸­ç©é«éæ°å®åçåå±¤ç­ç¥ãéç¨®åå±¤ç­ç¥å­¸ç¿æ ¹æç°å¢åä½å±¤æè½ç­ç¥æ¬èº«çåé¥é¸æå·è¡åªç¨®ä½å±¤æè½ãèå¾é ­éå§å­¸ç¿ç¸æ¯ï¼åå±¤ç­ç¥å°åä½å¤è®åæ´å¼·å¥ï¼ä¸¦ä¸å¯ä»¥è¼é¬å°å¾æ¨¡æ¬è½ç§»å°ç¾å¯¦ä¸çç°å¢ãæ­¤å¤ï¼æåæåºäºä¸åå¯æ³åçç©é«å§¿å¢ä¼°è¨å¨ï¼å®ä½¿ç¨ proprioceptive ä¿¡æ¯ãä½å±¤æè½é æ¸¬åæ§å¶èª¤å·®ä½çºè¼¸å¥ä¾ä¼°è¨ç©é«å§¿å¢ãæåè­æäºæåçç³»çµ±å¯ä»¥å°ç©é«ï¼åæ¬å°ç¨±åç¡ç´ççç©é«ï¼éæ°å®åå°æéçå§¿å¢ã

##### **Strategy Masking: A Method for Guardrails in Value-based Reinforcement Learning Agents**
2501.05501v2 by Jonathan Keane, Sam Keyser, Jeremy Kedziora

The use of reward functions to structure AI learning and decision making is
core to the current reinforcement learning paradigm; however, without careful
design of reward functions, agents can learn to solve problems in ways that may
be considered "undesirable" or "unethical." Without thorough understanding of
the incentives a reward function creates, it can be difficult to impose
principled yet general control mechanisms over its behavior. In this paper, we
study methods for constructing guardrails for AI agents that use reward
functions to learn decision making. We introduce a novel approach, which we
call strategy masking, to explicitly learn and then suppress undesirable AI
agent behavior. We apply our method to study lying in AI agents and show that
it can be used to effectively modify agent behavior by suppressing lying
post-training without compromising agent ability to perform effectively.

æè¦ï¼ä½¿ç¨çåµå½æ¸ä¾å»ºæ§ AI å­¸ç¿åæ±ºç­å¶å®æ¯ç®åå¼·åå­¸ç¿ç¯ä¾çæ ¸å¿ï¼ç¶èï¼å¨æ²æä»ç´°è¨­è¨çåµå½æ¸çææ³ä¸ï¼ä»£çäººå¯è½æå­¸å°ä»¥å¯è½è¢«è¦çºãä¸åæ­¡è¿ãæãä¸éå¾·ãçæ¹å¼ä¾è§£æ±ºåé¡ãå¨æ²æå¾¹åºäºè§£çåµå½æ¸æåµé çèªå çææ³ä¸ï¼å¾é£å°å¶è¡çºæ½å æååä½åéç¨çæ§å¶æ©å¶ãå¨æ¬æä¸­ï¼æåç ç©¶äºçºä½¿ç¨çåµå½æ¸ä¾å­¸ç¿æ±ºç­å¶å®ç AI ä»£çå»ºç«è­·æ¬çæ¹æ³ãæåä»ç´¹äºä¸ç¨®æ°ç©çæ¹æ³ï¼æåç¨±ä¹çºç­ç¥é®ç½©ï¼ç¨æ¼æç¢ºå­¸ç¿ä¸¦æå¶ä¸åæ­¡è¿ç AI ä»£çè¡çºãæåå°æåçéç¨®æ¹æ³æç¨æ¼ç ç©¶ AI ä»£çä¸­çèªªè¬è¡çºï¼ä¸¦è¡¨æå®å¯ç¨æ¼ééå¨è¨ç·´å¾æå¶èªªè¬ä¾ææä¿®æ¹ä»£çè¡çºï¼åæä¸æå®³ä»£çææå·è¡çè½åã

##### **Atlas: A Novel Pathology Foundation Model by Mayo Clinic, CharitÃ©, and Aignostics**
2501.05409v2 by Maximilian Alber, Stephan Tietz, Jonas Dippel, Timo Milbich, TimothÃ©e Lesort, Panos Korfiatis, Moritz KrÃ¼gener, Beatriz Perez Cancer, Neelay Shah, Alexander MÃ¶llers, Philipp Seegerer, Alexandra Carpen-Amarie, Kai Standvoss, Gabriel Dernbach, Edwin de Jong, Simon Schallenberg, Andreas Kunft, Helmut Hoffer von Ankershoffen, Gavin Schaeferle, Patrick Duffy, Matt Redlon, Philipp Jurmeister, David Horst, Lukas Ruff, Klaus-Robert MÃ¼ller, Frederick Klauschen, Andrew Norgan

Recent advances in digital pathology have demonstrated the effectiveness of
foundation models across diverse applications. In this report, we present
Atlas, a novel vision foundation model based on the RudolfV approach. Our model
was trained on a dataset comprising 1.2 million histopathology whole slide
images, collected from two medical institutions: Mayo Clinic and Charit\'e -
Universt\"atsmedizin Berlin. Comprehensive evaluations show that Atlas achieves
state-of-the-art performance across twenty-one public benchmark datasets, even
though it is neither the largest model by parameter count nor by training
dataset size.

æè¦ï¼æè¿å¨æ¸ä½ççå­¸çé²å±å·²å±ç¾åºç¤æ¨¡åå¨åç¨®æç¨ä¸çæææ§ãå¨æ­¤å ±åä¸­ï¼æåæåº Atlasï¼ä¸ç¨®åºæ¼ RudolfV æ¹æ³çæ°ç©è¦è¦ºåºç¤æ¨¡åãæåçæ¨¡åè¨ç·´æ¼ä¸ååå« 120 è¬å¼µçµç¹ççå¨ç»çå½±åçè³æéï¼éäºå½±åæ¶éèªå©åé«çæ©æ§ï¼æ¢ç´è¨ºæåææå¤éç¹å¤§å­¸é«å­¸ä¸­å¿ãå¨é¢çè©ä¼°é¡¯ç¤ºï¼Atlas å¨ 21 åå¬éåºæºè³æéä¸éå°äºæåé²çæè½ï¼å³ä½¿å®æ¢ä¸æ¯åæ¸æ¸éæå¤§çæ¨¡åï¼ä¹ä¸æ¯è¨ç·´è³æéè¦æ¨¡æå¤§çæ¨¡åã

##### **An Algorithmic Approach for Causal Health Equity: A Look at Race Differentials in Intensive Care Unit (ICU) Outcomes**
2501.05197v1 by Drago Plecko, Paul Secombe, Andrea Clarke, Amelia Fiske, Samarra Toby, Donisha Duff, David Pilcher, Leo Anthony Celi, Rinaldo Bellomo, Elias Bareinboim

The new era of large-scale data collection and analysis presents an
opportunity for diagnosing and understanding the causes of health inequities.
In this study, we describe a framework for systematically analyzing health
disparities using causal inference. The framework is illustrated by
investigating racial and ethnic disparities in intensive care unit (ICU)
outcome between majority and minority groups in Australia (Indigenous vs.
Non-Indigenous) and the United States (African-American vs. White). We
demonstrate that commonly used statistical measures for quantifying inequity
are insufficient, and focus on attributing the observed disparity to the causal
mechanisms that generate it. We find that minority patients are younger at
admission, have worse chronic health, are more likely to be admitted for urgent
and non-elective reasons, and have higher illness severity. At the same time,
however, we find a protective direct effect of belonging to a minority group,
with minority patients showing improved survival compared to their majority
counterparts, with all other variables kept equal. We demonstrate that this
protective effect is related to the increased probability of being admitted to
ICU, with minority patients having an increased risk of ICU admission. We also
find that minority patients, while showing improved survival, are more likely
to be readmitted to ICU. Thus, due to worse access to primary health care,
minority patients are more likely to end up in ICU for preventable conditions,
causing a reduction in the mortality rates and creating an effect that appears
to be protective. Since the baseline risk of ICU admission may serve as proxy
for lack of access to primary care, we developed the Indigenous Intensive Care
Equity (IICE) Radar, a monitoring system for tracking the over-utilization of
ICU resources by the Indigenous population of Australia across geographical
areas.

æè¦ï¼å¤§åè³ææ¶éååæçæ°æä»£ï¼æä¾äºè¨ºæ·åäºè§£å¥åº·ä¸å¹³ç­æå çæ©æãå¨éé ç ç©¶ä¸­ï¼æåæè¿°äºä¸åä½¿ç¨å ææ¨è«ç³»çµ±åæå¥åº·å·®è·çæ¶æ§ãéåæ¶æ§ééèª¿æ¥æ¾³æ´²ï¼åä½æ°å°éåä½æ°ï¼åç¾åï¼éè£ç¾åäººå°ç½äººï¼ä¸­ï¼éçå è­·çæ¿ï¼ICUï¼çµæå¨ç¨®æåæç¾¤ä¸çå·®ç°ä¾å ä»¥èªªæãæåè­æäºéå¸¸ç¨æ¼éåä¸å¹³ç­ççµ±è¨æ¸¬éæ¯ä¸å¤ çï¼ä¸¦å°æ³¨æ¼å°è§å¯å°çå·®ç°æ­¸å æ¼ç¢çå®çå ææ©å¶ãæåç¼ç¾ï¼å°æ¸æè£æ£èå¨å¥é¢æè¼å¹´è¼ï¼æ¢æ§å¥åº·çæ³è¼å·®ï¼æ´æå¯è½å ç·æ¥åéé¸ææ§åå èå¥é¢ï¼ä¸ç¾çå´éç¨åº¦è¼é«ãç¶èï¼åææåç¼ç¾å±¬æ¼å°æ¸æè£ç¾¤é«å·æä¿è­·æ§çç´æ¥å½±é¿ï¼èå¤æ¸æè£çå°ç§çµç¸æ¯ï¼å°æ¸æè£æ£èå¨å¶ä»ææè®æ¸ä¿æç¸åçææ³ä¸ï¼å­æ´»çæææ¹åãæåè­æéç¨®ä¿è­·ææèè¢«éé² ICU çæ©çå¢å æéï¼å°æ¸æè£æ£èç ICU å¥é¢é¢¨éªå¢å ãæåä¹ç¼ç¾ï¼å°æ¸æè£æ£èéç¶å­æ´»çæææ¹åï¼ä½æ´æå¯è½åæ¬¡å¥é¢å° ICUãå æ­¤ï¼ç±æ¼è¼é£ç²å¾åç´é«çä¿å¥ï¼å°æ¸æè£æ£èæ´æå¯è½å å¯é é²çç¾çèé²å¥ ICUï¼å°è´æ­»äº¡çéä½ä¸¦ç¢ççä¼¼å·æä¿è­·ä½ç¨çææãç±æ¼ ICU å¥é¢çåºæ¬é¢¨éªå¯è½ä½çºç¼ºä¹åç´ç§è­·çææ¨ï¼å æ­¤æåéç¼äºåä½æ°éçç£è­·å¬å¹³æ§ï¼IICEï¼é·éï¼éæ¯ä¸åç£æ§ç³»çµ±ï¼ç¨æ¼è¿½è¹¤æ¾³æ´²åä½æ°äººå£å¨ä¸åå°çååéåº¦ä½¿ç¨ ICU è³æºçææ³ã

##### **Addressing Domain Shift via Imbalance-Aware Domain Adaptation in Embryo Development Assessment**
2501.04958v1 by Lei Li, Xinglin Zhang, Jun Liang, Tao Chen

Deep learning models in medical imaging face dual challenges: domain shift,
where models perform poorly when deployed in settings different from their
training environment, and class imbalance, where certain disease conditions are
naturally underrepresented. We present Imbalance-Aware Domain Adaptation
(IADA), a novel framework that simultaneously tackles both challenges through
three key components: (1) adaptive feature learning with class-specific
attention mechanisms, (2) balanced domain alignment with dynamic weighting, and
(3) adaptive threshold optimization. Our theoretical analysis establishes
convergence guarantees and complexity bounds. Through extensive experiments on
embryo development assessment across four imaging modalities, IADA demonstrates
significant improvements over existing methods, achieving up to 25.19\% higher
accuracy while maintaining balanced performance across classes. In challenging
scenarios with low-quality imaging systems, IADA shows robust generalization
with AUC improvements of up to 12.56\%. These results demonstrate IADA's
potential for developing reliable and equitable medical imaging systems for
diverse clinical settings. The code is made public available at
\url{https://github.com/yinghemedical/imbalance-aware_domain_adaptation}

æè¦ï¼<paragraph>é«çå½±åä¸­çæ·±åº¦å­¸ç¿æ¨¡åé¢è¨ééææ°ï¼é åè½ç§»ï¼æ¨¡åå¨èå¶è¨ç·´ç°å¢ä¸åçè¨­å®ä¸­é¨ç½²æè¡¨ç¾ä¸ä½³ï¼ä»¥åé¡å¥ä¸å¹³è¡¡ï¼æäºç¾ççæ³å¨èªç¶çä¸­ä»£è¡¨æ§ä¸è¶³ãæåæåºä¸å¹³è¡¡æç¥åé©æ (IADA)ï¼éæ¯ä¸åæ°ç©çæ¡æ¶ï¼ééä¸åééµçµæé¨ååææå°éå©åææ°ï¼(1) å·æé¡å¥ç¹å®æ³¨æåæ©å¶çèªé©æç¹å¾µå­¸ç¿ï¼(2) å·æåæå æ¬çå¹³è¡¡åå°é½ï¼ä»¥å (3) èªé©æé¾å¼æä½³åãæåççè«åæå»ºç«äºæ¶æä¿è­åè¤éåº¦çéãééå°åç¨®å½±åæ¨¡å¼çèèç¼è²è©ä¼°é²è¡å»£æ³çå¯¦é©ï¼IADA è­æäºå°ç¾ææ¹æ³çé¡¯èæ¹é²ï¼å¨ç¶­æé¡å¥éå¹³è¡¡æ§è½çåæï¼æºç¢ºåº¦æé«äº 25.19%ãå¨ä½åè³ªå½±åç³»çµ±çææ°æ§å ´æ¯ä¸­ï¼IADA ä»¥é«é 12.56% ç AUC æ¹é²é¡¯ç¤ºåºå¼·å¤§çæ³åè½åãéäºçµæè­æäº IADA å¨çºä¸åçè¨åºè¨­å®éç¼å¯é ä¸å¬å¹³çé«çå½±åç³»çµ±æ¹é¢çæ½åãç¨å¼ç¢¼å·²å¬éæ¼ \url{https://github.com/yinghemedical/imbalance-aware_domain_adaptation}</paragraph>

##### **Quantifying Itch and its Impact on Sleep Using Machine Learning and Radio Signals**
2501.04896v1 by Michail Ouroutzoglou, Mingmin Zhao, Joshua Hellerstein, Hariharan Rahul, Asima Badic, Brian S. Kim, Dina Katabi

Chronic itch affects 13% of the US population, is highly debilitating, and
underlies many medical conditions. A major challenge in clinical care and new
therapeutics development is the lack of an objective measure for quantifying
itch, leading to reliance on subjective measures like patients' self-assessment
of itch severity. In this paper, we show that a home radio device paired with
artificial intelligence (AI) can concurrently capture scratching and evaluate
its impact on sleep quality by analyzing radio signals bouncing in the
environment. The device eliminates the need for wearable sensors or skin
contact, enabling monitoring of chronic itch over extended periods at home
without burdening patients or interfering with their skin condition. To
validate the technology, we conducted an observational clinical study of
chronic pruritus patients, monitored at home for one month using both the radio
device and an infrared camera. Comparing the output of the device to ground
truth data from the camera demonstrates its feasibility and accuracy (ROC AUC =
0.997, sensitivity = 0.825, specificity = 0.997). The results reveal a
significant correlation between scratching and low sleep quality, manifested as
a reduction in sleep efficiency (R = 0.6, p < 0.001) and an increase in sleep
latency (R = 0.68, p < 0.001). Our study underscores the potential of passive,
long-term, at-home monitoring of chronic scratching and its sleep implications,
offering a valuable tool for both clinical care of chronic itch patients and
pharmaceutical clinical trials.

æè¦ï¼æ¢æ§æç¢å½±é¿ç¾å 13% çäººå£ï¼æå´éè¡°å¼±ï¼ä¸æ¯è¨±å¤ç¾ççæ ¹æ¬åå ãè¨åºè­·çåæ°çæ³éç¼çä¸å¤§ææ°æ¯ç¼ºä¹å®¢è§çææ¨ä¾éåæç¢ï¼å°è´ä¾è³´æ¼æ£èèªæè©ä¼°æç¢å´éç¨åº¦ç­ä¸»è§ææ¨ãå¨æ¬æä¸­ï¼æåå±ç¤ºäºä¸ç¨®èäººå·¥æºæ§ (AI) éå°çå®¶ç¨ç¡ç·é»è£ç½®ï¼å¯ééåæå¨ç°å¢ä¸­å½è·³çç¡ç·é»è¨èï¼åææ·åææä¸¦è©ä¼°å¶å°ç¡ç åè³ªçå½±é¿ãæ­¤è£ç½®æ¶é¤äºå°ç©¿æ´å¼ææ¸¬å¨æç®èæ¥è§¸çéæ±ï¼è®æ£èå¨å®¶ä¸­é·æéç£æ§æ¢æ§æç¢ï¼èä¸æé æè² ææå¹²æ¾å¶ç®èçæ³ãçºäºé©è­éé æè¡ï¼æåå°æ¢æ§æç¢çæ£èé²è¡äºä¸é è§å¯æ§è¨åºç ç©¶ï¼ä½¿ç¨ç¡ç·é»è£ç½®åç´å¤ç·æå½±æ©å¨å®¶ä¸­ç£æ§ä¸åæãå°è£ç½®çè¼¸åºèæå½±æ©ççå¯¦æ¸æé²è¡æ¯è¼ï¼è­æäºå¶å¯è¡æ§åæºç¢ºæ§ (ROC AUC = 0.997ï¼éæåº¦ = 0.825ï¼ç¹ç°åº¦ = 0.997)ãçµæé¡¯ç¤ºææèç¡ç åè³ªä½ä¸ä¹éå­å¨é¡¯èç¸éæ§ï¼è¡¨ç¾çºç¡ç æçéä½ (R = 0.6ï¼p < 0.001) åç¡ç æ½ä¼æå¢å  (R = 0.68ï¼p < 0.001)ãæåçç ç©¶å¼·èª¿äºè¢«åãé·æãå¨å®¶ä¸­ç£æ§æ¢æ§ææåå¶å°ç¡ç çå½±é¿çæ½åï¼çºæ¢æ§æç¢çæ£èçè¨åºè­·çåè¥å» è¨åºè©¦é©æä¾äºæå¹å¼çå·¥å·ã

##### **MedCoDi-M: A Multi-Prompt Foundation Model for Multimodal Medical Data Generation**
2501.04614v2 by Daniele Molino, Francesco Di Feola, Eliodoro Faiella, Deborah Fazzini, Domiziana Santucci, Linlin Shen, Valerio Guarrasi, Paolo Soda

Artificial Intelligence is revolutionizing medical practice, enhancing
diagnostic accuracy and healthcare delivery. However, its adaptation in medical
settings still faces significant challenges, related to data availability and
privacy constraints. Synthetic data has emerged as a promising solution to
mitigate these issues, addressing data scarcity while preserving privacy.
Recently, Latent Diffusion Models have emerged as a powerful tool for
generating high-quality synthetic data. Meanwhile, the integration of different
modalities has gained interest, emphasizing the need of models capable of
handle multimodal medical data. Existing approaches struggle to integrate
complementary information and lack the ability to generate modalities
simultaneously. To address this challenge, we present MedCoDi-M, a
6.77-billion-parameter model, designed for multimodal medical data generation,
that, following Foundation Model paradigm, exploits contrastive learning and
large quantity of data to build a shared latent space which capture the
relationships between different data modalities. Further, we introduce the
Multi-Prompt training technique, which significantly boosts MedCoDi-M's
generation under different settings. We extensively validate MedCoDi-M: first
we benchmark it against five competitors on the MIMIC-CXR dataset, a
state-of-the-art dataset for Chest X-ray and radiological report generation.
Secondly, we perform a Visual Turing Test with expert radiologists to assess
the realism and clinical relevance of the generated data, ensuring alignment
with real-world scenarios. Finally, we assess the utility of MedCoDi-M in
addressing key challenges in the medical field, such as anonymization, data
scarcity and imbalance learning. The results are promising, demonstrating the
applicability of MedCoDi-M in medical contexts. Project page is at
https://cosbidev.github.io/MedCoDi-M/.

æè¦ï¼äººå·¥æºè½æ­£å¨é©æ°é«çå¯¦åï¼æåè¨ºæ·æºç¢ºåº¦åé«çä¿å¥æåãç¶èï¼å®å¨é«çå ´æ¯ä¸­çæç¨ä»é¢è¨èéå¤§ææ°ï¼éèè³æå¯ç¨æ§åé±ç§éå¶æéãåæè³æå·²æçºç·©è§£éäºåé¡çæ½å¨è§£æ±ºæ¹æ¡ï¼å®å¨ä¿è­·é±ç§çåæè§£æ±ºäºè³æç­ç¼ºçåé¡ãæè¿ï¼æ½å¨æ´æ£æ¨¡åå·²æçºç¢çé«åè³ªåæè³æçå¼·å¤§å·¥å·ãåæï¼æ´åä¸åæ¨¡æå·²å¼èµ·èè¶£ï¼å¼·èª¿äºéè¦è½å¤ èçå¤æ¨¡æé«çè³æçæ¨¡åãç¾ææ¹æ³é£ä»¥æ´åè£åè³è¨ï¼ä¸¦ä¸ç¼ºä¹åæç¢çæ¨¡æçè½åãçºäºæå°éä¸ææ°ï¼æåæåºäº MedCoDi-Mï¼éæ¯ä¸å 67.7 ååæ¸çæ¨¡åï¼å°çºå¤æ¨¡æé«çè³æç¢çèè¨­è¨ï¼å®éµå¾ªåºç¤æ¨¡åç¯ä¾ï¼å©ç¨å°æ¯å­¸ç¿åå¤§éçè³æä¾å»ºç«ä¸åå±äº«æ½å¨ç©ºéï¼ä»¥ææä¸åè³ææ¨¡æä¹éçéä¿ãæ­¤å¤ï¼æåå¼å¥äºå¤æç¤ºè¨ç·´æè¡ï¼å®é¡¯èæåäº MedCoDi-M å¨ä¸åè¨­å®ä¸çç¢çãæåå»£æ³é©è­äº MedCoDi-Mï¼é¦åï¼æåå¨ MIMIC-CXR è³æéä¸å°å®èäºåç«¶ç­èé²è¡äºåºæºæ¸¬è©¦ï¼éæ¯è¸é¨ X ååæ¾å°å ±åç¢çé åçææ°è³æéãå¶æ¬¡ï¼æåèæ¾å°ç§å°å®¶é²è¡äºè¦è¦ºåéæ¸¬è©¦ï¼ä»¥è©ä¼°ç¢çè³æççå¯¦æ§åè¨åºç¸éæ§ï¼ç¢ºä¿èçå¯¦å ´æ¯ä¿æä¸è´ãæå¾ï¼æåè©ä¼°äº MedCoDi-M å¨è§£æ±ºé«çé åééµææ°ä¸­çæç¨ï¼ä¾å¦å¿ååãè³æç­ç¼ºåä¸å¹³è¡¡å­¸ç¿ãçµæä»¤äººæ»¿æï¼è­æäº MedCoDi-M å¨é«çç°å¢ä¸­çé©ç¨æ§ãå°æ¡é é¢ä½æ¼ https://cosbidev.github.io/MedCoDi-M/ã

##### **A 65 nm Bayesian Neural Network Accelerator with 360 fJ/Sample In-Word GRNG for AI Uncertainty Estimation**
2501.04577v2 by Zephan M. Enciso, Boyang Cheng, Likai Pei, Jianbo Liu, Steven Davis, Michael Niemier, Ningyuan Cao

Uncertainty estimation is an indispensable capability for AI-enabled,
safety-critical applications, e.g. autonomous vehicles or medical diagnosis.
Bayesian neural networks (BNNs) use Bayesian statistics to provide both
classification predictions and uncertainty estimation, but they suffer from
high computational overhead associated with random number generation and
repeated sample iterations. Furthermore, BNNs are not immediately amenable to
acceleration through compute-in-memory architectures due to the frequent memory
writes necessary after each RNG operation. To address these challenges, we
present an ASIC that integrates 360 fJ/Sample Gaussian RNG directly into the
SRAM memory words. This integration reduces RNG overhead and enables
fully-parallel compute-in-memory operations for BNNs. The prototype chip
achieves 5.12 GSa/s RNG throughput and 102 GOp/s neural network throughput
while occupying 0.45 mm2, bringing AI uncertainty estimation to edge
computation.

æè¦ï¼ä¸ç¢ºå®æ§ä¼°è¨å°æ¼ AI åç¨ãå®å¨è³ä¸çæç¨ç¨å¼èè¨ï¼ä¾å¦èªåé§é§è»è¼æé«çè¨ºæ·ï¼ä¸å¯æç¼ºãè²æ°ç¥ç¶ç¶²è·¯ (BNN) ä½¿ç¨è²æ°çµ±è¨æä¾åé¡é æ¸¬åä¸ç¢ºå®æ§ä¼°è¨ï¼ä½å®åæå çºé¨æ©æ¸å­ç¢çåéè¤åæ¨£è¿­ä»£èé æå·¨å¤§çéç®è² æãæ­¤å¤ï¼BNN ä¸¦éç«å³é©ç¨æ¼éééç®æ¼è¨æ¶é«æ¶æ§é²è¡å éï¼å çºæ¯æ¬¡ RNG ä½æ¥­å¾é½éè¦é »ç¹å¯«å¥è¨æ¶é«ãçºäºè§£æ±ºéäºææ°ï¼æåæåºäºä¸ç¨® ASICï¼å° 360 fJ/åæ¨£çé«æ¯ RNG ç´æ¥æ´åå° SRAM è¨æ¶é«å­ä¸­ãéç¨®æ´åå¯éä½ RNG è² æï¼ä¸¦çº BNN åç¨å®å¨ä¸¦è¡çéç®æ¼è¨æ¶é«ä½æ¥­ãååæ¶çå¯éå° 5.12 GSa/s RNG èçéå 102 GOp/s ç¥ç¶ç¶²è·¯èçéï¼åæä½ç¨ 0.45 mm2ï¼å° AI ä¸ç¢ºå®æ§ä¼°è¨å¸¶å¥éç·£éç®ã

##### **Continual Self-supervised Learning Considering Medical Domain Knowledge in Chest CT Images**
2501.04217v1 by Ren Tasai, Guang Li, Ren Togo, Minghui Tang, Takaaki Yoshimura, Hiroyuki Sugimori, Kenji Hirata, Takahiro Ogawa, Kohsuke Kudo, Miki Haseyama

We propose a novel continual self-supervised learning method (CSSL)
considering medical domain knowledge in chest CT images. Our approach addresses
the challenge of sequential learning by effectively capturing the relationship
between previously learned knowledge and new information at different stages.
By incorporating an enhanced DER into CSSL and maintaining both diversity and
representativeness within the rehearsal buffer of DER, the risk of data
interference during pretraining is reduced, enabling the model to learn more
richer and robust feature representations. In addition, we incorporate a mixup
strategy and feature distillation to further enhance the model's ability to
learn meaningful representations. We validate our method using chest CT images
obtained under two different imaging conditions, demonstrating superior
performance compared to state-of-the-art methods.

æè¦ï¼æåæåºäºä¸ç¨®æ°çæçºèªæç£ç£å­¸ç¿æ¹æ³ (CSSL)ï¼èéäºè¸é¨é»è¦æ·å±¤å½±åä¸­çé«å­¸é åç¥è­ãæåçåæ³ééææææååå­¸ç¿çç¥è­èä¸åéæ®µçæ°è³è¨ä¹éçéä¿ï¼ä¾è§£æ±ºå¾ªåºå­¸ç¿çææ°ãééå°å¢å¼·ç DER ç´å¥ CSSLï¼ä¸¦å¨ DER çæç·´ç·©è¡åå§ç¶­æå¤æ¨£æ§åä»£è¡¨æ§ï¼é è¨ç·´æéè³æå¹²æ¾çé¢¨éªéä½ï¼ä½¿æ¨¡åè½å¤ å­¸ç¿æ´è±å¯ä¸å¼·å¥çç¹å¾µè¡¨å¾µãæ­¤å¤ï¼æåç´å¥æ··æ·ç­ç¥åç¹å¾µèåï¼é²ä¸æ­¥å¢å¼·æ¨¡åå­¸ç¿ææç¾©è¡¨å¾µçè½åãæåä½¿ç¨å¨å©ç¨®ä¸åå½±åæ¢ä»¶ä¸åå¾çè¸é¨é»è¦æ·å±¤å½±åé©è­æåçæ¨¡åï¼è­æèç¾ææè¡ç¸æ¯å·æåªç°çæè½ã

##### **Generative Style Transfer for MRI Image Segmentation: A Case of Glioma Segmentation in Sub-Saharan Africa**
2501.04734v1 by Rancy Chepchirchir, Jill Sunday, Raymond Confidence, Dong Zhang, Talha Chaudhry, Udunna C. Anazodo, Kendi Muchungi, Yujing Zou

In Sub-Saharan Africa (SSA), the utilization of lower-quality Magnetic
Resonance Imaging (MRI) technology raises questions about the applicability of
machine learning methods for clinical tasks. This study aims to provide a
robust deep learning-based brain tumor segmentation (BraTS) method tailored for
the SSA population using a threefold approach. Firstly, the impact of domain
shift from the SSA training data on model efficacy was examined, revealing no
significant effect. Secondly, a comparative analysis of 3D and 2D
full-resolution models using the nnU-Net framework indicates similar
performance of both the models trained for 300 epochs achieving a five-fold
cross-validation score of 0.93. Lastly, addressing the performance gap observed
in SSA validation as opposed to the relatively larger BraTS glioma (GLI)
validation set, two strategies are proposed: fine-tuning SSA cases using the
GLI+SSA best-pretrained 2D fullres model at 300 epochs, and introducing a novel
neural style transfer-based data augmentation technique for the SSA cases. This
investigation underscores the potential of enhancing brain tumor prediction
within SSA's unique healthcare landscape.

æè¦ï¼å¨æåæä»¥åéæ´² (SSA)ï¼ä½è´¨éç£å±æ¯æå (MRI) ææ¯çä½¿ç¨å¼åäºæå³æºå¨å­¦ä¹ æ¹æ³å¨ä¸´åºä»»å¡ä¸­éç¨æ§çé®é¢ãæ¬ç ç©¶æ¨å¨æä¾ä¸ç§éå¯¹ SSA äººç¾¤éèº«å®å¶çé²æ£æ·±åº¦å­¦ä¹ èè¿ç¤åå² (BraTS) æ¹æ³ï¼éç¨ä¸éæ¹æ³ãé¦åï¼æ£æ¥äº SSA è®­ç»æ°æ®å¯¹æ¨¡åæè½çååç§»å½±åï¼ç»ææ¾ç¤ºæ²¡ææ¾çå½±åãå¶æ¬¡ï¼ä½¿ç¨ nnU-Net æ¡æ¶å¯¹ 3D å 2D å¨åè¾¨çæ¨¡åè¿è¡æ¯è¾åæï¼è¡¨æéå¯¹ 300 ä¸ª epoch è®­ç»çä¸¤ä¸ªæ¨¡åçæ§è½ç¸ä¼¼ï¼å®ç°äº 0.93 çäºéäº¤åéªè¯åæ°ãæåï¼éå¯¹ SSA éªè¯ä¸­è§å¯å°çæ§è½å·®è·ï¼èä¸æ¯ç¸å¯¹è¾å¤§ç BraTS ç¥ç»è¶è´¨ç¤ (GLI) éªè¯éï¼æåºäºä¸¤ç§ç­ç¥ï¼ä½¿ç¨ GLI+SSA æä½³é¢è®­ç»ç 2D å¨åè¾¨çæ¨¡åå¨ 300 ä¸ª epoch å¯¹ SSA çä¾è¿è¡å¾®è°ï¼å¹¶ä¸º SSA çä¾å¼å¥ä¸ç§æ°é¢çç¥ç»é£æ ¼è¿ç§»æ°æ®å¢å¼ºææ¯ãè¿é¡¹è°æ¥å¼ºè°äºå¨ SSA ç¬ç¹çå»çä¿å¥ç¯å¢ä¸­æé«èè¿ç¤é¢æµæ½åçå¯è½æ§ã

##### **Exploring the Potential of Large Language Models in Public Transportation: San Antonio Case Study**
2501.03904v1 by Ramya Jonnala, Gongbo Liang, Jeong Yang, Izzat Alsmadi

The integration of large language models (LLMs) into public transit systems
presents a transformative opportunity to enhance urban mobility. This study
explores the potential of LLMs to revolutionize public transportation
management within the context of San Antonio's transit system. Leveraging the
capabilities of LLMs in natural language processing and data analysis, we
investigate their capabilities to optimize route planning, reduce wait times,
and provide personalized travel assistance. By utilizing the General Transit
Feed Specification (GTFS) and other relevant data, this research aims to
demonstrate how LLMs can potentially improve resource allocation, elevate
passenger satisfaction, and inform data-driven decision-making in transit
operations. A comparative analysis of different ChatGPT models was conducted to
assess their ability to understand transportation information, retrieve
relevant data, and provide comprehensive responses. Findings from this study
suggest that while LLMs hold immense promise for public transit, careful
engineering and fine-tuning are essential to realizing their full potential.
San Antonio serves as a case study to inform the development of LLM-powered
transit systems in other urban environments.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) æ´åå°å¬å±äº¤éç³»çµ±ä¸­ï¼çºæååå¸æµåæ§å¸¶ä¾è½åå¥æ©ãæ¬ç ç©¶æ¢è¨ LLM å¨èå®æ±å°¼å¥§äº¤éç³»çµ±èçµ¡ä¸ï¼é©æ°å¤§ç¾éè¼¸ç®¡ççæ½åãå©ç¨ LLM å¨èªç¶èªè¨èçåè³æåææ¹é¢çè½åï¼æåæ¢è¨å¶å¨åªåè·¯ç·è¦åãç¸®ç­ç­åæéï¼ä»¥åæä¾åäººåæéåå©æ¹é¢çè½åãééå©ç¨éç¨å¤§ç¾éè¼¸è³æè¦ç¯ (GTFS) åå¶ä»ç¸éè³æï¼æ¬ç ç©¶æ¨å¨è­æ LLM å¦ä½æ½å¨æåè³æºéç½®ãæåä¹å®¢æ»¿æåº¦ï¼ä»¥åå¨äº¤éçéä¸­æä¾è³æé©åçæ±ºç­ãéå°ä¸åç ChatGPT æ¨¡åé²è¡æ¯è¼åæï¼ä»¥è©ä¼°å¶çè§£äº¤éè³è¨ãæ·åç¸éè³æï¼ä»¥åæä¾å¨é¢åæçè½åãæ¬ç ç©¶çç¼ç¾é¡¯ç¤ºï¼åç®¡ LLM å°å¤§ç¾éè¼¸æ¥µå·åæ¯ï¼ä½ç²¾å¯çå·¥ç¨åå¾®èª¿å°æ¼å¯¦ç¾å¶å¨é¨æ½åè³ééè¦ãèå®æ±å°¼å¥§ä½çºä¸åæ¡ä¾ç ç©¶ï¼çºå¨å¶ä»é½å¸ç°å¢ä¸­éç¼ç± LLM é©åçäº¤éç³»çµ±æä¾åèã

##### **SCC-YOLO: An Improved Object Detector for Assisting in Brain Tumor Diagnosis**
2501.03836v2 by Runci Bai

Brain tumors can result in neurological dysfunction, alterations in cognitive
and psychological states, increased intracranial pressure, and the occurrence
of seizures, thereby presenting a substantial risk to human life and health.
The You Only Look Once(YOLO) series models have demonstrated superior accuracy
in object detection for medical imaging. In this paper, we develop a novel
SCC-YOLO architecture by integrating the SCConv attention mechanism into
YOLOv9. The SCConv module reconstructs an efficient convolutional module by
reducing spatial and channel redundancy among features, thereby enhancing the
learning of image features. We investigate the impact of intergrating different
attention mechanisms with the YOLOv9 model on brain tumor image detection using
both the Br35H dataset and our self-made dataset(Brain_Tumor_Dataset).
Experimental results show that on the Br35H dataset, SCC-YOLO achieved a 0.3%
improvement in mAp50 compared to YOLOv9, while on our self-made dataset,
SCC-YOLO exhibited a 0.5% improvement over YOLOv9. SCC-YOLO has reached
state-of-the-art performance in brain tumor detection. Source code is available
at : https://jihulab.com/healthcare-information-studio/SCC-YOLO/-/tree/master

æè¦ï¼è¦ç¤å¯è½å°è´ç¥ç¶åè½éç¤ãèªç¥åå¿ççææ¹è®ãé¡±å§å£åé«åç²çç¼ä½ï¼å¾èå°äººé¡çå½åå¥åº·æ§æéå¤§é¢¨éªãYou Only Look Once (YOLO) ç³»åæ¨¡åå·²è­æå¨é«å­¸å½±åçç®æ¨æª¢æ¸¬ä¸­å·æåªç°çæºç¢ºåº¦ãå¨æ¬æä¸­ï¼æåééå° SCConv æ³¨æåæ©å¶æ´åå° YOLOv9 ä¸­ï¼éç¼äºä¸ç¨®æ°ç©ç SCC-YOLO æ¶æ§ãSCConv æ¨¡çµééæ¸å°ç¹å¾µä¹éçç©ºéåééåé¤ä¾éå»ºä¸åé«æçå·ç©æ¨¡çµï¼å¾èå¢å¼·å½±åç¹å¾µçå­¸ç¿ãæåä½¿ç¨ Br35H è³æéåæåèªè£½çè³æé (Brain_Tumor_Dataset) èª¿æ¥äºå°ä¸åçæ³¨æåæ©å¶è YOLOv9 æ¨¡åæ´åå°è¦ç¤å½±åæª¢æ¸¬çå½±é¿ãå¯¦é©çµæè¡¨æï¼å¨ Br35H è³æéä¸ï¼è YOLOv9 ç¸æ¯ï¼SCC-YOLO å¨ mAP50 ä¸æé«äº 0.3%ï¼èå¨æåèªè£½çè³æéä¸ï¼SCC-YOLO æ¯ YOLOv9 æé«äº 0.5%ãSCC-YOLO å·²éå°è¦ç¤æª¢æ¸¬çææ°æè½ãåå§ç¢¼å¯å¨ä»¥ä¸ç¶²ååå¾ï¼https://jihulab.com/healthcare-information-studio/SCC-YOLO/-/tree/master

##### **SelectiveFinetuning: Enhancing Transfer Learning in Sleep Staging through Selective Domain Alignment**
2501.03764v1 by Siyuan Zhao, Chenyu Liu, Yi Ding, Xinliang Zhou

In practical sleep stage classification, a key challenge is the variability
of EEG data across different subjects and environments. Differences in
physiology, age, health status, and recording conditions can lead to domain
shifts between data. These domain shifts often result in decreased model
accuracy and reliability, particularly when the model is applied to new data
with characteristics different from those it was originally trained on, which
is a typical manifestation of negative transfer. To address this, we propose
SelectiveFinetuning in this paper. Our method utilizes a pretrained Multi
Resolution Convolutional Neural Network (MRCNN) to extract EEG features,
capturing the distinctive characteristics of different sleep stages. To
mitigate the effect of domain shifts, we introduce a domain aligning mechanism
that employs Earth Mover Distance (EMD) to evaluate and select source domain
data closely matching the target domain. By finetuning the model with selective
source data, our SelectiveFinetuning enhances the model's performance on target
domain that exhibits domain shifts compared to the data used for training.
Experimental results show that our method outperforms existing baselines,
offering greater robustness and adaptability in practical scenarios where data
distributions are often unpredictable.

æè¦ï¼å¨å¯¦éçç¡ç éæ®µåé¡ä¸­ï¼ä¸åééµçææ°æ¯è¦é»åæ¸æå¨ä¸ååè©¦èåç°å¢ä¸­çè®ç°æ§ãççãå¹´é½¡ãå¥åº·çæ³åè¨éæ¢ä»¶çå·®ç°å¯è½å°è´æ¸æä¹éçé ååç§»ãéäºé ååç§»éå¸¸æå°è´æ¨¡åæºç¢ºåº¦åå¯é æ§ä¸éï¼ç¹å¥æ¯ç¶æ¨¡åæç¨æ¼èå¶æåè¨ç·´æä¸åçç¹å¾µçæ°æ¸ææï¼éæ¯è² é·ç§»çå¸åè¡¨ç¾ãçºäºè§£æ±ºéååé¡ï¼æåå¨æ¬æä¸­æåºé¸ææ§å¾®èª¿ãæåçæ¨¡åå©ç¨é è¨ç·´çå¤è§£æåº¦å·ç©ç¥ç¶ç¶²è·¯ (MRCNN) ä¾æåè¦é»åç¹å¾µï¼ææä¸åç¡ç éæ®µçç¨ç¹ç¹å¾µãçºäºæ¸è¼é ååç§»çå½±é¿ï¼æåå¼å¥äºä¸åé åå°é½æ©å¶ï¼å®æ¡ç¨å°çç§»åè·é¢ (EMD) ä¾è©ä¼°åé¸æèç®æ¨é åç·å¯å¹éçæºé åæ¸æãééä½¿ç¨é¸ææ§æºæ¸æå¾®èª¿æ¨¡åï¼æåçé¸ææ§å¾®èª¿å¢å¼·äºæ¨¡åå¨èç¨æ¼è¨ç·´çæ¸æç¸æ¯è¡¨ç¾åºé ååç§»çç®æ¨é åä¸çæ§è½ãå¯¦é©çµæè¡¨æï¼æåçæ¨¡ååªæ¼ç¾æçåºæºï¼å¨æ¸æåä½éå¸¸ä¸å¯é æ¸¬çå¯¦éå ´æ¯ä¸­æä¾äºæ´å¤§çç©©å¥æ§åé©ææ§ã

##### **Self-adaptive vision-language model for 3D segmentation of pulmonary artery and vein**
2501.03722v1 by Xiaotong Guo, Deqian Yang, Dan Wang, Haochen Zhao, Yuan Li, Zhilin Sui, Tao Zhou, Lijun Zhang, Yanda Meng

Accurate segmentation of pulmonary structures iscrucial in clinical
diagnosis, disease study, and treatment planning. Significant progress has been
made in deep learning-based segmentation techniques, but most require much
labeled data for training. Consequently, developing precise segmentation
methods that demand fewer labeled datasets is paramount in medical image
analysis. The emergence of pre-trained vision-language foundation models, such
as CLIP, recently opened the door for universal computer vision tasks.
Exploiting the generalization ability of these pre-trained foundation models on
downstream tasks, such as segmentation, leads to unexpected performance with a
relatively small amount of labeled data. However, exploring these models for
pulmonary artery-vein segmentation is still limited. This paper proposes a
novel framework called Language-guided self-adaptive Cross-Attention Fusion
Framework. Our method adopts pre-trained CLIP as a strong feature extractor for
generating the segmentation of 3D CT scans, while adaptively aggregating the
cross-modality of text and image representations. We propose a s pecially
designed adapter module to fine-tune pre-trained CLIP with a self-adaptive
learning strategy to effectively fuse the two modalities of embeddings. We
extensively validate our method on a local dataset, which is the largest
pulmonary artery-vein CT dataset to date and consists of 718 labeled data in
total. The experiments show that our method outperformed other state-of-the-art
methods by a large margin. Our data and code will be made publicly available
upon acceptance.

æè¦ï¼ç²¾ç¢ºåå²èºé¨çµæ§å¨è¨åºè¨ºæ·ãç¾çç ç©¶åæ²»çè¨ç«ä¸­è³ééè¦ãåºæ¼æ·±åº¦å­¸ç¿çåå²æè¡å·²åå¾éå¤§é²å±ï¼ä½å¤§å¤æ¸æè¡å¨è¨ç·´æéè¦å¤§éçæ¨è¨è³æãå æ­¤ï¼éç¼ç²¾ç¢ºçåå²æ¹æ³ï¼ä»¥æ¸å°æ¨è¨è³æéçéæ±ï¼å¨é«å­¸å½±ååæä¸­è³ééè¦ãé è¨ç·´çè¦è¦ºèªè¨åºç¤æ¨¡åï¼ä¾å¦ CLIPï¼çåºç¾ï¼æè¿çºéç¨é»è¦è¦è¦ºä»»åéåäºå¤§éãå©ç¨éäºé è¨ç·´åºç¤æ¨¡åå¨åå²ç­ä¸æ¸¸ä»»åä¸­çæ³åè½åï¼å³ä½¿æ¨è¨è³æéç¸å°è¼å°ï¼ä¹è½ç¢çææ³ä¸å°çæè½ãç¶èï¼æ¢ç´¢éäºæ¨¡åå¨èºåèéèåå²ä¸­çæç¨ä»ç¶æéãæ¬ææåºäºä¸ååçºèªè¨å¼å°èªé©æäº¤åæ³¨æåèåæ¡æ¶çæ°æ¡æ¶ãæåçæ¨¡åæ¡ç¨é è¨ç·´ç CLIP ä½çºå¼·å¤§çç¹å¾µèåå¨ï¼ç¨æ¼ç¢ç 3D é»è¦æ·å±¤ææçåå²ï¼åæèªé©æå°èåææ¬åå½±åè¡¨å¾µçè·¨æ¨¡æãæåæåºäºä¸åç¹å¥è¨­è¨çé©éå¨æ¨¡çµï¼ä»¥èªé©æå­¸ç¿ç­ç¥å¾®èª¿é è¨ç·´ç CLIPï¼ä»¥ææèåå©ç¨®åµå¥æ¨¡æãæåå¨ä¸åæ¬å°è³æéä¸å»£æ³é©è­äºæåçæ¨¡åï¼éæ¯è¿ä»çºæ­¢æå¤§çèºåèéèé»è¦æ·å±¤ææè³æéï¼ç¸½å±åå« 718 åæ¨è¨è³æãå¯¦é©è¡¨æï¼æåçæ¨¡åä»¥å¤§å¹åªæ¼å¶ä»æåé²æ¨¡åãæåçè³æåç¨å¼ç¢¼å°å¨ç²å¾æ¥åå¾å¬éã

##### **Can Deep Learning Trigger Alerts from Mobile-Captured Images?**
2501.03499v1 by Pritisha Sarkar, Duranta Durbaar Vishal Saha, Mousumi Saha

Our research presents a comprehensive approach to leveraging mobile camera
image data for real-time air quality assessment and recommendation. We develop
a regression-based Convolutional Neural Network model and tailor it explicitly
for air quality prediction by exploiting the inherent relationship between
output parameters. As a result, the Mean Squared Error of 0.0077 and 0.0112
obtained for 2 and 5 pollutants respectively outperforms existing models.
Furthermore, we aim to verify the common practice of augmenting the original
dataset with a view to introducing more variation in the training phase. It is
one of our most significant contributions that our experimental results
demonstrate minimal accuracy differences between the original and augmented
datasets. Finally, a real-time, user-friendly dashboard is implemented which
dynamically displays the Air Quality Index and pollutant values derived from
captured mobile camera images. Users' health conditions are considered to
recommend whether a location is suitable based on current air quality metrics.
Overall, this research contributes to verification of data augmentation
techniques, CNN-based regression modelling for air quality prediction, and
user-centric air quality monitoring through mobile technology. The proposed
system offers practical solutions for individuals to make informed
environmental health and well-being decisions.

æè¦ï¼æåçç ç©¶æåºäºä¸ç¨®å©ç¨è¡åè£ç½®ç¸æ©å½±åè³æé²è¡å³æç©ºæ°£åè³ªè©ä¼°åå»ºè­°çå¨é¢æ§æ¹æ³ãæåéç¼äºä¸ç¨®åºæ¼è¿´æ­¸çå·ç©ç¥ç¶ç¶²è·¯æ¨¡åï¼ä¸¦ééå©ç¨è¼¸åºåæ¸ä¹éçå§å¨éä¿ï¼éå°ç©ºæ°£åè³ªé æ¸¬éèº«æé ãå æ­¤ï¼åå¥éå° 2 å 5 ç¨®æ±¡æç©åå¾çå¹³åå¹³æ¹èª¤å·®çº 0.0077 å 0.0112ï¼åªæ¼ç¾æçæ¨¡åãæ­¤å¤ï¼æåæ¨å¨é©è­æ´ååå§è³æéçå¸¸è¦åæ³ï¼ä»¥æå¨è¨ç·´éæ®µå¼å¥æ´å¤è®ç°ãæåçå¯¦é©çµæé¡¯ç¤ºåå§è³æéåæ´åè³æéä¹éçæºç¢ºåº¦å·®ç°æ¥µå°ï¼éæ¯æåæéè¦çè²¢ç»ä¹ä¸ãæå¾ï¼æåå¯¦ä½äºä¸åå³æãä½¿ç¨èååçåè¡¨æ¿ï¼å¯åæé¡¯ç¤ºå¾æ·åçè¡åè£ç½®ç¸æ©å½±åä¸­è¡ççç©ºæ°£åè³ªææ¸åæ±¡æç©æ¸å¼ãèéä½¿ç¨èçå¥åº·çæ³ï¼å»ºè­°æ¯å¦æ ¹æç®åçç©ºæ°£åè³ªææ¨é¸æé©åçå°é»ãæ´é«èè¨ï¼éé ç ç©¶æå©æ¼é©è­è³ææ´åæè¡ãåºæ¼ CNN çè¿´æ­¸æ¨¡åï¼ç¨æ¼ç©ºæ°£åè³ªé æ¸¬ï¼ä»¥åééè¡åæè¡é²è¡ä»¥ä½¿ç¨èçºä¸­å¿çç©ºæ°£åè³ªç£æ§ãææåºçç³»çµ±çºåäººæä¾å¯¦éçè§£æ±ºæ¹æ¡ï¼ä»¥ä¾¿ååºææºçç°å¢å¥åº·åç¦ç¥æ±ºç­ã

##### **Activating Associative Disease-Aware Vision Token Memory for LLM-Based X-ray Report Generation**
2501.03458v1 by Xiao Wang, Fuling Wang, Haowen Wang, Bo Jiang, Chuanfu Li, Yaowei Wang, Yonghong Tian, Jin Tang

X-ray image based medical report generation achieves significant progress in
recent years with the help of the large language model, however, these models
have not fully exploited the effective information in visual image regions,
resulting in reports that are linguistically sound but insufficient in
describing key diseases. In this paper, we propose a novel associative
memory-enhanced X-ray report generation model that effectively mimics the
process of professional doctors writing medical reports. It considers both the
mining of global and local visual information and associates historical report
information to better complete the writing of the current report. Specifically,
given an X-ray image, we first utilize a classification model along with its
activation maps to accomplish the mining of visual regions highly associated
with diseases and the learning of disease query tokens. Then, we employ a
visual Hopfield network to establish memory associations for disease-related
tokens, and a report Hopfield network to retrieve report memory information.
This process facilitates the generation of high-quality reports based on a
large language model and achieves state-of-the-art performance on multiple
benchmark datasets, including the IU X-ray, MIMIC-CXR, and Chexpert Plus. The
source code of this work is released on
\url{https://github.com/Event-AHU/Medical_Image_Analysis}.

æè¦ï¼è¿å¹´ä¾ï¼å¨å¤§åèªè¨æ¨¡åçå¹«å©ä¸ï¼åºæ¼ X åå½±åçé«çå ±åçæåå¾äºé¡¯èé²å±ï¼ç¶èï¼éäºæ¨¡åä¸¦æªååå©ç¨è¦è¦ºå½±åååä¸­çææè³è¨ï¼å°è´å ±åå¨èªè¨ä¸éç¶æµæ¢ï¼ä½å¨æè¿°ééµç¾çæ¹é¢å»ä¸è¶³ãå¨æ¬æä¸­ï¼æåæåºäºä¸åæ°ç©çè¯æ³å¼è¨æ¶å¢å¼· X åå ±åçææ¨¡åï¼ææå°æ¨¡æ¬å°æ¥­é«çæ°å¯«é«çå ±åçéç¨ãå®åæèæ®äºå°å¨å±åå±é¨è¦è¦ºè³è¨çææï¼ä¸¦è¯ç¹«æ­·å²å ±åè³è¨ï¼ä»¥æ´å¥½å°å®æç¶åå ±åçæ°å¯«ãå·é«ä¾èªªï¼çµ¦å®ä¸å¼µ X åå½±åï¼æåé¦åå©ç¨åé¡æ¨¡ååå¶æ¿æ´»æ å°ä¾å®æèç¾çé«åº¦ç¸éçè¦è¦ºååçææåç¾çæ¥è©¢ä»¤ççå­¸ç¿ãç¶å¾ï¼æåæ¡ç¨è¦è¦ºéæ®è²ç¾å¾·ç¶²è·¯ä¾å»ºç«èç¾çç¸éçä»¤ççè¨æ¶è¯ç¹«ï¼ä¸¦æ¡ç¨å ±åéæ®è²ç¾å¾·ç¶²è·¯ä¾æª¢ç´¢å ±åè¨æ¶è³è¨ãéåéç¨æå©æ¼åºæ¼å¤§åèªè¨æ¨¡åçæé«åè³ªçå ±åï¼ä¸¦å¨åæ¬ IU X å°ç·ãMIMIC-CXR å Chexpert Plus å¨å§çå¤ååºæºè³æéä¸å¯¦ç¾äºæåé²çæè½ãæ­¤é å·¥ä½çåå§ç¢¼å·²ç¼ä½å¨\url{https://github.com/Event-AHU/Medical_Image_Analysis}ã

##### **Existential Crisis: A Social Robot's Reason for Being**
2501.03376v1 by Dora Medgyesy, Joella Galas, Julian van Pol, Rustam Eynaliyev, Thijs Vollebregt

As Robots become ever more important in our daily lives there's growing need
for understanding how they're perceived by people. This study aims to
investigate how the user perception of robots is influenced by displays of
personality. Using LLMs and speech to text technology, we designed a
within-subject study to compare two conditions: a personality-driven robot and
a purely task-oriented, personality-neutral robot. Twelve participants,
recruited from Socially Intelligent Robotics course at Vrije Universiteit
Amsterdam, interacted with a robot Nao tasked with asking them a set of medical
questions under both conditions. After completing both interactions, the
participants completed a user experience questionnaire measuring their
emotional states and robot perception using standardized questionnaires from
the SRI and Psychology literature.

æè¦ï¼é¨èæ©å¨äººå¨æåæ¥å¸¸çæ´»ä¸­çéè¦æ§æ¥çæåï¼å°æ¼äºè§£äººåå¦ä½æç¥æ©å¨äººçéæ±ä¹æ¥çå¢å ãæ¬ç ç©¶æ¨å¨æ¢è¨æ©å¨äººçä½¿ç¨èæç¥å¦ä½åå°äººæ ¼è¡¨ç¾çå½±é¿ãæåä½¿ç¨å¤§åèªè¨æ¨¡å (LLM) åèªé³è½æå­æè¡ï¼è¨­è¨äºä¸é åè©¦èå§ç ç©¶ï¼ä»¥æ¯è¼å©ç¨®ææ³ï¼ä¸ç¨®æ¯äººæ ¼é©åçæ©å¨äººï¼å¦ä¸ç¨®æ¯ç´ç²¹ä»¥ä»»åçºå°åãäººæ ¼ä¸­ç«çæ©å¨äººãæåå¾é¿å§æ¯ç¹ä¸¹èªç±å¤§å­¸çç¤¾äº¤æºè½æ©å¨äººèª²ç¨ä¸­æåäº 12 ååèèï¼ä»åèæ©å¨äºº Nao äºåï¼å¨å©ç¨®ææ³ä¸é½åä»åè©¢åä¸ç³»åé«çåé¡ãå¨å®æéå©ç¨®äºåå¾ï¼åèèå®æäºä¸ä»½ä½¿ç¨èé«é©åå·ï¼ä½¿ç¨ä¾èª SRI åå¿çå­¸æç»çæ¨æºååå·æ¸¬éä»åçæç·çæåæ©å¨äººæç¥ã

##### **Label-free Concept Based Multiple Instance Learning for Gigapixel Histopathology**
2501.02922v1 by Susu Sun, Leslie Tessier, FrÃ©dÃ©rique Meeuwsen, ClÃ©ment Grisi, Dominique van Midden, Geert Litjens, Christian F. Baumgartner

Multiple Instance Learning (MIL) methods allow for gigapixel Whole-Slide
Image (WSI) analysis with only slide-level annotations. Interpretability is
crucial for safely deploying such algorithms in high-stakes medical domains.
Traditional MIL methods offer explanations by highlighting salient regions.
However, such spatial heatmaps provide limited insights for end users. To
address this, we propose a novel inherently interpretable WSI-classification
approach that uses human-understandable pathology concepts to generate
explanations. Our proposed Concept MIL model leverages recent advances in
vision-language models to directly predict pathology concepts based on image
features. The model's predictions are obtained through a linear combination of
the concepts identified on the top-K patches of a WSI, enabling inherent
explanations by tracing each concept's influence on the prediction. In contrast
to traditional concept-based interpretable models, our approach eliminates the
need for costly human annotations by leveraging the vision-language model. We
validate our method on two widely used pathology datasets: Camelyon16 and
PANDA. On both datasets, Concept MIL achieves AUC and accuracy scores over 0.9,
putting it on par with state-of-the-art models. We further find that 87.1\%
(Camelyon16) and 85.3\% (PANDA) of the top 20 patches fall within the tumor
region. A user study shows that the concepts identified by our model align with
the concepts used by pathologists, making it a promising strategy for
human-interpretable WSI classification.

æè¦ï¼å¤å¯¦ä¾å­¸ç¿ (MIL) æ¹æ³åä½¿ç¨ç»çå±¤ç´è¨»è§£ï¼å³å¯é²è¡ååç´ å¨ç»çå½±å (WSI) åæãå¯è§£éæ§å°æ¼å¨é«é¢¨éªé«çé åå®å¨é¨ç½²æ­¤é¡æ¼ç®æ³è³ééè¦ãå³çµ±ç MIL æ¹æ³ééå¼·èª¿é¡¯èååä¾æä¾èªªæãç¶èï¼æ­¤é¡ç©ºéç±åçºæçµä½¿ç¨èæä¾çè¦è§£æéãçºäºè§£æ±ºæ­¤åé¡ï¼æåæåºäºä¸ç¨®æ°ç©ä¸æ¬è³ªä¸å¯è§£éç WSI åé¡æ¹æ³ï¼è©²æ¹æ³ä½¿ç¨äººé¡å¯çè§£çççæ¦å¿µä¾ç¢çèªªæãæåæåºçæ¦å¿µ MIL æ¨¡åå©ç¨è¦è¦ºèªè¨æ¨¡åçææ°é²å±ï¼æ ¹æå½±åç¹å¾µç´æ¥é æ¸¬ççæ¦å¿µãè©²æ¨¡åçé æ¸¬æ¯ééç·æ§çµå WSI é é¨ K ååå¡ä¸è­å¥çæ¦å¿µèç²å¾çï¼ééè¿½è¹¤æ¯åæ¦å¿µå°é æ¸¬çå½±é¿ï¼å¯ä»¥æä¾å§å¨èªªæãèå³çµ±åºæ¼æ¦å¿µçå¯è§£éæ¨¡åç¸æ¯ï¼æåçåæ³ééå©ç¨è¦è¦ºèªè¨æ¨¡åï¼æ¶é¤äºå°æè²´çäººå·¥è¨»è§£çéæ±ãæåå¨å©åå»£æ³ä½¿ç¨çççè³æéï¼Camelyon16 å PANDA ä¸é©è­äºæåçæ¨¡åãå¨å©åè³æéä¸ï¼æ¦å¿µ MIL ç AUC åæºç¢ºçé½è¶é 0.9ï¼èæåé²çæ¨¡åä¸ç¸ä¸ä¸ãæåé²ä¸æ­¥ç¼ç¾ï¼å 20 ååå¡ä¸­æ 87.1%ï¼Camelyon16ï¼å 85.3%ï¼PANDAï¼è½å¨è«ç¤ååå§ãä¸é ä½¿ç¨èç ç©¶è¡¨æï¼æåçæ¨¡åè­å¥çæ¦å¿µèççå­¸å®¶ä½¿ç¨çæ¦å¿µä¸è´ï¼ä½¿å¶æçºäººé¡å¯è§£é WSI åé¡çä¸ç¨®æåéçç­ç¥ã

