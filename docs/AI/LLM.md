
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-12-11**|**GPD-1: Generative Pre-training for Driving**|Zixun Xie et.al.|[2412.08643v1](http://arxiv.org/abs/2412.08643v1)|[link](https://github.com/wzzheng/gpd)|
|**2024-12-11**|**Fast Prompt Alignment for Text-to-Image Generation**|Khalil Mrini et.al.|[2412.08639v1](http://arxiv.org/abs/2412.08639v1)|[link](https://github.com/tiktok/fast_prompt_alignment)|
|**2024-12-11**|**DMin: Scalable Training Data Influence Estimation for Diffusion Models**|Huawei Lin et.al.|[2412.08637v1](http://arxiv.org/abs/2412.08637v1)|[link](https://github.com/huawei-lin/DMin)|
|**2024-12-11**|**Multimodal Latent Language Modeling with Next-Token Diffusion**|Yutao Sun et.al.|[2412.08635v1](http://arxiv.org/abs/2412.08635v1)|null|
|**2024-12-11**|**Synthetic Vision: Training Vision-Language Models to Understand Physics**|Vahid Balazadeh et.al.|[2412.08619v1](http://arxiv.org/abs/2412.08619v1)|null|
|**2024-12-11**|**Image Retrieval Methods in the Dissimilarity Space**|Madhu Kiran et.al.|[2412.08618v1](http://arxiv.org/abs/2412.08618v1)|null|
|**2024-12-11**|**Exploiting the Index Gradients for Optimization-Based Jailbreaking on Large Language Models**|Jiahui Li et.al.|[2412.08615v1](http://arxiv.org/abs/2412.08615v1)|null|
|**2024-12-11**|**Competition and Diversity in Generative AI**|Manish Raghavan et.al.|[2412.08610v1](http://arxiv.org/abs/2412.08610v1)|[link](https://github.com/mraghavan/llm-scattergories)|
|**2024-12-11**|**AdvWave: Stealthy Adversarial Jailbreak Attack against Large Audio-Language Models**|Mintong Kang et.al.|[2412.08608v1](http://arxiv.org/abs/2412.08608v1)|null|
|**2024-12-11**|**Preference Discerning with LLM-Enhanced Generative Retrieval**|Fabian Paischer et.al.|[2412.08604v1](http://arxiv.org/abs/2412.08604v1)|null|
|**2024-12-11**|**Der Effizienz- und Intelligenzbegriff in der Lexikographie und kuenstlichen Intelligenz: kann ChatGPT die lexikographische Textsorte nachbilden?**|Ivan Arias-Arias et.al.|[2412.08599v1](http://arxiv.org/abs/2412.08599v1)|null|
|**2024-12-11**|**RoomTour3D: Geometry-Aware Video-Instruction Tuning for Embodied Navigation**|Mingfei Han et.al.|[2412.08591v1](http://arxiv.org/abs/2412.08591v1)|null|
|**2024-12-11**|**Advancing Single- and Multi-task Text Classification through Large Language Model Fine-tuning**|Hang Zhao et.al.|[2412.08587v1](http://arxiv.org/abs/2412.08587v1)|null|
|**2024-12-11**|**TURBOATTENTION: Efficient Attention Approximation For High Throughputs LLMs**|Hao Kang et.al.|[2412.08585v1](http://arxiv.org/abs/2412.08585v1)|null|
|**2024-12-11**|**Machine Learning Information Retrieval and Summarisation to Support Systematic Review on Outcomes Based Contracting**|Iman Munire Bilal et.al.|[2412.08578v1](http://arxiv.org/abs/2412.08578v1)|null|
|**2024-12-11**|**GenPlan: Generative sequence models as adaptive planners**|Akash Karthikeyan et.al.|[2412.08565v1](http://arxiv.org/abs/2412.08565v1)|null|
|**2024-12-11**|**Can We Generate Visual Programs Without Prompting LLMs?**|Michal Shlapentokh-Rothman et.al.|[2412.08564v1](http://arxiv.org/abs/2412.08564v1)|null|
|**2024-12-11**|**Bilevel Joint Unsupervised and Supervised Training for Automatic Speech Recognition**|Xiaodong Cui et.al.|[2412.08548v1](http://arxiv.org/abs/2412.08548v1)|null|
|**2024-12-11**|**MaestroMotif: Skill Design from Artificial Intelligence Feedback**|Martin Klissarov et.al.|[2412.08542v1](http://arxiv.org/abs/2412.08542v1)|null|
|**2024-12-11**|**TECO: Improving Multimodal Intent Recognition with Text Enhancement through Commonsense Knowledge Extraction**|Quynh-Mai Thi Nguyen et.al.|[2412.08529v1](http://arxiv.org/abs/2412.08529v1)|null|
|**2024-12-11**|**Continual Learning for Encoder-only Language Models via a Discrete Key-Value Bottleneck**|Andor Diera et.al.|[2412.08528v1](http://arxiv.org/abs/2412.08528v1)|null|
|**2024-12-11**|**EMS: Adaptive Evict-then-Merge Strategy for Head-wise KV Cache Compression Based on Global-Local Importance**|Yingxin Li et.al.|[2412.08521v1](http://arxiv.org/abs/2412.08521v1)|null|
|**2024-12-11**|**GR-NLP-TOOLKIT: An Open-Source NLP Toolkit for Modern Greek**|Lefteris Loukas et.al.|[2412.08520v1](http://arxiv.org/abs/2412.08520v1)|[link](https://github.com/nlpaueb/gr-nlp-toolkit)|
|**2024-12-11**|**Bridging Relevance and Reasoning: Rationale Distillation in Retrieval-Augmented Generation**|Pengyue Jia et.al.|[2412.08519v1](http://arxiv.org/abs/2412.08519v1)|null|
|**2024-12-11**|**Enhancing Interpretability Through Loss-Defined Classification Objective in Structured Latent Spaces**|Daniel Geissler et.al.|[2412.08515v1](http://arxiv.org/abs/2412.08515v1)|null|
|**2024-12-11**|**REPEAT: Improving Uncertainty Estimation in Representation Learning Explainability**|Kristoffer K. Wickstrøm et.al.|[2412.08513v1](http://arxiv.org/abs/2412.08513v1)|[link](https://github.com/wickstrom/repeat)|
|**2024-12-11**|**Comparative Opinion Mining in Product Reviews: Multi-perspective Prompt-based Learning**|Hai-Yen Thi Nguyen et.al.|[2412.08508v1](http://arxiv.org/abs/2412.08508v1)|null|
|**2024-12-11**|**SuperCode: Sustainability PER AI-driven CO-DEsign**|P. Chris Broekema et.al.|[2412.08490v1](http://arxiv.org/abs/2412.08490v1)|null|
|**2024-12-11**|**Multi-perspective Alignment for Increasing Naturalness in Neural Machine Translation**|Huiyuan Lai et.al.|[2412.08473v1](http://arxiv.org/abs/2412.08473v1)|null|
|**2024-12-11**|**Bootstrapping Language-Guided Navigation Learning with Self-Refining Data Flywheel**|Zun Wang et.al.|[2412.08467v1](http://arxiv.org/abs/2412.08467v1)|[link](https://github.com/wz0919/vln-srdf)|
|**2024-12-11**|**IRL for Restless Multi-Armed Bandits with Applications in Maternal and Child Health**|Gauri Jain et.al.|[2412.08463v1](http://arxiv.org/abs/2412.08463v1)|[link](https://github.com/gjain234/whirl)|
|**2024-12-11**|**Federated Learning for Traffic Flow Prediction with Synthetic Data Augmentation**|Fermin Orozco et.al.|[2412.08460v1](http://arxiv.org/abs/2412.08460v1)|null|
|**2024-12-11**|**Efficient Rectification of Neuro-Symbolic Reasoning Inconsistencies by Abductive Reflection**|Wen-Chao Hu et.al.|[2412.08457v1](http://arxiv.org/abs/2412.08457v1)|null|
|**2024-12-11**|**TapeAgents: a Holistic Framework for Agent Development and Optimization**|Dzmitry Bahdanau et.al.|[2412.08445v1](http://arxiv.org/abs/2412.08445v1)|null|
|**2024-12-11**|**Proactive Model Adaptation Against Concept Drift for Online Time Series Forecasting**|Lifan Zhao et.al.|[2412.08435v1](http://arxiv.org/abs/2412.08435v1)|null|
|**2024-12-11**|**Mitigating Out-of-Entity Errors in Named Entity Recognition: A Sentence-Level Strategy**|Guochao Jiang et.al.|[2412.08434v1](http://arxiv.org/abs/2412.08434v1)|null|
|**2024-12-11**|**Assessing Personalized AI Mentoring with Large Language Models in the Computing Field**|Xiao Luo et.al.|[2412.08430v1](http://arxiv.org/abs/2412.08430v1)|null|
|**2024-12-11**|**SwarmGPT-Primitive: A Language-Driven Choreographer for Drone Swarms Using Safe Motion Primitive Composition**|Vedant Vyas et.al.|[2412.08428v1](http://arxiv.org/abs/2412.08428v1)|null|
|**2024-12-11**|**Detecting Conversational Mental Manipulation with Intent-Aware Prompting**|Jiayuan Ma et.al.|[2412.08414v1](http://arxiv.org/abs/2412.08414v1)|[link](https://github.com/anton-jiayuan-ma/manip-iap)|
|**2024-12-11**|**Learning to Reason via Self-Iterative Process Feedback for Small Language Models**|Kaiyuan Chen et.al.|[2412.08393v1](http://arxiv.org/abs/2412.08393v1)|null|
|**2024-12-11**|**The Roles of English in Evaluating Multilingual Language Models**|Wessel Poelman et.al.|[2412.08392v1](http://arxiv.org/abs/2412.08392v1)|null|
|**2024-12-11**|**SweetieChat: A Strategy-Enhanced Role-playing Framework for Diverse Scenarios Handling Emotional Support Agent**|Jing Ye et.al.|[2412.08389v1](http://arxiv.org/abs/2412.08389v1)|null|
|**2024-12-11**|**NyayaAnumana & INLegalLlama: The Largest Indian Legal Judgment Prediction Dataset and Specialized Language Model for Enhanced Decision Analysis**|Shubham Kumar Nigam et.al.|[2412.08385v1](http://arxiv.org/abs/2412.08385v1)|null|
|**2024-12-11**|**HyViLM: Enhancing Fine-Grained Recognition with a Hybrid Encoder for Vision-Language Models**|Shiding Zhu et.al.|[2412.08378v1](http://arxiv.org/abs/2412.08378v1)|null|
|**2024-12-11**|**SmolTulu: Higher Learning Rate to Batch Size Ratios Can Lead to Better Reasoning in SLMs**|Sultan Alrashed et.al.|[2412.08347v1](http://arxiv.org/abs/2412.08347v1)|null|
|**2024-12-11**|**BEIR-NL: Zero-shot Information Retrieval Benchmark for the Dutch Language**|Nikolay Banar et.al.|[2412.08329v1](http://arxiv.org/abs/2412.08329v1)|null|
|**2024-12-11**|**Large Language Models Still Face Challenges in Multi-Hop Reasoning with External Knowledge**|Haotong Zhang et.al.|[2412.08317v1](http://arxiv.org/abs/2412.08317v1)|null|
|**2024-12-11**|**Rumor Detection on Social Media with Temporal Propagation Structure Optimization**|Xingyu Peng et.al.|[2412.08316v1](http://arxiv.org/abs/2412.08316v1)|null|
|**2024-12-11**|**Self-Refining Diffusion Samplers: Enabling Parallelization via Parareal Iterations**|Nikil Roashan Selvam et.al.|[2412.08292v1](http://arxiv.org/abs/2412.08292v1)|[link](https://github.com/nikilrselvam/srds)|
|**2024-12-11**|**Code LLMs: A Taxonomy-based Survey**|Nishat Raihan et.al.|[2412.08291v1](http://arxiv.org/abs/2412.08291v1)|null|
|**2024-12-11**|**Adaptive Prompting for Continual Relation Extraction: A Within-Task Variance Perspective**|Minh Le et.al.|[2412.08285v1](http://arxiv.org/abs/2412.08285v1)|null|
|**2024-12-11**|**A Preliminary Analysis of Automatic Word and Syllable Prominence Detection in Non-Native Speech With Text-to-Speech Prosody Embeddings**|Anindita Mondal et.al.|[2412.08283v1](http://arxiv.org/abs/2412.08283v1)|null|
|**2024-12-11**|**Y-NQ: English-Yorùbá Evaluation dataset for Open-Book Reading Comprehension and Text Generation**|Marta R. Costa-jussà et.al.|[2412.08279v1](http://arxiv.org/abs/2412.08279v1)|null|
|**2024-12-11**|**2M-BELEBELE: Highly Multilingual Speech and American Sign Language Comprehension Dataset**|Marta R. Costa-jussà et.al.|[2412.08274v1](http://arxiv.org/abs/2412.08274v1)|null|
|**2024-12-11**|**Position-aware Guided Point Cloud Completion with CLIP Model**|Feng Zhou et.al.|[2412.08271v1](http://arxiv.org/abs/2412.08271v1)|null|
|**2024-12-11**|**LCFO: Long Context and Long Form Output Dataset and Benchmarking**|Marta R. Costa-jussà et.al.|[2412.08268v1](http://arxiv.org/abs/2412.08268v1)|null|
|**2024-12-11**|**Discrete Subgraph Sampling for Interpretable Graph based Visual Question Answering**|Pascal Tilli et.al.|[2412.08263v1](http://arxiv.org/abs/2412.08263v1)|[link](https://github.com/digitalphonetics/intrinsic-subgraph-generation-for-vqa)|
|**2024-12-11**|**FLIP: Flow-Centric Generative Planning for General-Purpose Manipulation Tasks**|Chongkai Gao et.al.|[2412.08261v1](http://arxiv.org/abs/2412.08261v1)|null|
|**2024-12-11**|**Large Language Models for Scholarly Ontology Generation: An Extensive Analysis in the Engineering Field**|Tanay Aggarwal et.al.|[2412.08258v1](http://arxiv.org/abs/2412.08258v1)|[link](https://github.com/ImTanay/LLM-Automatic-Ontology-Generation)|
|**2024-12-11**|**Accurate Medical Named Entity Recognition Through Specialized NLP Models**|Jiacheng Hu et.al.|[2412.08255v1](http://arxiv.org/abs/2412.08255v1)|null|
|**2024-12-11**|**TouchTTS: An Embarrassingly Simple TTS Framework that Everyone Can Touch**|Xingchen Song et.al.|[2412.08237v1](http://arxiv.org/abs/2412.08237v1)|null|
|**2024-12-11**|**Generate Any Scene: Evaluating and Improving Text-to-Vision Generation with Scene Graph Programming**|Ziqi Gao et.al.|[2412.08221v1](http://arxiv.org/abs/2412.08221v1)|null|
|**2024-12-11**|**DocSum: Domain-Adaptive Pre-training for Document Abstractive Summarization**|Phan Phuong Mai Chau et.al.|[2412.08196v1](http://arxiv.org/abs/2412.08196v1)|null|
|**2024-12-11**|**Semantic Scene Completion Based 3D Traversability Estimation for Off-Road Terrains**|Zitong Chen et.al.|[2412.08195v1](http://arxiv.org/abs/2412.08195v1)|null|
|**2024-12-11**|**From communities to interpretable network and word embedding: an unified approach**|Thibault Prouteau et.al.|[2412.08187v1](http://arxiv.org/abs/2412.08187v1)|null|
|**2024-12-11**|**Auto-Generating Earnings Report Analysis via a Financial-Augmented LLM**|Van-Duc Le et.al.|[2412.08179v1](http://arxiv.org/abs/2412.08179v1)|null|
|**2024-12-11**|**Can Graph Neural Networks Learn Language with Extremely Weak Text Supervision?**|Zihao Li et.al.|[2412.08174v1](http://arxiv.org/abs/2412.08174v1)|null|
|**2024-12-11**|**Illusory VQA: Benchmarking and Enhancing Multimodal Models on Visual Illusions**|Mohammadmostafa Rostamkhani et.al.|[2412.08169v1](http://arxiv.org/abs/2412.08169v1)|[link](https://github.com/IllusoryVQA/IllusoryVQA)|
|**2024-12-11**|**NLPineers@ NLU of Devanagari Script Languages 2025: Hate Speech Detection using Ensembling of BERT-based models**|Anmol Guragain et.al.|[2412.08163v1](http://arxiv.org/abs/2412.08163v1)|null|
|**2024-12-11**|**How Vision-Language Tasks Benefit from Large Pre-trained Models: A Survey**|Yayun Qi et.al.|[2412.08158v1](http://arxiv.org/abs/2412.08158v1)|null|
|**2024-12-11**|**Antelope: Potent and Concealed Jailbreak Attack Strategy**|Xin Zhao et.al.|[2412.08156v1](http://arxiv.org/abs/2412.08156v1)|null|
|**2024-12-11**|**A Review of Intelligent Device Fault Diagnosis Technologies Based on Machine Vision**|Guiran Liu et.al.|[2412.08148v1](http://arxiv.org/abs/2412.08148v1)|null|
|**2024-12-11**|**How to Weight Multitask Finetuning? Fast Previews via Bayesian Model-Merging**|Hugo Monzón Maldonado et.al.|[2412.08147v1](http://arxiv.org/abs/2412.08147v1)|null|
|**2024-12-11**|**A Survey on Private Transformer Inference**|Yang Li et.al.|[2412.08145v1](http://arxiv.org/abs/2412.08145v1)|null|
|**2024-12-11**|**AGMixup: Adaptive Graph Mixup for Semi-supervised Node Classification**|Weigang Lu et.al.|[2412.08144v1](http://arxiv.org/abs/2412.08144v1)|null|
|**2024-12-11**|**Wasserstein Distance Rivals Kullback-Leibler Divergence for Knowledge Distillation**|Jiaming Lv et.al.|[2412.08139v1](http://arxiv.org/abs/2412.08139v1)|null|
|**2024-12-11**|**Learn How to Query from Unlabeled Data Streams in Federated Learning**|Yuchang Sun et.al.|[2412.08138v1](http://arxiv.org/abs/2412.08138v1)|[link](https://github.com/hiyuchang/leadq)|
|**2024-12-11**|**DiffRaman: A Conditional Latent Denoising Diffusion Probabilistic Model for Bacterial Raman Spectroscopy Identification Under Limited Data Conditions**|Haiming Yao et.al.|[2412.08131v1](http://arxiv.org/abs/2412.08131v1)|null|
|**2024-12-11**|**Evil twins are not that evil: Qualitative insights into machine-generated prompts**|Nathanaël Carraz Rakotonirina et.al.|[2412.08127v1](http://arxiv.org/abs/2412.08127v1)|null|
|**2024-12-11**|**Progressive Multi-granular Alignments for Grounded Reasoning in Large Vision-Language Models**|Quang-Hung Le et.al.|[2412.08125v1](http://arxiv.org/abs/2412.08125v1)|null|
|**2024-12-11**|**LatentSpeech: Latent Diffusion for Text-To-Speech Generation**|Haowei Lou et.al.|[2412.08117v1](http://arxiv.org/abs/2412.08117v1)|null|
|**2024-12-11**|**Aligner-Guided Training Paradigm: Advancing Text-to-Speech Models with Aligner Guided Duration**|Haowei Lou et.al.|[2412.08112v1](http://arxiv.org/abs/2412.08112v1)|null|
|**2024-12-11**|**Seeing Syntax: Uncovering Syntactic Learning Limitations in Vision-Language Models**|Sri Harsha Dumpala et.al.|[2412.08111v1](http://arxiv.org/abs/2412.08111v1)|null|
|**2024-12-11**|**Barking Up The Syntactic Tree: Enhancing VLM Training with Syntactic Losses**|Jiayun Luo et.al.|[2412.08110v1](http://arxiv.org/abs/2412.08110v1)|null|
|**2024-12-11**|**Unseen Horizons: Unveiling the Real Capability of LLM Code Generation Beyond the Familiar**|Yuanliang Zhang et.al.|[2412.08109v1](http://arxiv.org/abs/2412.08109v1)|null|
|**2024-12-11**|**Doubly-Universal Adversarial Perturbations: Deceiving Vision-Language Models Across Both Images and Text with a Single Perturbation**|Hee-Seon Kim et.al.|[2412.08108v1](http://arxiv.org/abs/2412.08108v1)|null|
|**2024-12-11**|**Adversarial Vulnerabilities in Large Language Models for Time Series Forecasting**|Fuqiang Liu et.al.|[2412.08099v1](http://arxiv.org/abs/2412.08099v1)|null|
|**2024-12-11**|**What You See Is Not Always What You Get: An Empirical Study of Code Comprehension by Large Language Models**|Bangshuo Zhu et.al.|[2412.08098v1](http://arxiv.org/abs/2412.08098v1)|null|
|**2024-12-11**|**Multilingual LLMs Inherently Reward In-Language Time-Sensitive Semantic Alignment for Low-Resource Languages**|Ashutosh Bajpai et.al.|[2412.08090v1](http://arxiv.org/abs/2412.08090v1)|null|
|**2024-12-11**|**How to select slices for annotation to train best-performing deep learning segmentation models for cross-sectional medical images?**|Yixin Zhang et.al.|[2412.08081v1](http://arxiv.org/abs/2412.08081v1)|null|
|**2024-12-11**|**Using Large Language Models for Parametric Shape Optimization**|Xinxin Zhang et.al.|[2412.08072v1](http://arxiv.org/abs/2412.08072v1)|null|
|**2024-12-11**|**DialogAgent: An Auto-engagement Agent for Code Question Answering Data Production**|Xiaoyun Liang et.al.|[2412.08069v1](http://arxiv.org/abs/2412.08069v1)|null|
|**2024-12-11**|**Repository-Level Graph Representation Learning for Enhanced Security Patch Detection**|Xin-Cheng Wen et.al.|[2412.08068v1](http://arxiv.org/abs/2412.08068v1)|[link](https://github.com/Xin-Cheng-Wen/RepoSPD)|
|**2024-12-11**|**ContextModule: Improving Code Completion via Repository-level Contextual Information**|Zhanming Guan et.al.|[2412.08063v1](http://arxiv.org/abs/2412.08063v1)|null|
|**2024-12-11**|**Go-Oracle: Automated Test Oracle for Go Concurrency Bugs**|Foivos Tsimpourlas et.al.|[2412.08061v1](http://arxiv.org/abs/2412.08061v1)|null|
|**2024-12-11**|**Federated In-Context LLM Agent Learning**|Panlong Wu et.al.|[2412.08054v1](http://arxiv.org/abs/2412.08054v1)|null|
|**2024-12-11**|**DynamicPAE: Generating Scene-Aware Physical Adversarial Examples in Real-Time**|Jin Hu et.al.|[2412.08053v1](http://arxiv.org/abs/2412.08053v1)|null|
|**2024-12-11**|**M2SE: A Multistage Multitask Instruction Tuning Strategy for Unified Sentiment and Emotion Analysis**|Ao Li et.al.|[2412.08049v1](http://arxiv.org/abs/2412.08049v1)|null|
|**2024-12-11**|**Bootstrapping Heterogeneous Graph Representation Learning via Large Language Models: A Generalized Approach**|Hang Gao et.al.|[2412.08038v1](http://arxiv.org/abs/2412.08038v1)|null|
|**2024-12-11**|**TinyThinker: Distilling Reasoning through Coarse-to-Fine Knowledge Internalization with Self-Reflection**|Shengmin Piao et.al.|[2412.08024v1](http://arxiv.org/abs/2412.08024v1)|null|

#### Abstracts
##### **GPD-1: Generative Pre-training for Driving**
2412.08643v1 by Zixun Xie, Sicheng Zuo, Wenzhao Zheng, Yunpeng Zhang, Dalong Du, Jie Zhou, Jiwen Lu, Shanghang Zhang

Modeling the evolutions of driving scenarios is important for the evaluation
and decision-making of autonomous driving systems. Most existing methods focus
on one aspect of scene evolution such as map generation, motion prediction, and
trajectory planning. In this paper, we propose a unified Generative
Pre-training for Driving (GPD-1) model to accomplish all these tasks altogether
without additional fine-tuning. We represent each scene with ego, agent, and
map tokens and formulate autonomous driving as a unified token generation
problem. We adopt the autoregressive transformer architecture and use a
scene-level attention mask to enable intra-scene bi-directional interactions.
For the ego and agent tokens, we propose a hierarchical positional tokenizer to
effectively encode both 2D positions and headings. For the map tokens, we train
a map vector-quantized autoencoder to efficiently compress ego-centric semantic
maps into discrete tokens. We pre-train our GPD-1 on the large-scale nuPlan
dataset and conduct extensive experiments to evaluate its effectiveness. With
different prompts, our GPD-1 successfully generalizes to various tasks without
finetuning, including scene generation, traffic simulation, closed-loop
simulation, map prediction, and motion planning. Code:
https://github.com/wzzheng/GPD.

摘要：模擬駕駛場景的演進對於評估和決策自動駕駛系統非常重要。現有的方法大多專注於場景演進的一個面向，例如地圖生成、運動預測和軌跡規劃。在本文中，我們提出了一個統一的生成式駕駛預訓練 (GPD-1) 模型，可以同時完成所有這些任務，而無需額外的微調。我們使用自我、代理和地圖符號表示每個場景，並將自動駕駛表述為一個統一的符號生成問題。我們採用自迴歸Transformer架構，並使用場景級別的注意力遮罩來啟用場景內雙向交互。對於自我和代理符號，我們提出了一個分層位置標記器，以有效編碼 2D 位置和標題。對於地圖符號，我們訓練了一個地圖向量量化的自動編碼器，以有效地將以自我為中心的語義地圖壓縮成離散符號。我們在大型 nuPlan 資料集上預訓練我們的 GPD-1，並進行廣泛的實驗來評估其有效性。透過不同的提示，我們的 GPD-1 成功地推廣到各種任務，而無需微調，包括場景生成、交通模擬、閉環模擬、地圖預測和運動規劃。程式碼：
https://github.com/wzzheng/GPD。

##### **Fast Prompt Alignment for Text-to-Image Generation**
2412.08639v1 by Khalil Mrini, Hanlin Lu, Linjie Yang, Weilin Huang, Heng Wang

Text-to-image generation has advanced rapidly, yet aligning complex textual
prompts with generated visuals remains challenging, especially with intricate
object relationships and fine-grained details. This paper introduces Fast
Prompt Alignment (FPA), a prompt optimization framework that leverages a
one-pass approach, enhancing text-to-image alignment efficiency without the
iterative overhead typical of current methods like OPT2I. FPA uses large
language models (LLMs) for single-iteration prompt paraphrasing, followed by
fine-tuning or in-context learning with optimized prompts to enable real-time
inference, reducing computational demands while preserving alignment fidelity.
Extensive evaluations on the COCO Captions and PartiPrompts datasets
demonstrate that FPA achieves competitive text-image alignment scores at a
fraction of the processing time, as validated through both automated metrics
(TIFA, VQA) and human evaluation. A human study with expert annotators further
reveals a strong correlation between human alignment judgments and automated
scores, underscoring the robustness of FPA's improvements. The proposed method
showcases a scalable, efficient alternative to iterative prompt optimization,
enabling broader applicability in real-time, high-demand settings. The codebase
is provided to facilitate further research:
https://github.com/tiktok/fast_prompt_alignment

摘要：文本到圖像生成技術已快速進步，但將複雜的文字提示與生成的視覺效果對齊仍然具有挑戰性，特別是在複雜的物件關係和細微的細節方面。本文介紹了快速提示對齊 (FPA)，這是一個提示最佳化框架，它利用一站式方法來提升文字到圖像對齊效率，而無需像 OPT2I 等現行方法常見的重複開銷。FPA 使用大型語言模型 (LLM) 進行單次迭代提示改寫，然後使用最佳化提示進行微調或情境學習，以實現即時推論，從而降低運算需求，同時保持對齊保真度。在 COCO Captions 和 PartiPrompts 資料集上的廣泛評估表明，FPA 在處理時間的一小部分內實現了具有競爭力的文字圖像對齊分數，這通過自動化指標 (TIFA、VQA) 和人工評估得到驗證。與專家註解員進行的人類研究進一步揭示了人類對齊判斷與自動化分數之間的強相關性，這突顯了 FPA 改進的穩健性。所提出的方法展示了一種可擴充、高效的迭代提示最佳化替代方案，可在實時、高需求的設定中實現更廣泛的應用性。提供程式碼庫以利於進一步研究：
https://github.com/tiktok/fast_prompt_alignment

##### **DMin: Scalable Training Data Influence Estimation for Diffusion Models**
2412.08637v1 by Huawei Lin, Yingjie Lao, Weijie Zhao

Identifying the training data samples that most influence a generated image
is a critical task in understanding diffusion models, yet existing influence
estimation methods are constrained to small-scale or LoRA-tuned models due to
computational limitations. As diffusion models scale up, these methods become
impractical. To address this challenge, we propose DMin (Diffusion Model
influence), a scalable framework for estimating the influence of each training
data sample on a given generated image. By leveraging efficient gradient
compression and retrieval techniques, DMin reduces storage requirements from
339.39 TB to only 726 MB and retrieves the top-k most influential training
samples in under 1 second, all while maintaining performance. Our empirical
results demonstrate DMin is both effective in identifying influential training
samples and efficient in terms of computational and storage requirements.

摘要：找出對生成影像影響最大的訓練資料範例，是了解擴散模型的重要任務，但現有的影響評估方法由於運算限制，僅限於小規模或 LoRA 調整過的模型。隨著擴散模型規模擴大，這些方法變得不切實際。為了應對這個挑戰，我們提出了 DMin（擴散模型影響），一個可擴充的架構，用於評估每個訓練資料範例對給定生成影像的影響。透過利用高效的梯度壓縮和檢索技術，DMin 將儲存需求從 339.39 TB 減少到僅 726 MB，並在不到 1 秒的時間內檢索出影響力最大的前 k 個訓練範例，同時還能維持效能。我們的實證結果證明，DMin 在找出有影響力的訓練範例方面既有效率，在運算和儲存需求方面也十分有效率。

##### **Multimodal Latent Language Modeling with Next-Token Diffusion**
2412.08635v1 by Yutao Sun, Hangbo Bao, Wenhui Wang, Zhiliang Peng, Li Dong, Shaohan Huang, Jianyong Wang, Furu Wei

Multimodal generative models require a unified approach to handle both
discrete data (e.g., text and code) and continuous data (e.g., image, audio,
video). In this work, we propose Latent Language Modeling (LatentLM), which
seamlessly integrates continuous and discrete data using causal Transformers.
Specifically, we employ a variational autoencoder (VAE) to represent continuous
data as latent vectors and introduce next-token diffusion for autoregressive
generation of these vectors. Additionally, we develop $\sigma$-VAE to address
the challenges of variance collapse, which is crucial for autoregressive
modeling. Extensive experiments demonstrate the effectiveness of LatentLM
across various modalities. In image generation, LatentLM surpasses Diffusion
Transformers in both performance and scalability. When integrated into
multimodal large language models, LatentLM provides a general-purpose interface
that unifies multimodal generation and understanding. Experimental results show
that LatentLM achieves favorable performance compared to Transfusion and vector
quantized models in the setting of scaling up training tokens. In
text-to-speech synthesis, LatentLM outperforms the state-of-the-art VALL-E 2
model in speaker similarity and robustness, while requiring 10x fewer decoding
steps. The results establish LatentLM as a highly effective and scalable
approach to advance large multimodal models.

摘要：多模态生成模型需要一种统一的方法来处理离散数据（例如文本和代码）和连续数据（例如图像、音频、视频）。在这项工作中，我们提出了潜在语言模型（LatentLM），它使用因果 Transformer 无缝地集成了连续数据和离散数据。具体来说，我们采用变分自动编码器 (VAE) 将连续数据表示为潜在向量，并引入下一个标记扩散来自动回归生成这些向量。此外，我们开发了 σ-VAE 来解决方差坍缩的挑战，这对自回归建模至关重要。广泛的实验表明 LatentLM 在各种模态中都很有效。在图像生成中，LatentLM 在性能和可扩展性方面都超越了扩散 Transformer。当集成到多模态大语言模型中时，LatentLM 提供了一个通用接口，它统一了多模态生成和理解。实验结果表明，在扩展训练标记的设置中，与 Transfusion 和矢量量化模型相比，LatentLM 实现了良好的性能。在文本到语音合成中，LatentLM 在说话者相似性和鲁棒性方面优于最先进的 VALL-E 2 模型，同时需要的解码步骤减少了 10 倍。结果表明 LatentLM 是一种非常有效且可扩展的方法，可以推进大型多模态模型。

##### **Synthetic Vision: Training Vision-Language Models to Understand Physics**
2412.08619v1 by Vahid Balazadeh, Mohammadmehdi Ataei, Hyunmin Cheong, Amir Hosein Khasahmadi, Rahul G. Krishnan

Physical reasoning, which involves the interpretation, understanding, and
prediction of object behavior in dynamic environments, remains a significant
challenge for current Vision-Language Models (VLMs). In this work, we propose
two methods to enhance VLMs' physical reasoning capabilities using simulated
data. First, we fine-tune a pre-trained VLM using question-answer (QA) pairs
generated from simulations relevant to physical reasoning tasks. Second, we
introduce Physics Context Builders (PCBs), specialized VLMs fine-tuned to
create scene descriptions enriched with physical properties and processes.
During physical reasoning tasks, these PCBs can be leveraged as context to
assist a Large Language Model (LLM) to improve its performance. We evaluate
both of our approaches using multiple benchmarks, including a new stability
detection QA dataset called Falling Tower, which includes both simulated and
real-world scenes, and CLEVRER. We demonstrate that a small QA fine-tuned VLM
can significantly outperform larger state-of-the-art foundational models. We
also show that integrating PCBs boosts the performance of foundational LLMs on
physical reasoning tasks. Using the real-world scenes from the Falling Tower
dataset, we also validate the robustness of both approaches in Sim2Real
transfer. Our results highlight the utility that simulated data can have in the
creation of learning systems capable of advanced physical reasoning.

摘要：物理推理涉及對動態環境中物體行為的解讀、理解和預測，仍然是當前視覺語言模型 (VLM) 的重大挑戰。在這項工作中，我們提出兩種方法，使用模擬數據增強 VLM 的物理推理能力。首先，我們使用與物理推理任務相關的模擬產生的問答 (QA) 對，微調預先訓練的 VLM。其次，我們引入了物理情境建構器 (PCB)，這是經過微調的專業 VLM，用於建立豐富了物理屬性和過程的情境描述。在物理推理任務期間，這些 PCB 可以作為情境，協助大型語言模型 (LLM) 改善其效能。我們使用多個基準對我們的兩種方法進行評估，包括一個稱為 Falling Tower 的新穩定性偵測 QA 資料集，其中包含模擬和真實世界的場景，以及 CLEVRER。我們證明了一個經過 QA 微調的小型 VLM 可以顯著優於更大的最先進基礎模型。我們還表明，整合 PCB 可以提升基礎 LLM 在物理推理任務上的效能。使用 Falling Tower 資料集中的真實世界場景，我們還驗證了兩種方法在 Sim2Real 轉移中的穩健性。我們的結果突顯了模擬數據在建立具備進階物理推理能力的學習系統中可能具有的效用。

##### **Image Retrieval Methods in the Dissimilarity Space**
2412.08618v1 by Madhu Kiran, Kartikey Vishnu, Rafael M. O. Cruz, Eric Granger

Image retrieval methods rely on metric learning to train backbone feature
extraction models that can extract discriminant queries and reference (gallery)
feature representations for similarity matching. Although state-of-the-art
accuracy has improved considerably with the advent of deep learning (DL) models
trained on large datasets, image retrieval remains challenging in many
real-world video analytics and surveillance applications, e.g., person
re-identification. Using the Euclidean space for matching limits the
performance in real-world applications due to the curse of dimensionality,
overfitting, and sensitivity to noisy data.
  We argue that the feature dissimilarity space is more suitable for similarity
matching, and propose a dichotomy transformation to project query and reference
embeddings into a single embedding in the dissimilarity space.
  We also advocate for end-to-end training of a backbone and binary
classification models for pair-wise matching. As opposed to comparing the
distance between queries and reference embeddings, we show the benefits of
classifying the single dissimilarity space embedding (as similar or
dissimilar), especially when trained end-to-end. We propose a method to train
the max-margin classifier together with the backbone feature extractor by
applying constraints to the L2 norm of the classifier weights along with the
hinge loss.
  Our extensive experiments on challenging image retrieval datasets and using
diverse feature extraction backbones highlight the benefits of similarity
matching in the dissimilarity space. In particular, when jointly training the
feature extraction backbone and regularised classifier for matching, the
dissimilarity space provides a higher level of accuracy.

摘要：影像擷取方法仰賴度量學習來訓練主幹特徵提取模型，此模型可以提取辨別式查詢和參考（圖庫）特徵表示，以進行相似度比對。雖然最先進的準確度已隨著在大型資料集上訓練的深度學習（DL）模型的出現而大幅提升，但在許多真實世界影片分析和監控應用程式中，影像擷取仍具有挑戰性，例如人員再辨識。由於維度災難、過度擬合和對雜訊資料的敏感性，使用歐幾里得空間進行比對會限制真實世界應用程式的效能。
我們主張特徵相異性空間更適合相似度比對，並提出二分法轉換，將查詢和參考嵌入投影到相異性空間中的單一嵌入。
我們也提倡對主幹和二元分類模型進行端到端訓練，以進行成對比對。與比較查詢和參考嵌入之間的距離相反，我們展示了對單一相異性空間嵌入（類似或相異）進行分類的好處，特別是在端到端訓練時。我們提出了一種方法，透過對分類器權重的 L2 範數套用約束，以及鉸鏈損失，來訓練最大邊際分類器和主幹特徵萃取器。
我們在具有挑戰性的影像擷取資料集上進行的廣泛實驗，並使用不同的特徵萃取主幹，突顯了在相異性空間中進行相似度比對的好處。特別是在聯合訓練特徵萃取主幹和正規化分類器以進行比對時，相異性空間提供了更高的準確度。

##### **Exploiting the Index Gradients for Optimization-Based Jailbreaking on Large Language Models**
2412.08615v1 by Jiahui Li, Yongchang Hao, Haoyu Xu, Xing Wang, Yu Hong

Despite the advancements in training Large Language Models (LLMs) with
alignment techniques to enhance the safety of generated content, these models
remain susceptible to jailbreak, an adversarial attack method that exposes
security vulnerabilities in LLMs. Notably, the Greedy Coordinate Gradient (GCG)
method has demonstrated the ability to automatically generate adversarial
suffixes that jailbreak state-of-the-art LLMs. However, the optimization
process involved in GCG is highly time-consuming, rendering the jailbreaking
pipeline inefficient. In this paper, we investigate the process of GCG and
identify an issue of Indirect Effect, the key bottleneck of the GCG
optimization. To this end, we propose the Model Attack Gradient Index GCG
(MAGIC), that addresses the Indirect Effect by exploiting the gradient
information of the suffix tokens, thereby accelerating the procedure by having
less computation and fewer iterations. Our experiments on AdvBench show that
MAGIC achieves up to a 1.5x speedup, while maintaining Attack Success Rates
(ASR) on par or even higher than other baselines. Our MAGIC achieved an ASR of
74% on the Llama-2 and an ASR of 54% when conducting transfer attacks on
GPT-3.5. Code is available at https://github.com/jiah-li/magic.

摘要：儘管在使用調整技術訓練大型語言模型 (LLM) 以增強所產生內容的安全性的過程中取得進展，但這些模型仍容易受到越獄攻擊，這是一種會暴露 LLM 中安全漏洞的對抗攻擊方法。值得注意的是，貪婪坐標梯度 (GCG) 方法已證明有能力自動產生對抗後綴，以越獄最先進的 LLM。然而，GCG 中涉及的最佳化過程非常耗時，導致越獄管道效率低下。在本文中，我們研究了 GCG 的過程，並找出間接效應的問題，這是 GCG 最佳化的關鍵瓶頸。為此，我們提出了模型攻擊梯度指標 GCG (MAGIC)，它透過利用後綴標記的梯度資訊來解決間接效應，從而透過減少運算和反覆運算來加速程序。我們在 AdvBench 上的實驗顯示，MAGIC 可將速度提升至 1.5 倍，同時維持攻擊成功率 (ASR) 與其他基線相當，甚至更高。我們的 MAGIC 在 Llama-2 上達到了 74% 的 ASR，在對 GPT-3.5 進行轉移攻擊時達到了 54% 的 ASR。程式碼可於 https://github.com/jiah-li/magic 取得。

##### **Competition and Diversity in Generative AI**
2412.08610v1 by Manish Raghavan

Recent evidence suggests that the use of generative artificial intelligence
reduces the diversity of content produced. In this work, we develop a
game-theoretic model to explore the downstream consequences of content
homogeneity when producers use generative AI to compete with one another. At
equilibrium, players indeed produce content that is less diverse than optimal.
However, stronger competition mitigates homogeneity and induces more diverse
production. Perhaps more surprisingly, we show that a generative AI model that
performs well in isolation (i.e., according to a benchmark) may fail to do so
when faced with competition, and vice versa. We validate our results
empirically by using language models to play Scattergories, a word game in
which players are rewarded for producing answers that are both correct and
unique. We discuss how the interplay between competition and homogeneity has
implications for the development, evaluation, and use of generative AI.

摘要：最近的證據表明，使用生成式人工智慧會減少產出內容的多樣性。在這項工作中，我們開發了一個博弈論模型來探討當生產者使用生成式人工智慧彼此競爭時，內容同質性的下游後果。在均衡狀態下，參與者確實會生產出多樣性低於最佳狀態的內容。然而，更強烈的競爭會減輕同質性並誘導更多樣化的生產。或許更令人驚訝的是，我們表明一個在孤立狀態下表現良好的生成式人工智慧模型（即根據基準），在面對競爭時可能無法表現良好，反之亦然。我們使用語言模型玩猜謎遊戲 Scattergories 來驗證我們的結果，這是一個單字遊戲，玩家因產生正確且獨特的答案而獲得獎勵。我們討論競爭和同質性之間的交互作用如何對生成式人工智慧的開發、評估和使用產生影響。

##### **AdvWave: Stealthy Adversarial Jailbreak Attack against Large Audio-Language Models**
2412.08608v1 by Mintong Kang, Chejian Xu, Bo Li

Recent advancements in large audio-language models (LALMs) have enabled
speech-based user interactions, significantly enhancing user experience and
accelerating the deployment of LALMs in real-world applications. However,
ensuring the safety of LALMs is crucial to prevent risky outputs that may raise
societal concerns or violate AI regulations. Despite the importance of this
issue, research on jailbreaking LALMs remains limited due to their recent
emergence and the additional technical challenges they present compared to
attacks on DNN-based audio models. Specifically, the audio encoders in LALMs,
which involve discretization operations, often lead to gradient shattering,
hindering the effectiveness of attacks relying on gradient-based optimizations.
The behavioral variability of LALMs further complicates the identification of
effective (adversarial) optimization targets. Moreover, enforcing stealthiness
constraints on adversarial audio waveforms introduces a reduced, non-convex
feasible solution space, further intensifying the challenges of the
optimization process. To overcome these challenges, we develop AdvWave, the
first jailbreak framework against LALMs. We propose a dual-phase optimization
method that addresses gradient shattering, enabling effective end-to-end
gradient-based optimization. Additionally, we develop an adaptive adversarial
target search algorithm that dynamically adjusts the adversarial optimization
target based on the response patterns of LALMs for specific queries. To ensure
that adversarial audio remains perceptually natural to human listeners, we
design a classifier-guided optimization approach that generates adversarial
noise resembling common urban sounds. Extensive evaluations on multiple
advanced LALMs demonstrate that AdvWave outperforms baseline methods, achieving
a 40% higher average jailbreak attack success rate.

摘要：<paragraph>大型語音語言模型 (LALM) 最近的進展已經實現了基於語音的使用者互動，大幅提升使用者體驗，並加速 LALM 在實際應用中的部署。不過，確保 LALM 的安全性至關重要，以防止產生有風險的輸出，這些輸出可能會引發社會問題或違反 AI 法規。儘管這個問題很重要，但由於 LALM 最近才出現，而且與針對基於深度神經網路 (DNN) 的音訊模型的攻擊相比，LALM 具有額外的技術挑戰，因此對 LALM 進行越獄的研究仍然有限。具體來說，LALM 中的音訊編碼器涉及離散化運算，這通常會導致梯度破碎，進而妨礙依賴於基於梯度的最佳化的攻擊的有效性。LALM 的行為變異性進一步複雜化了有效（對抗性）最佳化目標的識別。此外，對對抗性音訊波形施加隱蔽性約束會引入一個縮小的非凸可行解空間，進一步加劇了最佳化過程的挑戰。為了克服這些挑戰，我們開發了 AdvWave，這是針對 LALM 的第一個越獄架構。我們提出了一種雙階段最佳化方法，它可以解決梯度破碎問題，從而實現有效的端到端基於梯度的最佳化。此外，我們開發了一個適應性對抗目標搜尋演算法，它可以根據 LALM 對特定查詢的回應模式動態調整對抗性最佳化目標。為了確保對抗性音訊對人類聽眾來說在感知上仍然自然，我們設計了一種分類器引導的最佳化方法，它會產生類似於常見城市聲音的對抗性雜訊。在多個進階 LALM 上的廣泛評估證明，AdvWave 優於基準方法，達到了高出 40% 的平均越獄攻擊成功率。</paragraph>

##### **Preference Discerning with LLM-Enhanced Generative Retrieval**
2412.08604v1 by Fabian Paischer, Liu Yang, Linfeng Liu, Shuai Shao, Kaveh Hassani, Jiacheng Li, Ricky Chen, Zhang Gabriel Li, Xialo Gao, Wei Shao, Xue Feng, Nima Noorshams, Sem Park, Bo Long, Hamid Eghbalzadeh

Sequential recommendation systems aim to provide personalized recommendations
for users based on their interaction history. To achieve this, they often
incorporate auxiliary information, such as textual descriptions of items and
auxiliary tasks, like predicting user preferences and intent. Despite numerous
efforts to enhance these models, they still suffer from limited
personalization. To address this issue, we propose a new paradigm, which we
term preference discerning. In preference dscerning, we explicitly condition a
generative sequential recommendation system on user preferences within its
context. To this end, we generate user preferences using Large Language Models
(LLMs) based on user reviews and item-specific data. To evaluate preference
discerning capabilities of sequential recommendation systems, we introduce a
novel benchmark that provides a holistic evaluation across various scenarios,
including preference steering and sentiment following. We assess current
state-of-the-art methods using our benchmark and show that they struggle to
accurately discern user preferences. Therefore, we propose a new method named
Mender ($\textbf{M}$ultimodal Prefer$\textbf{en}$ce
$\textbf{d}$iscern$\textbf{er}$), which improves upon existing methods and
achieves state-of-the-art performance on our benchmark. Our results show that
Mender can be effectively guided by human preferences even though they have not
been observed during training, paving the way toward more personalized
sequential recommendation systems. We will open-source the code and benchmarks
upon publication.

摘要：序列推薦系統旨在根據使用者的互動記錄提供個人化推薦。為此，它們通常會納入輔助資訊，例如項目的文字描述和輔助任務，例如預測使用者偏好和意圖。儘管為增強這些模型付出了許多努力，但它們仍受到個人化有限的影響。為了解決這個問題，我們提出了一個新的範例，我們稱之為偏好辨識。在偏好辨識中，我們明確地將生成式序列推薦系統置於其內容中的使用者偏好之上。為此，我們根據使用者評論和特定於專案的資料，使用大型語言模型 (LLM) 來產生使用者偏好。為了評估序列推薦系統的偏好辨識能力，我們引入了一個新的基準，它提供了跨不同場景的整體評估，包括偏好導向和情緒追蹤。我們使用我們的基準評估了當前最先進的方法，並表明它們難以準確辨識使用者偏好。因此，我們提出了一種名為 Mender（**M**ultimodal Prefer**en**ce **d**iscern**er**）的新方法，它改進了現有方法，並在我們的基準上達到了最先進的效能。我們的結果表明，即使在訓練期間未觀察到人類偏好，Mender 也可以有效地受到人類偏好的指導，為更個人化的序列推薦系統鋪平了道路。我們將在發表後開放原始碼和基準。

##### **Der Effizienz- und Intelligenzbegriff in der Lexikographie und kuenstlichen Intelligenz: kann ChatGPT die lexikographische Textsorte nachbilden?**
2412.08599v1 by Ivan Arias-Arias, Maria Jose Dominguez Vazquez, Carlos Valcarcel Riveiro

By means of pilot experiments for the language pair German and Galician, this
paper examines the concept of efficiency and intelligence in lexicography and
artificial intelligence, AI. The aim of the experiments is to gain empirically
and statistically based insights into the lexicographical text type,dictionary
article, in the responses of ChatGPT 3.5, as well as into the lexicographical
data on which this chatbot was trained. Both quantitative and qualitative
methods are used for this purpose. The analysis is based on the evaluation of
the outputs of several sessions with the same prompt in ChatGPT 3.5. On the one
hand, the algorithmic performance of intelligent systems is evaluated in
comparison with data from lexicographical works. On the other hand, the ChatGPT
data supplied is analysed using specific text passages of the aforementioned
lexicographical text type. The results of this study not only help to evaluate
the efficiency of this chatbot regarding the creation of dictionary articles,
but also to delve deeper into the concept of intelligence, the thought
processes and the actions to be carried out in both disciplines.

摘要：透過德語和加利西亞語對語言的試驗，本文探討了詞彙學和人工智慧（AI）中的效率和智慧概念。實驗的目的是透過 ChatGPT 3.5 的回應，以及訓練這個聊天機器人的詞彙學資料，來獲得詞彙文本類型（字典條目）的經驗和統計見解。為此，我們使用定量和定性方法。分析是根據對 ChatGPT 3.5 中使用相同提示的幾個會話的輸出進行評估。一方面，我們評估了智慧系統的演算法效能，並與詞彙學著作的資料進行比較。另一方面，我們使用上述詞彙學文本類型的特定文字段落來分析提供的 ChatGPT 資料。這項研究的結果不僅有助於評估這個聊天機器人在建立字典條目方面的效率，還能更深入地探討智慧、思考過程以及在兩個領域中執行的行動。

##### **RoomTour3D: Geometry-Aware Video-Instruction Tuning for Embodied Navigation**
2412.08591v1 by Mingfei Han, Liang Ma, Kamila Zhumakhanova, Ekaterina Radionova, Jingyi Zhang, Xiaojun Chang, Xiaodan Liang, Ivan Laptev

Vision-and-Language Navigation (VLN) suffers from the limited diversity and
scale of training data, primarily constrained by the manual curation of
existing simulators. To address this, we introduce RoomTour3D, a
video-instruction dataset derived from web-based room tour videos that capture
real-world indoor spaces and human walking demonstrations. Unlike existing VLN
datasets, RoomTour3D leverages the scale and diversity of online videos to
generate open-ended human walking trajectories and open-world navigable
instructions. To compensate for the lack of navigation data in online videos,
we perform 3D reconstruction and obtain 3D trajectories of walking paths
augmented with additional information on the room types, object locations and
3D shape of surrounding scenes. Our dataset includes $\sim$100K open-ended
description-enriched trajectories with $\sim$200K instructions, and 17K
action-enriched trajectories from 1847 room tour environments. We demonstrate
experimentally that RoomTour3D enables significant improvements across multiple
VLN tasks including CVDN, SOON, R2R, and REVERIE. Moreover, RoomTour3D
facilitates the development of trainable zero-shot VLN agents, showcasing the
potential and challenges of advancing towards open-world navigation.

摘要：視覺語言導航 (VLN) 受到訓練資料的多樣性和規模限制，這主要是受到現有模擬器手動策劃的約束。為了解決這個問題，我們引入了 RoomTour3D，一個從網路上的房間導覽影片中衍生的影片指令資料集，該資料集擷取了真實世界的室內空間和人類行走示範。與現有的 VLN 資料集不同，RoomTour3D 利用線上影片的規模和多樣性來產生開放式的行走軌跡和開放世界的導航指令。為了彌補線上影片中導航資料的不足，我們執行 3D 重建，並取得行走路徑的 3D 軌跡，並加上房間類型、物件位置和周圍場景的 3D 形狀等額外資訊。我們的資料集包含大約 10 萬個開放式描述豐富的軌跡，其中有大約 20 萬個指令，以及來自 1847 個房間導覽環境的 1 萬 7 千個動作豐富的軌跡。我們透過實驗證明，RoomTour3D 能在多個 VLN 任務中帶來顯著的改善，包括 CVDN、SOON、R2R 和 REVERIE。此外，RoomTour3D 促進了可訓練的零次學習 VLN 代理的開發，展示了邁向開放世界導航的潛力和挑戰。

##### **Advancing Single- and Multi-task Text Classification through Large Language Model Fine-tuning**
2412.08587v1 by Hang Zhao, Qile P. Chen, Yijing Barry Zhang, Gang Yang

Both encoder-only models (e.g., BERT, RoBERTa) and large language models
(LLMs, e.g., Llama3) have been widely used for text classification tasks.
However, there is a lack of systematic studies comparing the performance of
encoder-based models and LLMs in text classification, particularly when
fine-tuning is involved. This study employed a diverse range of models and
methods, varying in size and architecture, and including both fine-tuned and
pre-trained approaches. We first assessed the performances of these LLMs on the
20 Newsgroups (20NG) and MASSIVE datasets, comparing them to encoder-only
RoBERTa models. Additionally, we explored the multi-task capabilities of both
model types by combining multiple classification tasks, including intent
detection and slot-filling, into a single model using data from both datasets.
Our results indicate that fully fine-tuned Llama3-70B models outperform
RoBERTa-large and other decoder LLMs across various classification tasks and
datasets. Moreover, the consolidated multi-task fine-tuned LLMs matched the
performance of dual-model setups in both tasks across both datasets. Overall,
our study provides a comprehensive benchmark of encoder-only and LLM models on
text classification tasks and demonstrates a method to combine two or more
fully fine-tuned decoder LLMs for reduced latency and equivalent performance.

摘要：<paragraph>僅編碼器模型（例如 BERT、RoBERTa）和大語言模型（LLM，例如 Llama3）已被廣泛用於文本分類任務。
然而，缺乏比較編碼器模型和 LLM 在文本分類中的效能的系統性研究，特別是在涉及微調時。本研究採用了各種不同的模型和方法，在大小和架構上有所不同，並且包括微調和預訓練方法。我們首先評估了這些 LLM 在 20 個新聞組 (20NG) 和 MASSIVE 資料集上的效能，並將其與僅編碼器 RoBERTa 模型進行比較。此外，我們透過將多個分類任務（包括意圖偵測和槽位填補）結合到一個模型中，使用來自兩個資料集的資料，探索了兩種模型類型的多任務功能。我們的結果表明，經過完全微調的 Llama3-70B 模型在各種分類任務和資料集上優於 RoBERTa-large 和其他解碼器 LLM。此外，合併的多任務微調 LLM 在兩個任務中都與雙模型設定的效能相匹配。總體而言，我們的研究提供了編碼器和 LLM 模型在文本分類任務上的全面基準，並展示了一種結合兩個或更多完全微調的解碼器 LLM 以降低延遲和等效效能的方法。</paragraph>

##### **TURBOATTENTION: Efficient Attention Approximation For High Throughputs LLMs**
2412.08585v1 by Hao Kang, Srikant Bharadwaj, James Hensman, Tushar Krishna, Victor Ruhle, Saravan Rajmohan

Large language model (LLM) inference demands significant amount of
computation and memory, especially in the key attention mechanism. While
techniques, such as quantization and acceleration algorithms, like
FlashAttention, have improved efficiency of the overall inference, they address
different aspects of the problem: quantization focuses on weight-activation
operations, while FlashAttention improves execution but requires high-precision
formats. Recent Key-value (KV) cache quantization reduces memory bandwidth but
still needs floating-point dequantization for attention operation.
  We present TurboAttention, a comprehensive approach to enable quantized
execution of attention that simultaneously addresses both memory and
computational efficiency. Our solution introduces two key innovations: FlashQ,
a headwise attention quantization technique that enables both compression of KV
cache and quantized execution of activation-activation multiplication, and
Sparsity-based Softmax Approximation (SAS), which eliminates the need for
dequantization to FP32 during exponentiation operation in attention.
Experimental results demonstrate that TurboAttention achieves 1.2-1.8x speedup
in attention, reduces the KV cache size by over 4.4x, and enables up to 2.37x
maximum throughput over the FP16 baseline while outperforming state-of-the-art
quantization and compression techniques across various datasets and models.

摘要：大型語言模型 (LLM) 推論需要大量的運算和記憶體，特別是在關鍵的注意力機制中。雖然量化和加速演算法等技術，例如 FlashAttention，已改善整體推論效率，但它們解決了問題的不同面向：量化專注於權重啟動操作，而 FlashAttention 則改善執行，但需要高精度格式。最近的 Key-value (KV) 快取量化減少了記憶體頻寬，但仍需要浮點去量化以進行注意力操作。
我們提出 TurboAttention，這是一種全面的方法，用於啟用注意力的量化執行，同時處理記憶體和運算效率。我們的解決方案引入了兩項關鍵創新：FlashQ，一種頭部注意力量化技術，可同時壓縮 KV 快取和啟用啟動乘法的量化執行，以及基於稀疏性的 Softmax 近似 (SAS)，它消除了在注意力中指數運算期間對 FP32 去量化的需求。
實驗結果表明，TurboAttention 在注意力方面實現了 1.2-1.8 倍的加速，將 KV 快取大小減少了 4.4 倍以上，並在各種資料集和模型上優於最先進的量化和壓縮技術，同時啟用了比 FP16 基線高達 2.37 倍的最大吞吐量。

##### **Machine Learning Information Retrieval and Summarisation to Support Systematic Review on Outcomes Based Contracting**
2412.08578v1 by Iman Munire Bilal, Zheng Fang, Miguel Arana-Catania, Felix-Anselm van Lier, Juliana Outes Velarde, Harry Bregazzi, Eleanor Carter, Mara Airoldi, Rob Procter

As academic literature proliferates, traditional review methods are
increasingly challenged by the sheer volume and diversity of available
research. This article presents a study that aims to address these challenges
by enhancing the efficiency and scope of systematic reviews in the social
sciences through advanced machine learning (ML) and natural language processing
(NLP) tools. In particular, we focus on automating stages within the systematic
reviewing process that are time-intensive and repetitive for human annotators
and which lend themselves to immediate scalability through tools such as
information retrieval and summarisation guided by expert advice. The article
concludes with a summary of lessons learnt regarding the integrated approach
towards systematic reviews and future directions for improvement, including
explainability.

摘要：隨著學術文獻的激增，傳統的審查方法越來越受到可用研究的龐大數量和多樣性的挑戰。本文提出了一項研究，旨在通過先進的機器學習 (ML) 和自然語言處理 (NLP) 工具來提高社會科學中系統性審查的效率和範圍，以應對這些挑戰。特別是，我們專注於自動化系統性審查過程中耗時且對人類註釋者來說重複的階段，這些階段本身就可以通過信息檢索和專家建議指導的摘要等工具立即實現可擴展性。本文最後總結了關於系統性審查的綜合方法和改進的未來方向（包括可解釋性）的經驗教訓。

##### **GenPlan: Generative sequence models as adaptive planners**
2412.08565v1 by Akash Karthikeyan, Yash Vardhan Pant

Offline reinforcement learning has shown tremendous success in behavioral
planning by learning from previously collected demonstrations. However,
decision-making in multitask missions still presents significant challenges.
For instance, a mission might require an agent to explore an unknown
environment, discover goals, and navigate to them, even if it involves
interacting with obstacles along the way. Such behavioral planning problems are
difficult to solve due to: a) agents failing to adapt beyond the single task
learned through their reward function, and b) the inability to generalize to
new environments not covered in the training demonstrations, e.g., environments
where all doors were unlocked in the demonstrations. Consequently,
state-of-the-art decision making methods are limited to missions where the
required tasks are well-represented in the training demonstrations and can be
solved within a short (temporal) planning horizon. To address this, we propose
GenPlan: a stochastic and adaptive planner that leverages discrete-flow models
for generative sequence modeling, enabling sample-efficient exploration and
exploitation. This framework relies on an iterative denoising procedure to
generate a sequence of goals and actions. This approach captures multi-modal
action distributions and facilitates goal and task discovery, thereby enhancing
generalization to out-of-distribution tasks and environments, i.e., missions
not part of the training data. We demonstrate the effectiveness of our method
through multiple simulation environments. Notably, GenPlan outperforms the
state-of-the-art methods by over 10% on adaptive planning tasks, where the
agent adapts to multi-task missions while leveraging demonstrations on
single-goal-reaching tasks.

摘要：<paragraph>離線強化學習已在行為規劃方面展現出巨大的成功，方法是從先前收集的示範中學習。然而，多任務任務中的決策制定仍帶來重大挑戰。例如，任務可能需要代理探索未知環境、發現目標並導航至目標，即使這涉及與沿途障礙物互動。此類行為規劃問題難以解決，原因有：a) 代理無法適應超出其獎勵函數所學到的單一任務，以及 b) 無法概括到訓練示範中未涵蓋的新環境，例如，在示範中所有門都已解鎖的環境。因此，最先進的決策制定方法僅限於訓練示範中充分呈現所需任務且可以在短（時間）規劃範圍內解決的任務。為了解決此問題，我們提出 GenPlan：一個隨機且自適應規劃器，它利用離散流模型進行生成序列建模，從而實現樣本有效探索和利用。此框架依賴於反覆的去噪程序，以產生目標和動作序列。此方法擷取多模態動作分佈，並促進目標和任務發現，從而增強對分布外任務和環境的概括，即，不屬於訓練數據的任務。我們透過多個模擬環境展示了我們方法的有效性。值得注意的是，在自適應規劃任務上，GenPlan 的表現優於最先進的方法超過 10%，其中代理適應多任務任務，同時利用單一目標到達任務的示範。</paragraph>

##### **Can We Generate Visual Programs Without Prompting LLMs?**
2412.08564v1 by Michal Shlapentokh-Rothman, Yu-Xiong Wang, Derek Hoiem

Visual programming prompts LLMs (large language mod-els) to generate
executable code for visual tasks like visual question answering (VQA).
Prompt-based methods are difficult to improve while also being unreliable and
costly in both time and money. Our goal is to develop an efficient visual
programming system without 1) using prompt-based LLMs at inference time and 2)
a large set of program and answer annotations. We develop a synthetic data
augmentation approach and alternative program generation method based on
decoupling programs into higher-level skills called templates and the
corresponding arguments. Our results show that with data augmentation,
prompt-free smaller LLMs ($\approx$ 1B parameters) are competitive with
state-of-the art models with the added benefit of much faster inference

摘要：視覺程式設計提示 LLM（大型語言模型）為視覺任務（例如視覺問答 (VQA)）產生可執行的程式碼。
提示式方法難以改進，而且在時間和金錢上既不可靠又昂貴。我們的目標是開發一個高效的視覺程式設計系統，不 1) 在推理時間使用提示式 LLM，以及 2) 大量的程式和答案註解。我們開發了一種基於將程式解耦成稱為範本的高階技能，以及對應參數的合成資料擴充方法和替代程式產生方法。我們的結果顯示，使用資料擴充，無提示式較小的 LLM（$\approx$ 1B 參數）與最先進的模型具有競爭力，而且具有推理速度更快的附加優點

##### **Bilevel Joint Unsupervised and Supervised Training for Automatic Speech Recognition**
2412.08548v1 by Xiaodong Cui, A F M Saif, Songtao Lu, Lisha Chen, Tianyi Chen, Brian Kingsbury, George Saon

In this paper, we propose a bilevel joint unsupervised and supervised
training (BL-JUST) framework for automatic speech recognition. Compared to the
conventional pre-training and fine-tuning strategy which is a disconnected
two-stage process, BL-JUST tries to optimize an acoustic model such that it
simultaneously minimizes both the unsupervised and supervised loss functions.
Because BL-JUST seeks matched local optima of both loss functions, acoustic
representations learned by the acoustic model strike a good balance between
being generic and task-specific. We solve the BL-JUST problem using
penalty-based bilevel gradient descent and evaluate the trained deep neural
network acoustic models on various datasets with a variety of architectures and
loss functions. We show that BL-JUST can outperform the widely-used
pre-training and fine-tuning strategy and some other popular semi-supervised
techniques.

摘要：在本文中，我們提出了一個雙層聯合無監督和監督訓練 (BL-JUST) 框架，用於自動語音辨識。與傳統的預訓練和微調策略（一個不連續的兩階段過程）相比，BL-JUST 嘗試優化一個聲學模型，使它同時最小化無監督和監督損失函數。由於 BL-JUST 尋求兩個損失函數的匹配局部最優值，因此聲學模型學習到的聲學表示在通用性和特定於任務之間取得了良好的平衡。我們使用基於懲罰的雙層梯度下降來解決 BL-JUST 問題，並在具有各種架構和損失函數的不同資料集上評估訓練好的深度神經網路聲學模型。我們表明，BL-JUST 可以優於廣泛使用的預訓練和微調策略以及其他一些流行的半監督技術。

##### **MaestroMotif: Skill Design from Artificial Intelligence Feedback**
2412.08542v1 by Martin Klissarov, Mikael Henaff, Roberta Raileanu, Shagun Sodhani, Pascal Vincent, Amy Zhang, Pierre-Luc Bacon, Doina Precup, Marlos C. Machado, Pierluca D'Oro

Describing skills in natural language has the potential to provide an
accessible way to inject human knowledge about decision-making into an AI
system. We present MaestroMotif, a method for AI-assisted skill design, which
yields high-performing and adaptable agents. MaestroMotif leverages the
capabilities of Large Language Models (LLMs) to effectively create and reuse
skills. It first uses an LLM's feedback to automatically design rewards
corresponding to each skill, starting from their natural language description.
Then, it employs an LLM's code generation abilities, together with
reinforcement learning, for training the skills and combining them to implement
complex behaviors specified in language. We evaluate MaestroMotif using a suite
of complex tasks in the NetHack Learning Environment (NLE), demonstrating that
it surpasses existing approaches in both performance and usability.

摘要：用自然語言描述技能有潛力提供一種可存取的方式，將人類關於決策的知識注入 AI 系統。我們提出 MaestroMotif，一種由 AI 輔助的技能設計方法，它產生高性能且適應性強的代理。MaestroMotif 利用大型語言模型 (LLM) 的功能，有效地建立和重複使用技能。它首先使用 LLM 的回饋，根據其自然語言描述，自動設計與每個技能對應的獎勵。然後，它採用 LLM 的程式碼產生能力，並結合強化學習，訓練技能並將它們結合起來，以實作語言中指定的複雜行為。我們使用 NetHack 學習環境 (NLE) 中的一組複雜任務評估 MaestroMotif，證明它在效能和可用性方面都超越了現有方法。

##### **TECO: Improving Multimodal Intent Recognition with Text Enhancement through Commonsense Knowledge Extraction**
2412.08529v1 by Quynh-Mai Thi Nguyen, Lan-Nhi Thi Nguyen, Cam-Van Thi Nguyen

The objective of multimodal intent recognition (MIR) is to leverage various
modalities-such as text, video, and audio-to detect user intentions, which is
crucial for understanding human language and context in dialogue systems.
Despite advances in this field, two main challenges persist: (1) effectively
extracting and utilizing semantic information from robust textual features; (2)
aligning and fusing non-verbal modalities with verbal ones effectively. This
paper proposes a Text Enhancement with CommOnsense Knowledge Extractor (TECO)
to address these challenges. We begin by extracting relations from both
generated and retrieved knowledge to enrich the contextual information in the
text modality. Subsequently, we align and integrate visual and acoustic
representations with these enhanced text features to form a cohesive multimodal
representation. Our experimental results show substantial improvements over
existing baseline methods.

摘要：多模態意圖識別 (MIR) 的目標是利用各種模式（例如文字、影片和音訊）來偵測使用者的意圖，這對於理解對話系統中的人類語言和脈絡至關重要。儘管這個領域有進展，但仍有兩個主要挑戰：(1) 有效地從強大的文字特徵中提取和利用語義資訊；(2) 有效地對齊和融合非語言模式與語言模式。本文提出了一種具備常識知識萃取器的文字強化 (TECO) 來應對這些挑戰。我們首先從已產生和已擷取的知識中提取關係，以豐富文字模式中的脈絡資訊。接著，我們將視覺和聽覺表示與這些增強的文字特徵對齊並整合，以形成一個有凝聚力的多模態表示。我們的實驗結果顯示，與現有的基準方法相比，有顯著的進步。

##### **Continual Learning for Encoder-only Language Models via a Discrete Key-Value Bottleneck**
2412.08528v1 by Andor Diera, Lukas Galke, Fabian Karl, Ansgar Scherp

Continual learning remains challenging across various natural language
understanding tasks. When models are updated with new training data, they risk
catastrophic forgetting of prior knowledge. In the present work, we introduce a
discrete key-value bottleneck for encoder-only language models, allowing for
efficient continual learning by requiring only localized updates. Inspired by
the success of a discrete key-value bottleneck in vision, we address new and
NLP-specific challenges. We experiment with different bottleneck architectures
to find the most suitable variants regarding language, and present a generic
discrete key initialization technique for NLP that is task independent. We
evaluate the discrete key-value bottleneck in four continual learning NLP
scenarios and demonstrate that it alleviates catastrophic forgetting. We
showcase that it offers competitive performance to other popular continual
learning methods, with lower computational costs.

摘要：持續學習在各種自然語言理解任務中仍然具有挑戰性。當模型使用新的訓練資料更新時，它們有災難性遺忘先前知識的風險。在目前的工作中，我們為僅編碼器語言模型引入了離散鍵值瓶頸，僅需要局部更新，即可實現有效的持續學習。受離散鍵值瓶頸在視覺中的成功啟發，我們解決了 NLP 特有的新挑戰。我們嘗試使用不同的瓶頸架構，以找到最適合語言的變體，並提出了一種適用於 NLP 的通用離散鍵初始化技術，該技術與任務無關。我們在四個持續學習 NLP 場景中評估了離散鍵值瓶頸，並證明它減輕了災難性遺忘。我們展示了它以較低的計算成本為其他流行的持續學習方法提供了競爭力的效能。

##### **EMS: Adaptive Evict-then-Merge Strategy for Head-wise KV Cache Compression Based on Global-Local Importance**
2412.08521v1 by Yingxin Li, Ye Li, Yuan Meng, Xinzhu Ma, Zihan Geng, Shutao Xia, Zhi Wang

As large language models (LLMs) continue to advance, the demand for higher
quality and faster processing of long contexts across various applications is
growing. KV cache is widely adopted as it stores previously generated key and
value tokens, effectively reducing redundant computations during inference.
However, as memory overhead becomes a significant concern, efficient
compression of KV cache has gained increasing attention. Most existing methods
perform compression from two perspectives: identifying important tokens and
designing compression strategies. However, these approaches often produce
biased distributions of important tokens due to the influence of accumulated
attention scores or positional encoding. Furthermore, they overlook the
sparsity and redundancy across different heads, which leads to difficulties in
preserving the most effective information at the head level. To this end, we
propose EMS to overcome these limitations, while achieving better KV cache
compression under extreme compression ratios. Specifically, we introduce a
Global-Local score that combines accumulated attention scores from both global
and local KV tokens to better identify the token importance. For the
compression strategy, we design an adaptive and unified Evict-then-Merge
framework that accounts for the sparsity and redundancy of KV tokens across
different heads. Additionally, we implement the head-wise parallel compression
through a zero-class mechanism to enhance efficiency. Extensive experiments
demonstrate our SOTA performance even under extreme compression ratios. EMS
consistently achieves the lowest perplexity, improves scores by over 1.28
points across four LLMs on LongBench under a 256 cache budget, and preserves
95% retrieval accuracy with a cache budget less than 2% of the context length
in the Needle-in-a-Haystack task.

摘要：隨著大型語言模型 (LLM) 持續進步，對於各種應用程式中更長內容的高品質和更快速處理的需求也與日俱增。KV 快取被廣泛採用，因為它儲存先前產生的金鑰和值權杖，有效地減少推理期間的冗餘運算。然而，隨著記憶體開銷成為一個重要的問題，KV 快取的有效壓縮也越來越受到重視。現有的方法大多從兩個角度進行壓縮：識別重要權杖和設計壓縮策略。然而，由於累積注意力分數或位置編碼的影響，這些方法通常會產生重要權杖的偏差分佈。此外，它們忽略了不同頭部之間的稀疏性和冗餘，這導致難以在頭部層級保留最有效的資訊。為此，我們提出 EMS 來克服這些限制，同時在極端的壓縮比下實現更好的 KV 快取壓縮。具體來說，我們引入了一個結合來自全局和局部 KV 權杖的累積注意力分數的全局局部分數，以更好地識別權杖的重要性。對於壓縮策略，我們設計了一個適應性和統一性的逐出再合併架構，它考量了不同頭部中 KV 權杖的稀疏性和冗餘。此外，我們透過零類別機制實現頭部明智的平行壓縮，以提高效率。廣泛的實驗證明了我們即使在極端的壓縮比下也能達到 SOTA 效能。在 LongBench 上的四個 LLM 中，EMS 在 256 快取預算下持續實現最低困惑度，將分數提高了 1.28 分以上，並在 Needle-in-a-Haystack 任務中以小於內容長度 2% 的快取預算保留了 95% 的檢索準確度。

##### **GR-NLP-TOOLKIT: An Open-Source NLP Toolkit for Modern Greek**
2412.08520v1 by Lefteris Loukas, Nikolaos Smyrnioudis, Chrysa Dikonomaki, Spyros Barbakos, Anastasios Toumazatos, John Koutsikakis, Manolis Kyriakakis, Mary Georgiou, Stavros Vassos, John Pavlopoulos, Ion Androutsopoulos

We present GR-NLP-TOOLKIT, an open-source natural language processing (NLP)
toolkit developed specifically for modern Greek. The toolkit provides
state-of-the-art performance in five core NLP tasks, namely part-of-speech
tagging, morphological tagging, dependency parsing, named entity recognition,
and Greeklishto-Greek transliteration. The toolkit is based on pre-trained
Transformers, it is freely available, and can be easily installed in Python
(pip install gr-nlp-toolkit). It is also accessible through a demonstration
platform on HuggingFace, along with a publicly available API for non-commercial
use. We discuss the functionality provided for each task, the underlying
methods, experiments against comparable open-source toolkits, and future
possible enhancements. The toolkit is available at:
https://github.com/nlpaueb/gr-nlp-toolkit

摘要：我們提出 GR-NLP-TOOLKIT，這是一個專門為現代希臘語開發的開源自然語言處理 (NLP) 工具包。該工具包在五項核心 NLP 任務中提供最先進的效能，即詞性標記、形態標記、依存句法分析、命名實體辨識和 Greeklish 轉換為希臘語轉寫。該工具包基於預先訓練的 Transformers，它是免費提供的，並且可以輕鬆安裝在 Python 中（pip 安裝 gr-nlp-toolkit）。它也可以透過 HuggingFace 上的示範平台存取，以及一個公開提供的 API 供非商業用途使用。我們討論了為每個任務提供的功能、基礎方法、針對可比較開源工具包的實驗，以及未來可能的增強功能。該工具包可在以下網址取得：
https://github.com/nlpaueb/gr-nlp-toolkit

##### **Bridging Relevance and Reasoning: Rationale Distillation in Retrieval-Augmented Generation**
2412.08519v1 by Pengyue Jia, Derong Xu, Xiaopeng Li, Zhaocheng Du, Xiangyang Li, Xiangyu Zhao, Yichao Wang, Yuhao Wang, Huifeng Guo, Ruiming Tang

The reranker and generator are two critical components in the
Retrieval-Augmented Generation (i.e., RAG) pipeline, responsible for ranking
relevant documents and generating responses. However, due to differences in
pre-training data and objectives, there is an inevitable gap between the
documents ranked as relevant by the reranker and those required by the
generator to support answering the query. To address this gap, we propose
RADIO, a novel and practical preference alignment framework with RAtionale
DIstillatiOn. Specifically, We first propose a rationale extraction method that
leverages the reasoning capabilities of Large Language Models (LLMs) to extract
the rationales necessary for answering the query. Subsequently, a
rationale-based alignment process is designed to rerank the documents based on
the extracted rationales, and fine-tune the reranker to align the preferences.
We conduct extensive experiments on two tasks across three datasets to
demonstrate the effectiveness of our approach compared to baseline methods. Our
code is released online to ease reproduction.

摘要：重新排序器和生成器是检索增强生成（即 RAG）管道中的两个关键组件，负责对相关文档进行排序并生成响应。然而，由于预训练数据和目标的不同，重新排序器排名的相关文档与生成器回答查询所需的文档之间存在不可避免的差距。为了解决这一差距，我们提出了 RADIO，一个新颖且实用的偏好对齐框架，带有 RAtionale DIstillatiOn。具体来说，我们首先提出了一种基本原理提取方法，该方法利用大型语言模型 (LLM) 的推理能力来提取回答查询所需的基本原理。随后，设计了一个基于基本原理的对齐过程，根据提取的基本原理对文档进行重新排序，并微调重新排序器以对齐偏好。我们对三个数据集中的两个任务进行了广泛的实验，以证明我们方法与基线方法相比的有效性。我们的代码已在线发布，以简化再现。

##### **Enhancing Interpretability Through Loss-Defined Classification Objective in Structured Latent Spaces**
2412.08515v1 by Daniel Geissler, Bo Zhou, Mengxi Liu, Paul Lukowicz

Supervised machine learning often operates on the data-driven paradigm,
wherein internal model parameters are autonomously optimized to converge
predicted outputs with the ground truth, devoid of explicitly programming rules
or a priori assumptions. Although data-driven methods have yielded notable
successes across various benchmark datasets, they inherently treat models as
opaque entities, thereby limiting their interpretability and yielding a lack of
explanatory insights into their decision-making processes. In this work, we
introduce Latent Boost, a novel approach that integrates advanced distance
metric learning into supervised classification tasks, enhancing both
interpretability and training efficiency. Thus during training, the model is
not only optimized for classification metrics of the discrete data points but
also adheres to the rule that the collective representation zones of each class
should be sharply clustered. By leveraging the rich structural insights of
intermediate model layer latent representations, Latent Boost improves
classification interpretability, as demonstrated by higher Silhouette scores,
while accelerating training convergence. These performance and latent
structural benefits are achieved with minimum additional cost, making it
broadly applicable across various datasets without requiring data-specific
adjustments. Furthermore, Latent Boost introduces a new paradigm for aligning
classification performance with improved model transparency to address the
challenges of black-box models.

摘要：监督式机器学习通常遵循数据驱动范例，其中内部模型参数会自动优化，以使预测输出与地面实况相符，而无需明确编程规则或先验假设。尽管数据驱动方法在各种基准数据集上取得了显着的成功，但它们本质上将模型视为不透明实体，从而限制了其可解释性，并且无法对其决策过程提供解释性见解。在这项工作中，我们引入了潜在提升，这是一种新颖的方法，它将先进的距离度量学习集成到监督分类任务中，从而增强了可解释性和训练效率。因此，在训练期间，该模型不仅针对离散数据点的分类指标进行了优化，还遵守了每个类的集体表示区域应该被锐利聚类的规则。通过利用中间模型层潜在表示的丰富结构见解，潜在提升改善了分类的可解释性，如更高的轮廓得分所示，同时加速了训练收敛。这些性能和潜在结构优势以最小的额外成本实现，使其广泛适用于各种数据集，而无需进行特定于数据的调整。此外，潜在提升引入了一种新的范例，用于将分类性能与改进的模型透明性相结合，以应对黑盒模型的挑战。

##### **REPEAT: Improving Uncertainty Estimation in Representation Learning Explainability**
2412.08513v1 by Kristoffer K. Wickstrøm, Thea Brüsch, Michael C. Kampffmeyer, Robert Jenssen

Incorporating uncertainty is crucial to provide trustworthy explanations of
deep learning models. Recent works have demonstrated how uncertainty modeling
can be particularly important in the unsupervised field of representation
learning explainable artificial intelligence (R-XAI). Current R-XAI methods
provide uncertainty by measuring variability in the importance score. However,
they fail to provide meaningful estimates of whether a pixel is certainly
important or not. In this work, we propose a new R-XAI method called REPEAT
that addresses the key question of whether or not a pixel is \textit{certainly}
important. REPEAT leverages the stochasticity of current R-XAI methods to
produce multiple estimates of importance, thus considering each pixel in an
image as a Bernoulli random variable that is either important or unimportant.
From these Bernoulli random variables we can directly estimate the importance
of a pixel and its associated certainty, thus enabling users to determine
certainty in pixel importance. Our extensive evaluation shows that REPEAT gives
certainty estimates that are more intuitive, better at detecting
out-of-distribution data, and more concise.

摘要：將不確定性納入考量對於提供深度學習模型的可靠解釋至關重要。最近的研究已證明不確定性建模在無監督表示學習解釋性人工智慧 (R-XAI) 領域中可能特別重要。目前的 R-XAI 方法透過測量重要性分數中的變異性來提供不確定性。但是，它們無法提供有意義的估計值，說明像素是否確實重要。在此研究中，我們提出了一種名為 REPEAT 的新 R-XAI 方法，用於解決像素是否「確實」重要的關鍵問題。REPEAT 利用當前 R-XAI 方法的隨機性來產生多個重要性估計值，因此將影像中的每個像素視為一個伯努利隨機變數，它可能是重要的或不重要的。從這些伯努利隨機變數中，我們可以直接估計像素及其相關確定性的重要性，從而使用戶能夠確定像素重要性的確定性。我們的廣泛評估顯示，REPEAT 提供的確定性估計更直觀、更能偵測分布外資料，而且更簡潔。

##### **Comparative Opinion Mining in Product Reviews: Multi-perspective Prompt-based Learning**
2412.08508v1 by Hai-Yen Thi Nguyen, Cam-Van Thi Nguyen

Comparative reviews are pivotal in understanding consumer preferences and
influencing purchasing decisions. Comparative Quintuple Extraction (COQE) aims
to identify five key components in text: the target entity, compared entities,
compared aspects, opinions on these aspects, and polarity. Extracting precise
comparative information from product reviews is challenging due to nuanced
language and sequential task errors in traditional methods. To mitigate these
problems, we propose MTP-COQE, an end-to-end model designed for COQE.
Leveraging multi-perspective prompt-based learning, MTP-COQE effectively guides
the generative model in comparative opinion mining tasks. Evaluation on the
Camera-COQE (English) and VCOM (Vietnamese) datasets demonstrates MTP-COQE's
efficacy in automating COQE, achieving superior performance with a 1.41% higher
F1 score than the previous baseline models on the English dataset.
Additionally, we designed a strategy to limit the generative model's creativity
to ensure the output meets expectations. We also performed data augmentation to
address data imbalance and to prevent the model from becoming biased towards
dominant samples.

摘要：比較評論對於了解消費者偏好和影響購買決定至關重要。比較五元萃取 (COQE) 旨在識別文本中的五個關鍵組成部分：目標實體、比較實體、比較面向、對這些面向的意見以及極性。由於傳統方法中語言的細微差別和順序任務錯誤，從產品評論中提取精確的比較資訊具有挑戰性。為了減輕這些問題，我們提出了 MTP-COQE，這是一個專為 COQE 設計的端到端模型。利用多視角提示式學習，MTP-COQE 有效地指導生成模型進行比較意見挖掘任務。在 Camera-COQE（英語）和 VCOM（越南語）資料集上的評估證明了 MTP-COQE 在自動化 COQE 中的功效，在英語資料集上比以前的基準模型實現了高出 1.41% 的 F1 分數的優異效能。此外，我們設計了一種策略來限制生成模型的創造力，以確保輸出符合預期。我們還執行了資料擴充，以解決資料不平衡問題，並防止模型對主要樣本產生偏見。

##### **SuperCode: Sustainability PER AI-driven CO-DEsign**
2412.08490v1 by P. Chris Broekema, Rob V. van Nieuwpoort

Currently, data-intensive scientific applications require vast amounts of
compute resources to deliver world-leading science. The climate emergency has
made it clear that unlimited use of resources (e.g., energy) for scientific
discovery is no longer acceptable. Future computing hardware promises to be
much more energy efficient, but without better optimized software this cannot
reach its full potential. In this vision paper, we propose a generic AI-driven
co-design methodology, using specialized Large Language Models (like ChatGPT),
to effectively generate efficient code for emerging computing hardware. We
describe how we will validate our methodology with two radio astronomy
applications, with sustainability as the key performance indicator. This paper
is a modified version of our accepted SuperCode project proposal. We present it
here in this form to introduce the vision behind this project and to
disseminate the work in the spirit of Open Science and transparency. An
additional aim is to collect feedback, invite potential collaboration partners
and use-cases to join the project.

摘要：目前，資料密集的科學應用程式需要大量的運算資源才能提供領先世界的科學。氣候緊急事件已經表明，不再能接受為了科學發現而無限使用資源（例如能源）。未來的運算硬體承諾將會更節能，但沒有經過最佳化優化的軟體，無法發揮其全部潛力。在這份願景文件中，我們提出一個通用的 AI 驅動共同設計方法，使用大型語言模型（例如 ChatGPT），有效地為新興運算硬體產生高效的程式碼。我們描述了如何使用兩個無線電天文學應用程式驗證我們的技術，其中永續性為關鍵效能指標。這份文件是我們已接受的 SuperCode 專案提案的修改版本。我們在此以這種形式呈現，以介紹這個專案背後的願景，並本著開放科學和透明的精神傳播這項工作。另一個目的是收集回饋，邀請潛在的合作夥伴和使用案例加入這個專案。

##### **Multi-perspective Alignment for Increasing Naturalness in Neural Machine Translation**
2412.08473v1 by Huiyuan Lai, Esther Ploeger, Rik van Noord, Antonio Toral

Neural machine translation (NMT) systems amplify lexical biases present in
their training data, leading to artificially impoverished language in output
translations. These language-level characteristics render automatic
translations different from text originally written in a language and human
translations, which hinders their usefulness in for example creating evaluation
datasets. Attempts to increase naturalness in NMT can fall short in terms of
content preservation, where increased lexical diversity comes at the cost of
translation accuracy. Inspired by the reinforcement learning from human
feedback framework, we introduce a novel method that rewards both naturalness
and content preservation. We experiment with multiple perspectives to produce
more natural translations, aiming at reducing machine and human translationese.
We evaluate our method on English-to-Dutch literary translation, and find that
our best model produces translations that are lexically richer and exhibit more
properties of human-written language, without loss in translation accuracy.

摘要：神經機器翻譯 (NMT) 系統擴大了其訓練資料中存在的詞彙偏差，導致輸出翻譯中的語言人為地貧乏。這些語言層面的特徵使自動翻譯不同於原本用一種語言寫成的文字和人工翻譯，這阻礙了它們在例如建立評估資料集方面的用途。增加 NMT 中自然性的嘗試可能會在內容保存方面有所不足，其中增加詞彙多樣性是以犧牲翻譯準確性為代價的。受到人類回饋框架中的強化學習的啟發，我們引入了一種新的方法，它同時獎勵自然性和內容保存。我們嘗試了多種觀點來產生更自然的翻譯，旨在減少機器和人工翻譯腔。我們對英語到荷蘭語文學翻譯評估了我們的方法，發現我們最好的模型產生的翻譯在詞彙上更豐富，並表現出更多人類書面語言的特性，而不會降低翻譯準確性。

##### **Bootstrapping Language-Guided Navigation Learning with Self-Refining Data Flywheel**
2412.08467v1 by Zun Wang, Jialu Li, Yicong Hong, Songze Li, Kunchang Li, Shoubin Yu, Yi Wang, Yu Qiao, Yali Wang, Mohit Bansal, Limin Wang

Creating high-quality data for training robust language-instructed agents is
a long-lasting challenge in embodied AI. In this paper, we introduce a
Self-Refining Data Flywheel (SRDF) that generates high-quality and large-scale
navigational instruction-trajectory pairs by iteratively refining the data pool
through the collaboration between two models, the instruction generator and the
navigator, without any human-in-the-loop annotation. Specifically, SRDF starts
with using a base generator to create an initial data pool for training a base
navigator, followed by applying the trained navigator to filter the data pool.
This leads to higher-fidelity data to train a better generator, which can, in
turn, produce higher-quality data for training the next-round navigator. Such a
flywheel establishes a data self-refining process, yielding a continuously
improved and highly effective dataset for large-scale language-guided
navigation learning. Our experiments demonstrate that after several flywheel
rounds, the navigator elevates the performance boundary from 70% to 78% SPL on
the classic R2R test set, surpassing human performance (76%) for the first
time. Meanwhile, this process results in a superior generator, evidenced by a
SPICE increase from 23.5 to 26.2, better than all previous VLN instruction
generation methods. Finally, we demonstrate the scalability of our method
through increasing environment and instruction diversity, and the
generalization ability of our pre-trained navigator across various downstream
navigation tasks, surpassing state-of-the-art methods by a large margin in all
cases.

摘要：<paragraph>為訓練強大的語言指導代理建立高品質資料是體現式人工智慧的長期挑戰。在這篇論文中，我們介紹一個自我精煉資料飛輪 (SRDF)，透過兩個模型（指令產生器和導航員）的合作，在資料庫中反覆精煉資料，產生高品質且大規模的導航指令軌跡配對，而無需任何人工迴圈註解。具體來說，SRDF 從使用基本產生器建立一個初始資料庫，用於訓練基本導航員，接著使用訓練好的導航員來過濾資料庫。這會產生更高保真度的資料，用於訓練更好的產生器，進而產生更高品質的資料，用於訓練下一輪導航員。這樣的飛輪建立了一個資料自我精煉流程，產生一個持續改善且高度有效的資料集，用於大規模語言引導導航學習。我們的實驗顯示，經過幾輪飛輪後，導航員將經典 R2R 測試集上的效能界線從 70% 提升到 78% SPL，首次超越人類效能 (76%)。同時，這個流程產生了一個優異的產生器，SPICE 從 23.5 增加到 26.2，優於所有先前的 VLN 指令產生方法。最後，我們透過增加環境和指令多樣性，以及預訓練導航員在各種下游導航任務中的泛化能力，證明了我們方法的可擴充性，在所有情況下都大幅超越現有技術。</paragraph>

##### **IRL for Restless Multi-Armed Bandits with Applications in Maternal and Child Health**
2412.08463v1 by Gauri Jain, Pradeep Varakantham, Haifeng Xu, Aparna Taneja, Prashant Doshi, Milind Tambe

Public health practitioners often have the goal of monitoring patients and
maximizing patients' time spent in "favorable" or healthy states while being
constrained to using limited resources. Restless multi-armed bandits (RMAB) are
an effective model to solve this problem as they are helpful to allocate
limited resources among many agents under resource constraints, where patients
behave differently depending on whether they are intervened on or not. However,
RMABs assume the reward function is known. This is unrealistic in many public
health settings because patients face unique challenges and it is impossible
for a human to know who is most deserving of any intervention at such a large
scale. To address this shortcoming, this paper is the first to present the use
of inverse reinforcement learning (IRL) to learn desired rewards for RMABs, and
we demonstrate improved outcomes in a maternal and child health telehealth
program. First we allow public health experts to specify their goals at an
aggregate or population level and propose an algorithm to design expert
trajectories at scale based on those goals. Second, our algorithm WHIRL uses
gradient updates to optimize the objective, allowing for efficient and accurate
learning of RMAB rewards. Third, we compare with existing baselines and
outperform those in terms of run-time and accuracy. Finally, we evaluate and
show the usefulness of WHIRL on thousands on beneficiaries from a real-world
maternal and child health setting in India. We publicly release our code here:
https://github.com/Gjain234/WHIRL.

摘要：<paragraph>公共衛生從業人員通常有監控患者和最大化患者處於「有利」或健康狀態的時間的目標，同時受到有限資源的限制。不安分的多臂強盜 (RMAB) 是解決此問題的有效模型，因為它們有助於在資源限制下，在許多代理之間分配有限的資源，其中患者的行為取決於是否對其進行干預。然而，RMAB 假設已知回報函數。這在許多公共衛生環境中是不切實際的，因為患者面臨獨特的挑戰，而且對於如此大規模的干預，人類不可能知道誰最需要干預。為了解決這個缺點，本文首次提出使用逆向強化學習 (IRL) 來學習 RMAB 的期望回報，並且我們在母嬰健康遠距醫療計畫中展示了改善的結果。首先，我們允許公共衛生專家在總體或人口層級指定他們的目標，並提出一個演算法來根據這些目標大規模設計專家軌跡。其次，我們的演算法 WHIRL 使用梯度更新來最佳化目標，允許有效且準確地學習 RMAB 回報。第三，我們與現有的基準進行比較，並在執行時間和準確性方面優於這些基準。最後，我們評估並展示了 WHIRL 在印度實際母嬰健康環境中對數千名受益者的有用性。我們在此公開發布我們的程式碼：https://github.com/Gjain234/WHIRL。</paragraph>

##### **Federated Learning for Traffic Flow Prediction with Synthetic Data Augmentation**
2412.08460v1 by Fermin Orozco, Pedro Porto Buarque de Gusmão, Hongkai Wen, Johan Wahlström, Man Luo

Deep-learning based traffic prediction models require vast amounts of data to
learn embedded spatial and temporal dependencies. The inherent privacy and
commercial sensitivity of such data has encouraged a shift towards
decentralised data-driven methods, such as Federated Learning (FL). Under a
traditional Machine Learning paradigm, traffic flow prediction models can
capture spatial and temporal relationships within centralised data. In reality,
traffic data is likely distributed across separate data silos owned by multiple
stakeholders. In this work, a cross-silo FL setting is motivated to facilitate
stakeholder collaboration for optimal traffic flow prediction applications.
This work introduces an FL framework, referred to as FedTPS, to generate
synthetic data to augment each client's local dataset by training a
diffusion-based trajectory generation model through FL. The proposed framework
is evaluated on a large-scale real world ride-sharing dataset using various FL
methods and Traffic Flow Prediction models, including a novel prediction model
we introduce, which leverages Temporal and Graph Attention mechanisms to learn
the Spatio-Temporal dependencies embedded within regional traffic flow data.
Experimental results show that FedTPS outperforms multiple other FL baselines
with respect to global model performance.

摘要：深度學習的交通預測模型需要大量的資料來學習內嵌的時空依賴性。這些資料固有的隱私性和商業敏感性促使人們轉向分散式資料驅動方法，例如聯合學習 (FL)。在傳統的機器學習範例中，交通流量預測模型可以在集中式資料中擷取時空關係。實際上，交通資料可能分散在由多個利害關係人擁有的獨立資料倉儲中。在這項工作中，跨倉儲 FL 設定的目的是促進利害關係人合作，以實現最佳的交通流量預測應用。這項工作引入了一個 FL 架構，稱為 FedTPS，用於生成合成資料，以透過 FL 訓練基於擴散的軌跡生成模型，來擴充每個客戶端的本地資料集。所提出的架構在一個大規模的真實世界共乘資料集上進行評估，使用各種 FL 方法和交通流量預測模型，包括我們引入的一個新穎預測模型，它利用時序和圖形注意力機制來學習區域交通流量資料中內嵌的時空依賴性。實驗結果表明，FedTPS 在全球模型效能方面優於其他多個 FL 基準。

##### **Efficient Rectification of Neuro-Symbolic Reasoning Inconsistencies by Abductive Reflection**
2412.08457v1 by Wen-Chao Hu, Wang-Zhou Dai, Yuan Jiang, Zhi-Hua Zhou

Neuro-Symbolic (NeSy) AI could be regarded as an analogy to human
dual-process cognition, modeling the intuitive System 1 with neural networks
and the algorithmic System 2 with symbolic reasoning. However, for complex
learning targets, NeSy systems often generate outputs inconsistent with domain
knowledge and it is challenging to rectify them. Inspired by the human
Cognitive Reflection, which promptly detects errors in our intuitive response
and revises them by invoking the System 2 reasoning, we propose to improve NeSy
systems by introducing Abductive Reflection (ABL-Refl) based on the Abductive
Learning (ABL) framework. ABL-Refl leverages domain knowledge to abduce a
reflection vector during training, which can then flag potential errors in the
neural network outputs and invoke abduction to rectify them and generate
consistent outputs during inference. ABL-Refl is highly efficient in contrast
to previous ABL implementations. Experiments show that ABL-Refl outperforms
state-of-the-art NeSy methods, achieving excellent accuracy with fewer training
resources and enhanced efficiency.

摘要：神經符號（NeSy）人工智慧可以視為人類雙重過程認知的類比，以神經網路建模直覺的系統 1，並以符號推理建模演算法系統 2。然而，對於複雜的學習目標，NeSy 系統經常產生與領域知識不一致的輸出，且難以修正。受人類認知反省的啟發，它可以迅速偵測我們直覺反應中的錯誤，並透過呼叫系統 2 推理來修正它們，我們提出透過在演繹學習（ABL）架構中導入演繹反省（ABL-Refl）來改善 NeSy 系統。ABL-Refl 在訓練期間利用領域知識演繹反射向量，然後可以標記神經網路輸出中的潛在錯誤，並呼叫演繹來修正它們，並在推論期間產生一致的輸出。與先前的 ABL 實作相比，ABL-Refl 非常有效率。實驗顯示，ABL-Refl 優於最先進的 NeSy 方法，在訓練資源較少且效率更高的情況下，達到極佳的準確度。

##### **TapeAgents: a Holistic Framework for Agent Development and Optimization**
2412.08445v1 by Dzmitry Bahdanau, Nicolas Gontier, Gabriel Huang, Ehsan Kamalloo, Rafael Pardinas, Alex Piché, Torsten Scholak, Oleh Shliazhko, Jordan Prince Tremblay, Karam Ghanem, Soham Parikh, Mitul Tiwari, Quaizar Vohra

We present TapeAgents, an agent framework built around a granular, structured
log tape of the agent session that also plays the role of the session's
resumable state. In TapeAgents we leverage tapes to facilitate all stages of
the LLM Agent development lifecycle. The agent reasons by processing the tape
and the LLM output to produce new thought and action steps and append them to
the tape. The environment then reacts to the agent's actions by likewise
appending observation steps to the tape. By virtue of this tape-centred design,
TapeAgents can provide AI practitioners with holistic end-to-end support. At
the development stage, tapes facilitate session persistence, agent auditing,
and step-by-step debugging. Post-deployment, one can reuse tapes for
evaluation, fine-tuning, and prompt-tuning; crucially, one can adapt tapes from
other agents or use revised historical tapes. In this report, we explain the
TapeAgents design in detail. We demonstrate possible applications of TapeAgents
with several concrete examples of building monolithic agents and multi-agent
teams, of optimizing agent prompts and finetuning the agent's LLM. We present
tooling prototypes and report a case study where we use TapeAgents to finetune
a Llama-3.1-8B form-filling assistant to perform as well as GPT-4o while being
orders of magnitude cheaper. Lastly, our comparative analysis shows that
TapeAgents's advantages over prior frameworks stem from our novel design of the
LLM agent as a resumable, modular state machine with a structured
configuration, that generates granular, structured logs and that can transform
these logs into training text -- a unique combination of features absent in
previous work.

摘要：<paragraph>我們提出 TapeAgents，一種圍繞著代理人會話的細緻結構化日誌磁帶建立的代理人架構，該架構也扮演著會話可恢復狀態的角色。在 TapeAgents 中，我們利用磁帶促進 LLM 代理人開發生命週期的所有階段。代理人通過處理磁帶和 LLM 輸出，產生新的想法和行動步驟，並將它們附加到磁帶上，從而進行推理。然後，環境通過同樣將觀察步驟附加到磁帶上來對代理人的動作做出反應。由於這種以磁帶為中心的設計，TapeAgents 可以為 AI 從業者提供整體的端到端支持。在開發階段，磁帶促進會話持久性、代理人稽核和逐步除錯。部署後，可以重複使用磁帶進行評估、微調和提示調整；至關重要的是，可以調整其他代理人的磁帶或使用修改後的歷史磁帶。在此報告中，我們詳細說明了 TapeAgents 的設計。我們通過幾個具體的構建單體代理人和多代理人團隊、優化代理人提示和微調代理人的 LLM 的示例，展示了 TapeAgents 的可能的應用。我們展示了工具原型，並報告了一個案例研究，在該案例研究中，我們使用 TapeAgents 微調了 Llama-3.1-8B 表單填寫助手，使其在執行時與 GPT-4o 一樣好，同時成本低幾個數量級。最後，我們的比較分析表明，TapeAgents 相對於先前框架的優勢源於我們將 LLM 代理人設計成一個可恢復的、模組化的狀態機的新穎設計，它具有結構化的配置，可以產生細緻的、結構化的日誌，並且可以將這些日誌轉換為訓練文本——這是一個以前的工作中沒有的獨特功能組合。</paragraph>

##### **Proactive Model Adaptation Against Concept Drift for Online Time Series Forecasting**
2412.08435v1 by Lifan Zhao, Yanyan Shen

Time series forecasting always faces the challenge of concept drift, where
data distributions evolve over time, leading to a decline in forecast model
performance. Existing solutions are based on online learning, which continually
organize recent time series observations as new training samples and update
model parameters according to the forecasting feedback on recent data. However,
they overlook a critical issue: obtaining ground-truth future values of each
sample should be delayed until after the forecast horizon. This delay creates a
temporal gap between the training samples and the test sample. Our empirical
analysis reveals that the gap can introduce concept drift, causing forecast
models to adapt to outdated concepts. In this paper, we present
\textsc{Proceed}, a novel proactive model adaptation framework for online time
series forecasting. \textsc{Proceed} first operates by estimating the concept
drift between the recently used training samples and the current test sample.
It then employs an adaptation generator to efficiently translate the estimated
drift into parameter adjustments, proactively adapting the model to the test
sample. To enhance the generalization capability of the framework,
\textsc{Proceed} is trained on synthetic diverse concept drifts. We conduct
extensive experiments on five real-world datasets across various forecast
models. The empirical study demonstrates that our proposed \textsc{Proceed}
brings more performance improvements than the state-of-the-art online learning
methods, significantly facilitating forecast models' resilience against concept
drifts.

摘要：時間序列預測總是面臨概念漂移的挑戰，其中資料分佈會隨著時間演變，導致預測模型效能下降。現有的解決方案基於線上學習，它會持續整理最近的時間序列觀察結果作為新的訓練樣本，並根據最近資料的預測回饋來更新模型參數。然而，它們忽略了一個關鍵問題：每個樣本的真實未來值應延遲到預測範圍之後才能取得。這種延遲會在訓練樣本和測試樣本之間產生時間差距。我們的經驗分析顯示，這個差距可能會引發概念漂移，導致預測模型適應過時的觀念。在本文中，我們提出 \textsc{Proceed}，一個新的主動模型適應架構，用於線上時間序列預測。\textsc{Proceed} 首先透過估計最近使用的訓練樣本和當前測試樣本之間的概念漂移來運作。然後，它使用適應產生器有效地將估計的漂移轉換為參數調整，主動地將模型適應到測試樣本。為了增強架構的泛化能力，\textsc{Proceed} 在合成多樣化的概念漂移上進行訓練。我們對五個真實世界的資料集進行了廣泛的實驗，涵蓋各種預測模型。實證研究表明，我們提出的 \textsc{Proceed} 比最先進的線上學習方法帶來更多效能提升，大幅提升預測模型對抗概念漂移的韌性。

##### **Mitigating Out-of-Entity Errors in Named Entity Recognition: A Sentence-Level Strategy**
2412.08434v1 by Guochao Jiang, Ziqin Luo, Chengwei Hu, Zepeng Ding, Deqing Yang

Many previous models of named entity recognition (NER) suffer from the
problem of Out-of-Entity (OOE), i.e., the tokens in the entity mentions of the
test samples have not appeared in the training samples, which hinders the
achievement of satisfactory performance. To improve OOE-NER performance, in
this paper, we propose a new framework, namely S+NER, which fully leverages
sentence-level information. Our S+NER achieves better OOE-NER performance
mainly due to the following two particular designs. 1) It first exploits the
pre-trained language model's capability of understanding the target entity's
sentence-level context with a template set. 2) Then, it refines the
sentence-level representation based on the positive and negative templates,
through a contrastive learning strategy and template pooling method, to obtain
better NER results. Our extensive experiments on five benchmark datasets have
demonstrated that, our S+NER outperforms some state-of-the-art OOE-NER models.

摘要：許多先前的命名實體辨識 (NER) 模型都飽受實體外部 (OOE) 問題所苦，亦即測試樣本中實體提及的詞彙並未出現在訓練樣本中，這阻礙了令人滿意的效能達成。為了改善 OOE-NER 效能，我們在本文中提出一個新的架構，即 S+NER，它充分利用了句子層級的資訊。我們的 S+NER 能夠達成更好的 OOE-NER 效能，主要歸功於以下兩個特別的設計。1) 它首先利用預先訓練的語言模型，透過一組範本來理解目標實體的句子層級脈絡。2) 接著，它透過對比式學習策略和範本匯集方法，根據正向和負向範本來改善句子層級的表徵，以獲得更好的 NER 結果。我們在五個基準資料集上進行的廣泛實驗已證明，我們的 S+NER 優於一些最先進的 OOE-NER 模型。

##### **Assessing Personalized AI Mentoring with Large Language Models in the Computing Field**
2412.08430v1 by Xiao Luo, Sean O'Connell, Shamima Mithun

This paper provides an in-depth evaluation of three state-of-the-art Large
Language Models (LLMs) for personalized career mentoring in the computing
field, using three distinct student profiles that consider gender, race, and
professional levels. We evaluated the performance of GPT-4, LLaMA 3, and Palm 2
using a zero-shot learning approach without human intervention. A quantitative
evaluation was conducted through a custom natural language processing analytics
pipeline to highlight the uniqueness of the responses and to identify words
reflecting each student's profile, including race, gender, or professional
level. The analysis of frequently used words in the responses indicates that
GPT-4 offers more personalized mentoring compared to the other two LLMs.
Additionally, a qualitative evaluation was performed to see if human experts
reached similar conclusions. The analysis of survey responses shows that GPT-4
outperformed the other two LLMs in delivering more accurate and useful
mentoring while addressing specific challenges with encouragement languages.
Our work establishes a foundation for developing personalized mentoring tools
based on LLMs, incorporating human mentors in the process to deliver a more
impactful and tailored mentoring experience.

摘要：本文提供對三個最先進的大型語言模型 (LLM) 的深入評估，用於計算領域中的個人化職業指導，使用三個不同的學生檔案，其中考慮了性別、種族和專業水平。我們使用零次學習方法評估了 GPT-4、LLaMA 3 和 Palm 2 的性能，而無需人工干預。通過自定義自然語言處理分析管道進行定量評估，以突出回應的獨特性並識別反映每個學生檔案的詞彙，包括種族、性別或專業水平。對回應中常用詞彙的分析表明，與其他兩個 LLM 相比，GPT-4 提供了更個性化的指導。此外，還進行了定性評估，以了解人類專家是否得出類似的結論。對調查回應的分析表明，GPT-4 在提供更準確和有用的指導方面優於其他兩個 LLM，同時使用鼓勵語言來應對具體挑戰。我們的研究為基於 LLM 開發個性化指導工具奠定了基礎，在過程中加入人類導師，以提供更有影響力和更量身定制的指導體驗。

##### **SwarmGPT-Primitive: A Language-Driven Choreographer for Drone Swarms Using Safe Motion Primitive Composition**
2412.08428v1 by Vedant Vyas, Martin Schuck, Dinushka O. Dahanaggamaarachchi, Siqi Zhou, Angela P. Schoellig

Catalyzed by advancements in hardware and software, drone performances are
increasingly making their mark in the entertainment industry. However,
designing smooth and safe choreographies for drone swarms is complex and often
requires expert domain knowledge. In this work, we introduce
SwarmGPT-Primitive, a language-based choreographer that integrates the
reasoning capabilities of large language models (LLMs) with safe motion
planning to facilitate deployable drone swarm choreographies. The LLM composes
choreographies for a given piece of music by utilizing a library of motion
primitives; the language-based choreographer is augmented with an
optimization-based safety filter, which certifies the choreography for
real-world deployment by making minimal adjustments when feasibility and safety
constraints are violated. The overall SwarmGPT-Primitive framework decouples
choreographic design from safe motion planning, which allows non-expert users
to re-prompt and refine compositions without concerns about compliance with
constraints such as avoiding collisions or downwash effects or satisfying
actuation limits. We demonstrate our approach through simulations and
experiments with swarms of up to 20 drones performing choreographies designed
based on various songs, highlighting the system's ability to generate effective
and synchronized drone choreographies for real-world deployment.

摘要：在硬體和軟體進步的催化下，無人機表演在娛樂產業中越來越受到重視。然而，為無人機群設計流暢且安全的編舞很複雜，而且通常需要專家的領域知識。在這項工作中，我們介紹了 SwarmGPT-Primitive，這是一種基於語言的編舞器，它將大型語言模型 (LLM) 的推理能力與安全的動作規劃相結合，以促進可部署的無人機群編舞。LLM 利用動作基元的庫為給定的音樂創作編舞；基於語言的編舞器會擴充一個基於最佳化的安全過濾器，透過在可行性和安全性約束遭到破壞時進行最小的調整，來認證編舞以進行實際部署。整體的 SwarmGPT-Primitive 框架將編舞設計與安全的動作規劃分開，這允許非專家使用者重新提示和調整構圖，而無需擔心是否符合約束，例如避免碰撞或下降氣流效應，或滿足致動限制。我們透過模擬和實驗來展示我們的做法，其中有最多 20 架無人機表演基於各種歌曲設計的編舞，突顯了系統為實際部署產生有效且同步的無人機編舞的能力。

##### **Detecting Conversational Mental Manipulation with Intent-Aware Prompting**
2412.08414v1 by Jiayuan Ma, Hongbin Na, Zimu Wang, Yining Hua, Yue Liu, Wei Wang, Ling Chen

Mental manipulation severely undermines mental wellness by covertly and
negatively distorting decision-making. While there is an increasing interest in
mental health care within the natural language processing community, progress
in tackling manipulation remains limited due to the complexity of detecting
subtle, covert tactics in conversations. In this paper, we propose Intent-Aware
Prompting (IAP), a novel approach for detecting mental manipulations using
large language models (LLMs), providing a deeper understanding of manipulative
tactics by capturing the underlying intents of participants. Experimental
results on the MentalManip dataset demonstrate superior effectiveness of IAP
against other advanced prompting strategies. Notably, our approach
substantially reduces false negatives, helping detect more instances of mental
manipulation with minimal misjudgment of positive cases. The code of this paper
is available at https://github.com/Anton-Jiayuan-MA/Manip-IAP.

摘要：心理操縱通過隱蔽和負面地扭曲決策制定嚴重破壞心理健康。儘管自然語言處理社群對心理保健越來越感興趣，但由於在對話中偵測微妙、隱蔽策略的複雜性，因此在應對操縱方面的進展仍然有限。在本文中，我們提出意圖感知提示 (IAP)，這是一種使用大型語言模型 (LLM) 偵測心理操縱的新方法，通過捕捉參與者的基本意圖，更深入地理解操縱策略。MentalManip 資料集上的實驗結果證明了 IAP 優於其他先進提示策略的優越有效性。值得注意的是，我們的做法大幅減少了假陰性，有助於偵測更多的心理操縱案例，同時將陽性案例的誤判降到最低。本文的程式碼可在 https://github.com/Anton-Jiayuan-MA/Manip-IAP 取得。

##### **Learning to Reason via Self-Iterative Process Feedback for Small Language Models**
2412.08393v1 by Kaiyuan Chen, Jin Wang, Xuejie Zhang

Small language models (SLMs) are more efficient, cost-effective, and
customizable than large language models (LLMs), though they often underperform
in specific areas like reasoning. Past methods for enhancing SLMs' reasoning,
such as supervised fine-tuning and distillation, often depend on costly
external signals, resulting in SLMs being overly confident with limited
supervision signals, thus limiting their abilities. Therefore, this study
enables SLMs to learn to reason from self-iterative feedback. By combining odds
ratio preference optimization (ORPO), we fine-tune and align SLMs using
positive and negative signals generated by themselves. Additionally, we
introduce process supervision for rewards in preference alignment by
sampling-based inference simulation and process reward models. Compared to
Supervised Fine-Tuning (SFT), our method improves the performance of Gemma-2B
by 12.43 (Acc) on GSM8K and 3.95 (Pass@1) on MBPP. Furthermore, the proposed
method also demonstrated superior out-of-domain generalization capabilities on
MMLU_Math and HumanEval.

摘要：小型语言模型 (SLM) 比大型语言模型 (LLM) 更有效率、更具成本效益且更具可定制性，尽管它们在推理等特定领域通常表现不佳。过去增强 SLM 推理的方法，例如监督微调和蒸馏，通常依赖于昂贵的外部信号，导致 SLM 对有限的监督信号过度自信，从而限制了它们的能力。因此，本研究使 SLM 能够从自我迭代反馈中学习推理。通过结合比值偏好优化 (ORPO)，我们使用自身生成的正负信号对 SLM 进行微调和对齐。此外，我们通过基于采样的推理模拟和过程奖励模型，引入了奖励的过程监督以进行偏好对齐。与监督微调 (SFT) 相比，我们的方法在 GSM8K 上将 Gemma-2B 的性能提高了 12.43（Acc），在 MBPP 上提高了 3.95（Pass@1）。此外，所提出的方法还在 MMLU_Math 和 HumanEval 上展示了出色的域外泛化能力。

##### **The Roles of English in Evaluating Multilingual Language Models**
2412.08392v1 by Wessel Poelman, Miryam de Lhoneux

Multilingual natural language processing is getting increased attention, with
numerous models, benchmarks, and methods being released for many languages.
English is often used in multilingual evaluation to prompt language models
(LMs), mainly to overcome the lack of instruction tuning data in other
languages. In this position paper, we lay out two roles of English in
multilingual LM evaluations: as an interface and as a natural language. We
argue that these roles have different goals: task performance versus language
understanding. This discrepancy is highlighted with examples from datasets and
evaluation setups. Numerous works explicitly use English as an interface to
boost task performance. We recommend to move away from this imprecise method
and instead focus on furthering language understanding.

摘要：多語言自然語言處理正受到越來越多的關注，許多語言都發布了大量的模型、基準和方法。英語通常用於多語言評估，以提示語言模型 (LM)，主要是為了克服其他語言中缺乏指令調整數據的問題。在本文中，我們闡述了英語在多語言 LM 評估中的兩個角色：作為介面和作為自然語言。我們認為這些角色有不同的目標：任務執行與語言理解。這種差異通過數據集和評估設置的範例得到強調。許多作品明確使用英語作為介面來提升任務執行。我們建議遠離這種不精確的方法，而應專注於進一步提升語言理解。

##### **SweetieChat: A Strategy-Enhanced Role-playing Framework for Diverse Scenarios Handling Emotional Support Agent**
2412.08389v1 by Jing Ye, Lu Xiang, Yaping Zhang, Chengqing Zong

Large Language Models (LLMs) have demonstrated promising potential in
providing empathetic support during interactions. However, their responses
often become verbose or overly formulaic, failing to adequately address the
diverse emotional support needs of real-world scenarios. To tackle this
challenge, we propose an innovative strategy-enhanced role-playing framework,
designed to simulate authentic emotional support conversations. Specifically,
our approach unfolds in two steps: (1) Strategy-Enhanced Role-Playing
Interactions, which involve three pivotal roles -- Seeker, Strategy Counselor,
and Supporter -- engaging in diverse scenarios to emulate real-world
interactions and promote a broader range of dialogues; and (2) Emotional
Support Agent Training, achieved through fine-tuning LLMs using our specially
constructed dataset. Within this framework, we develop the \textbf{ServeForEmo}
dataset, comprising an extensive collection of 3.7K+ multi-turn dialogues and
62.8K+ utterances. We further present \textbf{SweetieChat}, an emotional
support agent capable of handling diverse open-domain scenarios. Extensive
experiments and human evaluations confirm the framework's effectiveness in
enhancing emotional support, highlighting its unique ability to provide more
nuanced and tailored assistance.

摘要：大型語言模型 (LLM) 在互動中提供同理心支持方面已展現出有希望的潛力。然而，他們的回應常常變得冗長或過於公式化，無法充分滿足現實世界場景中多樣的情緒支持需求。為了應對這一挑戰，我們提出了一個創新的策略增強角色扮演框架，旨在模擬真實的情緒支持對話。具體來說，我們的做法分為兩個步驟：(1) 策略增強的角色扮演互動，其中涉及三個關鍵角色——尋求者、策略顧問和支持者——參與不同的場景，模擬現實世界的互動並促進更廣泛的對話；(2) 情緒支持代理訓練，通過使用我們專門構建的數據集對 LLM 進行微調來實現。在此框架內，我們開發了 \textbf{ServeForEmo} 數據集，其中包含 3.7K+ 多輪對話和 62.8K+ 話語的廣泛集合。我們進一步提出了 \textbf{SweetieChat}，這是一個能夠處理多樣開放領域場景的情緒支持代理。廣泛的實驗和人類評估證實了該框架在增強情緒支持方面的有效性，突出了其提供更細緻和個性化協助的獨特能力。

##### **NyayaAnumana & INLegalLlama: The Largest Indian Legal Judgment Prediction Dataset and Specialized Language Model for Enhanced Decision Analysis**
2412.08385v1 by Shubham Kumar Nigam, Balaramamahanthi Deepak Patnaik, Shivam Mishra, Noel Shallum, Kripabandhu Ghosh, Arnab Bhattacharya

The integration of artificial intelligence (AI) in legal judgment prediction
(LJP) has the potential to transform the legal landscape, particularly in
jurisdictions like India, where a significant backlog of cases burdens the
legal system. This paper introduces NyayaAnumana, the largest and most diverse
corpus of Indian legal cases compiled for LJP, encompassing a total of 7,02,945
preprocessed cases. NyayaAnumana, which combines the words "Nyay" (judgment)
and "Anuman" (prediction or inference) respectively for most major Indian
languages, includes a wide range of cases from the Supreme Court, High Courts,
Tribunal Courts, District Courts, and Daily Orders and, thus, provides
unparalleled diversity and coverage. Our dataset surpasses existing datasets
like PredEx and ILDC, offering a comprehensive foundation for advanced AI
research in the legal domain.
  In addition to the dataset, we present INLegalLlama, a domain-specific
generative large language model (LLM) tailored to the intricacies of the Indian
legal system. It is developed through a two-phase training approach over a base
LLaMa model. First, Indian legal documents are injected using continual
pretraining. Second, task-specific supervised finetuning is done. This method
allows the model to achieve a deeper understanding of legal contexts.
  Our experiments demonstrate that incorporating diverse court data
significantly boosts model accuracy, achieving approximately 90% F1-score in
prediction tasks. INLegalLlama not only improves prediction accuracy but also
offers comprehensible explanations, addressing the need for explainability in
AI-assisted legal decisions.

摘要：人工智慧 (AI) 整合於法律判決預測 (LJP) 有可能轉化法律領域，特別是在像印度這樣案件積壓量大到成為法律系統負擔的司法管轄區。本文介紹 NyayaAnumana，這是一個針對 LJP 編纂的印度法律案件中規模最大且最多樣化的語料庫，總共包含 7,02,945 個經過預處理的案件。NyayaAnumana 結合了「Nyay」（判決）和「Anuman」（預測或推論）這兩個字，分別用於大多數主要的印度語言，包含了來自最高法院、高等法院、法庭、地方法院和每日命令的廣泛案件，因此提供了無與倫比的多樣性和涵蓋範圍。我們的資料集超越了現有的資料集，例如 PredEx 和 ILDC，為法律領域的高階 AI 研究提供了全面的基礎。
除了資料集之外，我們還展示了 INLegalLlama，這是一個針對印度法律系統的複雜性量身打造的特定領域生成式大型語言模型 (LLM)。它是透過在基礎 LLaMa 模型上進行兩階段訓練方法開發的。首先，使用持續預訓練注入印度法律文件。其次，執行特定於任務的監督微調。此方法讓模型能夠更深入地了解法律脈絡。
我們的實驗證明，整合多樣化的法庭資料會顯著提升模型準確度，在預測任務中達到約 90% 的 F1 分數。INLegalLlama 不僅提高了預測準確度，也提供了易於理解的解釋，滿足了 AI 輔助法律決策中對可解釋性的需求。

##### **HyViLM: Enhancing Fine-Grained Recognition with a Hybrid Encoder for Vision-Language Models**
2412.08378v1 by Shiding Zhu, Wenhui Dong, Jun Song, Yanan Guo, Bo Zheng

Recently, there has been growing interest in the capability of multimodal
large language models (MLLMs) to process high-resolution images. A common
approach currently involves dynamically cropping the original high-resolution
image into smaller sub-images, which are then fed into a vision encoder that
was pre-trained on lower-resolution images. However, this cropping approach
often truncates objects and connected areas in the original image, causing
semantic breaks. To address this limitation, we introduce HyViLM, designed to
process images of any resolution while retaining the overall context during
encoding. Specifically, we: (i) Design a new visual encoder called Hybrid
Encoder that not only encodes individual sub-images but also interacts with
detailed global visual features, significantly improving the model's ability to
encode high-resolution images. (ii) Propose an optimal feature fusion strategy
for the dynamic cropping approach, effectively leveraging information from
different layers of the vision encoder. Compared with the state-of-the-art
MLLMs under the same setting, our HyViLM outperforms existing MLLMs in nine out
of ten tasks. Specifically, HyViLM achieves a 9.6% improvement in performance
on the TextVQA task and a 6.9% enhancement on the DocVQA task.

摘要：<paragraph>最近，人们对多模态大型语言模型 (MLLM) 处理高分辨率图像的能力越来越感兴趣。目前，一种常见的方法涉及将原始高分辨率图像动态裁剪成较小的子图像，然后将其输入到在低分辨率图像上预训练的视觉编码器中。然而，这种裁剪方法通常会截断原始图像中的对象和连接区域，从而导致语义中断。为了解决这一限制，我们引入了 HyViLM，它旨在处理任何分辨率的图像，同时在编码期间保留整体上下文。具体来说，我们：(i) 设计了一种新的视觉编码器，称为混合编码器，它不仅可以对各个子图像进行编码，还可以与详细的全局视觉特征进行交互，从而显著提高模型对高分辨率图像进行编码的能力。(ii) 为动态裁剪方法提出了一种最佳特征融合策略，有效地利用了视觉编码器不同层的信息。与在相同设置下的最先进的 MLLM 相比，我们的 HyViLM 在十分之九的任务中优于现有的 MLLM。具体来说，HyViLM 在 TextVQA 任务上的性能提高了 9.6%，在 DocVQA 任务上的性能提高了 6.9%。</paragraph>

##### **SmolTulu: Higher Learning Rate to Batch Size Ratios Can Lead to Better Reasoning in SLMs**
2412.08347v1 by Sultan Alrashed

We present SmolTulu-1.7b-Instruct, referenced in this report as
SmolTulu-DPO-1130, an instruction-tuned language model that adapts AllenAI's
Tulu 3 post-training pipeline to enhance Huggingface's SmolLM2-1.7B base model.
Through comprehensive empirical analysis using a 135M parameter model, we
demonstrate that the relationship between learning rate and batch size
significantly impacts model performance in a task-dependent manner. Our
findings reveal a clear split: reasoning tasks like ARC and GSM8K benefit from
higher learning rate to batch size ratios, while pattern recognition tasks such
as HellaSwag and IFEval show optimal performance with lower ratios. These
insights informed the development of SmolTulu, which achieves state-of-the-art
performance among sub-2B parameter models on instruction following, scoring
67.7% on IFEval ($\Delta$11%), and mathematical reasoning with 51.6% on GSM8K
($\Delta$3.4%), with an alternate version achieving scoring 57.1% on ARC
($\Delta5.4%$). We release our model, training recipes, and ablation studies to
facilitate further research in efficient model alignment, demonstrating that
careful adaptation of optimization dynamics can help bridge the capability gap
between small and large language models.

摘要：我們提出 SmolTulu-1.7b-Instruct，本報告中稱為 SmolTulu-DPO-1130，這是一種指令調整語言模型，採用 AllenAI 的 Tulu 3 後訓練管道來增強 Huggingface 的 SmolLM2-1.7B 基礎模型。透過使用 135M 參數模型的全面經驗分析，我們證明學習率與批次大小之間的關係會以任務相關的方式顯著影響模型效能。我們的發現揭示了一個明確的分歧：像 ARC 和 GSM8K 等推理任務受益於較高的學習率對批次大小的比率，而像 HellaSwag 和 IFEval 等模式辨識任務則顯示出較低比率的最佳效能。這些見解為 SmolTulu 的開發提供了資訊，在小於 2B 參數模型中，在指令遵循方面取得了最先進的表現，在 IFEval 上得分 67.7%（Δ11%），在 GSM8K 上的數學推理得分為 51.6%（Δ3.4%），而另一個版本在 ARC 上得分 57.1%（Δ5.4%）。我們發布我們的模型、訓練範例和消融研究，以促進高效模型對齊的進一步研究，證明仔細調整最佳化動態可以幫助縮小小型和大型語言模型之間的能力差距。

##### **BEIR-NL: Zero-shot Information Retrieval Benchmark for the Dutch Language**
2412.08329v1 by Nikolay Banar, Ehsan Lotfi, Walter Daelemans

Zero-shot evaluation of information retrieval (IR) models is often performed
using BEIR; a large and heterogeneous benchmark composed of multiple datasets,
covering different retrieval tasks across various domains. Although BEIR has
become a standard benchmark for the zero-shot setup, its exclusively English
content reduces its utility for underrepresented languages in IR, including
Dutch. To address this limitation and encourage the development of Dutch IR
models, we introduce BEIR-NL by automatically translating the publicly
accessible BEIR datasets into Dutch. Using BEIR-NL, we evaluated a wide range
of multilingual dense ranking and reranking models, as well as the lexical BM25
method. Our experiments show that BM25 remains a competitive baseline, and is
only outperformed by the larger dense models trained for retrieval. When
combined with reranking models, BM25 achieves performance on par with the best
dense ranking models. In addition, we explored the impact of translation on the
data by back-translating a selection of datasets to English, and observed a
performance drop for both dense and lexical methods, indicating the limitations
of translation for creating benchmarks. BEIR-NL is publicly available on the
Hugging Face hub.

摘要：資訊檢索 (IR) 模型的零次評估通常使用 BEIR 執行；這是一個大型且異質的基準，由多個資料集組成，涵蓋各種領域的不同檢索任務。雖然 BEIR 已成為零次設定的標準基準，但其專屬的英文內容降低了其在 IR 中代表性不足的語言（包括荷蘭語）中的效用。為了解決這個限制並鼓勵開發荷蘭語 IR 模型，我們透過將公開可存取的 BEIR 資料集自動翻譯成荷蘭語來引入 BEIR-NL。使用 BEIR-NL，我們評估了廣泛的多語言密集排名和重新排名模型，以及詞彙 BM25 方法。我們的實驗顯示，BM25 仍然是一個有競爭力的基準，並且僅次於針對檢索訓練的較大型密集模型。與重新排名模型結合時，BM25 的效能與最佳密集排名模型相當。此外，我們透過將部分資料集反向翻譯成英文來探討翻譯對資料的影響，並觀察到密集和詞彙方法的效能下降，這表示翻譯在建立基準上的限制。BEIR-NL 已在 Hugging Face 集散地中公開。

##### **Large Language Models Still Face Challenges in Multi-Hop Reasoning with External Knowledge**
2412.08317v1 by Haotong Zhang

We carry out a series of experiments to test large language models' multi-hop
reasoning ability from three aspects: selecting and combining external
knowledge, dealing with non-sequential reasoning tasks and generalising to data
samples with larger numbers of hops. We test the GPT-3.5 model on four
reasoning benchmarks with Chain-of-Thought prompting (and its variations). Our
results reveal that despite the amazing performance achieved by large language
models on various reasoning tasks, models still suffer from severe drawbacks
which shows a large gap with humans.

摘要：我們進行一系列實驗，從三個方面測試大型語言模型的多跳推理能力：選擇和組合外部知識、處理非順序推理任務以及推廣到具有更多跳數的數據樣本。我們在四個推理基準上測試 GPT-3.5 模型，並使用思考鏈提示（及其變體）。我們的結果表明，儘管大型語言模型在各種推理任務上取得了驚人的表現，但模型仍然存在嚴重的缺點，這表明與人類存在很大的差距。

##### **Rumor Detection on Social Media with Temporal Propagation Structure Optimization**
2412.08316v1 by Xingyu Peng, Junran Wu, Ruomei Liu, Ke Xu

Traditional methods for detecting rumors on social media primarily focus on
analyzing textual content, often struggling to capture the complexity of online
interactions. Recent research has shifted towards leveraging graph neural
networks to model the hierarchical conversation structure that emerges during
rumor propagation. However, these methods tend to overlook the temporal aspect
of rumor propagation and may disregard potential noise within the propagation
structure. In this paper, we propose a novel approach that incorporates
temporal information by constructing a weighted propagation tree, where the
weight of each edge represents the time interval between connected posts.
Drawing upon the theory of structural entropy, we transform this tree into a
coding tree. This transformation aims to preserve the essential structure of
rumor propagation while reducing noise. Finally, we introduce a recursive
neural network to learn from the coding tree for rumor veracity prediction.
Experimental results on two common datasets demonstrate the superiority of our
approach.

摘要：傳統的社群媒體謠言偵測方法主要著重於分析文字內容，通常難以捕捉線上互動的複雜性。最近的研究已轉向利用圖形神經網路來模擬謠言傳播期間出現的階層式對話結構。然而，這些方法傾向於忽略謠言傳播的時間面向，並可能忽略傳播結構中的潛在雜訊。在本文中，我們提出一個新的方法，透過建構加權傳播樹來納入時間資訊，其中每條邊的權重代表連接貼文之間的時間間隔。根據結構熵理論，我們將這棵樹轉換成編碼樹。此轉換旨在保留謠言傳播的基本結構，同時減少雜訊。最後，我們引入遞迴神經網路，從編碼樹中學習以進行謠言真實性預測。在兩個常見資料集上的實驗結果證明了我們方法的優越性。

##### **Self-Refining Diffusion Samplers: Enabling Parallelization via Parareal Iterations**
2412.08292v1 by Nikil Roashan Selvam, Amil Merchant, Stefano Ermon

In diffusion models, samples are generated through an iterative refinement
process, requiring hundreds of sequential model evaluations. Several recent
methods have introduced approximations (fewer discretization steps or
distillation) to trade off speed at the cost of sample quality. In contrast, we
introduce Self-Refining Diffusion Samplers (SRDS) that retain sample quality
and can improve latency at the cost of additional parallel compute. We take
inspiration from the Parareal algorithm, a popular numerical method for
parallel-in-time integration of differential equations. In SRDS, a quick but
rough estimate of a sample is first created and then iteratively refined in
parallel through Parareal iterations. SRDS is not only guaranteed to accurately
solve the ODE and converge to the serial solution but also benefits from
parallelization across the diffusion trajectory, enabling batched inference and
pipelining. As we demonstrate for pre-trained diffusion models, the early
convergence of this refinement procedure drastically reduces the number of
steps required to produce a sample, speeding up generation for instance by up
to 1.7x on a 25-step StableDiffusion-v2 benchmark and up to 4.3x on longer
trajectories.

摘要：在擴散模型中，樣本是透過反覆的精煉過程產生的，需要進行數百次順序模型評估。最近有幾種方法引入了近似值（較少的離散化步驟或蒸餾）來以樣本品質為代價來換取速度。相反地，我們引入了自我精煉擴散取樣器 (SRDS)，它保留了樣本品質，並且可以以額外的並行運算為代價來改善延遲。我們從 Parareal 演算法中汲取靈感，這是一種用於微分方程式並行時間積分的熱門數值方法。在 SRDS 中，首先建立一個快速但粗略的樣本估計，然後透過 Parareal 迭代並行地反覆精煉。SRDS 不僅保證準確地求解 ODE 並收斂到序列解，而且還受益於擴散軌跡的並行化，從而實現批次推論和流水線。正如我們為預先訓練的擴散模型所展示的那樣，這種精煉程序的早期收斂大幅減少了產生樣本所需的步驟數，例如，在 25 步的 StableDiffusion-v2 基準上將生成速度提高了 1.7 倍，在更長的軌跡上將速度提高了 4.3 倍。

##### **Code LLMs: A Taxonomy-based Survey**
2412.08291v1 by Nishat Raihan, Christian Newman, Marcos Zampieri

Large language models (LLMs) have demonstrated remarkable capabilities across
various NLP tasks and have recently expanded their impact to coding tasks,
bridging the gap between natural languages (NL) and programming languages (PL).
This taxonomy-based survey provides a comprehensive analysis of LLMs in the
NL-PL domain, investigating how these models are utilized in coding tasks and
examining their methodologies, architectures, and training processes. We
propose a taxonomy-based framework that categorizes relevant concepts,
providing a unified classification system to facilitate a deeper understanding
of this rapidly evolving field. This survey offers insights into the current
state and future directions of LLMs in coding tasks, including their
applications and limitations.

摘要：大型語言模型（LLM）已在各種 NLP 任務中展現出非凡的能力，最近更擴展其影響力至編碼任務，縮小了自然語言（NL）與程式語言（PL）之間的差距。這項基於分類的調查提供了 LLM 在 NL-PL 領域的全面分析，探討了這些模型如何用於編碼任務，並檢視其方法、架構和訓練流程。我們提出了一個基於分類的架構，對相關概念進行分類，提供了一個統一的分類系統，以促進對這個快速演變的領域有更深入的了解。這項調查提供了對 LLM 在編碼任務中當前狀態和未來方向的見解，包括其應用和限制。

##### **Adaptive Prompting for Continual Relation Extraction: A Within-Task Variance Perspective**
2412.08285v1 by Minh Le, Tien Ngoc Luu, An Nguyen The, Thanh-Thien Le, Trang Nguyen, Thanh Tung Nguyen, Linh Ngo Van, Thien Huu Nguyen

To address catastrophic forgetting in Continual Relation Extraction (CRE),
many current approaches rely on memory buffers to rehearse previously learned
knowledge while acquiring new tasks. Recently, prompt-based methods have
emerged as potent alternatives to rehearsal-based strategies, demonstrating
strong empirical performance. However, upon analyzing existing prompt-based
approaches for CRE, we identified several critical limitations, such as
inaccurate prompt selection, inadequate mechanisms for mitigating forgetting in
shared parameters, and suboptimal handling of cross-task and within-task
variances. To overcome these challenges, we draw inspiration from the
relationship between prefix-tuning and mixture of experts, proposing a novel
approach that employs a prompt pool for each task, capturing variations within
each task while enhancing cross-task variances. Furthermore, we incorporate a
generative model to consolidate prior knowledge within shared parameters,
eliminating the need for explicit data storage. Extensive experiments validate
the efficacy of our approach, demonstrating superior performance over
state-of-the-art prompt-based and rehearsal-free methods in continual relation
extraction.

摘要：為了解決持續關係萃取 (CRE) 中的災難性遺忘，許多現有方法依賴記憶體緩衝區來排練先前學習的知識，同時獲取新任務。最近，基於提示的方法已成為基於排練策略的有力替代方案，展示出強大的經驗效能。然而，在分析現有的基於提示的 CRE 方法後，我們發現了幾個關鍵限制，例如不準確的提示選擇、減輕共享參數中遺忘的不充分機制，以及對跨任務和任務內變異的次優處理。為了克服這些挑戰，我們從前綴調整和專家混合之間的關係中汲取靈感，提出了一種新方法，該方法為每個任務採用提示池，捕捉每個任務內的變異，同時增強跨任務變異。此外，我們結合了一個生成模型來整合共享參數內的先前知識，消除了對明確資料儲存的需求。廣泛的實驗驗證了我們方法的效力，展示了在持續關係萃取中優於最先進的基於提示和無排練方法的卓越效能。

##### **A Preliminary Analysis of Automatic Word and Syllable Prominence Detection in Non-Native Speech With Text-to-Speech Prosody Embeddings**
2412.08283v1 by Anindita Mondal, Rangavajjala Sankara Bharadwaj, Jhansi Mallela, Anil Kumar Vuppala, Chiranjeevi Yarra

Automatic detection of prominence at the word and syllable-levels is critical
for building computer-assisted language learning systems. It has been shown
that prosody embeddings learned by the current state-of-the-art (SOTA)
text-to-speech (TTS) systems could generate word- and syllable-level prominence
in the synthesized speech as natural as in native speech. To understand the
effectiveness of prosody embeddings from TTS for prominence detection under
nonnative context, a comparative analysis is conducted on the embeddings
extracted from native and non-native speech considering the prominence-related
embeddings: duration, energy, and pitch from a SOTA TTS named FastSpeech2.
These embeddings are extracted under two conditions considering: 1) only text,
2) both speech and text. For the first condition, the embeddings are extracted
directly from the TTS inference mode, whereas for the second condition, we
propose to extract from the TTS under training mode. Experiments are conducted
on native speech corpus: Tatoeba, and non-native speech corpus: ISLE. For
experimentation, word-level prominence locations are manually annotated for
both corpora. The highest relative improvement on word \& syllable-level
prominence detection accuracies with the TTS embeddings are found to be 13.7% &
5.9% and 16.2% & 6.9% compared to those with the heuristic-based features and
self-supervised Wav2Vec-2.0 representations, respectively.

摘要：自動偵測單字和音節層級的重音對於建構電腦輔助語言學習系統至關重要。目前最先進 (SOTA) 的文字轉語音 (TTS) 系統所學習到的韻律嵌入，已被證實可以合成出與母語人士說話一樣自然的單字和音節層級重音。為了了解 TTS 韻律嵌入在非母語脈絡中用於重音偵測的有效性，我們對從母語和非母語演說中萃取出的嵌入進行比較分析，考量 SOTA TTS（稱為 FastSpeech2）中與重音相關的嵌入：時長、能量和音高。這些嵌入是在兩個條件下萃取的：1) 只有文字，2) 語音和文字皆有。對於第一個條件，嵌入是直接從 TTS 推論模式中萃取，而對於第二個條件，我們建議從訓練模式中的 TTS 中萃取。實驗是在母語語料庫：Tatoeba 和非母語語料庫：ISLE 上進行。為了實驗，兩個語料庫的單字層級重音位置都經過手動標註。發現使用 TTS 嵌入在單字和音節層級重音偵測準確率上最高的相對改善為 13.7% 和 5.9% 以及 16.2% 和 6.9%，分別與基於啟發式特徵和自監督 Wav2Vec-2.0 表徵相比。

##### **Y-NQ: English-Yorùbá Evaluation dataset for Open-Book Reading Comprehension and Text Generation**
2412.08279v1 by Marta R. Costa-jussà, Joy Chen, Ifeoluwanimi Adebara, Joe Chuang, Christophe Ropers, Eduardo Sánchez

The purpose of this work is to share an English-Yor\`ub\'a evaluation dataset
for open-book reading comprehension and text generation to assess the
performance of models both in a high- and a low- resource language. The dataset
contains 358 questions and answers on 338 English documents and 208 Yor\`ub\'a
documents. The average document length is ~ 10k words for English and 430 words
for Yor\`ub\'a. Experiments show a consistent disparity in performance between
the two languages, with Yor\`ub\'a falling behind English for automatic metrics
even if documents are much shorter for this language. For a small set of
documents with comparable length, performance of Yor\`ub\'a drops by x2.5
times. When analyzing performance by length, we observe that Yor\`ub\'a
decreases performance dramatically for documents that reach 1500 words while
English performance is barely affected at that length. Our dataset opens the
door to showcasing if English LLM reading comprehension capabilities extend to
Yor\`ub\'a, which for the evaluated LLMs is not the case.

摘要：本研究的目的是分享一个英语-约鲁巴语评估数据集，用于开放式阅读理解和文本生成，以评估模型在高资源和低资源语言中的表现。该数据集包含 358 个问题和答案，涉及 338 篇英语文档和 208 篇约鲁巴语文档。英语文档的平均长度约为 10k 个单词，约鲁巴语文档的平均长度为 430 个单词。实验表明，两种语言在表现上存在持续的差异，约鲁巴语在自动指标方面落后于英语，即使该语言的文档要短得多。对于一组长度相当的文档，约鲁巴语的表现下降了 x2.5 倍。在按长度分析表现时，我们观察到，约鲁巴语在文档达到 1500 个单词时表现急剧下降，而英语在该长度下的表现几乎没有受到影响。我们的数据集展示了英语 LLM 阅读理解能力是否扩展到约鲁巴语，对于评估过的 LLM 来说，事实并非如此。

##### **2M-BELEBELE: Highly Multilingual Speech and American Sign Language Comprehension Dataset**
2412.08274v1 by Marta R. Costa-jussà, Bokai Yu, Pierre Andrews, Belen Alastruey, Necati Cihan Camgoz, Joe Chuang, Jean Maillard, Christophe Ropers, Arina Turkantenko, Carleigh Wood

We introduce the first highly multilingual speech and American Sign Language
(ASL) comprehension dataset by extending BELEBELE. Our dataset covers 74 spoken
languages at the intersection of BELEBELE and FLEURS, and one sign language
(ASL). We evaluate 2M-BELEBELE dataset for both 5-shot and zero-shot settings
and across languages, the speech comprehension accuracy is ~ 8% average lower
compared to reading comprehension.

摘要：我們透過擴充 BELEBELE 介紹第一個高度多語言的語音和美國手語 (ASL) 理解資料集。我們的資料集涵蓋 BELEBELE 和 FLEURS 交集中的 74 種口說語言，以及一種手語 (ASL)。我們針對 5-shot 和 zero-shot 設定以及跨語言評估 2M-BELEBELE 資料集，與閱讀理解相比，語音理解準確度平均低約 8%。

##### **Position-aware Guided Point Cloud Completion with CLIP Model**
2412.08271v1 by Feng Zhou, Qi Zhang, Ju Dai, Lei Li, Qing Fan, Junliang Xing

Point cloud completion aims to recover partial geometric and topological
shapes caused by equipment defects or limited viewpoints. Current methods
either solely rely on the 3D coordinates of the point cloud to complete it or
incorporate additional images with well-calibrated intrinsic parameters to
guide the geometric estimation of the missing parts. Although these methods
have achieved excellent performance by directly predicting the location of
complete points, the extracted features lack fine-grained information regarding
the location of the missing area. To address this issue, we propose a rapid and
efficient method to expand an unimodal framework into a multimodal framework.
This approach incorporates a position-aware module designed to enhance the
spatial information of the missing parts through a weighted map learning
mechanism. In addition, we establish a Point-Text-Image triplet corpus PCI-TI
and MVP-TI based on the existing unimodal point cloud completion dataset and
use the pre-trained vision-language model CLIP to provide richer detail
information for 3D shapes, thereby enhancing performance. Extensive
quantitative and qualitative experiments demonstrate that our method
outperforms state-of-the-art point cloud completion methods.

摘要：點雲完成的目標是復原因設備缺陷或視點受限而造成的局部幾何和拓撲形狀。目前的方法，要不只依賴點雲的 3D 座標來完成它，要不就結合額外具有良好校正內部參數的影像，來引導遺失部分的幾何估計。雖然這些方法透過直接預測完整點的位置，達到了絕佳的表現，但提取出的特徵缺乏有關遺失區域位置的細微資訊。為了解決這個問題，我們提出一個快速且有效率的方法，將單峰架構擴展成多峰架構。此方法結合了一個位置感知模組，旨在透過加權地圖學習機制，提升遺失部分的空間資訊。此外，我們在現有的單峰點雲完成資料集的基礎上，建立了一個點-文字-影像三重體語料庫 PCI-TI 和 MVP-TI，並使用預先訓練好的視覺語言模型 CLIP，來提供更豐富的細節資訊，用於 3D 形狀，進而提升效能。廣泛的量化和定性實驗證明，我們的方法優於現有的點雲完成方法。

##### **LCFO: Long Context and Long Form Output Dataset and Benchmarking**
2412.08268v1 by Marta R. Costa-jussà, Pierre Andrews, Mariano Coria Meglioli, Joy Chen, Joe Chuang, David Dale, Christophe Ropers, Alexandre Mourachko, Eduardo Sánchez, Holger Schwenk, Tuan Tran, Arina Turkatenko, Carleigh Wood

This paper presents the Long Context and Form Output (LCFO) benchmark, a
novel evaluation framework for assessing gradual summarization and summary
expansion capabilities across diverse domains. LCFO consists of long input
documents (5k words average length), each of which comes with three summaries
of different lengths (20%, 10%, and 5% of the input text), as well as
approximately 15 questions and answers (QA) related to the input content.
Notably, LCFO also provides alignments between specific QA pairs and
corresponding summaries in 7 domains. The primary motivation behind providing
summaries of different lengths is to establish a controllable framework for
generating long texts from shorter inputs, i.e. summary expansion. To establish
an evaluation metric framework for summarization and summary expansion, we
provide human evaluation scores for human-generated outputs, as well as results
from various state-of-the-art large language models (LLMs). GPT-4o-mini
achieves best human scores among automatic systems in both summarization and
summary expansion tasks (~ +10% and +20%, respectively). It even surpasses
human output quality in the case of short summaries (~ +7%). Overall automatic
metrics achieve low correlations with human evaluation scores (~ 0.4) but
moderate correlation on specific evaluation aspects such as fluency and
attribution (~ 0.6). The LCFO benchmark offers a standardized platform for
evaluating summarization and summary expansion performance, as well as
corresponding automatic metrics, thereby providing an important evaluation
framework to advance generative AI.

摘要：<paragraph>這篇論文提出了長文本與形式輸出（LCFO）基準，一個用於評估漸進式摘要和摘要擴充能力的全新評估架構，適用於各種領域。LCFO 包含長輸入文件（平均長度 5k 字），每個文件都附有三個不同長度的摘要（輸入文字的 20%、10% 和 5%），以及大約 15 個與輸入內容相關的問題和答案 (QA)。值得注意的是，LCFO 還提供了特定 QA 對與對應摘要在 7 個領域之間的比對。提供不同長度的摘要的主要動機是建立一個可控的架構，用於從較短的輸入產生較長的文字，即摘要擴充。為了建立摘要和摘要擴充的評估指標架構，我們提供了人類對人類產出進行評估的分數，以及來自各種最先進的大語言模型 (LLM) 的結果。GPT-4o-mini 在摘要和摘要擴充任務中均獲得了自動系統中最佳的人類評分（分別為 ~ +10% 和 +20%）。在短摘要的情況下，它甚至超越了人類的輸出品質（~ +7%）。整體而言，自動指標與人類評分之間的相關性較低（~ 0.4），但在特定評估方面（例如流暢度和歸因）的相關性較高（~ 0.6）。LCFO 基準提供了一個標準化的平台，用於評估摘要和摘要擴充效能，以及對應的自動指標，從而提供了一個重要的評估架構來推進生成式 AI。</paragraph>

##### **Discrete Subgraph Sampling for Interpretable Graph based Visual Question Answering**
2412.08263v1 by Pascal Tilli, Ngoc Thang Vu

Explainable artificial intelligence (XAI) aims to make machine learning
models more transparent. While many approaches focus on generating explanations
post-hoc, interpretable approaches, which generate the explanations
intrinsically alongside the predictions, are relatively rare. In this work, we
integrate different discrete subset sampling methods into a graph-based visual
question answering system to compare their effectiveness in generating
interpretable explanatory subgraphs intrinsically. We evaluate the methods on
the GQA dataset and show that the integrated methods effectively mitigate the
performance trade-off between interpretability and answer accuracy, while also
achieving strong co-occurrences between answer and question tokens.
Furthermore, we conduct a human evaluation to assess the interpretability of
the generated subgraphs using a comparative setting with the extended
Bradley-Terry model, showing that the answer and question token co-occurrence
metrics strongly correlate with human preferences. Our source code is publicly
available.

摘要：可解釋人工智慧 (XAI) 旨在使機器學習模型更透明。儘管許多方法專注於事後產生解釋，但可解釋的方法（在預測的同時內建產生解釋）相對較少見。在此工作中，我們將不同的離散子集抽樣方法整合到基於圖形的視覺問答系統中，以比較它們在內建產生可解釋的解釋性子圖方面的有效性。我們在 GQA 資料集上評估這些方法，並表明整合的方法有效減輕了可解釋性與答案準確性之間的效能取捨，同時也實現了答案和問題標記之間的強共現。此外，我們進行人類評估以評估所產生子圖的可解釋性，並使用擴展的 Bradley-Terry 模型進行比較設定，結果表明答案和問題標記共現指標與人類偏好密切相關。我們的原始碼已公開。

##### **FLIP: Flow-Centric Generative Planning for General-Purpose Manipulation Tasks**
2412.08261v1 by Chongkai Gao, Haozhuo Zhang, Zhixuan Xu, Zhehao Cai, Lin Shao

We aim to develop a model-based planning framework for world models that can
be scaled with increasing model and data budgets for general-purpose
manipulation tasks with only language and vision inputs. To this end, we
present FLow-centric generative Planning (FLIP), a model-based planning
algorithm on visual space that features three key modules: 1. a multi-modal
flow generation model as the general-purpose action proposal module; 2. a
flow-conditioned video generation model as the dynamics module; and 3. a
vision-language representation learning model as the value module. Given an
initial image and language instruction as the goal, FLIP can progressively
search for long-horizon flow and video plans that maximize the discounted
return to accomplish the task. FLIP is able to synthesize long-horizon plans
across objects, robots, and tasks with image flows as the general action
representation, and the dense flow information also provides rich guidance for
long-horizon video generation. In addition, the synthesized flow and video
plans can guide the training of low-level control policies for robot execution.
Experiments on diverse benchmarks demonstrate that FLIP can improve both the
success rates and quality of long-horizon video plan synthesis and has the
interactive world model property, opening up wider applications for future
works.

摘要：我们旨在为世界模型开发一个基于模型的规划框架，该框架可以随着模型和数据预算的增加而扩展，仅使用语言和视觉输入即可完成通用操作任务。为此，我们提出了以流为中心的生成式规划 (FLIP)，这是一种基于视觉空间的基于模型的规划算法，具有三个关键模块：1. 多模态流生成模型作为通用动作提议模块；2. 流条件视频生成模型作为动力学模块；3. 视觉语言表示学习模型作为价值模块。给定一个初始图像和语言指令作为目标，FLIP 可以逐步搜索长视野流和视频计划，以最大化折扣回报以完成任务。FLIP 能够跨对象、机器人和任务综合长视野计划，以图像流作为通用动作表示，并且密集流信息还为长视野视频生成提供了丰富的指导。此外，合成的流和视频计划可以指导低级控制策略的训练以进行机器人执行。在不同基准上的实验表明，FLIP 可以提高长视野视频计划合成的成功率和质量，并且具有交互式世界模型属性，为未来的工作开辟了更广泛的应用。

##### **Large Language Models for Scholarly Ontology Generation: An Extensive Analysis in the Engineering Field**
2412.08258v1 by Tanay Aggarwal, Angelo Salatino, Francesco Osborne, Enrico Motta

Ontologies of research topics are crucial for structuring scientific
knowledge, enabling scientists to navigate vast amounts of research, and
forming the backbone of intelligent systems such as search engines and
recommendation systems. However, manual creation of these ontologies is
expensive, slow, and often results in outdated and overly general
representations. As a solution, researchers have been investigating ways to
automate or semi-automate the process of generating these ontologies. This
paper offers a comprehensive analysis of the ability of large language models
(LLMs) to identify semantic relationships between different research topics,
which is a critical step in the development of such ontologies. To this end, we
developed a gold standard based on the IEEE Thesaurus to evaluate the task of
identifying four types of relationships between pairs of topics: broader,
narrower, same-as, and other. Our study evaluates the performance of seventeen
LLMs, which differ in scale, accessibility (open vs. proprietary), and model
type (full vs. quantised), while also assessing four zero-shot reasoning
strategies. Several models have achieved outstanding results, including
Mixtral-8x7B, Dolphin-Mistral-7B, and Claude 3 Sonnet, with F1-scores of 0.847,
0.920, and 0.967, respectively. Furthermore, our findings demonstrate that
smaller, quantised models, when optimised through prompt engineering, can
deliver performance comparable to much larger proprietary models, while
requiring significantly fewer computational resources.

摘要：<paragraph>研究主題的本体論對於結構化科學知識至關重要，讓科學家能夠瀏覽大量的研究，並形成搜尋引擎和推薦系統等智慧系統的骨幹。然而，手動建立這些本体論的成本高昂、緩慢，而且經常導致過時且過於概括的表示。作為解決方案，研究人員一直在研究自動化或半自動化這些本体論生成過程的方法。本文全面分析了大型語言模型 (LLM) 識別不同研究主題之間語義關係的能力，這是開發此類本体論的關鍵步驟。為此，我們根據 IEEE 詞彙表開發了一個黃金標準，用於評估識別主題對之間四種類型關係的任務：較廣泛、較狹窄、相同，以及其他。我們的研究評估了十七個 LLM 的效能，這些 LLM 在規模、可及性（開放與專有）和模型類型（完整與量化）上有所不同，同時也評估了四種零次方推理策略。幾個模型取得了傑出的成果，包括 Mixtral-8x7B、Dolphin-Mistral-7B 和 Claude 3 Sonnet，F1 分數分別為 0.847、0.920 和 0.967。此外，我們的研究結果表明，較小、量化的模型在通過提示工程進行最佳化時，可以提供與規模更大的專有模型相當的效能，同時需要顯著更少的運算資源。</paragraph>

##### **Accurate Medical Named Entity Recognition Through Specialized NLP Models**
2412.08255v1 by Jiacheng Hu, Runyuan Bao, Yang Lin, Hanchao Zhang, Yanlin Xiang

This study evaluated the effect of BioBERT in medical text processing for the
task of medical named entity recognition. Through comparative experiments with
models such as BERT, ClinicalBERT, SciBERT, and BlueBERT, the results showed
that BioBERT achieved the best performance in both precision and F1 score,
verifying its applicability and superiority in the medical field. BioBERT
enhances its ability to understand professional terms and complex medical texts
through pre-training on biomedical data, providing a powerful tool for medical
information extraction and clinical decision support. The study also explored
the privacy and compliance challenges of BioBERT when processing medical data,
and proposed future research directions for combining other medical-specific
models to improve generalization and robustness. With the development of deep
learning technology, the potential of BioBERT in application fields such as
intelligent medicine, personalized treatment, and disease prediction will be
further expanded. Future research can focus on the real-time and
interpretability of the model to promote its widespread application in the
medical field.

摘要：本研究評估了 BioBERT 在醫療文本處理中對醫療命名實體識別任務的影響。通過與 BERT、ClinicalBERT、SciBERT 和 BlueBERT 等模型的比較實驗，結果表明 BioBERT 在精確度和 F1 分數方面均取得了最佳表現，驗證了其在醫療領域的適用性和優越性。BioBERT 通過對生物醫學數據的預訓練，增強了其理解專業術語和複雜醫療文本的能力，為醫療信息提取和臨床決策支持提供了強有力的工具。該研究還探討了 BioBERT 在處理醫療數據時面臨的隱私和合規挑戰，並提出了結合其他特定於醫療的模型以提高泛化性和魯棒性的未來研究方向。隨著深度學習技術的發展，BioBERT 在智能醫療、個性化治療和疾病預測等應用領域的潛力將進一步擴大。未來的研究可以關注模型的實時性和可解釋性，以促進其在醫療領域的廣泛應用。

##### **TouchTTS: An Embarrassingly Simple TTS Framework that Everyone Can Touch**
2412.08237v1 by Xingchen Song, Mengtao Xing, Changwei Ma, Shengqiang Li, Di Wu, Binbin Zhang, Fuping Pan, Dinghao Zhou, Yuekai Zhang, Shun Lei, Zhendong Peng, Zhiyong Wu

It is well known that LLM-based systems are data-hungry. Recent LLM-based TTS
works typically employ complex data processing pipelines to obtain high-quality
training data. These sophisticated pipelines require excellent models at each
stage (e.g., speech denoising, speech enhancement, speaker diarization, and
punctuation models), which themselves demand high-quality training data and are
rarely open-sourced. Even with state-of-the-art models, issues persist, such as
incomplete background noise removal and misalignment between punctuation and
actual speech pauses. Moreover, the stringent filtering strategies often retain
only 10-30\% of the original data, significantly impeding data scaling efforts.
In this work, we leverage a noise-robust audio tokenizer (S3Tokenizer) to
design a simplified yet effective TTS data processing pipeline that maintains
data quality while substantially reducing data acquisition costs, achieving a
data retention rate of over 50\%. Beyond data scaling challenges, LLM-based TTS
systems also incur higher deployment costs compared to conventional approaches.
Current systems typically use LLMs solely for text-to-token generation, while
requiring separate models (e.g., flow matching models) for token-to-waveform
generation, which cannot be directly executed by LLM inference engines, further
complicating deployment. To address these challenges, we eliminate redundant
modules in both LLM and flow components, replacing the flow model backbone with
an LLM architecture. Building upon this simplified flow backbone, we propose a
unified architecture for both streaming and non-streaming inference,
significantly reducing deployment costs. Finally, we explore the feasibility of
unifying TTS and ASR tasks using the same data for training, thanks to the
simplified pipeline and the S3Tokenizer that reduces the quality requirements
for TTS training data.

摘要：眾所周知，基於 LLM 的系統非常耗資料。最近基於 LLM 的 TTS 作品通常採用複雜的資料處理管線，以取得高品質的訓練資料。這些複雜的管線在每個階段都需要優秀的模型（例如語音去雜訊、語音增強、說話者日記化和標點符號模型），而這些模型本身需要高品質的訓練資料，而且很少開源。即使使用最先進的模型，問題仍然存在，例如背景雜訊移除不完全，以及標點符號和實際語音停頓之間的對齊錯誤。此外，嚴格的過濾策略通常只保留原始資料的 10-30%，這會顯著阻礙資料擴充工作。在這項工作中，我們利用抗雜訊音訊分詞器 (S3Tokenizer) 來設計一個簡化但有效的 TTS 資料處理管線，在大幅降低資料取得成本的同時，維持資料品質，達成超過 50% 的資料保留率。除了資料擴充的挑戰之外，與傳統方法相比，基於 LLM 的 TTS 系統也產生更高的部署成本。目前的系統通常只使用 LLM 來進行文字到代碼的產生，同時需要不同的模型（例如流程匹配模型）來進行代碼到波形的產生，而 LLM 推論引擎無法直接執行這些模型，這進一步複雜化了部署。為了應對這些挑戰，我們消除了 LLM 和流程元件中的重複模組，並以 LLM 架構取代流程模型主幹。建構在這個簡化的流程主幹之上，我們提出了一個統一的架構，用於串流和非串流推論，大幅降低部署成本。最後，由於簡化的管線和 S3Tokenizer 降低了 TTS 訓練資料的品質需求，我們探討了使用相同的資料來訓練 TTS 和 ASR 任務的可行性。

##### **Generate Any Scene: Evaluating and Improving Text-to-Vision Generation with Scene Graph Programming**
2412.08221v1 by Ziqi Gao, Weikai Huang, Jieyu Zhang, Aniruddha Kembhavi, Ranjay Krishna

DALL-E and Sora have gained attention by producing implausible images, such
as "astronauts riding a horse in space." Despite the proliferation of
text-to-vision models that have inundated the internet with synthetic visuals,
from images to 3D assets, current benchmarks predominantly evaluate these
models on real-world scenes paired with captions. We introduce Generate Any
Scene, a framework that systematically enumerates scene graphs representing a
vast array of visual scenes, spanning realistic to imaginative compositions.
Generate Any Scene leverages 'scene graph programming', a method for
dynamically constructing scene graphs of varying complexity from a structured
taxonomy of visual elements. This taxonomy includes numerous objects,
attributes, and relations, enabling the synthesis of an almost infinite variety
of scene graphs. Using these structured representations, Generate Any Scene
translates each scene graph into a caption, enabling scalable evaluation of
text-to-vision models through standard metrics. We conduct extensive
evaluations across multiple text-to-image, text-to-video, and text-to-3D
models, presenting key findings on model performance. We find that DiT-backbone
text-to-image models align more closely with input captions than UNet-backbone
models. Text-to-video models struggle with balancing dynamics and consistency,
while both text-to-video and text-to-3D models show notable gaps in human
preference alignment. We demonstrate the effectiveness of Generate Any Scene by
conducting three practical applications leveraging captions generated by
Generate Any Scene: 1) a self-improving framework where models iteratively
enhance their performance using generated data, 2) a distillation process to
transfer specific strengths from proprietary models to open-source
counterparts, and 3) improvements in content moderation by identifying and
generating challenging synthetic data.

摘要：DALL-E 和 Sora 因產生令人難以置信的影像而備受關注，例如「太空騎馬的太空人」。儘管文字轉視覺模型大量出現，並以合成視覺效果充斥網路，從影像到 3D 素材，目前的基準主要在配有文字說明的真實場景中評估這些模型。我們推出 Generate Any Scene，一個系統性列舉場景圖的架構，表示各種視覺場景，涵蓋從寫實到富有想像力的構圖。Generate Any Scene 活用「場景圖程式設計」，這是一種從視覺元素的結構化分類法中動態建構不同複雜度場景圖的方法。此分類法包含許多物件、屬性和關係，能合成幾乎無限多變的場景圖。Generate Any Scene 使用這些結構化表示，將每個場景圖轉換為文字說明，能透過標準指標進行文字轉視覺模型的可擴充評估。我們針對多個文字轉影像、文字轉影片和文字轉 3D 模型進行廣泛評估，並提出模型效能的主要發現。我們發現，DiT 主幹的文字轉影像模型比 UNet 主幹模型更貼近輸入文字說明。文字轉影片模型在平衡動態和一致性方面有困難，而文字轉影片和文字轉 3D 模型在人類偏好對齊方面都有明顯的差距。我們透過進行三項實用應用來展示 Generate Any Scene 的有效性，這些應用利用 Generate Any Scene 生成的文字說明：1) 一個自我提升的架構，其中模型會使用產生的資料反覆提升其效能，2) 一個萃取程序，將專有模型的特定優點轉移到開源對應模型，以及 3) 透過識別和產生具有挑戰性的合成資料來改善內容審核。

##### **DocSum: Domain-Adaptive Pre-training for Document Abstractive Summarization**
2412.08196v1 by Phan Phuong Mai Chau, Souhail Bakkali, Antoine Doucet

Abstractive summarization has made significant strides in condensing and
rephrasing large volumes of text into coherent summaries. However, summarizing
administrative documents presents unique challenges due to domain-specific
terminology, OCR-generated errors, and the scarcity of annotated datasets for
model fine-tuning. Existing models often struggle to adapt to the intricate
structure and specialized content of such documents. To address these
limitations, we introduce DocSum, a domain-adaptive abstractive summarization
framework tailored for administrative documents. Leveraging pre-training on
OCR-transcribed text and fine-tuning with an innovative integration of
question-answer pairs, DocSum enhances summary accuracy and relevance. This
approach tackles the complexities inherent in administrative content, ensuring
outputs that align with real-world business needs. To evaluate its
capabilities, we define a novel downstream task setting-Document Abstractive
Summarization-which reflects the practical requirements of business and
organizational settings. Comprehensive experiments demonstrate DocSum's
effectiveness in producing high-quality summaries, showcasing its potential to
improve decision-making and operational workflows across the public and private
sectors.

摘要：摘要式摘要在將大量文字濃縮並改寫為連貫的摘要方面取得重大進展。然而，由於特定領域的術語、OCR 生成的錯誤，以及用於模型微調的註解資料集的稀缺性，摘要管理文件會帶來獨特的挑戰。現有的模型通常難以適應此類文件的複雜結構和專業內容。為了解決這些限制，我們引入了 DocSum，這是一個針對管理文件量身打造的領域適應型摘要式摘要架構。利用 OCR 轉錄文本的預訓練，並與問題答案對的創新整合進行微調，DocSum 提高了摘要的準確性和相關性。這種方法解決了管理內容中固有的複雜性，確保輸出與現實世界的業務需求保持一致。為了評估其能力，我們定義了一個新的下游任務設定——文件摘要式摘要——它反映了商業和組織環境的實際要求。全面的實驗證明了 DocSum 在產生高品質摘要方面的有效性，展示了其在公共和私營部門改善決策制定和運營工作流程的潛力。

##### **Semantic Scene Completion Based 3D Traversability Estimation for Off-Road Terrains**
2412.08195v1 by Zitong Chen, Chao Sun, Shida Nie, Chen Min, Changjiu Ning, Haoyu Li, Bo Wang

Off-road environments present significant challenges for autonomous ground
vehicles due to the absence of structured roads and the presence of complex
obstacles, such as uneven terrain, vegetation, and occlusions. Traditional
perception algorithms, designed primarily for structured environments, often
fail under these conditions, leading to inaccurate traversability estimations.
In this paper, ORDformer, a novel multimodal method that combines LiDAR point
clouds with monocular images, is proposed to generate dense traversable
occupancy predictions from a forward-facing perspective. By integrating
multimodal data, environmental feature extraction is enhanced, which is crucial
for accurate occupancy estimation in complex terrains. Furthermore, RELLIS-OCC,
a dataset with 3D traversable occupancy annotations, is introduced,
incorporating geometric features such as step height, slope, and unevenness.
Through a comprehensive analysis of vehicle obstacle-crossing conditions and
the incorporation of vehicle body structure constraints, four traversability
cost labels are generated: lethal, medium-cost, low-cost, and free.
Experimental results demonstrate that ORDformer outperforms existing approaches
in 3D traversable area recognition, particularly in off-road environments with
irregular geometries and partial occlusions. Specifically, ORDformer achieves
over a 20\% improvement in scene completion IoU compared to other models. The
proposed framework is scalable and adaptable to various vehicle platforms,
allowing for adjustments to occupancy grid parameters and the integration of
advanced dynamic models for traversability cost estimation.

摘要：越野環境由於缺乏結構化的道路，且存在不平坦的地形、植被和遮擋物等複雜障礙，因此對自主地面車輛構成重大挑戰。傳統的感知演算法主要設計用於結構化的環境，在這些條件下通常會失敗，導致無法精確估計可通行性。在本文中，提出了一種名為 ORDformer 的新多模式方法，它將 LiDAR 點雲與單目影像結合起來，從朝前的視角產生密集的可通行佔用預測。透過整合多模式資料，增強了環境特徵萃取，這對於在複雜地形中精確估計佔用率至關重要。此外，還引入了 RELLIS-OCC，這是一個具有 3D 可通行佔用標註的資料集，其中包含階梯高度、坡度和不平整度等幾何特徵。透過對車輛障礙物穿越條件進行全面分析，並結合車身結構約束，生成了四個可通行成本標籤：致命、中成本、低成本和自由。實驗結果表明，ORDformer 在 3D 可通行區域識別方面優於現有方法，特別是在具有不規則幾何形狀和部分遮擋物的越野環境中。具體而言，與其他模型相比，ORDformer 在場景完成 IoU 方面提高了 20% 以上。所提出的框架具有可擴充性和可適應性，適用於各種車輛平台，允許調整佔用率網格參數，並整合先進的動態模型以估計可通行成本。

##### **From communities to interpretable network and word embedding: an unified approach**
2412.08187v1 by Thibault Prouteau, Nicolas Dugué, Simon Guillot

Modelling information from complex systems such as humans social interaction
or words co-occurrences in our languages can help to understand how these
systems are organized and function. Such systems can be modelled by networks,
and network theory provides a useful set of methods to analyze them. Among
these methods, graph embedding is a powerful tool to summarize the interactions
and topology of a network in a vectorized feature space. When used in input of
machine learning algorithms, embedding vectors help with common graph problems
such as link prediction, graph matching, etc. Word embedding has the goal of
representing the sense of words, extracting it from large text corpora. Despite
differences in the structure of information in input of embedding algorithms,
many graph embedding approaches are adapted and inspired from methods in NLP.
Limits of these methods are observed in both domains. Most of these methods
require long and resource greedy training. Another downside to most methods is
that they are black-box, from which understanding how the information is
structured is rather complex. Interpretability of a model allows understanding
how the vector space is structured without the need for external information,
and thus can be audited more easily. With both these limitations in mind, we
propose a novel framework to efficiently embed network vertices in an
interpretable vector space. Our Lower Dimension Bipartite Framework (LDBGF)
leverages the bipartite projection of a network using cliques to reduce
dimensionality. Along with LDBGF, we introduce two implementations of this
framework that rely on communities instead of cliques: SINr-NR and SINr-MF. We
show that SINr-MF can perform well on classical graphs and SINr-NR can produce
high-quality graph and word embeddings that are interpretable and stable across
runs.

摘要：<paragraph>透過模擬人類社交互動或語言中詞彙共現等複雜系統中的資訊，有助於了解這些系統的組織和運作方式。這些系統可以用網路來建模，而網路理論提供了有用的方法集來分析它們。在這些方法中，圖形嵌入是一種強大的工具，可用於在向量化特徵空間中總結網路的交互和拓撲。當用於機器學習演算法的輸入時，嵌入向量有助於常見的圖形問題，例如連結預測、圖形配對等。詞嵌入的目標是表示詞彙的意義，從大型文字語料庫中萃取它。儘管嵌入演算法輸入資訊的結構不同，但許多圖形嵌入方法都是根據自然語言處理中的方法改編和啟發的。在兩個領域中都觀察到這些方法的限制。大多數這些方法需要漫長且耗費資源的訓練。大多數方法的另一個缺點是它們是黑盒子，從中理解資訊如何被結構化相當複雜。模型的可解釋性允許在不需要外部資訊的情況下了解向量空間是如何被結構化的，因此可以更容易地進行稽核。牢記這兩個限制，我們提出了一個新穎的框架，以有效的方式將網路頂點嵌入可解釋的向量空間中。我們的低維二部圖框架 (LDBGF) 利用網路的二部圖投影使用派系來降低維度。除了 LDBGF 之外，我們還介紹了兩個依賴社群而非派系的此框架實作：SINr-NR 和 SINr-MF。我們展示了 SINr-MF 在經典圖形上可以執行良好，而 SINr-NR 可以產生高品質的圖形和詞嵌入，這些嵌入在各次執行中都是可解釋且穩定的。</paragraph>

##### **Auto-Generating Earnings Report Analysis via a Financial-Augmented LLM**
2412.08179v1 by Van-Duc Le

Financial analysis heavily relies on the evaluation of earnings reports to
gain insights into company performance. Traditional generation of these reports
requires extensive financial expertise and is time-consuming. With the
impressive progress in Large Language Models (LLMs), a wide variety of
financially focused LLMs has emerged, addressing tasks like sentiment analysis
and entity recognition in the financial domain. This paper presents a novel
challenge: developing an LLM specifically for automating the generation of
earnings reports analysis. Our methodology involves an in-depth analysis of
existing earnings reports followed by a unique approach to fine-tune an LLM for
this purpose. This approach combines retrieval augmentation and the generation
of instruction-based data, specifically tailored for the financial sector, to
enhance the LLM's performance. With extensive financial documents, we construct
financial instruction data, enabling the refined adaptation of our LLM to
financial contexts. Preliminary results indicate that our augmented LLM
outperforms general open-source models and rivals commercial counterparts like
GPT-3.5 in financial applications. Our research paves the way for streamlined
and insightful automation in financial report generation, marking a significant
stride in the field of financial analysis.

摘要：財務分析高度依賴對收益報告的評估，以深入了解公司績效。傳統上，產生這些報告需要廣泛的財務專業知識，而且非常耗時。隨著大型語言模型 (LLM) 的驚人進展，已經出現了各種以財務為重點的 LLM，用於解決財務領域的情緒分析和實體識別等任務。本文提出了新的挑戰：開發一個 LLM，專門用於自動化收益報告分析的產生。我們的做法包括對現有收益報告進行深入分析，然後採用獨特的方法微調 LLM 以達到此目的。此方法結合檢索擴充和生成基於指令的資料，專門針對金融部門進行調整，以增強 LLM 的效能。利用廣泛的財務文件，我們建構了財務指令資料，讓我們的 LLM 能夠精確地適應財務背景。初步結果表明，我們擴充的 LLM 優於一般開源模型，並且在財務應用中與 GPT-3.5 等商業對手不相上下。我們的研究為財務報告產生的簡化和深入自動化鋪平了道路，標誌著財務分析領域的重大進展。

##### **Can Graph Neural Networks Learn Language with Extremely Weak Text Supervision?**
2412.08174v1 by Zihao Li, Lecheng Zheng, Bowen Jin, Dongqi Fu, Baoyu Jing, Yikun Ban, Jingrui He, Jiawei Han

While great success has been achieved in building vision models with
Contrastive Language-Image Pre-training (CLIP) over Internet-scale image-text
pairs, building transferable Graph Neural Networks (GNNs) with CLIP pipeline is
challenging because of three fundamental issues: the scarcity of labeled data
and text supervision, different levels of downstream tasks, and the conceptual
gaps between domains. In this work, to address these issues, we leverage
multi-modal prompt learning to effectively adapt pre-trained GNN to downstream
tasks and data, given only a few semantically labeled samples, each with
extremely weak text supervision. Our new paradigm embeds the graphs directly in
the same space as the Large Language Models (LLMs) by learning both graph
prompts and text prompts simultaneously. To accomplish this, we improve
state-of-the-art graph prompt method, and then propose the first graph-language
multi-modal prompt learning approach for exploiting the knowledge in
pre-trained models. Notably, due to the insufficient supervision for
fine-tuning, in our paradigm, the pre-trained GNN and the LLM are kept frozen,
so the learnable parameters are much fewer than fine-tuning any pre-trained
model. Through extensive experiments on real-world datasets, we demonstrate the
superior performance of our paradigm in few-shot, multi-task-level, and
cross-domain settings. Moreover, we build the first CLIP-style zero-shot
classification prototype that can generalize GNNs to unseen classes with
extremely weak text supervision.

摘要：<paragraph>儘管利用網際網路規模的圖像文字配對，在建立具有對比語言影像預訓練 (CLIP) 的視覺模型方面已取得巨大的成功，但由於三個基本問題，使用 CLIP 管線建立可轉移的圖神經網路 (GNN) 具有挑戰性：標記資料和文字監督的稀缺性、不同層級的下游任務，以及領域之間的概念差距。為了解決這些問題，我們在這個工作中利用多模式提示學習，在僅給予少數語義標記範例（每個範例都具有極弱的文字監督）的情況下，有效地調整預訓練的 GNN 以適應下游任務和資料。我們的範例透過同時學習圖提示和文字提示，將圖形直接嵌入與大型語言模型 (LLM) 相同的空間中。為了達成這個目標，我們改進了最先進的圖提示方法，然後提出第一個圖語言多模式提示學習方法，以利用預訓練模型中的知識。值得注意的是，由於微調的監督不足，在我們的範例中，預訓練的 GNN 和 LLM 保持凍結，因此可學習的參數遠少於微調任何預訓練模型。透過在真實世界資料集上進行廣泛的實驗，我們展示了我們的範例在少量、多任務層級和跨領域設定中的優異效能。此外，我們建立了第一個 CLIP 風格的零次分類原型，它可以將 GNN 推廣到具有極弱文字監督的未見類別。</paragraph>

##### **Illusory VQA: Benchmarking and Enhancing Multimodal Models on Visual Illusions**
2412.08169v1 by Mohammadmostafa Rostamkhani, Baktash Ansari, Hoorieh Sabzevari, Farzan Rahmani, Sauleh Eetemadi

In recent years, Visual Question Answering (VQA) has made significant
strides, particularly with the advent of multimodal models that integrate
vision and language understanding. However, existing VQA datasets often
overlook the complexities introduced by image illusions, which pose unique
challenges for both human perception and model interpretation. In this study,
we introduce a novel task called Illusory VQA, along with four specialized
datasets: IllusionMNIST, IllusionFashionMNIST, IllusionAnimals, and
IllusionChar. These datasets are designed to evaluate the performance of
state-of-the-art multimodal models in recognizing and interpreting visual
illusions. We assess the zero-shot performance of various models, fine-tune
selected models on our datasets, and propose a simple yet effective solution
for illusion detection using Gaussian and blur low-pass filters. We show that
this method increases the performance of models significantly and in the case
of BLIP-2 on IllusionAnimals without any fine-tuning, it outperforms humans.
Our findings highlight the disparity between human and model perception of
illusions and demonstrate that fine-tuning and specific preprocessing
techniques can significantly enhance model robustness. This work contributes to
the development of more human-like visual understanding in multimodal models
and suggests future directions for adapting filters using learnable parameters.

摘要：近年來，視覺問答（VQA）取得了顯著進展，特別是隨著整合視覺和語言理解的多模態模型的出現。然而，現有的 VQA 資料集通常會忽略由視覺錯覺帶來的複雜性，而這對人類知覺和模型解釋都構成了獨特的挑戰。在本研究中，我們引入了一項稱為 Illusory VQA 的新任務，以及四個專門的資料集：IllusionMNIST、IllusionFashionMNIST、IllusionAnimals 和 IllusionChar。這些資料集旨在評估最先進的多模態模型在識別和解釋視覺錯覺方面的效能。我們評估了各種模型的零次學習效能，微調了我們資料集中的選定模型，並提出了一個簡單但有效的解決方案，使用高斯和模糊低通濾波器進行錯覺偵測。我們表明，這種方法顯著提升了模型效能，在沒有任何微調的情況下，對於 IllusionAnimals 上的 BLIP-2，它的表現優於人類。我們的研究結果突出了人類和模型對錯覺感知的差異，並證明微調和特定的預處理技術可以顯著增強模型的穩健性。這項工作有助於在多模態模型中開發更接近人類的視覺理解，並提出了使用可學習參數調整濾波器的未來方向。

##### **NLPineers@ NLU of Devanagari Script Languages 2025: Hate Speech Detection using Ensembling of BERT-based models**
2412.08163v1 by Anmol Guragain, Nadika Poudel, Rajesh Piryani, Bishesh Khanal

This paper explores hate speech detection in Devanagari-scripted languages,
focusing on Hindi and Nepali, for Subtask B of the CHIPSAL@COLING 2025 Shared
Task. Using a range of transformer-based models such as XLM-RoBERTa, MURIL, and
IndicBERT, we examine their effectiveness in navigating the nuanced boundary
between hate speech and free expression. Our best performing model, implemented
as ensemble of multilingual BERT models achieve Recall of 0.7762 (Rank 3/31 in
terms of recall) and F1 score of 0.6914 (Rank 17/31). To address class
imbalance, we used backtranslation for data augmentation, and cosine similarity
to preserve label consistency after augmentation. This work emphasizes the need
for hate speech detection in Devanagari-scripted languages and presents a
foundation for further research.

摘要：本文探討天城文語言中的仇恨言論偵測，重點放在印地語和尼泊爾語，針對 CHIPSAL@COLING 2025 共享任務的子任務 B。我們使用各種基於轉換器的模型，例如 XLM-RoBERTa、MURIL 和 IndicBERT，探討它們在導航仇恨言論和言論自由之間微妙界限的有效性。我們效能最佳的模型實作為多語言 BERT 模型的合奏，在召回率方面達到 0.7762（召回率排名第 3/31），F1 分數為 0.6914（排名第 17/31）。為了解決類別不平衡問題，我們使用反向翻譯進行資料擴充，並使用餘弦相似度在擴充後保留標籤一致性。這項工作強調天城文語言中仇恨言論偵測的需求，並為進一步的研究奠定基礎。

##### **How Vision-Language Tasks Benefit from Large Pre-trained Models: A Survey**
2412.08158v1 by Yayun Qi, Hongxi Li, Yiqi Song, Xinxiao Wu, Jiebo Luo

The exploration of various vision-language tasks, such as visual captioning,
visual question answering, and visual commonsense reasoning, is an important
area in artificial intelligence and continuously attracts the research
community's attention. Despite the improvements in overall performance, classic
challenges still exist in vision-language tasks and hinder the development of
this area. In recent years, the rise of pre-trained models is driving the
research on vision-language tasks. Thanks to the massive scale of training data
and model parameters, pre-trained models have exhibited excellent performance
in numerous downstream tasks. Inspired by the powerful capabilities of
pre-trained models, new paradigms have emerged to solve the classic challenges.
Such methods have become mainstream in current research with increasing
attention and rapid advances. In this paper, we present a comprehensive
overview of how vision-language tasks benefit from pre-trained models. First,
we review several main challenges in vision-language tasks and discuss the
limitations of previous solutions before the era of pre-training. Next, we
summarize the recent advances in incorporating pre-trained models to address
the challenges in vision-language tasks. Finally, we analyze the potential
risks associated with the inherent limitations of pre-trained models and
discuss possible solutions, attempting to provide future research directions.

摘要：各種視覺語言任務的探索，例如視覺字幕、視覺問答和視覺常識推理，是人工智慧中一個重要的領域，並持續吸引研究社群的關注。儘管整體效能有所提升，經典挑戰仍存在於視覺語言任務中，並阻礙這個領域的發展。近年來，預訓練模型的興起帶動了視覺語言任務的研究。得益於訓練資料和模型參數的大規模規模，預訓練模型在許多下游任務中表現出色的效能。受到預訓練模型強大功能的啟發，新的典範已經出現來解決經典挑戰。這些方法已成為當前研究的主流，並受到越來越多的關注和快速進展。在本文中，我們提出了預訓練模型如何使視覺語言任務受益的全面概述。首先，我們回顧了視覺語言任務中的幾個主要挑戰，並討論了預訓練時代之前先前解決方案的限制。接下來，我們總結了將預訓練模型納入以應對視覺語言任務中挑戰的最新進展。最後，我們分析了與預訓練模型固有限制相關的潛在風險，並討論可能的解決方案，試圖提供未來的研究方向。

##### **Antelope: Potent and Concealed Jailbreak Attack Strategy**
2412.08156v1 by Xin Zhao, Xiaojun Chen, Haoyu Gao

Due to the remarkable generative potential of diffusion-based models,
numerous researches have investigated jailbreak attacks targeting these
frameworks. A particularly concerning threat within image models is the
generation of Not-Safe-for-Work (NSFW) content. Despite the implementation of
security filters, numerous efforts continue to explore ways to circumvent these
safeguards. Current attack methodologies primarily encompass adversarial prompt
engineering or concept obfuscation, yet they frequently suffer from slow search
efficiency, conspicuous attack characteristics and poor alignment with targets.
To overcome these challenges, we propose Antelope, a more robust and covert
jailbreak attack strategy designed to expose security vulnerabilities inherent
in generative models. Specifically, Antelope leverages the confusion of
sensitive concepts with similar ones, facilitates searches in the semantically
adjacent space of these related concepts and aligns them with the target
imagery, thereby generating sensitive images that are consistent with the
target and capable of evading detection. Besides, we successfully exploit the
transferability of model-based attacks to penetrate online black-box services.
Experimental evaluations demonstrate that Antelope outperforms existing
baselines across multiple defensive mechanisms, underscoring its efficacy and
versatility.

摘要：由於基於擴散模型的顯著生成潛力，許多研究探討了針對這些框架的越獄攻擊。圖像模型中一個特別令人擔憂的威脅是非工作安全 (NSFW) 內容的生成。儘管實施了安全過濾器，但仍有許多努力持續探索規避這些防護措施的方法。目前的攻擊方法主要包括對抗提示工程或概念混淆，但它們經常遭受搜索效率低、攻擊特徵明顯以及與目標對齊不良的問題。為了克服這些挑戰，我們提出了 Antelope，這是一種更強大且隱蔽的越獄攻擊策略，旨在揭露生成模型中固有的安全漏洞。具體來說，Antelope 利用敏感概念與相似概念的混淆，促進在這些相關概念的語義鄰近空間中進行搜索，並將它們與目標圖像對齊，從而生成與目標一致且能夠逃避檢測的敏感圖像。此外，我們成功利用基於模型的攻擊的可傳遞性來滲透在線黑盒子服務。實驗評估表明，Antelope 在多種防禦機制中優於現有的基準，突顯了其有效性和多功能性。

##### **A Review of Intelligent Device Fault Diagnosis Technologies Based on Machine Vision**
2412.08148v1 by Guiran Liu, Binrong Zhu

This paper provides a comprehensive review of mechanical equipment fault
diagnosis methods, focusing on the advancements brought by Transformer-based
models. It details the structure, working principles, and benefits of
Transformers, particularly their self-attention mechanism and parallel
computation capabilities, which have propelled their widespread application in
natural language processing and computer vision. The discussion highlights key
Transformer model variants, such as Vision Transformers (ViT) and their
extensions, which leverage self-attention to improve accuracy and efficiency in
visual tasks. Furthermore, the paper examines the application of
Transformer-based approaches in intelligent fault diagnosis for mechanical
systems, showcasing their superior ability to extract and recognize patterns
from complex sensor data for precise fault identification. Despite these
advancements, challenges remain, including the reliance on extensive labeled
datasets, significant computational demands, and difficulties in deploying
models on resource-limited devices. To address these limitations, the paper
proposes future research directions, such as developing lightweight Transformer
architectures, integrating multimodal data sources, and enhancing adaptability
to diverse operational conditions. These efforts aim to further expand the
application of Transformer-based methods in mechanical fault diagnosis, making
them more robust, efficient, and suitable for real-world industrial
environments.

摘要：本文全面回顾了機械設備故障診斷方法，重點關注 Transformer 模型帶來的進展。它詳細說明了 Transformer 的結構、工作原理和優點，特別是它們的自我注意機制和並行計算能力，這些能力推動了它們在自然語言處理和電腦視覺中的廣泛應用。討論重點介紹了關鍵的 Transformer 模型變體，例如視覺 Transformer (ViT) 及其擴充套件，它們利用自我注意來提高視覺任務的準確性和效率。此外，本文探討了 Transformer 方法在機械系統的智慧故障診斷中的應用，展示了它們從複雜感測器資料中提取和識別模式以進行精確故障識別的優異能力。儘管有這些進展，但仍存在挑戰，包括依賴於廣泛標記的資料集、大量的計算需求以及在資源受限的裝置上部署模型的困難。為了應對這些限制，本文提出了未來的研究方向，例如開發輕量級 Transformer 架構、整合多模式資料來源，並增強對不同操作條件的適應性。這些努力旨在進一步擴大 Transformer 方法在機械故障診斷中的應用，使其更強大、更有效率，並更適合於現實世界的工業環境。

##### **How to Weight Multitask Finetuning? Fast Previews via Bayesian Model-Merging**
2412.08147v1 by Hugo Monzón Maldonado, Thomas Möllenhoff, Nico Daheim, Iryna Gurevych, Mohammad Emtiyaz Khan

When finetuning multiple tasks altogether, it is important to carefully weigh
them to get a good performance, but searching for good weights can be difficult
and costly. Here, we propose to aid the search with fast previews to quickly
get a rough idea of different reweighting options. We use model merging to
create previews by simply reusing and averaging parameters of models trained on
each task separately (no retraining required). To improve the quality of
previews, we propose a Bayesian approach to design new merging strategies by
using more flexible posteriors. We validate our findings on vision and
natural-language transformers. Our work shows the benefits of model merging via
Bayes to improve multitask finetuning.

摘要：在微调多个任务时，仔细权衡它们以获得良好的性能非常重要，但寻找合适的权重可能既困难又昂贵。在此，我们建议使用快速预览来辅助搜索，以快速大致了解不同的重新加权选项。我们使用模型合并来创建预览，方法是简单地重复使用并平均在每个任务上单独训练的模型的参数（无需重新训练）。为了提高预览的质量，我们提出了一种贝叶斯方法，通过使用更灵活的后验来设计新的合并策略。我们在视觉和自然语言转换器上验证了我们的发现。我们的工作展示了通过贝叶斯模型合并的好处，以改善多任务微调。

##### **A Survey on Private Transformer Inference**
2412.08145v1 by Yang Li, Xinyu Zhou, Yitong Wang, Liangxin Qian, Jun Zhao

Transformer models have revolutionized AI, enabling applications like content
generation and sentiment analysis. However, their use in Machine Learning as a
Service (MLaaS) raises significant privacy concerns, as centralized servers
process sensitive user data. Private Transformer Inference (PTI) addresses
these issues using cryptographic techniques such as Secure Multi-Party
Computation (MPC) and Homomorphic Encryption (HE), enabling secure model
inference without exposing inputs or models. This paper reviews recent
advancements in PTI, analyzing state-of-the-art solutions, their challenges,
and potential improvements. We also propose evaluation guidelines to assess
resource efficiency and privacy guarantees, aiming to bridge the gap between
high-performance inference and data privacy.

摘要：Transformer模型徹底改變了 AI，讓內容生成和情緒分析等應用程式得以問世。然而，它們用於機器學習即服務 (MLaaS) 時會引發重大的隱私問題，因為集中式伺服器會處理敏感的使用者資料。私人Transformer推論 (PTI) 使用安全多方運算 (MPC) 和同態加密 (HE) 等密碼技術來解決這些問題，讓模型能夠在不公開輸入或模型的情況下進行安全推論。本文回顧了 PTI 的最新進展，分析了最先進的解決方案、它們的挑戰和潛在的改進。我們也提出評估準則來評估資源效率和隱私保證，目標是彌合高性能推論和資料隱私之間的差距。

##### **AGMixup: Adaptive Graph Mixup for Semi-supervised Node Classification**
2412.08144v1 by Weigang Lu, Ziyu Guan, Wei Zhao, Yaming Yang, Yibing Zhan, Yiheng Lu, Dapeng Tao

Mixup is a data augmentation technique that enhances model generalization by
interpolating between data points using a mixing ratio $\lambda$ in the image
domain. Recently, the concept of mixup has been adapted to the graph domain
through node-centric interpolations. However, these approaches often fail to
address the complexity of interconnected relationships, potentially damaging
the graph's natural topology and undermining node interactions. Furthermore,
current graph mixup methods employ a one-size-fits-all strategy with a randomly
sampled $\lambda$ for all mixup pairs, ignoring the diverse needs of different
pairs. This paper proposes an Adaptive Graph Mixup (AGMixup) framework for
semi-supervised node classification. AGMixup introduces a subgraph-centric
approach, which treats each subgraph similarly to how images are handled in
Euclidean domains, thus facilitating a more natural integration of mixup into
graph-based learning. We also propose an adaptive mechanism to tune the mixing
ratio $\lambda$ for diverse mixup pairs, guided by the contextual similarity
and uncertainty of the involved subgraphs. Extensive experiments across seven
datasets on semi-supervised node classification benchmarks demonstrate
AGMixup's superiority over state-of-the-art graph mixup methods. Source codes
are available at \url{https://github.com/WeigangLu/AGMixup}.

摘要：Mixup 是一種資料擴充技術，透過在影像領域中使用混合比例 $\lambda$ 在資料點之間進行內插，來提升模型的泛化能力。最近，Mixup 的概念已經透過以節點為中心的內插方式，改編到圖形領域。然而，這些方法常常無法處理相互關聯關係的複雜性，可能會損害圖形的自然拓撲結構，並破壞節點互動。此外，目前的圖形 Mixup 方法採用一體適用的策略，對所有 Mixup 對使用隨機取樣的 $\lambda$，忽略了不同對之間不同的需求。本文提出了一個適應式圖形 Mixup (AGMixup) 架構，用於半監督節點分類。AGMixup 採用了一個以子圖為中心的途徑，將每個子圖視為類似於在歐幾里德領域中處理影像的方式，從而促進 Mixup 更自然地整合到基於圖形的學習中。我們還提出了一個適應機制，根據所涉及子圖的上下文相似性和不確定性，調整不同 Mixup 對的混合比例 $\lambda$。在七個資料集上的廣泛實驗，在半監督節點分類基準上證明了 AGMixup 優於最先進的圖形 Mixup 方法。原始碼可在 \url{https://github.com/WeigangLu/AGMixup} 取得。

##### **Wasserstein Distance Rivals Kullback-Leibler Divergence for Knowledge Distillation**
2412.08139v1 by Jiaming Lv, Haoyuan Yang, Peihua Li

Since pioneering work of Hinton et al., knowledge distillation based on
Kullback-Leibler Divergence (KL-Div) has been predominant, and recently its
variants have achieved compelling performance. However, KL-Div only compares
probabilities of the corresponding category between the teacher and student
while lacking a mechanism for cross-category comparison. Besides, KL-Div is
problematic when applied to intermediate layers, as it cannot handle
non-overlapping distributions and is unaware of geometry of the underlying
manifold. To address these downsides, we propose a methodology of Wasserstein
Distance (WD) based knowledge distillation. Specifically, we propose a logit
distillation method called WKD-L based on discrete WD, which performs
cross-category comparison of probabilities and thus can explicitly leverage
rich interrelations among categories. Moreover, we introduce a feature
distillation method called WKD-F, which uses a parametric method for modeling
feature distributions and adopts continuous WD for transferring knowledge from
intermediate layers. Comprehensive evaluations on image classification and
object detection have shown (1) for logit distillation WKD-L outperforms very
strong KL-Div variants; (2) for feature distillation WKD-F is superior to the
KL-Div counterparts and state-of-the-art competitors. The source code is
available at https://peihuali.org/WKD

摘要：自 Hinton 等人的开创性工作以来，基于 Kullback-Leibler 散度 (KL-Div) 的知识蒸馏一直占主导地位，最近其变体已经取得了令人信服的性能。然而，KL-Div 仅比较了教师和学生之间对应类别的概率，而缺少跨类别比较的机制。此外，KL-Div 在应用于中间层时存在问题，因为它无法处理非重叠分布，并且不了解底层流形的几何形状。为了解决这些缺点，我们提出了一种基于 Wasserstein 距离 (WD) 的知识蒸馏方法。具体来说，我们提出了一种称为 WKD-L 的 logit 蒸馏方法，它基于离散 WD，它执行概率的跨类别比较，因此可以明确利用类别之间的丰富相互关系。此外，我们引入了一种称为 WKD-F 的特征蒸馏方法，它使用参数化方法对特征分布进行建模，并采用连续 WD 从中间层传输知识。在图像分类和对象检测方面的综合评估表明 (1) 对于 logit 蒸馏，WKD-L 优于非常强大的 KL-Div 变体；(2) 对于特征蒸馏，WKD-F 优于 KL-Div 对应项和最先进的竞争对手。源代码可在 https://peihuali.org/WKD 获得

##### **Learn How to Query from Unlabeled Data Streams in Federated Learning**
2412.08138v1 by Yuchang Sun, Xinran Li, Tao Lin, Jun Zhang

Federated learning (FL) enables collaborative learning among decentralized
clients while safeguarding the privacy of their local data. Existing studies on
FL typically assume offline labeled data available at each client when the
training starts. Nevertheless, the training data in practice often arrive at
clients in a streaming fashion without ground-truth labels. Given the expensive
annotation cost, it is critical to identify a subset of informative samples for
labeling on clients. However, selecting samples locally while accommodating the
global training objective presents a challenge unique to FL. In this work, we
tackle this conundrum by framing the data querying process in FL as a
collaborative decentralized decision-making problem and proposing an effective
solution named LeaDQ, which leverages multi-agent reinforcement learning
algorithms. In particular, under the implicit guidance from global information,
LeaDQ effectively learns the local policies for distributed clients and steers
them towards selecting samples that can enhance the global model's accuracy.
Extensive simulations on image and text tasks show that LeaDQ advances the
model performance in various FL scenarios, outperforming the benchmarking
algorithms.

摘要：聯邦學習 (FL) 能夠在分散式用戶端之間進行協作學習，同時保護其本地資料的隱私。現有關於 FL 的研究通常假設在訓練開始時每個用戶端都有離線標籤資料可用。然而，實際上的訓練資料通常以串流方式傳送給用戶端，且沒有基本事實標籤。由於註解成本昂貴，因此在用戶端上識別出具有資訊性的樣本子集進行標籤非常重要。然而，在容納全球訓練目標的同時，在本地選擇樣本對 FL 來說是一個獨特的挑戰。在這項工作中，我們將 FL 中的資料查詢程序建構為一個協作式分散式決策制定問題，並提出了一個名為 LeaDQ 的有效解決方案，它利用了多主體強化學習演算法。特別是在全球資訊的隱式指導下，LeaDQ 有效地學習了分散式用戶端的本地政策，並引導它們選擇能夠增強全球模型準確性的樣本。在影像和文字任務上的廣泛模擬顯示，LeaDQ 在各種 FL 場景中提升了模型效能，優於基準演算法。

##### **DiffRaman: A Conditional Latent Denoising Diffusion Probabilistic Model for Bacterial Raman Spectroscopy Identification Under Limited Data Conditions**
2412.08131v1 by Haiming Yao, Wei Luo, Ang Gao, Tao Zhou, Xue Wang

Raman spectroscopy has attracted significant attention in various biochemical
detection fields, especially in the rapid identification of pathogenic
bacteria. The integration of this technology with deep learning to facilitate
automated bacterial Raman spectroscopy diagnosis has emerged as a key focus in
recent research. However, the diagnostic performance of existing deep learning
methods largely depends on a sufficient dataset, and in scenarios where there
is a limited availability of Raman spectroscopy data, it is inadequate to fully
optimize the numerous parameters of deep neural networks. To address these
challenges, this paper proposes a data generation method utilizing deep
generative models to expand the data volume and enhance the recognition
accuracy of bacterial Raman spectra. Specifically, we introduce DiffRaman, a
conditional latent denoising diffusion probability model for Raman spectra
generation. Experimental results demonstrate that synthetic bacterial Raman
spectra generated by DiffRaman can effectively emulate real experimental
spectra, thereby enhancing the performance of diagnostic models, especially
under conditions of limited data. Furthermore, compared to existing generative
models, the proposed DiffRaman offers improvements in both generation quality
and computational efficiency. Our DiffRaman approach offers a well-suited
solution for automated bacteria Raman spectroscopy diagnosis in data-scarce
scenarios, offering new insights into alleviating the labor of spectroscopic
measurements and enhancing rare bacteria identification.

摘要：拉曼光譜在各種生化檢測領域中備受關注，特別是在病原菌的快速鑑定中。將此技術與深度學習整合以促進自動化細菌拉曼光譜診斷已成為近年研究的重點。然而，現有深度學習方法的診斷性能在很大程度上取決於充足的數據集，而在拉曼光譜數據可用性有限的情況下，無法充分優化深度神經網路的眾多參數。為了應對這些挑戰，本文提出了一種利用深度生成模型來擴展數據量並增強細菌拉曼光譜識別精度的數據生成方法。具體來說，我們引入了 DiffRaman，這是一種用於拉曼光譜生成的條件潛在去噪擴散概率模型。實驗結果表明，由 DiffRaman 生成的合成細菌拉曼光譜可以有效地模擬真實實驗光譜，從而增強診斷模型的性能，特別是在數據有限的情況下。此外，與現有的生成模型相比，所提出的 DiffRaman 在生成質量和計算效率方面都有所改進。我們的 DiffRaman 方法為數據稀缺場景中的自動細菌拉曼光譜診斷提供了一個適用的解決方案，為減輕光譜測量的勞動和增強罕見細菌的鑑定提供了新的見解。

##### **Evil twins are not that evil: Qualitative insights into machine-generated prompts**
2412.08127v1 by Nathanaël Carraz Rakotonirina, Corentin Kervadec, Francesca Franzon, Marco Baroni

It has been widely observed that language models (LMs) respond in predictable
ways to algorithmically generated prompts that are seemingly unintelligible.
This is both a sign that we lack a full understanding of how LMs work, and a
practical challenge, because opaqueness can be exploited for harmful uses of
LMs, such as jailbreaking. We present the first thorough analysis of opaque
machine-generated prompts, or autoprompts, pertaining to 3 LMs of different
sizes and families. We find that machine-generated prompts are characterized by
a last token that is often intelligible and strongly affects the generation. A
small but consistent proportion of the previous tokens are fillers that
probably appear in the prompt as a by-product of the fact that the optimization
process fixes the number of tokens. The remaining tokens tend to have at least
a loose semantic relation with the generation, although they do not engage in
well-formed syntactic relations with it. We find moreover that some of the
ablations we applied to machine-generated prompts can also be applied to
natural language sequences, leading to similar behavior, suggesting that
autoprompts are a direct consequence of the way in which LMs process linguistic
inputs in general.

摘要：人們廣泛觀察到，語言模型 (LM) 以可預測的方式回應看似難以理解的演算法產生提示。這既是我們缺乏對 LM 工作方式的充分理解的跡象，也是一個實際挑戰，因為不透明性可能會被利用於 LM 的有害用途，例如越獄。我們針對 3 個不同大小和類型的 LM 提出首次對不透明機器產生的提示或自動提示的徹底分析。我們發現機器產生的提示的特徵是最後一個通常可以理解且強烈影響生成的標記。前一個標記中有一小部分但一致的比例是填料，這些填料可能出現在提示中，因為最佳化過程固定了標記的數量。其餘標記往往與生成至少有鬆散的語義關係，儘管它們不會與生成建立良好的句法關係。此外，我們發現應用於機器產生的提示的一些消融也可以應用於自然語言序列，導致類似的行為，這表明自動提示是 LM 一般處理語言輸入的方式的直接結果。

##### **Progressive Multi-granular Alignments for Grounded Reasoning in Large Vision-Language Models**
2412.08125v1 by Quang-Hung Le, Long Hoang Dang, Ngan Le, Truyen Tran, Thao Minh Le

Existing Large Vision-Language Models (LVLMs) excel at matching concepts
across multi-modal inputs but struggle with compositional concepts and
high-level relationships between entities. This paper introduces Progressive
multi-granular Vision-Language alignments (PromViL), a novel framework to
enhance LVLMs' ability in performing grounded compositional visual reasoning
tasks. Our approach constructs a hierarchical structure of multi-modal
alignments, ranging from simple to complex concepts. By progressively aligning
textual descriptions with corresponding visual regions, our model learns to
leverage contextual information from lower levels to inform higher-level
reasoning. To facilitate this learning process, we introduce a data generation
process that creates a novel dataset derived from Visual Genome, providing a
wide range of nested compositional vision-language pairs. Experimental results
demonstrate that our PromViL framework significantly outperforms baselines on
various visual grounding and compositional question answering tasks.

摘要：現有的大型視覺語言模型 (LVLMs) 擅長比對跨多模式輸入的概念，但在組合概念和實體之間的高層級關係上卻有困難。本文介紹漸進式多粒度視覺語言對齊 (PromViL)，這是一種新穎的架構，用於增強 LVLMs 在執行基礎組合視覺推理任務的能力。我們的做法建構了一個多模式對齊的分層結構，從簡單到複雜的概念。透過漸進式地將文字描述與對應的視覺區域對齊，我們的模型學習利用較低層級的脈絡資訊，來告知較高層級的推理。為了促進這個學習過程，我們引入了一個資料產生程序，這個程序會建立一個新穎的資料集，衍生自 Visual Genome，提供廣泛的嵌套組合視覺語言配對。實驗結果證明，我們的 PromViL 架構在各種視覺基礎和組合式問答任務上，都顯著優於基準。

##### **LatentSpeech: Latent Diffusion for Text-To-Speech Generation**
2412.08117v1 by Haowei Lou, Helen Paik, Pari Delir Haghighi, Wen Hu, Lina Yao

Diffusion-based Generative AI gains significant attention for its superior
performance over other generative techniques like Generative Adversarial
Networks and Variational Autoencoders. While it has achieved notable
advancements in fields such as computer vision and natural language processing,
their application in speech generation remains under-explored. Mainstream
Text-to-Speech systems primarily map outputs to Mel-Spectrograms in the
spectral space, leading to high computational loads due to the sparsity of
MelSpecs. To address these limitations, we propose LatentSpeech, a novel TTS
generation approach utilizing latent diffusion models. By using latent
embeddings as the intermediate representation, LatentSpeech reduces the target
dimension to 5% of what is required for MelSpecs, simplifying the processing
for the TTS encoder and vocoder and enabling efficient high-quality speech
generation. This study marks the first integration of latent diffusion models
in TTS, enhancing the accuracy and naturalness of generated speech.
Experimental results on benchmark datasets demonstrate that LatentSpeech
achieves a 25% improvement in Word Error Rate and a 24% improvement in Mel
Cepstral Distortion compared to existing models, with further improvements
rising to 49.5% and 26%, respectively, with additional training data. These
findings highlight the potential of LatentSpeech to advance the
state-of-the-art in TTS technology

摘要：基於擴散的生成式 AI 因其優於其他生成式技術（例如生成對抗網路和變異自動編碼器）的卓越效能而備受關注。雖然它在電腦視覺和自然語言處理等領域取得顯著進展，但其在語音生成的應用仍未得到充分探索。主流的文字轉語音系統主要將輸出映射到頻譜空間中的梅爾頻譜圖，由於梅爾頻譜圖的稀疏性，導致高運算負載。為了解決這些限制，我們提出了 LatentSpeech，一種利用潛在擴散模型的新型 TTS 生成方法。通過使用潛在嵌入作為中間表示，LatentSpeech 將目標維度減少到梅爾頻譜圖所需維度的 5%，簡化了 TTS 編碼器和語音編碼器的處理，並實現了高效的高品質語音生成。這項研究標誌著潛在擴散模型首次整合到 TTS 中，增強了生成語音的準確性和自然性。基準資料集上的實驗結果表明，與現有模型相比，LatentSpeech 的字元錯誤率提高了 25%，梅爾倒頻譜失真提高了 24%，而隨著訓練資料的增加，進一步的改善分別達到 49.5% 和 26%。這些發現突顯了 LatentSpeech 推動 TTS 技術進步的潛力。

##### **Aligner-Guided Training Paradigm: Advancing Text-to-Speech Models with Aligner Guided Duration**
2412.08112v1 by Haowei Lou, Helen Paik, Wen Hu, Lina Yao

Recent advancements in text-to-speech (TTS) systems, such as FastSpeech and
StyleSpeech, have significantly improved speech generation quality. However,
these models often rely on duration generated by external tools like the
Montreal Forced Aligner, which can be time-consuming and lack flexibility. The
importance of accurate duration is often underestimated, despite their crucial
role in achieving natural prosody and intelligibility. To address these
limitations, we propose a novel Aligner-Guided Training Paradigm that
prioritizes accurate duration labelling by training an aligner before the TTS
model. This approach reduces dependence on external tools and enhances
alignment accuracy. We further explore the impact of different acoustic
features, including Mel-Spectrograms, MFCCs, and latent features, on TTS model
performance. Our experimental results show that aligner-guided duration
labelling can achieve up to a 16\% improvement in word error rate and
significantly enhance phoneme and tone alignment. These findings highlight the
effectiveness of our approach in optimizing TTS systems for more natural and
intelligible speech generation.

摘要：近期的文字轉語音 (TTS) 系統進展，例如 FastSpeech 和 StyleSpeech，已顯著提升語音產生品質。然而，這些模型通常依賴由外部工具產生的時長，例如 Montreal Forced Aligner，這可能會耗時且缺乏彈性。儘管準確時長在達成自然音律和清晰度方面扮演至關重要的角色，其重要性卻常常被低估。為了解決這些限制，我們提出一個新穎的 Aligner 引導訓練範例，其優先考量準確時長標籤，並在 TTS 模型之前訓練一個 Aligner。此方法減少對外部工具的依賴，並提升對齊準確度。我們進一步探討不同聲學特徵，包括梅爾頻譜圖、MFCC 和潛在特徵，對 TTS 模型效能的影響。我們的實驗結果顯示，Aligner 引導時長標籤可以達成最高 16% 的字元錯誤率改善，並顯著提升音素和聲調對齊。這些發現突顯我們的方法在最佳化 TTS 系統以產生更自然且清晰的語音方面的成效。

##### **Seeing Syntax: Uncovering Syntactic Learning Limitations in Vision-Language Models**
2412.08111v1 by Sri Harsha Dumpala, David Arps, Sageev Oore, Laura Kallmeyer, Hassan Sajjad

Vision-language models (VLMs), serve as foundation models for multi-modal
applications such as image captioning and text-to-image generation. Recent
studies have highlighted limitations in VLM text encoders, particularly in
areas like compositionality and semantic understanding, though the underlying
reasons for these limitations remain unclear. In this work, we aim to address
this gap by analyzing the syntactic information, one of the fundamental
linguistic properties, encoded by the text encoders of VLMs. We perform a
thorough analysis comparing VLMs with different objective functions, parameter
size and training data size, and with uni-modal language models (ULMs) in their
ability to encode syntactic knowledge. Our findings suggest that ULM text
encoders acquire syntactic information more effectively than those in VLMs. The
syntactic information learned by VLM text encoders is shaped primarily by the
pre-training objective, which plays a more crucial role than other factors such
as model architecture, model size, or the volume of pre-training data. Models
exhibit different layer-wise trends where CLIP performance dropped across
layers while for other models, middle layers are rich in encoding syntactic
knowledge.

摘要：視覺語言模型 (VLM) 是多模態應用程式的基礎模型，例如影像標題和文字轉影像生成。最近的研究強調了 VLM 文字編碼器的限制，特別是在組合性和語義理解等領域，儘管這些限制的根本原因仍不清楚。在這項工作中，我們旨在透過分析語法資訊（語言基本屬性之一）來解決這個差距，由 VLM 的文字編碼器編碼。我們執行了一項徹底的分析，比較具有不同目標函數、參數大小和訓練資料大小的 VLM，以及在其編碼語法知識的能力中具有單模態語言模型 (ULM)。我們的研究結果表明，ULM 文字編碼器比 VLM 中的編碼器更有效地獲取語法資訊。VLM 文字編碼器學習到的語法資訊主要由預訓練目標形成，它比其他因素（例如模型架構、模型大小或預訓練資料量）扮演更重要的角色。模型展現出不同的逐層趨勢，其中 CLIP 性能在各層下降，而對於其他模型，中間層富含編碼語法知識。

##### **Barking Up The Syntactic Tree: Enhancing VLM Training with Syntactic Losses**
2412.08110v1 by Jiayun Luo, Mir Rayat Imtiaz Hossain, Boyang Li, Leonid Sigal

Vision-Language Models (VLMs) achieved strong performance on a variety of
tasks (e.g., image-text retrieval, visual question answering). However, most
VLMs rely on coarse-grained image-caption pairs for alignment, relying on data
volume to resolve ambiguities and ground linguistic concepts in images. The
richer semantic and syntactic structure within text is largely overlooked. To
address this, we propose HIerarchically STructured Learning (HIST) that
enhances VLM training without any additional supervision, by hierarchically
decomposing captions into the constituent Subject, Noun Phrases, and Composite
Phrases. Entailment between these constituent components allows us to formulate
additional regularization constraints on the VLM attention maps. Specifically,
we introduce two novel loss functions: (1) Subject Loss, which aligns image
content with the subject of corresponding phrase, acting as an entailment of
standard contrastive/matching losses at the Phrase level; (2) Addition Loss, to
balance attention across multiple objects. HIST is general, and can be applied
to any VLM for which attention between vision and language can be computed; we
illustrate its efficacy on BLIP and ALBEF. HIST outperforms baseline VLMs,
achieving up to +9.8% improvement in visual grounding, +6.3% in multi-object
referring segmentation, +1.1% in image-text retrieval, and +0.2% in visual
question answering, underscoring the value of structuring learning in VLMs.

摘要：視覺語言模型 (VLM) 在各種任務上 (例如，影像文字檢索、視覺問題解答) 皆有強勁的表現。然而，大多數 VLM 依賴粗略的影像標題配對來對齊，仰賴資料量來解決歧義並在影像中建立語言概念。文本中更豐富的語意和語法結構在很大程度上被忽略了。為了解決這個問題，我們提出分層結構學習 (HIST)，透過將標題分層分解為構成主詞、名詞片語和複合片語，在沒有任何額外監督的情況下增強 VLM 訓練。這些構成成分之間的蘊涵關係讓我們能夠制定 VLM 注意力圖上的額外正則化約束。具體來說，我們引入了兩個新穎的損失函數：(1) 主詞損失，將影像內容與對應片語的主詞對齊，作為片語層級標準對比/匹配損失的蘊涵關係；(2) 加法損失，平衡多個物件的注意力。HIST 是通用的，並且可以應用於任何可以計算視覺和語言之間注意力的 VLM；我們說明了它在 BLIP 和 ALBEF 上的功效。HIST 優於基準 VLM，在視覺基礎上提升了 +9.8%，在多物件參考分割上提升了 +6.3%，在影像文字檢索上提升了 +1.1%，在視覺問題解答上提升了 +0.2%，強調了在 VLM 中建構學習的價值。

##### **Unseen Horizons: Unveiling the Real Capability of LLM Code Generation Beyond the Familiar**
2412.08109v1 by Yuanliang Zhang, Yifan Xie, Shanshan Li, Ke Liu, Chong Wang, Zhouyang Jia, Xiangbing Huang, Jie Song, Chaopeng Luo, Zhizheng Zheng, Rulin Xu, Yitong Liu, Si Zheng, Xiangke Liao

Recently, large language models (LLMs) have shown strong potential in code
generation tasks. However, there are still gaps before they can be fully
applied in actual software development processes. Accurately assessing the code
generation capabilities of large language models has become an important basis
for evaluating and improving the models. Some existing works have constructed
datasets to evaluate the capabilities of these models. However, the current
evaluation process may encounter the illusion of "Specialist in Familiarity",
primarily due to three gaps: the exposure of target code, case timeliness, and
dependency availability. The fundamental reason for these gaps is that the code
in current datasets may have been extensively exposed and exercised during the
training phase, and due to the continuous training and development of LLM,
their timeliness has been severely compromised. The key to solve the problem is
to, as much as possible, evaluate the LLMs using code that they have not
encountered before. Thus, the fundamental idea in this paper is to draw on the
concept of code obfuscation, changing code at different levels while ensuring
the functionality and output. To this end, we build a code-obfuscation based
benchmark OBFUSEVAL. We first collect 1,354 raw cases from five real-world
projects, including function description and code. Then we use three-level
strategy (symbol, structure and semantic) to obfuscate descriptions, code and
context dependencies. We evaluate four LLMs on OBFU- SEVAL and compared the
effectiveness of different obfuscation strategy. We use official test suites of
these projects to evaluate the generated code. The results show that after
obfuscation, the average decrease ratio of test pass rate can up to 62.5%.

摘要：<paragraph>最近，大型语言模型（LLM）在代码生成任务中显示出强大的潜力。然而，在它们能完全应用于实际软件开发流程之前，仍存在差距。准确评估大型语言模型的代码生成能力已成为评估和改进模型的重要基础。一些现有工作已经构建了数据集来评估这些模型的能力。然而，当前的评估过程可能会遇到“熟能生巧”的错觉，这主要是由于三个差距：目标代码的暴露、案例时效性和依赖性可用性。这些差距的根本原因在于，当前数据集中的代码可能在训练阶段已经得到广泛的暴露和练习，并且由于 LLM 的持续训练和开发，它们的时间性受到了严重损害。解决该问题的关键是尽可能使用 LLM 之前未遇到过的代码来评估 LLM。因此，本文的基本思想是借鉴代码混淆的概念，在确保功能和输出的同时改变不同级别的代码。为此，我们构建了一个基于代码混淆的基准 OBFUSEVAL。我们首先从五个真实项目中收集了 1,354 个原始案例，包括功能描述和代码。然后，我们使用三级策略（符号、结构和语义）来混淆描述、代码和上下文依赖性。我们在 OBFU-SEVAL 上评估了四个 LLM，并比较了不同混淆策略的有效性。我们使用这些项目的官方测试套件来评估生成的代码。结果表明，混淆后，测试通过率的平均下降率可达 62.5%。</paragraph>

##### **Doubly-Universal Adversarial Perturbations: Deceiving Vision-Language Models Across Both Images and Text with a Single Perturbation**
2412.08108v1 by Hee-Seon Kim, Minbeom Kim, Changick Kim

Large Vision-Language Models (VLMs) have demonstrated remarkable performance
across multimodal tasks by integrating vision encoders with large language
models (LLMs). However, these models remain vulnerable to adversarial attacks.
Among such attacks, Universal Adversarial Perturbations (UAPs) are especially
powerful, as a single optimized perturbation can mislead the model across
various input images. In this work, we introduce a novel UAP specifically
designed for VLMs: the Doubly-Universal Adversarial Perturbation (Doubly-UAP),
capable of universally deceiving VLMs across both image and text inputs. To
successfully disrupt the vision encoder's fundamental process, we analyze the
core components of the attention mechanism. After identifying value vectors in
the middle-to-late layers as the most vulnerable, we optimize Doubly-UAP in a
label-free manner with a frozen model. Despite being developed as a black-box
to the LLM, Doubly-UAP achieves high attack success rates on VLMs, consistently
outperforming baseline methods across vision-language tasks. Extensive ablation
studies and analyses further demonstrate the robustness of Doubly-UAP and
provide insights into how it influences internal attention mechanisms.

摘要：大型視覺語言模型 (VLM) 透過整合視覺編碼器與大型語言模型 (LLM)，在多模態任務中展現出卓越的效能。然而，這些模型仍然容易受到對抗性攻擊。在這些攻擊中，通用對抗擾動 (UAP) 特別強大，因為單一最佳化的擾動可以誤導模型跨越各種輸入影像。在這項工作中，我們引入一種專門為 VLM 設計的新型 UAP：雙重通用對抗擾動 (Doubly-UAP)，它能夠普遍欺騙跨越影像和文字輸入的 VLM。為了成功破壞視覺編碼器的基本過程，我們分析了注意力機制的核心組成部分。在將中間到後面的層中的值向量識別為最脆弱的層後，我們使用凍結模型以無標籤的方式最佳化 Doubly-UAP。儘管是作為 LLM 的黑盒子開發，Doubly-UAP 在 VLM 上實現了很高的攻擊成功率，在視覺語言任務中始終優於基線方法。廣泛的消融研究和分析進一步證明了 Doubly-UAP 的穩健性，並提供了它如何影響內部注意力機制的見解。

##### **Adversarial Vulnerabilities in Large Language Models for Time Series Forecasting**
2412.08099v1 by Fuqiang Liu, Sicong Jiang, Luis Miranda-Moreno, Seongjin Choi, Lijun Sun

Large Language Models (LLMs) have recently demonstrated significant potential
in the field of time series forecasting, offering impressive capabilities in
handling complex temporal data. However, their robustness and reliability in
real-world applications remain under-explored, particularly concerning their
susceptibility to adversarial attacks. In this paper, we introduce a targeted
adversarial attack framework for LLM-based time series forecasting. By
employing both gradient-free and black-box optimization methods, we generate
minimal yet highly effective perturbations that significantly degrade the
forecasting accuracy across multiple datasets and LLM architectures. Our
experiments, which include models like TimeGPT and LLM-Time with GPT-3.5,
GPT-4, LLaMa, and Mistral, show that adversarial attacks lead to much more
severe performance degradation than random noise, and demonstrate the broad
effectiveness of our attacks across different LLMs. The results underscore the
critical vulnerabilities of LLMs in time series forecasting, highlighting the
need for robust defense mechanisms to ensure their reliable deployment in
practical applications.

摘要：大型語言模型 (LLM) 近期在時間序列預測領域展示了顯著的潛力，在處理複雜時間數據方面展現了令人印象深刻的能力。然而，它們在實際應用中的穩健性和可靠性仍未得到充分探討，特別是關於它們對對抗性攻擊的敏感性。在本文中，我們引入了一個針對 LLM 時間序列預測的目標對抗性攻擊框架。通過採用無梯度和黑盒優化方法，我們生成了極小但高效率的擾動，這些擾動會顯著降低多個資料集和 LLM 架構的預測準確度。我們的實驗包括 TimeGPT 和 LLM-Time 等模型，以及 GPT-3.5、GPT-4、LLaMa 和 Mistral，結果顯示對抗性攻擊導致的效能下降遠比隨機雜訊嚴重，並證明了我們的攻擊在不同 LLM 中的廣泛有效性。這些結果強調了 LLM 在時間序列預測中的關鍵漏洞，突顯了在實際應用中確保它們可靠部署的必要性。

##### **What You See Is Not Always What You Get: An Empirical Study of Code Comprehension by Large Language Models**
2412.08098v1 by Bangshuo Zhu, Jiawen Wen, Huaming Chen

Recent studies have demonstrated outstanding capabilities of large language
models (LLMs) in software engineering domain, covering numerous tasks such as
code generation and comprehension. While the benefit of LLMs for coding task is
well noted, it is perceived that LLMs are vulnerable to adversarial attacks. In
this paper, we study the specific LLM vulnerability to imperceptible character
attacks, a type of prompt-injection attack that uses special characters to
befuddle an LLM whilst keeping the attack hidden to human eyes. We devise four
categories of attacks and investigate their effects on the performance outcomes
of tasks relating to code analysis and code comprehension. Two generations of
ChatGPT are included to evaluate the impact of advancements made to
contemporary models. Our experimental design consisted of comparing perturbed
and unperturbed code snippets and evaluating two performance outcomes, which
are model confidence using log probabilities of response, and correctness of
response. We conclude that earlier version of ChatGPT exhibits a strong
negative linear correlation between the amount of perturbation and the
performance outcomes, while the recent ChatGPT presents a strong negative
correlation between the presence of perturbation and performance outcomes, but
no valid correlational relationship between perturbation budget and performance
outcomes. We anticipate this work contributes to an in-depth understanding of
leveraging LLMs for coding tasks. It is suggested future research should delve
into how to create LLMs that can return a correct response even if the prompt
exhibits perturbations.

摘要：<paragraph>最近的研究已證明大型語言模型 (LLM) 在軟體工程領域具有傑出的能力，涵蓋了許多任務，例如程式碼產生和理解。雖然 LLM 對編碼任務的好處已廣為人知，但 LLM 被認為容易受到對抗性攻擊。在本文中，我們研究了 LLM 對難以察覺的字元攻擊的具體漏洞，這是一種提示注入攻擊，它使用特殊字元來混淆 LLM，同時讓攻擊對人眼隱藏。我們設計了四種類型的攻擊，並研究它們對與程式碼分析和程式碼理解相關任務的效能結果的影響。包含兩代 ChatGPT 以評估對當代模型所做進展的影響。我們的實驗設計包括比較擾動和未擾動的程式碼片段，並評估兩個效能結果，分別是使用回應的對數機率的模型信心，以及回應的正確性。我們得出的結論是，較早版本的 ChatGPT 在擾動量和效能結果之間表現出強烈的負線性相關性，而最近的 ChatGPT 在擾動的存在和效能結果之間表現出強烈的負相關性，但擾動預算和效能結果之間沒有有效的相關關係。我們預期這項工作有助於深入了解如何利用 LLM 進行編碼任務。建議未來的研究應深入探討如何建立即使提示出現擾動也能回傳正確回應的 LLM。</paragraph>

##### **Multilingual LLMs Inherently Reward In-Language Time-Sensitive Semantic Alignment for Low-Resource Languages**
2412.08090v1 by Ashutosh Bajpai, Tanmoy Chakraborty

The unwavering disparity in labeled resources between resource-rich languages
and those considered low-resource remains a significant impediment for Large
Language Models (LLMs). Recent strides in cross-lingual in-context learning
(X-ICL), mainly through semantically aligned examples retrieved from
multilingual pre-trained transformers, have shown promise in mitigating this
issue. However, our investigation reveals that LLMs intrinsically reward
in-language semantically aligned cross-lingual instances over direct
cross-lingual semantic alignments, with a pronounced disparity in handling
time-sensitive queries in the X-ICL setup. Such queries demand sound temporal
reasoning ability from LLMs, yet the advancements have predominantly focused on
English. This study aims to bridge this gap by improving temporal reasoning
capabilities in low-resource languages. To this end, we introduce mTEMPREASON a
temporal reasoning dataset aimed at the varied degrees of low-resource
languages and propose Cross-Lingual Time-Sensitive Semantic Alignment
(CLiTSSA), a novel method to improve temporal reasoning in these contexts. To
facilitate this, we construct an extension of mTEMPREASON comprising pairs of
parallel cross-language temporal queries along with their anticipated
in-language semantic similarity scores. Our empirical evidence underscores the
superior performance of CLiTSSA compared to established baselines across three
languages - Romanian, German, and French, encompassing three temporal tasks and
including a diverse set of four contemporaneous LLMs. This marks a significant
step forward in addressing resource disparity in the context of temporal
reasoning across languages.

摘要：<paragraph>在資源豐富的語言和被認為是低資源的語言之間標記資源的堅定差異仍然是大型語言模型 (LLM) 的重大障礙。最近跨語言情境學習 (X-ICL) 的進展，主要是透過從多語言預訓練轉換器中擷取的語義對齊範例，已展現出緩解此問題的希望。然而，我們的調查顯示，LLM 本質上獎勵語言內語義對齊的跨語言實例，而不是直接的跨語言語義對齊，在處理 X-ICL 設定中的時間敏感查詢時有顯著差異。此類查詢要求 LLM 具備良好的時間推理能力，但進展主要集中在英語上。本研究旨在透過改善低資源語言中的時間推理能力來彌合此差距。為此，我們引入了 mTEMPREASON，一個針對不同程度低資源語言的時間推理資料集，並提出了跨語言時間敏感語義對齊 (CLiTSSA)，一種在這些情境中改善時間推理的新方法。為了促進這一點，我們建構了一個 mTEMPREASON 延伸，其中包含平行跨語言時間查詢對以及它們預期的語言內語義相似性評分。我們的實證證據強調了 CLiTSSA 的效能優於三個語言（羅馬尼亞語、德語和法語）的既定基準，涵蓋了三個時間任務，並包含了四個當代 LLM 的多樣化集合。這標誌著在跨語言時間推理中解決資源差異方面邁出了重要一步。</paragraph>

##### **How to select slices for annotation to train best-performing deep learning segmentation models for cross-sectional medical images?**
2412.08081v1 by Yixin Zhang, Kevin Kramer, Maciej A. Mazurowski

Automated segmentation of medical images highly depends on the availability
of accurate manual image annotations. Such annotations are very time-consuming
and costly to generate, and often require specialized expertise, particularly
for cross-sectional images which contain many slices for each patient. It is
crucial to ensure the best use of annotation resources. In this paper, we
systematically answer the question of how to select slices of cross-sectional
medical images in order to maximize performance of the resulting deep learning
segmentation models. We conducted experiments on 4 medical imaging segmentation
tasks with varying annotation budgets, numbers of annotated cases, numbers of
annotated slices per volume, slice selection techniques, and mask
interpolations. We found that:
  1) It is almost always preferable to annotate fewer slices per volume and
more volumes given an annotation budget. 2) Selecting slices for annotation by
unsupervised active learning (UAL) is not superior to selecting slices randomly
or at fixed intervals, provided that each volume is allocated the same number
of annotated slices. 3) Interpolating masks between annotated slices rarely
enhances model performance, with exceptions of some specific configuration for
3D models.

摘要：醫學影像的自動化分割高度依賴於準確的手動影像標註。此類標註非常耗時且生成成本高昂，且通常需要專業知識，特別是對於每個患者包含許多切片的橫斷面影像。確保最佳利用標註資源至關重要。在本文中，我們系統性地回答了如何選擇橫斷面醫學影像切片以最大化深度學習分割模型效能的問題。我們針對 4 項醫學影像分割任務進行了實驗，這些任務具有不同的標註預算、標註案例數、每個體積的標註切片數、切片選擇技術和遮罩內插。我們發現：
1) 在給定標註預算的情況下，幾乎總是優先標註每個體積較少切片和更多體積。2) 透過非監督主動學習 (UAL) 選擇切片進行標註並不優於隨機或固定間隔選擇切片，前提是每個體積分配的標註切片數相同。3) 在標註切片之間內插遮罩很少能提升模型效能，但某些 3D 模型的特定組態除外。

##### **Using Large Language Models for Parametric Shape Optimization**
2412.08072v1 by Xinxin Zhang, Zhuoqun Xu, Guangpu Zhu, Chien Ming Jonathan Tay, Yongdong Cui, Boo Cheong Khoo, Lailai Zhu

Recent advanced large language models (LLMs) have showcased their emergent
capability of in-context learning, facilitating intelligent decision-making
through natural language prompts without retraining. This new machine learning
paradigm has shown promise in various fields, including general control and
optimization problems. Inspired by these advancements, we explore the potential
of LLMs for a specific and essential engineering task: parametric shape
optimization (PSO). We develop an optimization framework, LLM-PSO, that
leverages an LLM to determine the optimal shape of parameterized engineering
designs in the spirit of evolutionary strategies. Utilizing the ``Claude 3.5
Sonnet'' LLM, we evaluate LLM-PSO on two benchmark flow optimization problems,
specifically aiming to identify drag-minimizing profiles for 1) a
two-dimensional airfoil in laminar flow, and 2) a three-dimensional
axisymmetric body in Stokes flow. In both cases, LLM-PSO successfully
identifies optimal shapes in agreement with benchmark solutions. Besides, it
generally converges faster than other classical optimization algorithms. Our
preliminary exploration may inspire further investigations into harnessing LLMs
for shape optimization and engineering design more broadly.

摘要：最近的先进大型语言模型 (LLM) 展示了它们在情境学习中的新兴能力，通过自然语言提示促进智能决策制定，而无需重新训练。这种新的机器学习范例在各个领域都显示出前景，包括通用控制和优化问题。受这些进步的启发，我们探索了 LLM 在特定且必要的工程任务中的潜力：参数化形状优化 (PSO)。我们开发了一个优化框架 LLM-PSO，它利用 LLM 根据进化策略的精神确定参数化工程设计的最佳形状。利用 ``Claude 3.5 Sonnet'' LLM，我们在两个基准流优化问题上评估 LLM-PSO，具体目标是识别阻力最小的轮廓，用于 1) 层流中的二维机翼和 2) 斯托克斯流中的三维轴对称体。在这两种情况下，LLM-PSO 都成功识别出与基准解决方案一致的最佳形状。此外，它通常比其他经典优化算法收敛得更快。我们的初步探索可能会激发进一步的研究，以利用 LLM 更广泛地进行形状优化和工程设计。

##### **DialogAgent: An Auto-engagement Agent for Code Question Answering Data Production**
2412.08069v1 by Xiaoyun Liang, Jingyi Ren, Jiayi Qi, Chao Peng, Bo Jiang

Large Language Models (LLMs) have become increasingly integral to enhancing
developer productivity, particularly in code generation, comprehension, and
repair tasks. However, fine-tuning these models with high-quality, real-world
data is challenging due to privacy concerns and the lack of accessible, labeled
datasets. In this paper, we present DialogAgent, an automated tool for
generating synthetic training data that closely mimics real developer
interactions within Integrated Development Environments (IDEs). DialogAgent
enables the production of diverse, high-fidelity query-response pairs by
simulating multi-turn dialogues and contextual behaviors observed in real-world
programming scenarios. The tool significantly reduces the reliance on manual
data generation, increasing efficiency by 4.8 times compared to traditional
methods. Our experiments and online deployment demonstrate substantial
improvements in model performance for code-related question-answering tasks:
the acceptance rate of responses generated by our in-house model is improved by
33%, after training on synthesized data generated by DialogAgent.

摘要：大型語言模型 (LLM) 已日益成為提升開發人員生產力的重要組成部分，特別是在程式碼生成、理解和修復任務中。然而，由於隱私問題和可存取標記資料集的缺乏，使用高品質的真實世界資料微調這些模型具有挑戰性。在本文中，我們提出 DialogAgent，這是一種自動化工具，用於生成合成訓練資料，該資料可以緊密模擬整合開發環境 (IDE) 中的真實開發人員互動。DialogAgent 透過模擬真實世界程式設計場景中觀察到的多輪對話和情境行為，能夠產生多樣化、高保真度的查詢回應配對。此工具大幅減少對手動資料生成的依賴，與傳統方法相比，效率提高 4.8 倍。我們的實驗和線上部署證明了程式碼相關問題回答任務的模型效能有大幅進步：在經過 DialogAgent 生成的合成資料訓練後，我們內部模型產生的回應接受率提高了 33%。

##### **Repository-Level Graph Representation Learning for Enhanced Security Patch Detection**
2412.08068v1 by Xin-Cheng Wen, Zirui Lin, Cuiyun Gao, Hongyu Zhang, Yong Wang, Qing Liao

Software vendors often silently release security patches without providing
sufficient advisories (e.g., Common Vulnerabilities and Exposures) or delayed
updates via resources (e.g., National Vulnerability Database). Therefore, it
has become crucial to detect these security patches to ensure secure software
maintenance. However, existing methods face the following challenges: (1) They
primarily focus on the information within the patches themselves, overlooking
the complex dependencies in the repository. (2) Security patches typically
involve multiple functions and files, increasing the difficulty in well
learning the representations. To alleviate the above challenges, this paper
proposes a Repository-level Security Patch Detection framework named RepoSPD,
which comprises three key components: 1) a repository-level graph construction,
RepoCPG, which represents software patches by merging pre-patch and post-patch
source code at the repository level; 2) a structure-aware patch representation,
which fuses the graph and sequence branch and aims at comprehending the
relationship among multiple code changes; 3) progressive learning, which
facilitates the model in balancing semantic and structural information. To
evaluate RepoSPD, we employ two widely-used datasets in security patch
detection: SPI-DB and PatchDB. We further extend these datasets to the
repository level, incorporating a total of 20,238 and 28,781 versions of
repository in C/C++ programming languages, respectively, denoted as SPI-DB* and
PatchDB*. We compare RepoSPD with six existing security patch detection methods
and five static tools. Our experimental results demonstrate that RepoSPD
outperforms the state-of-the-art baseline, with improvements of 11.90%, and
3.10% in terms of accuracy on the two datasets, respectively.

摘要：<paragraph>軟體供應商通常會在沒有提供足夠的諮詢（例如常見漏洞和曝險）或延遲透過資源（例如國家漏洞資料庫）更新的情況下，無聲地發布安全性修補程式。因此，偵測這些安全性修補程式以確保軟體維護安全至關重要。然而，現有方法面臨以下挑戰：(1) 它們主要關注修補程式本身的資訊，忽略了儲存庫中複雜的相依性。(2) 安全性修補程式通常涉及多個函式和檔案，增加了良好學習表示形式的難度。為了緩解上述挑戰，本文提出了一個名為 RepoSPD 的儲存庫層級安全性修補程式偵測架構，它包含三個關鍵元件：1) 儲存庫層級圖形建構，RepoCPG，它透過合併儲存庫層級的前修補程式和後修補程式原始碼來表示軟體修補程式；2) 結構感知修補程式表示形式，它融合了圖形和序列分支，旨在理解多個程式碼變更之間的關係；3) 漸進式學習，它有助於模型平衡語意和結構資訊。為了評估 RepoSPD，我們在安全性修補程式偵測中採用了兩個廣泛使用的資料集：SPI-DB 和 PatchDB。我們進一步將這些資料集擴充套件到儲存庫層級，分別納入了 C/C++ 程式語言中總計 20,238 和 28,781 個版本的儲存庫，表示為 SPI-DB* 和 PatchDB*。我們將 RepoSPD 與六種現有的安全性修補程式偵測方法和五種靜態工具進行比較。我們的實驗結果表明，RepoSPD 優於最先進的基準，在兩個資料集上的準確性分別提高了 11.90% 和 3.10%。</paragraph>

##### **ContextModule: Improving Code Completion via Repository-level Contextual Information**
2412.08063v1 by Zhanming Guan, Junlin Liu, Jierui Liu, Chao Peng, Dexin Liu, Ningyuan Sun, Bo Jiang, Wenchao Li, Jie Liu, Hang Zhu

Large Language Models (LLMs) have demonstrated impressive capabilities in
code completion tasks, where they assist developers by predicting and
generating new code in real-time. However, existing LLM-based code completion
systems primarily rely on the immediate context of the file being edited, often
missing valuable repository-level information, user behaviour and edit history
that could improve suggestion accuracy. Additionally, challenges such as
efficiently retrieving relevant code snippets from large repositories,
incorporating user behavior, and balancing accuracy with low-latency
requirements in production environments remain unresolved. In this paper, we
propose ContextModule, a framework designed to enhance LLM-based code
completion by retrieving and integrating three types of contextual information
from the repository: user behavior-based code, similar code snippets, and
critical symbol definitions. By capturing user interactions across files and
leveraging repository-wide static analysis, ContextModule improves the
relevance and precision of generated code. We implement performance
optimizations, such as index caching, to ensure the system meets the latency
constraints of real-world coding environments. Experimental results and
industrial practise demonstrate that ContextModule significantly improves code
completion accuracy and user acceptance rates.

摘要：大型語言模型 (LLM) 已在代碼完成任務中展現出令人印象深刻的能力，它們能協助開發人員即時預測和產生新代碼。然而，現有的 LLM 基於代碼完成系統主要依賴於正在編輯檔案的即時內容，通常會遺漏有價值的儲存庫層級資訊、使用者行為和編輯記錄，而這些資訊可以提升建議的準確度。此外，在生產環境中有效率地從大型儲存庫擷取相關程式碼片段、納入使用者行為，以及平衡準確度與低延遲需求等挑戰仍然未獲解決。在本文中，我們提出 ContextModule，一個旨在透過從儲存庫擷取和整合三種類型的內容資訊來增強 LLM 基於代碼完成的架構：基於使用者行為的代碼、類似的程式碼片段和關鍵符號定義。透過擷取跨檔案的使用者互動並利用儲存庫範圍的靜態分析，ContextModule 提升了所產生代碼的相關性和精確度。我們實作效能最佳化，例如索引快取，以確保系統符合真實世界編碼環境的延遲限制。實驗結果和產業實務證明，ContextModule 大幅提升了代碼完成的準確度和使用者接受率。

##### **Go-Oracle: Automated Test Oracle for Go Concurrency Bugs**
2412.08061v1 by Foivos Tsimpourlas, Chao Peng, Carlos Rosuero, Ping Yang, Ajitha Rajan

The Go programming language has gained significant traction for developing
software, especially in various infrastructure systems. Nonetheless,
concurrency bugs have become a prevalent issue within Go, presenting a unique
challenge due to the language's dual concurrency mechanisms-communicating
sequential processes and shared memory. Detecting concurrency bugs and
accurately classifying program executions as pass or fail presents an immense
challenge, even for domain experts. We conducted a survey with expert
developers at Bytedance that confirmed this challenge. Our work seeks to
address the test oracle problem for Go programs, to automatically classify test
executions as pass or fail. This problem has not been investigated in the
literature for Go programs owing to its distinctive programming model.
  Our approach involves collecting both passing and failing execution traces
from various subject Go programs. We capture a comprehensive array of execution
events using the native Go execution tracer. Subsequently, we preprocess and
encode these traces before training a transformer-based neural network to
effectively classify the traces as either passing or failing. The evaluation of
our approach encompasses 8 subject programs sourced from the GoBench
repository. These subject programs are routinely used as benchmarks in an
industry setting. Encouragingly, our test oracle, Go-Oracle, demonstrates high
accuracies even when operating with a limited dataset, showcasing the efficacy
and potential of our methodology. Developers at Bytedance strongly agreed that
they would use the Go-Oracle tool over the current practice of manual
inspections to classify tests for Go programs as pass or fail.

摘要：Go 程式語言在開發軟體方面獲得顯著的進展，特別是在各種基礎架構系統中。儘管如此，並發錯誤已成為 Go 中普遍的問題，由於語言的雙重並發機制（傳遞順序處理和共享記憶體），這提出了獨特的挑戰。即使對於領域專家來說，偵測並發錯誤和準確地將程式執行分類為通過或失敗也構成了巨大的挑戰。我們在 ByteDance 進行了一項專家開發人員調查，證實了這項挑戰。我們的研究旨在解決 Go 程式的測試預言問題，以自動將測試執行分類為通過或失敗。由於其獨特的程式設計模型，這個問題尚未在 Go 程式的文獻中得到探討。我們的做法包括從各種主題 Go 程式收集通過和失敗的執行追蹤。我們使用原生 Go 執行追蹤器擷取全面的執行事件陣列。隨後，我們在訓練基於轉換器的類神經網路以有效地將追蹤分類為通過或失敗之前，對這些追蹤進行預處理和編碼。我們的方法評估包含來自 GoBench 儲存庫的 8 個主題程式。這些主題程式通常用作產業環境中的基準。令人鼓舞的是，即使在使用有限的資料集操作時，我們的測試預言 Go-Oracle 也表現出很高的準確性，展示了我們方法的有效性和潛力。ByteDance 的開發人員強烈同意，他們將使用 Go-Oracle 工具，而不是目前的測試手動檢查方式，將 Go 程式的測試分類為通過或失敗。

##### **Federated In-Context LLM Agent Learning**
2412.08054v1 by Panlong Wu, Kangshuo Li, Junbao Nan, Fangxin Wang

Large Language Models (LLMs) have revolutionized intelligent services by
enabling logical reasoning, tool use, and interaction with external systems as
agents. The advancement of LLMs is frequently hindered by the scarcity of
high-quality data, much of which is inherently sensitive. Federated learning
(FL) offers a potential solution by facilitating the collaborative training of
distributed LLMs while safeguarding private data. However, FL frameworks face
significant bandwidth and computational demands, along with challenges from
heterogeneous data distributions. The emerging in-context learning capability
of LLMs offers a promising approach by aggregating natural language rather than
bulky model parameters. Yet, this method risks privacy leakage, as it
necessitates the collection and presentation of data samples from various
clients during aggregation. In this paper, we propose a novel
privacy-preserving Federated In-Context LLM Agent Learning (FICAL) algorithm,
which to our best knowledge for the first work unleashes the power of
in-context learning to train diverse LLM agents through FL. In our design,
knowledge compendiums generated by a novel LLM-enhanced Knowledge Compendiums
Generation (KCG) module are transmitted between clients and the server instead
of model parameters in previous FL methods. Apart from that, an incredible
Retrieval Augmented Generation (RAG) based Tool Learning and Utilizing (TLU)
module is designed and we incorporate the aggregated global knowledge
compendium as a teacher to teach LLM agents the usage of tools. We conducted
extensive experiments and the results show that FICAL has competitive
performance compared to other SOTA baselines with a significant communication
cost decrease of $\mathbf{3.33\times10^5}$ times.

摘要：<paragraph>大型語言模型 (LLM) 透過讓代理人進行邏輯推理、使用工具以及與外部系統互動，進而革新了智慧服務。LLM 的進展經常受到高品質資料短缺的阻礙，其中許多資料本質上是敏感的。聯合學習 (FL) 提供了一個潛在的解決方案，它促進了分散式 LLM 的協作訓練，同時保護了私人資料。然而，FL 框架面臨著顯著的頻寬和運算需求，以及異質資料分佈帶來的挑戰。LLM 新興的語境學習能力提供了一個有前途的方法，它聚合自然語言，而不是龐大的模型參數。然而，此方法有隱私外洩的風險，因為它需要在聚合過程中收集和呈現來自不同客戶端的資料樣本。在本文中，我們提出了一種新穎的隱私保護聯合語境 LLM 代理學習 (FICAL) 演算法，根據我們所知，這是第一個發揮語境學習的力量，透過 FL 訓練多樣化的 LLM 代理。在我們的設計中，由新穎的 LLM 增強的知識彙編生成 (KCG) 模組產生的知識彙編在客戶端和伺服器之間傳輸，而不是先前 FL 方法中的模型參數。除此之外，我們設計了一個基於令人難以置信的檢索增強生成 (RAG) 的工具學習和利用 (TLU) 模組，並將聚合的全球知識彙編作為老師，教導 LLM 代理如何使用工具。我們進行了廣泛的實驗，結果顯示 FICAL 與其他 SOTA 基準相比具有競爭力的效能，同時將通訊成本大幅降低 $\mathbf{3.33\times10^5}$ 倍。</paragraph>

##### **DynamicPAE: Generating Scene-Aware Physical Adversarial Examples in Real-Time**
2412.08053v1 by Jin Hu, Xianglong Liu, Jiakai Wang, Junkai Zhang, Xianqi Yang, Haotong Qin, Yuqing Ma, Ke Xu

Physical adversarial examples (PAEs) are regarded as "whistle-blowers" of
real-world risks in deep-learning applications. However, current PAE generation
studies show limited adaptive attacking ability to diverse and varying scenes.
The key challenges in generating dynamic PAEs are exploring their patterns
under noisy gradient feedback and adapting the attack to agnostic scenario
natures. To address the problems, we present DynamicPAE, the first generative
framework that enables scene-aware real-time physical attacks beyond static
attacks. Specifically, to train the dynamic PAE generator under noisy gradient
feedback, we introduce the residual-driven sample trajectory guidance
technique, which redefines the training task to break the limited feedback
information restriction that leads to the degeneracy problem. Intuitively, it
allows the gradient feedback to be passed to the generator through a low-noise
auxiliary task, thereby guiding the optimization away from degenerate solutions
and facilitating a more comprehensive and stable exploration of feasible PAEs.
To adapt the generator to agnostic scenario natures, we introduce the
context-aligned scene expectation simulation process, consisting of the
conditional-uncertainty-aligned data module and the skewness-aligned objective
re-weighting module. The former enhances robustness in the context of
incomplete observation by employing a conditional probabilistic model for
domain randomization, while the latter facilitates consistent stealth control
across different attack targets by automatically reweighting losses based on
the skewness indicator. Extensive digital and physical evaluations demonstrate
the superior attack performance of DynamicPAE, attaining a 1.95 $\times$ boost
(65.55% average AP drop under attack) on representative object detectors (e.g.,
Yolo-v8) over state-of-the-art static PAE generating methods.

摘要：<paragraph>物理对抗性範例 (PAE) 被視為深度學習應用中「吹哨者」的真實世界風險。然而，目前的 PAE 生成研究顯示出有限的適應性攻擊能力，無法應對多樣化和變化的場景。生成動態 PAE 的主要挑戰是探索它們在有雜訊的梯度回饋下的模式，並適應攻擊到不可知場景的性質。為了解決這些問題，我們提出了 DynamicPAE，這是第一個生成式架構，它能進行場景感知的實時物理攻擊，超越靜態攻擊。具體來說，為了在有雜訊的梯度回饋下訓練動態 PAE 生成器，我們引入了殘差驅動的樣本軌跡引導技術，它重新定義了訓練任務，以打破導致退化問題的有限回饋資訊限制。直觀地說，它允許梯度回饋通過低雜訊輔助任務傳遞到生成器，從而引導最佳化遠離退化解，並促進對可行 PAE 進行更全面和穩定的探索。為了適應生成器到不可知場景的性質，我們引入了上下文對齊的場景期望模擬過程，它包含條件不確定性對齊數據模組和偏度對齊目標重新加權模組。前者通過採用條件機率模型進行網域隨機化，增強了在不完整觀測下的穩健性，而後者通過根據偏度指標自動重新加權損失，促进了在不同攻击目标之间的一致隐身控制。廣泛的數位和物理評估證明了 DynamicPAE 優異的攻擊性能，在代表性的物件偵測器（例如，Yolo-v8）上，與最先進的靜態 PAE 生成方法相比，攻擊下的平均 AP 下降了 1.95 倍（65.55%）。</paragraph>

##### **M2SE: A Multistage Multitask Instruction Tuning Strategy for Unified Sentiment and Emotion Analysis**
2412.08049v1 by Ao Li, Longwei Xu, Chen Ling, Jinghui Zhang, Pengwei Wang

Sentiment analysis and emotion recognition are crucial for applications such
as human-computer interaction and depression detection. Traditional unimodal
methods often fail to capture the complexity of emotional expressions due to
conflicting signals from different modalities. Current Multimodal Large
Language Models (MLLMs) also face challenges in detecting subtle facial
expressions and addressing a wide range of emotion-related tasks. To tackle
these issues, we propose M2SE, a Multistage Multitask Sentiment and Emotion
Instruction Tuning Strategy for general-purpose MLLMs. It employs a combined
approach to train models on tasks such as multimodal sentiment analysis,
emotion recognition, facial expression recognition, emotion reason inference,
and emotion cause-pair extraction. We also introduce the Emotion Multitask
dataset (EMT), a custom dataset that supports these five tasks. Our model,
Emotion Universe (EmoVerse), is built on a basic MLLM framework without
modifications, yet it achieves substantial improvements across these tasks when
trained with the M2SE strategy. Extensive experiments demonstrate that EmoVerse
outperforms existing methods, achieving state-of-the-art results in sentiment
and emotion tasks. These results highlight the effectiveness of M2SE in
enhancing multimodal emotion perception. The dataset and code are available at
https://github.com/xiaoyaoxinyi/M2SE.

摘要：情緒分析和情緒辨識對於人機互動和憂鬱症偵測等應用至關重要。傳統的單模態方法由於不同模態的訊號相互衝突，常常無法捕捉到情緒表達的複雜性。目前的多模態大型語言模型 (MLLM) 在偵測細微面部表情和處理廣泛的情緒相關任務方面也面臨挑戰。為了解決這些問題，我們提出了 M2SE，一種針對通用 MLLM 的多階段多任務情緒和情緒指令調整策略。它採用一種結合方法來訓練模型，執行多模態情緒分析、情緒辨識、面部表情辨識、情緒原因推論和情緒成因對萃取等任務。我們也引入了情緒多任務資料集 (EMT)，這是一個支援這五項任務的客製化資料集。我們的模型情緒宇宙 (EmoVerse) 建立在一個基本的 MLLM 架構上，沒有修改，但在使用 M2SE 策略訓練後，在這些任務中都取得了顯著的進步。廣泛的實驗證明，EmoVerse 優於現有方法，在情緒和情感任務中取得了最先進的結果。這些結果突顯了 M2SE 在增強多模態情緒感知方面的有效性。資料集和程式碼可在 https://github.com/xiaoyaoxinyi/M2SE 取得。

##### **Bootstrapping Heterogeneous Graph Representation Learning via Large Language Models: A Generalized Approach**
2412.08038v1 by Hang Gao, Chenhao Zhang, Fengge Wu, Junsuo Zhao, Changwen Zheng, Huaping Liu

Graph representation learning methods are highly effective in handling
complex non-Euclidean data by capturing intricate relationships and features
within graph structures. However, traditional methods face challenges when
dealing with heterogeneous graphs that contain various types of nodes and edges
due to the diverse sources and complex nature of the data. Existing
Heterogeneous Graph Neural Networks (HGNNs) have shown promising results but
require prior knowledge of node and edge types and unified node feature
formats, which limits their applicability. Recent advancements in graph
representation learning using Large Language Models (LLMs) offer new solutions
by integrating LLMs' data processing capabilities, enabling the alignment of
various graph representations. Nevertheless, these methods often overlook
heterogeneous graph data and require extensive preprocessing. To address these
limitations, we propose a novel method that leverages the strengths of both LLM
and GNN, allowing for the processing of graph data with any format and type of
nodes and edges without the need for type information or special preprocessing.
Our method employs LLM to automatically summarize and classify different data
formats and types, aligns node features, and uses a specialized GNN for
targeted learning, thus obtaining effective graph representations for
downstream tasks. Theoretical analysis and experimental validation have
demonstrated the effectiveness of our method.

摘要：圖表表示學習方法在處理複雜的非歐幾里得數據方面非常有效，方法是捕捉圖形結構中的複雜關係和特徵。然而，由於數據來源多樣且性質複雜，傳統方法在處理包含各種類型節點和邊的異質圖形時面臨挑戰。現有的異質圖形神經網路 (HGNN) 已展現出有希望的成果，但需要事先了解節點和邊的類型，以及統一的節點特徵格式，這限制了其適用性。最近使用大型語言模型 (LLM) 的圖形表示學習的進展提供了新的解決方案，方法是整合 LLM 的數據處理功能，使各種圖形表示得以對齊。儘管如此，這些方法通常會忽略異質圖形數據，並且需要廣泛的預處理。為了解決這些限制，我們提出了一種新方法，它利用了 LLM 和 GNN 的優點，允許處理任何格式和類型的節點和邊的圖形數據，而不需要類型信息或特殊預處理。我們的模型採用 LLM 自動總結和分類不同的數據格式和類型，對齊節點特徵，並使用專門的 GNN 進行目標學習，從而為下游任務獲取有效的圖形表示。理論分析和實驗驗證已證明了我們方法的有效性。

##### **TinyThinker: Distilling Reasoning through Coarse-to-Fine Knowledge Internalization with Self-Reflection**
2412.08024v1 by Shengmin Piao, Sanghyun Park

Large Language Models exhibit impressive reasoning capabilities across
diverse tasks, motivating efforts to distill these capabilities into smaller
models through generated reasoning data. However, direct training on such
synthesized reasoning data may lead to superficial imitation of reasoning
process, rather than fostering a genuine integration of reasoning capabilities
with underlying knowledge. To address this, we propose TinyThinker, a framework
introducing two novel approaches. First, we introduce a three-stage process
that incrementally guides the student model through the reasoning process,
progressively refining knowledge from coarse to fine granularity. Second, we
develop a two-phase training framework comprising an initial reasoning
acquisition phase followed by a self-reflection phase utilizing self-generated
data. Experiments on commonsense reasoning benchmarks demonstrate that
TinyThinker achieves superior performance compared to baselines. Ablation
studies further validate the effectiveness of each component in our framework.
TinyThinker is extendable to other knowledge-intensive reasoning tasks,
offering an alternative strategy for developing effective reasoning
capabilities in smaller language models. Codes are available at
https://github.com/shengminp/TinyThinker

摘要：大型語言模型在各種任務中展現出令人印象深刻的推理能力，激勵人們透過產生的推理資料將這些能力提煉到較小的模型中。然而，直接訓練此類合成的推理資料可能會導致推理過程的表面模仿，而不是促進推理能力與基礎知識的真正整合。為了解決這個問題，我們提出 TinyThinker，一個引入兩種新方法的框架。首先，我們引入一個三階段流程，逐步引導學生模型完成推理過程，逐步從粗略到精細的粒度中提煉知識。其次，我們開發了一個兩階段訓練框架，包括一個初始推理獲取階段，然後是一個利用自生資料的自省階段。在常識推理基準上的實驗表明，與基準線相比，TinyThinker 達到了更高的性能。消融研究進一步驗證了我們框架中每個組件的有效性。TinyThinker 可擴展到其他知識密集型推理任務，為在較小的語言模型中開發有效的推理能力提供了一種替代策略。程式碼可在 https://github.com/shengminp/TinyThinker 獲得

