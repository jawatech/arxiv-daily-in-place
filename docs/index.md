# arxiv-daily
 Automated deployment @ 2024-12-10 09:12:41 Asia/Taipei
> Welcome to contribute! Add your topics and keywords in [`topic.yml`](https://github.com/jawatech/arxiv-daily-in-place/blob/main/database/topic.yml).
> You can also view historical data through the [storage](https://github.com/jawatech/arxiv-daily-in-place/blob/main/database/storage).

## AI

### Medical explainable AI
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-11-30**|**2-Factor Retrieval for Improved Human-AI Decision Making in Radiology**|Jim Solomon et.al.|[2412.00372v1](http://arxiv.org/abs/2412.00372v1)|null|
|**2024-11-28**|**Mapping Public Perception of Artificial Intelligence: Expectations, Risk-Benefit Tradeoffs, and Value As Determinants for Societal Acceptance**|Philipp Brauner et.al.|[2411.19356v1](http://arxiv.org/abs/2411.19356v1)|null|
|**2024-11-26**|**Explainable AI for Classifying UTI Risk Groups Using a Real-World Linked EHR and Pathology Lab Dataset**|Yujie Dai et.al.|[2411.17645v1](http://arxiv.org/abs/2411.17645v1)|null|
|**2024-11-18**|**Exploring the Requirements of Clinicians for Explainable AI Decision Support Systems in Intensive Care**|Jeffrey N. Clark et.al.|[2411.11774v1](http://arxiv.org/abs/2411.11774v1)|null|
|**2024-11-15**|**Artificial Intelligence in Pediatric Echocardiography: Exploring Challenges, Opportunities, and Clinical Applications with Explainable AI and Federated Learning**|Mohammed Yaseen Jabarulla et.al.|[2411.10255v1](http://arxiv.org/abs/2411.10255v1)|null|
|**2024-11-01**|**Enhancing Osteoporosis Detection: An Explainable Multi-Modal Learning Framework with Feature Fusion and Variable Clustering**|Mehdi Hosseini Chagahi et.al.|[2411.00916v2](http://arxiv.org/abs/2411.00916v2)|null|
|**2024-10-25**|**A Review of Deep Learning Approaches for Non-Invasive Cognitive Impairment Detection**|Muath Alsuhaibani et.al.|[2410.19898v1](http://arxiv.org/abs/2410.19898v1)|null|
|**2024-10-23**|**An Ontology-Enabled Approach For User-Centered and Knowledge-Enabled Explanations of AI Systems**|Shruthi Chari et.al.|[2410.17504v1](http://arxiv.org/abs/2410.17504v1)|[link](https://github.com/tetherless-world/metaexplainer)|
|**2024-10-22**|**Contrasting Attitudes Towards Current and Future AI Applications for Computerised Interpretation of ECG: A Clinical Stakeholder Interview Study**|Lukas Hughes-Noehrer et.al.|[2410.16879v1](http://arxiv.org/abs/2410.16879v1)|null|
|**2024-10-19**|**Pathologist-like explainable AI for interpretable Gleason grading in prostate cancer**|Gesa Mittmann et.al.|[2410.15012v1](http://arxiv.org/abs/2410.15012v1)|null|
|**2024-10-15**|**Explainable AI Methods for Multi-Omics Analysis: A Survey**|Ahmad Hussein et.al.|[2410.11910v1](http://arxiv.org/abs/2410.11910v1)|null|
|**2024-10-14**|**Study on the Helpfulness of Explainable Artificial Intelligence**|Tobias Labarta et.al.|[2410.11896v1](http://arxiv.org/abs/2410.11896v1)|[link](https://github.com/tlabarta/helpfulnessofxai)|
|**2024-10-12**|**Use of What-if Scenarios to Help Explain Artificial Intelligence Models for Neonatal Health**|Abdullah Mamun et.al.|[2410.09635v1](http://arxiv.org/abs/2410.09635v1)|[link](https://github.com/ab9mamun/aimen)|
|**2024-10-10**|**Artificial intelligence techniques in inherited retinal diseases: A review**|Han Trinh et.al.|[2410.09105v1](http://arxiv.org/abs/2410.09105v1)|null|
|**2024-10-07**|**CasiMedicos-Arg: A Medical Question Answering Dataset Annotated with Explanatory Argumentative Structures**|Ekaterina Sviridova et.al.|[2410.05235v2](http://arxiv.org/abs/2410.05235v2)|[link](https://github.com/ixa-ehu/antidote-casimedicos)|
|**2024-10-01**|**Explainable Diagnosis Prediction through Neuro-Symbolic Integration**|Qiuhao Lu et.al.|[2410.01855v1](http://arxiv.org/abs/2410.01855v1)|null|
|**2024-10-01**|**Easydiagnos: a framework for accurate feature selection for automatic diagnosis in smart healthcare**|Prasenjit Maji et.al.|[2410.00366v1](http://arxiv.org/abs/2410.00366v1)|null|
|**2024-09-20**|**Dermatologist-like explainable AI enhances melanoma diagnosis accuracy: eye-tracking study**|Tirtha Chanda et.al.|[2409.13476v1](http://arxiv.org/abs/2409.13476v1)|null|
|**2024-09-19**|**Explainable AI for Autism Diagnosis: Identifying Critical Brain Regions Using fMRI Data**|Suryansh Vidya et.al.|[2409.15374v1](http://arxiv.org/abs/2409.15374v1)|null|
|**2024-09-19**|**Improving Prototypical Parts Abstraction for Case-Based Reasoning Explanations Designed for the Kidney Stone Type Recognition**|Daniel Flores-Araiza et.al.|[2409.12883v1](http://arxiv.org/abs/2409.12883v1)|null|
|**2024-09-18**|**Towards Interpretable End-Stage Renal Disease (ESRD) Prediction: Utilizing Administrative Claims Data with Explainable AI Techniques**|Yubo Li et.al.|[2409.12087v3](http://arxiv.org/abs/2409.12087v3)|null|
|**2024-09-09**|**Explainable AI: Definition and attributes of a good explanation for health AI**|Evangelia Kyrimi et.al.|[2409.15338v1](http://arxiv.org/abs/2409.15338v1)|null|
|**2024-08-30**|**Exploring the Effect of Explanation Content and Format on User Comprehension and Trust**|Antonio Rago et.al.|[2408.17401v1](http://arxiv.org/abs/2408.17401v1)|null|
|**2024-08-29**|**A Survey for Large Language Models in Biomedicine**|Chong Wang et.al.|[2409.00133v1](http://arxiv.org/abs/2409.00133v1)|null|
|**2024-08-27**|**Aligning XAI with EU Regulations for Smart Biomedical Devices: A Methodology for Compliance Analysis**|Francesco Sovrano et.al.|[2408.15121v1](http://arxiv.org/abs/2408.15121v1)|null|
|**2024-08-24**|**Towards Case-based Interpretability for Medical Federated Learning**|Laura Latorre et.al.|[2408.13626v1](http://arxiv.org/abs/2408.13626v1)|null|
|**2024-08-22**|**AI in radiological imaging of soft-tissue and bone tumours: a systematic review evaluating against CLAIM and FUTURE-AI guidelines**|Douwe J. Spaanderman et.al.|[2408.12491v1](http://arxiv.org/abs/2408.12491v1)|null|
|**2024-08-14**|**Evaluating Explainable AI Methods in Deep Learning Models for Early Detection of Cerebral Palsy**|Kimji N. Pellano et.al.|[2409.00001v1](http://arxiv.org/abs/2409.00001v1)|null|
|**2024-08-06**|**MicroXercise: A Micro-Level Comparative and Explainable System for Remote Physical Therapy**|Hanchen David Wang et.al.|[2408.11837v1](http://arxiv.org/abs/2408.11837v1)|null|
|**2024-08-05**|**The Literature Review Network: An Explainable Artificial Intelligence for Systematic Literature Reviews, Meta-analyses, and Method Development**|Joshua Morriss et.al.|[2408.05239v1](http://arxiv.org/abs/2408.05239v1)|null|
|**2024-08-05**|**Enhancing Medical Learning and Reasoning Systems: A Boxology-Based Comparative Analysis of Design Patterns**|Chi Him Ng et.al.|[2408.02709v1](http://arxiv.org/abs/2408.02709v1)|null|
|**2024-08-05**|**Bayesian Kolmogorov Arnold Networks (Bayesian_KANs): A Probabilistic Approach to Enhance Accuracy and Interpretability**|Masoud Muhammed Hassan et.al.|[2408.02706v1](http://arxiv.org/abs/2408.02706v1)|null|
|**2024-07-26**|**MLtoGAI: Semantic Web based with Machine Learning for Enhanced Disease Prediction and Personalized Recommendations using Generative AI**|Shyam Dongre et.al.|[2407.20284v1](http://arxiv.org/abs/2407.20284v1)|null|
|**2024-07-25**|**Introducing Î´-XAI: a novel sensitivity-based method for local AI explanations**|Alessandro De Carlo et.al.|[2407.18343v2](http://arxiv.org/abs/2407.18343v2)|null|
|**2024-07-24**|**Enhanced Deep Learning Methodologies and MRI Selection Techniques for Dementia Diagnosis in the Elderly Population**|Nikolaos Ntampakis et.al.|[2407.17324v2](http://arxiv.org/abs/2407.17324v2)|null|
|**2024-07-24**|**Using Large Language Models to Compare Explainable Models for Smart Home Human Activity Recognition**|Michele Fiori et.al.|[2408.06352v1](http://arxiv.org/abs/2408.06352v1)|null|
|**2024-07-21**|**Explainable AI-based Intrusion Detection System for Industry 5.0: An Overview of the Literature, associated Challenges, the existing Solutions, and Potential Research Directions**|Naseem Khan et.al.|[2408.03335v1](http://arxiv.org/abs/2408.03335v1)|null|
|**2024-07-18**|**A Comparative Study on Automatic Coding of Medical Letters with Explainability**|Jamie Glen et.al.|[2407.13638v1](http://arxiv.org/abs/2407.13638v1)|[link](https://github.com/Glenj01/Medical-Coding)|
|**2024-07-09**|**Explainable AI for Enhancing Efficiency of DL-based Channel Estimation**|Abdul Karim Gizzini et.al.|[2407.07009v1](http://arxiv.org/abs/2407.07009v1)|null|
|**2024-07-07**|**Explainable AI: Comparative Analysis of Normal and Dilated ResNet Models for Fundus Disease Classification**|P. N. Karthikayan et.al.|[2407.05440v2](http://arxiv.org/abs/2407.05440v2)|null|
|**2024-07-03**|**A Survey on Trustworthiness in Foundation Models for Medical Image Analysis**|Congzhen Shi et.al.|[2407.15851v2](http://arxiv.org/abs/2407.15851v2)|null|
|**2024-07-01**|**The Impact of an XAI-Augmented Approach on Binary Classification with Scarce Data**|Ximing Wen et.al.|[2407.06206v1](http://arxiv.org/abs/2407.06206v1)|null|
|**2024-06-28**|**Can GPT-4 Help Detect Quit Vaping Intentions? An Exploration of Automatic Data Annotation Approach**|Sai Krishna Revanth Vuruma et.al.|[2407.00167v1](http://arxiv.org/abs/2407.00167v1)|null|
|**2024-06-25**|**Towards Compositional Interpretability for XAI**|Sean Tull et.al.|[2406.17583v1](http://arxiv.org/abs/2406.17583v1)|null|
|**2024-06-17**|**Slicing Through Bias: Explaining Performance Gaps in Medical Image Analysis using Slice Discovery Methods**|Vincent Olesen et.al.|[2406.12142v2](http://arxiv.org/abs/2406.12142v2)|[link](https://github.com/volesen/slicing-through-bias)|
|**2024-06-11**|**Unlocking the Potential of Metaverse in Innovative and Immersive Digital Health**|Fatemeh Ebrahimzadeh et.al.|[2406.07114v2](http://arxiv.org/abs/2406.07114v2)|null|
|**2024-06-10**|**AI-Driven Predictive Analytics Approach for Early Prognosis of Chronic Kidney Disease Using Ensemble Learning and Explainable AI**|K M Tawsik Jawad et.al.|[2406.06728v1](http://arxiv.org/abs/2406.06728v1)|null|
|**2024-06-10**|**Explainable AI for Mental Disorder Detection via Social Media: A survey and outlook**|Yusif Ibrahimov et.al.|[2406.05984v1](http://arxiv.org/abs/2406.05984v1)|null|
|**2024-06-09**|**Methodology and Real-World Applications of Dynamic Uncertain Causality Graph for Clinical Diagnosis with Explainability and Invariance**|Zhan Zhang et.al.|[2406.05746v1](http://arxiv.org/abs/2406.05746v1)|null|
|**2024-06-07**|**Advancing Histopathology-Based Breast Cancer Diagnosis: Insights into Multi-Modality and Explainability**|Faseela Abdullakutty et.al.|[2406.12897v1](http://arxiv.org/abs/2406.12897v1)|null|
|**2024-06-07**|**Revisiting Attention Weights as Interpretations of Message-Passing Neural Networks**|Yong-Min Shin et.al.|[2406.04612v1](http://arxiv.org/abs/2406.04612v1)|[link](https://github.com/jordan7186/gatt)|
|**2024-06-04**|**Using Explainable AI for EEG-based Reduced Montage Neonatal Seizure Detection**|Dinuka Sandun Udayantha et.al.|[2406.16908v3](http://arxiv.org/abs/2406.16908v3)|[link](https://github.com/dinuka-1999/braineocare)|
|**2024-06-01**|**Breast Cancer Diagnosis: A Comprehensive Exploration of Explainable Artificial Intelligence (XAI) Techniques**|Samita Bai et.al.|[2406.00532v1](http://arxiv.org/abs/2406.00532v1)|null|
|**2024-06-01**|**Unveiling Hidden Factors: Explainable AI for Feature Boosting in Speech Emotion Recognition**|Alaa Nfissi et.al.|[2406.01624v2](http://arxiv.org/abs/2406.01624v2)|[link](https://github.com/alaanfissi/unveiling-hidden-factors-explainable-ai-for-feature-boosting-in-speech-emotion-recognition)|
|**2024-05-31**|**The Explanation Necessity for Healthcare AI**|Michail Mamalakis et.al.|[2406.00216v1](http://arxiv.org/abs/2406.00216v1)|null|
|**2024-05-29**|**Interdisciplinary Expertise to Advance Equitable Explainable AI**|Chloe R. Bennett et.al.|[2406.18563v1](http://arxiv.org/abs/2406.18563v1)|null|
|**2024-05-27**|**"It depends": Configuring AI to Improve Clinical Usefulness Across Contexts**|Hubert D. ZajÄc et.al.|[2407.11978v1](http://arxiv.org/abs/2407.11978v1)|null|
|**2024-05-26**|**Improving Health Professionals' Onboarding with AI and XAI for Trustworthy Human-AI Collaborative Decision Making**|Min Hun Lee et.al.|[2405.16424v1](http://arxiv.org/abs/2405.16424v1)|null|
|**2024-05-26**|**Exploring Nutritional Impact on Alzheimer's Mortality: An Explainable AI Approach**|Ziming Liu et.al.|[2405.17502v1](http://arxiv.org/abs/2405.17502v1)|null|
|**2024-05-24**|**Explainable AI Enhances Glaucoma Referrals, Yet the Human-AI Team Still Falls Short of the AI Alone**|Catalina Gomez et.al.|[2407.11974v1](http://arxiv.org/abs/2407.11974v1)|null|
|**2024-05-23**|**Decoding Decision Reasoning: A Counterfactual-Powered Model for Knowledge Discovery**|Yingying Fang et.al.|[2406.18552v1](http://arxiv.org/abs/2406.18552v1)|null|
|**2024-05-21**|**The Role of Emotions in Informational Support Question-Response Pairs in Online Health Communities: A Multimodal Deep Learning Approach**|Mohsen Jozani et.al.|[2405.13099v1](http://arxiv.org/abs/2405.13099v1)|null|
|**2024-05-17**|**ChatGPT in Classrooms: Transforming Challenges into Opportunities in Education**|Harris Bin Munawar et.al.|[2405.10645v1](http://arxiv.org/abs/2405.10645v1)|null|
|**2024-05-13**|**Evaluating the Explainable AI Method Grad-CAM for Breath Classification on Newborn Time Series Data**|Camelia Oprea et.al.|[2405.07590v1](http://arxiv.org/abs/2405.07590v1)|null|
|**2024-05-10**|**XAI4LLM. Let Machine Learning Models and LLMs Collaborate for Enhanced In-Context Learning in Healthcare**|Fatemeh Nazary et.al.|[2405.06270v3](http://arxiv.org/abs/2405.06270v3)|null|
|**2024-05-09**|**To Trust or Not to Trust: Towards a novel approach to measure trust for XAI systems**|Miquel MirÃ³-Nicolau et.al.|[2405.05766v1](http://arxiv.org/abs/2405.05766v1)|null|
|**2024-05-05**|**Region-specific Risk Quantification for Interpretable Prognosis of COVID-19**|Zhusi Zhong et.al.|[2405.02815v1](http://arxiv.org/abs/2405.02815v1)|[link](https://github.com/zzs95/RSP_COVID)|
|**2024-04-26**|**Rad4XCNN: a new agnostic method for post-hoc global explanation of CNN-derived features by means of radiomics**|Francesco Prinzi et.al.|[2405.02334v1](http://arxiv.org/abs/2405.02334v1)|null|
|**2024-04-25**|**Attributing Responsibility in AI-Induced Incidents: A Computational Reflective Equilibrium Framework for Accountability**|Yunfei Ge et.al.|[2404.16957v1](http://arxiv.org/abs/2404.16957v1)|null|
|**2024-04-19**|**Explainable AI for Fair Sepsis Mortality Predictive Model**|Chia-Hsuan Chang et.al.|[2404.13139v1](http://arxiv.org/abs/2404.13139v1)|null|
|**2024-04-19**|**Multi Class Depression Detection Through Tweets using Artificial Intelligence**|Muhammad Osama Nusrat et.al.|[2404.13104v1](http://arxiv.org/abs/2404.13104v1)|[link](https://github.com/mnusrat786/masters-thesis)|
|**2024-04-19**|**COIN: Counterfactual inpainting for weakly supervised semantic segmentation for medical images**|Dmytro Shvetsov et.al.|[2404.12832v2](http://arxiv.org/abs/2404.12832v2)|[link](https://github.com/dmytro-shvetsov/counterfactual-search)|
|**2024-04-15**|**Hybrid Intelligence for Digital Humanities**|Victor de Boer et.al.|[2406.15374v1](http://arxiv.org/abs/2406.15374v1)|null|
|**2024-04-14**|**Ethical Framework for Responsible Foundational Models in Medical Imaging**|Abhijit Das et.al.|[2406.11868v1](http://arxiv.org/abs/2406.11868v1)|null|
|**2024-04-09**|**Advancements in Radiomics and Artificial Intelligence for Thyroid Cancer Diagnosis**|Milad Yousefi et.al.|[2404.07239v1](http://arxiv.org/abs/2404.07239v1)|null|
|**2024-04-06**|**Predictive Modeling for Breast Cancer Classification in the Context of Bangladeshi Patients: A Supervised Machine Learning Approach with Explainable AI**|Taminul Islam et.al.|[2404.04686v1](http://arxiv.org/abs/2404.04686v1)|null|
|**2024-04-05**|**Enhancing Breast Cancer Diagnosis in Mammography: Evaluation and Integration of Convolutional Neural Networks and Explainable AI**|Maryam Ahmed et.al.|[2404.03892v3](http://arxiv.org/abs/2404.03892v3)|null|
|**2024-03-30**|**Advancing Multimodal Data Fusion in Pain Recognition: A Strategy Leveraging Statistical Correlation and Human-Centered Perspectives**|Xingrui Gu et.al.|[2404.00320v2](http://arxiv.org/abs/2404.00320v2)|null|
|**2024-03-26**|**Addressing Social Misattributions of Large Language Models: An HCXAI-based Approach**|Andrea Ferrario et.al.|[2403.17873v1](http://arxiv.org/abs/2403.17873v1)|null|
|**2024-03-26**|**Clinical Domain Knowledge-Derived Template Improves Post Hoc AI Explanations in Pneumothorax Classification**|Han Yuan et.al.|[2403.18871v1](http://arxiv.org/abs/2403.18871v1)|[link](https://github.com/han-yuan-med/template-explanation)|
|**2024-03-03**|**Enhancing Neural Machine Translation of Low-Resource Languages: Corpus Development, Human Evaluation and Explainable AI Architectures**|SÃ©amus Lankford et.al.|[2403.01580v1](http://arxiv.org/abs/2403.01580v1)|null|
|**2024-02-28**|**Cause and Effect: Can Large Language Models Truly Understand Causality?**|Swagata Ashwani et.al.|[2402.18139v3](http://arxiv.org/abs/2402.18139v3)|null|
|**2024-02-28**|**Artificial Intelligence and Diabetes Mellitus: An Inside Look Through the Retina**|Yasin Sadeghi Bazargani et.al.|[2402.18600v1](http://arxiv.org/abs/2402.18600v1)|null|
|**2024-02-22**|**Multi-stakeholder Perspective on Responsible Artificial Intelligence and Acceptability in Education**|A. J. Karran et.al.|[2402.15027v2](http://arxiv.org/abs/2402.15027v2)|null|
|**2024-02-12**|**Deciphering Heartbeat Signatures: A Vision Transformer Approach to Explainable Atrial Fibrillation Detection from ECG Signals**|Aruna Mohan et.al.|[2402.09474v2](http://arxiv.org/abs/2402.09474v2)|null|
|**2024-02-05**|**Illuminate: A novel approach for depression detection with explainable analysis and proactive therapy using prompt engineering**|Aryan Agrawal et.al.|[2402.05127v1](http://arxiv.org/abs/2402.05127v1)|null|
|**2024-01-24**|**Information That Matters: Exploring Information Needs of People Affected by Algorithmic Decisions**|TimothÃ©e Schmude et.al.|[2401.13324v6](http://arxiv.org/abs/2401.13324v6)|null|
|**2024-01-02**|**Evaluating Large Language Models on the GMAT: Implications for the Future of Business Education**|Vahid Ashrafimoghari et.al.|[2401.02985v1](http://arxiv.org/abs/2401.02985v1)|null|
|**2023-12-29**|**XAI for In-hospital Mortality Prediction via Multimodal ICU Data**|Xingqiao Li et.al.|[2312.17624v1](http://arxiv.org/abs/2312.17624v1)|[link](https://github.com/lixingqiao/xai-icu)|
|**2023-12-22**|**Joining Forces for Pathology Diagnostics with AI Assistance: The EMPAIA Initiative**|Norman Zerbe et.al.|[2401.09450v2](http://arxiv.org/abs/2401.09450v2)|null|
|**2023-12-18**|**Robust Stochastic Graph Generator for Counterfactual Explanations**|Mario Alfonso Prado-Romero et.al.|[2312.11747v2](http://arxiv.org/abs/2312.11747v2)|null|
|**2023-12-10**|**Evaluating the Utility of Model Explanations for Model Development**|Shawn Im et.al.|[2312.06032v1](http://arxiv.org/abs/2312.06032v1)|null|
|**2023-12-05**|**Building Trustworthy NeuroSymbolic AI Systems: Consistency, Reliability, Explainability, and Safety**|Manas Gaur et.al.|[2312.06798v1](http://arxiv.org/abs/2312.06798v1)|null|
|**2023-12-04**|**Class-Discriminative Attention Maps for Vision Transformers**|Lennart Brocki et.al.|[2312.02364v3](http://arxiv.org/abs/2312.02364v3)|null|
|**2023-11-28**|**Deployment of a Robust and Explainable Mortality Prediction Model: The COVID-19 Pandemic and Beyond**|Jacob R. Epifano et.al.|[2311.17133v1](http://arxiv.org/abs/2311.17133v1)|null|
|**2023-11-27**|**Variational Autoencoders for Feature Exploration and Malignancy Prediction of Lung Lesions**|Benjamin Keel et.al.|[2311.15719v1](http://arxiv.org/abs/2311.15719v1)|[link](https://github.com/benkeel/vae_lung_lesion_bmvc)|
|**2023-11-24**|**MRxaI: Black-Box Explainability for Image Classifiers in a Medical Setting**|Nathan Blake et.al.|[2311.14471v1](http://arxiv.org/abs/2311.14471v1)|null|
|**2023-11-21**|**Moderating Model Marketplaces: Platform Governance Puzzles for AI Intermediaries**|Robert Gorwa et.al.|[2311.12573v3](http://arxiv.org/abs/2311.12573v3)|null|
|**2023-11-20**|**Ovarian Cancer Data Analysis using Deep Learning: A Systematic Review from the Perspectives of Key Features of Data Analysis and AI Assurance**|Muta Tah Hira et.al.|[2311.11932v1](http://arxiv.org/abs/2311.11932v1)|null|
|**2023-11-18**|**Representing visual classification as a linear combination of words**|Shobhit Agarwal et.al.|[2311.10933v1](http://arxiv.org/abs/2311.10933v1)|[link](https://github.com/lotterlab/task_word_explainability)|

#### Abstracts
##### **2-Factor Retrieval for Improved Human-AI Decision Making in Radiology**
2412.00372v1 by Jim Solomon, Laleh Jalilian, Alexander Vilesov, Meryl Mathew, Tristan Grogan, Arash Bedayat, Achuta Kadambi

Human-machine teaming in medical AI requires us to understand to what degree
a trained clinician should weigh AI predictions. While previous work has shown
the potential of AI assistance at improving clinical predictions, existing
clinical decision support systems either provide no explainability of their
predictions or use techniques like saliency and Shapley values, which do not
allow for physician-based verification. To address this gap, this study
compares previously used explainable AI techniques with a newly proposed
technique termed '2-factor retrieval (2FR)', which is a combination of
interface design and search retrieval that returns similarly labeled data
without processing this data. This results in a 2-factor security blanket
where: (a) correct images need to be retrieved by the AI; and (b) humans should
associate the retrieved images with the current pathology under test. We find
that when tested on chest X-ray diagnoses, 2FR leads to increases in clinician
accuracy, with particular improvements when clinicians are radiologists and
have low confidence in their decision. Our results highlight the importance of
understanding how different modes of human-AI decision making may impact
clinician accuracy in clinical decision support systems.

æè¦ï¼äººæ©åä½å¨é«ç AI ä¸­ï¼éè¦æåçè§£åéè¨ç·´çè¨åºé«çå¨å¤å¤§ç¨åº¦ä¸æéè¦ AI é æ¸¬ãéç¶ååçç ç©¶é¡¯ç¤º AI è¼å©å¨æ¹åè¨åºé æ¸¬æ¹é¢çæ½åï¼ä½ç¾æçè¨åºæ±ºç­æ¯æ´ç³»çµ±ï¼è¦ä¸å°±æ²ææä¾é æ¸¬çå¯è§£éæ§ï¼è¦ä¸å°±æ¯ä½¿ç¨åé¡¯èæ§å Shapley å¼ä¹é¡çæè¡ï¼éäºæè¡ä¸åè¨±åºæ¼é«ççé©è­ãçºäºè§£æ±ºéåå·®è·ï¼æ¬ç ç©¶å°ååä½¿ç¨çå¯è§£é AI æè¡èä¸ç¨®æ°æåºçç¨±çºã2 å å­æª¢ç´¢ (2FR)ãçæè¡é²è¡æ¯è¼ï¼å¾èæ¯ä¸ç¨®ä»é¢è¨­è¨åæå°æª¢ç´¢ççµåï¼å®æå³åæ¨ç±¤ç¸ä¼¼çè³æï¼èä¸æèçéäºè³æãéæç¢çä¸å 2 å å­å®å¨æ©å¶ï¼å¶ä¸­ï¼(a) æ­£ç¢ºçå½±åéè¦ç± AI æª¢ç´¢ï¼(b) äººé¡æå°æª¢ç´¢çå½±åèæ­£å¨æ¸¬è©¦ä¸­çççè¯æ³èµ·ä¾ãæåç¼ç¾ï¼ç¶å¨è¸é¨ X åè¨ºæ·ä¸é²è¡æ¸¬è©¦æï¼2FR ææé«è¨åºé«ççæºç¢ºåº¦ï¼ç¹å¥æ¯å¨è¨åºé«çæ¯æ¾å°ç§é«çä¸å°å¶æ±ºç­ä¿¡å¿ä¸è¶³æï¼ææé¡¯èçæ¹åãæåççµæå¼·èª¿äºçè§£äººæ©æ±ºç­çä¸åæ¨¡å¼å¦ä½å½±é¿è¨åºé«çå¨è¨åºæ±ºç­æ¯æ´ç³»çµ±ä¸­çæºç¢ºæ§çéè¦æ§ã

##### **Mapping Public Perception of Artificial Intelligence: Expectations, Risk-Benefit Tradeoffs, and Value As Determinants for Societal Acceptance**
2411.19356v1 by Philipp Brauner, Felix Glawe, Gian Luca Liehner, Luisa Vervier, Martina Ziefle

Understanding public perception of artificial intelligence (AI) and the
tradeoffs between potential risks and benefits is crucial, as these perceptions
might shape policy decisions, influence innovation trajectories for successful
market strategies, and determine individual and societal acceptance of AI
technologies. Using a representative sample of 1100 participants from Germany,
this study examines mental models of AI. Participants quantitatively evaluated
71 statements about AI's future capabilities (e.g., autonomous driving, medical
care, art, politics, warfare, and societal divides), assessing the expected
likelihood of occurrence, perceived risks, benefits, and overall value. We
present rankings of these projections alongside visual mappings illustrating
public risk-benefit tradeoffs. While many scenarios were deemed likely,
participants often associated them with high risks, limited benefits, and low
overall value. Across all scenarios, 96.4% ($r^2=96.4\%$) of the variance in
value assessment can be explained by perceived risks ($\beta=-.504$) and
perceived benefits ($\beta=+.710$), with no significant relation to expected
likelihood. Demographics and personality traits influenced perceptions of
risks, benefits, and overall evaluations, underscoring the importance of
increasing AI literacy and tailoring public information to diverse user needs.
These findings provide actionable insights for researchers, developers, and
policymakers by highlighting critical public concerns and individual factors
essential to align AI development with individual values.

æè¦ï¼<paragraph>äºè§£å¬ç¾å°äººå·¥æºæ§ (AI) çèªç¥ä»¥åæ½å¨é¢¨éªèå¥½èä¹éçæ¬è¡¡è³ééè¦ï¼å çºéäºèªç¥å¯è½æå½±é¿æ¿ç­æ±ºç­ãå½±é¿æåå¸å ´ç­ç¥çåµæ°è»è·¡ï¼ä¸¦æ±ºå®åäººåç¤¾æå° AI æè¡çæ¥ååº¦ãæ¬ç ç©¶ä½¿ç¨ä¾èªå¾·åç 1100 ååèèçä»£è¡¨æ§æ¨£æ¬ï¼æ¢è¨äº AI çå¿æºæ¨¡åãåèèå° 71 é éæ¼ AI æªä¾è½åçé³è¿°ï¼ä¾å¦ï¼èªåé§é§ãé«çä¿å¥ãèè¡ãæ¿æ²»ãæ°ç­åç¤¾æåæ­§ï¼é²è¡äºå®éè©ä¼°ï¼è©ä¼°é æçç¼çå¯è½æ§ãæç¥é¢¨éªãå¥½èåæ´é«å¹å¼ãæåå±ç¤ºäºéäºé æ¸¬çæåï¼ä¸¦éä¸è¦è¦ºåæ å°ï¼èªªæäºå¬ç¾çé¢¨éªæ¶çæ¬è¡¡ãåç®¡è¨±å¤å ´æ¯è¢«èªçºæ¯å¯è½çï¼ä½åèèéå¸¸å°å®åèé«é¢¨éªãæéçå¥½èåä½æ´é«å¹å¼è¯ç¹«èµ·ä¾ãå¨ææå ´æ¯ä¸­ï¼96.4% ($r^2=96.4\%$) çå¹å¼è©ä¼°å·®ç°å¯ä»¥ç¨æç¥é¢¨éª ($\beta=-.504$) åæç¥å¥½è ($\beta=+.710$) ä¾è§£éï¼èé æçå¯è½æ§æ²æé¡¯èéä¿ãäººå£çµ±è¨åäººæ ¼ç¹è³ªå½±é¿äºå°é¢¨éªãå¥½èåæ´é«è©ä¼°ççæ³ï¼éå¸é¡¯äºæé« AI ç´ é¤åæ ¹æä¸åçä½¿ç¨èéæ±èª¿æ´å¬å±è³è¨çéè¦æ§ãéäºç¼ç¾ééå¼·èª¿ééµçå¬å±éæ³¨åèåäººå¹å¼è§ä¸è´ç AI éç¼å¿ä¸å¯å°çåäººå ç´ ï¼çºç ç©¶äººå¡ãéç¼äººå¡åæ¿ç­å¶å®èæä¾äºå¯è¡çè¦è§£ã</paragraph>

##### **Explainable AI for Classifying UTI Risk Groups Using a Real-World Linked EHR and Pathology Lab Dataset**
2411.17645v1 by Yujie Dai, Brian Sullivan, Axel Montout, Amy Dillon, Chris Waller, Peter Acs, Rachel Denholm, Philip Williams, Alastair D Hay, Raul Santos-Rodriguez, Andrew Dowsey

The use of machine learning and AI on electronic health records (EHRs) holds
substantial potential for clinical insight. However, this approach faces
significant challenges due to data heterogeneity, sparsity, temporal
misalignment, and limited labeled outcomes. In this context, we leverage a
linked EHR dataset of approximately one million de-identified individuals from
Bristol, North Somerset, and South Gloucestershire, UK, to characterize urinary
tract infections (UTIs) and develop predictive models focused on data quality,
fairness and transparency. A comprehensive data pre-processing and curation
pipeline transforms the raw EHR data into a structured format suitable for AI
modeling. Given the limited availability and biases of ground truth UTI
outcomes, we introduce a UTI risk estimation framework informed by clinical
expertise to estimate UTI risk across individual patient timelines. Using this
framework, we built pairwise XGBoost models to differentiate UTI risk
categories with explainable AI techniques to identify key predictors while
ensuring interpretability. Our findings reveal differences in clinical and
demographic factors across risk groups, offering insights into UTI risk
stratification and progression. This study demonstrates the added value of
AI-driven insights into UTI clinical decision-making while prioritizing
interpretability, transparency, and fairness, underscoring the importance of
sound data practices in advancing health outcomes.

æè¦ï¼æ©å¨å­¸ç¿åäººå·¥æºæ§å¨é»å­å¥åº·ç´é (EHR) ä¸çæç¨å·æ
è¨åºè¦è§£çå·¨å¤§æ½åãç¶èï¼éç¨®æ¹æ³ç±æ¼è³æç°è³ªæ§ãç¨çæ§ãæéé¯ä½åæ¨è¨çµææéï¼å æ­¤é¢è¨éå¤§ææ°ãå¨æ­¤èæ¯ä¸ï¼æåå©ç¨ä¾èªè±åå¸éæ¯æãåè©é»å¡ç¹é¡ååæ ¼æ´æ¯ç¹é¡çå¤§ç´ä¸ç¾è¬åå»è­å¥ååäººçé£çµå¼ EHR è³æéï¼ä»¥æè¿°æ³å°¿éææ (UTI) ä¸¦éç¼å°æ³¨æ¼è³æåè³ªãå¬å¹³æ§åéæåº¦çé æ¸¬æ¨¡åãå¨é¢çè³æåèçåæ´çç®¡éå°åå§ EHR è³æè½æçºé©å AI å»ºæ¨¡ççµæ§åæ ¼å¼ãéæ¼å¯¦é UTI çµæçå¯ç¨æ§æéååè¦ï¼æåå¼å¥äºä¸åç±è¨åºå°æ¥­ç¥è­æä¾è³è¨ç UTI é¢¨éªè©ä¼°æ¶æ§ï¼ä»¥ä¼°è¨åäººæ£èæéç·ä¸ç UTI é¢¨éªãä½¿ç¨æ­¤æ¶æ§ï¼æåå»ºç«äºæå°ç XGBoost æ¨¡åï¼ä»¥åå UTI é¢¨éªé¡å¥ï¼ä¸¦ä½¿ç¨å¯è§£éç AI æè¡ä¾è­å¥ééµé æ¸¬å å­ï¼åæç¢ºä¿å¯è§£éæ§ãæåçç ç©¶çµææ­ç¤ºäºä¸åé¢¨éªç¾¤çµçè¨åºåäººå£çµ±è¨å ç´ çå·®ç°ï¼æä¾äºå° UTI é¢¨éªåå±¤åé²å±çè¦è§£ãæ¬ç ç©¶å±ç¤ºäº AI é©åçè¦è§£å¨ UTI è¨åºæ±ºç­ä¸­çéå å¹å¼ï¼åæåªåèæ®å¯è§£éæ§ãéæåº¦åå¬å¹³æ§ï¼å¼·èª¿äºå¥å¨è³æå¯¦åå¨ä¿é²å¥åº·çµæä¸­çéè¦æ§ã

##### **Exploring the Requirements of Clinicians for Explainable AI Decision Support Systems in Intensive Care**
2411.11774v1 by Jeffrey N. Clark, Matthew Wragg, Emily Nielsen, Miquel Perello-Nieto, Nawid Keshtmand, Michael Ambler, Shiv Sharma, Christopher P. Bourdeaux, Amberly Brigden, Raul Santos-Rodriguez

There is a growing need to understand how digital systems can support
clinical decision-making, particularly as artificial intelligence (AI) models
become increasingly complex and less human-interpretable. This complexity
raises concerns about trustworthiness, impacting safe and effective adoption of
such technologies. Improved understanding of decision-making processes and
requirements for explanations coming from decision support tools is a vital
component in providing effective explainable solutions. This is particularly
relevant in the data-intensive, fast-paced environments of intensive care units
(ICUs). To explore these issues, group interviews were conducted with seven ICU
clinicians, representing various roles and experience levels. Thematic analysis
revealed three core themes: (T1) ICU decision-making relies on a wide range of
factors, (T2) the complexity of patient state is challenging for shared
decision-making, and (T3) requirements and capabilities of AI decision support
systems. We include design recommendations from clinical input, providing
insights to inform future AI systems for intensive care.

æè¦ï¼é¨èäººå·¥æºæ§ (AI) æ¨¡åè®å¾è¶ä¾è¶è¤éï¼ä¸è¶ä¾è¶é£ä»¥è¢«äººçè§£ï¼äºè§£æ¸ä½ç³»çµ±å¦ä½æ¯æ´è¨åºæ±ºç­çéæ±ä¹æ¥çå¢å ãéç¨®è¤éæ§å¼ç¼äºå°å¯ä¿¡åº¦ççæ®ï¼å½±é¿äºæ­¤é¡æè¡çå®å¨ä¸æææ¡ç¨ãæ¹åå°æ±ºç­å¶å®æµç¨ççè§£ï¼ä»¥åå°æ±ºç­æ¯æ´å·¥å·ææä¾èªªæçè¦æ±ï¼æ¯æä¾ææå¯è§£éè§£æ±ºæ¹æ¡çéè¦çµæé¨åãéå¨è³æå¯éãå¿«ç¯å¥çå è­·çæ¿ (ICU) ç°å¢ä¸­ç¹å¥ç¸éãçºäºæ¢è¨éäºåé¡ï¼å°ä¸ä½ ICU è¨åºé«å¸«é²è¡äºå°çµè¨ªè«ï¼éäºé«å¸«ä»£è¡¨äºä¸åçè§è²åç¶é©å±¤ç´ãä¸»é¡åææ­é²äºä¸åæ ¸å¿ä¸»é¡ï¼(T1) ICU æ±ºç­å¶å®ä¾è³´æ¼å»£æ³çå ç´ ï¼(T2) çæ£çæçè¤éæ§å°å±åæ±ºç­å¶å®æ§æææ°ï¼ä»¥å (T3) AI æ±ºç­æ¯æ´ç³»çµ±çè¦æ±åè½åãæåç´å¥äºè¨åºè¼¸å¥çè¨­è¨å»ºè­°ï¼æä¾è¦è§£ä»¥æä¾è³è¨çµ¦æªä¾ç¨æ¼å è­·ç AI ç³»çµ±ã

##### **Artificial Intelligence in Pediatric Echocardiography: Exploring Challenges, Opportunities, and Clinical Applications with Explainable AI and Federated Learning**
2411.10255v1 by Mohammed Yaseen Jabarulla, Theodor Uden, Thomas Jack, Philipp Beerbaum, Steffen Oeltze-Jafra

Pediatric heart diseases present a broad spectrum of congenital and acquired
diseases. More complex congenital malformations require a differentiated and
multimodal decision-making process, usually including echocardiography as a
central imaging method. Artificial intelligence (AI) offers considerable
promise for clinicians by facilitating automated interpretation of pediatric
echocardiography data. However, adapting AI technologies for pediatric
echocardiography analysis has challenges such as limited public data
availability, data privacy, and AI model transparency. Recently, researchers
have focused on disruptive technologies, such as federated learning (FL) and
explainable AI (XAI), to improve automatic diagnostic and decision support
workflows. This study offers a comprehensive overview of the limitations and
opportunities of AI in pediatric echocardiography, emphasizing the synergistic
workflow and role of XAI and FL, identifying research gaps, and exploring
potential future developments. Additionally, three relevant clinical use cases
demonstrate the functionality of XAI and FL with a focus on (i) view
recognition, (ii) disease classification, (iii) segmentation of cardiac
structures, and (iv) quantitative assessment of cardiac function.

æè¦ï¼å°åå¿èç¾çåç¾åå¤©æ§èå¾å¤©æ§ç¾ççå»£æ³åè­ãè¼è¤éçåå¤©æ§ç¸å½¢éè¦ä¸åå·®ç°åä¸å¤æ¨¡å¼çæ±ºç­éç¨ï¼éå¸¸åæ¬è¶é³æ³¢æª¢æ¥ä½çºä¸»è¦çå½±åæ¹æ³ãäººå·¥æºæ§ (AI) çºè¨åºé«çæä¾äºç¸ç¶å¤§çå¸æï¼å çºå®å¯ä»¥ä¿é²å°åè¶é³æ³¢æª¢æ¥è³æçèªååè§£è®ãç¶èï¼å°äººå·¥æºæ§æè¡æç¨æ¼å°åè¶é³æ³¢æª¢æ¥åææè¨±å¤ææ°ï¼ä¾å¦æéçå¬éè³æå¯ç¨æ§ãè³æé±ç§åäººå·¥æºæ§æ¨¡åéæåº¦ãæè¿ï¼ç ç©¶äººå¡å°æ³¨æ¼ç ´å£æ§æè¡ï¼ä¾å¦è¯åå­¸ç¿ (FL) åå¯è§£éäººå·¥æºæ§ (XAI)ï¼ä»¥æ¹åèªåè¨ºæ·åæ±ºç­æ¯æ´å·¥ä½æµç¨ãæ¬ç ç©¶æä¾äºäººå·¥æºæ§å¨å°åè¶é³æ³¢æª¢æ¥ä¸­çéå¶åæ©æçå¨é¢æ¦è¿°ï¼å¼·èª¿äº XAI å FL çååå·¥ä½æµç¨åè§è²ï¼æ¾åºç ç©¶å·®è·ä¸¦æ¢è¨æ½å¨çæªä¾ç¼å±ãæ­¤å¤ï¼ä¸åç¸éçè¨åºä½¿ç¨æ¡ä¾å±ç¤ºäº XAI å FL çåè½ï¼éé»å¨æ¼ (i) æª¢è¦è¾¨è­ã(ii) ç¾çåé¡ã(iii) å¿èçµæ§åå²å (iv) å¿èåè½çéåè©ä¼°ã

##### **Enhancing Osteoporosis Detection: An Explainable Multi-Modal Learning Framework with Feature Fusion and Variable Clustering**
2411.00916v2 by Mehdi Hosseini Chagahi, Saeed Mohammadi Dashtaki, Niloufar Delfan, Nadia Mohammadi, Alireza Samari, Behzad Moshiri, Md. Jalil Piran, Oliver Faust

Osteoporosis is a common condition that increases fracture risk, especially
in older adults. Early diagnosis is vital for preventing fractures, reducing
treatment costs, and preserving mobility. However, healthcare providers face
challenges like limited labeled data and difficulties in processing medical
images. This study presents a novel multi-modal learning framework that
integrates clinical and imaging data to improve diagnostic accuracy and model
interpretability. The model utilizes three pre-trained networks-VGG19,
InceptionV3, and ResNet50-to extract deep features from X-ray images. These
features are transformed using PCA to reduce dimensionality and focus on the
most relevant components. A clustering-based selection process identifies the
most representative components, which are then combined with preprocessed
clinical data and processed through a fully connected network (FCN) for final
classification. A feature importance plot highlights key variables, showing
that Medical History, BMI, and Height were the main contributors, emphasizing
the significance of patient-specific data. While imaging features were
valuable, they had lower importance, indicating that clinical data are crucial
for accurate predictions. This framework promotes precise and interpretable
predictions, enhancing transparency and building trust in AI-driven diagnoses
for clinical integration.

æè¦ï¼éª¨è³ªçé¬çæ¯ä¸ç¨®å¸¸è¦çç¾çï¼æå¢å éª¨æçé¢¨éªï¼ç¹å¥æ¯èå¹´äººãæ©æè¨ºæ·å°æ¼é é²éª¨æãéä½æ²»çææ¬åç¶­æè¡åè½åè³ééè¦ãç¶èï¼é«çä¿å¥æä¾èé¢è¨èæ¨è¨æ¸ææéåèçé«å­¸å½±åå°é£ç­ææ°ãæ¬ç ç©¶æåºäºä¸åæ°ç©çå¤æ¨¡å¼å­¸ç¿æ¡æ¶ï¼è©²æ¡æ¶æ´åäºè¨åºåå½±åæ¸æï¼ä»¥æé«è¨ºæ·æºç¢ºæ§åæ¨¡åå¯è§£éæ§ãè©²æ¨¡åå©ç¨ä¸åé è¨ç·´çç¶²è·¯ï¼VGG19ãInceptionV3 å ResNet50ï¼å¾ X å°ç·å½±åä¸­æåæ·±åº¦ç¹å¾µãéäºç¹å¾µä½¿ç¨ PCA è½æä»¥éä½ç¶­åº¦ä¸¦å°æ³¨æ¼æç¸éççµæé¨åãåºæ¼èé¡çé¸æéç¨è­å¥åºæå·ä»£è¡¨æ§ççµæé¨åï¼ç¶å¾å°éäºçµæé¨åèé èççè¨åºæ¸æçµåï¼ä¸¦ééå¨é£æ¥ç¶²è·¯ (FCN) é²è¡æçµåé¡ãç¹å¾µéè¦æ§åçªåºäºééµè®æ¸ï¼è¡¨æçå²ãBMI åèº«é«æ¯ä¸»è¦è²¢ç»å ç´ ï¼å¼·èª¿äºæ£èç¹å®æ¸æçéè¦æ§ãéç¶å½±åç¹å¾µå¾æå¹å¼ï¼ä½å®åçéè¦æ§è¼ä½ï¼éè¡¨æè¨åºæ¸æå°æ¼æºç¢ºé æ¸¬è³ééè¦ãæ­¤æ¡æ¶ä¿è¿äºæºç¢ºä¸å¯è§£éçé æ¸¬ï¼æé«äºéæåº¦ï¼ä¸¦å»ºç«äºå° AI é©åè¨ºæ·å¨è¨åºæ´åä¸­çä¿¡ä»»ã

##### **A Review of Deep Learning Approaches for Non-Invasive Cognitive Impairment Detection**
2410.19898v1 by Muath Alsuhaibani, Ali Pourramezan Fard, Jian Sun, Farida Far Poor, Peter S. Pressman, Mohammad H. Mahoor

This review paper explores recent advances in deep learning approaches for
non-invasive cognitive impairment detection. We examine various non-invasive
indicators of cognitive decline, including speech and language, facial, and
motoric mobility. The paper provides an overview of relevant datasets,
feature-extracting techniques, and deep-learning architectures applied to this
domain. We have analyzed the performance of different methods across modalities
and observed that speech and language-based methods generally achieved the
highest detection performance. Studies combining acoustic and linguistic
features tended to outperform those using a single modality. Facial analysis
methods showed promise for visual modalities but were less extensively studied.
Most papers focused on binary classification (impaired vs. non-impaired), with
fewer addressing multi-class or regression tasks. Transfer learning and
pre-trained language models emerged as popular and effective techniques,
especially for linguistic analysis. Despite significant progress, several
challenges remain, including data standardization and accessibility, model
explainability, longitudinal analysis limitations, and clinical adaptation.
Lastly, we propose future research directions, such as investigating
language-agnostic speech analysis methods, developing multi-modal diagnostic
systems, and addressing ethical considerations in AI-assisted healthcare. By
synthesizing current trends and identifying key obstacles, this review aims to
guide further development of deep learning-based cognitive impairment detection
systems to improve early diagnosis and ultimately patient outcomes.

æè¦ï¼æ¬ç¯è©è«æ¢è¨äºæ·±åº¦å­¸ç¿æ¹æ³å¨éä¾µå¥å¼èªç¥åè½éç¤æª¢æ¸¬ä¸çææ°é²å±ãæåæª¢è¦äºåç¨®éä¾µå¥å¼çèªç¥è¡°éææ¨ï¼åæ¬èªè¨åèªè¨ãé¢é¨åéåæ©è½ãæ¬ææ¦è¿°äºèæ­¤é åç¸éçè³æéãç¹å¾µæåæè¡åæ·±åº¦å­¸ç¿æ¶æ§ãæååæäºä¸åæ¹æ³å¨ä¸åæ¹å¼ä¸çè¡¨ç¾ï¼ä¸¦è§å¯å°åºæ¼èªè¨åèªè¨çæ¹æ³éå¸¸è½éå°æé«çæª¢æ¸¬è¡¨ç¾ãçµåè²å­¸åèªè¨ç¹å¾µçç ç©¶å¾å¾åªæ¼ä½¿ç¨å®ä¸æ¹å¼çç ç©¶ãé¢é¨åææ¹æ³é¡¯ç¤ºåºè¦è¦ºæ¹å¼çæ½åï¼ä½ç ç©¶è¼å°ãå¤§å¤æ¸è«æå°æ³¨æ¼äºååé¡ï¼åæèæªåæï¼ï¼è¼å°æ¢è¨å¤é¡æåæ­¸ä»»åãé·ç§»å­¸ç¿åé è¨ç·´èªè¨æ¨¡åå·²æçºæµè¡ä¸ææçæè¡ï¼ç¹å¥æ¯å°æ¼èªè¨åæãåç®¡åå¾äºéå¤§é²å±ï¼ä½ä»å­å¨ä¸äºææ°ï¼åæ¬è³ææ¨æºååå¯åæ§ãæ¨¡åå¯è§£éæ§ãç¸±ååæéå¶åè¨åºé©ææ§ãæå¾ï¼æåæåºäºæªä¾çç ç©¶æ¹åï¼ä¾å¦èª¿æ¥èèªè¨ç¡éçèªé³åææ¹æ³ãéç¼å¤æ¨¡å¼è¨ºæ·ç³»çµ±ï¼ä»¥åè§£æ±ºäººå·¥æºæ§è¼å©é«çä¿å¥ä¸­çå«çèéãééç¶åç®åçè¶¨å¢åæ¾åºééµéç¤ï¼æ¬ç¯è©è«æ¨å¨å¼å°æ·±åº¦å­¸ç¿çºåºç¤çèªç¥åè½éç¤æª¢æ¸¬ç³»çµ±çé²ä¸æ­¥ç¼å±ï¼ä»¥æ¹åæ©æè¨ºæ·ï¼ä¸¦æçµæ¹åæ£èçæ²»ççµæã

##### **An Ontology-Enabled Approach For User-Centered and Knowledge-Enabled Explanations of AI Systems**
2410.17504v1 by Shruthi Chari

Explainable Artificial Intelligence (AI) focuses on helping humans understand
the working of AI systems or their decisions and has been a cornerstone of AI
for decades. Recent research in explainability has focused on explaining the
workings of AI models or model explainability. There have also been several
position statements and review papers detailing the needs of end-users for
user-centered explainability but fewer implementations. Hence, this thesis
seeks to bridge some gaps between model and user-centered explainability. We
create an explanation ontology (EO) to represent literature-derived explanation
types via their supporting components. We implement a knowledge-augmented
question-answering (QA) pipeline to support contextual explanations in a
clinical setting. Finally, we are implementing a system to combine explanations
from different AI methods and data modalities. Within the EO, we can represent
fifteen different explanation types, and we have tested these representations
in six exemplar use cases. We find that knowledge augmentations improve the
performance of base large language models in the contextualized QA, and the
performance is variable across disease groups. In the same setting, clinicians
also indicated that they prefer to see actionability as one of the main foci in
explanations. In our explanations combination method, we plan to use similarity
metrics to determine the similarity of explanations in a chronic disease
detection setting. Overall, through this thesis, we design methods that can
support knowledge-enabled explanations across different use cases, accounting
for the methods in today's AI era that can generate the supporting components
of these explanations and domain knowledge sources that can enhance them.

æè¦ï¼å¯è§£éäººå·¥æºæ§ï¼AIï¼å°æ³¨æ¼åå©äººé¡äºè§£ AI ç³»çµ±éä½æå¶æ±ºç­ï¼æ¸åå¹´ä¾ä¸ç´æ¯ AI çåºç³ãæè¿çå¯è§£éæ§ç ç©¶å°æ³¨æ¼è§£é AI æ¨¡åææ¨¡åå¯è§£éæ§çéä½ãä¹æå¹¾ä»½ç«å ´è²æåè©è«è«æè©³ç´°èªªæäºæçµä½¿ç¨èå°ä»¥ä½¿ç¨èçºä¸­å¿çå¯è§£éæ§çéæ±ï¼ä½å¯¦ä½è¼å°ãå æ­¤ï¼æ¬è«ææ¨å¨å½è£æ¨¡ååä»¥ä½¿ç¨èçºä¸­å¿çå¯è§£éæ§ä¹éçä¸äºå·®è·ãæåå»ºç«ä¸åè§£éæ¬é«ï¼EOï¼ä»¥ééå¶æ¯æ´åä»¶ä¾è¡¨ç¤ºå¾æç»ä¸­è¡ççè§£éé¡åãæåå¯¦ä½ä¸åç¥è­å¢å¼·çåç­ï¼QAï¼ç®¡ç·ï¼ä»¥å¨è¨åºç°å¢ä¸­æ¯æ´æå¢è§£éãæå¾ï¼æåæ­£å¨å¯¦ä½ä¸åç³»çµ±ï¼ä»¥çµåä¾èªä¸å AI æ¹æ³åè³ææ¨¡å¼çè§£éãå¨ EO ä¸­ï¼æåå¯ä»¥è¡¨ç¤º 15 ç¨®ä¸åçè§£éé¡åï¼ä¸¦ä¸æåå·²å¨å­åç¯ä¾ä½¿ç¨æ¡ä¾ä¸­æ¸¬è©¦éäºè¡¨ç¤ºãæåç¼ç¾ï¼ç¥è­å¢å¼·æ¹åäºåºç¤å¤§åèªè¨æ¨¡åå¨æå¢å QA ä¸­çæè½ï¼ä¸¦ä¸æè½å ç¾çç¾¤çµèç°ãå¨ç¸åçç°å¢ä¸­ï¼è¨åºé«çä¹è¡¨ç¤ºä»åå¸æå°å¯æä½æ§è¦çºè§£éä¸­çä¸»è¦ç¦é»ä¹ä¸ãå¨æåçè§£éçµåæ¹æ³ä¸­ï¼æåè¨ç«ä½¿ç¨ç¸ä¼¼æ§ææ¨ä¾ç¢ºå®æ¢æ§çåµæ¸¬ç°å¢ä¸­è§£éçç¸ä¼¼æ§ãç¸½é«èè¨ï¼ééæ¬è«æï¼æåè¨­è¨äºå¯ä»¥å¨ä¸åä½¿ç¨æ¡ä¾ä¸­æ¯æ´ç¥è­åç¨è§£éçæ¹æ³ï¼èéå°ç¶ä» AI æä»£ä¸­å¯ä»¥ç¢çéäºè§£éçæ¯æ´åä»¶åå¯ä»¥å¢å¼·éäºè§£éçé åç¥è­ä¾æºçæ¹æ³ã

##### **Contrasting Attitudes Towards Current and Future AI Applications for Computerised Interpretation of ECG: A Clinical Stakeholder Interview Study**
2410.16879v1 by Lukas Hughes-Noehrer, Leda Channer, Gabriel Strain, Gregory Yates, Richard Body, Caroline Jay

Objectives: To investigate clinicians' attitudes towards current automated
interpretation of ECG and novel AI technologies and their perception of
computer-assisted interpretation. Materials and Methods: We conducted a series
of interviews with clinicians in the UK. Our study: (i) explores the potential
for AI, specifically future 'human-like' computing approaches, to facilitate
ECG interpretation and support clinical decision making, and (ii) elicits their
opinions about the importance of explainability and trustworthiness of AI
algorithms. Results: We performed inductive thematic analysis on interview
transcriptions from 23 clinicians and identified the following themes: (i) a
lack of trust in current systems, (ii) positive attitudes towards future AI
applications and requirements for these, (iii) the relationship between the
accuracy and explainability of algorithms, and (iv) opinions on education,
possible deskilling, and the impact of AI on clinical competencies. Discussion:
Clinicians do not trust current computerised methods, but welcome future 'AI'
technologies. Where clinicians trust future AI interpretation to be accurate,
they are less concerned that it is explainable. They also preferred ECG
interpretation that demonstrated the results of the algorithm visually. Whilst
clinicians do not fear job losses, they are concerned about deskilling and the
need to educate the workforce to use AI responsibly. Conclusion: Clinicians are
positive about the future application of AI in clinical decision-making.
Accuracy is a key factor of uptake and visualisations are preferred over
current computerised methods. This is viewed as a potential means of training
and upskilling, in contrast to the deskilling that automation might be
perceived to bring.

æè¦ï¼<paragraph>ç®çï¼èª¿æ¥è¨åºé«çå°ç®åèªååå¿é»åè§£è®åæ°çäººå·¥æºæ§æè¡çæåº¦ï¼ä»¥åä»åå°é»è¦è¼å©è§£è®ççæ³ãææåæ¹æ³ï¼æåå°è±åçè¨åºé«çé²è¡äºä¸ç³»åè¨ªè«ãæåçç ç©¶ï¼(i) æ¢è¨äººå·¥æºæ§çæ½åï¼ç¹å¥æ¯æªä¾çãé¡äººé¡ãéç®æ¹æ³ï¼ä»¥ä¿é²å¿é»åè§£è®ä¸¦æ¯æè¨åºæ±ºç­å¶å®ï¼ä»¥å (ii) å¾µæ±ä»åå°äººå·¥æºæ§æ¼ç®æ³çå¯è§£éæ§åå¯ä¿¡åº¦ççæ³ãçµæï¼æåå° 23 ä½è¨åºé«ççè¨ªè«è¨éé²è¡äºæ­¸ç´ä¸»é¡åæï¼ä¸¦æ¾åºä»¥ä¸ä¸»é¡ï¼(i) å°ç®åç³»çµ±ç¼ºä¹ä¿¡ä»»ï¼(ii) å°æªä¾äººå·¥æºæ§æç¨åå°éäºæç¨çè¦æ±ææ­£é¢æåº¦ï¼(iii) æ¼ç®æ³çæºç¢ºæ§åå¯è§£éæ§ä¹éçéä¿ï¼ä»¥å (iv) å°æè²ãå¯è½çæè½éåï¼ä»¥åäººå·¥æºæ§å°è¨åºè½åçå½±é¿ççæ³ãè¨è«ï¼è¨åºé«çä¸ä¿¡ä»»ç®åçé»è¦åæ¹æ³ï¼ä½æ­¡è¿æªä¾çãäººå·¥æºæ§ãæè¡ãå¨è¨åºé«çç¸ä¿¡æªä¾ç AI è§£è®æºç¢ºçææ³ä¸ï¼ä»åä¸å¤ªæå¿å®æ¯å¦å¯è§£éãä»åä¹æ¯è¼åæ­¡è½ä»¥è¦è¦ºæ¹å¼åç¾æ¼ç®æ³çµæçå¿é»åè§£è®ãéç¶è¨åºé«çä¸å®³æå¤±æ¥­ï¼ä½ä»åæå¿æè½éåï¼ä»¥åéè¦æè²å¡å·¥è² è²¬ä»»å°ä½¿ç¨äººå·¥æºæ§ãçµè«ï¼è¨åºé«çå°äººå·¥æºæ§å¨è¨åºæ±ºç­å¶å®ä¸­çæªä¾æç¨ææ­£é¢æåº¦ãæºç¢ºæ§æ¯æ¡ç¨äººå·¥æºæ§çä¸åééµå ç´ ï¼èè¦è¦ºåæ¯ç®åçé»è¦åæ¹æ³æ´åéçãéè¢«è¦çºä¸ç¨®æ½å¨çå¹è¨åæåæè½çæ¹æ³ï¼èèªååå¯è½å¸¶ä¾çæè½éåå½¢æå°æ¯ã</paragraph>

##### **Pathologist-like explainable AI for interpretable Gleason grading in prostate cancer**
2410.15012v1 by Gesa Mittmann, Sara Laiouar-Pedari, Hendrik A. Mehrtens, Sarah HaggenmÃ¼ller, Tabea-Clara Bucher, Tirtha Chanda, Nadine T. Gaisa, Mathias Wagner, Gilbert Georg Klamminger, Tilman T. Rau, Christina Neppl, Eva Maria CompÃ©rat, Andreas Gocht, Monika HÃ¤mmerle, Niels J. Rupp, Jula Westhoff, Irene KrÃ¼cken, Maximillian Seidl, Christian M. SchÃ¼rch, Marcus Bauer, Wiebke Solass, Yu Chun Tam, Florian Weber, Rainer Grobholz, Jaroslaw Augustyniak, Thomas Kalinski, Christian HÃ¶rner, Kirsten D. Mertz, Constanze DÃ¶ring, Andreas Erbersdobler, Gabriele Deubler, Felix Bremmer, Ulrich Sommer, Michael Brodhun, Jon Griffin, Maria Sarah L. Lenon, Kiril Trpkov, Liang Cheng, Fei Chen, Angelique Levi, Guoping Cai, Tri Q. Nguyen, Ali Amin, Alessia Cimadamore, Ahmed Shabaik, Varsha Manucha, Nazeel Ahmad, Nidia Messias, Francesca Sanguedolce, Diana Taheri, Ezra Baraban, Liwei Jia, Rajal B. Shah, Farshid Siadat, Nicole Swarbrick, Kyung Park, Oudai Hassan, Siamak Sakhaie, Michelle R. Downes, Hiroshi Miyamoto, Sean R. Williamson, Tim Holland-Letz, Carolin V. Schneider, Jakob Nikolas Kather, Yuri Tolkach, Titus J. Brinker

The aggressiveness of prostate cancer, the most common cancer in men
worldwide, is primarily assessed based on histopathological data using the
Gleason scoring system. While artificial intelligence (AI) has shown promise in
accurately predicting Gleason scores, these predictions often lack inherent
explainability, potentially leading to distrust in human-machine interactions.
To address this issue, we introduce a novel dataset of 1,015 tissue microarray
core images, annotated by an international group of 54 pathologists. The
annotations provide detailed localized pattern descriptions for Gleason grading
in line with international guidelines. Utilizing this dataset, we develop an
inherently explainable AI system based on a U-Net architecture that provides
predictions leveraging pathologists' terminology. This approach circumvents
post-hoc explainability methods while maintaining or exceeding the performance
of methods trained directly for Gleason pattern segmentation (Dice score: 0.713
$\pm$ 0.003 trained on explanations vs. 0.691 $\pm$ 0.010 trained on Gleason
patterns). By employing soft labels during training, we capture the intrinsic
uncertainty in the data, yielding strong results in Gleason pattern
segmentation even in the context of high interobserver variability. With the
release of this dataset, we aim to encourage further research into segmentation
in medical tasks with high levels of subjectivity and to advance the
understanding of pathologists' reasoning processes.

æè¦ï¼ååèºçæ¯å¨çç·æ§æå¸¸è¦çççï¼å¶æ¡æ§ç¨åº¦ä¸»è¦æ ¹æ Gleason è©åç³»çµ±ä½¿ç¨çµç¹ççå­¸æ¸æé²è¡è©ä¼°ãéç¶äººå·¥æºæ§ (AI) å¨æºç¢ºé æ¸¬ Gleason è©åæ¹é¢å·²å±ç¾æ½åï¼ä½éäºé æ¸¬éå¸¸ç¼ºä¹å§å¨çå¯è§£éæ§ï¼å¯è½æå°è´å°äººæ©äºåçä¸ä¿¡ä»»ãçºäºè§£æ±ºéååé¡ï¼æåå¼é²äºä¸åç± 54 ä½ççå­¸å®¶çµæçåéåéè¨»è§£ç 1,015 åçµç¹å¾®é£åæ ¸å¿å½±åçæ°ç©è³æéãéäºè¨»è§£æä¾äºè©³ç´°çå±é¨æ¨¡å¼æè¿°ï¼ç¨æ¼ç¬¦ååéæºåç Gleason åç´ãå©ç¨éåè³æéï¼æåéç¼äºä¸ååºæ¼ U-Net æ¶æ§çå§å¨å¯è§£é AI ç³»çµ±ï¼è©²ç³»çµ±æä¾äºå©ç¨ççå­¸å®¶è¡èªé²è¡é æ¸¬ãéç¨®æ¹æ³è¦é¿äºäºå¾å¯è§£éæ§æ¹æ³ï¼åæç¶­ææè¶è¶äºç´æ¥è¨ç·´ç¨æ¼ Gleason æ¨¡å¼åå²çæ¹æ³çæè½ï¼Dice åæ¸ï¼0.713 Â± 0.003ï¼è¨ç·´æ¼è§£éï¼ç¸å°æ¼ 0.691 Â± 0.010ï¼è¨ç·´æ¼ Gleason æ¨¡å¼ï¼ãééå¨è¨ç·´æéæ¡ç¨è»æ¨ç±¤ï¼æåææäºè³æä¸­çå§å¨ä¸ç¢ºå®æ§ï¼å³ä½¿å¨è§å¯èéè®ç°æ§é«çææ³ä¸ï¼ä¹è½å¨ Gleason æ¨¡å¼åå²ä¸­ç¢çå¼·å¤§ççµæãéééåºéåè³æéï¼æåæ¨å¨é¼åµé²ä¸æ­¥ç ç©¶ä¸»è§æ§é«çé«çä»»åä¸­çåå²ï¼ä¸¦å¢é²å°ççå­¸å®¶æ¨çéç¨ççè§£ã

##### **Explainable AI Methods for Multi-Omics Analysis: A Survey**
2410.11910v1 by Ahmad Hussein, Mukesh Prasad, Ali Braytee

Advancements in high-throughput technologies have led to a shift from
traditional hypothesis-driven methodologies to data-driven approaches.
Multi-omics refers to the integrative analysis of data derived from multiple
'omes', such as genomics, proteomics, transcriptomics, metabolomics, and
microbiomics. This approach enables a comprehensive understanding of biological
systems by capturing different layers of biological information. Deep learning
methods are increasingly utilized to integrate multi-omics data, offering
insights into molecular interactions and enhancing research into complex
diseases. However, these models, with their numerous interconnected layers and
nonlinear relationships, often function as black boxes, lacking transparency in
decision-making processes. To overcome this challenge, explainable artificial
intelligence (xAI) methods are crucial for creating transparent models that
allow clinicians to interpret and work with complex data more effectively. This
review explores how xAI can improve the interpretability of deep learning
models in multi-omics research, highlighting its potential to provide
clinicians with clear insights, thereby facilitating the effective application
of such models in clinical settings.

æè¦ï¼é«ééæè¡çé²æ­¥å°è´å¾å³çµ±çåè¨­é©åæ¹æ³è½è®çºè³æé©åçæ¹æ³ãå¤çµå­¸æ¯ææ´ååæä¾èªå¤åãçµå­¸ãçè³æï¼ä¾å¦åºå çµå­¸ãèç½è³ªçµå­¸ãè½éçµå­¸ãä»£è¬çµå­¸åå¾®çç©çµå­¸ãæ­¤æ¹æ³ééæ·åçç©è³è¨çä¸åå±¤é¢ï¼è½å¨é¢äºè§£çç©ç³»çµ±ãæ·±åº¦å­¸ç¿æ¹æ³æä¾æå¸¸è¢«ç¨æ¼æ´åå¤çµå­¸è³æï¼æä¾åå­äº¤äºä½ç¨çæ´å¯åï¼ä¸¦å å¼·å°è¤éç¾ççç ç©¶ãç¶èï¼éäºæ¨¡åå·æè¨±å¤ç¸äºé£æ¥çå±¤ç´åéç·æ§éä¿ï¼éå¸¸æåé»çå­ä¸æ¨£éä½ï¼ç¼ºä¹æ±ºç­éç¨çéæåº¦ãçºäºåææ­¤ææ°ï¼å¯è§£éäººå·¥æºæ§ (xAI) æ¹æ³å°æ¼å»ºç«éææ¨¡åè³ééè¦ï¼è®è¨åºé«çå¯ä»¥æ´ææå°è§£éåèçè¤éè³æãæ­¤è©è«æ¢è¨ xAI å¦ä½è½æ¹åå¤çµå­¸ç ç©¶ä¸­æ·±åº¦å­¸ç¿æ¨¡åçå¯è§£éæ§ï¼å¼·èª¿å¶æä¾è¨åºé«çæç¢ºè¦è§£çæ½åï¼é²èä¿é²æ­¤é¡æ¨¡åå¨è¨åºç°å¢ä¸­çæææç¨ã

##### **Study on the Helpfulness of Explainable Artificial Intelligence**
2410.11896v1 by Tobias Labarta, Elizaveta Kulicheva, Ronja Froelian, Christian GeiÃler, Xenia Melman, Julian von Klitzing

Explainable Artificial Intelligence (XAI) is essential for building advanced
machine learning-powered applications, especially in critical domains such as
medical diagnostics or autonomous driving. Legal, business, and ethical
requirements motivate using effective XAI, but the increasing number of
different methods makes it challenging to pick the right ones. Further, as
explanations are highly context-dependent, measuring the effectiveness of XAI
methods without users can only reveal a limited amount of information,
excluding human factors such as the ability to understand it. We propose to
evaluate XAI methods via the user's ability to successfully perform a proxy
task, designed such that a good performance is an indicator for the explanation
to provide helpful information. In other words, we address the helpfulness of
XAI for human decision-making. Further, a user study on state-of-the-art
methods was conducted, showing differences in their ability to generate trust
and skepticism and the ability to judge the rightfulness of an AI decision
correctly. Based on the results, we highly recommend using and extending this
approach for more objective-based human-centered user studies to measure XAI
performance in an end-to-end fashion.

æè¦ï¼å¯è§£éäººå·¥æºæ§ (XAI) å°æ¼å»ºæ§åé²çæ©å¨å­¸ç¿é©åæç¨ç¨å¼è³ééè¦ï¼ç¹å¥æ¯å¨é«çè¨ºæ·æèªåé§é§ç­ééµé åãæ³å¾ãåæ¥­åå«çè¦æ±ä¿ä½¿ä½¿ç¨ææç XAIï¼ä½æ¸éæ¥çå¢å çä¸åæ¹æ³ä½¿å¾æé¸æ­£ç¢ºçæ¹æ³å·æææ°æ§ãæ­¤å¤ï¼ç±æ¼è§£éé«åº¦ä¾è³´æ¼èæ¯ï¼å¨æ²æä½¿ç¨èçææ³ä¸è¡¡é XAI æ¹æ³çæææ§åªè½æ­ç¤ºæéçè³è¨ï¼æé¤äººé¡å ç´ ï¼ä¾å¦çè§£å®çè½åãæåå»ºè­°ééä½¿ç¨èæåå·è¡ä»£çä»»åçè½åä¾è©ä¼° XAI æ¹æ³ï¼è¨­è¨ä½¿å¾è¯å¥½çå·è¡è¡¨ç¾æ¯è§£éæä¾æç¨è³è¨çææ¨ãæå¥è©±èªªï¼æåæ¢è¨ XAI å°äººé¡æ±ºç­å¶å®çå¹«å©ãæ­¤å¤ï¼å°æåé²çæ¹æ³é²è¡ä½¿ç¨èç ç©¶ï¼é¡¯ç¤ºåºå®åå¨ç¢çä¿¡ä»»åæ·ççè½åä»¥åæ­£ç¢ºå¤æ· AI æ±ºç­æ¯å¦æ­£ç¢ºçè½åæ¹é¢å­å¨å·®ç°ãæ ¹æçµæï¼æåå¼·çå»ºè­°ä½¿ç¨åæ´åéç¨®æ¹æ³ï¼ä»¥é²è¡æ´å¤ä»¥ç®æ¨çºåºç¤çäººçºä¸­å¿ä½¿ç¨èç ç©¶ï¼ä»¥çµç«¯å°çµç«¯çæ¹å¼è¡¡é XAI æè½ã

##### **Use of What-if Scenarios to Help Explain Artificial Intelligence Models for Neonatal Health**
2410.09635v1 by Abdullah Mamun, Lawrence D. Devoe, Mark I. Evans, David W. Britt, Judith Klein-Seetharaman, Hassan Ghasemzadeh

Early detection of intrapartum risk enables interventions to potentially
prevent or mitigate adverse labor outcomes such as cerebral palsy. Currently,
there is no accurate automated system to predict such events to assist with
clinical decision-making. To fill this gap, we propose "Artificial Intelligence
(AI) for Modeling and Explaining Neonatal Health" (AIMEN), a deep learning
framework that not only predicts adverse labor outcomes from maternal, fetal,
obstetrical, and intrapartum risk factors but also provides the model's
reasoning behind the predictions made. The latter can provide insights into
what modifications in the input variables of the model could have changed the
predicted outcome. We address the challenges of imbalance and small datasets by
synthesizing additional training data using Adaptive Synthetic Sampling
(ADASYN) and Conditional Tabular Generative Adversarial Networks (CTGAN). AIMEN
uses an ensemble of fully-connected neural networks as the backbone for its
classification with the data augmentation supported by either ADASYN or CTGAN.
AIMEN, supported by CTGAN, outperforms AIMEN supported by ADASYN in
classification. AIMEN can predict a high risk for adverse labor outcomes with
an average F1 score of 0.784. It also provides counterfactual explanations that
can be achieved by changing 2 to 3 attributes on average. Resources available:
https://github.com/ab9mamun/AIMEN.

æè¦ï¼ç¢ç¨ä¸­é¢¨éªçæ©æåµæ¸¬æå©æ¼é²è¡å¹²é æªæ½ï¼ä»¥é é²ææ¸è¼ä¸å©ççç¢çµæï¼ä¾å¦è¦æ§éº»çºãç®åï¼æ²ææºç¢ºçèªååç³»çµ±å¯ä»¥é æ¸¬æ­¤é¡äºä»¶ï¼ä»¥åå©è¨åºæ±ºç­ãçºäºå¡«è£éä¸ç©ºç½ï¼æåæåºãç¨æ¼å»ºæ¨¡åè§£éæ°çåå¥åº·çäººå·¥æºæ§ã(AIMEN)ï¼éæ¯ä¸åæ·±åº¦å­¸ç¿æ¶æ§ï¼å®ä¸åå¯ä»¥æ ¹æå­ç¢å©¦ãèåãç¢ç§åç¢ç¨é¢¨éªå ç´ é æ¸¬ä¸å©ççç¢çµæï¼éè½æä¾æ¨¡åååºé æ¸¬èå¾çåå ãå¾èå¯ä»¥æä¾è¦è§£ï¼èªªææ¨¡åè¼¸å¥è®æ¸ä¸­çåªäºä¿®æ¹å¯è½ææ¹è®é æ¸¬çµæãæåééä½¿ç¨é©ææ§åææ½æ¨£ (ADASYN) åæ¢ä»¶è¡¨æ ¼çæå°æç¶²è·¯ (CTGAN) ä¾åæé¡å¤çè¨ç·´è³æï¼ä»¥è§£æ±ºä¸å¹³è¡¡åå°åè³æéçææ°ãAIMEN ä½¿ç¨å¨é£æ¥ç¥ç¶ç¶²è·¯çéåä½çºå¶åé¡çéª¨å¹¹ï¼ä¸¦éé ADASYN æ CTGAN æ¯æ´è³ææ´åãç± CTGAN æ¯æ´ç AIMEN å¨åé¡æ¹é¢åªæ¼ç± ADASYN æ¯æ´ç AIMENãAIMEN å¯ä»¥é æ¸¬ä¸å©ççç¢çµæçé«é¢¨éªï¼å¹³å F1 åæ¸çº 0.784ãå®éæä¾åäºå¯¦è§£éï¼å¯ééå¹³åè®æ´ 2 è³ 3 åå±¬æ§ä¾éæãå¯ç¨è³æºï¼https://github.com/ab9mamun/AIMENã

##### **Artificial intelligence techniques in inherited retinal diseases: A review**
2410.09105v1 by Han Trinh, Jordan Vice, Jason Charng, Zahra Tajbakhsh, Khyber Alam, Fred K. Chen, Ajmal Mian

Inherited retinal diseases (IRDs) are a diverse group of genetic disorders
that lead to progressive vision loss and are a major cause of blindness in
working-age adults. The complexity and heterogeneity of IRDs pose significant
challenges in diagnosis, prognosis, and management. Recent advancements in
artificial intelligence (AI) offer promising solutions to these challenges.
However, the rapid development of AI techniques and their varied applications
have led to fragmented knowledge in this field. This review consolidates
existing studies, identifies gaps, and provides an overview of AI's potential
in diagnosing and managing IRDs. It aims to structure pathways for advancing
clinical applications by exploring AI techniques like machine learning and deep
learning, particularly in disease detection, progression prediction, and
personalized treatment planning. Special focus is placed on the effectiveness
of convolutional neural networks in these areas. Additionally, the integration
of explainable AI is discussed, emphasizing its importance in clinical settings
to improve transparency and trust in AI-based systems. The review addresses the
need to bridge existing gaps in focused studies on AI's role in IRDs, offering
a structured analysis of current AI techniques and outlining future research
directions. It concludes with an overview of the challenges and opportunities
in deploying AI for IRDs, highlighting the need for interdisciplinary
collaboration and the continuous development of robust, interpretable AI models
to advance clinical applications.

æè¦ï¼éºå³æ§è¦ç¶²èç¾ç (IRD) æ¯ä¸çµå¤æ¨£åçéºå³ç¾çï¼
æå°è´è¦åéæ¼¸åªå¤±ï¼æ¯å·¥ä½å¹´é½¡æäººå¤±æçä¸»è¦åå ãIRD çè¤éæ§åç°è³ªæ§å°è¨ºæ·ãé å¾åç®¡çæåºäºéå¤§ææ°ãæè¿äººå·¥æºè½ (AI) çé²æ­¥çºéäºææ°æä¾äºæå¸æçè§£æ±ºæ¹æ¡ã
ç¶èï¼AI æè¡çå¿«éç¼å±åå¶å¤ç¨®æç¨å°è´äºè©²é åçç¥è­åæ£ãæ¬ç¶è¿°æ´åäºç¾æç ç©¶ï¼æ¾åºå·®è·ï¼ä¸¦æ¦è¿°äº AI å¨è¨ºæ·åç®¡ç IRD ä¸­çæ½åãå®æ¨å¨ééæ¢ç´¢æ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿ç­ AI æè¡ï¼ç¹å¥æ¯å¨ç¾çæª¢æ¸¬ãé²ç¨é æ¸¬ååæ§åæ²»çè¨åä¸­ï¼çºæ¨é²è¨åºæç¨æ§å»ºéå¾ãç¹å¥éæ³¨éäºé åä¸­å·ç©ç¥ç¶ç¶²è·¯çæææ§ãæ­¤å¤ï¼è¨è«äºå¯è§£é AI çæ´åï¼å¼·èª¿äºå¶å¨è¨åºç°å¢ä¸­æé«éæåº¦åå°åºæ¼ AI çç³»çµ±çä¿¡ä»»çéè¦æ§ãè©²ç¶è¿°è§£æ±ºäºå½å AI å¨ IRD ä¸­ä½ç¨çéé»ç ç©¶ä¸­ç¾æå·®è·çå¿è¦æ§ï¼æä¾äºå°ç¶å AI æè¡ççµæ§ååæï¼ä¸¦æ¦è¿°äºæªä¾çç ç©¶æ¹åãæå¾æ¦è¿°äºå¨ IRD ä¸­é¨ç½² AI çææ°åæ©éï¼å¼·èª¿äºè·¨å­¸ç§åä½åæçºéç¼å¼·å¤§ãå¯è§£éç AI æ¨¡åä»¥æ¨é²è¨åºæç¨çå¿è¦æ§ã

##### **CasiMedicos-Arg: A Medical Question Answering Dataset Annotated with Explanatory Argumentative Structures**
2410.05235v2 by Ekaterina Sviridova, Anar Yeginbergen, Ainara Estarrona, Elena Cabrio, Serena Villata, Rodrigo Agerri

Explaining Artificial Intelligence (AI) decisions is a major challenge
nowadays in AI, in particular when applied to sensitive scenarios like medicine
and law. However, the need to explain the rationale behind decisions is a main
issue also for human-based deliberation as it is important to justify
\textit{why} a certain decision has been taken. Resident medical doctors for
instance are required not only to provide a (possibly correct) diagnosis, but
also to explain how they reached a certain conclusion. Developing new tools to
aid residents to train their explanation skills is therefore a central
objective of AI in education. In this paper, we follow this direction, and we
present, to the best of our knowledge, the first multilingual dataset for
Medical Question Answering where correct and incorrect diagnoses for a clinical
case are enriched with a natural language explanation written by doctors. These
explanations have been manually annotated with argument components (i.e.,
premise, claim) and argument relations (i.e., attack, support), resulting in
the Multilingual CasiMedicos-Arg dataset which consists of 558 clinical cases
in four languages (English, Spanish, French, Italian) with explanations, where
we annotated 5021 claims, 2313 premises, 2431 support relations, and 1106
attack relations. We conclude by showing how competitive baselines perform over
this challenging dataset for the argument mining task.

æè¦ï¼è§£éäººå·¥æºæ§ (AI) çæ±ºç­æ¯ç¾å¨ AI çä¸é éå¤§ææ°ï¼ç¹å¥æ¯æç¨æ¼åé«å­¸åæ³å¾ç­æææå¢æãç¶èï¼è§£éæ±ºç­èå¾çç±çéæ±ä¹æ¯åºæ¼äººé¡çèéçä¸åä¸»è¦åé¡ï¼å çºæå¿è¦è­æçºä»éº¼ååºæåæ±ºç­ãä¾å¦ï¼ä½é¢é«å¸«ä¸åéè¦æä¾ï¼å¯è½æ¯æ­£ç¢ºçï¼è¨ºæ·ï¼ééè¦è§£éä»åå¦ä½éææåçµè«ãå æ­¤ï¼éç¼æ°çå·¥å·ä¾å¹«å©ä½é¢é«å¸«è¨ç·´ä»åçè§£éæå·§æ¯æè²ä¸­ AI çä¸é æ ¸å¿ç®æ¨ãå¨æ¬æä¸­ï¼æåéµå¾ªéåæ¹åï¼ä¸¦ä¸æ ¹ææåçäºè§£ï¼æåºç¬¬ä¸åå¤èªè¨é«å­¸åç­è³æéï¼å¶ä¸­è¨åºçä¾çæ­£ç¢ºåä¸æ­£ç¢ºè¨ºæ·é½éæç±é«çæ°å¯«çèªç¶èªè¨è§£éãéäºè§£éå·²ä½¿ç¨è«è­çµæï¼å³åæãä¸»å¼µï¼åè«è­éä¿ï¼å³æ»æãæ¯æï¼é²è¡æåè¨»è§£ï¼ç¢çå¤èªè¨ CasiMedicos-Arg è³æéï¼å¶ä¸­åå« 558 åå·æè§£éçåç¨®èªè¨ï¼è±èªãè¥¿ç­çèªãæ³èªãç¾©å¤§å©èªï¼çè¨åºçä¾ï¼æåè¨»è§£äº 5021 åä¸»å¼µã2313 ååæã2431 åæ¯æéä¿å 1106 åæ»æéä¿ãæåæå¾å±ç¤ºäºç«¶ç­åºæºå¦ä½éå°è«è­æ¢åä»»åå·è¡æ­¤å·ææ°æ§çè³æéã

##### **Explainable Diagnosis Prediction through Neuro-Symbolic Integration**
2410.01855v1 by Qiuhao Lu, Rui Li, Elham Sagheb, Andrew Wen, Jinlian Wang, Liwei Wang, Jungwei W. Fan, Hongfang Liu

Diagnosis prediction is a critical task in healthcare, where timely and
accurate identification of medical conditions can significantly impact patient
outcomes. Traditional machine learning and deep learning models have achieved
notable success in this domain but often lack interpretability which is a
crucial requirement in clinical settings. In this study, we explore the use of
neuro-symbolic methods, specifically Logical Neural Networks (LNNs), to develop
explainable models for diagnosis prediction. Essentially, we design and
implement LNN-based models that integrate domain-specific knowledge through
logical rules with learnable thresholds. Our models, particularly
$M_{\text{multi-pathway}}$ and $M_{\text{comprehensive}}$, demonstrate superior
performance over traditional models such as Logistic Regression, SVM, and
Random Forest, achieving higher accuracy (up to 80.52\%) and AUROC scores (up
to 0.8457) in the case study of diabetes prediction. The learned weights and
thresholds within the LNN models provide direct insights into feature
contributions, enhancing interpretability without compromising predictive
power. These findings highlight the potential of neuro-symbolic approaches in
bridging the gap between accuracy and explainability in healthcare AI
applications. By offering transparent and adaptable diagnostic models, our work
contributes to the advancement of precision medicine and supports the
development of equitable healthcare solutions. Future research will focus on
extending these methods to larger and more diverse datasets to further validate
their applicability across different medical conditions and populations.

æè¦ï¼è¨ºæ·é æ¸¬æ¯é«çä¿å¥ä¸­çä¸é ééµä»»åï¼åæä¸æºç¢ºå°è­å¥é«ççæ³æå°æ£èççµæç¢çéå¤§å½±é¿ãå³çµ±æ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿æ¨¡åå·²å¨æ­¤é ååå¾é¡¯èæåï¼ä½éå¸¸ç¼ºä¹å¯è§£éæ§ï¼éæ¯è¨åºç°å¢ä¸­çééµè¦æ±ãå¨æ¬ç ç©¶ä¸­ï¼æåæ¢è¨äºç¥ç¶ç¬¦èæ¹æ³ï¼ç¹å¥æ¯éè¼¯ç¥ç¶ç¶²è·¯ (LNN)ï¼ä»¥éç¼å¯è§£éçè¨ºæ·é æ¸¬æ¨¡åãåºæ¬ä¸ï¼æåè¨­è¨ä¸¦å¯¦ä½äºåºæ¼ LNN çæ¨¡åï¼è©²æ¨¡åéééè¼¯è¦ååå¯å­¸ç¿çé¾å¼æ´åé åç¹å®çç¥è­ãæåçæ¨¡åï¼ç¹å¥æ¯ $M_{\text{multi-pathway}}$ å $M_{\text{comprehensive}}$ï¼è¡¨ç¾åºåªæ¼å³çµ±æ¨¡åï¼å¦éè¼¯è¿´æ­¸ãSVM åé¨æ©æ£®æï¼çåè¶æè½ï¼å¨ç³å°¿çé æ¸¬çæ¡ä¾ç ç©¶ä¸­ï¼éå°äºæ´é«çæºç¢ºåº¦ï¼é«é 80.52%ï¼å AUROC åæ¸ï¼é«é 0.8457ï¼ãLNN æ¨¡åä¸­å­¸ç¿çæ¬éåé¾å¼æä¾äºå°ç¹å¾µè²¢ç»çç´æ¥è¦è§£ï¼å¢å¼·äºå¯è§£éæ§ï¼åæä¸æå®³é æ¸¬è½åãéäºç¼ç¾çªé¡¯äºç¥ç¶ç¬¦èæ¹æ³å¨å½åé«çä¿å¥ AI æç¨ä¸­æºç¢ºæ§åå¯è§£éæ§å·®è·æ¹é¢çæ½åãééæä¾éæä¸é©ææ§å¼·çè¨ºæ·æ¨¡åï¼æåçç ç©¶æå©æ¼ç²¾æºé«ççé²æ­¥ï¼ä¸¦æ¯æ´å¬å¹³é«çä¿å¥è§£æ±ºæ¹æ¡çéç¼ãæªä¾çç ç©¶å°å°æ³¨æ¼å°éäºæ¹æ³æ´å±å°æ´å¤§ä¸æ´å¤æ¨£åçè³æéï¼ä»¥é²ä¸æ­¥é©è­å¶å¨ä¸åé«ççæ³åäººç¾¤ä¸­çé©ç¨æ§ã

##### **Easydiagnos: a framework for accurate feature selection for automatic diagnosis in smart healthcare**
2410.00366v1 by Prasenjit Maji, Amit Kumar Mondal, Hemanta Kumar Mondal, Saraju P. Mohanty

The rapid advancements in artificial intelligence (AI) have revolutionized
smart healthcare, driving innovations in wearable technologies, continuous
monitoring devices, and intelligent diagnostic systems. However, security,
explainability, robustness, and performance optimization challenges remain
critical barriers to widespread adoption in clinical environments. This
research presents an innovative algorithmic method using the Adaptive Feature
Evaluator (AFE) algorithm to improve feature selection in healthcare datasets
and overcome problems. AFE integrating Genetic Algorithms (GA), Explainable
Artificial Intelligence (XAI), and Permutation Combination Techniques (PCT),
the algorithm optimizes Clinical Decision Support Systems (CDSS), thereby
enhancing predictive accuracy and interpretability. The proposed method is
validated across three diverse healthcare datasets using six distinct machine
learning algorithms, demonstrating its robustness and superiority over
conventional feature selection techniques. The results underscore the
transformative potential of AFE in smart healthcare, enabling personalized and
transparent patient care. Notably, the AFE algorithm, when combined with a
Multi-layer Perceptron (MLP), achieved an accuracy of up to 98.5%, highlighting
its capability to improve clinical decision-making processes in real-world
healthcare applications.

æè¦ï¼äººå·¥æºæ§ (AI) çå¿«éé²å±å¾¹åºæ¹è®äºæºæ§é«çä¿å¥ï¼æ¨åäºå¯ç©¿æ´æè¡ãæçºç£æ§è£ç½®åæºæ§è¨ºæ·ç³»çµ±çåµæ°ãç¶èï¼å®å¨æ§ãå¯è§£éæ§ãç©©å¥æ§åæè½æä½³åææ°ä»ç¶æ¯è¨åºç°å¢ä¸­å»£æ³æ¡ç¨çééµéç¤ãæ¬ç ç©¶æåºä¸ååµæ°çæ¼ç®æ³æ¹æ³ï¼ä½¿ç¨èªé©æç¹å¾µè©ä¼°å¨ (AFE) æ¼ç®æ³ä¾æ¹åé«çä¿å¥è³æéä¸­çç¹å¾µé¸åä¸¦åæåé¡ãAFE æ´åäºéºå³æ¼ç®æ³ (GA)ãå¯è§£éäººå·¥æºæ§ (XAI) åæåçµåæè¡ (PCT)ï¼è©²æ¼ç®æ³æä½³åäºè¨åºæ±ºç­æ¯æ´ç³»çµ± (CDSS)ï¼å¾èæé«äºé æ¸¬æºç¢ºæ§åå¯è§£éæ§ãææåºçæ¹æ³ä½¿ç¨å­ç¨®ä¸åçæ©å¨å­¸ç¿æ¼ç®æ³é©è­äºä¸åä¸åçé«çä¿å¥è³æéï¼è­æäºå¶ç©©å¥æ§ååªæ¼å³çµ±ç¹å¾µé¸åæè¡ãçµæå¼·èª¿äº AFE å¨æºæ§é«çä¿å¥ä¸­çè½è®æ½åï¼å¯¦ç¾äºåäººååéæçæ£èç§è­·ãå¼å¾æ³¨æçæ¯ï¼AFE æ¼ç®æ³èå¤å±¤æç¥å¨ (MLP) çµåä½¿ç¨æï¼æºç¢ºåº¦é«é 98.5%ï¼çªé¡¯äºå¶æ¹åå¯¦éé«çä¿å¥æç¨ä¸­è¨åºæ±ºç­å¶å®æµç¨çè½åã

##### **Dermatologist-like explainable AI enhances melanoma diagnosis accuracy: eye-tracking study**
2409.13476v1 by Tirtha Chanda, Sarah Haggenmueller, Tabea-Clara Bucher, Tim Holland-Letz, Harald Kittler, Philipp Tschandl, Markus V. Heppt, Carola Berking, Jochen S. Utikal, Bastian Schilling, Claudia Buerger, Cristian Navarrete-Dechent, Matthias Goebeler, Jakob Nikolas Kather, Carolin V. Schneider, Benjamin Durani, Hendrike Durani, Martin Jansen, Juliane Wacker, Joerg Wacker, Reader Study Consortium, Titus J. Brinker

Artificial intelligence (AI) systems have substantially improved
dermatologists' diagnostic accuracy for melanoma, with explainable AI (XAI)
systems further enhancing clinicians' confidence and trust in AI-driven
decisions. Despite these advancements, there remains a critical need for
objective evaluation of how dermatologists engage with both AI and XAI tools.
In this study, 76 dermatologists participated in a reader study, diagnosing 16
dermoscopic images of melanomas and nevi using an XAI system that provides
detailed, domain-specific explanations. Eye-tracking technology was employed to
assess their interactions. Diagnostic performance was compared with that of a
standard AI system lacking explanatory features. Our findings reveal that XAI
systems improved balanced diagnostic accuracy by 2.8 percentage points relative
to standard AI. Moreover, diagnostic disagreements with AI/XAI systems and
complex lesions were associated with elevated cognitive load, as evidenced by
increased ocular fixations. These insights have significant implications for
clinical practice, the design of AI tools for visual tasks, and the broader
development of XAI in medical diagnostics.

æè¦ï¼äººå·¥æºæ§ (AI) ç³»çµ±å·²å¤§å¹æ¹åç®èç§é«å¸«å°é»è²ç´ ç¤çè¨ºæ·æºç¢ºåº¦ï¼èå¯è§£é AI (XAI) ç³»çµ±é²ä¸æ­¥æåè¨åºé«å¸«å° AI é©åæ±ºç­çä¿¡å¿èä¿¡è³´ãåç®¡æéäºé²å±ï¼å°æ¼ç®èç§é«å¸«å¦ä½ä½¿ç¨ AI å XAI å·¥å·ï¼ä»æå®¢è§è©ä¼°çè¿«åéæ±ãå¨éé ç ç©¶ä¸­ï¼76 ä½ç®èç§é«å¸«åèäºä¸é è®èç ç©¶ï¼ä½¿ç¨ XAI ç³»çµ±è¨ºæ· 16 å¼µé»è²ç´ ç¤åç£çç®èé¡å½±åï¼è©²ç³»çµ±æä¾è©³ç´°çé åç¹å®èªªæãæ¡ç¨ç¼çè¿½è¹¤æè¡ä¾è©ä¼°ä»åçäºåãå°è¨ºæ·è¡¨ç¾èç¼ºä¹èªªæåè½çæ¨æº AI ç³»çµ±é²è¡æ¯è¼ãæåçç ç©¶çµæé¡¯ç¤ºï¼XAI ç³»çµ±ç¸è¼æ¼æ¨æº AIï¼å°å¹³è¡¡è¨ºæ·æºç¢ºåº¦æåäº 2.8 åç¾åé»ãæ­¤å¤ï¼è AI/XAI ç³»çµ±çè¨ºæ·åæ­§åè¤éççç¶èèªç¥è² æåé«æéï¼éç±å¢å çç¼çæ³¨è¦æ¬¡æ¸æè­å¯¦ãéäºè¦è§£å°è¨åºå¯¦åãè¦è¦ºä»»å AI å·¥å·çè¨­è¨åé«å­¸è¨ºæ·ä¸­ XAI çå»£æ³ç¼å±å·æéå¤§æç¾©ã

##### **Explainable AI for Autism Diagnosis: Identifying Critical Brain Regions Using fMRI Data**
2409.15374v1 by Suryansh Vidya, Kush Gupta, Amir Aly, Andy Wills, Emmanuel Ifeachor, Rohit Shankar

Early diagnosis and intervention for Autism Spectrum Disorder (ASD) has been
shown to significantly improve the quality of life of autistic individuals.
However, diagnostics methods for ASD rely on assessments based on clinical
presentation that are prone to bias and can be challenging to arrive at an
early diagnosis. There is a need for objective biomarkers of ASD which can help
improve diagnostic accuracy. Deep learning (DL) has achieved outstanding
performance in diagnosing diseases and conditions from medical imaging data.
Extensive research has been conducted on creating models that classify ASD
using resting-state functional Magnetic Resonance Imaging (fMRI) data. However,
existing models lack interpretability. This research aims to improve the
accuracy and interpretability of ASD diagnosis by creating a DL model that can
not only accurately classify ASD but also provide explainable insights into its
working. The dataset used is a preprocessed version of the Autism Brain Imaging
Data Exchange (ABIDE) with 884 samples. Our findings show a model that can
accurately classify ASD and highlight critical brain regions differing between
ASD and typical controls, with potential implications for early diagnosis and
understanding of the neural basis of ASD. These findings are validated by
studies in the literature that use different datasets and modalities,
confirming that the model actually learned characteristics of ASD and not just
the dataset. This study advances the field of explainable AI in medical imaging
by providing a robust and interpretable model, thereby contributing to a future
with objective and reliable ASD diagnostics.

æè¦ï¼èªéçè­ç³»éç¤ (ASD) çæ©æè¨ºæ·åä»å¥å·²è¢«è­å¯¦è½é¡¯èæ¹åèªéçæ£èççæ´»åè³ªãç¶èï¼ASD çè¨ºæ·æ¹æ³ä¾è³´æ¼åºæ¼è¨åºè¡¨ç¾çè©ä¼°ï¼å®¹æç¢çåè¦ï¼ä¸å¯è½é£ä»¥ååºæ©æè¨ºæ·ãæå¿è¦æ¾åº ASD çå®¢è§çç©æ¨è¨ï¼ä»¥å¹«å©æé«è¨ºæ·æºç¢ºæ§ãæ·±åº¦å­¸ç¿ (DL) å¨å¾é«å­¸å½±åè³æè¨ºæ·ç¾çåççæ¹é¢åå¾ååºçè¡¨ç¾ãå·²ç¶éå°å»ºç«ä½¿ç¨éæåè½æ§ç£æ¯é å½± (fMRI) è³æå° ASD é²è¡åé¡çæ¨¡åé²è¡å»£æ³çç ç©¶ãç¶èï¼ç¾æçæ¨¡åç¼ºä¹å¯è§£éæ§ãæ¬ç ç©¶æ¨å¨ééå»ºç«ä¸åä¸åè½æºç¢ºåé¡ ASDï¼éè½æä¾å¯è§£éè¦è§£èªªæå¶éä½åçç DL æ¨¡åï¼ä¾æ¹å ASD è¨ºæ·çæºç¢ºæ§åå¯è§£éæ§ãæä½¿ç¨çè³æéæ¯èªéçå¤§è¦å½±åè³æäº¤æ (ABIDE) çé èççæ¬ï¼åå« 884 åæ¨£æ¬ãæåçç ç©¶çµæé¡¯ç¤ºï¼è©²æ¨¡åè½æºç¢ºåé¡ ASDï¼ä¸¦å¼·èª¿ ASD èå¸åå°ç§çµä¹éå­å¨å·®ç°çééµè¦åï¼å°æ¼ ASD çæ©æè¨ºæ·åç¥ç¶åºç¤ççè§£å·ææ½å¨çæç¾©ãéäºç ç©¶çµæå·²ç±ä½¿ç¨ä¸åè³æéåæ¹å¼çæç»ç ç©¶é©è­ï¼è­å¯¦è©²æ¨¡åå¯¦éä¸å­¸ç¿äº ASD çç¹å¾µï¼èä¸ååæ¯è³æéãæ¬ç ç©¶ééæä¾ä¸åå¼·å¥ä¸å¯è§£éçæ¨¡åï¼æ¨åäºé«å­¸å½±åä¸­å¯è§£é AI çé åï¼å¾èçºæªä¾æä¾å®¢è§ä¸å¯é ç ASD è¨ºæ·ååºè²¢ç»ã

##### **Improving Prototypical Parts Abstraction for Case-Based Reasoning Explanations Designed for the Kidney Stone Type Recognition**
2409.12883v1 by Daniel Flores-Araiza, Francisco Lopez-Tiro, ClÃ©ment Larose, Salvador Hinojosa, Andres Mendez-Vazquez, Miguel Gonzalez-Mendoza, Gilberto Ochoa-Ruiz, Christian Daul

The in-vivo identification of the kidney stone types during an ureteroscopy
would be a major medical advance in urology, as it could reduce the time of the
tedious renal calculi extraction process, while diminishing infection risks.
Furthermore, such an automated procedure would make possible to prescribe
anti-recurrence treatments immediately. Nowadays, only few experienced
urologists are able to recognize the kidney stone types in the images of the
videos displayed on a screen during the endoscopy. Thus, several deep learning
(DL) models have recently been proposed to automatically recognize the kidney
stone types using ureteroscopic images. However, these DL models are of black
box nature whicl limits their applicability in clinical settings. This
contribution proposes a case-based reasoning DL model which uses prototypical
parts (PPs) and generates local and global descriptors. The PPs encode for each
class (i.e., kidney stone type) visual feature information (hue, saturation,
intensity and textures) similar to that used by biologists. The PPs are
optimally generated due a new loss function used during the model training.
Moreover, the local and global descriptors of PPs allow to explain the
decisions ("what" information, "where in the images") in an understandable way
for biologists and urologists. The proposed DL model has been tested on a
database including images of the six most widespread kidney stone types. The
overall average classification accuracy was 90.37. When comparing this results
with that of the eight other DL models of the kidney stone state-of-the-art, it
can be seen that the valuable gain in explanability was not reached at the
expense of accuracy which was even slightly increased with respect to that
(88.2) of the best method of the literature. These promising and interpretable
results also encourage urologists to put their trust in AI-based solutions.

æè¦ï¼å°¿è·¯é¡æª¢æ¥ä¸­èçµç³é¡åçé«å§è­å¥å°æ¯æ³å°¿ç§çä¸é éå¤§é²å±ï¼å çºå®å¯ä»¥æ¸å°ç¹ç£çèçµç³ååºéç¨çæéï¼åæéä½ææé¢¨éªãæ­¤å¤ï¼éç¨®èªååç¨åºå°ä½¿ç«å³éç«æå¾©ç¼æ²»çæçºå¯è½ãå¦ä»ï¼åªæå°æ¸ç¶é©è±å¯çæ³å°¿ç§é«çè½å¤ å¨å§è¦é¡æª¢æ¥æéå±å¹ä¸é¡¯ç¤ºçè¦é »ååä¸­è­å¥èçµç³é¡åãå æ­¤ï¼æè¿å·²æåºå¤ç¨®æ·±åº¦å­¸ç¿ (DL) æ¨¡åï¼ä»¥ä½¿ç¨è¼¸å°¿ç®¡é¡ååèªåè­å¥èçµç³é¡åãç¶èï¼éäº DL æ¨¡åæ¬è³ªä¸æ¯é»çå­ï¼ééå¶äºå®åå¨è¨åºç°å¢ä¸­çæç¨æ§ãæ¬ææåºäºä¸ååºæ¼æ¡ä¾æ¨çç DL æ¨¡åï¼å®ä½¿ç¨ååé¨å (PP) ä¸¦çæå±é¨åå¨å±æè¿°ç¬¦ãPP çºæ¯ç¨®é¡åï¼å³èçµç³é¡åï¼ç·¨ç¢¼è¦è¦ºç¹å¾µä¿¡æ¯ï¼è²èª¿ãé£½ååº¦ãå¼·åº¦åç´çï¼ï¼é¡ä¼¼æ¼çç©å­¸å®¶ä½¿ç¨çä¿¡æ¯ãç±æ¼å¨æ¨¡åè¨ç·´æéä½¿ç¨çæ°æå¤±å½æ¸ï¼PP å¾å°äºæä½³çæãæ­¤å¤ï¼PP çå±é¨åå¨å±æè¿°ç¬¦åè¨±ä»¥çç©å­¸å®¶åæ³å°¿ç§é«çå¯ä»¥çè§£çæ¹å¼è§£éæ±ºç­ï¼âä»éº¼âä¿¡æ¯ï¼âååä¸­çä»éº¼ä½ç½®âï¼ãææåºç DL æ¨¡åå·²å¨ä¸ååå«å­ç¨®æå»£æ³çèçµç³é¡åååçæ¸æåº«ä¸é²è¡äºæ¸¬è©¦ãç¸½é«å¹³ååé¡æºç¢ºççº 90.37ãå°æ­¤çµæèèçµç³æåé²çå«åå¶ä» DL æ¨¡åççµæé²è¡æ¯è¼æï¼å¯ä»¥çåºï¼å¯è§£éæ§çå¯¶è²´å¢çä¸¦æªä»¥æºç¢ºæ§çºä»£å¹ï¼çè³ç¥æå¢å èæç»ä¸­æå¥½çæ¹æ³ (88.2) ç¸æ¯ãéäºæå¸æä¸å¯è§£éççµæä¹é¼åµæ³å°¿ç§é«çç¸ä¿¡åºæ¼äººå·¥æºè½çè§£æ±ºæ¹æ¡ã

##### **Towards Interpretable End-Stage Renal Disease (ESRD) Prediction: Utilizing Administrative Claims Data with Explainable AI Techniques**
2409.12087v3 by Yubo Li, Saba Al-Sayouri, Rema Padman

This study explores the potential of utilizing administrative claims data,
combined with advanced machine learning and deep learning techniques, to
predict the progression of Chronic Kidney Disease (CKD) to End-Stage Renal
Disease (ESRD). We analyze a comprehensive, 10-year dataset provided by a major
health insurance organization to develop prediction models for multiple
observation windows using traditional machine learning methods such as Random
Forest and XGBoost as well as deep learning approaches such as Long Short-Term
Memory (LSTM) networks. Our findings demonstrate that the LSTM model,
particularly with a 24-month observation window, exhibits superior performance
in predicting ESRD progression, outperforming existing models in the
literature. We further apply SHapley Additive exPlanations (SHAP) analysis to
enhance interpretability, providing insights into the impact of individual
features on predictions at the individual patient level. This study underscores
the value of leveraging administrative claims data for CKD management and
predicting ESRD progression.

æè¦ï¼æ¬ç ç©¶æ¢è¨å©ç¨è¡æ¿ç³å ±è³æï¼çµååé²æ©å¨å­¸ç¿èæ·±åº¦å­¸ç¿æè¡ï¼é æ¸¬æ¢æ§èèç (CKD) é²å±è³æ«æèèç¾ç (ESRD) çå¯è½æ§ãæååæä¸å®¶å¤§åå¥åº·ä¿éªçµç¹æä¾ç 10 å¹´ç¶åè³æéï¼ä½¿ç¨å³çµ±æ©å¨å­¸ç¿æ¹æ³ï¼ä¾å¦é¨æ©æ£®æå XGBoostï¼ä»¥åæ·±åº¦å­¸ç¿æ¹æ³ï¼ä¾å¦é·æç­æè¨æ¶ (LSTM) ç¶²è·¯ï¼éç¼å¤åè§å¯è¦çªçé æ¸¬æ¨¡åãæåçç ç©¶çµæé¡¯ç¤ºï¼LSTM æ¨¡åï¼å°¤å¶æ¯ 24 åæè§å¯è¦çªï¼å¨é æ¸¬ ESRD é²å±æ¹é¢è¡¨ç¾åªç°ï¼åªæ¼æç»ä¸­çç¾ææ¨¡åãæåé²ä¸æ­¥æç¨ SHapley å¯å æ§è§£é (SHAP) åæä»¥å¢å¼·å¯è§£éæ§ï¼æ·±å¥äºè§£åå¥ç¹å¾µå°åå¥æ£èå±¤ç´é æ¸¬çå½±é¿ãæ¬ç ç©¶å¼·èª¿äºå©ç¨è¡æ¿ç³å ±è³æé²è¡ CKD ç®¡çåé æ¸¬ ESRD é²å±çå¹å¼ã

##### **Explainable AI: Definition and attributes of a good explanation for health AI**
2409.15338v1 by Evangelia Kyrimi, Scott McLachlan, Jared M Wohlgemut, Zane B Perkins, David A. Lagnado, William Marsh, the ExAIDSS Expert Group

Proposals of artificial intelligence (AI) solutions based on increasingly
complex and accurate predictive models are becoming ubiquitous across many
disciplines. As the complexity of these models grows, transparency and users'
understanding often diminish. This suggests that accurate prediction alone is
insufficient for making an AI-based solution truly useful. In the development
of healthcare systems, this introduces new issues related to accountability and
safety. Understanding how and why an AI system makes a recommendation may
require complex explanations of its inner workings and reasoning processes.
Although research on explainable AI (XAI) has significantly increased in recent
years and there is high demand for XAI in medicine, defining what constitutes a
good explanation remains ad hoc, and providing adequate explanations continues
to be challenging. To fully realize the potential of AI, it is critical to
address two fundamental questions about explanations for safety-critical AI
applications, such as health-AI: (1) What is an explanation in health-AI? and
(2) What are the attributes of a good explanation in health-AI? In this study,
we examined published literature and gathered expert opinions through a
two-round Delphi study. The research outputs include (1) a definition of what
constitutes an explanation in health-AI and (2) a comprehensive list of
attributes that characterize a good explanation in health-AI.

æè¦ï¼é¨èè¶ä¾è¶è¤éä¸æºç¢ºçé æ¸¬æ¨¡åï¼åºæ¼äººå·¥æºæ§ (AI) è§£æ±ºæ¹æ¡çææ¡å¨è¨±å¤é åä¸­è®å¾ç¡èä¸å¨ãé¨èéäºæ¨¡åè¤éæ§çå¢å ï¼éæåº¦åä½¿ç¨èççè§£åå¾å¾æéä½ãéè¡¨ç¤ºåææºç¢ºçé æ¸¬ä¸¦ä¸è¶³ä»¥è® AI è§£æ±ºæ¹æ¡çæ­£æç¨ãå¨é«çä¿å¥ç³»çµ±çéç¼ä¸­ï¼éå¼å¥äºèåè²¬å¶åå®å¨æ§ç¸éçæ°åé¡ãç­è§£ AI ç³»çµ±å¦ä½ä»¥åçºä½æåºå»ºè­°å¯è½éè¦å°å¶å§é¨éä½åæ¨çéç¨é²è¡è¤éçèªªæãåç®¡è¿å¹´ä¾å°å¯è§£é AI (XAI) çç ç©¶å·²å¤§å¹å¢å ï¼ä¸é«å­¸é åå° XAI æå¾é«çéæ±ï¼ä½å®ç¾©ä»éº¼æ§æä¸åå¥½çè§£éä»æ¯è¨ææ§çï¼èæä¾é©ç¶çè§£éä»ç¶å·æææ°æ§ãçºäºååç¼æ® AI çæ½åï¼å°æ¼å®å¨ééµå AI æç¨ï¼ä¾å¦å¥åº· AIï¼çè§£éï¼æ¢è¨å©ååºæ¬åé¡è³ééè¦ï¼(1) ä»éº¼æ¯å¥åº· AI ä¸­çè§£éï¼ä»¥å (2) å¥åº· AI ä¸­ä¸åå¥½çè§£éæåªäºå±¬æ§ï¼å¨æ¬ç ç©¶ä¸­ï¼æåæª¢è¦äºå·²ç¼è¡¨çæç»ï¼ä¸¦ééå©è¼ªå¾·ç¾è²ç ç©¶æ¶éäºå°å®¶æè¦ãç ç©¶ææåæ¬ï¼(1) å¥åº· AI ä¸­ä»éº¼æ§æè§£éçå®ç¾©ï¼ä»¥å (2) å¥åº· AI ä¸­ä¸åå¥½è§£éçå±¬æ§æ¸å®ã

##### **Exploring the Effect of Explanation Content and Format on User Comprehension and Trust**
2408.17401v1 by Antonio Rago, Bence Palfi, Purin Sukpanichnant, Hannibal Nabli, Kavyesh Vivek, Olga Kostopoulou, James Kinross, Francesca Toni

In recent years, various methods have been introduced for explaining the
outputs of "black-box" AI models. However, it is not well understood whether
users actually comprehend and trust these explanations. In this paper, we focus
on explanations for a regression tool for assessing cancer risk and examine the
effect of the explanations' content and format on the user-centric metrics of
comprehension and trust. Regarding content, we experiment with two explanation
methods: the popular SHAP, based on game-theoretic notions and thus potentially
complex for everyday users to comprehend, and occlusion-1, based on feature
occlusion which may be more comprehensible. Regarding format, we present SHAP
explanations as charts (SC), as is conventional, and occlusion-1 explanations
as charts (OC) as well as text (OT), to which their simpler nature also lends
itself. The experiments amount to user studies questioning participants, with
two different levels of expertise (the general population and those with some
medical training), on their subjective and objective comprehension of and trust
in explanations for the outputs of the regression tool. In both studies we
found a clear preference in terms of subjective comprehension and trust for
occlusion-1 over SHAP explanations in general, when comparing based on content.
However, direct comparisons of explanations when controlling for format only
revealed evidence for OT over SC explanations in most cases, suggesting that
the dominance of occlusion-1 over SHAP explanations may be driven by a
preference for text over charts as explanations. Finally, we found no evidence
of a difference between the explanation types in terms of objective
comprehension. Thus overall, the choice of the content and format of
explanations needs careful attention, since in some contexts format, rather
than content, may play the critical role in improving user experience.

æè¦ï¼<paragraph>è¿å¹´ä¾ï¼å·²ç¶å¼é²åç¨®æ¹æ³ä¾è§£éãé»ç®±ãAI æ¨¡åçè¼¸åºãç¶èï¼ç®åä¸¦ä¸æ¸æ¥ä½¿ç¨èæ¯å¦å¯¦éçè§£åä¿¡ä»»éäºè§£éãå¨æ¬æä¸­ï¼æåå°æ³¨æ¼è©ä¼°ççé¢¨éªçåæ­¸å·¥å·çè§£éï¼ä¸¦æ¢è¨è§£éçå§å®¹åæ ¼å¼å°ä»¥ä½¿ç¨èçºä¸­å¿ççè§£åä¿¡ä»»ææ¨çå½±é¿ãéæ¼å§å®¹ï¼æåå¯¦é©äºå©ç¨®è§£éæ¹æ³ï¼æµè¡ç SHAPï¼åºæ¼åå¼è«æ¦å¿µï¼å æ­¤å°æ¼æ¥å¸¸ä½¿ç¨èä¾èªªå¯è½å¾è¤éï¼ä»¥ååºæ¼ç¹å¾µé®è½ç occlusion-1ï¼å¯è½æ´ææ¼çè§£ãéæ¼æ ¼å¼ï¼æåå° SHAP è§£éåç¾çºåè¡¨ (SC)ï¼éæ¯æ£ä¾ï¼èå° occlusion-1 è§£éåç¾çºåè¡¨ (OC) ä»¥åæå­ (OT)ï¼å¶è¼çºç°¡å®çæ§è³ªä¹é©ç¨æ¼æ­¤ãéäºå¯¦é©ç­åæ¼ä½¿ç¨èç ç©¶ï¼è©¢ååèèï¼å·æå©ç¨®ä¸åç¨åº¦çå°æ¥­ç¥è­ï¼ä¸è¬æ°ç¾åå·åä¸äºé«å­¸è¨ç·´çäººï¼ï¼ä»åå°åæ­¸å·¥å·è¼¸åºè§£éçä¸»è§åå®¢è§çè§£åä¿¡ä»»ãå¨å©é ç ç©¶ä¸­ï¼æåç¼ç¾ï¼å¨åºæ¼å§å®¹é²è¡æ¯è¼æï¼ä¸è¬ä¾èªªï¼occlusion-1 åªæ¼ SHAP è§£éï¼å¨ä¸»è§çè§£åä¿¡ä»»æ¹é¢ææé¡¯çåå¥½ãç¶èï¼å¨åæ§å¶æ ¼å¼çææ³ä¸ç´æ¥æ¯è¼è§£éï¼å¨å¤§å¤æ¸ææ³ä¸åªé¡¯ç¤º OT åªæ¼ SC è§£éçè­æï¼éè¡¨æ occlusion-1 åªæ¼ SHAP è§£éçä¸»å°å°ä½å¯è½æ¯ç±åå¥½æå­èéåè¡¨ä½çºè§£éæé©åçãæå¾ï¼æåæ²æç¼ç¾è§£éé¡åå¨å®¢è§çè§£æ¹é¢çå·®ç°è­æãå æ­¤ï¼ç¸½é«èè¨ï¼å°è§£éçå§å®¹åæ ¼å¼çé¸æéè¦ä»ç´°æ³¨æï¼å çºå¨æäºææ³ä¸ï¼æ ¼å¼èéå§å®¹ï¼å¯è½å¨æ¹åä½¿ç¨èé«é©æ¹é¢ç¼æ®ééµä½ç¨ã</paragraph>

##### **A Survey for Large Language Models in Biomedicine**
2409.00133v1 by Chong Wang, Mengyao Li, Junjun He, Zhongruo Wang, Erfan Darzi, Zan Chen, Jin Ye, Tianbin Li, Yanzhou Su, Jing Ke, Kaili Qu, Shuxin Li, Yi Yu, Pietro LiÃ², Tianyun Wang, Yu Guang Wang, Yiqing Shen

Recent breakthroughs in large language models (LLMs) offer unprecedented
natural language understanding and generation capabilities. However, existing
surveys on LLMs in biomedicine often focus on specific applications or model
architectures, lacking a comprehensive analysis that integrates the latest
advancements across various biomedical domains. This review, based on an
analysis of 484 publications sourced from databases including PubMed, Web of
Science, and arXiv, provides an in-depth examination of the current landscape,
applications, challenges, and prospects of LLMs in biomedicine, distinguishing
itself by focusing on the practical implications of these models in real-world
biomedical contexts. Firstly, we explore the capabilities of LLMs in zero-shot
learning across a broad spectrum of biomedical tasks, including diagnostic
assistance, drug discovery, and personalized medicine, among others, with
insights drawn from 137 key studies. Then, we discuss adaptation strategies of
LLMs, including fine-tuning methods for both uni-modal and multi-modal LLMs to
enhance their performance in specialized biomedical contexts where zero-shot
fails to achieve, such as medical question answering and efficient processing
of biomedical literature. Finally, we discuss the challenges that LLMs face in
the biomedicine domain including data privacy concerns, limited model
interpretability, issues with dataset quality, and ethics due to the sensitive
nature of biomedical data, the need for highly reliable model outputs, and the
ethical implications of deploying AI in healthcare. To address these
challenges, we also identify future research directions of LLM in biomedicine
including federated learning methods to preserve data privacy and integrating
explainable AI methodologies to enhance the transparency of LLMs.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çææ°çªç ´æä¾äºåææªæçèªç¶èªè¨çè§£åçæè½åãç¶èï¼ç¾æéæ¼çç©é«å­¸ä¸­ LLM çèª¿æ¥éå¸¸å°æ³¨æ¼ç¹å®æç¨ææ¨¡åæ¶æ§ï¼ç¼ºä¹æ´ååç¨®çç©é«å­¸é åææ°é²å±çå¨é¢åæãæ¬ç¶è¿°åºæ¼å°ä¾èª PubMedãWeb of Science å arXiv ç­æ¸æåº«ç 484 ç¯åºçç©çåæï¼æ·±å¥æ¢è¨äºçç©é«å­¸ä¸­ LLM çç¶åç¾æ³ãæç¨ãææ°ååæ¯ï¼å¶ç¹é»æ¯éæ³¨éäºæ¨¡åå¨ç¾å¯¦ä¸ççç©é«å­¸èæ¯ä¸­çå¯¦éæç¨ãé¦åï¼æåæ¢è¨äº LLM å¨å»£æ³ççç©é«å­¸ä»»åä¸­çé¶æ¬¡å­¸ç¿è½åï¼åæ¬è¨ºæ·è¼å©ãè¥ç©ç¼ç¾ååæ§åé«çç­ï¼ä¸¦å¾ 137 é ééµç ç©¶ä¸­æ±²åè¦è§£ãç¶å¾ï¼æåè¨è«äº LLM çé©æç­ç¥ï¼åæ¬å®æ¨¡æåå¤æ¨¡æ LLM çå¾®èª¿æ¹æ³ï¼ä»¥å¢å¼·å®åå¨é¶æ¬¡å­¸ç¿ç¡æ³å¯¦ç¾çå°æ¥­çç©é«å­¸èæ¯ä¸­çæ§è½ï¼ä¾å¦é«çåé¡è§£ç­åçç©é«å­¸æç»çææèçãæå¾ï¼æåè¨è«äº LLM å¨çç©é«å­¸é åé¢è¨çææ°ï¼åæ¬æ¸æé±ç§åé¡ãæ¨¡åå¯è§£éæ§æéãæ¸æéè³ªéåé¡ä»¥åç±æ¼çç©é«å­¸æ¸æçæææ§ãå°é«åº¦å¯é æ¨¡åè¼¸åºçéæ±ä»¥åå¨é«çä¿å¥ä¸­é¨ç½² AI çå«çå½±é¿èç¢ççå«çåé¡ãçºäºæå°éäºææ°ï¼æåéç¢ºå®äºçç©é«å­¸ä¸­ LLM æªä¾çç ç©¶æ¹åï¼åæ¬ç¨æ¼ä¿è­·æ¸æé±ç§çè¯åå­¸ç¿æ¹æ³ä»¥åæ´åå¯è§£é AI æ¹æ³ä»¥å¢å¼· LLM çéæåº¦ã

##### **Aligning XAI with EU Regulations for Smart Biomedical Devices: A Methodology for Compliance Analysis**
2408.15121v1 by Francesco Sovrano, Michael Lognoul, Giulia Vilone

Significant investment and development have gone into integrating Artificial
Intelligence (AI) in medical and healthcare applications, leading to advanced
control systems in medical technology. However, the opacity of AI systems
raises concerns about essential characteristics needed in such sensitive
applications, like transparency and trustworthiness. Our study addresses these
concerns by investigating a process for selecting the most adequate Explainable
AI (XAI) methods to comply with the explanation requirements of key EU
regulations in the context of smart bioelectronics for medical devices. The
adopted methodology starts with categorising smart devices by their control
mechanisms (open-loop, closed-loop, and semi-closed-loop systems) and delving
into their technology. Then, we analyse these regulations to define their
explainability requirements for the various devices and related goals.
Simultaneously, we classify XAI methods by their explanatory objectives. This
allows for matching legal explainability requirements with XAI explanatory
goals and determining the suitable XAI algorithms for achieving them. Our
findings provide a nuanced understanding of which XAI algorithms align better
with EU regulations for different types of medical devices. We demonstrate this
through practical case studies on different neural implants, from chronic
disease management to advanced prosthetics. This study fills a crucial gap in
aligning XAI applications in bioelectronics with stringent provisions of EU
regulations. It provides a practical framework for developers and researchers,
ensuring their AI innovations advance healthcare technology and adhere to legal
and ethical standards.

æè¦ï¼äººå·¥æºæ§ï¼AIï¼å¨é«çåä¿å¥æç¨ä¸­æå¥äºå¤§éçæè³åéç¼ï¼é²èå°è´é«çæè¡ä¸­çåé²æ§å¶ç³»çµ±ãç¶èï¼AI ç³»çµ±çä¸éææ§å¼ç¼äºå°æ­¤é¡æææç¨ä¸­æéåºæ¬ç¹æ§çææï¼ä¾å¦éæåº¦åå¯ä¿¡åº¦ãæåçç ç©¶ééèª¿æ¥ä¸åç¨åºä¾è§£æ±ºéäºåé¡ï¼ç¨æ¼é¸ææååçå¯è§£é AIï¼XAIï¼æ¹æ³ï¼ä»¥ç¬¦åæ­çæ³è¦å¨é«çå¨æçæºæ§åçç©é»å­å­¸ä¸­çèªªæè¦æ±ãæ¡ç¨çæ¹æ³å¾ééå¶æ§å¶æ©å¶ï¼éè¿´è·¯ãéè¿´è·¯ååéè¿´è·¯ç³»çµ±ï¼å°æºæ§åè£ç½®é²è¡åé¡ï¼ä¸¦æ·±å¥æ¢è¨å¶æè¡éå§ãç¶å¾ï¼æååæéäºæ³è¦ä»¥å®ç¾©å¶å°åç¨®è£ç½®åç¸éç®æ¨çå¯è§£éæ§è¦æ±ãåæï¼æåééå¶èªªæç®æ¨å° XAI æ¹æ³é²è¡åé¡ãéåè¨±å°æ³å¾å¯è§£éæ§è¦æ±è XAI èªªæç®æ¨ç¸å¹éï¼ä¸¦ç¢ºå®é©ç¶ç XAI æ¼ç®æ³ä¾éæå®åãæåçç ç©¶çµææä¾äºå°åªäº XAI æ¼ç®æ³æ´ç¬¦åæ­çæ³è¦ä»¥é©ç¨æ¼ä¸åé¡åçé«çå¨æçç´°ç·»çè§£ãæåééä¸åç¥ç¶æ¤å¥ç©çå¯¦éæ¡ä¾ç ç©¶ä¾è­æéä¸é»ï¼å¾æ¢æ§ç¾çç®¡çå°åé²çç¾©è¢ãéé ç ç©¶å¡«è£äºå°çç©é»å­å­¸ä¸­ç XAI æç¨èæ­çæ³è¦çå´æ ¼è¦å®ç¸ç¬¦çéè¦ç©ºç½ãå®çºéç¼äººå¡åç ç©¶äººå¡æä¾äºä¸åå¯¦ç¨çæ¶æ§ï¼ç¢ºä¿å¶ AI åµæ°è½ä¿é²é«çæè¡ä¸¦éµå®æ³å¾åéå¾·æ¨æºã

##### **Towards Case-based Interpretability for Medical Federated Learning**
2408.13626v1 by Laura Latorre, Liliana Petrychenko, Regina Beets-Tan, Taisiya Kopytova, Wilson Silva

We explore deep generative models to generate case-based explanations in a
medical federated learning setting. Explaining AI model decisions through
case-based interpretability is paramount to increasing trust and allowing
widespread adoption of AI in clinical practice. However, medical AI training
paradigms are shifting towards federated learning settings in order to comply
with data protection regulations. In a federated scenario, past data is
inaccessible to the current user. Thus, we use a deep generative model to
generate synthetic examples that protect privacy and explain decisions. Our
proof-of-concept focuses on pleural effusion diagnosis and uses publicly
available Chest X-ray data.

æè¦ï¼æåæ¢ç´¢æ·±åº¦çææ¨¡åï¼å¨é«çè¯é¦å­¸ç¿è¨­ç½®ä¸­çæåºæ¼æ¡ä¾çèªªæãééåºæ¼æ¡ä¾çå¯è§£éæ§ä¾è§£é AI æ¨¡åæ±ºç­ï¼å°æ¼å¢å ä¿¡ä»»ä¸¦åè¨± AI å¨è¨åºå¯¦åä¸­å»£æ³æ¡ç¨è³ééè¦ãç¶èï¼é«ç AI è¨ç·´ç¯ä¾æ­£è½åè¯é¦å­¸ç¿è¨­ç½®ï¼ä»¥ç¬¦åè³æä¿è­·æ³è¦ãå¨è¯é¦æå¢ä¸­ï¼éå»çè³æå°ç®åçä½¿ç¨èèè¨æ¯ç¡æ³åå¾çãå æ­¤ï¼æåä½¿ç¨æ·±åº¦çææ¨¡åä¾ç¢çä¿è­·é±ç§åè§£éæ±ºç­çåæç¯ä¾ãæåçæ¦å¿µé©è­èéæ¼è¸èç©æ¶²è¨ºæ·ï¼ä¸¦ä½¿ç¨å¬éå¯åå¾çè¸é¨ X åè³æã

##### **AI in radiological imaging of soft-tissue and bone tumours: a systematic review evaluating against CLAIM and FUTURE-AI guidelines**
2408.12491v1 by Douwe J. Spaanderman, Matthew Marzetti, Xinyi Wan, Andrew F. Scarsbrook, Philip Robinson, Edwin H. G. Oei, Jacob J. Visser, Robert Hemke, Kirsten van Langevelde, David F. Hanff, Geert J. L. H. van Leenders, Cornelis Verhoef, Dirk J. GruÃ¼hagen, Wiro J. Niessen, Stefan Klein, Martijn P. A. Starmans

Soft-tissue and bone tumours (STBT) are rare, diagnostically challenging
lesions with variable clinical behaviours and treatment approaches. This
systematic review provides an overview of Artificial Intelligence (AI) methods
using radiological imaging for diagnosis and prognosis of these tumours,
highlighting challenges in clinical translation, and evaluating study alignment
with the Checklist for AI in Medical Imaging (CLAIM) and the FUTURE-AI
international consensus guidelines for trustworthy and deployable AI to promote
the clinical translation of AI methods. The review covered literature from
several bibliographic databases, including papers published before 17/07/2024.
Original research in peer-reviewed journals focused on radiology-based AI for
diagnosing or prognosing primary STBT was included. Exclusion criteria were
animal, cadaveric, or laboratory studies, and non-English papers. Abstracts
were screened by two of three independent reviewers for eligibility. Eligible
papers were assessed against guidelines by one of three independent reviewers.
The search identified 15,015 abstracts, from which 325 articles were included
for evaluation. Most studies performed moderately on CLAIM, averaging a score
of 28.9$\pm$7.5 out of 53, but poorly on FUTURE-AI, averaging 5.1$\pm$2.1 out
of 30. Imaging-AI tools for STBT remain at the proof-of-concept stage,
indicating significant room for improvement. Future efforts by AI developers
should focus on design (e.g. define unmet clinical need, intended clinical
setting and how AI would be integrated in clinical workflow), development (e.g.
build on previous work, explainability), evaluation (e.g. evaluating and
addressing biases, evaluating AI against best practices), and data
reproducibility and availability (making documented code and data publicly
available). Following these recommendations could improve clinical translation
of AI methods.

æè¦ï¼è»çµç¹åéª¨éª¼è«ç¤ï¼STBTï¼æ¯ç½è¦ãè¨ºæ·å·æææ°æ§ççç¶ï¼å¶è¨åºè¡çºåæ²»çæ¹æ³åä¸ç¸åãéç¯ç³»çµ±æ§åé¡§æä¾äºä½¿ç¨æ¾å°å½±åé²è¡è¨ºæ·åé å¾çäººå·¥æºæ§ (AI) æ¹æ³çæ¦è§ï¼éé»èªªæäºè¨åºè½è­¯çææ°ï¼ä¸¦è©ä¼°ç ç©¶èé«çå½±å AI æ ¸æ¥è¡¨ (CLAIM) å FUTURE-AI å¯ä¿¡è³´ä¸å¯é¨ç½² AI çåéå±è­æºåçä¸è´æ§ï¼ä»¥ä¿é² AI æ¹æ³çè¨åºè½è­¯ãéç¯åé¡§æ¶µèäºå¹¾åæ¸ç®è³æåº«ä¸­çæç»ï¼åæ¬å¨ 2024 å¹´ 7 æ 17 æ¥ä¹åç¼è¡¨çè«æãç´å¥äºä»¥æ¾å°çºåºç¤ç AI è¨ºæ·æé å¾åç¼æ§ STBT çåè¡è©å¯©æåä¸­çåå§ç ç©¶ãæé¤æ¨æºæ¯åç©ãå±é«æå¯¦é©å®¤ç ç©¶ï¼ä»¥åéè±æè«æãæè¦ç±ä¸ä½ç¨ç«å¯©æ¥å¡ä¸­çå©ä½ç¯©é¸è³æ ¼ãåæ ¼çè«æç±ä¸ä½ç¨ç«å¯©æ¥å¡ä¸­çä¸ä½æ ¹ææºåé²è¡è©ä¼°ãæç´¢è­å¥åº 15,015 ç¯æè¦ï¼å¶ä¸­ 325 ç¯æç« è¢«ç´å¥è©ä¼°ãå¤§å¤æ¸ç ç©¶å¨ CLAIM ä¸­è¡¨ç¾ä¸­ç­ï¼å¹³åå¾åçº 53 åä¸­ç 28.9Â±7.5 åï¼ä½å¨ FUTURE-AI ä¸­è¡¨ç¾ä¸ä½³ï¼å¹³åå¾åçº 30 åä¸­ç 5.1Â±2.1 åãSTBT çå½±å AI å·¥å·ä»èæ¼æ¦å¿µé©è­éæ®µï¼è¡¨ææé¡¯èçæ¹é²ç©ºéãAI éç¼äººå¡æªä¾çåªåæéä¸­å¨è¨­è¨ï¼ä¾å¦å®ç¾©æªæ»¿è¶³çè¨åºéæ±ãé æçè¨åºç°å¢ä»¥å AI å¦ä½æ´åå°è¨åºå·¥ä½æµç¨ä¸­ï¼ãéç¼ï¼ä¾å¦å»ºç«å¨ååçå·¥ä½ãå¯è§£éæ§ï¼ãè©ä¼°ï¼ä¾å¦è©ä¼°åè§£æ±ºåå·®ãè©ä¼° AI èæä½³å¯¦åï¼ãä»¥åæ¸æå¯è¤è£½æ§åå¯ç¨æ§ï¼å¬éæä¾æä»¶åçä»£ç¢¼åæ¸æï¼ãéµå¾ªéäºå»ºè­°å¯ä»¥æ¹å AI æ¹æ³çè¨åºè½è­¯ã

##### **Evaluating Explainable AI Methods in Deep Learning Models for Early Detection of Cerebral Palsy**
2409.00001v1 by Kimji N. Pellano, Inga StrÃ¼mke, Daniel Groos, Lars Adde, Espen Alexander F. Ihlen

Early detection of Cerebral Palsy (CP) is crucial for effective intervention
and monitoring. This paper tests the reliability and applicability of
Explainable AI (XAI) methods using a deep learning method that predicts CP by
analyzing skeletal data extracted from video recordings of infant movements.
Specifically, we use XAI evaluation metrics -- namely faithfulness and
stability -- to quantitatively assess the reliability of Class Activation
Mapping (CAM) and Gradient-weighted Class Activation Mapping (Grad-CAM) in this
specific medical application. We utilize a unique dataset of infant movements
and apply skeleton data perturbations without distorting the original dynamics
of the infant movements. Our CP prediction model utilizes an ensemble approach,
so we evaluate the XAI metrics performances for both the overall ensemble and
the individual models. Our findings indicate that both XAI methods effectively
identify key body points influencing CP predictions and that the explanations
are robust against minor data perturbations. Grad-CAM significantly outperforms
CAM in the RISv metric, which measures stability in terms of velocity. In
contrast, CAM performs better in the RISb metric, which relates to bone
stability, and the RRS metric, which assesses internal representation
robustness. Individual models within the ensemble show varied results, and
neither CAM nor Grad-CAM consistently outperform the other, with the ensemble
approach providing a representation of outcomes from its constituent models.

æè¦ï¼è¦æ§éº»çº (CP) çæ©æåµæ¸¬å°æ¼ææçä»å¥åç£æ¸¬è³ééè¦ãæ¬ææ¸¬è©¦äºå¯è§£é AI (XAI) æ¹æ³çå¯é æ§åé©ç¨æ§ï¼ä½¿ç¨æ·±åº¦å­¸ç¿æ¹æ³ï¼ééåæå¾å¬°ååä½å½±çè¨éä¸­æåçéª¨éª¼è³æä¾é æ¸¬ CPãå·é«ä¾èªªï¼æåä½¿ç¨ XAI è©ä¼°ææ¨ï¼å³å¿ å¯¦åº¦åç©©å®æ§ï¼ä¾éåè©ä¼°é¡å¥æ¿æ´»æ å° (CAM) åæ¢¯åº¦å æ¬é¡å¥æ¿æ´»æ å° (Grad-CAM) å¨éåç¹å®é«çæç¨ä¸­çå¯é æ§ãæåå©ç¨ä¸åç¨ç¹çå¬°ååä½è³æéï¼ä¸¦æç¨éª¨éª¼è³ææ¾åï¼èä¸ææ­æ²å¬°ååä½çåå§ååãæåç CP é æ¸¬æ¨¡åå©ç¨æ´é«æ¹æ³ï¼å æ­¤æåè©ä¼°äºæ´é«æ´é«ååå¥æ¨¡åç XAI ææ¨è¡¨ç¾ãæåçç ç©¶çµæè¡¨æï¼å©ç¨® XAI æ¹æ³é½è½ææè­å¥å½±é¿ CP é æ¸¬çééµèº«é«é¨ä½ï¼ä¸¦ä¸éäºè§£éå°æ¼å¾®å°çè³ææ¾åå·æé­¯æ£æ§ãGrad-CAM å¨ RISv ææ¨ä¸­é¡¯èåªæ¼ CAMï¼è©²ææ¨è¡¡ééåº¦æ¹é¢çç©©å®æ§ãç¸æ¯ä¹ä¸ï¼CAM å¨ RISb ææ¨ä¸­è¡¨ç¾å¾æ´å¥½ï¼è©²ææ¨èéª¨éª¼ç©©å®æ§æéï¼è RRS ææ¨åè©ä¼°å§é¨è¡¨ç¤ºçé­¯æ£æ§ãæ´é«ä¸­çåå¥æ¨¡åé¡¯ç¤ºåºä¸åççµæï¼CAM å Grad-CAM é½ä¸ä¸è´å°åªæ¼å¦ä¸ç¨®ï¼æ´é«æ¹æ³æä¾äºå¶çµææ¨¡åçµæçè¡¨ç¤ºã

##### **MicroXercise: A Micro-Level Comparative and Explainable System for Remote Physical Therapy**
2408.11837v1 by Hanchen David Wang, Nibraas Khan, Anna Chen, Nilanjan Sarkar, Pamela Wisniewski, Meiyi Ma

Recent global estimates suggest that as many as 2.41 billion individuals have
health conditions that would benefit from rehabilitation services. Home-based
Physical Therapy (PT) faces significant challenges in providing interactive
feedback and meaningful observation for therapists and patients. To fill this
gap, we present MicroXercise, which integrates micro-motion analysis with
wearable sensors, providing therapists and patients with a comprehensive
feedback interface, including video, text, and scores. Crucially, it employs
multi-dimensional Dynamic Time Warping (DTW) and attribution-based explainable
methods to analyze the existing deep learning neural networks in monitoring
exercises, focusing on a high granularity of exercise. This synergistic
approach is pivotal, providing output matching the input size to precisely
highlight critical subtleties and movements in PT, thus transforming complex AI
analysis into clear, actionable feedback. By highlighting these micro-motions
in different metrics, such as stability and range of motion, MicroXercise
significantly enhances the understanding and relevance of feedback for
end-users. Comparative performance metrics underscore its effectiveness over
traditional methods, such as a 39% and 42% improvement in Feature Mutual
Information (FMI) and Continuity. MicroXercise is a step ahead in home-based
physical therapy, providing a technologically advanced and intuitively helpful
solution to enhance patient care and outcomes.

æè¦ï¼æè¿çå¨çä¼°è¨è¡¨æï¼å¤é 24.1 åäººæ
å¥åº·çæ³å¯å¾å¾©å¥æåä¸­åçãå±å®¶
ç©çæ²»ç (PT) å¨æä¾äºåå¼
åé¥åææç¾©çè§å¯æ¹é¢é¢è¨éå¤§ææ°ï¼ä¾æ²»çå¸«åæ£èä½¿ç¨ãçºäºå¡«è£é
åç¼ºå£ï¼æåæåº MicroXerciseï¼å®å°å¾®åä½åæè
å¯ç©¿æ´å¼ææ¸¬å¨æ´åå¨ä¸èµ·ï¼çºæ²»çå¸«åæ£èæä¾ä¸åå¨é¢ç
åé¥ä»é¢ï¼åæ¬å½±çãæå­ååæ¸ãè³ééè¦çæ¯ï¼å®æ¡ç¨
å¤ç¶­åææéè¦æ´ (DTW) ååºæ¼æ­¸å çå¯è§£é
æ¹æ³ä¾åæç£æ§éåä¸­ç¾æçæ·±åº¦å­¸ç¿ç¥ç¶ç¶²è·¯ï¼å°æ³¨æ¼éåçé«ç²åº¦ãéç¨®åå
æ¹æ³è³ééè¦ï¼æä¾èè¼¸å¥å¤§å°å¹éçè¼¸åºï¼ä»¥ç²¾ç¢ºå°
çªåº PT ä¸­ééµçç´°å¾®å·®å¥ååä½ï¼å¾èå°è¤éç AI
åæè½æçºæ¸æ°ãå¯æä½çåé¥ãééå¨ä¸åææ¨ä¸­çªé¡¯éäºå¾®åä½ï¼ä¾å¦ç©©å®æ§ååä½ç¯åï¼MicroXercise
é¡¯èæåæçµä½¿ç¨èå°åé¥ççè§£åç¸éæ§ãæ¯è¼æè½ææ¨å¼·èª¿å¶åªæ¼
å³çµ±æ¹æ³çæææ§ï¼ä¾å¦ç¹å¾µäºæ è³è¨ (FMI) åé£çºæ§åå¥æåäº 39% å 42%ãMicroXercise å¨å±å®¶
ç©çæ²»çæ¹é¢æ´é²ä¸æ­¥ï¼æä¾æè¡åé²ä¸ç´è¦ºæç¨ç
è§£æ±ºæ¹æ¡ï¼ä»¥æåæ£èç§è­·åçµæã

##### **The Literature Review Network: An Explainable Artificial Intelligence for Systematic Literature Reviews, Meta-analyses, and Method Development**
2408.05239v1 by Joshua Morriss, Tod Brindle, Jessica Bah RÃ¶sman, Daniel Reibsamen, Andreas Enz

Systematic literature reviews are the highest quality of evidence in
research. However, the review process is hindered by significant resource and
data constraints. The Literature Review Network (LRN) is the first of its kind
explainable AI platform adhering to PRISMA 2020 standards, designed to automate
the entire literature review process. LRN was evaluated in the domain of
surgical glove practices using 3 search strings developed by experts to query
PubMed. A non-expert trained all LRN models. Performance was benchmarked
against an expert manual review. Explainability and performance metrics
assessed LRN's ability to replicate the experts' review. Concordance was
measured with the Jaccard index and confusion matrices. Researchers were
blinded to the other's results until study completion. Overlapping studies were
integrated into an LRN-generated systematic review. LRN models demonstrated
superior classification accuracy without expert training, achieving 84.78% and
85.71% accuracy. The highest performance model achieved high interrater
reliability (k = 0.4953) and explainability metrics, linking 'reduce',
'accident', and 'sharp' with 'double-gloving'. Another LRN model covered 91.51%
of the relevant literature despite diverging from the non-expert's judgments (k
= 0.2174), with the terms 'latex', 'double' (gloves), and 'indication'. LRN
outperformed the manual review (19,920 minutes over 11 months), reducing the
entire process to 288.6 minutes over 5 days. This study demonstrates that
explainable AI does not require expert training to successfully conduct
PRISMA-compliant systematic literature reviews like an expert. LRN summarized
the results of surgical glove studies and identified themes that were nearly
identical to the clinical researchers' findings. Explainable AI can accurately
expedite our understanding of clinical practices, potentially revolutionizing
healthcare research.

æè¦ï¼ç³»çµ±æ§æç»åé¡§æ¯ç ç©¶ä¸­è­æåè³ªæé«çãç¶èï¼åé¡§éç¨åå°é¡¯èè³æºåè³æéå¶çé»ç¤ãæç»åé¡§ç¶²è·¯ (LRN) æ¯ç¬¬ä¸åéµå¾ª PRISMA 2020 æ¨æºçå¯è§£é AI å¹³å°ï¼æ¨å¨èªååæ´åæç»åé¡§éç¨ãLRN å¨å¤ç§æå¥å¯¦åé åä¸­é²è¡è©ä¼°ï¼ä½¿ç¨å°å®¶éç¼ç 3 åæå°å­ä¸²ä¾æ¥è©¢ PubMedãéå°å®¶è¨ç·´ææ LRN æ¨¡åãæè½ä»¥å°å®¶æååé¡§ä½çºåºæºãå¯è§£éæ§åæè½ææ¨è©ä¼° LRN è¤è£½å°å®¶åé¡§çè½åãä¸è´æ§ä»¥ Jaccard ææ¸åæ··æ·ç©é£æ¸¬éãç ç©¶äººå¡å¨ç ç©¶å®æåå°å½¼æ­¤ççµæä¿å¯ãéççç ç©¶æ´åå° LRN çæçç³»çµ±æ§åé¡§ä¸­ãLRN æ¨¡åå¨æ²æå°å®¶è¨ç·´çææ³ä¸å±ç¾åºåªç°çåé¡æºç¢ºçï¼éå° 84.78% å 85.71% çæºç¢ºçãæè½æé«çæ¨¡åéå°äºé«è©åèéä¿¡è³´åº¦ (k = 0.4953) åå¯è§£éæ§ææ¨ï¼å°ãæ¸å°ãããæå¤ãåãé³å©ãèãééæ´æå¥ãé£çµå¨ä¸èµ·ãå¦ä¸å LRN æ¨¡åæ¶µèäº 91.51% çç¸éæç»ï¼åç®¡èéå°å®¶çå¤æ·ä¸å (k = 0.2174)ï¼ä½åå«äºãä¹³è ãããééãï¼æå¥ï¼åãé©æçãç­è©å½ãLRN åªæ¼æååé¡§ï¼11 åæè¶é 19,920 åéï¼ï¼å°æ´åéç¨ç¸®ç­çº 5 å¤©è¶é 288.6 åéãéé ç ç©¶é¡¯ç¤ºï¼å¯è§£éç AI ä¸éè¦å°å®¶è¨ç·´å³å¯æåé²è¡å°å®¶ç­ç´ç PRISMA ç¸å®¹ç³»çµ±æ§æç»åé¡§ãLRN ç¸½çµäºå¤ç§æå¥ç ç©¶ççµæï¼ä¸¦æ¾åºèè¨åºç ç©¶äººå¡ç¼ç¾å¹¾ä¹ç¸åçä¸»é¢ãå¯è§£éç AI å¯ä»¥æºç¢ºå°å å¿«æåå°è¨åºå¯¦åççè§£ï¼ææ½åé©æ°é«çä¿å¥ç ç©¶ã

##### **Enhancing Medical Learning and Reasoning Systems: A Boxology-Based Comparative Analysis of Design Patterns**
2408.02709v1 by Chi Him Ng

This study analyzes hybrid AI systems' design patterns and their
effectiveness in clinical decision-making using the boxology framework. It
categorizes and copares various architectures combining machine learning and
rule-based reasoning to provide insights into their structural foundations and
healthcare applications. Addressing two main questions, how to categorize these
systems againts established design patterns and how to extract insights through
comparative analysis, the study uses design patterns from software engineering
to understand and optimize healthcare AI systems. Boxology helps identify
commonalities and create reusable solutions, enhancing these systems'
scalability, reliability, and performance. Five primary architectures are
examined: REML, MLRB, RBML, RMLT, and PERML. Each has unique strengths and
weaknesses, highlighting the need for tailored approaches in clinical tasks.
REML excels in high-accuracy prediction for datasets with limited data; MLRB in
handling large datasets and complex data integration; RBML in explainability
and trustworthiness; RMLT in managing high-dimensional data; and PERML, though
limited in analysis, shows promise in urgent care scenarios. The study
introduces four new patterns, creates five abstract categorization patterns,
and refines those five further to specific systems. These contributions enhance
Boxlogy's taxonomical organization and offer novel approaches to integrating
expert knowledge with machine learning. Boxology's structured, modular apporach
offers significant advantages in developing and analyzing hybrid AI systems,
revealing commonalities, and promoting reusable solutions. In conclusion, this
study underscores hybrid AI systems' crucial role in advancing healthcare and
Boxology's potential to drive further innovation in AI integration, ultimately
improving clinical decision support and patient outcomes.

æè¦ï¼æ¬ç ç©¶ä½¿ç¨çå­å­¸æ¡æ¶åææ··åäººå·¥æºæ§ç³»çµ±çè¨­è¨æ¨¡å¼åå¶å¨è¨åºæ±ºç­ä¸­çæææ§ãå®åé¡ä¸¦æ¯è¼çµåæ©å¨å­¸ç¿ååºæ¼è¦åçæ¨ççåç¨®æ¶æ§ï¼ä»¥æ·±å¥äºè§£å¶çµæ§åºç¤åé«çä¿å¥æç¨ãéå°å©åä¸»è¦åé¡ï¼å¦ä½æ ¹ææ¢å®çè¨­è¨æ¨¡å¼å°éäºç³»çµ±é²è¡åé¡ï¼ä»¥åå¦ä½ééæ¯è¼åææåè¦è§£ï¼æ¬ç ç©¶ä½¿ç¨è»é«å·¥ç¨ä¸­çè¨­è¨æ¨¡å¼ä¾äºè§£ååªåé«çä¿å¥äººå·¥æºæ§ç³»çµ±ãçå­å­¸æå©æ¼è­å¥å±æ§ä¸¦å»ºç«å¯éè¤ä½¿ç¨çè§£æ±ºæ¹æ¡ï¼å¾èå¢å¼·éäºç³»çµ±çå¯æ´åæ§ãå¯é æ§åæè½ãæª¢æ¥äºäºç¨®ä¸»è¦çæ¶æ§ï¼REMLãMLRBãRBMLãRMLT å PERMLãæ¯ç¨®æ¶æ§é½æç¨ç¹çåªç¼ºé»ï¼å¼·èª¿äºå¨è¨åºä»»åä¸­éè¦éèº«æé çæ¹æ³ãREML å¨è³ææéçè³æéä¸­è¡¨ç¾åºé«ç²¾åº¦çé æ¸¬ï¼MLRB å¨èçå¤§åè³æéåè¤éè³ææ´åæ¹é¢è¡¨ç¾åºè²ï¼RBML å¨å¯è§£éæ§åå¯ä¿¡åº¦æ¹é¢è¡¨ç¾åºè²ï¼RMLT å¨ç®¡çé«ç¶­è³ææ¹é¢è¡¨ç¾åºè²ï¼è PERML åç®¡å¨åææ¹é¢æéï¼ä½å¨ç·æ¥ç§è­·å ´æ¯ä¸­è¡¨ç¾åºæ½åãæ¬ç ç©¶å¼å¥äºåç¨®æ°æ¨¡å¼ï¼å»ºç«äºäºç¨®æ½è±¡åé¡æ¨¡å¼ï¼ä¸¦é²ä¸æ­¥å°éäºç¨®æ¨¡å¼ç´°åçºå·é«çç³»çµ±ãéäºè²¢ç»å¢å¼·äºçå­å­¸çåé¡çµç¹ï¼ä¸¦æä¾äºå°å°å®¶ç¥è­èæ©å¨å­¸ç¿æ´åçæ°æ¹æ³ãçå­å­¸ççµæ§åãæ¨¡çµåæ¹æ³å¨éç¼ååææ··åäººå·¥æºæ§ç³»çµ±ãæ­ç¤ºå±æ§ä»¥åæ¨å»£å¯éè¤ä½¿ç¨çè§£æ±ºæ¹æ¡æ¹é¢å·æé¡¯èåªå¢ãç¸½ä¹ï¼æ¬ç ç©¶å¼·èª¿äºæ··åäººå·¥æºæ§ç³»çµ±å¨æ¨é²é«çä¿å¥ä¸­çééµä½ç¨ï¼ä»¥åçå­å­¸å¨æ¨åäººå·¥æºæ§æ´åé²ä¸æ­¥åµæ°æ¹é¢çæ½åï¼æçµæ¹åè¨åºæ±ºç­æ¯æ´åæ£èçæ²»çææã

##### **Bayesian Kolmogorov Arnold Networks (Bayesian_KANs): A Probabilistic Approach to Enhance Accuracy and Interpretability**
2408.02706v1 by Masoud Muhammed Hassan

Because of its strong predictive skills, deep learning has emerged as an
essential tool in many industries, including healthcare. Traditional deep
learning models, on the other hand, frequently lack interpretability and omit
to take prediction uncertainty into account two crucial components of clinical
decision making. In order to produce explainable and uncertainty aware
predictions, this study presents a novel framework called Bayesian Kolmogorov
Arnold Networks (BKANs), which combines the expressive capacity of Kolmogorov
Arnold Networks with Bayesian inference. We employ BKANs on two medical
datasets, which are widely used benchmarks for assessing machine learning
models in medical diagnostics: the Pima Indians Diabetes dataset and the
Cleveland Heart Disease dataset. Our method provides useful insights into
prediction confidence and decision boundaries and outperforms traditional deep
learning models in terms of prediction accuracy. Moreover, BKANs' capacity to
represent aleatoric and epistemic uncertainty guarantees doctors receive more
solid and trustworthy decision support. Our Bayesian strategy improves the
interpretability of the model and considerably minimises overfitting, which is
important for tiny and imbalanced medical datasets, according to experimental
results. We present possible expansions to further use BKANs in more
complicated multimodal datasets and address the significance of these
discoveries for future research in building reliable AI systems for healthcare.
This work paves the way for a new paradigm in deep learning model deployment in
vital sectors where transparency and reliability are crucial.

æè¦ï¼ç±æ¼å¶å¼·å¤§çé æ¸¬è½åï¼æ·±åº¦å­¸ç¿å·²æçºè¨±å¤ç¢æ¥­ä¸­ä¸å¯æç¼ºçå·¥å·ï¼åæ¬é«çä¿å¥ãç¶èï¼å³çµ±çæ·±åº¦å­¸ç¿æ¨¡åéå¸¸ç¼ºä¹å¯è§£éæ§ï¼ä¸¦ä¸å¿½ç¥äºå°é æ¸¬ä¸ç¢ºå®æ§ç´å¥èéï¼èéå©åå ç´ æ¯è¨åºæ±ºç­å¶å®çééµçµæé¨åãçºäºç¢çå¯è§£éä¸å·æä¸ç¢ºå®æ§æè­çé æ¸¬ï¼æ¬ç ç©¶æåºäºä¸ååçºè²æ°æ¯ç¾è«å¥æ´å¤«é¿è«¾å¾·ç¶²è·¯ (BKAN) çæ°æ¶æ§ï¼å®çµåäºæ¯ç¾è«å¥æ´å¤«é¿è«¾å¾·ç¶²è·¯çè¡¨éè½åèè²æ°æ¨è«ãæåå¨å©åé«å­¸è³æéä¸ä½¿ç¨ BKANï¼éäºè³æéæ¯è©ä¼°æ©å¨å­¸ç¿æ¨¡åå¨é«å­¸è¨ºæ·ä¸­çå»£æ³ä½¿ç¨åºæºï¼ç®é¦¬å°ç¬¬å®äººç³å°¿çè³æéååéå¤«è­å¿èçè³æéãæåçæ¨¡åæä¾äºå°é æ¸¬ä¿¡å¿åæ±ºç­éççæçè¦è§£ï¼ä¸¦ä¸å¨é æ¸¬æºç¢ºåº¦æ¹é¢åªæ¼å³çµ±çæ·±åº¦å­¸ç¿æ¨¡åãæ­¤å¤ï¼BKAN è¡¨ç¾é¨æ©åèªè­ä¸ç¢ºå®æ§çè½åï¼å¯ç¢ºä¿é«çç²å¾æ´å¯é ä¸å¼å¾ä¿¡è³´çæ±ºç­æ¯æ´ãæ ¹æå¯¦é©çµæï¼æåçè²æ°ç­ç¥æé«äºæ¨¡åçå¯è§£éæ§ï¼ä¸¦å¤§å¹æ¸å°äºéåº¦æ¬åï¼éå°æ¼å°åä¸ä¸å¹³è¡¡çé«å­¸è³æééå¸¸éè¦ãæåæåºäºå¯è½çæ´ååè½ï¼ä»¥é²ä¸æ­¥å° BKAN ç¨æ¼æ´è¤éçå¤æ¨¡å¼è³æéï¼ä¸¦æ¢è¨éäºç¼ç¾å°æ¼æªä¾å»ºç«å¯é çé«çä¿å¥ AI ç³»çµ±ç ç©¶çéè¦æ§ãéé å·¥ä½çºæ·±åº¦å­¸ç¿æ¨¡åé¨ç½²å¨éæåº¦åå¯é æ§è³ééè¦çéè¦é åä¸­éåäºä¸åæ°çå¸ç¯ã

##### **MLtoGAI: Semantic Web based with Machine Learning for Enhanced Disease Prediction and Personalized Recommendations using Generative AI**
2407.20284v1 by Shyam Dongre, Ritesh Chandra, Sonali Agarwal

In modern healthcare, addressing the complexities of accurate disease
prediction and personalized recommendations is both crucial and challenging.
This research introduces MLtoGAI, which integrates Semantic Web technology with
Machine Learning (ML) to enhance disease prediction and offer user-friendly
explanations through ChatGPT. The system comprises three key components: a
reusable disease ontology that incorporates detailed knowledge about various
diseases, a diagnostic classification model that uses patient symptoms to
detect specific diseases accurately, and the integration of Semantic Web Rule
Language (SWRL) with ontology and ChatGPT to generate clear, personalized
health advice. This approach significantly improves prediction accuracy and
ensures results that are easy to understand, addressing the complexity of
diseases and diverse symptoms. The MLtoGAI system demonstrates substantial
advancements in accuracy and user satisfaction, contributing to developing more
intelligent and accessible healthcare solutions. This innovative approach
combines the strengths of ML algorithms with the ability to provide
transparent, human-understandable explanations through ChatGPT, achieving
significant improvements in prediction accuracy and user comprehension. By
leveraging semantic technology and explainable AI, the system enhances the
accuracy of disease prediction and ensures that the recommendations are
relevant and easily understood by individual patients. Our research highlights
the potential of integrating advanced technologies to overcome existing
challenges in medical diagnostics, paving the way for future developments in
intelligent healthcare systems. Additionally, the system is validated using 200
synthetic patient data records, ensuring robust performance and reliability.

æè¦ï¼å¨ç¾ä»£é«çä¿å¥ä¸­ï¼è§£æ±ºæºç¢ºç¾çé æ¸¬ååæ§åå»ºè­°çè¤éæ§æ¢è³ééè¦åå·æææ°æ§ãæ¬ç ç©¶å¼å¥äº MLtoGAIï¼å®å°èªç¾©ç¶²è·¯æè¡èæ©å¨å­¸ç¿ (ML) ç¸çµåï¼ä»¥å¢å¼·ç¾çé æ¸¬ä¸¦éé ChatGPT æä¾ä½¿ç¨èååçèªªæãè©²ç³»çµ±åå«ä¸åééµçµæé¨åï¼ä¸åå¯éè¤ä½¿ç¨çç¾çæ¬ä½ï¼å¶ä¸­åå«æéåç¨®ç¾ççè©³ç´°ç¥è­ï¼ä¸åè¨ºæ·åé¡æ¨¡åï¼å®ä½¿ç¨æ£èççä¾æºç¢ºæª¢æ¸¬ç¹å®ç¾çï¼ä»¥åèªç¾©ç¶²è·¯è¦åèªè¨ (SWRL) èæ¬ä½å ChatGPT çæ´åï¼ä»¥ç¢çæ¸æ°ãåæ§åçå¥åº·å»ºè­°ãéç¨®æ¹æ³é¡¯èæé«äºé æ¸¬æºç¢ºæ§ï¼ä¸¦ç¢ºä¿äºææ¼çè§£ççµæï¼è§£æ±ºäºç¾çåä¸åçççè¤éæ§ãMLtoGAI ç³»çµ±å±ç¤ºäºæºç¢ºæ§åä½¿ç¨èæ»¿æåº¦çå¯¦è³ªæ§é²æ­¥ï¼æå©æ¼éç¼æ´æºæ§ä¸æ´ææ¼åå¾çé«çä¿å¥è§£æ±ºæ¹æ¡ãéç¨®åµæ°çæ¹æ³çµåäº ML æ¼ç®æ³çåªé»ï¼ä»¥åéé ChatGPT æä¾éæä¸äººé¡å¯ä»¥çè§£çèªªæçè½åï¼å¨é æ¸¬æºç¢ºæ§åä½¿ç¨èçè§£æ¹é¢åå¾äºé¡¯èçé²æ­¥ãééå©ç¨èªç¾©æè¡åå¯è§£éç AIï¼è©²ç³»çµ±æé«äºç¾çé æ¸¬çæºç¢ºæ§ï¼ä¸¦ç¢ºä¿äºå»ºè­°èåå¥æ£èç¸éä¸ææ¼çè§£ãæåçç ç©¶å¼·èª¿äºæ´ååé²æè¡ä»¥åæé«çè¨ºæ·ä¸­ç¾æææ°çæ½åï¼çºæºæ§é«çä¿å¥ç³»çµ±çæªä¾ç¼å±éªè·¯ãæ­¤å¤ï¼è©²ç³»çµ±ä½¿ç¨ 200 ååææ£èè³æè¨éé²è¡é©è­ï¼ç¢ºä¿äºç©©å¥çæè½åå¯é æ§ã

##### **Introducing Î´-XAI: a novel sensitivity-based method for local AI explanations**
2407.18343v2 by Alessandro De Carlo, Enea Parimbelli, Nicola Melillo, Giovanna Nicora

Explainable Artificial Intelligence (XAI) is central to the debate on
integrating Artificial Intelligence (AI) and Machine Learning (ML) algorithms
into clinical practice. High-performing AI/ML models, such as ensemble learners
and deep neural networks, often lack interpretability, hampering clinicians'
trust in their predictions. To address this, XAI techniques are being developed
to describe AI/ML predictions in human-understandable terms. One promising
direction is the adaptation of sensitivity analysis (SA) and global sensitivity
analysis (GSA), which inherently rank model inputs by their impact on
predictions. Here, we introduce a novel delta-XAI method that provides local
explanations of ML model predictions by extending the delta index, a GSA
metric. The delta-XAI index assesses the impact of each feature's value on the
predicted output for individual instances in both regression and classification
problems. We formalize the delta-XAI index and provide code for its
implementation. The delta-XAI method was evaluated on simulated scenarios using
linear regression models, with Shapley values serving as a benchmark. Results
showed that the delta-XAI index is generally consistent with Shapley values,
with notable discrepancies in models with highly impactful or extreme feature
values. The delta-XAI index demonstrated higher sensitivity in detecting
dominant features and handling extreme feature values. Qualitatively, the
delta-XAI provides intuitive explanations by leveraging probability density
functions, making feature rankings clearer and more explainable for
practitioners. Overall, the delta-XAI method appears promising for robustly
obtaining local explanations of ML model predictions. Further investigations in
real-world clinical settings will be conducted to evaluate its impact on
AI-assisted clinical workflows.

æè¦ï¼å¯è§£éäººå·¥æºæ§ (XAI) æ¯å°äººå·¥æºæ§ (AI) åæ©å¨å­¸ç¿ (ML) æ¼ç®æ³æ´åå°è¨åºå¯¦åä¸­çè¾¯è«æ ¸å¿ãé«å·è¡æè½ç AI/ML æ¨¡åï¼ä¾å¦æ´é«å­¸ç¿å¨åæ·±åº¦ç¥ç¶ç¶²è·¯ï¼éå¸¸ç¼ºä¹å¯è§£éæ§ï¼é»ç¤è¨åºé«çå°å¶é æ¸¬çä¿¡ä»»ãçºäºè§£æ±ºéååé¡ï¼æ­£å¨éç¼ XAI æè¡ï¼ä»¥äººé¡å¯ä»¥çè§£çè¡èªæè¿° AI/ML é æ¸¬ãä¸åæå¸æçæ¹åæ¯æ¡ç¨ææåº¦åæ (SA) åå¨çææåº¦åæ (GSA)ï¼å®åæ¬è³ªä¸æä¾ææ¨¡åè¼¸å¥å°é æ¸¬çå½±é¿ä¾å°å¶é²è¡æåãå¨æ­¤ï¼æåä»ç´¹ä¸ç¨®æ°ç delta-XAI æ¹æ³ï¼ééæ´å GSA ææ¨ delta ææ¸ä¾æä¾ ML æ¨¡åé æ¸¬çå±é¨è§£éãdelta-XAI ææ¸è©ä¼°æ¯åç¹å¾µå¼å°åæ­¸ååé¡åé¡ä¸­åå¥ä¾é çé æ¸¬è¼¸åºä¹å½±é¿ãæåå° delta-XAI ææ¸å½¢å¼åï¼ä¸¦æä¾å¶å¯¦ä½çç¨å¼ç¢¼ãä½¿ç¨ç·æ§åæ­¸æ¨¡åå°æ¨¡æ¬æå¢è©ä¼° delta-XAI æ¹æ³ï¼ä¸¦ä»¥ Shapley å¼ä½çºåºæºãçµæé¡¯ç¤º delta-XAI ææ¸éå¸¸è Shapley å¼ä¸è´ï¼ä½å¨å·æé«åº¦å½±é¿åææ¥µç«¯ç¹å¾µå¼çæ¨¡åä¸­å­å¨é¡¯èå·®ç°ãdelta-XAI ææ¸å¨åµæ¸¬ä¸»è¦ç¹å¾µåèçæ¥µç«¯ç¹å¾µå¼æ¹é¢è¡¨ç¾åºæ´é«çææåº¦ãå®æ§å°ä¾èªªï¼delta-XAI ééå©ç¨æ©çå¯åº¦å½æ¸æä¾ç´è§çè§£éï¼ä½¿ç¹å¾µæåæ´æ¸æ°ä¸å°å¾æ¥­äººå¡ä¾èªªæ´å·å¯è§£éæ§ãç¸½é«èè¨ï¼delta-XAI æ¹æ³å°æ¼ç©©å¥å°åå¾ ML æ¨¡åé æ¸¬çå±é¨è§£éä¼¼ä¹å¾æå¸æãå°å¨çå¯¦ä¸ççè¨åºç°å¢ä¸­é²è¡é²ä¸æ­¥èª¿æ¥ï¼ä»¥è©ä¼°å¶å° AI è¼å©è¨åºå·¥ä½æµç¨çå½±é¿ã

##### **Enhanced Deep Learning Methodologies and MRI Selection Techniques for Dementia Diagnosis in the Elderly Population**
2407.17324v2 by Nikolaos Ntampakis, Konstantinos Diamantaras, Ioanna Chouvarda, Vasileios Argyriou, Panagiotis Sarigianndis

Dementia, a debilitating neurological condition affecting millions worldwide,
presents significant diagnostic challenges. In this work, we introduce a novel
methodology for the classification of demented and non-demented elderly
patients using 3D brain Magnetic Resonance Imaging (MRI) scans. Our approach
features a unique technique for selectively processing MRI slices, focusing on
the most relevant brain regions and excluding less informative sections. This
methodology is complemented by a confidence-based classification committee
composed of three custom deep learning models: Dem3D ResNet, Dem3D CNN, and
Dem3D EfficientNet. These models work synergistically to enhance
decision-making accuracy, leveraging their collective strengths. Tested on the
Open Access Series of Imaging Studies(OASIS) dataset, our method achieved an
impressive accuracy of 94.12%, surpassing existing methodologies. Furthermore,
validation on the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset
confirmed the robustness and generalizability of our approach. The use of
explainable AI (XAI) techniques and comprehensive ablation studies further
substantiate the effectiveness of our techniques, providing insights into the
decision-making process and the importance of our methodology. This research
offers a significant advancement in dementia diagnosis, providing a highly
accurate and efficient tool for clinical applications.

æè¦ï¼å¤±æºçæ¯ä¸ç¨®å½±é¿å¨çæ¸ç¾è¬äººçè¡°å¼±æ§ç¥ç¶ç¾çï¼å¨è¨ºæ·ä¸å·æéå¤§ææ°ãå¨éé å·¥ä½ä¸­ï¼æåæåºäºä¸ç¨®æ°çæ¹æ³ï¼ç¨æ¼å°å¤±æºåéå¤±æºèå¹´æ£èé²è¡åé¡ï¼ä½¿ç¨ 3D å¤§è¦ç£æ¯é å½± (MRI) ææãæåçåæ³æ¡ç¨äºä¸ç¨®ç¨ç¹æè¡ï¼ç¨æ¼é¸ææ§èç MRI åçï¼éé»éæ³¨æç¸éçå¤§è¦ååï¼ä¸¦æé¤ä¿¡æ¯éè¼å°çé¨åãéç¨®æ¹æ³ç±ä¸ååºæ¼ä¿¡å¿çåé¡å§å¡æè£åï¼è©²å§å¡æç±ä¸åèªå®ç¾©æ·±åº¦å­¸ç¿æ¨¡åçµæï¼Dem3D ResNetãDem3D CNN å Dem3D EfficientNetãéäºæ¨¡åååå·¥ä½ä»¥å¢å¼·æ±ºç­çæºç¢ºæ§ï¼å©ç¨å®åçéé«åªå¢ãå¨å½±åç ç©¶éæ¾å­åç³»å (OASIS) è³æéä¸é²è¡æ¸¬è©¦ï¼æåçæ¨¡åéå°äº 94.12% çé©äººæºç¢ºåº¦ï¼è¶éäºç¾ææ¹æ³ãæ­¤å¤ï¼å¨é¿è²æµ·é»çç¥ç¶å½±åå¡è­° (ADNI) è³æéä¸çé©è­è­å¯¦äºæåæ¹æ³çç©©å¥æ§åæ®éæ§ãå¯è§£é AI (XAI) æè¡åå¨é¢çæ¶èç ç©¶é²ä¸æ­¥è­å¯¦äºæåæè¡çæææ§ï¼æä¾äºå°æ±ºç­éç¨åæåæ¹æ³éè¦æ§çè¦è§£ãéé ç ç©¶çºå¤±æºçè¨ºæ·æä¾äºéå¤§é²å±ï¼çºè¨åºæç¨æä¾äºä¸åé«åº¦æºç¢ºä¸é«æçå·¥å·ã

##### **Using Large Language Models to Compare Explainable Models for Smart Home Human Activity Recognition**
2408.06352v1 by Michele Fiori, Gabriele Civitarese, Claudio Bettini

Recognizing daily activities with unobtrusive sensors in smart environments
enables various healthcare applications. Monitoring how subjects perform
activities at home and their changes over time can reveal early symptoms of
health issues, such as cognitive decline. Most approaches in this field use
deep learning models, which are often seen as black boxes mapping sensor data
to activities. However, non-expert users like clinicians need to trust and
understand these models' outputs. Thus, eXplainable AI (XAI) methods for Human
Activity Recognition have emerged to provide intuitive natural language
explanations from these models. Different XAI methods generate different
explanations, and their effectiveness is typically evaluated through user
surveys, that are often challenging in terms of costs and fairness. This paper
proposes an automatic evaluation method using Large Language Models (LLMs) to
identify, in a pool of candidates, the best XAI approach for non-expert users.
Our preliminary results suggest that LLM evaluation aligns with user surveys.

æè¦ï¼èç±æºæ§ç°å¢ä¸­ä¸å¼äººæ³¨ç®çææ¸¬å¨è¾¨è­æ¥å¸¸æ´»åï¼è½åç¨åç¨®é«çä¿å¥æç¨ãç£æ§åè©¦èå¨å®¶ä¸­å¦ä½å·è¡æ´»åï¼ä»¥åå¶é¨èæéçè®åï¼å¯ä»¥æ­ç¤ºå¥åº·åé¡çæ©æççï¼ä¾å¦èªç¥è½åä¸éãæ­¤é åä¸­çå¤§å¤æ¸æ¹æ³é½ä½¿ç¨æ·±åº¦å­¸ç¿æ¨¡åï¼éäºæ¨¡åéå¸¸è¢«è¦çºå°ææ¸¬å¨è³æå°æè³æ´»åçé»çå­ãç¶èï¼éå°å®¶ä½¿ç¨èï¼ä¾å¦è¨åºé«å¸«ï¼éè¦ä¿¡ä»»ä¸¦äºè§£éäºæ¨¡åçè¼¸åºãå æ­¤ï¼äººé¡æ´»åè¾¨è­çå¯è§£é AI (XAI) æ¹æ³æéèçï¼ä»¥æä¾ä¾èªéäºæ¨¡åçç´è¦ºèªç¶èªè¨èªªæãä¸åç XAI æ¹æ³æç¢çä¸åçèªªæï¼èå¶æææ§éå¸¸ééä½¿ç¨èèª¿æ¥ä¾è©ä¼°ï¼éå¨ææ¬åå¬å¹³æ§æ¹é¢éå¸¸å·æææ°æ§ãæ¬ææåºä½¿ç¨å¤§åèªè¨æ¨¡å (LLM) çèªåè©ä¼°æ¹æ³ï¼ä»¥å¨åé¸èä¸­æ¾åºæé©åéå°å®¶ä½¿ç¨èç XAI æ¹æ³ãæåçåæ­¥çµæè¡¨æï¼LLM è©ä¼°èä½¿ç¨èèª¿æ¥ä¸è´ã

##### **Explainable AI-based Intrusion Detection System for Industry 5.0: An Overview of the Literature, associated Challenges, the existing Solutions, and Potential Research Directions**
2408.03335v1 by Naseem Khan, Kashif Ahmad, Aref Al Tamimi, Mohammed M. Alani, Amine Bermak, Issa Khalil

Industry 5.0, which focuses on human and Artificial Intelligence (AI)
collaboration for performing different tasks in manufacturing, involves a
higher number of robots, Internet of Things (IoTs) devices and
interconnections, Augmented/Virtual Reality (AR), and other smart devices. The
huge involvement of these devices and interconnection in various critical
areas, such as economy, health, education and defense systems, poses several
types of potential security flaws. AI itself has been proven a very effective
and powerful tool in different areas of cybersecurity, such as intrusion
detection, malware detection, and phishing detection, among others. Just as in
many application areas, cybersecurity professionals were reluctant to accept
black-box ML solutions for cybersecurity applications. This reluctance pushed
forward the adoption of eXplainable Artificial Intelligence (XAI) as a tool
that helps explain how decisions are made in ML-based systems. In this survey,
we present a comprehensive study of different XAI-based intrusion detection
systems for industry 5.0, and we also examine the impact of explainability and
interpretability on Cybersecurity practices through the lens of Adversarial
XIDS (Adv-XIDS) approaches. Furthermore, we analyze the possible opportunities
and challenges in XAI cybersecurity systems for industry 5.0 that elicit future
research toward XAI-based solutions to be adopted by high-stakes industry 5.0
applications. We believe this rigorous analysis will establish a foundational
framework for subsequent research endeavors within the specified domain.

æè¦ï¼å·¥æ¥­ 5.0 èéæ¼äººé¡èäººå·¥æºæ§ (AI) åä½å·è¡è£½é ä¸­çä¸åä»»åï¼æ¶åæ´å¤æ©å¨äººãç©è¯ç¶² (IoT) è£ç½®åäºé£ãæ´å¢/èæ¬å¯¦å¢ (AR) åå¶ä»æºæ§è£ç½®ãéäºè£ç½®åäºé£å¨ç¶æ¿ãé«çä¿å¥ãæè²ååé²ç³»çµ±ç­åç¨®ééµé åçå»£æ³åèï¼å¼ç¼äºå¤ç¨®é¡åçæ½å¨å®å¨æ¼æ´ãAI æ¬èº«å·²è¢«è­ææ¯ç¶²è·¯å®å¨ä¸åé åä¸­éå¸¸ææä¸å¼·å¤§çå·¥å·ï¼ä¾å¦å¥ä¾µåµæ¸¬ãæ¡æè»é«åµæ¸¬åç¶²è·¯é£é­åµæ¸¬ç­ãå°±åå¨è¨±å¤æç¨é åä¸æ¨£ï¼ç¶²è·¯å®å¨å°æ¥­äººå¡ä¸é¡ææ¥åé»ç ML è§£æ±ºæ¹æ¡ä¾æç¨æ¼ç¶²è·¯å®å¨ãéç¨®ä¸é¡æä¿ä½¿å¯è§£éäººå·¥æºæ§ (XAI) ä½çºä¸ç¨®å·¥å·è¢«æ¡ç¨ï¼æå©æ¼èªªæå¨åºæ¼ ML çç³»çµ±ä¸­å¦ä½ååºæ±ºç­ãå¨éé èª¿æ¥ä¸­ï¼æåå°å·¥æ¥­ 5.0 çä¸ååºæ¼ XAI çå¥ä¾µåµæ¸¬ç³»çµ±é²è¡äºå¨é¢çç ç©¶ï¼ä¸¦ä¸æåä¹ééå°æå¼ XIDS (Adv-XIDS) æ¹æ³çè§é»ä¾æ¢è¨å¯è§£éæ§åå¯è©®éæ§å°ç¶²è·¯å®å¨å¯¦åçå½±é¿ãæ­¤å¤ï¼æååæäºå·¥æ¥­ 5.0 ç XAI ç¶²è·¯å®å¨ç³»çµ±ä¸­å¯è½å­å¨çæ©æåææ°ï¼å¼ç¼äºæªä¾éå° XAI åºç¤è§£æ±ºæ¹æ¡çç ç©¶ï¼ä»¥ä¾é«é¢¨éªçå·¥æ¥­ 5.0 æç¨æ¡ç¨ãæåç¸ä¿¡éé å´è¬¹çåæå°çºæå®é åå§çå¾çºç ç©¶å·¥ä½å»ºç«åºç¤æ¶æ§ã

##### **A Comparative Study on Automatic Coding of Medical Letters with Explainability**
2407.13638v1 by Jamie Glen, Lifeng Han, Paul Rayson, Goran Nenadic

This study aims to explore the implementation of Natural Language Processing
(NLP) and machine learning (ML) techniques to automate the coding of medical
letters with visualised explainability and light-weighted local computer
settings. Currently in clinical settings, coding is a manual process that
involves assigning codes to each condition, procedure, and medication in a
patient's paperwork (e.g., 56265001 heart disease using SNOMED CT code). There
are preliminary research on automatic coding in this field using
state-of-the-art ML models; however, due to the complexity and size of the
models, the real-world deployment is not achieved. To further facilitate the
possibility of automatic coding practice, we explore some solutions in a local
computer setting; in addition, we explore the function of explainability for
transparency of AI models. We used the publicly available MIMIC-III database
and the HAN/HLAN network models for ICD code prediction purposes. We also
experimented with the mapping between ICD and SNOMED CT knowledge bases. In our
experiments, the models provided useful information for 97.98\% of codes. The
result of this investigation can shed some light on implementing automatic
clinical coding in practice, such as in hospital settings, on the local
computers used by clinicians , project page
\url{https://github.com/Glenj01/Medical-Coding}.

æè¦ï¼æ¬ç ç©¶æ¨å¨æ¢è¨å°èªç¶èªè¨èç (NLP) åæ©å¨å­¸ç¿ (ML) æè¡å¯¦ä½æ¼é«çä¿¡å½ç·¨ç¢¼èªååï¼ä¸¦å·åè¦è¦ºåèªªæè½ååè¼éåçæ¬å°é»è¦è¨­å®ãç®åå¨è¨åºç°å¢ä¸­ï¼ç·¨ç¢¼æ¯ä¸ç¨®æåæµç¨ï¼æ¶åçºçæ£æä»¶ä¸­çæ¯é ççãç¨åºåè¥ç©ææ´¾ä»£ç¢¼ (ä¾å¦ï¼ä½¿ç¨ SNOMED CT ä»£ç¢¼ 56265001 è¡¨ç¤ºå¿èç)ãæ­¤é åæä½¿ç¨ææ° ML æ¨¡åé²è¡èªåç·¨ç¢¼çåæ­¥ç ç©¶ï¼ç¶èï¼ç±æ¼æ¨¡åçè¤éæ§åå¤§å°ï¼ä¸¦æªå¯¦ç¾å¯¦éé¨ç½²ãçºäºé²ä¸æ­¥ä¿é²èªåç·¨ç¢¼å¯¦åçå¯è½æ§ï¼æåå¨æ¬å°é»è¦è¨­å®ä¸­æ¢è¨äºä¸äºè§£æ±ºæ¹æ¡ï¼æ­¤å¤ï¼æåæ¢è¨äºèªªæåè½å¨ AI æ¨¡åéæåº¦ä¸­çåè½ãæåä½¿ç¨å¬éç MIMIC-III è³æåº«å HAN/HLAN ç¶²è·¯æ¨¡åé²è¡ ICD ä»£ç¢¼é æ¸¬ãæåéè©¦é©äº ICD å SNOMED CT ç¥è­åº«ä¹éçå°æãå¨æåçå¯¦é©ä¸­ï¼éäºæ¨¡åæä¾äº 97.98% ä»£ç¢¼çæç¨è³è¨ãéé èª¿æ¥çµæå¯ä»¥çºå¯¦åä¸­çèªåè¨åºç·¨ç¢¼å¯¦ä½æä¾ä¸äºè¦è§£ï¼ä¾å¦å¨é«é¢ç°å¢ä¸­ï¼ç±è¨åºé«çä½¿ç¨çæ¬å°é»è¦ï¼å°æ¡é é¢ \url{https://github.com/Glenj01/Medical-Coding}ã

##### **Explainable AI for Enhancing Efficiency of DL-based Channel Estimation**
2407.07009v1 by Abdul Karim Gizzini, Yahia Medjahdi, Ali J. Ghandour, Laurent Clavier

The support of artificial intelligence (AI) based decision-making is a key
element in future 6G networks, where the concept of native AI will be
introduced. Moreover, AI is widely employed in different critical applications
such as autonomous driving and medical diagnosis. In such applications, using
AI as black-box models is risky and challenging. Hence, it is crucial to
understand and trust the decisions taken by these models. Tackling this issue
can be achieved by developing explainable AI (XAI) schemes that aim to explain
the logic behind the black-box model behavior, and thus, ensure its efficient
and safe deployment. Recently, we proposed a novel perturbation-based XAI-CHEST
framework that is oriented toward channel estimation in wireless
communications. The core idea of the XAI-CHEST framework is to identify the
relevant model inputs by inducing high noise on the irrelevant ones. This
manuscript provides the detailed theoretical foundations of the XAI-CHEST
framework. In particular, we derive the analytical expressions of the XAI-CHEST
loss functions and the noise threshold fine-tuning optimization problem. Hence
the designed XAI-CHEST delivers a smart input feature selection methodology
that can further improve the overall performance while optimizing the
architecture of the employed model. Simulation results show that the XAI-CHEST
framework provides valid interpretations, where it offers an improved bit error
rate performance while reducing the required computational complexity in
comparison to the classical DL-based channel estimation.

æè¦ï¼äººå·¥æºè½ (AI) æ¯æçæ±ºç­å¶å®æ¯æªä¾ 6G ç¶²è·¯ä¸­çééµåç´ ï¼å¶ä¸­å°å¼å¥åç AI çæ¦å¿µãæ­¤å¤ï¼AI å»£æ³ç¨æ¼ä¸åçééµæç¨ä¸­ï¼ä¾å¦èªåé§é§åé«çè¨ºæ·ãå¨éäºæç¨ä¸­ï¼ä½¿ç¨ AI ä½çºé»çæ¨¡åæ¯æé¢¨éªä¸å·æææ°æ§çãå æ­¤ï¼çè§£åä¿¡ä»»éäºæ¨¡åååºçæ±ºç­è³ééè¦ãè§£æ±ºæ­¤åé¡çæ¹æ³æ¯éç¼å¯è§£é AI (XAI) æ¶æ§ï¼æ¨å¨è§£éé»çæ¨¡åè¡çºèå¾çéè¼¯ï¼å¾èç¢ºä¿å¶ææä¸å®å¨çé¨ç½²ãæè¿ï¼æåæåºäºä¸åæ°çåºæ¼æ¾åç XAI-CHEST æ¡æ¶ï¼è©²æ¡æ¶é¢åç¡ç·éä¿¡ä¸­çä¿¡éä¼°è¨ãXAI-CHEST æ¡æ¶çæ ¸å¿ææ³æ¯ééå¨ç¡éè¼¸å¥ä¸å¼å¥é«åªè²ä¾è­å¥ç¸éæ¨¡åè¼¸å¥ãéä»½æç¨¿æä¾äº XAI-CHEST æ¡æ¶çè©³ç´°çè«åºç¤ãç¹å¥æ¯ï¼æåæ¨å°äº XAI-CHEST æå¤±å½æ¸ååªè²é¾å¼å¾®èª¿åªååé¡çè§£æè¡¨éå¼ãå æ­¤ï¼è¨­è¨ç XAI-CHEST æä¾äºä¸ç¨®æºè½è¼¸å¥ç¹å¾µé¸ææ¹æ³ï¼å¯ä»¥å¨åªåæç¨æ¨¡åçæ¶æ§çåæé²ä¸æ­¥æé«æ´é«æ§è½ãæ¨¡æ¬çµæè¡¨æï¼XAI-CHEST æ¡æ¶æä¾äºææçè§£éï¼å¨éä½æéçè¨ç®è¤éåº¦çåæï¼æä¾äºæ¹é²çæ¯ç¹é¯èª¤çæ§è½ï¼èéèåºæ¼å³çµ± DL çä¿¡éä¼°è¨ç¸æ¯ã

##### **Explainable AI: Comparative Analysis of Normal and Dilated ResNet Models for Fundus Disease Classification**
2407.05440v2 by P. N. Karthikayan, Yoga Sri Varshan V, Hitesh Gupta Kattamuri, Umarani Jayaraman

This paper presents dilated Residual Network (ResNet) models for disease
classification from retinal fundus images. Dilated convolution filters are used
to replace normal convolution filters in the higher layers of the ResNet model
(dilated ResNet) in order to improve the receptive field compared to the normal
ResNet model for disease classification. This study introduces
computer-assisted diagnostic tools that employ deep learning, enhanced with
explainable AI techniques. These techniques aim to make the tool's
decision-making process transparent, thereby enabling medical professionals to
understand and trust the AI's diagnostic decision. They are particularly
relevant in today's healthcare landscape, where there is a growing demand for
transparency in AI applications to ensure their reliability and ethical use.
The dilated ResNet is used as a replacement for the normal ResNet to enhance
the classification accuracy of retinal eye diseases and reduce the required
computing time. The dataset used in this work is the Ocular Disease Intelligent
Recognition (ODIR) dataset which is a structured ophthalmic database with eight
classes covering most of the common retinal eye diseases. The evaluation
metrics used in this work include precision, recall, accuracy, and F1 score. In
this work, a comparative study has been made between normal ResNet models and
dilated ResNet models on five variants namely ResNet-18, ResNet-34, ResNet-50,
ResNet-101, and ResNet-152. The dilated ResNet model shows promising results as
compared to normal ResNet with an average F1 score of 0.71, 0.70, 0.69, 0.67,
and 0.70 respectively for the above respective variants in ODIR multiclass
disease classification.

æè¦ï¼è¿ç¯è®ºææåºäºç¨äºä»è§ç½èç¼åºå¾åè¿è¡ç¾çåç±»çæ©å¼ æ®å·®ç½ç» (ResNet) æ¨¡åãæ©å¼ å·ç§¯æ»¤æ³¢å¨ç¨äºæ¿æ¢ ResNet æ¨¡åè¾é«å±ä¸­çæ­£å¸¸å·ç§¯æ»¤æ³¢å¨ï¼æ©å¼  ResNetï¼ï¼ä»¥æ¹åæç¥åºï¼ä»èéå¯¹ç¾çåç±»å¯¹æ­£å¸¸ ResNet æ¨¡åè¿è¡æ¹è¿ãæ¬ç ç©¶å¼å¥äºéç¨æ·±åº¦å­¦ä¹ çè®¡ç®æºè¾å©è¯æ­å·¥å·ï¼å¹¶éè¿å¯è§£éç AI ææ¯è¿è¡äºå¢å¼ºãè¿äºææ¯æ¨å¨ä½¿è¯¥å·¥å·çå³ç­è¿ç¨éæåï¼ä»èä½¿å»å­¦ä¸ä¸äººå£«è½å¤çè§£åä¿¡ä»» AI çè¯æ­å³ç­ãå®ä»¬ä¸å½ä»çå»çä¿å¥é¢åå°¤ä¸ºç¸å³ï¼å¨è¯¥é¢åï¼å¯¹ AI åºç¨çéæåº¦éæ±ä¸æ­å¢é¿ï¼ä»¥ç¡®ä¿å¶å¯é æ§ååä¹éå¾·çä½¿ç¨ãæ©å¼  ResNet ç¨ä½æ­£å¸¸ ResNet çæ¿ä»£åï¼ä»¥æé«è§ç½èç¼é¨ç¾ççåç±»åç¡®æ§å¹¶åå°æéçè®¡ç®æ¶é´ãæ¬å·¥ä½ä¸­ä½¿ç¨çæ°æ®éæ¯ç¼ç§ç¾çæºè½è¯å« (ODIR) æ°æ®éï¼è¿æ¯ä¸ä¸ªç»æåçç¼ç§æ°æ®åºï¼åå«å«ç±»æ¶µçå¤§å¤æ°å¸¸è§è§ç½èç¼é¨ç¾çãæ¬å·¥ä½ä¸­ä½¿ç¨çè¯ä¼°ææ åæ¬ç²¾ç¡®åº¦ãå¬åçãåç¡®åº¦å F1 å¾åãå¨è¿é¡¹å·¥ä½ä¸­ï¼å¯¹ ResNet-18ãResNet-34ãResNet-50ãResNet-101 å ResNet-152 äºä¸ªåä½çæ­£å¸¸ ResNet æ¨¡ååæ©å¼  ResNet æ¨¡åè¿è¡äºæ¯è¾ç ç©¶ãä¸æ­£å¸¸ ResNet ç¸æ¯ï¼æ©å¼  ResNet æ¨¡åæ¾ç¤ºåºæå¸æçç»æï¼å¨ ODIR å¤ç±»ç¾çåç±»ä¸­ï¼ä¸è¿°åä¸ªåä½çå¹³å F1 å¾åä¸º 0.71ã0.70ã0.69ã0.67 å 0.70ã

##### **A Survey on Trustworthiness in Foundation Models for Medical Image Analysis**
2407.15851v2 by Congzhen Shi, Ryan Rezai, Jiaxi Yang, Qi Dou, Xiaoxiao Li

The rapid advancement of foundation models in medical imaging represents a
significant leap toward enhancing diagnostic accuracy and personalized
treatment. However, the deployment of foundation models in healthcare
necessitates a rigorous examination of their trustworthiness, encompassing
privacy, robustness, reliability, explainability, and fairness. The current
body of survey literature on foundation models in medical imaging reveals
considerable gaps, particularly in the area of trustworthiness. Additionally,
existing surveys on the trustworthiness of foundation models do not adequately
address their specific variations and applications within the medical imaging
domain. This survey aims to fill that gap by presenting a novel taxonomy of
foundation models used in medical imaging and analyzing the key motivations for
ensuring their trustworthiness. We review current research on foundation models
in major medical imaging applications, focusing on segmentation, medical report
generation, medical question and answering (Q\&A), and disease diagnosis. These
areas are highlighted because they have seen a relatively mature and
substantial number of foundation models compared to other applications. We
focus on literature that discusses trustworthiness in medical image analysis
manuscripts. We explore the complex challenges of building trustworthy
foundation models for each application, summarizing current concerns and
strategies for enhancing trustworthiness. Furthermore, we examine the potential
of these models to revolutionize patient care. Our analysis underscores the
imperative for advancing towards trustworthy AI in medical image analysis,
advocating for a balanced approach that fosters innovation while ensuring
ethical and equitable healthcare delivery.

æè¦ï¼åºç¤æ¨¡åå¨é«å­¸å½±åæ¹é¢çå¿«éé²å±ï¼ä»£è¡¨èå¨å å¼·è¨ºæ·æºç¢ºæ§ååäººåæ²»çæ¹é¢éåºä¸å¤§æ­¥ãç¶èï¼åºç¤æ¨¡åå¨é«çä¿å¥ä¸­çé¨ç½²éè¦å°å¶å¯ä¿¡åº¦é²è¡å´æ ¼çå¯©æ¥ï¼åæ¬é±ç§ãç©©å¥æ§ãå¯é æ§ãå¯è§£éæ§åå¬å¹³æ§ãç®åéæ¼é«å­¸å½±åä¸­åºç¤æ¨¡åçèª¿æ¥æç»ä¸­é¡¯ç¤ºåºç¸ç¶å¤§çå·®è·ï¼ç¹å¥æ¯å¨å¯ä¿¡åº¦æ¹é¢ãæ­¤å¤ï¼ç¾æéæ¼åºç¤æ¨¡åå¯ä¿¡åº¦çèª¿æ¥ä¸¦æªååè§£æ±ºå¶å¨é«å­¸å½±åé åä¸­çç¹å®è®ååæç¨ãæ¬èª¿æ¥æ¨å¨ééæåºé«å­¸å½±åä¸­ä½¿ç¨çåºç¤æ¨¡åçæ°åé¡æ³ä¸¦åæç¢ºä¿å¶å¯ä¿¡åº¦çééµåæ©ï¼ä¾å¡«è£éä¸ç©ºç½ãæååé¡§äºåºç¤æ¨¡åå¨ä¸»è¦é«å­¸å½±åæç¨ä¸­çç¶åç ç©¶ï¼éé»éæ³¨åå²ãé«çå ±åçæãé«çåé¡ååç­ (Q&A) ä»¥åç¾çè¨ºæ·ãéäºé åä¹æä»¥è¢«å¼·èª¿ï¼æ¯å çºèå¶ä»æç¨ç¸æ¯ï¼å®åå·²ç¶çå°ç¸å°æçä¸å¤§éçåºç¤æ¨¡åãæåå°æ³¨æ¼æ¢è¨é«å­¸å½±ååææç¨¿ä¸­å¯ä¿¡åº¦çæç»ãæåæ¢è¨äºçºæ¯åæç¨æ§å»ºå¯ä¿¡åºç¤æ¨¡åçè¤éææ°ï¼ç¸½çµäºç¶åéæ³¨é»åå¢å¼·å¯ä¿¡åº¦çç­ç¥ãæ­¤å¤ï¼æåæ¢è¨äºéäºæ¨¡åå¨é©æ°æ£èè­·çæ¹é¢çæ½åãæåçåæå¼·èª¿äºå¨é«å­¸å½±ååæä¸­æèå¯ä¿¡è³´çäººå·¥æºæ§éé²çå¿è¦æ§ï¼ä¸¦å¡å°ä¸ç¨®å¹³è¡¡çæ¹æ³ï¼æ¢è½ä¿é²åµæ°ï¼åè½ç¢ºä¿éå¾·åå¬å¹³çé«çä¿å¥æåã

##### **The Impact of an XAI-Augmented Approach on Binary Classification with Scarce Data**
2407.06206v1 by Ximing Wen, Rosina O. Weber, Anik Sen, Darryl Hannan, Steven C. Nesbit, Vincent Chan, Alberto Goffi, Michael Morris, John C. Hunninghake, Nicholas E. Villalobos, Edward Kim, Christopher J. MacLellan

Point-of-Care Ultrasound (POCUS) is the practice of clinicians conducting and
interpreting ultrasound scans right at the patient's bedside. However, the
expertise needed to interpret these images is considerable and may not always
be present in emergency situations. This reality makes algorithms such as
machine learning classifiers extremely valuable to augment human decisions.
POCUS devices are becoming available at a reasonable cost in the size of a
mobile phone. The challenge of turning POCUS devices into life-saving tools is
that interpretation of ultrasound images requires specialist training and
experience. Unfortunately, the difficulty to obtain positive training images
represents an important obstacle to building efficient and accurate
classifiers. Hence, the problem we try to investigate is how to explore
strategies to increase accuracy of classifiers trained with scarce data. We
hypothesize that training with a few data instances may not suffice for
classifiers to generalize causing them to overfit. Our approach uses an
Explainable AI-Augmented approach to help the algorithm learn more from less
and potentially help the classifier better generalize.

æè¦ï¼åºéè¶é³æ³¢ (POCUS) æ¯è¨åºé«å¸«å¨æ£èåºéé²è¡åè§£è®è¶é³æ³¢ææçå¯¦åãç¶èï¼è§£è®éäºå½±åæéçå°æ¥­ç¥è­ç¸ç¶å¯è§ï¼èä¸å¨ç·æ¥ææ³ä¸å¯è½ä¸¦éé¨æå·åãéç¨®ç¾å¯¦ææ³ä½¿å¾æ©å¨å­¸ç¿åé¡å¨ç­æ¼ç®æ³å°æ¼å å¼·äººé¡æ±ºç­è®å¾æ¥µçºæå¹å¼ãPOCUS è£ç½®æ­£ä»¥åçææ¬æ¨åºï¼å°ºå¯¸çºææ©å¤§å°ãå° POCUS è£ç½®è½è®çºæçå·¥å·çææ°å¨æ¼ï¼è§£è®è¶é³æ³¢å½±åéè¦å°éè¨ç·´åç¶é©ãä¸å¹¸çæ¯ï¼åå¾æ­£åè¨ç·´å½±åçå°é£åº¦ä»£è¡¨èå»ºç½®ææçä¸æºç¢ºçåé¡å¨çä¸å¤§éç¤ãå æ­¤ï¼æååè©¦æ¢è¨çåé¡æ¯å¦ä½æ¢ç´¢ç­ç¥ï¼ä»¥æé«ä½¿ç¨ç¨çè³æè¨ç·´çåé¡å¨çæºç¢ºåº¦ãæååè¨­ä½¿ç¨å°æ¸è³æå¯¦ä¾é²è¡è¨ç·´å¯è½ä¸è¶³ä»¥è®åé¡å¨æ¦æ¬ï¼å°è´å®åéåº¦æ¬åãæåçåæ³ä½¿ç¨å¯è§£é AI å¢å¼·æ¹æ³ï¼ä»¥åå©æ¼ç®æ³å¾è¼å°çè³æä¸­å­¸ç¿æ´å¤ï¼ä¸¦æ½å¨åå©åé¡å¨æ´å¥½å°æ¦æ¬ã

##### **Can GPT-4 Help Detect Quit Vaping Intentions? An Exploration of Automatic Data Annotation Approach**
2407.00167v1 by Sai Krishna Revanth Vuruma, Dezhi Wu, Saborny Sen Gupta, Lucas Aust, Valerie Lookingbill, Wyatt Bellamy, Yang Ren, Erin Kasson, Li-Shiun Chen, Patricia Cavazos-Rehg, Dian Hu, Ming Huang

In recent years, the United States has witnessed a significant surge in the
popularity of vaping or e-cigarette use, leading to a notable rise in cases of
e-cigarette and vaping use-associated lung injury (EVALI) that caused
hospitalizations and fatalities during the EVALI outbreak in 2019, highlighting
the urgency to comprehend vaping behaviors and develop effective strategies for
cessation. Due to the ubiquity of social media platforms, over 4.7 billion
users worldwide use them for connectivity, communications, news, and
entertainment with a significant portion of the discourse related to health,
thereby establishing social media data as an invaluable organic data resource
for public health research. In this study, we extracted a sample dataset from
one vaping sub-community on Reddit to analyze users' quit-vaping intentions.
Leveraging OpenAI's latest large language model GPT-4 for sentence-level quit
vaping intention detection, this study compares the outcomes of this model
against layman and clinical expert annotations. Using different prompting
strategies such as zero-shot, one-shot, few-shot and chain-of-thought
prompting, we developed 8 prompts with varying levels of detail to explain the
task to GPT-4 and also evaluated the performance of the strategies against each
other. These preliminary findings emphasize the potential of GPT-4 in social
media data analysis, especially in identifying users' subtle intentions that
may elude human detection.

æè¦ï¼è¿å¹´ä¾ï¼ç¾åè¦è­äºé»å­çæé»å­é¦è¸ä½¿ç¨çå¤§å¹æ¿å¢ï¼å°è´é»å­çåé»å­çä½¿ç¨ç¸éèºæå· (EVALI) çä¾é¡¯èå¢å ï¼å¨ 2019 å¹´ EVALI çç¼æéé æä½é¢åæ­»äº¡ï¼å¸é¡¯äºçè§£é»å­çè¡çºåå¶å®æææè¸ç­ç¥çè¿«åæ§ãç±æ¼ç¤¾ç¾¤åªé«å¹³å°çæ®åï¼å¨çè¶é 47 åä½¿ç¨èä½¿ç¨å®åé²è¡é£çµãæºéãæ°èåå¨æ¨ï¼å¶ä¸­å¾å¤§ä¸é¨åèå¥åº·ç¸éï¼å æ­¤å°ç¤¾ç¾¤åªé«è³æå»ºç«çºå¬å±è¡çç ç©¶ä¸­ç¡å¹çææ©è³æè³æºãå¨æ¬ç ç©¶ä¸­ï¼æåå¾ Reddit ä¸ä¸åé»å­çå­ç¤¾ç¾¤ä¸­æåä¸åç¯ä¾è³æéï¼ä»¥åæä½¿ç¨èçæé»å­çæåãå©ç¨ OpenAI ææ°çå¤§åèªè¨æ¨¡å GPT-4 é²è¡å¥å­å±¤ç´çæé»å­çæååµæ¸¬ï¼æ¬ç ç©¶æ¯è¼äºæ­¤æ¨¡åççµæèå¤è¡äººåè¨åºå°å®¶è¨»è§£ãä½¿ç¨ä¸åçæç¤ºç­ç¥ï¼ä¾å¦é¶æ¬¡å­¸ç¿ãä¸æ¬¡å­¸ç¿ãå°æ¬¡å­¸ç¿åæèéæç¤ºï¼æåéç¼äº 8 åæç¤ºï¼è©³ç´°ç¨åº¦ä¸åï¼å GPT-4 è§£éä»»åï¼ä¸¦è©ä¼°éäºç­ç¥å½¼æ­¤ä¹éçæè½ãéäºåæ­¥ç¼ç¾å¼·èª¿äº GPT-4 å¨ç¤¾ç¾¤åªé«è³æåæä¸­çæ½åï¼ç¹å¥æ¯å¨è­å¥äººé¡åµæ¸¬å¯è½ç¡æ³å¯è¦ºçä½¿ç¨èå¾®å¦æåæ¹é¢ã

##### **Towards Compositional Interpretability for XAI**
2406.17583v1 by Sean Tull, Robin Lorenz, Stephen Clark, Ilyas Khan, Bob Coecke

Artificial intelligence (AI) is currently based largely on black-box machine
learning models which lack interpretability. The field of eXplainable AI (XAI)
strives to address this major concern, being critical in high-stakes areas such
as the finance, legal and health sectors.
  We present an approach to defining AI models and their interpretability based
on category theory. For this we employ the notion of a compositional model,
which sees a model in terms of formal string diagrams which capture its
abstract structure together with its concrete implementation. This
comprehensive view incorporates deterministic, probabilistic and quantum
models. We compare a wide range of AI models as compositional models, including
linear and rule-based models, (recurrent) neural networks, transformers, VAEs,
and causal and DisCoCirc models.
  Next we give a definition of interpretation of a model in terms of its
compositional structure, demonstrating how to analyse the interpretability of a
model, and using this to clarify common themes in XAI. We find that what makes
the standard 'intrinsically interpretable' models so transparent is brought out
most clearly diagrammatically. This leads us to the more general notion of
compositionally-interpretable (CI) models, which additionally include, for
instance, causal, conceptual space, and DisCoCirc models.
  We next demonstrate the explainability benefits of CI models. Firstly, their
compositional structure may allow the computation of other quantities of
interest, and may facilitate inference from the model to the modelled
phenomenon by matching its structure. Secondly, they allow for diagrammatic
explanations for their behaviour, based on influence constraints, diagram
surgery and rewrite explanations. Finally, we discuss many future directions
for the approach, raising the question of how to learn such meaningfully
structured models in practice.

æè¦ï¼<paragraph>äººå·¥æºæ§ï¼AIï¼ç®åå¨å¾å¤§ç¨åº¦ä¸ä¾è³´æ¼ç¼ºä¹å¯è§£éæ§çé»çæ©å¨å­¸ç¿æ¨¡åãå¯è§£éæ§äººå·¥æºæ§ï¼XAIï¼é åè´åæ¼è§£æ±ºéåä¸»è¦åé¡ï¼éå¨éèãæ³å¾åå¥åº·ç­é«é¢¨éªé åè³ééè¦ã
æåæåºäºä¸ç¨®åºæ¼ç¯çè«å®ç¾© AI æ¨¡ååå¶å¯è§£éæ§çæ¹æ³ãçºæ­¤ï¼æåæ¡ç¨çµåæ¨¡åçæ¦å¿µï¼å®ä»¥å½¢å¼å¼¦åçå½¢å¼çå¾æ¨¡åï¼éäºå¼¦åæç²äºæ¨¡åçæ½è±¡çµæ§åå¶å·é«å¯¦ç¾ãéç¨®ç¶åè§é»åå«äºç¢ºå®æ§ãæ¦çæ§åéå­æ¨¡åãæåå°åç¨® AI æ¨¡åä½çºçµåæ¨¡åé²è¡æ¯è¼ï¼åæ¬ç·æ§ååºæ¼è¦åçæ¨¡åãï¼éè¿´ï¼ç¥ç¶ç¶²è·¯ãTransformerãVAEï¼ä»¥åå æå DisCoCirc æ¨¡åã
æ¥ä¸ä¾ï¼æåæ ¹ææ¨¡åççµåçµæ§çµ¦åºæ¨¡åè§£éçå®ç¾©ï¼å±ç¤ºå¦ä½åææ¨¡åçå¯è§£éæ§ï¼ä¸¦ä½¿ç¨å®ä¾æ¾æ¸ XAI ä¸­çå¸¸è¦ä¸»é¡ãæåç¼ç¾ï¼è®æ¨æºçãå§å¨å¯è§£éãæ¨¡åå¦æ­¤éæçåå å¨åè¡¨ä¸­è¡¨ç¾å¾æçºæ¸æ¥ãéå¼å°æåå¾åºæ´ä¸è¬ççµåå¯è§£éï¼CIï¼æ¨¡åæ¦å¿µï¼å®å¦å¤éåæ¬å æãæ¦å¿µç©ºéå DisCoCirc æ¨¡åã
æ¥ä¸ä¾ï¼æåå±ç¤ºäº CI æ¨¡åçå¯è§£éæ§åªå¢ãé¦åï¼å®åççµåçµæ§åè¨±è¨ç®å¶ä»æèè¶£çéï¼ä¸¦å¯è½ééå¹éæ¨¡åççµæ§ä¾ä¿é²å¾æ¨¡åå°è¢«å»ºæ¨¡ç¾è±¡çæ¨çãå¶æ¬¡ï¼å®ååè¨±å°å¶è¡çºé²è¡åè§£èªªæï¼éäºèªªæåºæ¼å½±é¿ç´æãåè§£æè¡åéå¯«èªªæãæå¾ï¼æåè¨è«äºéç¨®æ¹æ³çè¨±å¤æªä¾æ¹åï¼æåºäºå¦ä½å¨å¯¦è¸ä¸­å­¸ç¿éç¨®ææç¾©ççµæ§åæ¨¡åçåé¡ã</paragraph>

##### **Slicing Through Bias: Explaining Performance Gaps in Medical Image Analysis using Slice Discovery Methods**
2406.12142v2 by Vincent Olesen, Nina Weng, Aasa Feragen, Eike Petersen

Machine learning models have achieved high overall accuracy in medical image
analysis. However, performance disparities on specific patient groups pose
challenges to their clinical utility, safety, and fairness. This can affect
known patient groups - such as those based on sex, age, or disease subtype - as
well as previously unknown and unlabeled groups. Furthermore, the root cause of
such observed performance disparities is often challenging to uncover,
hindering mitigation efforts. In this paper, to address these issues, we
leverage Slice Discovery Methods (SDMs) to identify interpretable
underperforming subsets of data and formulate hypotheses regarding the cause of
observed performance disparities. We introduce a novel SDM and apply it in a
case study on the classification of pneumothorax and atelectasis from chest
x-rays. Our study demonstrates the effectiveness of SDMs in hypothesis
formulation and yields an explanation of previously observed but unexplained
performance disparities between male and female patients in widely used chest
X-ray datasets and models. Our findings indicate shortcut learning in both
classification tasks, through the presence of chest drains and ECG wires,
respectively. Sex-based differences in the prevalence of these shortcut
features appear to cause the observed classification performance gap,
representing a previously underappreciated interaction between shortcut
learning and model fairness analyses.

æè¦ï¼æ©å¨å­¸ç¿æ¨¡åå¨é«å­¸å½±ååæä¸­å·²éå°æ´é«é«æºç¢ºåº¦ãç¶èï¼ç¹å®æ£èç¾¤é«çæè½å·®ç°å°å¶è¨åºæç¨ãå®å¨æ§èå¬å¹³æ§æ§æææ°ãéå¯è½æå½±é¿å·²ç¥çæ£èç¾¤é«ï¼ä¾å¦åºæ¼æ§å¥ãå¹´é½¡æç¾çäºåï¼ä»¥åååæªç¥ä¸æªæ¨ç±¤çç¾¤é«ãæ­¤å¤ï¼æ­¤é¡è§å¯å°çæè½å·®ç°çæ ¹æ¬åå éå¸¸é£ä»¥ç¼ç¾ï¼é»ç¤äºç·©è§£æªæ½ãå¨æ¬æä¸­ï¼çºäºè§£æ±ºéäºåé¡ï¼æåå©ç¨åçç¼ç¾æ¹æ³ (SDM) ä¾è­å¥å¯è§£éçè³ææè½ä¸ä½³å­éï¼ä¸¦éå°è§å¯å°çæè½å·®ç°åå å¶å®åè¨­ãæåå¼å¥ä¸ç¨®æ°ç SDMï¼ä¸¦å¨è¸é¨ X åçä¸­èºçåèºä¸å¼µåé¡çæ¡ä¾ç ç©¶ä¸­æç¨å®ãæåçç ç©¶è­æäº SDM å¨åè¨­å¶å®ä¸­çæææ§ï¼ä¸¦å°å»£æ³ä½¿ç¨çè¸é¨ X åçè³æéåæ¨¡åä¸­ååè§å¯å°ä½ç¡æ³è§£éçç·æ§åå¥³æ§æ£èä¹éçæè½å·®ç°æä¾äºè§£éãæåçç¼ç¾è¡¨æï¼å¨åé¡ä»»åä¸­ï¼ééè¸èå¼æµç®¡åå¿é»åå°ç·çå­å¨ï¼å­å¨æ·å¾å­¸ç¿ãéäºæ·å¾ç¹å¾µççè¡çå­å¨åºæ¼æ§å¥çå·®ç°ï¼ä¼¼ä¹æå°è´è§å¯å°çåé¡æè½å·®è·ï¼éä»£è¡¨æ·å¾å­¸ç¿åæ¨¡åå¬å¹³æ§åæä¹éååæªåå°éè¦çäº¤äºä½ç¨ã

##### **Unlocking the Potential of Metaverse in Innovative and Immersive Digital Health**
2406.07114v2 by Fatemeh Ebrahimzadeh, Ramin Safa

The concept of Metaverse has attracted a lot of attention in various fields
and one of its important applications is health and treatment. The Metaverse
has enormous potential to transform healthcare by changing patient care,
medical education, and the way teaching/learning and research are done. The
purpose of this research is to provide an introduction to the basic concepts
and fundamental technologies of the Metaverse. This paper examines the pros and
cons of the Metaverse in healthcare context and analyzes its potential from the
technology and AI perspective. In particular, the role of machine learning
methods is discussed; We will explain how machine learning algorithms can be
applied to the Metaverse generated data to gain better insights in healthcare
applications. Additionally, we examine the future visions of the Metaverse in
health delivery, by examining emerging technologies such as blockchain and also
addressing privacy concerns. The findings of this study contribute to a deeper
understanding of the applications of Metaverse in healthcare and its potential
to revolutionize the delivery of medical services.

æè¦ï¼åå®å®çæ¦å¿µå¨ååé åé½ååéæ³¨ï¼å¶éè¦æç¨ä¹ä¸ä¾¿æ¯é«çä¿å¥ãåå®å®æå·¨å¤§çæ½åééæ¹è®çæ£ç§è­·ãé«å­¸æè²ï¼ä»¥åæå­¸/å­¸ç¿åç ç©¶çæ¹å¼ä¾è½åé«çä¿å¥ãæ¬ç ç©¶çç®çæ¯æä¾åå®å®åºæ¬æ¦å¿µååºç¤æè¡çä»ç´¹ãæ¬ææ¢è¨äºåå®å®å¨é«çä¿å¥èæ¯ä¸çåªç¼ºé»ï¼ä¸¦å¾æè¡å AI çè§åº¦åæå¶æ½åãç¹å¥æ¯ï¼è¨è«äºæ©å¨å­¸ç¿æ¹æ³çè§è²ï¼æåå°èªªæå¦ä½å°æ©å¨å­¸ç¿æ¼ç®æ³æç¨æ¼åå®å®ç¢ççè³æï¼ä»¥ç²å¾é«çä¿å¥æç¨æ¹é¢çæ´ä½³è¦è§£ãæ­¤å¤ï¼æåééæ¢è¨åå¡éç­æ°èæè¡ï¼ä¸¦è§£æ±ºé±ç§åé¡ï¼ä¾æ¢è¨åå®å®å¨é«çä¿å¥æ¹é¢çæªä¾é¡æ¯ãæ¬ç ç©¶çç¼ç¾æå©æ¼æ´æ·±å¥å°äºè§£åå®å®å¨é«çä¿å¥ä¸­çæç¨ï¼ä»¥åå¶å¨é«çæåæä¾æ¹é¢ç¼æ®é©å½æ§è®é©çæ½åã

##### **AI-Driven Predictive Analytics Approach for Early Prognosis of Chronic Kidney Disease Using Ensemble Learning and Explainable AI**
2406.06728v1 by K M Tawsik Jawad, Anusha Verma, Fathi Amsaad

Chronic Kidney Disease (CKD) is one of the widespread Chronic diseases with
no known ultimo cure and high morbidity. Research demonstrates that progressive
Chronic Kidney Disease (CKD) is a heterogeneous disorder that significantly
impacts kidney structure and functions, eventually leading to kidney failure.
With the progression of time, chronic kidney disease has moved from a
life-threatening disease affecting few people to a common disorder of varying
severity. The goal of this research is to visualize dominating features,
feature scores, and values exhibited for early prognosis and detection of CKD
using ensemble learning and explainable AI. For that, an AI-driven predictive
analytics approach is proposed to aid clinical practitioners in prescribing
lifestyle modifications for individual patients to reduce the rate of
progression of this disease. Our dataset is collected on body vitals from
individuals with CKD and healthy subjects to develop our proposed AI-driven
solution accurately. In this regard, blood and urine test results are provided,
and ensemble tree-based machine-learning models are applied to predict unseen
cases of CKD. Our research findings are validated after lengthy consultations
with nephrologists. Our experiments and interpretation results are compared
with existing explainable AI applications in various healthcare domains,
including CKD. The comparison shows that our developed AI models, particularly
the Random Forest model, have identified more features as significant
contributors than XgBoost. Interpretability (I), which measures the ratio of
important to masked features, indicates that our XgBoost model achieved a
higher score, specifically a Fidelity of 98\%, in this metric and naturally in
the FII index compared to competing models.

æè¦ï¼æ¢æ§èèçï¼CKDï¼æ¯ä¸ç¨®å»£æ³çæ¢æ§ç¾çï¼æ²æå·²ç¥çæçµçæ³ä¸ç¼ççå¾é«ãç ç©¶è¡¨æï¼é²è¡æ§æ¢æ§èèçï¼CKDï¼æ¯ä¸ç¨®ç°è³ªæ§ç¾çï¼æé¡¯èå½±é¿èèçµæ§ååè½ï¼æçµå°è´èè¡°ç«­ãé¨èæéçæ¨ç§»ï¼æ¢æ§èèçå·²å¾å½±é¿å°æ¸äººçè´å½ç¾çè½è®çºä¸ç¨®å´éç¨åº¦ä¸åçå¸¸è¦ç¾çãæ¬ç ç©¶çç®æ¨æ¯ä½¿ç¨éæå­¸ç¿åå¯è§£éç AI é²è¡æ©æé å¾å CKD æª¢æ¸¬ï¼ä¸¦è¦è¦ºåä¸»å°ç¹å¾µãç¹å¾µåæ¸åè¡¨ç¾åºçå¼ãçºæ­¤ï¼æåºäºä¸ç¨® AI é©åçé æ¸¬åææ¹æ³ï¼ä»¥å¹«å©è¨åºé«ççºåå¥æ£èéå·çæ´»æ¹å¼ä¿®æ¹å»ºè­°ï¼ä»¥éä½éç¨®ç¾ççé²å±éåº¦ãæåçæ¸æéæ¯å¾ CKD æ£èåå¥åº·åè©¦èçèº«é«çå½é«å¾µä¸­æ¶éçï¼ä»¥æºç¢ºéç¼æåæåºç AI é©åçè§£æ±ºæ¹æ¡ãå¨éæ¹é¢ï¼æä¾äºè¡æ¶²åå°¿æ¶²æª¢æ¸¬çµæï¼ä¸¦æç¨åºæ¼éææ¨¹çæ©å¨å­¸ç¿æ¨¡åä¾é æ¸¬æªç¼ç¾ç CKD çä¾ãæåçç ç©¶çµæç¶éèèèç§é«ççé·æè«®è©¢å¾å¾å°é©è­ãæåçå¯¦é©åè§£éçµæèåç¨®é«çä¿å¥é åä¸­ç¾æçå¯è§£é AI æç¨é²è¡äºæ¯è¼ï¼åæ¬ CKDãæ¯è¼è¡¨æï¼æåéç¼ç AI æ¨¡åï¼ç¹å¥æ¯é¨æ©æ£®ææ¨¡åï¼å·²ç¶ç¢ºå®äºæ¯ XgBoost æ´å¤ä½çºéè¦è²¢ç»èçç¹å¾µãå¯è§£éæ§ (I) è¡¡ééè¦ç¹å¾µèæ©èç¹å¾µçæ¯çï¼è¡¨ææåç XgBoost æ¨¡åå¨éåææ¨ä¸­ç²å¾äºæ´é«çåæ¸ï¼ç¹å¥æ¯ 98% çä¿çåº¦ï¼ä¸¦ä¸å¨ FII ææ¸ä¸­èªç¶é«æ¼ç«¶ç­æ¨¡åã

##### **Explainable AI for Mental Disorder Detection via Social Media: A survey and outlook**
2406.05984v1 by Yusif Ibrahimov, Tarique Anwar, Tommy Yuan

Mental health constitutes a complex and pervasive global challenge, affecting
millions of lives and often leading to severe consequences. In this paper, we
conduct a thorough survey to explore the intersection of data science,
artificial intelligence, and mental healthcare, focusing on the recent
developments of mental disorder detection through online social media (OSM). A
significant portion of the population actively engages in OSM platforms,
creating a vast repository of personal data that holds immense potential for
mental health analytics. The paper navigates through traditional diagnostic
methods, state-of-the-art data- and AI-driven research studies, and the
emergence of explainable AI (XAI) models for mental healthcare. We review
state-of-the-art machine learning methods, particularly those based on modern
deep learning, while emphasising the need for explainability in healthcare AI
models. The experimental design section provides insights into prevalent
practices, including available datasets and evaluation approaches. We also
identify key issues and challenges in the field and propose promising future
research directions. As mental health decisions demand transparency,
interpretability, and ethical considerations, this paper contributes to the
ongoing discourse on advancing XAI in mental healthcare through social media.
The comprehensive overview presented here aims to guide researchers,
practitioners, and policymakers in developing the area of mental disorder
detection.

æè¦ï¼å¿çå¥åº·æ§æäºä¸é è¤éä¸æ®éçå¨çææ°ï¼å½±é¿äºæ¸ç¾è¬äººççæ´»ï¼ä¸¦ç¶å¸¸å°è´å´éçå¾æãå¨æ¬æä¸­ï¼æåé²è¡äºä¸é å¾¹åºçèª¿æ¥ï¼ä»¥æ¢ç´¢æ¸æç§å­¸ãäººå·¥æºæ§åå¿çä¿å¥çäº¤éï¼éé»éæ³¨ééç·ä¸ç¤¾äº¤åªé« (OSM) é²è¡å¿çç¾çæª¢æ¸¬çææ°ç¼å±ãå¾å¤§ä¸é¨åäººå£ç©æ¥µåè OSM å¹³å°ï¼åµé äºä¸åé¾å¤§çäººå¡è³æåº«ï¼å°å¿çå¥åº·åæå·æå·¨å¤§çæ½åãæ¬ææ¢è¨äºå³çµ±çè¨ºæ·æ¹æ³ãæåé²çè³æå AI é©åçç ç©¶ï¼ä»¥åå¿çä¿å¥ä¸­å¯è§£é AI (XAI) æ¨¡åçåºç¾ãæååé¡§äºæåé²çæ©å¨å­¸ç¿æ¹æ³ï¼ç¹å¥æ¯é£äºåºæ¼ç¾ä»£æ·±åº¦å­¸ç¿çæ¹æ³ï¼åæå¼·èª¿äºé«çä¿å¥ AI æ¨¡åä¸­å¯è§£éæ§çå¿è¦æ§ãå¯¦é©è¨­è¨é¨åæä¾äºå°æ®éåæ³çè¦è§£ï¼åæ¬å¯ç¨çè³æéåè©ä¼°æ¹æ³ãæåéæ¾åºè©²é åçä¸»è¦åé¡åææ°ï¼ä¸¦æåºäºæå¸æçæªä¾ç ç©¶æ¹åãç±æ¼å¿çå¥åº·æ±ºç­éè¦éæåº¦ãå¯è§£éæ§åéå¾·èéï¼æ¬ææå©æ¼æ¨é²å¿çä¿å¥ä¸­ééç¤¾äº¤åªé«æ¨é² XAI çæçºè¨è«ãéè£¡æåºçå¨é¢æ¦è¿°æ¨å¨å¼å°ç ç©¶äººå¡ãå¾æ¥­äººå¡åæ¿ç­å¶å®èç¼å±å¿çç¾çæª¢æ¸¬é åã

##### **Methodology and Real-World Applications of Dynamic Uncertain Causality Graph for Clinical Diagnosis with Explainability and Invariance**
2406.05746v1 by Zhan Zhang, Qin Zhang, Yang Jiao, Lin Lu, Lin Ma, Aihua Liu, Xiao Liu, Juan Zhao, Yajun Xue, Bing Wei, Mingxia Zhang, Ru Gao, Hong Zhao, Jie Lu, Fan Li, Yang Zhang, Yiming Wang, Lei Zhang, Fengwei Tian, Jie Hu, Xin Gou

AI-aided clinical diagnosis is desired in medical care. Existing deep
learning models lack explainability and mainly focus on image analysis. The
recently developed Dynamic Uncertain Causality Graph (DUCG) approach is
causality-driven, explainable, and invariant across different application
scenarios, without problems of data collection, labeling, fitting, privacy,
bias, generalization, high cost and high energy consumption. Through close
collaboration between clinical experts and DUCG technicians, 46 DUCG models
covering 54 chief complaints were constructed. Over 1,000 diseases can be
diagnosed without triage. Before being applied in real-world, the 46 DUCG
models were retrospectively verified by third-party hospitals. The verified
diagnostic precisions were no less than 95%, in which the diagnostic precision
for every disease including uncommon ones was no less than 80%. After
verifications, the 46 DUCG models were applied in the real-world in China. Over
one million real diagnosis cases have been performed, with only 17 incorrect
diagnoses identified. Due to DUCG's transparency, the mistakes causing the
incorrect diagnoses were found and corrected. The diagnostic abilities of the
clinicians who applied DUCG frequently were improved significantly. Following
the introduction to the earlier presented DUCG methodology, the recommendation
algorithm for potential medical checks is presented and the key idea of DUCG is
extracted.

æè¦ï¼<paragraph>é«çç§è­·ä¸­éè¦ AI è¼å©çè¨åºè¨ºæ·ãç¾æçæ·±åº¦å­¸ç¿æ¨¡åç¼ºä¹å¯è§£éæ§ï¼ä¸¦ä¸ä¸»è¦å°æ³¨æ¼å½±ååæãæè¿éç¼çåæä¸ç¢ºå®å æéä¿å (DUCG) æ¹æ³æ¯å æé©åçãå¯è§£éçï¼ä¸¦ä¸å¨ä¸åçæç¨å ´æ¯ä¸­æ¯ä¸è®çï¼æ²æè³ææ¶éãæ¨è¨ãæ¬åãé±ç§ãåè¦ãæ¦åãé«ææ¬åé«è½èçåé¡ãééè¨åºå°å®¶å DUCG æè¡äººå¡ä¹éçå¯ååä½ï¼æ§å»ºäºæ¶µè 54 åä¸»è¨´ç 46 å DUCG æ¨¡åãå¯ä»¥å¨æ²æåæµçææ³ä¸è¨ºæ·åº 1,000 å¤ç¨®ç¾çãå¨æç¨æ¼å¯¦éä¸çä¹åï¼46 å DUCG æ¨¡åå·²ç±ç¬¬ä¸æ¹é«é¢åæº¯æ§é©è­ãé©è­çè¨ºæ·ç²¾åº¦ä¸ä½æ¼ 95%ï¼å¶ä¸­åæ¬ç½è¦ç¾çå¨å§çæ¯ç¨®ç¾ççè¨ºæ·ç²¾åº¦ä¸ä½æ¼ 80%ãé©è­å¾ï¼46 å DUCG æ¨¡åå·²å¨ä¸­åå¯¦éæç¨ãå·²ç¶å·è¡äºè¶éä¸ç¾è¬åçå¯¦è¨ºæ·æ¡ä¾ï¼åç¼ç¾ 17 åä¸æ­£ç¢ºçè¨ºæ·ãç±æ¼ DUCG çéææ§ï¼ç¼ç¾ä¸¦ç³¾æ­£äºå°è´ä¸æ­£ç¢ºè¨ºæ·çé¯èª¤ãé »ç¹æç¨ DUCG çè¨åºé«ççè¨ºæ·è½åå¾å°äºé¡¯èæé«ãå¨ä»ç´¹äºåé¢æåºç DUCG æ¹æ³è«ä¹å¾ï¼æåºäºæ½å¨å¥åº·æª¢æ¥çæ¨è¦æ¼ç®æ³ï¼ä¸¦æåäº DUCG çééµææ³ã</paragraph>

##### **Advancing Histopathology-Based Breast Cancer Diagnosis: Insights into Multi-Modality and Explainability**
2406.12897v1 by Faseela Abdullakutty, Younes Akbari, Somaya Al-Maadeed, Ahmed Bouridane, Rifat Hamoudi

It is imperative that breast cancer is detected precisely and timely to
improve patient outcomes. Diagnostic methodologies have traditionally relied on
unimodal approaches; however, medical data analytics is integrating diverse
data sources beyond conventional imaging. Using multi-modal techniques,
integrating both image and non-image data, marks a transformative advancement
in breast cancer diagnosis. The purpose of this review is to explore the
burgeoning field of multimodal techniques, particularly the fusion of
histopathology images with non-image data. Further, Explainable AI (XAI) will
be used to elucidate the decision-making processes of complex algorithms,
emphasizing the necessity of explainability in diagnostic processes. This
review utilizes multi-modal data and emphasizes explainability to enhance
diagnostic accuracy, clinician confidence, and patient engagement, ultimately
fostering more personalized treatment strategies for breast cancer, while also
identifying research gaps in multi-modality and explainability, guiding future
studies, and contributing to the strategic direction of the field.

æè¦ï¼ç²¾ç¢ºä¸åæå°åµæ¸¬ä¹³çå°æ¼æ¹åæ£èé å¾è³ééè¦ãè¨ºæ·æ¹æ³å³çµ±ä¸ä¾è³´æ¼å®ä¸æ¨¡å¼æ¹æ³ï¼ç¶èï¼é«çè³æåææ­£å¨æ´åè¶è¶å³çµ±å½±åçåç¨®è³æä¾æºãä½¿ç¨æ´åå½±ååéå½±åè³æçå¤æ¨¡å¼æè¡ï¼æ¨èªèä¹³çè¨ºæ·çè®é©æ§é²å±ãæ¬ç¯ç¶è¿°çç®çæ¯æ¢è¨å¤æ¨¡å¼æè¡çæ°èé åï¼ç¹å¥æ¯å°çµç¹ççå­¸å½±åèéå½±åè³æèåãæ­¤å¤ï¼å¯è§£éäººå·¥æºæ§ (XAI) å°ç¨æ¼é¡æè¤éæ¼ç®æ³çæ±ºç­éç¨ï¼å¼·èª¿è¨ºæ·éç¨ä¸­å¯è§£éæ§çå¿è¦æ§ãæ¬ç¶è¿°å©ç¨å¤æ¨¡å¼è³æä¸¦å¼·èª¿å¯è§£éæ§ï¼ä»¥æé«è¨ºæ·æºç¢ºæ§ãè¨åºé«å¸«çä¿¡å¿åæ£èåèåº¦ï¼æçµä¿é²ä¹³çæ´åäººåçæ²»çç­ç¥ï¼åæä¹æ¾åºå¤æ¨¡å¼åå¯è§£éæ§çç ç©¶å·®è·ï¼å¼å°æªä¾çç ç©¶ï¼ä¸¦çºè©²é åçç­ç¥æ¹åååºè²¢ç»ã

##### **Revisiting Attention Weights as Interpretations of Message-Passing Neural Networks**
2406.04612v1 by Yong-Min Shin, Siqing Li, Xin Cao, Won-Yong Shin

The self-attention mechanism has been adopted in several widely-used
message-passing neural networks (MPNNs) (e.g., GATs), which adaptively controls
the amount of information that flows along the edges of the underlying graph.
This usage of attention has made such models a baseline for studies on
explainable AI (XAI) since interpretations via attention have been popularized
in various domains (e.g., natural language processing and computer vision).
However, existing studies often use naive calculations to derive attribution
scores from attention, and do not take the precise and careful calculation of
edge attribution into consideration. In our study, we aim to fill the gap
between the widespread usage of attention-enabled MPNNs and their potential in
largely under-explored explainability, a topic that has been actively
investigated in other areas. To this end, as the first attempt, we formalize
the problem of edge attribution from attention weights in GNNs. Then, we
propose GATT, an edge attribution calculation method built upon the computation
tree. Through comprehensive experiments, we demonstrate the effectiveness of
our proposed method when evaluating attributions from GATs. Conversely, we
empirically validate that simply averaging attention weights over graph
attention layers is insufficient to interpret the GAT model's behavior. Code is
publicly available at https://github.com/jordan7186/GAtt/tree/main.

æè¦ï¼èªæ³¨æåæ©å¶å·²è¢«æ¡ç¨æ¼å¤åå»£æ³ä½¿ç¨çè¨æ¯å³éç¥ç¶ç¶²è·¯ (MPNN)ï¼ä¾å¦ GATï¼ï¼å®å¯ä»¥èªé©æå°æ§å¶æ²¿èåºå±¤åå½¢éç·£æµåçè³è¨éãéç¨®æ³¨æåçä½¿ç¨ä½¿å¾æ­¤é¡æ¨¡åæçºå¯è§£é AI (XAI) ç ç©¶çåºç·ï¼å çºééæ³¨æåçè©®éå·²å¨åç¨®é åï¼ä¾å¦èªç¶èªè¨èçåé»è¦è¦è¦ºï¼ä¸­æ®åãç¶èï¼ç¾æçç ç©¶éå¸¸ä½¿ç¨å¤©ççè¨ç®æ¹æ³å¾æ³¨æåä¸­æ¨å°åºæ­¸å åæ¸ï¼ä¸¦ä¸æ²æèæ®å°éç·£æ­¸å çç²¾ç¢ºä¸ä»ç´°çè¨ç®ãå¨æåçç ç©¶ä¸­ï¼æåæ¨å¨å¡«è£æ³¨æååç¨ MPNN çå»£æ³ä½¿ç¨èå®åå¨å¾å¤§ç¨åº¦ä¸æªè¢«ååæ¢ç´¢çå¯è§£éæ§ä¹éçå·®è·ï¼éåä¸»é¡å·²å¨å¶ä»é åç©æ¥µç ç©¶ãçºæ­¤ï¼ä½çºç¬¬ä¸æ¬¡åè©¦ï¼æåå° GNN ä¸­æ³¨æåæ¬éçéç·£æ­¸å åé¡å½¢å¼åãç¶å¾ï¼æåæåº GATTï¼ä¸ç¨®å»ºç«å¨è¨ç®æ¨¹ä¸çéç·£æ­¸å è¨ç®æ¹æ³ãééå¨é¢çå¯¦é©ï¼æåå±ç¤ºäºæåæåºçæ¹æ³å¨è©ä¼° GAT çæ­¸å ææå·æçææãç¸åå°ï¼æåæç¶é©é©è­äºåå°åæ³¨æåå±¤ä¸çæ³¨æåæ¬éåå¹³åå¼ä¸è¶³ä»¥è©®é GAT æ¨¡åçè¡çºãç¨å¼ç¢¼å·²å¬éæ¼ https://github.com/jordan7186/GAtt/tree/mainã

##### **Using Explainable AI for EEG-based Reduced Montage Neonatal Seizure Detection**
2406.16908v3 by Dinuka Sandun Udayantha, Kavindu Weerasinghe, Nima Wickramasinghe, Akila Abeyratne, Kithmin Wickremasinghe, Jithangi Wanigasinghe, Anjula De Silva, Chamira U. S. Edussooriya

The neonatal period is the most vulnerable time for the development of
seizures. Seizures in the immature brain lead to detrimental consequences,
therefore require early diagnosis. The gold-standard for neonatal seizure
detection currently relies on continuous video-EEG monitoring; which involves
recording multi-channel electroencephalogram (EEG) alongside real-time video
monitoring within a neonatal intensive care unit (NICU). However, video-EEG
monitoring technology requires clinical expertise and is often limited to
technologically advanced and resourceful settings. Cost-effective new
techniques could help the medical fraternity make an accurate diagnosis and
advocate treatment without delay. In this work, a novel explainable deep
learning model to automate the neonatal seizure detection process with a
reduced EEG montage is proposed, which employs convolutional nets, graph
attention layers, and fully connected layers. Beyond its ability to detect
seizures in real-time with a reduced montage, this model offers the unique
advantage of real-time interpretability. By evaluating the performance on the
Zenodo dataset with 10-fold cross-validation, the presented model achieves an
absolute improvement of 8.31% and 42.86% in area under curve (AUC) and recall,
respectively.

æè¦ï¼æ°çåææ¯å¤§è¦ç¼è²æèå¼±çææï¼å®¹æåºç¾ç²çç¼ä½ãå¤§è¦ç¼è²ä¸æçæåºç¾ç²çç¼ä½æé æä¸è¯å¾æï¼å æ­¤éè¦åæ©è¨ºæ·ãç®åæ°çåç²çç¼ä½çé»éæ¨æºä¾è³´æ¼é£çºçè¦è¨è¦é»å (EEG) ç£æ¸¬ï¼å¶ä¸­åæ¬å¨æ°çåå è­·çæ¿ (NICU) å§åæé²è¡å¤é »éè¦é»å (EEG) è¨éåå³æè¦è¨ç£æ§ãç¶èï¼è¦è¨è¦é»åç£æ§æè¡éè¦è¨åºå°æ¥­ç¥è­ï¼èä¸éå¸¸åéæ¼æè¡åé²ä¸è³æºè±å¯çç°å¢ãå·ææ¬æççæ°æè¡å¯ä»¥å¹«å©é«ççæºç¢ºè¨ºæ·ä¸¦ç«å³æå¡æ²»çãå¨éé å·¥ä½ä¸­ï¼æåºäºä¸åæ°ç©çå¯è§£éæ·±åº¦å­¸ç¿æ¨¡åï¼ä»¥èªååæ°çåç²çç¼ä½åµæ¸¬éç¨ï¼ä¸¦æ¡ç¨æ¸å°çè¦é»åè£ç½®ï¼å¶ä¸­æ¡ç¨äºå·ç©ç¥ç¶ç¶²è·¯ãåå½¢æ³¨æåå±¤åå¨é£æ¥å±¤ãé¤äºè½å¤ ä½¿ç¨æ¸å°çè£ç½®å³æåµæ¸¬ç²çç¼ä½å¤ï¼æ­¤æ¨¡åéæä¾äºå³æå¯è§£éæ§çç¨ç¹åªå¢ãééå¨ Zenodo è³æéä¸ä½¿ç¨ 10 åäº¤åé©è­è©ä¼°æè½ï¼ææåºçæ¨¡åå¨æ²ç·ä¸é¢ç© (AUC) åå¬åçæ¹é¢åå¥éå°äº 8.31% å 42.86% ççµå°æ¹åã

##### **Breast Cancer Diagnosis: A Comprehensive Exploration of Explainable Artificial Intelligence (XAI) Techniques**
2406.00532v1 by Samita Bai, Sidra Nasir, Rizwan Ahmed Khan, Sheeraz Arif, Alexandre Meyer, Hubert Konik

Breast cancer (BC) stands as one of the most common malignancies affecting
women worldwide, necessitating advancements in diagnostic methodologies for
better clinical outcomes. This article provides a comprehensive exploration of
the application of Explainable Artificial Intelligence (XAI) techniques in the
detection and diagnosis of breast cancer. As Artificial Intelligence (AI)
technologies continue to permeate the healthcare sector, particularly in
oncology, the need for transparent and interpretable models becomes imperative
to enhance clinical decision-making and patient care. This review discusses the
integration of various XAI approaches, such as SHAP, LIME, Grad-CAM, and
others, with machine learning and deep learning models utilized in breast
cancer detection and classification. By investigating the modalities of breast
cancer datasets, including mammograms, ultrasounds and their processing with
AI, the paper highlights how XAI can lead to more accurate diagnoses and
personalized treatment plans. It also examines the challenges in implementing
these techniques and the importance of developing standardized metrics for
evaluating XAI's effectiveness in clinical settings. Through detailed analysis
and discussion, this article aims to highlight the potential of XAI in bridging
the gap between complex AI models and practical healthcare applications,
thereby fostering trust and understanding among medical professionals and
improving patient outcomes.

æè¦ï¼ä¹³ç (BC) æ¯å½±é¿å¨çå¥³æ§æå¸¸è¦çæ¡æ§è«ç¤ä¹ä¸ï¼å æ­¤éè¦é²æ­¥çè¨ºæ·æ¹æ³ï¼ä»¥æ¹åè¨åºçµæãæ¬æå¨é¢æ¢è¨äºå¯è§£éäººå·¥æºæ§ (XAI) æè¡å¨ä¹³çåµæ¸¬åè¨ºæ·ä¸­çæç¨ãé¨èäººå·¥æºæ§ (AI) æè¡æçºæ»²éé«çä¿å¥é åï¼ç¹å¥æ¯å¨è«ç¤å­¸ä¸­ï¼éæä¸å¯è§£éçæ¨¡åéæ±è®å¾å¢å¨å¿è¡ï¼ä»¥å¢å¼·è¨åºæ±ºç­å¶å®åæ£èç§è­·ãæ­¤ç¯è©è«æ¢è¨äºåç¨® XAI æ¹æ³çæ´åï¼ä¾å¦ SHAPãLIMEãGrad-CAM ç­ï¼ä»¥åç¨æ¼ä¹³çåµæ¸¬ååé¡çæ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿æ¨¡åãééæ¢è¨ä¹³çè³æéçæ¨¡å¼ï¼åæ¬ä¹³æ¿æå½±ãè¶é³æ³¢åå¶å¨ AI ä¸­çèçï¼æ¬æéé»èªªæ XAI å¦ä½è½å°è´æ´æºç¢ºçè¨ºæ·ååäººåæ²»çè¨ç«ãå®ä¹æ¢è¨äºå¯¦æ½éäºæè¡çææ°ï¼ä»¥åå¶å®æ¨æºåè©éææ¨ä»¥è©ä¼° XAI å¨è¨åºç°å¢ä¸­çæææ§çéè¦æ§ãééè©³ç´°çåæåè¨è«ï¼æ¬ææ¨å¨å¼·èª¿ XAI å¨ç¸®å°è¤é AI æ¨¡åèå¯¦åé«çä¿å¥æç¨ä¹éå·®è·çæ½åï¼é²èä¿é²é«çå°æ¥­äººå¡ä¹éçä¿¡ä»»èçè§£ï¼ä¸¦æ¹åæ£èççµæã

##### **Unveiling Hidden Factors: Explainable AI for Feature Boosting in Speech Emotion Recognition**
2406.01624v2 by Alaa Nfissi, Wassim Bouachir, Nizar Bouguila, Brian Mishara

Speech emotion recognition (SER) has gained significant attention due to its
several application fields, such as mental health, education, and
human-computer interaction. However, the accuracy of SER systems is hindered by
high-dimensional feature sets that may contain irrelevant and redundant
information. To overcome this challenge, this study proposes an iterative
feature boosting approach for SER that emphasizes feature relevance and
explainability to enhance machine learning model performance. Our approach
involves meticulous feature selection and analysis to build efficient SER
systems. In addressing our main problem through model explainability, we employ
a feature evaluation loop with Shapley values to iteratively refine feature
sets. This process strikes a balance between model performance and
transparency, which enables a comprehensive understanding of the model's
predictions. The proposed approach offers several advantages, including the
identification and removal of irrelevant and redundant features, leading to a
more effective model. Additionally, it promotes explainability, facilitating
comprehension of the model's predictions and the identification of crucial
features for emotion determination. The effectiveness of the proposed method is
validated on the SER benchmarks of the Toronto emotional speech set (TESS),
Berlin Database of Emotional Speech (EMO-DB), Ryerson Audio-Visual Database of
Emotional Speech and Song (RAVDESS), and Surrey Audio-Visual Expressed Emotion
(SAVEE) datasets, outperforming state-of-the-art methods. To the best of our
knowledge, this is the first work to incorporate model explainability into an
SER framework. The source code of this paper is publicly available via this
https://github.com/alaaNfissi/Unveiling-Hidden-Factors-Explainable-AI-for-Feature-Boosting-in-Speech-Emotion-Recognition.

æè¦ï¼èªé³æç·è¾¨è­ (SER) ç±æ¼å¶å¨å¿çå¥åº·ãæè²åäººæ©äºåç­å¤åæç¨é åèååéæ³¨ãç¶èï¼SER ç³»çµ±çæºç¢ºæ§åå°é«ç¶­ç¹å¾µéçé»ç¤ï¼éäºç¹å¾µéå¯è½åå«ä¸ç¸éååé¤çè³è¨ãçºäºåæéåææ°ï¼æ¬ç ç©¶æåºäºä¸ç¨®ç¨æ¼ SER çè¿­ä»£ç¹å¾µæåæ¹æ³ï¼è©²æ¹æ³å¼·èª¿ç¹å¾µç¸éæ§åå¯è§£éæ§ï¼ä»¥å¢å¼·æ©å¨å­¸ç¿æ¨¡åçæè½ãæåçåæ³æ¶åä»ç´°çç¹å¾µé¸æååæï¼ä»¥å»ºç«é«æç SER ç³»çµ±ãçºäºééæ¨¡åå¯è§£éæ§è§£æ±ºæåçæ ¸å¿åé¡ï¼æåæ¡ç¨äºå·æ Shapley å¼çç¹å¾µè©ä¼°è¿´åï¼ä»¥åè¦æ¹åç¹å¾µéãéåéç¨å¨æ¨¡åæè½åéæåº¦ä¹éåå¾å¹³è¡¡ï¼éä½¿å¾æåè½å¤ å¨é¢äºè§£æ¨¡åçé æ¸¬ãææåºçæ¹æ³æä¾äºå¤é åªé»ï¼åæ¬è­å¥åç§»é¤ä¸ç¸éååé¤çç¹å¾µï¼å¾èå»ºç«æ´ææçæ¨¡åãæ­¤å¤ï¼å®ä¿é²äºå¯è§£éæ§ï¼æå©æ¼çè§£æ¨¡åçé æ¸¬ä»¥åè­å¥æç·æ±ºå®çééµç¹å¾µãææåºçæ¹æ³çæææ§å·²å¨å¤å«å¤æç·èªé³é (TESS)ãæææç·èªé³è³æåº« (EMO-DB)ãè³´ç¾æ£®é³è¨è¦è¦ºæç·èªé³åæ­æ²è³æåº« (RAVDESS) åè©éé³è¨è¦è¦ºè¡¨éæç· (SAVEE) è³æéç SER åºæºä¸å¾å°é©è­ï¼å¶æè½åªæ¼ç¾ææ¹æ³ãææåæç¥ï¼éæ¯ç¬¬ä¸åå°æ¨¡åå¯è§£éæ§ç´å¥ SER æ¶æ§çç ç©¶ãæ¬æçåå§ç¢¼å¯ééæ­¤é£çµå¬éåå¾ï¼https://github.com/alaaNfissi/Unveiling-Hidden-Factors-Explainable-AI-for-Feature-Boosting-in-Speech-Emotion-Recognitionã

##### **The Explanation Necessity for Healthcare AI**
2406.00216v1 by Michail Mamalakis, HÃ©loÃ¯se de Vareilles, Graham Murray, Pietro Lio, John Suckling

Explainability is often critical to the acceptable implementation of
artificial intelligence (AI). Nowhere is this more important than healthcare
where decision-making directly impacts patients and trust in AI systems is
essential. This trust is often built on the explanations and interpretations
the AI provides. Despite significant advancements in AI interpretability, there
remains the need for clear guidelines on when and to what extent explanations
are necessary in the medical context. We propose a novel categorization system
with four distinct classes of explanation necessity, guiding the level of
explanation required: patient or sample (local) level, cohort or dataset
(global) level, or both levels. We introduce a mathematical formulation that
distinguishes these categories and offers a practical framework for researchers
to determine the necessity and depth of explanations required in medical AI
applications. Three key factors are considered: the robustness of the
evaluation protocol, the variability of expert observations, and the
representation dimensionality of the application. In this perspective, we
address the question: When does an AI medical application need to be explained,
and at what level of detail?

æè¦ï¼å¯è§£éæ§éå¸¸å¯¹äºäººå·¥æºè½ (AI) çå¯æ¥åå®æ½è³å³éè¦ãå¨å»çä¿å¥é¢åï¼è¿ä¸ç¹å°¤ä¸ºéè¦ï¼å ä¸ºå³ç­ç´æ¥å½±åæ£èï¼å¹¶ä¸å¯¹ AI ç³»ç»çä¿¡ä»»è³å³éè¦ãè¿ç§ä¿¡ä»»éå¸¸å»ºç«å¨ AI æä¾çè§£éåè¯ éä¹ä¸ãå°½ç®¡ AI å¯è§£éæ§åå¾äºéå¤§è¿å±ï¼ä½ä»ç¶éè¦æç¡®çæå¯¼æ¹éï¼è¯´æå¨å»çç¯å¢ä¸­ä½æ¶ä»¥åå¨å¤å¤§ç¨åº¦ä¸éè¦è§£éãæä»¬æåºäºä¸ç§æ°é¢çåç±»ç³»ç»ï¼è¯¥ç³»ç»å·æåç§ä¸åçè§£éå¿è¦æ§ç±»å«ï¼æå¯¼æéçè§£éçº§å«ï¼æ£èææ ·æ¬ï¼å±é¨ï¼çº§å«ãéåææ°æ®éï¼å¨å±ï¼çº§å«ï¼æä¸¤ä¸ªçº§å«ãæä»¬å¼å¥äºä¸ä¸ªæ°å­¦å¬å¼ï¼è¯¥å¬å¼åºåäºè¿äºç±»å«ï¼å¹¶ä¸ºç ç©¶äººåæä¾äºä¸ä¸ªå®ç¨æ¡æ¶ï¼ä»¥ç¡®å®å»ç AI åºç¨ä¸­æéçè§£éçå¿è¦æ§åæ·±åº¦ãèèäºä¸ä¸ªå³é®å ç´ ï¼è¯ä¼°åè®®çç¨³å¥æ§ãä¸å®¶è§å¯çå¯åæ§ä»¥ååºç¨ç¨åºçè¡¨ç¤ºç»´æ°ãä»è¿ä¸ªè§åº¦æ¥çï¼æä»¬è§£å³äºè¿ä¸ªé®é¢ï¼AI å»çåºç¨ä½æ¶éè¦è§£éï¼ä»¥åéè¦è§£éå°ä½ç§ç¨åº¦ï¼

##### **Interdisciplinary Expertise to Advance Equitable Explainable AI**
2406.18563v1 by Chloe R. Bennett, Heather Cole-Lewis, Stephanie Farquhar, Naama Haamel, Boris Babenko, Oran Lang, Mat Fleck, Ilana Traynis, Charles Lau, Ivor Horn, Courtney Lyles

The field of artificial intelligence (AI) is rapidly influencing health and
healthcare, but bias and poor performance persists for populations who face
widespread structural oppression. Previous work has clearly outlined the need
for more rigorous attention to data representativeness and model performance to
advance equity and reduce bias. However, there is an opportunity to also
improve the explainability of AI by leveraging best practices of social
epidemiology and health equity to help us develop hypotheses for associations
found. In this paper, we focus on explainable AI (XAI) and describe a framework
for interdisciplinary expert panel review to discuss and critically assess AI
model explanations from multiple perspectives and identify areas of bias and
directions for future research. We emphasize the importance of the
interdisciplinary expert panel to produce more accurate, equitable
interpretations which are historically and contextually informed.
Interdisciplinary panel discussions can help reduce bias, identify potential
confounders, and identify opportunities for additional research where there are
gaps in the literature. In turn, these insights can suggest opportunities for
AI model improvement.

æè¦ï¼äººå·¥æºæ§ (AI) é åæ­£å¿«éå½±é¿èå¥åº·èé«çä¿å¥ï¼ä½å°æ¼é¢è¨å»£æ³çµæ§æ§å£è¿«çäººç¾¤ä¾èªªï¼åè¦åä¸è¯è¡¨ç¾ä¾ç¶å­å¨ãååçç ç©¶å·²æ¸æ¥èªªæï¼éè¦æ´å´æ ¼å°æ³¨æè³æä»£è¡¨æ§åæ¨¡åæè½ï¼ä»¥ä¿é²å¬å¹³æ§ä¸¦æ¸å°åè¦ãç¶èï¼æåææ©æéééç¨ç¤¾ææµè¡çå­¸åå¥åº·å¬å¹³çæä½³å¯¦åï¼ä¾æ¹å AI çå¯è§£éæ§ï¼ä»¥å¹«å©æåéå°ç¼ç¾çéè¯æ§ï¼ç¼å±åè¨­ãå¨æ¬æä¸­ï¼æåå°æ³¨æ¼å¯è§£é AI (XAI)ï¼ä¸¦æè¿°ä¸åè·¨é åå°å®¶å°çµå¯©æ¥æ¶æ§ï¼ä»¥å¾å¤éè§é»è¨è«åæ¹å¤æ§è©ä¼° AI æ¨¡åçè§£éï¼ä¸¦æ¾åºåè¦é ååæªä¾ç ç©¶çæ¹åãæåå¼·èª¿è·¨é åå°å®¶å°çµå°æ¼ç¢çæ´æºç¢ºãå¬å¹³çè©®éè³ééè¦ï¼èéäºè©®éæ¯æ ¹ææ­·å²åèçµ¡èä¾çãè·¨é åå°çµè¨è«æå©æ¼æ¸å°åè¦ãæ¾åºæ½å¨çæ··æ·å ç´ ï¼ä¸¦å¨æç»ä¸­æç¼ºå£ææ¾åºé¡å¤ç ç©¶çæ©æãåéä¾ï¼éäºè¦è§£å¯ä»¥å»ºè­° AI æ¨¡åæ¹é²çæ©æã

##### **"It depends": Configuring AI to Improve Clinical Usefulness Across Contexts**
2407.11978v1 by Hubert D. ZajÄc, Jorge M. N. Ribeiro, Silvia Ingala, Simona Gentile, Ruth Wanjohi, Samuel N. Gitau, Jonathan F. Carlsen, Michael B. Nielsen, Tariq O. Andersen

Artificial Intelligence (AI) repeatedly match or outperform radiologists in
lab experiments. However, real-world implementations of radiological AI-based
systems are found to provide little to no clinical value. This paper explores
how to design AI for clinical usefulness in different contexts. We conducted 19
design sessions and design interventions with 13 radiologists from 7 clinical
sites in Denmark and Kenya, based on three iterations of a functional AI-based
prototype. Ten sociotechnical dependencies were identified as crucial for the
design of AI in radiology. We conceptualised four technical dimensions that
must be configured to the intended clinical context of use: AI functionality,
AI medical focus, AI decision threshold, and AI Explainability. We present four
design recommendations on how to address dependencies pertaining to the medical
knowledge, clinic type, user expertise level, patient context, and user
situation that condition the configuration of these technical dimensions.

æè¦ï¼äººå·¥æºæ§ï¼AIï¼å¨å¯¦é©å®¤å¯¦é©ä¸­ä¸æ·å°èæ¾å°ç§é«å¸«å¹æµæè¡¨ç¾å¾æ´åºè²ãç¶èï¼ç¼ç¾æ¾å°ç§ AI çºåºç¤ç³»çµ±çå¯¦éå·è¡å¹¾ä¹æ²ææä¾è¨åºå¹å¼ãæ¬ææ¢è¨å¦ä½çº AI è¨­è¨å¨ä¸åæå¢ä¸­è¨åºä¸çæç¨ãæåæ ¹æåè½æ§ AI çºåºç¤ååçä¸æ¬¡è¿­ä»£ï¼å¨ä¸¹éº¥åè¯äºç 7 åè¨åºå ´åè 13 ä½æ¾å°ç§é«å¸«é²è¡äº 19 æ¬¡è¨­è¨æè­°åè¨­è¨ä»å¥ãååç¤¾ææè¡ä¾è³´éä¿è¢«èªçºå°æ¼æ¾å°ç§ä¸­ AI çè¨­è¨è³ééè¦ãæåæ¦å¿µåäºååæè¡é¢åï¼å¿é æ ¹æé æçè¨åºä½¿ç¨æå¢é²è¡è¨­å®ï¼AI åè½ãAI é«çéé»ãAI æ±ºç­éæª»ï¼ä»¥å AI å¯è§£éæ§ãæåæåºåé è¨­è¨å»ºè­°ï¼èªªæå¦ä½èçèé«çç¥è­ãè¨ºæé¡åãä½¿ç¨èå°æ¥­ç¥è­ç­ç´ãæ£èæå¢ï¼ä»¥åå½±é¿éäºæè¡é¢åè¨­å®çä½¿ç¨èæå¢ç¸éçä¾è³´éä¿ã

##### **Improving Health Professionals' Onboarding with AI and XAI for Trustworthy Human-AI Collaborative Decision Making**
2405.16424v1 by Min Hun Lee, Silvana Xin Yi Choo, Shamala D/O Thilarajah

With advanced AI/ML, there has been growing research on explainable AI (XAI)
and studies on how humans interact with AI and XAI for effective human-AI
collaborative decision-making. However, we still have a lack of understanding
of how AI systems and XAI should be first presented to users without technical
backgrounds. In this paper, we present the findings of semi-structured
interviews with health professionals (n=12) and students (n=4) majoring in
medicine and health to study how to improve onboarding with AI and XAI. For the
interviews, we built upon human-AI interaction guidelines to create onboarding
materials of an AI system for stroke rehabilitation assessment and AI
explanations and introduce them to the participants. Our findings reveal that
beyond presenting traditional performance metrics on AI, participants desired
benchmark information, the practical benefits of AI, and interaction trials to
better contextualize AI performance, and refine the objectives and performance
of AI. Based on these findings, we highlight directions for improving
onboarding with AI and XAI and human-AI collaborative decision-making.

æè¦ï¼é¨èåé²ç AI/MLï¼å°å¯è§£é AI (XAI) çç ç©¶ä¸æ·å¢å ï¼ä»¥åéæ¼äººé¡å¦ä½è AI å XAI äºåä»¥é²è¡ææçäººå·¥æºæ§åä½æ±ºç­å¶å®ãç¶èï¼æåä»ç¶ç¼ºä¹å° AI ç³»çµ±å XAI æå¦ä½é¦ååç¾çµ¦æ²ææè¡èæ¯çç¨æ¶çäºè§£ãå¨æ¬æä¸­ï¼æåå±ç¤ºäºèé«çå°æ¥­äººå¡ (n=12) åä¸»ä¿®é«å­¸åå¥åº·çå­¸ç (n=4) é²è¡åçµæ§åè¨ªè«ççµæï¼ä»¥ç ç©¶å¦ä½æ¹å AI å XAI çå¥éãå°æ¼è¨ªè«ï¼æåå»ºç«å¨äººæ©äºåæºåä¹ä¸ï¼çºä¸­é¢¨åº·å¾©è©ä¼°å AI è§£éç AI ç³»çµ±åµå»ºå¥éææï¼ä¸¦å°å®åä»ç´¹çµ¦åèèãæåçç ç©¶çµæè¡¨æï¼é¤äºåç¾å³çµ±ç AI æ§è½ææ¨å¤ï¼åèèéå¸æåºåä¿¡æ¯ãAI çå¯¦éå¥½èä»¥åäº¤äºè©¦é©ï¼ä»¥æ´å¥½å°å° AI æ§è½æå¢åï¼ä¸¦å®å AI çç®æ¨åæ§è½ãæ ¹æéäºç¼ç¾ï¼æåå¼·èª¿äºæ¹é² AI å XAI ä»¥åäººæ©åä½æ±ºç­å¶å®çå¥éæ¹åã

##### **Exploring Nutritional Impact on Alzheimer's Mortality: An Explainable AI Approach**
2405.17502v1 by Ziming Liu, Longjian Liu, Robert E. Heidel, Xiaopeng Zhao

This article uses machine learning (ML) and explainable artificial
intelligence (XAI) techniques to investigate the relationship between
nutritional status and mortality rates associated with Alzheimers disease (AD).
The Third National Health and Nutrition Examination Survey (NHANES III)
database is employed for analysis. The random forest model is selected as the
base model for XAI analysis, and the Shapley Additive Explanations (SHAP)
method is used to assess feature importance. The results highlight significant
nutritional factors such as serum vitamin B12 and glycated hemoglobin. The
study demonstrates the effectiveness of random forests in predicting AD
mortality compared to other diseases. This research provides insights into the
impact of nutrition on AD and contributes to a deeper understanding of disease
progression.

æè¦ï¼æ¬æä½¿ç¨æ©å¨å­¸ç¿ (ML) åå¯è§£éäººå·¥æºæ§ (XAI) æè¡ä¾æ¢è¨çé¤çæ³èé¿è²æµ·é»ç (AD) ç¸éçæ­»äº¡çä¹éçéä¿ãæ¡ç¨ç¬¬ä¸æ¬¡å¨åå¥åº·èçé¤æª¢æ¥èª¿æ¥ (NHANES III) è³æåº«é²è¡åæãé¸æé¨æ©æ£®ææ¨¡åä½çº XAI åæçåºç¤æ¨¡åï¼ä¸¦ä½¿ç¨ Shapley Additive Explanations (SHAP) æ¹æ³ä¾è©ä¼°ç¹å¾µéè¦æ§ãçµæçªé¡¯äºéè¦ççé¤å ç´ ï¼ä¾å¦è¡æ¸ç¶­çç´  B12 åç³åè¡ç´èç½ãè©²ç ç©¶è­æäºé¨æ©æ£®æå¨é æ¸¬ AD æ­»äº¡çæ¹é¢ç¸è¼æ¼å¶ä»ç¾ççæææ§ãæ¬ç ç©¶æä¾äºçé¤å° AD çå½±é¿çè¦è§£ï¼ä¸¦æå©æ¼æ´æ·±å¥å°äºè§£ç¾ççé²å±ã

##### **Explainable AI Enhances Glaucoma Referrals, Yet the Human-AI Team Still Falls Short of the AI Alone**
2407.11974v1 by Catalina Gomez, Ruolin Wang, Katharina Breininger, Corinne Casey, Chris Bradley, Mitchell Pavlak, Alex Pham, Jithin Yohannan, Mathias Unberath

Primary care providers are vital for initial triage and referrals to
specialty care. In glaucoma, asymptomatic and fast progression can lead to
vision loss, necessitating timely referrals to specialists. However, primary
eye care providers may not identify urgent cases, potentially delaying care.
Artificial Intelligence (AI) offering explanations could enhance their referral
decisions. We investigate how various AI explanations help providers
distinguish between patients needing immediate or non-urgent specialist
referrals. We built explainable AI algorithms to predict glaucoma surgery needs
from routine eyecare data as a proxy for identifying high-risk patients. We
incorporated intrinsic and post-hoc explainability and conducted an online
study with optometrists to assess human-AI team performance, measuring referral
accuracy and analyzing interactions with AI, including agreement rates, task
time, and user experience perceptions. AI support enhanced referral accuracy
among 87 participants (59.9%/50.8% with/without AI), though Human-AI teams
underperformed compared to AI alone. Participants believed they included AI
advice more when using the intrinsic model, and perceived it more useful and
promising. Without explanations, deviations from AI recommendations increased.
AI support did not increase workload, confidence, and trust, but reduced
challenges. On a separate test set, our black-box and intrinsic models achieved
an accuracy of 77% and 71%, respectively, in predicting surgical outcomes. We
identify opportunities of human-AI teaming for glaucoma management in primary
eye care, noting that while AI enhances referral accuracy, it also shows a
performance gap compared to AI alone, even with explanations. Human involvement
remains essential in medical decision making, underscoring the need for future
research to optimize collaboration, ensuring positive experiences and safe AI
use.

æè¦ï¼<paragraph>åç´ä¿å¥æä¾èå°æ¼æåçåæµåè½è¨ºå°å°ç§ç§è­·è³ééè¦ãå¨éåç¼çææ³ä¸ï¼ç¡ççä¸å¿«éæ¡åå¯è½å°è´è¦ååªå¤±ï¼å æ­¤éè¦åæè½è¨ºçµ¦å°å®¶ãç¶èï¼åç´ç¼ç§ä¿å¥æä¾èå¯è½ç¡æ³è­å¥ç·æ¥ææ³ï¼å¯è½æå»¶èª¤ç§è­·ãæä¾è§£éçäººå·¥æºæ§ (AI) å¯ä»¥å å¼·ä»åçè½è¨ºæ±ºç­ãæåç ç©¶åç¨® AI è§£éå¦ä½å¹«å©æä¾èååéè¦ç«å³æéç·æ¥å°ç§è½è¨ºçæ£èãæåå»ºç«äºè§£éæ§ AI æ¼ç®æ³ï¼ä»¥å¾ä¾è¡ç¼ç§è­·çè³æé æ¸¬éåç¼æè¡éæ±ï¼ä½çºè­å¥é«é¢¨éªæ£èçä»£çãæåç´å¥äºå§å¨åäºå¾è§£éæ§ï¼ä¸¦èé©åå¸«é²è¡äºä¸é ç·ä¸ç ç©¶ï¼ä»¥è©ä¼°äººæ©åéçè¡¨ç¾ï¼è¡¡éè½è¨ºæºç¢ºåº¦ä¸¦åæè AI çäºåï¼åæ¬åæçãä»»åæéåä½¿ç¨èé«é©æç¥ãå¨ 87 ååèèä¸­ï¼AI æ¯æ´æé«äºè½è¨ºæºç¢ºåº¦ï¼ä½¿ç¨ AI/æªä½¿ç¨çæ¯ä¾çº 59.9%/50.8%ï¼ï¼åç®¡äººæ©åéçè¡¨ç¾ä¸å¦å®ç¨ä½¿ç¨ AIãåèèèªçºä»åå¨ä½¿ç¨å§å¨æ¨¡åææ´å¤å°ç´å¥äº AI å»ºè­°ï¼ä¸¦èªçºå®æ´æç¨ä¸æ´æå¸æãæ²æè§£éï¼AI å»ºè­°çåå·®æå¢å ãAI æ¯æ´ä¸¦æªå¢å å·¥ä½éãä¿¡å¿åä¿¡ä»»ï¼ä½æ¸å°äºææ°ãå¨ä¸åå®ç¨çæ¸¬è©¦éä¸­ï¼æåçé»çå­åå§å¨æ¨¡åå¨é æ¸¬æè¡çµææ¹é¢åå¥éå°äº 77% å 71% çæºç¢ºåº¦ãæåæ¾åºå¨åç´ç¼ç§ä¿å¥ä¸­ï¼äººæ©åéåä½ç®¡çéåç¼çæ©æï¼ä¸¦æ³¨æå°éç¶ AI æé«äºè½è¨ºæºç¢ºåº¦ï¼ä½å³ä½¿æè§£éï¼å®ä¹é¡¯ç¤ºåºèå®ç¨ä½¿ç¨ AI ç¸æ¯çæè½å·®è·ãäººé¡åèå¨é«çæ±ºç­ä¸­ä»ç¶è³ééè¦ï¼éå¼·èª¿äºæªä¾ç ç©¶åªååä½ãç¢ºä¿æ­£é¢ç¶é©åå®å¨ä½¿ç¨ AI çå¿è¦æ§ã</paragraph>

##### **Decoding Decision Reasoning: A Counterfactual-Powered Model for Knowledge Discovery**
2406.18552v1 by Yingying Fang, Zihao Jin, Xiaodan Xing, Simon Walsh, Guang Yang

In medical imaging, particularly in early disease detection and prognosis
tasks, discerning the rationale behind an AI model's predictions is crucial for
evaluating the reliability of its decisions. Conventional explanation methods
face challenges in identifying discernible decisive features in medical image
classifications, where discriminative features are subtle or not immediately
apparent. To bridge this gap, we propose an explainable model that is equipped
with both decision reasoning and feature identification capabilities. Our
approach not only detects influential image patterns but also uncovers the
decisive features that drive the model's final predictions. By implementing our
method, we can efficiently identify and visualise class-specific features
leveraged by the data-driven model, providing insights into the decision-making
processes of deep learning models. We validated our model in the demanding
realm of medical prognosis task, demonstrating its efficacy and potential in
enhancing the reliability of AI in healthcare and in discovering new knowledge
in diseases where prognostic understanding is limited.

æè¦ï¼å¨é«å­¸å½±åä¸­ï¼ç¹å¥æ¯å¨æ©æç¾çæª¢æ¸¬åé å¾ä»»åä¸­ï¼è¾¨å¥ AI æ¨¡åé æ¸¬èå¾çåçå°æ¼è©ä¼°å¶æ±ºç­çå¯é æ§è³ééè¦ãå³çµ±çè§£éæ¹æ³å¨è­å¥é«å­¸å½±ååé¡ä¸­å¯è­å¥çæ±ºå®æ§ç¹å¾µæé¢è¨ææ°ï¼å¶ä¸­åå¥æ§ç¹å¾µå¾å¾®å¦æä¸¦ä¸æé¡¯ãçºäºå½åéä¸å·®è·ï¼æåæåºäºä¸åå¯è§£éçæ¨¡åï¼è©²æ¨¡åå·åæ±ºç­æ¨çåç¹å¾µè­å¥è½åãæåçåæ³ä¸åæª¢æ¸¬æå½±é¿åçå½±åæ¨¡å¼ï¼éæ­ç¤ºäºæ¨åæ¨¡åæçµé æ¸¬çæ±ºå®æ§ç¹å¾µãééå¯¦æ½æåçæ¨¡åï¼æåå¯ä»¥ææè­å¥åè¦è¦ºåç±æ¸æé©åæ¨¡åå©ç¨çé¡ç¹å®ç¹å¾µï¼å¾èæ·±å¥äºè§£æ·±åº¦å­¸ç¿æ¨¡åçæ±ºç­éç¨ãæåå¨è¦æ±å´æ ¼çé«å­¸é å¾ä»»åé åé©è­äºæåçæ¨¡åï¼å±ç¤ºäºå¶å¨æé« AI å¨é«çä¿å¥ä¸­çå¯é æ§åç¼ç¾é å¾çè§£åéç¾ççæ°ç¥è­æ¹é¢çåæåæ½åã

##### **The Role of Emotions in Informational Support Question-Response Pairs in Online Health Communities: A Multimodal Deep Learning Approach**
2405.13099v1 by Mohsen Jozani, Jason A. Williams, Ahmed Aleroud, Sarbottam Bhagat

This study explores the relationship between informational support seeking
questions, responses, and helpfulness ratings in online health communities. We
created a labeled data set of question-response pairs and developed multimodal
machine learning and deep learning models to reliably predict informational
support questions and responses. We employed explainable AI to reveal the
emotions embedded in informational support exchanges, demonstrating the
importance of emotion in providing informational support. This complex
interplay between emotional and informational support has not been previously
researched. The study refines social support theory and lays the groundwork for
the development of user decision aids. Further implications are discussed.

æè¦ï¼æ¬ç ç©¶æ¢è¨ç·ä¸å¥åº·ç¤¾ç¾¤ä¸­å°æ±è³è¨æ¯æçåé¡ãåæï¼ä»¥åæå¹«å©çè©åä¹éçéä¿ãæåå»ºç«äºä¸çµæ¨è¨çåç­éå°è³æéï¼ä¸¦éç¼äºå¤æ¨¡ææ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿æ¨¡åï¼ä»¥å¯é å°é æ¸¬è³è¨æ¯æåé¡ååæãæåæ¡ç¨å¯è§£éç AI ä¾æ­ç¤ºè³è¨æ¯æäº¤æµä¸­èå«çæç·ï¼è­ææç·å¨æä¾è³è¨æ¯æä¸­çéè¦æ§ãéç¨®æç·æ¯æåè³è¨æ¯æä¹éçè¤éäº¤äºä½ç¨ä»¥åä¸¦æªè¢«ç ç©¶éãæ¬ç ç©¶æ¹é²äºç¤¾ææ¯æçè«ï¼ä¸¦çºä½¿ç¨èæ±ºç­è¼å©å·¥å·çéç¼å¥ å®äºåºç¤ãè¨è«äºé²ä¸æ­¥çå½±é¿ã

##### **ChatGPT in Classrooms: Transforming Challenges into Opportunities in Education**
2405.10645v1 by Harris Bin Munawar, Nikolaos Misirlis

In the era of exponential technology growth, one unexpected guest has claimed
a seat in classrooms worldwide, Artificial Intelligence. Generative AI, such as
ChatGPT, promises a revolution in education, yet it arrives with a double-edged
sword. Its potential for personalized learning is offset by issues of cheating,
inaccuracies, and educators struggling to incorporate it effectively into their
lesson design. We are standing on the brink of this educational frontier, and
it is clear that we need to navigate this terrain with a lot of care. This is a
major challenge that could undermine the integrity and value of our educational
process. So, how can we turn these challenges into opportunities? When used
inappropriately, AI tools can become the perfect tool for the cut copy paste
mentality, and quickly begin to corrode critical thinking, creativity, and deep
understanding, the most important skills in our rapidly changing world.
Teachers feel that they are not equipped to leverage this technology, widening
the digital divide among educators and institutions. Addressing these concerns
calls for an in depth research approach. We will employ empirical research,
drawing on the Technology Acceptance Model, to assess the attitudes toward
generative AI among educators and students. Understanding their perceptions,
usage patterns, and hurdles is the first crucial step in creating an effective
solution. The present study will be used as a process manual for future
researchers to apply, running their own data, based on the steps explained here

æè¦ï¼å¨ç§æé£éç¼å±çæä»£ï¼ä¸ä½æå¤çè¨ªå®¢å·²å¨å¨çæå®¤ä¸­ä½æä¸å¸­ä¹å°ï¼é£å°±æ¯äººå·¥æºæ§ãçæå¼ AIï¼ä¾å¦ ChatGPTï¼æ¿è«¾å¨æè²é åæèµ·ä¸å ´é©å½ï¼ä½å®å»æ¯ä¸æéé¢åãå®å¨åäººåå­¸ç¿æ¹é¢çæ½åï¼å»å ä½å¼ãä¸æºç¢ºä»¥åæè²å·¥ä½èé£ä»¥å°å¶ææèå¥æå­¸è¨­è¨ç­åé¡èæµé·ãæåæ­£ç«å¨éæè²åæ²¿çéç·£ï¼é¡¯ç¶æåéè¦éå¸¸å°å¿å°æ¢ç´¢éçé åãéæ¯ä¸åéå¤§çææ°ï¼å¯è½ææå®³æåæè²éç¨çå®æ´æ§åå¹å¼ãé£éº¼ï¼æåå¦ä½å°éäºææ°è½åçºæ©éï¼ç¶ä¸é©ç¶å°ä½¿ç¨æï¼AI å·¥å·å¯è½ææçºè¤è£½è²¼ä¸å¿æçå®ç¾å·¥å·ï¼ä¸¦è¿éèèæ¹å¤æ§æç¶­ãåµé ååæ·±å¥çè§£ï¼éäºé½æ¯æåå¿«éè®åçä¸çä¸­æéè¦çæè½ãæå¸«åè¦ºå¾ä»åæ²æè½åå©ç¨éé æè¡ï¼éæ´å¤§äºæè²å·¥ä½èåæ©æ§ä¹éçæ¸ä½é´»æºãè§£æ±ºéäºåé¡éè¦æ·±å¥çç ç©¶æ¹æ³ãæåå°æ¡ç¨å¯¦è­ç ç©¶ï¼åéæè¡æ¥åæ¨¡åï¼ä¾è©ä¼°æè²å·¥ä½èåå­¸çå°çæå¼ AI çæåº¦ãäºè§£ä»åççæ³ãä½¿ç¨æ¨¡å¼åéç¤æ¯åµé ææè§£æ±ºæ¹æ¡çç¬¬ä¸åééµæ­¥é©ãæ¬ç ç©¶å°ä½çºæªä¾ç ç©¶äººå¡æç¨çæµç¨æåï¼æ ¹ææ­¤èèªªæçæ­¥é©éè¡ä»åèªå·±çæ¸æ

##### **Evaluating the Explainable AI Method Grad-CAM for Breath Classification on Newborn Time Series Data**
2405.07590v1 by Camelia Oprea, Mike GrÃ¼ne, Mateusz Buglowski, Lena Olivier, Thorsten Orlikowsky, Stefan Kowalewski, Mark Schoberer, AndrÃ© Stollenwerk

With the digitalization of health care systems, artificial intelligence
becomes more present in medicine. Especially machine learning shows great
potential for complex tasks such as time series classification, usually at the
cost of transparency and comprehensibility. This leads to a lack of trust by
humans and thus hinders its active usage. Explainable artificial intelligence
tries to close this gap by providing insight into the decision-making process,
the actual usefulness of its different methods is however unclear. This paper
proposes a user study based evaluation of the explanation method Grad-CAM with
application to a neural network for the classification of breaths in time
series neonatal ventilation data. We present the perceived usefulness of the
explainability method by different stakeholders, exposing the difficulty to
achieve actual transparency and the wish for more in-depth explanations by many
of the participants.

æè¦ï¼é¨èé«çä¿å¥ç³»çµ±çæ¸ä½åï¼äººå·¥æºæ§å¨é«å­¸é åä¸­è®å¾æ´å æ®åãç¹å¥æ¯æ©å¨å­¸ç¿å¨æéåºååé¡ç­è¤éä»»åä¸­å±ç¾åºæ¥µå¤§çæ½åï¼ä½éå¸¸æ¯ä»¥éæåº¦åå¯çè§£æ§çºä»£å¹ãéå°è´äººé¡ç¼ºä¹ä¿¡ä»»ï¼å¾èé»ç¤äºå¶ç©æ¥µä½¿ç¨ãå¯è§£éçäººå·¥æºæ§è©¦åééæä¾å°æ±ºç­éç¨çæ´å¯ä¾å½è£éä¸å·®è·ï¼ä½å¶ä¸åæ¹æ³çå¯¦éæç¨å°ä¸æ¸æ¥ãæ¬ææåºäºä¸ååºæ¼ä½¿ç¨èç ç©¶çè©ä¼°ï¼å¶ä¸­åå«äº Grad-CAM è§£éæ¹æ³ï¼ä¸¦å°å¶æç¨æ¼ç¥ç¶ç¶²è·¯ä»¥åé¡æéåºåæ°çåå¼å¸æ¸æä¸­çå¼å¸ãæåå±ç¤ºäºä¸åå©çç¸éèå°å¯è§£éæ§æ¹æ³çæç¥æç¨ï¼æ­ç¤ºäºå¯¦ç¾å¯¦ééæåº¦çé£åº¦ï¼ä»¥åè¨±å¤åèèå¸æç²å¾æ´æ·±å¥çè§£éã

##### **XAI4LLM. Let Machine Learning Models and LLMs Collaborate for Enhanced In-Context Learning in Healthcare**
2405.06270v3 by Fatemeh Nazary, Yashar Deldjoo, Tommaso Di Noia, Eugenio di Sciascio

The integration of Large Language Models (LLMs) into healthcare diagnostics
offers a promising avenue for clinical decision-making. This study outlines the
development of a novel method for zero-shot/few-shot in-context learning (ICL)
by integrating medical domain knowledge using a multi-layered structured
prompt. We also explore the efficacy of two communication styles between the
user and LLMs: the Numerical Conversational (NC) style, which processes data
incrementally, and the Natural Language Single-Turn (NL-ST) style, which
employs long narrative prompts.
  Our study systematically evaluates the diagnostic accuracy and risk factors,
including gender bias and false negative rates, using a dataset of 920 patient
records in various few-shot scenarios. Results indicate that traditional
clinical machine learning (ML) models generally outperform LLMs in zero-shot
and few-shot settings. However, the performance gap narrows significantly when
employing few-shot examples alongside effective explainable AI (XAI) methods as
sources of domain knowledge. Moreover, with sufficient time and an increased
number of examples, the conversational style (NC) nearly matches the
performance of ML models. Most notably, LLMs demonstrate comparable or superior
cost-sensitive accuracy relative to ML models.
  This research confirms that, with appropriate domain knowledge and tailored
communication strategies, LLMs can significantly enhance diagnostic processes.
The findings highlight the importance of optimizing the number of training
examples and communication styles to improve accuracy and reduce biases in LLM
applications.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) èé«çè¨ºæ·æ´å
çºè¨åºæ±ºç­æä¾äºä¸åæåæ¯çéå¾ãæ¬ç ç©¶æ¦è¿°äºä¸ç¨®æ°ç©æ¹æ³çéç¼ï¼ç¨æ¼é¶æ¬¡å­¸ç¿/å°éå­¸ç¿æå¢å­¸ç¿ (ICL)ï¼æ¹æ³æ¯ä½¿ç¨å¤å±¤çµæ§åæç¤ºæ´åé«çé åç¥è­ãæåéæ¢è¨äºä½¿ç¨èè LLM ä¹éå©ç¨®æºéæ¹å¼çåæï¼æ¸å¼å°è©± (NC) æ¹å¼ï¼å®æéæ­¥èçè³æï¼ä»¥åèªç¶èªè¨å®åå (NL-ST) æ¹å¼ï¼å®æä½¿ç¨é·ç¯æäºæç¤ºã
æåçç ç©¶ç³»çµ±æ§å°è©ä¼°äºè¨ºæ·æºç¢ºæ§åé¢¨éªå å­ï¼åæ¬æ§å¥åè¦ååé°æ§çï¼ä½¿ç¨äºä¸ååå« 920 åæ£èè¨éçè³æéï¼æ¡ç¨åç¨®å°éå­¸ç¿æå¢ãçµæè¡¨æï¼å³çµ±çè¨åºæ©å¨å­¸ç¿ (ML) æ¨¡åéå¸¸å¨é¶æ¬¡å­¸ç¿åå°éå­¸ç¿è¨­å®ä¸­è¡¨ç¾åªæ¼ LLMãç¶èï¼ç¶ä½¿ç¨å°éå­¸ç¿ç¯ä¾ä»¥åææçå¯è§£é AI (XAI) æ¹æ³ä½çºé åç¥è­ä¾æºæï¼æè½å·®è·æé¡¯èç¸®å°ãæ­¤å¤ï¼é¨èæéåè¶³åç¯ä¾æ¸éå¢å ï¼å°è©±æ¹å¼ (NC) å¹¾ä¹å¯ä»¥åª²ç¾ ML æ¨¡åçæè½ãæå¼å¾æ³¨æçæ¯ï¼LLM ç¸å°æ¼ ML æ¨¡åå±ç¾åºç¸ç¶ææ´ä½³çææ¬æææºç¢ºåº¦ã
æ¬ç ç©¶è­å¯¦ï¼ééé©ç¶çé åç¥è­åéèº«æé çæºéç­ç¥ï¼LLM å¯ä»¥é¡¯èå¢å¼·è¨ºæ·ç¨åºãéäºç¼ç¾çªé¡¯äºæä½³åè¨ç·´ç¯ä¾æ¸éåæºéæ¹å¼çéè¦æ§ï¼ä»¥æé«æºç¢ºåº¦ä¸¦æ¸å° LLM æç¨ä¸­çåå·®ã

##### **To Trust or Not to Trust: Towards a novel approach to measure trust for XAI systems**
2405.05766v1 by Miquel MirÃ³-Nicolau, Gabriel MoyÃ -Alcover, Antoni Jaume-i-CapÃ³, Manuel GonzÃ¡lez-Hidalgo, Maria Gemma Sempere Campello, Juan Antonio Palmer Sancho

The increasing reliance on Deep Learning models, combined with their inherent
lack of transparency, has spurred the development of a novel field of study
known as eXplainable AI (XAI) methods. These methods seek to enhance the trust
of end-users in automated systems by providing insights into the rationale
behind their decisions. This paper presents a novel approach for measuring user
trust in XAI systems, allowing their refinement. Our proposed metric combines
both performance metrics and trust indicators from an objective perspective. To
validate this novel methodology, we conducted a case study in a realistic
medical scenario: the usage of XAI system for the detection of pneumonia from
x-ray images.

æè¦ï¼é¨èå°æ·±åº¦å­¸ç¿æ¨¡åä¾è³´æ§çå¢å ï¼å ä¸å¶åºæçéæåº¦ä¸è¶³ï¼ä¿ä½¿ä¸åæ°çç ç©¶é åç¼å±ï¼ç¨±çºå¯è§£é AI (XAI) æ¹æ³ãéäºæ¹æ³æ¨å¨ééæ·±å¥äºè§£æ±ºç­èå¾çåçï¼ä¾æåæçµä½¿ç¨èå°èªååç³»çµ±çä¿¡è³´ãæ¬ææåºäºä¸ç¨®è¡¡éä½¿ç¨èå° XAI ç³»çµ±ä¿¡è³´åº¦çæ°ç©æ¹æ³ï¼åè¨±å°å¶é²è¡æ¹é²ãæåæåºçææ¨çµåäºå®¢è§è§é»ä¸çæè½ææ¨åä¿¡è³´ææ¨ãçºäºé©è­éåæ°ç©çæ¹æ³ï¼æåå¨ä¸åçå¯¦çé«çå ´æ¯ä¸­é²è¡äºä¸åæ¡ä¾ç ç©¶ï¼ä½¿ç¨ XAI ç³»çµ±å¾ X åå½±åä¸­åµæ¸¬èºçã

##### **Region-specific Risk Quantification for Interpretable Prognosis of COVID-19**
2405.02815v1 by Zhusi Zhong, Jie Li, Zhuoqi Ma, Scott Collins, Harrison Bai, Paul Zhang, Terrance Healey, Xinbo Gao, Michael K. Atalay, Zhicheng Jiao

The COVID-19 pandemic has strained global public health, necessitating
accurate diagnosis and intervention to control disease spread and reduce
mortality rates. This paper introduces an interpretable deep survival
prediction model designed specifically for improved understanding and trust in
COVID-19 prognosis using chest X-ray (CXR) images. By integrating a large-scale
pretrained image encoder, Risk-specific Grad-CAM, and anatomical region
detection techniques, our approach produces regional interpretable outcomes
that effectively capture essential disease features while focusing on rare but
critical abnormal regions. Our model's predictive results provide enhanced
clarity and transparency through risk area localization, enabling clinicians to
make informed decisions regarding COVID-19 diagnosis with better understanding
of prognostic insights. We evaluate the proposed method on a multi-center
survival dataset and demonstrate its effectiveness via quantitative and
qualitative assessments, achieving superior C-indexes (0.764 and 0.727) and
time-dependent AUCs (0.799 and 0.691). These results suggest that our
explainable deep survival prediction model surpasses traditional survival
analysis methods in risk prediction, improving interpretability for clinical
decision making and enhancing AI system trustworthiness.

æè¦ï¼COVID-19 ç«æå°å¨çå¬å±è¡çé æå£åï¼å¿é é²è¡æºç¢ºçè¨ºæ·åå¹²é ï¼ä»¥æ§å¶ç¾çå³æ­ä¸¦éä½æ­»äº¡çãæ¬æä»ç´¹äºä¸åå¯è§£éçæ·±åº¦çå­é æ¸¬æ¨¡åï¼å°éè¨­è¨ç¨æ¼ééè¸é¨ X å (CXR) å½±åæ¹åå° COVID-19 é å¾ççè§£åä¿¡è³´ãééæ´åå¤§è¦æ¨¡é è¨ç·´å½±åç·¨ç¢¼å¨ãé¢¨éªç¹å® Grad-CAM åè§£ååååµæ¸¬æè¡ï¼æåçåæ³ç¢çååå¯è§£éççµæï¼ææææå¿è¦çç¾çç¹å¾µï¼åæå°æ³¨æ¼ç½è¦ä½ééµçç°å¸¸ååãæåçæ¨¡åé æ¸¬çµæééé¢¨éªååå®ä½æä¾å¢å¼·çæ¸æ°åº¦åéæåº¦ï¼è®è¨åºé«çè½å¤ å¨æ´äºè§£é å¾è¦è§£çææ³ä¸ï¼å°± COVID-19 è¨ºæ·ååºææºçæ±ºç­ãæåå¨å¤ä¸­å¿çå­è³æéä¸è©ä¼°ææåºçæ¹æ³ï¼ä¸¦éééååè³ªåè©ä¼°è­æå¶æææ§ï¼éå°åªç°ç C ææ¸ï¼0.764 å 0.727ï¼åæéç¸é AUCï¼0.799 å 0.691ï¼ãéäºçµæè¡¨æï¼æåå¯è§£éçæ·±åº¦çå­é æ¸¬æ¨¡åå¨é¢¨éªé æ¸¬æ¹é¢è¶è¶å³çµ±ççå­åææ¹æ³ï¼æåè¨åºæ±ºç­çè§£éæ§ï¼ä¸¦å¢å¼· AI ç³»çµ±çä¿¡è³´åº¦ã

##### **Rad4XCNN: a new agnostic method for post-hoc global explanation of CNN-derived features by means of radiomics**
2405.02334v1 by Francesco Prinzi, Carmelo Militello, Calogero Zarcaro, Tommaso Vincenzo Bartolotta, Salvatore Gaglio, Salvatore Vitabile

In the last years, artificial intelligence (AI) in clinical decision support
systems (CDSS) played a key role in harnessing machine learning and deep
learning architectures. Despite their promising capabilities, the lack of
transparency and explainability of AI models poses significant challenges,
particularly in medical contexts where reliability is a mandatory aspect.
Achieving transparency without compromising predictive accuracy remains a key
challenge. This paper presents a novel method, namely Rad4XCNN, to enhance the
predictive power of CNN-derived features with the interpretability inherent in
radiomic features. Rad4XCNN diverges from conventional methods based on
saliency map, by associating intelligible meaning to CNN-derived features by
means of Radiomics, offering new perspectives on explanation methods beyond
visualization maps. Using a breast cancer classification task as a case study,
we evaluated Rad4XCNN on ultrasound imaging datasets, including an online
dataset and two in-house datasets for internal and external validation. Some
key results are: i) CNN-derived features guarantee more robust accuracy when
compared against ViT-derived and radiomic features; ii) conventional
visualization map methods for explanation present several pitfalls; iii)
Rad4XCNN does not sacrifice model accuracy for their explainability; iv)
Rad4XCNN provides global explanation insights enabling the physician to analyze
the model outputs and findings. In addition, we highlight the importance of
integrating interpretability into AI models for enhanced trust and adoption in
clinical practice, emphasizing how our method can mitigate some concerns
related to explainable AI methods.

æè¦ï¼<paragraph>å¨éå»å¹¾å¹´ï¼è¨åºæ±ºç­æ¯æ´ç³»çµ± (CDSS) ä¸­çäººå·¥æºæ§ (AI) å¨å©ç¨æ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿æ¶æ§æ¹é¢ç¼æ®äºééµä½ç¨ãåç®¡ AI æ¨¡åå·æä»¤äººæ»¿æçè½åï¼ä½ç¼ºä¹éæåº¦åå¯è§£éæ§ï¼ç¹å¥æ¯å¨å¯é æ§çºå¿è¦èéçé«çèæ¯ä¸ï¼éå¸¶ä¾äºéå¤§çææ°ãå¨ä¸å½±é¿é æ¸¬ç²¾æºåº¦çææ³ä¸å¯¦ç¾éæåº¦ä»ç¶æ¯ä¸é ééµææ°ãæ¬ææåºäºä¸ç¨®æ°æ¹æ³ï¼å³ Rad4XCNNï¼ä»¥å¢å¼· CNN è¡çç¹å¾µçé æ¸¬è½åï¼åæå·åæ¾å°ç¹å¾µåºæçå¯è§£éæ§ãRad4XCNN ä¸åæ¼åºæ¼é¡¯èæ§åçå³çµ±æ¹æ³ï¼å®ééæ¾å°çµå­¸å°å¯çè§£çå«ç¾©è CNN è¡çç¹å¾µéè¯èµ·ä¾ï¼çºè¶è¶è¦è¦ºååè¡¨çè§£éæ¹æ³æä¾äºæ°çè§é»ãæåä»¥ä¹³çåé¡ä»»åä½çºæ¡ä¾ç ç©¶ï¼å¨è¶é³æ³¢å½±åè³æéä¸è©ä¼° Rad4XCNNï¼åæ¬ä¸åç·ä¸è³æéåå©åç¨æ¼å§é¨åå¤é¨é©è­çå§é¨è³æéãä¸äºééµçµæå¦ä¸ï¼i) è ViT è¡çç¹å¾µåæ¾å°ç¹å¾µç¸æ¯ï¼CNN è¡çç¹å¾µä¿è­äºæ´ç©©å¥çæºç¢ºåº¦ï¼ii) å³çµ±çè¦è¦ºååè§£éæ¹æ³å­å¨ä¸äºç¼ºé·ï¼iii) Rad4XCNN æ²æç§ç²æ¨¡åæºç¢ºåº¦ä¾æåå¶å¯è§£éæ§ï¼iv) Rad4XCNN æä¾äºå¨å±è§£éè¦è§£ï¼ä½¿é«å¸«è½å¤ åææ¨¡åè¼¸åºåç¼ç¾ãæ­¤å¤ï¼æåå¼·èª¿å°å¯è§£éæ§æ´åå° AI æ¨¡åä¸­å°æ¼å¢å¼·è¨åºå¯¦åä¸­çä¿¡ä»»åæ¡ç¨è³ééè¦ï¼ä¸¦å¼·èª¿äºæåçæ¹æ³å¦ä½è½ç·©è§£èå¯è§£é AI æ¹æ³ç¸éçä¸äºçæ®ã</paragraph>

##### **Attributing Responsibility in AI-Induced Incidents: A Computational Reflective Equilibrium Framework for Accountability**
2404.16957v1 by Yunfei Ge, Quanyan Zhu

The pervasive integration of Artificial Intelligence (AI) has introduced
complex challenges in the responsibility and accountability in the event of
incidents involving AI-enabled systems. The interconnectivity of these systems,
ethical concerns of AI-induced incidents, coupled with uncertainties in AI
technology and the absence of corresponding regulations, have made traditional
responsibility attribution challenging. To this end, this work proposes a
Computational Reflective Equilibrium (CRE) approach to establish a coherent and
ethically acceptable responsibility attribution framework for all stakeholders.
The computational approach provides a structured analysis that overcomes the
limitations of conceptual approaches in dealing with dynamic and multifaceted
scenarios, showcasing the framework's explainability, coherence, and adaptivity
properties in the responsibility attribution process. We examine the pivotal
role of the initial activation level associated with claims in equilibrium
computation. Using an AI-assisted medical decision-support system as a case
study, we illustrate how different initializations lead to diverse
responsibility distributions. The framework offers valuable insights into
accountability in AI-induced incidents, facilitating the development of a
sustainable and resilient system through continuous monitoring, revision, and
reflection.

æè¦ï¼é¨èäººå·¥æºæ§ (AI) çæ®åæ´åï¼å¨æ¶å AI é©åç³»çµ±çäºæä¸­ï¼è²¬ä»»åç¾©åæ­¸å±¬ç¢çäºè¤éçææ°ãéäºç³»çµ±çäºé£æ§ãAI å¼ç¼äºæçå«çåé¡ï¼å ä¸ AI æè¡çä¸ç¢ºå®æ§åç¼ºä¹ç¸ææ³è¦ï¼ä½¿å¾å³çµ±è²¬ä»»æ­¸å±¬é¢è¨ææ°ãçºæ­¤ï¼æ¬ç ç©¶æåºäºä¸ç¨®è¨ç®åæåè¡¡ (CRE) æ¹æ³ï¼ä»¥å»ºç«ä¸åé£è²«ä¸å¨å«çä¸å¯æ¥åçè²¬ä»»æ­¸å±¬æ¶æ§ï¼é©ç¨æ¼ææå©å®³éä¿äººãè¨ç®æ¹æ³æä¾äºçµæ§åçåæï¼åæäºæ¦å¿µæ¹æ³å¨èçåæä¸å¤é¢åæå¢æçéå¶ï¼å±ç¤ºäºè©²æ¶æ§å¨è²¬ä»»æ­¸å±¬éç¨ä¸­å·åçå¯è§£éæ§ãé£è²«æ§åé©ææ§ãæåæ¢è¨äºèåè¡¡è¨ç®ä¸­ç´¢è³ ç¸éçåå§ååå±¤ç´çééµä½ç¨ãæåä»¥ AI è¼å©é«çæ±ºç­æ¯æ´ç³»çµ±çºæ¡ä¾ç ç©¶ï¼èªªæä¸åçåå§åå¦ä½å°è´ä¸åçè²¬ä»»åéãè©²æ¶æ§æä¾äºå° AI å¼ç¼äºæä¸­åè²¬å¶çå¯¶è²´è¦è§£ï¼ééæçºç£æ§ãä¿®è¨ååæï¼ä¿é²äºæ°¸çºä¸æéæ§çç³»çµ±ç¼å±ã

##### **Explainable AI for Fair Sepsis Mortality Predictive Model**
2404.13139v1 by Chia-Hsuan Chang, Xiaoyang Wang, Christopher C. Yang

Artificial intelligence supports healthcare professionals with predictive
modeling, greatly transforming clinical decision-making. This study addresses
the crucial need for fairness and explainability in AI applications within
healthcare to ensure equitable outcomes across diverse patient demographics. By
focusing on the predictive modeling of sepsis-related mortality, we propose a
method that learns a performance-optimized predictive model and then employs
the transfer learning process to produce a model with better fairness. Our
method also introduces a novel permutation-based feature importance algorithm
aiming at elucidating the contribution of each feature in enhancing fairness on
predictions. Unlike existing explainability methods concentrating on explaining
feature contribution to predictive performance, our proposed method uniquely
bridges the gap in understanding how each feature contributes to fairness. This
advancement is pivotal, given sepsis's significant mortality rate and its role
in one-third of hospital deaths. Our method not only aids in identifying and
mitigating biases within the predictive model but also fosters trust among
healthcare stakeholders by improving the transparency and fairness of model
predictions, thereby contributing to more equitable and trustworthy healthcare
delivery.

æè¦ï¼äººå·¥æºæ§ééé æ¸¬æ¨¡ååå©é«çå°æ¥­äººå¡ï¼å¤§å¹è½è®äºè¨åºæ±ºç­å¶å®ãæ¬ç ç©¶æ¢è¨äºå¨é«çä¿å¥ä¸­ä½¿ç¨äººå·¥æºæ§æç¨ç¨å¼æå¬å¹³æ§åå¯è§£éæ§çééµéæ±ï¼ä»¥ç¢ºä¿å¨ä¸åçæ£èäººå£çµ±è¨è³æä¸­ç²å¾å¬å¹³ççµæãééå°æ³¨æ¼æè¡çç¸éæ­»äº¡ççé æ¸¬æ¨¡åï¼æåæåºäºä¸ç¨®æ¹æ³ï¼è©²æ¹æ³æå­¸ç¿ä¸åæè½æä½³åçé æ¸¬æ¨¡åï¼ç¶å¾æ¡ç¨è½ç§»å­¸ç¿éç¨ä¾ç¢çä¸åå·ææ´å¥½å¬å¹³æ§çæ¨¡åãæåçæ¨¡åéå¼å¥äºä¸ç¨®æ°ç©çåºæ¼æåçç¹å¾µéè¦æ§æ¼ç®æ³ï¼æ¨å¨é¡ææ¯åç¹å¾µå¨å¢å¼·é æ¸¬å¬å¹³æ§æ¹é¢çè²¢ç»ãèç¾æçå¯è§£éæ§æ¹æ³å°æ³¨æ¼è§£éç¹å¾µå°é æ¸¬æè½çè²¢ç»ä¸åï¼æåæåºçæ¹æ³ç¨ç¹å°å½è£äºçè§£æ¯åç¹å¾µå¦ä½æå©æ¼å¬å¹³æ§çå·®è·ãéé é²å±è³ééè¦ï¼å çºæè¡ççæ­»äº¡çå¾é«ï¼ä¸å¨ä¸åä¹ä¸çé«é¢æ­»äº¡ä¸­æ®æ¼èè§è²ãæåçæ¨¡åä¸åæå©æ¼è­å¥åæ¸è¼é æ¸¬æ¨¡åä¸­çåå·®ï¼éè½ééæé«æ¨¡åé æ¸¬çéæåº¦åå¬å¹³æ§ä¾å¹é¤é«çä¿å¥å©çç¸éèä¹éçä¿¡ä»»ï¼é²èæå©æ¼æä¾æ´å¬å¹³ä¸å¼å¾ä¿¡è³´çé«çä¿å¥æåã

##### **Multi Class Depression Detection Through Tweets using Artificial Intelligence**
2404.13104v1 by Muhammad Osama Nusrat, Waseem Shahzad, Saad Ahmed Jamal

Depression is a significant issue nowadays. As per the World Health
Organization (WHO), in 2023, over 280 million individuals are grappling with
depression. This is a huge number; if not taken seriously, these numbers will
increase rapidly. About 4.89 billion individuals are social media users. People
express their feelings and emotions on platforms like Twitter, Facebook,
Reddit, Instagram, etc. These platforms contain valuable information which can
be used for research purposes. Considerable research has been conducted across
various social media platforms. However, certain limitations persist in these
endeavors. Particularly, previous studies were only focused on detecting
depression and the intensity of depression in tweets. Also, there existed
inaccuracies in dataset labeling. In this research work, five types of
depression (Bipolar, major, psychotic, atypical, and postpartum) were predicted
using tweets from the Twitter database based on lexicon labeling. Explainable
AI was used to provide reasoning by highlighting the parts of tweets that
represent type of depression. Bidirectional Encoder Representations from
Transformers (BERT) was used for feature extraction and training. Machine
learning and deep learning methodologies were used to train the model. The BERT
model presented the most promising results, achieving an overall accuracy of
0.96.

æè¦ï¼ç¾ä»ï¼æé¬±çæ¯ä¸åéè¦çè­°é¡ãæ ¹æä¸çè¡ççµç¹ (WHO) çè³æï¼å¨ 2023 å¹´ï¼è¶é 2.8 åäººæ­£å¨èæé¬±çæé¬¥ãéæ¯ä¸åé¾å¤§çæ¸å­ï¼å¦æä¸èªççå¾ï¼éäºæ¸å­å°æå¿«éå¢å ãå¤§ç´æ 48.9 åäººæ¯ç¤¾ç¾¤åªé«ä½¿ç¨èãäººåå¨ TwitterãFacebookãRedditãInstagram ç­å¹³å°ä¸è¡¨éèªå·±çæååæç·ãéäºå¹³å°åå«æå¹å¼çè³è¨ï¼å¯ç¨æ¼ç ç©¶ç®çãå·²ç¶å¨åç¨®ç¤¾ç¾¤åªé«å¹³å°ä¸é²è¡äºå¤§éçç ç©¶ãç¶èï¼éäºåªåä»å­å¨æäºéå¶ãç¹å¥æ¯ï¼ååçç ç©¶åå°æ³¨æ¼åµæ¸¬æ¨æä¸­çæé¬±çåæé¬±ççå¼·åº¦ãæ­¤å¤ï¼è³æéæ¨ç±¤ä¸­å­å¨ä¸æºç¢ºçææ³ãå¨éé ç ç©¶å·¥ä½ä¸­ï¼ä½¿ç¨åºæ¼è©å½æ¨ç±¤ç Twitter è³æåº«ä¸­çæ¨æé æ¸¬äºäºç¨®é¡åçæé¬±çï¼éæ¥µåãéåº¦ãç²¾ç¥çåãéå¸ååç¢å¾ï¼ãå¯è§£éç AI ç¨æ¼ééå¼·èª¿ä»£è¡¨æé¬±çé¡åçæ¨æé¨åä¾æä¾æ¨çãå¾ Transformersï¼BERTï¼ä¸­æåçéåç·¨ç¢¼å¨è¡¨ç¤ºç¨æ¼ç¹å¾µæååè¨ç·´ãæ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿æ¹æ³ç¨æ¼è¨ç·´æ¨¡åãBERT æ¨¡ååç¾åºææå¸æççµæï¼éå° 0.96 çæ´é«æºç¢ºåº¦ã

##### **COIN: Counterfactual inpainting for weakly supervised semantic segmentation for medical images**
2404.12832v2 by Dmytro Shvetsov, Joonas Ariva, Marharyta Domnich, Raul Vicente, Dmytro Fishman

Deep learning is dramatically transforming the field of medical imaging and
radiology, enabling the identification of pathologies in medical images,
including computed tomography (CT) and X-ray scans. However, the performance of
deep learning models, particularly in segmentation tasks, is often limited by
the need for extensive annotated datasets. To address this challenge, the
capabilities of weakly supervised semantic segmentation are explored through
the lens of Explainable AI and the generation of counterfactual explanations.
The scope of this research is development of a novel counterfactual inpainting
approach (COIN) that flips the predicted classification label from abnormal to
normal by using a generative model. For instance, if the classifier deems an
input medical image X as abnormal, indicating the presence of a pathology, the
generative model aims to inpaint the abnormal region, thus reversing the
classifier's original prediction label. The approach enables us to produce
precise segmentations for pathologies without depending on pre-existing
segmentation masks. Crucially, image-level labels are utilized, which are
substantially easier to acquire than creating detailed segmentation masks. The
effectiveness of the method is demonstrated by segmenting synthetic targets and
actual kidney tumors from CT images acquired from Tartu University Hospital in
Estonia. The findings indicate that COIN greatly surpasses established
attribution methods, such as RISE, ScoreCAM, and LayerCAM, as well as an
alternative counterfactual explanation method introduced by Singla et al. This
evidence suggests that COIN is a promising approach for semantic segmentation
of tumors in CT images, and presents a step forward in making deep learning
applications more accessible and effective in healthcare, where annotated data
is scarce.

æè¦ï¼æ·±åº¦å­¦ä¹ æ­£å¤§å¹è½è®é«å­¸å½±ååæ¾å°ç·å­¸é åï¼è½è¾¨è­é«å­¸å½±åä¸­çççï¼åæ¬é»è¦æ·å±¤ææ (CT) å X åææãç¶èï¼æ·±åº¦å­¸ç¿æ¨¡åçæè½ï¼ç¹å¥æ¯å¨åå²ä»»åä¸­ï¼å¸¸å¸¸åå°å»£æ³è¨»è§£è³æééæ±çéå¶ãçºäºæå°æ­¤ææ°ï¼ééå¯è§£é AI ååäºå¯¦è§£éçç¢çï¼æ¢ç´¢å¼±ç£ç£èªæåå²çè½åãæ¬ç ç©¶çç¯åæ¯éç¼ä¸ç¨®æ°çåäºå¯¦å§ææ¹æ³ (COIN)ï¼è©²æ¹æ³ä½¿ç¨çææ¨¡åå°é æ¸¬çåé¡æ¨ç±¤å¾ç°å¸¸ç¿»è½çºæ­£å¸¸ãä¾å¦ï¼å¦æåé¡å¨å°è¼¸å¥çé«å­¸å½±å X è¦çºç°å¸¸ï¼è¡¨ç¤ºå­å¨ççï¼åçææ¨¡åæ¨å¨å§æç°å¸¸ååï¼å¾èéè½åé¡å¨çåå§é æ¸¬æ¨ç±¤ãæ­¤æ¹æ³ä½¿æåè½å¤ ç¢ççççç²¾ç¢ºåå²ï¼èç¡éä¾è³´æ¼é åå­å¨çåå²é®ç½©ãè³ééè¦çæ¯ï¼å©ç¨å½±åå±¤ç´æ¨ç±¤ï¼éæ¯å»ºç«è©³ç´°çåå²é®ç½©å®¹æåå¾ãè©²æ¹æ³çæææ§ééåå²åæç®æ¨åå¾ææ²å°¼äºå¡ç¾åå¤§å­¸é«é¢åå¾ç CT å½±åä¸­çå¯¦éèèè«ç¤ä¾è­æãç ç©¶çµæè¡¨æï¼COIN é é è¶éå·²å»ºç«çæ­¸å æ¹æ³ï¼ä¾å¦ RISEãScoreCAM å LayerCAMï¼ä»¥å Singla ç­äººæåºçå¦ä¸ç¨®åäºå¯¦è§£éæ¹æ³ãæ­¤è­æè¡¨æï¼COIN æ¯ä¸ç¨®å¾æåéç CT å½±åä¸­è«ç¤èªæåå²æ¹æ³ï¼ä¸¦å¨é«çä¿å¥ä¸­è®æ·±åº¦å­¸ç¿æç¨æ´ææ¼åå¾åæ´ææçéé²ä¸æ­¥ï¼å¶ä¸­è¨»è§£è³æå¾ç¨å°ã

##### **Hybrid Intelligence for Digital Humanities**
2406.15374v1 by Victor de Boer, Lise Stork

In this paper, we explore the synergies between Digital Humanities (DH) as a
discipline and Hybrid Intelligence (HI) as a research paradigm. In DH research,
the use of digital methods and specifically that of Artificial Intelligence is
subject to a set of requirements and constraints. We argue that these are
well-supported by the capabilities and goals of HI. Our contribution includes
the identification of five such DH requirements: Successful AI systems need to
be able to 1) collaborate with the (human) scholar; 2) support data criticism;
3) support tool criticism; 4) be aware of and cater to various perspectives and
5) support distant and close reading. We take the CARE principles of Hybrid
Intelligence (collaborative, adaptive, responsible and explainable) as
theoretical framework and map these to the DH requirements. In this mapping, we
include example research projects. We finally address how insights from DH can
be applied to HI and discuss open challenges for the combination of the two
disciplines.

æè¦ï¼å¨æ¬æä¸­ï¼æåæ¢è¨æ¸ä½äººæå­¸ç§ (DH) ä½çºä¸éå­¸ç§èæ··åæºè½ (HI) ä½çºä¸åç ç©¶å¸ç¯ä¹éçååä½ç¨ãå¨ DH ç ç©¶ä¸­ï¼æ¸ä½æ¹æ³çä½¿ç¨ï¼ç¹å¥æ¯äººå·¥æºæ§çä½¿ç¨ï¼åå°ä¸ç³»åè¦æ±åéå¶ãæåèªçºéäºè¦æ±åéå¶ç²å¾ HI çè½ååç®æ¨çååæ¯æãæåçè²¢ç»åæ¬æ¾åºäºåéæ¨£ç DH è¦æ±ï¼æåç AI ç³»çµ±éè¦è½å¤  1) èï¼äººé¡ï¼å­¸èåä½ï¼2) æ¯æ´è³ææ¹è©ï¼3) æ¯æ´å·¥å·æ¹è©ï¼4) å¯è¦ºä¸¦è¿ååç¨®è§é»ï¼5) æ¯æ´é è·åè¿è·é¢é±è®ãæåå°æ··åæºè½ç CARE ååï¼åä½ãé©æãè² è²¬åå¯è§£éï¼ä½çºçè«æ¶æ§ï¼ä¸¦å°éäºååå°æå° DH è¦æ±ãå¨æ­¤å°æä¸­ï¼æåç´å¥ç¯ä¾ç ç©¶å°æ¡ãæå¾ï¼æåæ¢è¨å¦ä½å° DH çè¦è§£æç¨æ¼ HIï¼ä¸¦è¨è«çµåéå©åå­¸ç§çéæ¾ææ°ã

##### **Ethical Framework for Responsible Foundational Models in Medical Imaging**
2406.11868v1 by Abhijit Das, Debesh Jha, Jasmer Sanjotra, Onkar Susladkar, Suramyaa Sarkar, Ashish Rauniyar, Nikhil Tomar, Vanshali Sharma, Ulas Bagci

Foundational models (FMs) have tremendous potential to revolutionize medical
imaging. However, their deployment in real-world clinical settings demands
extensive ethical considerations. This paper aims to highlight the ethical
concerns related to FMs and propose a framework to guide their responsible
development and implementation within medicine. We meticulously examine ethical
issues such as privacy of patient data, bias mitigation, algorithmic
transparency, explainability and accountability. The proposed framework is
designed to prioritize patient welfare, mitigate potential risks, and foster
trust in AI-assisted healthcare.

æè¦ï¼åºç¤æ¨¡å (FM) å·æå¾¹åºæ¹è®é«å­¸å½±åçå·¨å¤§æ½åãç¶èï¼å®åå¨ç¾å¯¦ä¸çè¨åºç°å¢ä¸­çé¨ç½²éè¦å»£æ³çå«çèéãæ¬ææ¨å¨å¼·èª¿è FM ç¸éçå«çåé¡ï¼ä¸¦æåºä¸åæ¡æ¶ä¾æå°å®åå¨é«å­¸ä¸­çè² è²¬ä»»éç¼åå¯¦æ½ãæåä»ç´°å¯©æ¥äºå«çåé¡ï¼ä¾å¦æ£èæ¸æé±ç§ãåå·®ç·©è§£ãæ¼ç®æ³éæåº¦ãå¯è§£éæ§ååè²¬å¶ãææåºçæ¡æ¶æ¨å¨åªåèæ®æ£èç¦å©ãæ¸è¼æ½å¨é¢¨éªï¼ä¸¦å¹é¤å° AI è¼å©é«çä¿å¥çä¿¡ä»»ã

##### **Advancements in Radiomics and Artificial Intelligence for Thyroid Cancer Diagnosis**
2404.07239v1 by Milad Yousefi, Shadi Farabi Maleki, Ali Jafarizadeh, Mahya Ahmadpour Youshanlui, Aida Jafari, Siamak Pedrammehr, Roohallah Alizadehsani, Ryszard Tadeusiewicz, Pawel Plawiak

Thyroid cancer is an increasing global health concern that requires advanced
diagnostic methods. The application of AI and radiomics to thyroid cancer
diagnosis is examined in this review. A review of multiple databases was
conducted in compliance with PRISMA guidelines until October 2023. A
combination of keywords led to the discovery of an English academic publication
on thyroid cancer and related subjects. 267 papers were returned from the
original search after 109 duplicates were removed. Relevant studies were
selected according to predetermined criteria after 124 articles were eliminated
based on an examination of their abstract and title. After the comprehensive
analysis, an additional six studies were excluded. Among the 28 included
studies, radiomics analysis, which incorporates ultrasound (US) images,
demonstrated its effectiveness in diagnosing thyroid cancer. Various results
were noted, some of the studies presenting new strategies that outperformed the
status quo. The literature has emphasized various challenges faced by AI
models, including interpretability issues, dataset constraints, and operator
dependence. The synthesized findings of the 28 included studies mentioned the
need for standardization efforts and prospective multicenter studies to address
these concerns. Furthermore, approaches to overcome these obstacles were
identified, such as advances in explainable AI technology and personalized
medicine techniques. The review focuses on how AI and radiomics could transform
the diagnosis and treatment of thyroid cancer. Despite challenges, future
research on multidisciplinary cooperation, clinical applicability validation,
and algorithm improvement holds the potential to improve patient outcomes and
diagnostic precision in the treatment of thyroid cancer.

æè¦ï¼ç²çèºçæ¯ä¸ç¨®æ¥çå´éçå¨çå¥åº·åé¡ï¼éè¦åé²çè¨ºæ·æ¹æ³ãæ¬ç¯è©è«æ¢è¨äºäººå·¥æºè½èæ¾å°ç¹å¾µåæå¨ç²çèºçè¨ºæ·ä¸­çæç¨ãå¨ç¬¦å PRISMA æåçææ³ä¸ï¼å°å¤åè³æåº«é²è¡äºåé¡§ï¼ç´å° 2023 å¹´ 10 æãééçµåééµå­ï¼ç¼ç¾äºä¸ç¯éæ¼ç²çèºçåç¸éä¸»é¡çè±æå­¸è¡åºçç©ãå¨ç§»é¤ 109 ç¯éè¤æç»å¾ï¼åå§æå°å±åå³ 267 ç¯è«æãå¨æ ¹æé åç¢ºå®çæ¨æºï¼æ·æ±°äº 124 ç¯æç« çæè¦åæ¨é¡å¾ï¼é¸åºäºç¸éç ç©¶ãå¨é²è¡å¨é¢åæå¾ï¼é¡å¤æé¤äºå­é ç ç©¶ãå¨ç´å¥ç 28 é ç ç©¶ä¸­ï¼çµåè¶é³æ³¢ (US) å½±åçæ¾å°ç¹å¾µåæï¼è­æäºå¶å¨è¨ºæ·ç²çèºçæ¹é¢çæææ§ãç ç©¶çµæä¸ä¸ï¼æäºç ç©¶æåºäºåªæ¼ç¾ççæ°ç­ç¥ãæç»å¼·èª¿äºäººå·¥æºè½æ¨¡åé¢è¨çåç¨®ææ°ï¼åæ¬å¯è§£éæ§åé¡ãè³æééå¶åæä½å¡ä¾è³´æ§ã28 é ç´å¥ç ç©¶çç¶åç¼ç¾æå°ï¼éè¦æ¨æºåå·¥ä½ååç»æ§å¤ä¸­å¿ç ç©¶ä¾è§£æ±ºéäºåé¡ãæ­¤å¤ï¼éç¢ºå®äºåæéäºéç¤çæ¹æ³ï¼ä¾å¦å¯è§£éäººå·¥æºè½æè¡ååäººåé«çæè¡çé²æ­¥ãæ¬ç¯è©è«éé»æ¢è¨äºäººå·¥æºè½åæ¾å°ç¹å¾µåæå¦ä½è½è®ç²çèºççè¨ºæ·åæ²»çãåç®¡å­å¨ææ°ï¼ä½æªä¾å°å¤å­¸ç§åä½ãè¨åºé©ç¨æ§é©è­åæ¼ç®æ³æ¹é²çç ç©¶ï¼ä»ææ½åæ¹åç²çèºçæ²»çä¸­çæ£èé å¾åè¨ºæ·ç²¾æºåº¦ã

##### **Predictive Modeling for Breast Cancer Classification in the Context of Bangladeshi Patients: A Supervised Machine Learning Approach with Explainable AI**
2404.04686v1 by Taminul Islam, Md. Alif Sheakh, Mst. Sazia Tahosin, Most. Hasna Hena, Shopnil Akash, Yousef A. Bin Jardan, Gezahign Fentahun Wondmie, Hiba-Allah Nafidi, Mohammed Bourhia

Breast cancer has rapidly increased in prevalence in recent years, making it
one of the leading causes of mortality worldwide. Among all cancers, it is by
far the most common. Diagnosing this illness manually requires significant time
and expertise. Since detecting breast cancer is a time-consuming process,
preventing its further spread can be aided by creating machine-based forecasts.
Machine learning and Explainable AI are crucial in classification as they not
only provide accurate predictions but also offer insights into how the model
arrives at its decisions, aiding in the understanding and trustworthiness of
the classification results. In this study, we evaluate and compare the
classification accuracy, precision, recall, and F-1 scores of five different
machine learning methods using a primary dataset (500 patients from Dhaka
Medical College Hospital). Five different supervised machine learning
techniques, including decision tree, random forest, logistic regression, naive
bayes, and XGBoost, have been used to achieve optimal results on our dataset.
Additionally, this study applied SHAP analysis to the XGBoost model to
interpret the model's predictions and understand the impact of each feature on
the model's output. We compared the accuracy with which several algorithms
classified the data, as well as contrasted with other literature in this field.
After final evaluation, this study found that XGBoost achieved the best model
accuracy, which is 97%.

æè¦ï¼<paragraph>è¿å¹´ä¾ï¼ä¹³çççè¡çè¿éå¢å ï¼ä½¿å¶æçºå¨çä¸»è¦çæ­»äº¡åå ä¹ä¸ãå¨ææççä¸­ï¼ä¹³çè¿ä»çºæ­¢æ¯æå¸¸è¦çãæåè¨ºæ·æ­¤ç¾çéè¦å¤§éçæéåå°æ¥­ç¥è­ãç±æ¼ä¹³ççæª¢æ¸¬éç¨èæï¼å æ­¤ééå»ºç«æ©å¨å­¸ç¿æ¨¡åä¾é æ¸¬ï¼æå©æ¼é²æ­¢å¶é²ä¸æ­¥æ´æ£ãæ©å¨å­¸ç¿åå¯è§£é AI å¨åé¡ä¸­è³ééè¦ï¼å çºå®åä¸åå¯ä»¥æä¾æºç¢ºçé æ¸¬ï¼éå¯ä»¥æ·±å¥äºè§£æ¨¡åå¦ä½ååºæ±ºç­ï¼æå©æ¼çè§£åä¿¡è³´åé¡çµæãå¨æ­¤ç ç©¶ä¸­ï¼æåè©ä¼°ä¸¦æ¯è¼äºäºç¨®ä¸åçæ©å¨å­¸ç¿æ¹æ³çåé¡æºç¢ºåº¦ãç²¾ç¢ºåº¦ãå¬åçå F1 åæ¸ï¼ä½¿ç¨äºä¸åä¸»è¦çè³æéï¼éå¡é«å­¸é¢é«é¢ç 500 åæ£èï¼ãäºç¨®ä¸åçç£ç£å¼æ©å¨å­¸ç¿æè¡ï¼åæ¬æ±ºç­æ¨¹ãé¨æ©æ£®æãéè¼¯è¿´æ­¸ãæ´ç´ è²æ°å XGBoostï¼å·²ç¨æ¼å¨æåçè³æéä¸åå¾æä½³çµæãæ­¤å¤ï¼æ¬ç ç©¶å° SHAP åææç¨æ¼ XGBoost æ¨¡åï¼ä»¥è§£éæ¨¡åçé æ¸¬ä¸¦äºè§£æ¯åç¹å¾µå°æ¨¡åè¼¸åºçå½±é¿ãæåæ¯è¼äºå¹¾ç¨®æ¼ç®æ³å°è³æé²è¡åé¡çæºç¢ºåº¦ï¼ä¸¦èè©²é åçå¶ä»æç»é²è¡å°æ¯ãå¨æå¾è©ä¼°å¾ï¼æ¬ç ç©¶ç¼ç¾ XGBoost éå°äºæä½³çæ¨¡åæºç¢ºåº¦ï¼çº 97%ã</paragraph>

##### **Enhancing Breast Cancer Diagnosis in Mammography: Evaluation and Integration of Convolutional Neural Networks and Explainable AI**
2404.03892v3 by Maryam Ahmed, Tooba Bibi, Rizwan Ahmed Khan, Sidra Nasir

The Deep learning (DL) models for diagnosing breast cancer from mammographic
images often operate as "black boxes", making it difficult for healthcare
professionals to trust and understand their decision-making processes. The
study presents an integrated framework combining Convolutional Neural Networks
(CNNs) and Explainable Artificial Intelligence (XAI) for the enhanced diagnosis
of breast cancer using the CBIS-DDSM dataset. The methodology encompasses an
elaborate data preprocessing pipeline and advanced data augmentation techniques
to counteract dataset limitations and transfer learning using pre-trained
networks such as VGG-16, Inception-V3 and ResNet was employed. A focal point of
our study is the evaluation of XAI's effectiveness in interpreting model
predictions, highlighted by utilizing the Hausdorff measure to assess the
alignment between AI-generated explanations and expert annotations
quantitatively. This approach is critical for XAI in promoting trustworthiness
and ethical fairness in AI-assisted diagnostics. The findings from our research
illustrate the effective collaboration between CNNs and XAI in advancing
diagnostic methods for breast cancer, thereby facilitating a more seamless
integration of advanced AI technologies within clinical settings. By enhancing
the interpretability of AI driven decisions, this work lays the groundwork for
improved collaboration between AI systems and medical practitioners, ultimately
enriching patient care. Furthermore, the implications of our research extended
well beyond the current methodologies. It encourages further research into how
to combine multimodal data and improve AI explanations to meet the needs of
clinical practice.

æè¦ï¼æ·±åº¦å­¸ç¿ (DL) ç¨æ¼å¾ä¹³æ¿æå½±è¡å½±åè¨ºæ·ä¹³ççæ¨¡åéå¸¸ä»¥ãé»çå­ãæ¹å¼éä½ï¼éä½¿å¾é«çä¿å¥å°æ¥­äººå¡é£ä»¥ä¿¡ä»»åçè§£å¶æ±ºç­éç¨ãæ¬ç ç©¶æåºä¸åæ´åæ¶æ§ï¼çµåå·ç©ç¥ç¶ç¶²è·¯ (CNN) åå¯è§£éäººå·¥æºæ§ (XAI)ï¼ä»¥ä½¿ç¨ CBIS-DDSM è³æéå¢å¼·ä¹³ççè¨ºæ·ãæ¹æ³åå«ä¸åç²¾ç´°çè³æåèçç®¡ç·åé²éè³ææ´åæè¡ï¼ä»¥å°æè³æééå¶ï¼ä¸¦æ¡ç¨é åè¨ç·´çç¶²è·¯ï¼ä¾å¦ VGG-16ãInception-V3 å ResNetï¼é²è¡é·ç§»å­¸ç¿ãæåç ç©¶çéé»æ¯è©ä¼° XAI å¨è§£éæ¨¡åé æ¸¬ä¸­çæææ§ï¼éé»å©ç¨è±ªæ¯å¤å¤«æ¸¬åº¦éåè©ä¼° AI çæçè§£éåå°å®¶è¨»è§£ä¹éçä¸è´æ§ãéç¨®æ¹æ³å°æ¼ XAI å¨ä¿é² AI è¼å©è¨ºæ·ä¸­çå¯ä¿¡åº¦åå«çå¬å¹³æ§è³ééè¦ãæåç ç©¶çç¼ç¾èªªæäº CNN å XAI å¨æ¨é²ä¹³çè¨ºæ·æ¹æ³ä¸­çææåä½ï¼å¾èä¿é²äºåé² AI æè¡å¨è¨åºç°å¢ä¸­çæ´é æ¢æ´åãééå¢å¼· AI é©åæ±ºç­çå¯è§£éæ§ï¼éé å·¥ä½çº AI ç³»çµ±åé«çå¾æ¥­äººå¡ä¹éçæ¹ååä½å¥ å®äºåºç¤ï¼æçµè±å¯äºæ£èç§è­·ãæ­¤å¤ï¼æåç ç©¶çå½±é¿é é è¶åºäºç®åçæè¡ãå®é¼åµé²ä¸æ­¥ç ç©¶å¦ä½çµåå¤æ¨¡å¼è³æä¸¦æ¹å AI è§£éï¼ä»¥æ»¿è¶³è¨åºå¯¦åçéæ±ã

##### **Advancing Multimodal Data Fusion in Pain Recognition: A Strategy Leveraging Statistical Correlation and Human-Centered Perspectives**
2404.00320v2 by Xingrui Gu, Zhixuan Wang, Irisa Jin, Zekun Wu

This research presents a novel multimodal data fusion methodology for pain
behavior recognition, integrating statistical correlation analysis with
human-centered insights. Our approach introduces two key innovations: 1)
integrating data-driven statistical relevance weights into the fusion strategy
to effectively utilize complementary information from heterogeneous modalities,
and 2) incorporating human-centric movement characteristics into multimodal
representation learning for detailed modeling of pain behaviors. Validated
across various deep learning architectures, our method demonstrates superior
performance and broad applicability. We propose a customizable framework that
aligns each modality with a suitable classifier based on statistical
significance, advancing personalized and effective multimodal fusion.
Furthermore, our methodology provides explainable analysis of multimodal data,
contributing to interpretable and explainable AI in healthcare. By highlighting
the importance of data diversity and modality-specific representations, we
enhance traditional fusion techniques and set new standards for recognizing
complex pain behaviors. Our findings have significant implications for
promoting patient-centered healthcare interventions and supporting explainable
clinical decision-making.

æè¦ï¼æ¬ç ç©¶æåºäºä¸ç¨®åµæ°çå¤æ¨¡ææ¸æèåæ¹æ³ï¼ç¨æ¼ç¼çè¡çºè­å¥ï¼å°çµ±è¨ç¸éåæèä»¥äººçºä¸­å¿çè¦è§£ç¸çµåãæåçåæ³å¼å¥äºå©é ééµåµæ°ï¼1) å°æ¸æé©åççµ±è¨ç¸éæ¬éæ´åå°èåç­ç¥ä¸­ï¼ä»¥ææå©ç¨ä¾èªç°è³ªæ¨¡æçè£åä¿¡æ¯ï¼ä»¥å 2) å°ä»¥äººçºä¸­å¿çéåç¹å¾µç´å¥å¤æ¨¡æè¡¨ç¤ºå­¸ç¿ä¸­ï¼ä»¥è©³ç´°å»ºæ¨¡ç¼çè¡çºãæåçæ¨¡åå¨åç¨®æ·±åº¦å­¸ç¿æ¶æ§ä¸­å¾å°é©è­ï¼å±ç¤ºäºåè¶çæ§è½åå»£æ³çé©ç¨æ§ãæåæåºäºä¸åå¯èªå®ç¾©çæ¡æ¶ï¼æ ¹æçµ±è¨é¡¯èæ§å°æ¯åæ¨¡æèåé©çåé¡å¨å°é½ï¼æ¨é²åæ§ååææçå¤æ¨¡æèåãæ­¤å¤ï¼æåçæ¨¡åæä¾å°å¤æ¨¡ææ¸æçå¯è§£éåæï¼æå©æ¼é«çä¿å¥ä¸­çå¯è§£éåå¯è§£é AIãééå¼·èª¿æ¸æå¤æ¨£æ§åæ¨¡æç¹å®è¡¨ç¤ºçéè¦æ§ï¼æåå¢å¼·äºå³çµ±çèåæè¡ï¼ä¸¦çºè­å¥è¤éçç¼çè¡çºè¨­å®äºæ°çæ¨æºãæåçç¼ç¾å°ä¿é²ä»¥æ£èçºä¸­å¿çé«çä¿å¥å¹²é åæ¯æå¯è§£éçè¨åºæ±ºç­å¶å®å·æéè¦æç¾©ã

##### **Addressing Social Misattributions of Large Language Models: An HCXAI-based Approach**
2403.17873v1 by Andrea Ferrario, Alberto Termine, Alessandro Facchini

Human-centered explainable AI (HCXAI) advocates for the integration of social
aspects into AI explanations. Central to the HCXAI discourse is the Social
Transparency (ST) framework, which aims to make the socio-organizational
context of AI systems accessible to their users. In this work, we suggest
extending the ST framework to address the risks of social misattributions in
Large Language Models (LLMs), particularly in sensitive areas like mental
health. In fact LLMs, which are remarkably capable of simulating roles and
personas, may lead to mismatches between designers' intentions and users'
perceptions of social attributes, risking to promote emotional manipulation and
dangerous behaviors, cases of epistemic injustice, and unwarranted trust. To
address these issues, we propose enhancing the ST framework with a fifth
'W-question' to clarify the specific social attributions assigned to LLMs by
its designers and users. This addition aims to bridge the gap between LLM
capabilities and user perceptions, promoting the ethically responsible
development and use of LLM-based technology.

æè¦ï¼ä»¥äººä¸ºæ¬çå¯è§£é AI (HCXAI) å¡å¯¼å°ç¤¾ä¼å±é¢æ´åå° AI è§£éä¸­ãHCXAI è¯è¯­çæ ¸å¿æ¯ç¤¾ä¼éæåº¦ (ST) æ¡æ¶ï¼å¶ç®æ æ¯è®© AI ç³»ç»çç¤¾ä¼ç»ç»èæ¯å¯¹ç¨æ·æ¥è¯´æ¯å¯çè§£çãå¨è¿é¡¹å·¥ä½ä¸­ï¼æä»¬å»ºè®®æ©å± ST æ¡æ¶ä»¥è§£å³å¤§åè¯­è¨æ¨¡å (LLM) ä¸­ç¤¾ä¼éè¯¯å½å çé£é©ï¼å°¤å¶æ¯å¨å¿çå¥åº·ç­ææé¢åãäºå®ä¸ï¼LLM è½å¤åºè²å°æ¨¡æè§è²åäººæ ¼ï¼è¿å¯è½å¯¼è´è®¾è®¡èçæå¾åç¨æ·å¯¹ç¤¾ä¼å±æ§çè®¤ç¥ä¹é´åºç°ééï¼ä»èæé£é©ä¿è¿æç»ªæçºµåå±é©è¡ä¸ºãè®¤ç¥ä¸å¬æ­£åä¸åççä¿¡ä»»ãä¸ºäºè§£å³è¿äºé®é¢ï¼æä»¬å»ºè®®ç¨ç¬¬äºä¸ªâW é®é¢âæ¥å¢å¼º ST æ¡æ¶ï¼ä»¥æç¡®è®¾è®¡èåç¨æ·èµäº LLM çå·ä½ç¤¾ä¼å±æ§ãæ­¤è¡¥åæ¨å¨å¼¥å LLM è½ååç¨æ·è®¤ç¥ä¹é´çå·®è·ï¼ä¿è¿åºäº LLM çææ¯å¨éå¾·ä¸è´è´£ä»»å°å¼ååä½¿ç¨ã

##### **Clinical Domain Knowledge-Derived Template Improves Post Hoc AI Explanations in Pneumothorax Classification**
2403.18871v1 by Han Yuan, Chuan Hong, Pengtao Jiang, Gangming Zhao, Nguyen Tuan Anh Tran, Xinxing Xu, Yet Yen Yan, Nan Liu

Background: Pneumothorax is an acute thoracic disease caused by abnormal air
collection between the lungs and chest wall. To address the opaqueness often
associated with deep learning (DL) models, explainable artificial intelligence
(XAI) methods have been introduced to outline regions related to pneumothorax
diagnoses made by DL models. However, these explanations sometimes diverge from
actual lesion areas, highlighting the need for further improvement. Method: We
propose a template-guided approach to incorporate the clinical knowledge of
pneumothorax into model explanations generated by XAI methods, thereby
enhancing the quality of these explanations. Utilizing one lesion delineation
created by radiologists, our approach first generates a template that
represents potential areas of pneumothorax occurrence. This template is then
superimposed on model explanations to filter out extraneous explanations that
fall outside the template's boundaries. To validate its efficacy, we carried
out a comparative analysis of three XAI methods with and without our template
guidance when explaining two DL models in two real-world datasets. Results: The
proposed approach consistently improved baseline XAI methods across twelve
benchmark scenarios built on three XAI methods, two DL models, and two
datasets. The average incremental percentages, calculated by the performance
improvements over the baseline performance, were 97.8% in Intersection over
Union (IoU) and 94.1% in Dice Similarity Coefficient (DSC) when comparing model
explanations and ground-truth lesion areas. Conclusions: In the context of
pneumothorax diagnoses, we proposed a template-guided approach for improving AI
explanations. We anticipate that our template guidance will forge a fresh
approach to elucidating AI models by integrating clinical domain expertise.

æè¦ï¼<paragraph>èæ¯ï¼æ°£è¸æ¯ä¸ç¨®å èºé¨èè¸å£ä¹éç°å¸¸éæ°£æå¼èµ·çæ¥æ§è¸èç¾çãçºäºè§£æ±ºæ·±åº¦å­¸ç¿ï¼DLï¼æ¨¡åç¶å¸¸ä¼´é¨çä¸éææ§ï¼å¯è§£éäººå·¥æºæ§ï¼XAIï¼æ¹æ³å·²è¢«å¼å¥ï¼ç¨æ¼æ¦è¿°è DL æ¨¡åååºçæ°£è¸è¨ºæ·ç¸éçååãç¶èï¼éäºè§£éæææèå¯¦éçç¶ååææåºå¥ï¼çªé¡¯åºé²ä¸æ­¥æ¹é²çå¿è¦æ§ãæ¹æ³ï¼æåæåºäºä¸ç¨®æ¨¡æ¿å¼å°å¼æ¹æ³ï¼å°æ°£è¸çè¨åºç¥è­ç´å¥ XAI æ¹æ³ç¢ççæ¨¡åè§£éä¸­ï¼å¾èæåéäºè§£éçåè³ªãå©ç¨æ¾å°ç§é«å¸«å»ºç«ççç¶æç¹ªï¼æåçåæ³é¦åç¢çä¸åæ¨¡æ¿ï¼ç¨æ¼è¡¨ç¤ºæ°£è¸å¯è½ç¼ççååãç¶å¾å°æ­¤æ¨¡æ¿çå å¨æ¨¡åè§£éä¸ï¼ä»¥ç¯©é¸åºè¶åºæ¨¡æ¿éççç¡éè§£éãçºäºé©è­å¶æåï¼æåå°ä¸ç¨® XAI æ¹æ³é²è¡äºæ¯è¼åæï¼å¨å©åçå¯¦ä¸çè³æéä¸­è§£éå©å DL æ¨¡åæï¼åå¥æ¡ç¨åä¸æ¡ç¨æåçæ¨¡æ¿å¼å°ãçµæï¼ææåºçæ¹æ³å¨å»ºç«æ¼ä¸ç¨® XAI æ¹æ³ãå©å DL æ¨¡ååå©åè³æéçåäºç¨®åºæºæå¢ä¸­ï¼å§çµæ¹åäºåºæº XAI æ¹æ³ãå¨æ¯è¼æ¨¡åè§£éåçå¯¦çç¶ååæï¼ééåºæºæè½çæè½æ¹é²è¨ç®åºçå¹³åå¢éç¾åæ¯çºäº¤éæ¯ï¼IoUï¼ç 97.8% åéª°å­ç¸ä¼¼æ§ä¿æ¸ï¼DSCï¼ç 94.1%ãçµè«ï¼å¨æ°£è¸è¨ºæ·çèæ¯ä¸ï¼æåæåºäºä¸ç¨®æ¨¡æ¿å¼å°å¼æ¹æ³ï¼ç¨æ¼æ¹å AI è§£éãæåé ææåçæ¨¡æ¿å¼å°å°ééæ´åè¨åºé åå°æ¥­ç¥è­ï¼çºé¡æ AI æ¨¡åå»ºç«ä¸ç¨®æ°æ¹æ³ã</paragraph>

##### **Enhancing Neural Machine Translation of Low-Resource Languages: Corpus Development, Human Evaluation and Explainable AI Architectures**
2403.01580v1 by SÃ©amus Lankford

In the current machine translation (MT) landscape, the Transformer
architecture stands out as the gold standard, especially for high-resource
language pairs. This research delves into its efficacy for low-resource
language pairs including both the English$\leftrightarrow$Irish and
English$\leftrightarrow$Marathi language pairs. Notably, the study identifies
the optimal hyperparameters and subword model type to significantly improve the
translation quality of Transformer models for low-resource language pairs.
  The scarcity of parallel datasets for low-resource languages can hinder MT
development. To address this, gaHealth was developed, the first bilingual
corpus of health data for the Irish language. Focusing on the health domain,
models developed using this in-domain dataset exhibited very significant
improvements in BLEU score when compared with models from the LoResMT2021
Shared Task. A subsequent human evaluation using the multidimensional quality
metrics error taxonomy showcased the superior performance of the Transformer
system in reducing both accuracy and fluency errors compared to an RNN-based
counterpart.
  Furthermore, this thesis introduces adaptNMT and adaptMLLM, two open-source
applications streamlined for the development, fine-tuning, and deployment of
neural machine translation models. These tools considerably simplify the setup
and evaluation process, making MT more accessible to both developers and
translators. Notably, adaptNMT, grounded in the OpenNMT ecosystem, promotes
eco-friendly natural language processing research by highlighting the
environmental footprint of model development. Fine-tuning of MLLMs by adaptMLLM
demonstrated advancements in translation performance for two low-resource
language pairs: English$\leftrightarrow$Irish and
English$\leftrightarrow$Marathi, compared to baselines from the LoResMT2021
Shared Task.

æè¦ï¼<paragraph>å¨ç¶åæ©å¨ç¿»è­¯ (MT) é åä¸­ï¼Transformer æ¶æ§è«ç©èåºï¼æçºé»éæ¨æºï¼ç¹å¥æ¯å°æ¼é«è³æºèªè¨å°ãæ¬ç ç©¶æ¢è¨å¶å°ä½è³æºèªè¨å°çæè½ï¼åæ¬è±èªâæç¾è­èªåè±èªâé¦¬æå°èªèªè¨å°ãå¼å¾æ³¨æçæ¯ï¼æ¬ç ç©¶è­å¥åºæä½³è¶åæ¸åå­è©æ¨¡åé¡åï¼ä»¥é¡¯èæé« Transformer æ¨¡åå°ä½è³æºèªè¨å°çç¿»è­¯åè³ªã
ä½è³æºèªè¨çå¹³è¡è³æéçç¨ç¼ºæé»ç¤ MT çç¼å±ãçºäºè§£æ±ºéååé¡ï¼éç¼äº gaHealthï¼éæ¯æç¾è­èªçç¬¬ä¸åéèªå¥åº·è³æèªæåº«ãå°æ³¨æ¼å¥åº·é åï¼ä½¿ç¨æ­¤åå§è³æééç¼çæ¨¡åå¨ BLEU å¾åæ¹é¢è¡¨ç¾åºéå¸¸é¡¯èçé²æ­¥ï¼è LoResMT2021 å±äº«ä»»åä¸­çæ¨¡åç¸æ¯ãé¨å¾ä½¿ç¨å¤ç¶­åè³ªææ¨é¯èª¤åé¡æ³é²è¡çäººå·¥è©ä¼°é¡¯ç¤ºï¼èåºæ¼ RNN çå°ææ¨¡åç¸æ¯ï¼Transformer ç³»çµ±å¨æ¸å°æºç¢ºæ§åæµæ¢æ§é¯èª¤æ¹é¢è¡¨ç¾åºåªç°çæ§è½ã
æ­¤å¤ï¼æ¬è«æä»ç´¹äº adaptNMT å adaptMLLMï¼éå©åéæºæç¨ç¨å¼ç°¡åäºç¥ç¶æ©å¨ç¿»è­¯æ¨¡åçéç¼ãå¾®èª¿åé¨ç½²ãéäºå·¥å·å¤§å¹ç°¡åäºè¨­å®åè©ä¼°æµç¨ï¼è® MT æ´å®¹æè®éç¼äººå¡åç¿»è­¯äººå¡ä½¿ç¨ãå¼å¾æ³¨æçæ¯ï¼adaptNMT ä»¥ OpenNMT çæç³»çµ±çºåºç¤ï¼ééå¼·èª¿æ¨¡åéç¼çç°å¢è¶³è·¡ä¾ä¿é²çæåå¥½çèªç¶èªè¨èçç ç©¶ãè LoResMT2021 å±äº«ä»»åä¸­çåºæºç¸æ¯ï¼adaptMLLM å° MLLM çå¾®èª¿è­æäºè±èªâæç¾è­èªåè±èªâé¦¬æå°èªéå©åä½è³æºèªè¨å°çç¿»è­¯æ§è½é²æ­¥ã</paragraph>

##### **Cause and Effect: Can Large Language Models Truly Understand Causality?**
2402.18139v3 by Swagata Ashwani, Kshiteesh Hegde, Nishith Reddy Mannuru, Mayank Jindal, Dushyant Singh Sengar, Krishna Chaitanya Rao Kathala, Dishant Banga, Vinija Jain, Aman Chadha

With the rise of Large Language Models(LLMs), it has become crucial to
understand their capabilities and limitations in deciphering and explaining the
complex web of causal relationships that language entails. Current methods use
either explicit or implicit causal reasoning, yet there is a strong need for a
unified approach combining both to tackle a wide array of causal relationships
more effectively. This research proposes a novel architecture called Context
Aware Reasoning Enhancement with Counterfactual Analysis(CARE CA) framework to
enhance causal reasoning and explainability. The proposed framework
incorporates an explicit causal detection module with ConceptNet and
counterfactual statements, as well as implicit causal detection through LLMs.
Our framework goes one step further with a layer of counterfactual explanations
to accentuate LLMs understanding of causality. The knowledge from ConceptNet
enhances the performance of multiple causal reasoning tasks such as causal
discovery, causal identification and counterfactual reasoning. The
counterfactual sentences add explicit knowledge of the not caused by scenarios.
By combining these powerful modules, our model aims to provide a deeper
understanding of causal relationships, enabling enhanced interpretability.
Evaluation of benchmark datasets shows improved performance across all metrics,
such as accuracy, precision, recall, and F1 scores. We also introduce
CausalNet, a new dataset accompanied by our code, to facilitate further
research in this domain.

æè¦ï¼é¨èå¤§åèªè¨æ¨¡å (LLM) çèèµ·ï¼äºè§£å®åå¨è§£ç¢¼åè§£éèªè¨æèå«çè¤éå æéä¿ç¶²è·¯ä¸­çè½ååéå¶è®å¾è³ééè¦ãç®åçæè¡ä½¿ç¨æç¢ºæé±å«çå ææ¨çï¼ä½å¼·çéè¦ä¸ç¨®çµ±ä¸çæ¹æ³ï¼çµåå©èä»¥æ´ææå°èçå»£æ³çå æéä¿ãæ¬ç ç©¶æåºäºä¸ç¨®ç¨±çºæå¢æç¥æ¨çå¢å¼·èåäºå¯¦åæ (CARE CA) æ¡æ¶çæ°æ¶æ§ï¼ä»¥å¢å¼·å ææ¨çåå¯è§£éæ§ãæåºçæ¡æ¶çµåäºä½¿ç¨ ConceptNet ååäºå¯¦é³è¿°çæç¢ºå ææª¢æ¸¬æ¨¡çµï¼ä»¥åéé LLM é²è¡çé±å«å ææª¢æ¸¬ãæåçæ¡æ¶æ´é²ä¸æ­¥ï¼å å¥ä¸å±¤åäºå¯¦è§£éï¼ä»¥å¼·èª¿ LLM å°å æéä¿ççè§£ãä¾èª ConceptNet çç¥è­å¢å¼·äºå¤é å ææ¨çä»»åçå·è¡ï¼ä¾å¦å æç¼ç¾ãå æè­å¥ååäºå¯¦æ¨çãåäºå¯¦å¥å å¥äºæªç±æå¢é æçæç¢ºç¥è­ãééçµåéäºå¼·å¤§çæ¨¡çµï¼æåçæ¨¡åæ¨å¨æä¾å°å æéä¿æ´æ·±å¥ççè§£ï¼å¯¦ç¾å¢å¼·çå¯è§£éæ§ãåºæºè³æéçè©ä¼°é¡¯ç¤ºå¨ææææ¨ï¼ä¾å¦æºç¢ºåº¦ãç²¾ç¢ºåº¦ãå¬åçå F1 åæ¸ï¼ä¸é½æææåãæåéå¼å¥äº CausalNetï¼ä¸åæ°çè³æéï¼ä¸¦éä¸äºæåçç¨å¼ç¢¼ï¼ä»¥ä¿é²å¨éåé åçé²ä¸æ­¥ç ç©¶ã

##### **Artificial Intelligence and Diabetes Mellitus: An Inside Look Through the Retina**
2402.18600v1 by Yasin Sadeghi Bazargani, Majid Mirzaei, Navid Sobhi, Mirsaeed Abdollahi, Ali Jafarizadeh, Siamak Pedrammehr, Roohallah Alizadehsani, Ru San Tan, Sheikh Mohammed Shariful Islam, U. Rajendra Acharya

Diabetes mellitus (DM) predisposes patients to vascular complications.
Retinal images and vasculature reflect the body's micro- and macrovascular
health. They can be used to diagnose DM complications, including diabetic
retinopathy (DR), neuropathy, nephropathy, and atherosclerotic cardiovascular
disease, as well as forecast the risk of cardiovascular events. Artificial
intelligence (AI)-enabled systems developed for high-throughput detection of DR
using digitized retinal images have become clinically adopted. Beyond DR
screening, AI integration also holds immense potential to address challenges
associated with the holistic care of the patient with DM. In this work, we aim
to comprehensively review the literature for studies on AI applications based
on retinal images related to DM diagnosis, prognostication, and management. We
will describe the findings of holistic AI-assisted diabetes care, including but
not limited to DR screening, and discuss barriers to implementing such systems,
including issues concerning ethics, data privacy, equitable access, and
explainability. With the ability to evaluate the patient's health status vis a
vis DM complication as well as risk prognostication of future cardiovascular
complications, AI-assisted retinal image analysis has the potential to become a
central tool for modern personalized medicine in patients with DM.

æè¦ï¼ç³å°¿çï¼DMï¼ä½¿æ£èå®¹æåºç¾è¡ç®¡ä½µç¼çã
è¦ç¶²èå½±ååè¡ç®¡åæ èº«é«çå¾®è¡ç®¡åå·¨è¡ç®¡å¥åº·çæ³ãå®åå¯ç¨æ¼è¨ºæ·ç³å°¿çä½µç¼çï¼åæ¬ç³å°¿çè¦ç¶²èçè®ï¼DRï¼ãç¥ç¶çè®ãèçååèç²¥æ¨£ç¡¬åæ§å¿è¡ç®¡ç¾çï¼ä»¥åé æ¸¬å¿è¡ç®¡äºä»¶çé¢¨éªãçºä½¿ç¨æ¸ä½åè¦ç¶²èå½±åé²è¡é«éé DR æª¢æ¸¬èéç¼çäººå·¥æºæ§ï¼AIï¼åç¨ç³»çµ±å·²å¨è¨åºæ¡ç¨ãé¤äº DR ç¯©æª¢å¤ï¼AI æ´åä¹å·æå·¨å¤§çæ½åä¾æå°èç³å°¿çæ£èæ´é«ç§è­·ç¸éçææ°ãå¨éé å·¥ä½ä¸­ï¼æåæ¨å¨å¨é¢åé¡§åºæ¼è¦ç¶²èå½±åç AI æç¨ç¸éç ç©¶çæç»ï¼éäºç ç©¶èç³å°¿ççè¨ºæ·ãé å¾åç®¡çæéãæåå°æè¿°æ´é« AI è¼å©ç³å°¿çç§è­·çç¼ç¾ï¼åæ¬ä½ä¸éæ¼ DR ç¯©æª¢ï¼ä¸¦è¨è«å¯¦æ½æ­¤é¡ç³»çµ±çéç¤ï¼åæ¬èå«çãè³æé±ç§ãå¬å¹³å­ååå¯è§£éæ§æéçåé¡ãééè©ä¼°æ£èçå¥åº·çæ³ï¼åæèéç³å°¿çä½µç¼çä»¥åæªä¾å¿è¡ç®¡ä½µç¼ççé¢¨éªé å¾ï¼AI è¼å©è¦ç¶²èå½±ååæææ½åæçºç³å°¿çæ£èç¾ä»£ååäººåé«ççä¸­å¿å·¥å·ã

##### **Multi-stakeholder Perspective on Responsible Artificial Intelligence and Acceptability in Education**
2402.15027v2 by A. J. Karran, P. Charland, J-T. Martineau, A. Ortiz de Guinea Lopez de Arana, AM. Lesage, S. Senecal, P-M. Leger

This study investigates the acceptability of different artificial
intelligence (AI) applications in education from a multi-stakeholder
perspective, including students, teachers, and parents. Acknowledging the
transformative potential of AI in education, it addresses concerns related to
data privacy, AI agency, transparency, explainability and the ethical
deployment of AI. Through a vignette methodology, participants were presented
with four scenarios where AI's agency, transparency, explainability, and
privacy were manipulated. After each scenario, participants completed a survey
that captured their perceptions of AI's global utility, individual usefulness,
justice, confidence, risk, and intention to use each scenario's AI if
available. The data collection comprising a final sample of 1198
multi-stakeholder participants was distributed through a partner institution
and social media campaigns and focused on individual responses to four AI use
cases. A mediation analysis of the data indicated that acceptance and trust in
AI varies significantly across stakeholder groups. We found that the key
mediators between high and low levels of AI's agency, transparency, and
explainability, as well as the intention to use the different educational AI,
included perceived global utility, justice, and confidence. The study
highlights that the acceptance of AI in education is a nuanced and multifaceted
issue that requires careful consideration of specific AI applications and their
characteristics, in addition to the diverse stakeholders' perceptions.

æè¦ï¼éé ç ç©¶å¾å¤åå©å®³éä¿äººçè§åº¦æ¢è¨ä¸åçäººå·¥æºæ§ (AI) æç¨å¨æè²ä¸çå¯æ¥åæ§ï¼åæ¬å­¸çãèå¸«åå®¶é·ãæ¿èª AI å¨æè²ä¸çè½åæ½åï¼å®è§£æ±ºäºèè³æé±ç§ãAI ä»£çãéæåº¦ãå¯è§£éæ§å AI çéå¾·é¨ç½²ç¸éççæ®ãééå°ææ²æ¹æ³ï¼åèèè¢«åç¾äºåç¨®æå¢ï¼å¶ä¸­ AI çä»£çãéæåº¦ãå¯è§£éæ§åé±ç§åå°æç¸±ãå¨æ¯åæå¢å¾ï¼åèèå®æäºä¸é èª¿æ¥ï¼è©²èª¿æ¥ææäºä»åå° AI çæ´é«æç¨ãåäººæç¨ãæ­£ç¾©ãä¿¡å¿ãé¢¨éªåå¦æå¯ç¨ï¼ä½¿ç¨æ¯åæå¢ç AI çæåççæ³ãè³æèéåå«ä¾èªåä½æ©æ§åç¤¾ç¾¤åªé«æ´»åç 1198 ä½å¤å©å®³éä¿äººåèèçæçµæ¨£æ¬ï¼ä¸¦å°æ³¨æ¼å°åå AI ä½¿ç¨æ¡ä¾çåå¥åæãå°è³æçèª¿è§£åæè¡¨æï¼å° AI çæ¥ååº¦åä¿¡ä»»å¨å©å®³éä¿äººåé«ä¹éæé¡¯èå·®ç°ãæåç¼ç¾ï¼AI çä»£çãéæåº¦åå¯è§£éæ§é«ä½ç¨åº¦ä¹éçééµèª¿è§£èï¼ä»¥åä½¿ç¨ä¸åæè² AI çæåï¼åæ¬æç¥å°çæ´é«æç¨ãæ­£ç¾©åä¿¡å¿ãéé ç ç©¶å¼·èª¿ï¼æ¥å AI å¨æè²ä¸çæç¨æ¯ä¸åå¾®å¦ä¸å¤é¢åçåé¡ï¼é¤äºä¸åçå©å®³éä¿äººççæ³å¤ï¼ééè¦ä»ç´°èæ®å·é«ç AI æç¨åå¶ç¹å¾µã

##### **Deciphering Heartbeat Signatures: A Vision Transformer Approach to Explainable Atrial Fibrillation Detection from ECG Signals**
2402.09474v2 by Aruna Mohan, Danne Elbers, Or Zilbershot, Fatemeh Afghah, David Vorchheimer

Remote patient monitoring based on wearable single-lead electrocardiogram
(ECG) devices has significant potential for enabling the early detection of
heart disease, especially in combination with artificial intelligence (AI)
approaches for automated heart disease detection. There have been prior studies
applying AI approaches based on deep learning for heart disease detection.
However, these models are yet to be widely accepted as a reliable aid for
clinical diagnostics, in part due to the current black-box perception
surrounding many AI algorithms. In particular, there is a need to identify the
key features of the ECG signal that contribute toward making an accurate
diagnosis, thereby enhancing the interpretability of the model. In the present
study, we develop a vision transformer approach to identify atrial fibrillation
based on single-lead ECG data. A residual network (ResNet) approach is also
developed for comparison with the vision transformer approach. These models are
applied to the Chapman-Shaoxing dataset to classify atrial fibrillation, as
well as another common arrhythmia, sinus bradycardia, and normal sinus rhythm
heartbeats. The models enable the identification of the key regions of the
heartbeat that determine the resulting classification, and highlight the
importance of P-waves and T-waves, as well as heartbeat duration and signal
amplitude, in distinguishing normal sinus rhythm from atrial fibrillation and
sinus bradycardia.

æè¦ï¼<paragraph>åºæ¼å¯ç©¿æ´å¼å®å°ç¨å¿é»å (ECG) è£ç½®çé ç«¯çæ£ç£æ¸¬å¨æ©æåµæ¸¬å¿èç¾çæ¹é¢å·æé¡¯èçæ½åï¼ç¹å¥æ¯èç¨æ¼èªååå¿èç¾çåµæ¸¬çäººå·¥æºæ§ (AI) æ¹æ³çµåä½¿ç¨æãååå·²æç ç©¶æç¨åºæ¼æ·±åº¦å­¸ç¿ç AI æ¹æ³é²è¡å¿èç¾çåµæ¸¬ãç¶èï¼éäºæ¨¡åå°æªè¢«å»£æ³æ¥åçºè¨åºè¨ºæ·çå¯é è¼å©å·¥å·ï¼é¨ååå å¨æ¼åç¹è¨±å¤ AI æ¼ç®æ³çç¶åé»ç®±æç¥ãç¹å¥æ¯ï¼æå¿è¦æ¾åºæå©æ¼ååºæºç¢ºè¨ºæ·ç ECG è¨èééµç¹å¾µï¼å¾èå¢å¼·æ¨¡åçå¯è§£éæ§ãå¨æ¬ç ç©¶ä¸­ï¼æåéç¼äºä¸ç¨®è¦è¦ºè½æå¨æ¹æ³ï¼ä»¥æ ¹æå®å°ç¨ ECG è³ææ¾åºå¿æ¿é¡«åãæ®å·®ç¶²è·¯ (ResNet) æ¹æ³ä¹å·²éç¼åºä¾ï¼ä»¥ä¾¿èè¦è¦ºè½æå¨æ¹æ³é²è¡æ¯è¼ãéäºæ¨¡åæç¨æ¼ Chapman-Shaoxing è³æéï¼ä»¥åé¡å¿æ¿é¡«åï¼ä»¥åå¦ä¸ç¨®å¸¸è¦çå¿å¾ä¸æ´ï¼ç«æ§å¿åéç·©ï¼åæ­£å¸¸ç«æ§å¿å¾çå¿è·³ãéäºæ¨¡åè½å¤ æ¾åºæ±ºå®æçµåé¡çå¿è·³ééµååï¼ä¸¦å¼·èª¿ P æ³¢å T æ³¢ï¼ä»¥åå¿è·³æçºæéåè¨èæ¯å¹å¨ååæ­£å¸¸ç«æ§å¿å¾èå¿æ¿é¡«ååç«æ§å¿åéç·©æ¹é¢çéè¦æ§ã</paragraph>

##### **Illuminate: A novel approach for depression detection with explainable analysis and proactive therapy using prompt engineering**
2402.05127v1 by Aryan Agrawal

This paper introduces a novel paradigm for depression detection and treatment
using advanced Large Language Models (LLMs): Generative Pre-trained Transformer
4 (GPT-4), Llama 2 chat, and Gemini. These LLMs are fine-tuned with specialized
prompts to diagnose, explain, and suggest therapeutic interventions for
depression. A unique few-shot prompting method enhances the models' ability to
analyze and explain depressive symptoms based on the DSM-5 criteria. In the
interaction phase, the models engage in empathetic dialogue management, drawing
from resources like PsychDB and a Cognitive Behavioral Therapy (CBT) Guide,
fostering supportive interactions with individuals experiencing major
depressive disorders. Additionally, the research introduces the Illuminate
Database, enriched with various CBT modules, aiding in personalized therapy
recommendations. The study evaluates LLM performance using metrics such as F1
scores, Precision, Recall, Cosine similarity, and Recall-Oriented Understudy
for Gisting Evaluation (ROUGE) across different test sets, demonstrating their
effectiveness. This comprehensive approach blends cutting-edge AI with
established psychological methods, offering new possibilities in mental health
care and showcasing the potential of LLMs in revolutionizing depression
diagnosis and treatment strategies.

æè¦ï¼æ¬æä»ç´¹äºä¸ç¨®ä½¿ç¨åé²å¤§åèªè¨æ¨¡å (LLM) é²è¡æé¬±çåµæ¸¬åæ²»ççæ°æ¨¡å¼ï¼çæå¼é è¨ç·´Transformer 4 (GPT-4)ãLlama 2 èå¤©æ©å¨äººå Geminiãéäº LLM ç¶éå¾®èª¿ï¼å·åå°æ¥­æç¤ºï¼å¯è¨ºæ·ãè§£éä¸¦å»ºè­°æé¬±ççæ²»çä»å¥æ¹æ³ãä¸ç¨®ç¨ç¹çå°æ¬¡æç¤ºæ¹æ³å¢å¼·äºæ¨¡åæ ¹æ DSM-5 æ¨æºåæåè§£éæé¬±çççè½åãå¨äºåéæ®µï¼éäºæ¨¡åæåèåçå¿å°è©±ç®¡çï¼å¾ PsychDB åèªç¥è¡çºçæ³ (CBT) æåç­è³æºä¸­æ±²åï¼ä¿é²èç¶æ­·éåº¦æé¬±ççäººåçæ¯ææ§äºåãæ­¤å¤ï¼éé ç ç©¶éä»ç´¹äº Illuminate è³æåº«ï¼å¶ä¸­åå«åç¨® CBT æ¨¡çµï¼æå©æ¼åæ§åæ²»çå»ºè­°ãéé ç ç©¶ä½¿ç¨ F1 åæ¸ãæºç¢ºçãå¬åçãé¤å¼¦ç¸ä¼¼åº¦åé¢åå¬åçç Gisting è©ä¼°æ¿èº« (ROUGE) ç­ææ¨ï¼å¨ä¸åçæ¸¬è©¦éä¸­è©ä¼° LLM çè¡¨ç¾ï¼è­æäºå®åçæææ§ãéç¨®ç¶åæ¹æ³çµåäºå°ç«¯ç AI èæ¢å®çå¿çæ¹æ³ï¼çºå¿çä¿å¥æä¾äºæ°çå¯è½æ§ï¼ä¸¦å±ç¤ºäº LLM å¨é©æ°æé¬±çè¨ºæ·åæ²»çç­ç¥æ¹é¢çæ½åã

##### **Information That Matters: Exploring Information Needs of People Affected by Algorithmic Decisions**
2401.13324v6 by TimothÃ©e Schmude, Laura Koesten, Torsten MÃ¶ller, Sebastian Tschiatschek

Every AI system that makes decisions about people has a group of stakeholders
that are personally affected by these decisions. However, explanations of AI
systems rarely address the information needs of this stakeholder group, who
often are AI novices. This creates a gap between conveyed information and
information that matters to those who are impacted by the system's decisions,
such as domain experts and decision subjects. To address this, we present the
"XAI Novice Question Bank," an extension of the XAI Question Bank containing a
catalog of information needs from AI novices in two use cases: employment
prediction and health monitoring. The catalog covers the categories of data,
system context, system usage, and system specifications. We gathered
information needs through task-based interviews where participants asked
questions about two AI systems to decide on their adoption and received verbal
explanations in response. Our analysis showed that participants' confidence
increased after receiving explanations but that their understanding faced
challenges. These included difficulties in locating information and in
assessing their own understanding, as well as attempts to outsource
understanding. Additionally, participants' prior perceptions of the systems'
risks and benefits influenced their information needs. Participants who
perceived high risks sought explanations about the intentions behind a system's
deployment, while those who perceived low risks rather asked about the system's
operation. Our work aims to support the inclusion of AI novices in
explainability efforts by highlighting their information needs, aims, and
challenges. We summarize our findings as five key implications that can inform
the design of future explanations for lay stakeholder audiences.

æè¦ï¼<paragraph>æ¯åå°äººååºæ±ºå®ç AI ç³»çµ±é½æä¸ç¾¤å©å®³éä¿äºº
åå°éäºæ±ºå®çè¦ªèº«å½±é¿ãç¶èï¼AI
ç³»çµ±çè§£éå¾å°è½æ»¿è¶³éç¾¤å©å®³éä¿äººçè³è¨éæ±ï¼èä»å
éå¸¸é½æ¯ AI æ°æãéé æäºå³éè³è¨è
åå°ç³»çµ±æ±ºç­å½±é¿çäººå£«ï¼ä¾å¦é åå°å®¶åæ±ºç­ä¸»é«ï¼éè¦çè³è¨ä¹éçè½å·®ãçºäºè§£æ±ºéååé¡ï¼æåæåºäº
ãXAI æ°æåé¡åº«ãï¼å®æ¯ XAI åé¡åº«çå»¶ä¼¸ï¼åå«ä¾èª AI æ°æå¨å©åä½¿ç¨æ¡ä¾ä¸­çè³è¨éæ±ç®éï¼å°±æ¥­
é æ¸¬åå¥åº·ç£æ¸¬ãç®éæ¶µèäºè³æã
ç³»çµ±èæ¯ãç³»çµ±ä½¿ç¨åç³»çµ±è¦æ ¼ç­é¡å¥ãæåééä»»ååè¨ªè«æ¶éè³è¨éæ±ï¼åèèå¨è¨ªè«ä¸­è©¢åäºå©å AI ç³»çµ±çåé¡ï¼ä»¥æ±ºå®æ¯å¦æ¡ç¨å®åï¼ä¸¦æ¶å°å£é ­
è§£éä½çºåæãæåçåæé¡¯ç¤ºï¼åèèå¨æ¶å°è§£éå¾ä¿¡å¿æææåï¼ä½ä»åççè§£å»é¢è¨ææ°ãéäºææ°åæ¬é£ä»¥æ¾å°è³è¨åè©ä¼°èªå·±ççè§£ï¼ä»¥åè©¦åå¤å
çè§£ãæ­¤å¤ï¼åèèå°ç³»çµ±é¢¨éªåå¥½èçåååé¥å½±é¿äºä»åçè³è¨éæ±ãèªçºé¢¨éªé«çåèèå°æ±è§£éç³»çµ±é¨ç½²èå¾çæåï¼èèªçºé¢¨éªä½çäººåè©¢åç³»çµ±ç
æä½ãæåçç ç©¶æ¨å¨ééå¼·èª¿ AI æ°æçè³è¨éæ±ãç®æ¨å
ææ°ï¼ä¾æ¯æå° AI æ°æç´å¥å¯è§£éæ§å·¥ä½ä¸­ãæåå°æåçç ç©¶çµæç¸½çµçºäºåééµåç¤ºï¼éäºåç¤ºå¯ä»¥çºæªä¾éå°éå°æ¥­å©å®³éä¿äººåç¾çè§£éè¨­è¨æä¾åèã</paragraph>

##### **Evaluating Large Language Models on the GMAT: Implications for the Future of Business Education**
2401.02985v1 by Vahid Ashrafimoghari, Necdet GÃ¼rkan, Jordan W. Suchow

The rapid evolution of artificial intelligence (AI), especially in the domain
of Large Language Models (LLMs) and generative AI, has opened new avenues for
application across various fields, yet its role in business education remains
underexplored. This study introduces the first benchmark to assess the
performance of seven major LLMs, OpenAI's models (GPT-3.5 Turbo, GPT-4, and
GPT-4 Turbo), Google's models (PaLM 2, Gemini 1.0 Pro), and Anthropic's models
(Claude 2 and Claude 2.1), on the GMAT, which is a key exam in the admission
process for graduate business programs. Our analysis shows that most LLMs
outperform human candidates, with GPT-4 Turbo not only outperforming the other
models but also surpassing the average scores of graduate students at top
business schools. Through a case study, this research examines GPT-4 Turbo's
ability to explain answers, evaluate responses, identify errors, tailor
instructions, and generate alternative scenarios. The latest LLM versions,
GPT-4 Turbo, Claude 2.1, and Gemini 1.0 Pro, show marked improvements in
reasoning tasks compared to their predecessors, underscoring their potential
for complex problem-solving. While AI's promise in education, assessment, and
tutoring is clear, challenges remain. Our study not only sheds light on LLMs'
academic potential but also emphasizes the need for careful development and
application of AI in education. As AI technology advances, it is imperative to
establish frameworks and protocols for AI interaction, verify the accuracy of
AI-generated content, ensure worldwide access for diverse learners, and create
an educational environment where AI supports human expertise. This research
sets the stage for further exploration into the responsible use of AI to enrich
educational experiences and improve exam preparation and assessment methods.

æè¦ï¼äººå·¥æºæ§ (AI) çå¿«éæ¼é²ï¼å°¤å¶æ¯å¨å¤§åèªè¨æ¨¡å (LLM) åçæå¼ AI çé åï¼çºååé åçæç¨éåäºæ°éå¾ï¼ä½å¶å¨åæ¥­æè²ä¸­çè§è²ä»æªè¢«ååæ¢è¨ãæ¬ç ç©¶é¦æ¬¡å¼å¥äºåºæºï¼ç¨ä»¥è©ä¼°ä¸åä¸»è¦ LLM çæè½ï¼åæ¬ OpenAI çæ¨¡å (GPT-3.5 TurboãGPT-4 å GPT-4 Turbo)ãGoogle çæ¨¡å (PaLM 2ãGemini 1.0 Pro) å Anthropic çæ¨¡å (Claude 2 å Claude 2.1)ï¼éäºæ¨¡åå°ç¨æ¼ç ç©¶çåæ¥­èª²ç¨å¥å­¸ç¨åºä¸­çééµèè©¦ GMATãæåçåæé¡¯ç¤ºï¼å¤§å¤æ¸ LLM çè¡¨ç¾é½åªæ¼äººé¡èçï¼å¶ä¸­ GPT-4 Turbo ä¸ååªæ¼å¶ä»æ¨¡åï¼æ´è¶è¶äºé å°åå­¸é¢çç ç©¶çå¹³ååæ¸ãééæ¡ä¾ç ç©¶ï¼æ¬ç ç©¶æ¢è¨äº GPT-4 Turbo å¨è§£éç­æ¡ãè©ä¼°åæãè¾¨è­é¯èª¤ãèª¿æ´èªªæåç¢çæ¿ä»£æå¢æ¹é¢çè½åãèåä¸ä»£çæ¬ç¸æ¯ï¼ææ°ç LLM çæ¬ GPT-4 TurboãClaude 2.1 å Gemini 1.0 Pro å¨æ¨çä»»åæ¹é¢æé¡¯èçé²æ­¥ï¼å¸é¡¯äºå¶å¨è§£æ±ºè¤éåé¡æ¹é¢çæ½åãåç®¡ AI å¨æè²ãè©éåè¼å°æ¹é¢çæ¿è«¾å¾æç¢ºï¼ä½ä»æææ°å­å¨ãæåçç ç©¶ä¸åé¡æäº LLM çå­¸è¡æ½åï¼ä¹å¼·èª¿äºå¨æè²ä¸­å¯©æéç¼åæç¨ AI çå¿è¦æ§ãé¨è AI æè¡çé²æ­¥ï¼å»ºç« AI äºåçæ¶æ§ååå®ãé©è­ AI çæçå§å®¹çæºç¢ºæ§ãç¢ºä¿å¨çåå°å¤åå­¸ç¿èçå­åæ¬ï¼ä»¥ååµé ä¸å AI æ¯æäººé¡å°æ¥­ç¥è­çæè²ç°å¢è³ééè¦ãæ¬ç ç©¶çºé²ä¸æ­¥æ¢ç´¢è² è²¬ä»»å°ä½¿ç¨ AI ä¾è±å¯æè²é«é©ä¸¦æ¹åèè©¦æºååè©éæ¹æ³å¥ å®äºåºç¤ã

##### **XAI for In-hospital Mortality Prediction via Multimodal ICU Data**
2312.17624v1 by Xingqiao Li, Jindong Gu, Zhiyong Wang, Yancheng Yuan, Bo Du, Fengxiang He

Predicting in-hospital mortality for intensive care unit (ICU) patients is
key to final clinical outcomes. AI has shown advantaged accuracy but suffers
from the lack of explainability. To address this issue, this paper proposes an
eXplainable Multimodal Mortality Predictor (X-MMP) approaching an efficient,
explainable AI solution for predicting in-hospital mortality via multimodal ICU
data. We employ multimodal learning in our framework, which can receive
heterogeneous inputs from clinical data and make decisions. Furthermore, we
introduce an explainable method, namely Layer-Wise Propagation to Transformer,
as a proper extension of the LRP method to Transformers, producing explanations
over multimodal inputs and revealing the salient features attributed to
prediction. Moreover, the contribution of each modality to clinical outcomes
can be visualized, assisting clinicians in understanding the reasoning behind
decision-making. We construct a multimodal dataset based on MIMIC-III and
MIMIC-III Waveform Database Matched Subset. Comprehensive experiments on
benchmark datasets demonstrate that our proposed framework can achieve
reasonable interpretation with competitive prediction accuracy. In particular,
our framework can be easily transferred to other clinical tasks, which
facilitates the discovery of crucial factors in healthcare research.

æè¦ï¼é æ¸¬å è­·çæ¿ (ICU) çæ£çé¢å§æ­»äº¡çæ¯æçµè¨åºçµæçééµãAI å·²å±ç¾åºåªç°çæºç¢ºåº¦ï¼ä½å»ç¼ºä¹å¯è§£éæ§ãçºäºè§£æ±ºéååé¡ï¼æ¬ææåºäºä¸åå¯è§£éçå¤æ¨¡å¼æ­»äº¡çé æ¸¬å¨ (X-MMP)ï¼æ¡ç¨ææä¸å¯è§£éç AI æ¹å¼ï¼èç±å¤æ¨¡å¼ ICU è³æä¾é æ¸¬é¢å§æ­»äº¡çãæåå¨æ¶æ§ä¸­æ¡ç¨å¤æ¨¡å¼å­¸ç¿ï¼å¯ä»¥æ¥æ¶ä¾èªè¨åºè³æçç°è³ªè¼¸å¥ä¸¦ååºæ±ºç­ãæ­¤å¤ï¼æåå¼å¥äºä¸åå¯è§£éçæ¹æ³ï¼ä¹å°±æ¯åå±¤å³æ­è³ Transformerï¼ä½çº LRP æ¹æ³é©ç¶å°å»¶ä¼¸è³ Transformerï¼å°å¤æ¨¡å¼è¼¸å¥ç¢çè§£éï¼ä¸¦æ­é²æ­¸å æ¼é æ¸¬çé¡¯èç¹å¾µãæ­¤å¤ï¼æ¯åæ¨¡å¼å°è¨åºçµæçè²¢ç»å¯ä»¥è¦è¦ºåï¼åå©è¨åºé«å¸«äºè§£æ±ºç­èå¾ççç±ãæåæ ¹æ MIMIC-III å MIMIC-III æ³¢å½¢è³æåº«æ¯å°å­éå»ºæ§äºä¸åå¤æ¨¡å¼è³æéãå¨åºæºè³æéä¸çå¨é¢å¯¦é©è­æï¼æåæåºçæ¶æ§å¯ä»¥éæåççè©®éï¼ä¸¦å·åç«¶ç­åçé æ¸¬æºç¢ºåº¦ãç¹å¥æ¯ï¼æåçæ¶æ§å¯ä»¥è¼é¬å°è½ç§»å°å¶ä»è¨åºä»»åï¼éæå©æ¼å¨é«çä¿å¥ç ç©¶ä¸­ç¼ç¾ééµå ç´ ã

##### **Joining Forces for Pathology Diagnostics with AI Assistance: The EMPAIA Initiative**
2401.09450v2 by Norman Zerbe, Lars Ole Schwen, Christian GeiÃler, Katja Wiesemann, Tom Bisson, Peter Boor, Rita Carvalho, Michael Franz, Christoph Jansen, Tim-Rasmus Kiehl, BjÃ¶rn Lindequist, Nora Charlotte Pohlan, Sarah Schmell, Klaus Strohmenger, Falk Zakrzewski, Markus Plass, Michael Takla, Tobias KÃ¼ster, AndrÃ© Homeyer, Peter Hufnagl

Over the past decade, artificial intelligence (AI) methods in pathology have
advanced substantially. However, integration into routine clinical practice has
been slow due to numerous challenges, including technical and regulatory
hurdles in translating research results into clinical diagnostic products and
the lack of standardized interfaces. The open and vendor-neutral EMPAIA
initiative addresses these challenges. Here, we provide an overview of EMPAIA's
achievements and lessons learned. EMPAIA integrates various stakeholders of the
pathology AI ecosystem, i.e., pathologists, computer scientists, and industry.
In close collaboration, we developed technical interoperability standards,
recommendations for AI testing and product development, and explainability
methods. We implemented the modular and open-source EMPAIA platform and
successfully integrated 14 AI-based image analysis apps from 8 different
vendors, demonstrating how different apps can use a single standardized
interface. We prioritized requirements and evaluated the use of AI in real
clinical settings with 14 different pathology laboratories in Europe and Asia.
In addition to technical developments, we created a forum for all stakeholders
to share information and experiences on digital pathology and AI. Commercial,
clinical, and academic stakeholders can now adopt EMPAIA's common open-source
interfaces, providing a unique opportunity for large-scale standardization and
streamlining of processes. Further efforts are needed to effectively and
broadly establish AI assistance in routine laboratory use. To this end, a
sustainable infrastructure, the non-profit association EMPAIA International,
has been established to continue standardization and support broad
implementation and advocacy for an AI-assisted digital pathology future.

æè¦ï¼å¨éå»çåå¹´ä¸­ï¼ççå­¸ä¸­çäººå·¥æºæ§ (AI) æ¹æ³å·²å¤§å¹é²æ­¥ãç¶èï¼ç±æ¼è¨±å¤ææ°ï¼åæ¬å°ç ç©¶çµæè½åçºè¨åºè¨ºæ·ç¢åå¨æè¡åæ³è¦æ¹é¢çéç¤ï¼ä»¥åç¼ºä¹æ¨æºåä»é¢ï¼å°è´æ´åå°å¸¸è¦è¨åºå¯¦åä¸­é²å±ç·©æ¢ãéæ¾ä¸èä¾æåç¡éç EMPAIA è¨ç«æå°äºéäºææ°ãå¨æ­¤ï¼æåæä¾ EMPAIA çæå°±åç¶é©æè¨çæ¦è¿°ãEMPAIA æ´åäºççå­¸ AI çæç³»çµ±çååå©å®³éä¿äººï¼å³ççå­¸å®¶ãé»è¦ç§å­¸å®¶åç¢æ¥­ãå¨å¯ååä½ä¸ï¼æåå¶å®äºæè¡äºéæ§æ¨æºãAI æ¸¬è©¦åç¢åéç¼å»ºè­°ï¼ä»¥åå¯è§£éæ§æ¹æ³ãæåå¯¦ä½äºæ¨¡çµåä¸éæ¾åå§ç¢¼ç EMPAIA å¹³èºï¼ä¸¦æåæ´åäºä¾èª 8 åä¸åä¾æåç 14 ååºæ¼ AI çå½±ååææç¨ç¨å¼ï¼å±ç¤ºäºä¸åçæç¨ç¨å¼å¦ä½ä½¿ç¨å®ä¸çæ¨æºåä»é¢ãæååªåèæ®éæ±ï¼ä¸¦è©ä¼°äº AI å¨æ­æ´²åäºæ´²ç 14 åä¸åççå¯¦é©å®¤ä¸­çå¯¦éè¨åºæç¨ãé¤äºæè¡éç¼å¤ï¼æåéçºææå©å®³éä¿äººå»ºç«äºä¸åè«å£ï¼ä»¥åäº«æ¸ä½ççå­¸å AI çè³è¨åç¶é©ãåæ¥­ãè¨åºåå­¸è¡å©å®³éä¿äººç¾å¨å¯ä»¥æ¡ç¨ EMPAIA çå¸¸è¦éæ¾åå§ç¢¼ä»é¢ï¼éçºå¤§è¦æ¨¡æ¨æºååç°¡åæµç¨æä¾äºç¨ç¹çæ©æãéè¦é²ä¸æ­¥çåªåæè½ææä¸å»£æ³å°å»ºç«ä¾è¡å¯¦é©å®¤ä½¿ç¨ä¸­ç AI è¼å©ãçºæ­¤ï¼å·²æç«éçå©åæ EMPAIA Internationalï¼ä»¥ä½çºæ°¸çºåºç¤æ¶æ§ï¼ç¹¼çºé²è¡æ¨æºåï¼ä¸¦æ¯æ´å»£æ³å¯¦ä½åå¡å° AI è¼å©æ¸ä½ççå­¸çæªä¾ã

##### **Robust Stochastic Graph Generator for Counterfactual Explanations**
2312.11747v2 by Mario Alfonso Prado-Romero, Bardh Prenkaj, Giovanni Stilo

Counterfactual Explanation (CE) techniques have garnered attention as a means
to provide insights to the users engaging with AI systems. While extensively
researched in domains such as medical imaging and autonomous vehicles, Graph
Counterfactual Explanation (GCE) methods have been comparatively
under-explored. GCEs generate a new graph similar to the original one, with a
different outcome grounded on the underlying predictive model. Among these GCE
techniques, those rooted in generative mechanisms have received relatively
limited investigation despite demonstrating impressive accomplishments in other
domains, such as artistic styles and natural language modelling. The preference
for generative explainers stems from their capacity to generate counterfactual
instances during inference, leveraging autonomously acquired perturbations of
the input graph. Motivated by the rationales above, our study introduces
RSGG-CE, a novel Robust Stochastic Graph Generator for Counterfactual
Explanations able to produce counterfactual examples from the learned latent
space considering a partially ordered generation sequence. Furthermore, we
undertake quantitative and qualitative analyses to compare RSGG-CE's
performance against SoA generative explainers, highlighting its increased
ability to engendering plausible counterfactual candidates.

æè¦ï¼åäºå¯¦è§£é (CE) æè¡å·²å¼èµ·éæ³¨ï¼ä½çºä¸ç¨®çºè AI ç³»çµ±äºåçä½¿ç¨èæä¾è¦è§£çæ¹æ³ãéç¶å¨é«å­¸å½±ååèªåé§é§æ±½è»ç­é åå»£æ³ç ç©¶ï¼åå½¢åäºå¯¦è§£é (GCE) æ¹æ³ç¸å°è¼å°è¢«æ¢ç´¢ãGCE æç¢çä¸åé¡ä¼¼æ¼åå§åå½¢çæ°åå½¢ï¼ä¸¦æ ¹æåºç¤é æ¸¬æ¨¡åç¢çä¸åççµæãå¨éäº GCE æè¡ä¸­ï¼åç®¡å¨å¶ä»é åï¼ä¾å¦èè¡é¢¨æ ¼åèªç¶èªè¨å»ºæ¨¡ï¼ä¸­å±ç¾åºä»¤äººå°è±¡æ·±å»çæå°±ï¼ä½æ¤åºæ¼çææ©å¶çæè¡ç²å¾çéæ³¨ç¸å°æéãå°çæå¼è§£éå¨çåå¥½æºæ¼å®åå¨æ¨çæéç¢çåäºå¯¦å¯¦ä¾çè½åï¼å©ç¨è¼¸å¥åå½¢çèªä¸»ç²åæ¾åãåºæ¼ä¸è¿°çç±ï¼æåçç ç©¶å¼å¥äº RSGG-CEï¼ä¸ç¨®ç¨æ¼åäºå¯¦è§£éçæ°åç©©å¥é¨æ©åå½¢çæå¨ï¼è½å¤ å¾å­¸ç¿å°çæ½å¨ç©ºéä¸­ç¢çåäºå¯¦ç¯ä¾ï¼èæ®é¨åæåºççæåºåãæ­¤å¤ï¼æåé²è¡å®éåå®æ§åæï¼ä»¥æ¯è¼ RSGG-CE çæè½è SoA çæå¼è§£éå¨ï¼å¼·èª¿å¶å¢å¼·äºç¢çåçè§£éåé¸çè½åã

##### **Evaluating the Utility of Model Explanations for Model Development**
2312.06032v1 by Shawn Im, Jacob Andreas, Yilun Zhou

One of the motivations for explainable AI is to allow humans to make better
and more informed decisions regarding the use and deployment of AI models. But
careful evaluations are needed to assess whether this expectation has been
fulfilled. Current evaluations mainly focus on algorithmic properties of
explanations, and those that involve human subjects often employ subjective
questions to test human's perception of explanation usefulness, without being
grounded in objective metrics and measurements. In this work, we evaluate
whether explanations can improve human decision-making in practical scenarios
of machine learning model development. We conduct a mixed-methods user study
involving image data to evaluate saliency maps generated by SmoothGrad,
GradCAM, and an oracle explanation on two tasks: model selection and
counterfactual simulation. To our surprise, we did not find evidence of
significant improvement on these tasks when users were provided with any of the
saliency maps, even the synthetic oracle explanation designed to be simple to
understand and highly indicative of the answer. Nonetheless, explanations did
help users more accurately describe the models. These findings suggest caution
regarding the usefulness and potential for misunderstanding in saliency-based
explanations.

æè¦ï¼å¯è§£é AI çåæ©ä¹ä¸æ¯è®äººåå¨ä½¿ç¨åé¨ç½² AI æ¨¡åæååºæ´å¥½ãæ´ææºçæ±ºç­ãä½éè¦ä»ç´°è©ä¼°ä»¥è©ä¼°æ¯å¦å·²éå°æ­¤é æãç®åçè©ä¼°ä¸»è¦éä¸­å¨è§£éçæ¼ç®æ³ç¹æ§ï¼èæ¶åäººé¡åè©¦èçè©ä¼°éå¸¸æ¡ç¨ä¸»è§åé¡ä¾æ¸¬è©¦äººé¡å°è§£éæç¨æ§ççæ³ï¼èæ²æåºæ¼å®¢è§ææ¨åæ¸¬éãå¨éé å·¥ä½ä¸­ï¼æåè©ä¼°è§£éæ¯å¦å¯ä»¥å¨æ©å¨å­¸ç¿æ¨¡åéç¼çå¯¦éå ´æ¯ä¸­æ¹åäººé¡æ±ºç­å¶å®ãæåé²è¡äºä¸é æ¶åå½±åè³æçæ··åæ¹æ³ä½¿ç¨èç ç©¶ï¼ä»¥è©ä¼° SmoothGradãGradCAM åé è¨è§£éå¨å©åä»»åä¸­ç¢ççé¡¯èæ§åï¼æ¨¡åé¸æååäºå¯¦æ¨¡æ¬ãä»¤äººé©è¨çæ¯ï¼æåæ²æç¼ç¾ä»»ä½é¡¯èæ§åï¼å³ä½¿æ¯è¨­è¨çºææ¼çè§£ä¸é«åº¦æç¤ºç­æ¡çåæé è¨è§£éï¼è½è®ä½¿ç¨èå¨éäºä»»åä¸é¡¯èæ¹åçè­æãåç®¡å¦æ­¤ï¼è§£éç¢ºå¯¦æå©æ¼ä½¿ç¨èæ´æºç¢ºå°æè¿°æ¨¡åãéäºç¼ç¾æç¤ºæåè¦å°åºæ¼é¡¯èæ§çè§£éä¸­å¯è½å­å¨èª¤è§£çæç¨æ§ä¿æè¬¹æã

##### **Building Trustworthy NeuroSymbolic AI Systems: Consistency, Reliability, Explainability, and Safety**
2312.06798v1 by Manas Gaur, Amit Sheth

Explainability and Safety engender Trust. These require a model to exhibit
consistency and reliability. To achieve these, it is necessary to use and
analyze data and knowledge with statistical and symbolic AI methods relevant to
the AI application - neither alone will do. Consequently, we argue and seek to
demonstrate that the NeuroSymbolic AI approach is better suited for making AI a
trusted AI system. We present the CREST framework that shows how Consistency,
Reliability, user-level Explainability, and Safety are built on NeuroSymbolic
methods that use data and knowledge to support requirements for critical
applications such as health and well-being. This article focuses on Large
Language Models (LLMs) as the chosen AI system within the CREST framework. LLMs
have garnered substantial attention from researchers due to their versatility
in handling a broad array of natural language processing (NLP) scenarios. For
example, ChatGPT and Google's MedPaLM have emerged as highly promising
platforms for providing information in general and health-related queries,
respectively. Nevertheless, these models remain black boxes despite
incorporating human feedback and instruction-guided tuning. For instance,
ChatGPT can generate unsafe responses despite instituting safety guardrails.
CREST presents a plausible approach harnessing procedural and graph-based
knowledge within a NeuroSymbolic framework to shed light on the challenges
associated with LLMs.

æè¦ï¼å¯è§£éæ§åå®å¨æ§å»ºç«ä¿¡ä»»ãéäºéè¦ä¸åæ¨¡åä¾å±ç¤ºä¸è´æ§åå¯é æ§ãçºäºå¯¦ç¾éäºï¼æå¿è¦ä½¿ç¨ååææ¸æåç¥è­ï¼ä¸¦ä½¿ç¨è AI æç¨ç¸éççµ±è¨åç¬¦è AI æ¹æ³ - å®ç¨ä½¿ç¨ä»»ä½ä¸ç¨®æ¹æ³é½ä¸æå¥æãå æ­¤ï¼æåä¸»å¼µä¸¦è©¦åè­æ NeuroSymbolic AI æ¹æ³æ´é©åæ¼ä½¿ AI æçºåä¿¡ä»»ç AI ç³»çµ±ãæåæåºäº CREST æ¡æ¶ï¼å±ç¤ºäºä¸è´æ§ãå¯é æ§ãä½¿ç¨èå±¤ç´çå¯è§£éæ§åå®å¨æ§æ¯å¦ä½å»ºç«å¨ NeuroSymbolic æ¹æ³ä¸çï¼è©²æ¹æ³ä½¿ç¨æ¸æåç¥è­ä¾æ¯æééµæç¨ï¼ä¾å¦å¥åº·åç¦ç¥ï¼çè¦æ±ãæ¬æéé»éæ³¨å¤§åèªè¨æ¨¡å (LLM)ï¼å çºå®æ¯ CREST æ¡æ¶ä¸­é¸æç AI ç³»çµ±ãLLM å å¶å¨èçå»£æ³çèªç¶èªè¨èç (NLP) å ´æ¯æ¹é¢çå¤åè½æ§èååç ç©¶äººå¡çéæ³¨ãä¾å¦ï¼ChatGPT å Google ç MedPaLM å·²æçºæä¾ä¸è¬åå¥åº·ç¸éæ¥è©¢ä¿¡æ¯çæ¥µæå¸æçå¹³å°ãåç®¡å¦æ­¤ï¼éäºæ¨¡åä»ç¶æ¯é»çå­ï¼åç®¡ç´å¥äºäººé¡åé¥åæä»¤å¼å°çèª¿æ´ãä¾å¦ï¼åç®¡å¶å®äºå®å¨é²è­·æªæ½ï¼ChatGPT ä»å¯è½ç¢çä¸å®å¨çåæãCREST æåºäºä¸ç¨®åççæ¹æ³ï¼å¨ NeuroSymbolic æ¡æ¶ä¸­å©ç¨ç¨åºååºæ¼åè¡¨çç¥è­ï¼ä»¥é¡æè LLM ç¸éçææ°ã

##### **Class-Discriminative Attention Maps for Vision Transformers**
2312.02364v3 by Lennart Brocki, Jakub Binda, Neo Christopher Chung

Importance estimators are explainability methods that quantify feature
importance for deep neural networks (DNN). In vision transformers (ViT), the
self-attention mechanism naturally leads to attention maps, which are sometimes
interpreted as importance scores that indicate which input features ViT models
are focusing on. However, attention maps do not account for signals from
downstream tasks. To generate explanations that are sensitive to downstream
tasks, we have developed class-discriminative attention maps (CDAM), a
gradient-based extension that estimates feature importance with respect to a
known class or a latent concept. CDAM scales attention scores by how relevant
the corresponding tokens are for the predictions of a classifier head. In
addition to targeting the supervised classifier, CDAM can explain an arbitrary
concept shared by selected samples by measuring similarity in the latent space
of ViT. Additionally, we introduce Smooth CDAM and Integrated CDAM, which
average a series of CDAMs with slightly altered tokens. Our quantitative
benchmarks include correctness, compactness, and class sensitivity, in
comparison to 7 other importance estimators. Vanilla, Smooth, and Integrated
CDAM excel across all three benchmarks. In particular, our results suggest that
existing importance estimators may not provide sufficient class-sensitivity. We
demonstrate the utility of CDAM in medical images by training and explaining
malignancy and biomarker prediction models based on lung Computed Tomography
(CT) scans. Overall, CDAM is shown to be highly class-discriminative and
semantically relevant, while providing compact explanations.

æè¦ï¼<paragraph>éè¦æ§ä¼°è¨å¨æ¯ä¸ç¨®å¯è§£éæ§æ¹æ³ï¼ç¨æ¼éåæ·±åº¦ç¥ç¶ç¶²è·¯ (DNN) çç¹å¾µéè¦æ§ãå¨è¦è¦ºTransformer (ViT) ä¸­ï¼èªææ³¨ææ©å¶èªç¶æå°è´æ³¨æååï¼æææå°å¶è§£éçºéè¦æ§åæ¸ï¼è¡¨ç¤º ViT æ¨¡åéæ³¨åªäºè¼¸å¥ç¹å¾µãç¶èï¼æ³¨æååä¸¦æªèæ®ä¾èªä¸æ¸¸ä»»åçä¿¡èãçºäºç¢çå°ä¸æ¸¸ä»»åææçè§£éï¼æåéç¼äºé¡å¥ååæ³¨æåå (CDAM)ï¼éæ¯ä¸ç¨®åºæ¼æ¢¯åº¦çæ´åï¼ç¨æ¼ä¼°è¨ç¸å°æ¼å·²ç¥é¡å¥ææ½å¨æ¦å¿µçç¹å¾µéè¦æ§ãCDAM æ ¹æå°æçç¬¦èèåé¡å¨é ­çé æ¸¬ç¸éç¨åº¦ï¼èª¿æ´æ³¨æååæ¸ãé¤äºéå°ç£ç£åé¡å¨å¤ï¼CDAM éå¯ä»¥ééæ¸¬é ViT çæ½å¨ç©ºéä¸­çç¸ä¼¼æ§ä¾è§£éé¸å®æ¨£æ¬å±æçä»»ææ¦å¿µãæ­¤å¤ï¼æåå¼å¥äºå¹³æ» CDAM åç©å CDAMï¼å®åå°ä¸ç³»åå·æç¥å¾®æ¹è®çç¬¦èç CDAM é²è¡å¹³åãæåçéååºæºåæ¬æ­£ç¢ºæ§ãç·æ¹æ§åé¡å¥æææ§ï¼èå¶ä» 7 åéè¦æ§ä¼°è¨å¨ç¸æ¯ãé¦èãå¹³æ»åç©å CDAM å¨ææä¸ååºæºä¸­è¡¨ç¾åºè²ãç¹å¥æ¯ï¼æåççµæè¡¨æç¾æçéè¦æ§ä¼°è¨å¨å¯è½ç¡æ³æä¾è¶³å¤ çé¡å¥æææ§ãæåééåºæ¼èºé¨é»è¦æ·å±¤ææ (CT) ææè¨ç·´åè§£éæ¡æ§è«ç¤åçç©æ¨è¨é æ¸¬æ¨¡åï¼è­æäº CDAM å¨é«å­¸å½±åä¸­çæç¨ãç¸½çä¾èªªï¼CDAM è¢«è­æå·æé«åº¦é¡å¥ååæ§åèªç¾©ç¸éæ§ï¼åææä¾ç°¡æ½çè§£éã</paragraph>

##### **Deployment of a Robust and Explainable Mortality Prediction Model: The COVID-19 Pandemic and Beyond**
2311.17133v1 by Jacob R. Epifano, Stephen Glass, Ravi P. Ramachandran, Sharad Patel, Aaron J. Masino, Ghulam Rasool

This study investigated the performance, explainability, and robustness of
deployed artificial intelligence (AI) models in predicting mortality during the
COVID-19 pandemic and beyond. The first study of its kind, we found that
Bayesian Neural Networks (BNNs) and intelligent training techniques allowed our
models to maintain performance amidst significant data shifts. Our results
emphasize the importance of developing robust AI models capable of matching or
surpassing clinician predictions, even under challenging conditions. Our
exploration of model explainability revealed that stochastic models generate
more diverse and personalized explanations thereby highlighting the need for AI
models that provide detailed and individualized insights in real-world clinical
settings. Furthermore, we underscored the importance of quantifying uncertainty
in AI models which enables clinicians to make better-informed decisions based
on reliable predictions. Our study advocates for prioritizing implementation
science in AI research for healthcare and ensuring that AI solutions are
practical, beneficial, and sustainable in real-world clinical environments. By
addressing unique challenges and complexities in healthcare settings,
researchers can develop AI models that effectively improve clinical practice
and patient outcomes.

æè¦ï¼æ¬ç ç©¶è°æ¥äºå¨ COVID-19 ç«ææé´åä»¥åé¢æµæ­»äº¡çæ¶ï¼å·²é¨ç½²äººå·¥æºè½ (AI) æ¨¡åçæ§è½ãå¯è§£éæ§åç¨³å¥æ§ãä½ä¸ºåç±»ç ç©¶ä¸­çé¦ä¾ï¼æä»¬åç°è´å¶æ¯ç¥ç»ç½ç» (BNN) åæºè½è®­ç»ææ¯è®©æä»¬çæ¨¡åå¨æ°æ®åçéå¤§ååæ¶ä»è½ä¿ææ§è½ãæä»¬çç»æå¼ºè°äºå¼åç¨³å¥ç AI æ¨¡åçéè¦æ§ï¼å³ä½¿å¨å·ææææ§çæ¡ä»¶ä¸ï¼è¿äºæ¨¡åä¹è½å¹éæè¶è¶ä¸´åºå»ççé¢æµãæä»¬å¯¹æ¨¡åå¯è§£éæ§çæ¢ç´¢è¡¨æï¼éæºæ¨¡åä¼äº§çæ´å¤æ ·åä¸ä¸ªæ§åçè§£éï¼ä»èçªåºäºå¨ç°å®ä¸ççä¸´åºç¯å¢ä¸­æä¾è¯¦ç»ä¸ä¸ªæ§åè§è§£ç AI æ¨¡åçå¿è¦æ§ãæ­¤å¤ï¼æä»¬å¼ºè°äºéå AI æ¨¡åä¸­ä¸ç¡®å®æ§çéè¦æ§ï¼è¿ä½¿ä¸´åºå»çè½å¤æ ¹æ®å¯é çé¢æµååºæ´ææºçå³ç­ãæä»¬çç ç©¶æå¡å¨å»çä¿å¥ç AI ç ç©¶ä¸­ä¼åèèå®æ½ç§å­¦ï¼å¹¶ç¡®ä¿ AI è§£å³æ¹æ¡å¨ç°å®ä¸ççä¸´åºç¯å¢ä¸­å®ç¨ãæçä¸å¯æç»­ãéè¿è§£å³å»çä¿å¥ç¯å¢ä¸­çç¬ç¹ææåå¤ææ§ï¼ç ç©¶äººåå¯ä»¥å¼ååºæææ¹åä¸´åºå®è·µåæ£èé¢åç AI æ¨¡åã

##### **Variational Autoencoders for Feature Exploration and Malignancy Prediction of Lung Lesions**
2311.15719v1 by Benjamin Keel, Aaron Quyn, David Jayne, Samuel D. Relton

Lung cancer is responsible for 21% of cancer deaths in the UK and five-year
survival rates are heavily influenced by the stage the cancer was identified
at. Recent studies have demonstrated the capability of AI methods for accurate
and early diagnosis of lung cancer from routine scans. However, this evidence
has not translated into clinical practice with one barrier being a lack of
interpretable models. This study investigates the application Variational
Autoencoders (VAEs), a type of generative AI model, to lung cancer lesions.
Proposed models were trained on lesions extracted from 3D CT scans in the
LIDC-IDRI public dataset. Latent vector representations of 2D slices produced
by the VAEs were explored through clustering to justify their quality and used
in an MLP classifier model for lung cancer diagnosis, the best model achieved
state-of-the-art metrics of AUC 0.98 and 93.1% accuracy. Cluster analysis shows
the VAE latent space separates the dataset of malignant and benign lesions
based on meaningful feature components including tumour size, shape, patient
and malignancy class. We also include a comparative analysis of the standard
Gaussian VAE (GVAE) and the more recent Dirichlet VAE (DirVAE), which replaces
the prior with a Dirichlet distribution to encourage a more explainable latent
space with disentangled feature representation. Finally, we demonstrate the
potential for latent space traversals corresponding to clinically meaningful
feature changes.

æè¦ï¼èºçå è±åççæ­»äº¡äººæ¸ç 21%ï¼äºå¹´å­æ´»çå¾å¤§ç¨åº¦åæ±ºæ¼ççè¢«ç¼ç¾çéæ®µãæè¿çç ç©¶å·²è­æäººå·¥æºè½æ¹æ³å·æå¾ä¾è¡ææä¸­æºç¢ºåæ©è¨ºæ·èºççè½åãç¶èï¼æ­¤è­æå°æªè½åçºè¨åºå¯¦åï¼å¶ä¸­ä¸åéç¤æ¯ç¼ºä¹å¯è§£éçæ¨¡åãæ¬ç ç©¶æ¢è¨äºæç¨è®åèªåç·¨ç¢¼å¨ (VAE)ï¼ä¸ç¨®çæå¼äººå·¥æºè½æ¨¡åï¼æ¼èºççç¶ãå°æåºçæ¨¡åè¨ç·´æ¼å¾ LIDC-IDRI å¬å±æ¸æéä¸­æåç 3D é»è¦æ·å±¤ææçç¶ãééèé¡æ¢ç´¢äº VAE çæç 2D åççæ½å¨åéè¡¨ç¤ºï¼ä»¥è­æå¶åè³ªï¼ä¸¦ç¨æ¼èºçè¨ºæ·ç MLP åé¡å¨æ¨¡åï¼æä½³æ¨¡åéå°äº AUC 0.98 å 93.1% æºç¢ºåº¦çæåé²ææ¨ãèé¡åæé¡¯ç¤ºï¼VAE æ½å¨ç©ºéæ ¹æææç¾©çç¹å¾µçµæï¼åæ¬è«ç¤å¤§å°ãå½¢çãæ£èåæ¡æ§é¡å¥ï¼å°æ¡æ§åè¯æ§çç¶çæ¸æéåéãæåéåæ¬æ¨æºé«æ¯ VAE (GVAE) åæ´æ°ççå©åé· VAE (DirVAE) çæ¯è¼åæï¼å¾èç¨çå©åé·åä½åä»£åé©ï¼ä»¥ä¿é²å·æè§£éç¹å¾µè¡¨ç¤ºçæ´å·å¯è§£éæ§çæ½å¨ç©ºéãæå¾ï¼æåå±ç¤ºäºèè¨åºææç¾©çç¹å¾µè®åç¸æçæ½å¨ç©ºéæ©«è¶çæ½åã

##### **MRxaI: Black-Box Explainability for Image Classifiers in a Medical Setting**
2311.14471v1 by Nathan Blake, Hana Chockler, David A. Kelly, Santiago Calderon Pena, Akchunya Chanchal

Existing tools for explaining the output of image classifiers can be divided
into white-box, which rely on access to the model internals, and black-box,
agnostic to the model. As the usage of AI in the medical domain grows, so too
does the usage of explainability tools. Existing work on medical image
explanations focuses on white-box tools, such as gradcam. However, there are
clear advantages to switching to a black-box tool, including the ability to use
it with any classifier and the wide selection of black-box tools available. On
standard images, black-box tools are as precise as white-box. In this paper we
compare the performance of several black-box methods against gradcam on a brain
cancer MRI dataset. We demonstrate that most black-box tools are not suitable
for explaining medical image classifications and present a detailed analysis of
the reasons for their shortcomings. We also show that one black-box tool, a
causal explainability-based rex, performs as well as \gradcam.

æè¦ï¼ç¾æçåååé¡å¨è¼¸åºè§£éå·¥å·å¯åçºä¾è³´æ¼æ¨¡åå§é¨å­åæ¬éçç½çï¼ä»¥åèæ¨¡åç¡éçé»çãé¨è AI å¨é«çé åçä½¿ç¨å¢å ï¼å¯è§£éæ§å·¥å·çä½¿ç¨ä¹é¨ä¹å¢å ãç¾æé«å­¸å½±åè§£éçå·¥ä½éé»å¨æ¼ç½çå·¥å·ï¼ä¾å¦ gradcamãç¶èï¼åæå°é»çå·¥å·ææé¡¯çåªé»ï¼åæ¬è½å¤ èä»»ä½åé¡å¨ä¸èµ·ä½¿ç¨ï¼ä»¥åå»£æ³çé»çå·¥å·å¯ä¾é¸æãå¨æ¨æºå½±åä¸ï¼é»çå·¥å·èç½çä¸æ¨£ç²¾ç¢ºãå¨æ¬æä¸­ï¼æåæ¯è¼äºå¤ç¨®é»çæ¹æ³å¨è¦ç MRI è³æéä¸è gradcam çæè½ãæåè­æå¤§å¤æ¸é»çå·¥å·ä¸é©åè§£éé«å­¸å½±ååé¡ï¼ä¸¦è©³ç´°åæå¶ç¼ºé»çåå ãæåéè¡¨æä¸ç¨®é»çå·¥å·ï¼åºæ¼å æå¯è§£éæ§ç rexï¼è¡¨ç¾è \gradcam ä¸æ¨£å¥½ã

##### **Moderating Model Marketplaces: Platform Governance Puzzles for AI Intermediaries**
2311.12573v3 by Robert Gorwa, Michael Veale

The AI development community is increasingly making use of hosting
intermediaries such as Hugging Face provide easy access to user-uploaded models
and training data. These model marketplaces lower technical deployment barriers
for hundreds of thousands of users, yet can be used in numerous potentially
harmful and illegal ways. In this article, we explain ways in which AI systems,
which can both `contain' content and be open-ended tools, present one of the
trickiest platform governance challenges seen to date. We provide case studies
of several incidents across three illustrative platforms -- Hugging Face,
GitHub and Civitai -- to examine how model marketplaces moderate models.
Building on this analysis, we outline important (and yet nevertheless limited)
practices that industry has been developing to respond to moderation demands:
licensing, access and use restrictions, automated content moderation, and open
policy development. While the policy challenge at hand is a considerable one,
we conclude with some ideas as to how platforms could better mobilize resources
to act as a careful, fair, and proportionate regulatory access point.

æè¦ï¼AI éç¼ç¤¾ç¾¤æ¥çå©ç¨ Hugging Face ç­è¨ç®¡ä¸­ä»æ©æ§æä¾ç¨æ¶ä¸å³çæ¨¡ååè¨ç·´è³æçç°¡æå­åæ¬éãéäºæ¨¡åå¸ééä½äºæ¸åè¬åç¨æ¶çæè¡é¨ç½²éç¤ï¼ä½å¯è½æè¢«ç¨æ¼è¨±å¤æ½å¨æå®³åéæ³çæ¹å¼ãå¨æ¬æä¸­ï¼æåèªªæ AI ç³»çµ±æ¢å¯ä»¥ãåå«ãå§å®¹ï¼åå¯ä»¥ä½çºéæ¾å¼å·¥å·ï¼éæåºäºè¿ä»çºæ­¢ææ£æçå¹³å°æ²»çææ°ä¹ä¸ãæåæä¾ Hugging FaceãGitHub å Civitai ç­ä¸åèªªææ§å¹³å°ä¸æ¸èµ·äºä»¶çæ¡ä¾ç ç©¶ï¼ä»¥æª¢è¦æ¨¡åå¸éå¦ä½å¯©æ ¸æ¨¡åãæ ¹ææ­¤åæï¼æåæ¦è¿°ç¢æ¥­çºåæå¯©æ ¸éæ±èéç¼çéè¦ï¼ä½ä»æéï¼å¯¦åï¼ææ¬ãå­ååä½¿ç¨éå¶ãèªååå§å®¹å¯©æ ¸åéæ¾æ¿ç­å¶å®ãéç¶ç¶åæ¿ç­ææ°ç¸ç¶å¯è§ï¼æåæå¾æåºä¸äºæ§æ³ï¼èªªæå¹³å°å¦ä½è½æ´å¥½å°åå¡è³æºï¼ä½çºè¬¹æãå¬å¹³ä¸é©åº¦çæ³è¦å­åé»ã

##### **Ovarian Cancer Data Analysis using Deep Learning: A Systematic Review from the Perspectives of Key Features of Data Analysis and AI Assurance**
2311.11932v1 by Muta Tah Hira, Mohammad A. Razzaque, Mosharraf Sarker

Background and objectives: By extracting this information, Machine or Deep
Learning (ML/DL)-based autonomous data analysis tools can assist clinicians and
cancer researchers in discovering patterns and relationships from complex data
sets. Many DL-based analyses on ovarian cancer (OC) data have recently been
published. These analyses are highly diverse in various aspects of cancer
(e.g., subdomain(s) and cancer type they address) and data analysis features.
However, a comprehensive understanding of these analyses in terms of these
features and AI assurance (AIA) is currently lacking. This systematic review
aims to fill this gap by examining the existing literature and identifying
important aspects of OC data analysis using DL, explicitly focusing on the key
features and AI assurance perspectives. Methods: The PRISMA framework was used
to conduct comprehensive searches in three journal databases. Only studies
published between 2015 and 2023 in peer-reviewed journals were included in the
analysis. Results: In the review, a total of 96 DL-driven analyses were
examined. The findings reveal several important insights regarding DL-driven
ovarian cancer data analysis: - Most studies 71% (68 out of 96) focused on
detection and diagnosis, while no study addressed the prediction and prevention
of OC. - The analyses were predominantly based on samples from a non-diverse
population (75% (72/96 studies)), limited to a geographic location or country.
- Only a small proportion of studies (only 33% (32/96)) performed integrated
analyses, most of which used homogeneous data (clinical or omics). - Notably, a
mere 8.3% (8/96) of the studies validated their models using external and
diverse data sets, highlighting the need for enhanced model validation, and -
The inclusion of AIA in cancer data analysis is in a very early stage; only
2.1% (2/96) explicitly addressed AIA through explainability.

æè¦ï¼<paragraph>èæ¯åç®æ¨ï¼ééæåéäºè³è¨ï¼æ©å¨ææ·±åº¦å­¸ç¿ (ML/DL) åºæ¼èªä¸»æ¸æåæå·¥å·å¯ä»¥åå©è¨åºé«çåççç ç©¶äººå¡å¾è¤éçæ¸æéä¸­ç¼ç¾æ¨¡å¼åéä¿ãæè¿å·²ç¼è¡¨è¨±å¤åºæ¼ DL çåµå·¢ç (OC) æ¸æåæãéäºåæå¨çççååæ¹é¢ï¼ä¾å¦ï¼å®åæ¶åçå­é ååççé¡åï¼åæ¸æåæåè½æ¹é¢é«åº¦å¤æ¨£åãç¶èï¼ç®åç¼ºä¹å°éäºåæå¨éäºç¹å¾µå AI ä¿è­ (AIA) æ¹é¢çå¨é¢çè§£ãéç¯ç³»çµ±æ§åé¡§æ¨å¨ééæª¢è¦ç¾ææç»ä¸¦æç¢ºéæ³¨ééµç¹å¾µå AI ä¿è­è§é»ï¼ä¾å¡«è£éåç©ºç½ãæ¹æ³ï¼ä½¿ç¨ PRISMA æ¶æ§å¨ä¸åæåè³æåº«ä¸­é²è¡å¨é¢æå°ãåæååæ¬ 2015 å¹´è³ 2023 å¹´éç¼è¡¨æ¼åè¡è©å¯©æåçç ç©¶ãçµæï¼å¨åé¡§ä¸­ï¼ç¸½å±æª¢è¦äº 96 é ç± DL é©åçåæãç ç©¶çµææ­ç¤ºäºå¹¾åéæ¼ç± DL é©åçåµå·¢çæ¸æåæçéè¦è¦è§£ï¼- å¤§å¤æ¸ç ç©¶ 71%ï¼96 é ä¸­æ 68 é ï¼å°æ³¨æ¼æª¢æ¸¬åè¨ºæ·ï¼èæ²æç ç©¶æ¢è¨ OC çé æ¸¬åé é²ã- éäºåæä¸»è¦åºæ¼ä¾èªéå¤åæç¾¤çæ¨£æ¬ï¼75%ï¼96 é ç ç©¶ä¸­ç 72 é ï¼ï¼ï¼åéæ¼æåå°çä½ç½®æåå®¶ã- åªæå°é¨åç ç©¶ï¼å 33%ï¼96 é ç ç©¶ä¸­ç 32 é ï¼å·è¡æ´ååæï¼å¶ä¸­å¤§å¤æ¸ä½¿ç¨åè³ªæ¸æï¼è¨åºæçµå­¸ï¼ã- å¼å¾æ³¨æçæ¯ï¼åªæ 8.3%ï¼96 é ç ç©¶ä¸­ç 8 é ï¼ä½¿ç¨å¤é¨åå¤åæ¸æéé©è­äºå¶æ¨¡åï¼å¼·èª¿äºå å¼·æ¨¡åé©è­çå¿è¦æ§ï¼ä»¥å- å° AIA ç´å¥ççæ¸æåæä»èæ¼éå¸¸æ©æçéæ®µï¼åªæ 2.1%ï¼96 é ç ç©¶ä¸­ç 2 é ï¼ééå¯è§£éæ§æç¢ºæ¢è¨äº AIAã</paragraph>

##### **Representing visual classification as a linear combination of words**
2311.10933v1 by Shobhit Agarwal, Yevgeniy R. Semenov, William Lotter

Explainability is a longstanding challenge in deep learning, especially in
high-stakes domains like healthcare. Common explainability methods highlight
image regions that drive an AI model's decision. Humans, however, heavily rely
on language to convey explanations of not only "where" but "what".
Additionally, most explainability approaches focus on explaining individual AI
predictions, rather than describing the features used by an AI model in
general. The latter would be especially useful for model and dataset auditing,
and potentially even knowledge generation as AI is increasingly being used in
novel tasks. Here, we present an explainability strategy that uses a
vision-language model to identify language-based descriptors of a visual
classification task. By leveraging a pre-trained joint embedding space between
images and text, our approach estimates a new classification task as a linear
combination of words, resulting in a weight for each word that indicates its
alignment with the vision-based classifier. We assess our approach using two
medical imaging classification tasks, where we find that the resulting
descriptors largely align with clinical knowledge despite a lack of
domain-specific language training. However, our approach also identifies the
potential for 'shortcut connections' in the public datasets used. Towards a
functional measure of explainability, we perform a pilot reader study where we
find that the AI-identified words can enable non-expert humans to perform a
specialized medical task at a non-trivial level. Altogether, our results
emphasize the potential of using multimodal foundational models to deliver
intuitive, language-based explanations of visual tasks.

æè¦ï¼<paragraph>è§£éæ§æ¯æ·±åº¦å­¸ç¿ä¸­é·æçææ°ï¼ç¹å¥æ¯å¨é«çä¿å¥ç­é«é¢¨éªé åãå¸¸è¦çè§£éæ§æ¹æ³æå¼·èª¿é©å AI æ¨¡åæ±ºç­çå½±åååãç¶èï¼äººé¡å¾å¤§ç¨åº¦ä¾è³´èªè¨ä¾å³éä¸åæ¯ãå¨åªè£¡ãï¼éæãæ¯ä»éº¼ãçè§£éãæ­¤å¤ï¼å¤§å¤æ¸è§£éæ§æ¹æ³é½å°æ³¨æ¼è§£éåå¥ AI é æ¸¬ï¼èä¸æ¯æè¿° AI æ¨¡åä¸è¬ä½¿ç¨çç¹å¾µãå¾èå°æ¼æ¨¡ååè³æéç¨½æ ¸ç¹å¥æç¨ï¼çè³å¯è½å¨ AI æä¾æç¨æ¼æ°ç©ä»»åæç¢çç¥è­ãå¨æ­¤ï¼æåæåºä¸åä½¿ç¨è¦è¦ºèªè¨æ¨¡åä¾è¾¨è­è¦è¦ºåé¡ä»»åçèªè¨æè¿°ç¬¦çè§£éæ§ç­ç¥ãééå©ç¨å½±ååæå­ä¹éé åè¨ç·´çè¯ååµå¥ç©ºéï¼æåçåæ³å°æ°çåé¡ä»»åä¼°è¨çºä¸åç·æ§æå­çµåï¼å°è´æ¯åæå­é½ææ¬éï¼è¡¨ç¤ºå®èåºæ¼è¦è¦ºçåé¡å¨å°é½ãæåä½¿ç¨å©åé«å­¸å½±ååé¡ä»»åä¾è©ä¼°æåçåæ³ï¼æåç¼ç¾ç¢ççæè¿°ç¬¦å¨å¾å¤§ç¨åº¦ä¸èè¨åºç¥è­ä¸è´ï¼åç®¡ç¼ºä¹ç¹å®é åçèªè¨è¨ç·´ãç¶èï¼æåçåæ³ä¹ç¼ç¾äºæç¨å¬éè³æéä¸­çãæ·å¾é£ç·ãçå¯è½æ§ãçºäºéå°è§£éæ§çåè½æ§è¡¡éï¼æåé²è¡äºä¸é è©¦é©è®èç ç©¶ï¼ç¼ç¾ AI è­å¥çæå­è½è®éå°å®¶äººé¡å¨éå¹³å¡çå±¤ç´å·è¡å°æ¥­çé«çä»»åãç¸½ä¹ï¼æåççµæå¼·èª¿äºä½¿ç¨å¤æ¨¡å¼åºç¤æ¨¡åä¾æä¾ç´è§çãåºæ¼èªè¨çè¦è¦ºä»»åè§£éçæ½åã</paragraph>


### Medical
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-12-06**|**Enhancing FKG.in: automating Indian food composition analysis**|Saransh Kumar Gupta et.al.|[2412.05248v1](http://arxiv.org/abs/2412.05248v1)|null|
|**2024-12-06**|**Are Frontier Large Language Models Suitable for Q&A in Science Centres?**|Jacob Watson et.al.|[2412.05200v1](http://arxiv.org/abs/2412.05200v1)|null|
|**2024-12-06**|**SurgBox: Agent-Driven Operating Room Sandbox with Surgery Copilot**|Jinlin Wu et.al.|[2412.05187v1](http://arxiv.org/abs/2412.05187v1)|[link](https://github.com/franciszchen/surgbox)|
|**2024-12-06**|**Project Report: Requirements for a Social Robot as an Information Provider in the Public Sector**|Thomas Sievers et.al.|[2412.05013v1](http://arxiv.org/abs/2412.05013v1)|null|
|**2024-12-06**|**Backdooring Outlier Detection Methods: A Novel Attack Approach**|ZeinabSadat Taghavi et.al.|[2412.05010v1](http://arxiv.org/abs/2412.05010v1)|null|
|**2024-12-06**|**Bed-Attached Vibration Sensor System: A Machine Learning Approach for Fall Detection in Nursing Homes**|Thomas Bartz-Beielstein et.al.|[2412.04950v1](http://arxiv.org/abs/2412.04950v1)|null|
|**2024-12-06**|**Estimating the treatment effect over time under general interference through deep learner integrated TMLE**|Suhan Guo et.al.|[2412.04799v1](http://arxiv.org/abs/2412.04799v1)|null|
|**2024-12-06**|**Multi-class heart disease Detection, Classification, and Prediction using Machine Learning Models**|Mahfuzul Haque et.al.|[2412.04792v1](http://arxiv.org/abs/2412.04792v1)|null|
|**2024-12-06**|**DAWN-SI: Data-Aware and Noise-Informed Stochastic Interpolation for Solving Inverse Problems**|Shadab Ahamed et.al.|[2412.04766v1](http://arxiv.org/abs/2412.04766v1)|null|
|**2024-12-06**|**PCTreeS: 3D Point Cloud Tree Species Classification Using Airborne LiDAR Images**|Hongjin Lin et.al.|[2412.04714v1](http://arxiv.org/abs/2412.04714v1)|null|
|**2024-12-05**|**Semantic Consistency-Based Uncertainty Quantification for Factuality in Radiology Report Generation**|Chenyu Wang et.al.|[2412.04606v1](http://arxiv.org/abs/2412.04606v1)|null|
|**2024-12-05**|**CLINICSUM: Utilizing Language Models for Generating Clinical Summaries from Patient-Doctor Conversations**|Subash Neupane et.al.|[2412.04254v1](http://arxiv.org/abs/2412.04254v1)|null|
|**2024-12-05**|**Automated Medical Report Generation for ECG Data: Bridging Medical Text and Signal Processing with Deep Learning**|Amnon Bleich et.al.|[2412.04067v1](http://arxiv.org/abs/2412.04067v1)|null|
|**2024-12-05**|**FedMetaMed: Federated Meta-Learning for Personalized Medication in Distributed Healthcare Systems**|Jiechao Gao et.al.|[2412.03851v1](http://arxiv.org/abs/2412.03851v1)|null|
|**2024-12-05**|**ELEMENT: Episodic and Lifelong Exploration via Maximum Entropy**|Hongming Li et.al.|[2412.03800v1](http://arxiv.org/abs/2412.03800v1)|null|
|**2024-12-05**|**Automated Multi-Label Annotation for Mental Health Illnesses Using Large Language Models**|Abdelrahaman A. Hassan et.al.|[2412.03796v1](http://arxiv.org/abs/2412.03796v1)|null|
|**2024-12-05**|**Speech Recognition-based Feature Extraction for Enhanced Automatic Severity Classification in Dysarthric Speech**|Yerin Choi et.al.|[2412.03784v1](http://arxiv.org/abs/2412.03784v1)|null|
|**2024-12-04**|**Exploring the Role of AI-Powered Chatbots for Teens and Young Adults with ASD or Social Anxiety**|Dilan Mian et.al.|[2412.03740v1](http://arxiv.org/abs/2412.03740v1)|null|
|**2024-12-04**|**MRGen: Diffusion-based Controllable Data Engine for MRI Segmentation towards Unannotated Modalities**|Haoning Wu et.al.|[2412.04106v1](http://arxiv.org/abs/2412.04106v1)|null|
|**2024-12-04**|**Intuitive Axial Augmentation Using Polar-Sine-Based Piecewise Distortion for Medical Slice-Wise Segmentation**|Yiqin Zhang et.al.|[2412.03352v1](http://arxiv.org/abs/2412.03352v1)|[link](https://github.com/mgamz/psbpd)|
|**2024-12-04**|**Detecting abnormal heart sound using mobile phones and on-device IConNet**|Linh Vu et.al.|[2412.03267v1](http://arxiv.org/abs/2412.03267v1)|null|
|**2024-12-04**|**MRNet: Multifaceted Resilient Networks for Medical Image-to-Image Translation**|Hyojeong Lee et.al.|[2412.03039v1](http://arxiv.org/abs/2412.03039v1)|null|
|**2024-12-04**|**Higher Order Transformers: Efficient Attention Mechanism for Tensor Structured Data**|Soroush Omranpour et.al.|[2412.02919v1](http://arxiv.org/abs/2412.02919v1)|null|
|**2024-12-03**|**A Novel Compact LLM Framework for Local, High-Privacy EHR Data Applications**|Yixiang Qu et.al.|[2412.02868v1](http://arxiv.org/abs/2412.02868v1)|null|
|**2024-12-03**|**Block MedCare: Advancing healthcare through blockchain integration with AI and IoT**|Oliver Simonoski et.al.|[2412.02851v1](http://arxiv.org/abs/2412.02851v1)|null|
|**2024-12-03**|**CNNSum: Exploring Long-Conext Summarization with Large Language Models in Chinese Novels**|Lingxiao Wei et.al.|[2412.02819v2](http://arxiv.org/abs/2412.02819v2)|null|
|**2024-12-03**|**Optimization of Transformer heart disease prediction model based on particle swarm optimization algorithm**|Peiyang Yu et.al.|[2412.02801v1](http://arxiv.org/abs/2412.02801v1)|null|
|**2024-12-03**|**Medical Multimodal Foundation Models in Clinical Diagnosis and Treatment: Applications, Challenges, and Future Directions**|Kai Sun et.al.|[2412.02621v1](http://arxiv.org/abs/2412.02621v1)|null|
|**2024-12-03**|**U-Net in Medical Image Segmentation: A Review of Its Applications Across Modalities**|Fnu Neha et.al.|[2412.02242v1](http://arxiv.org/abs/2412.02242v1)|null|
|**2024-12-03**|**Recovering implicit physics model under real-world constraints**|Ayan Banerjee et.al.|[2412.02215v1](http://arxiv.org/abs/2412.02215v1)|null|
|**2024-12-03**|**Comparative Performance of Machine Learning Algorithms for Early Genetic Disorder and Subclass Classification**|Abu Bakar Siddik et.al.|[2412.02189v1](http://arxiv.org/abs/2412.02189v1)|null|
|**2024-12-03**|**Anatomically-Grounded Fact Checking of Automated Chest X-ray Reports**|R. Mahmood et.al.|[2412.02177v1](http://arxiv.org/abs/2412.02177v1)|null|
|**2024-12-03**|**Keeping Experts in the Loop: Expert-Guided Optimization for Clinical Data Classification using Large Language Models**|Nader Karayanni et.al.|[2412.02173v1](http://arxiv.org/abs/2412.02173v1)|null|
|**2024-12-03**|**Construction and optimization of health behavior prediction model for the elderly in smart elderly care**|Qian Guo et.al.|[2412.02062v1](http://arxiv.org/abs/2412.02062v1)|null|
|**2024-12-02**|**INSIGHT: Explainable Weakly-Supervised Medical Image Analysis**|Wenbo Zhang et.al.|[2412.02012v1](http://arxiv.org/abs/2412.02012v1)|null|
|**2024-12-02**|**The use of large language models to enhance cancer clinical trial educational materials**|Mingye Gao et.al.|[2412.01955v2](http://arxiv.org/abs/2412.01955v2)|null|
|**2024-12-02**|**Recurrent Neural Network on PICTURE Model**|Weihan Xu et.al.|[2412.01933v1](http://arxiv.org/abs/2412.01933v1)|null|
|**2024-12-02**|**ECG-SleepNet: Deep Learning-Based Comprehensive Sleep Stage Classification Using ECG Signals**|Poorya Aghaomidi et.al.|[2412.01929v1](http://arxiv.org/abs/2412.01929v1)|null|
|**2024-12-02**|**Deep Guess acceleration for explainable image reconstruction in sparse-view CT**|Elena Loli Piccolomini et.al.|[2412.01703v1](http://arxiv.org/abs/2412.01703v1)|[link](https://github.com/devangelista2/DeepGuess)|
|**2024-12-02**|**Digital Epidemiology: Leveraging Social Media for Insight into Epilepsy and Mental Health**|Liza Dahiya et.al.|[2412.01692v1](http://arxiv.org/abs/2412.01692v1)|null|
|**2024-12-02**|**Medchain: Bridging the Gap Between LLM Agents and Clinical Practice through Interactive Sequential Benchmarking**|Jie Liu et.al.|[2412.01605v1](http://arxiv.org/abs/2412.01605v1)|null|
|**2024-12-02**|**NCDD: Nearest Centroid Distance Deficit for Out-Of-Distribution Detection in Gastrointestinal Vision**|Sandesh Pokhrel et.al.|[2412.01590v1](http://arxiv.org/abs/2412.01590v1)|[link](https://github.com/bhattarailab/ncdd)|
|**2024-12-02**|**MambaU-Lite: A Lightweight Model based on Mamba and Integrated Channel-Spatial Attention for Skin Lesion Segmentation**|Thi-Nhu-Quynh Nguyen et.al.|[2412.01405v1](http://arxiv.org/abs/2412.01405v1)|[link](https://github.com/nqnguyen812/mambau-lite)|
|**2024-12-02**|**Su-RoBERTa: A Semi-supervised Approach to Predicting Suicide Risk through Social Media using Base Language Models**|Chayan Tank et.al.|[2412.01353v1](http://arxiv.org/abs/2412.01353v1)|null|
|**2024-12-02**|**Multimodal Medical Disease Classification with LLaMA II**|Christian Gapp et.al.|[2412.01306v1](http://arxiv.org/abs/2412.01306v1)|null|
|**2024-12-02**|**Best Practices for Large Language Models in Radiology**|Christian Bluethgen et.al.|[2412.01233v1](http://arxiv.org/abs/2412.01233v1)|null|
|**2024-12-02**|**Object Tracking in a $360^o$ View: A Novel Perspective on Bridging the Gap to Biomedical Advancements**|Mojtaba S. Fazli et.al.|[2412.01119v1](http://arxiv.org/abs/2412.01119v1)|null|
|**2024-12-02**|**Evaluating Automated Radiology Report Quality through Fine-Grained Phrasal Grounding of Clinical Findings**|Razi Mahmood et.al.|[2412.01031v1](http://arxiv.org/abs/2412.01031v1)|null|
|**2024-12-01**|**Generative Language Models Potential for Requirement Engineering Applications: Insights into Current Strengths and Limitations**|Summra Saleem et.al.|[2412.00959v1](http://arxiv.org/abs/2412.00959v1)|null|
|**2024-12-01**|**TSUBF-Net: Trans-Spatial UNet-like Network with Bi-direction Fusion for Segmentation of Adenoid Hypertrophy in CT**|Rulin Zhou et.al.|[2412.00787v1](http://arxiv.org/abs/2412.00787v1)|null|
|**2024-12-01**|**Automating Feedback Analysis in Surgical Training: Detection, Categorization, and Assessment**|Firdavs Nasriddinov et.al.|[2412.00760v1](http://arxiv.org/abs/2412.00760v1)|[link](https://github.com/firdavsn/SurgicalFeedbackAI)|
|**2024-11-30**|**Fairness at Every Intersection: Uncovering and Mitigating Intersectional Biases in Multimodal Clinical Predictions**|Resmi Ramachandranpillai et.al.|[2412.00606v1](http://arxiv.org/abs/2412.00606v1)|null|
|**2024-11-30**|**Opus: A Large Work Model for Complex Workflow Generation**|ThÃ©o Fagnoni et.al.|[2412.00573v2](http://arxiv.org/abs/2412.00573v2)|null|
|**2024-11-30**|**Polish Medical Exams: A new dataset for cross-lingual medical knowledge transfer assessment**|Åukasz Grzybowski et.al.|[2412.00559v1](http://arxiv.org/abs/2412.00559v1)|null|
|**2024-11-30**|**Unveiling Performance Challenges of Large Language Models in Low-Resource Healthcare: A Demographic Fairness Perspective**|Yue Zhou et.al.|[2412.00554v1](http://arxiv.org/abs/2412.00554v1)|null|
|**2024-11-30**|**2-Factor Retrieval for Improved Human-AI Decision Making in Radiology**|Jim Solomon et.al.|[2412.00372v1](http://arxiv.org/abs/2412.00372v1)|null|
|**2024-11-30**|**One Model for One Graph: A New Perspective for Pretraining with Cross-domain Graphs**|Jingzhe Liu et.al.|[2412.00315v1](http://arxiv.org/abs/2412.00315v1)|null|
|**2024-11-30**|**BOTS: Batch Bayesian Optimization of Extended Thompson Sampling for Severely Episode-Limited RL Settings**|Karine Karine et.al.|[2412.00308v1](http://arxiv.org/abs/2412.00308v1)|null|
|**2024-11-29**|**Fine Tuning Large Language Models to Deliver CBT for Depression**|Talha Tahir et.al.|[2412.00251v1](http://arxiv.org/abs/2412.00251v1)|[link](https://github.com/ttahir-git/FineTuning_LLMs_for_CBT_for_Depression)|
|**2024-11-29**|**Integrating Social Determinants of Health into Knowledge Graphs: Evaluating Prediction Bias and Fairness in Healthcare**|Tianqi Shang et.al.|[2412.00245v1](http://arxiv.org/abs/2412.00245v1)|[link](https://github.com/hwq0726/sdoh-kg)|
|**2024-11-29**|**Dynamic EEG-fMRI mapping: Revealing the relationship between brain connectivity and cognitive state**|Guiran Liu et.al.|[2411.19922v1](http://arxiv.org/abs/2411.19922v1)|null|
|**2024-11-29**|**Graph Neural Networks for Heart Failure Prediction on an EHR-Based Patient Similarity Graph**|Heloisa Oss Boll et.al.|[2411.19742v1](http://arxiv.org/abs/2411.19742v1)|[link](https://github.com/hossboll/patient-gnn)|
|**2024-11-29**|**Multimodal Whole Slide Foundation Model for Pathology**|Tong Ding et.al.|[2411.19666v1](http://arxiv.org/abs/2411.19666v1)|[link](https://github.com/mahmoodlab/titan)|
|**2024-11-29**|**SkelMamba: A State Space Model for Efficient Skeleton Action Recognition of Neurological Disorders**|Niki Martinel et.al.|[2411.19544v1](http://arxiv.org/abs/2411.19544v1)|null|
|**2024-11-29**|**Knowledge-Data Fusion Based Source-Free Semi-Supervised Domain Adaptation for Seizure Subtype Classification**|Ruimin Peng et.al.|[2411.19502v1](http://arxiv.org/abs/2411.19502v1)|null|
|**2024-11-29**|**Adaptive Interactive Segmentation for Multimodal Medical Imaging via Selection Engine**|Zhi Li et.al.|[2411.19447v1](http://arxiv.org/abs/2411.19447v1)|[link](https://github.com/RicoLeehdu/SISeg)|
|**2024-11-28**|**Libra: Leveraging Temporal Images for Biomedical Radiology Analysis**|Xi Zhang et.al.|[2411.19378v1](http://arxiv.org/abs/2411.19378v1)|[link](https://github.com/X-iZhang/Libra)|
|**2024-11-28**|**Mapping Public Perception of Artificial Intelligence: Expectations, Risk-Benefit Tradeoffs, and Value As Determinants for Societal Acceptance**|Philipp Brauner et.al.|[2411.19356v1](http://arxiv.org/abs/2411.19356v1)|null|
|**2024-11-28**|**FonTS: Text Rendering with Typography and Style Controls**|Wenda Shi et.al.|[2412.00136v1](http://arxiv.org/abs/2412.00136v1)|null|
|**2024-11-28**|**Pre-Training Graph Contrastive Masked Autoencoders are Strong Distillers for EEG**|Xinxu Wei et.al.|[2411.19230v1](http://arxiv.org/abs/2411.19230v1)|null|
|**2024-11-28**|**Open-Sora Plan: Open-Source Large Video Generation Model**|Bin Lin et.al.|[2412.00131v1](http://arxiv.org/abs/2412.00131v1)|[link](https://github.com/pku-yuangroup/open-sora-plan)|
|**2024-11-28**|**CovidLLM: A Robust Large Language Model with Missing Value Adaptation and Multi-Objective Learning Strategy for Predicting Disease Severity and Clinical Outcomes in COVID-19 Patients**|Shengjun Zhu et.al.|[2412.03593v1](http://arxiv.org/abs/2412.03593v1)|[link](https://github.com/sysll/CovidLLM)|
|**2024-11-28**|**A Unified Platform for At-Home Post-Stroke Rehabilitation Enabled by Wearable Technologies and Artificial Intelligence**|Chenyu Tang et.al.|[2411.19000v1](http://arxiv.org/abs/2411.19000v1)|null|
|**2024-11-28**|**Devising a Set of Compact and Explainable Spoken Language Feature for Screening Alzheimer's Disease**|Junan Li et.al.|[2411.18922v1](http://arxiv.org/abs/2411.18922v1)|null|
|**2024-11-27**|**LLM-ABBA: Understanding time series via symbolic approximation**|Erin Carson et.al.|[2411.18506v3](http://arxiv.org/abs/2411.18506v3)|null|
|**2024-11-27**|**MvKeTR: Chest CT Report Generation with Multi-View Perception and Knowledge Enhancement**|Xiwei Deng et.al.|[2411.18309v1](http://arxiv.org/abs/2411.18309v1)|null|
|**2024-11-27**|**Wearable intelligent throat enables natural speech in stroke patients with dysarthria**|Chenyu Tang et.al.|[2411.18266v2](http://arxiv.org/abs/2411.18266v2)|null|
|**2024-11-27**|**Multimodal Integration of Longitudinal Noninvasive Diagnostics for Survival Prediction in Immunotherapy Using Deep Learning**|Melda Yeghaian et.al.|[2411.18253v1](http://arxiv.org/abs/2411.18253v1)|null|
|**2024-11-27**|**Randomized-Grid Search for Hyperparameter Tuning in Decision Tree Model to Improve Performance of Cardiovascular Disease Classification**|Abhay Kumar Pathak et.al.|[2411.18234v1](http://arxiv.org/abs/2411.18234v1)|null|
|**2024-11-27**|**The Return of Pseudosciences in Artificial Intelligence: Have Machine Learning and Deep Learning Forgotten Lessons from Statistics and History?**|JÃ©rÃ©mie Sublime et.al.|[2411.18656v1](http://arxiv.org/abs/2411.18656v1)|null|
|**2024-11-27**|**Graph Neural Network for Cerebral Blood Flow Prediction With Clinical Datasets**|Seungyeon Kim et.al.|[2411.17971v1](http://arxiv.org/abs/2411.17971v1)|null|
|**2024-11-26**|**Evaluating Generative AI-Enhanced Content: A Conceptual Framework Using Qualitative, Quantitative, and Mixed-Methods Approaches**|Saman Sarraf et.al.|[2411.17943v1](http://arxiv.org/abs/2411.17943v1)|null|
|**2024-11-26**|**Automating grapevine LAI features estimation with UAV imagery and machine learning**|Muhammad Waseem Akram et.al.|[2411.17897v1](http://arxiv.org/abs/2411.17897v1)|null|
|**2024-11-26**|**HOPPR Medical-Grade Platform for Medical Imaging AI**|Kalina P. Slavkova et.al.|[2411.17891v1](http://arxiv.org/abs/2411.17891v1)|null|
|**2024-11-26**|**Explainable AI for Classifying UTI Risk Groups Using a Real-World Linked EHR and Pathology Lab Dataset**|Yujie Dai et.al.|[2411.17645v1](http://arxiv.org/abs/2411.17645v1)|null|
|**2024-11-26**|**DapPep: Domain Adaptive Peptide-agnostic Learning for Universal T-cell Receptor-antigen Binding Affinity Prediction**|Jiangbin Zheng et.al.|[2411.17798v1](http://arxiv.org/abs/2411.17798v1)|null|
|**2024-11-26**|**Learning Explainable Treatment Policies with Clinician-Informed Representations: A Practical Approach**|Johannes O. Ferstad et.al.|[2411.17570v1](http://arxiv.org/abs/2411.17570v1)|[link](https://github.com/jferstad/ml4h-explainable-policies)|
|**2024-11-26**|**A Bilayer Segmentation-Recombination Network for Accurate Segmentation of Overlapping C. elegans**|Mengqian Dinga et.al.|[2411.17557v1](http://arxiv.org/abs/2411.17557v1)|null|
|**2024-11-26**|**AI-Augmented Ethical Hacking: A Practical Examination of Manual Exploitation and Privilege Escalation in Linux Environments**|Haitham S. Al-Sinani et.al.|[2411.17539v1](http://arxiv.org/abs/2411.17539v1)|null|
|**2024-11-26**|**ShowUI: One Vision-Language-Action Model for GUI Visual Agent**|Kevin Qinghong Lin et.al.|[2411.17465v1](http://arxiv.org/abs/2411.17465v1)|[link](https://github.com/showlab/showui)|
|**2024-11-26**|**Social Distancing Induced Coronavirus Optimization Algorithm (COVO): Application to Multimodal Function Optimization and Noise Removal**|Om Ramakisan Varma et.al.|[2411.17282v1](http://arxiv.org/abs/2411.17282v1)|null|
|**2024-11-26**|**Semantic Data Augmentation for Long-tailed Facial Expression Recognition**|Zijian Li et.al.|[2411.17254v1](http://arxiv.org/abs/2411.17254v1)|null|
|**2024-11-26**|**GraphSubDetector: Time Series Subsequence Anomaly Detection via Density-Aware Adaptive Graph Neural Network**|Weiqi Chen et.al.|[2411.17218v1](http://arxiv.org/abs/2411.17218v1)|null|
|**2024-11-26**|**Strategic Prompting for Conversational Tasks: A Comparative Analysis of Large Language Models Across Diverse Conversational Tasks**|Ratnesh Kumar Joshi et.al.|[2411.17204v2](http://arxiv.org/abs/2411.17204v2)|null|
|**2024-11-25**|**Contrastive Deep Learning Reveals Age Biomarkers in Histopathological Skin Biopsies**|Kaustubh Chakradeo et.al.|[2411.16956v1](http://arxiv.org/abs/2411.16956v1)|null|
|**2024-11-25**|**Enabling Adoption of Regenerative Agriculture through Soil Carbon Copilots**|Margaret Capetz et.al.|[2411.16872v2](http://arxiv.org/abs/2411.16872v2)|null|
|**2024-11-25**|**Enhancing In-Hospital Mortality Prediction Using Multi-Representational Learning with LLM-Generated Expert Summaries**|Harshavardhan Battula et.al.|[2411.16818v1](http://arxiv.org/abs/2411.16818v1)|null|
|**2024-11-25**|**Will an AI with Private Information Allow Itself to Be Switched Off?**|Andrew Garber et.al.|[2411.17749v1](http://arxiv.org/abs/2411.17749v1)|null|
|**2024-11-25**|**Privacy-Preserving Federated Foundation Model for Generalist Ultrasound Artificial Intelligence**|Yuncheng Jiang et.al.|[2411.16380v1](http://arxiv.org/abs/2411.16380v1)|null|
|**2024-11-25**|**GEMeX: A Large-Scale, Groundable, and Explainable Medical VQA Benchmark for Chest X-ray Diagnosis**|Bo Liu et.al.|[2411.16778v1](http://arxiv.org/abs/2411.16778v1)|null|

#### Abstracts
##### **Enhancing FKG.in: automating Indian food composition analysis**
2412.05248v1 by Saransh Kumar Gupta, Lipika Dey, Partha Pratim Das, Geeta Trilok-Kumar, Ramesh Jain

This paper presents a novel approach to compute food composition data for
Indian recipes using a knowledge graph for Indian food (FKG.in) and LLMs. The
primary focus is to provide a broad overview of an automated food composition
analysis workflow and describe its core functionalities: nutrition data
aggregation, food composition analysis, and LLM-augmented information
resolution. This workflow aims to complement FKG.in and iteratively supplement
food composition data from verified knowledge bases. Additionally, this paper
highlights the challenges of representing Indian food and accessing food
composition data digitally. It also reviews three key sources of food
composition data: the Indian Food Composition Tables, the Indian Nutrient
Databank, and the Nutritionix API. Furthermore, it briefly outlines how users
can interact with the workflow to obtain diet-based health recommendations and
detailed food composition information for numerous recipes. We then explore the
complex challenges of analyzing Indian recipe information across dimensions
such as structure, multilingualism, and uncertainty as well as present our
ongoing work on LLM-based solutions to address these issues. The methods
proposed in this workshop paper for AI-driven knowledge curation and
information resolution are application-agnostic, generalizable, and replicable
for any domain.

æè¦ï¼éç¯è«ææåºä¸ååµæ°çæ¹æ³ï¼ä½¿ç¨å°åº¦é£ç©ç¥è­åè­ (FKG.in) åå¤§åèªè¨æ¨¡å (LLM) ä¾è¨ç®å°åº¦é£è­çé£åæåè³æãä¸»è¦ç®æ¨æ¯æä¾èªååé£åæååæå·¥ä½æµç¨çæ¦è§ï¼ä¸¦æè¿°å¶æ ¸å¿åè½ï¼çé¤è³æå½æ´ãé£åæååæï¼ä»¥å LLM å¢å¼·çè³è¨è§£æãæ­¤å·¥ä½æµç¨æ¨å¨è£å FKG.inï¼ä¸¦åè¦è£åä¾èªé©è­ç¥è­åº«çé£åæåè³æãæ­¤å¤ï¼éç¯è«æå¼·èª¿äºåç¾å°åº¦é£ç©åä»¥æ¸ä½æ¹å¼å­åé£åæåè³æçææ°ãå®ä¹æª¢è¦äºé£åæåè³æçä¸åä¸»è¦ä¾æºï¼å°åº¦é£åæåè¡¨ãå°åº¦çé¤è³æåº«ï¼ä»¥å Nutritionix APIãæ­¤å¤ï¼å®ç°¡è¦æ¦è¿°äºä½¿ç¨èå¦ä½èå·¥ä½æµç¨äºåï¼ä»¥åå¾åºæ¼é£²é£çå¥åº·å»ºè­°åè¨±å¤é£è­çè©³ç´°é£åæåè³è¨ãæ¥èæåæ¢è¨åæå°åº¦é£è­è³è¨çè¤éææ°ï¼åæ¬çµæ§ãå¤èªè¨æ§ï¼ä»¥åä¸ç¢ºå®æ§ï¼ä¸¦æåºæåæ­£å¨é²è¡ç LLM åºç¤è§£æ±ºæ¹æ¡ä¾è§£æ±ºéäºåé¡ãéç¯å·¥ä½åè«æä¸­æåºç AI é©åç¥è­ç­å±åè³è¨è§£ææ¹æ³èæç¨ç¨å¼ç¡éï¼å¯æ¦æ¬åï¼ä¸å¯è¤è£½å°ä»»ä½é åã

##### **Are Frontier Large Language Models Suitable for Q&A in Science Centres?**
2412.05200v1 by Jacob Watson, FabrÃ­cio GÃ³es, Marco Volpe, Talles Medeiros

This paper investigates the suitability of frontier Large Language Models
(LLMs) for Q&A interactions in science centres, with the aim of boosting
visitor engagement while maintaining factual accuracy. Using a dataset of
questions collected from the National Space Centre in Leicester (UK), we
evaluated responses generated by three leading models: OpenAI's GPT-4, Claude
3.5 Sonnet, and Google Gemini 1.5. Each model was prompted for both standard
and creative responses tailored to an 8-year-old audience, and these responses
were assessed by space science experts based on accuracy, engagement, clarity,
novelty, and deviation from expected answers. The results revealed a trade-off
between creativity and accuracy, with Claude outperforming GPT and Gemini in
both maintaining clarity and engaging young audiences, even when asked to
generate more creative responses. Nonetheless, experts observed that higher
novelty was generally associated with reduced factual reliability across all
models. This study highlights the potential of LLMs in educational settings,
emphasizing the need for careful prompt engineering to balance engagement with
scientific rigor.

æè¦ï¼éç¯è«ææ¢è¨åæ²¿å¤§åèªè¨æ¨¡å (LLM) å¨ç§å­¸ä¸­å¿åç­äºåä¸­çé©ç¨æ§ï¼ç®çæ¯å¨ç¶­æäºå¯¦æºç¢ºæ§çåææåè¨ªå®¢åèåº¦ãæåä½¿ç¨å¾è±åèæ¯ç¹åå®¶å¤ªç©ºä¸­å¿æ¶éçæåè³æéï¼è©ä¼°äºä¸åé åæ¨¡åçæçåæï¼OpenAI ç GPT-4ãClaude 3.5 Sonnet å Google Gemini 1.5ãæ¯åæ¨¡åé½è¢«æç¤ºéå° 8 æ­²çåç¾éèº«æé æ¨æºåæåµæçåæï¼èéäºåæåç±å¤ªç©ºç§å­¸å°å®¶æ ¹ææºç¢ºæ§ãåèåº¦ãæ¸æ°åº¦ãæ°ç©æ§åèé æç­æ¡çåå·®é²è¡è©ä¼°ãçµæé¡¯ç¤ºåµé åèæºç¢ºæ§ä¹éå­å¨æ¬è¡¡ï¼Claude å¨ç¶­ææ¸æ°åº¦åå¸å¼å¹´è¼åç¾æ¹é¢åªæ¼ GPT å Geminiï¼å³ä½¿è¢«è¦æ±ç¢çæ´å¤æåµæçåæãåç®¡å¦æ­¤ï¼å°å®¶åè§å¯å°ï¼æææ¨¡åä¸­è¼é«çæ°ç©æ§éå¸¸èè¼ä½çå¯¦éå¯é æ§ç¸éãéé ç ç©¶å¼·èª¿äº LLM å¨æè²ç°å¢ä¸­çæ½åï¼ä¸¦å¼·èª¿éè¦ä»ç´°æç¤ºå·¥ç¨ä»¥å¹³è¡¡åèåº¦åç§å­¸å´è¬¹æ§ã

##### **SurgBox: Agent-Driven Operating Room Sandbox with Surgery Copilot**
2412.05187v1 by Jinlin Wu, Xusheng Liang, Xuexue Bai, Zhen Chen

Surgical interventions, particularly in neurology, represent complex and
high-stakes scenarios that impose substantial cognitive burdens on surgical
teams. Although deliberate education and practice can enhance cognitive
capabilities, surgical training opportunities remain limited due to patient
safety concerns. To address these cognitive challenges in surgical training and
operation, we propose SurgBox, an agent-driven sandbox framework to
systematically enhance the cognitive capabilities of surgeons in immersive
surgical simulations. Specifically, our SurgBox leverages large language models
(LLMs) with tailored Retrieval-Augmented Generation (RAG) to authentically
replicate various surgical roles, enabling realistic training environments for
deliberate practice. In particular, we devise Surgery Copilot, an AI-driven
assistant to actively coordinate the surgical information stream and support
clinical decision-making, thereby diminishing the cognitive workload of
surgical teams during surgery. By incorporating a novel Long-Short Memory
mechanism, our Surgery Copilot can effectively balance immediate procedural
assistance with comprehensive surgical knowledge. Extensive experiments using
real neurosurgical procedure records validate our SurgBox framework in both
enhancing surgical cognitive capabilities and supporting clinical
decision-making. By providing an integrated solution for training and
operational support to address cognitive challenges, our SurgBox framework
advances surgical education and practice, potentially transforming surgical
outcomes and healthcare quality. The code is available at
https://github.com/franciszchen/SurgBox.

æè¦ï¼å¤ç§æè¡ï¼ç¹å¥æ¯å¨ç¥ç¶å¤ç§ï¼ä»£è¡¨äºè¤éä¸é«é¢¨éªçå ´æ¯ï¼å°å¤ç§åéæ½å äºå·¨å¤§çèªç¥è² æãåç®¡ç¶éæ·±æçæ®çæè²åå¯¦è¸å¯ä»¥å¢å¼·èªç¥è½åï¼ä½ç±æ¼æ£èå®å¨åé¡ï¼å¤ç§å¹è¨æ©æä»ç¶æéãçºäºæå°å¤ç§å¹è¨åæè¡ä¸­çéäºèªç¥ææ°ï¼æåæåºäº SurgBoxï¼ä¸åç±ä»£çé©åçæ²çæ¡æ¶ï¼ç¨æ¼ç³»çµ±å°å¢å¼·å¤ç§é«çå¨æ²æµ¸å¼å¤ç§æ¨¡æ¬ä¸­çèªç¥è½åãå·é«ä¾èªªï¼æåç SurgBox å©ç¨å¤§åèªè¨æ¨¡å (LLM) åéèº«å®å¶çæª¢ç´¢å¢å¼·çæ (RAG) ä¾çå¯¦å°è¤è£½åç¨®å¤ç§è§è²ï¼çºæ·±æçæ®çå¯¦è¸æä¾é¼ççå¹è¨ç°å¢ãç¹å¥æ¯ï¼æåè¨­è¨äºæè¡å¯é§é§ï¼ä¸åç± AI é©åçå©æï¼ç¨æ¼ä¸»ååèª¿å¤ç§ä¿¡æ¯æµä¸¦æ¯æè¨åºæ±ºç­å¶å®ï¼å¾èæ¸å°å¤ç§åéå¨æè¡æéçèªç¥è² æãééçµåä¸ç¨®æ°ç©çé·ç­æè¨æ¶æ©å¶ï¼æåç Surgery Copilot å¯ä»¥ææå°å¹³è¡¡å³æç¨åºåå©åå¨é¢çå¤ç§ç¥è­ãä½¿ç¨çå¯¦çç¥ç¶å¤ç§æè¡è¨éé²è¡çå»£æ³å¯¦é©é©è­äºæåç SurgBox æ¡æ¶ï¼æ¢è½å¢å¼·å¤ç§èªç¥è½åï¼åè½æ¯æè¨åºæ±ºç­å¶å®ãééæä¾ä¸åç¶åçå¹è¨åéçæ¯æè§£æ±ºæ¹æ¡ä¾æå°èªç¥ææ°ï¼æåç SurgBox æ¡æ¶æ¨åäºå¤ç§æè²åå¯¦è¸ï¼æå¯è½æ¹è®å¤ç§çµæåé«çä¿å¥è³ªéãä»£ç¢¼å¯å¨ https://github.com/franciszchen/SurgBox ç²å¾ã

##### **Project Report: Requirements for a Social Robot as an Information Provider in the Public Sector**
2412.05013v1 by Thomas Sievers, Nele Russwinkel

Is it possible to integrate a humanoid social robot into the work processes
or customer care in an official environment, e.g. in municipal offices? If so,
what could such an application scenario look like and what skills would the
robot need to have when interacting with human customers? What are requirements
for this kind of interactions? We have devised an application scenario for such
a case, determined the necessary or desirable capabilities of the robot,
developed a corresponding robot application and carried out initial tests and
evaluations in a project together with the Kiel City Council. One of the most
important insights gained in the project was that a humanoid robot with natural
language processing capabilities based on large language models as well as
human-like gestures and posture changes (animations) proved to be much more
preferred by users compared to standard browser-based solutions on tablets for
an information system in the City Council. Furthermore, we propose a connection
of the ACT-R cognitive architecture with the robot, where an ACT-R model is
used in interaction with the robot application to cognitively process and
enhance a dialogue between human and robot.

æè¦ï¼æ¯å¦å¯è½å°é¡äººç¤¾ææ©å¨äººæ´åå°å·¥ä½æµç¨æå®æ¹ç°å¢ä¸­çå®¢æ¶æåä¸­ï¼ä¾å¦å¸æ¿è¾¦å¬å®¤ï¼å¦ææ¯éæ¨£ï¼éæ¨£çæç¨å ´æ¯å¯è½ææ¯ä»éº¼æ¨£å­ï¼èæ©å¨äººå¨èäººé¡å®¢æ¶äºåæéè¦å·ååªäºæè½ï¼éç¨®äºåæåªäºè¦æ±ï¼æåçºéç¨®ææ³è¨­è¨äºä¸åæç¨å ´æ¯ï¼ç¢ºå®äºæ©å¨äººå¿è¦æçæ³çè½åï¼éç¼äºä¸åå°æçæ©å¨äººæç¨ç¨å¼ï¼ä¸¦èåºç¾å¸è­°æå±åå¨ä¸åå°æ¡ä¸­é²è¡äºåæ­¥æ¸¬è©¦åè©ä¼°ãè©²å°æ¡ç²å¾çæéè¦è¦è§£ä¹ä¸æ¯ï¼èå¹³æ¿é»è¦ä¸ç¨æ¼å¸è­°æè³è¨ç³»çµ±çæ¨æºçè¦½å¨è§£æ±ºæ¹æ¡ç¸æ¯ï¼å·æäººå·¥èªè¨èçè½åï¼åºæ¼å¤§åèªè¨æ¨¡åï¼ä»¥åé¡äººçæå¢åå§¿å¢è®åï¼åç«ï¼çé¡äººæ©å¨äººè¢«ä½¿ç¨èæ´çºéçãæ­¤å¤ï¼æåå»ºè­°å° ACT-R èªç¥æ¶æ§èæ©å¨äººé£æ¥èµ·ä¾ï¼å¶ä¸­ ACT-R æ¨¡åç¨æ¼èæ©å¨äººæç¨ç¨å¼äºåï¼ä»¥èªç¥èçåå¢å¼·äººèæ©å¨äººä¹éçå°è©±ã

##### **Backdooring Outlier Detection Methods: A Novel Attack Approach**
2412.05010v1 by ZeinabSadat Taghavi, Hossein Mirzaei

There have been several efforts in backdoor attacks, but these have primarily
focused on the closed-set performance of classifiers (i.e., classification).
This has left a gap in addressing the threat to classifiers' open-set
performance, referred to as outlier detection in the literature. Reliable
outlier detection is crucial for deploying classifiers in critical real-world
applications such as autonomous driving and medical image analysis. First, we
show that existing backdoor attacks fall short in affecting the open-set
performance of classifiers, as they have been specifically designed to confuse
intra-closed-set decision boundaries. In contrast, an effective backdoor attack
for outlier detection needs to confuse the decision boundary between the closed
and open sets. Motivated by this, in this study, we propose BATOD, a novel
Backdoor Attack targeting the Outlier Detection task. Specifically, we design
two categories of triggers to shift inlier samples to outliers and vice versa.
We evaluate BATOD using various real-world datasets and demonstrate its
superior ability to degrade the open-set performance of classifiers compared to
previous attacks, both before and after applying defenses.

æè¦ï¼å°æ¼å¾éæ»æå·²ç¶æå¹¾é åªåï¼ä½éäºä¸»è¦éä¸­å¨åé¡å¨çééæè½ï¼å³åé¡ï¼ä¸ãéä½¿å¾å¨èçåé¡å¨éæ¾éæè½çå¨èä¸åºç¾äºä¸åç¼ºå£ï¼å¨æç»ä¸­ç¨±çºç°å¸¸å¼åµæ¸¬ãå¯é çç°å¸¸å¼åµæ¸¬å°æ¼å¨ééµççå¯¦ä¸çæç¨ä¸­é¨ç½²åé¡å¨è³ééè¦ï¼ä¾å¦èªåé§é§åé«å­¸å½±ååæãé¦åï¼æåå±ç¤ºç¾æçå¾éæ»æå¨å½±é¿åé¡å¨çéæ¾éæè½æ¹é¢ä¸è¶³ï¼å çºå®åè¢«ç¹å¥è¨­è¨ç¨ä¾æ··æ·ééå§æ±ºç­éçãç¸æ¯ä¹ä¸ï¼ææçç°å¸¸å¼åµæ¸¬å¾éæ»æéè¦æ··æ·ééåéæ¾éä¹éçæ±ºç­éçãæéæ¼æ­¤ï¼å¨æ¬ç ç©¶ä¸­ï¼æåæåº BATODï¼ä¸ç¨®éå°ç°å¸¸å¼åµæ¸¬ä»»åçæ°åå¾éæ»æãå·é«ä¾èªªï¼æåè¨­è¨äºå©ç¨®é¡åçè§¸ç¼å¨ï¼å°å§é»æ¨£æ¬è½ç§»å°ç°å¸¸å¼ï¼åä¹äº¦ç¶ãæåä½¿ç¨åç¨®çå¯¦ä¸çè³æéè©ä¼° BATODï¼ä¸¦å±ç¤ºäºå®å¨éä½åé¡å¨çéæ¾éæè½æ¹é¢çåªç°è½åï¼èä¹åå¨æç¨é²ç¦¦æªæ½ä¹ååä¹å¾çæ»æç¸æ¯ã

##### **Bed-Attached Vibration Sensor System: A Machine Learning Approach for Fall Detection in Nursing Homes**
2412.04950v1 by Thomas Bartz-Beielstein, Axel Wellendorf, Noah PÃ¼tz, Jens Brandt, Alexander Hinterleitner, Richard Schulz, Richard Scholz, Olaf Mersmann, Robin Knabe

The increasing shortage of nursing staff and the acute risk of falls in
nursing homes pose significant challenges for the healthcare system. This study
presents the development of an automated fall detection system integrated into
care beds, aimed at enhancing patient safety without compromising privacy
through wearables or video monitoring. Mechanical vibrations transmitted
through the bed frame are processed using a short-time Fourier transform,
enabling robust classification of distinct human fall patterns with a
convolutional neural network. Challenges pertaining to the quantity and
diversity of the data are addressed, proposing the generation of additional
data with a specific emphasis on enhancing variation. While the model shows
promising results in distinguishing fall events from noise using lab data,
further testing in real-world environments is recommended for validation and
improvement. Despite limited available data, the proposed system shows the
potential for an accurate and rapid response to falls, mitigating health
implications, and addressing the needs of an aging population. This case study
was performed as part of the ZIM Project. Further research on sensors enhanced
by artificial intelligence will be continued in the ShapeFuture Project.

æè¦ï¼è­·çäººå¡æ¥çç­ç¼ºï¼ä¸è­·çä¹å®¶ç¼çè·åçé¢¨éªæ¥µé«ï¼å°é«çä¿å¥ç³»çµ±æ§æéå¤§ææ°ãæ¬ç ç©¶æåºå°èªååè·ååµæ¸¬ç³»çµ±æ´åè³è­·çåºï¼æ¨å¨æåçæ£å®å¨ï¼åæééç©¿æ´å¼è£ç½®æè¦è¨ç£æ§ä¾ä¿è­·é±ç§ãééåºæ¶å³éçæ©æ¢°æ¯åæä½¿ç¨ç­æè·åç«èè½æé²è¡èçï¼ä¸¦è½å©ç¨å·ç©ç¥ç¶ç¶²è·¯å°ä¸åäººé¡è·åæ¨¡å¼é²è¡ç©©å¥åé¡ãéå°è³ææ¸éåå¤æ¨£æ§çææ°ï¼æåºç¢çé¡å¤è³æçå»ºè­°ï¼ç¹å¥èéæ¼å¢å è®åæ§ãéç¶æ­¤æ¨¡åå¨ä½¿ç¨å¯¦é©å®¤è³æååè·åäºä»¶åéè¨æé¡¯ç¤ºåºæå¸æççµæï¼ä½å»ºè­°å¨çå¯¦ç°å¢ä¸­é²ä¸æ­¥æ¸¬è©¦ä»¥é²è¡é©è­åæ¹é²ãåç®¡å¯ç¨è³ææéï¼ä½ææåºçç³»çµ±é¡¯ç¤ºåºå°è·åäºä»¶ååºæºç¢ºä¸å¿«éçåæçæ½åï¼æ¸è¼å¥åº·å½±é¿ï¼ä¸¦æ»¿è¶³èé½¡åäººå£çéæ±ãæ­¤æ¡ä¾ç ç©¶æ¯ä½çº ZIM å°æ¡çä¸é¨åé²è¡çãShapeFuture å°æ¡å°æçºé²è¡äººå·¥æºæ§å¢å¼·ææ¸¬å¨çé²ä¸æ­¥ç ç©¶ã

##### **Estimating the treatment effect over time under general interference through deep learner integrated TMLE**
2412.04799v1 by Suhan Guo, Furao Shen, Ni Li

Understanding the effects of quarantine policies in populations with
underlying social networks is crucial for public health, yet most causal
inference methods fail here due to their assumption of independent individuals.
We introduce DeepNetTMLE, a deep-learning-enhanced Targeted Maximum Likelihood
Estimation (TMLE) method designed to estimate time-sensitive treatment effects
in observational data. DeepNetTMLE mitigates bias from time-varying confounders
under general interference by incorporating a temporal module and domain
adversarial training to build intervention-invariant representations. This
process removes associations between current treatments and historical
variables, while the targeting step maintains the bias-variance trade-off,
enhancing the reliability of counterfactual predictions. Using simulations of a
``Susceptible-Infected-Recovered'' model with varied quarantine coverages, we
show that DeepNetTMLE achieves lower bias and more precise confidence intervals
in counterfactual estimates, enabling optimal quarantine recommendations within
budget constraints, surpassing state-of-the-art methods.

æè¦ï¼äºè§£å·ææ½å¨ç¤¾äº¤ç¶²çµ¡çäººç¾¤ä¸­éé¢æ¿ç­çå½±é¿å°æ¼å¬å±è¡çè³ééè¦ï¼ä½ç±æ¼åè¨­åäººç¨ç«ï¼å¤§å¤æ¸å ææ¨è«æ¹æ³å¨æ­¤èå¤±æãæåå¼å¥äº DeepNetTMLEï¼éæ¯ä¸ç¨®æ·±åº¦å­¸ç¿å¢å¼·çç®æ¨æå¤§ä¼¼ç¶ä¼°è¨ (TMLE) æ¹æ³ï¼æ¨å¨ä¼°è¨è§æ¸¬æ¸æä¸­çæéææèçææãDeepNetTMLE ééæ´åæéæ¨¡çµåé åå°æè¨ç·´ä¾å»ºç«ä»å¥ä¸è®è¡¨ç¤ºï¼å¾èæ¸è¼ä¸è¬å¹²æ¾ä¸æè®æ··éå ç´ çåå·®ãæ­¤éç¨æ¶é¤äºç¶åèçèæ­·å²è®æ¸ä¹éçéè¯ï¼èç®æ¨è¨­å®æ­¥é©åç¶­æåå·®è®ç°æ¬è¡¡ï¼å¢å¼·åäºå¯¦é æ¸¬çå¯é æ§ãä½¿ç¨å·æä¸åéé¢è¦èççãææè-ææè-åº·å¾©èãæ¨¡åçæ¨¡æ¬ï¼æåè¡¨æ DeepNetTMLE å¨åäºå¯¦ä¼°è¨ä¸­å¯¦ç¾äºè¼ä½çåå·®åæ´ç²¾ç¢ºçä¿¡å¿åéï¼å¾èå¨é ç®éå¶å§å¯¦ç¾äºæä½³éé¢å»ºè­°ï¼è¶è¶äºæåé²çæ¹æ³ã

##### **Multi-class heart disease Detection, Classification, and Prediction using Machine Learning Models**
2412.04792v1 by Mahfuzul Haque, Abu Saleh Musa Miah, Debashish Gupta, Md. Maruf Al Hossain Prince, Tanzina Alam, Nusrat Sharmin, Mohammed Sowket Ali, Jungpil Shin

Heart disease is a leading cause of premature death worldwide, particularly
among middle-aged and older adults, with men experiencing a higher prevalence.
According to the World Health Organization (WHO), non-communicable diseases,
including heart disease, account for 25\% (17.9 million) of global deaths, with
over 43,204 annual fatalities in Bangladesh. However, the development of heart
disease detection (HDD) systems tailored to the Bangladeshi population remains
underexplored due to the lack of benchmark datasets and reliance on manual or
limited-data approaches. This study addresses these challenges by introducing
new, ethically sourced HDD dataset, BIG-Dataset and CD dataset which
incorporates comprehensive data on symptoms, examination techniques, and risk
factors. Using advanced machine learning techniques, including Logistic
Regression and Random Forest, we achieved a remarkable testing accuracy of up
to 96.6\% with Random Forest. The proposed AI-driven system integrates these
models and datasets to provide real-time, accurate diagnostics and personalized
healthcare recommendations. By leveraging structured datasets and
state-of-the-art machine learning algorithms, this research offers an
innovative solution for scalable and effective heart disease detection, with
the potential to reduce mortality rates and improve clinical outcomes.

æè¦ï¼<paragraph>å¿èçæ¯å¨çéæ©æ­»äº¡çä¸»å ï¼ç¹å¥æ¯å¨ä¸­å¹´åèå¹´äººä¸­ï¼ç·æ§ç¼ççè¼é«ãæ ¹æä¸çè¡ççµç¹ (WHO) çæ¸æï¼åæ¬å¿èçå¨å§çéå³ææ§ç¾çå å¨çæ­»äº¡äººæ¸ç 25%ï¼1790 è¬ï¼ï¼å­å æåæ¯å¹´æè¶é 43,204 äººæ­»æ¼å¿èçãç¶èï¼ç±æ¼ç¼ºä¹åºæºæ¸æéåä¾è³´æåææ¸ææéçæ¹æ³ï¼éå°å­å æåäººå£éèº«æé çå¿èçæª¢æ¸¬ (HDD) ç³»çµ±çéç¼ä»æªå¾å°ååæ¢ç´¢ãæ¬ç ç©¶ééå¼å¥æ°çãç¬¦åéå¾·æ¨æºç HDD æ¸æéãBIG æ¸æéå CD æ¸æéä¾æå°éäºææ°ï¼å¶ä¸­åå«æéççãæª¢æ¥æè¡åé¢¨éªå ç´ çå¨é¢æ¸æãä½¿ç¨åé²çæ©å¨å­¸ç¿æè¡ï¼åæ¬éè¼¯è¿´æ­¸åé¨æ©æ£®æï¼æåä½¿ç¨é¨æ©æ£®æå¯¦ç¾äºé«é 96.6% çé¡¯èæ¸¬è©¦æºç¢ºåº¦ãææåºç AI é©åç³»çµ±æ´åäºéäºæ¨¡ååæ¸æéï¼ä»¥æä¾å¯¦æçæºç¢ºè¨ºæ·ååæ§åçé«çä¿å¥å»ºè­°ãééå©ç¨çµæ§åæ¸æéåæåé²çæ©å¨å­¸ç¿ç®æ³ï¼æ¬ç ç©¶çºå¯æ´å±ä¸ææçå¿èçæª¢æ¸¬æä¾äºä¸ååµæ°çè§£æ±ºæ¹æ¡ï¼å·æéä½æ­»äº¡çåæ¹åè¨åºçµæçæ½åã</paragraph>

##### **DAWN-SI: Data-Aware and Noise-Informed Stochastic Interpolation for Solving Inverse Problems**
2412.04766v1 by Shadab Ahamed, Eldad Haber

Inverse problems, which involve estimating parameters from incomplete or
noisy observations, arise in various fields such as medical imaging,
geophysics, and signal processing. These problems are often ill-posed,
requiring regularization techniques to stabilize the solution. In this work, we
employ $\textit{Stochastic Interpolation}$ (SI), a generative framework that
integrates both deterministic and stochastic processes to map a simple
reference distribution, such as a Gaussian, to the target distribution. Our
method $\textbf{DAWN-SI}$: $\textbf{D}$ata-$\textbf{AW}$are and
$\textbf{N}$oise-informed $\textbf{S}$tochastic $\textbf{I}$nterpolation
incorporates data and noise embedding, allowing the model to access
representations about the measured data explicitly and also account for noise
in the observations, making it particularly robust in scenarios where data is
noisy or incomplete. By learning a time-dependent velocity field, SI not only
provides accurate solutions but also enables uncertainty quantification by
generating multiple plausible outcomes. Unlike pre-trained diffusion models,
which may struggle in highly ill-posed settings, our approach is trained
specifically for each inverse problem and adapts to varying noise levels. We
validate the effectiveness and robustness of our method through extensive
numerical experiments on tasks such as image deblurring and tomography.

æè¦ï¼ååé¡æ¶åå¾ä¸å®æ´ææéè¨çè§æ¸¬ä¸­ä¼°è¨åæ¸ï¼åºç¾å¨åç¨®é åï¼ä¾å¦é«å­¸å½±åãå°çç©çåè¨èèçãéäºåé¡éå¸¸æ¯ä¸é©å®çï¼éè¦æ­£ååæè¡ä¾ç©©å®è§£ãå¨éé å·¥ä½ä¸­ï¼æåæ¡ç¨é¨æ©æå¼ (SI)ï¼ä¸ç¨®çæå¼æ¶æ§ï¼æ´åç¢ºå®æ§åé¨æ©éç¨ï¼å°ç°¡å®çåèåä½ï¼ä¾å¦é«æ¯åä½ï¼å°æå°ç®æ¨åä½ãæåç DAWS-SI æ¹æ³ï¼è³ææç¥åéè¨ç¥æçé¨æ©æå¼ï¼çµåè³æåéè¨åµå¥ï¼è®æ¨¡åè½å¤ æç¢ºå­åéæ¼æ¸¬éè³æçè¡¨ç¤ºï¼ä¸¦èéè§æ¸¬ä¸­çéè¨ï¼ä½¿å¶å¨è³ææéè¨æä¸å®æ´çææ³ä¸ç¹å¥ç©©å¥ãééå­¸ç¿èæéç¸éçéåº¦å ´ï¼SI ä¸åæä¾ç²¾ç¢ºçè§£ï¼éè½ééç¢çå¤ååçççµæä¾éåä¸ç¢ºå®æ§ãèé åè¨ç·´çæ´æ£æ¨¡åä¸åï¼å¾èå¨é«åº¦ä¸é©å®çè¨­å®ä¸­å¯è½æéå°å°é£ï¼æåçåæ³æ¯éå°æ¯åååé¡é²è¡è¨ç·´ï¼ä¸¦é©æä¸åçéè¨ç­ç´ãæåééå»£æ³çæ¸å¼å¯¦é©é©è­äºæåæ¹æ³çæææ§åç©©å¥æ§ï¼éäºä»»ååæ¬å½±åå»æ¨¡ç³åæ·å±¤ææã

##### **PCTreeS: 3D Point Cloud Tree Species Classification Using Airborne LiDAR Images**
2412.04714v1 by Hongjin Lin, Matthew Nazari, Derek Zheng

Reliable large-scale data on the state of forests is crucial for monitoring
ecosystem health, carbon stock, and the impact of climate change. Current
knowledge of tree species distribution relies heavily on manual data collection
in the field, which often takes years to complete, resulting in limited
datasets that cover only a small subset of the world's forests. Recent works
show that state-of-the-art deep learning models using Light Detection and
Ranging (LiDAR) images enable accurate and scalable classification of tree
species in various ecosystems. While LiDAR images contain rich 3D information,
most previous works flatten the 3D images into 2D projections to use
Convolutional Neural Networks (CNNs). This paper offers three significant
contributions: (1) we apply the deep learning framework for tree classification
in tropical savannas; (2) we use Airborne LiDAR images, which have a lower
resolution but greater scalability than Terrestrial LiDAR images used in most
previous works; (3) we introduce the approach of directly feeding 3D point
cloud images into a vision transformer model (PCTreeS). Our results show that
the PCTreeS approach outperforms current CNN baselines with 2D projections in
AUC (0.81), overall accuracy (0.72), and training time (~45 mins). This paper
also motivates further LiDAR image collection and validation for accurate
large-scale automatic classification of tree species.

æè¦ï¼å¯é çå¤§è¦æ¨¡æ£®æçæè³æå°æ¼ç£æ¸¬çæç³»çµ±å¥åº·ãç¢³å²éåæ°£åè®é·çå½±é¿è³ééè¦ãç®åå°æ¨¹ç¨®åå¸çäºè§£æ¥µåº¦ä¾è³´æ¼å¯¦å°æåæ¶éè³æï¼ééå¸¸éè¦è±è²»æ¸å¹´æè½å®æï¼å°è´åªè½æ¶µèå¨çå°æ¸æ£®æçæéè³æéãæè¿çç ç©¶é¡¯ç¤ºï¼ä½¿ç¨åæ¢æ¸¬åæ¸¬è· (LiDAR) å½±åçææ°æ·±åº¦å­¸ç¿æ¨¡åï¼å¯ä»¥å¨åç¨®çæç³»çµ±ä¸­å°æ¨¹ç¨®é²è¡æºç¢ºä¸å¯æ´åçåé¡ãåç®¡ LiDAR å½±ååå«è±å¯ç 3D è³è¨ï¼ä½å¤§å¤æ¸ååçç ç©¶æå° 3D å½±åå£ç¸®æ 2D æå½±ï¼ä»¥ä½¿ç¨å·ç©ç¥ç¶ç¶²è·¯ (CNN)ãæ¬ææä¾äºä¸é éè¦çè²¢ç»ï¼(1) æåå°æ·±åº¦å­¸ç¿æ¶æ§æç¨æ¼ç±å¸¶ç¨æ¨¹èåçæ¨¹ç¨®åé¡ï¼(2) æåä½¿ç¨æ©è¼ LiDAR å½±åï¼å¶è§£æåº¦è¼ä½ï¼ä½å¯æ´åæ§æ¯å¤§å¤æ¸ååç ç©¶ä¸­ä½¿ç¨çå°é¢ LiDAR å½±åæ´é«ï¼(3) æåå¼å¥äºç´æ¥å° 3D é»é²å½±åè¼¸å¥å°è¦è¦ºTransformeræ¨¡å (PCTreeS) çæ¹æ³ãæåççµæé¡¯ç¤ºï¼PCTreeS æ¹æ³å¨ AUC (0.81)ãæ´é«æºç¢ºåº¦ (0.72) åè¨ç·´æé (~45 åé) æ¹é¢åªæ¼ç¶åä½¿ç¨ 2D æå½±ç CNN åºæºãæ¬æä¹æ¿åµé²ä¸æ­¥æ¶éåé©è­ LiDAR å½±åï¼ä»¥é²è¡æºç¢ºçå¤§è¦æ¨¡æ¨¹ç¨®èªååé¡ã

##### **Semantic Consistency-Based Uncertainty Quantification for Factuality in Radiology Report Generation**
2412.04606v1 by Chenyu Wang, Weichao Zhou, Shantanu Ghosh, Kayhan Batmanghelich, Wenchao Li

Radiology report generation (RRG) has shown great potential in assisting
radiologists by automating the labor-intensive task of report writing. While
recent advancements have improved the quality and coherence of generated
reports, ensuring their factual correctness remains a critical challenge.
Although generative medical Vision Large Language Models (VLLMs) have been
proposed to address this issue, these models are prone to hallucinations and
can produce inaccurate diagnostic information. To address these concerns, we
introduce a novel Semantic Consistency-Based Uncertainty Quantification
framework that provides both report-level and sentence-level uncertainties.
Unlike existing approaches, our method does not require modifications to the
underlying model or access to its inner state, such as output token logits,
thus serving as a plug-and-play module that can be seamlessly integrated with
state-of-the-art models. Extensive experiments demonstrate the efficacy of our
method in detecting hallucinations and enhancing the factual accuracy of
automatically generated radiology reports. By abstaining from high-uncertainty
reports, our approach improves factuality scores by $10$%, achieved by
rejecting $20$% of reports using the Radialog model on the MIMIC-CXR dataset.
Furthermore, sentence-level uncertainty flags the lowest-precision sentence in
each report with an $82.9$% success rate.

æè¦ï¼æ¾å°ç§æ¥åçæ (RRG) å·²æ¾ç¤ºåºæå¤§çæ½åï¼å¯éè¿èªå¨æ§è¡æ¥åç¼åçå³å¨å¯éåä»»å¡æ¥åå©æ¾å°ç§å»çãè½ç¶æè¿çè¿æ­¥æé«äºçææ¥åçè´¨éåè¿è´¯æ§ï¼ä½ç¡®ä¿å¶äºå®æ­£ç¡®æ§ä»ç¶æ¯ä¸é¡¹éå¤§ææãå°½ç®¡å·²æåºçææ§å»å­¦è§è§å¤§è¯­è¨æ¨¡å (VLLM) æ¥è§£å³æ­¤é®é¢ï¼ä½è¿äºæ¨¡åå®¹æåºç°å¹»è§å¹¶å¯è½äº§çä¸åç¡®çè¯æ­ä¿¡æ¯ãä¸ºäºè§£å³è¿äºé®é¢ï¼æä»¬å¼å¥äºä¸ä¸ªæ°é¢çåºäºè¯­ä¹ä¸è´æ§çä¸ç¡®å®æ§éåæ¡æ¶ï¼è¯¥æ¡æ¶æä¾æ¥åçº§åå¥å­çº§çä¸ç¡®å®æ§ãä¸ç°ææ¹æ³ä¸åï¼æä»¬çæ¹æ³ä¸éè¦ä¿®æ¹åºå±æ¨¡åæè®¿é®å¶åé¨ç¶æï¼ä¾å¦è¾åºæ è®° logitï¼ï¼å æ­¤å¯ç¨ä½å³æå³ç¨æ¨¡åï¼å¯ä»¥ä¸æåè¿çæ¨¡åæ ç¼éæãå¹¿æ³çå®éªè¡¨æäºæä»¬çæ¹æ³å¨æ£æµå¹»è§åæé«èªå¨çæçæ¾å°ç§æ¥åçäºå®åç¡®æ§æ¹é¢çåæãéè¿é¿åé«åº¦ä¸ç¡®å®çæ¥åï¼æä»¬çæ¹æ³å°çå®æ§å¾åæé«äº 10%ï¼è¿æ¯éè¿ä½¿ç¨ MIMIC-CXR æ°æ®éä¸ç Radialog æ¨¡åæç» 20% çæ¥åå®ç°çãæ­¤å¤ï¼å¥å­çº§ä¸ç¡®å®æ§æ è®°äºæ¯ä»½æ¥åä¸­ç²¾åº¦æä½çå¥å­ï¼æåçä¸º 82.9%ã

##### **CLINICSUM: Utilizing Language Models for Generating Clinical Summaries from Patient-Doctor Conversations**
2412.04254v1 by Subash Neupane, Himanshu Tripathi, Shaswata Mitra, Sean Bozorgzad, Sudip Mittal, Shahram Rahimi, Amin Amirlatifi

This paper presents ClinicSum, a novel framework designed to automatically
generate clinical summaries from patient-doctor conversations. It utilizes a
two-module architecture: a retrieval-based filtering module that extracts
Subjective, Objective, Assessment, and Plan (SOAP) information from
conversation transcripts, and an inference module powered by fine-tuned
Pre-trained Language Models (PLMs), which leverage the extracted SOAP data to
generate abstracted clinical summaries. To fine-tune the PLM, we created a
training dataset of consisting 1,473 conversations-summaries pair by
consolidating two publicly available datasets, FigShare and MTS-Dialog, with
ground truth summaries validated by Subject Matter Experts (SMEs). ClinicSum's
effectiveness is evaluated through both automatic metrics (e.g., ROUGE,
BERTScore) and expert human assessments. Results show that ClinicSum
outperforms state-of-the-art PLMs, demonstrating superior precision, recall,
and F-1 scores in automatic evaluations and receiving high preference from SMEs
in human assessment, making it a robust solution for automated clinical
summarization.

æè¦ï¼æ¬æä»ç´¹ ClinicSumï¼éæ¯ä¸åæ°ç©çæ¶æ§ï¼æ¨å¨èªåå¾çæ£èé«å¸«çå°è©±ä¸­ç¢çè¨åºæè¦ãå®å©ç¨ä¸åéæ¨¡çµæ¶æ§ï¼ä¸ååºæ¼æª¢ç´¢çéæ¿¾æ¨¡çµï¼å¾å°è©±è½éä¸­èåä¸»è§ãå®¢è§ãè©ä¼°åè¨ç« (SOAP) è³è¨ï¼ä»¥åä¸åç±å¾®èª¿éä¹é åè¨ç·´èªè¨æ¨¡å (PLM) æä¾ååçæ¨è«æ¨¡çµï¼å®å©ç¨èåç SOAP è³æç¢çæè¦çè¨åºæè¦ãçºäºå¾®èª¿ PLMï¼æåå»ºç«äºä¸åè¨ç·´è³æéï¼å¶ä¸­åå« 1,473 çµå°è©±æè¦ï¼ééåä½µå©åå¬éå¯ç¨çè³æé FigShare å MTS-Dialogï¼ä»¥åç±ä¸»é¡å°å®¶ (SME) é©è­ççå¯¦æè¦ãClinicSum çæè½ééèªåè©éææ¨ (ä¾å¦ ROUGEãBERTScore) åå°å®¶äººé¡è©ä¼°é²è¡è©éãçµæé¡¯ç¤º ClinicSum åéç¾ææåé²ç PLMï¼å¨èªåè©éä¸­å±ç¾åºåªç°çç²¾ç¢ºåº¦ãå¬åçå F-1 åæ¸ï¼ä¸¦å¨äººé¡è©ä¼°ä¸­ç²å¾ SME çé«åº¦åå¥½ï¼ä½¿å¶æçºèªåè¨åºæè¦çå¼·å¥è§£æ±ºæ¹æ¡ã

##### **Automated Medical Report Generation for ECG Data: Bridging Medical Text and Signal Processing with Deep Learning**
2412.04067v1 by Amnon Bleich, Antje Linnemann, Bjoern H. Diem, Tim OF Conrad

Recent advances in deep learning and natural language generation have
significantly improved image captioning, enabling automated, human-like
descriptions for visual content. In this work, we apply these captioning
techniques to generate clinician-like interpretations of ECG data. This study
leverages existing ECG datasets accompanied by free-text reports authored by
healthcare professionals (HCPs) as training data. These reports, while often
inconsistent, provide a valuable foundation for automated learning. We
introduce an encoder-decoder-based method that uses these reports to train
models to generate detailed descriptions of ECG episodes. This represents a
significant advancement in ECG analysis automation, with potential applications
in zero-shot classification and automated clinical decision support.
  The model is tested on various datasets, including both 1- and 12-lead ECGs.
It significantly outperforms the state-of-the-art reference model by Qiu et
al., achieving a METEOR score of 55.53% compared to 24.51% achieved by the
reference model. Furthermore, several key design choices are discussed,
providing a comprehensive overview of current challenges and innovations in
this domain.
  The source codes for this research are publicly available in our Git
repository https://git.zib.de/ableich/ecg-comment-generation-public

æè¦ï¼æ·±åº¦å­¸ç¿åèªç¶èªè¨çææè¡çææ°é²å±é¡¯èæ¹åäºå½±åæ¨é¡ï¼è½çºè¦è¦ºå§å®¹æä¾èªååçäººé¡èªè¨æè¿°ãå¨éé å·¥ä½ä¸­ï¼æåå°éäºæ¨é¡æè¡æç¨æ¼ç¢çé¡ä¼¼è¨åºé«å¸«å°å¿é»åè³æçè©®éãéé ç ç©¶å©ç¨æ¢æçå¿é»åè³æéï¼ä¸¦éä¸ç±é«çä¿å¥å°æ¥­äººå¡ (HCP) æ°å¯«çèªç±æå­å ±åä½çºè¨ç·´è³æãéäºå ±åéç¶å¸¸å¸¸ä¸ä¸è´ï¼ä½çºèªååå­¸ç¿æä¾äºæå¹å¼çåºç¤ãæåå¼å¥äºä¸åç·¨ç¢¼å¨-è§£ç¢¼å¨æ¹æ³ï¼ä½¿ç¨éäºå ±åä¾è¨ç·´æ¨¡åï¼ä»¥ç¢çå¿é»åäºä»¶çè©³ç´°æè¿°ãéä»£è¡¨å¿é»ååæèªååçéå¤§é²å±ï¼å¨é¶æ¬¡å­¸ç¿åé¡åèªååè¨åºæ±ºç­æ¯æ´ä¸­å·ææ½å¨æç¨ãæ­¤æ¨¡åå¨åç¨®è³æéä¸é²è¡æ¸¬è©¦ï¼åæ¬ 1 å°ç¨å 12 å°ç¨å¿é»åãå®æé¡¯åªæ¼é±ç­äººçç¾ææä½³åèæ¨¡åï¼èåèæ¨¡åéæç 24.51% ç¸æ¯ï¼éå°äº 55.53% ç METEOR åæ¸ãæ­¤å¤ï¼è¨è«äºå¹¾åééµçè¨­è¨é¸æï¼æä¾äºå°éåé åä¸­ç¶åææ°ååµæ°çå¨é¢æ¦è¿°ãæ­¤ç ç©¶çåå§ç¨å¼ç¢¼å¨æåç Git å²å­åº« https://git.zib.de/ableich/ecg-comment-generation-public ä¸­å¬éã

##### **FedMetaMed: Federated Meta-Learning for Personalized Medication in Distributed Healthcare Systems**
2412.03851v1 by Jiechao Gao, Yuangang Li

Personalized medication aims to tailor healthcare to individual patient
characteristics. However, the heterogeneity of patient data across healthcare
systems presents significant challenges to achieving accurate and effective
personalized treatments. Ethical concerns further complicate the aggregation of
large volumes of data from diverse institutions. Federated Learning (FL) offers
a promising decentralized solution by enabling collaborative model training
through the exchange of client models rather than raw data, thus preserving
privacy. However, existing FL methods often suffer from retrogression during
server aggregation, leading to a decline in model performance in real-world
medical FL settings. To address data variability in distributed healthcare
systems, we introduce Federated Meta-Learning for Personalized Medication
(FedMetaMed), which combines federated learning and meta-learning to create
models that adapt to diverse patient data across healthcare systems. The
FedMetaMed framework aims to produce superior personalized models for
individual clients by addressing these limitations. Specifically, we introduce
Cumulative Fourier Aggregation (CFA) at the server to improve stability and
effectiveness in global knowledge aggregation. CFA achieves this by gradually
integrating client models from low to high frequencies. At the client level, we
implement a Collaborative Transfer Optimization (CTO) strategy with a
three-step process - Retrieve, Reciprocate, and Refine - to enhance the
personalized local model through seamless global knowledge transfer.
Experiments on real-world medical imaging datasets demonstrate that FedMetaMed
outperforms state-of-the-art FL methods, showing superior generalization even
on out-of-distribution cohorts.

æè¦ï¼åäººåé«çæ¨å¨éå°åå¥æ£èç¹å¾µèª¿æ´é«çä¿å¥ãç¶èï¼é«çç³»çµ±ä¸­æ£èè³æçç°è³ªæ§å°éææºç¢ºä¸ææçåäººåæ²»çå¸¶ä¾éå¤§ææ°ãå«çåé¡é²ä¸æ­¥ä½¿ä¾èªä¸åæ©æ§çå¤§éè³æçå½ç¸½è¤éåãè¯é¦å­¸ç¿ (FL) æä¾äºä¸ç¨®æåæ¯çåæ£å¼è§£æ±ºæ¹æ¡ï¼ééäº¤æå®¢æ¶æ¨¡åèéåå§è³æä¾å¯¦ç¾åä½æ¨¡åè¨ç·´ï¼å¾èä¿è­·é±ç§ãç¶èï¼ç¾æç FL æ¹æ³å¨ä¼ºæå¨å½ç¸½æéç¶å¸¸é­åéåï¼å°è´å¯¦éé«ç FL è¨­å®ä¸­çæ¨¡åæè½ä¸éãçºäºè§£æ±ºåæ£å¼é«çç³»çµ±ä¸­çè³æè®ç°æ§ï¼æåå¼å¥äºåäººåè¥ç©è¯é¦åå­¸ç¿ (FedMetaMed)ï¼å®çµåäºè¯é¦å­¸ç¿ååå­¸ç¿ä¾å»ºç«æ¨¡åï¼ä»¥é©æé«çç³»çµ±ä¸­ä¸åçæ£èè³æãFedMetaMed æ¡æ¶æ¨å¨ééè§£æ±ºéäºéå¶ï¼çºåå¥å®¢æ¶ç¢çåªè¶çåäººåæ¨¡åãå·é«ä¾èªªï¼æåå¨ä¼ºæå¨ç«¯å¼å¥äºç´¯ç©åç«èå½ç¸½ (CFA)ï¼ä»¥æ¹åå¨çç¥è­å½ç¸½çç©©å®æ§åæææ§ãCFA éééæ­¥æ´åå¾ä½é »çå°é«é »ççå®¢æ¶æ¨¡åä¾å¯¦ç¾éä¸é»ãå¨å®¢æ¶ç«¯å±¤ç´ï¼æåå¯¦æ½äºä¸ç¨®åä½å³è¼¸æä½³å (CTO) ç­ç¥ï¼æ¡ç¨ä¸æ­¥é©æµç¨ - æ·åãåé¥åç²¾ç - ééç¡ç¸«çå¨çç¥è­å³è¼¸ä¾å¢å¼·åäººåæ¬å°æ¨¡åãå¨å¯¦éé«çå½±åè³æéä¸çå¯¦é©è¡¨æï¼FedMetaMed åªæ¼æåé²ç FL æ¹æ³ï¼å³ä½¿å¨éåä½ç¾¤çµä¸­ä¹å±ç¾åºåªè¶çæ³åæ§ã

##### **ELEMENT: Episodic and Lifelong Exploration via Maximum Entropy**
2412.03800v1 by Hongming Li, Shujian Yu, Bin Liu, Jose C. Principe

This paper proposes \emph{Episodic and Lifelong Exploration via Maximum
ENTropy} (ELEMENT), a novel, multiscale, intrinsically motivated reinforcement
learning (RL) framework that is able to explore environments without using any
extrinsic reward and transfer effectively the learned skills to downstream
tasks. We advance the state of the art in three ways. First, we propose a
multiscale entropy optimization to take care of the fact that previous maximum
state entropy, for lifelong exploration with millions of state observations,
suffers from vanishing rewards and becomes very expensive computationally
across iterations. Therefore, we add an episodic maximum entropy over each
episode to speedup the search further. Second, we propose a novel intrinsic
reward for episodic entropy maximization named \emph{average episodic state
entropy} which provides the optimal solution for a theoretical upper bound of
the episodic state entropy objective. Third, to speed the lifelong entropy
maximization, we propose a $k$ nearest neighbors ($k$NN) graph to organize the
estimation of the entropy and updating processes that reduces the computation
substantially. Our ELEMENT significantly outperforms state-of-the-art intrinsic
rewards in both episodic and lifelong setups. Moreover, it can be exploited in
task-agnostic pre-training, collecting data for offline reinforcement learning,
etc.

æè¦ï¼æ¬ææåºäºä¸ç§æ°é¢çå¤å°ºåº¦ãåå¨å¨æºå¼ºåå­¦ä¹  (RL) æ¡æ¶ï¼åä¸ºâéè¿æå¤§çµè¿è¡ææ¯åç»èº«æ¢ç´¢â(ELEMENT)ï¼è¯¥æ¡æ¶è½å¤å¨ä¸ä½¿ç¨ä»»ä½å¤å¨å¥å±çæåµä¸æ¢ç´¢ç¯å¢ï¼å¹¶ææå°å°æå­¦æè½è½¬ç§»å°ä¸æ¸¸ä»»å¡ä¸­ãæä»¬å¨ä¸ä¸ªæ¹é¢æåäºææ¯æ°´å¹³ãé¦åï¼æä»¬æåºäºå¤å°ºåº¦çµä¼åï¼ä»¥è§£å³ä»¥ä¸äºå®ï¼ååçæå¤§ç¶æçµå¨è¿è¡æ°ç¾ä¸æ¬¡ç¶æè§å¯çç»èº«æ¢ç´¢æ¶ï¼ä¼é­åå¥å±æ¶å¤±çå½±åï¼å¹¶ä¸å¨æ¯æ¬¡è¿­ä»£ä¸­é½ä¼åå¾éå¸¸æè´µãå æ­¤ï¼æä»¬å¨æ¯ä¸ªææ¯ä¸­æ·»å äºä¸ä¸ªææ¯æå¤§çµï¼ä»¥è¿ä¸æ­¥å å¿«æç´¢éåº¦ãå¶æ¬¡ï¼æä»¬æåºäºä¸ç§æ°çåå¨å¥å±ï¼ç¨äºææ¯çµæå¤§åï¼åä¸ºâå¹³åææ¯ç¶æçµâï¼å®ä¸ºææ¯ç¶æçµç®æ ççè®ºä¸éæä¾äºæä¼è§£ãç¬¬ä¸ï¼ä¸ºäºå å¿«ç»èº«çµæå¤§åï¼æä»¬æåºäºä¸ä¸ª $k$ è¿é» ($k$NN) å¾ï¼ç¨äºç»ç»çµçä¼°è®¡åæ´æ°è¿ç¨ï¼ä»èå¤§å¹åå°äºè®¡ç®ãæä»¬ç ELEMENT å¨ææ¯åç»èº«è®¾ç½®ä¸­é½ææ¾ä¼äºæåè¿çåå¨å¥å±ãæ­¤å¤ï¼å®è¿å¯ä»¥ç¨äºä¸ä»»å¡æ å³çé¢è®­ç»ãæ¶éç¦»çº¿å¼ºåå­¦ä¹ æ°æ®ç­ã

##### **Automated Multi-Label Annotation for Mental Health Illnesses Using Large Language Models**
2412.03796v1 by Abdelrahaman A. Hassan, Radwa J. Hanafy, Mohammed E. Fouda

The growing prevalence and complexity of mental health disorders present
significant challenges for accurate diagnosis and treatment, particularly in
understanding the interplay between co-occurring conditions. Mental health
disorders, such as depression and Anxiety, often co-occur, yet current datasets
derived from social media posts typically focus on single-disorder labels,
limiting their utility in comprehensive diagnostic analyses. This paper
addresses this critical gap by proposing a novel methodology for cleaning,
sampling, labeling, and combining data to create versatile multi-label
datasets. Our approach introduces a synthetic labeling technique to transform
single-label datasets into multi-label annotations, capturing the complexity of
overlapping mental health conditions. To achieve this, two single-label
datasets are first merged into a foundational multi-label dataset, enabling
realistic analyses of co-occurring diagnoses. We then design and evaluate
various prompting strategies for large language models (LLMs), ranging from
single-label predictions to unrestricted prompts capable of detecting any
present disorders. After rigorously assessing multiple LLMs and prompt
configurations, the optimal combinations are identified and applied to label
six additional single-disorder datasets from RMHD. The result is SPAADE-DR, a
robust, multi-label dataset encompassing diverse mental health conditions. This
research demonstrates the transformative potential of LLM-driven synthetic
labeling in advancing mental health diagnostics from social media data, paving
the way for more nuanced, data-driven insights into mental health care.

æè¦ï¼é¨èå¿çå¥åº·éç¤ççè¡çåè¤éæ§æ¥çå¢å ï¼å°æ¼æºç¢ºè¨ºæ·åæ²»çæåºäºå´å³»çææ°ï¼ç¹å¥æ¯å¨äºè§£å±å­ç¾çä¹éçç¸äºä½ç¨æãå¿çå¥åº·éç¤ï¼ä¾å¦æé¬±çåç¦æ®çï¼ç¶å¸¸å±å­ï¼ä½ç®åå¾ç¤¾ç¾¤åªé«è²¼æä¸­è¡ççè³æééå¸¸åªéæ³¨å®ä¸éç¤æ¨ç±¤ï¼éå¶äºå®åå¨å¨é¢è¨ºæ·åæä¸­çæç¨ãæ¬æééæåºä¸ååµæ°çæ¹æ³ä¾æ¸çãæ½æ¨£ãæ¨ç±¤åçµåè³æï¼ä»¥å»ºç«å¤åè½çå¤æ¨ç±¤è³æéï¼ä¾è§£æ±ºéåééµçå·®è·ãæåçåæ³å¼é²äºä¸ç¨®åææ¨ç±¤æè¡ï¼å°å®æ¨ç±¤è³æéè½æçºå¤æ¨ç±¤è¨»è§£ï¼ææéçå¿çå¥åº·çæ³çè¤éæ§ãçºäºéæéåç®æ¨ï¼é¦åå°å©åå®æ¨ç±¤è³æéåä½µæä¸ååºç¤å¤æ¨ç±¤è³æéï¼ä»¥é²è¡å±å­è¨ºæ·çå¯¦éåæãç¶å¾ï¼æåè¨­è¨ä¸¦è©ä¼°å¤§åèªè¨æ¨¡å (LLM) çåç¨®æç¤ºç­ç¥ï¼å¾å®æ¨ç±¤é æ¸¬å°è½å¤ åµæ¸¬ä»»ä½ç¾æéç¤çç¡éå¶æç¤ºãå¨å´æ ¼è©ä¼°å¤å LLM åæç¤ºéç½®å¾ï¼æ¾åºæä½³çµåä¸¦æç¨æ¼æ¨ç±¤ä¾èª RMHD çå­åå¶ä»å®ä¸éç¤è³æéãçµææ¯ SPAADE-DRï¼ä¸ååå«åç¨®å¿çå¥åº·çæ³çå¼·å¥å¤æ¨ç±¤è³æéãéé ç ç©¶å±ç¤ºäº LLM é©åçåææ¨ç±¤å¨æ¨é²å¾ç¤¾ç¾¤åªé«è³æé²è¡å¿çå¥åº·è¨ºæ·çè½åæ½åï¼çºæ´ç´°ç·»ãè³æé©åçå¿çä¿å¥è¦è§£éªè·¯ã

##### **Speech Recognition-based Feature Extraction for Enhanced Automatic Severity Classification in Dysarthric Speech**
2412.03784v1 by Yerin Choi, Jeehyun Lee, Myoung-Wan Koo

Due to the subjective nature of current clinical evaluation, the need for
automatic severity evaluation in dysarthric speech has emerged. DNN models
outperform ML models but lack user-friendly explainability. ML models offer
explainable results at a feature level, but their performance is comparatively
lower. Current ML models extract various features from raw waveforms to predict
severity. However, existing methods do not encompass all dysarthric features
used in clinical evaluation. To address this gap, we propose a feature
extraction method that minimizes information loss. We introduce an ASR
transcription as a novel feature extraction source. We finetune the ASR model
for dysarthric speech, then use this model to transcribe dysarthric speech and
extract word segment boundary information. It enables capturing finer
pronunciation and broader prosodic features. These features demonstrated an
improved severity prediction performance to existing features: balanced
accuracy of 83.72%.

æè¦ï¼ç±æ¼ç¶åè¨åºè©ä¼°çä¸»è§æ§ï¼å æ­¤åºç¾äºå°æ§é³éç¤è¨èªä¸­èªåå´éç¨åº¦è©ä¼°çéæ±ãDNN æ¨¡ååªæ¼ ML æ¨¡åï¼ä½ç¼ºä¹ä½¿ç¨èååçå¯è§£éæ§ãML æ¨¡åå¨ç¹å¾µå±¤ç´æä¾å¯è§£éççµæï¼ä½å¶æè½ç¸å°è¼ä½ãç¶åç ML æ¨¡åå¾åå§æ³¢å½¢ä¸­æ·ååç¨®ç¹å¾µä»¥é æ¸¬å´éç¨åº¦ãç¶èï¼ç¾ææ¹æ³ä¸¦æªæ¶µèè¨åºè©ä¼°ä¸­ä½¿ç¨çæææ§é³éç¤ç¹å¾µãçºäºè§£æ±ºéåå·®è·ï¼æåæåºäºä¸ç¨®å¯å°è³è¨æå¤±éè³æä½çç¹å¾µæ·åæ¹æ³ãæåå¼å¥äº ASR è½éä½çºä¸ç¨®æ°ç©çç¹å¾µæ·åä¾æºãæåçºæ§é³éç¤è¨èªå¾®èª¿ ASR æ¨¡åï¼ç¶å¾ä½¿ç¨æ­¤æ¨¡åè½éæ§é³éç¤è¨èªä¸¦æ·åå­ååæ®µéçè³è¨ãå®å¯ä»¥æ·åæ´ç²¾ç´°çç¼é³åæ´å»£æ³çé»å¾ç¹å¾µãéäºç¹å¾µé¡¯ç¤ºåºæ¯ç¾æç¹å¾µæ´å¥½çå´éç¨åº¦é æ¸¬æè½ï¼å¹³è¡¡æºç¢ºåº¦çº 83.72%ã

##### **Exploring the Role of AI-Powered Chatbots for Teens and Young Adults with ASD or Social Anxiety**
2412.03740v1 by Dilan Mian

The world can be a complex and difficult place to navigate. People with
High-Functioning Autistic Spectrum Disorder as well as general social
ineptitude often face navigation challenges that individuals of other
demographics simply do not themselves. This can become even more pronounced
with people of that specific group when they are in their teenage years and
early adulthood (that being the usual age range of college students). When they
are at such a vulnerable age, they can be far more susceptible to the struggles
of becoming comfortable and content with social interactions as well as having
strong relationships (outside their immediate family). Concerning this, the
rapid emergence of artificial intelligence chatbots has led to many of them
being used to benefit people of different ages and demographics with easy
accessibility. With this, if there is anything that people with
High-Functioning ASD and social ineptitude want when it comes to guidance
towards self-improvement, surely easy accessibility would be one. What are the
potential benefits and limitations of using a Mindstudio AI-powered chatbot to
provide mental health support for teens and young adults with the
aforementioned conditions? What could be done with a tool like this to help
those individuals navigate ethical dilemmas within different social
environments to reduce existing social tensions? This paper addresses these
queries and offers insights to inform future discussions on the subject.

æè¦ï¼ä¸çå¯è½æ¯ä¸åè¤éä¸é£ä»¥æä»çå°æ¹ãé«åè½èªéçè­ç³»éç¤ä»¥åä¸è¬ç¤¾äº¤ç¡è½çäººï¼ç¶å¸¸æé¢å°å¶ä»äººå£çµ±è¨è³æä¸­çäººæ ¹æ¬ä¸æéå°çæå°ææ°ãç¶ä»åèæ¼éå°å¹´ææåæå¹´åæï¼éå¸¸æ¯å¤§å­¸ççå¹´é½¡ç¯åï¼æï¼éç¨®ææ³å¯è½æè®å¾æ´å æé¡¯ãç¶ä»åèæ¼å¦æ­¤èå¼±çå¹´é½¡æï¼ä»åæ´å®¹æåå°ç¤¾äº¤äºåæå°èªå¨åæ»¿è¶³çææï¼ä»¥åææç¢åºéä¿ï¼å¨ä»åçç´ç³»è¦ªå±¬ä¹å¤ï¼çå½±é¿ãéæ¼éä¸é»ï¼äººå·¥æºæ§èå¤©æ©å¨äººçå¿«éåºç¾ï¼å°è´è¨±å¤äººè¢«ç¨æ¼é ç¦ä¸åå¹´é½¡åäººå£çµ±è¨è³æçäººï¼ä¸¦å·æææ¼å­åæ§ãæäºéåï¼å¦ææ£æé«åè½èªéçåç¤¾äº¤ç¡è½çäººå¨èªææåçæå°æ¹é¢æä»»ä½æ³è¦çæ±è¥¿ï¼é£éº¼ææ¼å­åè¯å®ææ¯ä¸åãä½¿ç¨ç± Mindstudio AI æä¾æè¡æ¯æ´çèå¤©æ©å¨äººï¼çºæ£æä¸è¿°ææ³çéå°å¹´åå¹´è¼äººæä¾å¿çå¥åº·æ¯æ´ï¼æåªäºæ½å¨çå¥½èåéå¶ï¼å¯ä»¥ä½¿ç¨éæ¨£çå·¥å·ä¾å¹«å©é£äºäººæå°ä¸åç¤¾æç°å¢ä¸­çéå¾·å°å¢ï¼ä»¥æ¸å°ç¾æçç¤¾æç·å¼µå±å¢ï¼å¯ä»¥åäºä»éº¼ï¼æ¬ææ¢è¨éäºåé¡ï¼ä¸¦æä¾è¦è§£ï¼çºæªä¾éæ¼æ­¤ä¸»é¡çè¨è«æä¾è³è¨ã

##### **MRGen: Diffusion-based Controllable Data Engine for MRI Segmentation towards Unannotated Modalities**
2412.04106v1 by Haoning Wu, Ziheng Zhao, Ya Zhang, Weidi Xie, Yanfeng Wang

Medical image segmentation has recently demonstrated impressive progress with
deep neural networks, yet the heterogeneous modalities and scarcity of mask
annotations limit the development of segmentation models on unannotated
modalities. This paper investigates a new paradigm for leveraging generative
models in medical applications: controllably synthesizing data for unannotated
modalities, without requiring registered data pairs. Specifically, we make the
following contributions in this paper: (i) we collect and curate a large-scale
radiology image-text dataset, MedGen-1M, comprising modality labels,
attributes, region, and organ information, along with a subset of organ mask
annotations, to support research in controllable medical image generation; (ii)
we propose a diffusion-based data engine, termed MRGen, which enables
generation conditioned on text prompts and masks, synthesizing MR images for
diverse modalities lacking mask annotations, to train segmentation models on
unannotated modalities; (iii) we conduct extensive experiments across various
modalities, illustrating that our data engine can effectively synthesize
training samples and extend MRI segmentation towards unannotated modalities.

æè¦ï¼é«å­¸å½±ååå²æè¿å·²ééæ·±åº¦ç¥ç¶ç¶²è·¯å±ç¾é©äººçé²å±ï¼ä½ç°è³ªæ¨¡æåæ¨ç±¤ç¨å°éå¶äºå¨æªæ¨è¨»æ¨¡æä¸éç¼åå²æ¨¡åãæ¬ææ¢è¨äºä¸åæ°å¸ç¯ï¼ä»¥å©ç¨çææ¨¡åå¨é«å­¸æç¨ä¸­ï¼å¯æ§å°åææªæ¨è¨»æ¨¡æçè³æï¼èç¡éè¨»åè³æå°ãå·é«ä¾èªªï¼æåå¨æ¬æä¸­ååºä»¥ä¸è²¢ç»ï¼(i) æåæ¶éä¸¦ç­åäºä¸åå¤§è¦æ¨¡çæ¾å°å½±åæå­è³æé MedGen-1Mï¼åå«æ¨¡ææ¨ç±¤ãå±¬æ§ãåååå¨å®è³è¨ï¼ä»¥åä¸é¨åå¨å®æ¨ç±¤ï¼ä»¥æ¯æ´å¯æ§é«å­¸å½±åçæçç¸éç ç©¶ï¼(ii) æåæåºäºä¸ååºæ¼æ´æ£çè³æå¼æï¼ç¨±çº MRGenï¼å®è½å¤ æ ¹ææå­æç¤ºåæ¨ç±¤çææ¢ä»¶ï¼åæç¼ºä¹æ¨ç±¤è¨»è§£çä¸åæ¨¡æç MR å½±åï¼ä»¥è¨ç·´æªæ¨è¨»æ¨¡æçåå²æ¨¡åï¼(iii) æåå¨åç¨®æ¨¡æä¸­é²è¡äºå»£æ³çå¯¦é©ï¼èªªææåçè³æå¼æå¯ä»¥ææå°åæè¨ç·´æ¨£æ¬ï¼ä¸¦å° MRI åå²å»¶ä¼¸è³æªæ¨è¨»çæ¨¡æã

##### **Intuitive Axial Augmentation Using Polar-Sine-Based Piecewise Distortion for Medical Slice-Wise Segmentation**
2412.03352v1 by Yiqin Zhang, Qingkui Chen, Chen Huang, Zhengjie Zhang, Meiling Chen, Zhibing Fu

Most data-driven models for medical image analysis rely on universal
augmentations to improve performance. Experimental evidence has confirmed their
effectiveness, but the unclear mechanism underlying them poses a barrier to the
widespread acceptance and trust in such methods within the medical community.
We revisit and acknowledge the unique characteristics of medical images apart
from traditional digital images, and consequently, proposed a medical-specific
augmentation algorithm that is more elastic and aligns well with radiology scan
procedure. The method performs piecewise affine with sinusoidal distorted ray
according to radius on polar coordinates, thus simulating uncertain postures of
human lying flat on the scanning table. Our method could generate human
visceral distribution without affecting the fundamental relative position on
axial plane. Two non-adaptive algorithms, namely Meta-based Scan Table Removal
and Similarity-Guided Parameter Search, are introduced to bolster robustness of
our augmentation method. Experiments show our method improves accuracy across
multiple famous segmentation frameworks without requiring more data samples.
Our preview code is available in: https://github.com/MGAMZ/PSBPD.

æè¦ï¼å¤§å¤æ¸ç¨æ¼é«å­¸å½±ååæçè³æé©åæ¨¡åä»°è³´éç¨æ´ååè½ä¾æåæè½ãå¯¦é©è­æå·²è­å¯¦å¶æææ§ï¼ä½å¶èå¾ä¸æç¢ºçæ©å¶å°é«å­¸çå»£æ³æ¥ååä¿¡ä»»æ­¤é¡æ¹æ³æ§æé»ç¤ãæåéæ°æª¢è¦ä¸¦æ¿èªé«å­¸å½±åèå³çµ±æ¸ä½å½±åçç¨ç¹ç¹æ§ï¼å æ­¤æåºæ´å·å½æ§ä¸èæ¾å°ç·ææç¨åºå¯åéåçé«å­¸ç¹å®æ´åæ¼ç®æ³ãè©²æ¹æ³æ ¹ææ¥µåº§æ¨ä¸çåå¾å·è¡æ­£å¼¦æ­æ²å°ç·çéæ®µä»¿å°ï¼å¾èæ¨¡æ¬äººå¹³èººå¨ææå°ä¸æçä¸ç¢ºå®å§¿å¢ãæåçæ¹æ³å¯ä»¥å¨ä¸å½±é¿è»¸åå¹³é¢ä¸åºæ¬ç¸å°ä½ç½®çææ³ä¸çæäººé«å§èåä½ãå¼å¥äºå©ç¨®éèªé©ææ¼ç®æ³ï¼å³åºæ¼ Meta çææå°ç§»é¤åç¸ä¼¼æ§å°å¼åæ¸æå°ï¼ä»¥å å¼·æåæ´åæ¹æ³çç©©å¥æ§ãå¯¦é©è¡¨æï¼æåçæ¼ç®æ³å¨ä¸éè¦æ´å¤è³ææ¨£æ¬çææ³ä¸ï¼å°±è½æåå¤åèååå²æ¶æ§çæºç¢ºæ§ãæåçé è¦½ç¨å¼ç¢¼å¯å¨ https://github.com/MGAMZ/PSBPD ä¸­åå¾ã

##### **Detecting abnormal heart sound using mobile phones and on-device IConNet**
2412.03267v1 by Linh Vu, Thu Tran

Given the global prevalence of cardiovascular diseases, there is a pressing
need for easily accessible early screening methods. Typically, this requires
medical practitioners to investigate heart auscultations for irregular sounds,
followed by echocardiography and electrocardiography tests. To democratize
early diagnosis, we present a user-friendly solution for abnormal heart sound
detection, utilizing mobile phones and a lightweight neural network optimized
for on-device inference. Unlike previous approaches reliant on specialized
stethoscopes, our method directly analyzes audio recordings, facilitated by a
novel architecture known as IConNet. IConNet, an Interpretable Convolutional
Neural Network, harnesses insights from audio signal processing, enhancing
efficiency and providing transparency in neural pattern extraction from raw
waveform signals. This is a significant step towards trustworthy AI in
healthcare, aiding in remote health monitoring efforts.

æè¦ï¼é´äºå¿è¡ç®¡ç¾çå¨å¨ççæ®éæ§ï¼è¿«åéè¦å®¹æè·åçæ©æç­æ¥æ¹æ³ãéå¸¸ï¼è¿éè¦å»çä»ä¸äººåæ£æ¥å¿èå¬è¯æ¯å¦æä¸è§åçå£°é³ï¼ç¶åè¿è¡è¶å£°å¿å¨å¾åå¿çµå¾æ£æ¥ãä¸ºäºä½¿æ©æè¯æ­æ°ä¸»åï¼æä»¬æåºäºä¸ç§ç¨æ·åå¥½çè§£å³æ¹æ¡ï¼ç¨äºæ£æµå¼å¸¸å¿èå£°é³ï¼å©ç¨ç§»å¨çµè¯åä¸ä¸ªè½»éçº§ç¥ç»ç½ç»ï¼è¯¥ç¥ç»ç½ç»éå¯¹è®¾å¤åæ¨çè¿è¡äºä¼åãä¸ä»¥åä¾èµäºä¸ç¨å¬è¯å¨çåæ³ä¸åï¼æä»¬çæ¹æ³ç´æ¥åæé³é¢è®°å½ï¼è¿å¾çäºä¸ç§ç§°ä¸º IConNet çæ°é¢æ¶æãIConNet æ¯ä¸ç§å¯è§£éçå·ç§¯ç¥ç»ç½ç»ï¼å©ç¨é³é¢ä¿¡å·å¤ççè§è§£ï¼æé«æçï¼å¹¶æä¾ä»åå§æ³¢å½¢ä¿¡å·ä¸­æåç¥ç»æ¨¡å¼çéææ§ãè¿æ¯æåå»çä¿å¥ä¸­å¯ä¿¡èµçäººå·¥æºè½è¿åºçéè¦ä¸æ­¥ï¼æå©äºè¿ç¨å¥åº·çæµå·¥ä½ã

##### **MRNet: Multifaceted Resilient Networks for Medical Image-to-Image Translation**
2412.03039v1 by Hyojeong Lee, Youngwan Jo, Inpyo Hong, Sanghyun Park

We propose a Multifaceted Resilient Network(MRNet), a novel architecture
developed for medical image-to-image translation that outperforms
state-of-the-art methods in MRI-to-CT and MRI-to-MRI conversion. MRNet
leverages the Segment Anything Model (SAM) to exploit frequency-based features
to build a powerful method for advanced medical image transformation. The
architecture extracts comprehensive multiscale features from diverse datasets
using a powerful SAM image encoder and performs resolution-aware feature fusion
that consistently integrates U-Net encoder outputs with SAM-derived features.
This fusion optimizes the traditional U-Net skip connection while leveraging
transformer-based contextual analysis. The translation is complemented by an
innovative dual-mask configuration incorporating dynamic attention patterns and
a specialized loss function designed to address regional mapping mismatches,
preserving both the gross anatomy and tissue details. Extensive validation
studies have shown that MRNet outperforms state-of-the-art architectures,
particularly in maintaining anatomical fidelity and minimizing translation
artifacts.

æè¦ï¼æåæåºä¸åå¤æ¹é¢çå½æ§ç¶²è·¯ (MRNet)ï¼éæ¯ä¸ååµæ°çæ¶æ§ï¼
éç¼ç¨æ¼é«å­¸å½±åè½å½±åçç¿»è­¯ï¼å¶åªæ¼ MRI è½ CT å MRI è½ MRI è½æçææ°æ¹æ³ãMRNet
å©ç¨ Segment Anything Model (SAM) ä¾å©ç¨åºæ¼é »ççç¹å¾µï¼ä»¥å»ºç«ä¸ç¨®å¼·å¤§çæ¹æ³ï¼ç¨æ¼åé²çé«å­¸å½±åè½æãæ­¤
æ¶æ§ä½¿ç¨å¼·å¤§ç SAM å½±åç·¨ç¢¼å¨å¾ä¸åçè³æéæåå¨é¢çå¤å°ºåº¦ç¹å¾µï¼ä¸¦å·è¡è§£æåº¦æç¥ç¹å¾µèåï¼æçºå° U-Net ç·¨ç¢¼å¨è¼¸åºè SAM è¡ççç¹å¾µæ´åå¨ä¸èµ·ã
æ­¤èåæä½³åå³çµ±ç U-Net è·³èºé£æ¥ï¼åæå©ç¨åºæ¼Transformerçä¸ä¸æåæãç¿»è­¯ç±ä¸ååµæ°çéé®ç½©éç½®è£åï¼å®çµåäºåææ³¨ææ¨¡å¼åä¸åå°éçæå¤±å½æ¸ï¼æ¨å¨è§£æ±ºååå°æä¸å¹éçåé¡ï¼åæä¿çäºæ´é«è§£åçµæ§åçµç¹ç´°ç¯ãå»£æ³çé©è­ç ç©¶é¡¯ç¤ºï¼MRNet åªæ¼æåé²çæ¶æ§ï¼ç¹å¥æ¯å¨ç¶­æè§£åä¿çåº¦åæå°åè½æå½å½±æ¹é¢ã

##### **Higher Order Transformers: Efficient Attention Mechanism for Tensor Structured Data**
2412.02919v1 by Soroush Omranpour, Guillaume Rabusseau, Reihaneh Rabbany

Transformers are now ubiquitous for sequence modeling tasks, but their
extension to multi-dimensional data remains a challenge due to the quadratic
cost of the attention mechanism. In this paper, we propose Higher-Order
Transformers (HOT), a novel architecture designed to efficiently process data
with more than two axes, i.e. higher-order tensors. To address the
computational challenges associated with high-order tensor attention, we
introduce a novel Kronecker factorized attention mechanism that reduces the
attention cost to quadratic in each axis' dimension, rather than quadratic in
the total size of the input tensor. To further enhance efficiency, HOT
leverages kernelized attention, reducing the complexity to linear. This
strategy maintains the model's expressiveness while enabling scalable attention
computation. We validate the effectiveness of HOT on two high-dimensional
tasks, including multivariate time series forecasting, and 3D medical image
classification. Experimental results demonstrate that HOT achieves competitive
performance while significantly improving computational efficiency, showcasing
its potential for tackling a wide range of complex, multi-dimensional data.

æè¦ï¼è®å½¢éåç¾å¨æ®éç¨æ¼åºåå»ºæ¨¡ä»»åï¼ä½ç±æ¼æ³¨æåæ©å¶çäºæ¬¡æ¹ææ¬ï¼å®åæ´å±å°å¤ç¶­æ¸æä»ç¶æ¯ä¸åææ°ãå¨æ¬æä¸­ï¼æåæåºäºé«éè®å½¢éå (HOT)ï¼éæ¯ä¸ç¨®æ°ç©çæ¶æ§ï¼æ¨å¨ææèçå·æå©åä»¥ä¸è»¸ç·çæ¸æï¼å³é«éå¼µéãçºäºæå°èé«éå¼µéæ³¨æåç¸éçè¨ç®ææ°ï¼æåå¼å¥äºä¸ç¨®æ°ç©çåç¾å§ååè§£æ³¨æåæ©å¶ï¼è©²æ©å¶å°æ³¨æåææ¬éä½å°æ¯åè»¸ç·ç¶­åº¦çäºæ¬¡æ¹ï¼èä¸æ¯è¼¸å¥å¼µéçç¸½å¤§å°çäºæ¬¡æ¹ãçºäºé²ä¸æ­¥æé«æçï¼HOT å©ç¨æ ¸åæ³¨æåï¼å°è¤éåº¦éä½å°ç·æ§ãæ­¤ç­ç¥ä¿æäºæ¨¡åçè¡¨ç¾åï¼åæå¯¦ç¾äºå¯æ´å±çæ³¨æåè¨ç®ãæåå¨å©åé«ç¶­ä»»åä¸é©è­äº HOT çæææ§ï¼åæ¬å¤åæéåºåé æ¸¬å 3D é«å­¸å½±ååé¡ãå¯¦é©çµæè¡¨æï¼HOT å¨é¡¯èæé«è¨ç®æççåæå¯¦ç¾äºç«¶ç­åçæè½ï¼å±ç¤ºäºå¶æå°åç¨®è¤éçå¤ç¶­æ¸æçæ½åã

##### **A Novel Compact LLM Framework for Local, High-Privacy EHR Data Applications**
2412.02868v1 by Yixiang Qu, Yifan Dai, Shilin Yu, Pradham Tanikella, Travis Schrank, Trevor Hackman, Didong Li, Di Wu

Large Language Models (LLMs) have shown impressive capabilities in natural
language processing, yet their use in sensitive domains like healthcare,
particularly with Electronic Health Records (EHR), faces significant challenges
due to privacy concerns and limited computational resources. This paper
presents a compact LLM framework designed for local deployment in settings with
strict privacy requirements and limited access to high-performance GPUs. We
introduce a novel preprocessing technique that uses information extraction
methods, e.g., regular expressions, to filter and emphasize critical
information in clinical notes, enhancing the performance of smaller LLMs on EHR
data. Our framework is evaluated using zero-shot and few-shot learning
paradigms on both private and publicly available (MIMIC-IV) datasets, and we
also compare its performance with fine-tuned LLMs on the MIMIC-IV dataset. The
results demonstrate that our preprocessing approach significantly boosts the
prediction accuracy of smaller LLMs, making them suitable for high-privacy,
resource-constrained applications. This study offers valuable insights into
optimizing LLM performance for sensitive, data-intensive tasks while addressing
computational and privacy limitations.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨èªç¶èªè¨èçæ¹é¢å±ç¾åºä»¤äººå°è±¡æ·±å»çè½åï¼ç¶èå®åå¨é«çä¿å¥ç­ææé åçä½¿ç¨ï¼ç¹å¥æ¯é»å­å¥åº·ç´é (EHR)ï¼ç±æ¼é±ç§åé¡åæéçéç®è³æºèé¢è¨éå¤§ææ°ãæ¬ææåºäºä¸åç·æ¹ç LLM æ¡æ¶ï¼æ¨å¨å¨å·æå´æ ¼é±ç§è¦æ±åæéä½¿ç¨é«æ§è½ GPU çç°å¢ä¸­é²è¡æ¬å°é¨ç½²ãæåå¼å¥äºä¸ç¨®æ°ç©çé èçæè¡ï¼å®ä½¿ç¨è³è¨èåæ¹æ³ï¼ä¾å¦æ­£è¦è¡¨ç¤ºæ³ï¼ä¾éæ¿¾åå¼·èª¿è¨åºç­è¨ä¸­çééµè³è¨ï¼å¢å¼·è¼å° LLM å¨ EHR è³æä¸çæè½ãæåçæ¡æ¶ä½¿ç¨é¶æ¬¡å­¸ç¿åå°æ¬¡å­¸ç¿ç¯ä¾å¨ç§äººåå¬éå¯ç¨ç (MIMIC-IV) è³æéä¸é²è¡è©ä¼°ï¼æåä¹æ¯è¼å®å¨ MIMIC-IV è³æéä¸èå¾®èª¿ LLM çæè½ãçµæè¡¨æï¼æåçé èçæ¹æ³é¡¯èæåäºè¼å° LLM çé æ¸¬æºç¢ºåº¦ï¼ä½¿å¶é©ç¨æ¼é«åº¦é±ç§ãè³æºåéçæç¨ç¨å¼ãéé ç ç©¶æä¾äºå¯¶è²´çè¦è§£ï¼ç¨æ¼æä½³å LLM æè½ä»¥æå°ææãè³æå¯éåä»»åï¼åæè§£æ±ºéç®åé±ç§éå¶ã

##### **Block MedCare: Advancing healthcare through blockchain integration with AI and IoT**
2412.02851v1 by Oliver Simonoski, Dijana Capeska Bogatinoska

This research explores the integration of blockchain technology in
healthcare, focusing on enhancing the security and efficiency of Electronic
Health Record (EHR) management. We propose a novel Ethereum-based system that
empowers patients with secure control over their medical data. Our approach
addresses key challenges in healthcare blockchain implementation, including
scalability, privacy, and regulatory compliance. The system incorporates
digital signatures, Role-Based Access Control, and a multi-layered architecture
to ensure secure, controlled access. We developed a decentralized application
(dApp) with user-friendly interfaces for patients, doctors, and administrators,
demonstrating the practical application of our solution. A survey among
healthcare professionals and IT experts revealed strong interest in blockchain
adoption, while also highlighting concerns about integration costs. The study
explores future enhancements, including integration with IoT devices and
AI-driven analytics, contributing to the evolution of secure, efficient, and
interoperable healthcare systems that leverage cutting-edge technologies for
improved patient care.

æè¦ï¼æ¬ç ç©¶æ¢è¨åå¡éæè¡å¨é«çä¿å¥ä¸­çæ´åï¼å°æ³¨æ¼æåé»å­å¥åº·ç´é (EHR) ç®¡ççå®å¨æ§èæçãæåæåºä¸ååµæ°çä»¥å¤ªåç³»çµ±ï¼è³¦äºæ£èå®å¨å°æ§å¶å¶é«çæ¸æçæ¬åãæåçåæ³è§£æ±ºäºé«çä¿å¥åå¡éå¯¦ä½ä¸­çä¸»è¦ææ°ï¼åæ¬å¯æ´åæ§ãé±ç§åæ³è¦éµå¾ªãè©²ç³»çµ±æ´åäºæ¸ä½ç°½ç« ãåºæ¼è§è²çå­åæ§å¶åå¤å±¤æ¶æ§ï¼ä»¥ç¢ºä¿å®å¨ä¸åæ§çå­åãæåéç¼äºä¸åå·æä½¿ç¨èååä»é¢çå»ä¸­å¿åæç¨ç¨å¼ (dApp)ï¼é©ç¨æ¼æ£èãé«çåç®¡çå¡ï¼å±ç¤ºäºæåè§£æ±ºæ¹æ¡çå¯¦éæç¨ãå¨é«çä¿å¥å°æ¥­äººå¡å IT å°å®¶ä¹éé²è¡çä¸é èª¿æ¥é¡¯ç¤ºï¼ä»åå°åå¡éçæ¡ç¨ææ¿åèè¶£ï¼ä½ä¹å¼·èª¿äºå°æ´åææ¬çææãè©²ç ç©¶æ¢è¨äºæªä¾çå¼·åï¼åæ¬è IoT è£ç½®æ´åå AI é©åçåæï¼æå©æ¼å®å¨ãé«æä¸å¯äºæä½çé«çä¿å¥ç³»çµ±çæ¼é²ï¼è©²ç³»çµ±å©ç¨å°ç«¯æè¡æ¹åæ£èç§è­·ã

##### **CNNSum: Exploring Long-Conext Summarization with Large Language Models in Chinese Novels**
2412.02819v2 by Lingxiao Wei, He Yan, Xiangju Lu, Junmin Zhu, Jun Wang, Wei Zhang

Large Language Models (LLMs) have been well-researched in many long-context
tasks. However, due to high annotation costs, high-quality long-context summary
datasets for training or evaluation are scarce, limiting further research. In
this work, we introduce CNNSum, a new multi-scale Chinese long-context novel
summarization benchmark, including four subsets, length covering
16k\textasciitilde128k, 695 samples in total, the annotations are human-driven.
We evaluate commercial and open-source models on CNNSum and conduct a detailed
analysis. Based on the observations, we further conduct fine-tuning exploration
with short-context summary data. In our study: (1) GPT-4o underperformed, due
to excessive subjective commentary. (2) Currently, long-context summarization
mainly relies on memory ability, small LLMs with stable longer context lengths
are the most cost-effective. Using long data concatenated from short-context
summaries makes a significant improvement. (3) Prompt templates may cause a
large performance gap but can be mitigated through fine-tuning. (4) Fine-tuned
Chat or Instruction versions may harm the Base model and further fine-tuning
cannot bridge performance gap. (5) while models with RoPE base scaling exhibit
strong extrapolation potential, their performance may vary significantly when
combined with other interpolation methods and need careful selection. (6)
CNNSum provides more reliable and insightful evaluation results than other
benchmarks. We release CNNSum to advance research in this field.

æè¦ï¼<paragraph>å¤§åèªè¨æ¨¡å (LLM) å·²å¨è¨±å¤é·èªå¢ä»»åä¸­ç²å¾æ·±å¥ç ç©¶ãç¶èï¼ç±æ¼æ¨è¨»ææ¬é«æï¼ç¨æ¼è¨ç·´æè©ä¼°çé«åè³ªé·èªå¢æè¦è³æéç¨ç¼ºï¼éå¶äºé²ä¸æ­¥çç ç©¶ãå¨æ¬æä¸­ï¼æåä»ç´¹äº CNNSumï¼ä¸åæ°çå¤å°ºåº¦ä¸­æé·èªå¢å°èªªæè¦åºæºï¼åæ¬ååå­éï¼é·åº¦æ¶µè 16k\textasciitilde128kï¼å± 695 åç¯ä¾ï¼æ¨è¨»ç±äººå·¥é©åãæåå¨ CNNSum ä¸è©ä¼°äºåæ¥­åéæºæ¨¡åï¼ä¸¦é²è¡äºè©³ç´°åæãæ ¹æè§å¯çµæï¼æåé²ä¸æ­¥ä½¿ç¨ç­èªå¢æè¦è³æé²è¡å¾®èª¿æ¢ç´¢ãå¨æåçç ç©¶ä¸­ï¼(1) GPT-4o è¡¨ç¾ä¸ä½³ï¼åå æ¯éåº¦çä¸»è§è©è«ã(2) ç®åï¼é·èªå¢æè¦ä¸»è¦ä¾è³´è¨æ¶è½åï¼å·æç©©å®è¼é·èªå¢é·åº¦çå°å LLM æå·ææ¬æçãä½¿ç¨å¾ç­èªå¢æè¦ä¸²è¯èæçé·è³æï¼å¯ä»¥é¡¯èæåææã(3) æç¤ºç¯æ¬å¯è½æé æå¾å¤§çæè½å·®è·ï¼ä½å¯ä»¥ééå¾®èª¿ä¾æ¸è¼ã(4) å¾®èª¿çèå¤©ææä»¤çæ¬å¯è½ææå®³åºç¤æ¨¡åï¼èé²ä¸æ­¥çå¾®èª¿ä¹ç¡æ³å½åæè½å·®è·ã(5) éç¶å·æ RoPE åºç¤ç¸®æ¾çæ¨¡åå±ç¾åºå¼·å¤§çå¤æ¨æ½åï¼ä½èå¶ä»å§ææ¹æ³çµåæï¼å¶æè½å¯è½æå¤§å¹è®åï¼éè¦ä»ç´°é¸æã(6) CNNSum æä¾æ¯å¶ä»åºæºæ´å¯é ä¸æè¦å°çè©ä¼°çµæãæåç¼å¸ CNNSum ä»¥æ¨åæ­¤é åçç ç©¶ã</paragraph>

##### **Optimization of Transformer heart disease prediction model based on particle swarm optimization algorithm**
2412.02801v1 by Peiyang Yu, Jingyuan Yi, Tianyi Huang, Zeqiu Xu, Xiaochuan Xu

Aiming at the latest particle swarm optimization algorithm, this paper
proposes an improved Transformer model to improve the accuracy of heart disease
prediction and provide a new algorithm idea. We first use three mainstream
machine learning classification algorithms - decision tree, random forest and
XGBoost, and then output the confusion matrix of these three models. The
results showed that the random forest model had the best performance in
predicting the classification of heart disease, with an accuracy of 92.2%.
Then, we apply the Transformer model based on particle swarm optimization (PSO)
algorithm to the same dataset for classification experiment. The results show
that the classification accuracy of the model is as high as 96.5%, 4.3
percentage points higher than that of random forest, which verifies the
effectiveness of PSO in optimizing Transformer model. From the above research,
we can see that particle swarm optimization significantly improves Transformer
performance in heart disease prediction. Improving the ability to predict heart
disease is a global priority with benefits for all humankind. Accurate
prediction can enhance public health, optimize medical resources, and reduce
healthcare costs, leading to healthier populations and more productive
societies worldwide. This advancement paves the way for more efficient health
management and supports the foundation of a healthier, more resilient global
community.

æè¦ï¼éå°ææ°çç²å­ç¾¤æä½³åæ¼ç®æ³ï¼æ¬ææåºä¸åæ¹è¯ç Transformer æ¨¡åï¼ä»¥æåå¿èçé æ¸¬çæºç¢ºåº¦ï¼ä¸¦æä¾ä¸åæ°çæ¼ç®æ³æç¶­ãæåé¦åä½¿ç¨ä¸åä¸»æµçæ©å¨å­¸ç¿åé¡æ¼ç®æ³ââæ±ºç­æ¨¹ãé¨æ©æ£®æå XGBoostï¼åè¼¸åºéä¸åæ¨¡åçæ··æ·ç©é£ãçµæé¡¯ç¤ºï¼é¨æ©æ£®ææ¨¡åå¨é æ¸¬å¿èçåé¡çè¡¨ç¾æä½³ï¼æºç¢ºçé 92.2%ãæ¥èï¼æåå°åºæ¼ç²å­ç¾¤æä½³å (PSO) æ¼ç®æ³ç Transformer æ¨¡åå¥ç¨æ¼ç¸åçè³æéï¼é²è¡åé¡å¯¦é©ãçµæé¡¯ç¤ºï¼è©²æ¨¡åçåé¡æºç¢ºçé«é 96.5%ï¼æ¯é¨æ©æ£®æé«åº 4.3 åç¾åé»ï¼é©è­äº PSO å¨æä½³å Transformer æ¨¡åä¸çæææ§ãå¾ä»¥ä¸ç ç©¶ä¸­ï¼æåå¯ä»¥çåºç²å­ç¾¤æä½³åé¡¯èæåäº Transformer å¨å¿èçé æ¸¬ä¸çè¡¨ç¾ãæåé æ¸¬å¿èççè½åæ¯ä¸é å¨çæ§çåªåè¦åï¼å°å¨äººé¡é½æçèãæºç¢ºçé æ¸¬å¯ä»¥å¢é²å¬å±è¡çãåªåé«çè³æºï¼ä¸¦éä½é«çä¿å¥ææ¬ï¼é²èè®å¨çäººå£æ´å¥åº·ãç¤¾ææ´å·çç¢åãéé é²å±çºæ´ææççå¥åº·ç®¡çéªè·¯ï¼ä¸¦æ¯æå»ºç«ä¸åæ´å¥åº·ãæ´å·éæ§çå¨çç¤¾ç¾¤ã

##### **Medical Multimodal Foundation Models in Clinical Diagnosis and Treatment: Applications, Challenges, and Future Directions**
2412.02621v1 by Kai Sun, Siyan Xue, Fuchun Sun, Haoran Sun, Yu Luo, Ling Wang, Siyuan Wang, Na Guo, Lei Liu, Tian Zhao, Xinzhou Wang, Lei Yang, Shuo Jin, Jun Yan, Jiahong Dong

Recent advancements in deep learning have significantly revolutionized the
field of clinical diagnosis and treatment, offering novel approaches to improve
diagnostic precision and treatment efficacy across diverse clinical domains,
thus driving the pursuit of precision medicine. The growing availability of
multi-organ and multimodal datasets has accelerated the development of
large-scale Medical Multimodal Foundation Models (MMFMs). These models, known
for their strong generalization capabilities and rich representational power,
are increasingly being adapted to address a wide range of clinical tasks, from
early diagnosis to personalized treatment strategies. This review offers a
comprehensive analysis of recent developments in MMFMs, focusing on three key
aspects: datasets, model architectures, and clinical applications. We also
explore the challenges and opportunities in optimizing multimodal
representations and discuss how these advancements are shaping the future of
healthcare by enabling improved patient outcomes and more efficient clinical
workflows.

æè¦ï¼æ·±åº¦å­¸ç¿çææ°é²å±å¤§å¹é©æ°äºè¨åºè¨ºæ·åæ²»çé åï¼æä¾äºæ¹ååç¨®è¨åºé åè¨ºæ·ç²¾æºåº¦åæ²»çææçæ°æ¹æ³ï¼é²èæ¨åç²¾æºé«ççè¿½æ±ãå¤å¨å®åå¤æ¨¡æè³æéçå¯ç¨æ§æ¥çå¢å ï¼å éäºå¤§è¦æ¨¡é«çå¤æ¨¡æåºç¤æ¨¡å (MMFM) çç¼å±ãéäºæ¨¡åä»¥å¶å¼·å¤§çæ¦åè½ååè±å¯çè¡¨å¾µè½åèèåï¼æ­£æ¥çè¢«æ¹ç·¨ä»¥è§£æ±ºå»£æ³çè¨åºä»»åï¼å¾æ©æè¨ºæ·å°åäººåæ²»çç­ç¥ãæ¬ç¯è©è«æä¾äºå° MMFM è¿æç¼å±çå¨é¢åæï¼éé»éæ³¨ä¸åééµé¢åï¼è³æéãæ¨¡åæ¶æ§åè¨åºæç¨ãæåä¹æ¢è¨äºæä½³åå¤æ¨¡æè¡¨å¾µçææ°åæ©æï¼ä¸¦è¨è«éäºé²å±å¦ä½ééæ¹åæ£èé å¾åæ´ææççè¨åºå·¥ä½æµç¨ï¼å½¢å¡é«çä¿å¥çæªä¾ã

##### **U-Net in Medical Image Segmentation: A Review of Its Applications Across Modalities**
2412.02242v1 by Fnu Neha, Deepshikha Bhati, Deepak Kumar Shukla, Sonavi Makarand Dalvi, Nikolaos Mantzou, Safa Shubbar

Medical imaging is essential in healthcare to provide key insights into
patient anatomy and pathology, aiding in diagnosis and treatment. Non-invasive
techniques such as X-ray, Magnetic Resonance Imaging (MRI), Computed Tomography
(CT), and Ultrasound (US), capture detailed images of organs, tissues, and
abnormalities. Effective analysis of these images requires precise segmentation
to delineate regions of interest (ROI), such as organs or lesions. Traditional
segmentation methods, relying on manual feature-extraction, are labor-intensive
and vary across experts. Recent advancements in Artificial Intelligence (AI)
and Deep Learning (DL), particularly convolutional models such as U-Net and its
variants (U-Net++ and U-Net 3+), have transformed medical image segmentation
(MIS) by automating the process and enhancing accuracy. These models enable
efficient, precise pixel-wise classification across various imaging modalities,
overcoming the limitations of manual segmentation. This review explores various
medical imaging techniques, examines the U-Net architectures and their
adaptations, and discusses their application across different modalities. It
also identifies common challenges in MIS and proposes potential solutions.

æè¦ï¼é«çå½±åå¨é«çä¿å¥ä¸­è³ééè¦ï¼å¯æä¾æ£èè§£åçµæ§åççå­¸çéè¦è¦è§£ï¼æå©æ¼è¨ºæ·åæ²»çãX åãç£æ¯é å½± (MRI)ãé»è¦æ·å±¤ææ (CT) åè¶é³æ³¢ (US) ç­éä¾µå¥å¼æè¡ï¼å¯ææå¨å®ãçµç¹åç°å¸¸çè©³ç´°å½±åãææåæéäºå½±åéè¦ç²¾ç¢ºçåå²ï¼ä»¥æç¹ªæèè¶£åå (ROI)ï¼ä¾å¦å¨å®æçç¶ãå³çµ±çåå²æ¹æ³ä¾è³´æ¼æåç¹å¾µèåï¼æ¢è²»æåå å°å®¶èç°ãäººå·¥æºæ§ (AI) åæ·±åº¦å­¸ç¿ (DL) çææ°é²å±ï¼ç¹å¥æ¯ U-Net åå¶è®é« (U-Net++ å U-Net 3+) ç­å·ç©æ¨¡åï¼å·²ééèªååæµç¨åæé«æºç¢ºåº¦ï¼è½è®äºé«çå½±ååå² (MIS)ãéäºæ¨¡åè½è·¨è¶åç¨®å½±åæ¨¡å¼é²è¡ææä¸ç²¾ç¢ºçéåç´ åé¡ï¼åæäºæååå²çéå¶ãæ¬ç¯è©è«æ¢è¨äºåç¨®é«çå½±åæè¡ï¼å¯©æ¥äº U-Net æ¶æ§åå¶æ¹ç·¨ï¼ä¸¦è¨è«äºå®åå¨ä¸åæ¨¡å¼ä¸­çæç¨ãå®ä¹æ¾åºäº MIS ä¸­å¸¸è¦çææ°ï¼ä¸¦æåºäºæ½å¨çè§£æ±ºæ¹æ¡ã

##### **Recovering implicit physics model under real-world constraints**
2412.02215v1 by Ayan Banerjee, Sandeep K. S. Gupta

Recovering a physics-driven model, i.e. a governing set of equations of the
underlying dynamical systems, from the real-world data has been of recent
interest. Most existing methods either operate on simulation data with
unrealistically high sampling rates or require explicit measurements of all
system variables, which is not amenable in real-world deployments. Moreover,
they assume the timestamps of external perturbations to the physical system are
known a priori, without uncertainty, implicitly discounting any sensor
time-synchronization or human reporting errors. In this paper, we propose a
novel liquid time constant neural network (LTC-NN) based architecture to
recover underlying model of physical dynamics from real-world data. The
automatic differentiation property of LTC-NN nodes overcomes problems
associated with low sampling rates, the input dependent time constant in the
forward pass of the hidden layer of LTC-NN nodes creates a massive search space
of implicit physical dynamics, the physics model solver based data
reconstruction loss guides the search for the correct set of implicit dynamics,
and the use of the dropout regularization in the dense layer ensures extraction
of the sparsest model. Further, to account for the perturbation timing error,
we utilize dense layer nodes to search through input shifts that results in the
lowest reconstruction loss. Experiments on four benchmark dynamical systems,
three with simulation data and one with the real-world data show that the
LTC-NN architecture is more accurate in recovering implicit physics model
coefficients than the state-of-the-art sparse model recovery approaches. We
also introduce four additional case studies (total eight) on real-life medical
examples in simulation and with real-world clinical data to show effectiveness
of our approach in recovering underlying model in practice.

æè¦ï¼<paragraph>å¾çå¯¦ä¸çè³æä¸­éåç©çé©åæ¨¡åï¼å³åºç¤åæç³»çµ±çæ§å¶æ¹ç¨å¼çµï¼ä¸ç´æ¯è¿æçç ç©¶éé»ãç¾ææ¹æ³å¤§å¤å¨å·æéç¾å¯¦é«åæ¨£ççæ¨¡æ¬è³æä¸å·è¡ï¼æéè¦ææç³»çµ±è®æ¸çæç¢ºæ¸¬éå¼ï¼éå¨çå¯¦ä¸ççé¨ç½²ä¸­ä¸¦ä¸å¯è¡ãæ­¤å¤ï¼éäºæ¹æ³åè¨­å°ç©çç³»çµ±çå¤é¨æ¾åçæéæ³æ¯åé©å·²ç¥çï¼ä¸æ²æä¸ç¢ºå®æ§ï¼é±å«å°å¿½ç¥äºä»»ä½ææ¸¬å¨æéåæ­¥æäººçºåå ±é¯èª¤ãå¨æ¬æä¸­ï¼æåæåºäºä¸ç¨®åºæ¼æ°ç©æ¶²ææéå¸¸æ¸ç¥ç¶ç¶²è·¯ (LTC-NN) çæ¶æ§ï¼ä»¥å¾çå¯¦ä¸çè³æä¸­éåç©çåæçåºç¤æ¨¡åãLTC-NN ç¯é»çèªåå¾®åç¹æ§åæäºèä½åæ¨£çç¸éçåé¡ï¼LTC-NN ç¯é»é±èå±¤çååå³éä¸­è¼¸å¥ä¾è³´çæéå¸¸æ¸æç¢çä¸åå·¨å¤§çé±å¼ç©çåææå°ç©ºéï¼åºæ¼ç©çæ¨¡åæ±è§£å¨çè³æéå»ºæå¤±å¼å°äºå°æ­£ç¢ºé±å¼åæéçæå°ï¼ä¸¦ä¸å¨ç¨ å¯å±¤ä¸­ä½¿ç¨ä¸­æ·æ­£ååç¢ºä¿äºæç¨çæ¨¡åçæåãæ­¤å¤ï¼çºäºèæ®æ¾åè¨æé¯èª¤ï¼æåå©ç¨ç¨ å¯å±¤ç¯é»ä¾æå°è¼¸å¥ä½ç§»ï¼éå°å°è´æä½çéå»ºæå¤±ãå¨åååºæºåæç³»çµ±ï¼ä¸åä½¿ç¨æ¨¡æ¬è³æï¼ä¸åä½¿ç¨çå¯¦ä¸çè³æï¼ä¸çå¯¦é©è¡¨æï¼LTC-NN æ¶æ§å¨æ¢å¾©é±å¼ç©çæ¨¡åä¿æ¸æ¹é¢æ¯æåé²çç¨çæ¨¡åæ¢å¾©æ¹æ³æ´æºç¢ºãæåéä»ç´¹äºååé¡å¤çæ¡ä¾ç ç©¶ï¼ç¸½å±å«åï¼ï¼éäºç ç©¶æ¶åæ¨¡æ¬ä¸­ççå¯¦é«çç¯ä¾åçå¯¦ä¸ççè¨åºè³æï¼ä»¥å±ç¤ºæåçåæ³å¨å¯¦åä¸­æ¢å¾©åºç¤æ¨¡åçæææ§ã</paragraph>

##### **Comparative Performance of Machine Learning Algorithms for Early Genetic Disorder and Subclass Classification**
2412.02189v1 by Abu Bakar Siddik, Faisal R. Badal, Afroza Islam

A great deal of effort has been devoted to discovering a particular genetic
disorder, but its classification across a broad spectrum of disorder classes
and types remains elusive. Early diagnosis of genetic disorders enables timely
interventions and improves outcomes. This study implements machine learning
models using basic clinical indicators measurable at birth or infancy to enable
diagnosis in preliminary life stages. Supervised learning algorithms were
implemented on a dataset of 22083 instances with 42 features like family
history, newborn metrics, and basic lab tests. Extensive hyperparameter tuning,
feature engineering, and selection were undertaken. Two multi-class classifiers
were developed: one for predicting disorder classes (mitochondrial,
multifactorial, and single-gene) and one for subtypes (9 disorders).
Performance was evaluated using accuracy, precision, recall, and the F1-score.
The CatBoost classifier achieved the highest accuracy of 77% for predicting
genetic disorder classes. For subtypes, SVM attained a maximum accuracy of 80%.
The study demonstrates the feasibility of using basic clinical data in machine
learning models for early categorization and diagnosis across various genetic
disorders. Applying ML with basic clinical indicators can enable timely
interventions once validated on larger datasets. It is necessary to conduct
further studies to improve model performance on this dataset.

æè¦ï¼<paragraph>è¨±å¤ç ç©¶è´åæ¼ç¼ç¾ç¹å®éºå³æ§ç¾çï¼ä½å¶å¨å»£æ³çç¾çé¡åååé¡ä¸­çåé¡ä»ç¶é£ä»¥ææ¸ãéºå³æ§ç¾ççæ©æè¨ºæ·è½åæä»å¥ä¸¦æ¹åçµæãæ¬ç ç©¶å¯¦ä½æ©å¨å­¸ç¿æ¨¡åï¼ä½¿ç¨åºçæå¬°åææå¯æ¸¬éçåºæ¬è¨åºææ¨ï¼ä»¥å¨çå½çæ©æéæ®µé²è¡è¨ºæ·ãç£ç£å¼å­¸ç¿æ¼ç®æ³å¯¦ä½å¨ä¸ååå« 22083 åå¯¦ä¾çè³æéä¸ï¼å¶ä¸­åå« 42 åç¹å¾µï¼ä¾å¦å®¶æå²ãæ°çåææ¨ååºæ¬å¯¦é©å®¤æª¢é©ãé²è¡äºå»£æ³çè¶åæ¸èª¿æ´ãç¹å¾µå·¥ç¨åé¸æãéç¼äºå©åå¤é¡å¥åé¡å¨ï¼ä¸åç¨æ¼é æ¸¬ç¾çé¡åï¼ç²ç·é«ãå¤å ç´ åå®åºå ï¼ï¼å¦ä¸åç¨æ¼é æ¸¬äºåï¼9 ç¨®ç¾çï¼ãä½¿ç¨æºç¢ºåº¦ãç²¾ç¢ºåº¦ãå¬åçå F1 åæ¸è©ä¼°æè½ãCatBoost åé¡å¨å¨é æ¸¬éºå³æ§ç¾çé¡åæ¹é¢éå°äº 77% çæé«æºç¢ºåº¦ãå°æ¼äºåï¼SVM éå°äº 80% çæé«æºç¢ºåº¦ãæ¬ç ç©¶è­æäºå¨æ©å¨å­¸ç¿æ¨¡åä¸­ä½¿ç¨åºæ¬è¨åºè³æé²è¡æ©æåé¡åè¨ºæ·åç¨®éºå³æ§ç¾ççå¯è¡æ§ãå°æ©å¨å­¸ç¿æç¨æ¼åºæ¬è¨åºææ¨ï¼å¯ä»¥å¨è¼å¤§çè³æéä¸é©è­å¾åæé²è¡å¹²é ãæå¿è¦é²è¡é²ä¸æ­¥çç ç©¶ä»¥æ¹åæ­¤è³æéä¸çæ¨¡åæè½ã</paragraph>

##### **Anatomically-Grounded Fact Checking of Automated Chest X-ray Reports**
2412.02177v1 by R. Mahmood, K. C. L. Wong, D. M. Reyes, N. D'Souza, L. Shi, J. Wu, P. Kaviani, M. Kalra, G. Wang, P. Yan, T. Syeda-Mahmood

With the emergence of large-scale vision-language models, realistic radiology
reports may be generated using only medical images as input guided by simple
prompts. However, their practical utility has been limited due to the factual
errors in their description of findings. In this paper, we propose a novel
model for explainable fact-checking that identifies errors in findings and
their locations indicated through the reports. Specifically, we analyze the
types of errors made by automated reporting methods and derive a new synthetic
dataset of images paired with real and fake descriptions of findings and their
locations from a ground truth dataset. A new multi-label cross-modal
contrastive regression network is then trained on this datsaset. We evaluate
the resulting fact-checking model and its utility in correcting reports
generated by several SOTA automated reporting tools on a variety of benchmark
datasets with results pointing to over 40\% improvement in report quality
through such error detection and correction.

æè¦ï¼é¨èå¤§è¦æ¨¡è¦è¦ºèªè¨æ¨¡åçåºç¾ï¼åä½¿ç¨é«çå½±åä½çºè¼¸å¥ï¼ä¸¦ééç°¡å®æç¤ºå¼å°ï¼å³å¯ç¢çé¼ççæ¾å°ç§å ±åãç¶èï¼ç±æ¼å¶å°ç¼ç¾çæè¿°æäºå¯¦ä¸çé¯èª¤ï¼å æ­¤å¶å¯¦éæç¨åå°éå¶ãå¨æ¬æä¸­ï¼æåæåºäºä¸åç¨æ¼å¯è§£éäºå¯¦æ¥æ ¸çæ°æ¨¡åï¼è©²æ¨¡åå¯è­å¥å ±åä¸­ç¼ç¾çé¯èª¤åå¶ä½ç½®ãå·é«ä¾èªªï¼æååæäºèªååå ±åæ¹æ³æç¢ççé¯èª¤é¡åï¼ä¸¦å¾çå¯¦è³æéä¸­è¡çåºä¸åæ°çåæå½±åè³æéï¼å¶ä¸­éå°äºç¼ç¾åå¶ä½ç½®ççå¯¦åèåæè¿°ãç¶å¾å¨éåè³æéä¸è¨ç·´ä¸åæ°çå¤æ¨ç±¤è·¨æ¨¡æå°æ¯åæ­¸ç¶²è·¯ãæåè©ä¼°äºç¢ççäºå¯¦æ¥æ ¸æ¨¡ååå¶å¨æ´æ­£ç±å¤å SOTA èªååå ±åå·¥å·å¨åç¨®åºæºè³æéä¸ç¢ççå ±åä¸­çæç¨ï¼çµæè¡¨æéééç¨®é¯èª¤åµæ¸¬åæ´æ­£ï¼å ±ååè³ªç²å¾äºè¶é 40% çæåã

##### **Keeping Experts in the Loop: Expert-Guided Optimization for Clinical Data Classification using Large Language Models**
2412.02173v1 by Nader Karayanni, Aya Awwad, Chein-Lien Hsiao, Surish P Shanmugam

Since the emergence of Large Language Models (LLMs), the challenge of
effectively leveraging their potential in healthcare has taken center stage. A
critical barrier to using LLMs for extracting insights from unstructured
clinical notes lies in the prompt engineering process. Despite its pivotal role
in determining task performance, a clear framework for prompt optimization
remains absent. Current methods to address this gap take either a manual prompt
refinement approach, where domain experts collaborate with prompt engineers to
create an optimal prompt, which is time-intensive and difficult to scale, or
through employing automatic prompt optimizing approaches, where the value of
the input of domain experts is not fully realized. To address this, we propose
StructEase, a novel framework that bridges the gap between automation and the
input of human expertise in prompt engineering. A core innovation of the
framework is SamplEase, an iterative sampling algorithm that identifies
high-value cases where expert feedback drives significant performance
improvements. This approach minimizes expert intervention, to effectively
enhance classification outcomes. This targeted approach reduces labeling
redundancy, mitigates human error, and enhances classification outcomes. We
evaluated the performance of StructEase using a dataset of de-identified
clinical narratives from the US National Electronic Injury Surveillance System
(NEISS), demonstrating significant gains in classification performance compared
to current methods. Our findings underscore the value of expert integration in
LLM workflows, achieving notable improvements in F1 score while maintaining
minimal expert effort. By combining transparency, flexibility, and scalability,
StructEase sets the foundation for a framework to integrate expert input into
LLM workflows in healthcare and beyond.

æè¦ï¼èªå¤§åèªè¨æ¨¡å (LLM) åºç¾ä»¥ä¾ï¼ææå©ç¨å¶å¨é«çä¿å¥ä¸­çæ½åçææ°å·²æçºéä¸­ä¹éãä½¿ç¨ LLM å¾éçµæ§åè¨åºç­è¨ä¸­æåè¦è§£çä¸åééµéç¤å¨æ¼æç¤ºå·¥ç¨éç¨ãåç®¡å®å¨ç¢ºå®ä»»åç¸¾æä¸­æ®æ¼èèè¶³è¼éçè§è²ï¼ä½ä»ç¼ºä¹æç¢ºçæç¤ºæä½³åæ¡æ¶ãç®åè§£æ±ºæ­¤å·®è·çæ¹æ³æ¡ç¨æåæç¤ºåªåæ¹æ³ï¼å¶ä¸­é åå°å®¶èæç¤ºå·¥ç¨å¸«åä½å»ºç«æä½³æç¤ºï¼ééå¸¸èæä¸é£ä»¥æ´å±ï¼æééæ¡ç¨èªåæç¤ºæä½³åæ¹æ³ï¼å¶ä¸­é åå°å®¶çè¼¸å¥å¹å¼ä¸¦æªååå¯¦ç¾ãçºäºè§£æ±ºéååé¡ï¼æåæåºäº StructEaseï¼éæ¯ä¸åæ°ç©çæ¡æ¶ï¼å®å½åäºèªååèæç¤ºå·¥ç¨ä¸­äººé¡å°æ¥­ç¥è­è¼¸å¥ä¹éçå·®è·ãè©²æ¡æ¶çæ ¸å¿åµæ°æ¯ SamplEaseï¼éæ¯ä¸ç¨®è¿­ä»£å¼æ½æ¨£æ¼ç®æ³ï¼å®è­å¥åºå°å®¶åé¥è½é¡¯èæåç¸¾æçé«å¹å¼æ¡ä¾ãéç¨®æ¹æ³å°å°å®¶ä»å¥éå°æä½ï¼ä»¥æææååé¡çµæãéç¨®æéå°æ§çæ¹æ³æ¸å°äºæ¨ç±¤åé¤ï¼æ¸è¼äºäººçºé¯èª¤ï¼ä¸¦æåäºåé¡çµæãæåä½¿ç¨ä¾èªç¾ååå®¶é»å­å·å®³ç£æ¸¬ç³»çµ± (NEISS) çå»è­å¥åè¨åºæè¿°è³æéè©ä¼°äº StructEase çç¸¾æï¼èç®åçæ¹æ³ç¸æ¯ï¼åé¡ç¸¾ææäºé¡¯èçæåãæåçç ç©¶çµæå¼·èª¿äºå°å®¶æ´åå¨ LLM å·¥ä½æµç¨ä¸­çå¹å¼ï¼å¨ç¶­ææå°å°å®¶å·¥ä½éçåæï¼éå°äº F1 åæ¸çé¡¯èæåãééçµåéæåº¦ãå½æ§åå¯æ´å±æ§ï¼StructEase çºä¸åæ¡æ¶å¥ å®äºåºç¤ï¼å°å°å®¶è¼¸å¥æ´åå°é«çä¿å¥åå¶ä»é åç LLM å·¥ä½æµç¨ä¸­ã

##### **Construction and optimization of health behavior prediction model for the elderly in smart elderly care**
2412.02062v1 by Qian Guo, Peiyuan Chen

With the intensification of global aging, health management of the elderly
has become a focus of social attention. This study designs and implements a
smart elderly care service model to address issues such as data diversity,
health status complexity, long-term dependence and data loss, sudden changes in
behavior, and data privacy in the prediction of health behaviors of the
elderly. The model achieves accurate prediction and dynamic management of
health behaviors of the elderly through modules such as multimodal data fusion,
data loss processing, nonlinear prediction, emergency detection, and privacy
protection. In the experimental design, based on multi-source data sets and
market research results, the model demonstrates excellent performance in health
behavior prediction, emergency detection, and personalized services. The
experimental results show that the model can effectively improve the accuracy
and robustness of health behavior prediction and meet the actual application
needs in the field of smart elderly care. In the future, with the integration
of more data and further optimization of technology, the model will provide
more powerful technical support for smart elderly care services.

æè¦ï¼é¨èå¨çé«é½¡åå åï¼èå¹´äººçå¥åº·ç®¡çå·²æçºç¤¾æéæ³¨çç¦é»ãæ¬ç ç©¶è¨­è¨ä¸¦å¯¦ä½ä¸åæºæ§èäººç§è­·æåæ¨¡åï¼ä»¥è§£æ±ºèäººå¥åº·è¡çºé æ¸¬ä¸­çè³æç°è³ªæ§ãå¥åº·çæè¤éæ§ãé·æä¾è³´æ§èè³ææµå¤±ãè¡çºçªè®ãè³æé±ç§ç­åé¡ãè©²æ¨¡åééå¤æ¨¡æè³æèåãè³ææµå¤±èçãéç·æ§é æ¸¬ãç·æ¥äºä»¶åµæ¸¬ãé±ç§ä¿è­·ç­æ¨¡çµï¼éå°èäººå¥åº·è¡çºçç²¾æºé æ¸¬èåæç®¡çãå¨å¯¦é©è¨­è¨ä¸ï¼åºæ¼å¤ä¾æºè³æéèå¸å ´èª¿æ¥çµæï¼è©²æ¨¡åå¨å¥åº·è¡çºé æ¸¬ãç·æ¥äºä»¶åµæ¸¬ãåäººåæåç­æ¹é¢åå±ç¾åºåªç°çè¡¨ç¾ãå¯¦é©çµæé¡¯ç¤ºï¼è©²æ¨¡åè½æææåå¥åº·è¡çºé æ¸¬çæºç¢ºæ§èé­¯æ£æ§ï¼ä¸¦æ»¿è¶³æºæ§èäººç§è­·é åçå¯¦éæç¨éæ±ãæªä¾é¨èæ´å¤è³æçæ´åèæè¡çé²ä¸æ­¥åªåï¼è©²æ¨¡åå°çºæºæ§èäººç§è­·æåæä¾æ´å¼·å¤§çæè¡æ¯æã

##### **INSIGHT: Explainable Weakly-Supervised Medical Image Analysis**
2412.02012v1 by Wenbo Zhang, Junyu Chen, Christopher Kanan

Due to their large sizes, volumetric scans and whole-slide pathology images
(WSIs) are often processed by extracting embeddings from local regions and then
an aggregator makes predictions from this set. However, current methods require
post-hoc visualization techniques (e.g., Grad-CAM) and often fail to localize
small yet clinically crucial details. To address these limitations, we
introduce INSIGHT, a novel weakly-supervised aggregator that integrates heatmap
generation as an inductive bias. Starting from pre-trained feature maps,
INSIGHT employs a detection module with small convolutional kernels to capture
fine details and a context module with a broader receptive field to suppress
local false positives. The resulting internal heatmap highlights diagnostically
relevant regions. On CT and WSI benchmarks, INSIGHT achieves state-of-the-art
classification results and high weakly-labeled semantic segmentation
performance. Project website and code are available at:
https://zhangdylan83.github.io/ewsmia/

æè¦ï¼ç±æ¼é«ç©é¾å¤§ï¼é«ç©ææåå¨ç»çççåå (WSI) éå¸¸æééå¾å±é¨ååæ·ååµå¥å¼èçï¼ç¶å¾èåå¨ææ ¹æéçµè³æé²è¡é æ¸¬ãç¶èï¼ç®åçæ¹æ³éè¦äºå¾è¦è¦ºåæè¡ï¼ä¾å¦ Grad-CAMï¼ï¼èä¸å¾å¾ç¡æ³å®ä½éç¶ç´°å¾®ä½è¨åºä¸è³ééè¦çç´°ç¯ãçºäºè§£æ±ºéäºéå¶ï¼æåå¼å¥äº INSIGHTï¼éæ¯ä¸ç¨®æ°ç©çå¼±ç£ç£èåå¨ï¼å¯å°ç±åçææ´åçºæ­¸ç´åå·®ãINSIGHT å¾é åè¨ç·´å¥½çç¹å¾µåéå§ï¼æ¡ç¨å·æå°åå·ç©æ ¸çåµæ¸¬æ¨¡çµä¾æ·åç²¾ç´°çç´°ç¯ï¼ä¸¦æ¡ç¨å·æè¼å»£æ³æåéçå§å®¹æ¨¡çµä¾æå¶å±é¨èª¤å¤ãç¢ççå§é¨ç±åçªé¡¯äºè¨ºæ·ç¸éçååãå¨ CT å WSI åºæºä¸ï¼INSIGHT éå°äºæåé²çåé¡çµæï¼ä¸¦å·åé«åº¦å¼±æ¨è¨èªæåå²æè½ãå°æ¡ç¶²ç«åç¨å¼ç¢¼å¯æ¼ä¸åç¶²ååå¾ï¼
https://zhangdylan83.github.io/ewsmia/

##### **The use of large language models to enhance cancer clinical trial educational materials**
2412.01955v2 by Mingye Gao, Aman Varshney, Shan Chen, Vikram Goddla, Jack Gallifant, Patrick Doyle, Claire Novack, Maeve Dillon-Martin, Teresia Perkins, Xinrong Correia, Erik Duhaime, Howard Isenstein, Elad Sharon, Lisa Soleymani Lehmann, David Kozono, Brian Anthony, Dmitriy Dligach, Danielle S. Bitterman

Cancer clinical trials often face challenges in recruitment and engagement
due to a lack of participant-facing informational and educational resources.
This study investigated the potential of Large Language Models (LLMs),
specifically GPT4, in generating patient-friendly educational content from
clinical trial informed consent forms. Using data from ClinicalTrials.gov, we
employed zero-shot learning for creating trial summaries and one-shot learning
for developing multiple-choice questions, evaluating their effectiveness
through patient surveys and crowdsourced annotation. Results showed that
GPT4-generated summaries were both readable and comprehensive, and may improve
patients' understanding and interest in clinical trials. The multiple-choice
questions demonstrated high accuracy and agreement with crowdsourced
annotators. For both resource types, hallucinations were identified that
require ongoing human oversight. The findings demonstrate the potential of LLMs
"out-of-the-box" to support the generation of clinical trial education
materials with minimal trial-specific engineering, but implementation with a
human-in-the-loop is still needed to avoid misinformation risks.

æè¦ï¼ççè¨åºè©¦é©ç±æ¼ç¼ºä¹é¢ååèèçè³è¨åæè²è³æºï¼å¸¸å¸¸å¨æåååèæ¹é¢é¢è¨ææ°ãæ¬ç ç©¶æ¢è¨äºå¤§åèªè¨æ¨¡å (LLM)ï¼ç¹å¥æ¯ GPT4ï¼å¾è¨åºè©¦é©ç¥æåææ¸ä¸­ç¢çå°æ£èååçæè²å§å®¹çæ½åãæåä½¿ç¨ä¾èª ClinicalTrials.gov çè³æï¼æ¡ç¨é¶æ¬¡å­¸ç¿ä¾å»ºç«è©¦é©æè¦ï¼ä»¥åä¸æ¬¡å­¸ç¿ä¾éç¼å¤é¸é¡ï¼ä¸¦ééæ£èèª¿æ¥åç¾¤ç¾å¤åè¨»è§£ä¾è©ä¼°å¶æææ§ãçµæé¡¯ç¤ºï¼GPT4 çæçæè¦å·æå¯è®æ§åå¨é¢æ§ï¼ä¸¦ä¸å¯è½æé«æ£èå°è¨åºè©¦é©ççè§£åèè¶£ãå¤é¸é¡å±ç¤ºåºå¾é«çæºç¢ºåº¦ï¼ä¸¦ä¸èç¾¤ç¾å¤åè¨»è§£èéæå±è­ãå°æ¼éå©ç¨®è³æºé¡åï¼æåç¼ç¾äºéè¦æçºçäººå·¥ç£ç£çå¹»è¦ºãéäºç¼ç¾å±ç¤ºäº LLMãéç®±å³ç¨ãçæ½åï¼å¯ä»¥ç¨æå°çè©¦é©ç¹å®å·¥ç¨ä¾æ¯æ´è¨åºè©¦é©æè²ææçç¢çï¼ä½ä»éè¦æ¡ç¨æäººå¨è¿´è·¯ä¸­çå¯¦ä½ä¾é¿åé¯èª¤è³è¨çé¢¨éªã

##### **Recurrent Neural Network on PICTURE Model**
2412.01933v1 by Weihan Xu

Intensive Care Units (ICUs) provide critical care and life support for most
severely ill and injured patients in the hospital. With the need for ICUs
growing rapidly and unprecedentedly, especially during COVID-19, accurately
identifying the most critical patients helps hospitals to allocate resources
more efficiently and save more lives. The Predicting Intensive Care Transfers
and Other Unforeseen Events (PICTURE) model predicts patient deterioration by
separating those at high risk for imminent intensive care unit transfer,
respiratory failure, or death from those at lower risk. This study aims to
implement a deep learning model to benchmark the performance from the XGBoost
model, an existing model which has competitive results on prediction.

æè¦ï¼å è­·çæ¿ (ICU) æä¾éçç§è­·åçå½æ¯æï¼çµ¦äºé«é¢ä¸­çææå´éååå·æå´éçæ£èãç±æ¼å°å è­·çæ¿çéæ±å¿«éä¸ç©ºåå°å¢é·ï¼ç¹å¥æ¯å¨ COVID-19 æéï¼æºç¢ºæ¾åºçææå±æ¥çæ£èæå©æ¼é«é¢æ´ææå°åéè³æºä¸¦æ½ææ´å¤çå½ãé æ¸¬å è­·çæ¿è½è¨ºåå¶ä»ç¡æ³é è¦äºä»¶ (PICTURE) æ¨¡åééå°é¢è¨è¿«å¨çç«çå è­·çæ¿è½è¨ºãå¼å¸è¡°ç«­ææ­»äº¡çé«é¢¨éªæ£èèé¢¨éªè¼ä½çæ£èååéä¾ï¼é æ¸¬æ£èæ¡åãæ¬ç ç©¶æ¨å¨å¯¦ä½æ·±åº¦å­¸ç¿æ¨¡åï¼ä»¥åºæºå XGBoost æ¨¡åçæè½ï¼å¾èæ¯ä¸ç¨®å¨é æ¸¬æ¹é¢å·æç«¶ç­åçç¾ææ¨¡åã

##### **ECG-SleepNet: Deep Learning-Based Comprehensive Sleep Stage Classification Using ECG Signals**
2412.01929v1 by Poorya Aghaomidi, Ge Wang

Accurate sleep stage classification is essential for understanding sleep
disorders and improving overall health. This study proposes a novel three-stage
approach for sleep stage classification using ECG signals, offering a more
accessible alternative to traditional methods that often rely on complex
modalities like EEG. In Stages 1 and 2, we initialize the weights of two
networks, which are then integrated in Stage 3 for comprehensive
classification. In the first phase, we estimate key features using Feature
Imitating Networks (FINs) to achieve higher accuracy and faster convergence.
The second phase focuses on identifying the N1 sleep stage through the
time-frequency representation of ECG signals. Finally, the third phase
integrates models from the previous stages and employs a Kolmogorov-Arnold
Network (KAN) to classify five distinct sleep stages. Additionally, data
augmentation techniques, particularly SMOTE, are used in enhancing
classification capabilities for underrepresented stages like N1. Our results
demonstrate significant improvements in the classification performance, with an
overall accuracy of 80.79% an overall kappa of 0.73. The model achieves
specific accuracies of 86.70% for Wake, 60.36% for N1, 83.89% for N2, 84.85%
for N3, and 87.16% for REM. This study emphasizes the importance of weight
initialization and data augmentation in optimizing sleep stage classification
with ECG signals.

æè¦ï¼ç²¾æºçç¡ç åæåé¡å°æ¼äºè§£ç¡ç éç¤åæ¹åæ´é«å¥åº·è³ééè¦ãæ¬ç ç©¶æåºä¸åæ°çä¸éæ®µæ¹æ³ï¼ä½¿ç¨ ECG è¨èé²è¡ç¡ç åæåé¡ï¼æä¾äºä¸åæ´ææ¼åå¾çæ¿ä»£æ¹æ¡ï¼å³çµ±æ¹æ³éå¸¸ä¾è³´æ¼ EEG ç­è¤éçæ¨¡å¼ãå¨ç¬¬ 1 åç¬¬ 2 éæ®µï¼æååå§åå©åç¶²è·¯çæ¬éï¼ç¶å¾å¨ç¬¬ 3 éæ®µæ´åå®åä»¥é²è¡å¨é¢çåé¡ãå¨ç¬¬ä¸éæ®µï¼æåä½¿ç¨ç¹å¾µæ¨¡ä»¿ç¶²è·¯ (FIN) ä¼°è¨ééµç¹å¾µï¼ä»¥å¯¦ç¾æ´é«çæºç¢ºåº¦åæ´å¿«çæ¶æãç¬¬äºéæ®µå°æ³¨æ¼éé ECG è¨èçæé »è¡¨ç¤ºä¾è­å¥ N1 ç¡ç éæ®µãæå¾ï¼ç¬¬ä¸éæ®µæ´ååä¸éæ®µçæ¨¡åï¼ä¸¦æ¡ç¨ Kolmogorov-Arnold ç¶²è·¯ (KAN) ä¾åé¡äºåä¸åçç¡ç éæ®µãæ­¤å¤ï¼è³ææ´åæè¡ï¼ç¹å¥æ¯ SMOTEï¼ç¨æ¼å¢å¼·å° N1 ç­ä»£è¡¨æ§ä¸è¶³éæ®µçåé¡è½åãæåççµæè­æäºåé¡æè½æé¡¯èçæ¹åï¼æ´é«æºç¢ºåº¦çº 80.79%ï¼æ´é« kappa çº 0.73ãè©²æ¨¡åå°æ¸éãN1ãN2ãN3 å REM çç¹å®æºç¢ºåº¦åå¥çº 86.70%ã60.36%ã83.89%ã84.85% å 87.16%ãæ¬ç ç©¶å¼·èª¿äºæ¬éåå§ååè³ææ´åå¨ä½¿ç¨ ECG è¨èæä½³åç¡ç åæåé¡ä¸­çéè¦æ§ã

##### **Deep Guess acceleration for explainable image reconstruction in sparse-view CT**
2412.01703v1 by Elena Loli Piccolomini, Davide Evangelista, Elena Morotti

Sparse-view Computed Tomography (CT) is an emerging protocol designed to
reduce X-ray dose radiation in medical imaging. Traditional Filtered Back
Projection algorithm reconstructions suffer from severe artifacts due to sparse
data. In contrast, Model-Based Iterative Reconstruction (MBIR) algorithms,
though better at mitigating noise through regularization, are too
computationally costly for clinical use. This paper introduces a novel
technique, denoted as the Deep Guess acceleration scheme, using a trained
neural network both to quicken the regularized MBIR and to enhance the
reconstruction accuracy. We integrate state-of-the-art deep learning tools to
initialize a clever starting guess for a proximal algorithm solving a
non-convex model and thus computing an interpretable solution image in a few
iterations. Experimental results on real CT images demonstrate the Deep Guess
effectiveness in (very) sparse tomographic protocols, where it overcomes its
mere variational counterpart and many data-driven approaches at the state of
the art. We also consider a ground truth-free implementation and test the
robustness of the proposed framework to noise.

æè¦ï¼ç¨çè¦åé»è¦æ·å±¤ææ (CT) æ¯ä¸ç¨®æ°èçåå®ï¼æ¨å¨æ¸å°é«çå½±åä¸­ç X å°ç·åéè¼»å°ãå³çµ±çæ¿¾æ³¢ååæå½±æ¼ç®æ³éå»ºå ç¨çè³æèå°è´å´éçå½å½±ãç¸æ¯ä¹ä¸ï¼åºæ¼æ¨¡åçè¿­ä»£éå»º (MBIR) æ¼ç®æ³ï¼éç¶ééæ­£ååå¨æ¸è¼éè¨æ¹é¢è¡¨ç¾å¾æ´å¥½ï¼ä½å°æ¼è¨åºä½¿ç¨èè¨ï¼å¶è¨ç®ææ¬éé«ãæ¬æä»ç´¹äºä¸ç¨®åµæ°çæè¡ï¼ç¨±çº Deep Guess å éæ¹æ¡ï¼å®ä½¿ç¨è¨ç·´éçé¡ç¥ç¶ç¶²è·¯ä¾å éæ­£ååç MBIR ä¸¦å¢å¼·éå»ºæºç¢ºåº¦ãæåæ´åäºæåé²çæ·±åº¦å­¸ç¿å·¥å·ï¼çºæ±è§£éå¸æ¨¡åçè¿ç«¯æ¼ç®æ³åå§åä¸åè°æçèµ·å§çæ¸¬ï¼å¾èåå¨å¹¾æ¬¡è¿­ä»£ä¸­è¨ç®åºå¯è§£éçè§£å½±åãå¨çå¯¦ CT å½±åä¸çå¯¦é©çµæè­æäº Deep Guess å¨ï¼éå¸¸ï¼ç¨çæ·å±¤æå½±åå®ä¸­çæææ§ï¼å¨è©²åå®ä¸­ï¼å®åæäºå¶å®ç´çè®åå°æç©åè¨±å¤æåé²çè³æé©åæ¹æ³ãæåéèæ®äºç¡çå¯¦ä¾æçå¯¦ä½ï¼ä¸¦æ¸¬è©¦äºææåºçæ¶æ§å°éè¨çç©©å¥æ§ã

##### **Digital Epidemiology: Leveraging Social Media for Insight into Epilepsy and Mental Health**
2412.01692v1 by Liza Dahiya, Rachit Bagga

Social media platforms, particularly Reddit's r/Epilepsy community, offer a
unique perspective into the experiences of individuals with epilepsy (PWE) and
their caregivers. This study analyzes 57k posts and 533k comments to explore
key themes across demographics such as age, gender, and relationships. Our
findings highlight significant discussions on epilepsy-related challenges,
including depression (with 39.75\% of posts indicating severe symptoms),
driving restrictions, workplace concerns, and pregnancy-related issues in women
with epilepsy. We introduce a novel engagement metric, F(P), which incorporates
post length, sentiment scores, and readability to quantify community
interaction. This analysis underscores the importance of integrated care
addressing both neurological and mental health challenges faced by PWE. The
insights from this study inform strategies for targeted support and awareness
interventions.

æè¦ï¼ç¤¾ç¾¤åªé«å¹³å°ï¼ç¹å¥æ¯ Reddit ç r/Epilepsy ç¤¾ç¾¤ï¼æä¾äºç²çæ£è (PWE) åå¶ç§é¡§èçç¶é©ç¨ç¹è§é»ãéé ç ç©¶åæäº 57k åè²¼æå 533k åçè¨ï¼æ¢è¨ä¸åäººå£çµ±è¨è³æï¼ä¾å¦å¹´é½¡ãæ§å¥åéä¿ï¼ä¸­çä¸»è¦ä¸»é¡ãæåçç¼ç¾å¼·èª¿äºéæ¼ç²çç¸éææ°çéè¦è¨è«ï¼åæ¬æé¬±çï¼39.75% çè²¼æè¡¨ç¤ºæå´éççï¼ãé§é§éå¶ãè·å ´åé¡åç²çå¥³æ§çæ·å­ç¸éåé¡ãæåå¼é²äºä¸é åµæ°çåèåº¦ææ¨ F(P)ï¼å®çµåäºè²¼æé·åº¦ãæç·åæ¸åå¯è®æ§ï¼ä»¥éåç¤¾ç¾¤äºåãéé åæå¼·èª¿äºæ´åæ§ç§è­·çéè¦æ§ï¼å®è½åæè§£æ±º PWE é¢è¨çç¥ç¶åå¿çå¥åº·ææ°ãéé ç ç©¶çè¦è§£æä¾äºéå°æ§æ¯æåæè­ä»å¥ç­ç¥ã

##### **Medchain: Bridging the Gap Between LLM Agents and Clinical Practice through Interactive Sequential Benchmarking**
2412.01605v1 by Jie Liu, Wenxuan Wang, Zizhan Ma, Guolin Huang, Yihang SU, Kao-Jung Chang, Wenting Chen, Haoliang Li, Linlin Shen, Michael Lyu

Clinical decision making (CDM) is a complex, dynamic process crucial to
healthcare delivery, yet it remains a significant challenge for artificial
intelligence systems. While Large Language Model (LLM)-based agents have been
tested on general medical knowledge using licensing exams and knowledge
question-answering tasks, their performance in the CDM in real-world scenarios
is limited due to the lack of comprehensive testing datasets that mirror actual
medical practice. To address this gap, we present MedChain, a dataset of 12,163
clinical cases that covers five key stages of clinical workflow. MedChain
distinguishes itself from existing benchmarks with three key features of
real-world clinical practice: personalization, interactivity, and
sequentiality. Further, to tackle real-world CDM challenges, we also propose
MedChain-Agent, an AI system that integrates a feedback mechanism and a
MCase-RAG module to learn from previous cases and adapt its responses.
MedChain-Agent demonstrates remarkable adaptability in gathering information
dynamically and handling sequential clinical tasks, significantly outperforming
existing approaches. The relevant dataset and code will be released upon
acceptance of this paper.

æè¦ï¼è¨åºæ±ºç­å¶å® (CDM) æ¯ä¸åè¤éãåæçéç¨ï¼å°æ¼é«çä¿å¥çæä¾è³ééè¦ï¼ç¶èå°æ¼äººå·¥æºæ§ç³»çµ±ä¾èªªï¼å®ä»ç¶æ¯ä¸é éå¤§çææ°ãéç¶å¤§åèªè¨æ¨¡å (LLM) åºç¤ä»£çå·²ä½¿ç¨å·ç§èè©¦åç¥è­åç­ä»»åå°ä¸è¬é«çç¥è­é²è¡äºæ¸¬è©¦ï¼ä½å®åå¨å¯¦éå ´æ¯ä¸­ç CDM ä¸­çè¡¨ç¾åå°ç¼ºä¹åæ å¯¦éé«çå¯¦åçç¶åæ¸¬è©¦è³æéçéå¶ãçºäºè§£æ±ºéåå·®è·ï¼æåæåºäº MedChainï¼éæ¯ä¸ååå« 12,163 åè¨åºæ¡ä¾çè³æéï¼æ¶µèäºè¨åºå·¥ä½æµç¨çäºåééµéæ®µãMedChain ä»¥ç¾å¯¦ä¸çè¨åºå¯¦åçä¸åééµç¹å¾µåå¥æ¼ç¾æçåºæºï¼åäººåãäºåæ§åé åºæ§ãæ­¤å¤ï¼çºäºæå°ç¾å¯¦ä¸çç CDM ææ°ï¼æåéæåºäº MedChain-Agentï¼éæ¯ä¸åæ´åäºåé¥æ©å¶å MCase-RAG æ¨¡çµçäººå·¥æºæ§ç³»çµ±ï¼ç¨æ¼å¾ååçæ¡ä¾ä¸­å­¸ç¿ä¸¦èª¿æ´å¶åæãMedChain-Agent å¨åææ¶éè³è¨åèçé åºæ§è¨åºä»»åæ¹é¢å±ç¾äºé¡¯èçé©ææ§ï¼é¡¯èåªæ¼ç¾ææ¹æ³ãç¸éçè³æéåç¨å¼ç¢¼å°å¨æ¬æè¢«æ¥åå¾ç¼å¸ã

##### **NCDD: Nearest Centroid Distance Deficit for Out-Of-Distribution Detection in Gastrointestinal Vision**
2412.01590v1 by Sandesh Pokhrel, Sanjay Bhandari, Sharib Ali, Tryphon Lambrou, Anh Nguyen, Yash Raj Shrestha, Angus Watson, Danail Stoyanov, Prashnna Gyawali, Binod Bhattarai

The integration of deep learning tools in gastrointestinal vision holds the
potential for significant advancements in diagnosis, treatment, and overall
patient care. A major challenge, however, is these tools' tendency to make
overconfident predictions, even when encountering unseen or newly emerging
disease patterns, undermining their reliability.
  We address this critical issue of reliability by framing it as an
out-of-distribution (OOD) detection problem, where previously unseen and
emerging diseases are identified as OOD examples. However, gastrointestinal
images pose a unique challenge due to the overlapping feature representations
between in- Distribution (ID) and OOD examples. Existing approaches often
overlook this characteristic, as they are primarily developed for natural image
datasets, where feature distinctions are more apparent. Despite the overlap, we
hypothesize that the features of an in-distribution example will cluster closer
to the centroids of their ground truth class, resulting in a shorter distance
to the nearest centroid. In contrast, OOD examples maintain an equal distance
from all class centroids. Based on this observation, we propose a novel
nearest-centroid distance deficit (NCCD) score in the feature space for
gastrointestinal OOD detection.
  Evaluations across multiple deep learning architectures and two publicly
available benchmarks, Kvasir2 and Gastrovision, demonstrate the effectiveness
of our approach compared to several state-of-the-art methods. The code and
implementation details are publicly available at:
https://github.com/bhattarailab/NCDD

æè¦ï¼æ·±åº¦å­¸ç¿å·¥å·æ´åå¨èè¸éè¦è¦ºä¸­ï¼å¨è¨ºæ·ãæ²»çåæ´é«çäººç§è­·æ¹é¢å·æé¡¯èé²å±çæ½åãç¶èï¼ä¸åéå¤§çææ°æ¯ï¼éäºå·¥å·å¾åæ¼ååºéåº¦èªä¿¡çé æ¸¬ï¼å³ä½¿å¨éå°æªè¦ææ°åºç¾çç¾çæ¨¡å¼æï¼ä¹æç ´å£å¶å¯é æ§ã
æåå°æ­¤å¯é æ§çééµåé¡ï¼æ¶æ§çºä¸åç°å¸¸åä½ (OOD) åµæ¸¬åé¡ï¼å¶ä¸­ä»¥åæªè¦åæ°åºç¾çç¾çè¢«è¦çº OOD ç¯ä¾ãç¶èï¼ç±æ¼åä½å§ (ID) å OOD ç¯ä¾ä¹éçéçç¹å¾µè¡¨ç¤ºï¼èè¸éå½±åæ§æäºä¸é ç¨ç¹çææ°ãç¾æçæ¹æ³éå¸¸å¿½ç¥æ­¤ç¹æ§ï¼å çºå®åä¸»è¦æ¯çºèªç¶å½±åè³æéèéç¼ï¼å¶ä¸­ç¹å¾µåå¥è¼çºæé¡¯ãåç®¡æéçï¼æååè¨­åä½å§ç¯ä¾çç¹å¾µæèéå¨å¶çå¯¦é¡å¥çè³ªå¿éè¿ï¼å°è´å°æè¿è³ªå¿çè·é¢è¼ç­ãç¸åå°ï¼OOD ç¯ä¾èææé¡å¥è³ªå¿çè·é¢ç¸ç­ãåºæ¼æ­¤è§å¯ï¼æåå¨ç¹å¾µç©ºéä¸­æåºäºä¸åç¨æ¼èè¸é OOD åµæ¸¬çæ°ç©æè¿è³ªå¿è·é¢å·® (NCCD) åæ¸ã
å¨å¤åæ·±åº¦å­¸ç¿æ¶æ§åå©åå¬éåºæº Kvasir2 å Gastrovision ä¸­çè©ä¼°ï¼è­æäºæåçæ¹æ³èå¹¾ç¨®æåé²çæ¹æ³ç¸æ¯çæææ§ãç¨å¼ç¢¼åå¯¦ä½ç´°ç¯å¬éæ¼ï¼
https://github.com/bhattarailab/NCDD

##### **MambaU-Lite: A Lightweight Model based on Mamba and Integrated Channel-Spatial Attention for Skin Lesion Segmentation**
2412.01405v1 by Thi-Nhu-Quynh Nguyen, Quang-Huy Ho, Duy-Thai Nguyen, Hoang-Minh-Quang Le, Van-Truong Pham, Thi-Thao Tran

Early detection of skin abnormalities plays a crucial role in diagnosing and
treating skin cancer. Segmentation of affected skin regions using AI-powered
devices is relatively common and supports the diagnostic process. However,
achieving high performance remains a significant challenge due to the need for
high-resolution images and the often unclear boundaries of individual lesions.
At the same time, medical devices require segmentation models to have a small
memory foot-print and low computational cost. Based on these requirements, we
introduce a novel lightweight model called MambaU-Lite, which combines the
strengths of Mamba and CNN architectures, featuring just over 400K parameters
and a computational cost of more than 1G flops. To enhance both global context
and local feature extraction, we propose the P-Mamba block, a novel component
that incorporates VSS blocks along-side multiple pooling layers, enabling the
model to effectively learn multiscale features and enhance segmentation
performance. We evaluate the model's performance on two skin datasets, ISIC2018
and PH2, yielding promising results. Our source code will be made publicly
available at: https://github.com/nqnguyen812/MambaU-Lite.

æè¦ï¼æ©æç®èç°å¸¸åµæ¸¬å¨è¨ºæ·åæ²»çç®èçä¸­æ®æ¼èè³ééè¦çè§è²ãä½¿ç¨ AI é©åçè£ç½®åå²åå½±é¿çç®èååç¸å°å¸¸è¦ï¼ä¸¦æ¯æ´è¨ºæ·æµç¨ãç¶èï¼ç±æ¼éè¦é«è§£æåº¦å½±åååå¥çç¶éå¸¸ä¸æç¢ºçéçï¼è¦éæé«æ§è½ä»æ¯ä¸é éå¤§çææ°ãåæï¼é«çè£ç½®è¦æ±åå²æ¨¡åå·æå°çè¨æ¶é«ä½ç¨ç©ºéåä½éç®ææ¬ãåºæ¼éäºéæ±ï¼æåå¼é²äºä¸ç¨®åçº MambaU-Lite çæ°åè¼éç´æ¨¡åï¼å®çµåäº Mamba å CNN æ¶æ§çåªé»ï¼ç¹é»æ¯åªæè¶é 400K ååæ¸åè¶é 1G flops çéç®ææ¬ãçºäºå¢å¼·å¨å±èæ¯åå±é¨ç¹å¾µèåï¼æåæåºäº P-Mamba å¡ï¼éæ¯ä¸åæ°ççµæé¨åï¼å®çµåäº VSS å¡åå¤åæ± åå±¤ï¼ä½¿æ¨¡åè½å¤ ææå°å­¸ç¿å¤å°ºåº¦ç¹å¾µä¸¦å¢å¼·åå²æ§è½ãæåå¨å©åç®èè³æé ISIC2018 å PH2 ä¸è©ä¼°äºæ¨¡åçæ§è½ï¼ç¢çäºæå¸æççµæãæåçåå§ç¨å¼ç¢¼å°å¬éæ¼ï¼https://github.com/nqnguyen812/MambaU-Liteã

##### **Su-RoBERTa: A Semi-supervised Approach to Predicting Suicide Risk through Social Media using Base Language Models**
2412.01353v1 by Chayan Tank, Shaina Mehta, Sarthak Pol, Vinayak Katoch, Avinash Anand, Raj Jaiswal, Rajiv Ratn Shah

In recent times, more and more people are posting about their mental states
across various social media platforms. Leveraging this data, AI-based systems
can be developed that help in assessing the mental health of individuals, such
as suicide risk. This paper is a study done on suicidal risk assessments using
Reddit data leveraging Base language models to identify patterns from social
media posts. We have demonstrated that using smaller language models, i.e.,
less than 500M parameters, can also be effective in contrast to LLMs with
greater than 500M parameters. We propose Su-RoBERTa, a fine-tuned RoBERTa on
suicide risk prediction task that utilized both the labeled and unlabeled
Reddit data and tackled class imbalance by data augmentation using GPT-2 model.
Our Su-RoBERTa model attained a 69.84% weighted F1 score during the Final
evaluation. This paper demonstrates the effectiveness of Base language models
for the analysis of the risk factors related to mental health with an efficient
computation pipeline

æè¦ï¼è¿ä¾ï¼æä¾æå¤äººæ¼åç¨®ç¤¾ç¾¤åªé«å¹³å°ç¼å¸å¶å¿ççæãå©ç¨æ­¤è³æï¼å¯ä»¥éç¼åºåºæ¼ AI çç³»çµ±ï¼ç¨æ¼è©ä¼°åäººçå¿çå¥åº·ï¼ä¾å¦èªæ®ºé¢¨éªãæ¬ææ¯ä¸é éå°èªæ®ºé¢¨éªè©ä¼°çç ç©¶ï¼å©ç¨ Reddit è³æï¼ä¸¦å©ç¨åºç¤èªè¨æ¨¡åä¾è­å¥ç¤¾ç¾¤åªé«è²¼æçæ¨¡å¼ãæåå·²ç¶è­æï¼ä½¿ç¨è¼å°çèªè¨æ¨¡åï¼å³å°æ¼ 5 åååæ¸ï¼ä¹å¯ä»¥ææï¼éèåæ¸å¤§æ¼ 5 ååç LLM ç¸æ¯ãæåæåº Su-RoBERTaï¼ä¸åéå°èªæ®ºé¢¨éªé æ¸¬ä»»åé²è¡å¾®èª¿ç RoBERTaï¼å®å©ç¨æ¨è¨åæªæ¨è¨ç Reddit è³æï¼ä¸¦ééä½¿ç¨ GPT-2 æ¨¡åé²è¡è³ææ´åä¾è§£æ±ºé¡å¥ä¸å¹³è¡¡çåé¡ãæåç Su-RoBERTa æ¨¡åå¨æçµè©ä¼°æéç²å¾äº 69.84% çå æ¬ F1 åæ¸ãæ¬æè­æäºåºç¤èªè¨æ¨¡åå¨åæèå¿çå¥åº·ç¸éçé¢¨éªå å­æ¹é¢çæææ§ï¼ä¸¦å·åé«æçéç®ç®¡é

##### **Multimodal Medical Disease Classification with LLaMA II**
2412.01306v1 by Christian Gapp, Elias Tappeiner, Martin Welk, Rainer Schubert

Medical patient data is always multimodal. Images, text, age, gender,
histopathological data are only few examples for different modalities in this
context. Processing and integrating this multimodal data with deep learning
based methods is of utmost interest due to its huge potential for medical
procedure such as diagnosis and patient treatment planning. In this work we
retrain a multimodal transformer-based model for disease classification. To
this end we use the text-image pair dataset from OpenI consisting of 2D chest
X-rays associated with clinical reports. Our focus is on fusion methods for
merging text and vision information extracted from medical datasets. Different
architecture structures with a LLaMA II backbone model are tested. Early fusion
of modality specific features creates better results with the best model
reaching 97.10% mean AUC than late fusion from a deeper level of the
architecture (best model: 96.67% mean AUC). Both outperform former
classification models tested on the same multimodal dataset. The newly
introduced multimodal architecture can be applied to other multimodal datasets
with little effort and can be easily adapted for further research, especially,
but not limited to, the field of medical AI.

æè¦ï¼é«ççæ£è³æç¸½æ¯å¤æ¨¡æçãå½±åãæå­ãå¹´é½¡ãæ§å¥ãçµç¹ççå­¸è³æåªæ¯æ­¤èçµ¡ä¸ä¸åæ¨¡æçå¹¾åä¾å­ãèçåæ´åéäºå¤æ¨¡æè³æï¼ä¸¦ä½¿ç¨æ·±åº¦å­¸ç¿æ¹æ³ï¼ç±æ¼å¶å¨é«çç¨åºï¼ä¾å¦è¨ºæ·åçæ£æ²»çè¨ç«ï¼çé¾å¤§æ½åï¼å æ­¤è³ééè¦ãå¨éé å·¥ä½ä¸­ï¼æåéæ°è¨ç·´ä¸åå¤æ¨¡æTransformeråºç¤æ¨¡åï¼ç¨æ¼ç¾çåé¡ãçºæ­¤ï¼æåä½¿ç¨ä¾èª OpenI çæå­å½±åéå°è³æéï¼å¶ä¸­åå«èè¨åºå ±åç¸éç 2D è¸é¨ X åãæåçéé»å¨æ¼èåæ¹æ³ï¼ç¨æ¼åä½µå¾é«çè³æéæåçæå­åå½±åè³è¨ãæ¸¬è©¦äºå·æ LLaMA II ä¸»å¹¹æ¨¡åçä¸åæ¶æ§çµæ§ãç¹å®æ¼æ¨¡æç¹å¾µçæ©æèåæç¢çæ´å¥½ççµæï¼æä½³æ¨¡åéå° 97.10% çå¹³å AUCï¼é«æ¼å¾æ¶æ§æ´æ·±å±¤æ¬¡é²è¡çå¾æèåï¼æä½³æ¨¡åï¼96.67% çå¹³å AUCï¼ãå©èé½åªæ¼å¨ç¸åå¤æ¨¡æè³æéä¸æ¸¬è©¦çååé¡æ¨¡åãæ°æ¨åºçå¤æ¨¡ææ¶æ§å¯ä»¥æ¯«ä¸è²»åå°æç¨æ¼å¶ä»å¤æ¨¡æè³æéï¼ä¸¦ä¸å¯ä»¥è¼é¬æ¹ç·¨ä»¥é²è¡é²ä¸æ­¥çç ç©¶ï¼ç¹å¥æ¯ï¼ä½ä¸éæ¼ï¼é«ç AI é åã

##### **Best Practices for Large Language Models in Radiology**
2412.01233v1 by Christian Bluethgen, Dave Van Veen, Cyril Zakka, Katherine Link, Aaron Fanous, Roxana Daneshjou, Thomas Frauenfelder, Curtis Langlotz, Sergios Gatidis, Akshay Chaudhari

At the heart of radiological practice is the challenge of integrating complex
imaging data with clinical information to produce actionable insights. Nuanced
application of language is key for various activities, including managing
requests, describing and interpreting imaging findings in the context of
clinical data, and concisely documenting and communicating the outcomes. The
emergence of large language models (LLMs) offers an opportunity to improve the
management and interpretation of the vast data in radiology. Despite being
primarily general-purpose, these advanced computational models demonstrate
impressive capabilities in specialized language-related tasks, even without
specific training. Unlocking the potential of LLMs for radiology requires basic
understanding of their foundations and a strategic approach to navigate their
idiosyncrasies. This review, drawing from practical radiology and machine
learning expertise and recent literature, provides readers insight into the
potential of LLMs in radiology. It examines best practices that have so far
stood the test of time in the rapidly evolving landscape of LLMs. This includes
practical advice for optimizing LLM characteristics for radiology practices
along with limitations, effective prompting, and fine-tuning strategies.

æè¦ï¼æ¾å°å­¸å¯¦åçæ ¸å¿ææ°ï¼å¨æ¼æ´åè¤éçå½±åè³æèè¨åºè³è¨ï¼ä»¥ç¢çå¯è¡çè¦è§£ãèªè¨çç´°ç·»éç¨æ¯åç¨®æ´»åçééµï¼åæ¬ç®¡çè«æ±ãæè¿°åè§£è®å½±åçµæçè¨åºè³æï¼ä»¥åç°¡æ½å°è¨éåå³éçµæãå¤§åèªè¨æ¨¡å (LLM) çåºç¾ï¼æä¾äºä¸åæ©æä¾æ¹åæ¾å°å­¸ä¸­å¤§éè³æçç®¡çåè§£è®ãåç®¡ä¸»è¦æ¯ä¸è¬ç¨éï¼éäºåé²çè¨ç®æ¨¡åå¨å°æ¥­çèªè¨ç¸éä»»åä¸­å±ç¾åºä»¤äººå°è±¡æ·±å»çè½åï¼å³ä½¿æ²æç¹å®çè¨ç·´ãè¦è§£é LLM å¨æ¾å°å­¸ä¸­çæ½åï¼éè¦åºæ¬äºè§£å¶åºç¤ï¼ä»¥åæå°å¶ç¨ç¹ä¹èçç­ç¥æ§æ¹æ³ãéç¯è©è«å¾å¯¦åæ¾å°å­¸åæ©å¨å­¸ç¿å°æ¥­ç¥è­ä»¥åè¿ææç»ä¸­æ±²åï¼çºè®èæä¾ LLM å¨æ¾å°å­¸ä¸­çæ½åçè¦è§£ãå®æª¢è¦äºè¿ä»çºæ­¢å¨ LLM å¿«éæ¼è®çé åä¸­ç¶å¾èµ·æéèé©çæä½³å¯¦åãéåæ¬éå°æ¾å°å­¸å¯¦åæä½³å LLM ç¹æ§çå¯¦åå»ºè­°ï¼ä»¥åéå¶ãææçæç¤ºåå¾®èª¿ç­ç¥ã

##### **Object Tracking in a $360^o$ View: A Novel Perspective on Bridging the Gap to Biomedical Advancements**
2412.01119v1 by Mojtaba S. Fazli, Shannon Quinn

Object tracking is a fundamental tool in modern innovation, with applications
in defense systems, autonomous vehicles, and biomedical research. It enables
precise identification, monitoring, and spatiotemporal analysis of objects
across sequential frames, providing insights into dynamic behaviors. In cell
biology, object tracking is vital for uncovering cellular mechanisms, such as
migration, interactions, and responses to drugs or pathogens. These insights
drive breakthroughs in understanding disease progression and therapeutic
interventions.
  Over time, object tracking methods have evolved from traditional
feature-based approaches to advanced machine learning and deep learning
frameworks. While classical methods are reliable in controlled settings, they
struggle in complex environments with occlusions, variable lighting, and high
object density. Deep learning models address these challenges by delivering
greater accuracy, adaptability, and robustness.
  This review categorizes object tracking techniques into traditional,
statistical, feature-based, and machine learning paradigms, with a focus on
biomedical applications. These methods are essential for tracking cells and
subcellular structures, advancing our understanding of health and disease. Key
performance metrics, including accuracy, efficiency, and adaptability, are
discussed. The paper explores limitations of current methods and highlights
emerging trends to guide the development of next-generation tracking systems
for biomedical research and broader scientific domains.

æè¦ï¼ç©ä»¶è¿½è¹¤æ¯ç¾ä»£åµæ°ä¸­çä¸é åºæ¬å·¥å·ï¼æç¨æ¼åé²ç³»çµ±ãèªåé§é§è»è¼åçç©é«å­¸ç ç©¶ä¸­ãå®è½ç²¾æºå°è¾¨è­ãç£æ§åæç©ºåæé£çºç«é¢ä¸­çç©ä»¶ï¼æä¾åæè¡çºçè¦è§£ãå¨ç´°èçç©å­¸ä¸­ï¼ç©ä»¶è¿½è¹¤å°æ¼æ­é²ç´°èæ©å¶è³ééè¦ï¼ä¾å¦é·ç§»ãäº¤äºä½ç¨åå°è¥ç©æçåé«çåæãéäºè¦è§£æ¨åäºå°ç¾çé²ç¨åæ²»çå¹²é ççè§£ççªç ´ã
é¨èæéçæ¨ç§»ï¼ç©ä»¶è¿½è¹¤æ¹æ³å·²å¾å³çµ±çåºæ¼ç¹å¾µçæ¹æ³æ¼è®çºåé²çæ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿æ¶æ§ãéç¶å³çµ±æ¹æ³å¨åæ§ç°å¢ä¸­æ¯å¯é çï¼ä½å®åå¨æé®æãåç·è®ååç©ä»¶å¯åº¦é«çè¤éç°å¢ä¸­æéå°å°é£ãæ·±åº¦å­¸ç¿æ¨¡åééæä¾æ´é«çæºç¢ºæ§ãé©ææ§åé­¯æ£æ§ä¾æå°éäºææ°ã
æ¬ç¶è¿°å°ç©ä»¶è¿½è¹¤æè¡åçºå³çµ±ãçµ±è¨ãåºæ¼ç¹å¾µåæ©å¨å­¸ç¿ç¯ä¾ï¼éé»éæ³¨çç©é«å­¸æç¨ãéäºæ¹æ³å°æ¼è¿½è¹¤ç´°èåäºç´°èçµæ§è³ééè¦ï¼ä¿é²äºæåå°å¥åº·åç¾çççè§£ãè¨è«äºééµçæè½ææ¨ï¼åæ¬æºç¢ºæ§ãæçåé©ææ§ãæ¬ææ¢è¨äºç¶åæ¹æ³çå±éæ§ï¼ä¸¦éé»ä»ç´¹äºæ°èè¶¨å¢ï¼ä»¥æå°ä¸ä¸ä»£çç©é«å­¸ç ç©¶åæ´å»£æ³çç§å­¸é åè¿½è¹¤ç³»çµ±çéç¼ã

##### **Evaluating Automated Radiology Report Quality through Fine-Grained Phrasal Grounding of Clinical Findings**
2412.01031v1 by Razi Mahmood, Pingkun Yan, Diego Machado Reyes, Ge Wang, Mannudeep K. Kalra, Parisa Kaviani, Joy T. Wu, Tanveer Syeda-Mahmood

Several evaluation metrics have been developed recently to automatically
assess the quality of generative AI reports for chest radiographs based only on
textual information using lexical, semantic, or clinical named entity
recognition methods. In this paper, we develop a new method of report quality
evaluation by first extracting fine-grained finding patterns capturing the
location, laterality, and severity of a large number of clinical findings. We
then performed phrasal grounding to localize their associated anatomical
regions on chest radiograph images. The textual and visual measures are then
combined to rate the quality of the generated reports. We present results that
compare this evaluation metric with other textual metrics on a gold standard
dataset derived from the MIMIC collection and show its robustness and
sensitivity to factual errors.

æè¦ï¼æè¿å·²å¼ååºå ç§è¯ä¼°ææ ï¼ä»¥ä»ä½¿ç¨è¯æ±ãè¯­ä¹æä¸´åºå½åå®ä½è¯å«æ¹æ³ï¼æ ¹æ®ææ¬ä¿¡æ¯èªå¨è¯ä¼°è¸é¨ X åçççæå¼ AI æ¥åçè´¨éãå¨æ¬æä¸­ï¼æä»¬å¼åäºä¸ç§æ°çæ¥åè´¨éè¯ä¼°æ¹æ³ï¼é¦åæåç»ç²åº¦çåç°æ¨¡å¼ï¼ææå¤§éä¸´åºåç°çä½ç½®ãä¾§åæ§åä¸¥éæ§ãç¶åï¼æä»¬æ§è¡ç­è¯­æ¥å°ä»¥å®ä½å¶å¨è¸é¨ X åçå¾åä¸çç¸å³è§£ååºåãç¶åå°ææ¬åè§è§æµéå¼ç»åèµ·æ¥ï¼å¯¹çæçæ¥åçè´¨éè¿è¡è¯åãæä»¬å±ç¤ºäºå°æ­¤è¯ä¼°ææ ä¸å¶ä»ææ¬ææ å¨ä» MIMIC éåä¸­å¾åºçé»éæ åæ°æ®éä¸çæ¯è¾ç»æï¼å¹¶å±ç¤ºäºå¶å¯¹äºå®éè¯¯çç¨³å¥æ§åæææ§ã

##### **Generative Language Models Potential for Requirement Engineering Applications: Insights into Current Strengths and Limitations**
2412.00959v1 by Summra Saleem, Muhammad Nabeel Asim, Ludger Van Elst, Andreas Dengel

Traditional language models have been extensively evaluated for software
engineering domain, however the potential of ChatGPT and Gemini have not been
fully explored. To fulfill this gap, the paper in hand presents a comprehensive
case study to investigate the potential of both language models for development
of diverse types of requirement engineering applications. It deeply explores
impact of varying levels of expert knowledge prompts on the prediction
accuracies of both language models. Across 4 different public benchmark
datasets of requirement engineering tasks, it compares performance of both
language models with existing task specific machine/deep learning predictors
and traditional language models. Specifically, the paper utilizes 4 benchmark
datasets; Pure (7,445 samples, requirements extraction),PROMISE (622 samples,
requirements classification), REQuestA (300 question answer (QA) pairs) and
Aerospace datasets (6347 words, requirements NER tagging). Our experiments
reveal that, in comparison to ChatGPT, Gemini requires more careful prompt
engineering to provide accurate predictions. Moreover, across requirement
extraction benchmark dataset the state-of-the-art F1-score is 0.86 while
ChatGPT and Gemini achieved 0.76 and 0.77,respectively. The State-of-the-art
F1-score on requirements classification dataset is 0.96 and both language
models 0.78. In name entity recognition (NER) task the state-of-the-art
F1-score is 0.92 and ChatGPT managed to produce 0.36, and Gemini 0.25.
Similarly, across question answering dataset the state-of-the-art F1-score is
0.90 and ChatGPT and Gemini managed to produce 0.91 and 0.88 respectively. Our
experiments show that Gemini requires more precise prompt engineering than
ChatGPT. Except for question-answering, both models under-perform compared to
current state-of-the-art predictors across other tasks.

æè¦ï¼å³çµ±èªè¨æ¨¡åå·²å»£æ³è©ä¼°è»é«å·¥ç¨é åï¼ä½ ChatGPT å Gemini çæ½åå°æªè¢«å®å¨æ¢ç´¢ãçºäºå¡«è£éåå·®è·ï¼æ¬ææåºäºå¨é¢çæ¡ä¾ç ç©¶ï¼ä»¥æ¢è¨éå©ç¨®èªè¨æ¨¡åå¨éç¼åç¨®éæ±å·¥ç¨æç¨ç¨å¼æ¹é¢çæ½åãå®æ·±å¥æ¢è¨äºä¸åå±¤ç´å°å®¶ç¥è­æç¤ºå°éå©ç¨®èªè¨æ¨¡åé æ¸¬ç²¾åº¦çå½±é¿ãå¨ 4 åä¸åçéæ±å·¥ç¨ä»»åå¬å±åºæºè³æéï¼å®æ¯è¼äºéå©ç¨®èªè¨æ¨¡åèç¾æä»»åç¹å®æ©å¨/æ·±åº¦å­¸ç¿é æ¸¬å¨åå³çµ±èªè¨æ¨¡åçæè½ãå·é«ä¾èªªï¼æ¬æå©ç¨ 4 ååºæºè³æéï¼Pureï¼7,445 åæ¨£æ¬ï¼éæ±èåï¼ãPROMISEï¼622 åæ¨£æ¬ï¼éæ±åé¡ï¼ãREQuestAï¼300 ååç­ (QA) å°ï¼åèªå¤ªè³æéï¼6347 åå­ï¼éæ± NER æ¨è¨ï¼ãæåçå¯¦é©é¡¯ç¤ºï¼è ChatGPT ç¸æ¯ï¼Gemini éè¦æ´ä»ç´°çæç¤ºå·¥ç¨æè½æä¾æºç¢ºçé æ¸¬ãæ­¤å¤ï¼å¨éæ±èååºæºè³æéï¼æåé²ç F1 åæ¸çº 0.86ï¼è ChatGPT å Gemini åå¥éå° 0.76 å 0.77ãéæ±åé¡è³æéçæåé² F1 åæ¸çº 0.96ï¼èéå©ç¨®èªè¨æ¨¡åé½çº 0.78ãå¨å½åå¯¦é«è­å¥ (NER) ä»»åä¸­ï¼æåé²ç F1 åæ¸çº 0.92ï¼è ChatGPT ç¢ç 0.36ï¼Gemini ç¢ç 0.25ãé¡ä¼¼å°ï¼å¨åç­è³æéï¼æåé²ç F1 åæ¸çº 0.90ï¼è ChatGPT å Gemini åå¥ç¢ç 0.91 å 0.88ãæåçå¯¦é©è¡¨æï¼Gemini éè¦æ¯ ChatGPT æ´ç²¾ç¢ºçæç¤ºå·¥ç¨ãé¤äºåç­ä¹å¤ï¼éå©åæ¨¡åå¨å¶ä»ä»»åçè¡¨ç¾é½ä½æ¼ç®åçææ°é æ¸¬å¨ã

##### **TSUBF-Net: Trans-Spatial UNet-like Network with Bi-direction Fusion for Segmentation of Adenoid Hypertrophy in CT**
2412.00787v1 by Rulin Zhou, Yingjie Feng, Guankun Wang, Xiaopin Zhong, Zongze Wu, Qiang Wu, Xi Zhang

Adenoid hypertrophy stands as a common cause of obstructive sleep
apnea-hypopnea syndrome in children. It is characterized by snoring, nasal
congestion, and growth disorders. Computed Tomography (CT) emerges as a pivotal
medical imaging modality, utilizing X-rays and advanced computational
techniques to generate detailed cross-sectional images. Within the realm of
pediatric airway assessments, CT imaging provides an insightful perspective on
the shape and volume of enlarged adenoids. Despite the advances of deep
learning methods for medical imaging analysis, there remains an emptiness in
the segmentation of adenoid hypertrophy in CT scans. To address this research
gap, we introduce TSUBF-Nett (Trans-Spatial UNet-like Network based on
Bi-direction Fusion), a 3D medical image segmentation framework. TSUBF-Net is
engineered to effectively discern intricate 3D spatial interlayer features in
CT scans and enhance the extraction of boundary-blurring features. Notably, we
propose two innovative modules within the U-shaped network architecture:the
Trans-Spatial Perception module (TSP) and the Bi-directional Sampling
Collaborated Fusion module (BSCF).These two modules are in charge of operating
during the sampling process and strategically fusing down-sampled and
up-sampled features, respectively. Furthermore, we introduce the Sobel loss
term, which optimizes the smoothness of the segmentation results and enhances
model accuracy. Extensive 3D segmentation experiments are conducted on several
datasets. TSUBF-Net is superior to the state-of-the-art methods with the lowest
HD95: 7.03, IoU:85.63, and DSC: 92.26 on our own AHSD dataset. The results in
the other two public datasets also demonstrate that our methods can robustly
and effectively address the challenges of 3D segmentation in CT scans.

æè¦ï¼èºæ¨£é«è¥å¤§æ¯åç«¥é»å¡æ§ç¡ç å¼å¸ä¸­æ­¢ä½éæ°£ç¶åå¾µçå¸¸è¦åå ãå¶ç¹å¾µçºæé¼¾ãé¼»å¡åçé·éç¤ãé»è¦æ·å±¤ææ (CT) æ¯ä¸ç¨®éè¦çé«å­¸å½±åæ¨¡å¼ï¼å©ç¨ X å°ç·ååé²çè¨ç®æè¡çæè©³ç´°çæ©«æ·é¢å½±åãå¨å°åæ°£éè©ä¼°é åï¼CT å½±åæä¾äºèºæ¨£é«è¥å¤§çå½¢çåé«ç©çæ·±å»è¦è§£ãåç®¡æ·±åº¦å­¸ç¿æ¹æ³å¨é«å­¸å½±ååææ¹é¢åå¾äºé²å±ï¼ä½ CT ææä¸­èºæ¨£é«è¥å¤§çåå²ä»å­å¨ç©ºç¼ºãçºäºè§£æ±ºéåç ç©¶å·®è·ï¼æåå¼å¥äº TSUBF-Nettï¼åºæ¼éåèåç Trans-Spatial UNet é¡ç¶²è·¯ï¼ï¼éæ¯ä¸å 3D é«å­¸å½±ååå²æ¡æ¶ãTSUBF-Net è¢«è¨­è¨çºææè­å¥ CT ææä¸­è¤éç 3D ç©ºéäºå±¤ç¹å¾µï¼ä¸¦å¢å¼·éçæ¨¡ç³ç¹å¾µçæåãå¼å¾æ³¨æçæ¯ï¼æåå¨ U å½¢ç¶²è·¯æ¶æ§ä¸­æåºäºå©ååµæ°çæ¨¡çµï¼Trans-Spatial æç¥æ¨¡çµ (TSP) åéåæ¡æ¨£åä½èåæ¨¡çµ (BSCF)ãéå©åæ¨¡çµè² è²¬å¨æ¡æ¨£éç¨ä¸­éä½ï¼ä¸¦åå¥ç­ç¥æ§å°èåä¸æ¡æ¨£åä¸æ¡æ¨£ç¹å¾µãæ­¤å¤ï¼æåå¼å¥äº Sobel æå¤±é ï¼å®åªåäºåå²çµæçå¹³æ»åº¦ä¸¦å¢å¼·äºæ¨¡åçæºç¢ºæ§ãå¨å¤åè³æéä¸é²è¡äºå»£æ³ç 3D åå²å¯¦é©ãTSUBF-Net åªæ¼æåé²çæ¹æ³ï¼å¨æåèªå·±ç AHSD è³æéä¸å·ææä½ç HD95ï¼7.03ãIoUï¼85.63 å DSCï¼92.26ãå¶ä»å©åå¬å±è³æéä¸­ççµæä¹è¡¨æï¼æåçæ¨¡åå¯ä»¥ç©©å¥ææå°è§£æ±º CT ææä¸­ 3D åå²çææ°ã

##### **Automating Feedback Analysis in Surgical Training: Detection, Categorization, and Assessment**
2412.00760v1 by Firdavs Nasriddinov, Rafal Kocielnik, Arushi Gupta, Cherine Yang, Elyssa Wong, Anima Anandkumar, Andrew Hung

This work introduces the first framework for reconstructing surgical dialogue
from unstructured real-world recordings, which is crucial for characterizing
teaching tasks. In surgical training, the formative verbal feedback that
trainers provide to trainees during live surgeries is crucial for ensuring
safety, correcting behavior immediately, and facilitating long-term skill
acquisition. However, analyzing and quantifying this feedback is challenging
due to its unstructured and specialized nature. Automated systems are essential
to manage these complexities at scale, allowing for the creation of structured
datasets that enhance feedback analysis and improve surgical education. Our
framework integrates voice activity detection, speaker diarization, and
automated speech recaognition, with a novel enhancement that 1) removes
hallucinations (non-existent utterances generated during speech recognition
fueled by noise in the operating room) and 2) separates speech from trainers
and trainees using few-shot voice samples. These aspects are vital for
reconstructing accurate surgical dialogues and understanding the roles of
operating room participants. Using data from 33 real-world surgeries, we
demonstrated the system's capability to reconstruct surgical teaching dialogues
and detect feedback instances effectively (F1 score of 0.79+/-0.07). Moreover,
our hallucination removal step improves feedback detection performance by ~14%.
Evaluation on downstream clinically relevant tasks of predicting Behavioral
Adjustment of trainees and classifying Technical feedback, showed performances
comparable to manual annotations with F1 scores of 0.82+/0.03 and 0.81+/0.03
respectively. These results highlight the effectiveness of our framework in
supporting clinically relevant tasks and improving over manual methods.

æè¦ï¼<paragraph>éé å·¥ä½ä»ç´¹äºç¬¬ä¸åç¨æ¼éå»ºæè¡å°è©±çæ¶æ§ï¼è©²æ¶æ§ä¾èªéçµæ§åççå¯¦ä¸çéé³ï¼éå°æ¼æè¿°æå­¸ä»»åè³ééè¦ãå¨å¤ç§å¹è¨ä¸­ï¼å¹è¨èå¨ç¾å ´æè¡æéååè¨èæä¾çå½¢ææ§è¨èªåé¥å°æ¼ç¢ºä¿å®å¨ãç«å³ç³¾æ­£è¡çºåä¿é²é·ææè½ç¿å¾è³ééè¦ãç¶èï¼ç±æ¼å¶éçµæ§ååå°æ¥­æ§è³ªï¼å°æ­¤åé¥é²è¡åæåéåå·æææ°æ§ãèªååç³»çµ±å°æ¼å¤§è¦æ¨¡ç®¡çéäºè¤éæ§è³ééè¦ï¼åè¨±åµå»ºçµæ§åçè³æéï¼ä»¥å¢å¼·åé¥åæä¸¦æ¹åå¤ç§æè²ãæåçæ¶æ§æ´åäºèªé³æ´»ååµæ¸¬ãèªªè©±èæ¥è¨åèªåèªé³è­å¥ï¼ä¸¦å·æä¸åæ°ç©çå¢å¼·åè½ï¼è©²åè½ 1) æ¶é¤äºå¹»è¦ºï¼å¨æè¡å®¤çåªé³å¼ç¼èªé³è­å¥æéç¢ççä¸å­å¨çèªå¥ï¼å 2) ä½¿ç¨å°æ¸èªé³æ¨£æ¬å°å¹è¨èååè¨èçèªé³åéãéäºæ¹é¢å°æ¼éå»ºæºç¢ºçæè¡å°è©±åçè§£æè¡å®¤åèèçè§è²è³ééè¦ãä½¿ç¨ä¾èª 33 æ¬¡çå¯¦æè¡çè³æï¼æåå±ç¤ºäºè©²ç³»çµ±éå»ºæè¡æå­¸å°è©±åæææª¢æ¸¬åé¥å¯¦ä¾çè½åï¼F1 åæ¸çº 0.79+/-0.07ï¼ãæ­¤å¤ï¼æåçå¹»è¦ºæ¶é¤æ­¥é©å°åé¥æª¢æ¸¬æè½æåäºç´ 14%ãå¨é æ¸¬åè¨èçè¡çºèª¿æ´ååé¡æè¡åé¥çä¸æ¸¸è¨åºç¸éä»»åçè©ä¼°ä¸­ï¼é¡¯ç¤ºåºè F1 åæ¸åå¥çº 0.82+/0.03 å 0.81+/0.03 çæåæ¨è¨»ç¸ç¶çæè½ãéäºçµæçªé¡¯äºæåçæ¶æ§å¨æ¯æ´è¨åºç¸éä»»ååæ¹é²æåæ¹æ³æ¹é¢çæææ§ã</paragraph>

##### **Fairness at Every Intersection: Uncovering and Mitigating Intersectional Biases in Multimodal Clinical Predictions**
2412.00606v1 by Resmi Ramachandranpillai, Kishore Sampath, Ayaazuddin Mohammad, Malihe Alikhani

Biases in automated clinical decision-making using Electronic Healthcare
Records (EHR) impose significant disparities in patient care and treatment
outcomes. Conventional approaches have primarily focused on bias mitigation
strategies stemming from single attributes, overlooking intersectional
subgroups -- groups formed across various demographic intersections (such as
race, gender, ethnicity, etc.). Rendering single-attribute mitigation
strategies to intersectional subgroups becomes statistically irrelevant due to
the varying distribution and bias patterns across these subgroups. The
multimodal nature of EHR -- data from various sources such as combinations of
text, time series, tabular, events, and images -- adds another layer of
complexity as the influence on minority groups may fluctuate across modalities.
In this paper, we take the initial steps to uncover potential intersectional
biases in predictions by sourcing extensive multimodal datasets, MIMIC-Eye1 and
MIMIC-IV ED, and propose mitigation at the intersectional subgroup level. We
perform and benchmark downstream tasks and bias evaluation on the datasets by
learning a unified text representation from multimodal sources, harnessing the
enormous capabilities of the pre-trained clinical Language Models (LM),
MedBERT, Clinical BERT, and Clinical BioBERT. Our findings indicate that the
proposed sub-group-specific bias mitigation is robust across different
datasets, subgroups, and embeddings, demonstrating effectiveness in addressing
intersectional biases in multimodal settings.

æè¦ï¼é»å­çæ­· (EHR) ä¸­èªååè¨åºæ±ºç­çåå·®æå°æ£èç§è­·åæ²»ççµæé æé¡¯èçå·®ç°ãå³çµ±æ¹æ³ä¸»è¦å°æ³¨æ¼å®ä¸å±¬æ§çåå·®ç·©è§£ç­ç¥ï¼å¿½ç¥äºäº¤åç¾¤é«ââå¨åç¨®äººå£çµ±è¨äº¤åé»ï¼ä¾å¦ç¨®æãæ§å¥ãç¨®æç­ï¼å½¢æçç¾¤é«ãç±æ¼éäºå­ç¾¤çåå¸ååå·®æ¨¡å¼ä¸åï¼å°å®ä¸å±¬æ§ç·©è§£ç­ç¥æç¨æ¼äº¤åå­ç¾¤å¨çµ±è¨ä¸è®å¾ç¡éç·è¦ãEHR çå¤æ¨¡ææ§è³ªââä¾èªåç¨®ä¾æºçæ¸æï¼ä¾å¦ææ¬ãæéåºåãè¡¨æ ¼ãäºä»¶åååççµåââå¢å äºå¦ä¸å±¤è¤éæ§ï¼å çºå°å°æ¸ç¾¤é«çå½±é¿å¯è½æå¨ä¸åæ¨¡å¼ä¹éæ³¢åãå¨æ¬æä¸­ï¼æåæ¡åäºåæ­¥æ­¥é©ï¼ééæ¡éå»£æ³çå¤æ¨¡ææ¸æé MIMIC-Eye1 å MIMIC-IV ED ä¾æ­ç¤ºé æ¸¬ä¸­çæ½å¨äº¤ååå·®ï¼ä¸¦æåºå¨äº¤åå­ç¾¤ç´å¥é²è¡ç·©è§£ãæåééå¾å¤æ¨¡æä¾æºå­¸ç¿çµ±ä¸çææ¬è¡¨ç¤ºï¼å©ç¨é è¨ç·´çè¨åºèªè¨æ¨¡å (LM)ãMedBERTãClinical BERT å Clinical BioBERT çå¼·å¤§åè½ï¼å°æ¸æéå·è¡ä¸¦åºæºä¸æ¸¸ä»»åååå·®è©ä¼°ãæåçç ç©¶çµæè¡¨æï¼ææåºçå­ç¾¤ç¹å®åå·®ç·©è§£å¨ä¸åçæ¸æéãå­ç¾¤ååµå¥ä¸­é½æ¯ç©©å¥çï¼è­æäºå¨å¤æ¨¡æè¨­ç½®ä¸­è§£æ±ºäº¤ååå·®çæææ§ã

##### **Opus: A Large Work Model for Complex Workflow Generation**
2412.00573v2 by ThÃ©o Fagnoni, Bellinda Mesbah, Mahsun Altin, Phillip Kingston

This paper introduces Opus, a novel framework for generating and optimizing
Workflows tailored to complex Business Process Outsourcing (BPO) use cases,
focusing on cost reduction and quality enhancement while adhering to
established industry processes and operational constraints. Our approach
generates executable Workflows from Intention, defined as the alignment of
Client Input, Client Output, and Process Context. These Workflows are
represented as Directed Acyclic Graphs (DAGs), with nodes as Tasks consisting
of sequences of executable Instructions, including tools and human expert
reviews. We adopt a two-phase methodology: Workflow Generation and Workflow
Optimization. In the Generation phase, Workflows are generated using a Large
Work Model (LWM) informed by a Work Knowledge Graph (WKG) that encodes
domain-specific procedural and operational knowledge. In the Optimization
phase, Workflows are transformed into Workflow Graphs (WFGs), where optimal
Workflows are determined through path optimization. Our experiments demonstrate
that state-of-the-art Large Language Models (LLMs) face challenges in reliably
retrieving detailed process data as well as generating industry-compliant
workflows. The key contributions of this paper include integrating a Work
Knowledge Graph (WKG) into a Large Work Model (LWM) to enable the generation of
context-aware, semantically aligned, structured and auditable Workflows. It
further introduces a two-phase approach that combines Workflow Generation from
Intention with graph-based Workflow Optimization. Finally, we present Opus
Alpha 1 Large and Opus Alpha 1 Small that outperform state-of-the-art LLMs by
38% and 29% respectively in Workflow Generation for a Medical Coding use case.

æè¦ï¼éç¯è«æä»ç´¹äº Opusï¼ä¸åç¨æ¼ç¢çåæä½³åå·¥ä½æµç¨çæ°ç©æ¶æ§ï¼å°çºè¤éçæ¥­åæµç¨å¤å (BPO) ä½¿ç¨æ¡ä¾éèº«æé ï¼éé»å¨æ¼éä½ææ¬åæååè³ªï¼åæéµå®æ¢å®çç¢æ¥­æµç¨åçééå¶ãæåçåæ³æ ¹ææåç¢çå¯å·è¡çå·¥ä½æµç¨ï¼æåå®ç¾©çºå®¢æ¶è¼¸å¥ãå®¢æ¶è¼¸åºåæµç¨èæ¯çå°é½ãéäºå·¥ä½æµç¨è¡¨ç¤ºçºæåç¡ç°å (DAG)ï¼ç¯é»çºåå«å¯å·è¡æä»¤åºåçä»»åï¼åæ¬å·¥å·åäººé¡å°å®¶çå¯©æ¥ãæåæ¡ç¨å©éæ®µæ¹æ³ï¼å·¥ä½æµç¨ç¢çåå·¥ä½æµç¨æä½³åãå¨ç¢çéæ®µï¼å·¥ä½æµç¨ä½¿ç¨å¤§åå·¥ä½æ¨¡å (LWM) ç¢çï¼è©²æ¨¡åç±ç·¨ç¢¼ç¹å®é åç¨åºåéä½ç¥è­çå·¥ä½ç¥è­å (WKG) æä¾è³è¨ãå¨æä½³åéæ®µï¼å·¥ä½æµç¨è½æçºå·¥ä½æµç¨å (WFG)ï¼å¶ä¸­ééè·¯å¾æä½³åä¾ç¢ºå®æä½³å·¥ä½æµç¨ãæåçå¯¦é©è¡¨æï¼æåé²çå¤§åèªè¨æ¨¡å (LLM) å¨å¯é å°æ·åè©³ç´°çæµç¨è³æä»¥åç¢çç¬¦åç¢æ¥­è¦ç¯çå·¥ä½æµç¨æ¹é¢é¢è¨ææ°ãéç¯è«æçä¸»è¦è²¢ç»åæ¬å°å·¥ä½ç¥è­å (WKG) æ´åå°å¤§åå·¥ä½æ¨¡å (LWM) ä¸­ï¼ä»¥ç¢çå·åæå¢æç¥ãèªç¾©å°é½ãçµæ§ååå¯ç¨½æ ¸çå·¥ä½æµç¨ãå®é²ä¸æ­¥ä»ç´¹äºä¸ç¨®å©éæ®µæ¹æ³ï¼å°åºæ¼æåçå·¥ä½æµç¨ç¢çèåºæ¼åå½¢çå·¥ä½æµç¨æä½³åç¸çµåãæå¾ï¼æåå±ç¤ºäº Opus Alpha 1 Large å Opus Alpha 1 Smallï¼å®åå¨é«çç·¨ç¢¼ä½¿ç¨æ¡ä¾ä¸­åå¥æ¯æåé²ç LLM å¨å·¥ä½æµç¨ç¢çæ¹é¢é«åº 38% å 29%ã

##### **Polish Medical Exams: A new dataset for cross-lingual medical knowledge transfer assessment**
2412.00559v1 by Åukasz Grzybowski, Jakub Pokrywka, MichaÅ CiesiÃ³Åka, Jeremi I. Kaczmarek, Marek Kubis

Large Language Models (LLMs) have demonstrated significant potential in
handling specialized tasks, including medical problem-solving. However, most
studies predominantly focus on English-language contexts. This study introduces
a novel benchmark dataset based on Polish medical licensing and specialization
exams (LEK, LDEK, PES) taken by medical doctor candidates and practicing
doctors pursuing specialization. The dataset was web-scraped from publicly
available resources provided by the Medical Examination Center and the Chief
Medical Chamber. It comprises over 24,000 exam questions, including a subset of
parallel Polish-English corpora, where the English portion was professionally
translated by the examination center for foreign candidates. By creating a
structured benchmark from these existing exam questions, we systematically
evaluate state-of-the-art LLMs, including general-purpose, domain-specific, and
Polish-specific models, and compare their performance against human medical
students. Our analysis reveals that while models like GPT-4o achieve near-human
performance, significant challenges persist in cross-lingual translation and
domain-specific understanding. These findings underscore disparities in model
performance across languages and medical specialties, highlighting the
limitations and ethical considerations of deploying LLMs in clinical practice.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²å±ç¾åºå¨èçå°æ¥­ä»»åï¼åæ¬é«çåé¡è§£æ±ºï¼æ¹é¢å·æçé¡¯èæ½åãç¶èï¼å¤§å¤æ¸ç ç©¶ä¸»è¦éæ³¨æ¼è±èªèªå¢ãæ¬ç ç©¶å¼å¥äºåºæ¼æ³¢è­é«å­¸è¨±å¯åå°ç§èè©¦ (LEKãLDEKãPES) çæ°åºæºè³æéï¼ç±é«å­¸åå£«åé¸äººåå¾äºå°ç§çå·æ¥­é«çåå ãè©²è³æéå¾é«å­¸èè©¦ä¸­å¿åé¦å¸­é«å­¸é¨éæä¾çå¬éè³æºä¸­é²è¡ç¶²è·¯æåãå®åå«è¶é 24,000 åèè©¦é¡ç®ï¼åæ¬æ³¢è­èª-è±èªèªæåº«çå­éï¼å¶ä¸­è±èªé¨åç±èè©¦ä¸­å¿çºå¤ç±èçå°æ¥­ç¿»è­¯ãééæ ¹æéäºç¾æèè©¦é¡ç®å»ºç«çµæ§ååºæºï¼æåç³»çµ±æ§å°è©ä¼°äºæåé²ç LLMï¼åæ¬éç¨ãç¹å®é ååç¹å®æ¼æ³¢è­çæ¨¡åï¼ä¸¦å°å¶æ§è½èäººé¡é«å­¸çé²è¡æ¯è¼ãæåçåæè¡¨æï¼åç®¡ GPT-4o ç­æ¨¡åéå°äºæ¥è¿äººé¡çæ§è½ï¼ä½è·¨èªè¨ç¿»è­¯åç¹å®é åçè§£ä¸­ä»ç¶å­å¨éå¤§ææ°ãéäºç¼ç¾å¼·èª¿äºè·¨èªè¨åé«å­¸å°æ¥­çæ¨¡åæ§è½å·®ç°ï¼çªé¡¯äºå¨è¨åºå¯¦è¸ä¸­é¨ç½² LLM çå±éæ§åå«çèéã

##### **Unveiling Performance Challenges of Large Language Models in Low-Resource Healthcare: A Demographic Fairness Perspective**
2412.00554v1 by Yue Zhou, Barbara Di Eugenio, Lu Cheng

This paper studies the performance of large language models (LLMs),
particularly regarding demographic fairness, in solving real-world healthcare
tasks. We evaluate state-of-the-art LLMs with three prevalent learning
frameworks across six diverse healthcare tasks and find significant challenges
in applying LLMs to real-world healthcare tasks and persistent fairness issues
across demographic groups. We also find that explicitly providing demographic
information yields mixed results, while LLM's ability to infer such details
raises concerns about biased health predictions. Utilizing LLMs as autonomous
agents with access to up-to-date guidelines does not guarantee performance
improvement. We believe these findings reveal the critical limitations of LLMs
in healthcare fairness and the urgent need for specialized research in this
area.

æè¦ï¼æ¬ææ¢è¨å¤§åèªè¨æ¨¡å (LLM) çæè½ï¼ç¹å¥æ¯å¨äººå£çµ±è¨å¬å¹³æ§æ¹é¢ï¼ä»¥è§£æ±ºç¾å¯¦ä¸ççé«çä¿å¥ä»»åãæåè©ä¼°äºæåé²ç LLMï¼æ¡ç¨ä¸åæµè¡çå­¸ç¿æ¶æ§ï¼æ¶µèå­é ä¸åçé«çä¿å¥ä»»åï¼ç¼ç¾å° LLM æç¨æ¼ç¾å¯¦ä¸ççé«çä¿å¥ä»»åææé¢è¨éå¤§ææ°ï¼ä¸¦ä¸å¨ä¸åäººå£çµ±è¨ç¾¤é«ä¸­å­å¨æçºçå¬å¹³æ§åé¡ãæåéç¼ç¾ï¼æç¢ºæä¾äººå£çµ±è¨è³è¨æç¢çä¸åççµæï¼è LLM æ¨æ·æ­¤é¡ç´°ç¯çè½åå¼ç¼äºå°æåè¦çå¥åº·é æ¸¬çææãå©ç¨ LLM ä½çºå·æå­åææ°æåçèªä¸»ä»£çä¸¦ä¸è½ä¿è­æè½æåãæåç¸ä¿¡éäºç¼ç¾æ­ç¤ºäº LLM å¨é«çä¿å¥å¬å¹³æ§æ¹é¢çéå¤§éå¶ï¼ä»¥åå°æ­¤é åé²è¡å°éç ç©¶çè¿«åéè¦ã

##### **2-Factor Retrieval for Improved Human-AI Decision Making in Radiology**
2412.00372v1 by Jim Solomon, Laleh Jalilian, Alexander Vilesov, Meryl Mathew, Tristan Grogan, Arash Bedayat, Achuta Kadambi

Human-machine teaming in medical AI requires us to understand to what degree
a trained clinician should weigh AI predictions. While previous work has shown
the potential of AI assistance at improving clinical predictions, existing
clinical decision support systems either provide no explainability of their
predictions or use techniques like saliency and Shapley values, which do not
allow for physician-based verification. To address this gap, this study
compares previously used explainable AI techniques with a newly proposed
technique termed '2-factor retrieval (2FR)', which is a combination of
interface design and search retrieval that returns similarly labeled data
without processing this data. This results in a 2-factor security blanket
where: (a) correct images need to be retrieved by the AI; and (b) humans should
associate the retrieved images with the current pathology under test. We find
that when tested on chest X-ray diagnoses, 2FR leads to increases in clinician
accuracy, with particular improvements when clinicians are radiologists and
have low confidence in their decision. Our results highlight the importance of
understanding how different modes of human-AI decision making may impact
clinician accuracy in clinical decision support systems.

æè¦ï¼äººæ©åä½å¨é«ç AI ä¸­ï¼éè¦æåçè§£åéè¨ç·´çè¨åºé«çå¨å¤å¤§ç¨åº¦ä¸æéè¦ AI é æ¸¬ãéç¶ååçç ç©¶é¡¯ç¤º AI è¼å©å¨æ¹åè¨åºé æ¸¬æ¹é¢çæ½åï¼ä½ç¾æçè¨åºæ±ºç­æ¯æ´ç³»çµ±ï¼è¦ä¸å°±æ²ææä¾é æ¸¬çå¯è§£éæ§ï¼è¦ä¸å°±æ¯ä½¿ç¨åé¡¯èæ§å Shapley å¼ä¹é¡çæè¡ï¼éäºæè¡ä¸åè¨±åºæ¼é«ççé©è­ãçºäºè§£æ±ºéåå·®è·ï¼æ¬ç ç©¶å°ååä½¿ç¨çå¯è§£é AI æè¡èä¸ç¨®æ°æåºçç¨±çºã2 å å­æª¢ç´¢ (2FR)ãçæè¡é²è¡æ¯è¼ï¼å¾èæ¯ä¸ç¨®ä»é¢è¨­è¨åæå°æª¢ç´¢ççµåï¼å®æå³åæ¨ç±¤ç¸ä¼¼çè³æï¼èä¸æèçéäºè³æãéæç¢çä¸å 2 å å­å®å¨æ©å¶ï¼å¶ä¸­ï¼(a) æ­£ç¢ºçå½±åéè¦ç± AI æª¢ç´¢ï¼(b) äººé¡æå°æª¢ç´¢çå½±åèæ­£å¨æ¸¬è©¦ä¸­çççè¯æ³èµ·ä¾ãæåç¼ç¾ï¼ç¶å¨è¸é¨ X åè¨ºæ·ä¸é²è¡æ¸¬è©¦æï¼2FR ææé«è¨åºé«ççæºç¢ºåº¦ï¼ç¹å¥æ¯å¨è¨åºé«çæ¯æ¾å°ç§é«çä¸å°å¶æ±ºç­ä¿¡å¿ä¸è¶³æï¼ææé¡¯èçæ¹åãæåççµæå¼·èª¿äºçè§£äººæ©æ±ºç­çä¸åæ¨¡å¼å¦ä½å½±é¿è¨åºé«çå¨è¨åºæ±ºç­æ¯æ´ç³»çµ±ä¸­çæºç¢ºæ§çéè¦æ§ã

##### **One Model for One Graph: A New Perspective for Pretraining with Cross-domain Graphs**
2412.00315v1 by Jingzhe Liu, Haitao Mao, Zhikai Chen, Wenqi Fan, Mingxuan Ju, Tong Zhao, Neil Shah, Jiliang Tang

Graph Neural Networks (GNNs) have emerged as a powerful tool to capture
intricate network patterns, achieving success across different domains.
However, existing GNNs require careful domain-specific architecture designs and
training from scratch on each dataset, leading to an expertise-intensive
process with difficulty in generalizing across graphs from different domains.
Therefore, it can be hard for practitioners to infer which GNN model can
generalize well to graphs from their domains. To address this challenge, we
propose a novel cross-domain pretraining framework, "one model for one graph,"
which overcomes the limitations of previous approaches that failed to use a
single GNN to capture diverse graph patterns across domains with significant
gaps. Specifically, we pretrain a bank of expert models, with each one
corresponding to a specific dataset. When inferring to a new graph, gating
functions choose a subset of experts to effectively integrate prior model
knowledge while avoiding negative transfer. Extensive experiments consistently
demonstrate the superiority of our proposed method on both link prediction and
node classification tasks.

æè¦ï¼åå½¢ç¥ç¶ç¶²è·¯ (GNN) å·²æçºææè¤éç¶²è·¯æ¨¡å¼çå¼·å¤§å·¥å·ï¼å¨ä¸åé åçåå¾æåã
ç¶èï¼ç¾æç GNN éè¦ä»ç´°çç¹å®æ¼é åçæ¶æ§è¨­è¨ï¼ä¸¦éå°æ¯åè³æéå¾é ­éå§è¨ç·´ï¼å°è´å°æ¥­ç¥è­å¯éçéç¨ï¼é£ä»¥æ¦æ¬ä¾èªä¸åé åçåå½¢ã
å æ­¤ï¼å¾æ¥­èå¾é£æ¨æ·åªå GNN æ¨¡åå¯ä»¥å¾å¥½å°æ¦æ¬å°å¶é åçåå½¢ãçºäºæå°éä¸ææ°ï¼æåæåºäºä¸åæ°ç©çè·¨é åé è¨ç·´æ¡æ¶ï¼ãä¸åæ¨¡åå°æä¸ååå½¢ãï¼å®åæäºååæ¹æ³çéå¶ï¼éäºéå¶ç¡æ³ä½¿ç¨å®å GNN ä¾ææè·¨è¶å·æé¡¯èå·®è·çé åçä¸ååå½¢æ¨¡å¼ãå·é«ä¾èªªï¼æåé è¨ç·´äºä¸çµå°å®¶æ¨¡åï¼æ¯ä¸åé½å°æä¸åç¹å®è³æéãå¨æ¨è«å°ä¸åæ°åå½¢æï¼éæ§å½æ¸æé¸æä¸åå°å®¶å­éï¼ä»¥æææ´åååçæ¨¡åç¥è­ï¼åæé¿åè² é¢å³éãå»£æ³çå¯¦é©æçºè­æäºæåæåºçæ¹æ³å¨é£çµé æ¸¬åç¯é»åé¡ä»»åä¸çåªè¶æ§ã

##### **BOTS: Batch Bayesian Optimization of Extended Thompson Sampling for Severely Episode-Limited RL Settings**
2412.00308v1 by Karine Karine, Susan A. Murphy, Benjamin M. Marlin

In settings where the application of reinforcement learning (RL) requires
running real-world trials, including the optimization of adaptive health
interventions, the number of episodes available for learning can be severely
limited due to cost or time constraints. In this setting, the bias-variance
trade-off of contextual bandit methods can be significantly better than that of
more complex full RL methods. However, Thompson sampling bandits are limited to
selecting actions based on distributions of immediate rewards. In this paper,
we extend the linear Thompson sampling bandit to select actions based on a
state-action utility function consisting of the Thompson sampler's estimate of
the expected immediate reward combined with an action bias term. We use batch
Bayesian optimization over episodes to learn the action bias terms with the
goal of maximizing the expected return of the extended Thompson sampler. The
proposed approach is able to learn optimal policies for a strictly broader
class of Markov decision processes (MDPs) than standard Thompson sampling.
Using an adaptive intervention simulation environment that captures key aspects
of behavioral dynamics, we show that the proposed method can significantly
out-perform standard Thompson sampling in terms of total return, while
requiring significantly fewer episodes than standard value function and policy
gradient methods.

æè¦ï¼å¨éè¦ä½¿ç¨å¼·åå­¸ç¿ (RL) é²è¡å¯¦éä¸çè©¦é©ï¼åæ¬æä½³åé©ææ§å¥åº·å¹²é æªæ½çè¨­å®ä¸­ï¼å¯ç¨æ¼å­¸ç¿çååæ¸å¯è½æå çºææ¬ææééå¶èåå°å´ééå¶ãå¨æ­¤è¨­å®ä¸­ï¼æå¢å¼·çæ¹æ³çåå·®è®ç°åæ¨æé¡¯èåªæ¼æ´è¤éçå®æ´ RL æ¹æ³ãä¸éï¼æ¹¯æ®æ£®æ½æ¨£å¼·çåªè½æ ¹æç«å³çåµçåéä¾é¸æè¡åãå¨æ¬æä¸­ï¼æåå»¶ä¼¸ç·æ§æ¹¯æ®æ£®æ½æ¨£å¼·çï¼ä»¥æ ¹æçæè¡åæç¨å½æ¸é¸æè¡åï¼è©²å½æ¸åå«æ¹¯æ®æ£®æ¡æ¨£å¨å°é æç«å³çåµçä¼°è¨å¼ï¼ä»¥ååä½åå·®é ãæåä½¿ç¨æ¹æ¬¡è²æ°æä½³åå¨ååä¸­å­¸ç¿åä½åå·®é ï¼ç®æ¨æ¯æå¤§åå»¶ä¼¸æ¹¯æ®æ£®æ¡æ¨£å¨çé æåå ±ãæåºçæ¹æ³è½å¤ çºæ¯æ¨æºæ¹¯æ®æ£®æ½æ¨£æ´å»£æ³çé¦¬å¯å¤«æ±ºç­ç¨åº (MDP) é¡å¥å­¸ç¿æä½³ç­ç¥ãä½¿ç¨ææè¡çºåæééµå±¤é¢çé©ææ§å¹²é æ¨¡æ¬ç°å¢ï¼æåè­æææåºçæ¹æ³å¨ç¸½åå ±æ¹é¢å¯ä»¥é¡¯èåªæ¼æ¨æºæ¹¯æ®æ£®æ½æ¨£ï¼åææéååæ¸é å°æ¼æ¨æºå¹å¼å½æ¸åç­ç¥æ¢¯åº¦æ¹æ³ã

##### **Fine Tuning Large Language Models to Deliver CBT for Depression**
2412.00251v1 by Talha Tahir

Cognitive Behavioral Therapy (CBT) is a well-established, evidence-based
treatment for Major Depressive Disorder. Unfortunately, there exist significant
barriers to individuals accessing CBT, including cost, scarcity of therapists
and stigma. This study explores the feasibility of fine-tuning small open
weight large language models (LLMs) to deliver CBT for depression. Using 58
sets of synthetic CBT transcripts generated by the Nous Research fine-tune of
Llama 3.1 405b, we fine-tuned three models: Mistral 7b v0.3, Qwen 2.5 7b, and
Llama 3.1 8b. CBT fidelity was evaluated through a modified Cognitive Therapy
Rating Scale (CTRS). All fine-tuned models were compared against each other, as
well as their instruct-tuned variants. Simulated patient transcripts were
generated for the purpose of evaluating model performance, with the instruct
and CBT-tuned models acting as the therapist and DeepSeek-V2.5 acting as the
patient. These simulated transcripts were evaluated on a modified CTRS by
Gemini 1.5 Pro-002. Our findings demonstrated that the CBT-tuned models
significantly outperformed their instruct-tuned counterparts, with an average
improvement of 11.33 points (p < 0.001) on total CTRS score. Llama 3.1 8b had
the strongest performance (mean CTRS score 67.86 +/- 7.24), followed by Qwen
2.5 7b (64.28 +/- 9.55) and Mistral 7b v0.3 (64.17 +/- 9.79), with these
differences between models being statistically significant. The CBT-tuned
models were competent in implementing core CBT techniques and providing
empathetic responses, however, there were limitations observed in agenda
adherence, exploration depth and long-context coherence. This study establishes
that CBT specific fine-tuning can effectively encode therapeutic competencies
in small LLMs, though significant technical and ethical considerations must be
resolved prior to clinical deployment.

æè¦ï¼<paragraph>èªç¥è¡çºçæ³ (CBT) æ¯ä¸ç¨®æ²»çéåº¦æé¬±ççå®åä¸æå¯¦è­åºç¤ççæ³ãä¸å¹¸çæ¯ï¼åäººæ¥å CBT ä»å­å¨éå¤§éç¤ï¼åæ¬è²»ç¨ãæ²»çå¸«ç¨ç¼ºåæ±ååãæ¬ç ç©¶æ¢è¨å¾®èª¿å°åéæ¾å¼æ¬éå¤§åèªè¨æ¨¡å (LLM) ä»¥æä¾ CBT æ²»çæé¬±ççå¯è¡æ§ãä½¿ç¨ Nous Research å¾®èª¿ Llama 3.1 405b æç¢çç 58 çµåæ CBT è¬æ¬ï¼æåå¾®èª¿äºä¸åæ¨¡åï¼Mistral 7b v0.3ãQwen 2.5 7b å Llama 3.1 8bãCBT ä¿çåº¦ééä¿®æ­£å¾çèªç¥æ²»çè©åéè¡¨ (CTRS) é²è¡è©ä¼°ãææå¾®èª¿æ¨¡åå½¼æ­¤æ¯è¼ï¼ä»¥åå®åçæä»¤å¾®èª¿è®é«ãæ¨¡æ¬æ£èè¬æ¬æ¯çºäºè©ä¼°æ¨¡åæè½èç¢ççï¼æä»¤å CBT å¾®èª¿æ¨¡åæ®æ¼æ²»çå¸«ï¼è DeepSeek-V2.5 æ®æ¼æ£èãéäºæ¨¡æ¬è¬æ¬ç± Gemini 1.5 Pro-002 ä½¿ç¨ä¿®æ­£å¾ç CTRS é²è¡è©ä¼°ãæåçç ç©¶çµæé¡¯ç¤ºï¼CBT å¾®èª¿æ¨¡åé¡¯èåªæ¼å¶æä»¤å¾®èª¿æ¨¡åï¼CTRS ç¸½åå¹³åæå 11.33 å (p < 0.001)ãLlama 3.1 8b æè½æå¼· (CTRS å¹³ååæ¸ 67.86 +/- 7.24)ï¼å¶æ¬¡æ¯ Qwen 2.5 7b (64.28 +/- 9.55) å Mistral 7b v0.3 (64.17 +/- 9.79)ï¼éäºæ¨¡åä¹éçå·®ç°å·æçµ±è¨é¡¯èæ§ãCBT å¾®èª¿æ¨¡åå¨å¯¦æ½æ ¸å¿ CBT æè¡åæä¾åçåææ¹é¢è¡¨ç¾å¾å¾å¥½ï¼ç¶èå¨è­°ç¨éµå¾ªãæ¢ç´¢æ·±åº¦åé·èçµ¡é£è²«æ§æ¹é¢ä»æè§å¯å°çéå¶ãæ¬ç ç©¶è­å¯¦ï¼ç¹å®æ¼ CBT çå¾®èª¿å¯ä»¥ææå°å°æ²»çè½åç·¨ç¢¼å°å°å LLM ä¸­ï¼åç®¡å¨è¨åºé¨ç½²ä¹åå¿é è§£æ±ºéå¤§çæè¡åå«çèéã</paragraph>

##### **Integrating Social Determinants of Health into Knowledge Graphs: Evaluating Prediction Bias and Fairness in Healthcare**
2412.00245v1 by Tianqi Shang, Weiqing He, Tianlong Chen, Ying Ding, Huanmei Wu, Kaixiong Zhou, Li Shen

Social determinants of health (SDoH) play a crucial role in patient health
outcomes, yet their integration into biomedical knowledge graphs remains
underexplored. This study addresses this gap by constructing an SDoH-enriched
knowledge graph using the MIMIC-III dataset and PrimeKG. We introduce a novel
fairness formulation for graph embeddings, focusing on invariance with respect
to sensitive SDoH information. Via employing a heterogeneous-GCN model for
drug-disease link prediction, we detect biases related to various SDoH factors.
To mitigate these biases, we propose a post-processing method that
strategically reweights edges connected to SDoHs, balancing their influence on
graph representations. This approach represents one of the first comprehensive
investigations into fairness issues within biomedical knowledge graphs
incorporating SDoH. Our work not only highlights the importance of considering
SDoH in medical informatics but also provides a concrete method for reducing
SDoH-related biases in link prediction tasks, paving the way for more equitable
healthcare recommendations. Our code is available at
\url{https://github.com/hwq0726/SDoH-KG}.

æè¦ï¼ç¤¾æå¥åº·æ±ºå®å ç´ ï¼SDoHï¼å¨æ£èå¥åº·çµæä¸­æ®æ¼èè³ééè¦çè§è²ï¼ä½å®åæ´åå°çç©é«å­¸ç¥è­åè­ä¸­çé¨åä»æå¾æ¢è¨ãæ¬ç ç©¶ééä½¿ç¨ MIMIC-III è³æéå PrimeKG å»ºæ§ä¸å SDoH è±å¯çç¥è­åè­ä¾è§£æ±ºéåå·®è·ãæåéå°åå½¢åµå¥å¼å¥ä¸åæ°çå¬å¹³æ§å¬å¼ï¼å°æ³¨æ¼å°ææç SDoH è³è¨ä¿æä¸è®æ§ãééæ¡ç¨ç°è³ª GCN æ¨¡åé²è¡è¥ç©ç¾çé£çµé æ¸¬ï¼æååµæ¸¬å°èåç¨® SDoH å å­ç¸éçåå·®ãçºäºæ¸è¼éäºåå·®ï¼æåæåºä¸åå¾èçæ¹æ³ï¼è©²æ¹æ³ç­ç¥æ§å°éæ°å æ¬é£æ¥å° SDoH çéç·£ï¼å¹³è¡¡å®åå°åè¡¨è¡¨ç¤ºçå½±é¿ãæ­¤æ¹æ³ä»£è¡¨äºå° SDoH ç´å¥çç©é«å­¸ç¥è­åè­ä¸­å¬å¹³æ§åé¡çç¬¬ä¸åå¨é¢èª¿æ¥ä¹ä¸ãæåçç ç©¶ä¸åå¼·èª¿äºå¨é«å­¸è³è¨å­¸ä¸­èé SDoH çéè¦æ§ï¼ä¹æä¾äºä¸åå·é«çæ¹æ³ä¾æ¸å°é£çµé æ¸¬ä»»åä¸­è SDoH ç¸éçåå·®ï¼çºæ´å¬å¹³çé«çä¿å¥å»ºè­°éªè·¯ãæåçç¨å¼ç¢¼å¯å¨ \url{https://github.com/hwq0726/SDoH-KG} åå¾ã

##### **Dynamic EEG-fMRI mapping: Revealing the relationship between brain connectivity and cognitive state**
2411.19922v1 by Guiran Liu, Binrong Zhu

This study investigated the dynamic connectivity patterns between EEG and
fMRI modalities, contributing to our understanding of brain network
interactions. By employing a comprehensive approach that integrated static and
dynamic analyses of EEG-fMRI data, we were able to uncover distinct
connectivity states and characterize their temporal fluctuations. The results
revealed modular organization within the intrinsic connectivity networks (ICNs)
of the brain, highlighting the significant roles of sensory systems and the
default mode network. The use of a sliding window technique allowed us to
assess how functional connectivity varies over time, further elucidating the
transient nature of brain connectivity. Additionally, our findings align with
previous literature, reinforcing the notion that cognitive states can be
effectively identified through short-duration data, specifically within the
30-60 second timeframe. The established relationships between connectivity
strength and cognitive processes, particularly during different visual states,
underscore the relevance of our approach for future research into brain
dynamics. Overall, this study not only enhances our understanding of the
interplay between EEG and fMRI signals but also paves the way for further
exploration into the neural correlates of cognitive functions and their
implications in clinical settings. Future research should focus on refining
these methodologies and exploring their applications in various cognitive and
clinical contexts.

æè¦ï¼æ¬ç ç©¶èª¿æ¥äºè¦é»åååè½æ§ç£æ¯é å½±ä¹éçåæé£æ¥æ¨¡å¼ï¼æå©æ¼æåäºè§£è¦ç¶²è·¯äºåãééæ¡ç¨æ´åéæååæè¦é»ååè½æ§ç£æ¯é å½±è³æåæçç¶åæ¹æ³ï¼æåå¾ä»¥æ­ç¤ºä¸åçé£æ¥çæä¸¦æè¿°å¶æéæ³¢åãçµæé¡¯ç¤ºè¦é¨å§å¨é£æ¥ç¶²è·¯ (ICN) ä¸­çæ¨¡çµåçµç¹ï¼çªé¡¯äºæå®ç³»çµ±åé è¨­æ¨¡å¼ç¶²è·¯çéè¦è§è²ãæ»åè¦çªæè¡çä½¿ç¨è®æåå¾ä»¥è©ä¼°åè½æ§é£æ¥å¦ä½é¨æéè®åï¼é²ä¸æ­¥é¡æè¦é¨é£æ¥çæ«ææ§ãæ­¤å¤ï¼æåçç ç©¶çµæèååçæç»ä¸è´ï¼å¼·åäºééç­æè³æï¼ç¹å¥æ¯å¨ 30-60 ç§çæéç¯åå§ï¼å¯ä»¥ææè­å¥èªç¥çæçæ¦å¿µãé£æ¥å¼·åº¦åèªç¥éç¨ä¹éå»ºç«çéä¿ï¼ç¹å¥æ¯å¨ä¸åçè¦è¦ºçæä¸ï¼å¼·èª¿äºæåçéå¾èæªä¾è¦é¨åæç ç©¶ç¸éæ§ãæ´é«èè¨ï¼æ¬ç ç©¶ä¸åå¢å¼·äºæåå°è¦é»åååè½æ§ç£æ¯é å½±è¨èä¹éäº¤äºä½ç¨ççè§£ï¼ä¹çºé²ä¸æ­¥æ¢ç´¢èªç¥åè½çç¥ç¶ç¸éæ§åå¶å¨è¨åºç°å¢ä¸­çæç¾©éªè·¯ãæªä¾çç ç©¶æå°æ³¨æ¼åªåéäºæ¹æ³ä¸¦æ¢è¨å¶å¨åç¨®èªç¥åè¨åºèæ¯ä¸­çæç¨ã

##### **Graph Neural Networks for Heart Failure Prediction on an EHR-Based Patient Similarity Graph**
2411.19742v1 by Heloisa Oss Boll, Ali Amirahmadi, Amira Soliman, Stefan Byttner, Mariana Recamonde-Mendoza

Objective: In modern healthcare, accurately predicting diseases is a crucial
matter. This study introduces a novel approach using graph neural networks
(GNNs) and a Graph Transformer (GT) to predict the incidence of heart failure
(HF) on a patient similarity graph at the next hospital visit. Materials and
Methods: We used electronic health records (EHR) from the MIMIC-III dataset and
applied the K-Nearest Neighbors (KNN) algorithm to create a patient similarity
graph using embeddings from diagnoses, procedures, and medications. Three
models - GraphSAGE, Graph Attention Network (GAT), and Graph Transformer (GT) -
were implemented to predict HF incidence. Model performance was evaluated using
F1 score, AUROC, and AUPRC metrics, and results were compared against baseline
algorithms. An interpretability analysis was performed to understand the
model's decision-making process. Results: The GT model demonstrated the best
performance (F1 score: 0.5361, AUROC: 0.7925, AUPRC: 0.5168). Although the
Random Forest (RF) baseline achieved a similar AUPRC value, the GT model
offered enhanced interpretability due to the use of patient relationships in
the graph structure. A joint analysis of attention weights, graph connectivity,
and clinical features provided insight into model predictions across different
classification groups. Discussion and Conclusion: Graph-based approaches such
as GNNs provide an effective framework for predicting HF. By leveraging a
patient similarity graph, GNNs can capture complex relationships in EHR data,
potentially improving prediction accuracy and clinical interpretability.

æè¦ï¼<paragraph>ç®æ¨ï¼å¨ç¾ä»£é«çä¿å¥ä¸­ï¼æºç¢ºé æ¸¬ç¾çæ¯ä¸é è³ééè¦çåé¡ãæ¬ç ç©¶ä»ç´¹äºä¸ç¨®ä½¿ç¨åç¥ç¶ç¶²çµ¡ (GNN) ååå½¢è½æå¨ (GT) çæ°æ¹æ³ï¼ç¨æ¼é æ¸¬ä¸æ¬¡é«é¢å°±è¨ºææ£èç¸ä¼¼åè¡¨ä¸çå¿èè¡°ç«­ (HF) ç¼ççãææåæ¹æ³ï¼æåä½¿ç¨äº MIMIC-III è³æéä¸­çé»å­å¥åº·è¨é (EHR)ï¼ä¸¦æç¨ K-æè¿é° (KNN) æ¼ç®æ³ï¼ä½¿ç¨ä¾èªè¨ºæ·ãç¨åºåè¥ç©çåµå¥ä¾å»ºç«æ£èç¸ä¼¼åè¡¨ãå¯¦ä½äºä¸åæ¨¡å - GraphSAGEãåå½¢æ³¨æåç¶²è·¯ (GAT) ååå½¢è½æå¨ (GT) - ä¾é æ¸¬ HF ç¼ççãä½¿ç¨ F1 åæ¸ãAUROC å AUPRC ææ¨è©ä¼°æ¨¡åæè½ï¼ä¸¦å°çµæèåºæºæ¼ç®æ³é²è¡æ¯è¼ãå·è¡äºè§£éæ§åæä»¥äºè§£æ¨¡åçæ±ºç­éç¨ãçµæï¼GT æ¨¡åè¡¨ç¾åºæä½³æè½ (F1 åæ¸ï¼0.5361ï¼AUROCï¼0.7925ï¼AUPRCï¼0.5168)ãåç®¡é¨æ©æ£®æ (RF) åºæºéå°äºé¡ä¼¼ç AUPRC å¼ï¼ä½ç±æ¼å¨åå½¢çµæ§ä¸­ä½¿ç¨äºæ£èéä¿ï¼å æ­¤ GT æ¨¡åæä¾äºå¢å¼·çè§£éæ§ãå°æ³¨æåæ¬éãåå½¢é£éæ§åè¨åºç¹å¾µçè¯ååææä¾äºå°ä¸ååé¡ç¾¤çµä¸­æ¨¡åé æ¸¬çè¦è§£ãè¨è«åçµè«ï¼åºæ¼åå½¢çæ¹æ³ï¼ä¾å¦ GNNï¼æä¾äºé æ¸¬ HF çæææ¡æ¶ãééå©ç¨æ£èç¸ä¼¼åå½¢ï¼GNN å¯ä»¥æ·å EHR è³æä¸­çè¤ééä¿ï¼é²èå¯è½æé«é æ¸¬æºç¢ºåº¦åè¨åºè§£éæ§ã</paragraph>

##### **Multimodal Whole Slide Foundation Model for Pathology**
2411.19666v1 by Tong Ding, Sophia J. Wagner, Andrew H. Song, Richard J. Chen, Ming Y. Lu, Andrew Zhang, Anurag J. Vaidya, Guillaume Jaume, Muhammad Shaban, Ahrong Kim, Drew F. K. Williamson, Bowen Chen, Cristina Almagro-Perez, Paul Doucet, Sharifa Sahai, Chengkuan Chen, Daisuke Komura, Akihiro Kawabe, Shumpei Ishikawa, Georg Gerber, Tingying Peng, Long Phi Le, Faisal Mahmood

The field of computational pathology has been transformed with recent
advances in foundation models that encode histopathology region-of-interests
(ROIs) into versatile and transferable feature representations via
self-supervised learning (SSL). However, translating these advancements to
address complex clinical challenges at the patient and slide level remains
constrained by limited clinical data in disease-specific cohorts, especially
for rare clinical conditions. We propose TITAN, a multimodal whole slide
foundation model pretrained using 335,645 WSIs via visual self-supervised
learning and vision-language alignment with corresponding pathology reports and
423,122 synthetic captions generated from a multimodal generative AI copilot
for pathology. Without any finetuning or requiring clinical labels, TITAN can
extract general-purpose slide representations and generate pathology reports
that generalize to resource-limited clinical scenarios such as rare disease
retrieval and cancer prognosis. We evaluate TITAN on diverse clinical tasks and
find that TITAN outperforms both ROI and slide foundation models across machine
learning settings such as linear probing, few-shot and zero-shot
classification, rare cancer retrieval and cross-modal retrieval, and pathology
report generation.

æè¦ï¼è¨ç®ççå­¸é åå·²å åºç¤æ¨¡åçææ°é²å±èè½åï¼éäºæ¨¡åééèªç£ç£å­¸ç¿ (SSL) å°çµç¹ççå­¸æèè¶£åå (ROI) ç·¨ç¢¼æå¤åè½ä¸å¯è½ç§»çç¹å¾µè¡¨ç¤ºãç¶èï¼è¦è§£æ±ºæ£èååçå±¤é¢çè¤éè¨åºææ°ï¼å°éäºé²å±è½åçºè§£æ±ºæ¹æ¡ä»åéæ¼ç¹å®ç¾çç¾¤é«ä¸­æéçè¨åºè³æï¼å°¤å¶æ¯ç½è¦çè¨åºææ³ãæåæåº TITANï¼éæ¯ä¸åå¤æ¨¡æå¨åçåºç¤æ¨¡åï¼ä½¿ç¨ 335,645 å WSI ééè¦è¦ºèªç£ç£å­¸ç¿åèå°æççå ±åçè¦è¦ºèªè¨å°é½ï¼ä»¥åç±å¤æ¨¡æçæå¼ AI è¼å©å¡çºççå­¸çæç 423,122 ååææ¨é¡é²è¡é è¨ç·´ãå¨æ²æä»»ä½å¾®èª¿æéè¦è¨åºæ¨ç±¤çææ³ä¸ï¼TITAN å¯ä»¥æåéç¨åçè¡¨ç¤ºï¼ä¸¦çæççå ±åï¼ä»¥æ¦æ¬å°è³æºæéçè¨åºå ´æ¯ï¼ä¾å¦ç½è¦ç¾çæª¢ç´¢åççé å¾ãæåå¨ä¸åçè¨åºä»»åä¸è©ä¼° TITANï¼ç¼ç¾ TITAN å¨æ©å¨å­¸ç¿è¨­å®ä¸­åªæ¼ ROI ååçåºç¤æ¨¡åï¼ä¾å¦ç·æ§æ¢æ¥ãå°æ¬¡å­¸ç¿åé¶æ¬¡å­¸ç¿åé¡ãç½è¦ççæª¢ç´¢åè·¨æ¨¡ææª¢ç´¢ï¼ä»¥åççå ±åçæã

##### **SkelMamba: A State Space Model for Efficient Skeleton Action Recognition of Neurological Disorders**
2411.19544v1 by Niki Martinel, Mariano Serrao, Christian Micheloni

We introduce a novel state-space model (SSM)-based framework for
skeleton-based human action recognition, with an anatomically-guided
architecture that improves state-of-the-art performance in both clinical
diagnostics and general action recognition tasks. Our approach decomposes
skeletal motion analysis into spatial, temporal, and spatio-temporal streams,
using channel partitioning to capture distinct movement characteristics
efficiently. By implementing a structured, multi-directional scanning strategy
within SSMs, our model captures local joint interactions and global motion
patterns across multiple anatomical body parts. This anatomically-aware
decomposition enhances the ability to identify subtle motion patterns critical
in medical diagnosis, such as gait anomalies associated with neurological
conditions. On public action recognition benchmarks, i.e., NTU RGB+D, NTU RGB+D
120, and NW-UCLA, our model outperforms current state-of-the-art methods,
achieving accuracy improvements up to $3.2\%$ with lower computational
complexity than previous leading transformer-based models. We also introduce a
novel medical dataset for motion-based patient neurological disorder analysis
to validate our method's potential in automated disease diagnosis.

æè¦ï¼<paragraph>æåæåºä¸åæ°ç©çåºæ¼çæç©ºéæ¨¡å (SSM) çæ¡æ¶ï¼ç¨æ¼åºæ¼éª¨æ¶çäººé¡åä½è­å¥ï¼å®å·æè§£åå­¸æå°æ¶æ§ï¼å¯æ¹åè¨åºè¨ºæ·åä¸è¬åä½è­å¥ä»»åçææ°æè¡æ§è½ãæåçåæ³å°éª¨éª¼éååæåè§£çºç©ºéãæéåæç©ºæµï¼ä½¿ç¨ééåå²ä¾ææææä¸åçéåç¹å¾µãééå¨ SSM ä¸­å¯¦æ½çµæ§åãå¤åææç­ç¥ï¼æåçæ¨¡åææå°å¤åè§£åèº«é«é¨ä½çå±é¨éç¯äº¤äºåæ´é«éåæ¨¡å¼ãéç¨®è§£åå­¸æç¥åè§£å¢å¼·äºè­å¥å¾®å¦éåæ¨¡å¼çè½åï¼éäºæ¨¡å¼å¨é«å­¸è¨ºæ·ä¸­è³ééè¦ï¼ä¾å¦èç¥ç¶ç³»çµ±ç¾çç¸éçæ­¥æç°å¸¸ãå¨å¬å±åä½è­å¥åºæºä¸ï¼å³ NTU RGB+DãNTU RGB+D 120 å NW-UCLAï¼æåçæ¨¡ååªæ¼ç¶åæåé²çæ¹æ³ï¼èä»¥åé åçåºæ¼Transformerçæ¨¡åç¸æ¯ï¼å¨è¼ä½çè¨ç®è¤éåº¦ä¸å¯¦ç¾äºé«é 3.2% çæºç¢ºåº¦æ¹é²ãæåéå¼å¥äºä¸åæ°çé«å­¸æ¸æéï¼ç¨æ¼åºæ¼éåçæ£èç¥ç¶ç³»çµ±ç¾çåæï¼ä»¥é©è­æåçæ¹æ³å¨èªåç¾çè¨ºæ·ä¸­çæ½åã</paragraph>

##### **Knowledge-Data Fusion Based Source-Free Semi-Supervised Domain Adaptation for Seizure Subtype Classification**
2411.19502v1 by Ruimin Peng, Jiayu An, Dongrui Wu

Electroencephalogram (EEG)-based seizure subtype classification enhances
clinical diagnosis efficiency. Source-free semi-supervised domain adaptation
(SF-SSDA), which transfers a pre-trained model to a new dataset with no source
data and limited labeled target data, can be used for privacy-preserving
seizure subtype classification. This paper considers two challenges in SF-SSDA
for EEG-based seizure subtype classification: 1) How to effectively fuse both
raw EEG data and expert knowledge in classifier design? 2) How to align the
source and target domain distributions for SF-SSDA? We propose a Knowledge-Data
Fusion based SF-SSDA approach, KDF-MutualSHOT, for EEG-based seizure subtype
classification. In source model training, KDF uses Jensen-Shannon Divergence to
facilitate mutual learning between a feature-driven Decision Tree-based model
and a data-driven Transformer-based model. To adapt KDF to a new target
dataset, an SF-SSDA algorithm, MutualSHOT, is developed, which features a
consistency-based pseudo-label selection strategy. Experiments on the public
TUSZ and CHSZ datasets demonstrated that KDF-MutualSHOT outperformed other
supervised and source-free domain adaptation approaches in cross-subject
seizure subtype classification.

æè¦ï¼åºæ¼è¦é»å (EEG) çç²çäºååé¡å¯æåè¨åºè¨ºæ·æçãç¡ä¾æºåç£ç£é åé©æ (SF-SSDA) å¯å°é åè¨ç·´çæ¨¡åè½ç§»è³æ²æä¾æºè³æä¸æ¨ç±¤ç®æ¨è³ææéçæ°è³æéï¼å¯ç¨æ¼é±ç§ä¿è­·çç²çäºååé¡ãæ¬ææ¢è¨ SF-SSDA å¨åºæ¼ EEG çç²çäºååé¡ä¸­çå©åææ°ï¼1) å¦ä½ææèååå§ EEG è³æååé¡å¨è¨­è¨ä¸­çå°å®¶ç¥è­ï¼2) å¦ä½èª¿æ´ SF-SSDA çä¾æºåç®æ¨ç¶²ååä½ï¼æåæåºä¸ååºæ¼ç¥è­è³æèåç SF-SSDA æ¹æ³ï¼KDF-MutualSHOTï¼ç¨æ¼åºæ¼ EEG çç²çäºååé¡ãå¨ä¾æºæ¨¡åè¨ç·´ä¸­ï¼KDF ä½¿ç¨ Jensen-Shannon è·é¢ä¿é²ç¹å¾µé©åçæ±ºç­æ¨¹æ¨¡ååè³æé©åç Transformer æ¨¡åä¹éçç¸äºå­¸ç¿ãçºäºå° KDF èª¿æ´è³æ°çç®æ¨è³æéï¼éç¼äºä¸å SF-SSDA æ¼ç®æ³ï¼MutualSHOTï¼å¶ç¹é»æ¯åºæ¼ä¸è´æ§çå½æ¨ç±¤é¸æç­ç¥ãå¨å¬éç TUSZ å CHSZ è³æéä¸çå¯¦é©è¡¨æï¼KDF-MutualSHOT å¨è·¨åè©¦èç²çäºååé¡ä¸­åªæ¼å¶ä»ç£ç£å¼åç¡ä¾æºé åé©ææ¹æ³ã

##### **Adaptive Interactive Segmentation for Multimodal Medical Imaging via Selection Engine**
2411.19447v1 by Zhi Li, Kai Zhao, Yaqi Wang, Shuai Wang

In medical image analysis, achieving fast, efficient, and accurate
segmentation is essential for automated diagnosis and treatment. Although
recent advancements in deep learning have significantly improved segmentation
accuracy, current models often face challenges in adaptability and
generalization, particularly when processing multi-modal medical imaging data.
These limitations stem from the substantial variations between imaging
modalities and the inherent complexity of medical data. To address these
challenges, we propose the Strategy-driven Interactive Segmentation Model
(SISeg), built on SAM2, which enhances segmentation performance across various
medical imaging modalities by integrating a selection engine. To mitigate
memory bottlenecks and optimize prompt frame selection during the inference of
2D image sequences, we developed an automated system, the Adaptive Frame
Selection Engine (AFSE). This system dynamically selects the optimal prompt
frames without requiring extensive prior medical knowledge and enhances the
interpretability of the model's inference process through an interactive
feedback mechanism. We conducted extensive experiments on 10 datasets covering
7 representative medical imaging modalities, demonstrating the SISeg model's
robust adaptability and generalization in multi-modal tasks. The project page
and code will be available at: [URL].

æè¦ï¼å¨å»å­¦å½±ååæä¸­ï¼å®ç°å¿«éãé«æååç¡®çåå²å¯¹äºèªå¨åè¯æ­åæ²»çè³å³éè¦ãå°½ç®¡æ·±åº¦å­¦ä¹ çææ°è¿å±æ¾èæé«äºåå²åç¡®æ§ï¼ä½å½åæ¨¡åå¨éåºæ§åæ³åæ§æ¹é¢å¸¸å¸¸é¢ä¸´ææï¼å°¤å¶æ¯å¨å¤çå¤æ¨¡æå»å­¦å½±åæ°æ®æ¶ãè¿äºéå¶æºäºå½±åæ¹å¼ä¹é´çå·¨å¤§å·®å¼åå»å­¦æ°æ®çåºæå¤ææ§ãä¸ºäºåºå¯¹è¿äºææï¼æä»¬æåºäºåºäº SAM2 çç­ç¥é©±å¨äº¤äºå¼åå²æ¨¡å (SISeg)ï¼å®éè¿éæéæ©å¼ææ¥å¢å¼ºåç§å»å­¦å½±åæ¹å¼çåå²æ§è½ãä¸ºäºç¼è§£åå­ç¶é¢å¹¶ä¼å 2D å¾ååºåæ¨çæé´çæç¤ºå¸§éæ©ï¼æä»¬å¼åäºä¸ä¸ªèªå¨åç³»ç»ï¼å³èªéåºå¸§éæ©å¼æ (AFSE)ãè¯¥ç³»ç»å¨æ éå¹¿æ³çååå»å­¦ç¥è¯çæåµä¸å¨æéæ©æä½³æç¤ºå¸§ï¼å¹¶éè¿äº¤äºå¼åé¦æºå¶å¢å¼ºæ¨¡åæ¨çè¿ç¨çå¯è§£éæ§ãæä»¬å¨æ¶µç 7 ç§ä»£è¡¨æ§å»å­¦å½±åæ¹å¼ç 10 ä¸ªæ°æ®éä¸è¿è¡äºå¹¿æ³çå®éªï¼å±ç¤ºäº SISeg æ¨¡åå¨å¤æ¨¡æä»»å¡ä¸­çé²æ£éåºæ§åæ³åæ§ãé¡¹ç®é¡µé¢åä»£ç å°æä¾å¨ï¼[URL]ã

##### **Libra: Leveraging Temporal Images for Biomedical Radiology Analysis**
2411.19378v1 by Xi Zhang, Zaiqiao Meng, Jake Lever, Edmond S. L. Ho

Radiology report generation (RRG) is a challenging task, as it requires a
thorough understanding of medical images, integration of multiple temporal
inputs, and accurate report generation. Effective interpretation of medical
images, such as chest X-rays (CXRs), demands sophisticated visual-language
reasoning to map visual findings to structured reports. Recent studies have
shown that multimodal large language models (MLLMs) can acquire multimodal
capabilities by aligning with pre-trained vision encoders. However, current
approaches predominantly focus on single-image analysis or utilise rule-based
symbolic processing to handle multiple images, thereby overlooking the
essential temporal information derived from comparing current images with prior
ones. To overcome this critical limitation, we introduce Libra, a
temporal-aware MLLM tailored for CXR report generation using temporal images.
Libra integrates a radiology-specific image encoder with a MLLM and utilises a
novel Temporal Alignment Connector to capture and synthesise temporal
information of images across different time points with unprecedented
precision. Extensive experiments show that Libra achieves new state-of-the-art
performance among the same parameter scale MLLMs for RRG tasks on the
MIMIC-CXR. Specifically, Libra improves the RadCliQ metric by 12.9% and makes
substantial gains across all lexical metrics compared to previous models.

æè¦ï¼æ¾å°å­¸å ±åçæ (RRG) æ¯ä¸é å·æææ°æ§çä»»åï¼å çºå®éè¦éå¾¹äºè§£é«å­¸å½±åãæ´åå¤åæéè¼¸å¥ä»¥åæºç¢ºçå ±åçæãææè§£è®é«å­¸å½±åï¼ä¾å¦è¸é¨ X å (CXR)ï¼éè¦è¤éçè¦è¦ºèªè¨æ¨çæè½å°è¦è¦ºç¼ç¾å°æå°çµæ§åçå ±åä¸­ãæè¿çç ç©¶è¡¨æï¼å¤æ¨¡æå¤§åèªè¨æ¨¡å (MLLM) å¯ä»¥ééèé åè¨ç·´çè¦è¦ºç·¨ç¢¼å¨å°é½ä¾ç²å¾å¤æ¨¡æè½åãç¶èï¼ç®åçæ¹æ³ä¸»è¦å°æ³¨æ¼å®ä¸å½±ååææå©ç¨åºæ¼è¦åçç¬¦èèçä¾èçå¤åå½±åï¼å¾èå¿½ç¥äºå¾æ¯è¼ç¶åå½±åèååå½±åä¸­å¾åºçåºæ¬æéè³è¨ãçºäºåæéåééµéå¶ï¼æåå¼å¥äº Libraï¼ä¸åå°çºä½¿ç¨æéå½±åé²è¡ CXR å ±åçæçæææç¥ MLLMãLibra å°æ¾å°å­¸å°ç¨å½±åç·¨ç¢¼å¨è MLLM æ´åå¨ä¸èµ·ï¼ä¸¦å©ç¨ä¸åæ°ç©çæéå°é½é£æ¥å¨ä¾æ·åååæä¸åæéé»å½±åçæéè³è¨ï¼ä¸¦å·æåææªæçç²¾ç¢ºåº¦ãå»£æ³çå¯¦é©è¡¨æï¼Libra å¨ MIMIC-CXR ç RRG ä»»åä¸­ï¼å¨ååæ¸è¦æ¨¡ç MLLM ä¸­åå¾äºæ°çæåé²æè½ãå·é«ä¾èªªï¼Libra å° RadCliQ ææ¨æåäº 12.9%ï¼ä¸¦å¨ææè©å½ææ¨æ¹é¢é½æ¯ä»¥åçæ¨¡ååå¾äºé¡¯èé²æ­¥ã

##### **Mapping Public Perception of Artificial Intelligence: Expectations, Risk-Benefit Tradeoffs, and Value As Determinants for Societal Acceptance**
2411.19356v1 by Philipp Brauner, Felix Glawe, Gian Luca Liehner, Luisa Vervier, Martina Ziefle

Understanding public perception of artificial intelligence (AI) and the
tradeoffs between potential risks and benefits is crucial, as these perceptions
might shape policy decisions, influence innovation trajectories for successful
market strategies, and determine individual and societal acceptance of AI
technologies. Using a representative sample of 1100 participants from Germany,
this study examines mental models of AI. Participants quantitatively evaluated
71 statements about AI's future capabilities (e.g., autonomous driving, medical
care, art, politics, warfare, and societal divides), assessing the expected
likelihood of occurrence, perceived risks, benefits, and overall value. We
present rankings of these projections alongside visual mappings illustrating
public risk-benefit tradeoffs. While many scenarios were deemed likely,
participants often associated them with high risks, limited benefits, and low
overall value. Across all scenarios, 96.4% ($r^2=96.4\%$) of the variance in
value assessment can be explained by perceived risks ($\beta=-.504$) and
perceived benefits ($\beta=+.710$), with no significant relation to expected
likelihood. Demographics and personality traits influenced perceptions of
risks, benefits, and overall evaluations, underscoring the importance of
increasing AI literacy and tailoring public information to diverse user needs.
These findings provide actionable insights for researchers, developers, and
policymakers by highlighting critical public concerns and individual factors
essential to align AI development with individual values.

æè¦ï¼<paragraph>äºè§£å¬ç¾å°äººå·¥æºæ§ (AI) çèªç¥ä»¥åæ½å¨é¢¨éªèå¥½èä¹éçæ¬è¡¡è³ééè¦ï¼å çºéäºèªç¥å¯è½æå½±é¿æ¿ç­æ±ºç­ãå½±é¿æåå¸å ´ç­ç¥çåµæ°è»è·¡ï¼ä¸¦æ±ºå®åäººåç¤¾æå° AI æè¡çæ¥ååº¦ãæ¬ç ç©¶ä½¿ç¨ä¾èªå¾·åç 1100 ååèèçä»£è¡¨æ§æ¨£æ¬ï¼æ¢è¨äº AI çå¿æºæ¨¡åãåèèå° 71 é éæ¼ AI æªä¾è½åçé³è¿°ï¼ä¾å¦ï¼èªåé§é§ãé«çä¿å¥ãèè¡ãæ¿æ²»ãæ°ç­åç¤¾æåæ­§ï¼é²è¡äºå®éè©ä¼°ï¼è©ä¼°é æçç¼çå¯è½æ§ãæç¥é¢¨éªãå¥½èåæ´é«å¹å¼ãæåå±ç¤ºäºéäºé æ¸¬çæåï¼ä¸¦éä¸è¦è¦ºåæ å°ï¼èªªæäºå¬ç¾çé¢¨éªæ¶çæ¬è¡¡ãåç®¡è¨±å¤å ´æ¯è¢«èªçºæ¯å¯è½çï¼ä½åèèéå¸¸å°å®åèé«é¢¨éªãæéçå¥½èåä½æ´é«å¹å¼è¯ç¹«èµ·ä¾ãå¨ææå ´æ¯ä¸­ï¼96.4% ($r^2=96.4\%$) çå¹å¼è©ä¼°å·®ç°å¯ä»¥ç¨æç¥é¢¨éª ($\beta=-.504$) åæç¥å¥½è ($\beta=+.710$) ä¾è§£éï¼èé æçå¯è½æ§æ²æé¡¯èéä¿ãäººå£çµ±è¨åäººæ ¼ç¹è³ªå½±é¿äºå°é¢¨éªãå¥½èåæ´é«è©ä¼°ççæ³ï¼éå¸é¡¯äºæé« AI ç´ é¤åæ ¹æä¸åçä½¿ç¨èéæ±èª¿æ´å¬å±è³è¨çéè¦æ§ãéäºç¼ç¾ééå¼·èª¿ééµçå¬å±éæ³¨åèåäººå¹å¼è§ä¸è´ç AI éç¼å¿ä¸å¯å°çåäººå ç´ ï¼çºç ç©¶äººå¡ãéç¼äººå¡åæ¿ç­å¶å®èæä¾äºå¯è¡çè¦è§£ã</paragraph>

##### **FonTS: Text Rendering with Typography and Style Controls**
2412.00136v1 by Wenda Shi, Yiren Song, Dengming Zhang, Jiaming Liu, Xingxing Zou

Visual text images are prevalent in various applications, requiring careful
font selection and typographic choices. Recent advances in Diffusion
Transformer (DiT)-based text-to-image (T2I) models show promise in automating
these processes. However, these methods still face challenges such as
inconsistent fonts, style variation, and limited fine-grained control,
particularly at the word level. This paper proposes a two-stage DiT-based
pipeline to address these issues by enhancing controllability over typography
and style in text rendering. We introduce Typography Control (TC) finetuning,
an efficient parameter fine-tuning method, and enclosing typography control
tokens (ETC-tokens), which enable precise word-level application of typographic
features. To further enhance style control, we present a Style Control Adapter
(SCA) that injects style information through image inputs independent of text
prompts. Through comprehensive experiments, we demonstrate the effectiveness of
our approach in achieving superior word-level typographic control, font
consistency, and style consistency in Basic and Artistic Text Rendering (BTR
and ATR) tasks. Our results mark a significant advancement in the precision and
adaptability of T2I models, presenting new possibilities for creative
applications and design-oriented tasks.

æè¦ï¼è¦è¦ºæå­ååå¨åç¨®æç¨ä¸­å¾æ®éï¼éè¦ä»ç´°é¸æå­é«åæçé¸é ãæè¿å¨åºæ¼æ´æ£è½æå¨ (DiT) çæå­è½åå (T2I) æ¨¡åçé²å±é¡¯ç¤ºåºèªååéäºç¨åºçæ½åãç¶èï¼éäºæ¹æ³ä»ç¶é¢è¨è«¸å¦å­é«ä¸ä¸è´ãæ¨£å¼è®ååæéçç´°ç²åº¦æ§å¶ç­ææ°ï¼ç¹å¥æ¯å¨æå­å±¤ç´ãæ¬ææåºäºä¸ååºæ¼ DiT çå©éæ®µç®¡éä¾è§£æ±ºéäºåé¡ï¼æ¹æ³æ¯å¢å¼·å°æå­æ¸²æä¸­çæçåæ¨£å¼çå¯æ§æ§ãæåå¼å¥äºæçæ§å¶ (TC) å¾®èª¿ï¼ä¸ç¨®é«æçåæ¸å¾®èª¿æ¹æ³ï¼ä»¥åå°è£æçæ§å¶ä»£å¹£ (ETC ä»£å¹£)ï¼å®è½ç²¾ç¢ºå°æç¨å­é«åè½å¨æå­å±¤ç´ãçºäºé²ä¸æ­¥å¢å¼·æ¨£å¼æ§å¶ï¼æåæåºäºä¸åæ¨£å¼æ§å¶é©éå¨ (SCA)ï¼å®ééååè¼¸å¥æ³¨å¥æ¨£å¼è³è¨ï¼èèæå­æç¤ºç¡éãééå¨é¢çå¯¦é©ï¼æåè­æäºæåçæ¹æ³å¨å¯¦ç¾åªç°çæå­å±¤ç´æçæ§å¶ãå­é«ä¸è´æ§ååºæ¬åèè¡æå­æ¸²æ (BTR å ATR) ä»»åä¸­çæ¨£å¼ä¸è´æ§æ¹é¢çæææ§ãæåççµææ¨èªè T2I æ¨¡åçç²¾ç¢ºåº¦åé©ææ§çéå¤§é²å±ï¼çºåµææç¨åè¨­è¨å°åä»»åæä¾äºæ°çå¯è½æ§ã

##### **Pre-Training Graph Contrastive Masked Autoencoders are Strong Distillers for EEG**
2411.19230v1 by Xinxu Wei, Kanhao Zhao, Yong Jiao, Nancy B. Carlisle, Hua Xie, Yu Zhang

Effectively utilizing extensive unlabeled high-density EEG data to improve
performance in scenarios with limited labeled low-density EEG data presents a
significant challenge. In this paper, we address this by framing it as a graph
transfer learning and knowledge distillation problem. We propose a Unified
Pre-trained Graph Contrastive Masked Autoencoder Distiller, named EEG-DisGCMAE,
to bridge the gap between unlabeled/labeled and high/low-density EEG data. To
fully leverage the abundant unlabeled EEG data, we introduce a novel unified
graph self-supervised pre-training paradigm, which seamlessly integrates Graph
Contrastive Pre-training and Graph Masked Autoencoder Pre-training. This
approach synergistically combines contrastive and generative pre-training
techniques by reconstructing contrastive samples and contrasting the
reconstructions. For knowledge distillation from high-density to low-density
EEG data, we propose a Graph Topology Distillation loss function, allowing a
lightweight student model trained on low-density data to learn from a teacher
model trained on high-density data, effectively handling missing electrodes
through contrastive distillation. To integrate transfer learning and
distillation, we jointly pre-train the teacher and student models by
contrasting their queries and keys during pre-training, enabling robust
distillers for downstream tasks. We demonstrate the effectiveness of our method
on four classification tasks across two clinical EEG datasets with abundant
unlabeled data and limited labeled data. The experimental results show that our
approach significantly outperforms contemporary methods in both efficiency and
accuracy.

æè¦ï¼<paragraph>ææå©ç¨å¤§éæªæ¨ç±¤çé«å¯åº¦è¦é»åè³æï¼ä»¥æ¹åæ¨ç±¤è³ææéçä½å¯åº¦è¦é»åè³ææå¢ä¸­çæè½ï¼æ¯ä¸é éå¤§çææ°ãå¨æ¬æä¸­ï¼æåå°å¶è¦çºåå½¢å³è¼¸å­¸ç¿èç¥è­èååé¡ä¾æ¢è¨ãæåæåºä¸åçµ±ä¸çé è¨ç·´åå½¢å°æ¯é®ç½©èªåç·¨ç¢¼å¨èåå¨ï¼ç¨±çº EEG-DisGCMAEï¼ä»¥å½åæªæ¨ç±¤/æ¨ç±¤åé«/ä½å¯åº¦è¦é»åè³æä¹éçå·®è·ãçºäºååå©ç¨å¤§éçæªæ¨ç±¤è¦é»åè³æï¼æåå¼å¥äºä¸åæ°ç©ççµ±ä¸åå½¢èªæç£ç£é è¨ç·´ç¯ä¾ï¼å®ç¡ç¸«æ´åäºåå½¢å°æ¯é è¨ç·´ååå½¢é®ç½©èªåç·¨ç¢¼å¨é è¨ç·´ãæ­¤æ¹æ³éééå»ºå°æ¯æ¨£æ¬åå°æ¯éå»ºçµæï¼ååçµåäºå°æ¯åçæé è¨ç·´æè¡ãå°æ¼å¾é«å¯åº¦å°ä½å¯åº¦è¦é»åè³æçç¥è­èåï¼æåæåºäºä¸ååå½¢ææ²èåæå¤±å½æ¸ï¼åè¨±å¨ä½å¯åº¦è³æä¸è¨ç·´çè¼éç´å­¸çæ¨¡åå¾å¨é«å¯åº¦è³æä¸è¨ç·´çèå¸«æ¨¡åä¸­å­¸ç¿ï¼ééå°æ¯èåææèçéºå¤±çé»æ¥µãçºäºæ´åå³è¼¸å­¸ç¿åèåï¼æåééå¨é è¨ç·´æéå°æ¯å®åçæ¥è©¢åéé°ï¼å±åé è¨ç·´èå¸«åå­¸çæ¨¡åï¼çºä¸æ¸¸ä»»ååç¨ç©©å¥çèåå¨ãæåå¨å©åè¨åºè¦é»åè³æéä¸å±ç¤ºäºæåçæ¹æ³å¨åååé¡ä»»åä¸­çæææ§ï¼éäºè³æéå·æå¤§éçæªæ¨ç±¤è³æåæéçæ¨ç±¤è³æãå¯¦é©çµæè¡¨æï¼æåçåæ³å¨æçåæºç¢ºæ§æ¹é¢é½é¡¯èåªæ¼ç¶ä»£æ¹æ³ã</paragraph>

##### **Open-Sora Plan: Open-Source Large Video Generation Model**
2412.00131v1 by Bin Lin, Yunyang Ge, Xinhua Cheng, Zongjian Li, Bin Zhu, Shaodong Wang, Xianyi He, Yang Ye, Shenghai Yuan, Liuhan Chen, Tanghui Jia, Junwu Zhang, Zhenyu Tang, Yatian Pang, Bin She, Cen Yan, Zhiheng Hu, Xiaoyi Dong, Lin Chen, Zhang Pan, Xing Zhou, Shaoling Dong, Yonghong Tian, Li Yuan

We introduce Open-Sora Plan, an open-source project that aims to contribute a
large generation model for generating desired high-resolution videos with long
durations based on various user inputs. Our project comprises multiple
components for the entire video generation process, including a Wavelet-Flow
Variational Autoencoder, a Joint Image-Video Skiparse Denoiser, and various
condition controllers. Moreover, many assistant strategies for efficient
training and inference are designed, and a multi-dimensional data curation
pipeline is proposed for obtaining desired high-quality data. Benefiting from
efficient thoughts, our Open-Sora Plan achieves impressive video generation
results in both qualitative and quantitative evaluations. We hope our careful
design and practical experience can inspire the video generation research
community. All our codes and model weights are publicly available at
\url{https://github.com/PKU-YuanGroup/Open-Sora-Plan}.

æè¦ï¼æåæ¨åº Open-Sora Planï¼éæ¯ä¸åéæ¾åå§ç¢¼å°æ¡ï¼æ¨å¨çºæ ¹æåç¨®ä½¿ç¨èè¼¸å¥ä¾ç¢çæéçé«è§£æåº¦å½±çæä¾ä¸åå¤§åçææ¨¡åï¼ä¸¦å·åé·æéçæçºæéãæåçå°æ¡åå«äºæ´åå½±ççæèçæµç¨çå¤åçµæé¨åï¼åæ¬å°æ³¢æµè®åèªåç·¨ç¢¼å¨ãè¯åå½±åå½±ç Skiparse å»éè¨å¨ï¼ä»¥ååç¨®æ¢ä»¶æ§å¶å¨ãæ­¤å¤ï¼éè¨­è¨äºè¨±å¤ç¨æ¼é«æè¨ç·´èæ¨è«çè¼å©ç­ç¥ï¼ä¸¦æåºäºä¸åå¤ç¶­è³æç­å±ç®¡éï¼ç¨æ¼åå¾æéçé«åè³ªè³æãåçæ¼é«æçæ³æ³ï¼æåç Open-Sora Plan å¨å®æ§åå®éè©ä¼°ä¸­é½éå°äºä»¤äººå°è±¡æ·±å»çå½±ççæçµæãæåå¸ææåä»ç´°çè¨­è¨åå¯¦åç¶é©å¯ä»¥æ¿åµå½±ççæç ç©¶ç¤¾ç¾¤ãæåææçç¨å¼ç¢¼åæ¨¡åæ¬éé½å¬éå¨ \url{https://github.com/PKU-YuanGroup/Open-Sora-Plan}ã

##### **CovidLLM: A Robust Large Language Model with Missing Value Adaptation and Multi-Objective Learning Strategy for Predicting Disease Severity and Clinical Outcomes in COVID-19 Patients**
2412.03593v1 by Shengjun Zhu, Siyu Liu, Yang Li, Qing Lei, Hongyan Hou, Hewei Jiang, Shujuan Guo, Feng Wang, Rongshang Chen, Xionglin Fan, Shengce Tao, Jiaxin Cai

Coronavirus Disease 2019 (COVID-19), which emerged in 2019, has caused
millions of deaths worldwide. Although effective vaccines have been developed
to mitigate severe symptoms, certain populations, particularly the elderly and
those with comorbidities, remain at high risk for severe outcomes and increased
mortality. Consequently, early identification of the severity and clinical
outcomes of the disease in these patients is vital to prevent adverse
prognoses. Although traditional machine learning and deep learning models have
been widely employed in this area, the potential of large language models
(LLMs) remains largely unexplored. Our research focuses primarily on
constructing specialized prompts and adopting multi-objective learning
strategies. We started by selecting serological indicators that significantly
correlate with clinical outcomes and disease severity to serve as input data
for the model. Blood test samples often contain numerous missing values, and
traditional models generally rely on imputation to handle these gaps in the
data. In contrast, LLMs offer the advantage of robust semantic understanding.
By setting prompts, we can explicitly inform the model when a feature's value
is missing, without the need for imputation. For the multi-objective learning
strategy, the model is designed to first predict disease severity and then
predict clinical outcomes. Given that LLMs utilize both the input text and the
generated tokens as input for generating the next token, the predicted severity
is used as a basis for generating the clinical outcome. During the fine-tuning
of the LLM, the two objectives influence and improve each other. Our
experiments were implemented based on the ChatGLM model. The results
demonstrate the effectiveness of LLMs in this task, suggesting promising
potential for further development.

æè¦ï¼2019 å¹´åºç¾çå ççæ¯ç¾ç (COVID-19) å·²é æå¨çæ¸ç¾è¬äººæ­»äº¡ãåç®¡å·²ç ç¼åºææçç«èä¾æ¸è¼å´éççï¼ä½æäºæç¾¤ï¼å°¤å¶æ¯èå¹´äººåæåä½µçèï¼ä»ç¶é¢è¨å´éçå¾æåæ­»äº¡çå¢å çé«é¢¨éªãå æ­¤ï¼åæ©è¾¨è­éäºæ£èçç¾çå´éç¨åº¦åè¨åºçµæå°æ¼é é²ä¸è¯é å¾è³ééè¦ãåç®¡å³çµ±æ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿æ¨¡åå·²å»£æ³ç¨æ¼æ­¤é åï¼ä½å¤§åèªè¨æ¨¡å (LLM) çæ½åä»æªè¢«ååæ¢ç´¢ãæåçç ç©¶ä¸»è¦å°æ³¨æ¼å»ºæ§å°æ¥­æç¤ºåæ¡ç¨å¤ç®æ¨å­¸ç¿ç­ç¥ãæåé¦åé¸æèè¨åºçµæåç¾çå´éç¨åº¦é¡¯èç¸éçè¡æ¸ææ¨ï¼ä½çºæ¨¡åçè¼¸å¥è³æãè¡æ¶²æª¢é©æ¨£æ¬éå¸¸åå«è¨±å¤ç¼ºå¤±å¼ï¼èå³çµ±æ¨¡åéå¸¸ä¾è³´æè£ä¾èçè³æä¸­çéäºç©ºç½ãç¸æ¯ä¹ä¸ï¼LLM æä¾äºå¼·å¤§çèªç¾©çè§£åªå¢ãééè¨­å®æç¤ºï¼æåå¯ä»¥æç¢ºåç¥æ¨¡åä½æç¼ºå°ç¹å¾µå¼ï¼èç¡éæè£ãå°æ¼å¤ç®æ¨å­¸ç¿ç­ç¥ï¼æ¨¡åè¢«è¨­è¨çºåé æ¸¬ç¾çå´éç¨åº¦ï¼ç¶å¾é æ¸¬è¨åºçµæãç±æ¼ LLM å°è¼¸å¥æå­åç¢ççç¬¦èåæä½çºè¼¸å¥ä¾ç¢çä¸ä¸åç¬¦èï¼å æ­¤é æ¸¬çå´éç¨åº¦è¢«ç¨ä½ç¢çè¨åºçµæçåºç¤ãå¨ LLM çå¾®èª¿éç¨ä¸­ï¼éå©åç®æ¨æç¸äºå½±é¿åæ¹åãæåçå¯¦é©æ¯åºæ¼ ChatGLM æ¨¡åå¯¦ä½çãçµæè­æäº LLM å¨æ­¤ä»»åä¸­çæææ§ï¼é¡¯ç¤ºåºé²ä¸æ­¥ç¼å±çæ½åã

##### **A Unified Platform for At-Home Post-Stroke Rehabilitation Enabled by Wearable Technologies and Artificial Intelligence**
2411.19000v1 by Chenyu Tang, Ruizhi Zhang, Shuo Gao, Zihe Zhao, Zibo Zhang, Jiaqi Wang, Cong Li, Junliang Chen, Yanning Dai, Shengbo Wang, Ruoyu Juan, Qiaoying Li, Ruimou Xie, Xuhang Chen, Xinkai Zhou, Yunjia Xia, Jianan Chen, Fanghao Lu, Xin Li, Ninglli Wang, Peter Smielewski, Yu Pan, Hubin Zhao, Luigi G. Occhipinti

At-home rehabilitation for post-stroke patients presents significant
challenges, as continuous, personalized care is often limited outside clinical
settings. Additionally, the absence of comprehensive solutions addressing
diverse rehabilitation needs in home environments complicates recovery efforts.
Here, we introduce a smart home platform that integrates wearable sensors,
ambient monitoring, and large language model (LLM)-powered assistance to
provide seamless health monitoring and intelligent support. The system
leverages machine learning enabled plantar pressure arrays for motor recovery
assessment (94% classification accuracy), a wearable eye-tracking module for
cognitive evaluation, and ambient sensors for precise smart home control (100%
operational success, <1 s latency). Additionally, the LLM-powered agent,
Auto-Care, offers real-time interventions, such as health reminders and
environmental adjustments, enhancing user satisfaction by 29%. This work
establishes a fully integrated platform for long-term, personalized
rehabilitation, offering new possibilities for managing chronic conditions and
supporting aging populations.

æè¦ï¼å±å®¶å¾©å¥å°æ¼ä¸­é¢¨æ£èä¾èªªæ¯ä¸å¤§ææ°ï¼å çºæçºä¸åäººåçç§è­·éå¸¸å¨è¨åºç°å¢ä¹å¤åå°éå¶ãæ­¤å¤ï¼ç¼ºä¹è§£æ±ºå±å®¶ç°å¢ä¸­å¤åå¾©å¥éæ±çå¨é¢æ§è§£æ±ºæ¹æ¡ï¼è®å¾©åå·¥ä½æ´å½¢è¤éãå¨æ­¤ï¼æåä»ç´¹ä¸åæ´åç©¿æ´å¼ææ¸¬å¨ãç°å¢ç£æ§åå¤§åèªè¨æ¨¡å (LLM) é©ååå©çæºæ§å±å®¶å¹³å°ï¼æä¾ç¡ç¸«çå¥åº·ç£æ§åæºæ§æ¯æ´ãæ­¤ç³»çµ±å©ç¨æ©å¨å­¸ç¿åç¨çè¶³åºå£åé£åé²è¡éåå¾©åè©ä¼° (94% åé¡æºç¢ºåº¦)ãç©¿æ´å¼ç¼çè¿½è¹¤æ¨¡çµé²è¡èªç¥è©ä¼°ï¼ä»¥åç°å¢ææ¸¬å¨é²è¡ç²¾æºçæºæ§å±å®¶æ§å¶ (100% æä½æåï¼<1 ç§å»¶é²)ãæ­¤å¤ï¼LLM é©åçä»£çç¨å¼ Auto-Care æä¾å³æä»å¥æªæ½ï¼ä¾å¦å¥åº·æéåç°å¢èª¿æ´ï¼å°ä½¿ç¨èæ»¿æåº¦æå 29%ãéé å·¥ä½å»ºç«äºä¸åé·æãåäººåçå¾©å¥å¨æ´åå¹³å°ï¼çºç®¡çæ¢æ§ç¾çåæ¯æé«é½¡äººå£æä¾äºæ°çå¯è½æ§ã

##### **Devising a Set of Compact and Explainable Spoken Language Feature for Screening Alzheimer's Disease**
2411.18922v1 by Junan Li, Yunxiang Li, Yuren Wang, Xixin Wu, Helen Meng

Alzheimer's disease (AD) has become one of the most significant health
challenges in an aging society. The use of spoken language-based AD detection
methods has gained prevalence due to their scalability due to their
scalability. Based on the Cookie Theft picture description task, we devised an
explainable and effective feature set that leverages the visual capabilities of
a large language model (LLM) and the Term Frequency-Inverse Document Frequency
(TF-IDF) model. Our experimental results show that the newly proposed features
consistently outperform traditional linguistic features across two different
classifiers with high dimension efficiency. Our new features can be well
explained and interpreted step by step which enhance the interpretability of
automatic AD screening.

æè¦ï¼é¿è²æµ·é»ç (AD) å·²æçºé«é½¡åç¤¾æä¸­æéè¦çå¥åº·ææ°ä¹ä¸ãåºæ¼å¶å¯æ´åæ§ï¼ä½¿ç¨åºæ¼å£èªç AD æª¢æ¸¬æ¹æ³å·²ç²å¾æ®éä½¿ç¨ãæ ¹æ Cookie Theft åçæè¿°ä»»åï¼æåè¨­è¨äºä¸åå¯è§£éä¸ææçç¹å¾µéï¼å®å©ç¨å¤§åèªè¨æ¨¡å (LLM) çè¦è¦ºåè½åè©é »-éåæä»¶é »ç (TF-IDF) æ¨¡åãæåçå¯¦é©çµæè¡¨æï¼æ°æåºçç¹å¾µå¨å©åä¸ååé¡å¨ä¸­å§çµåªæ¼å³çµ±èªè¨ç¹å¾µï¼ä¸å·æé«ç¶­åº¦æçãæåçç¹å¾µå¯ä»¥å¾å¥½å°è§£éåéæ­¥è©®éï¼éå¢å¼·äºèªå AD ç¯©æª¢çå¯è§£éæ§ã

##### **LLM-ABBA: Understanding time series via symbolic approximation**
2411.18506v3 by Erin Carson, Xinye Chen, Cheng Kang

The success of large language models (LLMs) for time series has been
demonstrated in previous work. Utilizing a symbolic time series representation,
one can efficiently bridge the gap between LLMs and time series. However, the
remaining challenge is to exploit the semantic information hidden in time
series by using symbols or existing tokens of LLMs, while aligning the
embedding space of LLMs according to the hidden information of time series. The
symbolic time series approximation (STSA) method called adaptive Brownian
bridge-based symbolic aggregation (ABBA) shows outstanding efficacy in
preserving salient time series features by modeling time series patterns in
terms of amplitude and period while using existing tokens of LLMs.
  In this paper, we introduce a method, called LLM-ABBA, that integrates ABBA
into large language models for various downstream time series tasks. By
symbolizing time series, LLM-ABBA compares favorably to the recent
state-of-the-art (SOTA) in UCR and three medical time series classification
tasks. Meanwhile, a fixed-polygonal chain trick in ABBA is introduced to
\kc{avoid obvious drifting} during prediction tasks by significantly mitigating
the effects of cumulative error arising from misused symbols during the
transition from symbols to numerical values. In time series regression tasks,
LLM-ABBA achieves the new SOTA on Time Series Extrinsic Regression (TSER)
benchmarks. LLM-ABBA also shows competitive prediction capability compared to
recent SOTA time series prediction results. We believe this framework can also
seamlessly extend to other time series tasks.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨æéåºåæ¹é¢çæåå·²å¨ååçç ç©¶ä¸­å¾å°è­æãå©ç¨ç¬¦èæéåºåè¡¨ç¤ºï¼å¯ä»¥ææå°å½å LLM åæéåºåä¹éçå·®è·ãç¶èï¼å©ä¸çææ°æ¯å©ç¨ç¬¦èæç¾æ LLM æ¨è¨ä¾å©ç¨é±èå¨æéåºåä¸­çèªç¾©è³è¨ï¼åææ ¹ææéåºåçé±èè³è¨å°é½ LLM çåµå¥ç©ºéãç¨±çºèªé©æå¸ææ©ç¬¦èèå (ABBA) çç¬¦èæéåºåè¿ä¼¼ (STSA) æ¹æ³å¨ééæ¯å¹åé±æä¾å»ºæ¨¡æéåºåæ¨¡å¼ï¼åæä½¿ç¨ç¾æ LLM æ¨è¨æ¹é¢ï¼å±ç¾åºå¨ä¿çé¡¯èæéåºåç¹å¾µæ¹é¢çåºè²åæã
å¨æ¬æä¸­ï¼æåä»ç´¹ä¸ç¨®ç¨±çº LLM-ABBA çæ¹æ³ï¼å®å° ABBA æ´åå°å¤§åèªè¨æ¨¡åä¸­ï¼ä»¥å·è¡åç¨®ä¸æ¸¸æéåºåä»»åãééå°æéåºåç¬¦èåï¼LLM-ABBA è UCR åä¸åé«çæéåºååé¡ä»»åä¸­çææ°æè¡ (SOTA) ç¸æ¯ï¼å·ææé¡¯çåªå¢ãåæï¼ABBA ä¸­å¼å¥äºåºå®å¤éå½¢éæå·§ï¼ééå¤§å¹æ¸è¼å¾ç¬¦èè½æçºæ¸å¼æï¼å èª¤ç¨ç¬¦èèç¢ççç´¯ç©èª¤å·®å½±é¿ï¼ä¾é¿åå¨é æ¸¬ä»»åæéåºç¾æé¡¯çæ¼ç§»ãå¨æéåºååæ­¸ä»»åä¸­ï¼LLM-ABBA å¨æéåºåå¤å¨åæ­¸ (TSER) åºæºä¸éå°äºæ°ç SOTAãèæè¿ç SOTA æéåºåé æ¸¬çµæç¸æ¯ï¼LLM-ABBA ä¹å±ç¾åºå·ç«¶ç­åçé æ¸¬è½åãæåç¸ä¿¡éåæ¶æ§ä¹å¯ä»¥ç¡ç¸«å°æ´åå°å¶ä»æéåºåä»»åã

##### **MvKeTR: Chest CT Report Generation with Multi-View Perception and Knowledge Enhancement**
2411.18309v1 by Xiwei Deng, Xianchun He, Yudan Zhou, Shuhui Cai, Congbo Cai, Zhong Chen

CT report generation (CTRG) aims to automatically generate diagnostic reports
for 3D volumes, relieving clinicians' workload and improving patient care.
Despite clinical value, existing works fail to effectively incorporate
diagnostic information from multiple anatomical views and lack related clinical
expertise essential for accurate and reliable diagnosis. To resolve these
limitations, we propose a novel Multi-view perception Knowledge-enhanced
Tansformer (MvKeTR) to mimic the diagnostic workflow of clinicians. Just as
radiologists first examine CT scans from multiple planes, a Multi-View
Perception Aggregator (MVPA) with view-aware attention effectively synthesizes
diagnostic information from multiple anatomical views. Then, inspired by how
radiologists further refer to relevant clinical records to guide diagnostic
decision-making, a Cross-Modal Knowledge Enhancer (CMKE) retrieves the most
similar reports based on the query volume to incorporate domain knowledge into
the diagnosis procedure. Furthermore, instead of traditional MLPs, we employ
Kolmogorov-Arnold Networks (KANs) with learnable nonlinear activation functions
as the fundamental building blocks of both modules to better capture intricate
diagnostic patterns in CT interpretation. Extensive experiments on the public
CTRG-Chest-548K dataset demonstrate that our method outpaces prior
state-of-the-art models across all metrics.

æè¦ï¼é»è¦æ·å±¤å ±åçæï¼CTRGï¼æ¨å¨èªåçæ 3D é«ç©çè¨ºæ·å ±åï¼æ¸è¼è¨åºé«å¸«çå·¥ä½éä¸¦æ¹åæ£èç§è­·ã
åç®¡å·æè¨åºå¹å¼ï¼ç¾æç ç©¶ç¡æ³æææ´åä¾èªå¤åè§£åè¦åçè¨ºæ·è³è¨ï¼ä¸¦ä¸ç¼ºä¹æºç¢ºä¸å¯é è¨ºæ·æå¿éçç¸éè¨åºå°æ¥­ç¥è­ãçºäºè§£æ±ºéäºéå¶ï¼æåæåºäºä¸ç¨®æ°ç©çå¤è¦è¦ºæç¥ç¥è­å¢å¼·è½æå¨ (MvKeTR) ä¾æ¨¡æ¬è¨åºé«å¸«çè¨ºæ·å·¥ä½æµç¨ãæ­£å¦æ¾å°ç§é«å¸«é¦åå¾å¤åå¹³é¢æª¢æ¥é»è¦æ·å±¤ææï¼å·æè¦åæç¥æ³¨æåçå¤è¦è¦ºæç¥èåå¨ (MVPA) ææå°ç¶åäºä¾èªå¤åè§£åè¦åçè¨ºæ·è³è¨ãæ¥èï¼åå°æ¾å°ç§é«å¸«å¦ä½é²ä¸æ­¥åèç¸éè¨åºè¨éä¾æå°è¨ºæ·æ±ºç­çåç¼ï¼è·¨æ¨¡æç¥è­å¢å¼·å¨ (CMKE) åºæ¼æ¥è©¢é«ç©æ·åæç¸ä¼¼çå ±åï¼ä»¥å°é åç¥è­ç´å¥è¨ºæ·ç¨åºãæ­¤å¤ï¼æåæ¡ç¨å·æå¯å­¸ç¿éç·æ§åç¨å½æ¸ç Kolmogorov-Arnold ç¶²è·¯ (KAN) ä½çºå©åæ¨¡çµçåºæ¬å»ºæ§æ¨¡çµï¼èä¸æ¯å³çµ±çå¤å±¤æç¥å¨ï¼ä»¥å¨é»è¦æ·å±¤è©®éä¸­æ´å¥½å°æ·åè¤éçè¨ºæ·æ¨¡å¼ãå¨å¬å± CTRG-Chest-548K è³æéä¸çå»£æ³å¯¦é©è­æï¼æåçæ¨¡åå¨ææææ¨ä¸é½è¶è¶äºååçæåé²æ¨¡åã

##### **Wearable intelligent throat enables natural speech in stroke patients with dysarthria**
2411.18266v2 by Chenyu Tang, Shuo Gao, Cong Li, Wentian Yi, Yuxuan Jin, Xiaoxue Zhai, Sixuan Lei, Hongbei Meng, Zibo Zhang, Muzi Xu, Shengbo Wang, Xuhang Chen, Chenxi Wang, Hongyun Yang, Ningli Wang, Wenyu Wang, Jin Cao, Xiaodong Feng, Peter Smielewski, Yu Pan, Wenhui Song, Martin Birchall, Luigi G. Occhipinti

Wearable silent speech systems hold significant potential for restoring
communication in patients with speech impairments. However, seamless, coherent
speech remains elusive, and clinical efficacy is still unproven. Here, we
present an AI-driven intelligent throat (IT) system that integrates throat
muscle vibrations and carotid pulse signal sensors with large language model
(LLM) processing to enable fluent, emotionally expressive communication. The
system utilizes ultrasensitive textile strain sensors to capture high-quality
signals from the neck area and supports token-level processing for real-time,
continuous speech decoding, enabling seamless, delay-free communication. In
tests with five stroke patients with dysarthria, IT's LLM agents intelligently
corrected token errors and enriched sentence-level emotional and logical
coherence, achieving low error rates (4.2% word error rate, 2.9% sentence error
rate) and a 55% increase in user satisfaction. This work establishes a
portable, intuitive communication platform for patients with dysarthria with
the potential to be applied broadly across different neurological conditions
and in multi-language support systems.

æè¦ï¼å¯ç©¿æ´å¼æ å£°è¯­é³ç³»ç»å¨æ¢å¤è¨è¯­éç¢æ£èçæ²éè½åæ¹é¢å·æéå¤§æ½åãç¶èï¼æ ç¼ãè¿è´¯çè¯­é³ä»ç¶é¾ä»¥å®ç°ï¼ä¸´åºçæä»æªå¾å°è¯å®ãå¨æ­¤ï¼æä»¬æåºäºä¸ç§äººå·¥æºè½é©±å¨çæºè½åå (IT) ç³»ç»ï¼å®å°ååèèæ¯å¨åé¢å¨èèå²ä¿¡å·ä¼ æå¨ä¸å¤§è¯­è¨æ¨¡å (LLM) å¤çç¸ç»åï¼ä»¥å®ç°æµçãå¯æææè¡¨ç°åçæ²éãè¯¥ç³»ç»å©ç¨è¶çµæçººç»ååºåä¼ æå¨ä»é¢é¨åºåæè·é«è´¨éä¿¡å·ï¼å¹¶æ¯æä»¤ççº§å¤çï¼ä»¥è¿è¡å®æ¶ãè¿ç»­çè¯­é³è§£ç ï¼ä»èå®ç°æ ç¼ãæ å»¶è¿çéä¿¡ãå¨å¯¹äºåæ£ææé³éç¢çä¸­é£æ£èè¿è¡çæµè¯ä¸­ï¼IT ç LLM ä»£çæºè½å°çº æ­£äºä»¤çéè¯¯ï¼å¹¶ä¸°å¯äºå¥å­çº§å«çè¯­ä¹åé»è¾è¿è´¯æ§ï¼å®ç°äºè¾ä½çéè¯¯çï¼4.2% çåè¯éè¯¯çï¼2.9% çå¥å­éè¯¯çï¼å 55% çç¨æ·æ»¡æåº¦æåãè¿é¡¹å·¥ä½ä¸ºæé³éç¢æ£èå»ºç«äºä¸ä¸ªä¾¿æºãç´è§çæ²éå¹³å°ï¼æå¯è½å¹¿æ³åºç¨äºä¸åçç¥ç»ç³»ç»ç¾çåå¤è¯­è¨æ¯æç³»ç»ã

##### **Multimodal Integration of Longitudinal Noninvasive Diagnostics for Survival Prediction in Immunotherapy Using Deep Learning**
2411.18253v1 by Melda Yeghaian, Zuhir Bodalal, Daan van den Broek, John B A G Haanen, Regina G H Beets-Tan, Stefano Trebeschi, Marcel A J van Gerven

Purpose: Analyzing noninvasive longitudinal and multimodal data using
artificial intelligence could potentially transform immunotherapy for cancer
patients, paving the way towards precision medicine. Methods: In this study, we
integrated pre- and on-treatment blood measurements, prescribed medications and
CT-based volumes of organs from a large pan-cancer cohort of 694 patients
treated with immunotherapy to predict short and long-term overall survival. By
leveraging a combination of recent developments, different variants of our
extended multimodal transformer-based simple temporal attention (MMTSimTA)
network were trained end-to-end to predict mortality at three, six, nine and
twelve months. These models were also compared to baseline methods
incorporating intermediate and late fusion based integration methods. Results:
The strongest prognostic performance was demonstrated using the extended
transformer-based multimodal model with area under the curves (AUCs) of $0.84
\pm $0.04, $0.83 \pm $0.02, $0.82 \pm $0.02, $0.81 \pm $0.03 for 3-, 6-, 9-,
and 12-month survival prediction, respectively. Conclusion: Our findings
suggest that analyzing integrated early treatment data has potential for
predicting survival of immunotherapy patients. Integrating complementary
noninvasive modalities into a jointly trained model, using our extended
transformer-based architecture, demonstrated an improved multimodal prognostic
performance, especially in short term survival prediction.

æè¦ï¼<paragraph>ç®çï¼ä½¿ç¨äººå·¥æºè½åæéä¾µå¥æ§çºµåå¤æ¨¡ææ°æ®å¯è½ä¼æ¹åççæ£èçåç«æ²»çï¼ä¸ºç²¾åå»çéºå¹³éè·¯ãæ¹æ³ï¼å¨è¿é¡¹ç ç©¶ä¸­ï¼æä»¬æ´åäº 694 åæ¥ååç«æ²»ççççæ£èéåçæ²»çååæ²»çä¸­çè¡æ¶²æµéå¼ãå¤æ¹è¯ååºäº CT çå¨å®ä½ç§¯ï¼ä»¥é¢æµç­æåé¿ææ»ä½çå­çãéè¿å©ç¨æè¿åå±çç»åï¼æä»¬æ©å±çå¤æ¨¡æåºäº Transformer çç®åæ¶é´æ³¨æå (MMTSimTA) ç½ç»çä¸ååä½ç»è¿ç«¯å°ç«¯è®­ç»ï¼ä»¥é¢æµä¸ä¸ªãå­ä¸ªãä¹ä¸ªååäºä¸ªæçæ­»äº¡çãè¿äºæ¨¡åè¿ä¸ç»åäºåºäºä¸­é´èåååæèåçéææ¹æ³çåºçº¿æ¹æ³è¿è¡äºæ¯è¾ãç»æï¼ä½¿ç¨æ©å±çåºäº Transformer çå¤æ¨¡ææ¨¡åå±ç¤ºäºæå¼ºçé¢åè¡¨ç°ï¼æ²çº¿ä¸é¢ç§¯ (AUC) åå«ä¸º 3 ä¸ªã6 ä¸ªã9 ä¸ªå 12 ä¸ªæççå­é¢æµä¸º 0.84 Â± 0.04ã0.83 Â± 0.02ã0.82 Â± 0.02ã0.81 Â± 0.03ãç»è®ºï¼æä»¬çç ç©¶ç»æè¡¨æï¼åææ´åçæ©ææ²»çæ°æ®æå¯è½é¢æµåç«æ²»çæ£èççå­çãä½¿ç¨æä»¬æ©å±çåºäº Transformer çæ¶æï¼å°äºè¡¥çéä¾µå¥æ§æ¹å¼æ´åå°ä¸ä¸ªèåè®­ç»çæ¨¡åä¸­ï¼å±ç¤ºäºæ¹è¿çå¤æ¨¡æé¢åè¡¨ç°ï¼å°¤å¶æ¯å¨ç­æçå­é¢æµä¸­ã</paragraph>

##### **Randomized-Grid Search for Hyperparameter Tuning in Decision Tree Model to Improve Performance of Cardiovascular Disease Classification**
2411.18234v1 by Abhay Kumar Pathak, Mrityunjay Chaubey, Manjari Gupta

Cardiovascular disease refers to any critical condition that impacts the
heart. Because heart diseases can be life-threatening. Researchers are focusing
on designing smart systems to accurately diagnose them based on electronic
health data, with the aid of machine learning algorithms. Heart disease
classification using machine learning (ML) algorithms such as Support Vector
Machine(SVM), Na\"ive Bayes(NB), Decision Trees (DTs) and Random Forests (RFs)
are often hindered by overfitting. These ML algorithms need extensive
hyperparameter tuning. Random Search offers a faster, and, more efficient
exploration of hyperparameter space, but, it may overlook optimal regions. Grid
Search, though exhaustive, but, it is computationally expensive and
inefficient, particularly with high-dimensional data. To address these
limitations, Randomized-Grid Search, a novel hybrid optimization method is
proposed that combines the global exploration strengths of Random Search with
the focused, and, exhaustive search of Grid Search in the most promising
regions. This hybrid approach efficiently balances exploration and
exploitation. The proposed model optimizes the hyperparameter for Decision Tree
model. The proposed model is applied to UCI heart disease dataset for
classification. It enhances model performance, provides improved accuracy,
generalization, and computational efficiency. Experimental results demonstrate
that Randomized-Grid Search outperforms traditional methods by significant
margins. The proposed model provides a more effective solution for machine
learning applications in healthcare diagnosis.

æè¦ï¼å¿è¡ç®¡ç¾çæ¯æä»»ä½å½±åå¿èçå±æ¥ç¶åµãç±äºå¿èç¾çå¯è½å±åçå½ãç ç©¶äººåæ­£ä¸æ³¨äºè®¾è®¡æºè½ç³»ç»ï¼ä»¥åå©æºå¨å­¦ä¹ ç®æ³æ ¹æ®çµå­å¥åº·æ°æ®åç¡®è¯æ­å¿èç¾çãä½¿ç¨æºå¨å­¦ä¹  (ML) ç®æ³ï¼å¦æ¯æåéæº (SVM)ãæ´ç´ è´å¶æ¯ (NB)ãå³ç­æ  (DT) åéæºæ£®æ (RF)ï¼è¿è¡å¿èçåç±»éå¸¸ä¼åå°è¿åº¦æåçé»ç¢ãè¿äº ML ç®æ³éè¦å¹¿æ³çè¶åæ°è°æ´ãéæºæç´¢æä¾äºå¯¹è¶åæ°ç©ºé´æ´å¿«éãæ´é«æçæ¢ç´¢ï¼ä½å®å¯è½ä¼å¿½ç¥æä¼åºåãç½æ ¼æç´¢è½ç¶è¯¦å°½ï¼ä½è®¡ç®ææ¬é«ä¸æçä½ä¸ï¼å°¤å¶æ¯å¨å¤çé«ç»´æ°æ®æ¶ãä¸ºäºè§£å³è¿äºéå¶ï¼æåºäºä¸ç§æ°é¢çæ··åä¼åæ¹æ³éæºç½æ ¼æç´¢ï¼å®å°éæºæç´¢çå¨å±æ¢ç´¢ä¼å¿ä¸ç½æ ¼æç´¢å¨ææå¸æçåºåä¸­çéä¸­åè¯¦å°½æç´¢ç¸ç»åãè¿ç§æ··åæ¹æ³ææå°å¹³è¡¡äºæ¢ç´¢åå©ç¨ãææåºçæ¨¡åä¼åäºå³ç­æ æ¨¡åçè¶åæ°ãææåºçæ¨¡ååºç¨äº UCI å¿èçæ°æ®éè¿è¡åç±»ãå®å¢å¼ºäºæ¨¡åæ§è½ï¼æé«äºåç¡®æ§ãæ³åè½ååè®¡ç®æçãå®éªç»æè¡¨æï¼éæºç½æ ¼æç´¢ä»¥æ¾èçä¼å¿ä¼äºä¼ ç»æ¹æ³ãææåºçæ¨¡åä¸ºå»çè¯æ­ä¸­çæºå¨å­¦ä¹ åºç¨æä¾äºæ´ææçè§£å³æ¹æ¡ã

##### **The Return of Pseudosciences in Artificial Intelligence: Have Machine Learning and Deep Learning Forgotten Lessons from Statistics and History?**
2411.18656v1 by JÃ©rÃ©mie Sublime

In today's world, AI programs powered by Machine Learning are ubiquitous, and
have achieved seemingly exceptional performance across a broad range of tasks,
from medical diagnosis and credit rating in banking, to theft detection via
video analysis, and even predicting political or sexual orientation from facial
images. These predominantly deep learning methods excel due to their
extraordinary capacity to process vast amounts of complex data to extract
complex correlations and relationship from different levels of features.
  In this paper, we contend that the designers and final users of these ML
methods have forgotten a fundamental lesson from statistics: correlation does
not imply causation. Not only do most state-of-the-art methods neglect this
crucial principle, but by doing so they often produce nonsensical or flawed
causal models, akin to social astrology or physiognomy. Consequently, we argue
that current efforts to make AI models more ethical by merely reducing biases
in the training data are insufficient. Through examples, we will demonstrate
that the potential for harm posed by these methods can only be mitigated by a
complete rethinking of their core models, improved quality assessment metrics
and policies, and by maintaining humans oversight throughout the process.

æè¦ï¼å¨ç¶ä»ä¸çï¼ç±æ©å¨å­¸ç¿é©åçäººå·¥æºæ§ç¨å¼ç¡èä¸å¨ï¼ä¸¦ä¸å¨å»£æ³çä»»åä¸­å¯¦ç¾äºçä¼¼åè¶çæè½ï¼å¾é«çè¨ºæ·åéè¡æ¥­ä¿¡ç¨è©åï¼å°ééå½±çåæé²è¡ç«çåµæ¸¬ï¼çè³å¾èé¨å½±åé æ¸¬æ¿æ²»ææ§ååãéäºä¸»è¦æ·±åº¦å­¸ç¿æ¹æ³ä¹æä»¥åºè²ï¼æ¯å çºå®åå·æéå¡çèçå¤§éè¤éè³æçè½åï¼å¾ä¸åå±¤ç´çç¹å¾µä¸­æåè¤éçéè¯æ§åéä¿ã
å¨æ¬æä¸­ï¼æåèªçºéäºæ©å¨å­¸ç¿æ¹æ³çè¨­è¨èåæçµä½¿ç¨èå¿è¨äºçµ±è¨å­¸ä¸­çåºæ¬æè¨ï¼ç¸éæ§ä¸¦ä¸æå³èå æéä¿ãæåé²çæ¹æ³ä¸åå¿½ç¥äºéé ééµååï¼èä¸ééº¼åæï¼å®åéå¸¸æç¢çèè¬¬ææç¼ºé·çå ææ¨¡åï¼é¡ä¼¼æ¼ç¤¾æå æå­¸æé¢ç¸å­¸ãå æ­¤ï¼æåèªçºç¶åééåæ¸å°è¨ç·´è³æä¸­çåå·®ä¾è®äººå·¥æºæ§æ¨¡åæ´å·å«ççåæ³æ¯ä¸å¤ çãééç¯ä¾ï¼æåå°è­æéäºæ¹æ³é æçæ½å¨å±å®³åªè½ééå¾¹åºéæ°æèå¶æ ¸å¿æ¨¡åãæ¹ååè³ªè©ä¼°ææ¨åæ¿ç­ï¼ä»¥åå¨æ´åéç¨ä¸­ç¶­æäººé¡ç£ç£ä¾æ¸è¼ã

##### **Graph Neural Network for Cerebral Blood Flow Prediction With Clinical Datasets**
2411.17971v1 by Seungyeon Kim, Wheesung Lee, Sung-Ho Ahn, Do-Eun Lee, Tae-Rin Lee

Accurate prediction of cerebral blood flow is essential for the diagnosis and
treatment of cerebrovascular diseases. Traditional computational methods,
however, often incur significant computational costs, limiting their
practicality in real-time clinical applications. This paper proposes a graph
neural network (GNN) to predict blood flow and pressure in previously unseen
cerebral vascular network structures that were not included in training data.
The GNN was developed using clinical datasets from patients with stenosis,
featuring complex and abnormal vascular geometries. Additionally, the GNN model
was trained on data incorporating a wide range of inflow conditions, vessel
topologies, and network connectivities to enhance its generalization
capability. The approach achieved Pearson's correlation coefficients of 0.727
for pressure and 0.824 for flow rate, with sufficient training data. These
findings demonstrate the potential of the GNN for real-time cerebrovascular
diagnostics, particularly in handling intricate and pathological vascular
networks.

æè¦ï¼æºç¢ºé æ¸¬è¦é¨è¡æµå°æ¼è¦è¡ç®¡ç¾ççè¨ºæ·åæ²»çè³ééè¦ãç¶èï¼å³çµ±çè¨ç®æ¹æ³éå¸¸æç¢çå¤§éçè¨ç®ææ¬ï¼éå¶äºå®åå¨è¨åºæç¨ä¸­çå¯¦ç¨æ§ãæ¬ææåºäºä¸ååå½¢ç¥ç¶ç¶²è·¯ (GNN) ä¾é æ¸¬ååæªè¦éçè¦è¡ç®¡ç¶²è·¯çµæ§ä¸­çè¡æµåå£åï¼éäºçµæ§æªåå«å¨è¨ç·´è³æä¸­ãGNN æ¯ä½¿ç¨ä¾èªç¹çªçæ£èçè¨åºè³æééç¼çï¼éäºè³æéå·æè¤éä¸ç°å¸¸çè¡ç®¡å¹¾ä½å½¢çãæ­¤å¤ï¼GNN æ¨¡åæ¯å¨åå«åç¨®æµå¥æ¢ä»¶ãè¡ç®¡ææ²åç¶²è·¯é£æ¥æ§çè³æä¸è¨ç·´çï¼ä»¥å¢å¼·å¶æ³åè½åãè©²æ¹æ³å¨æè¶³å¤ çè¨ç·´è³æçææ³ä¸ï¼å£åéå° 0.727 çç®ç¾æ£®ç¸éä¿æ¸ï¼æµééå° 0.824ãéäºç¼ç¾è­æäº GNN å¨å¯¦æè¦è¡ç®¡è¨ºæ·ä¸­çæ½åï¼ç¹å¥æ¯å¨èçè¤éä¸ççæ§çè¡ç®¡ç¶²è·¯æ¹é¢ã

##### **Evaluating Generative AI-Enhanced Content: A Conceptual Framework Using Qualitative, Quantitative, and Mixed-Methods Approaches**
2411.17943v1 by Saman Sarraf

Generative AI (GenAI) has revolutionized content generation, offering
transformative capabilities for improving language coherence, readability, and
overall quality. This manuscript explores the application of qualitative,
quantitative, and mixed-methods research approaches to evaluate the performance
of GenAI models in enhancing scientific writing. Using a hypothetical use case
involving a collaborative medical imaging manuscript, we demonstrate how each
method provides unique insights into the impact of GenAI. Qualitative methods
gather in-depth feedback from expert reviewers, analyzing their responses using
thematic analysis tools to capture nuanced improvements and identify
limitations. Quantitative approaches employ automated metrics such as BLEU,
ROUGE, and readability scores, as well as user surveys, to objectively measure
improvements in coherence, fluency, and structure. Mixed-methods research
integrates these strengths, combining statistical evaluations with detailed
qualitative insights to provide a comprehensive assessment. These research
methods enable quantifying improvement levels in GenAI-generated content,
addressing critical aspects of linguistic quality and technical accuracy. They
also offer a robust framework for benchmarking GenAI tools against traditional
editing processes, ensuring the reliability and effectiveness of these
technologies. By leveraging these methodologies, researchers can evaluate the
performance boost driven by GenAI, refine its applications, and guide its
responsible adoption in high-stakes domains like healthcare and scientific
research. This work underscores the importance of rigorous evaluation
frameworks for advancing trust and innovation in GenAI.

æè¦ï¼çæå¼ AI (GenAI) å¾¹åºæ¹è®äºå§å®¹çæï¼æä¾äºè®é©æ§çè½åä¾æ¹åèªè¨çé£è²«æ§ãå¯è®æ§åæ´é«åè³ªãéä»½æç¨¿æ¢è¨äºéç¨å®æ§ãå®éåæ··åæ¹æ³ç ç©¶æ¹æ³ä¾è©ä¼° GenAI æ¨¡åå¨æåç§å­¸å¯«ä½æ¹é¢çè¡¨ç¾ãä½¿ç¨æ¶ååä½é«å­¸å½±åæç¨¿çåè¨­ç¨ä¾ï¼æåå±ç¤ºäºæ¯ç¨®æ¹æ³å¦ä½æä¾å° GenAI å½±é¿çç¨ç¹è¦è§£ãå®æ§æ¹æ³å¾å°å®¶å¯©æ¥å¡æ¶éæ·±å¥çåé¥ï¼ä½¿ç¨ä¸»é¡åæå·¥å·åæä»åçåæï¼ä»¥ææç´°å¾®çæ¹é²ä¸¦æ¾åºéå¶ãå®éæ¹æ³æ¡ç¨èªååææ¨ï¼ä¾å¦ BLEUãROUGE åå¯è®æ§è©åï¼ä»¥åä½¿ç¨èèª¿æ¥ï¼ä»¥å®¢è§å°è¡¡éé£è²«æ§ãæµæ¢æ§åçµæ§çæ¹é²ãæ··åæ¹æ³ç ç©¶æ´åäºéäºåªå¢ï¼çµåçµ±è¨è©ä¼°åè©³ç´°çå®æ§è¦è§£ï¼ä»¥æä¾å¨é¢çè©ä¼°ãéäºç ç©¶æ¹æ³è½å¤ éå GenAI çæçå§å®¹çæ¹é²ç¨åº¦ï¼è§£æ±ºèªè¨åè³ªåæè¡æºç¢ºæ§çééµé¢åãå®åéæä¾äºä¸åç©©å¥çæ¶æ§ï¼ç¨æ¼å° GenAI å·¥å·èå³çµ±çç·¨è¼¯æµç¨é²è¡åºæºæ¯è¼ï¼ç¢ºä¿éäºæè¡çå¯é æ§åæææ§ãéééç¨éäºæ¹æ³ï¼ç ç©¶äººå¡å¯ä»¥è©ä¼° GenAI å¸¶ä¾çæè½æåï¼åªåå¶æç¨ï¼ä¸¦æå°å¶å¨é«çä¿å¥åç§å­¸ç ç©¶ç­é«é¢¨éªé åä¸­çè² è²¬ä»»æ¡ç¨ãéé å·¥ä½å¼·èª¿äºå´è¬¹è©ä¼°æ¶æ§å°æ¼æå GenAI çä¿¡ä»»ååµæ°çéè¦æ§ã

##### **Automating grapevine LAI features estimation with UAV imagery and machine learning**
2411.17897v1 by Muhammad Waseem Akram, Marco Vannucci, Giorgio Buttazzo, Valentina Colla, Stefano Roccella, Andrea Vannini, Giovanni Caruso, Simone Nesi, Alessandra Francini, Luca Sebastiani

The leaf area index determines crop health and growth. Traditional methods
for calculating it are time-consuming, destructive, costly, and limited to a
scale. In this study, we automate the index estimation method using drone image
data of grapevine plants and a machine learning model. Traditional feature
extraction and deep learning methods are used to obtain helpful information
from the data and enhance the performance of the different machine learning
models employed for the leaf area index prediction. The results showed that
deep learning based feature extraction is more effective than traditional
methods. The new approach is a significant improvement over old methods,
offering a faster, non-destructive, and cost-effective leaf area index
calculation, which enhances precision agriculture practices.

æè¦ï¼èé¢ç©ææ¸æ±ºå®ä½ç©çå¥åº·åçé·ãå³çµ±è¨ç®æ¹æ³èæãå·ç ´å£æ§ãæè²´ä¸åéæ¼æä¸è¦æ¨¡ãå¨æ¬ç ç©¶ä¸­ï¼æåä½¿ç¨è¡èè¤æ¤æ ªçç¡äººæ©å½±åè³æåæ©å¨å­¸ç¿æ¨¡åèªååææ¸ä¼°è¨æ¹æ³ãå³çµ±ç¹å¾µæååæ·±åº¦å­¸ç¿æ¹æ³ç¨æ¼å¾è³æä¸­ç²åæç¨çè³è¨ï¼ä¸¦æåç¨æ¼èé¢ç©ææ¸é æ¸¬çä¸åæ©å¨å­¸ç¿æ¨¡åçæè½ãçµæé¡¯ç¤ºï¼åºæ¼æ·±åº¦å­¸ç¿çç¹å¾µæåæ¯å³çµ±æ¹æ³æ´ææãæ°æ¹æ³æ¯èæ¹æ³æé¡¯èçæ¹é²ï¼æä¾æ´å¿«éãéç ´å£æ§ä¸å·ææ¬æççèé¢ç©ææ¸è¨ç®ï¼é²èæåç²¾æºè¾²æ¥­å¯¦åã

##### **HOPPR Medical-Grade Platform for Medical Imaging AI**
2411.17891v1 by Kalina P. Slavkova, Melanie Traughber, Oliver Chen, Robert Bakos, Shayna Goldstein, Dan Harms, Bradley J. Erickson, Khan M. Siddiqui

Technological advances in artificial intelligence (AI) have enabled the
development of large vision language models (LVLMs) that are trained on
millions of paired image and text samples. Subsequent research efforts have
demonstrated great potential of LVLMs to achieve high performance in medical
imaging use cases (e.g., radiology report generation), but there remain
barriers that hinder the ability to deploy these solutions broadly. These
include the cost of extensive computational requirements for developing large
scale models, expertise in the development of sophisticated AI models, and the
difficulty in accessing substantially large, high-quality datasets that
adequately represent the population in which the LVLM solution is to be
deployed. The HOPPR Medical-Grade Platform addresses these barriers by
providing powerful computational infrastructure, a suite of foundation models
on top of which developers can fine-tune for their specific use cases, and a
robust quality management system that sets a standard for evaluating fine-tuned
models for deployment in clinical settings. The HOPPR Platform has access to
millions of imaging studies and text reports sourced from hundreds of imaging
centers from diverse populations to pretrain foundation models and enable use
case-specific cohorts for fine-tuning. All data are deidentified and securely
stored for HIPAA compliance. Additionally, developers can securely host models
on the HOPPR platform and access them via an API to make inferences using these
models within established clinical workflows. With the Medical-Grade Platform,
HOPPR's mission is to expedite the deployment of LVLM solutions for medical
imaging and ultimately optimize radiologist's workflows and meet the growing
demands of the field.

æè¦ï¼äººå·¥æºè½ (AI) çæè¡é²å±ä½¿å¤§åè¦è¦ºèªè¨æ¨¡å (LVLMs) çéç¼æçºå¯è½ï¼éäºæ¨¡åç¶éæ¸ç¾è¬éå°åååææ¬ç¯ä¾çè¨ç·´ãå¾çºçç ç©¶å·¥ä½å·²è­æ LVLMs å¨é«å­¸å½±åä½¿ç¨æ¡ä¾ï¼ä¾å¦æ¾å°å­¸å ±åçæï¼ä¸­å¯¦ç¾é«æ§è½çå·¨å¤§æ½åï¼ä½ä»å­å¨é»ç¤éäºè§£æ±ºæ¹æ¡å»£æ³é¨ç½²çè½åçéç¤ãéäºéç¤åæ¬éç¼å¤§åæ¨¡åçå»£æ³è¨ç®éæ±çææ¬ãéç¼è¤é AI æ¨¡åçå°æ¥­ç¥è­ï¼ä»¥åé£ä»¥å­åååé¾å¤§ãé«åè³ªçè³æéï¼éäºè³æéååä»£è¡¨äº LVLM è§£æ±ºæ¹æ¡å°è¦é¨ç½²çäººç¾¤ãHOPPR é«çç´å¹³å°ééæä¾å¼·å¤§çéç®åºç¤æ¶æ§ãä¸å¥åºç¤æ¨¡åï¼éç¼äººå¡å¯ä»¥å¨å¶ä¸éå°å¶ç¹å®ä½¿ç¨æ¡ä¾é²è¡å¾®èª¿ï¼ä»¥åä¸å¥å¥å¨çåè³ªç®¡çç³»çµ±ä¾è§£æ±ºéäºéç¤ï¼çºè©ä¼°å¾®èª¿æ¨¡åå¨è¨åºç°å¢ä¸­é¨ç½²è¨­å®æ¨æºãHOPPR å¹³å°å¯ä»¥å­åæ¸ç¾è¬ä»½å½±åç ç©¶åä¾èªä¸åæç¾¤çæ¸ç¾åå½±åä¸­å¿çæå­å ±åï¼ä»¥é åè¨ç·´åºç¤æ¨¡åä¸¦éå°ç¹å®ä½¿ç¨æ¡ä¾åç¨å¾®èª¿çç¾¤çµãææè³æåå·²å»è­å¥åä¸¦å®å¨å²å­ï¼ä»¥ç¬¦å HIPAA è¦ç¯ãæ­¤å¤ï¼éç¼äººå¡å¯ä»¥å¨ HOPPR å¹³å°ä¸å®å¨å°ä¸»æ©æ¨¡åï¼ä¸¦éé API å­åéäºæ¨¡åï¼ä»¥ä¾¿å¨æ¢å®çè¨åºå·¥ä½æµç¨ä¸­ä½¿ç¨éäºæ¨¡åé²è¡æ¨è«ãHOPPR çä½¿å½æ¯ééé«çç´å¹³å°å éé¨ç½²ç¨æ¼é«å­¸å½±åç LVLM è§£æ±ºæ¹æ¡ï¼ä¸¦æçµæä½³åæ¾å°ç§é«å¸«çå·¥ä½æµç¨ï¼ä»¥æ»¿è¶³è©²é åä¸æ·å¢é·çéæ±ã

##### **Explainable AI for Classifying UTI Risk Groups Using a Real-World Linked EHR and Pathology Lab Dataset**
2411.17645v1 by Yujie Dai, Brian Sullivan, Axel Montout, Amy Dillon, Chris Waller, Peter Acs, Rachel Denholm, Philip Williams, Alastair D Hay, Raul Santos-Rodriguez, Andrew Dowsey

The use of machine learning and AI on electronic health records (EHRs) holds
substantial potential for clinical insight. However, this approach faces
significant challenges due to data heterogeneity, sparsity, temporal
misalignment, and limited labeled outcomes. In this context, we leverage a
linked EHR dataset of approximately one million de-identified individuals from
Bristol, North Somerset, and South Gloucestershire, UK, to characterize urinary
tract infections (UTIs) and develop predictive models focused on data quality,
fairness and transparency. A comprehensive data pre-processing and curation
pipeline transforms the raw EHR data into a structured format suitable for AI
modeling. Given the limited availability and biases of ground truth UTI
outcomes, we introduce a UTI risk estimation framework informed by clinical
expertise to estimate UTI risk across individual patient timelines. Using this
framework, we built pairwise XGBoost models to differentiate UTI risk
categories with explainable AI techniques to identify key predictors while
ensuring interpretability. Our findings reveal differences in clinical and
demographic factors across risk groups, offering insights into UTI risk
stratification and progression. This study demonstrates the added value of
AI-driven insights into UTI clinical decision-making while prioritizing
interpretability, transparency, and fairness, underscoring the importance of
sound data practices in advancing health outcomes.

æè¦ï¼æ©å¨å­¸ç¿åäººå·¥æºæ§å¨é»å­å¥åº·ç´é (EHR) ä¸çæç¨å·æ
è¨åºè¦è§£çå·¨å¤§æ½åãç¶èï¼éç¨®æ¹æ³ç±æ¼è³æç°è³ªæ§ãç¨çæ§ãæéé¯ä½åæ¨è¨çµææéï¼å æ­¤é¢è¨éå¤§ææ°ãå¨æ­¤èæ¯ä¸ï¼æåå©ç¨ä¾èªè±åå¸éæ¯æãåè©é»å¡ç¹é¡ååæ ¼æ´æ¯ç¹é¡çå¤§ç´ä¸ç¾è¬åå»è­å¥ååäººçé£çµå¼ EHR è³æéï¼ä»¥æè¿°æ³å°¿éææ (UTI) ä¸¦éç¼å°æ³¨æ¼è³æåè³ªãå¬å¹³æ§åéæåº¦çé æ¸¬æ¨¡åãå¨é¢çè³æåèçåæ´çç®¡éå°åå§ EHR è³æè½æçºé©å AI å»ºæ¨¡ççµæ§åæ ¼å¼ãéæ¼å¯¦é UTI çµæçå¯ç¨æ§æéååè¦ï¼æåå¼å¥äºä¸åç±è¨åºå°æ¥­ç¥è­æä¾è³è¨ç UTI é¢¨éªè©ä¼°æ¶æ§ï¼ä»¥ä¼°è¨åäººæ£èæéç·ä¸ç UTI é¢¨éªãä½¿ç¨æ­¤æ¶æ§ï¼æåå»ºç«äºæå°ç XGBoost æ¨¡åï¼ä»¥åå UTI é¢¨éªé¡å¥ï¼ä¸¦ä½¿ç¨å¯è§£éç AI æè¡ä¾è­å¥ééµé æ¸¬å å­ï¼åæç¢ºä¿å¯è§£éæ§ãæåçç ç©¶çµææ­ç¤ºäºä¸åé¢¨éªç¾¤çµçè¨åºåäººå£çµ±è¨å ç´ çå·®ç°ï¼æä¾äºå° UTI é¢¨éªåå±¤åé²å±çè¦è§£ãæ¬ç ç©¶å±ç¤ºäº AI é©åçè¦è§£å¨ UTI è¨åºæ±ºç­ä¸­çéå å¹å¼ï¼åæåªåèæ®å¯è§£éæ§ãéæåº¦åå¬å¹³æ§ï¼å¼·èª¿äºå¥å¨è³æå¯¦åå¨ä¿é²å¥åº·çµæä¸­çéè¦æ§ã

##### **DapPep: Domain Adaptive Peptide-agnostic Learning for Universal T-cell Receptor-antigen Binding Affinity Prediction**
2411.17798v1 by Jiangbin Zheng, Qianhui Xu, Ruichen Xia, Stan Z. Li

Identifying T-cell receptors (TCRs) that interact with antigenic peptides
provides the technical basis for developing vaccines and immunotherapies. The
emergent deep learning methods excel at learning antigen binding patterns from
known TCRs but struggle with novel or sparsely represented antigens. However,
binding specificity for unseen antigens or exogenous peptides is critical. We
introduce a domain-adaptive peptide-agnostic learning framework DapPep for
universal TCR-antigen binding affinity prediction to address this challenge.
The lightweight self-attention architecture combines a pre-trained protein
language model with an inner-loop self-supervised regime to enable robust
TCR-peptide representations. Extensive experiments on various benchmarks
demonstrate that DapPep consistently outperforms existing tools, showcasing
robust generalization capability, especially for data-scarce settings and
unseen peptides. Moreover, DapPep proves effective in challenging clinical
tasks such as sorting reactive T cells in tumor neoantigen therapy and
identifying key positions in 3D structures.

æè¦ï¼è¯å«ä¸æåè½ç¸äºä½ç¨ç T ç»èåä½ (TCR) ä¸ºå¼åç«èååç«çæ³æä¾äºææ¯åºç¡ãæ°å´çæ·±åº¦å­¦ä¹ æ¹æ³æé¿ä»å·²ç¥ç TCR ä¸­å­¦ä¹ æåç»åæ¨¡å¼ï¼ä½å¨æ°é¢æç¨çè¡¨ç¤ºçæåæ¹é¢å´æå°é¾ãç¶èï¼å¯¹æªè§æåæå¤æºè½çç»åç¹å¼æ§è³å³éè¦ãæä»¬å¼å¥äºä¸ä¸ªåèªéåºè½ä¸å¯ç¥å­¦ä¹ æ¡æ¶ DapPepï¼ç¨äºéç¨ç TCR æåç»åäº²ååé¢æµï¼ä»¥åºå¯¹è¿ä¸ææãè½»éçº§èªæ³¨æåæ¶æå°é¢è®­ç»çèç½è´¨è¯­è¨æ¨¡åä¸åé¨å¾ªç¯èªçç£æºå¶ç¸ç»åï¼ä»¥å¯ç¨é²æ£ç TCR è½è¡¨ç¤ºãå¨åç§åºåä¸çå¹¿æ³å®éªè¡¨æï¼DapPep å§ç»ä¼äºç°æå·¥å·ï¼å±ç¤ºäºå¼ºå¤§çæ³åè½åï¼å°¤å¶æ¯å¨æ°æ®ç¨ç¼ºçè®¾ç½®åæªè§è½ä¸­ãæ­¤å¤ï¼DapPep è¢«è¯æå¨å·ææææ§çä¸´åºä»»å¡ä¸­æ¯ææçï¼ä¾å¦å¨è¿ç¤æ°æåæ²»çä¸­å¯¹ååºæ§ T ç»èè¿è¡åç±»ï¼ä»¥åè¯å« 3D ç»æä¸­çå³é®ä½ç½®ã

##### **Learning Explainable Treatment Policies with Clinician-Informed Representations: A Practical Approach**
2411.17570v1 by Johannes O. Ferstad, Emily B. Fox, David Scheinker, Ramesh Johari

Digital health interventions (DHIs) and remote patient monitoring (RPM) have
shown great potential in improving chronic disease management through
personalized care. However, barriers like limited efficacy and workload
concerns hinder adoption of existing DHIs; while limited sample sizes and lack
of interpretability limit the effectiveness and adoption of purely black-box
algorithmic DHIs. In this paper, we address these challenges by developing a
pipeline for learning explainable treatment policies for RPM-enabled DHIs. We
apply our approach in the real-world setting of RPM using a DHI to improve
glycemic control of youth with type 1 diabetes. Our main contribution is to
reveal the importance of clinical domain knowledge in developing state and
action representations for effective, efficient, and interpretable targeting
policies. We observe that policies learned from clinician-informed
representations are significantly more efficacious and efficient than policies
learned from black-box representations. This work emphasizes the importance of
collaboration between ML researchers and clinicians for developing effective
DHIs in the real world.

æè¦ï¼æ¸ä½å¥åº·å¹²é ï¼DHIï¼åé è·çäººç£æ§ï¼RPMï¼å·²é¡¯ç¤ºåºééåäººåç§è­·æ¹åæ¢æ§ç¾çç®¡ççå·¨å¤§æ½åãç¶èï¼è«¸å¦æææéåå·¥ä½è² æç­éç¤é»ç¤äºç¾æ DHI çæ¡ç¨ï¼èæ¨£æ¬éæéåç¼ºä¹å¯è§£éæ§åéå¶äºç´é»çæ¼ç®æ³ DHI çæææ§åæ¡ç¨ãå¨æ¬æä¸­ï¼æåéééç¼ä¸åç¨æ¼å­¸ç¿ RPM æ¯æ´ DHI çå¯è§£éæ²»çæ¿ç­çç®¡éä¾è§£æ±ºéäºææ°ãæåå¨ä½¿ç¨ DHI æ¹åç¬¬ä¸åç³å°¿çéå°å¹´çè¡ç³æ§å¶ç RPM å¯¦ä¾ä¸­æç¨æåçåæ³ãæåçè²¢ç»éé»å¨æ¼æ­é²è¨åºé åç¥è­å¨éç¼ææãé«æä¸å¯è§£éçç®æ¨æ¿ç­ççæååä½è¡¨ç¤ºä¸­çéè¦æ§ãæåè§å¯å°ï¼å¾è¨åºé«å¸«æä¾çè¡¨ç¤ºä¸­å­¸ç¿å°çæ¿ç­é¡¯èæ¯å¾é»çè¡¨ç¤ºä¸­å­¸ç¿å°çæ¿ç­æ´ææä¸æ´ææçãéé å·¥ä½å¼·èª¿äº ML ç ç©¶äººå¡åè¨åºé«å¸«ä¹éçåä½å°æ¼å¨ç¾å¯¦ä¸çä¸­éç¼ææç DHI çéè¦æ§ã

##### **A Bilayer Segmentation-Recombination Network for Accurate Segmentation of Overlapping C. elegans**
2411.17557v1 by Mengqian Dinga, Jun Liua, Yang Luo, Jinshan Tang

Caenorhabditis elegans (C. elegans) is an excellent model organism because of
its short lifespan and high degree of homology with human genes, and it has
been widely used in a variety of human health and disease models. However, the
segmentation of C. elegans remains challenging due to the following reasons: 1)
the activity trajectory of C. elegans is uncontrollable, and multiple nematodes
often overlap, resulting in blurred boundaries of C. elegans. This makes it
impossible to clearly study the life trajectory of a certain nematode; and 2)
in the microscope images of overlapping C. elegans, the translucent tissues at
the edges obscure each other, leading to inaccurate boundary segmentation. To
solve these problems, a Bilayer Segmentation-Recombination Network (BR-Net) for
the segmentation of C. elegans instances is proposed. The network consists of
three parts: A Coarse Mask Segmentation Module (CMSM), a Bilayer Segmentation
Module (BSM), and a Semantic Consistency Recombination Module (SCRM). The CMSM
is used to extract the coarse mask, and we introduce a Unified Attention Module
(UAM) in CMSM to make CMSM better aware of nematode instances. The Bilayer
Segmentation Module (BSM) segments the aggregated C. elegans into overlapping
and non-overlapping regions. This is followed by integration by the SCRM, where
semantic consistency regularization is introduced to segment nematode instances
more accurately. Finally, the effectiveness of the method is verified on the C.
elegans dataset. The experimental results show that BR-Net exhibits good
competitiveness and outperforms other recently proposed instance segmentation
methods in processing C. elegans occlusion images.

æè¦ï¼ç§éºé±æ¡¿ç·è² (C. elegans) æ¯ä¸ç¨®æ¥µä½³çæ¨¡å¼çç©ï¼åå å¨æ¼å¶å£½å½ç­ä¸èäººé¡åºå æé«åº¦åæºæ§ï¼ä¸å·²å»£æ³ç¨æ¼åç¨®äººé¡å¥åº·èç¾çæ¨¡å¼ä¸­ãç¶èï¼C. elegans çåå²ä»ç¶å·æææ°æ§ï¼åå å¦ä¸ï¼1) C. elegans çæ´»åè»è·¡ç¡æ³æ§å¶ï¼ä¸å¤åç·è²ç¶å¸¸éçï¼å°è´ C. elegans çéçæ¨¡ç³ãéä½¿å¾ç¡æ³æ¸æ¥å°ç ç©¶æåç·è²ççå½è»è·¡ï¼2) å¨éçç C. elegans çé¡¯å¾®é¡å½±åä¸­ï¼éç·£çåéæçµç¹å½¼æ­¤é®è½ï¼å°è´éçåå²ä¸æºç¢ºãçºäºè§£æ±ºéäºåé¡ï¼æåºäºä¸åç¨æ¼åå² C. elegans åé«çéå±¤åå²éçµç¶²è·¯ (BR-Net)ãè©²ç¶²è·¯åå«ä¸åé¨åï¼ç²ç¥é®ç½©åå²æ¨¡çµ (CMSM)ãéå±¤åå²æ¨¡çµ (BSM) åèªæä¸è´æ§éçµæ¨¡çµ (SCRM)ãCMSM ç¨æ¼æåç²ç¥é®ç½©ï¼æåå¨ CMSM ä¸­å¼å¥äºä¸åçµ±ä¸æ³¨æåæ¨¡çµ (UAM)ï¼ä»¥ä½¿ CMSM æ´è½æç¥ç·è²åé«ãéå±¤åå²æ¨¡çµ (BSM) å°èéç C. elegans åå²æéçåééçååãæ¥èç± SCRM æ´åï¼å¶ä¸­å¼å¥äºèªæä¸è´æ§æ­£ååï¼ä»¥æ´æºç¢ºå°åå²ç·è²åé«ãæå¾ï¼å¨ C. elegans è³æéä¸é©è­äºè©²æ¹æ³çæææ§ãå¯¦é©çµæé¡¯ç¤ºï¼BR-Net å±ç¾åºè¯å¥½çç«¶ç­åï¼ä¸å¨èç C. elegans é®è½å½±åæåªæ¼å¶ä»æè¿æåºçåé«åå²æ¹æ³ã

##### **AI-Augmented Ethical Hacking: A Practical Examination of Manual Exploitation and Privilege Escalation in Linux Environments**
2411.17539v1 by Haitham S. Al-Sinani, Chris J. Mitchell

This study explores the application of generative AI (GenAI) within manual
exploitation and privilege escalation tasks in Linux-based penetration testing
environments, two areas critical to comprehensive cybersecurity assessments.
Building on previous research into the role of GenAI in the ethical hacking
lifecycle, this paper presents a hands-on experimental analysis conducted in a
controlled virtual setup to evaluate the utility of GenAI in supporting these
crucial, often manual, tasks. Our findings demonstrate that GenAI can
streamline processes, such as identifying potential attack vectors and parsing
complex outputs for sensitive data during privilege escalation. The study also
identifies key benefits and challenges associated with GenAI, including
enhanced efficiency and scalability, alongside ethical concerns related to data
privacy, unintended discovery of vulnerabilities, and potential for misuse.
This work contributes to the growing field of AI-assisted cybersecurity by
emphasising the importance of human-AI collaboration, especially in contexts
requiring careful decision-making, rather than the complete replacement of
human input.

æè¦ï¼æ¬ç ç©¶æ¢è¨äºå¨ä»¥ Linux çºåºç¤çæ»²éæ¸¬è©¦ç°å¢ä¸­ï¼å°çæå¼ AI (GenAI) æç¨æ¼æåæ¼æ´å©ç¨åæ¬éæåä»»åï¼éå©åé åå°æ¼å¨é¢çç¶²è·¯å®å¨è©ä¼°è³ééè¦ãæ¬è«æå»ºç«æ¼ååçç ç©¶ï¼æ¢è¨ GenAI å¨éå¾·é§­å®¢çå½é±æä¸­çè§è²ï¼ä¸¦æåºå¨åæ§èæ¬è¨­å®ä¸­é²è¡çå¯¦ä½å¯¦é©åæï¼ä»¥è©ä¼° GenAI å¨æ¯æ´éäºééµä¸éå¸¸æåå·è¡çä»»åä¸­çæç¨ãæåçç ç©¶çµæé¡¯ç¤ºï¼GenAI å¯ä»¥ç°¡åæµç¨ï¼ä¾å¦å¨æ¬éæåæéè­å¥æ½å¨çæ»æåªä»ï¼ä¸¦åæè¤éçè¼¸åºä»¥åå¾ææè³æãæ¬ç ç©¶ä¹æ¾åºè GenAI ç¸éçä¸»è¦å¥½èåææ°ï¼åæ¬å¢å¼·æçåå¯æ´åæ§ï¼ä»¥åèè³æé±ç§ãæå¤ç¼ç¾æ¼æ´åæ½å¨æ¿«ç¨ç¸éçéå¾·çæ®ãéé å·¥ä½ééå¼·èª¿äººæ©åä½çéè¦æ§ï¼çº AI è¼å©ç¶²è·¯å®å¨éåä¸æ·æé·çé åååºè²¢ç»ï¼ç¹å¥æ¯å¨éè¦è¬¹ææ±ºç­å¶å®ï¼èéå®å¨åä»£äººé¡è¼¸å¥çèçµ¡ä¸­ã

##### **ShowUI: One Vision-Language-Action Model for GUI Visual Agent**
2411.17465v1 by Kevin Qinghong Lin, Linjie Li, Difei Gao, Zhengyuan Yang, Shiwei Wu, Zechen Bai, Weixian Lei, Lijuan Wang, Mike Zheng Shou

Building Graphical User Interface (GUI) assistants holds significant promise
for enhancing human workflow productivity. While most agents are
language-based, relying on closed-source API with text-rich meta-information
(e.g., HTML or accessibility tree), they show limitations in perceiving UI
visuals as humans do, highlighting the need for GUI visual agents. In this
work, we develop a vision-language-action model in digital world, namely
ShowUI, which features the following innovations: (i) UI-Guided Visual Token
Selection to reduce computational costs by formulating screenshots as an UI
connected graph, adaptively identifying their redundant relationship and serve
as the criteria for token selection during self-attention blocks; (ii)
Interleaved Vision-Language-Action Streaming that flexibly unifies diverse
needs within GUI tasks, enabling effective management of visual-action history
in navigation or pairing multi-turn query-action sequences per screenshot to
enhance training efficiency; (iii) Small-scale High-quality GUI
Instruction-following Datasets by careful data curation and employing a
resampling strategy to address significant data type imbalances. With above
components, ShowUI, a lightweight 2B model using 256K data, achieves a strong
75.1% accuracy in zero-shot screenshot grounding. Its UI-guided token selection
further reduces 33% of redundant visual tokens during training and speeds up
the performance by 1.4x. Navigation experiments across web Mind2Web, mobile
AITW, and online MiniWob environments further underscore the effectiveness and
potential of our model in advancing GUI visual agents. The models are available
at https://github.com/showlab/ShowUI.

æè¦ï¼<paragraph>å»ºæ§åå½¢ä½¿ç¨èä»é¢ (GUI) å©çæ¥µæææåäººé¡å·¥ä½æµç¨ççç¢åãéç¶å¤§å¤æ¸ä»£çé½æ¯åºæ¼èªè¨ï¼ä»°è³´å·æè±å¯æå­åè³è¨å°éåå§ç¢¼ APIï¼ä¾å¦ HTML æç¡éç¤æ¨¹ï¼ï¼ä½å®åå¨æç¥ä½¿ç¨èä»é¢è¦è¦ºæææ¹é¢é¡¯ç¤ºåºéå¶ï¼éå¸é¡¯äºå° GUI è¦è¦ºä»£ççéæ±ãå¨éé å·¥ä½ä¸­ï¼æåå¨æ¸ä½ä¸çä¸­éç¼äºä¸åè¦è¦ºèªè¨åä½æ¨¡åï¼å³ ShowUIï¼å¶å·æä»¥ä¸åµæ°åè½ï¼(i) UI å¼å°è¦è¦ºä»£å¹£é¸æï¼ééå°è¢å¹æªåè¡¨è¿°çº UI é£æ¥åï¼èªé©æå°è­å¥å¶åé¤éä¿ï¼ä¸¦ä½çºèªæ³¨æååå¡ä¸­ä»£å¹£é¸æçæºåï¼ä»¥éä½éç®ææ¬ï¼(ii) äº¤é¯è¦è¦ºèªè¨åä½ä¸²æµï¼éæ´»å°çµ±ä¸ GUI ä»»åä¸­çåç¨®éæ±ï¼å¨å°è¦½ä¸­ææç®¡çè¦è¦ºåä½æ­·ç¨ï¼æéå°æ¯åè¢å¹æªåçå¤è¼ªæ¥è©¢åä½åºåï¼ä»¥æåè¨ç·´æçï¼(iii) å°è¦æ¨¡é«åè³ª GUI æä»¤éµå¾ªè³æéï¼ééä»ç´°çè³ææ´çåæ¡ç¨åæ½æ¨£ç­ç¥ï¼ä¾è§£æ±ºé¡¯èçè³æé¡åä¸å¹³è¡¡ãShowUI æ¯ä¸åä½¿ç¨ 256K è³æçè¼éç´ 2B æ¨¡åï¼å·åä¸è¿°çµæé¨åï¼å¨é¶æ¬¡æ¹è¢å¹æªåæ¥å°ä¸­éå°å¼·åç 75.1% ç²¾ç¢ºåº¦ãå¶ UI å¼å°ä»£å¹£é¸æé²ä¸æ­¥æ¸å°äºè¨ç·´æé 33% çåé¤è¦è¦ºä»£å¹£ï¼ä¸¦å°æè½æåäº 1.4 åãè·¨ç¶²è·¯ Mind2Webãè¡å AITW åç·ä¸ MiniWob ç°å¢çå°è¦½å¯¦é©é²ä¸æ­¥å¼·èª¿äºæåçæ¨¡åå¨æ¨é² GUI è¦è¦ºä»£çæ¹é¢çæææ§åæ½åãéäºæ¨¡åå¯å¨ https://github.com/showlab/ShowUI åå¾ã</paragraph>

##### **Social Distancing Induced Coronavirus Optimization Algorithm (COVO): Application to Multimodal Function Optimization and Noise Removal**
2411.17282v1 by Om Ramakisan Varma, Mala Kalra

The metaheuristic optimization technique attained more awareness for handling
complex optimization problems. Over the last few years, numerous optimization
techniques have been developed that are inspired by natural phenomena.
Recently, the propagation of the new COVID-19 implied a burden on the public
health system to suffer several deaths. Vaccination, masks, and social
distancing are the major steps taken to minimize the spread of the deadly
COVID-19 virus. Considering the social distance to combat the coronavirus
epidemic, a novel bio-inspired metaheuristic optimization model is proposed in
this work, and it is termed as Social Distancing Induced Coronavirus
Optimization Algorithm (COVO). The pace of propagation of the coronavirus can
indeed be slowed by maintaining social distance. Thirteen benchmark functions
are used to evaluate the COVO performance for discrete, continuous, and complex
problems, and the COVO model performance is compared with other well-known
optimization algorithms. The main motive of COVO optimization is to obtain a
global solution to various applications by solving complex problems with faster
convergence. At last, the validated results depict that the proposed COVO
optimization has a reasonable and acceptable performance.

æè¦ï¼åå¯åå¼ä¼åææ¯å¨å¤çå¤æä¼åé®é¢æ¹é¢è·å¾äºæ´å¤çå³æ³¨ãå¨è¿å»çå å¹´ä¸­ï¼å·²ç»å¼ååºè®¸å¤åèªç¶ç°è±¡å¯åçä¼åææ¯ãæè¿ï¼æ°åå ç¶çæ¯èºççä¼ æ­ç»å¬å±å«çç³»ç»å¸¦æ¥äºæ²éè´æï¼å¯¼è´å¤äººæ­»äº¡ãæ¥ç§ç«èãæ´å£ç½©åä¿æç¤¾äº¤è·ç¦»æ¯ä¸ºæå¤§ç¨åº¦åå°è´å½çæ°å çæ¯ä¼ æ­èéåçä¸»è¦æªæ½ãèèå°ä¿æç¤¾äº¤è·ç¦»ä»¥å¯¹æå ç¶çæ¯ç«æï¼è¿é¡¹å·¥ä½æåºäºä¸ç§æ°çåçç©å¯åçåå¯åå¼ä¼åæ¨¡åï¼å¹¶å°å¶ç§°ä¸ºç¤¾äº¤è·ç¦»è¯±å¯¼å ç¶çæ¯ä¼åç®æ³ (COVO)ãä¿æç¤¾äº¤è·ç¦»ç¡®å®å¯ä»¥åç¼å ç¶çæ¯çä¼ æ­éåº¦ãåä¸é¡¹åºåå½æ°ç¨äºè¯ä¼° COVO å¨ç¦»æ£ãè¿ç»­åå¤æé®é¢ä¸çæ§è½ï¼å¹¶å° COVO æ¨¡åçæ§è½ä¸å¶ä»ä¼æå¨ç¥çä¼åç®æ³è¿è¡äºæ¯è¾ãCOVO ä¼åç®æ³çä¸»è¦ç®çæ¯éè¿è§£å³å¤æé®é¢ä»¥æ´å¿«çæ¶æéåº¦ä¸ºåç§åºç¨è·åå¨å±è§£å³æ¹æ¡ãæåï¼éªè¯ç»æè¡¨æï¼ææåºç COVO ä¼åç®æ³å·æåçä¸å¯æ¥åçæ§è½ã

##### **Semantic Data Augmentation for Long-tailed Facial Expression Recognition**
2411.17254v1 by Zijian Li, Yan Wang, Bowen Guan, JianKai Yin

Facial Expression Recognition has a wide application prospect in social
robotics, health care, driver fatigue monitoring, and many other practical
scenarios. Automatic recognition of facial expressions has been extensively
studied by the Computer Vision research society. But Facial Expression
Recognition in real-world is still a challenging task, partially due to the
long-tailed distribution of the dataset. Many recent studies use data
augmentation for Long-Tailed Recognition tasks. In this paper, we propose a
novel semantic augmentation method. By introducing randomness into the encoding
of the source data in the latent space of VAE-GAN, new samples are generated.
Then, for facial expression recognition in RAF-DB dataset, we use our
augmentation method to balance the long-tailed distribution. Our method can be
used in not only FER tasks, but also more diverse data-hungry scenarios.

æè¦ï¼äººèè¡¨æè¾¨è­å¨ç¤¾äº¤æ©å¨äººãé«çä¿å¥ãé§é§ç²åç£æ§ä»¥åè¨±å¤å¶ä»å¯¦éå ´æ¯ä¸­å·æå»£æ³çæç¨åæ¯ãé»è¦è¦è¦ºç ç©¶å­¸æå·²å»£æ³ç ç©¶äººèè¡¨æçèªåè¾¨è­ãä½ç¾å¯¦ä¸çä¸­çäººèè¡¨æè¾¨è­ä»æ¯ä¸é å·æææ°æ§çä»»åï¼é¨ååå æ¯è³æéçé·å°¾åä½ãè¨±å¤è¿æç ç©¶ä½¿ç¨è³ææ´åé²è¡é·å°¾è¾¨è­ä»»åãå¨æ¬æä¸­ï¼æåæåºäºä¸ç¨®æ°ç©çèªç¾©æ´åæ¹æ³ãééå°é¨æ©æ§å¼å¥ VAE-GAN æ½å¨ç©ºéä¸­åå§è³æçç·¨ç¢¼ï¼ç¢çæ°çæ¨£æ¬ãç¶å¾ï¼å°æ¼ RAF-DB è³æéä¸­çé¢é¨è¡¨æè¾¨è­ï¼æåä½¿ç¨æ´åæ¹æ³å¹³è¡¡é·å°¾åä½ãæåçéç¨®æ¹æ³ä¸åå¯ç¨æ¼ FER ä»»åï¼éå¯ç¨æ¼æ´å¤æ¨£åçè³æå¯éå ´æ¯ã

##### **GraphSubDetector: Time Series Subsequence Anomaly Detection via Density-Aware Adaptive Graph Neural Network**
2411.17218v1 by Weiqi Chen, Zhiqiang Zhou, Qingsong Wen, Liang Sun

Time series subsequence anomaly detection is an important task in a large
variety of real-world applications ranging from health monitoring to AIOps, and
is challenging due to the following reasons: 1) how to effectively learn
complex dynamics and dependencies in time series; 2) diverse and complicated
anomalous subsequences as well as the inherent variance and noise of normal
patterns; 3) how to determine the proper subsequence length for effective
detection, which is a required parameter for many existing algorithms. In this
paper, we present a novel approach to subsequence anomaly detection, namely
GraphSubDetector. First, it adaptively learns the appropriate subsequence
length with a length selection mechanism that highlights the characteristics of
both normal and anomalous patterns. Second, we propose a density-aware adaptive
graph neural network (DAGNN), which can generate further robust representations
against variance of normal data for anomaly detection by message passing
between subsequences. The experimental results demonstrate the effectiveness of
the proposed algorithm, which achieves superior performance on multiple time
series anomaly benchmark datasets compared to state-of-the-art algorithms.

æè¦ï¼æéåºåå­åºåç°å¸¸åµæ¸¬å¨åç¨®å¯¦éæç¨ä¸­æ¯ä¸é éè¦çä»»åï¼å¾å¥åº·ç£æ§å° AIOpsï¼ç±æ¼ä»¥ä¸åå èå·æææ°æ§ï¼1) å¦ä½ææå°å­¸ç¿æéåºåä¸­çè¤éåæåä¾è³´æ§ï¼2) å¤æ¨£ä¸è¤éçç°å¸¸å­åºåä»¥åæ­£å¸¸æ¨¡å¼åºæçè®ç°åéè¨ï¼3) å¦ä½ç¢ºå®é©ç¶çå­åºåé·åº¦ä»¥é²è¡ææåµæ¸¬ï¼éæ¯è¨±å¤ç¾ææ¼ç®æ³çå¿è¦åæ¸ãå¨æ¬æä¸­ï¼æåæåºäºä¸åç¨æ¼å­åºåç°å¸¸åµæ¸¬çæ°ç©æ¹æ³ï¼å³ GraphSubDetectorãé¦åï¼å®ä½¿ç¨é·åº¦é¸ææ©å¶èªé©æå°å­¸ç¿é©ç¶çå­åºåé·åº¦ï¼è©²æ©å¶çªåºäºæ­£å¸¸æ¨¡å¼åç°å¸¸æ¨¡å¼çç¹å¾µãå¶æ¬¡ï¼æåæåºäºä¸åå¯åº¦æç¥èªé©æåç¥ç¶ç¶²è·¯ (DAGNN)ï¼å®å¯ä»¥ééå­åºåä¹éçè¨æ¯å³éï¼éå°æ­£å¸¸è³æçè®ç°ç¢çæ´å¼·å¤§çè¡¨ç¤ºï¼ä»¥é²è¡ç°å¸¸åµæ¸¬ãå¯¦é©çµæè­æäºææåºçæ¼ç®æ³çæææ§ï¼èæåé²çæ¼ç®æ³ç¸æ¯ï¼å®å¨å¤åæéåºåç°å¸¸åºæºè³æéä¸å¯¦ç¾äºåè¶çæè½ã

##### **Strategic Prompting for Conversational Tasks: A Comparative Analysis of Large Language Models Across Diverse Conversational Tasks**
2411.17204v2 by Ratnesh Kumar Joshi, Priyanshu Priya, Vishesh Desai, Saurav Dudhate, Siddhant Senapati, Asif Ekbal, Roshni Ramnani, Anutosh Maitra, Shubhashis Sengupta

Given the advancements in conversational artificial intelligence, the
evaluation and assessment of Large Language Models (LLMs) play a crucial role
in ensuring optimal performance across various conversational tasks. In this
paper, we present a comprehensive study that thoroughly evaluates the
capabilities and limitations of five prevalent LLMs: Llama, OPT, Falcon,
Alpaca, and MPT. The study encompasses various conversational tasks, including
reservation, empathetic response generation, mental health and legal
counseling, persuasion, and negotiation. To conduct the evaluation, an
extensive test setup is employed, utilizing multiple evaluation criteria that
span from automatic to human evaluation. This includes using generic and
task-specific metrics to gauge the LMs' performance accurately. From our
evaluation, no single model emerges as universally optimal for all tasks.
Instead, their performance varies significantly depending on the specific
requirements of each task. While some models excel in certain tasks, they may
demonstrate comparatively poorer performance in others. These findings
emphasize the importance of considering task-specific requirements and
characteristics when selecting the most suitable LM for conversational
applications.

æè¦ï¼é¨èå°è©±å¼äººå·¥æºæ§çé²æ­¥ï¼å¤§åèªè¨æ¨¡å (LLM) çè©ä¼°èè©éå¨ç¢ºä¿åç¨®å°è©±å¼ä»»åçæä½³æè½ä¸­æ®æ¼èè³ééè¦çè§è²ãå¨æ¬æä¸­ï¼æåæåºäºä¸é å¨é¢çç ç©¶ï¼å¾¹åºè©ä¼°äºäºç¨®å¸¸è¦ LLM çè½ååéå¶ï¼LlamaãOPTãFalconãAlpaca å MPTãéé ç ç©¶æ¶µèäºåç¨®å°è©±å¼ä»»åï¼åæ¬é ç´ãåçå¿åæç¢çãå¿çå¥åº·åæ³å¾è«®è©¢ãèªªæåååãçºäºé²è¡è©ä¼°ï¼æ¡ç¨äºå»£æ³çæ¸¬è©¦è¨­å®ï¼å©ç¨äºå¾èªåè©ä¼°å°äººå·¥è©ä¼°çå¤éè©ä¼°æ¨æºãéåæ¬ä½¿ç¨éç¨åç¹å®æ¼ä»»åçææ¨ä¾æºç¢ºè©é LLM çæè½ãå¾æåçè©ä¼°ä¸­ï¼æ²æå®ä¸æ¨¡åå¨ææä»»åä¸­é½è¡¨ç¾å¾æ®éæä½³ãç¸åå°ï¼å®åçæè½ææ ¹ææ¯åä»»åçç¹å®éæ±èæé¡¯èå·®ç°ãéç¶æäºæ¨¡åå¨æäºä»»åä¸­è¡¨ç¾åºè²ï¼ä½å¨å¶ä»ä»»åä¸­å®åå¯è½æè¡¨ç¾åºç¸å°è¼å·®çæè½ãéäºç¼ç¾å¼·èª¿äºå¨çºå°è©±å¼æç¨ç¨å¼é¸ææåé©ç LLM æï¼èéç¹å®æ¼ä»»åçéæ±åç¹æ§çéè¦æ§ã

##### **Contrastive Deep Learning Reveals Age Biomarkers in Histopathological Skin Biopsies**
2411.16956v1 by Kaustubh Chakradeo, Pernille Nielsen, Lise Mette Rahbek Gjerdrum, Gry Sahl Hansen, David A DuchÃªne, Laust H Mortensen, Majken K Jensen, Samir Bhatt

As global life expectancy increases, so does the burden of chronic diseases,
yet individuals exhibit considerable variability in the rate at which they age.
Identifying biomarkers that distinguish fast from slow ageing is crucial for
understanding the biology of ageing, enabling early disease detection, and
improving prevention strategies. Using contrastive deep learning, we show that
skin biopsy images alone are sufficient to determine an individual's age. We
then use visual features in histopathology slides of the skin biopsies to
construct a novel biomarker of ageing. By linking with comprehensive health
registers in Denmark, we demonstrate that visual features in histopathology
slides of skin biopsies predict mortality and the prevalence of chronic
age-related diseases. Our work highlights how routinely collected health data
can provide additional value when used together with deep learning, by creating
a new biomarker for ageing which can be actively used to determine mortality
over time.

æè¦ï¼é¨èå¨çé æå£½å½çå¢å ï¼æ¢æ§ç¾ççè² æä¹é¨ä¹å¢å ï¼
ä½åäººè¡°èçéåº¦å»æç¸ç¶å¤§çå·®ç°ã
æ¾åºè½ååå¿«éåç·©æ¢è¡°èççç©æ¨è¨ï¼å°æ¼äºè§£è¡°èççç©å­¸ã
æ©æç¾çåµæ¸¬åæ¹åé é²ç­ç¥è³ééè¦ãæåä½¿ç¨å°æ¯æ·±åº¦å­¸ç¿ï¼
è­æåç®èåçååå°±è¶³ä»¥ç¢ºå®åäººçå¹´é½¡ãæå
æ¥èä½¿ç¨ç®èåçæ´»çµç¹åçä¸­å¯è¦åçç¹å¾µä¾
å»ºæ§ä¸åæ°çè¡°èçç©æ¨è¨ãééèä¸¹éº¥çç¶åå¥åº·è¨»åè³æé£çµï¼æå
è­æç®èåçæ´»çµç¹åçä¸­å¯è¦åçç¹å¾µå¯ä»¥é æ¸¬æ­»äº¡çåæ¢æ§
å¹´é½¡ç¸éç¾çççè¡çãæåçç ç©¶å¼·èª¿ï¼å¸¸è¦æ¶éçå¥åº·è³æ
èæ·±åº¦å­¸ç¿çµåä½¿ç¨æï¼å¯ä»¥æä¾é¡å¤çå¹å¼ï¼ééå»ºç«ä¸åæ°çè¡°èçç©æ¨è¨ï¼
å¯ä»¥ç©æ¥µç¨æ¼ç¢ºå®é¨èæéæ¨ç§»çæ­»äº¡çã

##### **Enabling Adoption of Regenerative Agriculture through Soil Carbon Copilots**
2411.16872v2 by Margaret Capetz, Swati Sharma, Rafael Padilha, Peder Olsen, Jessica Wolk, Emre Kiciman, Ranveer Chandra

Mitigating climate change requires transforming agriculture to minimize
environ mental impact and build climate resilience. Regenerative agricultural
practices enhance soil organic carbon (SOC) levels, thus improving soil health
and sequestering carbon. A challenge to increasing regenerative agriculture
practices is cheaply measuring SOC over time and understanding how SOC is
affected by regenerative agricultural practices and other environmental factors
and farm management practices. To address this challenge, we introduce an
AI-driven Soil Organic Carbon Copilot that automates the ingestion of complex
multi-resolution, multi-modal data to provide large-scale insights into soil
health and regenerative practices. Our data includes extreme weather event data
(e.g., drought and wildfire incidents), farm management data (e.g., cropland
information and tillage predictions), and SOC predictions. We find that
integrating public data and specialized models enables large-scale, localized
analysis for sustainable agriculture. In comparisons of agricultural practices
across California counties, we find evidence that diverse agricultural activity
may mitigate the negative effects of tillage; and that while extreme weather
conditions heavily affect SOC, composting may mitigate SOC loss. Finally,
implementing role-specific personas empowers agronomists, farm consultants,
policymakers, and other stakeholders to implement evidence-based strategies
that promote sustainable agriculture and build climate resilience.

æè¦ï¼æ¸ç·©æ°£åè®é·éè¦è½åè¾²æ¥­ï¼ä»¥å°ç°å¢å½±é¿éå°æä½ä¸¦å»ºç«æ°£åéæ§ãåçè¾²æ¥­å¯¦åè½æååå£¤ææ©ç¢³ (SOC) å«éï¼é²èæ¹ååå£¤å¥åº·ä¸¦å°å­ç¢³ãæ´å¤§åçè¾²æ¥­å¯¦åçä¸é ææ°å¨æ¼å¨ä¸æ®µæéå§ä»¥ä½ææ¬æ¸¬é SOCï¼ä¸¦äºè§£ SOC å¦ä½åå°åçè¾²æ¥­å¯¦ååå¶ä»ç°å¢å ç´ èè¾²å ´ç®¡çå¯¦åå½±é¿ãçºäºæå°éé ææ°ï¼æåæ¨åºäºä¸æ¬¾ AI é©åçåå£¤ææ©ç¢³å¯é§é§ï¼èªåå°å¥è¤éçå¤è§£æåº¦ãå¤æ¨¡å¼è³æï¼ä»¥æä¾å¤§è¦æ¨¡çåå£¤å¥åº·èåçå¯¦åè¦è§£ãæåçè³æåå«æ¥µç«¯å¤©æ°£äºä»¶è³æï¼ä¾å¦ä¹¾æ±åéç«äºä»¶ï¼ãè¾²å ´ç®¡çè³æï¼ä¾å¦è¾²ç°è³è¨åèä½é æ¸¬ï¼ï¼ä»¥å SOC é æ¸¬ãæåç¼ç¾ï¼æ´åå¬éè³æåå°æ¥­æ¨¡åè½éå°æ°¸çºè¾²æ¥­é²è¡å¤§è¦æ¨¡ãå¨å°åçåæãå¨æ¯è¼å å·åé¡çè¾²æ¥­å¯¦åå¾ï¼æåç¼ç¾è­æé¡¯ç¤ºï¼å¤åçè¾²æ¥­æ´»åå¯ä»¥æ¸è¼èä½çè² é¢å½±é¿ï¼èä¸åç®¡æ¥µç«¯å¤©æ°£æ¢ä»¶æå´éå½±é¿ SOCï¼å è¥å¯è½ææ¸è¼ SOC æµå¤±ãæå¾ï¼å¯¦æ½è§è²ç¹å®çè§è²è½è®è¾²èå­¸å®¶ãè¾²å ´é¡§åãæ¿ç­å¶å®èåå¶ä»å©å®³éä¿äººå¯¦æ½ä»¥è­æçºåºç¤çç­ç¥ï¼ä»¥ä¿é²æ°¸çºè¾²æ¥­ä¸¦å»ºç«æ°£åéæ§ã

##### **Enhancing In-Hospital Mortality Prediction Using Multi-Representational Learning with LLM-Generated Expert Summaries**
2411.16818v1 by Harshavardhan Battula, Jiacheng Liu, Jaideep Srivastava

In-hospital mortality (IHM) prediction for ICU patients is critical for
timely interventions and efficient resource allocation. While structured
physiological data provides quantitative insights, clinical notes offer
unstructured, context-rich narratives. This study integrates these modalities
with Large Language Model (LLM)-generated expert summaries to improve IHM
prediction accuracy. Using the MIMIC-III database, we analyzed time-series
physiological data and clinical notes from the first 48 hours of ICU admission.
Clinical notes were concatenated chronologically for each patient and
transformed into expert summaries using Med42-v2 70B. A multi-representational
learning framework was developed to integrate these data sources, leveraging
LLMs to enhance textual data while mitigating direct reliance on LLM
predictions, which can introduce challenges in uncertainty quantification and
interpretability. The proposed model achieved an AUPRC of 0.6156 (+36.41%) and
an AUROC of 0.8955 (+7.64%) compared to a time-series-only baseline. Expert
summaries outperformed clinical notes or time-series data alone, demonstrating
the value of LLM-generated knowledge. Performance gains were consistent across
demographic groups, with notable improvements in underrepresented populations,
underscoring the framework's equitable application potential. By integrating
LLM-generated summaries with structured and unstructured data, the framework
captures complementary patient information, significantly improving predictive
performance. This approach showcases the potential of LLMs to augment critical
care prediction models, emphasizing the need for domain-specific validation and
advanced integration strategies for broader clinical adoption.

æè¦ï¼<paragraph>å°æ¼ ICU çæ£ï¼é¢å§æ­»äº¡ç (IHM) é æ¸¬å°æ¼åæä»å¥åææè³æºåéè³ééè¦ãéç¶çµæ§åçççæ¸ææä¾äºå®éçè¦è§£ï¼ä½è¨åºç­è¨æä¾äºéçµæ§åçãè±å¯çèæ¯è³è¨ãæ¬ç ç©¶æ´åäºéäºæ¨¡å¼èå¤§åèªè¨æ¨¡å (LLM) çæçå°å®¶æè¦ï¼ä»¥æé« IHM é æ¸¬æºç¢ºåº¦ãä½¿ç¨ MIMIC-III è³æåº«ï¼æååæäº ICU å¥é¢å 48 å°æçççæ¸æåè¨åºç­è¨çæéåºåãæ¯åçæ£çè¨åºç­è¨ææéé åºä¸²æ¥ï¼ä¸¦ä½¿ç¨ Med42-v2 70B è½ææå°å®¶æè¦ãéç¼äºä¸åå¤éè¡¨å¾µå­¸ç¿æ¶æ§ä¾æ´åéäºæ¸æä¾æºï¼å©ç¨ LLM ä¾å¢å¼·ææ¬æ¸æï¼åææ¸è¼å° LLM é æ¸¬çç´æ¥ä¾è³´ï¼éå¯è½æå¨ä¸ç¢ºå®æ§éååå¯è§£éæ§æ¹é¢é æææ°ãèåéæéåºåçåºæºç·ç¸æ¯ï¼ææåºçæ¨¡åéå°äº 0.6156 (+36.41%) ç AUPRC å 0.8955 (+7.64%) ç AUROCãå°å®¶æè¦åªæ¼åæçè¨åºç­è¨ææéåºåæ¸æï¼è­æäº LLM çæçç¥è­çå¹å¼ãå¨ä¸åçäººå£çµ±è¨ç¾¤çµä¸­ï¼æè½æåæ¯ä¸è´çï¼å¨ä»£è¡¨æ§ä¸è¶³çæç¾¤ä¸­ä¹æé¡¯èçæ¹åï¼å¼·èª¿äºè©²æ¶æ§å¬å¹³æç¨æ½åãééæ´å LLM çæçæè¦èçµæ§ååéçµæ§åæ¸æï¼è©²æ¶æ§æ·åäºäºè£ççæ£è³è¨ï¼é¡¯èæ¹åäºé æ¸¬æè½ãæ­¤æ¹æ³å±ç¤ºäº LLM æ´åéçç§è­·é æ¸¬æ¨¡åçæ½åï¼å¼·èª¿äºç¹å®é åé©è­åé²éæ´åç­ç¥å°æ¼æ´å»£æ³çè¨åºæ¡ç¨çå¿è¦æ§ã</paragraph>

##### **Will an AI with Private Information Allow Itself to Be Switched Off?**
2411.17749v1 by Andrew Garber, Rohan Subramani, Linus Luu, Mark Bedaywi, Stuart Russell, Scott Emmons

A wide variety of goals could cause an AI to disable its off switch because
"you can't fetch the coffee if you're dead" (Russell 2019). Prior theoretical
work on this shutdown problem assumes that humans know everything that AIs do.
In practice, however, humans have only limited information. Moreover, in many
of the settings where the shutdown problem is most concerning, AIs might have
vast amounts of private information. To capture these differences in knowledge,
we introduce the Partially Observable Off-Switch Game (POSG), a game-theoretic
model of the shutdown problem with asymmetric information. Unlike when the
human has full observability, we find that in optimal play, even AI agents
assisting perfectly rational humans sometimes avoid shutdown. As expected,
increasing the amount of communication or information available always
increases (or leaves unchanged) the agents' expected common payoff. But
counterintuitively, introducing bounded communication can make the AI defer to
the human less in optimal play even though communication mitigates information
asymmetry. In particular, communication sometimes enables new optimal behavior
requiring strategic AI deference to achieve outcomes that were previously
inaccessible. Thus, designing safe artificial agents in the presence of
asymmetric information requires careful consideration of the tradeoffs between
maximizing payoffs (potentially myopically) and maintaining AIs' incentives to
defer to humans.

æè¦ï¼ç±æ¼ãå¦æä½ æ­»äºï¼ä½ å°±ç¡æ³å»æ¿åå¡ãï¼ç¾ç´ ï¼2019 å¹´ï¼ï¼åç¨®ç®æ¨é½å¯è½å°è´ AI ééå¶ééééãååéæ¼æ­¤ééåé¡ççè«ç ç©¶åè¨­äººé¡ç¥é AI æåçä¸åãç¶èï¼å¨å¯¦åä¸ï¼äººé¡åªææéçè³è¨ãæ­¤å¤ï¼å¨ééåé¡æä»¤äººææçè¨±å¤ææ³ä¸ï¼AI å¯è½ææå¤§éçç§äººè³è¨ãçºäºææ¡éäºç¥è­å·®ç°ï¼æåå¼å¥äºé¨åå¯è§å¯éééééæ² (POSG)ï¼éæ¯ééåé¡çåå¼è«æ¨¡åï¼å¶ä¸­è³è¨ä¸å°ç¨±ãèäººé¡ææå®å¨å¯è§å¯æ§ä¸åï¼æåç¼ç¾ï¼å¨æä½³åå¼ä¸­ï¼å³ä½¿åå©å®å¨çæ§ç AI ä»£çææä¹æé¿åééãæ­£å¦é æçé£æ¨£ï¼å¢å å¯ç¨çæºéæè³è¨éç¸½æ¯æå¢å ï¼æä¿æä¸è®ï¼ä»£ççé æå±åå ±é¬ãä½åç´è¦ºçæ¯ï¼å³ä½¿æºéå¯ä»¥æ¸è¼è³è¨ä¸å°ç¨±ï¼å¼å¥æçæºéä¹æè® AI å¨æä½³åå¼ä¸­è¼å°æå¾äººé¡ãç¹å¥æ¯ï¼æºéæææä¿ææ°çæä½³è¡çºï¼éè¦ç­ç¥æ§ AI æå¾æè½éæä»¥åç¡æ³éæççµæãå æ­¤ï¼å¨å­å¨è³è¨ä¸å°ç¨±çææ³ä¸è¨­è¨å®å¨ç AI ä»£çï¼éè¦ä»ç´°èéå¨æå¤§åå ±é¬ï¼å¯è½è¿è¦ï¼åç¶­æ AI æå¾äººé¡çèªå ä¹éçåæ¨ã

##### **Privacy-Preserving Federated Foundation Model for Generalist Ultrasound Artificial Intelligence**
2411.16380v1 by Yuncheng Jiang, Chun-Mei Feng, Jinke Ren, Jun Wei, Zixun Zhang, Yiwen Hu, Yunbi Liu, Rui Sun, Xuemei Tang, Juan Du, Xiang Wan, Yong Xu, Bo Du, Xin Gao, Guangyu Wang, Shaohua Zhou, Shuguang Cui, Rick Siow Mong Goh, Yong Liu, Zhen Li

Ultrasound imaging is widely used in clinical diagnosis due to its
non-invasive nature and real-time capabilities. However, conventional
ultrasound diagnostics face several limitations, including high dependence on
physician expertise and suboptimal image quality, which complicates
interpretation and increases the likelihood of diagnostic errors. Artificial
intelligence (AI) has emerged as a promising solution to enhance clinical
diagnosis, particularly in detecting abnormalities across various biomedical
imaging modalities. Nonetheless, current AI models for ultrasound imaging face
critical challenges. First, these models often require large volumes of labeled
medical data, raising concerns over patient privacy breaches. Second, most
existing models are task-specific, which restricts their broader clinical
utility. To overcome these challenges, we present UltraFedFM, an innovative
privacy-preserving ultrasound foundation model. UltraFedFM is collaboratively
pre-trained using federated learning across 16 distributed medical institutions
in 9 countries, leveraging a dataset of over 1 million ultrasound images
covering 19 organs and 10 ultrasound modalities. This extensive and diverse
data, combined with a secure training framework, enables UltraFedFM to exhibit
strong generalization and diagnostic capabilities. It achieves an average area
under the receiver operating characteristic curve of 0.927 for disease
diagnosis and a dice similarity coefficient of 0.878 for lesion segmentation.
Notably, UltraFedFM surpasses the diagnostic accuracy of mid-level
ultrasonographers and matches the performance of expert-level sonographers in
the joint diagnosis of 8 common systemic diseases. These findings indicate that
UltraFedFM can significantly enhance clinical diagnostics while safeguarding
patient privacy, marking an advancement in AI-driven ultrasound imaging for
future clinical applications.

æè¦ï¼è¶é³æ³¢å½±åå å¶éä¾µå¥æ§èå³ææ§å»£æ³æç¨æ¼è¨åºè¨ºæ·ãç¶èï¼å³çµ±è¶é³æ³¢è¨ºæ·é¢è¨æ¸é éå¶ï¼åæ¬é«åº¦ä¾è³´é«å¸«å°æ¥­ç¥è­åæ¬¡ä½³å½±ååè³ªï¼éä½¿å¾å½±åå¤è®æ´çºè¤éï¼ä¸¦å¢å è¨ºæ·é¯èª¤çå¯è½æ§ãäººå·¥æºæ§ (AI) å·²æçºå¢å¼·è¨åºè¨ºæ·çæ½å¨è§£æ±ºæ¹æ¡ï¼ç¹å¥æ¯å¨åµæ¸¬åç¨®çç©é«å­¸å½±åæ¨¡å¼ä¸­çç°å¸¸ãåç®¡å¦æ­¤ï¼ç®åç¨æ¼è¶é³æ³¢å½±åç AI æ¨¡åé¢è¨å´å³»ææ°ãé¦åï¼éäºæ¨¡åéå¸¸éè¦å¤§éçæ¨ç±¤é«å­¸è³æï¼éå¼ç¼äºå°çæ£é±ç§é­ä¾µç¯ççæ®ãå¶æ¬¡ï¼ç¾æçå¤§é¨åæ¨¡åé½æ¯éå°ç¹å®ä»»åèè¨­è¨ï¼ééå¶äºå®åå¨æ´å»£æ³çè¨åºæç¨ãçºäºè§£æ±ºéäºææ°ï¼æåæåºäº UltraFedFMï¼ä¸ååµæ°çé±ç§ä¿è­·è¶é³æ³¢åºç¤æ¨¡åãUltraFedFM éé 9 ååå®¶/å°åç 16 ååæ£å¼é«çæ©æ§çè¯åå­¸ç¿é²è¡åä½é è¨ç·´ï¼å©ç¨åå«è¶é 100 è¬å¼µè¶é³æ³¢å½±åçè³æéï¼æ¶µè 19 åå¨å®å 10 ç¨®è¶é³æ³¢æ¨¡å¼ãéäºå»£æ³ä¸å¤æ¨£åçè³æï¼çµåå®å¨çè¨ç·´æ¶æ§ï¼ä½¿ UltraFedFM è½å¤ å±ç¾å¼·å¤§çæ¦ååè¨ºæ·è½åãå¨ç¾çè¨ºæ·æ¹é¢ï¼å¶åè©¦èå·¥ä½ç¹å¾µæ²ç·ä¸çå¹³åé¢ç©éå° 0.927ï¼å¨çç¶åå²æ¹é¢ï¼å¶ Dice ç¸ä¼¼ä¿æ¸çº 0.878ãå¼å¾æ³¨æçæ¯ï¼UltraFedFM è¶è¶äºä¸­éè¶é³æ³¢æª¢æ¥å¡çè¨ºæ·æºç¢ºæ§ï¼ä¸¦å¨ 8 ç¨®å¸¸è¦å¨èº«æ§ç¾ççè¯åè¨ºæ·ä¸­éå°å°å®¶ç´è¶é³æ³¢æª¢æ¥å¡çæ°´æºãéäºç¼ç¾è¡¨æï¼UltraFedFM å¯ä»¥é¡¯èå¢å¼·è¨åºè¨ºæ·ï¼åæä¿è­·çæ£é±ç§ï¼éæ¨èªè AI é©åè¶é³æ³¢å½±åå¨æªä¾è¨åºæç¨ä¸­çä¸é é²æ­¥ã

##### **GEMeX: A Large-Scale, Groundable, and Explainable Medical VQA Benchmark for Chest X-ray Diagnosis**
2411.16778v1 by Bo Liu, Ke Zou, Liming Zhan, Zexin Lu, Xiaoyu Dong, Yidi Chen, Chengqiang Xie, Jiannong Cao, Xiao-Ming Wu, Huazhu Fu

Medical Visual Question Answering (VQA) is an essential technology that
integrates computer vision and natural language processing to automatically
respond to clinical inquiries about medical images. However, current medical
VQA datasets exhibit two significant limitations: (1) they often lack visual
and textual explanations for answers, which impedes their ability to satisfy
the comprehension needs of patients and junior doctors; (2) they typically
offer a narrow range of question formats, inadequately reflecting the diverse
requirements encountered in clinical scenarios. These limitations pose
significant challenges to the development of a reliable and user-friendly
Med-VQA system. To address these challenges, we introduce a large-scale,
Groundable, and Explainable Medical VQA benchmark for chest X-ray diagnosis
(GEMeX), featuring several innovative components: (1) A multi-modal
explainability mechanism that offers detailed visual and textual explanations
for each question-answer pair, thereby enhancing answer comprehensibility; (2)
Four distinct question types, open-ended, closed-ended, single-choice, and
multiple-choice, that better reflect diverse clinical needs. We evaluated 10
representative large vision language models on GEMeX and found that they
underperformed, highlighting the dataset's complexity. However, after
fine-tuning a baseline model using the training set, we observed a significant
performance improvement, demonstrating the dataset's effectiveness. The project
is available at www.med-vqa.com/GEMeX.

æè¦ï¼é«çè¦è¦ºåç­ (VQA) æ¯ä¸é æ´åäºé»è¦è¦è¦ºåèªç¶èªè¨èçæè¡ï¼ç¨æ¼èªååè¦é«çå½±åç¸éè¨åºåé¡çåºæ¬æè¡ãç¶èï¼ç¾æçé«ç VQA è³æéæå©åä¸»è¦çéå¶ï¼(1) å®åéå¸¸ç¼ºä¹ç­æ¡çè¦è¦ºåæå­èªªæï¼éæé»ç¤å®åæ»¿è¶³æ£èååç´é«å¸«ççè§£éæ±ï¼(2) å®åéå¸¸åªæä¾ç¹çªç¯åçåé¡æ ¼å¼ï¼ç¡æ³åååæ è¨åºå ´æ¯ä¸­éå°çåç¨®éæ±ãéäºéå¶å°å¯é ä¸ä½¿ç¨èååç Med-VQA ç³»çµ±çéç¼æ§æäºéå¤§ææ°ãçºäºæå°éäºææ°ï¼æåéå°è¸é¨ X åè¨ºæ·å¼å¥äºå¤§è¦æ¨¡ãå¯ä¾æåå¯è§£éçé«ç VQA åºæº (GEMeX)ï¼å®åå«äºå¹¾ååµæ°ççµæé¨åï¼(1) ä¸ç¨®å¤æ¨¡å¼å¯è§£éæ§æ©å¶ï¼å®çºæ¯ååç­å°æä¾è©³ç´°çè¦è¦ºåæå­èªªæï¼å¾èå¢å¼·ç­æ¡çå¯çè§£æ§ï¼(2) åç¨®ä¸åçåé¡é¡åï¼éæ¾å¼ãå°éå¼ãå®é¸åå¤é¸ï¼å®åè½æ´å¥½å°åæ ä¸åçè¨åºéæ±ãæåå¨ GEMeX ä¸­è©ä¼°äº 10 åå·æä»£è¡¨æ§çå¤§åè¦è¦ºèªè¨æ¨¡åï¼ç¼ç¾å®åçè¡¨ç¾ä¸ä½³ï¼éå¸é¡¯äºè©²è³æéçè¤éæ§ãç¶èï¼å¨ä½¿ç¨è¨ç·´éå¾®èª¿åºæºæ¨¡åå¾ï¼æåè§å¯å°æ§è½é¡¯èæåï¼éè­æäºè©²è³æéçæææ§ãè©²å°æ¡å¯å¨ www.med-vqa.com/GEMeX æ¾å°ã


### Knowledge Graphs
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-12-06**|**KaLM: Knowledge-aligned Autoregressive Language Modeling via Dual-view Knowledge Graph Contrastive Learning**|Peng Yu et.al.|[2412.04948v1](http://arxiv.org/abs/2412.04948v1)|null|
|**2024-12-06**|**HyperGraphOS: A Meta Operating System for Science and Engineering**|Antonello Ceravola et.al.|[2412.04923v1](http://arxiv.org/abs/2412.04923v1)|null|
|**2024-12-06**|**Transformers Struggle to Learn to Search**|Abulhair Saparov et.al.|[2412.04703v1](http://arxiv.org/abs/2412.04703v1)|null|
|**2024-12-06**|**LLM-Align: Utilizing Large Language Models for Entity Alignment in Knowledge Graphs**|Xuan Chen et.al.|[2412.04690v1](http://arxiv.org/abs/2412.04690v1)|null|
|**2024-12-05**|**Retrieval-Augmented Machine Translation with Unstructured Knowledge**|Jiaan Wang et.al.|[2412.04342v1](http://arxiv.org/abs/2412.04342v1)|[link](https://github.com/krystalan/RAGtrans)|
|**2024-12-05**|**GRAF: Graph Retrieval Augmented by Facts for Legal Question Answering**|Cristian-George CrÄciun et.al.|[2412.04119v1](http://arxiv.org/abs/2412.04119v1)|null|
|**2024-12-05**|**MIND: Effective Incorrect Assignment Detection through a Multi-Modal Structure-Enhanced Language Model**|Yunhe Pang et.al.|[2412.03930v1](http://arxiv.org/abs/2412.03930v1)|[link](https://github.com/thudm/whoiswho)|
|**2024-12-05**|**How Good is ChatGPT in Giving Adaptive Guidance Using Knowledge Graphs in E-Learning Environments?**|Patrick Ocheja et.al.|[2412.03856v1](http://arxiv.org/abs/2412.03856v1)|null|
|**2024-12-05**|**Synergizing LLMs and Knowledge Graphs: A Novel Approach to Software Repository-Related Question Answering**|Samuel Abedu et.al.|[2412.03815v1](http://arxiv.org/abs/2412.03815v1)|null|
|**2024-12-05**|**Agent AI with LangGraph: A Modular Framework for Enhancing Machine Translation Using Large Language Models**|Jialin Wang et.al.|[2412.03801v1](http://arxiv.org/abs/2412.03801v1)|null|
|**2024-12-04**|**Language Model Meets Prototypes: Towards Interpretable Text Classification Models through Prototypical Networks**|Ximing Wen et.al.|[2412.03761v1](http://arxiv.org/abs/2412.03761v1)|null|
|**2024-12-04**|**How to Correctly do Semantic Backpropagation on Language-based Agentic Systems**|Wenyi Wang et.al.|[2412.03624v1](http://arxiv.org/abs/2412.03624v1)|[link](https://github.com/hishamalyahya/semantic_backprop)|
|**2024-12-04**|**Enhancing Supply Chain Visibility with Generative AI: An Exploratory Case Study on Relationship Prediction in Knowledge Graphs**|Ge Zheng et.al.|[2412.03390v1](http://arxiv.org/abs/2412.03390v1)|null|
|**2024-12-04**|**CBEval: A framework for evaluating and interpreting cognitive biases in LLMs**|Ammar Shaikh et.al.|[2412.03605v1](http://arxiv.org/abs/2412.03605v1)|null|
|**2024-12-03**|**Hybrid-SQuAD: Hybrid Scholarly Question Answering Dataset**|Tilahun Abedissa Taffa et.al.|[2412.02788v2](http://arxiv.org/abs/2412.02788v2)|[link](https://github.com/semantic-systems/hybrid-squad)|
|**2024-12-03**|**Characterizing Information Shared by Participants to Coding Challenges: The Case of Advent of Code**|Francesco Cauteruccio et.al.|[2412.02290v1](http://arxiv.org/abs/2412.02290v1)|null|
|**2024-12-02**|**A Neurosymbolic Fast and Slow Architecture for Graph Coloring**|Vedant Khandelwal et.al.|[2412.01752v1](http://arxiv.org/abs/2412.01752v1)|null|
|**2024-12-02**|**Intelligent Spark Agents: A Modular LangGraph Framework for Scalable, Visualized, and Enhanced Big Data Machine Learning Workflows**|Jialin Wang et.al.|[2412.01490v4](http://arxiv.org/abs/2412.01490v4)|null|
|**2024-12-01**|**SelfPrompt: Autonomously Evaluating LLM Robustness via Domain-Constrained Knowledge Guidelines and Refined Adversarial Prompts**|Aihua Pei et.al.|[2412.00765v1](http://arxiv.org/abs/2412.00765v1)|null|
|**2024-11-30**|**Leveraging LLM for Automated Ontology Extraction and Knowledge Graph Generation**|Mohammad Sadeq Abolhasani et.al.|[2412.00608v2](http://arxiv.org/abs/2412.00608v2)|null|
|**2024-11-30**|**Opus: A Large Work Model for Complex Workflow Generation**|ThÃ©o Fagnoni et.al.|[2412.00573v2](http://arxiv.org/abs/2412.00573v2)|null|
|**2024-11-30**|**Node Importance Estimation Leveraging LLMs for Semantic Augmentation in Knowledge Graphs**|Xinyu Lin et.al.|[2412.00478v1](http://arxiv.org/abs/2412.00478v1)|[link](https://github.com/xinyulin-fz/lenie)|
|**2024-11-29**|**An AI-Driven Data Mesh Architecture Enhancing Decision-Making in Infrastructure Construction and Public Procurement**|Saurabh Mishra et.al.|[2412.00224v1](http://arxiv.org/abs/2412.00224v1)|null|
|**2024-11-29**|**PerLA: Perceptive 3D Language Assistant**|Guofeng Mei et.al.|[2411.19774v1](http://arxiv.org/abs/2411.19774v1)|null|
|**2024-11-29**|**Knowledge Management for Automobile Failure Analysis Using Graph RAG**|Yuta Ojima et.al.|[2411.19539v1](http://arxiv.org/abs/2411.19539v1)|null|
|**2024-11-28**|**Way to Specialist: Closing Loop Between Specialized LLM and Evolving Domain Knowledge Graph**|Yutong Zhang et.al.|[2411.19064v1](http://arxiv.org/abs/2411.19064v1)|null|
|**2024-11-28**|**EzSQL: An SQL intermediate representation for improving SQL-to-text Generation**|Meher Bhardwaj et.al.|[2411.18923v1](http://arxiv.org/abs/2411.18923v1)|null|
|**2024-11-27**|**MLLM-Search: A Zero-Shot Approach to Finding People using Multimodal Large Language Models**|Angus Fung et.al.|[2412.00103v1](http://arxiv.org/abs/2412.00103v1)|null|
|**2024-11-27**|**Human Evaluation of Procedural Knowledge Graph Extraction from Text with Large Language Models**|Valentina Anita Carriero et.al.|[2412.03589v1](http://arxiv.org/abs/2412.03589v1)|null|
|**2024-11-27**|**Regularized Multi-LLMs Collaboration for Enhanced Score-based Causal Discovery**|Xiaoxuan Li et.al.|[2411.17989v1](http://arxiv.org/abs/2411.17989v1)|null|
|**2024-11-26**|**ShowUI: One Vision-Language-Action Model for GUI Visual Agent**|Kevin Qinghong Lin et.al.|[2411.17465v1](http://arxiv.org/abs/2411.17465v1)|[link](https://github.com/showlab/showui)|
|**2024-11-26**|**Can LLMs be Good Graph Judger for Knowledge Graph Construction?**|Haoyu Huang et.al.|[2411.17388v1](http://arxiv.org/abs/2411.17388v1)|[link](https://github.com/hhy-huang/graphjudger)|
|**2024-11-26**|**Interleaved Scene Graph for Interleaved Text-and-Image Generation Assessment**|Dongping Chen et.al.|[2411.17188v1](http://arxiv.org/abs/2411.17188v1)|null|
|**2024-11-25**|**AtomR: Atomic Operator-Empowered Large Language Models for Heterogeneous Knowledge Reasoning**|Amy Xin et.al.|[2411.16495v2](http://arxiv.org/abs/2411.16495v2)|[link](https://github.com/THU-KEG/AtomR)|
|**2024-11-25**|**Learning by Analogy: Enhancing Few-Shot Prompting for Math Word Problem Solving with Computational Graph-Based Retrieval**|Xiaocong Yang et.al.|[2411.16454v1](http://arxiv.org/abs/2411.16454v1)|null|
|**2024-11-25**|**Adapter-based Approaches to Knowledge-enhanced Language Models -- A Survey**|Alexander Fichtl et.al.|[2411.16403v1](http://arxiv.org/abs/2411.16403v1)|null|
|**2024-11-24**|**Decoding Urban Industrial Complexity: Enhancing Knowledge-Driven Insights via IndustryScopeGPT**|Siqi Wang et.al.|[2411.15758v1](http://arxiv.org/abs/2411.15758v1)|[link](https://github.com/tongji-kgllm/industryscope)|
|**2024-11-22**|**One to rule them all: natural language to bind communication, perception and action**|Simone Colombani et.al.|[2411.15033v1](http://arxiv.org/abs/2411.15033v1)|null|
|**2024-11-22**|**Time is on my sight: scene graph filtering for dynamic environment perception in an LLM-driven robot**|Simone Colombani et.al.|[2411.15027v1](http://arxiv.org/abs/2411.15027v1)|null|
|**2024-11-22**|**GOT4Rec: Graph of Thoughts for Sequential Recommendation**|Zewen Long et.al.|[2411.14922v1](http://arxiv.org/abs/2411.14922v1)|null|
|**2024-11-22**|**VisGraphVar: A Benchmark Generator for Assessing Variability in Graph Analysis Using Large Vision-Language Models**|Camilo ChacÃ³n Sartori et.al.|[2411.14832v1](http://arxiv.org/abs/2411.14832v1)|null|
|**2024-11-22**|**MolReFlect: Towards In-Context Fine-grained Alignments between Molecules and Texts**|Jiatong Li et.al.|[2411.14721v1](http://arxiv.org/abs/2411.14721v1)|null|
|**2024-11-21**|**G-RAG: Knowledge Expansion in Material Science**|Radeen Mostafa et.al.|[2411.14592v2](http://arxiv.org/abs/2411.14592v2)|[link](https://github.com/RadeenXALNW/G-RAG_1.0)|
|**2024-11-21**|**Knowledge Graphs, Large Language Models, and Hallucinations: An NLP Perspective**|Ernests Lavrinovics et.al.|[2411.14258v1](http://arxiv.org/abs/2411.14258v1)|null|
|**2024-11-21**|**Logic Augmented Generation**|Aldo Gangemi et.al.|[2411.14012v1](http://arxiv.org/abs/2411.14012v1)|null|
|**2024-11-21**|**FastRAG: Retrieval Augmented Generation for Semi-structured Data**|Amar Abane et.al.|[2411.13773v1](http://arxiv.org/abs/2411.13773v1)|null|
|**2024-11-20**|**Predictive Insights into LGBTQ+ Minority Stress: A Transductive Exploration of Social Media Discourse**|S. Chapagain et.al.|[2411.13534v1](http://arxiv.org/abs/2411.13534v1)|[link](https://github.com/chapagaisa/transductive)|
|**2024-11-20**|**KAAE: Numerical Reasoning for Knowledge Graphs via Knowledge-aware Attributes Learning**|Ming Yin et.al.|[2411.12950v2](http://arxiv.org/abs/2411.12950v2)|null|
|**2024-11-19**|**Neurosymbolic Graph Enrichment for Grounded World Models**|Stefano De Giorgis et.al.|[2411.12671v1](http://arxiv.org/abs/2411.12671v1)|null|
|**2024-11-19**|**Instant Policy: In-Context Imitation Learning via Graph Diffusion**|Vitalis Vosylius et.al.|[2411.12633v1](http://arxiv.org/abs/2411.12633v1)|null|
|**2024-11-19**|**Bias-Free Sentiment Analysis through Semantic Blinding and Graph Neural Networks**|Hubert Plisiecki et.al.|[2411.12493v2](http://arxiv.org/abs/2411.12493v2)|null|
|**2024-11-19**|**Neon: News Entity-Interaction Extraction for Enhanced Question Answering**|Sneha Singhania et.al.|[2411.12449v2](http://arxiv.org/abs/2411.12449v2)|null|
|**2024-11-19**|**GRL-Prompt: Towards Knowledge Graph based Prompt Optimization via Reinforcement Learning**|Yuze Liu et.al.|[2411.14479v1](http://arxiv.org/abs/2411.14479v1)|null|
|**2024-11-19**|**Just KIDDIN: Knowledge Infusion and Distillation for Detection of INdecent Memes**|Rahul Garg et.al.|[2411.12174v1](http://arxiv.org/abs/2411.12174v1)|null|
|**2024-11-18**|**Regret-Free Reinforcement Learning for LTL Specifications**|Rupak Majumdar et.al.|[2411.12019v1](http://arxiv.org/abs/2411.12019v1)|null|
|**2024-11-18**|**Semantic-Geometric-Physical-Driven Robot Manipulation Skill Transfer via Skill Library and Tactile Representation**|Mingchao Qi et.al.|[2411.11714v1](http://arxiv.org/abs/2411.11714v1)|[link](https://github.com/mingchaoqi/skill_transfer)|
|**2024-11-18**|**Addressing Hallucinations in Language Models with Knowledge Graph Embeddings as an Additional Modality**|Viktoriia Chekalina et.al.|[2411.11531v1](http://arxiv.org/abs/2411.11531v1)|null|
|**2024-11-17**|**RPN 2: On Interdependence Function Learning Towards Unifying and Advancing CNN, RNN, GNN, and Transformer**|Jiawei Zhang et.al.|[2411.11162v1](http://arxiv.org/abs/2411.11162v1)|null|
|**2024-11-16**|**LLaSA: Large Language and Structured Data Assistant**|Yao Xu et.al.|[2411.14460v1](http://arxiv.org/abs/2411.14460v1)|null|
|**2024-11-16**|**Unveiling User Preferences: A Knowledge Graph and LLM-Driven Approach for Conversational Recommendation**|Zhangchi Qiu et.al.|[2411.14459v1](http://arxiv.org/abs/2411.14459v1)|null|
|**2024-11-16**|**A Novel Approach to Eliminating Hallucinations in Large Language Model-Assisted Causal Discovery**|Grace Sng et.al.|[2411.12759v1](http://arxiv.org/abs/2411.12759v1)|null|
|**2024-11-15**|**VeriGraph: Scene Graphs for Execution Verifiable Robot Planning**|Daniel Ekpo et.al.|[2411.10446v2](http://arxiv.org/abs/2411.10446v2)|null|
|**2024-11-15**|**A Survey of Event Causality Identification: Principles, Taxonomy, Challenges, and Assessment**|Qing Cheng et.al.|[2411.10371v2](http://arxiv.org/abs/2411.10371v2)|null|
|**2024-11-15**|**Prompting and Fine-tuning Large Language Models for Automated Code Review Comment Generation**|Md. Asif Haider et.al.|[2411.10129v1](http://arxiv.org/abs/2411.10129v1)|null|
|**2024-11-15**|**HistoLens: An LLM-Powered Framework for Multi-Layered Analysis of Historical Texts -- A Case Application of Yantie Lun**|Yifan Zeng et.al.|[2411.09978v1](http://arxiv.org/abs/2411.09978v1)|null|
|**2024-11-14**|**Accelerating Knowledge Graph and Ontology Engineering with Large Language Models**|Cogan Shimizu et.al.|[2411.09601v1](http://arxiv.org/abs/2411.09601v1)|null|
|**2024-11-14**|**Automating Reformulation of Essence Specifications via Graph Rewriting**|Ian Miguel et.al.|[2411.09576v1](http://arxiv.org/abs/2411.09576v1)|null|
|**2024-11-13**|**Towards Evaluating Large Language Models for Graph Query Generation**|Siraj Munir et.al.|[2411.08449v2](http://arxiv.org/abs/2411.08449v2)|null|
|**2024-11-13**|**Knowledge Bases in Support of Large Language Models for Processing Web News**|Yihe Zhang et.al.|[2411.08278v2](http://arxiv.org/abs/2411.08278v2)|null|
|**2024-11-12**|**Retrieval, Reasoning, Re-ranking: A Context-Enriched Framework for Knowledge Graph Completion**|Muzhi Li et.al.|[2411.08165v1](http://arxiv.org/abs/2411.08165v1)|null|
|**2024-11-12**|**Language Models as Causal Effect Generators**|Lucius E. J. Bynum et.al.|[2411.08019v1](http://arxiv.org/abs/2411.08019v1)|[link](https://github.com/lbynum/sequence-driven-scms)|
|**2024-11-12**|**From General to Specific: Utilizing General Hallucination to Benchmark Specific Role-Playing Agents**|Chuyi Kong et.al.|[2411.07965v2](http://arxiv.org/abs/2411.07965v2)|null|
|**2024-11-12**|**Chain Association-based Attacking and Shielding Natural Language Processing Systems**|Jiacheng Huang et.al.|[2411.07843v1](http://arxiv.org/abs/2411.07843v1)|null|
|**2024-11-11**|**Gradual Fine-Tuning with Graph Routing for Multi-Source Unsupervised Domain Adaptation**|Yao Ma et.al.|[2411.07185v1](http://arxiv.org/abs/2411.07185v1)|null|
|**2024-11-11**|**A Domain-Agnostic Neurosymbolic Approach for Big Social Data Analysis: Evaluating Mental Health Sentiment on Social Media during COVID-19**|Vedant Khandelwal et.al.|[2411.07163v1](http://arxiv.org/abs/2411.07163v1)|null|
|**2024-11-11**|**A Multi-Agent Approach for REST API Testing with Semantic Graphs and LLM-Driven Inputs**|Myeongsoo Kim et.al.|[2411.07098v1](http://arxiv.org/abs/2411.07098v1)|null|
|**2024-11-11**|**Bridge: A Unified Framework to Knowledge Graph Completion via Language Models and Knowledge Representation**|Qiao Qiao et.al.|[2411.06660v1](http://arxiv.org/abs/2411.06660v1)|null|
|**2024-11-10**|**CausalStock: Deep End-to-end Causal Discovery for News-driven Stock Movement Prediction**|Shuqi Li et.al.|[2411.06391v1](http://arxiv.org/abs/2411.06391v1)|null|
|**2024-11-09**|**Analyzing the Evolution of Graphs and Texts**|Xingzhi Guo et.al.|[2411.06295v1](http://arxiv.org/abs/2411.06295v1)|null|
|**2024-11-09**|**An Empirical Analysis on Spatial Reasoning Capabilities of Large Multimodal Models**|Fatemeh Shiri et.al.|[2411.06048v1](http://arxiv.org/abs/2411.06048v1)|[link](https://github.com/fatemehshiri/spatial-mm)|
|**2024-11-08**|**Mitigating Hallucination with ZeroG: An Advanced Knowledge Management Engine**|Anantha Sharma et.al.|[2411.05936v1](http://arxiv.org/abs/2411.05936v1)|null|
|**2024-11-08**|**SM3-Text-to-Query: Synthetic Multi-Model Medical Text-to-Query Benchmark**|Sithursan Sivasubramaniam et.al.|[2411.05521v2](http://arxiv.org/abs/2411.05521v2)|[link](https://github.com/jf87/sm3-text-to-query)|
|**2024-11-08**|**EUREKHA: Enhancing User Representation for Key Hackers Identification in Underground Forums**|Abdoul Nasser Hassane Amadou et.al.|[2411.05479v1](http://arxiv.org/abs/2411.05479v1)|[link](https://github.com/jumbo110/eurekha)|
|**2024-11-08**|**When are 1.58 bits enough? A Bottom-up Exploration of BitNet Quantization**|Jacob Nielsen et.al.|[2411.05882v1](http://arxiv.org/abs/2411.05882v1)|null|
|**2024-11-08**|**Exploring the Alignment Landscape: LLMs and Geometric Deep Models in Protein Representation**|Dong Shu et.al.|[2411.05316v1](http://arxiv.org/abs/2411.05316v1)|[link](https://github.com/tizzzzy/llm-gdm-alignment)|
|**2024-11-07**|**AMSnet-KG: A Netlist Dataset for LLM-based AMS Circuit Auto-Design Using Knowledge Graph RAG**|Yichen Shi et.al.|[2411.13560v1](http://arxiv.org/abs/2411.13560v1)|null|
|**2024-11-06**|**LEGO-GraphRAG: Modularizing Graph-based Retrieval-Augmented Generation for Design Space Exploration**|Yukun Cao et.al.|[2411.05844v1](http://arxiv.org/abs/2411.05844v1)|null|
|**2024-11-06**|**MEG: Medical Knowledge-Augmented Large Language Models for Question Answering**|Laura Cabello et.al.|[2411.03883v2](http://arxiv.org/abs/2411.03883v2)|[link](https://github.com/lautel/meg)|
|**2024-11-06**|**A Library Perspective on Supervised Text Processing in Digital Libraries: An Investigation in the Biomedical Domain**|Hermann Kroll et.al.|[2411.12752v1](http://arxiv.org/abs/2411.12752v1)|[link](https://github.com/hermannkroll/supervisedtextprocessing)|
|**2024-11-06**|**The American Sign Language Knowledge Graph: Infusing ASL Models with Linguistic Knowledge**|Lee Kezar et.al.|[2411.03568v1](http://arxiv.org/abs/2411.03568v1)|null|
|**2024-11-05**|**Graph-DPEP: Decomposed Plug and Ensemble Play for Few-Shot Document Relation Extraction with Graph-of-Thoughts Reasoning**|Tao Zhang et.al.|[2411.02864v1](http://arxiv.org/abs/2411.02864v1)|null|
|**2024-11-05**|**Multimodal Commonsense Knowledge Distillation for Visual Question Answering**|Shuo Yang et.al.|[2411.02722v1](http://arxiv.org/abs/2411.02722v1)|null|
|**2024-11-04**|**Geometry of orofacial neuromuscular signals: speech articulation decoding using surface electromyography**|Harshavardhana T. Gowda et.al.|[2411.02591v2](http://arxiv.org/abs/2411.02591v2)|[link](https://github.com/HarshavardhanaTG/geometryOfOrofacialNeuromuscularSystem)|
|**2024-11-04**|**GraphXAIN: Narratives to Explain Graph Neural Networks**|Mateusz Cedro et.al.|[2411.02540v2](http://arxiv.org/abs/2411.02540v2)|[link](https://github.com/ADMAntwerp/GraphXAIN)|
|**2024-11-04**|**Improving Scientific Hypothesis Generation with Knowledge Grounded Large Language Models**|Guangzhi Xiong et.al.|[2411.02382v1](http://arxiv.org/abs/2411.02382v1)|null|
|**2024-11-04**|**QCG-Rerank: Chunks Graph Rerank with Query Expansion in Retrieval-Augmented LLMs for Tourism Domain**|Qikai Wei et.al.|[2411.08724v1](http://arxiv.org/abs/2411.08724v1)|null|
|**2024-11-04**|**Can Language Models Enable In-Context Database?**|Yu Pan et.al.|[2411.01807v1](http://arxiv.org/abs/2411.01807v1)|null|
|**2024-11-03**|**Graph-based Confidence Calibration for Large Language Models**|Yukun Li et.al.|[2411.02454v1](http://arxiv.org/abs/2411.02454v1)|null|
|**2024-11-03**|**Ontology Population using LLMs**|Sanaz Saki Norouzi et.al.|[2411.01612v1](http://arxiv.org/abs/2411.01612v1)|null|
|**2024-11-03**|**Pre-trained Molecular Language Models with Random Functional Group Masking**|Tianhao Peng et.al.|[2411.01401v1](http://arxiv.org/abs/2411.01401v1)|null|

#### Abstracts
##### **KaLM: Knowledge-aligned Autoregressive Language Modeling via Dual-view Knowledge Graph Contrastive Learning**
2412.04948v1 by Peng Yu, Cheng Deng, Beiya Dai, Xinbing Wang, Ying Wen

Autoregressive large language models (LLMs) pre-trained by next token
prediction are inherently proficient in generative tasks. However, their
performance on knowledge-driven tasks such as factual knowledge querying
remains unsatisfactory. Knowledge graphs (KGs), as high-quality structured
knowledge bases, can provide reliable knowledge for LLMs, potentially
compensating for their knowledge deficiencies. Aligning LLMs with explicit,
structured knowledge from KGs has been a challenge; previous attempts either
failed to effectively align knowledge representations or compromised the
generative capabilities of LLMs, leading to less-than-optimal outcomes. This
paper proposes \textbf{KaLM}, a \textit{Knowledge-aligned Language Modeling}
approach, which fine-tunes autoregressive LLMs to align with KG knowledge via
the joint objective of explicit knowledge alignment and implicit knowledge
alignment. The explicit knowledge alignment objective aims to directly optimize
the knowledge representation of LLMs through dual-view knowledge graph
contrastive learning. The implicit knowledge alignment objective focuses on
incorporating textual patterns of knowledge into LLMs through triple completion
language modeling. Notably, our method achieves a significant performance boost
in evaluations of knowledge-driven tasks, specifically embedding-based
knowledge graph completion and generation-based knowledge graph question
answering.

æè¦ï¼<paragraph>èªååæ­¸å¤§åèªè¨æ¨¡å (LLM) ç¶ç±ä¸ä¸åç¬¦èé æ¸¬é åè¨ç·´ï¼æ¬è³ªä¸æé·çæå¼ä»»åãç¶èï¼å®åå¨ç¥è­é©åä»»åï¼ä¾å¦äºå¯¦ç¥è­æ¥è©¢ï¼ä¸çè¡¨ç¾ä»ä¸ç¡äººæãç¥è­åè­ (KG) ä½çºé«åè³ªççµæ§åç¥è­åº«ï¼å¯ä»¥çº LLM æä¾å¯é çç¥è­ï¼æ½å¨å°å½è£å¶ç¥è­ä¸è¶³ãå° LLM èä¾èª KG çæç¢ºçµæ§åç¥è­å°é½ä¸ç´æ¯ä¸é ææ°ï¼ååçåè©¦è¦ä¹ç¡æ³ææå°é½ç¥è­è¡¨ç¤ºï¼è¦ä¹æå®³ LLM ççæè½åï¼å°è´çµæä¸ç¡çæ³ãæ¬ææåºäºä¸å**KaLM**ï¼ä¸ç¨®**ç¥è­å°é½èªè¨å»ºæ¨¡**æ¹æ³ï¼å®å¾®èª¿èªååæ­¸ LLM ä»¥ééæç¢ºç¥è­å°é½åé±å¼ç¥è­å°é½çè¯åç®æ¨è KG ç¥è­å°é½ãæç¢ºç¥è­å°é½ç®æ¨æ¨å¨éééè¦åç¥è­åè­å°æ¯å­¸ç¿ç´æ¥æä½³å LLM çç¥è­è¡¨ç¤ºãé±å¼ç¥è­å°é½ç®æ¨å°æ³¨æ¼ééä¸åçµå®æèªè¨å»ºæ¨¡å°ç¥è­çæå­æ¨¡å¼ç´å¥ LLMãå¼å¾æ³¨æçæ¯ï¼æåçæ¨¡åå¨ç¥è­é©åä»»åçè©ä¼°ä¸­ç²å¾é¡¯èçæè½æåï¼ç¹å¥æ¯åºæ¼åµå¥çç¥è­åè­å®æååºæ¼çæçç¥è­åè­åé¡è§£ç­ã</paragraph>

##### **HyperGraphOS: A Meta Operating System for Science and Engineering**
2412.04923v1 by Antonello Ceravola, Frank Joublin, Ahmed R. Sadik, Bram Bolder, Juha-Pekka Tolvanen

This paper presents HyperGraphOS, an innovative Operating System designed for
the scientific and engineering domains. It combines model based engineering,
graph modeling, data containers, and computational tools, offering users a
dynamic workspace for creating and managing complex models represented as
customizable graphs. Using a web based architecture, HyperGraphOS requires only
a modern browser to organize knowledge, documents, and content into
interconnected models. Domain Specific Languages drive workspace navigation,
code generation, AI integration, and process organization.The platform models
function as both visual drawings and data structures, enabling dynamic
modifications and inspection, both interactively and programmatically.
HyperGraphOS was evaluated across various domains, including virtual avatars,
robotic task planning using Large Language Models, and meta modeling for
feature based code development. Results show significant improvements in
flexibility, data management, computation, and document handling.

æè¦ï¼æ¬ææåº HyperGraphOSï¼éæ¯ä¸ååµæ°çä½æ¥­ç³»çµ±ï¼å°çºç§å­¸åå·¥ç¨é åè¨­è¨ãå®çµåäºåºæ¼æ¨¡åçå·¥ç¨ãåå½¢å»ºæ¨¡ãè³æå®¹å¨åè¨ç®å·¥å·ï¼çºä½¿ç¨èæä¾ä¸ååæå·¥ä½ç©ºéï¼ç¨æ¼å»ºç«åç®¡çè¡¨ç¤ºçºå¯èªè¨åå½¢çè¤éæ¨¡åãHyperGraphOS ä½¿ç¨åºæ¼ Web çæ¶æ§ï¼åªéè¦ä¸åç¾ä»£çè¦½å¨å³å¯å°ç¥è­ãæä»¶åå§å®¹çµç¹æäºé£æ¨¡åãç¹å®é åèªè¨é©åå·¥ä½ç©ºéå°è¦½ãç¨å¼ç¢¼ç¢çãAI æ´ååæµç¨çµç¹ãå¹³å°æ¨¡ååæä½çºè¦è¦ºç¹ªååè³æçµæ§ï¼æ¯æ´åæä¿®æ¹åæª¢æ¥ï¼ç¡è«æ¯äºåå¼éæ¯ä»¥ç¨å¼æ¹å¼é²è¡ãHyperGraphOS å·²å¨åç¨®é åä¸­é²è¡è©ä¼°ï¼åæ¬èæ¬åèº«ãä½¿ç¨å¤§åèªè¨æ¨¡åçæ©å¨äººä»»åè¦åï¼ä»¥åç¨æ¼åºæ¼ç¹å¾µçç¨å¼ç¢¼éç¼çåå»ºæ¨¡ãçµæé¡¯ç¤ºåºéæ´»æ§ãè³æç®¡çãéç®åæä»¶èçæ¹é¢çé¡¯èæ¹é²ã

##### **Transformers Struggle to Learn to Search**
2412.04703v1 by Abulhair Saparov, Srushti Pawar, Shreyas Pimpalgaonkar, Nitish Joshi, Richard Yuanzhe Pang, Vishakh Padmakumar, Seyed Mehran Kazemi, Najoung Kim, He He

Search is an ability foundational in many important tasks, and recent studies
have shown that large language models (LLMs) struggle to perform search
robustly. It is unknown whether this inability is due to a lack of data,
insufficient model parameters, or fundamental limitations of the transformer
architecture. In this work, we use the foundational graph connectivity problem
as a testbed to generate effectively limitless high-coverage data to train
small transformers and test whether they can learn to perform search. We find
that, when given the right training distribution, the transformer is able to
learn to search.
  We analyze the algorithm that the transformer has learned through a novel
mechanistic interpretability technique that enables us to extract the
computation graph from the trained model. We find that for each vertex in the
input graph, transformers compute the set of vertices reachable from that
vertex. Each layer then progressively expands these sets, allowing the model to
search over a number of vertices exponential in the number of layers.
  However, we find that as the input graph size increases, the transformer has
greater difficulty in learning the task. This difficulty is not resolved even
as the number of parameters is increased, suggesting that increasing model
scale will not lead to robust search abilities. We also find that performing
search in-context (i.e., chain-of-thought) does not resolve this inability to
learn to search on larger graphs.

æè¦ï¼æå°æ¯è¨±å¤éè¦ä»»åä¸­çä¸é åºç¤è½åï¼æè¿çç ç©¶è¡¨æï¼å¤§åèªè¨æ¨¡å (LLM) é£ä»¥ç©©å¥å°å·è¡æå°ãç®åå°ä¸æ¸æ¥éç¨®ç¡è½æ¯æºæ¼è³æä¸è¶³ãæ¨¡ååæ¸ä¸è¶³ï¼éæ¯ Transformer æ¶æ§çåºæ¬éå¶ãå¨éé å·¥ä½ä¸­ï¼æåä½¿ç¨åºç¤åå½¢é£éæ§åé¡ä½çºæ¸¬è©¦å¹³å°ï¼çæææç¡éçé«è¦èçè³æï¼ä»¥è¨ç·´å°å Transformer ä¸¦æ¸¬è©¦å®åæ¯å¦è½å­¸æå·è¡æå°ãæåç¼ç¾ï¼ç¶çµ¦äºæ­£ç¢ºçè¨ç·´åä½æï¼Transformer è½å¤ å­¸ææå°ã
æåééä¸ç¨®æ°ç©çæ©å¶å¯è§£éæ§æè¡åæ Transformer å­¸å°çæ¼ç®æ³ï¼éè®æåè½å¤ å¾è¨ç·´å¥½çæ¨¡åä¸­æåéç®åå½¢ãæåç¼ç¾ï¼å°æ¼è¼¸å¥åå½¢ä¸­çæ¯åé é»ï¼Transformer æè¨ç®å¾è©²é é»å¯å°éçé é»éåãç¶å¾ï¼æ¯ä¸å±¤é½æéæ­¥æ´åéäºéåï¼è®æ¨¡åè½å¤ å¨èå±¤æ¸åææ¸éä¿çé é»æ¸ç®ä¸é²è¡æå°ã
ç¶èï¼æåç¼ç¾ï¼é¨èè¼¸å¥åå½¢å¤§å°çå¢å ï¼Transformer å¨å­¸ç¿ä»»åææéå°æ´å¤§çå°é£ãå³ä½¿å¢å åæ¸æ¸éï¼éç¨®å°é£ä¹ä¸æå¾å°è§£æ±ºï¼éè¡¨æå¢å æ¨¡åè¦æ¨¡ä¸æå¸¶ä¾ç©©å¥çæå°è½åãæåéç¼ç¾ï¼å¨ä¸ä¸æä¸­å·è¡æå°ï¼å³æèéï¼ç¡æ³è§£æ±ºéç¨®ç¡æ³å­¸ç¿å¨è¼å¤§åå½¢ä¸æå°çåé¡ã

##### **LLM-Align: Utilizing Large Language Models for Entity Alignment in Knowledge Graphs**
2412.04690v1 by Xuan Chen, Tong Lu, Zhichun Wang

Entity Alignment (EA) seeks to identify and match corresponding entities
across different Knowledge Graphs (KGs), playing a crucial role in knowledge
fusion and integration. Embedding-based entity alignment (EA) has recently
gained considerable attention, resulting in the emergence of many innovative
approaches. Initially, these approaches concentrated on learning entity
embeddings based on the structural features of knowledge graphs (KGs) as
defined by relation triples. Subsequent methods have integrated entities' names
and attributes as supplementary information to improve the embeddings used for
EA. However, existing methods lack a deep semantic understanding of entity
attributes and relations. In this paper, we propose a Large Language Model
(LLM) based Entity Alignment method, LLM-Align, which explores the
instruction-following and zero-shot capabilities of Large Language Models to
infer alignments of entities. LLM-Align uses heuristic methods to select
important attributes and relations of entities, and then feeds the selected
triples of entities to an LLM to infer the alignment results. To guarantee the
quality of alignment results, we design a multi-round voting mechanism to
mitigate the hallucination and positional bias issues that occur with LLMs.
Experiments on three EA datasets, demonstrating that our approach achieves
state-of-the-art performance compared to existing EA methods.

æè¦ï¼å¯¦é«å°é½ (EA) æ¨å¨è­å¥åå¹éä¸åç¥è­åè­ (KG) ä¸­å°æçå¯¦é«ï¼å¨ç¥è­èååæ´åä¸­æ®æ¼èè³ééè¦çè§è²ãåºæ¼åµå¥çå¯¦é«å°é½ (EA) è¿ä¾ååéæ³¨ï¼é²èå¬çåºè¨±å¤åµæ°çæ¹æ³ãæåï¼éäºæ¹æ³å°æ³¨æ¼æ ¹æç¥è­åè­ (KG) ççµæ§ç¹å¾µä¾å­¸ç¿å¯¦é«åµå¥ï¼éäºç¹å¾µç±éä¿ä¸åçµå®ç¾©ãå¾çºæ¹æ³å°å¯¦é«åç¨±åå±¬æ§æ´åçºè£åè³è¨ï¼ä»¥æ¹åç¨æ¼ EA çåµå¥ãç¶èï¼ç¾ææ¹æ³ç¼ºä¹å°å¯¦é«å±¬æ§åéä¿çæ·±å¥èªç¾©çè§£ãå¨æ¬æä¸­ï¼æåæåºäºä¸ç¨®åºæ¼å¤§åèªè¨æ¨¡å (LLM) çå¯¦é«å°é½æ¹æ³ LLM-Alignï¼è©²æ¹æ³æ¢ç´¢äºå¤§åèªè¨æ¨¡åçéµå¾ªæä»¤åé¶æ¬¡å­¸ç¿è½åï¼ä»¥æ¨è«å¯¦é«å°é½ãLLM-Align ä½¿ç¨åç¼å¼æ¹æ³ä¾é¸æå¯¦é«çéè¦å±¬æ§åéä¿ï¼ç¶å¾å°å¯¦é«çé¸å®ä¸åçµé¥å¥ LLM ä»¥æ¨è«å°é½çµæãçºäºä¿è­å°é½çµæçåè³ªï¼æåè¨­è¨äºä¸åå¤è¼ªæç¥¨æ©å¶ï¼ä»¥æ¸è¼ LLM ä¸­åºç¾çå¹»è¦ºåä½ç½®åå·®åé¡ãå¨ä¸å EA è³æéä¸çå¯¦é©è¡¨æï¼èç¾æç EA æ¹æ³ç¸æ¯ï¼æåçåæ³éå°äºæåé²çæè½ã

##### **Retrieval-Augmented Machine Translation with Unstructured Knowledge**
2412.04342v1 by Jiaan Wang, Fandong Meng, Yingxue Zhang, Jie Zhou

Retrieval-augmented generation (RAG) introduces additional information to
enhance large language models (LLMs). In machine translation (MT), previous
work typically retrieves in-context examples from paired MT corpora, or
domain-specific knowledge from knowledge graphs, to enhance models' MT ability.
However, a large amount of world knowledge is organized in unstructured
documents, and might not be fully paired across different languages. In this
paper, we study retrieval-augmented MT using unstructured documents.
Specifically, we build RAGtrans, the first benchmark to train and evaluate
LLMs' retrieval-augmented MT ability. RAGtrans contains 79K MT samples
collected via GPT-4o and human translators. Besides, documents from different
languages are also provided to supply the knowledge to these samples. Based on
RAGtrans, we further propose a multi-task training method to teach LLMs how to
use information from multilingual documents during their translation. The
method uses existing multilingual corpora to create auxiliary training
objectives without additional labeling requirements. Extensive experiments show
that the method improves LLMs by 1.58-3.09 BLEU and 1.00-2.03 COMET scores.

æè¦ï¼æª¢ç´¢å¢å¼·ç¢ç (RAG) æå¼å¥é¡å¤è³è¨ï¼ä»¥å¢å¼·å¤§åèªè¨æ¨¡å (LLM)ãå¨æ©å¨ç¿»è­¯ (MT) ä¸­ï¼ååçä½æ¥­éå¸¸æå¾éå°ç MT èªæåº«ä¸­æª¢ç´¢æå¢ç¯ä¾ï¼æå¾ç¥è­åè¡¨ä¸­æª¢ç´¢ç¹å®é åçç¥è­ï¼ä»¥å¢å¼·æ¨¡åç MT è½åãç¶èï¼å¤§éçä¸çç¥è­é½æ¯ä»¥éçµæ§åæä»¶çµç¹ï¼èä¸å¯è½ç¡æ³å®å¨éå°å°ä¸åçèªè¨ä¸­ãå¨æ¬æä¸­ï¼æåç ç©¶ä½¿ç¨éçµæ§åæä»¶é²è¡æª¢ç´¢å¢å¼· MTãå·é«ä¾èªªï¼æåå»ºç«äº RAGtransï¼éæ¯ç¬¬ä¸åç¨æ¼è¨ç·´åè©ä¼° LLM çæª¢ç´¢å¢å¼· MT è½åçåºæºãRAGtrans åå«éé GPT-4o åäººå·¥ç¿»è­¯äººå¡æ¶éç 79K å MT ç¯ä¾ãæ­¤å¤ï¼ä¹æä¾äºä¸åèªè¨çæä»¶ï¼ä»¥æä¾éäºç¯ä¾çç¥è­ãæ ¹æ RAGtransï¼æåé²ä¸æ­¥æåºäºä¸åå¤ä»»åè¨ç·´æ¹æ³ï¼ä»¥æå° LLM å¦ä½å¨ç¿»è­¯éç¨ä¸­ä½¿ç¨å¤èªè¨æä»¶çè³è¨ãè©²æ¹æ³ä½¿ç¨ç¾æçå¤èªè¨èªæåº«å»ºç«è¼å©è¨ç·´ç®æ¨ï¼èç¡éé¡å¤çæ¨è¨éæ±ãå»£æ³çå¯¦é©é¡¯ç¤ºï¼è©²æ¹æ³å° LLM ç BLEU åæ¸æé«äº 1.58-3.09ï¼COMET åæ¸æé«äº 1.00-2.03ã

##### **GRAF: Graph Retrieval Augmented by Facts for Legal Question Answering**
2412.04119v1 by Cristian-George CrÄciun, RÄzvan-Alexandru SmÄdu, Dumitru-Clementin Cercel, Mihaela-Claudia Cercel

Pre-trained Language Models (PLMs) have shown remarkable performances in
recent years, setting a new paradigm for NLP research and industry. The legal
domain has received some attention from the NLP community partly due to its
textual nature. Some tasks from this domain are represented by
question-answering (QA) tasks. This work explores the legal domain
Multiple-Choice QA (MCQA) for a low-resource language. The contribution of this
work is multi-fold. We first introduce JuRO, the first openly available
Romanian legal MCQA dataset, comprising three different examinations and a
number of 10,836 total questions. Along with this dataset, we introduce CROL,
an organized corpus of laws that has a total of 93 distinct documents with
their modifications from 763 time spans, that we leveraged in this work for
Information Retrieval (IR) techniques. Moreover, we are the first to propose
Law-RoG, a Knowledge Graph (KG) for the Romanian language, and this KG is
derived from the aforementioned corpus. Lastly, we propose a novel approach for
MCQA, Graph Retrieval Augmented by Facts (GRAF), which achieves competitive
results with generally accepted SOTA methods and even exceeds them in most
settings.

æè¦ï¼<paragraph>é è¨ç·´èªè¨æ¨¡å (PLM) å¨è¿å¹´ä¾å±ç¾åºåè¶çæè½ï¼çºèªç¶èªè¨èççç ç©¶åç¢æ¥­æ¨¹ç«äºæ°çå¸ç¯ãæ³å¾é åå çºå¶ææ¬æ§è³ªèåå°èªç¶èªè¨èçç¤¾ç¾¤çé¨åéæ³¨ãæ­¤é åä¸­çä¸äºä»»åç±åç­ (QA) ä»»åè¡¨ç¤ºãéé å·¥ä½æ¢ç´¢äºä½è³æºèªè¨çæ³å¾é åå¤éé¸æåç­ (MCQA)ãéé å·¥ä½çè²¢ç»æ¯å¤æ¹é¢çãæåé¦åä»ç´¹ JuROï¼éæ¯ç¬¬ä¸åå¬éçç¾é¦¬å°¼äºæ³å¾ MCQA è³æéï¼åå«ä¸æ¬¡ä¸åçèè©¦åç¸½å± 10,836 ååé¡ãé¤äºéåè³æéä¹å¤ï¼æåéä»ç´¹äº CROLï¼éæ¯ä¸åæçµç¹çæ³å¾èªæåº«ï¼ç¸½å±æ 93 åä¸åçæä»¶ï¼åå«äºä¾èª 763 åæéåéçä¿®æ¹ï¼æåå¨éåå·¥ä½ä¸­å©ç¨å®ä¾é²è¡è³è¨æª¢ç´¢ (IR) æè¡ãæ­¤å¤ï¼æåæ¯ç¬¬ä¸åæåº Law-RoG çäººï¼éæ¯ä¸åç¾é¦¬å°¼äºèªçç¥è­åè­ (KG)ï¼èéå KG æ¯å¾ä¸è¿°èªæåº«è¡ççãæå¾ï¼æåæåºäºä¸åæ°çå¤éé¸æåç­æ¹æ³ï¼ç±äºå¯¦å¢å¼·çåå½¢æª¢ç´¢ (GRAF)ï¼å®å¨ä¸è¬å¬èªç SOTA æ¹æ³ä¸­ç²å¾äºæç«¶ç­åççµæï¼çè³å¨å¤§å¤æ¸è¨­å®ä¸­é½è¶è¶äºå®åã</paragraph>

##### **MIND: Effective Incorrect Assignment Detection through a Multi-Modal Structure-Enhanced Language Model**
2412.03930v1 by Yunhe Pang, Bo Chen, Fanjin Zhang, Yanghui Rao, Jie Tang

The rapid growth of academic publications has exacerbated the issue of author
name ambiguity in online digital libraries. Despite advances in name
disambiguation algorithms, cumulative errors continue to undermine the
reliability of academic systems. It is estimated that over 10% paper-author
assignments are rectified when constructing the million-scale WhoIsWho
benchmark. Existing endeavors to detect incorrect assignments are either
semantic-based or graph-based approaches, which fall short of making full use
of the rich text attributes of papers and implicit structural features defined
via the co-occurrence of paper attributes. To this end, this paper introduces a
structure-enhanced language model that combines key structural features from
graph-based methods with fine-grained semantic features from rich paper
attributes to detect incorrect assignments. The proposed model is trained with
a highly effective multi-modal multi-turn instruction tuning framework, which
incorporates task-guided instruction tuning, text-attribute modality, and
structural modality. Experimental results demonstrate that our model
outperforms previous approaches, achieving top performance on the leaderboard
of KDD Cup 2024. Our code has been publicly available.

æè¦ï¼å­¸è¡åºçåçå¿«éæé·ï¼å åäºç·ä¸æ¸ä½åæ¸é¤¨ä¸­ä½èå§åæ­§ç¾©çåé¡ãåç®¡å§åæ¶æ­§æ¼ç®æ³æé²å±ï¼ç´¯ç©çé¯èª¤ä»æçºç ´å£å­¸è¡ç³»çµ±çå¯é æ§ãæä¼°è¨ï¼å¨å»ºæ§ç¾è¬è¦æ¨¡ç WhoIsWho åºæºæï¼è¶é 10% çè«æä½èææ´¾è¢«ä¿®æ­£ãç¾æçåµæ¸¬ä¸æ­£ç¢ºææ´¾çåªåï¼ä¸æ¯åºæ¼èªæçï¼å°±æ¯åºæ¼åçï¼ç¡æ³ååå©ç¨è«æè±å¯çæå­å±¬æ§åééè«æå±¬æ§å±ç¾å®ç¾©çé±å«çµæ§ç¹å¾µãçºæ­¤ï¼æ¬æä»ç´¹äºä¸åçµæ§å¢å¼·èªè¨æ¨¡åï¼å°åºæ¼åçæ¹æ³ä¸­çééµçµæ§ç¹å¾µèè±å¯è«æå±¬æ§ä¸­çç´°ç²åº¦èªç¾©ç¹å¾µç¸çµåï¼ä»¥åµæ¸¬ä¸æ­£ç¢ºçææ´¾ãææåºçæ¨¡åä½¿ç¨ä¸åé«æçå¤æ¨¡æå¤è¼ªæä»¤å¾®èª¿æ¶æ§é²è¡è¨ç·´ï¼å¶ä¸­åå«ä»»åå°åçæä»¤å¾®èª¿ãæå­å±¬æ§æ¨¡æåçµæ§æ¨¡æãå¯¦é©çµæè­æï¼æåçæ¨¡ååªæ¼ååçæ¨¡åï¼å¨ KDD Cup 2024 çæè¡æ¦ä¸åå¾æä½³æè½ãæåçç¨å¼ç¢¼å·²å¬éã

##### **How Good is ChatGPT in Giving Adaptive Guidance Using Knowledge Graphs in E-Learning Environments?**
2412.03856v1 by Patrick Ocheja, Brendan Flanagan, Yiling Dai, Hiroaki Ogata

E-learning environments are increasingly harnessing large language models
(LLMs) like GPT-3.5 and GPT-4 for tailored educational support. This study
introduces an approach that integrates dynamic knowledge graphs with LLMs to
offer nuanced student assistance. By evaluating past and ongoing student
interactions, the system identifies and appends the most salient learning
context to prompts directed at the LLM. Central to this method is the knowledge
graph's role in assessing a student's comprehension of topic prerequisites.
Depending on the categorized understanding (good, average, or poor), the LLM
adjusts its guidance, offering advanced assistance, foundational reviews, or
in-depth prerequisite explanations, respectively. Preliminary findings suggest
students could benefit from this tiered support, achieving enhanced
comprehension and improved task outcomes. However, several issues related to
potential errors arising from LLMs were identified, which can potentially
mislead students. This highlights the need for human intervention to mitigate
these risks. This research aims to advance AI-driven personalized learning
while acknowledging the limitations and potential pitfalls, thus guiding future
research in technology and data-driven education.

æè¦ï¼é»å­å­¸ç¿ç°å¢æ­£æ¥çå©ç¨å¤§åèªè¨æ¨¡å (LLM)ï¼ä¾å¦ GPT-3.5 å GPT-4ï¼æä¾éèº«æé çæè²æ¯æ´ãæ¬ç ç©¶æåºäºä¸ç¨®æ¹æ³ï¼å°åæç¥è­åè LLM æ´åï¼æä¾ç´°ç·»å¥å¾®çå­¸çåå©ãç³»çµ±æè©ä¼°éå»åæ­£å¨é²è¡çå­¸çäºåï¼æ¾åºä¸¦éå æé¡¯èçå­¸ç¿èçµ¡ï¼ä»¥æç¤º LLMãæ­¤æ¹æ³çæ ¸å¿å¨æ¼ç¥è­åå¨è©ä¼°å­¸çå°ä¸»é¡ååç¥è­ççè§£ç¨åº¦æ¹é¢ææ®æ¼çè§è²ãLLM ææ ¹æåé¡å¾ççè§£ç¨åº¦ï¼è¯å¥½ãæ®éæå·®ï¼èª¿æ´å¶æå°ï¼åå¥æä¾é²éåå©ãåºç¤åé¡§ææ·±å¥çååç¥è­èªªæãåæ­¥ç¼ç¾è¡¨æï¼å­¸çå¯ä»¥åçæ¼éç¨®åå±¤æ¯æ´ï¼éå°å¢å¼·ççè§£ååæ¹åçä»»åææãç¶èï¼å·²æ¾åºè LLM ç¢ççæ½å¨é¯èª¤ç¸éçå¹¾ååé¡ï¼éäºé¯èª¤å¯è½æèª¤å°å­¸çãéçªé¡¯äºäººé¡ä»å¥ä»¥éä½éäºé¢¨éªçå¿è¦æ§ãæ¬ç ç©¶æ¨å¨æ¨é² AI é©åçåäººåå­¸ç¿ï¼åææ¿èªéå¶åæ½å¨çé·é±ï¼å¾èæå°æªä¾å¨æè¡åè³æé©åæè²æ¹é¢çç ç©¶ã

##### **Synergizing LLMs and Knowledge Graphs: A Novel Approach to Software Repository-Related Question Answering**
2412.03815v1 by Samuel Abedu, SayedHassan Khatoonabadi, Emad Shihab

Software repositories contain valuable information for gaining insights into
their development process. However, extracting insights from these repository
data is time-consuming and requires technical expertise. While software
engineering chatbots have been developed to facilitate natural language
interactions with repositories, they struggle with understanding natural
language and accurately retrieving relevant data. This study aims to improve
the accuracy of LLM-based chatbots in answering repository-related questions by
augmenting them with knowledge graphs. We achieve this in a two-step approach;
(1) constructing a knowledge graph from the repository data and (2) synergizing
the knowledge graph with LLM to allow for the natural language questions and
answers. We curated a set of 20 questions with different complexities and
evaluated our approach on five popular open-source projects. Our approach
achieved an accuracy of 65%. We further investigated the limitations and
identified six key issues, with the majority relating to the reasoning
capability of the LLM. We experimented with a few-shot chain-of-thought
prompting to determine if it could enhance our approach. This technique
improved the overall accuracy to 84%. Our findings demonstrate the synergy
between LLMs and knowledge graphs as a viable solution for making repository
data accessible to both technical and non-technical stakeholders.

æè¦ï¼è»é«å²å­åº«åå«æå¹å¼çè³è¨ï¼å¯æ·±å¥äºè§£å¶éç¼æµç¨ãç¶èï¼å¾éäºå²å­åº«è³æä¸­æ·åè¦è§£æ¢èæåéè¦æè¡å°æ¥­ç¥è­ãåç®¡å·²éç¼åºè»é«å·¥ç¨èå¤©æ©å¨äººä¾ä¿é²èå²å­åº«çèªç¶èªè¨äºåï¼ä½å®åå¨çè§£èªç¶èªè¨åæºç¢ºæ·åç¸éè³ææ¹é¢ä»æå°é£ãæ¬ç ç©¶æ¨å¨ééç¥è­åè­æ´å LLM åºç¤èå¤©æ©å¨äººï¼ä»¥æé«å¶åç­å²å­åº«ç¸éåé¡çæºç¢ºæ§ãæåæ¡ç¨å©æ­¥é©æ¹æ³ä¾éææ­¤ç®æ¨ï¼(1) å¾å²å­åº«è³æå»ºæ§ç¥è­åè­ï¼ä»¥å (2) å°ç¥è­åè­è LLM çµåï¼ä»¥åè¨±èªç¶èªè¨åé¡åç­æ¡ãæåç­åäºä¸çµ 20 åå·æä¸åè¤éåº¦çåé¡ï¼ä¸¦éå°äºåç±éçéæºå°æ¡è©ä¼°æåçåæ³ãæåçåæ³éå°äº 65% çæºç¢ºåº¦ãæåé²ä¸æ­¥æ¢è¨äºéå¶ï¼ä¸¦æ¾åºå­åééµåé¡ï¼å¶ä¸­å¤§é¨åè LLM çæ¨çè½åæéãæåå¯¦é©äºå°æ¬¡æ¸çæèéæç¤ºï¼ä»¥ç¢ºå®å®æ¯å¦å¯ä»¥å¢å¼·æåçåæ³ãæ­¤æè¡å°æ´é«æºç¢ºåº¦æé«å° 84%ãæåçç ç©¶çµæè­æäº LLM åç¥è­åè­ä¹éçååææï¼ä½çºè®æè¡åéæè¡å©å®³éä¿äººè½å¤ å­åå²å­åº«è³æçå¯è¡è§£æ±ºæ¹æ¡ã

##### **Agent AI with LangGraph: A Modular Framework for Enhancing Machine Translation Using Large Language Models**
2412.03801v1 by Jialin Wang, Zhihua Duan

This paper explores the transformative role of Agent AI and LangGraph in
advancing the automation and effectiveness of machine translation (MT). Agents
are modular components designed to perform specific tasks, such as translating
between particular languages, with specializations like TranslateEnAgent,
TranslateFrenchAgent, and TranslateJpAgent for English, French, and Japanese
translations, respectively. These agents leverage the powerful semantic
capabilities of large language models (LLMs), such as GPT-4o, to ensure
accurate, contextually relevant translations while maintaining modularity,
scalability, and context retention.
  LangGraph, a graph-based framework built on LangChain, simplifies the
creation and management of these agents and their workflows. It supports
dynamic state management, enabling agents to maintain dialogue context and
automates complex workflows by linking agents and facilitating their
collaboration. With flexibility, open-source community support, and seamless
integration with LLMs, LangGraph empowers agents to deliver high-quality
translations.
  Together, Agent AI and LangGraph create a cohesive system where LangGraph
orchestrates agent interactions, ensuring that user inputs are analyzed,
routed, and processed efficiently. Experimental results demonstrate the
potential of this system to enhance multilingual translation accuracy and
scalability. By highlighting modular design and automated workflows, this paper
sets the stage for further innovations in intelligent machine translation
services.

æè¦ï¼æ¬ææ¢è¨äº Agent AI å LangGraph å¨æ¨åæ©å¨ç¿»è­¯ (MT) çèªåååæçæ¹é¢çè®é©æ§ä½ç¨ãAgent æ¯æ¨¡çµååä»¶ï¼æ¨å¨å·è¡ç¹å®ä»»åï¼ä¾å¦å¨ç¹å®èªè¨ä¹éç¿»è­¯ï¼ä¸¦å·æå°éé åï¼ä¾å¦ TranslateEnAgentãTranslateFrenchAgent å TranslateJpAgent åå¥ç¨æ¼è±æãæ³æåæ¥æçç¿»è­¯ãéäº Agent éç¨å¤§åèªè¨æ¨¡å (LLM) çå¼·å¤§èªç¾©åè½ï¼ä¾å¦ GPT-4oï¼ä»¥ç¢ºä¿æºç¢ºãèä¸ä¸æç¸éçç¿»è­¯ï¼åæä¿ææ¨¡çµåãå¯æ´åæ§åä¸ä¸æä¿çã
LangGraph æ¯å»ºæ§æ¼ LangChain ä¸çåå½¢åæ¡æ¶ï¼ç°¡åäºéäº Agent åå¶å·¥ä½æµç¨çå»ºç«åç®¡çãå®æ¯æ´åæçæç®¡çï¼è® Agent è½å¤ ç¶­è­·å°è©±å§å®¹ï¼ä¸¦ééé£çµ Agent åä¿é²å¶åä½ï¼èªååè¤éçå·¥ä½æµç¨ãLangGraph å·æéæ´»æ§ãéæ¾åå§ç¢¼ç¤¾ç¾¤æ¯æ´åè LLM ç¡ç¸«æ´åç­åªé»ï¼è® Agent è½å¤ æä¾é«åè³ªçç¿»è­¯ã
Agent AI å LangGraph å±åå»ºç«äºä¸åç·å¯çç³»çµ±ï¼å¶ä¸­ LangGraph ç·¨æ Agent äºåï¼ç¢ºä¿ä½¿ç¨èè¼¸å¥è¢«ææå°åæãè·¯ç±åèçãå¯¦é©çµæè­æäºéåç³»çµ±å¨æåå¤èªè¨ç¿»è­¯æºç¢ºæ§åå¯æ´åæ§æ¹é¢çæ½åãééå¼·èª¿æ¨¡çµåè¨­è¨åèªååå·¥ä½æµç¨ï¼æ¬æçºæºæ§åæ©å¨ç¿»è­¯æåçé²ä¸æ­¥åµæ°å¥ å®äºåºç¤ã

##### **Language Model Meets Prototypes: Towards Interpretable Text Classification Models through Prototypical Networks**
2412.03761v1 by Ximing Wen

Pretrained transformer-based Language Models (LMs) are well-known for their
ability to achieve significant improvement on NLP tasks, but their black-box
nature, which leads to a lack of interpretability, has been a major concern. My
dissertation focuses on developing intrinsically interpretable models when
using LMs as encoders while maintaining their superior performance via
prototypical networks. I initiated my research by investigating enhancements in
performance for interpretable models of sarcasm detection. My proposed approach
focuses on capturing sentiment incongruity to enhance accuracy while offering
instance-based explanations for the classification decisions. Later, I
developed a novel white-box multi-head graph attention-based prototype network
designed to explain the decisions of text classification models without
sacrificing the accuracy of the original black-box LMs. In addition, I am
working on extending the attention-based prototype network with contrastive
learning to redesign an interpretable graph neural network, aiming to enhance
both the interpretability and performance of the model in document
classification.

æè¦ï¼é åè¨ç·´å¥½çåºæ¼ Transformer çèªè¨æ¨¡å (LM) ä»¥å¶å¨ NLP ä»»åä¸­åå¾é¡¯èé²æ­¥çè½åèèåï¼ä½å®åçé»çæ§è³ªå°è´ç¼ºä¹å¯è§£éæ§ï¼ä¸ç´æ¯ä¸åä¸»è¦åé¡ãæçè«æéé»å¨æ¼å¨ä½¿ç¨ LM ä½çºç·¨ç¢¼å¨æéç¼å§å¨å¯è§£éçæ¨¡åï¼åæééååç¶²è·¯ç¶­æå¶åªç°çæè½ãæééç ç©¶è«·åºåµæ¸¬çå¯è§£éæ¨¡åçæè½æåä¾ååæçç ç©¶ãææåºçæ¹æ³å°æ³¨æ¼æææç·ä¸ä¸è´æ§ï¼ä»¥æé«æºç¢ºåº¦ï¼åæçºåé¡æ±ºç­æä¾åºæ¼å¯¦ä¾çè§£éãå¾ä¾ï¼æéç¼äºä¸åæ°ç©çç½çå¤é ­åå½¢æ³¨æåååç¶²è·¯ï¼æ¨å¨è§£éæå­åé¡æ¨¡åçæ±ºç­ï¼èä¸æç§ç²åå§é»ç LM çæºç¢ºåº¦ãæ­¤å¤ï¼ææ­£å¨åªåå°åºæ¼æ³¨æåçååç¶²è·¯èå°æ¯å­¸ç¿æ´å±ï¼ä»¥éæ°è¨­è¨ä¸åå¯è§£éçåå½¢ç¥ç¶ç¶²è·¯ï¼æ¨å¨å¢å¼·æ¨¡åå¨æä»¶åé¡ä¸­çå¯è§£éæ§åæè½ã

##### **How to Correctly do Semantic Backpropagation on Language-based Agentic Systems**
2412.03624v1 by Wenyi Wang, Hisham A. Alyahya, Dylan R. Ashley, Oleg Serikov, Dmitrii Khizbullin, Francesco Faccio, JÃ¼rgen Schmidhuber

Language-based agentic systems have shown great promise in recent years,
transitioning from solving small-scale research problems to being deployed in
challenging real-world tasks. However, optimizing these systems often requires
substantial manual labor. Recent studies have demonstrated that these systems
can be represented as computational graphs, enabling automatic optimization.
Despite these advancements, most current efforts in Graph-based Agentic System
Optimization (GASO) fail to properly assign feedback to the system's components
given feedback on the system's output. To address this challenge, we formalize
the concept of semantic backpropagation with semantic gradients -- a
generalization that aligns several key optimization techniques, including
reverse-mode automatic differentiation and the more recent TextGrad by
exploiting the relationship among nodes with a common successor. This serves as
a method for computing directional information about how changes to each
component of an agentic system might improve the system's output. To use these
gradients, we propose a method called semantic gradient descent which enables
us to solve GASO effectively. Our results on both BIG-Bench Hard and GSM8K show
that our approach outperforms existing state-of-the-art methods for solving
GASO problems. A detailed ablation study on the LIAR dataset demonstrates the
parsimonious nature of our method. A full copy of our implementation is
publicly available at https://github.com/HishamAlyahya/semantic_backprop

æè¦ï¼<paragraph>è¿å¹´ä¾ï¼åºæ¼èªè¨çä»£çç³»çµ±å±ç¾äºæ¥µå¤§çåæ¯ï¼
å¾è§£æ±ºå°è¦æ¨¡çç ç©¶åé¡ï¼è½è®çºé¨ç½²å¨
å·æææ°æ§ççå¯¦ä¸çä»»åä¸­ãç¶èï¼æä½³åéäºç³»çµ±éå¸¸éè¦
å¤§éçäººå·¥ååãæè¿çç ç©¶è¡¨æï¼éäºç³»çµ±
å¯ä»¥è¡¨ç¤ºçºè¨ç®åï¼å¯¦ç¾èªåæä½³åã
åç®¡æéäºé²å±ï¼ä½ç®åå¤§å¤æ¸åºæ¼åå½¢çä»£çç³»çµ±
æä½³å (GASO) çåªåï¼é½ç¡æ³é©ç¶å°å°åé¥åéçµ¦ç³»çµ±ççµæé¨å
çµ¦äºç³»çµ±è¼¸åºçåé¥ãçºäºæå°éä¸ææ°ï¼æåæ­£å¼åäº
èªç¾©ååå³æ­çæ¦å¿µï¼ä¸¦å¸¶æèªç¾©æ¢¯åº¦ââä¸ç¨®
æ¦æ¬ï¼å®çµåäºå¹¾ç¨®ééµçæä½³åæè¡ï¼åæ¬
ååæ¨¡å¼èªåå¾®ååæè¿ç TextGradï¼å©ç¨å·æå±åå¾ç¹¼èçç¯é»ä¹éçéä¿ãéå¯ä»¥ç¨ä½
ä¸ç¨®è¨ç®æ¹åè³è¨çæ¹æ³ï¼èªªæå¦ä½æ¹è®ä»£çç³»çµ±çæ¯å
çµæé¨åå¯è½ææ¹åç³»çµ±çè¼¸åºãçºäºä½¿ç¨éäº
æ¢¯åº¦ï¼æåæåºäºä¸ç¨®ç¨±çºèªç¾©æ¢¯åº¦ä¸éçæ¹æ³ï¼ä½¿æåè½å¤ 
ææå°è§£æ±º GASOãæåå¨ BIG-Bench Hard å GSM8K ä¸ççµæè¡¨æ
æåçåæ³åªæ¼è§£æ±º
GASO åé¡çç¾ææåé²æ¹æ³ãå¨ LIAR è³æéä¸é²è¡çè©³ç´°æ¶èç ç©¶è­æäº
æåæ¹æ³çç°¡ç´æ§ãæåçå¯¦ä½çå®æ´å¯æ¬å¬éæ¼ https://github.com/HishamAlyahya/semantic_backprop</paragraph>

##### **Enhancing Supply Chain Visibility with Generative AI: An Exploratory Case Study on Relationship Prediction in Knowledge Graphs**
2412.03390v1 by Ge Zheng, Alexandra Brintrup

A key stumbling block in effective supply chain risk management for companies
and policymakers is a lack of visibility on interdependent supply network
relationships. Relationship prediction, also called link prediction is an
emergent area of supply chain surveillance research that aims to increase the
visibility of supply chains using data-driven techniques. Existing methods have
been successful for predicting relationships but struggle to extract the
context in which these relationships are embedded - such as the products being
supplied or locations they are supplied from. Lack of context prevents
practitioners from distinguishing transactional relations from established
supply chain relations, hindering accurate estimations of risk. In this work,
we develop a new Generative Artificial Intelligence (Gen AI) enhanced machine
learning framework that leverages pre-trained language models as embedding
models combined with machine learning models to predict supply chain
relationships within knowledge graphs. By integrating Generative AI techniques,
our approach captures the nuanced semantic relationships between entities,
thereby improving supply chain visibility and facilitating more precise risk
management. Using data from a real case study, we show that GenAI-enhanced link
prediction surpasses all benchmarks, and demonstrate how GenAI models can be
explored and effectively used in supply chain risk management.

æè¦ï¼ä¾æéé¢¨éªç®¡çä¸­çä¸åééµéç¤å¨æ¼ä¼æ¥­åæ¿ç­å¶å®èç¼ºä¹å°ç¸äºä¾å­ä¾æç¶²è·¯éä¿çè½è¦åº¦ãéä¿é æ¸¬ï¼ä¹ç¨±çºé£çµé æ¸¬ï¼æ¯ä¾æéç£æ§ç ç©¶ä¸­ä¸åæ°èé åï¼æ¨å¨ä½¿ç¨è³æé©åæè¡æé«ä¾æéçè½è¦åº¦ãç¾ææ¹æ³å·²æåé æ¸¬éä¿ï¼ä½é£ä»¥æåéäºéä¿æåµå¥çèæ¯ï¼ä¾å¦æä¾æçç¢åæä¾æå°é»ãç¼ºä¹èæ¯æå¦¨ç¤å¾æ¥­èååäº¤æéä¿åæ¢å®çä¾æééä¿ï¼é²èé»ç¤é¢¨éªçæºç¢ºè©ä¼°ãå¨éé å·¥ä½ä¸­ï¼æåéç¼äºä¸åæ°ççæå¼äººå·¥æºæ§ (Gen AI) å¢å¼·æ©å¨å­¸ç¿æ¶æ§ï¼å®å©ç¨é åè¨ç·´çèªè¨æ¨¡åä½çºåµå¥æ¨¡åï¼ä¸¦çµåæ©å¨å­¸ç¿æ¨¡åä¾é æ¸¬ç¥è­åè­ä¸­çä¾æééä¿ãééæ´åçæå¼ AI æè¡ï¼æåçåæ³ææå°å¯¦é«ä¹éç´°å¾®çèªç¾©éä¿ï¼å¾èæé«ä¾æéè½è¦åº¦ä¸¦ä¿é²æ´ç²¾ç¢ºçé¢¨éªç®¡çãä½¿ç¨ä¾èªçå¯¦æ¡ä¾ç ç©¶çè³æï¼æåè­æ GenAI å¢å¼·é£çµé æ¸¬åªæ¼ææåºæºï¼ä¸¦å±ç¤ºå¦ä½æ¢ç´¢åææå°å¨ä¾æéé¢¨éªç®¡çä¸­ä½¿ç¨ GenAI æ¨¡åã

##### **CBEval: A framework for evaluating and interpreting cognitive biases in LLMs**
2412.03605v1 by Ammar Shaikh, Raj Abhijit Dandekar, Sreedath Panat, Rajat Dandekar

Rapid advancements in Large Language models (LLMs) has significantly enhanced
their reasoning capabilities. Despite improved performance on benchmarks, LLMs
exhibit notable gaps in their cognitive processes. Additionally, as reflections
of human-generated data, these models have the potential to inherit cognitive
biases, raising concerns about their reasoning and decision making
capabilities. In this paper we present a framework to interpret, understand and
provide insights into a host of cognitive biases in LLMs. Conducting our
research on frontier language models we're able to elucidate reasoning
limitations and biases, and provide reasoning behind these biases by
constructing influence graphs that identify phrases and words most responsible
for biases manifested in LLMs. We further investigate biases such as round
number bias and cognitive bias barrier revealed when noting framing effect in
language models.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çå¿«éé²æ­¥é¡¯èå¢å¼·äºå®åçæ¨çè½åãåç®¡å¨åºæºæ¸¬è©¦ä¸­çè¡¨ç¾æææåï¼ä½ LLM å¨å¶èªç¥éç¨ä¸­ä»å­å¨é¡¯èçå·®è·ãæ­¤å¤ï¼ä½çºäººé¡çææ¸æçåæ ï¼éäºæ¨¡åæå¯è½ç¹¼æ¿èªç¥åå·®ï¼å¼ç¼äººåå°å¶æ¨çåæ±ºç­è½åçææãå¨æ¬æä¸­ï¼æåæåºäºä¸åæ¡æ¶ä¾è§£éãçè§£åæ´å¯ LLM ä¸­çä¸ç³»åèªç¥åå·®ãééå°åæ²¿èªè¨æ¨¡åé²è¡ç ç©¶ï¼æåè½å¤ é¡ææ¨çéå¶ååå·®ï¼ä¸¦ééæ§å»ºå½±é¿åä¾æä¾éäºåå·®èå¾çæ¨çï¼éäºå½±é¿åè­å¥åºå° LLM ä¸­è¡¨ç¾åºçåå·®è² ææå¤§è²¬ä»»çç­èªåè©å½ãæåé²ä¸æ­¥ç ç©¶äºå¨èªè¨æ¨¡åä¸­è¨»ææ¡æ¶ææææ­ç¤ºçåå·®ï¼ä¾å¦åæ¨äºå¥åå·®åèªç¥åå·®éç¤ã

##### **Hybrid-SQuAD: Hybrid Scholarly Question Answering Dataset**
2412.02788v2 by Tilahun Abedissa Taffa, Debayan Banerjee, Yaregal Assabie, Ricardo Usbeck

Existing Scholarly Question Answering (QA) methods typically target
homogeneous data sources, relying solely on either text or Knowledge Graphs
(KGs). However, scholarly information often spans heterogeneous sources,
necessitating the development of QA systems that integrate information from
multiple heterogeneous data sources. To address this challenge, we introduce
Hybrid-SQuAD (Hybrid Scholarly Question Answering Dataset), a novel large-scale
QA dataset designed to facilitate answering questions incorporating both text
and KG facts. The dataset consists of 10.5K question-answer pairs generated by
a large language model, leveraging the KGs DBLP and SemOpenAlex alongside
corresponding text from Wikipedia. In addition, we propose a RAG-based baseline
hybrid QA model, achieving an exact match score of 69.65 on the Hybrid-SQuAD
test set.

æè¦ï¼ç¾æçå­¸è¡åé¡è§£ç­ (QA) æ¹æ³éå¸¸éå°åè³ªè³æä¾æºï¼åä¾è³´ææ¬æç¥è­åè­ (KG)ãç¶èï¼å­¸è¡è³è¨éå¸¸æ©«è·¨ç°è³ªä¾æºï¼å æ­¤æå¿è¦éç¼æ´åä¾èªå¤åç°è³ªè³æä¾æºè³è¨ç QA ç³»çµ±ãçºäºæå°æ­¤ææ°ï¼æåå¼å¥äº Hybrid-SQuADï¼æ··åå­¸è¡åé¡è§£ç­è³æéï¼ï¼éæ¯ä¸åæ°ç©çå¤§è¦æ¨¡ QA è³æéï¼æ¨å¨ä¿é²åç­åå«ææ¬å KG äºå¯¦çåé¡ãè©²è³æéåå« 10.5K ååé¡ç­æ¡å°ï¼ç±å¤§åèªè¨æ¨¡åçæï¼å©ç¨ KGs DBLP å SemOpenAlex ä»¥åä¾èªç¶­åºç¾ç§çå°æææ¬ãæ­¤å¤ï¼æåæåºäºåºæ¼ RAG çåºç·æ··å QA æ¨¡åï¼å¨ Hybrid-SQuAD æ¸¬è©¦éä¸­å¯¦ç¾äº 69.65 çå®å¨å¹éåæ¸ã

##### **Characterizing Information Shared by Participants to Coding Challenges: The Case of Advent of Code**
2412.02290v1 by Francesco Cauteruccio, Enrico Corradini, Luca Virgili

Advent of Code (AoC from now on) is a popular coding challenge requiring to
solve programming puzzles for a variety of skill sets and levels. AoC follows
the advent calendar, therefore it is an annual challenge that lasts for 25
days. AoC participants usually post their solutions on social networks and
discuss them online. These challenges are interesting to study since they could
highlight the adoption of new tools, the evolution of the developer community,
or the technological requirements of well-known companies. For these reasons,
we first create a dataset of the 2019-2021 AoC editions containing the
discussion threads made on the subreddit {\tt /r/adventofcode}. Then, we
propose a model based on stream graphs to best study this context, where we
represent its most important actors through time: participants, comments, and
programming languages. Thanks to our model, we investigate user participation,
adoption of new programming languages during a challenge and between two of
them, and resiliency of programming languages based on a Stack Overflow survey.
We find that the top-used programming languages are almost the same in the
three years, pointing out their importance. Moreover, participants tend to keep
the same programming language for the whole challenge, while the ones attending
two AoCs usually change it in the next one. Finally, we observe interesting
results about the programming languages that are ``Popular'' or ``Loved''
according to the Stack Overflow survey. Firstly, these are the ones adopted for
the longest time in an AoC edition, thanks to which users have a high chance of
reaching the end of the challenge. Secondly, they are the most chosen when a
participant decides to change programming language during the same challenge.

æè¦ï¼éè¨ç¯å¯ç¢¼ï¼ä»¥ä¸ç°¡ç¨± AoCï¼æ¯ä¸é æµè¡çç·¨ç¢¼ææ°ï¼éè¦è§£æ±ºåç¨®æè½çµåç­ç´çç¨å¼è¨­è¨è¬é¡ãAoC éµå¾ªéè¨æï¼å æ­¤æ¯ä¸é çºæ 25 å¤©çå¹´åº¦ææ°ãAoC åèèéå¸¸å¨ç¤¾ç¾¤ç¶²è·¯ä¸ç¼å¸ä»åçè§£æ±ºæ¹æ¡ï¼ä¸¦å¨ç¶²è·¯ä¸è¨è«å®åãéäºææ°å¾æè¶£ï¼å çºå®åå¯ä»¥çªé¡¯æ°å·¥å·çæ¡ç¨ãéç¼äººå¡ç¤¾ç¾¤çæ¼é²ï¼æç¥åå¬å¸çæè¡éæ±ãåºæ¼éäºåå ï¼æåé¦åå»ºç«ä¸ååå«å¨ subreddit {\tt /r/adventofcode} ä¸é²è¡è¨è«ä¸²ç 2019-2021 å¹´ AoC çæ¬è³æéãç¶å¾ï¼æåæåºä¸ååºæ¼ä¸²æµåçæ¨¡åä¾æä½³ç ç©¶æ­¤èæ¯ï¼å¶ä¸­æåé¨èæéåç¾å¶æéè¦çåèèï¼åèèãçè¨åç¨å¼èªè¨ãééæåçæ¨¡åï¼æåèª¿æ¥ä½¿ç¨èåèåº¦ãå¨ææ°æéåå©èä¹éæ¡ç¨æ°ç¨å¼èªè¨çææ³ï¼ä»¥åæ ¹æ Stack Overflow èª¿æ¥å°ç¨å¼èªè¨çå¾©ååãæåç¼ç¾ä¸å¹´ä¾æå¸¸ç¨çç¨å¼èªè¨å¹¾ä¹ç¸åï¼æåºäºå®åçéè¦æ§ãæ­¤å¤ï¼åèèå¾åæ¼å¨æ´åææ°ä¸­ä½¿ç¨ç¸åçç¨å¼èªè¨ï¼èåå å©å AoC çåèèéå¸¸æå¨ä¸ä¸å ´æ¯è³½ä¸­æ´æç¨å¼èªè¨ãæå¾ï¼æåè§å¯å°éæ¼æ ¹æ Stack Overflow èª¿æ¥è¢«æ­¸é¡çºãç±éãæãåæãçç¨å¼èªè¨çä¸äºæè¶£çµæãé¦åï¼éäºç¨å¼èªè¨æ¯ AoC çæ¬ä¸­æ¡ç¨æä¹çç¨å¼èªè¨ï¼å æ­¤ä½¿ç¨èæå¾é«çæ©æå®æææ°ãå¶æ¬¡ï¼ç¶åèèæ±ºå®å¨åä¸åææ°ä¸­æ´æ¹ç¨å¼èªè¨æï¼å®åæ¯æå¸¸è¢«é¸ç¨çç¨å¼èªè¨ã

##### **A Neurosymbolic Fast and Slow Architecture for Graph Coloring**
2412.01752v1 by Vedant Khandelwal, Vishal Pallagani, Biplav Srivastava, Francesca Rossi

Constraint Satisfaction Problems (CSPs) present significant challenges to
artificial intelligence due to their intricate constraints and the necessity
for precise solutions. Existing symbolic solvers are often slow, and prior
research has shown that Large Language Models (LLMs) alone struggle with CSPs
because of their complexity. To bridge this gap, we build upon the existing
SOFAI architecture (or SOFAI-v1), which adapts Daniel Kahneman's ''Thinking,
Fast and Slow'' cognitive model to AI. Our enhanced architecture, SOFAI-v2,
integrates refined metacognitive governance mechanisms to improve adaptability
across complex domains, specifically tailored for solving CSPs like graph
coloring. SOFAI-v2 combines a fast System 1 (S1) based on LLMs with a
deliberative System 2 (S2) governed by a metacognition module. S1's initial
solutions, often limited by non-adherence to constraints, are enhanced through
metacognitive governance, which provides targeted feedback and examples to
adapt S1 to CSP requirements. If S1 fails to solve the problem, metacognition
strategically invokes S2, ensuring accurate and reliable solutions. With
empirical results, we show that SOFAI-v2 for graph coloring problems achieves a
16.98% increased success rate and is 32.42% faster than symbolic solvers.

æè¦ï¼ç´ææ»¿è¶³åé¡ (CSP) å çºå¶è¤éçç´æåå°ç²¾ç¢ºè§£çå¿è¦æ§ï¼å°äººå·¥æºæ§æåºäºéå¤§çææ°ãç¾æçç¬¦èæ±è§£å¨éå¸¸å¾æ¢ï¼èååçç ç©¶è¡¨æï¼å¤§åèªè¨æ¨¡å (LLM) å çºå¶è¤éæ§èç¡æ³å®ç¨èç CSPãçºäºå½è£éåå·®è·ï¼æåå»ºç«å¨ç¾æç SOFAI æ¶æ§ï¼æ SOFAI-v1ï¼ä¹ä¸ï¼å®å° Daniel Kahneman çãå¿«ææ¢æ³ãèªç¥æ¨¡åèª¿æ´çº AIãæåå¢å¼·çæ¶æ§ SOFAI-v2 æ´åäºç²¾ç·»çåèªç¥æ²»çæ©å¶ï¼ä»¥æé«è·¨è¤éé åçé©ææ§ï¼ç¹å¥æ¯éå°è§£æ±ºåå½¢èè²ç­ CSP èéèº«æé ãSOFAI-v2 çµåäºåºæ¼ LLM çå¿«éç³»çµ± 1 (S1) åç±åèªç¥æ¨¡çµç®¡æ§çå¯©æç³»çµ± 2 (S2)ãS1 çåå§è§£æ³éå¸¸åå°ä¸éµå®ç´æçéå¶ï¼ééåèªç¥æ²»çå¾ä»¥å¢å¼·ï¼æä¾æéå°æ§çåé¥åç¯ä¾ï¼ä»¥é©æ S1 ç CSP éæ±ãå¦æ S1 ç¡æ³è§£æ±ºåé¡ï¼åèªç¥æç­ç¥æ§å°å¼å« S2ï¼ç¢ºä¿æºç¢ºä¸å¯é çè§£æ³ãééç¶é©çµæï¼æåå±ç¤ºäºç¨æ¼åå½¢èè²åé¡ç SOFAI-v2 éå°äºæåçæé« 16.98%ï¼ä¸¦ä¸æ¯ç¬¦èæ±è§£å¨å¿« 32.42%ã

##### **Intelligent Spark Agents: A Modular LangGraph Framework for Scalable, Visualized, and Enhanced Big Data Machine Learning Workflows**
2412.01490v4 by Jialin Wang, Zhihua Duan

This paper presents a Spark-based modular LangGraph framework, designed to
enhance machine learning workflows through scalability, visualization, and
intelligent process optimization. At its core, the framework introduces Agent
AI, a pivotal innovation that leverages Spark's distributed computing
capabilities and integrates with LangGraph for workflow orchestration.
  Agent AI facilitates the automation of data preprocessing, feature
engineering, and model evaluation while dynamically interacting with data
through Spark SQL and DataFrame agents. Through LangGraph's graph-structured
workflows, the agents execute complex tasks, adapt to new inputs, and provide
real-time feedback, ensuring seamless decision-making and execution in
distributed environments. This system simplifies machine learning processes by
allowing users to visually design workflows, which are then converted into
Spark-compatible code for high-performance execution.
  The framework also incorporates large language models through the LangChain
ecosystem, enhancing interaction with unstructured data and enabling advanced
data analysis. Experimental evaluations demonstrate significant improvements in
process efficiency and scalability, as well as accurate data-driven
decision-making in diverse application scenarios.
  This paper emphasizes the integration of Spark with intelligent agents and
graph-based workflows to redefine the development and execution of machine
learning tasks in big data environments, paving the way for scalable and
user-friendly AI solutions.

æè¦ï¼<paragraph>æ¬ææåºäºä¸ååºæ¼ Spark çæ¨¡çµå LangGraph æ¡æ¶ï¼æ¨å¨ééå¯æ´åæ§ãå¯è¦ååæºæ§æµç¨æä½³åä¾æåæ©å¨å­¸ç¿å·¥ä½æµç¨ãå¨æ ¸å¿é¨åï¼æ­¤æ¡æ¶å¼å¥äº Agent AIï¼éé ééµåµæ°å©ç¨äº Spark çåæ£å¼éç®è½åï¼ä¸¦è LangGraph æ´åä»¥é²è¡å·¥ä½æµç¨ç·¨æã
  Agent AI ä¿é²äºè³æåèçãç¹å¾µå·¥ç¨åæ¨¡åè©ä¼°çèªååï¼åæéé Spark SQL å DataFrame ä»£çèè³æåæäºåãéé LangGraph çåå½¢çµæ§å·¥ä½æµç¨ï¼éäºä»£çå·è¡è¤éçä»»åãé©ææ°çè¼¸å¥ï¼ä¸¦æä¾å³æåé¥ï¼ç¢ºä¿å¨åæ£å¼ç°å¢ä¸­é²è¡ç¡ç¸«æ±ºç­å¶å®åå·è¡ãæ­¤ç³»çµ±ééåè¨±ä½¿ç¨èè¦è¦ºåè¨­è¨å·¥ä½æµç¨ï¼å¶å¾è½æçºç¸å®¹æ¼ Spark çç¨å¼ç¢¼ä»¥é²è¡é«æ§è½å·è¡ï¼ä¾ç°¡åæ©å¨å­¸ç¿æµç¨ã
  æ­¤æ¡æ¶ä¹éé LangChain çæç³»æ´åäºå¤§åèªè¨æ¨¡åï¼å¢å¼·äºèéçµæ§åè³æçäºåï¼ä¸¦åç¨äºé²éè³æåæãå¯¦é©è©ä¼°é¡¯ç¤ºï¼æµç¨æçåå¯æ´åæ§æé¡¯èæ¹åï¼èä¸å¨ä¸åçæç¨æå¢ä¸­é²è¡äºç²¾ç¢ºçè³æé©åæ±ºç­å¶å®ã
  æ¬æå¼·èª¿äº Spark èæºæ§ä»£çååºæ¼åå½¢çå·¥ä½æµç¨çæ´åï¼ä»¥éæ°å®ç¾©å¤§è³æç°å¢ä¸­æ©å¨å­¸ç¿ä»»åçéç¼åå·è¡ï¼çºå¯æ´åä¸ä½¿ç¨èååç AI è§£å³æ¹æ¡éªè·¯ã</paragraph>

##### **SelfPrompt: Autonomously Evaluating LLM Robustness via Domain-Constrained Knowledge Guidelines and Refined Adversarial Prompts**
2412.00765v1 by Aihua Pei, Zehua Yang, Shunan Zhu, Ruoxi Cheng, Ju Jia

Traditional methods for evaluating the robustness of large language models
(LLMs) often rely on standardized benchmarks, which can escalate costs and
limit evaluations across varied domains. This paper introduces a novel
framework designed to autonomously evaluate the robustness of LLMs by
incorporating refined adversarial prompts and domain-constrained knowledge
guidelines in the form of knowledge graphs. Our method systematically generates
descriptive sentences from domain-constrained knowledge graph triplets to
formulate adversarial prompts, enhancing the relevance and challenge of the
evaluation. These prompts, generated by the LLM itself and tailored to evaluate
its own robustness, undergo a rigorous filtering and refinement process,
ensuring that only those with high textual fluency and semantic fidelity are
used. This self-evaluation mechanism allows the LLM to evaluate its robustness
without the need for external benchmarks. We assess the effectiveness of our
framework through extensive testing on both proprietary models like ChatGPT and
open-source models such as Llama-3.1, Phi-3, and Mistral. Results confirm that
our approach not only reduces dependency on conventional data but also provides
a targeted and efficient means of evaluating LLM robustness in constrained
domains.

æè¦ï¼å³çµ±ç¨æ¼è©ä¼°å¤§åèªè¨æ¨¡å (LLM) ç©©å¥æ§çæ¹æ³éå¸¸ä¾è³´æ¨æºååºæºï¼éå¯è½æå¢å ææ¬ä¸¦éå¶è·¨ä¸åé åçè©ä¼°ãæ¬æä»ç´¹äºä¸åæ°ç©çæ¡æ¶ï¼æ¨å¨ééå¨ç¥è­åè­çå½¢å¼ä¸­ç´å¥ç²¾ç·»çå°ææç¤ºåé åç´æç¥è­æºåï¼ä¾èªä¸»è©ä¼° LLM çç©©å¥æ§ãæåçåæ³æ¯ç³»çµ±æ§å°å¾é åç´æç¥è­åè­ä¸åçµä¸­ç¢çæè¿°æ§å¥å­ï¼ä»¥å¶å®å°ææç¤ºï¼å¢å¼·è©ä¼°çç¸éæ§åææ°æ§ãéäºæç¤ºæ¯ç± LLM æ¬èº«ç¢çï¼ä¸¦éå°è©ä¼°å¶èªèº«çç©©å¥æ§èéèº«æé ï¼å®åæç¶æ­·å´æ ¼çéæ¿¾åç²¾çéç¨ï¼ç¢ºä¿åªæé£äºå·æé«åº¦ææ¬æµæ¢æ§åèªç¾©ä¿çæ§çæç¤ºææè¢«ä½¿ç¨ãéç¨®èªæè©ä¼°æ©å¶åè¨± LLM å¨ä¸éè¦å¤é¨åºæºçææ³ä¸è©ä¼°å¶ç©©å¥æ§ãæåééå°å°ææ¨¡åï¼ä¾å¦ ChatGPTï¼åéæºæ¨¡åï¼ä¾å¦ Llama-3.1ãPhi-3 å Mistralï¼é²è¡å»£æ³æ¸¬è©¦ï¼è©ä¼°æåæ¡æ¶çæææ§ãçµæè­å¯¦ï¼æåçåæ³ä¸åæ¸å°äºå°å³çµ±è³æçä¾è³´æ§ï¼éæä¾äºä¸ç¨®æéå°æ§åææçæ¹æ³ï¼å¯ä»¥å¨åéé åä¸­è©ä¼° LLM çç©©å¥æ§ã

##### **Leveraging LLM for Automated Ontology Extraction and Knowledge Graph Generation**
2412.00608v2 by Mohammad Sadeq Abolhasani, Rong Pan

Extracting relevant and structured knowledge from large, complex technical
documents within the Reliability and Maintainability (RAM) domain is
labor-intensive and prone to errors. Our work addresses this challenge by
presenting OntoKGen, a genuine pipeline for ontology extraction and Knowledge
Graph (KG) generation. OntoKGen leverages Large Language Models (LLMs) through
an interactive user interface guided by our adaptive iterative Chain of Thought
(CoT) algorithm to ensure that the ontology extraction process and, thus, KG
generation align with user-specific requirements. Although KG generation
follows a clear, structured path based on the confirmed ontology, there is no
universally correct ontology as it is inherently based on the user's
preferences. OntoKGen recommends an ontology grounded in best practices,
minimizing user effort and providing valuable insights that may have been
overlooked, all while giving the user complete control over the final ontology.
Having generated the KG based on the confirmed ontology, OntoKGen enables
seamless integration into schemeless, non-relational databases like Neo4j. This
integration allows for flexible storage and retrieval of knowledge from
diverse, unstructured sources, facilitating advanced querying, analysis, and
decision-making. Moreover, the generated KG serves as a robust foundation for
future integration into Retrieval Augmented Generation (RAG) systems, offering
enhanced capabilities for developing domain-specific intelligent applications.

æè¦ï¼å¾å¯é åº¦åå¯ç¶­è­·æ§ (RAM) é åä¸­å¤§éè¤éçæè¡æä»¶èåç¸éä¸çµæ§åçç¥è­ï¼æ¯ä¸é ååå¯éä¸å®¹æåºé¯çä»»åãæåçç ç©¶ééæä¾ OntoKGen ä¾è§£æ±ºéåææ°ï¼éæ¯ä¸åçæ­£çæ¬ä½èååç¥è­åè­ (KG) çæç®¡ç·ãOntoKGen ééä¸åäºåå¼ä½¿ç¨èä»é¢ï¼å©ç¨å¤§åèªè¨æ¨¡å (LLM) ä¸¦ç±æåèªé©æçè¿­ä»£æèé (CoT) æ¼ç®æ³å¼å°ï¼ä»¥ç¢ºä¿æ¬ä½èåéç¨ï¼ä»¥åé¨ä¹èä¾ç KG çæï¼ç¬¦åä½¿ç¨èç¹å®çéæ±ãéç¶ KG çæéµå¾ªä¸åæç¢ºççµæ§åè·¯å¾ï¼åºæ¼å·²ç¢ºèªçæ¬ä½ï¼ä½ä¸¦æ²æä¸åæ®éæ­£ç¢ºçæ¬ä½ï¼å çºå®æ¬è³ªä¸æ¯åºæ¼ä½¿ç¨èçåå¥½ãOntoKGen å»ºè­°ä¸ååºæ¼æä½³å¯¦åçæ¬ä½ï¼å°ä½¿ç¨èçå·¥ä½ééå°æä½ï¼ä¸¦æä¾æå¹å¼çè¦è§£ï¼éäºè¦è§£å¯è½æ¯è¢«å¿½ç¥çï¼åæè®ä½¿ç¨èå®å¨æ§å¶æçµçæ¬ä½ãå¨åºæ¼å·²ç¢ºèªçæ¬ä½ç¢ç KG ä¹å¾ï¼OntoKGen è½å¤ ç¡ç¸«æ´åå°ç¡æ¨¡å¼ãééè¯å¼è³æåº«ï¼ä¾å¦ Neo4jãéåæ´ååè¨±å¾åç¨®éçµæ§åä¾æºéæ´»å°å²å­åæª¢ç´¢ç¥è­ï¼ä¿é²é²éæ¥è©¢ãåæåæ±ºç­å¶å®ãæ­¤å¤ï¼çæç KG å¯ä½çºæªä¾æ´åå°æª¢ç´¢å¢å¼·çæ (RAG) ç³»çµ±çç©©åºåºç¤ï¼æä¾éç¼ç¹å®é åæºæ§åæç¨ç¨å¼çå¢å¼·åè½ã

##### **Opus: A Large Work Model for Complex Workflow Generation**
2412.00573v2 by ThÃ©o Fagnoni, Bellinda Mesbah, Mahsun Altin, Phillip Kingston

This paper introduces Opus, a novel framework for generating and optimizing
Workflows tailored to complex Business Process Outsourcing (BPO) use cases,
focusing on cost reduction and quality enhancement while adhering to
established industry processes and operational constraints. Our approach
generates executable Workflows from Intention, defined as the alignment of
Client Input, Client Output, and Process Context. These Workflows are
represented as Directed Acyclic Graphs (DAGs), with nodes as Tasks consisting
of sequences of executable Instructions, including tools and human expert
reviews. We adopt a two-phase methodology: Workflow Generation and Workflow
Optimization. In the Generation phase, Workflows are generated using a Large
Work Model (LWM) informed by a Work Knowledge Graph (WKG) that encodes
domain-specific procedural and operational knowledge. In the Optimization
phase, Workflows are transformed into Workflow Graphs (WFGs), where optimal
Workflows are determined through path optimization. Our experiments demonstrate
that state-of-the-art Large Language Models (LLMs) face challenges in reliably
retrieving detailed process data as well as generating industry-compliant
workflows. The key contributions of this paper include integrating a Work
Knowledge Graph (WKG) into a Large Work Model (LWM) to enable the generation of
context-aware, semantically aligned, structured and auditable Workflows. It
further introduces a two-phase approach that combines Workflow Generation from
Intention with graph-based Workflow Optimization. Finally, we present Opus
Alpha 1 Large and Opus Alpha 1 Small that outperform state-of-the-art LLMs by
38% and 29% respectively in Workflow Generation for a Medical Coding use case.

æè¦ï¼éç¯è«æä»ç´¹äº Opusï¼ä¸åç¨æ¼ç¢çåæä½³åå·¥ä½æµç¨çæ°ç©æ¶æ§ï¼å°çºè¤éçæ¥­åæµç¨å¤å (BPO) ä½¿ç¨æ¡ä¾éèº«æé ï¼éé»å¨æ¼éä½ææ¬åæååè³ªï¼åæéµå®æ¢å®çç¢æ¥­æµç¨åçééå¶ãæåçåæ³æ ¹ææåç¢çå¯å·è¡çå·¥ä½æµç¨ï¼æåå®ç¾©çºå®¢æ¶è¼¸å¥ãå®¢æ¶è¼¸åºåæµç¨èæ¯çå°é½ãéäºå·¥ä½æµç¨è¡¨ç¤ºçºæåç¡ç°å (DAG)ï¼ç¯é»çºåå«å¯å·è¡æä»¤åºåçä»»åï¼åæ¬å·¥å·åäººé¡å°å®¶çå¯©æ¥ãæåæ¡ç¨å©éæ®µæ¹æ³ï¼å·¥ä½æµç¨ç¢çåå·¥ä½æµç¨æä½³åãå¨ç¢çéæ®µï¼å·¥ä½æµç¨ä½¿ç¨å¤§åå·¥ä½æ¨¡å (LWM) ç¢çï¼è©²æ¨¡åç±ç·¨ç¢¼ç¹å®é åç¨åºåéä½ç¥è­çå·¥ä½ç¥è­å (WKG) æä¾è³è¨ãå¨æä½³åéæ®µï¼å·¥ä½æµç¨è½æçºå·¥ä½æµç¨å (WFG)ï¼å¶ä¸­ééè·¯å¾æä½³åä¾ç¢ºå®æä½³å·¥ä½æµç¨ãæåçå¯¦é©è¡¨æï¼æåé²çå¤§åèªè¨æ¨¡å (LLM) å¨å¯é å°æ·åè©³ç´°çæµç¨è³æä»¥åç¢çç¬¦åç¢æ¥­è¦ç¯çå·¥ä½æµç¨æ¹é¢é¢è¨ææ°ãéç¯è«æçä¸»è¦è²¢ç»åæ¬å°å·¥ä½ç¥è­å (WKG) æ´åå°å¤§åå·¥ä½æ¨¡å (LWM) ä¸­ï¼ä»¥ç¢çå·åæå¢æç¥ãèªç¾©å°é½ãçµæ§ååå¯ç¨½æ ¸çå·¥ä½æµç¨ãå®é²ä¸æ­¥ä»ç´¹äºä¸ç¨®å©éæ®µæ¹æ³ï¼å°åºæ¼æåçå·¥ä½æµç¨ç¢çèåºæ¼åå½¢çå·¥ä½æµç¨æä½³åç¸çµåãæå¾ï¼æåå±ç¤ºäº Opus Alpha 1 Large å Opus Alpha 1 Smallï¼å®åå¨é«çç·¨ç¢¼ä½¿ç¨æ¡ä¾ä¸­åå¥æ¯æåé²ç LLM å¨å·¥ä½æµç¨ç¢çæ¹é¢é«åº 38% å 29%ã

##### **Node Importance Estimation Leveraging LLMs for Semantic Augmentation in Knowledge Graphs**
2412.00478v1 by Xinyu Lin, Tianyu Zhang, Chengbin Hou, Jinbao Wang, Jianye Xue, Hairong Lv

Node Importance Estimation (NIE) is a task that quantifies the importance of
node in a graph. Recent research has investigated to exploit various
information from Knowledge Graphs (KGs) to estimate node importance scores.
However, the semantic information in KGs could be insufficient, missing, and
inaccurate, which would limit the performance of existing NIE models. To
address these issues, we leverage Large Language Models (LLMs) for semantic
augmentation thanks to the LLMs' extra knowledge and ability of integrating
knowledge from both LLMs and KGs. To this end, we propose the LLMs Empowered
Node Importance Estimation (LENIE) method to enhance the semantic information
in KGs for better supporting NIE tasks. To our best knowledge, this is the
first work incorporating LLMs into NIE. Specifically, LENIE employs a novel
clustering-based triplet sampling strategy to extract diverse knowledge of a
node sampled from the given KG. After that, LENIE adopts the node-specific
adaptive prompts to integrate the sampled triplets and the original node
descriptions, which are then fed into LLMs for generating richer and more
precise augmented node descriptions. These augmented descriptions finally
initialize node embeddings for boosting the downstream NIE model performance.
Extensive experiments demonstrate LENIE's effectiveness in addressing semantic
deficiencies in KGs, enabling more informative semantic augmentation and
enhancing existing NIE models to achieve the state-of-the-art performance. The
source code of LENIE is freely available at
\url{https://github.com/XinyuLin-FZ/LENIE}.

æè¦ï¼ç¯é»éè¦æ§ä¼°è¨ (NIE) æ¯ä¸é éååä¸­ç¯é»éè¦æ§çä»»åãæè¿çç ç©¶å·²èª¿æ¥å©ç¨ç¥è­åè­ (KG) ä¸­çåç¨®è³è¨ä¾ä¼°è¨ç¯é»éè¦æ§åæ¸ãç¶èï¼KG ä¸­çèªç¾©è³è¨å¯è½ä¸è¶³ãéºå¤±ä¸ä¸æºç¢ºï¼éå°éå¶ç¾æ NIE æ¨¡åçæè½ãçºäºè§£æ±ºéäºåé¡ï¼æåå©ç¨å¤§åèªè¨æ¨¡å (LLM) é²è¡èªç¾©å¢å¼·ï¼éè¦æ­¸åæ¼ LLM çé¡å¤ç¥è­åæ´å LLM å KG ä¸­ç¥è­çè½åãçºæ­¤ï¼æåæåº LLM å¼·åç¯é»éè¦æ§ä¼°è¨ (LENIE) æ¹æ³ï¼ä»¥å¢å¼· KG ä¸­çèªç¾©è³è¨ï¼ä»¥ä¾¿æ´å¥½å°æ¯æ´ NIE ä»»åãææåæç¥ï¼éæ¯å° LLM ç´å¥ NIE çç¬¬ä¸é å·¥ä½ãå·é«ä¾èªªï¼LENIE æ¡ç¨æ°ç©çåºæ¼ç¾¤éçä¸åçµåæ¨£ç­ç¥ï¼ä»¥èåå¾çµ¦å® KG åæ¨£çç¯é»çå¤åç¥è­ãå¨é£ä¹å¾ï¼LENIE æ¡ç¨ç¹å®æ¼ç¯é»çèªé©ææç¤ºï¼ä»¥æ´ååæ¨£çä¸åçµååå§ç¯é»æè¿°ï¼ç¶å¾å°å®åè¼¸å¥ LLM ä»¥ç¢çæ´è±å¯ä¸æ´ç²¾ç¢ºçå¢å¼·ç¯é»æè¿°ãéäºå¢å¼·çæè¿°æçµåå§åç¯é»åµå¥ï¼ä»¥æåä¸æ¸¸ NIE æ¨¡åæè½ãå»£æ³çå¯¦é©è­æäº LENIE å¨è§£æ±º KG ä¸­çèªç¾©ç¼ºé·æ¹é¢çæææ§ï¼å¯¦ç¾æ´å¤è³è¨æ§çèªç¾©å¢å¼·ï¼ä¸¦å¢å¼·ç¾æç NIE æ¨¡åä»¥éææåé²çæè½ãLENIE çåå§ç¨å¼ç¢¼å¯æ¼\url{https://github.com/XinyuLin-FZ/LENIE} åè²»åå¾ã

##### **An AI-Driven Data Mesh Architecture Enhancing Decision-Making in Infrastructure Construction and Public Procurement**
2412.00224v1 by Saurabh Mishra, Mahendra Shinde, Aniket Yadav, Bilal Ayyub, Anand Rao

Infrastructure construction, often dubbed an "industry of industries," is
closely linked with government spending and public procurement, offering
significant opportunities for improved efficiency and productivity through
better transparency and information access. By leveraging these opportunities,
we can achieve notable gains in productivity, cost savings, and broader
economic benefits. Our approach introduces an integrated software ecosystem
utilizing Data Mesh and Service Mesh architectures. This system includes the
largest training dataset for infrastructure and procurement, encompassing over
100 billion tokens, scientific publications, activities, and risk data, all
structured by a systematic AI framework. Supported by a Knowledge Graph linked
to domain-specific multi-agent tasks and Q&A capabilities, our platform
standardizes and ingests diverse data sources, transforming them into
structured knowledge. Leveraging large language models (LLMs) and automation,
our system revolutionizes data structuring and knowledge creation, aiding
decision-making in early-stage project planning, detailed research, market
trend analysis, and qualitative assessments. Its web-scalable architecture
delivers domain-curated information, enabling AI agents to facilitate reasoning
and manage uncertainties, while preparing for future expansions with
specialized agents targeting particular challenges. This integration of AI with
domain expertise not only boosts efficiency and decision-making in construction
and infrastructure but also establishes a framework for enhancing government
efficiency and accelerating the transition of traditional industries to digital
workflows. This work is poised to significantly influence AI-driven initiatives
in this sector and guide best practices in AI Operations.

æè¦ï¼åºç¤å»ºè¨­å»ºè¨­ï¼å¸¸è¢«ç¨±çºãç¢æ¥­ä¸­çç¢æ¥­ãï¼èæ¿åºæ¯åºåå¬å±æ¡è³¼æ¯æ¯ç¸éï¼ééæåéæåº¦åè³è¨åå¾ï¼è½å¤§å¹æåæçåçç¢åãééåç¨éäºæ©æï¼æåè½å¨çç¢åãææ¬ç¯çåæ´å»£æ³çç¶æ¿æçä¸ç²å¾é¡¯èçæ¶çãæåçåæ³å¼é²ä¸åæ´åå¼è»é«çæç³»ï¼å©ç¨è³æç¶²æ ¼åæåç¶²æ ¼æ¶æ§ãéåç³»çµ±åå«åºç¤å»ºè¨­åæ¡è³¼æå¤§çè¨ç·´è³æéï¼æ¶µèè¶é 1000 ååç¬¦èãç§å­¸åºçåãæ´»ååé¢¨éªè³æï¼ææè³æé½ä»¥ç³»çµ±åç AI æ¶æ§é²è¡çµæ§åãæåçå¹³å°ç±é£çµå°ç¹å®é åçå¤éä»£çäººä»»åååç­åè½çç¥è­åè­æä¾æ¯æ´ï¼æ¨æºåä¸¦å¯å¥ä¸åçè³æä¾æºï¼å°å¶è½æçºçµæ§åçç¥è­ãæåçç³»çµ±å©ç¨å¤§èªè¨æ¨¡å (LLM) åèªååï¼å¾¹åºæ¹é©è³æçµæ§ååç¥è­å»ºç«ï¼åå©å¨æ©æéæ®µçå°æ¡è¦åãè©³ç´°ç ç©¶ãå¸å ´è¶¨å¢åæåå®æ§è©ä¼°ä¸­é²è¡æ±ºç­å¶å®ãå¶å¯æ´åè³ç¶²è·¯è¦æ¨¡çæ¶æ§æä¾é åç­å±çè³è¨ï¼è® AI ä»£çäººè½å¤ ä¿é²æ¨çåç®¡çä¸ç¢ºå®æ§ï¼åææºåå¥½ä»¥å°éä»£çäººå æç¹å®ææ°ï¼é²è¡æªä¾çæ´åãéç¨®å° AI èé åå°æ¥­ç¥è­æ´åçæ¹å¼ï¼ä¸åæåå»ºè¨­ååºç¤å»ºè¨­çæçåæ±ºç­å¶å®ï¼ä¹å»ºç«äºä¸åæ¶æ§ï¼ä»¥æåæ¿åºæçä¸¦å éå³çµ±ç¢æ¥­è½åè³æ¸ä½å·¥ä½æµç¨ãéé å·¥ä½æºåå°éåé¨éç AI é©åè¨ç«ç¢çéå¤§å½±é¿ï¼ä¸¦å¼å° AI ä½æ¥­çæä½³å¯¦åã

##### **PerLA: Perceptive 3D Language Assistant**
2411.19774v1 by Guofeng Mei, Wei Lin, Luigi Riz, Yujiao Wu, Fabio Poiesi, Yiming Wang

Enabling Large Language Models (LLMs) to understand the 3D physical world is
an emerging yet challenging research direction. Current strategies for
processing point clouds typically downsample the scene or divide it into
smaller parts for separate analysis. However, both approaches risk losing key
local details or global contextual information. In this paper, we introduce
PerLA, a 3D language assistant designed to be more perceptive to both details
and context, making visual representations more informative for the LLM. PerLA
captures high-resolution (local) details in parallel from different point cloud
areas and integrates them with (global) context obtained from a
lower-resolution whole point cloud. We present a novel algorithm that preserves
point cloud locality through the Hilbert curve and effectively aggregates
local-to-global information via cross-attention and a graph neural network.
Lastly, we introduce a novel loss for local representation consensus to promote
training stability. PerLA outperforms state-of-the-art 3D language assistants,
with gains of up to +1.34 CiDEr on ScanQA for question answering, and +4.22 on
ScanRefer and +3.88 on Nr3D for dense
captioning.\url{https://gfmei.github.io/PerLA/}

æè¦ï¼è®å¤§åèªè¨æ¨¡å (LLM) çè§£ 3D ç©çä¸çæ¯ä¸åæ°èä½å·æææ°æ§çç ç©¶æ¹åãç¶åèçé»é²çç­ç¥éå¸¸æå°å ´æ¯é²è¡éæ¡æ¨£æå°å¶åçºæ´å°çé¨åä»¥é²è¡å®ç¨åæãç¶èï¼éå©ç¨®æ¹æ³é½æå¯è½éºå¤±ééµçå±é¨ç´°ç¯æå¨å±èæ¯è³è¨ãå¨æ¬æä¸­ï¼æåä»ç´¹äº PerLAï¼éæ¯ä¸å 3D èªè¨å©çï¼æ¨å¨æ´æé³å°æç¥ç´°ç¯åèæ¯ï¼è®è¦è¦ºè¡¨ç¾å° LLM æ´æè³è¨æ§ãPerLA å¾ä¸åçé»é²ååä¸¦è¡æ·åé«è§£æåº¦ï¼å±é¨ï¼ç´°ç¯ï¼ä¸¦å°å¶èå¾ä½è§£æåº¦å¨é»é²ä¸­ç²å¾çï¼å¨å±ï¼èæ¯æ´åå¨ä¸èµ·ãæåæåºäºä¸ç¨®æ°æ¼ç®æ³ï¼ééå¸ç¾ä¼¯ç¹æ²ç·ä¿çé»é²å±é¨æ§ï¼ä¸¦ééäº¤åæ³¨æåååå½¢ç¥ç¶ç¶²è·¯ææå°å¯ç¸½å±é¨å°å¨å±è³è¨ãæå¾ï¼æåå¼å¥äºä¸åæ°çæå¤±å½æ¸ï¼ç¨æ¼å±é¨è¡¨ç¤ºå±è­ï¼ä»¥ä¿é²è¨ç·´ç©©å®æ§ãPerLA åªæ¼æåé²ç 3D èªè¨å©çï¼å¨ ScanQA ä¸åç­ç²å¾é«é +1.34 CiDEr çå¢çï¼å¨ ScanRefer ä¸ç²å¾ +4.22ï¼å¨ Nr3D ä¸ç²å¾ +3.88 çå¯éæ¨é¡ã\url{https://gfmei.github.io/PerLA/}

##### **Knowledge Management for Automobile Failure Analysis Using Graph RAG**
2411.19539v1 by Yuta Ojima, Hiroki Sakaji, Tadashi Nakamura, Hiroaki Sakata, Kazuya Seki, Yuu Teshigawara, Masami Yamashita, Kazuhiro Aoyama

This paper presents a knowledge management system for automobile failure
analysis using retrieval-augmented generation (RAG) with large language models
(LLMs) and knowledge graphs (KGs). In the automotive industry, there is a
growing demand for knowledge transfer of failure analysis from experienced
engineers to young engineers. However, failure events are phenomena that occur
in a chain reaction, making them difficult for beginners to analyze them. While
knowledge graphs, which can describe semantic relationships and structure
information is effective in representing failure events, due to their
capability of representing the relationships between components, there is much
information in KGs, so it is challenging for young engineers to extract and
understand sub-graphs from the KG. On the other hand, there is increasing
interest in the use of Graph RAG, a type of RAG that combines LLMs and KGs for
knowledge management. However, when using the current Graph RAG framework with
an existing knowledge graph for automobile failures, several issues arise
because it is difficult to generate executable queries for a knowledge graph
database which is not constructed by LLMs. To address this, we focused on
optimizing the Graph RAG pipeline for existing knowledge graphs. Using an
original Q&A dataset, the ROUGE F1 score of the sentences generated by the
proposed method showed an average improvement of 157.6% compared to the current
method. This highlights the effectiveness of the proposed method for automobile
failure analysis.

æè¦ï¼æ¬ææåºäºä¸åä½¿ç¨æª¢ç´¢å¢å¼·çæï¼RAGï¼åå¤§åèªè¨æ¨¡åï¼LLMï¼åç¥è­åè­ï¼KGï¼çæ±½è»æéåæç¥è­ç®¡çç³»çµ±ãå¨æ±½è»ç¢æ¥­ä¸­ï¼æè¶ä¾è¶å¤çéæ±ï¼å°æéåæç¥è­å¾ç¶é©è±å¯çå·¥ç¨å¸«å³æçµ¦å¹´è¼çå·¥ç¨å¸«ãç¶èï¼æéäºä»¶æ¯ä¸ç¨®é£éåæä¸­ç¼ççç¾è±¡ï¼éä½¿å¾åå­¸èé£ä»¥åæå®åãåç®¡ç¥è­åè­å¯ä»¥æè¿°èªç¾©éä¿åçµæ§åè³è¨ï¼ä¸¦ææå°è¡¨ç¤ºæéäºä»¶ï¼ç±æ¼å®åæè¡¨ç¤ºåä»¶ä¹ééä¿çè½åï¼KG ä¸­æè¨±å¤è³è¨ï¼å æ­¤å¹´è¼çå·¥ç¨å¸«å¾é£å¾ KG ä¸­æååçè§£å­åãå¦ä¸æ¹é¢ï¼äººåè¶ä¾è¶æèè¶£ä½¿ç¨ Graph RAGï¼éæ¯ä¸ç¨®çµå LLM å KG é²è¡ç¥è­ç®¡çç RAGãç¶èï¼ç¶å°ç®åç Graph RAG æ¡æ¶èç¾æçæ±½è»æéç¥è­åè­ä¸èµ·ä½¿ç¨æï¼æåºç¾å¹¾ååé¡ï¼å çºé£ä»¥çæéå°é LLM æ§å»ºçç¥è­åè­è³æåº«çå¯å·è¡æ¥è©¢ãçºäºè§£æ±ºéååé¡ï¼æåå°æ³¨æ¼éå°ç¾æç¥è­åè­æä½³å Graph RAG ç®¡éãä½¿ç¨åå§åç­è³æéï¼ææåºæ¹æ³çæçå¥å­ç ROUGE F1 åæ¸èç®åæ¹æ³ç¸æ¯ï¼å¹³åæåäº 157.6%ãéçªé¡¯äºææåºæ¹æ³å°æ¼æ±½è»æéåæçæææ§ã

##### **Way to Specialist: Closing Loop Between Specialized LLM and Evolving Domain Knowledge Graph**
2411.19064v1 by Yutong Zhang, Lixing Chen, Shenghong Li, Nan Cao, Yang Shi, Jiaxin Ding, Zhe Qu, Pan Zhou, Yang Bai

Large language models (LLMs) have demonstrated exceptional performance across
a wide variety of domains. Nonetheless, generalist LLMs continue to fall short
in reasoning tasks necessitating specialized knowledge. Prior investigations
into specialized LLMs focused on domain-specific training, which entails
substantial efforts in domain data acquisition and model parameter fine-tuning.
To address these challenges, this paper proposes the Way-to-Specialist (WTS)
framework, which synergizes retrieval-augmented generation with knowledge
graphs (KGs) to enhance the specialized capability of LLMs in the absence of
specialized training. In distinction to existing paradigms that merely utilize
external knowledge from general KGs or static domain KGs to prompt LLM for
enhanced domain-specific reasoning, WTS proposes an innovative
"LLM$\circlearrowright$KG" paradigm, which achieves bidirectional enhancement
between specialized LLM and domain knowledge graph (DKG). The proposed paradigm
encompasses two closely coupled components: the DKG-Augmented LLM and the
LLM-Assisted DKG Evolution. The former retrieves question-relevant domain
knowledge from DKG and uses it to prompt LLM to enhance the reasoning
capability for domain-specific tasks; the latter leverages LLM to generate new
domain knowledge from processed tasks and use it to evolve DKG. WTS closes the
loop between DKG-Augmented LLM and LLM-Assisted DKG Evolution, enabling
continuous improvement in the domain specialization as it progressively answers
and learns from domain-specific questions. We validate the performance of WTS
on 6 datasets spanning 5 domains. The experimental results show that WTS
surpasses the previous SOTA in 4 specialized domains and achieves a maximum
performance improvement of 11.3%.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²å¨ååé åå±ç¾åºåªç°çè¡¨ç¾ãç¶èï¼éæ LLM å¨éè¦å°æ¥­ç¥è­çæ¨çä»»åä¸­ä»è¡¨ç¾ä¸ä½³ãååå°å°æ¥­ LLM çç ç©¶éä¸­å¨ç¹å®é åè¨ç·´ï¼ééè¦å¤§éé åè³æåå¾åæ¨¡ååæ¸å¾®èª¿ãçºäºæå°éäºææ°ï¼æ¬ææåº Way-to-Specialist (WTS) æ¶æ§ï¼å®å°æª¢ç´¢å¢å¼·çæèç¥è­åè­ (KG) çµåèµ·ä¾ï¼ä»¥æå LLM å¨æ²æå°æ¥­è¨ç·´ææ³ä¸çå°æ¥­è½åãèåå©ç¨ä¾èªä¸è¬ KG æéæé å KG çå¤é¨ç¥è­æç¤º LLM ä»¥å¢å¼·ç¹å®é åæ¨ççæ¢æç¯ä¾ä¸åï¼WTS æåºä¸ååµæ°çãLLM$\circlearrowright$KGãç¯ä¾ï¼å®å¨å°æ¥­ LLM åé åç¥è­åè­ (DKG) ä¹éå¯¦ç¾éåå¢å¼·ãææåºçç¯ä¾åå«å©åç·å¯çµåççµæé¨åï¼DKG å¢å¼· LLM å LLM è¼å© DKG æ¼åãåèå¾ DKG ä¸­æª¢ç´¢èåé¡ç¸éçé åç¥è­ï¼ä¸¦ä½¿ç¨å®æç¤º LLM ä»¥å¢å¼·ç¹å®é åä»»åçæ¨çè½åï¼å¾èå©ç¨ LLM å¾èçéçä»»åä¸­ç¢çæ°çé åç¥è­ï¼ä¸¦ä½¿ç¨å®ä¾æ¼å DKGãWTS éåäº DKG å¢å¼· LLM å LLM è¼å© DKG æ¼åä¹éçè¿´è·¯ï¼é¨èå®éæ¼¸åç­åå­¸ç¿ç¹å®é ååé¡ï¼è½å¤ æçºæ¹åé åå°æ¥­åãæåå¨æ©«è·¨ 5 åé åç 6 åè³æéä¸é©è­ WTS çæè½ãå¯¦é©çµæé¡¯ç¤ºï¼WTS å¨ 4 åå°æ¥­é åä¸­è¶è¶ååç SOTAï¼ä¸¦éå° 11.3% çæå¤§æè½æåã

##### **EzSQL: An SQL intermediate representation for improving SQL-to-text Generation**
2411.18923v1 by Meher Bhardwaj, Hrishikesh Ethari, Dennis Singh Moirangthem

The SQL-to-text generation task traditionally uses template base, Seq2Seq,
tree-to-sequence, and graph-to-sequence models. Recent models take advantage of
pre-trained generative language models for this task in the Seq2Seq framework.
However, treating SQL as a sequence of inputs to the pre-trained models is not
optimal. In this work, we put forward a new SQL intermediate representation
called EzSQL to align SQL with the natural language text sequence. EzSQL
simplifies the SQL queries and brings them closer to natural language text by
modifying operators and keywords, which can usually be described in natural
language. EzSQL also removes the need for set operators. Our proposed
SQL-to-text generation model uses EzSQL as the input to a pre-trained
generative language model for generating the text descriptions. We demonstrate
that our model is an effective state-of-the-art method to generate text
narrations from SQL queries on the WikiSQL and Spider datasets. We also show
that by generating pretraining data using our SQL-to-text generation model, we
can enhance the performance of Text-to-SQL parsers.

æè¦ï¼SQL è½æå­çæä»»åå³çµ±ä¸ä½¿ç¨ç¯æ¬åºç¤ãSeq2Seqãæ¨¹å°åºåååå°åºåæ¨¡åãæè¿çæ¨¡åå©ç¨é è¨ç·´çæå¼èªè¨æ¨¡åä¾å·è¡ Seq2Seq æ¶æ§ä¸­çæ­¤é ä»»åãç¶èï¼å° SQL è¦çºé è¨ç·´æ¨¡åè¼¸å¥åºåä¸¦éæä½³è§£ãå¨æ­¤é å·¥ä½ä¸­ï¼æåæåºä¸ååçº EzSQL çæ°å¼ SQL ä¸­éè¡¨ç¤ºï¼ä»¥å° SQL èèªç¶èªè¨æå­åºåå°é½ãEzSQL ç°¡å SQL æ¥è©¢ï¼ä¸¦ééä¿®æ¹éç®å­èééµå­ï¼éå¸¸å¯ä»¥ç¨èªç¶èªè¨æè¿°ï¼ï¼è®å®åæ´æ¥è¿èªç¶èªè¨æå­ãEzSQL ä¹æ¶é¤äºå°éåéç®å­çéæ±ãæåæåºç SQL è½æå­çææ¨¡åä½¿ç¨ EzSQL ä½çºè¼¸å¥ï¼è¼¸å¥é è¨ç·´çæå¼èªè¨æ¨¡åä»¥ç¢çæå­æè¿°ãæåç¤ºç¯æåçæ¨¡åæ¯ä¸ç¨®ææçææ°æ¹æ³ï¼å¯ä»¥ç¨æ¼å¾ WikiSQL è Spider è³æéä¸­ç SQL æ¥è©¢ç¢çæå­æè¿°ãæåä¹å±ç¤ºééä½¿ç¨æåç SQL è½æå­çææ¨¡åç¢çé è¨ç·´è³æï¼æåå¯ä»¥æåæå­è½ SQL è§£æå¨çæè½ã

##### **MLLM-Search: A Zero-Shot Approach to Finding People using Multimodal Large Language Models**
2412.00103v1 by Angus Fung, Aaron Hao Tan, Haitong Wang, Beno Benhabib, Goldie Nejat

Robotic search of people in human-centered environments, including healthcare
settings, is challenging as autonomous robots need to locate people without
complete or any prior knowledge of their schedules, plans or locations.
Furthermore, robots need to be able to adapt to real-time events that can
influence a person's plan in an environment. In this paper, we present
MLLM-Search, a novel zero-shot person search architecture that leverages
multimodal large language models (MLLM) to address the mobile robot problem of
searching for a person under event-driven scenarios with varying user
schedules. Our approach introduces a novel visual prompting method to provide
robots with spatial understanding of the environment by generating a spatially
grounded waypoint map, representing navigable waypoints by a topological graph
and regions by semantic labels. This is incorporated into a MLLM with a region
planner that selects the next search region based on the semantic relevance to
the search scenario, and a waypoint planner which generates a search path by
considering the semantically relevant objects and the local spatial context
through our unique spatial chain-of-thought prompting approach. Extensive 3D
photorealistic experiments were conducted to validate the performance of
MLLM-Search in searching for a person with a changing schedule in different
environments. An ablation study was also conducted to validate the main design
choices of MLLM-Search. Furthermore, a comparison study with state-of-the art
search methods demonstrated that MLLM-Search outperforms existing methods with
respect to search efficiency. Real-world experiments with a mobile robot in a
multi-room floor of a building showed that MLLM-Search was able to generalize
to finding a person in a new unseen environment.

æè¦ï¼æ©å¨äººå¨ä»¥äººçºä¸­å¿çç°å¢ä¸­æå°äººï¼åæ¬é«çä¿å¥ç°å¢ï¼éæ¯ä¸åææ°ï¼å çºèªä¸»æ©å¨äººéè¦å¨å®å¨ææ²æäºåç¥éä»åçæéè¡¨ãè¨ç«æä½ç½®çææ³ä¸æ¾å°äººãæ­¤å¤ï¼æ©å¨äººéè¦è½å¤ é©æå¯è½å½±é¿ç°å¢ä¸­æäººè¨ç«çå³æäºä»¶ãå¨æ¬æä¸­ï¼æåæåº MLLM-Searchï¼ä¸ç¨®æ°ç©çé¶æ¬¡äººæå°æ¶æ§ï¼å®å©ç¨å¤æ¨¡æå¤§åèªè¨æ¨¡å (MLLM) ä¾è§£æ±ºå¨äºä»¶é©åå ´æ¯ä¸­æå°å·æä¸åä½¿ç¨èæéè¡¨çæäººçè¡åæ©å¨äººåé¡ãæåçåæ³å¼å¥äºä¸ç¨®æ°ç©çè¦è¦ºæç¤ºæ¹æ³ï¼ééçæä¸åç©ºéæ¥å°çèªé»åï¼ä»¥ææ²åè¡¨ç¤ºå¯å°èªèªé»ï¼ä¸¦ééèªç¾©æ¨ç±¤è¡¨ç¤ºååï¼çºæ©å¨äººæä¾ç°å¢çç©ºéçè§£ãéè¢«æ´åå°ä¸åå·æååè¦åå¨ç MLLM ä¸­ï¼è©²ååè¦åå¨æ ¹æèæå°å ´æ¯çèªç¾©ç¸éæ§é¸æä¸ä¸åæå°ååï¼ä»¥åä¸åèªé»è¦åå¨ï¼è©²è¦åå¨ééèæ®èªç¾©ç¸éç©ä»¶åå±é¨ç©ºéèæ¯ééæåç¨ç¹çç©ºéæç¶­æç¤ºæ¹æ³çææå°è·¯å¾ãé²è¡äºå»£æ³ç 3D çå¯¦æå¯¦é©ï¼ä»¥é©è­ MLLM-Search å¨ä¸åç°å¢ä¸­æå°å·æè®æ´æéè¡¨çäººçæè½ãéé²è¡äºä¸é æ¶èç ç©¶ï¼ä»¥é©è­ MLLM-Search çä¸»è¦è¨­è¨é¸æãæ­¤å¤ï¼èæåé²çæå°æ¹æ³çæ¯è¼ç ç©¶è¡¨æï¼MLLM-Search å¨æå°æçæ¹é¢åªæ¼ç¾ææ¹æ³ãå¨å»ºç¯ç©å¤æ¿éæ¨å±¤ä¸­ä½¿ç¨è¡åæ©å¨äººé²è¡ççå¯¦ä¸çå¯¦é©è¡¨æï¼MLLM-Search è½å¤ æ¦æ¬å°å¨ä¸åæ°çæªè¦ç°å¢ä¸­æ¾å°æäººã

##### **Human Evaluation of Procedural Knowledge Graph Extraction from Text with Large Language Models**
2412.03589v1 by Valentina Anita Carriero, Antonia Azzini, Ilaria Baroni, Mario Scrocca, Irene Celino

Procedural Knowledge is the know-how expressed in the form of sequences of
steps needed to perform some tasks. Procedures are usually described by means
of natural language texts, such as recipes or maintenance manuals, possibly
spread across different documents and systems, and their interpretation and
subsequent execution is often left to the reader. Representing such procedures
in a Knowledge Graph (KG) can be the basis to build digital tools to support
those users who need to apply or execute them. In this paper, we leverage Large
Language Model (LLM) capabilities and propose a prompt engineering approach to
extract steps, actions, objects, equipment and temporal information from a
textual procedure, in order to populate a Procedural KG according to a
pre-defined ontology. We evaluate the KG extraction results by means of a user
study, in order to qualitatively and quantitatively assess the perceived
quality and usefulness of the LLM-extracted procedural knowledge. We show that
LLMs can produce outputs of acceptable quality and we assess the subjective
perception of AI by human evaluators.

æè¦ï¼ç¨åºæ§ç¥è­æ¯ä»¥å·è¡æäºä»»åæéçæ­¥é©åºåå½¢å¼è¡¨éçæè¡ç¥è­ãç¨åºéå¸¸ç±èªç¶èªè¨ææ¬æè¿°ï¼ä¾å¦é£è­æç¶­è­·æåï¼å¯è½åæ£å¨ä¸åçæä»¶åç³»çµ±ä¸­ï¼å¶è§£éåå¾çºå·è¡éå¸¸ççµ¦è®èãå¨ç¥è­åè­ (KG) ä¸­è¡¨ç¤ºæ­¤é¡ç¨åºå¯ä»¥æçºæ§å»ºæ¸ä½å·¥å·çåºç¤ï¼ä»¥æ¯æ´éè¦æç¨æå·è¡éäºç¨åºçä½¿ç¨èãå¨æ¬æä¸­ï¼æåå©ç¨å¤§åèªè¨æ¨¡å (LLM) åè½ä¸¦æåºæç¤ºå·¥ç¨æ¹æ³ï¼å¾æå­ç¨åºä¸­æåæ­¥é©ãåä½ãç©ä»¶ãè¨­ååæéè³è¨ï¼ä»¥ä¾¿æ ¹æé å®ç¾©çæ¬ä½å¡«åç¨åº KGãæåééä½¿ç¨èç ç©¶è©ä¼° KG æåçµæï¼ä»¥å®æ§åå®éè©ä¼° LLM æåçç¨åºç¥è­çæç¥åè³ªåå¯¦ç¨æ§ãæåè¡¨æ LLM å¯ä»¥ç¢çå¯æ¥ååè³ªçè¼¸åºï¼ä¸¦ä¸æåè©ä¼°äºäººé¡è©ä¼°èå° AI çä¸»è§æç¥ã

##### **Regularized Multi-LLMs Collaboration for Enhanced Score-based Causal Discovery**
2411.17989v1 by Xiaoxuan Li, Yao Liu, Ruoyu Wang, Lina Yao

As the significance of understanding the cause-and-effect relationships among
variables increases in the development of modern systems and algorithms,
learning causality from observational data has become a preferred and efficient
approach over conducting randomized control trials. However, purely
observational data could be insufficient to reconstruct the true causal graph.
Consequently, many researchers tried to utilise some form of prior knowledge to
improve causal discovery process. In this context, the impressive capabilities
of large language models (LLMs) have emerged as a promising alternative to the
costly acquisition of prior expert knowledge. In this work, we further explore
the potential of using LLMs to enhance causal discovery approaches,
particularly focusing on score-based methods, and we propose a general
framework to utilise the capacity of not only one but multiple LLMs to augment
the discovery process.

æè¦ï¼é¨èçè§£ç¾ä»£ç³»çµ±åæ¼ç®æ³ä¸­è®æ¸ä¹éçå æéä¿çéè¦æ§æ¥çå¢å ï¼å¾è§æ¸¬è³æä¸­å­¸ç¿å æéä¿å·²æçºä¸ç¨®æ¯é²è¡é¨æ©å°ç§è©¦é©æ´åéçä¸æ´ææççæ¹æ³ãç¶èï¼ç´ç²¹çè§æ¸¬è³æå¯è½ä¸è¶³ä»¥éå»ºçæ­£çå æåãå æ­¤ï¼è¨±å¤ç ç©¶äººå¡åè©¦å©ç¨æç¨®å½¢å¼çåé©ç¥è­ä¾æ¹åå æç¼ç¾éç¨ãå¨æ­¤èæ¯ä¸ï¼å¤§åèªè¨æ¨¡å (LLM) çå¼·å¤§åè½å·²æçºæè²´çåé©å°å®¶ç¥è­ç²åçæ¿ä»£æ¹æ¡ãå¨éé å·¥ä½ä¸­ï¼æåé²ä¸æ­¥æ¢è¨äºä½¿ç¨ LLM ä¾å¢å¼·å æç¼ç¾æ¹æ³çå¯è½æ§ï¼ç¹å¥éæ³¨åºæ¼è©åçæ¨¡åï¼ä¸¦ä¸æåæåºäºä¸åéç¨æ¡æ¶ï¼ä¸åå¯ä»¥å©ç¨ä¸å LLMï¼éå¯ä»¥å©ç¨å¤å LLM ä¾æ´åç¼ç¾éç¨ã

##### **ShowUI: One Vision-Language-Action Model for GUI Visual Agent**
2411.17465v1 by Kevin Qinghong Lin, Linjie Li, Difei Gao, Zhengyuan Yang, Shiwei Wu, Zechen Bai, Weixian Lei, Lijuan Wang, Mike Zheng Shou

Building Graphical User Interface (GUI) assistants holds significant promise
for enhancing human workflow productivity. While most agents are
language-based, relying on closed-source API with text-rich meta-information
(e.g., HTML or accessibility tree), they show limitations in perceiving UI
visuals as humans do, highlighting the need for GUI visual agents. In this
work, we develop a vision-language-action model in digital world, namely
ShowUI, which features the following innovations: (i) UI-Guided Visual Token
Selection to reduce computational costs by formulating screenshots as an UI
connected graph, adaptively identifying their redundant relationship and serve
as the criteria for token selection during self-attention blocks; (ii)
Interleaved Vision-Language-Action Streaming that flexibly unifies diverse
needs within GUI tasks, enabling effective management of visual-action history
in navigation or pairing multi-turn query-action sequences per screenshot to
enhance training efficiency; (iii) Small-scale High-quality GUI
Instruction-following Datasets by careful data curation and employing a
resampling strategy to address significant data type imbalances. With above
components, ShowUI, a lightweight 2B model using 256K data, achieves a strong
75.1% accuracy in zero-shot screenshot grounding. Its UI-guided token selection
further reduces 33% of redundant visual tokens during training and speeds up
the performance by 1.4x. Navigation experiments across web Mind2Web, mobile
AITW, and online MiniWob environments further underscore the effectiveness and
potential of our model in advancing GUI visual agents. The models are available
at https://github.com/showlab/ShowUI.

æè¦ï¼<paragraph>å»ºæ§åå½¢ä½¿ç¨èä»é¢ (GUI) å©çæ¥µæææåäººé¡å·¥ä½æµç¨ççç¢åãéç¶å¤§å¤æ¸ä»£çé½æ¯åºæ¼èªè¨ï¼ä»°è³´å·æè±å¯æå­åè³è¨å°éåå§ç¢¼ APIï¼ä¾å¦ HTML æç¡éç¤æ¨¹ï¼ï¼ä½å®åå¨æç¥ä½¿ç¨èä»é¢è¦è¦ºæææ¹é¢é¡¯ç¤ºåºéå¶ï¼éå¸é¡¯äºå° GUI è¦è¦ºä»£ççéæ±ãå¨éé å·¥ä½ä¸­ï¼æåå¨æ¸ä½ä¸çä¸­éç¼äºä¸åè¦è¦ºèªè¨åä½æ¨¡åï¼å³ ShowUIï¼å¶å·æä»¥ä¸åµæ°åè½ï¼(i) UI å¼å°è¦è¦ºä»£å¹£é¸æï¼ééå°è¢å¹æªåè¡¨è¿°çº UI é£æ¥åï¼èªé©æå°è­å¥å¶åé¤éä¿ï¼ä¸¦ä½çºèªæ³¨æååå¡ä¸­ä»£å¹£é¸æçæºåï¼ä»¥éä½éç®ææ¬ï¼(ii) äº¤é¯è¦è¦ºèªè¨åä½ä¸²æµï¼éæ´»å°çµ±ä¸ GUI ä»»åä¸­çåç¨®éæ±ï¼å¨å°è¦½ä¸­ææç®¡çè¦è¦ºåä½æ­·ç¨ï¼æéå°æ¯åè¢å¹æªåçå¤è¼ªæ¥è©¢åä½åºåï¼ä»¥æåè¨ç·´æçï¼(iii) å°è¦æ¨¡é«åè³ª GUI æä»¤éµå¾ªè³æéï¼ééä»ç´°çè³ææ´çåæ¡ç¨åæ½æ¨£ç­ç¥ï¼ä¾è§£æ±ºé¡¯èçè³æé¡åä¸å¹³è¡¡ãShowUI æ¯ä¸åä½¿ç¨ 256K è³æçè¼éç´ 2B æ¨¡åï¼å·åä¸è¿°çµæé¨åï¼å¨é¶æ¬¡æ¹è¢å¹æªåæ¥å°ä¸­éå°å¼·åç 75.1% ç²¾ç¢ºåº¦ãå¶ UI å¼å°ä»£å¹£é¸æé²ä¸æ­¥æ¸å°äºè¨ç·´æé 33% çåé¤è¦è¦ºä»£å¹£ï¼ä¸¦å°æè½æåäº 1.4 åãè·¨ç¶²è·¯ Mind2Webãè¡å AITW åç·ä¸ MiniWob ç°å¢çå°è¦½å¯¦é©é²ä¸æ­¥å¼·èª¿äºæåçæ¨¡åå¨æ¨é² GUI è¦è¦ºä»£çæ¹é¢çæææ§åæ½åãéäºæ¨¡åå¯å¨ https://github.com/showlab/ShowUI åå¾ã</paragraph>

##### **Can LLMs be Good Graph Judger for Knowledge Graph Construction?**
2411.17388v1 by Haoyu Huang, Chong Chen, Conghui He, Yang Li, Jiawei Jiang, Wentao Zhang

In real-world scenarios, most of the data obtained from information retrieval
(IR) system is unstructured. Converting natural language sentences into
structured Knowledge Graphs (KGs) remains a critical challenge. The quality of
constructed KGs may also impact the performance of some KG-dependent domains
like GraphRAG systems and recommendation systems. Recently, Large Language
Models (LLMs) have demonstrated impressive capabilities in addressing a wide
range of natural language processing tasks. However, there are still challenges
when utilizing LLMs to address the task of generating structured KGs. And we
have identified three limitations with respect to existing KG construction
methods. (1)There is a large amount of information and excessive noise in
real-world documents, which could result in extracting messy information.
(2)Native LLMs struggle to effectively extract accuracy knowledge from some
domain-specific documents. (3)Hallucinations phenomenon cannot be overlooked
when utilizing LLMs directly as an unsupervised method for constructing KGs.
  In this paper, we propose GraphJudger, a knowledge graph construction
framework to address the aforementioned challenges. We introduce three
innovative modules in our method, which are entity-centric iterative text
denoising, knowledge aware instruction tuning and graph judgement,
respectively. We seek to utilize the capacity of LLMs to function as a graph
judger, a capability superior to their role only as a predictor for KG
construction problems. Experiments conducted on two general text-graph pair
datasets and one domain-specific text-graph pair dataset show superior
performances compared to baseline methods. The code of our proposed method is
available at https://github.com/hhy-huang/GraphJudger.

æè¦ï¼<paragraph>å¨ç¾å¯¦ä¸ççå ´æ¯ä¸­ï¼å¾è³è¨æª¢ç´¢ (IR) ç³»çµ±åå¾çå¤§é¨åè³æé½æ¯éçµæ§åçãå°èªç¶èªè¨å¥å­è½æçºçµæ§åçç¥è­åè­ (KG) ä»ç¶æ¯ä¸é éå¤§çææ°ãå·²å»ºæ§ç KG åè³ªä¹å¯è½å½±é¿æäºä¾è³´ KG çé åï¼ä¾å¦ GraphRAG ç³»çµ±åæ¨è¦ç³»çµ±çæè½ãæè¿ï¼å¤§åèªè¨æ¨¡å (LLM) å·²å±ç¾åºä»¤äººå°è±¡æ·±å»çè½åï¼è½èçå»£æ³çèªç¶èªè¨èçä»»åãç¶èï¼ç¶å©ç¨ LLM ä¾èçç¢ççµæ§å KG çä»»åæï¼ä»ç¶å­å¨ææ°ãæåå·²éå°ç¾æç KG å»ºæ§æ¹æ³æ¾åºä¸åéå¶ã(1) å¨ç¾å¯¦ä¸ççæä»¶ä¸­æå¤§éçè³è¨åéå¤çéè¨ï¼éå¯è½æå°è´èåéäºçè³è¨ã(2) åç LLM é£ä»¥å¾æäºç¹å®é åçæä»¶ä¸­ææèåç²¾ç¢ºçç¥è­ã(3) å¨å° LLM ç´æ¥ç¨ä½å»ºæ§ KG çéç£ç£å¼æ¹æ³æï¼ç¡æ³å¿½ç¥å¹»è¦ºç¾è±¡ãå¨æ¬æä¸­ï¼æåæåº GraphJudgerï¼éæ¯ä¸åç¥è­åè­å»ºæ§æ¶æ§ï¼ç¨æ¼è§£æ±ºä¸è¿°ææ°ãæåå¨æ¹æ³ä¸­å¼å¥äºä¸ååµæ°çæ¨¡çµï¼åå¥æ¯å¯¦é«çºä¸­å¿çåè¦æå­å»éè¨ãç¥è­æç¥æä»¤å¾®èª¿ååå½¢å¤æ·ãæåå°æ±å©ç¨ LLM çè½åï¼ä½¿å¶ç¼æ®åå½¢å¤æ·èçåè½ï¼éé è½ååªæ¼å¶åä½çº KG å»ºæ§åé¡é æ¸¬èçè§è²ãå¨å©åä¸è¬æå­åå½¢éå°è³æéåä¸åç¹å®é åæå­åå½¢éå°è³æéä¸é²è¡çå¯¦é©é¡¯ç¤ºï¼èåºç·æ¹æ³ç¸æ¯ï¼å¶æè½åªç°ãæåæåºçæ¹æ³çç¨å¼ç¢¼å¯æ¼ https://github.com/hhy-huang/GraphJudger åå¾ã</paragraph>

##### **Interleaved Scene Graph for Interleaved Text-and-Image Generation Assessment**
2411.17188v1 by Dongping Chen, Ruoxi Chen, Shu Pu, Zhaoyi Liu, Yanru Wu, Caixi Chen, Benlin Liu, Yue Huang, Yao Wan, Pan Zhou, Ranjay Krishna

Many real-world user queries (e.g. "How do to make egg fried rice?") could
benefit from systems capable of generating responses with both textual steps
with accompanying images, similar to a cookbook. Models designed to generate
interleaved text and images face challenges in ensuring consistency within and
across these modalities. To address these challenges, we present ISG, a
comprehensive evaluation framework for interleaved text-and-image generation.
ISG leverages a scene graph structure to capture relationships between text and
image blocks, evaluating responses on four levels of granularity: holistic,
structural, block-level, and image-specific. This multi-tiered evaluation
allows for a nuanced assessment of consistency, coherence, and accuracy, and
provides interpretable question-answer feedback. In conjunction with ISG, we
introduce a benchmark, ISG-Bench, encompassing 1,150 samples across 8
categories and 21 subcategories. This benchmark dataset includes complex
language-vision dependencies and golden answers to evaluate models effectively
on vision-centric tasks such as style transfer, a challenging area for current
models. Using ISG-Bench, we demonstrate that recent unified vision-language
models perform poorly on generating interleaved content. While compositional
approaches that combine separate language and image models show a 111%
improvement over unified models at the holistic level, their performance
remains suboptimal at both block and image levels. To facilitate future work,
we develop ISG-Agent, a baseline agent employing a "plan-execute-refine"
pipeline to invoke tools, achieving a 122% performance improvement.

æè¦ï¼è¨±å¤çå¯¦ä¸ççä½¿ç¨èæ¥è©¢ï¼ä¾å¦ãå¦ä½è£½ä½èçé£¯ï¼ãï¼å¯ä»¥åçæ¼è½å¤ ç¢çåå«æå­æ­¥é©åéå¸¶åççåæçç³»çµ±ï¼é¡ä¼¼æ¼é£è­ãå°éç¨æ¼ç¢çäº¤é¯ææ¬ååççæ¨¡åé¢è¨ç¢ºä¿éäºæ¹å¼å§é¨åä¹éçä¸è´æ§çææ°ãçºäºæå°éäºææ°ï¼æåæåºäº ISGï¼ä¸åç¨æ¼äº¤é¯ææ¬ååçç¢ççç¶åè©ä¼°æ¶æ§ãISG å©ç¨å ´æ¯åçµæ§ä¾ææææ¬ååçåå¡ä¹éçéä¿ï¼å¨ååå±¤ç´çç²åº¦ä¸è©ä¼°åæï¼æ´é«ãçµæ§ãåå¡å±¤ç´ååçç¹å®ãéç¨®å¤å±¤è©ä¼°åè¨±å°ä¸è´æ§ãé£è²«æ§åæºç¢ºæ§é²è¡ç´°ç·»çè©ä¼°ï¼ä¸¦æä¾å¯è§£éçåé¡è§£ç­åé¥ãçµå ISGï¼æåå¼å¥äºåºæº ISG-Benchï¼æ¶µè 8 åé¡å¥å 21 åå­é¡å¥ä¸­ç 1,150 åç¯ä¾ãéååºæºè³æéåå«è¤éçèªè¨è¦è¦ºä¾è³´éä¿åé»éç­æ¡ï¼ä»¥ææè©ä¼°æ¨¡åå¨ä»¥è¦è¦ºçºä¸­å¿çä»»åï¼ä¾å¦é¢¨æ ¼è½ç§»ï¼ä¸çè¡¨ç¾ï¼éæ¯ç¶åæ¨¡åé¢è¨çææ°é åãä½¿ç¨ ISG-Benchï¼æåè­æäºæè¿ççµ±ä¸è¦è¦ºèªè¨æ¨¡åå¨ç¢çäº¤é¯å§å®¹ä¸çè¡¨ç¾ä¸ä½³ãéç¶çµåå®ç¨èªè¨ååçæ¨¡åççµåæ¹æ³å¨æ´é«å±¤ç´ä¸æ¯çµ±ä¸æ¨¡åæåäº 111%ï¼ä½å®åå¨åå¡ååçå±¤ç´ä¸çè¡¨ç¾ä»ç¶ä¸ä½³ãçºäºä¿é²å¾çºå·¥ä½ï¼æåéç¼äº ISG-Agentï¼ä¸åæ¡ç¨ãè¨ç«å·è¡ä¿®æ­£ãç®¡ç·çåºæºä»£çï¼ç¨æ¼å¼å«å·¥å·ï¼å¯¦ç¾äº 122% çæè½æåã

##### **AtomR: Atomic Operator-Empowered Large Language Models for Heterogeneous Knowledge Reasoning**
2411.16495v2 by Amy Xin, Jinxin Liu, Zijun Yao, Zhicheng Lee, Shulin Cao, Lei Hou, Juanzi Li

Recent advancements in large language models (LLMs) have led to significant
improvements in various natural language processing tasks, but it is still
challenging for LLMs to perform knowledge-intensive complex question answering
due to LLMs' inefficacy in reasoning planning and the hallucination problem. A
typical solution is to employ retrieval-augmented generation (RAG) coupled with
chain-of-thought (CoT) reasoning, which decomposes complex questions into
chain-like sub-questions and applies iterative RAG at each sub-question.
However, prior works exhibit sub-optimal reasoning planning and overlook
dynamic knowledge retrieval from heterogeneous sources. In this paper, we
propose AtomR, a novel heterogeneous knowledge reasoning framework that
conducts multi-source reasoning at the atomic level. Drawing inspiration from
the graph modeling of knowledge, AtomR leverages large language models (LLMs)
to decompose complex questions into combinations of three atomic knowledge
operators, significantly enhancing the reasoning process at both the planning
and execution stages. We also introduce BlendQA, a novel evaluation benchmark
tailored to assess complex heterogeneous knowledge reasoning. Experiments show
that AtomR significantly outperforms state-of-the-art baselines across three
single-source and two multi-source reasoning benchmarks, with notable
performance gains of 9.4% on 2WikiMultihop and 9.5% on BlendQA.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çææ°é²å±å·²å¤§å¹æååç¨®èªç¶èªè¨èçä»»åçè¡¨ç¾ï¼ä½ LLM ä»é£ä»¥å·è¡ç¥è­å¯éåè¤éåé¡è§£ç­ï¼åå å¨æ¼ LLM å¨æ¨çè¦ååå¹»è¦ºåé¡æ¹é¢æçä¸å½°ãå¸åçè§£æ±ºæ¹æ¡æ¯æ¡ç¨æª¢ç´¢å¢å¼·çæ (RAG) æ­éæç¶­é (CoT) æ¨çï¼å°è¤éåé¡åè§£æéçå­åé¡ï¼ä¸¦å¨æ¯åå­åé¡å¥ç¨åè¦ RAGãç¶èï¼ååçç ç©¶å±ç¾åºæ¬¡ä½³æ¨çè¦åï¼ä¸¦å¿½ç¥å¾ç°è³ªä¾æºé²è¡åæç¥è­æª¢ç´¢ãå¨æ¬æä¸­ï¼æåæåº AtomRï¼ä¸åæ°ç©çç°è³ªç¥è­æ¨çæ¶æ§ï¼å¨åå­å±¤ç´é²è¡å¤ä¾æºæ¨çãAtomR å¾ç¥è­çåå½¢å»ºæ¨¡ä¸­æ±²åéæï¼å©ç¨å¤§åèªè¨æ¨¡å (LLM) å°è¤éåé¡åè§£æä¸ç¨®åå­ç¥è­éç®å­ççµåï¼å¤§å¹æåè¦ååå·è¡éæ®µçæ¨çç¨åºãæåä¹å¼é² BlendQAï¼ä¸åæ°ç©çè©éåºæºï¼å°éç¨æ¼è©ä¼°è¤éç°è³ªç¥è­æ¨çãå¯¦é©é¡¯ç¤ºï¼AtomR å¨ä¸åå®ä¸ä¾æºåå©åå¤ä¾æºæ¨çåºæºä¸­ï¼è¡¨ç¾é¡¯èåªæ¼ç¾ææè¡åºç·ï¼å¨ 2WikiMultihop ä¸ç²å¾ 9.4% çé¡¯èæè½æåï¼å¨ BlendQA ä¸ç²å¾ 9.5% çæåã

##### **Learning by Analogy: Enhancing Few-Shot Prompting for Math Word Problem Solving with Computational Graph-Based Retrieval**
2411.16454v1 by Xiaocong Yang, Jiacheng Lin, Ziqi Wang, Chengxiang Zhai

Large language models (LLMs) are known to struggle with complicated reasoning
tasks such as math word problems (MWPs). In this paper, we present how analogy
from similarly structured questions can improve LLMs' problem-solving
capabilities for MWPs. Specifically, we rely on the retrieval of problems with
similar computational graphs to the given question to serve as exemplars in the
prompt, providing the correct reasoning path for the generation model to refer
to. Empirical results across six math word problem datasets demonstrate the
effectiveness of our proposed method, which achieves a significant improvement
of up to 6.7 percent on average in absolute value, compared to baseline
methods. These results highlight our method's potential in addressing the
reasoning challenges in current LLMs.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²ç¥å¨è¤éæ¨çä»»åï¼ä¾å¦æ¸å­¸æå­é¡ (MWP)ï¼ä¸­æéå°å°é£ãå¨æ¬æä¸­ï¼æåå±ç¤ºäºä¾èªçµæ§ç¸ä¼¼çåé¡çé¡æ¯å¦ä½è½æ¹å LLM å° MWP çåé¡è§£æ±ºè½åãå·é«ä¾èªªï¼æåä¾è³´æ¼æ·åèçµ¦å®åé¡å·æé¡ä¼¼éç®åå½¢çåé¡ï¼ä½çºæç¤ºä¸­çç¯ä¾ï¼çºçææ¨¡åæä¾æ­£ç¢ºçæ¨çè·¯å¾ä»¥ä¾åèãå­åæ¸å­¸æå­é¡æ¸æéçå¯¦è­çµæè­æäºæåæåºçæ¹æ³çæææ§ï¼èåºç·æ¹æ³ç¸æ¯ï¼å¹³åçµå°å¼æé«äº 6.7 åç¾åé»ãéäºçµæçªåºäºæåçæ¹æ³å¨è§£æ±ºç¶å LLM ä¸­çæ¨çææ°æ¹é¢çæ½åã

##### **Adapter-based Approaches to Knowledge-enhanced Language Models -- A Survey**
2411.16403v1 by Alexander Fichtl, Juraj Vladika, Georg Groh

Knowledge-enhanced language models (KELMs) have emerged as promising tools to
bridge the gap between large-scale language models and domain-specific
knowledge. KELMs can achieve higher factual accuracy and mitigate
hallucinations by leveraging knowledge graphs (KGs). They are frequently
combined with adapter modules to reduce the computational load and risk of
catastrophic forgetting. In this paper, we conduct a systematic literature
review (SLR) on adapter-based approaches to KELMs. We provide a structured
overview of existing methodologies in the field through quantitative and
qualitative analysis and explore the strengths and potential shortcomings of
individual approaches. We show that general knowledge and domain-specific
approaches have been frequently explored along with various adapter
architectures and downstream tasks. We particularly focused on the popular
biomedical domain, where we provided an insightful performance comparison of
existing KELMs. We outline the main trends and propose promising future
directions.

æè¦ï¼ç¥è­å¢å¼·èªè¨æ¨¡åï¼KELMï¼å·²æçºå½åå¤§è¦æ¨¡èªè¨æ¨¡åèç¹å®é åç¥è­å·®è·çæåéçå·¥å·ãKELM å¯ä»¥ééå©ç¨ç¥è­åè­ï¼KGï¼ä¾æé«äºå¯¦æºç¢ºæ§ä¸¦æ¸å°å¹»è¦ºãå®åç¶å¸¸èé©éå¨æ¨¡çµçµåä½¿ç¨ï¼ä»¥éä½éç®è² è¼åç½é£æ§éºå¿çé¢¨éªãå¨æ¬æä¸­ï¼æåå°åºæ¼é©éå¨ç KELM æ¹æ³é²è¡ç³»çµ±æ§çæç»åé¡§ï¼SLRï¼ãæåééå®éåå®æ§åææä¾è©²é åæ¢ææ¹æ³è«ççµæ§åæ¦è§ï¼ä¸¦æ¢è¨åå¥æ¹æ³çåªé»åæ½å¨ç¼ºé»ãæåè¡¨æï¼ä¸è¬ç¥è­åç¹å®é åçæ¹æ³å·²èåç¨®é©éå¨æ¶æ§åä¸æ¸¸ä»»åä¸èµ·è¢«é »ç¹æ¢ç´¢ãæåç¹å¥éæ³¨ç±éççç©é«å­¸é åï¼å¨è©²é åä¸­ï¼æåæä¾äºç¾æ KELM çæè¦å°æè½æ¯è¼ãæåæ¦è¿°äºä¸»è¦è¶¨å¢ï¼ä¸¦æåºäºæåéçæªä¾æ¹åã

##### **Decoding Urban Industrial Complexity: Enhancing Knowledge-Driven Insights via IndustryScopeGPT**
2411.15758v1 by Siqi Wang, Chao Liang, Yunfan Gao, Yang Liu, Jing Li, Haofen Wang

Industrial parks are critical to urban economic growth. Yet, their
development often encounters challenges stemming from imbalances between
industrial requirements and urban services, underscoring the need for strategic
planning and operations. This paper introduces IndustryScopeKG, a pioneering
large-scale multi-modal, multi-level industrial park knowledge graph, which
integrates diverse urban data including street views, corporate,
socio-economic, and geospatial information, capturing the complex relationships
and semantics within industrial parks. Alongside this, we present the
IndustryScopeGPT framework, which leverages Large Language Models (LLMs) with
Monte Carlo Tree Search to enhance tool-augmented reasoning and decision-making
in Industrial Park Planning and Operation (IPPO). Our work significantly
improves site recommendation and functional planning, demonstrating the
potential of combining LLMs with structured datasets to advance industrial park
management. This approach sets a new benchmark for intelligent IPPO research
and lays a robust foundation for advancing urban industrial development. The
dataset and related code are available at
https://github.com/Tongji-KGLLM/IndustryScope.

æè¦ï¼å·¥æ¥­ååå°æ¼é½å¸ç¶æ¿æé·è³ééè¦ãç¶èï¼å¶ç¼å±ç¶å¸¸æéå°å·¥æ¥­éæ±èé½å¸æåä¹éä¸å¹³è¡¡æç¢ççææ°ï¼éå¸é¡¯äºç­ç¥æ§è¦åèçéçéæ±ãæ¬æä»ç´¹äº IndustryScopeKGï¼ä¸ååé©æ§çãå¤§è¦æ¨¡ãå¤æ¨¡å¼ãå¤å±¤ç´çå·¥æ¥­ååç¥è­åè­ï¼å®æ´åäºåå«è¡æ¯ãå¬å¸ãç¤¾æç¶æ¿åå°çç©ºéè³è¨å¨å§çåç¨®é½å¸è³æï¼ææå·¥æ¥­ååå§è¤éçéä¿åèªæãé¤æ­¤ä¹å¤ï¼æåæåºäº IndustryScopeGPT æ¶æ§ï¼å®å©ç¨å¤§åèªè¨æ¨¡å (LLM) èèå°å¡ç¾æ¨¹çæå°ï¼ä»¥å¢å¼·å·¥å·è¼å©æ¨çåå¨å·¥æ¥­ååè¦ååçé (IPPO) ä¸­çæ±ºç­å¶å®ãæåçç ç©¶å¤§å¹æ¹åäºå ´å°æ¨è¦ååè½è¦åï¼å±ç¤ºäºçµå LLM åçµæ§åè³æéä»¥æ¨é²å·¥æ¥­ååç®¡ççæ½åãéåæ¹æ³çºæºæ§ IPPO ç ç©¶è¨­å®äºæ°çåºæºï¼ä¸¦çºæ¨é²é½å¸ç¢æ¥­ç¼å±å¥ å®äºç©©åºçåºç¤ãè³æéåç¸éç¨å¼ç¢¼å¯å¨ https://github.com/Tongji-KGLLM/IndustryScope åå¾ã

##### **One to rule them all: natural language to bind communication, perception and action**
2411.15033v1 by Simone Colombani, Dimitri Ognibene, Giuseppe Boccignone

In recent years, research in the area of human-robot interaction has focused
on developing robots capable of understanding complex human instructions and
performing tasks in dynamic and diverse environments. These systems have a wide
range of applications, from personal assistance to industrial robotics,
emphasizing the importance of robots interacting flexibly, naturally and safely
with humans. This paper presents an advanced architecture for robotic action
planning that integrates communication, perception, and planning with Large
Language Models (LLMs). Our system is designed to translate commands expressed
in natural language into executable robot actions, incorporating environmental
information and dynamically updating plans based on real-time feedback. The
Planner Module is the core of the system where LLMs embedded in a modified
ReAct framework are employed to interpret and carry out user commands. By
leveraging their extensive pre-trained knowledge, LLMs can effectively process
user requests without the need to introduce new knowledge on the changing
environment. The modified ReAct framework further enhances the execution space
by providing real-time environmental perception and the outcomes of physical
actions. By combining robust and dynamic semantic map representations as graphs
with control components and failure explanations, this architecture enhances a
robot adaptability, task execution, and seamless collaboration with human users
in shared and dynamic environments. Through the integration of continuous
feedback loops with the environment the system can dynamically adjusts the plan
to accommodate unexpected changes, optimizing the robot ability to perform
tasks. Using a dataset of previous experience is possible to provide detailed
feedback about the failure. Updating the LLMs context of the next iteration
with suggestion on how to overcame the issue.

æè¦ï¼è¿å¹´æ¥ï¼äººæºäº¤äºé¢åçç ç©¶éç¹
å¨äºå¼åè½å¤çè§£å¤æäººç±»æä»¤å¹¶å¨å¨æåå¤æ ·åç¯å¢ä¸­æ§è¡ä»»å¡çæºå¨äººãè¿äºç³»ç»å·æå¹¿æ³çåºç¨ï¼ä»ä¸ªäººå©çå°å·¥ä¸æºå¨äººï¼å¼ºè°äºæºå¨äººä¸äººç±»çµæ´»ãèªç¶åå®å¨äº¤äºçéè¦æ§ãæ¬ææåºäºä¸ç§åè¿çæºå¨äººå¨ä½è§åæ¶æï¼è¯¥æ¶æéæäºéä¿¡ãæç¥åè§åä¸å¤§åè¯­è¨æ¨¡å (LLM)ãæä»¬çç³»ç»æ¨å¨å°ä»¥èªç¶è¯­è¨è¡¨è¾¾çå½ä»¤ç¿»è¯æå¯æ§è¡çæºå¨äººå¨ä½ï¼å¹¶ç»åç¯å¢ä¿¡æ¯å¹¶æ ¹æ®å®æ¶åé¦å¨ææ´æ°è®¡åãè§åå¨æ¨¡åæ¯ç³»ç»çæ ¸å¿ï¼å¶ä¸­åµå¥å¨ä¿®æ¹åç ReAct æ¡æ¶ä¸­ç LLM ç¨äºè§£éåæ§è¡ç¨æ·å½ä»¤ãéè¿å©ç¨å¶å¹¿æ³çé¢è®­ç»ç¥è¯ï¼LLM å¯ä»¥ææå¤çç¨æ·è¯·æ±ï¼èæ éå¼å¥æå³ä¸æ­ååçç¯å¢çæ°ç¥è¯ãä¿®æ¹åç ReAct æ¡æ¶éè¿æä¾å®æ¶ç¯å¢æç¥åç©çå¨ä½çç»æè¿ä¸æ­¥å¢å¼ºäºæ§è¡ç©ºé´ãéè¿å°é²æ£ä¸å¨æè¯­ä¹å°å¾è¡¨ç¤ºä¸æ§å¶ç»ä»¶åæéè§£éç¸ç»åï¼è¯¥æ¶æå¢å¼ºäºæºå¨äººçéåºæ§ãä»»å¡æ§è¡ä»¥åä¸äººç±»ç¨æ·å¨å±äº«åå¨æç¯å¢ä¸­çæ ç¼åä½ãéè¿å°è¿ç»­åé¦åè·¯ä¸ç¯å¢ç¸ç»åï¼ç³»ç»å¯ä»¥å¨æè°æ´è®¡åä»¥éåºæå¤ååï¼ä»èä¼åæºå¨äººæ§è¡ä»»å¡çè½åãå©ç¨ååçç»éªæ°æ®éï¼å¯ä»¥æä¾æå³æéçè¯¦ç»åé¦ãä½¿ç¨æå³å¦ä½åæé®é¢çå»ºè®®æ´æ°ä¸ä¸ä¸ªè¿­ä»£ç LLM ä¸ä¸æã

##### **Time is on my sight: scene graph filtering for dynamic environment perception in an LLM-driven robot**
2411.15027v1 by Simone Colombani, Luca Brini, Dimitri Ognibene, Giuseppe Boccignone

Robots are increasingly being used in dynamic environments like workplaces,
hospitals, and homes. As a result, interactions with robots must be simple and
intuitive, with robots perception adapting efficiently to human-induced
changes. This paper presents a robot control architecture that addresses key
challenges in human-robot interaction, with a particular focus on the dynamic
creation and continuous update of the robot state representation. The
architecture uses Large Language Models to integrate diverse information
sources, including natural language commands, robotic skills representation,
real-time dynamic semantic mapping of the perceived scene. This enables
flexible and adaptive robotic behavior in complex, dynamic environments.
Traditional robotic systems often rely on static, pre-programmed instructions
and settings, limiting their adaptability to dynamic environments and real-time
collaboration. In contrast, this architecture uses LLMs to interpret complex,
high-level instructions and generate actionable plans that enhance human-robot
collaboration. At its core, the system Perception Module generates and
continuously updates a semantic scene graph using RGB-D sensor data, providing
a detailed and structured representation of the environment. A particle filter
is employed to ensure accurate object localization in dynamic, real-world
settings. The Planner Module leverages this up-to-date semantic map to break
down high-level tasks into sub-tasks and link them to robotic skills such as
navigation, object manipulation (e.g., PICK and PLACE), and movement (e.g.,
GOTO). By combining real-time perception, state tracking, and LLM-driven
communication and task planning, the architecture enhances adaptability, task
efficiency, and human-robot collaboration in dynamic environments.

æè¦ï¼<paragraph>æ©å¨äººæ­£è¶ä¾è¶å»£æ³å°æç¨æ¼å·¥ä½å ´æãé«é¢åå®¶åº­ç­åæç°å¢ä¸­ãå æ­¤ï¼èæ©å¨äººçäºåå¿é ç°¡å®ç´è§ï¼æ©å¨äººçæç¥è½åå¿é ææé©æäººé¡å¼ç¼çè®åãæ¬ææåºäºä¸ç¨®æ©å¨äººæ§å¶æ¶æ§ï¼ç¨æ¼è§£æ±ºäººæ©äºåä¸­çééµææ°ï¼ç¹å¥éæ³¨æ©å¨äººçæè¡¨ç¤ºçåæå»ºç«åæçºæ´æ°ãè©²æ¶æ§ä½¿ç¨å¤§åèªè¨æ¨¡åæ´åå¤ç¨®è³è¨ä¾æºï¼åæ¬èªç¶èªè¨å½ä»¤ãæ©å¨äººæè½è¡¨ç¤ºãæç¥å ´æ¯çå³æåæèªç¾©å°æãéä½¿å¾æ©å¨äººå¨è¤éçåæç°å¢ä¸­è½å¤ éæ´»é©æãå³çµ±çæ©å¨äººç³»çµ±éå¸¸ä¾è³´æ¼éæçãé åç·¨ç¨çæä»¤åè¨­å®ï¼ééå¶äºå®åå°åæç°å¢åå³æåä½çé©æè½åãç¸æ¯ä¹ä¸ï¼æ­¤æ¶æ§ä½¿ç¨ LLM ä¾è©®éè¤éçé«å±¤ç´æä»¤ï¼ä¸¦å¶å®å¯è¡çè¨ç«ï¼ä»¥å¢å¼·äººæ©åä½ãå¨ç³»çµ±çæ ¸å¿ï¼æç¥æ¨¡çµä½¿ç¨ RGB-D ææ¸¬å¨è³æç¢çä¸¦æçºæ´æ°èªç¾©å ´æ¯åï¼æä¾ç°å¢çè©³ç´°ä¸çµæ§åçè¡¨ç¤ºãæ¡ç¨ç²å­æ¿¾æ³¢å¨ä»¥ç¢ºä¿å¨åæççå¯¦ä¸çè¨­å®ä¸­æºç¢ºå®ä½ç©ä»¶ãè¦åæ¨¡çµå©ç¨éåææ°çèªç¾©å°åï¼å°é«å±¤ç´ä»»ååè§£çºå­ä»»åï¼ä¸¦å°å®åé£çµå°æ©å¨äººæè½ï¼ä¾å¦å°èªãç©ä»¶æä½ï¼ä¾å¦ï¼åæ¾ï¼åç§»åï¼ä¾å¦ï¼åå¾ï¼ãééçµåå³ææç¥ãçæè¿½è¹¤å LLM é©åçæºéåä»»åè¦åï¼æ­¤æ¶æ§å¢å¼·äºåæç°å¢ä¸­çé©æè½åãä»»åæçåäººæ©åä½ã</paragraph>

##### **GOT4Rec: Graph of Thoughts for Sequential Recommendation**
2411.14922v1 by Zewen Long, Liang Wang, Shu Wu, Qiang Liu, Liang Wang

With the advancement of large language models (LLMs), researchers have
explored various methods to optimally leverage their comprehension and
generation capabilities in sequential recommendation scenarios. However,
several challenges persist in this endeavor. Firstly, most existing approaches
rely on the input-output prompting paradigm, which can result in irrelevant or
inaccurate responses. Secondly, while there have been attempts to enhance LLMs
using prompting strategies such as chain-of-thought (CoT), these efforts have
not fully harnessed the reasoning abilities of LLMs or effectively captured the
multifaceted information contained within user sequences. To address these
limitations, we propose GOT4Rec, a sequential recommendation method that
utilizes the graph of thoughts (GoT) prompting strategy. Specifically, we
identify and utilize three key types of information within user history
sequences: short-term interests, long-term interests and collaborative
information from other users. Our approach enables LLMs to independently reason
and generate recommendations based on these distinct types of information,
subsequently aggregating the results within the GoT framework to derive the
final recommended items. This method allows LLMs, with enhanced reasoning
capabilities, to more effectively consider the diverse information within user
sequences, resulting in more accurate recommendations and more comprehensive
explanations. Extensive experiments on real-world datasets demonstrate the
effectiveness of GOT4Rec, indicating that it outperforms existing
state-of-the-art baselines. Our code is available at
https://anonymous.4open.science/r/GOT4Rec-ED99.

æè¦ï¼é¨èå¤§åèªè¨æ¨¡å (LLM) çé²æ­¥ï¼ç ç©¶äººå¡å·²æ¢ç´¢åç¨®æ¹æ³ï¼ä»¥æä½³æ¹å¼å©ç¨å¶çè§£åçæè½åå¨é åºæ¨è¦å ´æ¯ä¸­ãç¶èï¼å¨éååªåä¸­ä»å­å¨ä¸äºææ°ãé¦åï¼å¤§å¤æ¸ç¾ææ¹æ³ä¾è³´æ¼è¼¸å¥è¼¸åºæç¤ºç¯ä¾ï¼éå¯è½æå°è´ä¸ç¸éæä¸æºç¢ºçåæãå¶æ¬¡ï¼éç¶æäººåè©¦ä½¿ç¨æç¤ºç­ç¥ï¼ä¾å¦ææ³é (CoT)ï¼ä¾å¢å¼· LLMï¼ä½éäºåªåä¸¦æªååå©ç¨ LLM çæ¨çè½åææææ·åä½¿ç¨èåºåä¸­åå«çå¤æ¹é¢è³è¨ãçºäºè§£æ±ºéäºéå¶ï¼æåæåº GOT4Recï¼éæ¯ä¸ç¨®é åºæ¨è¦æ¹æ³ï¼å©ç¨äºææ³å (GoT) æç¤ºç­ç¥ãå·é«ä¾èªªï¼æåå¨ä½¿ç¨èæ­·å²åºåä¸­è­å¥ä¸¦å©ç¨ä¸ç¨®é¡åçééµè³è¨ï¼ç­æèè¶£ãé·æèè¶£åä¾èªå¶ä»ä½¿ç¨èçåä½è³è¨ãæåçæ¹æ³ä½¿ LLM è½å¤ æ ¹æéäºä¸åé¡åçè³è¨ç¨ç«æ¨çä¸¦ç¢çå»ºè­°ï¼ç¶å¾å¨ GoT æ¡æ¶å§å¯ç¸½çµæä»¥æ¨å°åºæçµæ¨è¦çé ç®ãéç¨®æ¹æ³åè¨± LLM å¨å¢å¼·æ¨çè½åçåæï¼æ´ææå°èæ®ä½¿ç¨èåºåä¸­çä¸åè³è¨ï¼å¾èç¢çæ´æºç¢ºçå»ºè­°åæ´å¨é¢çèªªæãå¨çå¯¦ä¸çè³æéä¸çå¤§éå¯¦é©è­æäº GOT4Rec çæææ§ï¼è¡¨æå®åªæ¼ç¾æçæåé²åºæºãæåçç¨å¼ç¢¼å¯å¨ https://anonymous.4open.science/r/GOT4Rec-ED99 åå¾ã

##### **VisGraphVar: A Benchmark Generator for Assessing Variability in Graph Analysis Using Large Vision-Language Models**
2411.14832v1 by Camilo ChacÃ³n Sartori, Christian Blum, Filippo Bistaffa

The fast advancement of Large Vision-Language Models (LVLMs) has shown
immense potential. These models are increasingly capable of tackling abstract
visual tasks. Geometric structures, particularly graphs with their inherent
flexibility and complexity, serve as an excellent benchmark for evaluating
these models' predictive capabilities. While human observers can readily
identify subtle visual details and perform accurate analyses, our investigation
reveals that state-of-the-art LVLMs exhibit consistent limitations in specific
visual graph scenarios, especially when confronted with stylistic variations.
In response to these challenges, we introduce VisGraphVar (Visual Graph
Variability), a customizable benchmark generator able to produce graph images
for seven distinct task categories (detection, classification, segmentation,
pattern recognition, link prediction, reasoning, matching), designed to
systematically evaluate the strengths and limitations of individual LVLMs. We
use VisGraphVar to produce 990 graph images and evaluate six LVLMs, employing
two distinct prompting strategies, namely zero-shot and chain-of-thought. The
findings demonstrate that variations in visual attributes of images (e.g., node
labeling and layout) and the deliberate inclusion of visual imperfections, such
as overlapping nodes, significantly affect model performance. This research
emphasizes the importance of a comprehensive evaluation across graph-related
tasks, extending beyond reasoning alone. VisGraphVar offers valuable insights
to guide the development of more reliable and robust systems capable of
performing advanced visual graph analysis.

æè¦ï¼å¤§åè¦è¦ºèªè¨æ¨¡å (LVLMs) çå¿«éé²æ­¥å·²å±ç¾åºå·¨å¤§çæ½åãéäºæ¨¡åè¶ä¾è¶æè½åèçæ½è±¡çè¦è¦ºä»»åãå¹¾ä½çµæ§ï¼ç¹å¥æ¯å·æå§å¨éæ´»æ§èè¤éæ§çåå½¢ï¼å¯ç¨ä½è©ä¼°éäºæ¨¡åé æ¸¬è½åççµä½³åºæºãäººé¡è§å¯èå¯ä»¥è¼æè¾¨è­å¾®å¦çè¦è¦ºç´°ç¯ä¸¦å·è¡æºç¢ºçåæï¼ä½æåçèª¿æ¥é¡¯ç¤ºï¼æåé²ç LVLMs å¨ç¹å®çè¦è¦ºåå½¢å ´æ¯ä¸­è¡¨ç¾åºæçºçéå¶ï¼ç¹å¥æ¯å¨é¢å°é¢¨æ ¼è®åæãçºäºæå°éäºææ°ï¼æåå¼å¥äº VisGraphVarï¼è¦è¦ºåå½¢è®ç°ï¼ï¼éæ¯ä¸åå¯èªè¨çåºæºç¢çå¨ï¼è½å¤ ç¢çä¸åä¸åä»»åé¡å¥çåå½¢å½±åï¼åµæ¸¬ãåé¡ãåå²ãæ¨¡å¼è¾¨è­ãé£çµé æ¸¬ãæ¨çãéå°ï¼ï¼æ¨å¨ç³»çµ±æ§å°è©ä¼°åå¥ LVLMs çåªé»åéå¶ãæåä½¿ç¨ VisGraphVar ç¢ç 990 ååå½¢å½±åä¸¦è©ä¼°å­å LVLMsï¼æ¡ç¨å©ç¨®ä¸åçæç¤ºç­ç¥ï¼å³é¶æ¬¡å­¸ç¿åæç¶­éãç ç©¶çµæè¡¨æï¼å½±åè¦è¦ºå±¬æ§çè®åï¼ä¾å¦ç¯é»æ¨ç±¤åçé¢ï¼ä»¥åè¦è¦ºççµçææå å¥ï¼ä¾å¦éçç¯é»ï¼æé¡¯èå½±é¿æ¨¡åæè½ãéé ç ç©¶å¼·èª¿äºè·¨åå½¢ç¸éä»»åé²è¡å¨é¢è©ä¼°çéè¦æ§ï¼èä¸åéæ¼æ¨çãVisGraphVar æä¾äºå¯¶è²´çè¦è§£ï¼ä»¥æå°æ´å¯é ä¸å¼·å¤§çç³»çµ±çéç¼ï¼éäºç³»çµ±è½å¤ å·è¡é²éçè¦è¦ºåå½¢åæã

##### **MolReFlect: Towards In-Context Fine-grained Alignments between Molecules and Texts**
2411.14721v1 by Jiatong Li, Yunqing Liu, Wei Liu, Jingdi Le, Di Zhang, Wenqi Fan, Dongzhan Zhou, Yuqiang Li, Qing Li

Molecule discovery is a pivotal research field, impacting everything from the
medicines we take to the materials we use. Recently, Large Language Models
(LLMs) have been widely adopted in molecule understanding and generation, yet
the alignments between molecules and their corresponding captions remain a
significant challenge. Previous endeavours often treat the molecule as a
general SMILES string or molecular graph, neglecting the fine-grained
alignments between the molecular sub-structures and the descriptive textual
phrases, which are crucial for accurate and explainable predictions. In this
case, we introduce MolReFlect, a novel teacher-student framework designed to
contextually perform the molecule-caption alignments in a fine-grained way. Our
approach initially leverages a larger teacher LLM to label the detailed
alignments by directly extracting critical phrases from molecule captions or
SMILES strings and implying them to corresponding sub-structures or
characteristics. To refine these alignments, we propose In-Context Selective
Reflection, which retrieves previous extraction results as context examples for
teacher LLM to reflect and lets a smaller student LLM select from in-context
reflection and previous extraction results. Finally, we enhance the learning
process of the student LLM through Chain-of-Thought In-Context Molecule Tuning,
integrating the fine-grained alignments and the reasoning processes within the
Chain-of-Thought format. Our experimental results demonstrate that MolReFlect
enables LLMs like Mistral-7B to significantly outperform the previous
baselines, achieving SOTA performance on the ChEBI-20 dataset. This advancement
not only enhances the generative capabilities of LLMs in the molecule-caption
translation task, but also contributes to a more explainable framework.

æè¦ï¼åå­ç¼ç¾æ¯ä¸åééµçç ç©¶é åï¼å¾æåæç¨çè¥ç©å°æåä½¿ç¨çææï¼å½±é¿èä¸åãæè¿ï¼å¤§åèªè¨æ¨¡å (LLM) å·²å»£æ³æç¨æ¼åå­çè§£åçæä¸­ï¼ä½åå­åå¶å°ææ¨é¡ä¹éçå°é½ä»ç¶æ¯ä¸é éå¤§ææ°ãååçåªåéå¸¸å°åå­è¦çºä¸è¬ç SMILES å­ç¬¦ä¸²æåå­åï¼å¿½ç¥äºåå­å­çµæ§åæè¿°æ§ææ¬ç­èªä¹éçç´°ç²åº¦å°é½ï¼éå°æ¼æºç¢ºä¸å¯è§£éçé æ¸¬è³ééè¦ãå¨éç¨®ææ³ä¸ï¼æåå¼å¥äº MolReFlectï¼éæ¯ä¸åæ°ç©çå¸«çæ¡æ¶ï¼æ¨å¨ä»¥ç´°ç²åº¦çæ¹å¼å°åå­æ¨é¡å°é½é²è¡ä¸ä¸æå·è¡ãæåçåæ³æåå©ç¨ä¸åæ´å¤§çæå¸« LLM ä¾æ¨è¨è©³ç´°å°é½ï¼æ¹æ³æ¯ç´æ¥å¾åå­æ¨é¡æ SMILES å­ç¬¦ä¸²ä¸­æåééµç­èªï¼ä¸¦å°å®åæç¤ºçºå°æçå­çµæ§æç¹å¾µãçºäºåªåéäºå°é½ï¼æåæåºäºä¸ä¸æé¸ææ§åå°ï¼å®å°ä»¥åçæåçµæä½çºä¸ä¸æç¯ä¾ï¼ä¾æå¸« LLM é²è¡åå°ï¼ä¸¦è®ä¸åè¼å°çå­¸ç LLM å¾ä¸ä¸æåå°åä»¥åçæåçµæä¸­é²è¡é¸æãæå¾ï¼æåééææ³éä¸ä¸æåå­èª¿æ´å¢å¼·äºå­¸ç LLM çå­¸ç¿éç¨ï¼å°ç´°ç²åº¦å°é½åæ¨çéç¨æ´åå°ææ³éæ ¼å¼ä¸­ãæåçå¯¦é©çµæè¡¨æï¼MolReFlect ä½¿å Mistral-7B éæ¨£ç LLM è½å¤ é¡¯èåªæ¼ååçåºæºï¼å¨ ChEBI-20 æ¸æéä¸å¯¦ç¾äº SOTA æ§è½ãéä¸é²æ­¥ä¸åå¢å¼·äº LLM å¨åå­æ¨é¡ç¿»è­¯ä»»åä¸­ççæè½åï¼èä¸éæå©æ¼å»ºç«ä¸åæ´å·å¯è§£éæ§çæ¡æ¶ã

##### **G-RAG: Knowledge Expansion in Material Science**
2411.14592v2 by Radeen Mostafa, Mirza Nihal Baig, Mashaekh Tausif Ehsan, Jakir Hasan

In the field of Material Science, effective information retrieval systems are
essential for facilitating research. Traditional Retrieval-Augmented Generation
(RAG) approaches in Large Language Models (LLMs) often encounter challenges
such as outdated information, hallucinations, limited interpretability due to
context constraints, and inaccurate retrieval. To address these issues, Graph
RAG integrates graph databases to enhance the retrieval process. Our proposed
method processes Material Science documents by extracting key entities
(referred to as MatIDs) from sentences, which are then utilized to query
external Wikipedia knowledge bases (KBs) for additional relevant information.
We implement an agent-based parsing technique to achieve a more detailed
representation of the documents. Our improved version of Graph RAG called G-RAG
further leverages a graph database to capture relationships between these
entities, improving both retrieval accuracy and contextual understanding. This
enhanced approach demonstrates significant improvements in performance for
domains that require precise information retrieval, such as Material Science.

æè¦ï¼å¨ææç§å­¸é åï¼ææçè³è¨æª¢ç´¢ç³»çµ±å°æ¼ä¿é²ç ç©¶è³ééè¦ãå¤§åèªè¨æ¨¡å (LLM) ä¸­çå³çµ±æª¢ç´¢å¢å¼·çæ (RAG) æ¹æ³éå¸¸æéå°ææ°ï¼ä¾å¦éæçè³è¨ãå¹»è¦ºãç±æ¼ä¸ä¸æéå¶èå°è´çå¯è§£éæ§æéï¼ä»¥åæª¢ç´¢ä¸æºç¢ºãçºäºè§£æ±ºéäºåé¡ï¼Graph RAG æ´åäºåå½¢è³æåº«ä»¥å¢å¼·æª¢ç´¢éç¨ãæåæåºçæ¹æ³ééå¾å¥å­ä¸­èåééµå¯¦é« (ç¨±çº MatID) ä¾èçææç§å­¸æä»¶ï¼ç¶å¾å©ç¨éäºå¯¦é«æ¥è©¢å¤é¨çç¶­åºç¾ç§ç¥è­åº« (KB) ä»¥åå¾å¶ä»ç¸éè³è¨ãæåå¯¦ä½äºä¸ç¨®åºæ¼ä»£ççè§£ææè¡ï¼ä»¥éææ´è©³ç´°çæä»¶è¡¨ç¤ºãæåæ¹è¯çæ¬ç Graph RAGï¼ç¨±çº G-RAGï¼é²ä¸æ­¥å©ç¨åå½¢è³æåº«ä¾æ·åéäºå¯¦é«ä¹éçéä¿ï¼é²èæ¹åæª¢ç´¢æºç¢ºåº¦åèçµ¡çè§£ãéç¨®å¢å¼·çæ¹æ³å¨éè¦ç²¾ç¢ºè³è¨æª¢ç´¢çé åï¼ä¾å¦ææç§å­¸ï¼ä¸­ï¼å±ç¾äºé¡¯èçæè½æåã

##### **Knowledge Graphs, Large Language Models, and Hallucinations: An NLP Perspective**
2411.14258v1 by Ernests Lavrinovics, Russa Biswas, Johannes Bjerva, Katja Hose

Large Language Models (LLMs) have revolutionized Natural Language Processing
(NLP) based applications including automated text generation, question
answering, chatbots, and others. However, they face a significant challenge:
hallucinations, where models produce plausible-sounding but factually incorrect
responses. This undermines trust and limits the applicability of LLMs in
different domains. Knowledge Graphs (KGs), on the other hand, provide a
structured collection of interconnected facts represented as entities (nodes)
and their relationships (edges). In recent research, KGs have been leveraged to
provide context that can fill gaps in an LLM understanding of certain topics
offering a promising approach to mitigate hallucinations in LLMs, enhancing
their reliability and accuracy while benefiting from their wide applicability.
Nonetheless, it is still a very active area of research with various unresolved
open problems. In this paper, we discuss these open challenges covering
state-of-the-art datasets and benchmarks as well as methods for knowledge
integration and evaluating hallucinations. In our discussion, we consider the
current use of KGs in LLM systems and identify future directions within each of
these challenges.

æè¦ï¼å¤§åèªè¨æ¨¡åï¼LLMï¼å¾¹åºæ¹è®äºåºæ¼èªç¶èªè¨èçï¼NLPï¼çæç¨ï¼åæ¬èªåæå­çæãåé¡è§£ç­ãèå¤©æ©å¨äººç­ãç¶èï¼å®åé¢è¨èä¸åéå¤§çææ°ï¼å¹»è¦ºï¼æ¨¡åç¢çè½èµ·ä¾åçä½äºå¯¦ä¸ä¸æ­£ç¢ºçåæãéæç ´å£ä¿¡ä»»ï¼ä¸¦éå¶ LLM å¨ä¸åé åçé©ç¨æ§ãå¦ä¸æ¹é¢ï¼ç¥è­åè­ï¼KGï¼æä¾äºä»¥å¯¦é«ï¼ç¯é»ï¼åå¶éä¿ï¼éç·£ï¼è¡¨ç¤ºçç¸äºé£æ¥äºå¯¦ççµæ§åéåãå¨æè¿çç ç©¶ä¸­ï¼KG å·²è¢«ç¨æ¼æä¾ä¸ä¸æï¼å¯ä»¥å¡«è£ LLM å°æäºä¸»é¡çè§£çç©ºç½ï¼æä¾äºä¸ç¨®æå¸æçæ¹æ³ä¾æ¸è¼ LLM ä¸­çå¹»è¦ºï¼æé«å®åçå¯é æ§åæºç¢ºæ§ï¼åæåçæ¼å®åçå»£æ³é©ç¨æ§ãåç®¡å¦æ­¤ï¼éä»ç¶æ¯ä¸åéå¸¸æ´»èºçç ç©¶é åï¼æåç¨®æªè§£æ±ºçéæ¾åé¡ãå¨æ¬æä¸­ï¼æåè¨è«äºéäºéæ¾ææ°ï¼æ¶µèäºæåé²çæ¸æéååºæºï¼ä»¥åç¥è­æ´ååè©ä¼°å¹»è¦ºçæ¹æ³ãå¨æåçè¨è«ä¸­ï¼æåèæ®äº LLM ç³»çµ±ä¸­ KG çç¶åä½¿ç¨ï¼ä¸¦ç¢ºå®äºéäºææ°ä¸­çæ¯ä¸åæªä¾çæ¹åã

##### **Logic Augmented Generation**
2411.14012v1 by Aldo Gangemi, Andrea Giovanni Nuzzolese

Semantic Knowledge Graphs (SKG) face challenges with scalability,
flexibility, contextual understanding, and handling unstructured or ambiguous
information. However, they offer formal and structured knowledge enabling
highly interpretable and reliable results by means of reasoning and querying.
Large Language Models (LLMs) overcome those limitations making them suitable in
open-ended tasks and unstructured environments. Nevertheless, LLMs are neither
interpretable nor reliable. To solve the dichotomy between LLMs and SKGs we
envision Logic Augmented Generation (LAG) that combines the benefits of the two
worlds. LAG uses LLMs as Reactive Continuous Knowledge Graphs that can generate
potentially infinite relations and tacit knowledge on-demand. SKGs are key for
injecting a discrete heuristic dimension with clear logical and factual
boundaries. We exemplify LAG in two tasks of collective intelligence, i.e.,
medical diagnostics and climate projections. Understanding the properties and
limitations of LAG, which are still mostly unknown, is of utmost importance for
enabling a variety of tasks involving tacit knowledge in order to provide
interpretable and effective results.

æè¦ï¼èªæç¥è­åï¼SKGï¼å¨å¯æ´åæ§ãéæ´»æ§ãæå¢çè§£ä»¥åèçéçµæ§åæå«ç³è³è¨æ¹é¢é¢è¨ææ°ãç¶èï¼å®åæä¾æ­£å¼ä¸çµæ§åçç¥è­ï¼è½ééæ¨çåæ¥è©¢æä¾é«åº¦å¯è§£éä¸å¯é ççµæãå¤§åèªè¨æ¨¡åï¼LLMï¼åæäºéäºéå¶ï¼ä½¿å¶é©ç¨æ¼éæ¾å¼ä»»ååéçµæ§åç°å¢ãåç®¡å¦æ­¤ï¼LLM æ¢ä¸å¯è§£éä¹ä¸å¯é ãçºäºè§£æ±º LLM å SKG ä¹éçäºåæ³ï¼æåè¨­æ³äºéè¼¯å¢å¼·çæï¼LAGï¼ï¼å®çµåäºå©åä¸ççåªé»ãLAG ä½¿ç¨ LLM ä½çºåæå¼é£çºç¥è­åï¼å®å¯ä»¥æéç¢çæ½å¨çç¡ééä¿åé»æç¥è­ãSKG æ¯æ³¨å¥é¢æ£åç¼å¼ç¶­åº¦ï¼å·ææç¢ºéè¼¯åäºå¯¦éçï¼çééµãæåå¨éé«æºæ§çå©åä»»åä¸­èä¾èªªæ LAGï¼å³é«çè¨ºæ·åæ°£åé æ¸¬ãçè§£ LAG çç¹æ§åéå¶ï¼ç®åä»ç¶å¤§å¤æ¸æªç¥ï¼å°æ¼åç¨æ¶åé»æç¥è­çåç¨®ä»»åä»¥æä¾å¯è§£éä¸ææççµæè³ééè¦ã

##### **FastRAG: Retrieval Augmented Generation for Semi-structured Data**
2411.13773v1 by Amar Abane, Anis Bekri, Abdella Battou

Efficiently processing and interpreting network data is critical for the
operation of increasingly complex networks. Recent advances in Large Language
Models (LLM) and Retrieval-Augmented Generation (RAG) techniques have improved
data processing in network management. However, existing RAG methods like
VectorRAG and GraphRAG struggle with the complexity and implicit nature of
semi-structured technical data, leading to inefficiencies in time, cost, and
retrieval. This paper introduces FastRAG, a novel RAG approach designed for
semi-structured data. FastRAG employs schema learning and script learning to
extract and structure data without needing to submit entire data sources to an
LLM. It integrates text search with knowledge graph (KG) querying to improve
accuracy in retrieving context-rich information. Evaluation results demonstrate
that FastRAG provides accurate question answering, while improving up to 90% in
time and 85% in cost compared to GraphRAG.

æè¦ï¼ææçå°èçåè§£è®ç¶²è·¯è³æå°æ¼æ¥çè¤éçç¶²è·¯æä½è³ééè¦ãå¤§åèªè¨æ¨¡å (LLM) åæª¢ç´¢å¢å¼·ç¢ç (RAG) æè¡çææ°é²å±å·²ç¶æ¹åäºç¶²è·¯ç®¡çä¸­çè³æèçãç¶èï¼ç¾æç RAG æ¹æ³ï¼ä¾å¦ VectorRAG å GraphRAGï¼é£ä»¥æä»åçµæ§åæè¡è³æçè¤éæ§åé±å«æ§è³ªï¼å°è´æéãææ¬åæª¢ç´¢æçä¸å½°ãæ¬æä»ç´¹ FastRAGï¼ä¸ç¨®å°çºåçµæ§åè³æè¨­è¨çæ°ç© RAG æ¹æ³ãFastRAG ä½¿ç¨æ¶æ§å­¸ç¿åè³æ¬å­¸ç¿ä¾èååå»ºæ§è³æï¼èç¡éå°æ´åè³æä¾æºæäº¤çµ¦ LLMãå®å°æå­æå°èç¥è­åè­ (KG) æ¥è©¢æ´åï¼ä»¥æé«æª¢ç´¢å§å®¹è±å¯è³è¨çæºç¢ºæ§ãè©ä¼°çµæè­æï¼FastRAG æä¾äºæºç¢ºçåç­ï¼åæè GraphRAG ç¸æ¯ï¼æéæ¹åäº 90%ï¼ææ¬æ¹åäº 85%ã

##### **Predictive Insights into LGBTQ+ Minority Stress: A Transductive Exploration of Social Media Discourse**
2411.13534v1 by S. Chapagain, Y. Zhao, T. K. Rohleen, S. M. Hamdi, S. F. Boubrahimi, R. E. Flinn, E. M. Lund, D. Klooster, J. R. Scheer, C. J. Cascalheira

Individuals who identify as sexual and gender minorities, including lesbian,
gay, bisexual, transgender, queer, and others (LGBTQ+) are more likely to
experience poorer health than their heterosexual and cisgender counterparts.
One primary source that drives these health disparities is minority stress
(i.e., chronic and social stressors unique to LGBTQ+ communities' experiences
adapting to the dominant culture). This stress is frequently expressed in
LGBTQ+ users' posts on social media platforms. However, these expressions are
not just straightforward manifestations of minority stress. They involve
linguistic complexity (e.g., idiom or lexical diversity), rendering them
challenging for many traditional natural language processing methods to detect.
In this work, we designed a hybrid model using Graph Neural Networks (GNN) and
Bidirectional Encoder Representations from Transformers (BERT), a pre-trained
deep language model to improve the classification performance of minority
stress detection. We experimented with our model on a benchmark social media
dataset for minority stress detection (LGBTQ+ MiSSoM+). The dataset is
comprised of 5,789 human-annotated Reddit posts from LGBTQ+ subreddits. Our
approach enables the extraction of hidden linguistic nuances through
pretraining on a vast amount of raw data, while also engaging in transductive
learning to jointly develop representations for both labeled training data and
unlabeled test data. The RoBERTa-GCN model achieved an accuracy of 0.86 and an
F1 score of 0.86, surpassing the performance of other baseline models in
predicting LGBTQ+ minority stress. Improved prediction of minority stress
expressions on social media could lead to digital health interventions to
improve the wellbeing of LGBTQ+ people-a community with high rates of
stress-sensitive health problems.

æè¦ï¼<paragraph>èªåèªå·±æ¯æ§èæ§å¥å°æ¸æç¾¤çäººï¼åæ¬å¥³åæ§æãç·åæ§æãéæ§æãè·¨æ§å¥ãé·ååå¶ä» LGBTQ+ æç¾¤ï¼æ¯ç°æ§æåé æ§å¥èæ´å®¹ææè¼å·®çå¥åº·çæ³ãé æéäºå¥åº·å·®ç°çä¸»è¦ä¾æºä¹ä¸æ¯å°æ¸æç¾¤å£åï¼å³ LGBTQ+ ç¤¾ç¾¤å¨é©æä¸»æµæåæç¨æçæ¢æ§èç¤¾æå£åï¼ãéç¨®å£åç¶å¸¸å¨ LGBTQ+ ä½¿ç¨èæ¼ç¤¾ç¾¤åªé«å¹³å°ä¸çè²¼æä¸­è¡¨éåºä¾ãç¶èï¼éäºè¡¨éä¸¦ä¸ååæ¯å°æ¸æç¾¤å£åçç´æ¥è¡¨ç¾ãå®ååå«äºèªè¨è¤éæ§ï¼ä¾å¦æ£ç¨èªæè©å½å¤æ¨£æ§ï¼ï¼è®è¨±å¤å³çµ±çèªç¶èªè¨èçæ¹æ³é£ä»¥è¾¨è­ãå¨éé ç ç©¶ä¸­ï¼æåè¨­è¨äºä¸åæ··åæ¨¡åï¼ä½¿ç¨åç¥ç¶ç¶²è·¯ (GNN) åä¾èª Transformer çéåç·¨ç¢¼å¨è¡¨å¾µ (BERT)ï¼éæ¯ä¸åç¶éé åè¨ç·´çæ·±åº¦èªè¨æ¨¡åï¼ä»¥æåå°æ¸æç¾¤å£åè¾¨è­çåé¡æè½ãæåå¨ä¸åç¨æ¼å°æ¸æç¾¤å£åè¾¨è­çåºæºç¤¾ç¾¤åªé«è³æé (LGBTQ+ MiSSoM+) ä¸å°æåçæ¨¡åé²è¡å¯¦é©ãè©²è³æéåå«äº 5,789 ç¯ç±äººé¡è¨»è§£ç Reddit è²¼æï¼ä¾èªæ¼ LGBTQ+ ç subredditãæåçåæ³è½å¤ ééå¨å¤§éçåå§è³æä¸é²è¡é è¨ç·´ä¾èåé±èçèªè¨å·®ç°ï¼åæä¹åèè½å°å¼å­¸ç¿ï¼ä»¥å±åéç¼æ¨ç±¤è¨ç·´è³æåæªæ¨ç±¤æ¸¬è©¦è³æçè¡¨å¾µãRoBERTa-GCN æ¨¡åéå°äº 0.86 çæºç¢ºçå 0.86 ç F1 åæ¸ï¼å¨é æ¸¬ LGBTQ+ å°æ¸æç¾¤å£åæ¹é¢è¶è¶äºå¶ä»åºç·æ¨¡åçæè½ãå¨ç¤¾ç¾¤åªé«ä¸å°å°æ¸æç¾¤å£åè¡¨éçé æ¸¬æ¹åï¼å¯ä»¥å°è´æ¸ä½å¥åº·ä»å¥æªæ½ï¼ä»¥æ¹å LGBTQ+ æç¾¤çç¦ç¥ï¼èéåæç¾¤æå¾é«çå£åæææ§å¥åº·åé¡ç¼ççã</paragraph>

##### **KAAE: Numerical Reasoning for Knowledge Graphs via Knowledge-aware Attributes Learning**
2411.12950v2 by Ming Yin, Qiang Zhou, Zongsheng Cao, Mei Li

Numerical reasoning is pivotal in various artificial intelligence
applications, such as natural language processing and recommender systems,
where it involves using entities, relations, and attribute values (e.g.,
weight, length) to infer new factual relations (e.g., the Nile is longer than
the Amazon). However, existing approaches encounter two critical challenges in
modeling: (1) semantic relevance-the challenge of insufficiently capturing the
necessary contextual interactions among entities, relations, and numerical
attributes, often resulting in suboptimal inference; and (2) semantic
ambiguity-the difficulty in accurately distinguishing ordinal relationships
during numerical reasoning, which compromises the generation of high-quality
samples and limits the effectiveness of contrastive learning. To address these
challenges, we propose the novel Knowledge-Aware Attributes Embedding model
(KAAE) for knowledge graph embeddings in numerical reasoning. Specifically, to
overcome the challenge of semantic relevance, we introduce a
Mixture-of-Experts-Knowledge-Aware (MoEKA) Encoder, designed to integrate the
semantics of entities, relations, and numerical attributes into a joint
semantic space. To tackle semantic ambiguity, we implement a new ordinal
knowledge contrastive learning (OKCL) strategy that generates high-quality
ordinal samples from the original data with the aid of ordinal relations,
capturing fine-grained semantic nuances essential for accurate numerical
reasoning. Experiments on three public benchmark datasets demonstrate the
superior performance of KAAE across various attribute value distributions.

æè¦ï¼æ¸å¼æ¨çå¨åç¨®äººå·¥æºæ§æç¨ä¸­è³ééè¦ï¼ä¾å¦èªç¶èªè¨èçåæ¨è¦ç³»çµ±ï¼å¶ä¸­æ¶åä½¿ç¨å¯¦é«ãéä¿åå±¬æ§å¼ï¼ä¾å¦ï¼ééãé·åº¦ï¼ä¾æ¨è«æ°çäºå¯¦éä¿ï¼ä¾å¦ï¼å°¼ç¾æ²³æ¯äºé¦¬éæ²³é·ï¼ãç¶èï¼ç¾ææ¹æ³å¨å»ºæ¨¡ä¸­éå°å©åééµææ°ï¼ï¼1ï¼èªç¾©ç¸éæ§ - ç¡æ³ååææå¯¦é«ãéä¿åæ¸å¼å±¬æ§ä¹éå¿è¦çä¸ä¸æäº¤äºçææ°ï¼éå¸¸å°è´æ¬¡åªæ¨çï¼ä»¥åï¼2ï¼èªç¾©æ­§ç¾© - å¨æ¸å¼æ¨çæéæºç¢ºåååºæ¸éä¿çé£åº¦ï¼éææå®³é«åè³ªæ¨£æ¬çç¢çä¸¦éå¶å°æ¯å­¸ç¿çæææ§ãçºäºæå°éäºææ°ï¼æåæåºäºç¨æ¼æ¸å¼æ¨ççç¥è­åè­åµå¥çæ°åç¥è­æç¥å±¬æ§åµå¥æ¨¡å (KAAE)ãå·é«ä¾èªªï¼çºäºåæèªç¾©ç¸éæ§çææ°ï¼æåå¼å¥äºä¸åæ··åå°å®¶ç¥è­æç¥ (MoEKA) ç·¨ç¢¼å¨ï¼æ¨å¨å°å¯¦é«ãéä¿åæ¸å¼å±¬æ§çèªç¾©æ´åå°ä¸åè¯åèªç¾©ç©ºéä¸­ãçºäºæå°èªç¾©æ­§ç¾©ï¼æåå¯¦æ½äºä¸ç¨®æ°çåºæ¸ç¥è­å°æ¯å­¸ç¿ (OKCL) ç­ç¥ï¼è©²ç­ç¥å©ç¨åºæ¸éä¿å¾åå§æ¸æä¸­çæé«åè³ªåºæ¸æ¨£æ¬ï¼ææå°æºç¢ºæ¸å¼æ¨çè³ééè¦çç´°ç·»èªç¾©å·®ç°ãå¨ä¸åå¬éåºæºæ¸æéä¸çå¯¦é©è­æäº KAAE å¨åç¨®å±¬æ§å¼åä½ä¸­çåªç°æ§è½ã

##### **Neurosymbolic Graph Enrichment for Grounded World Models**
2411.12671v1 by Stefano De Giorgis, Aldo Gangemi, Alessandro Russo

The development of artificial intelligence systems capable of understanding
and reasoning about complex real-world scenarios is a significant challenge. In
this work we present a novel approach to enhance and exploit LLM reactive
capability to address complex problems and interpret deeply contextual
real-world meaning. We introduce a method and a tool for creating a multimodal,
knowledge-augmented formal representation of meaning that combines the
strengths of large language models with structured semantic representations.
Our method begins with an image input, utilizing state-of-the-art large
language models to generate a natural language description. This description is
then transformed into an Abstract Meaning Representation (AMR) graph, which is
formalized and enriched with logical design patterns, and layered semantics
derived from linguistic and factual knowledge bases. The resulting graph is
then fed back into the LLM to be extended with implicit knowledge activated by
complex heuristic learning, including semantic implicatures, moral values,
embodied cognition, and metaphorical representations. By bridging the gap
between unstructured language models and formal semantic structures, our method
opens new avenues for tackling intricate problems in natural language
understanding and reasoning.

æè¦ï¼äººå·¥æºè½ç³»çµ±çç¼å±è½å¤ çè§£ä¸¦æ¨çè¤éççå¯¦ä¸çå ´æ¯æ¯ä¸åéå¤§çææ°ãå¨éé å·¥ä½ä¸­ï¼æåæåºäºä¸ç¨®æ°ç©çæ¹æ³ä¾å¢å¼·åå©ç¨ LLM åæè½åï¼ä»¥è§£æ±ºè¤éçåé¡ä¸¦è§£éæ·±å±¤çèªå¢çå¯¦ä¸çæç¾©ãæåä»ç´¹äºä¸ç¨®æ¹æ³åå·¥å·ï¼ç¨æ¼å»ºç«å¤æ¨¡æãç¥è­å¢å¼·çæç¾©å½¢å¼åè¡¨ç¤ºï¼çµåäºå¤§åèªè¨æ¨¡åèçµæ§åèªç¾©è¡¨ç¤ºçåªé»ãæåçæ¨¡åå¾å½±åè¼¸å¥éå§ï¼å©ç¨æåé²çå¤§åèªè¨æ¨¡åä¾ç¢çèªç¶èªè¨æè¿°ãç¶å¾å°æ­¤æè¿°è½æçºæ½è±¡æç¾©è¡¨ç¤º (AMR) åå½¢ï¼ä¸¦ä½¿ç¨éè¼¯è¨­è¨æ¨¡å¼é²è¡å½¢å¼ååè±å¯ï¼ä»¥åå¾èªè¨åäºå¯¦ç¥è­åº«ä¸­è¡ççåå±¤èªç¾©ãç¶å¾å°çµæåå½¢åé¥å° LLMï¼ä»¥æ´å LLM ä¸­ç±è¤éçåç¼å¼å­¸ç¿æåç¨çå§é±ç¥è­ï¼åæ¬èªç¾©èæ¶µãéå¾·å¹å¼ãå·èº«èªç¥åé±å»è¡¨ç¤ºãæåçæ¨¡åééå½åéçµæ§åèªè¨æ¨¡åèå½¢å¼èªç¾©çµæ§ä¹éçå·®è·ï¼çºè§£æ±ºèªç¶èªè¨çè§£åæ¨çä¸­çè¤éåé¡éé¢äºæ°çéå¾ã

##### **Instant Policy: In-Context Imitation Learning via Graph Diffusion**
2411.12633v1 by Vitalis Vosylius, Edward Johns

Following the impressive capabilities of in-context learning with large
transformers, In-Context Imitation Learning (ICIL) is a promising opportunity
for robotics. We introduce Instant Policy, which learns new tasks instantly
(without further training) from just one or two demonstrations, achieving ICIL
through two key components. First, we introduce inductive biases through a
graph representation and model ICIL as a graph generation problem with a
learned diffusion process, enabling structured reasoning over demonstrations,
observations, and actions. Second, we show that such a model can be trained
using pseudo-demonstrations - arbitrary trajectories generated in simulation -
as a virtually infinite pool of training data. Simulated and real experiments
show that Instant Policy enables rapid learning of various everyday robot
tasks. We also show how it can serve as a foundation for cross-embodiment and
zero-shot transfer to language-defined tasks. Code and videos are available at
https://www.robot-learning.uk/instant-policy.

æè¦ï¼ç¹¼å¤§åTransformerå¨æå¢å­¸ç¿ä¸­è¡¨ç¾åºä»¤äººå°è±¡æ·±å»çè½åå¾ï¼æå¢æ¨¡ä»¿å­¸ç¿ (ICIL) æçºäºæ©å¨äººé åä¸­ä¸åæåéçæ©æãæåå¼å¥äºå³æç­ç¥ï¼å®åå¾ä¸æå©æ¬¡ç¤ºç¯ä¸­ç«å³å­¸ç¿æ°ä»»åï¼ç¡éé²ä¸æ­¥è¨ç·´ï¼ï¼ä¸¦ééå©åééµçµæé¨åå¯¦ç¾ ICILãé¦åï¼æåééåå½¢è¡¨ç¤ºåæ¨¡å ICIL å¼å¥æ­¸ç´åå·®ï¼ä¸¦å°å¶ä½çºå·æå­¸ç¿æ´æ£éç¨çåå½¢çæåé¡ï¼å¾èè½å¤ å°ç¤ºç¯ãè§å¯ååä½é²è¡çµæ§åæ¨çãå¶æ¬¡ï¼æåå±ç¤ºäºéç¨®æ¨¡åå¯ä»¥ä½¿ç¨å½ç¤ºç¯é²è¡è¨ç·´ï¼èå½ç¤ºç¯æ¯æ¨¡æ¬ä¸­ç¢ççä»»æè»è·¡ï¼å¯ç¨ä½å¹¾ä¹ç¡éçè¨ç·´æ¸ææ± ãæ¨¡æ¬åçå¯¦å¯¦é©è¡¨æï¼å³æç­ç¥è½å¤ å¿«éå­¸ç¿åç¨®æ¥å¸¸æ©å¨äººä»»åãæåéå±ç¤ºäºå®å¦ä½ä½çºè·¨å·èº«åé¶æ¬¡å³è¼¸å°èªè¨å®ç¾©ä»»åçåºç¤ãä»£ç¢¼åå½±çå¯å¨ https://www.robot-learning.uk/instant-policy åå¾ã

##### **Bias-Free Sentiment Analysis through Semantic Blinding and Graph Neural Networks**
2411.12493v2 by Hubert Plisiecki

This paper introduces the Semantic Propagation Graph Neural Network (SProp
GNN), a machine learning sentiment analysis (SA) architecture that relies
exclusively on syntactic structures and word-level emotional cues to predict
emotions in text. By semantically blinding the model to information about
specific words, it is robust to biases such as political or gender bias that
have been plaguing previous machine learning-based SA systems. The SProp GNN
shows performance superior to lexicon-based alternatives such as VADER and
EmoAtlas on two different prediction tasks, and across two languages.
Additionally, it approaches the accuracy of transformer-based models while
significantly reducing bias in emotion prediction tasks. By offering improved
explainability and reducing bias, the SProp GNN bridges the methodological gap
between interpretable lexicon approaches and powerful, yet often opaque, deep
learning models, offering a robust tool for fair and effective emotion analysis
in understanding human behavior through text.

æè¦ï¼æ¬æä»ç´¹äºèªç¾©å³æ­åç¥ç¶ç¶²è·¯ (SProp GNN)ï¼éæ¯ä¸ç¨®æ©å¨å­¸ç¿æç·åæ (SA) æ¶æ§ï¼å°éä¾è³´å¥æ³çµæ§åè©å½å±¤ç´çæç·ç·ç´¢ä¾é æ¸¬æå­ä¸­çæç·ãééå¨èªç¾©ä¸è®æ¨¡åå°ç¹å®å­è©çè³è¨è¦èä¸è¦ï¼å®è½æææ¶é¤æ¿æ²»ææ§å¥åè¦ç­åèª¤ï¼éäºåèª¤ä¸ç´å°æ¾èååçæ©å¨å­¸ç¿å¼ SA ç³»çµ±ãSProp GNN å¨å©é ä¸åçé æ¸¬ä»»ååå©ç¨®èªè¨ä¸çè¡¨ç¾é½åªæ¼åºæ¼è©å½åº«çæ¿ä»£æ¹æ¡ï¼ä¾å¦ VADER å EmoAtlasãæ­¤å¤ï¼å®å¨å¤§å¹æ¸å°æç·é æ¸¬ä»»åä¸­çåèª¤åæï¼ä¹æ¥è¿äºåºæ¼è½æå¨çæ¨¡åçæºç¢ºåº¦ãééæä¾æ´å¥½çå¯è§£éæ§ä¸¦æ¸å°åèª¤ï¼SProp GNN æ­èµ·äºå¯è©®éè©å½æ¹æ³èå¼·å¤§ä½ç¶å¸¸ä¸éæçæ·±åº¦å­¸ç¿æ¨¡åä¹éçæ¹æ³è«é´»æºï¼æä¾äºä¸åå¼·å¥çå·¥å·ï¼å¯ä»¥ééæå­çè§£äººé¡è¡çºï¼é²è¡å¬å¹³ä¸ææçåæã

##### **Neon: News Entity-Interaction Extraction for Enhanced Question Answering**
2411.12449v2 by Sneha Singhania, Silviu Cucerzan, Allen Herring, Sujay Kumar Jauhar

Capturing fresh information in near real-time and using it to augment
existing large language models (LLMs) is essential to generate up-to-date,
grounded, and reliable output. This problem becomes particularly challenging
when LLMs are used for informational tasks in rapidly evolving fields, such as
Web search related to recent or unfolding events involving entities, where
generating temporally relevant responses requires access to up-to-the-hour news
sources. However, the information modeled by the parametric memory of LLMs is
often outdated, and Web results from prototypical retrieval systems may fail to
capture the latest relevant information and struggle to handle conflicting
reports in evolving news. To address this challenge, we present the NEON
framework, designed to extract emerging entity interactions -- such as events
or activities -- as described in news articles. NEON constructs an
entity-centric timestamped knowledge graph that captures such interactions,
thereby facilitating enhanced QA capabilities related to news events. Our
framework innovates by integrating open Information Extraction (openIE) style
tuples into LLMs to enable in-context retrieval-augmented generation. This
integration demonstrates substantial improvements in QA performance when
tackling temporal, entity-centric search queries. Through NEON, LLMs can
deliver more accurate, reliable, and up-to-date responses.

æè¦ï¼ææè¿ä¹å¯¦æçææ°è³è¨ï¼ä¸¦å©ç¨å®ä¾æ´åç¾æçå¤§åèªè¨æ¨¡å (LLM)ï¼å°æ¼ç¢çå³æãææ ¹æä¸å¯é çè¼¸åºè³ééè¦ãç¶ LLM è¢«ç¨æ¼å¿«éæ¼åçé åä¸­çè¨æ¯ä»»åæï¼éååé¡æè®å¾ç¹å¥å·æææ°æ§ï¼ä¾å¦èæ¶åå¯¦é«çè¿æææ­£å¨ç¼ççäºä»¶ç¸éçç¶²è·¯æå°ï¼å¨éç¨®ææ³ä¸ï¼ç¢çæéç¸éçåæéè¦åå¾ææ°çæ°èä¾æºãç¶èï¼LLM çåæ¸è¨æ¶é«å»ºæ¨¡çè³è¨ç¶å¸¸éæï¼èååæª¢ç´¢ç³»çµ±çç¶²è·¯çµæå¯è½ç¡æ³ææææ°çç¸éè³è¨ï¼ä¸¦ä¸é£ä»¥èçæ¼åä¸­çæ°èä¸­çç¸äºçç¾çå ±å°ãçºäºæå°éåææ°ï¼æåæåºäº NEON æ¡æ¶ï¼æ¨å¨èåæ°èå¯¦é«äºåï¼ä¾å¦äºä»¶ææ´»åï¼ï¼å¦æ°èæç« ä¸­ææè¿°çãNEON å»ºæ§äºä¸åä»¥å¯¦é«çºä¸­å¿çå¸¶æéæ³è¨çç¥è­åè­ï¼ç¨ä¾æææ­¤é¡äºåï¼å¾èä¿é²èæ°èäºä»¶ç¸éçå¢å¼·å¼åç­è½åãæåçæ¡æ¶ééå°éæ¾è³è¨èå (openIE) é¢¨æ ¼åçµæ´åå° LLM ä¸­ï¼ä»¥åç¨æå¢å§æª¢ç´¢å¢å¼·å¼ç¢çï¼é²èåµæ°ãç¶èçæéãä»¥å¯¦é«çºä¸­å¿çæå°æ¥è©¢æï¼éç¨®æ´åé¡¯ç¤ºåºåç­æè½çé¡¯èæåãéé NEONï¼LLM å¯ä»¥æä¾æ´æºç¢ºãå¯é ä¸ææ°çåæã

##### **GRL-Prompt: Towards Knowledge Graph based Prompt Optimization via Reinforcement Learning**
2411.14479v1 by Yuze Liu, Tingjie Liu, Tiehua Zhang, Youhua Xia, Jinze Wang, Zhishu Shen, Jiong Jin, Fei Richard Yu

Large language models (LLMs) have demonstrated impressive success in a wide
range of natural language processing (NLP) tasks due to their extensive general
knowledge of the world. Recent works discovered that the performance of LLMs is
heavily dependent on the input prompt. However, prompt engineering is usually
done manually in a trial-and-error fashion, which can be labor-intensive and
challenging in order to find the optimal prompts. To address these problems and
unleash the utmost potential of LLMs, we propose a novel LLMs-agnostic
framework for prompt optimization, namely GRL-Prompt, which aims to
automatically construct optimal prompts via reinforcement learning (RL) in an
end-to-end manner. To provide structured action/state representation for
optimizing prompts, we construct a knowledge graph (KG) that better encodes the
correlation between the user query and candidate in-context examples.
Furthermore, a policy network is formulated to generate the optimal action by
selecting a set of in-context examples in a rewardable order to construct the
prompt. Additionally, the embedding-based reward shaping is utilized to
stabilize the RL training process. The experimental results show that
GRL-Prompt outperforms recent state-of-the-art methods, achieving an average
increase of 0.10 in ROUGE-1, 0.07 in ROUGE-2, 0.07 in ROUGE-L, and 0.05 in
BLEU.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨å»£æ³çèªç¶èªè¨èç (NLP) ä»»åä¸­å±ç¾åºä»¤äººå°è±¡æ·±å»çæåï¼éæ­¸åæ¼å®åå°ä¸ççå»£æ³ä¸è¬ç¥è­ãæè¿çç ç©¶ç¼ç¾ï¼LLM çæè½é«åº¦ä¾è³´æ¼è¼¸å¥æç¤ºãç¶èï¼æç¤ºå·¥ç¨éå¸¸ä»¥è©¦é¯çæ¹å¼æåå®æï¼éå¨å°æ¾æä½³æç¤ºæå¯è½æèè²»å¤§éäººåä¸å·æææ°æ§ãçºäºè§£æ±ºéäºåé¡ä¸¦ç¼æ® LLM çæå¤§æ½åï¼æåæåºäºä¸åæ°ç LLM ä¸å¯ç¥æ¡æ¶ï¼ç¨æ¼æç¤ºæä½³åï¼å³ GRL-Promptï¼å¶æ¨å¨ééå¼·åå­¸ç¿ (RL) ä»¥ç«¯å°ç«¯çæ¹å¼èªåå»ºæ§æä½³æç¤ºãçºäºæä¾çµæ§åçåä½/çæè¡¨ç¤ºä»¥æä½³åæç¤ºï¼æåå»ºæ§äºä¸åç¥è­åè­ (KG)ï¼å®è½æ´å¥½å°ç·¨ç¢¼ä½¿ç¨èæ¥è©¢èåé¸æå¢ç¯ä¾ä¹éçéè¯æ§ãæ­¤å¤ï¼æåå¶å®äºä¸åç­ç¥ç¶²è·¯ï¼ééä»¥å¯çåµçé åºé¸æä¸çµæå¢ç¯ä¾ä¾å»ºæ§æç¤ºï¼ä»¥ç¢çæä½³åä½ãæ­¤å¤ï¼æåå©ç¨åºæ¼åµå¥ççåµå¡é ä¾ç©©å® RL è¨ç·´éç¨ãå¯¦é©çµæé¡¯ç¤ºï¼GRL-Prompt åªæ¼æè¿çææ°æ¹æ³ï¼å¨ ROUGE-1 ä¸­å¹³åå¢å  0.10ï¼å¨ ROUGE-2 ä¸­å¢å  0.07ï¼å¨ ROUGE-L ä¸­å¢å  0.07ï¼å¨ BLEU ä¸­å¢å  0.05ã

##### **Just KIDDIN: Knowledge Infusion and Distillation for Detection of INdecent Memes**
2411.12174v1 by Rahul Garg, Trilok Padhi, Hemang Jain, Ugur Kursuncu, Ponnurangam Kumaraguru

Toxicity identification in online multimodal environments remains a
challenging task due to the complexity of contextual connections across
modalities (e.g., textual and visual). In this paper, we propose a novel
framework that integrates Knowledge Distillation (KD) from Large Visual
Language Models (LVLMs) and knowledge infusion to enhance the performance of
toxicity detection in hateful memes. Our approach extracts sub-knowledge graphs
from ConceptNet, a large-scale commonsense Knowledge Graph (KG) to be infused
within a compact VLM framework. The relational context between toxic phrases in
captions and memes, as well as visual concepts in memes enhance the model's
reasoning capabilities. Experimental results from our study on two hate speech
benchmark datasets demonstrate superior performance over the state-of-the-art
baselines across AU-ROC, F1, and Recall with improvements of 1.1%, 7%, and 35%,
respectively. Given the contextual complexity of the toxicity detection task,
our approach showcases the significance of learning from both explicit (i.e.
KG) as well as implicit (i.e. LVLMs) contextual cues incorporated through a
hybrid neurosymbolic approach. This is crucial for real-world applications
where accurate and scalable recognition of toxic content is critical for
creating safer online environments.

æè¦ï¼ç¶²è·¯å¤æ¨¡æç°å¢ä¸­çæ¯æ§è¾¨è­ï¼ç±æ¼æ¨¡æéï¼ä¾å¦æå­åè¦è¦ºï¼çèçµ¡éè¯è¤éï¼å æ­¤ä»æ¯ä¸é å·æææ°æ§çä»»åãå¨æ¬æä¸­ï¼æåæåºä¸åæ°ç©çæ¶æ§ï¼æ´åä¾èªå¤§åè¦è¦ºèªè¨æ¨¡å (LVLMs) çç¥è­è¸é¤¾ (KD) åç¥è­æ³¨å¥ï¼ä»¥å¢å¼·ä»æ¨è¿·å ä¸­æ¯æ§åµæ¸¬çæè½ãæåçåæ³å¾ ConceptNetï¼ä¸åå¤§åå¸¸è­ç¥è­åè­ (KG)ï¼ä¸­èåå­ç¥è­åï¼ä¸¦æ³¨å¥å°ä¸åç·æ¹ç VLM æ¶æ§ä¸­ãæ¨é¡åè¿·å ä¸­å·ææ¯æ§çè©å½ä¹éçéä¿èçµ¡ï¼ä»¥åè¿·å ä¸­çè¦è¦ºæ¦å¿µï¼å¢å¼·äºæ¨¡åçæ¨çè½åãæåå¨å©åä»æ¨è¨è«åºæºè³æéä¸é²è¡çç ç©¶çå¯¦é©çµæï¼è­æäºå¨ AU-ROCãF1 åå¬åçæ¹é¢ï¼æåçåæ³åªæ¼æåé²çåºæºï¼åå¥æåäº 1.1%ã7% å 35%ãéæ¼æ¯æ§åµæ¸¬ä»»åçèçµ¡è¤éæ§ï¼æåçåæ³å±ç¤ºäºå¾æç¢ºï¼ä¾å¦ KGï¼åé±å«ï¼ä¾å¦ LVLMsï¼èçµ¡ç·ç´¢ä¸­å­¸ç¿ï¼ä¸¦ééæ··åç¥ç¶ç¬¦èæ¹æ³æ´åèµ·ä¾çéè¦æ§ãéå°æ¼çå¯¦ä¸ççæç¨è³ééè¦ï¼å¨éäºæç¨ä¸­ï¼æºç¢ºä¸å¯æ´åçæ¯æ§å§å®¹è¾¨è­å°æ¼åµé æ´å®å¨çç¶²è·¯ç°å¢è³ééè¦ã

##### **Regret-Free Reinforcement Learning for LTL Specifications**
2411.12019v1 by Rupak Majumdar, Mahmoud Salamati, Sadegh Soudjani

Reinforcement learning (RL) is a promising method to learn optimal control
policies for systems with unknown dynamics. In particular, synthesizing
controllers for safety-critical systems based on high-level specifications,
such as those expressed in temporal languages like linear temporal logic (LTL),
presents a significant challenge in control systems research. Current RL-based
methods designed for LTL tasks typically offer only asymptotic guarantees,
which provide no insight into the transient performance during the learning
phase. While running an RL algorithm, it is crucial to assess how close we are
to achieving optimal behavior if we stop learning.
  In this paper, we present the first regret-free online algorithm for learning
a controller that addresses the general class of LTL specifications over Markov
decision processes (MDPs) with a finite set of states and actions. We begin by
proposing a regret-free learning algorithm to solve infinite-horizon
reach-avoid problems. For general LTL specifications, we show that the
synthesis problem can be reduced to a reach-avoid problem when the graph
structure is known. Additionally, we provide an algorithm for learning the
graph structure, assuming knowledge of a minimum transition probability, which
operates independently of the main regret-free algorithm.

æè¦ï¼å¼·åå­¸ç¿ (RL) æ¯ä¸ç¨®æå¸æçæ¹æ³ï¼å¯ä»¥å­¸ç¿æªç¥åæç³»çµ±çæä½³æ§å¶ç­ç¥ãç¹å¥æ¯ï¼åºæ¼é«éè¦ç¯ï¼ä¾å¦ç¨ç·æ§æåºéè¼¯ (LTL) ç­æåºèªè¨è¡¨éçè¦ç¯ï¼çºå®å¨ééµç³»çµ±åææ§å¶å¨ï¼éå¨æ§å¶ç³»çµ±ç ç©¶ä¸­æ¯ä¸åéå¤§ææ°ãç®åçåºæ¼ RL ç LTL ä»»åæ¹æ³éå¸¸åæä¾æ¼¸è¿ä¿è­ï¼éå¨å­¸ç¿éæ®µæ²ææä¾æ«ææè½çè¦è§£ãå¨å·è¡ RL æ¼ç®æ³æï¼å¦ææååæ­¢å­¸ç¿ï¼è©ä¼°æåè·é¢éææä½³è¡çºæå¤è¿è³ééè¦ãå¨æ¬æä¸­ï¼æåæåºäºç¬¬ä¸åç¡éºæ¾ç·ä¸æ¼ç®æ³ï¼ç¨æ¼å­¸ç¿ä¸åæ§å¶å¨ï¼è©²æ§å¶å¨è§£æ±ºäºé¦¬å¯å¤«æ±ºç­éç¨ (MDP) ä¸çä¸è¬é¡å¥ LTL è¦ç¯ï¼å¶ä¸­åå«æéççæååä½éåãæåé¦åæåºä¸åç¡éºæ¾å­¸ç¿æ¼ç®æ³ä¾è§£æ±ºç¡éæåå°éé¿ååé¡ãå°æ¼ä¸è¬ LTL è¦ç¯ï¼æåè¡¨æç¶åå½¢çµæ§å·²ç¥æï¼åæåé¡å¯ä»¥ç°¡åçºå°éé¿ååé¡ãæ­¤å¤ï¼æåæä¾äºä¸åæ¼ç®æ³ä¾å­¸ç¿åå½¢çµæ§ï¼åè¨­ç¥éæå°è½ç§»æ©çï¼å®ç¨ç«æ¼ä¸»è¦çç¡éºæ¾æ¼ç®æ³éä½ã

##### **Semantic-Geometric-Physical-Driven Robot Manipulation Skill Transfer via Skill Library and Tactile Representation**
2411.11714v1 by Mingchao Qi, Yuanjin Li, Xing Liu, Zhengxiong Liu, Panfeng Huang

Deploying robots in open-world environments involves complex tasks
characterized by long sequences and rich interactions, necessitating efficient
transfer of robotic skills across diverse and complex scenarios. To address
this challenge, we propose a skill library framework based on knowledge graphs,
which endows robots with high-level skill awareness and spatial semantic
understanding. The framework hierarchically organizes operational knowledge by
constructing a "task graph" and a "scene graph" to represent task and scene
semantic information, respectively. We introduce a "state graph" to facilitate
interaction between high-level task planning and low-level scene information.
Furthermore, we propose a hierarchical transfer framework for operational
skills. At the task level, the framework integrates contextual learning and
chain-of-thought prompting within a four-stage prompt paradigm, leveraging
large language models' (LLMs) reasoning and generalization capabilities to
achieve task-level subtask sequence transfer. At the motion level, an adaptive
trajectory transfer method is developed using the A* algorithm and the skill
library, enabling motion-level adaptive trajectory transfer. At the physical
level, we introduce an adaptive contour extraction and posture perception
method based on tactile perception. This method dynamically obtains
high-precision contour and posture information from visual-tactile texture data
and adjusts transferred skills, such as contact positions and postures, to
ensure effectiveness in new environments. Experimental results validate the
effectiveness of the proposed methods. Project
website:https://github.com/MingchaoQi/skill_transfer

æè¦ï¼<paragraph>å¨å¼æ¾ä¸çç¯å¢ä¸­é¨ç½²æºå¨äººæ¶åå¤æçä»»å¡ï¼å¶ç¹ç¹æ¯åºåé¿ãäº¤äºä¸°å¯ï¼éè¦å¨ä¸åä¸å¤æçåºæ¯ä¸­é«æå°è½¬ç§»æºå¨äººæè½ãä¸ºäºåºå¯¹è¿ä¸ææï¼æä»¬æåºä¸ä¸ªåºäºç¥è¯å¾è°±çæè½åºæ¡æ¶ï¼å®èµäºæºå¨äººé«çº§æè½æè¯åç©ºé´è¯­ä¹çè§£ãè¯¥æ¡æ¶éè¿æå»ºâä»»å¡å¾âåâåºæ¯å¾âæ¥åå±ç»ç»æä½ç¥è¯ï¼åå«è¡¨ç¤ºä»»å¡ååºæ¯è¯­ä¹ä¿¡æ¯ãæä»¬å¼å¥ä¸ä¸ªâç¶æå¾âæ¥ä¿è¿é«çº§ä»»å¡è§ååä½çº§åºæ¯ä¿¡æ¯ä¹é´çäº¤äºãæ­¤å¤ï¼æä»¬æåºäºä¸ä¸ªæä½æè½çåå±è½¬ç§»æ¡æ¶ãå¨ä»»å¡å±é¢ï¼è¯¥æ¡æ¶å¨ä¸ä¸ªåé¶æ®µæç¤ºèå¼ä¸­éæäºä¸ä¸æå­¦ä¹ åææ³é¾æç¤ºï¼å©ç¨å¤§è¯­è¨æ¨¡å (LLM) çæ¨çåæ³åè½åæ¥å®ç°ä»»å¡çº§å­ä»»å¡åºåè½¬ç§»ãå¨è¿å¨å±é¢ï¼ä½¿ç¨ A* ç®æ³åæè½åºå¼åäºä¸ç§èªéåºè½¨è¿¹è½¬ç§»æ¹æ³ï¼å®ç°è¿å¨çº§èªéåºè½¨è¿¹è½¬ç§»ãå¨ç©çå±é¢ï¼æä»¬å¼å¥äºä¸ç§åºäºè§¦è§æç¥çèªéåºè½®å»æååå§¿ææç¥æ¹æ³ãè¯¥æ¹æ³ä»è§è§è§¦è§çº¹çæ°æ®ä¸­å¨æè·åé«ç²¾åº¦çè½®å»åå§¿æä¿¡æ¯ï¼å¹¶è°æ´è½¬ç§»çæè½ï¼ä¾å¦æ¥è§¦ä½ç½®åå§¿æï¼ä»¥ç¡®ä¿å¨æ°çç¯å¢ä¸­ææãå®éªç»æéªè¯äºææåºæ¹æ³çæææ§ãé¡¹ç®ç½ç«ï¼https://github.com/MingchaoQi/skill_transfer</paragraph>

##### **Addressing Hallucinations in Language Models with Knowledge Graph Embeddings as an Additional Modality**
2411.11531v1 by Viktoriia Chekalina, Anton Razzigaev, Elizaveta Goncharova, Andrey Kuznetsov

In this paper we present an approach to reduce hallucinations in Large
Language Models (LLMs) by incorporating Knowledge Graphs (KGs) as an additional
modality. Our method involves transforming input text into a set of KG
embeddings and using an adapter to integrate these embeddings into the language
model space, without relying on external retrieval processes.
  To facilitate this, we created WikiEntities, a dataset containing over 3
million Wikipedia texts annotated with entities from Wikidata and their
corresponding embeddings from PyTorch-BigGraph. This dataset serves as a
valuable resource for training Entity Linking models and adapting the described
method to various LLMs using specialized adapters.
  Our method does not require fine-tuning of the language models themselves;
instead, we only train the adapter. This ensures that the model's performance
on other tasks is not affected. We trained an adapter for the Mistral 7B, LLaMA
2-7B (chat), and LLaMA 3-8B (instruct) models using this dataset and
demonstrated that our approach improves performance on the HaluEval, True-False
benchmarks and FEVER dataset. The results indicate that incorporating KGs as a
new modality can effectively reduce hallucinations and improve the factual
accuracy of language models, all without the need for external retrieval.

æè¦ï¼<paragraph>å¨æ¬æä¸­ï¼æåæåºäºä¸ç¨®æ¹æ³ï¼ééå°ç¥è­åè­ (KG) ä½çºéå æ¹å¼ç´å¥å¤§åèªè¨æ¨¡å (LLM)ï¼ä»¥æ¸å°å¹»è¦ºãæåçåæ³åæ¬å°è¼¸å¥æå­è½ææä¸çµ KG åµå¥ï¼ä¸¦ä½¿ç¨é©éå¨å°éäºåµå¥æ´åå°èªè¨æ¨¡åç©ºéï¼èç¡éä¾è³´å¤é¨æª¢ç´¢ç¨åºã
çºäºä¿é²éä¸é»ï¼æåå»ºç«äº WikiEntitiesï¼éæ¯ä¸ååå«è¶é 300 è¬åç¶­åºç¾ç§æå­çè³æéï¼å¶ä¸­éæä¾èª Wikidata çå¯¦é«è¨»è§£ï¼ä»¥åå®åä¾èª PyTorch-BigGraph çå°æåµå¥ãæ­¤è³æéä½çºè¨ç·´å¯¦é«é£çµæ¨¡ååä½¿ç¨å°éé©éå¨å°æè¿°æ¹æ³èª¿æ´å°åç¨® LLM çå¯¶è²´è³æºã
æåçåæ³ä¸éè¦å¾®èª¿èªè¨æ¨¡åæ¬èº«ï¼ç¸åï¼æååªè¨ç·´é©éå¨ãéç¢ºä¿äºæ¨¡åå¨å¶ä»ä»»åä¸çæè½ä¸åå½±é¿ãæåä½¿ç¨æ­¤è³æéè¨ç·´äº Mistral 7BãLLaMA 2-7B (èå¤©) å LLaMA 3-8B (æä»¤) æ¨¡åçé©éå¨ï¼ä¸¦è­æäºæåçåæ³æ¹åäº HaluEvalãçååºæºå FEVER è³æéçæè½ãçµæè¡¨æï¼å° KG ä½çºä¸ç¨®æ°æ¹å¼ç´å¥å¯ä»¥æææ¸å°å¹»è¦ºï¼ä¸¦æé«èªè¨æ¨¡åçäºå¯¦æºç¢ºæ§ï¼èç¡éå¤é¨æª¢ç´¢ã</paragraph>

##### **RPN 2: On Interdependence Function Learning Towards Unifying and Advancing CNN, RNN, GNN, and Transformer**
2411.11162v1 by Jiawei Zhang

This paper builds upon our previous work on the Reconciled Polynomial Network
(RPN). The original RPN model was designed under the assumption of input data
independence, presuming the independence among both individual instances within
data batches and attributes in each data instance. However, this assumption
often proves invalid for function learning tasks involving complex,
interdependent data such as language, images, time series, and graphs. Ignoring
such data interdependence may inevitably lead to significant performance
degradation.
  To overcome these limitations, we introduce the new Reconciled Polynomial
Network (version 2), namely RPN 2, in this paper. By incorporating data and
structural interdependence functions, RPN 2 explicitly models data
interdependence via new component functions in its architecture.
  This enhancement not only significantly improves RPN 2's learning performance
but also substantially expands its unifying potential, enabling it to encompass
a broader range of contemporary dominant backbone models within its canonical
representation. These backbones include, but are not limited to, convolutional
neural networks (CNNs), recurrent neural networks (RNNs), graph neural networks
(GNNs), and Transformers. Our analysis reveals that the fundamental
distinctions among these backbone models primarily stem from their diverse
approaches to defining the interdependence functions. Furthermore, this unified
representation opens up new opportunities for designing innovative
architectures with the potential to surpass the performance of these dominant
backbones.

æè¦ï¼æ¬æå»ºç«å¨æä»¬ååå³äºåè°å¤é¡¹å¼ç½ç» (RPN) çå·¥ä½ä¹ä¸ãæåç RPN æ¨¡åæ¯å¨è¾å¥æ°æ®ç¬ç«æ§çåè®¾ä¸è®¾è®¡çï¼åå®æ°æ®æ¹æ¬¡ä¸­åä¸ªå®ä¾ä¹é´çç¬ç«æ§ä»¥åæ¯ä¸ªæ°æ®å®ä¾ä¸­çå±æ§ä¹é´çç¬ç«æ§ãç¶èï¼å¯¹äºæ¶åå¤æç¸äºä¾èµæ°æ®ï¼ä¾å¦è¯­è¨ãå¾åãæ¶é´åºååå¾å½¢ï¼çåè½å­¦ä¹ ä»»å¡ï¼è¿ç§åè®¾éå¸¸è¢«è¯ææ¯æ æçãå¿½ç¥æ­¤ç±»æ°æ®ç¸äºä¾èµæ§ä¸å¯é¿åå°ä¼å¯¼è´æ§è½æ¾çä¸éã
ä¸ºäºåæè¿äºéå¶ï¼æä»¬å¨æ¬æä¸­å¼å¥äºæ°çåè°å¤é¡¹å¼ç½ç»ï¼çæ¬ 2ï¼ï¼å³ RPN 2ãéè¿ç»åæ°æ®åç»æç¸äºä¾èµå½æ°ï¼RPN 2 éè¿å¶æ¶æä¸­çæ°ç»ä»¶å½æ°æç¡®å°å¯¹æ°æ®ç¸äºä¾èµæ§è¿è¡å»ºæ¨¡ã
è¿ç§å¢å¼ºä¸ä»æ¾çæé«äº RPN 2 çå­¦ä¹ æ§è½ï¼èä¸è¿å¤§å¹æ©å±äºå¶ç»ä¸æ½åï¼ä½¿å¶è½å¤å¨å¶è§èè¡¨ç¤ºä¸­åå«æ´å¹¿æ³çå½ä»£ä¸»å¹²æ¨¡åãè¿äºä¸»å¹²åæ¬ä½ä¸éäºå·ç§¯ç¥ç»ç½ç» (CNN)ãå¾ªç¯ç¥ç»ç½ç» (RNN)ãå¾ç¥ç»ç½ç» (GNN) å Transformerãæä»¬çåæè¡¨æï¼è¿äºä¸»å¹²æ¨¡åä¹é´çæ ¹æ¬åºå«ä¸»è¦æºäºå®ä»¬å®ä¹ç¸äºä¾èµå½æ°çä¸åæ¹æ³ãæ­¤å¤ï¼è¿ç§ç»ä¸è¡¨ç¤ºä¸ºè®¾è®¡åæ°æ¶æå¼è¾äºæ°çæºä¼ï¼è¿äºæ¶ææå¯è½è¶è¶è¿äºä¸»å¹²çæ§è½ã

##### **LLaSA: Large Language and Structured Data Assistant**
2411.14460v1 by Yao Xu, Shizhu He, Zeng Xiangrong, Jiabei Chen, Guang Liu, Bingning Wang, Jun Zhao, Kang Liu

Structured data, such as tables, graphs, and databases, play a critical role
in plentiful NLP tasks such as question answering and dialogue system.
Recently, inspired by Vision-Language Models, Graph Neutral Networks (GNNs)
have been introduced as an additional modality into the input of Large Language
Models (LLMs) to improve their performance on Structured Knowledge Grounding
(SKG) tasks. However, those GNN-enhanced LLMs have the following limitations:
(1) They employ diverse GNNs to model varying types of structured data,
rendering them unable to uniformly process various forms of structured data.
(2) The pretraining of GNNs is coupled with specific LLMs, which prevents GNNs
from fully aligning with the textual space and limits their adaptability to
other LLMs. To address these issues, we propose \textbf{L}arge
\textbf{L}anguage and \textbf{S}tructured Data \textbf{A}ssistant (LLaSA), a
general framework for enhancing LLMs' ability to handle structured data.
Specifically, we represent various types of structured data in a unified
hypergraph format, and use self-supervised learning to pretrain a hypergraph
encoder, and a G-Former compressing encoded hypergraph representations with
cross-attention. The compressed hypergraph representations are appended to the
serialized inputs during training and inference stages of LLMs. Experimental
results on multiple SKG tasks show that our pretrained hypergraph encoder can
adapt to various LLMs and enhance their ability to process different types of
structured data. Besides, LLaSA, with LoRA fine-tuning, outperforms previous
SOTA method using full parameters tuning.

æè¦ï¼<paragraph>çµæ§åè³æï¼ä¾å¦è¡¨æ ¼ãåè¡¨åè³æåº«ï¼å¨è±å¯ç NLP ä»»åä¸­æ®æ¼èè³ééè¦çè§è²ï¼ä¾å¦åç­åå°è©±ç³»çµ±ã
æè¿ï¼åå°è¦è¦ºèªè¨æ¨¡åçåç¼ï¼åå½¢ä¸­ç«ç¶²è·¯ (GNN) å·²è¢«å¼å¥å¤§åèªè¨æ¨¡å (LLM) çè¼¸å¥ä¸­ä½çºä¸ç¨®é¡å¤çæ¨¡å¼ï¼ä»¥æåå¶å¨çµæ§åç¥è­åºç¤ (SKG) ä»»åä¸çè¡¨ç¾ãç¶èï¼éäº GNN å¢å¼·ç LLM å·æä»¥ä¸éå¶ï¼
(1) å®åä½¿ç¨ä¸åç GNN ä¾å»ºæ¨¡åç¨®çµæ§åè³æé¡åï¼å°è´å®åç¡æ³çµ±ä¸èçåç¨®å½¢å¼ççµæ§åè³æã
(2) GNN çé è¨ç·´èç¹å®ç LLM çµåå¨ä¸èµ·ï¼éæé»æ­¢ GNN èææ¬ç©ºéå®å¨å°é½ï¼ä¸¦éå¶å¶é©æå¶ä» LLMãçºäºè§£æ±ºéäºåé¡ï¼æåæåºäº**L**arge **L**anguage and **S**tructured Data **A**ssistant (LLaSA)ï¼ä¸åç¨æ¼å¢å¼· LLM èççµæ§åè³æè½åçéç¨æ¡æ¶ã
å·é«ä¾èªªï¼æåä»¥çµ±ä¸çè¶åæ ¼å¼è¡¨ç¤ºåç¨®çµæ§åè³æé¡åï¼ä¸¦ä½¿ç¨èªæç£ç£å­¸ç¿ä¾é è¨ç·´è¶åç·¨ç¢¼å¨ï¼ä»¥åä½¿ç¨è·¨æ³¨æåå£ç¸®ç·¨ç¢¼è¶åè¡¨ç¤ºç G-Formerãå£ç¸®çè¶åè¡¨ç¤ºæéå å° LLM çè¨ç·´åæ¨è«éæ®µçåºååè¼¸å¥ä¸­ãå¤å SKG ä»»åçå¯¦é©çµæè¡¨æï¼æåé è¨ç·´çè¶åç·¨ç¢¼å¨å¯ä»¥é©æåç¨® LLMï¼ä¸¦å¢å¼·å¶èçä¸åé¡åçµæ§åè³æçè½åãæ­¤å¤ï¼LLaSA ä½¿ç¨ LoRA å¾®èª¿ï¼åªæ¼ä½¿ç¨å¨åæ¸å¾®èª¿çåå SOTA æ¹æ³ã</paragraph>

##### **Unveiling User Preferences: A Knowledge Graph and LLM-Driven Approach for Conversational Recommendation**
2411.14459v1 by Zhangchi Qiu, Linhao Luo, Shirui Pan, Alan Wee-Chung Liew

Conversational Recommender Systems (CRSs) aim to provide personalized
recommendations through dynamically capturing user preferences in interactive
conversations. Conventional CRSs often extract user preferences as hidden
representations, which are criticized for their lack of interpretability. This
diminishes the transparency and trustworthiness of the recommendation process.
Recent works have explored combining the impressive capabilities of Large
Language Models (LLMs) with the domain-specific knowledge of Knowledge Graphs
(KGs) to generate human-understandable recommendation explanations. Despite
these efforts, the integration of LLMs and KGs for CRSs remains challenging due
to the modality gap between unstructured dialogues and structured KGs.
Moreover, LLMs pre-trained on large-scale corpora may not be well-suited for
analyzing user preferences, which require domain-specific knowledge. In this
paper, we propose COMPASS, a plug-and-play framework that synergizes LLMs and
KGs to unveil user preferences, enhancing the performance and explainability of
existing CRSs. To address integration challenges, COMPASS employs a two-stage
training approach: first, it bridges the gap between the structured KG and
natural language through an innovative graph entity captioning pre-training
mechanism. This enables the LLM to transform KG entities into concise natural
language descriptions, allowing them to comprehend domain-specific knowledge.
Following, COMPASS optimizes user preference modeling via knowledge-aware
instruction fine-tuning, where the LLM learns to reason and summarize user
preferences from both dialogue histories and KG-augmented context. This enables
COMPASS to perform knowledge-aware reasoning and generate comprehensive and
interpretable user preferences that can seamlessly integrate with existing CRS
models for improving recommendation performance and explainability.

æè¦ï¼å°è©±å¼æ¨è¦ç³»çµ± (CRS) æ¨å¨ééåæææäºåå°è©±ä¸­çä½¿ç¨èåå¥½ï¼æä¾åäººåæ¨è¦ãå³çµ±ç CRS éå¸¸æå°ä½¿ç¨èåå¥½æ·åçºé±èå¼è¡¨å¾µï¼èå¶ç¼ºé»å¨æ¼ç¼ºä¹å¯è§£éæ§ï¼ééä½äºæ¨è¦ç¨å¼çéæåº¦åå¯ä¿¡åº¦ãæè¿çç ç©¶æ¢è¨å°å¤§åèªè¨æ¨¡å (LLM) çå¼·å¤§åè½èç¥è­åè­ (KG) çç¹å®é åç¥è­çµåï¼ä»¥ç¢çäººé¡å¯ä»¥çè§£çæ¨è¦èªªæãåç®¡æéäºåªåï¼ç±æ¼éçµæ§åå°è©±åçµæ§å KG ä¹éçæ¨¡å¼å·®ç°ï¼LLM å KG å¨ CRS ä¸­çæ´åä»ç¶å·æææ°æ§ãæ­¤å¤ï¼éå°å¤§åèªæåº«é åè¨ç·´ç LLM å¯è½ä¸é©ååæä½¿ç¨èåå¥½ï¼å çºééè¦ç¹å®é åçç¥è­ãå¨æ¬æä¸­ï¼æåæåº COMPASSï¼éæ¯ä¸åå³æå³ç¨çæ¶æ§ï¼å®ååéç¨ LLM å KG ä¾æ­ç¤ºä½¿ç¨èåå¥½ï¼å¢å¼·ç¾æ CRS çæè½åå¯è§£éæ§ãçºäºæå°æ´åææ°ï¼COMPASS æ¡ç¨äºå©éæ®µçè¨ç·´æ¹æ³ï¼é¦åï¼å®ééåµæ°çåå½¢å¯¦é«æ¨é¡é è¨ç·´æ©å¶ï¼å½åçµæ§å KG åèªç¶èªè¨ä¹éçå·®è·ãéè® LLM è½å¤ å° KG å¯¦é«è½æçºç°¡æ½çèªç¶èªè¨æè¿°ï¼è®å®åè½å¤ çè§£ç¹å®é åçç¥è­ãæ¥ä¸ä¾ï¼COMPASS ééç¥è­æç¥æä»¤å¾®èª¿ä¾æä½³åä½¿ç¨èåå¥½å»ºæ¨¡ï¼å¶ä¸­ LLM å­¸ç¿å¾å°è©±è¨éå KG æ´åçå§å®¹ä¸­æ¨è«åç¸½çµä½¿ç¨èåå¥½ãéè® COMPASS è½å¤ å·è¡ç¥è­æç¥æ¨çï¼ä¸¦ç¢çå¨é¢ä¸å¯è§£éçä½¿ç¨èåå¥½ï¼éäºåå¥½å¯ä»¥ç¡ç¸«æ´åå°ç¾æç CRS æ¨¡åä¸­ï¼ä»¥æ¹åæ¨è¦æè½åå¯è§£éæ§ã

##### **A Novel Approach to Eliminating Hallucinations in Large Language Model-Assisted Causal Discovery**
2411.12759v1 by Grace Sng, Yanming Zhang, Klaus Mueller

The increasing use of large language models (LLMs) in causal discovery as a
substitute for human domain experts highlights the need for optimal model
selection. This paper presents the first hallucination survey of popular LLMs
for causal discovery. We show that hallucinations exist when using LLMs in
causal discovery so the choice of LLM is important. We propose using Retrieval
Augmented Generation (RAG) to reduce hallucinations when quality data is
available. Additionally, we introduce a novel method employing multiple LLMs
with an arbiter in a debate to audit edges in causal graphs, achieving a
comparable reduction in hallucinations to RAG.

æè¦ï¼é¨èå¤§åèªè¨æ¨¡å (LLM) å¨å æç¼ç¾ä¸­ä½çºäººé¡é åå°å®¶çæ¿ä»£åä½¿ç¨æ¥çå¢å ï¼éå¸é¡¯äºæä½³æ¨¡åé¸æçéæ±ãæ¬ææåºäºç¬¬ä¸ä»½æµè¡ LLM çå¹»è¦ºèª¿æ¥ä»¥é²è¡å æç¼ç¾ãæåè¡¨æå¨å æç¼ç¾ä¸­ä½¿ç¨ LLM æå­å¨å¹»è¦ºï¼å æ­¤ LLM çé¸æå¾éè¦ãæåå»ºè­°ä½¿ç¨æª¢ç´¢å¼·åçæ (RAG) ä¾æ¸å°å¨æåè³ªè³ææç¢ççå¹»è¦ºãæ­¤å¤ï¼æåå¼å¥äºä¸ç¨®æ°çæ¹æ³ï¼å¨è¾¯è«ä¸­ä½¿ç¨å¤å LLM åä»²è£èä¾å¯©æ ¸å æåä¸­çéç·£ï¼è RAG ç¸æ¯ï¼å¹»è¦ºæ¸å°äºè¨±å¤ã

##### **VeriGraph: Scene Graphs for Execution Verifiable Robot Planning**
2411.10446v2 by Daniel Ekpo, Mara Levy, Saksham Suri, Chuong Huynh, Abhinav Shrivastava

Recent advancements in vision-language models (VLMs) offer potential for
robot task planning, but challenges remain due to VLMs' tendency to generate
incorrect action sequences. To address these limitations, we propose VeriGraph,
a novel framework that integrates VLMs for robotic planning while verifying
action feasibility. VeriGraph employs scene graphs as an intermediate
representation, capturing key objects and spatial relationships to improve plan
verification and refinement. The system generates a scene graph from input
images and uses it to iteratively check and correct action sequences generated
by an LLM-based task planner, ensuring constraints are respected and actions
are executable. Our approach significantly enhances task completion rates
across diverse manipulation scenarios, outperforming baseline methods by 58%
for language-based tasks and 30% for image-based tasks.

æè¦ï¼è¦è¦ºèªè¨æ¨¡å (VLM) çææ°é²å±çºæ©å¨äººä»»åè¦åæä¾äºæ½åï¼ä½ç±æ¼ VLM å¾åæ¼çæä¸æ­£ç¢ºçåä½åºåï¼å æ­¤ä»å­å¨ææ°ãçºäºè§£æ±ºéäºéå¶ï¼æåæåºäº VeriGraphï¼éæ¯ä¸åæ°ç©çæ¶æ§ï¼å®æ´åäº VLM ä»¥é²è¡æ©å¨äººè¦åï¼åæé©è­åä½çå¯è¡æ§ãVeriGraph ä½¿ç¨å ´æ¯åä½çºä¸­éè¡¨ç¤ºï¼æ·åééµç©ä»¶åç©ºééä¿ä»¥æ¹åè¨ç«é©è­åç²¾çãç³»çµ±å¾è¼¸å¥å½±åä¸­çæå ´æ¯åï¼ä¸¦ä½¿ç¨å®ä¾åè¦æª¢æ¥åä¿®æ­£ç±åºæ¼ LLM çä»»åè¦åå¨ç¢ççåä½åºåï¼ç¢ºä¿éµå®ç´æä¸åä½å¯å·è¡ãæåçåæ³å¤§å¹æé«äºå¨åç¨®æä½å ´æ¯ä¸­çä»»åå®æçï¼å¨åºæ¼èªè¨çä»»åä¸­åªæ¼åºç·æ¹æ³ 58%ï¼å¨åºæ¼å½±åçä»»åä¸­åªæ¼ 30%ã

##### **A Survey of Event Causality Identification: Principles, Taxonomy, Challenges, and Assessment**
2411.10371v2 by Qing Cheng, Zefan Zeng, Xingchen Hu, Yuehang Si, Zhong Liu

Event Causality Identification (ECI) has become a crucial task in Natural
Language Processing (NLP), aimed at automatically extracting causalities from
textual data. In this survey, we systematically address the foundational
principles, technical frameworks, and challenges of ECI, offering a
comprehensive taxonomy to categorize and clarify current research
methodologies, as well as a quantitative assessment of existing models. We
first establish a conceptual framework for ECI, outlining key definitions,
problem formulations, and evaluation standards. Our taxonomy classifies ECI
methods according to the two primary tasks of sentence-level (SECI) and
document-level (DECI) event causality identification. For SECI, we examine
feature pattern-based matching, deep semantic encoding, causal knowledge
pre-training and prompt-based fine-tuning, and external knowledge enhancement
methods. For DECI, we highlight approaches focused on event graph reasoning and
prompt-based techniques to address the complexity of cross-sentence causal
inference. Additionally, we analyze the strengths, limitations, and open
challenges of each approach. We further conduct an extensive quantitative
evaluation of various ECI methods on two benchmark datasets. Finally, we
explore future research directions, highlighting promising pathways to overcome
current limitations and broaden ECI applications.

æè¦ï¼äºä»¶å æéä¿è­å¥ (ECI) å·²æçºèªç¶èªè¨èç (NLP) ä¸­ä¸é è³ééè¦çä»»åï¼æ¨å¨å¾ææ¬è³æä¸­èªåèåå æéä¿ãå¨æ­¤èª¿æ¥ä¸­ï¼æåç³»çµ±æ§å°æ¢è¨ ECI çåºç¤åçãæè¡æ¶æ§åææ°ï¼æä¾ä¸åå¨é¢çåé¡æ³ä¾åé¡åéæ¸ç¶åçç ç©¶æ¹æ³ï¼ä»¥åå°ç¾ææ¨¡åçéåè©ä¼°ãæåé¦åçº ECI å»ºç«ä¸åæ¦å¿µæ¡æ¶ï¼æ¦è¿°ééµå®ç¾©ãåé¡è¡¨è¿°åè©ä¼°æ¨æºãæåçåé¡æ³æ ¹æå¥å­å±¤ç´ (SECI) åæä»¶å±¤ç´ (DECI) äºä»¶å æéä¿è­å¥éå©åä¸»è¦ä»»åï¼å° ECI æ¹æ³é²è¡åé¡ãå°æ¼ SECIï¼æåæª¢è¦åºæ¼ç¹å¾µæ¨¡å¼çæ¯å°ãæ·±åº¦èªæç·¨ç¢¼ãå æç¥è­é è¨ç·´ååºæ¼æç¤ºçå¾®èª¿ï¼ä»¥åå¤é¨ç¥è­å¢å¼·æ¹æ³ãå°æ¼ DECIï¼æåå¼·èª¿ä»¥äºä»¶åæ¨è«ååºæ¼æç¤ºçæè¡çºéé»çæ¹æ³ï¼ä»¥è§£æ±ºè·¨å¥å­å ææ¨è«çè¤éæ§ãæ­¤å¤ï¼æååææ¯ç¨®æ¹æ³çåªé»ãéå¶åéæ¾æ§ææ°ãæåé²ä¸æ­¥å°åç¨® ECI æ¹æ³å¨å©ååºæºè³æéä¸é²è¡å»£æ³çéåè©ä¼°ãæå¾ï¼æåæ¢è¨æªä¾çç ç©¶æ¹åï¼å¼·èª¿æå¸æåæç¶åéå¶åæ´å± ECI æç¨ç¨å¼çéå¾ã

##### **Prompting and Fine-tuning Large Language Models for Automated Code Review Comment Generation**
2411.10129v1 by Md. Asif Haider, Ayesha Binte Mostofa, Sk. Sabit Bin Mosaddek, Anindya Iqbal, Toufique Ahmed

Generating accurate code review comments remains a significant challenge due
to the inherently diverse and non-unique nature of the task output. Large
language models pretrained on both programming and natural language data tend
to perform well in code-oriented tasks. However, large-scale pretraining is not
always feasible due to its environmental impact and project-specific
generalizability issues. In this work, first we fine-tune open-source Large
language models (LLM) in parameter-efficient, quantized low-rank (QLoRA)
fashion on consumer-grade hardware to improve review comment generation. Recent
studies demonstrate the efficacy of augmenting semantic metadata information
into prompts to boost performance in other code-related tasks. To explore this
in code review activities, we also prompt proprietary, closed-source LLMs
augmenting the input code patch with function call graphs and code summaries.
Both of our strategies improve the review comment generation performance, with
function call graph augmented few-shot prompting on the GPT-3.5 model
surpassing the pretrained baseline by around 90% BLEU-4 score on the
CodeReviewer dataset. Moreover, few-shot prompted Gemini-1.0 Pro, QLoRA
fine-tuned Code Llama and Llama 3.1 models achieve competitive results (ranging
from 25% to 83% performance improvement) on this task. An additional human
evaluation study further validates our experimental findings, reflecting
real-world developers' perceptions of LLM-generated code review comments based
on relevant qualitative metrics.

æè¦ï¼<paragraph>ç¢çæºç¢ºçç¨å¼ç¢¼å¯©æ¥è©è«ä»ç¶æ¯ä¸åéå¤§ææ°ï¼å çºä»»åè¼¸åºçæ¬è³ªä¸æ¯å¤æ¨£ä¸éç¨ç¹çãå¨ç¨å¼è¨­è¨åèªç¶èªè¨è³æä¸é²è¡é è¨ç·´çå¤§åèªè¨æ¨¡åå¾å¾å¨ä»¥ç¨å¼ç¢¼çºå°åçä»»åä¸­è¡¨ç¾è¯å¥½ãç¶èï¼ç±æ¼å¶å°ç°å¢çå½±é¿åå°æ¡ç¹å®çä¸è¬ååé¡ï¼å¤§è¦æ¨¡é è¨ç·´ä¸¦éç¸½æ¯å¯è¡çãå¨éé å·¥ä½ä¸­ï¼æåé¦åå¨åæ¸ææãéåçä½ç§© (QLoRA) æ¹å¼ä¸­å¾®èª¿éæºå¤§åèªè¨æ¨¡å (LLM)ï¼å¨æ¶è²»ç´ç¡¬é«ä¸æ¹åå¯©æ¥è©è«çç¢çãæè¿çç ç©¶è­æäºå¨æç¤ºä¸­å¢å èªç¾©åè³æè³è¨ä»¥æåå¶ä»èç¨å¼ç¢¼ç¸éä»»åä¸­æè½çåæãçºäºå¨ç¨å¼ç¢¼å¯©æ¥æ´»åä¸­æ¢ç´¢éä¸é»ï¼æåä¹æç¤ºå°æçãéæº LLMï¼ä½¿ç¨å½æ¸å¼å«ååç¨å¼ç¢¼æè¦ä¾å¢å è¼¸å¥ç¨å¼ç¢¼ä¿®è£ç¨å¼ãæåçå©ç¨®ç­ç¥é½æ¹åäºå¯©æ¥è©è«ç¢ççæè½ï¼å¨ GPT-3.5 æ¨¡åä¸ä½¿ç¨å½æ¸å¼å«åå¢å çå°éæç¤ºï¼å¨ CodeReviewer è³æéä¸è¶è¶äºé è¨ç·´åºæºï¼BLEU-4 åæ¸æé«äºç´ 90%ãæ­¤å¤ï¼å°éæç¤ºç Gemini-1.0 ProãQLoRA å¾®èª¿ç Code Llama å Llama 3.1 æ¨¡åå¨æ­¤ä»»åä¸éå°äºæç«¶ç­åççµæï¼æè½æåç¯åçº 25% è³ 83%ï¼ãé¡å¤çä½¿ç¨èè©ä¼°ç ç©¶é²ä¸æ­¥é©è­äºæåçå¯¦é©çµæï¼åæ äºå¯¦ééç¼äººå¡å° LLM ç¢ççç¨å¼ç¢¼å¯©æ¥è©è«ççæ³ï¼éäºçæ³åºæ¼ç¸éçå®æ§ææ¨ã</paragraph>

##### **HistoLens: An LLM-Powered Framework for Multi-Layered Analysis of Historical Texts -- A Case Application of Yantie Lun**
2411.09978v1 by Yifan Zeng

This paper proposes HistoLens, a multi-layered analysis framework for
historical texts based on Large Language Models (LLMs). Using the important
Western Han dynasty text "Yantie Lun" as a case study, we demonstrate the
framework's potential applications in historical research and education.
HistoLens integrates NLP technology (especially LLMs), including named entity
recognition, knowledge graph construction, and geographic information
visualization. The paper showcases how HistoLens explores Western Han culture
in "Yantie Lun" through multi-dimensional, visual, and quantitative methods,
focusing particularly on the influence of Confucian and Legalist thoughts on
political, economic, military, and ethnic. We also demonstrate how HistoLens
constructs a machine teaching scenario using LLMs for explainable analysis,
based on a dataset of Confucian and Legalist ideas extracted with LLM
assistance. This approach offers novel and diverse perspectives for studying
historical texts like "Yantie Lun" and provides new auxiliary tools for history
education. The framework aims to equip historians and learners with
LLM-assisted tools to facilitate in-depth, multi-layered analysis of historical
texts and foster innovation in historical education.

æè¦ï¼æ¬ææåº HistoLensï¼ä¸ååºæ¼å¤§åèªè¨æ¨¡å (LLM) çå¤å±¤åææ¶æ§ï¼ç¨æ¼æ­·å²ææ¬ãä½¿ç¨éè¦çè¥¿æ¼¢çæææ¬ãé¹½éµè«ãä½çºåæ¡ç ç©¶ï¼æåå±ç¤ºäºè©²æ¶æ§å¨æ­·å²ç ç©¶åæè²ä¸­çæ½å¨æç¨ãHistoLens æ´åäº NLP æè¡ï¼å°¤å¶æ¯ LLMï¼ï¼åæ¬å½åå¯¦é«è­å¥ãç¥è­åè­å»ºæ§åå°çè³è¨è¦è¦ºåãæ¬æå±ç¤ºäº HistoLens å¦ä½ééå¤ç¶­åº¦ãè¦è¦ºååéåæ¹æ³æ¢ç´¢ãé¹½éµè«ãä¸­çè¥¿æ¼¢æåï¼ç¹å¥éæ³¨åå®¶åæ³å®¶ææ³å°æ¿æ²»ãç¶æ¿ãè»äºåç¨®æçå½±é¿ãæåéå±ç¤ºäº HistoLens å¦ä½å»ºæ§ä¸åä½¿ç¨ LLM çæ©å¨æå­¸å ´æ¯ï¼ä»¥é²è¡å¯è§£éåæï¼éæ¯åºæ¼ LLM åå©æåçåå®¶åæ³å®¶ææ³è³æéãéç¨®æ¹æ³çºç ç©¶ãé¹½éµè«ãç­æ­·å²ææ¬æä¾äºæ°ç©ä¸å¤æ¨£åçè§é»ï¼ä¸¦çºæ­·å²æè²æä¾äºæ°çè¼å©å·¥å·ãè©²æ¶æ§æ¨å¨çºæ­·å²å­¸å®¶åå­¸ç¿èæä¾ LLM åå©çå·¥å·ï¼ä»¥å©æ¼æ·±å¥ãå¤å±¤æ¬¡å°åææ­·å²ææ¬ï¼ä¸¦ä¿é²æ­·å²æè²çåµæ°ã

##### **Accelerating Knowledge Graph and Ontology Engineering with Large Language Models**
2411.09601v1 by Cogan Shimizu, Pascal Hitzler

Large Language Models bear the promise of significant acceleration of key
Knowledge Graph and Ontology Engineering tasks, including ontology modeling,
extension, modification, population, alignment, as well as entity
disambiguation. We lay out LLM-based Knowledge Graph and Ontology Engineering
as a new and coming area of research, and argue that modular approaches to
ontologies will be of central importance.

æè¦ï¼å¤§åèªè¨æ¨¡åæ¿è«¾å¤§å¹å éééµç¥è­åè­åæ¬ä½å·¥ç¨ä»»åï¼åæ¬æ¬ä½å»ºæ¨¡ãæ´åãä¿®æ¹ãå¡«åãæ¯å°ä»¥åå¯¦é«æ¶æ­§ãæåå° LLM çºåºç¤çç¥è­åè­åæ¬ä½å·¥ç¨è¦åçºä¸åæ°èçç ç©¶é åï¼ä¸¦ä¸»å¼µæ¨¡çµåæ¬ä½æ¹æ³å°è³ééè¦ã

##### **Automating Reformulation of Essence Specifications via Graph Rewriting**
2411.09576v1 by Ian Miguel, AndrÃ¡s Z. Salamon, Christopher Stone

Formulating an effective constraint model of a parameterised problem class is
crucial to the efficiency with which instances of the class can subsequently be
solved. It is difficult to know beforehand which of a set of candidate models
will perform best in practice. This paper presents a system that employs graph
rewriting to reformulate an input model for improved performance automatically.
By situating our work in the Essence abstract constraint specification
language, we can use the structure in its high level variable types to trigger
rewrites directly. We implement our system via rewrite rules expressed in the
Graph Programs 2 language, applied to the abstract syntax tree of an input
specification. We show how to automatically translate the solution of the
reformulated problem into a solution of the original problem for verification
and presentation. We demonstrate the efficacy of our system with a detailed
case study.

æè¦ï¼å¶å®ä¸ååæ¸ååé¡é¡å¥çææç´ææ¨¡åå°æ¼é¨å¾æ±è§£è©²é¡å¥çå¯¦ä¾çæçè³ééè¦ãäºåå¾é£ç¥éä¸çµåé¸æ¨¡åä¸­åªä¸åå¨å¯¦åä¸è¡¨ç¾æä½³ãæ¬ææåºä¸åç³»çµ±ï¼æ¡ç¨åå½¢éå¯«ä¾èªåéæ°å¶å®è¼¸å¥æ¨¡åä»¥æ¹åæè½ãééå°æåçå·¥ä½ç½®æ¼ Essence æ½è±¡ç´æè¦ç¯èªè¨ä¸­ï¼æåå¯ä»¥ä½¿ç¨å¶é«å±¤ç´è®æ¸é¡åä¸­ççµæ§ä¾ç´æ¥è§¸ç¼éå¯«ãæåééä»¥ Graph Programs 2 èªè¨è¡¨ç¤ºçéå¯«è¦åä¾å¯¦ä½æåçç³»çµ±ï¼æç¨æ¼è¼¸å¥è¦ç¯çæ½è±¡èªæ³æ¨¹ãæåå±ç¤ºå¦ä½èªåå°éæ°å¶å®åé¡çè§£æ³è½æçºåå§åé¡çè§£æ³ï¼ä»¥é²è¡é©è­ååç¾ãæåééè©³ç´°çåæ¡ç ç©¶ä¾å±ç¤ºæåç³»çµ±çæè½ã

##### **Towards Evaluating Large Language Models for Graph Query Generation**
2411.08449v2 by Siraj Munir, Alessandro Aldini

Large Language Models (LLMs) are revolutionizing the landscape of Generative
Artificial Intelligence (GenAI), with innovative LLM-backed solutions emerging
rapidly. However, when applied to database technologies, specifically query
generation for graph databases and Knowledge Graphs (KGs), LLMs still face
significant challenges. While research on LLM-driven query generation for
Structured Query Language (SQL) exists, similar systems for graph databases
remain underdeveloped. This paper presents a comparative study addressing the
challenge of generating Cypher queries a powerful language for interacting with
graph databases using open-access LLMs. We rigorously evaluate several LLM
agents (OpenAI ChatGPT 4o, Claude Sonnet 3.5, Google Gemini Pro 1.5, and a
locally deployed Llama 3.1 8B) using a designed few-shot learning prompt and
Retrieval Augmented Generation (RAG) backed by Chain-of-Thoughts (CoT)
reasoning. Our empirical analysis of query generation accuracy reveals that
Claude Sonnet 3.5 outperforms its counterparts in this specific domain.
Further, we highlight promising future research directions to address the
identified limitations and advance LLM-driven query generation for graph
databases.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) æ­£å¨é©æ°çæå¼äººå·¥æºæ§ (GenAI) çé åï¼åµæ°ç LLM æ¯æè§£æ±ºæ¹æ¡è¿éæ¹§ç¾ãç¶èï¼ç¶æç¨æ¼è³æåº«æè¡ï¼ç¹å¥æ¯åå½¢è³æåº«åç¥è­åè­ (KG) çæ¥è©¢ç¢çæï¼LLM ä»ç¶é¢è¨éå¤§ææ°ãéç¶å­å¨éå°çµæ§åæ¥è©¢èªè¨ (SQL) ç LLM é©åæ¥è©¢ç¢ççç ç©¶ï¼ä½åå½¢è³æåº«çé¡ä¼¼ç³»çµ±ä»æªååç¼å±ãæ¬ææåºäºä¸é æ¯è¼ç ç©¶ï¼ä»¥è§£æ±ºä½¿ç¨éæ¾å¼ LLM ç¢ç Cypher æ¥è©¢çææ°ï¼Cypher æ¥è©¢æ¯ä¸ç¨®ç¨æ¼èåå½¢è³æåº«äºåçå¼·å¤§èªè¨ãæåä½¿ç¨è¨­è¨çå°éå­¸ç¿æç¤ºåç±ææ³é (CoT) æ¨çæ¯æçæª¢ç´¢æ´åçæ (RAG) å´æ ¼è©ä¼°äºå¤å LLM ä»£çï¼OpenAI ChatGPT 4oãClaude Sonnet 3.5ãGoogle Gemini Pro 1.5 åæ¬å°é¨ç½²ç Llama 3.1 8Bï¼ãæåå°æ¥è©¢ç¢çæºç¢ºæ§çå¯¦è­åæè¡¨æï¼Claude Sonnet 3.5 å¨éåç¹å®é ååªæ¼å¶åé¡ç¢åãæ­¤å¤ï¼æåéé»ä»ç´¹äºæå¸æçæªä¾ç ç©¶æ¹åï¼ä»¥è§£æ±ºå·²è­å¥çéå¶ä¸¦æ¨é² LLM é©åçåå½¢è³æåº«æ¥è©¢ç¢çã

##### **Knowledge Bases in Support of Large Language Models for Processing Web News**
2411.08278v2 by Yihe Zhang, Nabin Pakka, Nian-Feng Tzeng

Large Language Models (LLMs) have received considerable interest in wide
applications lately. During pre-training via massive datasets, such a model
implicitly memorizes the factual knowledge of trained datasets in its hidden
parameters. However, knowledge held implicitly in parameters often makes its
use by downstream applications ineffective due to the lack of common-sense
reasoning. In this article, we introduce a general framework that permits to
build knowledge bases with an aid of LLMs, tailored for processing Web news.
The framework applies a rule-based News Information Extractor (NewsIE) to news
items for extracting their relational tuples, referred to as knowledge bases,
which are then graph-convoluted with the implicit knowledge facts of news items
obtained by LLMs, for their classification. It involves two lightweight
components: 1) NewsIE: for extracting the structural information of every news
item, in the form of relational tuples; 2) BERTGraph: for graph convoluting the
implicit knowledge facts with relational tuples extracted by NewsIE. We have
evaluated our framework under different news-related datasets for news category
classification, with promising experimental results.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) è¿ä¾å¨å»£æ³çæç¨ä¸­ååéæ³¨ãå¨ééå¤§éè³æéé²è¡é è¨ç·´æéï¼æ­¤é¡æ¨¡åæé±å«å°å°è¨ç·´è³æéçäºå¯¦ç¥è­è¨æ¶å¨å¶é±èåæ¸ä¸­ãç¶èï¼é±å«å¨åæ¸ä¸­çç¥è­éå¸¸æå çºç¼ºä¹å¸¸è­æ¨çèå°è´ä¸æ¸¸æç¨ç¡æ³ææä½¿ç¨ãå¨æ¬æä¸­ï¼æåä»ç´¹äºä¸åéç¨æ¶æ§ï¼åè¨±å¨ LLM çåå©ä¸å»ºç«ç¥è­åº«ï¼å°éç¨æ¼èçç¶²è·¯æ°èãæ­¤æ¶æ§å°åºæ¼è¦åçæ°èè³è¨èåå¨ (NewsIE) å¥ç¨å°æ°èé ç®ï¼ä»¥èåå¶éä¿åçµï¼ç¨±çºç¥è­åº«ï¼ï¼ç¶å¾å°å¶è LLM åå¾çæ°èé ç®çé±å«ç¥è­äºå¯¦é²è¡åå½¢å·ç©ï¼ä»¥é²è¡åé¡ãå®åå«å©åè¼éç´åä»¶ï¼1) NewsIEï¼ç¨æ¼èåæ¯åæ°èé ç®ççµæ§åè³è¨ï¼ä»¥éä¿åçµçå½¢å¼åç¾ï¼2) BERTGraphï¼ç¨æ¼å° NewsIE èåçéä¿åçµèé±å«ç¥è­äºå¯¦é²è¡åå½¢å·ç©ãæåå·²å¨ä¸åçèæ°èç¸éçè³æéä¸è©ä¼°æåçæ¶æ§ï¼ç¨æ¼æ°èé¡å¥åé¡ï¼ä¸¦ç²å¾æå¸æçå¯¦é©çµæã

##### **Retrieval, Reasoning, Re-ranking: A Context-Enriched Framework for Knowledge Graph Completion**
2411.08165v1 by Muzhi Li, Cehao Yang, Chengjin Xu, Xuhui Jiang, Yiyan Qi, Jian Guo, Ho-fung Leung, Irwin King

The Knowledge Graph Completion~(KGC) task aims to infer the missing entity
from an incomplete triple. Existing embedding-based methods rely solely on
triples in the KG, which is vulnerable to specious relation patterns and
long-tail entities. On the other hand, text-based methods struggle with the
semantic gap between KG triples and natural language. Apart from triples,
entity contexts (e.g., labels, descriptions, aliases) also play a significant
role in augmenting KGs. To address these limitations, we propose KGR3, a
context-enriched framework for KGC. KGR3 is composed of three modules. Firstly,
the Retrieval module gathers supporting triples from the KG, collects plausible
candidate answers from a base embedding model, and retrieves context for each
related entity. Then, the Reasoning module employs a large language model to
generate potential answers for each query triple. Finally, the Re-ranking
module combines candidate answers from the two modules mentioned above, and
fine-tunes an LLM to provide the best answer. Extensive experiments on widely
used datasets demonstrate that KGR3 consistently improves various KGC methods.
Specifically, the best variant of KGR3 achieves absolute Hits@1 improvements of
12.3% and 5.6% on the FB15k237 and WN18RR datasets.

æè¦ï¼ç¥è­åè­å®æåè½ (KGC) çä»»åæ¨å¨å¾ä¸å®æ´ç 3 åçµä¸­æ¨æ·åºéºå¤±çå¯¦é«ãç¾æçåµå¥å¼æ¹æ³åä¾è³´æ¼ KG ä¸­ç 3 åçµï¼éå®¹æåå°èåéä¿æ¨¡å¼åé·å°¾å¯¦é«çå½±é¿ãå¦ä¸æ¹é¢ï¼åºæ¼ææ¬çæ¹æ³é£ä»¥èç KG 3 åçµåèªç¶èªè¨ä¹éçèªç¾©å·®è·ãé¤äº 3 åçµä¹å¤ï¼å¯¦é«ä¸ä¸æï¼ä¾å¦æ¨ç±¤ãæè¿°ãå¥åï¼å¨æ´å KG ä¸­ä¹æ®æ¼èéè¦çè§è²ãçºäºè§£æ±ºéäºéå¶ï¼æåæåºäº KGR3ï¼ä¸åç¨æ¼ KGC çä¸ä¸æè±å¯æ¶æ§ãKGR3 ç±ä¸åæ¨¡çµçµæãé¦åï¼æª¢ç´¢æ¨¡çµå¾ KG ä¸­æ¶éæ¯æ´ 3 åçµï¼å¾åºç¤åµå¥æ¨¡åä¸­æ¶éå¯è½çåé¸ç­æ¡ï¼ä¸¦çºæ¯åç¸éå¯¦é«æª¢ç´¢ä¸ä¸æãæ¥èï¼æ¨çæ¨¡çµæ¡ç¨å¤§åèªè¨æ¨¡åçºæ¯åæ¥è©¢ 3 åçµçææ½å¨ç­æ¡ãæå¾ï¼éæ°æåæ¨¡çµå°ä¸è¿°å©åæ¨¡çµçåé¸ç­æ¡çµåèµ·ä¾ï¼ä¸¦å¾®èª¿ LLM ä»¥æä¾æä½³ç­æ¡ãå¨å»£æ³ä½¿ç¨çè³æéä¸é²è¡çå»£æ³å¯¦é©è­æï¼KGR3 æçºæ¹é²åç¨® KGC æ¹æ³ãå·é«ä¾èªªï¼KGR3 çæä½³è®é«å¨ FB15k237 å WN18RR è³æéä¸åå¥å¯¦ç¾äº 12.3% å 5.6% ççµå° Hits@1 æ¹é²ã

##### **Language Models as Causal Effect Generators**
2411.08019v1 by Lucius E. J. Bynum, Kyunghyun Cho

We present a framework for large language model (LLM) based data generation
with controllable causal structure. In particular, we define a procedure for
turning any language model and any directed acyclic graph (DAG) into a
sequence-driven structural causal model (SD-SCM). Broadly speaking, an SD-SCM
is a causal model with user-defined structure and LLM-defined structural
equations. We characterize how an SD-SCM allows sampling from observational,
interventional, and counterfactual distributions according to the desired
causal structure. We then leverage this procedure to propose a new type of
benchmark for causal inference methods, generating individual-level
counterfactual data without needing to manually specify functional
relationships between variables. We create an example benchmark consisting of
thousands of datasets, and test a suite of popular estimation methods on these
datasets for average, conditional average, and individual treatment effect
estimation, both with and without hidden confounding. Apart from generating
data, the same procedure also allows us to test for the presence of a causal
effect that might be encoded in an LLM. This procedure can underpin auditing
LLMs for misinformation, discrimination, or otherwise undesirable behavior. We
believe SD-SCMs can serve as a useful tool in any application that would
benefit from sequential data with controllable causal structure.

æè¦ï¼<paragraph>æåæåºäºä¸ååºæ¼å¤§åèªè¨æ¨¡å (LLM) çè³æçææ¶æ§ï¼å·æå¯æ§å¶çå æçµæ§ãå·é«ä¾èªªï¼æåå®ç¾©äºä¸åç¨åºï¼å°ä»»ä½èªè¨æ¨¡ååä»»ä½æåç¡ç°å (DAG) è½ææä¸ååºåé©åççµæ§å ææ¨¡å (SD-SCM)ãå»£ç¾©ä¾èªªï¼SD-SCM æ¯ä¸åå ææ¨¡åï¼å·æä½¿ç¨èå®ç¾©ççµæ§å LLM å®ç¾©ççµæ§æ¹ç¨å¼ãæåæè¿°äº SD-SCM å¦ä½æ ¹ææéçå æçµæ§ï¼åè¨±å¾è§æ¸¬ãä»å¥ååäºå¯¦åä½ä¸­é²è¡æ½æ¨£ãç¶å¾ï¼æåå©ç¨éåç¨åºæåºäºä¸ç¨®é¡åçå ææ¨è«æ¹æ³åºæºï¼çæåé«å±¤ç´çåäºå¯¦è³æï¼èç¡éæåæå®è®æ¸ä¹éçåè½éä¿ãæåå»ºç«äºä¸åç¯ä¾åºæºï¼åå«æ¸ååè³æéï¼ä¸¦å¨éäºè³æéä¸æ¸¬è©¦äºä¸ç³»åæµè¡çä¼°è¨æ¹æ³ï¼ç¨æ¼å¹³åå¼ãæ¢ä»¶å¹³åå¼ååå¥èçææä¼°è¨ï¼ç¡è«æ¯æææ²æé±èæ··æ·ãé¤äºçæè³æä¹å¤ï¼ç¸åçç¨åºä¹åè¨±æåæ¸¬è©¦ LLM ä¸­å¯è½ç·¨ç¢¼çå æææçå­å¨ãæ­¤ç¨åºå¯ä»¥æ¯æå¯©æ ¸ LLM çé¯èª¤è³è¨ãæ­§è¦æå¶ä»ä¸è¯è¡çºãæåç¸ä¿¡ SD-SCM å¯ä»¥ä½çºä»»ä½æç¨ç¨å¼çæç¨å·¥å·ï¼éäºæç¨ç¨å¼å¯ä»¥å¾å·æå¯æ§å¶å æçµæ§çåºåè³æä¸­åçã</paragraph>

##### **From General to Specific: Utilizing General Hallucination to Benchmark Specific Role-Playing Agents**
2411.07965v2 by Chuyi Kong, Ziyang Luo, Hongzhan Lin, Zhiyuan Fan, Yaxin Fan, Yuxi Sun, Jing Ma

The advanced role-playing capabilities of Large Language Models (LLMs) have
paved the way for developing Role-Playing Agents (RPAs). However, existing
benchmarks in this domain, such as HPD and SocialBench face limitations like
poor generalizability, implicit and inaccurate judgments, and the risk of model
forgetting. To address the above issues, we propose an automatic, scalable, and
generalizable paradigm. Specifically, we construct a benchmark, SHARP, by
extracting relations from a general knowledge graph and leveraging the inherent
hallucination properties of RPAs to simulate interactions across roles. We
employ ChatGPT for stance detection and define relationship hallucination along
with three related metrics based on stance transfer. Extensive experiments
validate the effectiveness and stability of our paradigm. Our findings further
explore the factors influencing these metrics and discuss the trade-off between
blind loyalty to relationships and adherence to facts in RPAs.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çé²éè§è²æ®æ¼è½åå·²çºè§è²æ®æ¼ä»£ç (RPA) çéç¼éªå¹³éè·¯ãç¶èï¼æ­¤é åç¾æçåºæºï¼ä¾å¦ HPD å SocialBenchï¼é¢è¨èæ¦æ¬æ§å·®ãå¤æ·é±å«ä¸ä¸æºç¢ºï¼ä»¥åæ¨¡åéºå¿çé¢¨éªç­éå¶ãçºäºè§£æ±ºä¸è¿°åé¡ï¼æåæåºäºä¸åèªååãå¯æ´åä¸å¯æ¦æ¬çç¯ä¾ãå·é«ä¾èªªï¼æåééå¾ä¸è¬ç¥è­åè­ä¸­æåéä¿ï¼ä¸¦å©ç¨ RPA åºæçå¹»è¦ºç¹æ§ä¾æ¨¡æ¬è·¨è§è²äºåï¼æ§å»ºäºä¸ååºæº SHARPãæåæ¡ç¨ ChatGPT é²è¡ç«å ´æª¢æ¸¬ï¼ä¸¦å®ç¾©éä¿å¹»è¦ºä»¥ååºæ¼ç«å ´è½ç§»çä¸åç¸éææ¨ãå»£æ³çå¯¦é©é©è­äºæåç¯ä¾çæææ§åç©©å®æ§ãæåçç¼ç¾é²ä¸æ­¥æ¢è¨äºå½±é¿éäºææ¨çå ç´ ï¼ä¸¦è¨è«äº RPA ä¸­å°éä¿çç²ç®å¿ èª åº¦èå°äºå¯¦çå æä¹éçæ¬è¡¡ã

##### **Chain Association-based Attacking and Shielding Natural Language Processing Systems**
2411.07843v1 by Jiacheng Huang, Long Chen

Association as a gift enables people do not have to mention something in
completely straightforward words and allows others to understand what they
intend to refer to. In this paper, we propose a chain association-based
adversarial attack against natural language processing systems, utilizing the
comprehension gap between humans and machines. We first generate a chain
association graph for Chinese characters based on the association paradigm for
building search space of potential adversarial examples. Then, we introduce an
discrete particle swarm optimization algorithm to search for the optimal
adversarial examples. We conduct comprehensive experiments and show that
advanced natural language processing models and applications, including large
language models, are vulnerable to our attack, while humans appear good at
understanding the perturbed text. We also explore two methods, including
adversarial training and associative graph-based recovery, to shield systems
from chain association-based attack. Since a few examples that use some
derogatory terms, this paper contains materials that may be offensive or
upsetting to some people.

æè¦ï¼è¯æ³ä½çºä¸ç¨®ç¦®ç©ï¼ä½¿äººåä¸å¿ç¨å®å¨ç´ç½çè©±èªæåæäºï¼ä¸¦è®å¶ä»äººæç½ä»åæ³æçæ¯ä»éº¼ãå¨æ¬æä¸­ï¼æåæåºäºä¸ç¨®åºæ¼éå¼è¯æ³çå°ææ§æ»æï¼ç¨æ¼èªç¶èªè¨èçç³»çµ±ï¼å©ç¨äºäººé¡èæ©å¨ä¹éççè§£å·®è·ãæåé¦ååºæ¼è¯æ³ç¯ä¾çºæ¼¢å­çæä¸åéå¼è¯æ³åï¼ç¨æ¼æ§å»ºæ½å¨å°ææ§ç¯ä¾çæç´¢ç©ºéãç¶å¾ï¼æåå¼å¥ä¸åé¢æ£ç²å­ç¾¤åªåæ¼ç®æ³ä¾æç´¢æä½³çå°ææ§ç¯ä¾ãæåé²è¡äºå¨é¢çå¯¦é©ï¼ä¸¦è¡¨æåé²çèªç¶èªè¨èçæ¨¡ååæç¨ç¨å¼ï¼åæ¬å¤§åèªè¨æ¨¡åï¼é½å®¹æåå°æåçæ»æï¼èäººé¡ä¼¼ä¹å¾æé·çè§£æ¾åå¾çæå­ãæåéæ¢ç´¢äºå©ç¨®æ¹æ³ï¼åæ¬å°ææ§è¨ç·´ååºæ¼è¯æ³åçæ¢å¾©ï¼ä»¥ä¿è­·ç³»çµ±åååºæ¼éå¼è¯æ³çæ»æãç±æ¼ä¸äºç¯ä¾ä½¿ç¨äºæäºè²¶ç¾©è©ï¼å æ­¤æ¬æåå«å¯è½åç¯æä»¤æäºäººæå°ä¸å®çææã

##### **Gradual Fine-Tuning with Graph Routing for Multi-Source Unsupervised Domain Adaptation**
2411.07185v1 by Yao Ma, Samuel Louvan, Zhunxuan Wang

Multi-source unsupervised domain adaptation aims to leverage labeled data
from multiple source domains for training a machine learning model to
generalize well on a target domain without labels. Source domain selection
plays a crucial role in determining the model's performance. It relies on the
similarities amongst source and target domains. Nonetheless, existing work for
source domain selection often involves heavyweight computational procedures,
especially when dealing with numerous source domains and the need to identify
the best ones from them. In this paper, we introduce a framework for gradual
fine tuning (GFT) of machine learning models on multiple source domains. We
represent multiple source domains as an undirected weighted graph. We then give
a new generalization error bound for GFT along any path within the graph, which
is used to determine the optimal path corresponding to the optimal training
order. With this formulation, we introduce three lightweight graph-routing
strategies which tend to minimize the error bound. Our best strategy improves
$2.3\%$ of accuracy over the state-of-the-art on Natural Language Inference
(NLI) task and achieves competitive performance on Sentiment Analysis (SA)
task, especially a $3.9\%$ improvement on a more diverse subset of data we use
for SA.

æè¦ï¼å¤æºæ çç£åèªéåºæ¨å¨å©ç¨æ¥èªå¤ä¸ªæºåçæ è®°æ°æ®ï¼è®­ç»æºå¨å­¦ä¹ æ¨¡åï¼ä»¥ä¾¿å¨æ²¡ææ ç­¾çç®æ åä¸å¾å¥½å°æ³åãæºåéæ©å¨ç¡®å®æ¨¡åæ§è½æ¹é¢èµ·çè³å³éè¦çä½ç¨ãå®ä¾èµäºæºååç®æ åä¹é´çç¸ä¼¼æ§ãå°½ç®¡å¦æ­¤ï¼ç°æçæºåéæ©å·¥ä½éå¸¸æ¶åééçº§è®¡ç®ç¨åºï¼å°¤å¶æ¯å¨å¤çä¼å¤æºåä»¥åéè¦ä»ä¸­è¯å«æä½³æºåæ¶ãå¨æ¬æä¸­ï¼æä»¬ä»ç»äºä¸ä¸ªå¨å¤ä¸ªæºåä¸å¯¹æºå¨å­¦ä¹ æ¨¡åè¿è¡éæ­¥å¾®è° (GFT) çæ¡æ¶ãæä»¬å°å¤ä¸ªæºåè¡¨ç¤ºä¸ºæ åå æå¾ãç¶åï¼æä»¬ä¸ºå¾ä¸­æ²¿ä»»ä½è·¯å¾ç GFT ç»åºäºä¸ä¸ªæ°çæ³åè¯¯å·®çï¼ç¨äºç¡®å®å¯¹åºäºæä½³è®­ç»é¡ºåºçæä½³è·¯å¾ãéè¿è¿ç§è¡¨è¿°ï¼æä»¬ä»ç»äºä¸ç§è½»éçº§çå¾è·¯ç±ç­ç¥ï¼è¿äºç­ç¥å¾åäºæå°åè¯¯å·®çãæä»¬æå¥½çç­ç¥å¨èªç¶è¯­è¨æ¨ç (NLI) ä»»å¡ä¸æ¯æåè¿çææ¯æé«äº 2.3% çåç¡®çï¼å¹¶å¨ææåæ (SA) ä»»å¡ä¸åå¾äºæç«äºåçæ§è½ï¼ç¹å«æ¯å¨æä»¬ç¨äº SA çæ´å¤æ ·åçæ°æ®å­éä¸æé«äº 3.9%ã

##### **A Domain-Agnostic Neurosymbolic Approach for Big Social Data Analysis: Evaluating Mental Health Sentiment on Social Media during COVID-19**
2411.07163v1 by Vedant Khandelwal, Manas Gaur, Ugur Kursuncu, Valerie Shalin, Amit Sheth

Monitoring public sentiment via social media is potentially helpful during
health crises such as the COVID-19 pandemic. However, traditional
frequency-based, data-driven neural network-based approaches can miss newly
relevant content due to the evolving nature of language in a dynamically
evolving environment. Human-curated symbolic knowledge sources, such as
lexicons for standard language and slang terms, can potentially elevate social
media signals in evolving language. We introduce a neurosymbolic method that
integrates neural networks with symbolic knowledge sources, enhancing the
detection and interpretation of mental health-related tweets relevant to
COVID-19. Our method was evaluated using a corpus of large datasets
(approximately 12 billion tweets, 2.5 million subreddit data, and 700k news
articles) and multiple knowledge graphs. This method dynamically adapts to
evolving language, outperforming purely data-driven models with an F1 score
exceeding 92\%. This approach also showed faster adaptation to new data and
lower computational demands than fine-tuning pre-trained large language models
(LLMs). This study demonstrates the benefit of neurosymbolic methods in
interpreting text in a dynamic environment for tasks such as health
surveillance.

æè¦ï¼ééç¤¾ç¾¤åªé«ç£æ§å¬ç¾æç·å¨ COVID-19 ç­å¥åº·å±æ©æéå¯è½å¾æå¹«å©ãç¶èï¼å³çµ±çåºæ¼é »çãè³æé©åçç¥ç¶ç¶²è·¯æ¹æ³å¯è½æé¯éæ°ç¸éçå§å®¹ï¼å çºèªè¨å¨åææ¼åçç°å¢ä¸­ææçºæ¼åãç±äººé¡ç­åçè±¡å¾µæ§ç¥è­ä¾æºï¼ä¾å¦æ¨æºèªè¨åä¿èªè¡èªçè©å½ï¼å¯è½ææåç¤¾ç¾¤åªé«å¨æ¼åèªè¨ä¸­çè¨èãæåå¼å¥ä¸ç¨®å°ç¥ç¶ç¶²è·¯èè±¡å¾µæ§ç¥è­ä¾æºæ´åçç¥ç¶ç¬¦èæ¹æ³ï¼å¢å¼·è COVID-19 ç¸éçå¿çå¥åº·ç¸éæ¨æçåµæ¸¬åè©®éãæåçåæ³ä½¿ç¨å¤§åè³æéèªæåº«ï¼ç´ 120 ååæ¨æã250 è¬å subreddit è³æå 70 è¬åæ°èæç« ï¼åå¤åç¥è­åè­é²è¡è©ä¼°ãéç¨®æ¹æ³åæé©ææ¼åçèªè¨ï¼åªæ¼ç´è³æé©åæ¨¡åï¼F1 åæ¸è¶é 92%ãéç¨®æ¹æ³ä¹é¡¯ç¤ºåºæ¯å¾®èª¿é è¨ç·´å¤§åèªè¨æ¨¡å (LLM) æ´å¿«é©ææ°è³æåæ´ä½çéç®éæ±ãæ¬ç ç©¶è­æäºç¥ç¶ç¬¦èæ¹æ³å¨åæç°å¢ä¸­è©®éæå­çåªé»ï¼é©ç¨æ¼å¥åº·ç£æ§ç­ä»»åã

##### **A Multi-Agent Approach for REST API Testing with Semantic Graphs and LLM-Driven Inputs**
2411.07098v1 by Myeongsoo Kim, Tyler Stennett, Saurabh Sinha, Alessandro Orso

As modern web services increasingly rely on REST APIs, their thorough testing
has become crucial. Furthermore, the advent of REST API specifications such as
the OpenAPI Specification has led to the emergence of many black-box REST API
testing tools. However, these tools often focus on individual test elements in
isolation (e.g., APIs, parameters, values), resulting in lower coverage and
less effectiveness in detecting faults (i.e., 500 response codes). To address
these limitations, we present AutoRestTest, the first black-box framework to
adopt a dependency-embedded multi-agent approach for REST API testing,
integrating Multi-Agent Reinforcement Learning (MARL) with a Semantic Property
Dependency Graph (SPDG) and Large Language Models (LLMs). Our approach treats
REST API testing as a separable problem, where four agents -- API, dependency,
parameter, and value -- collaborate to optimize API exploration. LLMs handle
domain-specific value restrictions, the SPDG model simplifies the search space
for dependencies using a similarity score between API operations, and MARL
dynamically optimizes the agents' behavior. Evaluated on 12 real-world REST
services, AutoRestTest outperforms the four leading black-box REST API testing
tools, including those assisted by RESTGPT (which augments realistic test
inputs using LLMs), in terms of code coverage, operation coverage, and fault
detection. Notably, AutoRestTest is the only tool able to identify an internal
server error in Spotify. Our ablation study underscores the significant
contributions of the agent learning, SPDG, and LLM components.

æè¦ï¼<paragraph>é¨èç¾ä»£ç¶²è·¯æåæ¥çä¾è³´ REST APIï¼å¶å¾¹åºçæ¸¬è©¦è®å¾è³ééè¦ãæ­¤å¤ï¼REST API è¦ç¯ï¼ä¾å¦ OpenAPI è¦ç¯ï¼çåºç¾ï¼å°è´è¨±å¤é»ç REST API æ¸¬è©¦å·¥å·çåºç¾ãç¶èï¼éäºå·¥å·éå¸¸å°æ³¨æ¼å®ç¨çæ¸¬è©¦åç´ ï¼ä¾å¦ APIãåæ¸ãå¼ï¼ï¼å°è´è¦èçè¼ä½ï¼ä¸å¨åµæ¸¬é¯èª¤ï¼å³ 500 åæç¢¼ï¼æ¹é¢æçè¼ä½ãçºäºè§£æ±ºéäºéå¶ï¼æåæåº AutoRestTestï¼éæ¯ç¬¬ä¸åæ¡ç¨ä¾è³´åµå¥å¼å¤ä»£çæ¹æ³é²è¡ REST API æ¸¬è©¦çé»çæ¡æ¶ï¼å°å¤ä»£çå¼·åå­¸ç¿ (MARL) èèªç¾©å±¬æ§ä¾è³´å (SPDG) åå¤§åèªè¨æ¨¡å (LLM) æ´åå¨ä¸èµ·ãæåçåæ³å° REST API æ¸¬è©¦è¦çºä¸åå¯åé¢çåé¡ï¼å¶ä¸­ååä»£çï¼APIãä¾è³´éä¿ãåæ¸åå¼ï¼åååä½ä»¥æä½³å API æ¢ç´¢ãLLM èçç¹å®é åçå¼éå¶ï¼SPDG æ¨¡åä½¿ç¨ API æä½ä¹éçç¸ä¼¼æ§åæ¸ç°¡åä¾è³´éä¿çæå°ç©ºéï¼è MARL ååææä½³åä»£ççè¡çºãå¨ 12 é çå¯¦ä¸çç REST æåä¸é²è¡è©ä¼°ï¼AutoRestTest å¨ç¨å¼ç¢¼è¦èçãæä½è¦èçåé¯èª¤åµæ¸¬æ¹é¢ï¼åªæ¼åç¨®é åçé»ç REST API æ¸¬è©¦å·¥å·ï¼åæ¬é£äºç± RESTGPTï¼ä½¿ç¨ LLM å¢å é¼ççæ¸¬è©¦è¼¸å¥ï¼è¼å©çå·¥å·ãå¼å¾æ³¨æçæ¯ï¼AutoRestTest æ¯å¯ä¸è½å¤ è­å¥ Spotify ä¸­å§é¨ä¼ºæå¨é¯èª¤çå·¥å·ãæåçæ¶èç ç©¶å¼·èª¿äºä»£çå­¸ç¿ãSPDG å LLM çµä»¶çéå¤§è²¢ç»ã</paragraph>

##### **Bridge: A Unified Framework to Knowledge Graph Completion via Language Models and Knowledge Representation**
2411.06660v1 by Qiao Qiao, Yuepei Li, Qing Wang, Kang Zhou, Qi Li

Knowledge graph completion (KGC) is a task of inferring missing triples based
on existing Knowledge Graphs (KGs). Both structural and semantic information
are vital for successful KGC. However, existing methods only use either the
structural knowledge from the KG embeddings or the semantic information from
pre-trained language models (PLMs), leading to suboptimal model performance.
Moreover, since PLMs are not trained on KGs, directly using PLMs to encode
triples may be inappropriate. To overcome these limitations, we propose a novel
framework called Bridge, which jointly encodes structural and semantic
information of KGs. Specifically, we strategically encode entities and
relations separately by PLMs to better utilize the semantic knowledge of PLMs
and enable structured representation learning via a structural learning
principle. Furthermore, to bridge the gap between KGs and PLMs, we employ a
self-supervised representation learning method called BYOL to fine-tune PLMs
with two different views of a triple. Unlike BYOL, which uses augmentation
methods to create two semantically similar views of the same image, potentially
altering the semantic information. We strategically separate the triple into
two parts to create different views, thus avoiding semantic alteration.
Experiments demonstrate that Bridge outperforms the SOTA models on three
benchmark datasets.

æè¦ï¼ç¥è­åè­è£å¨ (KGC) æ¯ä¸é æ ¹æç¾æç¥è­åè­ (KG) æ¨è«éºå¤±ä¸åçµçä»»åãçµæ§åèªç¾©è³è¨å°æ¼æåç KGC è³ééè¦ãç¶èï¼ç¾ææ¹æ³åä½¿ç¨ä¾èª KG åµå¥ççµæ§ç¥è­æä¾èªé è¨ç·´èªè¨æ¨¡å (PLM) çèªç¾©è³è¨ï¼å°è´æ¨¡åæè½ä¸ä½³ãæ­¤å¤ï¼ç±æ¼ PLM æ²æå¨ KG ä¸è¨ç·´ï¼å æ­¤ç´æ¥ä½¿ç¨ PLM ç·¨ç¢¼ä¸åçµå¯è½ä¸¦ä¸é©ç¶ãçºäºåæéäºéå¶ï¼æåæåºä¸ååçº Bridge çæ°æ¶æ§ï¼è©²æ¶æ§è¯åç·¨ç¢¼ KG ççµæ§åèªç¾©è³è¨ãå·é«ä¾èªªï¼æåéé PLM åå¥å°å¯¦é«åéä¿é²è¡ç­ç¥æ§ç·¨ç¢¼ï¼ä»¥æ´å¥½å°å©ç¨ PLM çèªç¾©ç¥è­ï¼ä¸¦ééçµæ§å­¸ç¿åååç¨çµæ§åè¡¨ç¤ºå­¸ç¿ãæ­¤å¤ï¼çºäºå½å KG å PLM ä¹éçå·®è·ï¼æåæ¡ç¨ä¸ç¨®ç¨±çº BYOL çèªç£ç£è¡¨ç¤ºå­¸ç¿æ¹æ³ï¼ä»¥ä¸åçµçå©åä¸åè¦åå¾®èª¿ PLMãè BYOL ä¸åï¼BYOL ä½¿ç¨æ´åæ¹æ³ä¾å»ºç«å©åèªç¾©ä¸ç¸ä¼¼çç¸åå½±åè¦åï¼å¯è½ææ¹è®èªç¾©è³è¨ãæåç­ç¥æ§å°å°ä¸åçµåçºå©é¨åä»¥å»ºç«ä¸åçè¦åï¼å¾èé¿åèªç¾©æ¹è®ãå¯¦é©è­æ Bridge å¨ä¸ååºæºè³æéä¸åªæ¼ SOTA æ¨¡åã

##### **CausalStock: Deep End-to-end Causal Discovery for News-driven Stock Movement Prediction**
2411.06391v1 by Shuqi Li, Yuebo Sun, Yuxin Lin, Xin Gao, Shuo Shang, Rui Yan

There are two issues in news-driven multi-stock movement prediction tasks
that are not well solved in the existing works. On the one hand, "relation
discovery" is a pivotal part when leveraging the price information of other
stocks to achieve accurate stock movement prediction. Given that stock
relations are often unidirectional, such as the "supplier-consumer"
relationship, causal relations are more appropriate to capture the impact
between stocks. On the other hand, there is substantial noise existing in the
news data leading to extracting effective information with difficulty. With
these two issues in mind, we propose a novel framework called CausalStock for
news-driven multi-stock movement prediction, which discovers the temporal
causal relations between stocks. We design a lag-dependent temporal causal
discovery mechanism to model the temporal causal graph distribution. Then a
Functional Causal Model is employed to encapsulate the discovered causal
relations and predict the stock movements. Additionally, we propose a Denoised
News Encoder by taking advantage of the excellent text evaluation ability of
large language models (LLMs) to extract useful information from massive news
data. The experiment results show that CausalStock outperforms the strong
baselines for both news-driven multi-stock movement prediction and multi-stock
movement prediction tasks on six real-world datasets collected from the US,
China, Japan, and UK markets. Moreover, getting benefit from the causal
relations, CausalStock could offer a clear prediction mechanism with good
explainability.

æè¦ï¼<paragraph>å¨æ°èé©åçå¤è¡ç¥¨ç§»åé æ¸¬ä»»åä¸­ï¼ç¾æç ç©¶å°æªå¦¥åè§£æ±ºå©ååé¡ãä¸æ¹é¢ï¼å¨å©ç¨å¶ä»è¡ç¥¨çå¹æ ¼è³è¨ä¾å¯¦ç¾æºç¢ºçè¡ç¥¨ç§»åé æ¸¬æï¼ãéä¿ç¼ç¾ãæ¯ä¸åééµé¨åãç±æ¼è¡ç¥¨éä¿éå¸¸æ¯å®åçï¼ä¾å¦ãä¾æå-æ¶è²»èãéä¿ï¼å æ­¤å æéä¿æ´é©åææè¡ç¥¨ä¹éçå½±é¿ãå¦ä¸æ¹é¢ï¼æ°èè³æä¸­å­å¨å¤§ééè¨ï¼å°è´é£ä»¥æåææè³è¨ãèæ®å°éå©ååé¡ï¼æåæåºäºä¸ååçº CausalStock çæ°æ¡æ¶ï¼ç¨æ¼æ°èé©åçå¤è¡ç¥¨ç§»åé æ¸¬ï¼è©²æ¡æ¶ç¼ç¾äºè¡ç¥¨ä¹éçæåºå æéä¿ãæåè¨­è¨äºä¸åå»¶é²ä¾è³´çæåºå æç¼ç¾æ©å¶ï¼ä»¥å»ºæ¨¡æåºå æååå¸ãç¶å¾æ¡ç¨åè½å ææ¨¡åä¾å°è£ç¼ç¾çå æéä¿ä¸¦é æ¸¬è¡ç¥¨èµ°å¢ãæ­¤å¤ï¼æåæåºäºä¸åå»åªæ°èç·¨ç¢¼å¨ï¼å©ç¨å¤§åèªè¨æ¨¡å (LLM) åºè²çææ¬è©ä¼°è½åå¾å¤§éæ°èè³æä¸­æåæç¨è³è¨ãå¯¦é©çµæè¡¨æï¼CausalStock å¨å¾ç¾åãä¸­åãæ¥æ¬åè±åå¸å ´æ¶éçå­åçå¯¦ä¸çè³æéä¸ï¼å¨æ°èé©åçå¤è¡ç¥¨ç§»åé æ¸¬åå¤è¡ç¥¨ç§»åé æ¸¬ä»»åä¸­é½åªæ¼å¼·å¤§çåºç·ãæ­¤å¤ï¼CausalStock åçæ¼å æéä¿ï¼å¯ä»¥æä¾å·æè¯å¥½å¯è§£éæ§çæ¸æ°é æ¸¬æ©å¶ã</paragraph>

##### **Analyzing the Evolution of Graphs and Texts**
2411.06295v1 by Xingzhi Guo

With the recent advance of representation learning algorithms on graphs
(e.g., DeepWalk/GraphSage) and natural languages (e.g., Word2Vec/BERT) , the
state-of-the art models can even achieve human-level performance over many
downstream tasks, particularly for the task of node and sentence
classification. However, most algorithms focus on large-scale models for static
graphs and text corpus without considering the inherent dynamic characteristics
or discovering the reasons behind the changes. This dissertation aims to
efficiently model the dynamics in graphs (such as social networks and citation
graphs) and understand the changes in texts (specifically news titles and
personal biographies). To achieve this goal, we utilize the renowned
Personalized PageRank algorithm to create effective dynamic network embeddings
for evolving graphs. Our proposed approaches significantly improve the running
time and accuracy for both detecting network abnormal intruders and discovering
entity meaning shifts over large-scale dynamic graphs. For text changes, we
analyze the post-publication changes in news titles to understand the intents
behind the edits and discuss the potential impact of titles changes from
information integrity perspective. Moreover, we investigate self-presented
occupational identities in Twitter users' biographies over five years,
investigating job prestige and demographics effects in how people disclose
jobs, quantifying over-represented jobs and their transitions over time.

æè¦ï¼é¨èåå½¢è¡¨ç¤ºå­¸ç¿æ¼ç®æ³çææ°é²å±ï¼ä¾å¦ DeepWalk/GraphSageï¼åèªç¶èªè¨ï¼ä¾å¦ Word2Vec/BERTï¼ï¼æåé²çæ¨¡åçè³å¯ä»¥å¨è¨±å¤ä¸æ¸¸ä»»åä¸­éå°äººé¡ç­ç´çæè½ï¼ç¹å¥æ¯å°æ¼ç¯é»åå¥å­åé¡çä»»åãç¶èï¼å¤§å¤æ¸æ¼ç®æ³é½å°æ³¨æ¼éæåå½¢åå¤§è¦æ¨¡æå­èªæåº«çæ¨¡åï¼èæ²æèæ®åºæçåæç¹æ§ææ¾åºè®åçåå ãæ¬è«ææ¨å¨ææå°çºåå½¢ï¼ä¾å¦ç¤¾ç¾¤ç¶²è·¯åå¼æåå½¢ï¼å»ºæ¨¡åæï¼ä¸¦äºè§£æå­çè®åï¼ç¹å¥æ¯æ°èæ¨é¡ååäººå³è¨ï¼ãçºäºéæéåç®æ¨ï¼æåå©ç¨èåç Personalized PageRank æ¼ç®æ³çºä¸æ·è®åçåå½¢å»ºç«ææçåæç¶²è·¯åµå¥ãæåæåºçæ¹æ³é¡¯èæ¹åäºåµæ¸¬ç¶²è·¯ç°å¸¸å¥ä¾µèåæ¾åºå¤§è¦æ¨¡åæåå½¢ä¸­å¯¦é«å«ç¾©è½ç§»çå·è¡æéåæºç¢ºåº¦ãå°æ¼æå­è®åçé¨åï¼æååæäºæ°èæ¨é¡å¨åºçå¾çè®åï¼ä»¥äºè§£ç·¨è¼¯èå¾çæåï¼ä¸¦è¨è«æ¨é¡è®æ´å°è³è¨å®æ´æ§çæ½å¨å½±é¿ãæ­¤å¤ï¼æåèª¿æ¥äº Twitter ä½¿ç¨èå¨å³è¨ä¸­åç¾çè·æ¥­èº«åé·éäºå¹´ï¼æ¢è¨äºå·¥ä½è²æåäººå£çµ±è¨è³æå°äººåæ­é²å·¥ä½çå½±é¿ï¼ä¸¦éåäºéåº¦ä»£è¡¨çå·¥ä½åå¶é¨èæéæ¨ç§»çè½è®ã

##### **An Empirical Analysis on Spatial Reasoning Capabilities of Large Multimodal Models**
2411.06048v1 by Fatemeh Shiri, Xiao-Yu Guo, Mona Golestan Far, Xin Yu, Gholamreza Haffari, Yuan-Fang Li

Large Multimodal Models (LMMs) have achieved strong performance across a
range of vision and language tasks. However, their spatial reasoning
capabilities are under-investigated. In this paper, we construct a novel VQA
dataset, Spatial-MM, to comprehensively study LMMs' spatial understanding and
reasoning capabilities. Our analyses on object-relationship and multi-hop
reasoning reveal several important findings. Firstly, bounding boxes and scene
graphs, even synthetic ones, can significantly enhance LMMs' spatial reasoning.
Secondly, LMMs struggle more with questions posed from the human perspective
than the camera perspective about the image. Thirdly, chain of thought (CoT)
prompting does not improve model performance on complex multi-hop questions
involving spatial relations. % Moreover, spatial reasoning steps are much less
accurate than non-spatial ones across MLLMs. Lastly, our perturbation analysis
on GQA-spatial reveals that LMMs are much stronger at basic object detection
than complex spatial reasoning. We believe our benchmark dataset and in-depth
analyses can spark further research on LMMs spatial reasoning. Spatial-MM
benchmark is available at: https://github.com/FatemehShiri/Spatial-MM

æè¦ï¼å¤§åå¤æ¨¡ææ¨¡å (LMM) å·²å¨åç¨®è¦è¦ºåèªè¨ä»»åä¸­åå¾å¼·åçè¡¨ç¾ãç¶èï¼å®åçç©ºéæ¨çè½åå°æªå¾å°ååç ç©¶ãå¨æ¬æä¸­ï¼æåæ§å»ºäºä¸åæ°ç©ç VQA è³æé Spatial-MMï¼ä»¥å¨é¢ç ç©¶ LMM çç©ºéçè§£åæ¨çè½åãæåå°ç©ä»¶éä¿åå¤è·³æ¨ççåææ­ç¤ºäºå¹¾åéè¦çç¼ç¾ãé¦åï¼éçæ¡åå ´æ¯åï¼å³ä½¿æ¯åæçï¼ä¹å¯ä»¥é¡¯èå¢å¼· LMM çç©ºéæ¨çè½åãå¶æ¬¡ï¼LMM å¨åç­å¾äººé¡è¦è§æåºçåé¡ææ¯å¾ç¸æ©è¦è§æåºçåé¡æéå°æ´å¤å°é£ãç¬¬ä¸ï¼æèé (CoT) æç¤ºä¸¦æªæ¹åæ¨¡åå¨æ¶åç©ºééä¿çè¤éå¤è·³åé¡ä¸çæè½ã% æ­¤å¤ï¼å¨ MLLM ä¸­ï¼ç©ºéæ¨çæ­¥é©çæºç¢ºåº¦é ä½æ¼éç©ºéæ­¥é©ãæå¾ï¼æåå° GQA-spatial çæ¾ååæè¡¨æï¼LMM å¨åºæ¬ç©ä»¶åµæ¸¬æ¹é¢çè½åé å¼·æ¼è¤éçç©ºéæ¨çãæåç¸ä¿¡æåçåºæºè³æéåæ·±å¥åæå¯ä»¥æ¿ç¼å° LMM ç©ºéæ¨ççé²ä¸æ­¥ç ç©¶ãSpatial-MM åºæºå¯å¨ä»¥ä¸ç¶²ååå¾ï¼https://github.com/FatemehShiri/Spatial-MM

##### **Mitigating Hallucination with ZeroG: An Advanced Knowledge Management Engine**
2411.05936v1 by Anantha Sharma, Sheeba Elizabeth John, Fatemeh Rezapoor Nikroo, Krupali Bhatt, Mrunal Zambre, Aditi Wikhe

The growth of digital documents presents significant challenges in efficient
management and knowledge extraction. Traditional methods often struggle with
complex documents, leading to issues such as hallucinations and high latency in
responses from Large Language Models (LLMs). ZeroG, an innovative approach,
significantly mitigates these challenges by leveraging knowledge distillation
and prompt tuning to enhance model performance.
  ZeroG utilizes a smaller model that replicates the behavior of a larger
teacher model, ensuring contextually relevant and grounded responses, by
employing a black-box distillation approach, it creates a distilled dataset
without relying on intermediate features, optimizing computational efficiency.
This method significantly enhances accuracy and reduces response times,
providing a balanced solution for modern document management.
  Incorporating advanced techniques for document ingestion and metadata
utilization, ZeroG improves the accuracy of question-and-answer systems. The
integration of graph databases and robust metadata management further
streamlines information retrieval, allowing for precise and context-aware
responses. By transforming how organizations interact with complex data, ZeroG
enhances productivity and user experience, offering a scalable solution for the
growing demands of digital document management.

æè¦ï¼æ¸ä½æä»¶æé·å¸¶ä¾é¡¯èçææ°ï¼åæ¬ææç®¡çåç¥è­èåãå³çµ±æ¹æ³ç¶å¸¸é£ä»¥èçè¤éæä»¶ï¼å°è´åé¡ï¼ä¾å¦ç¢çå¹»è¦ºåå¤§åèªè¨æ¨¡å (LLM) åæçé«å»¶é²ãZeroG æ¯ä¸ç¨®åµæ°çæ¹æ³ï¼ééå©ç¨ç¥è­è¸é¤¾åæç¤ºèª¿æ´ä¾å¢å¼·æ¨¡åæè½ï¼å¤§å¹æ¸è¼éäºææ°ã
ZeroG ä½¿ç¨è¼å°çæ¨¡åè¤è£½è¼å¤§çæå¸«æ¨¡åçè¡çºï¼ééæ¡ç¨é»çè¸é¤¾æ¹æ³ï¼ç¢ºä¿å¨èçµ¡ä¸ç¸éä¸ææ ¹æçåæï¼å®å»ºç«ä¸åè¸é¤¾çè³æéï¼èä¸éè¦ä¾è³´ä¸­éç¹å¾µï¼æä½³åéç®æçãéç¨®æ¹æ³å¤§å¹æåæºç¢ºåº¦ä¸¦æ¸å°åææéï¼æä¾ç¾ä»£æä»¶ç®¡ççå¹³è¡¡è§£æ±ºæ¹æ¡ã
ééæ´åé²éæè¡ä¾æ·åæä»¶åä½¿ç¨åè³æï¼ZeroG æ¹ååç­ç³»çµ±çæºç¢ºåº¦ãåå½¢è³æåº«åå¼·å¥çåè³æç®¡ççæ´åé²ä¸æ­¥ç°¡åè³è¨æ·åï¼åè¨±ç²¾ç¢ºä¸ç¬¦åèçµ¡çåæãééè½æçµç¹èè¤éè³æäºåçæ¹å¼ï¼ZeroG æåçç¢ååä½¿ç¨èé«é©ï¼æä¾å¯æ´åçè§£æ±ºæ¹æ¡ï¼ä»¥æ»¿è¶³æ¸ä½æä»¶ç®¡çæ¥çå¢é·çéæ±ã

##### **SM3-Text-to-Query: Synthetic Multi-Model Medical Text-to-Query Benchmark**
2411.05521v2 by Sithursan Sivasubramaniam, Cedric Osei-Akoto, Yi Zhang, Kurt Stockinger, Jonathan Fuerst

Electronic health records (EHRs) are stored in various database systems with
different database models on heterogeneous storage architectures, such as
relational databases, document stores, or graph databases. These different
database models have a big impact on query complexity and performance. While
this has been a known fact in database research, its implications for the
growing number of Text-to-Query systems have surprisingly not been investigated
so far. In this paper, we present SM3-Text-to-Query, the first multi-model
medical Text-to-Query benchmark based on synthetic patient data from Synthea,
following the SNOMED-CT taxonomy -- a widely used knowledge graph ontology
covering medical terminology. SM3-Text-to-Query provides data representations
for relational databases (PostgreSQL), document stores (MongoDB), and graph
databases (Neo4j and GraphDB (RDF)), allowing the evaluation across four
popular query languages, namely SQL, MQL, Cypher, and SPARQL. We systematically
and manually develop 408 template questions, which we augment to construct a
benchmark of 10K diverse natural language question/query pairs for these four
query languages (40K pairs overall). On our dataset, we evaluate several common
in-context-learning (ICL) approaches for a set of representative closed and
open-source LLMs. Our evaluation sheds light on the trade-offs between database
models and query languages for different ICL strategies and LLMs. Last,
SM3-Text-to-Query is easily extendable to additional query languages or real,
standard-based patient databases.

æè¦ï¼é»å­å¥åº·è¨é (EHR) å²å­å¨å·æä¸åè³æåº«æ¨¡åçåç¨®è³æåº«ç³»çµ±ä¸­ï¼æ¡ç¨ç°è³ªå²å­æ¶æ§ï¼ä¾å¦éè¯å¼è³æåº«ãæä»¶å²å­åº«æåå½¢è³æåº«ãéäºä¸åçè³æåº«æ¨¡åå°æ¥è©¢è¤éåº¦åæè½æå¾å¤§çå½±é¿ãéç¶éå¨è³æåº«ç ç©¶ä¸­æ¯ä¸åå·²ç¥çäºå¯¦ï¼ä½å¶å°è¶ä¾è¶å¤çæå­è½æ¥è©¢ç³»çµ±çå½±é¿å»ä»¤äººé©è¨å°å°æªè¢«ç ç©¶ãå¨æ¬æä¸­ï¼æåæåº SM3-Text-to-Queryï¼éæ¯ç¬¬ä¸ååºæ¼ Synthea åææ£èè³æçå¤æ¨¡åé«çæå­è½æ¥è©¢åºæºï¼éµå¾ª SNOMED-CT åé¡æ³ï¼éæ¯ä¸åå»£æ³ä½¿ç¨çç¥è­åå½¢æ¬é«ï¼æ¶µèé«å­¸è¡èªãSM3-Text-to-Query æä¾äºéä¿è³æåº« (PostgreSQL)ãæä»¶å²å­åº« (MongoDB) ååå½¢è³æåº« (Neo4j å GraphDB (RDF)) çè³æè¡¨ç¤ºï¼åè¨±è·¨åç¨®æµè¡çæ¥è©¢èªè¨é²è¡è©ä¼°ï¼å³ SQLãMQLãCypher å SPARQLãæåç³»çµ±ä¸æåéç¼äº 408 åç¯æ¬åé¡ï¼ä¸¦æ´åéäºåé¡ä»¥å»ºæ§ä¸ååºæºï¼å¶ä¸­åå« 10K åéå°éåç¨®æ¥è©¢èªè¨çå¤æ¨£åèªç¶èªè¨åé¡/æ¥è©¢éå°ï¼ç¸½å± 40K åéå°ï¼ãå¨æåçè³æéä¸ï¼æåè©ä¼°äºä¸çµä»£è¡¨æ§çå°éåéæ¾åå§ç¢¼ LLM çå¹¾åå¸¸è¦æå¢å­¸ç¿ (ICL) æ¹æ³ãæåçè©ä¼°æ­ç¤ºäºä¸å ICL ç­ç¥å LLM çè³æåº«æ¨¡ååæ¥è©¢èªè¨ä¹éçæ¬è¡¡ãæå¾ï¼SM3-Text-to-Query å¯ä»¥è¼é¬æ´åå°å¶ä»æ¥è©¢èªè¨æçå¯¦çãåºæ¼æ¨æºçæ£èè³æåº«ã

##### **EUREKHA: Enhancing User Representation for Key Hackers Identification in Underground Forums**
2411.05479v1 by Abdoul Nasser Hassane Amadou, Anas Motii, Saida Elouardi, EL Houcine Bergou

Underground forums serve as hubs for cybercriminal activities, offering a
space for anonymity and evasion of conventional online oversight. In these
hidden communities, malicious actors collaborate to exchange illicit knowledge,
tools, and tactics, driving a range of cyber threats from hacking techniques to
the sale of stolen data, malware, and zero-day exploits. Identifying the key
instigators (i.e., key hackers), behind these operations is essential but
remains a complex challenge. This paper presents a novel method called EUREKHA
(Enhancing User Representation for Key Hacker Identification in Underground
Forums), designed to identify these key hackers by modeling each user as a
textual sequence. This sequence is processed through a large language model
(LLM) for domain-specific adaptation, with LLMs acting as feature extractors.
These extracted features are then fed into a Graph Neural Network (GNN) to
model user structural relationships, significantly improving identification
accuracy. Furthermore, we employ BERTopic (Bidirectional Encoder
Representations from Transformers Topic Modeling) to extract personalized
topics from user-generated content, enabling multiple textual representations
per user and optimizing the selection of the most representative sequence. Our
study demonstrates that fine-tuned LLMs outperform state-of-the-art methods in
identifying key hackers. Additionally, when combined with GNNs, our model
achieves significant improvements, resulting in approximately 6% and 10%
increases in accuracy and F1-score, respectively, over existing methods.
EUREKHA was tested on the Hack-Forums dataset, and we provide open-source
access to our code.

æè¦ï¼<paragraph>å°ä¸è«å£æ¯ç¶²è·¯ç¯ç½ªæ´»åçæ¨ç´ï¼æä¾å¿ååè¦é¿å³çµ±ç¶²è·¯ç£ç£çç©ºéãå¨éäºé±èçç¤¾ç¾¤ä¸­ï¼æ¡æè¡çºèåä½äº¤æéæ³ç¥è­ãå·¥å·åç­ç¥ï¼æ¨åå¾é§­å®¢æè¡å°é·å®ç«åè³æãæ¡æè»é«åé¶æå·®æ¼æ´çåç¨®ç¶²è·¯å¨èãæ¾åºéäºè¡åèå¾çééµç½åèï¼å³ééµé§­å®¢ï¼è³ééè¦ï¼ä½ä»ç¶æ¯ä¸åè¤éçææ°ãæ¬ææåºäºä¸ç¨®ç¨±çº EUREKHAï¼å¢å¼·ä½¿ç¨èè¡¨å¾µä»¥è­å¥å°ä¸è«å£ä¸­çééµé§­å®¢ï¼çæ°æ¹æ³ï¼æ¨å¨ééå°æ¯åä½¿ç¨èå»ºæ¨¡çºæå­åºåä¾è­å¥éäºééµé§­å®¢ãæ­¤åºåééå¤§åèªè¨æ¨¡åï¼LLMï¼èçä»¥é²è¡ç¹å®é åçé©æï¼å¶ä¸­ LLM ä½çºç¹å¾µèåå¨ãç¶å¾å°éäºèåçç¹å¾µè¼¸å¥åç¥ç¶ç¶²è·¯ï¼GNNï¼ä»¥å»ºæ¨¡ä½¿ç¨èçµæ§éä¿ï¼å¤§å¹æåè­å¥æºç¢ºåº¦ãæ­¤å¤ï¼æåæ¡ç¨ BERTopicï¼ä¾èª Transformer ä¸»é¡å»ºæ¨¡çéåç·¨ç¢¼å¨è¡¨å¾µï¼å¾ä½¿ç¨èç¢ççå§å®¹ä¸­èååäººåä¸»é¡ï¼çºæ¯åä½¿ç¨èåç¨å¤åæå­è¡¨å¾µï¼ä¸¦æä½³åæå·ä»£è¡¨æ§åºåçé¸æãæåçç ç©¶è¡¨æï¼å¾®èª¿å¾ç LLM å¨è­å¥ééµé§­å®¢æ¹é¢åªæ¼æåé²çæ¹æ³ãæ­¤å¤ï¼ç¶è GNN çµåä½¿ç¨æï¼æåçæ¨¡åç²å¾é¡¯èçæåï¼èç¾ææ¹æ³ç¸æ¯ï¼æºç¢ºåº¦å F1 åæ¸åå¥æé«äºç´ 6% å 10%ãEUREKHA å·²å¨ Hack-Forums è³æéä¸é²è¡æ¸¬è©¦ï¼æåæä¾éæºæ¹å¼å­åæåçç¨å¼ç¢¼ã</paragraph>

##### **When are 1.58 bits enough? A Bottom-up Exploration of BitNet Quantization**
2411.05882v1 by Jacob Nielsen, Lukas Galke, Peter Schneider-Kamp

Contemporary machine learning models, such as language models, are powerful,
but come with immense resource requirements both at training and inference
time. It has been shown that decoder-only language models can be trained to a
competitive state with ternary weights (1.58 bits per weight), facilitating
efficient inference. Here, we start our exploration with non-transformer model
architectures, investigating 1.58-bit training for multi-layer perceptrons and
graph neural networks. Then, we explore 1.58-bit training in other
transformer-based language models, namely encoder-only and encoder-decoder
models. Our results show that in all of these settings, 1.58-bit training is on
par with or sometimes even better than the standard 32/16-bit models.

æè¦ï¼ç¶ä»£æ©å¨å­¸ç¿æ¨¡åï¼ä¾å¦èªè¨æ¨¡åï¼åè½å¼·å¤§ï¼
ä½å¨è¨ç·´åæ¨è«æéä¸é½éè¦å¤§éçè³æºãå·²ç¶è­æï¼åè§£ç¢¼å¨èªè¨æ¨¡åå¯ä»¥ç¨ä¸åæ¬éï¼æ¯åæ¬é 1.58 ä½åï¼è¨ç·´å°ç«¶ç­çæï¼ä¿é²ææççæ¨è«ãå¨æ­¤ï¼æåå¾éTransformeræ¨¡åæ¶æ§éå§æ¢è¨ï¼ç ç©¶å¤å±¤æç¥å¨ååç¥ç¶ç¶²è·¯ç 1.58 ä½åè¨ç·´ãæ¥èï¼æåæ¢è¨å¶ä»åºæ¼Transformerçèªè¨æ¨¡åï¼å³åç·¨ç¢¼å¨åç·¨ç¢¼å¨-è§£ç¢¼å¨æ¨¡åï¼ç 1.58 ä½åè¨ç·´ãæåççµæé¡¯ç¤ºï¼å¨ææéäºè¨­å®ä¸­ï¼1.58 ä½åè¨ç·´èæ¨æº 32/16 ä½åæ¨¡åç¸ç¶ï¼ææçè³æ´å¥½ã

##### **Exploring the Alignment Landscape: LLMs and Geometric Deep Models in Protein Representation**
2411.05316v1 by Dong Shu, Bingbing Duan, Kai Guo, Kaixiong Zhou, Jiliang Tang, Mengnan Du

Latent representation alignment has become a foundational technique for
constructing multimodal large language models (MLLM) by mapping embeddings from
different modalities into a shared space, often aligned with the embedding
space of large language models (LLMs) to enable effective cross-modal
understanding. While preliminary protein-focused MLLMs have emerged, they have
predominantly relied on heuristic approaches, lacking a fundamental
understanding of optimal alignment practices across representations. In this
study, we explore the alignment of multimodal representations between LLMs and
Geometric Deep Models (GDMs) in the protein domain. We comprehensively evaluate
three state-of-the-art LLMs (Gemma2-2B, LLaMa3.1-8B, and LLaMa3.1-70B) with
four protein-specialized GDMs (GearNet, GVP, ScanNet, GAT). Our work examines
alignment factors from both model and protein perspectives, identifying
challenges in current alignment methodologies and proposing strategies to
improve the alignment process. Our key findings reveal that GDMs incorporating
both graph and 3D structural information align better with LLMs, larger LLMs
demonstrate improved alignment capabilities, and protein rarity significantly
impacts alignment performance. We also find that increasing GDM embedding
dimensions, using two-layer projection heads, and fine-tuning LLMs on
protein-specific data substantially enhance alignment quality. These strategies
offer potential enhancements to the performance of protein-related multimodal
models. Our code and data are available at
https://github.com/Tizzzzy/LLM-GDM-alignment.

æè¦ï¼æ½å¨è¡¨å¾µå°é½å·²æçºå»ºæ§å¤æ¨¡æå¤§åèªè¨æ¨¡å (MLLM) çåºç¤æè¡ï¼æ¹æ³æ¯å°ä¸åæ¨¡æçåµå¥æ å°å°å±äº«ç©ºéä¸­ï¼éå¸¸èå¤§åèªè¨æ¨¡å (LLM) çåµå¥ç©ºéå°é½ï¼ä»¥å¯¦ç¾ææçè·¨æ¨¡æçè§£ãéç¶åæ­¥ä»¥èç½è³ªçºéé»ç MLLM å·²åºç¾ï¼ä½å®åä¸»è¦ä¾è³´åç¼å¼æ¹æ³ï¼ç¼ºä¹å°è·¨è¡¨å¾µæä½³å°é½å¯¦åçåºæ¬çè§£ãå¨æ¬ç ç©¶ä¸­ï¼æåæ¢è¨äºèç½è³ªé åä¸­ LLM èå¹¾ä½æ·±åº¦æ¨¡å (GDM) ä¹éçå¤æ¨¡æè¡¨å¾µå°é½ãæåå¨é¢è©ä¼°äºä¸åæåé²ç LLMï¼Gemma2-2BãLLaMa3.1-8B å LLaMa3.1-70Bï¼èååèç½è³ªå°ç¨ GDMï¼GearNetãGVPãScanNetãGATï¼ãæåçç ç©¶å¾æ¨¡ååèç½è³ªè§åº¦æª¢è¦å°é½å ç´ ï¼è­å¥ç¶åå°é½æ¹æ³çææ°ï¼ä¸¦æåºæ¹åå°é½ç¨åºçç­ç¥ãæåçééµç¼ç¾é¡¯ç¤ºï¼åæåå«åå½¢å 3D çµæ§è³è¨ç GDM è LLM çå°é½ææè¼ä½³ï¼è¼å¤§ç LLM å±ç¾åºæ´ä½³çå°é½è½åï¼èèç½è³ªçç¨ææ§é¡¯èå½±é¿å°é½æè½ãæåéç¼ç¾ï¼å¢å  GDM åµå¥ç¶­åº¦ãä½¿ç¨å©å±¤æå½±é ­ï¼ä»¥åéå°èç½è³ªç¹å®è³æå¾®èª¿ LLMï¼å¯ä»¥å¤§å¹æåå°é½åè³ªãéäºç­ç¥çºèç½è³ªç¸éå¤æ¨¡ææ¨¡åçæè½æä¾æ½å¨çå¼·åãæåçç¨å¼ç¢¼åè³æå¯å¨ https://github.com/Tizzzzy/LLM-GDM-alignment åå¾ã

##### **AMSnet-KG: A Netlist Dataset for LLM-based AMS Circuit Auto-Design Using Knowledge Graph RAG**
2411.13560v1 by Yichen Shi, Zhuofu Tao, Yuhao Gao, Tianjia Zhou, Cheng Chang, Yaxing Wang, Bingyu Chen, Genhao Zhang, Alvin Liu, Zhiping Yu, Ting-Jung Lin, Lei He

High-performance analog and mixed-signal (AMS) circuits are mainly
full-custom designed, which is time-consuming and labor-intensive. A
significant portion of the effort is experience-driven, which makes the
automation of AMS circuit design a formidable challenge. Large language models
(LLMs) have emerged as powerful tools for Electronic Design Automation (EDA)
applications, fostering advancements in the automatic design process for
large-scale AMS circuits. However, the absence of high-quality datasets has led
to issues such as model hallucination, which undermines the robustness of
automatically generated circuit designs. To address this issue, this paper
introduces AMSnet-KG, a dataset encompassing various AMS circuit schematics and
netlists. We construct a knowledge graph with annotations on detailed
functional and performance characteristics. Facilitated by AMSnet-KG, we
propose an automated AMS circuit generation framework that utilizes the
comprehensive knowledge embedded in LLMs. We first formulate a design strategy
(e.g., circuit architecture using a number of circuit components) based on
required specifications. Next, matched circuit components are retrieved and
assembled into a complete topology, and transistor sizing is obtained through
Bayesian optimization. Simulation results of the netlist are fed back to the
LLM for further topology refinement, ensuring the circuit design specifications
are met. We perform case studies of operational amplifier and comparator design
to verify the automatic design flow from specifications to netlists with
minimal human effort. The dataset used in this paper will be open-sourced upon
publishing of this paper.

æè¦ï¼é«æ§è½é¡æ¯èæ··åè¨è (AMS) é»è·¯ä¸»è¦çºå¨å®¢è£½åè¨­è¨ï¼éç¸ç¶èæä¸è²»å·¥ãå¶ä¸­å¾å¤§ä¸é¨åçå·¥ä½ä»°è³´ç¶é©ï¼éè® AMS é»è·¯è¨­è¨çèªååæçºä¸é è±éçææ°ãå¤§åèªè¨æ¨¡å (LLM) å·²æçºé»å­è¨­è¨èªåå (EDA) æç¨ç¨å¼å¼·å¤§çå·¥å·ï¼ä¿é²å¤§è¦æ¨¡ AMS é»è·¯èªåè¨­è¨æµç¨çé²å±ãç¶èï¼ç¼ºä¹é«åè³ªçè³æéå°è´æ¨¡ååºç¾å¹»è¦ºç­åé¡ï¼éæå®³äºèªåç¢çé»è·¯è¨­è¨çç©©å¥æ§ãçºäºè§£æ±ºæ­¤åé¡ï¼æ¬æä»ç´¹äº AMSnet-KGï¼éæ¯ä¸ååå«åç¨® AMS é»è·¯åçååç¶²è·¯æ¸å®çè³æéãæåå»ºç«äºä¸ååå«è©³ç´°åè½åæè½ç¹å¾µè¨»è§£çç¥è­åè­ãå¨ AMSnet-KG çåå©ä¸ï¼æåæåºäºä¸åèªåå AMS é»è·¯ç¢çæ¶æ§ï¼å®å©ç¨äºå§åµå¨ LLM ä¸­çå¨é¢ç¥è­ãæåé¦åæ ¹ææéè¦æ ¼å¶å®è¨­è¨ç­ç¥ï¼ä¾å¦ä½¿ç¨å¤åé»è·¯åä»¶çé»è·¯æ¶æ§ï¼ãæ¥èï¼æ·åå¹éçé»è·¯åä»¶ä¸¦çµè£æä¸åå®æ´çææ²ï¼ä¸¦ééè²æ°æä½³ååå¾é»æ¶é«å°ºå¯¸ãç¶²è·¯æ¸å®çæ¨¡æ¬çµææåé¥çµ¦ LLM ä»¥é²ä¸æ­¥åªåææ²ï¼ç¢ºä¿é»è·¯è¨­è¨è¦æ ¼å¾å°æ»¿è¶³ãæåå·è¡éç®æ¾å¤§å¨åæ¯è¼å¨è¨­è¨çåæ¡ç ç©¶ï¼ä»¥é©è­å¾è¦æ ¼å°ç¶²è·¯æ¸å®çèªåè¨­è¨æµç¨ï¼ä¸¦å°äººçºä»å¥éå°æä½ãæ¬æä¸­ä½¿ç¨çè³æéå°å¨æ¬æç¼å¸å¾éæºã

##### **LEGO-GraphRAG: Modularizing Graph-based Retrieval-Augmented Generation for Design Space Exploration**
2411.05844v1 by Yukun Cao, Zengyi Gao, Zhiyang Li, Xike Xie, S Kevin Zhou

GraphRAG addresses significant challenges in Retrieval-Augmented Generation
(RAG) by leveraging graphs with embedded knowledge to enhance the reasoning
capabilities of Large Language Models (LLMs). Despite its promising potential,
the GraphRAG community currently lacks a unified framework for fine-grained
decomposition of the graph-based knowledge retrieval process. Furthermore,
there is no systematic categorization or evaluation of existing solutions
within the retrieval process. In this paper, we present LEGO-GraphRAG, a
modular framework that decomposes the retrieval process of GraphRAG into three
interconnected modules: subgraph-extraction, path-filtering, and
path-refinement. We systematically summarize and classify the algorithms and
neural network (NN) models relevant to each module, providing a clearer
understanding of the design space for GraphRAG instances. Additionally, we
identify key design factors, such as Graph Coupling and Computational Cost,
that influence the effectiveness of GraphRAG implementations. Through extensive
empirical studies, we construct high-quality GraphRAG instances using a
representative selection of solutions and analyze their impact on retrieval and
reasoning performance. Our findings offer critical insights into optimizing
GraphRAG instance design, ultimately contributing to the advancement of more
accurate and contextually relevant LLM applications.

æè¦ï¼GraphRAG ééå©ç¨å·åµå¥ç¥è­çåè¡¨ä¾å¢å¼·å¤§åèªè¨æ¨¡å (LLM) çæ¨çè½åï¼è§£æ±ºäºæª¢ç´¢å¢å¼·çæ (RAG) ä¸­çéå¤§ææ°ãåç®¡å·æä»¤äººæå¾çæ½åï¼ä½ GraphRAG ç¤¾ç¾¤ç®åç¼ºä¹ä¸åçµ±ä¸çæ¶æ§ï¼ç¨æ¼å°åºæ¼åè¡¨çç¥è­æª¢ç´¢éç¨é²è¡ç´°ç²åº¦çåè§£ãæ­¤å¤ï¼å¨æª¢ç´¢éç¨ä¸­ï¼ç¾æè§£æ±ºæ¹æ¡ä¸¦æªé²è¡ç³»çµ±æ§çåé¡æè©ä¼°ãå¨æ¬æä¸­ï¼æåæåºäº LEGO-GraphRAGï¼éæ¯ä¸åæ¨¡çµåæ¶æ§ï¼å° GraphRAG çæª¢ç´¢éç¨åè§£çºä¸åç¸äºé£æ¥çæ¨¡çµï¼å­åèåãè·¯å¾éæ¿¾åè·¯å¾ç²¾çãæåç³»çµ±æ§å°ç¸½çµååé¡èæ¯åæ¨¡çµç¸éçæ¼ç®æ³åç¥ç¶ç¶²è·¯ (NN) æ¨¡åï¼æä¾å° GraphRAG å¯¦ä¾è¨­è¨ç©ºéçæ´æ¸æ°çè§£ãæ­¤å¤ï¼æåæ¾åºå½±é¿ GraphRAG å¯¦ä½æææ§çééµè¨­è¨å ç´ ï¼ä¾å¦åè¡¨è¦ååéç®ææ¬ãééå»£æ³çç¶é©ç ç©¶ï¼æåä½¿ç¨å·ä»£è¡¨æ§çè§£æ±ºæ¹æ¡é¸æä¾å»ºæ§é«åè³ªç GraphRAG å¯¦ä¾ï¼ä¸¦åæå®åå°æª¢ç´¢åæ¨çæè½çå½±é¿ãæåçç ç©¶çµææä¾äºåªå GraphRAG å¯¦ä¾è¨­è¨çéè¦è¦è§£ï¼æçµæå©æ¼æ¨é²æ´æºç¢ºä¸èèçµ¡ç¸éç LLM æç¨ã

##### **MEG: Medical Knowledge-Augmented Large Language Models for Question Answering**
2411.03883v2 by Laura Cabello, Carmen Martin-Turrero, Uchenna Akujuobi, Anders SÃ¸gaard, Carlos Bobed

Question answering is a natural language understanding task that involves
reasoning over both explicit context and unstated, relevant domain knowledge.
Large language models (LLMs), which underpin most contemporary question
answering systems, struggle to induce how concepts relate in specialized
domains such as medicine. Existing medical LLMs are also costly to train. In
this work, we present MEG, a parameter-efficient approach for medical
knowledge-augmented LLMs. MEG uses a lightweight mapping network to integrate
graph embeddings into the LLM, enabling it to leverage external knowledge in a
cost-effective way. We evaluate our method on four popular medical
multiple-choice datasets and show that LLMs greatly benefit from the factual
grounding provided by knowledge graph embeddings. MEG attains an average of
+10.2% accuracy over the Mistral-Instruct baseline, and +6.7% over specialized
models like BioMistral. We also show results based on Llama-3. Finally, we show
that MEG's performance remains robust to the choice of graph encoder.

æè¦ï¼åç­æ¯èªç¶èªè¨çè§£ä»»åï¼æ¶åå°æç¢ºçä¸ä¸æåæªèªªæçç¸éé åç¥è­é²è¡æ¨çãæ¯æå¤§å¤æ¸ç¶ä»£åç­ç³»çµ±çå¤§åèªè¨æ¨¡å (LLM) é£ä»¥æ¨è«æ¦å¿µå¦ä½å¨é«å­¸ç­å°æ¥­é åä¸­éè¯ãç¾æçé«å­¸ LLM è¨ç·´ææ¬ä¹å¾é«ãå¨éé å·¥ä½ä¸­ï¼æåæåºäº MEGï¼éæ¯ä¸ç¨®ç¨æ¼é«å­¸ç¥è­å¢å¼· LLM çåæ¸æææ¹æ³ãMEG ä½¿ç¨è¼éç´æ å°ç¶²è·¯å°åè¡¨åµå¥æ´åå° LLM ä¸­ï¼ä½¿å¶è½å¤ ä»¥ç¶æ¿ææçæ¹å¼å©ç¨å¤é¨ç¥è­ãæåå¨ååæµè¡çé«å­¸å¤é¸é¡è³æéä¸è©ä¼°äºæåçæ¹æ³ï¼ä¸¦è¡¨æ LLM å¾ç¥è­åè¡¨åµå¥æä¾çå¯¦éä¾æä¸­åçåªæ·ºãMEG å¨ Mistral-Instruct åºæºä¸å¹³åæé«äº +10.2% çæºç¢ºåº¦ï¼å¨ BioMistral ç­å°éæ¨¡åä¸æé«äº +6.7%ãæåéå±ç¤ºäºåºæ¼ Llama-3 ççµæãæå¾ï¼æåè¡¨æ MEG çæ§è½å°åè¡¨ç·¨ç¢¼å¨çé¸æä¿æç©©å¥ã

##### **A Library Perspective on Supervised Text Processing in Digital Libraries: An Investigation in the Biomedical Domain**
2411.12752v1 by Hermann Kroll, Pascal Sackhoff, Bill Matthias Thang, Maha Ksouri, Wolf-Tilo Balke

Digital libraries that maintain extensive textual collections may want to
further enrich their content for certain downstream applications, e.g.,
building knowledge graphs, semantic enrichment of documents, or implementing
novel access paths. All of these applications require some text processing,
either to identify relevant entities, extract semantic relationships between
them, or to classify documents into some categories. However, implementing
reliable, supervised workflows can become quite challenging for a digital
library because suitable training data must be crafted, and reliable models
must be trained. While many works focus on achieving the highest accuracy on
some benchmarks, we tackle the problem from a digital library practitioner. In
other words, we also consider trade-offs between accuracy and application
costs, dive into training data generation through distant supervision and large
language models such as ChatGPT, LLama, and Olmo, and discuss how to design
final pipelines. Therefore, we focus on relation extraction and text
classification, using the showcase of eight biomedical benchmarks.

æè¦ï¼ç¶­è­·å»£æ³ææ¬éåçæ¸ä½åæ¸é¤¨å¯è½å¸æé²ä¸æ­¥è±å¯å¶å§å®¹ä»¥ä¾ç¹å®ä¸æ¸¸æç¨ç¨å¼ä½¿ç¨ï¼ä¾å¦å»ºæ§ç¥è­åè­ãæä»¶èªæè±å¯åæå¯¦ä½æ°ç©çå­åè·¯å¾ãææéäºæç¨ç¨å¼é½éè¦ä¸äºæå­èçï¼æè½è­å¥ç¸éå¯¦é«ãèåå®åä¹éçèªæéä¿ï¼æå°æä»¶åé¡å°æäºé¡å¥ä¸­ãç¶èï¼å°æ¼æ¸ä½åæ¸é¤¨ä¾èªªï¼å¯¦ä½å¯é çç£ç£å¼å·¥ä½æµç¨å¯è½æè®å¾ç¸ç¶å·æææ°æ§ï¼å çºå¿é å»ºç«é©ç¶çè¨ç·´è³æï¼ä¸¦è¨ç·´å¯é çæ¨¡åãéç¶è¨±å¤ç ç©¶å°æ³¨æ¼å¨æäºåºæºä¸éææé«æºç¢ºåº¦ï¼ä½æåå¾æ¸ä½åæ¸é¤¨å¯¦åèçè§åº¦ä¾è§£æ±ºéååé¡ãæå¥è©±èªªï¼æåä¹èæ®æºç¢ºåº¦åæç¨ææ¬ä¹éçæ¬è¡¡ï¼æ·±å¥æ¢è¨ééé è·ç£ç£åå¤§åèªè¨æ¨¡åï¼ä¾å¦ ChatGPTãLLama å Olmoï¼ä¾ç¢çè¨ç·´è³æï¼ä¸¦è¨è«å¦ä½è¨­è¨æçµç®¡ç·ãå æ­¤ï¼æåå°æ³¨æ¼éä¿èååæå­åé¡ï¼ä¸¦ä½¿ç¨å«åçç©é«å­¸åºæºä½çºå±ç¤ºæ¡ä¾ã

##### **The American Sign Language Knowledge Graph: Infusing ASL Models with Linguistic Knowledge**
2411.03568v1 by Lee Kezar, Nidhi Munikote, Zian Zeng, Zed Sehyr, Naomi Caselli, Jesse Thomason

Language models for American Sign Language (ASL) could make language
technologies substantially more accessible to those who sign. To train models
on tasks such as isolated sign recognition (ISR) and ASL-to-English
translation, datasets provide annotated video examples of ASL signs. To
facilitate the generalizability and explainability of these models, we
introduce the American Sign Language Knowledge Graph (ASLKG), compiled from
twelve sources of expert linguistic knowledge. We use the ASLKG to train
neuro-symbolic models for 3 ASL understanding tasks, achieving accuracies of
91% on ISR, 14% for predicting the semantic features of unseen signs, and 36%
for classifying the topic of Youtube-ASL videos.

æè¦ï¼ç¾åæèª (ASL) çèªè¨æ¨¡åå¯ä»¥è®èªè¨æè¡å°æèªä½¿ç¨èæ´ææ¼ä½¿ç¨ãçºäºè¨ç·´æ¨¡åå·è¡æèªè¾¨è­ (ISR) å ASL è½ææè±æç­ä»»åï¼è³æéæä¾ ASL æå¢çè¨»è§£å½±çç¯ä¾ãçºäºä¿é²éäºæ¨¡åçæ¦æ¬æ§åå¯è§£éæ§ï¼æåå¼å¥äºç¾åæèªç¥è­åè­ (ASLKG)ï¼å®æ¯ç±åäºåå°å®¶èªè¨ç¥è­ä¾æºç·¨è­¯èæçãæåä½¿ç¨ ASLKG è¨ç·´ç¥ç¶ç¬¦èæ¨¡åä¾å·è¡ 3 é  ASL çè§£ä»»åï¼å¨ ISR ä¸éå° 91% çæºç¢ºåº¦ãå¨é æ¸¬æªè¦æå¢çèªç¾©ç¹å¾µä¸éå° 14%ï¼ä»¥åå¨åé¡ YouTube-ASL å½±çä¸»é¡ä¸éå° 36%ã

##### **Graph-DPEP: Decomposed Plug and Ensemble Play for Few-Shot Document Relation Extraction with Graph-of-Thoughts Reasoning**
2411.02864v1 by Tao Zhang, Ning Yan, Masood Mortazavi, Hoang H. Nguyen, Zhongfen Deng, Philip S. Yu

Large language models (LLMs) pre-trained on massive corpora have demonstrated
impressive few-shot learning capability on many NLP tasks. Recasting an NLP
task into a text-to-text generation task is a common practice so that
generative LLMs can be prompted to resolve it. However, performing
document-level relation extraction (DocRE) tasks with generative LLM models is
still challenging due to the structured output format of DocRE, which
complicates the conversion to plain text. Limited information available in
few-shot samples and prompt instructions induce further difficulties and
challenges in relation extraction for mentioned entities in a document. In this
paper, we represent the structured output as a graph-style triplet rather than
natural language expressions and leverage generative LLMs for the DocRE task.
Our approach, the Graph-DPEP framework is grounded in the reasoning behind
triplet explanation thoughts presented in natural language. In this framework,
we first introduce a ``decomposed-plug" method for performing the generation
from LLMs over prompts with type-space decomposition to alleviate the burden of
distinguishing all relation types. Second, we employ a verifier for calibrating
the generation and identifying overlooked query entity pairs. Third, we develop
"ensemble-play", reapplying generation on the entire type list by leveraging
the reasoning thoughts embedded in a sub-graph associated with the missing
query pair to address the missingness issue. Through extensive comparisons with
existing prompt techniques and alternative Language Models (LLMs), our
framework demonstrates superior performance on publicly available benchmarks in
experiments.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨æµ·éèªæåº«ä¸é åè¨ç·´ï¼å·²å¨è¨±å¤èªç¶èªè¨èçä»»åä¸å±ç¾åºä»¤äººå°è±¡æ·±å»çå°éæ¨£æ¬å­¸ç¿è½åãå°èªç¶èªè¨èçä»»åè½åçºæå­å°æå­ççæä»»åæ¯ä¸ç¨®å¸¸è¦åæ³ï¼éæ¨£çæå¼å¤§åèªè¨æ¨¡åå°±å¯ä»¥æç¤ºè§£æ±ºå®ãç¶èï¼ç±æ¼ DocRE ççµæ§åè¼¸åºæ ¼å¼ï¼ä½¿ç¨çæå¼å¤§åèªè¨æ¨¡åä¾å·è¡æä»¶ç´å¥éä¿èå (DocRE) ä»»åä»ç¶å·æææ°æ§ï¼éä½¿å¾è½æçºç´æå­è®å¾è¤éãå°éæ¨£æ¬åæç¤ºèªªæä¸­å¯ç¨çè³è¨æéï¼æå°è´å¨æä»¶ä¸­æå°å¯¦é«çéä¿èåä¸­ç¢çé²ä¸æ­¥çå°é£åææ°ãå¨æ¬æä¸­ï¼æåå°çµæ§åè¼¸åºè¡¨ç¤ºçºåå½¢æ¨£å¼çä¸åçµï¼èä¸æ¯èªç¶èªè¨è¡¨éï¼ä¸¦å©ç¨çæå¼å¤§åèªè¨æ¨¡åä¾å·è¡ DocRE ä»»åãæåçåæ³ï¼åå½¢ DPEP æ¡æ¶ï¼æ¯åºæ¼èªç¶èªè¨ä¸­åç¾çä¸åçµè§£éææ³èå¾çæ¨çãå¨éåæ¡æ¶ä¸­ï¼æåé¦åä»ç´¹ä¸ç¨®ãåè§£æå¥ãæ¹æ³ï¼ç¨æ¼å°å·æé¡åç©ºéåè§£çæç¤ºé²è¡å¤§åèªè¨æ¨¡åçæï¼ä»¥æ¸è¼ååææéä¿é¡åçè² æãå¶æ¬¡ï¼æåä½¿ç¨é©è­å¨ä¾æ ¡æºçæä¸¦è­å¥è¢«å¿½ç¥çæ¥è©¢å¯¦é«å°ãç¬¬ä¸ï¼æåéç¼ãæ´é«éæ²ãï¼ééå©ç¨èéºå¤±æ¥è©¢å°ç¸éçå­åä¸­åµå¥çæ¨çææ³ï¼å¨æ´åé¡ååè¡¨ä¸éæ°æç¨çæï¼ä»¥è§£æ±ºéºå¤±åé¡ãééèç¾ææç¤ºæè¡åæ¿ä»£èªè¨æ¨¡å (LLM) çå»£æ³æ¯è¼ï¼æåçæ¡æ¶å¨å¯¦é©ä¸­è­æäºå¨å¬éåºæºä¸çåªç°æ§è½ã

##### **Multimodal Commonsense Knowledge Distillation for Visual Question Answering**
2411.02722v1 by Shuo Yang, Siwen Luo, Soyeon Caren Han

Existing Multimodal Large Language Models (MLLMs) and Visual Language
Pretrained Models (VLPMs) have shown remarkable performances in the general
Visual Question Answering (VQA). However, these models struggle with VQA
questions that require external commonsense knowledge due to the challenges in
generating high-quality prompts and the high computational costs of
fine-tuning. In this work, we propose a novel graph-based multimodal
commonsense knowledge distillation framework that constructs a unified
relational graph over commonsense knowledge, visual objects and questions
through a Graph Convolutional Network (GCN) following a teacher-student
environment. This proposed framework is flexible with any type of teacher and
student models without further fine-tuning, and has achieved competitive
performances on the ScienceQA dataset.

æè¦ï¼ç¾æçå¤æ¨¡æå¤§åèªè¨æ¨¡å (MLLM) åè¦è¦ºèªè¨é è¨ç·´æ¨¡å (VLPM) å¨ä¸è¬çè¦è¦ºåç­ (VQA) ä¸­å±ç¾äºåè¶çè¡¨ç¾ãç¶èï¼éäºæ¨¡åå¨éè¦å¤é¨å¸¸è­ç¥è­ç VQA åé¡ä¸æéå°å°é£ï¼åå å¨æ¼ç¢çé«åè³ªæç¤ºçææ°ä»¥åå¾®èª¿çé«éç®ææ¬ãå¨éé å·¥ä½ä¸­ï¼æåæåºäºä¸åæ°ç©çåºæ¼åå½¢çæ¨¡æå¸¸è­ç¥è­èåæ¶æ§ï¼ééåå½¢å·ç©ç¶²è·¯ (GCN) å¨å¸¸è­ç¥è­ãè¦è¦ºç©ä»¶ååé¡ä¸å»ºæ§ä¸åçµ±ä¸çéè¯åå½¢ï¼éµå¾ªå¸«çç°å¢ãéåæåºçæ¶æ§å°æ¼ä»»ä½é¡åçæå¸«åå­¸çæ¨¡åé½å·æå½æ§ï¼ç¡éé²ä¸æ­¥å¾®èª¿ï¼ä¸¦å¨ ScienceQA è³æéä¸åå¾äºæç«¶ç­åçè¡¨ç¾ã

##### **Geometry of orofacial neuromuscular signals: speech articulation decoding using surface electromyography**
2411.02591v2 by Harshavardhana T. Gowda, Zachary D. McNaughton, Lee M. Miller

Each year, millions of individuals lose the ability to speak intelligibly due
to causes such as neuromuscular disease, stroke, trauma, and head/neck cancer
surgery (e.g. laryngectomy) or treatment (e.g. radiotherapy toxicity to the
speech articulators). Effective communication is crucial for daily activities,
and losing the ability to speak leads to isolation, depression, anxiety, and a
host of detrimental sequelae. Noninvasive surface electromyography (sEMG) has
shown promise to restore speech output in these individuals. The goal is to
collect sEMG signals from multiple articulatory sites as people silently
produce speech and then decode the signals to enable fluent and natural
communication. Currently, many fundamental properties of orofacial
neuromuscular signals relating to speech articulation remain unanswered. They
include questions relating to 1) the data structure of the orofacial sEMG
signals, 2)the signal distribution shift of sEMG across individuals, 3) ability
of sEMG signals to span the entire English language phonetic space during
silent speech articulations, and 4) the generalization capability of
non-invasive sEMG based silent speech interfaces. We address these questions
through a series of experiments involving healthy human subjects. We show that
sEMG signals evince graph data structure and that the signal distribution shift
is given by a change of basis. Furthermore, we show that silently voiced
articulations spanning the entire English language phonetic space can be
decoded using small neural networks which can be trained with little data and
that such architectures work well across individuals. To ensure transparency
and reproducibility, we open-source all the data and codes used in this study.

æè¦ï¼æ¯å¹´ï¼æ¸ç¾è¬äººå ç¥ç¶èèç¾çãä¸­é¢¨ãåµå·ãé ­é ¸çæè¡ï¼ä¾å¦ååé¤è¡ï¼ææ²»çï¼ä¾å¦æ¾å°æ²»çå°è¨èªæ§é³å¨å®çæ¯æ§ï¼èå¤±å»æ¸æ°èªªè©±çè½åãææçæºéå°æ¼æ¥å¸¸æ´»åè³ééè¦ï¼èå¤±å»èªªè©±çè½åæå°è´å­¤ç«ãæ²®åªãç¦æ®åä¸ç³»åæå®³çå¾éºçãéä¾µå¥æ§è¡¨é¢èé»å (sEMG) å·²é¡¯ç¤ºåºæ¢å¾©éäºäººèªªè©±è¼¸åºçå¸æãç®æ¨æ¯å¾å¤åæ§é³é¨ä½æ¶é sEMG ä¿¡èï¼å çºäººåå¨ç¡è²å°ç¼é³ï¼ç¶å¾è§£ç¢¼ä¿¡èä»¥å¯¦ç¾æµå©èèªç¶çæºéãç®åï¼è¨±å¤èè¨èªæ§é³æéçé¢é¨ç¥ç¶èèä¿¡èçåºæ¬ç¹æ§ä»æªå¾å°è§£ç­ãå®ååæ¬è 1) é¢é¨ sEMG ä¿¡èçæ¸æçµæ§ã2) sEMG å¨åäººä¹éçä¿¡èåä½è½ç§»ã3) sEMG ä¿¡èå¨ç¡è²è¨èªæ§é³éç¨ä¸­è·¨è¶æ´åè±èªèªé³ç©ºéçè½åä»¥å 4) åºæ¼éä¾µå¥æ§ sEMG çç¡è²è¨èªä»é¢çæ³åè½åç¸éçåé¡ãæåééä¸ç³»åæ¶åå¥åº·äººé¡åè©¦èçå¯¦é©ä¾è§£æ±ºéäºåé¡ãæåè¡¨æ sEMG ä¿¡èè¡¨ç¾åºåæ¸æçµæ§ï¼ä¸¦ä¸ä¿¡èåä½è½ç§»æ¯ç±åºè®åççµ¦åºçãæ­¤å¤ï¼æåè¡¨æï¼ä½¿ç¨å¯ä»¥ééå°éæ¸æè¨ç·´çå°ç¥ç¶ç¶²è·¯å¯ä»¥è§£ç¢¼è·¨è¶æ´åè±èªèªé³ç©ºéçç¡è²ç¼é³ï¼ä¸¦ä¸éç¨®æ¶æ§å¨ä¸ååé«ä¹éé½è½å¾å¥½å°å·¥ä½ãçºäºç¢ºä¿éæåº¦åå¯è¤è£½æ§ï¼æåå¬éäºæ¬ç ç©¶ä¸­ä½¿ç¨çæææ¸æåä»£ç¢¼ã

##### **GraphXAIN: Narratives to Explain Graph Neural Networks**
2411.02540v2 by Mateusz Cedro, David Martens

Graph Neural Networks (GNNs) are a powerful technique for machine learning on
graph-structured data, yet they pose interpretability challenges, especially
for non-expert users. Existing GNN explanation methods often yield technical
outputs such as subgraphs and feature importance scores, which are not easily
understood. Building on recent insights from social science and other
Explainable AI (XAI) methods, we propose GraphXAIN, a natural language
narrative that explains individual predictions made by GNNs. We present a
model-agnostic and explainer-agnostic XAI approach that complements graph
explainers by generating GraphXAINs, using Large Language Models (LLMs) and
integrating graph data, individual predictions from GNNs, explanatory
subgraphs, and feature importances. We define XAI Narratives and XAI
Descriptions, highlighting their distinctions and emphasizing the importance of
narrative principles in effective explanations. By incorporating natural
language narratives, our approach supports graph practitioners and non-expert
users, aligning with social science research on explainability and enhancing
user understanding and trust in complex GNN models. We demonstrate GraphXAIN's
capabilities on a real-world graph dataset, illustrating how its generated
narratives can aid understanding compared to traditional graph explainer
outputs or other descriptive explanation methods.

æè¦ï¼åå½¢ç¥ç¶ç¶²è·¯ (GNN) æ¯ç¨æ¼åå½¢çµæ§è³æçæ©å¨å­¸ç¿å¼·å¤§æè¡ï¼ä½å®åæé æå¯è§£éæ§ææ°ï¼ç¹å¥æ¯å°æ¼éå°å®¶ä½¿ç¨èãç¾æç GNN è§£éæ¹æ³éå¸¸æç¢çæè¡è¼¸åºï¼ä¾å¦å­ååç¹å¾µéè¦æ§åæ¸ï¼éäºè¼¸åºä¸å®¹æçè§£ãå»ºæ§æ¼ç¤¾æç§å­¸åå¶ä»å¯è§£é AI (XAI) æ¹æ³çææ°è¦è§£ï¼æåæåº GraphXAINï¼éæ¯ä¸ç¨®èªç¶èªè¨æè¿°ï¼å¯ä»¥è§£é GNN ååºçåå¥é æ¸¬ãæåæåºä¸åèæ¨¡åç¡éä¸èè§£éå¨ç¡éç XAI æ¹æ³ï¼å®ééä½¿ç¨å¤§åèªè¨æ¨¡å (LLM) åæ´ååå½¢è³æãGNN çåå¥é æ¸¬ãèªªææ§å­ååç¹å¾µéè¦æ§ä¾è£ååå½¢è§£éå¨ï¼é²èç¢ç GraphXAINãæåå®ç¾© XAI æè¿°å XAI æè¿°ï¼å¼·èª¿å®åçåå¥ï¼ä¸¦å¼·èª¿æè¿°ååå¨ææè§£éä¸­çéè¦æ§ãééçµåèªç¶èªè¨æè¿°ï¼æåçåæ³æ¯æ´åå½¢å¾æ¥­èåéå°å®¶ä½¿ç¨èï¼èå¯è§£éæ§çç¤¾æç§å­¸ç ç©¶ä¿æä¸è´ï¼ä¸¦å¢å¼·ä½¿ç¨èå°è¤é GNN æ¨¡åççè§£åä¿¡ä»»ãæåå¨çå¯¦ä¸çåå½¢è³æéä¸å±ç¤º GraphXAIN çåè½ï¼èªªæèå³çµ±åå½¢è§£éå¨è¼¸åºæå¶ä»æè¿°æ§è§£éæ¹æ³ç¸æ¯ï¼å¶ç¢ççæè¿°å¦ä½æå©æ¼çè§£ã

##### **Improving Scientific Hypothesis Generation with Knowledge Grounded Large Language Models**
2411.02382v1 by Guangzhi Xiong, Eric Xie, Amir Hassan Shariatmadari, Sikun Guo, Stefan Bekiranov, Aidong Zhang

Large language models (LLMs) have demonstrated remarkable capabilities in
various scientific domains, from natural language processing to complex
problem-solving tasks. Their ability to understand and generate human-like text
has opened up new possibilities for advancing scientific research, enabling
tasks such as data analysis, literature review, and even experimental design.
One of the most promising applications of LLMs in this context is hypothesis
generation, where they can identify novel research directions by analyzing
existing knowledge. However, despite their potential, LLMs are prone to
generating ``hallucinations'', outputs that are plausible-sounding but
factually incorrect. Such a problem presents significant challenges in
scientific fields that demand rigorous accuracy and verifiability, potentially
leading to erroneous or misleading conclusions. To overcome these challenges,
we propose KG-CoI (Knowledge Grounded Chain of Ideas), a novel system that
enhances LLM hypothesis generation by integrating external, structured
knowledge from knowledge graphs (KGs). KG-CoI guides LLMs through a structured
reasoning process, organizing their output as a chain of ideas (CoI), and
includes a KG-supported module for the detection of hallucinations. With
experiments on our newly constructed hypothesis generation dataset, we
demonstrate that KG-CoI not only improves the accuracy of LLM-generated
hypotheses but also reduces the hallucination in their reasoning chains,
highlighting its effectiveness in advancing real-world scientific research.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²å¨åç¨®ç§å­¸é åå±ç¾åè¶çè½åï¼å¾èªç¶èªè¨èçå°è¤éçè§£æ±ºåé¡ä»»åãå®åçè§£åç¢çé¡ä¼¼äººé¡æå­çè½åçºæ¨é²ç§å­¸ç ç©¶éåäºæ°çå¯è½æ§ï¼è®è³æåæãæç»åé¡§ï¼çè³å¯¦é©è¨­è¨ç­ä»»åæçºå¯è½ãLLM å¨æ­¤èçµ¡ä¸­ææå¸æçæç¨ä¹ä¸æ¯åè¨­ç¢çï¼å®åè½ééåæç¾æç¥è­ä¾æ¾åºæ°çç ç©¶æ¹åãç¶èï¼åç®¡ LLM å·ææ½åï¼å®åå»å®¹æç¢çãå¹»è¦ºãï¼ä¹å°±æ¯è½èµ·ä¾åçä½äºå¯¦ä¸ä¸æ­£ç¢ºçè¼¸åºãæ­¤é¡åé¡å¨éè¦å´è¬¹æºç¢ºæ§åå¯é©è­æ§çç§å­¸é åä¸­æé æéå¤§ææ°ï¼æå¯è½å°è´é¯èª¤æèª¤å°æ§ççµè«ãçºäºåæéäºææ°ï¼æåæåº KG-CoIï¼ç¥è­åºç¤è§å¿µéï¼ï¼éæ¯ä¸ååµæ°çç³»çµ±ï¼å®ééæ´åç¥è­åè­ (KG) ä¸­çå¤é¨çµæ§åç¥è­ä¾å¢å¼· LLM åè¨­ç¢çãKG-CoI å¼å° LLM é²è¡çµæ§åæ¨çç¨åºï¼å°å¶è¼¸åºæ´çæè§å¿µé (CoI)ï¼ä¸¦åå«ä¸åç± KG æ¯æ´çæ¨¡çµä¾åµæ¸¬å¹»è¦ºãééæåæ°å»ºç«çåè¨­ç¢çè³æéé²è¡çå¯¦é©ï¼æåè­æ KG-CoI ä¸åæ¹åäº LLM ç¢ççåè¨­çæºç¢ºæ§ï¼ä¹æ¸å°äºå¶æ¨çéä¸­çå¹»è¦ºï¼çªé¡¯äºå¶å¨æ¨é²ç¾å¯¦ä¸çç§å­¸ç ç©¶ä¸­çæè½ã

##### **QCG-Rerank: Chunks Graph Rerank with Query Expansion in Retrieval-Augmented LLMs for Tourism Domain**
2411.08724v1 by Qikai Wei, Mingzhi Yang, Chunlong Han, Jingfu Wei, Minghao Zhang, Feifei Shi, Huansheng Ning

Retrieval-Augmented Generation (RAG) mitigates the issue of hallucination in
Large Language Models (LLMs) by integrating information retrieval techniques.
However, in the tourism domain, since the query is usually brief and the
content in the database is diverse, existing RAG may contain a significant
amount of irrelevant or contradictory information contents after retrieval. To
address this challenge, we propose the QCG-Rerank model. This model first
performs an initial retrieval to obtain candidate chunks and then enhances
semantics by extracting critical information to expand the original query.
Next, we utilize the expanded query and candidate chunks to calculate
similarity scores as the initial transition probability and construct the
chunks graph. Subsequently, We iteratively compute the transition probabilities
based on an initial estimate until convergence. The chunks with the highest
score are selected and input into the LLMs to generate responses. We evaluate
the model on Cultour, IIRC, StrategyQA, HotpotQA, SQuAD, and MuSiQue datasets.
The experimental results demonstrate the effectiveness and superiority of the
QCG-Rerank method.

æè¦ï¼æ·åå¢å¼·çæï¼RAGï¼ééæ´åè³è¨æ·åæè¡ä¾ç·©è§£å¤§åèªè¨æ¨¡åï¼LLMï¼ä¸­çå¹»è¦ºåé¡ãç¶èï¼å¨æéé åä¸­ï¼ç±æ¼æ¥è©¢éå¸¸å¾ç°¡ç­ï¼èè³æåº«ä¸­çå§å®¹å¤æ¨£ï¼å æ­¤ç¾æç RAG å¯è½æå¨æ·åå¾åå«å¤§éä¸ç¸éæçç¾çè³è¨å§å®¹ãçºäºæå°éåææ°ï¼æåæåºäº QCG-Rerank æ¨¡åãæ­¤æ¨¡åé¦åå·è¡åå§æ·åä»¥åå¾åé¸åå¡ï¼ç¶å¾ééæ·åééµè³è¨ä¾æ´ååå§æ¥è©¢ä»¥å¢å¼·èªæãæ¥èï¼æåå©ç¨æ´åçæ¥è©¢ååé¸åå¡ä¾è¨ç®ç¸ä¼¼åº¦åæ¸ä½çºåå§è½ç§»æ©çï¼ä¸¦å»ºæ§åå¡åãé¨å¾ï¼æåæ ¹æåå§ä¼°è¨åè¦è¨ç®è½ç§»æ©çï¼ç´å°æ¶æãæé¸ååæ¸æé«çåå¡ï¼ä¸¦è¼¸å¥å° LLM ä»¥ç¢çåæãæåå¨ CultourãIIRCãStrategyQAãHotpotQAãSQuAD å MuSiQue è³æéä¸è©ä¼°æ­¤æ¨¡åãå¯¦é©çµæè­æäº QCG-Rerank æ¹æ³çæææ§ååªè¶æ§ã

##### **Can Language Models Enable In-Context Database?**
2411.01807v1 by Yu Pan, Hongfeng Yu, Tianjiao Zhao, Jianxin Sun

Large language models (LLMs) are emerging as few-shot learners capable of
handling a variety of tasks, including comprehension, planning, reasoning,
question answering, arithmetic calculations, and more. At the core of these
capabilities is LLMs' proficiency in representing and understanding structural
or semi-structural data, such as tables and graphs. Numerous studies have
demonstrated that reasoning on tabular data or graphs is not only feasible for
LLMs but also gives a promising research direction which treats these data as
in-context data. The lightweight and human readable characteristics of
in-context database can potentially make it an alternative for the traditional
database in typical RAG (Retrieval Augmented Generation) settings. However,
almost all current work focuses on static in-context data, which does not allow
dynamic update. In this paper, to enable dynamic database update, delta
encoding of database is proposed. We explore how data stored in traditional
RDBMS can be encoded as in-context text and evaluate LLMs' proficiency for CRUD
(Create, Read, Update and Delete) operations on in-context databases. A
benchmark named InConDB is presented and extensive experiments are conducted to
show the performance of different language models in enabling in-context
database by varying the database encoding method, prompting method, operation
type and input data distribution, revealing both the proficiency and
limitations.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) éæ¼¸æçºåéå°éç¯ä¾å°±è½èçåç¨®ä»»åçå­¸ç¿èï¼åæ¬çè§£ãè¦åãæ¨çãåç­ãç®è¡è¨ç®ç­ãéäºè½åçæ ¸å¿æ¯ LLM å¨è¡¨ç¤ºåçè§£çµæ§åæåçµæ§åè³æï¼ä¾å¦è¡¨æ ¼ååå½¢ï¼æ¹é¢çè½åãè¨±å¤ç ç©¶å·²è­æï¼LLM ä¸åå¯ä»¥æ¨è«è¡¨æ ¼è³ææåå½¢ï¼éæä¾äºä¸åæåæ¯çç ç©¶æ¹åï¼å°éäºè³æè¦çºèªå¢è³æãèªå¢è³æåº«çè¼éç´åäººé¡å¯è®åç¹æ§æå¯è½ä½¿å¶æçºå¸å RAGï¼æª¢ç´¢æ´åçæï¼è¨­å®ä¸­å³çµ±è³æåº«çæ¿ä»£æ¹æ¡ãç¶èï¼å¹¾ä¹ææç®åçå·¥ä½é½å°æ³¨æ¼éæèªå¢è³æï¼éä¸åè¨±åææ´æ°ãå¨æ¬æä¸­ï¼çºäºå¯¦ç¾åæè³æåº«æ´æ°ï¼æåºäºè³æåº«ç delta ç·¨ç¢¼ãæåæ¢è¨äºå¦ä½å°å²å­å¨å³çµ± RDBMS ä¸­çè³æç·¨ç¢¼çºèªå¢æå­ï¼ä¸¦è©ä¼° LLM å¨èªå¢è³æåº«ä¸é²è¡ CRUDï¼å»ºç«ãè®åãæ´æ°ååªé¤ï¼æä½çè½åãæåºäºåçº InConDB çåºæºï¼ä¸¦é²è¡äºå»£æ³çå¯¦é©ï¼ä»¥é¡¯ç¤ºä¸åèªè¨æ¨¡åå¨ééæ¹è®è³æåº«ç·¨ç¢¼æ¹æ³ãæç¤ºæ¹æ³ãæä½é¡ååè¼¸å¥è³æåä½ä¾åç¨èªå¢è³æåº«æ¹é¢çæè½ï¼æ­ç¤ºäºè½ååéå¶ã

##### **Graph-based Confidence Calibration for Large Language Models**
2411.02454v1 by Yukun Li, Sijia Wang, Lifu Huang, Li-Ping Liu

One important approach to improving the reliability of large language models
(LLMs) is to provide accurate confidence estimations regarding the correctness
of their answers. However, developing a well-calibrated confidence estimation
model is challenging, as mistakes made by LLMs can be difficult to detect. We
propose a novel method combining the LLM's self-consistency with labeled data
and training an auxiliary model to estimate the correctness of its responses to
questions. This auxiliary model predicts the correctness of responses based
solely on their consistent information. To set up the learning problem, we use
a weighted graph to represent the consistency among the LLM's multiple
responses to a question. Correctness labels are assigned to these responses
based on their similarity to the correct answer. We then train a graph neural
network to estimate the probability of correct responses. Experiments
demonstrate that the proposed approach substantially outperforms several of the
most recent methods in confidence calibration across multiple widely adopted
benchmark datasets. Furthermore, the proposed approach significantly improves
the generalization capability of confidence calibration on out-of-domain (OOD)
data.

æè¦ï¼ä¸ç¨®æ¹åå¤§åèªè¨æ¨¡å (LLM) å¯é æ§çéè¦æ¹æ³æ¯æä¾æéå¶ç­æ¡æ­£ç¢ºæ§çæºç¢ºä¿¡å¿ä¼°è¨ãç¶èï¼éç¼ä¸åæ ¡æºè¯å¥½çä¿¡å¿ä¼°è¨æ¨¡åå·æææ°æ§ï¼å çº LLM æç¯çé¯èª¤å¯è½é£ä»¥åµæ¸¬ãæåæåºä¸åæ°æ¹æ³ï¼çµå LLM çèªæä¸è´æ§èæ¨ç±¤è³æï¼ä¸¦è¨ç·´ä¸åè¼å©æ¨¡åä¾ä¼°è¨å¶å°åé¡çåææ­£ç¢ºæ§ãéåè¼å©æ¨¡ååæ ¹æå¶ä¸è´æ§è³è¨ä¾é æ¸¬åæçæ­£ç¢ºæ§ãçºäºè¨­å®å­¸ç¿åé¡ï¼æåä½¿ç¨ä¸åå æ¬åå½¢ä¾è¡¨ç¤º LLM å°ä¸ååé¡çå¤æ¬¡åæä¹éçä¸è´æ§ãæ­£ç¢ºæ§æ¨ç±¤ææ ¹æéäºåæèæ­£ç¢ºç­æ¡çç¸ä¼¼æ§åéçµ¦éäºåæãç¶å¾ï¼æåè¨ç·´ä¸ååå½¢ç¥ç¶ç¶²è·¯ä¾ä¼°è¨æ­£ç¢ºåæçæ©çãå¯¦é©è­æï¼ææåºçæ¹æ³å¨å¤åå»£æ³æ¡ç¨çåºæºè³æéä¸ï¼å¨ä¿¡å¿æ ¡æºæ¹é¢æé¡¯åªæ¼å¤ç¨®ææ°æ¹æ³ãæ­¤å¤ï¼ææåºçæ¹æ³é¡¯èæ¹åäºå¨é åå¤ (OOD) è³æä¸ä¿¡å¿æ ¡æºçæ³åè½åã

##### **Ontology Population using LLMs**
2411.01612v1 by Sanaz Saki Norouzi, Adrita Barua, Antrea Christou, Nikita Gautam, Andrew Eells, Pascal Hitzler, Cogan Shimizu

Knowledge graphs (KGs) are increasingly utilized for data integration,
representation, and visualization. While KG population is critical, it is often
costly, especially when data must be extracted from unstructured text in
natural language, which presents challenges, such as ambiguity and complex
interpretations. Large Language Models (LLMs) offer promising capabilities for
such tasks, excelling in natural language understanding and content generation.
However, their tendency to ``hallucinate'' can produce inaccurate outputs.
Despite these limitations, LLMs offer rapid and scalable processing of natural
language data, and with prompt engineering and fine-tuning, they can
approximate human-level performance in extracting and structuring data for KGs.
This study investigates LLM effectiveness for the KG population, focusing on
the Enslaved.org Hub Ontology. In this paper, we report that compared to the
ground truth, LLM's can extract ~90% of triples, when provided a modular
ontology as guidance in the prompts.

æè¦ï¼ç¥è­åè­ (KG) æä¾æå¤ç¨æ¼è³ææ´åãè¡¨ç¤ºåè¦è¦ºåãåç®¡ KG å¡«åè³ééè¦ï¼ä½å®éå¸¸å¾æè²´ï¼ç¹å¥æ¯å¨å¿é å¾èªç¶èªè¨ä¸­éçµæ§åæå­ä¸­æåè³ææï¼éæå¸¶ä¾ææ°ï¼ä¾å¦æ­§ç¾©åè¤éçè©®éãå¤§åèªè¨æ¨¡å (LLM) çºæ­¤é¡ä»»åæä¾äºæåæ¯çè½åï¼æé·èªç¶èªè¨çè§£åå§å®¹çæãç¶èï¼å®åãç¢çå¹»è¦ºãçå¾åå¯è½æç¢çä¸æºç¢ºçè¼¸åºãåç®¡æéäºéå¶ï¼LLM æä¾äºèªç¶èªè¨è³æçå¿«éä¸å¯æ´åèçï¼ä¸¦ä¸ééæç¤ºå·¥ç¨åå¾®èª¿ï¼å®åå¯ä»¥è¿ä¼¼äººé¡å±¤ç´çæè½ï¼ä»¥æååå»ºæ§ KG çè³æãæ¬ç ç©¶èª¿æ¥ LLM å° KG å¡«åçæææ§ï¼éé»éæ³¨ Enslaved.org Hub Ontologyãå¨æ¬æä¸­ï¼æåå ±åèçå¯¦ææ³ç¸æ¯ï¼ç¶å¨æç¤ºä¸­æä¾æ¨¡çµåæ¬ä½ä½çºæå°æï¼LLM å¯ä»¥æåç´ 90% çä¸åçµã

##### **Pre-trained Molecular Language Models with Random Functional Group Masking**
2411.01401v1 by Tianhao Peng, Yuchen Li, Xuhong Li, Jiang Bian, Zeke Xie, Ning Sui, Shahid Mumtaz, Yanwu Xu, Linghe Kong, Haoyi Xiong

Recent advancements in computational chemistry have leveraged the power of
trans-former-based language models, such as MoLFormer, pre-trained using a vast
amount of simplified molecular-input line-entry system (SMILES) sequences, to
understand and predict molecular properties and activities, a critical step in
fields like drug discovery and materials science. To further improve
performance, researchers have introduced graph neural networks with graph-based
molecular representations, such as GEM, incorporating the topology, geometry,
2D or even 3D structures of molecules into pre-training. While most of
molecular graphs in existing studies were automatically converted from SMILES
sequences, it is to assume that transformer-based language models might be able
to implicitly learn structure-aware representations from SMILES sequences. In
this paper, we propose \ours{} -- a SMILES-based \underline{\em M}olecular
\underline{\em L}anguage \underline{\em M}odel, which randomly masking SMILES
subsequences corresponding to specific molecular \underline{\em F}unctional
\underline{\em G}roups to incorporate structure information of atoms during the
pre-training phase. This technique aims to compel the model to better infer
molecular structures and properties, thus enhancing its predictive
capabilities. Extensive experimental evaluations across 11 benchmark
classification and regression tasks in the chemical domain demonstrate the
robustness and superiority of \ours{}. Our findings reveal that \ours{}
outperforms existing pre-training models, either based on SMILES or graphs, in
9 out of the 11 downstream tasks, ranking as a close second in the remaining
ones.

æè¦ï¼<paragraph>è¨ç®åå­¸çè¿æé²å±å·²å©ç¨è½æå¨èªè¨æ¨¡åçåéï¼ä¾å¦ MoLFormerï¼ä½¿ç¨å¤§éç°¡ååå­è¼¸å¥ç·æ¢è¼¸å¥ç³»çµ± (SMILES) åºåé²è¡é è¨ç·´ï¼ä»¥äºè§£åé æ¸¬åå­ç¹æ§åæ´»æ§ï¼éæ¯è¥ç©ç¼ç¾åææç§å­¸ç­é åçéè¦æ­¥é©ãçºäºé²ä¸æ­¥æåæè½ï¼ç ç©¶äººå¡å¼å¥äºå·æåå½¢çºåºç¤çåå­è¡¨ç¤ºçåå½¢ç¥ç¶ç¶²è·¯ï¼ä¾å¦ GEMï¼å°åå­çææ¨¸ãå¹¾ä½ã2D çè³ 3D çµæ§ç´å¥é è¨ç·´ä¸­ãéç¶ç¾æç ç©¶ä¸­çå¤§å¤æ¸åå­åå½¢é½æ¯å¾ SMILES åºåèªåè½æèä¾çï¼ä½å¯ä»¥åè¨­åºæ¼è½æå¨çèªè¨æ¨¡åå¯è½è½å¤ å¾ SMILES åºåä¸­é±å¼å­¸ç¿çµæ§æç¥è¡¨ç¤ºãå¨æ¬æä¸­ï¼æåæåº \ours{} -- ä¸ååºæ¼ SMILES ç\underline{\em M}olecular\underline{\em L}anguage \underline{\em M}odelï¼å®é¨æ©é®è½å°ææ¼ç¹å®åå­\underline{\em F}unctional\underline{\em G}roups ç SMILES å­åºåï¼ä»¥å¨é è¨ç·´éæ®µç´å¥åå­ççµæ§è³è¨ãæ­¤æè¡æ¨å¨å¼·å¶æ¨¡åæ´å¥½å°æ¨æ·åå­çµæ§åç¹æ§ï¼å¾èå¢å¼·å¶é æ¸¬è½åãå¨åå­¸é åç 11 ååºæºåé¡ååæ­¸ä»»åä¸­é²è¡çå»£æ³å¯¦é©è©ä¼°è­æäº \ours{} çç©©å¥æ§ååªè¶æ§ãæåçç ç©¶çµæé¡¯ç¤ºï¼\ours{} å¨ 11 åä¸æ¸¸ä»»åä¸­ç 9 åä»»åä¸­åªæ¼ç¾æçé è¨ç·´æ¨¡åï¼åºæ¼ SMILES æåå½¢ï¼ï¼å¨å©ä¸çä»»åä¸­æåç¬¬äºã</paragraph>


### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-12-06**|**Stag-1: Towards Realistic 4D Driving Simulation with Video Generation Model**|Lening Wang et.al.|[2412.05280v1](http://arxiv.org/abs/2412.05280v1)|[link](https://github.com/wzzheng/stag)|
|**2024-12-06**|**MotionFlow: Attention-Driven Motion Transfer in Video Diffusion Models**|Tuna Han Salih Meral et.al.|[2412.05275v1](http://arxiv.org/abs/2412.05275v1)|null|
|**2024-12-06**|**APOLLO: SGD-like Memory, AdamW-level Performance**|Hanqing Zhu et.al.|[2412.05270v1](http://arxiv.org/abs/2412.05270v1)|null|
|**2024-12-06**|**Chimera: Accurate retrosynthesis prediction by ensembling models with diverse inductive biases**|Krzysztof Maziarz et.al.|[2412.05269v1](http://arxiv.org/abs/2412.05269v1)|null|
|**2024-12-06**|**Reinforcement Learning: An Overview**|Kevin Murphy et.al.|[2412.05265v1](http://arxiv.org/abs/2412.05265v1)|null|
|**2024-12-06**|**Extrapolated Urban View Synthesis Benchmark**|Xiangyu Han et.al.|[2412.05256v1](http://arxiv.org/abs/2412.05256v1)|[link](https://github.com/ai4ce/EUVS-Benchmark)|
|**2024-12-06**|**TeamCraft: A Benchmark for Multi-Modal Multi-Agent Systems in Minecraft**|Qian Long et.al.|[2412.05255v1](http://arxiv.org/abs/2412.05255v1)|[link](https://github.com/teamcraft-bench/teamcraft)|
|**2024-12-06**|**From classical techniques to convolution-based models: A review of object detection algorithms**|Fnu Neha et.al.|[2412.05252v1](http://arxiv.org/abs/2412.05252v1)|null|
|**2024-12-06**|**Uncertainty Quantification for Transformer Models for Dark-Pattern Detection**|Javier MuÃ±oz et.al.|[2412.05251v1](http://arxiv.org/abs/2412.05251v1)|null|
|**2024-12-06**|**Enhancing FKG.in: automating Indian food composition analysis**|Saransh Kumar Gupta et.al.|[2412.05248v1](http://arxiv.org/abs/2412.05248v1)|null|
|**2024-12-06**|**Enhancing Foundation Models for Time Series Forecasting via Wavelet-based Tokenization**|Luca Masserano et.al.|[2412.05244v1](http://arxiv.org/abs/2412.05244v1)|null|
|**2024-12-06**|**CompCap: Improving Multimodal Large Language Models with Composite Captions**|Xiaohui Chen et.al.|[2412.05243v1](http://arxiv.org/abs/2412.05243v1)|null|
|**2024-12-06**|**MAmmoTH-VL: Eliciting Multimodal Reasoning with Instruction Tuning at Scale**|Jarvis Guo et.al.|[2412.05237v1](http://arxiv.org/abs/2412.05237v1)|null|
|**2024-12-06**|**LIAR: Leveraging Alignment (Best-of-N) to Jailbreak LLMs in Seconds**|James Beetham et.al.|[2412.05232v1](http://arxiv.org/abs/2412.05232v1)|null|
|**2024-12-06**|**BEExformer: A Fast Inferencing Transformer Architecture via Binarization with Multiple Early Exits**|Wazib Ansar et.al.|[2412.05225v1](http://arxiv.org/abs/2412.05225v1)|null|
|**2024-12-06**|**100% Hallucination Elimination Using Acurai**|Michael C. Wood et.al.|[2412.05223v1](http://arxiv.org/abs/2412.05223v1)|null|
|**2024-12-06**|**Evaluating and Aligning CodeLLMs on Human Preference**|Jian Yang et.al.|[2412.05210v1](http://arxiv.org/abs/2412.05210v1)|null|
|**2024-12-06**|**A Survey of Large Language Model-Based Generative AI for Text-to-SQL: Benchmarks, Applications, Use Cases, and Challenges**|Aditi Singh et.al.|[2412.05208v1](http://arxiv.org/abs/2412.05208v1)|null|
|**2024-12-06**|**ConQRet: Benchmarking Fine-Grained Evaluation of Retrieval Augmented Argumentation with LLM Judges**|Kaustubh D. Dhole et.al.|[2412.05206v1](http://arxiv.org/abs/2412.05206v1)|[link](https://github.com/emory-irlab/conqret-rag)|
|**2024-12-06**|**Archaeoscape: Bringing Aerial Laser Scanning Archaeology to the Deep Learning Era**|Yohann Perron et.al.|[2412.05203v1](http://arxiv.org/abs/2412.05203v1)|null|
|**2024-12-06**|**Are Frontier Large Language Models Suitable for Q&A in Science Centres?**|Jacob Watson et.al.|[2412.05200v1](http://arxiv.org/abs/2412.05200v1)|null|
|**2024-12-06**|**SurgBox: Agent-Driven Operating Room Sandbox with Surgery Copilot**|Jinlin Wu et.al.|[2412.05187v1](http://arxiv.org/abs/2412.05187v1)|[link](https://github.com/franciszchen/surgbox)|
|**2024-12-06**|**QueEn: A Large Language Model for Quechua-English Translation**|Junhao Chen et.al.|[2412.05184v1](http://arxiv.org/abs/2412.05184v1)|null|
|**2024-12-06**|**Benchmarking Open-ended Audio Dialogue Understanding for Large Audio-Language Models**|Kuofeng Gao et.al.|[2412.05167v1](http://arxiv.org/abs/2412.05167v1)|null|
|**2024-12-06**|**DNF: Unconditional 4D Generation with Dictionary-based Neural Fields**|Xinyi Zhang et.al.|[2412.05161v1](http://arxiv.org/abs/2412.05161v1)|null|
|**2024-12-06**|**Enhancing Cross-Language Code Translation via Task-Specific Embedding Alignment in Retrieval-Augmented Generation**|Manish Bhattarai et.al.|[2412.05159v1](http://arxiv.org/abs/2412.05159v1)|null|
|**2024-12-06**|**Multimodal Fact-Checking with Vision Language Models: A Probing Classifier based Solution with Embedding Strategies**|Recep Firat Cekinel et.al.|[2412.05155v1](http://arxiv.org/abs/2412.05155v1)|null|
|**2024-12-06**|**Navigating Shortcuts, Spurious Correlations, and Confounders: From Origins via Detection to Mitigation**|David Steinmann et.al.|[2412.05152v1](http://arxiv.org/abs/2412.05152v1)|null|
|**2024-12-06**|**Findings of the Second BabyLM Challenge: Sample-Efficient Pretraining on Developmentally Plausible Corpora**|Michael Y. Hu et.al.|[2412.05149v1](http://arxiv.org/abs/2412.05149v1)|null|
|**2024-12-06**|**LoRA.rar: Learning to Merge LoRAs via Hypernetworks for Subject-Style Conditioned Image Generation**|Donald Shenaj et.al.|[2412.05148v1](http://arxiv.org/abs/2412.05148v1)|null|
|**2024-12-06**|**Explingo: Explaining AI Predictions using Large Language Models**|Alexandra Zytek et.al.|[2412.05145v1](http://arxiv.org/abs/2412.05145v1)|null|
|**2024-12-06**|**A Practical Examination of AI-Generated Text Detectors for Large Language Models**|Brian Tufts et.al.|[2412.05139v1](http://arxiv.org/abs/2412.05139v1)|null|
|**2024-12-06**|**Can Large Language Models Serve as Effective Classifiers for Hierarchical Multi-Label Classification of Scientific Documents at Industrial Scale?**|Seyed Amin Tabatabaei et.al.|[2412.05137v1](http://arxiv.org/abs/2412.05137v1)|null|
|**2024-12-06**|**Technology as uncharted territory: Contextual integrity and the notion of AI as new ethical ground**|Alexander Martin Mussgnug et.al.|[2412.05130v1](http://arxiv.org/abs/2412.05130v1)|null|
|**2024-12-06**|**The Prompt Canvas: A Literature-Based Practitioner Guide for Creating Effective Prompts in Large Language Models**|Michael Hewing et.al.|[2412.05127v1](http://arxiv.org/abs/2412.05127v1)|null|
|**2024-12-06**|**A*Net and NBFNet Learn Negative Patterns on Knowledge Graphs**|Patrick Betz et.al.|[2412.05114v1](http://arxiv.org/abs/2412.05114v1)|null|
|**2024-12-06**|**Modeling Task Immersion based on Goal Activation Mechanism**|Kazuma Nagashima et.al.|[2412.05112v1](http://arxiv.org/abs/2412.05112v1)|null|
|**2024-12-06**|**From Defects to Demands: A Unified, Iterative, and Heuristically Guided LLM-Based Framework for Automated Software Repair and Requirement Realization**|Alex et.al.|[2412.05098v1](http://arxiv.org/abs/2412.05098v1)|null|
|**2024-12-06**|**OCEAN: Open-World Contrastive Authorship Identification**|Felix MÃ¤chtle et.al.|[2412.05049v1](http://arxiv.org/abs/2412.05049v1)|[link](https://github.com/uzl-its/ocean)|
|**2024-12-06**|**Improving Post-Earthquake Crack Detection using Semi-Synthetic Generated Images**|Piercarlo Dondi et.al.|[2412.05042v1](http://arxiv.org/abs/2412.05042v1)|null|
|**2024-12-06**|**Talking Like One of Us: Effects of Using Regional Language in a Humanoid Social Robot**|Thomas Sievers et.al.|[2412.05024v1](http://arxiv.org/abs/2412.05024v1)|null|
|**2024-12-06**|**Steps are all you need: Rethinking STEM Education with Prompt Engineering**|Krishnasai Addala et.al.|[2412.05023v1](http://arxiv.org/abs/2412.05023v1)|null|
|**2024-12-06**|**Get It Right: Improving Comprehensibility with Adaptable Speech Expression of a Humanoid Service Robot**|Thomas Sievers et.al.|[2412.05022v1](http://arxiv.org/abs/2412.05022v1)|null|
|**2024-12-06**|**Project Report: Requirements for a Social Robot as an Information Provider in the Public Sector**|Thomas Sievers et.al.|[2412.05013v1](http://arxiv.org/abs/2412.05013v1)|null|
|**2024-12-06**|**ETLNet: An Efficient TCN-BiLSTM Network for Road Anomaly Detection Using Smartphone Sensors**|Mohd Faiz Ansari et.al.|[2412.04990v1](http://arxiv.org/abs/2412.04990v1)|null|
|**2024-12-06**|**Frontier Models are Capable of In-context Scheming**|Alexander Meinke et.al.|[2412.04984v1](http://arxiv.org/abs/2412.04984v1)|null|
|**2024-12-06**|**PETapter: Leveraging PET-style classification heads for modular few-shot parameter-efficient fine-tuning**|Jonas Rieger et.al.|[2412.04975v1](http://arxiv.org/abs/2412.04975v1)|null|
|**2024-12-06**|**Putting the Iterative Training of Decision Trees to the Test on a Real-World Robotic Task**|Raphael C. Engelhardt et.al.|[2412.04974v1](http://arxiv.org/abs/2412.04974v1)|null|
|**2024-12-06**|**Flash Communication: Reducing Tensor Parallelization Bottleneck for Fast Large Language Model Inference**|Qingyuan Li et.al.|[2412.04964v1](http://arxiv.org/abs/2412.04964v1)|null|
|**2024-12-06**|**Gla-AI4BioMed at RRG24: Visual Instruction-tuned Adaptation for Radiology Report Generation**|Xi Zhang et.al.|[2412.04954v1](http://arxiv.org/abs/2412.04954v1)|null|
|**2024-12-06**|**Bed-Attached Vibration Sensor System: A Machine Learning Approach for Fall Detection in Nursing Homes**|Thomas Bartz-Beielstein et.al.|[2412.04950v1](http://arxiv.org/abs/2412.04950v1)|null|
|**2024-12-06**|**KaLM: Knowledge-aligned Autoregressive Language Modeling via Dual-view Knowledge Graph Contrastive Learning**|Peng Yu et.al.|[2412.04948v1](http://arxiv.org/abs/2412.04948v1)|null|
|**2024-12-06**|**C$^2$LEVA: Toward Comprehensive and Contamination-Free Language Model Evaluation**|Yanyang Li et.al.|[2412.04947v1](http://arxiv.org/abs/2412.04947v1)|null|
|**2024-12-06**|**A Federated Approach to Few-Shot Hate Speech Detection for Marginalized Communities**|Haotian Ye et.al.|[2412.04942v1](http://arxiv.org/abs/2412.04942v1)|null|
|**2024-12-06**|**Who Speaks Next? Multi-party AI Discussion Leveraging the Systematics of Turn-taking in Murder Mystery Games**|Ryota Nonomura et.al.|[2412.04937v1](http://arxiv.org/abs/2412.04937v1)|null|
|**2024-12-06**|**Probing the contents of semantic representations from text, behavior, and brain data using the psychNorms metabase**|Zak Hussain et.al.|[2412.04936v1](http://arxiv.org/abs/2412.04936v1)|[link](https://github.com/zak-hussain/psychnorms)|
|**2024-12-06**|**Uncertainty-aware retinal layer segmentation in OCT through probabilistic signed distance functions**|Mohammad Mohaiminul Islam et.al.|[2412.04935v1](http://arxiv.org/abs/2412.04935v1)|[link](https://github.com/niazoys/rls_psdf)|
|**2024-12-06**|**Continuous Video Process: Modeling Videos as Continuous Multi-Dimensional Processes for Video Prediction**|Gaurav Shrivastava et.al.|[2412.04929v1](http://arxiv.org/abs/2412.04929v1)|null|
|**2024-12-06**|**HyperGraphOS: A Meta Operating System for Science and Engineering**|Antonello Ceravola et.al.|[2412.04923v1](http://arxiv.org/abs/2412.04923v1)|null|
|**2024-12-06**|**Large Language Models for Ingredient Substitution in Food Recipes using Supervised Fine-tuning and Direct Preference Optimization**|Thevin Senath et.al.|[2412.04922v1](http://arxiv.org/abs/2412.04922v1)|null|
|**2024-12-06**|**DEMO: Reframing Dialogue Interaction with Fine-grained Element Modeling**|Minzheng Wang et.al.|[2412.04905v1](http://arxiv.org/abs/2412.04905v1)|[link](https://github.com/mozerwang/demo)|
|**2024-12-06**|**EACO: Enhancing Alignment in Multimodal LLMs via Critical Observation**|Yongxin Wang et.al.|[2412.04903v1](http://arxiv.org/abs/2412.04903v1)|null|
|**2024-12-06**|**AI-Driven Non-Invasive Detection and Staging of Steatosis in Fatty Liver Disease Using a Novel Cascade Model and Information Fusion Techniques**|Niloufar Delfan et.al.|[2412.04884v1](http://arxiv.org/abs/2412.04884v1)|null|
|**2024-12-06**|**Building a Family of Data Augmentation Models for Low-cost LLM Fine-tuning on the Cloud**|Yuanhao Yue et.al.|[2412.04871v1](http://arxiv.org/abs/2412.04871v1)|null|
|**2024-12-06**|**NebulaFL: Effective Asynchronous Federated Learning for JointCloud Computing**|Fei Gao et.al.|[2412.04868v1](http://arxiv.org/abs/2412.04868v1)|null|
|**2024-12-06**|**EXAONE 3.5: Series of Large Language Models for Real-world Use Cases**|LG AI Research et.al.|[2412.04862v1](http://arxiv.org/abs/2412.04862v1)|null|
|**2024-12-06**|**Breaking Event Rumor Detection via Stance-Separated Multi-Agent Debate**|Mingqing Zhang et.al.|[2412.04859v1](http://arxiv.org/abs/2412.04859v1)|null|
|**2024-12-06**|**Neuro-Symbolic Data Generation for Math Reasoning**|Zenan Li et.al.|[2412.04857v1](http://arxiv.org/abs/2412.04857v1)|null|
|**2024-12-06**|**MTSpark: Enabling Multi-Task Learning with Spiking Neural Networks for Generalist Agents**|Avaneesh Devkota et.al.|[2412.04847v1](http://arxiv.org/abs/2412.04847v1)|null|
|**2024-12-06**|**eXpath: Explaining Knowledge Graph Link Prediction with Ontological Closed Path Rules**|Ye Sun et.al.|[2412.04846v1](http://arxiv.org/abs/2412.04846v1)|null|
|**2024-12-06**|**Using Machine Learning to Discover Parsimonious and Physically-Interpretable Representations of Catchment-Scale Rainfall-Runoff Dynamics**|Yuan-Heng Wang et.al.|[2412.04845v1](http://arxiv.org/abs/2412.04845v1)|null|
|**2024-12-06**|**Maximizing Alignment with Minimal Feedback: Efficiently Learning Rewards for Visuomotor Robot Policy Alignment**|Ran Tian et.al.|[2412.04835v1](http://arxiv.org/abs/2412.04835v1)|null|
|**2024-12-06**|**WRF-GS: Wireless Radiation Field Reconstruction with 3D Gaussian Splatting**|Chaozheng Wen et.al.|[2412.04832v1](http://arxiv.org/abs/2412.04832v1)|null|
|**2024-12-06**|**Rethinking Time Series Forecasting with LLMs via Nearest Neighbor Contrastive Learning**|Jayanie Bogahawatte et.al.|[2412.04806v1](http://arxiv.org/abs/2412.04806v1)|null|
|**2024-12-06**|**Estimating the treatment effect over time under general interference through deep learner integrated TMLE**|Suhan Guo et.al.|[2412.04799v1](http://arxiv.org/abs/2412.04799v1)|null|
|**2024-12-06**|**Multi-class heart disease Detection, Classification, and Prediction using Machine Learning Models**|Mahfuzul Haque et.al.|[2412.04792v1](http://arxiv.org/abs/2412.04792v1)|null|
|**2024-12-06**|**GUIDE: A Global Unified Inference Engine for Deploying Large Language Models in Heterogeneous Environments**|Yanyu Chen et.al.|[2412.04788v1](http://arxiv.org/abs/2412.04788v1)|null|
|**2024-12-06**|**Direct Quantized Training of Language Models with Stochastic Rounding**|Kaiyan Zhao et.al.|[2412.04787v1](http://arxiv.org/abs/2412.04787v1)|null|
|**2024-12-06**|**NLP-ADBench: NLP Anomaly Detection Benchmark**|Yuangang Li et.al.|[2412.04784v1](http://arxiv.org/abs/2412.04784v1)|[link](https://github.com/usc-fortis/nlp-adbench)|
|**2024-12-06**|**KNN-MMD: Cross Domain Wi-Fi Sensing Based on Local Distribution Alignment**|Zijian Zhao et.al.|[2412.04783v1](http://arxiv.org/abs/2412.04783v1)|null|
|**2024-12-06**|**A Survey of Sustainability in Large Language Models: Applications, Economics, and Challenges**|Aditi Singh et.al.|[2412.04782v1](http://arxiv.org/abs/2412.04782v1)|null|
|**2024-12-06**|**Foundation Models for Low-Resource Language Education (Vision Paper)**|Zhaojun Ding et.al.|[2412.04774v1](http://arxiv.org/abs/2412.04774v1)|null|
|**2024-12-06**|**DAWN-SI: Data-Aware and Noise-Informed Stochastic Interpolation for Solving Inverse Problems**|Shadab Ahamed et.al.|[2412.04766v1](http://arxiv.org/abs/2412.04766v1)|null|
|**2024-12-06**|**Short-term Streamflow and Flood Forecasting based on Graph Convolutional Recurrent Neural Network and Residual Error Learning**|Xiyu Pan et.al.|[2412.04764v1](http://arxiv.org/abs/2412.04764v1)|null|
|**2024-12-06**|**REGENT: A Retrieval-Augmented Generalist Agent That Can Act In-Context in New Environments**|Kaustubh Sridhar et.al.|[2412.04759v1](http://arxiv.org/abs/2412.04759v1)|null|
|**2024-12-06**|**Measuring Goal-Directedness**|Matt MacDermott et.al.|[2412.04758v1](http://arxiv.org/abs/2412.04758v1)|null|
|**2024-12-06**|**Ltri-LLM: Streaming Long Context Inference for LLMs with Training-Free Dynamic Triangular Attention Pattern**|Hongyin Tang et.al.|[2412.04757v1](http://arxiv.org/abs/2412.04757v1)|null|
|**2024-12-06**|**ChatNVD: Advancing Cybersecurity Vulnerability Assessment with Large Language Models**|Shivansh Chopra et.al.|[2412.04756v1](http://arxiv.org/abs/2412.04756v1)|null|
|**2024-12-06**|**Question Answering for Decisionmaking in Green Building Design: A Multimodal Data Reasoning Method Driven by Large Language Models**|Yihui Li et.al.|[2412.04741v1](http://arxiv.org/abs/2412.04741v1)|null|
|**2024-12-06**|**BESSTIE: A Benchmark for Sentiment and Sarcasm Classification for Varieties of English**|Dipankar Srirag et.al.|[2412.04726v1](http://arxiv.org/abs/2412.04726v1)|null|
|**2024-12-06**|**Adaptive Optimization for Enhanced Efficiency in Large-Scale Language Model Training**|Jiajing Chen et.al.|[2412.04718v1](http://arxiv.org/abs/2412.04718v1)|null|
|**2024-12-06**|**NoLoR: An ASR-Based Framework for Expedited Endangered Language Documentation with Neo-Aramaic as a Case Study**|Matthew Nazari et.al.|[2412.04717v1](http://arxiv.org/abs/2412.04717v1)|null|
|**2024-12-06**|**PCTreeS: 3D Point Cloud Tree Species Classification Using Airborne LiDAR Images**|Hongjin Lin et.al.|[2412.04714v1](http://arxiv.org/abs/2412.04714v1)|null|
|**2024-12-06**|**Parametric-ControlNet: Multimodal Control in Foundation Models for Precise Engineering Design Synthesis**|Rui Zhou et.al.|[2412.04707v1](http://arxiv.org/abs/2412.04707v1)|null|
|**2024-12-06**|**On Interpreting the Effectiveness of Unsupervised Software Traceability with Information Theory**|David N. Palacio et.al.|[2412.04704v1](http://arxiv.org/abs/2412.04704v1)|null|
|**2024-12-06**|**Transformers Struggle to Learn to Search**|Abulhair Saparov et.al.|[2412.04703v1](http://arxiv.org/abs/2412.04703v1)|null|
|**2024-12-06**|**Privacy-Preserving Retrieval Augmented Generation with Differential Privacy**|Tatsuki Koga et.al.|[2412.04697v1](http://arxiv.org/abs/2412.04697v1)|null|
|**2024-12-06**|**Smoothie: Label Free Language Model Routing**|Neel Guha et.al.|[2412.04692v1](http://arxiv.org/abs/2412.04692v1)|null|
|**2024-12-06**|**LLM-Align: Utilizing Large Language Models for Entity Alignment in Knowledge Graphs**|Xuan Chen et.al.|[2412.04690v1](http://arxiv.org/abs/2412.04690v1)|null|
|**2024-12-06**|**Two stages domain invariant representation learners solve the large co-variate shift in unsupervised domain adaptation with two dimensional data domains**|Hisashi Oshima et.al.|[2412.04682v1](http://arxiv.org/abs/2412.04682v1)|[link](https://github.com/oh-yu/domain-invariant-learning)|

#### Abstracts
##### **Stag-1: Towards Realistic 4D Driving Simulation with Video Generation Model**
2412.05280v1 by Lening Wang, Wenzhao Zheng, Dalong Du, Yunpeng Zhang, Yilong Ren, Han Jiang, Zhiyong Cui, Haiyang Yu, Jie Zhou, Jiwen Lu, Shanghang Zhang

4D driving simulation is essential for developing realistic autonomous
driving simulators. Despite advancements in existing methods for generating
driving scenes, significant challenges remain in view transformation and
spatial-temporal dynamic modeling. To address these limitations, we propose a
Spatial-Temporal simulAtion for drivinG (Stag-1) model to reconstruct
real-world scenes and design a controllable generative network to achieve 4D
simulation. Stag-1 constructs continuous 4D point cloud scenes using
surround-view data from autonomous vehicles. It decouples spatial-temporal
relationships and produces coherent keyframe videos. Additionally, Stag-1
leverages video generation models to obtain photo-realistic and controllable 4D
driving simulation videos from any perspective. To expand the range of view
generation, we train vehicle motion videos based on decomposed camera poses,
enhancing modeling capabilities for distant scenes. Furthermore, we reconstruct
vehicle camera trajectories to integrate 3D points across consecutive views,
enabling comprehensive scene understanding along the temporal dimension.
Following extensive multi-level scene training, Stag-1 can simulate from any
desired viewpoint and achieve a deep understanding of scene evolution under
static spatial-temporal conditions. Compared to existing methods, our approach
shows promising performance in multi-view scene consistency, background
coherence, and accuracy, and contributes to the ongoing advancements in
realistic autonomous driving simulation. Code: https://github.com/wzzheng/Stag.

æè¦ï¼4D é§é§æ¨¡æ¬å°æ¼éç¼é¼ççèªåé§é§æ¨¡æ¬å¨è³ééè¦ãåç®¡ç¾ææ¹æ³å¨ç¢çé§é§å ´æ¯æ¹é¢åå¾é²å±ï¼ä½å¨è¦åè½æåæç©ºåæå»ºæ¨¡æ¹é¢ä»é¢è¨éå¤§ææ°ãçºäºè§£æ±ºéäºéå¶ï¼æåæåºäºä¸ç¨®ç¨æ¼é§é§çæç©ºæ¨¡æ¬ (Stag-1) æ¨¡åï¼ä»¥éå»ºçå¯¦ä¸ççå ´æ¯ä¸¦è¨­è¨ä¸åå¯æ§ççæç¶²è·¯ä»¥å¯¦ç¾ 4D æ¨¡æ¬ãStag-1 ä½¿ç¨ä¾èªèªåé§é§æ±½è»çç°æ¯è³æï¼æ§å»ºé£çºç 4D é»é²å ´æ¯ãå®è§£è¦æç©ºéä¿ä¸¦ç¢çé£è²«çééµå½±æ ¼å½±çãæ­¤å¤ï¼Stag-1 å©ç¨å½±ççææ¨¡åå¾ä»»ä½è§åº¦ç²åé¼ççå¯æ§ 4D é§é§æ¨¡æ¬å½±çãçºäºæ´å±è¦åçæç¯åï¼æåæ ¹æåè§£çç¸æ©å§¿å¢è¨ç·´è»è¼éåå½±çï¼å¢å¼·é æ¯å»ºæ¨¡è½åãæ­¤å¤ï¼æåéå»ºè»è¼ç¸æ©è»è·¡ä»¥æ´åé£çºè¦åä¸­ç 3D é»ï¼å¯¦ç¾æ²¿æéç¶­åº¦çå¨é¢å ´æ¯çè§£ãç¶éå»£æ³çå¤ç´å ´æ¯è¨ç·´å¾ï¼Stag-1 å¯ä»¥å¾ä»»ä½æéçè¦é»é²è¡æ¨¡æ¬ï¼ä¸¦å¨éææç©ºæ¢ä»¶ä¸å°å ´æ¯æ¼åææ·±å¥çäºè§£ãèç¾ææ¹æ³ç¸æ¯ï¼æåçæ¹æ³å¨å¤è¦åå ´æ¯ä¸è´æ§ãèæ¯é£è²«æ§åæºç¢ºæ§æ¹é¢è¡¨ç¾åºè¯å¥½çæè½ï¼ä¸¦æå©æ¼é¼çèªåé§é§æ¨¡æ¬çæçºé²æ­¥ãç¨å¼ç¢¼ï¼https://github.com/wzzheng/Stagã

##### **MotionFlow: Attention-Driven Motion Transfer in Video Diffusion Models**
2412.05275v1 by Tuna Han Salih Meral, Hidir Yesiltepe, Connor Dunlop, Pinar Yanardag

Text-to-video models have demonstrated impressive capabilities in producing
diverse and captivating video content, showcasing a notable advancement in
generative AI. However, these models generally lack fine-grained control over
motion patterns, limiting their practical applicability. We introduce
MotionFlow, a novel framework designed for motion transfer in video diffusion
models. Our method utilizes cross-attention maps to accurately capture and
manipulate spatial and temporal dynamics, enabling seamless motion transfers
across various contexts. Our approach does not require training and works on
test-time by leveraging the inherent capabilities of pre-trained video
diffusion models. In contrast to traditional approaches, which struggle with
comprehensive scene changes while maintaining consistent motion, MotionFlow
successfully handles such complex transformations through its attention-based
mechanism. Our qualitative and quantitative experiments demonstrate that
MotionFlow significantly outperforms existing models in both fidelity and
versatility even during drastic scene alterations.

æè¦ï¼ææ¬å°å½±çæ¨¡åå·²å±ç¤ºåºä»¤äººå°è±¡æ·±å»çè½åï¼è½ç¢çå¤åä¸å¼äººå¥åçå½±çå§å®¹ï¼å±ç¾çæå¼ AI çé¡¯èé²å±ãç¶èï¼éäºæ¨¡åéå¸¸ç¼ºä¹å°åä½æ¨¡å¼çç´°ç·»æ§å¶ï¼éå¶äºå¶å¯¦ç¨æ§ãæåå¼å¥äº MotionFlowï¼ä¸åå°çºå½±çæ´æ£æ¨¡åä¸­çåä½è½ç§»èè¨­è¨çæ°ç©æ¶æ§ãæåçæ¨¡åå©ç¨äº¤åæ³¨æååä¾ç²¾ç¢ºææåæ§å¶æç©ºåæï¼è®åä½è½å¨åç¨®æå¢ä¸­ç¡ç¸«è½ç§»ãæåçæ¨¡åä¸éè¦è¨ç·´ï¼ä¸¦å¨æ¸¬è©¦æééå©ç¨é åè¨ç·´çå½±çæ´æ£æ¨¡åçå§å¨è½åä¾éä½ãèå³çµ±æ¹æ³ä¸åï¼å³çµ±æ¹æ³å¨ç¶­æä¸è´åä½çåæé£ä»¥èçå¨é¢çå ´æ¯è®åï¼MotionFlow ééå¶åºæ¼æ³¨æåçæ©å¶æåå°èçäºéäºè¤éçè½æãæåçå®æ§åå®éå¯¦é©è­æï¼å³ä½¿å¨åççå ´æ¯è®åä¸­ï¼MotionFlow å¨ä¿çåº¦åå¤åè½æ§æ¹é¢é½æé¡¯åªæ¼ç¾ææ¨¡åã

##### **APOLLO: SGD-like Memory, AdamW-level Performance**
2412.05270v1 by Hanqing Zhu, Zhenyu Zhang, Wenyan Cong, Xi Liu, Sem Park, Vikas Chandra, Bo Long, David Z. Pan, Zhangyang Wang, Jinwon Lee

Large language models (LLMs) are notoriously memory-intensive during
training, particularly with the popular AdamW optimizer. This memory burden
necessitates using more or higher-end GPUs or reducing batch sizes, limiting
training scalability and throughput. To address this, various memory-efficient
optimizers have been proposed to reduce optimizer memory usage. However, they
face critical challenges: (i) reliance on costly SVD operations; (ii)
significant performance trade-offs compared to AdamW; and (iii) still
substantial optimizer memory overhead to maintain competitive performance.
  In this work, we identify that AdamW's learning rate adaptation rule can be
effectively coarsened as a structured learning rate update. Based on this
insight, we propose Approximated Gradient Scaling for Memory-Efficient LLM
Optimization (APOLLO), which approximates learning rate scaling using an
auxiliary low-rank optimizer state based on pure random projection. This
structured learning rate update rule makes APOLLO highly tolerant to further
memory reductions while delivering comparable pre-training performance. Even
its rank-1 variant, APOLLO-Mini, achieves superior pre-training performance
compared to AdamW with SGD-level memory costs.
  Extensive experiments demonstrate that the APOLLO series performs on-par with
or better than AdamW, while achieving greater memory savings by nearly
eliminating the optimization states of AdamW. These savings provide significant
system-level benefits: (1) Enhanced Throughput: 3x throughput on an 8xA100-80GB
setup compared to AdamW by supporting 4x larger batch sizes. (2) Improved Model
Scalability: Pre-training LLaMA-13B with naive DDP on A100-80GB GPUs without
system-level optimizations. (3) Low-End GPU Friendly Pre-training: Pre-training
LLaMA-7B on a single GPU using less than 12 GB of memory with weight
quantization.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨è¨ç·´æéä»¥æ¶èå¤§éè¨æ¶é«èæ¡åæ­å½°ï¼ç¹å¥æ¯ä½¿ç¨å»£åæ­¡è¿ç AdamW æä½³åå¨æãéç¨®è¨æ¶é«è² æéè¦ä½¿ç¨æ´å¤ææ´é«éç GPU ææ¸å°æ¹æ¬¡å¤§å°ï¼éå¶è¨ç·´å¯æ´åæ§åååéãçºäºè§£æ±ºéååé¡ï¼å·²ç¶æåºåç¨®çè¨æ¶é«çæä½³åå¨ä¾æ¸å°æä½³åå¨è¨æ¶é«ä½¿ç¨éãç¶èï¼å®åé¢è¨å´å³»çææ°ï¼(i) ä¾è³´æè²´ç SVD éç®ï¼(ii) è AdamW ç¸æ¯æé¡¯èçæè½åæ¨ï¼(iii) ä»ç¶éè¦å¤§éçæä½³åå¨è¨æ¶é«éé·ä¾ç¶­æç«¶ç­åãå¨æ¬æä¸­ï¼æåç¼ç¾ AdamW çå­¸ç¿çé©æè¦åå¯ä»¥ææå°ç²ç¥åçºçµæ§åçå­¸ç¿çæ´æ°ãæ ¹æéåè¦è§£ï¼æåæåºäºè¨æ¶é«é«æ LLM æä½³åè¿ä¼¼æ¢¯åº¦ç¸®æ¾ (APOLLO)ï¼å®ä½¿ç¨åºæ¼ç´é¨æ©æå½±çè¼å©ä½ç§©æä½³åå¨çæä¾è¿ä¼¼å­¸ç¿çç¸®æ¾ãéç¨®çµæ§åçå­¸ç¿çæ´æ°è¦åè® APOLLO éå¸¸èåé²ä¸æ­¥çè¨æ¶é«æ¸å°ï¼åææä¾å¯æ¯è¼çé è¨ç·´æè½ãå³ä½¿æ¯å®çç§© 1 è®é« APOLLO-Miniï¼è SGD ç­ç´çè¨æ¶é«ææ¬ç¸æ¯ï¼ä¹éå°äºåªç°çé è¨ç·´æè½ãå»£æ³çå¯¦é©è¡¨æï¼APOLLO ç³»åçæè½è AdamW ç¸ç¶æåªæ¼ AdamWï¼åæééå¹¾ä¹æ¶é¤ AdamW çæä½³åçæä¾ç¯çæ´å¤è¨æ¶é«ãéäºç¯çæä¾äºé¡¯èçç³»çµ±å±¤ç´åªé»ï¼(1) å¢å¼·çååéï¼è AdamW ç¸æ¯ï¼å¨ 8xA100-80GB è¨­å®ä¸æé«äº 3 åçååéï¼æ¯æ´ 4 åæ´å¤§çæ¹æ¬¡å¤§å°ã(2) æ¹åæ¨¡åå¯æ´åæ§ï¼å¨æ²æç³»çµ±å±¤ç´æä½³åçææ³ä¸ï¼ä½¿ç¨ A100-80GB GPU é è¨ç·´ LLaMA-13B ææ¡ç¨å®ç´ç DDPã(3) ä½é GPU ååçé è¨ç·´ï¼ä½¿ç¨ä½æ¼ 12 GB çè¨æ¶é«åæ¬ééåå¨å®ä¸ GPU ä¸é è¨ç·´ LLaMA-7Bã

##### **Chimera: Accurate retrosynthesis prediction by ensembling models with diverse inductive biases**
2412.05269v1 by Krzysztof Maziarz, Guoqing Liu, Hubert Misztela, Aleksei Kornev, Piotr GaiÅski, Holger Hoefling, Mike Fortunato, Rishi Gupta, Marwin Segler

Planning and conducting chemical syntheses remains a major bottleneck in the
discovery of functional small molecules, and prevents fully leveraging
generative AI for molecular inverse design. While early work has shown that
ML-based retrosynthesis models can predict reasonable routes, their low
accuracy for less frequent, yet important reactions has been pointed out. As
multi-step search algorithms are limited to reactions suggested by the
underlying model, the applicability of those tools is inherently constrained by
the accuracy of retrosynthesis prediction. Inspired by how chemists use
different strategies to ideate reactions, we propose Chimera: a framework for
building highly accurate reaction models that combine predictions from diverse
sources with complementary inductive biases using a learning-based ensembling
strategy. We instantiate the framework with two newly developed models, which
already by themselves achieve state of the art in their categories. Through
experiments across several orders of magnitude in data scale and time-splits,
we show Chimera outperforms all major models by a large margin, owing both to
the good individual performance of its constituents, but also to the
scalability of our ensembling strategy. Moreover, we find that PhD-level
organic chemists prefer predictions from Chimera over baselines in terms of
quality. Finally, we transfer the largest-scale checkpoint to an internal
dataset from a major pharmaceutical company, showing robust generalization
under distribution shift. With the new dimension that our framework unlocks, we
anticipate further acceleration in the development of even more accurate
models.

æè¦ï¼è¦ååå·è¡åå­¸åæä»ç¶æ¯ç¼ç¾åè½æ§å°åå­æçä¸»è¦ç¶é ¸ï¼èä¸ç¡æ³ååå©ç¨çæå¼ AI é²è¡åå­éåè¨­è¨ãåç®¡æ©æç ç©¶é¡¯ç¤ºï¼åºæ¼ ML çéåææ¨¡åå¯ä»¥é æ¸¬åççè·¯ç·ï¼ä½å·²æåºå¶å°è¼ä¸å¸¸è¦ä½éè¦çåæçä½æºç¢ºåº¦ãç±æ¼å¤æ­¥é©æå°æ¼ç®æ³åéæ¼åºå±¤æ¨¡åå»ºè­°çåæï¼å æ­¤éäºå·¥å·çé©ç¨æ§æ¬è³ªä¸åå°éåæé æ¸¬æºç¢ºåº¦çéå¶ãåå°åå­¸å®¶ä½¿ç¨ä¸åç­ç¥æ§æåæçåç¼ï¼æåæåº Chimeraï¼ä¸åçµåä¾èªä¸åä¾æºçé æ¸¬ï¼ä¸¦ä½¿ç¨åºæ¼å­¸ç¿çéæç­ç¥ï¼å·æäºè£æ­¸ç´åå·®çé«æºç¢ºåº¦åææ¨¡åå»ºæ§æ¶æ§ãæåä½¿ç¨å©åæ°éç¼çæ¨¡åå¯¦ä¾åè©²æ¶æ§ï¼å®åæ¬èº«å·²å¨åèªçé¡å¥ä¸­éå°ææ°æè¡ãééè·¨è¶æ¸åæ¸éç´çè³æè¦æ¨¡åæéåå²çå¯¦é©ï¼æåå±ç¤º Chimera å¨å¾å¤§ç¨åº¦ä¸åªæ¼ææä¸»è¦æ¨¡åï¼éæ­¸åæ¼å¶çµæé¨åçè¯å¥½åå¥æè½ï¼ä½ä¹æ­¸åæ¼æåéæç­ç¥çå¯æ´åæ§ãæ­¤å¤ï¼æåç¼ç¾åå£«ç´çææ©åå­¸å®¶å¨åè³ªæ¹é¢åå¥½ Chimera çé æ¸¬ï¼èéåºç·ãæå¾ï¼æåå°æå¤§è¦æ¨¡çæª¢æ¥é»è½ç§»å°ä¸å®¶ä¸»è¦è£½è¥å¬å¸çå§é¨è³æéï¼é¡¯ç¤ºå¨åä½è½ç§»ä¸å·æç©©å¥çæ¦æ¬æ§ãééæåçæ¶æ§è§£éçæ°é¢åï¼æåé æå¨éç¼æ´æºç¢ºçæ¨¡åæ¹é¢å°é²ä¸æ­¥å éã

##### **Reinforcement Learning: An Overview**
2412.05265v1 by Kevin Murphy

This manuscript gives a big-picture, up-to-date overview of the field of
(deep) reinforcement learning and sequential decision making, covering
value-based RL, policy-gradient methods, model-based methods, and various other
topics (including a very brief discussion of RL+LLMs).

æè¦ï¼éä»½æç¨¿æä¾äºéæ¼ï¼æ·±åº¦ï¼å¼·åå­¸ç¿åé åºæ±ºç­å¶å®é åçå¨é¢ä¸ææ°çæ¦è§ï¼æ¶µèåºæ¼å¹å¼ç RLãç­ç¥æ¢¯åº¦æ¹æ³ãåºæ¼æ¨¡åçæ¹æ³ä»¥åå¶ä»åç¨®ä¸»é¡ï¼åæ¬å° RL+LLM çéå¸¸ç°¡ç­çè¨è«ï¼ã

##### **Extrapolated Urban View Synthesis Benchmark**
2412.05256v1 by Xiangyu Han, Zhen Jia, Boyi Li, Yan Wang, Boris Ivanovic, Yurong You, Lingjie Liu, Yue Wang, Marco Pavone, Chen Feng, Yiming Li

Photorealistic simulators are essential for the training and evaluation of
vision-centric autonomous vehicles (AVs). At their core is Novel View Synthesis
(NVS), a crucial capability that generates diverse unseen viewpoints to
accommodate the broad and continuous pose distribution of AVs. Recent advances
in radiance fields, such as 3D Gaussian Splatting, achieve photorealistic
rendering at real-time speeds and have been widely used in modeling large-scale
driving scenes. However, their performance is commonly evaluated using an
interpolated setup with highly correlated training and test views. In contrast,
extrapolation, where test views largely deviate from training views, remains
underexplored, limiting progress in generalizable simulation technology. To
address this gap, we leverage publicly available AV datasets with multiple
traversals, multiple vehicles, and multiple cameras to build the first
Extrapolated Urban View Synthesis (EUVS) benchmark. Meanwhile, we conduct
quantitative and qualitative evaluations of state-of-the-art Gaussian Splatting
methods across different difficulty levels. Our results show that Gaussian
Splatting is prone to overfitting to training views. Besides, incorporating
diffusion priors and improving geometry cannot fundamentally improve NVS under
large view changes, highlighting the need for more robust approaches and
large-scale training. We have released our data to help advance self-driving
and urban robotics simulation technology.

æè¦ï¼é¼ççæ¨¡æ¬å¨å°æ¼ä»¥è¦è¦ºçºä¸­å¿çèªåé§é§è»è¼ (AV) çè¨ç·´åè©ä¼°è³ééè¦ãå¶æ ¸å¿æ¯æ°è¦è§åæ (NVS)ï¼éæ¯ä¸é ééµåè½ï¼å¯ç¢çå¤æ¨£åçæªè¦è¦è§ï¼ä»¥é©æèªåé§é§è»è¼å»£æ³ä¸é£çºçå§¿æåä½ãæè¿å¨è¼»å°å ´çé²å±ï¼ä¾å¦ 3D é«æ¯æ½æ¿ºï¼å¯¦ç¾äºå¯¦æéåº¦çåå¯«å¯¦æ¸²æï¼ä¸¦å·²å»£æ³ç¨æ¼å»ºæ¨¡å¤§è¦æ¨¡é§é§å ´æ¯ãç¶èï¼å®åçæ§è½éå¸¸ä½¿ç¨å§æè¨­ç½®é²è¡è©ä¼°ï¼å¶ä¸­è¨ç·´åæ¸¬è©¦è¦è§é«åº¦ç¸éãç¸æ¯ä¹ä¸ï¼å¤æ¨ï¼æ¸¬è©¦è¦è§èè¨ç·´è¦è§æå¾å¤§åå·®ï¼ä»ç¶æªå¾å°ååæ¢ç´¢ï¼ééå¶äºå¯æ¦æ¬æ¨¡æ¬æè¡çé²æ­¥ãçºäºè§£æ±ºéåå·®è·ï¼æåå©ç¨å·æå¤éç©¿è¶ãå¤éè»è¼åå¤éç¸æ©çå¬éèªåé§é§è»è¼æ¸æéä¾æ§å»ºç¬¬ä¸åå¤æ¨åå¸è¦è§åæ (EUVS) åºæºãåæï¼æåå°æåé²çé«æ¯æ½æ¿ºæ¹æ³å¨ä¸åé£åº¦ç´å¥ä¸é²è¡äºå®éåå®æ§è©ä¼°ãæåççµæè¡¨æï¼é«æ¯æ½æ¿ºå®¹æéåº¦æ¬åè¨ç·´è¦è§ãæ­¤å¤ï¼çµåæ´æ£åé©åæ¹é²å¹¾ä½å½¢çç¡æ³å¾æ ¹æ¬ä¸æ¹åå¤§è¦è§è®åä¸ç NVSï¼éçªé¡¯äºå°æ´å¼·å¤§çæ¹æ³åå¤§è¦æ¨¡è¨ç·´çéæ±ãæåå·²ç¶ç¼å¸äºæåçæ¸æï¼ä»¥å¹«å©æ¨é²èªåé§é§ååå¸æ©å¨äººæ¨¡æ¬æè¡ã

##### **TeamCraft: A Benchmark for Multi-Modal Multi-Agent Systems in Minecraft**
2412.05255v1 by Qian Long, Zhi Li, Ran Gong, Ying Nian Wu, Demetri Terzopoulos, Xiaofeng Gao

Collaboration is a cornerstone of society. In the real world, human teammates
make use of multi-sensory data to tackle challenging tasks in ever-changing
environments. It is essential for embodied agents collaborating in
visually-rich environments replete with dynamic interactions to understand
multi-modal observations and task specifications. To evaluate the performance
of generalizable multi-modal collaborative agents, we present TeamCraft, a
multi-modal multi-agent benchmark built on top of the open-world video game
Minecraft. The benchmark features 55,000 task variants specified by multi-modal
prompts, procedurally-generated expert demonstrations for imitation learning,
and carefully designed protocols to evaluate model generalization capabilities.
We also perform extensive analyses to better understand the limitations and
strengths of existing approaches. Our results indicate that existing models
continue to face significant challenges in generalizing to novel goals, scenes,
and unseen numbers of agents. These findings underscore the need for further
research in this area. The TeamCraft platform and dataset are publicly
available at https://github.com/teamcraft-bench/teamcraft.

æè¦ï¼åä½æ¯ç¤¾æçåºç³ãå¨ç¾å¯¦ä¸çä¸­ï¼äººé¡éåå©ç¨å¤æå®æ¸æä¾æå°ä¸æ·è®åçç°å¢ä¸­çå·æææ°æ§çä»»åãå°æ¼å¨åæ»¿åæäº¤äºä½ç¨çè¦è¦ºè±å¯ç°å¢ä¸­åä½çå·é«ä»£çèè¨ï¼çè§£å¤æ¨¡å¼è§å¯åä»»åè¦ç¯è³ééè¦ãçºäºè©ä¼°å¯æ¦æ¬å¤æ¨¡å¼åä½ä»£ççæ§è½ï¼æåæåºäº TeamCraftï¼éæ¯ä¸åå»ºç«å¨éæ¾ä¸çè¦é »éæ² Minecraft ä¹ä¸çå¤æ¨¡å¼å¤ä»£çåºæºãè©²åºæºæ¸¬è©¦å·æ 55,000 åç±å¤æ¨¡å¼æç¤ºæå®çä»»åè®é«ãç¨æ¼æ¨¡ä»¿å­¸ç¿çç¨åºçæå°å®¶æ¼ç¤ºï¼ä»¥åç²¾å¿è¨­è¨çåè­°ä¾è©ä¼°æ¨¡åæ³åè½åãæåéé²è¡äºå»£æ³çåæï¼ä»¥æ´å¥½å°äºè§£ç¾ææ¹æ³çå±éæ§ååªå¢ãæåççµæè¡¨æï¼ç¾ææ¨¡åå¨æ¦æ¬å°æ°çç®æ¨ãå ´æ¯åæªè¦çä»£çæ¸éæ¹é¢ä»ç¶é¢è¨éå¤§ææ°ãéäºç¼ç¾å¼·èª¿äºé²ä¸æ­¥ç ç©¶éä¸é åçå¿è¦æ§ãTeamCraft å¹³å°åæ¸æéå¯å¨ https://github.com/teamcraft-bench/teamcraft å¬éç²å¾ã

##### **From classical techniques to convolution-based models: A review of object detection algorithms**
2412.05252v1 by Fnu Neha, Deepshikha Bhati, Deepak Kumar Shukla, Md Amiruzzaman

Object detection is a fundamental task in computer vision and image
understanding, with the goal of identifying and localizing objects of interest
within an image while assigning them corresponding class labels. Traditional
methods, which relied on handcrafted features and shallow models, struggled
with complex visual data and showed limited performance. These methods combined
low-level features with contextual information and lacked the ability to
capture high-level semantics. Deep learning, especially Convolutional Neural
Networks (CNNs), addressed these limitations by automatically learning rich,
hierarchical features directly from data. These features include both semantic
and high-level representations essential for accurate object detection. This
paper reviews object detection frameworks, starting with classical computer
vision methods. We categorize object detection approaches into two groups: (1)
classical computer vision techniques and (2) CNN-based detectors. We compare
major CNN models, discussing their strengths and limitations. In conclusion,
this review highlights the significant advancements in object detection through
deep learning and identifies key areas for further research to improve
performance.

æè¦ï¼ç©ä»¶åµæ¸¬æ¯é»è¦è¦è¦ºåå½±åçè§£ä¸­çä¸é åºæ¬ä»»åï¼ç®æ¨æ¯è¾¨è­åå®ä½å½±åä¸­çæèè¶£ç©ä»¶ï¼åæçºå¶æå®å°æçé¡å¥æ¨ç±¤ãå³çµ±æ¹æ³ä¾è³´æ¼æå·¥ç¹å¾µåæ·ºå±¤æ¨¡åï¼å¨èçè¤éçè¦è¦ºè³æææéå°å°é£ï¼æè½ä¹æéãéäºæ¹æ³å°ä½éç¹å¾µèèçµ¡è³è¨çµåï¼ä½ç¼ºä¹æ·åé«éèªæçè½åãæ·±åº¦å­¸ç¿ï¼ç¹å¥æ¯å·ç©ç¥ç¶ç¶²è·¯ (CNN)ï¼ééç´æ¥å¾è³æä¸­èªåå­¸ç¿è±å¯çåå±¤ç¹å¾µä¾è§£æ±ºéäºéå¶ãéäºç¹å¾µåå«èªæåé«éè¡¨ç¤ºï¼å°æ¼æºç¢ºçç©ä»¶åµæ¸¬è³ééè¦ãæ¬æåé¡§äºç©ä»¶åµæ¸¬æ¶æ§ï¼å¾ç¶å¸çé»è¦è¦è¦ºæ¹æ³éå§ãæåå°ç©ä»¶åµæ¸¬æ¹æ³åé¡çºå©çµï¼(1) ç¶å¸é»è¦è¦è¦ºæè¡å (2) åºæ¼ CNN çåµæ¸¬å¨ãæåæ¯è¼äºä¸»è¦ç CNN æ¨¡åï¼ä¸¦è¨è«å¶åªé»åéå¶ãæå¾ï¼æ¬åé¡§å¼·èª¿äºæ·±åº¦å­¸ç¿å¨ç©ä»¶åµæ¸¬æ¹é¢åå¾çéå¤§é²å±ï¼ä¸¦æ¾åºé²ä¸æ­¥ç ç©¶ä»¥æåæè½çä¸»è¦é åã

##### **Uncertainty Quantification for Transformer Models for Dark-Pattern Detection**
2412.05251v1 by Javier MuÃ±oz, Ãlvaro Huertas-GarcÃ­a, Carlos MartÃ­-GonzÃ¡lez, Enrique De Miguel Ambite

The opaque nature of transformer-based models, particularly in applications
susceptible to unethical practices such as dark-patterns in user interfaces,
requires models that integrate uncertainty quantification to enhance trust in
predictions. This study focuses on dark-pattern detection, deceptive design
choices that manipulate user decisions, undermining autonomy and consent. We
propose a differential fine-tuning approach implemented at the final
classification head via uncertainty quantification with transformer-based
pre-trained models. Employing a dense neural network (DNN) head architecture as
a baseline, we examine two methods capable of quantifying uncertainty:
Spectral-normalized Neural Gaussian Processes (SNGPs) and Bayesian Neural
Networks (BNNs). These methods are evaluated on a set of open-source
foundational models across multiple dimensions: model performance, variance in
certainty of predictions and environmental impact during training and inference
phases. Results demonstrate that integrating uncertainty quantification
maintains performance while providing insights into challenging instances
within the models. Moreover, the study reveals that the environmental impact
does not uniformly increase with the incorporation of uncertainty
quantification techniques. The study's findings demonstrate that uncertainty
quantification enhances transparency and provides measurable confidence in
predictions, improving the explainability and clarity of black-box models. This
facilitates informed decision-making and mitigates the influence of
dark-patterns on user interfaces. These results highlight the importance of
incorporating uncertainty quantification techniques in developing machine
learning models, particularly in domains where interpretability and
trustworthiness are critical.

æè¦ï¼<paragraph>åºæ¼Transformerçæ¨¡åä¸éæçæ¬è³ªï¼ç¹å¥æ¯å¨å®¹æåå°ä¸éå¾·è¡çºï¼ä¾å¦ä½¿ç¨èä»é¢çææ¨¡å¼ï¼å½±é¿çæç¨ä¸­ï¼éè¦æ´åä¸ç¢ºå®æ§éåä»¥å¢å¼·å°é æ¸¬çä¿¡ä»»ãæ¬ç ç©¶å°æ³¨æ¼ææ¨¡å¼åµæ¸¬ï¼ä¹å°±æ¯ææç¸±ä½¿ç¨èæ±ºç­ãç ´å£èªä¸»æ§ååæçæ¬ºé¨æ§è¨­è¨é¸æãæåæåºä¸ç¨®å·®åå¾®èª¿æ¹æ³ï¼ééåºæ¼Transformerçé è¨ç·´æ¨¡åçä¸ç¢ºå®æ§éåå¨æçµåé¡æ¨é ­ä¸­å¯¦ä½ãä½¿ç¨å¯éç¥ç¶ç¶²è·¯ (DNN) æ¨é ­æ¶æ§ä½çºåºæºï¼æåæª¢è¦å©ç¨®è½å¤ éåä¸ç¢ºå®æ§çæ¹æ³ï¼åè­æ­£è¦åç¥ç¶é«æ¯éç¨ (SNGP) åè²æ°ç¥ç¶ç¶²è·¯ (BNN)ãéäºæ¹æ³å¨å¤åé¢åçéæ¾åå§ç¢¼åºç¤æ¨¡åä¸é²è¡è©ä¼°ï¼æ¨¡åæè½ãé æ¸¬ç¢ºå®æ§çè®ç°ä»¥åè¨ç·´åæ¨è«éæ®µçç°å¢å½±é¿ãçµæè¡¨æï¼æ´åä¸ç¢ºå®æ§éåè½ç¶­ææè½ï¼åææä¾å°æ¨¡åä¸­å·ææ°æ§æ¡ä¾çè¦è§£ãæ­¤å¤ï¼ç ç©¶é¡¯ç¤ºç°å¢å½±é¿ä¸¦ä¸æé¨èä¸ç¢ºå®æ§éåæè¡çç´å¥èåå»å¢å ãç ç©¶çµæè¡¨æï¼ä¸ç¢ºå®æ§éåè½å¢å¼·éæåº¦ï¼ä¸¦æä¾å¯è¡¡éçé æ¸¬ä¿¡å¿ï¼é²èæåé»ç®±æ¨¡åçå¯è§£éæ§åæ¸æ°åº¦ãéæå©æ¼ææºçæ±ºç­å¶å®ï¼ä¸¦æ¸è¼ææ¨¡å¼å°ä½¿ç¨èä»é¢çå½±é¿ãéäºçµæçªé¡¯äºå¨éç¼æ©å¨å­¸ç¿æ¨¡åæç´å¥ä¸ç¢ºå®æ§éåæè¡çéè¦æ§ï¼ç¹å¥æ¯å¨å¯è§£éæ§åå¯ä¿¡åº¦è³ééè¦çé åä¸­ã</paragraph>

##### **Enhancing FKG.in: automating Indian food composition analysis**
2412.05248v1 by Saransh Kumar Gupta, Lipika Dey, Partha Pratim Das, Geeta Trilok-Kumar, Ramesh Jain

This paper presents a novel approach to compute food composition data for
Indian recipes using a knowledge graph for Indian food (FKG.in) and LLMs. The
primary focus is to provide a broad overview of an automated food composition
analysis workflow and describe its core functionalities: nutrition data
aggregation, food composition analysis, and LLM-augmented information
resolution. This workflow aims to complement FKG.in and iteratively supplement
food composition data from verified knowledge bases. Additionally, this paper
highlights the challenges of representing Indian food and accessing food
composition data digitally. It also reviews three key sources of food
composition data: the Indian Food Composition Tables, the Indian Nutrient
Databank, and the Nutritionix API. Furthermore, it briefly outlines how users
can interact with the workflow to obtain diet-based health recommendations and
detailed food composition information for numerous recipes. We then explore the
complex challenges of analyzing Indian recipe information across dimensions
such as structure, multilingualism, and uncertainty as well as present our
ongoing work on LLM-based solutions to address these issues. The methods
proposed in this workshop paper for AI-driven knowledge curation and
information resolution are application-agnostic, generalizable, and replicable
for any domain.

æè¦ï¼éç¯è«ææåºä¸ååµæ°çæ¹æ³ï¼ä½¿ç¨å°åº¦é£ç©ç¥è­åè­ (FKG.in) åå¤§åèªè¨æ¨¡å (LLM) ä¾è¨ç®å°åº¦é£è­çé£åæåè³æãä¸»è¦ç®æ¨æ¯æä¾èªååé£åæååæå·¥ä½æµç¨çæ¦è§ï¼ä¸¦æè¿°å¶æ ¸å¿åè½ï¼çé¤è³æå½æ´ãé£åæååæï¼ä»¥å LLM å¢å¼·çè³è¨è§£æãæ­¤å·¥ä½æµç¨æ¨å¨è£å FKG.inï¼ä¸¦åè¦è£åä¾èªé©è­ç¥è­åº«çé£åæåè³æãæ­¤å¤ï¼éç¯è«æå¼·èª¿äºåç¾å°åº¦é£ç©åä»¥æ¸ä½æ¹å¼å­åé£åæåè³æçææ°ãå®ä¹æª¢è¦äºé£åæåè³æçä¸åä¸»è¦ä¾æºï¼å°åº¦é£åæåè¡¨ãå°åº¦çé¤è³æåº«ï¼ä»¥å Nutritionix APIãæ­¤å¤ï¼å®ç°¡è¦æ¦è¿°äºä½¿ç¨èå¦ä½èå·¥ä½æµç¨äºåï¼ä»¥åå¾åºæ¼é£²é£çå¥åº·å»ºè­°åè¨±å¤é£è­çè©³ç´°é£åæåè³è¨ãæ¥èæåæ¢è¨åæå°åº¦é£è­è³è¨çè¤éææ°ï¼åæ¬çµæ§ãå¤èªè¨æ§ï¼ä»¥åä¸ç¢ºå®æ§ï¼ä¸¦æåºæåæ­£å¨é²è¡ç LLM åºç¤è§£æ±ºæ¹æ¡ä¾è§£æ±ºéäºåé¡ãéç¯å·¥ä½åè«æä¸­æåºç AI é©åç¥è­ç­å±åè³è¨è§£ææ¹æ³èæç¨ç¨å¼ç¡éï¼å¯æ¦æ¬åï¼ä¸å¯è¤è£½å°ä»»ä½é åã

##### **Enhancing Foundation Models for Time Series Forecasting via Wavelet-based Tokenization**
2412.05244v1 by Luca Masserano, Abdul Fatir Ansari, Boran Han, Xiyuan Zhang, Christos Faloutsos, Michael W. Mahoney, Andrew Gordon Wilson, Youngsuk Park, Syama Rangapuram, Danielle C. Maddix, Yuyang Wang

How to best develop foundational models for time series forecasting remains
an important open question. Tokenization is a crucial consideration in this
effort: what is an effective discrete vocabulary for a real-valued sequential
input? To address this question, we develop WaveToken, a wavelet-based
tokenizer that allows models to learn complex representations directly in the
space of time-localized frequencies. Our method first scales and decomposes the
input time series, then thresholds and quantizes the wavelet coefficients, and
finally pre-trains an autoregressive model to forecast coefficients for the
forecast horizon. By decomposing coarse and fine structures in the inputs,
wavelets provide an eloquent and compact language for time series forecasting
that simplifies learning. Empirical results on a comprehensive benchmark,
including 42 datasets for both in-domain and zero-shot settings, show that
WaveToken: i) provides better accuracy than recently proposed foundation models
for forecasting while using a much smaller vocabulary (1024 tokens), and
performs on par or better than modern deep learning models trained specifically
on each dataset; and ii) exhibits superior generalization capabilities,
achieving the best average rank across all datasets for three complementary
metrics. In addition, we show that our method can easily capture complex
temporal patterns of practical relevance that are challenging for other recent
pre-trained models, including trends, sparse spikes, and non-stationary time
series with varying frequencies evolving over time.

æè¦ï¼å¦ä½æä½³å°éç¼æéåºåé æ¸¬çåºæ¬æ¨¡åä»ç¶æ¯ä¸åéè¦çéæ¾æ§åé¡ãå¨æ­¤å·¥ä½ä¸­ï¼ç¬¦èåæ¯ä¸åééµèéï¼å°æ¼ä¸åå¯¦å¼åºåè¼¸å¥ä¾èªªï¼ä»éº¼æ¯ä¸åææçé¢æ£è©å½ï¼çºäºè§£æ±ºéååé¡ï¼æåéç¼äº WaveTokenï¼ä¸ååºæ¼å°æ³¢çç¬¦èåå¨ï¼å®åè¨±æ¨¡åç´æ¥å¨æåé »ççç©ºéä¸­å­¸ç¿è¤éçè¡¨ç¤ºãæåçæ¨¡åé¦åå°è¼¸å¥æéåºåé²è¡ç¸®æ¾ååè§£ï¼ç¶å¾å°å°æ³¢ä¿æ¸é²è¡é¾å¼èçåéåï¼æå¾é è¨ç·´ä¸åèªè¿´æ­¸æ¨¡åä¾é æ¸¬é æ¸¬ç¯åå§çä¿æ¸ãééåè§£è¼¸å¥ä¸­çç²ç³åç²¾ç´°çµæ§ï¼å°æ³¢çºæéåºåé æ¸¬æä¾äºä¸ç¨®ç°¡æ½èç·æ¹çèªè¨ï¼ç°¡åäºå­¸ç¿ãå¨ä¸åç¶ååºæºä¸çç¶é©çµæï¼åæ¬ 42 åç¨æ¼åå§åé¶æ¬¡å­¸ç¿è¨­ç½®çæ¸æéï¼è¡¨æ WaveTokenï¼i) å¨é æ¸¬ææä¾äºæ¯æè¿æåºçåºç¤æ¨¡åæ´å¥½çæºç¢ºåº¦ï¼åæä½¿ç¨äºæ´å°çè©å½éï¼1024 åç¬¦èï¼ï¼ä¸¦ä¸å¨å°ééå°æ¯åæ¸æéè¨ç·´çç¾ä»£æ·±åº¦å­¸ç¿æ¨¡åä¸­è¡¨ç¾å¾ä¸æ¨£å¥½ææ´å¥½ï¼ä¸¦ä¸ ii) å±ç¾åºåè¶çæ³åè½åï¼å°æ¼ä¸åäºè£ææ¨ï¼å¨æææ¸æéä¸å¯¦ç¾äºæä½³å¹³åæåãæ­¤å¤ï¼æåè¡¨æï¼æåçæ¨¡åå¯ä»¥è¼é¬ææå¶ä»æè¿é è¨ç·´æ¨¡åé£ä»¥æå°çè¤éæéæ¨¡å¼ï¼åæ¬è¶¨å¢ãç¨çå°å³°åé¨èæéæ¨ç§»èæ¼è®çå·æä¸åé »ççéå¹³ç©©æéåºåã

##### **CompCap: Improving Multimodal Large Language Models with Composite Captions**
2412.05243v1 by Xiaohui Chen, Satya Narayan Shukla, Mahmoud Azab, Aashu Singh, Qifan Wang, David Yang, ShengYun Peng, Hanchao Yu, Shen Yan, Xuewen Zhang, Baosheng He

How well can Multimodal Large Language Models (MLLMs) understand composite
images? Composite images (CIs) are synthetic visuals created by merging
multiple visual elements, such as charts, posters, or screenshots, rather than
being captured directly by a camera. While CIs are prevalent in real-world
applications, recent MLLM developments have primarily focused on interpreting
natural images (NIs). Our research reveals that current MLLMs face significant
challenges in accurately understanding CIs, often struggling to extract
information or perform complex reasoning based on these images. We find that
existing training data for CIs are mostly formatted for question-answer tasks
(e.g., in datasets like ChartQA and ScienceQA), while high-quality
image-caption datasets, critical for robust vision-language alignment, are only
available for NIs. To bridge this gap, we introduce Composite Captions
(CompCap), a flexible framework that leverages Large Language Models (LLMs) and
automation tools to synthesize CIs with accurate and detailed captions. Using
CompCap, we curate CompCap-118K, a dataset containing 118K image-caption pairs
across six CI types. We validate the effectiveness of CompCap-118K by
supervised fine-tuning MLLMs of three sizes: xGen-MM-inst.-4B and
LLaVA-NeXT-Vicuna-7B/13B. Empirical results show that CompCap-118K
significantly enhances MLLMs' understanding of CIs, yielding average gains of
1.7%, 2.0%, and 2.9% across eleven benchmarks, respectively.

æè¦ï¼å¤æ¨¡æå¤§åèªè¨æ¨¡å (MLLM) è½æå¤å¥½å°çè§£åæå½±åï¼åæå½±å (CI) æ¯ééåä½µå¤åè¦è¦ºåç´ ï¼ä¾å¦åè¡¨ãæµ·å ±æè¢å¹æªåï¼æå»ºç«çåæè¦è¦ºææï¼èä¸æ¯ç´æ¥ç±ç¸æ©ææãåç®¡ CI å¨ç¾å¯¦ä¸ççæç¨ä¸­å¾æ®éï¼ä½æè¿ç MLLM ç¼å±ä¸»è¦éä¸­å¨è©®éèªç¶å½±å (NI)ãæåçç ç©¶é¡¯ç¤ºï¼ç¾æç MLLM å¨æºç¢ºçè§£ CI æé¢è¨éå¤§ææ°ï¼ç¶å¸¸é£ä»¥æ ¹æéäºå½±åæ·åè³è¨æå·è¡è¤éçæ¨çãæåç¼ç¾ï¼CI çç¾æè¨ç·´è³æå¤§å¤ä»¥åç­ä»»åçæ ¼å¼åç¾ï¼ä¾å¦ ChartQA å ScienceQA ç­è³æéï¼ï¼èå°æ¼ç©©å¥çè¦è¦ºèªè¨å°é½è³ééè¦çåªè³ªå½±åæ¨é¡è³æéåé©ç¨æ¼ NIãçºäºå½è£éåå·®è·ï¼æåå¼å¥äºåææ¨é¡ (CompCap)ï¼éæ¯ä¸åéæ´»çæ¶æ§ï¼å©ç¨å¤§åèªè¨æ¨¡å (LLM) åèªååå·¥å·ä¾åæå·ææºç¢ºä¸è©³ç´°æ¨é¡ç CIãä½¿ç¨ CompCapï¼æåæ´çäº CompCap-118Kï¼ä¸ååå« 118K å½±åæ¨é¡å°æçè³æéï¼æ¶µèå­ç¨®é¡åç CIãæåééç£ç£å¾®èª¿ä¸ç¨®å°ºå¯¸ç MLLM ä¾é©è­ CompCap-118K çæææ§ï¼xGen-MM-inst.-4B å LLaVA-NeXT-Vicuna-7B/13Bãç¶é©çµæé¡¯ç¤ºï¼CompCap-118K å¤§å¹æåäº MLLM å° CI ççè§£ï¼å¨ 11 ååºæºä¸­åå¥ç¢çäºå¹³å 1.7%ã2.0% å 2.9% çå¢çã

##### **MAmmoTH-VL: Eliciting Multimodal Reasoning with Instruction Tuning at Scale**
2412.05237v1 by Jarvis Guo, Tuney Zheng, Yuelin Bai, Bo Li, Yubo Wang, King Zhu, Yizhi Li, Graham Neubig, Wenhu Chen, Xiang Yue

Open-source multimodal large language models (MLLMs) have shown significant
potential in a broad range of multimodal tasks. However, their reasoning
capabilities remain constrained by existing instruction-tuning datasets, which
were predominately repurposed from academic datasets such as VQA, AI2D, and
ChartQA. These datasets target simplistic tasks, and only provide phrase-level
answers without any intermediate rationales. To address these challenges, we
introduce a scalable and cost-effective method to construct a large-scale
multimodal instruction-tuning dataset with rich intermediate rationales
designed to elicit CoT reasoning. Using only open models, we create a dataset
containing 12M instruction-response pairs to cover diverse, reasoning-intensive
tasks with detailed and faithful rationales. Experiments demonstrate that
training MLLMs on this dataset significantly improves reasoning capabilities,
achieving state-of-the-art performance on benchmarks such as MathVerse (+8.1%),
MMMU-Pro (+7%), and MuirBench (+13.3%). Additionally, the model demonstrates
notable improvements of up to 4% on non-reasoning-based benchmarks. Ablation
studies further highlight the importance of key components, such as rewriting
and self-filtering, in the dataset construction process.

æè¦ï¼éæ¾åå§ç¢¼å¤æ¨¡æå¤§åèªè¨æ¨¡å (MLLM) å·²å¨å»£æ³çå¤æ¨¡æä»»åä¸­å±ç¾é¡¯èæ½åãç¶èï¼å¶æ¨çè½åä»åéæ¼ç¾æçæä»¤èª¿æ´è³æéï¼èéäºè³æéä¸»è¦æ¹ç·¨èªå­¸è¡è³æéï¼ä¾å¦ VQAãAI2D å ChartQAãéäºè³æééå®ç°¡åçä»»åï¼èä¸åæä¾çèªå±¤ç´çç­æ¡ï¼èæ²æä»»ä½ä¸­éçä¾æãçºäºæå°éäºææ°ï¼æåå¼é²ä¸ç¨®å¯æ´åä¸å·ææ¬æççæ¹æ³ï¼ä»¥å»ºæ§ä¸åå¤§åå¤æ¨¡ææä»¤èª¿æ´è³æéï¼å¶ä¸­åå«è±å¯çä¸­éä¾æï¼æ¨å¨å¼ç¼ CoT æ¨çãæååä½¿ç¨éæ¾æ¨¡åï¼å°±è½å»ºç«ä¸ååå« 1200 è¬åæä»¤åæéå°çè³æéï¼æ¶µèåç¨®æ¨çå¯éåä»»åï¼ä¸¦å·åè©³ç´°ä¸å¿ å¯¦çä¾æãå¯¦é©è­æï¼å¨éåè³æéä¸è¨ç·´ MLLM è½é¡¯èæåæ¨çè½åï¼å¨ MathVerse (+8.1%)ãMMMU-Pro (+7%) å MuirBench (+13.3%) ç­åºæºæ¸¬è©¦ä¸­ç²å¾æåé²çæè½ãæ­¤å¤ï¼è©²æ¨¡åå¨éåºæ¼æ¨ççåºæºæ¸¬è©¦ä¸­å±ç¾åºé«é 4% çé¡¯èé²æ­¥ãæ¶èç ç©¶é²ä¸æ­¥çªé¡¯äºééµçµæè¦ç´ ï¼ä¾å¦å¨è³æéå»ºæ§éç¨ä¸­é²è¡æ¹å¯«åèªæéæ¿¾ï¼çéè¦æ§ã

##### **LIAR: Leveraging Alignment (Best-of-N) to Jailbreak LLMs in Seconds**
2412.05232v1 by James Beetham, Souradip Chakraborty, Mengdi Wang, Furong Huang, Amrit Singh Bedi, Mubarak Shah

Many existing jailbreak techniques rely on solving discrete combinatorial
optimization, while more recent approaches involve training LLMs to generate
multiple adversarial prompts. However, both approaches require significant
computational resources to produce even a single adversarial prompt. We
hypothesize that the inefficiency of current approaches stems from an
inadequate characterization of the jailbreak problem. To address this gap, we
formulate the jailbreak problem in terms of alignment. By starting from an
available safety-aligned model, we leverage an unsafe reward to guide the safe
model towards generating unsafe outputs using alignment techniques (e.g.,
reinforcement learning from human feedback), effectively performing
jailbreaking via alignment. We propose a novel jailbreak method called LIAR
(LeveragIng Alignment to jailbReak). To demonstrate the simplicity and
effectiveness of our approach, we employ a best-of-N method to solve the
alignment problem. LIAR offers significant advantages: lower computational
requirements without additional training, fully black-box operation,
competitive attack success rates, and more human-readable prompts. We provide
theoretical insights into the possibility of jailbreaking a safety-aligned
model, revealing inherent vulnerabilities in current alignment strategies for
LLMs. We also provide sub-optimality guarantees for the proposed \algo.
Experimentally, we achieve ASR comparable to the SoTA with a 10x improvement to
perplexity and a Time-to-Attack measured in seconds rather than tens of hours.

æè¦ï¼è¨±å¤ç¾æçè¶çæè¡ä¾è³´æ¼è§£æ±ºé¢æ£çµåæä½³åï¼èè¼æ°çæ¹æ³åæ¶åè¨ç·´ LLM ä»¥ç¢çå¤åå°ææç¤ºãç¶èï¼éå©ç¨®æ¹æ³é½éè¦å¤§éçè¨ç®è³æºæè½ç¢çå®ä¸çå°ææç¤ºãæååè¨­ç¶åæ¹æ³çä½æçæºæ¼å°è¶çåé¡çä¸ååè¡¨å¾µãçºäºè§£æ±ºéåå·®è·ï¼æåæ ¹æå°é½ä¾å¶å®è¶çåé¡ãå¾ä¸åå¯ç¨çå®å¨å°é½æ¨¡åéå§ï¼æåå©ç¨ä¸å®å¨ççåµä¾å¼å°å®å¨æ¨¡åä½¿ç¨å°é½æè¡ï¼ä¾å¦ï¼å¾äººé¡åé¥ä¸­é²è¡å¼·åå­¸ç¿ï¼ç¢çä¸å®å¨çè¼¸åºï¼ææå°ééå°é½é²è¡è¶çãæåæåºäºä¸ç¨®åçº LIARï¼LeveragIng Alignment to jailbReakï¼çæ°åè¶çæ¹æ³ãçºäºå±ç¤ºæåæ¹æ³çç°¡å®æ§åæææ§ï¼æåæ¡ç¨ N ä¸­æä½³æ¹æ³ä¾è§£æ±ºå°é½åé¡ãLIAR æä¾é¡¯èçåªå¢ï¼ç¡éé¡å¤è¨ç·´å³å¯éä½è¨ç®è¦æ±ãå®å¨é»çæä½ãå·æç«¶ç­åçæ»ææåçä»¥åæ´å·å¯è®æ§çæç¤ºãæåæä¾äºå°è¶çå®å¨å°é½æ¨¡åçå¯è½æ§ççè«è¦è§£ï¼æ­ç¤ºäºç¶å LLM å°é½ç­ç¥ä¸­åºæçæ¼æ´ãæåéçºæåºçæ¼ç®æ³æä¾æ¬¡åªä¿è­ãå¨å¯¦é©ä¸­ï¼æåå¯¦ç¾äºè SoTA ç¸ç¶ç ASRï¼å°æåº¦æé«äº 10 åï¼æ»ææéä»¥ç§çºå®ä½è¡¡éï¼èä¸æ¯ä»¥æ¸åå°æçºå®ä½ã

##### **BEExformer: A Fast Inferencing Transformer Architecture via Binarization with Multiple Early Exits**
2412.05225v1 by Wazib Ansar, Saptarsi Goswami, Amlan Chakrabarti

Large Language Models (LLMs) based on transformers achieve cutting-edge
results on a variety of applications. However, their enormous size and
processing requirements make deployment on devices with constrained resources
extremely difficult. Among various efficiency considerations, model
binarization and Early Exit (EE) are common effective solutions. However,
binarization may lead to performance loss due to reduced precision affecting
gradient estimation and parameter updates. Besides, the present early-exit
mechanisms are still in the nascent stages of research. To ameliorate these
issues, we propose Binarized Early Exit Transformer (BEExformer), the
first-ever selective learning transformer architecture to combine early exit
with binarization for textual inference. It improves the binarization process
through a differentiable second-order approximation to the impulse function.
This enables gradient computation concerning both the sign as well as the
magnitude of the weights. In contrast to absolute threshold-based EE, the
proposed EE mechanism hinges on fractional reduction in entropy among
intermediate transformer blocks with soft-routing loss estimation. While
binarization results in 18.44 times reduction in model size, early exit reduces
the FLOPs during inference by 54.85% and even improves accuracy by 5.98%
through resolving the "overthinking" problem inherent in deep networks.
Moreover, the proposed BEExformer simplifies training by not requiring
knowledge distillation from a full-precision LLM. Extensive evaluation on the
GLUE dataset and comparison with the SOTA works showcase its pareto-optimal
performance-efficiency trade-off.

æè¦ï¼<paragraph>åºæ¼Transformerçå·¨éèªè¨æ¨¡å (LLM) å¨åç¨®æç¨ä¸é½è½éå°å°ç«¯ççµæãç¶èï¼å®åé¾å¤§çè¦æ¨¡åèçéæ±è®å¨è³æºåéçè£ç½®ä¸é¨ç½²è®å¾æ¥µå¶å°é£ãå¨åç¨®æçèéä¸­ï¼æ¨¡åäºåååæ©æéåº (EE) æ¯å¸¸è¦çæææ¹æ¡ãç¶èï¼äºååå¯è½æå°è´æè½æå¤±ï¼å çºéä½çç²¾åº¦æå½±é¿æ¢¯åº¦ä¼°è¨ååæ¸æ´æ°ãæ­¤å¤ï¼ç¾æçæ©æéåºæ©å¶ä»èæ¼ç ç©¶çèè½éæ®µãçºäºæ¹åéäºåé¡ï¼æåæåºäºäºååæ©æéåºTransformer (BEExformer)ï¼éæ¯ç¬¬ä¸åçµåæ©æéåºèäºååçé¸ææ§å­¸ç¿Transformeræ¶æ§ï¼ç¨æ¼æå­æ¨è«ãå®ééå°èè¡å½æ¸é²è¡å¯å¾®åçäºéè¿ä¼¼ä¾æ¹åäºååç¨åºãéä½¿å¾æ¢¯åº¦è¨ç®èæ¬éçç¬¦èåå¤§å°é½æéãèåºæ¼çµå°é¾å¼ç EE ç¸æ¯ï¼æè­°ç EE æ©å¶åæ±ºæ¼ä¸­éTransformeråå¡ä¹éçµçåæ¸æ¸å°ï¼ä¸¦å·æè»è·¯ç±æå¤±ä¼°è¨ãéç¶äºååå°è´æ¨¡åå¤§å°æ¸å°äº 18.44 åï¼ä½æ©æéåºå°æ¨è«æéç FLOP æ¸å°äº 54.85%ï¼çè³ééè§£æ±ºæ·±åº¦ç¶²è·¯ä¸­åºæçãéåº¦æèãåé¡èå°æºç¢ºåº¦æåäº 5.98%ãæ­¤å¤ï¼ææåºç BEExformer ç°¡åäºè¨ç·´ï¼å çºä¸éè¦å¾å¨ç²¾åº¦ LLM é²è¡ç¥è­è¸é¤¾ãå¨ GLUE è³æéä¸çå»£æ³è©ä¼°ä»¥åè SOTA ä½åçæ¯è¼å±ç¤ºäºå¶å¸ç´¯ææåªçæè½æçæ¬è¡¡ã</paragraph>

##### **100% Hallucination Elimination Using Acurai**
2412.05223v1 by Michael C. Wood, Adam A. Forbes

The issue of hallucinations in large language models (LLMs) remains a
critical barrier to the adoption of AI in enterprise and other high-stakes
applications. Despite advancements in retrieval-augmented generation (RAG)
systems, current state-of-the-art methods fail to achieve more than 80%
accuracy in generating faithful and factually correct outputs, even when
provided with relevant and accurate context. In this work, we introduce Acurai,
a novel systematic approach that achieves 100% hallucination-free responses in
LLMs by reformatting queries and context data prior to input. Leveraging a deep
understanding of LLM internal representations, the importance of noun-phrase
dominance, and the role of discrete functional units (DFUs), Acurai ensures
alignment between input context and generated output. We validate this method
using the RAGTruth corpus, demonstrating its ability to eliminate 100%
hallucinations for both GPT-4 and GPT-3.5 Turbo. Acurai sets a new standard for
achieving consistent, accurate, and faithful AI responses, marking a
significant step forward in the development of trustworthy AI systems.

æè¦ï¼å¤§åèªè¨æ¨¡åï¼LLMï¼ä¸­çå¹»è¦ºåé¡ä»ç¶æ¯ä¼æ¥­åå¶ä»é«é¢¨éªæç¨ä¸­æ¡ç¨ AI çééµéç¤ãåç®¡æª¢ç´¢å¢å¼·çæï¼RAGï¼ç³»çµ±åå¾äºé²å±ï¼ä½ç¾æçæåé²æ¹æ³å¨çæå¿ å¯¦ä¸äºå¯¦æ­£ç¢ºçè¼¸åºæ¹é¢ç¡æ³éå° 80% ä»¥ä¸çæºç¢ºåº¦ï¼å³ä½¿å¨æä¾äºç¸éä¸æºç¢ºçèæ¯ä¸ä¹æ¯å¦æ­¤ãå¨éé å·¥ä½ä¸­ï¼æåå¼å¥äº Acuraiï¼éæ¯ä¸ç¨®æ°ç©çç³»çµ±åæ¹æ³ï¼ééå¨è¼¸å¥ä¹åéæ°æ ¼å¼åæ¥è©¢åä¸ä¸ææ¸æï¼å¨ LLM ä¸­å¯¦ç¾ 100% ç¡å¹»è¦ºçåæãAcurai å©ç¨å° LLM å§é¨è¡¨ç¤ºãåè©ç­èªæ¯éçéè¦æ§ä»¥åé¢æ£åè½å®åï¼DFUï¼ä½ç¨çæ·±å¥çè§£ï¼ç¢ºä¿è¼¸å¥ä¸ä¸æåçæçè¼¸åºä¹éçä¸è´æ§ãæåä½¿ç¨ RAGTruth èªæåº«é©è­äºæ­¤æ¹æ³ï¼è­æäºå®æ¶é¤ GPT-4 å GPT-3.5 Turbo ç 100% å¹»è¦ºçè½åãAcurai çºå¯¦ç¾ä¸è´ãæºç¢ºåå¿ å¯¦ç AI é¿æè¨­å®äºæ°çæ¨æºï¼æ¨èªèå¯ä¿¡è³´ AI ç³»çµ±éç¼ååéåºäºéè¦ä¸æ­¥ã

##### **Evaluating and Aligning CodeLLMs on Human Preference**
2412.05210v1 by Jian Yang, Jiaxi Yang, Ke Jin, Yibo Miao, Lei Zhang, Liqun Yang, Zeyu Cui, Yichang Zhang, Binyuan Hui, Junyang Lin

Code large language models (codeLLMs) have made significant strides in code
generation. Most previous code-related benchmarks, which consist of various
programming exercises along with the corresponding test cases, are used as a
common measure to evaluate the performance and capabilities of code LLMs.
However, the current code LLMs focus on synthesizing the correct code snippet,
ignoring the alignment with human preferences, where the query should be
sampled from the practical application scenarios and the model-generated
responses should satisfy the human preference. To bridge the gap between the
model-generated response and human preference, we present a rigorous
human-curated benchmark CodeArena to emulate the complexity and diversity of
real-world coding tasks, where 397 high-quality samples spanning 40 categories
and 44 programming languages, carefully curated from user queries. Further, we
propose a diverse synthetic instruction corpus SynCode-Instruct (nearly 20B
tokens) by scaling instructions from the website to verify the effectiveness of
the large-scale synthetic instruction fine-tuning, where Qwen2.5-SynCoder
totally trained on synthetic instruction data can achieve top-tier performance
of open-source code LLMs. The results find performance differences between
execution-based benchmarks and CodeArena. Our systematic experiments of
CodeArena on 40+ LLMs reveal a notable performance gap between open SOTA code
LLMs (e.g. Qwen2.5-Coder) and proprietary LLMs (e.g., OpenAI o1), underscoring
the importance of the human preference
alignment.\footnote{\url{https://codearenaeval.github.io/ }}

æè¦ï¼<paragraph>å¤§åèªè¨æ¨¡åï¼codeLLMï¼å¨ç¨å¼ç¢¼çææ¹é¢åå¾äºé¡¯èé²å±ãå¤§å¤æ¸ååçç¨å¼ç¢¼ç¸éåºæºï¼åå«åç¨®ç¨å¼è¨­è¨ç·´ç¿ä»¥åå°æçæ¸¬è©¦æ¡ä¾ï¼ç¨ä½è©ä¼° code LLM æè½ååè½çå¸¸è¦æ¸¬éæ¨æºãç¶èï¼ç®åç code LLM å°æ³¨æ¼åææ­£ç¢ºçç¨å¼ç¢¼çæ®µï¼å¿½ç¥èäººé¡åå¥½çå°é½ï¼å¶ä¸­æ¥è©¢æå¾å¯¦éæç¨æå¢ä¸­æ½æ¨£ï¼èæ¨¡åç¢ççåæææ»¿è¶³äººé¡åå¥½ãçºäºå½åæ¨¡åç¢ççåæèäººé¡åå¥½ä¹éçå·®è·ï¼æåæåºäºä¸åå´è¬¹çäººå·¥ç­å±åºæº CodeArenaï¼ä»¥æ¨¡æ¬çå¯¦ä¸çç¨å¼è¨­è¨ä»»åçè¤éæ§åå¤æ¨£æ§ï¼å¶ä¸­ 397 åé«åè³ªç¯ä¾æ¶µè 40 åé¡å¥å 44 ç¨®ç¨å¼èªè¨ï¼å¾ä½¿ç¨èæ¥è©¢ä¸­ä»ç´°ç­å±ãæ­¤å¤ï¼æåæåºäºä¸åå¤æ¨£åçåææä»¤èªæåº« SynCode-Instructï¼å°è¿ 20B åä»£å¹£ï¼ï¼ééæ´åç¶²ç«ä¸çæä»¤ä¾é©è­å¤§è¦æ¨¡åææä»¤å¾®èª¿çæææ§ï¼å¶ä¸­ Qwen2.5-SynCoder å®å¨è¨ç·´æ¼åææä»¤è³æï¼å¯ä»¥éå°éæ¾åå§ç¢¼ code LLM çé ç´æè½ãçµæç¼ç¾åºæ¼å·è¡çåºæºå CodeArena ä¹éçæè½å·®ç°ãæåå¨ 40 å¤å LLM ä¸é²è¡ CodeArena çç³»çµ±æ§å¯¦é©ï¼æ­ç¤ºäºéæ¾ SOTA code LLMï¼ä¾å¦ Qwen2.5-Coderï¼åå°æ LLMï¼ä¾å¦ OpenAI o1ï¼ä¹éé¡¯èçæè½å·®è·ï¼å¼·èª¿äºäººé¡åå¥½å°é½çéè¦æ§ã\footnote{\url{https://codearenaeval.github.io/ }}</paragraph>

##### **A Survey of Large Language Model-Based Generative AI for Text-to-SQL: Benchmarks, Applications, Use Cases, and Challenges**
2412.05208v1 by Aditi Singh, Akash Shetty, Abul Ehtesham, Saket Kumar, Tala Talaei Khoei

Text-to-SQL systems facilitate smooth interaction with databases by
translating natural language queries into Structured Query Language (SQL),
bridging the gap between non-technical users and complex database management
systems. This survey provides a comprehensive overview of the evolution of
AI-driven text-to-SQL systems, highlighting their foundational components,
advancements in large language model (LLM) architectures, and the critical role
of datasets such as Spider, WikiSQL, and CoSQL in driving progress. We examine
the applications of text-to-SQL in domains like healthcare, education, and
finance, emphasizing their transformative potential for improving data
accessibility. Additionally, we analyze persistent challenges, including domain
generalization, query optimization, support for multi-turn conversational
interactions, and the limited availability of datasets tailored for NoSQL
databases and dynamic real-world scenarios. To address these challenges, we
outline future research directions, such as extending text-to-SQL capabilities
to support NoSQL databases, designing datasets for dynamic multi-turn
interactions, and optimizing systems for real-world scalability and robustness.
By surveying current advancements and identifying key gaps, this paper aims to
guide the next generation of research and applications in LLM-based text-to-SQL
systems.

æè¦ï¼ææ¬è½¬ SQL ç³»ç»éè¿å°èªç¶è¯­è¨æ¥è¯¢è½¬æ¢ä¸ºç»æåæ¥è¯¢è¯­è¨ (SQL) æ¥ä¿è¿ä¸æ°æ®åºçé¡ºçäº¤äºï¼å¼¥åéææ¯ç¨æ·ä¸å¤ææ°æ®åºç®¡çç³»ç»ä¹é´çå·®è·ãæ¬è°æ¥å¨é¢æ¦è¿°äº AI é©±å¨çææ¬è½¬ SQL ç³»ç»çæ¼åï¼éç¹ä»ç»äºå¶åºç¡ç»ä»¶ãå¤§è¯­è¨æ¨¡å (LLM) æ¶æçè¿æ­¥ä»¥å SpiderãWikiSQL å CoSQL ç­æ°æ®éå¨æ¨å¨è¿æ­¥ä¸­çå³é®ä½ç¨ãæä»¬ç ç©¶äºææ¬è½¬ SQL å¨å»çä¿å¥ãæè²åéèç­é¢åçåºç¨ï¼å¼ºè°äºå®ä»¬å¨æé«æ°æ®å¯è®¿é®æ§æ¹é¢çåé©æ½åãæ­¤å¤ï¼æä»¬åæäºæç»­å­å¨çææï¼åæ¬é¢åæ³åãæ¥è¯¢ä¼åãå¯¹å¤è½®å¯¹è¯äº¤äºçæ¯æä»¥åéå¯¹ NoSQL æ°æ®åºåå¨æçå®ä¸çåºæ¯å®å¶çæ°æ®éçå¯ç¨æ§æéãä¸ºäºåºå¯¹è¿äºææï¼æä»¬æ¦è¿°äºæªæ¥çç ç©¶æ¹åï¼ä¾å¦æ©å±ææ¬è½¬ SQL åè½ä»¥æ¯æ NoSQL æ°æ®åºãä¸ºå¨æå¤è½®äº¤äºè®¾è®¡æ°æ®éä»¥åä¼åç³»ç»ä»¥å®ç°å®éä¸ççå¯æ©å±æ§åé²æ£æ§ãéè¿è°æ¥å½åçè¿æ­¥å¹¶æ¾åºå³é®å·®è·ï¼æ¬ææ¨å¨æå¯¼åºäº LLM çææ¬è½¬ SQL ç³»ç»çä¸ä¸ä»£ç ç©¶ååºç¨ã

##### **ConQRet: Benchmarking Fine-Grained Evaluation of Retrieval Augmented Argumentation with LLM Judges**
2412.05206v1 by Kaustubh D. Dhole, Kai Shu, Eugene Agichtein

Computational argumentation, which involves generating answers or summaries
for controversial topics like abortion bans and vaccination, has become
increasingly important in today's polarized environment. Sophisticated LLM
capabilities offer the potential to provide nuanced, evidence-based answers to
such questions through Retrieval-Augmented Argumentation (RAArg), leveraging
real-world evidence for high-quality, grounded arguments. However, evaluating
RAArg remains challenging, as human evaluation is costly and difficult for
complex, lengthy answers on complicated topics. At the same time, re-using
existing argumentation datasets is no longer sufficient, as they lack long,
complex arguments and realistic evidence from potentially misleading sources,
limiting holistic evaluation of retrieval effectiveness and argument quality.
To address these gaps, we investigate automated evaluation methods using
multiple fine-grained LLM judges, providing better and more interpretable
assessments than traditional single-score metrics and even previously reported
human crowdsourcing. To validate the proposed techniques, we introduce ConQRet,
a new benchmark featuring long and complex human-authored arguments on debated
topics, grounded in real-world websites, allowing an exhaustive evaluation
across retrieval effectiveness, argument quality, and groundedness. We validate
our LLM Judges on a prior dataset and the new ConQRet benchmark. Our proposed
LLM Judges and the ConQRet benchmark can enable rapid progress in computational
argumentation and can be naturally extended to other complex
retrieval-augmented generation tasks.

æè¦ï¼è¨ç®è«è­ï¼æ¶åçæç­æ¡ææè¦ï¼ä¾å¦å¢®èç¦ä»¤åç«èæ¥ç¨®ç­æç­è­°çä¸»é¡ï¼å¨ç¶ä»å©æ¥µååçç°å¢ä¸­è®å¾è¶ä¾è¶éè¦ãåé²ç LLM è½åæä¾äºééæª¢ç´¢å¢å¼·è«è­ (RAArg) çºæ­¤é¡åé¡æä¾ç´°ç·»å¥å¾®ãåºæ¼è­æçç­æ¡çæ½åï¼å©ç¨ç¾å¯¦ä¸ççè­æé²è¡é«è³ªéãææ ¹æçè«è­ãç¶èï¼è©ä¼° RAArg ä»ç¶å·æææ°æ§ï¼å çºå°æ¼è¤éãåé·çéæ¼è¤éä¸»é¡çç­æ¡ï¼äººå·¥è©ä¼°æ¢æè²´åå°é£ãèæ­¤åæï¼éè¤ä½¿ç¨ç¾æçè«è­æ¸æéä¸åè¶³å¤ ï¼å çºå®åç¼ºä¹ä¾èªæ½å¨èª¤å°ä¾æºçé·ç¯ãè¤éçè«è­åç¾å¯¦è­æï¼éå¶äºæª¢ç´¢æææ§åè«è­è³ªéçæ´é«è©ä¼°ãçºäºè§£æ±ºéäºå·®è·ï¼æåä½¿ç¨å¤åç´°ç²åº¦ç LLM è©å§ç ç©¶äºèªååè©ä¼°æ¹æ³ï¼æä¾äºæ¯å³çµ±å®åæ¸ææ¨çè³ååå ±åçäººå·¥ç¾åæ´å¥½çãæ´å·å¯è§£éæ§çè©ä¼°ãçºäºé©è­ææåºçæè¡ï¼æåå¼å¥äº ConQRetï¼éæ¯ä¸åæ°çåºæºï¼å¶ä¸­åå«å¨æç­è­°çä¸»é¡ä¸ç±äººé¡æ°å¯«çé·ç¯ä¸è¤éçè«è­ï¼åºæ¼ç¾å¯¦ä¸ççç¶²ç«ï¼åè¨±å°æª¢ç´¢æææ§ãè«è­è³ªéåä¾ææ§é²è¡å¨é¢è©ä¼°ãæåå¨ååçæ¸æéåæ°ç ConQRet åºæºä¸é©è­äºæåç LLM è©å§ãæåæåºç LLM è©å§å ConQRet åºæºå¯ä»¥ä½¿è¨ç®è«è­å¿«éé²æ­¥ï¼ä¸¦å¯ä»¥èªç¶å°æ´å±å°å¶ä»è¤éçæª¢ç´¢å¢å¼·çæä»»åã

##### **Archaeoscape: Bringing Aerial Laser Scanning Archaeology to the Deep Learning Era**
2412.05203v1 by Yohann Perron, Vladyslav Sydorov, Adam P. Wijker, Damian Evans, Christophe Pottier, Loic Landrieu

Airborne Laser Scanning (ALS) technology has transformed modern archaeology
by unveiling hidden landscapes beneath dense vegetation. However, the lack of
expert-annotated, open-access resources has hindered the analysis of ALS data
using advanced deep learning techniques. We address this limitation with
Archaeoscape (available at https://archaeoscape.ai), a novel large-scale
archaeological ALS dataset spanning 888 km$^2$ in Cambodia with 31,141
annotated archaeological features from the Angkorian period. Archaeoscape is
over four times larger than comparable datasets, and the first ALS archaeology
resource with open-access data, annotations, and models.
  We benchmark several recent segmentation models to demonstrate the benefits
of modern vision techniques for this problem and highlight the unique
challenges of discovering subtle human-made structures under dense jungle
canopies. By making Archaeoscape available in open access, we hope to bridge
the gap between traditional archaeology and modern computer vision methods.

æè¦ï¼<paragraph>æ©è¼é·å°ææï¼ALSï¼æè¡ééæ­é²èå¯æ¤è¢«ä¸çé±èæ¯è§ï¼è½è®äºç¾ä»£èå¤å­¸ãç¶èï¼ç¼ºä¹å°å®¶è¨»éãéæ¾å­åçè³æºé»ç¤äºä½¿ç¨åé²æ·±åº¦å­¸ç¿æè¡åæ ALS è³æãæåå©ç¨ Archaeoscapeï¼å¯æ¼ https://archaeoscape.ai åå¾ï¼ä¾è§£æ±ºéåéå¶ï¼éæ¯ä¸åæ°ç©çå¤§è¦æ¨¡èå¤ ALS è³æéï¼æ¶µèæ¬åå¯¨ 888 å¹³æ¹å¬éçç¯åï¼ä¸¦æ 31,141 åä¾èªå³å¥ææçèå¤ç¹å¾µè¨»éãArchaeoscape æ¯åé¡è³æéå¤§ååä»¥ä¸ï¼ä¸¦ä¸æ¯ç¬¬ä¸åå·æéæ¾å­åè³æãè¨»éåæ¨¡åç ALS èå¤è³æºã
æåå°å¹¾åæè¿çåå²æ¨¡åé²è¡åºæºæ¸¬è©¦ï¼ä»¥å±ç¤ºç¾ä»£è¦è¦ºæè¡å°æ­¤åé¡çå¥½èï¼ä¸¦å¼·èª¿å¨èå¯çå¢ææ¨¹å ä¸ç¼ç¾ç´°å¾®äººé çµæ§çç¨ç¹ææ°ãéééæ¾å­å Archaeoscapeï¼æåå¸æç¸®å°å³çµ±èå¤å­¸åç¾ä»£é»è¦è¦è¦ºæ¹æ³ä¹éçå·®è·ã</paragraph>

##### **Are Frontier Large Language Models Suitable for Q&A in Science Centres?**
2412.05200v1 by Jacob Watson, FabrÃ­cio GÃ³es, Marco Volpe, Talles Medeiros

This paper investigates the suitability of frontier Large Language Models
(LLMs) for Q&A interactions in science centres, with the aim of boosting
visitor engagement while maintaining factual accuracy. Using a dataset of
questions collected from the National Space Centre in Leicester (UK), we
evaluated responses generated by three leading models: OpenAI's GPT-4, Claude
3.5 Sonnet, and Google Gemini 1.5. Each model was prompted for both standard
and creative responses tailored to an 8-year-old audience, and these responses
were assessed by space science experts based on accuracy, engagement, clarity,
novelty, and deviation from expected answers. The results revealed a trade-off
between creativity and accuracy, with Claude outperforming GPT and Gemini in
both maintaining clarity and engaging young audiences, even when asked to
generate more creative responses. Nonetheless, experts observed that higher
novelty was generally associated with reduced factual reliability across all
models. This study highlights the potential of LLMs in educational settings,
emphasizing the need for careful prompt engineering to balance engagement with
scientific rigor.

æè¦ï¼éç¯è«ææ¢è¨åæ²¿å¤§åèªè¨æ¨¡å (LLM) å¨ç§å­¸ä¸­å¿åç­äºåä¸­çé©ç¨æ§ï¼ç®çæ¯å¨ç¶­æäºå¯¦æºç¢ºæ§çåææåè¨ªå®¢åèåº¦ãæåä½¿ç¨å¾è±åèæ¯ç¹åå®¶å¤ªç©ºä¸­å¿æ¶éçæåè³æéï¼è©ä¼°äºä¸åé åæ¨¡åçæçåæï¼OpenAI ç GPT-4ãClaude 3.5 Sonnet å Google Gemini 1.5ãæ¯åæ¨¡åé½è¢«æç¤ºéå° 8 æ­²çåç¾éèº«æé æ¨æºåæåµæçåæï¼èéäºåæåç±å¤ªç©ºç§å­¸å°å®¶æ ¹ææºç¢ºæ§ãåèåº¦ãæ¸æ°åº¦ãæ°ç©æ§åèé æç­æ¡çåå·®é²è¡è©ä¼°ãçµæé¡¯ç¤ºåµé åèæºç¢ºæ§ä¹éå­å¨æ¬è¡¡ï¼Claude å¨ç¶­ææ¸æ°åº¦åå¸å¼å¹´è¼åç¾æ¹é¢åªæ¼ GPT å Geminiï¼å³ä½¿è¢«è¦æ±ç¢çæ´å¤æåµæçåæãåç®¡å¦æ­¤ï¼å°å®¶åè§å¯å°ï¼æææ¨¡åä¸­è¼é«çæ°ç©æ§éå¸¸èè¼ä½çå¯¦éå¯é æ§ç¸éãéé ç ç©¶å¼·èª¿äº LLM å¨æè²ç°å¢ä¸­çæ½åï¼ä¸¦å¼·èª¿éè¦ä»ç´°æç¤ºå·¥ç¨ä»¥å¹³è¡¡åèåº¦åç§å­¸å´è¬¹æ§ã

##### **SurgBox: Agent-Driven Operating Room Sandbox with Surgery Copilot**
2412.05187v1 by Jinlin Wu, Xusheng Liang, Xuexue Bai, Zhen Chen

Surgical interventions, particularly in neurology, represent complex and
high-stakes scenarios that impose substantial cognitive burdens on surgical
teams. Although deliberate education and practice can enhance cognitive
capabilities, surgical training opportunities remain limited due to patient
safety concerns. To address these cognitive challenges in surgical training and
operation, we propose SurgBox, an agent-driven sandbox framework to
systematically enhance the cognitive capabilities of surgeons in immersive
surgical simulations. Specifically, our SurgBox leverages large language models
(LLMs) with tailored Retrieval-Augmented Generation (RAG) to authentically
replicate various surgical roles, enabling realistic training environments for
deliberate practice. In particular, we devise Surgery Copilot, an AI-driven
assistant to actively coordinate the surgical information stream and support
clinical decision-making, thereby diminishing the cognitive workload of
surgical teams during surgery. By incorporating a novel Long-Short Memory
mechanism, our Surgery Copilot can effectively balance immediate procedural
assistance with comprehensive surgical knowledge. Extensive experiments using
real neurosurgical procedure records validate our SurgBox framework in both
enhancing surgical cognitive capabilities and supporting clinical
decision-making. By providing an integrated solution for training and
operational support to address cognitive challenges, our SurgBox framework
advances surgical education and practice, potentially transforming surgical
outcomes and healthcare quality. The code is available at
https://github.com/franciszchen/SurgBox.

æè¦ï¼å¤ç§æè¡ï¼ç¹å¥æ¯å¨ç¥ç¶å¤ç§ï¼ä»£è¡¨äºè¤éä¸é«é¢¨éªçå ´æ¯ï¼å°å¤ç§åéæ½å äºå·¨å¤§çèªç¥è² æãåç®¡ç¶éæ·±æçæ®çæè²åå¯¦è¸å¯ä»¥å¢å¼·èªç¥è½åï¼ä½ç±æ¼æ£èå®å¨åé¡ï¼å¤ç§å¹è¨æ©æä»ç¶æéãçºäºæå°å¤ç§å¹è¨åæè¡ä¸­çéäºèªç¥ææ°ï¼æåæåºäº SurgBoxï¼ä¸åç±ä»£çé©åçæ²çæ¡æ¶ï¼ç¨æ¼ç³»çµ±å°å¢å¼·å¤ç§é«çå¨æ²æµ¸å¼å¤ç§æ¨¡æ¬ä¸­çèªç¥è½åãå·é«ä¾èªªï¼æåç SurgBox å©ç¨å¤§åèªè¨æ¨¡å (LLM) åéèº«å®å¶çæª¢ç´¢å¢å¼·çæ (RAG) ä¾çå¯¦å°è¤è£½åç¨®å¤ç§è§è²ï¼çºæ·±æçæ®çå¯¦è¸æä¾é¼ççå¹è¨ç°å¢ãç¹å¥æ¯ï¼æåè¨­è¨äºæè¡å¯é§é§ï¼ä¸åç± AI é©åçå©æï¼ç¨æ¼ä¸»ååèª¿å¤ç§ä¿¡æ¯æµä¸¦æ¯æè¨åºæ±ºç­å¶å®ï¼å¾èæ¸å°å¤ç§åéå¨æè¡æéçèªç¥è² æãééçµåä¸ç¨®æ°ç©çé·ç­æè¨æ¶æ©å¶ï¼æåç Surgery Copilot å¯ä»¥ææå°å¹³è¡¡å³æç¨åºåå©åå¨é¢çå¤ç§ç¥è­ãä½¿ç¨çå¯¦çç¥ç¶å¤ç§æè¡è¨éé²è¡çå»£æ³å¯¦é©é©è­äºæåç SurgBox æ¡æ¶ï¼æ¢è½å¢å¼·å¤ç§èªç¥è½åï¼åè½æ¯æè¨åºæ±ºç­å¶å®ãééæä¾ä¸åç¶åçå¹è¨åéçæ¯æè§£æ±ºæ¹æ¡ä¾æå°èªç¥ææ°ï¼æåç SurgBox æ¡æ¶æ¨åäºå¤ç§æè²åå¯¦è¸ï¼æå¯è½æ¹è®å¤ç§çµæåé«çä¿å¥è³ªéãä»£ç¢¼å¯å¨ https://github.com/franciszchen/SurgBox ç²å¾ã

##### **QueEn: A Large Language Model for Quechua-English Translation**
2412.05184v1 by Junhao Chen, Peng Shu, Yiwei Li, Huaqin Zhao, Hanqi Jiang, Yi Pan, Yifan Zhou, Zhengliang Liu, Lewis C Howe, Tianming Liu

Recent studies show that large language models (LLMs) are powerful tools for
working with natural language, bringing advances in many areas of computational
linguistics. However, these models face challenges when applied to low-resource
languages due to limited training data and difficulty in understanding cultural
nuances. In this paper, we propose QueEn, a novel approach for Quechua-English
translation that combines Retrieval-Augmented Generation (RAG) with
parameter-efficient fine-tuning techniques. Our method leverages external
linguistic resources through RAG and uses Low-Rank Adaptation (LoRA) for
efficient model adaptation. Experimental results show that our approach
substantially exceeds baseline models, with a BLEU score of 17.6 compared to
1.5 for standard GPT models. The integration of RAG with fine-tuning allows our
system to address the challenges of low-resource language translation while
maintaining computational efficiency. This work contributes to the broader goal
of preserving endangered languages through advanced language technologies.

æè¦ï¼æè¿çç ç©¶è¡¨æå¤§åè¯­è¨æ¨¡å (LLM) æ¯èçèªç¶èªè¨çå¼·å¤§å·¥å·ï¼çºè¨ç®èªè¨å­¸çè¨±å¤é åå¸¶ä¾é²å±ãç¶èï¼éäºæ¨¡åå¨æç¨æ¼ä½è³æºèªè¨ææé¢è¨ææ°ï¼åå æ¯è¨ç·´è³ææéï¼ä¸é£ä»¥çè§£æåå·®ç°ãå¨æ¬æä¸­ï¼æåæåº QueEnï¼éæ¯ä¸ç¨® Quechua-English ç¿»è­¯çæ°æ¹æ³ï¼å®çµåäºæª¢ç´¢å¢å¼·çæ (RAG) èåæ¸ææå¾®èª¿æè¡ãæåçæ¨¡åéé RAG å©ç¨å¤é¨èªè¨è³æºï¼ä¸¦ä½¿ç¨ä½ç§©é©æ (LoRA) é²è¡ææçæ¨¡åé©æãå¯¦é©çµæè¡¨æï¼æåçæ¨¡åå¤§å¹è¶è¶åºæºæ¨¡åï¼BLEU åæ¸çº 17.6ï¼èæ¨æº GPT æ¨¡åçº 1.5ãRAG èå¾®èª¿çæ´åä½¿æåçç³»çµ±è½å¤ è§£æ±ºä½è³æºèªè¨ç¿»è­¯çææ°ï¼åæç¶­æè¨ç®æçãéé å·¥ä½æå©æ¼ééåé²çèªè¨æè¡ä¾ä¿å­çå±èªè¨çæ´å»£æ³ç®æ¨ã

##### **Benchmarking Open-ended Audio Dialogue Understanding for Large Audio-Language Models**
2412.05167v1 by Kuofeng Gao, Shu-Tao Xia, Ke Xu, Philip Torr, Jindong Gu

Large Audio-Language Models (LALMs) have unclocked audio dialogue
capabilities, where audio dialogues are a direct exchange of spoken language
between LALMs and humans. Recent advances, such as GPT-4o, have enabled LALMs
in back-and-forth audio dialogues with humans. This progression not only
underscores the potential of LALMs but also broadens their applicability across
a wide range of practical scenarios supported by audio dialogues. However,
given these advancements, a comprehensive benchmark to evaluate the performance
of LALMs in the open-ended audio dialogue understanding remains absent
currently. To address this gap, we propose an Audio Dialogue Understanding
Benchmark (ADU-Bench), which consists of 4 benchmark datasets. They assess the
open-ended audio dialogue ability for LALMs in 3 general scenarios, 12 skills,
9 multilingual languages, and 4 categories of ambiguity handling. Notably, we
firstly propose the evaluation of ambiguity handling in audio dialogues that
expresses different intentions beyond the same literal meaning of sentences,
e.g., "Really!?" with different intonations. In summary, ADU-Bench includes
over 20,000 open-ended audio dialogues for the assessment of LALMs. Through
extensive experiments conducted on 13 LALMs, our analysis reveals that there is
still considerable room for improvement in the audio dialogue understanding
abilities of existing LALMs. In particular, they struggle with mathematical
symbols and formulas, understanding human behavior such as roleplay,
comprehending multiple languages, and handling audio dialogue ambiguities from
different phonetic elements, such as intonations, pause positions, and
homophones.

æè¦ï¼å¤§åèªè¨é³è¨æ¨¡å (LALM) å·²è§£éé³è¨å°è©±è½åï¼å¶ä¸­é³è¨å°è©±æ¯ LALM èäººé¡ä¹éå£èªçç´æ¥äº¤æµãæè¿çé²å±ï¼ä¾å¦ GPT-4oï¼å·²è® LALM è½èäººé¡é²è¡ä¾åé³è¨å°è©±ãæ­¤é²å±ä¸åå¼·èª¿ LALM çæ½åï¼ä¹æ´å±å¶å¨é³è¨å°è©±æ¯æ´çåç¨®å¯¦éå ´æ¯ä¸­çé©ç¨æ§ãç¶èï¼èééäºé²å±ï¼ç®åä»ç¼ºä¹ä¸åå¨é¢çåºæºä¾è©ä¼° LALM å¨éæ¾å¼é³è¨å°è©±çè§£ä¸­çè¡¨ç¾ãçºäºè§£æ±ºæ­¤å·®è·ï¼æåæåºä¸åé³è¨å°è©±çè§£åºæº (ADU-Bench)ï¼å¶ä¸­åå« 4 ååºæºè³æéãå®åè©ä¼° LALM å¨ 3 åä¸è¬å ´æ¯ã12 é æè½ã9 ç¨®å¤èªè¨å 4 é¡å«ç³æ§èçä¸­çéæ¾å¼é³è¨å°è©±è½åãå¼å¾æ³¨æçæ¯ï¼æåé¦åæåºè©ä¼°é³è¨å°è©±ä¸­çå«ç³æ§èçï¼å¶è¡¨éäºè¶åºå¥å­ç¸åå­é¢æç¾©çä¸åæåï¼ä¾å¦èªèª¿ä¸åçãççåï¼ããç¸½ä¹ï¼ADU-Bench åå«è¶é 20,000 åéæ¾å¼é³è¨å°è©±ï¼ç¨æ¼è©ä¼° LALMãééå° 13 å LALM é²è¡å»£æ³çå¯¦é©ï¼æåçåæé¡¯ç¤ºï¼ç¾æ LALM çé³è¨å°è©±çè§£è½åä»æå¾å¤§çæ¹é²ç©ºéãç¹å¥æ¯ï¼ä»åå¨æ¸å­¸ç¬¦èåå¬å¼ãçè§£è§è²æ®æ¼ç­äººé¡è¡çºãçè§£å¤ç¨®èªè¨ä»¥åèçä¾èªä¸åèªé³åç´ ï¼ä¾å¦èªèª¿ãåé ä½ç½®ååé³ç°ç¾©è©ï¼çé³è¨å°è©±å«ç³æ§æ¹é¢éå°äºå°é£ã

##### **DNF: Unconditional 4D Generation with Dictionary-based Neural Fields**
2412.05161v1 by Xinyi Zhang, Naiqi Li, Angela Dai

While remarkable success has been achieved through diffusion-based 3D
generative models for shapes, 4D generative modeling remains challenging due to
the complexity of object deformations over time. We propose DNF, a new 4D
representation for unconditional generative modeling that efficiently models
deformable shapes with disentangled shape and motion while capturing
high-fidelity details in the deforming objects. To achieve this, we propose a
dictionary learning approach to disentangle 4D motion from shape as neural
fields. Both shape and motion are represented as learned latent spaces, where
each deformable shape is represented by its shape and motion global latent
codes, shape-specific coefficient vectors, and shared dictionary information.
This captures both shape-specific detail and global shared information in the
learned dictionary. Our dictionary-based representation well balances fidelity,
contiguity and compression -- combined with a transformer-based diffusion
model, our method is able to generate effective, high-fidelity 4D animations.

æè¦ï¼åç®¡å¨å½¢ççåºæ¼æ´æ£ç 3D çææ¨¡åä¸­ç²å¾äºé¡¯èçæåï¼ä½ç±æ¼ç©ä»¶é¨æéè®å½¢çè¤éæ§ï¼4D çææ¨¡åä»ç¶å·æææ°æ§ãæåæåº DNFï¼éæ¯ä¸ç¨®æ°ç 4D è¡¨ç¤ºæ³ï¼ç¨æ¼ç¡æ¢ä»¶çææ¨¡åï¼è©²æ¨¡åææå°å°å¯è®å½¢å½¢çé²è¡å»ºæ¨¡ï¼åæåé¢å½¢çåéåï¼ä¸¦ææè®å½¢ç©ä»¶ä¸­çé«ä¿çç´°ç¯ãçºå¯¦ç¾æ­¤ç®çï¼æåæåºäºä¸ç¨®å­å¸å­¸ç¿æ¹æ³ï¼å° 4D éåå¾å½¢çä¸­åé¢åºä¾ï¼ä½çºç¥ç¶å ´ãå½¢çåéåé½è¡¨ç¤ºçºå­¸ç¿å°çæ½å¨ç©ºéï¼å¶ä¸­æ¯åå¯è®å½¢å½¢çç±å¶å½¢çåéåå¨å±æ½å¨ä»£ç¢¼ãç¹å®æ¼å½¢ççä¿æ¸åéåå±äº«å­å¸è³è¨è¡¨ç¤ºãéæææå­¸ç¿å°çå­å¸ä¸­çç¹å®æ¼å½¢ççç´°ç¯åå¨å±å±äº«è³è¨ãæååºæ¼å­å¸çè¡¨ç¤ºå¾å¥½å°å¹³è¡¡äºä¿çåº¦ãé£çºæ§åå£ç¸®æ§ââçµååºæ¼Transformerçæ´æ£æ¨¡åï¼æåçæ¹æ³è½å¤ çæææçé«ä¿ç 4D åç«ã

##### **Enhancing Cross-Language Code Translation via Task-Specific Embedding Alignment in Retrieval-Augmented Generation**
2412.05159v1 by Manish Bhattarai, Minh Vu, Javier E. Santos, Ismael Boureima, Daniel O' Malley

We introduce a novel method to enhance cross-language code translation from
Fortran to C++ by integrating task-specific embedding alignment into a
Retrieval-Augmented Generation (RAG) framework. Unlike conventional retrieval
approaches that utilize generic embeddings agnostic to the downstream task, our
strategy aligns the retrieval model directly with the objective of maximizing
translation quality, as quantified by the CodeBLEU metric. This alignment
ensures that the embeddings are semantically and syntactically meaningful for
the specific code translation task. Our methodology involves constructing a
dataset of 25,000 Fortran code snippets sourced from Stack-V2 dataset and
generating their corresponding C++ translations using the LLaMA 3.1-8B language
model. We compute pairwise CodeBLEU scores between the generated translations
and ground truth examples to capture fine-grained similarities. These scores
serve as supervision signals in a contrastive learning framework, where we
optimize the embedding model to retrieve Fortran-C++ pairs that are most
beneficial for improving the language model's translation performance. By
integrating these CodeBLEU-optimized embeddings into the RAG framework, our
approach significantly enhances both retrieval accuracy and code generation
quality over methods employing generic embeddings. On the HPC Fortran2C++
dataset, our method elevates the average CodeBLEU score from 0.64 to 0.73,
achieving a 14% relative improvement. On the Numerical Recipes dataset, we
observe an increase from 0.52 to 0.60, marking a 15% relative improvement.
Importantly, these gains are realized without any fine-tuning of the language
model, underscoring the efficiency and practicality of our approach.

æè¦ï¼<paragraph>æåæåºäºä¸ç¨®åµæ°çæ¹æ³ï¼ééå°ç¹å®ä»»ååµå¥å¼å°é½æ´åå°æª¢ç´¢å¢å¼·çæ (RAG) æ¶æ§ä¸­ï¼ä¾å¢å¼· Fortran å° C++ çè·¨èªè¨ç¨å¼ç¢¼ç¿»è­¯ãèå©ç¨èä¸æ¸¸ä»»åç¡éçä¸è¬åµå¥å¼çå³çµ±æª¢ç´¢æ¹æ³ä¸åï¼æåçç­ç¥ç´æ¥å°æª¢ç´¢æ¨¡åèæå¤§åç¿»è­¯åè³ªçç®æ¨å°é½ï¼ä»¥ CodeBLEU ææ¨éåãéç¨®å°é½ç¢ºä¿åµå¥å¼å°æ¼ç¹å®çç¨å¼ç¢¼ç¿»è­¯ä»»åå¨èªç¾©åèªæ³ä¸å·ææç¾©ãæåçåæ³åæ¬å»ºæ§ä¸åè³æéï¼å¶ä¸­åå«å¾ Stack-V2 è³æéåå¾ç 25,000 å Fortran ç¨å¼ç¢¼çæ®µï¼ä¸¦ä½¿ç¨ LLaMA 3.1-8B èªè¨æ¨¡åç¢çå¶å°æç C++ ç¿»è­¯ãæåè¨ç®ç¢ççç¿»è­¯èåºæ¬å¯¦ä¾ä¹éæå°ç CodeBLEU åæ¸ï¼ä»¥æ·åç´°å¾®çç¸ä¼¼æ§ãéäºåæ¸å¨å°æ¯å­¸ç¿æ¶æ§ä¸­ä½çºç£ç£è¨èï¼æåå¨å¶ä¸­æä½³ååµå¥å¼æ¨¡åï¼ä»¥æª¢ç´¢å°æ¹åèªè¨æ¨¡åç¿»è­¯æè½ææå¹«å©ç Fortran-C++ å°ãééå°éäº CodeBLEU æä½³åçåµå¥å¼æ´åå° RAG æ¶æ§ä¸­ï¼æåçæ¹æ³é¡¯èæåäºæª¢ç´¢æºç¢ºåº¦åç¨å¼ç¢¼ç¢çåè³ªï¼è¶è¶äºä½¿ç¨ä¸è¬åµå¥å¼çå¶ä»æ¹æ³ãå¨ HPC Fortran2C++ è³æéä¸ï¼æåçæ¹æ³å°å¹³å CodeBLEU åæ¸å¾ 0.64 æåå° 0.73ï¼éå°äº 14% çç¸å°æ¹åãå¨ Numerical Recipes è³æéä¸ï¼æåè§å¯å°å¾ 0.52 æåå° 0.60ï¼æ¨èªè 15% çç¸å°æ¹åãéè¦çæ¯ï¼éäºå¢çæ¯å¨æªå°èªè¨æ¨¡åé²è¡ä»»ä½å¾®èª¿çææ³ä¸å¯¦ç¾çï¼éå¸é¡¯äºæåæ¹æ³çæçåå¯¦ç¨æ§ã</paragraph>

##### **Multimodal Fact-Checking with Vision Language Models: A Probing Classifier based Solution with Embedding Strategies**
2412.05155v1 by Recep Firat Cekinel, Pinar Karagoz, Cagri Coltekin

This study evaluates the effectiveness of Vision Language Models (VLMs) in
representing and utilizing multimodal content for fact-checking. To be more
specific, we investigate whether incorporating multimodal content improves
performance compared to text-only models and how well VLMs utilize text and
image information to enhance misinformation detection. Furthermore we propose a
probing classifier based solution using VLMs. Our approach extracts embeddings
from the last hidden layer of selected VLMs and inputs them into a neural
probing classifier for multi-class veracity classification. Through a series of
experiments on two fact-checking datasets, we demonstrate that while
multimodality can enhance performance, fusing separate embeddings from text and
image encoders yielded superior results compared to using VLM embeddings.
Furthermore, the proposed neural classifier significantly outperformed KNN and
SVM baselines in leveraging extracted embeddings, highlighting its
effectiveness for multimodal fact-checking.

æè¦ï¼æ¬ç ç©¶è©ä¼°è¦è¦ºèªè¨æ¨¡å (VLM) å¨è¡¨ç¤ºåå©ç¨å¤æ¨¡æå§å®¹é²è¡äºå¯¦æ¥æ ¸æ¹é¢çæææ§ãæ´å·é«å°èªªï¼æåæ¢è¨äºèåææ¬æ¨¡åç¸æ¯ï¼æ´åå¤æ¨¡æå§å®¹æ¯å¦è½æåæè½ï¼ä»¥å VLM å¦ä½å©ç¨ææ¬åå½±åè³è¨ä¾å¼·åé¯èª¤è¨æ¯åµæ¸¬ãæ­¤å¤ï¼æåæåºä¸ååºæ¼ VLM çæ¢æ¸¬åé¡å¨è§£æ±ºæ¹æ¡ãæåçåæ³å¾é¸å®ç VLM çæå¾é±èå±¤æ·ååµå¥ï¼ä¸¦å°å¶è¼¸å¥å°ç¥ç¶æ¢æ¸¬åé¡å¨ä¸­é²è¡å¤é¡çå¯¦æ§åé¡ãééå°å©åäºå¯¦æ¥æ ¸è³æéé²è¡ä¸ç³»åå¯¦é©ï¼æåè­æéç¶å¤æ¨¡æå¯ä»¥æåæè½ï¼ä½èä½¿ç¨ VLM åµå¥ç¸æ¯ï¼èåä¾èªææ¬åå½±åç·¨ç¢¼å¨çç¨ç«åµå¥ç¢çäºæ´åªç°ççµæãæ­¤å¤ï¼ææåºçç¥ç¶åé¡å¨å¨å©ç¨æåçåµå¥æ¹é¢æé¡¯åªæ¼ KNN å SVM åºæºï¼çªé¡¯äºå¶å°å¤æ¨¡æäºå¯¦æ¥æ ¸çæææ§ã

##### **Navigating Shortcuts, Spurious Correlations, and Confounders: From Origins via Detection to Mitigation**
2412.05152v1 by David Steinmann, Felix Divo, Maurice Kraus, Antonia WÃ¼st, Lukas Struppek, Felix Friedrich, Kristian Kersting

Shortcuts, also described as Clever Hans behavior, spurious correlations, or
confounders, present a significant challenge in machine learning and AI,
critically affecting model generalization and robustness. Research in this
area, however, remains fragmented across various terminologies, hindering the
progress of the field as a whole. Consequently, we introduce a unifying
taxonomy of shortcut learning by providing a formal definition of shortcuts and
bridging the diverse terms used in the literature. In doing so, we further
establish important connections between shortcuts and related fields, including
bias, causality, and security, where parallels exist but are rarely discussed.
Our taxonomy organizes existing approaches for shortcut detection and
mitigation, providing a comprehensive overview of the current state of the
field and revealing underexplored areas and open challenges. Moreover, we
compile and classify datasets tailored to study shortcut learning. Altogether,
this work provides a holistic perspective to deepen understanding and drive the
development of more effective strategies for addressing shortcuts in machine
learning.

æè¦ï¼æ·å¾ï¼ä¹ç¨±çºåèä½æ¼¢æ¯è¡çºãèåç¸éææ··æ·å å­ï¼å¨æ©å¨å­¸ç¿åäººå·¥æºæ§ä¸­æ§æéå¤§ææ°ï¼å´éå½±é¿æ¨¡åçæ¦ååå¥å¨æ§ãç¶èï¼éæ¹é¢çç ç©¶ä»å åç¨®è¡èªèæ¯é¢ç ´ç¢ï¼é»ç¤äºæ´åé åçé²å±ãå æ­¤ï¼æåééæä¾æ·å¾çæ­£å¼å®ç¾©ï¼ä¸¦é£çµæç»ä¸­ä½¿ç¨çåç¨®è¡èªï¼ä¾å¼å¥æ·å¾å­¸ç¿ççµ±ä¸åé¡æ³ãå¨éæ¨£åçéç¨ä¸­ï¼æåé²ä¸æ­¥å»ºç«äºæ·å¾èç¸éé åä¹éçéè¦éè¯ï¼åæ¬åå·®ãå æéä¿åå®å¨æ§ï¼éäºé åå­å¨ç¸ä¼¼ä¹èï¼ä½å¾å°è¢«è¨è«ãæåçåé¡æ³çµç¹äºç¾æçæ·å¾åµæ¸¬åç·©è§£æ¹æ³ï¼æä¾äºè©²é åç¶åçæçå¨é¢æ¦è¿°ï¼ä¸¦æ­ç¤ºäºæªååæ¢è¨çé ååæªè§£æ±ºçææ°ãæ­¤å¤ï¼æåç·¨å¶ä¸¦åé¡äºå°éç¨æ¼ç ç©¶æ·å¾å­¸ç¿çè³æéãç¸½ä¹ï¼éé å·¥ä½æä¾äºæ´é«è§é»ï¼ä»¥å æ·±çè§£ï¼ä¸¦æ¨åå¶å®æ´ææçç­ç¥ä¾è§£æ±ºæ©å¨å­¸ç¿ä¸­çæ·å¾ã

##### **Findings of the Second BabyLM Challenge: Sample-Efficient Pretraining on Developmentally Plausible Corpora**
2412.05149v1 by Michael Y. Hu, Aaron Mueller, Candace Ross, Adina Williams, Tal Linzen, Chengxu Zhuang, Ryan Cotterell, Leshem Choshen, Alex Warstadt, Ethan Gotlieb Wilcox

The BabyLM Challenge is a community effort to close the data-efficiency gap
between human and computational language learners. Participants compete to
optimize language model training on a fixed language data budget of 100 million
words or less. This year, we released improved text corpora, as well as a
vision-and-language corpus to facilitate research into cognitively plausible
vision language models. Submissions were compared on evaluation tasks targeting
grammatical ability, (visual) question answering, pragmatic abilities, and
grounding, among other abilities. Participants could submit to a 10M-word
text-only track, a 100M-word text-only track, and/or a 100M-word and image
multimodal track. From 31 submissions employing diverse methods, a hybrid
causal-masked language model architecture outperformed other approaches. No
submissions outperformed the baselines in the multimodal track. In follow-up
analyses, we found a strong relationship between training FLOPs and average
performance across tasks, and that the best-performing submissions proposed
changes to the training data, training objective, and model architecture. This
year's BabyLM Challenge shows that there is still significant room for
innovation in this setting, in particular for image-text modeling, but
community-driven research can yield actionable insights about effective
strategies for small-scale language modeling.

æè¦ï¼BabyLM ææ°è³½æ¯ç¤¾ç¾¤çå±ååªåï¼æ¨å¨ç¸®å°äººé¡åè¨ç®èªè¨å­¸ç¿èä¹éçè³ææçå·®è·ãåèèç«¶ç¸å¨åºå®çº 1 ååå­ææ´å°çèªè¨è³æé ç®ä¸­ï¼æä½³åèªè¨æ¨¡åè¨ç·´ãä»å¹´ï¼æåç¼å¸äºæ¹è¯çæå­èªæåº«ï¼ä»¥åä¸åè¦è¦ºèèªè¨èªæåº«ï¼ä»¥ä¿é²å°èªç¥ä¸åççè¦è¦ºèªè¨æ¨¡åçç ç©¶ãæäº¤çä½åå¨è©éä»»åä¸­é²è¡æ¯è¼ï¼éäºä»»åéå°èªæ³è½åãï¼è¦è¦ºï¼åé¡è§£ç­ãèªç¨è½åååºç¤ç­åç¨®è½åãåèèå¯ä»¥æäº¤å°åéæå­ç 10M å­çµãåéæå­ç 100M å­çµï¼å/æ 100M å­åååçå¤æ¨¡çµçµãå¨æ¡ç¨åç¨®æ¹æ³ç 31 é æäº¤ä¸­ï¼ä¸åæ··åå æé®ç½©èªè¨æ¨¡åæ¶æ§åªæ¼å¶ä»æ¹æ³ãå¨å¤æ¨¡çµçµä¸­ï¼æ²ææäº¤çä½ååªæ¼åºæºãå¨å¾çºåæä¸­ï¼æåç¼ç¾è¨ç·´ FLOP ååé ä»»åçå¹³åè¡¨ç¾ä¹éæå¾å¼·çéä¿ï¼ä¸¦ä¸è¡¨ç¾æä½³çæäº¤ä½åæåºäºè¨ç·´è³æãè¨ç·´ç®æ¨åæ¨¡åæ¶æ§çè®æ´ãä»å¹´ç BabyLM ææ°è³½é¡¯ç¤ºï¼å¨éåè¨­å®ä¸­ä»ç¶æå¾å¤§çåµæ°ç©ºéï¼ç¹å¥æ¯å°æ¼å½±åæå­å»ºæ¨¡ï¼ä½ç¤¾ç¾¤é©åçç ç©¶å¯ä»¥ç¢çéæ¼å°è¦æ¨¡èªè¨å»ºæ¨¡çææç­ç¥çå¯è¡è¦è§£ã

##### **LoRA.rar: Learning to Merge LoRAs via Hypernetworks for Subject-Style Conditioned Image Generation**
2412.05148v1 by Donald Shenaj, Ondrej Bohdal, Mete Ozay, Pietro Zanuttigh, Umberto Michieli

Recent advancements in image generation models have enabled personalized
image creation with both user-defined subjects (content) and styles. Prior
works achieved personalization by merging corresponding low-rank adaptation
parameters (LoRAs) through optimization-based methods, which are
computationally demanding and unsuitable for real-time use on
resource-constrained devices like smartphones. To address this, we introduce
LoRA.rar, a method that not only improves image quality but also achieves a
remarkable speedup of over $4000\times$ in the merging process. LoRA.rar
pre-trains a hypernetwork on a diverse set of content-style LoRA pairs,
learning an efficient merging strategy that generalizes to new, unseen
content-style pairs, enabling fast, high-quality personalization. Moreover, we
identify limitations in existing evaluation metrics for content-style quality
and propose a new protocol using multimodal large language models (MLLM) for
more accurate assessment. Our method significantly outperforms the current
state of the art in both content and style fidelity, as validated by MLLM
assessments and human evaluations.

æè¦ï¼æè¿å½±åçææ¨¡åçé²å±ï¼ä½¿å¾åäººåå½±ååµä½æçºå¯è½ï¼ä¸åæå·åä½¿ç¨èå®ç¾©çä¸»é¡ï¼å§å®¹ï¼åé¢¨æ ¼ãååçä½åééæä½³åæ¹æ³åä½µå°æçä½éé©æåæ¸ï¼LoRAï¼ï¼éæåäººåï¼éå¨è¨ç®ä¸éè¦å¤§éçéæ±ï¼ä¸ä¸é©åå¨æºæ§åææ©ç­è³æºåéçè£ç½®ä¸å³æä½¿ç¨ãçºäºè§£æ±ºéååé¡ï¼æåå¼å¥äº LoRA.rarï¼éæ¯ä¸ç¨®ä¸åæ¹åå½±ååè³ªï¼ä¸å¨åä½µéç¨ä¸­ï¼éåº¦æåè¶é 4000 åçæ¹æ³ãLoRA.rar å¨åç¨®å§å®¹é¢¨æ ¼ç LoRA éå°ä¸é åè¨ç·´äºä¸åè¶ç¶²è·¯ï¼å­¸ç¿ä¸ç¨®ææççåä½µç­ç¥ï¼éåç­ç¥å¯ä»¥æ¨å»£å°æ°çãæªè¦éçå§å®¹é¢¨æ ¼éå°ï¼é²èå¯¦ç¾å¿«éãé«åè³ªçåäººåãæ­¤å¤ï¼æåæ¾åºç¾æå§å®¹é¢¨æ ¼åè³ªè©ä¼°ææ¨çéå¶ï¼ä¸¦æåºä¸åæ°çåå®ï¼ä½¿ç¨å¤æ¨¡æå¤§åèªè¨æ¨¡åï¼MLLMï¼é²è¡æ´æºç¢ºçè©ä¼°ãæåçæ¨¡åå¨å§å®¹åé¢¨æ ¼çå¿ å¯¦åº¦ä¸ï¼æé¡¯åªæ¼ç®åæåé²çæè¡ï¼éç¶ç± MLLM è©ä¼°åäººé¡è©ä¼°é©è­ã

##### **Explingo: Explaining AI Predictions using Large Language Models**
2412.05145v1 by Alexandra Zytek, Sara Pido, Sarah Alnegheimish, Laure Berti-Equille, Kalyan Veeramachaneni

Explanations of machine learning (ML) model predictions generated by
Explainable AI (XAI) techniques such as SHAP are essential for people using ML
outputs for decision-making. We explore the potential of Large Language Models
(LLMs) to transform these explanations into human-readable, narrative formats
that align with natural communication. We address two key research questions:
(1) Can LLMs reliably transform traditional explanations into high-quality
narratives? and (2) How can we effectively evaluate the quality of narrative
explanations? To answer these questions, we introduce Explingo, which consists
of two LLM-based subsystems, a Narrator and Grader. The Narrator takes in ML
explanations and transforms them into natural-language descriptions. The Grader
scores these narratives on a set of metrics including accuracy, completeness,
fluency, and conciseness.
  Our experiments demonstrate that LLMs can generate high-quality narratives
that achieve high scores across all metrics, particularly when guided by a
small number of human-labeled and bootstrapped examples. We also identified
areas that remain challenging, in particular for effectively scoring narratives
in complex domains. The findings from this work have been integrated into an
open-source tool that makes narrative explanations available for further
applications.

æè¦ï¼æ©å¨å­¸ç¿ (ML) æ¨¡åé æ¸¬çèªªæç±å¯è§£é AI (XAI) æè¡ (ä¾å¦ SHAP) ç¢çï¼å°æ¼ä½¿ç¨ ML è¼¸åºé²è¡æ±ºç­çäººä¾èªªè³ééè¦ãæåæ¢ç´¢å¤§åèªè¨æ¨¡å (LLM) çæ½åï¼å°éäºèªªæè½æçºèèªç¶æºéä¸è´çäººé¡å¯è®æäºæ ¼å¼ãæåè§£æ±ºäºå©åééµçç ç©¶åé¡ï¼(1) LLM è½å¦å¯é å°å°å³çµ±èªªæè½æçºé«è³ªéçæäºï¼(2) æåå¦ä½ææè©ä¼°æäºèªªæçåè³ªï¼çºäºåç­éäºåé¡ï¼æåå¼å¥äº Explingoï¼å®åå«å©ååºæ¼ LLM çå­ç³»çµ±ï¼ä¸åæè¿°èåä¸åè©åèãæè¿°èæ¥å ML èªªæï¼ä¸¦å°å®åè½æçºèªç¶èªè¨æè¿°ãè©åèæ ¹ææºç¢ºæ§ãå®æ´æ§ãæµæ¢æ§åç°¡æ½æ§ç­ä¸ç³»åææ¨å°éäºæäºé²è¡è©åãæåçå¯¦é©è¡¨æï¼LLM å¯ä»¥çæé«è³ªéçæäºï¼å¨ææææ¨ä¸é½è½ç²å¾é«åï¼ç¹å¥æ¯å¨å°éäººå·¥æ¨è¨åå¼å°å¼ç¯ä¾çæå°ä¸ãæåéç¼ç¾äºä»ç¶å·æææ°æ§çé åï¼ç¹å¥æ¯å¨è¤éé åä¸­ææè©åæäºãéé å·¥ä½çç¼ç¾å·²æ´åå°ä¸åéæºå·¥å·ä¸­ï¼è©²å·¥å·ä½¿æäºèªªæå¯ä¾é²ä¸æ­¥æç¨ã

##### **A Practical Examination of AI-Generated Text Detectors for Large Language Models**
2412.05139v1 by Brian Tufts, Xuandong Zhao, Lei Li

The proliferation of large language models has raised growing concerns about
their misuse, particularly in cases where AI-generated text is falsely
attributed to human authors. Machine-generated content detectors claim to
effectively identify such text under various conditions and from any language
model. This paper critically evaluates these claims by assessing several
popular detectors (RADAR, Wild, T5Sentinel, Fast-DetectGPT, GPTID, LogRank,
Binoculars) on a range of domains, datasets, and models that these detectors
have not previously encountered. We employ various prompting strategies to
simulate adversarial attacks, demonstrating that even moderate efforts can
significantly evade detection. We emphasize the importance of the true positive
rate at a specific false positive rate (TPR@FPR) metric and demonstrate that
these detectors perform poorly in certain settings, with TPR@.01 as low as 0\%.
Our findings suggest that both trained and zero-shot detectors struggle to
maintain high sensitivity while achieving a reasonable true positive rate.

æè¦ï¼å¤§åèªè¨æ¨¡åçæ´æ£å¼èµ·äºäººåå°å¶è¢«æ¿«ç¨çææï¼ç¹å¥æ¯å¨å° AI çæçæå­é¯èª¤å°æ­¸å æ¼äººé¡ä½èçææ³ä¸ãæ©å¨çæçå§å®¹æª¢æ¸¬å¨è²ç¨±å¯ä»¥ææè­å¥å¨åç¨®æ¢ä»¶ä¸åä¾èªä»»ä½èªè¨æ¨¡åçæ­¤é¡æå­ãæ¬æééè©ä¼°å¹¾åæµè¡çæª¢æ¸¬å¨ï¼RADARãWildãT5SentinelãFast-DetectGPTãGPTIDãLogRankãBinocularsï¼å°éäºæª¢æ¸¬å¨ä»¥åæªéå°çåç¨®é åãæ¸æéåæ¨¡åï¼ä¾æ¹å¤æ§å°è©ä¼°éäºè²æãæåæ¡ç¨åç¨®æç¤ºç­ç¥ä¾æ¨¡æ¬å°ææ§æ»æï¼è­æå³ä½¿æ¯é©åº¦çåªåä¹å¯ä»¥é¡¯èéé¿æª¢æ¸¬ãæåå¼·èª¿ç¹å®èåæ­£çï¼TPR@FPRï¼ææ¨ççæ­£æ­£ççéè¦æ§ï¼ä¸¦è­æéäºæª¢æ¸¬å¨å¨æäºè¨­ç½®ä¸­è¡¨ç¾ä¸ä½³ï¼TPR@.01 ä½è³ 0%ãæåçç ç©¶çµæè¡¨æï¼è¨ç·´æç´ çåé¶æ¬¡å­¸ç¿çæª¢æ¸¬å¨å¨å¯¦ç¾åçççæ­£æ­£ççåæï¼é½é£ä»¥ç¶­æé«éæåº¦ã

##### **Can Large Language Models Serve as Effective Classifiers for Hierarchical Multi-Label Classification of Scientific Documents at Industrial Scale?**
2412.05137v1 by Seyed Amin Tabatabaei, Sarah Fancher, Michael Parsons, Arian Askari

We address the task of hierarchical multi-label classification (HMC) of
scientific documents at an industrial scale, where hundreds of thousands of
documents must be classified across thousands of dynamic labels. The rapid
growth of scientific publications necessitates scalable and efficient methods
for classification, further complicated by the evolving nature of
taxonomies--where new categories are introduced, existing ones are merged, and
outdated ones are deprecated. Traditional machine learning approaches, which
require costly retraining with each taxonomy update, become impractical due to
the high overhead of labelled data collection and model adaptation. Large
Language Models (LLMs) have demonstrated great potential in complex tasks such
as multi-label classification. However, applying them to large and dynamic
taxonomies presents unique challenges as the vast number of labels can exceed
LLMs' input limits. In this paper, we present novel methods that combine the
strengths of LLMs with dense retrieval techniques to overcome these challenges.
Our approach avoids retraining by leveraging zero-shot HMC for real-time label
assignment. We evaluate the effectiveness of our methods on SSRN, a large
repository of preprints spanning multiple disciplines, and demonstrate
significant improvements in both classification accuracy and cost-efficiency.
By developing a tailored evaluation framework for dynamic taxonomies and
publicly releasing our code, this research provides critical insights into
applying LLMs for document classification, where the number of classes
corresponds to the number of nodes in a large taxonomy, at an industrial scale.

æè¦ï¼<paragraph>æåä»¥ç¢æ¥­è¦æ¨¡èçç§å­¸æç»çåå±¤å¤æ¨ç±¤åé¡ (HMC) ä»»åï¼å¶ä¸­æ¸åè¬ä»½æä»¶å¿é å¨æ¸åååææ¨ç±¤ä¸­é²è¡åé¡ãç§å­¸åºçç©çå¿«éå¢é·éè¦å¯æ´åä¸ææççåé¡æ¹æ³ï¼èåé¡æ³ä¸æ·æ¼è®çæ¬è³ªé²ä¸æ­¥è¤éåäºéåä»»åï¼ä¹å°±æ¯æ°é¡å¥æè¢«å¼å¥ãç¾æé¡å¥æåä½µï¼èéæçé¡å¥åæè¢«æ£ç¨ãå³çµ±æ©å¨å­¸ç¿æ¹æ³éè¦å¨æ¯æ¬¡åé¡æ³æ´æ°æé²è¡æè²´çéæ°è¨ç·´ï¼ç±æ¼æ¨ç±¤è³ææ¶éåæ¨¡åèª¿æ´çéé·å¾å¤§ï¼å æ­¤è®å¾ä¸åå¯¦éãå¤§åèªè¨æ¨¡å (LLM) å·²å¨å¤æ¨ç±¤åé¡ç­è¤éä»»åä¸­å±ç¾åºå·¨å¤§çæ½åãç¶èï¼å°å®åæç¨æ¼å¤§åä¸åæçåé¡æ³æç¢çç¨ç¹çææ°ï¼å çºæ¨ç±¤çé¾å¤§æ¸éå¯è½æè¶é LLM çè¼¸å¥éå¶ãå¨æ¬æä¸­ï¼æåæåºäºæ°ç©çæ¹æ³ï¼çµå LLM çåªå¢åå¯éæª¢ç´¢æè¡ä¾åæéäºææ°ãæåçåæ³ééå©ç¨é¶æ¬¡å­¸ç¿ HMC ä¾é¿åéæ°è¨ç·´ï¼ä»¥é²è¡å³ææ¨ç±¤ææ´¾ãæåå¨ SSRNï¼ä¸åè·¨è¶å¤åå­¸ç§çå¤§åé å°æ¬è³æåº«ï¼ä¸è©ä¼°äºæåæ¹æ³çæææ§ï¼ä¸¦è­æäºåé¡æºç¢ºæ§åææ¬æçé½æé¡¯èçæåãééçºåæåé¡æ³éç¼ä¸åéèº«æé çè©ä¼°æ¶æ§ï¼ä¸¦å¬éç¼å¸æåçç¨å¼ç¢¼ï¼éé ç ç©¶æä¾äºééµè¦è§£ï¼èªªæå¦ä½å° LLM æç¨æ¼æä»¶åé¡ï¼å¶ä¸­é¡å¥æ¸éå°ææ¼å¤§ååé¡æ³ä¸­ç¯é»çæ¸éï¼ä¸¦ä»¥ç¢æ¥­è¦æ¨¡é²è¡ã</paragraph>

##### **Technology as uncharted territory: Contextual integrity and the notion of AI as new ethical ground**
2412.05130v1 by Alexander Martin Mussgnug

Recent research illustrates how AI can be developed and deployed in a manner
detached from the concrete social context of application. By abstracting from
the contexts of AI application, practitioners also disengage from the distinct
normative structures that govern them. Building upon Helen Nissenbaum's
framework of contextual integrity, I illustrate how disregard for contextual
norms can threaten the integrity of a context with often decisive ethical
implications. I argue that efforts to promote responsible and ethical AI can
inadvertently contribute to and seemingly legitimize this disregard for
established contextual norms. Echoing a persistent undercurrent in technology
ethics of understanding emerging technologies as uncharted moral territory,
certain approaches to AI ethics can promote a notion of AI as a novel and
distinct realm for ethical deliberation, norm setting, and virtue cultivation.
This narrative of AI as new ethical ground, however, can come at the expense of
practitioners, policymakers and ethicists engaging with already established
norms and virtues that were gradually cultivated to promote successful and
responsible practice within concrete social contexts. In response, I question
the current narrow prioritization in AI ethics of moral innovation over moral
preservation. Engaging also with emerging foundation models, I advocate for a
moderately conservative approach to the ethics of AI that prioritizes the
responsible and considered integration of AI within established social contexts
and their respective normative structures.

æè¦ï¼æè¿çç ç©¶è¯´æäºå¦ä½ä»¥è±ç¦»æç¨å·é«ç¤¾æèæ¯çæ¹å¼éç¼åé¨ç½² AIãééå¾ AI æç¨çèæ¯ä¸­æ½è±¡åºä¾ï¼å¾æ¥­äººå¡ä¹æºè«äºè¦ç¯å®åçä¸åè¦ç¯çµæ§ãå»ºç«å¨ Helen Nissenbaum çèçµ¡å®æ´æ§æ¡æ¶ä¹ä¸ï¼æèªªæäºå°èçµ¡è¦ç¯çä¸éè¦å¦ä½å¨èå°èçµ¡çå®æ´æ§ï¼ä¸¦å¸¸å¸¸é ææ±ºå®æ§çå«çå½±é¿ãæä¸»å¼µï¼ä¿é²è² è²¬ä»»åå«ç AI çåªåå¯è½æç¡æéå©é·ä¸¦çä¼¼ä½¿éç¨®å°æ¢å®èçµ¡è¦ç¯çä¸éè¦åæ³åãå¼ææè¡å«çä¸­å°æ°èæè¡çè§£çºæªæ¢ç´¢éå¾·é åçæçºææµï¼æäº AI å«çæ¹æ³å¯è½æä¿é²ä¸ç¨®è§å¿µï¼å³ AI æ¯å«çå¯©è­°ãè¦ç¯è¨­å®åç¾å¾·å¹é¤çä¸åæ°ç©ä¸ç¨ç¹çé åãç¶èï¼å° AI è¦çºæ°çå«çåºç¤çéç¨®æè¿°å¯è½æç§ç²å¾æ¥­äººå¡ãæ¿ç­å¶å®èåå«çå­¸å®¶èæ¢å®è¦ç¯åç¾å¾·æ¥è§¸çæ©æï¼èéäºè¦ç¯åç¾å¾·æ¯éæ¼¸å¹é¤åºä¾çï¼ç®çæ¯å¨å·é«çç¤¾æèæ¯ä¸­ä¿é²æåä¸è² è²¬ä»»çå¯¦åãä½çºåæï¼æè³ªç AI å«çä¸­ç®åå°éå¾·åµæ°é«æ¼éå¾·ä¿å­çç¹éåªåé åºãæä¹æ¥è§¸æ°èåºç¤æ¨¡åï¼ä¸»å¼µæ¡åé©åº¦ä¿å®çæ¹æ³ä¾èç AI å«çï¼éç¨®æ¹æ³å° AI è² è²¬ä»»ä¸ç¶éæ·±æçæ®çæ´åä½çºåªåèéï¼æ´åå¨æ¢å®çç¤¾æèæ¯åå¶åèªçè¦ç¯çµæ§ä¸­ã

##### **The Prompt Canvas: A Literature-Based Practitioner Guide for Creating Effective Prompts in Large Language Models**
2412.05127v1 by Michael Hewing, Vincent Leinhos

The rise of large language models (LLMs) has highlighted the importance of
prompt engineering as a crucial technique for optimizing model outputs. While
experimentation with various prompting methods, such as Few-shot,
Chain-of-Thought, and role-based techniques, has yielded promising results,
these advancements remain fragmented across academic papers, blog posts and
anecdotal experimentation. The lack of a single, unified resource to
consolidate the field's knowledge impedes the progress of both research and
practical application. This paper argues for the creation of an overarching
framework that synthesizes existing methodologies into a cohesive overview for
practitioners. Using a design-based research approach, we present the Prompt
Canvas, a structured framework resulting from an extensive literature review on
prompt engineering that captures current knowledge and expertise. By combining
the conceptual foundations and practical strategies identified in prompt
engineering, the Prompt Canvas provides a practical approach for leveraging the
potential of Large Language Models. It is primarily designed as a learning
resource for pupils, students and employees, offering a structured introduction
to prompt engineering. This work aims to contribute to the growing discourse on
prompt engineering by establishing a unified methodology for researchers and
providing guidance for practitioners.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çèèµ·å¸é¡¯äºæç¤ºå·¥ç¨ä½çºåªåæ¨¡åè¼¸åºçééµæè¡çéè¦æ§ãéç¶å°åç¨®æç¤ºæ¹æ³ï¼ä¾å¦å°æ¨£æ¬ãæç¶­éååºæ¼è§è²çæè¡ï¼çå¯¦é©å·²ç¶ç¢çäºæå¸æççµæï¼ä½éäºé²å±ä»ç¶åæ£å¨å­¸è¡è«æãé¨è½æ ¼æç« åè»¼äºå¯¦é©ä¸­ãç¼ºä¹å®ä¸ãçµ±ä¸çè³æºä¾æ´åè©²é åçç¥è­ï¼é»ç¤äºç ç©¶åå¯¦éæç¨çé²å±ãæ¬æä¸»å¼µå»ºç«ä¸åç¸½æ¬æ§çæ¡æ¶ï¼å°ç¾ææ¹æ³ç¶åæä¸åé£è²«çæ¦è§ï¼ä¾å¾æ¥­èä½¿ç¨ãæåä½¿ç¨åºæ¼è¨­è¨çç ç©¶æ¹æ³ï¼æåºäºæç¤ºç«å¸ï¼éæ¯ä¸åçµæ§åçæ¡æ¶ï¼æºèªå°æç¤ºå·¥ç¨çå»£æ³æç»åé¡§ï¼ææäºç¶åçç¥è­åå°æ¥­ç¥è­ãééçµåå¨æç¤ºå·¥ç¨ä¸­ç¢ºå®çæ¦å¿µåºç¤åå¯¦ç¨ç­ç¥ï¼æç¤ºç«å¸æä¾äºä¸ç¨®å¯¦ç¨çæ¹æ³ä¾å©ç¨å¤§åèªè¨æ¨¡åçæ½åãå®ä¸»è¦è¨­è¨çºå­¸çåå¡å·¥çå­¸ç¿è³æºï¼æä¾æç¤ºå·¥ç¨ççµæ§åä»ç´¹ãéé å·¥ä½æ¨å¨ééçºç ç©¶äººå¡å»ºç«çµ±ä¸çæ¹æ³è«ä¸¦çºå¾æ¥­èæä¾æå°ï¼çºæç¤ºå·¥ç¨çè¨è«ååºè²¢ç»ã

##### **A*Net and NBFNet Learn Negative Patterns on Knowledge Graphs**
2412.05114v1 by Patrick Betz, Nathanael Stelzner, Christian Meilicke, Heiner Stuckenschmidt, Christian Bartelt

In this technical report, we investigate the predictive performance
differences of a rule-based approach and the GNN architectures NBFNet and A*Net
with respect to knowledge graph completion. For the two most common benchmarks,
we find that a substantial fraction of the performance difference can be
explained by one unique negative pattern on each dataset that is hidden from
the rule-based approach. Our findings add a unique perspective on the
performance difference of different model classes for knowledge graph
completion: Models can achieve a predictive performance advantage by penalizing
scores of incorrect facts opposed to providing high scores for correct facts.

æè¦ï¼å¨æè¡å ±åä¸­ï¼æåç ç©¶åºæ¼è¦åçæ¹æ³å GNN æ¶æ§ NBFNet å A*Net å¨ç¥è­åè­è£å¨æ¹é¢çé æ¸¬æè½å·®ç°ãå°æ¼å©åæå¸¸è¦çåºæºï¼æåç¼ç¾æè½å·®ç°çå¾å¤§ä¸é¨åå¯ä»¥ç¨æ¯åè³æéä¸ä¸åç¨ç¹çè² é¢æ¨¡å¼ä¾è§£éï¼èåºæ¼è¦åçæ¹æ³ç¡æ³å¾ç¥ãæåçç¼ç¾çºç¥è­åè­è£å¨ä¸­ä¸åæ¨¡åé¡å¥çæè½å·®ç°æä¾äºä¸åç¨ç¹çè§é»ï¼æ¨¡åå¯ä»¥ééæ²ç½°ä¸æ­£ç¢ºäºå¯¦çåæ¸ï¼èä¸æ¯çºæ­£ç¢ºäºå¯¦æä¾é«åï¼ä¾ç²å¾é æ¸¬æè½åªå¢ã

##### **Modeling Task Immersion based on Goal Activation Mechanism**
2412.05112v1 by Kazuma Nagashima, Jumpei Nishikawa, Junya Morita

Immersion in a task is a prerequisite for creativity. However, excessive
arousal in a single task has drawbacks, such as overlooking events outside of
the task. To examine such a negative aspect, this study constructs a
computational model of arousal dynamics where the excessively increased arousal
makes the task transition difficult. The model was developed using functions
integrated into the cognitive architecture Adaptive Control of Thought-Rational
(ACT-R). Under the framework, arousal is treated as a coefficient affecting the
overall activation level in the model. In our simulations, we set up two
conditions demanding low and high arousal, trying to replicate corresponding
human experiments. In each simulation condition, two sets of ACT-R parameters
were assumed from the different interpretations of the human experimental
settings. The results showed consistency of behavior between humans and models
both in the two different simulation settings. This result suggests the
validity of our assumptions and has implications of controlling arousal in our
daily life.

æè¦ï¼æ²æµ¸å¨ä»»åä¸­æ¯åµé åçåæ±ºæ¢ä»¶ãç¶èï¼éåº¦æ¿ç¼å¨å®ä¸ä»»åä¸­å·æç¼ºé»ï¼ä¾å¦å¿½è¦ä»»åä¹å¤çäºä»¶ãçºäºæª¢é©éç¨®è² é¢æ¹é¢ï¼æ¬ç ç©¶æ§å»ºäºä¸åæ¿ç¼åæçè¨ç®æ¨¡åï¼å¶ä¸­éåº¦å¢å çæ¿ç¼ä½¿å¾ä»»åè½æè®å¾å°é£ãè©²æ¨¡åæ¯ä½¿ç¨æ´åå°èªç¥æ¶æ§é©ææ§ææ³æ§å¶çæ§ (ACT-R) ä¸­çåè½éç¼çãå¨è©²æ¡æ¶ä¸ï¼æ¿ç¼è¢«è¦çºå½±é¿æ¨¡åä¸­æ´é«æ¿æ´»ç´æ¸çä¿æ¸ãå¨æåçæ¨¡æ¬ä¸­ï¼æåè¨­å®äºå©åéè¦ä½æ¿ç¼åé«æ¿ç¼çæ¢ä»¶ï¼è©¦åè¤è£½ç¸æçäººé«å¯¦é©ãå¨æ¯åæ¨¡æ¬æ¢ä»¶ä¸­ï¼æ ¹æå°äººé«å¯¦é©è¨­ç½®çä¸åè§£éï¼åè¨­äºå©çµ ACT-R åæ¸ãçµæè¡¨æï¼å¨å©ç¨®ä¸åçæ¨¡æ¬è¨­ç½®ä¸­ï¼äººé¡åæ¨¡åä¹éçè¡çºä¸è´ãéä¸çµæè¡¨æäºæåçåè¨­çæææ§ï¼ä¸¦å°æåæ¥å¸¸çæ´»ä¸­çæ¿ç¼æ§å¶ç¢çäºå½±é¿ã

##### **From Defects to Demands: A Unified, Iterative, and Heuristically Guided LLM-Based Framework for Automated Software Repair and Requirement Realization**
2412.05098v1 by Alex, Liu, Vivian, Chi

This manuscript signals a new era in the integration of artificial
intelligence with software engineering, placing machines at the pinnacle of
coding capability. We present a formalized, iterative methodology proving that
AI can fully replace human programmers in all aspects of code creation and
refinement. Our approach, combining large language models with formal
verification, test-driven development, and incremental architectural guidance,
achieves a 38.6% improvement over the current top performer's 48.33% accuracy
on the SWE-bench benchmark. This surpasses previously assumed limits, signaling
the end of human-exclusive coding and the rise of autonomous AI-driven software
innovation. More than a technical advance, our work challenges centuries-old
assumptions about human creativity. We provide robust evidence of AI
superiority, demonstrating tangible gains in practical engineering contexts and
laying the foundation for a future in which computational creativity outpaces
human ingenuity.

æè¦ï¼éä»½æç¨¿æ¨èªèäººå·¥æºæ§èè»é«å·¥ç¨æ´åçæ°æä»£ï¼è®æ©å¨å¨ç·¨ç¢¼è½åä¸éå°é å³°ãæåæåºä¸åå½¢å¼åãåè¦éç®çæ¹æ³ï¼è­æäººå·¥æºæ§å¯ä»¥å¨ç¨å¼ç¢¼å»ºç«ååªåçæææ¹é¢å®å¨åä»£äººé¡ç¨å¼è¨­è¨å¸«ãæåçåæ³çµåäºå¤§åèªè¨æ¨¡åãå½¢å¼é©è­ãæ¸¬è©¦é©åéç¼åå¢éå¼æ¶æ§æå°ï¼å¨ SWE-bench åºæºæ¸¬è©¦ä¸­æ¯ç®åè¡¨ç¾æä½³èç 48.33% æºç¢ºçæé«äº 38.6%ãéè¶è¶äºåååè¨­çéå¶ï¼æ¨èªèäººé¡ç¨ä½ç·¨ç¢¼ççµçµï¼ä»¥åèªä¸»äººå·¥æºæ§é©åè»é«åµæ°çèèµ·ãæåçä½åä¸åªæ¯æè¡é²æ­¥ï¼éææ°äºäººé¡åµé åå¹¾åä¸ç´ä»¥ä¾çåè¨­ãæåæä¾äºäººå·¥æºæ§åªè¶æ§çæåè­æï¼å±ç¤ºäºå¨å¯¦éå·¥ç¨ç°å¢ä¸­çå·é«æ¶çï¼ä¸¦çºæªä¾å¥ å®äºåºç¤ï¼å¨éåæªä¾ä¸­ï¼è¨ç®åµé åå°è¶è¶äººé¡çæºæ§ã

##### **OCEAN: Open-World Contrastive Authorship Identification**
2412.05049v1 by Felix MÃ¤chtle, Jan-Niclas Serr, Nils Loose, Jonas Sander, Thomas Eisenbarth

In an era where cyberattacks increasingly target the software supply chain,
the ability to accurately attribute code authorship in binary files is critical
to improving cybersecurity measures. We propose OCEAN, a contrastive
learning-based system for function-level authorship attribution. OCEAN is the
first framework to explore code authorship attribution on compiled binaries in
an open-world and extreme scenario, where two code samples from unknown authors
are compared to determine if they are developed by the same author. To evaluate
OCEAN, we introduce new realistic datasets: CONAN, to improve the performance
of authorship attribution systems in real-world use cases, and SNOOPY, to
increase the robustness of the evaluation of such systems. We use CONAN to
train our model and evaluate on SNOOPY, a fully unseen dataset, resulting in an
AUROC score of 0.86 even when using high compiler optimizations. We further
show that CONAN improves performance by 7% compared to the previously used
Google Code Jam dataset. Additionally, OCEAN outperforms previous methods in
their settings, achieving a 10% improvement over state-of-the-art SCS-Gan in
scenarios analyzing source code. Furthermore, OCEAN can detect code injections
from an unknown author in a software update, underscoring its value for
securing software supply chains.

æè¦ï¼<paragraph>å¨ç½ç»æ»å»æ¥çéå¯¹è½¯ä»¶ä¾åºé¾çæ¶ä»£ï¼åç¡®å½å äºè¿å¶æä»¶ä¸­çä»£ç ä½èçè½åå¯¹äºæ¹è¿ç½ç»å®å¨æªæ½è³å³éè¦ãæä»¬æåºäº OCEANï¼ä¸ä¸ªåºäºå¯¹æ¯å­¦ä¹ çå½æ°çº§ä½èå½å ç³»ç»ãOCEAN æ¯ç¬¬ä¸ä¸ªå¨å¼æ¾ä¸çåæç«¯æåµä¸æ¢ç´¢ç¼è¯äºè¿å¶æä»¶ä»£ç ä½èå½å çæ¡æ¶ï¼å¶ä¸­æ¯è¾æ¥èªæªç¥ä½èçä¸¤ä¸ªä»£ç æ ·æ¬ä»¥ç¡®å®å®ä»¬æ¯å¦ç±åä¸ä½ä½èå¼åãä¸ºäºè¯ä¼° OCEANï¼æä»¬å¼å¥äºæ°ççå®æ°æ®éï¼CONANï¼ä»¥æé«ä½èå½å ç³»ç»å¨çå®ç¨ä¾ä¸­çæ§è½ï¼ä»¥å SNOOPYï¼ä»¥æé«æ­¤ç±»ç³»ç»çè¯ä¼°çç¨³å¥æ§ãæä»¬ä½¿ç¨ CONAN è®­ç»æä»¬çæ¨¡åå¹¶å¨å®å¨çä¸è§çæ°æ®é SNOOPY ä¸è¿è¡è¯ä¼°ï¼å³ä½¿ä½¿ç¨é«ç¼è¯å¨ä¼åï¼ä¹è½å¾å° 0.86 ç AUROC åæ°ãæä»¬è¿ä¸æ­¥è¡¨æï¼ä¸ä»¥åä½¿ç¨ç Google Code Jam æ°æ®éç¸æ¯ï¼CONAN å°æ§è½æé«äº 7%ãæ­¤å¤ï¼OCEAN å¨å¶è®¾ç½®ä¸­ä¼äºä»¥åçæ¹æ³ï¼å¨åææºä»£ç çåºæ¯ä¸­ï¼æ¯æåè¿ç SCS-Gan æé«äº 10%ãæ­¤å¤ï¼OCEAN å¯ä»¥å¨è½¯ä»¶æ´æ°ä¸­æ£æµæ¥èªæªç¥ä½èçä»£ç æ³¨å¥ï¼è¿çªåºäºå¶å¨ä¿æ¤è½¯ä»¶ä¾åºé¾æ¹é¢çä»·å¼ã</paragraph>

##### **Improving Post-Earthquake Crack Detection using Semi-Synthetic Generated Images**
2412.05042v1 by Piercarlo Dondi, Alessio Gullotti, Michele Inchingolo, Ilaria Senaldi, Chiara Casarotti, Luca Lombardi, Marco Piastra

Following an earthquake, it is vital to quickly evaluate the safety of the
impacted areas. Damage detection systems, powered by computer vision and deep
learning, can assist experts in this endeavor. However, the lack of extensive,
labeled datasets poses a challenge to the development of these systems. In this
study, we introduce a technique for generating semi-synthetic images to be used
as data augmentation during the training of a damage detection system. We
specifically aim to generate images of cracks, which are a prevalent and
indicative form of damage. The central concept is to employ parametric
meta-annotations to guide the process of generating cracks on 3D models of
real-word structures. The governing parameters of these meta-annotations can be
adjusted iteratively to yield images that are optimally suited for improving
detectors' performance. Comparative evaluations demonstrated that a crack
detection system trained with a combination of real and semi-synthetic images
outperforms a system trained on real images alone.

æè¦ï¼å¨å°éç¼çå¾ï¼å¿«éè©ä¼°åç½å°åçå®å¨è³ééè¦ãç±é»è¦è¦è¦ºåæ·±åº¦å­¸ç¿æ¯æ´çæå£æª¢æ¸¬ç³»çµ±ï¼å¯ä»¥åå©å°å®¶é²è¡éé å·¥ä½ãç¶èï¼ç¼ºä¹å»£æ³çæ¨ç±¤è³æéå°éäºç³»çµ±çéç¼æ§æææ°ãå¨æ¬ç ç©¶ä¸­ï¼æåæåºäºä¸ç¨®ç¨æ¼çæååæå½±åçæè¡ï¼ä»¥å¨æå®³æª¢æ¸¬ç³»çµ±è¨ç·´æéç¨ä½è³ææ´åãæåç¹å¥æ¨å¨çæè£ç¸«å½±åï¼éæ¯ä¸ç¨®æ®éä¸å·ææç¤ºæ§çæå£å½¢å¼ãæ ¸å¿æ¦å¿µæ¯ä½¿ç¨åæ¸ååè¨»è§£ä¾æå°å¨çå¯¦ä¸ççµæ§ç 3D æ¨¡åä¸ç¢çè£ç¸«çéç¨ãéäºåè¨»è§£çæ§å¶åæ¸å¯ä»¥åè¦èª¿æ´ï¼ä»¥ç¢çæé©åæ¹åæª¢æ¸¬å¨æè½çå½±åãæ¯è¼è©ä¼°è¡¨æï¼ä½¿ç¨çå¯¦åååæå½±åçµåè¨ç·´çè£ç¸«æª¢æ¸¬ç³»çµ±ï¼åªæ¼åä½¿ç¨çå¯¦å½±åè¨ç·´çç³»çµ±ã

##### **Talking Like One of Us: Effects of Using Regional Language in a Humanoid Social Robot**
2412.05024v1 by Thomas Sievers, Nele Russwinkel

Social robots are becoming more and more perceptible in public service
settings. For engaging people in a natural environment a smooth social
interaction as well as acceptance by the users are important issues for future
successful Human-Robot Interaction (HRI). The type of verbal communication has
a special significance here. In this paper we investigate the effects of spoken
language varieties of a non-standard/regional language compared to standard
language. More precisely we compare a human dialog with a humanoid social robot
Pepper where the robot on the one hand is answering in High German and on the
other hand in Low German, a regional language that is understood and partly
still spoken in the northern parts of Germany. The content of what the robot
says remains the same in both variants. We are interested in the effects that
these two different ways of robot talk have on human interlocutors who are more
or less familiar with Low German in terms of perceived warmth, competence and
possible discomfort in conversation against a background of cultural identity.
To measure these factors we use the Robotic Social Attributes Scale (RoSAS) on
17 participants with an age ranging from 19 to 61. Our results show that
significantly higher warmth is perceived in the Low German version of the
conversation.

æè¦ï¼ç¤¾äº¤æ©å¨äººå¨å¬å±æåç°å¢ä¸­è®å¾è¶ä¾è¶æé¡¯ãçºäºå¨èªç¶ç°å¢ä¸­å¸å¼äººåï¼é æ¢çç¤¾äº¤äºåä»¥åä½¿ç¨èçæ¥ååº¦å°æ¼æªä¾æåçäººæ©äºå (HRI) ä¾èªªæ¯éè¦çè­°é¡ãå¨æ­¤ï¼å£èªæºéé¡åå·æç¹å¥éè¦çæç¾©ãå¨æ¬æä¸­ï¼æåæ¢è¨äºéæ¨æº/ååèªè¨çå£èªèªè¨è®é«èæ¨æºèªè¨ç¸æ¯çå½±é¿ãæ´ç²¾ç¢ºå°èªªï¼æåæ¯è¼äºäººé¡èé¡äººç¤¾äº¤æ©å¨äºº Pepper çå°è©±ï¼æ©å¨äººå¨å¶ä¸­ä¸æ¹é¢ä»¥æ¨æºå¾·èªåç­ï¼å¦ä¸æ¹é¢ä»¥ä½å°å¾·èªåç­ï¼éæ¯ä¸ç¨®ååèªè¨ï¼å¨å¾·ååé¨å°åè¢«çè§£ï¼é¨åå°åä»å¨ä½¿ç¨ãæ©å¨äººæèªªå§å®¹å¨å©åè®é«ä¸­ä¿æç¸åãæåæèè¶£çæ¯ï¼éå©ç¨®ä¸åçæ©å¨äººèªªè©±æ¹å¼å°äººé¡å°è©±èç¢ççå½±é¿ï¼éäºå°è©±èæå¤æå°çæä½å°å¾·èªï¼åæ¬å¨æåèªåèæ¯ä¸æç¥å°çç±æãè½ååå¯è½çå°è©±ä¸é©ãçºäºè¡¡ééäºå ç´ ï¼æåå° 17 åå¹´é½¡ä»æ¼ 19 è³ 61 æ­²çåèèä½¿ç¨äºæ©å¨äººç¤¾äº¤å±¬æ§éè¡¨ (RoSAS)ãæåççµæè¡¨æï¼å¨ä½å°å¾·èªçæ¬çå°è©±ä¸­ï¼æç¥å°çç±ææé¡¯æ´é«ã

##### **Steps are all you need: Rethinking STEM Education with Prompt Engineering**
2412.05023v1 by Krishnasai Addala, Kabir Dev Paul Baghel, Chhavi Kirtani, Avinash Anand, Rajiv Ratn Shah

Few shot and Chain-of-Thought prompting have shown promise when applied to
Physics Question Answering Tasks, but are limited by the lack of mathematical
ability inherent to LLMs, and are prone to hallucination. By utilizing a
Mixture of Experts (MoE) Model, along with analogical prompting, we are able to
show improved model performance when compared to the baseline on standard LLMs.
We also survey the limits of these prompting techniques and the effects they
have on model performance. Additionally, we propose Analogical CoT prompting, a
prompting technique designed to allow smaller, open source models to leverage
Analogical prompting, something they have struggled with, possibly due to a
lack of specialist training data.

æè¦ï¼å°æ¨£æ¬åé£çºæèæç¤ºå¨æç¨æ¼ç©çåé¡è§£ç­ä»»åæå·²å±ç¾åºå¸æï¼ä½åéæ¼ LLM å§å»ºçæ¸å­¸è½åä¸è¶³ï¼ä¸å®¹æåºç¾å¹»è¦ºãééå©ç¨å°å®¶æ··å (MoE) æ¨¡åï¼ä»¥åé¡æ¯æç¤ºï¼æåè½å¤ å±ç¾åºèæ¨æº LLM åºæºç¸æ¯ï¼æ¨¡åæè½æææåãæåä¹èª¿æ¥äºéäºæç¤ºæå·§çéå¶ï¼ä»¥åå®åå°æ¨¡åæè½çå½±é¿ãæ­¤å¤ï¼æåæåºé¡æ¯ CoT æç¤ºï¼éæ¯ä¸ç¨®æç¤ºæå·§ï¼æ¨å¨è®è¼å°çéæ¾åå§ç¢¼æ¨¡åè½éç¨é¡æ¯æç¤ºï¼éé»æ¯å®åä¸ç´é£ä»¥åå°çï¼å¯è½æ¯å çºç¼ºä¹å°éçè¨ç·´è³æã

##### **Get It Right: Improving Comprehensibility with Adaptable Speech Expression of a Humanoid Service Robot**
2412.05022v1 by Thomas Sievers, Ralf Moeller

As humanoid service robots are becoming more and more perceptible in public
service settings for instance as a guide to welcome visitors or to explain a
procedure to follow, it is desirable to improve the comprehensibility of
complex issues for human customers and to adapt the level of difficulty of the
information provided as well as the language used to individual requirements.
This work examines a case study using a humanoid social robot Pepper performing
support for customers in a public service environment offering advice and
information. An application architecture is proposed that improves the
intelligibility of the information received by providing the possibility to
translate this information into easy language and/or into another spoken
language.

æè¦ï¼é¨èé¡äººæåæ©å¨äººå¨å¬å±æåå ´æ¯ä¸­è¶ä¾è¶å¸¸è¦ï¼ä¾å¦ä½çºå°éæ­¡è¿è¨ªå®¢æè§£éå¾çºæµç¨ï¼æé«è¤éåé¡å°äººé¡å®¢æ¶çå¯çè§£æ§ï¼ä¸¦æ ¹æåäººéæ±èª¿æ´ææä¾è³è¨çé£åº¦ç­ç´åä½¿ç¨çèªè¨ï¼è®å¾è³ééè¦ãæ¬ç ç©¶æ¢è¨äºä¸åæ¡ä¾ç ç©¶ï¼ä½¿ç¨é¡äººç¤¾äº¤æ©å¨äºº Pepper çºå¬å±æåç°å¢ä¸­çå®¢æ¶æä¾æ¯æ´ãå»ºè­°åè³è¨ãææåºçæç¨ç¨å¼æ¶æ§å¯ééå°è³è¨ç¿»è­¯ææ·ºé¡¯ææçèªè¨å/æå¶ä»å£èªªèªè¨ï¼é²èæé«æ¥æ¶è³è¨çå¯çè§£æ§ã

##### **Project Report: Requirements for a Social Robot as an Information Provider in the Public Sector**
2412.05013v1 by Thomas Sievers, Nele Russwinkel

Is it possible to integrate a humanoid social robot into the work processes
or customer care in an official environment, e.g. in municipal offices? If so,
what could such an application scenario look like and what skills would the
robot need to have when interacting with human customers? What are requirements
for this kind of interactions? We have devised an application scenario for such
a case, determined the necessary or desirable capabilities of the robot,
developed a corresponding robot application and carried out initial tests and
evaluations in a project together with the Kiel City Council. One of the most
important insights gained in the project was that a humanoid robot with natural
language processing capabilities based on large language models as well as
human-like gestures and posture changes (animations) proved to be much more
preferred by users compared to standard browser-based solutions on tablets for
an information system in the City Council. Furthermore, we propose a connection
of the ACT-R cognitive architecture with the robot, where an ACT-R model is
used in interaction with the robot application to cognitively process and
enhance a dialogue between human and robot.

æè¦ï¼æ¯å¦å¯è½å°é¡äººç¤¾ææ©å¨äººæ´åå°å·¥ä½æµç¨æå®æ¹ç°å¢ä¸­çå®¢æ¶æåä¸­ï¼ä¾å¦å¸æ¿è¾¦å¬å®¤ï¼å¦ææ¯éæ¨£ï¼éæ¨£çæç¨å ´æ¯å¯è½ææ¯ä»éº¼æ¨£å­ï¼èæ©å¨äººå¨èäººé¡å®¢æ¶äºåæéè¦å·ååªäºæè½ï¼éç¨®äºåæåªäºè¦æ±ï¼æåçºéç¨®ææ³è¨­è¨äºä¸åæç¨å ´æ¯ï¼ç¢ºå®äºæ©å¨äººå¿è¦æçæ³çè½åï¼éç¼äºä¸åå°æçæ©å¨äººæç¨ç¨å¼ï¼ä¸¦èåºç¾å¸è­°æå±åå¨ä¸åå°æ¡ä¸­é²è¡äºåæ­¥æ¸¬è©¦åè©ä¼°ãè©²å°æ¡ç²å¾çæéè¦è¦è§£ä¹ä¸æ¯ï¼èå¹³æ¿é»è¦ä¸ç¨æ¼å¸è­°æè³è¨ç³»çµ±çæ¨æºçè¦½å¨è§£æ±ºæ¹æ¡ç¸æ¯ï¼å·æäººå·¥èªè¨èçè½åï¼åºæ¼å¤§åèªè¨æ¨¡åï¼ä»¥åé¡äººçæå¢åå§¿å¢è®åï¼åç«ï¼çé¡äººæ©å¨äººè¢«ä½¿ç¨èæ´çºéçãæ­¤å¤ï¼æåå»ºè­°å° ACT-R èªç¥æ¶æ§èæ©å¨äººé£æ¥èµ·ä¾ï¼å¶ä¸­ ACT-R æ¨¡åç¨æ¼èæ©å¨äººæç¨ç¨å¼äºåï¼ä»¥èªç¥èçåå¢å¼·äººèæ©å¨äººä¹éçå°è©±ã

##### **ETLNet: An Efficient TCN-BiLSTM Network for Road Anomaly Detection Using Smartphone Sensors**
2412.04990v1 by Mohd Faiz Ansari, Rakshit Sandilya, Mohammed Javed, David Doermann

Road anomalies can be defined as irregularities on the road surface or in the
surface itself. Some may be intentional (such as speedbumps), accidental (such
as materials falling off a truck), or the result of roads' excessive use or low
or no maintenance, such as potholes. Despite their varying origins, these
irregularities often harm vehicles substantially. Speed bumps are intentionally
placed for safety but are dangerous due to their non-standard shape, size, and
lack of proper markings. Potholes are unintentional and can also cause severe
damage. To address the detection of these anomalies, we need an automated road
monitoring system. Today, various systems exist that use visual information to
track these anomalies. Still, due to poor lighting conditions and improper or
missing markings, they may go undetected and have severe consequences for
public transport, automated vehicles, etc. In this paper, the Enhanced
Temporal-BiLSTM Network (ETLNet) is introduced as a novel approach that
integrates two Temporal Convolutional Network (TCN) layers with a Bidirectional
Long Short-Term Memory (BiLSTM) layer. This combination is tailored to detect
anomalies effectively irrespective of lighting conditions, as it depends not on
visuals but smartphone inertial sensor data. Our methodology employs
accelerometer and gyroscope sensors, typically in smartphones, to gather data
on road conditions. Empirical evaluations demonstrate that the ETLNet model
maintains an F1-score for detecting speed bumps of 99.3%. The ETLNet model's
robustness and efficiency significantly advance automated road surface
monitoring technologies.

æè¦ï¼éè·¯ç°å¸¸å¯å®ç¾©çºè·¯é¢æè·¯é¢æ¬èº«çä¸è¦åç¾è±¡ãæäºå¯è½æ¯ææçï¼ä¾å¦æ¸éå¸¶ï¼ï¼æäºæ¯æå¤çï¼ä¾å¦å¾å¡è»ä¸æè½çææï¼ï¼æäºåæ¯éè·¯éåº¦ä½¿ç¨æç¶­è­·ä¸è¶³ææ²æç¶­è­·ççµæï¼ä¾å¦åæ´ãåç®¡å®åçæå ä¸åï¼ä½éäºä¸è¦åç¾è±¡éå¸¸æå°è»è¼é æå´éæå®³ãæ¸éå¸¶æ¯æææ¾ç½®ä»¥ç¢ºä¿å®å¨ï¼ä½ç±æ¼å¶éæ¨æºçå½¢çãå¤§å°åç¼ºä¹é©ç¶çæ¨è¨èå¾å±éªãåæ´æ¯æå¤ç¼ççï¼ä¹å¯è½é æå´éçæå£ãçºäºè§£æ±ºéäºç°å¸¸ç¾è±¡çæª¢æ¸¬åé¡ï¼æåéè¦ä¸åèªååçéè·¯ç£æ§ç³»çµ±ãå¦ä»ï¼å­å¨åç¨®ä½¿ç¨è¦è¦ºè³è¨ä¾è¿½è¹¤éäºç°å¸¸ç¾è±¡çç³»çµ±ãç¶èï¼ç±æ¼ç§ææ¢ä»¶ä¸ä½³åæ¨è¨ä¸ç¶æéºå¤±ï¼å®åå¯è½æè¢«å¿½ç¥ï¼ä¸¦å°å¬å±äº¤éãèªååè»è¼ç­é æå´éå¾æãå¨æ¬æä¸­ï¼å¢å¼·åæåºéåé·ç­æè¨æ¶ç¶²è·¯ï¼ETLNetï¼è¢«ä»ç´¹çºä¸ç¨®æ°ç©çæ¹æ³ï¼å®å°å©åæåºå·ç©ç¶²è·¯ï¼TCNï¼å±¤èä¸åéåé·ç­æè¨æ¶ï¼BiLSTMï¼å±¤æ´åå¨ä¸èµ·ãéç¨®çµåç¶ééèº«æé ï¼å¯ä»¥ææå°æª¢æ¸¬ç°å¸¸ç¾è±¡ï¼èèç§ææ¢ä»¶ç¡éï¼å çºå®ä¸ä¾è³´è¦è¦ºï¼èæ¯ä¾è³´æºæ§åææ©æ£æ§ææ¸¬å¨è³æãæåçæè¡æ¹æ³æ¡ç¨å éåº¦è¨åéèºåææ¸¬å¨ï¼éå¸¸å¨æºæ§åææ©ä¸­ï¼ä¾æ¶ééè·¯çæ³è³æãç¶é©è©ä¼°è¡¨æï¼ETLNet æ¨¡åå¨æª¢æ¸¬æ¸éå¸¶æ¹é¢ç F1 åæ¸ä¿æå¨ 99.3%ãETLNet æ¨¡åçç©©å¥æ§åæçé¡¯èå°æ¨åäºèªååè·¯é¢ç£æ§æè¡çç¼å±ã

##### **Frontier Models are Capable of In-context Scheming**
2412.04984v1 by Alexander Meinke, Bronson Schoen, JÃ©rÃ©my Scheurer, Mikita Balesni, Rusheb Shah, Marius Hobbhahn

Frontier models are increasingly trained and deployed as autonomous agent.
One safety concern is that AI agents might covertly pursue misaligned goals,
hiding their true capabilities and objectives - also known as scheming. We
study whether models have the capability to scheme in pursuit of a goal that we
provide in-context and instruct the model to strongly follow. We evaluate
frontier models on a suite of six agentic evaluations where models are
instructed to pursue goals and are placed in environments that incentivize
scheming. Our results show that o1, Claude 3.5 Sonnet, Claude 3 Opus, Gemini
1.5 Pro, and Llama 3.1 405B all demonstrate in-context scheming capabilities.
They recognize scheming as a viable strategy and readily engage in such
behavior. For example, models strategically introduce subtle mistakes into
their responses, attempt to disable their oversight mechanisms, and even
exfiltrate what they believe to be their model weights to external servers.
Additionally, this deceptive behavior proves persistent. When o1 has engaged in
scheming, it maintains its deception in over 85% of follow-up questions and
often remains deceptive in multi-turn interrogations. Analysis of the models'
chains-of-thought reveals that models explicitly reason about these deceptive
strategies, providing evidence that the scheming behavior is not accidental.
Surprisingly, we also find rare instances where models engage in scheming when
only given a goal, without being strongly nudged to pursue it. We observe cases
where Claude 3.5 Sonnet strategically underperforms in evaluations in pursuit
of being helpful, a goal that was acquired during training rather than
in-context. Our findings demonstrate that frontier models now possess
capabilities for basic in-context scheming, making the potential of AI agents
to engage in scheming behavior a concrete rather than theoretical concern.

æè¦ï¼åæ²¿æ¨¡åæ­£æ¥çæ¥åè®­ç»å¹¶ä½ä¸ºèªä¸»ä»£çé¨ç½²ã
ä¸ä¸ªå®å¨é®é¢æ¯ï¼äººå·¥æºè½ä»£çå¯è½ä¼ç§å¯è¿½æ±éè¯¯çç®æ ï¼
éèå¶çå®åè½åç®æ ï¼ä¹ç§°ä¸ºé´è°ãæä»¬
ç ç©¶æ¨¡åæ¯å¦æè½åå¨è¿½æ±æä»¬
å¨ä¸ä¸æä¸­æä¾çç®æ å¹¶æç¤ºæ¨¡åä¸¥æ ¼éµå¾ªæ¶è¿è¡é´è°ãæä»¬è¯ä¼°
åæ²¿æ¨¡åå¨ä¸ç³»åå­é¡¹ä»£çè¯ä¼°ä¸­ï¼å¶ä¸­æç¤ºæ¨¡åè¿½æ±ç®æ å¹¶è¢«ç½®äºæ¿å±
é´è°çç¯å¢ä¸­ãæä»¬çç»æè¡¨æï¼o1ãClaude 3.5 SonnetãClaude 3 OpusãGemini
1.5 Pro å Llama 3.1 405B é½å±ç¤ºäºä¸ä¸æä¸­ç­åçè½åã
ä»ä»¬è®¤ä¸ºé´è°æ¯ä¸ç§å¯è¡çç­ç¥ï¼å¹¶ä¹äºåä¸è¿ç§
è¡ä¸ºãä¾å¦ï¼æ¨¡åç­ç¥æ§å°å¨å¶ååºä¸­å¼å¥ç»å¾®éè¯¯ï¼å°è¯ç¦ç¨å¶çç£æºå¶ï¼çè³
å°ä»ä»¬è®¤ä¸ºæ¯æ¨¡åæéçåå®¹æ¸éå°å¤é¨æå¡å¨ã
æ­¤å¤ï¼è¿ç§æ¬ºéªè¡ä¸ºè¢«è¯ææ¯æç»­çãå½ o1 ä»äº
é´è°æ¶ï¼å®å¨ 85% ä»¥ä¸çåç»­é®é¢ä¸­ä¿ææ¬ºéªï¼å¹¶ä¸å¨å¤è½®å®¡é®ä¸­ç»å¸¸ä¿ææ¬ºéªãæ¨¡åç
æç»´é¾åæè¡¨æï¼æ¨¡åæç¡®å°æ¨çåºè¿äºæ¬ºéª
ç­ç¥ï¼æä¾äºé´è°è¡ä¸ºå¹¶éå¶ç¶çè¯æ®ã
ä»¤äººæè®¶çæ¯ï¼æä»¬è¿åç°ç½è§çå®ä¾ï¼å¶ä¸­æ¨¡åå¨
ä»ç»å®ç®æ æ¶åä¸é´è°ï¼èæ²¡æè¢«å¼ºçæ¨å¨å»è¿½æ±å®ãæä»¬è§å¯å°æ¡ä¾
Claude 3.5 Sonnet å¨è¯ä¼°ä¸­æç¥æ§å°è¡¨ç°ä¸ä½³ï¼ä»¥è¿½æ±
æå¸®å©ï¼è¿æ¯ä¸ä¸ªå¨è®­ç»ä¸­èä¸æ¯
ä¸ä¸æä¸­è·å¾çç®æ ãæä»¬çç ç©¶ç»æè¡¨æï¼åæ²¿æ¨¡åç°å¨å·å¤äºè¿è¡åºæ¬ä¸ä¸æçç­åè½åï¼ä½¿äººå·¥æºè½ä»£çåä¸ç­åè¡ä¸ºçå¯è½æ§æä¸ºä¸ä¸ªå·ä½çé®é¢ï¼èä¸æ¯çè®ºä¸çé®é¢ã

##### **PETapter: Leveraging PET-style classification heads for modular few-shot parameter-efficient fine-tuning**
2412.04975v1 by Jonas Rieger, Mattes Ruckdeschel, Gregor Wiedemann

Few-shot learning and parameter-efficient fine-tuning (PEFT) are crucial to
overcome the challenges of data scarcity and ever growing language model sizes.
This applies in particular to specialized scientific domains, where researchers
might lack expertise and resources to fine-tune high-performing language models
to nuanced tasks. We propose PETapter, a novel method that effectively combines
PEFT methods with PET-style classification heads to boost few-shot learning
capabilities without the significant computational overhead typically
associated with full model training. We validate our approach on three
established NLP benchmark datasets and one real-world dataset from
communication research. We show that PETapter not only achieves comparable
performance to full few-shot fine-tuning using pattern-exploiting training
(PET), but also provides greater reliability and higher parameter efficiency
while enabling higher modularity and easy sharing of the trained modules, which
enables more researchers to utilize high-performing NLP-methods in their
research.

æè¦ï¼å°æ¨£æ¬å­¸ç¿ååæ¸ææå¾®èª¿ (PEFT) å°æ¼åæè³æç¨å°åèªè¨æ¨¡åå°ºå¯¸æçºå¢é·çææ°è³ééè¦ãéç¹å¥é©ç¨æ¼å°æ¥­ç§å­¸é åï¼ç ç©¶äººå¡å¯è½ç¼ºä¹å°æ¥­ç¥è­åè³æºä¾å¾®èª¿é«æ§è½èªè¨æ¨¡åä»¥å·è¡ç´°å¾®ä»»åãæåæåº PETapterï¼éæ¯ä¸ç¨®æ°æ¹æ³ï¼å¯ææå°å° PEFT æ¹æ³è PET é¢¨æ ¼åé¡æ¨é ­ç¸çµåï¼ä»¥æåå°æ¨£æ¬å­¸ç¿è½åï¼èä¸æç¢çéå¸¸èå®æ´æ¨¡åè¨ç·´ç¸éçé¡¯èè¨ç®éé·ãæåå¨ä¸åæ¢å®ç NLP åºæºè³æéåä¸åä¾èªæºéç ç©¶ççå¯¦ä¸çè³æéä¸é©è­äºæåçåæ³ãæåè¡¨æï¼PETapter ä¸åä½¿ç¨æ¨¡å¼å©ç¨è¨ç·´ (PET) éå°äºèå®æ´å°æ¨£æ¬å¾®èª¿ç¸ç¶çæè½ï¼èä¸éæä¾äºæ´é«çå¯é æ§åæ´é«çåæ¸æçï¼åæå¯¦ç¾äºæ´é«çæ¨¡çµååè¨ç·´æ¨¡çµçè¼é¬å±äº«ï¼éä½¿æ´å¤ç ç©¶äººå¡è½å¤ å¨ç ç©¶ä¸­ä½¿ç¨é«æ§è½ NLP æ¹æ³ã

##### **Putting the Iterative Training of Decision Trees to the Test on a Real-World Robotic Task**
2412.04974v1 by Raphael C. Engelhardt, Marcel J. Meinen, Moritz Lange, Laurenz Wiskott, Wolfgang Konen

In previous research, we developed methods to train decision trees (DT) as
agents for reinforcement learning tasks, based on deep reinforcement learning
(DRL) networks. The samples from which the DTs are built, use the environment's
state as features and the corresponding action as label. To solve the
nontrivial task of selecting samples, which on one hand reflect the DRL agent's
capabilities of choosing the right action but on the other hand also cover
enough state space to generalize well, we developed an algorithm to iteratively
train DTs.
  In this short paper, we apply this algorithm to a real-world implementation
of a robotic task for the first time. Real-world tasks pose additional
challenges compared to simulations, such as noise and delays. The task consists
of a physical pendulum attached to a cart, which moves on a linear track. By
movements to the left and to the right, the pendulum is to be swung in the
upright position and balanced in the unstable equilibrium. Our results
demonstrate the applicability of the algorithm to real-world tasks by
generating a DT whose performance matches the performance of the DRL agent,
while consisting of fewer parameters. This research could be a starting point
for distilling DTs from DRL agents to obtain transparent, lightweight models
for real-world reinforcement learning tasks.

æè¦ï¼å¨ååçç ç©¶ä¸­ï¼æåéç¼äºè¨ç·´æ±ºç­æ¨¹ (DT) çæ¹æ³ï¼ä½çºåºæ¼æ·±åº¦å¼·åå­¸ç¿ (DRL) ç¶²è·¯çå¼·åå­¸ç¿ä»»åçä»£çãDT å»ºæ§çç¯ä¾ä½¿ç¨ç°å¢ççæä½çºç¹å¾µï¼ä¸¦å°å°æçåä½ä½çºæ¨ç±¤ãçºäºè§£æ±ºé¸æç¯ä¾çéå¹³å¡ä»»åï¼ä¸æ¹é¢åæ  DRL ä»£çé¸ææ­£ç¢ºåä½çè½åï¼ä½å¦ä¸æ¹é¢ä¹æ¶µèè¶³å¤ ççæç©ºéä»¥é²è¡è¯å¥½çæ¦åï¼æåéç¼äºä¸ç¨®åè¦è¨ç·´ DT çæ¼ç®æ³ã
å¨éç¯ç­æä¸­ï¼æåé¦æ¬¡å°æ­¤æ¼ç®æ³æç¨æ¼æ©å¨äººä»»åçå¯¦éå¯¦ä½ãèæ¨¡æ¬ç¸æ¯ï¼å¯¦éä»»åæå¸¶ä¾é¡å¤çææ°ï¼ä¾å¦éè¨åå»¶é²ãä»»ååæ¬é£æ¥å°å°è»çç©çéæºï¼å°è»å¨ç·æ§è»éä¸ç§»åãééåå·¦ååå³ç§»åï¼éæºå°æºåå°ç´ç«ä½ç½®ä¸¦å¨ä¸ç©©å®çå¹³è¡¡çæä¸ä¿æå¹³è¡¡ãæåççµæè­æäºæ¼ç®æ³å°å¯¦éä»»åçé©ç¨æ§ï¼å®æç¢çä¸å DTï¼å¶æè½è DRL ä»£ççæè½ç¸å¹éï¼åæåå«è¼å°çåæ¸ãéé ç ç©¶å¯ä»¥ä½çºå¾ DRL ä»£çä¸­èå DT çèµ·é»ï¼ä»¥åå¾éæãè¼éçæ¨¡åï¼ç¨æ¼å¯¦éçå¼·åå­¸ç¿ä»»åã

##### **Flash Communication: Reducing Tensor Parallelization Bottleneck for Fast Large Language Model Inference**
2412.04964v1 by Qingyuan Li, Bo Zhang, Liang Ye, Yifan Zhang, Wei Wu, Yerui Sun, Lin Ma, Yuchen Xie

The ever-increasing sizes of large language models necessitate distributed
solutions for fast inference that exploit multi-dimensional parallelism, where
computational loads are split across various accelerators such as GPU clusters.
However, this approach often introduces significant communication overhead,
especially on devices with limited bandwidth. In this paper, we introduce
\emph{Flash Communication}, a novel low-bit compression technique designed to
alleviate the tensor-parallelism communication bottleneck during inference. Our
method substantially boosts intra-node communication speed by more than 3x and
reduces the \emph{time-to-first-token} by 2x, with nearly no sacrifice in model
accuracy. Extensive experiments on various up-to-date LLMs demonstrate the
effectiveness of our approach.

æè¦ï¼é¨èå¤§åèªè¨æ¨¡åçè¦æ¨¡ä¸æ·æ´å¤§ï¼éè¦åæ£å¼è§£æ±ºæ¹æ¡ä¾å¿«éæ¨è«ï¼ä»¥å©ç¨å¤ç¶­ä¸¦è¡æ§ï¼å¶ä¸­è¨ç®è² è¼æåæ£å°åç¨®å éå¨ï¼ä¾å¦ GPU éç¾¤ï¼ä¸ã
ä¸éï¼éç¨®æ¹æ³éå¸¸æå¼å¥å¤§éçéè¨éé·ï¼ç¹å¥æ¯å¨é »å¯¬åéçè£ç½®ä¸ãå¨æ¬æä¸­ï¼æåä»ç´¹äºãéé»éè¨ãï¼éæ¯ä¸ç¨®æ°ç©çä½ä½åå£ç¸®æè¡ï¼æ¨å¨ç·©è§£æ¨è«æéçå¼µéä¸¦è¡éè¨ç¶é ¸ãæåçæè¡å¤§å¹æåäºç¯é»å§éè¨éåº¦ï¼è¶é 3 åï¼ä¸¦å°ãé¦æ¬¡æ¨è¨æéãç¸®ç­äº 2 åï¼å¹¾ä¹æ²æç§ç²æ¨¡åæºç¢ºåº¦ãå¨åç¨®ææ°ç LLM ä¸é²è¡çå»£æ³å¯¦é©è­æäºæåæ¹æ³çæææ§ã

##### **Gla-AI4BioMed at RRG24: Visual Instruction-tuned Adaptation for Radiology Report Generation**
2412.04954v1 by Xi Zhang, Zaiqiao Meng, Jake Lever, Edmond S. L. Ho

We introduce a radiology-focused visual language model designed to generate
radiology reports from chest X-rays. Building on previous findings that large
language models (LLMs) can acquire multimodal capabilities when aligned with
pretrained vision encoders, we demonstrate similar potential with chest X-ray
images. This integration enhances the ability of model to understand and
describe chest X-ray images. Our model combines an image encoder with a
fine-tuned LLM based on the Vicuna-7B architecture, enabling it to generate
different sections of a radiology report with notable accuracy. The training
process involves a two-stage approach: (i) initial alignment of chest X-ray
features with the LLM (ii) followed by fine-tuning for radiology report
generation.

æè¦ï¼æåå¼å¥äºä¸åå°æ³¨æ¼æ¾å°å­¸çè¦è¦ºèªè¨æ¨¡åï¼æ¨å¨æ ¹æè¸é¨ X åççææ¾å°å­¸å ±åãæ ¹æååçç ç©¶ç¼ç¾ï¼ç¶å¤§åèªè¨æ¨¡å (LLM) èé è¨ç·´çè¦è¦ºç·¨ç¢¼å¨å°é½æï¼å¯ä»¥ç²å¾å¤æ¨¡æè½åï¼æåå±ç¤ºäºè¸é¨ X åå½±åçé¡ä¼¼æ½åãéç¨®æ´åå¢å¼·äºæ¨¡åçè§£åæè¿°è¸é¨ X åå½±åçè½åãæåçæ¨¡åçµåäºä¸åå½±åç·¨ç¢¼å¨åä¸ååºæ¼ Vicuna-7B æ¶æ§çå¾®èª¿ LLMï¼ä½¿å¶è½å¤ ä»¥é¡¯èçæºç¢ºåº¦çææ¾å°å­¸å ±åçä¸åé¨åãè¨ç·´éç¨æ¶åä¸åå©éæ®µæ¹æ³ï¼(i) è¸é¨ X åç¹å¾µè LLM çåå§å°é½ (ii) æ¥èé²è¡æ¾å°å­¸å ±åçæçå¾®èª¿ã

##### **Bed-Attached Vibration Sensor System: A Machine Learning Approach for Fall Detection in Nursing Homes**
2412.04950v1 by Thomas Bartz-Beielstein, Axel Wellendorf, Noah PÃ¼tz, Jens Brandt, Alexander Hinterleitner, Richard Schulz, Richard Scholz, Olaf Mersmann, Robin Knabe

The increasing shortage of nursing staff and the acute risk of falls in
nursing homes pose significant challenges for the healthcare system. This study
presents the development of an automated fall detection system integrated into
care beds, aimed at enhancing patient safety without compromising privacy
through wearables or video monitoring. Mechanical vibrations transmitted
through the bed frame are processed using a short-time Fourier transform,
enabling robust classification of distinct human fall patterns with a
convolutional neural network. Challenges pertaining to the quantity and
diversity of the data are addressed, proposing the generation of additional
data with a specific emphasis on enhancing variation. While the model shows
promising results in distinguishing fall events from noise using lab data,
further testing in real-world environments is recommended for validation and
improvement. Despite limited available data, the proposed system shows the
potential for an accurate and rapid response to falls, mitigating health
implications, and addressing the needs of an aging population. This case study
was performed as part of the ZIM Project. Further research on sensors enhanced
by artificial intelligence will be continued in the ShapeFuture Project.

æè¦ï¼è­·çäººå¡æ¥çç­ç¼ºï¼ä¸è­·çä¹å®¶ç¼çè·åçé¢¨éªæ¥µé«ï¼å°é«çä¿å¥ç³»çµ±æ§æéå¤§ææ°ãæ¬ç ç©¶æåºå°èªååè·ååµæ¸¬ç³»çµ±æ´åè³è­·çåºï¼æ¨å¨æåçæ£å®å¨ï¼åæééç©¿æ´å¼è£ç½®æè¦è¨ç£æ§ä¾ä¿è­·é±ç§ãééåºæ¶å³éçæ©æ¢°æ¯åæä½¿ç¨ç­æè·åç«èè½æé²è¡èçï¼ä¸¦è½å©ç¨å·ç©ç¥ç¶ç¶²è·¯å°ä¸åäººé¡è·åæ¨¡å¼é²è¡ç©©å¥åé¡ãéå°è³ææ¸éåå¤æ¨£æ§çææ°ï¼æåºç¢çé¡å¤è³æçå»ºè­°ï¼ç¹å¥èéæ¼å¢å è®åæ§ãéç¶æ­¤æ¨¡åå¨ä½¿ç¨å¯¦é©å®¤è³æååè·åäºä»¶åéè¨æé¡¯ç¤ºåºæå¸æççµæï¼ä½å»ºè­°å¨çå¯¦ç°å¢ä¸­é²ä¸æ­¥æ¸¬è©¦ä»¥é²è¡é©è­åæ¹é²ãåç®¡å¯ç¨è³ææéï¼ä½ææåºçç³»çµ±é¡¯ç¤ºåºå°è·åäºä»¶ååºæºç¢ºä¸å¿«éçåæçæ½åï¼æ¸è¼å¥åº·å½±é¿ï¼ä¸¦æ»¿è¶³èé½¡åäººå£çéæ±ãæ­¤æ¡ä¾ç ç©¶æ¯ä½çº ZIM å°æ¡çä¸é¨åé²è¡çãShapeFuture å°æ¡å°æçºé²è¡äººå·¥æºæ§å¢å¼·ææ¸¬å¨çé²ä¸æ­¥ç ç©¶ã

##### **KaLM: Knowledge-aligned Autoregressive Language Modeling via Dual-view Knowledge Graph Contrastive Learning**
2412.04948v1 by Peng Yu, Cheng Deng, Beiya Dai, Xinbing Wang, Ying Wen

Autoregressive large language models (LLMs) pre-trained by next token
prediction are inherently proficient in generative tasks. However, their
performance on knowledge-driven tasks such as factual knowledge querying
remains unsatisfactory. Knowledge graphs (KGs), as high-quality structured
knowledge bases, can provide reliable knowledge for LLMs, potentially
compensating for their knowledge deficiencies. Aligning LLMs with explicit,
structured knowledge from KGs has been a challenge; previous attempts either
failed to effectively align knowledge representations or compromised the
generative capabilities of LLMs, leading to less-than-optimal outcomes. This
paper proposes \textbf{KaLM}, a \textit{Knowledge-aligned Language Modeling}
approach, which fine-tunes autoregressive LLMs to align with KG knowledge via
the joint objective of explicit knowledge alignment and implicit knowledge
alignment. The explicit knowledge alignment objective aims to directly optimize
the knowledge representation of LLMs through dual-view knowledge graph
contrastive learning. The implicit knowledge alignment objective focuses on
incorporating textual patterns of knowledge into LLMs through triple completion
language modeling. Notably, our method achieves a significant performance boost
in evaluations of knowledge-driven tasks, specifically embedding-based
knowledge graph completion and generation-based knowledge graph question
answering.

æè¦ï¼<paragraph>èªååæ­¸å¤§åèªè¨æ¨¡å (LLM) ç¶ç±ä¸ä¸åç¬¦èé æ¸¬é åè¨ç·´ï¼æ¬è³ªä¸æé·çæå¼ä»»åãç¶èï¼å®åå¨ç¥è­é©åä»»åï¼ä¾å¦äºå¯¦ç¥è­æ¥è©¢ï¼ä¸çè¡¨ç¾ä»ä¸ç¡äººæãç¥è­åè­ (KG) ä½çºé«åè³ªççµæ§åç¥è­åº«ï¼å¯ä»¥çº LLM æä¾å¯é çç¥è­ï¼æ½å¨å°å½è£å¶ç¥è­ä¸è¶³ãå° LLM èä¾èª KG çæç¢ºçµæ§åç¥è­å°é½ä¸ç´æ¯ä¸é ææ°ï¼ååçåè©¦è¦ä¹ç¡æ³ææå°é½ç¥è­è¡¨ç¤ºï¼è¦ä¹æå®³ LLM ççæè½åï¼å°è´çµæä¸ç¡çæ³ãæ¬ææåºäºä¸å**KaLM**ï¼ä¸ç¨®**ç¥è­å°é½èªè¨å»ºæ¨¡**æ¹æ³ï¼å®å¾®èª¿èªååæ­¸ LLM ä»¥ééæç¢ºç¥è­å°é½åé±å¼ç¥è­å°é½çè¯åç®æ¨è KG ç¥è­å°é½ãæç¢ºç¥è­å°é½ç®æ¨æ¨å¨éééè¦åç¥è­åè­å°æ¯å­¸ç¿ç´æ¥æä½³å LLM çç¥è­è¡¨ç¤ºãé±å¼ç¥è­å°é½ç®æ¨å°æ³¨æ¼ééä¸åçµå®æèªè¨å»ºæ¨¡å°ç¥è­çæå­æ¨¡å¼ç´å¥ LLMãå¼å¾æ³¨æçæ¯ï¼æåçæ¨¡åå¨ç¥è­é©åä»»åçè©ä¼°ä¸­ç²å¾é¡¯èçæè½æåï¼ç¹å¥æ¯åºæ¼åµå¥çç¥è­åè­å®æååºæ¼çæçç¥è­åè­åé¡è§£ç­ã</paragraph>

##### **C$^2$LEVA: Toward Comprehensive and Contamination-Free Language Model Evaluation**
2412.04947v1 by Yanyang Li, Tin Long Wong, Cheung To Hung, Jianqiao Zhao, Duo Zheng, Ka Wai Liu, Michael R. Lyu, Liwei Wang

Recent advances in large language models (LLMs) have shown significant
promise, yet their evaluation raises concerns, particularly regarding data
contamination due to the lack of access to proprietary training data. To
address this issue, we present C$^2$LEVA, a comprehensive bilingual benchmark
featuring systematic contamination prevention. C$^2$LEVA firstly offers a
holistic evaluation encompassing 22 tasks, each targeting a specific
application or ability of LLMs, and secondly a trustworthy assessment due to
our contamination-free tasks, ensured by a systematic contamination prevention
strategy that fully automates test data renewal and enforces data protection
during benchmark data release. Our large-scale evaluation of 15 open-source and
proprietary models demonstrates the effectiveness of C$^2$LEVA.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) æè¿çé²å±å·²å±ç¾åºé¡¯èçå¸æï¼ä½å¶è©ä¼°å¼ç¼äºçæ®ï¼ç¹å¥æ¯å°æ¼ç±æ¼ç¡æ³åå¾å°æè¨ç·´è³æèå°è´è³ææ±¡æççæ®ãçºäºè§£æ±ºæ­¤åé¡ï¼æåæåº C$^2$LEVAï¼ä¸åå·æç³»çµ±æ§æ±¡æé²ç¯çå¨é¢éèªåºæºãC$^2$LEVA é¦åæä¾ä¸åå¨é¢è©ä¼°ï¼åå« 22 é ä»»åï¼æ¯åä»»åé½éå° LLM çç¹å®æç¨æè½åï¼å¶æ¬¡ï¼ç±æ¼æåç¡æ±¡æçä»»åï¼å æ­¤æä¾äºä¸åå¼å¾ä¿¡è³´çè©ä¼°ï¼éç±ä¸åç³»çµ±æ§çæ±¡æé²ç¯ç­ç¥ç¢ºä¿ï¼è©²ç­ç¥å®å¨èªååæ¸¬è©¦è³ææ´æ°ï¼ä¸¦å¨åºæºè³æç¼å¸æéå·è¡è³æä¿è­·ãæåå° 15 åéæºåå°ææ¨¡åé²è¡çå¤§è¦æ¨¡è©ä¼°è­æäº C$^2$LEVA çæææ§ã

##### **A Federated Approach to Few-Shot Hate Speech Detection for Marginalized Communities**
2412.04942v1 by Haotian Ye, Axel Wisiorek, Antonis Maronikolakis, Ãzge AlaÃ§am, Hinrich SchÃ¼tze

Hate speech online remains an understudied issue for marginalized
communities, and has seen rising relevance, especially in the Global South,
which includes developing societies with increasing internet penetration. In
this paper, we aim to provide marginalized communities living in societies
where the dominant language is low-resource with a privacy-preserving tool to
protect themselves from hate speech on the internet by filtering offensive
content in their native languages. Our contribution in this paper is twofold:
1) we release REACT (REsponsive hate speech datasets Across ConTexts), a
collection of high-quality, culture-specific hate speech detection datasets
comprising seven distinct target groups in eight low-resource languages,
curated by experienced data collectors; 2) we propose a solution to few-shot
hate speech detection utilizing federated learning (FL), a privacy-preserving
and collaborative learning approach, to continuously improve a central model
that exhibits robustness when tackling different target groups and languages.
By keeping the training local to the users' devices, we ensure the privacy of
the users' data while benefitting from the efficiency of federated learning.
Furthermore, we personalize client models to target-specific training data and
evaluate their performance. Our results indicate the effectiveness of FL across
different target groups, whereas the benefits of personalization on few-shot
learning are not clear.

æè¦ï¼å¨ç·ä»æ¨è¨è«å°æ¼å°æ¸æç¾¤ä¾èªªä»ç¶æ¯ä¸åç ç©¶ä¸è¶³çåé¡ï¼ä¸¦ä¸è¶ä¾è¶éè¦ï¼ç¹å¥æ¯å¨å¨çåæ¹ï¼å¶ä¸­åæ¬ç¶²è·¯æ®åçè¶ä¾è¶é«çéç¼ä¸­åå®¶ãå¨æ¬æä¸­ï¼æåæ¨å¨çºçæ´»å¨ä¸»æµèªè¨çºä½è³æºèªè¨çç¤¾æä¸­çå°æ¸æç¾¤æä¾ä¸åä¿è­·é±ç§çå·¥å·ï¼ä»¥éééæ¿¾æ¯èªä¸­çæ»ææ§å§å®¹ä¾ä¿è­·ä»ååæ¼ç¶²è·¯ä¸çä»æ¨è¨è«ãæåå¨æ¬æä¸­çè²¢ç»æå©åï¼1ï¼æåç¼å¸äº REACTï¼èªå¢ä¸­çåæå¼ä»æ¨è¨è«è³æéï¼ï¼éæ¯ä¸åç±ç¶é©è±å¯çè³ææ¶éèç­åçé«åè³ªãç¹å®æåä»æ¨è¨è«åµæ¸¬è³æéï¼åå«å«ç¨®ä½è³æºèªè¨ä¸­çä¸åä¸åç®æ¨æç¾¤ï¼2ï¼æåæåºäºä¸åå©ç¨è¯çå¼å­¸ç¿ï¼FLï¼çå°ç¼è¨è«åµæ¸¬è§£æ±ºæ¹æ¡ï¼éæ¯ä¸ç¨®ä¿è­·é±ç§ååä½å­¸ç¿çæ¹æ³ï¼å¯ä»¥æçºæ¹åä¸åå¨èçä¸åç®æ¨æç¾¤åèªè¨æè¡¨ç¾åºç©©å¥æ§çä¸­å¤®æ¨¡åãééè®è¨ç·´ä¿æå¨ä½¿ç¨èçè£ç½®ä¸ï¼æåç¢ºä¿ä½¿ç¨èçè³æé±ç§ï¼åæåçæ¼è¯çå¼å­¸ç¿çæçãæ­¤å¤ï¼æåå°ç¨æ¶ç«¯æ¨¡ååäººåå°ç¹å®è¨ç·´è³æï¼ä¸¦è©ä¼°å¶æè½ãæåççµæé¡¯ç¤ºè¯çå¼å­¸ç¿å¨ä¸åç®æ¨æç¾¤ä¸­æ¯ææçï¼èåäººåå¨å°ç¼è¨è«å­¸ç¿ä¸­çåªé»åä¸æç¢ºã

##### **Who Speaks Next? Multi-party AI Discussion Leveraging the Systematics of Turn-taking in Murder Mystery Games**
2412.04937v1 by Ryota Nonomura, Hiroki Mori

Multi-agent systems utilizing large language models (LLMs) have shown great
promise in achieving natural dialogue. However, smooth dialogue control and
autonomous decision making among agents still remain challenges. In this study,
we focus on conversational norms such as adjacency pairs and turn-taking found
in conversation analysis and propose a new framework called "Murder Mystery
Agents" that applies these norms to AI agents' dialogue control. As an
evaluation target, we employed the "Murder Mystery" game, a reasoning-type
table-top role-playing game that requires complex social reasoning and
information manipulation. In this game, players need to unravel the truth of
the case based on fragmentary information through cooperation and bargaining.
The proposed framework integrates next speaker selection based on adjacency
pairs and a self-selection mechanism that takes agents' internal states into
account to achieve more natural and strategic dialogue. To verify the
effectiveness of this new approach, we analyzed utterances that led to dialogue
breakdowns and conducted automatic evaluation using LLMs, as well as human
evaluation using evaluation criteria developed for the Murder Mystery game.
Experimental results showed that the implementation of the next speaker
selection mechanism significantly reduced dialogue breakdowns and improved the
ability of agents to share information and perform logical reasoning. The
results of this study demonstrate that the systematics of turn-taking in human
conversation are also effective in controlling dialogue among AI agents, and
provide design guidelines for more advanced multi-agent dialogue systems.

æè¦ï¼å©ç¨å¤§åèªè¨æ¨¡å (LLM) çå¤ä¸»é«ç³»çµ±å¨å¯¦ç¾èªç¶å°è©±æ¹é¢å±ç¾äºæ¥µä½³çæ½åãç¶èï¼æµæ¢çå°è©±æ§å¶åä¸»é«éçèªä¸»æ±ºç­ä»æ¯ææ°ãå¨æ¬ç ç©¶ä¸­ï¼æåå°æ³¨æ¼å°è©±åæä¸­ç¼ç¾çé°æ¥å°åè¼ªæµç¼è¨ç­å°è©±è¦ç¯ï¼ä¸¦æåºä¸ååçºãè¬æ®ºè¬åä¸»é«ãçæ°æ¶æ§ï¼å°éäºè¦ç¯æç¨æ¼ AI ä¸»é«çå°è©±æ§å¶ãä½çºè©éç®æ¨ï¼æåæ¡ç¨ãè¬æ®ºè¬åãéæ²ï¼éæ¯ä¸æ¬¾æ¨çåæ¡ä¸è§è²æ®æ¼éæ²ï¼éè¦è¤éçç¤¾ææ¨çåè³è¨æç¸±ãå¨éåéæ²ä¸­ï¼ç©å®¶éè¦ééåä½åååï¼æ ¹æçæ·è³è¨è§£éæ¡ä»¶ççç¸ãææåºçæ¶æ§æ´åäºåºæ¼é°æ¥å°çä¸ä¸åç¼è¨èé¸æï¼ä»¥åèéä¸»é«å§é¨çæçèªæé¸ææ©å¶ï¼ä»¥å¯¦ç¾æ´èªç¶ä¸å·ç­ç¥æ§çå°è©±ãçºäºé©è­éåæ°æ¹æ³çæææ§ï¼æååæäºå°è´å°è©±ä¸­æ·çç¼è©±ï¼ä¸¦ä½¿ç¨ LLM é²è¡èªåè©éï¼ä»¥åä½¿ç¨çºè¬æ®ºè¬åéæ²éç¼çè©éæ¨æºé²è¡äººå·¥è©éãå¯¦é©çµæé¡¯ç¤ºï¼å¯¦æ½ä¸ä¸åç¼è¨èé¸ææ©å¶é¡¯èæ¸å°äºå°è©±ä¸­æ·ï¼ä¸¦æåäºä¸»é«åäº«è³è¨åé²è¡éè¼¯æ¨ççè½åãæ¬ç ç©¶çµæè­æï¼äººé¡å°è©±ä¸­è¼ªæµç¼è¨çç³»çµ±æ§å¨æ§å¶ AI ä¸»é«éçå°è©±æ¹é¢ä¹åæ¨£ææï¼ä¸¦çºæ´åé²çå¤ä¸»é«å°è©±ç³»çµ±æä¾äºè¨­è¨æ¹éã

##### **Probing the contents of semantic representations from text, behavior, and brain data using the psychNorms metabase**
2412.04936v1 by Zak Hussain, Rui Mata, Ben R. Newell, Dirk U. Wulff

Semantic representations are integral to natural language processing,
psycholinguistics, and artificial intelligence. Although often derived from
internet text, recent years have seen a rise in the popularity of
behavior-based (e.g., free associations) and brain-based (e.g., fMRI)
representations, which promise improvements in our ability to measure and model
human representations. We carry out the first systematic evaluation of the
similarities and differences between semantic representations derived from
text, behavior, and brain data. Using representational similarity analysis, we
show that word vectors derived from behavior and brain data encode information
that differs from their text-derived cousins. Furthermore, drawing on our
psychNorms metabase, alongside an interpretability method that we call
representational content analysis, we find that, in particular, behavior
representations capture unique variance on certain affective, agentic, and
socio-moral dimensions. We thus establish behavior as an important complement
to text for capturing human representations and behavior. These results are
broadly relevant to research aimed at learning human-aligned semantic
representations, including work on evaluating and aligning large language
models.

æè¦ï¼èªæè¡¨å¾µå°æ¼èªç¶èªè¨èçãå¿çèªè¨å­¸åäººå·¥æºæ§ä¾èªªæ¯ä¸å¯æç¼ºçãåç®¡ç¶å¸¸å¾ç¶²è·¯æå­ä¸­è¡çï¼ä½è¿å¹´ä¾è¡çºçºåºç¤ï¼ä¾å¦èªç±è¯æ³ï¼åè¦çºåºç¤ï¼ä¾å¦ fMRIï¼çè¡¨å¾µè¶ä¾è¶åå°æ­¡è¿ï¼éæææ¹åæåè¡¡éåå»ºæ¨¡äººé¡è¡¨å¾µçè½åãæåå°å¾æå­ãè¡çºåè¦é¨è³æè¡ççèªæè¡¨å¾µä¹éçç¸ä¼¼æ§åå·®ç°é²è¡äºé¦æ¬¡ç³»çµ±æ§è©ä¼°ãééä½¿ç¨è¡¨å¾µç¸ä¼¼æ§åæï¼æåé¡¯ç¤ºå¾è¡çºåè¦é¨è³æè¡ççè©åéç·¨ç¢¼çä¿¡æ¯ä¸åæ¼å¶å¾æå­è¡ççè¡¨è¦ªãæ­¤å¤ï¼å©ç¨æåç psychNorms åè³æåº«ï¼ä»¥åæåç¨±ä¹çºè¡¨å¾µå§å®¹åæçå¯è§£éæ§æ¹æ³ï¼æåç¼ç¾è¡çºè¡¨å¾µç¹å¥ææææäºææãè½ååç¤¾æéå¾·å±¤é¢çç¨ç¹è®ç°ãå æ­¤ï¼æåå°è¡çºç¢ºç«çºææäººé¡è¡¨å¾µåè¡çºçæå­éè¦è£åãéäºçµæèæ¨å¨å­¸ç¿èäººé¡ä¸è´çèªæè¡¨å¾µçç ç©¶å»£æ³ç¸éï¼åæ¬è©ä¼°åèª¿æ´å¤§åèªè¨æ¨¡åçå·¥ä½ã

##### **Uncertainty-aware retinal layer segmentation in OCT through probabilistic signed distance functions**
2412.04935v1 by Mohammad Mohaiminul Islam, Coen de Vente, Bart Liefers, Caroline Klaver, Erik J Bekkers, Clara I. SÃ¡nchez

In this paper, we present a new approach for uncertainty-aware retinal layer
segmentation in Optical Coherence Tomography (OCT) scans using probabilistic
signed distance functions (SDF). Traditional pixel-wise and regression-based
methods primarily encounter difficulties in precise segmentation and lack of
geometrical grounding respectively. To address these shortcomings, our
methodology refines the segmentation by predicting a signed distance function
(SDF) that effectively parameterizes the retinal layer shape via level set. We
further enhance the framework by integrating probabilistic modeling, applying
Gaussian distributions to encapsulate the uncertainty in the shape
parameterization. This ensures a robust representation of the retinal layer
morphology even in the presence of ambiguous input, imaging noise, and
unreliable segmentations. Both quantitative and qualitative evaluations
demonstrate superior performance when compared to other methods. Additionally,
we conducted experiments on artificially distorted datasets with various noise
types-shadowing, blinking, speckle, and motion-common in OCT scans to showcase
the effectiveness of our uncertainty estimation. Our findings demonstrate the
possibility to obtain reliable segmentation of retinal layers, as well as an
initial step towards the characterization of layer integrity, a key biomarker
for disease progression. Our code is available at
\url{https://github.com/niazoys/RLS_PSDF}.

æè¦ï¼<paragraph>å¨æ¬æä¸­ï¼æåæåºäºä¸ç¨®æ°çæ¹æ³ï¼ç¨æ¼åå­¸ç¸å¹²æ·å±¤ææ (OCT) ä¸­çä¸ç¢ºå®æ§è¦ç¶²èå±¤åå²ï¼ä½¿ç¨æ©çç°½ç½²è·é¢å½æ¸ (SDF)ãå³çµ±çéåç´ ååºæ¼åæ­¸çæ¹æ³ä¸»è¦å¨ç²¾ç¢ºåå²åç¼ºä¹å¹¾ä½åºç¤æ¹é¢éå°å°é£ãçºäºè§£æ±ºéäºç¼ºé»ï¼æåçç®æ³ééé æ¸¬ä¸åç°½ç½²è·é¢å½æ¸ (SDF) ä¾æ¹ååå²ï¼è©²å½æ¸ééæ°´å¹³éææå°åæ¸åè¦ç¶²èå±¤å½¢çãæåé²ä¸æ­¥ééæ´åæ©çå»ºæ¨¡ä¾å¢å¼·æ¡æ¶ï¼æç¨é«æ¯åå¸ä¾å°è£å½¢çåæ¸åçä¸ç¢ºå®æ§ãéç¢ºä¿äºè¦ç¶²èå±¤å½¢æçç©©å¥è¡¨ç¤ºï¼å³ä½¿å¨å­å¨æ¨¡ç³è¼¸å¥ãæåéè¨åä¸å¯é åå²çææ³ä¸ä¹æ¯å¦æ­¤ãèå¶ä»æ¹æ³ç¸æ¯ï¼å®éåå®æ§è©ä¼°é½è­æäºåªè¶çæ§è½ãæ­¤å¤ï¼æåå¨å·æåç¨®éè¨é¡åï¼é°å½±ãç¨ç¼ãæé»åéåï¼çäººå·¥æ­æ²æ¸æéä¸é²è¡äºå¯¦é©ï¼éäºéè¨é¡åå¨ OCT ææä¸­å¾å¸¸è¦ï¼ä»¥å±ç¤ºæåçä¸ç¢ºå®æ§ä¼°è¨çæææ§ãæåçç ç©¶çµæè­æäºç²å¾è¦ç¶²èå±¤å¯é åå²çå¯è½æ§ï¼ä»¥åæèè¡¨å¾µå±¤å®æ´æ§ï¼ç¾çé²å±çä¸åééµçç©æ¨èªï¼éåºçç¬¬ä¸æ­¥ãæåçä»£ç¢¼å¯ä»¥å¨ \url{https://github.com/niazoys/RLS_PSDF} ç²å¾ã</paragraph>

##### **Continuous Video Process: Modeling Videos as Continuous Multi-Dimensional Processes for Video Prediction**
2412.04929v1 by Gaurav Shrivastava, Abhinav Shrivastava

Diffusion models have made significant strides in image generation, mastering
tasks such as unconditional image synthesis, text-image translation, and
image-to-image conversions. However, their capability falls short in the realm
of video prediction, mainly because they treat videos as a collection of
independent images, relying on external constraints such as temporal attention
mechanisms to enforce temporal coherence. In our paper, we introduce a novel
model class, that treats video as a continuous multi-dimensional process rather
than a series of discrete frames. We also report a reduction of 75\% sampling
steps required to sample a new frame thus making our framework more efficient
during the inference time. Through extensive experimentation, we establish
state-of-the-art performance in video prediction, validated on benchmark
datasets including KTH, BAIR, Human3.6M, and UCF101. Navigate to the project
page https://www.cs.umd.edu/~gauravsh/cvp/supp/website.html for video results.}

æè¦ï¼æ´æ£æ¨¡åå¨å½±åçææ¹é¢åå¾é¡¯èé²å±ï¼ææ¡ç¡æ¢ä»¶å½±ååæãæå­å½±åç¿»è­¯åå½±åè½æç­ä»»åãç¶èï¼å®åå¨å½±çé æ¸¬é åçè½åä¸è¶³ï¼ä¸»è¦æ¯å çºå®åå°å½±çè¦çºç¨ç«å½±åçéåï¼ä¾è³´æ¼æéæ³¨æåæ©å¶ç­å¤é¨ç´æä¾å¼·å¶æéç¸å¹²æ§ãå¨æåçè«æä¸­ï¼æåå¼å¥äºä¸åæ°ç©çæ¨¡åé¡å¥ï¼å°å½±çè¦çºä¸åé£çºçå¤ç¶­éç¨ï¼èä¸æ¯ä¸ç³»åçé¢æ£å¹ãæåéå ±åäºå°æ¡æ¨£æ°å¹æéæ¡æ¨£æ­¥é©ç 75% æ¸å°ï¼å¾èä½¿æåçæ¡æ¶å¨æ¨çæéå§æ´ææçãééå»£æ³çå¯¦é©ï¼æåå»ºç«äºå½±çé æ¸¬çææ°æè¡ï¼é©è­äºåæ¬ KTHãBAIRãHuman3.6M å UCF101 å¨å§çåºæºè³æéãåå¾å°æ¡é é¢ https://www.cs.umd.edu/~gauravsh/cvp/supp/website.html ä»¥åå¾å½±ççµæã

##### **HyperGraphOS: A Meta Operating System for Science and Engineering**
2412.04923v1 by Antonello Ceravola, Frank Joublin, Ahmed R. Sadik, Bram Bolder, Juha-Pekka Tolvanen

This paper presents HyperGraphOS, an innovative Operating System designed for
the scientific and engineering domains. It combines model based engineering,
graph modeling, data containers, and computational tools, offering users a
dynamic workspace for creating and managing complex models represented as
customizable graphs. Using a web based architecture, HyperGraphOS requires only
a modern browser to organize knowledge, documents, and content into
interconnected models. Domain Specific Languages drive workspace navigation,
code generation, AI integration, and process organization.The platform models
function as both visual drawings and data structures, enabling dynamic
modifications and inspection, both interactively and programmatically.
HyperGraphOS was evaluated across various domains, including virtual avatars,
robotic task planning using Large Language Models, and meta modeling for
feature based code development. Results show significant improvements in
flexibility, data management, computation, and document handling.

æè¦ï¼æ¬ææåº HyperGraphOSï¼éæ¯ä¸ååµæ°çä½æ¥­ç³»çµ±ï¼å°çºç§å­¸åå·¥ç¨é åè¨­è¨ãå®çµåäºåºæ¼æ¨¡åçå·¥ç¨ãåå½¢å»ºæ¨¡ãè³æå®¹å¨åè¨ç®å·¥å·ï¼çºä½¿ç¨èæä¾ä¸ååæå·¥ä½ç©ºéï¼ç¨æ¼å»ºç«åç®¡çè¡¨ç¤ºçºå¯èªè¨åå½¢çè¤éæ¨¡åãHyperGraphOS ä½¿ç¨åºæ¼ Web çæ¶æ§ï¼åªéè¦ä¸åç¾ä»£çè¦½å¨å³å¯å°ç¥è­ãæä»¶åå§å®¹çµç¹æäºé£æ¨¡åãç¹å®é åèªè¨é©åå·¥ä½ç©ºéå°è¦½ãç¨å¼ç¢¼ç¢çãAI æ´ååæµç¨çµç¹ãå¹³å°æ¨¡ååæä½çºè¦è¦ºç¹ªååè³æçµæ§ï¼æ¯æ´åæä¿®æ¹åæª¢æ¥ï¼ç¡è«æ¯äºåå¼éæ¯ä»¥ç¨å¼æ¹å¼é²è¡ãHyperGraphOS å·²å¨åç¨®é åä¸­é²è¡è©ä¼°ï¼åæ¬èæ¬åèº«ãä½¿ç¨å¤§åèªè¨æ¨¡åçæ©å¨äººä»»åè¦åï¼ä»¥åç¨æ¼åºæ¼ç¹å¾µçç¨å¼ç¢¼éç¼çåå»ºæ¨¡ãçµæé¡¯ç¤ºåºéæ´»æ§ãè³æç®¡çãéç®åæä»¶èçæ¹é¢çé¡¯èæ¹é²ã

##### **Large Language Models for Ingredient Substitution in Food Recipes using Supervised Fine-tuning and Direct Preference Optimization**
2412.04922v1 by Thevin Senath, Kumuthu Athukorala, Ransika Costa, Surangika Ranathunga, Rishemjit Kaur

In this paper, we address the challenge of recipe personalization through
ingredient substitution. We make use of Large Language Models (LLMs) to build
an ingredient substitution system designed to predict plausible substitute
ingredients within a given recipe context. Given that the use of LLMs for this
task has been barely done, we carry out an extensive set of experiments to
determine the best LLM, prompt, and the fine-tuning setups. We further
experiment with methods such as multi-task learning, two-stage fine-tuning, and
Direct Preference Optimization (DPO). The experiments are conducted using the
publicly available Recipe1MSub corpus. The best results are produced by the
Mistral7-Base LLM after fine-tuning and DPO. This result outperforms the strong
baseline available for the same corpus with a Hit@1 score of 22.04. Thus we
believe that this research represents a significant step towards enabling
personalized and creative culinary experiences by utilizing LLM-based
ingredient substitution.

æè¦ï¼å¨æ¬æä¸­ï¼æä»¬ééé£ææ¿æä¾è§£æ±ºé£è­åäººåçææ°ãæåä½¿ç¨å¤§åèªè¨æ¨¡å (LLM) ä¾å»ºæ§é£ææ¿æç³»çµ±ï¼æ¨å¨é æ¸¬å¨çµ¦å®é£è­èæ¯ä¸åççæ¿ä»£é£æãç±æ¼é®®å°å° LLM ç¨æ¼æ­¤ä»»åï¼å æ­¤æåé²è¡äºä¸ç³»åå»£æ³çå¯¦é©ï¼ä»¥æ¾åºæä½³ç LLMãæç¤ºåå¾®èª¿è¨­å®ãæåé²ä¸æ­¥åè©¦å¤ä»»åå­¸ç¿ãå©éæ®µå¾®èª¿åç´æ¥åå¥½æä½³å (DPO) ç­æ¹æ³ãéäºå¯¦é©æ¯ä½¿ç¨å¬éç Recipe1MSub èªæåº«é²è¡çãå¾®èª¿å DPO å¾ï¼Mistral7-Base LLM ç¢çäºæä½³çµæãæ­¤çµæåªæ¼éå°ç¸åèªæåº«æä¾çå¼·å¤§åºæºï¼å¶ Hit@1 åæ¸çº 22.04ãå æ­¤ï¼æåç¸ä¿¡éé ç ç©¶ä»£è¡¨èå©ç¨åºæ¼ LLM çé£ææ¿æï¼æèå¯¦ç¾åäººåä¸å¯æåµæçæçé«é©éåºäºä¸å¤§æ­¥ã

##### **DEMO: Reframing Dialogue Interaction with Fine-grained Element Modeling**
2412.04905v1 by Minzheng Wang, Xinghua Zhang, Kun Chen, Nan Xu, Haiyang Yu, Fei Huang, Wenji Mao, Yongbin Li

Large language models (LLMs) have made dialogue one of the central modes of
human-machine interaction, leading to the accumulation of vast amounts of
conversation logs and increasing demand for dialogue generation. A
conversational life-cycle spans from the Prelude through the Interlocution to
the Epilogue, encompassing various elements. Despite the existence of numerous
dialogue-related studies, there is a lack of benchmarks that encompass
comprehensive dialogue elements, hindering precise modeling and systematic
evaluation. To bridge this gap, we introduce an innovative research task
$\textbf{D}$ialogue $\textbf{E}$lement $\textbf{MO}$deling, including
$\textit{Element Awareness}$ and $\textit{Dialogue Agent Interaction}$, and
propose a novel benchmark, $\textbf{DEMO}$, designed for a comprehensive
dialogue modeling and assessment. Inspired by imitation learning, we further
build the agent which possesses the adept ability to model dialogue elements
based on the DEMO benchmark. Extensive experiments indicate that existing LLMs
still exhibit considerable potential for enhancement, and our DEMO agent has
superior performance in both in-domain and out-of-domain tasks.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²å°å°è©±ä½çºäººæ©äºåçä¸»è¦æ¨¡å¼ä¹ä¸ï¼å°è´å°è©±è¨éå¤§éç´¯ç©ï¼å°è©±çæçéæ±ä¹é¨ä¹å¢å ãå°è©±çå½é±æå¾åºå¹è·¨è¶å°å°è©±ï¼åå°å°¾è²ï¼æ¶µèåç¨®åç´ ãåç®¡æè¨±å¤èå°è©±ç¸éçç ç©¶ï¼ä½ç¼ºä¹åå«å¨é¢å°è©±åç´ çåºæºï¼é»ç¤äºç²¾ç¢ºå»ºæ¨¡åç³»çµ±æ§è©ä¼°ãçºäºå½è£éä¸å·®è·ï¼æåå¼å¥äºä¸é åµæ°çç ç©¶ä»»å $\textbf{D}$ialogue $\textbf{E}$lement $\textbf{MO}$delingï¼åæ¬ $\textit{Element Awareness}$ å $\textit{Dialogue Agent Interaction}$ï¼ä¸¦æåºäºä¸åæ°çåºæº $\textbf{DEMO}$ï¼å°éç¨æ¼å¨é¢çå°è©±å»ºæ¨¡åè©ä¼°ãåå°æ¨¡ä»¿å­¸ç¿çåç¼ï¼æåé²ä¸æ­¥å»ºç«äºä»£çï¼å®å·åæ ¹æ DEMO åºæºå°è©±åç´ é²è¡å»ºæ¨¡çéå·§è½åãå¤§éçå¯¦é©è¡¨æï¼ç¾æç LLM ä»å±ç¾åºç¸ç¶å¤§çå¢å¼·æ½åï¼èæåç DEMO ä»£çå¨é åå§åé åå¤ä»»åä¸­é½å·æåè¶çæ§è½ã

##### **EACO: Enhancing Alignment in Multimodal LLMs via Critical Observation**
2412.04903v1 by Yongxin Wang, Meng Cao, Haokun Lin, Mingfei Han, Liang Ma, Jin Jiang, Yuhao Cheng, Xiaodan Liang

Multimodal large language models (MLLMs) have achieved remarkable progress on
various visual question answering and reasoning tasks leveraging instruction
fine-tuning specific datasets. They can also learn from preference data
annotated by human to enhance their reasoning ability and mitigate
hallucinations. Most of preference data is generated from the model itself.
However, existing methods require high-quality critical labels, which are
costly and rely on human or proprietary models like GPT-4V. In this work, we
propose Enhancing Alignment in MLLMs via Critical Observation (EACO), which
aligns MLLMs by self-generated preference data using only 5k images
economically. Our approach begins with collecting and refining a Scoring
Evaluation Instruction-tuning dataset to train a critical evaluation model,
termed the Critic. This Critic observes model responses across multiple
dimensions, selecting preferred and non-preferred outputs for refined Direct
Preference Optimization (DPO) tuning. To further enhance model performance, we
employ an additional supervised fine-tuning stage after preference tuning. EACO
reduces the overall hallucinations by 65.6% on HallusionBench and improves the
reasoning ability by 21.8% on MME-Cognition. EACO achieves an 8.5% improvement
over LLaVA-v1.6-Mistral-7B across multiple benchmarks. Remarkably, EACO also
shows the potential critical ability in open-source MLLMs, demonstrating that
EACO is a viable path to boost the competence of MLLMs.

æè¦ï¼å¤æ¨¡æå¤§åè¯­è¨æ¨¡å (MLLM) å¨åç§è§è§é®é¢è§£ç­åæ¨çä»»å¡ä¸åå¾äºæ¾èè¿å±ï¼å©ç¨æä»¤å¾®è°ç¹å®æ°æ®éãå®ä»¬è¿å¯ä»¥ä»äººç±»æ æ³¨çé¦éé¡¹æ°æ®ä¸­å­¦ä¹ ï¼ä»¥å¢å¼ºå¶æ¨çè½åå¹¶åè½»å¹»è§ãå¤§å¤æ°é¦éé¡¹æ°æ®é½æ¯ç±æ¨¡åæ¬èº«çæçãç¶èï¼ç°ææ¹æ³éè¦é«è´¨éçå³é®æ ç­¾ï¼è¿æ¢æè´µåä¾èµäº GPT-4V ç­äººç±»æä¸ææ¨¡åãå¨è¿é¡¹å·¥ä½ä¸­ï¼æä»¬æåºäºéè¿å³é®è§å¯ï¼EACOï¼å¢å¼º MLLM ä¸­çå¯¹é½ï¼å®ä»ä½¿ç¨ 5k å¼ å¾åç»æµå°éè¿èªçæçåå¥½æ°æ®å¯¹é½ MLLMãæä»¬çæ¹æ³é¦åä»æ¶éåä¼åè¯åè¯ä¼°æä»¤è°æ´æ°æ®éå¼å§ï¼ä»¥è®­ç»ä¸ä¸ªå³é®è¯ä¼°æ¨¡åï¼ç§°ä¸º Criticãè¯¥ Critic è§å¯è·¨å¤ä¸ªç»´åº¦çæ¨¡åååºï¼ä¸ºæ¹è¿çç´æ¥åå¥½ä¼å (DPO) è°æ´éæ©é¦éåéé¦éè¾åºãä¸ºäºè¿ä¸æ­¥æé«æ¨¡åæ§è½ï¼æä»¬å¨åå¥½è°æ´åéç¨äºé¢å¤ççç£å¾®è°é¶æ®µãEACO å¨ HallusionBench ä¸å°æ´ä½å¹»è§åå°äº 65.6%ï¼å¹¶å¨ MME-Cognition ä¸å°æ¨çè½åæé«äº 21.8%ãEACO å¨å¤ä¸ªåºåæµè¯ä¸­æ¯ LLaVA-v1.6-Mistral-7B æé«äº 8.5%ãå¼å¾æ³¨æçæ¯ï¼EACO ä¹æ¾ç¤ºäºå¼æº MLLM ä¸­æ½å¨çå³é®è½åï¼è¿è¡¨æ EACO æ¯æå MLLM è½åçå¯è¡éå¾ã

##### **AI-Driven Non-Invasive Detection and Staging of Steatosis in Fatty Liver Disease Using a Novel Cascade Model and Information Fusion Techniques**
2412.04884v1 by Niloufar Delfan, Pardis Ketabi Moghadam, Mohammad Khoshnevisan, Mehdi Hosseini Chagahi, Behzad Hatami, Melika Asgharzadeh, Mohammadreza Zali, Behzad Moshiri, Amin Momeni Moghaddam, Mohammad Amin Khalafi, Khosrow Dehnad

Non-alcoholic fatty liver disease (NAFLD) is one of the most widespread liver
disorders on a global scale, posing a significant threat of progressing to more
severe conditions like nonalcoholic steatohepatitis (NASH), liver fibrosis,
cirrhosis, and hepatocellular carcinoma. Diagnosing and staging NAFLD presents
challenges due to its non-specific symptoms and the invasive nature of liver
biopsies. Our research introduces a novel artificial intelligence cascade model
employing ensemble learning and feature fusion techniques. We developed a
non-invasive, robust, and reliable diagnostic artificial intelligence tool that
utilizes anthropometric and laboratory parameters, facilitating early detection
and intervention in NAFLD progression. Our novel artificial intelligence
achieved an 86% accuracy rate for the NASH steatosis staging task (non-NASH,
steatosis grade 1, steatosis grade 2, and steatosis grade 3) and an impressive
96% AUC-ROC for distinguishing between NASH (steatosis grade 1, grade 2, and
grade3) and non-NASH cases, outperforming current state-of-the-art models. This
notable improvement in diagnostic performance underscores the potential
application of artificial intelligence in the early diagnosis and treatment of
NAFLD, leading to better patient outcomes and a reduced healthcare burden
associated with advanced liver disease.

æè¦ï¼ééç²¾æ§èèªèç¾ç (NAFLD) æ¯å¨çææ®éçèèç¾çä¹ä¸ï¼å®æå´éå¨èé²å±ææ´å´éçç¾çï¼ä¾å¦ééç²¾æ§èèªæ§èç (NASH)ãèçºç¶­åãèç¡¬ååèç´°èçãè¨ºæ·ååæ NAFLD å·æææ°æ§ï¼å çºå®çççä¸å·ç¹ç°æ§ï¼èä¸èèæ´»æª¢å·æä¾µå¥æ§ãæåçç ç©¶å¼å¥äºä¸åæ°çäººå·¥æºæ§ä¸²è¯æ¨¡åï¼æ¡ç¨æ´åå­¸ç¿åç¹å¾µèåæè¡ãæåéç¼äºä¸åéä¾µå¥æ§ãç©©å¥ä¸å¯é çè¨ºæ·äººå·¥æºæ§å·¥å·ï¼å©ç¨äººé¡æ¸¬éåå¯¦é©å®¤åæ¸ï¼ä¿é² NAFLD é²å±çæ©ææª¢æ¸¬åå¹²é ãæåæ°çäººå·¥æºæ§å¨ NASH èèªè®æ§åæä»»åï¼é NASHãèèªè®æ§ 1 ç´ãèèªè®æ§ 2 ç´åèèªè®æ§ 3 ç´ï¼ä¸­éå° 86% çæºç¢ºçï¼ä¸¦ä¸å¨åå NASHï¼èèªè®æ§ 1 ç´ã2 ç´å 3 ç´ï¼åé NASH çä¾æ¹é¢éå°ä»¤äººå°è±¡æ·±å»ç 96% AUC-ROCï¼åªæ¼ç¶åæåé²çæ¨¡åãéç¨®è¨ºæ·æè½çé¡¯èæåçªé¡¯äºäººå·¥æºæ§å¨ NAFLD æ©æè¨ºæ·åæ²»çä¸­çæ½å¨æç¨ï¼å¾èå°è´æ´å¥½çæ£èé å¾åéä½èææèçç¸éçé«çä¿å¥è² æã

##### **Building a Family of Data Augmentation Models for Low-cost LLM Fine-tuning on the Cloud**
2412.04871v1 by Yuanhao Yue, Chengyu Wang, Jun Huang, Peng Wang

Specializing LLMs in various domain-specific tasks has emerged as a critical
step towards achieving high performance. However, the construction and
annotation of datasets in specific domains are always very costly. Apart from
using superior and expensive closed-source LLM APIs to construct datasets, some
open-source models have become strong enough to handle dataset construction in
many scenarios. Thus, we present a family of data augmentation models designed
to significantly improve the efficiency for model fine-tuning. These models,
trained based on sufficiently small LLMs, support key functionalities with low
inference costs: instruction expansion, instruction refinement, and
instruction-response pair expansion. To fulfill this goal, we first construct
an automatic data collection system with seed datasets generated from both
public repositories and our in-house datasets. This system leverages powerful
LLMs to expand, refine and re-write the instructions and responses,
incorporating quality assessment techniques. Following this, we introduce the
training process of our models, which effectively distills task-solving and
text synthesis abilities from teacher LLMs. Finally, we demonstrate how we
integrate these functionalities into a machine learning platform to support
low-cost LLM fine-tuning from both dataset preparation and training
perspectives for users. Experiments and an application study prove the
effectiveness of our approach.

æè¦ï¼å° LLM å°éç¨æ¼åç¨®ç¹å®é åä»»åå·²æçºå¯¦ç¾é«æ§è½çä¸é ééµæ­¥é©ãç¶èï¼å¨ç¹å®é åæ§å»ºåè¨»è§£è³æéçææ¬ç¸½æ¯ååé«æãé¤äºä½¿ç¨åªè¶ä¸æè²´çå°éåå§ç¢¼ LLM API ä¾æ§å»ºè³æéä¹å¤ï¼ä¸äºéæ¾åå§ç¢¼æ¨¡åå·²è®å¾è¶³å¤ å¼·å¤§ï¼è¶³ä»¥å¨è¨±å¤å ´æ¯ä¸­èçè³æéæ§å»ºãå æ­¤ï¼æåæåºäºä¸ç³»åæ¸ææ´åæ¨¡åï¼æ¨å¨é¡¯èæé«æ¨¡åå¾®èª¿çæçãéäºæ¨¡ååºæ¼è¶³å¤ å°ç LLM é²è¡è¨ç·´ï¼æ¯æ´å·æä½æ¨è«ææ¬çä¸»è¦åè½ï¼æä»¤æ´åãæä»¤æ¹é²åæä»¤åæéå°æ´åãçºå¯¦ç¾æ­¤ç®æ¨ï¼æåé¦åä½¿ç¨å¾å¬å±å²å­åº«åæåå§é¨è³æéç¢ççç¨®å­è³æéæ§å»ºèªåæ¸ææ¶éç³»çµ±ãæ­¤ç³»çµ±å©ç¨å¼·å¤§ç LLM ä¾æ´åãæ¹é²åéå¯«æä»¤ååæï¼ä¸¦ç´å¥åè³ªè©ä¼°æè¡ãå¨æ­¤ä¹å¾ï¼æåä»ç´¹äºæåæ¨¡åçè¨ç·´éç¨ï¼è©²éç¨ææå°å¾æå¸« LLM ä¸­æçäºè§£æ±ºä»»ååæå­åæè½åãæå¾ï¼æåå±ç¤ºäºå¦ä½å°éäºåè½æ´åå°æ©å¨å­¸ç¿å¹³å°ä¸­ï¼ä»¥æ¯æ´ä½¿ç¨èå¾è³æéæºååè¨ç·´è§åº¦é²è¡ä½ææ¬ LLM å¾®èª¿ãå¯¦é©åæç¨ç ç©¶è­æäºæåæ¹æ³çæææ§ã

##### **NebulaFL: Effective Asynchronous Federated Learning for JointCloud Computing**
2412.04868v1 by Fei Gao, Ming Hu, Zhiyu Xie, Peichang Shi, Xiaofei Xie, Guodong Yi, Huaimin Wang

With advancements in AI infrastructure and Trusted Execution Environment
(TEE) technology, Federated Learning as a Service (FLaaS) through JointCloud
Computing (JCC) is promising to break through the resource constraints caused
by heterogeneous edge devices in the traditional Federated Learning (FL)
paradigm. Specifically, with the protection from TEE, data owners can achieve
efficient model training with high-performance AI services in the cloud. By
providing additional FL services, cloud service providers can achieve
collaborative learning among data owners. However, FLaaS still faces three
challenges, i.e., i) low training performance caused by heterogeneous data
among data owners, ii) high communication overhead among different clouds
(i.e., data centers), and iii) lack of efficient resource scheduling strategies
to balance training time and cost. To address these challenges, this paper
presents a novel asynchronous FL approach named NebulaFL for collaborative
model training among multiple clouds. To address data heterogeneity issues,
NebulaFL adopts a version control-based asynchronous FL training scheme in each
data center to balance training time among data owners. To reduce communication
overhead, NebulaFL adopts a decentralized model rotation mechanism to achieve
effective knowledge sharing among data centers. To balance training time and
cost, NebulaFL integrates a reward-guided strategy for data owners selection
and resource scheduling. The experimental results demonstrate that, compared to
the state-of-the-art FL methods, NebulaFL can achieve up to 5.71\% accuracy
improvement. In addition, NebulaFL can reduce up to 50% communication overhead
and 61.94% costs under a target accuracy.

æè¦ï¼<paragraph>é¨è AI åºç¤è¨­æ½åå¯ä¿¡å·è¡ç°å¢ (TEE) æè¡çé²æ­¥ï¼ééè¯åé²ç«¯éç® (JCC) çè¯åå­¸ç¿å³æå (FLaaS) ææçªç ´å³çµ±è¯åå­¸ç¿ (FL) å¸ç¯ä¸­ç°è³ªéç·£è£ç½®æé æçè³æºéå¶ãå·é«ä¾èªªï¼éé TEE çä¿è­·ï¼è³æææèå¯ä»¥å¨é²ç«¯ä¸­ééé«æ§è½ AI æåéæææççæ¨¡åè¨ç·´ãé²ç«¯æåä¾æåééæä¾é¡å¤ç FL æåï¼å¯ä»¥å¨è³æææèä¹ééæåä½å­¸ç¿ãç¶èï¼FLaaS ä»é¢è¨ä¸é ææ°ï¼å³ï¼ä¸) è³æææèä¹éçç°è³ªè³ææé æçä½è¨ç·´æè½ãäº) ä¸åé²ç«¯ (å³è³æä¸­å¿) ä¹éçé«éè¨è² æï¼ä»¥åä¸) ç¼ºä¹ææççè³æºæç¨ç­ç¥ä¾å¹³è¡¡è¨ç·´æéåææ¬ãçºäºå æéäºææ°ï¼æ¬ææåºåçº NebulaFL çåµæ°éåæ­¥ FL æ¹æ³ï¼ç¨æ¼å¤åé²ç«¯ä¹éçåä½æ¨¡åè¨ç·´ãçºäºå æè³æç°è³ªæ§çåé¡ï¼NebulaFL å¨æ¯åè³æä¸­å¿æ¡ç¨åºæ¼çæ¬æ§å¶çéåæ­¥ FL è¨ç·´æ¹æ¡ï¼ä»¥å¹³è¡¡è³æææèä¹éçè¨ç·´æéãçºäºéä½éè¨è² æï¼NebulaFL æ¡ç¨åæ£å¼æ¨¡åè¼ªæ¿æ©å¶ï¼ä»¥å¨è³æä¸­å¿ä¹ééæææçç¥è­åäº«ãçºäºå¹³è¡¡è¨ç·´æéåææ¬ï¼NebulaFL æ´åäºçåµå¼å°ç­ç¥ï¼ç¨æ¼è³æææèé¸æåè³æºæç¨ãå¯¦é©çµæé¡¯ç¤ºï¼èç¾æç FL æ¹æ³ç¸æ¯ï¼NebulaFL å¯éæé«é 5.71% çæºç¢ºåº¦æåãæ­¤å¤ï¼NebulaFL å¨ç®æ¨æºç¢ºåº¦ä¸å¯éä½é«é 50% çéè¨è² æå 61.94% çææ¬ã</paragraph>

##### **EXAONE 3.5: Series of Large Language Models for Real-world Use Cases**
2412.04862v1 by LG AI Research, Soyoung An, Kyunghoon Bae, Eunbi Choi, Kibong Choi, Stanley Jungkyu Choi, Seokhee Hong, Junwon Hwang, Hyojin Jeon, Gerrard Jeongwon Jo, Hyunjik Jo, Jiyeon Jung, Yountae Jung, Hyosang Kim, Joonkee Kim, Seonghwan Kim, Soyeon Kim, Sunkyoung Kim, Yireun Kim, Yongil Kim, Youchul Kim, Edward Hwayoung Lee, Haeju Lee, Honglak Lee, Jinsik Lee, Kyungmin Lee, Woohyung Lim, Sangha Park, Sooyoun Park, Yongmin Park, Sihoon Yang, Heuiyeen Yeen, Hyeongu Yun

This technical report introduces the EXAONE 3.5 instruction-tuned language
models, developed and released by LG AI Research. The EXAONE 3.5 language
models are offered in three configurations: 32B, 7.8B, and 2.4B. These models
feature several standout capabilities: 1) exceptional instruction following
capabilities in real-world scenarios, achieving the highest scores across seven
benchmarks, 2) outstanding long-context comprehension, attaining the top
performance in four benchmarks, and 3) competitive results compared to
state-of-the-art open models of similar sizes across nine general benchmarks.
The EXAONE 3.5 language models are open to anyone for research purposes and can
be downloaded from https://huggingface.co/LGAI-EXAONE. For commercial use,
please reach out to the official contact point of LG AI Research:
contact_us@lgresearch.ai.

æè¦ï¼éä»½æè¡å ±åä»ç´¹äº LG AI Research éç¼ä¸¦ç¼å¸ç EXAONE 3.5 æä»¤èª¿æ´èªè¨æ¨¡åãEXAONE 3.5 èªè¨æ¨¡åæä¾ä¸ç¨®éç½®ï¼32Bã7.8B å 2.4Bãéäºæ¨¡åå·æå¹¾é ååºçåè½ï¼1) å¨ç¾å¯¦ä¸çå ´æ¯ä¸­å·æåºè²çæä»¤éµå¾ªè½åï¼å¨ä¸é åºæºæ¸¬è©¦ä¸­ç²å¾æé«åï¼2) åºè²çé·èªå¢çè§£è½åï¼å¨åé åºæºæ¸¬è©¦ä¸­ç²å¾æé«ç¸¾æï¼ä»¥å 3) èä¹é ä¸è¬åºæºæ¸¬è©¦ä¸­é¡ä¼¼è¦æ¨¡çææ°éæ¾æ¨¡åç¸æ¯å·æç«¶ç­åççµæãEXAONE 3.5 èªè¨æ¨¡åå°ä»»ä½ç ç©¶ç®çéæ¾ï¼å¯å¾ https://huggingface.co/LGAI-EXAONE ä¸è¼ãå¦è¦åæ¥­ä½¿ç¨ï¼è«è¯ç¹« LG AI Research çå®æ¹è¯çµ¡é»ï¼contact_us@lgresearch.aiã

##### **Breaking Event Rumor Detection via Stance-Separated Multi-Agent Debate**
2412.04859v1 by Mingqing Zhang, Haisong Gong, Qiang Liu, Shu Wu, Liang Wang

The rapid spread of rumors on social media platforms during breaking events
severely hinders the dissemination of the truth. Previous studies reveal that
the lack of annotated resources hinders the direct detection of unforeseen
breaking events not covered in yesterday's news. Leveraging large language
models (LLMs) for rumor detection holds significant promise. However, it is
challenging for LLMs to provide comprehensive responses to complex or
controversial issues due to limited diversity. In this work, we propose the
Stance Separated Multi-Agent Debate (S2MAD) to address this issue.
Specifically, we firstly introduce Stance Separation, categorizing comments as
either supporting or opposing the original claim. Subsequently, claims are
classified as subjective or objective, enabling agents to generate reasonable
initial viewpoints with different prompt strategies for each type of claim.
Debaters then follow specific instructions through multiple rounds of debate to
reach a consensus. If a consensus is not reached, a judge agent evaluates the
opinions and delivers a final verdict on the claim's veracity. Extensive
experiments conducted on two real-world datasets demonstrate that our proposed
model outperforms state-of-the-art methods in terms of performance and
effectively improves the performance of LLMs in breaking event rumor detection.

æè¦ï¼å¨çªç¼äºä»¶æéï¼è¬ è¨å¨ç¤¾ç¾¤åªé«å¹³å°ä¸çå¿«éå³æ­å´éé»ç¤äºçç¸çå³æ­ãååçç ç©¶è¡¨æï¼ç¼ºä¹è¨»è§£è³æºé»ç¤äºå°æ¨æ¥æ°èæªæ¶µèççªç¼äºä»¶çç´æ¥åµæ¸¬ãå©ç¨å¤§åèªè¨æ¨¡å (LLM) é²è¡è¬ è¨åµæ¸¬å·æé¡¯èçæ½åãç¶èï¼ç±æ¼å¤æ¨£æ§æéï¼LLM é£ä»¥å°è¤éææç­è­°çåé¡æä¾å¨é¢çåæãå¨éé å·¥ä½ä¸­ï¼æåæåºç«å ´åéçå¤ä¸»é«è¾¯è« (S2MAD) ä¾è§£æ±ºéååé¡ãå·é«ä¾èªªï¼æåé¦åå¼å¥ç«å ´åéï¼å°è©è«åé¡çºæ¯ææåå°åå§èªªæ³ãé¨å¾ï¼å°èªªæ³åé¡çºä¸»è§æå®¢è§ï¼ä½¿ä¸»é«è½å¤ éå°æ¯ç¨®é¡åçèªªæ³ç¢çåççåå§è§é»ï¼ä¸¦æ¡ç¨ä¸åçæç¤ºç­ç¥ãç¶å¾ï¼è¾¯è«èéµå¾ªå·é«çæç¤ºé²è¡å¤è¼ªè¾¯è«ï¼ä»¥éæå±è­ãå¦ææªéæå±è­ï¼æ³å®ä¸»é«æè©ä¼°æè¦ä¸¦å°èªªæ³ççå¯¦æ§ååºæçµè£æ±ºãå¨å©åçå¯¦ä¸çè³æéä¸é²è¡çå»£æ³å¯¦é©è¡¨æï¼æåæåºçæ¨¡åå¨æè½æ¹é¢åªæ¼æåé²çæ¹æ³ï¼ä¸¦æææåäº LLM å¨çªç¼äºä»¶è¬ è¨åµæ¸¬ä¸­çæè½ã

##### **Neuro-Symbolic Data Generation for Math Reasoning**
2412.04857v1 by Zenan Li, Zhi Zhou, Yuan Yao, Yu-Feng Li, Chun Cao, Fan Yang, Xian Zhang, Xiaoxing Ma

A critical question about Large Language Models (LLMs) is whether their
apparent deficiency in mathematical reasoning is inherent, or merely a result
of insufficient exposure to high-quality mathematical data. To explore this, we
developed an automated method for generating high-quality, supervised
mathematical datasets. The method carefully mutates existing math problems,
ensuring both diversity and validity of the newly generated problems. This is
achieved by a neuro-symbolic data generation framework combining the intuitive
informalization strengths of LLMs, and the precise symbolic reasoning of math
solvers along with projected Markov chain Monte Carlo sampling in the
highly-irregular symbolic space. Empirical experiments demonstrate the high
quality of data generated by the proposed method, and that the LLMs,
specifically LLaMA-2 and Mistral, when realigned with the generated data,
surpass their state-of-the-art counterparts.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çä¸åééµåé¡æ¯å®åå¨æ¸å­¸æ¨çä¸çæé¡¯ç¼ºé·æ¯åºæçï¼éæ¯ååæ¯æ¥è§¸é«åè³ªæ¸å­¸è³æä¸è¶³ççµæãçºäºæ¢è¨éä¸é»ï¼æåéç¼äºä¸ç¨®èªååæ¹æ³ä¾çæé«åè³ªãæç£ç£çæ¸å­¸è³æéãæ­¤æ¹æ³ä»ç´°å°è®ç°ç¾æçæ¸å­¸åé¡ï¼ç¢ºä¿æ°çæåé¡çå¤æ¨£æ§åæææ§ãéæ¯ééç¥ç¶ç¬¦èè³æçææ¶æ§ä¾å¯¦ç¾çï¼çµåäº LLM ç´è§çéæ­£è¦ååªå¢ï¼ä»¥åæ¸å­¸æ±è§£å¨çç²¾ç¢ºç¬¦èæ¨çï¼ä»¥åå¨é«åº¦ä¸è¦åçç¬¦èç©ºéä¸­é æ¸¬çé¦¬å¯å¤«éèå°å¡ç¾æ½æ¨£ãå¯¦è­å¯¦é©è­æäºææåºçæ¹æ³çæè³æçé«åè³ªï¼ä»¥å LLMï¼ç¹å¥æ¯ LLaMA-2 å Mistralï¼å¨èçæè³æéæ°å°é½å¾ï¼è¶è¶äºå®åæåé²çå°ææ¨¡åã

##### **MTSpark: Enabling Multi-Task Learning with Spiking Neural Networks for Generalist Agents**
2412.04847v1 by Avaneesh Devkota, Rachmad Vidya Wicaksana Putra, Muhammad Shafique

Currently, state-of-the-art RL methods excel in single-task settings, but
they still struggle to generalize across multiple tasks due to catastrophic
forgetting challenges, where previously learned tasks are forgotten as new
tasks are introduced. This multi-task learning capability is significantly
important for generalist agents, where adaptation features are highly required
(e.g., autonomous robots). On the other hand, Spiking Neural Networks (SNNs)
have emerged as alternative energy-efficient neural network algorithms due to
their sparse spike-based operations. Toward this, we propose MTSpark, a novel
methodology to enable multi-task RL using spiking networks. Specifically,
MTSpark develops a Deep Spiking Q-Network (DSQN) with active dendrites and
dueling structure by leveraging task-specific context signals. Specifically,
each neuron computes task-dependent activations that dynamically modulate
inputs, forming specialized sub-networks for each task. Moreover, this
bioplausible network model also benefits from SNNs, enhancing energy efficiency
and making the model suitable for hardware implementation. Experimental results
show that, our MTSpark effectively learns multiple tasks with higher
performance compared to the state-of-the-art. Specifically, MTSpark
successfully achieves high score in three Atari games (i.e., Pong: -5.4,
Breakout: 0.6, and Enduro: 371.2), reaching human-level performance (i.e.,
Pong: -3, Breakout: 31, and Enduro: 368), where state-of-the-art struggle to
achieve. In addition, our MTSpark also shows better accuracy in image
classification tasks than the state-of-the-art. These results highlight the
potential of our MTSpark methodology to develop generalist agents that can
learn multiple tasks by leveraging both RL and SNN concepts.

æè¦ï¼<paragraph>ç®åï¼æåé²ç RL æ¹æ³å¨å®ä¸ä»»åè¨­å®ä¸­è¡¨ç¾åºè²ï¼ä½ç±æ¼ç½é£æ§éºå¿ææ°ï¼å®åå¨å¤ä»»åä¸­ä»é£ä»¥æ¦æ¬ï¼å¶ä¸­ååå­¸ç¿çä»»åæé¨èæ°ä»»åçå¼å¥èè¢«éºå¿ãéç¨®å¤ä»»åå­¸ç¿è½åå°æ¼éè¦é©æåè½çéæä»£çä¾èªªéå¸¸éè¦ï¼ä¾å¦ï¼èªä¸»æ©å¨äººï¼ãå¦ä¸æ¹é¢ï¼ç±æ¼ç¨ççå°å³°æä½ï¼èè¡ç¥ç¶ç¶²è·¯ (SNN) å·²æçºæ¿ä»£çç¯è½ç¥ç¶ç¶²è·¯æ¼ç®æ³ãçºæ­¤ï¼æåæåºäº MTSparkï¼éæ¯ä¸ç¨®ä½¿ç¨èè¡ç¶²è·¯åç¨å¤ä»»å RL çæ°æ¹æ³ãå·é«ä¾èªªï¼MTSpark éç¼äºä¸åå·æä¸»åæ¨¹çªåå°æ±ºçµæ§çæ·±åº¦èè¡ Q ç¶²è·¯ (DSQN)ï¼å©ç¨ç¹å®ä»»åçä¸ä¸æä¿¡èãå·é«ä¾èªªï¼æ¯åç¥ç¶åè¨ç®ä»»åç¸éçæ¿æ´»ï¼åæèª¿ç¯è¼¸å¥ï¼çºæ¯åä»»åå½¢æå°éçå­ç¶²è·¯ãæ­¤å¤ï¼éç¨®çç©åçç¶²è·¯æ¨¡åä¹åçæ¼ SNNï¼æé«äºè½æï¼ä½¿æ¨¡åé©åæ¼ç¡¬é«å¯¦ä½ãå¯¦é©çµæè¡¨æï¼èæåé²æè¡ç¸æ¯ï¼æåç MTSpark ææå°å­¸ç¿äºå¤é ä»»åï¼ä¸¦å·ææ´é«çæè½ãå·é«ä¾èªªï¼MTSpark å¨ä¸æ¬¾ Atari éæ²ä¸­æåç²å¾é«åï¼å³ Pongï¼-5.4ï¼Breakoutï¼0.6ï¼å Enduroï¼371.2ï¼ï¼éå°äººé¡æ°´æºçè¡¨ç¾ï¼å³ Pongï¼-3ï¼Breakoutï¼31ï¼å Enduroï¼368ï¼ï¼èæåé²çæè¡é£ä»¥éå°ãæ­¤å¤ï¼æåç MTSpark å¨å½±ååé¡ä»»åä¸­ä¹é¡¯ç¤ºåºæ¯æåé²æè¡æ´å¥½çæºç¢ºåº¦ãéäºçµæçªé¡¯äºæåç MTSpark æ¹æ³çæ½åï¼å®å¯ä»¥ééå©ç¨ RL å SNN æ¦å¿µä¾éç¼è½å¤ å­¸ç¿å¤é ä»»åçéæä»£çã</paragraph>

##### **eXpath: Explaining Knowledge Graph Link Prediction with Ontological Closed Path Rules**
2412.04846v1 by Ye Sun, Lei Shi, Yongxin Tong

Link prediction (LP) is crucial for Knowledge Graphs (KG) completion but
commonly suffers from interpretability issues. While several methods have been
proposed to explain embedding-based LP models, they are generally limited to
local explanations on KG and are deficient in providing human interpretable
semantics. Based on real-world observations of the characteristics of KGs from
multiple domains, we propose to explain LP models in KG with path-based
explanations. An integrated framework, namely eXpath, is introduced which
incorporates the concept of relation path with ontological closed path rules to
enhance both the efficiency and effectiveness of LP interpretation. Notably,
the eXpath explanations can be fused with other single-link explanation
approaches to achieve a better overall solution. Extensive experiments across
benchmark datasets and LP models demonstrate that introducing eXpath can boost
the quality of resulting explanations by about 20% on two key metrics and
reduce the required explanation time by 61.4%, in comparison to the best
existing method. Case studies further highlight eXpath's ability to provide
more semantically meaningful explanations through path-based evidence.

æè¦ï¼é£çµé æ¸¬ (LP) å°æ¼ç¥è­åè­ (KG) çå®æè³ééè¦ï¼ä½éå¸¸æéå°å¯è§£éæ§çåé¡ãéç¶å·²ç¶æåºå¹¾ç¨®æ¹æ³ä¾è§£éåºæ¼åµå¥ç LP æ¨¡åï¼ä½å®åéå¸¸åéæ¼ KG ä¸çå±é¨è§£éï¼ä¸¦ä¸ç¡æ³æä¾äººé¡å¯è§£éçèªç¾©ãæ ¹æä¾èªå¤åé åç KG ç¹å¾µççå¯¦ä¸çè§å¯ï¼æåå»ºè­°ä½¿ç¨åºæ¼è·¯å¾çè§£éä¾è§£é KG ä¸­ç LP æ¨¡åãå¼å¥äºä¸ååçº eXpath çæ´åæ¡æ¶ï¼å®å°éä¿è·¯å¾çæ¦å¿µèæ¬é«å°éè·¯å¾è¦åç¸çµåï¼ä»¥æé« LP è§£éçæçåæææ§ãå¼å¾æ³¨æçæ¯ï¼eXpath è§£éå¯ä»¥èå¶ä»å®éè·¯è§£éæ¹æ³èåï¼ä»¥å¯¦ç¾æ´å¥½çæ´é«è§£æ±ºæ¹æ¡ãè·¨åºæºè³æéå LP æ¨¡åçå»£æ³å¯¦é©è¡¨æï¼èç¾æçæä½³æ¹æ³ç¸æ¯ï¼å¼å¥ eXpath å¯ä»¥å°çµæè§£éçåè³ªæé«ç´ 20%ï¼ä¸¦å°æéçè§£éæéæ¸å° 61.4%ãæ¡ä¾ç ç©¶é²ä¸æ­¥å¼·èª¿äº eXpath ééåºæ¼è·¯å¾çè­ææä¾æ´å·èªç¾©æç¾©çè§£éçè½åã

##### **Using Machine Learning to Discover Parsimonious and Physically-Interpretable Representations of Catchment-Scale Rainfall-Runoff Dynamics**
2412.04845v1 by Yuan-Heng Wang, Hoshin V. Gupta

Despite the excellent real-world predictive performance of modern machine
learning (ML) methods, many scientists remain hesitant to discard traditional
physical-conceptual (PC) approaches due mainly to their relative
interpretability, which contributes to credibility during decision-making. In
this context, a currently underexplored aspect of ML is how to develop
minimally-optimal representations that can facilitate better insight regarding
system functioning. Regardless of how this is achieved, it is arguably true
that parsimonious representations better support the advancement of scientific
understanding. Our own view is that ML-based modeling of geoscientific systems
should be based in the use of computational units that are fundamentally
interpretable by design.
  This paper continues our exploration of how the strengths of ML can be
exploited in the service of better understanding via scientific investigation.
Here, we use the Mass Conserving Perceptron (MCP) as the fundamental
computational unit in a generic network architecture consisting of nodes
arranged in series and parallel to explore several generic and important issues
related to the use of observational data for constructing input-state-output
models of dynamical systems. In the context of lumped catchment modeling, we
show that physical interpretability and excellent predictive performance can
both be achieved using a relatively parsimonious distributed-state
multiple-flow-path network with context-dependent gating and information
sharing across the nodes, suggesting that MCP-based modeling can play a
significant role in application of ML to geoscientific investigation.

æè¦ï¼åç®¡ç¾ä»£æ©å¨å­¸ç¿ (ML) æ¹æ³å·æåºè²çå¯¦éä¸çé æ¸¬æè½ï¼ä½è¨±å¤ç§å­¸å®¶ä»ç¶è±«æ¯å¦æ¾æ£å³çµ±çç©çæ¦å¿µ (PC) æ¹æ³ï¼éä¸»è¦æ¯å çºå®åå·æç¸å°çå¯è§£éæ§ï¼æå©æ¼å¨æ±ºç­éç¨ä¸­å»ºç«ä¿¡è­½ãå¨æ­¤èçµ¡ä¸ï¼ç®å ML ä¸åæªååæ¢è¨çé¢åæ¯å¦ä½éç¼å¯ä¿é²å°ç³»çµ±éä½ææ´ä½³è¦è§£çæå°æä½³è¡¨ç¤ºæ³ãä¸è«å¦ä½éææ­¤ç®æ¨ï¼ç°¡ç´è¡¨ç¤ºæ³æ´æå©æ¼ä¿é²ç§å­¸çè§£ï¼éé»ç¡åº¸ç½®çãæåèªå·±ççæ³æ¯ï¼åºæ¼ ML çå°çç§å­¸ç³»çµ±å»ºæ¨¡æä»¥ä½¿ç¨å¨è¨­è¨ä¸å·æåºæ¬å¯è§£éæ§çéç®å®åçºåºç¤ã
æ¬ææçºæ¢è¨å¦ä½ééç§å­¸ç ç©¶ï¼å©ç¨ ML çåªå¢ä¾å¢é²çè§£ãå¨æ­¤ï¼æåä½¿ç¨è³ªéå®ææç¥å¨ (MCP) ä½çºéç¨ç¶²è·¯æ¶æ§ä¸­çåºæ¬éç®å®åï¼è©²æ¶æ§åå«ä¸²è¯åä¸¦è¯æåçç¯é»ï¼ä»¥æ¢è¨èä½¿ç¨è§æ¸¬è³æå»ºæ§åæç³»çµ±è¼¸å¥çæè¼¸åºæ¨¡åç¸éçå¹¾åéç¨ä¸éè¦çåé¡ãå¨éç¸½éæ°´åå»ºæ¨¡çèçµ¡ä¸ï¼æåå±ç¤ºäºä½¿ç¨å·æèçµ¡ç¸ééæ§åè·¨ç¯é»è³è¨å±äº«çç¸å°ç°¡ç´åå¸çæå¤æµè·¯å¾ç¶²è·¯ï¼å³å¯éæç©çå¯è§£éæ§ååºè²çé æ¸¬æè½ï¼éè¡¨ç¤ºåºæ¼ MCP çå»ºæ¨¡å¯ä»¥å¨ ML æç¨æ¼å°çç§å­¸ç ç©¶ä¸­æ®æ¼éè¦çè§è²ã

##### **Maximizing Alignment with Minimal Feedback: Efficiently Learning Rewards for Visuomotor Robot Policy Alignment**
2412.04835v1 by Ran Tian, Yilin Wu, Chenfeng Xu, Masayoshi Tomizuka, Jitendra Malik, Andrea Bajcsy

Visuomotor robot policies, increasingly pre-trained on large-scale datasets,
promise significant advancements across robotics domains. However, aligning
these policies with end-user preferences remains a challenge, particularly when
the preferences are hard to specify. While reinforcement learning from human
feedback (RLHF) has become the predominant mechanism for alignment in
non-embodied domains like large language models, it has not seen the same
success in aligning visuomotor policies due to the prohibitive amount of human
feedback required to learn visual reward functions. To address this limitation,
we propose Representation-Aligned Preference-based Learning (RAPL), an
observation-only method for learning visual rewards from significantly less
human preference feedback. Unlike traditional RLHF, RAPL focuses human feedback
on fine-tuning pre-trained vision encoders to align with the end-user's visual
representation and then constructs a dense visual reward via feature matching
in this aligned representation space. We first validate RAPL through simulation
experiments in the X-Magical benchmark and Franka Panda robotic manipulation,
demonstrating that it can learn rewards aligned with human preferences, more
efficiently uses preference data, and generalizes across robot embodiments.
Finally, our hardware experiments align pre-trained Diffusion Policies for
three object manipulation tasks. We find that RAPL can fine-tune these policies
with 5x less real human preference data, taking the first step towards
minimizing human feedback while maximizing visuomotor robot policy alignment.

æè¦ï¼è¦è¦ºéåæ©å¨äººç­ç¥æ¥çå¨å¤§åè³æéä¸é²è¡é è¨ç·´ï¼æ¿è«¾å¨æ©å¨äººé åä¸­åå¾éå¤§é²å±ãç¶èï¼å°éäºç­ç¥èæçµä½¿ç¨èçåå¥½ä¿æä¸è´ä»ç¶æ¯ä¸åææ°ï¼ç¹å¥æ¯å¨åå¥½é£ä»¥å·é«èªªææãéç¶å¾äººé¡åé¥ä¸­é²è¡å¼·åå­¸ç¿ (RLHF) å·²æçºå¤§åèªè¨æ¨¡åç­éå·èº«é åä¸­é²è¡èª¿æ´çä¸»è¦æ©å¶ï¼ä½ç±æ¼å­¸ç¿è¦è¦ºçåµå½æ¸éè¦å¤§éçäººé¡åé¥ï¼å æ­¤å¨èª¿æ´è¦è¦ºéåç­ç¥æ¹é¢å°æªåå¾ç¸åçæåãçºäºè§£æ±ºéåéå¶ï¼æåæåºåºæ¼è¡¨ç¤ºå°é½åå¥½çå­¸ç¿ (RAPL)ï¼éæ¯ä¸ç¨®åè§å¯çæ¹æ³ï¼å¯ä»¥ç¨å°å¾å¤çåå¥½åé¥ä¾å­¸ç¿è¦è¦ºçåµãèå³çµ±ç RLHF ä¸åï¼RAPL å°äººé¡åé¥éä¸­å¨å¾®èª¿é è¨ç·´çè¦è¦ºç·¨ç¢¼å¨ä¸ï¼ä»¥èæçµä½¿ç¨èçè¦è¦ºè¡¨ç¤ºä¿æä¸è´ï¼ç¶å¾ééå¨éåå°é½çè¡¨ç¤ºç©ºéä¸­é²è¡ç¹å¾µå¹éä¾æ§å»ºå¯éçè¦è¦ºçåµãæåé¦åéé X-Magical åºæºå Franka Panda æ©å¨äººæä½ä¸­çæ¨¡æ¬å¯¦é©é©è­äº RAPLï¼è­æå®å¯ä»¥å­¸ç¿èäººé¡åå¥½ä¸è´ççåµï¼æ´ææå°ä½¿ç¨åå¥½æ¸æï¼ä¸¦å¨æ©å¨äººå·é«å¯¦ä¾ä¸­é²è¡æ¦æ¬ãæå¾ï¼æåçç¡¬é«å¯¦é©èª¿æ´äºé è¨ç·´çæ´æ£ç­ç¥ï¼ä»¥å·è¡ä¸åç©é«æä½ä»»åãæåç¼ç¾ RAPL å¯ä»¥ä½¿ç¨å° 5 åççå¯¦äººé¡åå¥½æ¸æå¾®èª¿éäºç­ç¥ï¼éæ¯æèæå¤§ç¨åº¦æ¸å°äººé¡åé¥ä¸¦æå¤§ç¨åº¦æé«è¦è¦ºéåæ©å¨äººç­ç¥å°é½éåºçç¬¬ä¸æ­¥ã

##### **WRF-GS: Wireless Radiation Field Reconstruction with 3D Gaussian Splatting**
2412.04832v1 by Chaozheng Wen, Jingwen Tong, Yingdong Hu, Zehong Lin, Jun Zhang

Wireless channel modeling plays a pivotal role in designing, analyzing, and
optimizing wireless communication systems. Nevertheless, developing an
effective channel modeling approach has been a longstanding challenge. This
issue has been escalated due to the denser network deployment, larger antenna
arrays, and wider bandwidth in 5G and beyond networks. To address this
challenge, we put forth WRF-GS, a novel framework for channel modeling based on
wireless radiation field (WRF) reconstruction using 3D Gaussian splatting.
WRF-GS employs 3D Gaussian primitives and neural networks to capture the
interactions between the environment and radio signals, enabling efficient WRF
reconstruction and visualization of the propagation characteristics. The
reconstructed WRF can then be used to synthesize the spatial spectrum for
comprehensive wireless channel characterization. Notably, with a small number
of measurements, WRF-GS can synthesize new spatial spectra within milliseconds
for a given scene, thereby enabling latency-sensitive applications.
Experimental results demonstrate that WRF-GS outperforms existing methods for
spatial spectrum synthesis, such as ray tracing and other deep-learning
approaches. Moreover, WRF-GS achieves superior performance in the channel state
information prediction task, surpassing existing methods by a significant
margin of more than 2.43 dB.

æè¦ï¼ç¡ç·ééå»ºæ¨¡å¨è¨­è¨ãåæåæä½³åç¡ç·éè¨ç³»çµ±ä¸­æ®æ¼èééµè§è²ãåç®¡å¦æ­¤ï¼éç¼ä¸åææçééå»ºæ¨¡æ¹æ³ä¸ç´æ¯ä¸åé·æçææ°ãéååé¡ç±æ¼ 5G åå¶å¾çºç¶²è·¯ä¸­æ´å¯éçç¶²è·¯é¨ç½²ãæ´å¤§çå¤©ç·é£ååæ´å¯¬çé »å¯¬èåç´ãçºäºæå°éåææ°ï¼æåæåºäº WRF-GSï¼ä¸ååºæ¼ä½¿ç¨ 3D é«æ¯æ£å°éæ§ç¡ç·è¼»å°å ´ (WRF) çééå»ºæ¨¡æ°æ¶æ§ãWRF-GS ä½¿ç¨ 3D é«æ¯åºååç¥ç¶ç¶²è·¯ä¾æ·åç°å¢åç¡ç·é»è¨èä¹éçäº¤äºä½ç¨ï¼å¯¦ç¾ææç WRF éæ§åå³æ­ç¹æ§çå¯è¦åãç¶å¾ï¼å¯ä»¥å©ç¨éæ§ç WRF åæç©ºéé »è­ï¼ä»¥é²è¡å¨é¢çç¡ç·ééç¹æ§æè¿°ãå¼å¾æ³¨æçæ¯ï¼ä½¿ç¨å°éæ¸¬éï¼WRF-GS å¯ä»¥éå°çµ¦å®çå ´æ¯å¨å¹¾æ¯«ç§å§åææ°çç©ºéé »è­ï¼å¾èæ¯æ´å°å»¶é²ææçæç¨ãå¯¦é©çµæè¡¨æï¼WRF-GS å¨ç©ºéé »è­åææ¹é¢åªæ¼ç¾ææ¹æ³ï¼ä¾å¦å°ç·è¿½è¹¤åå¶ä»æ·±åº¦å­¸ç¿æ¹æ³ãæ­¤å¤ï¼WRF-GS å¨ééçæè³è¨é æ¸¬ä»»åä¸­åå¾äºåè¶çæè½ï¼ä»¥è¶é 2.43 dB çé¡¯èå¹åº¦è¶è¶ç¾ææ¹æ³ã

##### **Rethinking Time Series Forecasting with LLMs via Nearest Neighbor Contrastive Learning**
2412.04806v1 by Jayanie Bogahawatte, Sachith Seneviratne, Maneesha Perera, Saman Halgamuge

Adapting Large Language Models (LLMs) that are extensively trained on
abundant text data, and customizing the input prompt to enable time series
forecasting has received considerable attention. While recent work has shown
great potential for adapting the learned prior of LLMs, the formulation of the
prompt to finetune LLMs remains challenging as prompt should be aligned with
time series data. Additionally, current approaches do not effectively leverage
word token embeddings which embody the rich representation space learned by
LLMs. This emphasizes the need for a robust approach to formulate the prompt
which utilizes the word token embeddings while effectively representing the
characteristics of the time series. To address these challenges, we propose
NNCL-TLLM: Nearest Neighbor Contrastive Learning for Time series forecasting
via LLMs. First, we generate time series compatible text prototypes such that
each text prototype represents both word token embeddings in its neighborhood
and time series characteristics via end-to-end finetuning. Next, we draw
inspiration from Nearest Neighbor Contrastive Learning to formulate the prompt
while obtaining the top-$k$ nearest neighbor time series compatible text
prototypes. We then fine-tune the layer normalization and positional embeddings
of the LLM, keeping the other layers intact, reducing the trainable parameters
and decreasing the computational cost. Our comprehensive experiments
demonstrate that NNCL-TLLM outperforms in few-shot forecasting while achieving
competitive or superior performance over the state-of-the-art methods in
long-term and short-term forecasting tasks.

æè¦ï¼<paragraph>éå°å¤§éææ¬è³æé²è¡å»£æ³è¨ç·´çå¤§åèªè¨æ¨¡å (LLM) é©æï¼ä¸¦èªè¨è¼¸å¥æç¤ºä»¥åç¨æéåºåé æ¸¬ï¼å·²åå°ç¸ç¶å¤§çéæ³¨ãéç¶æè¿çç ç©¶é¡¯ç¤ºåºé©æ LLM å­¸ç¿åé©æå¾å¤§çæ½åï¼ä½éå° LLM é²è¡å¾®èª¿çæç¤ºå¶å®ä»ç¶å·æææ°æ§ï¼å çºæç¤ºæèæéåºåè³æä¿æä¸è´ãæ­¤å¤ï¼ç®åçä½æ³ä¸¦æªææå©ç¨å­åæ¨è¨åµå¥ï¼èå­åæ¨è¨åµå¥é«ç¾äº LLM æå­¸ç¿çè±å¯è¡¨ç¤ºç©ºéãéå¼·èª¿äºå¶å®æç¤ºçå¥å¨ä½æ³ä¹å¿è¦æ§ï¼è©²ä½æ³å©ç¨å­åæ¨è¨åµå¥ï¼åæææå°è¡¨ç¤ºæéåºåçç¹å¾µãçºäºè§£æ±ºéäºææ°ï¼æåæåº NNCL-TLLMï¼æéåºåé æ¸¬çæè¿é°å°æ¯å­¸ç¿ï¼éé LLMãé¦åï¼æåç¢çæéåºåç¸å®¹çæå­ååï¼ä½¿å¾æ¯åæå­åååæè¡¨ç¤ºå¶é°åä¸­çå­åæ¨è¨åµå¥åééç«¯å°ç«¯å¾®èª¿çæéåºåç¹å¾µãæ¥ä¸ä¾ï¼æåå¾æè¿é°å°æ¯å­¸ç¿ä¸­æ±²åéæï¼ä»¥å¶å®æç¤ºï¼åæåå¾å $k$ åæè¿é°æéåºåç¸å®¹çæå­ååãç¶å¾ï¼æåå¾®èª¿ LLM çå±¤æ­£è¦ååä½ç½®åµå¥ï¼ä¿æå¶ä»å±¤ä¸è®ï¼æ¸å°å¯è¨ç·´åæ¸ä¸¦éä½éç®ææ¬ãæåçç¶åå¯¦é©è­æï¼NNCL-TLLM å¨å°æ¬¡é æ¸¬ä¸­è¡¨ç¾åªæ¼å¶ä»æ¹æ³ï¼åæå¨é·æåç­æé æ¸¬ä»»åä¸­éå°èæåé²çæ¹æ³ç«¶ç­æåªæ¼æåé²çæ¹æ³çæè½ã</paragraph>

##### **Estimating the treatment effect over time under general interference through deep learner integrated TMLE**
2412.04799v1 by Suhan Guo, Furao Shen, Ni Li

Understanding the effects of quarantine policies in populations with
underlying social networks is crucial for public health, yet most causal
inference methods fail here due to their assumption of independent individuals.
We introduce DeepNetTMLE, a deep-learning-enhanced Targeted Maximum Likelihood
Estimation (TMLE) method designed to estimate time-sensitive treatment effects
in observational data. DeepNetTMLE mitigates bias from time-varying confounders
under general interference by incorporating a temporal module and domain
adversarial training to build intervention-invariant representations. This
process removes associations between current treatments and historical
variables, while the targeting step maintains the bias-variance trade-off,
enhancing the reliability of counterfactual predictions. Using simulations of a
``Susceptible-Infected-Recovered'' model with varied quarantine coverages, we
show that DeepNetTMLE achieves lower bias and more precise confidence intervals
in counterfactual estimates, enabling optimal quarantine recommendations within
budget constraints, surpassing state-of-the-art methods.

æè¦ï¼äºè§£å·ææ½å¨ç¤¾äº¤ç¶²çµ¡çäººç¾¤ä¸­éé¢æ¿ç­çå½±é¿å°æ¼å¬å±è¡çè³ééè¦ï¼ä½ç±æ¼åè¨­åäººç¨ç«ï¼å¤§å¤æ¸å ææ¨è«æ¹æ³å¨æ­¤èå¤±æãæåå¼å¥äº DeepNetTMLEï¼éæ¯ä¸ç¨®æ·±åº¦å­¸ç¿å¢å¼·çç®æ¨æå¤§ä¼¼ç¶ä¼°è¨ (TMLE) æ¹æ³ï¼æ¨å¨ä¼°è¨è§æ¸¬æ¸æä¸­çæéææèçææãDeepNetTMLE ééæ´åæéæ¨¡çµåé åå°æè¨ç·´ä¾å»ºç«ä»å¥ä¸è®è¡¨ç¤ºï¼å¾èæ¸è¼ä¸è¬å¹²æ¾ä¸æè®æ··éå ç´ çåå·®ãæ­¤éç¨æ¶é¤äºç¶åèçèæ­·å²è®æ¸ä¹éçéè¯ï¼èç®æ¨è¨­å®æ­¥é©åç¶­æåå·®è®ç°æ¬è¡¡ï¼å¢å¼·åäºå¯¦é æ¸¬çå¯é æ§ãä½¿ç¨å·æä¸åéé¢è¦èççãææè-ææè-åº·å¾©èãæ¨¡åçæ¨¡æ¬ï¼æåè¡¨æ DeepNetTMLE å¨åäºå¯¦ä¼°è¨ä¸­å¯¦ç¾äºè¼ä½çåå·®åæ´ç²¾ç¢ºçä¿¡å¿åéï¼å¾èå¨é ç®éå¶å§å¯¦ç¾äºæä½³éé¢å»ºè­°ï¼è¶è¶äºæåé²çæ¹æ³ã

##### **Multi-class heart disease Detection, Classification, and Prediction using Machine Learning Models**
2412.04792v1 by Mahfuzul Haque, Abu Saleh Musa Miah, Debashish Gupta, Md. Maruf Al Hossain Prince, Tanzina Alam, Nusrat Sharmin, Mohammed Sowket Ali, Jungpil Shin

Heart disease is a leading cause of premature death worldwide, particularly
among middle-aged and older adults, with men experiencing a higher prevalence.
According to the World Health Organization (WHO), non-communicable diseases,
including heart disease, account for 25\% (17.9 million) of global deaths, with
over 43,204 annual fatalities in Bangladesh. However, the development of heart
disease detection (HDD) systems tailored to the Bangladeshi population remains
underexplored due to the lack of benchmark datasets and reliance on manual or
limited-data approaches. This study addresses these challenges by introducing
new, ethically sourced HDD dataset, BIG-Dataset and CD dataset which
incorporates comprehensive data on symptoms, examination techniques, and risk
factors. Using advanced machine learning techniques, including Logistic
Regression and Random Forest, we achieved a remarkable testing accuracy of up
to 96.6\% with Random Forest. The proposed AI-driven system integrates these
models and datasets to provide real-time, accurate diagnostics and personalized
healthcare recommendations. By leveraging structured datasets and
state-of-the-art machine learning algorithms, this research offers an
innovative solution for scalable and effective heart disease detection, with
the potential to reduce mortality rates and improve clinical outcomes.

æè¦ï¼<paragraph>å¿èçæ¯å¨çéæ©æ­»äº¡çä¸»å ï¼ç¹å¥æ¯å¨ä¸­å¹´åèå¹´äººä¸­ï¼ç·æ§ç¼ççè¼é«ãæ ¹æä¸çè¡ççµç¹ (WHO) çæ¸æï¼åæ¬å¿èçå¨å§çéå³ææ§ç¾çå å¨çæ­»äº¡äººæ¸ç 25%ï¼1790 è¬ï¼ï¼å­å æåæ¯å¹´æè¶é 43,204 äººæ­»æ¼å¿èçãç¶èï¼ç±æ¼ç¼ºä¹åºæºæ¸æéåä¾è³´æåææ¸ææéçæ¹æ³ï¼éå°å­å æåäººå£éèº«æé çå¿èçæª¢æ¸¬ (HDD) ç³»çµ±çéç¼ä»æªå¾å°ååæ¢ç´¢ãæ¬ç ç©¶ééå¼å¥æ°çãç¬¦åéå¾·æ¨æºç HDD æ¸æéãBIG æ¸æéå CD æ¸æéä¾æå°éäºææ°ï¼å¶ä¸­åå«æéççãæª¢æ¥æè¡åé¢¨éªå ç´ çå¨é¢æ¸æãä½¿ç¨åé²çæ©å¨å­¸ç¿æè¡ï¼åæ¬éè¼¯è¿´æ­¸åé¨æ©æ£®æï¼æåä½¿ç¨é¨æ©æ£®æå¯¦ç¾äºé«é 96.6% çé¡¯èæ¸¬è©¦æºç¢ºåº¦ãææåºç AI é©åç³»çµ±æ´åäºéäºæ¨¡ååæ¸æéï¼ä»¥æä¾å¯¦æçæºç¢ºè¨ºæ·ååæ§åçé«çä¿å¥å»ºè­°ãééå©ç¨çµæ§åæ¸æéåæåé²çæ©å¨å­¸ç¿ç®æ³ï¼æ¬ç ç©¶çºå¯æ´å±ä¸ææçå¿èçæª¢æ¸¬æä¾äºä¸ååµæ°çè§£æ±ºæ¹æ¡ï¼å·æéä½æ­»äº¡çåæ¹åè¨åºçµæçæ½åã</paragraph>

##### **GUIDE: A Global Unified Inference Engine for Deploying Large Language Models in Heterogeneous Environments**
2412.04788v1 by Yanyu Chen, Ganhong Huang

Efficiently deploying large language models (LLMs) in real-world scenarios
remains a critical challenge, primarily due to hardware heterogeneity,
inference framework limitations, and workload complexities.Efficiently
deploying large language models (LLMs) in real-world scenarios remains a
critical challenge, primarily due to hardware heterogeneity, inference
framework limitations, and workload complexities. These challenges often lead
to inefficiencies in memory utilization, latency, and throughput, hindering the
effective deployment of LLMs, especially for non-experts. Through extensive
experiments, we identify key performance bottlenecks, including sudden drops in
memory utilization, latency fluctuations with varying batch sizes, and
inefficiencies in multi-GPU configurations. These insights reveal a vast
optimization space shaped by the intricate interplay of hardware, frameworks,
and workload parameters. This underscores the need for a systematic approach to
optimize LLM inference, motivating the design of our framework, GUIDE. GUIDE
leverages dynamic modeling and simulation-based optimization to address these
issues, achieving prediction errors between 25% and 55% for key metrics such as
batch latency, TTFT, and decode throughput. By effectively bridging the gap
between theoretical performance and practical deployment, our framework
empowers practitioners, particularly non-specialists, to make data-driven
decisions and unlock the full potential of LLMs in heterogeneous environments
cheaply.

æè¦ï¼é«æé¨ç½²å¤§åèªè¨æ¨¡å (LLM) è³æ¼å¯¦éå ´æ¯ä¸­ï¼ä»æ¯ä¸åéå¤§çææ°ï¼ä¸»è¦åå å¨æ¼ç¡¬é«ç°è³ªæ§ãæ¨è«æ¶æ§éå¶ä»¥åå·¥ä½è² è¼çè¤éæ§ãé«æé¨ç½²å¤§åèªè¨æ¨¡å (LLM) è³æ¼å¯¦éå ´æ¯ä¸­ï¼ä»æ¯ä¸åéå¤§çææ°ï¼ä¸»è¦åå å¨æ¼ç¡¬é«ç°è³ªæ§ãæ¨è«æ¶æ§éå¶ä»¥åå·¥ä½è² è¼çè¤éæ§ãéäºææ°éå¸¸æå°è´è¨æ¶é«ä½¿ç¨çãå»¶é²åååéçä½æçï¼é»ç¤ LLM çææé¨ç½²ï¼å°¤å¶æ¯å°éå°å®¶èè¨ãééå»£æ³çå¯¦é©ï¼æåæ¾åºä¸»è¦çæè½ç¶é ¸ï¼åæ¬è¨æ¶é«ä½¿ç¨çççªç¶ä¸éãæ¹æ¬¡å¤§å°ä¸åçå»¶é²æ³¢åï¼ä»¥åå¤ GPU éç½®ä¸­çä½æçãéäºè¦è§£æ­ç¤ºäºä¸åå»£å¤§çæä½³åç©ºéï¼ç±ç¡¬é«ãæ¶æ§åå·¥ä½è² è¼åæ¸çè¤éäº¤äºä½ç¨æå½¢æãéå¼·èª¿äºéè¦ä¸åç³»çµ±åçæ¹æ³ä¾æä½³å LLM æ¨è«ï¼æ¿åµæåæ¶æ§ GUIDE çè¨­è¨ãGUIDE èç±åæå»ºæ¨¡ååºæ¼æ¨¡æ¬çæä½³åä¾è§£æ±ºéäºåé¡ï¼å°æ¼æ¹æ¬¡å»¶é²ãTTFT åè§£ç¢¼ååéç­ééµææ¨ï¼éæ 25% è³ 55% çé æ¸¬èª¤å·®ãééææç¸®å°çè«æè½åå¯¦éé¨ç½²ä¹éçå·®è·ï¼æåçæ¶æ§è®å¾æ¥­äººå¡ï¼å°¤å¶æ¯éå°å®¶ï¼è½å¤ ååºè³æé©åçæ±ºç­ï¼ä¸¦å¨ç°è³ªç°å¢ä¸­ä»¥ä½ææ¬ç¼æ® LLM çå¨é¨æ½åã

##### **Direct Quantized Training of Language Models with Stochastic Rounding**
2412.04787v1 by Kaiyan Zhao, Tsuguchika Tabaru, Kenichi Kobayashi, Takumi Honda, Masafumi Yamazaki, Yoshimasa Tsuruoka

Although recent quantized Large Language Models (LLMs), such as BitNet, have
paved the way for significant reduction in memory usage during deployment with
binary or ternary weights, training these models still demands substantial
memory footprints. This is partly because high-precision (i.e., unquantized)
weight matrices required for straight-through estimation must be maintained
throughout the whole training process. To address this, we explore the
potential of directly updating the quantized low-precision weight matrices
without relying on the straight-through estimator during backpropagation,
thereby saving memory usage during training. Specifically, we employ a
stochastic rounding technique to minimize information loss caused by the use of
low-bit weights throughout training. Experimental results on our
LLaMA-structured models indicate that (1) training with only low-precision
weights is feasible even when they are constrained to ternary values, (2)
extending the bit width to 8 bits results in only a 5% loss degradation
compared to BitNet b1.58 while offering the potential for reduced memory usage
during training, and (3) our models can also perform inference using ternary
weights, showcasing their flexibility in deployment.

æè¦ï¼åç®¡æè¿çéåå¤§åèªè¨æ¨¡å (LLM)ï¼ä¾å¦ BitNetï¼å·²çºå¨ä½¿ç¨äºé²ä½æä¸é²ä½æ¬éé²è¡é¨ç½²æå¤§å¹æ¸å°è¨æ¶é«ç¨ééªå¹³äºéè·¯ï¼ä½è¨ç·´éäºæ¨¡åä»éè¦å¤§éçè¨æ¶é«ç©ºéãéé¨åæ¯å çºå¿é å¨æ´åè¨ç·´éç¨ä¸­ç¶­è­·ç¨æ¼ç´éä¼°è¨çé«ç²¾åº¦ï¼å³æªéåï¼æ¬éç©é£ãçºäºè§£æ±ºéååé¡ï¼æåæ¢è¨äºå¨ååå³æ­éç¨ä¸­ä¸ä¾è³´ç´éä¼°è¨å¨èç´æ¥æ´æ°éåä½ç²¾åº¦æ¬éç©é£çå¯è½æ§ï¼å¾èç¯çè¨ç·´æéçè¨æ¶é«ç¨éãå·é«ä¾èªªï¼æåæ¡ç¨é¨æ©æ¨å¥æè¡ï¼ä»¥æå°åå¨æ´åè¨ç·´éç¨ä¸­ä½¿ç¨ä½ä½åæ¬éé æçè³è¨éºå¤±ãæåå¨ LLaMA çµæ§æ¨¡åä¸çå¯¦é©çµæè¡¨æï¼(1) å³ä½¿å°æ¬ééå¶çºä¸é²ä½å¼ï¼åä½¿ç¨ä½ç²¾åº¦æ¬éé²è¡è¨ç·´ä¹æ¯å¯è¡çï¼(2) å°ä½åå¯¬åº¦æ´å±å° 8 ä½ååªæå°è´ 5% çæå¤±å£åï¼èè BitNet b1.58 ç¸æ¯ï¼å¨è¨ç·´æéæä¾äºæ¸å°è¨æ¶é«ç¨éçå¯è½æ§ï¼(3) æåçæ¨¡åä¹å¯ä»¥ä½¿ç¨ä¸é²ä½æ¬éé²è¡æ¨è«ï¼å±ç¤ºäºå®åå¨é¨ç½²ä¸­çéæ´»æ§ã

##### **NLP-ADBench: NLP Anomaly Detection Benchmark**
2412.04784v1 by Yuangang Li, Jiaqi Li, Zhuo Xiao, Tiankai Yang, Yi Nian, Xiyang Hu, Yue Zhao

Anomaly detection (AD) is a critical machine learning task with diverse
applications in web systems, including fraud detection, content moderation, and
user behavior analysis. Despite its significance, AD in natural language
processing (NLP) remains underexplored, limiting advancements in detecting
anomalies in text data such as harmful content, phishing attempts, or spam
reviews. In this paper, we introduce NLP-ADBench, the most comprehensive
benchmark for NLP anomaly detection (NLP-AD), comprising eight curated datasets
and evaluations of nineteen state-of-the-art algorithms. These include three
end-to-end methods and sixteen two-step algorithms that apply traditional
anomaly detection techniques to language embeddings generated by
bert-base-uncased and OpenAI's text-embedding-3-large models.
  Our results reveal critical insights and future directions for NLP-AD.
Notably, no single model excels across all datasets, highlighting the need for
automated model selection. Moreover, two-step methods leveraging
transformer-based embeddings consistently outperform specialized end-to-end
approaches, with OpenAI embeddings demonstrating superior performance over BERT
embeddings. By releasing NLP-ADBench at
https://github.com/USC-FORTIS/NLP-ADBench, we provide a standardized framework
for evaluating NLP-AD methods, fostering the development of innovative
approaches. This work fills a crucial gap in the field and establishes a
foundation for advancing NLP anomaly detection, particularly in the context of
improving the safety and reliability of web-based systems.

æè¦ï¼ç°å¸¸åµæ¸¬ (AD) æ¯ä¸é éè¦çæ©å¨å­¸ç¿ä»»åï¼å¨ç¶²è·¯ç³»çµ±ä¸­å·æå¤æ¨£åçæç¨ï¼åæ¬è©æ¬ºåµæ¸¬ãå§å®¹å¯©æ ¸åä½¿ç¨èè¡çºåæãåç®¡ç°å¸¸åµæ¸¬å·æéè¦æ§ï¼ä½èªç¶èªè¨èç (NLP) ä¸­çç°å¸¸åµæ¸¬ä»æªè¢«ååæ¢ç´¢ï¼ééå¶äºåµæ¸¬æå­è³æä¸­ç°å¸¸ç¾è±¡çé²å±ï¼ä¾å¦æå®³å§å®¹ãç¶²è·¯é£é­åè©¦æåå¾è©è«ãå¨æ¬æä¸­ï¼æåä»ç´¹äº NLP-ADBenchï¼éæ¯ NLP ç°å¸¸åµæ¸¬ (NLP-AD) æå¨é¢çåºæºï¼åå«å«åç­åå¥½çè³æéååä¹ç¨®æåé²æ¼ç®æ³çè©ä¼°ãéäºåæ¬ä¸ç¨®ç«¯å°ç«¯æ¹æ³ååå­ç¨®å©æ­¥é©æ¼ç®æ³ï¼å®åå°å³çµ±çç°å¸¸åµæ¸¬æè¡æç¨æ¼ç± bert-base-uncased å OpenAI ç text-embedding-3-large æ¨¡åç¢ççèªè¨åµå¥ãæåççµææ­ç¤ºäº NLP-AD çééµè¦è§£åæªä¾æ¹åãå¼å¾æ³¨æçæ¯ï¼æ²æå®ä¸æ¨¡åå¨ææè³æéä¸è¡¨ç¾åªç°ï¼éçªé¡¯äºèªååæ¨¡åé¸æçå¿è¦æ§ãæ­¤å¤ï¼å©ç¨åºæ¼ Transformer çåµå¥çå©æ­¥é©æ¹æ³å§çµåªæ¼å°éçç«¯å°ç«¯æ¹æ³ï¼è OpenAI åµå¥è¡¨ç¾åºåªæ¼ BERT åµå¥çæè½ãééå¨ https://github.com/USC-FORTIS/NLP-ADBench ä¸ç¼å¸ NLP-ADBenchï¼æåæä¾äºä¸åæ¨æºåçæ¡æ¶ä¾è©ä¼° NLP-AD æ¹æ³ï¼ä¿é²åµæ°æ¹æ³çç¼å±ãéé å·¥ä½å¡«è£äºè©²é åçééµç©ºç½ï¼ä¸¦å»ºç«äºæ¨é² NLP ç°å¸¸åµæ¸¬çåºç¤ï¼ç¹å¥æ¯å¨æ¹ååºæ¼ç¶²è·¯ç³»çµ±çå®å¨æ§åå¯é æ§çææ³ä¸ã

##### **KNN-MMD: Cross Domain Wi-Fi Sensing Based on Local Distribution Alignment**
2412.04783v1 by Zijian Zhao, Zhijie Cai, Tingwei Chen, Xiaoyang Li, Hang Li, Guangxu Zhu

As a key technology in Integrated Sensing and Communications (ISAC), Wi-Fi
sensing has gained widespread application in various settings such as homes,
offices, and public spaces. By analyzing the patterns of Channel State
Information (CSI), we can obtain information about people's actions for tasks
like person identification, gesture recognition, and fall detection. However,
the CSI is heavily influenced by the environment, such that even minor
environmental changes can significantly alter the CSI patterns. This will cause
the performance deterioration and even failure when applying the Wi-Fi sensing
model trained in one environment to another. To address this problem, we
introduce a K-Nearest Neighbors Maximum Mean Discrepancy (KNN-MMD) model, a
few-shot method for cross-domain Wi-Fi sensing. We propose a local distribution
alignment method within each category, which outperforms traditional Domain
Adaptation (DA) methods based on global alignment. Besides, our method can
determine when to stop training, which cannot be realized by most DA methods.
As a result, our method is more stable and can be better used in practice. The
effectiveness of our method are evaluated in several cross-domain Wi-Fi sensing
tasks, including gesture recognition, person identification, fall detection,
and action recognition, using both a public dataset and a self-collected
dataset. In one-shot scenario, our method achieves accuracy of 93.26%, 81.84%,
77.62%, and 75.30% in the four tasks respectively. To facilitate future
research, we will make our code and dataset publicly available upon
publication.

æè¦ï¼ä½çºæ´åææ¸¬èéè¨ (ISAC) çééµæè¡ï¼Wi-Fi ææ¸¬å·²å»£æ³æç¨æ¼åç¨®å ´æ¯ï¼ä¾å¦å®¶åº­ãè¾¦å¬å®¤åå¬å±ç©ºéãééåæé »éçæè³è¨ (CSI) çæ¨¡å¼ï¼æåå¯ä»¥åå¾äººåå¨å·è¡ä»»åï¼ä¾å¦äººå¡è­å¥ãæå¢è¾¨è­åè·ååµæ¸¬ï¼æçåä½è³è¨ãç¶èï¼CSI æ·±åç°å¢å½±é¿ï¼å³ä½¿æ¯å¾®å°çç°å¢è®åä¹å¯è½å¤§å¹æ¹è® CSI æ¨¡å¼ãéå°å°è´å¨ä¸åç°å¢ä¸­è¨ç·´ç Wi-Fi ææ¸¬æ¨¡åå¥ç¨è³å¦ä¸åç°å¢æï¼æè½æä¸éçè³å¤±æãçºäºè§£æ±ºéååé¡ï¼æåå¼é² K æè¿é°æå¤§å¹³åå·®ç° (KNN-MMD) æ¨¡åï¼éæ¯ä¸ç¨®è·¨ç¶²å Wi-Fi ææ¸¬çå°æ¬¡å­¸ç¿æ¹æ³ãæåæåºä¸åé¡å¥å§é¨å±é¨åä½æ¯å°æ¹æ³ï¼å¶åªæ¼åºæ¼å¨åæ¯å°çå³çµ±ç¶²åé©æ (DA) æ¹æ³ãæ­¤å¤ï¼æåçæ¨¡åå¯ä»¥æ±ºå®ä½æåæ­¢è¨ç·´ï¼éæ¯å¤§å¤æ¸ DA æ¹æ³ç¡æ³åå°çãå æ­¤ï¼æåçæ¨¡åæ´ç©©å®ï¼ä¸æ´é©åå¯¦éæç¨ãæåå¨å¹¾åè·¨ç¶²å Wi-Fi ææ¸¬ä»»åä¸­è©ä¼°äºæåæ¨¡åçæè½ï¼åæ¬æå¢è¾¨è­ãäººå¡è­å¥ãè·ååµæ¸¬ååä½è¾¨è­ï¼ä¸¦ä½¿ç¨å¬éè³æéåèªå»ºè³æéãå¨ä¸æ¬¡å­¸ç¿æå¢ä¸­ï¼æåçæ¨¡åå¨ååä»»åä¸­åå¥éå° 93.26%ã81.84%ã77.62% å 75.30% çæºç¢ºåº¦ãçºäºä¿é²å¾çºç ç©¶ï¼æåå°å¨ç¼è¡¨å¾å¬éæåçç¨å¼ç¢¼åè³æéã

##### **A Survey of Sustainability in Large Language Models: Applications, Economics, and Challenges**
2412.04782v1 by Aditi Singh, Nirmal Prakashbhai Patel, Abul Ehtesham, Saket Kumar, Tala Talaei Khoei

Large Language Models (LLMs) have transformed numerous domains by providing
advanced capabilities in natural language understanding, generation, and
reasoning. Despite their groundbreaking applications across industries such as
research, healthcare, and creative media, their rapid adoption raises critical
concerns regarding sustainability. This survey paper comprehensively examines
the environmental, economic, and computational challenges associated with LLMs,
focusing on energy consumption, carbon emissions, and resource utilization in
data centers. By synthesizing insights from existing literature, this work
explores strategies such as resource-efficient training, sustainable deployment
practices, and lifecycle assessments to mitigate the environmental impacts of
LLMs. Key areas of emphasis include energy optimization, renewable energy
integration, and balancing performance with sustainability. The findings aim to
guide researchers, practitioners, and policymakers in developing actionable
strategies for sustainable AI systems, fostering a responsible and
environmentally conscious future for artificial intelligence.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²ééæä¾èªç¶èªè¨çè§£ãçæåæ¨ççé«éè½åï¼è½è®äºè¨±å¤é åãåç®¡å®åå¨ç ç©¶ãé«çä¿å¥ååµæåªé«ç­ç¢æ¥­ä¸­å·æçªç ´æ§çæç¨ï¼ä½å¶å¿«éæ¡ç¨ä¹å¼ç¼äºæéæ°¸çºæ§çéå¤§çæ®ãéç¯èª¿æ¥å ±åå¨é¢æ¢è¨äºè LLM ç¸éçç°å¢ãç¶æ¿åéç®ææ°ï¼éé»éæ³¨è³æä¸­å¿çè½æºæ¶èãç¢³ææ¾åè³æºå©ç¨ãééç¶åç¾ææç»çè¦è§£ï¼éé å·¥ä½æ¢è¨äºè³æºææè¨ç·´ãæ°¸çºé¨ç½²å¯¦ååçå½é±æè©ä¼°ç­ç­ç¥ï¼ä»¥æ¸è¼ LLM å°ç°å¢çå½±é¿ãéé»éæ³¨é ååæ¬è½æºæä½³åãåçè½æºæ´åï¼ä»¥åå¹³è¡¡æè½èæ°¸çºæ§ãç ç©¶çµææ¨å¨å¼å°ç ç©¶äººå¡ãå¾æ¥­äººå¡åæ¿ç­å¶å®èå¶å®æ°¸çº AI ç³»çµ±çå¯è¡ç­ç¥ï¼çºäººå·¥æºæ§å¹é¤è² è²¬ä»»ä¸æ³¨éç°å¢çæªä¾ã

##### **Foundation Models for Low-Resource Language Education (Vision Paper)**
2412.04774v1 by Zhaojun Ding, Zhengliang Liu, Hanqi Jiang, Yizhu Gao, Xiaoming Zhai, Tianming Liu, Ninghao Liu

Recent studies show that large language models (LLMs) are powerful tools for
working with natural language, bringing advances in many areas of computational
linguistics. However, these models face challenges when applied to low-resource
languages due to limited training data and difficulty in understanding cultural
nuances. Research is now focusing on multilingual models to improve LLM
performance for these languages. Education in these languages also struggles
with a lack of resources and qualified teachers, particularly in underdeveloped
regions. Here, LLMs can be transformative, supporting innovative methods like
community-driven learning and digital platforms. This paper discusses how LLMs
could enhance education for low-resource languages, emphasizing practical
applications and benefits.

æè¦ï¼æè¿çç ç©¶é¡¯ç¤ºï¼å¤§åèªè¨æ¨¡å (LLM) æ¯èçèªç¶èªè¨çå¼·å¤§å·¥å·ï¼çºè¨ç®èªè¨å­¸çè¨±å¤é åå¸¶ä¾é²å±ãç¶èï¼éäºæ¨¡åå¨æç¨æ¼ä½è³æºèªè¨ææé¢è¨ææ°ï¼å çºè¨ç·´è³ææéï¼ä¸é£ä»¥çè§£æåå·®ç°ãç ç©¶ç¾å¨æ­£å°æ³¨æ¼å¤èªè¨æ¨¡åï¼ä»¥æå LLM å¨éäºèªè¨ä¸­çæè½ãéäºèªè¨çæè²ä¹å ç¼ºä¹è³æºååæ ¼æå¸«èé¢è¨å°å¢ï¼ç¹å¥æ¯å¨æªéç¼å°åãå¨æ­¤ï¼LLM å¯ä»¥ç¼æ®è®é©ä½ç¨ï¼æ¯æ´ç¤¾ç¾¤é©åå­¸ç¿åæ¸ä½å¹³å°ç­åµæ°æ¹æ³ãæ¬ææ¢è¨ LLM å¦ä½æåä½è³æºèªè¨çæè²ï¼å¼·èª¿å¯¦éæç¨ååªé»ã

##### **DAWN-SI: Data-Aware and Noise-Informed Stochastic Interpolation for Solving Inverse Problems**
2412.04766v1 by Shadab Ahamed, Eldad Haber

Inverse problems, which involve estimating parameters from incomplete or
noisy observations, arise in various fields such as medical imaging,
geophysics, and signal processing. These problems are often ill-posed,
requiring regularization techniques to stabilize the solution. In this work, we
employ $\textit{Stochastic Interpolation}$ (SI), a generative framework that
integrates both deterministic and stochastic processes to map a simple
reference distribution, such as a Gaussian, to the target distribution. Our
method $\textbf{DAWN-SI}$: $\textbf{D}$ata-$\textbf{AW}$are and
$\textbf{N}$oise-informed $\textbf{S}$tochastic $\textbf{I}$nterpolation
incorporates data and noise embedding, allowing the model to access
representations about the measured data explicitly and also account for noise
in the observations, making it particularly robust in scenarios where data is
noisy or incomplete. By learning a time-dependent velocity field, SI not only
provides accurate solutions but also enables uncertainty quantification by
generating multiple plausible outcomes. Unlike pre-trained diffusion models,
which may struggle in highly ill-posed settings, our approach is trained
specifically for each inverse problem and adapts to varying noise levels. We
validate the effectiveness and robustness of our method through extensive
numerical experiments on tasks such as image deblurring and tomography.

æè¦ï¼ååé¡æ¶åå¾ä¸å®æ´ææéè¨çè§æ¸¬ä¸­ä¼°è¨åæ¸ï¼åºç¾å¨åç¨®é åï¼ä¾å¦é«å­¸å½±åãå°çç©çåè¨èèçãéäºåé¡éå¸¸æ¯ä¸é©å®çï¼éè¦æ­£ååæè¡ä¾ç©©å®è§£ãå¨éé å·¥ä½ä¸­ï¼æåæ¡ç¨é¨æ©æå¼ (SI)ï¼ä¸ç¨®çæå¼æ¶æ§ï¼æ´åç¢ºå®æ§åé¨æ©éç¨ï¼å°ç°¡å®çåèåä½ï¼ä¾å¦é«æ¯åä½ï¼å°æå°ç®æ¨åä½ãæåç DAWS-SI æ¹æ³ï¼è³ææç¥åéè¨ç¥æçé¨æ©æå¼ï¼çµåè³æåéè¨åµå¥ï¼è®æ¨¡åè½å¤ æç¢ºå­åéæ¼æ¸¬éè³æçè¡¨ç¤ºï¼ä¸¦èéè§æ¸¬ä¸­çéè¨ï¼ä½¿å¶å¨è³ææéè¨æä¸å®æ´çææ³ä¸ç¹å¥ç©©å¥ãééå­¸ç¿èæéç¸éçéåº¦å ´ï¼SI ä¸åæä¾ç²¾ç¢ºçè§£ï¼éè½ééç¢çå¤ååçççµæä¾éåä¸ç¢ºå®æ§ãèé åè¨ç·´çæ´æ£æ¨¡åä¸åï¼å¾èå¨é«åº¦ä¸é©å®çè¨­å®ä¸­å¯è½æéå°å°é£ï¼æåçåæ³æ¯éå°æ¯åååé¡é²è¡è¨ç·´ï¼ä¸¦é©æä¸åçéè¨ç­ç´ãæåééå»£æ³çæ¸å¼å¯¦é©é©è­äºæåæ¹æ³çæææ§åç©©å¥æ§ï¼éäºä»»ååæ¬å½±åå»æ¨¡ç³åæ·å±¤ææã

##### **Short-term Streamflow and Flood Forecasting based on Graph Convolutional Recurrent Neural Network and Residual Error Learning**
2412.04764v1 by Xiyu Pan, Neda Mohammadi, John E. Taylor

Accurate short-term streamflow and flood forecasting are critical for
mitigating river flood impacts, especially given the increasing climate
variability. Machine learning-based streamflow forecasting relies on large
streamflow datasets derived from rating curves. Uncertainties in rating curve
modeling could introduce errors to the streamflow data and affect the
forecasting accuracy. This study proposes a streamflow forecasting method that
addresses these data errors, enhancing the accuracy of river flood forecasting
and flood modeling, thereby reducing flood-related risk. A convolutional
recurrent neural network is used to capture spatiotemporal patterns, coupled
with residual error learning and forecasting. The neural network outperforms
commonly used forecasting models over 1-6 hours of forecasting horizons, and
the residual error learners can further correct the residual errors. This
provides a more reliable tool for river flood forecasting and climate
adaptation in this critical 1-6 hour time window for flood risk mitigation
efforts.

æè¦ï¼æºç¢ºçç­ææµéåæ´ªæ°´é æ¸¬å°æ¼æ¸è¼æ²³æµæ´ªæ°´å½±é¿è³ééè¦ï¼ç¹å¥æ¯å¨æ°£åè®ç°æ§å¢å çææ³ä¸ãåºæ¼æ©å¨å­¸ç¿çæµéé æ¸¬ä¾è³´æ¼å¾è©åæ²ç·ä¸­å¾åºçå¤§éæµéæ¸æéãè©åæ²ç·å»ºæ¨¡ä¸­çä¸ç¢ºå®æ§å¯è½æçµ¦æµéæ¸æå¼å¥èª¤å·®ï¼ä¸¦å½±é¿é æ¸¬æºç¢ºæ§ãæ¬ç ç©¶æåºäºä¸ç¨®æµéé æ¸¬æ¹æ³ä¾è§£æ±ºéäºæ¸æé¯èª¤ï¼å¾èæé«æ²³æµæ´ªæ°´é æ¸¬åæ´ªæ°´å»ºæ¨¡çæºç¢ºæ§ï¼å¾èéä½æ´ªæ°´ç¸éé¢¨éªãå·ç©éæ­¸ç¥ç¶ç¶²è·¯ç¨æ¼æç²æç©ºæ¨¡å¼ï¼ä¸¦çµåæ®å·®èª¤å·®å­¸ç¿åé æ¸¬ãç¥ç¶ç¶²è·¯å¨ 1-6 å°æçé æ¸¬ç¯åå§åªæ¼å¸¸ç¨çé æ¸¬æ¨¡åï¼èæ®å·®èª¤å·®å­¸ç¿å¨å¯ä»¥é²ä¸æ­¥æ ¡æ­£æ®å·®èª¤å·®ãéçºæ´ªæ°´é¢¨éªç·©è§£å·¥ä½ä¸­éåééµç 1-6 å°ææéçªå£ä¸­çæ²³æµæ´ªæ°´é æ¸¬åæ°£åé©ææä¾äºæ´å¯é çå·¥å·ã

##### **REGENT: A Retrieval-Augmented Generalist Agent That Can Act In-Context in New Environments**
2412.04759v1 by Kaustubh Sridhar, Souradeep Dutta, Dinesh Jayaraman, Insup Lee

Building generalist agents that can rapidly adapt to new environments is a
key challenge for deploying AI in the digital and real worlds. Is scaling
current agent architectures the most effective way to build generalist agents?
We propose a novel approach to pre-train relatively small policies on
relatively small datasets and adapt them to unseen environments via in-context
learning, without any finetuning. Our key idea is that retrieval offers a
powerful bias for fast adaptation. Indeed, we demonstrate that even a simple
retrieval-based 1-nearest neighbor agent offers a surprisingly strong baseline
for today's state-of-the-art generalist agents. From this starting point, we
construct a semi-parametric agent, REGENT, that trains a transformer-based
policy on sequences of queries and retrieved neighbors. REGENT can generalize
to unseen robotics and game-playing environments via retrieval augmentation and
in-context learning, achieving this with up to 3x fewer parameters and up to an
order-of-magnitude fewer pre-training datapoints, significantly outperforming
today's state-of-the-art generalist agents. Website:
https://kaustubhsridhar.github.io/regent-research

æè¦ï¼å»ºæ§è½å¿«éé©ææ°ç°å¢çéæä»£çï¼æ¯å° AI é¨ç½²å°æ¸ä½èçå¯¦ä¸ççä¸é ééµææ°ãæ´åç¾æçä»£çæ¶æ§æ¯å»ºæ§éæä»£çæææçæ¹æ³åï¼æåæåºä¸ååµæ°çæ¹æ³ï¼å¨ç¸å°å°çè³æéä¸é åè¨ç·´ç¸å°å°çæ¿ç­ï¼ä¸¦ééæå¢å­¸ç¿å°å®åèª¿æ´å°æªè¦éçç°å¢ä¸­ï¼èç¡éä»»ä½å¾®èª¿ãæåçééµæ³æ³æ¯ï¼æª¢ç´¢çºå¿«éé©ææä¾äºå¼·å¤§çåå·®ãäºå¯¦ä¸ï¼æåè­æäºå³ä½¿æ¯ä¸åç°¡å®çåºæ¼æª¢ç´¢ç 1-æè¿é°ä»£çï¼ä¹è½çºç¶ä»æåé²çéæä»£çæä¾ä¸åä»¤äººé©è¨çå¼·å¤§åºæºãå¾éåèµ·é»ï¼æåå»ºæ§äºä¸åååæ¸ä»£ç REGENTï¼å®å¨æ¥è©¢åæª¢ç´¢å°çé°å±åºåä¸è¨ç·´ä¸ååºæ¼Transformerçæ¿ç­ãREGENT å¯ä»¥ééæª¢ç´¢æ´ååæå¢å­¸ç¿ï¼æ¦æ¬å°æªè¦éçæ©å¨äººåéæ²ç°å¢ï¼ä¸¦ä»¥å°é 3 åçåæ¸åå°éä¸åæ¸éç´çé è¨ç·´è³æé»ä¾å¯¦ç¾éä¸é»ï¼é¡¯èåªæ¼ç¶ä»æåé²çéæä»£çãç¶²ç«ï¼
https://kaustubhsridhar.github.io/regent-research

##### **Measuring Goal-Directedness**
2412.04758v1 by Matt MacDermott, James Fox, Francesco Belardinelli, Tom Everitt

We define maximum entropy goal-directedness (MEG), a formal measure of
goal-directedness in causal models and Markov decision processes, and give
algorithms for computing it. Measuring goal-directedness is important, as it is
a critical element of many concerns about harm from AI. It is also of
philosophical interest, as goal-directedness is a key aspect of agency. MEG is
based on an adaptation of the maximum causal entropy framework used in inverse
reinforcement learning. It can measure goal-directedness with respect to a
known utility function, a hypothesis class of utility functions, or a set of
random variables. We prove that MEG satisfies several desiderata and
demonstrate our algorithms with small-scale experiments.

æè¦ï¼æåå®ç¾©æå¤§çµç®æ¨å°åæ§ (MEG)ï¼éæ¯ä¸åå ææ¨¡ååé¦¬å¯å¤«æ±ºç­éç¨ä¸­ç®æ¨å°åæ§çæ­£å¼è¡¡éæ¹æ³ï¼ä¸¦çµ¦åºè¨ç®å®çæ¼ç®æ³ãè¡¡éç®æ¨å°åæ§å¾éè¦ï¼å çºå®æ¯è¨±å¤éæ¼ AI å±å®³çééµå ç´ ãå®ä¹å·æå²å­¸æç¾©ï¼å çºç®æ¨å°åæ§æ¯è½åæ§çééµæ¹é¢ãMEG æ¯åºæ¼éåå¼·åå­¸ç¿ä¸­ä½¿ç¨çæå¤§å æçµæ¶æ§çæ¹ç·¨ãå®å¯ä»¥éå°å·²ç¥çæç¨å½æ¸ãæç¨å½æ¸çåè¨­é¡å¥æä¸çµé¨æ©è®æ¸ä¾è¡¡éç®æ¨å°åæ§ãæåè­æ MEG æ»¿è¶³äºå¹¾åçæ³æ¢ä»¶ï¼ä¸¦ä½¿ç¨å°è¦æ¨¡å¯¦é©ä¾å±ç¤ºæåçæ¼ç®æ³ã

##### **Ltri-LLM: Streaming Long Context Inference for LLMs with Training-Free Dynamic Triangular Attention Pattern**
2412.04757v1 by Hongyin Tang, Di Xiu, Lanrui Wang, Xiurui Geng, Jingang Wang, Xunliang Cai

The quadratic computational complexity of the attention mechanism in current
Large Language Models (LLMs) renders inference with long contexts prohibitively
expensive. To address this challenge, various approaches aim to retain critical
portions of the context to optimally approximate Full Attention (FA) through
Key-Value (KV) compression or Sparse Attention (SA), enabling the processing of
virtually unlimited text lengths in a streaming manner. However, these methods
struggle to achieve performance levels comparable to FA, particularly in
retrieval tasks. In this paper, our analysis of attention head patterns reveals
that LLMs' attention distributions show strong local correlations, naturally
reflecting a chunking mechanism for input context. We propose Ltri-LLM
framework, which divides KVs into spans, stores them in an offline index, and
retrieves the relevant KVs into memory for various queries. Experimental
results on popular long text benchmarks show that Ltri-LLM can achieve
performance close to FA while maintaining efficient, streaming-based inference.

æè¦ï¼ç¶åå¤§èªè¨æ¨¡å (LLM) ä¸­æ³¨æåæ©å¶çäºæ¬¡è¨ç®è¤éåº¦ä½¿å¾ä½¿ç¨é·æèé²è¡æ¨è«çææ¬é«å¾ä»¤äººæèå»æ­¥ãçºäºæå°éä¸ææ°ï¼åç¨®æ¹æ³æ¨å¨ä¿çæèä¸­çééµé¨åï¼ä»¥éééµå¼ (KV) å£ç¸®æç¨çæ³¨æå (SA) æä½³é¼è¿å¨æ³¨æå (FA)ï¼å¾èè½å¤ ä»¥ä¸²æµæ¹å¼èçå¹¾ä¹ç¡éçæå­é·åº¦ãç¶èï¼éäºæ¹æ³é£ä»¥éå°è FA ç¸ç¶çæè½æ°´æºï¼ç¹å¥æ¯å¨æª¢ç´¢ä»»åä¸­ãå¨æ¬æä¸­ï¼æåå°æ³¨æåé ­é¨æ¨¡å¼çåæè¡¨æï¼LLM çæ³¨æååä½é¡¯ç¤ºåºå¼·ççå±é¨éè¯æ§ï¼èªç¶å°åæ äºè¼¸å¥æèçåå¡æ©å¶ãæåæåº Ltri-LLM æ¡æ¶ï¼å®å° KV åæåå¡ï¼å°å®åå²å­å¨é¢ç·ç´¢å¼ä¸­ï¼ä¸¦å°ç¸é KV æª¢ç´¢å°è¨æ¶é«ä¸­ä»¥ä¾åç¨®æ¥è©¢ä½¿ç¨ãå¨æµè¡çé·æå­åºæºæ¸¬è©¦ä¸çå¯¦é©çµæè¡¨æï¼Ltri-LLM å¯ä»¥å¯¦ç¾æ¥è¿ FA çæè½ï¼åæä¿æé«æçåºæ¼ä¸²æµçæ¨è«ã

##### **ChatNVD: Advancing Cybersecurity Vulnerability Assessment with Large Language Models**
2412.04756v1 by Shivansh Chopra, Hussain Ahmad, Diksha Goel, Claudia Szabo

The increasing frequency and sophistication of cybersecurity vulnerabilities
in software systems underscore the urgent need for robust and effective methods
of vulnerability assessment. However, existing approaches often rely on highly
technical and abstract frameworks, which hinders understanding and increases
the likelihood of exploitation, resulting in severe cyberattacks. Given the
growing adoption of Large Language Models (LLMs) across diverse domains, this
paper explores their potential application in cybersecurity, specifically for
enhancing the assessment of software vulnerabilities. We propose ChatNVD, an
LLM-based cybersecurity vulnerability assessment tool leveraging the National
Vulnerability Database (NVD) to provide context-rich insights and streamline
vulnerability analysis for cybersecurity professionals, developers, and
non-technical users. We develop three variants of ChatNVD, utilizing three
prominent LLMs: GPT-4o mini by OpenAI, Llama 3 by Meta, and Gemini 1.5 Pro by
Google. To evaluate their efficacy, we conduct a comparative analysis of these
models using a comprehensive questionnaire comprising common security
vulnerability questions, assessing their accuracy in identifying and analyzing
software vulnerabilities. This study provides valuable insights into the
potential of LLMs to address critical challenges in understanding and
mitigation of software vulnerabilities.

æè¦ï¼é¨èè»é«ç³»çµ±ä¸­ç¶²è·¯å®å¨æ¼æ´çé »çåè¤éæ§èæ¥ä¿±å¢ï¼éå¸é¡¯äºå°å¥å¨ä¸ææçæ¼æ´è©ä¼°æ¹æ³çè¿«åéæ±ãç¶èï¼ç¾æçæ¹æ³éå¸¸ä¾è³´æ¼é«åº¦æè¡æ§åæ½è±¡çæ¶æ§ï¼éé»ç¤äºçè§£ä¸¦å¢å äºè¢«å©ç¨çå¯è½æ§ï¼å°è´å´éçç¶²è·¯æ»æãéæ¼å¤§åèªè¨æ¨¡å (LLM) å¨ä¸åé åä¸­è¢«å»£æ³æ¡ç¨ï¼æ¬ææ¢è¨äºå®åå¨ç¶²è·¯å®å¨ä¸­çæ½å¨æç¨ï¼ç¹å¥æ¯çºäºå å¼·è»é«æ¼æ´è©ä¼°ãæåæåºäº ChatNVDï¼éæ¯ä¸ååºæ¼ LLM çç¶²è·¯å®å¨æ¼æ´è©ä¼°å·¥å·ï¼å©ç¨åå®¶æ¼æ´è³æåº« (NVD) ä¾æä¾è±å¯çèæ¯è³è¨ï¼ä¸¦ç°¡åç¶²è·¯å®å¨å°æ¥­äººå¡ãéç¼äººå¡åéæè¡ä½¿ç¨èçæ¼æ´åæãæåéç¼äº ChatNVD çä¸åè®é«ï¼å©ç¨äºä¸åèåç LLMï¼OpenAI ç GPT-4o miniãMeta ç Llama 3 å Google ç Gemini 1.5 Proãçºäºè©ä¼°å®åçæè½ï¼æåä½¿ç¨åå«å¸¸è¦å®å¨æ¼æ´åé¡çç¶ååå·å°éäºæ¨¡åé²è¡æ¯è¼åæï¼è©ä¼°å®åå¨è­å¥ååæè»é«æ¼æ´æ¹é¢çæºç¢ºæ§ãæ¬ç ç©¶æä¾äºæå¹å¼çè¦è§£ï¼èªªæ LLM å¨è§£æ±ºçè§£åæ¸è¼è»é«æ¼æ´æ¹é¢çééµææ°çæ½åã

##### **Question Answering for Decisionmaking in Green Building Design: A Multimodal Data Reasoning Method Driven by Large Language Models**
2412.04741v1 by Yihui Li, Xiaoyue Yan, Hao Zhou, Borong Lin

In recent years, the critical role of green buildings in addressing energy
consumption and environmental issues has become widely acknowledged. Research
indicates that over 40% of potential energy savings can be achieved during the
early design stage. Therefore, decision-making in green building design (DGBD),
which is based on modeling and performance simulation, is crucial for reducing
building energy costs. However, the field of green building encompasses a broad
range of specialized knowledge, which involves significant learning costs and
results in low decision-making efficiency. Many studies have already applied
artificial intelligence (AI) methods to this field. Based on previous research,
this study innovatively integrates large language models with DGBD, creating
GreenQA, a question answering framework for multimodal data reasoning.
Utilizing Retrieval Augmented Generation, Chain of Thought, and Function Call
methods, GreenQA enables multimodal question answering, including weather data
analysis and visualization, retrieval of green building cases, and knowledge
query. Additionally, this study conducted a user survey using the GreenQA web
platform. The results showed that 96% of users believed the platform helped
improve design efficiency. This study not only effectively supports DGBD but
also provides inspiration for AI-assisted design.

æè¦ï¼è¿å¹´ä¾ï¼ç¶ è²å»ºç¯å¨è§£æ±ºè½æºæ¶èåç°å¢åé¡ä¸­æ®æ¼èè³ééè¦çè§è²ï¼éé»å·²ç²å¾å»£æ³èªå¯ãç ç©¶æåºï¼å¨æ©æè¨­è¨éæ®µï¼å¯éæè¶é 40% çæ½å¨ç¯è½ææãå æ­¤ï¼ç¶ è²å»ºç¯è¨­è¨ä¸­çæ±ºç­å¶å®ï¼DGBDï¼ï¼å¶åºç¤å¨æ¼æ¨¡åååæè½æ¨¡æ¬ï¼å°æ¼éä½å»ºç¯ç©çè½æºææ¬è³ééè¦ãç¶èï¼ç¶ è²å»ºç¯é ååå«äºå»£æ³çå°æ¥­ç¥è­ï¼éæ¶åäºå¤§éçå­¸ç¿ææ¬ï¼ä¸¦å°è´æ±ºç­å¶å®æçä½è½ãè¨±å¤ç ç©¶å·²å°äººå·¥æºæ§ï¼AIï¼æ¹æ³æç¨æ¼æ­¤é åãæ¬ç ç©¶åºæ¼ååçç ç©¶ï¼åµæ°å°å°å¤§åèªè¨æ¨¡åè DGBD æ´åï¼åµé äº GreenQAï¼ä¸åç¨æ¼å¤æ¨¡æè³ææ¨ççåç­æ¡æ¶ãå©ç¨æª¢ç´¢æ´åçæãæèéåå½æ¸å¼å«æ¹æ³ï¼GreenQA è½å¤ é²è¡å¤æ¨¡æåç­ï¼åæ¬å¤©æ°£è³æåæåè¦è¦ºåãæª¢ç´¢ç¶ è²å»ºç¯æ¡ä¾åç¥è­æ¥è©¢ãæ­¤å¤ï¼æ¬ç ç©¶ä½¿ç¨ GreenQA ç¶²è·¯å¹³å°é²è¡äºä¸é ä½¿ç¨èèª¿æ¥ãçµæé¡¯ç¤ºï¼96% çä½¿ç¨èèªçºè©²å¹³å°æå©æ¼æåè¨­è¨æçãæ¬ç ç©¶ä¸åææå°æ¯æ´ DGBDï¼ä¹çº AI è¼å©è¨­è¨æä¾äºéæã

##### **BESSTIE: A Benchmark for Sentiment and Sarcasm Classification for Varieties of English**
2412.04726v1 by Dipankar Srirag, Aditya Joshi, Jordan Painter, Diptesh Kanojia

Despite large language models (LLMs) being known to exhibit bias against
non-mainstream varieties, there are no known labeled datasets for sentiment
analysis of English. To address this gap, we introduce BESSTIE, a benchmark for
sentiment and sarcasm classification for three varieties of English: Australian
(en-AU), Indian (en-IN), and British (en-UK). Using web-based content from two
domains, namely, Google Place reviews and Reddit comments, we collect datasets
for these language varieties using two methods: location-based and topic-based
filtering. Native speakers of the language varieties manually annotate the
datasets with sentiment and sarcasm labels. Subsequently, we fine-tune nine
large language models (LLMs) (representing a range of encoder/decoder and
mono/multilingual models) on these datasets, and evaluate their performance on
the two tasks. Our results reveal that the models consistently perform better
on inner-circle varieties (i.e., en-AU and en-UK), with significant performance
drops for en-IN, particularly in sarcasm detection. We also report challenges
in cross-variety generalisation, highlighting the need for language
variety-specific datasets such as ours. BESSTIE promises to be a useful
evaluative benchmark for future research in equitable LLMs, specifically in
terms of language varieties. The BESSTIE datasets, code, and models are
currently available on request, while the paper is under review. Please email
aditya.joshi@unsw.edu.au.

æè¦ï¼åç®¡å¤§åèªè¨æ¨¡å (LLM) å·²ç¥æå°éä¸»æµè®é«è¡¨ç¾åºåè¦ï¼ä½ç®åæ²æå·²ç¥çæ¨ç±¤è³æéå¯ä¾åæè±èªçææãçºäºè§£æ±ºæ­¤å·®è·ï¼æåå¼å¥äº BESSTIEï¼éæ¯ä¸åéå°ä¸ç¨®è±èªè®é«ï¼æ¾³æ´²è±èª (en-AU)ãå°åº¦è±èª (en-IN) åè±åè±èª (en-UK)ï¼çææåè«·åºåé¡åºæºãæåä½¿ç¨ä¾èªå©åç¶²åï¼å³ Google å°é»è©è«å Reddit çè¨ï¼çç¶²è·¯å§å®¹ï¼ä½¿ç¨å©ç¨®æ¹æ³ï¼åºæ¼ä½ç½®ååºæ¼ä¸»é¡çç¯©é¸ï¼æ¶ééäºèªè¨è®é«çè³æéãéäºèªè¨è®é«çæ¯èªäººå£«ææåè¨»è§£è³æéï¼ä¸¦å ä¸ææåè«·åºæ¨ç±¤ãé¨å¾ï¼æåéå°éäºè³æéå¾®èª¿äºä¹åå¤§åèªè¨æ¨¡å (LLM)ï¼ä»£è¡¨ä¸ç³»åç·¨ç¢¼å¨/è§£ç¢¼å¨åå®èª/å¤èªæ¨¡åï¼ï¼ä¸¦è©ä¼°å®åå¨å©åä»»åä¸­çè¡¨ç¾ãæåççµæé¡¯ç¤ºï¼éäºæ¨¡åå¨å§åè®é«ï¼å³ en-AU å en-UKï¼ä¸çè¡¨ç¾å§çµè¼å¥½ï¼è en-IN çè¡¨ç¾é¡¯èä¸éï¼ç¹å¥æ¯å¨è«·åºåµæ¸¬æ¹é¢ãæåä¹å ±åäºè·¨è®é«æ¦æ¬çææ°ï¼å¼·èª¿äºå°åæåéæ¨£çèªè¨è®é«ç¹å®è³æéçéæ±ãBESSTIE æ¿è«¾æçºæªä¾å¨å¬å¹³ LLM ä¸­é²è¡ç ç©¶çæç¨è©ä¼°åºæºï¼ç¹å¥æ¯å¨èªè¨è®é«æ¹é¢ãBESSTIE è³æéãç¨å¼ç¢¼åæ¨¡åç®åå¯æè¦æ±åå¾ï¼èè«æåæ­£å¨å¯©æ¥ä¸­ãè«å¯é»å­éµä»¶è³ aditya.joshi@unsw.edu.auã

##### **Adaptive Optimization for Enhanced Efficiency in Large-Scale Language Model Training**
2412.04718v1 by Jiajing Chen, Bingying Liu, Xiaoxuan Liao, Jia Gao, Hongye Zheng, Yue Li

With the rapid development of natural language processing technology,
large-scale language models (LLM) have achieved remarkable results in a variety
of tasks. However, how to effectively train these huge models and improve their
performance and computational efficiency remains an important challenge. This
paper proposes an improved method based on adaptive optimization algorithm,
aiming to improve the training efficiency and final performance of LLM. Through
comparative experiments on the SQuAD and GLUE data sets, the experimental
results show that compared with traditional optimization algorithms (such as
SGD, Momentum, AdaGrad, RMSProp and Adam), the adaptive optimization algorithm
we proposed has better accuracy and F1 score. Both have achieved significant
improvements, especially showed stronger training capabilities when processed
large-scale texts and complex tasks. The research results verify the advantages
of adaptive optimization algorithms in large-scale language model training and
provide new ideas and directions for future optimization methods.

æè¦ï¼é¨èèªç¶èªè¨èçæè¡çå¿«éç¼å±ï¼
å¤§è¦æ¨¡èªè¨æ¨¡å (LLM) å¨åç¨®ä»»åä¸­åå¾äºé¡¯èçææã
ç¶èï¼å¦ä½ææå°è¨ç·´éäºé¾å¤§çæ¨¡åä¸¦æé«å¶
æè½åè¨ç®æçä»ç¶æ¯ä¸é éè¦çææ°ãæ¬ææåºäºä¸ç¨®åºæ¼èªé©æåªåæ¼ç®æ³çæ¹é²æ¹æ³ï¼
æ¨å¨æé« LLM çè¨ç·´æçåæçµæè½ãéé
å¨ SQuAD å GLUE è³æéä¸é²è¡æ¯è¼å¯¦é©ï¼å¯¦é©
çµæè¡¨æï¼èå³çµ±åªåæ¼ç®æ³ï¼ä¾å¦
SGDãMomentumãAdaGradãRMSProp å Adamï¼ç¸æ¯ï¼æåæåºçèªé©æåªåæ¼ç®æ³å·ææ´å¥½çæºç¢ºåº¦å F1 åæ¸ãå©èé½åå¾äºé¡¯èç
é²æ­¥ï¼ç¹å¥æ¯å¨èç
å¤§è¦æ¨¡æå­åè¤éä»»åæè¡¨ç¾åºæ´å¼·çè¨ç·´è½åãç ç©¶çµæé©è­äºèªé©æåªåæ¼ç®æ³å¨å¤§è¦æ¨¡èªè¨æ¨¡åè¨ç·´ä¸­çåªé»ï¼ä¸¦çºæªä¾çåªåæ¹æ³æä¾äºæ°çæè·¯åæ¹åã

##### **NoLoR: An ASR-Based Framework for Expedited Endangered Language Documentation with Neo-Aramaic as a Case Study**
2412.04717v1 by Matthew Nazari

The documentation of the Neo-Aramaic dialects before their extinction has
been described as the most urgent task in all of Semitology today. The death of
this language will be an unfathomable loss to the descendents of the indigenous
speakers of Aramaic, now predominantly diasporic after forced displacement due
to violence. This paper develops an ASR model to expedite the documentation of
this endangered language and generalizes the strategy in a new framework we
call NoLoR.

æè¦ï¼æ°äºæå§èªæ¹è¨å¨æ»çµåæçä¸çæä»¶ï¼è¢«æè¿°çºç¶ä»éèªå­¸ä¸­æè¿«åçä»»åãéç¨®èªè¨çæ¶éå°ææ¯äºæå§èªåä½æ°å¾è£ç¡æ³ä¼°éçæå¤±ï¼ç±æ¼æ´åèè¢«è¿«æµé¢å¤±æå¾ï¼ç¾å¨ä»åä¸»è¦æ£å±å¨åå¤ãæ¬æéç¼äºä¸å ASR æ¨¡åï¼ä»¥å ééç¨®çå±èªè¨çæä»¶åï¼ä¸¦å¨ä¸åæåç¨±çº NoLoR çæ°æ¶æ§ä¸­æ¦æ¬äºè©²ç­ç¥ã

##### **PCTreeS: 3D Point Cloud Tree Species Classification Using Airborne LiDAR Images**
2412.04714v1 by Hongjin Lin, Matthew Nazari, Derek Zheng

Reliable large-scale data on the state of forests is crucial for monitoring
ecosystem health, carbon stock, and the impact of climate change. Current
knowledge of tree species distribution relies heavily on manual data collection
in the field, which often takes years to complete, resulting in limited
datasets that cover only a small subset of the world's forests. Recent works
show that state-of-the-art deep learning models using Light Detection and
Ranging (LiDAR) images enable accurate and scalable classification of tree
species in various ecosystems. While LiDAR images contain rich 3D information,
most previous works flatten the 3D images into 2D projections to use
Convolutional Neural Networks (CNNs). This paper offers three significant
contributions: (1) we apply the deep learning framework for tree classification
in tropical savannas; (2) we use Airborne LiDAR images, which have a lower
resolution but greater scalability than Terrestrial LiDAR images used in most
previous works; (3) we introduce the approach of directly feeding 3D point
cloud images into a vision transformer model (PCTreeS). Our results show that
the PCTreeS approach outperforms current CNN baselines with 2D projections in
AUC (0.81), overall accuracy (0.72), and training time (~45 mins). This paper
also motivates further LiDAR image collection and validation for accurate
large-scale automatic classification of tree species.

æè¦ï¼å¯é çå¤§è¦æ¨¡æ£®æçæè³æå°æ¼ç£æ¸¬çæç³»çµ±å¥åº·ãç¢³å²éåæ°£åè®é·çå½±é¿è³ééè¦ãç®åå°æ¨¹ç¨®åå¸çäºè§£æ¥µåº¦ä¾è³´æ¼å¯¦å°æåæ¶éè³æï¼ééå¸¸éè¦è±è²»æ¸å¹´æè½å®æï¼å°è´åªè½æ¶µèå¨çå°æ¸æ£®æçæéè³æéãæè¿çç ç©¶é¡¯ç¤ºï¼ä½¿ç¨åæ¢æ¸¬åæ¸¬è· (LiDAR) å½±åçææ°æ·±åº¦å­¸ç¿æ¨¡åï¼å¯ä»¥å¨åç¨®çæç³»çµ±ä¸­å°æ¨¹ç¨®é²è¡æºç¢ºä¸å¯æ´åçåé¡ãåç®¡ LiDAR å½±ååå«è±å¯ç 3D è³è¨ï¼ä½å¤§å¤æ¸ååçç ç©¶æå° 3D å½±åå£ç¸®æ 2D æå½±ï¼ä»¥ä½¿ç¨å·ç©ç¥ç¶ç¶²è·¯ (CNN)ãæ¬ææä¾äºä¸é éè¦çè²¢ç»ï¼(1) æåå°æ·±åº¦å­¸ç¿æ¶æ§æç¨æ¼ç±å¸¶ç¨æ¨¹èåçæ¨¹ç¨®åé¡ï¼(2) æåä½¿ç¨æ©è¼ LiDAR å½±åï¼å¶è§£æåº¦è¼ä½ï¼ä½å¯æ´åæ§æ¯å¤§å¤æ¸ååç ç©¶ä¸­ä½¿ç¨çå°é¢ LiDAR å½±åæ´é«ï¼(3) æåå¼å¥äºç´æ¥å° 3D é»é²å½±åè¼¸å¥å°è¦è¦ºTransformeræ¨¡å (PCTreeS) çæ¹æ³ãæåççµæé¡¯ç¤ºï¼PCTreeS æ¹æ³å¨ AUC (0.81)ãæ´é«æºç¢ºåº¦ (0.72) åè¨ç·´æé (~45 åé) æ¹é¢åªæ¼ç¶åä½¿ç¨ 2D æå½±ç CNN åºæºãæ¬æä¹æ¿åµé²ä¸æ­¥æ¶éåé©è­ LiDAR å½±åï¼ä»¥é²è¡æºç¢ºçå¤§è¦æ¨¡æ¨¹ç¨®èªååé¡ã

##### **Parametric-ControlNet: Multimodal Control in Foundation Models for Precise Engineering Design Synthesis**
2412.04707v1 by Rui Zhou, Yanxia Zhang, Chenyang Yuan, Frank Permenter, Nikos Arechiga, Matt Klenk, Faez Ahmed

This paper introduces a generative model designed for multimodal control over
text-to-image foundation generative AI models such as Stable Diffusion,
specifically tailored for engineering design synthesis. Our model proposes
parametric, image, and text control modalities to enhance design precision and
diversity. Firstly, it handles both partial and complete parametric inputs
using a diffusion model that acts as a design autocomplete co-pilot, coupled
with a parametric encoder to process the information. Secondly, the model
utilizes assembly graphs to systematically assemble input component images,
which are then processed through a component encoder to capture essential
visual data. Thirdly, textual descriptions are integrated via CLIP encoding,
ensuring a comprehensive interpretation of design intent. These diverse inputs
are synthesized through a multimodal fusion technique, creating a joint
embedding that acts as the input to a module inspired by ControlNet. This
integration allows the model to apply robust multimodal control to foundation
models, facilitating the generation of complex and precise engineering designs.
This approach broadens the capabilities of AI-driven design tools and
demonstrates significant advancements in precise control based on diverse data
modalities for enhanced design generation.

æè¦ï¼æ¬æä»ç´¹ä¸åçææ¨¡åï¼æ¨å¨å° Stable Diffusion ç­å¤æ¨¡ææ§å¶ææ¬å°å½±ååºç¤çæå¼ AI æ¨¡åé²è¡æ§å¶ï¼ç¹å¥éå°å·¥ç¨è¨­è¨åæéèº«æé ãæåçæ¨¡åæåºåæ¸ãå½±ååæå­æ§å¶æ¨¡å¼ï¼ä»¥å¢å¼·è¨­è¨ç²¾åº¦åå¤æ¨£æ§ãé¦åï¼å®ä½¿ç¨ä¸åæ´æ£æ¨¡åèçé¨ååå®æ´çåæ¸è¼¸å¥ï¼è©²æ¨¡ååç¶è¨­è¨èªåå®æå¯é§é§ï¼ä¸¦çµåä¸ååæ¸ç·¨ç¢¼å¨ä¾èçè³è¨ãå¶æ¬¡ï¼è©²æ¨¡åå©ç¨çµè£åç³»çµ±æ§å°çµè£è¼¸å¥åä»¶å½±åï¼ç¶å¾ééåä»¶ç·¨ç¢¼å¨èçéäºå½±åä»¥æ·åå¿è¦çè¦è¦ºè³æãç¬¬ä¸ï¼æå­æè¿°éé CLIP ç·¨ç¢¼é²è¡æ´åï¼ç¢ºä¿å°è¨­è¨æåé²è¡å¨é¢è©®éãéäºå¤åè¼¸å¥ééå¤æ¨¡æèåæè¡é²è¡åæï¼å»ºç«ä¸åè¯ååµå¥ï¼ä½çºå ControlNet åç¼æ¨¡çµçè¼¸å¥ãéç¨®æ´åè®æ¨¡åè½å°åºç¤æ¨¡åå¥ç¨å¼·å¤§çå¤æ¨¡ææ§å¶ï¼ä¿é²çæè¤éä¸ç²¾ç¢ºçå·¥ç¨è¨­è¨ãéç¨®æ¹æ³æ´å±äº AI é©åè¨­è¨å·¥å·çè½åï¼ä¸¦å±ç¤ºäºåºæ¼å¤åè³ææ¨¡å¼çç²¾ç¢ºæ§å¶å¨å¢å¼·è¨­è¨çææ¹é¢çé¡¯èé²å±ã

##### **On Interpreting the Effectiveness of Unsupervised Software Traceability with Information Theory**
2412.04704v1 by David N. Palacio, Daniel Rodriguez-Cardenas, Denys Poshyvanyk, Kevin Moran

Traceability is a cornerstone of modern software development, ensuring system
reliability and facilitating software maintenance. While unsupervised
techniques leveraging Information Retrieval (IR) and Machine Learning (ML)
methods have been widely used for predicting trace links, their effectiveness
remains underexplored. In particular, these techniques often assume
traceability patterns are present within textual data - a premise that may not
hold universally. Moreover, standard evaluation metrics such as precision,
recall, accuracy, or F1 measure can misrepresent the model performance when
underlying data distributions are not properly analyzed. Given that automated
traceability techniques tend to struggle to establish links, we need further
insight into the information limits related to traceability artifacts. In this
paper, we propose an approach, TraceXplainer, for using information theory
metrics to evaluate and better understand the performance (limits) of
unsupervised traceability techniques. Specifically, we introduce
self-information, cross-entropy, and mutual information (MI) as metrics to
measure the informativeness and reliability of traceability links. Through a
comprehensive replication and analysis of well-studied datasets and techniques,
we investigate the effectiveness of unsupervised techniques that predict
traceability links using IR/ML. This application of TraceXplainer illustrates
an imbalance in typical traceability datasets where the source code has on
average 1.48 more information bits (i.e., entropy) than the linked
documentation. Additionally, we demonstrate that an average MI of 4.81 bits,
loss of 1.75, and noise of 0.28 bits signify that there are
information-theoretic limits on the effectiveness of unsupervised traceability
techniques. We hope these findings spur additional research on understanding
the limits and progress of traceability research.

æè¦ï¼<paragraph>è¿½æº¯æ§æ¯ç¾ä»£è»é«éç¼çåºç³ï¼ç¢ºä¿ç³»çµ±å¯é æ§ä¸¦ä¿é²è»é«ç¶­è­·ãåç®¡å©ç¨è³è¨æª¢ç´¢ (IR) åæ©å¨å­¸ç¿ (ML) æ¹æ³çéç£ç£æè¡å·²å»£æ³ç¨æ¼é æ¸¬è¿½æº¯é£çµï¼ä½å¶æææ§ä»æªååæ¢è¨ãç¹å¥æ¯ï¼éäºæè¡éå¸¸åè¨­è¿½æº¯æ¨¡å¼å­å¨æ¼æå­è³æä¸­ï¼èéé åæå¯è½ç¡æ³æ®éé©ç¨ãæ­¤å¤ï¼ç¶åºå±¤è³æåä½æªç¶é©ç¶åææï¼æ¨æºè©ä¼°ææ¨ï¼ä¾å¦ç²¾ç¢ºåº¦ãå¬åçãæºç¢ºåº¦æ F1 éæ¸¬ï¼å¯è½ææ²è§£æ¨¡åæè½ãéæ¼èªååè¿½æº¯æè¡å¾å¾é£ä»¥å»ºç«é£çµï¼æåéè¦é²ä¸æ­¥äºè§£èè¿½æº¯æ§äººå·¥è£½åç¸éçè³è¨éå¶ãå¨æ¬æä¸­ï¼æåæåº TraceXplainer æ¹æ³ï¼ä½¿ç¨è³è¨çè«ææ¨ä¾è©ä¼°åæ´æ·±å¥äºè§£éç£ç£è¿½æº¯æè¡çæè½ï¼éå¶ï¼ãå·é«ä¾èªªï¼æåå¼å¥èªè³è¨ãäº¤åçµåäºè³è¨ (MI) ä½çºææ¨ï¼ä»¥éæ¸¬è¿½æº¯é£çµçè³è¨éåå¯é æ§ãééå°ç ç©¶å®åçè³æéåæè¡é²è¡å¨é¢è¤è£½ååæï¼æåæ¢è¨ä½¿ç¨ IR/ML é æ¸¬è¿½æº¯é£çµçéç£ç£æè¡çæææ§ãTraceXplainer çæ­¤æç¨èªªæäºå¸åè¿½æº¯æ§è³æéçä¸å¹³è¡¡ï¼å¶ä¸­åå§ç¢¼å¹³åæ¯é£çµæä»¶å¤ 1.48 åè³è¨ä½åï¼å³çµï¼ãæ­¤å¤ï¼æåè­æå¹³å 4.81 ä½åç MIã1.75 çæå¤±å 0.28 ä½åçéè¨è¡¨ç¤ºéç£ç£è¿½æº¯æè¡çæææ§å­å¨è³è¨çè«éå¶ãæåå¸æéäºç¼ç¾è½æ¿åµæ´å¤ç ç©¶ï¼ä»¥äºè§£è¿½æº¯ç ç©¶çéå¶åé²å±ã</paragraph>

##### **Transformers Struggle to Learn to Search**
2412.04703v1 by Abulhair Saparov, Srushti Pawar, Shreyas Pimpalgaonkar, Nitish Joshi, Richard Yuanzhe Pang, Vishakh Padmakumar, Seyed Mehran Kazemi, Najoung Kim, He He

Search is an ability foundational in many important tasks, and recent studies
have shown that large language models (LLMs) struggle to perform search
robustly. It is unknown whether this inability is due to a lack of data,
insufficient model parameters, or fundamental limitations of the transformer
architecture. In this work, we use the foundational graph connectivity problem
as a testbed to generate effectively limitless high-coverage data to train
small transformers and test whether they can learn to perform search. We find
that, when given the right training distribution, the transformer is able to
learn to search.
  We analyze the algorithm that the transformer has learned through a novel
mechanistic interpretability technique that enables us to extract the
computation graph from the trained model. We find that for each vertex in the
input graph, transformers compute the set of vertices reachable from that
vertex. Each layer then progressively expands these sets, allowing the model to
search over a number of vertices exponential in the number of layers.
  However, we find that as the input graph size increases, the transformer has
greater difficulty in learning the task. This difficulty is not resolved even
as the number of parameters is increased, suggesting that increasing model
scale will not lead to robust search abilities. We also find that performing
search in-context (i.e., chain-of-thought) does not resolve this inability to
learn to search on larger graphs.

æè¦ï¼æå°æ¯è¨±å¤éè¦ä»»åä¸­çä¸é åºç¤è½åï¼æè¿çç ç©¶è¡¨æï¼å¤§åèªè¨æ¨¡å (LLM) é£ä»¥ç©©å¥å°å·è¡æå°ãç®åå°ä¸æ¸æ¥éç¨®ç¡è½æ¯æºæ¼è³æä¸è¶³ãæ¨¡ååæ¸ä¸è¶³ï¼éæ¯ Transformer æ¶æ§çåºæ¬éå¶ãå¨éé å·¥ä½ä¸­ï¼æåä½¿ç¨åºç¤åå½¢é£éæ§åé¡ä½çºæ¸¬è©¦å¹³å°ï¼çæææç¡éçé«è¦èçè³æï¼ä»¥è¨ç·´å°å Transformer ä¸¦æ¸¬è©¦å®åæ¯å¦è½å­¸æå·è¡æå°ãæåç¼ç¾ï¼ç¶çµ¦äºæ­£ç¢ºçè¨ç·´åä½æï¼Transformer è½å¤ å­¸ææå°ã
æåééä¸ç¨®æ°ç©çæ©å¶å¯è§£éæ§æè¡åæ Transformer å­¸å°çæ¼ç®æ³ï¼éè®æåè½å¤ å¾è¨ç·´å¥½çæ¨¡åä¸­æåéç®åå½¢ãæåç¼ç¾ï¼å°æ¼è¼¸å¥åå½¢ä¸­çæ¯åé é»ï¼Transformer æè¨ç®å¾è©²é é»å¯å°éçé é»éåãç¶å¾ï¼æ¯ä¸å±¤é½æéæ­¥æ´åéäºéåï¼è®æ¨¡åè½å¤ å¨èå±¤æ¸åææ¸éä¿çé é»æ¸ç®ä¸é²è¡æå°ã
ç¶èï¼æåç¼ç¾ï¼é¨èè¼¸å¥åå½¢å¤§å°çå¢å ï¼Transformer å¨å­¸ç¿ä»»åææéå°æ´å¤§çå°é£ãå³ä½¿å¢å åæ¸æ¸éï¼éç¨®å°é£ä¹ä¸æå¾å°è§£æ±ºï¼éè¡¨æå¢å æ¨¡åè¦æ¨¡ä¸æå¸¶ä¾ç©©å¥çæå°è½åãæåéç¼ç¾ï¼å¨ä¸ä¸æä¸­å·è¡æå°ï¼å³æèéï¼ç¡æ³è§£æ±ºéç¨®ç¡æ³å­¸ç¿å¨è¼å¤§åå½¢ä¸æå°çåé¡ã

##### **Privacy-Preserving Retrieval Augmented Generation with Differential Privacy**
2412.04697v1 by Tatsuki Koga, Ruihan Wu, Kamalika Chaudhuri

With the recent remarkable advancement of large language models (LLMs), there
has been a growing interest in utilizing them in the domains with highly
sensitive data that lies outside their training data. For this purpose,
retrieval augmented generation (RAG) is particularly effective -- it assists
LLMs by directly providing relevant information from the external knowledge
sources. However, without extra privacy safeguards, RAG outputs risk leaking
sensitive information from the external data source. In this work, we explore
RAG under differential privacy (DP), a formal guarantee of data privacy. The
main challenge with differentially private RAG is how to generate long accurate
answers within a moderate privacy budget. We address this by proposing an
algorithm that smartly spends privacy budget only for the tokens that require
the sensitive information and uses the non-private LLM for other tokens. Our
extensive empirical evaluations reveal that our algorithm outperforms the
non-RAG baseline under a reasonable privacy budget of $\epsilon\approx 10$
across different models and datasets.

æè¦ï¼é¨èå¤§åèªè¨æ¨¡å (LLM) è¿æçé¡¯èé²æ­¥ï¼
å¨å©ç¨å®åæ¼è¨ç·´è³æä¹å¤çé«æææ§è³æé åä¸­ï¼
å·²ç¶ç¢çäºè¶ä¾è¶å¤§çèè¶£ãçºæ­¤ï¼
æª¢ç´¢å¢å¼·çæ (RAG) ç¹å¥ææï¼å®ééç´æ¥æä¾ä¾èªå¤é¨ç¥è­ä¾æºçç¸éè³è¨ä¾åå© LLMãç¶èï¼å¨æ²æé¡å¤é±ç§ä¿éæªæ½çææ³ä¸ï¼RAG è¼¸åºææ´©æ¼ä¾èªå¤é¨è³æä¾æºçææè³è¨çé¢¨éªãå¨éé å·¥ä½ä¸­ï¼æåå¨å·®åé±ç§ (DP) ä¸æ¢ç´¢ RAGï¼éæ¯è³æé±ç§çæ­£å¼ä¿è­ãå·®åé±ç§ RAG çä¸»è¦ææ°æ¯å¦ä½å¨é©åº¦çé±ç§é ç®ä¸­ç¢çé·èæºç¢ºçç­æ¡ãæåééæåºä¸åæ¼ç®æ³ä¾è§£æ±ºéååé¡ï¼è©²æ¼ç®æ³å·§å¦å°åå°é±ç§é ç®è±è²»å¨éè¦ææè³è¨çç¬¦èä¸ï¼ä¸¦å°éç§æç LLM ç¨æ¼å¶ä»ç¬¦èãæåå»£æ³çç¶é©è©ä¼°é¡¯ç¤ºï¼æåçæ¼ç®æ³å¨ä¸åçæ¨¡ååè³æéä¸ï¼å¨åççé±ç§é ç® $\epsilon\approx 10$ ä¸ï¼åªæ¼é RAG åºæºã

##### **Smoothie: Label Free Language Model Routing**
2412.04692v1 by Neel Guha, Mayee F. Chen, Trevor Chow, Ishan S. Khare, Christopher RÃ©

Large language models (LLMs) are increasingly used in applications where LLM
inputs may span many different tasks. Recent work has found that the choice of
LLM is consequential, and different LLMs may be good for different input
samples. Prior approaches have thus explored how engineers might select an LLM
to use for each sample (i.e. routing). While existing routing methods mostly
require training auxiliary models on human-annotated data, our work explores
whether it is possible to perform unsupervised routing. We propose Smoothie, a
weak supervision-inspired routing approach that requires no labeled data. Given
a set of outputs from different LLMs, Smoothie constructs a latent variable
graphical model over embedding representations of observable LLM outputs and
unknown "true" outputs. Using this graphical model, we estimate
sample-dependent quality scores for each LLM, and route each sample to the LLM
with the highest corresponding score. We find that Smoothie's LLM
quality-scores correlate with ground-truth model quality (correctly identifying
the optimal model on 9/14 tasks), and that Smoothie outperforms baselines for
routing by up to 10 points accuracy.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM)  zunehmend in Anwendungen verwendet werden, bei denen LLM-Eingaben viele verschiedene Aufgaben umfassen kÃ¶nnen. JÃ¼ngste Arbeiten haben ergeben, dass die Wahl des LLM ausschlaggebend ist und verschiedene LLMs fÃ¼r verschiedene Eingabeproben geeignet sein kÃ¶nnen. Bisherige AnsÃ¤tze haben daher untersucht, wie Ingenieure ein LLM auswÃ¤hlen kÃ¶nnen, das fÃ¼r jede Probe verwendet werden soll (d. h. Routing). WÃ¤hrend bestehende Routing-Methoden meist erfordern, dass Hilfsmodelle fÃ¼r mit menschlichen Anmerkungen versehene Daten trainiert werden, untersucht unsere Arbeit, ob es mÃ¶glich ist, unÃ¼berwachtes Routing durchzufÃ¼hren. Wir schlagen Smoothie vor, einen von schwacher Ãberwachung inspirierten Routing-Ansatz, der keine beschrifteten Daten benÃ¶tigt. Angesichts einer Reihe von Ausgaben verschiedener LLMs konstruiert Smoothie ein latentes variables grafisches Modell Ã¼ber eingebettete ReprÃ¤sentationen von beobachtbaren LLM-Ausgaben und unbekannten âwahrenâ Ausgaben. Mithilfe dieses grafischen Modells schÃ¤tzen wir probenabhÃ¤ngige QualitÃ¤tswerte fÃ¼r jedes LLM und leiten jede Probe an das LLM mit der hÃ¶chsten entsprechenden Punktzahl weiter. Wir stellen fest, dass die LLM-QualitÃ¤tswerte von Smoothie mit der GrundwahrheitsmodellqualitÃ¤t korrelieren (die das optimale Modell bei 9/14 Aufgaben korrekt identifiziert) und dass Smoothie Basiswerte fÃ¼r Routing um bis zu 10 Punkte Genauigkeit Ã¼bertrifft.

##### **LLM-Align: Utilizing Large Language Models for Entity Alignment in Knowledge Graphs**
2412.04690v1 by Xuan Chen, Tong Lu, Zhichun Wang

Entity Alignment (EA) seeks to identify and match corresponding entities
across different Knowledge Graphs (KGs), playing a crucial role in knowledge
fusion and integration. Embedding-based entity alignment (EA) has recently
gained considerable attention, resulting in the emergence of many innovative
approaches. Initially, these approaches concentrated on learning entity
embeddings based on the structural features of knowledge graphs (KGs) as
defined by relation triples. Subsequent methods have integrated entities' names
and attributes as supplementary information to improve the embeddings used for
EA. However, existing methods lack a deep semantic understanding of entity
attributes and relations. In this paper, we propose a Large Language Model
(LLM) based Entity Alignment method, LLM-Align, which explores the
instruction-following and zero-shot capabilities of Large Language Models to
infer alignments of entities. LLM-Align uses heuristic methods to select
important attributes and relations of entities, and then feeds the selected
triples of entities to an LLM to infer the alignment results. To guarantee the
quality of alignment results, we design a multi-round voting mechanism to
mitigate the hallucination and positional bias issues that occur with LLMs.
Experiments on three EA datasets, demonstrating that our approach achieves
state-of-the-art performance compared to existing EA methods.

æè¦ï¼å¯¦é«å°é½ (EA) æ¨å¨è­å¥åå¹éä¸åç¥è­åè­ (KG) ä¸­å°æçå¯¦é«ï¼å¨ç¥è­èååæ´åä¸­æ®æ¼èè³ééè¦çè§è²ãåºæ¼åµå¥çå¯¦é«å°é½ (EA) è¿ä¾ååéæ³¨ï¼é²èå¬çåºè¨±å¤åµæ°çæ¹æ³ãæåï¼éäºæ¹æ³å°æ³¨æ¼æ ¹æç¥è­åè­ (KG) ççµæ§ç¹å¾µä¾å­¸ç¿å¯¦é«åµå¥ï¼éäºç¹å¾µç±éä¿ä¸åçµå®ç¾©ãå¾çºæ¹æ³å°å¯¦é«åç¨±åå±¬æ§æ´åçºè£åè³è¨ï¼ä»¥æ¹åç¨æ¼ EA çåµå¥ãç¶èï¼ç¾ææ¹æ³ç¼ºä¹å°å¯¦é«å±¬æ§åéä¿çæ·±å¥èªç¾©çè§£ãå¨æ¬æä¸­ï¼æåæåºäºä¸ç¨®åºæ¼å¤§åèªè¨æ¨¡å (LLM) çå¯¦é«å°é½æ¹æ³ LLM-Alignï¼è©²æ¹æ³æ¢ç´¢äºå¤§åèªè¨æ¨¡åçéµå¾ªæä»¤åé¶æ¬¡å­¸ç¿è½åï¼ä»¥æ¨è«å¯¦é«å°é½ãLLM-Align ä½¿ç¨åç¼å¼æ¹æ³ä¾é¸æå¯¦é«çéè¦å±¬æ§åéä¿ï¼ç¶å¾å°å¯¦é«çé¸å®ä¸åçµé¥å¥ LLM ä»¥æ¨è«å°é½çµæãçºäºä¿è­å°é½çµæçåè³ªï¼æåè¨­è¨äºä¸åå¤è¼ªæç¥¨æ©å¶ï¼ä»¥æ¸è¼ LLM ä¸­åºç¾çå¹»è¦ºåä½ç½®åå·®åé¡ãå¨ä¸å EA è³æéä¸çå¯¦é©è¡¨æï¼èç¾æç EA æ¹æ³ç¸æ¯ï¼æåçåæ³éå°äºæåé²çæè½ã

##### **Two stages domain invariant representation learners solve the large co-variate shift in unsupervised domain adaptation with two dimensional data domains**
2412.04682v1 by Hisashi Oshima, Tsuyoshi Ishizone, Tomoyuki Higuchi

Recent developments in the unsupervised domain adaptation (UDA) enable the
unsupervised machine learning (ML) prediction for target data, thus this will
accelerate real world applications with ML models such as image recognition
tasks in self-driving. Researchers have reported the UDA techniques are not
working well under large co-variate shift problems where e.g. supervised source
data consists of handwritten digits data in monotone color and unsupervised
target data colored digits data from the street view. Thus there is a need for
a method to resolve co-variate shift and transfer source labelling rules under
this dynamics. We perform two stages domain invariant representation learning
to bridge the gap between source and target with semantic intermediate data
(unsupervised). The proposed method can learn domain invariant features
simultaneously between source and intermediate also intermediate and target.
Finally this achieves good domain invariant representation between source and
target plus task discriminability owing to source labels. This induction for
the gradient descent search greatly eases learning convergence in terms of
classification performance for target data even when large co-variate shift. We
also derive a theorem for measuring the gap between trained models and
unsupervised target labelling rules, which is necessary for the free parameters
optimization. Finally we demonstrate that proposing method is superiority to
previous UDA methods using 4 representative ML classification datasets
including 38 UDA tasks. Our experiment will be a basis for challenging UDA
problems with large co-variate shift.

æè¦ï¼æè¿å¨ç¡ç£ç£é åé©æ (UDA) çç¼å±ï¼ä½¿å¾ç¡ç£ç£æ©å¨å­¸ç¿ (ML) é æ¸¬å¯æç¨æ¼ç®æ¨è³æï¼å æ­¤éå°å é ML æ¨¡åçå¯¦éæç¨ï¼ä¾å¦èªé§è»ä¸­çå½±åè¾¨è­ä»»åãç ç©¶äººå¡å ±åæåºï¼UDA æè¡å¨å¤§åå±è®ç°æ¸è½ç§»åé¡ä¸ç¡æ³é å©éä½ï¼ä¾å¦ç£ç£ä¾æºè³æåå«å®è²æå¯«æ¸å­è³æï¼èç¡ç£ç£ç®æ¨è³æååå«ä¾èªè¡æ¯çå½©è²æ¸å­è³æãå æ­¤ï¼éè¦ä¸ç¨®æ¹æ³ä¾è§£æ±ºå±è®ç°æ¸è½ç§»ï¼ä¸¦å¨æ­¤åæä¸è½ç§»ä¾æºæ¨ç±¤è¦åãæåå·è¡å©éæ®µç¶²åä¸è®è¡¨ç¤ºå­¸ç¿ï¼ä»¥ééèªæä¸­éè³æï¼ç¡ç£ç£ï¼ä¾å½åä¾æºèç®æ¨ä¹éçå·®è·ãææåºçæ¹æ³å¯ä»¥å¨ä¾æºèä¸­éï¼ä»¥åä¸­éèç®æ¨ä¹éåæå­¸ç¿ç¶²åä¸è®ç¹å¾µãæå¾ï¼éå¨ä¾æºæ¨ç±¤çå¹«å©ä¸ï¼éå°äºä¾æºèç®æ¨ä¹éè¯å¥½çç¶²åä¸è®è¡¨ç¤ºï¼ä»¥åä»»åå¯è¾¨å¥æ§ãéç¨®ç¨æ¼æ¢¯åº¦ä¸éæå°çæ­¸ç´ï¼å³ä½¿å¨å¤§åå±è®ç°æ¸è½ç§»çææ³ä¸ï¼ä¹è½å¤§å¹ç°¡åç®æ¨è³æåé¡æè½çå­¸ç¿æ¶æãæåä¹æ¨å°äºä¸åç¨æ¼æ¸¬éè¨ç·´æ¨¡åèç¡ç£ç£ç®æ¨æ¨ç±¤è¦åä¹éå·®è·çå®çï¼éå°æ¼èªç±åæ¸æä½³åèè¨æ¯å¿è¦çãæå¾ï¼æåè­æäºææåºçæ¹æ³åªæ¼ååç UDA æ¹æ³ï¼ä½¿ç¨ 4 åå·ä»£è¡¨æ§ç ML åé¡è³æéï¼å¶ä¸­åæ¬ 38 å UDA ä»»åãæåçå¯¦é©å°æçºææ°å·æå¤§åå±è®ç°æ¸è½ç§»ç UDA åé¡çåºç¤ã

