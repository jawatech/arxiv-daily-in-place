
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-10-21**|**Reflection-Bench: probing AI intelligence with reflection**|Lingyu Li et.al.|[2410.16270v1](http://arxiv.org/abs/2410.16270v1)|[link](https://github.com/yabyum/reflectionbench)|
|**2024-10-21**|**xGen-MM-Vid (BLIP-3-Video): You Only Need 32 Tokens to Represent a Video Even in VLMs**|Michael S. Ryoo et.al.|[2410.16267v1](http://arxiv.org/abs/2410.16267v1)|null|
|**2024-10-21**|**3DGS-Enhancer: Enhancing Unbounded 3D Gaussian Splatting with View-consistent 2D Diffusion Priors**|Xi Liu et.al.|[2410.16266v1](http://arxiv.org/abs/2410.16266v1)|null|
|**2024-10-21**|**CompassJudger-1: All-in-one Judge Model Helps Model Evaluation and Evolution**|Maosong Cao et.al.|[2410.16256v1](http://arxiv.org/abs/2410.16256v1)|[link](https://github.com/open-compass/compassjudger)|
|**2024-10-21**|**Can Knowledge Editing Really Correct Hallucinations?**|Baixiang Huang et.al.|[2410.16251v1](http://arxiv.org/abs/2410.16251v1)|[link](https://github.com/llm-editing/HalluEditBench)|
|**2024-10-21**|**Analyzing Context Contributions in LLM-based Machine Translation**|Emmanouil Zaranis et.al.|[2410.16246v1](http://arxiv.org/abs/2410.16246v1)|null|
|**2024-10-21**|**MoRE: Multi-Modal Contrastive Pre-training with Transformers on X-Rays, ECGs, and Diagnostic Report**|Samrajya Thapa et.al.|[2410.16239v1](http://arxiv.org/abs/2410.16239v1)|[link](https://github.com/svthapa/more)|
|**2024-10-21**|**ToW: Thoughts of Words Improve Reasoning in Large Language Models**|Zhikun Xu et.al.|[2410.16235v1](http://arxiv.org/abs/2410.16235v1)|null|
|**2024-10-21**|**Sketch2Code: Evaluating Vision-Language Models for Interactive Web Design Prototyping**|Ryan Li et.al.|[2410.16232v1](http://arxiv.org/abs/2410.16232v1)|null|
|**2024-10-21**|**Building A Coding Assistant via the Retrieval-Augmented Language Model**|Xinze Li et.al.|[2410.16229v1](http://arxiv.org/abs/2410.16229v1)|null|
|**2024-10-21**|**On Creating an English-Thai Code-switched Machine Translation in Medical Domain**|Parinthapat Pengpun et.al.|[2410.16221v1](http://arxiv.org/abs/2410.16221v1)|null|
|**2024-10-21**|**Pre-training Distillation for Large Language Models: A Design Space Exploration**|Hao Peng et.al.|[2410.16215v1](http://arxiv.org/abs/2410.16215v1)|null|
|**2024-10-21**|**Comprehensive benchmarking of large language models for RNA secondary structure prediction**|L. I. Zablocki et.al.|[2410.16212v1](http://arxiv.org/abs/2410.16212v1)|[link](https://github.com/sinc-lab/rna-llm-folding)|
|**2024-10-21**|**Compute-Constrained Data Selection**|Junjie Oscar Yin et.al.|[2410.16208v1](http://arxiv.org/abs/2410.16208v1)|[link](https://github.com/oseyosey/ccds)|
|**2024-10-21**|**CoT-TL: Low-Resource Temporal Knowledge Representation of Planning Instructions Using Chain-of-Thought Reasoning**|Kumar Manas et.al.|[2410.16207v1](http://arxiv.org/abs/2410.16207v1)|null|
|**2024-10-21**|**Systematic Review: Text Processing Algorithms in Machine Learning and Deep Learning for Mental Health Detection on Social Media**|Yuchen Cao et.al.|[2410.16204v1](http://arxiv.org/abs/2410.16204v1)|null|
|**2024-10-21**|**Improve Vision Language Model Chain-of-thought Reasoning**|Ruohong Zhang et.al.|[2410.16198v1](http://arxiv.org/abs/2410.16198v1)|null|
|**2024-10-21**|**Information for Conversation Generation: Proposals Utilising Knowledge Graphs**|Alex Clay et.al.|[2410.16196v1](http://arxiv.org/abs/2410.16196v1)|null|
|**2024-10-21**|**Contamination Report for Multilingual Benchmarks**|Sanchit Ahuja et.al.|[2410.16186v1](http://arxiv.org/abs/2410.16186v1)|null|
|**2024-10-21**|**RM-Bench: Benchmarking Reward Models of Language Models with Subtlety and Style**|Yantao Liu et.al.|[2410.16184v1](http://arxiv.org/abs/2410.16184v1)|[link](https://github.com/thu-keg/rm-bench)|
|**2024-10-21**|**MagicPIG: LSH Sampling for Efficient LLM Generation**|Zhuoming Chen et.al.|[2410.16179v1](http://arxiv.org/abs/2410.16179v1)|null|
|**2024-10-21**|**Exploring Pretraining via Active Forgetting for Improving Cross Lingual Transfer for Decoder Language Models**|Divyanshu Aggarwal et.al.|[2410.16168v1](http://arxiv.org/abs/2410.16168v1)|null|
|**2024-10-21**|**Beyond Filtering: Adaptive Image-Text Quality Enhancement for MLLM Pretraining**|Han Huang et.al.|[2410.16166v1](http://arxiv.org/abs/2410.16166v1)|[link](https://github.com/hanhuang22/aitqe)|
|**2024-10-21**|**From Tokens to Materials: Leveraging Language Models for Scientific Discovery**|Yuwei Wan et.al.|[2410.16165v1](http://arxiv.org/abs/2410.16165v1)|null|
|**2024-10-21**|**Sparkle: Mastering Basic Spatial Capabilities in Vision Language Models Elicits Generalization to Composite Spatial Reasoning**|Yihong Tang et.al.|[2410.16162v1](http://arxiv.org/abs/2410.16162v1)|null|
|**2024-10-21**|**Limpeh ga li gong: Challenges in Singlish Annotations**|Lynnette Hui Xian Ng et.al.|[2410.16156v1](http://arxiv.org/abs/2410.16156v1)|null|
|**2024-10-21**|**A Troublemaker with Contagious Jailbreak Makes Chaos in Honest Towns**|Tianyi Men et.al.|[2410.16155v1](http://arxiv.org/abs/2410.16155v1)|null|
|**2024-10-21**|**Pangea: A Fully Open Multilingual Multimodal LLM for 39 Languages**|Xiang Yue et.al.|[2410.16153v1](http://arxiv.org/abs/2410.16153v1)|null|
|**2024-10-21**|**Warped Diffusion: Solving Video Inverse Problems with Image Diffusion Models**|Giannis Daras et.al.|[2410.16152v2](http://arxiv.org/abs/2410.16152v2)|null|
|**2024-10-21**|**Small Contributions, Small Networks: Efficient Neural Network Pruning Based on Relative Importance**|Mostafa Hussien et.al.|[2410.16151v1](http://arxiv.org/abs/2410.16151v1)|null|
|**2024-10-21**|**PODTILE: Facilitating Podcast Episode Browsing with Auto-generated Chapters**|Azin Ghazimatin et.al.|[2410.16148v1](http://arxiv.org/abs/2410.16148v1)|null|
|**2024-10-21**|**1-bit AI Infra: Part 1.1, Fast and Lossless BitNet b1.58 Inference on CPUs**|Jinheng Wang et.al.|[2410.16144v1](http://arxiv.org/abs/2410.16144v1)|[link](https://github.com/microsoft/bitnet)|
|**2024-10-21**|**A Psycholinguistic Evaluation of Language Models' Sensitivity to Argument Roles**|Eun-Kyoung Rosa Lee et.al.|[2410.16139v1](http://arxiv.org/abs/2410.16139v1)|null|
|**2024-10-21**|**Modeling dynamic neural activity by combining naturalistic video stimuli and stimulus-independent latent factors**|Finn Schmidt et.al.|[2410.16136v1](http://arxiv.org/abs/2410.16136v1)|null|
|**2024-10-21**|**Beyond 2:4: exploring V:N:M sparsity for efficient transformer inference on GPUs**|Kang Zhao et.al.|[2410.16135v1](http://arxiv.org/abs/2410.16135v1)|null|
|**2024-10-21**|**A Data-driven Crowd Simulation Framework Integrating Physics-informed Machine Learning with Navigation Potential Fields**|Runkang Guo et.al.|[2410.16132v1](http://arxiv.org/abs/2410.16132v1)|null|
|**2024-10-21**|**Can Large Audio-Language Models Truly Hear? Tackling Hallucinations with Multi-Task Assessment and Stepwise Audio Reasoning**|Chun-Yi Kuan et.al.|[2410.16130v1](http://arxiv.org/abs/2410.16130v1)|null|
|**2024-10-21**|**SMART: Self-learning Meta-strategy Agent for Reasoning Tasks**|Rongxing Liu et.al.|[2410.16128v1](http://arxiv.org/abs/2410.16128v1)|[link](https://github.com/kumar-shridhar/smart)|
|**2024-10-21**|**SeaDAG: Semi-autoregressive Diffusion for Conditional Directed Acyclic Graph Generation**|Xinyi Zhou et.al.|[2410.16119v1](http://arxiv.org/abs/2410.16119v1)|null|
|**2024-10-21**|**Multimodal Flare Forecasting with Deep Learning**|Gr√©goire Francisco et.al.|[2410.16116v1](http://arxiv.org/abs/2410.16116v1)|null|
|**2024-10-21**|**Do LLMs write like humans? Variation in grammatical and rhetorical styles**|Alex Reinhart et.al.|[2410.16107v1](http://arxiv.org/abs/2410.16107v1)|null|
|**2024-10-21**|**Addressing Spectral Bias of Deep Neural Networks by Multi-Grade Deep Learning**|Ronglong Fang et.al.|[2410.16105v1](http://arxiv.org/abs/2410.16105v1)|[link](https://github.com/ronglong-fang/addressingspectralbiasviamgdl)|
|**2024-10-21**|**Neural Quantum Propagators for Driven-Dissipative Quantum Dynamics**|Jiaji Zhang et.al.|[2410.16091v1](http://arxiv.org/abs/2410.16091v1)|null|
|**2024-10-21**|**Analysing the Residual Stream of Language Models Under Knowledge Conflicts**|Yu Zhao et.al.|[2410.16090v1](http://arxiv.org/abs/2410.16090v1)|null|
|**2024-10-21**|**Multi-Sensor Fusion for UAV Classification Based on Feature Maps of Image and Radar Data**|Nikos Sakellariou et.al.|[2410.16089v1](http://arxiv.org/abs/2410.16089v1)|null|
|**2024-10-21**|**Fine-Tuning LLMs for Reliable Medical Question-Answering Services**|Ali Anaissi et.al.|[2410.16088v1](http://arxiv.org/abs/2410.16088v1)|null|
|**2024-10-21**|**Critical Example Mining for Vehicle Trajectory Prediction using Flow-based Generative Models**|Zhezhang Ding et.al.|[2410.16083v1](http://arxiv.org/abs/2410.16083v1)|null|
|**2024-10-21**|**CartesianMoE: Boosting Knowledge Sharing among Experts via Cartesian Product Routing in Mixture-of-Experts**|Zhenpeng Su et.al.|[2410.16077v2](http://arxiv.org/abs/2410.16077v2)|null|
|**2024-10-21**|**On-Device LLMs for SMEs: Challenges and Opportunities**|Jeremy Stephen Gabriel Yee et.al.|[2410.16070v2](http://arxiv.org/abs/2410.16070v2)|null|
|**2024-10-21**|**Rolling the DICE on Idiomaticity: How LLMs Fail to Grasp Context**|Maggie Mi et.al.|[2410.16069v1](http://arxiv.org/abs/2410.16069v1)|null|
|**2024-10-21**|**Integrated Image-Text Based on Semi-supervised Learning for Small Sample Instance Segmentation**|Ruting Chi et.al.|[2410.16063v1](http://arxiv.org/abs/2410.16063v1)|null|
|**2024-10-21**|**Surprise! Uniform Information Density Isn't the Whole Story: Predicting Surprisal Contours in Long-form Discourse**|Eleftheria Tsipidi et.al.|[2410.16062v1](http://arxiv.org/abs/2410.16062v1)|null|
|**2024-10-21**|**Large Language Models Know What To Say But Not When To Speak**|Muhammad Umair et.al.|[2410.16044v1](http://arxiv.org/abs/2410.16044v1)|null|
|**2024-10-21**|**TimeMixer++: A General Time Series Pattern Machine for Universal Predictive Analysis**|Shiyu Wang et.al.|[2410.16032v1](http://arxiv.org/abs/2410.16032v1)|null|
|**2024-10-21**|**ComPO: Community Preferences for Language Model Personalization**|Sachin Kumar et.al.|[2410.16027v1](http://arxiv.org/abs/2410.16027v1)|null|
|**2024-10-21**|**A New Approach to Solving SMAC Task: Generating Decision Tree Code from Large Language Models**|Yue Deng et.al.|[2410.16024v1](http://arxiv.org/abs/2410.16024v1)|[link](https://github.com/devindeng94/llm-smac)|
|**2024-10-21**|**Massimo: Public Queue Monitoring and Management using Mass-Spring Model**|Abhijeet Kumar et.al.|[2410.16012v1](http://arxiv.org/abs/2410.16012v1)|null|
|**2024-10-21**|**Resilient Temporal GCN for Smart Grid State Estimation Under Topology Inaccuracies**|Seyed Hamed Haghshenas et.al.|[2410.16008v1](http://arxiv.org/abs/2410.16008v1)|null|
|**2024-10-21**|**Are Language Model Logits Calibrated?**|Charles Lovering et.al.|[2410.16007v1](http://arxiv.org/abs/2410.16007v1)|null|
|**2024-10-21**|**Exploring Continual Fine-Tuning for Enhancing Language Ability in Large Language Model**|Divyanshu Aggarwal et.al.|[2410.16006v1](http://arxiv.org/abs/2410.16006v1)|null|
|**2024-10-21**|**Steering Knowledge Selection Behaviours in LLMs via SAE-Based Representation Engineering**|Yu Zhao et.al.|[2410.15999v1](http://arxiv.org/abs/2410.15999v1)|null|
|**2024-10-21**|**1024m at SMM4H 2024: Tasks 3, 5 & 6 -- Ensembles of Transformers and Large Language Models for Medical Text Classification**|Ram Mohan Rao Kadiyala et.al.|[2410.15998v1](http://arxiv.org/abs/2410.15998v1)|null|
|**2024-10-21**|**Augmenting Legal Decision Support Systems with LLM-based NLI for Analyzing Social Media Evidence**|Ram Mohan Rao Kadiyala et.al.|[2410.15990v1](http://arxiv.org/abs/2410.15990v1)|null|
|**2024-10-21**|**Analyzing Closed-loop Training Techniques for Realistic Traffic Agent Models in Autonomous Highway Driving Simulations**|Matthias Bitzer et.al.|[2410.15987v1](http://arxiv.org/abs/2410.15987v1)|null|
|**2024-10-21**|**PROMPTHEUS: A Human-Centered Pipeline to Streamline SLRs with LLMs**|Jo√£o Pedro Fernandes Torres et.al.|[2410.15978v2](http://arxiv.org/abs/2410.15978v2)|[link](https://github.com/joaopftorres/promptheus)|
|**2024-10-21**|**Enabling Energy-Efficient Deployment of Large Language Models on Memristor Crossbar: A Synergy of Large and Small**|Zhehui Wang et.al.|[2410.15977v1](http://arxiv.org/abs/2410.15977v1)|null|
|**2024-10-21**|**Large Language Models for Cross-lingual Emotion Detection**|Ram Mohan Rao Kadiyala et.al.|[2410.15974v1](http://arxiv.org/abs/2410.15974v1)|[link](https://github.com/1024-m/acl-2024-wassa-exalt)|
|**2024-10-21**|**Karush-Kuhn-Tucker Condition-Trained Neural Networks (KKT Nets)**|Shreya Arvind et.al.|[2410.15973v1](http://arxiv.org/abs/2410.15973v1)|null|
|**2024-10-21**|**Policy-driven Knowledge Selection and Response Generation for Document-grounded Dialogue**|Longxuan Ma et.al.|[2410.15970v1](http://arxiv.org/abs/2410.15970v1)|null|
|**2024-10-21**|**Self-Explained Keywords Empower Large Language Models for Code Generation**|Lishui Fan et.al.|[2410.15966v1](http://arxiv.org/abs/2410.15966v1)|null|
|**2024-10-21**|**Systematic Exploration of Dialogue Summarization Approaches for Reproducibility, Comparative Assessment, and Methodological Innovations for Advancing Natural Language Processing in Abstractive Summarization**|Yugandhar Reddy Gogireddy et.al.|[2410.15962v1](http://arxiv.org/abs/2410.15962v1)|null|
|**2024-10-21**|**Do Large Language Models Have an English Accent? Evaluating and Improving the Naturalness of Multilingual LLMs**|Yanzhu Guo et.al.|[2410.15956v1](http://arxiv.org/abs/2410.15956v1)|null|
|**2024-10-21**|**TS-ACL: A Time Series Analytic Continual Learning Framework for Privacy-Preserving and Class-Incremental Pattern Recognition**|Kejia Fan et.al.|[2410.15954v1](http://arxiv.org/abs/2410.15954v1)|null|
|**2024-10-21**|**User-centric evaluation of explainability of AI with and for humans: a comprehensive empirical study**|Szymon Bobek et.al.|[2410.15952v1](http://arxiv.org/abs/2410.15952v1)|null|
|**2024-10-21**|**Findings of the Third Shared Task on Multilingual Coreference Resolution**|Michal Nov√°k et.al.|[2410.15949v1](http://arxiv.org/abs/2410.15949v1)|null|
|**2024-10-21**|**Developing Retrieval Augmented Generation (RAG) based LLM Systems from PDFs: An Experience Report**|Ayman Asad Khan et.al.|[2410.15944v1](http://arxiv.org/abs/2410.15944v1)|[link](https://github.com/gpt-laboratory/rag-llm-development-guidebook-from-pdfs)|
|**2024-10-21**|**CausalGraph2LLM: Evaluating LLMs for Causal Queries**|Ivaxi Sheth et.al.|[2410.15939v1](http://arxiv.org/abs/2410.15939v1)|[link](https://github.com/ivaxi0s/causalgraph2llm)|
|**2024-10-21**|**Centrality-aware Product Retrieval and Ranking**|Hadeel Saadany et.al.|[2410.15930v1](http://arxiv.org/abs/2410.15930v1)|null|
|**2024-10-21**|**Yeah, Un, Oh: Continuous and Real-time Backchannel Prediction with Fine-tuning of Voice Activity Projection**|Koji Inoue et.al.|[2410.15929v1](http://arxiv.org/abs/2410.15929v1)|null|
|**2024-10-21**|**GReFEL: Geometry-Aware Reliable Facial Expression Learning under Bias and Imbalanced Data Distribution**|Azmine Toushik Wasi et.al.|[2410.15927v1](http://arxiv.org/abs/2410.15927v1)|null|
|**2024-10-21**|**Mitigating Object Hallucination via Concentric Causal Attention**|Yun Xing et.al.|[2410.15926v1](http://arxiv.org/abs/2410.15926v1)|[link](https://github.com/xing0047/cca-llava)|
|**2024-10-21**|**Bench4Merge: A Comprehensive Benchmark for Merging in Realistic Dense Traffic with Micro-Interactive Vehicles**|Zhengming Wang et.al.|[2410.15912v1](http://arxiv.org/abs/2410.15912v1)|null|
|**2024-10-21**|**DefVerify: Do Hate Speech Models Reflect Their Dataset's Definition?**|Urja Khurana et.al.|[2410.15911v1](http://arxiv.org/abs/2410.15911v1)|null|
|**2024-10-21**|**IGMaxHS -- An Incremental MaxSAT Solver with Support for XOR Clauses**|Ole L√ºbke et.al.|[2410.15897v1](http://arxiv.org/abs/2410.15897v1)|null|
|**2024-10-21**|**Model Mimic Attack: Knowledge Distillation for Provably Transferable Adversarial Examples**|Kirill Lukyanov et.al.|[2410.15889v1](http://arxiv.org/abs/2410.15889v1)|null|
|**2024-10-21**|**How to Build a Pre-trained Multimodal model for Simultaneously Chatting and Decision-making?**|Zuojin Tang et.al.|[2410.15885v1](http://arxiv.org/abs/2410.15885v1)|null|
|**2024-10-21**|**Using GPT Models for Qualitative and Quantitative News Analytics in the 2024 US Presidental Election Process**|Bohdan M. Pavlyshenko et.al.|[2410.15884v1](http://arxiv.org/abs/2410.15884v1)|null|
|**2024-10-21**|**MI-VisionShot: Few-shot adaptation of vision-language models for slide-level classification of histopathological images**|Pablo Meseguer et.al.|[2410.15881v1](http://arxiv.org/abs/2410.15881v1)|null|
|**2024-10-21**|**FlickerFusion: Intra-trajectory Domain Generalizing Multi-Agent RL**|Woosung Koh et.al.|[2410.15876v1](http://arxiv.org/abs/2410.15876v1)|null|
|**2024-10-21**|**Principles of semantic and functional efficiency in grammatical patterning**|Emily Cheng et.al.|[2410.15865v1](http://arxiv.org/abs/2410.15865v1)|null|
|**2024-10-21**|**Mesa-Extrapolation: A Weave Position Encoding Method for Enhanced Extrapolation in LLMs**|Xin Ma et.al.|[2410.15859v2](http://arxiv.org/abs/2410.15859v2)|null|
|**2024-10-21**|**Random Token Fusion for Multi-View Medical Diagnosis**|Jingyu Guo et.al.|[2410.15847v1](http://arxiv.org/abs/2410.15847v1)|null|
|**2024-10-21**|**LLM4GRN: Discovering Causal Gene Regulatory Networks with LLMs -- Evaluation through Synthetic Data Generation**|Tejumade Afonja et.al.|[2410.15828v1](http://arxiv.org/abs/2410.15828v1)|null|
|**2024-10-21**|**The effect of fine-tuning on language model toxicity**|Will Hawkins et.al.|[2410.15821v1](http://arxiv.org/abs/2410.15821v1)|[link](https://github.com/willhawkins3/finetuningtoxicity)|
|**2024-10-21**|**LiMTR: Time Series Motion Prediction for Diverse Road Users through Multimodal Feature Integration**|Camiel Oerlemans et.al.|[2410.15819v1](http://arxiv.org/abs/2410.15819v1)|[link](https://github.com/cing2/limtr)|
|**2024-10-21**|**Kaninfradet3D:A Road-side Camera-LiDAR Fusion 3D Perception Model based on Nonlinear Feature Extraction and Intrinsic Correlation**|Pei Liu et.al.|[2410.15814v1](http://arxiv.org/abs/2410.15814v1)|null|
|**2024-10-21**|**RAG4ITOps: A Supervised Fine-Tunable and Comprehensive RAG Framework for IT Operations and Maintenance**|Tianyang Zhang et.al.|[2410.15805v1](http://arxiv.org/abs/2410.15805v1)|null|
|**2024-10-21**|**Deep Learning and Data Augmentation for Detecting Self-Admitted Technical Debt**|Edi Sutoyo et.al.|[2410.15804v1](http://arxiv.org/abs/2410.15804v1)|[link](https://github.com/edisutoyo/satd-augmentation)|
|**2024-10-21**|**Habaek: High-performance water segmentation through dataset expansion and inductive bias optimization**|Hanseon Joo et.al.|[2410.15794v1](http://arxiv.org/abs/2410.15794v1)|[link](https://github.com/HanseonJoo/Habaek)|
|**2024-10-21**|**Arithmetic Transformers Can Length-Generalize in Both Operand Length and Count**|Hanseul Cho et.al.|[2410.15787v1](http://arxiv.org/abs/2410.15787v1)|[link](https://github.com/hanseuljo/position-coupling)|

#### Abstracts
##### **Reflection-Bench: probing AI intelligence with reflection**
2410.16270v1 by Lingyu Li, Yixu Wang, Haiquan Zhao, Shuqi Kong, Yan Teng, Chunbo Li, Yingchun Wang

The ability to adapt beliefs or behaviors in response to unexpected outcomes,
reflection, is fundamental to intelligent systems' interaction with the world.
From a cognitive science perspective, this serves as a core principle of
intelligence applicable to both human and AI systems. To address the debate on
the intelligence of large language models (LLMs), we propose Reflection-Bench,
a comprehensive benchmark comprising 7 tasks spanning core cognitive functions
crucial for reflection, including perception, memory, belief updating,
decision-making, prediction, counterfactual thinking, and meta-reflection. We
evaluate the performances of 13 prominent LLMs such as OpenAI o1, GPT-4, Claude
3.5 Sonnet, etc. The results indicate that current LLMs still lack satisfactory
reflection ability. We discuss the underlying causes of these results and
suggest potential avenues for future research. In conclusion, Reflection-Bench
offers both evaluation tools and inspiration for developing AI capable of
reliably interacting with the environment. Our data and code are available at
https://github.com/YabYum/ReflectionBench.

ÊëòË¶ÅÔºöÈÅ©Êáâ‰ø°ÂøµÊàñË°åÁÇ∫‰ª•ÊáâÂ∞çÊÑèÂ§ñÁµêÊûúÁöÑËÉΩÂäõÔºåÂèçÊÄùÔºåÊòØÊô∫ÊÖßÁ≥ªÁµ±Ëàá‰∏ñÁïå‰∫íÂãïÁöÑÂü∫Á§é„ÄÇ
ÂæûË™çÁü•ÁßëÂ≠∏ÁöÑËßíÂ∫¶‰æÜÁúãÔºåÈÄô‰ΩúÁÇ∫ÈÅ©Áî®Êñº‰∫∫È°ûÂíå AI Á≥ªÁµ±ÁöÑÊô∫ÊÖßÊ†∏ÂøÉÂéüÂâá„ÄÇÁÇ∫‰∫ÜÊé¢Ë®éÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊô∫ÊÖßÁà≠Ë≠∞ÔºåÊàëÂÄëÊèêÂá∫ Reflection-BenchÔºå‰∏ÄÂÄãÂÖ®Èù¢ÁöÑÂü∫Ê∫ñÔºåÂåÖÂê´Ê∂µËìãÂèçÊÄùÊ†∏ÂøÉË™çÁü•ÂäüËÉΩÁöÑ 7 È†Ö‰ªªÂãôÔºåÂåÖÊã¨ÊÑüÁü•„ÄÅË®òÊÜ∂„ÄÅ‰ø°ÂøµÊõ¥Êñ∞„ÄÅÊ±∫Á≠ñÂà∂ÂÆö„ÄÅÈ†êÊ∏¨„ÄÅÂèç‰∫ãÂØ¶ÊÄùËÄÉÂíåÂÖÉÂèçÊÄù„ÄÇÊàëÂÄëË©ï‰º∞‰∫Ü 13 ÂÄãËëóÂêçÁöÑ LLM ÁöÑÊÄßËÉΩÔºå‰æãÂ¶Ç OpenAI o1„ÄÅGPT-4„ÄÅClaude 3.5 Sonnet Á≠â„ÄÇÁµêÊûúË°®ÊòéÔºåÁõÆÂâçÁöÑ LLM ‰ªçÁÑ∂Áº∫‰πè‰ª§‰∫∫ÊªøÊÑèÁöÑÂèçÊÄùËÉΩÂäõ„ÄÇÊàëÂÄëË®éË´ñ‰∫ÜÈÄô‰∫õÁµêÊûúÁöÑÊ†πÊú¨ÂéüÂõ†Ôºå‰∏¶Âª∫Ë≠∞‰∫ÜÊú™‰æÜÁ†îÁ©∂ÁöÑÊΩõÂú®ÈÄîÂæë„ÄÇÁ∏Ω‰πãÔºåReflection-Bench Êèê‰æõ‰∫ÜË©ï‰º∞Â∑•ÂÖ∑ÂíåÈùàÊÑüÔºåÁî®ÊñºÈñãÁôºËÉΩÂ§†ÂèØÈù†Âú∞ËàáÁí∞Â¢É‰∫íÂãïÁöÑ AI„ÄÇÊàëÂÄëÁöÑË≥áÊñôÂíåÁ®ãÂºèÁ¢ºÂèØÂú® https://github.com/YabYum/ReflectionBench ÂèñÂæó„ÄÇ

##### **xGen-MM-Vid (BLIP-3-Video): You Only Need 32 Tokens to Represent a Video Even in VLMs**
2410.16267v1 by Michael S. Ryoo, Honglu Zhou, Shrikant Kendre, Can Qin, Le Xue, Manli Shu, Silvio Savarese, Ran Xu, Caiming Xiong, Juan Carlos Niebles

We present xGen-MM-Vid (BLIP-3-Video): a multimodal language model for
videos, particularly designed to efficiently capture temporal information over
multiple frames. BLIP-3-Video takes advantage of the 'temporal encoder' in
addition to the conventional visual tokenizer, which maps a sequence of tokens
over multiple frames into a compact set of visual tokens. This enables
BLIP3-Video to use much fewer visual tokens than its competing models (e.g., 32
vs. 4608 tokens). We explore different types of temporal encoders, including
learnable spatio-temporal pooling as well as sequential models like Token
Turing Machines. We experimentally confirm that BLIP-3-Video obtains video
question-answering accuracies comparable to much larger state-of-the-art models
(e.g., 34B), while being much smaller (i.e., 4B) and more efficient by using
fewer visual tokens. The project website is at
https://www.salesforceairesearch.com/opensource/xGen-MM-Vid/index.html

ÊëòË¶ÅÔºöÊàëÂÄëÊèêÂá∫‰∫Ü xGen-MM-Vid (BLIP-3-Video)Ôºö‰∏ÄÁ®ÆÂ§öÊ®°ÊÖãË™ûË®ÄÊ®°ÂûãÔºåÈÅ©Áî®ÊñºÂΩ±ÁâáÔºåÁâπÂà•Ë®≠Ë®àÁî®ÊñºÊúâÊïàÊçïÊçâÂ§öÂÄãÁï´Ê†ºÁöÑÊôÇÈñìË≥áË®ä„ÄÇBLIP-3-Video Èô§‰∫ÜÂÇ≥Áµ±ÁöÑË¶ñË¶∫Ê®ôË®òÂåñÂô®Â§ñÔºåÈÇÑÂà©Áî®„ÄåÊôÇÈñìÁ∑®Á¢ºÂô®„ÄçÔºåÂ∞áÂ§öÂÄãÁï´Ê†ºÁöÑÊ®ôË®òÂ∫èÂàóÂ∞çÊáâÂà∞‰∏ÄÁµÑÁ≤æÁ∞°ÁöÑË¶ñË¶∫Ê®ôË®ò„ÄÇÈÄô‰ΩøÂæó BLIP3-Video ËÉΩÂ§†‰ΩøÁî®ÁöÑË¶ñË¶∫Ê®ôË®òÊØîÁ´∂Áà≠Ê®°ÂûãÂ∞ëÂæóÂ§öÔºà‰æãÂ¶ÇÔºå32 ÂÄãÊ®ôË®òÂ∞ç 4608 ÂÄãÊ®ôË®òÔºâ„ÄÇÊàëÂÄëÊé¢Á¥¢‰∫Ü‰∏çÂêåÈ°ûÂûãÁöÑÊôÇÈñìÁ∑®Á¢ºÂô®ÔºåÂåÖÊã¨ÂèØÂ≠∏ÁøíÁöÑÊôÇÁ©∫Ê±†Âåñ‰ª•ÂèäÂ∫èÂàóÊ®°ÂûãÔºå‰æãÂ¶ÇÊ®ôË®òÂúñÈùàÊ©ü„ÄÇÊàëÂÄëÈÄèÈÅéÂØ¶È©óÁ¢∫Ë™çÔºåBLIP-3-Video Áç≤ÂæóÁöÑÂΩ±ÁâáÂïèÁ≠îÊ∫ñÁ¢∫Â∫¶ÂèØËàáÊõ¥Â§ßÁöÑÊúÄÂÖàÈÄ≤Ê®°ÂûãÔºà‰æãÂ¶ÇÔºå34BÔºâÁõ∏Â™≤ÁæéÔºåÂêåÊôÇÈ´îÁ©çÂ∞èÂæóÂ§öÔºàÂç≥ 4BÔºâÔºå‰∏¶‰∏îÈÄèÈÅé‰ΩøÁî®ËºÉÂ∞ëÁöÑË¶ñË¶∫Ê®ôË®òËÄåÊõ¥ÊúâÊïàÁéá„ÄÇÂ∞àÊ°àÁ∂≤Á´ô‰ΩçÊñº https://www.salesforceairesearch.com/opensource/xGen-MM-Vid/index.html

##### **3DGS-Enhancer: Enhancing Unbounded 3D Gaussian Splatting with View-consistent 2D Diffusion Priors**
2410.16266v1 by Xi Liu, Chaoyi Zhou, Siyu Huang

Novel-view synthesis aims to generate novel views of a scene from multiple
input images or videos, and recent advancements like 3D Gaussian splatting
(3DGS) have achieved notable success in producing photorealistic renderings
with efficient pipelines. However, generating high-quality novel views under
challenging settings, such as sparse input views, remains difficult due to
insufficient information in under-sampled areas, often resulting in noticeable
artifacts. This paper presents 3DGS-Enhancer, a novel pipeline for enhancing
the representation quality of 3DGS representations. We leverage 2D video
diffusion priors to address the challenging 3D view consistency problem,
reformulating it as achieving temporal consistency within a video generation
process. 3DGS-Enhancer restores view-consistent latent features of rendered
novel views and integrates them with the input views through a spatial-temporal
decoder. The enhanced views are then used to fine-tune the initial 3DGS model,
significantly improving its rendering performance. Extensive experiments on
large-scale datasets of unbounded scenes demonstrate that 3DGS-Enhancer yields
superior reconstruction performance and high-fidelity rendering results
compared to state-of-the-art methods. The project webpage is
https://xiliu8006.github.io/3DGS-Enhancer-project .

ÊëòË¶ÅÔºöÊñ∞Ë¶ñÂúñÂêàÊàêÊó®Âú®ÂæûÂ§öÂÄãËº∏ÂÖ•ÂΩ±ÂÉèÊàñÂΩ±ÁâáÁî¢ÁîüÂ†¥ÊôØÁöÑÊñ∞Ë¶ñÂúñÔºåËÄå 3D È´òÊñØÊï£Â∞Ñ (3DGS) Á≠âËøëÊúüÈÄ≤Â±ïÂ∑≤Âú®Áî¢ÁîüÂÖ∑ÊúâÈ´òÊïàÁÆ°Á∑öÁöÑÂÖâÂØ´ÂØ¶Ê∏≤ÊüìÊñπÈù¢ÂèñÂæóÈ°ØËëóÊàêÂäü„ÄÇÁÑ∂ËÄåÔºåÂú®ÂÖ∑ÊúâÊåëÊà∞ÊÄßÁöÑË®≠ÂÆö‰∏ãÁî¢ÁîüÈ´òÂìÅË≥™ÁöÑÊñ∞Ë¶ñÂúñÔºà‰æãÂ¶ÇËº∏ÂÖ•Ë¶ñÂúñÁ®ÄÁñèÔºâ‰ªçÁÑ∂ÂæàÂõ∞Èõ£ÔºåÂõ†ÁÇ∫Âú®Êé°Ê®£‰∏çË∂≥ÂçÄÂüü‰∏≠Ë≥áË®ä‰∏çË∂≥ÔºåÈÄöÂ∏∏ÊúÉÂ∞éËá¥ÊòéÈ°ØÁöÑ‰∫∫Â∑•Ë£ΩÂìÅ„ÄÇÊú¨ÊñáÊèêÂá∫ 3DGS-EnhancerÔºåÈÄôÊòØ‰∏ÄÂÄãÁî®ÊñºÂ¢ûÂº∑ 3DGS Ë°®ÂæµÂìÅË≥™ÁöÑÊñ∞ÁÆ°Á∑ö„ÄÇÊàëÂÄëÂà©Áî® 2D ÂΩ±ÁâáÊì¥Êï£ÂÖàÈ©ó‰æÜËß£Ê±∫ÂÖ∑ÊúâÊåëÊà∞ÊÄßÁöÑ 3D Ë¶ñÂúñ‰∏ÄËá¥ÊÄßÂïèÈ°åÔºå‰∏¶Â∞áÂÖ∂ÈáçÊñ∞Ë°®Ëø∞ÁÇ∫Âú®ÂΩ±ÁâáÁî¢ÁîüÈÅéÁ®ã‰∏≠ÂØ¶ÁèæÊôÇÈñì‰∏ÄËá¥ÊÄß„ÄÇ3DGS-Enhancer ÈÇÑÂéüÊ∏≤ÊüìÊñ∞Ë¶ñÂúñÁöÑË¶ñÂúñ‰∏ÄËá¥ÊΩõÂú®ÁâπÂæµÔºå‰∏¶ÈÄèÈÅéÊôÇÁ©∫Ëß£Á¢ºÂô®Â∞áÂÆÉÂÄëËàáËº∏ÂÖ•Ë¶ñÂúñÊï¥Âêà„ÄÇÁÑ∂Âæå‰ΩøÁî®Â¢ûÂº∑ÁöÑË¶ñÂúñÂæÆË™øÂàùÂßã 3DGS Ê®°ÂûãÔºåÈ°ØËëóÊîπÂñÑÂÖ∂Ê∏≤ÊüìÊïàËÉΩ„ÄÇÂú®ÁÑ°ÁïåÂ†¥ÊôØÁöÑÂ§ßË¶èÊ®°Ë≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÁöÑÂª£Ê≥õÂØ¶È©óË≠âÊòéÔºåËàáÊúÄÂÖàÈÄ≤ÁöÑÊñπÊ≥ïÁõ∏ÊØîÔºå3DGS-Enhancer Áî¢Áîü‰∫ÜÂÑ™Áï∞ÁöÑÈáçÂª∫ÊïàËÉΩÂíåÈ´ò‰øùÁúüÊ∏≤ÊüìÁµêÊûú„ÄÇÂ∞àÊ°àÁ∂≤È†ÅÁÇ∫ https://xiliu8006.github.io/3DGS-Enhancer-project „ÄÇ

##### **CompassJudger-1: All-in-one Judge Model Helps Model Evaluation and Evolution**
2410.16256v1 by Maosong Cao, Alexander Lam, Haodong Duan, Hongwei Liu, Songyang Zhang, Kai Chen

Efficient and accurate evaluation is crucial for the continuous improvement
of large language models (LLMs). Among various assessment methods, subjective
evaluation has garnered significant attention due to its superior alignment
with real-world usage scenarios and human preferences. However, human-based
evaluations are costly and lack reproducibility, making precise automated
evaluators (judgers) vital in this process. In this report, we introduce
\textbf{CompassJudger-1}, the first open-source \textbf{all-in-one} judge LLM.
CompassJudger-1 is a general-purpose LLM that demonstrates remarkable
versatility. It is capable of: 1. Performing unitary scoring and two-model
comparisons as a reward model; 2. Conducting evaluations according to specified
formats; 3. Generating critiques; 4. Executing diverse tasks like a general
LLM. To assess the evaluation capabilities of different judge models under a
unified setting, we have also established \textbf{JudgerBench}, a new benchmark
that encompasses various subjective evaluation tasks and covers a wide range of
topics. CompassJudger-1 offers a comprehensive solution for various evaluation
tasks while maintaining the flexibility to adapt to diverse requirements. Both
CompassJudger and JudgerBench are released and available to the research
community athttps://github.com/open-compass/CompassJudger. We believe that by
open-sourcing these tools, we can foster collaboration and accelerate progress
in LLM evaluation methodologies.

ÊëòË¶ÅÔºö<paragraph>Â∞çÊñºÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊåÅÁ∫åÊîπÈÄ≤ËÄåË®ÄÔºåÊúâÊïà‰∏îÊ∫ñÁ¢∫ÁöÑË©ï‰º∞Ëá≥ÈóúÈáçË¶Å„ÄÇÂú®ÂêÑÁ®ÆË©ï‰º∞ÊñπÊ≥ï‰∏≠Ôºå‰∏ªËßÄË©ï‰º∞Âõ†ÂÖ∂ËàáÁúüÂØ¶‰ΩøÁî®Â†¥ÊôØÂíå‰∫∫È°ûÂÅèÂ•ΩÁöÑÂá∫Ëâ≤Â∞çÈΩäËÄåÂÇôÂèóÈóúÊ≥®„ÄÇÁÑ∂ËÄåÔºåÂü∫Êñº‰∫∫È°ûÁöÑË©ï‰º∞ÊàêÊú¨È´òÊòÇ‰∏îÁº∫‰πèÂèØË§áË£ΩÊÄßÔºåÈÄô‰ΩøÂæóÁ≤æÁ¢∫ÁöÑËá™ÂãïÂåñË©ï‰º∞Âô®ÔºàË©ïÂØ©Âì°ÔºâÂú®Ê≠§ÈÅéÁ®ã‰∏≠Ëá≥ÈóúÈáçË¶Å„ÄÇÂú®Ê≠§Â†±Âëä‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫Ü\textbf{CompassJudger-1}ÔºåÁ¨¨‰∏ÄÂÄãÈñãÊ∫êÁöÑ\textbf{‰∏ÄÈ´îÂåñ}Ë©ïÂØ© LLM„ÄÇCompassJudger-1 ÊòØ‰∏ÄÊ¨æÈÄöÁî® LLMÔºåÂ±ïÁ§∫‰∫ÜÈùûÂá°ÁöÑÂ§öÂäüËÉΩÊÄß„ÄÇÂÆÉËÉΩÂ§†Ôºö1. ‰ΩúÁÇ∫ÁçéÂãµÊ®°ÂûãÂü∑Ë°åÂñÆÂÖÉË©ïÂàÜÂíåÂÖ©ÂÄãÊ®°ÂûãÊØîËºÉÔºõ2. Ê†πÊìöÊåáÂÆöÊ†ºÂºèÈÄ≤Ë°åË©ï‰º∞Ôºõ3. ÁîüÊàêË©ïË´ñÔºõ4. ÂÉèÈÄöÁî® LLM ‰∏ÄÊ®£Âü∑Ë°åÂ§öÊ®£ÂåñÁöÑ‰ªªÂãô„ÄÇÁÇ∫‰∫ÜÂú®Áµ±‰∏ÄÁöÑÁí∞Â¢É‰∏ãË©ï‰º∞‰∏çÂêåË©ïÂØ©Ê®°ÂûãÁöÑË©ï‰º∞ËÉΩÂäõÔºåÊàëÂÄëÈÇÑÂª∫Á´ã‰∫Ü\textbf{JudgerBench}Ôºå‰∏ÄÂÄãÊñ∞ÁöÑÂü∫Ê∫ñÔºåÊ∂µËìãÂêÑÁ®Æ‰∏ªËßÄË©ï‰º∞‰ªªÂãô‰∏¶Ê∂µËìãÂª£Ê≥õÁöÑ‰∏ªÈ°å„ÄÇCompassJudger-1 ÁÇ∫ÂêÑÁ®ÆË©ï‰º∞‰ªªÂãôÊèê‰æõ‰∫Ü‰∏ÄÂÄãÂÖ®Èù¢ÁöÑËß£Ê±∫ÊñπÊ°àÔºåÂêåÊôÇ‰øùÊåÅ‰∫ÜÈÅ©Êáâ‰∏çÂêåÈúÄÊ±ÇÁöÑÈùàÊ¥ªÊÄß„ÄÇCompassJudger Âíå JudgerBench ÈÉΩÂ∑≤ÁôºÂ∏ÉÔºå‰∏¶ÂèØ‰æõÁ†îÁ©∂Á§æÁæ§Âú® athttps://github.com/open-compass/CompassJudger ‰ΩøÁî®„ÄÇÊàëÂÄëÁõ∏‰ø°ÈÄöÈÅéÈñãÊ∫êÈÄô‰∫õÂ∑•ÂÖ∑ÔºåÊàëÂÄëÂèØ‰ª•‰øÉÈÄ≤Âçî‰Ωú‰∏¶Âä†ÈÄü LLM Ë©ï‰º∞ÊñπÊ≥ïÁöÑÈÄ≤Â±ï„ÄÇ</paragraph>

##### **Can Knowledge Editing Really Correct Hallucinations?**
2410.16251v1 by Baixiang Huang, Canyu Chen, Xiongxiao Xu, Ali Payani, Kai Shu

Large Language Models (LLMs) suffer from hallucinations, referring to the
non-factual information in generated content, despite their superior capacities
across tasks. Meanwhile, knowledge editing has been developed as a new popular
paradigm to correct the erroneous factual knowledge encoded in LLMs with the
advantage of avoiding retraining from scratch. However, one common issue of
existing evaluation datasets for knowledge editing is that they do not ensure
LLMs actually generate hallucinated answers to the evaluation questions before
editing. When LLMs are evaluated on such datasets after being edited by
different techniques, it is hard to directly adopt the performance to assess
the effectiveness of different knowledge editing methods in correcting
hallucinations. Thus, the fundamental question remains insufficiently
validated: Can knowledge editing really correct hallucinations in LLMs? We
proposed HalluEditBench to holistically benchmark knowledge editing methods in
correcting real-world hallucinations. First, we rigorously construct a massive
hallucination dataset with 9 domains, 26 topics and more than 6,000
hallucinations. Then, we assess the performance of knowledge editing methods in
a holistic way on five dimensions including Efficacy, Generalization,
Portability, Locality, and Robustness. Through HalluEditBench, we have provided
new insights into the potentials and limitations of different knowledge editing
methods in correcting hallucinations, which could inspire future improvements
and facilitate the progress in the field of knowledge editing.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂÑòÁÆ°Âú®ÂêÑÈ†Ö‰ªªÂãô‰∏≠Ë°®ÁèæÂÑ™Áï∞Ôºå‰ΩÜ‰ªçÂ≠òÂú®Áî¢ÁîüÁöÑÂÖßÂÆπ‰∏≠Âá∫ÁèæÈùû‰∫ãÂØ¶Ë≥áË®äÁöÑÂπªË¶∫ÂïèÈ°å„ÄÇËàáÊ≠§ÂêåÊôÇÔºåÁü•Ë≠òÁ∑®ËºØÂ∑≤Ë¢´ÈñãÁôºÁÇ∫‰∏ÄÁ®ÆÊñ∞ÁöÑÊµÅË°åÁØÑ‰æãÔºåÁî®Êñº‰øÆÊ≠£ LLM ‰∏≠Á∑®Á¢ºÁöÑÈåØË™§‰∫ãÂØ¶Áü•Ë≠òÔºå‰∏¶ÂÖ∑ÊúâÈÅøÂÖçÂæûÈ†≠ÈñãÂßãÈáçÊñ∞Ë®ìÁ∑¥ÁöÑÂÑ™Èªû„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÁü•Ë≠òÁ∑®ËºØË©ï‰º∞Ë≥áÊñôÈõÜÁöÑ‰∏ÄÂÄãÂ∏∏Ë¶ãÂïèÈ°åÊòØÔºåÂÆÉÂÄë‰∏¶Êú™Á¢∫‰øù LLM Âú®Á∑®ËºØÂâçÂØ¶ÈöõÂ∞çË©ï‰º∞ÂïèÈ°åÁî¢ÁîüÂπªË¶∫Á≠îÊ°à„ÄÇÁï∂ LLM Âú®Á∂ìÈÅé‰∏çÂêåÊäÄË°ìÁ∑®ËºØÂæåÂú®ÈÄô‰∫õË≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åË©ï‰º∞ÊôÇÔºåÂæàÈõ£Áõ¥Êé•Êé°Áî®ÊïàËÉΩ‰æÜË©ï‰º∞‰∏çÂêåÁü•Ë≠òÁ∑®ËºØÊñπÊ≥ïÂú®‰øÆÊ≠£ÂπªË¶∫ÊñπÈù¢ÁöÑÊúâÊïàÊÄß„ÄÇÂõ†Ê≠§Ôºå‰∏ÄÂÄãÂü∫Êú¨ÂïèÈ°å‰ªçÁÑ∂È©óË≠â‰∏çË∂≥ÔºöÁü•Ë≠òÁ∑®ËºØÊòØÂê¶ÁúüÁöÑÂèØ‰ª•‰øÆÊ≠£ LLM ‰∏≠ÁöÑÂπªË¶∫ÔºüÊàëÂÄëÊèêÂá∫‰∫Ü HalluEditBenchÔºå‰ª•ÂÖ®Èù¢Ë©ïÈáèÁü•Ë≠òÁ∑®ËºØÊñπÊ≥ïÂú®‰øÆÊ≠£ÁúüÂØ¶‰∏ñÁïåÂπªË¶∫ÊñπÈù¢ÁöÑË°®Áèæ„ÄÇÈ¶ñÂÖàÔºåÊàëÂÄëÂö¥Ë¨πÂú∞Âª∫Êßã‰∫Ü‰∏ÄÂÄãÂåÖÂê´ 9 ÂÄãÈ†òÂüü„ÄÅ26 ÂÄã‰∏ªÈ°åÂíåË∂ÖÈÅé 6,000 ÂÄãÂπªË¶∫ÁöÑÈæêÂ§ßÂπªË¶∫Ë≥áÊñôÈõÜ„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÂú®ÂåÖÊã¨ÊïàËÉΩ„ÄÅÊ¶ÇÂåñ„ÄÅÂèØÊîúÊÄß„ÄÅÂ±ÄÈÉ®ÊÄßÂíåÂÅ•ÂÖ®ÊÄßÁ≠â‰∫îÂÄãÈù¢ÂêëÂÖ®Èù¢Ë©ï‰º∞Áü•Ë≠òÁ∑®ËºØÊñπÊ≥ïÁöÑË°®Áèæ„ÄÇÈÄèÈÅé HalluEditBenchÔºåÊàëÂÄëÊèê‰æõ‰∫ÜÂ∞ç‰∏çÂêåÁü•Ë≠òÁ∑®ËºØÊñπÊ≥ïÂú®‰øÆÊ≠£ÂπªË¶∫ÊñπÈù¢ÁöÑÊΩõÂäõÂíåÈôêÂà∂ÁöÑÊñ∞Ë¶ãËß£ÔºåÈÄôÂèØ‰ª•ÊøÄÂãµÊú™‰æÜÁöÑÊîπÈÄ≤Ôºå‰∏¶‰øÉÈÄ≤Áü•Ë≠òÁ∑®ËºØÈ†òÂüüÁöÑÈÄ≤Â±ï„ÄÇ

##### **Analyzing Context Contributions in LLM-based Machine Translation**
2410.16246v1 by Emmanouil Zaranis, Nuno M. Guerreiro, Andr√© F. T. Martins

Large language models (LLMs) have achieved state-of-the-art performance in
machine translation (MT) and demonstrated the ability to leverage in-context
learning through few-shot examples. However, the mechanisms by which LLMs use
different parts of the input context remain largely unexplored. In this work,
we provide a comprehensive analysis of context utilization in MT, studying how
LLMs use various context parts, such as few-shot examples and the source text,
when generating translations. We highlight several key findings: (1) the source
part of few-shot examples appears to contribute more than its corresponding
targets, irrespective of translation direction; (2) finetuning LLMs with
parallel data alters the contribution patterns of different context parts; and
(3) there is a positional bias where earlier few-shot examples have higher
contributions to the translated sequence. Finally, we demonstrate that
inspecting anomalous context contributions can potentially uncover pathological
translations, such as hallucinations. Our findings shed light on the internal
workings of LLM-based MT which go beyond those known for standard
encoder-decoder MT models.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®Ê©üÂô®ÁøªË≠Ø (MT) ‰∏≠Â∑≤ÈÅîÂà∞ÊúÄÂÖàÈÄ≤ÁöÑÊïàËÉΩÔºå‰∏¶Ë≠âÊòé‰∫ÜÈÄèÈÅéÂ∞ëÊï∏ÁØÑ‰æãÈÄ≤Ë°åÊÉÖÂ¢ÉÂ≠∏ÁøíÁöÑËÉΩÂäõ„ÄÇÁÑ∂ËÄåÔºåLLM ‰ΩøÁî®Ëº∏ÂÖ•ÊÉÖÂ¢É‰∏çÂêåÈÉ®ÂàÜÁöÑÊ©üÂà∂Âú®ÂæàÂ§ßÁ®ãÂ∫¶‰∏ä‰ªçÊú™Ë¢´Êé¢Á¥¢„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèê‰æõ‰∫Ü MT ‰∏≠ÊÉÖÂ¢ÉÂà©Áî®ÁöÑÂÖ®Èù¢ÂàÜÊûêÔºåÁ†îÁ©∂ LLM Âú®Áî¢ÁîüÁøªË≠ØÊôÇÂ¶Ç‰Ωï‰ΩøÁî®ÂêÑÁ®ÆÊÉÖÂ¢ÉÈÉ®ÂàÜÔºå‰æãÂ¶ÇÂ∞ëÊï∏ÁØÑ‰æãÂíåÂéüÂßãÊñáÂ≠ó„ÄÇÊàëÂÄëÂº∑Ë™ø‰∫ÜÂπæÂÄãÈóúÈçµÁôºÁèæÔºö(1) Â∞ëÊï∏ÁØÑ‰æãÁöÑÂéüÂßãÈÉ®ÂàÜ‰ºº‰πéÊØîÂÖ∂Â∞çÊáâÁöÑÁõÆÊ®ôË≤¢ÁçªÊõ¥Â§öÔºåËàáÁøªË≠ØÊñπÂêëÁÑ°ÈóúÔºõ(2) ‰ΩøÁî®Âπ≥Ë°åË≥áÊñôÂæÆË™ø LLM ÊúÉÊîπËÆä‰∏çÂêåÊÉÖÂ¢ÉÈÉ®ÂàÜÁöÑË≤¢ÁçªÊ®°ÂºèÔºõ(3) Â≠òÂú®‰ΩçÁΩÆÂÅèÂ∑ÆÔºåÂÖ∂‰∏≠ËºÉÊó©ÁöÑÂ∞ëÊï∏ÁØÑ‰æãÂ∞çÁøªË≠ØÂ∫èÂàóÁöÑË≤¢ÁçªËºÉÈ´ò„ÄÇÊúÄÂæåÔºåÊàëÂÄëË≠âÊòéÊ™¢Êü•Áï∞Â∏∏ÁöÑÊÉÖÂ¢ÉË≤¢ÁçªÂèØËÉΩÊúÉÊè≠Èú≤ÁóÖÊÖãÁöÑÁøªË≠ØÔºå‰æãÂ¶ÇÂπªË¶∫„ÄÇÊàëÂÄëÁöÑÁôºÁèæÈó°Êòé‰∫ÜÂü∫Êñº LLM ÁöÑ MT ÁöÑÂÖßÈÉ®ÈÅã‰ΩúÔºåÈÄôË∂ÖÂá∫‰∫ÜÊ®ôÊ∫ñÁ∑®Á¢ºÂô®-Ëß£Á¢ºÂô® MT Ê®°ÂûãÊâÄÁü•ÁöÑÁØÑÂúç„ÄÇ

##### **MoRE: Multi-Modal Contrastive Pre-training with Transformers on X-Rays, ECGs, and Diagnostic Report**
2410.16239v1 by Samrajya Thapa, Koushik Howlader, Subhankar Bhattacharjee, Wei le

In this paper, we introduce a novel Multi-Modal Contrastive Pre-training
Framework that synergistically combines X-rays, electrocardiograms (ECGs), and
radiology/cardiology reports. Our approach leverages transformers to encode
these diverse modalities into a unified representation space, aiming to enhance
diagnostic accuracy and facilitate comprehensive patient assessments. We
utilize LoRA-Peft to significantly reduce trainable parameters in the LLM and
incorporate recent linear attention dropping strategy in the Vision
Transformer(ViT) for smoother attention. Furthermore, we provide novel
multimodal attention explanations and retrieval for our model. To the best of
our knowledge, we are the first to propose an integrated model that combines
X-ray, ECG, and Radiology/Cardiology Report with this approach. By utilizing
contrastive loss, MoRE effectively aligns modality-specific features into a
coherent embedding, which supports various downstream tasks such as zero-shot
classification and multimodal retrieval. Employing our proposed methodology, we
achieve state-of-the-art (SOTA) on the Mimic-IV, CheXpert, Edema Severity, and
PtbXl downstream datasets, surpassing existing multimodal approaches. Our
proposed framework shows significant improvements in capturing intricate
inter-modal relationships and its robustness in medical diagnosis that
establishes a framework for future research in multimodal learning in the
healthcare sector.

ÊëòË¶ÅÔºöÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÂ§öÊ®°ÊÖãÂ∞çÊØîÈ†êË®ìÁ∑¥Ê°ÜÊû∂ÔºåË©≤Ê°ÜÊû∂ÂçîÂêåÁµêÂêà‰∫Ü X Â∞ÑÁ∑ö„ÄÅÂøÉÈõªÂúñ (ECG) ÂíåÊîæÂ∞ÑÂ≠∏/ÂøÉËáüÁóÖÂ≠∏Â†±Âëä„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÂà©Áî®TransformerÂ∞áÈÄô‰∫õ‰∏çÂêåÁöÑÊ®°ÊÖãÁ∑®Á¢ºÂà∞‰∏ÄÂÄãÁµ±‰∏ÄÁöÑË°®Á§∫Á©∫Èñì‰∏≠ÔºåÊó®Âú®ÊèêÈ´òË®∫Êñ∑Ê∫ñÁ¢∫ÊÄß‰∏¶‰øÉÈÄ≤ÂÖ®Èù¢ÁöÑÊÇ£ËÄÖË©ï‰º∞„ÄÇÊàëÂÄëÂà©Áî® LoRA-Peft ‰æÜÈ°ØËëóÊ∏õÂ∞ë LLM ‰∏≠ÁöÑÂèØË®ìÁ∑¥ÂèÉÊï∏Ôºå‰∏¶Âú® Vision Transformer (ViT) ‰∏≠Á¥çÂÖ•ÊúÄËøëÁöÑÁ∑öÊÄßÊ≥®ÊÑèÂäõ‰∏ãÈôçÁ≠ñÁï•‰ª•ÂØ¶ÁèæÊõ¥Âπ≥ÊªëÁöÑÊ≥®ÊÑèÂäõ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁÇ∫ÊàëÂÄëÁöÑÊ®°ÂûãÊèê‰æõ‰∫ÜÊñ∞Á©éÁöÑÂ§öÊ®°ÊÖãÊ≥®ÊÑèÂäõËß£ÈáãÂíåÊ™¢Á¥¢„ÄÇÊìöÊàëÂÄëÊâÄÁü•ÔºåÊàëÂÄëÊòØÁ¨¨‰∏ÄÂÄãÊèêÂá∫ÁµêÂêà X Â∞ÑÁ∑ö„ÄÅECG ÂíåÊîæÂ∞ÑÂ≠∏/ÂøÉËáüÁóÖÂ≠∏Â†±ÂëäÁöÑÊï¥ÂêàÊ®°Âûã„ÄÇÈÄöÈÅéÂà©Áî®Â∞çÊØîÊêçÂ§±ÔºåMoRE ÊúâÊïàÂú∞Â∞áÁâπÂÆöÊñºÊ®°ÊÖãÁöÑÁâπÂæµÂ∞çÈΩäÂà∞‰∏ÄÂÄãÈÄ£Ë≤´ÁöÑÂµåÂÖ•‰∏≠ÔºåÈÄôÊîØÊåÅ‰∫ÜÂêÑÁ®Æ‰∏ãÊ∏∏‰ªªÂãôÔºå‰æãÂ¶ÇÈõ∂Ê¨°ÂàÜÈ°ûÂíåÂ§öÊ®°ÊÖãÊ™¢Á¥¢„ÄÇÊé°Áî®ÊàëÂÄëÊèêÂá∫ÁöÑÊñπÊ≥ïÔºåÊàëÂÄëÂú® Mimic-IV„ÄÅCheXpert„ÄÅEdema Severity Âíå PtbXl ‰∏ãÊ∏∏Êï∏ÊìöÈõÜ‰∏äÂèñÂæó‰∫ÜÊúÄÂÖàÈÄ≤ (SOTA) ÁöÑÊàêÂ∞±ÔºåË∂ÖË∂ä‰∫ÜÁèæÊúâÁöÑÂ§öÊ®°ÊÖãÊñπÊ≥ï„ÄÇÊàëÂÄëÊèêÂá∫ÁöÑÊ°ÜÊû∂Âú®ÊçïÊçâË§áÈõúÁöÑÊ®°ÈñìÈóú‰øÇÂèäÂÖ∂Âú®ÈÜ´ÁôÇË®∫Êñ∑‰∏≠ÁöÑÁ©©ÂÅ•ÊÄßÊñπÈù¢È°ØÁ§∫Âá∫È°ØËëóÁöÑÊîπÈÄ≤ÔºåÈÄôÁÇ∫ÈÜ´ÁôÇ‰øùÂÅ•È†òÂüüÁöÑÂ§öÊ®°ÊÖãÂ≠∏ÁøíÁöÑÊú™‰æÜÁ†îÁ©∂Âª∫Á´ã‰∫Ü‰∏ÄÂÄãÊ°ÜÊû∂„ÄÇ

##### **ToW: Thoughts of Words Improve Reasoning in Large Language Models**
2410.16235v1 by Zhikun Xu, Ming Shen, Jacob Dineen, Zhaonan Li, Xiao Ye, Shijie Lu, Aswin RRV, Chitta Baral, Ben Zhou

We introduce thoughts of words (ToW), a novel training-time data-augmentation
method for next-word prediction. ToW views next-word prediction as a core
reasoning task and injects fine-grained thoughts explaining what the next word
should be and how it is related to the previous contexts in pre-training texts.
Our formulation addresses two fundamental drawbacks of existing next-word
prediction learning schemes: they induce factual hallucination and are
inefficient for models to learn the implicit reasoning processes in raw texts.
While there are many ways to acquire such thoughts of words, we explore the
first step of acquiring ToW annotations through distilling from larger models.
After continual pre-training with only 70K ToW annotations, we effectively
improve models' reasoning performances by 7% to 9% on average and reduce model
hallucination by up to 10%. At the same time, ToW is entirely agnostic to tasks
and applications, introducing no additional biases on labels or semantics.

ÊëòË¶ÅÔºöÊàëÂÄëÂºïÂÖ•‰∫ÜÊñáÂ≠óÊÄùËÄÉ (ToW)Ôºå‰∏ÄÁ®ÆÊñ∞Á©éÁöÑË®ìÁ∑¥ÊôÇÈñìË≥áÊñôÊì¥ÂÖÖÊñπÊ≥ïÔºåÁî®Êñº‰∏ã‰∏ÄÂÄãÂ≠óË©ûÈ†êÊ∏¨„ÄÇToW Â∞á‰∏ã‰∏ÄÂÄãÂ≠óË©ûÈ†êÊ∏¨Ë¶ñÁÇ∫‰∏ÄÈ†ÖÊ†∏ÂøÉÊé®ÁêÜ‰ªªÂãôÔºå‰∏¶Ê≥®ÂÖ•Á≤æÁ¥∞ÁöÑÊÄùËÄÉÔºåË™™Êòé‰∏ã‰∏ÄÂÄãÂ≠óË©ûÊáâË©≤ÊòØ‰ªÄÈ∫ºÔºå‰ª•ÂèäÂÆÉÂ¶Ç‰ΩïËàáÈ†êË®ìÁ∑¥ÊñáÊú¨‰∏≠ÁöÑÂÖàÂâçÂÖßÂÆπÁõ∏Èóú„ÄÇÊàëÂÄëÁöÑË°®Ëø∞Ëß£Ê±∫‰∫ÜÁèæÊúâ‰∏ã‰∏ÄÂÄãÂ≠óË©ûÈ†êÊ∏¨Â≠∏ÁøíÊñπÊ°àÁöÑÂÖ©ÂÄãÂü∫Êú¨Áº∫ÈªûÔºöÂÆÉÂÄëÊúÉÂ∞éËá¥‰∫ãÂØ¶ÊÄßÂπªË¶∫ÔºåËÄå‰∏îÂ∞çÊñºÊ®°ÂûãÂ≠∏ÁøíÂéüÂßãÊñáÊú¨‰∏≠ÁöÑÈö±Âê´Êé®ÁêÜÈÅéÁ®ãËÄåË®ÄÊïàÁéá‰Ωé‰∏ã„ÄÇÂÑòÁÆ°ÊúâË®±Â§öÊñπÊ≥ïÂèØ‰ª•Áç≤ÂèñÊ≠§È°ûÊñáÂ≠óÊÄùËÄÉÔºå‰ΩÜÊàëÂÄëÊé¢Á¥¢‰∫ÜÈÄèÈÅéÂæûËºÉÂ§ßÁöÑÊ®°Âûã‰∏≠ËêÉÂèñ‰æÜÁç≤Âèñ ToW Ê®ôË®ªÁöÑÁ¨¨‰∏ÄÊ≠•„ÄÇÂú®ÂÉÖ‰ΩøÁî® 70K ToW Ê®ôË®ªÈÄ≤Ë°åÊåÅÁ∫åÈ†êË®ìÁ∑¥ÂæåÔºåÊàëÂÄëÊúâÊïàÂú∞Â∞áÊ®°ÂûãÁöÑÊé®ÁêÜÊïàËÉΩÂπ≥ÂùáÊèêÈ´ò‰∫Ü 7% Ëá≥ 9%Ôºå‰∏¶Â∞áÊ®°ÂûãÂπªË¶∫Ê∏õÂ∞ë‰∫ÜÂ§öÈÅî 10%„ÄÇÂêåÊôÇÔºåToW ÂÆåÂÖ®‰∏ç‰æùË≥¥‰ªªÂãôÂíåÊáâÁî®Ôºå‰∏çÊúÉÂ∞çÊ®ôÁ±§ÊàñË™ûÁæ©ÂºïÂÖ•È°çÂ§ñÁöÑÂÅèÂ∑Æ„ÄÇ

##### **Sketch2Code: Evaluating Vision-Language Models for Interactive Web Design Prototyping**
2410.16232v1 by Ryan Li, Yanzhe Zhang, Diyi Yang

Sketches are a natural and accessible medium for UI designers to
conceptualize early-stage ideas. However, existing research on UI/UX automation
often requires high-fidelity inputs like Figma designs or detailed screenshots,
limiting accessibility and impeding efficient design iteration. To bridge this
gap, we introduce Sketch2Code, a benchmark that evaluates state-of-the-art
Vision Language Models (VLMs) on automating the conversion of rudimentary
sketches into webpage prototypes. Beyond end-to-end benchmarking, Sketch2Code
supports interactive agent evaluation that mimics real-world design workflows,
where a VLM-based agent iteratively refines its generations by communicating
with a simulated user, either passively receiving feedback instructions or
proactively asking clarification questions. We comprehensively analyze ten
commercial and open-source models, showing that Sketch2Code is challenging for
existing VLMs; even the most capable models struggle to accurately interpret
sketches and formulate effective questions that lead to steady improvement.
Nevertheless, a user study with UI/UX experts reveals a significant preference
for proactive question-asking over passive feedback reception, highlighting the
need to develop more effective paradigms for multi-turn conversational agents.

ÊëòË¶ÅÔºöËçâÂúñÊòØ UI Ë®≠Ë®àÂ∏´Ê¶ÇÂøµÂåñÊó©ÊúüÈöéÊÆµÊÉ≥Ê≥ïÁöÑËá™ÁÑ∂‰∏îÊòìÊñº‰ΩøÁî®ÁöÑÂ™í‰ªã„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÁöÑ UI/UX Ëá™ÂãïÂåñÁ†îÁ©∂ÈÄöÂ∏∏ÈúÄË¶ÅÈ´ò‰øùÁúüËº∏ÂÖ•Ôºå‰æãÂ¶Ç Figma Ë®≠Ë®àÊàñË©≥Á¥∞Ëû¢ÂπïÊà™ÂúñÔºåÈÄôÈôêÂà∂‰∫ÜÂèØÂèäÊÄß‰∏¶ÈòªÁ§ô‰∫ÜÈ´òÊïàÁöÑË®≠Ë®àËø≠‰ª£„ÄÇÁÇ∫‰∫ÜÂΩåÂêàÈÄô‰∏ÄÂ∑ÆË∑ùÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü Sketch2CodeÔºåÈÄôÊòØ‰∏ÄÂÄãÂü∫Ê∫ñÊ∏¨Ë©¶ÔºåÁî®ÊñºË©ï‰º∞ÊúÄÂÖàÈÄ≤ÁöÑË¶ñË¶∫Ë™ûË®ÄÊ®°Âûã (VLM) Âú®Ëá™ÂãïÂ∞áÂü∫Êú¨ËçâÂúñËΩâÊèõÁÇ∫Á∂≤È†ÅÂéüÂûãÊñπÈù¢ÁöÑËÉΩÂäõ„ÄÇÈô§‰∫ÜÁ´ØÂà∞Á´ØÂü∫Ê∫ñÊ∏¨Ë©¶‰πãÂ§ñÔºåSketch2Code ÈÇÑÊîØÊè¥‰∫íÂãïÂºè‰ª£ÁêÜË©ï‰º∞ÔºåÊ®°Êì¨ÁúüÂØ¶‰∏ñÁïåÁöÑË®≠Ë®àÂ∑•‰ΩúÊµÅÁ®ãÔºåÂÖ∂‰∏≠Âü∫Êñº VLM ÁöÑ‰ª£ÁêÜÈÄöÈÅéËàáÊ®°Êì¨‰ΩøÁî®ËÄÖÊ∫ùÈÄöÔºåË¢´ÂãïÊé•Êî∂ÂõûÈ•ãË™™ÊòéÊàñ‰∏ªÂãïË©¢ÂïèÊæÑÊ∏ÖÂïèÈ°åÔºå‰ª•ÂèçË¶ÜÂÑ™ÂåñÂÖ∂ÁîüÊàê„ÄÇÊàëÂÄëÂÖ®Èù¢ÂàÜÊûê‰∫ÜÂçÅÂÄãÂïÜÊ•≠ÂíåÈñãÊ∫êÊ®°ÂûãÔºåË°®Êòé Sketch2Code Â∞çÁèæÊúâÁöÑ VLM ‰æÜË™™ÂÖ∑ÊúâÊåëÊà∞ÊÄßÔºõÂç≥‰ΩøÊòØÊúÄÊúâËÉΩÂäõÁöÑÊ®°Âûã‰πüÂæàÈõ£Ê∫ñÁ¢∫Âú∞Ëß£ÈáãËçâÂúñ‰∏¶Âà∂ÂÆöÊúâÊïàÁöÑÂïèÈ°åÔºåÂæûËÄåÂ∞éËá¥Á©©Ê≠•ÊîπÈÄ≤„ÄÇÂÑòÁÆ°Â¶ÇÊ≠§Ôºå‰∏ÄÈ†ÖÈáùÂ∞ç UI/UX Â∞àÂÆ∂ÁöÑ‰ΩøÁî®ËÄÖÁ†îÁ©∂È°ØÁ§∫ÔºåËàáË¢´ÂãïÊé•Êî∂ÂõûÈ•ãÁõ∏ÊØîÔºå‰∏ªÂãïÊèêÂïèÂÖ∑ÊúâÈ°ØËëóÁöÑÂÅèÂ•ΩÔºåÈÄôÂá∏È°Ø‰∫ÜÈñãÁôºÊõ¥ÊúâÊïàÁöÑÂ§öËº™Â∞çË©±‰ª£ÁêÜÁØÑ‰æãÁöÑÂøÖË¶ÅÊÄß„ÄÇ

##### **Building A Coding Assistant via the Retrieval-Augmented Language Model**
2410.16229v1 by Xinze Li, Hanbin Wang, Zhenghao Liu, Shi Yu, Shuo Wang, Shuo Wang, Yukun Yan, Yukai Fu, Yu Gu, Ge Yu

Pretrained language models have shown strong effectiveness in code-related
tasks, such as code retrieval, code generation, code summarization, and code
completion tasks. In this paper, we propose COde assistaNt viA
retrieval-augmeNted language model (CONAN), which aims to build a code
assistant by mimicking the knowledge-seeking behaviors of humans during coding.
Specifically, it consists of a code structure aware retriever (CONAN-R) and a
dual-view code representation-based retrieval-augmented generation model
(CONAN-G). CONAN-R pretrains CodeT5 using Code-Documentation Alignment and
Masked Entity Prediction tasks to make language models code structure-aware and
learn effective representations for code snippets and documentation. Then
CONAN-G designs a dual-view code representation mechanism for implementing a
retrieval-augmented code generation model. CONAN-G regards the code
documentation descriptions as prompts, which help language models better
understand the code semantics. Our experiments show that CONAN achieves
convincing performance on different code generation tasks and significantly
outperforms previous retrieval augmented code generation models. Our further
analyses show that CONAN learns tailored representations for both code snippets
and documentation by aligning code-documentation data pairs and capturing
structural semantics by masking and predicting entities in the code data.
Additionally, the retrieved code snippets and documentation provide necessary
information from both program language and natural language to assist the code
generation process. CONAN can also be used as an assistant for Large Language
Models (LLMs), providing LLMs with external knowledge in shorter code document
lengths to improve their effectiveness on various code tasks. It shows the
ability of CONAN to extract necessary information and help filter out the noise
from retrieved code documents.

ÊëòË¶ÅÔºö<paragraph>È†êË®ìÁ∑¥Ë™ûË®ÄÊ®°ÂûãÂú®ËàáÁ®ãÂºèÁ¢ºÁõ∏ÈóúÁöÑ‰ªªÂãô‰∏≠Â±ïÁèæÂá∫Âº∑Â§ßÁöÑÊïàËÉΩÔºå‰æãÂ¶ÇÁ®ãÂºèÁ¢ºÊì∑Âèñ„ÄÅÁ®ãÂºèÁ¢ºÁî¢Áîü„ÄÅÁ®ãÂºèÁ¢ºÊëòË¶ÅÂíåÁ®ãÂºèÁ¢ºÂÆåÊàê‰ªªÂãô„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫ÈÄèÈÅéÊì∑ÂèñÂ¢ûÂº∑Ë™ûË®ÄÊ®°ÂûãÔºàCONANÔºâÁöÑÁ®ãÂºèÁ¢ºÂä©ÁêÜÔºàCONANÔºâÔºåÂÖ∂ÁõÆÁöÑÊòØÈÄèÈÅéÊ®°Êì¨‰∫∫È°ûÂú®Á∑®Á¢ºÊúüÈñìÂ∞ãÊ±ÇÁü•Ë≠òÁöÑË°åÁÇ∫‰æÜÂª∫ÊßãÁ®ãÂºèÁ¢ºÂä©ÁêÜ„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÂÆÉÂåÖÂê´‰∏ÄÂÄãÁ®ãÂºèÁ¢ºÁµêÊßãÊÑüÁü•Êì∑ÂèñÂô®ÔºàCONAN-RÔºâÂíå‰∏ÄÂÄãÂü∫ÊñºÈõôË¶ñËßíÁ®ãÂºèÁ¢ºË°®Á§∫ÁöÑÊì∑ÂèñÂ¢ûÂº∑Áî¢ÁîüÊ®°ÂûãÔºàCONAN-GÔºâ„ÄÇCONAN-R ‰ΩøÁî®Á®ãÂºèÁ¢ºÊñá‰ª∂Â∞çÈΩäÂíåÈÅÆÁΩ©ÂØ¶È´îÈ†êÊ∏¨‰ªªÂãôÈ†êË®ìÁ∑¥ CodeT5Ôºå‰ª•‰ΩøË™ûË®ÄÊ®°ÂûãÂÖ∑ÊúâÁ®ãÂºèÁ¢ºÁµêÊßãÊÑüÁü•Ôºå‰∏¶Â≠∏ÁøíÁ®ãÂºèÁ¢ºÁâáÊÆµÂíåÊñá‰ª∂ÁöÑÊúâÊïàË°®Á§∫„ÄÇÁÑ∂ÂæåÔºåCONAN-G Ë®≠Ë®à‰∏ÄÂÄãÈõôË¶ñËßíÁ®ãÂºèÁ¢ºË°®Á§∫Ê©üÂà∂ÔºåÁî®ÊñºÂØ¶‰ΩúÊì∑ÂèñÂ¢ûÂº∑Á®ãÂºèÁ¢ºÁî¢ÁîüÊ®°Âûã„ÄÇCONAN-G Â∞áÁ®ãÂºèÁ¢ºÊñá‰ª∂ÊèèËø∞Ë¶ñÁÇ∫ÊèêÁ§∫ÔºåÈÄôÊúâÂä©ÊñºË™ûË®ÄÊ®°ÂûãÊõ¥‰∫ÜËß£Á®ãÂºèÁ¢ºË™ûÁæ©„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÈ°ØÁ§∫ÔºåCONAN Âú®‰∏çÂêåÁöÑÁ®ãÂºèÁ¢ºÁî¢Áîü‰ªªÂãô‰∏äÈÉΩËÉΩÈÅîÂà∞‰ª§‰∫∫‰ø°ÊúçÁöÑÊïàËÉΩÔºå‰∏¶‰∏îÈ°ØËëóÂÑ™ÊñºÂÖàÂâçÁöÑÊì∑ÂèñÂ¢ûÂº∑Á®ãÂºèÁ¢ºÁî¢ÁîüÊ®°Âûã„ÄÇÊàëÂÄëÈÄ≤‰∏ÄÊ≠•ÁöÑÂàÜÊûêÈ°ØÁ§∫ÔºåCONAN ÈÄèÈÅéÂ∞çÈΩäÁ®ãÂºèÁ¢ºÊñá‰ª∂Ë≥áÊñôÂ∞ç‰∏¶ÈÅÆÁΩ©ÂíåÈ†êÊ∏¨Á®ãÂºèÁ¢ºË≥áÊñô‰∏≠ÁöÑÂØ¶È´î‰æÜÊçïÊçâÁµêÊßãË™ûÁæ©ÔºåÂ≠∏ÁøíÁ®ãÂºèÁ¢ºÁâáÊÆµÂíåÊñá‰ª∂ÁöÑÂÆ¢Ë£ΩÂåñË°®Á§∫„ÄÇÊ≠§Â§ñÔºåÊì∑ÂèñÁöÑÁ®ãÂºèÁ¢ºÁâáÊÆµÂíåÊñá‰ª∂Êèê‰æõ‰∫ÜÁ®ãÂºèË™ûË®ÄÂíåËá™ÁÑ∂Ë™ûË®ÄÁöÑÂøÖË¶ÅË≥áË®äÔºå‰ª•ÂçîÂä©Á®ãÂºèÁ¢ºÁî¢ÁîüÈÅéÁ®ã„ÄÇCONAN ‰πüÂèØ‰ª•Áî®‰ΩúÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâÁöÑÂä©ÁêÜÔºåÁÇ∫ LLM Êèê‰æõËºÉÁü≠Á®ãÂºèÁ¢ºÊñá‰ª∂Èï∑Â∫¶ÁöÑÂ§ñÈÉ®Áü•Ë≠òÔºå‰ª•ÊèêÈ´òÂÖ∂Âú®ÂêÑÁ®ÆÁ®ãÂºèÁ¢º‰ªªÂãô‰∏äÁöÑÊïàËÉΩ„ÄÇÈÄôÈ°ØÁ§∫‰∫Ü CONAN ÂæûÊì∑ÂèñÁöÑÁ®ãÂºèÁ¢ºÊñá‰ª∂‰∏≠Êì∑ÂèñÂøÖË¶ÅË≥áË®ä‰∏¶ÂçîÂä©ÈÅéÊøæÈõúË®äÁöÑËÉΩÂäõ„ÄÇ</paragraph>

##### **On Creating an English-Thai Code-switched Machine Translation in Medical Domain**
2410.16221v1 by Parinthapat Pengpun, Krittamate Tiankanon, Amrest Chinkamol, Jiramet Kinchagawat, Pitchaya Chairuengjitjaras, Pasit Supholkhan, Pubordee Aussavavirojekul, Chiraphat Boonnag, Kanyakorn Veerakanjana, Hirunkul Phimsiri, Boonthicha Sae-jia, Nattawach Sataudom, Piyalitt Ittichaiwong, Peerat Limkonchotiwat

Machine translation (MT) in the medical domain plays a pivotal role in
enhancing healthcare quality and disseminating medical knowledge. Despite
advancements in English-Thai MT technology, common MT approaches often
underperform in the medical field due to their inability to precisely translate
medical terminologies. Our research prioritizes not merely improving
translation accuracy but also maintaining medical terminology in English within
the translated text through code-switched (CS) translation. We developed a
method to produce CS medical translation data, fine-tuned a CS translation
model with this data, and evaluated its performance against strong baselines,
such as Google Neural Machine Translation (NMT) and GPT-3.5/GPT-4. Our model
demonstrated competitive performance in automatic metrics and was highly
favored in human preference evaluations. Our evaluation result also shows that
medical professionals significantly prefer CS translations that maintain
critical English terms accurately, even if it slightly compromises fluency. Our
code and test set are publicly available
https://github.com/preceptorai-org/NLLB_CS_EM_NLP2024.

ÊëòË¶ÅÔºöÊ©üÂô®ÁøªË≠Ø (MT) Âú®ÈÜ´Â≠∏È†òÂüüÊâÆÊºîËëóÈóúÈçµËßíËâ≤ÔºåËÉΩÊèêÂçáÈÜ´ÁôÇ‰øùÂÅ•ÂìÅË≥™‰∏¶ÂÇ≥Êí≠ÈÜ´Â≠∏Áü•Ë≠ò„ÄÇÂÑòÁÆ°Ëã±Ê≥∞Ê©üÂô®ÁøªË≠ØÊäÄË°ìÂ∑≤ÊúâÈÄ≤Â±ïÔºå‰ΩÜÂ∏∏Ë¶ãÁöÑÊ©üÂô®ÁøªË≠ØÊñπÊ≥ïÂú®ÈÜ´Â≠∏È†òÂüüÂæÄÂæÄË°®Áèæ‰∏ç‰Ω≥ÔºåÂõ†ÁÇ∫ÂÆÉÂÄëÁÑ°Ê≥ïÁ≤æÁ¢∫ÁøªË≠ØÈÜ´Â≠∏Ë°ìË™û„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂‰∏çÂÉÖÂÑ™ÂÖàÊîπÂñÑÁøªË≠ØÊ∫ñÁ¢∫Â∫¶Ôºå‰πüÈÄèÈÅé‰ª£Á¢ºËΩâÊèõ (CS) ÁøªË≠ØÔºåÂú®ÁøªË≠ØÂæåÁöÑÊñáÂ≠ó‰∏≠‰øùÁïôËã±ÊñáÈÜ´Â≠∏Ë°ìË™û„ÄÇÊàëÂÄëÈñãÁôº‰∫Ü‰∏ÄÁ®ÆÁî¢Áîü CS ÈÜ´Â≠∏ÁøªË≠ØË≥áÊñôÁöÑÊñπÊ≥ïÔºå‰∏¶‰ΩøÁî®ÈÄô‰∫õË≥áÊñôÂæÆË™ø CS ÁøªË≠ØÊ®°ÂûãÔºå‰∏¶ÈáùÂ∞ç Google Á•ûÁ∂ìÊ©üÂô®ÁøªË≠Ø (NMT) Âíå GPT-3.5/GPT-4 Á≠âÂº∑Â§ßÁöÑÂü∫Ê∫ñÈÄ≤Ë°åË©ï‰º∞„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÂú®Ëá™ÂãïÂåñÊåáÊ®ô‰∏≠Â±ïÁèæÂá∫Á´∂Áà≠ÂäõÔºå‰∏îÂú®‰∫∫È°ûÂÅèÂ•ΩË©ï‰º∞‰∏≠ÂÇôÂèóÈùíÁùû„ÄÇÊàëÂÄëÁöÑË©ï‰º∞ÁµêÊûú‰πüÈ°ØÁ§∫ÔºåÂç≥‰ΩøÊúÉÁ®çÂæÆÂΩ±ÈüøÊµÅÊö¢Â∫¶ÔºåÈÜ´Â≠∏Â∞àÊ•≠‰∫∫Âì°‰πüÈ°ØËëóÂÅèÂ•ΩËÉΩÁ≤æÁ¢∫‰øùÁïôÈóúÈçµËã±ÊñáË°ìË™ûÁöÑ CS ÁøªË≠Ø„ÄÇÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÂíåÊ∏¨Ë©¶ÈõÜÂ∑≤ÂÖ¨Èñã https://github.com/preceptorai-org/NLLB_CS_EM_NLP2024„ÄÇ

##### **Pre-training Distillation for Large Language Models: A Design Space Exploration**
2410.16215v1 by Hao Peng, Xin Lv, Yushi Bai, Zijun Yao, Jiajie Zhang, Lei Hou, Juanzi Li

Knowledge distillation (KD) aims to transfer knowledge from a large teacher
model to a smaller student model. Previous work applying KD in the field of
large language models (LLMs) typically focused on the post-training phase,
where the student LLM learns directly from instructions and corresponding
responses generated by the teacher model. In this paper, we extend KD to the
pre-training phase of LLMs, named pre-training distillation (PD). We first
conduct a preliminary experiment using GLM-4-9B as the teacher LLM to distill a
1.9B parameter student LLM, validating the effectiveness of PD. Considering the
key impact factors of distillation, we systematically explore the design space
of pre-training distillation across four aspects: logits processing, loss
selection, scaling law, and offline or online logits. We conduct extensive
experiments to explore the design space of pre-training distillation and find
better configurations and interesting conclusions, such as larger student LLMs
generally benefiting more from pre-training distillation, while a larger
teacher LLM does not necessarily guarantee better results. We hope our
exploration of the design space will inform future practices in pre-training
distillation.

ÊëòË¶ÅÔºöÁü•Ë≠òËí∏È§æ (KD) ÁöÑÁõÆÊ®ôÊòØÂ∞áÁü•Ë≠òÂæûÂ§ßÂûãÊïôÂ∏´Ê®°ÂûãÂÇ≥Ëº∏Âà∞Â∞èÂûãÂ≠∏ÁîüÊ®°Âûã„ÄÇÂÖàÂâçÂú®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) È†òÂüü‰∏≠ÊáâÁî® KD ÁöÑÂ∑•‰ΩúÈÄöÂ∏∏Â∞àÊ≥®ÊñºÂæåË®ìÁ∑¥ÈöéÊÆµÔºåÂÖ∂‰∏≠Â≠∏Áîü LLM Áõ¥Êé•ÂæûÊïôÂ∏´Ê®°ÂûãÁî¢ÁîüÁöÑË™™ÊòéÂíåÂ∞çÊáâÂõûÊáâ‰∏≠Â≠∏Áøí„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂ∞á KD Êì¥Â±ïÂà∞ LLM ÁöÑÈ†êË®ìÁ∑¥ÈöéÊÆµÔºåÁ®±ÁÇ∫È†êË®ìÁ∑¥Ëí∏È§æ (PD)„ÄÇÊàëÂÄëÈ¶ñÂÖà‰ΩøÁî® GLM-4-9B ‰ΩúÁÇ∫ÊïôÂ∏´ LLM ÈÄ≤Ë°åÂàùÊ≠•ÂØ¶È©óÔºå‰ª•Ëí∏È§æ 1.9B ÂèÉÊï∏Â≠∏Áîü LLMÔºåÈ©óË≠â PD ÁöÑÊúâÊïàÊÄß„ÄÇËÄÉÊÖÆÂà∞Ëí∏È§æÁöÑ‰∏ªË¶ÅÂΩ±ÈüøÂõ†Á¥†ÔºåÊàëÂÄëÁ≥ªÁµ±Âú∞Êé¢Á¥¢‰∫ÜÈ†êË®ìÁ∑¥Ëí∏È§æÁöÑË®≠Ë®àÁ©∫ÈñìÔºåÊ∂µËìãÂõõÂÄãÊñπÈù¢ÔºöÂ∞çÊï∏ËôïÁêÜ„ÄÅÊêçÂ§±ÈÅ∏Êìá„ÄÅÊØî‰æãÂÆöÂæãÂíåÈõ¢Á∑öÊàñÁ∑ö‰∏äÂ∞çÊï∏„ÄÇÊàëÂÄëÈÄ≤Ë°å‰∫ÜÂª£Ê≥õÁöÑÂØ¶È©óÔºå‰ª•Êé¢Á¥¢È†êË®ìÁ∑¥Ëí∏È§æÁöÑË®≠Ë®àÁ©∫ÈñìÔºå‰∏¶ÊâæÂá∫Êõ¥Â•ΩÁöÑÈÖçÁΩÆÂíåÊúâË∂£ÁöÑÁµêË´ñÔºå‰æãÂ¶ÇÔºåËºÉÂ§ßÁöÑÂ≠∏Áîü LLM ÈÄöÂ∏∏ÂæûÈ†êË®ìÁ∑¥Ëí∏È§æ‰∏≠Áç≤ÁõäÊõ¥Â§öÔºåËÄåËºÉÂ§ßÁöÑÊïôÂ∏´ LLM ‰∏¶‰∏ç‰∏ÄÂÆöËÉΩ‰øùË≠âÊõ¥Â•ΩÁöÑÁµêÊûú„ÄÇÊàëÂÄëÂ∏åÊúõÊàëÂÄëÂ∞çË®≠Ë®àÁ©∫ÈñìÁöÑÊé¢Á¥¢Â∞áÁÇ∫È†êË®ìÁ∑¥Ëí∏È§æ‰∏≠ÁöÑÊú™‰æÜÂØ¶ÂãôÊèê‰æõË≥áË®ä„ÄÇ

##### **Comprehensive benchmarking of large language models for RNA secondary structure prediction**
2410.16212v1 by L. I. Zablocki, L. A. Bugnon, M. Gerard, L. Di Persia, G. Stegmayer, D. H. Milone

Inspired by the success of large language models (LLM) for DNA and proteins,
several LLM for RNA have been developed recently. RNA-LLM uses large datasets
of RNA sequences to learn, in a self-supervised way, how to represent each RNA
base with a semantically rich numerical vector. This is done under the
hypothesis that obtaining high-quality RNA representations can enhance
data-costly downstream tasks. Among them, predicting the secondary structure is
a fundamental task for uncovering RNA functional mechanisms. In this work we
present a comprehensive experimental analysis of several pre-trained RNA-LLM,
comparing them for the RNA secondary structure prediction task in an unified
deep learning framework. The RNA-LLM were assessed with increasing
generalization difficulty on benchmark datasets. Results showed that two LLM
clearly outperform the other models, and revealed significant challenges for
generalization in low-homology scenarios.

ÊëòË¶ÅÔºöÂèó DNA ÂíåËõãÁôΩË¥®ÁöÑÂ§ßËØ≠Ë®ÄÊ®°Âûã (LLM) ÁöÑÊàêÂäüÂêØÂèëÔºåÊúÄËøëÂ∑≤ÁªèÂºÄÂèëÂá∫Âá†ÁßçÁî®‰∫é RNA ÁöÑ LLM„ÄÇRNA-LLM ‰ΩøÁî®Â§ßÂûã RNA Â∫èÂàóÊï∞ÊçÆÈõÜ‰ª•Ëá™ÁõëÁù£ÁöÑÊñπÂºèÂ≠¶‰π†Â¶Ç‰ΩïÁî®ËØ≠‰πâ‰∏∞ÂØåÁöÑÊï∞Â≠óÂêëÈáèË°®Á§∫ÊØè‰∏™ RNA Á¢±Âü∫„ÄÇËøôÊòØÂú®ÂÅáËÆæËé∑ÂæóÈ´òË¥®ÈáèÁöÑ RNA Ë°®Á§∫ÂèØ‰ª•Â¢ûÂº∫Êï∞ÊçÆÊàêÊú¨È´òÊòÇÁöÑ‰∏ãÊ∏∏‰ªªÂä°ÁöÑÂâçÊèê‰∏ãÂÆåÊàêÁöÑ„ÄÇÂÖ∂‰∏≠ÔºåÈ¢ÑÊµã‰∫åÁ∫ßÁªìÊûÑÊòØÊè≠Á§∫ RNA ÂäüËÉΩÊú∫Âà∂ÁöÑ‰∏ÄÈ°πÂü∫Êú¨‰ªªÂä°„ÄÇÂú®ËøôÈ°πÂ∑•‰Ωú‰∏≠ÔºåÊàë‰ª¨ÂØπÂá†‰∏™ÁªèËøáÈ¢ÑËÆ≠ÁªÉÁöÑ RNA-LLM ËøõË°å‰∫ÜÂÖ®Èù¢ÁöÑÂÆûÈ™åÂàÜÊûêÔºåÂú®Áªü‰∏ÄÁöÑÊ∑±Â∫¶Â≠¶‰π†Ê°ÜÊû∂‰∏≠Â∞ÜÂÆÉ‰ª¨Áî®‰∫é RNA ‰∫åÁ∫ßÁªìÊûÑÈ¢ÑÊµã‰ªªÂä°ËøõË°å‰∫ÜÊØîËæÉ„ÄÇRNA-LLM Âú®Âü∫ÂáÜÊï∞ÊçÆÈõÜ‰∏ä‰ª•Ë∂äÊù•Ë∂äÂ§ßÁöÑÊ≥õÂåñÈöæÂ∫¶ËøõË°å‰∫ÜËØÑ‰º∞„ÄÇÁªìÊûúË°®ÊòéÔºå‰∏§‰∏™ LLM ÊòéÊòæ‰ºò‰∫éÂÖ∂‰ªñÊ®°ÂûãÔºåÂπ∂Êè≠Á§∫‰∫ÜÂú®‰ΩéÂêåÊ∫êÊÄßÂú∫ÊôØ‰∏≠Ê≥õÂåñÁöÑÈáçÂ§ßÊåëÊàò„ÄÇ

##### **Compute-Constrained Data Selection**
2410.16208v1 by Junjie Oscar Yin, Alexander M. Rush

Data selection can reduce the amount of training data needed to finetune
LLMs; however, the efficacy of data selection scales directly with its compute.
Motivated by the practical challenge of compute-constrained finetuning, we
consider the setting in which both the cost of selecting data and training are
budgeted for. We first formalize the problem of data selection with a
cost-aware utility function, and model the data selection problem as trading
off initial-selection cost for training gain. We run a comprehensive sweep of
experiments across multiple tasks, varying compute budget by scaling finetuning
tokens, model sizes, and data selection compute. These experiments show the
validity of this model in real-world experiments. Interestingly we find that
many powerful data selection methods are almost never compute-optimal, and that
cheaper data selection alternatives dominate both from a theoretical and
empirical perspective.

ÊëòË¶ÅÔºöË≥áÊñôÈÅ∏ÊìáÂèØ‰ª•Ê∏õÂ∞ëÂæÆË™ø LLM ÊâÄÈúÄÁöÑË®ìÁ∑¥Ë≥áÊñôÈáèÔºõÁÑ∂ËÄåÔºåË≥áÊñôÈÅ∏ÊìáÁöÑÊïàÁéáËàáÂÖ∂ÈÅãÁÆóÈáèÊàêÊ≠£ÊØî„ÄÇÂú®ÈÅãÁÆóÈáèÂèóÈôêÁöÑÂæÆË™øÁöÑÂØ¶ÈöõÊåëÊà∞ÁöÑÈ©Ö‰Ωø‰∏ãÔºåÊàëÂÄëËÄÉÊÖÆ‰∫ÜË≥áÊñôÈÅ∏ÊìáÂíåË®ìÁ∑¥ÊàêÊú¨ÈÉΩÁ∑®ÂàóÈ†êÁÆóÁöÑË®≠ÂÆö„ÄÇÊàëÂÄëÈ¶ñÂÖà‰ΩøÁî®ÂÖ∑ÊúâÊàêÊú¨ÊïàÁõäÁöÑÊïàÁî®ÂáΩÊï∏ÂΩ¢ÂºèÂåñË≥áÊñôÈÅ∏ÊìáÂïèÈ°åÔºå‰∏¶Â∞áË≥áÊñôÈÅ∏ÊìáÂïèÈ°åÂª∫Ê®°ÁÇ∫‰ª•Ë®ìÁ∑¥Êî∂ÁõäÊèõÂèñÂàùÂßãÈÅ∏ÊìáÊàêÊú¨„ÄÇÊàëÂÄëÂ∞çÂ§öÈ†Ö‰ªªÂãôÂü∑Ë°åÂÖ®Èù¢ÁöÑÂØ¶È©óÊéÉÊèèÔºåÈÄèÈÅéË™øÊï¥ÂæÆË™øÊ¨äÊùñ„ÄÅÊ®°ÂûãÂ§ßÂ∞èÂíåË≥áÊñôÈÅ∏ÊìáÈÅãÁÆóÈáè‰æÜÊîπËÆäÈÅãÁÆóÈ†êÁÆó„ÄÇÈÄô‰∫õÂØ¶È©óÈ°ØÁ§∫‰∫ÜÊ≠§Ê®°ÂûãÂú®ÂØ¶ÈöõÂØ¶È©ó‰∏≠ÁöÑÊúâÊïàÊÄß„ÄÇÊúâË∂£ÁöÑÊòØÔºåÊàëÂÄëÁôºÁèæË®±Â§öÂº∑Â§ßÁöÑË≥áÊñôÈÅ∏ÊìáÊñπÊ≥ïÂπæ‰πéÂæûÊú™Âú®ÈÅãÁÆó‰∏äÈÅîÂà∞ÊúÄ‰Ω≥ÔºåËÄå‰∏îÂæûÁêÜË´ñÂíåÁ∂ìÈ©óËßíÂ∫¶‰æÜÁúãÔºåÊõ¥‰æøÂÆúÁöÑË≥áÊñôÈÅ∏ÊìáÊõø‰ª£ÊñπÊ°àÈÉΩÂç†ÂÑ™Âã¢„ÄÇ

##### **CoT-TL: Low-Resource Temporal Knowledge Representation of Planning Instructions Using Chain-of-Thought Reasoning**
2410.16207v1 by Kumar Manas, Stefan Zwicklbauer, Adrian Paschke

Autonomous agents often face the challenge of interpreting uncertain natural
language instructions for planning tasks. Representing these instructions as
Linear Temporal Logic (LTL) enables planners to synthesize actionable plans. We
introduce CoT-TL, a data-efficient in-context learning framework for
translating natural language specifications into LTL representations. CoT-TL
addresses the limitations of large language models, which typically rely on
extensive fine-tuning data, by extending chain-of-thought reasoning and
semantic roles to align with the requirements of formal logic creation. This
approach enhances the transparency and rationale behind LTL generation,
fostering user trust. CoT-TL achieves state-of-the-art accuracy across three
diverse datasets in low-data scenarios, outperforming existing methods without
fine-tuning or intermediate translations. To improve reliability and minimize
hallucinations, we incorporate model checking to validate the syntax of the
generated LTL output. We further demonstrate CoT-TL's effectiveness through
ablation studies and evaluations on unseen LTL structures and formulas in a new
dataset. Finally, we validate CoT-TL's practicality by integrating it into a
QuadCopter for multi-step drone planning based on natural language
instructions.

ÊëòË¶ÅÔºöËá™‰∏ª‰ª£ÁêÜÁ∂ìÂ∏∏Èù¢Ëá®Ëß£ËÆÄ‰∏çÁ¢∫ÂÆöÁöÑËá™ÁÑ∂Ë™ûË®ÄÊåá‰ª§‰ª•Ë¶èÂäÉ‰ªªÂãôÁöÑÊåëÊà∞„ÄÇÂ∞áÈÄô‰∫õÊåá‰ª§Ë°®Á§∫ÁÇ∫Á∑öÊÄßÊôÇÂ∫èÈÇèËºØ (LTL) ËÉΩËÆìË¶èÂäÉËÄÖÁ∂úÂêàÂèØË°åÁöÑË®àÁï´„ÄÇÊàëÂÄëÂºïÂÖ•‰∫Ü CoT-TLÔºåÈÄôÊòØ‰∏ÄÂÄãË≥áÊñôÊïàÁéáÈ´òÁöÑÊÉÖÂ¢ÉÂ≠∏ÁøíÊ°ÜÊû∂ÔºåÁî®ÊñºÂ∞áËá™ÁÑ∂Ë™ûË®ÄË¶èÊ†ºËΩâÊèõÁÇ∫ LTL Ë°®Á§∫„ÄÇCoT-TL ÈÄèÈÅéÊì¥Â±ïÊÄùËÄÉÈèàÊé®ÁêÜÂíåË™ûÊÑèËßíËâ≤‰æÜÁ¨¶ÂêàÂΩ¢ÂºèÈÇèËºØÂª∫Á´ãÁöÑË¶ÅÊ±ÇÔºå‰æÜËß£Ê±∫Â§ßÂûãË™ûË®ÄÊ®°ÂûãÁöÑÈôêÂà∂ÔºåËÄåÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÈÄöÂ∏∏‰ª∞Ë≥¥Âª£Ê≥õÁöÑÂæÆË™øË≥áÊñô„ÄÇÈÄôÁ®ÆÊñπÊ≥ïÂ¢ûÂº∑‰∫Ü LTL ÁîüÊàêÁöÑÈÄèÊòéÂ∫¶Âíå‰æùÊìöÔºå‰øÉÈÄ≤‰ΩøÁî®ËÄÖ‰ø°‰ªª„ÄÇCoT-TL Âú®‰∏âÂÄã‰∏çÂêåÁöÑË≥áÊñôÈõÜ‰∏≠ÔºåÊñº‰ΩéË≥áÊñôÊÉÖÂ¢É‰∏≠ÈÅîÊàêÊúÄÂÖàÈÄ≤ÁöÑÊ∫ñÁ¢∫Â∫¶ÔºåÂú®Ê≤íÊúâÂæÆË™øÊàñ‰∏≠ÈñìËΩâÊèõÁöÑÊÉÖÊ≥Å‰∏ãÔºåË°®ÁèæÂÑ™ÊñºÁèæÊúâÊñπÊ≥ï„ÄÇÁÇ∫‰∫ÜÊèêÂçáÂèØÈù†Â∫¶‰∏¶Â∞áÂπªË¶∫ÈôçËá≥ÊúÄ‰ΩéÔºåÊàëÂÄëÁ¥çÂÖ•‰∫ÜÊ®°ÂûãÊ™¢Êü•‰æÜÈ©óË≠âÊâÄÁî¢Áîü LTL Ëº∏Âá∫ÁöÑË™ûÊ≥ï„ÄÇÊàëÂÄëÈÄ≤‰∏ÄÊ≠•ÈÄèÈÅéÊ∂àËûçÁ†îÁ©∂Ôºå‰ª•ÂèäÂ∞çÊñ∞Ë≥áÊñôÈõÜ‰∏≠ÂâçÊâÄÊú™Ë¶ãÁöÑ LTL ÁµêÊßãÂíåÂÖ¨ÂºèÁöÑË©ï‰º∞Ôºå‰æÜË≠âÊòé CoT-TL ÁöÑÊïàËÉΩ„ÄÇÊúÄÂæåÔºåÊàëÂÄëÈÄèÈÅéÂ∞á CoT-TL Êï¥ÂêàÂà∞ÂõõÊóãÁøºÈ£õË°åÂô®‰∏≠ÔºåÊ†πÊìöËá™ÁÑ∂Ë™ûË®ÄÊåá‰ª§ÈÄ≤Ë°åÂ§öÊ≠•È©üÁÑ°‰∫∫Ê©üË¶èÂäÉÔºå‰æÜÈ©óË≠â CoT-TL ÁöÑÂØ¶Áî®ÊÄß„ÄÇ

##### **Systematic Review: Text Processing Algorithms in Machine Learning and Deep Learning for Mental Health Detection on Social Media**
2410.16204v1 by Yuchen Cao, Jianglai Dai, Zhongyan Wang, Yeyubei Zhang, Xiaorui Shen, Yunchong Liu, Yexin Tian

The global rise in depression necessitates innovative detection methods for
early intervention. Social media provides a unique opportunity to identify
depression through user-generated posts. This systematic review evaluates
machine learning (ML) models for depression detection on social media, focusing
on biases and methodological challenges throughout the ML lifecycle. A search
of PubMed, IEEE Xplore, and Google Scholar identified 47 relevant studies
published after 2010. The Prediction model Risk Of Bias ASsessment Tool
(PROBAST) was utilized to assess methodological quality and risk of bias.
Significant biases impacting model reliability and generalizability were found.
There is a predominant reliance on Twitter (63.8%) and English-language content
(over 90%), with most studies focusing on users from the United States and
Europe. Non-probability sampling methods (approximately 80%) limit
representativeness. Only 23% of studies explicitly addressed linguistic nuances
like negations, crucial for accurate sentiment analysis. Inconsistent
hyperparameter tuning was observed, with only 27.7% properly tuning models.
About 17% did not adequately partition data into training, validation, and test
sets, risking overfitting. While 74.5% used appropriate evaluation metrics for
imbalanced data, others relied on accuracy without addressing class imbalance,
potentially skewing results. Reporting transparency varied, often lacking
critical methodological details. These findings highlight the need to diversify
data sources, standardize preprocessing protocols, ensure consistent model
development practices, address class imbalance, and enhance reporting
transparency. By overcoming these challenges, future research can develop more
robust and generalizable ML models for depression detection on social media,
contributing to improved mental health outcomes globally.

ÊëòË¶ÅÔºöÂÖ®ÁêÉÊÜÇÈ¨±ÁóáÁöÑ‰∏äÂçáË∂®Âã¢ÈúÄË¶ÅÂâµÊñ∞ÁöÑÂÅµÊ∏¨ÊñπÊ≥ïÔºå‰ª•‰æøÊó©Êúü‰ªãÂÖ•„ÄÇÁ§æÁæ§Â™íÈ´îÈÄèÈÅé‰ΩøÁî®ËÄÖÁî¢ÁîüÁöÑË≤ºÊñáÔºåÊèê‰æõ‰∫Ü‰∏ÄÂÄãÁç®ÁâπÁöÑÊ©üÊúÉ‰æÜË≠òÂà•ÊÜÇÈ¨±Áóá„ÄÇÈÄôÁØáÁ≥ªÁµ±ÊÄßÂõûÈ°ßÈáùÂ∞çÁ§æÁæ§Â™íÈ´î‰∏äÁöÑÊÜÇÈ¨±ÁóáÂÅµÊ∏¨ÔºåË©ï‰º∞Ê©üÂô®Â≠∏Áøí (ML) Ê®°ÂûãÔºåÈáçÈªûÈóúÊ≥® ML ÁîüÂëΩÈÄ±Êúü‰∏≠ÁöÑÂÅèË™§ÂíåÊñπÊ≥ïË´ñÊåëÊà∞„ÄÇÂú® PubMed„ÄÅIEEE Xplore Âíå Google Scholar ‰∏≠ÊêúÂ∞ãÔºåÊâæÂá∫ 2010 Âπ¥ÂæåÁôºË°®ÁöÑ 47 È†ÖÁõ∏ÈóúÁ†îÁ©∂„ÄÇÈ†êÊ∏¨Ê®°ÂûãÈ¢®Èö™ÂÅèË™§Ë©ï‰º∞Â∑•ÂÖ∑ (PROBAST) Ë¢´Áî®ÊñºË©ï‰º∞ÊñπÊ≥ïË´ñÂìÅË≥™ÂíåÂÅèË™§È¢®Èö™„ÄÇÁôºÁèæÈ°ØËëóÁöÑÂÅèË™§ÊúÉÂΩ±ÈüøÊ®°ÂûãÁöÑÂèØÈù†ÊÄßÂíåÊ¶ÇÊã¨ÊÄß„ÄÇÈÅéÂ∫¶‰æùË≥¥ Twitter (63.8%) ÂíåËã±ÊñáÂÖßÂÆπ (Ë∂ÖÈÅé 90%)ÔºåËÄå‰∏îÂ§ßÂ§öÊï∏Á†îÁ©∂ÈÉΩÂ∞àÊ≥®Êñº‰æÜËá™ÁæéÂúãÂíåÊ≠êÊ¥≤ÁöÑ‰ΩøÁî®ËÄÖ„ÄÇÈùûÊ©üÁéáÊäΩÊ®£ÊñπÊ≥ï (Á¥Ñ 80%) ÈôêÂà∂‰∫Ü‰ª£Ë°®ÊÄß„ÄÇÂè™Êúâ 23% ÁöÑÁ†îÁ©∂ÊòéÁ¢∫Ë™™Êòé‰∫ÜË™ûË®Ä‰∏äÁöÑÁ¥∞ÂæÆÂ∑ÆÂà•Ôºå‰æãÂ¶ÇÂê¶ÂÆöÔºåÈÄôÂ∞çÊñºÊ∫ñÁ¢∫ÁöÑÊÉÖÁ∑íÂàÜÊûêËá≥ÈóúÈáçË¶Å„ÄÇËßÄÂØüÂà∞‰∏ç‰∏ÄËá¥ÁöÑË∂ÖÂèÉÊï∏Ë™øÊï¥ÔºåÂè™Êúâ 27.7% ÈÅ©Áï∂Âú∞Ë™øÊï¥Ê®°Âûã„ÄÇÁ¥Ñ 17% Ê≤íÊúâÈÅ©Áï∂Âú∞Â∞áË≥áÊñôÂàÜÂâ≤ÊàêË®ìÁ∑¥„ÄÅÈ©óË≠âÂíåÊ∏¨Ë©¶ÈõÜÔºåÊúâÈÅéÂ∫¶Êì¨ÂêàÁöÑÈ¢®Èö™„ÄÇÈõñÁÑ∂ 74.5% ‰ΩøÁî®‰∫ÜÈÅ©Áï∂ÁöÑË©ï‰º∞ÊåáÊ®ô‰æÜËôïÁêÜ‰∏çÂπ≥Ë°°ÁöÑË≥áÊñôÔºå‰ΩÜÂÖ∂‰ªñÊåáÊ®ô‰æùË≥¥ÊñºÊ∫ñÁ¢∫ÊÄßÔºåËÄåÊ≤íÊúâËß£Ê±∫È°ûÂà•‰∏çÂπ≥Ë°°ÁöÑÂïèÈ°åÔºåÂèØËÉΩÊúÉÊâ≠Êõ≤ÁµêÊûú„ÄÇÂ†±ÂëäÁöÑÈÄèÊòéÂ∫¶ÊúâÊâÄ‰∏çÂêåÔºåÈÄöÂ∏∏Áº∫‰πèÈáçË¶ÅÁöÑÊñπÊ≥ïË´ñÁ¥∞ÁØÄ„ÄÇÈÄô‰∫õÁôºÁèæÁ™ÅÈ°Ø‰∫ÜÂ§öÊ®£ÂåñË≥áÊñô‰æÜÊ∫ê„ÄÅÊ®ôÊ∫ñÂåñÂâçËôïÁêÜÂçîÂÆö„ÄÅÁ¢∫‰øù‰∏ÄËá¥ÁöÑÊ®°ÂûãÈñãÁôºÂØ¶Âãô„ÄÅËß£Ê±∫È°ûÂà•‰∏çÂπ≥Ë°°‰ª•ÂèäÊèêÈ´òÂ†±ÂëäÈÄèÊòéÂ∫¶ÁöÑÂøÖË¶ÅÊÄß„ÄÇÈÄèÈÅéÂÖãÊúçÈÄô‰∫õÊåëÊà∞ÔºåÊú™‰æÜÁöÑÁ†îÁ©∂ÂèØ‰ª•ÈñãÁôºÂá∫Êõ¥Âº∑Â§ß‰∏îÊõ¥ÂÖ∑Ê¶ÇÊã¨ÊÄßÁöÑ ML Ê®°ÂûãÔºåÁî®ÊñºÁ§æÁæ§Â™íÈ´î‰∏äÁöÑÊÜÇÈ¨±ÁóáÂÅµÊ∏¨ÔºåÈÄ≤ËÄåÊîπÂñÑÂÖ®ÁêÉÁöÑÂøÉÁêÜÂÅ•Â∫∑ÊàêÊûú„ÄÇ

##### **Improve Vision Language Model Chain-of-thought Reasoning**
2410.16198v1 by Ruohong Zhang, Bowen Zhang, Yanghao Li, Haotian Zhang, Zhiqing Sun, Zhe Gan, Yinfei Yang, Ruoming Pang, Yiming Yang

Chain-of-thought (CoT) reasoning in vision language models (VLMs) is crucial
for improving interpretability and trustworthiness. However, current training
recipes lack robust CoT reasoning data, relying on datasets dominated by short
annotations with minimal rationales. In this work, we show that training VLM on
short answers does not generalize well to reasoning tasks that require more
detailed responses. To address this, we propose a two-fold approach. First, we
distill rationales from GPT-4o model to enrich the training data and fine-tune
VLMs, boosting their CoT performance. Second, we apply reinforcement learning
to further calibrate reasoning quality. Specifically, we construct positive
(correct) and negative (incorrect) pairs of model-generated reasoning chains,
by comparing their predictions with annotated short answers. Using this
pairwise data, we apply the Direct Preference Optimization algorithm to refine
the model's reasoning abilities. Our experiments demonstrate significant
improvements in CoT reasoning on benchmark datasets and better generalization
to direct answer prediction as well. This work emphasizes the importance of
incorporating detailed rationales in training and leveraging reinforcement
learning to strengthen the reasoning capabilities of VLMs.

ÊëòË¶ÅÔºöÂú®Ë¶ñË¶∫Ë™ûË®ÄÊ®°Âûã (VLM) ‰∏≠ÔºåÊÄùÊÉ≥Èèà (CoT) Êé®ÁêÜÂ∞çÊñºÊèêÂçáÂèØËß£ÈáãÊÄßÂíåÂèØ‰ø°Â∫¶Ëá≥ÈóúÈáçË¶Å„ÄÇÁÑ∂ËÄåÔºåÁõÆÂâçÁöÑË®ìÁ∑¥ÁØÑ‰æãÁº∫‰πèÁ©©ÂÅ•ÁöÑ CoT Êé®ÁêÜË≥áÊñôÔºå‰æùË≥¥ÊñºÁî±Á∞°Áü≠Ë®ªËß£ÔºàÊèê‰æõÊúÄÂ∞ëÁêÜÁî±ÔºâÊâÄ‰∏ªÂ∞éÁöÑË≥áÊñôÈõÜ„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÂ±ïÁ§∫Âú®Á∞°Áü≠Á≠îÊ°à‰∏äË®ìÁ∑¥ VLM ÁÑ°Ê≥ïÂª£Ê≥õÊáâÁî®ÊñºÈúÄË¶ÅÊõ¥Ë©≥Á¥∞ÂõûÊáâÁöÑÊé®ÁêÜ‰ªªÂãô„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÈõôÁÆ°ÈΩä‰∏ãÁöÑÊñπÊ≥ï„ÄÇÈ¶ñÂÖàÔºåÊàëÂÄëÂæû GPT-4o Ê®°Âûã‰∏≠ËêÉÂèñÂá∫ÁêÜÁî±Ôºå‰ª•Ë±êÂØåË®ìÁ∑¥Ë≥áÊñô‰∏¶ÂæÆË™ø VLMÔºåÊèêÂçáÂÖ∂ CoT ÊïàËÉΩ„ÄÇÂÖ∂Ê¨°ÔºåÊàëÂÄëÈÅãÁî®Âº∑ÂåñÂ≠∏ÁøíÈÄ≤‰∏ÄÊ≠•Ê†°Ê∫ñÊé®ÁêÜÂìÅË≥™„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÈÄèÈÅéÊØîËºÉÊ®°ÂûãÁî¢ÁîüÁöÑÊé®ÁêÜÈèàËàáË®ªËß£ÁöÑÁ∞°Áü≠Á≠îÊ°àÔºåÂª∫ÊßãÊ≠£ÂêëÔºàÊ≠£Á¢∫ÔºâÂíåË≤†ÂêëÔºà‰∏çÊ≠£Á¢∫ÔºâÁöÑÊàêÂ∞çË≥áÊñô„ÄÇ‰ΩøÁî®Ê≠§ÊàêÂ∞çË≥áÊñôÔºåÊàëÂÄëÈÅãÁî®Áõ¥Êé•ÂÅèÂ•ΩÊúÄ‰Ω≥ÂåñÊºîÁÆóÊ≥ï‰æÜÊîπÂñÑÊ®°ÂûãÁöÑÊé®ÁêÜËÉΩÂäõ„ÄÇÊàëÂÄëÁöÑÂØ¶È©óË≠âÊòéÔºåÂú®Âü∫Ê∫ñË≥áÊñôÈõÜ‰∏äÁöÑ CoT Êé®ÁêÜÊúâÈ°ØËëóÁöÑÈÄ≤Ê≠•Ôºå‰∏¶‰∏îÂú®Áõ¥Êé•Á≠îÊ°àÈ†êÊ∏¨‰∏ä‰πüÊúâÊõ¥Â•ΩÁöÑÂª£Ê≥õÊÄß„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÂº∑Ë™ø‰∫ÜÂú®Ë®ìÁ∑¥‰∏≠Á¥çÂÖ•Ë©≥Á¥∞ÁêÜÁî±Ôºå‰∏¶Âà©Áî®Âº∑ÂåñÂ≠∏Áøí‰æÜÂº∑Âåñ VLM Êé®ÁêÜËÉΩÂäõÁöÑÈáçË¶ÅÊÄß„ÄÇ

##### **Information for Conversation Generation: Proposals Utilising Knowledge Graphs**
2410.16196v1 by Alex Clay, Ernesto Jim√©nez-Ruiz

LLMs are frequently used tools for conversational generation. Without
additional information LLMs can generate lower quality responses due to lacking
relevant content and hallucinations, as well as the perception of poor
emotional capability, and an inability to maintain a consistent character.
Knowledge graphs are commonly used forms of external knowledge and may provide
solutions to these challenges. This paper introduces three proposals, utilizing
knowledge graphs to enhance LLM generation. Firstly, dynamic knowledge graph
embeddings and recommendation could allow for the integration of new
information and the selection of relevant knowledge for response generation.
Secondly, storing entities with emotional values as additional features may
provide knowledge that is better emotionally aligned with the user input.
Thirdly, integrating character information through narrative bubbles would
maintain character consistency, as well as introducing a structure that would
readily incorporate new information.

ÊëòË¶ÅÔºöLLM Á∂ìÂ∏∏Ë¢´Áî®‰ΩúÂ∞çË©±ÁîüÊàêÂ∑•ÂÖ∑„ÄÇÊ≤íÊúâ
È°çÂ§ñË≥áË®äÔºåLLM ÊúÉÁî¢ÁîüÂìÅË≥™ËºÉ‰ΩéÁöÑÂõûÊáâÔºåÂõ†ÁÇ∫Áº∫‰πè
Áõ∏ÈóúÂÖßÂÆπÂíåÂπªË¶∫Ôºå‰ª•ÂèäÂ∞çÊÉÖÁ∑íËÉΩÂäõÂ∑ÆÁöÑË™çÁü•ÔºåËÄå‰∏îÁÑ°Ê≥ïÁ∂≠ÊåÅ‰∏ÄËá¥ÁöÑËßíËâ≤„ÄÇ
Áü•Ë≠òÂúñË≠úÈÄöÂ∏∏Áî®ÊñºÂ§ñÈÉ®Áü•Ë≠òÂΩ¢ÂºèÔºå‰∏¶‰∏îÂèØËÉΩÊèê‰æõ
ÈÄô‰∫õÊåëÊà∞ÁöÑËß£Ê±∫ÊñπÊ°à„ÄÇÊú¨Êñá‰ªãÁ¥π‰∫Ü‰∏âÈ†ÖÂª∫Ë≠∞ÔºåÂà©Áî®
Áü•Ë≠òÂúñË≠ú‰æÜÂ¢ûÂº∑ LLM ÁîüÊàê„ÄÇÈ¶ñÂÖàÔºåÂãïÊÖãÁü•Ë≠òÂúñË≠ú
ÂµåÂÖ•ÂíåÂª∫Ë≠∞ÂèØ‰ª•Êï¥ÂêàÊñ∞ÁöÑ
Ë≥áË®äÔºå‰∏¶ÈÅ∏ÊìáÁõ∏ÈóúÁü•Ë≠ò‰æÜÁî¢ÁîüÂõûÊáâ„ÄÇ
ÂÖ∂Ê¨°ÔºåÂ∞áÂÖ∑ÊúâÊÉÖÁ∑íÂÉπÂÄºÁöÑÂØ¶È´îÂÑ≤Â≠òÁÇ∫È°çÂ§ñÂäüËÉΩÂèØËÉΩ
Êèê‰æõËàá‰ΩøÁî®ËÄÖËº∏ÂÖ•Âú®ÊÉÖÁ∑í‰∏äÊõ¥‰∏ÄËá¥ÁöÑÁü•Ë≠ò„ÄÇ
Á¨¨‰∏âÔºåÈÄèÈÅéÊïò‰∫ãÊ∞£Ê≥°Êï¥ÂêàËßíËâ≤Ë≥áË®äÊúÉ
Á∂≠ÊåÅËßíËâ≤‰∏ÄËá¥ÊÄßÔºå‰∏¶ÂºïÂÖ•‰∏ÄÂÄãÁµêÊßãÔºåÂèØ‰ª•
ËºïÈ¨ÜÁ¥çÂÖ•Êñ∞Ë≥áË®ä„ÄÇ

##### **Contamination Report for Multilingual Benchmarks**
2410.16186v1 by Sanchit Ahuja, Varun Gumma, Sunayana Sitaram

Benchmark contamination refers to the presence of test datasets in Large
Language Model (LLM) pre-training or post-training data. Contamination can lead
to inflated scores on benchmarks, compromising evaluation results and making it
difficult to determine the capabilities of models. In this work, we study the
contamination of popular multilingual benchmarks in LLMs that support multiple
languages. We use the Black Box test to determine whether $7$ frequently used
multilingual benchmarks are contaminated in $7$ popular open and closed LLMs
and find that almost all models show signs of being contaminated with almost
all the benchmarks we test. Our findings can help the community determine the
best set of benchmarks to use for multilingual evaluation.

ÊëòË¶ÅÔºöÂü∫Ê∫ñÊ±öÊüì„Å®„ÅØ„ÄÅÂ§ßË¶èÊ®°Ë®ÄË™û„É¢„Éá„É´ (LLM) „ÅÆ‰∫ãÂâç„Éà„É¨„Éº„Éã„É≥„Ç∞„Åæ„Åü„ÅØ‰∫ãÂæå„Éà„É¨„Éº„Éã„É≥„Ç∞„Éá„Éº„Çø„Å´„ÉÜ„Çπ„Éà„Éá„Éº„Çø„Çª„ÉÉ„Éà„ÅåÂ≠òÂú®„Åô„Çã„Åì„Å®„ÇíÊåá„Åó„Åæ„Åô„ÄÇÊ±öÊüì„ÅØÂü∫Ê∫ñ„Åß„ÅÆ„Çπ„Ç≥„Ç¢„ÇíÊ∞¥Â¢ó„Åó„Åó„ÄÅË©ï‰æ°ÁµêÊûú„ÇíÊêç„Å™„ÅÑ„ÄÅ„É¢„Éá„É´„ÅÆËÉΩÂäõ„ÇíÂà§Êñ≠„Åô„Çã„Åì„Å®„ÇíÂõ∞Èõ£„Å´„Åó„Åæ„Åô„ÄÇ„Åì„ÅÆÁ†îÁ©∂„Åß„ÅØ„ÄÅË§áÊï∞„ÅÆË®ÄË™û„Çí„Çµ„Éù„Éº„Éà„Åô„Çã LLM „Åß‰∏ÄËà¨ÁöÑ„Å™Â§öË®ÄË™ûÂü∫Ê∫ñ„ÅÆÊ±öÊüì„ÇíË™øÊüª„Åó„Åæ„Åô„ÄÇ„Éñ„É©„ÉÉ„ÇØ„Éú„ÉÉ„ÇØ„Çπ„ÉÜ„Çπ„Éà„Çí‰ΩøÁî®„Åó„Å¶„ÄÅ7 „Å§„ÅÆÈ†ªÁπÅ„Å´‰ΩøÁî®„Åï„Çå„ÇãÂ§öË®ÄË™ûÂü∫Ê∫ñ„Åå 7 „Å§„ÅÆ‰∏ÄËà¨ÁöÑ„Å™„Ç™„Éº„Éó„É≥ LLM „Åä„Çà„Å≥„ÇØ„É≠„Éº„Ç∫ LLM „ÅßÊ±öÊüì„Åï„Çå„Å¶„ÅÑ„Çã„Åã„Å©„ÅÜ„Åã„ÇíÂà§Êñ≠„Åó„ÄÅ„Åª„Å®„Çì„Å©„Åô„Åπ„Å¶„ÅÆ„É¢„Éá„É´„Åå„ÉÜ„Çπ„Éà„Åó„Åü„Åª„Å®„Çì„Å©„Åô„Åπ„Å¶„ÅÆÂü∫Ê∫ñ„ÅßÊ±öÊüì„ÅÆÂÖÜÂÄô„ÇíÁ§∫„Åó„Å¶„ÅÑ„Çã„Åì„Å®„Åå„Çè„Åã„Çä„Åæ„Åó„Åü„ÄÇÁßÅ„Åü„Å°„ÅÆË™øÊüªÁµêÊûú„ÅØ„ÄÅ„Ç≥„Éü„É•„Éã„ÉÜ„Ç£„ÅåÂ§öË®ÄË™ûË©ï‰æ°„Å´‰ΩøÁî®„Åô„ÇãÂü∫Ê∫ñ„ÅÆÊúÄÈÅ©„Å™„Çª„ÉÉ„Éà„ÇíÊ±∫ÂÆö„Åô„Çã„ÅÆ„Å´ÂΩπÁ´ã„Å°„Åæ„Åô„ÄÇ

##### **RM-Bench: Benchmarking Reward Models of Language Models with Subtlety and Style**
2410.16184v1 by Yantao Liu, Zijun Yao, Rui Min, Yixin Cao, Lei Hou, Juanzi Li

Reward models are critical in techniques like Reinforcement Learning from
Human Feedback (RLHF) and Inference Scaling Laws, where they guide language
model alignment and select optimal responses. Despite their importance,
existing reward model benchmarks often evaluate models by asking them to
distinguish between responses generated by models of varying power. However,
this approach fails to assess reward models on subtle but critical content
changes and variations in style, resulting in a low correlation with policy
model performance. To this end, we introduce RM-Bench, a novel benchmark
designed to evaluate reward models based on their sensitivity to subtle content
differences and resistance to style biases. Extensive experiments demonstrate
that RM-Bench strongly correlates with policy model performance, making it a
reliable reference for selecting reward models to align language models
effectively. We evaluate nearly 40 reward models on RM-Bench. Our results
reveal that even state-of-the-art models achieve an average performance of only
46.6%, which falls short of random-level accuracy (50%) when faced with style
bias interference. These findings highlight the significant room for
improvement in current reward models. Related code and data are available at
https://github.com/THU-KEG/RM-Bench.

ÊëòË¶ÅÔºöÁçéÂãµÊ®°ÂûãÂú®‰∫∫È°ûÂõûÈ•ãÂº∑ÂåñÂ≠∏Áøí (RLHF) ÂíåÊé®Ë´ñË¶èÊ®°ÂÆöÂæãÁ≠âÊäÄË°ì‰∏≠Ëá≥ÈóúÈáçË¶ÅÔºåÂÆÉÂÄëÊåáÂ∞éË™ûË®ÄÊ®°ÂûãÂ∞çÈΩä‰∏¶ÈÅ∏ÊìáÊúÄ‰Ω≥ÂõûÊáâ„ÄÇÂÑòÁÆ°ÂÆÉÂÄëÂæàÈáçË¶ÅÔºå‰ΩÜÁèæÊúâÁöÑÁçéÂãµÊ®°ÂûãÂü∫Ê∫ñÈÄöÂ∏∏ÊúÉË¶ÅÊ±ÇÊ®°ÂûãÂçÄÂàÜÁî±‰∏çÂêåËÉΩÂäõÊ®°ÂûãÁî¢ÁîüÁöÑÂõûÊáâ‰æÜË©ï‰º∞Ê®°Âûã„ÄÇÁÑ∂ËÄåÔºåÈÄôÁ®ÆÊñπÊ≥ïÁÑ°Ê≥ïË©ï‰º∞ÁçéÂãµÊ®°ÂûãÂ∞çÂæÆÂ¶ô‰ΩÜÈáçË¶ÅÁöÑÂÖßÂÆπËÆäÊõ¥ÂíåÈ¢®Ê†ºËÆäÂåñÁöÑÂΩ±ÈüøÔºåÂ∞éËá¥ËàáÊîøÁ≠ñÊ®°ÂûãÊïàËÉΩÁõ∏ÈóúÊÄß‰Ωé„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü RM-BenchÔºåÈÄôÊòØ‰∏ÄÂÄãÊñ∞Âü∫Ê∫ñÔºåÊó®Âú®Ê†πÊìöÁçéÂãµÊ®°ÂûãÂ∞çÂæÆÂ¶ôÂÖßÂÆπÂ∑ÆÁï∞ÁöÑÊïèÊÑüÊÄßÂíåÂ∞çÈ¢®Ê†ºÂÅèË¶ãÁöÑÊäµÊäóÂäõ‰æÜË©ï‰º∞ÁçéÂãµÊ®°Âûã„ÄÇÂª£Ê≥õÁöÑÂØ¶È©óË≠âÊòé RM-Bench ËàáÊîøÁ≠ñÊ®°ÂûãÊïàËÉΩÂØÜÂàáÁõ∏ÈóúÔºå‰ΩøÂÖ∂ÊàêÁÇ∫ÈÅ∏ÊìáÁçéÂãµÊ®°Âûã‰ª•ÊúâÊïàÂ∞çÈΩäË™ûË®ÄÊ®°ÂûãÁöÑÂèØÈù†ÂèÉËÄÉ„ÄÇÊàëÂÄëÂú® RM-Bench ‰∏äË©ï‰º∞‰∫ÜËøë 40 ÂÄãÁçéÂãµÊ®°Âûã„ÄÇÊàëÂÄëÁöÑÁµêÊûúË°®ÊòéÔºåÂç≥‰ΩøÊòØÊúÄÂÖàÈÄ≤ÁöÑÊ®°ÂûãÔºåÂÖ∂Âπ≥ÂùáÊïàËÉΩ‰πüÂÉÖÈÅîÂà∞ 46.6%ÔºåÂú®Èù¢Â∞çÈ¢®Ê†ºÂÅèË¶ãÂπ≤ÊìæÊôÇÔºå‰ΩéÊñºÈö®Ê©üÂ±§Á¥öÊ∫ñÁ¢∫Â∫¶ (50%)„ÄÇÈÄô‰∫õÁôºÁèæÁ™ÅÈ°Ø‰∫ÜÁï∂ÂâçÁçéÂãµÊ®°ÂûãÊúâÈ°ØËëóÁöÑÊîπÈÄ≤Á©∫Èñì„ÄÇÁõ∏ÈóúÁ®ãÂºèÁ¢ºÂíåË≥áÊñôÂèØÊñº https://github.com/THU-KEG/RM-Bench ÂèñÂæó„ÄÇ

##### **MagicPIG: LSH Sampling for Efficient LLM Generation**
2410.16179v1 by Zhuoming Chen, Ranajoy Sadhukhan, Zihao Ye, Yang Zhou, Jianyu Zhang, Niklas Nolte, Yuandong Tian, Matthijs Douze, Leon Bottou, Zhihao Jia, Beidi Chen

Large language models (LLMs) with long context windows have gained
significant attention. However, the KV cache, stored to avoid re-computation,
becomes a bottleneck. Various dynamic sparse or TopK-based attention
approximation methods have been proposed to leverage the common insight that
attention is sparse. In this paper, we first show that TopK attention itself
suffers from quality degradation in certain downstream tasks because attention
is not always as sparse as expected. Rather than selecting the keys and values
with the highest attention scores, sampling with theoretical guarantees can
provide a better estimation for attention output. To make the sampling-based
approximation practical in LLM generation, we propose MagicPIG, a heterogeneous
system based on Locality Sensitive Hashing (LSH). MagicPIG significantly
reduces the workload of attention computation while preserving high accuracy
for diverse tasks. MagicPIG stores the LSH hash tables and runs the attention
computation on the CPU, which allows it to serve longer contexts and larger
batch sizes with high approximation accuracy. MagicPIG can improve decoding
throughput by $1.9\sim3.9\times$ across various GPU hardware and achieve 110ms
decoding latency on a single RTX 4090 for Llama-3.1-8B-Instruct model with a
context of 96k tokens. The code is available at
\url{https://github.com/Infini-AI-Lab/MagicPIG}.

ÊëòË¶ÅÔºöÂÖ∑ÊúâÈï∑ËÉåÊôØË¶ñÁ™óÁöÑÂ§ßË™ûË®ÄÊ®°Âûã (LLM) Áç≤ÂæóÂª£Ê≥õÈóúÊ≥®„ÄÇÁÑ∂ËÄåÔºåÁî®ÊñºÈÅøÂÖçÈáçÊñ∞Ë®àÁÆóÁöÑ KV Âø´ÂèñÂ∑≤ÊàêÁÇ∫Áì∂È†∏„ÄÇÂ∑≤Á∂ìÊèêÂá∫ÂêÑÁ®ÆÂãïÊÖãÁ®ÄÁñèÊàñÂü∫Êñº TopK ÁöÑÊ≥®ÊÑèÂäõËøë‰ººÊñπÊ≥ïÔºå‰ª•Âà©Áî®Ê≥®ÊÑèÂäõÊòØÁ®ÄÁñèÁöÑÂÖ±ÂêåË¶ãËß£„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÈ¶ñÂÖàË°®Êòé TopK Ê≥®ÊÑèÂäõÊú¨Ë∫´Âú®Êüê‰∫õ‰∏ãÊ∏∏‰ªªÂãô‰∏≠ÊúÉÂ∞éËá¥ÂìÅË≥™‰∏ãÈôçÔºåÂõ†ÁÇ∫Ê≥®ÊÑèÂäõ‰∏¶ÈùûÁ∏ΩÊòØÂÉèÈ†êÊúüÁöÑÈÇ£È∫ºÁ®ÄÁñè„ÄÇËàáÂÖ∂ÈÅ∏ÊìáÂÖ∑ÊúâÊúÄÈ´òÊ≥®ÊÑèÂäõÂàÜÊï∏ÁöÑÈçµÂíåÂÄºÔºå‰∏çÂ¶Ç‰ΩøÁî®ÂÖ∑ÊúâÁêÜË´ñ‰øùË≠âÁöÑÊäΩÊ®£ÂèØ‰ª•ÁÇ∫Ê≥®ÊÑèÂäõËº∏Âá∫Êèê‰æõÊõ¥Â•ΩÁöÑ‰º∞Ë®à„ÄÇÁÇ∫‰∫ÜÂú® LLM ÁîüÊàê‰∏≠ÂØ¶ÁèæÂü∫ÊñºÊäΩÊ®£ÁöÑËøë‰ººÔºåÊàëÂÄëÊèêÂá∫‰∫Ü MagicPIGÔºåÈÄôÊòØ‰∏ÄÂÄãÂü∫ÊñºÂ±ÄÈÉ®ÊïèÊÑüÈõúÊπä (LSH) ÁöÑÁï∞Ë≥™Á≥ªÁµ±„ÄÇMagicPIG Â§ßÂπÖÊ∏õÂ∞ë‰∫ÜÊ≥®ÊÑèÂäõË®àÁÆóÁöÑÂ∑•‰ΩúË≤†ËºâÔºåÂêåÊôÇÁÇ∫ÂêÑÁ®Æ‰ªªÂãô‰øùÁïô‰∫ÜÈ´òÊ∫ñÁ¢∫Â∫¶„ÄÇMagicPIG ÂÑ≤Â≠ò LSH ÈõúÊπäË°®Ôºå‰∏¶Âú® CPU ‰∏äÂü∑Ë°åÊ≥®ÊÑèÂäõË®àÁÆóÔºåÈÄôÂÖÅË®±ÂÆÉ‰ΩøÁî®È´òËøë‰ººÊ∫ñÁ¢∫Â∫¶Êèê‰æõÊõ¥Èï∑ÁöÑËÉåÊôØÂíåÊõ¥Â§ßÁöÑÊâπÊ¨°Â§ßÂ∞è„ÄÇMagicPIG ÂèØ‰ª•Â∞áÂêÑÁ®Æ GPU Á°¨È´îÁöÑËß£Á¢ºÂêûÂêêÈáèÊèêÈ´ò $1.9\sim3.9\times$Ôºå‰∏¶Âú®ÂñÆÂÄã RTX 4090 ‰∏äÂØ¶Áèæ 110ms ÁöÑËß£Á¢ºÂª∂ÈÅ≤ÔºåÈÅ©Áî®ÊñºÂÖ∑Êúâ 96k ‰ª§ÁâåËÉåÊôØÁöÑ Llama-3.1-8B-Instruct Ê®°Âûã„ÄÇÁ®ãÂºèÁ¢ºÂèØÂú®
\url{https://github.com/Infini-AI-Lab/MagicPIG} ÂèñÂæó„ÄÇ

##### **Exploring Pretraining via Active Forgetting for Improving Cross Lingual Transfer for Decoder Language Models**
2410.16168v1 by Divyanshu Aggarwal, Ashutosh Sathe, Sunayana Sitaram

Large Language Models (LLMs) demonstrate exceptional capabilities in a
multitude of NLP tasks. However, the efficacy of such models to languages other
than English is often limited. Prior works have shown that encoder-only models
such as BERT or XLM-RoBERTa show impressive cross lingual transfer of their
capabilities from English to other languages. In this work, we propose a
pretraining strategy that uses active forgetting to achieve similar cross
lingual transfer in decoder-only LLMs. We show that LLMs pretrained with active
forgetting are highly effective when adapting to new and unseen languages.
Through extensive experimentation, we find that LLMs pretrained with active
forgetting are able to learn better multilingual representations which
translates to better performance in many downstream tasks.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®Â§ßÈáèËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ‰ªªÂãô‰∏≠Â±ïÁèæÂá∫ÈùûÂá°ÁöÑÊïàËÉΩ„ÄÇÁÑ∂ËÄåÔºåÊ≠§È°ûÊ®°ÂûãÂú®Ëã±Ë™û‰ª•Â§ñÁöÑË™ûË®Ä‰∏≠ÔºåÂÖ∂ÊïàËÉΩÂæÄÂæÄÂèóÂà∞ÈôêÂà∂„ÄÇÂÖàÂâçÁöÑÁ†îÁ©∂È°ØÁ§∫ÔºåÂÉÖÁ∑®Á¢ºÂô®Ê®°ÂûãÔºà‰æãÂ¶Ç BERT Êàñ XLM-RoBERTaÔºâÂ±ïÁèæÂá∫ÂÖ∂ËÉΩÂäõÂæûËã±Ë™ûËΩâÁßªËá≥ÂÖ∂‰ªñË™ûË®ÄÁöÑÈ©ö‰∫∫Ë∑®Ë™ûË®ÄËΩâÁßª„ÄÇÂú®ÈÄôÈ†ÖÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÈ†êË®ìÁ∑¥Á≠ñÁï•ÔºåË©≤Á≠ñÁï•‰ΩøÁî®‰∏ªÂãïÈÅ∫Âøò‰æÜÈÅîÊàêÂÉÖËß£Á¢ºÂô® LLM ‰∏≠È°û‰ººÁöÑË∑®Ë™ûË®ÄËΩâÁßª„ÄÇÊàëÂÄëË≠âÊòé‰∫Ü‰ΩøÁî®‰∏ªÂãïÈÅ∫ÂøòÈÄ≤Ë°åÈ†êË®ìÁ∑¥ÁöÑ LLM Âú®ÈÅ©ÊáâÊñ∞ÁöÑÂíåÊú™Ë¶ãÈÅéÁöÑË™ûË®ÄÊôÇÈùûÂ∏∏ÊúâÊïà„ÄÇÈÄèÈÅéÂª£Ê≥õÁöÑÂØ¶È©óÔºåÊàëÂÄëÁôºÁèæ‰ΩøÁî®‰∏ªÂãïÈÅ∫ÂøòÈÄ≤Ë°åÈ†êË®ìÁ∑¥ÁöÑ LLM ËÉΩÂ§†Â≠∏ÁøíÂà∞Êõ¥Â•ΩÁöÑÂ§öË™ûË®ÄË°®ÂæµÔºåÈÄôËΩâÂåñÁÇ∫Âú®Ë®±Â§ö‰∏ãÊ∏∏‰ªªÂãô‰∏≠Áç≤ÂæóÊõ¥Â•ΩÁöÑÊïàËÉΩ„ÄÇ

##### **Beyond Filtering: Adaptive Image-Text Quality Enhancement for MLLM Pretraining**
2410.16166v1 by Han Huang, Yuqi Huo, Zijia Zhao, Haoyu Lu, Shu Wu, Bingning Wang, Qiang Liu, Weipeng Chen, Liang Wang

Multimodal large language models (MLLMs) have made significant strides by
integrating visual and textual modalities. A critical factor in training MLLMs
is the quality of image-text pairs within multimodal pretraining datasets.
However, $\textit {de facto}$ filter-based data quality enhancement paradigms
often discard a substantial portion of high-quality image data due to
inadequate semantic alignment between images and texts, leading to
inefficiencies in data utilization and scalability. In this paper, we propose
the Adaptive Image-Text Quality Enhancer (AITQE), a model that dynamically
assesses and enhances the quality of image-text pairs. AITQE employs a text
rewriting mechanism for low-quality pairs and incorporates a negative sample
learning strategy to improve evaluative capabilities by integrating
deliberately selected low-quality samples during training. Unlike prior
approaches that significantly alter text distributions, our method minimally
adjusts text to preserve data volume while enhancing quality. Experimental
results demonstrate that AITQE surpasses existing methods on various benchmark,
effectively leveraging raw data and scaling efficiently with increasing data
volumes. We hope our work will inspire future works. The code and model are
available at: https://github.com/hanhuang22/AITQE.

ÊëòË¶ÅÔºöÂ§öÊ®°ÊÄÅÂ§ßÂûãËØ≠Ë®ÄÊ®°Âûã (MLLM) ÈÄèËøáÊï¥ÂêàËßÜËßâÂíåÊñáÊú¨Ê®°ÊÄÅÔºåÂèñÂæó‰∫ÜÈáçÂ§ßËøõÂ±ï„ÄÇËÆ≠ÁªÉ MLLM ÁöÑÂÖ≥ÈîÆÂõ†Á¥†ÊòØÂ§öÊ®°ÊÄÅÈ¢ÑËÆ≠ÁªÉÊï∞ÊçÆÈõÜ‰∏≠ÁöÑÂõæÂÉèÊñáÊú¨ÂØπÁöÑË¥®Èáè„ÄÇÁÑ∂ËÄåÔºå‰∫ãÂÆû‰∏äÂü∫‰∫éËøáÊª§Âô®ÁöÑËµÑÊñôÂìÅË¥®ÊèêÂçáËåÉ‰æãÔºåÂ∏∏Â∏∏‰ºöÂõ†‰∏∫ÂõæÂÉèÂíåÊñáÊú¨‰πãÈó¥ÁöÑËØ≠ÊÑèÂØπÈΩê‰∏çË∂≥ÔºåËÄå‰∏¢ÂºÉÂ§ßÈáèÈ´òÂìÅË¥®ÁöÑÂõæÂÉèËµÑÊñôÔºåÂØºËá¥ËµÑÊñô‰ΩøÁî®ÂíåÂèØÊâ©Â±ïÊÄßÁöÑ‰ΩéÊïàÁéá„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨ÊèêÂá∫Ëá™ÈÄÇÂ∫îÂõæÂÉèÊñáÊú¨ÂìÅË¥®Âº∫ÂåñÂô® (AITQE)ÔºåËøôÊòØ‰∏Ä‰∏™Âä®ÊÄÅËØÑ‰º∞ÂíåÊèêÂçáÂõæÂÉèÊñáÊú¨ÂØπÂìÅË¥®ÁöÑÊ®°Âûã„ÄÇAITQE ÂØπ‰ΩéÂìÅË¥®ÁöÑÂØπ‰ΩøÁî®ÊñáÊú¨ÊîπÂÜôÊú∫Âà∂ÔºåÂπ∂ÁªìÂêàË¥üÊ†∑Êú¨Â≠¶‰π†Á≠ñÁï•ÔºåÈÄèËøáÂú®ËÆ≠ÁªÉÊúüÈó¥Êï¥ÂêàÂàªÊÑèÈÄâÂèñÁöÑ‰ΩéÂìÅË¥®Ê†∑Êú¨ÔºåÊù•ÊèêÂçáËØÑ‰º∞ËÉΩÂäõ„ÄÇ‰∏éÂ§ßÂπÖÂ∫¶ÊîπÂèòÊñáÊú¨ÂàÜÂ∏ÉÁöÑÂÖàÂâçÊñπÊ≥ï‰∏çÂêåÔºåÊàë‰ª¨ÁöÑÊñπÊ≥ïÊúÄÂ∞èÂπÖÂ∫¶Âú∞Ë∞ÉÊï¥ÊñáÊú¨Ôºå‰ª•Âú®ÊèêÂçáÂìÅË¥®ÁöÑÂêåÊó∂‰øùÁïôËµÑÊñôÈáè„ÄÇÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåAITQE Âú®ÂêÑÁßçÂü∫ÂáÜ‰∏äÈÉΩË∂ÖË∂äÁé∞ÊúâÁöÑÊñπÊ≥ïÔºåÊúâÊïàÂà©Áî®ÂéüÂßãËµÑÊñôÔºåÂπ∂ÈöèÁùÄËµÑÊñôÈáèÁöÑÂ¢ûÂä†ËÄåÊúâÊïàÊâ©Â±ï„ÄÇÊàë‰ª¨Â∏åÊúõÊàë‰ª¨ÁöÑÂ∑•‰ΩúËÉΩÂêØÂèëÊú™Êù•ÁöÑÁ†îÁ©∂„ÄÇ‰ª£Á†ÅÂíåÊ®°ÂûãÂèØÂú®‰ª•‰∏ãÁΩëÂùÄÂèñÂæóÔºöhttps://github.com/hanhuang22/AITQE„ÄÇ

##### **From Tokens to Materials: Leveraging Language Models for Scientific Discovery**
2410.16165v1 by Yuwei Wan, Tong Xie, Nan Wu, Wenjie Zhang, Chunyu Kit, Bram Hoex

Exploring the predictive capabilities of language models in material science
is an ongoing interest. This study investigates the application of language
model embeddings to enhance material property prediction in materials science.
By evaluating various contextual embedding methods and pre-trained models,
including Bidirectional Encoder Representations from Transformers (BERT) and
Generative Pre-trained Transformers (GPT), we demonstrate that domain-specific
models, particularly MatBERT significantly outperform general-purpose models in
extracting implicit knowledge from compound names and material properties. Our
findings reveal that information-dense embeddings from the third layer of
MatBERT, combined with a context-averaging approach, offer the most effective
method for capturing material-property relationships from the scientific
literature. We also identify a crucial "tokenizer effect," highlighting the
importance of specialized text processing techniques that preserve complete
compound names while maintaining consistent token counts. These insights
underscore the value of domain-specific training and tokenization in materials
science applications and offer a promising pathway for accelerating the
discovery and development of new materials through AI-driven approaches.

ÊëòË¶ÅÔºöÊé¢Á¥¢Ë™ûË®ÄÊ®°ÂûãÂú®ÊùêÊñôÁßëÂ≠∏‰∏≠ÁöÑÈ†êÊ∏¨ËÉΩÂäõÊòØ‰∏ÄÈ†ÖÊåÅÁ∫åÁöÑËààË∂£„ÄÇÊú¨Á†îÁ©∂Êé¢Ë®é‰∫ÜË™ûË®ÄÊ®°ÂûãÂµåÂÖ•ÊáâÁî®ÊñºÂ¢ûÂº∑ÊùêÊñôÁßëÂ≠∏‰∏≠ÊùêÊñôÂ±¨ÊÄßÈ†êÊ∏¨„ÄÇÈÄöÈÅéË©ï‰º∞ÂêÑÁ®Æ‰∏ä‰∏ãÊñáÂµåÂÖ•ÊñπÊ≥ïÂíåÈ†êË®ìÁ∑¥Ê®°ÂûãÔºåÂåÖÊã¨‰æÜËá™ Transformer ÁöÑÈõôÂêëÁ∑®Á¢ºÂô®Ë°®Á§∫ÔºàBERTÔºâÂíåÁîüÊàêÂºèÈ†êË®ìÁ∑¥ TransformerÔºàGPTÔºâÔºåÊàëÂÄëË≠âÊòé‰∫ÜÁâπÂÆöÈ†òÂüüÁöÑÊ®°ÂûãÔºåÁâπÂà•ÊòØ MatBERT Âú®ÂæûÂåñÂêàÁâ©ÂêçÁ®±ÂíåÊùêÊñôÂ±¨ÊÄß‰∏≠ÊèêÂèñÈö±Âê´Áü•Ë≠òÊñπÈù¢ÊòéÈ°ØÂÑ™ÊñºÈÄöÁî®Ê®°Âûã„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúË°®ÊòéÔºå‰æÜËá™ MatBERT Á¨¨‰∏âÂ±§ÁöÑ‰ø°ÊÅØÂØÜÈõÜÂµåÂÖ•Ëàá‰∏ä‰∏ãÊñáÂπ≥ÂùáÊñπÊ≥ïÁõ∏ÁµêÂêàÔºåÊèê‰æõ‰∫Ü‰∏ÄÁ®ÆÊúÄÊúâÊïàÁöÑÊñπÊ≥ïÔºåÂèØ‰ª•ÂæûÁßëÂ≠∏ÊñáÁçª‰∏≠Áç≤ÂèñÊùêÊñôÂ±¨ÊÄßÈóú‰øÇ„ÄÇÊàëÂÄëÈÇÑÁôºÁèæ‰∫Ü‰∏ÄÂÄãËá≥ÈóúÈáçË¶ÅÁöÑ„ÄåÂàÜË©ûÂô®ÊïàÊáâ„ÄçÔºåÂº∑Ë™ø‰∫ÜÂ∞àÊ•≠ÊñáÊú¨ËôïÁêÜÊäÄË°ìÁöÑÈáçË¶ÅÊÄßÔºåÈÄô‰∫õÊäÄË°ìÂú®‰øùÊåÅ‰∏ÄËá¥ÁöÑ‰ª§ÁâåË®àÊï∏ÁöÑÂêåÊôÇ‰øùÁïô‰∫ÜÂÆåÊï¥ÁöÑÂåñÂêàÁâ©ÂêçÁ®±„ÄÇÈÄô‰∫õË¶ãËß£Âº∑Ë™ø‰∫ÜÁâπÂÆöÈ†òÂüüÁöÑË®ìÁ∑¥ÂíåÂàÜË©ûÂú®ÊùêÊñôÁßëÂ≠∏ÊáâÁî®‰∏≠ÁöÑÂÉπÂÄºÔºå‰∏¶ÁÇ∫ÈÄöÈÅé‰∫∫Â∑•Êô∫ËÉΩÈ©ÖÂãïÁöÑÊñπÊ≥ïÂä†ÈÄüÁôºÁèæÂíåÈñãÁôºÊñ∞ÊùêÊñôÊèê‰æõ‰∫Ü‰∏ÄÊ¢ùÊúâÂâçÊôØÁöÑÈÄîÂæë„ÄÇ

##### **Sparkle: Mastering Basic Spatial Capabilities in Vision Language Models Elicits Generalization to Composite Spatial Reasoning**
2410.16162v1 by Yihong Tang, Ao Qu, Zhaokai Wang, Dingyi Zhuang, Zhaofeng Wu, Wei Ma, Shenhao Wang, Yunhan Zheng, Zhan Zhao, Jinhua Zhao

Vision language models (VLMs) have demonstrated impressive performance across
a wide range of downstream tasks. However, their proficiency in spatial
reasoning remains limited, despite its crucial role in tasks involving
navigation and interaction with physical environments. Specifically, much of
the spatial reasoning in these tasks occurs in two-dimensional (2D)
environments, and our evaluation reveals that state-of-the-art VLMs frequently
generate implausible and incorrect responses to composite spatial reasoning
problems, including simple pathfinding tasks that humans can solve effortlessly
at a glance. To address this, we explore an effective approach to enhance 2D
spatial reasoning within VLMs by training the model on basic spatial
capabilities. We begin by disentangling the key components of 2D spatial
reasoning: direction comprehension, distance estimation, and localization. Our
central hypothesis is that mastering these basic spatial capabilities can
significantly enhance a model's performance on composite spatial tasks
requiring advanced spatial understanding and combinatorial problem-solving. To
investigate this hypothesis, we introduce Sparkle, a framework that fine-tunes
VLMs on these three basic spatial capabilities by synthetic data generation and
targeted supervision to form an instruction dataset for each capability. Our
experiments demonstrate that VLMs fine-tuned with Sparkle achieve significant
performance gains, not only in the basic tasks themselves but also in
generalizing to composite and out-of-distribution spatial reasoning tasks
(e.g., improving from 13.5% to 40.0% on the shortest path problem). These
findings underscore the effectiveness of mastering basic spatial capabilities
in enhancing composite spatial problem-solving, offering insights for improving
VLMs' spatial reasoning capabilities.

ÊëòË¶ÅÔºöË¶ñË¶∫Ë™ûË®ÄÊ®°Âûã (VLM) Â∑≤Âú®Âª£Ê≥õÁöÑ‰∏ãÊ∏∏‰ªªÂãô‰∏≠Â±ïÁèæÂá∫‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑÊïàËÉΩ„ÄÇÁÑ∂ËÄåÔºåÂÑòÁÆ°ÂÆÉÂÄëÂú®Á©∫ÈñìÊé®ÁêÜ‰∏≠ÁöÑÁÜüÁ∑¥Â∫¶Âú®Ê∂âÂèäÂ∞éËà™ÂíåËàáÁâ©ÁêÜÁí∞Â¢É‰∫íÂãïÁöÑ‰ªªÂãô‰∏≠ÊâÆÊºîËëóËá≥ÈóúÈáçË¶ÅÁöÑËßíËâ≤Ôºå‰ΩÜ‰ªçÂèóÂà∞ÈôêÂà∂„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÈÄô‰∫õ‰ªªÂãô‰∏≠ÁöÑË®±Â§öÁ©∫ÈñìÊé®ÁêÜÈÉΩÁôºÁîüÂú®‰∫åÁ∂≠ (2D) Áí∞Â¢É‰∏≠ÔºåËÄåÊàëÂÄëÁöÑË©ï‰º∞È°ØÁ§∫ÔºåÊúÄÂÖàÈÄ≤ÁöÑ VLM Á∂ìÂ∏∏Â∞çË§áÂêàÁ©∫ÈñìÊé®ÁêÜÂïèÈ°åÁî¢ÁîüÈõ£‰ª•ÁΩÆ‰ø°‰∏î‰∏çÊ≠£Á¢∫ÁöÑÂõûÊáâÔºåÂåÖÊã¨‰∫∫È°ûÂèØ‰ª•‰∏ÄÁû•ËÄåËºïÈ¨ÜËß£Ê±∫ÁöÑÁ∞°ÂñÆÂ∞ãÂæë‰ªªÂãô„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÊé¢Á¥¢‰∫Ü‰∏ÄÁ®ÆÊúâÊïàÁöÑÊñπÊ≥ïÔºåÈÄèÈÅéË®ìÁ∑¥Ê®°ÂûãÁöÑÂü∫Êú¨Á©∫ÈñìËÉΩÂäõÔºå‰æÜÂ¢ûÂº∑ VLM ‰∏≠ÁöÑ 2D Á©∫ÈñìÊé®ÁêÜ„ÄÇÊàëÂÄëÈ¶ñÂÖàËß£Èñã 2D Á©∫ÈñìÊé®ÁêÜÁöÑÈóúÈçµÁµÑÊàêÈÉ®ÂàÜÔºöÊñπÂêëÁêÜËß£„ÄÅË∑ùÈõ¢‰º∞Ë®àÂíåÂÆö‰Ωç„ÄÇÊàëÂÄëÁöÑÊ†∏ÂøÉÂÅáË®≠ÊòØÔºåÊéåÊè°ÈÄô‰∫õÂü∫Êú¨Á©∫ÈñìËÉΩÂäõÂèØ‰ª•È°ØËëóÂ¢ûÂº∑Ê®°ÂûãÂú®ÈúÄË¶ÅÈÄ≤ÈöéÁ©∫ÈñìÁêÜËß£ÂíåÁµÑÂêàÂïèÈ°åËß£Ê±∫ÁöÑË§áÂêàÁ©∫Èñì‰ªªÂãô‰∏äÁöÑÊïàËÉΩ„ÄÇÁÇ∫‰∫ÜÁ†îÁ©∂ÈÄôÂÄãÂÅáË®≠ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü SparkleÔºå‰∏ÄÂÄãÈÄèÈÅéÂêàÊàêË≥áÊñôÁî¢ÁîüÂíåÈáùÂ∞çÊÄßÁõ£Áù£ÔºåÈáùÂ∞çÈÄô‰∏âÂÄãÂü∫Êú¨Á©∫ÈñìËÉΩÂäõÂæÆË™ø VLM ÁöÑÊû∂ÊßãÔºå‰ª•ÂΩ¢ÊàêÊØèÂÄãËÉΩÂäõÁöÑÊåá‰ª§Ë≥áÊñôÈõÜ„ÄÇÊàëÂÄëÁöÑÂØ¶È©óË≠âÊòéÔºå‰ΩøÁî® Sparkle ÂæÆË™øÁöÑ VLM ‰∏çÂÉÖÂú®Âü∫Êú¨‰ªªÂãôÊú¨Ë∫´‰∏≠Áç≤ÂæóÈ°ØËëóÁöÑÊïàËÉΩÊèêÂçáÔºåÈÇÑËÉΩÊé®Âª£Âà∞Ë§áÂêàÂíåÈùûÂàÜ‰ΩàÁ©∫ÈñìÊé®ÁêÜ‰ªªÂãôÔºà‰æãÂ¶ÇÔºåÂú®ÊúÄÁü≠Ë∑ØÂæëÂïèÈ°å‰∏äÂæû 13.5% ÊèêÂçáÂà∞ 40.0%Ôºâ„ÄÇÈÄô‰∫õÁôºÁèæÂº∑Ë™ø‰∫ÜÊéåÊè°Âü∫Êú¨Á©∫ÈñìËÉΩÂäõÂú®Â¢ûÂº∑Ë§áÂêàÁ©∫ÈñìÂïèÈ°åËß£Ê±∫‰∏≠ÁöÑÊúâÊïàÊÄßÔºåÁÇ∫ÊîπÂñÑ VLM ÁöÑÁ©∫ÈñìÊé®ÁêÜËÉΩÂäõÊèê‰æõ‰∫ÜË¶ãËß£„ÄÇ

##### **Limpeh ga li gong: Challenges in Singlish Annotations**
2410.16156v1 by Lynnette Hui Xian Ng, Luo Qi Chan

Singlish, or Colloquial Singapore English, is a language formed from oral and
social communication within multicultural Singapore. In this work, we work on a
fundamental Natural Language Processing (NLP) task: Parts-Of-Speech (POS)
tagging of Singlish sentences. For our analysis, we build a parallel Singlish
dataset containing direct English translations and POS tags, with translation
and POS annotation done by native Singlish speakers. Our experiments show that
automatic transition- and transformer- based taggers perform with only $\sim
80\%$ accuracy when evaluated against human-annotated POS labels, suggesting
that there is indeed room for improvement on computation analysis of the
language. We provide an exposition of challenges in Singlish annotation: its
inconsistencies in form and semantics, the highly context-dependent particles
of the language, its structural unique expressions, and the variation of the
language on different mediums. Our task definition, resultant labels and
results reflects the challenges in analysing colloquial languages formulated
from a variety of dialects, and paves the way for future studies beyond POS
tagging.

ÊëòË¶ÅÔºöÊñ∞Âä†Âù°ÂºèËã±Ë™ûÔºåÂèàÁ®±Êñ∞Âä†Âù°Âè£Ë™ûËã±Ë™ûÔºåÊòØ‰∏ÄÁ®ÆÂú®Êñ∞Âä†Âù°Â§öÂÖÉÊñáÂåñÁ§æÊúÉ‰∏≠Áî±Âè£È†≠ÂíåÁ§æ‰∫§Ê∫ùÈÄöÂΩ¢ÊàêÁöÑË™ûË®Ä„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÂæû‰∫ã‰∏ÄÈ†ÖÂü∫Êú¨ÁöÑËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ (NLP) ‰ªªÂãôÔºöÊñ∞Âä†Âù°ÂºèËã±Ë™ûÂè•Â≠êÁöÑË©ûÊÄßÊ®ôË®ò (POS)„ÄÇÂ∞çÊñºÊàëÂÄëÁöÑÂàÜÊûêÔºåÊàëÂÄëÂª∫Á´ã‰∫Ü‰∏ÄÂÄãÂπ≥Ë°åÁöÑÊñ∞Âä†Âù°ÂºèËã±Ë™ûÊï∏ÊìöÈõÜÔºåÂÖ∂‰∏≠ÂåÖÂê´Áõ¥Êé•ÁöÑËã±ÊñáÁøªË≠ØÂíåË©ûÊÄßÊ®ôË®òÔºåÁøªË≠ØÂíåË©ûÊÄßÊ®ôË®òÊòØÁî±Êñ∞Âä†Âù°ÂºèËã±Ë™ûÊØçË™û‰∫∫Â£´ÂÆåÊàêÁöÑ„ÄÇÊàëÂÄëÁöÑÂØ¶È©óË°®ÊòéÔºåÂú®Ê†πÊìö‰∫∫Â∑•Ê®ôË®òÁöÑË©ûÊÄßÊ®ôÁ±§ÈÄ≤Ë°åË©ï‰º∞ÊôÇÔºåÂü∫ÊñºËá™ÂãïËΩâÊèõÂíåËÆäÊèõÂô®ÁöÑÊ®ôË®òÂô®ÂÉÖËÉΩÂü∑Ë°åÁ¥Ñ 80% ÁöÑÊ∫ñÁ¢∫Â∫¶ÔºåÈÄôË°®ÊòéË™ûË®ÄÁöÑË®àÁÆóÂàÜÊûêÁ¢∫ÂØ¶ÊúâÊîπÈÄ≤ÁöÑÁ©∫Èñì„ÄÇÊàëÂÄëÈó°Ëø∞‰∫ÜÊñ∞Âä†Âù°ÂºèËã±Ë™ûÊ®ôË®ò‰∏≠ÁöÑÊåëÊà∞ÔºöÂÖ∂ÂΩ¢ÂºèÂíåË™ûÁæ©ÁöÑ‰∏ç‰∏ÄËá¥ÊÄß„ÄÅÈ´òÂ∫¶‰æùË≥¥ÊñºË™ûÂ¢ÉÁöÑË™ûË®ÄÁ≤íÂ≠ê„ÄÅÂÖ∂ÁµêÊßãÁç®ÁâπÁöÑË°®ÈÅîÊñπÂºè‰ª•ÂèäË™ûË®ÄÂú®‰∏çÂêåÂ™í‰ªã‰∏äÁöÑËÆäÂåñ„ÄÇÊàëÂÄëÁöÑ‰ªªÂãôÂÆöÁæ©„ÄÅÁµêÊûúÊ®ôÁ±§ÂíåÁµêÊûúÂèçÊò†‰∫ÜÂàÜÊûêÁî±ÂêÑÁ®ÆÊñπË®ÄÊßãÊàêÁöÑÂè£Ë™ûË™ûË®ÄÁöÑÊåëÊà∞Ôºå‰∏¶ÁÇ∫Ë∂ÖË∂äË©ûÊÄßÊ®ôË®òÁöÑÊú™‰æÜÁ†îÁ©∂Èã™Âπ≥‰∫ÜÈÅìË∑Ø„ÄÇ

##### **A Troublemaker with Contagious Jailbreak Makes Chaos in Honest Towns**
2410.16155v1 by Tianyi Men, Pengfei Cao, Zhuoran Jin, Yubo Chen, Kang Liu, Jun Zhao

With the development of large language models, they are widely used as agents
in various fields. A key component of agents is memory, which stores vital
information but is susceptible to jailbreak attacks. Existing research mainly
focuses on single-agent attacks and shared memory attacks. However, real-world
scenarios often involve independent memory. In this paper, we propose the
Troublemaker Makes Chaos in Honest Town (TMCHT) task, a large-scale,
multi-agent, multi-topology text-based attack evaluation framework. TMCHT
involves one attacker agent attempting to mislead an entire society of agents.
We identify two major challenges in multi-agent attacks: (1) Non-complete graph
structure, (2) Large-scale systems. We attribute these challenges to a
phenomenon we term toxicity disappearing. To address these issues, we propose
an Adversarial Replication Contagious Jailbreak (ARCJ) method, which optimizes
the retrieval suffix to make poisoned samples more easily retrieved and
optimizes the replication suffix to make poisoned samples have contagious
ability. We demonstrate the superiority of our approach in TMCHT, with 23.51%,
18.95%, and 52.93% improvements in line topology, star topology, and 100-agent
settings. Encourage community attention to the security of multi-agent systems.

ÊëòË¶ÅÔºöÈöèÁùÄÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÁöÑÂèëÂ±ïÔºåÂÆÉ‰ª¨Ë¢´ÂπøÊ≥õÁî®‰ΩúÂêÑ‰∏™È¢ÜÂüüÁöÑ‰ª£ÁêÜ„ÄÇ‰ª£ÁêÜÁöÑÂÖ≥ÈîÆÁªÑÊàêÈÉ®ÂàÜÊòØËÆ∞ÂøÜÔºåÂÆÉÂ≠òÂÇ®ÈáçË¶Å‰ø°ÊÅØÔºå‰ΩÜÂÆπÊòìÂèóÂà∞Ë∂äÁã±ÊîªÂáª„ÄÇÁé∞ÊúâÁ†îÁ©∂‰∏ªË¶ÅÈõÜ‰∏≠Âú®Âçï‰∏Ä‰ª£ÁêÜÊîªÂáªÂíåÂÖ±‰∫´ÂÜÖÂ≠òÊîªÂáª‰∏ä„ÄÇÁÑ∂ËÄåÔºåÁé∞ÂÆû‰∏ñÁïå‰∏≠ÁöÑÂú∫ÊôØÈÄöÂ∏∏Ê∂âÂèäÁã¨Á´ãÁöÑÂÜÖÂ≠ò„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü Troublemaker Makes Chaos in Honest Town (TMCHT) ‰ªªÂä°ÔºåËøôÊòØ‰∏Ä‰∏™Â§ßËßÑÊ®°„ÄÅÂ§ö‰ª£ÁêÜ„ÄÅÂ§öÊãìÊâëÂü∫‰∫éÊñáÊú¨ÁöÑÊîªÂáªËØÑ‰º∞Ê°ÜÊû∂„ÄÇTMCHT Ê∂âÂèä‰∏Ä‰∏™ÊîªÂáªËÄÖ‰ª£ÁêÜËØïÂõæËØØÂØºÊï¥‰∏™‰ª£ÁêÜÁ§æ‰ºö„ÄÇÊàë‰ª¨Á°ÆÂÆö‰∫ÜÂ§ö‰ª£ÁêÜÊîªÂáª‰∏≠ÁöÑ‰∏§‰∏™‰∏ªË¶ÅÊåëÊàòÔºö(1) ÈùûÂÆåÊï¥ÂõæÁªìÊûÑÔºå(2) Â§ßËßÑÊ®°Á≥ªÁªü„ÄÇÊàë‰ª¨Â∞ÜËøô‰∫õÊåëÊàòÂΩíÂõ†‰∫éÊàë‰ª¨Áß∞‰πã‰∏∫ÊØíÊÄßÊ∂àÂ§±ÁöÑÁé∞Ë±°„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∫õÈóÆÈ¢òÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçÂØπÊäóÊÄßÂ§çÂà∂‰º†ÊüìÊÄßË∂äÁã± (ARCJ) ÊñπÊ≥ïÔºåËØ•ÊñπÊ≥ï‰ºòÂåñ‰∫ÜÊ£ÄÁ¥¢ÂêéÁºÄ‰ª•‰Ωø‰∏≠ÊØíÊ†∑Êú¨Êõ¥ÂÆπÊòìË¢´Ê£ÄÁ¥¢ÔºåÂπ∂‰ºòÂåñ‰∫ÜÂ§çÂà∂ÂêéÁºÄ‰ª•‰Ωø‰∏≠ÊØíÊ†∑Êú¨ÂÖ∑Êúâ‰º†ÊüìÊÄß„ÄÇÊàë‰ª¨Âú® TMCHT ‰∏≠Â±ïÁ§∫‰∫ÜÊàë‰ª¨ÊñπÊ≥ïÁöÑ‰ºòË∂äÊÄßÔºåÂú®Áõ¥Á∫øÊãìÊâë„ÄÅÊòüÂΩ¢ÊãìÊâëÂíå 100 ‰ª£ÁêÜËÆæÁΩÆ‰∏≠ÂàÜÂà´ÊèêÈ´ò‰∫Ü 23.51%„ÄÅ18.95% Âíå 52.93%„ÄÇÈºìÂä±Á§æÂå∫ÂÖ≥Ê≥®Â§ö‰ª£ÁêÜÁ≥ªÁªüÁöÑÂÆâÂÖ®ÊÄß„ÄÇ

##### **Pangea: A Fully Open Multilingual Multimodal LLM for 39 Languages**
2410.16153v1 by Xiang Yue, Yueqi Song, Akari Asai, Seungone Kim, Jean de Dieu Nyandwi, Simran Khanuja, Anjali Kantharuban, Lintang Sutawika, Sathyanarayanan Ramamoorthy, Graham Neubig

Despite recent advances in multimodal large language models (MLLMs), their
development has predominantly focused on English- and western-centric datasets
and tasks, leaving most of the world's languages and diverse cultural contexts
underrepresented. This paper introduces Pangea, a multilingual multimodal LLM
trained on PangeaIns, a diverse 6M instruction dataset spanning 39 languages.
PangeaIns features: 1) high-quality English instructions, 2) carefully
machine-translated instructions, and 3) culturally relevant multimodal tasks to
ensure cross-cultural coverage. To rigorously assess models' capabilities, we
introduce PangeaBench, a holistic evaluation suite encompassing 14 datasets
covering 47 languages. Results show that Pangea significantly outperforms
existing open-source models in multilingual settings and diverse cultural
contexts. Ablation studies further reveal the importance of English data
proportions, language popularity, and the number of multimodal training samples
on overall performance. We fully open-source our data, code, and trained
checkpoints, to facilitate the development of inclusive and robust multilingual
MLLMs, promoting equity and accessibility across a broader linguistic and
cultural spectrum.

ÊëòË¶ÅÔºöÂÑòÁÆ°Â§öÊ®°ÊÖãÂ§ßÂûãË™ûË®ÄÊ®°Âûã (MLLM) ËøëÊúüÊúâÈï∑Ë∂≥ÈÄ≤Â±ïÔºåÂÆÉÂÄëÁöÑÈñãÁôº‰∏ªË¶ÅÈõÜ‰∏≠Êñº‰ª•Ëã±Ë™ûÂíåË•øÊñπÁÇ∫‰∏≠ÂøÉÁöÑË≥áÊñôÈõÜÂíå‰ªªÂãô‰∏äÔºåÂ∞éËá¥‰∏ñÁïå‰∏äÂ§ßÂ§öÊï∏Ë™ûË®ÄÂíåÂ§öÂÖÉÊñáÂåñËÑàÁµ°ÈÉΩÊú™ÂæóÂà∞ÂÖÖÂàÜÁöÑ‰ª£Ë°®„ÄÇÊú¨Êñá‰ªãÁ¥π‰∫Ü PangeaÔºåÈÄôÊòØ‰∏ÄÂÄãÂ§öË™ûË®ÄÂ§öÊ®°ÊÖã LLMÔºåÁ∂ìÈÅé PangeaIns Ë®ìÁ∑¥ÔºåPangeaIns ÊòØ‰∏ÄÂÄãË∑®Ë∂ä 39 Á®ÆË™ûË®ÄÁöÑÂ§öÂÖÉÂåñ 6M Êåá‰ª§Ë≥áÊñôÈõÜ„ÄÇPangeaIns ÁöÑÁâπËâ≤Ôºö1) È´òÂìÅË≥™ÁöÑËã±Ë™ûÊåá‰ª§Ôºå2) Á∂ìÈÅé‰ªîÁ¥∞Ê©üÂô®ÁøªË≠ØÁöÑÊåá‰ª§Ôºå‰ª•Âèä 3) ËàáÊñáÂåñÁõ∏ÈóúÁöÑÂ§öÊ®°ÊÖã‰ªªÂãôÔºå‰ª•Á¢∫‰øùË∑®ÊñáÂåñÊ∂µËìãÁØÑÂúç„ÄÇÁÇ∫‰∫ÜÂö¥Ê†ºË©ï‰º∞Ê®°ÂûãÁöÑËÉΩÂäõÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü PangeaBenchÔºåÈÄôÊòØ‰∏ÄÂÄãÂÖ®Èù¢ÁöÑË©ï‰º∞Â•ó‰ª∂ÔºåÊ∂µËìã‰∫Ü 14 ÂÄãË≥áÊñôÈõÜÔºåÊ∂µËìã 47 Á®ÆË™ûË®Ä„ÄÇÁµêÊûúÈ°ØÁ§∫ÔºåPangea Âú®Â§öË™ûË®ÄÁí∞Â¢ÉÂíåÂ§öÂÖÉÊñáÂåñËÑàÁµ°‰∏≠ÊòéÈ°ØÂÑ™ÊñºÁèæÊúâÁöÑÈñãÊîæÂéüÂßãÁ¢ºÊ®°Âûã„ÄÇÊ∂àËûçÁ†îÁ©∂ÈÄ≤‰∏ÄÊ≠•Êè≠Á§∫‰∫ÜËã±Ë™ûË≥áÊñôÊØî‰æã„ÄÅË™ûË®ÄÊôÆÂèäÁ®ãÂ∫¶ÂíåÂ§öÊ®°ÊÖãË®ìÁ∑¥Ê®£Êú¨Êï∏ÈáèÂ∞çÊï¥È´îÊïàËÉΩÁöÑÈáçË¶ÅÊÄß„ÄÇÊàëÂÄëÂÆåÂÖ®ÈñãÊîæÂéüÂßãÁ¢º„ÄÅ‰ª£Á¢ºÂíåË®ìÁ∑¥ÈÅéÁöÑÊ™¢Êü•ÈªûÔºå‰ª•‰øÉÈÄ≤ÂåÖÂÆπ‰∏îÂº∑Â§ßÁöÑÂ§öË™ûË®Ä MLLM ÁöÑÈñãÁôºÔºåÂú®Êõ¥Âª£Ê≥õÁöÑË™ûË®ÄÂíåÊñáÂåñÈ†òÂüüÊé®Âª£ÂÖ¨Âπ≥ÊÄßÂíåÂèØÂèäÊÄß„ÄÇ

##### **Warped Diffusion: Solving Video Inverse Problems with Image Diffusion Models**
2410.16152v2 by Giannis Daras, Weili Nie, Karsten Kreis, Alex Dimakis, Morteza Mardani, Nikola Borislavov Kovachki, Arash Vahdat

Using image models naively for solving inverse video problems often suffers
from flickering, texture-sticking, and temporal inconsistency in generated
videos. To tackle these problems, in this paper, we view frames as continuous
functions in the 2D space, and videos as a sequence of continuous warping
transformations between different frames. This perspective allows us to train
function space diffusion models only on images and utilize them to solve
temporally correlated inverse problems. The function space diffusion models
need to be equivariant with respect to the underlying spatial transformations.
To ensure temporal consistency, we introduce a simple post-hoc test-time
guidance towards (self)-equivariant solutions. Our method allows us to deploy
state-of-the-art latent diffusion models such as Stable Diffusion XL to solve
video inverse problems. We demonstrate the effectiveness of our method for
video inpainting and $8\times$ video super-resolution, outperforming existing
techniques based on noise transformations. We provide generated video results:
https://giannisdaras.github.io/warped_diffusion.github.io/.

ÊëòË¶ÅÔºö‰ΩøÁî®ÂõæÂÉèÊ®°ÂûãÊù•Ëß£ÂÜ≥ÈÄÜËßÜÈ¢ëÈóÆÈ¢òÊó∂ÔºåÈÄöÂ∏∏‰ºöÂá∫Áé∞Èó™ÁÉÅ„ÄÅÁ∫πÁêÜÁ≤òËøûÂíåÁîüÊàêËßÜÈ¢ëÁöÑÊó∂Èó¥‰∏ç‰∏ÄËá¥ÈóÆÈ¢ò„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∫õÈóÆÈ¢òÔºåÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨Â∞ÜÂ∏ßËßÜ‰∏∫ 2D Á©∫Èó¥‰∏≠ÁöÑËøûÁª≠ÂáΩÊï∞ÔºåÂπ∂Â∞ÜËßÜÈ¢ëËßÜ‰∏∫‰∏çÂêåÂ∏ß‰πãÈó¥ÁöÑËøûÁª≠Êâ≠Êõ≤ÂèòÊç¢Â∫èÂàó„ÄÇËøôÁßçËßÇÁÇπ‰ΩøÊàë‰ª¨ËÉΩÂ§ü‰ªÖÂú®ÂõæÂÉè‰∏äËÆ≠ÁªÉÂáΩÊï∞Á©∫Èó¥Êâ©Êï£Ê®°ÂûãÔºåÂπ∂Âà©Áî®ÂÆÉ‰ª¨Êù•Ëß£ÂÜ≥Êó∂Èó¥Áõ∏ÂÖ≥ÈÄÜÈóÆÈ¢ò„ÄÇÂáΩÊï∞Á©∫Èó¥Êâ©Êï£Ê®°ÂûãÈúÄË¶ÅÁõ∏ÂØπ‰∫éÂ∫ïÂ±ÇÁ©∫Èó¥ÂèòÊç¢‰øùÊåÅÁ≠âÂèòÊÄß„ÄÇ‰∏∫‰∫ÜÁ°Æ‰øùÊó∂Èó¥‰∏ÄËá¥ÊÄßÔºåÊàë‰ª¨Âú®‰∫ãÂêéÊµãËØïÊó∂Èó¥ÊåáÂØº‰∏≠ÂºïÂÖ•‰∫Ü‰∏Ä‰∏™ÁÆÄÂçïÁöÑÔºàËá™ÔºâÁ≠âÂèòËß£„ÄÇÊàë‰ª¨ÁöÑÊñπÊ≥ï‰ΩøÊàë‰ª¨ËÉΩÂ§üÈÉ®ÁΩ≤ÊúÄÂÖàËøõÁöÑÊΩúÂú®Êâ©Êï£Ê®°ÂûãÔºà‰æãÂ¶Ç Stable Diffusion XLÔºâÊù•Ëß£ÂÜ≥ËßÜÈ¢ëÈÄÜÈóÆÈ¢ò„ÄÇÊàë‰ª¨Â±ïÁ§∫‰∫ÜÊàë‰ª¨ÁöÑÊñπÊ≥ïÂú®ËßÜÈ¢ë‰øÆÂ§çÂíå 8 ÂÄçËßÜÈ¢ëË∂ÖÂàÜËæ®ÁéáÊñπÈù¢ÁöÑÊúâÊïàÊÄßÔºå‰ºò‰∫éÂü∫‰∫éÂô™Â£∞ÂèòÊç¢ÁöÑÁé∞ÊúâÊäÄÊúØ„ÄÇÊàë‰ª¨Êèê‰æõ‰∫ÜÁîüÊàêÁöÑËßÜÈ¢ëÁªìÊûúÔºöhttps://giannisdaras.github.io/warped_diffusion.github.io/„ÄÇ

##### **Small Contributions, Small Networks: Efficient Neural Network Pruning Based on Relative Importance**
2410.16151v1 by Mostafa Hussien, Mahmoud Afifi, Kim Khoa Nguyen, Mohamed Cheriet

Recent advancements have scaled neural networks to unprecedented sizes,
achieving remarkable performance across a wide range of tasks. However,
deploying these large-scale models on resource-constrained devices poses
significant challenges due to substantial storage and computational
requirements. Neural network pruning has emerged as an effective technique to
mitigate these limitations by reducing model size and complexity. In this
paper, we introduce an intuitive and interpretable pruning method based on
activation statistics, rooted in information theory and statistical analysis.
Our approach leverages the statistical properties of neuron activations to
identify and remove weights with minimal contributions to neuron outputs.
Specifically, we build a distribution of weight contributions across the
dataset and utilize its parameters to guide the pruning process. Furthermore,
we propose a Pruning-aware Training strategy that incorporates an additional
regularization term to enhance the effectiveness of our pruning method.
Extensive experiments on multiple datasets and network architectures
demonstrate that our method consistently outperforms several baseline and
state-of-the-art pruning techniques.

ÊëòË¶ÅÔºöÊúÄËøëÁöÑÈÄ≤Â±ïÂ∑≤Â∞áÁ•ûÁ∂ìÁ∂≤Ë∑ØÊì¥Â±ïÂà∞ÂâçÊâÄÊú™ÊúâÁöÑË¶èÊ®°ÔºåÂú®Âª£Ê≥õÁöÑ‰ªªÂãô‰∏≠ÂØ¶Áèæ‰∫ÜÈ°ØËëóÁöÑÊïàËÉΩ„ÄÇÁÑ∂ËÄåÔºåÁî±ÊñºÂ§ßÈáèÁöÑÂÑ≤Â≠òÂíåÈÅãÁÆóÈúÄÊ±ÇÔºåÂú®Ë≥áÊ∫êÂèóÈôêÁöÑË£ùÁΩÆ‰∏äÈÉ®ÁΩ≤ÈÄô‰∫õÂ§ßË¶èÊ®°Ê®°ÂûãÊúÉÂ∏∂‰æÜÈáçÂ§ßÁöÑÊåëÊà∞„ÄÇÁ•ûÁ∂ìÁ∂≤Ë∑ØÂâ™ÊûùÂ∑≤ÊàêÁÇ∫‰∏ÄÁ®ÆÊúâÊïàÁöÑÊäÄË°ìÔºåÂèØÈÄèÈÅéÊ∏õÂ∞ëÊ®°ÂûãÂ§ßÂ∞èÂíåË§áÈõúÂ∫¶‰æÜÊ∏õËºïÈÄô‰∫õÈôêÂà∂„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫Ü‰∏ÄÁ®ÆÂü∫ÊñºÂïüÁî®Áµ±Ë®àÁöÑÁõ¥Ë¶∫‰∏îÂèØËß£ÈáãÁöÑÂâ™ÊûùÊñπÊ≥ïÔºåÂÖ∂Ê†πÊ§çÊñºË≥áË®äÁêÜË´ñÂíåÁµ±Ë®àÂàÜÊûê„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÂà©Áî®Á•ûÁ∂ìÂÖÉÂïüÁî®ÁöÑÁµ±Ë®àÁâπÊÄß‰æÜË≠òÂà•‰∏¶ÁßªÈô§Â∞çÁ•ûÁ∂ìÂÖÉËº∏Âá∫Ë≤¢ÁçªÊúÄÂ∞èÁöÑÊ¨äÈáç„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÂª∫Á´ã‰∫ÜË∑®Ë≥áÊñôÈõÜÁöÑÊ¨äÈáçË≤¢ÁçªÂàÜ‰ΩàÔºå‰∏¶Âà©Áî®ÂÖ∂ÂèÉÊï∏‰æÜÊåáÂ∞éÂâ™ÊûùÈÅéÁ®ã„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂâ™ÊûùÊÑüÁü•Ë®ìÁ∑¥Á≠ñÁï•ÔºåÂÖ∂‰∏≠ÂåÖÂê´‰∏ÄÂÄãÈ°çÂ§ñÁöÑÊ≠£ÂâáÂåñÈ†ÖÔºå‰ª•Â¢ûÂº∑ÊàëÂÄëÂâ™ÊûùÊñπÊ≥ïÁöÑÊúâÊïàÊÄß„ÄÇÂú®Â§öÂÄãË≥áÊñôÈõÜÂíåÁ∂≤Ë∑ØÊû∂Êßã‰∏äÁöÑÂª£Ê≥õÂØ¶È©óË°®ÊòéÔºåÊàëÂÄëÁöÑÊ®°ÂûãÂßãÁµÇÂÑ™ÊñºÂ§öÁ®ÆÂü∫Á∑öÂíåÊúÄÂÖàÈÄ≤ÁöÑÂâ™ÊûùÊäÄË°ì„ÄÇ

##### **PODTILE: Facilitating Podcast Episode Browsing with Auto-generated Chapters**
2410.16148v1 by Azin Ghazimatin, Ekaterina Garmash, Gustavo Penha, Kristen Sheets, Martin Achenbach, Oguz Semerci, Remi Galvez, Marcus Tannenberg, Sahitya Mantravadi, Divya Narayanan, Ofeliya Kalaydzhyan, Douglas Cole, Ben Carterette, Ann Clifton, Paul N. Bennett, Claudia Hauff, Mounia Lalmas

Listeners of long-form talk-audio content, such as podcast episodes, often
find it challenging to understand the overall structure and locate relevant
sections. A practical solution is to divide episodes into
chapters--semantically coherent segments labeled with titles and timestamps.
Since most episodes on our platform at Spotify currently lack creator-provided
chapters, automating the creation of chapters is essential. Scaling the
chapterization of podcast episodes presents unique challenges. First, episodes
tend to be less structured than written texts, featuring spontaneous
discussions with nuanced transitions. Second, the transcripts are usually
lengthy, averaging about 16,000 tokens, which necessitates efficient processing
that can preserve context. To address these challenges, we introduce PODTILE, a
fine-tuned encoder-decoder transformer to segment conversational data. The
model simultaneously generates chapter transitions and titles for the input
transcript. To preserve context, each input text is augmented with global
context, including the episode's title, description, and previous chapter
titles. In our intrinsic evaluation, PODTILE achieved an 11% improvement in
ROUGE score over the strongest baseline. Additionally, we provide insights into
the practical benefits of auto-generated chapters for listeners navigating
episode content. Our findings indicate that auto-generated chapters serve as a
useful tool for engaging with less popular podcasts. Finally, we present
empirical evidence that using chapter titles can enhance effectiveness of
sparse retrieval in search tasks.

ÊëòË¶ÅÔºö<paragraph>ËÅÜËÅΩÈï∑ÁØáË´áË©±ÂºèÈü≥Ë®äÂÖßÂÆπÔºà‰æãÂ¶ÇÊí≠ÂÆ¢ÁØÄÁõÆÔºâÁöÑËÅΩÁúæÔºåÈÄöÂ∏∏ÂæàÈõ£ÁêÜËß£Êï¥È´îÁµêÊßã‰∏¶ÊâæÂà∞Áõ∏ÈóúÈÉ®ÂàÜ„ÄÇ‰∏ÄÂÄãÂØ¶Áî®ÁöÑËß£Ê±∫ÊñπÊ°àÊòØÂ∞áÁØÄÁõÆÂàÜÁÇ∫Á´†ÁØÄÔºåÂç≥Ê®ôË®òÊúâÊ®ôÈ°åÂíåÊôÇÈñìÊà≥ÁöÑË™ûÁæ©ÈÄ£Ë≤´ÂçÄÊÆµ„ÄÇÁî±Êñº Spotify ‰∏äÊàëÂÄëÂπ≥Âè∞‰∏äÁöÑÂ§ßÂ§öÊï∏ÁØÄÁõÆÁõÆÂâçÁº∫‰πèÂâµ‰ΩúËÄÖÊèê‰æõÁöÑÁ´†ÁØÄÔºåÂõ†Ê≠§Ëá™ÂãïÂª∫Á´ãÁ´†ÁØÄËá≥ÈóúÈáçË¶Å„ÄÇÂ∞çÊí≠ÂÆ¢ÁØÄÁõÆÈÄ≤Ë°åÁ´†ÁØÄÂåñÁöÑÊì¥Â±ïÊèêÂá∫‰∫ÜÁç®ÁâπÁöÑÊåëÊà∞„ÄÇÈ¶ñÂÖàÔºåÁØÄÁõÆÂæÄÂæÄ‰∏çÂ¶ÇÊõ∏Èù¢ÊñáÊú¨ÁµêÊßãÂåñÔºåËÄåÊòØ‰ª•Ëá™ÁôºÁöÑË®éË´ñÂíåÂæÆÂ¶ôÁöÑÈÅéÊ∏°ÁÇ∫ÁâπËâ≤„ÄÇÂÖ∂Ê¨°ÔºåË¨ÑÊú¨ÈÄöÂ∏∏ÂæàÈï∑ÔºåÂπ≥ÂùáÁ¥Ñ 16,000 ÂÄãË©ûÂΩôÔºåÈÄôÈúÄË¶ÅËÉΩÂ§†‰øùÁïô‰∏ä‰∏ãÊñáÁöÑÊúâÊïàËôïÁêÜ„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü PODTILEÔºå‰∏ÄÂÄãÁ∂ìÈÅéÂæÆË™øÁöÑÁ∑®Á¢ºÂô®-Ëß£Á¢ºÂô®ËΩâÊèõÂô®ÔºåÁî®ÊñºÂ∞çË©±Êï∏ÊìöÈÄ≤Ë°åÂàÜÊÆµ„ÄÇË©≤Ê®°ÂûãÂêåÊôÇÁÇ∫Ëº∏ÂÖ•Ë¨ÑÊú¨ÁîüÊàêÁ´†ÁØÄËΩâÊèõÂíåÊ®ôÈ°å„ÄÇÁÇ∫‰∫Ü‰øùÁïô‰∏ä‰∏ãÊñáÔºåÊØèÂÄãËº∏ÂÖ•ÊñáÊú¨ÈÉΩÈôÑÊúâÂÖ®Â±Ä‰∏ä‰∏ãÊñáÔºåÂåÖÊã¨ÁØÄÁõÆÁöÑÊ®ôÈ°å„ÄÅÊèèËø∞ÂíåÂâç‰∏ÄÁ´†ÁØÄÁöÑÊ®ôÈ°å„ÄÇÂú®ÊàëÂÄëÁöÑÂÖßÈÉ®Ë©ï‰º∞‰∏≠ÔºåPODTILE ÁöÑ ROUGE ÂæóÂàÜÊØîÊúÄÂº∑ÁöÑÂü∫Ê∫ñÁ∑öÊèêÈ´ò‰∫Ü 11%„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèê‰æõ‰∫ÜÂ∞çËá™ÂãïÁîüÊàêÁ´†ÁØÄÂ∞çËÅΩÁúæÁÄèË¶ΩÁØÄÁõÆÂÖßÂÆπÁöÑÂØ¶ÈöõÂ•ΩËôïÁöÑË¶ãËß£„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúË°®ÊòéÔºåËá™ÂãïÁîüÊàêÁöÑÁ´†ÁØÄÂèØÁî®‰ΩúËàá‰∏çÂ§™ÊµÅË°åÁöÑÊí≠ÂÆ¢‰∫íÂãïÁöÑÊúâÁî®Â∑•ÂÖ∑„ÄÇÊúÄÂæåÔºåÊàëÂÄëÊèêÂá∫‰∫ÜÁ∂ìÂØ¶Ë≠âË≠âÊòéÁöÑË≠âÊìöÔºåË°®Êòé‰ΩøÁî®Á´†ÁØÄÊ®ôÈ°åÂèØ‰ª•ÊèêÈ´òÊêúÁ¥¢‰ªªÂãô‰∏≠Á®ÄÁñèÊ™¢Á¥¢ÁöÑÊúâÊïàÊÄß„ÄÇ</paragraph>

##### **1-bit AI Infra: Part 1.1, Fast and Lossless BitNet b1.58 Inference on CPUs**
2410.16144v1 by Jinheng Wang, Hansong Zhou, Ting Song, Shaoguang Mao, Shuming Ma, Hongyu Wang, Yan Xia, Furu Wei

Recent advances in 1-bit Large Language Models (LLMs), such as BitNet and
BitNet b1.58, present a promising approach to enhancing the efficiency of LLMs
in terms of speed and energy consumption. These developments also enable local
LLM deployment across a broad range of devices. In this work, we introduce
bitnet.cpp, a tailored software stack designed to unlock the full potential of
1-bit LLMs. Specifically, we develop a set of kernels to support fast and
lossless inference of ternary BitNet b1.58 LLMs on CPUs. Extensive experiments
demonstrate that bitnet.cpp achieves significant speedups, ranging from 2.37x
to 6.17x on x86 CPUs and from 1.37x to 5.07x on ARM CPUs, across various model
sizes. The code is available at https://github.com/microsoft/BitNet.

ÊëòË¶ÅÔºöÊúÄËøëÂú® 1 ‰ΩçÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÈÄ≤Â±ïÔºå‰æãÂ¶Ç BitNet Âíå BitNet b1.58ÔºåÊèê‰æõ‰∫Ü‰∏ÄÂÄãÊúâÂ∏åÊúõÁöÑÊñπÊ≥ï‰æÜÊèêÈ´ò LLM Âú®ÈÄüÂ∫¶ÂíåËÉΩÊ∫êÊ∂àËÄóÊñπÈù¢ÁöÑÊïàÁéá„ÄÇÈÄô‰∫õÁôºÂ±ï‰πüËÆì LLM Âú®Âª£Ê≥õÁöÑË£ùÁΩÆ‰∏äÈÄ≤Ë°åÊú¨Ê©üÈÉ®ÁΩ≤„ÄÇÂú®ÈÄôÂÄãÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π bitnet.cppÔºå‰∏ÄÂÄãÈáèË∫´ÊâìÈÄ†ÁöÑËªüÈ´îÂ†ÜÁñäÔºåÊó®Âú®ÈáãÊîæ 1 ‰Ωç LLM ÁöÑÂÖ®ÈÉ®ÊΩõÂäõ„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÈñãÁôº‰∫Ü‰∏ÄÁµÑÊ†∏ÂøÉ‰æÜÊîØÊè¥ CPU ‰∏ä‰∏âÂÖÉ BitNet b1.58 LLM ÁöÑÂø´ÈÄü‰∏îÁÑ°ÊêçÊé®Ë´ñ„ÄÇÂª£Ê≥õÁöÑÂØ¶È©óË≠âÊòéÔºåbitnet.cpp Áç≤ÂæóÈ°ØËëóÁöÑÂä†ÈÄüÔºåÂú® x86 CPU ‰∏äÂæû 2.37 ÂÄçÂà∞ 6.17 ÂÄçÔºåÂú® ARM CPU ‰∏äÂæû 1.37 ÂÄçÂà∞ 5.07 ÂÄçÔºåÊ∂µËìãÂêÑÁ®ÆÊ®°ÂûãÂ§ßÂ∞è„ÄÇÁ®ãÂºèÁ¢ºÂèØÂú® https://github.com/microsoft/BitNet ÂèñÂæó„ÄÇ

##### **A Psycholinguistic Evaluation of Language Models' Sensitivity to Argument Roles**
2410.16139v1 by Eun-Kyoung Rosa Lee, Sathvik Nair, Naomi Feldman

We present a systematic evaluation of large language models' sensitivity to
argument roles, i.e., who did what to whom, by replicating psycholinguistic
studies on human argument role processing. In three experiments, we find that
language models are able to distinguish verbs that appear in plausible and
implausible contexts, where plausibility is determined through the relation
between the verb and its preceding arguments. However, none of the models
capture the same selective patterns that human comprehenders exhibit during
real-time verb prediction. This indicates that language models' capacity to
detect verb plausibility does not arise from the same mechanism that underlies
human real-time sentence processing.

ÊëòË¶ÅÔºöÊàëÂÄëÈÄèÈÅéË§áË£ΩÂøÉÁêÜË™ûË®ÄÂ≠∏‰∏≠ÈóúÊñº‰∫∫È°ûË´ñÂÖÉËßíËâ≤ËôïÁêÜÁöÑÁ†îÁ©∂ÔºåÂ∞çÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÂ∞çË´ñÂÖÉËßíËâ≤ÔºàÂç≥Ë™∞Â∞çË™∞ÂÅö‰∫Ü‰ªÄÈ∫ºÔºâÁöÑÊïèÊÑüÂ∫¶ÈÄ≤Ë°åÁ≥ªÁµ±Ë©ï‰º∞„ÄÇÂú®‰∏âÂÄãÂØ¶È©ó‰∏≠ÔºåÊàëÂÄëÁôºÁèæË™ûË®ÄÊ®°ÂûãËÉΩÂ§†ÂçÄÂàÜÂá∫Âú®ÂêàÁêÜÂíå‰∏çÂêàÁêÜË™ûÂ¢É‰∏≠Âá∫ÁèæÁöÑÂãïË©ûÔºåÂÖ∂‰∏≠ÂêàÁêÜÊÄßÊòØÁî±ÂãïË©ûÂèäÂÖ∂ÂâçÁΩÆË´ñÂÖÉ‰πãÈñìÁöÑÈóú‰øÇÊ±∫ÂÆöÁöÑ„ÄÇÁÑ∂ËÄåÔºåÊ≤íÊúâ‰ªª‰ΩïÊ®°ÂûãËÉΩÊçïÊçâÂà∞‰∫∫È°ûÁêÜËß£ËÄÖÂú®ÂãïË©ûÈ†êÊ∏¨ÁöÑÂØ¶ÊôÇÈÅéÁ®ã‰∏≠Ë°®ÁèæÂá∫ÁöÑÁõ∏ÂêåÈÅ∏ÊìáÊ®°Âºè„ÄÇÈÄôË°®ÊòéË™ûË®ÄÊ®°ÂûãÊ™¢Ê∏¨ÂãïË©ûÂêàÁêÜÊÄßÁöÑËÉΩÂäõ‰∏¶ÈùûÊ∫êËá™‰∫∫È°ûÂØ¶ÊôÇÂè•Â≠êËôïÁêÜÁöÑÂü∫Á§éÊ©üÂà∂„ÄÇ

##### **Modeling dynamic neural activity by combining naturalistic video stimuli and stimulus-independent latent factors**
2410.16136v1 by Finn Schmidt, Suhas Shrinivasan, Polina Turishcheva, Fabian H. Sinz

Understanding how the brain processes dynamic natural stimuli remains a
fundamental challenge in neuroscience. Current dynamic neural encoding models
either take stimuli as input but ignore shared variability in neural responses,
or they model this variability by deriving latent embeddings from neural
responses or behavior while ignoring the visual input. To address this gap, we
propose a probabilistic model that incorporates video inputs along with
stimulus-independent latent factors to capture variability in neuronal
responses, predicting a joint distribution for the entire population. After
training and testing our model on mouse V1 neuronal responses, we found that it
outperforms video-only models in terms of log-likelihood and achieves further
improvements when conditioned on responses from other neurons. Furthermore, we
find that the learned latent factors strongly correlate with mouse behavior,
although the model was trained without behavior data.

ÊëòË¶ÅÔºö‰∫ÜËß£Â§ßËÑëÂ¶Ç‰ΩïÂ§ÑÁêÜÂä®ÊÄÅËá™ÁÑ∂Âà∫ÊøÄ‰ªçÁÑ∂ÊòØÁ•ûÁªèÁßëÂ≠¶‰∏≠ÁöÑ‰∏Ä‰∏™Âü∫Êú¨ÊåëÊàò„ÄÇÂΩìÂâçÁöÑÂä®ÊÄÅÁ•ûÁªèÁºñÁ†ÅÊ®°ÂûãË¶Å‰πàÂ∞ÜÂà∫ÊøÄ‰Ωú‰∏∫ËæìÂÖ•Ôºå‰ΩÜÂøΩÁï•Á•ûÁªèÂèçÂ∫î‰∏≠ÁöÑÂÖ±‰∫´ÂèòÂºÇÊÄßÔºåË¶Å‰πàÈÄöËøá‰ªéÁ•ûÁªèÂèçÂ∫îÊàñË°å‰∏∫‰∏≠ÂØºÂá∫ÊΩúÂú®ÂµåÂÖ•Êù•Âª∫Ê®°ËøôÁßçÂèòÂºÇÊÄßÔºåÂêåÊó∂ÂøΩÁï•ËßÜËßâËæìÂÖ•„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∏ÄÂ∑ÆË∑ùÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏Ä‰∏™Ê¶ÇÁéáÊ®°ÂûãÔºåËØ•Ê®°ÂûãÂ∞ÜËßÜÈ¢ëËæìÂÖ•‰∏éÁã¨Á´ã‰∫éÂà∫ÊøÄÁöÑÊΩúÂú®Âõ†Á¥†ÁªìÂêàËµ∑Êù•Ôºå‰ª•ÊçïËé∑Á•ûÁªèÂÖÉÂèçÂ∫î‰∏≠ÁöÑÂèòÂºÇÊÄßÔºåÈ¢ÑÊµãÊï¥‰∏™ÁßçÁæ§ÁöÑËÅîÂêàÂàÜÂ∏É„ÄÇÂú®ÂØπÂ∞èÈº† V1 Á•ûÁªèÂÖÉÂèçÂ∫îËøõË°åÊ®°ÂûãËÆ≠ÁªÉÂíåÊµãËØïÂêéÔºåÊàë‰ª¨ÂèëÁé∞ÂÆÉÂú®ÂØπÊï∞‰ººÁÑ∂ÊñπÈù¢‰ºò‰∫é‰ªÖËßÜÈ¢ëÊ®°ÂûãÔºåÂπ∂‰∏îÂú®‰ª•ÂÖ∂‰ªñÁ•ûÁªèÂÖÉÁöÑÂèçÂ∫î‰∏∫Êù°‰ª∂Êó∂ÂèñÂæó‰∫ÜËøõ‰∏ÄÊ≠•ÁöÑÊîπËøõ„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨ÂèëÁé∞Â≠¶‰π†Âà∞ÁöÑÊΩúÂú®Âõ†Á¥†‰∏éÂ∞èÈº†Ë°å‰∏∫ÂØÜÂàáÁõ∏ÂÖ≥ÔºåÂ∞ΩÁÆ°ËØ•Ê®°ÂûãÊòØÂú®Ê≤°ÊúâË°å‰∏∫Êï∞ÊçÆÁöÑÊÉÖÂÜµ‰∏ãËøõË°åËÆ≠ÁªÉÁöÑ„ÄÇ

##### **Beyond 2:4: exploring V:N:M sparsity for efficient transformer inference on GPUs**
2410.16135v1 by Kang Zhao, Tao Yuan, Han Bao, Zhenfeng Su, Chang Gao, Zhaofeng Sun, Zichen Liang, Liping Jing, Jianfei Chen

To date, 2:4 sparsity has stood as the only sparse pattern that can be
accelerated using sparse tensor cores on GPUs. In practice, 2:4 sparsity often
possesses low actual speedups ($\leq 1.3$) and requires fixed sparse ratios,
meaning that other ratios, such as 4:8, 8:16, or those exceeding 50% sparsity,
do not incur any speedups on GPUs. Recent studies suggest that V:N:M sparsity
is promising in addressing these limitations of 2:4 sparsity. However,
regarding accuracy, the effects of V:N:M sparsity on broader Transformer
models, such as vision Transformers and large language models (LLMs), are
largely unexamined. Moreover, Some specific issues related to V:N:M sparsity,
such as how to select appropriate V and M values, remain unresolved. In this
study, we thoroughly investigate the application of V:N:M sparsity in vision
models and LLMs across multiple tasks, from pertaining to downstream tasks. We
propose three key approaches to enhance the applicability and accuracy of
V:N:M-sparse Transformers, including heuristic V and M selection,
V:N:M-specific channel permutation, and three-staged LoRA training techniques.
Experimental results show that, with our methods, the DeiT-small achieves
lossless accuracy at 64:2:5 sparsity, while the DeiT-base maintains accuracy
even at 64:2:8 sparsity. In addition, the fine-tuned LLama2-7B at 64:2:5
sparsity performs comparably or better than training-free 2:4 sparse
alternatives on downstream tasks. More importantly, V:N:M-sparse Transformers
offer a wider range of speedup-accuracy trade-offs compared to 2:4 sparsity.
Overall, our exploration largely facilitates the V:N:M sparsity to act as a
truly effective acceleration solution for Transformers in cost-sensitive
inference scenarios.

ÊëòË¶ÅÔºöËøÑ‰ªä‰∏∫Ê≠¢Ôºå2:4 Á®ÄÁñèÊÄß‰∏ÄÁõ¥ÊòØÂîØ‰∏ÄÂèØ‰ª•‰ΩøÁî® GPU ‰∏äÁöÑÁ®ÄÁñèÂº†ÈáèÊ†∏Âä†ÈÄüÁöÑÁ®ÄÁñèÊ®°Âºè„ÄÇÂú®ÂÆûË∑µ‰∏≠Ôºå2:4 Á®ÄÁñèÊÄßÈÄöÂ∏∏ÂÖ∑ÊúâËæÉ‰ΩéÁöÑÂÆûÈôÖÂä†ÈÄüÔºà‚â§ 1.3ÔºâÔºåÂπ∂‰∏îÈúÄË¶ÅÂõ∫ÂÆöÁöÑÁ®ÄÁñèÊØîÁéáÔºåËøôÊÑèÂë≥ÁùÄÂÖ∂‰ªñÊØîÁéáÔºå‰æãÂ¶Ç 4:8„ÄÅ8:16 ÊàñË∂ÖËøá 50% Á®ÄÁñèÊÄßÁöÑÊØîÁéáÔºå‰∏ç‰ºöÂú® GPU ‰∏ä‰∫ßÁîü‰ªª‰ΩïÂä†ÈÄü„ÄÇÊúÄËøëÁöÑÁ†îÁ©∂Ë°®ÊòéÔºåV:N:M Á®ÄÁñèÊÄßÊúâÊúõËß£ÂÜ≥ 2:4 Á®ÄÁñèÊÄßÁöÑËøô‰∫õÈôêÂà∂„ÄÇÁÑ∂ËÄåÔºåÂú®ÂáÜÁ°ÆÊÄßÊñπÈù¢ÔºåV:N:M Á®ÄÁñèÊÄßÂØπÊõ¥ÂπøÊ≥õÁöÑ Transformer Ê®°ÂûãÔºà‰æãÂ¶ÇËßÜËßâ Transformer ÂíåÂ§ßÂûãËØ≠Ë®ÄÊ®°Âûã (LLM)ÔºâÁöÑÂΩ±ÂìçÂú®ÂæàÂ§ßÁ®ãÂ∫¶‰∏äÂ∞öÊú™ÂæóÂà∞Ê£ÄÈ™å„ÄÇÊ≠§Â§ñÔºå‰∏é V:N:M Á®ÄÁñèÊÄßÁõ∏ÂÖ≥ÁöÑ‰∏Ä‰∫õÂÖ∑‰ΩìÈóÆÈ¢òÔºå‰æãÂ¶ÇÂ¶Ç‰ΩïÈÄâÊã©ÂêàÈÄÇÁöÑ V Âíå M ÂÄºÔºå‰ªçÁÑ∂Ê≤°ÊúâÂæóÂà∞Ëß£ÂÜ≥„ÄÇÂú®ËøôÈ°πÁ†îÁ©∂‰∏≠ÔºåÊàë‰ª¨ÂΩªÂ∫ïÁ†îÁ©∂‰∫Ü V:N:M Á®ÄÁñèÊÄßÂú®ËßÜËßâÊ®°ÂûãÂíå LLM ‰∏≠ÁöÑÂ∫îÁî®ÔºåÊ∂µÁõñ‰ªéÂ±û‰∫é‰∏ãÊ∏∏‰ªªÂä°ÁöÑÂ§ö‰∏™‰ªªÂä°„ÄÇÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏âÁßçÂÖ≥ÈîÆÊñπÊ≥ïÊù•Â¢ûÂº∫ V:N:M Á®ÄÁñè Transformer ÁöÑÈÄÇÁî®ÊÄßÂíåÂáÜÁ°ÆÊÄßÔºåÂåÖÊã¨ÂêØÂèëÂºè V Âíå M ÈÄâÊã©„ÄÅV:N:M ÁâπÂÆöÈÄöÈÅìÁΩÆÊç¢Âíå‰∏âÈò∂ÊÆµ LoRA ËÆ≠ÁªÉÊäÄÊúØ„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºå‰ΩøÁî®Êàë‰ª¨ÁöÑÊñπÊ≥ïÔºåDeiT-small Âú® 64:2:5 Á®ÄÁñèÊÄß‰∏ãÂÆûÁé∞‰∫ÜÊó†ÊçüÂáÜÁ°ÆÊÄßÔºåËÄå DeiT-base Âç≥‰ΩøÂú® 64:2:8 Á®ÄÁñèÊÄß‰∏ã‰πüËÉΩ‰øùÊåÅÂáÜÁ°ÆÊÄß„ÄÇÊ≠§Â§ñÔºåÂú® 64:2:5 Á®ÄÁñèÊÄß‰∏ãÂæÆË∞ÉÁöÑ LLama2-7B Âú®‰∏ãÊ∏∏‰ªªÂä°‰∏äÁöÑË°®Áé∞‰∏éÊó†ËÆ≠ÁªÉ 2:4 Á®ÄÁñèÊõø‰ª£ÊñπÊ°àÁõ∏ÂΩìÊàñÊõ¥Â•Ω„ÄÇÊõ¥ÈáçË¶ÅÁöÑÊòØÔºå‰∏é 2:4 Á®ÄÁñèÊÄßÁõ∏ÊØîÔºåV:N:M Á®ÄÁñè Transformer Êèê‰æõ‰∫ÜÊõ¥ÂπøÊ≥õÁöÑÂä†ÈÄüÁ≤æÂ∫¶ÊùÉË°°„ÄÇÊÄª‰ΩìËÄåË®ÄÔºåÊàë‰ª¨ÁöÑÊé¢Á¥¢ÊûÅÂ§ßÂú∞‰øÉËøõ‰∫Ü V:N:M Á®ÄÁñèÊÄß‰Ωú‰∏∫ÊàêÊú¨ÊïèÊÑüÂûãÊé®ÁêÜÂú∫ÊôØ‰∏≠ Transformer ÁöÑÁúüÊ≠£ÊúâÊïàÁöÑÂä†ÈÄüËß£ÂÜ≥ÊñπÊ°à„ÄÇ

##### **A Data-driven Crowd Simulation Framework Integrating Physics-informed Machine Learning with Navigation Potential Fields**
2410.16132v1 by Runkang Guo, Bin Chen, Qi Zhang, Yong Zhao, Xiao Wang, Zhengqiu Zhu

Traditional rule-based physical models are limited by their reliance on
singular physical formulas and parameters, making it difficult to effectively
tackle the intricate tasks associated with crowd simulation. Recent research
has introduced deep learning methods to tackle these issues, but most current
approaches focus primarily on generating pedestrian trajectories, often lacking
interpretability and failing to provide real-time dynamic simulations.To
address the aforementioned issues, we propose a novel data-driven crowd
simulation framework that integrates Physics-informed Machine Learning (PIML)
with navigation potential fields. Our approach leverages the strengths of both
physical models and PIML. Specifically, we design an innovative
Physics-informed Spatio-temporal Graph Convolutional Network (PI-STGCN) as a
data-driven module to predict pedestrian movement trends based on crowd
spatio-temporal data. Additionally, we construct a physical model of navigation
potential fields based on flow field theory to guide pedestrian movements,
thereby reinforcing physical constraints during the simulation. In our
framework, navigation potential fields are dynamically computed and updated
based on the movement trends predicted by the PI-STGCN, while the updated crowd
dynamics, guided by these fields, subsequently feed back into the PI-STGCN.
Comparative experiments on two publicly available large-scale real-world
datasets across five scenes demonstrate that our proposed framework outperforms
existing rule-based methods in accuracy and fidelity. The similarity between
simulated and actual pedestrian trajectories increases by 10.8%, while the
average error is reduced by 4%. Moreover, our framework exhibits greater
adaptability and better interpretability compared to methods that rely solely
on deep learning for trajectory generation.

ÊëòË¶ÅÔºö<paragraph>ÂÇ≥Áµ±ÁöÑÂü∫ÊñºË¶èÂâáÁöÑÁâ©ÁêÜÊ®°ÂûãÂèóÂà∞Â∞çÂñÆ‰∏ÄÁâ©ÁêÜÂÖ¨ÂºèÂíåÂèÉÊï∏ÁöÑ‰æùË≥¥ÊâÄÈôêÔºåÈÄô‰ΩøÂæóÊúâÊïàÊáâÂ∞çËàáÁæ§È´îÊ®°Êì¨Áõ∏ÈóúÁöÑË§áÈõú‰ªªÂãôËÆäÂæóÂõ∞Èõ£„ÄÇÊúÄËøëÁöÑÁ†îÁ©∂ÂºïÂÖ•‰∫ÜÊ∑±Â∫¶Â≠∏ÁøíÊñπÊ≥ï‰æÜËß£Ê±∫ÈÄô‰∫õÂïèÈ°åÔºå‰ΩÜÁõÆÂâçÂ§ßÂ§öÊï∏ÊñπÊ≥ï‰∏ªË¶ÅÈõÜ‰∏≠Âú®ÁîüÊàêË°å‰∫∫ËªåË∑°‰∏äÔºåÂæÄÂæÄÁº∫‰πèÂèØËß£ÈáãÊÄßÔºå‰∏¶‰∏îÁÑ°Ê≥ïÊèê‰æõÂØ¶ÊôÇÁöÑÂãïÊÖãÊ®°Êì¨„ÄÇÁÇ∫‰∫ÜËß£Ê±∫‰∏äËø∞ÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊñ∞Á©éÁöÑÊï∏ÊìöÈ©ÖÂãïÂûãÁæ§È´îÊ®°Êì¨Ê°ÜÊû∂ÔºåË©≤Ê°ÜÊû∂Â∞áÁâ©ÁêÜ‰ø°ÊÅØÊ©üÂô®Â≠∏Áøí (PIML) ËàáÂ∞éËà™Âã¢Â†¥Áõ∏ÁµêÂêà„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÂà©Áî®‰∫ÜÁâ©ÁêÜÊ®°ÂûãÂíå PIML ÁöÑÂÑ™Âã¢„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëË®≠Ë®à‰∫Ü‰∏ÄÂÄãÂâµÊñ∞ÁöÑÁâ©ÁêÜ‰ø°ÊÅØÊôÇÁ©∫ÂúñÂç∑Á©çÁ•ûÁ∂ìÁ∂≤Áµ° (PI-STGCN) ‰ΩúÁÇ∫‰∏ÄÂÄãÊï∏ÊìöÈ©ÖÂãïÊ®°Â°äÔºåÂü∫ÊñºÁæ§È´îÊôÇÁ©∫Êï∏ÊìöÈ†êÊ∏¨Ë°å‰∫∫ÈÅãÂãïË∂®Âã¢„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂü∫ÊñºÊµÅÂ†¥ÁêÜË´ñÊßãÂª∫‰∫Ü‰∏ÄÂÄãÂ∞éËà™Âã¢Â†¥Áâ©ÁêÜÊ®°Âûã‰æÜÊåáÂ∞éË°å‰∫∫ÈÅãÂãïÔºåÂæûËÄåÂä†Âº∑‰∫ÜÊ®°Êì¨ÈÅéÁ®ã‰∏≠ÁöÑÁâ©ÁêÜÁ¥ÑÊùü„ÄÇÂú®ÊàëÂÄëÁöÑÊ°ÜÊû∂‰∏≠ÔºåÂ∞éËà™Âã¢Â†¥ÊòØÊ†πÊìö PI-STGCN È†êÊ∏¨ÁöÑÈÅãÂãïË∂®Âã¢ÂãïÊÖãË®àÁÆóÂíåÊõ¥Êñ∞ÁöÑÔºåËÄåÁî±ÈÄô‰∫õÂ†¥ÂºïÂ∞éÁöÑÊõ¥Êñ∞ÂæåÁöÑÁæ§È´îÂãïÊÖãÈö®ÂæåÂèçÈ•ãÂà∞ PI-STGCN ‰∏≠„ÄÇÂú®‰∫îÂÄãÂ†¥ÊôØ‰∏≠Â∞çÂÖ©ÂÄãÂÖ¨ÈñãÂèØÁî®ÁöÑÂ§ßÂûãÁúüÂØ¶‰∏ñÁïåÊï∏ÊìöÈõÜÈÄ≤Ë°åÁöÑÊØîËºÉÂØ¶È©óË°®ÊòéÔºåÊàëÂÄëÊèêÂá∫ÁöÑÊ°ÜÊû∂Âú®Ê∫ñÁ¢∫ÊÄßÂíå‰øùÁúüÂ∫¶ÊñπÈù¢ÂÑ™ÊñºÁèæÊúâÁöÑÂü∫ÊñºË¶èÂâáÁöÑÊñπÊ≥ï„ÄÇÊ®°Êì¨Ë°å‰∫∫ËªåË∑°ËàáÂØ¶ÈöõË°å‰∫∫ËªåË∑°‰πãÈñìÁöÑÁõ∏‰ººÊÄßÊèêÈ´ò‰∫Ü 10.8%ÔºåËÄåÂπ≥ÂùáË™§Â∑ÆÈôç‰Ωé‰∫Ü 4%„ÄÇÊ≠§Â§ñÔºåËàáÂÉÖ‰æùË≥¥Ê∑±Â∫¶Â≠∏ÁøíÈÄ≤Ë°åËªåË∑°ÁîüÊàêÁöÑÈÇ£‰∫õÊñπÊ≥ïÁõ∏ÊØîÔºåÊàëÂÄëÁöÑÊ°ÜÊû∂Ë°®ÁèæÂá∫Êõ¥È´òÁöÑÈÅ©ÊáâÊÄßÂíåÊõ¥Â•ΩÁöÑÂèØËß£ÈáãÊÄß„ÄÇ</paragraph>

##### **Can Large Audio-Language Models Truly Hear? Tackling Hallucinations with Multi-Task Assessment and Stepwise Audio Reasoning**
2410.16130v1 by Chun-Yi Kuan, Hung-yi Lee

Recent advancements in large audio-language models (LALMs) have shown
impressive capabilities in understanding and reasoning about audio and speech
information. However, these models still face challenges, including
hallucinating non-existent sound events, misidentifying the order of sound
events, and incorrectly attributing sound sources, which undermine their
reliability and real-world application. To systematically evaluate these
issues, we propose three distinct tasks: object existence, temporal order, and
object attribute within audio. These tasks assess the models' comprehension of
critical audio information aspects. Our experimental results reveal limitations
in these fundamental tasks, underscoring the need for better models in
recognizing specific sound events, determining event sequences, and identifying
sound sources. To improve performance in these areas, we introduce a multi-turn
chain-of-thought approach, which demonstrates significantly improved model
performance across the proposed tasks.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÈü≥Ë®äÊ®°Âûã (LALM) ËøëÊúüÁöÑÈÄ≤Â±ïÈ°ØÁ§∫Âá∫Âú®ÁêÜËß£ÂíåÊé®Ë´ñÈü≥Ë®äÂíåË™ûÈü≥Ë≥áË®äÊñπÈù¢ÂÖ∑Êúâ‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑËÉΩÂäõ„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÊ®°Âûã‰ªçÁÑ∂Èù¢Ëá®ÊåëÊà∞ÔºåÂåÖÊã¨Áî¢Áîü‰∏çÂ≠òÂú®ÁöÑËÅ≤Èü≥‰∫ã‰ª∂„ÄÅË™§Ë™çËÅ≤Èü≥‰∫ã‰ª∂ÁöÑÈ†ÜÂ∫èÔºå‰ª•ÂèäÈåØË™§Âú∞Ê≠∏Âõ†ËÅ≤Èü≥‰æÜÊ∫êÔºåÈÄôÊúÉÊêçÂÆ≥ÂÆÉÂÄëÁöÑÂèØÈù†ÊÄßÂíåÂØ¶ÈöõÊáâÁî®„ÄÇÁÇ∫‰∫ÜÁ≥ªÁµ±Âú∞Ë©ï‰º∞ÈÄô‰∫õÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏âÂÄã‰∏çÂêåÁöÑ‰ªªÂãôÔºöÁâ©‰ª∂Â≠òÂú®„ÄÅÊôÇÈñìÈ†ÜÂ∫èÂíåÈü≥Ë®ä‰∏≠ÁöÑÁâ©‰ª∂Â±¨ÊÄß„ÄÇÈÄô‰∫õ‰ªªÂãôË©ï‰º∞Ê®°ÂûãÂ∞çÈóúÈçµÈü≥Ë®äË≥áË®äÈù¢ÂêëÁöÑÁêÜËß£„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÁµêÊûúÊè≠Á§∫‰∫ÜÈÄô‰∫õÂü∫Êú¨‰ªªÂãôÁöÑÈôêÂà∂ÔºåÂº∑Ë™ø‰∫ÜÈúÄË¶ÅÊõ¥Â•ΩÁöÑÊ®°Âûã‰æÜË≠òÂà•ÁâπÂÆöËÅ≤Èü≥‰∫ã‰ª∂„ÄÅÁ¢∫ÂÆö‰∫ã‰ª∂È†ÜÂ∫èÂíåË≠òÂà•ËÅ≤Èü≥‰æÜÊ∫ê„ÄÇÁÇ∫‰∫ÜÊîπÂñÑÈÄô‰∫õÈ†òÂüüÁöÑÊïàËÉΩÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÂ§öËº™ÊÄùËÄÉÈèàÊñπÊ≥ïÔºåË©≤ÊñπÊ≥ïË≠âÊòé‰∫ÜÂú®ÊâÄÊèêÂá∫ÁöÑ‰ªªÂãô‰∏≠Ê®°ÂûãÊïàËÉΩÈ°ØËëóÊèêÂçá„ÄÇ

##### **SMART: Self-learning Meta-strategy Agent for Reasoning Tasks**
2410.16128v1 by Rongxing Liu, Kumar Shridhar, Manish Prajapat, Patrick Xia, Mrinmaya Sachan

Tasks requiring deductive reasoning, especially those involving multiple
steps, often demand adaptive strategies such as intermediate generation of
rationales or programs, as no single approach is universally optimal. While
Language Models (LMs) can enhance their outputs through iterative
self-refinement and strategy adjustments, they frequently fail to apply the
most effective strategy in their first attempt. This inefficiency raises the
question: Can LMs learn to select the optimal strategy in the first attempt,
without a need for refinement? To address this challenge, we introduce SMART
(Self-learning Meta-strategy Agent for Reasoning Tasks), a novel framework that
enables LMs to autonomously learn and select the most effective strategies for
various reasoning tasks. We model the strategy selection process as a Markov
Decision Process and leverage reinforcement learning-driven continuous
self-improvement to allow the model to find the suitable strategy to solve a
given task. Unlike traditional self-refinement methods that rely on multiple
inference passes or external feedback, SMART allows an LM to internalize the
outcomes of its own reasoning processes and adjust its strategy accordingly,
aiming for correct solutions on the first attempt. Our experiments across
various reasoning datasets and with different model architectures demonstrate
that SMART significantly enhances the ability of models to choose optimal
strategies without external guidance (+15 points on the GSM8K dataset). By
achieving higher accuracy with a single inference pass, SMART not only improves
performance but also reduces computational costs for refinement-based
strategies, paving the way for more efficient and intelligent reasoning in LMs.

ÊëòË¶ÅÔºö<paragraph>ÈúÄË¶ÅÊºîÁªéÊé®ÁêÜÁöÑ‰ªªÂä°ÔºåÁâπÂà´ÊòØÊ∂âÂèäÂ§ö‰∏™Ê≠•È™§ÁöÑ‰ªªÂä°ÔºåÈÄöÂ∏∏ÈúÄË¶ÅËá™ÈÄÇÂ∫îÁ≠ñÁï•Ôºå‰æãÂ¶Ç‰∏≠Èó¥ÁîüÊàêÂéüÁêÜÊàñÁ®ãÂ∫èÔºåÂõ†‰∏∫Ê≤°Êúâ‰∏ÄÁßçÊñπÊ≥ïÂú®ÊâÄÊúâÊÉÖÂÜµ‰∏ãÈÉΩÊòØÊúÄ‰ºòÁöÑ„ÄÇËôΩÁÑ∂ËØ≠Ë®ÄÊ®°Âûã (LM) ÂèØ‰ª•ÈÄöËøáËø≠‰ª£Ëá™Êàë‰ºòÂåñÂíåÁ≠ñÁï•Ë∞ÉÊï¥Êù•Â¢ûÂº∫ÂÖ∂ËæìÂá∫Ôºå‰ΩÜÂÆÉ‰ª¨ÁªèÂ∏∏Êó†Ê≥ïÂú®Á¨¨‰∏ÄÊ¨°Â∞ùËØï‰∏≠Â∫îÁî®ÊúÄÊúâÊïàÁöÑÁ≠ñÁï•„ÄÇËøôÁßç‰ΩéÊïàÁéáÊèêÂá∫‰∫Ü‰∏Ä‰∏™ÈóÆÈ¢òÔºöLM ËÉΩÂê¶Âú®Á¨¨‰∏ÄÊ¨°Â∞ùËØï‰∏≠Â≠¶‰ºöÈÄâÊã©ÊúÄ‰Ω≥Á≠ñÁï•ÔºåËÄå‰∏çÈúÄË¶Å‰ºòÂåñÔºü‰∏∫‰∫ÜÂ∫îÂØπËøô‰∏ÄÊåëÊàòÔºåÊàë‰ª¨ÂºïÂÖ•‰∫Ü SMARTÔºàÊé®ÁêÜ‰ªªÂä°ÁöÑËá™Â≠¶‰π†ÂÖÉÁ≠ñÁï•‰ª£ÁêÜÔºâÔºåËøôÊòØ‰∏Ä‰∏™Êñ∞Ê°ÜÊû∂Ôºå‰Ωø LM ËÉΩÂ§üËá™‰∏ªÂ≠¶‰π†ÂíåÈÄâÊã©ÂêÑÁßçÊé®ÁêÜ‰ªªÂä°ÁöÑÊúÄÊúâÊïàÁ≠ñÁï•„ÄÇÊàë‰ª¨Â∞ÜÁ≠ñÁï•ÈÄâÊã©ËøáÁ®ãÂª∫Ê®°‰∏∫È©¨Â∞îÂèØÂ§´ÂÜ≥Á≠ñËøáÁ®ãÔºåÂπ∂Âà©Áî®Âº∫ÂåñÂ≠¶‰π†È©±Âä®ÁöÑÊåÅÁª≠Ëá™ÊàëÊîπËøõÔºåËÆ©Ê®°ÂûãÊâæÂà∞Ëß£ÂÜ≥ÁªôÂÆö‰ªªÂä°ÁöÑÂêàÈÄÇÁ≠ñÁï•„ÄÇ‰∏é‰æùËµñ‰∫éÂ§öÊ¨°Êé®ÁêÜ‰º†ÈÄíÊàñÂ§ñÈÉ®ÂèçÈ¶àÁöÑ‰º†ÁªüËá™Êàë‰ºòÂåñÊñπÊ≥ï‰∏çÂêåÔºåSMART ÂÖÅËÆ∏ LM ÂÜÖÂåñÂÖ∂Ëá™Ë∫´Êé®ÁêÜËøáÁ®ãÁöÑÁªìÊûúÔºåÂπ∂Áõ∏Â∫îÂú∞Ë∞ÉÊï¥ÂÖ∂Á≠ñÁï•ÔºåÊó®Âú®Âú®Á¨¨‰∏ÄÊ¨°Â∞ùËØï‰∏≠ÊâæÂà∞Ê≠£Á°ÆÁöÑËß£ÂÜ≥ÊñπÊ°à„ÄÇÊàë‰ª¨Âú®ÂêÑÁßçÊé®ÁêÜÊï∞ÊçÆÈõÜÂíå‰∏çÂêåÊ®°ÂûãÊû∂ÊûÑ‰∏äÁöÑÂÆûÈ™åË°®ÊòéÔºåSMART ÊòæÁùÄÂ¢ûÂº∫‰∫ÜÊ®°ÂûãÂú®Ê≤°ÊúâÂ§ñÈÉ®ÊåáÂØºÁöÑÊÉÖÂÜµ‰∏ãÈÄâÊã©ÊúÄ‰Ω≥Á≠ñÁï•ÁöÑËÉΩÂäõÔºàÂú® GSM8K Êï∞ÊçÆÈõÜ‰∏äÊèêÈ´ò‰∫Ü 15 ÂàÜÔºâ„ÄÇÈÄöËøáÂçïÊ¨°Êé®ÁêÜ‰º†ÈÄíÂÆûÁé∞Êõ¥È´òÁöÑÂáÜÁ°ÆÊÄßÔºåSMART ‰∏ç‰ªÖÊèêÈ´ò‰∫ÜÊÄßËÉΩÔºåËÄå‰∏îËøòÈôç‰Ωé‰∫ÜÂü∫‰∫é‰ºòÂåñÁ≠ñÁï•ÁöÑËÆ°ÁÆóÊàêÊú¨Ôºå‰∏∫ LM ‰∏≠Êõ¥ÊúâÊïàÂíåÊô∫ËÉΩÁöÑÊé®ÁêÜÈì∫Âπ≥‰∫ÜÈÅìË∑Ø„ÄÇ</paragraph>

##### **SeaDAG: Semi-autoregressive Diffusion for Conditional Directed Acyclic Graph Generation**
2410.16119v1 by Xinyi Zhou, Xing Li, Yingzhao Lian, Yiwen Wang, Lei Chen, Mingxuan Yuan, Jianye Hao, Guangyong Chen, Pheng Ann Heng

We introduce SeaDAG, a semi-autoregressive diffusion model for conditional
generation of Directed Acyclic Graphs (DAGs). Considering their inherent
layer-wise structure, we simulate layer-wise autoregressive generation by
designing different denoising speed for different layers. Unlike conventional
autoregressive generation that lacks a global graph structure view, our method
maintains a complete graph structure at each diffusion step, enabling
operations such as property control that require the full graph structure.
Leveraging this capability, we evaluate the DAG properties during training by
employing a graph property decoder. We explicitly train the model to learn
graph conditioning with a condition loss, which enhances the diffusion model's
capacity to generate graphs that are both realistic and aligned with specified
properties. We evaluate our method on two representative conditional DAG
generation tasks: (1) circuit generation from truth tables, where precise DAG
structures are crucial for realizing circuit functionality, and (2) molecule
generation based on quantum properties. Our approach demonstrates promising
results, generating high-quality and realistic DAGs that closely align with
given conditions.

ÊëòË¶ÅÔºöÊàëÂÄë‰ªãÁ¥π SeaDAGÔºå‰∏ÄÁ®ÆÁî®ÊñºÊúâÂêëÁÑ°Áí∞Âúñ (DAG) Ê¢ù‰ª∂ÁîüÊàêÁöÑÂçäËá™Ëø¥Ê≠∏Êì¥Êï£Ê®°Âûã„ÄÇËÄÉÊÖÆÂà∞ÂÆÉÂÄëÂõ∫ÊúâÁöÑÈÄêÂ±§ÁµêÊßãÔºåÊàëÂÄëÈÄèÈÅéÁÇ∫‰∏çÂêåÂ±§Ë®≠Ë®à‰∏çÂêåÁöÑÂéªÂô™ÈÄüÂ∫¶Ôºå‰æÜÊ®°Êì¨ÈÄêÂ±§Ëá™Ëø¥Ê≠∏ÁîüÊàê„ÄÇËàáÁº∫‰πèÂÖ®Â±ÄÂúñÁµêÊßãËßÄÈªûÁöÑÂÇ≥Áµ±Ëá™Ëø¥Ê≠∏ÁîüÊàê‰∏çÂêåÔºåÊàëÂÄëÁöÑÊñπÊ≥ïÂú®ÊØèÂÄãÊì¥Êï£Ê≠•È©ü‰∏≠Á∂≠Ë≠∑‰∏ÄÂÄãÂÆåÊï¥ÁöÑÂúñÁµêÊßãÔºåÂæûËÄåËÉΩÂ§†Âü∑Ë°åÈúÄË¶ÅÂÆåÊï¥ÂúñÁµêÊßãÁöÑÈÅãÁÆóÔºå‰æãÂ¶ÇÂ±¨ÊÄßÊéßÂà∂„ÄÇÂà©Áî®Ê≠§ÂäüËÉΩÔºåÊàëÂÄëÂú®Ë®ìÁ∑¥ÊúüÈñìÈÄèÈÅé‰ΩøÁî®ÂúñÂ±¨ÊÄßËß£Á¢ºÂô®‰æÜË©ï‰º∞ DAG Â±¨ÊÄß„ÄÇÊàëÂÄëÊòéÁ¢∫Ë®ìÁ∑¥Ê®°ÂûãÔºå‰ª•Ê¢ù‰ª∂ÊêçÂ§±Â≠∏ÁøíÂúñÊ¢ù‰ª∂ÔºåÈÄôÂ¢ûÂº∑‰∫ÜÊì¥Êï£Ê®°ÂûãÁîüÊàêÊó¢ÁúüÂØ¶ÂèàËàáÊåáÂÆöÂ±¨ÊÄßÂ∞çÈΩäÁöÑÂúñÂΩ¢ÁöÑËÉΩÂäõ„ÄÇÊàëÂÄëÂú®ÂÖ©ÂÄãÂÖ∑‰ª£Ë°®ÊÄßÁöÑÊ¢ù‰ª∂ DAG ÁîüÊàê‰ªªÂãô‰∏äË©ï‰º∞ÊàëÂÄëÁöÑÊñπÊ≥ïÔºö(1) ÂæûÁúüÂÄºË°®‰∏≠ÁîüÊàêÈõªË∑ØÔºåÂÖ∂‰∏≠Á≤æÁ¢∫ÁöÑ DAG ÁµêÊßãÂ∞çÊñºÂØ¶ÁèæÈõªË∑ØÂäüËÉΩËá≥ÈóúÈáçË¶ÅÔºå‰ª•Âèä (2) Âü∫ÊñºÈáèÂ≠êÂ±¨ÊÄßÁöÑÂàÜÂ≠êÁîüÊàê„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÂ±ïÁ§∫‰∫ÜÊúâÂ∏åÊúõÁöÑÁµêÊûúÔºåÁîüÊàê‰∫ÜËàáÁµ¶ÂÆöÊ¢ù‰ª∂Á∑äÂØÜÂ∞çÈΩäÁöÑÈ´òÂìÅË≥™‰∏îÁúüÂØ¶ÁöÑ DAG„ÄÇ

##### **Multimodal Flare Forecasting with Deep Learning**
2410.16116v1 by Gr√©goire Francisco, Sabrina Guastavino, Teresa Barata, Jo√£o Fernandes, Dario Del Moro

Solar flare forecasting mainly relies on photospheric magnetograms and
associated physical features to predict forthcoming flares. However, it is
believed that flare initiation mechanisms often originate in the chromosphere
and the lower corona. In this study, we employ deep learning as a purely
data-driven approach to compare the predictive capabilities of chromospheric
and coronal UV and EUV emissions across different wavelengths with those of
photospheric line-of-sight magnetograms. Our findings indicate that individual
EUV wavelengths can provide discriminatory power comparable or better to that
of line-of-sight magnetograms. Moreover, we identify simple multimodal neural
network architectures that consistently outperform single-input models, showing
complementarity between the flare precursors that can be extracted from the
distinct layers of the solar atmosphere. To mitigate potential biases from
known misattributions in Active Region flare catalogs, our models are trained
and evaluated using full-disk images and a comprehensive flare event catalog at
the full-disk level. We introduce a deep-learning architecture suited for
extracting temporal features from full-disk videos.

ÊëòË¶ÅÔºöÂ§™ÈôΩËÄÄÊñëÈ†êÊ∏¨‰∏ªË¶Å‰æùË≥¥ÂÖâÁêÉÁ£ÅÂÉèÂÑÄÂíåÁõ∏ÈóúÁâ©ÁêÜÁâπÂæµ‰æÜÈ†êÊ∏¨Âç≥Â∞áÁôºÁîüÁöÑËÄÄÊñë„ÄÇÁÑ∂ËÄåÔºå‰∫∫ÂÄëË™çÁÇ∫ËÄÄÊñëÂºïÁôºÊ©üÂà∂ÈÄöÂ∏∏Ëµ∑Ê∫êÊñºËâ≤ÁêÉÂíåÊó•ÂÜï‰∏ãÂ±§„ÄÇÂú®Êú¨Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëÊé°Áî®Ê∑±Â∫¶Â≠∏Áøí‰ΩúÁÇ∫Á¥îÁ≤πÁöÑË≥áÊñôÈ©ÖÂãïÊñπÊ≥ïÔºåÊØîËºÉ‰∏çÂêåÊ≥¢Èï∑ÁöÑËâ≤ÁêÉÂíåÊó•ÂÜïÁ¥´Â§ñÁ∑öÂíåÊ•µÁ¥´Â§ñÁ∑öÁôºÂ∞ÑÁöÑÈ†êÊ∏¨ËÉΩÂäõÔºå‰ª•ÂèäÂÖâÁêÉË¶ñÁ∑öÁ£ÅÂÉèÂÑÄÁöÑÈ†êÊ∏¨ËÉΩÂäõ„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúË°®ÊòéÔºåÂÄãÂà•Ê•µÁ¥´Â§ñÁ∑öÊ≥¢Èï∑ÂèØ‰ª•Êèê‰æõËàáË¶ñÁ∑öÁ£ÅÂÉèÂÑÄÁõ∏Áï∂ÊàñÊõ¥Â•ΩÁöÑÂçÄÂàÜËÉΩÂäõ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëË≠òÂà•Âá∫Á∞°ÂñÆÁöÑÂ§öÊ®°ÂºèÁ•ûÁ∂ìÁ∂≤Ë∑ØÊû∂ÊßãÔºåÂÖ∂ÂßãÁµÇÂÑ™ÊñºÂñÆËº∏ÂÖ•Ê®°ÂûãÔºåÈ°ØÁ§∫‰∫ÜÂèØ‰ª•ÂæûÂ§™ÈôΩÂ§ßÊ∞£‰∏çÂêåÂ±§‰∏≠ÊèêÂèñÁöÑËÄÄÊñëÂâçÂÖÜ‰πãÈñìÁöÑ‰∫íË£úÊÄß„ÄÇÁÇ∫‰∫ÜÊ∏õËºïÂ∑≤Áü•Ê¥ªÂãïÂçÄËÄÄÊñëÁõÆÈåÑ‰∏≠ÈåØË™§Ê≠∏Âõ†ÁöÑÊΩõÂú®ÂÅèÂ∑ÆÔºåÊàëÂÄëÁöÑÊ®°Âûã‰ΩøÁî®ÂÖ®ÂúìÁõ§ÂΩ±ÂÉèÂíåÂÖ®ÂúìÁõ§Â±§Á¥öÁöÑÁ∂úÂêàËÄÄÊñë‰∫ã‰ª∂ÁõÆÈåÑÈÄ≤Ë°åË®ìÁ∑¥ÂíåË©ï‰º∞„ÄÇÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÁ®ÆÊ∑±Â∫¶Â≠∏ÁøíÊû∂ÊßãÔºåÈÅ©Áî®ÊñºÂæûÂÖ®ÂúìÁõ§ÂΩ±Áâá‰∏≠ÊèêÂèñÊôÇÈñìÁâπÂæµ„ÄÇ

##### **Do LLMs write like humans? Variation in grammatical and rhetorical styles**
2410.16107v1 by Alex Reinhart, David West Brown, Ben Markey, Michael Laudenbach, Kachatad Pantusen, Ronald Yurko, Gordon Weinberg

Large language models (LLMs) are capable of writing grammatical text that
follows instructions, answers questions, and solves problems. As they have
advanced, it has become difficult to distinguish their output from
human-written text. While past research has found some differences in surface
features such as word choice and punctuation, and developed classifiers to
detect LLM output, none has studied the rhetorical styles of LLMs.
  Using several variants of Llama 3 and GPT-4o, we construct two parallel
corpora of human- and LLM-written texts from common prompts. Using Douglas
Biber's set of lexical, grammatical, and rhetorical features, we identify
systematic differences between LLMs and humans and between different LLMs.
These differences persist when moving from smaller models to larger ones, and
are larger for instruction-tuned models than base models. This demonstrates
that despite their advanced abilities, LLMs struggle to match human styles, and
hence more advanced linguistic features can detect patterns in their behavior
not previously recognized.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ËÉΩÊí∞ÂØ´Á¨¶ÂêàÊñáÊ≥ïË¶èÁØÑÁöÑÊñáÂ≠óÔºåÈÅµÂæ™ÊåáÁ§∫„ÄÅÂõûÁ≠îÂïèÈ°åÂíåËß£Ê±∫ÂïèÈ°å„ÄÇÈö®ËëóÂÆÉÂÄëÁöÑÈÄ≤Ê≠•ÔºåË¶ÅÂçÄÂàÜÂÆÉÂÄëÁöÑËº∏Âá∫Âíå‰∫∫È°ûÊí∞ÂØ´ÁöÑÊñáÂ≠óÂ∑≤ËÆäÂæóÂõ∞Èõ£„ÄÇÈõñÁÑ∂ÈÅéÂéªÁöÑÁ†îÁ©∂ÁôºÁèæ‰∫Ü‰∏Ä‰∫õË°®Â±§ÁâπÂæµÁöÑÂ∑ÆÁï∞Ôºå‰æãÂ¶ÇË©ûÂΩôÈÅ∏ÊìáÂíåÊ®ôÈªûÁ¨¶ËôüÔºå‰∏¶ÈñãÁôº‰∫ÜÂàÜÈ°ûÂô®‰æÜÂÅµÊ∏¨ LLM Ëº∏Âá∫Ôºå‰ΩÜÊ≤íÊúâÁ†îÁ©∂Êé¢Ë®é LLM ÁöÑ‰øÆËæ≠È¢®Ê†º„ÄÇ
ÊàëÂÄë‰ΩøÁî® Llama 3 Âíå GPT-4o ÁöÑÂπæÂÄãËÆäÈ´îÔºåÂæûÂ∏∏Ë¶ãÊèêÁ§∫‰∏≠Âª∫Êßã‰∫ÜÂÖ©ÁµÑ‰∫∫È°ûÂíå LLM Êí∞ÂØ´ÁöÑÂπ≥Ë°åË™ûÊñôÂ∫´„ÄÇ‰ΩøÁî® Douglas Biber ÁöÑ‰∏ÄÁµÑË©ûÂΩô„ÄÅË™ûÊ≥ïÂíå‰øÆËæ≠ÁâπÂæµÔºåÊàëÂÄëËæ®Ë≠òÂá∫ LLM Âíå‰∫∫È°û‰πãÈñì‰ª•Âèä‰∏çÂêå LLM ‰πãÈñìÁöÑÁ≥ªÁµ±ÊÄßÂ∑ÆÁï∞„ÄÇÈÄô‰∫õÂ∑ÆÁï∞Âú®ÂæûËºÉÂ∞èÁöÑÊ®°ÂûãËΩâÁßªÂà∞ËºÉÂ§ßÁöÑÊ®°ÂûãÊôÇ‰ªçÁÑ∂Â≠òÂú®Ôºå‰∏¶‰∏îÂ∞çÊñºÁ∂ìÈÅéÊåá‰ª§Ë™øÊï¥ÁöÑÊ®°Âûã‰æÜË™™ÊØîÂü∫Á§éÊ®°ÂûãÊõ¥Â§ß„ÄÇÈÄôË°®ÊòéÂÑòÁÆ° LLM ÂÖ∑ÊúâÂÖàÈÄ≤ÁöÑËÉΩÂäõÔºå‰ΩÜÂÆÉÂÄë‰ªçÈõ£‰ª•ÂåπÈÖç‰∫∫È°ûÁöÑÈ¢®Ê†ºÔºåÂõ†Ê≠§Êõ¥ÂÖàÈÄ≤ÁöÑË™ûË®ÄÁâπÂæµÂèØ‰ª•ÂÅµÊ∏¨Âà∞ÂÆÉÂÄëË°åÁÇ∫‰∏≠‰ª•ÂâçÁÑ°Ê≥ïËæ®Ë≠òÁöÑÊ®°Âºè„ÄÇ

##### **Addressing Spectral Bias of Deep Neural Networks by Multi-Grade Deep Learning**
2410.16105v1 by Ronglong Fang, Yuesheng Xu

Deep neural networks (DNNs) suffer from the spectral bias, wherein DNNs
typically exhibit a tendency to prioritize the learning of lower-frequency
components of a function, struggling to capture its high-frequency features.
This paper is to address this issue. Notice that a function having only low
frequency components may be well-represented by a shallow neural network (SNN),
a network having only a few layers. By observing that composition of low
frequency functions can effectively approximate a high-frequency function, we
propose to learn a function containing high-frequency components by composing
several SNNs, each of which learns certain low-frequency information from the
given data. We implement the proposed idea by exploiting the multi-grade deep
learning (MGDL) model, a recently introduced model that trains a DNN
incrementally, grade by grade, a current grade learning from the residue of the
previous grade only an SNN composed with the SNNs trained in the preceding
grades as features. We apply MGDL to synthetic, manifold, colored images, and
MNIST datasets, all characterized by presence of high-frequency features. Our
study reveals that MGDL excels at representing functions containing
high-frequency information. Specifically, the neural networks learned in each
grade adeptly capture some low-frequency information, allowing their
compositions with SNNs learned in the previous grades effectively representing
the high-frequency features. Our experimental results underscore the efficacy
of MGDL in addressing the spectral bias inherent in DNNs. By leveraging MGDL,
we offer insights into overcoming spectral bias limitation of DNNs, thereby
enhancing the performance and applicability of deep learning models in tasks
requiring the representation of high-frequency information. This study confirms
that the proposed method offers a promising solution to address the spectral
bias of DNNs.

ÊëòË¶ÅÔºöÊ∑±Â∫¶Á•ûÁªèÁ∂≤Ë∑Ø (DNN) Â≠òÂú®È†ªË≠úÂÅèÂ∑ÆÔºåÂÖ∂‰∏≠ DNN ÈÄöÂ∏∏Ë°®ÁèæÂá∫ÂÑ™ÂÖàÂ≠∏ÁøíÂáΩÊï∏ÁöÑ‰ΩéÈ†ªÁéáÁµÑÊàêÈÉ®ÂàÜÁöÑÂÇæÂêëÔºåÈõ£‰ª•Êì∑ÂèñÂÖ∂È´òÈ†ªÁéáÁâπÂæµ„ÄÇÊú¨ÊñáÊó®Âú®Ëß£Ê±∫Ê≠§ÂïèÈ°å„ÄÇË´ãÊ≥®ÊÑèÔºåÂÉÖÂÖ∑Êúâ‰ΩéÈ†ªÁéáÁµÑÊàêÈÉ®ÂàÜÁöÑÂáΩÊï∏ÂèØ‰ª•Áî®Ê∑∫Â±§Á•ûÁ∂ìÁ∂≤Ë∑Ø (SNN)ÔºàÂÉÖÊúâÂ∞ëÊï∏Â±§ÁöÑÁ∂≤Ë∑ØÔºâÂæàÂ•ΩÂú∞Ë°®Á§∫„ÄÇÈÄèÈÅéËßÄÂØü‰ΩéÈ†ªÁéáÂáΩÊï∏ÁöÑÁµÑÂêàÂèØ‰ª•ÊúâÊïàÈÄºËøëÈ´òÈ†ªÁéáÂáΩÊï∏ÔºåÊàëÂÄëÂª∫Ë≠∞ÈÄèÈÅéÁµÑÂêàÂ§öÂÄã SNN ‰æÜÂ≠∏ÁøíÂåÖÂê´È´òÈ†ªÁéáÁµÑÊàêÈÉ®ÂàÜÁöÑÂáΩÊï∏ÔºåÊØèÂÄã SNN ÈÉΩÂæûÁµ¶ÂÆöÁöÑË≥áÊñô‰∏≠Â≠∏ÁøíÊüê‰∫õ‰ΩéÈ†ªÁéáË≥áË®ä„ÄÇÊàëÂÄëÈÄèÈÅéÂà©Áî®Â§öÁ¥öÊ∑±Â∫¶Â≠∏Áøí (MGDL) Ê®°Âûã‰æÜÂØ¶‰ΩúÊâÄÊèêÂá∫ÁöÑÊßãÊÉ≥ÔºåMGDL ÊòØ‰∏ÄÂÄãÊúÄËøëÊé®Âá∫ÁöÑÊ®°ÂûãÔºåÂÆÉÊúÉÈÄêÊ≠•Ë®ìÁ∑¥ DNNÔºåÈÄêÁ¥öÈÄ≤Ë°åÔºåÁõÆÂâçÁöÑÁ¥öÂà•ÂÉÖÂæûÂâç‰∏ÄÂÄãÁ¥öÂà•ÁöÑÊÆòÂ∑ÆÂ≠∏Áøí‰∏ÄÂÄã SNNÔºå‰∏¶Â∞áÂÖ∂ËàáÂú®ÂÖàÂâçÁ¥öÂà•Ë®ìÁ∑¥ÁöÑ SNN ÁµÑÂêàÊàêÁâπÂæµ„ÄÇÊàëÂÄëÂ∞á MGDL ÊáâÁî®ÊñºÂêàÊàê„ÄÅÊµÅÂΩ¢„ÄÅÂΩ©Ëâ≤ÂΩ±ÂÉèÂíå MNIST Ë≥áÊñôÈõÜÔºåÈÄô‰∫õË≥áÊñôÈõÜÁöÑÁâπÂæµÊòØÂ≠òÂú®È´òÈ†ªÁéáÁâπÂæµ„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂È°ØÁ§∫ÔºåMGDL ÊìÖÈï∑Ë°®Á§∫ÂåÖÂê´È´òÈ†ªÁéáË≥áË®äÁöÑÂáΩÊï∏„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÂú®ÊØèÂÄãÁ¥öÂà•‰∏≠Â≠∏ÁøíÁöÑÁ•ûÁ∂ìÁ∂≤Ë∑ØÈÉΩËÉΩÈùàÊ¥ªÂú∞Êì∑Âèñ‰∏Ä‰∫õ‰ΩéÈ†ªÁéáË≥áË®äÔºåËÆìÂÖ∂ËàáÂÖàÂâçÁ¥öÂà•‰∏≠Â≠∏ÁøíÁöÑ SNN ÁµÑÂêàÊúâÊïàÂú∞Ë°®Á§∫È´òÈ†ªÁéáÁâπÂæµ„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÁµêÊûúÂº∑Ë™ø‰∫Ü MGDL Âú®Ëß£Ê±∫ DNN ‰∏≠Âõ∫ÊúâÁöÑÈ†ªË≠úÂÅèÂ∑ÆÊñπÈù¢ÁöÑÊïàËÉΩ„ÄÇÈÄèÈÅéÂà©Áî® MGDLÔºåÊàëÂÄëÊèê‰æõ‰∫ÜÂÖãÊúç DNN ÁöÑÈ†ªË≠úÂÅèÂ∑ÆÈôêÂà∂ÁöÑË¶ãËß£ÔºåÂæûËÄåÂ¢ûÂº∑Ê∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÂú®ÈúÄË¶ÅË°®Á§∫È´òÈ†ªÁéáË≥áË®äÁöÑ‰ªªÂãô‰∏≠ÁöÑÊïàËÉΩÂíåÈÅ©Áî®ÊÄß„ÄÇÊú¨Á†îÁ©∂Ë≠âÂØ¶ÔºåÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÊèê‰æõ‰∫Ü‰∏ÄÂÄãÊúâÂ∏åÊúõÁöÑËß£Ê±∫ÊñπÊ°à‰æÜËß£Ê±∫ DNN ÁöÑÈ†ªË≠úÂÅèÂ∑Æ„ÄÇ

##### **Neural Quantum Propagators for Driven-Dissipative Quantum Dynamics**
2410.16091v1 by Jiaji Zhang, Carlos L. Benavides-Riveros, Lipeng Chen

Describing the dynamics of strong-laser driven open quantum systems is a very
challenging task that requires the solution of highly involved equations of
motion. While machine learning techniques are being applied with some success
to simulate the time evolution of individual quantum states, their use to
approximate time-dependent operators (that can evolve various states) remains
largely unexplored. In this work, we develop driven neural quantum propagators
(NQP), a universal neural network framework that solves driven-dissipative
quantum dynamics by approximating propagators rather than wavefunctions or
density matrices. NQP can handle arbitrary initial quantum states, adapt to
various external fields, and simulate long-time dynamics, even when trained on
far shorter time windows. Furthermore, by appropriately configuring the
external fields, our trained NQP can be transferred to systems governed by
different Hamiltonians. We demonstrate the effectiveness of our approach by
studying the spin-boson and the three-state transition Gamma models.

ÊëòË¶ÅÔºöÊèèËø∞Âº∑Èõ∑Â∞ÑÈ©ÖÂãïÈñãÊîæÈáèÂ≠êÁ≥ªÁµ±ÁöÑÂãïÂäõÂ≠∏ÊòØ‰∏ÄÂÄãÈùûÂ∏∏ÂÖ∑ÊúâÊåëÊà∞ÊÄßÁöÑ‰ªªÂãôÔºåÈúÄË¶ÅÊ±ÇËß£È´òÂ∫¶Ë§áÈõúÁöÑÈÅãÂãïÊñπÁ®ãÂºè„ÄÇÂÑòÁÆ°Ê©üÂô®Â≠∏ÁøíÊäÄË°ìÂ∑≤ÊàêÂäüÊáâÁî®ÊñºÊ®°Êì¨ÂÄãÂà•ÈáèÂ≠êÊÖãÁöÑÊôÇÈñìÊºîÂåñÔºå‰ΩÜÂÖ∂Áî®ÊñºËøë‰ººÊôÇÈñìÁõ∏ÈóúÁÆóÁ¨¶ÔºàÂèØÊºîÂåñÂêÑÁ®ÆÊÖãÔºâÁöÑÁî®ÈÄî‰ªçÊú™Ë¢´Âª£Ê≥õÊé¢Ë®é„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÈñãÁôº‰∫ÜÈ©ÖÂãïÁ•ûÁ∂ìÈáèÂ≠êÂÇ≥Êí≠Âô® (NQP)ÔºåÈÄôÊòØ‰∏ÄÁ®ÆÈÄöÁî®ÁöÑÁ•ûÁ∂ìÁ∂≤Ë∑ØÊû∂ÊßãÔºåÈÄèÈÅéËøë‰ººÂÇ≥Êí≠Âô®ÔºåËÄå‰∏çÊòØÊ≥¢ÂáΩÊï∏ÊàñÂØÜÂ∫¶Áü©Èô£Ôºå‰æÜÊ±ÇËß£È©ÖÂãïËÄóÊï£ÈáèÂ≠êÂãïÂäõÂ≠∏„ÄÇNQP ÂèØ‰ª•ËôïÁêÜ‰ªªÊÑèÂàùÂßãÈáèÂ≠êÊÖãÔºåÈÅ©ÊáâÂêÑÁ®ÆÂ§ñÂ†¥Ôºå‰∏¶Ê®°Êì¨Èï∑ÊôÇÈñìÂãïÂäõÂ≠∏ÔºåÂç≥‰ΩøÊòØÂú®ÈÅ†Áü≠ÊôÇÈñìÁ™ó‰∏äË®ìÁ∑¥ÊôÇ‰πüÊòØÂ¶ÇÊ≠§„ÄÇÊ≠§Â§ñÔºåÈÄèÈÅéÈÅ©Áï∂Âú∞ÈÖçÁΩÆÂ§ñÂ†¥ÔºåÊàëÂÄëË®ìÁ∑¥Â•ΩÁöÑ NQP ÂèØ‰ª•ËΩâÁßªÂà∞Âèó‰∏çÂêåÂìàÂØÜÈ†ìÈáèÊîØÈÖçÁöÑÁ≥ªÁµ±„ÄÇÊàëÂÄëÈÄèÈÅéÁ†îÁ©∂Ëá™ÊóãÁéªËâ≤Â≠êÂíå‰∏âÊÖãËΩâÊèõ Gamma Ê®°Âûã‰æÜË≠âÊòéÊàëÂÄëÊñπÊ≥ïÁöÑÊúâÊïàÊÄß„ÄÇ

##### **Analysing the Residual Stream of Language Models Under Knowledge Conflicts**
2410.16090v1 by Yu Zhao, Xiaotang Du, Giwon Hong, Aryo Pradipta Gema, Alessio Devoto, Hongru Wang, Xuanli He, Kam-Fai Wong, Pasquale Minervini

Large language models (LLMs) can store a significant amount of factual
knowledge in their parameters. However, their parametric knowledge may conflict
with the information provided in the context. Such conflicts can lead to
undesirable model behaviour, such as reliance on outdated or incorrect
information. In this work, we investigate whether LLMs can identify knowledge
conflicts and whether it is possible to know which source of knowledge the
model will rely on by analysing the residual stream of the LLM. Through probing
tasks, we find that LLMs can internally register the signal of knowledge
conflict in the residual stream, which can be accurately detected by probing
the intermediate model activations. This allows us to detect conflicts within
the residual stream before generating the answers without modifying the input
or model parameters. Moreover, we find that the residual stream shows
significantly different patterns when the model relies on contextual knowledge
versus parametric knowledge to resolve conflicts. This pattern can be employed
to estimate the behaviour of LLMs when conflict happens and prevent unexpected
answers before producing the answers. Our analysis offers insights into how
LLMs internally manage knowledge conflicts and provides a foundation for
developing methods to control the knowledge selection processes.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂèØ‰ª•Â∞áÂ§ßÈáèÁöÑÂØ¶ÈöõÁü•Ë≠òÂÑ≤Â≠òÂú®ÂÖ∂ÂèÉÊï∏‰∏≠„ÄÇÁÑ∂ËÄåÔºåÂÆÉÂÄëÁöÑÂèÉÊï∏ÂåñÁü•Ë≠òÂèØËÉΩËàáÊñá‰∏≠Êèê‰æõÁöÑË≥áË®äÁõ∏Ë°ùÁ™Å„ÄÇÊ≠§È°ûË°ùÁ™ÅÂèØËÉΩÊúÉÂ∞éËá¥‰∏çÁêÜÊÉ≥ÁöÑÊ®°ÂûãË°åÁÇ∫Ôºå‰æãÂ¶Ç‰æùË≥¥ÊñºÈÅéÊôÇÊàñ‰∏çÊ≠£Á¢∫ÁöÑË≥áË®ä„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊé¢Ë®é LLM ÊòØÂê¶ËÉΩË≠òÂà•Áü•Ë≠òË°ùÁ™ÅÔºå‰ª•ÂèäÊòØÂê¶ÂèØ‰ª•ÈÄèÈÅéÂàÜÊûê LLM ÁöÑÊÆòÂ∑ÆÊµÅ‰æÜÂæóÁü•Ê®°ÂûãÂ∞á‰æùË≥¥ÊñºÂì™ÂÄãÁü•Ë≠ò‰æÜÊ∫ê„ÄÇÈÄèÈÅéÊé¢Ê∏¨‰ªªÂãôÔºåÊàëÂÄëÁôºÁèæ LLM ËÉΩÂú®ÊÆòÂ∑ÆÊµÅ‰∏≠ÂÖßÈÉ®Ë®ªÂÜäÁü•Ë≠òË°ùÁ™ÅË®äËôüÔºåËÄåÈÄôËÉΩÈÄèÈÅéÊé¢Ê∏¨‰∏≠ÈñìÊ®°ÂûãÁöÑÊøÄÊ¥ª‰æÜÊ∫ñÁ¢∫Âú∞ÂÅµÊ∏¨„ÄÇÈÄôËÆìÊàëÂÄëÂæó‰ª•Âú®Áî¢ÁîüÁ≠îÊ°à‰πãÂâçÂÅµÊ∏¨ÊÆòÂ∑ÆÊµÅ‰∏≠ÁöÑË°ùÁ™ÅÔºåËÄåÁÑ°ÈúÄ‰øÆÊîπËº∏ÂÖ•ÊàñÊ®°ÂûãÂèÉÊï∏„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁôºÁèæÁï∂Ê®°Âûã‰æùË≥¥ÊñºËÑàÁµ°Áü•Ë≠òËàáÂèÉÊï∏ÂåñÁü•Ë≠ò‰æÜËß£Ê±∫Ë°ùÁ™ÅÊôÇÔºåÊÆòÂ∑ÆÊµÅÊúÉÈ°ØÁ§∫Âá∫È°ØËëó‰∏çÂêåÁöÑÊ®°Âºè„ÄÇÊ≠§Ê®°ÂºèÂèØÁî®ÊñºÈ†êÊ∏¨ LLM Âú®ÁôºÁîüË°ùÁ™ÅÊôÇÁöÑË°åÁÇ∫Ôºå‰∏¶Âú®Áî¢ÁîüÁ≠îÊ°à‰πãÂâçÈò≤Ê≠¢Âá∫ÁèæÊÑèÂ§ñÁöÑÁ≠îÊ°à„ÄÇÊàëÂÄëÁöÑÂàÜÊûêÊèê‰æõ‰∫Ü LLM Â¶Ç‰ΩïÂú®ÂÖßÈÉ®ÁÆ°ÁêÜÁü•Ë≠òË°ùÁ™ÅÁöÑË¶ãËß£Ôºå‰∏¶ÁÇ∫ÈñãÁôºÊéßÂà∂Áü•Ë≠òÈÅ∏ÊìáÁ®ãÂ∫èÁöÑÊñπÊ≥ïÂ•†ÂÆö‰∫ÜÂü∫Á§é„ÄÇ

##### **Multi-Sensor Fusion for UAV Classification Based on Feature Maps of Image and Radar Data**
2410.16089v1 by Nikos Sakellariou, Antonios Lalas, Konstantinos Votis, Dimitrios Tzovaras

The unique cost, flexibility, speed, and efficiency of modern UAVs make them
an attractive choice in many applications in contemporary society. This,
however, causes an ever-increasing number of reported malicious or accidental
incidents, rendering the need for the development of UAV detection and
classification mechanisms essential. We propose a methodology for developing a
system that fuses already processed multi-sensor data into a new Deep Neural
Network to increase its classification accuracy towards UAV detection. The DNN
model fuses high-level features extracted from individual object detection and
classification models associated with thermal, optronic, and radar data.
Additionally, emphasis is given to the model's Convolutional Neural Network
(CNN) based architecture that combines the features of the three sensor
modalities by stacking the extracted image features of the thermal and optronic
sensor achieving higher classification accuracy than each sensor alone.

ÊëòË¶ÅÔºöÁèæ‰ª£ÁÑ°‰∫∫Ê©üÁöÑÁç®ÁâπÊàêÊú¨„ÄÅÈùàÊ¥ªÊÄß„ÄÅÈÄüÂ∫¶ÂíåÊïàÁéá‰ΩøÂÖ∂ÊàêÁÇ∫Áï∂‰ª£Á§æÊúÉË®±Â§öÊáâÁî®‰∏≠ÁöÑË™ò‰∫∫ÈÅ∏Êìá„ÄÇÁÑ∂ËÄåÔºåÈÄôÂ∞éËá¥ÊÉ°ÊÑèÊàñÊÑèÂ§ñ‰∫ã‰ª∂ÁöÑÂ†±ÂëäÊï∏Èáè‰∏çÊñ∑Â¢ûÂä†Ôºå‰ΩøÂæóÈñãÁôºÁÑ°‰∫∫Ê©üÊ™¢Ê∏¨ÂíåÂàÜÈ°ûÊ©üÂà∂ÁöÑÈúÄÊ±ÇËÆäÂæóËá≥ÈóúÈáçË¶Å„ÄÇÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñπÊ≥ïÔºåÁî®ÊñºÈñãÁôº‰∏ÄÂÄãÁ≥ªÁµ±ÔºåÂ∞áÂ∑≤ËôïÁêÜÁöÑÂ§öÂÇ≥ÊÑüÂô®Êï∏ÊìöËûçÂêàÂà∞‰∏ÄÂÄãÊñ∞ÁöÑÊ∑±Â∫¶Á•ûÁ∂ìÁ∂≤Ë∑Ø‰∏≠Ôºå‰ª•ÊèêÈ´òÂÖ∂ÁÑ°‰∫∫Ê©üÊ™¢Ê∏¨ÁöÑÂàÜÈ°ûÊ∫ñÁ¢∫ÊÄß„ÄÇDNN Ê®°ÂûãËûçÂêà‰∫ÜÂæûËàáÁÜ±„ÄÅÂÖâÈõªÂíåÈõ∑ÈÅîÊï∏ÊìöÁõ∏ÈóúÁöÑÂÄãÂà•Â∞çË±°Ê™¢Ê∏¨ÂíåÂàÜÈ°ûÊ®°Âûã‰∏≠ÊèêÂèñÁöÑÈ´òÁ¥öÁâπÂæµ„ÄÇÊ≠§Â§ñÔºåÈáçÈªûÊîæÂú®Âü∫ÊñºÂç∑Á©çÁ•ûÁ∂ìÁ∂≤Ë∑Ø (CNN) ÁöÑÊ®°ÂûãÊû∂Êßã‰∏äÔºåË©≤Êû∂ÊßãÈÄöÈÅéÂ†ÜÁñäÁÜ±ÂíåÂÖâÈõªÂÇ≥ÊÑüÂô®ÁöÑÊèêÂèñÂúñÂÉèÁâπÂæµÔºåÂ∞á‰∏âÁ®ÆÂÇ≥ÊÑüÂô®Ê®°ÂºèÁöÑÁâπÂæµÁµêÂêàËµ∑‰æÜÔºåÂæûËÄåÊØîÂñÆÂÄãÂÇ≥ÊÑüÂô®ÂØ¶ÁèæÊõ¥È´òÁöÑÂàÜÈ°ûÊ∫ñÁ¢∫ÊÄß„ÄÇ

##### **Fine-Tuning LLMs for Reliable Medical Question-Answering Services**
2410.16088v1 by Ali Anaissi, Ali Braytee, Junaid Akram

We present an advanced approach to medical question-answering (QA) services,
using fine-tuned Large Language Models (LLMs) to improve the accuracy and
reliability of healthcare information. Our study focuses on optimizing models
like LLaMA-2 and Mistral, which have shown great promise in delivering precise,
reliable medical answers. By leveraging comprehensive datasets, we applied
fine-tuning techniques such as rsDoRA+ and ReRAG. rsDoRA+ enhances model
performance through a combination of decomposed model weights, varied learning
rates for low-rank matrices, and rank stabilization, leading to improved
efficiency. ReRAG, which integrates retrieval on demand and question rewriting,
further refines the accuracy of the responses. This approach enables healthcare
providers to access fast, dependable information, aiding in more efficient
decision-making and fostering greater patient trust. Our work highlights the
potential of fine-tuned LLMs to significantly improve the quality and
accessibility of medical information services, ultimately contributing to
better healthcare outcomes for all.

ÊëòË¶ÅÔºöÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂÖàÈÄ≤ÁöÑÈÜ´ÁôÇÂïèÁ≠î (QA) ÊúçÂãôÊñπÊ≥ïÔºå
‰ΩøÁî®ÂæÆË™øÈÅéÁöÑÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰æÜÊèêÈ´òÈÜ´ÁôÇ‰øùÂÅ•Ë≥áË®äÁöÑÊ∫ñÁ¢∫ÊÄßÂíå
ÂèØÈù†ÊÄß„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂Â∞àÊ≥®ÊñºÂÑ™ÂåñÊ®°ÂûãÔºå‰æãÂ¶Ç LLaMA-2 Âíå MistralÔºåÈÄô‰∫õÊ®°ÂûãÂú®Êèê‰æõÁ≤æÁ¢∫„ÄÅ
ÂèØÈù†ÁöÑÈÜ´ÁôÇÁ≠îÊ°àÊñπÈù¢Â∑≤Â±ïÁèæÂá∫Â∑®Â§ßÁöÑÂâçÊôØ„ÄÇÈÄèÈÅéÂà©Áî®ÂÖ®Èù¢ÁöÑË≥áÊñôÈõÜÔºåÊàëÂÄëÊáâÁî®
‰∫ÜÂæÆË™øÊäÄË°ìÔºå‰æãÂ¶Ç rsDoRA+ Âíå ReRAG„ÄÇrsDoRA+ ÈÄèÈÅéÂàÜËß£Ê®°ÂûãÊ¨äÈáç„ÄÅÈáùÂ∞ç‰ΩéÈöéÁü©Èô£‰ΩøÁî®‰∏çÂêåÁöÑÂ≠∏Áøí
ÁéáÔºå‰ª•ÂèäÁß©Á©©ÂÆöÂåñ‰æÜÂ¢ûÂº∑Ê®°ÂûãÊïàËÉΩÔºåÂæûËÄåÊèêÈ´òÊïàÁéá„ÄÇReRAG Êï¥Âêà‰∫Ü‰æùÈúÄÊ±ÇÊ™¢Á¥¢ÂíåÂïèÈ°åÈáçÂØ´Ôºå
ÈÄ≤‰∏ÄÊ≠•Á≤æÁÖâ‰∫ÜÂõûÊáâÁöÑÊ∫ñÁ¢∫ÊÄß„ÄÇÊ≠§ÊñπÊ≥ïËÆìÈÜ´ÁôÇ‰øùÂÅ•Êèê‰æõËÄÖËÉΩÂ§†Â≠òÂèñÂø´ÈÄü„ÄÅÂèØÈù†ÁöÑË≥áË®äÔºåÂçîÂä©Êõ¥ÊúâÊïàÁéáÂú∞ÈÄ≤Ë°å
Ê±∫Á≠ñÂà∂ÂÆö‰∏¶Â¢ûÈÄ≤ÁóÖÊÇ£ÁöÑ‰ø°‰ªª„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÈáçÈªûË™™Êòé‰∫ÜÂæÆË™ø LLM ÁöÑÊΩõÂäõÔºåËÉΩÂ§ßÂπÖÊîπÂñÑÈÜ´ÁôÇË≥áË®äÊúçÂãôÁöÑÂìÅË≥™Âíå
ÂèØËøëÊÄßÔºåÊúÄÁµÇÁÇ∫ÊâÄÊúâ‰∫∫Â∏∂‰æÜÊõ¥Â•ΩÁöÑÈÜ´ÁôÇ‰øùÂÅ•ÊàêÊûú„ÄÇ

##### **Critical Example Mining for Vehicle Trajectory Prediction using Flow-based Generative Models**
2410.16083v1 by Zhezhang Ding, Huijing Zhao

Precise trajectory prediction in complex driving scenarios is essential for
autonomous vehicles. In practice, different driving scenarios present varying
levels of difficulty for trajectory prediction models. However, most existing
research focuses on the average precision of prediction results, while ignoring
the underlying distribution of the input scenarios. This paper proposes a
critical example mining method that utilizes a data-driven approach to estimate
the rareness of the trajectories. By combining the rareness estimation of
observations with whole trajectories, the proposed method effectively
identifies a subset of data that is relatively hard to predict BEFORE feeding
them to a specific prediction model. The experimental results show that the
mined subset has higher prediction error when applied to different downstream
prediction models, which reaches +108.1% error (greater than two times compared
to the average on dataset) when mining 5% samples. Further analysis indicates
that the mined critical examples include uncommon cases such as sudden brake
and cancelled lane-change, which helps to better understand and improve the
performance of prediction models.

ÊëòË¶ÅÔºöÂú®Ë§áÈõúÁöÑÈßïÈßõÊÉÖÂ¢É‰∏≠ÈÄ≤Ë°åÁ≤æÊ∫ñÁöÑËªåË∑°È†êÊ∏¨Â∞çÊñºËá™ÈßïËªäËÄåË®ÄËá≥ÈóúÈáçË¶Å„ÄÇÂú®ÂØ¶Âãô‰∏äÔºå‰∏çÂêåÁöÑÈßïÈßõÊÉÖÂ¢ÉÊúÉÁÇ∫ËªåË∑°È†êÊ∏¨Ê®°ÂûãÂ∏∂‰æÜ‰∏çÂêåÁöÑÈõ£Â∫¶„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÁöÑÁ†îÁ©∂Â§ßÂ§öÈóúÊ≥®È†êÊ∏¨ÁµêÊûúÁöÑÂπ≥ÂùáÊ∫ñÁ¢∫Â∫¶ÔºåËÄåÂøΩÁï•‰∫ÜËº∏ÂÖ•ÊÉÖÂ¢ÉÁöÑÂ∫ïÂ±§ÂàÜ‰Ωà„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÈóúÈçµÁØÑ‰æãÊåñÊéòÊñπÊ≥ïÔºåË©≤ÊñπÊ≥ïÂà©Áî®Ë≥áÊñôÈ©ÖÂãïÁöÑÊñπÊ≥ï‰æÜ‰º∞Ë®àËªåË∑°ÁöÑÁ®ÄÊúâÊÄß„ÄÇÈÄèÈÅéÁµêÂêàËßÄÊ∏¨ÁöÑÁ®ÄÊúâÊÄß‰º∞Ë®àËàáÊï¥ÂÄãËªåË∑°ÔºåÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÊúâÊïàÂú∞Ë≠òÂà•‰∫Ü‰∏ÄÁµÑÁõ∏Â∞çÈõ£‰ª•È†êÊ∏¨ÁöÑË≥áÊñôÂ≠êÈõÜÔºåÂú®Â∞áÂÖ∂Êèê‰æõÁµ¶ÁâπÂÆöÁöÑÈ†êÊ∏¨Ê®°Âûã‰πãÂâç„ÄÇÂØ¶È©óÁµêÊûúÈ°ØÁ§∫ÔºåÊåñÊéòÂá∫ÁöÑÂ≠êÈõÜÂú®ÊáâÁî®Êñº‰∏çÂêåÁöÑ‰∏ãÊ∏∏È†êÊ∏¨Ê®°ÂûãÊôÇÂÖ∑ÊúâËºÉÈ´òÁöÑÈ†êÊ∏¨Ë™§Â∑ÆÔºåÂú®ÊåñÊéò 5% Ê®£Êú¨ÊôÇÈÅîÂà∞ +108.1% ÁöÑË™§Â∑ÆÔºàÊØîË≥áÊñôÈõÜ‰∏äÁöÑÂπ≥ÂùáÂÄºÈ´òÂá∫ÂÖ©ÂÄç‰ª•‰∏äÔºâ„ÄÇÈÄ≤‰∏ÄÊ≠•ÁöÑÂàÜÊûêË°®ÊòéÔºåÊåñÊéòÂá∫ÁöÑÈóúÈçµÁØÑ‰æãÂåÖÊã¨Á™ÅÁÑ∂ÁÖûËªäÂíåÂèñÊ∂àÊèõËªäÈÅìÁ≠â‰∏çÂ∏∏Ë¶ãÁöÑÊ°à‰æãÔºåÈÄôÊúâÂä©ÊñºÊõ¥Â•ΩÂú∞‰∫ÜËß£ÂíåÊîπÂñÑÈ†êÊ∏¨Ê®°ÂûãÁöÑÊïàËÉΩ„ÄÇ

##### **CartesianMoE: Boosting Knowledge Sharing among Experts via Cartesian Product Routing in Mixture-of-Experts**
2410.16077v2 by Zhenpeng Su, Xing Wu, Zijia Lin, Yizhe Xiong, Minxuan Lv, Guangyuan Ma, Hui Chen, Songlin Hu, Guiguang Ding

Large language models (LLM) have been attracting much attention from the
community recently, due to their remarkable performance in all kinds of
downstream tasks. According to the well-known scaling law, scaling up a dense
LLM enhances its capabilities, but also significantly increases the
computational complexity. Mixture-of-Experts (MoE) models address that by
allowing the model size to grow without substantially raising training or
inference costs. Yet MoE models face challenges regarding knowledge sharing
among experts, making their performance somehow sensitive to routing accuracy.
To tackle that, previous works introduced shared experts and combined their
outputs with those of the top $K$ routed experts in an ``addition'' manner. In
this paper, inspired by collective matrix factorization to learn shared
knowledge among data, we propose CartesianMoE, which implements more effective
knowledge sharing among experts in more like a ``multiplication'' manner.
Extensive experimental results indicate that CartesianMoE outperforms previous
MoE models for building LLMs, in terms of both perplexity and downstream task
performance. And we also find that CartesianMoE achieves better expert routing
robustness.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ËøëÊúüÂª£ÂèóÁ§æÁæ§ÈóúÊ≥®ÔºåÂõ†ÁÇ∫ÂÆÉÂÄëÂú®ÂêÑÁ®Æ‰∏ãÊ∏∏‰ªªÂãô‰∏≠Ë°®ÁèæÂÇëÂá∫„ÄÇÊ†πÊìöËëóÂêçÁöÑË¶èÊ®°ÂÆöÂæãÔºåÊì¥Â§ßÂØÜÈõÜ LLM ËÉΩÂ¢ûÂº∑ÂÖ∂ÂäüËÉΩÔºå‰ΩÜ‰πüÂ§ßÂπÖÂ¢ûÂä†ÈÅãÁÆóË§áÈõúÂ∫¶„ÄÇÂ∞àÂÆ∂Ê∑∑Âêà (MoE) Ê®°ÂûãÈÄèÈÅéÂÖÅË®±Ê®°ÂûãË¶èÊ®°Êì¥Â§ßËÄå‰∏çÊúÉÂ§ßÂπÖÂ¢ûÂä†Ë®ìÁ∑¥ÊàñÊé®Ë´ñÊàêÊú¨‰æÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°å„ÄÇÁÑ∂ËÄåÔºåMoE Ê®°ÂûãÂú®Â∞àÂÆ∂‰πãÈñìÁöÑÁü•Ë≠òÂÖ±‰∫´ÊñπÈù¢Èù¢Ëá®ÊåëÊà∞Ôºå‰ΩøÂæóÂÆÉÂÄëÁöÑÊïàËÉΩÂ§öÂ∞ëÊúÉÂèóÂà∞Ë∑ØÁî±Á≤æÊ∫ñÂ∫¶ÁöÑÂΩ±Èüø„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÂÖàÂâçÁöÑÁ†îÁ©∂ÂºïÂÖ•‰∫ÜÂÖ±‰∫´Â∞àÂÆ∂Ôºå‰∏¶‰ª•„ÄåÂä†Ê≥ï„ÄçÁöÑÊñπÂºèÂ∞á‰ªñÂÄëÁöÑËº∏Âá∫ËàáË∑ØÁî±Ââç $K$ ÂêçÂ∞àÂÆ∂ÁöÑËº∏Âá∫ÁµêÂêà„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂèóÂà∞ÈõÜÈ´îÁü©Èô£ÂàÜËß£ÁöÑÂïüÁôºÔºåÂæûË≥áÊñô‰∏≠Â≠∏ÁøíÂÖ±‰∫´Áü•Ë≠òÔºå‰∏¶ÊèêÂá∫Á¨õÂç°ÂÖí MoEÔºåÂÆÉ‰ª•Êõ¥ÂÉèÊòØ„Äå‰πòÊ≥ï„ÄçÁöÑÊñπÂºèÂú®Â∞àÂÆ∂‰πãÈñìÂØ¶‰ΩúÊõ¥ÊúâÊïàÁöÑÁü•Ë≠òÂÖ±‰∫´„ÄÇÂª£Ê≥õÁöÑÂØ¶È©óÁµêÊûúË°®ÊòéÔºåÁ¨õÂç°ÂÖí MoE Âú®Âõ∞ÊÉëÂ∫¶Âíå‰∏ãÊ∏∏‰ªªÂãôÊïàËÉΩÊñπÈù¢ÈÉΩÂÑ™ÊñºÂÖàÂâçÁöÑ MoE Ê®°ÂûãÔºåÁî®ÊñºÂª∫Êßã LLM„ÄÇÊàëÂÄë‰πüÁôºÁèæÁ¨õÂç°ÂÖí MoE ÈÅîÂà∞Êõ¥Â•ΩÁöÑÂ∞àÂÆ∂Ë∑ØÁî±Á©©ÂÅ•ÊÄß„ÄÇ

##### **On-Device LLMs for SMEs: Challenges and Opportunities**
2410.16070v2 by Jeremy Stephen Gabriel Yee, Pai Chet Ng, Zhengkui Wang, Ian McLoughlin, Aik Beng Ng, Simon See

This paper presents a systematic review of the infrastructure requirements
for deploying Large Language Models (LLMs) on-device within the context of
small and medium-sized enterprises (SMEs), focusing on both hardware and
software perspectives. From the hardware viewpoint, we discuss the utilization
of processing units like GPUs and TPUs, efficient memory and storage solutions,
and strategies for effective deployment, addressing the challenges of limited
computational resources typical in SME settings. From the software perspective,
we explore framework compatibility, operating system optimization, and the use
of specialized libraries tailored for resource-constrained environments. The
review is structured to first identify the unique challenges faced by SMEs in
deploying LLMs on-device, followed by an exploration of the opportunities that
both hardware innovations and software adaptations offer to overcome these
obstacles. Such a structured review provides practical insights, contributing
significantly to the community by enhancing the technological resilience of
SMEs in integrating LLMs.

ÊëòË¶ÅÔºöÊú¨ÊñáÈáùÂ∞ç‰∏≠Â∞èÂûã‰ºÅÊ•≠ (SME) ÁöÑÊÉÖÂ¢ÉÔºåÁ≥ªÁµ±ÊÄßÊé¢Ë®é‰∫ÜÂú®Ë£ùÁΩÆ‰∏äÈÉ®ÁΩ≤Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÂü∫Á§éË®≠ÊñΩÈúÄÊ±ÇÔºåÈáçÈªûÂú®Á°¨È´îÂíåËªüÈ´îÁöÑËßÄÈªû„ÄÇÂæûÁ°¨È´îËßÄÈªû‰æÜÁúãÔºåÊàëÂÄëÊé¢Ë®éËôïÁêÜÂñÆÂÖÉÔºàÂ¶Ç GPU Âíå TPUÔºâÁöÑÂà©Áî®„ÄÅÈ´òÊïàËÉΩË®òÊÜ∂È´îÂíåÂÑ≤Â≠òËß£Ê±∫ÊñπÊ°àÔºå‰ª•ÂèäÊúâÊïàÈÉ®ÁΩ≤Á≠ñÁï•Ôºå‰ª•Ëß£Ê±∫ SME Áí∞Â¢É‰∏≠Â∏∏Ë¶ãÁöÑÈÅãÁÆóË≥áÊ∫êÂèóÈôêÊåëÊà∞„ÄÇÂæûËªüÈ´îËßÄÈªû‰æÜÁúãÔºåÊàëÂÄëÊé¢Ë®éÊû∂ÊßãÁõ∏ÂÆπÊÄß„ÄÅ‰ΩúÊ•≠Á≥ªÁµ±ÊúÄ‰Ω≥ÂåñÔºå‰ª•Âèä‰ΩøÁî®Â∞àÈñÄÁÇ∫Ë≥áÊ∫êÂèóÈôêÁí∞Â¢ÉÈáèË∫´ÊâìÈÄ†ÁöÑÂáΩÂºèÂ∫´„ÄÇÊú¨Êé¢Ë®éÁöÑÊû∂ÊßãÈ¶ñÂÖàÊâæÂá∫ SME Âú®Ë£ùÁΩÆ‰∏äÈÉ®ÁΩ≤ LLM ÊôÇÈù¢Ëá®ÁöÑÁç®ÁâπÊåëÊà∞ÔºåÊé•ËëóÊé¢Ë®éÁ°¨È´îÂâµÊñ∞ÂíåËªüÈ´îË™øÊï¥ÊâÄÊèê‰æõÁöÑÊ©üÊúÉÔºå‰ª•ÂÖãÊúçÈÄô‰∫õÈöúÁ§ô„ÄÇÈÄôÊ®£‰∏ÄÂÄãÁµêÊßãÂåñÁöÑÊé¢Ë®éÊèê‰æõ‰∫ÜÂØ¶Áî®ÁöÑË¶ãËß£ÔºåÈÄèÈÅéÊèêÂçá SME Êï¥Âêà LLM ÁöÑÊäÄË°ìÈüåÊÄßÔºåÁÇ∫Á§æÁæ§ÂÅöÂá∫ÈáçÂ§ßË≤¢Áçª„ÄÇ

##### **Rolling the DICE on Idiomaticity: How LLMs Fail to Grasp Context**
2410.16069v1 by Maggie Mi, Aline Villavicencio, Nafise Sadat Moosavi

Human processing of idioms relies on understanding the contextual sentences
in which idioms occur, as well as language-intrinsic features such as frequency
and speaker-intrinsic factors like familiarity. While LLMs have shown high
performance on idiomaticity detection tasks, this success may be attributed to
reasoning shortcuts in existing datasets. To this end, we construct a novel,
controlled contrastive dataset designed to test whether LLMs can effectively
use context to disambiguate idiomatic meaning. Additionally, we explore how
collocational frequency and sentence probability influence model performance.
Our findings reveal that LLMs often fail to resolve idiomaticity when it is
required to attend to the surrounding context, and that models perform better
on sentences that have higher likelihood. The collocational frequency of
expressions also impacts performance. We make our code and dataset publicly
available.

ÊëòË¶ÅÔºö‰∫∫È°ûÂ∞çÊÖ£Áî®Ë™ûÁöÑËôïÁêÜ‰æùË≥¥ÊñºÁêÜËß£ÊÖ£Áî®Ë™ûÂá∫ÁèæÁöÑË™ûÂ¢ÉÂè•Â≠êÔºå‰ª•ÂèäË™ûË®ÄÂÖßÂú®ÁâπÂæµÔºà‰æãÂ¶ÇÈ†ªÁéáÔºâÂíåË™™Ë©±ËÄÖÂÖßÂú®Âõ†Á¥†Ôºà‰æãÂ¶ÇÁÜüÊÇâÂ∫¶Ôºâ„ÄÇÈõñÁÑ∂Â§ßË™ûË®ÄÊ®°ÂûãÂú®ÊÖ£Áî®Ë™ûÊ™¢Ê∏¨‰ªªÂãô‰∏äË°®ÁèæÂá∫È´òÊÄßËÉΩÔºå‰ΩÜÈÄôÁ®ÆÊàêÂäüÂèØËÉΩÊòØÊ≠∏Âõ†ÊñºÁèæÊúâË≥áÊñôÈõÜ‰∏≠ÁöÑÊé®ÁêÜÊç∑Âæë„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÊßãÂª∫‰∫Ü‰∏ÄÂÄãÊñ∞Á©é„ÄÅÂèóÊéßÁöÑÂ∞çÊØîË≥áÊñôÈõÜÔºåÊó®Âú®Ê∏¨Ë©¶Â§ßË™ûË®ÄÊ®°ÂûãÊòØÂê¶ËÉΩÊúâÊïà‰ΩøÁî®Ë™ûÂ¢É‰æÜÊ∂àÈô§ÊÖ£Áî®Ë™ûÂê´Áæ©ÁöÑÊ≠ßÁæ©„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊé¢Ë®é‰∫ÜÊê≠ÈÖçÈ†ªÁéáÂíåÂè•Â≠êÊ©üÁéáÂ¶Ç‰ΩïÂΩ±ÈüøÊ®°ÂûãÊïàËÉΩ„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÈ°ØÁ§∫ÔºåÁï∂ÈúÄË¶ÅÈóúÊ≥®Âë®ÂúçË™ûÂ¢ÉÊôÇÔºåÂ§ßË™ûË®ÄÊ®°ÂûãÂ∏∏Â∏∏ÁÑ°Ê≥ïËß£Ê±∫ÊÖ£Áî®Ë™ûÔºåËÄå‰∏îÊ®°ÂûãÂú®Ê©üÁéáËºÉÈ´òÁöÑÂè•Â≠ê‰∏≠Ë°®ÁèæÂæóÊõ¥Â•Ω„ÄÇË°®ÈÅîÂºèÁöÑÊê≠ÈÖçÈ†ªÁéá‰πüÂΩ±ÈüøÊïàËÉΩ„ÄÇÊàëÂÄëÂÖ¨ÈñãÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÂíåË≥áÊñôÈõÜ„ÄÇ

##### **Integrated Image-Text Based on Semi-supervised Learning for Small Sample Instance Segmentation**
2410.16063v1 by Ruting Chi, Zhiyi Huang, Yuexing Han

Small sample instance segmentation is a very challenging task, and many
existing methods follow the training strategy of meta-learning which pre-train
models on support set and fine-tune on query set. The pre-training phase, which
is highly task related, requires a significant amount of additional training
time and the selection of datasets with close proximity to ensure
effectiveness. The article proposes a novel small sample instance segmentation
solution from the perspective of maximizing the utilization of existing
information without increasing annotation burden and training costs. The
proposed method designs two modules to address the problems encountered in
small sample instance segmentation. First, it helps the model fully utilize
unlabeled data by learning to generate pseudo labels, increasing the number of
available samples. Second, by integrating the features of text and image, more
accurate classification results can be obtained. These two modules are suitable
for box-free and box-dependent frameworks. In the way, the proposed method not
only improves the performance of small sample instance segmentation, but also
greatly reduce reliance on pre-training. We have conducted experiments in three
datasets from different scenes: on land, underwater and under microscope. As
evidenced by our experiments, integrated image-text corrects the confidence of
classification, and pseudo labels help the model obtain preciser masks. All the
results demonstrate the effectiveness and superiority of our method.

ÊëòË¶ÅÔºöÂ∞èÊ†∑Êú¨ÂÆû‰æãÂàÜÂâ≤ÊòØ‰∏ÄÈ°πÊûÅÂÖ∑ÊåëÊàòÊÄßÁöÑ‰ªªÂä°ÔºåËÆ∏Â§öÁé∞ÊúâÊñπÊ≥ïÈÅµÂæ™ÂÖÉÂ≠¶‰π†ÁöÑËÆ≠ÁªÉÁ≠ñÁï•ÔºåÂç≥Âú®ÊîØÊåÅÈõÜ‰∏äÈ¢ÑËÆ≠ÁªÉÊ®°ÂûãÂπ∂Âú®Êü•ËØ¢ÈõÜ‰∏äËøõË°åÂæÆË∞É„ÄÇ‰∏é‰ªªÂä°È´òÂ∫¶Áõ∏ÂÖ≥ÁöÑÈ¢ÑËÆ≠ÁªÉÈò∂ÊÆµÈúÄË¶ÅÂ§ßÈáèÁöÑÈ¢ùÂ§ñËÆ≠ÁªÉÊó∂Èó¥ÔºåÂπ∂‰∏îÈúÄË¶ÅÈÄâÊã©‰∏éÊï∞ÊçÆÈõÜÂØÜÂàáÁõ∏ÂÖ≥ÁöÑÁ°Æ‰øùÊúâÊïàÊÄß„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞È¢ñÁöÑÂ∞èÊ†∑Êú¨ÂÆû‰æãÂàÜÂâ≤Ëß£ÂÜ≥ÊñπÊ°àÔºå‰ªéÊúÄÂ§ßÂåñÂà©Áî®Áé∞Êúâ‰ø°ÊÅØËÄå‰∏çÂ¢ûÂä†Ê≥®ÈáäË¥üÊãÖÂíåËÆ≠ÁªÉÊàêÊú¨ÁöÑËßíÂ∫¶Âá∫Âèë„ÄÇÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïËÆæËÆ°‰∫Ü‰∏§‰∏™Ê®°ÂùóÊù•Ëß£ÂÜ≥Â∞èÊ†∑Êú¨ÂÆû‰æãÂàÜÂâ≤‰∏≠ÈÅáÂà∞ÁöÑÈóÆÈ¢ò„ÄÇÈ¶ñÂÖàÔºåÂÆÉÈÄöËøáÂ≠¶‰π†ÁîüÊàê‰º™Ê†áÁ≠æÊù•Â∏ÆÂä©Ê®°ÂûãÂÖÖÂàÜÂà©Áî®Êú™Ê†áËÆ∞Êï∞ÊçÆÔºå‰ªéËÄåÂ¢ûÂä†ÂèØÁî®Ê†∑Êú¨ÁöÑÊï∞Èáè„ÄÇÂÖ∂Ê¨°ÔºåÈÄöËøáÊï¥ÂêàÊñáÊú¨ÂíåÂõæÂÉèÁöÑÁâπÂæÅÔºåÂèØ‰ª•Ëé∑ÂæóÊõ¥ÂáÜÁ°ÆÁöÑÂàÜÁ±ªÁªìÊûú„ÄÇËøô‰∏§‰∏™Ê®°ÂùóÈÄÇÁî®‰∫éÊó†Ê°ÜÂíå‰æùËµñÊ°ÜÁöÑÊ°ÜÊû∂„ÄÇÈÄöËøáËøôÁßçÊñπÂºèÔºåÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ï‰∏ç‰ªÖÊèêÈ´ò‰∫ÜÂ∞èÊ†∑Êú¨ÂÆû‰æãÂàÜÂâ≤ÁöÑÊÄßËÉΩÔºåËÄå‰∏îÊûÅÂ§ßÂú∞ÂáèÂ∞ë‰∫ÜÂØπÈ¢ÑËÆ≠ÁªÉÁöÑ‰æùËµñ„ÄÇÊàë‰ª¨Âú®Êù•Ëá™‰∏çÂêåÂú∫ÊôØÁöÑ‰∏â‰∏™Êï∞ÊçÆÈõÜ‰∏äËøõË°å‰∫ÜÂÆûÈ™åÔºöÈôÜÂú∞„ÄÅÊ∞¥‰∏ãÂíåÊòæÂæÆÈïú‰∏ã„ÄÇÊ≠£Â¶ÇÊàë‰ª¨ÁöÑÂÆûÈ™åÊâÄËØÅÊòéÁöÑÔºåÈõÜÊàêÁöÑÂõæÂÉèÊñáÊú¨Á∫†Ê≠£‰∫ÜÂàÜÁ±ªÁöÑÁΩÆ‰ø°Â∫¶Ôºå‰º™Ê†áÁ≠æÂ∏ÆÂä©Ê®°ÂûãËé∑Âæó‰∫ÜÊõ¥Á≤æÁ°ÆÁöÑÊé©Á†Å„ÄÇÊâÄÊúâÁªìÊûúÈÉΩËØÅÊòé‰∫ÜÊàë‰ª¨ÊñπÊ≥ïÁöÑÊúâÊïàÊÄßÂíå‰ºòË∂äÊÄß„ÄÇ

##### **Surprise! Uniform Information Density Isn't the Whole Story: Predicting Surprisal Contours in Long-form Discourse**
2410.16062v1 by Eleftheria Tsipidi, Franz Nowak, Ryan Cotterell, Ethan Wilcox, Mario Giulianelli, Alex Warstadt

The Uniform Information Density (UID) hypothesis posits that speakers tend to
distribute information evenly across linguistic units to achieve efficient
communication. Of course, information rate in texts and discourses is not
perfectly uniform. While these fluctuations can be viewed as theoretically
uninteresting noise on top of a uniform target, another explanation is that UID
is not the only functional pressure regulating information content in a
language. Speakers may also seek to maintain interest, adhere to writing
conventions, and build compelling arguments. In this paper, we propose one such
functional pressure; namely that speakers modulate information rate based on
location within a hierarchically-structured model of discourse. We term this
the Structured Context Hypothesis and test it by predicting the surprisal
contours of naturally occurring discourses extracted from large language models
using predictors derived from discourse structure. We find that hierarchical
predictors are significant predictors of a discourse's information contour and
that deeply nested hierarchical predictors are more predictive than shallow
ones. This work takes an initial step beyond UID to propose testable hypotheses
for why the information rate fluctuates in predictable ways

ÊëòË¶ÅÔºöÂùáÂåÄ‰ø°ÊÅØÂØÜÂ∫¶ (UID) ÂÅáËÆæËÆ§‰∏∫ËØ¥ËØùËÄÖÂÄæÂêë‰∫éÂ∞Ü‰ø°ÊÅØÂùáÂåÄÂàÜÂ∏ÉÂú®ËØ≠Ë®ÄÂçï‰Ωç‰∏≠Ôºå‰ª•ÂÆûÁé∞ÊúâÊïàÁöÑÊ≤üÈÄö„ÄÇÂΩìÁÑ∂ÔºåÊñáÊú¨ÂíåËØùËØ≠‰∏≠ÁöÑ‰ø°ÊÅØÁéáÂπ∂‰∏çÊòØÂÆåÂÖ®ÂùáÂåÄÁöÑ„ÄÇËôΩÁÑ∂Ëøô‰∫õÊ≥¢Âä®ÂèØ‰ª•Ë¢´ËßÜ‰∏∫ÂùáÂåÄÁõÆÊ†á‰πã‰∏äÁöÑÁêÜËÆ∫‰∏äÊó†Ë∂£ÁöÑÂô™Èü≥Ôºå‰ΩÜÂè¶‰∏ÄÁßçËß£ÈáäÊòØ UID Âπ∂‰∏çÊòØÂîØ‰∏ÄË∞ÉËäÇËØ≠Ë®Ä‰∏≠‰ø°ÊÅØÂÜÖÂÆπÁöÑÂäüËÉΩÂéãÂäõ„ÄÇËØ¥ËØùËÄÖËøòÂèØËÉΩÂØªÊ±Ç‰øùÊåÅÂÖ¥Ë∂£„ÄÅÈÅµÂÆàÂÜô‰ΩúÊÉØ‰æãÂπ∂ÊûÑÂª∫ÊúâËØ¥ÊúçÂäõÁöÑËÆ∫ÊçÆ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏Ä‰∏™ËøôÊ†∑ÁöÑÂäüËÉΩÂéãÂäõÔºõÂç≥ËØ¥ËØùËÄÖÊ†πÊçÆÂàÜÂ±ÇÁªìÊûÑÁöÑËØùËØ≠Ê®°Âûã‰∏≠ÁöÑ‰ΩçÁΩÆÊù•Ë∞ÉËäÇ‰ø°ÊÅØÁéá„ÄÇÊàë‰ª¨Áß∞‰πã‰∏∫ÁªìÊûÑÂåñ‰∏ä‰∏ãÊñáÂÅáËÆæÔºåÂπ∂ÈÄöËøáÈ¢ÑÊµã‰ªéÂ§ßÂûãËØ≠Ë®ÄÊ®°Âûã‰∏≠ÊèêÂèñÁöÑËá™ÁÑ∂ÂèëÁîüÁöÑËØùËØ≠ÁöÑÊÑèÂ§ñËΩÆÂªìÊù•ÂØπÂÖ∂ËøõË°åÊµãËØïÔºåËøô‰∫õÈ¢ÑÊµãÊ∫êËá™ËØùËØ≠ÁªìÊûÑ„ÄÇÊàë‰ª¨ÂèëÁé∞ÂàÜÂ±ÇÈ¢ÑÊµãÂõ†Â≠êÊòØËØùËØ≠‰ø°ÊÅØËΩÆÂªìÁöÑÈáçË¶ÅÈ¢ÑÊµãÂõ†Â≠êÔºåÂπ∂‰∏îÊ∑±Â∫¶ÂµåÂ•óÁöÑÂàÜÂ±ÇÈ¢ÑÊµãÂõ†Â≠êÊØîÊµÖÂ±ÇÈ¢ÑÊµãÂõ†Â≠êÊõ¥ÂÖ∑È¢ÑÊµãÊÄß„ÄÇËøôÈ°πÂ∑•‰ΩúË∂ÖË∂ä‰∫Ü UIDÔºåÊèêÂá∫‰∫ÜÂèØÊµãËØïÁöÑÂÅáËÆæÔºåËØ¥Êòé‰∏∫‰ªÄ‰πà‰ø°ÊÅØÁéá‰ª•ÂèØÈ¢ÑÊµãÁöÑÊñπÂºèÊ≥¢Âä®

##### **Large Language Models Know What To Say But Not When To Speak**
2410.16044v1 by Muhammad Umair, Vasanth Sarathy, JP de Ruiter

Turn-taking is a fundamental mechanism in human communication that ensures
smooth and coherent verbal interactions. Recent advances in Large Language
Models (LLMs) have motivated their use in improving the turn-taking
capabilities of Spoken Dialogue Systems (SDS), such as their ability to respond
at appropriate times. However, existing models often struggle to predict
opportunities for speaking -- called Transition Relevance Places (TRPs) -- in
natural, unscripted conversations, focusing only on turn-final TRPs and not
within-turn TRPs. To address these limitations, we introduce a novel dataset of
participant-labeled within-turn TRPs and use it to evaluate the performance of
state-of-the-art LLMs in predicting opportunities for speaking. Our experiments
reveal the current limitations of LLMs in modeling unscripted spoken
interactions, highlighting areas for improvement and paving the way for more
naturalistic dialogue systems.

ÊëòË¶ÅÔºöËº™ÊµÅÁôºË®ÄÊòØ‰∫∫È°ûÊ∫ùÈÄö‰∏≠ÁöÑ‰∏ÄÁ®ÆÂü∫Êú¨Ê©üÂà∂ÔºåÂèØÁ¢∫‰øùË®ÄË™û‰∫íÂãïÈ†ÜÊö¢‰∏îÈÄ£Ë≤´„ÄÇÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊúÄÊñ∞ÈÄ≤Â±ïÊøÄÂãµ‰∫ÜÂÆÉÂÄëÂú®ÊîπÈÄ≤Âè£Ë™ûÂ∞çË©±Á≥ªÁµ± (SDS) Ëº™ÊµÅÁôºË®ÄËÉΩÂäõÊñπÈù¢ÁöÑÊáâÁî®Ôºå‰æãÂ¶ÇÂÆÉÂÄëÂú®ÈÅ©Áï∂ÊôÇÈñìÂÅöÂá∫ÂõûÊáâÁöÑËÉΩÂäõ„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÁöÑÊ®°ÂûãÈÄöÂ∏∏Èõ£‰ª•È†êÊ∏¨Ëá™ÁÑ∂„ÄÅÈùûËÖ≥Êú¨Â∞çË©±‰∏≠ÁöÑÁôºË®ÄÊ©üÊúÉ‚Äî‚ÄîÁ®±ÁÇ∫ËΩâÊèõÁõ∏Èóú‰ΩçÁΩÆ (TRP)‚Äî‚ÄîÂÉÖÈóúÊ≥®ÂõûÂêàÁµêÊùüÁöÑ TRPÔºåËÄå‰∏çÈóúÊ≥®ÂõûÂêàÂÖßÁöÑ TRP„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÈôêÂà∂ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÁî±ÂèÉËàáËÄÖÊ®ôË®òÁöÑÂõûÂêàÂÖß TRP ÁöÑÊñ∞Êï∏ÊìöÈõÜÔºå‰∏¶‰ΩøÁî®ÂÆÉ‰æÜË©ï‰º∞ÊúÄÂÖàÈÄ≤ÁöÑ LLM Âú®È†êÊ∏¨ÁôºË®ÄÊ©üÊúÉÊñπÈù¢ÁöÑÊÄßËÉΩ„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÊè≠Á§∫‰∫Ü LLM Âú®Âª∫Ê®°ÈùûËÖ≥Êú¨Âè£Ë™û‰∫íÂãïÊñπÈù¢ÁöÑÁï∂ÂâçÈôêÂà∂ÔºåÁ™ÅÂá∫‰∫ÜÊîπÈÄ≤È†òÂüüÔºå‰∏¶ÁÇ∫Êõ¥Ëá™ÁÑ∂ÁöÑÂ∞çË©±Á≥ªÁµ±Èã™Âπ≥‰∫ÜÈÅìË∑Ø„ÄÇ

##### **TimeMixer++: A General Time Series Pattern Machine for Universal Predictive Analysis**
2410.16032v1 by Shiyu Wang, Jiawei Li, Xiaoming Shi, Zhou Ye, Baichuan Mo, Wenze Lin, Shengtong Ju, Zhixuan Chu, Ming Jin

Time series analysis plays a critical role in numerous applications,
supporting tasks such as forecasting, classification, anomaly detection, and
imputation. In this work, we present the time series pattern machine (TSPM), a
model designed to excel in a broad range of time series tasks through powerful
representation and pattern extraction capabilities. Traditional time series
models often struggle to capture universal patterns, limiting their
effectiveness across diverse tasks. To address this, we define multiple scales
in the time domain and various resolutions in the frequency domain, employing
various mixing strategies to extract intricate, task-adaptive time series
patterns. Specifically, we introduce a general-purpose TSPM that processes
multi-scale time series using (1) multi-resolution time imaging (MRTI), (2)
time image decomposition (TID), (3) multi-scale mixing (MCM), and (4)
multi-resolution mixing (MRM) to extract comprehensive temporal patterns. MRTI
transforms multi-scale time series into multi-resolution time images, capturing
patterns across both temporal and frequency domains. TID leverages dual-axis
attention to extract seasonal and trend patterns, while MCM hierarchically
aggregates these patterns across scales. MRM adaptively integrates all
representations across resolutions. This method achieves state-of-the-art
performance across 8 time series analytical tasks, consistently surpassing both
general-purpose and task-specific models. Our work marks a promising step
toward the next generation of TSPMs, paving the way for further advancements in
time series analysis.

ÊëòË¶ÅÔºö<paragraph>ÊôÇÂ∫èÂàÜÊûêÂú®Ë®±Â§öÊáâÁî®‰∏≠ÊâÆÊºîËëóËá≥ÈóúÈáçË¶ÅÁöÑËßíËâ≤Ôºå
ÊîØÊè¥È†êÊ∏¨„ÄÅÂàÜÈ°û„ÄÅÁï∞Â∏∏ÂÅµÊ∏¨Âíå‰º∞ÁÆóÁ≠â‰ªªÂãô„ÄÇÂú®ÈÄôÈ†ÖÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄëÊèêÂá∫ÊôÇÂ∫èÊ®°ÂºèÊ©üÂô® (TSPM)ÔºåÈÄôÊòØ‰∏ÄÂÄãÊó®Âú®ÈÄèÈÅéÂº∑Â§ßÁöÑË°®ÂæµÂíåÊ®°ÂºèËêÉÂèñËÉΩÂäõÂú®Âª£Ê≥õÊôÇÂ∫è‰ªªÂãô‰∏≠Ë°®ÁèæÂÑ™Áï∞ÁöÑÊ®°Âûã„ÄÇÂÇ≥Áµ±ÊôÇÂ∫èÊ®°ÂûãÁ∂ìÂ∏∏Èõ£‰ª•Êì∑ÂèñÈÄöÁî®Ê®°ÂºèÔºåÈôêÂà∂‰∫ÜÂÆÉÂÄëÂú®‰∏çÂêå‰ªªÂãô‰∏≠ÁöÑÊïàËÉΩ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÂú®ÊôÇÂüü‰∏≠ÂÆöÁæ©Â§öÂÄãÂ∞∫Â∫¶ÔºåÂú®È†ªÂüü‰∏≠ÂÆöÁæ©ÂêÑÁ®ÆËß£ÊûêÂ∫¶Ôºå‰∏¶Êé°Áî®ÂêÑÁ®ÆÊ∑∑ÂêàÁ≠ñÁï•‰æÜËêÉÂèñË§áÈõú‰∏îÈÅ©Êáâ‰ªªÂãôÁöÑÊôÇÂ∫èÊ®°Âºè„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰ΩøÁî® (1) Â§öËß£ÊûêÂ∫¶ÊôÇÈñìÂΩ±ÂÉè (MRTI)„ÄÅ(2) ÊôÇÈñìÂΩ±ÂÉèÂàÜËß£ (TID)„ÄÅ(3) Â§öÂ∞∫Â∫¶Ê∑∑Âêà (MCM) Âíå (4) Â§öËß£ÊûêÂ∫¶Ê∑∑Âêà (MRM) ‰æÜËêÉÂèñÂÖ®Èù¢ÊÄßÊôÇÈñìÊ®°ÂºèÁöÑÈÄöÁî® TSPMÔºå‰ª•ËôïÁêÜÂ§öÂ∞∫Â∫¶ÊôÇÂ∫è„ÄÇMRTI Â∞áÂ§öÂ∞∫Â∫¶ÊôÇÂ∫èËΩâÊèõÊàêÂ§öËß£ÊûêÂ∫¶ÊôÇÈñìÂΩ±ÂÉèÔºåÊì∑ÂèñÊôÇÈñìÂíåÈ†ªÂüü‰∏≠ÁöÑÊ®°Âºè„ÄÇTID Âà©Áî®ÈõôËª∏Ê≥®ÊÑèÂäõ‰æÜËêÉÂèñÂ≠£ÁØÄÊÄßÂíåË∂®Âã¢Ê®°ÂºèÔºåËÄå MCM ÂâáÂú®‰∏çÂêåÂ∞∫Â∫¶‰∏äÈöéÂ±§ÊÄßÂú∞ÂΩôÁ∏ΩÈÄô‰∫õÊ®°Âºè„ÄÇMRM Ëá™ÈÅ©ÊáâÂú∞Êï¥ÂêàÊâÄÊúâËß£ÊûêÂ∫¶‰∏≠ÁöÑË°®Âæµ„ÄÇÊ≠§ÊñπÊ≥ïÂú® 8 È†ÖÊôÇÂ∫èÂàÜÊûê‰ªªÂãô‰∏≠ÈÅîÂà∞‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÊïàËÉΩÔºåÂßãÁµÇË∂ÖË∂äÈÄöÁî®ÂíåÁâπÂÆö‰ªªÂãôÊ®°Âûã„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂Ê®ôË™åËëóÈÇÅÂêë‰∏ã‰∏Ä‰ª£ TSPM ÁöÑÊúâÂ∏åÊúõÁöÑ‰∏ÄÊ≠•ÔºåÁÇ∫ÊôÇÂ∫èÂàÜÊûêÁöÑÈÄ≤‰∏ÄÊ≠•ÁôºÂ±ïÈã™Âπ≥‰∫ÜÈÅìË∑Ø„ÄÇ</paragraph>

##### **ComPO: Community Preferences for Language Model Personalization**
2410.16027v1 by Sachin Kumar, Chan Young Park, Yulia Tsvetkov, Noah A. Smith, Hannaneh Hajishirzi

Conventional algorithms for training language models (LMs) with human
feedback rely on preferences that are assumed to account for an "average" user,
disregarding subjectivity and finer-grained variations. Recent studies have
raised concerns that aggregating such diverse and often contradictory human
feedback to finetune models results in generic models that generate outputs not
preferred by many user groups, as they tend to average out styles and norms. To
address this issue, we draw inspiration from recommendation systems and propose
ComPO, a method to personalize preference optimization in LMs by
contextualizing the probability distribution of model outputs with the
preference provider. Focusing on group-level preferences rather than
individuals, we collect and release ComPRed, a question answering dataset with
community-level preferences from Reddit. This dataset facilitates studying
diversity in preferences without incurring privacy concerns associated with
individual feedback. Our experiments reveal that conditioning language models
on a community identifier (i.e., subreddit name) during preference tuning
substantially enhances model performance. Conversely, replacing this context
with random subreddit identifiers significantly diminishes performance,
highlighting the effectiveness of our approach in tailoring responses to
communities' preferences.

ÊëòË¶ÅÔºöÂÇ≥Áµ±Áî®ÊñºË®ìÁ∑¥Ë™ûË®ÄÊ®°Âûã (LM) ÁöÑÊºîÁÆóÊ≥ïÔºå‰ª∞Ë≥¥ÊñºË¢´ÂÅáË®≠ÁÇ∫„ÄåÂπ≥Âùá„Äç‰ΩøÁî®ËÄÖÁöÑÂÅèÂ•ΩÔºåÂøΩÁï•‰∫Ü‰∏ªËßÄÊÄßÂíåÊõ¥Á¥∞ÂæÆÁöÑÂ∑ÆÁï∞„ÄÇÊúÄËøëÁöÑÁ†îÁ©∂ÊåáÂá∫ÔºåÂΩôÊï¥Â¶ÇÊ≠§Â§öÊ®£‰∏îÁ∂ìÂ∏∏Áõ∏‰∫íÁüõÁõæÁöÑ‰∫∫È°ûÂÅèÂ•Ω‰æÜÂæÆË™øÊ®°ÂûãÔºåÊúÉÂ∞éËá¥Áî¢Áîü‰∏çÂèóË®±Â§ö‰ΩøÁî®ËÄÖÁæ§È´îÂÅèÂ•ΩÁöÑÈÄöÁî®Ê®°ÂûãÔºåÂõ†ÁÇ∫ÈÄô‰∫õÊ®°ÂûãÂæÄÂæÄÊúÉÂπ≥ÂùáÂá∫ÂêÑÁ®ÆÈ¢®Ê†ºÂíåË¶èÁØÑ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÂæûÊé®Ëñ¶Á≥ªÁµ±‰∏≠Ê±≤ÂèñÈùàÊÑüÔºå‰∏¶ÊèêÂá∫ ComPOÔºåÈÄôÊòØ‰∏ÄÁ®ÆÈÄèÈÅéÂ∞áÊ®°ÂûãËº∏Âá∫ÁöÑÊ©üÁéáÂàÜ‰ΩàËàáÂÅèÂ•ΩÊèê‰æõËÄÖËÑàÁµ°ÂåñÁöÑÊñπÂºèÔºå‰æÜÂÄã‰∫∫Âåñ LM ‰∏≠ÁöÑÂÅèÂ•ΩÊúÄ‰Ω≥Âåñ„ÄÇÊàëÂÄëËëóÈáçÊñºÁæ§ÁµÑÂ±§Á¥öÁöÑÂÅèÂ•ΩÔºåËÄåÈùûÂÄã‰∫∫ÔºåÂõ†Ê≠§ÊàëÂÄëÊî∂ÈõÜ‰∏¶ÁôºÂ∏É ComPRedÔºåÈÄôÊòØ‰∏ÄÂÄã‰æÜËá™ Reddit Á§æÁæ§Â±§Á¥öÂÅèÂ•ΩÁöÑÂïèÁ≠îË≥áÊñôÈõÜ„ÄÇÈÄôÂÄãË≥áÊñôÈõÜÊúâÂä©ÊñºÁ†îÁ©∂ÂÅèÂ•ΩÁöÑÂ§öÊ®£ÊÄßÔºåËÄå‰∏çÊúÉÊãõËá¥ËàáÂÄã‰∫∫ÂÅèÂ•ΩÁõ∏ÈóúÁöÑÈö±ÁßÅÂïèÈ°å„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÈ°ØÁ§∫ÔºåÂú®ÂÅèÂ•ΩË™øÊï¥ÊúüÈñìÔºåÂ∞áË™ûË®ÄÊ®°ÂûãÁΩÆÊñºÁ§æÁæ§Ë≠òÂà•Á¢ºÔºà‰æãÂ¶ÇÔºåsubreddit ÂêçÁ®±ÔºâÁöÑÊ¢ù‰ª∂‰∏ãÔºåÊúÉÂ§ßÂπÖÊèêÂçáÊ®°ÂûãÊïàËÉΩ„ÄÇÁõ∏ÂèçÂú∞ÔºåËã•Â∞áÊ≠§ËÑàÁµ°ÊõøÊèõÁÇ∫Èö®Ê©üÁöÑ subreddit Ë≠òÂà•Á¢ºÔºåÂâáÊúÉÈ°ØËëóÈôç‰ΩéÊïàËÉΩÔºåÁ™ÅÈ°Ø‰∫ÜÊàëÂÄëÂú®Ê†πÊìöÁ§æÁæ§ÂÅèÂ•ΩË™øÊï¥ÂõûÊáâÊñπÈù¢ÁöÑÊúâÊïàÊÄß„ÄÇ

##### **A New Approach to Solving SMAC Task: Generating Decision Tree Code from Large Language Models**
2410.16024v1 by Yue Deng, Weiyu Ma, Yuxin Fan, Yin Zhang, Haifeng Zhang, Jian Zhao

StarCraft Multi-Agent Challenge (SMAC) is one of the most commonly used
experimental environments in multi-agent reinforcement learning (MARL), where
the specific task is to control a set number of allied units to defeat enemy
forces. Traditional MARL algorithms often require interacting with the
environment for up to 1 million steps to train a model, and the resulting
policies are typically non-interpretable with weak transferability. In this
paper, we propose a novel approach to solving SMAC tasks called LLM-SMAC. In
our framework, agents leverage large language models (LLMs) to generate
decision tree code by providing task descriptions. The model is further
self-reflection using feedback from the rewards provided by the environment. We
conduct experiments in the SMAC and demonstrate that our method can produce
high-quality, interpretable decision trees with minimal environmental
exploration. Moreover, these models exhibit strong transferability,
successfully applying to similar SMAC environments without modification. We
believe this approach offers a new direction for solving decision-making tasks
in the future.

ÊëòË¶ÅÔºöÊòüÊµ∑Áà≠Èú∏Â§öÊô∫ËÉΩÈ´îÊåëÊà∞ (SMAC) ÊòØÂ§öÊô∫ËÉΩÈ´îÂº∑ÂåñÂ≠∏Áøí (MARL) ‰∏≠ÊúÄÂ∏∏‰ΩøÁî®ÁöÑÂØ¶È©óÁí∞Â¢É‰πã‰∏ÄÔºåÂÖ∂‰∏≠ÂÖ∑È´î‰ªªÂãôÊòØÊéßÂà∂‰∏ÄÂÆöÊï∏ÈáèÁöÑÁõüËªçÂñÆ‰Ωç‰æÜÊìäÊïóÊïµËªç„ÄÇÂÇ≥Áµ±ÁöÑ MARL ÊºîÁÆóÊ≥ïÈÄöÂ∏∏ÈúÄË¶ÅËàáÁí∞Â¢É‰∫íÂãïÂ§öÈÅî 100 Ëê¨Ê≠•ÊâçËÉΩË®ìÁ∑¥Ê®°ÂûãÔºåËÄåÁî¢ÁîüÁöÑÁ≠ñÁï•ÈÄöÂ∏∏Èõ£‰ª•Ëß£ÈáãÔºå‰∏îÂèØËΩâÁßªÊÄßËºÉÂº±„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆËß£Ê±∫ SMAC ‰ªªÂãôÁöÑÊñ∞ÊñπÊ≥ïÔºåÁ®±ÁÇ∫ LLM-SMAC„ÄÇÂú®ÊàëÂÄëÁöÑÊ°ÜÊû∂‰∏≠ÔºåÊô∫ËÉΩÈ´îÂà©Áî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÈÄèÈÅéÊèê‰æõ‰ªªÂãôÊèèËø∞‰æÜÁî¢ÁîüÊ±∫Á≠ñÊ®πÁ®ãÂºèÁ¢º„ÄÇË©≤Ê®°ÂûãÈÄ≤‰∏ÄÊ≠•Âà©Áî®Áí∞Â¢ÉÊèê‰æõÁöÑÂõûÈ•ãÈÄ≤Ë°åËá™ÊàëÂèçÁúÅ„ÄÇÊàëÂÄëÂú® SMAC ‰∏≠ÈÄ≤Ë°åÂØ¶È©óÔºå‰∏¶Ë≠âÊòéÊàëÂÄëÁöÑÊ®°ÂûãÂèØ‰ª•Áî¢ÁîüÈ´òÂìÅË≥™„ÄÅÂèØËß£ÈáãÁöÑÊ±∫Á≠ñÊ®πÔºå‰∏îÁí∞Â¢ÉÊé¢Á¥¢ÊúÄÂ∞ë„ÄÇÊ≠§Â§ñÔºåÈÄô‰∫õÊ®°ÂûãÂ±ïÁèæÂá∫Âº∑Â§ßÁöÑÂèØËΩâÁßªÊÄßÔºåÊàêÂäüÊáâÁî®ÊñºÈ°û‰ººÁöÑ SMAC Áí∞Â¢ÉËÄåÁÑ°ÈúÄ‰øÆÊîπ„ÄÇÊàëÂÄëÁõ∏‰ø°ÈÄôÁ®ÆÊñπÊ≥ïÁÇ∫Êú™‰æÜËß£Ê±∫Ê±∫Á≠ñÂà∂ÂÆö‰ªªÂãôÊèê‰æõ‰∫ÜÊñ∞ÁöÑÊñπÂêë„ÄÇ

##### **Massimo: Public Queue Monitoring and Management using Mass-Spring Model**
2410.16012v1 by Abhijeet Kumar, Unnati Singh, Rajdeep Chatterjee, Tathagata Bandyopadhyay

An efficient system of a queue control and regulation in public spaces is
very important in order to avoid the traffic jams and to improve the customer
satisfaction. This article offers a detailed road map based on a merger of
intelligent systems and creating an efficient systems of queues in public
places. Through the utilization of different technologies i.e. computer vision,
machine learning algorithms, deep learning our system provide accurate
information about the place is crowded or not and the necessary efforts to be
taken.

ÊëòË¶ÅÔºö‰∏ÄÂÄãÊúâÊïàÁéáÁöÑÂÖ¨ÂÖ±Á©∫ÈñìÈöä‰ºçÊéßÂà∂ÂíåÁÆ°ÁêÜÁ≥ªÁµ±ÔºåÂ∞çÊñºÈÅøÂÖç‰∫§ÈÄöÂ†µÂ°ûÂíåÊèêÂçáÈ°ßÂÆ¢ÊªøÊÑèÂ∫¶ÈùûÂ∏∏ÈáçË¶Å„ÄÇÊú¨ÊñáÊèê‰æõ‰∫ÜË©≥Á¥∞ÁöÑË∑ØÂæëÂúñÔºåÂü∫ÊñºÊô∫ÊÖßÁ≥ªÁµ±ÁöÑÂêà‰ΩµÂíåÂª∫Á´ã‰∏ÄÂÄãÊúâÊïàÁöÑÂÖ¨ÂÖ±Á©∫ÈñìÈöä‰ºçÁ≥ªÁµ±„ÄÇÈÄèÈÅé‰ΩøÁî®‰∏çÂêåÁöÑÊäÄË°ìÔºå‰æãÂ¶ÇÈõªËÖ¶Ë¶ñË¶∫„ÄÅÊ©üÂô®Â≠∏ÁøíÊºîÁÆóÊ≥ï„ÄÅÊ∑±Â∫¶Â≠∏ÁøíÔºåÊàëÂÄëÁöÑÁ≥ªÁµ±Êèê‰æõ‰∫ÜÊ∫ñÁ¢∫ÁöÑË≥áË®äÔºåË°®Á§∫ÈÄôÂÄãÂú∞ÊñπÊòØÂê¶ÊìÅÊì†Ôºå‰ª•ÂèäÈúÄË¶ÅÊé°ÂèñÁöÑÂøÖË¶ÅÊé™ÊñΩ„ÄÇ

##### **Resilient Temporal GCN for Smart Grid State Estimation Under Topology Inaccuracies**
2410.16008v1 by Seyed Hamed Haghshenas, Mia Naeini

State Estimation is a crucial task in power systems. Graph Neural Networks
have demonstrated significant potential in state estimation for power systems
by effectively analyzing measurement data and capturing the complex
interactions and interrelations among the measurements through the system's
graph structure. However, the information about the system's graph structure
may be inaccurate due to noise, attack or lack of accurate information about
the topology of the system. This paper studies these scenarios under topology
uncertainties and evaluates the impact of the topology uncertainties on the
performance of a Temporal Graph Convolutional Network (TGCN) for state
estimation in power systems. In order to make the model resilient to topology
uncertainties, modifications in the TGCN model are proposed to incorporate a
knowledge graph, generated based on the measurement data. This knowledge graph
supports the assumed uncertain system graph. Two variations of the TGCN
architecture are introduced to integrate the knowledge graph, and their
performances are evaluated and compared to demonstrate improved resilience
against topology uncertainties. The evaluation results indicate that while the
two proposed architecture show different performance, they both improve the
performance of the TGCN state estimation under topology uncertainties.

ÊëòË¶ÅÔºöÁãÄÊÖã‰º∞Ë®àÊòØÈõªÂäõÁ≥ªÁµ±‰∏≠ÁöÑ‰∏ÄÈ†ÖÈóúÈçµ‰ªªÂãô„ÄÇÂúñÁ•ûÁ∂ìÁ∂≤Ë∑ØÂ∑≤Ë≠âÊòéÂÖ∂Âú®ÈõªÂäõÁ≥ªÁµ±ÁãÄÊÖã‰º∞Ë®à‰∏≠ÂÖ∑ÊúâÈ°ØËëóÁöÑÊΩõÂäõÔºåÊñπÊ≥ïÊòØÊúâÊïàÂàÜÊûêÊ∏¨ÈáèË≥áÊñô‰∏¶ÈÄèÈÅéÁ≥ªÁµ±ÂúñÁµêÊßãÊì∑ÂèñÊ∏¨Èáè‰∏≠Ë§áÈõúÁöÑ‰∫íÂãïÂíåÁõ∏‰∫íÈóú‰øÇ„ÄÇÁÑ∂ËÄåÔºåÁî±ÊñºÈõúË®ä„ÄÅÊîªÊìäÊàñÁº∫‰πèÈóúÊñºÁ≥ªÁµ±ÊãìÊí≤ÁµêÊßãÁöÑÊ∫ñÁ¢∫Ë≥áË®äÔºåÁ≥ªÁµ±ÂúñÁµêÊßãÁöÑË≥áË®äÂèØËÉΩ‰∏çÊ∫ñÁ¢∫„ÄÇÊú¨ÊñáÁ†îÁ©∂‰∫ÜÊãìÊí≤ÁµêÊßã‰∏çÁ¢∫ÂÆöÊÄß‰∏ãÁöÑÈÄô‰∫õÊÉÖÂ¢ÉÔºå‰∏¶Ë©ï‰º∞ÊãìÊí≤ÁµêÊßã‰∏çÁ¢∫ÂÆöÊÄßÂ∞çÊôÇÊÖãÂúñÂΩ¢Âç∑Á©çÁ∂≤Ë∑Ø (TGCN) Âú®ÈõªÂäõÁ≥ªÁµ±ÁãÄÊÖã‰º∞Ë®à‰∏äÁöÑÊïàËÉΩÂΩ±Èüø„ÄÇÁÇ∫‰∫Ü‰ΩøÊ®°ÂûãÂ∞çÊãìÊí≤ÁµêÊßã‰∏çÁ¢∫ÂÆöÊÄßÂÖ∑ÊúâÂæ©ÂéüÂäõÔºåÊèêÂá∫‰∫Ü TGCN Ê®°ÂûãÁöÑ‰øÆÊîπÔºå‰ª•Á¥çÂÖ•Âü∫ÊñºÊ∏¨ÈáèË≥áÊñôÁî¢ÁîüÁöÑÁü•Ë≠òÂúñ„ÄÇÊ≠§Áü•Ë≠òÂúñÊîØÊè¥ÂÅáË®≠ÁöÑ‰∏çÁ¢∫ÂÆöÁ≥ªÁµ±Âúñ„ÄÇÂºïÂÖ•‰∫Ü TGCN Êû∂ÊßãÁöÑÂÖ©ÂÄãËÆäÈ´î‰æÜÊï¥ÂêàÁü•Ë≠òÂúñÔºå‰∏¶Ë©ï‰º∞ÂÖ∂ÊïàËÉΩ‰∏¶Ëàá‰πãÊØîËºÉÔºå‰ª•Ë≠âÊòéÂ∞çÊãìÊí≤ÁµêÊßã‰∏çÁ¢∫ÂÆöÊÄßÂÖ∑ÊúâÊîπÂñÑÁöÑÂæ©ÂéüÂäõ„ÄÇË©ï‰º∞ÁµêÊûúË°®ÊòéÔºåÈõñÁÑ∂ÂÖ©ÂÄãÊèêÂá∫ÁöÑÊû∂ÊßãË°®ÁèæÂá∫‰∏çÂêåÁöÑÊïàËÉΩÔºå‰ΩÜÂÆÉÂÄëÈÉΩÊîπÂñÑ‰∫Ü TGCN ÁãÄÊÖã‰º∞Ë®àÂú®ÊãìÊí≤ÁµêÊßã‰∏çÁ¢∫ÂÆöÊÄß‰∏ãÁöÑÊïàËÉΩ„ÄÇ

##### **Are Language Model Logits Calibrated?**
2410.16007v1 by Charles Lovering, Michael Krumdick, Viet Dac Lai, Nilesh Kumar, Varshini Reddy, Rik Koncel-Kedziorski, Chris Tanner

Some information is factual (e.g., "Paris is in France"), whereas other
information is probabilistic (e.g., "the coin flip will be a [Heads/Tails].").
We believe that good Language Models (LMs) should understand and reflect this
nuance. Our work investigates this by testing if LMs' output probabilities are
calibrated to their textual contexts. We define model "calibration" as the
degree to which the output probabilities of candidate tokens are aligned with
the relative likelihood that should be inferred from the given context. For
example, if the context concerns two equally likely options (e.g., heads or
tails for a fair coin), the output probabilities should reflect this. Likewise,
context that concerns non-uniformly likely events (e.g., rolling a six with a
die) should also be appropriately captured with proportionate output
probabilities. We find that even in simple settings the best LMs (1) are poorly
calibrated, and (2) have systematic biases (e.g., preferred colors and
sensitivities to word orderings). For example, gpt-4o-mini often picks the
first of two options presented in the prompt regardless of the options' implied
likelihood, whereas Llama-3.1-8B picks the second. Our other consistent finding
is mode-collapse: Instruction-tuned models often over-allocate probability mass
on a single option. These systematic biases introduce non-intuitive model
behavior, making models harder for users to understand.

ÊëòË¶ÅÔºöÊüê‰∫õË≥áË®äÊòØ‰∫ãÂØ¶Ôºà‰æãÂ¶ÇÔºö„ÄåÂ∑¥ÈªéÂú®Ê≥ïÂúã„ÄçÔºâÔºåËÄåÂÖ∂‰ªñË≥áË®äÂâáÊòØÊ©üÁéáÊÄßÁöÑÔºà‰æãÂ¶ÇÔºö„ÄåÊããÁ°¨Âπ£ÊúÉÊòØ [Ê≠£Èù¢/ÂèçÈù¢]„ÄçÔºâ„ÄÇÊàëÂÄëÁõ∏‰ø°ËâØÂ•ΩÁöÑË™ûË®ÄÊ®°Âûã (LM) ÊáâÁêÜËß£‰∏¶ÂèçÊò†ÈÄôÁ®ÆÂ∑ÆÁï∞„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÈÄèÈÅéÊ∏¨Ë©¶Ë™ûË®ÄÊ®°ÂûãÁöÑËº∏Âá∫Ê©üÁéáÊòØÂê¶Ê†°Ê∫ñËá≥ÂÖ∂ÊñáÂ≠óËÑàÁµ°‰æÜÊé¢Ë®éÈÄô‰∏ÄÈªû„ÄÇÊàëÂÄëÂ∞áÊ®°Âûã„ÄåÊ†°Ê∫ñ„ÄçÂÆöÁæ©ÁÇ∫ÂÄôÈÅ∏Ë©ûÂΩôÁöÑËº∏Âá∫Ê©üÁéáËàáÊáâÂæûÁµ¶ÂÆöËÑàÁµ°Êé®Ë´ñÂá∫ÁöÑÁõ∏Â∞çÂèØËÉΩÊÄß‰∏ÄËá¥ÁöÑÁ®ãÂ∫¶„ÄÇ‰æãÂ¶ÇÔºåÂ¶ÇÊûúËÑàÁµ°Ê∂âÂèäÂÖ©ÂÄãÂèØËÉΩÊÄßÁõ∏Á≠âÁöÑÈÅ∏È†ÖÔºà‰æãÂ¶ÇÂÖ¨Âπ≥Á°¨Âπ£ÁöÑÊ≠£Èù¢ÊàñÂèçÈù¢ÔºâÔºåËº∏Âá∫Ê©üÁéáÊáâÂèçÊò†ÈÄô‰∏ÄÈªû„ÄÇÂêåÊ®£Âú∞ÔºåÊ∂âÂèäÂèØËÉΩÊÄß‰∏çÂùáÁ≠âÁöÑ‰∫ã‰ª∂Ôºà‰æãÂ¶ÇÁî®È™∞Â≠êÊì≤Âá∫ÂÖ≠ÈªûÔºâÁöÑËÑàÁµ°‰πüÊáâÈÄèÈÅéÁõ∏ÊáâÁöÑËº∏Âá∫Ê©üÁéáÈÅ©Áï∂Âú∞ÊçïÊçâ„ÄÇÊàëÂÄëÁôºÁèæÔºåÂç≥‰ΩøÂú®Á∞°ÂñÆÁöÑË®≠ÂÆö‰∏≠ÔºåÊúÄ‰Ω≥ÁöÑË™ûË®ÄÊ®°Âûã (1) Ê†°Ê∫ñ‰∏çËâØÔºå‰∏î (2) ÂÖ∑ÊúâÁ≥ªÁµ±ÊÄßÂÅèÂ∑ÆÔºà‰æãÂ¶ÇÔºåÂÅèÂ•ΩÁöÑÈ°èËâ≤ÂíåÂ∞çÂ≠óÂ∫èÁöÑÊïèÊÑüÊÄßÔºâ„ÄÇ‰æãÂ¶ÇÔºågpt-4o-mini ÈÄöÂ∏∏ÊúÉÈÅ∏ÊìáÊèêÁ§∫‰∏≠ÂëàÁèæÁöÑÂÖ©ÂÄãÈÅ∏È†Ö‰∏≠ÁöÑÁ¨¨‰∏ÄÂÄãÔºåËÄå‰∏çÁÆ°ÈÅ∏È†ÖÊöóÁ§∫ÁöÑÂèØËÉΩÊÄßÂ¶Ç‰ΩïÔºåËÄå Llama-3.1-8B ÂâáÊúÉÈÅ∏ÊìáÁ¨¨‰∫åÂÄã„ÄÇÊàëÂÄëÂè¶‰∏ÄÂÄã‰∏ÄËá¥ÁöÑÁôºÁèæÊòØÊ®°ÂºèÂ¥©ÊΩ∞ÔºöÁ∂ìÈÅéÊåá‰ª§ÂæÆË™øÁöÑÊ®°ÂûãÈÄöÂ∏∏ÊúÉÈÅéÂ∫¶ÂàÜÈÖçÂñÆ‰∏ÄÈÅ∏È†ÖÁöÑÊ©üÁéáË≥™Èáè„ÄÇÈÄô‰∫õÁ≥ªÁµ±ÊÄßÂÅèÂ∑ÆÊúÉÂ∞éËá¥ÈùûÁõ¥Ë¶∫ÁöÑÊ®°ÂûãË°åÁÇ∫ÔºåËÆì‰ΩøÁî®ËÄÖÊõ¥Èõ£ÁêÜËß£Ê®°Âûã„ÄÇ

##### **Exploring Continual Fine-Tuning for Enhancing Language Ability in Large Language Model**
2410.16006v1 by Divyanshu Aggarwal, Sankarshan Damle, Navin Goyal, Satya Lokam, Sunayana Sitaram

A common challenge towards the adaptability of Large Language Models (LLMs)
is their ability to learn new languages over time without hampering the model's
performance on languages in which the model is already proficient (usually
English). Continual fine-tuning (CFT) is the process of sequentially
fine-tuning an LLM to enable the model to adapt to downstream tasks with
varying data distributions and time shifts. This paper focuses on the language
adaptability of LLMs through CFT. We study a two-phase CFT process in which an
English-only end-to-end fine-tuned LLM from Phase 1 (predominantly Task
Ability) is sequentially fine-tuned on a multilingual dataset -- comprising
task data in new languages -- in Phase 2 (predominantly Language Ability). We
observe that the ``similarity'' of Phase 2 tasks with Phase 1 determines the
LLM's adaptability. For similar phase-wise datasets, the LLM after Phase 2 does
not show deterioration in task ability. In contrast, when the phase-wise
datasets are not similar, the LLM's task ability deteriorates. We test our
hypothesis on the open-source \mis\ and \llm\ models with multiple phase-wise
dataset pairs. To address the deterioration, we analyze tailored variants of
two CFT methods: layer freezing and generative replay. Our findings demonstrate
their effectiveness in enhancing the language ability of LLMs while preserving
task performance, in comparison to relevant baselines.

ÊëòË¶ÅÔºö<paragraph>Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÈÅ©ÊáâÊÄßÁöÑÂ∏∏Ë¶ãÊåëÊà∞ÊòØÂÆÉÂÄëÂú®‰∏çÂΩ±ÈüøÊ®°ÂûãÂú®Â∑≤Á∂ìÁÜüÁ∑¥ÁöÑË™ûË®ÄÔºàÈÄöÂ∏∏ÊòØËã±Ë™ûÔºâ‰∏äÁöÑË°®ÁèæÁöÑÊÉÖÊ≥Å‰∏ãÔºåÈö®ËëóÊôÇÈñìÊé®ÁßªÂ≠∏ÁøíÊñ∞Ë™ûË®ÄÁöÑËÉΩÂäõ„ÄÇÊåÅÁ∫åÂæÆË™ø (CFT) ÊòØÊåâÈ†ÜÂ∫èÂæÆË™ø LLM ÁöÑÈÅéÁ®ãÔºå‰ΩøÊ®°ÂûãËÉΩÂ§†ÈÅ©ÊáâÂÖ∑Êúâ‰∏çÂêåË≥áÊñôÂàÜ‰ΩàÂíåÊôÇÈñìËÆäÂåñÁöÑ‰∏ãÊ∏∏‰ªªÂãô„ÄÇÊú¨ÊñáÈáçÈªûÈóúÊ≥® LLM ÈÄöÈÅé CFT ÁöÑË™ûË®ÄÈÅ©ÊáâÊÄß„ÄÇÊàëÂÄëÁ†îÁ©∂‰∫Ü‰∏ÄÂÄãÂÖ©ÈöéÊÆµ CFT ÈÅéÁ®ãÔºåÂÖ∂‰∏≠‰∏ÄÂÄãÂÉÖÈôêËã±Ë™ûÁöÑÁ´ØÂà∞Á´ØÂæÆË™ø LLMÔºàÁ¨¨ 1 ÈöéÊÆµÔºå‰∏ªË¶ÅÊòØ‰ªªÂãôËÉΩÂäõÔºâÂú®Á¨¨ 2 ÈöéÊÆµÔºà‰∏ªË¶ÅÊòØË™ûË®ÄËÉΩÂäõÔºâ‰∏≠Âú®‰∏ÄÂÄãÂ§öË™ûË®ÄË≥áÊñôÈõÜÔºàÂåÖÊã¨Êñ∞Ë™ûË®ÄÁöÑ‰ªªÂãôË≥áÊñôÔºâ‰∏äÊåâÈ†ÜÂ∫èÂæÆË™ø„ÄÇÊàëÂÄëËßÄÂØüÂà∞Á¨¨ 2 ÈöéÊÆµ‰ªªÂãôËàáÁ¨¨ 1 ÈöéÊÆµÁöÑ„ÄåÁõ∏‰ººÊÄß„ÄçÊ±∫ÂÆö‰∫Ü LLM ÁöÑÈÅ©ÊáâÊÄß„ÄÇÂ∞çÊñºÁõ∏‰ººÁöÑÈöéÊÆµË≥áÊñôÈõÜÔºåÁ¨¨ 2 ÈöéÊÆµÂæåÁöÑ LLM ‰ªªÂãôËÉΩÂäõÊ≤íÊúâ‰∏ãÈôç„ÄÇÁõ∏ÂèçÔºåÁï∂ÈöéÊÆµË≥áÊñôÈõÜ‰∏çÁõ∏‰ººÁöÑÔºåLLM ÁöÑ‰ªªÂãôËÉΩÂäõÊúÉ‰∏ãÈôç„ÄÇÊàëÂÄë‰ΩøÁî®Â§öÂÄãÈöéÊÆµË≥áÊñôÈõÜÂ∞çÂú®ÈñãÊ∫ê \mis\ Âíå \llm\ Ê®°Âûã‰∏äÊ∏¨Ë©¶ÊàëÂÄëÁöÑÂÅáË®≠„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÊÉ°ÂåñÂïèÈ°åÔºåÊàëÂÄëÂàÜÊûê‰∫ÜÂÖ©Á®Æ CFT ÊñπÊ≥ïÁöÑÂÆöÂà∂ËÆäÈ´îÔºöÂ±§ÂáçÁµêÂíåÁîüÊàêÂºèÈáçÊí≠„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúË≠âÊòé‰∫ÜÂÆÉÂÄëÂú®Â¢ûÂº∑ LLM ÁöÑË™ûË®ÄËÉΩÂäõÁöÑÂêåÊôÇ‰øùÊåÅ‰ªªÂãôË°®ÁèæÊñπÈù¢ÁöÑÊúâÊïàÊÄßÔºåËàáÁõ∏ÈóúÂü∫Ê∫ñÁõ∏ÊØî„ÄÇ</paragraph>

##### **Steering Knowledge Selection Behaviours in LLMs via SAE-Based Representation Engineering**
2410.15999v1 by Yu Zhao, Alessio Devoto, Giwon Hong, Xiaotang Du, Aryo Pradipta Gema, Hongru Wang, Kam-Fai Wong, Pasquale Minervini

Large language models (LLMs) can store a significant amount of factual
knowledge in their parameters. However, their parametric knowledge may conflict
with the information provided in the context -- this phenomenon, known as
\emph{context-memory knowledge conflicts}, can lead to undesirable model
behaviour, such as reliance on outdated or incorrect information. Analysing the
internal activations of LLMs, we find that they can internally register the
signals of knowledge conflict at mid-layers. Such signals allow us to detect
whether a knowledge conflict occurs and use \emph{inference-time} intervention
strategies to resolve it. In this work, we propose \textsc{SpARE}, a
\emph{training-free} representation engineering method that uses pre-trained
sparse auto-encoders (SAEs) to control the knowledge selection behaviour of
LLMs. \textsc{SpARE} identifies the functional features that control the
knowledge selection behaviours and applies them to edit the internal
activations of LLMs at inference time. Our experimental results show that
\textsc{SpARE} can effectively control the usage of either knowledge source to
resolve knowledge conflict in open-domain question-answering tasks, surpassing
existing representation engineering methods ($+10\%$) as well as contrastive
decoding methods ($+15\%$).

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂèØ‰ª•Â∞áÂ§ßÈáèÁöÑÂØ¶ÈöõÁü•Ë≠òÂÑ≤Â≠òÂú®ÂÖ∂ÂèÉÊï∏‰∏≠„ÄÇÁÑ∂ËÄåÔºåÂÆÉÂÄëÁöÑÂèÉÊï∏ÂåñÁü•Ë≠òÂèØËÉΩÊúÉËàá‰∏ä‰∏ãÊñá‰∏≠Êèê‰æõÁöÑË≥áË®äÁî¢ÁîüË°ùÁ™Å‚Äî‚ÄîÈÄôÁ®ÆÁèæË±°Á®±ÁÇ∫„Äå‰∏ä‰∏ãÊñáË®òÊÜ∂Áü•Ë≠òË°ùÁ™Å„ÄçÔºåÂèØËÉΩÊúÉÂ∞éËá¥‰∏çËâØÁöÑÊ®°ÂûãË°åÁÇ∫Ôºå‰æãÂ¶Ç‰æùË≥¥ÈÅéÊôÇÊàñ‰∏çÊ≠£Á¢∫ÁöÑË≥áË®ä„ÄÇÂàÜÊûê LLM ÁöÑÂÖßÈÉ®ÊøÄÊ¥ªÔºåÊàëÂÄëÁôºÁèæÂÆÉÂÄëÂèØ‰ª•Âú®‰∏≠ÈñìÂ±§ÂÖßÈÉ®Ë®ªÂÜäÁü•Ë≠òË°ùÁ™ÅÁöÑ‰ø°Ëôü„ÄÇÊ≠§È°û‰ø°Ëôü‰ΩøÊàëÂÄëËÉΩÂ§†ÂÅµÊ∏¨Áü•Ë≠òË°ùÁ™ÅÊòØÂê¶ÁôºÁîüÔºå‰∏¶‰ΩøÁî®„ÄåÊé®Ë´ñÊôÇÈñì„Äç‰ªãÂÖ•Á≠ñÁï•‰æÜËß£Ê±∫ÂÆÉ„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫ \textsc{SpARE}Ôºå‰∏ÄÁ®Æ„ÄåÁÑ°Ë®ìÁ∑¥„ÄçÁöÑË°®Á§∫Â∑•Á®ãÊñπÊ≥ïÔºåÂÆÉ‰ΩøÁî®È†êÂÖàË®ìÁ∑¥ÁöÑÁ®ÄÁñèËá™ÂãïÁ∑®Á¢ºÂô® (SAE) ‰æÜÊéßÂà∂ LLM ÁöÑÁü•Ë≠òÈÅ∏ÊìáË°åÁÇ∫„ÄÇ\textsc{SpARE} Ë≠òÂà•ÊéßÂà∂Áü•Ë≠òÈÅ∏ÊìáË°åÁÇ∫ÁöÑÂäüËÉΩÁâπÂæµÔºå‰∏¶Â∞áÂÆÉÂÄëÊáâÁî®ÊñºÁ∑®ËºØ LLM Âú®Êé®Ë´ñÊôÇÈñìÁöÑÂÖßÈÉ®ÊøÄÊ¥ª„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÁµêÊûúË°®ÊòéÔºå\textsc{SpARE} ÂèØ‰ª•ÊúâÊïàÊéßÂà∂‰ªª‰∏ÄÁü•Ë≠ò‰æÜÊ∫êÁöÑ‰ΩøÁî®Ôºå‰ª•Ëß£Ê±∫ÈñãÊîæÈ†òÂüüÂïèÁ≠î‰ªªÂãô‰∏≠ÁöÑÁü•Ë≠òË°ùÁ™ÅÔºåË∂ÖË∂äÁèæÊúâÁöÑË°®Á§∫Â∑•Á®ãÊñπÊ≥ïÔºà+10%Ôºâ‰ª•ÂèäÂ∞çÊØîËß£Á¢ºÊñπÊ≥ïÔºà+15%Ôºâ„ÄÇ

##### **1024m at SMM4H 2024: Tasks 3, 5 & 6 -- Ensembles of Transformers and Large Language Models for Medical Text Classification**
2410.15998v1 by Ram Mohan Rao Kadiyala, M. V. P. Chandra Sekhara Rao

Social media is a great source of data for users reporting information and
regarding their health and how various things have had an effect on them. This
paper presents various approaches using Transformers and Large Language Models
and their ensembles, their performance along with advantages and drawbacks for
various tasks of SMM4H'24 - Classifying texts on impact of nature and outdoor
spaces on the author's mental health (Task 3), Binary classification of tweets
reporting their children's health disorders like Asthma, Autism, ADHD and
Speech disorder (task 5), Binary classification of users self-reporting their
age (task 6).

ÊëòË¶ÅÔºöÁ§æÁæ§Â™íÈ´îÊòØ‰ΩøÁî®ËÄÖÂõûÂ†±Ë≥áË®äÁöÑÁµï‰Ω≥Ë≥áÊñô‰æÜÊ∫êÔºåÈóúÊñº‰ªñÂÄëÁöÑÂÅ•Â∫∑‰ª•ÂèäÂêÑÁ®Æ‰∫ãÁâ©Â∞ç‰ªñÂÄëÁöÑÂΩ±Èüø„ÄÇÊú¨ÊñáÊèêÂá∫ÂêÑÁ®Æ‰ΩøÁî® Transformer ÂíåÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÂèäÂÖ∂ÂêàÂ•èÁöÑÊñπÊ≥ïÔºå‰ª•ÂèäÂÆÉÂÄëÂú® SMM4H'24 ÂêÑÁ®Æ‰ªªÂãô‰∏≠ÁöÑË°®ÁèæÔºå‰ª•ÂèäÂÑ™Áº∫Èªû - ÂàÜÈ°ûÂΩ±Èüø‰ΩúËÄÖÂøÉÁêÜÂÅ•Â∫∑ÁöÑËá™ÁÑ∂ÂíåÊà∂Â§ñÁ©∫ÈñìÊñáÊú¨Ôºà‰ªªÂãô 3ÔºâÔºåÂõûÂ†±ÂÖ∂ÂÖíÁ´•ÂÅ•Â∫∑ÈöúÁ§ôÔºà‰æãÂ¶ÇÊ∞£Âñò„ÄÅËá™ÈñâÁóá„ÄÅÊ≥®ÊÑèÂäõ‰∏çË∂≥ÈÅéÂãïÁóáÂíåË®ÄË™ûÈöúÁ§ôÔºâÁöÑÊé®Êñá‰∫åÂÖÉÂàÜÈ°ûÔºà‰ªªÂãô 5ÔºâÔºå‰ΩøÁî®ËÄÖËá™Ë°åÂõûÂ†±ÂÖ∂Âπ¥ÈΩ°ÁöÑ‰∫åÂÖÉÂàÜÈ°ûÔºà‰ªªÂãô 6Ôºâ„ÄÇ

##### **Augmenting Legal Decision Support Systems with LLM-based NLI for Analyzing Social Media Evidence**
2410.15990v1 by Ram Mohan Rao Kadiyala, Siddartha Pullakhandam, Kanwal Mehreen, Subhasya Tippareddy, Ashay Srivastava

This paper presents our system description and error analysis of our entry
for NLLP 2024 shared task on Legal Natural Language Inference (L-NLI)
\citep{hagag2024legallenssharedtask2024}. The task required classifying these
relationships as entailed, contradicted, or neutral, indicating any association
between the review and the complaint. Our system emerged as the winning
submission, significantly outperforming other entries with a substantial margin
and demonstrating the effectiveness of our approach in legal text analysis. We
provide a detailed analysis of the strengths and limitations of each model and
approach tested, along with a thorough error analysis and suggestions for
future improvements. This paper aims to contribute to the growing field of
legal NLP by offering insights into advanced techniques for natural language
inference in legal contexts, making it accessible to both experts and newcomers
in the field.

ÊëòË¶ÅÔºöÊú¨Êñá‰ªãÁ¥πÊàëÂÄëÁ≥ªÁµ±Ë™™ÊòéÂíåÈåØË™§ÂàÜÊûêÔºåÊàëÂÄëÂú® NLLP 2024 ÂÖ±‰∫´‰ªªÂãô‰∏≠Êèê‰∫§ÁöÑÊ≥ïÂæãËá™ÁÑ∂Ë™ûË®ÄÊé®Ë´ñ (L-NLI) È†ÖÁõÆ
\citep{hagag2024legallenssharedtask2024}„ÄÇË©≤‰ªªÂãôÈúÄË¶ÅÂ∞áÈÄô‰∫õÈóú‰øÇÂàÜÈ°ûÁÇ∫ËòäÂê´„ÄÅÁüõÁõæÊàñ‰∏≠Á´ãÔºåÊåáÂá∫Ë©ïË´ñËàáÁî≥Ë®¥‰πãÈñìÁöÑ‰ªª‰ΩïÈóúËÅØ„ÄÇÊàëÂÄëÁöÑÁ≥ªÁµ±ÊàêÁÇ∫Áç≤ÂãùÊèê‰∫§ÔºåÈ°ØËëóÂÑ™ÊñºÂÖ∂‰ªñÊ¢ùÁõÆÔºå‰∏¶Âú®Ê≥ïÂæãÊñáÊú¨ÂàÜÊûê‰∏≠Ë≠âÊòé‰∫ÜÊàëÂÄëÊñπÊ≥ïÁöÑÊúâÊïàÊÄß„ÄÇÊàëÂÄëÂ∞çÊØèÂÄãÊ®°ÂûãÂíåÂ∑≤Ê∏¨Ë©¶ÊñπÊ≥ïÁöÑÂÑ™Âã¢ÂíåÈôêÂà∂ÈÄ≤Ë°å‰∫ÜË©≥Á¥∞ÂàÜÊûêÔºå‰∏¶Êèê‰æõ‰∫ÜÂæπÂ∫ïÁöÑÈåØË™§ÂàÜÊûêÂíåÊú™‰æÜÊîπÈÄ≤Âª∫Ë≠∞„ÄÇÊú¨ÊñáÊó®Âú®ÈÄöÈÅéÊèê‰æõÂ∞çÊ≥ïÂæãËÉåÊôØ‰∏≠Ëá™ÁÑ∂Ë™ûË®ÄÊé®Ë´ñÁöÑÂÖàÈÄ≤ÊäÄË°ìÁöÑË¶ãËß£ÔºåÁÇ∫Ê≥ïÂæã NLP ÁöÑÊàêÈï∑È†òÂüüÂÅöÂá∫Ë≤¢ÁçªÔºåËÆìË©≤È†òÂüüÁöÑÂ∞àÂÆ∂ÂíåÊñ∞ÊâãÈÉΩËÉΩÁêÜËß£„ÄÇ

##### **Analyzing Closed-loop Training Techniques for Realistic Traffic Agent Models in Autonomous Highway Driving Simulations**
2410.15987v1 by Matthias Bitzer, Reinis Cimurs, Benjamin Coors, Johannes Goth, Sebastian Ziesche, Philipp Geiger, Maximilian Naumann

Simulation plays a crucial role in the rapid development and safe deployment
of autonomous vehicles. Realistic traffic agent models are indispensable for
bridging the gap between simulation and the real world. Many existing
approaches for imitating human behavior are based on learning from
demonstration. However, these approaches are often constrained by focusing on
individual training strategies. Therefore, to foster a broader understanding of
realistic traffic agent modeling, in this paper, we provide an extensive
comparative analysis of different training principles, with a focus on
closed-loop methods for highway driving simulation. We experimentally compare
(i) open-loop vs. closed-loop multi-agent training, (ii) adversarial vs.
deterministic supervised training, (iii) the impact of reinforcement losses,
and (iv) the impact of training alongside log-replayed agents to identify
suitable training techniques for realistic agent modeling. Furthermore, we
identify promising combinations of different closed-loop training methods.

ÊëòË¶ÅÔºöÊ®°Êì¨Âú®Ëá™ÂãïÈßïÈßõËªäËºõÁöÑÂø´ÈÄüÈñãÁôºÂíåÂÆâÂÖ®ÈÉ®ÁΩ≤‰∏≠ÊâÆÊºîËëóËá≥ÈóúÈáçË¶ÅÁöÑËßíËâ≤„ÄÇÈÄºÁúüÁöÑ‰∫§ÈÄö‰ª£ÁêÜÊ®°ÂûãÂ∞çÊñºÁ∏ÆÂ∞èÊ®°Êì¨ÂíåÁèæÂØ¶‰∏ñÁïå‰πãÈñìÁöÑÂ∑ÆË∑ùËá≥ÈóúÈáçË¶Å„ÄÇË®±Â§öÁèæÊúâÁöÑÊ®°‰ªø‰∫∫È°ûË°åÁÇ∫ÁöÑÊñπÊ≥ïÈÉΩÊòØÂü∫ÊñºÁ§∫ÁØÑÂ≠∏Áøí„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÊñπÊ≥ïÈÄöÂ∏∏ÂèóÂà∞ÈóúÊ≥®ÊñºÂÄãÂà•Ë®ìÁ∑¥Á≠ñÁï•ÁöÑÈôêÂà∂„ÄÇÂõ†Ê≠§ÔºåÁÇ∫‰∫Ü‰øÉÈÄ≤Â∞çÁèæÂØ¶‰∫§ÈÄö‰ª£ÁêÜÂª∫Ê®°ÁöÑÊõ¥Âª£Ê≥õÁêÜËß£ÔºåÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèê‰æõ‰∫ÜÂ∞ç‰∏çÂêåË®ìÁ∑¥ÂéüÂâáÁöÑÂª£Ê≥õÊØîËºÉÂàÜÊûêÔºåÈáçÈªûÈóúÊ≥®Áî®ÊñºÈ´òÈÄüÂÖ¨Ë∑ØÈßïÈßõÊ®°Êì¨ÁöÑÈñâÁí∞ÊñπÊ≥ï„ÄÇÊàëÂÄëÈÄöÈÅéÂØ¶È©óÊØîËºÉ‰∫Ü (i) ÈñãÁí∞ËàáÈñâÁí∞Â§ö‰ª£ÁêÜË®ìÁ∑¥Ôºå(ii) Â∞çÊäóÂºèËàáÁ¢∫ÂÆöÊÄßÁõ£Áù£Ë®ìÁ∑¥Ôºå(iii) Âº∑ÂåñÊêçÂ§±ÁöÑÂΩ±ÈüøÔºå‰ª•Âèä (iv) ËàáÊó•Ë™åÈáçÊí≠‰ª£ÁêÜ‰∏ÄËµ∑Ë®ìÁ∑¥ÁöÑÂΩ±ÈüøÔºå‰ª•Ë≠òÂà•ÈÅ©ÂêàÊñºÁèæÂØ¶‰ª£ÁêÜÂª∫Ê®°ÁöÑË®ìÁ∑¥ÊäÄË°ì„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÈÇÑÁ¢∫ÂÆö‰∫Ü‰∏çÂêåÈñâÁí∞Ë®ìÁ∑¥ÊñπÊ≥ïÁöÑÊúâÂ∏åÊúõÁöÑÁµÑÂêà„ÄÇ

##### **PROMPTHEUS: A Human-Centered Pipeline to Streamline SLRs with LLMs**
2410.15978v2 by Jo√£o Pedro Fernandes Torres, Catherine Mulligan, Joaquim Jorge, Catarina Moreira

The growing volume of academic publications poses significant challenges for
researchers conducting timely and accurate Systematic Literature Reviews,
particularly in fast-evolving fields like artificial intelligence. This growth
of academic literature also makes it increasingly difficult for lay people to
access scientific knowledge effectively, meaning academic literature is often
misrepresented in the popular press and, more broadly, in society. Traditional
SLR methods are labor-intensive and error-prone, and they struggle to keep up
with the rapid pace of new research. To address these issues, we developed
\textit{PROMPTHEUS}: an AI-driven pipeline solution that automates the SLR
process using Large Language Models. We aimed to enhance efficiency by reducing
the manual workload while maintaining the precision and coherence required for
comprehensive literature synthesis. PROMPTHEUS automates key stages of the SLR
process, including systematic search, data extraction, topic modeling using
BERTopic, and summarization with transformer models. Evaluations conducted
across five research domains demonstrate that PROMPTHEUS reduces review time,
achieves high precision, and provides coherent topic organization, offering a
scalable and effective solution for conducting literature reviews in an
increasingly crowded research landscape. In addition, such tools may reduce the
increasing mistrust in science by making summarization more accessible to
laypeople.
  The code for this project can be found on the GitHub repository at
https://github.com/joaopftorres/PROMPTHEUS.git

ÊëòË¶ÅÔºö<paragraph>Â≠∏Ë°ìÂá∫ÁâàÂìÅÁöÑÊï∏ÈáèÊåÅÁ∫åÂ¢ûÂä†ÔºåÂ∞çÊñºÈÄ≤Ë°åÂèäÊôÇ‰∏îÊ∫ñÁ¢∫ÁöÑÁ≥ªÁµ±ÊÄßÊñáÁçªÂõûÈ°ßÁöÑÁ†îÁ©∂‰∫∫Âì°‰æÜË™™ÔºåÈÄôÊßãÊàê‰∫ÜÈáçÂ§ßÁöÑÊåëÊà∞ÔºåÁâπÂà•ÊòØÂú®ÂÉè‰∫∫Â∑•Êô∫ÊÖßÁ≠âÂø´ÈÄüÁôºÂ±ïÁöÑÈ†òÂüü‰∏≠„ÄÇÂ≠∏Ë°ìÊñáÁçªÁöÑÂ¢ûÈï∑‰πü‰ΩøÂæó‰∏ÄËà¨‰∫∫Ë∂ä‰æÜË∂äÈõ£‰ª•ÊúâÊïàÂú∞Áç≤ÂèñÁßëÂ≠∏Áü•Ë≠òÔºåÈÄôÊÑèÂë≥ËëóÂ≠∏Ë°ìÊñáÁçªÁ∂ìÂ∏∏Âú®ÈÄö‰øóÂ™íÈ´î‰∏≠Ë¢´ÈåØË™§ÂëàÁèæÔºåÊõ¥Âª£Ê≥õÂú∞Ë™™ÔºåÂú®Á§æÊúÉ‰∏≠‰πüÊòØÂ¶ÇÊ≠§„ÄÇÂÇ≥Áµ±ÁöÑÁ≥ªÁµ±ÊÄßÊñáÁçªÂõûÈ°ßÊñπÊ≥ïÊó¢Ë≤ªÂäõÂèàÂÆπÊòìÂá∫ÈåØÔºåËÄå‰∏îÈõ£‰ª•Ë∑ü‰∏äÊñ∞Á†îÁ©∂ÁöÑÂø´ÈÄüÊ≠•‰ºê„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÂïèÈ°åÔºåÊàëÂÄëÈñãÁôº‰∫ÜPROMPTHEUSÔºö‰∏ÄÁ®ÆÁî±Â§ßÂûãË™ûË®ÄÊ®°ÂûãËá™ÂãïÂåñÁ≥ªÁµ±ÊÄßÊñáÁçªÂõûÈ°ßÊµÅÁ®ãÁöÑ AI È©ÖÂãïÁÆ°ÈÅìËß£Ê±∫ÊñπÊ°à„ÄÇÊàëÂÄëÁöÑÁõÆÊ®ôÊòØÈÄöÈÅéÊ∏õÂ∞ëÊâãÂãïÂ∑•‰ΩúÈáè‰æÜÊèêÈ´òÊïàÁéáÔºåÂêåÊôÇ‰øùÊåÅÁ∂úÂêàÊñáÁçªÂêàÊàêÊâÄÈúÄÁöÑÁ≤æÁ¢∫ÊÄßÂíå‰∏ÄËá¥ÊÄß„ÄÇPROMPTHEUS Ëá™ÂãïÂåñ‰∫ÜÁ≥ªÁµ±ÊÄßÊñáÁçªÂõûÈ°ßÊµÅÁ®ãÁöÑ‰∏ªË¶ÅÈöéÊÆµÔºåÂåÖÊã¨Á≥ªÁµ±ÊÄßÊêúÂ∞ã„ÄÅË≥áÊñôËêÉÂèñ„ÄÅ‰ΩøÁî® BERTopic ÁöÑ‰∏ªÈ°åÂª∫Ê®°Ôºå‰ª•Âèä‰ΩøÁî®ËΩâÊèõÂô®Ê®°ÂûãÈÄ≤Ë°åÊëòË¶Å„ÄÇÂú®‰∫îÂÄãÁ†îÁ©∂È†òÂüüÈÄ≤Ë°åÁöÑË©ï‰º∞Ë°®ÊòéÔºåPROMPTHEUS Á∏ÆÁü≠‰∫ÜÂõûÈ°ßÊôÇÈñìÔºåÈÅîÂà∞‰∫ÜÈ´òÁ≤æÂ∫¶Ôºå‰∏¶Êèê‰æõ‰∫ÜÈÄ£Ë≤´ÁöÑ‰∏ªÈ°åÁµÑÁπîÔºåÁÇ∫Âú®Êó•ÁõäÊìÅÊì†ÁöÑÁ†îÁ©∂È†òÂüü‰∏≠ÈÄ≤Ë°åÊñáÁçªÂõûÈ°ßÊèê‰æõ‰∫Ü‰∏ÄÂÄãÂèØÊì¥ÂÖÖ‰∏îÊúâÊïàÁöÑËß£Ê±∫ÊñπÊ°à„ÄÇÊ≠§Â§ñÔºåÊ≠§È°ûÂ∑•ÂÖ∑ÂèØ‰ª•ËÆì‰∏ÄËà¨‰∫∫Êõ¥ÂÆπÊòìÂèñÂæóÊëòË¶ÅÔºåÂæûËÄåÊ∏õÂ∞ëÂ∞çÁßëÂ≠∏ÁöÑ‰∏ç‰ø°‰ªª„ÄÇÈÄôÂÄãÂ∞àÊ°àÁöÑÁ®ãÂºèÁ¢ºÂèØ‰ª•Âú® GitHub ÂÑ≤Â≠òÂ∫´‰∏≠ÊâæÂà∞ÔºåÁ∂≤ÂùÄÁÇ∫ https://github.com/joaopftorres/PROMPTHEUS.git</paragraph>

##### **Enabling Energy-Efficient Deployment of Large Language Models on Memristor Crossbar: A Synergy of Large and Small**
2410.15977v1 by Zhehui Wang, Tao Luo, Cheng Liu, Weichen Liu, Rick Siow Mong Goh, Weng-Fai Wong

Large language models (LLMs) have garnered substantial attention due to their
promising applications in diverse domains. Nevertheless, the increasing size of
LLMs comes with a significant surge in the computational requirements for
training and deployment. Memristor crossbars have emerged as a promising
solution, which demonstrated a small footprint and remarkably high energy
efficiency in computer vision (CV) models. Memristors possess higher density
compared to conventional memory technologies, making them highly suitable for
effectively managing the extreme model size associated with LLMs. However,
deploying LLMs on memristor crossbars faces three major challenges. Firstly,
the size of LLMs increases rapidly, already surpassing the capabilities of
state-of-the-art memristor chips. Secondly, LLMs often incorporate multi-head
attention blocks, which involve non-weight stationary multiplications that
traditional memristor crossbars cannot support. Third, while memristor
crossbars excel at performing linear operations, they are not capable of
executing complex nonlinear operations in LLM such as softmax and layer
normalization. To address these challenges, we present a novel architecture for
the memristor crossbar that enables the deployment of state-of-the-art LLM on a
single chip or package, eliminating the energy and time inefficiencies
associated with off-chip communication. Our testing on BERT_Large showed
negligible accuracy loss. Compared to traditional memristor crossbars, our
architecture achieves enhancements of up to 39X in area overhead and 18X in
energy consumption. Compared to modern TPU/GPU systems, our architecture
demonstrates at least a 68X reduction in the area-delay product and a
significant 69% energy consumption reduction.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âõ†ÂÖ∂Âú®ÂêÑÁ®ÆÈ†òÂüü‰∏≠ÂÖ∑ÊúâÂª£Ê≥õÁöÑÊáâÁî®ÂâçÊôØËÄåÂÇôÂèóÈóúÊ≥®„ÄÇÂÑòÁÆ°Â¶ÇÊ≠§ÔºåLLM ÁöÑË¶èÊ®°Êó•ÁõäÈæêÂ§ßÔºåÂ∞çË®ìÁ∑¥ÂíåÈÉ®ÁΩ≤ÁöÑË®àÁÆóÈúÄÊ±Ç‰πüÂ§ßÂπÖÂ¢ûÂä†„ÄÇÊÜ∂ÈòªÂô®‰∫§ÂèâÈô£ÂàóÂ∑≤ÊàêÁÇ∫‰∏ÄÁ®ÆÊúâÂâçÈÄîÁöÑËß£Ê±∫ÊñπÊ°àÔºåÂÆÉÂú®Ë®àÁÆóÊ©üË¶ñË¶∫ (CV) Ê®°Âûã‰∏≠Â±ïÁ§∫‰∫ÜËºÉÂ∞èÁöÑ‰ΩîÁî®Á©∫ÈñìÂíåÊ•µÈ´òÁöÑËÉΩÊïà„ÄÇËàáÂÇ≥Áµ±Ë®òÊÜ∂È´îÊäÄË°ìÁõ∏ÊØîÔºåÊÜ∂ÈòªÂô®ÂÖ∑ÊúâÊõ¥È´òÁöÑÂØÜÂ∫¶ÔºåÈÄô‰ΩøÂÖ∂ÈùûÂ∏∏ÈÅ©ÂêàÊúâÊïàÁÆ°ÁêÜËàá LLM Áõ∏ÈóúÁöÑÊ•µÁ´ØÊ®°ÂûãÂ§ßÂ∞è„ÄÇÁÑ∂ËÄåÔºåÂú®ÊÜ∂ÈòªÂô®‰∫§ÂèâÈô£Âàó‰∏äÈÉ®ÁΩ≤ LLM Èù¢Ëá®‰∏âÂ§ßÊåëÊà∞„ÄÇÈ¶ñÂÖàÔºåLLM ÁöÑË¶èÊ®°ËøÖÈÄüÊì¥Â§ßÔºåÂ∑≤Á∂ìË∂ÖÈÅé‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÊÜ∂ÈòªÂô®Êô∂ÁâáÁöÑÊïàËÉΩ„ÄÇÂÖ∂Ê¨°ÔºåLLM ÈÄöÂ∏∏ÂåÖÂê´Â§öÈ†≠Ê≥®ÊÑèÂäõÂçÄÂ°äÔºåÂÖ∂‰∏≠Ê∂âÂèäÈùûÊ¨äÈáçÂπ≥Á©©‰πòÊ≥ïÔºåËÄåÂÇ≥Áµ±ÁöÑÊÜ∂ÈòªÂô®‰∫§ÂèâÈô£ÂàóÁÑ°Ê≥ïÊîØÊè¥„ÄÇÁ¨¨‰∏âÔºåÂÑòÁÆ°ÊÜ∂ÈòªÂô®‰∫§ÂèâÈô£ÂàóÊìÖÈï∑Âü∑Ë°åÁ∑öÊÄßÈÅãÁÆóÔºå‰ΩÜÂÆÉÂÄëÁÑ°Ê≥ïÂü∑Ë°å LLM ‰∏≠ÁöÑË§áÈõúÈùûÁ∑öÊÄßÈÅãÁÆóÔºå‰æãÂ¶Ç softmax ÂíåÂ±§Ê®ôÊ∫ñÂåñ„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÁî®ÊñºÊÜ∂ÈòªÂô®‰∫§ÂèâÈô£ÂàóÁöÑÊñ∞Êû∂ÊßãÔºåË©≤Êû∂ÊßãÂèØ‰ª•Âú®ÂñÆ‰∏ÄÊô∂ÁâáÊàñÂ∞ÅË£ù‰∏äÈÉ®ÁΩ≤ÊúÄÂÖàÈÄ≤ÁöÑ LLMÔºåÂæûËÄåÊ∂àÈô§ËàáÊô∂ÁâáÂ§ñÈÄöË®äÁõ∏ÈóúÁöÑËÉΩËÄóÂíåÊôÇÈñìÊïàÁéá‰Ωé‰∏ã„ÄÇÊàëÂÄëÂú® BERT_Large ‰∏äÁöÑÊ∏¨Ë©¶È°ØÁ§∫Âá∫ÂèØ‰ª•ÂøΩÁï•‰∏çË®àÁöÑÊ∫ñÁ¢∫Â∫¶ÊêçÂ§±„ÄÇËàáÂÇ≥Áµ±ÁöÑÊÜ∂ÈòªÂô®‰∫§ÂèâÈô£ÂàóÁõ∏ÊØîÔºåÊàëÂÄëÁöÑÊû∂ÊßãÂú®Èù¢Á©çÈñãÈä∑ÊñπÈù¢ÊèêÂçá‰∫Ü 39 ÂÄçÔºåÂú®ËÉΩËÄóÊñπÈù¢ÊèêÂçá‰∫Ü 18 ÂÄç„ÄÇËàáÁèæ‰ª£ TPU/GPU Á≥ªÁµ±Áõ∏ÊØîÔºåÊàëÂÄëÁöÑÊû∂ÊßãÂú®Èù¢Á©çÂª∂ÈÅ≤‰πòÁ©çÊñπÈù¢Ëá≥Â∞ëÊ∏õÂ∞ë‰∫Ü 68 ÂÄçÔºåËÉΩËÄóÊñπÈù¢È°ØËëóÊ∏õÂ∞ë‰∫Ü 69%„ÄÇ

##### **Large Language Models for Cross-lingual Emotion Detection**
2410.15974v1 by Ram Mohan Rao Kadiyala

This paper presents a detailed system description of our entry for the WASSA
2024 Task 2, focused on cross-lingual emotion detection. We utilized a
combination of large language models (LLMs) and their ensembles to effectively
understand and categorize emotions across different languages. Our approach not
only outperformed other submissions with a large margin, but also demonstrated
the strength of integrating multiple models to enhance performance.
Additionally, We conducted a thorough comparison of the benefits and
limitations of each model used. An error analysis is included along with
suggested areas for future improvement. This paper aims to offer a clear and
comprehensive understanding of advanced techniques in emotion detection, making
it accessible even to those new to the field.

ÊëòË¶ÅÔºöÊú¨ÊñáË©≥Á¥∞Ë™™ÊòéÊàëÂÄëÂú® WASSA 2024 ‰ªªÂãô 2 ‰∏≠ÁöÑÂèÉË≥ΩÁ≥ªÁµ±ÔºåÈáçÈªûÂú®ÊñºË∑®Ë™ûË®ÄÁöÑÊÉÖÁ∑íÂÅµÊ∏¨„ÄÇÊàëÂÄëÂà©Áî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂèäÂÖ∂ÂêàÂ•èÔºåÊúâÊïàÂú∞ÁêÜËß£‰∏¶ÂàÜÈ°û‰∏çÂêåË™ûË®ÄÁöÑÊÉÖÁ∑í„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ï‰∏çÂÉÖÂ§ßÂπÖË∂ÖË∂äÂÖ∂‰ªñÊèê‰∫§ÁöÑ‰ΩúÂìÅÔºå‰πüË≠âÊòéÊï¥ÂêàÂ§öÁ®ÆÊ®°ÂûãÂèØ‰ª•ÊèêÂçáÊïàËÉΩ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂæπÂ∫ïÊØîËºÉ‰∫ÜÂêÑÂÄãÊ®°ÂûãÁöÑÂÑ™Áº∫Èªû„ÄÇÊú¨ÊñáÂåÖÂê´ÈåØË™§ÂàÜÊûêÔºå‰ª•ÂèäÂª∫Ë≠∞ÁöÑÊú™‰æÜÊîπÈÄ≤È†òÂüü„ÄÇÊú¨ÊñáÊó®Âú®Êèê‰æõÊ∏ÖÊô∞‰∏îÂÖ®Èù¢ÁöÑÈÄ≤ÈöéÊÉÖÁ∑íÂÅµÊ∏¨ÊäÄË°ìË™™ÊòéÔºåÂç≥‰ΩøÊòØË©≤È†òÂüüÁöÑÊñ∞Êâã‰πüËÉΩÁêÜËß£„ÄÇ

##### **Karush-Kuhn-Tucker Condition-Trained Neural Networks (KKT Nets)**
2410.15973v1 by Shreya Arvind, Rishabh Pomaje, Rajshekhar V Bhat

This paper presents a novel approach to solving convex optimization problems
by leveraging the fact that, under certain regularity conditions, any set of
primal or dual variables satisfying the Karush-Kuhn-Tucker (KKT) conditions is
necessary and sufficient for optimality. Similar to Theory-Trained Neural
Networks (TTNNs), the parameters of the convex optimization problem are input
to the neural network, and the expected outputs are the optimal primal and dual
variables. A choice for the loss function in this case is a loss, which we
refer to as the KKT Loss, that measures how well the network's outputs satisfy
the KKT conditions. We demonstrate the effectiveness of this approach using a
linear program as an example. For this problem, we observe that minimizing the
KKT Loss alone outperforms training the network with a weighted sum of the KKT
Loss and a Data Loss (the mean-squared error between the ground truth optimal
solutions and the network's output). Moreover, minimizing only the Data Loss
yields inferior results compared to those obtained by minimizing the KKT Loss.
While the approach is promising, the obtained primal and dual solutions are not
sufficiently close to the ground truth optimal solutions. In the future, we aim
to develop improved models to obtain solutions closer to the ground truth and
extend the approach to other problem classes.

ÊëòË¶ÅÔºöÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆËß£Ê±∫Âá∏ÂÑ™ÂåñÂïèÈ°åÁöÑÊñ∞ÊñπÊ≥ïÔºåÊñπÊ≥ïÊòØÂà©Áî®Âú®ÁâπÂÆöË¶èÂâáÊ¢ù‰ª∂‰∏ãÔºå‰ªª‰ΩïÊªøË∂≥ Karush-Kuhn-Tucker (KKT) Ê¢ù‰ª∂ÁöÑÂéüÂßãÊàñÂ∞çÂÅ∂ËÆäÊï∏ÁµÑÂ∞çÊñºÊúÄÂÑ™ÊÄßËÄåË®ÄÊòØÂøÖË¶Å‰∏îÂÖÖÂàÜÁöÑ‰∫ãÂØ¶„ÄÇÈ°û‰ººÊñºÁêÜË´ñË®ìÁ∑¥Á•ûÁ∂ìÁ∂≤Ë∑Ø (TTNN)ÔºåÂá∏ÂÑ™ÂåñÂïèÈ°åÁöÑÂèÉÊï∏ÊúÉËº∏ÂÖ•Á•ûÁ∂ìÁ∂≤Ë∑ØÔºåËÄåÈ†êÊúüÁöÑËº∏Âá∫ÊòØÊúÄ‰Ω≥ÂéüÂßãÂíåÂ∞çÂÅ∂ËÆäÊï∏„ÄÇÂú®ÈÄôÁ®ÆÊÉÖÊ≥Å‰∏ãÔºåÊêçÂ§±ÂáΩÊï∏ÁöÑÈÅ∏ÊìáÊòØ‰∏ÄÁ®ÆÊêçÂ§±ÔºåÊàëÂÄëÁ®±‰πãÁÇ∫ KKT ÊêçÂ§±ÔºåÂÆÉË°°ÈáèÁ∂≤Ë∑ØËº∏Âá∫ÊªøË∂≥ KKT Ê¢ù‰ª∂ÁöÑÁ®ãÂ∫¶„ÄÇÊàëÂÄë‰ª•Á∑öÊÄßË¶èÂäÉÁÇ∫‰æãÔºåÂ±ïÁ§∫‰∫ÜÈÄôÁ®ÆÊñπÊ≥ïÁöÑÊúâÊïàÊÄß„ÄÇÂ∞çÊñºÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëËßÄÂØüÂà∞ÂÉÖÊúÄÂ∞èÂåñ KKT ÊêçÂ§±Â∞±ÂÑ™Êñº‰ΩøÁî® KKT ÊêçÂ§±ÂíåË≥áÊñôÊêçÂ§±ÔºàÂú∞Èù¢ÂØ¶Ê≥ÅÊúÄ‰Ω≥Ëß£ËàáÁ∂≤Ë∑ØËº∏Âá∫‰πãÈñìÁöÑÂùáÊñπË™§Â∑ÆÔºâÁöÑÂä†Ê¨äÂíå‰æÜË®ìÁ∑¥Á∂≤Ë∑Ø„ÄÇÊ≠§Â§ñÔºåÂÉÖÊúÄÂ∞èÂåñË≥áÊñôÊêçÂ§±ÊúÉÁî¢ÁîüÂä£ÊñºÊúÄÂ∞èÂåñ KKT ÊêçÂ§±ÁöÑÁµêÊûú„ÄÇÈõñÁÑ∂ÈÄôÁ®ÆÊñπÊ≥ïÂæàÊúâÂ∏åÊúõÔºå‰ΩÜÁç≤ÂæóÁöÑÂéüÂßãÂíåÂ∞çÂÅ∂Ëß£‰∏¶‰∏çË∂≥‰ª•Êé•ËøëÂú∞Èù¢ÂØ¶Ê≥ÅÁöÑÊúÄ‰Ω≥Ëß£„ÄÇÊú™‰æÜÔºåÊàëÂÄëÊó®Âú®ÈñãÁôºÊîπÈÄ≤ÁöÑÊ®°ÂûãÔºå‰ª•Áç≤ÂæóÊõ¥Êé•ËøëÂú∞Èù¢ÂØ¶Ê≥ÅÁöÑËß£Ôºå‰∏¶Â∞áÈÄôÁ®ÆÊñπÊ≥ïÊì¥Â±ïÂà∞ÂÖ∂‰ªñÂïèÈ°åÈ°ûÂà•„ÄÇ

##### **Policy-driven Knowledge Selection and Response Generation for Document-grounded Dialogue**
2410.15970v1 by Longxuan Ma, Jiapeng Li, Mingda Li, Wei-Nan Zhang, Ting Liu

Document-grounded dialogue (DGD) uses documents as external knowledge for
dialogue generation. Correctly understanding the dialogue context is crucial
for selecting knowledge from the document and generating proper responses. In
this paper, we propose using a dialogue policy to help the dialogue
understanding in DGD. Our dialogue policy consists of two kinds of guiding
signals: utterance function and topic transfer intent. The utterance function
reflects the purpose and style of an utterance, and the topic transfer intent
reflects the topic and content of an utterance. We propose a novel framework
exploiting our dialogue policy for two core tasks in DGD, namely knowledge
selection (KS) and response generation (RG). The framework consists of two
modules: the Policy planner leverages policy-aware dialogue representation to
select knowledge and predict the policy of the response; the generator uses
policy/knowledge-aware dialogue representation for response generation. Our
policy-driven model gets state-of-the-art performance on three public
benchmarks and we provide a detailed analysis of the experimental results. Our
code/data will be released on GitHub.

ÊëòË¶ÅÔºöÊñá‰ª∂Âü∫Á§éÂ∞çË©± (DGD) ‰ΩøÁî®Êñá‰ª∂‰ΩúÁÇ∫Â∞çË©±Áî¢ÁîüÁöÑÂ§ñÈÉ®Áü•Ë≠ò„ÄÇÊ≠£Á¢∫ÁêÜËß£Â∞çË©±ÂÖßÂÆπÂ∞çÊñºÂæûÊñá‰ª∂‰∏≠ÈÅ∏ÂèñÁü•Ë≠ò‰∏¶Áî¢ÁîüÈÅ©Áï∂ÂõûÊáâËá≥ÈóúÈáçË¶Å„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂª∫Ë≠∞‰ΩøÁî®Â∞çË©±Á≠ñÁï•‰æÜÂçîÂä© DGD ‰∏≠ÁöÑÂ∞çË©±ÁêÜËß£„ÄÇÊàëÂÄëÁöÑÂ∞çË©±Á≠ñÁï•ÂåÖÂê´ÂÖ©Á®ÆÊåáÂ∞é‰ø°ËôüÔºöÁôºË©±ÂäüËÉΩÂíå‰∏ªÈ°åËΩâÁßªÊÑèÂúñ„ÄÇÁôºË©±ÂäüËÉΩÂèçÊò†ÁôºË©±ÁöÑÁõÆÁöÑÂíåÈ¢®Ê†ºÔºåËÄå‰∏ªÈ°åËΩâÁßªÊÑèÂúñÂèçÊò†ÁôºË©±ÁöÑ‰∏ªÈ°åÂíåÂÖßÂÆπ„ÄÇÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÊñ∞Á©éÁöÑÊû∂ÊßãÔºåÂà©Áî®ÊàëÂÄëÁöÑÂ∞çË©±Á≠ñÁï•‰æÜÂü∑Ë°å DGD ‰∏≠ÁöÑÂÖ©ÂÄãÊ†∏ÂøÉ‰ªªÂãôÔºåÂç≥Áü•Ë≠òÈÅ∏Âèñ (KS) ÂíåÂõûÊáâÁî¢Áîü (RG)„ÄÇË©≤Êû∂ÊßãÂåÖÂê´ÂÖ©ÂÄãÊ®°ÁµÑÔºöÁ≠ñÁï•Ë¶èÂäÉÂô®Âà©Áî®Á≠ñÁï•ÊÑüÁü•Â∞çË©±Ë°®Á§∫‰æÜÈÅ∏ÂèñÁü•Ë≠ò‰∏¶È†êÊ∏¨ÂõûÊáâÁöÑÁ≠ñÁï•ÔºõÁî¢ÁîüÂô®‰ΩøÁî®Á≠ñÁï•/Áü•Ë≠òÊÑüÁü•Â∞çË©±Ë°®Á§∫‰æÜÁî¢ÁîüÂõûÊáâ„ÄÇÊàëÂÄëÁöÑÁ≠ñÁï•È©ÖÂãïÊ®°ÂûãÂú®‰∏âÂÄãÂÖ¨ÂÖ±Âü∫Ê∫ñÊ∏¨Ë©¶‰∏≠Áç≤ÂæóÊúÄÂÖàÈÄ≤ÁöÑÊïàËÉΩÔºåÊàëÂÄëÊèê‰æõ‰∫ÜÂØ¶È©óÁµêÊûúÁöÑË©≥Á¥∞ÂàÜÊûê„ÄÇÊàëÂÄëÁöÑÁ®ãÂºèÁ¢º/Ë≥áÊñôÂ∞áÂú® GitHub ‰∏äÁôºÂ∏É„ÄÇ

##### **Self-Explained Keywords Empower Large Language Models for Code Generation**
2410.15966v1 by Lishui Fan, Mouxiang Chen, Zhongxin Liu

Large language models (LLMs) have achieved impressive performance in code
generation. However, due to the long-tail distribution of LLMs' training data,
low-frequency terms are typically underrepresented in the training process.
Consequently, LLMs often misunderstand or overlook problem-specific,
low-frequency keywords during code generation, compromising the accuracy of the
generated code. To address this, we propose a novel technique named
SEK(\textbf{S}elf-\textbf{E}xplained \textbf{K}eywords), which empowers an LLM
for better code generation by extracting and explaining the key terms in the
problem description with the LLM itself and ranking them based on frequency.
Comprehensive experiments across three benchmarks, i.e., HumanEval(+), MBPP(+),
and APPS, with five representative LLMs, show that SEK can significantly
improve LLMs in code generation, yielding substantial and consistent gains. For
instance, SEK improves the Pass@1 of DeepSeek-Coder-V2-Instruct from 85.4\% to
93.3\% on the Humaneval benchmark. Further analysis confirms that SEK enables
the LLMs to shift their attention from low-frequency keywords to their
corresponding high-frequency counterparts.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®Á®ãÂºèÁ¢ºÁîüÊàê‰∏≠Â∑≤ÂèñÂæó‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑË°®Áèæ„ÄÇÁÑ∂ËÄåÔºåÁî±Êñº LLM Ë®ìÁ∑¥Ë≥áÊñôÁöÑÈï∑Â∞æÂàÜÂ∏ÉÔºå‰ΩéÈ†ªÁéáË°ìË™ûÈÄöÂ∏∏Âú®Ë®ìÁ∑¥ÈÅéÁ®ã‰∏≠‰ª£Ë°®ÊÄß‰∏çË∂≥„ÄÇÂõ†Ê≠§ÔºåLLM Âú®Á®ãÂºèÁ¢ºÁîüÊàêÈÅéÁ®ã‰∏≠Á∂ìÂ∏∏Ë™§Ëß£ÊàñÂøΩÁï•ÁâπÂÆöÊñºÂïèÈ°åÁöÑ‰ΩéÈ†ªÁéáÈóúÈçµÂ≠óÔºåÊêçÂÆ≥‰∫ÜÊâÄÁîüÊàêÁ®ãÂºèÁ¢ºÁöÑÊ∫ñÁ¢∫ÊÄß„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂêçÁÇ∫ SEKÔºà**S**elf-**E**xplained **K**eywordsÔºâÁöÑÊñ∞ÊäÄË°ìÔºåÂÆÉÈÄöÈÅé‰ΩøÁî® LLM Êú¨Ë∫´ÂæûÂïèÈ°åÊèèËø∞‰∏≠ÊèêÂèñÂíåËß£ÈáãÈóúÈçµË°ìË™û‰∏¶Ê†πÊìöÈ†ªÁéáÂ∞çÂÆÉÂÄëÈÄ≤Ë°åÊéíÂ∫èÔºåË≥¶‰∫à LLM Êõ¥Â•ΩÁöÑÁ®ãÂºèÁ¢ºÁîüÊàêËÉΩÂäõ„ÄÇÂú®‰∏âÂÄãÂü∫Ê∫ñÔºåÂç≥ HumanEval(+)„ÄÅMBPP(+) Âíå APPSÔºå‰ª•Âèä‰∫îÂÄãÂÖ∑Êúâ‰ª£Ë°®ÊÄßÁöÑ LLM ‰∏äÈÄ≤Ë°åÁöÑÁ∂úÂêàÂØ¶È©óË°®ÊòéÔºåSEK ÂèØ‰ª•È°ØËëóÊîπÂñÑ LLM Âú®Á®ãÂºèÁ¢ºÁîüÊàê‰∏≠ÁöÑË°®ÁèæÔºåÁî¢ÁîüÈ°ØËëó‰∏î‰∏ÄËá¥ÁöÑÊî∂Áõä„ÄÇ‰æãÂ¶ÇÔºåSEK Â∞á DeepSeek-Coder-V2-Instruct Âú® Humaneval Âü∫Ê∫ñ‰∏äÁöÑ Pass@1 Âæû 85.4% ÊèêÈ´òÂà∞ 93.3%„ÄÇÈÄ≤‰∏ÄÊ≠•ÁöÑÂàÜÊûêË≠âÂØ¶ÔºåSEK ‰Ωø LLM ËÉΩÂ§†Â∞áÊ≥®ÊÑèÂäõÂæû‰ΩéÈ†ªÁéáÈóúÈçµÂ≠óËΩâÁßªÂà∞ÂÆÉÂÄëÂ∞çÊáâÁöÑÈ´òÈ†ªÁéáÂ∞çÊáâË©û„ÄÇ

##### **Systematic Exploration of Dialogue Summarization Approaches for Reproducibility, Comparative Assessment, and Methodological Innovations for Advancing Natural Language Processing in Abstractive Summarization**
2410.15962v1 by Yugandhar Reddy Gogireddy, Jithendra Reddy Gogireddy

Reproducibility in scientific research, particularly within the realm of
natural language processing (NLP), is essential for validating and verifying
the robustness of experimental findings. This paper delves into the
reproduction and evaluation of dialogue summarization models, focusing
specifically on the discrepancies observed between original studies and our
reproduction efforts. Dialogue summarization is a critical aspect of NLP,
aiming to condense conversational content into concise and informative
summaries, thus aiding in efficient information retrieval and decision-making
processes. Our research involved a thorough examination of several dialogue
summarization models using the AMI (Augmented Multi-party Interaction) dataset.
The models assessed include Hierarchical Memory Networks (HMNet) and various
versions of Pointer-Generator Networks (PGN), namely PGN(DKE), PGN(DRD),
PGN(DTS), and PGN(DALL). The primary objective was to evaluate the
informativeness and quality of the summaries generated by these models through
human assessment, a method that introduces subjectivity and variability in the
evaluation process. The analysis began with Dataset 1, where the sample
standard deviation of 0.656 indicated a moderate dispersion of data points
around the mean.

ÊëòË¶ÅÔºöÂú®ÁßëÂ≠∏Á†îÁ©∂‰∏≠ÔºåÁâπÂà•ÊòØÂú®Ëá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ (NLP) È†òÂüüÔºåÂèØÈáçË§áÊÄßÂ∞çÊñºÈ©óË≠âÂíåÈ©óË≠âÂØ¶È©óÁµêÊûúÁöÑÁ©©ÂÅ•ÊÄßËá≥ÈóúÈáçË¶Å„ÄÇÊú¨ÊñáÊ∑±ÂÖ•Êé¢Ë®éÂ∞çË©±ÊëòË¶ÅÊ®°ÂûãÁöÑÈáçÁèæÂíåË©ï‰º∞ÔºåÁâπÂà•ÈóúÊ≥®ÂéüÂßãÁ†îÁ©∂ÂíåÊàëÂÄëÁöÑÈáçÁèæÂ∑•‰Ωú‰πãÈñìËßÄÂØüÂà∞ÁöÑÂ∑ÆÁï∞„ÄÇÂ∞çË©±ÊëòË¶ÅÊòØ NLP ÁöÑ‰∏ÄÂÄãÈóúÈçµÊñπÈù¢ÔºåÊó®Âú®Â∞áÂ∞çË©±ÂÖßÂÆπÊøÉÁ∏ÆÊàêÁ∞°ÊΩî‰∏îÊúâË≥áË®äÊÄßÁöÑÊëòË¶ÅÔºåÂæûËÄåÊúâÂä©ÊñºÊúâÊïàÁöÑË≥áË®äÊ™¢Á¥¢ÂíåÊ±∫Á≠ñÂà∂ÂÆöÈÅéÁ®ã„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂Ê∂âÂèä‰ΩøÁî® AMIÔºàÊì¥Â¢ûÂ§öÊñπ‰∫íÂãïÔºâË≥áÊñôÈõÜÂ∞çÂπæÂÄãÂ∞çË©±ÊëòË¶ÅÊ®°ÂûãÈÄ≤Ë°åÂæπÂ∫ïÁöÑÊ™¢È©ó„ÄÇË©ï‰º∞ÁöÑÊ®°ÂûãÂåÖÊã¨ÈöéÂ±§Ë®òÊÜ∂Á∂≤Ë∑Ø (HMNet) ÂíåÂêÑÁ®ÆÁâàÊú¨ÁöÑÊåáÊ®ôÁîüÊàêÂô®Á∂≤Ë∑Ø (PGN)ÔºåÂç≥ PGN(DKE)„ÄÅPGN(DRD)„ÄÅPGN(DTS) Âíå PGN(DALL)„ÄÇ‰∏ªË¶ÅÁõÆÊ®ôÊòØÈÄèÈÅé‰∫∫Â∑•Ë©ï‰º∞‰æÜË©ï‰º∞ÈÄô‰∫õÊ®°ÂûãÁî¢ÁîüÁöÑÊëòË¶ÅÁöÑË≥áË®äÊÄßÂíåÂìÅË≥™ÔºåÈÄôÁ®ÆÊñπÊ≥ïÂú®Ë©ï‰º∞ÈÅéÁ®ã‰∏≠ÂºïÂÖ•‰∫Ü‰∏ªËßÄÊÄßÂíåÂèØËÆäÊÄß„ÄÇÂàÜÊûêÂæûË≥áÊñôÈõÜ 1 ÈñãÂßãÔºåÂÖ∂‰∏≠Ê®£Êú¨Ê®ôÊ∫ñÂ∑ÆÁÇ∫ 0.656ÔºåË°®Á§∫Ë≥áÊñôÈªûÂú®Âπ≥ÂùáÂÄºÂë®ÂúçÊúâÈÅ©Â∫¶ÁöÑÂàÜÊï£„ÄÇ

##### **Do Large Language Models Have an English Accent? Evaluating and Improving the Naturalness of Multilingual LLMs**
2410.15956v1 by Yanzhu Guo, Simone Conia, Zelin Zhou, Min Li, Saloni Potdar, Henry Xiao

Current Large Language Models (LLMs) are predominantly designed with English
as the primary language, and even the few that are multilingual tend to exhibit
strong English-centric biases. Much like speakers who might produce awkward
expressions when learning a second language, LLMs often generate unnatural
outputs in non-English languages, reflecting English-centric patterns in both
vocabulary and grammar. Despite the importance of this issue, the naturalness
of multilingual LLM outputs has received limited attention. In this paper, we
address this gap by introducing novel automatic corpus-level metrics to assess
the lexical and syntactic naturalness of LLM outputs in a multilingual context.
Using our new metrics, we evaluate state-of-the-art LLMs on a curated benchmark
in French and Chinese, revealing a tendency towards English-influenced
patterns. To mitigate this issue, we also propose a simple and effective
alignment method to improve the naturalness of an LLM in a target language and
domain, achieving consistent improvements in naturalness without compromising
the performance on general-purpose benchmarks. Our work highlights the
importance of developing multilingual metrics, resources and methods for the
new wave of multilingual LLMs.

ÊëòË¶ÅÔºöÁõÆÂâçÁöÑÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâ‰∏ªË¶ÅÊòØ‰ª•Ëã±Ë™û‰ΩúÁÇ∫‰∏ªË¶ÅË™ûË®ÄË®≠Ë®àÁöÑÔºåÂç≥‰ΩøÊòØÂ∞ëÊï∏ÁöÑÂ§öË™ûË®ÄÊ®°Âûã‰πüÂÇæÂêëÊñºË°®ÁèæÂá∫Âº∑ÁÉàÁöÑ‰ª•Ëã±Ë™ûÁÇ∫‰∏≠ÂøÉÁöÑÂÅèË¶ã„ÄÇÂ∞±ÂÉèÂ≠∏ÁøíÁ¨¨‰∫åË™ûË®ÄÊôÇÂèØËÉΩÊúÉÁî¢ÁîüÂ•áÊÄ™Ë°®ÈÅîÊñπÂºèÁöÑË™™Ë©±ËÄÖ‰∏ÄÊ®£ÔºåLLM ÈÄöÂ∏∏ÊúÉ‰ª•ÈùûËã±Ë™ûË™ûË®ÄÁî¢Áîü‰∏çËá™ÁÑ∂ÁöÑËº∏Âá∫ÔºåÂèçÊò†Âú®Ë©ûÂΩôÂíåË™ûÊ≥ï‰∏≠‰ª•Ëã±Ë™ûÁÇ∫‰∏≠ÂøÉÁöÑÊ®°Âºè„ÄÇÂÑòÁÆ°ÈÄôÂÄãÂïèÈ°åÂæàÈáçË¶ÅÔºå‰ΩÜÂ§öË™ûË®Ä LLM Áî¢Âá∫ÁöÑËá™ÁÑ∂ÊÄßÂçªÂæàÂ∞ëÂèóÂà∞ÈóúÊ≥®„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÈÄèÈÅéÂºïÂÖ•Êñ∞ÁöÑËá™ÂãïË™ûÊñôÂ∫´Á¥öÂ∫¶ÈáèÂ∫¶‰æÜËß£Ê±∫ÈÄôÂÄãÂ∑ÆË∑ùÔºå‰ª•Ë©ï‰º∞Â§öË™ûË®ÄÁí∞Â¢É‰∏≠ LLM Áî¢Âá∫ÁöÑË©ûÂΩôÂíåÂè•Ê≥ïËá™ÁÑ∂ÊÄß„ÄÇ‰ΩøÁî®ÊàëÂÄëÊñ∞ÁöÑÂ∫¶ÈáèÊ®ôÊ∫ñÔºåÊàëÂÄëË©ï‰º∞‰∫ÜÊ≥ïË™ûÂíå‰∏≠ÊñáÁ≤æÈÅ∏Âü∫Ê∫ñ‰∏äÁöÑÊúÄÊñ∞ LLMÔºåÊè≠Á§∫‰∫ÜÂèóËã±Ë™ûÂΩ±ÈüøÁöÑÊ®°ÂºèÁöÑË∂®Âã¢„ÄÇÁÇ∫‰∫ÜÊ∏õËºïÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÈÇÑÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÁ∞°ÂñÆ‰∏îÊúâÊïàÁöÑÊñπÊ≥ïÔºå‰ª•ÊèêÈ´ò LLM Âú®ÁõÆÊ®ôË™ûË®ÄÂíåÈ†òÂüü‰∏≠ÁöÑËá™ÁÑ∂ÊÄßÔºåÂú®‰∏çÂΩ±ÈüøÈÄöÁî®Âü∫Ê∫ñÊïàËÉΩÁöÑÊÉÖÊ≥Å‰∏ãÔºåÊåÅÁ∫åÊîπÂñÑËá™ÁÑ∂ÊÄß„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÈáçÈªûË™™Êòé‰∫ÜÁÇ∫Êñ∞‰∏ÄÊ≥¢ÁöÑÂ§öË™ûË®Ä LLM ÈñãÁôºÂ§öË™ûË®ÄÂ∫¶ÈáèÊ®ôÊ∫ñ„ÄÅË≥áÊ∫êÂíåÊñπÊ≥ïÁöÑÈáçË¶ÅÊÄß„ÄÇ

##### **TS-ACL: A Time Series Analytic Continual Learning Framework for Privacy-Preserving and Class-Incremental Pattern Recognition**
2410.15954v1 by Kejia Fan, Jiaxu Li, Songning Lai, Linpu Lv, Anfeng Liu, Jianheng Tang, Houbing Herbert Song, Huiping Zhuang

Class-incremental Learning (CIL) in Time Series Classification (TSC) aims to
incrementally train models using the streaming time series data that arrives
continuously. The main problem in this scenario is catastrophic forgetting,
i.e., training models with new samples inevitably leads to the forgetting of
previously learned knowledge. Among existing methods, the replay-based methods
achieve satisfactory performance but compromise privacy, while exemplar-free
methods protect privacy but suffer from low accuracy. However, more critically,
owing to their reliance on gradient-based update techniques, these existing
methods fundamentally cannot solve the catastrophic forgetting problem. In TSC
scenarios with continuously arriving data and temporally shifting
distributions, these methods become even less practical. In this paper, we
propose a Time Series Analytic Continual Learning framework, called TS-ACL.
Inspired by analytical learning, TS-ACL transforms neural network updates into
gradient-free linear regression problems, thereby fundamentally mitigating
catastrophic forgetting. Specifically, employing a pre-trained and frozen
feature extraction encoder, TS-ACL only needs to update its analytic classifier
recursively in a lightweight manner that is highly suitable for real-time
applications and large-scale data processing. Additionally, we theoretically
demonstrate that the model obtained recursively through the TS-ACL is exactly
equivalent to a model trained on the complete dataset in a centralized manner,
thereby establishing the property of absolute knowledge memory. Extensive
experiments validate the superior performance of our TS-ACL.

ÊëòË¶ÅÔºöÊôÇÈñìÂ∫èÂàóÂàÜÈ°û (TSC) ‰∏≠ÁöÑÈ°ûÂà•Â¢ûÈáèÂ≠∏Áøí (CIL) Êó®Âú®‰ΩøÁî®ÊåÅÁ∫åÊäµÈÅîÁöÑ‰∏≤ÊµÅÊôÇÈñìÂ∫èÂàóË≥áÊñôÈÄêÊ≠•Ë®ìÁ∑¥Ê®°Âûã„ÄÇÊ≠§ÊÉÖÂ¢É‰∏≠ÁöÑ‰∏ªË¶ÅÂïèÈ°åÊòØÁÅΩÈõ£ÊÄßÈÅ∫ÂøòÔºåÂç≥‰ΩøÁî®Êñ∞ÁØÑ‰æãË®ìÁ∑¥Ê®°ÂûãÁÑ°ÂèØÈÅøÂÖçÂú∞ÊúÉÈÅ∫ÂøòÂÖàÂâçÂ≠∏ÁøíÂà∞ÁöÑÁü•Ë≠ò„ÄÇÂú®ÁèæÊúâÊñπÊ≥ï‰∏≠ÔºåÂü∫ÊñºÈáçÊí≠ÁöÑÊñπÊ≥ïÂèØÈÅîÊàê‰ª§‰∫∫ÊªøÊÑèÁöÑÊïàËÉΩÔºå‰ΩÜÊúÉÂç±ÂÆ≥Èö±ÁßÅÔºåËÄåÁÑ°ÁØÑ‰æãÊñπÊ≥ïÂâáÂèØ‰øùË≠∑Èö±ÁßÅÔºå‰ΩÜÊ∫ñÁ¢∫Â∫¶ËºÉ‰Ωé„ÄÇÁÑ∂ËÄåÔºåÊõ¥ÈáçË¶ÅÁöÑÊòØÔºåÁî±ÊñºÈÄô‰∫õÁèæÊúâÊñπÊ≥ï‰æùË≥¥ÊñºÂü∫ÊñºÊ¢ØÂ∫¶ÁöÑÊõ¥Êñ∞ÊäÄË°ìÔºåÂõ†Ê≠§ÂÆÉÂÄëÂú®Ê†πÊú¨‰∏äÁÑ°Ê≥ïËß£Ê±∫ÁÅΩÈõ£ÊÄßÈÅ∫ÂøòÂïèÈ°å„ÄÇÂú®Ë≥áÊñôÊåÅÁ∫åÊäµÈÅî‰∏îÂàÜ‰ΩàÊúÉÈö®ÊôÇÈñìÊé®ÁßªÁöÑ TSC ÊÉÖÂ¢É‰∏≠ÔºåÈÄô‰∫õÊñπÊ≥ïËÆäÂæóÊõ¥‰∏çÂàáÂØ¶Èöõ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂêçÁÇ∫ TS-ACL ÁöÑÊôÇÈñìÂ∫èÂàóÂàÜÊûêÊåÅÁ∫åÂ≠∏ÁøíÊû∂Êßã„ÄÇÂèóÂà∞ÂàÜÊûêÂ≠∏ÁøíÁöÑÂïüÁôºÔºåTS-ACL Â∞áÁ•ûÁ∂ìÁ∂≤Ë∑ØÊõ¥Êñ∞ËΩâÊèõÁÇ∫ÁÑ°Ê¢ØÂ∫¶ÁöÑÁ∑öÊÄßÂõûÊ≠∏ÂïèÈ°åÔºåÂæûËÄåÂæûÊ†πÊú¨‰∏äÊ∏õËºïÁÅΩÈõ£ÊÄßÈÅ∫Âøò„ÄÇÂÖ∑È´î‰æÜË™™ÔºåTS-ACL ÂÉÖÈúÄ‰ΩøÁî®È†êÂÖàË®ìÁ∑¥‰∏îÂáçÁµêÁöÑÁâπÂæµËêÉÂèñÁ∑®Á¢ºÂô®ÔºåÂ∞±ËÉΩ‰ª•ËºïÈáèÁ¥öÁöÑÊñπÂºèÈÅûËø¥Êõ¥Êñ∞ÂÖ∂ÂàÜÊûêÂàÜÈ°ûÂô®ÔºåÈùûÂ∏∏ÈÅ©ÂêàÊñºÂç≥ÊôÇÊáâÁî®Á®ãÂºèÂíåÂ§ßË¶èÊ®°Ë≥áÊñôËôïÁêÜ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂú®ÁêÜË´ñ‰∏äË≠âÊòéÔºåÈÄèÈÅé TS-ACL ÈÅûËø¥ÂèñÂæóÁöÑÊ®°ÂûãËàá‰ª•ÈõÜ‰∏≠ÊñπÂºèÂú®ÂÆåÊï¥Ë≥áÊñôÈõÜ‰∏äË®ìÁ∑¥ÁöÑÊ®°ÂûãÂÆåÂÖ®Á≠âÊïàÔºåÂæûËÄåÂª∫Á´ãÁµïÂ∞çÁü•Ë≠òË®òÊÜ∂ÁöÑÁâπÊÄß„ÄÇÂª£Ê≥õÁöÑÂØ¶È©óÈ©óË≠â‰∫ÜÊàëÂÄëÁöÑ TS-ACL ÁöÑÂçìË∂äÊïàËÉΩ„ÄÇ

##### **User-centric evaluation of explainability of AI with and for humans: a comprehensive empirical study**
2410.15952v1 by Szymon Bobek, Paloma Koryci≈Ñska, Monika Krakowska, Maciej Mozolewski, Dorota Rak, Magdalena Zych, Magdalena W√≥jcik, Grzegorz J. Nalepa

This study is located in the Human-Centered Artificial Intelligence (HCAI)
and focuses on the results of a user-centered assessment of commonly used
eXplainable Artificial Intelligence (XAI) algorithms, specifically
investigating how humans understand and interact with the explanations provided
by these algorithms. To achieve this, we employed a multi-disciplinary approach
that included state-of-the-art research methods from social sciences to measure
the comprehensibility of explanations generated by a state-of-the-art lachine
learning model, specifically the Gradient Boosting Classifier (XGBClassifier).
We conducted an extensive empirical user study involving interviews with 39
participants from three different groups, each with varying expertise in data
science, data visualization, and domain-specific knowledge related to the
dataset used for training the machine learning model. Participants were asked a
series of questions to assess their understanding of the model's explanations.
To ensure replicability, we built the model using a publicly available dataset
from the UC Irvine Machine Learning Repository, focusing on edible and
non-edible mushrooms. Our findings reveal limitations in existing XAI methods
and confirm the need for new design principles and evaluation techniques that
address the specific information needs and user perspectives of different
classes of AI stakeholders. We believe that the results of our research and the
cross-disciplinary methodology we developed can be successfully adapted to
various data types and user profiles, thus promoting dialogue and address
opportunities in HCAI research. To support this, we are making the data
resulting from our study publicly available.

ÊëòË¶ÅÔºöÊú¨Á†îÁ©∂‰ΩçÊñº‰ª•‰∫∫ÁÇ∫‰∏≠ÂøÉÁöÑ AI (HCAI) ‰∏≠ÔºåÈáçÈªûÂú®ÊñºÈáùÂ∞çÂ∏∏Ë¶ãÁöÑ eXplainable AI (XAI) ÊºîÁÆóÊ≥ïÈÄ≤Ë°å‰ª•‰ΩøÁî®ËÄÖÁÇ∫‰∏≠ÂøÉÁöÑË©ï‰º∞ÁµêÊûúÔºåÁâπÂà•ÊòØÊé¢Ë®é‰∫∫È°ûÂ¶Ç‰ΩïÁêÜËß£ÂíåËàáÈÄô‰∫õÊºîÁÆóÊ≥ïÊèê‰æõÁöÑË™™Êòé‰∫íÂãï„ÄÇÁÇ∫ÈÅîÊàêÊ≠§ÁõÆÁöÑÔºåÊàëÂÄëÊé°Áî®Â§öÂ≠∏ÁßëÊñπÊ≥ïÔºåÂÖ∂‰∏≠ÂåÖÂê´Á§æÊúÉÁßëÂ≠∏ÁöÑÊúÄÊñ∞Á†îÁ©∂ÊñπÊ≥ïÔºåÁî®ÊñºË°°ÈáèÊúÄÂÖàÈÄ≤ÁöÑÊ©üÂô®Â≠∏ÁøíÊ®°ÂûãÊâÄÁî¢ÁîüÁöÑË™™ÊòéÁöÑÂèØÁêÜËß£ÊÄßÔºåÁâπÂà•ÊòØÊ¢ØÂ∫¶ÊèêÂçáÂàÜÈ°ûÂô® (XGBClassifier)„ÄÇÊàëÂÄëÈÄ≤Ë°å‰∫Ü‰∏ÄÈ†ÖÂª£Ê≥õÁöÑÁ∂ìÈ©ó‰ΩøÁî®ËÄÖÁ†îÁ©∂ÔºåÂåÖÊã¨Ë®™Ë´á‰æÜËá™‰∏âÂÄã‰∏çÂêåÁæ§ÁµÑÁöÑ 39 ‰ΩçÂèÉËàáËÄÖÔºåÊØè‰ΩçÂèÉËàáËÄÖÂú®Ë≥áÊñôÁßëÂ≠∏„ÄÅË≥áÊñôË¶ñË¶∫ÂåñÂíåËàáÁî®ÊñºË®ìÁ∑¥Ê©üÂô®Â≠∏ÁøíÊ®°ÂûãÁöÑË≥áÊñôÈõÜÁõ∏ÈóúÁöÑÁâπÂÆöÈ†òÂüüÁü•Ë≠òÊñπÈù¢ÈÉΩÊúâ‰∏çÂêåÁöÑÂ∞àÊ•≠Áü•Ë≠ò„ÄÇÊàëÂÄëË©¢ÂïèÂèÉËàáËÄÖ‰∏ÄÁ≥ªÂàóÂïèÈ°åÔºå‰ª•Ë©ï‰º∞‰ªñÂÄëÂ∞çÊ®°ÂûãË™™ÊòéÁöÑÁêÜËß£„ÄÇÁÇ∫‰∫ÜÁ¢∫‰øùÂèØË§áË£ΩÊÄßÔºåÊàëÂÄë‰ΩøÁî®‰æÜËá™ UC Irvine Ê©üÂô®Â≠∏ÁøíÂÑ≤Â≠òÂ∫´ÁöÑÂÖ¨ÈñãË≥áÊñôÈõÜÂª∫Á´ãÊ®°ÂûãÔºåÈáçÈªûÈóúÊ≥®ÂèØÈ£üÁî®Âíå‰∏çÂèØÈ£üÁî®ÁöÑËòëËèá„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÊè≠Á§∫‰∫ÜÁèæÊúâ XAI ÊñπÊ≥ïÁöÑÈôêÂà∂Ôºå‰∏¶Á¢∫Ë™çÈúÄË¶ÅÊñ∞ÁöÑË®≠Ë®àÂéüÂâáÂíåË©ï‰º∞ÊäÄË°ìÔºå‰ª•ÊªøË∂≥‰∏çÂêåÈ°ûÂà•ÁöÑ AI Âà©ÁõäÁõ∏ÈóúËÄÖÁöÑÁâπÂÆöË≥áË®äÈúÄÊ±ÇÂíå‰ΩøÁî®ËÄÖËßÄÈªû„ÄÇÊàëÂÄëÁõ∏‰ø°ÔºåÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÂíåÊàëÂÄëÈñãÁôºÁöÑË∑®È†òÂüüÊñπÊ≥ïÂèØ‰ª•ÊàêÂäüÂú∞ÊáâÁî®ÊñºÂêÑÁ®ÆË≥áÊñôÈ°ûÂûãÂíå‰ΩøÁî®ËÄÖË®≠ÂÆöÊ™îÔºåÂæûËÄå‰øÉÈÄ≤Â∞çË©±‰∏¶Ëß£Ê±∫ HCAI Á†îÁ©∂‰∏≠ÁöÑÊ©üÊúÉ„ÄÇÁÇ∫‰∫ÜÊîØÊåÅÈÄô‰∏ÄÈªûÔºåÊàëÂÄëÂ∞áÁ†îÁ©∂‰∏≠Áî¢ÁîüÁöÑË≥áÊñôÂÖ¨Èñã„ÄÇ

##### **Findings of the Third Shared Task on Multilingual Coreference Resolution**
2410.15949v1 by Michal Nov√°k, Barbora Dohnalov√°, Miloslav Konop√≠k, Anna Nedoluzhko, Martin Popel, Ond≈ôej Pra≈æ√°k, Jakub Sido, Milan Straka, Zdenƒõk ≈Ωabokrtsk√Ω, Daniel Zeman

The paper presents an overview of the third edition of the shared task on
multilingual coreference resolution, held as part of the CRAC 2024 workshop.
Similarly to the previous two editions, the participants were challenged to
develop systems capable of identifying mentions and clustering them based on
identity coreference.
  This year's edition took another step towards real-world application by not
providing participants with gold slots for zero anaphora, increasing the task's
complexity and realism. In addition, the shared task was expanded to include a
more diverse set of languages, with a particular focus on historical languages.
The training and evaluation data were drawn from version 1.2 of the
multilingual collection of harmonized coreference resources CorefUD,
encompassing 21 datasets across 15 languages. 6 systems competed in this shared
task.

ÊëòË¶ÅÔºöÊú¨ÊñáÊ¶ÇËø∞‰∫ÜÂ§öËØ≠Ë®ÄÂÖ±ÊåáÊ∂àËß£ÂÖ±‰∫´‰ªªÂä°ÁöÑÁ¨¨‰∏âÁâàÔºåËØ•‰ªªÂä°‰Ωú‰∏∫ CRAC 2024 Á†îËÆ®‰ºöÁöÑ‰∏ÄÈÉ®ÂàÜ‰∏æË°å„ÄÇ
‰∏éÂâç‰∏§ÁâàÁ±ª‰ººÔºåÂèÇ‰∏éËÄÖÈù¢‰∏¥ÁöÑÊåëÊàòÊòØÂºÄÂèëËÉΩÂ§üËØÜÂà´ÊèêÂèäÂπ∂Ê†πÊçÆË∫´‰ªΩÂÖ±ÊåáÂØπÂÆÉ‰ª¨ËøõË°åËÅöÁ±ªÁöÑÁ≥ªÁªü„ÄÇ
‰ªäÂπ¥ÁöÑÁâàÊú¨ÈÄöËøá‰∏ç‰∏∫ÂèÇ‰∏éËÄÖÊèê‰æõÈõ∂‰ª£ËØçÊåá‰ª£ÁöÑÈáëÊßΩ‰ΩçÔºåÂêëÁé∞ÂÆû‰∏ñÁïåÂ∫îÁî®ËøàÂá∫‰∫ÜÂèà‰∏ÄÊ≠•Ôºå‰ªéËÄåÂ¢ûÂä†‰∫Ü‰ªªÂä°ÁöÑÂ§çÊùÇÊÄßÂíåÁúüÂÆûÊÄß„ÄÇÊ≠§Â§ñÔºåÂÖ±‰∫´‰ªªÂä°Â∑≤Êâ©Â±ïÂà∞ÂåÖÊã¨Êõ¥Â§öÊ†∑ÂåñÁöÑËØ≠Ë®ÄÈõÜÔºåÁâπÂà´ÂÖ≥Ê≥®ÂéÜÂè≤ËØ≠Ë®Ä„ÄÇ
ËÆ≠ÁªÉÂíåËØÑ‰º∞Êï∞ÊçÆÂèñËá™Â§öËØ≠Ë®ÄÂçèË∞ÉÂåñÂÖ±ÊåáËµÑÊ∫ê CorefUD ÁöÑ 1.2 ÁâàÔºåÊ∂µÁõñ 15 ÁßçËØ≠Ë®ÄÁöÑ 21 ‰∏™Êï∞ÊçÆÈõÜ„ÄÇ6 ‰∏™Á≥ªÁªüÂèÇÂä†‰∫ÜÊ≠§ÂÖ±‰∫´‰ªªÂä°„ÄÇ

##### **Developing Retrieval Augmented Generation (RAG) based LLM Systems from PDFs: An Experience Report**
2410.15944v1 by Ayman Asad Khan, Md Toufique Hasan, Kai Kristian Kemell, Jussi Rasku, Pekka Abrahamsson

This paper presents an experience report on the development of Retrieval
Augmented Generation (RAG) systems using PDF documents as the primary data
source. The RAG architecture combines generative capabilities of Large Language
Models (LLMs) with the precision of information retrieval. This approach has
the potential to redefine how we interact with and augment both structured and
unstructured knowledge in generative models to enhance transparency, accuracy,
and contextuality of responses. The paper details the end-to-end pipeline, from
data collection, preprocessing, to retrieval indexing and response generation,
highlighting technical challenges and practical solutions. We aim to offer
insights to researchers and practitioners developing similar systems using two
distinct approaches: OpenAI's Assistant API with GPT Series and Llama's
open-source models. The practical implications of this research lie in
enhancing the reliability of generative AI systems in various sectors where
domain-specific knowledge and real-time information retrieval is important. The
Python code used in this work is also available at:
https://github.com/GPT-Laboratory/RAG-LLM-Development-Guidebook-from-PDFs.

ÊëòË¶ÅÔºöÈÄôÁØáË´ñÊñáÊèêÂá∫‰∫Ü‰∏Ä‰ªΩÁ∂ìÈ©óÂ†±ÂëäÔºåË™™ÊòéÂ¶Ç‰Ωï‰ΩøÁî® PDF Êñá‰ª∂‰ΩúÁÇ∫‰∏ªË¶ÅË≥áÊñô‰æÜÊ∫ê‰æÜÈñãÁôºÊ™¢Á¥¢Â¢ûÂº∑ÁîüÊàê (RAG) Á≥ªÁµ±„ÄÇRAG Êû∂ÊßãÁµêÂêà‰∫ÜÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÁîüÊàêËÉΩÂäõÂíåË≥áË®äÊ™¢Á¥¢ÁöÑÁ≤æÁ¢∫Â∫¶„ÄÇÈÄôÁ®ÆÊñπÊ≥ïÊúâÂèØËÉΩÈáçÊñ∞ÂÆöÁæ©ÊàëÂÄëÂ¶Ç‰ΩïËàáÁîüÊàêÊ®°Âûã‰∏≠ÁöÑÁµêÊßãÂåñÂíåÈùûÁµêÊßãÂåñÁü•Ë≠ò‰∫íÂãï‰∏¶Âä†‰ª•Â¢ûÂº∑Ôºå‰ª•ÊèêÈ´òÂõûÊáâÁöÑÈÄèÊòéÂ∫¶„ÄÅÊ∫ñÁ¢∫ÊÄßÂíåËÑàÁµ°ÊÄß„ÄÇÈÄôÁØáË´ñÊñáË©≥Á¥∞Ë™™Êòé‰∫ÜÁ´ØÂà∞Á´ØÁÆ°Á∑öÔºåÂæûË≥áÊñôÊî∂ÈõÜ„ÄÅÈ†êËôïÁêÜÂà∞Ê™¢Á¥¢Á¥¢ÂºïÂíåÂõûÊáâÁî¢ÁîüÔºåÈáçÈªûË™™ÊòéÊäÄË°ìÊåëÊà∞ÂíåÂØ¶ÈöõËß£Ê±∫ÊñπÊ°à„ÄÇÊàëÂÄëÊó®Âú®ÁÇ∫‰ΩøÁî®ÂÖ©Á®Æ‰∏çÂêåÊñπÊ≥ïÈñãÁôºÈ°û‰ººÁ≥ªÁµ±ÁöÑÁ†îÁ©∂‰∫∫Âì°ÂíåÂæûÊ•≠‰∫∫Âì°Êèê‰æõË¶ãËß£ÔºöOpenAI ÁöÑÂä©ÁêÜ API Ëàá GPT Á≥ªÂàóÂíå Llama ÁöÑÈñãÊ∫êÊ®°Âûã„ÄÇÈÄôÈ†ÖÁ†îÁ©∂ÁöÑÂØ¶ÈöõÊÑèÁæ©Âú®ÊñºÊèêÈ´òÁîüÊàêÂºè AI Á≥ªÁµ±Âú®ÂêÑÁ®ÆÈ†òÂüüÁöÑÂèØÈù†ÊÄßÔºåÈÄô‰∫õÈ†òÂüüÈáçË¶ñÁâπÂÆöÈ†òÂüüÁöÑÁü•Ë≠òÂíåÂç≥ÊôÇË≥áË®äÊ™¢Á¥¢„ÄÇÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠‰ΩøÁî®ÁöÑ Python Á®ãÂºèÁ¢º‰πüÂèØÂú®‰ª•‰∏ãÁ∂≤ÂùÄÂèñÂæóÔºöhttps://github.com/GPT-Laboratory/RAG-LLM-Development-Guidebook-from-PDFs„ÄÇ

##### **CausalGraph2LLM: Evaluating LLMs for Causal Queries**
2410.15939v1 by Ivaxi Sheth, Bahare Fatemi, Mario Fritz

Causality is essential in scientific research, enabling researchers to
interpret true relationships between variables. These causal relationships are
often represented by causal graphs, which are directed acyclic graphs. With the
recent advancements in Large Language Models (LLMs), there is an increasing
interest in exploring their capabilities in causal reasoning and their
potential use to hypothesize causal graphs. These tasks necessitate the LLMs to
encode the causal graph effectively for subsequent downstream tasks. In this
paper, we propose a comprehensive benchmark, \emph{CausalGraph2LLM},
encompassing a variety of causal graph settings to assess the causal graph
understanding capability of LLMs. We categorize the causal queries into two
types: graph-level and node-level queries. We benchmark both open-sourced and
closed models for our study. Our findings reveal that while LLMs show promise
in this domain, they are highly sensitive to the encoding used. Even capable
models like GPT-4 and Gemini-1.5 exhibit sensitivity to encoding, with
deviations of about $60\%$. We further demonstrate this sensitivity for
downstream causal intervention tasks. Moreover, we observe that LLMs can often
display biases when presented with contextual information about a causal graph,
potentially stemming from their parametric memory.

ÊëòË¶ÅÔºöÂõ†ÊûúÂÖ≥Á≥ªÂú®ÁßëÂ≠¶Á†îÁ©∂‰∏≠Ëá≥ÂÖ≥ÈáçË¶ÅÔºåÂÆÉ‰ΩøÁ†îÁ©∂‰∫∫ÂëòËÉΩÂ§üËß£ÈáäÂèòÈáè‰πãÈó¥ÁöÑÁúüÂÆûÂÖ≥Á≥ª„ÄÇËøô‰∫õÂõ†ÊûúÂÖ≥Á≥ªÈÄöÂ∏∏Áî®Âõ†ÊûúÂõæË°®Á§∫ÔºåÂõ†ÊûúÂõæÊòØÊúâÂêëÊó†ÁéØÂõæ„ÄÇÈöèÁùÄÂ§ßËØ≠Ë®ÄÊ®°Âûã (LLM) ÁöÑÊúÄÊñ∞ËøõÂ±ïÔºå‰∫∫‰ª¨Ë∂äÊù•Ë∂äÊúâÂÖ¥Ë∂£Êé¢Á¥¢ÂÆÉ‰ª¨Âú®Âõ†ÊûúÊé®ÁêÜ‰∏≠ÁöÑËÉΩÂäõ‰ª•ÂèäÂÆÉ‰ª¨Âú®ÂÅáËÆæÂõ†ÊûúÂõæ‰∏≠ÁöÑÊΩúÂú®Áî®ÈÄî„ÄÇËøô‰∫õ‰ªªÂä°ÈúÄË¶Å LLM ÊúâÊïàÂú∞ÂØπÂõ†ÊûúÂõæËøõË°åÁºñÁ†ÅÔºå‰ª•‰æøÂêéÁª≠ÁöÑ‰∏ãÊ∏∏‰ªªÂä°„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏Ä‰∏™ÁªºÂêàÂü∫ÂáÜÔºå\emph{CausalGraph2LLM}ÔºåÂÆÉÂåÖÂê´‰∫ÜÂêÑÁßçÂõ†ÊûúÂõæËÆæÁΩÆÔºå‰ª•ËØÑ‰º∞ LLM ÁöÑÂõ†ÊûúÂõæÁêÜËß£ËÉΩÂäõ„ÄÇÊàë‰ª¨Â∞ÜÂõ†ÊûúÊü•ËØ¢ÂàÜ‰∏∫‰∏§Á±ªÔºöÂõæÁ∫ßÊü•ËØ¢ÂíåËäÇÁÇπÁ∫ßÊü•ËØ¢„ÄÇÊàë‰ª¨ÂØπÂºÄÊ∫êÊ®°ÂûãÂíåÂ∞ÅÈó≠Ê®°ÂûãËøõË°å‰∫ÜÂü∫ÂáÜÊµãËØï„ÄÇÊàë‰ª¨ÁöÑÁ†îÁ©∂ÁªìÊûúË°®ÊòéÔºåËôΩÁÑ∂ LLM Âú®ËØ•È¢ÜÂüüÊòæÁ§∫Âá∫ÂâçÊôØÔºå‰ΩÜÂÆÉ‰ª¨ÂØπÊâÄ‰ΩøÁî®ÁöÑÁºñÁ†ÅÈùûÂ∏∏ÊïèÊÑü„ÄÇÂç≥‰ΩøÂÉè GPT-4 Âíå Gemini-1.5 ËøôÊ†∑ÁöÑÂº∫Â§ßÊ®°Âûã‰πüÂØπÁºñÁ†ÅË°®Áé∞Âá∫ÊïèÊÑüÊÄßÔºåÂÅèÂ∑ÆÁ∫¶‰∏∫ 60%„ÄÇÊàë‰ª¨Ëøõ‰∏ÄÊ≠•ËØÅÊòé‰∫ÜËøôÁßçÂØπ‰∏ãÊ∏∏Âõ†ÊûúÂπ≤È¢Ñ‰ªªÂä°ÁöÑÊïèÊÑüÊÄß„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨ËßÇÂØüÂà∞ÔºåÂΩì LLM Ëé∑ÂæóÊúâÂÖ≥Âõ†ÊûúÂõæÁöÑ‰∏ä‰∏ãÊñá‰ø°ÊÅØÊó∂ÔºåÂÆÉ‰ª¨ÈÄöÂ∏∏‰ºöË°®Áé∞Âá∫ÂÅèËßÅÔºåËøôÂèØËÉΩÊ∫ê‰∫éÂÆÉ‰ª¨ÁöÑÂèÇÊï∞ËÆ∞ÂøÜ„ÄÇ

##### **Centrality-aware Product Retrieval and Ranking**
2410.15930v1 by Hadeel Saadany, Swapnil Bhosale, Samarth Agrawal, Diptesh Kanojia, Constantin Orasan, Zhe Wu

This paper addresses the challenge of improving user experience on e-commerce
platforms by enhancing product ranking relevant to users' search queries.
Ambiguity and complexity of user queries often lead to a mismatch between the
user's intent and retrieved product titles or documents. Recent approaches have
proposed the use of Transformer-based models, which need millions of annotated
query-title pairs during the pre-training stage, and this data often does not
take user intent into account. To tackle this, we curate samples from existing
datasets at eBay, manually annotated with buyer-centric relevance scores and
centrality scores, which reflect how well the product title matches the users'
intent. We introduce a User-intent Centrality Optimization (UCO) approach for
existing models, which optimises for the user intent in semantic product
search. To that end, we propose a dual-loss based optimisation to handle hard
negatives, i.e., product titles that are semantically relevant but do not
reflect the user's intent. Our contributions include curating challenging
evaluation sets and implementing UCO, resulting in significant product ranking
efficiency improvements observed for different evaluation metrics. Our work
aims to ensure that the most buyer-centric titles for a query are ranked
higher, thereby, enhancing the user experience on e-commerce platforms.

ÊëòË¶ÅÔºöÊú¨ÊñáÊé¢ËÆ®‰∫ÜÈÄöËøáÊèêÂçá‰∏éÁî®Êà∑ÊêúÂØªÊü•ËØ¢Áõ∏ÂÖ≥ÁöÑ‰∫ßÂìÅÊéíÂêçÔºåËøõËÄåÊîπÂñÑÁîµÂ≠êÂïÜÂä°Âπ≥Âè∞Áî®Êà∑‰ΩìÈ™åÁöÑÊåëÊàò„ÄÇÁî®Êà∑Êü•ËØ¢ÁöÑÊ®°Á≥äÊÄßÂíåÂ§çÊùÇÊÄßÈÄöÂ∏∏‰ºöÂØºËá¥Áî®Êà∑ÊÑèÂõæ‰∏éÊ£ÄÁ¥¢Âà∞ÁöÑ‰∫ßÂìÅÊ†áÈ¢òÊàñÊñá‰ª∂‰πãÈó¥Âá∫Áé∞‰∏çÂåπÈÖç„ÄÇÊúÄËøëÁöÑÊñπÊ≥ïÊèêÂá∫‰∫Ü‰ΩøÁî®Âü∫‰∫é Transformer ÁöÑÊ®°ÂûãÔºåËØ•Ê®°ÂûãÂú®È¢ÑËÆ≠ÁªÉÈò∂ÊÆµÈúÄË¶ÅÊï∞Áôæ‰∏á‰∏™Â∏¶Ê≥®ÈáäÁöÑÊü•ËØ¢-Ê†áÈ¢òÂØπÔºåËÄåËøô‰∫õÊï∞ÊçÆÈÄöÂ∏∏Êú™Â∞ÜÁî®Êà∑ÊÑèÂõæËÄÉËôëÂú®ÂÜÖ„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢òÔºåÊàë‰ª¨‰ªé eBay ÁöÑÁé∞ÊúâÊï∞ÊçÆÈõÜÊï¥ÁêÜÊ†∑Êú¨ÔºåÂπ∂Áî®‰ª•‰π∞ÂÆ∂‰∏∫‰∏≠ÂøÉÁöÑÂÖ≥ËÅîÊÄßÂæóÂàÜÂíå‰∏≠ÂøÉÊÄßÂæóÂàÜÊâãÂä®ËøõË°åÊ≥®ÈáäÔºåËøô‰∫õÂæóÂàÜÂèçÊò†‰∫Ü‰∫ßÂìÅÊ†áÈ¢ò‰∏éÁî®Êà∑ÊÑèÂõæÁöÑÂåπÈÖçÁ®ãÂ∫¶„ÄÇÊàë‰ª¨‰∏∫Áé∞ÊúâÊ®°ÂûãÂºïÂÖ•‰∫ÜÁî®Êà∑ÊÑèÂõæ‰∏≠ÂøÉÊÄß‰ºòÂåñ (UCO) ÊñπÊ≥ïÔºåËØ•ÊñπÊ≥ï‰ºòÂåñ‰∫ÜËØ≠‰πâ‰∫ßÂìÅÊêúÁ¥¢‰∏≠ÁöÑÁî®Êà∑ÊÑèÂõæ„ÄÇ‰∏∫Ê≠§ÔºåÊàë‰ª¨ÊèêÂá∫‰∫ÜÂü∫‰∫éÂèåÊçüÂ§±ÁöÑ‰ºòÂåñÊù•Â§ÑÁêÜÁ°¨Âê¶ÂÆöÔºåÂç≥ËØ≠‰πâÁõ∏ÂÖ≥ÁöÑ‰∫ßÂìÅÊ†áÈ¢òÔºå‰ΩÜ‰∏çËÉΩÂèçÊò†Áî®Êà∑ÁöÑÊÑèÂõæ„ÄÇÊàë‰ª¨ÁöÑË¥°ÁåÆÂåÖÊã¨Êï¥ÁêÜÂÖ∑ÊúâÊåëÊàòÊÄßÁöÑËØÑ‰º∞ÈõÜÂíåÂÆûÁé∞ UCOÔºå‰ªéËÄåÂØºËá¥ËßÇÂØüÂà∞ÈíàÂØπ‰∏çÂêåËØÑ‰º∞ÊåáÊ†áÁöÑ‰∫ßÂìÅÊéíÂêçÊïàÁéáÊúâÊòæËëóÊèêÂçá„ÄÇÊàë‰ª¨ÁöÑÂ∑•‰ΩúÊó®Âú®Á°Æ‰øùÈíàÂØπÊü•ËØ¢ÁöÑÊúÄ‰ª•‰π∞ÂÆ∂‰∏∫‰∏≠ÂøÉÊ†áÈ¢òËé∑ÂæóÊõ¥È´òÁöÑÊéíÂêçÔºå‰ªéËÄåÊèêÂçáÁîµÂ≠êÂïÜÂä°Âπ≥Âè∞ÁöÑÁî®Êà∑‰ΩìÈ™å„ÄÇ

##### **Yeah, Un, Oh: Continuous and Real-time Backchannel Prediction with Fine-tuning of Voice Activity Projection**
2410.15929v1 by Koji Inoue, Divesh Lala, Gabriel Skantze, Tatsuya Kawahara

In human conversations, short backchannel utterances such as "yeah" and "oh"
play a crucial role in facilitating smooth and engaging dialogue. These
backchannels signal attentiveness and understanding without interrupting the
speaker, making their accurate prediction essential for creating more natural
conversational agents. This paper proposes a novel method for real-time,
continuous backchannel prediction using a fine-tuned Voice Activity Projection
(VAP) model. While existing approaches have relied on turn-based or
artificially balanced datasets, our approach predicts both the timing and type
of backchannels in a continuous and frame-wise manner on unbalanced, real-world
datasets. We first pre-train the VAP model on a general dialogue corpus to
capture conversational dynamics and then fine-tune it on a specialized dataset
focused on backchannel behavior. Experimental results demonstrate that our
model outperforms baseline methods in both timing and type prediction tasks,
achieving robust performance in real-time environments. This research offers a
promising step toward more responsive and human-like dialogue systems, with
implications for interactive spoken dialogue applications such as virtual
assistants and robots.

ÊëòË¶ÅÔºöÂú®‰∫∫È°ûÂ∞çË©±‰∏≠ÔºåË´∏Â¶Ç„ÄåÂóØ„ÄçÂíå„ÄåÂñî„ÄçÁ≠âÁ∞°Áü≠ÁöÑÂõûÈ•ãË™ûÂè•Âú®‰øÉÈÄ≤È†ÜÊö¢‰∏îÂºï‰∫∫ÂÖ•ÂãùÁöÑÂ∞çË©±‰∏≠ÊâÆÊºîËëóËá≥ÈóúÈáçË¶ÅÁöÑËßíËâ≤„ÄÇÈÄô‰∫õÂõûÈ•ãË™ûÂè•ÂÇ≥ÈÅî‰∫ÜÊ≥®ÊÑèÂäõÂíåÁêÜËß£ÔºåÂçª‰∏ç‰∏≠Êñ∑Ë™™Ë©±ËÄÖÔºåÂõ†Ê≠§Ê∫ñÁ¢∫È†êÊ∏¨ÈÄô‰∫õË™ûÂè•Â∞çÊñºÂâµÈÄ†Êõ¥Ëá™ÁÑ∂ÁöÑÂ∞çË©±‰ª£ÁêÜËá≥ÈóúÈáçË¶Å„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁ®Æ‰ΩøÁî®ÂæÆË™øË™ûÈü≥Ê¥ªÂãïÈ†êÊ∏¨ (VAP) Ê®°ÂûãÈÄ≤Ë°åÂØ¶ÊôÇ„ÄÅÈÄ£Á∫åÂõûÈ•ãË™ûÂè•È†êÊ∏¨ÁöÑÊñ∞ÊñπÊ≥ï„ÄÇÈõñÁÑ∂ÁèæÊúâÊñπÊ≥ï‰æùË≥¥ÊñºÂõûÂêàÂà∂Êàñ‰∫∫Â∑•Âπ≥Ë°°ÁöÑÊï∏ÊìöÈõÜÔºå‰ΩÜÊàëÂÄëÁöÑÂÅöÊ≥ïÊòØ‰ª•ÈÄ£Á∫å‰∏îÈÄêÂπÄÁöÑÊñπÂºèÂú®‰∏çÂπ≥Ë°°ÁöÑÁúüÂØ¶‰∏ñÁïåÊï∏ÊìöÈõÜ‰∏äÈ†êÊ∏¨ÂõûÈ•ãË™ûÂè•ÁöÑÊôÇÊ©üÂíåÈ°ûÂûã„ÄÇÊàëÂÄëÈ¶ñÂÖàÂú®‰∏ÄËà¨Â∞çË©±Ë™ûÊñôÂ∫´‰∏äÈ†êË®ìÁ∑¥ VAP Ê®°Âûã‰ª•ÊçïÊçâÂ∞çË©±ÂãïÊÖãÔºåÁÑ∂ÂæåÂú®Â∞àÊ≥®ÊñºÂõûÈ•ãË™ûÂè•Ë°åÁÇ∫ÁöÑÂ∞àÈñÄÊï∏ÊìöÈõÜ‰∏äÂæÆË™øÂÆÉ„ÄÇÂØ¶È©óÁµêÊûúË°®ÊòéÔºåÊàëÂÄëÁöÑÊ®°ÂûãÂú®ÊôÇÊ©üÂíåÈ°ûÂûãÈ†êÊ∏¨‰ªªÂãô‰∏≠ÈÉΩÂÑ™ÊñºÂü∫Á∑öÊñπÊ≥ïÔºåÂú®ÂØ¶ÊôÇÁí∞Â¢É‰∏≠ÂØ¶Áèæ‰∫ÜÁ©©ÂÅ•ÁöÑÊÄßËÉΩ„ÄÇÈÄôÈ†ÖÁ†îÁ©∂ÁÇ∫Êõ¥ÂÖ∑ÂõûÊáâÊÄßÂíåÊõ¥Êì¨‰∫∫ÁöÑÂ∞çË©±Á≥ªÁµ±ÈÇÅÂá∫‰∫ÜÊúâÂ∏åÊúõÁöÑ‰∏ÄÊ≠•ÔºåÂ∞ç‰∫íÂãïÂºèÂè£Ë™ûÂ∞çË©±ÊáâÁî®Ôºà‰æãÂ¶ÇËôõÊì¨Âä©ÁêÜÂíåÊ©üÂô®‰∫∫ÔºâÂÖ∑ÊúâÂΩ±Èüø„ÄÇ

##### **GReFEL: Geometry-Aware Reliable Facial Expression Learning under Bias and Imbalanced Data Distribution**
2410.15927v1 by Azmine Toushik Wasi, Taki Hasan Rafi, Raima Islam, Karlo Serbetar, Dong Kyu Chae

Reliable facial expression learning (FEL) involves the effective learning of
distinctive facial expression characteristics for more reliable, unbiased and
accurate predictions in real-life settings. However, current systems struggle
with FEL tasks because of the variance in people's facial expressions due to
their unique facial structures, movements, tones, and demographics. Biased and
imbalanced datasets compound this challenge, leading to wrong and biased
prediction labels. To tackle these, we introduce GReFEL, leveraging Vision
Transformers and a facial geometry-aware anchor-based reliability balancing
module to combat imbalanced data distributions, bias, and uncertainty in facial
expression learning. Integrating local and global data with anchors that learn
different facial data points and structural features, our approach adjusts
biased and mislabeled emotions caused by intra-class disparity, inter-class
similarity, and scale sensitivity, resulting in comprehensive, accurate, and
reliable facial expression predictions. Our model outperforms current
state-of-the-art methodologies, as demonstrated by extensive experiments on
various datasets.

ÊëòË¶ÅÔºöÂèØÈù†ÁöÑÈù¢ÈÉ®Ë°®ÊÉÖÂ≠∏Áøí (FEL) Ê∂âÂèäÊúâÊïàÂ≠∏ÁøíÁç®ÁâπÁöÑÈù¢ÈÉ®Ë°®ÊÉÖÁâπÂæµÔºå‰ª•‰æøÂú®ÁèæÂØ¶ÁîüÊ¥ª‰∏≠ÈÄ≤Ë°åÊõ¥ÂèØÈù†„ÄÅÁÑ°ÂÅèË¶ãÂíåÊ∫ñÁ¢∫ÁöÑÈ†êÊ∏¨„ÄÇÁÑ∂ËÄåÔºåÁî±Êñº‰∫∫ÂÄëÁöÑÈù¢ÈÉ®ÁµêÊßã„ÄÅÂãï‰Ωú„ÄÅË™ûË™øÂíå‰∫∫Âè£Áµ±Ë®àË≥áÊñôÁöÑÂ∑ÆÁï∞ÔºåÁï∂ÂâçÁ≥ªÁµ±Èõ£‰ª•ÊáâÂ∞ç FEL ‰ªªÂãô„ÄÇÊúâÂÅèË¶ãÂíå‰∏çÂπ≥Ë°°ÁöÑË≥áÊñôÈõÜÂä†Âäá‰∫ÜÈÄô‰∏ÄÊåëÊà∞ÔºåÂ∞éËá¥ÈåØË™§ÂíåÊúâÂÅèË¶ãÁöÑÈ†êÊ∏¨Ê®ôÁ±§„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÂïèÈ°åÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü GReFELÔºåÂà©Áî®Ë¶ñË¶∫TransformerÂíå‰∏ÄÂÄãÈù¢ÈÉ®Âπæ‰ΩïÊÑüÁü•ÁöÑÂü∫ÊñºÈå®ÈªûÁöÑÂèØÈù†ÊÄßÂπ≥Ë°°Ê®°ÁµÑÔºå‰ª•ÊáâÂ∞çÈù¢ÈÉ®Ë°®ÊÉÖÂ≠∏Áøí‰∏≠ÁöÑ‰∏çÂπ≥Ë°°Ë≥áÊñôÂàÜ‰Ωà„ÄÅÂÅèË¶ãÂíå‰∏çÁ¢∫ÂÆöÊÄß„ÄÇÈÄöÈÅéÂ∞áÂ±ÄÈÉ®ÂíåÂÖ®Â±ÄË≥áÊñôËàáÂ≠∏Áøí‰∏çÂêåÈù¢ÈÉ®Ë≥áÊñôÈªûÂíåÁµêÊßãÁâπÂæµÁöÑÈå®ÈªûÁõ∏Êï¥ÂêàÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïË™øÊï¥‰∫ÜÁî±È°ûÂÖßÂ∑ÆÁï∞„ÄÅÈ°ûÈñìÁõ∏‰ººÊÄßÂíåÂ∞∫Â∫¶ÊïèÊÑüÊÄßÂ∞éËá¥ÁöÑÊúâÂÅèË¶ãÂíåÊ®ôÁ±§ÈåØË™§ÁöÑÊÉÖÁ∑íÔºåÂæûËÄåÁî¢ÁîüÂÖ®Èù¢„ÄÅÊ∫ñÁ¢∫ÂíåÂèØÈù†ÁöÑÈù¢ÈÉ®Ë°®ÊÉÖÈ†êÊ∏¨„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÂÑ™ÊñºÁï∂ÂâçÁöÑÊúÄÂÖàÈÄ≤ÊñπÊ≥ïÔºåÈÄôÂ∑≤ÈÄöÈÅéÂú®ÂêÑÁ®ÆË≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÁöÑÂª£Ê≥õÂØ¶È©óÂæóÂà∞Ë≠âÊòé„ÄÇ

##### **Mitigating Object Hallucination via Concentric Causal Attention**
2410.15926v1 by Yun Xing, Yiheng Li, Ivan Laptev, Shijian Lu

Recent Large Vision Language Models (LVLMs) present remarkable zero-shot
conversational and reasoning capabilities given multimodal queries.
Nevertheless, they suffer from object hallucination, a phenomenon where LVLMs
are prone to generate textual responses not factually aligned with image
inputs. Our pilot study reveals that object hallucination is closely tied with
Rotary Position Encoding (RoPE), a widely adopted positional dependency
modeling design in existing LVLMs. Due to the long-term decay in RoPE, LVLMs
tend to hallucinate more when relevant visual cues are distant from instruction
tokens in the multimodal input sequence. Additionally, we observe a similar
effect when reversing the sequential order of visual tokens during multimodal
alignment. Our tests indicate that long-term decay in RoPE poses challenges to
LVLMs while capturing visual-instruction interactions across long distances. We
propose Concentric Causal Attention (CCA), a simple yet effective positional
alignment strategy that mitigates the impact of RoPE long-term decay in LVLMs
by naturally reducing relative distance between visual and instruction tokens.
With CCA, visual tokens can better interact with instruction tokens, thereby
enhancing model's perception capability and alleviating object hallucination.
Without bells and whistles, our positional alignment method surpasses existing
hallucination mitigation strategies by large margins on multiple object
hallucination benchmarks.

ÊëòË¶ÅÔºöÊúÄËøëÁöÑÂ§ßÂûãËßÜËßâËØ≠Ë®ÄÊ®°Âûã (LVLMs) Âú®ÁªôÂÆöÂ§öÊ®°ÊÄÅÊü•ËØ¢Êó∂ÂëàÁé∞Âá∫ÈùûÂá°ÁöÑÈõ∂Ê¨°Â≠¶‰π†ÂØπËØùÂíåÊé®ÁêÜËÉΩÂäõ„ÄÇ
Â∞ΩÁÆ°Â¶ÇÊ≠§ÔºåÂÆÉ‰ª¨ËøòÊòØ‰ºö‰∫ßÁîüÂØπË±°ÂπªËßâÔºåËøôÊòØ‰∏Ä‰∏™Áé∞Ë±°ÔºåÂç≥ LVLMs ÂÆπÊòìÁîüÊàê‰∏éÂõæÂÉèËæìÂÖ•‰∫ãÂÆû‰∏çÁ¨¶ÁöÑÊñáÊú¨ÂìçÂ∫î„ÄÇÊàë‰ª¨ÁöÑËØïÁÇπÁ†îÁ©∂Ë°®ÊòéÔºåÂØπË±°ÂπªËßâ‰∏éÊóãËΩ¨‰ΩçÁΩÆÁºñÁ†Å (RoPE) ÂØÜÂàáÁõ∏ÂÖ≥ÔºåÊóãËΩ¨‰ΩçÁΩÆÁºñÁ†ÅÊòØÁé∞Êúâ LVLMs ‰∏≠ÂπøÊ≥õÈááÁî®ÁöÑ‰ΩçÁΩÆ‰æùËµñÂª∫Ê®°ËÆæËÆ°„ÄÇÁî±‰∫é RoPE ‰∏≠ÁöÑÈïøÊúüË°∞ÂáèÔºåÂΩìÁõ∏ÂÖ≥ËßÜËßâÁ∫øÁ¥¢‰∏éÂ§öÊ®°ÊÄÅËæìÂÖ•Â∫èÂàó‰∏≠ÁöÑÊåá‰ª§Ê†áËÆ∞Áõ∏Ë∑ùËæÉËøúÊó∂ÔºåLVLMs ÂæÄÂæÄ‰ºö‰∫ßÁîüÊõ¥Â§öÁöÑÂπªËßâ„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨Âú®Â§öÊ®°ÊÄÅÂØπÈΩêÊúüÈó¥ÂèçËΩ¨ËßÜËßâÊ†áËÆ∞ÁöÑÈ°∫Â∫èÊó∂ËßÇÂØüÂà∞‰∫ÜÁ±ª‰ººÁöÑÊïàÊûú„ÄÇÊàë‰ª¨ÁöÑÊµãËØïË°®ÊòéÔºåRoPE ‰∏≠ÁöÑÈïøÊúüË°∞ÂáèÂØπ LVLMs Âú®ËøúË∑ùÁ¶ªÊçïËé∑ËßÜËßâÊåá‰ª§‰∫§‰∫íÊó∂ÊûÑÊàê‰∫ÜÊåëÊàò„ÄÇÊàë‰ª¨ÊèêÂá∫‰∫ÜÂêåÂøÉÂõ†ÊûúÊ≥®ÊÑèÂäõ (CCA)ÔºåËøôÊòØ‰∏ÄÁßçÁÆÄÂçïËÄåÊúâÊïàÁöÑÂÆö‰ΩçÂØπÈΩêÁ≠ñÁï•ÔºåÈÄöËøáËá™ÁÑ∂Âú∞Áº©Áü≠ËßÜËßâÊ†áËÆ∞ÂíåÊåá‰ª§Ê†áËÆ∞‰πãÈó¥ÁöÑÁõ∏ÂØπË∑ùÁ¶ªÊù•ÂáèËΩª RoPE ÈïøÊúüË°∞ÂáèÂØπ LVLMs ÁöÑÂΩ±Âìç„ÄÇÂÄüÂä© CCAÔºåËßÜËßâÊ†áËÆ∞ÂèØ‰ª•Êõ¥Â•ΩÂú∞‰∏éÊåá‰ª§Ê†áËÆ∞‰∫§‰∫íÔºå‰ªéËÄåÂ¢ûÂº∫Ê®°ÂûãÁöÑÊÑüÁü•ËÉΩÂäõÂπ∂ÂáèËΩªÂØπË±°ÂπªËßâ„ÄÇÂú®Ê≤°ÊúâËä±ÈáåËÉ°Âì®ÁöÑÊÉÖÂÜµ‰∏ãÔºåÊàë‰ª¨ÁöÑ‰ΩçÁΩÆÂØπÈΩêÊñπÊ≥ïÂú®Â§ö‰∏™ÂØπË±°ÂπªËßâÂü∫ÂáÜ‰∏ä‰ª•Â§ßÂπÖ‰ºòÂäøË∂ÖË∂ä‰∫ÜÁé∞ÊúâÁöÑÂπªËßâÁºìËß£Á≠ñÁï•„ÄÇ

##### **Bench4Merge: A Comprehensive Benchmark for Merging in Realistic Dense Traffic with Micro-Interactive Vehicles**
2410.15912v1 by Zhengming Wang, Junli Wang, Pengfei Li, Zhaohan Li, Peng Li, Yilun Chen

While the capabilities of autonomous driving have advanced rapidly, merging
into dense traffic remains a significant challenge, many motion planning
methods for this scenario have been proposed but it is hard to evaluate them.
Most existing closed-loop simulators rely on rule-based controls for other
vehicles, which results in a lack of diversity and randomness, thus failing to
accurately assess the motion planning capabilities in highly interactive
scenarios. Moreover, traditional evaluation metrics are insufficient for
comprehensively evaluating the performance of merging in dense traffic. In
response, we proposed a closed-loop evaluation benchmark for assessing motion
planning capabilities in merging scenarios. Our approach involves other
vehicles trained in large scale datasets with micro-behavioral characteristics
that significantly enhance the complexity and diversity. Additionally, we have
restructured the evaluation mechanism by leveraging large language models to
assess each autonomous vehicle merging onto the main road. Extensive
experiments have demonstrated the advanced nature of this evaluation benchmark.
Through this benchmark, we have obtained an evaluation of existing methods and
identified common issues. The environment and vehicle motion planning models we
have designed can be accessed at
https://anonymous.4open.science/r/Bench4Merge-EB5D

ÊëòË¶ÅÔºöÂÑòÁÆ°Ëá™ÂãïÈßïÈßõÁöÑËÉΩÂäõÈÄ≤Â±ïËøÖÈÄüÔºå‰ΩÜËûçÂÖ•ÂØÜÈõÜÁöÑ‰∫§ÈÄö‰ªçÁÑ∂ÊòØ‰∏ÄÈ†ÖÈáçÂ§ßÊåëÊà∞ÔºåÈáùÂ∞çÊ≠§ÊÉÖÂ¢ÉÁöÑË®±Â§öÈÅãÂãïË¶èÂäÉÊñπÊ≥ïÂ∑≤Ë¢´ÊèêÂá∫Ôºå‰ΩÜÂæàÈõ£Â∞çÂÆÉÂÄëÈÄ≤Ë°åË©ï‰º∞„ÄÇ
ÁèæÊúâÁöÑÂ∞ÅÈñâËø¥Ë∑ØÊ®°Êì¨Âô®Â§ßÂ§ö‰æùË≥¥ÊñºÂÖ∂‰ªñËªäËºõÁöÑÂü∫ÊñºË¶èÂâáÁöÑÊéßÂà∂ÔºåÈÄôÂ∞éËá¥Áº∫‰πèÂ§öÊ®£ÊÄßÂíåÈö®Ê©üÊÄßÔºåÂõ†Ê≠§ÁÑ°Ê≥ïÊ∫ñÁ¢∫Ë©ï‰º∞Âú®È´òÂ∫¶‰∫íÂãïÊÉÖÂ¢É‰∏≠ÁöÑÈÅãÂãïË¶èÂäÉËÉΩÂäõ„ÄÇ
Ê≠§Â§ñÔºåÂÇ≥Áµ±ÁöÑË©ï‰º∞ÊåáÊ®ô‰∏çË∂≥‰ª•ÂÖ®Èù¢Ë©ï‰º∞Âú®ÂØÜÈõÜ‰∫§ÈÄö‰∏≠Âêà‰ΩµÁöÑÊÄßËÉΩ„ÄÇ
‰ΩúÁÇ∫ÂõûÊáâÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂ∞ÅÈñâËø¥Ë∑ØË©ï‰º∞Âü∫Ê∫ñÔºåÁî®ÊñºË©ï‰º∞Âêà‰ΩµÊÉÖÂ¢É‰∏≠ÁöÑÈÅãÂãïË¶èÂäÉËÉΩÂäõ„ÄÇ
ÊàëÂÄëÁöÑÂÅöÊ≥ïÊ∂âÂèäÂú®ÂÖ∑ÊúâÂæÆË°åÁÇ∫ÁâπÂæµÁöÑÂ§ßË¶èÊ®°Êï∏ÊìöÈõÜ‰∏≠Ë®ìÁ∑¥ÁöÑÂÖ∂‰ªñËªäËºõÔºåÈÄôÈ°ØËëóÊèêÈ´ò‰∫ÜË§áÈõúÊÄßÂíåÂ§öÊ®£ÊÄß„ÄÇ
Ê≠§Â§ñÔºåÊàëÂÄëÈÄöÈÅéÂà©Áî®Â§ßÂûãË™ûË®ÄÊ®°ÂûãÈáçÊñ∞Ë™øÊï¥‰∫ÜË©ï‰º∞Ê©üÂà∂Ôºå‰ª•Ë©ï‰º∞ÊØèÂÄãËá™‰∏ªËªäËºõ‰ΩµÂÖ•‰∏ªÂππÈÅì„ÄÇ
Âª£Ê≥õÁöÑÂØ¶È©óË≠âÊòé‰∫ÜÈÄôÂÄãË©ï‰º∞Âü∫Ê∫ñÁöÑÂÖàÈÄ≤ÊÄß„ÄÇ
ÈÄöÈÅéÈÄôÂÄãÂü∫Ê∫ñÔºåÊàëÂÄëÁç≤Âæó‰∫ÜÂ∞çÁèæÊúâÊñπÊ≥ïÁöÑË©ï‰º∞Ôºå‰∏¶ÊâæÂá∫Â∏∏Ë¶ãÁöÑÂïèÈ°å„ÄÇ
ÊàëÂÄëË®≠Ë®àÁöÑÁí∞Â¢ÉÂíåËªäËºõÈÅãÂãïË¶èÂäÉÊ®°ÂûãÂèØ‰ª•Âú®
https://anonymous.4open.science/r/Bench4Merge-EB5D Áç≤Âæó

##### **DefVerify: Do Hate Speech Models Reflect Their Dataset's Definition?**
2410.15911v1 by Urja Khurana, Eric Nalisnick, Antske Fokkens

When building a predictive model, it is often difficult to ensure that
domain-specific requirements are encoded by the model that will eventually be
deployed. Consider researchers working on hate speech detection. They will have
an idea of what is considered hate speech, but building a model that reflects
their view accurately requires preserving those ideals throughout the workflow
of data set construction and model training. Complications such as sampling
bias, annotation bias, and model misspecification almost always arise, possibly
resulting in a gap between the domain specification and the model's actual
behavior upon deployment. To address this issue for hate speech detection, we
propose DefVerify: a 3-step procedure that (i) encodes a user-specified
definition of hate speech, (ii) quantifies to what extent the model reflects
the intended definition, and (iii) tries to identify the point of failure in
the workflow. We use DefVerify to find gaps between definition and model
behavior when applied to six popular hate speech benchmark datasets.

ÊëòË¶ÅÔºöÂú®Âª∫Á´ãÈ†êÊ∏¨Ê®°ÂûãÊôÇÔºåÈÄöÂ∏∏Èõ£‰ª•Á¢∫‰øùÊ®°ÂûãÁ∑®Á¢º‰∫ÜÁâπÂÆöÈ†òÂüüÁöÑË¶ÅÊ±ÇÔºåËÄåÈÄô‰∫õË¶ÅÊ±ÇÊúÄÁµÇÂ∞áÊúÉË¢´ÈÉ®ÁΩ≤„ÄÇËÄÉÊÖÆÁ†îÁ©∂‰ªáÊÅ®Ë®ÄË´ñÂÅµÊ∏¨ÁöÑÁ†îÁ©∂‰∫∫Âì°„ÄÇ‰ªñÂÄëÂ∞áÊúÉ‰∫ÜËß£‰ªÄÈ∫ºË¢´Ë¶ñÁÇ∫‰ªáÊÅ®Ë®ÄË´ñÔºå‰ΩÜÂª∫Á´ã‰∏ÄÂÄãÊ∫ñÁ¢∫ÂèçÊò†‰ªñÂÄëËßÄÈªûÁöÑÊ®°ÂûãÈúÄË¶ÅÂú®Ë≥áÊñôÈõÜÂª∫ÊßãÂíåÊ®°ÂûãË®ìÁ∑¥ÁöÑÂ∑•‰ΩúÊµÅÁ®ã‰∏≠‰øùÁïôÈÄô‰∫õÁêÜÊÉ≥„ÄÇÂπæ‰πéÁ∏ΩÊòØÊúÉÂá∫ÁèæÂÉèÊäΩÊ®£ÂÅèÂ∑Æ„ÄÅË®ªËß£ÂÅèÂ∑ÆÂíåÊ®°ÂûãÈåØË™§Ë¶èÁØÑÁ≠âË§áÈõúÊÉÖÊ≥ÅÔºåÂèØËÉΩÂ∞éËá¥È†òÂüüË¶èÁØÑÂíåÊ®°ÂûãÂú®ÈÉ®ÁΩ≤ÂæåÁöÑÂØ¶ÈöõË°åÁÇ∫‰πãÈñìÂá∫ÁèæÂ∑ÆË∑ù„ÄÇÁÇ∫‰∫ÜËß£Ê±∫‰ªáÊÅ®Ë®ÄË´ñÂÅµÊ∏¨ÁöÑÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫ DefVerifyÔºö‰∏ÄÂÄã 3 Ê≠•È©üÁ®ãÂ∫èÔºåÂÆÉ (i) Á∑®Á¢º‰ΩøÁî®ËÄÖÊåáÂÆöÁöÑ‰ªáÊÅ®Ë®ÄË´ñÂÆöÁæ©Ôºå(ii) ÈáèÂåñÊ®°ÂûãÂèçÊò†È†êÊúüÂÆöÁæ©ÁöÑÁ®ãÂ∫¶Ôºå‰ª•Âèä (iii) ÂòóË©¶ÊâæÂá∫Â∑•‰ΩúÊµÅÁ®ã‰∏≠ÁöÑÂ§±ÊïóÈªû„ÄÇÊàëÂÄë‰ΩøÁî® DefVerify ‰æÜÊâæÂá∫ÂÆöÁæ©ÂíåÊ®°ÂûãË°åÁÇ∫‰πãÈñìÁöÑÂ∑ÆË∑ùÔºå‰∏¶Â∞áÂÖ∂ÊáâÁî®ÊñºÂÖ≠ÂÄãÊµÅË°åÁöÑ‰ªáÊÅ®Ë®ÄË´ñÂü∫Ê∫ñË≥áÊñôÈõÜ„ÄÇ

##### **IGMaxHS -- An Incremental MaxSAT Solver with Support for XOR Clauses**
2410.15897v1 by Ole L√ºbke

Recently, a novel, MaxSAT-based method for error correction in quantum
computing has been proposed that requires both incremental MaxSAT solving
capabilities and support for XOR constraints, but no dedicated MaxSAT solver
fulfilling these criteria existed yet. We alleviate that and introduce IGMaxHS,
which is based on the existing solvers iMaxHS and GaussMaxHS, but poses fewer
restrictions on the XOR constraints than GaussMaxHS. IGMaxHS is fuzz tested
with xwcnfuzz, an extension of wcnfuzz that can directly output XOR
constraints. As a result, IGMaxHS is the only solver that reported neither
incorrect unsatisfiability verdicts nor invalid models nor incoherent cost
model combinations in a final fuzz testing comparison of all three solvers with
10000 instances. We detail the steps required for implementing Gaussian
elimination on XOR constraints in CDCL SAT solvers, and extend the recently
proposed re-entrant incremental MaxSAT solver application program interface to
allow for incremental addition of XOR constraints. Finally, we show that
IGMaxHS is capable of decoding quantum color codes through simulation with the
Munich Quantum Toolkit.

ÊëòË¶ÅÔºöÊúÄËøëÔºåÊèêÂá∫‰∫Ü‰∏ÄÁßçÂü∫‰∫é MaxSAT ÁöÑÈáèÂ≠êËÆ°ÁÆóÁ∫†ÈîôÊñ∞ÊñπÊ≥ïÔºåËØ•ÊñπÊ≥ïÈúÄË¶ÅÂ¢ûÈáèÂºè MaxSAT Ê±ÇËß£ËÉΩÂäõÂíåÂØπ XOR Á∫¶ÊùüÁöÑÊîØÊåÅÔºå‰ΩÜËøòÊ≤°Êúâ‰∏ìÈó®ÁöÑ MaxSAT Ê±ÇËß£Âô®Êª°Ë∂≥Ëøô‰∫õÊ†áÂáÜ„ÄÇÊàë‰ª¨ÁºìËß£‰∫ÜËøô‰∏™ÈóÆÈ¢òÔºåÂπ∂ÂºïÂÖ•‰∫Ü IGMaxHSÔºåÂÆÉÂü∫‰∫éÁé∞ÊúâÁöÑÊ±ÇËß£Âô® iMaxHS Âíå GaussMaxHSÔºå‰ΩÜÂØπ XOR Á∫¶ÊùüÁöÑÈôêÂà∂ÊØî GaussMaxHS Â∞ë„ÄÇIGMaxHS ‰ΩøÁî® xwcnfuzz ËøõË°åÊ®°Á≥äÊµãËØïÔºåxwcnfuzz ÊòØ wcnfuzz ÁöÑÊâ©Â±ïÔºåÂèØ‰ª•Áõ¥Êé•ËæìÂá∫ XOR Á∫¶Êùü„ÄÇÂõ†Ê≠§ÔºåIGMaxHS ÊòØÂîØ‰∏Ä‰∏Ä‰∏™Âú®ÊâÄÊúâ‰∏â‰∏™Ê±ÇËß£Âô®ÁöÑÊúÄÁªàÊ®°Á≥äÊµãËØïÊØîËæÉ‰∏≠Êó¢Ê≤°ÊúâÊä•Âëä‰∏çÊ≠£Á°ÆÁöÑ‰∏çÂèØÊª°Ë∂≥ÊÄßÁªìÊûúÔºå‰πüÊ≤°ÊúâÊä•ÂëäÊó†ÊïàÊ®°ÂûãÊàñ‰∏çËøûË¥ØÁöÑÊàêÊú¨Ê®°ÂûãÁªÑÂêàÁöÑÊ±ÇËß£Âô®ÔºåÊµãËØïÂÆû‰æã‰∏∫ 10000 ‰∏™„ÄÇÊàë‰ª¨ËØ¶ÁªÜ‰ªãÁªç‰∫ÜÂú® CDCL SAT Ê±ÇËß£Âô®‰∏≠ÂØπ XOR Á∫¶ÊùüÂÆûÁé∞È´òÊñØÊ∂àÂÖÉÊâÄÈúÄÁöÑÊ≠•È™§ÔºåÂπ∂Êâ©Â±ï‰∫ÜÊúÄËøëÊèêÂá∫ÁöÑÂèØÈáçÂÖ•Â¢ûÈáè MaxSAT Ê±ÇËß£Âô®Â∫îÁî®Á®ãÂ∫èÁºñÁ®ãÊé•Âè£Ôºå‰ª•ÂÖÅËÆ∏Â¢ûÈáèÊ∑ªÂä† XOR Á∫¶Êùü„ÄÇÊúÄÂêéÔºåÊàë‰ª¨Â±ïÁ§∫‰∫Ü IGMaxHS ËÉΩÂ§üÈÄöËøá‰ΩøÁî®ÊÖïÂ∞ºÈªëÈáèÂ≠êÂ∑•ÂÖ∑ÂåÖËøõË°åÊ®°ÊãüÊù•Ëß£Á†ÅÈáèÂ≠êÈ¢úËâ≤Á†Å„ÄÇ

##### **Model Mimic Attack: Knowledge Distillation for Provably Transferable Adversarial Examples**
2410.15889v1 by Kirill Lukyanov, Andrew Perminov, Denis Turdakov, Mikhail Pautov

The vulnerability of artificial neural networks to adversarial perturbations
in the black-box setting is widely studied in the literature. The majority of
attack methods to construct these perturbations suffer from an impractically
large number of queries required to find an adversarial example. In this work,
we focus on knowledge distillation as an approach to conduct transfer-based
black-box adversarial attacks and propose an iterative training of the
surrogate model on an expanding dataset. This work is the first, to our
knowledge, to provide provable guarantees on the success of knowledge
distillation-based attack on classification neural networks: we prove that if
the student model has enough learning capabilities, the attack on the teacher
model is guaranteed to be found within the finite number of distillation
iterations.

ÊëòË¶ÅÔºö‰∫∫Â∑•Á•ûÁ∂ìÁ∂≤Ë∑ØÂú®ÈªëÁÆ±Ë®≠ÂÆö‰∏≠Â∞çÊäóÊìæÂãïÁöÑËÑÜÂº±ÊÄßÂú®ÊñáÁçª‰∏≠Âª£Ê≥õÁ†îÁ©∂„ÄÇÂ§ßÂ§öÊï∏Áî®ÊñºÂª∫ÊßãÈÄô‰∫õÊìæÂãïÁöÑÊîªÊìäÊñπÊ≥ïÈÉΩÂ≠òÂú®‰∏ÄÂÄã‰∏çÂàáÂØ¶ÈöõÁöÑÁº∫ÈªûÔºåÂç≥ÈúÄË¶ÅÂ§ßÈáèÁöÑÊü•Ë©¢ÊâçËÉΩÊâæÂà∞Â∞çÊäóÁØÑ‰æã„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÂ∞àÊ≥®ÊñºÁü•Ë≠òËêÉÂèñ‰ΩúÁÇ∫Âü∑Ë°åÂü∫ÊñºÂÇ≥Ëº∏ÁöÑÈªëÁÆ±Â∞çÊäóÊîªÊìäÁöÑÊñπÊ≥ïÔºå‰∏¶ÊèêÂá∫Âú®Êì¥ÂÖÖË≥áÊñôÈõÜ‰∏äÂ∞ç‰ª£ÁêÜÊ®°ÂûãÈÄ≤Ë°åÂèçË¶ÜË®ìÁ∑¥„ÄÇÊìöÊàëÂÄëÊâÄÁü•ÔºåÈÄôÈ†ÖÂ∑•‰ΩúÊòØÁ¨¨‰∏ÄÂÄãÈáùÂ∞çÂü∫ÊñºÁü•Ë≠òËêÉÂèñÁöÑÂàÜÈ°ûÁ•ûÁ∂ìÁ∂≤Ë∑ØÊîªÊìäÁöÑÊàêÂäüÊèê‰æõÂèØË≠âÊòé‰øùË≠âÔºöÊàëÂÄëË≠âÊòéÔºåÂ¶ÇÊûúÂ≠∏ÁîüÊ®°ÂûãÊúâË∂≥Â§†ÁöÑÂ≠∏ÁøíËÉΩÂäõÔºåÂâá‰øùË≠âÂèØ‰ª•Âú®ÊúâÈôêÁöÑËêÉÂèñÂèçË¶ÜÈÅãÁÆó‰∏≠ÊâæÂà∞Â∞çÊïôÂ∏´Ê®°ÂûãÁöÑÊîªÊìä„ÄÇ

##### **How to Build a Pre-trained Multimodal model for Simultaneously Chatting and Decision-making?**
2410.15885v1 by Zuojin Tang, Bin Hu, Chenyang Zhao, De Ma, Gang Pan, Bin Liu

Existing large pre-trained models typically map text input to text output in
an end-to-end manner, such as ChatGPT, or map a segment of text input to a
hierarchy of action decisions, such as OpenVLA. However, humans can
simultaneously generate text and actions when receiving specific input signals.
For example, a driver can make precise driving decisions while conversing with
a friend in the passenger seat. Motivated by this observation, we consider the
following question in this work: is it possible to construct a pre-trained
model that can provide both language interaction and precise decision-making
capabilities in dynamic open scenarios. We provide a definitive answer to this
question by developing a new model architecture termed Visual Language Action
model for Chatting and Decision Making (VLA4CD), and further demonstrating its
performance in challenging autonomous driving tasks. Specifically, we leverage
LoRA to fine-tune a pre-trained LLM with data of multiple modalities covering
language, visual, and action. Unlike the existing LoRA operations used for LLM
fine-tuning, we have designed new computational modules and training cost
functions for VLA4CD. These designs enable VLA4CD to provide continuous-valued
action decisions while outputting text responses. In contrast, existing LLMs
can only output text responses, and current VLA models can only output action
decisions. Moreover, these VLA models handle action data by discretizing and
then tokenizing the discretized actions, a method unsuitable for complex
decision-making tasks involving high-dimensional continuous-valued action
vectors, such as autonomous driving. The experimental results on CARLA validate
that: (1) our proposed model construction method is effective; (2) compared to
the SOTA VLA model, VLA4CD can provide more accurate real-time decision-making
while retaining the text interaction capability inherent to LLMs.

ÊëòË¶ÅÔºöÁèæÊúâÁöÑÂ§ßÂûãÈ†êË®ìÁ∑¥Ê®°ÂûãÈÄöÂ∏∏ÊúÉ‰ª•Á´ØÂ∞çÁ´ØÁöÑÊñπÂºèÂ∞áÊñáÂ≠óËº∏ÂÖ•Â∞çÊáâÂà∞ÊñáÂ≠óËº∏Âá∫Ôºå‰æãÂ¶Ç ChatGPTÔºåÊàñÂ∞á‰∏ÄÊÆµÊñáÂ≠óËº∏ÂÖ•Â∞çÊáâÂà∞‰∏ÄÈÄ£‰∏≤Âãï‰ΩúÊ±∫Á≠ñÁöÑÈöéÂ±§Ôºå‰æãÂ¶Ç OpenVLA„ÄÇÁÑ∂ËÄåÔºå‰∫∫È°ûÂú®Êî∂Âà∞ÁâπÂÆöÁöÑËº∏ÂÖ•Ë®äËôüÊôÇÔºåÂèØ‰ª•ÂêåÊôÇÁî¢ÁîüÊñáÂ≠óÂíåÂãï‰Ωú„ÄÇ‰æãÂ¶ÇÔºå‰∏ÄÂêçÈßïÈßõÂú®ËàáÂùêÂú®ÂâØÈßïÈßõÂ∫ßÁöÑÊúãÂèã‰∫§Ë´áÊôÇÔºåÂèØ‰ª•ÂÅöÂá∫Á≤æÁ¢∫ÁöÑÈßïÈßõÊ±∫Á≠ñ„ÄÇÂèóÂà∞Ê≠§È†ÖËßÄÂØüÁöÑÂïüÁôºÔºåÊàëÂÄëÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÊÄùËÄÉ‰ª•‰∏ãÂïèÈ°åÔºöÊòØÂê¶ÂèØ‰ª•Âª∫Êßã‰∏ÄÂÄãÈ†êË®ìÁ∑¥Ê®°ÂûãÔºåÂú®ÂãïÊÖãÈñãÊîæÂ†¥ÊôØ‰∏≠ÂêåÊôÇÊèê‰æõË™ûË®Ä‰∫íÂãïÂíåÁ≤æÁ¢∫Ê±∫Á≠ñÁöÑËÉΩÂäõ„ÄÇÊàëÂÄëÈÄèÈÅéÈñãÁôº‰∏ÄÁ®ÆÁ®±ÁÇ∫ËÅäÂ§©ÂíåÊ±∫Á≠ñË£Ω‰ΩúÁöÑË¶ñË¶∫Ë™ûË®ÄÂãï‰ΩúÊ®°ÂûãÔºàVLA4CDÔºâÁöÑÊñ∞Ê®°ÂûãÊû∂ÊßãÔºå‰∏¶ÈÄ≤‰∏ÄÊ≠•Â±ïÁ§∫ÂÖ∂Âú®ÂÖ∑ÊúâÊåëÊà∞ÊÄßÁöÑËá™ÂãïÈßïÈßõ‰ªªÂãô‰∏≠ÁöÑÊïàËÉΩÔºåÂ∞çÊ≠§ÂïèÈ°åÁµ¶Âá∫ÊòéÁ¢∫ÁöÑÁ≠îÊ°à„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÂà©Áî® LoRA ÂæÆË™ø‰∏ÄÂÄãÈ†êË®ìÁ∑¥ÁöÑ LLMÔºåÂÖ∂Ë≥áÊñôÂåÖÂê´Ë™ûË®Ä„ÄÅË¶ñË¶∫ÂíåÂãï‰ΩúÁ≠âÂ§öÁ®ÆÊ®°Âºè„ÄÇËàáÁî®Êñº LLM ÂæÆË™øÁöÑÁèæÊúâ LoRA Êìç‰Ωú‰∏çÂêåÔºåÊàëÂÄëÁÇ∫ VLA4CD Ë®≠Ë®à‰∫ÜÊñ∞ÁöÑÈÅãÁÆóÊ®°ÁµÑÂíåË®ìÁ∑¥ÊàêÊú¨ÂáΩÊï∏„ÄÇÈÄô‰∫õË®≠Ë®à‰Ωø VLA4CD ËÉΩÂ§†Âú®Ëº∏Âá∫ÊñáÂ≠óÂõûÊáâÁöÑÂêåÊôÇÔºåÊèê‰æõÈÄ£Á∫åÂÄºÂãï‰ΩúÊ±∫Á≠ñ„ÄÇÁõ∏ÊØî‰πã‰∏ãÔºåÁèæÊúâÁöÑ LLM Âè™ËÉΩËº∏Âá∫ÊñáÂ≠óÂõûÊáâÔºåËÄåÁèæÊúâÁöÑ VLA Ê®°ÂûãÂè™ËÉΩËº∏Âá∫Âãï‰ΩúÊ±∫Á≠ñ„ÄÇÊ≠§Â§ñÔºåÈÄô‰∫õ VLA Ê®°ÂûãÈÄèÈÅéÂ∞áÈõ¢Êï£ÂåñÂãï‰ΩúÈõ¢Êï£Âåñ‰∏¶ÈÄ≤Ë°åÊ®ôË®òÂåñ‰æÜËôïÁêÜÂãï‰ΩúË≥áÊñôÔºåÈÄôÁ®ÆÊñπÊ≥ï‰∏çÈÅ©ÂêàÊ∂âÂèäÈ´òÁ∂≠ÈÄ£Á∫åÂÄºÂãï‰ΩúÂêëÈáèÁöÑË§áÈõúÊ±∫Á≠ñ‰ªªÂãôÔºå‰æãÂ¶ÇËá™ÂãïÈßïÈßõ„ÄÇCARLA ‰∏äÁöÑÂØ¶È©óÁµêÊûúÈ©óË≠â‰∫ÜÔºö(1) ÊàëÂÄëÊèêÂá∫ÁöÑÊ®°ÂûãÂª∫ÊßãÊñπÊ≥ïÊòØÊúâÊïàÁöÑÔºõ(2) Ëàá SOTA VLA Ê®°ÂûãÁõ∏ÊØîÔºåVLA4CD ËÉΩÂ§†Âú®‰øùÊúâ LLM Âõ∫ÊúâÁöÑÊñáÂ≠ó‰∫íÂãïËÉΩÂäõÁöÑÂêåÊôÇÔºåÊèê‰æõÊõ¥Ê∫ñÁ¢∫ÁöÑÂç≥ÊôÇÊ±∫Á≠ñ„ÄÇ

##### **Using GPT Models for Qualitative and Quantitative News Analytics in the 2024 US Presidental Election Process**
2410.15884v1 by Bohdan M. Pavlyshenko

The paper considers an approach of using Google Search API and GPT-4o model
for qualitative and quantitative analyses of news through retrieval-augmented
generation (RAG). This approach was applied to analyze news about the 2024 US
presidential election process. Different news sources for different time
periods have been analyzed. Quantitative scores generated by GPT model have
been analyzed using Bayesian regression to derive trend lines. The
distributions found for the regression parameters allow for the analysis of
uncertainty in the election process. The obtained results demonstrate that
using the GPT models for news analysis, one can get informative analytics and
provide key insights that can be applied in further analyses of election
processes.

ÊëòË¶ÅÔºöÊú¨ÊñáËÄÉÊÖÆ‰ΩøÁî® Google Search API Âíå GPT-4o Ê®°ÂûãÁöÑÊñπÊ≥ïÔºåÈÄèÈÅéÊ™¢Á¥¢Â¢ûÂº∑ÁîüÊàê (RAG) ÈÄ≤Ë°åÊñ∞ËÅûÁöÑÂÆöÊÄßÂíåÂÆöÈáèÂàÜÊûê„ÄÇÊ≠§ÊñπÊ≥ïÁî®ÊñºÂàÜÊûêÊúâÈóú 2024 Âπ¥ÁæéÂúãÁ∏ΩÁµ±ÈÅ∏ËàâÈÅéÁ®ãÁöÑÊñ∞ËÅû„ÄÇÂ∑≤ÂàÜÊûê‰∏çÂêåÊôÇÈñìÊÆµÁöÑ‰∏çÂêåÊñ∞ËÅû‰æÜÊ∫ê„ÄÇÂ∑≤‰ΩøÁî®Ë≤ùÊ∞èËø¥Ê≠∏ÂàÜÊûê GPT Ê®°ÂûãÁî¢ÁîüÁöÑÈáèÂåñÂàÜÊï∏Ôºå‰ª•Â∞éÂá∫Ë∂®Âã¢Á∑ö„ÄÇËø¥Ê≠∏ÂèÉÊï∏‰∏≠ÁôºÁèæÁöÑÂàÜÂ∏ÉÂÖÅË®±ÂàÜÊûêÈÅ∏ËàâÈÅéÁ®ã‰∏≠ÁöÑ‰∏çÁ¢∫ÂÆöÊÄß„ÄÇÁç≤ÂæóÁöÑÁµêÊûúË°®ÊòéÔºå‰ΩøÁî® GPT Ê®°ÂûãÈÄ≤Ë°åÊñ∞ËÅûÂàÜÊûêÔºåÂèØ‰ª•Áç≤ÂæóÊúâÊÑèÁæ©ÁöÑÂàÜÊûê‰∏¶Êèê‰æõÈóúÈçµË¶ãËß£ÔºåÈÄô‰∫õË¶ãËß£ÂèØ‰ª•ÊáâÁî®ÊñºÈÅ∏ËàâÈÅéÁ®ãÁöÑÈÄ≤‰∏ÄÊ≠•ÂàÜÊûê‰∏≠„ÄÇ

##### **MI-VisionShot: Few-shot adaptation of vision-language models for slide-level classification of histopathological images**
2410.15881v1 by Pablo Meseguer, Roc√≠o del Amor, Valery Naranjo

Vision-language supervision has made remarkable strides in learning visual
representations from textual guidance. In digital pathology, vision-language
models (VLM), pre-trained on curated datasets of histological image-captions,
have been adapted to downstream tasks, such as region of interest
classification. Zero-shot transfer for slide-level prediction has been
formulated by MI-Zero, but it exhibits high variability depending on the
textual prompts. Inspired by prototypical learning, we propose MI-VisionShot, a
training-free adaptation method on top of VLMs to predict slide-level labels in
few-shot learning scenarios. Our framework takes advantage of the excellent
representation learning of VLM to create prototype-based classifiers under a
multiple-instance setting by retrieving the most discriminative patches within
each slide. Experimentation through different settings shows the ability of
MI-VisionShot to surpass zero-shot transfer with lower variability, even in
low-shot scenarios. Code coming soon at
thttps://github.com/cvblab/MIVisionShot.

ÊëòË¶ÅÔºöË¶ñË¶∫Ë™ûË®ÄÁõ£Áù£Âú®ÂæûÊñáÊú¨ÊåáÂ∞é‰∏≠Â≠∏ÁøíË¶ñË¶∫Ë°®ÂæµÊñπÈù¢ÂèñÂæó‰∫ÜÈ°ØËëóÈÄ≤Â±ï„ÄÇÂú®Êï∏‰ΩçÁóÖÁêÜÂ≠∏‰∏≠ÔºåÁ∂ìÈÅéÁµÑÁπîÂ≠∏ÂΩ±ÂÉèÊ®ôÈ°åÁöÑÁ≤æÈÅ∏Ë≥áÊñôÈõÜÈ†êÂÖàË®ìÁ∑¥ÁöÑË¶ñË¶∫Ë™ûË®ÄÊ®°Âûã (VLM) Â∑≤Ë™øÊï¥ÁÇ∫‰∏ãÊ∏∏‰ªªÂãôÔºå‰æãÂ¶ÇÊÑüËààË∂£ÂçÄÂüüÂàÜÈ°û„ÄÇMI-Zero Â∑≤Âà∂ÂÆöÂπªÁáàÁâáÁ¥öÂà•È†êÊ∏¨ÁöÑÈõ∂Ê¨°ËΩâÁßªÔºå‰ΩÜÂÆÉÊúÉÊ†πÊìöÊñáÂ≠óÊèêÁ§∫ËÄåË°®ÁèæÂá∫È´òÂ∫¶ËÆäÁï∞ÊÄß„ÄÇÂèóÂà∞ÂéüÂûãÂ≠∏ÁøíÁöÑÂïüÁôºÔºåÊàëÂÄëÊèêÂá∫ MI-VisionShotÔºåÈÄôÊòØ‰∏ÄÁ®ÆÂª∫Á´ãÂú® VLM ‰πã‰∏äÁöÑÁÑ°Ë®ìÁ∑¥ÈÅ©ÊáâÊñπÊ≥ïÔºåÁî®ÊñºÂú®Â∞ëÊ¨°Â≠∏ÁøíÂ†¥ÊôØ‰∏≠È†êÊ∏¨ÂπªÁáàÁâáÁ¥öÂà•Ê®ôÁ±§„ÄÇÊàëÂÄëÁöÑÊû∂ÊßãÂà©Áî® VLM ÂÑ™Áï∞ÁöÑË°®ÂæµÂ≠∏ÁøíÔºåÂú®Â§öÂÄãÂØ¶‰æãË®≠ÂÆö‰∏ãÈÄèÈÅéÊì∑ÂèñÊØèÂÄãÂπªÁáàÁâá‰∏≠ÊúÄÂÖ∑ÂçÄÂà•ÊÄßÁöÑ‰øÆË£úÁ®ãÂºè‰æÜÂª∫Á´ãÂü∫ÊñºÂéüÂûãÁöÑÂàÜÈ°ûÂô®„ÄÇÈÄèÈÅé‰∏çÂêåË®≠ÂÆöÁöÑÂØ¶È©óÈ°ØÁ§∫ÔºåMI-VisionShot ÊúâËÉΩÂäõË∂ÖË∂äËÆäÁï∞ÊÄßËºÉ‰ΩéÁöÑÈõ∂Ê¨°ËΩâÁßªÔºåÂç≥‰ΩøÂú®Â∞ëÊ¨°Â†¥ÊôØ‰∏≠‰πüÊòØÂ¶ÇÊ≠§„ÄÇÁ®ãÂºèÁ¢ºÂç≥Â∞áÂú® thttps://github.com/cvblab/MIVisionShot ‰∏äÊèê‰æõ„ÄÇ

##### **FlickerFusion: Intra-trajectory Domain Generalizing Multi-Agent RL**
2410.15876v1 by Woosung Koh, Wonbeen Oh, Siyeol Kim, Suhin Shin, Hyeongjin Kim, Jaein Jang, Junghyun Lee, Se-Young Yun

Multi-agent reinforcement learning has demonstrated significant potential in
addressing complex cooperative tasks across various real-world applications.
However, existing MARL approaches often rely on the restrictive assumption that
the number of entities (e.g., agents, obstacles) remains constant between
training and inference. This overlooks scenarios where entities are dynamically
removed or added during the inference trajectory -- a common occurrence in
real-world environments like search and rescue missions and dynamic combat
situations. In this paper, we tackle the challenge of intra-trajectory dynamic
entity composition under zero-shot out-of-domain (OOD) generalization, where
such dynamic changes cannot be anticipated beforehand. Our empirical studies
reveal that existing MARL methods suffer significant performance degradation
and increased uncertainty in these scenarios. In response, we propose
FlickerFusion, a novel OOD generalization method that acts as a universally
applicable augmentation technique for MARL backbone methods. Our results show
that FlickerFusion not only achieves superior inference rewards but also
uniquely reduces uncertainty vis-\`a-vis the backbone, compared to existing
methods. For standardized evaluation, we introduce MPEv2, an enhanced version
of Multi Particle Environments (MPE), consisting of 12 benchmarks. Benchmarks,
implementations, and trained models are organized and open-sourced at
flickerfusion305.github.io, accompanied by ample demo video renderings.

ÊëòË¶ÅÔºöÂ§öÊô∫ËÉΩÈ´îÂº∑ÂåñÂ≠∏ÁøíÂ∑≤Âú®ËôïÁêÜÂêÑÁ®ÆÁúüÂØ¶‰∏ñÁïåÊáâÁî®‰∏≠ÁöÑË§áÈõúÂçî‰Ωú‰ªªÂãôÊñπÈù¢Â±ïÁèæÂá∫È°ØËëóÁöÑÊΩõÂäõ„ÄÇ
ÁÑ∂ËÄåÔºåÁèæÊúâÁöÑÂ§öÊô∫ËÉΩÈ´îÂº∑ÂåñÂ≠∏ÁøíÊñπÊ≥ïÈÄöÂ∏∏‰æùË≥¥Êñº‰∏ÄÂÄãÈôêÂà∂ÊÄßÂÅáË®≠ÔºåÂç≥ÂØ¶È´îÔºà‰æãÂ¶ÇÔºåÊô∫ËÉΩÈ´î„ÄÅÈöúÁ§ôÁâ©ÔºâÁöÑÊï∏ÈáèÂú®Ë®ìÁ∑¥ÂíåÊé®ÁêÜ‰πãÈñì‰øùÊåÅ‰∏çËÆä„ÄÇÈÄôÂøΩË¶ñ‰∫ÜÂú®Êé®ÁêÜËªåË∑°ÊúüÈñìÂØ¶È´îÊúÉÂãïÊÖãÁßªÈô§ÊàñÊñ∞Â¢ûÁöÑÊÉÖÊ≥Å‚Äî‚ÄîÈÄôÂú®ÁèæÂØ¶‰∏ñÁïåÁí∞Â¢ÉÔºà‰æãÂ¶ÇÊêúÊïë‰ªªÂãôÂíåÂãïÊÖãÊà∞È¨•ÊÉÖÊ≥ÅÔºâ‰∏≠ÂæàÂ∏∏Ë¶ã„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊáâÂ∞ç‰∫ÜÂú®Èõ∂Ê¨°Â≠∏ÁøíÈ†òÂüüÂ§ñ (OOD) Ê¶ÇÊã¨‰∏ãÁöÑËªåË∑°ÂÖßÂãïÊÖãÂØ¶È´îÁµÑÊàêÁöÑÊåëÊà∞ÔºåÂÖ∂‰∏≠ÁÑ°Ê≥ïÈ†êÂÖàÈ†êÊ∏¨Ê≠§È°ûÂãïÊÖãËÆäÂåñ„ÄÇÊàëÂÄëÁöÑÂØ¶Ë≠âÁ†îÁ©∂Ë°®ÊòéÔºåÁèæÊúâÁöÑÂ§öÊô∫ËÉΩÈ´îÂº∑ÂåñÂ≠∏ÁøíÊñπÊ≥ïÂú®ÈÄô‰∫õÊÉÖÊ≥Å‰∏ãÊúÉÈÅ≠ÂèóÈ°ØËëóÁöÑÊïàËÉΩ‰∏ãÈôçÂíå‰∏çÁ¢∫ÂÆöÊÄßÂ¢ûÂä†„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∫Ü FlickerFusionÔºåÈÄôÊòØ‰∏ÄÁ®ÆÊñ∞Á©éÁöÑ OOD Ê¶ÇÊã¨ÊñπÊ≥ïÔºåÂèØÁî®‰ΩúÂ§öÊô∫ËÉΩÈ´îÂº∑ÂåñÂ≠∏Áøí‰∏ªÂππÊñπÊ≥ïÁöÑÈÄöÁî®Êì¥ÂÖÖÊäÄË°ì„ÄÇÊàëÂÄëÁöÑÁµêÊûúË°®ÊòéÔºåËàáÁèæÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåFlickerFusion ‰∏çÂÉÖÂØ¶Áèæ‰∫ÜÂÑ™Áï∞ÁöÑÊé®ÁêÜÁçéÂãµÔºåËÄå‰∏îÁç®ÁâπÂú∞Èôç‰Ωé‰∫ÜËàá‰∏ªÂππÁõ∏ÊØîÁöÑ‰∏çÁ¢∫ÂÆöÊÄß„ÄÇÁÇ∫‰∫ÜÈÄ≤Ë°åÊ®ôÊ∫ñÂåñË©ï‰º∞ÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜÂ§öÁ≤íÂ≠êÁí∞Â¢É (MPE) ÁöÑÂ¢ûÂº∑ÁâàÊú¨ MPEv2ÔºåÂÖ∂‰∏≠ÂåÖÂê´ 12 ÂÄãÂü∫Ê∫ñ„ÄÇÂü∫Ê∫ñ„ÄÅÂØ¶‰ΩúÂíåË®ìÁ∑¥Ê®°ÂûãÂ∑≤ÁµÑÁπî‰∏¶ÈñãÊîæÂéüÂßãÁ¢ºÊñº flickerfusion305.github.ioÔºå‰∏¶ÈôÑÊúâÂ§ßÈáèÁöÑÁ§∫ÁØÑÂΩ±ÁâáÊ∏≤Êüì„ÄÇ

##### **Principles of semantic and functional efficiency in grammatical patterning**
2410.15865v1 by Emily Cheng, Francesca Franzon

Grammatical features such as number and gender serve two central functions in
human languages. While they encode salient semantic attributes like numerosity
and animacy, they also offload sentence processing cost by predictably linking
words together via grammatical agreement. Grammars exhibit consistent
organizational patterns across diverse languages, invariably rooted in a
semantic foundation, a widely confirmed but still theoretically unexplained
phenomenon. To explain the basis of universal grammatical patterns, we unify
two fundamental properties of grammar, semantic encoding and agreement-based
predictability, into a single information-theoretic objective under cognitive
constraints. Our analyses reveal that grammatical organization provably
inherits from perceptual attributes, but that grammars empirically prioritize
functional goals, promoting efficient language processing over semantic
encoding.

ÊëòË¶ÅÔºöË™ûÊ≥ïÁâπÂæµÔºå‰æãÂ¶ÇÊï∏ÁõÆÂíåÊÄßÂà•ÔºåÂú®‰∫∫È°ûË™ûË®Ä‰∏≠ÂÖ∑ÊúâÂÖ©ÂÄãÊ†∏ÂøÉÂäüËÉΩ„ÄÇÈõñÁÑ∂ÂÆÉÂÄëÁ∑®Á¢º‰∫ÜÈ°ØËëóÁöÑË™ûÁæ©Â±¨ÊÄßÔºå‰æãÂ¶ÇÊï∏ÈáèÂíåÂãïÁâ©ÊÄßÔºå‰ΩÜÂÆÉÂÄë‰πüÈÄöÈÅéË™ûÊ≥ï‰∏ÄËá¥ÊÄßÂèØÈ†êÊ∏¨Âú∞Â∞áÂñÆË©ûËÅØÁπ´Âú®‰∏ÄËµ∑ÔºåÂæûËÄåÈôç‰Ωé‰∫ÜÂè•Â≠êËôïÁêÜÊàêÊú¨„ÄÇË™ûÊ≥ïÂú®‰∏çÂêåÁöÑË™ûË®Ä‰∏≠Ë°®ÁèæÂá∫‰∏ÄËá¥ÁöÑÁµÑÁπîÊ®°ÂºèÔºåÈÄô‰∫õÊ®°ÂºèÁ∏ΩÊòØÊ§çÊ†πÊñºË™ûÁæ©Âü∫Á§éÔºåÈÄôÊòØ‰∏ÄÂÄãÂæóÂà∞Âª£Ê≥õË≠âÂØ¶‰ΩÜ‰ªçÁÑ∂ÁÑ°Ê≥ïÂæûÁêÜË´ñ‰∏äËß£ÈáãÁöÑÁèæË±°„ÄÇÁÇ∫‰∫ÜËß£ÈáãÊôÆÈÅçË™ûÊ≥ïÊ®°ÂºèÁöÑÂü∫Á§éÔºåÊàëÂÄëÂ∞áË™ûÊ≥ïÁöÑÂÖ©ÂÄãÂü∫Êú¨Â±¨ÊÄßÔºåË™ûÁæ©Á∑®Á¢ºÂíåÂü∫Êñº‰∏ÄËá¥ÊÄßÁöÑÂèØÈ†êÊ∏¨ÊÄßÔºåÁµ±‰∏ÄÂà∞Ë™çÁü•Á¥ÑÊùü‰∏ãÁöÑÂñÆ‰∏ÄË≥áË®äÁêÜË´ñÁõÆÊ®ô‰∏≠„ÄÇÊàëÂÄëÁöÑÂàÜÊûêË°®ÊòéÔºåË™ûÊ≥ïÁµÑÁπîÈ°ØÁÑ∂ÁπºÊâøËá™ÊÑüÁü•Â±¨ÊÄßÔºå‰ΩÜË™ûÊ≥ïÂú®Á∂ìÈ©ó‰∏äÂÑ™ÂÖàËÄÉÊÖÆÂäüËÉΩÁõÆÊ®ôÔºå‰øÉÈÄ≤‰∫ÜÂ∞çË™ûÁæ©Á∑®Á¢ºÁöÑÈ´òÊïàË™ûË®ÄËôïÁêÜ„ÄÇ

##### **Mesa-Extrapolation: A Weave Position Encoding Method for Enhanced Extrapolation in LLMs**
2410.15859v2 by Xin Ma, Yang Liu, Jingjing Liu, Xiaoxu Ma

Large language models (LLMs), although having revolutionized many fields,
still suffer from the challenging extrapolation problem, where the inference
ability of LLMs sharply declines beyond their max training lengths. In this
work, we conduct a theoretical analysis to better understand why No Position
Encoding (NoPE) fails outside its effective range, as well as examining the
power of Position Encoding (PE) in this context. Our findings reveal that with
meticulous weave position, PE can indeed be extended beyond effective range.
Our theorems establish that LLMs equipped with weave PE can achieve improved
extrapolation performance without additional cost. Furthermore, we introduce a
novel weave PE method, Mesa-Extrapolation, which utilizes a chunk-based
triangular attention matrix and applies Stair PE to manage the final chunk.
This method not only retains competitive performance but also offers
substantial benefits such as significantly reduced memory demand and faster
inference speed. Extensive experiments validate the effectiveness of
Mesa-Extrapolation, demonstrating its potential as a scalable solution to
enhancing LLMs applicative reach.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂÑòÁÆ°Â∑≤Á∂ìÈù©Êñ∞Ë®±Â§öÈ†òÂüüÔºå
‰ªçÂèóÈôêÊñºÂÖ∑ÊúâÊåëÊà∞ÊÄßÁöÑÂ§ñÊé®ÂïèÈ°åÔºåÂÖ∂‰∏≠ LLM ÁöÑÊé®Ë´ñ
ËÉΩÂäõÂú®ÂÖ∂ÊúÄÂ§ßË®ìÁ∑¥Èï∑Â∫¶‰πãÂ§ñÊÄ•Âäá‰∏ãÈôç„ÄÇÂú®ÈÄô
È†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÈÄ≤Ë°åÁêÜË´ñÂàÜÊûêÔºå‰ª•Êõ¥Â•ΩÂú∞ÁêÜËß£ÁÇ∫‰ªÄÈ∫ºÁÑ°‰ΩçÁΩÆ
Á∑®Á¢º (NoPE) Âú®ÂÖ∂ÊúâÊïàÁØÑÂúç‰πãÂ§ñÊúÉÂ§±ÊïóÔºå‰ª•ÂèäÂú®Ê≠§ÊÉÖÊ≥Å‰∏ãÊé¢Ë®é
‰ΩçÁΩÆÁ∑®Á¢º (PE) ÁöÑËÉΩÂäõ„ÄÇÊàëÂÄëÁöÑÁôºÁèæÈ°ØÁ§∫ÔºåÈÄèÈÅé
Á¥∞Á∑ªÁöÑÁ∑®Áπî‰ΩçÁΩÆÔºåPE Á¢∫ÂØ¶ÂèØ‰ª•Êì¥Â±ïÂà∞ÊúâÊïàÁØÑÂúç‰πãÂ§ñ„ÄÇ
ÊàëÂÄëÁöÑÂÆöÁêÜË°®ÊòéÈÖçÂÇôÁ∑®Áπî PE ÁöÑ LLM ÂèØ‰ª•ÂØ¶ÁèæÊîπÈÄ≤
ÁöÑÂ§ñÊé®ÊïàËÉΩÔºåËÄåÁÑ°ÈúÄÈ°çÂ§ñÊàêÊú¨„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂºïÂÖ•‰∏ÄÁ®Æ
Êñ∞Á©éÁöÑÁ∑®Áπî PE ÊñπÊ≥ïÔºåMesa-ExtrapolationÔºåÂÆÉÂà©Áî®Âü∫ÊñºÂ°äÁöÑ
‰∏âËßíÂΩ¢Ê≥®ÊÑèÂäõÁü©Èô£Ôºå‰∏¶ÊáâÁî®ÈöéÊ¢Ø PE ‰æÜÁÆ°ÁêÜÊúÄÂæå‰∏ÄÂÄãÂ°ä„ÄÇ
Ê≠§ÊñπÊ≥ï‰∏çÂÉÖ‰øùÊåÅÁ´∂Áà≠ÂäõÔºåËÄå‰∏îÈÇÑÊèê‰æõ
È°ØËëóÈôç‰ΩéË®òÊÜ∂È´îÈúÄÊ±ÇÂíåÊõ¥Âø´ÁöÑÊé®Ë´ñÈÄüÂ∫¶Á≠âÂØ¶Ë≥™ÊÄßÂÑ™Èªû„ÄÇÂª£Ê≥õÁöÑÂØ¶È©óÈ©óË≠â‰∫Ü
Mesa-Extrapolation ÁöÑÊúâÊïàÊÄßÔºåË≠âÊòéÂÖ∂‰ΩúÁÇ∫ÂèØÊì¥ÂÖÖËß£Ê±∫ÊñπÊ°àÁöÑÊΩõÂäõÔºå‰ª•
Â¢ûÂº∑ LLM ÁöÑÊáâÁî®ÁØÑÂúç„ÄÇ

##### **Random Token Fusion for Multi-View Medical Diagnosis**
2410.15847v1 by Jingyu Guo, Christos Matsoukas, Fredrik Strand, Kevin Smith

In multi-view medical diagnosis, deep learning-based models often fuse
information from different imaging perspectives to improve diagnostic
performance. However, existing approaches are prone to overfitting and rely
heavily on view-specific features, which can lead to trivial solutions. In this
work, we introduce Random Token Fusion (RTF), a novel technique designed to
enhance multi-view medical image analysis using vision transformers. By
integrating randomness into the feature fusion process during training, RTF
addresses the issue of overfitting and enhances the robustness and accuracy of
diagnostic models without incurring any additional cost at inference. We
validate our approach on standard mammography and chest X-ray benchmark
datasets. Through extensive experiments, we demonstrate that RTF consistently
improves the performance of existing fusion methods, paving the way for a new
generation of multi-view medical foundation models.

ÊëòË¶ÅÔºöÂú®Â§öË¶ñÂúñÈÜ´ÁôÇË®∫Êñ∑‰∏≠ÔºåÂü∫ÊñºÊ∑±Â∫¶Â≠∏ÁøíÁöÑÊ®°ÂûãÈÄöÂ∏∏ËûçÂêà‰æÜËá™‰∏çÂêåÂΩ±ÂÉèË¶ñËßíÁöÑË≥áË®äÔºå‰ª•ÊèêÂçáË®∫Êñ∑ÊïàËÉΩ„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÊñπÊ≥ïÂÆπÊòìÈÅéÂ∫¶Êì¨ÂêàÔºå‰∏¶ÈÅéÂ∫¶‰æùË≥¥ÁâπÂÆöË¶ñËßíÁöÑÁâπÂæµÔºåÈÄôÂèØËÉΩÂ∞éËá¥Áë£Á¢éÁöÑËß£Ê±∫ÊñπÊ°à„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜÈö®Ê©üÁâπÂæµËûçÂêà (RTF)ÔºåÈÄôÊòØ‰∏ÄÁ®ÆÊñ∞ÊäÄË°ìÔºåÊó®Âú®‰ΩøÁî®Ë¶ñË¶∫ËΩâÊèõÂô®Â¢ûÂº∑Â§öË¶ñÂúñÈÜ´ÁôÇÂΩ±ÂÉèÂàÜÊûê„ÄÇÈÄèÈÅéÂú®Ë®ìÁ∑¥ÊúüÈñìÂ∞áÈö®Ê©üÊÄßÊï¥ÂêàÂà∞ÁâπÂæµËûçÂêàÈÅéÁ®ã‰∏≠ÔºåRTF Ëß£Ê±∫‰∫ÜÈÅéÂ∫¶Êì¨ÂêàÁöÑÂïèÈ°åÔºå‰∏¶Â¢ûÂº∑‰∫ÜË®∫Êñ∑Ê®°ÂûãÁöÑÁ©©ÂÅ•ÊÄßÂíåÊ∫ñÁ¢∫ÊÄßÔºåËÄå‰∏çÊúÉÂú®Êé®Ë´ñ‰∏≠Áî¢Áîü‰ªª‰ΩïÈ°çÂ§ñÁöÑÊàêÊú¨„ÄÇÊàëÂÄëÂú®Ê®ôÊ∫ñ‰π≥ÊàøÊîùÂΩ±ÂíåËÉ∏ÈÉ® X ÂÖâÂü∫Ê∫ñË≥áÊñôÈõÜ‰∏äÈ©óË≠â‰∫ÜÊàëÂÄëÁöÑÊñπÊ≥ï„ÄÇÈÄèÈÅéÂª£Ê≥õÁöÑÂØ¶È©óÔºåÊàëÂÄëË≠âÊòé RTF ÊåÅÁ∫åÊîπÂñÑÁèæÊúâËûçÂêàÊñπÊ≥ïÁöÑÊïàËÉΩÔºåÁÇ∫Êñ∞‰∏Ä‰ª£Â§öË¶ñÂúñÈÜ´ÁôÇÂü∫Á§éÊ®°ÂûãÈã™Âπ≥‰∫ÜÈÅìË∑Ø„ÄÇ

##### **LLM4GRN: Discovering Causal Gene Regulatory Networks with LLMs -- Evaluation through Synthetic Data Generation**
2410.15828v1 by Tejumade Afonja, Ivaxi Sheth, Ruta Binkyte, Waqar Hanif, Thomas Ulas, Matthias Becker, Mario Fritz

Gene regulatory networks (GRNs) represent the causal relationships between
transcription factors (TFs) and target genes in single-cell RNA sequencing
(scRNA-seq) data. Understanding these networks is crucial for uncovering
disease mechanisms and identifying therapeutic targets. In this work, we
investigate the potential of large language models (LLMs) for GRN discovery,
leveraging their learned biological knowledge alone or in combination with
traditional statistical methods. We develop a task-based evaluation strategy to
address the challenge of unavailable ground truth causal graphs. Specifically,
we use the GRNs suggested by LLMs to guide causal synthetic data generation and
compare the resulting data against the original dataset. Our statistical and
biological assessments show that LLMs can support statistical modeling and data
synthesis for biological research.

ÊëòË¶ÅÔºöÂü∫Âõ†Ë™øÊéßÁ∂≤Ë∑Ø (GRN) ‰ª£Ë°®ÂñÆÁ¥∞ËÉû RNA ÂÆöÂ∫è (scRNA-seq) Ë≥áÊñô‰∏≠ËΩâÈåÑÂõ†Â≠ê (TF) ËàáÁõÆÊ®ôÂü∫Âõ†‰πãÈñìÁöÑÂõ†ÊûúÈóú‰øÇ„ÄÇ‰∫ÜËß£ÈÄô‰∫õÁ∂≤Ë∑ØÂ∞çÊñºÊè≠Èú≤ÁñæÁóÖÊ©üÂà∂ÂíåÊâæÂá∫Ê≤ªÁôÇÁõÆÊ®ôËá≥ÈóúÈáçË¶Å„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊé¢Ë®éÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú® GRN Êé¢Á¥¢‰∏≠ÁöÑÊΩõÂäõÔºåÂà©Áî®ÂÆÉÂÄëÂ≠∏ÁøíÂà∞ÁöÑÁîüÁâ©Áü•Ë≠òÔºåÂñÆÁç®ÊàñËàáÂÇ≥Áµ±Áµ±Ë®àÊñπÊ≥ïÁµêÂêà‰ΩøÁî®„ÄÇÊàëÂÄëÂà∂ÂÆö‰∫Ü‰∏ÄÈ†ÖÂü∫Êñº‰ªªÂãôÁöÑË©ï‰º∞Á≠ñÁï•Ôºå‰ª•Ëß£Ê±∫ÁÑ°Ê≥ïÂèñÂæóÂú∞Èù¢ÁúüÁõ∏Âõ†ÊûúÂúñË°®ÁöÑÊåëÊà∞„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄë‰ΩøÁî® LLM Âª∫Ë≠∞ÁöÑ GRN ‰æÜÂºïÂ∞éÂõ†ÊûúÂêàÊàêË≥áÊñôÁî¢ÁîüÔºå‰∏¶Â∞áÁî¢ÁîüÁöÑË≥áÊñôËàáÂéüÂßãË≥áÊñôÈõÜÈÄ≤Ë°åÊØîËºÉ„ÄÇÊàëÂÄëÁöÑÁµ±Ë®àÂíåÁîüÁâ©Ë©ï‰º∞È°ØÁ§∫ÔºåLLM ÂèØ‰ª•ÊîØÊè¥ÁîüÁâ©Á†îÁ©∂ÁöÑÁµ±Ë®àÂª∫Ê®°ÂíåË≥áÊñôÂêàÊàê„ÄÇ

##### **The effect of fine-tuning on language model toxicity**
2410.15821v1 by Will Hawkins, Brent Mittelstadt, Chris Russell

Fine-tuning language models has become increasingly popular following the
proliferation of open models and improvements in cost-effective parameter
efficient fine-tuning. However, fine-tuning can influence model properties such
as safety. We assess how fine-tuning can impact different open models'
propensity to output toxic content. We assess the impacts of fine-tuning Gemma,
Llama, and Phi models on toxicity through three experiments. We compare how
toxicity is reduced by model developers during instruction-tuning. We show that
small amounts of parameter-efficient fine-tuning on developer-tuned models via
low-rank adaptation on a non-adversarial dataset can significantly alter these
results across models. Finally, we highlight the impact of this in the wild,
demonstrating how toxicity rates of models fine-tuned by community contributors
can deviate in hard-to-predict ways.

ÊëòË¶ÅÔºöÈö®ËëóÈñãÊîæÊ®°ÂûãÁöÑÊôÆÂèäÂíåÊàêÊú¨ÊïàÁõäÂèÉÊï∏È´òÊïàÂæÆË™øÁöÑÈÄ≤Ê≠•ÔºåË™ûË®ÄÊ®°ÂûãÁöÑÂæÆË™øËÆäÂæóË∂ä‰æÜË∂äÊôÆÈÅç„ÄÇÁÑ∂ËÄåÔºåÂæÆË™øÊúÉÂΩ±ÈüøÊ®°ÂûãÂ±¨ÊÄßÔºå‰æãÂ¶ÇÂÆâÂÖ®ÊÄß„ÄÇÊàëÂÄëË©ï‰º∞ÂæÆË™øÂ¶Ç‰ΩïÂΩ±Èüø‰∏çÂêåÈñãÊîæÊ®°ÂûãËº∏Âá∫ÊúâÂÆ≥ÂÖßÂÆπÁöÑÂÇæÂêë„ÄÇÊàëÂÄëÈÄèÈÅé‰∏âÂÄãÂØ¶È©óË©ï‰º∞ÂæÆË™øÂ∞ç Gemma„ÄÅLlama Âíå Phi Ê®°ÂûãÊØíÊÄßÁöÑÂΩ±Èüø„ÄÇÊàëÂÄëÊØîËºÉÊ®°ÂûãÈñãÁôº‰∫∫Âì°Âú®Êåá‰ª§ÂæÆË™øÊúüÈñìÂ¶Ç‰ΩïÈôç‰ΩéÊØíÊÄß„ÄÇÊàëÂÄëË°®ÊòéÔºåÈÄèÈÅéÈùûÂ∞çÊäóÊÄßË≥áÊñôÈõÜ‰∏äÁöÑ‰ΩéÁß©ÈÅ©ÊáâÔºåÂú®ÈñãÁôº‰∫∫Âì°Ë™øÊï¥ÁöÑÊ®°Âûã‰∏äÈÄ≤Ë°åÂ∞ëÈáèÂèÉÊï∏È´òÊïàÂæÆË™øÔºåÂèØ‰ª•Âú®ÈÄô‰∫õÊ®°Âûã‰∏äÈ°ØËëóÊîπËÆäÈÄô‰∫õÁµêÊûú„ÄÇÊúÄÂæåÔºåÊàëÂÄëÂº∑Ë™øÈÄôÂú®ÂØ¶ÈöõÊÉÖÊ≥Å‰∏≠ÁöÑÂΩ±ÈüøÔºåÂ±ïÁ§∫Áî±Á§æÁæ§Ë≤¢ÁçªËÄÖÂæÆË™øÁöÑÊ®°ÂûãÁöÑÊØíÊÄßÁéáÂ¶Ç‰Ωï‰ª•Èõ£‰ª•È†êÊ∏¨ÁöÑÊñπÂºèÂÅèÈõ¢„ÄÇ

##### **LiMTR: Time Series Motion Prediction for Diverse Road Users through Multimodal Feature Integration**
2410.15819v1 by Camiel Oerlemans, Bram Grooten, Michiel Braat, Alaa Alassi, Emilia Silvas, Decebal Constantin Mocanu

Predicting the behavior of road users accurately is crucial to enable the
safe operation of autonomous vehicles in urban or densely populated areas.
Therefore, there has been a growing interest in time series motion prediction
research, leading to significant advancements in state-of-the-art techniques in
recent years. However, the potential of using LiDAR data to capture more
detailed local features, such as a person's gaze or posture, remains largely
unexplored. To address this, we develop a novel multimodal approach for motion
prediction based on the PointNet foundation model architecture, incorporating
local LiDAR features. Evaluation on the Waymo Open Dataset shows a performance
improvement of 6.20% and 1.58% in minADE and mAP respectively, when integrated
and compared with the previous state-of-the-art MTR. We open-source the code of
our LiMTR model.

ÊëòË¶ÅÔºöÊ∫ñÁ¢∫È†êÊ∏¨ÈÅìË∑Ø‰ΩøÁî®ËÄÖÁöÑË°åÁÇ∫Â∞çÊñºÂú®Â∏ÇÂçÄÊàñ‰∫∫Âè£Á®†ÂØÜÂú∞ÂçÄÂÆâÂÖ®Êìç‰ΩúËá™ÂãïÈßïÈßõËªäËºõËá≥ÈóúÈáçË¶Å„ÄÇÂõ†Ê≠§ÔºåÊôÇÂ∫èÈÅãÂãïÈ†êÊ∏¨Á†îÁ©∂ÂºïËµ∑‰∫ÜË∂ä‰æÜË∂äÂ§ßÁöÑËààË∂£Ôºå‰∏¶Âú®ËøëÂπ¥‰æÜ‰øÉÊàê‰∫ÜÊúÄÂÖàÈÄ≤ÊäÄË°ìÁöÑÈáçÂ§ßÈÄ≤Â±ï„ÄÇÁÑ∂ËÄåÔºåÂà©Áî® LiDAR Ë≥áÊñôÊçïÊçâÊõ¥Â§öË©≥Á¥∞ÁöÑÂ±ÄÈÉ®ÁâπÂæµÔºà‰æãÂ¶Ç‰∫∫ÁöÑË¶ñÁ∑öÊàñÂßøÂã¢ÔºâÁöÑÊΩõÂäõÂú®ÂæàÂ§ßÁ®ãÂ∫¶‰∏ä‰ªçÊú™ÈñãÁôº„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÂü∫Êñº PointNet Âü∫Á§éÊ®°ÂûãÊû∂ÊßãÈñãÁôº‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÂ§öÊ®°ÂºèÈÅãÂãïÈ†êÊ∏¨ÊñπÊ≥ïÔºå‰∏¶ÁµêÂêà‰∫ÜÂ±ÄÈÉ® LiDAR ÁâπÂæµ„ÄÇÂú® Waymo ÈñãÊîæË≥áÊñôÈõÜ‰∏äÁöÑË©ï‰º∞È°ØÁ§∫ÔºåËàáÂÖàÂâçÁöÑÊúÄÂÖàÈÄ≤ MTR Êï¥Âêà‰∏¶ÈÄ≤Ë°åÊØîËºÉÊôÇÔºåminADE Âíå mAP ÂàÜÂà•ÊîπÈÄ≤‰∫Ü 6.20% Âíå 1.58%„ÄÇÊàëÂÄëÈñãÊîæ‰∫Ü LiMTR Ê®°ÂûãÁöÑÁ®ãÂºèÁ¢º„ÄÇ

##### **Kaninfradet3D:A Road-side Camera-LiDAR Fusion 3D Perception Model based on Nonlinear Feature Extraction and Intrinsic Correlation**
2410.15814v1 by Pei Liu, Nanfang Zheng, Yiqun Li, Junlan Chen, Ziyuan Pu

With the development of AI-assisted driving, numerous methods have emerged
for ego-vehicle 3D perception tasks, but there has been limited research on
roadside perception. With its ability to provide a global view and a broader
sensing range, the roadside perspective is worth developing. LiDAR provides
precise three-dimensional spatial information, while cameras offer semantic
information. These two modalities are complementary in 3D detection. However,
adding camera data does not increase accuracy in some studies since the
information extraction and fusion procedure is not sufficiently reliable.
Recently, Kolmogorov-Arnold Networks (KANs) have been proposed as replacements
for MLPs, which are better suited for high-dimensional, complex data. Both the
camera and the LiDAR provide high-dimensional information, and employing KANs
should enhance the extraction of valuable features to produce better fusion
outcomes. This paper proposes Kaninfradet3D, which optimizes the feature
extraction and fusion modules. To extract features from complex
high-dimensional data, the model's encoder and fuser modules were improved
using KAN Layers. Cross-attention was applied to enhance feature fusion, and
visual comparisons verified that camera features were more evenly integrated.
This addressed the issue of camera features being abnormally concentrated,
negatively impacting fusion. Compared to the benchmark, our approach shows
improvements of +9.87 mAP and +10.64 mAP in the two viewpoints of the TUMTraf
Intersection Dataset and an improvement of +1.40 mAP in the roadside end of the
TUMTraf V2X Cooperative Perception Dataset. The results indicate that
Kaninfradet3D can effectively fuse features, demonstrating the potential of
applying KANs in roadside perception tasks.

ÊëòË¶ÅÔºö<paragraph>Èö®Ëëó AI ËºîÂä©ÈßïÈßõÁöÑÁôºÂ±ïÔºåÂ∑≤Âá∫ÁèæË®±Â§öÁî®ÊñºËá™ÊàëËªäËºõ 3D ÊÑüÁü•‰ªªÂãôÁöÑÊñπÊ≥ïÔºå‰ΩÜÂ∞çÊñºË∑ØÂÅ¥ÊÑüÁü•ÁöÑÁ†îÁ©∂ÂçªÂæàÊúâÈôê„ÄÇË∑ØÂÅ¥Ë¶ñËßíÁî±ÊñºËÉΩÊèê‰æõÂÖ®Â±ÄË¶ñËßíÂíåÊõ¥Âª£Ê≥õÁöÑÊÑüÊ∏¨ÁØÑÂúçÔºåÂõ†Ê≠§ÂÄºÂæóÁôºÂ±ï„ÄÇLiDAR ÂèØÊèê‰æõÁ≤æÁ¢∫ÁöÑ‰∏âÁ∂≠Á©∫ÈñìË≥áË®äÔºåËÄåÁõ∏Ê©üÂâáÊèê‰æõË™ûÊÑèË≥áË®ä„ÄÇÈÄôÂÖ©Á®ÆÊñπÂºèÂú® 3D ÂÅµÊ∏¨‰∏≠ÊòØ‰∫íË£úÁöÑ„ÄÇÁÑ∂ËÄåÔºåÂú®Êüê‰∫õÁ†îÁ©∂‰∏≠ÔºåÊñ∞Â¢ûÁõ∏Ê©üË≥áÊñô‰∏¶Êú™ÊèêÈ´òÊ∫ñÁ¢∫Â∫¶ÔºåÂõ†ÁÇ∫Ë≥áË®äÊì∑ÂèñÂíåËûçÂêàÁ®ãÂ∫è‰∏çÂ§†ÂèØÈù†„ÄÇÊúÄËøëÔºåKolmogorov-Arnold Á∂≤Ë∑Ø (KAN) Â∑≤Ë¢´ÊèêÂá∫‰ΩúÁÇ∫ MLP ÁöÑÊõø‰ª£ÊñπÊ°àÔºåÊõ¥ÈÅ©ÂêàÊñºÈ´òÁ∂≠Â∫¶„ÄÅË§áÈõúÁöÑË≥áÊñô„ÄÇÁõ∏Ê©üÂíå LiDAR ÈÉΩÊèê‰æõÈ´òÁ∂≠Â∫¶Ë≥áË®äÔºåËÄåÊé°Áî® KAN ÊáâÂèØÂ¢ûÂº∑ÊúâÂÉπÂÄºÁâπÂæµÁöÑÊì∑ÂèñÔºå‰ª•Áî¢ÁîüÊõ¥Â•ΩÁöÑËûçÂêàÁµêÊûú„ÄÇÊú¨ÊñáÊèêÂá∫ Kaninfradet3DÔºåÂÆÉÊúÄ‰Ω≥Âåñ‰∫ÜÁâπÂæµÊì∑ÂèñÂíåËûçÂêàÊ®°ÁµÑ„ÄÇÁÇ∫‰∫ÜÂæûË§áÈõúÁöÑÈ´òÁ∂≠Â∫¶Ë≥áÊñô‰∏≠Êì∑ÂèñÁâπÂæµÔºå‰ΩøÁî® KAN Â±§ÊîπÈÄ≤‰∫ÜÊ®°ÂûãÁöÑÁ∑®Á¢ºÂô®ÂíåËûçÂêàÂô®Ê®°ÁµÑ„ÄÇÊáâÁî®‰∫§ÂèâÊ≥®ÊÑèÂäõ‰æÜÂ¢ûÂº∑ÁâπÂæµËûçÂêàÔºåËÄåË¶ñË¶∫ÊØîËºÉÈ©óË≠â‰∫ÜÁõ∏Ê©üÁâπÂæµÊõ¥ÂùáÂãªÂú∞Êï¥Âêà„ÄÇÈÄôËß£Ê±∫‰∫ÜÁõ∏Ê©üÁâπÂæµÁï∞Â∏∏ÈõÜ‰∏≠ÁöÑÂïèÈ°åÔºåÂ∞çËûçÂêàÁî¢ÁîüË≤†Èù¢ÂΩ±Èüø„ÄÇËàáÂü∫Ê∫ñÁõ∏ÊØîÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÂú® TUMTraf ‰∫§ÂèâË∑ØÂè£Ë≥áÊñôÈõÜÁöÑÂÖ©ÂÄãË¶ñÈªû‰∏≠È°ØÁ§∫Âá∫ +9.87 mAP Âíå +10.64 mAP ÁöÑÊîπÈÄ≤Ôºå‰ª•ÂèäÂú® TUMTraf V2X Âêà‰ΩúÊÑüÁü•Ë≥áÊñôÈõÜÁöÑË∑ØÂÅ¥Á´ØÊîπÈÄ≤‰∫Ü +1.40 mAP„ÄÇÁµêÊûúË°®ÊòéÔºåKaninfradet3D ÂèØ‰ª•ÊúâÊïàËûçÂêàÁâπÂæµÔºåÂ±ïÁ§∫‰∫ÜÂ∞á KAN ÊáâÁî®ÊñºË∑ØÂÅ¥ÊÑüÁü•‰ªªÂãôÁöÑÊΩõÂäõ„ÄÇ</paragraph>

##### **RAG4ITOps: A Supervised Fine-Tunable and Comprehensive RAG Framework for IT Operations and Maintenance**
2410.15805v1 by Tianyang Zhang, Zhuoxuan Jiang, Shengguang Bai, Tianrui Zhang, Lin Lin, Yang Liu, Jiawei Ren

With the ever-increasing demands on Question Answering (QA) systems for IT
operations and maintenance, an efficient and supervised fine-tunable framework
is necessary to ensure the data security, private deployment and continuous
upgrading. Although Large Language Models (LLMs) have notably improved the
open-domain QA's performance, how to efficiently handle enterprise-exclusive
corpora and build domain-specific QA systems are still less-studied for
industrial applications. In this paper, we propose a general and comprehensive
framework based on Retrieval Augmented Generation (RAG) and facilitate the
whole business process of establishing QA systems for IT operations and
maintenance. In accordance with the prevailing RAG method, our proposed
framework, named with RAG4ITOps, composes of two major stages: (1) Models
Fine-tuning \& Data Vectorization, and (2) Online QA System Process. At the
Stage 1, we leverage a contrastive learning method with two negative sampling
strategies to fine-tune the embedding model, and design the instruction
templates to fine-tune the LLM with a Retrieval Augmented Fine-Tuning method.
At the Stage 2, an efficient process of QA system is built for serving. We
collect enterprise-exclusive corpora from the domain of cloud computing, and
the extensive experiments show that our method achieves superior results than
counterparts on two kinds of QA tasks. Our experiment also provide a case for
applying the RAG4ITOps to real-world enterprise-level applications.

ÊëòË¶ÅÔºöÈö®ËëóÂ∞ç IT ÈÅã‰ΩúÂíåÁ∂≠Ë≠∑‰∏≠ÂïèÁ≠î (QA) Á≥ªÁµ±ÈúÄÊ±ÇÁöÑÊåÅÁ∫åÂ¢ûÂä†Ôºå‰∏ÄÂÄãÈ´òÊïà‰∏îÂèØÁõ£Áù£ÂæÆË™øÁöÑÊ°ÜÊû∂Â∞çÊñºÁ¢∫‰øùË≥áÊñôÂÆâÂÖ®ÊÄß„ÄÅÁßÅÊúâÈÉ®ÁΩ≤ÂíåÊåÅÁ∫åÂçáÁ¥öÊòØÂøÖË¶ÅÁöÑ„ÄÇÂÑòÁÆ°Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤È°ØËëóÊîπÂñÑÈñãÊîæÈ†òÂüü QA ÁöÑÊïàËÉΩÔºå‰ΩÜÂ¶Ç‰ΩïÊúâÊïàËôïÁêÜ‰ºÅÊ•≠Â∞àÂ±¨Ë™ûÊñôÂ∫´‰∏¶Âª∫ÊßãÁâπÂÆöÈ†òÂüüÁöÑ QA Á≥ªÁµ±ÔºåÂ∞çÊñºÁî¢Ê•≠ÊáâÁî®‰æÜË™™‰ªçËºÉÂ∞ëË¢´Á†îÁ©∂„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÂü∫ÊñºÊ™¢Á¥¢Êì¥ÂÖÖÁîüÊàê (RAG) ÁöÑÈÄöÁî®‰∏îÂÖ®Èù¢ÁöÑÊ°ÜÊû∂Ôºå‰∏¶‰øÉÈÄ≤Âª∫Á´ã QA Á≥ªÁµ±‰ª•ÈÄ≤Ë°å IT ÈÅã‰ΩúÂíåÁ∂≠Ë≠∑ÁöÑÊï¥ÂÄãÊ•≠ÂãôÊµÅÁ®ã„ÄÇÊ†πÊìöÁèæË°åÁöÑ RAG ÊñπÊ≥ïÔºåÊàëÂÄëÊèêÂá∫ÁöÑÊ°ÜÊû∂ÂëΩÂêçÁÇ∫ RAG4ITOpsÔºåÁî±ÂÖ©ÂÄã‰∏ªË¶ÅÈöéÊÆµÁµÑÊàêÔºö(1) Ê®°ÂûãÂæÆË™øËàáË≥áÊñôÂêëÈáèÂåñÔºå‰ª•Âèä (2) Á∑ö‰∏ä QA Á≥ªÁµ±ÊµÅÁ®ã„ÄÇÂú®ÈöéÊÆµ 1 ‰∏≠ÔºåÊàëÂÄëÂà©Áî®Â∞çÊØîÂ≠∏ÁøíÊñπÊ≥ïÂíåÂÖ©Á®ÆË≤†Èù¢ÊäΩÊ®£Á≠ñÁï•‰æÜÂæÆË™øÂµåÂÖ•Ê®°ÂûãÔºå‰∏¶Ë®≠Ë®àÊåá‰ª§ÁØÑÊú¨‰ª•‰ΩøÁî®Ê™¢Á¥¢Êì¥ÂÖÖÂæÆË™øÊñπÊ≥ïÂæÆË™ø LLM„ÄÇÂú®ÈöéÊÆµ 2 ‰∏≠ÔºåÂª∫Êßã‰∏ÄÂÄãÈ´òÊïàÁöÑ QA Á≥ªÁµ±ÊµÅÁ®ã‰ª•Êèê‰æõÊúçÂãô„ÄÇÊàëÂÄëÂæûÈõ≤Á´ØÈÅãÁÆóÈ†òÂüüÊî∂ÈõÜ‰ºÅÊ•≠Â∞àÂ±¨Ë™ûÊñôÂ∫´ÔºåÂª£Ê≥õÁöÑÂØ¶È©óÈ°ØÁ§∫ÔºåÊàëÂÄëÁöÑÊ®°ÂûãÂú®ÂÖ©Á®Æ QA ‰ªªÂãô‰∏äÈÉΩÂÑ™ÊñºÂÖ∂‰ªñÊ®°Âûã„ÄÇÊàëÂÄëÁöÑÂØ¶È©ó‰πüÊèê‰æõ‰∫ÜÂ∞á RAG4ITOps ÊáâÁî®ÊñºÂØ¶Èöõ‰∏ñÁïå‰ºÅÊ•≠Á¥öÊáâÁî®ÁöÑÊ°à‰æã„ÄÇ

##### **Deep Learning and Data Augmentation for Detecting Self-Admitted Technical Debt**
2410.15804v1 by Edi Sutoyo, Paris Avgeriou, Andrea Capiluppi

Self-Admitted Technical Debt (SATD) refers to circumstances where developers
use textual artifacts to explain why the existing implementation is not
optimal. Past research in detecting SATD has focused on either identifying SATD
(classifying SATD items as SATD or not) or categorizing SATD (labeling
instances as SATD that pertain to requirement, design, code, test debt, etc.).
However, the performance of these approaches remains suboptimal, particularly
for specific types of SATD, such as test and requirement debt, primarily due to
extremely imbalanced datasets. To address these challenges, we build on earlier
research by utilizing BiLSTM architecture for the binary identification of SATD
and BERT architecture for categorizing different types of SATD. Despite their
effectiveness, both architectures struggle with imbalanced data. Therefore, we
employ a large language model data augmentation strategy to mitigate this
issue. Furthermore, we introduce a two-step approach to identify and categorize
SATD across various datasets derived from different artifacts. Our
contributions include providing a balanced dataset for future SATD researchers
and demonstrating that our approach significantly improves SATD identification
and categorization performance compared to baseline methods.

ÊëòË¶ÅÔºöËá™ÊàëÊâøË™çÊäÄË°ìË≤†ÂÇµ (SATD) ÊåáÁöÑÊòØÈñãÁôº‰∫∫Âì°‰ΩøÁî®ÊñáÂ≠ó‰∫∫Â∑•Ë£ΩÂìÅ‰æÜËß£ÈáãÁÇ∫‰ΩïÁèæÊúâÂØ¶‰Ωú‰∏¶ÈùûÊúÄ‰Ω≥„ÄÇÈÅéÂéªÂú®ÂÅµÊ∏¨ SATD ÁöÑÁ†îÁ©∂ÔºåÈáçÈªûÂú®ÊñºË≠òÂà• SATD (Â∞á SATD È†ÖÁõÆÂàÜÈ°ûÁÇ∫ SATD ÊàñÈùû SATD) ÊàñÂàÜÈ°û SATD (Â∞áÂØ¶‰æãÊ®ôË®òÁÇ∫ËàáÈúÄÊ±Ç„ÄÅË®≠Ë®à„ÄÅÁ®ãÂºèÁ¢º„ÄÅÊ∏¨Ë©¶Ë≤†ÂÇµÁ≠âÁõ∏ÈóúÁöÑ SATD)„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÊñπÊ≥ïÁöÑÊïàËÉΩ‰ªçÁÑ∂Ê¨°‰Ω≥ÔºåÁâπÂà•ÊòØÂ∞çÊñºÁâπÂÆöÈ°ûÂûãÁöÑ SATDÔºå‰æãÂ¶ÇÊ∏¨Ë©¶ÂíåÈúÄÊ±ÇË≤†ÂÇµÔºåÈÄô‰∏ªË¶ÅÊòØÂõ†ÁÇ∫Ë≥áÊñôÈõÜÊ•µÂ∫¶‰∏çÂπ≥Ë°°„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÊ†πÊìöÂÖàÂâçÁöÑÁ†îÁ©∂ÔºåÂà©Áî® BiLSTM Êû∂ÊßãÈÄ≤Ë°å SATD ÁöÑ‰∫åÂÖÉË≠òÂà•Ôºå‰∏¶Âà©Áî® BERT Êû∂ÊßãÂ∞ç‰∏çÂêåÈ°ûÂûãÁöÑ SATD ÈÄ≤Ë°åÂàÜÈ°û„ÄÇÂÑòÁÆ°ÂÆÉÂÄëÂæàÊúâÊïàÔºå‰ΩÜÈÄôÂÖ©Á®ÆÊû∂ÊßãÈÉΩÈõ£‰ª•Êáâ‰ªò‰∏çÂπ≥Ë°°ÁöÑË≥áÊñô„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëÊé°Áî®Â§ßÂûãË™ûË®ÄÊ®°ÂûãË≥áÊñôÊì¥ÂÖÖÁ≠ñÁï•‰æÜÊ∏õËºïÈÄôÂÄãÂïèÈ°å„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÂÖ©Ê≠•È©üÊñπÊ≥ï‰æÜË≠òÂà•ÂíåÂàÜÈ°û‰æÜËá™‰∏çÂêå‰∫∫Â∑•Ë£ΩÂìÅÁöÑ‰∏çÂêåË≥áÊñôÈõÜ‰∏≠ÁöÑ SATD„ÄÇÊàëÂÄëÁöÑË≤¢ÁçªÂåÖÊã¨ÁÇ∫Êú™‰æÜÁöÑ SATD Á†îÁ©∂‰∫∫Âì°Êèê‰æõ‰∏ÄÂÄãÂπ≥Ë°°ÁöÑË≥áÊñôÈõÜÔºå‰∏¶Ë≠âÊòéËàáÂü∫Á∑öÊñπÊ≥ïÁõ∏ÊØîÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÈ°ØËëóÊîπÂñÑ‰∫Ü SATD Ë≠òÂà•ÂíåÂàÜÈ°ûÊïàËÉΩ„ÄÇ

##### **Habaek: High-performance water segmentation through dataset expansion and inductive bias optimization**
2410.15794v1 by Hanseon Joo, Eunji Lee, Minjong Cheon

Water segmentation is critical to disaster response and water resource
management. Authorities may employ high-resolution photography to monitor
rivers, lakes, and reservoirs, allowing for more proactive management in
agriculture, industry, and conservation. Deep learning has improved flood
monitoring by allowing models like CNNs, U-Nets, and transformers to handle
large volumes of satellite and aerial data. However, these models usually have
significant processing requirements, limiting their usage in real-time
applications. This research proposes upgrading the SegFormer model for water
segmentation by data augmentation with datasets such as ADE20K and RIWA to
boost generalization. We examine how inductive bias affects attention-based
models and discover that SegFormer performs better on bigger datasets. To
further demonstrate the function of data augmentation, Low-Rank Adaptation
(LoRA) is used to lower processing complexity while preserving accuracy. We
show that the suggested Habaek model outperforms current models in
segmentation, with an Intersection over Union (IoU) ranging from 0.91986 to
0.94397. In terms of F1-score, recall, accuracy, and precision, Habaek performs
better than rival models, indicating its potential for real-world applications.
This study highlights the need to enhance structures and include datasets for
effective water segmentation.

ÊëòË¶ÅÔºöÊ∞¥È´îÂàÜÂâ≤Â∞çÊñºÁÅΩÂÆ≥ÊáâËÆäÂíåÊ∞¥Ë≥áÊ∫êÁÆ°ÁêÜËá≥ÈóúÈáçË¶Å„ÄÇÁï∂Â±ÄÂèØ‰ª•Êé°Áî®È´òËß£ÊûêÂ∫¶ÊîùÂΩ±‰æÜÁõ£ÊéßÊ≤≥ÊµÅ„ÄÅÊπñÊ≥äÂíåÊ∞¥Â∫´Ôºå‰ª•‰æøÂú®Ëæ≤Ê•≠„ÄÅÂ∑•Ê•≠Âíå‰øùËÇ≤ÊñπÈù¢ÈÄ≤Ë°åÊõ¥Á©çÊ•µÁöÑÁÆ°ÁêÜ„ÄÇÊ∑±Â∫¶Â≠∏ÁøíÈÄèÈÅéËÆì CNN„ÄÅU-Net Âíå Transformer Á≠âÊ®°ÂûãËôïÁêÜÂ§ßÈáèË°õÊòüÂíåÁ©∫‰∏≠Ë≥áÊñôÔºåÊîπÈÄ≤‰∫ÜÊ¥™Ê∞¥Áõ£Ê∏¨„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÊ®°ÂûãÈÄöÂ∏∏ÊúâÂ§ßÈáèÁöÑËôïÁêÜÈúÄÊ±ÇÔºåÈôêÂà∂‰∫ÜÂÆÉÂÄëÂú®Âç≥ÊôÇÊáâÁî®‰∏≠ÁöÑ‰ΩøÁî®„ÄÇÊú¨Á†îÁ©∂ÊèêÂá∫ÈÄèÈÅéË≥áÊñôÊì¥ÂÖÖÔºå‰æãÂ¶Ç ADE20K Âíå RIWA Á≠âË≥áÊñôÈõÜÔºåÂçáÁ¥ö SegFormer Ê®°Âûã‰ª•ÈÄ≤Ë°åÊ∞¥È´îÂàÜÂâ≤Ôºå‰ª•ÊèêÂçáÊ≥õÂåñËÉΩÂäõ„ÄÇÊàëÂÄëÊé¢Ë®éÊ≠∏Á¥çÂÅèÂ∑ÆÂ¶Ç‰ΩïÂΩ±ÈüøÂü∫ÊñºÊ≥®ÊÑèÂäõÁöÑÊ®°ÂûãÔºå‰∏¶ÁôºÁèæ SegFormer Âú®ËºÉÂ§ßÁöÑË≥áÊñôÈõÜ‰∏äË°®ÁèæÂæóÊõ¥Â•Ω„ÄÇÁÇ∫‰∫ÜÈÄ≤‰∏ÄÊ≠•Â±ïÁ§∫Ë≥áÊñôÊì¥ÂÖÖÁöÑÂäüËÉΩÔºå‰ΩéÁß©ÈÅ©Êáâ (LoRA) Áî®ÊñºÈôç‰ΩéËôïÁêÜË§áÈõúÂ∫¶ÔºåÂêåÊôÇ‰øùÊåÅÊ∫ñÁ¢∫Â∫¶„ÄÇÊàëÂÄëÂ±ïÁ§∫Âª∫Ë≠∞ÁöÑ Habaek Ê®°ÂûãÂú®ÂàÜÂâ≤ÊñπÈù¢ÂÑ™ÊñºÁõÆÂâçÁöÑÊ®°ÂûãÔºåÂÖ∂‰∫§ÈõÜ‰∏¶ÈõÜ (IoU) ‰ªãÊñº 0.91986 Âà∞ 0.94397„ÄÇÂú® F1 ÂàÜÊï∏„ÄÅÂè¨ÂõûÁéá„ÄÅÊ∫ñÁ¢∫Â∫¶ÂíåÁ≤æÁ¢∫Â∫¶ÊñπÈù¢ÔºåHabaek ÁöÑË°®ÁèæÂÑ™ÊñºÁ´∂Áà≠Ê®°ÂûãÔºåÈ°ØÁ§∫ÂÖ∂Âú®ÂØ¶ÈöõÊáâÁî®‰∏≠ÁöÑÊΩõÂäõ„ÄÇÊú¨Á†îÁ©∂Âº∑Ë™ø‰∫ÜÂ¢ûÂº∑ÁµêÊßãÂíåÁ¥çÂÖ•Ë≥áÊñôÈõÜ‰ª•ÈÄ≤Ë°åÊúâÊïàÊ∞¥È´îÂàÜÂâ≤ÁöÑÂøÖË¶ÅÊÄß„ÄÇ

##### **Arithmetic Transformers Can Length-Generalize in Both Operand Length and Count**
2410.15787v1 by Hanseul Cho, Jaeyoung Cha, Srinadh Bhojanapalli, Chulhee Yun

Transformers often struggle with length generalization, meaning they fail to
generalize to sequences longer than those encountered during training. While
arithmetic tasks are commonly used to study length generalization, certain
tasks are considered notoriously difficult, e.g., multi-operand addition
(requiring generalization over both the number of operands and their lengths)
and multiplication (requiring generalization over both operand lengths). In
this work, we achieve approximately 2-3x length generalization on both tasks,
which is the first such achievement in arithmetic Transformers. We design
task-specific scratchpads enabling the model to focus on a fixed number of
tokens per each next-token prediction step, and apply multi-level versions of
Position Coupling (Cho et al., 2024; McLeish et al., 2024) to let Transformers
know the right position to attend to. On the theory side, we prove that a
1-layer Transformer using our method can solve multi-operand addition, up to
operand length and operand count that are exponential in embedding dimension.

ÊëòË¶ÅÔºöËÆäÂΩ¢ÈáëÂâõÈÄöÂ∏∏Èõ£‰ª•Êáâ‰ªòÈï∑Â∫¶Ê¶ÇÊã¨ÔºåË°®Á§∫ÂÆÉÂÄëÁÑ°Ê≥ïÊ¶ÇÊã¨Âà∞ÊØîË®ìÁ∑¥ÊúüÈñìÈÅáÂà∞ÁöÑÊõ¥Èï∑ÁöÑÂ∫èÂàó„ÄÇÈõñÁÑ∂Êï∏Â≠∏‰ªªÂãôÈÄöÂ∏∏Áî®ÊñºÁ†îÁ©∂Èï∑Â∫¶Ê¶ÇÊã¨Ôºå‰ΩÜÊüê‰∫õ‰ªªÂãôË¢´Ë™çÁÇ∫ÈùûÂ∏∏Âõ∞Èõ£Ôºå‰æãÂ¶ÇÂ§öÈÅãÁÆóÂÖÉÂä†Ê≥ïÔºàÈúÄË¶ÅÂ∞çÈÅãÁÆóÂÖÉÊï∏ÁõÆÂèäÂÖ∂Èï∑Â∫¶ÈÄ≤Ë°åÊ¶ÇÊã¨ÔºâÂíå‰πòÊ≥ïÔºàÈúÄË¶ÅÂ∞çÂÖ©ÂÄãÈÅãÁÆóÂÖÉÈï∑Â∫¶ÈÄ≤Ë°åÊ¶ÇÊã¨Ôºâ„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÂú®ÂÖ©ÂÄã‰ªªÂãô‰∏äÂØ¶Áèæ‰∫ÜÂ§ßÁ¥Ñ 2-3 ÂÄçÁöÑÈï∑Â∫¶Ê¶ÇÊã¨ÔºåÈÄôÊòØÁÆóË°ìËÆäÂΩ¢ÈáëÂâõ‰∏≠ÁöÑÈ¶ñÊ¨°Ê≠§È°ûÊàêÂ∞±„ÄÇÊàëÂÄëË®≠Ë®à‰∫ÜÁâπÂÆöÊñº‰ªªÂãôÁöÑÊö´Â≠òÂô®Ôºå‰ΩøÊ®°ÂûãËÉΩÂ§†Â∞àÊ≥®ÊñºÊØèÂÄã‰∏ã‰∏ÄÂÄã‰ª£Âπ£È†êÊ∏¨Ê≠•È©ü‰∏≠ÁöÑÂõ∫ÂÆö‰ª£Âπ£Êï∏Ôºå‰∏¶ÊáâÁî®Â§öÁ¥öÁâàÊú¨ÁöÑ Position CouplingÔºàCho Á≠â‰∫∫Ôºå2024ÔºõMcLeish Á≠â‰∫∫Ôºå2024ÔºâËÆìËÆäÂΩ¢ÈáëÂâõÁü•ÈÅìË¶ÅÈóúÊ≥®ÁöÑÊ≠£Á¢∫‰ΩçÁΩÆ„ÄÇÂú®ÁêÜË´ñÊñπÈù¢ÔºåÊàëÂÄëË≠âÊòé‰ΩøÁî®ÊàëÂÄëÊñπÊ≥ïÁöÑ 1 Â±§ËÆäÂΩ¢ÈáëÂâõÂèØ‰ª•Ëß£Ê±∫Â§öÈÅãÁÆóÂÖÉÂä†Ê≥ïÔºåÁõ¥Âà∞ÈÅãÁÆóÂÖÉÈï∑Â∫¶ÂíåÈÅãÁÆóÂÖÉÊï∏ÈáèÂú®ÂµåÂÖ•Á∂≠Â∫¶‰∏≠ÂëàÊåáÊï∏Á¥öÂ¢ûÈï∑„ÄÇ

