{"2411.08028": {"publish_time": "2024-11-12", "title": "Learning with Less: Knowledge Distillation from Large Language Models via Unlabeled Data", "paper_summary": "In real-world NLP applications, Large Language Models (LLMs) offer promising\nsolutions due to their extensive training on vast datasets. However, the large\nsize and high computation demands of LLMs limit their practicality in many\napplications, especially when further fine-tuning is required. To address these\nlimitations, smaller models are typically preferred for deployment. However,\ntheir training is hindered by the scarcity of labeled data. In contrast,\nunlabeled data is often readily which can be leveraged by using LLMs to\ngenerate pseudo-labels for training smaller models. This enables the smaller\nmodels (student) to acquire knowledge from LLMs(teacher) while reducing\ncomputational costs. This process introduces challenges, such as potential\nnoisy pseudo-labels. Selecting high-quality and informative data is therefore\ncritical to enhance model performance while improving the efficiency of data\nutilization. To address this, we propose LLKD that enables Learning with Less\ncomputational resources and less data for Knowledge Distillation from LLMs.\nLLKD is an adaptive sample selection method that incorporates signals from both\nthe teacher and student. Specifically, it prioritizes samples where the teacher\ndemonstrates high confidence in its labeling, indicating reliable labels, and\nwhere the student exhibits a high information need, identifying challenging\nsamples that require further learning. Our comprehensive experiments show that\nLLKD achieves superior performance across various datasets with higher data\nefficiency.", "paper_summary_zh": "\u5728\u5be6\u969b\u7684 NLP \u61c9\u7528\u4e2d\uff0c\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u56e0\u5176\u5728\u5927\u91cf\u8cc7\u6599\u96c6\u4e0a\u7684\u5ee3\u6cdb\u8a13\u7df4\u800c\u63d0\u4f9b\u6709\u524d\u666f\u7684\u89e3\u6c7a\u65b9\u6848\u3002\u7136\u800c\uff0cLLM \u7684\u9f90\u5927\u898f\u6a21\u548c\u9ad8\u904b\u7b97\u9700\u6c42\u9650\u5236\u4e86\u5b83\u5011\u5728\u8a31\u591a\u61c9\u7528\u4e2d\u7684\u5be6\u7528\u6027\uff0c\u7279\u5225\u662f\u5728\u9700\u8981\u9032\u4e00\u6b65\u5fae\u8abf\u6642\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u4e9b\u9650\u5236\uff0c\u901a\u5e38\u504f\u597d\u8f03\u5c0f\u7684\u6a21\u578b\u9032\u884c\u90e8\u7f72\u3002\u7136\u800c\uff0c\u5b83\u5011\u7684\u8a13\u7df4\u53d7\u5230\u6a19\u8a18\u8cc7\u6599\u7684\u7a00\u7f3a\u6027\u963b\u7919\u3002\u76f8\u53cd\uff0c\u672a\u6a19\u8a18\u7684\u8cc7\u6599\u901a\u5e38\u5f88\u5bb9\u6613\u7372\u5f97\uff0c\u53ef\u4ee5\u4f7f\u7528 LLM \u70ba\u8f03\u5c0f\u7684\u6a21\u578b\u751f\u6210\u507d\u6a19\u7c64\u9032\u884c\u8a13\u7df4\u3002\u9019\u4f7f\u8f03\u5c0f\u7684\u6a21\u578b\uff08\u5b78\u751f\uff09\u80fd\u5920\u5f9e LLM\uff08\u8001\u5e2b\uff09\u90a3\u88e1\u7372\u53d6\u77e5\u8b58\uff0c\u540c\u6642\u964d\u4f4e\u904b\u7b97\u6210\u672c\u3002\u9019\u500b\u904e\u7a0b\u6703\u5e36\u4f86\u6311\u6230\uff0c\u4f8b\u5982\u6f5b\u5728\u7684\u96dc\u8a0a\u507d\u6a19\u7c64\u3002\u56e0\u6b64\uff0c\u9078\u64c7\u9ad8\u54c1\u8cea\u4e14\u6709\u8cc7\u8a0a\u6027\u7684\u8cc7\u6599\u5c0d\u65bc\u63d0\u9ad8\u6a21\u578b\u6548\u80fd\u4e26\u63d0\u9ad8\u8cc7\u6599\u5229\u7528\u7387\u81f3\u95dc\u91cd\u8981\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u6211\u5011\u63d0\u51fa\u4e86 LLKD\uff0c\u5b83\u53ef\u4ee5\u5728\u5f9e LLM \u4e2d\u9032\u884c\u77e5\u8b58\u84b8\u993e\u6642\u4f7f\u7528\u8f03\u5c11\u7684\u904b\u7b97\u8cc7\u6e90\u548c\u8f03\u5c11\u7684\u8cc7\u6599\u9032\u884c\u5b78\u7fd2\u3002LLKD \u662f\u4e00\u7a2e\u81ea\u9069\u61c9\u7684\u6a23\u672c\u9078\u64c7\u65b9\u6cd5\uff0c\u5b83\u7d50\u5408\u4e86\u8001\u5e2b\u548c\u5b78\u751f\u7684\u8a0a\u865f\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u5b83\u512a\u5148\u8003\u616e\u8001\u5e2b\u5728\u6a19\u8a18\u4e2d\u8868\u73fe\u51fa\u9ad8\u5ea6\u4fe1\u5fc3\u7684\u6a23\u672c\uff0c\u8868\u793a\u6a19\u7c64\u53ef\u9760\uff0c\u4ee5\u53ca\u5b78\u751f\u8868\u73fe\u51fa\u9ad8\u5ea6\u8cc7\u8a0a\u9700\u6c42\u7684\u6a23\u672c\uff0c\u8b58\u5225\u9700\u8981\u9032\u4e00\u6b65\u5b78\u7fd2\u7684\u5177\u6709\u6311\u6230\u6027\u7684\u6a23\u672c\u3002\u6211\u5011\u7684\u7d9c\u5408\u5be6\u9a57\u8868\u660e\uff0cLLKD \u5728\u5177\u6709\u66f4\u9ad8\u8cc7\u6599\u6548\u7387\u7684\u5404\u7a2e\u8cc7\u6599\u96c6\u4e0a\u5be6\u73fe\u4e86\u5353\u8d8a\u7684\u6548\u80fd\u3002", "author": "Juanhui Li et.al.", "authors": "Juanhui Li, Sreyashi Nag, Hui Liu, Xianfeng Tang, Sheikh Sarwar, Limeng Cui, Hansu Gu, Suhang Wang, Qi He, Jiliang Tang", "id": "2411.08028v1", "paper_url": "http://arxiv.org/abs/2411.08028v1", "repo": "null"}}