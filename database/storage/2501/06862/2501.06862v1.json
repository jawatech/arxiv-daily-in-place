{"2501.06862": {"publish_time": "2025-01-12", "title": "LarvSeg: Exploring Image Classification Data For Large Vocabulary Semantic Segmentation via Category-wise Attentive Classifier", "paper_summary": "Scaling up the vocabulary of semantic segmentation models is extremely\nchallenging because annotating large-scale mask labels is labour-intensive and\ntime-consuming. Recently, language-guided segmentation models have been\nproposed to address this challenge. However, their performance drops\nsignificantly when applied to out-of-distribution categories. In this paper, we\npropose a new large vocabulary semantic segmentation framework, called LarvSeg.\nDifferent from previous works, LarvSeg leverages image classification data to\nscale the vocabulary of semantic segmentation models as large-vocabulary\nclassification datasets usually contain balanced categories and are much easier\nto obtain. However, for classification tasks, the category is image-level,\nwhile for segmentation we need to predict the label at pixel level. To address\nthis issue, we first propose a general baseline framework to incorporate\nimage-level supervision into the training process of a pixel-level segmentation\nmodel, making the trained network perform semantic segmentation on newly\nintroduced categories in the classification data. We then observe that a model\ntrained on segmentation data can group pixel features of categories beyond the\ntraining vocabulary. Inspired by this finding, we design a category-wise\nattentive classifier to apply supervision to the precise regions of\ncorresponding categories to improve the model performance. Extensive\nexperiments demonstrate that LarvSeg significantly improves the large\nvocabulary semantic segmentation performance, especially in the categories\nwithout mask labels. For the first time, we provide a 21K-category semantic\nsegmentation model with the help of ImageNet21K. The code is available at\nhttps://github.com/HaojunYu1998/large_voc_seg.", "paper_summary_zh": "<paragraph>\u64f4\u5c55\u8a9e\u610f\u5206\u5272\u6a21\u578b\u7684\u8a5e\u5f59\u6975\u5177\u6311\u6230\u6027\uff0c\u56e0\u70ba\u6a19\u8a3b\u5927\u898f\u6a21\u906e\u7f69\u6a19\u7c64\u9700\u8981\u5927\u91cf\u52de\u52d5\u529b\u4e14\u8017\u6642\u3002\u6700\u8fd1\uff0c\u8a9e\u8a00\u5f15\u5c0e\u5206\u5272\u6a21\u578b\u5df2\u88ab\u63d0\u51fa\u4ee5\u89e3\u6c7a\u6b64\u6311\u6230\u3002\u7136\u800c\uff0c\u7576\u61c9\u7528\u65bc\u5206\u5e03\u5916\u985e\u5225\u6642\uff0c\u5176\u6548\u80fd\u6703\u986f\u8457\u4e0b\u964d\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e00\u500b\u65b0\u7684\u5927\u578b\u8a5e\u5f59\u8a9e\u610f\u5206\u5272\u6846\u67b6\uff0c\u7a31\u70ba LarvSeg\u3002\u8207\u5148\u524d\u7684\u7814\u7a76\u4e0d\u540c\uff0cLarvSeg \u5229\u7528\u5f71\u50cf\u5206\u985e\u8cc7\u6599\u4f86\u64f4\u5c55\u8a9e\u610f\u5206\u5272\u6a21\u578b\u7684\u8a5e\u5f59\uff0c\u56e0\u70ba\u5927\u578b\u8a5e\u5f59\u5206\u985e\u8cc7\u6599\u96c6\u901a\u5e38\u5305\u542b\u5e73\u8861\u7684\u985e\u5225\u4e14\u66f4\u5bb9\u6613\u53d6\u5f97\u3002\u7136\u800c\uff0c\u5c0d\u65bc\u5206\u985e\u4efb\u52d9\uff0c\u985e\u5225\u662f\u5f71\u50cf\u5c64\u7d1a\u7684\uff0c\u800c\u5c0d\u65bc\u5206\u5272\uff0c\u6211\u5011\u9700\u8981\u5728\u756b\u7d20\u5c64\u7d1a\u9810\u6e2c\u6a19\u7c64\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u6211\u5011\u9996\u5148\u63d0\u51fa\u4e00\u500b\u901a\u7528\u7684\u57fa\u6e96\u67b6\u69cb\uff0c\u5c07\u5f71\u50cf\u5c64\u7d1a\u76e3\u7763\u7d0d\u5165\u756b\u7d20\u5c64\u7d1a\u5206\u5272\u6a21\u578b\u7684\u8a13\u7df4\u904e\u7a0b\u4e2d\uff0c\u8b93\u8a13\u7df4\u597d\u7684\u7db2\u8def\u5c0d\u5206\u985e\u8cc7\u6599\u4e2d\u65b0\u5f15\u5165\u7684\u985e\u5225\u57f7\u884c\u8a9e\u610f\u5206\u5272\u3002\u7136\u5f8c\u6211\u5011\u89c0\u5bdf\u5230\uff0c\u5728\u5206\u5272\u8cc7\u6599\u4e0a\u8a13\u7df4\u7684\u6a21\u578b\u53ef\u4ee5\u5c07\u985e\u5225\u7684\u756b\u7d20\u7279\u5fb5\u5206\u7d44\u5230\u8a13\u7df4\u8a5e\u5f59\u4e4b\u5916\u3002\u53d7\u5230\u9019\u500b\u767c\u73fe\u7684\u555f\u767c\uff0c\u6211\u5011\u8a2d\u8a08\u4e86\u4e00\u500b\u985e\u5225\u660e\u667a\u7684\u6ce8\u610f\u529b\u5206\u985e\u5668\uff0c\u5c07\u76e3\u7763\u61c9\u7528\u65bc\u5c0d\u61c9\u985e\u5225\u7684\u7cbe\u78ba\u5340\u57df\u4ee5\u6539\u5584\u6a21\u578b\u6548\u80fd\u3002\u5ee3\u6cdb\u7684\u5be6\u9a57\u8b49\u660e\uff0cLarvSeg \u5927\u5e45\u6539\u5584\u4e86\u5927\u578b\u8a5e\u5f59\u8a9e\u610f\u5206\u5272\u6548\u80fd\uff0c\u7279\u5225\u662f\u5728\u6c92\u6709\u906e\u7f69\u6a19\u7c64\u7684\u985e\u5225\u4e2d\u3002\u6211\u5011\u9996\u6b21\u5728 ImageNet21K \u7684\u5e6b\u52a9\u4e0b\u63d0\u4f9b\u4e86 21K \u985e\u5225\u7684\u8a9e\u610f\u5206\u5272\u6a21\u578b\u3002\u7a0b\u5f0f\u78bc\u53ef\u5728 https://github.com/HaojunYu1998/large_voc_seg \u53d6\u5f97\u3002</paragraph>", "author": "Haojun Yu et.al.", "authors": "Haojun Yu, Di Dai, Ziwei Zhao, Di He, Han Hu, Liwei Wang", "id": "2501.06862v1", "paper_url": "http://arxiv.org/abs/2501.06862v1", "repo": "https://github.com/haojunyu1998/larvseg"}}