{"2406.16609": {"publish_time": "2024-06-24", "title": "Evaluating the Robustness of Deep-Learning Algorithm-Selection Models by Evolving Adversarial Instances", "paper_summary": "Deep neural networks (DNN) are increasingly being used to perform\nalgorithm-selection in combinatorial optimisation domains, particularly as they\naccommodate input representations which avoid designing and calculating\nfeatures. Mounting evidence from domains that use images as input shows that\ndeep convolutional networks are vulnerable to adversarial samples, in which a\nsmall perturbation of an instance can cause the DNN to misclassify. However, it\nremains unknown as to whether deep recurrent networks (DRN) which have recently\nbeen shown promise as algorithm-selectors in the bin-packing domain are equally\nvulnerable. We use an evolutionary algorithm (EA) to find perturbations of\ninstances from two existing benchmarks for online bin packing that cause\ntrained DRNs to misclassify: adversarial samples are successfully generated\nfrom up to 56% of the original instances depending on the dataset. Analysis of\nthe new misclassified instances sheds light on the `fragility' of some training\ninstances, i.e. instances where it is trivial to find a small perturbation that\nresults in a misclassification and the factors that influence this. Finally,\nthe method generates a large number of new instances misclassified with a wide\nvariation in confidence, providing a rich new source of training data to create\nmore robust models.", "paper_summary_zh": "\u6df1\u5ea6\u795e\u7ecf\u7db2\u8def\uff08DNN\uff09\u6b63\u8d8a\u4f86\u8d8a\u5e38\u88ab\u7528\u65bc\u5728\u7d44\u5408\u6700\u4f73\u5316\u9818\u57df\u57f7\u884c\u6f14\u7b97\u6cd5\u9078\u64c7\uff0c\u7279\u5225\u662f\u56e0\u70ba\u5b83\u5011\u5bb9\u7d0d\u907f\u514d\u8a2d\u8a08\u548c\u8a08\u7b97\u7279\u5fb5\u7684\u8f38\u5165\u8868\u793a\u3002\u4f7f\u7528\u5f71\u50cf\u4f5c\u70ba\u8f38\u5165\u7684\u9818\u57df\u7684\u7d2f\u7a4d\u8b49\u64da\u986f\u793a\uff0c\u6df1\u5ea6\u5377\u7a4d\u7db2\u8def\u5bb9\u6613\u53d7\u5230\u5c0d\u6297\u6027\u7bc4\u4f8b\u7684\u5f71\u97ff\uff0c\u5176\u4e2d\u4e00\u500b\u5be6\u4f8b\u7684\u5fae\u5c0f\u64fe\u52d5\u53ef\u80fd\u5c0e\u81f4 DNN \u932f\u8aa4\u5206\u985e\u3002\u7136\u800c\uff0c\u6700\u8fd1\u88ab\u8b49\u660e\u6709\u671b\u6210\u70ba bin-packing \u9818\u57df\u6f14\u7b97\u6cd5\u9078\u64c7\u5668\u7684\u6df1\u5ea6\u905e\u8ff4\u7db2\u8def (DRN) \u662f\u5426\u540c\u6a23\u5bb9\u6613\u53d7\u5230\u653b\u64ca\uff0c\u9019\u4ecd\u7136\u672a\u77e5\u3002\u6211\u5011\u4f7f\u7528\u6f14\u5316\u6f14\u7b97\u6cd5 (EA) \u4f86\u627e\u51fa\u4f86\u81ea\u5169\u500b\u73fe\u6709\u5728\u7dda bin-packing \u57fa\u6e96\u7684\u5be6\u4f8b\u64fe\u52d5\uff0c\u9019\u4e9b\u64fe\u52d5\u6703\u5c0e\u81f4\u53d7\u904e\u8a13\u7df4\u7684 DRN \u932f\u8aa4\u5206\u985e\uff1a\u5c0d\u6297\u6027\u7bc4\u4f8b\u6210\u529f\u5730\u5f9e\u591a\u9054 56% \u7684\u539f\u59cb\u5be6\u4f8b\u4e2d\u751f\u6210\uff0c\u5177\u9ad4\u53d6\u6c7a\u65bc\u8cc7\u6599\u96c6\u3002\u5c0d\u65b0\u932f\u8aa4\u5206\u985e\u5be6\u4f8b\u7684\u5206\u6790\u63ed\u793a\u4e86\u4e00\u4e9b\u8a13\u7df4\u5be6\u4f8b\u7684\u300c\u8106\u5f31\u6027\u300d\uff0c\u5373\u5be6\u4f8b\uff0c\u5176\u4e2d\u5f88\u5bb9\u6613\u627e\u5230\u5c0e\u81f4\u932f\u8aa4\u5206\u985e\u7684\u5fae\u5c0f\u64fe\u52d5\u4ee5\u53ca\u5f71\u97ff\u6b64\u7684\u56e0\u7d20\u3002\u6700\u5f8c\uff0c\u8a72\u65b9\u6cd5\u7522\u751f\u5927\u91cf\u7684\u65b0\u7684\u932f\u8aa4\u5206\u985e\u5be6\u4f8b\uff0c\u4e26\u4e14\u4fe1\u5fc3\u8b8a\u5316\u5f88\u5927\uff0c\u63d0\u4f9b\u4e86\u4e00\u500b\u8c50\u5bcc\u7684\u65b0\u8a13\u7df4\u8cc7\u6599\u4f86\u6e90\uff0c\u4ee5\u5efa\u7acb\u66f4\u5f37\u5927\u7684\u6a21\u578b\u3002", "author": "Emma Hart et.al.", "authors": "Emma Hart, Quentin Renau, Kevin Sim, Mohamad Alissa", "id": "2406.16609v1", "paper_url": "http://arxiv.org/abs/2406.16609v1", "repo": "null"}}