{"2410.07167": {"publish_time": "2024-10-09", "title": "Deciphering Cross-Modal Alignment in Large Vision-Language Models with Modality Integration Rate", "paper_summary": "We present the Modality Integration Rate (MIR), an effective, robust, and\ngeneralized metric to indicate the multi-modal pre-training quality of Large\nVision Language Models (LVLMs). Large-scale pre-training plays a critical role\nin building capable LVLMs, while evaluating its training quality without the\ncostly supervised fine-tuning stage is under-explored. Loss, perplexity, and\nin-context evaluation results are commonly used pre-training metrics for Large\nLanguage Models (LLMs), while we observed that these metrics are less\nindicative when aligning a well-trained LLM with a new modality. Due to the\nlack of proper metrics, the research of LVLMs in the critical pre-training\nstage is hindered greatly, including the training data choice, efficient module\ndesign, etc. In this paper, we propose evaluating the pre-training quality from\nthe inter-modal distribution distance perspective and present MIR, the Modality\nIntegration Rate, which is 1) \\textbf{Effective} to represent the pre-training\nquality and show a positive relation with the benchmark performance after\nsupervised fine-tuning. 2) \\textbf{Robust} toward different training/evaluation\ndata. 3) \\textbf{Generalize} across training configurations and architecture\nchoices. We conduct a series of pre-training experiments to explore the\neffectiveness of MIR and observe satisfactory results that MIR is indicative\nabout training data selection, training strategy schedule, and model\narchitecture design to get better pre-training results. We hope MIR could be a\nhelpful metric for building capable LVLMs and inspire the following research\nabout modality alignment in different areas. Our code is at:\nhttps://github.com/shikiw/Modality-Integration-Rate.", "paper_summary_zh": "<paragraph>\u6211\u5011\u63d0\u51fa\u6a21\u614b\u6574\u5408\u7387 (MIR)\uff0c\u4e00\u500b\u6709\u6548\u3001\u7a69\u5065\u4e14\u901a\u7528\u7684\u6307\u6a19\uff0c\u7528\u4ee5\u8868\u793a\u5927\u578b\u8996\u89ba\u8a9e\u8a00\u6a21\u578b (LVLMs) \u7684\u591a\u6a21\u614b\u9810\u8a13\u7df4\u54c1\u8cea\u3002\u5927\u898f\u6a21\u9810\u8a13\u7df4\u5728\u5efa\u69cb\u6709\u80fd\u529b\u7684 LVLMs \u4e2d\u626e\u6f14\u95dc\u9375\u89d2\u8272\uff0c\u540c\u6642\u5728\u6c92\u6709\u6602\u8cb4\u76e3\u7763\u5fae\u8abf\u968e\u6bb5\u7684\u60c5\u6cc1\u4e0b\u8a55\u4f30\u5176\u8a13\u7df4\u54c1\u8cea\uff0c\u537b\u9bae\u5c11\u88ab\u63a2\u8a0e\u3002\u640d\u5931\u3001\u56f0\u60d1\u5ea6\u548c\u60c5\u5883\u5167\u8a55\u4f30\u7d50\u679c\u901a\u5e38\u7528\u65bc\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLMs) \u7684\u9810\u8a13\u7df4\u6307\u6a19\uff0c\u800c\u6211\u5011\u89c0\u5bdf\u5230\u5728\u5c07\u8a13\u7df4\u826f\u597d\u7684 LLM \u8207\u65b0\u6a21\u614b\u5c0d\u9f4a\u6642\uff0c\u9019\u4e9b\u6307\u6a19\u8f03\u4e0d\u5177\u6307\u793a\u6027\u3002\u7531\u65bc\u7f3a\u4e4f\u9069\u7576\u7684\u6307\u6a19\uff0cLVLMs \u5728\u95dc\u9375\u9810\u8a13\u7df4\u968e\u6bb5\u7684\u7814\u7a76\u53d7\u5230\u6975\u5927\u963b\u7919\uff0c\u5305\u62ec\u8a13\u7df4\u8cc7\u6599\u9078\u64c7\u3001\u6709\u6548\u6a21\u7d44\u8a2d\u8a08\u7b49\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u8b70\u5f9e\u6a21\u614b\u9593\u5206\u4f48\u8ddd\u96e2\u7684\u89d2\u5ea6\u8a55\u4f30\u9810\u8a13\u7df4\u54c1\u8cea\uff0c\u4e26\u63d0\u51fa MIR\uff08\u6a21\u614b\u6574\u5408\u7387\uff09\uff0c\u5176 1) \\textbf{\u6709\u6548} \u8868\u793a\u9810\u8a13\u7df4\u54c1\u8cea\uff0c\u4e26\u5728\u76e3\u7763\u5fae\u8abf\u5f8c\u986f\u793a\u8207\u57fa\u6e96\u6548\u80fd\u7684\u6b63\u5411\u95dc\u4fc2\u30022) \\textbf{\u7a69\u5065} \u5c0d\u4e0d\u540c\u7684\u8a13\u7df4/\u8a55\u4f30\u8cc7\u6599\u30023) \\textbf{\u901a\u7528} \u9069\u7528\u65bc\u5404\u7a2e\u8a13\u7df4\u7d44\u614b\u548c\u67b6\u69cb\u9078\u64c7\u3002\u6211\u5011\u9032\u884c\u4e00\u7cfb\u5217\u9810\u8a13\u7df4\u5be6\u9a57\uff0c\u4ee5\u63a2\u8a0e MIR \u7684\u6709\u6548\u6027\uff0c\u4e26\u89c0\u5bdf\u5230\u4ee4\u4eba\u6eff\u610f\u7684\u7d50\u679c\uff0c\u5373 MIR \u80fd\u6307\u793a\u8a13\u7df4\u8cc7\u6599\u9078\u64c7\u3001\u8a13\u7df4\u7b56\u7565\u6642\u7a0b\u548c\u6a21\u578b\u67b6\u69cb\u8a2d\u8a08\uff0c\u4ee5\u7372\u5f97\u66f4\u597d\u7684\u9810\u8a13\u7df4\u7d50\u679c\u3002\u6211\u5011\u5e0c\u671b MIR \u80fd\u6210\u70ba\u5efa\u69cb\u6709\u80fd\u529b\u7684 LVLMs \u7684\u6709\u7528\u6307\u6a19\uff0c\u4e26\u6fc0\u52f5\u5728\u4e0d\u540c\u9818\u57df\u4e2d\u9032\u884c\u6a21\u614b\u5c0d\u9f4a\u7684\u5f8c\u7e8c\u7814\u7a76\u3002\u6211\u5011\u7684\u7a0b\u5f0f\u78bc\u4f4d\u65bc\uff1a\nhttps://github.com/shikiw/Modality-Integration-Rate\u3002</paragraph>", "author": "Qidong Huang et.al.", "authors": "Qidong Huang, Xiaoyi Dong, Pan Zhang, Yuhang Zang, Yuhang Cao, Jiaqi Wang, Dahua Lin, Weiming Zhang, Nenghai Yu", "id": "2410.07167v1", "paper_url": "http://arxiv.org/abs/2410.07167v1", "repo": "https://github.com/shikiw/modality-integration-rate"}}