{"2411.16380": {"publish_time": "2024-11-25", "title": "Privacy-Preserving Federated Foundation Model for Generalist Ultrasound Artificial Intelligence", "paper_summary": "Ultrasound imaging is widely used in clinical diagnosis due to its\nnon-invasive nature and real-time capabilities. However, conventional\nultrasound diagnostics face several limitations, including high dependence on\nphysician expertise and suboptimal image quality, which complicates\ninterpretation and increases the likelihood of diagnostic errors. Artificial\nintelligence (AI) has emerged as a promising solution to enhance clinical\ndiagnosis, particularly in detecting abnormalities across various biomedical\nimaging modalities. Nonetheless, current AI models for ultrasound imaging face\ncritical challenges. First, these models often require large volumes of labeled\nmedical data, raising concerns over patient privacy breaches. Second, most\nexisting models are task-specific, which restricts their broader clinical\nutility. To overcome these challenges, we present UltraFedFM, an innovative\nprivacy-preserving ultrasound foundation model. UltraFedFM is collaboratively\npre-trained using federated learning across 16 distributed medical institutions\nin 9 countries, leveraging a dataset of over 1 million ultrasound images\ncovering 19 organs and 10 ultrasound modalities. This extensive and diverse\ndata, combined with a secure training framework, enables UltraFedFM to exhibit\nstrong generalization and diagnostic capabilities. It achieves an average area\nunder the receiver operating characteristic curve of 0.927 for disease\ndiagnosis and a dice similarity coefficient of 0.878 for lesion segmentation.\nNotably, UltraFedFM surpasses the diagnostic accuracy of mid-level\nultrasonographers and matches the performance of expert-level sonographers in\nthe joint diagnosis of 8 common systemic diseases. These findings indicate that\nUltraFedFM can significantly enhance clinical diagnostics while safeguarding\npatient privacy, marking an advancement in AI-driven ultrasound imaging for\nfuture clinical applications.", "paper_summary_zh": "\u8d85\u97f3\u6ce2\u5f71\u50cf\u56e0\u5176\u975e\u4fb5\u5165\u6027\u8207\u5373\u6642\u6027\u5ee3\u6cdb\u61c9\u7528\u65bc\u81e8\u5e8a\u8a3a\u65b7\u3002\u7136\u800c\uff0c\u50b3\u7d71\u8d85\u97f3\u6ce2\u8a3a\u65b7\u9762\u81e8\u6578\u9805\u9650\u5236\uff0c\u5305\u62ec\u9ad8\u5ea6\u4f9d\u8cf4\u91ab\u5e2b\u5c08\u696d\u77e5\u8b58\u548c\u6b21\u4f73\u5f71\u50cf\u54c1\u8cea\uff0c\u9019\u4f7f\u5f97\u5f71\u50cf\u5224\u8b80\u66f4\u70ba\u8907\u96dc\uff0c\u4e26\u589e\u52a0\u8a3a\u65b7\u932f\u8aa4\u7684\u53ef\u80fd\u6027\u3002\u4eba\u5de5\u667a\u6167 (AI) \u5df2\u6210\u70ba\u589e\u5f37\u81e8\u5e8a\u8a3a\u65b7\u7684\u6f5b\u5728\u89e3\u6c7a\u65b9\u6848\uff0c\u7279\u5225\u662f\u5728\u5075\u6e2c\u5404\u7a2e\u751f\u7269\u91ab\u5b78\u5f71\u50cf\u6a21\u5f0f\u4e2d\u7684\u7570\u5e38\u3002\u5118\u7ba1\u5982\u6b64\uff0c\u76ee\u524d\u7528\u65bc\u8d85\u97f3\u6ce2\u5f71\u50cf\u7684 AI \u6a21\u578b\u9762\u81e8\u56b4\u5cfb\u6311\u6230\u3002\u9996\u5148\uff0c\u9019\u4e9b\u6a21\u578b\u901a\u5e38\u9700\u8981\u5927\u91cf\u7684\u6a19\u7c64\u91ab\u5b78\u8cc7\u6599\uff0c\u9019\u5f15\u767c\u4e86\u5c0d\u75c5\u60a3\u96b1\u79c1\u906d\u4fb5\u72af\u7684\u7591\u616e\u3002\u5176\u6b21\uff0c\u73fe\u6709\u7684\u5927\u90e8\u5206\u6a21\u578b\u90fd\u662f\u91dd\u5c0d\u7279\u5b9a\u4efb\u52d9\u800c\u8a2d\u8a08\uff0c\u9019\u9650\u5236\u4e86\u5b83\u5011\u5728\u66f4\u5ee3\u6cdb\u7684\u81e8\u5e8a\u61c9\u7528\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u4e9b\u6311\u6230\uff0c\u6211\u5011\u63d0\u51fa\u4e86 UltraFedFM\uff0c\u4e00\u500b\u5275\u65b0\u7684\u96b1\u79c1\u4fdd\u8b77\u8d85\u97f3\u6ce2\u57fa\u790e\u6a21\u578b\u3002UltraFedFM \u900f\u904e 9 \u500b\u570b\u5bb6/\u5730\u5340\u7684 16 \u500b\u5206\u6563\u5f0f\u91ab\u7642\u6a5f\u69cb\u7684\u806f\u5408\u5b78\u7fd2\u9032\u884c\u5354\u4f5c\u9810\u8a13\u7df4\uff0c\u5229\u7528\u5305\u542b\u8d85\u904e 100 \u842c\u5f35\u8d85\u97f3\u6ce2\u5f71\u50cf\u7684\u8cc7\u6599\u96c6\uff0c\u6db5\u84cb 19 \u500b\u5668\u5b98\u548c 10 \u7a2e\u8d85\u97f3\u6ce2\u6a21\u5f0f\u3002\u9019\u4e9b\u5ee3\u6cdb\u4e14\u591a\u6a23\u5316\u7684\u8cc7\u6599\uff0c\u7d50\u5408\u5b89\u5168\u7684\u8a13\u7df4\u67b6\u69cb\uff0c\u4f7f UltraFedFM \u80fd\u5920\u5c55\u73fe\u5f37\u5927\u7684\u6982\u5316\u548c\u8a3a\u65b7\u80fd\u529b\u3002\u5728\u75be\u75c5\u8a3a\u65b7\u65b9\u9762\uff0c\u5176\u53d7\u8a66\u8005\u5de5\u4f5c\u7279\u5fb5\u66f2\u7dda\u4e0b\u7684\u5e73\u5747\u9762\u7a4d\u9054\u5230 0.927\uff0c\u5728\u75c5\u7076\u5206\u5272\u65b9\u9762\uff0c\u5176 Dice \u76f8\u4f3c\u4fc2\u6578\u70ba 0.878\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0cUltraFedFM \u8d85\u8d8a\u4e86\u4e2d\u968e\u8d85\u97f3\u6ce2\u6aa2\u67e5\u54e1\u7684\u8a3a\u65b7\u6e96\u78ba\u6027\uff0c\u4e26\u5728 8 \u7a2e\u5e38\u898b\u5168\u8eab\u6027\u75be\u75c5\u7684\u806f\u5408\u8a3a\u65b7\u4e2d\u9054\u5230\u5c08\u5bb6\u7d1a\u8d85\u97f3\u6ce2\u6aa2\u67e5\u54e1\u7684\u6c34\u6e96\u3002\u9019\u4e9b\u767c\u73fe\u8868\u660e\uff0cUltraFedFM \u53ef\u4ee5\u986f\u8457\u589e\u5f37\u81e8\u5e8a\u8a3a\u65b7\uff0c\u540c\u6642\u4fdd\u8b77\u75c5\u60a3\u96b1\u79c1\uff0c\u9019\u6a19\u8a8c\u8457 AI \u9a45\u52d5\u8d85\u97f3\u6ce2\u5f71\u50cf\u5728\u672a\u4f86\u81e8\u5e8a\u61c9\u7528\u4e2d\u7684\u4e00\u9805\u9032\u6b65\u3002", "author": "Yuncheng Jiang et.al.", "authors": "Yuncheng Jiang, Chun-Mei Feng, Jinke Ren, Jun Wei, Zixun Zhang, Yiwen Hu, Yunbi Liu, Rui Sun, Xuemei Tang, Juan Du, Xiang Wan, Yong Xu, Bo Du, Xin Gao, Guangyu Wang, Shaohua Zhou, Shuguang Cui, Rick Siow Mong Goh, Yong Liu, Zhen Li", "id": "2411.16380v1", "paper_url": "http://arxiv.org/abs/2411.16380v1", "repo": "null"}}