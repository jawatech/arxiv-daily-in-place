{"2501.07532": {"publish_time": "2025-01-13", "title": "Investigating Large Language Models in Inferring Personality Traits from User Conversations", "paper_summary": "Large Language Models (LLMs) are demonstrating remarkable human like\ncapabilities across diverse domains, including psychological assessment. This\nstudy evaluates whether LLMs, specifically GPT-4o and GPT-4o mini, can infer\nBig Five personality traits and generate Big Five Inventory-10 (BFI-10) item\nscores from user conversations under zero-shot prompting conditions. Our\nfindings reveal that incorporating an intermediate step--prompting for BFI-10\nitem scores before calculating traits--enhances accuracy and aligns more\nclosely with the gold standard than direct trait inference. This structured\napproach underscores the importance of leveraging psychological frameworks in\nimproving predictive precision. Additionally, a group comparison based on\ndepressive symptom presence revealed differential model performance.\nParticipants were categorized into two groups: those experiencing at least one\ndepressive symptom and those without symptoms. GPT-4o mini demonstrated\nheightened sensitivity to depression-related shifts in traits such as\nNeuroticism and Conscientiousness within the symptom-present group, whereas\nGPT-4o exhibited strengths in nuanced interpretation across groups. These\nfindings underscore the potential of LLMs to analyze real-world psychological\ndata effectively, offering a valuable foundation for interdisciplinary research\nat the intersection of artificial intelligence and psychology.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5728\u5404\u7a2e\u9818\u57df\u5c55\u73fe\u51fa\u4eba\u985e\u822c\u7684\u9a5a\u4eba\u80fd\u529b\uff0c\u5305\u62ec\u5fc3\u7406\u8a55\u4f30\u3002\u672c\u7814\u7a76\u8a55\u4f30 LLM\uff0c\u7279\u5225\u662f GPT-4o \u548c GPT-4o mini\uff0c\u662f\u5426\u80fd\u5728\u96f6\u6b21\u63d0\u793a\u689d\u4ef6\u4e0b\uff0c\u5f9e\u4f7f\u7528\u8005\u5c0d\u8a71\u4e2d\u63a8\u8ad6\u51fa\u5927\u4e94\u4eba\u683c\u7279\u8cea\u4e26\u7522\u751f\u5927\u4e94\u4eba\u683c\u554f\u5377-10 (BFI-10) \u984c\u76ee\u5206\u6578\u3002\u6211\u5011\u7684\u7814\u7a76\u7d50\u679c\u986f\u793a\uff0c\u52a0\u5165\u4e00\u500b\u4e2d\u9593\u6b65\u9a5f\uff0c\u5373\u5728\u8a08\u7b97\u7279\u8cea\u4e4b\u524d\u63d0\u793a BFI-10 \u984c\u76ee\u5206\u6578\uff0c\u53ef\u4ee5\u63d0\u9ad8\u6e96\u78ba\u5ea6\uff0c\u4e26\u4e14\u6bd4\u76f4\u63a5\u63a8\u8ad6\u7279\u8cea\u66f4\u7b26\u5408\u9ec3\u91d1\u6a19\u6e96\u3002\u9019\u7a2e\u7d50\u69cb\u5316\u7684\u505a\u6cd5\u5f37\u8abf\u4e86\u5229\u7528\u5fc3\u7406\u6846\u67b6\u4f86\u63d0\u9ad8\u9810\u6e2c\u7cbe\u5ea6\u7684\u91cd\u8981\u6027\u3002\u6b64\u5916\uff0c\u57fa\u65bc\u6182\u9b31\u75c7\u72c0\u5b58\u5728\u7684\u7fa4\u9ad4\u6bd4\u8f03\uff0c\u63ed\u793a\u4e86\u4e0d\u540c\u7684\u6a21\u578b\u8868\u73fe\u3002\u53c3\u8207\u8005\u88ab\u5206\u70ba\u5169\u7d44\uff1a\u81f3\u5c11\u7d93\u6b77\u4e00\u7a2e\u6182\u9b31\u75c7\u72c0\u7684\u4eba\u548c\u6c92\u6709\u75c7\u72c0\u7684\u4eba\u3002GPT-4o mini \u8b49\u660e\u4e86\u5c0d\u75c7\u72c0\u5b58\u5728\u7d44\u4e2d\u795e\u7d93\u8cea\u548c\u76e1\u8cac\u6027\u7b49\u7279\u8cea\u7684\u6182\u9b31\u75c7\u76f8\u95dc\u8b8a\u5316\u5177\u6709\u9ad8\u5ea6\u654f\u611f\u6027\uff0c\u800c GPT-4o \u5247\u5c55\u73fe\u4e86\u8de8\u7fa4\u9ad4\u7d30\u5fae\u89e3\u8b80\u7684\u512a\u52e2\u3002\u9019\u4e9b\u767c\u73fe\u5f37\u8abf\u4e86 LLM \u6709\u6548\u5206\u6790\u771f\u5be6\u4e16\u754c\u5fc3\u7406\u6578\u64da\u7684\u6f5b\u529b\uff0c\u70ba\u4eba\u5de5\u667a\u6167\u548c\u5fc3\u7406\u5b78\u4ea4\u6703\u8655\u7684\u8de8\u9818\u57df\u7814\u7a76\u63d0\u4f9b\u4e86\u6709\u50f9\u503c\u7684\u57fa\u790e\u3002", "author": "Jianfeng Zhu et.al.", "authors": "Jianfeng Zhu, Ruoming Jin, Karin G. Coifman", "id": "2501.07532v1", "paper_url": "http://arxiv.org/abs/2501.07532v1", "repo": "null"}}