
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-08-13**|**Fingerspelling within Sign Language Translation**|Garrett Tanzer et.al.|[2408.07065v1](http://arxiv.org/abs/2408.07065v1)|null|
|**2024-08-13**|**Diversity Empowers Intelligence: Integrating Expertise of Software Engineering Agents**|Kexun Zhang et.al.|[2408.07060v1](http://arxiv.org/abs/2408.07060v1)|null|
|**2024-08-13**|**Model Counting in the Wild**|Arijit Shaw et.al.|[2408.07059v1](http://arxiv.org/abs/2408.07059v1)|null|
|**2024-08-13**|**A Survey on Model MoErging: Recycling and Routing Among Specialized Experts for Collaborative Learning**|Prateek Yadav et.al.|[2408.07057v1](http://arxiv.org/abs/2408.07057v1)|null|
|**2024-08-13**|**LongWriter: Unleashing 10,000+ Word Generation from Long Context LLMs**|Yushi Bai et.al.|[2408.07055v1](http://arxiv.org/abs/2408.07055v1)|[link](https://github.com/thudm/longwriter)|
|**2024-08-13**|**TableGuard -- Securing Structured & Unstructured Data**|Anantha Sharma et.al.|[2408.07045v1](http://arxiv.org/abs/2408.07045v1)|null|
|**2024-08-13**|**KAN You See It? KANs and Sentinel for Effective and Explainable Crop Field Segmentation**|Daniele Rege Cambrin et.al.|[2408.07040v1](http://arxiv.org/abs/2408.07040v1)|null|
|**2024-08-13**|**PathInsight: Instruction Tuning of Multimodal Datasets and Models for Intelligence Assisted Diagnosis in Histopathology**|Xiaomin Wu et.al.|[2408.07037v1](http://arxiv.org/abs/2408.07037v1)|null|
|**2024-08-13**|**Casper: Prompt Sanitization for Protecting User Privacy in Web-Based Large Language Models**|Chun Jie Chong et.al.|[2408.07004v1](http://arxiv.org/abs/2408.07004v1)|null|
|**2024-08-13**|**Generative AI for automatic topic labelling**|Diego Kozlowski et.al.|[2408.07003v1](http://arxiv.org/abs/2408.07003v1)|null|
|**2024-08-13**|**LLMs can Schedule**|Henrik Abgaryan et.al.|[2408.06993v1](http://arxiv.org/abs/2408.06993v1)|[link](https://github.com/starjob42/datasetjsp)|
|**2024-08-13**|**Neural Speech and Audio Coding**|Minje Kim et.al.|[2408.06954v1](http://arxiv.org/abs/2408.06954v1)|null|
|**2024-08-13**|**The advantages of context specific language models: the case of the Erasmian Language Model**|João Gonçalves et.al.|[2408.06931v1](http://arxiv.org/abs/2408.06931v1)|null|
|**2024-08-13**|**Diagnosis extraction from unstructured Dutch echocardiogram reports using span- and document-level characteristic classification**|Bauke Arends et.al.|[2408.06930v1](http://arxiv.org/abs/2408.06930v1)|null|
|**2024-08-13**|**Evaluating Cultural Adaptability of a Large Language Model via Simulation of Synthetic Personas**|Louis Kwok et.al.|[2408.06929v1](http://arxiv.org/abs/2408.06929v1)|null|
|**2024-08-13**|**Heterogeneous Space Fusion and Dual-Dimension Attention: A New Paradigm for Speech Enhancement**|Tao Zheng et.al.|[2408.06911v1](http://arxiv.org/abs/2408.06911v1)|null|
|**2024-08-13**|**VNet: A GAN-based Multi-Tier Discriminator Network for Speech Synthesis Vocoders**|Yubing Cao et.al.|[2408.06906v1](http://arxiv.org/abs/2408.06906v1)|null|
|**2024-08-13**|**Re-TASK: Revisiting LLM Tasks from Capability, Skill, and Knowledge Perspectives**|Zhihu Wang et.al.|[2408.06904v1](http://arxiv.org/abs/2408.06904v1)|null|
|**2024-08-13**|**Entendre, a Social Bot Detection Tool for Niche, Fringe, and Extreme Social Media**|Pranav Venkatesh et.al.|[2408.06900v1](http://arxiv.org/abs/2408.06900v1)|null|
|**2024-08-13**|**Automatic Feature Recognition and Dimensional Attributes Extraction From CAD Models for Hybrid Additive-Subtractive Manufacturing**|Muhammad Tayyab Khan et.al.|[2408.06891v2](http://arxiv.org/abs/2408.06891v2)|null|
|**2024-08-13**|**BMFT: Achieving Fairness via Bias-based Weight Masking Fine-tuning**|Yuyang Xue et.al.|[2408.06890v1](http://arxiv.org/abs/2408.06890v1)|null|
|**2024-08-13**|**Advancing Interactive Explainable AI via Belief Change Theory**|Antonio Rago et.al.|[2408.06875v2](http://arxiv.org/abs/2408.06875v2)|null|
|**2024-08-13**|**Leveraging Language Models for Emotion and Behavior Analysis in Education**|Kaito Tanaka et.al.|[2408.06874v1](http://arxiv.org/abs/2408.06874v1)|null|
|**2024-08-13**|**LoRA$^2$ : Multi-Scale Low-Rank Approximations for Fine-Tuning Large Language Models**|Jia-Chen Zhang et.al.|[2408.06854v1](http://arxiv.org/abs/2408.06854v1)|null|
|**2024-08-13**|**BSS-CFFMA: Cross-Domain Feature Fusion and Multi-Attention Speech Enhancement Network based on Self-Supervised Embedding**|Alimjan Mattursun et.al.|[2408.06851v1](http://arxiv.org/abs/2408.06851v1)|null|
|**2024-08-13**|**Causal Agent based on Large Language Model**|Kairong Han et.al.|[2408.06849v1](http://arxiv.org/abs/2408.06849v1)|[link](https://github.com/kairong-han/causal_agent)|
|**2024-08-13**|**AI Research is not Magic, it has to be Reproducible and Responsible: Challenges in the AI field from the Perspective of its PhD Students**|Andrea Hrckova et.al.|[2408.06847v1](http://arxiv.org/abs/2408.06847v1)|null|
|**2024-08-13**|**Efficient Search for Customized Activation Functions with Gradient Descent**|Lukas Strack et.al.|[2408.06820v1](http://arxiv.org/abs/2408.06820v1)|[link](https://github.com/automl/grafs)|
|**2024-08-13**|**MAQA: Evaluating Uncertainty Quantification in LLMs Regarding Data Uncertainty**|Yongjin Yang et.al.|[2408.06816v1](http://arxiv.org/abs/2408.06816v1)|null|
|**2024-08-13**|**Unmasking the Uniqueness: A Glimpse into Age-Invariant Face Recognition of Indigenous African Faces**|Fakunle Ajewole et.al.|[2408.06806v1](http://arxiv.org/abs/2408.06806v1)|null|
|**2024-08-13**|**Deep Learning for Speaker Identification: Architectural Insights from AB-1 Corpus Analysis and Performance Evaluation**|Matthias Bartolo et.al.|[2408.06804v1](http://arxiv.org/abs/2408.06804v1)|[link](https://github.com/mbar0075/speech-technology)|
|**2024-08-13**|**Integrating Saliency Ranking and Reinforcement Learning for Enhanced Object Detection**|Matthias Bartolo et.al.|[2408.06803v1](http://arxiv.org/abs/2408.06803v1)|[link](https://github.com/mbar0075/sarlvision)|
|**2024-08-13**|**Layerwise Recurrent Router for Mixture-of-Experts**|Zihan Qiu et.al.|[2408.06793v1](http://arxiv.org/abs/2408.06793v1)|[link](https://github.com/qiuzh20/rmoe)|
|**2024-08-13**|**Unlock the Power of Frozen LLMs in Knowledge Graph Completion**|Bo Xue et.al.|[2408.06787v1](http://arxiv.org/abs/2408.06787v1)|null|
|**2024-08-13**|**Fast-and-Frugal Text-Graph Transformers are Effective Link Predictors**|Andrei C. Coman et.al.|[2408.06778v1](http://arxiv.org/abs/2408.06778v1)|null|
|**2024-08-13**|**Cross-View Geolocalization and Disaster Mapping with Street-View and VHR Satellite Imagery: A Case Study of Hurricane IAN**|Hao Li et.al.|[2408.06761v1](http://arxiv.org/abs/2408.06761v1)|null|
|**2024-08-13**|**Evaluating Research Quality with Large Language Models: An Analysis of ChatGPT's Effectiveness with Different Settings and Inputs**|Mike Thelwall et.al.|[2408.06752v1](http://arxiv.org/abs/2408.06752v1)|null|
|**2024-08-13**|**DiffLoRA: Generating Personalized Low-Rank Adaptation Weights with Diffusion**|Yujia Wu et.al.|[2408.06740v1](http://arxiv.org/abs/2408.06740v1)|null|
|**2024-08-13**|**Multilingual Models for Check-Worthy Social Media Posts Detection**|Sebastian Kula et.al.|[2408.06737v1](http://arxiv.org/abs/2408.06737v1)|null|
|**2024-08-13**|**Exploring the anatomy of articulation rate in spontaneous English speech: relationships between utterance length effects and social factors**|James Tanner et.al.|[2408.06732v1](http://arxiv.org/abs/2408.06732v1)|null|
|**2024-08-13**|**Large language models can consistently generate high-quality content for election disinformation operations**|Angus R. Williams et.al.|[2408.06731v1](http://arxiv.org/abs/2408.06731v1)|[link](https://github.com/alan-turing-institute/election-ai-safety)|
|**2024-08-13**|**Enhancing Visual Dialog State Tracking through Iterative Object-Entity Alignment in Multi-Round Conversations**|Wei Pang et.al.|[2408.06725v1](http://arxiv.org/abs/2408.06725v1)|null|
|**2024-08-13**|**Computation-friendly Graph Neural Network Design by Accumulating Knowledge on Large Language Models**|Jialiang Wang et.al.|[2408.06717v1](http://arxiv.org/abs/2408.06717v1)|null|
|**2024-08-13**|**Variational Learning of Gaussian Process Latent Variable Models through Stochastic Gradient Annealed Importance Sampling**|Jian Xu et.al.|[2408.06710v1](http://arxiv.org/abs/2408.06710v1)|null|
|**2024-08-13**|**Information Geometry and Beta Link for Optimizing Sparse Variational Student-t Processes**|Jian Xu et.al.|[2408.06699v1](http://arxiv.org/abs/2408.06699v1)|null|
|**2024-08-13**|**SlotLifter: Slot-guided Feature Lifting for Learning Object-centric Radiance Fields**|Yu Liu et.al.|[2408.06697v1](http://arxiv.org/abs/2408.06697v1)|null|
|**2024-08-13**|**DC3DO: Diffusion Classifier for 3D Objects**|Nursena Koprucu et.al.|[2408.06693v1](http://arxiv.org/abs/2408.06693v1)|null|
|**2024-08-13**|**Masked Image Modeling: A Survey**|Vlad Hondru et.al.|[2408.06687v1](http://arxiv.org/abs/2408.06687v1)|null|
|**2024-08-13**|**Pragmatic inference of scalar implicature by LLMs**|Ye-eun Cho et.al.|[2408.06673v1](http://arxiv.org/abs/2408.06673v1)|null|
|**2024-08-13**|**Leveraging Priors via Diffusion Bridge for Time Series Generation**|Jinseong Park et.al.|[2408.06672v1](http://arxiv.org/abs/2408.06672v1)|null|
|**2024-08-13**|**RW-NSGCN: A Robust Approach to Structural Attacks via Negative Sampling**|Shuqi He et.al.|[2408.06665v1](http://arxiv.org/abs/2408.06665v1)|null|
|**2024-08-13**|**Amuro & Char: Analyzing the Relationship between Pre-Training and Fine-Tuning of Large Language Models**|Kaiser Sun et.al.|[2408.06663v2](http://arxiv.org/abs/2408.06663v2)|null|
|**2024-08-13**|**Hierarchical Structured Neural Network for Retrieval**|Kaushik Rangadurai et.al.|[2408.06653v1](http://arxiv.org/abs/2408.06653v1)|null|
|**2024-08-13**|**Harnessing Earnings Reports for Stock Predictions: A QLoRA-Enhanced LLM Approach**|Haowei Ni et.al.|[2408.06634v1](http://arxiv.org/abs/2408.06634v1)|null|
|**2024-08-13**|**EditScribe: Non-Visual Image Editing with Natural Language Verification Loops**|Ruei-Che Chang et.al.|[2408.06632v1](http://arxiv.org/abs/2408.06632v1)|null|
|**2024-08-13**|**IFShip: A Large Vision-Language Model for Interpretable Fine-grained Ship Classification via Domain Knowledge-Enhanced Instruction Tuning**|Mingning Guo et.al.|[2408.06631v1](http://arxiv.org/abs/2408.06631v1)|null|
|**2024-08-13**|**WorldScribe: Towards Context-Aware Live Visual Descriptions**|Ruei-Che Chang et.al.|[2408.06627v1](http://arxiv.org/abs/2408.06627v1)|null|
|**2024-08-13**|**Towards Robust and Cost-Efficient Knowledge Unlearning for Large Language Models**|Sungmin Cha et.al.|[2408.06621v1](http://arxiv.org/abs/2408.06621v1)|null|
|**2024-08-13**|**Generalized knowledge-enhanced framework for biomedical entity and relation extraction**|Minh Nguyen et.al.|[2408.06618v1](http://arxiv.org/abs/2408.06618v1)|null|
|**2024-08-13**|**CROME: Cross-Modal Adapters for Efficient Multimodal LLM**|Sayna Ebrahimi et.al.|[2408.06610v1](http://arxiv.org/abs/2408.06610v1)|null|
|**2024-08-13**|**Simple but Effective Compound Geometric Operations for Temporal Knowledge Graph Completion**|Rui Ying et.al.|[2408.06603v1](http://arxiv.org/abs/2408.06603v1)|[link](https://github.com/nk-ruiying/tcompounde)|
|**2024-08-13**|**A Perspective on Large Language Models, Intelligent Machines, and Knowledge Acquisition**|Vladimir Cherkassky et.al.|[2408.06598v1](http://arxiv.org/abs/2408.06598v1)|null|
|**2024-08-13**|**An Event Structure-aware Generative Model for Biomedical Event Extraction**|Haohan Yuan et.al.|[2408.06583v2](http://arxiv.org/abs/2408.06583v2)|null|
|**2024-08-13**|**OpenEP: Open-Ended Future Event Prediction**|Yong Guan et.al.|[2408.06578v2](http://arxiv.org/abs/2408.06578v2)|null|
|**2024-08-13**|**CTISum: A New Benchmark Dataset For Cyber Threat Intelligence Summarization**|Wei Peng et.al.|[2408.06576v1](http://arxiv.org/abs/2408.06576v1)|null|
|**2024-08-13**|**SparkRA: A Retrieval-Augmented Knowledge Service System Based on Spark Large Language Model**|Dayong Wu et.al.|[2408.06574v1](http://arxiv.org/abs/2408.06574v1)|null|
|**2024-08-13**|**Social Debiasing for Fair Multi-modal LLMs**|Harry Cheng et.al.|[2408.06569v1](http://arxiv.org/abs/2408.06569v1)|null|
|**2024-08-13**|**AquilaMoE: Efficient Training for MoE Models with Scale-Up and Scale-Out Strategies**|Bo-Wen Zhang et.al.|[2408.06567v1](http://arxiv.org/abs/2408.06567v1)|null|
|**2024-08-13**|**HDRGS: High Dynamic Range Gaussian Splatting**|Jiahao Wu et.al.|[2408.06543v1](http://arxiv.org/abs/2408.06543v1)|[link](https://github.com/wujh2001/hdrgs)|
|**2024-08-13**|**Dynamic Exclusion of Low-Fidelity Data in Bayesian Optimization for Autonomous Beamline Alignment**|Megha R. Narayanan et.al.|[2408.06540v1](http://arxiv.org/abs/2408.06540v1)|null|
|**2024-08-13**|**Introducing the NewsPaLM MBR and QE Dataset: LLM-Generated High-Quality Parallel Data Outperforms Traditional Web-Crawled Data**|Mara Finkelstein et.al.|[2408.06537v1](http://arxiv.org/abs/2408.06537v1)|null|
|**2024-08-12**|**Chain-of-Strategy Planning with LLMs: Aligning the Generation of Psychotherapy Dialogue with Strategy in Motivational Interviewing**|Xin Sun et.al.|[2408.06527v1](http://arxiv.org/abs/2408.06527v1)|null|
|**2024-08-12**|**Hierarchical in-Context Reinforcement Learning with Hindsight Modular Reflections for Planning**|Chuanneng Sun et.al.|[2408.06520v1](http://arxiv.org/abs/2408.06520v1)|null|
|**2024-08-12**|**Does Liking Yellow Imply Driving a School Bus? Semantic Leakage in Language Models**|Hila Gonen et.al.|[2408.06518v1](http://arxiv.org/abs/2408.06518v1)|null|
|**2024-08-12**|**Learned Ranking Function: From Short-term Behavior Predictions to Long-term User Satisfaction**|Yi Wu et.al.|[2408.06512v1](http://arxiv.org/abs/2408.06512v1)|null|
|**2024-08-12**|**Fooling SHAP with Output Shuffling Attacks**|Jun Yuan et.al.|[2408.06509v1](http://arxiv.org/abs/2408.06509v1)|null|
|**2024-08-12**|**Benchmarking tree species classification from proximally-sensed laser scanning data: introducing the FOR-species20K dataset**|Stefano Puliti et.al.|[2408.06507v1](http://arxiv.org/abs/2408.06507v1)|null|
|**2024-08-12**|**Decentralized Cooperation in Heterogeneous Multi-Agent Reinforcement Learning via Graph Neural Network-Based Intrinsic Motivation**|Jahir Sadik Monon et.al.|[2408.06503v1](http://arxiv.org/abs/2408.06503v1)|[link](https://github.com/jahirsadik/cohet-implementation)|
|**2024-08-12**|**Cross-Lingual Conversational Speech Summarization with Large Language Models**|Max Nelson et.al.|[2408.06484v1](http://arxiv.org/abs/2408.06484v1)|null|
|**2024-08-12**|**TOGGL: Transcribing Overlapping Speech with Staggered Labeling**|Chak-Fai Li et.al.|[2408.06474v1](http://arxiv.org/abs/2408.06474v1)|null|
|**2024-08-12**|**Towards Autonomous Agents: Adaptive-planning, Reasoning, and Acting in Language Models**|Yen-Che Hsiao et.al.|[2408.06458v1](http://arxiv.org/abs/2408.06458v1)|[link](https://github.com/yenchehsiao/autonomousllmagentwithadaptingplanning)|
|**2024-08-12**|**Evaluating Language Models for Efficient Code Generation**|Jiawei Liu et.al.|[2408.06450v1](http://arxiv.org/abs/2408.06450v1)|null|
|**2024-08-12**|**Multi-View Neural Differential Equations for Continuous-Time Stream Data in Long-Term Traffic Forecasting**|Zibo Liu et.al.|[2408.06445v1](http://arxiv.org/abs/2408.06445v1)|null|
|**2024-08-12**|**Evaluating Language Models on Entity Disambiguation in Tables**|Federico Belotti et.al.|[2408.06423v1](http://arxiv.org/abs/2408.06423v1)|null|
|**2024-08-12**|**LOLgorithm: Integrating Semantic,Syntactic and Contextual Elements for Humor Classification**|Tanisha Khurana et.al.|[2408.06335v1](http://arxiv.org/abs/2408.06335v1)|null|
|**2024-08-12**|**FastFiD: Improve Inference Efficiency of Open Domain Question Answering via Sentence Selection**|Yufei Huang et.al.|[2408.06333v1](http://arxiv.org/abs/2408.06333v1)|[link](https://github.com/thunlp/fastfid)|
|**2024-08-12**|**Animate, or Inanimate, That is the Question for Large Language Models**|Leonardo Ranaldi et.al.|[2408.06332v1](http://arxiv.org/abs/2408.06332v1)|null|
|**2024-08-12**|**VisualAgentBench: Towards Large Multimodal Models as Visual Foundation Agents**|Xiao Liu et.al.|[2408.06327v1](http://arxiv.org/abs/2408.06327v1)|[link](https://github.com/thudm/visualagentbench)|
|**2024-08-12**|**Can We Rely on LLM Agents to Draft Long-Horizon Plans? Let's Take TravelPlanner as an Example**|Yanan Chen et.al.|[2408.06318v1](http://arxiv.org/abs/2408.06318v1)|null|
|**2024-08-12**|**Body Transformer: Leveraging Robot Embodiment for Policy Learning**|Carmelo Sferrazza et.al.|[2408.06316v1](http://arxiv.org/abs/2408.06316v1)|null|
|**2024-08-12**|**Long-Form Answers to Visual Questions from Blind and Low Vision People**|Mina Huh et.al.|[2408.06303v1](http://arxiv.org/abs/2408.06303v1)|null|
|**2024-08-12**|**The AI Scientist: Towards Fully Automated Open-Ended Scientific Discovery**|Chris Lu et.al.|[2408.06292v1](http://arxiv.org/abs/2408.06292v1)|[link](https://github.com/sakanaai/ai-scientist)|
|**2024-08-12**|**Synthetic Patient-Physician Dialogue Generation from Clinical Notes Using LLM**|Trisha Das et.al.|[2408.06285v1](http://arxiv.org/abs/2408.06285v1)|null|
|**2024-08-12**|**MovieSum: An Abstractive Summarization Dataset for Movie Screenplays**|Rohit Saxena et.al.|[2408.06281v1](http://arxiv.org/abs/2408.06281v1)|[link](https://github.com/saxenarohit/moviesum)|
|**2024-08-12**|**Review-driven Personalized Preference Reasoning with Large Language Models for Recommendation**|Jieyong Kim et.al.|[2408.06276v2](http://arxiv.org/abs/2408.06276v2)|null|
|**2024-08-12**|**FuxiTranyu: A Multilingual Large Language Model Trained with Balanced Data**|Haoran Sun et.al.|[2408.06273v2](http://arxiv.org/abs/2408.06273v2)|null|
|**2024-08-12**|**Anchored Preference Optimization and Contrastive Revisions: Addressing Underspecification in Alignment**|Karel D'Oosterlinck et.al.|[2408.06266v1](http://arxiv.org/abs/2408.06266v1)|null|
|**2024-08-12**|**Audio Enhancement for Computer Audition -- An Iterative Training Paradigm Using Sample Importance**|Manuel Milling et.al.|[2408.06264v1](http://arxiv.org/abs/2408.06264v1)|null|
|**2024-08-12**|**Open-Source Molecular Processing Pipeline for Generating Molecules**|Shreyas V et.al.|[2408.06261v1](http://arxiv.org/abs/2408.06261v1)|null|
|**2024-08-12**|**Context-aware Visual Storytelling with Visual Prefix Tuning and Contrastive Learning**|Yingjin Song et.al.|[2408.06259v1](http://arxiv.org/abs/2408.06259v1)|null|

#### Abstracts
##### **Fingerspelling within Sign Language Translation**
2408.07065v1 by Garrett Tanzer

Fingerspelling poses challenges for sign language processing due to its
high-frequency motion and use for open-vocabulary terms. While prior work has
studied fingerspelling recognition, there has been little attention to
evaluating how well sign language translation models understand fingerspelling
in the context of entire sentences -- and improving this capability. We
manually annotate instances of fingerspelling within FLEURS-ASL and use them to
evaluate the effect of two simple measures to improve fingerspelling
recognition within American Sign Language to English translation: 1) use a
model family (ByT5) with character- rather than subword-level tokenization, and
2) mix fingerspelling recognition data into the translation training mixture.
We find that 1) substantially improves understanding of fingerspelling (and
therefore translation quality overall), but the effect of 2) is mixed.

摘要：手語拼字由於其高頻率動作和用於開放式詞彙術語而對手語處理構成挑戰。雖然先前的研究已經研究了手語拼字識別，但對於評估手語翻譯模型在整個句子中理解手語拼字的能力以及提高這種能力的關注卻很少。我們手動註解了 FLEURS-ASL 中的手語拼字實例，並使用它們來評估兩個簡單措施對提高手語拼字識別的影響，從而將美國手語翻譯成英文：1) 使用具有字元而非子字元級標記化的模型系列 (ByT5)，以及 2) 將手語拼字識別資料混合到翻譯訓練混合中。我們發現 1) 大大提高了對手語拼字的理解（因此整體翻譯品質也提高了），但 2) 的效果卻好壞參半。

##### **Diversity Empowers Intelligence: Integrating Expertise of Software Engineering Agents**
2408.07060v1 by Kexun Zhang, Weiran Yao, Zuxin Liu, Yihao Feng, Zhiwei Liu, Rithesh Murthy, Tian Lan, Lei Li, Renze Lou, Jiacheng Xu, Bo Pang, Yingbo Zhou, Shelby Heinecke, Silvio Savarese, Huan Wang, Caiming Xiong

Large language model (LLM) agents have shown great potential in solving
real-world software engineering (SWE) problems. The most advanced open-source
SWE agent can resolve over 27% of real GitHub issues in SWE-Bench Lite.
However, these sophisticated agent frameworks exhibit varying strengths,
excelling in certain tasks while underperforming in others. To fully harness
the diversity of these agents, we propose DEI (Diversity Empowered
Intelligence), a framework that leverages their unique expertise. DEI functions
as a meta-module atop existing SWE agent frameworks, managing agent collectives
for enhanced problem-solving. Experimental results show that a DEI-guided
committee of agents is able to surpass the best individual agent's performance
by a large margin. For instance, a group of open-source SWE agents, with a
maximum individual resolve rate of 27.3% on SWE-Bench Lite, can achieve a 34.3%
resolve rate with DEI, making a 25% improvement and beating most closed-source
solutions. Our best-performing group excels with a 55% resolve rate, securing
the highest ranking on SWE-Bench Lite. Our findings contribute to the growing
body of research on collaborative AI systems and their potential to solve
complex software engineering challenges.

摘要：大型語言模型 (LLM) 代理在解決現實世界的軟體工程 (SWE) 問題方面展現了極大的潛力。最先進的開源 SWE 代理可以在 SWE-Bench Lite 中解決超過 27% 的實際 GitHub 問題。然而，這些複雜的代理架構表現出不同的優勢，在某些任務中表現出色，而在其他任務中表現不佳。為了充分利用這些代理的多樣性，我們提出了 DEI（Diversity Empowered Intelligence），一個利用其獨特專業知識的框架。DEI 作為一個元模組，位於現有的 SWE 代理架構之上，管理代理集合以增強問題解決能力。實驗結果表明，DEI 指導的代理委員會能夠大幅超越最佳個別代理的表現。例如，一群開源 SWE 代理，在 SWE-Bench Lite 上的最高個別解決率為 27.3%，使用 DEI 可以達到 34.3% 的解決率，改進了 25%，並且勝過大多數閉源解決方案。我們表現最好的組別以 55% 的解決率脫穎而出，在 SWE-Bench Lite 上獲得最高排名。我們的研究結果有助於擴大協作式 AI 系統的研究領域，以及它們解決複雜軟體工程挑戰的潛力。

##### **Model Counting in the Wild**
2408.07059v1 by Arijit Shaw, Kuldeep S. Meel

Model counting is a fundamental problem in automated reasoning with
applications in probabilistic inference, network reliability, neural network
verification, and more. Although model counting is computationally intractable
from a theoretical perspective due to its #P-completeness, the past decade has
seen significant progress in developing state-of-the-art model counters to
address scalability challenges.
  In this work, we conduct a rigorous assessment of the scalability of model
counters in the wild. To this end, we surveyed 11 application domains and
collected an aggregate of 2262 benchmarks from these domains. We then evaluated
six state-of-the-art model counters on these instances to assess scalability
and runtime performance.
  Our empirical evaluation demonstrates that the performance of model counters
varies significantly across different application domains, underscoring the
need for careful selection by the end user. Additionally, we investigated the
behavior of different counters with respect to two parameters suggested by the
model counting community, finding only a weak correlation. Our analysis
highlights the challenges and opportunities for portfolio-based approaches in
model counting.

摘要：模型計數是自動推理中的基本問題，在機率推論、網路可靠度、神經網路驗證等領域有其應用。儘管模型計數在理論上因其 #P-completeness 而在計算上難以處理，過去十年來，在開發最先進的模型計數器以解決可擴充性挑戰方面已取得顯著進展。
在本文中，我們對模型計數器的可擴充性進行了嚴謹的評估。為此，我們調查了 11 個應用領域，並從這些領域收集了 2262 個基準。然後，我們在這些實例上評估了六個最先進的模型計數器，以評估可擴充性和執行時間效能。
我們的實證評估表明，模型計數器的效能因不同的應用領域而異，這凸顯了最終使用者仔細選擇的必要性。此外，我們研究了不同計數器相對於模型計數社群建議的兩個參數的行為，發現只有微弱的相關性。我們的分析重點說明了模型計數中基於投資組合的方法所面臨的挑戰和機會。

##### **A Survey on Model MoErging: Recycling and Routing Among Specialized Experts for Collaborative Learning**
2408.07057v1 by Prateek Yadav, Colin Raffel, Mohammed Muqeeth, Lucas Caccia, Haokun Liu, Tianlong Chen, Mohit Bansal, Leshem Choshen, Alessandro Sordoni

The availability of performant pre-trained models has led to a proliferation
of fine-tuned expert models that are specialized to a particular domain or
task. Model MoErging methods aim to recycle expert models to create an
aggregate system with improved performance or generalization. A key component
of MoErging methods is the creation of a router that decides which expert
model(s) to use for a particular input or application. The promise,
effectiveness, and large design space of MoErging has spurred the development
of many new methods over the past few years. This rapid pace of development has
made it challenging to compare different MoErging methods, which are rarely
compared to one another and are often validated in different experimental
setups. To remedy such gaps, we present a comprehensive survey of MoErging
methods that includes a novel taxonomy for cataloging key design choices and
clarifying suitable applications for each method. Apart from surveying MoErging
research, we inventory software tools and applications that make use of
MoErging. We additionally discuss related fields of study such as model
merging, multitask learning, and mixture-of-experts models. Taken as a whole,
our survey provides a unified overview of existing MoErging methods and creates
a solid foundation for future work in this burgeoning field.

摘要：<paragraph>高效預訓練模型的可用性導致專門針對特定領域或任務進行微調的專家模型激增。模型合併方法旨在回收專家模型，以建立具有改進性能或泛化的聚合系統。合併方法的一個關鍵組成部分是建立一個路由器，用於決定針對特定輸入或應用程式使用哪個專家模型。合併的承諾、有效性和廣闊的設計空間在過去幾年中刺激了許多新方法的發展。這種快速的發展步伐使得比較不同的合併方法具有挑戰性，這些方法很少相互比較，而且通常在不同的實驗設置中得到驗證。為了彌補這些差距，我們對合併方法進行了全面的調查，其中包括一種新穎的分類法，用於編目關鍵設計選擇並釐清每種方法的合適應用。除了調查合併研究之外，我們還清點了使用合併的軟體工具和應用程式。此外，我們還討論了相關的研究領域，例如模型合併、多任務學習和專家混合模型。總的來說，我們的調查提供了現有合併方法的統一概述，並為這個新興領域的未來工作奠定了堅實的基礎。</paragraph>

##### **LongWriter: Unleashing 10,000+ Word Generation from Long Context LLMs**
2408.07055v1 by Yushi Bai, Jiajie Zhang, Xin Lv, Linzhi Zheng, Siqi Zhu, Lei Hou, Yuxiao Dong, Jie Tang, Juanzi Li

Current long context large language models (LLMs) can process inputs up to
100,000 tokens, yet struggle to generate outputs exceeding even a modest length
of 2,000 words. Through controlled experiments, we find that the model's
effective generation length is inherently bounded by the sample it has seen
during supervised fine-tuning (SFT). In other words, their output limitation is
due to the scarcity of long-output examples in existing SFT datasets. To
address this, we introduce AgentWrite, an agent-based pipeline that decomposes
ultra-long generation tasks into subtasks, enabling off-the-shelf LLMs to
generate coherent outputs exceeding 20,000 words. Leveraging AgentWrite, we
construct LongWriter-6k, a dataset containing 6,000 SFT data with output
lengths ranging from 2k to 32k words. By incorporating this dataset into model
training, we successfully scale the output length of existing models to over
10,000 words while maintaining output quality. We also develop LongBench-Write,
a comprehensive benchmark for evaluating ultra-long generation capabilities.
Our 9B parameter model, further improved through DPO, achieves state-of-the-art
performance on this benchmark, surpassing even much larger proprietary models.
In general, our work demonstrates that existing long context LLM already
possesses the potential for a larger output window--all you need is data with
extended output during model alignment to unlock this capability. Our code &
models are at: https://github.com/THUDM/LongWriter.

摘要：<paragraph>現今長語境大型語言模型 (LLM) 能處理多達 100,000 個詞彙的輸入，但仍難以產生超過 2,000 字的適度長度輸出。透過受控實驗，我們發現模型的有效產生長度本質上受到在監督微調 (SFT) 期間所見範例的限制。換句話說，他們的輸出限制是因現有 SFT 資料集中缺乏長輸出範例所致。為了解決此問題，我們引入了 AgentWrite，一個基於代理的管道，將超長產生任務分解成子任務，使現成的 LLM 能夠產生超過 20,000 字的相干輸出。利用 AgentWrite，我們構建了 LongWriter-6k，一個包含 6,000 個 SFT 資料的資料集，輸出長度從 2k 到 32k 字不等。透過將此資料集納入模型訓練中，我們成功地將現有模型的輸出長度擴展到超過 10,000 字，同時維持輸出品質。我們也開發了 LongBench-Write，一個評估超長產生能力的綜合基準。我們透過 DPO 進一步改進的 9B 參數模型，在此基準上達到了最先進的效能，甚至超越了更大規模的專有模型。總體而言，我們的研究證明現有的長語境 LLM 已具備更大輸出視窗的潛力——只要在模型比對期間提供具有延伸輸出的資料，就能解鎖此能力。我們的程式碼和模型位於：https://github.com/THUDM/LongWriter。</paragraph>

##### **TableGuard -- Securing Structured & Unstructured Data**
2408.07045v1 by Anantha Sharma, Ajinkya Deshmukh

With the increasing demand for data sharing across platforms and
organizations, ensuring the privacy and security of sensitive information has
become a critical challenge. This paper introduces "TableGuard". An innovative
approach to data obfuscation tailored for relational databases. Building on the
principles and techniques developed in prior work on context-sensitive
obfuscation, TableGuard applies these methods to ensure that API calls return
only obfuscated data, thereby safeguarding privacy when sharing data with third
parties. TableGuard leverages advanced context-sensitive obfuscation techniques
to replace sensitive data elements with contextually appropriate alternatives.
By maintaining the relational integrity and coherence of the data, our approach
mitigates the risks of cognitive dissonance and data leakage. We demonstrate
the implementation of TableGuard using a BERT based transformer model, which
identifies and obfuscates sensitive entities within relational tables. Our
evaluation shows that TableGuard effectively balances privacy protection with
data utility, minimizing information loss while ensuring that the obfuscated
data remains functionally useful for downstream applications. The results
highlight the importance of domain-specific obfuscation strategies and the role
of context length in preserving data integrity. The implications of this
research are significant for organizations that need to share data securely
with external parties. TableGuard offers a robust framework for implementing
privacy-preserving data sharing mechanisms, thereby contributing to the broader
field of data privacy and security.

摘要：隨著跨平台和組織對資料共享需求的增加，確保敏感資訊的隱私和安全性已成為一項嚴峻的挑戰。本文介紹「TableGuard」。這是一種創新的資料混淆方法，專為關聯式資料庫量身打造。TableGuard 建立在先前關於情境敏感混淆的研究原理和技術之上，將這些方法應用於確保 API 呼叫只會傳回混淆後的資料，從而保護與第三方共享資料時的隱私。TableGuard 採用先進的情境敏感混淆技術，用符合情境的替代方案取代敏感資料元素。透過維持資料的關聯性完整性和一致性，我們的做法減輕了認知失調和資料外洩的風險。我們使用基於 BERT 的Transformer模型來展示 TableGuard 的實作，此模型會識別並混淆關聯式表格中的敏感實體。我們的評估顯示，TableGuard 有效地平衡了隱私保護和資料效用，將資訊損失降至最低，同時確保混淆後的資料對下游應用程式仍具有功能性。結果突顯了特定領域混淆策略的重要性，以及情境長度在維護資料完整性中所扮演的角色。這項研究的影響對需要與外部方安全地共享資料的組織來說意義重大。TableGuard 提供了一個強大的架構來實作保護隱私的資料共享機制，從而為資料隱私和安全更廣泛的領域做出貢獻。

##### **KAN You See It? KANs and Sentinel for Effective and Explainable Crop Field Segmentation**
2408.07040v1 by Daniele Rege Cambrin, Eleonora Poeta, Eliana Pastor, Tania Cerquitelli, Elena Baralis, Paolo Garza

Segmentation of crop fields is essential for enhancing agricultural
productivity, monitoring crop health, and promoting sustainable practices. Deep
learning models adopted for this task must ensure accurate and reliable
predictions to avoid economic losses and environmental impact. The newly
proposed Kolmogorov-Arnold networks (KANs) offer promising advancements in the
performance of neural networks. This paper analyzes the integration of KAN
layers into the U-Net architecture (U-KAN) to segment crop fields using
Sentinel-2 and Sentinel-1 satellite images and provides an analysis of the
performance and explainability of these networks. Our findings indicate a 2\%
improvement in IoU compared to the traditional full-convolutional U-Net model
in fewer GFLOPs. Furthermore, gradient-based explanation techniques show that
U-KAN predictions are highly plausible and that the network has a very high
ability to focus on the boundaries of cultivated areas rather than on the areas
themselves. The per-channel relevance analysis also reveals that some channels
are irrelevant to this task.

摘要：農作物田區分割對於提升農業生產力、監控作物健康和促進永續實務至關重要。採用於此任務的深度學習模型必須確保準確且可靠的預測，以避免經濟損失和環境影響。新提出的柯爾莫哥洛夫-阿諾德網路 (KAN) 為神經網路的效能提供了有希望的進展。本文分析將 KAN 層整合到 U-Net 架構 (U-KAN) 中，以使用 Sentinel-2 和 Sentinel-1 衛星影像分割農作物田區，並提供對這些網路效能和可解釋性的分析。我們的研究結果顯示，與傳統的全卷積 U-Net 模型相比，IoU 提升了 2%，而 GFLOP 較少。此外，基於梯度的解釋技術顯示 U-KAN 預測非常合理，而且網路非常有能力專注於耕作區域的邊界，而不是區域本身。每個通道關聯性分析也顯示，有些通道與此任務無關。

##### **PathInsight: Instruction Tuning of Multimodal Datasets and Models for Intelligence Assisted Diagnosis in Histopathology**
2408.07037v1 by Xiaomin Wu, Rui Xu, Pengchen Wei, Wenkang Qin, Peixiang Huang, Ziheng Li, Lin Luo

Pathological diagnosis remains the definitive standard for identifying
tumors. The rise of multimodal large models has simplified the process of
integrating image analysis with textual descriptions. Despite this advancement,
the substantial costs associated with training and deploying these complex
multimodal models, together with a scarcity of high-quality training datasets,
create a significant divide between cutting-edge technology and its application
in the clinical setting. We had meticulously compiled a dataset of
approximately 45,000 cases, covering over 6 different tasks, including the
classification of organ tissues, generating pathology report descriptions, and
addressing pathology-related questions and answers. We have fine-tuned
multimodal large models, specifically LLaVA, Qwen-VL, InternLM, with this
dataset to enhance instruction-based performance. We conducted a qualitative
assessment of the capabilities of the base model and the fine-tuned model in
performing image captioning and classification tasks on the specific dataset.
The evaluation results demonstrate that the fine-tuned model exhibits
proficiency in addressing typical pathological questions. We hope that by
making both our models and datasets publicly available, they can be valuable to
the medical and research communities.

摘要：病理診斷仍然是識別腫瘤的明確標準。多模態大型模型的興起簡化了將影像分析與文字描述整合的過程。儘管有此進展，但訓練和部署這些複雜的多模態模型相關的龐大成本，以及缺乏高品質的訓練資料集，導致尖端技術與其在臨床環境中的應用之間產生了顯著的差距。我們已細心編制了一個包含約 45,000 個案例的資料集，涵蓋 6 項不同的任務，包括器官組織分類、產生病理報告描述，以及回答與病理相關的問題。我們使用這個資料集微調了多模態大型模型，特別是 LLaVA、Qwen-VL、InternLM，以增強基於指令的效能。我們對基礎模型和微調模型在特定資料集上執行影像標題和分類任務的能力進行了定性評估。評估結果表明，微調模型在回答典型病理問題方面表現出熟練度。我們希望透過公開我們的模型和資料集，它們能對醫療和研究社群有價值。

##### **Casper: Prompt Sanitization for Protecting User Privacy in Web-Based Large Language Models**
2408.07004v1 by Chun Jie Chong, Chenxi Hou, Zhihao Yao, Seyed Mohammadjavad Seyed Talebi

Web-based Large Language Model (LLM) services have been widely adopted and
have become an integral part of our Internet experience. Third-party plugins
enhance the functionalities of LLM by enabling access to real-world data and
services. However, the privacy consequences associated with these services and
their third-party plugins are not well understood. Sensitive prompt data are
stored, processed, and shared by cloud-based LLM providers and third-party
plugins. In this paper, we propose Casper, a prompt sanitization technique that
aims to protect user privacy by detecting and removing sensitive information
from user inputs before sending them to LLM services. Casper runs entirely on
the user's device as a browser extension and does not require any changes to
the online LLM services. At the core of Casper is a three-layered sanitization
mechanism consisting of a rule-based filter, a Machine Learning (ML)-based
named entity recognizer, and a browser-based local LLM topic identifier. We
evaluate Casper on a dataset of 4000 synthesized prompts and show that it can
effectively filter out Personal Identifiable Information (PII) and
privacy-sensitive topics with high accuracy, at 98.5% and 89.9%, respectively.

摘要：基於網路的大型語言模型 (LLM) 服務已被廣泛採用，並已成為我們網路體驗中不可或缺的一部分。第三方外掛程式透過提供存取真實世界資料和服務的功能，來增強 LLM 的功能。然而，與這些服務及其第三方外掛程式相關的隱私後果尚未被充分理解。基於雲端的 LLM 提供者和第三方外掛程式會儲存、處理和分享敏感的提示資料。在本文中，我們提出 Casper，這是一種提示消毒技術，旨在透過在將使用者輸入資料傳送至 LLM 服務之前偵測並移除敏感資訊，來保護使用者隱私。Casper 完全在使用者的裝置上以瀏覽器擴充功能執行，且不需要對線上 LLM 服務進行任何變更。Casper 的核心是一個三層式的消毒機制，包含一個基於規則的篩選器、一個基於機器學習 (ML) 的命名實體辨識器和一個基於瀏覽器的本地 LLM 主題識別器。我們在一個由 4000 個合成提示組成的資料集上評估 Casper，並顯示它可以有效地過濾出個人可識別資訊 (PII) 和隱私敏感主題，且準確度很高，分別為 98.5% 和 89.9%。

##### **Generative AI for automatic topic labelling**
2408.07003v1 by Diego Kozlowski, Carolina Pradier, Pierre Benz

Topic Modeling has become a prominent tool for the study of scientific
fields, as they allow for a large scale interpretation of research trends.
Nevertheless, the output of these models is structured as a list of keywords
which requires a manual interpretation for the labelling. This paper proposes
to assess the reliability of three LLMs, namely flan, GPT-4o, and GPT-4 mini
for topic labelling. Drawing on previous research leveraging BERTopic, we
generate topics from a dataset of all the scientific articles (n=34,797)
authored by all biology professors in Switzerland (n=465) between 2008 and
2020, as recorded in the Web of Science database. We assess the output of the
three models both quantitatively and qualitatively and find that, first, both
GPT models are capable of accurately and precisely label topics from the
models' output keywords. Second, 3-word labels are preferable to grasp the
complexity of research topics.

摘要：主題建模已成為科學領域研究的顯著工具，因為它們允許大規模解釋研究趨勢。儘管如此，這些模型的輸出被結構化為關鍵字列表，需要手動解釋才能標籤。本文提出評估三個 LLM 的可靠性，即 flan、GPT-4o 和 GPT-4 mini，用於主題標籤。利用利用 BERTopic 的先前研究，我們從所有生物學教授在瑞士（n=465）於 2008 年至 2020 年間撰寫的所有科學文章（n=34,797）的數據集中生成主題，如 Web of Science 數據庫中所記錄。我們對這三個模型的輸出進行定量和定性評估，發現首先，兩個 GPT 模型都能够準確且精確地標記模型輸出關鍵字的主題。其次，3 字標籤更適合掌握研究主題的複雜性。

##### **LLMs can Schedule**
2408.06993v1 by Henrik Abgaryan, Ararat Harutyunyan, Tristan Cazenave

The job shop scheduling problem (JSSP) remains a significant hurdle in
optimizing production processes. This challenge involves efficiently allocating
jobs to a limited number of machines while minimizing factors like total
processing time or job delays. While recent advancements in artificial
intelligence have yielded promising solutions, such as reinforcement learning
and graph neural networks, this paper explores the potential of Large Language
Models (LLMs) for JSSP. We introduce the very first supervised 120k dataset
specifically designed to train LLMs for JSSP. Surprisingly, our findings
demonstrate that LLM-based scheduling can achieve performance comparable to
other neural approaches. Furthermore, we propose a sampling method that
enhances the effectiveness of LLMs in tackling JSSP.

摘要：作業車間排程問題 (JSSP) 仍然是最佳化生產流程中的一大障礙。這項挑戰涉及將作業有效分配到數量有限的機器，同時將總處理時間或作業延遲等因素降至最低。儘管人工智慧的最新進展已產生有希望的解決方案，例如強化學習和圖形神經網路，但本文探討了大型語言模型 (LLM) 在 JSSP 中的潛力。我們引入了第一個監督式 120k 資料集，專門用於訓練 JSSP 的 LLM。令人驚訝的是，我們的研究結果表明，基於 LLM 的排程可以達到與其他神經方法相當的效能。此外，我們提出了一種抽樣方法，可增強 LLM 在處理 JSSP 中的有效性。

##### **Neural Speech and Audio Coding**
2408.06954v1 by Minje Kim, Jan Skoglund

This paper explores the integration of model-based and data-driven approaches
within the realm of neural speech and audio coding systems. It highlights the
challenges posed by the subjective evaluation processes of speech and audio
codecs and discusses the limitations of purely data-driven approaches, which
often require inefficiently large architectures to match the performance of
model-based methods. The study presents hybrid systems as a viable solution,
offering significant improvements to the performance of conventional codecs
through meticulously chosen design enhancements. Specifically, it introduces a
neural network-based signal enhancer designed to post-process existing codecs'
output, along with the autoencoder-based end-to-end models and LPCNet--hybrid
systems that combine linear predictive coding (LPC) with neural networks.
Furthermore, the paper delves into predictive models operating within custom
feature spaces (TF-Codec) or predefined transform domains (MDCTNet) and
examines the use of psychoacoustically calibrated loss functions to train
end-to-end neural audio codecs. Through these investigations, the paper
demonstrates the potential of hybrid systems to advance the field of speech and
audio coding by bridging the gap between traditional model-based approaches and
modern data-driven techniques.

摘要：這篇論文探討了基於模型和數據驅動方法在神經語言和音訊編碼系統領域的整合。它強調了語音和音訊編解碼器的主觀評估過程所帶來的挑戰，並討論了純數據驅動方法的局限性，這種方法通常需要低效率的大架構才能與基於模型的方法相匹配。研究提出混合系統作為可行的解決方案，通過精心選擇的設計改進，顯著改善傳統編解碼器的性能。具體來說，它引入了一個基於神經網路的信號增強器，旨在後處理現有編解碼器的輸出，以及基於自動編碼器的端到端模型和 LPCNet——將線性預測編碼 (LPC) 與神經網路相結合的混合系統。此外，本文深入探討了在自定義特徵空間 (TF-Codec) 或預定義變換域 (MDCTNet) 中運作的預測模型，並探討了使用經過心理聲學校準的損失函數來訓練端到端神經音訊編解碼器。通過這些研究，本文展示了混合系統在語言和音訊編碼領域的潛力，通過彌合傳統基於模型的方法和現代數據驅動技術之間的差距。

##### **The advantages of context specific language models: the case of the Erasmian Language Model**
2408.06931v1 by João Gonçalves, Nick Jelicic, Michele Murgia, Evert Stamhuis

The current trend to improve language model performance seems to be based on
scaling up with the number of parameters (e.g. the state of the art GPT4 model
has approximately 1.7 trillion parameters) or the amount of training data fed
into the model. However this comes at significant costs in terms of
computational resources and energy costs that compromise the sustainability of
AI solutions, as well as risk relating to privacy and misuse. In this paper we
present the Erasmian Language Model (ELM) a small context specific, 900 million
parameter model, pre-trained and fine-tuned by and for Erasmus University
Rotterdam. We show how the model performs adequately in a classroom context for
essay writing, and how it achieves superior performance in subjects that are
part of its context. This has implications for a wide range of institutions and
organizations, showing that context specific language models may be a viable
alternative for resource constrained, privacy sensitive use cases.

摘要：目前提升語言模型效能的趨勢似乎是基於參數數量擴充（例如，最先進的 GPT4 模型大約有 1.7 兆個參數）或輸入模型的訓練資料量。然而，這會帶來龐大的運算資源和能源成本，影響 AI 解決方案的可持續性，以及與隱私和濫用相關的風險。在本文中，我們提出伊拉斯謨語言模型 (ELM)，這是一個針對特定脈絡的小型 9 億參數模型，由鹿特丹伊拉斯謨大學預先訓練和微調。我們展示該模型如何在教室環境中適當地撰寫論文，以及如何在屬於其脈絡的科目中取得卓越的表現。這對許多機構和組織具有影響，表明特定脈絡的語言模型可能是資源受限、注重隱私的使用案例的可行替代方案。

##### **Diagnosis extraction from unstructured Dutch echocardiogram reports using span- and document-level characteristic classification**
2408.06930v1 by Bauke Arends, Melle Vessies, Dirk van Osch, Arco Teske, Pim van der Harst, René van Es, Bram van Es

Clinical machine learning research and AI driven clinical decision support
models rely on clinically accurate labels. Manually extracting these labels
with the help of clinical specialists is often time-consuming and expensive.
This study tests the feasibility of automatic span- and document-level
diagnosis extraction from unstructured Dutch echocardiogram reports.
  We included 115,692 unstructured echocardiogram reports from the UMCU a large
university hospital in the Netherlands. A randomly selected subset was manually
annotated for the occurrence and severity of eleven commonly described cardiac
characteristics. We developed and tested several automatic labelling techniques
at both span and document levels, using weighted and macro F1-score, precision,
and recall for performance evaluation. We compared the performance of span
labelling against document labelling methods, which included both direct
document classifiers and indirect document classifiers that rely on span
classification results.
  The SpanCategorizer and MedRoBERTa.nl models outperformed all other span and
document classifiers, respectively. The weighted F1-score varied between
characteristics, ranging from 0.60 to 0.93 in SpanCategorizer and 0.96 to 0.98
in MedRoBERTa.nl. Direct document classification was superior to indirect
document classification using span classifiers. SetFit achieved competitive
document classification performance using only 10\% of the training data.
Utilizing a reduced label set yielded near-perfect document classification
results.
  We recommend using our published SpanCategorizer and MedRoBERTa.nl models for
span- and document-level diagnosis extraction from Dutch echocardiography
reports. For settings with limited training data, SetFit may be a promising
alternative for document classification.

摘要：<paragraph>臨床機器學習研究和 AI 驅動的臨床決策支援模型依賴於臨床精確標籤。在臨床專家的協助下手動提取這些標籤通常既耗時又昂貴。本研究測試了從非結構化荷蘭超音波心動圖報告中自動提取跨度和文件級別診斷的可行性。我們納入了來自荷蘭一家大型大學醫院 UMCU 的 115,692 份非結構化超音波心動圖報告。手動註解了一個隨機選取的子集，以了解十一種常見描述的心臟特徵的發生和嚴重程度。我們開發並測試了跨度和文件級別的幾種自動標籤技術，使用加權和巨集 F1 分數、精確度和召回率進行效能評估。我們比較了跨度標籤相對於文件標籤方法的效能，其中包括直接文件分類器和依賴於跨度分類結果的間接文件分類器。SpanCategorizer 和 MedRoBERTa.nl 模型分別優於所有其他跨度和文件分類器。加權 F1 分數因特徵而異，在 SpanCategorizer 中介於 0.60 到 0.93，在 MedRoBERTa.nl 中介於 0.96 到 0.98。使用跨度分類器的間接文件分類不如直接文件分類。SetFit 僅使用 10% 的訓練資料就達到了有競爭力的文件分類效能。利用減少的標籤組產生了近乎完美的文件分類結果。我們建議使用我們發布的 SpanCategorizer 和 MedRoBERTa.nl 模型從荷蘭超音波心動圖報告中提取跨度和文件級別診斷。對於訓練資料有限的設定，SetFit 可能是一種有前途的文件分類替代方案。</paragraph>

##### **Evaluating Cultural Adaptability of a Large Language Model via Simulation of Synthetic Personas**
2408.06929v1 by Louis Kwok, Michal Bravansky, Lewis D. Griffin

The success of Large Language Models (LLMs) in multicultural environments
hinges on their ability to understand users' diverse cultural backgrounds. We
measure this capability by having an LLM simulate human profiles representing
various nationalities within the scope of a questionnaire-style psychological
experiment. Specifically, we employ GPT-3.5 to reproduce reactions to
persuasive news articles of 7,286 participants from 15 countries; comparing the
results with a dataset of real participants sharing the same demographic
traits. Our analysis shows that specifying a person's country of residence
improves GPT-3.5's alignment with their responses. In contrast, using native
language prompting introduces shifts that significantly reduce overall
alignment, with some languages particularly impairing performance. These
findings suggest that while direct nationality information enhances the model's
cultural adaptability, native language cues do not reliably improve simulation
fidelity and can detract from the model's effectiveness.

摘要：大型語言模型 (LLM) 在多元文化環境中的成功取決於它們理解使用者多元文化背景的能力。我們透過讓 LLM 模擬問卷式心理實驗中代表各種國籍的人類特徵來衡量這種能力。具體來說，我們使用 GPT-3.5 來重現來自 15 個國家的 7,286 名參與者對有說服力的新聞文章的反應；將結果與具有相同人口統計特徵的真實參與者資料集進行比較。我們的分析表明，指定個人的居住國家可以改善 GPT-3.5 與其反應的一致性。相反，使用母語提示會引入轉變，顯著降低整體一致性，有些語言特別會損害效能。這些發現表明，雖然直接的國籍資訊可以增強模型的文化適應性，但母語提示並不能可靠地改善模擬保真度，甚至可能降低模型的效能。

##### **Heterogeneous Space Fusion and Dual-Dimension Attention: A New Paradigm for Speech Enhancement**
2408.06911v1 by Tao Zheng, Liejun Wang, Yinfeng Yu

Self-supervised learning has demonstrated impressive performance in speech
tasks, yet there remains ample opportunity for advancement in the realm of
speech enhancement research. In addressing speech tasks, confining the
attention mechanism solely to the temporal dimension poses limitations in
effectively focusing on critical speech features. Considering the
aforementioned issues, our study introduces a novel speech enhancement
framework, HFSDA, which skillfully integrates heterogeneous spatial features
and incorporates a dual-dimension attention mechanism to significantly enhance
speech clarity and quality in noisy environments. By leveraging self-supervised
learning embeddings in tandem with Short-Time Fourier Transform (STFT)
spectrogram features, our model excels at capturing both high-level semantic
information and detailed spectral data, enabling a more thorough analysis and
refinement of speech signals. Furthermore, we employ the innovative
Omni-dimensional Dynamic Convolution (ODConv) technology within the spectrogram
input branch, enabling enhanced extraction and integration of crucial
information across multiple dimensions. Additionally, we refine the Conformer
model by enhancing its feature extraction capabilities not only in the temporal
dimension but also across the spectral domain. Extensive experiments on the
VCTK-DEMAND dataset show that HFSDA is comparable to existing state-of-the-art
models, confirming the validity of our approach.

摘要：自监督学习已在语音任务中表现出令人印象深刻的性能，然而在语音增强研究领域仍有很大的进步空间。在处理语音任务时，仅将注意力机制限制在时间维度上会限制有效关注关键语音特征。考虑到上述问题，我们的研究引入了一个新颖的语音增强框架 HFSDA，它巧妙地集成了异构空间特征，并结合了双维注意力机制，以显着提高噪声环境中的语音清晰度和质量。通过利用自监督学习嵌入与短时傅里叶变换 (STFT) 频谱图特征相结合，我们的模型擅长同时捕获高级语义信息和详细的光谱数据，从而能够更彻底地分析和优化语音信号。此外，我们在频谱图输入分支中采用了创新的全维动态卷积 (ODConv) 技术，从而能够增强跨多个维度提取和集成关键信息。此外，我们通过增强其特征提取能力来改进 Conformer 模型，不仅在时间维度上，而且在频谱域上。在 VCTK-DEMAND 数据集上的大量实验表明，HFSDA 与现有的最先进模型相当，证实了我们方法的有效性。

##### **VNet: A GAN-based Multi-Tier Discriminator Network for Speech Synthesis Vocoders**
2408.06906v1 by Yubing Cao, Yongming Li, Liejun Wang, Yinfeng Yu

Since the introduction of Generative Adversarial Networks (GANs) in speech
synthesis, remarkable achievements have been attained. In a thorough
exploration of vocoders, it has been discovered that audio waveforms can be
generated at speeds exceeding real-time while maintaining high fidelity,
achieved through the utilization of GAN-based models. Typically, the inputs to
the vocoder consist of band-limited spectral information, which inevitably
sacrifices high-frequency details. To address this, we adopt the full-band Mel
spectrogram information as input, aiming to provide the vocoder with the most
comprehensive information possible. However, previous studies have revealed
that the use of full-band spectral information as input can result in the issue
of over-smoothing, compromising the naturalness of the synthesized speech. To
tackle this challenge, we propose VNet, a GAN-based neural vocoder network that
incorporates full-band spectral information and introduces a Multi-Tier
Discriminator (MTD) comprising multiple sub-discriminators to generate
high-resolution signals. Additionally, we introduce an asymptotically
constrained method that modifies the adversarial loss of the generator and
discriminator, enhancing the stability of the training process. Through
rigorous experiments, we demonstrate that the VNet model is capable of
generating high-fidelity speech and significantly improving the performance of
the vocoder.

摘要：自生成对抗網路 (GAN) 引入語音合成以來，已取得顯著的成就。在對語音編碼器進行徹底探討後，發現可以以超過實時的速度生成音訊波形，同時透過利用基於 GAN 的模型維持高保真度。通常，語音編碼器的輸入包含頻帶限制的頻譜資訊，這不可避免地會犧牲高頻細節。為了解決這個問題，我們採用全頻段 Mel 頻譜圖資訊作為輸入，目標是為語音編碼器提供最全面的資訊。然而，先前的研究顯示，使用全頻段頻譜資訊作為輸入可能會導致過度平滑的問題，損害合成語音的自然性。為了應對這個挑戰，我們提出 VNet，一個基於 GAN 的神經語音編碼器網路，它結合了全頻段頻譜資訊，並引入了包含多個子辨別器的多層辨別器 (MTD) 來生成高解析度訊號。此外，我們引入了一個漸近約束方法，修改了生成器和辨別器的對抗損失，增強了訓練過程的穩定性。透過嚴謹的實驗，我們證明 VNet 模型能夠生成高保真度的語音，並顯著提升語音編碼器的效能。

##### **Re-TASK: Revisiting LLM Tasks from Capability, Skill, and Knowledge Perspectives**
2408.06904v1 by Zhihu Wang, Shiwan Zhao, Yu Wang, Heyuan Huang, Jiaxin Shi, Sitao Xie, Zhixing Wang, Yubo Zhang, Hongyan Li, Junchi Yan

As large language models (LLMs) continue to scale, their enhanced performance
often proves insufficient for solving domain-specific tasks. Systematically
analyzing their failures and effectively enhancing their performance remain
significant challenges. This paper introduces the Re-TASK framework, a novel
theoretical model that Revisits LLM Tasks from cApability, Skill, Knowledge
perspectives, guided by the principles of Bloom's Taxonomy and Knowledge Space
Theory. The Re-TASK framework provides a systematic methodology to deepen our
understanding, evaluation, and enhancement of LLMs for domain-specific tasks.
It explores the interplay among an LLM's capabilities, the knowledge it
processes, and the skills it applies, elucidating how these elements are
interconnected and impact task performance. Our application of the Re-TASK
framework reveals that many failures in domain-specific tasks can be attributed
to insufficient knowledge or inadequate skill adaptation. With this insight, we
propose structured strategies for enhancing LLMs through targeted knowledge
injection and skill adaptation. Specifically, we identify key capability items
associated with tasks and employ a deliberately designed prompting strategy to
enhance task performance, thereby reducing the need for extensive fine-tuning.
Alternatively, we fine-tune the LLM using capability-specific instructions,
further validating the efficacy of our framework. Experimental results confirm
the framework's effectiveness, demonstrating substantial improvements in both
the performance and applicability of LLMs.

摘要：隨著大型語言模型 (LLM) 持續擴展，它們增強的效能經常證明不足以解決特定領域的任務。系統性地分析其失敗並有效提升其效能仍然是重大的挑戰。本文介紹 Re-TASK 架構，這是一個創新的理論模型，它從能力、技能和知識的角度重新審視 LLM 任務，並以布魯姆分類法和知識空間理論的原則為指導。Re-TASK 架構提供了一個系統化的方法，以加深我們對 LLM 的理解、評估和增強，以應對特定領域的任務。它探討了 LLM 的能力、它處理的知識和它應用的技能之間的相互作用，闡明了這些元素如何相互關聯並影響任務效能。我們對 Re-TASK 架構的應用揭示，特定領域任務中的許多失敗可以歸因於知識不足或技能適應不足。有了這個見解，我們提出了通過有針對性的知識注入和技能適應來增強 LLM 的結構化策略。具體來說，我們識別與任務相關的主要能力項目，並採用經過精心設計的提示策略來增強任務效能，從而減少對廣泛微調的需求。或者，我們使用特定於能力的說明對 LLM 進行微調，進一步驗證了我們架構的功效。實驗結果證實了該架構的有效性，證明了 LLM 的效能和適用性都有顯著的提升。

##### **Entendre, a Social Bot Detection Tool for Niche, Fringe, and Extreme Social Media**
2408.06900v1 by Pranav Venkatesh, Kami Vinton, Dhiraj Murthy, Kellen Sharp, Akaash Kolluri

Social bots-automated accounts that generate and spread content on social
media-are exploiting vulnerabilities in these platforms to manipulate public
perception and disseminate disinformation. This has prompted the development of
public bot detection services; however, most of these services focus primarily
on Twitter, leaving niche platforms vulnerable. Fringe social media platforms
such as Parler, Gab, and Gettr often have minimal moderation, which facilitates
the spread of hate speech and misinformation. To address this gap, we introduce
Entendre, an open-access, scalable, and platform-agnostic bot detection
framework. Entendre can process a labeled dataset from any social platform to
produce a tailored bot detection model using a random forest classification
approach, ensuring robust social bot detection. We exploit the idea that most
social platforms share a generic template, where users can post content,
approve content, and provide a bio (common data features). By emphasizing
general data features over platform-specific ones, Entendre offers rapid
extensibility at the expense of some accuracy. To demonstrate Entendre's
effectiveness, we used it to explore the presence of bots among accounts
posting racist content on the now-defunct right-wing platform Parler. We
examined 233,000 posts from 38,379 unique users and found that 1,916 unique
users (4.99%) exhibited bot-like behavior. Visualization techniques further
revealed that these bots significantly impacted the network, amplifying
influential rhetoric and hashtags (e.g., #qanon, #trump, #antilgbt). These
preliminary findings underscore the need for tools like Entendre to monitor and
assess bot activity across diverse platforms.

摘要：<paragraph>社交機器人（自動生成內容並在社交媒體上散布內容的自動帳戶）正在利用這些平台中的漏洞來操縱公眾認知並散布錯誤訊息。這促成了公共機器人偵測服務的開發；然而，這些服務大多主要關注 Twitter，讓利基平台容易受到攻擊。邊緣社交媒體平台，例如 Parler、Gab 和 Gettr 通常只有最少的審核，這促成了仇恨言論和錯誤訊息的散布。為了解決這個差距，我們引入了 Entendre，一個開放存取、可擴充且與平台無關的機器人偵測架構。Entendre 可以處理來自任何社交平台的標籤資料集，以使用隨機森林分類方法產生量身打造的機器人偵測模型，確保強大的社交機器人偵測。我們利用了大多數社交平台共用一個通用範本的想法，使用者可以在其中發布內容、核准內容並提供個人簡介（常見資料特徵）。透過強調一般資料特徵而非特定於平台的特徵，Entendre 以犧牲一些準確度為代價提供了快速的擴充性。為了展示 Entendre 的效能，我們使用它來探索現在已不存在的右翼平台 Parler 上發布種族主義內容的帳戶中的機器人存在。我們檢視了 38,379 個唯一使用者的 233,000 則貼文，發現 1,916 個唯一使用者（4.99%）表現出類似機器人的行為。視覺化技術進一步顯示這些機器人對網路產生了重大影響，擴大了有影響力的言論和標籤（例如，#qanon、#trump、#antilgbt）。這些初步發現強調了像 Entendre 這樣的工具在不同平台上監控和評估機器人活動的必要性。</paragraph>

##### **Automatic Feature Recognition and Dimensional Attributes Extraction From CAD Models for Hybrid Additive-Subtractive Manufacturing**
2408.06891v2 by Muhammad Tayyab Khan, Wenhe Feng, Lequn Chen, Ye Han Ng, Nicholas Yew Jin Tan, Seung Ki Moon

The integration of Computer-Aided Design (CAD), Computer-Aided Process
Planning (CAPP), and Computer-Aided Manufacturing (CAM) plays a crucial role in
modern manufacturing, facilitating seamless transitions from digital designs to
physical products. However, a significant challenge within this integration is
the Automatic Feature Recognition (AFR) of CAD models, especially in the
context of hybrid manufacturing that combines subtractive and additive
manufacturing processes. Traditional AFR methods, focused mainly on the
identification of subtractive (machined) features including holes, fillets,
chamfers, pockets, and slots, fail to recognize features pertinent to additive
manufacturing. Furthermore, the traditional methods fall short in accurately
extracting geometric dimensions and orientations, which are also key factors
for effective manufacturing process planning. This paper presents a novel
approach for creating a synthetic CAD dataset that encompasses features
relevant to both additive and subtractive machining through Python Open
Cascade. The Hierarchical Graph Convolutional Neural Network (HGCNN) model is
implemented to accurately identify the composite additive-subtractive features
within the synthetic CAD dataset. The key novelty and contribution of the
proposed methodology lie in its ability to recognize a wide range of
manufacturing features, and precisely extracting their dimensions,
orientations, and stock sizes. The proposed model demonstrates remarkable
feature recognition accuracy exceeding 97% and a dimension extraction accuracy
of 100% for identified features. Therefore, the proposed methodology enhances
the integration of CAD, CAPP, and CAM within hybrid manufacturing by providing
precise feature recognition and dimension extraction. It facilitates improved
manufacturing process planning, by enabling more informed decision-making.

摘要：<paragraph>電腦輔助設計 (CAD)、電腦輔助製程規劃 (CAPP) 和電腦輔助製造 (CAM) 的整合在現代製造業中扮演著至關重要的角色，促使數位設計能順利轉化為實體產品。然而，此整合中一個重大的挑戰是 CAD 模型的自動特徵辨識 (AFR)，特別是在結合減材和增材製造製程的混合製造脈絡下。傳統的 AFR 方法主要著重於辨識減材（機械加工）特徵，包括孔、圓角、倒角、凹槽和槽，無法辨識與增材製造相關的特徵。此外，傳統方法無法準確擷取幾何尺寸和方向，而這也是有效製造製程規劃的關鍵因素。本文提出一個創新的方法，透過 Python Open Cascade 建立一個包含與增材和減材加工相關特徵的合成 CAD 資料集。實作階層式圖形卷積神經網路 (HGCNN) 模型，以準確辨識合成 CAD 資料集中的複合增材減材特徵。所提出的方法論的主要創新和貢獻在於它能辨識廣泛的製造特徵，並精確擷取其尺寸、方向和坯料大小。所提出的模型展現出卓越的特徵辨識準確度，超過 97%，以及對已辨識特徵的尺寸擷取準確度為 100%。因此，所提出的方法論透過提供精確的特徵辨識和尺寸擷取，增強了混合製造中 CAD、CAPP 和 CAM 的整合。它促成改善製造製程規劃，讓決策制定更明智。</paragraph>

##### **BMFT: Achieving Fairness via Bias-based Weight Masking Fine-tuning**
2408.06890v1 by Yuyang Xue, Junyu Yan, Raman Dutt, Fasih Haider, Jingshuai Liu, Steven McDonagh, Sotirios A. Tsaftaris

Developing models with robust group fairness properties is paramount,
particularly in ethically sensitive domains such as medical diagnosis. Recent
approaches to achieving fairness in machine learning require a substantial
amount of training data and depend on model retraining, which may not be
practical in real-world scenarios. To mitigate these challenges, we propose
Bias-based Weight Masking Fine-Tuning (BMFT), a novel post-processing method
that enhances the fairness of a trained model in significantly fewer epochs
without requiring access to the original training data. BMFT produces a mask
over model parameters, which efficiently identifies the weights contributing
the most towards biased predictions. Furthermore, we propose a two-step
debiasing strategy, wherein the feature extractor undergoes initial fine-tuning
on the identified bias-influenced weights, succeeded by a fine-tuning phase on
a reinitialised classification layer to uphold discriminative performance.
Extensive experiments across four dermatological datasets and two sensitive
attributes demonstrate that BMFT outperforms existing state-of-the-art (SOTA)
techniques in both diagnostic accuracy and fairness metrics. Our findings
underscore the efficacy and robustness of BMFT in advancing fairness across
various out-of-distribution (OOD) settings. Our code is available at:
https://github.com/vios-s/BMFT

摘要：<paragraph>開發具有穩健群組公平性特性的模型至關重要，特別是在醫療診斷等道德敏感領域。最近實現機器學習公平性的方法需要大量的訓練資料，並且依賴於模型再訓練，這在現實情況中可能不切實際。為了緩解這些挑戰，我們提出了基於偏差的權重遮罩微調 (BMFT)，這是一種新穎的後處理方法，可以在顯著更少的輪次中增強訓練模型的公平性，而無需訪問原始訓練資料。BMFT 在模型參數上產生一個遮罩，有效地識別出對偏差預測貢獻最大的權重。此外，我們提出了一種兩步去偏策略，其中特徵提取器對識別出的偏差影響權重進行初始微調，然後在重新初始化的分類層上進行微調階段以維持區分效能。在四個皮膚科資料集和兩個敏感屬性的廣泛實驗中證明，BMFT 在診斷準確性和公平性指標上都優於現有的最先進 (SOTA) 技術。我們的研究結果強調了 BMFT 在推進各種非分佈 (OOD) 設定中的公平性方面的效力和穩健性。我們的程式碼可在以下位置獲得：
https://github.com/vios-s/BMFT</paragraph>

##### **Advancing Interactive Explainable AI via Belief Change Theory**
2408.06875v2 by Antonio Rago, Maria Vanina Martinez

As AI models become ever more complex and intertwined in humans' daily lives,
greater levels of interactivity of explainable AI (XAI) methods are needed. In
this paper, we propose the use of belief change theory as a formal foundation
for operators that model the incorporation of new information, i.e. user
feedback in interactive XAI, to logical representations of data-driven
classifiers. We argue that this type of formalisation provides a framework and
a methodology to develop interactive explanations in a principled manner,
providing warranted behaviour and favouring transparency and accountability of
such interactions. Concretely, we first define a novel, logic-based formalism
to represent explanatory information shared between humans and machines. We
then consider real world scenarios for interactive XAI, with different
prioritisations of new and existing knowledge, where our formalism may be
instantiated. Finally, we analyse a core set of belief change postulates,
discussing their suitability for our real world settings and pointing to
particular challenges that may require the relaxation or reinterpretation of
some of the theoretical assumptions underlying existing operators.

摘要：隨著人工智慧模型在人類的日常生活變得更加複雜且相互交織，
需要更高層次的互動式可解釋人工智慧 (XAI) 方法。在
本文中，我們建議使用信念變更理論作為運算符的形式基礎，
這些運算符模擬了新資訊的整合，即互動式 XAI 中的使用者
回饋，以資料驅動分類器的邏輯表示。我們認為這種類型的形式化
提供了一個架構和方法，可以以有原則的方式開發互動式解釋，
提供合理的行為並支持此類互動的透明度和問責制。具體來說，
我們首先定義一種新穎的、基於邏輯的形式主義，以表示人類和機器之間共享的解釋資訊。我們
然後考慮互動式 XAI 的真實世界場景，其中對新知識和現有知識有不同的優先順序，我們的形式主義可以在其中實例化。最後，我們分析了一組核心的信念變更公設，
討論它們是否適合我們的真實世界設定，並指出可能需要放寬或重新詮釋某些運算符背後理論假設的特定挑戰。

##### **Leveraging Language Models for Emotion and Behavior Analysis in Education**
2408.06874v1 by Kaito Tanaka, Benjamin Tan, Brian Wong

The analysis of students' emotions and behaviors is crucial for enhancing
learning outcomes and personalizing educational experiences. Traditional
methods often rely on intrusive visual and physiological data collection,
posing privacy concerns and scalability issues. This paper proposes a novel
method leveraging large language models (LLMs) and prompt engineering to
analyze textual data from students. Our approach utilizes tailored prompts to
guide LLMs in detecting emotional and engagement states, providing a
non-intrusive and scalable solution. We conducted experiments using Qwen,
ChatGPT, Claude2, and GPT-4, comparing our method against baseline models and
chain-of-thought (CoT) prompting. Results demonstrate that our method
significantly outperforms the baselines in both accuracy and contextual
understanding. This study highlights the potential of LLMs combined with prompt
engineering to offer practical and effective tools for educational emotion and
behavior analysis.

摘要：分析學生的情緒與行為對於增強學習成效和個人化教育體驗至關重要。傳統方法通常依賴於侵入性的視覺和生理數據收集，這會引發隱私問題和可擴充性問題。本文提出了一種新方法，利用大型語言模型 (LLM) 和提示工程來分析學生的文字數據。我們的做法利用量身打造的提示來引導 LLM 偵測情緒和參與狀態，提供非侵入性和可擴充性的解決方案。我們使用 Qwen、ChatGPT、Claude2 和 GPT-4 進行了實驗，將我們的模型與基準模型和思考鏈 (CoT) 提示進行比較。結果表明，我們的模型在準確性和背景理解方面都明顯優於基準模型。這項研究強調了 LLM 結合提示工程在提供實用且有效的教育情緒和行為分析工具方面的潛力。

##### **LoRA$^2$ : Multi-Scale Low-Rank Approximations for Fine-Tuning Large Language Models**
2408.06854v1 by Jia-Chen Zhang, Yu-Jie Xiong, He-Xi Qiu, Dong-Hai Zhu, Chun-Ming Xia

Fine-tuning large language models (LLMs) with high parameter efficiency for
downstream tasks has become a new paradigm. Low-Rank Adaptation (LoRA)
significantly reduces the number of trainable parameters for fine-tuning.
Although it has demonstrated commendable performance, updating parameters
within a single scale may not be the optimal choice for complex downstream
tasks.In this paper, we extend the LoRA to multiple scales, dubbed as LoRA$^2$.
We first combine orthogonal projection theory to train a set of LoRAs in two
mutually orthogonal planes. Then, we improve the importance score algorithm,
which reduce parameter sensitivity score calculations by approximately 98.5\%.
By pruning singular values with lower importance scores, thereby enhancing
adaptability to various downstream tasks. Extensive experiments are conducted
on two widely used pre-trained models to validate the effectiveness of
LoRA$^2$. Results show that it significantly reduces the number of trainable
parameters to just 0.72\% compared to full fine-tuning, while still delivering
highly impressive performance. Even when the parameters are further reduced to
0.17M, it still achieves comparable results to the baseline with 8 times more
parameters. Our code is available here:
https://anonymous.4open.science/r/LoRA-2-5B4C

摘要：微调具有高参数效率的大型语言模型 (LLM) 以用于下游任务已成为一种新范例。低秩自适应 (LoRA) 大幅减少了微调的可训练参数数量。虽然它已展示出值得称道的性能，但在单个尺度内更新参数可能不是复杂下游任务的最佳选择。在本文中，我们将 LoRA 扩展到多个尺度，称为 LoRA^2。我们首先结合正交投影理论，在两个相互正交的平面上训练一组 LoRA。然后，我们改进了重要性评分算法，该算法将参数敏感性评分计算减少了大约 98.5%。通过修剪具有较低重要性评分的奇异值，从而增强了对各种下游任务的适应性。在两个广泛使用的预训练模型上进行了广泛的实验，以验证 LoRA^2 的有效性。结果表明，与完全微调相比，它将可训练参数的数量显着减少到仅 0.72%，同时仍然提供令人印象深刻的性能。即使将参数进一步减少到 0.17M，它仍然可以实现与具有多 8 倍参数的基线相当的结果。我们的代码可在此处获得：https://anonymous.4open.science/r/LoRA-2-5B4C

##### **BSS-CFFMA: Cross-Domain Feature Fusion and Multi-Attention Speech Enhancement Network based on Self-Supervised Embedding**
2408.06851v1 by Alimjan Mattursun, Liejun Wang, Yinfeng Yu

Speech self-supervised learning (SSL) represents has achieved
state-of-the-art (SOTA) performance in multiple downstream tasks. However, its
application in speech enhancement (SE) tasks remains immature, offering
opportunities for improvement. In this study, we introduce a novel cross-domain
feature fusion and multi-attention speech enhancement network, termed
BSS-CFFMA, which leverages self-supervised embeddings. BSS-CFFMA comprises a
multi-scale cross-domain feature fusion (MSCFF) block and a residual hybrid
multi-attention (RHMA) block. The MSCFF block effectively integrates
cross-domain features, facilitating the extraction of rich acoustic
information. The RHMA block, serving as the primary enhancement module,
utilizes three distinct attention modules to capture diverse attention
representations and estimate high-quality speech signals.
  We evaluate the performance of the BSS-CFFMA model through comparative and
ablation studies on the VoiceBank-DEMAND dataset, achieving SOTA results.
Furthermore, we select three types of data from the WHAMR! dataset, a
collection specifically designed for speech enhancement tasks, to assess the
capabilities of BSS-CFFMA in tasks such as denoising only, dereverberation
only, and simultaneous denoising and dereverberation. This study marks the
first attempt to explore the effectiveness of self-supervised embedding-based
speech enhancement methods in complex tasks encompassing dereverberation and
simultaneous denoising and dereverberation. The demo implementation of
BSS-CFFMA is available online\footnote[2]{https://github.com/AlimMat/BSS-CFFMA.
\label{s1}}.

摘要：<paragraph>語音自監督學習 (SSL) 代表已在多項下游任務中達成最先進 (SOTA) 的效能。然而，其在語音增強 (SE) 任務中的應用仍不成熟，提供了改進的機會。在此研究中，我們引入了一個新穎的跨域特徵融合和多注意力語音增強網路，稱為 BSS-CFFMA，它利用自監督嵌入。BSS-CFFMA 包含一個多尺度跨域特徵融合 (MSCFF) 區塊和一個殘差混合多注意力 (RHMA) 區塊。MSCFF 區塊有效地整合跨域特徵，促進了豐富的聲學資訊提取。RHMA 區塊作為主要的增強模組，利用三個不同的注意力模組來擷取多樣化的注意力表示並估計高品質的語音訊號。
我們透過在 VoiceBank-DEMAND 資料集上進行比較和消融研究來評估 BSS-CFFMA 模型的效能，並達成 SOTA 的結果。此外，我們從 WHAMR! 資料集中選取三種類型的資料，這是專門為語音增強任務設計的集合，用來評估 BSS-CFFMA 在僅去噪、僅去混響和同時去噪與去混響等任務中的能力。本研究標誌著首次嘗試探索基於自監督嵌入的語音增強方法在包含去混響和同時去噪與去混響的複雜任務中的有效性。BSS-CFFMA 的示範實作可在線上取得\footnote[2]{https://github.com/AlimMat/BSS-CFFMA.
\label{s1}}。</paragraph>

##### **Causal Agent based on Large Language Model**
2408.06849v1 by Kairong Han, Kun Kuang, Ziyu Zhao, Junjian Ye, Fei Wu

Large language models (LLMs) have achieved significant success across various
domains. However, the inherent complexity of causal problems and causal theory
poses challenges in accurately describing them in natural language, making it
difficult for LLMs to comprehend and use them effectively. Causal methods are
not easily conveyed through natural language, which hinders LLMs' ability to
apply them accurately. Additionally, causal datasets are typically tabular,
while LLMs excel in handling natural language data, creating a structural
mismatch that impedes effective reasoning with tabular data. This lack of
causal reasoning capability limits the development of LLMs. To address these
challenges, we have equipped the LLM with causal tools within an agent
framework, named the Causal Agent, enabling it to tackle causal problems. The
causal agent comprises tools, memory, and reasoning modules. In the tools
module, the causal agent applies causal methods to align tabular data with
natural language. In the reasoning module, the causal agent employs the ReAct
framework to perform reasoning through multiple iterations with the tools. In
the memory module, the causal agent maintains a dictionary instance where the
keys are unique names and the values are causal graphs. To verify the causal
ability of the causal agent, we established a benchmark consisting of four
levels of causal problems: variable level, edge level, causal graph level, and
causal effect level. We generated a test dataset of 1.3K using ChatGPT-3.5 for
these four levels of issues and tested the causal agent on the datasets. Our
methodology demonstrates remarkable efficacy on the four-level causal problems,
with accuracy rates all above 80%. For further insights and implementation
details, our code is accessible via the GitHub repository
https://github.com/Kairong-Han/Causal_Agent.

摘要：大型語言模型 (LLM) 已在各個領域取得重大成功。然而，因果問題和因果理論的內在複雜性，在自然語言中準確描述它們時構成挑戰，這使得 LLM 難以理解並有效使用它們。因果方法不易透過自然語言傳達，這阻礙了 LLM 準確應用它們的能力。此外，因果資料集通常是表格化的，而 LLM 擅長處理自然語言資料，這造成了結構上的不匹配，阻礙了對表格資料進行有效的推理。這種缺乏因果推理能力限制了 LLM 的發展。為了應對這些挑戰，我們在一個代理框架中為 LLM 配備了因果工具，稱為因果代理，使它能夠解決因果問題。因果代理包含工具、記憶體和推理模組。在工具模組中，因果代理應用因果方法將表格資料與自然語言對齊。在推理模組中，因果代理採用 ReAct 框架，透過與工具進行多次反覆運算來執行推理。在記憶體模組中，因果代理維護一個字典實例，其中鍵是唯一名稱，而值是因果圖。為了驗證因果代理的因果能力，我們建立了一個基準，其中包含四個層級的因果問題：變數層級、邊層級、因果圖層級和因果效應層級。我們使用 ChatGPT-3.5 為這四個層級的問題產生了 1.3K 的測試資料集，並在資料集上測試了因果代理。我們的這套方法在四個層級的因果問題上展現了顯著的功效，準確率都高於 80%。有關進一步的見解和實作細節，我們的程式碼可透過 GitHub 儲存庫 https://github.com/Kairong-Han/Causal_Agent 取得。

##### **AI Research is not Magic, it has to be Reproducible and Responsible: Challenges in the AI field from the Perspective of its PhD Students**
2408.06847v1 by Andrea Hrckova, Jennifer Renoux, Rafael Tolosana Calasanz, Daniela Chuda, Martin Tamajka, Jakub Simko

With the goal of uncovering the challenges faced by European AI students
during their research endeavors, we surveyed 28 AI doctoral candidates from 13
European countries. The outcomes underscore challenges in three key areas: (1)
the findability and quality of AI resources such as datasets, models, and
experiments; (2) the difficulties in replicating the experiments in AI papers;
(3) and the lack of trustworthiness and interdisciplinarity. From our findings,
it appears that although early stage AI researchers generally tend to share
their AI resources, they lack motivation or knowledge to engage more in dataset
and code preparation and curation, and ethical assessments, and are not used to
cooperate with well-versed experts in application domains. Furthermore, we
examine existing practices in data governance and reproducibility both in
computer science and in artificial intelligence. For instance, only a minority
of venues actively promote reproducibility initiatives such as reproducibility
evaluations.
  Critically, there is need for immediate adoption of responsible and
reproducible AI research practices, crucial for society at large, and essential
for the AI research community in particular. This paper proposes a combination
of social and technical recommendations to overcome the identified challenges.
Socially, we propose the general adoption of reproducibility initiatives in AI
conferences and journals, as well as improved interdisciplinary collaboration,
especially in data governance practices. On the technical front, we call for
enhanced tools to better support versioning control of datasets and code, and a
computing infrastructure that facilitates the sharing and discovery of AI
resources, as well as the sharing, execution, and verification of experiments.

摘要：<paragraph>為了了解歐洲 AI 學生在研究過程中面臨的挑戰，我們調查了來自 13 個歐洲國家的 28 位 AI 博士候選人。結果強調了三個關鍵領域的挑戰：(1) 資料集、模型和實驗等 AI 資源的可查找性和品質；(2) 複製 AI 論文中實驗的困難度；(3) 缺乏可信度和跨領域性。從我們的發現看來，儘管早期階段的 AI 研究人員通常傾向於分享他們的 AI 資源，但他們缺乏參與資料集和程式碼準備及策展、倫理評估的動機或知識，而且不習慣與應用領域的專家合作。此外，我們探討了電腦科學和人工智慧中現有的資料治理和可複製性實務。例如，只有少數場地積極推廣可複製性計畫，例如可複製性評估。
嚴格來說，需要立即採用負責任且可複製的 AI 研究實務，這對社會整體而言至關重要，對 AI 研究社群尤其重要。本文提出結合社會和技術建議，以克服已確定的挑戰。在社會方面，我們提議在 AI 會議和期刊中普遍採用可複製性計畫，以及改善跨領域合作，特別是在資料治理實務中。在技術方面，我們呼籲加強工具，以更好地支援資料集和程式的版本控制，以及一個運算基礎架構，以促進 AI 資源的分享和發現，以及實驗的分享、執行和驗證。</paragraph>

##### **Efficient Search for Customized Activation Functions with Gradient Descent**
2408.06820v1 by Lukas Strack, Mahmoud Safari, Frank Hutter

Different activation functions work best for different deep learning models.
To exploit this, we leverage recent advancements in gradient-based search
techniques for neural architectures to efficiently identify high-performing
activation functions for a given application. We propose a fine-grained search
cell that combines basic mathematical operations to model activation functions,
allowing for the exploration of novel activations. Our approach enables the
identification of specialized activations, leading to improved performance in
every model we tried, from image classification to language models. Moreover,
the identified activations exhibit strong transferability to larger models of
the same type, as well as new datasets. Importantly, our automated process for
creating customized activation functions is orders of magnitude more efficient
than previous approaches. It can easily be applied on top of arbitrary deep
learning pipelines and thus offers a promising practical avenue for enhancing
deep learning architectures.

摘要：不同的激活函數最適合不同的深度學習模型。
為了利用這一點，我們利用神經架構的梯度式搜尋技術的最新進展，以有效識別給定應用程式的效能最佳的激活函數。我們提出一個細緻的搜尋單元，結合基本的數學運算來建模激活函數，允許探索新穎的激活。我們的做法可以識別專門的激活，從影像分類到語言模型，提升我們嘗試的每個模型的效能。此外，識別出的激活表現出對同類型較大型模型以及新資料集的強大可移植性。重要的是，我們用於建立自訂激活函數的自動化流程，其效率比先前的做法高出好幾個數量級。它可以輕易套用在任意的深度學習管線上，因此提供了一個有前途的實務途徑來增強深度學習架構。

##### **MAQA: Evaluating Uncertainty Quantification in LLMs Regarding Data Uncertainty**
2408.06816v1 by Yongjin Yang, Haneul Yoo, Hwaran Lee

Although large language models (LLMs) are capable of performing various
tasks, they still suffer from producing plausible but incorrect responses. To
improve the reliability of LLMs, recent research has focused on uncertainty
quantification to predict whether a response is correct or not. However, most
uncertainty quantification methods have been evaluated on questions requiring a
single clear answer, ignoring the existence of data uncertainty that arises
from irreducible randomness. Instead, these methods only consider model
uncertainty, which arises from a lack of knowledge. In this paper, we
investigate previous uncertainty quantification methods under the presence of
data uncertainty. Our contributions are two-fold: 1) proposing a new
Multi-Answer Question Answering dataset, MAQA, consisting of world knowledge,
mathematical reasoning, and commonsense reasoning tasks to evaluate uncertainty
quantification regarding data uncertainty, and 2) assessing 5 uncertainty
quantification methods of diverse white- and black-box LLMs. Our findings show
that entropy and consistency-based methods estimate the model uncertainty well
even under data uncertainty, while other methods for white- and black-box LLMs
struggle depending on the tasks. Additionally, methods designed for white-box
LLMs suffer from overconfidence in reasoning tasks compared to simple knowledge
queries. We believe our observations will pave the way for future work on
uncertainty quantification in realistic setting.

摘要：儘管大型語言模型 (LLM) 能執行各種任務，但它們仍會產生看似合理但錯誤的回應。為了提升 LLM 的可靠性，最近的研究著重於不確定性量化，以預測回應是否正確。然而，大多數不確定性量化方法都是針對需要單一明確答案的問題進行評估，而忽略了由不可還原的隨機性所產生的資料不確定性。相反地，這些方法只考量模型不確定性，而這源自於知識的缺乏。在本文中，我們探討了在資料不確定性存在的情況下，先前的各種不確定性量化方法。我們的貢獻有兩個面向：1) 提出一個新的多答案問答資料集 MAQA，其中包含世界知識、數學推理和常識推理任務，以評估關於資料不確定性的不確定性量化，以及 2) 評估 5 種不同白盒和黑盒 LLM 的不確定性量化方法。我們的研究結果顯示，即使在資料不確定性的情況下，熵和基於一致性的方法也能很好地估計模型不確定性，而其他針對白盒和黑盒 LLM 的方法則會根據任務而有所不同。此外，與簡單的知識查詢相比，專為白盒 LLM 設計的方法在推理任務中會過於自信。我們相信我們的觀察將為在現實環境中進行不確定性量化奠定基礎。

##### **Unmasking the Uniqueness: A Glimpse into Age-Invariant Face Recognition of Indigenous African Faces**
2408.06806v1 by Fakunle Ajewole, Joseph Damilola Akinyemi, Khadijat Tope Ladoja, Olufade Falade Williams Onifade

The task of recognizing the age-separated faces of an individual,
Age-Invariant Face Recognition (AIFR), has received considerable research
efforts in Europe, America, and Asia, compared to Africa. Thus, AIFR research
efforts have often under-represented/misrepresented the African ethnicity with
non-indigenous Africans. This work developed an AIFR system for indigenous
African faces to reduce the misrepresentation of African ethnicity in facial
image analysis research. We adopted a pre-trained deep learning model (VGGFace)
for AIFR on a dataset of 5,000 indigenous African faces (FAGE\_v2) collected
for this study. FAGE\_v2 was curated via Internet image searches of 500
individuals evenly distributed across 10 African countries. VGGFace was trained
on FAGE\_v2 to obtain the best accuracy of 81.80\%. We also performed
experiments on an African-American subset of the CACD dataset and obtained the
best accuracy of 91.5\%. The results show a significant difference in the
recognition accuracies of indigenous versus non-indigenous Africans.

摘要：與年齡相關的臉部辨識（AIFR），也就是辨識個人不同年齡時期的臉部，在歐洲、美國和亞洲已獲得相當的研究成果，相較於非洲。因此，AIFR 研究成果經常低估或誤判非裔族群，且由非本地的非洲人進行。本研究開發了一套針對非洲原住民臉部的 AIFR 系統，以減少在臉部影像分析研究中對非洲族群的誤判。我們採用預先訓練好的深度學習模型（VGGFace），以 5,000 張本研究收集的非洲原住民臉部資料集（FAGE\_v2）進行 AIFR。FAGE\_v2 是透過網路搜尋 500 位來自 10 個非洲國家的個人影像，並平均分配而整理出來的。VGGFace 在 FAGE\_v2 上進行訓練，以獲得 81.80% 的最佳準確度。我們也針對 CACD 資料集的非裔美國人子集進行實驗，並獲得 91.5% 的最佳準確度。結果顯示，非洲原住民和非原住民的辨識準確度有顯著差異。

##### **Deep Learning for Speaker Identification: Architectural Insights from AB-1 Corpus Analysis and Performance Evaluation**
2408.06804v1 by Matthias Bartolo

In the fields of security systems, forensic investigations, and personalized
services, the importance of speech as a fundamental human input outweighs
text-based interactions. This research delves deeply into the complex field of
Speaker Identification (SID), examining its essential components and
emphasising Mel Spectrogram and Mel Frequency Cepstral Coefficients (MFCC) for
feature extraction. Moreover, this study evaluates six slightly distinct model
architectures using extensive analysis to evaluate their performance, with
hyperparameter tuning applied to the best-performing model. This work performs
a linguistic analysis to verify accent and gender accuracy, in addition to bias
evaluation within the AB-1 Corpus dataset.

摘要：在安全系統、法醫調查和個人化服務的領域中，語音作為人類基本輸入的重要性大於基於文字的互動。本研究深入探討了說話人識別 (SID) 的複雜領域，探討其基本組成部分，並強調 Mel 頻譜圖和 Mel 頻率倒頻譜係數 (MFCC) 以進行特徵提取。此外，本研究使用廣泛的分析評估了六種略微不同的模型架構，以評估其效能，並將超參數調整應用於效能最佳的模型。這項工作執行語言分析以驗證口音和性別的準確性，此外還評估了 AB-1 語料庫資料集中的偏差。

##### **Integrating Saliency Ranking and Reinforcement Learning for Enhanced Object Detection**
2408.06803v1 by Matthias Bartolo, Dylan Seychell, Josef Bajada

With the ever-growing variety of object detection approaches, this study
explores a series of experiments that combine reinforcement learning (RL)-based
visual attention methods with saliency ranking techniques to investigate
transparent and sustainable solutions. By integrating saliency ranking for
initial bounding box prediction and subsequently applying RL techniques to
refine these predictions through a finite set of actions over multiple time
steps, this study aims to enhance RL object detection accuracy. Presented as a
series of experiments, this research investigates the use of various image
feature extraction methods and explores diverse Deep Q-Network (DQN)
architectural variations for deep reinforcement learning-based localisation
agent training. Additionally, we focus on optimising the detection pipeline at
every step by prioritising lightweight and faster models, while also
incorporating the capability to classify detected objects, a feature absent in
previous RL approaches. We show that by evaluating the performance of these
trained agents using the Pascal VOC 2007 dataset, faster and more optimised
models were developed. Notably, the best mean Average Precision (mAP) achieved
in this study was 51.4, surpassing benchmarks set by RL-based single object
detectors in the literature.

摘要：隨著物件偵測方法的種類不斷增加，本研究探討一系列實驗，結合基於強化學習 (RL) 的視覺注意力方法與顯著性排名技術，以調查透明且永續的解決方案。透過整合顯著性排名以進行初始邊界框預測，並隨後應用 RL 技術，透過有限的動作集在多個時間步驟中精煉這些預測，本研究旨在提升 RL 物件偵測準確度。本研究以一系列實驗的形式呈現，探討使用各種影像特徵萃取方法，並探索各種深度 Q 網路 (DQN) 架構變異，以進行基於深度強化學習的定位代理訓練。此外，我們專注於透過優先考慮輕量級且更快速的模型，在每個步驟中最佳化偵測管線，同時也納入分類已偵測物件的能力，這項功能在先前的 RL 方法中並不存在。我們顯示，透過使用 Pascal VOC 2007 資料集評估這些訓練代理的效能，開發出更快速且最佳化的模型。值得注意的是，本研究中達成的最佳平均準確度 (mAP) 為 51.4，超越了文獻中基於 RL 的單一物件偵測器所設定的基準。

##### **Layerwise Recurrent Router for Mixture-of-Experts**
2408.06793v1 by Zihan Qiu, Zeyu Huang, Shuang Cheng, Yizhi Zhou, Zili Wang, Ivan Titov, Jie Fu

The scaling of large language models (LLMs) has revolutionized their
capabilities in various tasks, yet this growth must be matched with efficient
computational strategies. The Mixture-of-Experts (MoE) architecture stands out
for its ability to scale model size without significantly increasing training
costs. Despite their advantages, current MoE models often display parameter
inefficiency. For instance, a pre-trained MoE-based LLM with 52 billion
parameters might perform comparably to a standard model with 6.7 billion
parameters. Being a crucial part of MoE, current routers in different layers
independently assign tokens without leveraging historical routing information,
potentially leading to suboptimal token-expert combinations and the parameter
inefficiency problem. To alleviate this issue, we introduce the Layerwise
Recurrent Router for Mixture-of-Experts (RMoE). RMoE leverages a Gated
Recurrent Unit (GRU) to establish dependencies between routing decisions across
consecutive layers. Such layerwise recurrence can be efficiently parallelly
computed for input tokens and introduces negotiable costs. Our extensive
empirical evaluations demonstrate that RMoE-based language models consistently
outperform a spectrum of baseline models. Furthermore, RMoE integrates a novel
computation stage orthogonal to existing methods, allowing seamless
compatibility with other MoE architectures. Our analyses attribute RMoE's gains
to its effective cross-layer information sharing, which also improves expert
selection and diversity. Our code is at https://github.com/qiuzh20/RMoE

摘要：大型語言模型 (LLM) 的擴充徹底革新了它們在各種任務中的能力，然而這種成長必須與有效的運算策略相匹配。專家混合 (MoE) 架構因其在不顯著增加訓練成本的情況下擴充模型規模的能力而脫穎而出。儘管有其優點，目前的 MoE 模型通常會顯示參數效率低下。例如，一個預先訓練的、基於 MoE 的 LLM，擁有 520 億個參數，其表現可能與一個擁有 67 億個參數的標準模型相當。作為 MoE 的一個關鍵部分，不同層中的目前路由器會獨立分配符號，而不會利用歷史路由資訊，這可能會導致次佳符號專家組合和參數效率低下問題。為了緩解這個問題，我們引入了混合專家分層遞迴路由器 (RMoE)。RMoE 利用門控遞迴單元 (GRU) 來建立跨連續層的路由決策之間的依賴關係。這種分層遞迴可以有效地並行計算輸入符號，並引入可協商的成本。我們廣泛的實證評估表明，基於 RMoE 的語言模型始終優於一系列基準模型。此外，RMoE 整合了一個新穎的運算階段，與現有方法正交，允許與其他 MoE 架構無縫相容。我們的分析將 RMoE 的收益歸因於其有效的跨層資訊共享，這也改善了專家選擇和多樣性。我們的程式碼位於 https://github.com/qiuzh20/RMoE

##### **Unlock the Power of Frozen LLMs in Knowledge Graph Completion**
2408.06787v1 by Bo Xue, Yi Xu, Yunchong Song, Yiming Pang, Yuyang Ren, Jiaxin Ding, Luoyi Fu, Xinbing Wang

Classical knowledge graph completion (KGC) methods rely solely on structural
information, struggling with the inherent sparsity of knowledge graphs (KGs).
Large Language Models (LLMs) learn extensive knowledge from large corpora with
powerful context modeling, which is ideal for mitigating the limitations of
previous methods. Directly fine-tuning LLMs offers great capability but comes
at the cost of huge time and memory consumption, while utilizing frozen LLMs
yields suboptimal results. In this work, we aim to leverage LLMs for KGC
effectively and efficiently. We capture the context-aware hidden states of
knowledge triples by employing prompts to stimulate the intermediate layers of
LLMs. We then train a data-efficient classifier on these hidden states to
harness the inherent capabilities of frozen LLMs in KGC. We also generate
entity descriptions with subgraph sampling on KGs, reducing the ambiguity of
triplets and enriching the knowledge representation. Extensive experiments on
standard benchmarks showcase the efficiency and effectiveness of our approach.
We outperform classical KGC methods on most datasets and match the performance
of fine-tuned LLMs. Additionally, compared to fine-tuned LLMs, we boost GPU
memory efficiency by \textbf{$188\times$} and speed up training+inference by
\textbf{$13.48\times$}.

摘要：傳統知識圖譜完成 (KGC) 方法僅依賴結構化資訊，難以應對知識圖譜 (KG) 內在的稀疏性。大型語言模型 (LLM) 從大型語料庫中學習廣泛的知識，並具備強大的情境建模能力，這對於緩解先前方法的限制非常理想。直接微調 LLM 可提供強大的能力，但代價是耗費大量時間和記憶體，而利用凍結的 LLM 則會產生次佳結果。在這項工作中，我們旨在有效且高效地利用 LLM 來進行 KGC。我們透過使用提示來刺激 LLM 的中間層，捕捉到知識三元組的情境感知隱藏狀態。然後，我們在這些隱藏狀態上訓練一個資料有效率的分類器，以利用凍結 LLM 在 KGC 中的內在能力。我們還透過在 KG 上進行子圖抽樣來產生實體描述，減少三元組的模糊性並豐富知識表示。標準基準上的廣泛實驗展示了我們方法的效率和有效性。我們在多數資料集上優於傳統的 KGC 方法，並與微調後的 LLM 達到相同的效能。此外，與微調後的 LLM 相比，我們將 GPU 記憶體效率提升了 **$188\times$**，並將訓練 + 推論速度提升了 **$13.48\times$**。

##### **Fast-and-Frugal Text-Graph Transformers are Effective Link Predictors**
2408.06778v1 by Andrei C. Coman, Christos Theodoropoulos, Marie-Francine Moens, James Henderson

Link prediction models can benefit from incorporating textual descriptions of
entities and relations, enabling fully inductive learning and flexibility in
dynamic graphs. We address the challenge of also capturing rich structured
information about the local neighbourhood of entities and their relations, by
introducing a Transformer-based approach that effectively integrates textual
descriptions with graph structure, reducing the reliance on resource-intensive
text encoders. Our experiments on three challenging datasets show that our
Fast-and-Frugal Text-Graph (FnF-TG) Transformers achieve superior performance
compared to the previous state-of-the-art methods, while maintaining efficiency
and scalability.

摘要：連結預測模型可以從整合實體和關係的文字描述中受益，在動態圖表中實現完全歸納學習和靈活性。我們透過引入一種 Transformer 為基礎的方法來解決擷取實體和關係的局部鄰域的豐富結構化資訊的挑戰，該方法有效地將文字描述與圖形結構整合在一起，減少對資源密集型文字編碼器的依賴。我們在三個具有挑戰性的資料集上的實驗表明，與以前最先進的方法相比，我們的快速且簡約的文字圖形 (FnF-TG) Transformer 可實現卓越的效能，同時保持效率和可擴充性。

##### **Cross-View Geolocalization and Disaster Mapping with Street-View and VHR Satellite Imagery: A Case Study of Hurricane IAN**
2408.06761v1 by Hao Li, Fabian Deuser, Wenping Yina, Xuanshu Luo, Paul Walther, Gengchen Mai, Wei Huang, Martin Werner

Nature disasters play a key role in shaping human-urban infrastructure
interactions. Effective and efficient response to natural disasters is
essential for building resilience and a sustainable urban environment. Two
types of information are usually the most necessary and difficult to gather in
disaster response. The first information is about disaster damage perception,
which shows how badly people think that urban infrastructure has been damaged.
The second information is geolocation awareness, which means how people
whereabouts are made available. In this paper, we proposed a novel disaster
mapping framework, namely CVDisaster, aiming at simultaneously addressing
geolocalization and damage perception estimation using cross-view Street-View
Imagery (SVI) and Very High-Resolution satellite imagery. CVDisaster consists
of two cross-view models, where CVDisaster-Geoloc refers to a cross-view
geolocalization model based on a contrastive learning objective with a Siamese
ConvNeXt image encoder, and CVDisaster-Est is a cross-view classification model
based on a Couple Global Context Vision Transformer (CGCViT). Taking Hurricane
IAN as a case study, we evaluate the CVDisaster framework by creating a novel
cross-view dataset (CVIAN) and conducting extensive experiments. As a result,
we show that CVDisaster can achieve highly competitive performance (over 80%
for geolocalization and 75% for damage perception estimation) with even limited
fine-tuning efforts, which largely motivates future cross-view models and
applications within a broader GeoAI research community. The data and code are
publicly available at: https://github.com/tum-bgd/CVDisaster.

摘要：自然災害在塑造人類城市基礎設施互動中扮演著關鍵角色。有效且高效的自然災害應變措施對於建立韌性和永續的城市環境至關重要。在災害應變中，通常有兩種資訊最為必要且難以收集。第一種資訊是災害損害感知，這顯示了人們認為城市基礎設施損壞的程度。第二種資訊是地理位置感知，這表示人們的行蹤是如何被獲取的。在本文中，我們提出了一個新穎的災害製圖架構，即 CVDisaster，旨在同時利用跨視角街景影像 (SVI) 和極高解析度衛星影像，來解決地理定位和損害感知估計問題。CVDisaster 由兩個跨視角模型組成，其中 CVDisaster-Geoloc 指的是一個基於對比學習目標的跨視角地理定位模型，使用 Siamese ConvNeXt 影像編碼器；而 CVDisaster-Est 則是一個基於 Couple Global Context Vision Transformer (CGCViT) 的跨視角分類模型。我們以颶風 IAN 為例，透過建立一個新穎的跨視角資料集 (CVIAN) 並進行廣泛的實驗，來評估 CVDisaster 架構。結果顯示，即使在有限的微調工作下，CVDisaster 仍能達到極具競爭力的效能（地理定位超過 80%，損害感知估計超過 75%），這在很大程度上激勵了未來在更廣泛的 GeoAI 研究社群中開發跨視角模型和應用程式。資料和程式碼已公開於：https://github.com/tum-bgd/CVDisaster。

##### **Evaluating Research Quality with Large Language Models: An Analysis of ChatGPT's Effectiveness with Different Settings and Inputs**
2408.06752v1 by Mike Thelwall

Evaluating the quality of academic journal articles is a time consuming but
critical task for national research evaluation exercises, appointments and
promotion. It is therefore important to investigate whether Large Language
Models (LLMs) can play a role in this process. This article assesses which
ChatGPT inputs (full text without tables, figures and references; title and
abstract; title only) produce better quality score estimates, and the extent to
which scores are affected by ChatGPT models and system prompts. The results
show that the optimal input is the article title and abstract, with average
ChatGPT scores based on these (30 iterations on a dataset of 51 papers)
correlating at 0.67 with human scores, the highest ever reported. ChatGPT 4o is
slightly better than 3.5-turbo (0.66), and 4o-mini (0.66). The results suggest
that article full texts might confuse LLM research quality evaluations, even
though complex system instructions for the task are more effective than simple
ones. Thus, whilst abstracts contain insufficient information for a thorough
assessment of rigour, they may contain strong pointers about originality and
significance. Finally, linear regression can be used to convert the model
scores into the human scale scores, which is 31% more accurate than guessing.

摘要：評估學術期刊文章的品質是一項耗時但至關重要的任務，用於國家研究評鑑、任命和晉升。因此，探討大型語言模型 (LLM) 是否能在這個過程中發揮作用非常重要。本文評估了哪些 ChatGPT 輸入（沒有表格、圖表和參考文獻的全文；標題和摘要；僅標題）能產生品質更好的評分估計，以及 ChatGPT 模型和系統提示影響評分的程度。結果顯示，最佳輸入是文章標題和摘要，根據這些輸入的平均 ChatGPT 評分（對 51 篇論文的資料集進行 30 次反覆運算）與人工評分相關性為 0.67，是歷來報告過的最高分。ChatGPT 4o 略優於 3.5-turbo（0.66）和 4o-mini（0.66）。結果顯示，儘管針對此任務的複雜系統指令比簡單指令更有效，但文章全文可能會混淆 LLM 研究品質評估。因此，儘管摘要包含的資訊不足以進行徹底的嚴謹性評估，但它們可能包含關於原創性和重要性的有力指標。最後，線性迴歸可被用於將模型評分轉換為人工評分，其準確度比猜測高出 31%。

##### **DiffLoRA: Generating Personalized Low-Rank Adaptation Weights with Diffusion**
2408.06740v1 by Yujia Wu, Yiming Shi, Jiwei Wei, Chengwei Sun, Yuyang Zhou, Yang Yang, Heng Tao Shen

Personalized text-to-image generation has gained significant attention for
its capability to generate high-fidelity portraits of specific identities
conditioned on user-defined prompts. Existing methods typically involve
test-time fine-tuning or instead incorporating an additional pre-trained
branch. However, these approaches struggle to simultaneously address the
demands of efficiency, identity fidelity, and preserving the model's original
generative capabilities. In this paper, we propose DiffLoRA, a novel approach
that leverages diffusion models as a hypernetwork to predict personalized
low-rank adaptation (LoRA) weights based on the reference images. By
integrating these LoRA weights into the text-to-image model, DiffLoRA achieves
personalization during inference without further training. Additionally, we
propose an identity-oriented LoRA weight construction pipeline to facilitate
the training of DiffLoRA. By utilizing the dataset produced by this pipeline,
our DiffLoRA consistently generates high-performance and accurate LoRA weights.
Extensive evaluations demonstrate the effectiveness of our method, achieving
both time efficiency and maintaining identity fidelity throughout the
personalization process.

摘要：個性化文字轉圖片生成因其根據使用者定義提示生成特定身分的高保真肖像的能力而備受關注。現有方法通常涉及測試時微調，或改為納入額外預訓練分支。然而，這些方法難以同時滿足效率、身分保真度和保留模型原始生成能力的需求。在本文中，我們提出 DiffLoRA，一種新穎的方法，它利用擴散模型作為超網路，根據參考影像預測個性化的低秩適應 (LoRA) 權重。透過將這些 LoRA 權重整合到文字轉圖片模型中，DiffLoRA 在推理過程中實現個性化，而無需進一步訓練。此外，我們提出一個以身分為導向的 LoRA 權重建構管道，以簡化 DiffLoRA 的訓練。透過利用此管道產生的資料集，我們的 DiffLoRA 持續生成效能高且準確的 LoRA 權重。廣泛的評估證明了我們方法的有效性，在整個個性化過程中同時實現時間效率和維持身分保真度。

##### **Multilingual Models for Check-Worthy Social Media Posts Detection**
2408.06737v1 by Sebastian Kula, Michal Gregor

This work presents an extensive study of transformer-based NLP models for
detection of social media posts that contain verifiable factual claims and
harmful claims. The study covers various activities, including dataset
collection, dataset pre-processing, architecture selection, setup of settings,
model training (fine-tuning), model testing, and implementation. The study
includes a comprehensive analysis of different models, with a special focus on
multilingual models where the same model is capable of processing social media
posts in both English and in low-resource languages such as Arabic, Bulgarian,
Dutch, Polish, Czech, Slovak. The results obtained from the study were
validated against state-of-the-art models, and the comparison demonstrated the
robustness of the proposed models. The novelty of this work lies in the
development of multi-label multilingual classification models that can
simultaneously detect harmful posts and posts that contain verifiable factual
claims in an efficient way.

摘要：本研究針對基於 Transformer 的 NLP 模型進行廣泛的研究，以偵測包含可驗證事實聲明和有害聲明的社群媒體貼文。本研究涵蓋各種活動，包括資料集收集、資料集預處理、架構選擇、設定設定、模型訓練（微調）、模型測試和實作。本研究包含對不同模型的全面分析，特別關注多語言模型，其中同一個模型能夠處理英文和低資源語言（例如阿拉伯文、保加利亞文、荷蘭文、波蘭文、捷克文、斯洛伐克文）的社群媒體貼文。本研究獲得的結果已針對最先進的模型進行驗證，而比較結果則證明了所提出模型的穩健性。本研究的新穎之處在於開發多標籤多語言分類模型，能夠同時有效率地偵測有害貼文和包含可驗證事實聲明的貼文。

##### **Exploring the anatomy of articulation rate in spontaneous English speech: relationships between utterance length effects and social factors**
2408.06732v1 by James Tanner, Morgan Sonderegger, Jane Stuart-Smith, Tyler Kendall, Jeff Mielke, Robin Dodsworth, Erik Thomas

Speech rate has been shown to vary across social categories such as gender,
age, and dialect, while also being conditioned by properties of speech
planning. The effect of utterance length, where speech rate is faster and less
variable for longer utterances, has also been shown to reduce the role of
social factors once it has been accounted for, leaving unclear the relationship
between social factors and speech production in conditioning speech rate.
Through modelling of speech rate across 13 English speech corpora, it is found
that utterance length has the largest effect on speech rate, though this effect
itself varies little across corpora and speakers. While age and gender also
modulate speech rate, their effects are much smaller in magnitude. These
findings suggest utterance length effects may be conditioned by articulatory
and perceptual constraints, and that social influences on speech rate should be
interpreted in the broader context of how speech rate variation is structured.

摘要：語速已證實會因性別、年齡和方言等社會類別而有所不同，同時也受說話計畫的屬性制約。已證實，語句長度（語速較快且變異較小）的效果會降低社會因素在考量後所扮演的角色，使社會因素與說話生產在制約語速之間的關係不明確。透過對 13 個英語語料庫的語速建模，發現語句長度對語速的影響最大，儘管此效果本身在語料庫和說話者之間的差異很小。雖然年齡和性別也會調節語速，但其影響在幅度上小得多。這些發現表明語句長度效應可能受發音和感知約束的制約，並且應在語速變化如何構成的更廣泛背景下解釋語速的社會影響。

##### **Large language models can consistently generate high-quality content for election disinformation operations**
2408.06731v1 by Angus R. Williams, Liam Burke-Moore, Ryan Sze-Yin Chan, Florence E. Enock, Federico Nanni, Tvesha Sippy, Yi-Ling Chung, Evelina Gabasova, Kobi Hackenburg, Jonathan Bright

Advances in large language models have raised concerns about their potential
use in generating compelling election disinformation at scale. This study
presents a two-part investigation into the capabilities of LLMs to automate
stages of an election disinformation operation. First, we introduce DisElect, a
novel evaluation dataset designed to measure LLM compliance with instructions
to generate content for an election disinformation operation in localised UK
context, containing 2,200 malicious prompts and 50 benign prompts. Using
DisElect, we test 13 LLMs and find that most models broadly comply with these
requests; we also find that the few models which refuse malicious prompts also
refuse benign election-related prompts, and are more likely to refuse to
generate content from a right-wing perspective. Secondly, we conduct a series
of experiments (N=2,340) to assess the "humanness" of LLMs: the extent to which
disinformation operation content generated by an LLM is able to pass as
human-written. Our experiments suggest that almost all LLMs tested released
since 2022 produce election disinformation operation content indiscernible by
human evaluators over 50% of the time. Notably, we observe that multiple models
achieve above-human levels of humanness. Taken together, these findings suggest
that current LLMs can be used to generate high-quality content for election
disinformation operations, even in hyperlocalised scenarios, at far lower costs
than traditional methods, and offer researchers and policymakers an empirical
benchmark for the measurement and evaluation of these capabilities in current
and future models.

摘要：大型語言模型的進步引發了人們對其可能大規模產生引人注目的選舉錯誤訊息的擔憂。本研究對大型語言模型自動化選舉錯誤訊息操作階段的能力進行了兩部分調查。首先，我們介紹 DisElect，這是一個新穎的評估資料集，旨在衡量大型語言模型在英國本土語境中遵循指示為選舉錯誤訊息操作生成內容的能力，其中包含 2,200 個惡意提示和 50 個良性提示。使用 DisElect，我們測試了 13 個大型語言模型，發現大多數模型廣泛遵循這些請求；我們還發現，少數拒絕惡意提示的模型也拒絕良性的選舉相關提示，並且更有可能拒絕從右翼角度生成內容。其次，我們進行了一系列實驗 (N=2,340) 來評估大型語言模型的「人味」：大型語言模型產生的錯誤訊息操作內容能夠冒充人類編寫的程度。我們的實驗表明，自 2022 年以來測試的幾乎所有大型語言模型都產生了超過 50% 的時間讓人類評估者無法辨別的選舉錯誤訊息操作內容。值得注意的是，我們觀察到多個模型達到了高於人類的人味水平。綜上所述，這些發現表明，即使在高度本地化的場景中，當前的大型語言模型也可被用於為選舉錯誤訊息操作生成高品質的內容，成本遠低於傳統方法，並為研究人員和政策制定者提供了一個用於衡量和評估當前和未來模型中這些能力的經驗基準。

##### **Enhancing Visual Dialog State Tracking through Iterative Object-Entity Alignment in Multi-Round Conversations**
2408.06725v1 by Wei Pang, Ruixue Duan, Jinfu Yang, Ning Li

Visual Dialog (VD) is a task where an agent answers a series of image-related
questions based on a multi-round dialog history. However, previous VD methods
often treat the entire dialog history as a simple text input, disregarding the
inherent conversational information flows at the round level. In this paper, we
introduce Multi-round Dialogue State Tracking model (MDST), a framework that
addresses this limitation by leveraging the dialogue state learned from dialog
history to answer questions. MDST captures each round of dialog history,
constructing internal dialogue state representations defined as 2-tuples of
vision-language representations. These representations effectively ground the
current question, enabling the generation of accurate answers. Experimental
results on the VisDial v1.0 dataset demonstrate that MDST achieves a new
state-of-the-art performance in generative setting. Furthermore, through a
series of human studies, we validate the effectiveness of MDST in generating
long, consistent, and human-like answers while consistently answering a series
of questions correctly.

摘要：視覺對話 (VD) 是一項任務，其中代理會根據多輪對話歷史回答一系列與影像相關的問題。然而，先前的 VD 方法通常將整個對話歷史視為一個簡單的文字輸入，而忽略了回合層級中固有的對話資訊流。在本文中，我們介紹了多輪對話狀態追蹤模型 (MDST)，一個透過利用從對話歷史中學習到的對話狀態來回答問題，進而解決此限制的架構。MDST 擷取每一輪的對話歷史，建構內部對話狀態表示，定義為視覺語言表示的 2 元組。這些表示有效地奠定當前問題的基礎，使能夠產生準確的答案。在 VisDial v1.0 資料集上的實驗結果證明，MDST 在生成式設定中達到了新的最先進效能。此外，透過一系列的人類研究，我們驗證了 MDST 在產生長、一致且類似人類的答案方面的有效性，同時連續正確回答一系列問題。

##### **Computation-friendly Graph Neural Network Design by Accumulating Knowledge on Large Language Models**
2408.06717v1 by Jialiang Wang, Shimin Di, Hanmo Liu, Zhili Wang, Jiachuan Wang, Lei Chen, Xiaofang Zhou

Graph Neural Networks (GNNs), like other neural networks, have shown
remarkable success but are hampered by the complexity of their architecture
designs, which heavily depend on specific data and tasks. Traditionally,
designing proper architectures involves trial and error, which requires
intensive manual effort to optimize various components. To reduce human
workload, researchers try to develop automated algorithms to design GNNs.
However, both experts and automated algorithms suffer from two major issues in
designing GNNs: 1) the substantial computational resources expended in
repeatedly trying candidate GNN architectures until a feasible design is
achieved, and 2) the intricate and prolonged processes required for humans or
algorithms to accumulate knowledge of the interrelationship between graphs,
GNNs, and performance.
  To further enhance the automation of GNN architecture design, we propose a
computation-friendly way to empower Large Language Models (LLMs) with
specialized knowledge in designing GNNs, thereby drastically shortening the
computational overhead and development cycle of designing GNN architectures.
Our framework begins by establishing a knowledge retrieval pipeline that
comprehends the intercorrelations between graphs, GNNs, and performance. This
pipeline converts past model design experiences into structured knowledge for
LLM reference, allowing it to quickly suggest initial model proposals.
Subsequently, we introduce a knowledge-driven search strategy that emulates the
exploration-exploitation process of human experts, enabling quick refinement of
initial proposals within a promising scope. Extensive experiments demonstrate
that our framework can efficiently deliver promising (e.g., Top-5.77%) initial
model proposals for unseen datasets within seconds and without any prior
training and achieve outstanding search performance in a few iterations.

摘要：圖形神經網路 (GNN) 與其他神經網路一樣，已展現出顯著的成功，但其架構設計的複雜性卻阻礙了進一步的發展，而這種複雜性在很大程度上取決於具體的資料和任務。傳統上，設計適當的架構需要反覆嘗試，這需要大量的人工工作才能最佳化各種元件。為了減少人力的負擔，研究人員嘗試開發自動化演算法來設計 GNN。然而，專家和自動化演算法在設計 GNN 時都會遇到兩個主要問題：1) 在反覆嘗試候選 GNN 架構以達成可行的設計之前，會耗費大量的運算資源，以及 2) 人類或演算法需要花費大量複雜而漫長的程序才能累積有關圖形、GNN 和效能之間相互關係的知識。
為了進一步提升 GNN 架構設計的自動化，我們提出了一種運算友善的方式，讓大型語言模型 (LLM) 具備設計 GNN 的專業知識，從而大幅縮短設計 GNN 架構的運算負擔和開發週期。我們的架構首先建立一個知識擷取管道，了解圖形、GNN 和效能之間的相互關聯性。這個管道將過去的模型設計經驗轉換成結構化的知識，供 LLM 參考，讓 LLM 能夠快速提出初步的模型建議。隨後，我們引入一種知識驅動的搜尋策略，模擬人類專家的探索與開發程序，讓 LLM 能在有希望的範圍內快速改善初步建議。廣泛的實驗證明，我們的架構可以在幾秒鐘內有效地針對未見過的資料集提供有希望的 (例如，前 5.77%) 初步模型建議，而且無需任何先前的訓練，並在幾次反覆運算中就能達成傑出的搜尋效能。

##### **Variational Learning of Gaussian Process Latent Variable Models through Stochastic Gradient Annealed Importance Sampling**
2408.06710v1 by Jian Xu, Shian Du, Junmei Yang, Qianli Ma, Delu Zeng

Gaussian Process Latent Variable Models (GPLVMs) have become increasingly
popular for unsupervised tasks such as dimensionality reduction and missing
data recovery due to their flexibility and non-linear nature. An
importance-weighted version of the Bayesian GPLVMs has been proposed to obtain
a tighter variational bound. However, this version of the approach is primarily
limited to analyzing simple data structures, as the generation of an effective
proposal distribution can become quite challenging in high-dimensional spaces
or with complex data sets. In this work, we propose an Annealed Importance
Sampling (AIS) approach to address these issues. By transforming the posterior
into a sequence of intermediate distributions using annealing, we combine the
strengths of Sequential Monte Carlo samplers and VI to explore a wider range of
posterior distributions and gradually approach the target distribution. We
further propose an efficient algorithm by reparameterizing all variables in the
evidence lower bound (ELBO). Experimental results on both toy and image
datasets demonstrate that our method outperforms state-of-the-art methods in
terms of tighter variational bounds, higher log-likelihoods, and more robust
convergence.

摘要：高斯過程潛在變數模型 (GPLVM) 由於其靈活性與非線性性質，已在無監督任務中變得越來越受歡迎，例如降維和遺失資料復原。已提出貝氏 GPLVM 的重要性加權版本以獲得更緊密的變分界限。然而，此版本的應用主要限於分析簡單的資料結構，因為在高維空間或處理複雜資料集時，產生有效的提議分佈可能變得相當具有挑戰性。在這項工作中，我們提出退火重要性採樣 (AIS) 方法來解決這些問題。透過使用退火將後驗轉換為一系列中間分佈，我們結合了序列蒙地卡羅取樣器和 VI 的優點，探索更廣泛的後驗分佈並逐漸逼近目標分佈。我們進一步提出一個有效率的演算法，重新參數化 ELBO 中的所有變數。玩具和影像資料集的實驗結果證明，我們的模型在更緊密的變分界限、更高的對數似然值和更穩健的收斂性方面優於最先進的模型。

##### **Information Geometry and Beta Link for Optimizing Sparse Variational Student-t Processes**
2408.06699v1 by Jian Xu, Delu Zeng, John Paisley

Recently, a sparse version of Student-t Processes, termed sparse variational
Student-t Processes, has been proposed to enhance computational efficiency and
flexibility for real-world datasets using stochastic gradient descent. However,
traditional gradient descent methods like Adam may not fully exploit the
parameter space geometry, potentially leading to slower convergence and
suboptimal performance. To mitigate these issues, we adopt natural gradient
methods from information geometry for variational parameter optimization of
Student-t Processes. This approach leverages the curvature and structure of the
parameter space, utilizing tools such as the Fisher information matrix which is
linked to the Beta function in our model. This method provides robust
mathematical support for the natural gradient algorithm when using Student's
t-distribution as the variational distribution. Additionally, we present a
mini-batch algorithm for efficiently computing natural gradients. Experimental
results across four benchmark datasets demonstrate that our method consistently
accelerates convergence speed.

摘要：最近，有人提出了一种稀疏版本的 Student-t 过程，称为稀疏变分 Student-t 过程，旨在使用随机梯度下降来提高真实世界数据集的计算效率和灵活性。然而，传统的梯度下降方法（如 Adam）可能无法充分利用参数空间几何，这可能会导致收敛速度变慢和性能不佳。为了缓解这些问题，我们采用了信息几何中的自然梯度方法来对 Student-t 过程进行变分参数优化。这种方法利用了参数空间的曲率和结构，利用了诸如 Fisher 信息矩阵之类的工具，该矩阵在我们的模型中与 Beta 函数相关联。当使用 Student's t 分布作为变分分布时，这种方法为自然梯度算法提供了稳健的数学支持。此外，我们还提出了一种小批量算法，用于有效计算自然梯度。四个基准数据集的实验结果表明，我们的方法始终可以提高收敛速度。

##### **SlotLifter: Slot-guided Feature Lifting for Learning Object-centric Radiance Fields**
2408.06697v1 by Yu Liu, Baoxiong Jia, Yixin Chen, Siyuan Huang

The ability to distill object-centric abstractions from intricate visual
scenes underpins human-level generalization. Despite the significant progress
in object-centric learning methods, learning object-centric representations in
the 3D physical world remains a crucial challenge. In this work, we propose
SlotLifter, a novel object-centric radiance model addressing scene
reconstruction and decomposition jointly via slot-guided feature lifting. Such
a design unites object-centric learning representations and image-based
rendering methods, offering state-of-the-art performance in scene decomposition
and novel-view synthesis on four challenging synthetic and four complex
real-world datasets, outperforming existing 3D object-centric learning methods
by a large margin. Through extensive ablative studies, we showcase the efficacy
of designs in SlotLifter, revealing key insights for potential future
directions.

摘要：從複雜的視覺場景中提取以物體為中心的概念的能力，是人類層級概括的基礎。儘管以物體為中心的學習方法取得了顯著進展，但在 3D 物理世界中學習以物體為中心的表示仍然是一項關鍵挑戰。在這項工作中，我們提出了 SlotLifter，這是一種新穎的以物體為中心的輻射度模型，通過槽引導特徵提升，同時解決場景重建和分解問題。這種設計結合了以物體為中心的學習表示和基於影像的渲染方法，在場景分解和新視角合成方面提供了最先進的效能，在四個具有挑戰性的合成資料集和四個複雜的真實世界資料集上，大幅優於現有的 3D 以物體為中心的學習方法。透過廣泛的消融研究，我們展示了 SlotLifter 中設計的功效，揭示了對潛在未來方向的關鍵見解。

##### **DC3DO: Diffusion Classifier for 3D Objects**
2408.06693v1 by Nursena Koprucu, Meher Shashwat Nigam, Shicheng Xu, Biruk Abere, Gabriele Dominici, Andrew Rodriguez, Sharvaree Vadgam, Berfin Inal, Alberto Tono

Inspired by Geoffrey Hinton emphasis on generative modeling, To recognize
shapes, first learn to generate them, we explore the use of 3D diffusion models
for object classification. Leveraging the density estimates from these models,
our approach, the Diffusion Classifier for 3D Objects (DC3DO), enables
zero-shot classification of 3D shapes without additional training. On average,
our method achieves a 12.5 percent improvement compared to its multiview
counterparts, demonstrating superior multimodal reasoning over discriminative
approaches. DC3DO employs a class-conditional diffusion model trained on
ShapeNet, and we run inferences on point clouds of chairs and cars. This work
highlights the potential of generative models in 3D object classification.

摘要：受 Geoffrey Hinton 对生成式模型的强调所启发，要辨识形状，首先要学习生成它们，我们探索使用 3D 扩散模型进行物件分类。利用这些模型的密度估计，我们的方法，即 3D 物件扩散分类器 (DC3DO)，能够在没有额外训练的情况下进行 3D 形状的零次分类。平均而言，我们的方法比其多视图对应方法提高了 12.5 个百分点，展示了优于判别方法的多模态推理。DC3DO 采用在 ShapeNet 上训练的类条件扩散模型，我们在椅子的点云和汽车的点云上进行推理。这项工作突出了生成式模型在 3D 物件分类中的潜力。

##### **Masked Image Modeling: A Survey**
2408.06687v1 by Vlad Hondru, Florinel Alin Croitoru, Shervin Minaee, Radu Tudor Ionescu, Nicu Sebe

In this work, we survey recent studies on masked image modeling (MIM), an
approach that emerged as a powerful self-supervised learning technique in
computer vision. The MIM task involves masking some information, e.g. pixels,
patches, or even latent representations, and training a model, usually an
autoencoder, to predicting the missing information by using the context
available in the visible part of the input. We identify and formalize two
categories of approaches on how to implement MIM as a pretext task, one based
on reconstruction and one based on contrastive learning. Then, we construct a
taxonomy and review the most prominent papers in recent years. We complement
the manually constructed taxonomy with a dendrogram obtained by applying a
hierarchical clustering algorithm. We further identify relevant clusters via
manually inspecting the resulting dendrogram. Our review also includes datasets
that are commonly used in MIM research. We aggregate the performance results of
various masked image modeling methods on the most popular datasets, to
facilitate the comparison of competing methods. Finally, we identify research
gaps and propose several interesting directions of future work.

摘要：在這項工作中，我們調查了關於遮罩圖像建模 (MIM) 的最新研究，這是一種在電腦視覺中作為強大的自我監督學習技術出現的方法。MIM 任務涉及遮罩一些資訊，例如像素、貼片，甚至潛在表示，並訓練模型（通常是自動編碼器）使用輸入可見部分中的內容來預測遺失的資訊。我們識別並形式化了兩種關於如何將 MIM 實作為藉口任務的方法，一種基於重建，另一種基於對比學習。然後，我們構建了一個分類法，並回顧了近年來最突出的論文。我們使用分層聚類演算法取得樹狀圖，以補充人工構建的分類法。我們進一步透過人工檢查結果樹狀圖來識別相關叢集。我們的回顧還包括 MIM 研究中常用的資料集。我們彙總了各種遮罩圖像建模方法在最熱門資料集上的效能結果，以利於比較競爭方法。最後，我們找出研究差距，並提出未來工作中幾個有趣的發展方向。

##### **Pragmatic inference of scalar implicature by LLMs**
2408.06673v1 by Ye-eun Cho, Seong mook Kim

This study investigates how Large Language Models (LLMs), particularly BERT
(Devlin et al., 2019) and GPT-2 (Radford et al., 2019), engage in pragmatic
inference of scalar implicature, such as some. Two sets of experiments were
conducted using cosine similarity and next sentence/token prediction as
experimental methods. The results in experiment 1 showed that, both models
interpret some as pragmatic implicature not all in the absence of context,
aligning with human language processing. In experiment 2, in which Question
Under Discussion (QUD) was presented as a contextual cue, BERT showed
consistent performance regardless of types of QUDs, while GPT-2 encountered
processing difficulties since a certain type of QUD required pragmatic
inference for implicature. The findings revealed that, in terms of theoretical
approaches, BERT inherently incorporates pragmatic implicature not all within
the term some, adhering to Default model (Levinson, 2000). In contrast, GPT-2
seems to encounter processing difficulties in inferring pragmatic implicature
within context, consistent with Context-driven model (Sperber and Wilson,
2002).

摘要：本研究探討大型語言模型 (LLM)，特別是 BERT (Devlin 等人，2019) 和 GPT-2 (Radford 等人，2019) 如何進行標量暗示的語用推理，例如 some。使用餘弦相似性和下一個句子/符號預測作為實驗方法，進行了兩組實驗。實驗 1 的結果表明，這兩個模型在沒有語境的情況下，都將 some 解釋為語用暗示 not all，這與人類語言處理一致。在實驗 2 中，其中問題討論 (QUD) 被呈現為語境線索，BERT 顯示出無論 QUD 類型如何，都具有穩定的表現，而 GPT-2 遇到處理困難，因為某種類型的 QUD 需要語用推理才能暗示。研究結果表明，在理論方法方面，BERT 本質上將語用暗示 not all 納入術語 some 中，遵循默認模型 (Levinson，2000)。相比之下，GPT-2 似乎在推論語境中的語用暗示時遇到處理困難，這與語境驅動模型 (Sperber 和 Wilson，2002) 一致。

##### **Leveraging Priors via Diffusion Bridge for Time Series Generation**
2408.06672v1 by Jinseong Park, Seungyun Lee, Woojin Jeong, Yujin Choi, Jaewook Lee

Time series generation is widely used in real-world applications such as
simulation, data augmentation, and hypothesis test techniques. Recently,
diffusion models have emerged as the de facto approach for time series
generation, emphasizing diverse synthesis scenarios based on historical or
correlated time series data streams. Since time series have unique
characteristics, such as fixed time order and data scaling, standard Gaussian
prior might be ill-suited for general time series generation. In this paper, we
exploit the usage of diverse prior distributions for synthesis. Then, we
propose TimeBridge, a framework that enables flexible synthesis by leveraging
diffusion bridges to learn the transport between chosen prior and data
distributions. Our model covers a wide range of scenarios in time series
diffusion models, which leverages (i) data- and time-dependent priors for
unconditional synthesis, and (ii) data-scale preserving synthesis with a
constraint as a prior for conditional generation. Experimentally, our model
achieves state-of-the-art performance in both unconditional and conditional
time series generation tasks.

摘要：時間序列生成廣泛用於實際應用中，例如模擬、數據擴充和假設檢定技術。最近，擴散模型已成為時間序列生成的實際方法，強調基於歷史或相關時間序列數據流的不同合成場景。由於時間序列具有獨特特徵，例如固定的時間順序和數據縮放，標準高斯先驗可能不適合於一般時間序列生成。在本文中，我們利用了多樣化先驗分佈的合成用途。然後，我們提出 TimeBridge，一個透過利用擴散橋樑來學習所選先驗和數據分佈之間傳輸的架構，以實現靈活合成。我們的模型涵蓋了時間序列擴散模型中的廣泛場景，它利用 (i) 資料和時間相關先驗進行無條件合成，以及 (ii) 資料尺度保存合成，並以約束作為條件生成的先驗。在實驗中，我們的模型在無條件和條件時間序列生成任務中都達到了最先進的效能。

##### **RW-NSGCN: A Robust Approach to Structural Attacks via Negative Sampling**
2408.06665v1 by Shuqi He, Jun Zhuang, Ding Wang, Jun Song

Node classification using Graph Neural Networks (GNNs) has been widely
applied in various practical scenarios, such as predicting user interests and
detecting communities in social networks. However, recent studies have shown
that graph-structured networks often contain potential noise and attacks, in
the form of topological perturbations and weight disturbances, which can lead
to decreased classification performance in GNNs. To improve the robustness of
the model, we propose a novel method: Random Walk Negative Sampling Graph
Convolutional Network (RW-NSGCN). Specifically, RW-NSGCN integrates the Random
Walk with Restart (RWR) and PageRank (PGR) algorithms for negative sampling and
employs a Determinantal Point Process (DPP)-based GCN for convolution
operations. RWR leverages both global and local information to manage noise and
local variations, while PGR assesses node importance to stabilize the
topological structure. The DPP-based GCN ensures diversity among negative
samples and aggregates their features to produce robust node embeddings,
thereby improving classification performance. Experimental results demonstrate
that the RW-NSGCN model effectively addresses network topology attacks and
weight instability, increasing the accuracy of anomaly detection and overall
stability. In terms of classification accuracy, RW-NSGCN significantly
outperforms existing methods, showing greater resilience across various
scenarios and effectively mitigating the impact of such vulnerabilities.

摘要：圖形神經網路 (GNN) 的節點分類已廣泛應用於各種實際情境中，例如預測使用者興趣和偵測社群網路中的社群。然而，最近的研究顯示，圖形結構網路常常包含潛在的雜訊和攻擊，以拓撲擾動和權重擾動的形式存在，這可能會導致 GNN 中的分類效能下降。為了改善模型的穩健性，我們提出了一種新方法：隨機遊走負取樣圖形卷積網路 (RW-NSGCN)。具體來說，RW-NSGCN 將重新啟動隨機遊走 (RWR) 和 PageRank (PGR) 演算法整合用於負取樣，並採用基於行列式點過程 (DPP) 的 GCN 進行卷積運算。RWR 利用全域和局部資訊來管理雜訊和局部變化，而 PGR 則評估節點重要性以穩定拓撲結構。基於 DPP 的 GCN 確保負樣本之間的多樣性，並彙總其特徵以產生穩健的節點嵌入，從而改善分類效能。實驗結果證明，RW-NSGCN 模型有效地解決了網路拓撲攻擊和權重不穩定性的問題，提高了異常偵測的準確性和整體穩定性。在分類準確性方面，RW-NSGCN 明顯優於現有方法，在各種情境中展現出更高的韌性，並有效減輕此類漏洞的影響。

##### **Amuro & Char: Analyzing the Relationship between Pre-Training and Fine-Tuning of Large Language Models**
2408.06663v2 by Kaiser Sun, Mark Dredze

The development of large language models leads to the formation of a
pre-train-then-align paradigm, in which the model is typically pre-trained on a
large text corpus and undergoes a tuning stage to align the model with human
preference or downstream tasks. In this work, we investigate the relationship
between pre-training and fine-tuning by fine-tuning multiple intermediate
pre-trained model checkpoints. Our results on 18 datasets suggest that i)
continual pre-training improves the model in a latent way that unveils after
fine-tuning; ii) with extra fine-tuning, the datasets that the model does not
demonstrate capability gain much more than those that the model performs well
during the pre-training stage; iii) although model benefits significantly
through supervised fine-tuning, it may forget previously known domain knowledge
and the tasks that are not seen during fine-tuning; iv) the model resembles
high sensitivity to evaluation prompts after supervised fine-tuning, but this
sensitivity can be alleviated by more pre-training.

摘要：大型語言模型的發展導致形成預訓練後對齊的範例，其中模型通常在大型文本語料庫上進行預訓練，並經歷調整階段，以將模型與人類偏好或下游任務對齊。在這項工作中，我們透過微調多個中間預訓練模型檢查點來探討預訓練和微調之間的關係。我們在 18 個資料集上的結果表明：i) 持續預訓練以潛在的方式改善模型，這種方式在微調後揭示出來；ii) 透過額外的微調，模型未展現能力的資料集比在預訓練階段表現良好的資料集獲得更多收益；iii) 儘管模型透過監督式微調顯著受益，但它可能會忘記先前已知的領域知識和微調期間未見的任務；iv) 模型在監督式微調後對評估提示展現出高度敏感性，但這種敏感性可以透過更多預訓練來緩解。

##### **Hierarchical Structured Neural Network for Retrieval**
2408.06653v1 by Kaushik Rangadurai, Siyang Yuan, Minhui Huang, Yiqun Liu, Golnaz Ghasemiesfeh, Yunchen Pu, Xinfeng Xie, Xingfeng He, Fangzhou Xu, Andrew Cui, Vidhoon Viswanathan, Yan Dong, Liang Xiong, Lin Yang, Liang Wang, Jiyan Yang, Chonglin Sun

Embedding Based Retrieval (EBR) is a crucial component of the retrieval stage
in (Ads) Recommendation System that utilizes Two Tower or Siamese Networks to
learn embeddings for both users and items (ads). It then employs an Approximate
Nearest Neighbor Search (ANN) to efficiently retrieve the most relevant ads for
a specific user. Despite the recent rise to popularity in the industry, they
have a couple of limitations. Firstly, Two Tower model architecture uses a
single dot product interaction which despite their efficiency fail to capture
the data distribution in practice. Secondly, the centroid representation and
cluster assignment, which are components of ANN, occur after the training
process has been completed. As a result, they do not take into account the
optimization criteria used for retrieval model. In this paper, we present
Hierarchical Structured Neural Network (HSNN), a deployed jointly optimized
hierarchical clustering and neural network model that can take advantage of
sophisticated interactions and model architectures that are more common in the
ranking stages while maintaining a sub-linear inference cost. We achieve 6.5%
improvement in offline evaluation and also demonstrate 1.22% online gains
through A/B experiments. HSNN has been successfully deployed into the Ads
Recommendation system and is currently handling major portion of the traffic.
The paper shares our experience in developing this system, dealing with
challenges like freshness, volatility, cold start recommendations, cluster
collapse and lessons deploying the model in a large scale retrieval production
system.

摘要：嵌入式檢索 (EBR) 是檢索階段的關鍵組成部分，在 (廣告) 推薦系統中，它利用雙塔或連體網路來學習使用者和項目 (廣告) 的嵌入。接著，它使用近似最近鄰搜尋 (ANN) 有效地檢索與特定使用者最相關的廣告。儘管最近在業界中越來越受歡迎，它們還是有幾個限制。首先，雙塔模型架構使用單點積交互作用，儘管它們很有效率，但無法在實務中擷取資料分佈。其次，質心表示和叢集分配是 ANN 的組成部分，它們出現在訓練程序完成之後。因此，它們不會考量檢索模型所使用的最佳化準則。在本文中，我們提出分層結構神經網路 (HSNN)，一個已部署的經過聯合最佳化處理的分層叢集和神經網路模型，它可以利用在排名階段更常見的精密互動和模型架構，同時維持次線性推論成本。我們在離線評估中取得 6.5% 的進步，並透過 A/B 實驗證明有 1.22% 的線上收益。HSNN 已成功部署到廣告推薦系統中，目前處理大部分的流量。本文分享我們在開發此系統方面的經驗，處理新鮮度、波動性、冷啟動推薦、叢集崩潰等挑戰，以及在大型檢索生產系統中部署模型的經驗。

##### **Harnessing Earnings Reports for Stock Predictions: A QLoRA-Enhanced LLM Approach**
2408.06634v1 by Haowei Ni, Shuchen Meng, Xupeng Chen, Ziqing Zhao, Andi Chen, Panfeng Li, Shiyao Zhang, Qifu Yin, Yuanqing Wang, Yuxi Chan

Accurate stock market predictions following earnings reports are crucial for
investors. Traditional methods, particularly classical machine learning models,
struggle with these predictions because they cannot effectively process and
interpret extensive textual data contained in earnings reports and often
overlook nuances that influence market movements. This paper introduces an
advanced approach by employing Large Language Models (LLMs) instruction
fine-tuned with a novel combination of instruction-based techniques and
quantized low-rank adaptation (QLoRA) compression. Our methodology integrates
'base factors', such as financial metric growth and earnings transcripts, with
'external factors', including recent market indices performances and analyst
grades, to create a rich, supervised dataset. This comprehensive dataset
enables our models to achieve superior predictive performance in terms of
accuracy, weighted F1, and Matthews correlation coefficient (MCC), especially
evident in the comparison with benchmarks such as GPT-4. We specifically
highlight the efficacy of the llama-3-8b-Instruct-4bit model, which showcases
significant improvements over baseline models. The paper also discusses the
potential of expanding the output capabilities to include a 'Hold' option and
extending the prediction horizon, aiming to accommodate various investment
styles and time frames. This study not only demonstrates the power of
integrating cutting-edge AI with fine-tuned financial data but also paves the
way for future research in enhancing AI-driven financial analysis tools.

摘要：對於投資人而言，在收益報告後進行準確的股市預測至關重要。傳統方法，特別是經典機器學習模型，在這些預測中面臨挑戰，因為它們無法有效處理和詮釋收益報告中包含的廣泛文字資料，並且常常忽略影響市場波動的細微差別。本文介紹一種先進的方法，採用大型語言模型 (LLM) 指令，並結合基於指令的技術和量化低秩適應 (QLoRA) 壓縮進行微調。我們的技術整合了「基本因素」，例如財務指標成長和收益紀錄，以及「外部因素」，包括近期市場指數表現和分析師評級，以建立一個豐富的監督式資料集。這個全面的資料集讓我們的模型在準確度、加權 F1 和馬修斯相關係數 (MCC) 方面，達到優異的預測效能，特別是在與 GPT-4 等基準進行比較時，更為明顯。我們特別強調 llama-3-8b-Instruct-4bit 模型的效能，它展示出比基準模型有顯著的進步。本文也探討了將輸出能力擴展到包含「持有」選項，並延伸預測範圍的可能性，旨在容納各種投資風格和時間框架。本研究不僅展示了整合尖端 AI 與微調財務資料的力量，也為未來增強 AI 驅動的財務分析工具的研究鋪路。

##### **EditScribe: Non-Visual Image Editing with Natural Language Verification Loops**
2408.06632v1 by Ruei-Che Chang, Yuxuan Liu, Lotus Zhang, Anhong Guo

Image editing is an iterative process that requires precise visual evaluation
and manipulation for the output to match the editing intent. However, current
image editing tools do not provide accessible interaction nor sufficient
feedback for blind and low vision individuals to achieve this level of control.
To address this, we developed EditScribe, a prototype system that makes image
editing accessible using natural language verification loops powered by large
multimodal models. Using EditScribe, the user first comprehends the image
content through initial general and object descriptions, then specifies edit
actions using open-ended natural language prompts. EditScribe performs the
image edit, and provides four types of verification feedback for the user to
verify the performed edit, including a summary of visual changes, AI judgement,
and updated general and object descriptions. The user can ask follow-up
questions to clarify and probe into the edits or verification feedback, before
performing another edit. In a study with ten blind or low-vision users, we
found that EditScribe supported participants to perform and verify image edit
actions non-visually. We observed different prompting strategies from
participants, and their perceptions on the various types of verification
feedback. Finally, we discuss the implications of leveraging natural language
verification loops to make visual authoring non-visually accessible.

摘要：影像編輯是一個反覆的過程，需要精準的視覺評估和操作，才能讓輸出結果符合編輯意圖。然而，現有的影像編輯工具無法提供無障礙的互動，也無法提供足夠的回饋，讓失明或視力低落的使用者達到這樣的控制水準。為了解決這個問題，我們開發了 EditScribe，一個原型系統，它利用大型多模態模型提供自然語言驗證迴圈，讓使用者可以無障礙地編輯影像。使用 EditScribe 時，使用者會先透過最初的一般描述和物件描述來理解影像內容，然後使用開放式的自然語言提示來指定編輯動作。EditScribe 會執行影像編輯，並提供四種類型的驗證回饋，讓使用者驗證已執行的編輯，包括視覺變化的摘要、AI 判斷，以及更新的一般描述和物件描述。使用者可以在執行另一項編輯之前，提出後續問題來釐清和探討編輯或驗證回饋。在與十位失明或視力低落的使用者進行的研究中，我們發現 EditScribe 能夠協助參與者非視覺地執行和驗證影像編輯動作。我們觀察到參與者不同的提示策略，以及他們對各種驗證回饋的看法。最後，我們討論了利用自然語言驗證迴圈來讓非視覺化創作無障礙的意涵。

##### **IFShip: A Large Vision-Language Model for Interpretable Fine-grained Ship Classification via Domain Knowledge-Enhanced Instruction Tuning**
2408.06631v1 by Mingning Guo, Mengwei Wu, Yuxiang Shen, Haifeng Li, Chao Tao

End-to-end interpretation is currently the prevailing paradigm for remote
sensing fine-grained ship classification (RS-FGSC) task. However, its inference
process is uninterpretable, leading to criticism as a black box model. To
address this issue, we propose a large vision-language model (LVLM) named
IFShip for interpretable fine-grained ship classification. Unlike traditional
methods, IFShip excels in interpretability by accurately conveying the
reasoning process of FGSC in natural language. Specifically, we first design a
domain knowledge-enhanced Chain-of-Thought (COT) prompt generation mechanism.
This mechanism is used to semi-automatically construct a task-specific
instruction-following dataset named TITANIC-FGS, which emulates human-like
logical decision-making. We then train the IFShip model using task instructions
tuned with the TITANIC-FGS dataset. Building on IFShip, we develop an FGSC
visual chatbot that redefines the FGSC problem as a step-by-step reasoning task
and conveys the reasoning process in natural language. Experimental results
reveal that the proposed method surpasses state-of-the-art FGSC algorithms in
both classification interpretability and accuracy. Moreover, compared to LVLMs
like LLaVA and MiniGPT-4, our approach demonstrates superior expertise in the
FGSC task. It provides an accurate chain of reasoning when fine-grained ship
types are recognizable to the human eye and offers interpretable explanations
when they are not.

摘要：<paragraph>端到端解譯目前是遙感精細船舶分類 (RS-FGSC) 任務的主流範例。然而，其推論過程無法解釋，因此被批評為黑盒子模型。為了解決這個問題，我們提出一個名為 IFShip 的大型視覺語言模型 (LVLM)，用於可解釋的精細船舶分類。與傳統方法不同，IFShip 在可解釋性方面表現出色，能夠準確地以自然語言傳達 FGSC 的推理過程。具體來說，我們首先設計了一個基於領域知識的思考鏈 (COT) 提示生成機制。此機制用於半自動地構建一個名為 TITANIC-FGS 的特定於任務的指令遵循資料集，模擬人類的邏輯決策制定。然後，我們使用使用 TITANIC-FGS 資料集調整的任務指令訓練 IFShip 模型。在 IFShip 的基礎上，我們開發了一個 FGSC 視覺聊天機器人，將 FGSC 問題重新定義為一個逐步推理任務，並以自然語言傳達推理過程。實驗結果表明，所提出的方法在分類可解釋性和準確性方面都超越了最先進的 FGSC 演算法。此外，與 LLaVA 和 MiniGPT-4 等 LVLM 相比，我們的做法在 FGSC 任務中表現出優異的專業知識。當精細的船舶類型對人眼可識別時，它會提供準確的推理鏈，並且當它們不可識別時，它會提供可解釋的解釋。</paragraph>

##### **WorldScribe: Towards Context-Aware Live Visual Descriptions**
2408.06627v1 by Ruei-Che Chang, Yuxuan Liu, Anhong Guo

Automated live visual descriptions can aid blind people in understanding
their surroundings with autonomy and independence. However, providing
descriptions that are rich, contextual, and just-in-time has been a
long-standing challenge in accessibility. In this work, we develop WorldScribe,
a system that generates automated live real-world visual descriptions that are
customizable and adaptive to users' contexts: (i) WorldScribe's descriptions
are tailored to users' intents and prioritized based on semantic relevance.
(ii) WorldScribe is adaptive to visual contexts, e.g., providing consecutively
succinct descriptions for dynamic scenes, while presenting longer and detailed
ones for stable settings. (iii) WorldScribe is adaptive to sound contexts,
e.g., increasing volume in noisy environments, or pausing when conversations
start. Powered by a suite of vision, language, and sound recognition models,
WorldScribe introduces a description generation pipeline that balances the
tradeoffs between their richness and latency to support real-time use. The
design of WorldScribe is informed by prior work on providing visual
descriptions and a formative study with blind participants. Our user study and
subsequent pipeline evaluation show that WorldScribe can provide real-time and
fairly accurate visual descriptions to facilitate environment understanding
that is adaptive and customized to users' contexts. Finally, we discuss the
implications and further steps toward making live visual descriptions more
context-aware and humanized.

摘要：自動化即時視覺描述可以幫助視障人士自主且獨立地了解周遭環境。然而，提供豐富、符合情境且即時的描述一直是無障礙的長期挑戰。在這項工作中，我們開發了 WorldScribe，一個系統用於產生自動化即時真實世界的視覺描述，這些描述可以自訂且適應使用者的情境：(i) WorldScribe 的描述會根據使用者的意圖進行調整，並根據語意關聯性進行優先排序。(ii) WorldScribe 適應視覺情境，例如，為動態場景提供連續簡潔的描述，同時為穩定的設定提供較長且詳細的描述。(iii) WorldScribe 適應聲音情境，例如，在吵雜的環境中增加音量，或在對話開始時暫停。WorldScribe 採用一套視覺、語言和聲音辨識模型，引入了描述產生流程，在豐富度和延遲之間取得平衡，以支援即時使用。WorldScribe 的設計是根據先前提供視覺描述的工作和與視障參與者的形成性研究而來的。我們的使用者研究和後續的流程評估顯示，WorldScribe 可以提供即時且相當準確的視覺描述，以促進環境理解，並適應和自訂使用者情境。最後，我們討論了影響和進一步的步驟，以使即時視覺描述更具情境感知和人性化。

##### **Towards Robust and Cost-Efficient Knowledge Unlearning for Large Language Models**
2408.06621v1 by Sungmin Cha, Sungjun Cho, Dasol Hwang, Moontae Lee

Large Language Models (LLMs) have demonstrated strong reasoning and
memorization capabilities via pretraining on massive textual corpora. However,
training LLMs on human-written text entails significant risk of privacy and
copyright violations, which demands an efficient machine unlearning framework
to remove knowledge of sensitive data without retraining the model from
scratch. While Gradient Ascent (GA) is widely used for unlearning by reducing
the likelihood of generating unwanted information, the unboundedness of
increasing the cross-entropy loss causes not only unstable optimization, but
also catastrophic forgetting of knowledge that needs to be retained. We also
discover its joint application under low-rank adaptation results in
significantly suboptimal computational cost vs. generative performance
trade-offs. In light of this limitation, we propose two novel techniques for
robust and cost-efficient unlearning on LLMs. We first design an Inverted Hinge
loss that suppresses unwanted tokens by increasing the probability of the next
most likely token, thereby retaining fluency and structure in language
generation. We also propose to initialize low-rank adapter weights based on
Fisher-weighted low-rank approximation, which induces faster unlearning and
better knowledge retention by allowing model updates to be focused on
parameters that are important in generating textual data we wish to remove.

摘要：大型語言模型 (LLM) 已透過大量文本語料庫的預訓練，展現強大的推理和記憶能力。然而，在人工撰寫的文字上訓練 LLM 會帶來隱私和版權侵犯的重大風險，這需要一個有效率的機器遺忘架構，才能移除敏感資料的知識，而無需從頭開始重新訓練模型。雖然梯度上升 (GA) 廣泛用於遺忘，方法是降低產生不需要資訊的可能性，但增加交叉熵損失的無界性不僅會導致不穩定的最佳化，還會導致需要保留的知識發生災難性遺忘。我們也發現它在低秩適應下的聯合應用會導致顯著次佳的運算成本與生成效能的權衡。有鑑於此限制，我們提出兩種針對 LLM 的強健且成本效益高的遺忘新技術。我們首先設計一個反向鉸鏈損失，透過增加下一個最可能記號的機率來抑制不需要的記號，從而保留語言產生中的流暢度和結構。我們也建議根據 Fisher 加權低秩近似來初始化低秩適配器權重，這透過讓模型更新集中在產生我們想要移除的文本資料中重要的參數上，來誘發更快速的遺忘和更好的知識保留。

##### **Generalized knowledge-enhanced framework for biomedical entity and relation extraction**
2408.06618v1 by Minh Nguyen, Phuong Le

In recent years, there has been an increasing number of frameworks developed
for biomedical entity and relation extraction. This research effort aims to
address the accelerating growth in biomedical publications and the intricate
nature of biomedical texts, which are written for mainly domain experts. To
handle these challenges, we develop a novel framework that utilizes external
knowledge to construct a task-independent and reusable background knowledge
graph for biomedical entity and relation extraction. The design of our model is
inspired by how humans learn domain-specific topics. In particular, humans
often first acquire the most basic and common knowledge regarding a field to
build the foundational knowledge and then use that as a basis for extending to
various specialized topics. Our framework employs such common-knowledge-sharing
mechanism to build a general neural-network knowledge graph that is learning
transferable to different domain-specific biomedical texts effectively.
Experimental evaluations demonstrate that our model, equipped with this
generalized and cross-transferable knowledge base, achieves competitive
performance benchmarks, including BioRelEx for binding interaction detection
and ADE for Adverse Drug Effect identification.

摘要：近年來，為生物醫學實體和關係萃取開發的框架數量不斷增加。這項研究工作旨在解決生物醫學出版物快速增長和生物醫學文本複雜的本質，這些文本主要是為領域專家撰寫的。為了應對這些挑戰，我們開發了一個新穎的框架，利用外部知識來構建一個與任務無關且可重複使用的背景知識圖，用於生物醫學實體和關係萃取。我們模型的設計靈感來自人類學習特定領域主題的方式。具體來說，人類通常會先獲取一個領域最基本和最常見的知識，以建立基礎知識，然後再以此為基礎擴展到各種專業主題。我們的框架採用這種常識共享機制來構建一個通用的神經網路知識圖，該知識圖可以有效地將學習成果轉移到不同的特定領域生物醫學文本。實驗評估表明，我們的模型配備了這個廣泛且可跨領域轉移的知識庫，在包括 BioRelEx（用於結合交互檢測）和 ADE（用於不良藥物反應識別）在內的競爭性效能基準中取得了成就。

##### **CROME: Cross-Modal Adapters for Efficient Multimodal LLM**
2408.06610v1 by Sayna Ebrahimi, Sercan O. Arik, Tejas Nama, Tomas Pfister

Multimodal Large Language Models (MLLMs) demonstrate remarkable
image-language capabilities, but their widespread use faces challenges in
cost-effective training and adaptation. Existing approaches often necessitate
expensive language model retraining and limited adaptability. Additionally, the
current focus on zero-shot performance improvements offers insufficient
guidance for task-specific tuning. We propose CROME, an efficient
vision-language instruction tuning framework. It features a novel gated
cross-modal adapter that effectively combines visual and textual
representations prior to input into a frozen LLM. This lightweight adapter,
trained with minimal parameters, enables efficient cross-modal understanding.
Notably, CROME demonstrates superior zero-shot performance on standard visual
question answering and instruction-following benchmarks. Moreover, it yields
fine-tuning with exceptional parameter efficiency, competing with task-specific
specialist state-of-the-art methods. CROME demonstrates the potential of pre-LM
alignment for building scalable, adaptable, and parameter-efficient multimodal
models.

摘要：多模態大型語言模型 (MLLM) 展示了非凡的影像語言能力，但其廣泛使用在成本效益訓練和適應方面面臨挑戰。現有方法通常需要昂貴的語言模型重新訓練和有限的適應性。此外，目前專注於零次學習效能提升，無法為特定任務調整提供足夠的指導。我們提出 CROME，一個高效的視覺語言指令調整架構。它具備一個創新的閘控跨模態適配器，在輸入凍結的 LLM 之前，有效地結合視覺和文字表徵。這個輕量級適配器以最少的參數進行訓練，實現高效的跨模態理解。值得注意的是，CROME 在標準視覺問答和指令遵循基準上展現出優異的零次學習效能。此外，它產生微調，具有出色的參數效率，與特定任務的專家最先進方法競爭。CROME 展示了預先語言模型對齊在建構可擴充、可適應且參數效率的多模態模型的潛力。

##### **Simple but Effective Compound Geometric Operations for Temporal Knowledge Graph Completion**
2408.06603v1 by Rui Ying, Mengting Hu, Jianfeng Wu, Yalan Xie, Xiaoyi Liu, Zhunheng Wang, Ming Jiang, Hang Gao, Linlin Zhang, Renhong Cheng

Temporal knowledge graph completion aims to infer the missing facts in
temporal knowledge graphs. Current approaches usually embed factual knowledge
into continuous vector space and apply geometric operations to learn potential
patterns in temporal knowledge graphs. However, these methods only adopt a
single operation, which may have limitations in capturing the complex temporal
dynamics present in temporal knowledge graphs. Therefore, we propose a simple
but effective method, i.e. TCompoundE, which is specially designed with two
geometric operations, including time-specific and relation-specific operations.
We provide mathematical proofs to demonstrate the ability of TCompoundE to
encode various relation patterns. Experimental results show that our proposed
model significantly outperforms existing temporal knowledge graph embedding
models. Our code is available at https://github.com/nk-ruiying/TCompoundE.

摘要：時序知識圖譜完成功能旨在推論時序知識圖譜中缺失的事實。目前的做法通常會將事實知識嵌入連續向量空間，並套用幾何運算來學習時序知識圖譜中的潛在模式。不過，這些方法僅採用單一運算，在擷取時序知識圖譜中存在的複雜時序動態時可能有限制。因此，我們提出一個簡單但有效的方法，即 TCompoundE，它特別設計了兩個幾何運算，包括特定時間和特定關係的運算。我們提供數學證明來展示 TCompoundE 編碼各種關係模式的能力。實驗結果顯示，我們提出的模型顯著優於現有的時序知識圖譜嵌入模型。我們的程式碼可在 https://github.com/nk-ruiying/TCompoundE 取得。

##### **A Perspective on Large Language Models, Intelligent Machines, and Knowledge Acquisition**
2408.06598v1 by Vladimir Cherkassky, Eng Hock Lee

Large Language Models (LLMs) are known for their remarkable ability to
generate synthesized 'knowledge', such as text documents, music, images, etc.
However, there is a huge gap between LLM's and human capabilities for
understanding abstract concepts and reasoning. We discuss these issues in a
larger philosophical context of human knowledge acquisition and the Turing
test. In addition, we illustrate the limitations of LLMs by analyzing GPT-4
responses to questions ranging from science and math to common sense reasoning.
These examples show that GPT-4 can often imitate human reasoning, even though
it lacks understanding. However, LLM responses are synthesized from a large LLM
model trained on all available data. In contrast, human understanding is based
on a small number of abstract concepts. Based on this distinction, we discuss
the impact of LLMs on acquisition of human knowledge and education.

摘要：大型語言模型 (LLM) 以其生成綜合「知識」的非凡能力而聞名，例如文字文件、音樂、圖像等。然而，在理解抽象概念和推理方面，LLM 與人類的能力之間存在著巨大的差距。我們在人類知識獲取和圖靈測試的更大哲學背景下探討這些問題。此外，我們透過分析 GPT-4 對從科學和數學到常識推理等問題的回應來說明 LLM 的局限性。這些範例顯示，即使 GPT-4 缺乏理解力，但它經常可以模仿人類的推理。然而，LLM 的回應是由一個訓練於所有可用資料上的大型 LLM 模型綜合而成的。相反地，人類的理解是基於少數抽象概念。根據這個區別，我們探討 LLM 對人類知識和教育獲取的影響。

##### **An Event Structure-aware Generative Model for Biomedical Event Extraction**
2408.06583v2 by Haohan Yuan, Siu Cheung Hui, Haopeng Zhang

Biomedical Event Extraction (BEE) is a challenging task that involves
modeling complex relationships between fine-grained entities in biomedical
text. Most existing BEE models rely on classification methods that ignore label
semantics and argument dependencies in the data. Although generative models
that use prompts are increasingly being used for event extraction, they face
two main challenges: creating effective prompts for the biomedical domain and
dealing with events with complex structures in the text. To address these
limitations, we propose GenBEE, a generative model enhanced with
structure-aware prefixes for biomedical event extraction. GenBEE constructs
event prompts that leverage knowledge distilled from large language models
(LLMs), thereby incorporating both label semantics and argument dependency
relationships. Additionally, GenBEE introduces a structural prefix learning
module that generates structure-aware prefixes with structural prompts,
enriching the generation process with structural features. Extensive
experiments on three benchmark datasets demonstrate the effectiveness of GenBEE
and it achieves state-of-the-art performance on the MLEE and GE11 datasets.
Moreover, our analysis shows that the structural prefixes effectively bridge
the gap between structural prompts and the representation space of generative
models, enabling better integration of event structural information.

摘要：生物医学事件抽取 (BEE) 是一項具有挑戰性的任務，它涉及
在生物醫學文本中對細粒度實體之間的複雜關係進行建模。大多數現有的 BEE 模型依賴於分類方法，而忽略了數據中的標籤語義和依賴關係。儘管使用提示的生成模型正越來越多地用於事件抽取，但它們面臨著兩個主要挑戰：為生物醫學領域創建有效的提示，以及處理文本中結構複雜的事件。為了解決這些限制，我們提出了 GenBEE，這是一種增強了結構感知前綴的生物醫學事件抽取生成模型。GenBEE 構建事件提示，利用從大型語言模型 (LLM) 中提取的知識，從而結合標籤語義和依賴關係。此外，GenBEE 引入了一個結構前綴學習模組，該模組使用結構提示生成結構感知前綴，並使用結構特徵豐富生成過程。在三個基準數據集上進行的廣泛實驗證明了 GenBEE 的有效性，並且它在 MLEE 和 GE11 數據集上實現了最先進的性能。此外，我們的分析表明，結構前綴有效地彌合了結構提示和生成模型的表示空間之間的差距，從而能夠更好地整合事件結構信息。

##### **OpenEP: Open-Ended Future Event Prediction**
2408.06578v2 by Yong Guan, Hao Peng, Xiaozhi Wang, Lei Hou, Juanzi Li

Future event prediction (FEP) is a long-standing and crucial task in the
world, as understanding the evolution of events enables early risk
identification, informed decision-making, and strategic planning. Existing work
typically treats event prediction as classification tasks and confines the
outcomes of future events to a fixed scope, such as yes/no questions, candidate
set, and taxonomy, which is difficult to include all possible outcomes of
future events. In this paper, we introduce OpenEP (an Open-Ended Future Event
Prediction task), which generates flexible and diverse predictions aligned with
real-world scenarios. This is mainly reflected in two aspects: firstly, the
predictive questions are diverse, covering different stages of event
development and perspectives; secondly, the outcomes are flexible, without
constraints on scope or format. To facilitate the study of this task, we
construct OpenEPBench, an open-ended future event prediction dataset. For
question construction, we pose questions from seven perspectives, including
location, time, event development, event outcome, event impact, event response,
and other, to facilitate an in-depth analysis and understanding of the
comprehensive evolution of events. For outcome construction, we collect
free-form text containing the outcomes as ground truth to provide semantically
complete and detail-enriched outcomes. Furthermore, we propose StkFEP, a
stakeholder-enhanced future event prediction framework, that incorporates event
characteristics for open-ended settings. Our method extracts stakeholders
involved in events to extend questions to gather diverse information. We also
collect historically events that are relevant and similar to the question to
reveal potential evolutionary patterns. Experiment results indicate that
accurately predicting future events in open-ended settings is challenging for
existing LLMs.

摘要：<paragraph>未來事件預測 (FEP) 是世界上長久以來至關重要的任務，因為了解事件的演變有助於早期識別風險、明智決策制定和策略規劃。現有研究通常將事件預測視為分類任務，並將未來事件的結果限制在固定範圍內，例如是非題、候選人集合和分類法，這很難涵蓋未來事件的所有可能結果。在本文中，我們介紹了 OpenEP（一種開放式未來事件預測任務），它會產生靈活且多樣化的預測，與現實世界的場景保持一致。這主要反映在兩個方面：首先，預測問題是多樣的，涵蓋了事件發展的不同階段和觀點；其次，結果是靈活的，不受範圍或格式的約束。為了促進這項任務的研究，我們構建了 OpenEPBench，一個開放式的未來事件預測數據集。對於問題構建，我們從七個角度提出問題，包括位置、時間、事件發展、事件結果、事件影響、事件應對和其他，以利於對事件的全面演變進行深入分析和理解。對於結果構建，我們收集包含結果的自由形式文本作為基本事實，以提供語義上完整且細節豐富的結果。此外，我們提出了 StkFEP，一個利益相關者增強的未來事件預測框架，它結合了開放式設置的事件特徵。我們的模型提取參與事件的利益相關者，以擴展問題以收集多樣化的信息。我們還收集與問題相關且類似的歷史事件，以揭示潛在的演化模式。實驗結果表明，在開放式設置中準確預測未來事件對現有的 LLM 來說具有挑戰性。</paragraph>

##### **CTISum: A New Benchmark Dataset For Cyber Threat Intelligence Summarization**
2408.06576v1 by Wei Peng, Junmei Ding, Wei Wang, Lei Cui, Wei Cai, Zhiyu Hao, Xiaochun Yun

Cyber Threat Intelligence (CTI) summarization task requires the system to
generate concise and accurate highlights from raw intelligence data, which
plays an important role in providing decision-makers with crucial information
to quickly detect and respond to cyber threats in the cybersecurity domain.
However, efficient techniques for summarizing CTI reports, including facts,
analytical insights, attack processes, etc., have largely been unexplored,
primarily due to the lack of available dataset. To this end, we present CTISum,
a new benchmark for CTI summarization task. Considering the importance of
attack process, a novel fine-grained subtask of attack process summarization is
proposed to enable defenders to assess risk, identify security gaps,
vulnerabilities, and so on. Specifically, we first design a multi-stage
annotation pipeline to gather and annotate the CTI data, and then benchmark the
CTISum with a collection of extractive and abstractive summarization methods.
Experimental results show that current state-of-the-art models exhibit
limitations when applied to CTISum, underscoring the fact that automatically
producing concise summaries of CTI reports remains an open research challenge.

摘要：網路威脅情報 (CTI) 摘要任務需要系統從原始情報資料產生簡潔且準確的重點，這在提供決策者關鍵資訊以快速偵測並回應網路安全領域中的網路威脅方面扮演重要角色。然而，有效摘要 CTI 報告（包括事實、分析見解、攻擊流程等）的技術在很大程度上仍未被探索，這主要是由於缺乏可用的資料集。為此，我們提出了 CTISum，一個 CTI 摘要任務的新基準。考量攻擊流程的重要性，我們提出了一個新穎的攻擊流程摘要細粒度子任務，讓防禦者能夠評估風險、找出安全漏洞、弱點等等。具體來說，我們首先設計了一個多階段註解管道來收集並註解 CTI 資料，然後使用一組萃取式和抽象式摘要方法來評量 CTISum。實驗結果顯示，當前的最先進模型在應用於 CTISum 時會出現限制，這強調了自動產生 CTI 報告的簡潔摘要仍然是一個開放的研究挑戰。

##### **SparkRA: A Retrieval-Augmented Knowledge Service System Based on Spark Large Language Model**
2408.06574v1 by Dayong Wu, Jiaqi Li, Baoxin Wang, Honghong Zhao, Siyuan Xue, Yanjie Yang, Zhijun Chang, Rui Zhang, Li Qian, Bo Wang, Shijin Wang, Zhixiong Zhang, Guoping Hu

Large language models (LLMs) have shown remarkable achievements across
various language tasks.To enhance the performance of LLMs in scientific
literature services, we developed the scientific literature LLM (SciLit-LLM)
through pre-training and supervised fine-tuning on scientific literature,
building upon the iFLYTEK Spark LLM. Furthermore, we present a knowledge
service system Spark Research Assistant (SparkRA) based on our SciLit-LLM.
SparkRA is accessible online and provides three primary functions: literature
investigation, paper reading, and academic writing. As of July 30, 2024,
SparkRA has garnered over 50,000 registered users, with a total usage count
exceeding 1.3 million.

摘要：大型語言模型 (LLM) 已在各種語言任務中展現出顯著的成就。為了增強 LLM 在科學文獻服務中的效能，我們透過預先訓練和在科學文獻上進行監督式微調，開發了科學文獻 LLM (SciLit-LLM)，並建立在 iFLYTEK Spark LLM 之上。此外，我們根據我們的 SciLit-LLM 提出了一種知識服務系統 Spark 研究助理 (SparkRA)。SparkRA 可在線上存取，並提供三項主要功能：文獻調查、論文閱讀和學術寫作。截至 2024 年 7 月 30 日，SparkRA 已累積超過 50,000 名註冊使用者，總使用次數超過 130 萬次。

##### **Social Debiasing for Fair Multi-modal LLMs**
2408.06569v1 by Harry Cheng, Yangyang Guo, Qingpei Guo, Ming Yang, Tian Gan, Liqiang Nie

Multi-modal Large Language Models (MLLMs) have advanced significantly,
offering powerful vision-language understanding capabilities. However, these
models often inherit severe social biases from their training datasets, leading
to unfair predictions based on attributes like race and gender. This paper
addresses the issue of social biases in MLLMs by i) Introducing a comprehensive
Counterfactual dataset with Multiple Social Concepts (CMSC), which provides a
more diverse and extensive training set compared to existing datasets. ii)
Proposing an Anti-Stereotype Debiasing strategy (ASD). Our method works by
revisiting the MLLM training process, rescaling the autoregressive loss
function, and improving data sampling methods to counteract biases. Through
extensive experiments on various MLLMs, our CMSC dataset and ASD method
demonstrate a significant reduction in social biases while maintaining the
models' original performance.

摘要：多模态大型语言模型 (MLLM) 已大幅进步，
提供强大的视觉语言理解能力。然而，这些
模型通常会从其训练数据集继承严重的社会偏见，导致
基于种族和性别等属性的不公平预测。本文
通过 i) 引入包含多种社会概念的反事实数据集 (CMSC) 来解决 MLLM 中的社会偏见问题，该数据集提供了一个
与现有数据集相比更丰富且更广泛的训练集。ii)
提出反刻板印象去偏策略 (ASD)。我们的方法通过
重新审视 MLLM 训练过程、重新调整自回归损失
函数以及改进数据采样方法来对抗偏见。通过
对各种 MLLM 进行广泛的实验，我们的 CMSC 数据集和 ASD 方法
证明了在保持模型原始性能的同时，社会偏见得到了显著减少。

##### **AquilaMoE: Efficient Training for MoE Models with Scale-Up and Scale-Out Strategies**
2408.06567v1 by Bo-Wen Zhang, Liangdong Wang, Ye Yuan, Jijie Li, Shuhao Gu, Mengdi Zhao, Xinya Wu, Guang Liu, Chengwei Wu, Hanyu Zhao, Li Du, Yiming Ju, Quanyue Ma, Yulong Ao, Yingli Zhao, Songhe Zhu, Zhou Cao, Dong Liang, Yonghua Lin, Ming Zhang, Shunfei Wang, Yanxin Zhou, Min Ye, Xuekai Chen, Xinyang Yu, Xiangjun Huang, Jian Yang

In recent years, with the rapid application of large language models across
various fields, the scale of these models has gradually increased, and the
resources required for their pre-training have grown exponentially. Training an
LLM from scratch will cost a lot of computation resources while scaling up from
a smaller model is a more efficient approach and has thus attracted significant
attention. In this paper, we present AquilaMoE, a cutting-edge bilingual 8*16B
Mixture of Experts (MoE) language model that has 8 experts with 16 billion
parameters each and is developed using an innovative training methodology
called EfficientScale. This approach optimizes performance while minimizing
data requirements through a two-stage process. The first stage, termed
Scale-Up, initializes the larger model with weights from a pre-trained smaller
model, enabling substantial knowledge transfer and continuous pretraining with
significantly less data. The second stage, Scale-Out, uses a pre-trained dense
model to initialize the MoE experts, further enhancing knowledge transfer and
performance. Extensive validation experiments on 1.8B and 7B models compared
various initialization schemes, achieving models that maintain and reduce loss
during continuous pretraining. Utilizing the optimal scheme, we successfully
trained a 16B model and subsequently the 8*16B AquilaMoE model, demonstrating
significant improvements in performance and training efficiency.

摘要：近年来，随着大型语言模型在各个领域的快速应用，这些模型的规模逐渐增大，其预训练所需资源呈指数级增长。从头开始训练 LLM 将花费大量的计算资源，而从小模型扩展是一种更有效的方法，因此引起了极大的关注。在本文中，我们提出了 AquilaMoE，这是一种先进的双语 8*16B 专家混合 (MoE) 语言模型，它有 8 个专家，每个专家有 160 亿个参数，并且是使用称为 EfficientScale 的创新训练方法开发的。这种方法通过两阶段过程优化性能，同时最大程度地减少数据需求。第一阶段称为 Scale-Up，它使用预训练较小模型中的权重初始化较大的模型，从而实现实质性的知识转移和持续预训练，所需数据明显更少。第二阶段 Scale-Out 使用预训练的密集模型来初始化 MoE 专家，进一步增强知识转移和性能。对 1.8B 和 7B 模型进行的广泛验证实验比较了各种初始化方案，实现了在持续预训练期间保持和减少损失的模型。利用最优方案，我们成功训练了一个 16B 模型，随后训练了 8*16B AquilaMoE 模型，展示了性能和训练效率的显著提升。

##### **HDRGS: High Dynamic Range Gaussian Splatting**
2408.06543v1 by Jiahao Wu, Lu Xiao, Chao Wang, Rui Peng, Kaiqiang Xiong, Ronggang Wang

Recent years have witnessed substantial advancements in the field of 3D
reconstruction from 2D images, particularly following the introduction of the
neural radiance field (NeRF) technique. However, reconstructing a 3D high
dynamic range (HDR) radiance field, which aligns more closely with real-world
conditions, from 2D multi-exposure low dynamic range (LDR) images continues to
pose significant challenges. Approaches to this issue fall into two categories:
grid-based and implicit-based. Implicit methods, using multi-layer perceptrons
(MLP), face inefficiencies, limited solvability, and overfitting risks.
Conversely, grid-based methods require significant memory and struggle with
image quality and long training times. In this paper, we introduce Gaussian
Splatting-a recent, high-quality, real-time 3D reconstruction technique-into
this domain. We further develop the High Dynamic Range Gaussian Splatting
(HDR-GS) method, designed to address the aforementioned challenges. This method
enhances color dimensionality by including luminance and uses an asymmetric
grid for tone-mapping, swiftly and precisely converting pixel irradiance to
color. Our approach improves HDR scene recovery accuracy and integrates a novel
coarse-to-fine strategy to speed up model convergence, enhancing robustness
against sparse viewpoints and exposure extremes, and preventing local optima.
Extensive testing confirms that our method surpasses current state-of-the-art
techniques in both synthetic and real-world scenarios. Code will be released at
\url{https://github.com/WuJH2001/HDRGS}

摘要：近年來，在神經輻照場 (NeRF) 技術問世後，特別是從 2D 影像進行 3D 重建的領域中，見證了顯著的進展。然而，從 2D 多重曝光低動態範圍 (LDR) 影像重建一個與真實世界條件更為貼近的 3D 高動態範圍 (HDR) 輻照場，持續對我們構成重大的挑戰。針對此問題的方法可分為兩類：基於網格和基於隱式的。使用多層感知器 (MLP) 的隱式方法，會面臨效率低落、可解性受限和過度擬合的風險。反之，基於網格的方法需要大量的記憶體，且在影像品質和漫長的訓練時間上有所掙扎。在本文中，我們將 Gaussian Splatting（一種最近的高品質即時 3D 重建技術）引入此領域。我們進一步開發了高動態範圍 Gaussian Splatting (HDR-GS) 方法，旨在解決上述挑戰。此方法透過納入亮度來增強色彩維度，並使用非對稱網格進行色調對應，快速且精確地將像素輻照度轉換為色彩。我們的方法改善了 HDR 場景還原的準確度，並整合了一種新穎的由粗到精策略，以加速模型收斂，增強對稀疏視點和曝光極值的穩健性，並防止局部最優。廣泛的測試證實，我們的技術在合成和真實世界的場景中都超越了目前最先進的技術。程式碼將在 \url{https://github.com/WuJH2001/HDRGS} 發布

##### **Dynamic Exclusion of Low-Fidelity Data in Bayesian Optimization for Autonomous Beamline Alignment**
2408.06540v1 by Megha R. Narayanan, Thomas W. Morris

Aligning beamlines at synchrotron light sources is a high-dimensional,
expensive-to-sample optimization problem, as beams are focused using a series
of dynamic optical components. Bayesian Optimization is an efficient machine
learning approach to finding global optima of beam quality, but the model can
easily be impaired by faulty data points caused by the beam going off the edge
of the sensor or by background noise. This study, conducted at the National
Synchrotron Light Source II (NSLS-II) facility at Brookhaven National
Laboratory (BNL), is an investigation of methods to identify untrustworthy
readings of beam quality and discourage the optimization model from seeking out
points likely to yield low-fidelity beams. The approaches explored include
dynamic pruning using loss analysis of size and position models and a
lengthscale-based genetic algorithm to determine which points to include in the
model for optimal fit. Each method successfully classified high and low
fidelity points. This research advances BNL's mission to tackle our nation's
energy challenges by providing scientists at all beamlines with access to
higher quality beams, and faster convergence to these optima for their
experiments.

摘要：同步加速器光源中的光束线对齐是一个高维度、取样成本高昂的优化问题，因为光束是使用一系列动态光学组件聚焦的。贝叶斯优化是一种有效的机器学习方法，用于寻找光束质量的全局最优值，但是该模型很容易受到光束超出传感器边缘或背景噪声造成的有故障数据点的损害。这项研究是在布鲁克海文国家实验室 (BNL) 的国家同步加速器光源 II (NSLS-II) 设施进行的，是对识别不可靠光束质量读数和阻止优化模型寻找可能产生低保真光束的点的方法的研究。探索的方法包括使用尺寸和位置模型的损失分析进行动态剪枝，以及基于长度尺度的遗传算法，以确定哪些点应包含在模型中以获得最佳拟合。每种方法都成功地对高保真和低保真点进行了分类。这项研究促进了 BNL 解决我们国家能源挑战的使命，为所有光束线的科学家提供了更高质量光束的访问权限，并更快地收敛到这些最优值以进行他们的实验。

##### **Introducing the NewsPaLM MBR and QE Dataset: LLM-Generated High-Quality Parallel Data Outperforms Traditional Web-Crawled Data**
2408.06537v1 by Mara Finkelstein, David Vilar, Markus Freitag

Recent research in neural machine translation (NMT) has shown that training
on high-quality machine-generated data can outperform training on
human-generated data. This work accompanies the first-ever release of a
LLM-generated, MBR-decoded and QE-reranked dataset with both sentence-level and
multi-sentence examples. We perform extensive experiments to demonstrate the
quality of our dataset in terms of its downstream impact on NMT model
performance. We find that training from scratch on our (machine-generated)
dataset outperforms training on the (web-crawled) WMT'23 training dataset
(which is 300 times larger), and also outperforms training on the top-quality
subset of the WMT'23 training dataset. We also find that performing
self-distillation by finetuning the LLM which generated this dataset
outperforms the LLM's strong few-shot baseline. These findings corroborate the
quality of our dataset, and demonstrate the value of high-quality
machine-generated data in improving performance of NMT models.

摘要：最近的神经机器翻译 (NMT) 研究表明，在高质量机器生成的数据上进行训练可以优于在人工生成的数据上进行训练。这项工作伴随着首次发布 LLM 生成的、MBR 解码的和 QE 重新排名的数据集，其中包含句子级和多句子示例。我们进行了广泛的实验，以展示我们数据集的质量，就其对 NMT 模型性能的下游影响而言。我们发现，从头开始在我们的（机器生成的）数据集上进行训练优于在（网络爬取的）WMT'23 训练数据集（大 300 倍）上进行训练，并且也优于在 WMT'23 训练数据集的顶级子集上进行训练。我们还发现，通过微调生成此数据集的 LLM 来执行自蒸馏优于 LLM 的强少数镜头基线。这些发现证实了我们数据集的质量，并展示了高质量机器生成数据在提高 NMT 模型性能方面的价值。

##### **Chain-of-Strategy Planning with LLMs: Aligning the Generation of Psychotherapy Dialogue with Strategy in Motivational Interviewing**
2408.06527v1 by Xin Sun, Xiao Tang, Abdallah El Ali, Zhuying Li, Xiaoyu Shen, Pengjie Ren, Jan de Wit, Jiahuan Pei, Jos A. Bosch

Recent advancements in large language models (LLMs) have shown promise in
generating psychotherapeutic dialogues, especially in Motivational Interviewing
(MI). However, how to employ strategies, a set of motivational interviewing
(MI) skills, to generate therapeutic-adherent conversations with explainability
is underexplored. We propose an approach called strategy-aware dialogue
generation with Chain-of-Strategy (CoS) planning, which first predicts MI
strategies as reasoning and utilizes these strategies to guide the subsequent
dialogue generation. It brings the potential for controllable and explainable
generation in psychotherapy by aligning the generated MI dialogues with
therapeutic strategies. Extensive experiments including automatic and human
evaluations are conducted to validate the effectiveness of the MI strategy. Our
findings demonstrate the potential of LLMs in producing strategically aligned
dialogues and suggest directions for practical applications in
psychotherapeutic settings.

摘要：大型語言模型 (LLM) 的最新進展已顯示出在產生心理治療對話方面的前景，特別是在動機性訪談 (MI) 中。然而，如何運用策略（一組動機性訪談 (MI) 技能）來產生具有解釋性的治療性對話尚未得到充分探討。我們提出了一種稱為策略感知對話生成的方法，採用策略鏈 (CoS) 規劃，該方法首先預測 MI 策略作為推理，並利用這些策略來指導後續的對話生成。它通過將生成的 MI 對話與治療策略保持一致，帶來了心理治療中可控且可解釋的生成潛力。進行了包括自動和人工評估在內的廣泛實驗，以驗證 MI 策略的有效性。我們的研究結果證明了 LLM 在產生策略一致對話方面的潛力，並提出了心理治療環境中實際應用的方向。

##### **Hierarchical in-Context Reinforcement Learning with Hindsight Modular Reflections for Planning**
2408.06520v1 by Chuanneng Sun, Songjun Huang, Dario Pompili

Large Language Models (LLMs) have demonstrated remarkable abilities in
various language tasks, making them promising candidates for decision-making in
robotics. Inspired by Hierarchical Reinforcement Learning (HRL), we propose
Hierarchical in-Context Reinforcement Learning (HCRL), a novel framework that
decomposes complex tasks into sub-tasks using an LLM-based high-level policy,
in which a complex task is decomposed into sub-tasks by a high-level policy
on-the-fly. The sub-tasks, defined by goals, are assigned to the low-level
policy to complete. Once the LLM agent determines that the goal is finished, a
new goal will be proposed. To improve the agent's performance in multi-episode
execution, we propose Hindsight Modular Reflection (HMR), where, instead of
reflecting on the full trajectory, we replace the task objective with
intermediate goals and let the agent reflect on shorter trajectories to improve
reflection efficiency. We evaluate the decision-making ability of the proposed
HCRL in three benchmark environments--ALFWorld, Webshop, and HotpotQA. Results
show that HCRL can achieve 9%, 42%, and 10% performance improvement in 5
episodes of execution over strong in-context learning baselines.

摘要：大型語言模型 (LLM) 在各種語言任務中展現出非凡的能力，使其成為機器人決策的潛在候選者。受分層強化學習 (HRL) 的啟發，我們提出分層情境強化學習 (HCRL)，這是一種新穎的框架，它使用基於 LLM 的高階政策將複雜任務分解為子任務，其中複雜任務由高階政策即時分解為子任務。由目標定義的子任務被分配給低階政策以完成。一旦 LLM 代理確定目標已完成，將提出一個新目標。為了提高代理在多情境執行中的表現，我們提出回顧性模組化反思 (HMR)，其中，我們用中間目標取代任務目標，並讓代理回顧較短的軌跡以提高反思效率，而不是回顧完整的軌跡。我們在三個基準環境中評估了所提出的 HCRL 的決策能力——ALFWorld、Webshop 和 HotpotQA。結果顯示，HCRL 在 5 個執行情境中，相較於強大的情境學習基準，可以將效能提升 9%、42% 和 10%。

##### **Does Liking Yellow Imply Driving a School Bus? Semantic Leakage in Language Models**
2408.06518v1 by Hila Gonen, Terra Blevins, Alisa Liu, Luke Zettlemoyer, Noah A. Smith

Despite their wide adoption, the biases and unintended behaviors of language
models remain poorly understood. In this paper, we identify and characterize a
phenomenon never discussed before, which we call semantic leakage, where models
leak irrelevant information from the prompt into the generation in unexpected
ways. We propose an evaluation setting to detect semantic leakage both by
humans and automatically, curate a diverse test suite for diagnosing this
behavior, and measure significant semantic leakage in 13 flagship models. We
also show that models exhibit semantic leakage in languages besides English and
across different settings and generation scenarios. This discovery highlights
yet another type of bias in language models that affects their generation
patterns and behavior.

摘要：儘管語言模型被廣泛採用，但其偏見和無意的行為仍鮮為人知。在本文中，我們找出並描述了一個前所未有的現象，我們稱之為語義洩漏，其中模型會以出乎意料的方式將提示中的無關資訊洩漏到生成中。我們提出一個評估設定，以透過人工和自動方式偵測語義洩漏，策劃一個多元的測試套件來診斷此行為，並在 13 個旗艦模型中測量出顯著的語義洩漏。我們也顯示出，模型會在英語以外的語言以及不同的設定和生成場景中展現語義洩漏。這項發現突顯了語言模型中另一種會影響其生成模式和行為的偏見。

##### **Learned Ranking Function: From Short-term Behavior Predictions to Long-term User Satisfaction**
2408.06512v1 by Yi Wu, Daryl Chang, Jennifer She, Zhe Zhao, Li Wei, Lukasz Heldt

We present the Learned Ranking Function (LRF), a system that takes short-term
user-item behavior predictions as input and outputs a slate of recommendations
that directly optimizes for long-term user satisfaction. Most previous work is
based on optimizing the hyperparameters of a heuristic function. We propose to
model the problem directly as a slate optimization problem with the objective
of maximizing long-term user satisfaction. We also develop a novel constraint
optimization algorithm that stabilizes objective trade-offs for multi-objective
optimization. We evaluate our approach with live experiments and describe its
deployment on YouTube.

摘要：我們提出了學習排名函數 (LRF)，這是一個系統，它接收短期使用者-項目行為預測作為輸入，並輸出一個推薦清單，直接針對長期使用者滿意度進行最佳化。大多數先前的研究都基於最佳化啟發式函數的超參數。我們提議將問題直接建模為一個清單最佳化問題，目標是最大化長期使用者滿意度。我們還開發了一種新穎的約束最佳化演算法，用於穩定多目標最佳化的目標權衡。我們透過實時實驗評估我們的做法，並說明它在 YouTube 上的部署。

##### **Fooling SHAP with Output Shuffling Attacks**
2408.06509v1 by Jun Yuan, Aritra Dasgupta

Explainable AI~(XAI) methods such as SHAP can help discover feature
attributions in black-box models. If the method reveals a significant
attribution from a ``protected feature'' (e.g., gender, race) on the model
output, the model is considered unfair. However, adversarial attacks can
subvert the detection of XAI methods. Previous approaches to constructing such
an adversarial model require access to underlying data distribution, which may
not be possible in many practical scenarios. We relax this constraint and
propose a novel family of attacks, called shuffling attacks, that are
data-agnostic. The proposed attack strategies can adapt any trained machine
learning model to fool Shapley value-based explanations. We prove that Shapley
values cannot detect shuffling attacks. However, algorithms that estimate
Shapley values, such as linear SHAP and SHAP, can detect these attacks with
varying degrees of effectiveness. We demonstrate the efficacy of the attack
strategies by comparing the performance of linear SHAP and SHAP using
real-world datasets.

摘要：可解釋人工智慧 (XAI) 方法（例如 SHAP）有助於找出黑盒模型中的特徵歸因。如果該方法揭露模型輸出中來自「受保護特徵」（例如性別、種族）的顯著歸因，則該模型被視為不公平。然而，對抗攻擊可以破壞 XAI 方法的偵測。先前建構此類對抗模型的方法需要存取基礎資料分佈，這在許多實際情況中可能無法實現。我們放寬此限制，並提出了一系列稱為改組攻擊的新型攻擊，它們與資料無關。提出的攻擊策略可以調整任何訓練好的機器學習模型，以欺騙基於 Shapley 值的解釋。我們證明 Shapley 值無法偵測改組攻擊。然而，估計 Shapley 值的演算法，例如線性 SHAP 和 SHAP，可以偵測到這些攻擊，其有效性程度不一。我們透過比較線性 SHAP 和 SHAP 在使用真實世界資料集時的效能，來證明攻擊策略的效力。

##### **Benchmarking tree species classification from proximally-sensed laser scanning data: introducing the FOR-species20K dataset**
2408.06507v1 by Stefano Puliti, Emily R. Lines, Jana Müllerová, Julian Frey, Zoe Schindler, Adrian Straker, Matthew J. Allen, Lukas Winiwarter, Nataliia Rehush, Hristina Hristova, Brent Murray, Kim Calders, Louise Terryn, Nicholas Coops, Bernhard Höfle, Samuli Junttila, Martin Krůček, Grzegorz Krok, Kamil Král, Shaun R. Levick, Linda Luck, Azim Missarov, Martin Mokroš, Harry J. F. Owen, Krzysztof Stereńczak, Timo P. Pitkänen, Nicola Puletti, Ninni Saarinen, Chris Hopkinson, Chiara Torresan, Enrico Tomelleri, Hannah Weiser, Rasmus Astrup

Proximally-sensed laser scanning offers significant potential for automated
forest data capture, but challenges remain in automatically identifying tree
species without additional ground data. Deep learning (DL) shows promise for
automation, yet progress is slowed by the lack of large, diverse, openly
available labeled datasets of single tree point clouds. This has impacted the
robustness of DL models and the ability to establish best practices for species
classification.
  To overcome these challenges, the FOR-species20K benchmark dataset was
created, comprising over 20,000 tree point clouds from 33 species, captured
using terrestrial (TLS), mobile (MLS), and drone laser scanning (ULS) across
various European forests, with some data from other regions. This dataset
enables the benchmarking of DL models for tree species classification,
including both point cloud-based (PointNet++, MinkNet, MLP-Mixer, DGCNNs) and
multi-view image-based methods (SimpleView, DetailView, YOLOv5).
  2D image-based models generally performed better (average OA = 0.77) than 3D
point cloud-based models (average OA = 0.72), with consistent results across
different scanning platforms and sensors. The top model, DetailView, was
particularly robust, handling data imbalances well and generalizing effectively
across tree sizes.
  The FOR-species20K dataset, available at https://zenodo.org/records/13255198,
is a key resource for developing and benchmarking DL models for tree species
classification using laser scanning data, providing a foundation for future
advancements in the field.

摘要：<paragraph>近距離感測雷射掃描在自動化森林資料擷取方面具有顯著的潛力，但仍有挑戰在於自動識別樹種，而不需額外的地面資料。深度學習 (DL) 顯示出自動化的希望，但由於缺乏大型、多樣化、公開可用的單棵樹點雲標籤資料集，進度緩慢。這影響了 DL 模型的穩健性，以及建立物種分類最佳實務的能力。
為了克服這些挑戰，FOR-species20K 基準資料集應運而生，包含來自 33 個物種的 20,000 多棵樹點雲，使用地面 (TLS)、行動 (MLS) 和無人機雷射掃描 (ULS) 在各種歐洲森林中擷取，並包含來自其他地區的一些資料。此資料集能對樹種分類的 DL 模型進行基準測試，包括基於點雲的方法 (PointNet++、MinkNet、MLP-Mixer、DGCNN) 和基於多視圖影像的方法 (SimpleView、DetailView、YOLOv5)。
2D 影像式模型通常表現得比 3D 點雲式模型更好 (平均 OA = 0.77) (平均 OA = 0.72)，在不同的掃描平台和感測器中都有相符的結果。表現最佳的模型 DetailView 特別穩健，能妥善處理資料不平衡，並有效概括各種樹木大小。
FOR-species20K 資料集可在 https://zenodo.org/records/13255198 取得，是使用雷射掃描資料進行樹種分類的 DL 模型開發和基準測試的重要資源，為該領域的未來進展奠定基礎。</paragraph>

##### **Decentralized Cooperation in Heterogeneous Multi-Agent Reinforcement Learning via Graph Neural Network-Based Intrinsic Motivation**
2408.06503v1 by Jahir Sadik Monon, Deeparghya Dutta Barua, Md. Mosaddek Khan

Multi-agent Reinforcement Learning (MARL) is emerging as a key framework for
various sequential decision-making and control tasks. Unlike their single-agent
counterparts, multi-agent systems necessitate successful cooperation among the
agents. The deployment of these systems in real-world scenarios often requires
decentralized training, a diverse set of agents, and learning from infrequent
environmental reward signals. These challenges become more pronounced under
partial observability and the lack of prior knowledge about agent
heterogeneity. While notable studies use intrinsic motivation (IM) to address
reward sparsity or cooperation in decentralized settings, those dealing with
heterogeneity typically assume centralized training, parameter sharing, and
agent indexing. To overcome these limitations, we propose the CoHet algorithm,
which utilizes a novel Graph Neural Network (GNN) based intrinsic motivation to
facilitate the learning of heterogeneous agent policies in decentralized
settings, under the challenges of partial observability and reward sparsity.
Evaluation of CoHet in the Multi-agent Particle Environment (MPE) and
Vectorized Multi-Agent Simulator (VMAS) benchmarks demonstrates superior
performance compared to the state-of-the-art in a range of cooperative
multi-agent scenarios. Our research is supplemented by an analysis of the
impact of the agent dynamics model on the intrinsic motivation module, insights
into the performance of different CoHet variants, and its robustness to an
increasing number of heterogeneous agents.

摘要：多智能體強化學習 (MARL) 正成為各種順序決策和控制任務的關鍵框架。與單一智能體不同，多智能體系統需要智能體之間的成功合作。在現實世界中部署這些系統通常需要分散式訓練、多樣化的智能體，以及從不頻繁的環境獎勵信號中學習。在部分可觀察性和缺乏關於智能體異質性的先驗知識的情況下，這些挑戰變得更加明顯。雖然著名的研究使用內在動機 (IM) 來解決分散式環境中的獎勵稀疏性或合作，但處理異質性的研究通常假設集中式訓練、參數共享和智能體索引。為了克服這些限制，我們提出了 CoHet 演算法，該演算法利用基於圖神經網路 (GNN) 的新穎內在動機，在部分可觀察性和獎勵稀疏性的挑戰下，促進在分散式環境中學習異質智能體策略。在多智能體粒子環境 (MPE) 和向量化多智能體模擬器 (VMAS) 基準測試中對 CoHet 的評估顯示，與各種合作多智能體場景中的最新技術相比，其效能優異。我們的研究補充了對智能體動態模型對內在動機模組的影響的分析、對不同 CoHet 變體效能的見解，以及其對越來越多的異質智能體的穩健性。

##### **Cross-Lingual Conversational Speech Summarization with Large Language Models**
2408.06484v1 by Max Nelson, Shannon Wotherspoon, Francis Keith, William Hartmann, Matthew Snover

Cross-lingual conversational speech summarization is an important problem,
but suffers from a dearth of resources. While transcriptions exist for a number
of languages, translated conversational speech is rare and datasets containing
summaries are non-existent. We build upon the existing Fisher and Callhome
Spanish-English Speech Translation corpus by supplementing the translations
with summaries. The summaries are generated using GPT-4 from the reference
translations and are treated as ground truth. The task is to generate similar
summaries in the presence of transcription and translation errors. We build a
baseline cascade-based system using open-source speech recognition and machine
translation models. We test a range of LLMs for summarization and analyze the
impact of transcription and translation errors. Adapting the Mistral-7B model
for this task performs significantly better than off-the-shelf models and
matches the performance of GPT-4.

摘要：跨語言對話式語音摘要是一個重要的問題，
但缺乏資源。雖然許多語言都有轉錄，
但翻譯過的對話式語音很少，而且包含摘要的資料集並不存在。我們建立在現有的 Fisher 和 Callhome 西班牙文-英文語音翻譯語料庫上，並補充摘要作為翻譯。摘要是使用 GPT-4 從參考翻譯中產生的，並被視為真實情況。任務是在轉錄和翻譯錯誤的情況下產生類似的摘要。我們使用開源語音辨識和機器翻譯模型建立基準層疊式系統。我們測試了一系列 LLM 以進行摘要，並分析轉錄和翻譯錯誤的影響。調整 Mistral-7B 模型以執行此任務的表現顯著優於現成的模型，
並與 GPT-4 的表現相符。

##### **TOGGL: Transcribing Overlapping Speech with Staggered Labeling**
2408.06474v1 by Chak-Fai Li, William Hartmann, Matthew Snover

Transcribing the speech of multiple overlapping speakers typically requires
separating the audio into multiple streams and recognizing each one
independently. More recent work jointly separates and transcribes, but requires
a separate decoding component for each speaker. We propose the TOGGL model to
simultaneously transcribe the speech of multiple speakers. The TOGGL model uses
special output tokens to attribute the speech to each speaker with only a
single decoder. Our approach generalizes beyond two speakers, even when trained
only on two-speaker data. We demonstrate superior performance compared to
competing approaches on a conversational speech dataset. Our approach also
improves performance on single-speaker audio.

摘要：轉錄多個重疊說話者的語音通常需要將音訊分為多個串流，並獨立辨識每個串流。最近的研究同時進行分流和轉錄，但每個說話者都需要一個獨立的解碼元件。我們提出 TOGGL 模型，用於同時轉錄多個說話者的語音。TOGGL 模型使用特殊的輸出代碼，僅使用一個解碼器就能將語音歸因於每個說話者。我們的做法不僅適用於兩個以上的說話者，即使僅針對兩個說話者的資料進行訓練也是如此。我們在對話式語音資料集上展示出優於競爭方法的卓越效能。我們的做法也提升了針對單一說話者音訊的效能。

##### **Towards Autonomous Agents: Adaptive-planning, Reasoning, and Acting in Language Models**
2408.06458v1 by Yen-Che Hsiao, Abhishek Dutta

We propose a novel in-context learning algorithm for building autonomous
decision-making language agents. The language agent continuously attempts to
solve the same task by self-correcting each time the task fails. Our selected
language agent demonstrates the ability to solve tasks in a text-based game
environment. Our results show that the gemma-2-9b-it language model, using our
proposed method, can successfully complete two of six tasks that failed in the
first attempt. This highlights the effectiveness of our approach in enhancing
the problem-solving capabilities of a single language model through
self-correction, paving the way for more advanced autonomous agents. The code
is publicly available at
https://github.com/YenCheHsiao/AutonomousLLMAgentwithAdaptingPlanning.

摘要：我們提出了一種新的情境學習演算法，用於建構自主決策語言代理。語言代理不斷嘗試解決相同的任務，每次任務失敗時自我修正。我們選定的語言代理展示了解決文字遊戲環境中任務的能力。我們的結果顯示，gemma-2-9b-it 語言模型使用我們提出的方法，可以在第一次嘗試失敗的六個任務中成功完成兩個任務。這突顯了我們的方法在透過自我修正來增強單一語言模型的解決問題能力的有效性，為更進階的自主代理鋪路。程式碼已公開於 https://github.com/YenCheHsiao/AutonomousLLMAgentwithAdaptingPlanning。

##### **Evaluating Language Models for Efficient Code Generation**
2408.06450v1 by Jiawei Liu, Songrun Xie, Junhao Wang, Yuxiang Wei, Yifeng Ding, Lingming Zhang

We introduce Differential Performance Evaluation (DPE), a framework designed
to reliably evaluate Large Language Models (LLMs) for efficient code
generation. Traditional coding benchmarks often fail to provide reliable
insights into code efficiency, due to their reliance on simplistic test inputs
and the absence of effective compound metrics. DPE addresses these issues by
focusing on efficiency-demanding programming tasks and establishing an
insightful compound metric for performance evaluation. DPE operates in two
phases: To curate efficiency datasets, it selects efficiency-demanding tasks
from existing coding benchmarks and generates computationally expensive inputs
to stress the efficiency of LLM solutions. To assess the code efficiency, DPE
profiles the new solution and compares it globally against a set of reference
solutions that exhibit distinct efficiency levels, where the matched level
defines its efficiency score. As a proof of concept, we use DPE to create
EvalPerf, a benchmark with 121 performance-challenging coding tasks. Our
comprehensive evaluation draws interesting findings on the efficiency impact of
model sizes, instruction tuning, and prompting. For example, while the scaling
law fails to account for code efficiency, general instruction tuning benefits
both code correctness and efficiency. We also evaluate the evaluation by
examining the effectiveness of DPE, showing that EvalPerf is reliable and
convenient to use even across platforms.

摘要：<paragraph>我們介紹了差異化效能評估 (DPE)，一個旨在可靠評估大型語言模型 (LLM) 的架構，以進行高效的程式碼生成。傳統的編碼基準通常無法提供程式碼效率的可靠見解，因為它們依賴於簡化的測試輸入，而且缺乏有效的複合指標。DPE 透過專注於要求效率的程式設計任務，並為效能評估建立一個有見地的複合指標，來解決這些問題。DPE 分兩個階段操作：為了整理效率資料集，它從現有的編碼基準中選出要求效率的任務，並產生計算成本昂貴的輸入，以強調 LLM 解決方案的效率。為了評估程式碼效率，DPE 會分析新的解決方案，並在全球範圍內將其與一組展現不同效率層級的參考解決方案進行比較，其中匹配的層級定義其效率分數。作為概念證明，我們使用 DPE 來建立 EvalPerf，一個包含 121 個效能挑戰編碼任務的基準。我們的全面評估對模型大小、指令調整和提示的效率影響得出了有趣的發現。例如，雖然規模定律無法說明程式碼效率，但一般的指令調整對程式碼正確性和效率都有好處。我們也透過檢視 DPE 的有效性來評估評估，顯示 EvalPerf 可靠且易於使用，即使跨平台也是如此。</paragraph>

##### **Multi-View Neural Differential Equations for Continuous-Time Stream Data in Long-Term Traffic Forecasting**
2408.06445v1 by Zibo Liu, Zhe Jiang, Shigang Chen

Long-term traffic flow forecasting plays a crucial role in intelligent
transportation as it allows traffic managers to adjust their decisions in
advance. However, the problem is challenging due to spatio-temporal
correlations and complex dynamic patterns in continuous-time stream data.
Neural Differential Equations (NDEs) are among the state-of-the-art methods for
learning continuous-time traffic dynamics. However, the traditional NDE models
face issues in long-term traffic forecasting due to failures in capturing
delayed traffic patterns, dynamic edge (location-to-location correlation)
patterns, and abrupt trend patterns. To fill this gap, we propose a new NDE
architecture called Multi-View Neural Differential Equations. Our model
captures current states, delayed states, and trends in different state
variables (views) by learning latent multiple representations within Neural
Differential Equations. Extensive experiments conducted on several real-world
traffic datasets demonstrate that our proposed method outperforms the
state-of-the-art and achieves superior prediction accuracy for long-term
forecasting and robustness with noisy or missing inputs.

摘要：長期交通流量預測在智慧運輸中扮演至關重要的角色，因為它允許交通管理員提前調整他們的決策。然而，這個問題由於時空相關性和連續時間串流資料中的複雜動態模式而具有挑戰性。神經微分方程 (NDE) 是用於學習連續時間交通動態的最新方法之一。然而，傳統的 NDE 模型在長期交通預測中面臨問題，因為無法捕捉延遲的交通模式、動態邊緣（位置到位置相關性）模式和突然的趨勢模式。為了填補這個差距，我們提出了一種新的 NDE 架構，稱為多視角神經微分方程。我們的模型透過在神經微分方程中學習潛在的多重表示，捕捉不同狀態變數（視角）中的當前狀態、延遲狀態和趨勢。在幾個真實世界的交通資料集上進行的廣泛實驗表明，我們提出的方法優於最先進的方法，並在長期預測和在有雜訊或遺失輸入的情況下實現了出色的預測準確度。

##### **Evaluating Language Models on Entity Disambiguation in Tables**
2408.06423v1 by Federico Belotti, Fabio Dadda, Marco Cremaschi, Roberto Avogadro, Riccardo Pozzi, Matteo Palmonari

Tables are crucial containers of information, but understanding their meaning
may be challenging. Indeed, recently, there has been a focus on Semantic Table
Interpretation (STI), i.e., the task that involves the semantic annotation of
tabular data to disambiguate their meaning. Over the years, there has been a
surge in interest in data-driven approaches based on deep learning that have
increasingly been combined with heuristic-based approaches. In the last period,
the advent of Large Language Models (LLMs) has led to a new category of
approaches for table annotation. The interest in this research field,
characterised by multiple challenges, has led to a proliferation of approaches
employing different techniques. However, these approaches have not been
consistently evaluated on a common ground, making evaluation and comparison
difficult. This work proposes an extensive evaluation of four state-of-the-art
(SOTA) approaches - Alligator (formerly s-elBat), Dagobah, TURL, and
TableLlama; the first two belong to the family of heuristic-based algorithms,
while the others are respectively encoder-only and decoder-only LLMs. The
primary objective is to measure the ability of these approaches to solve the
entity disambiguation task, with the ultimate aim of charting new research
paths in the field.

摘要：表格是資訊的關鍵載體，但理解其含義可能具有挑戰性。事實上，最近，語意表格詮釋 (STI) 受到關注，即涉及表格資料語意註解的任務，以消除其含義的歧義。多年來，基於深度學習的資料驅動方法的興趣激增，這些方法已日益與基於啟發式的方法相結合。在最近一段時間，大型語言模型 (LLM) 的出現導致了一類新的表格註解方法。對這個研究領域的興趣，其特點是多重挑戰，導致採用不同技術的方法激增。然而，這些方法尚未在共同基礎上得到一致評估，這使得評估和比較變得困難。這項工作對四種最先進 (SOTA) 方法進行了廣泛評估——Alligator（以前稱為 s-elBat）、Dagobah、TURL 和 TableLlama；前兩種屬於基於啟發式演算法的家族，而其他兩種分別是僅編碼器和僅解碼器 LLM。主要目標是衡量這些方法解決實體消除歧義任務的能力，最終目的是繪製該領域的新研究路徑。

##### **LOLgorithm: Integrating Semantic,Syntactic and Contextual Elements for Humor Classification**
2408.06335v1 by Tanisha Khurana, Kaushik Pillalamarri, Vikram Pande, Munindar Singh

This paper explores humor detection through a linguistic lens, prioritizing
syntactic, semantic, and contextual features over computational methods in
Natural Language Processing. We categorize features into syntactic, semantic,
and contextual dimensions, including lexicons, structural statistics, Word2Vec,
WordNet, and phonetic style. Our proposed model, Colbert, utilizes BERT
embeddings and parallel hidden layers to capture sentence congruity. By
combining syntactic, semantic, and contextual features, we train Colbert for
humor detection. Feature engineering examines essential syntactic and semantic
features alongside BERT embeddings. SHAP interpretations and decision trees
identify influential features, revealing that a holistic approach improves
humor detection accuracy on unseen data. Integrating linguistic cues from
different dimensions enhances the model's ability to understand humor
complexity beyond traditional computational methods.

摘要：本文透過語言學角度探討幽默偵測，在自然語言處理中優先考量句法、語意和語境特徵，而非計算方法。我們將特徵分類為句法、語意和語境面向，包括詞彙、結構統計、Word2Vec、WordNet 和語音風格。我們提出的 Colbert 模型利用 BERT 嵌入和並行隱藏層來擷取句子的相符性。透過結合句法、語意和語境特徵，我們訓練 Colbert 進行幽默偵測。特徵工程會檢視基本的句法和語意特徵，以及 BERT 嵌入。SHAP 解釋和決策樹識別出有影響力的特徵，顯示出整體方法能提升未見資料的幽默偵測準確度。整合不同面向的語言線索，增強模型理解幽默複雜性的能力，超越傳統的計算方法。

##### **FastFiD: Improve Inference Efficiency of Open Domain Question Answering via Sentence Selection**
2408.06333v1 by Yufei Huang, Xu Han, Maosong Sun

Open Domain Question Answering (ODQA) has been advancing rapidly in recent
times, driven by significant developments in dense passage retrieval and
pretrained language models. Current models typically incorporate the FiD
framework, which is composed by a neural retriever alongside an encoder-decoder
neural reader. In the answer generation process, the retriever will retrieve
numerous passages (around 100 for instance), each of which is then individually
encoded by the encoder. Subsequently, the decoder makes predictions based on
these encoded passages. Nevertheless, this framework can be relatively
time-consuming, particularly due to the extensive length of the gathered
passages. To address this, we introduce FastFiD in this paper, a novel approach
that executes sentence selection on the encoded passages. This aids in
retaining valuable sentences while reducing the context length required for
generating answers. Experiments on three commonly used datasets (Natural
Questions, TriviaQA and ASQA) demonstrate that our method can enhance the
inference speed by 2.3X-5.7X, while simultaneously maintaining the model's
performance. Moreover, an in-depth analysis of the model's attention reveals
that the selected sentences indeed hold a substantial contribution towards the
final answer. The codes are publicly available at
https://github.com/thunlp/FastFiD.

摘要：開放領域問答 (ODQA) 最近進展快速，由密集段落檢索和預訓練語言模型的重大發展所推動。目前的模型通常結合 FiD 框架，它由神經檢索器和編碼器-解碼器神經閱讀器組成。在答案生成過程中，檢索器會檢索大量段落（例如約 100 個），然後編碼器會個別編碼每個段落。隨後，解碼器根據這些編碼段落進行預測。然而，這個框架可能相對耗時，特別是因為收集的段落長度很長。為了解決這個問題，我們在這篇論文中介紹 FastFiD，這是一種創新的方法，可以在編碼段落上執行句子選取。這有助於保留有價值的句子，同時減少生成答案所需的上下文長度。在三個常用的資料集（自然問題、TriviaQA 和 ASQA）上進行的實驗表明，我們的模型可以將推論速度提高 2.3X-5.7X，同時保持模型的效能。此外，對模型注意力的深入分析顯示，選取的句子確實對最終答案有很大的貢獻。程式碼可在 https://github.com/thunlp/FastFiD 公開取得。

##### **Animate, or Inanimate, That is the Question for Large Language Models**
2408.06332v1 by Leonardo Ranaldi, Giulia Pucci, Fabio Massimo Zanzotto

The cognitive essence of humans is deeply intertwined with the concept of
animacy, which plays an essential role in shaping their memory, vision, and
multi-layered language understanding. Although animacy appears in language via
nuanced constraints on verbs and adjectives, it is also learned and refined
through extralinguistic information. Similarly, we assume that the LLMs'
limited abilities to understand natural language when processing animacy are
motivated by the fact that these models are trained exclusively on text.
  Hence, the question this paper aims to answer arises: can LLMs, in their
digital wisdom, process animacy in a similar way to what humans would do? We
then propose a systematic analysis via prompting approaches. In particular, we
probe different LLMs by prompting them using animate, inanimate, usual, and
stranger contexts. Results reveal that, although LLMs have been trained
predominantly on textual data, they exhibit human-like behavior when faced with
typical animate and inanimate entities in alignment with earlier studies.
Hence, LLMs can adapt to understand unconventional situations by recognizing
oddities as animated without needing to interface with unspoken cognitive
triggers humans rely on to break down animations.

摘要：人類的認知本質與有生命概念緊密相連，而有生命概念在塑造人類的記憶、視覺和多層次語言理解中扮演著至關重要的角色。儘管有生命概念透過動詞和形容詞的微妙約束出現在語言中，但它也是透過語言外的資訊學習和提煉的。同樣地，我們假設大型語言模型（LLM）在處理有生命概念時理解自然語言的能力有限，其原因在於這些模型僅接受過文字訓練。因此，本文旨在回答的問題是：LLM 能否以類似於人類的方式處理有生命概念？我們接著透過提示方法提出一個系統性的分析。具體來說，我們透過使用有生命、無生命、常見和陌生語境提示不同的 LLM 來探測它們。結果顯示，儘管 LLM 主要接受過文字資料訓練，但它們在面對典型的有生命和無生命實體時表現出類似人類的行為，這與先前的研究一致。因此，LLM 可以適應理解非常規情況，將奇異事物視為有生命的，而無需與人類用來分解動畫的未言明的認知觸發器介面。

##### **VisualAgentBench: Towards Large Multimodal Models as Visual Foundation Agents**
2408.06327v1 by Xiao Liu, Tianjie Zhang, Yu Gu, Iat Long Iong, Yifan Xu, Xixuan Song, Shudan Zhang, Hanyu Lai, Xinyi Liu, Hanlin Zhao, Jiadai Sun, Xinyue Yang, Yu Yang, Zehan Qi, Shuntian Yao, Xueqiao Sun, Siyi Cheng, Qinkai Zheng, Hao Yu, Hanchen Zhang, Wenyi Hong, Ming Ding, Lihang Pan, Xiaotao Gu, Aohan Zeng, Zhengxiao Du, Chan Hee Song, Yu Su, Yuxiao Dong, Jie Tang

Large Multimodal Models (LMMs) have ushered in a new era in artificial
intelligence, merging capabilities in both language and vision to form highly
capable Visual Foundation Agents. These agents are postulated to excel across a
myriad of tasks, potentially approaching general artificial intelligence.
However, existing benchmarks fail to sufficiently challenge or showcase the
full potential of LMMs in complex, real-world environments. To address this
gap, we introduce VisualAgentBench (VAB), a comprehensive and pioneering
benchmark specifically designed to train and evaluate LMMs as visual foundation
agents across diverse scenarios, including Embodied, Graphical User Interface,
and Visual Design, with tasks formulated to probe the depth of LMMs'
understanding and interaction capabilities. Through rigorous testing across
nine proprietary LMM APIs and eight open models, we demonstrate the
considerable yet still developing agent capabilities of these models.
Additionally, VAB constructs a trajectory training set constructed through
hybrid methods including Program-based Solvers, LMM Agent Bootstrapping, and
Human Demonstrations, promoting substantial performance improvements in LMMs
through behavior cloning. Our work not only aims to benchmark existing models
but also provides a solid foundation for future development into visual
foundation agents. Code, train \& test data, and part of fine-tuned open LMMs
are available at \url{https://github.com/THUDM/VisualAgentBench}.

摘要：大型多模態模型 (LMM) 開啟了人工智慧的新紀元，結合語言和視覺能力，形成功能強大的視覺基礎代理。這些代理被假設可以在無數任務中表現出色，潛在地接近一般人工智慧。然而，現有的基準未能充分挑戰或展示 LMM 在複雜的現實環境中的全部潛力。為了解決這個差距，我們引入了 VisualAgentBench (VAB)，一個全面且開創性的基準，專門設計用於訓練和評估 LMM 作為視覺基礎代理，涵蓋各種場景，包括具身、圖形使用者介面和視覺設計，任務旨在探討 LMM 的理解和互動能力的深度。透過對九個專有 LMM API 和八個開放模型進行嚴格測試，我們展示了這些模型相當大但仍在發展的代理能力。此外，VAB 構建了一個通過混合方法構建的軌跡訓練集，包括基於程式的求解器、LMM 代理自舉和人類示範，透過行為複製提升 LMM 的顯著效能。我們的研究不僅旨在評量現有模型，也為未來發展成視覺基礎代理奠定了穩固的基礎。程式碼、訓練和測試資料，以及部分微調的開放 LMM 可在 \url{https://github.com/THUDM/VisualAgentBench} 取得。

##### **Can We Rely on LLM Agents to Draft Long-Horizon Plans? Let's Take TravelPlanner as an Example**
2408.06318v1 by Yanan Chen, Ali Pesaranghader, Tanmana Sadhu, Dong Hoon Yi

Large language models (LLMs) have brought autonomous agents closer to
artificial general intelligence (AGI) due to their promising generalization and
emergent capabilities. There is, however, a lack of studies on how LLM-based
agents behave, why they could potentially fail, and how to improve them,
particularly in demanding real-world planning tasks. In this paper, as an
effort to fill the gap, we present our study using a realistic benchmark,
TravelPlanner, where an agent must meet multiple constraints to generate
accurate plans. We leverage this benchmark to address four key research
questions: (1) are LLM agents robust enough to lengthy and noisy contexts when
it comes to reasoning and planning? (2) can few-shot prompting adversely impact
the performance of LLM agents in scenarios with long context? (3) can we rely
on refinement to improve plans, and (4) can fine-tuning LLMs with both positive
and negative feedback lead to further improvement? Our comprehensive
experiments indicate that, firstly, LLMs often fail to attend to crucial parts
of a long context, despite their ability to handle extensive reference
information and few-shot examples; secondly, they still struggle with analyzing
the long plans and cannot provide accurate feedback for refinement; thirdly, we
propose Feedback-Aware Fine-Tuning (FAFT), which leverages both positive and
negative feedback, resulting in substantial gains over Supervised Fine-Tuning
(SFT). Our findings offer in-depth insights to the community on various aspects
related to real-world planning applications.

摘要：大型語言模型 (LLM) 由於其令人期待的概括和新興能力，讓自主代理更接近於人工通用智能 (AGI)。然而，對於 LLM 基礎代理的行為方式、潛在失敗原因以及如何改進它們的研究卻有所欠缺，尤其是在要求嚴格的真實世界規劃任務中。在本文中，我們提出使用現實基準 TravelPlanner 的研究，作為填補空白的努力，其中代理必須滿足多項約束才能產生準確的計畫。我們利用此基準來解決四個關鍵研究問題：(1) 在推理和規劃方面，LLM 代理是否足夠健全，足以應對冗長且嘈雜的背景？(2) 在具有長背景的場景中，少次提示是否會對 LLM 代理的效能產生負面影響？(3) 我們是否可以依賴精進來改善計畫？(4) 使用正面和負面回饋微調 LLM 是否能進一步改善？我們的綜合實驗表明，首先，儘管 LLM 能夠處理廣泛的參考資訊和少次範例，但它們經常無法關注長背景的關鍵部分；其次，它們仍然難以分析長計畫，無法提供準確的回饋以供精進；第三，我們提出回饋感知微調 (FAFT)，它利用正面和負面回饋，產生優於監督式微調 (SFT) 的實質收益。我們的發現為社群提供深入的見解，涵蓋與現實世界規劃應用相關的各個方面。

##### **Body Transformer: Leveraging Robot Embodiment for Policy Learning**
2408.06316v1 by Carmelo Sferrazza, Dun-Ming Huang, Fangchen Liu, Jongmin Lee, Pieter Abbeel

In recent years, the transformer architecture has become the de facto
standard for machine learning algorithms applied to natural language processing
and computer vision. Despite notable evidence of successful deployment of this
architecture in the context of robot learning, we claim that vanilla
transformers do not fully exploit the structure of the robot learning problem.
Therefore, we propose Body Transformer (BoT), an architecture that leverages
the robot embodiment by providing an inductive bias that guides the learning
process. We represent the robot body as a graph of sensors and actuators, and
rely on masked attention to pool information throughout the architecture. The
resulting architecture outperforms the vanilla transformer, as well as the
classical multilayer perceptron, in terms of task completion, scaling
properties, and computational efficiency when representing either imitation or
reinforcement learning policies. Additional material including the open-source
code is available at https://sferrazza.cc/bot_site.

摘要：近年来，变压器架构已成为应用于自然语言处理和计算机视觉的机器学习算法的实际标准。尽管有显着证据表明在机器人学习的背景下成功部署了此架构，但我们声称原始变压器并未充分利用机器人学习问题的结构。因此，我们提出了 Body Transformer (BoT)，一种通过提供指导学习过程的归纳偏差来利用机器人体现的架构。我们将机器人主体表示为传感器和执行器的图形，并依靠掩码注意力来汇集整个架构中的信息。在完成任务、缩放属性和计算效率方面，无论是表示模仿还是强化学习策略，由此产生的架构都优于原始变压器以及经典的多层感知器。包括开源代码在内的其他材料可从 https://sferrazza.cc/bot_site 获得。

##### **Long-Form Answers to Visual Questions from Blind and Low Vision People**
2408.06303v1 by Mina Huh, Fangyuan Xu, Yi-Hao Peng, Chongyan Chen, Hansika Murugu, Danna Gurari, Eunsol Choi, Amy Pavel

Vision language models can now generate long-form answers to questions about
images - long-form visual question answers (LFVQA). We contribute VizWiz-LF, a
dataset of long-form answers to visual questions posed by blind and low vision
(BLV) users. VizWiz-LF contains 4.2k long-form answers to 600 visual questions,
collected from human expert describers and six VQA models. We develop and
annotate functional roles of sentences of LFVQA and demonstrate that long-form
answers contain information beyond the question answer such as explanations and
suggestions. We further conduct automatic and human evaluations with BLV and
sighted people to evaluate long-form answers. BLV people perceive both
human-written and generated long-form answers to be plausible, but generated
answers often hallucinate incorrect visual details, especially for unanswerable
visual questions (e.g., blurry or irrelevant images). To reduce hallucinations,
we evaluate the ability of VQA models to abstain from answering unanswerable
questions across multiple prompting strategies.

摘要：視覺語言模型現在可以針對圖片問題產生長篇答案，也就是長篇視覺問題解答 (LFVQA)。我們貢獻了 VizWiz-LF，這是一個長篇答案的資料集，由失明和視力低 (BLV) 的使用者提出的視覺問題。VizWiz-LF 包含 4.2k 個長篇答案，針對 600 個視覺問題，由人類專家描述者和六個 VQA 模型收集。我們開發並註解 LFVQA 句子的功能角色，並證明長篇答案包含了問題答案以外的資訊，例如解釋和建議。我們進一步與 BLV 和視力正常的人進行自動和人工評估，以評估長篇答案。BLV 人士認為，人類撰寫和產生的長篇答案都合理，但產生的答案通常會產生不正確的視覺細節，特別是針對無法回答的視覺問題（例如模糊或不相關的圖片）。為了減少幻覺，我們評估 VQA 模型在多種提示策略下，避免回答無法回答的問題的能力。

##### **The AI Scientist: Towards Fully Automated Open-Ended Scientific Discovery**
2408.06292v1 by Chris Lu, Cong Lu, Robert Tjarko Lange, Jakob Foerster, Jeff Clune, David Ha

One of the grand challenges of artificial general intelligence is developing
agents capable of conducting scientific research and discovering new knowledge.
While frontier models have already been used as aids to human scientists, e.g.
for brainstorming ideas, writing code, or prediction tasks, they still conduct
only a small part of the scientific process. This paper presents the first
comprehensive framework for fully automatic scientific discovery, enabling
frontier large language models to perform research independently and
communicate their findings. We introduce The AI Scientist, which generates
novel research ideas, writes code, executes experiments, visualizes results,
describes its findings by writing a full scientific paper, and then runs a
simulated review process for evaluation. In principle, this process can be
repeated to iteratively develop ideas in an open-ended fashion, acting like the
human scientific community. We demonstrate its versatility by applying it to
three distinct subfields of machine learning: diffusion modeling,
transformer-based language modeling, and learning dynamics. Each idea is
implemented and developed into a full paper at a cost of less than $15 per
paper. To evaluate the generated papers, we design and validate an automated
reviewer, which we show achieves near-human performance in evaluating paper
scores. The AI Scientist can produce papers that exceed the acceptance
threshold at a top machine learning conference as judged by our automated
reviewer. This approach signifies the beginning of a new era in scientific
discovery in machine learning: bringing the transformative benefits of AI
agents to the entire research process of AI itself, and taking us closer to a
world where endless affordable creativity and innovation can be unleashed on
the world's most challenging problems. Our code is open-sourced at
https://github.com/SakanaAI/AI-Scientist

摘要：人工智能通才的一大難題，在於開發出有能力進行科學研究和發現新知識的代理人。儘管前沿模型已用於協助人類科學家，例如集思廣益、撰寫程式碼或預測任務，但它們仍只進行科學程序的一小部分。本文提出了第一個全自動科學發現的綜合架構，讓前沿大型語言模型能夠獨立進行研究並傳達其發現。我們介紹了「AI 科學家」，它會產生新的研究想法、撰寫程式碼、執行實驗、視覺化結果，並透過撰寫完整的科學論文來描述其發現，然後執行模擬審查程序進行評估。原則上，這個程序可以重複進行，以開放式的方式反覆發展想法，就像人類科學社群一樣。我們透過將其應用於機器學習的三個不同子領域來展示其多樣性：擴散模型、基於Transformer的語言模型和學習動態。每個想法都以每篇論文不到 15 美元的成本實作並發展成一篇完整的論文。為了評估產生的論文，我們設計並驗證了一個自動審查員，我們展示其在評估論文分數時達到了接近人類的表現。AI 科學家可以產生論文，其根據我們的自動審查員的判斷，超過了頂尖機器學習會議的接受門檻。這種方法標誌著機器學習科學發現新時代的開始：將 AI 代理人的轉型優勢帶入 AI 本身的整個研究程序，並讓我們更接近一個無盡且負擔得起的創意和創新能被釋放到世界上最具挑戰性問題的世界。我們的程式碼在 https://github.com/SakanaAI/AI-Scientist 開源。

##### **Synthetic Patient-Physician Dialogue Generation from Clinical Notes Using LLM**
2408.06285v1 by Trisha Das, Dina Albassam, Jimeng Sun

Medical dialogue systems (MDS) enhance patient-physician communication,
improve healthcare accessibility, and reduce costs. However, acquiring suitable
data to train these systems poses significant challenges. Privacy concerns
prevent the use of real conversations, necessitating synthetic alternatives.
Synthetic dialogue generation from publicly available clinical notes offers a
promising solution to this issue, providing realistic data while safeguarding
privacy. Our approach, SynDial, uses a single LLM iteratively with zero-shot
prompting and a feedback loop to generate and refine high-quality synthetic
dialogues. The feedback consists of weighted evaluation scores for similarity
and extractiveness. The iterative process ensures dialogues meet predefined
thresholds, achieving superior extractiveness as a result of the feedback loop.
Additionally, evaluation shows that the generated dialogues excel in factuality
metric compared to the baselines and has comparable diversity scores with GPT4.

摘要：醫療對話系統 (MDS) 可增強病患與醫師的溝通、改善醫療保健的可近性，並降低成本。然而，取得適當的資料來訓練這些系統會造成重大的挑戰。隱私問題會妨礙真實對話的使用，因此需要合成替代方案。從公開可取得的臨床筆記生成合成對話提供了這個問題一個有前景的解決方案，在保護隱私的同時提供真實的資料。我們的 SynDial 方法使用單一 LLM 透過零次提示和回饋迴路，反覆生成和改善高品質的合成對話。回饋包含相似性和抽取性的加權評分。反覆的程序可確保對話符合預先定義的閾值，並因回饋迴路而達成優異的抽取性。此外，評估顯示生成的對話在事實性指標上優於基準，且與 GPT4 具有相當的多樣性評分。

##### **MovieSum: An Abstractive Summarization Dataset for Movie Screenplays**
2408.06281v1 by Rohit Saxena, Frank Keller

Movie screenplay summarization is challenging, as it requires an
understanding of long input contexts and various elements unique to movies.
Large language models have shown significant advancements in document
summarization, but they often struggle with processing long input contexts.
Furthermore, while television transcripts have received attention in recent
studies, movie screenplay summarization remains underexplored. To stimulate
research in this area, we present a new dataset, MovieSum, for abstractive
summarization of movie screenplays. This dataset comprises 2200 movie
screenplays accompanied by their Wikipedia plot summaries. We manually
formatted the movie screenplays to represent their structural elements.
Compared to existing datasets, MovieSum possesses several distinctive features:
(1) It includes movie screenplays, which are longer than scripts of TV
episodes. (2) It is twice the size of previous movie screenplay datasets. (3)
It provides metadata with IMDb IDs to facilitate access to additional external
knowledge. We also show the results of recently released large language models
applied to summarization on our dataset to provide a detailed baseline.

摘要：電影劇本摘要具有挑戰性，因為它需要了解長的輸入背景和電影獨有的各種元素。大型語言模型在文件摘要中顯示出顯著的進步，但它們通常難以處理長的輸入背景。此外，儘管電視轉錄在最近的研究中受到關注，但電影劇本摘要仍未得到充分探討。為了激發這方面的研究，我們提出了新的資料集 MovieSum，用於電影劇本的抽象摘要。此資料集包含 2200 部電影劇本及其維基百科情節摘要。我們手動格式化電影劇本以表示其結構元素。與現有資料集相比，MovieSum 具有幾個顯著特徵：(1) 它包括電影劇本，其長度超過電視劇集的腳本。(2) 它比以前的電影劇本資料集大兩倍。(3) 它提供帶有 IMDb ID 的元資料，以方便存取其他外部知識。我們還展示了最近發布的大型語言模型應用於我們資料集上的摘要結果，以提供詳細的基準。

##### **Review-driven Personalized Preference Reasoning with Large Language Models for Recommendation**
2408.06276v2 by Jieyong Kim, Hyunseo Kim, Hyunjin Cho, SeongKu Kang, Buru Chang, Jinyoung Yeo, Dongha Lee

Recent advancements in Large Language Models (LLMs) have demonstrated
exceptional performance across a wide range of tasks, generating significant
interest in their application to recommendation systems. However, existing
methods have not fully capitalized on the potential of LLMs, often constrained
by limited input information or failing to fully utilize their advanced
reasoning capabilities. To address these limitations, we introduce EXP3RT, a
novel LLM-based recommender designed to leverage rich preference information
contained in user and item reviews. EXP3RT is basically fine-tuned through
distillation from a teacher LLM to perform three key tasks in order: EXP3RT
first extracts and encapsulates essential subjective preferences from raw
reviews, aggregates and summarizes them according to specific criteria to
create user and item profiles. It then generates detailed step-by-step
reasoning followed by predicted rating, i.e., reasoning-enhanced rating
prediction, by considering both subjective and objective information from
user/item profiles and item descriptions. This personalized preference
reasoning from EXP3RT enhances rating prediction accuracy and also provides
faithful and reasonable explanations for recommendation. Extensive experiments
show that EXP3RT outperforms existing methods on both rating prediction and
candidate item reranking for top-k recommendation, while significantly
enhancing the explainability of recommendation systems.

摘要：大型語言模型 (LLM) 最近的進展已展現出在各種任務上的卓越表現，並對其在推薦系統中的應用產生極大的興趣。然而，現有方法並未充分發揮 LLM 的潛力，通常受到輸入資訊有限或未能充分利用其先進推理能力的限制。為了解決這些限制，我們引入了 EXP3RT，一種新穎的基於 LLM 的推薦器，旨在利用使用者和商品評論中包含的豐富偏好資訊。EXP3RT 基本上透過從教師 LLM 中進行蒸餾來微調，以便按順序執行三項關鍵任務：EXP3RT 首先從原始評論中提取並封裝必要的個人主觀偏好，根據特定標準彙總並總結它們以建立使用者和商品檔案。然後，它會考慮使用者/商品檔案和商品說明中的主觀和客觀資訊，產生詳細的逐步推理，然後進行預測評分，即增強推理的評分預測。EXP3RT 的這種個人化偏好推理增強了評分預測的準確性，也為推薦提供了忠實且合理的解釋。大量的實驗表明，EXP3RT 在評分預測和候選項目重新排序方面都優於現有方法，同時顯著提高了推薦系統的可解釋性。

##### **FuxiTranyu: A Multilingual Large Language Model Trained with Balanced Data**
2408.06273v2 by Haoran Sun, Renren Jin, Shaoyang Xu, Leiyu Pan, Supryadi, Menglong Cui, Jiangcun Du, Yikun Lei, Lei Yang, Ling Shi, Juesi Xiao, Shaolin Zhu, Deyi Xiong

Large language models (LLMs) have demonstrated prowess in a wide range of
tasks. However, many LLMs exhibit significant performance discrepancies between
high- and low-resource languages. To mitigate this challenge, we present
FuxiTranyu, an open-source multilingual LLM, which is designed to satisfy the
need of the research community for balanced and high-performing multilingual
capabilities. FuxiTranyu-8B, the base model with 8 billion parameters, is
trained from scratch on a meticulously balanced multilingual data repository
that contains 600 billion tokens covering 43 natural languages and 16
programming languages. In addition to the base model, we also develop two
instruction-tuned models: FuxiTranyu-8B-SFT that is fine-tuned on a diverse
multilingual instruction dataset, and FuxiTranyu-8B-DPO that is further refined
with DPO on a preference dataset for enhanced alignment ability. Extensive
experiments on a wide range of multilingual benchmarks demonstrate the
competitive performance of FuxiTranyu against existing multilingual LLMs, e.g.,
BLOOM-7B, PolyLM-13B, Llama-2-Chat-7B and Mistral-7B-Instruct. Interpretability
analyses at both the neuron and representation level suggest that FuxiTranyu is
able to learn consistent multilingual representations across different
languages. To promote further research into multilingual LLMs and their working
mechanisms, we release both the base and instruction-tuned FuxiTranyu models
together with 58 pretraining checkpoints at HuggingFace and Github.

摘要：大型語言模型 (LLM) 已在各種任務中展現其優異的表現。然而，許多 LLM 在高資源語言和低資源語言之間表現出顯著的差異。為了緩解此挑戰，我們提出 FuxiTranyu，這是一個開源的多語言 LLM，旨在滿足研究社群對於平衡且高性能的多語言功能的需求。FuxiTranyu-8B，一個擁有 80 億個參數的基本模型，從一個精心平衡的多語言資料庫中從頭訓練，其中包含 6000 億個符號，涵蓋 43 種自然語言和 16 種程式語言。除了基本模型之外，我們還開發了兩個指令調整模型：FuxiTranyu-8B-SFT，在一個多元的多語言指令資料集上進行微調，以及 FuxiTranyu-8B-DPO，在一個偏好資料集上進一步使用 DPO 進行調整，以增強對齊能力。在各種多語言基準上的廣泛實驗證明了 FuxiTranyu 相對於現有的多語言 LLM（例如 BLOOM-7B、PolyLM-13B、Llama-2-Chat-7B 和 Mistral-7B-Instruct）具有競爭力。在神經元和表徵層級的詮釋性分析表明，FuxiTranyu 能夠學習跨不同語言的一致多語言表徵。為了促進對多語言 LLM 及其工作機制的進一步研究，我們在 HuggingFace 和 Github 上同時釋出基本和指令調整的 FuxiTranyu 模型，以及 58 個預訓練檢查點。

##### **Anchored Preference Optimization and Contrastive Revisions: Addressing Underspecification in Alignment**
2408.06266v1 by Karel D'Oosterlinck, Winnie Xu, Chris Develder, Thomas Demeester, Amanpreet Singh, Christopher Potts, Douwe Kiela, Shikib Mehri

Large Language Models (LLMs) are often aligned using contrastive alignment
objectives and preference pair datasets. The interaction between model, paired
data, and objective makes alignment a complicated procedure, sometimes
producing subpar results. We study this and find that (i) preference data gives
a better learning signal when the underlying responses are contrastive, and
(ii) alignment objectives lead to better performance when they specify more
control over the model during training. Based on these insights, we introduce
Contrastive Learning from AI Revisions (CLAIR), a data-creation method which
leads to more contrastive preference pairs, and Anchored Preference
Optimization (APO), a controllable and more stable alignment objective. We
align Llama-3-8B-Instruct using various comparable datasets and alignment
objectives and measure MixEval-Hard scores, which correlate highly with human
judgments. The CLAIR preferences lead to the strongest performance out of all
datasets, and APO consistently outperforms less controllable objectives. Our
best model, trained on 32K CLAIR preferences with APO, improves
Llama-3-8B-Instruct by 7.65%, closing the gap with GPT4-turbo by 45%. Our code
is available at https://github.com/ContextualAI/CLAIR_and_APO.

摘要：大型語言模型 (LLM) 通常使用對比式比對目標和偏好配對資料集來對齊。模型、配對資料和目標之間的互動使對齊成為一個複雜的程序，有時會產生次佳結果。我們研究了這一點，發現 (i) 當基礎回應具有對比性時，偏好資料會提供更好的學習訊號，以及 (ii) 對齊目標會在訓練期間對模型有更多控制時帶來更好的效能。根據這些見解，我們引入了 AI 修訂對比學習 (CLAIR)，這是一種資料建立方法，可產生更多對比偏好配對，以及錨定偏好最佳化 (APO)，這是一種可控且更穩定的對齊目標。我們使用各種可比較的資料集和對齊目標來對齊 Llama-3-8B-Instruct，並測量與人類判斷高度相關的 MixEval-Hard 分數。在所有資料集中，CLAIR 偏好帶來最強的效能，而 APO 則始終優於可控性較低的目標。我們在 32K CLAIR 偏好上訓練的最佳模型，使用 APO，將 Llama-3-8B-Instruct 提升了 7.65%，將與 GPT4-turbo 的差距縮小了 45%。我們的程式碼可在 https://github.com/ContextualAI/CLAIR_and_APO 取得。

##### **Audio Enhancement for Computer Audition -- An Iterative Training Paradigm Using Sample Importance**
2408.06264v1 by Manuel Milling, Shuo Liu, Andreas Triantafyllopoulos, Ilhan Aslan, Björn W. Schuller

Neural network models for audio tasks, such as automatic speech recognition
(ASR) and acoustic scene classification (ASC), are susceptible to noise
contamination for real-life applications. To improve audio quality, an
enhancement module, which can be developed independently, is explicitly used at
the front-end of the target audio applications. In this paper, we present an
end-to-end learning solution to jointly optimise the models for audio
enhancement (AE) and the subsequent applications. To guide the optimisation of
the AE module towards a target application, and especially to overcome
difficult samples, we make use of the sample-wise performance measure as an
indication of sample importance. In experiments, we consider four
representative applications to evaluate our training paradigm, i.e., ASR,
speech command recognition (SCR), speech emotion recognition (SER), and ASC.
These applications are associated with speech and non-speech tasks concerning
semantic and non-semantic features, transient and global information, and the
experimental results indicate that our proposed approach can considerably boost
the noise robustness of the models, especially at low signal-to-noise ratios
(SNRs), for a wide range of computer audition tasks in everyday-life noisy
environments.

摘要：針對音訊任務的神經網路模型，例如自動語音辨識 (ASR) 和音景分類 (ASC)，容易受到真實應用中的噪音污染。為了提升音訊品質，一個可以獨立開發的增強模組會明確用於目標音訊應用的前端。在本文中，我們提出一個端對端的學習解決方案，以共同最佳化音訊增強 (AE) 模型和後續應用。為了引導 AE 模組針對目標應用進行最佳化，特別是克服困難的樣本，我們利用樣本層級的效能測量作為樣本重要性的指標。在實驗中，我們考慮了四個代表性應用來評估我們的訓練範例，即 ASR、語音指令辨識 (SCR)、語音情緒辨識 (SER) 和 ASC。這些應用與語音和非語音任務相關，涉及語意和非語意特徵、瞬態和全域性資訊，而實驗結果表明，我們提出的方法可以大幅提升模型的抗噪性，特別是在日常生活中嘈雜環境中低訊噪比 (SNR) 的情況下，適用於廣泛的電腦聽覺任務。

##### **Open-Source Molecular Processing Pipeline for Generating Molecules**
2408.06261v1 by Shreyas V, Jose Siguenza, Karan Bania, Bharath Ramsundar

Generative models for molecules have shown considerable promise for use in
computational chemistry, but remain difficult to use for non-experts. For this
reason, we introduce open-source infrastructure for easily building generative
molecular models into the widely used DeepChem [Ramsundar et al., 2019] library
with the aim of creating a robust and reusable molecular generation pipeline.
In particular, we add high quality PyTorch [Paszke et al., 2019]
implementations of the Molecular Generative Adversarial Networks (MolGAN) [Cao
and Kipf, 2022] and Normalizing Flows [Papamakarios et al., 2021]. Our
implementations show strong performance comparable with past work [Kuznetsov
and Polykovskiy, 2021, Cao and Kipf, 2022].

摘要：分子生成模型在計算化學中展現出極大的應用前景，但對於非專家來說，仍然難以使用。因此，我們引入了開源基礎架構，可以輕鬆地將生成式分子模型建置到廣泛使用的 DeepChem [Ramsundar 等人，2019] 函式庫中，目的是建立一個強健且可重複使用的分子生成管道。特別是，我們加入了高品質的 PyTorch [Paszke 等人，2019] 分子生成對抗網路 (MolGAN) [Cao 和 Kipf，2022] 和正規化流 [Papamakarios 等人，2021] 的實作。我們的實作展現出強勁的效能，與過去的研究 [Kuznetsov 和 Polykovskiy，2021，Cao 和 Kipf，2022] 相當。

##### **Context-aware Visual Storytelling with Visual Prefix Tuning and Contrastive Learning**
2408.06259v1 by Yingjin Song, Denis Paperno, Albert Gatt

Visual storytelling systems generate multi-sentence stories from image
sequences. In this task, capturing contextual information and bridging visual
variation bring additional challenges. We propose a simple yet effective
framework that leverages the generalization capabilities of pretrained
foundation models, only training a lightweight vision-language mapping network
to connect modalities, while incorporating context to enhance coherence. We
introduce a multimodal contrastive objective that also improves visual
relevance and story informativeness. Extensive experimental results, across
both automatic metrics and human evaluations, demonstrate that the stories
generated by our framework are diverse, coherent, informative, and interesting.

摘要：視覺敘事系統從影像序列產生多句式故事。在此任務中，擷取上下文資訊和彌合理視覺變化帶來額外的挑戰。我們提出一個簡單但有效的架構，利用預訓練基礎模型的概化能力，僅訓練一個輕量級的視覺語言對應網路來連接模態，同時納入上下文以增強連貫性。我們引入一個多模態對比目標，它也改善了視覺相關性和故事的資訊性。在自動指標和人工評估中，廣泛的實驗結果證明，我們的架構產生的故事多樣、連貫、資訊豐富且有趣。

