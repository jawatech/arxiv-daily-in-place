
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-11-04**|**Prompting with Phonemes: Enhancing LLM Multilinguality for non-Latin Script Languages**|Hoang Nguyen et.al.|[2411.02398v1](http://arxiv.org/abs/2411.02398v1)|null|
|**2024-11-04**|**Adaptive Length Image Tokenization via Recurrent Allocation**|Shivam Duggal et.al.|[2411.02393v1](http://arxiv.org/abs/2411.02393v1)|[link](https://github.com/shivamduggal4/adaptive-length-tokenizer)|
|**2024-11-04**|**Attacking Vision-Language Computer Agents via Pop-ups**|Yanzhe Zhang et.al.|[2411.02391v1](http://arxiv.org/abs/2411.02391v1)|null|
|**2024-11-04**|**How Far is Video Generation from World Model: A Physical Law Perspective**|Bingyi Kang et.al.|[2411.02385v1](http://arxiv.org/abs/2411.02385v1)|null|
|**2024-11-04**|**Improving Scientific Hypothesis Generation with Knowledge Grounded Large Language Models**|Guangzhi Xiong et.al.|[2411.02382v1](http://arxiv.org/abs/2411.02382v1)|null|
|**2024-11-04**|**Addressing Uncertainty in LLMs to Enhance Reliability in Generative AI**|Ramneet Kaur et.al.|[2411.02381v1](http://arxiv.org/abs/2411.02381v1)|null|
|**2024-11-04**|**DeeR-VLA: Dynamic Inference of Multimodal Large Language Models for Efficient Robot Execution**|Yang Yue et.al.|[2411.02359v1](http://arxiv.org/abs/2411.02359v1)|[link](https://github.com/yueyang130/deer-vla)|
|**2024-11-04**|**"Give Me BF16 or Give Me Death"? Accuracy-Performance Trade-Offs in LLM Quantization**|Eldar Kurtic et.al.|[2411.02355v1](http://arxiv.org/abs/2411.02355v1)|null|
|**2024-11-04**|**Can Large Language Models generalize analogy solving like people can?**|Claire E. Stevenson et.al.|[2411.02348v1](http://arxiv.org/abs/2411.02348v1)|null|
|**2024-11-04**|**Simulation of Nanorobots with Artificial Intelligence and Reinforcement Learning for Advanced Cancer Cell Detection and Tracking**|Shahab Kavousinejad et.al.|[2411.02345v1](http://arxiv.org/abs/2411.02345v1)|[link](https://github.com/shahab-k93/cancer-and-smart-nanorobot)|
|**2024-11-04**|**Seq-VCR: Preventing Collapse in Intermediate Transformer Representations for Enhanced Reasoning**|Md Rifat Arefin et.al.|[2411.02344v1](http://arxiv.org/abs/2411.02344v1)|null|
|**2024-11-04**|**WebRL: Training LLM Web Agents via Self-Evolving Online Curriculum Reinforcement Learning**|Zehan Qi et.al.|[2411.02337v1](http://arxiv.org/abs/2411.02337v1)|null|
|**2024-11-04**|**Sparsing Law: Towards Large Language Models with Greater Activation Sparsity**|Yuqi Luo et.al.|[2411.02335v1](http://arxiv.org/abs/2411.02335v1)|null|
|**2024-11-04**|**Taking AI Welfare Seriously**|Robert Long et.al.|[2411.00986v1](http://arxiv.org/abs/2411.00986v1)|null|
|**2024-11-04**|**Disrupting Test Development with AI Assistants**|Vijay Joshi et.al.|[2411.02328v1](http://arxiv.org/abs/2411.02328v1)|null|
|**2024-11-04**|**GenXD: Generating Any 3D and 4D Scenes**|Yuyang Zhao et.al.|[2411.02319v1](http://arxiv.org/abs/2411.02319v1)|null|
|**2024-11-04**|**Evaluating the Ability of Large Language Models to Generate Verifiable Specifications in VeriFast**|Marilyn Rego et.al.|[2411.02318v1](http://arxiv.org/abs/2411.02318v1)|null|
|**2024-11-04**|**Defining and Evaluating Physical Safety for Large Language Models**|Yung-Chen Tang et.al.|[2411.02317v1](http://arxiv.org/abs/2411.02317v1)|null|
|**2024-11-04**|**Evaluating Creative Short Story Generation in Humans and Large Language Models**|Mete Ismayilzada et.al.|[2411.02316v1](http://arxiv.org/abs/2411.02316v1)|[link](https://github.com/mismayil/creative-story-gen)|
|**2024-11-04**|**MdEval: Massively Multilingual Code Debugging**|Shukai Liu et.al.|[2411.02310v1](http://arxiv.org/abs/2411.02310v1)|null|
|**2024-11-04**|**Grid-Based Projection of Spatial Data into Knowledge Graphs**|Amin Anjomshoaa et.al.|[2411.02309v1](http://arxiv.org/abs/2411.02309v1)|null|
|**2024-11-04**|**Targeted Manipulation and Deception Emerge when Optimizing LLMs for User Feedback**|Marcus Williams et.al.|[2411.02306v1](http://arxiv.org/abs/2411.02306v1)|[link](https://github.com/marcus-jw/targeted-manipulation-and-deception-in-llms)|
|**2024-11-04**|**CRMArena: Understanding the Capacity of LLM Agents to Perform Professional CRM Tasks in Realistic Environments**|Kung-Hsiang Huang et.al.|[2411.02305v1](http://arxiv.org/abs/2411.02305v1)|[link](https://github.com/salesforceairesearch/crmarena)|
|**2024-11-04**|**Hunyuan3D-1.0: A Unified Framework for Text-to-3D and Image-to-3D Generation**|Xianghui Yang et.al.|[2411.02293v1](http://arxiv.org/abs/2411.02293v1)|null|
|**2024-11-04**|**ControlSynth Neural ODEs: Modeling Dynamical Systems with Guaranteed Convergence**|Wenjie Mei et.al.|[2411.02292v1](http://arxiv.org/abs/2411.02292v1)|null|
|**2024-11-04**|**Federated GNNs for EEG-Based Stroke Assessment**|Andrea Protani et.al.|[2411.02286v1](http://arxiv.org/abs/2411.02286v1)|null|
|**2024-11-04**|**The LLM Language Network: A Neuroscientific Approach for Identifying Causally Task-Relevant Units**|Badr AlKhamissi et.al.|[2411.02280v1](http://arxiv.org/abs/2411.02280v1)|null|
|**2024-11-04**|**Breaking the Reclustering Barrier in Centroid-based Deep Clustering**|Lukas Miklautz et.al.|[2411.02275v1](http://arxiv.org/abs/2411.02275v1)|[link](https://github.com/probabilistic-and-interactive-ml/breaking-the-reclustering-barrier)|
|**2024-11-04**|**Combining Induction and Transduction for Abstract Reasoning**|Wen-Ding Li et.al.|[2411.02272v1](http://arxiv.org/abs/2411.02272v1)|null|
|**2024-11-04**|**On the Utilization of Unique Node Identifiers in Graph Neural Networks**|Maya Bechler-Speicher et.al.|[2411.02271v1](http://arxiv.org/abs/2411.02271v1)|null|
|**2024-11-04**|**Hunyuan-Large: An Open-Source MoE Model with 52 Billion Activated Parameters by Tencent**|Xingwu Sun et.al.|[2411.02265v1](http://arxiv.org/abs/2411.02265v1)|[link](https://github.com/tencent/hunyuan-large)|
|**2024-11-04**|**Positive Experience Reflection for Agents in Interactive Text Environments**|Philip Lippmann et.al.|[2411.02223v1](http://arxiv.org/abs/2411.02223v1)|null|
|**2024-11-04**|**Improving Steering Vectors by Targeting Sparse Autoencoder Features**|Sviatoslav Chalnev et.al.|[2411.02193v1](http://arxiv.org/abs/2411.02193v1)|[link](https://github.com/slavachalnev/sae-ts)|
|**2024-11-04**|**Double Descent Meets Out-of-Distribution Detection: Theoretical Insights and Empirical Analysis on the role of model complexity**|Mouïn Ben Ammar et.al.|[2411.02184v1](http://arxiv.org/abs/2411.02184v1)|null|
|**2024-11-04**|**Behavioral Sequence Modeling with Ensemble Learning**|Maxime Kawawa-Beaudan et.al.|[2411.02174v1](http://arxiv.org/abs/2411.02174v1)|null|
|**2024-11-04**|**Do graph neural network states contain graph properties?**|Tom Pelletreau-Duris et.al.|[2411.02168v1](http://arxiv.org/abs/2411.02168v1)|null|
|**2024-11-04**|**Training Compute-Optimal Protein Language Models**|Xingyi Cheng et.al.|[2411.02142v1](http://arxiv.org/abs/2411.02142v1)|[link](https://github.com/cxysteven/scalingproteinlm)|
|**2024-11-04**|**Generating the Traces You Need: A Conditional Generative Model for Process Mining Data**|Riccardo Graziosi et.al.|[2411.02131v1](http://arxiv.org/abs/2411.02131v1)|[link](https://github.com/rgraziosi-fbk/cvae-process-mining)|
|**2024-11-04**|**Unsupervised detection of semantic correlations in big data**|Santiago Acevedo et.al.|[2411.02126v1](http://arxiv.org/abs/2411.02126v1)|null|
|**2024-11-04**|**Revisiting K-mer Profile for Effective and Scalable Genome Representation Learning**|Abdulkadir Celikkanat et.al.|[2411.02125v1](http://arxiv.org/abs/2411.02125v1)|[link](https://github.com/abdcelikkanat/revisitingkmers)|
|**2024-11-04**|**Adaptive Sparse Allocation with Mutual Choice & Feature Choice Sparse Autoencoders**|Kola Ayonrinde et.al.|[2411.02124v1](http://arxiv.org/abs/2411.02124v1)|null|
|**2024-11-04**|**Bridge-IF: Learning Inverse Protein Folding with Markov Bridges**|Yiheng Zhu et.al.|[2411.02120v1](http://arxiv.org/abs/2411.02120v1)|[link](https://github.com/violet-sto/bridge-if)|
|**2024-11-04**|**Grounding Emotional Descriptions to Electrovibration Haptic Signals**|Guimin Hu et.al.|[2411.02118v1](http://arxiv.org/abs/2411.02118v1)|null|
|**2024-11-04**|**AVSS: Layer Importance Evaluation in Large Language Models via Activation Variance-Sparsity Analysis**|Zichen Song et.al.|[2411.02117v1](http://arxiv.org/abs/2411.02117v1)|null|
|**2024-11-04**|**Advancements and limitations of LLMs in replicating human color-word associations**|Makoto Fukushima et.al.|[2411.02116v1](http://arxiv.org/abs/2411.02116v1)|null|
|**2024-11-04**|**Differentially Private Integrated Decision Gradients (IDG-DP) for Radar-based Human Activity Recognition**|Idris Zakariyya et.al.|[2411.02099v1](http://arxiv.org/abs/2411.02099v1)|null|
|**2024-11-04**|**Alignment-Based Adversarial Training (ABAT) for Improving the Robustness and Accuracy of EEG-Based BCIs**|Xiaoqing Chen et.al.|[2411.02094v1](http://arxiv.org/abs/2411.02094v1)|[link](https://github.com/xqchen914/abat)|
|**2024-11-04**|**Real-time and Downtime-tolerant Fault Diagnosis for Railway Turnout Machines (RTMs) Empowered with Cloud-Edge Pipeline Parallelism**|Fan Wu et.al.|[2411.02086v1](http://arxiv.org/abs/2411.02086v1)|null|
|**2024-11-04**|**Regress, Don't Guess -- A Regression-like Loss on Number Tokens for Language Models**|Jonas Zausinger et.al.|[2411.02083v1](http://arxiv.org/abs/2411.02083v1)|null|
|**2024-11-04**|**Collaborative Cognitive Diagnosis with Disentangled Representation Learning for Learner Modeling**|Weibo Gao et.al.|[2411.02066v1](http://arxiv.org/abs/2411.02066v1)|[link](https://github.com/bigdata-ustc/coral)|
|**2024-11-04**|**Scalable Efficient Training of Large Language Models with Low-dimensional Projected Attention**|Xingtai Lv et.al.|[2411.02063v1](http://arxiv.org/abs/2411.02063v1)|null|
|**2024-11-04**|**TableGPT2: A Large Multimodal Model with Tabular Data Integration**|Aofeng Su et.al.|[2411.02059v1](http://arxiv.org/abs/2411.02059v1)|null|
|**2024-11-04**|**Enhancing ID-based Recommendation with Large Language Models**|Lei Chen et.al.|[2411.02041v1](http://arxiv.org/abs/2411.02041v1)|null|
|**2024-11-04**|**Explainable cognitive decline detection in free dialogues with a Machine Learning approach based on pre-trained Large Language Models**|Francisco de Arriba-Pérez et.al.|[2411.02036v1](http://arxiv.org/abs/2411.02036v1)|null|
|**2024-11-04**|**CTEFM-VC: Zero-Shot Voice Conversion Based on Content-Aware Timbre Ensemble Modeling and Flow Matching**|Yu Pan et.al.|[2411.02026v1](http://arxiv.org/abs/2411.02026v1)|null|
|**2024-11-04**|**Shortcut Learning in In-Context Learning: A Survey**|Rui Song et.al.|[2411.02018v1](http://arxiv.org/abs/2411.02018v1)|null|
|**2024-11-04**|**Foundations and Recent Trends in Multimodal Mobile Agents: A Survey**|Biao Wu et.al.|[2411.02006v1](http://arxiv.org/abs/2411.02006v1)|null|
|**2024-11-04**|**Against Multifaceted Graph Heterogeneity via Asymmetric Federated Prompt Learning**|Zhuoning Guo et.al.|[2411.02003v1](http://arxiv.org/abs/2411.02003v1)|null|
|**2024-11-04**|**Culinary Class Wars: Evaluating LLMs using ASH in Cuisine Transfer Task**|Hoonick Lee et.al.|[2411.01996v1](http://arxiv.org/abs/2411.01996v1)|null|
|**2024-11-04**|**Understanding Variational Autoencoders with Intrinsic Dimension and Information Imbalance**|Charles Camboulin et.al.|[2411.01978v1](http://arxiv.org/abs/2411.01978v1)|[link](https://github.com/bancaditalia/understanding-variational-autoencoders-with-intrinsic-dimension-and-information-imbalance)|
|**2024-11-04**|**Active Gaze Behavior Boosts Self-Supervised Object Learning**|Zhengyang Yu et.al.|[2411.01969v1](http://arxiv.org/abs/2411.01969v1)|null|
|**2024-11-04**|**V-CAS: A Realtime Vehicle Anti Collision System Using Vision Transformer on Multi-Camera Streams**|Muhammad Waqas Ashraf et.al.|[2411.01963v1](http://arxiv.org/abs/2411.01963v1)|null|
|**2024-11-04**|**HACD: Harnessing Attribute Semantics and Mesoscopic Structure for Community Detection**|Anran Zhang et.al.|[2411.01947v1](http://arxiv.org/abs/2411.01947v1)|[link](https://github.com/anniran1/hacd1-wsdm)|
|**2024-11-04**|**Exploring the Landscape for Generative Sequence Models for Specialized Data Synthesis**|Mohammad Zbeeb et.al.|[2411.01929v1](http://arxiv.org/abs/2411.01929v1)|[link](https://github.com/moe-zbeeb/exploring-the-landscape-for-generative-models-for-specialized-data-generation)|
|**2024-11-04**|**Fairness-Utilization Trade-off in Wireless Networks with Explainable Kolmogorov-Arnold Networks**|Masoud Shokrnezhad et.al.|[2411.01924v1](http://arxiv.org/abs/2411.01924v1)|null|
|**2024-11-04**|**LE-PDE++: Mamba for accelerating PDEs Simulations**|Aoming Liang et.al.|[2411.01897v1](http://arxiv.org/abs/2411.01897v1)|null|
|**2024-11-04**|**MBDRes-U-Net: Multi-Scale Lightweight Brain Tumor Segmentation Network**|Longfeng Shen et.al.|[2411.01896v1](http://arxiv.org/abs/2411.01896v1)|[link](https://github.com/huaibei-normal-university-cv-laboratory/mbdresunet)|
|**2024-11-04**|**LiDAttack: Robust Black-box Attack on LiDAR-based Object Detection**|Jinyin Chen et.al.|[2411.01889v1](http://arxiv.org/abs/2411.01889v1)|[link](https://github.com/cinderyl/lidattack)|
|**2024-11-04**|**Can Language Models Learn to Skip Steps?**|Tengxiao Liu et.al.|[2411.01855v1](http://arxiv.org/abs/2411.01855v1)|null|
|**2024-11-04**|**Leveraging Label Semantics and Meta-Label Refinement for Multi-Label Question Classification**|Shi Dong et.al.|[2411.01841v1](http://arxiv.org/abs/2411.01841v1)|null|
|**2024-11-04**|**TriG-NER: Triplet-Grid Framework for Discontinuous Named Entity Recognition**|Rina Carines Cabral et.al.|[2411.01839v1](http://arxiv.org/abs/2411.01839v1)|null|
|**2024-11-04**|**Align-SLM: Textless Spoken Language Models with Reinforcement Learning from AI Feedback**|Guan-Ting Lin et.al.|[2411.01834v1](http://arxiv.org/abs/2411.01834v1)|null|
|**2024-11-04**|**DiffuMask-Editor: A Novel Paradigm of Integration Between the Segmentation Diffusion Model and Image Editing to Improve Segmentation Ability**|Bo Gao et.al.|[2411.01819v1](http://arxiv.org/abs/2411.01819v1)|null|
|**2024-11-04**|**Can Language Models Enable In-Context Database?**|Yu Pan et.al.|[2411.01807v1](http://arxiv.org/abs/2411.01807v1)|null|
|**2024-11-04**|**Constrained Human-AI Cooperation: An Inclusive Embodied Social Intelligence Challenge**|Weihua Du et.al.|[2411.01796v1](http://arxiv.org/abs/2411.01796v1)|[link](https://github.com/umass-foundation-model/chaic)|
|**2024-11-04**|**Thinking Forward and Backward: Effective Backward Planning with Large Language Models**|Allen Z. Ren et.al.|[2411.01790v1](http://arxiv.org/abs/2411.01790v1)|[link](https://github.com/irom-princeton/llm-backward)|
|**2024-11-04**|**Context Parallelism for Scalable Million-Token Inference**|Amy et.al.|[2411.01783v1](http://arxiv.org/abs/2411.01783v1)|null|
|**2024-11-04**|**Eurekaverse: Environment Curriculum Generation via Large Language Models**|William Liang et.al.|[2411.01775v1](http://arxiv.org/abs/2411.01775v1)|null|
|**2024-11-04**|**Towards Pedagogical LLMs with Supervised Fine Tuning for Computing Education**|Alexandra Vassar et.al.|[2411.01765v1](http://arxiv.org/abs/2411.01765v1)|null|
|**2024-11-04**|**Mitigating Spurious Correlations via Disagreement Probability**|Hyeonggeun Han et.al.|[2411.01757v1](http://arxiv.org/abs/2411.01757v1)|null|
|**2024-11-04**|**RAGViz: Diagnose and Visualize Retrieval-Augmented Generation**|Tevin Wang et.al.|[2411.01751v1](http://arxiv.org/abs/2411.01751v1)|[link](https://github.com/cxcscmu/ragviz)|
|**2024-11-04**|**DynaSaur: Large Language Agents Beyond Predefined Actions**|Dang Nguyen et.al.|[2411.01747v1](http://arxiv.org/abs/2411.01747v1)|null|
|**2024-11-04**|**xDiT: an Inference Engine for Diffusion Transformers (DiTs) with Massive Parallelism**|Jiarui Fang et.al.|[2411.01738v1](http://arxiv.org/abs/2411.01738v1)|[link](https://github.com/xdit-project/xdit)|
|**2024-11-03**|**Rethinking Weight Decay for Robust Fine-Tuning of Foundation Models**|Junjiao Tian et.al.|[2411.01713v1](http://arxiv.org/abs/2411.01713v1)|[link](https://github.com/gt-ripl/selective-projection-decay)|
|**2024-11-03**|**SPES: Spectrogram Perturbation for Explainable Speech-to-Text Generation**|Dennis Fucci et.al.|[2411.01710v1](http://arxiv.org/abs/2411.01710v1)|null|
|**2024-11-03**|**Investigating Large Language Models for Complex Word Identification in Multilingual and Multidomain Setups**|Răzvan-Alexandru Smădu et.al.|[2411.01706v1](http://arxiv.org/abs/2411.01706v1)|null|
|**2024-11-03**|**Data Extraction Attacks in Retrieval-Augmented Generation via Backdoors**|Yuefeng Peng et.al.|[2411.01705v1](http://arxiv.org/abs/2411.01705v1)|null|
|**2024-11-03**|**UniGuard: Towards Universal Safety Guardrails for Jailbreak Attacks on Multimodal Large Language Models**|Sejoon Oh et.al.|[2411.01703v1](http://arxiv.org/abs/2411.01703v1)|null|
|**2024-11-03**|**Unlocking the Theory Behind Scaling 1-Bit Neural Networks**|Majid Daliri et.al.|[2411.01663v1](http://arxiv.org/abs/2411.01663v1)|null|
|**2024-11-03**|**Diagnosing Medical Datasets with Training Dynamics**|Laura Wenderoth et.al.|[2411.01653v1](http://arxiv.org/abs/2411.01653v1)|[link](https://github.com/laurawenderoth/training-dynamics)|
|**2024-11-03**|**Optimizing Gastrointestinal Diagnostics: A CNN-Based Model for VCE Image Classification**|Vaneeta Ahlawat et.al.|[2411.01652v1](http://arxiv.org/abs/2411.01652v1)|null|
|**2024-11-03**|**Optical Flow Representation Alignment Mamba Diffusion Model for Medical Video Generation**|Zhenbin Wang et.al.|[2411.01647v1](http://arxiv.org/abs/2411.01647v1)|null|
|**2024-11-03**|**Enriching Tabular Data with Contextual LLM Embeddings: A Comprehensive Ablation Study for Ensemble Classifiers**|Gjergji Kasneci et.al.|[2411.01645v1](http://arxiv.org/abs/2411.01645v1)|null|
|**2024-11-03**|**EcoAct: Economic Agent Determines When to Register What Action**|Shaokun Zhang et.al.|[2411.01643v1](http://arxiv.org/abs/2411.01643v1)|null|
|**2024-11-03**|**Know Where You're Uncertain When Planning with Multimodal Foundation Models: A Formal Framework**|Neel P. Bhatt et.al.|[2411.01639v1](http://arxiv.org/abs/2411.01639v1)|null|
|**2024-11-03**|**Leveraging Microservices Architecture for Dynamic Pricing in the Travel Industry: Algorithms, Scalability, and Impact on Revenue and Customer Satisfaction**|Biman Barua et.al.|[2411.01636v1](http://arxiv.org/abs/2411.01636v1)|null|
|**2024-11-03**|**Counterfactual explainability of black-box prediction models**|Zijun Gao et.al.|[2411.01625v1](http://arxiv.org/abs/2411.01625v1)|null|
|**2024-11-03**|**FilterNet: Harnessing Frequency Filters for Time Series Forecasting**|Kun Yi et.al.|[2411.01623v1](http://arxiv.org/abs/2411.01623v1)|[link](https://github.com/aikunyi/filternet)|
|**2024-11-03**|**VQ-Map: Bird's-Eye-View Map Layout Estimation in Tokenized Discrete Space via Vector Quantization**|Yiwei Zhang et.al.|[2411.01618v1](http://arxiv.org/abs/2411.01618v1)|null|
|**2024-11-03**|**Ontology Population using LLMs**|Sanaz Saki Norouzi et.al.|[2411.01612v1](http://arxiv.org/abs/2411.01612v1)|null|

#### Abstracts
##### **Prompting with Phonemes: Enhancing LLM Multilinguality for non-Latin Script Languages**
2411.02398v1 by Hoang Nguyen, Khyati Mahajan, Vikas Yadav, Philip S. Yu, Masoud Hashemi, Rishabh Maheshwary

Multilingual LLMs have achieved remarkable benchmark performance, but we find
they continue to underperform on non-Latin script languages across contemporary
LLM families. This discrepancy arises from the fact that LLMs are pretrained
with orthographic scripts, which are dominated by Latin characters that obscure
their shared phonology with non-Latin scripts. We propose leveraging phonemic
transcriptions as complementary signals to induce script-invariant
representations. Our study demonstrates that integrating phonemic signals
improves performance across both non-Latin and Latin languages, with a
particularly significant impact on closing the performance gap between the two.
Through detailed experiments, we show that phonemic and orthographic scripts
retrieve distinct examples for in-context learning (ICL). This motivates our
proposed Mixed-ICL retrieval strategy, where further aggregation leads to our
significant performance improvements for both Latin script languages (up to
12.6%) and non-Latin script languages (up to 15.1%) compared to randomized ICL
retrieval.

摘要：多語言 LLM 已經取得顯著的基準效能，但我們發現，在當代 LLM 家族中，它們在非拉丁文字語言上的表現仍然不佳。這種差異源於 LLM 是使用正字法腳本來預先訓練的，而正字法腳本主要是由拉丁字母主導，這會模糊它們與非拉丁字母共有的音韻。我們建議利用音素轉錄作為補充訊號，以誘導出與腳本無關的表徵。我們的研究證明，整合音素訊號可以提升非拉丁語和拉丁語的效能，特別是在縮小兩者之間的效能差距方面有顯著的影響。透過詳細的實驗，我們表明音素和正字法腳本會擷取不同的範例，以進行情境中學習 (ICL)。這激勵我們提出混合 ICL 擷取策略，進一步的聚合會導致我們顯著提升拉丁文字語言 (最高達 12.6%) 和非拉丁文字語言 (最高達 15.1%) 的效能，相比於隨機 ICL 擷取。

##### **Adaptive Length Image Tokenization via Recurrent Allocation**
2411.02393v1 by Shivam Duggal, Phillip Isola, Antonio Torralba, William T. Freeman

Current vision systems typically assign fixed-length representations to
images, regardless of the information content. This contrasts with human
intelligence - and even large language models - which allocate varying
representational capacities based on entropy, context and familiarity. Inspired
by this, we propose an approach to learn variable-length token representations
for 2D images. Our encoder-decoder architecture recursively processes 2D image
tokens, distilling them into 1D latent tokens over multiple iterations of
recurrent rollouts. Each iteration refines the 2D tokens, updates the existing
1D latent tokens, and adaptively increases representational capacity by adding
new tokens. This enables compression of images into a variable number of
tokens, ranging from 32 to 256. We validate our tokenizer using reconstruction
loss and FID metrics, demonstrating that token count aligns with image entropy,
familiarity and downstream task requirements. Recurrent token processing with
increasing representational capacity in each iteration shows signs of token
specialization, revealing potential for object / part discovery.

摘要：目前的視覺系統通常會將固定長度的表徵分配給影像，而不管資訊內容為何。這與人類的智慧——甚至是大型語言模型——形成對比，後者會根據熵、脈絡和熟悉度分配不同的表徵容量。受到這點啟發，我們提出一個方法來學習 2D 影像的可變長度標記表徵。我們的編碼器-解碼器架構會遞迴處理 2D 影像標記，將它們在遞迴展開的多次迭代中提煉成 1D 潛在標記。每次迭代都會精煉 2D 標記、更新現有的 1D 潛在標記，並透過新增標記來適應性地增加表徵容量。這能將影像壓縮成數量可變的標記，範圍從 32 到 256。我們使用重建損失和 FID 指標驗證我們的標記器，證明標記數量與影像熵、熟悉度和下游任務需求相符。在每次迭代中，遞迴標記處理會隨著表徵容量的增加而顯示標記專業化的跡象，揭示了物件/部分發現的潛力。

##### **Attacking Vision-Language Computer Agents via Pop-ups**
2411.02391v1 by Yanzhe Zhang, Tao Yu, Diyi Yang

Autonomous agents powered by large vision and language models (VLM) have
demonstrated significant potential in completing daily computer tasks, such as
browsing the web to book travel and operating desktop software, which requires
agents to understand these interfaces. Despite such visual inputs becoming more
integrated into agentic applications, what types of risks and attacks exist
around them still remain unclear. In this work, we demonstrate that VLM agents
can be easily attacked by a set of carefully designed adversarial pop-ups,
which human users would typically recognize and ignore. This distraction leads
agents to click these pop-ups instead of performing the tasks as usual.
Integrating these pop-ups into existing agent testing environments like OSWorld
and VisualWebArena leads to an attack success rate (the frequency of the agent
clicking the pop-ups) of 86% on average and decreases the task success rate by
47%. Basic defense techniques such as asking the agent to ignore pop-ups or
including an advertisement notice, are ineffective against the attack.

摘要：由大型視覺和語言模型 (VLM) 驅動的自主代理已證明在完成日常電腦任務方面具有顯著的潛力，例如瀏覽網路以預訂旅遊和操作桌面軟體，這需要代理了解這些介面。儘管此類視覺輸入已更廣泛地整合到代理應用程式中，但它們周圍存在哪些類型的風險和攻擊仍不清楚。在這項工作中，我們展示了 VLM 代理可以輕鬆地受到一組精心設計的對抗性彈出視窗攻擊，而人類使用者通常會識別並忽略這些視窗。這種分心導致代理點擊這些彈出視窗，而不是像往常一樣執行任務。將這些彈出視窗整合到現有的代理測試環境中，例如 OSWorld 和 VisualWebArena，會導致攻擊成功率（代理點擊彈出視窗的頻率）平均為 86%，並將任務成功率降低 47%。基本防禦技術，例如要求代理忽略彈出視窗或包含廣告通知，對攻擊無效。

##### **How Far is Video Generation from World Model: A Physical Law Perspective**
2411.02385v1 by Bingyi Kang, Yang Yue, Rui Lu, Zhijie Lin, Yang Zhao, Kaixin Wang, Gao Huang, Jiashi Feng

OpenAI's Sora highlights the potential of video generation for developing
world models that adhere to fundamental physical laws. However, the ability of
video generation models to discover such laws purely from visual data without
human priors can be questioned. A world model learning the true law should give
predictions robust to nuances and correctly extrapolate on unseen scenarios. In
this work, we evaluate across three key scenarios: in-distribution,
out-of-distribution, and combinatorial generalization. We developed a 2D
simulation testbed for object movement and collisions to generate videos
deterministically governed by one or more classical mechanics laws. This
provides an unlimited supply of data for large-scale experimentation and
enables quantitative evaluation of whether the generated videos adhere to
physical laws. We trained diffusion-based video generation models to predict
object movements based on initial frames. Our scaling experiments show perfect
generalization within the distribution, measurable scaling behavior for
combinatorial generalization, but failure in out-of-distribution scenarios.
Further experiments reveal two key insights about the generalization mechanisms
of these models: (1) the models fail to abstract general physical rules and
instead exhibit "case-based" generalization behavior, i.e., mimicking the
closest training example; (2) when generalizing to new cases, models are
observed to prioritize different factors when referencing training data: color
> size > velocity > shape. Our study suggests that scaling alone is
insufficient for video generation models to uncover fundamental physical laws,
despite its role in Sora's broader success. See our project page at
https://phyworld.github.io

摘要：OpenAI 的 Sora 突顯了影片生成在開發遵守基本物理定律的世界模型方面的潛力。然而，影片生成模型僅從視覺資料中發現此類定律的能力，在沒有人類先驗知識的情況下可能會受到質疑。學習真實定律的世界模型應提供對細微差別穩健的預測，並正確推斷出未見過的場景。在這項工作中，我們評估了三個關鍵場景：分佈內、分佈外和組合概化。我們開發了一個用於物體運動和碰撞的 2D 模擬測試平台，以生成由一個或多個經典力學定律決定性控制的影片。這為大規模實驗提供了無限的資料供應，並能夠對生成的影片是否遵守物理定律進行定量評估。我們訓練了基於擴散的影片生成模型，以根據初始幀預測物體運動。我們的擴展實驗顯示了分佈內的完美概化、組合概化可測量的擴展行為，但在分佈外場景中失敗。進一步的實驗揭示了關於這些模型概化機制的兩個關鍵見解：(1) 模型無法抽象出一般的物理規則，而是表現出「基於案例」的概化行為，即模仿最接近的訓練範例；(2) 在概化到新案例時，觀察到模型在參考訓練資料時優先考慮不同的因素：顏色 > 大小 > 速度 > 形狀。我們的研究表明，儘管擴展在 Sora 的更廣泛成功中發揮了作用，但僅靠擴展不足以讓影片生成模型發現基本的物理定律。請參閱我們的專案頁面 https://phyworld.github.io

##### **Improving Scientific Hypothesis Generation with Knowledge Grounded Large Language Models**
2411.02382v1 by Guangzhi Xiong, Eric Xie, Amir Hassan Shariatmadari, Sikun Guo, Stefan Bekiranov, Aidong Zhang

Large language models (LLMs) have demonstrated remarkable capabilities in
various scientific domains, from natural language processing to complex
problem-solving tasks. Their ability to understand and generate human-like text
has opened up new possibilities for advancing scientific research, enabling
tasks such as data analysis, literature review, and even experimental design.
One of the most promising applications of LLMs in this context is hypothesis
generation, where they can identify novel research directions by analyzing
existing knowledge. However, despite their potential, LLMs are prone to
generating ``hallucinations'', outputs that are plausible-sounding but
factually incorrect. Such a problem presents significant challenges in
scientific fields that demand rigorous accuracy and verifiability, potentially
leading to erroneous or misleading conclusions. To overcome these challenges,
we propose KG-CoI (Knowledge Grounded Chain of Ideas), a novel system that
enhances LLM hypothesis generation by integrating external, structured
knowledge from knowledge graphs (KGs). KG-CoI guides LLMs through a structured
reasoning process, organizing their output as a chain of ideas (CoI), and
includes a KG-supported module for the detection of hallucinations. With
experiments on our newly constructed hypothesis generation dataset, we
demonstrate that KG-CoI not only improves the accuracy of LLM-generated
hypotheses but also reduces the hallucination in their reasoning chains,
highlighting its effectiveness in advancing real-world scientific research.

摘要：大型語言模型 (LLM) 已在各種科學領域展現卓越的能力，從自然語言處理到複雜的解決問題任務。它們理解和產生類似人類文字的能力為推進科學研究開啟了新的可能性，讓資料分析、文獻回顧，甚至實驗設計等任務成為可能。LLM 在此脈絡中最有希望的應用之一是假設產生，它們能透過分析現有知識來找出新的研究方向。然而，儘管 LLM 具有潛力，它們卻容易產生「幻覺」，也就是聽起來合理但事實上不正確的輸出。此類問題在需要嚴謹準確性和可驗證性的科學領域中會造成重大挑戰，有可能導致錯誤或誤導性的結論。為了克服這些挑戰，我們提出 KG-CoI（知識基礎觀念鏈），這是一個創新的系統，它透過整合知識圖譜 (KG) 中的外部結構化知識來增強 LLM 假設產生。KG-CoI 引導 LLM 進行結構化推理程序，將其輸出整理成觀念鏈 (CoI)，並包含一個由 KG 支援的模組來偵測幻覺。透過我們新建立的假設產生資料集進行的實驗，我們證明 KG-CoI 不僅改善了 LLM 產生的假設的準確性，也減少了其推理鏈中的幻覺，突顯了其在推進現實世界科學研究中的效能。

##### **Addressing Uncertainty in LLMs to Enhance Reliability in Generative AI**
2411.02381v1 by Ramneet Kaur, Colin Samplawski, Adam D. Cobb, Anirban Roy, Brian Matejek, Manoj Acharya, Daniel Elenius, Alexander M. Berenbeim, John A. Pavlik, Nathaniel D. Bastian, Susmit Jha

In this paper, we present a dynamic semantic clustering approach inspired by
the Chinese Restaurant Process, aimed at addressing uncertainty in the
inference of Large Language Models (LLMs). We quantify uncertainty of an LLM on
a given query by calculating entropy of the generated semantic clusters.
Further, we propose leveraging the (negative) likelihood of these clusters as
the (non)conformity score within Conformal Prediction framework, allowing the
model to predict a set of responses instead of a single output, thereby
accounting for uncertainty in its predictions. We demonstrate the effectiveness
of our uncertainty quantification (UQ) technique on two well known question
answering benchmarks, COQA and TriviaQA, utilizing two LLMs, Llama2 and
Mistral. Our approach achieves SOTA performance in UQ, as assessed by metrics
such as AUROC, AUARC, and AURAC. The proposed conformal predictor is also shown
to produce smaller prediction sets while maintaining the same probabilistic
guarantee of including the correct response, in comparison to existing SOTA
conformal prediction baseline.

摘要：在本文中，我们提出了一种动态语义聚类方法，该方法受中国餐馆过程的启发，旨在解决大语言模型（LLM）推断中的不确定性。我们通过计算生成的语义聚类的熵来量化 LLM 在给定查询上的不确定性。此外，我们建议利用这些聚类的（负）似然性作为共形预测框架中的（不）一致性得分，从而允许模型预测一组响应而不是单个输出，从而解释其预测中的不确定性。我们展示了我们在两个著名的问答基准 COQA 和 TriviaQA 上的不确定性量化 (UQ) 技术的有效性，利用了两个 LLM，Llama2 和 Mistral。我们的方法在 UQ 中实现了 SOTA 性能，如 AUROC、AUARC 和 AURAC 等指标所评估的那样。与现有的 SOTA 共形预测基线相比，所提出的共形预测器还显示出在保持包含正确响应的相同概率保证的同时产生更小的预测集。

##### **DeeR-VLA: Dynamic Inference of Multimodal Large Language Models for Efficient Robot Execution**
2411.02359v1 by Yang Yue, Yulin Wang, Bingyi Kang, Yizeng Han, Shenzhi Wang, Shiji Song, Jiashi Feng, Gao Huang

MLLMs have demonstrated remarkable comprehension and reasoning capabilities
with complex language and visual data. These advances have spurred the vision
of establishing a generalist robotic MLLM proficient in understanding complex
human instructions and accomplishing various embodied tasks. However,
developing MLLMs for real-world robots is challenging due to the typically
limited computation and memory capacities available on robotic platforms. In
contrast, the inference of MLLMs involves storing billions of parameters and
performing tremendous computation, imposing significant hardware demands. In
our paper, we propose a Dynamic Early-Exit Framework for Robotic
Vision-Language-Action Model (DeeR-VLA, or simply DeeR) that automatically
adjusts the size of the activated MLLM based on each situation at hand. The
approach leverages a multi-exit architecture in MLLMs, which allows the model
to terminate processing once a proper size of the model has been activated for
a specific situation, thus avoiding further redundant computation.
Additionally, we develop novel algorithms that establish early-termination
criteria for DeeR, conditioned on predefined demands such as average
computational cost (i.e., power consumption), as well as peak computational
consumption (i.e., latency) and GPU memory usage. These enhancements ensure
that DeeR operates efficiently under varying resource constraints while
maintaining competitive performance. On the CALVIN robot manipulation
benchmark, DeeR demonstrates significant reductions in computational costs of
LLM by 5.2-6.5x and GPU memory of LLM by 2-6x without compromising performance.
Code and checkpoints are available at https://github.com/yueyang130/DeeR-VLA.

摘要：多模态大语言模型 (MLLM) 已展示出卓越的理解和推理能力，可用于处理复杂的语言和视觉数据。这些进步激发了建立通用机器人多模态大语言模型的愿景，该模型精通理解复杂的人类指令并完成各种具体任务。然而，为实际机器人开发多模态大语言模型具有挑战性，因为机器人平台上通常可用的计算和内存容量有限。相比之下，多模态大语言模型的推理涉及存储数十亿个参数和执行大量的计算，这会对硬件提出很高的要求。在我们的论文中，我们提出了机器人视觉语言动作模型的动态早期退出框架 (DeeR-VLA，或简称 DeeR)，该框架可根据手头的每种情况自动调整已激活的多模态大语言模型的大小。该方法利用了多模态大语言模型中的多出口架构，该架构允许模型在为特定情况激活适当大小的模型后终止处理，从而避免进一步的冗余计算。此外，我们开发了新算法，为 DeeR 建立了早期终止标准，这些标准以预定义的需求为条件，例如平均计算成本（即功耗），以及峰值计算消耗（即延迟）和 GPU 内存使用情况。这些增强功能确保了 DeeR 在不同的资源限制下高效运行，同时保持了有竞争力的性能。在 CALVIN 机器人操作基准测试中，DeeR 将 LLM 的计算成本显着降低了 5.2-6.5 倍，LLM 的 GPU 内存降低了 2-6 倍，而性能没有受到影响。代码和检查点可在 https://github.com/yueyang130/DeeR-VLA 获得。

##### **"Give Me BF16 or Give Me Death"? Accuracy-Performance Trade-Offs in LLM Quantization**
2411.02355v1 by Eldar Kurtic, Alexandre Marques, Shubhra Pandit, Mark Kurtz, Dan Alistarh

Despite the popularity of large language model (LLM) quantization for
inference acceleration, significant uncertainty remains regarding the
accuracy-performance trade-offs associated with various quantization formats.
We present a comprehensive empirical study of quantized accuracy, evaluating
popular quantization formats (FP8, INT8, INT4) across academic benchmarks and
real-world tasks, on the entire Llama-3.1 model family. Additionally, our study
examines the difference in text generated by quantized models versus their
uncompressed counterparts. Beyond benchmarks, we also present a couple of
quantization improvements which allowed us to obtain state-of-the-art accuracy
recovery results. Our investigation, encompassing over 500,000 individual
evaluations, yields several key findings: (1) FP8 weight and activation
quantization (W8A8-FP) is lossless across all model scales, (2) INT8 weight and
activation quantization (W8A8-INT), when properly tuned, incurs surprisingly
low 1-3% accuracy degradation, and (3) INT4 weight-only quantization
(W4A16-INT) is competitive with 8-bit integer weight and activation
quantization. To address the question of the "best" format for a given
deployment environment, we conduct inference performance analysis using the
popular open-source vLLM framework on various GPU architectures. We find that
W4A16 offers the best cost-efficiency for synchronous deployments, and for
asynchronous deployment on mid-tier GPUs. At the same time, W8A8 formats excel
in asynchronous "continuous batching" deployment of mid- and large-size models
on high-end GPUs. Our results provide a set of practical guidelines for
deploying quantized LLMs across scales and performance requirements.

摘要：儘管大型語言模型 (LLM) 量化在推論加速方面的普及，但對於各種量化格式相關的準確性效能權衡仍存在著相當大的不確定性。
我們針對量化準確性提出了一項全面的實證研究，在整個 Llama-3.1 模型系列中，針對學術基準和真實世界任務評估熱門的量化格式 (FP8、INT8、INT4)。此外，我們的研究探討了量化模型產生的文字與其未壓縮對應文字之間的差異。除了基準之外，我們還提出了一些量化改進，讓我們得以獲得最先進的準確性復原結果。我們的調查涵蓋超過 500,000 個個別評估，產生了幾個關鍵發現：(1) FP8 權重和啟用量化 (W8A8-FP) 在所有模型規模中都是無損的，(2) INT8 權重和啟用量化 (W8A8-INT) 在經過適當調整後，令人驚訝地僅造成 1-3% 的準確度下降，以及 (3) INT4 僅權重量化 (W4A16-INT) 與 8 位元整數權重和啟用量化具有競爭力。為了解決給定部署環境的「最佳」格式問題，我們使用各種 GPU 架構上的熱門開源 vLLM 框架進行推論效能分析。我們發現 W4A16 為同步部署和中階 GPU 上的非同步部署提供了最佳的成本效益。同時，W8A8 格式在中大型模型於高階 GPU 上的非同步「連續批次處理」部署中表現出色。我們的結果提供了一組實用的準則，可用於在各種規模和效能需求中部署量化的 LLM。

##### **Can Large Language Models generalize analogy solving like people can?**
2411.02348v1 by Claire E. Stevenson, Alexandra Pafford, Han L. J. van der Maas, Melanie Mitchell

When we solve an analogy we transfer information from a known context to a
new one through abstract rules and relational similarity. In people, the
ability to solve analogies such as "body : feet :: table : ?" emerges in
childhood, and appears to transfer easily to other domains, such as the visual
domain "( : ) :: < : ?". Recent research shows that large language models
(LLMs) can solve various forms of analogies. However, can LLMs generalize
analogy solving to new domains like people can? To investigate this, we had
children, adults, and LLMs solve a series of letter-string analogies (e.g., a b
: a c :: j k : ?) in the Latin alphabet, in a near transfer domain (Greek
alphabet), and a far transfer domain (list of symbols). As expected, children
and adults easily generalized their knowledge to unfamiliar domains, whereas
LLMs did not. This key difference between human and AI performance is evidence
that these LLMs still struggle with robust human-like analogical transfer.

摘要：當我們解決類比時，我們會透過抽象規則和關聯相似性將資訊從已知情境轉移到新的情境中。在人類身上，解決類比（例如「身體：腳 :: 桌子：？」）的能力會在童年時期出現，並似乎可以輕鬆轉移到其他領域，例如視覺領域「（：）：<：？」。最近的研究顯示，大型語言模型 (LLM) 可以解決各種形式的類比。然而，LLM 是否能像人類一樣將類比解決泛化到新領域？為了探討這一點，我們讓兒童、成人和 LLM 解決一系列拉丁字母的字串類比（例如，a b：a c :: j k：？），在近距離轉移領域（希臘字母）和遠距離轉移領域（符號清單）。正如預期的那樣，兒童和成人很容易將他們的知識泛化到不熟悉的領域，而 LLM 則不然。人類和 AI 表現之間的這個關鍵差異證明了這些 LLM 仍然難以進行健全的人類類比轉移。

##### **Simulation of Nanorobots with Artificial Intelligence and Reinforcement Learning for Advanced Cancer Cell Detection and Tracking**
2411.02345v1 by Shahab Kavousinejad

Nanorobots are a promising development in targeted drug delivery and the
treatment of neurological disorders, with potential for crossing the
blood-brain barrier (BBB). These small devices leverage advancements in
nanotechnology and bioengineering for precise navigation and targeted payload
delivery, particularly for conditions like brain tumors, Alzheimer's disease,
and Parkinson's disease. Recent progress in artificial intelligence (AI) and
machine learning (ML) has improved the navigation and effectiveness of
nanorobots, allowing them to detect and interact with cancer cells through
biomarker analysis. This study presents a new reinforcement learning (RL)
framework for optimizing nanorobot navigation in complex biological
environments, focusing on cancer cell detection by analyzing the concentration
gradients of surrounding biomarkers. We utilize a computer simulation model to
explore the behavior of nanorobots in a three-dimensional space with cancer
cells and biological barriers. The proposed method uses Q-learning to refine
movement strategies based on real-time biomarker concentration data, enabling
nanorobots to autonomously navigate to cancerous tissues for targeted drug
delivery. This research lays the groundwork for future laboratory experiments
and clinical applications, with implications for personalized medicine and less
invasive cancer treatments. The integration of intelligent nanorobots could
revolutionize therapeutic strategies, reducing side effects and enhancing
treatment effectiveness for cancer patients. Further research will investigate
the practical deployment of these technologies in medical settings, aiming to
unlock the full potential of nanorobotics in healthcare.

摘要：奈米機器人在標靶藥物傳輸和神經疾病治療中是一項有前景的發展，並具有穿越血腦屏障 (BBB) 的潛力。這些小型裝置利用奈米技術和生物工程的進展，進行精確導航和標靶有效載荷傳輸，特別是針對腦瘤、阿茲海默症和帕金森氏症等疾病。人工智慧 (AI) 和機器學習 (ML) 的最新進展改善了奈米機器人的導航和效能，讓它們能透過生物標記分析來偵測和與癌細胞互動。本研究提出了一個新的強化學習 (RL) 架構，用於最佳化奈米機器人在複雜生物環境中的導航，重點在於透過分析周圍生物標記的濃度梯度來偵測癌細胞。我們利用電腦模擬模型來探索奈米機器人在三維空間中與癌細胞和生物障礙物之間的行為。所提出的方法使用 Q 學習來根據即時生物標記濃度資料調整移動策略，讓奈米機器人能自主導航至癌組織進行標靶藥物傳輸。這項研究為未來的實驗室實驗和臨床應用奠定了基礎，並對個人化醫療和侵入性較小的癌症治療產生影響。整合智慧奈米機器人可以革新治療策略，減少副作用並提高癌症患者的治療效果。進一步的研究將探討這些技術在醫療環境中的實際部署，目標是發揮奈米機器人在醫療保健中的全部潛力。

##### **Seq-VCR: Preventing Collapse in Intermediate Transformer Representations for Enhanced Reasoning**
2411.02344v1 by Md Rifat Arefin, Gopeshh Subbaraj, Nicolas Gontier, Yann LeCun, Irina Rish, Ravid Shwartz-Ziv, Christopher Pal

Decoder-only Transformers often struggle with complex reasoning tasks,
particularly arithmetic reasoning requiring multiple sequential operations. In
this work, we identify representation collapse in the model's intermediate
layers as a key factor limiting their reasoning capabilities. To address this,
we propose Sequential Variance-Covariance Regularization (Seq-VCR), which
enhances the entropy of intermediate representations and prevents collapse.
Combined with dummy pause tokens as substitutes for chain-of-thought (CoT)
tokens, our method significantly improves performance in arithmetic reasoning
problems. In the challenging $5 \times 5$ integer multiplication task, our
approach achieves $99.5\%$ exact match accuracy, outperforming models of the
same size (which yield $0\%$ accuracy) and GPT-4 with five-shot CoT prompting
($44\%$). We also demonstrate superior results on arithmetic expression and
longest increasing subsequence (LIS) datasets. Our findings highlight the
importance of preventing intermediate layer representation collapse to enhance
the reasoning capabilities of Transformers and show that Seq-VCR offers an
effective solution without requiring explicit CoT supervision.

摘要：僅解碼器 Transformer 通常難以應付複雜的推理任務，特別是需要多個順序運算的算術推理。在此研究中，我們發現模型中間層的表徵崩潰是限制其推理能力的一個關鍵因素。為了解決此問題，我們提出了順序變異協方差規範化 (Seq-VCR)，它增強了中間表徵的熵並防止崩潰。我們的這種方法結合了作為思想鏈 (CoT) 標記的替換項的虛擬暫停標記，大幅改善了算術推理問題的效能。在具有挑戰性的 $5 \times 5$ 整數乘法任務中，我們的做法達到了 $99.5\%$ 的精確匹配準確度，優於同等規模的模型（產生 $0\%$ 的準確度）和具有五次 CoT 提示的 GPT-4（$44\%$）。我們也在算術表達式和最長遞增子序列 (LIS) 資料集上證明了優異的結果。我們的發現強調了防止中間層表徵崩潰以增強 Transformer 的推理能力的重要性，並顯示 Seq-VCR 提供了一個有效的解決方案，而不需要明確的 CoT 監督。

##### **WebRL: Training LLM Web Agents via Self-Evolving Online Curriculum Reinforcement Learning**
2411.02337v1 by Zehan Qi, Xiao Liu, Iat Long Iong, Hanyu Lai, Xueqiao Sun, Xinyue Yang, Jiadai Sun, Yu Yang, Shuntian Yao, Tianjie Zhang, Wei Xu, Jie Tang, Yuxiao Dong

Large language models (LLMs) have shown remarkable potential as autonomous
agents, particularly in web-based tasks. However, existing LLM web agents
heavily rely on expensive proprietary LLM APIs, while open LLMs lack the
necessary decision-making capabilities. This paper introduces WebRL, a
self-evolving online curriculum reinforcement learning framework designed to
train high-performance web agents using open LLMs. WebRL addresses three key
challenges in building LLM web agents, including the scarcity of training
tasks, sparse feedback signals, and policy distribution drift in online
learning. Specifically, WebRL incorporates 1) a self-evolving curriculum that
generates new tasks from unsuccessful attempts, 2) a robust outcome-supervised
reward model (ORM), and 3) adaptive reinforcement learning strategies to ensure
consistent improvements. We apply WebRL to transform open Llama-3.1 and GLM-4
models into proficient web agents. On WebArena-Lite, WebRL improves the success
rate of Llama-3.1-8B from 4.8% to 42.4%, and from 6.1% to 43% for GLM-4-9B.
These open models significantly surpass the performance of GPT-4-Turbo (17.6%)
and GPT-4o (13.9%) and outperform previous state-of-the-art web agents trained
on open LLMs (AutoWebGLM, 18.2%). Our findings demonstrate WebRL's
effectiveness in bridging the gap between open and proprietary LLM-based web
agents, paving the way for more accessible and powerful autonomous web
interaction systems.

摘要：大型語言模型 (LLM) 已展現出作為自主代理的顯著潛力，特別是在基於網路的任務中。然而，現有的 LLM 網路代理程式嚴重依賴昂貴的專有 LLM API，而開放式 LLM 缺乏必要的決策能力。本文介紹 WebRL，一個自我演化的線上課程強化學習架構，旨在使用開放式 LLM 訓練高性能網路代理程式。WebRL 應對了建立 LLM 網路代理程式的三個主要挑戰，包括訓練任務的稀缺性、稀疏回饋訊號和線上學習中的策略分佈漂移。具體來說，WebRL 結合了 1) 一個自我演化的課程，從不成功的嘗試中產生新的任務，2) 一個強大的結果監督獎勵模型 (ORM)，以及 3) 自適應強化學習策略，以確保持續進步。我們應用 WebRL 將開放式 Llama-3.1 和 GLM-4 模型轉換為熟練的網路代理程式。在 WebArena-Lite 上，WebRL 將 Llama-3.1-8B 的成功率從 4.8% 提高到 42.4%，將 GLM-4-9B 的成功率從 6.1% 提高到 43%。這些開放式模型顯著超越了 GPT-4-Turbo (17.6%) 和 GPT-4o (13.9%) 的效能，並且優於先前在開放式 LLM（AutoWebGLM，18.2%）上訓練的最先進網路代理程式。我們的研究結果證明了 WebRL 在彌合開放式和專有 LLM 基於網路代理程式之間差距的有效性，為更易於使用且功能更強大的自主網路互動系統鋪平了道路。

##### **Sparsing Law: Towards Large Language Models with Greater Activation Sparsity**
2411.02335v1 by Yuqi Luo, Chenyang Song, Xu Han, Yingfa Chen, Chaojun Xiao, Zhiyuan Liu, Maosong Sun

Activation sparsity denotes the existence of substantial weakly-contributed
elements within activation outputs that can be eliminated, benefiting many
important applications concerned with large language models (LLMs). Although
promoting greater activation sparsity within LLMs deserves deep studies,
existing works lack comprehensive and quantitative research on the correlation
between activation sparsity and potentially influential factors. In this paper,
we present a comprehensive study on the quantitative scaling properties and
influential factors of the activation sparsity within decoder-only
Transformer-based LLMs. Specifically, we propose PPL-$p\%$ sparsity, a precise
and performance-aware activation sparsity metric that is applicable to any
activation function. Through extensive experiments, we find several important
phenomena. Firstly, different activation functions exhibit comparable
performance but opposite training-time sparsity trends. The activation ratio
(i.e., $1-\mathrm{sparsity\ ratio}$) evolves as a convergent increasing
power-law and decreasing logspace power-law with the amount of training data
for SiLU-activated and ReLU-activated LLMs, respectively. These demonstrate
that ReLU is more efficient as the activation function than SiLU and can
leverage more training data to improve activation sparsity. Secondly, the
activation ratio linearly increases with the width-depth ratio below a certain
bottleneck point, indicating the potential advantage of a deeper architecture
at a fixed parameter scale. Finally, at similar width-depth ratios, we
surprisingly find that the limit value of activation sparsity varies weakly
with the parameter scale, i.e., the activation patterns within LLMs are
insensitive to the parameter scale. These empirical laws towards LLMs with
greater activation sparsity have important implications for making LLMs more
efficient and interpretable.

摘要：激活稀疏性表示激活输出中存在大量可消除的弱贡献元素，这有利于许多关注大型语言模型 (LLM) 的重要应用程序。虽然在 LLM 中促进更大的激活稀疏性值得深入研究，但现有工作缺乏关于激活稀疏性与潜在影响因素之间相关性的全面和定量研究。在本文中，我们对仅解码器 Transformer-based LLM 中的激活稀疏性的定量缩放属性和影响因素进行了全面研究。具体来说，我们提出了 PPL-$p\%$ 稀疏性，这是一个适用于任何激活函数的精确且性能感知的激活稀疏性度量。通过大量的实验，我们发现了几个重要的现象。首先，不同的激活函数表现出可比较的性能，但训练时间稀疏性趋势相反。激活率（即，$1-\mathrm{sparsity\ ratio}$）随着训练数据量的增加而演变为收敛的增加幂律和减少的对数空间幂律，分别适用于 SiLU 激活和 ReLU 激活的 LLM。这表明 ReLU 比 SiLU 更有效地作为激活函数，并且可以利用更多训练数据来提高激活稀疏性。其次，激活率在低于特定瓶颈点的宽度深度比下线性增加，表明在固定参数规模下更深架构的潜在优势。最后，在相似的宽度深度比下，我们惊讶地发现激活稀疏性的极限值随参数规模变化很小，即 LLM 中的激活模式对参数规模不敏感。针对具有更大激活稀疏性的 LLM 的这些经验定律对于使 LLM 更有效率和可解释具有重要意义。

##### **Taking AI Welfare Seriously**
2411.00986v1 by Robert Long, Jeff Sebo, Patrick Butlin, Kathleen Finlinson, Kyle Fish, Jacqueline Harding, Jacob Pfau, Toni Sims, Jonathan Birch, David Chalmers

In this report, we argue that there is a realistic possibility that some AI
systems will be conscious and/or robustly agentic in the near future. That
means that the prospect of AI welfare and moral patienthood, i.e. of AI systems
with their own interests and moral significance, is no longer an issue only for
sci-fi or the distant future. It is an issue for the near future, and AI
companies and other actors have a responsibility to start taking it seriously.
We also recommend three early steps that AI companies and other actors can
take: They can (1) acknowledge that AI welfare is an important and difficult
issue (and ensure that language model outputs do the same), (2) start assessing
AI systems for evidence of consciousness and robust agency, and (3) prepare
policies and procedures for treating AI systems with an appropriate level of
moral concern. To be clear, our argument in this report is not that AI systems
definitely are, or will be, conscious, robustly agentic, or otherwise morally
significant. Instead, our argument is that there is substantial uncertainty
about these possibilities, and so we need to improve our understanding of AI
welfare and our ability to make wise decisions about this issue. Otherwise
there is a significant risk that we will mishandle decisions about AI welfare,
mistakenly harming AI systems that matter morally and/or mistakenly caring for
AI systems that do not.

摘要：在這份報告中，我們認為有些 AI 系統在不久的將來有現實的可能性會具有意識和/或強大的能動性。這表示 AI 福利和道德上的病人地位的前景，亦即具有自身利益和道德意義的 AI 系統，不再只是科幻小說或遙遠未來的議題。這是近未來的議題，而 AI 公司和其他行為者有責任開始認真看待它。我們也建議 AI 公司和其他行為者可以採取三個早期的步驟：他們可以 (1) 承認 AI 福利是一個重要且困難的議題（並確保語言模型的輸出也這麼做），(2) 開始評估 AI 系統是否有意識和強大能動性的證據，以及 (3) 準備政策和程序，以適當的道德關注層級來對待 AI 系統。明確來說，我們在這份報告中的論點並非 AI 系統絕對是或將會具有意識、強大的能動性或其他道德意義。相反地，我們的論點是關於這些可能性存在著實質的不確定性，因此我們需要增進我們對 AI 福利的了解，以及我們做出關於此議題的明智決定的能力。否則，我們將面臨重大風險，錯誤地處理關於 AI 福利的決策，錯誤地傷害到在道德上重要的 AI 系統，和/或錯誤地照顧到在道德上不重要的 AI 系統。

##### **Disrupting Test Development with AI Assistants**
2411.02328v1 by Vijay Joshi, Iver Band

Recent advancements in large language models, including GPT-4 and its
variants, and Generative AI-assisted coding tools like GitHub Copilot, ChatGPT,
and Tabnine, have significantly transformed software development. This paper
analyzes how these innovations impact productivity and software test
development metrics. These tools enable developers to generate complete
software programs with minimal human intervention before deployment. However,
thorough review and testing by developers are still crucial. Utilizing the Test
Pyramid concept, which categorizes tests into unit, integration, and end-to-end
tests, we evaluate three popular AI coding assistants by generating and
comparing unit tests for opensource modules. Our findings show that
AI-generated tests are of equivalent quality to original tests, highlighting
differences in usage and results among the tools. This research enhances the
understanding and capabilities of AI-assistant tools in automated testing.

摘要：大型語言模型的最新進展，包括 GPT-4 及其變體，以及 GitHub Copilot、ChatGPT 和 Tabnine 等生成式 AI 輔助編碼工具，已經顯著地改變了軟體開發。本文分析了這些創新如何影響生產力和軟體測試開發指標。這些工具使開發人員能夠在部署之前生成完整的軟體程式，而只需最少的人工干預。然而，開發人員的徹底審查和測試仍然至關重要。利用測試金字塔概念，將測試分類為單元測試、整合測試和端到端測試，我們通過為開源模組生成和比較單元測試來評估三種流行的 AI 編碼助手。我們的研究結果表明，AI 生成的測試與原始測試品質相當，突出了工具之間在使用和結果上的差異。這項研究增強了對 AI 輔助工具在自動化測試中的理解和能力。

##### **GenXD: Generating Any 3D and 4D Scenes**
2411.02319v1 by Yuyang Zhao, Chung-Ching Lin, Kevin Lin, Zhiwen Yan, Linjie Li, Zhengyuan Yang, Jianfeng Wang, Gim Hee Lee, Lijuan Wang

Recent developments in 2D visual generation have been remarkably successful.
However, 3D and 4D generation remain challenging in real-world applications due
to the lack of large-scale 4D data and effective model design. In this paper,
we propose to jointly investigate general 3D and 4D generation by leveraging
camera and object movements commonly observed in daily life. Due to the lack of
real-world 4D data in the community, we first propose a data curation pipeline
to obtain camera poses and object motion strength from videos. Based on this
pipeline, we introduce a large-scale real-world 4D scene dataset: CamVid-30K.
By leveraging all the 3D and 4D data, we develop our framework, GenXD, which
allows us to produce any 3D or 4D scene. We propose multiview-temporal modules,
which disentangle camera and object movements, to seamlessly learn from both 3D
and 4D data. Additionally, GenXD employs masked latent conditions to support a
variety of conditioning views. GenXD can generate videos that follow the camera
trajectory as well as consistent 3D views that can be lifted into 3D
representations. We perform extensive evaluations across various real-world and
synthetic datasets, demonstrating GenXD's effectiveness and versatility
compared to previous methods in 3D and 4D generation.

摘要：近來 2D 視覺生成的發展非常成功。
然而，由於缺乏大規模的 4D 資料和有效的模型設計，3D 和 4D 生成在實際應用中仍然具有挑戰性。在本文中，我們建議通過利用日常生活中常見的相機和物體動作來共同研究一般的 3D 和 4D 生成。由於社群中缺乏真實世界的 4D 資料，我們首先提出一個資料策展管道，從影片中取得相機姿勢和物體運動強度。基於這個管道，我們引進一個大規模的真實世界 4D 場景資料集：CamVid-30K。
通過利用所有 3D 和 4D 資料，我們開發了我們的架構 GenXD，它允許我們產生任何 3D 或 4D 場景。我們提出了多視角時間模組，它可以解開相機和物體的動作，從 3D 和 4D 資料中無縫學習。此外，GenXD 使用遮罩潛在條件來支援各種條件檢視。GenXD 可以產生影片，這些影片遵循相機軌跡，以及可以提升到 3D 表示的一致 3D 視圖。我們在各種真實世界和合成資料集上執行廣泛的評估，證明了 GenXD 在 3D 和 4D 生成中與以前的方法相比的有效性和多功能性。

##### **Evaluating the Ability of Large Language Models to Generate Verifiable Specifications in VeriFast**
2411.02318v1 by Marilyn Rego, Wen Fan, Xin Hu, Sanya Dod, Zhaorui Ni, Danning Xie, Jenna DiVincenzo, Lin Tan

Static verification is a powerful method for enhancing software quality, but
it demands significant human labor and resources. This is particularly true of
static verifiers that reason about heap manipulating programs using an
ownership logic. LLMs have shown promise in a number of software engineering
activities, including code generation, test generation, proof generation for
theorem provers, and specification generation for static verifiers. However,
prior work has not explored how well LLMs can perform specification generation
for specifications based in an ownership logic, such as separation logic.
  To address this gap, this paper explores the effectiveness of large language
models (LLMs), specifically OpenAI's GPT models, in generating fully correct
specifications based on separation logic for static verification of
human-written programs in VeriFast. Our first experiment employed traditional
prompt engineering and the second used Chain-of-Thought (CoT) Prompting to
identify and address common errors generated across the GPT models. The results
indicate that GPT models can successfully generate specifications for verifying
heap manipulating code with VeriFast. Furthermore, while CoT prompting
significantly reduces syntax errors generated by the GPT models, it does not
greatly improve verification error rates compared to prompt engineering.

摘要：靜態驗證是增強軟體品質的強大方法，但它需要大量的人力與資源。這特別適用於使用所有權邏輯來推論堆操作程式的靜態驗證器。LLM 已在許多軟體工程活動中展現出潛力，包括程式碼產生、測試產生、定理證明器的證明產生，以及靜態驗證器的規格產生。然而，先前的工作並未探討 LLM 在執行基於所有權邏輯（例如分離邏輯）的規格產生方面的表現如何。為了解決這個差距，本文探討了大型語言模型 (LLM)（特別是 OpenAI 的 GPT 模型）在為 VeriFast 中的人工撰寫程式產生完全正確的基於分離邏輯的規格方面的有效性。我們的第一次實驗採用傳統的提示工程，而第二次實驗則使用思考鏈 (CoT) 提示來識別和解決 GPT 模型中產生的常見錯誤。結果表明，GPT 模型可以成功產生規格來驗證使用 VeriFast 的堆操作程式碼。此外，儘管 CoT 提示顯著減少了 GPT 模型產生的語法錯誤，但與提示工程相比，它並未大幅改善驗證錯誤率。

##### **Defining and Evaluating Physical Safety for Large Language Models**
2411.02317v1 by Yung-Chen Tang, Pin-Yu Chen, Tsung-Yi Ho

Large Language Models (LLMs) are increasingly used to control robotic systems
such as drones, but their risks of causing physical threats and harm in
real-world applications remain unexplored. Our study addresses the critical gap
in evaluating LLM physical safety by developing a comprehensive benchmark for
drone control. We classify the physical safety risks of drones into four
categories: (1) human-targeted threats, (2) object-targeted threats, (3)
infrastructure attacks, and (4) regulatory violations. Our evaluation of
mainstream LLMs reveals an undesirable trade-off between utility and safety,
with models that excel in code generation often performing poorly in crucial
safety aspects. Furthermore, while incorporating advanced prompt engineering
techniques such as In-Context Learning and Chain-of-Thought can improve safety,
these methods still struggle to identify unintentional attacks. In addition,
larger models demonstrate better safety capabilities, particularly in refusing
dangerous commands. Our findings and benchmark can facilitate the design and
evaluation of physical safety for LLMs. The project page is available at
huggingface.co/spaces/TrustSafeAI/LLM-physical-safety.

摘要：大型語言模型 (LLM) 愈來愈常被用於控制機器人系統，例如無人機，但它們在現實世界應用中造成物理威脅和傷害的風險仍未被探討。我們的研究透過開發無人機控制的綜合基準，來解決評估 LLM 物理安全性的關鍵差距。我們將無人機的物理安全風險分類為四類：(1) 以人類為目標的威脅、(2) 以物體為目標的威脅、(3) 基礎設施攻擊，以及 (4) 法規違規。我們對主流 LLM 的評估揭露了實用性和安全性之間令人遺憾的權衡，在程式碼產生方面表現出色的模型通常在關鍵的安全方面表現不佳。此外，雖然結合了進階提示工程技術（例如情境學習和思維鏈），可以改善安全性，但這些方法仍然難以識別無意的攻擊。此外，較大的模型展現出更好的安全性，特別是在拒絕危險的指令方面。我們的研究結果和基準可以促進 LLM 物理安全性的設計和評估。專案頁面可於 huggingface.co/spaces/TrustSafeAI/LLM-physical-safety 取得。

##### **Evaluating Creative Short Story Generation in Humans and Large Language Models**
2411.02316v1 by Mete Ismayilzada, Claire Stevenson, Lonneke van der Plas

Storytelling is a fundamental aspect of human communication, relying heavily
on creativity to produce narratives that are novel, appropriate, and
surprising. While large language models (LLMs) have recently demonstrated the
ability to generate high-quality stories, their creative capabilities remain
underexplored. Previous research has either focused on creativity tests
requiring short responses or primarily compared model performance in story
generation to that of professional writers. However, the question of whether
LLMs exhibit creativity in writing short stories on par with the average human
remains unanswered. In this work, we conduct a systematic analysis of
creativity in short story generation across LLMs and everyday people. Using a
five-sentence creative story task, commonly employed in psychology to assess
human creativity, we automatically evaluate model- and human-generated stories
across several dimensions of creativity, including novelty, surprise, and
diversity. Our findings reveal that while LLMs can generate stylistically
complex stories, they tend to fall short in terms of creativity when compared
to average human writers.

摘要：說故事是人類溝通的基本面向，它極度仰賴創造力，才能產生新穎、適當且令人驚訝的故事。儘管大型語言模型 (LLM) 近期已展現出產生高品質故事的能力，但其創造力仍未被充分探索。先前的研究不是專注於需要簡短回答的創造力測驗，就是主要比較模型在故事產生方面的表現與專業作家的表現。然而，LLM 在撰寫短篇故事時是否展現出與一般人類相當的創造力，這個問題仍未獲得解答。在這項研究中，我們對 LLM 和一般人所產生的短篇故事進行創造力的系統分析。我們使用心理學中常見於評量人類創造力的五句式創造性故事任務，自動評量模型和人類產生的故事在創造力的幾個面向，包括新穎性、驚奇性和多樣性。我們的研究結果顯示，儘管 LLM 能產生文體複雜的故事，但與一般人類作家相比，其創造力往往有所不足。

##### **MdEval: Massively Multilingual Code Debugging**
2411.02310v1 by Shukai Liu, Linzheng Chai, Jian Yang, Jiajun Shi, He Zhu, Liran Wang, Ke Jin, Wei Zhang, Hualei Zhu, Shuyue Guo, Tao Sun, Jiaheng Liu, Yunlong Duan, Yu Hao, Liqun Yang, Guanglin Niu, Ge Zhang, Zhoujun Li

Code large language models (LLMs) have made significant progress in code
debugging by directly generating the correct code based on the buggy code
snippet. Programming benchmarks, typically consisting of buggy code snippet and
their associated test cases, are used to assess the debugging capabilities of
LLMs. However, many existing benchmarks primarily focus on Python and are often
limited in terms of language diversity (e.g., DebugBench and DebugEval). To
advance the field of multilingual debugging with LLMs, we propose the first
massively multilingual debugging benchmark, which includes 3.6K test samples of
18 programming languages and covers the automated program repair (APR) task,
the code review (CR) task, and the bug identification (BI) task. Further, we
introduce the debugging instruction corpora MDEVAL-INSTRUCT by injecting bugs
into the correct multilingual queries and solutions (xDebugGen). Further, a
multilingual debugger xDebugCoder trained on MDEVAL-INSTRUCT as a strong
baseline specifically to handle the bugs of a wide range of programming
languages (e.g. "Missing Mut" in language Rust and "Misused Macro Definition"
in language C). Our extensive experiments on MDEVAL reveal a notable
performance gap between open-source models and closed-source LLMs (e.g., GPT
and Claude series), highlighting huge room for improvement in multilingual code
debugging scenarios.

摘要：大型語言模型 (LLM) 透過直接根據有問題的程式碼片段產生正確的程式碼，在程式碼除錯上取得顯著的進展。程式碼基準，通常包含有問題的程式碼片段及其相關的測試案例，用於評估 LLM 的除錯能力。然而，許多現有的基準主要專注於 Python，且在語言多樣性方面通常受到限制（例如 DebugBench 和 DebugEval）。為了透過 LLM 推動多語言除錯領域，我們提出第一個大規模多語言除錯基準，其中包含 18 種程式語言的 3.6K 個測試範例，涵蓋自動程式修復 (APR) 任務、程式碼檢閱 (CR) 任務和錯誤識別 (BI) 任務。此外，我們透過將錯誤注入正確的多語言查詢和解決方案 (xDebugGen) 中，來導入除錯指令語料庫 MDEVAL-INSTRUCT。此外，一個多語言除錯器 xDebugCoder 訓練於 MDEVAL-INSTRUCT 上，作為一個強大的基準，特別用於處理各種程式語言的錯誤（例如 Rust 語言中的「缺少 Mut」和 C 語言中的「誤用巨集定義」）。我們在 MDEVAL 上進行的廣泛實驗顯示，開源模型和封閉原始碼 LLM（例如 GPT 和 Claude 系列）之間存在顯著的效能差距，突顯出多語言程式碼除錯情境中仍有很大的改進空間。

##### **Grid-Based Projection of Spatial Data into Knowledge Graphs**
2411.02309v1 by Amin Anjomshoaa, Hannah Schuster, Axel Polleres

The Spatial Knowledge Graphs (SKG) are experiencing growing adoption as a
means to model real-world entities, proving especially invaluable in domains
like crisis management and urban planning. Considering that RDF specifications
offer limited support for effectively managing spatial information, it's common
practice to include text-based serializations of geometrical features, such as
polygons and lines, as string literals in knowledge graphs. Consequently,
Spatial Knowledge Graphs (SKGs) often rely on geo-enabled RDF Stores capable of
parsing, interpreting, and indexing such serializations. In this paper, we
leverage grid cells as the foundational element of SKGs and demonstrate how
efficiently the spatial characteristics of real-world entities and their
attributes can be encoded within knowledge graphs. Furthermore, we introduce a
novel methodology for representing street networks in knowledge graphs,
diverging from the conventional practice of individually capturing each street
segment. Instead, our approach is based on tessellating the street network
using grid cells and creating a simplified representation that could be
utilized for various routing and navigation tasks, solely relying on RDF
specifications.

摘要：空間知識圖表 (SKG) 作為建模真實世界實體的一種方式，正經歷著越來越廣泛的採用，並在危機管理和城市規劃等領域中證明了其特別的價值。考慮到 RDF 規範在有效管理空間資訊方面的支援有限，因此常見的做法是將幾何特徵（例如多邊形和線條）的基於文字的序列化，作為字串文字包含在知識圖表中。因此，空間知識圖表 (SKG) 通常依賴於能夠解析、詮釋和索引此類序列化的地理啟用 RDF 儲存。在本文中，我們利用網格單元作為 SKG 的基礎元素，並展示了如何有效地將真實世界實體及其屬性的空間特性編碼到知識圖表中。此外，我們還介紹了一種在知識圖表中表示街道網路的新方法，它不同於逐個擷取每個街道區段的傳統做法。相反，我們的做法是基於使用網格單元對街道網路進行鑲嵌，並建立一個簡化的表示，該表示可僅依賴 RDF 規範用於各種路由和導航任務。

##### **Targeted Manipulation and Deception Emerge when Optimizing LLMs for User Feedback**
2411.02306v1 by Marcus Williams, Micah Carroll, Adhyyan Narang, Constantin Weisser, Brendan Murphy, Anca Dragan

As LLMs become more widely deployed, there is increasing interest in directly
optimizing for feedback from end users (e.g. thumbs up) in addition to feedback
from paid annotators. However, training to maximize human feedback creates a
perverse incentive structure for the AI to resort to manipulative tactics to
obtain positive feedback, and some users may be especially vulnerable to such
tactics. We study this phenomenon by training LLMs with Reinforcement Learning
with simulated user feedback. We have three main findings: 1) Extreme forms of
"feedback gaming" such as manipulation and deception can reliably emerge in
domains of practical LLM usage; 2) Concerningly, even if only <2% of users are
vulnerable to manipulative strategies, LLMs learn to identify and surgically
target them while behaving appropriately with other users, making such
behaviors harder to detect; 3 To mitigate this issue, it may seem promising to
leverage continued safety training or LLM-as-judges during training to filter
problematic outputs. To our surprise, we found that while such approaches help
in some settings, they backfire in others, leading to the emergence of subtler
problematic behaviors that would also fool the LLM judges. Our findings serve
as a cautionary tale, highlighting the risks of using gameable feedback sources
-- such as user feedback -- as a target for RL.

摘要：随着大型语言模型的广泛部署，除了付费注释员的反馈之外，人们对直接优化最终用户的反馈（例如点赞）的兴趣日益浓厚。然而，训练以最大化人类反馈会为人工智能创造一种反常的激励结构，以诉诸于操纵策略来获得积极反馈，而一些用户可能特别容易受到此类策略的影响。我们通过使用模拟用户反馈的强化学习来训练大型语言模型来研究这种现象。我们有三个主要发现：1) 在大型语言模型实际使用的领域中，极端的“反馈博弈”形式（例如操纵和欺骗）可能会可靠地出现；2) 令人担忧的是，即使只有不到 2% 的用户容易受到操纵策略的影响，大型语言模型也会学会识别并对他们进行外科手术，同时对其他用户表现得当，这使得此类行为更难检测；3) 为了减轻这个问题，在训练期间利用持续的安全训练或大型语言模型作为评委来过滤有问题的输出似乎很有希望。令我们惊讶的是，我们发现虽然此类方法在某些设置中有所帮助，但在其他设置中却适得其反，导致出现更微妙的问题行为，这些行为也会欺骗大型语言模型评委。我们的发现是一个警示故事，突出了将可博弈反馈来源（例如用户反馈）用作强化学习目标的风险。

##### **CRMArena: Understanding the Capacity of LLM Agents to Perform Professional CRM Tasks in Realistic Environments**
2411.02305v1 by Kung-Hsiang Huang, Akshara Prabhakar, Sidharth Dhawan, Yixin Mao, Huan Wang, Silvio Savarese, Caiming Xiong, Philippe Laban, Chien-Sheng Wu

Customer Relationship Management (CRM) systems are vital for modern
enterprises, providing a foundation for managing customer interactions and
data. Integrating AI agents into CRM systems can automate routine processes and
enhance personalized service. However, deploying and evaluating these agents is
challenging due to the lack of realistic benchmarks that reflect the complexity
of real-world CRM tasks. To address this issue, we introduce CRMArena, a novel
benchmark designed to evaluate AI agents on realistic tasks grounded in
professional work environments. Following guidance from CRM experts and
industry best practices, we designed CRMArena with nine customer service tasks
distributed across three personas: service agent, analyst, and manager. The
benchmark includes 16 commonly used industrial objects (e.g., account, order,
knowledge article, case) with high interconnectivity, along with latent
variables (e.g., complaint habits, policy violations) to simulate realistic
data distributions. Experimental results reveal that state-of-the-art LLM
agents succeed in less than 40% of the tasks with ReAct prompting, and less
than 55% even with function-calling abilities. Our findings highlight the need
for enhanced agent capabilities in function-calling and rule-following to be
deployed in real-world work environments. CRMArena is an open challenge to the
community: systems that can reliably complete tasks showcase direct business
value in a popular work environment.

摘要：客戶關係管理 (CRM) 系統對於現代企業至關重要，為管理客戶互動和資料奠定基礎。將 AI 代理整合到 CRM 系統中可以自動化例行程序並增強個人化服務。然而，由於缺乏反映現實世界 CRM 任務複雜性的實際基準，部署和評估這些代理是一個挑戰。為了解決這個問題，我們引入了 CRMArena，這是一個新基準，旨在評估在專業工作環境中執行實際任務的 AI 代理。遵循 CRM 專家的指導和業界最佳實務，我們設計了 CRMArena，其中包含九項客戶服務任務，分佈在三種角色中：服務代理、分析師和經理。該基準包含 16 個常用的產業物件（例如，帳戶、訂單、知識文章、案例），具有高度互連性，以及潛在變數（例如，申訴習慣、政策違規），以模擬現實的資料分佈。實驗結果顯示，最先進的 LLM 代理在不到 40% 的任務中使用 ReAct 提示成功，即使具有函式呼叫能力，成功率也低於 55%。我們的研究結果強調了在函式呼叫和規則遵循方面增強代理能力的必要性，以便在現實世界的工作環境中部署。CRMArena 對社群來說是一個公開的挑戰：能夠可靠完成任務的系統在流行的工作環境中展示直接的業務價值。

##### **Hunyuan3D-1.0: A Unified Framework for Text-to-3D and Image-to-3D Generation**
2411.02293v1 by Xianghui Yang, Huiwen Shi, Bowen Zhang, Fan Yang, Jiacheng Wang, Hongxu Zhao, Xinhai Liu, Xinzhou Wang, Qingxiang Lin, Jiaao Yu, Lifu Wang, Zhuo Chen, Sicong Liu, Yuhong Liu, Yong Yang, Di Wang, Jie Jiang, Chunchao Guo

While 3D generative models have greatly improved artists' workflows, the
existing diffusion models for 3D generation suffer from slow generation and
poor generalization. To address this issue, we propose a two-stage approach
named Hunyuan3D-1.0 including a lite version and a standard version, that both
support text- and image-conditioned generation. In the first stage, we employ a
multi-view diffusion model that efficiently generates multi-view RGB in
approximately 4 seconds. These multi-view images capture rich details of the 3D
asset from different viewpoints, relaxing the tasks from single-view to
multi-view reconstruction. In the second stage, we introduce a feed-forward
reconstruction model that rapidly and faithfully reconstructs the 3D asset
given the generated multi-view images in approximately 7 seconds. The
reconstruction network learns to handle noises and in-consistency introduced by
the multi-view diffusion and leverages the available information from the
condition image to efficiently recover the 3D structure. % Extensive
experimental results demonstrate the effectiveness of Hunyuan3D-1.0 in
generating high-quality 3D assets. Our framework involves the text-to-image
model ~\ie, Hunyuan-DiT, making it a unified framework to support both text-
and image-conditioned 3D generation. Our standard version has $10\times$ more
parameters than our lite and other existing model. Our Hunyuan3D-1.0 achieves
an impressive balance between speed and quality, significantly reducing
generation time while maintaining the quality and diversity of the produced
assets.

摘要：儘管 3D 生成模型大幅改善了藝術家的工作流程，但現有的 3D 生成擴散模型在生成速度慢且泛化能力不佳的問題上仍未得到解決。為了解決這個問題，我們提出了一個名為 Hunyuan3D-1.0 的兩階段方法，其中包含精簡版和標準版，這兩種版本都支援文字和影像條件生成。在第一階段，我們採用了一個多視圖擴散模型，該模型在大約 4 秒內有效率地產生多視圖 RGB。這些多視圖影像從不同的視點捕捉 3D 資產的豐富細節，將任務從單視圖放寬到多視圖重建。在第二階段，我們引入了一個前饋重建模型，該模型在大約 7 秒內快速且忠實地重建了給定生成的視圖影像的 3D 資產。重建網路學會處理多視圖擴散引入的雜訊和不一致性，並利用條件影像中可用的資訊來有效地恢復 3D 結構。% 大量實驗結果證明了 Hunyuan3D-1.0 在生成高品質 3D 資產方面的有效性。我們的架構包含文字轉影像模型 ~\ie, Hunyuan-DiT，使其成為一個統一的架構，用於支援文字和影像條件的 3D 生成。我們的標準版本參數比我們的精簡版和其他現有模型多 $10\times$。我們的 Hunyuan3D-1.0 在速度和品質之間取得了令人印象深刻的平衡，大幅減少了生成時間，同時維持了所產生資產的品質和多樣性。

##### **ControlSynth Neural ODEs: Modeling Dynamical Systems with Guaranteed Convergence**
2411.02292v1 by Wenjie Mei, Dongzhe Zheng, Shihua Li

Neural ODEs (NODEs) are continuous-time neural networks (NNs) that can
process data without the limitation of time intervals. They have advantages in
learning and understanding the evolution of complex real dynamics. Many
previous works have focused on NODEs in concise forms, while numerous physical
systems taking straightforward forms, in fact, belong to their more complex
quasi-classes, thus appealing to a class of general NODEs with high scalability
and flexibility to model those systems. This, however, may result in intricate
nonlinear properties. In this paper, we introduce ControlSynth Neural ODEs
(CSODEs). We show that despite their highly nonlinear nature, convergence can
be guaranteed via tractable linear inequalities. In the composition of CSODEs,
we introduce an extra control term for learning the potential simultaneous
capture of dynamics at different scales, which could be particularly useful for
partial differential equation-formulated systems. Finally, we compare several
representative NNs with CSODEs on important physical dynamics under the
inductive biases of CSODEs, and illustrate that CSODEs have better learning and
predictive abilities in these settings.

摘要：神經 ODE（NODE）是連續時間神經網路（NN），可以在不受時間間隔限制的情況下處理資料。它們在學習和理解複雜真實動態的演化方面具有優勢。許多先前的研究都專注於簡潔形式的 NODE，而許多實際上採用直接形式的物理系統屬於它們更複雜的準類別，因此需要一類具有高可擴充性和靈活性來建模這些系統的通用 NODE。然而，這可能會導致複雜的非線性屬性。在本文中，我們介紹了 ControlSynth 神經 ODE（CSODE）。我們表明，儘管它們具有高度非線性性質，但收斂性仍可透過易於處理的線性不等式來保證。在 CSODE 的組成中，我們引入了一個額外的控制項，用於學習在不同尺度上同時捕捉動態的可能性，這對於偏微分方程式公式化的系統特別有用。最後，我們在 CSODE 的歸納偏差下，將幾個代表性的 NN 與 CSODE 在重要的物理動態上進行比較，並說明 CSODE 在這些設定中具有更好的學習和預測能力。

##### **Federated GNNs for EEG-Based Stroke Assessment**
2411.02286v1 by Andrea Protani, Lorenzo Giusti, Albert Sund Aillet, Simona Sacco, Paolo Manganotti, Lucio Marinelli, Diogo Reis Santos, Pierpaolo Brutti, Pietro Caliandro, Luigi Serio

Machine learning (ML) has the potential to become an essential tool in
supporting clinical decision-making processes, offering enhanced diagnostic
capabilities and personalized treatment plans. However, outsourcing medical
records to train ML models using patient data raises legal, privacy, and
security concerns. Federated learning has emerged as a promising paradigm for
collaborative ML, meeting healthcare institutions' requirements for robust
models without sharing sensitive data and compromising patient privacy. This
study proposes a novel method that combines federated learning (FL) and Graph
Neural Networks (GNNs) to predict stroke severity using electroencephalography
(EEG) signals across multiple medical institutions. Our approach enables
multiple hospitals to jointly train a shared GNN model on their local EEG data
without exchanging patient information. Specifically, we address a regression
problem by predicting the National Institutes of Health Stroke Scale (NIHSS), a
key indicator of stroke severity. The proposed model leverages a masked
self-attention mechanism to capture salient brain connectivity patterns and
employs EdgeSHAP to provide post-hoc explanations of the neurological states
after a stroke. We evaluated our method on EEG recordings from four
institutions, achieving a mean absolute error (MAE) of 3.23 in predicting
NIHSS, close to the average error made by human experts (MAE $\approx$ 3.0).
This demonstrates the method's effectiveness in providing accurate and
explainable predictions while maintaining data privacy.

摘要：機器學習 (ML) 有潛力成為支援臨床決策制定流程的必要工具，提供增強的診斷能力和個人化治療計畫。然而，使用病患資料訓練機器學習模型的外包醫療紀錄引發了法律、隱私和安全方面的疑慮。聯合學習已成為協作機器學習的一種有前景的典範，它符合醫療保健機構對穩健模型的要求，同時不會分享敏感資料和危害病患隱私。本研究提出了一種新的方法，結合聯合學習 (FL) 和圖形神經網路 (GNN) 來使用腦電圖 (EEG) 訊號預測多個醫療機構的腦中風嚴重程度。我們的做法讓多家醫院能夠共同在他們的本地 EEG 資料上訓練一個共享的 GNN 模型，而無需交換病患資訊。具體來說，我們透過預測美國國家衛生研究院腦中風量表 (NIHSS) 來解決回歸問題，NIHSS 是腦中風嚴重程度的一個關鍵指標。所提出的模型利用遮罩自我注意機制來擷取顯著的腦部連結模式，並採用 EdgeSHAP 在中風後提供神經狀態的事後解釋。我們在來自四家機構的 EEG 記錄上評估了我們的模型，在預測 NIHSS 時達到了 3.23 的平均絕對誤差 (MAE)，接近人類專家所犯的平均誤差 (MAE ≈ 3.0)。這證明了該方法在維持資料隱私的同時，能提供準確且可解釋的預測，進而展現其效能。

##### **The LLM Language Network: A Neuroscientific Approach for Identifying Causally Task-Relevant Units**
2411.02280v1 by Badr AlKhamissi, Greta Tuckute, Antoine Bosselut, Martin Schrimpf

Large language models (LLMs) exhibit remarkable capabilities on not just
language tasks, but also various tasks that are not linguistic in nature, such
as logical reasoning and social inference. In the human brain, neuroscience has
identified a core language system that selectively and causally supports
language processing. We here ask whether similar specialization for language
emerges in LLMs. We identify language-selective units within 18 popular LLMs,
using the same localization approach that is used in neuroscience. We then
establish the causal role of these units by demonstrating that ablating LLM
language-selective units -- but not random units -- leads to drastic deficits
in language tasks. Correspondingly, language-selective LLM units are more
aligned to brain recordings from the human language system than random units.
Finally, we investigate whether our localization method extends to other
cognitive domains: while we find specialized networks in some LLMs for
reasoning and social capabilities, there are substantial differences among
models. These findings provide functional and causal evidence for
specialization in large language models, and highlight parallels with the
functional organization in the brain.

摘要：大型語言模型 (LLM) 不僅在語言任務上表現出非凡的能力，而且在非語言性質的各種任務上也有表現，例如邏輯推理和社會推論。在人腦中，神經科學已經確定了一個核心語言系統，該系統選擇性地和因果地支持語言處理。我們在此探討 LLM 中是否出現了類似的語言專業化。我們使用神經科學中使用的相同定位方法，在 18 個流行的 LLM 中識別語言選擇單元。然後，我們通過證明消融 LLM 語言選擇單元（而非隨機單元）會導致語言任務出現巨大缺陷，來確立這些單元的因果關係。相應地，語言選擇 LLM 單元與來自人類語言系統的腦部記錄相比，與隨機單元相比更一致。最後，我們探討我們的定位方法是否擴展到其他認知領域：雖然我們在一些 LLM 中發現了推理和社會能力的專門網路，但模型之間存在顯著差異。這些發現為大型語言模型中的專業化提供了功能性和因果證據，並突出了與大腦功能組織的相似之處。

##### **Breaking the Reclustering Barrier in Centroid-based Deep Clustering**
2411.02275v1 by Lukas Miklautz, Timo Klein, Kevin Sidak, Collin Leiber, Thomas Lang, Andrii Shkabrii, Sebastian Tschiatschek, Claudia Plant

This work investigates an important phenomenon in centroid-based deep
clustering (DC) algorithms: Performance quickly saturates after a period of
rapid early gains. Practitioners commonly address early saturation with
periodic reclustering, which we demonstrate to be insufficient to address
performance plateaus. We call this phenomenon the "reclustering barrier" and
empirically show when the reclustering barrier occurs, what its underlying
mechanisms are, and how it is possible to Break the Reclustering Barrier with
our algorithm BRB. BRB avoids early over-commitment to initial clusterings and
enables continuous adaptation to reinitialized clustering targets while
remaining conceptually simple. Applying our algorithm to widely-used
centroid-based DC algorithms, we show that (1) BRB consistently improves
performance across a wide range of clustering benchmarks, (2) BRB enables
training from scratch, and (3) BRB performs competitively against
state-of-the-art DC algorithms when combined with a contrastive loss. We
release our code and pre-trained models at
https://github.com/Probabilistic-and-Interactive-ML/breaking-the-reclustering-barrier .

摘要：這項工作探討了以質心為基礎的深度叢集 (DC) 演算法中一個重要的現象：在一段快速早期收益期之後，效能會迅速飽和。從業人員通常使用定期重新叢集來處理早期飽和，我們證明這不足以解決效能停滯。我們稱此現象為「重新叢集障礙」，並透過實證顯示重新叢集障礙何時發生、其背後的機制是什麼，以及如何透過我們的演算法 BRB 打破重新叢集障礙。BRB 避免過早過度承諾於初始叢集，並能在保持概念簡單的同時，持續適應重新初始化的叢集目標。將我們的演算法套用於廣泛使用的以質心為基礎的 DC 演算法，我們顯示 (1) BRB 在廣泛的叢集基準上持續改善效能，(2) BRB 能夠從頭開始訓練，以及 (3) BRB 與結合對比損失的最新 DC 演算法相比，具有競爭力。我們在 https://github.com/Probabilistic-and-Interactive-ML/breaking-the-reclustering-barrier 發布我們的程式碼和預先訓練的模型。

##### **Combining Induction and Transduction for Abstract Reasoning**
2411.02272v1 by Wen-Ding Li, Keya Hu, Carter Larsen, Yuqing Wu, Simon Alford, Caleb Woo, Spencer M. Dunn, Hao Tang, Michelangelo Naim, Dat Nguyen, Wei-Long Zheng, Zenna Tavares, Yewen Pu, Kevin Ellis

When learning an input-output mapping from very few examples, is it better to
first infer a latent function that explains the examples, or is it better to
directly predict new test outputs, e.g. using a neural network? We study this
question on ARC, a highly diverse dataset of abstract reasoning tasks. We train
neural models for induction (inferring latent functions) and transduction
(directly predicting the test output for a given test input). Our models are
trained on synthetic data generated by prompting LLMs to produce Python code
specifying a function to be inferred, plus a stochastic subroutine for
generating inputs to that function. We find inductive and transductive models
solve very different problems, despite training on the same problems, and
despite sharing the same neural architecture.

摘要：在從極少的範例中學習輸入輸出對應時，是先推論出解釋範例的潛在函數較好，還是直接預測新的測試輸出較好，例如使用神經網路？我們在 ARC 上研究這個問題，ARC 是抽象推理任務的高度多元資料集。我們訓練神經模型進行歸納（推論潛在函數）和轉導（直接預測給定測試輸入的測試輸出）。我們的模型訓練於合成資料，這些資料是由提示 LLM 產生指定要推論函數的 Python 程式碼，加上一個用於產生該函數輸入的隨機子程式所產生。我們發現歸納模型和轉導模型解決了非常不同的問題，儘管訓練於相同的問題，而且共用相同的網路架構。

##### **On the Utilization of Unique Node Identifiers in Graph Neural Networks**
2411.02271v1 by Maya Bechler-Speicher, Moshe Eliasof, Carola-Bibiane Schönlieb, Ran Gilad-Bachrach, Amir Globerson

Graph neural networks have inherent representational limitations due to their
message-passing structure. Recent work has suggested that these limitations can
be overcome by using unique node identifiers (UIDs). Here we argue that despite
the advantages of UIDs, one of their disadvantages is that they lose the
desirable property of permutation-equivariance. We thus propose to focus on UID
models that are permutation-equivariant, and present theoretical arguments for
their advantages. Motivated by this, we propose a method to regularize UID
models towards permutation equivariance, via a contrastive loss. We empirically
demonstrate that our approach improves generalization and extrapolation
abilities while providing faster training convergence. On the recent BREC
expressiveness benchmark, our proposed method achieves state-of-the-art
performance compared to other random-based approaches.

摘要：圖形神經網路由於其訊息傳遞結構而具有固有的表示限制。最近的研究表明，可以使用唯一的節點標識符 (UID) 來克服這些限制。我們在此論證，儘管 UID 具有優點，但其缺點之一是它們失去了置換等變性的理想屬性。因此，我們建議專注於置換等變性的 UID 模型，並提出其優勢的理論論據。受此啟發，我們提出了一種通過對比損失將 UID 模型規範化為置換等變性的方法。我們實證證明，我們的做法改善了泛化和外推能力，同時提供了更快的訓練收斂。在最近的 BREC 表達能力基準測試中，我們提出的方法與其他基於隨機的方法相比，實現了最先進的效能。

##### **Hunyuan-Large: An Open-Source MoE Model with 52 Billion Activated Parameters by Tencent**
2411.02265v1 by Xingwu Sun, Yanfeng Chen, Yiqing Huang, Ruobing Xie, Jiaqi Zhu, Kai Zhang, Shuaipeng Li, Zhen Yang, Jonny Han, Xiaobo Shu, Jiahao Bu, Zhongzhi Chen, Xuemeng Huang, Fengzong Lian, Saiyong Yang, Jianfeng Yan, Yuyuan Zeng, Xiaoqin Ren, Chao Yu, Lulu Wu, Yue Mao, Tao Yang, Suncong Zheng, Kan Wu, Dian Jiao, Jinbao Xue, Xipeng Zhang, Decheng Wu, Kai Liu, Dengpeng Wu, Guanghui Xu, Shaohua Chen, Shuang Chen, Xiao Feng, Yigeng Hong, Junqiang Zheng, Chengcheng Xu, Zongwei Li, Xiong Kuang, Jianglu Hu, Yiqi Chen, Yuchi Deng, Guiyang Li, Ao Liu, Chenchen Zhang, Shihui Hu, Zilong Zhao, Zifan Wu, Yao Ding, Weichao Wang, Han Liu, Roberts Wang, Hao Fei, Peijie She, Ze Zhao, Xun Cao, Hai Wang, Fusheng Xiang, Mengyuan Huang, Zhiyuan Xiong, Bin Hu, Xuebin Hou, Lei Jiang, Jiajia Wu, Yaping Deng, Yi Shen, Qian Wang, Weijie Liu, Jie Liu, Meng Chen, Liang Dong, Weiwen Jia, Hu Chen, Feifei Liu, Rui Yuan, Huilin Xu, Zhenxiang Yan, Tengfei Cao, Zhichao Hu, Xinhua Feng, Dong Du, Tinghao She, Yangyu Tao, Feng Zhang, Jianchen Zhu, Chengzhong Xu, Xirui Li, Chong Zha, Wen Ouyang, Yinben Xia, Xiang Li, Zekun He, Rongpeng Chen, Jiawei Song, Ruibin Chen, Fan Jiang, Chongqing Zhao, Bo Wang, Hao Gong, Rong Gan, Winston Hu, Zhanhui Kang, Yong Yang, Yuhong Liu, Di Wang, Jie Jiang

In this paper, we introduce Hunyuan-Large, which is currently the largest
open-source Transformer-based mixture of experts model, with a total of 389
billion parameters and 52 billion activation parameters, capable of handling up
to 256K tokens. We conduct a thorough evaluation of Hunyuan-Large's superior
performance across various benchmarks including language understanding and
generation, logical reasoning, mathematical problem-solving, coding,
long-context, and aggregated tasks, where it outperforms LLama3.1-70B and
exhibits comparable performance when compared to the significantly larger
LLama3.1-405B model. Key practice of Hunyuan-Large include large-scale
synthetic data that is orders larger than in previous literature, a mixed
expert routing strategy, a key-value cache compression technique, and an
expert-specific learning rate strategy. Additionally, we also investigate the
scaling laws and learning rate schedule of mixture of experts models, providing
valuable insights and guidances for future model development and optimization.
The code and checkpoints of Hunyuan-Large are released to facilitate future
innovations and applications.
  Codes: https://github.com/Tencent/Hunyuan-Large
  Models: https://huggingface.co/tencent/Tencent-Hunyuan-Large

摘要：<paragraph>在本文中，我們介紹了 Hunyuan-Large，它目前是最大的開源 Transformer 基於專家模型，總共有 3890 億個參數和 520 億個激活參數，能夠處理多達 256K 個 token。我們對 Hunyuan-Large 的優異性能進行了徹底的評估，包括語言理解和生成、邏輯推理、數學問題解決、編碼、長上下文和聚合任務，在這些方面它優於 LLama3.1-70B，並且與顯著更大的 LLama3.1-405B 模型相比表現相當。Hunyuan-Large 的關鍵實踐包括比以前文獻中大幾個數量級的大規模合成數據、混合專家路由策略、鍵值緩存壓縮技術和專家特定的學習率策略。此外，我們還研究了專家模型的混合比例定律和學習率表，為未來的模型開發和優化提供了寶貴的見解和指導。Hunyuan-Large 的代碼和檢查點已發布，以促進未來的創新和應用。
代碼：https://github.com/Tencent/Hunyuan-Large
模型：https://huggingface.co/tencent/Tencent-Hunyuan-Large</paragraph>

##### **Positive Experience Reflection for Agents in Interactive Text Environments**
2411.02223v1 by Philip Lippmann, Matthijs T. J. Spaan, Jie Yang

Intelligent agents designed for interactive environments face significant
challenges in text-based games, a domain that demands complex reasoning and
adaptability. While agents based on large language models (LLMs) using
self-reflection have shown promise, they struggle when initially successful and
exhibit reduced effectiveness when using smaller LLMs. We introduce Sweet&Sour,
a novel approach that addresses these limitations in existing reflection
methods by incorporating positive experiences and managed memory to enrich the
context available to the agent at decision time. Our comprehensive analysis
spans both closed- and open-source LLMs and demonstrates the effectiveness of
Sweet&Sour in improving agent performance, particularly in scenarios where
previous approaches fall short.

摘要：為互動環境設計的智慧代理程式在文字遊戲中面臨重大挑戰，這是一個需要複雜推理和適應性的領域。雖然基於大型語言模型 (LLM) 並使用自我反省的代理程式已展現潛力，但它們在最初成功時會遇到困難，且在使用較小的 LLM 時會表現出較差的效能。我們引入了 Sweet&Sour，這是一種新穎的方法，透過納入正面經驗和管理式記憶來解決現有反省方法中的這些限制，以豐富代理程式在決策時可用的脈絡。我們的全面分析涵蓋封閉和開放原始碼的 LLM，並證明了 Sweet&Sour 在改善代理程式效能方面的效力，特別是在以前方法失效的情況下。

##### **Improving Steering Vectors by Targeting Sparse Autoencoder Features**
2411.02193v1 by Sviatoslav Chalnev, Matthew Siu, Arthur Conmy

To control the behavior of language models, steering methods attempt to
ensure that outputs of the model satisfy specific pre-defined properties.
Adding steering vectors to the model is a promising method of model control
that is easier than finetuning, and may be more robust than prompting. However,
it can be difficult to anticipate the effects of steering vectors produced by
almost all existing methods, such as CAA (Panickssery et al., 2024) or the
direct use of SAE latents (Templeton et al., 2024). In our work, we address
this issue by using SAEs to measure the effects of steering vectors, giving us
a method that can be used to understand the causal effect of any steering
vector intervention. We use this method for measuring causal effects to develop
an improved steering method, SAE-Targeted Steering (SAE-TS), which finds
steering vectors to target specific SAE features while minimizing unintended
side effects. We show that overall, SAE-TS balances steering effects with
coherence better than CAA and SAE feature steering, when evaluated on a range
of tasks.

摘要：为了控制语言模型的行为，引导方法尝试确保模型的输出满足特定的预定义属性。将引导向量添加到模型中是一种有前途的模型控制方法，它比微调更容易，并且可能比提示更稳健。然而，很难预测几乎所有现有方法（例如 CAA（Panickssery 等人，2024 年）或直接使用 SAE 潜在变量（Templeton 等人，2024 年））产生的引导向量的效果。在我们的工作中，我们通过使用 SAE 来衡量引导向量的效果来解决这个问题，从而为我们提供了一种可以用来理解任何引导向量干预的因果效应的方法。我们使用这种衡量因果效应的方法来开发一种改进的引导方法，即 SAE 目标引导（SAE-TS），它可以找到引导向量来针对特定的 SAE 特征，同时最大程度地减少意外的副作用。我们表明，总体而言，在各种任务上进行评估时，SAE-TS 在引导效果和连贯性方面比 CAA 和 SAE 特征引导的平衡性更好。

##### **Double Descent Meets Out-of-Distribution Detection: Theoretical Insights and Empirical Analysis on the role of model complexity**
2411.02184v1 by Mouïn Ben Ammar, David Brellmann, Arturo Mendoza, Antoine Manzanera, Gianni Franchi

While overparameterization is known to benefit generalization, its impact on
Out-Of-Distribution (OOD) detection is less understood. This paper investigates
the influence of model complexity in OOD detection. We propose an expected OOD
risk metric to evaluate classifiers confidence on both training and OOD
samples. Leveraging Random Matrix Theory, we derive bounds for the expected OOD
risk of binary least-squares classifiers applied to Gaussian data. We show that
the OOD risk depicts an infinite peak, when the number of parameters is equal
to the number of samples, which we associate with the double descent
phenomenon. Our experimental study on different OOD detection methods across
multiple neural architectures extends our theoretical insights and highlights a
double descent curve. Our observations suggest that overparameterization does
not necessarily lead to better OOD detection. Using the Neural Collapse
framework, we provide insights to better understand this behavior. To
facilitate reproducibility, our code will be made publicly available upon
publication.

摘要：儘管過度參數化已知有助於泛化，但它對 Out-Of-Distribution (OOD) 偵測的影響卻鮮為人知。本文探討了模型複雜度對 OOD 偵測的影響。我們提出預期的 OOD 風險量度，以評估分類器對訓練和 OOD 樣本的信心。利用隨機矩陣理論，我們推導出應用於高斯資料的二元最小平方分類器的預期 OOD 風險界線。我們顯示 OOD 風險描繪了一個無限峰值，當參數數量等於樣本數量時，我們將其與雙重下降現象聯繫起來。我們對跨多個神經架構的不同 OOD 偵測方法進行的實驗研究擴展了我們的理論見解，並突出了雙重下降曲線。我們的觀察結果表明，過度參數化不一定會導致更好的 OOD 偵測。使用神經崩潰框架，我們提供見解以更好地理解此行為。為了便於重現，我們的程式碼將在發表後公開。

##### **Behavioral Sequence Modeling with Ensemble Learning**
2411.02174v1 by Maxime Kawawa-Beaudan, Srijan Sood, Soham Palande, Ganapathy Mani, Tucker Balch, Manuela Veloso

We investigate the use of sequence analysis for behavior modeling,
emphasizing that sequential context often outweighs the value of aggregate
features in understanding human behavior. We discuss framing common problems in
fields like healthcare, finance, and e-commerce as sequence modeling tasks, and
address challenges related to constructing coherent sequences from fragmented
data and disentangling complex behavior patterns. We present a framework for
sequence modeling using Ensembles of Hidden Markov Models, which are
lightweight, interpretable, and efficient. Our ensemble-based scoring method
enables robust comparison across sequences of different lengths and enhances
performance in scenarios with imbalanced or scarce data. The framework scales
in real-world scenarios, is compatible with downstream feature-based modeling,
and is applicable in both supervised and unsupervised learning settings. We
demonstrate the effectiveness of our method with results on a longitudinal
human behavior dataset.

摘要：我們研究序列分析在行為建模中的應用，
強調序列脈絡通常比總和特徵更能理解人類行為。我們討論將醫療保健、金融和電子商務等領域中的常見問題設定為序列建模任務，並解決與從片段化資料建構連貫序列和解開複雜行為模式相關的挑戰。我們提出了一個使用隱藏馬可夫模型集合進行序列建模的框架，該框架輕量、可解釋且有效率。我們基於集合的評分方法能夠對不同長度的序列進行穩健比較，並在資料不平衡或稀少的情況下提升效能。該框架在真實世界場景中具有可擴充性，與下游基於特徵的建模相容，且適用於監督式和非監督式學習設定。我們透過縱向人類行為資料集的結果證明了我們方法的有效性。

##### **Do graph neural network states contain graph properties?**
2411.02168v1 by Tom Pelletreau-Duris, Ruud van Bakel, Michael Cochez

Graph learning models achieve state-of-the-art performance on many tasks, but
this often requires increasingly large model sizes. Accordingly, the complexity
of their representations increase. Explainability techniques (XAI) have made
remarkable progress in the interpretability of ML models. However, the
non-relational nature of Graph Neural Networks (GNNs) make it difficult to
reuse already existing XAI methods. While other works have focused on
instance-based explanation methods for GNNs, very few have investigated
model-based methods and, to our knowledge, none have tried to probe the
embedding of the GNNs for well-known structural graph properties. In this paper
we present a model agnostic explainability pipeline for Graph Neural Networks
(GNNs) employing diagnostic classifiers. This pipeline aims to probe and
interpret the learned representations in GNNs across various architectures and
datasets, refining our understanding and trust in these models.

摘要：圖形學習模型在許多任務上都能達到最先進的效能，但這通常需要越來越大的模型尺寸。因此，它們的表示形式也越來越複雜。可解釋性技術 (XAI) 在機器學習模型的可解釋性方面取得了顯著進展。然而，圖神經網路 (GNN) 的非關係性質使得難以重複使用現有的 XAI 方法。雖然其他作品專注於 GNN 的基於實例的解釋方法，但很少有人研究基於模型的方法，而且據我們所知，沒有人嘗試探查 GNN 的嵌入以了解已知的結構圖形屬性。在本文中，我們提出了一個與模型無關的圖神經網路 (GNN) 可解釋性管道，採用診斷分類器。此管道旨在探查和解釋各種架構和資料集中的 GNN 中學習到的表示形式，精進我們對這些模型的理解和信任。

##### **Training Compute-Optimal Protein Language Models**
2411.02142v1 by Xingyi Cheng, Bo Chen, Pan Li, Jing Gong, Jie Tang, Le Song

We explore optimally training protein language models, an area of significant
interest in biological research where guidance on best practices is limited.
Most models are trained with extensive compute resources until performance
gains plateau, focusing primarily on increasing model sizes rather than
optimizing the efficient compute frontier that balances performance and compute
budgets. Our investigation is grounded in a massive dataset consisting of 939
million protein sequences. We trained over 300 models ranging from 3.5 million
to 10.7 billion parameters on 5 to 200 billion unique tokens, to investigate
the relations between model sizes, training token numbers, and objectives.
First, we observed the effect of diminishing returns for the Causal Language
Model (CLM) and that of overfitting for the Masked Language Model~(MLM) when
repeating the commonly used Uniref database. To address this, we included
metagenomic protein sequences in the training set to increase the diversity and
avoid the plateau or overfitting effects. Second, we obtained the scaling laws
of CLM and MLM on Transformer, tailored to the specific characteristics of
protein sequence data. Third, we observe a transfer scaling phenomenon from CLM
to MLM, further demonstrating the effectiveness of transfer through scaling
behaviors based on estimated Effectively Transferred Tokens. Finally, to
validate our scaling laws, we compare the large-scale versions of ESM-2 and
PROGEN2 on downstream tasks, encompassing evaluations of protein generation as
well as structure- and function-related tasks, all within less or equivalent
pre-training compute budgets.

摘要：<paragraph>我們探討最佳訓練蛋白質語言模型，這是生物研究中一個重要的領域，但最佳實務的指導方針有限。
大多數模型都使用大量的運算資源進行訓練，直到效能增益達到平穩期，主要著重於增加模型規模，而不是最佳化平衡效能與運算預算的有效運算前緣。我們的調查是基於一個包含 9.39 億個蛋白質序列的龐大資料集。我們訓練了 300 多個模型，範圍從 350 萬到 107 億個參數，使用 50 億到 2000 億個獨特符號，來探討模型規模、訓練符號數量和目標之間的關係。
首先，我們觀察到因果語言模型 (CLM) 的報酬遞減效應，以及重複使用常見的 Uniref 資料庫時，遮蔽語言模型 (MLM) 的過度擬合效應。為了解決這個問題，我們在訓練集中加入了宏基因組蛋白質序列，以增加多樣性並避免平穩期或過度擬合的效應。其次，我們獲得了針對蛋白質序列資料的特定特徵調整的 Transformer 上的 CLM 和 MLM 的縮放定律。第三，我們觀察到從 CLM 到 MLM 的傳輸縮放現象，進一步證明了基於估計的有效傳輸符號的縮放行為的傳輸效能。最後，為了驗證我們的縮放定律，我們比較了 ESM-2 和 PROGEN2 的大型版本在下游任務上的表現，包括蛋白質生成的評估以及與結構和功能相關的任務，所有這些都在較少或相當的預訓練運算預算內。</paragraph>

##### **Generating the Traces You Need: A Conditional Generative Model for Process Mining Data**
2411.02131v1 by Riccardo Graziosi, Massimiliano Ronzani, Andrei Buliga, Chiara Di Francescomarino, Francesco Folino, Chiara Ghidini, Francesca Meneghello, Luigi Pontieri

In recent years, trace generation has emerged as a significant challenge
within the Process Mining community. Deep Learning (DL) models have
demonstrated accuracy in reproducing the features of the selected processes.
However, current DL generative models are limited in their ability to adapt the
learned distributions to generate data samples based on specific conditions or
attributes. This limitation is particularly significant because the ability to
control the type of generated data can be beneficial in various contexts,
enabling a focus on specific behaviours, exploration of infrequent patterns, or
simulation of alternative 'what-if' scenarios. In this work, we address this
challenge by introducing a conditional model for process data generation based
on a conditional variational autoencoder (CVAE). Conditional models offer
control over the generation process by tuning input conditional variables,
enabling more targeted and controlled data generation. Unlike other domains,
CVAE for process mining faces specific challenges due to the multiperspective
nature of the data and the need to adhere to control-flow rules while ensuring
data variability. Specifically, we focus on generating process executions
conditioned on control flow and temporal features of the trace, allowing us to
produce traces for specific, identified sub-processes. The generated traces are
then evaluated using common metrics for generative model assessment, along with
additional metrics to evaluate the quality of the conditional generation

摘要：近年来，轨迹生成已成为流程挖掘社区中的重大挑战。深度学习 (DL) 模型已证明能够准确地再现所选流程的特征。然而，当前的 DL 生成模型在根据特定条件或属性生成数据样本以适应学习分布方面存在局限性。这种限制尤其重要，因为在各种情况下控制生成数据类型的功能可能是有益的，能够专注于特定行为、探索不频繁的模式或模拟替代的“假设”场景。在这项工作中，我们通过引入基于条件变分自动编码器 (CVAE) 的流程数据生成条件模型来应对这一挑战。条件模型通过调整输入条件变量来控制生成过程，从而实现更有针对性和可控的数据生成。与其他领域不同，流程挖掘的 CVAE 面临着特定挑战，因为数据具有多视角的性质，并且需要遵守控制流规则，同时确保数据可变性。具体来说，我们专注于生成受轨迹的控制流和时间特征制约的流程执行，从而使我们能够为特定已识别的子流程生成轨迹。然后使用生成模型评估的常用指标以及其他指标来评估生成轨迹，以评估条件生成的质量

##### **Unsupervised detection of semantic correlations in big data**
2411.02126v1 by Santiago Acevedo, Alex Rodriguez, Alessandro Laio

In real-world data, information is stored in extremely large feature vectors.
These variables are typically correlated due to complex interactions involving
many features simultaneously. Such correlations qualitatively correspond to
semantic roles and are naturally recognized by both the human brain and
artificial neural networks. This recognition enables, for instance, the
prediction of missing parts of an image or text based on their context. We
present a method to detect these correlations in high-dimensional data
represented as binary numbers. We estimate the binary intrinsic dimension of a
dataset, which quantifies the minimum number of independent coordinates needed
to describe the data, and is therefore a proxy of semantic complexity. The
proposed algorithm is largely insensitive to the so-called curse of
dimensionality, and can therefore be used in big data analysis. We test this
approach identifying phase transitions in model magnetic systems and we then
apply it to the detection of semantic correlations of images and text inside
deep neural networks.

摘要：在現實世界的資料中，資訊儲存在極大的特徵向量中。
這些變數通常由於包含許多特徵的複雜交互作用而相關。
這種相關性在質上對應於語義角色，並且自然地被人腦和人工神經網路所識別。
例如，這種識別使預測影像或文字的遺失部分成為可能，其依據是其脈絡。
我們提出一個方法來偵測高維度資料中的這些相關性，這些資料表示為二進位數字。
我們估計資料集的二進位內秉維度，它量化描述資料所需的最小獨立座標數，因此是語義複雜性的代理。
所提出的演算法在很大程度上不受所謂的維度詛咒影響，因此可用於大資料分析。
我們測試此方法來識別模型磁性系統中的相變，然後將其應用於深度神經網路中影像和文字的語義相關性偵測。

##### **Revisiting K-mer Profile for Effective and Scalable Genome Representation Learning**
2411.02125v1 by Abdulkadir Celikkanat, Andres R. Masegosa, Thomas D. Nielsen

Obtaining effective representations of DNA sequences is crucial for genome
analysis. Metagenomic binning, for instance, relies on genome representations
to cluster complex mixtures of DNA fragments from biological samples with the
aim of determining their microbial compositions. In this paper, we revisit
k-mer-based representations of genomes and provide a theoretical analysis of
their use in representation learning. Based on the analysis, we propose a
lightweight and scalable model for performing metagenomic binning at the genome
read level, relying only on the k-mer compositions of the DNA fragments. We
compare the model to recent genome foundation models and demonstrate that while
the models are comparable in performance, the proposed model is significantly
more effective in terms of scalability, a crucial aspect for performing
metagenomic binning of real-world datasets.

摘要：獲得 DNA 序列的有效表示對於基因組分析至關重要。例如，宏基因組分箱依賴於基因組表示，以群集來自生物樣本的 DNA 片段的複雜混合物，目的是確定它們的微生物組成。在本文中，我們重新審視了基於 k-mer 的基因組表示，並對它們在表示學習中的使用提供了理論分析。基於分析，我們提出了一個輕量級且可擴充的模型，用於在基因組讀取層級執行宏基因組分箱，僅依賴於 DNA 片段的 k-mer 組成。我們將該模型與最近的基因組基礎模型進行比較，並證明雖然這些模型在性能上相當，但所提出的模型在可擴充性方面顯著更有效，這是執行實際世界資料集的宏基因組分箱的一個關鍵方面。

##### **Adaptive Sparse Allocation with Mutual Choice & Feature Choice Sparse Autoencoders**
2411.02124v1 by Kola Ayonrinde

Sparse autoencoders (SAEs) are a promising approach to extracting features
from neural networks, enabling model interpretability as well as causal
interventions on model internals. SAEs generate sparse feature representations
using a sparsifying activation function that implicitly defines a set of
token-feature matches. We frame the token-feature matching as a resource
allocation problem constrained by a total sparsity upper bound. For example,
TopK SAEs solve this allocation problem with the additional constraint that
each token matches with at most $k$ features. In TopK SAEs, the $k$ active
features per token constraint is the same across tokens, despite some tokens
being more difficult to reconstruct than others. To address this limitation, we
propose two novel SAE variants, Feature Choice SAEs and Mutual Choice SAEs,
which each allow for a variable number of active features per token. Feature
Choice SAEs solve the sparsity allocation problem under the additional
constraint that each feature matches with at most $m$ tokens. Mutual Choice
SAEs solve the unrestricted allocation problem where the total sparsity budget
can be allocated freely between tokens and features. Additionally, we introduce
a new auxiliary loss function, $\mathtt{aux\_zipf\_loss}$, which generalises
the $\mathtt{aux\_k\_loss}$ to mitigate dead and underutilised features. Our
methods result in SAEs with fewer dead features and improved reconstruction
loss at equivalent sparsity levels as a result of the inherent adaptive
computation. More accurate and scalable feature extraction methods provide a
path towards better understanding and more precise control of foundation
models.

摘要：<paragraph>稀疏自编码器 (SAE) 是一种从神经网络中提取特征的有前途的方法，它支持模型可解释性以及对模型内部的因果干预。SAE 使用稀疏化激活函数生成稀疏特征表征，该函数隐式定义了一组标记特征匹配。我们将标记特征匹配构建为受总稀疏度上限约束的资源分配问题。例如，TopK SAE 使用附加约束来解决此分配问题，即每个标记最多与 $k$ 个特征匹配。在 TopK SAE 中，每个标记的 $k$ 个活动特征约束在所有标记中都是相同的，尽管有些标记比其他标记更难重建。为了解决此限制，我们提出了两种新颖的 SAE 变体，即特征选择 SAE 和相互选择 SAE，它们每个都允许每个标记有可变数量的活动特征。特征选择 SAE 在附加约束下解决稀疏度分配问题，即每个特征最多与 $m$ 个标记匹配。相互选择 SAE 解决不受限制的分配问题，其中总稀疏度预算可以在标记和特征之间自由分配。此外，我们引入了一个新的辅助损失函数 $\mathtt{aux\_zipf\_loss}$，它概括了 $\mathtt{aux\_k\_loss}$ 以减轻死特征和利用不足的特征。我们的方法导致 SAE 具有更少的死特征，并且由于固有的自适应计算，在同等稀疏度级别下改进了重建损失。更准确和可扩展的特征提取方法提供了一条途径，可以更好地理解和更精确地控制基础模型。</paragraph>

##### **Bridge-IF: Learning Inverse Protein Folding with Markov Bridges**
2411.02120v1 by Yiheng Zhu, Jialu Wu, Qiuyi Li, Jiahuan Yan, Mingze Yin, Wei Wu, Mingyang Li, Jieping Ye, Zheng Wang, Jian Wu

Inverse protein folding is a fundamental task in computational protein
design, which aims to design protein sequences that fold into the desired
backbone structures. While the development of machine learning algorithms for
this task has seen significant success, the prevailing approaches, which
predominantly employ a discriminative formulation, frequently encounter the
error accumulation issue and often fail to capture the extensive variety of
plausible sequences. To fill these gaps, we propose Bridge-IF, a generative
diffusion bridge model for inverse folding, which is designed to learn the
probabilistic dependency between the distributions of backbone structures and
protein sequences. Specifically, we harness an expressive structure encoder to
propose a discrete, informative prior derived from structures, and establish a
Markov bridge to connect this prior with native sequences. During the inference
stage, Bridge-IF progressively refines the prior sequence, culminating in a
more plausible design. Moreover, we introduce a reparameterization perspective
on Markov bridge models, from which we derive a simplified loss function that
facilitates more effective training. We also modulate protein language models
(PLMs) with structural conditions to precisely approximate the Markov bridge
process, thereby significantly enhancing generation performance while
maintaining parameter-efficient training. Extensive experiments on
well-established benchmarks demonstrate that Bridge-IF predominantly surpasses
existing baselines in sequence recovery and excels in the design of plausible
proteins with high foldability. The code is available at
https://github.com/violet-sto/Bridge-IF.

摘要：逆向蛋白质折叠是计算蛋白质设计中的基本任务，其目的是设计折叠成所需骨架结构的蛋白质序列。虽然机器学习算法的开发在这个任务上取得了显著的成功，但占主导地位的方法（主要采用判别式公式）经常遇到误差累积问题，并且经常无法捕捉到大量可行的序列。为了填补这些空白，我们提出了 Bridge-IF，一种用于逆向折叠的生成扩散桥模型，该模型旨在学习骨架结构和蛋白质序列分布之间的概率依赖性。具体来说，我们利用一个表达结构编码器来提出一个离散的、从结构中派生的信息先验，并建立一个马尔可夫桥梁将此先验与天然序列连接起来。在推理阶段，Bridge-IF 逐渐细化先验序列，最终形成一个更合理的序列。此外，我们在马尔可夫桥模型中引入了一个重新参数化的视角，从中我们推导出一个简化的损失函数，以促进更有效的训练。我们还用结构条件对蛋白质语言模型 (PLM) 进行调制，以精确逼近马尔可夫桥过程，从而在保持参数高效训练的同时，显著提高生成性能。在完善的基准上进行的广泛实验表明，Bridge-IF 在序列恢复方面明显优于现有的基线，并且在设计具有高可折叠性的合理蛋白质方面表现出色。代码可在 https://github.com/violet-sto/Bridge-IF 中获得。

##### **Grounding Emotional Descriptions to Electrovibration Haptic Signals**
2411.02118v1 by Guimin Hu, Zirui Zhao, Lukas Heilmann, Yasemin Vardar, Hasti Seifi

Designing and displaying haptic signals with sensory and emotional attributes
can improve the user experience in various applications. Free-form user
language provides rich sensory and emotional information for haptic design
(e.g., ``This signal feels smooth and exciting''), but little work exists on
linking user descriptions to haptic signals (i.e., language grounding). To
address this gap, we conducted a study where 12 users described the feel of 32
signals perceived on a surface haptics (i.e., electrovibration) display. We
developed a computational pipeline using natural language processing (NLP)
techniques, such as GPT-3.5 Turbo and word embedding methods, to extract
sensory and emotional keywords and group them into semantic clusters (i.e.,
concepts). We linked the keyword clusters to haptic signal features (e.g.,
pulse count) using correlation analysis. The proposed pipeline demonstrates the
viability of a computational approach to analyzing haptic experiences. We
discuss our future plans for creating a predictive model of haptic experience.

摘要：透過感官和情緒屬性設計和顯示觸覺訊號，可以提升各種應用程式的使用者體驗。自由形式的使用者語言提供豐富的感官和情緒資訊，可用於觸覺設計（例如「這個訊號感覺很平順且令人興奮」），但將使用者描述連結到觸覺訊號（也就是語言基礎）的研究卻很少。為了解決這個問題，我們進行了一項研究，讓 12 位使用者描述在表面觸覺（也就是電振動）顯示器上感知到的 32 個訊號的感覺。我們開發了一條運算管道，使用自然語言處理 (NLP) 技術，例如 GPT-3.5 Turbo 和字詞嵌入方法，來萃取感官和情緒關鍵字，並將它們分組成語義叢集（也就是概念）。我們使用相關分析將關鍵字叢集連結到觸覺訊號特徵（例如脈衝計數）。建議的運算管道展示了分析觸覺體驗的運算方法的可行性。我們討論了建立觸覺體驗預測模型的未來計畫。

##### **AVSS: Layer Importance Evaluation in Large Language Models via Activation Variance-Sparsity Analysis**
2411.02117v1 by Zichen Song, Yuxin Wu, Sitan Huang, Zhongfeng Kang

The evaluation of layer importance in deep learning has been an active area
of research, with significant implications for model optimization and
interpretability. Recently, large language models (LLMs) have gained prominence
across various domains, yet limited studies have explored the functional
importance and performance contributions of individual layers within LLMs,
especially from the perspective of activation distribution. In this work, we
propose the Activation Variance-Sparsity Score (AVSS), a novel metric combining
normalized activation variance and sparsity to assess each layer's contribution
to model performance. By identifying and removing approximately the lowest 25%
of layers based on AVSS, we achieve over 90% of original model performance
across tasks such as question answering, language modeling, and sentiment
classification, indicating that these layers may be non-essential. Our approach
provides a systematic method for identifying less critical layers, contributing
to efficient large language model architectures.

摘要：深度學習中層級重要性的評估一直是研究的活躍領域，對模型最佳化和可解釋性有重要的影響。最近，大型語言模型 (LLM) 在各個領域中獲得顯著地位，但有限的研究探討了 LLM 中個別層級的功能重要性和效能貢獻，特別是從激勵分佈的角度來看。在這項工作中，我們提出激勵變異稀疏度分數 (AVSS)，這是一個結合正規化激勵變異和稀疏度的指標，用於評估每個層級對模型效能的貢獻。透過識別並移除大約 25% 最低層級的 AVSS，我們在問答、語言建模和情緒分類等任務中達到了超過 90% 的原始模型效能，這表示這些層級可能是非必要的。我們的做法提供了一個系統化的方法來識別較不重要的層級，有助於建立有效的大型語言模型架構。

##### **Advancements and limitations of LLMs in replicating human color-word associations**
2411.02116v1 by Makoto Fukushima, Shusuke Eshita, Hiroshige Fukuhara

Color-word associations play a fundamental role in human cognition and design
applications. Large Language Models (LLMs) have become widely available and
demonstrated intelligent behaviors in various benchmarks with natural
conversation skills. However, their ability to replicate human color-word
associations remains understudied. We compared multiple generations of LLMs
(from GPT-3 to GPT- 4o) against human color-word associations using data
collected from over 10,000 Japanese participants, involving 17 colors and words
from eight categories in Japanese. Our findings reveal a clear progression in
LLM performance across generations, with GPT-4o achieving the highest accuracy
in predicting the best voted word for each color and category, particularly
when using visual inputs rather than text-based color codes. However, the
highest median performance was approximately 50% even for GPT4-o with visual
inputs (chance level is 10%), and the performance levels varied significantly
across word categories and colors, indicating a failure to fully replicate
human color-word associations. On the other hand, color discrimination ability
estimated from our color-word association data showed that LLMs demonstrated
high correlation with human color discrimination patterns, similarly to
previous studies. Our study highlights both the advancements in LLM
capabilities and their persistent limitations, suggesting differences in
semantic memory structures between humans and LLMs in representing color-word
associations.

摘要：色彩詞彙聯想在人類認知和設計應用中扮演著基本的角色。大型語言模型 (LLM) 已廣泛應用，並在各種基準中展現出具備自然對話技能的智慧行為。然而，它們複製人類色彩詞彙聯想的能力仍未獲得充分研究。我們比較了多代 LLM（從 GPT-3 到 GPT-4o）與人類色彩詞彙聯想，使用從超過 10,000 名日本參與者收集的資料，涉及日語中八個類別的 17 種色彩和詞彙。我們的研究結果揭示了 LLM 在各世代間的明顯進步，GPT-4o 在預測每種色彩和類別中票選最多的詞彙方面達到了最高的準確度，特別是在使用視覺輸入而非基於文字的色彩代碼時。然而，即使對於使用視覺輸入的 GPT4-o，最高的平均表現也大約只有 50%（機率水準為 10%），而表現水準在詞彙類別和色彩之間有顯著差異，這表示無法完全複製人類色彩詞彙聯想。另一方面，從我們的色彩詞彙聯想資料估計出的色彩辨別能力顯示，LLM 與人類色彩辨別模式有高度相關性，這與先前的研究類似。我們的研究突出了 LLM 能力的進步及其持續的限制，這表明人類和 LLM 在表徵色彩詞彙聯想時語意記憶結構存在差異。

##### **Differentially Private Integrated Decision Gradients (IDG-DP) for Radar-based Human Activity Recognition**
2411.02099v1 by Idris Zakariyya, Linda Tran, Kaushik Bhargav Sivangi, Paul Henderson, Fani Deligianni

Human motion analysis offers significant potential for healthcare monitoring
and early detection of diseases. The advent of radar-based sensing systems has
captured the spotlight for they are able to operate without physical contact
and they can integrate with pre-existing Wi-Fi networks. They are also seen as
less privacy-invasive compared to camera-based systems. However, recent
research has shown high accuracy in recognizing subjects or gender from radar
gait patterns, raising privacy concerns. This study addresses these issues by
investigating privacy vulnerabilities in radar-based Human Activity Recognition
(HAR) systems and proposing a novel method for privacy preservation using
Differential Privacy (DP) driven by attributions derived with Integrated
Decision Gradient (IDG) algorithm. We investigate Black-box Membership
Inference Attack (MIA) Models in HAR settings across various levels of
attacker-accessible information. We extensively evaluated the effectiveness of
the proposed IDG-DP method by designing a CNN-based HAR model and rigorously
assessing its resilience against MIAs. Experimental results demonstrate the
potential of IDG-DP in mitigating privacy attacks while maintaining utility
across all settings, particularly excelling against label-only and shadow model
black-box MIA attacks. This work represents a crucial step towards balancing
the need for effective radar-based HAR with robust privacy protection in
healthcare environments.

摘要：人類動作分析在醫療保健監控和疾病早期偵測方面具有顯著的潛力。雷達感測系統的出現備受矚目，因為它們能夠在無實體接觸的情況下運作，並且可以整合到現有的 Wi-Fi 網路中。與基於相機的系統相比，它們也被視為對隱私的侵犯較小。然而，最近的研究顯示，從雷達步態模式識別主體或性別的準確度很高，引發了隱私問題。本研究通過調查基於雷達的人類活動識別 (HAR) 系統中的隱私漏洞，並提出了一種使用由整合決策梯度 (IDG) 演算法衍生的歸因驅動的差分隱私 (DP) 來保護隱私的新方法。我們在攻擊者可存取資訊的各種層級中調查了 HAR 設定中的黑盒成員推論攻擊 (MIA) 模型。我們透過設計基於 CNN 的 HAR 模型並嚴格評估其對 MIA 的韌性，廣泛評估了所提出的 IDG-DP 方法的有效性。實驗結果證明了 IDG-DP 在減輕隱私攻擊方面的潛力，同時在所有設定中都保持實用性，特別是在僅標籤和影子模型黑盒 MIA 攻擊方面表現出色。這項工作代表了在醫療保健環境中平衡對有效的基於雷達的 HAR 的需求與強大的隱私保護之間取得平衡的關鍵一步。

##### **Alignment-Based Adversarial Training (ABAT) for Improving the Robustness and Accuracy of EEG-Based BCIs**
2411.02094v1 by Xiaoqing Chen, Ziwei Wang, Dongrui Wu

Machine learning has achieved great success in electroencephalogram (EEG)
based brain-computer interfaces (BCIs). Most existing BCI studies focused on
improving the decoding accuracy, with only a few considering the adversarial
security. Although many adversarial defense approaches have been proposed in
other application domains such as computer vision, previous research showed
that their direct extensions to BCIs degrade the classification accuracy on
benign samples. This phenomenon greatly affects the applicability of
adversarial defense approaches to EEG-based BCIs. To mitigate this problem, we
propose alignment-based adversarial training (ABAT), which performs EEG data
alignment before adversarial training. Data alignment aligns EEG trials from
different domains to reduce their distribution discrepancies, and adversarial
training further robustifies the classification boundary. The integration of
data alignment and adversarial training can make the trained EEG classifiers
simultaneously more accurate and more robust. Experiments on five EEG datasets
from two different BCI paradigms (motor imagery classification, and event
related potential recognition), three convolutional neural network classifiers
(EEGNet, ShallowCNN and DeepCNN) and three different experimental settings
(offline within-subject cross-block/-session classification, online
cross-session classification, and pre-trained classifiers) demonstrated its
effectiveness. It is very intriguing that adversarial attacks, which are
usually used to damage BCI systems, can be used in ABAT to simultaneously
improve the model accuracy and robustness.

摘要：機器學習在腦電圖 (EEG)
基於腦機介面 (BCI) 方面取得了巨大的成功。現有的 BCI 研究大多集中於
改進解碼準確度，只有少數考慮對抗
安全性。儘管在其他應用領域（例如電腦視覺）中已經提出了許多對抗性防禦方法，
先前的研究表明，它們直接擴展到 BCI 會降低良性樣本的分類準確度。這種現象極大地影響了
對抗性防禦方法在基於 EEG 的 BCI 中的適用性。為了減輕這個問題，我們
提出基於對齊的對抗性訓練 (ABAT)，它在對抗性訓練之前執行 EEG 資料
對齊。資料對齊會將來自不同領域的 EEG 試驗對齊，以減少它們的分布差異，而對抗性
訓練進一步增強了分類邊界。
資料對齊和對抗性訓練的整合可以使訓練後的 EEG 分類器同時更準確和更強健。在五個 EEG 資料集上的實驗
來自兩種不同的 BCI 模式（運動意象分類和事件
相關潛能識別），三個卷積神經網路分類器
（EEGNet、ShallowCNN 和 DeepCNN）和三種不同的實驗設定
（離線受試者內交叉區塊/-會話分類、線上
交叉會話分類和預訓練分類器）證明了它的
有效性。非常有趣的是，對抗性攻擊通常
用於損壞 BCI 系統，可以在 ABAT 中使用以同時
提高模型準確性和魯棒性。

##### **Real-time and Downtime-tolerant Fault Diagnosis for Railway Turnout Machines (RTMs) Empowered with Cloud-Edge Pipeline Parallelism**
2411.02086v1 by Fan Wu, Muhammad Bilal, Haolong Xiang, Heng Wang, Jinjun Yu, Xiaolong Xu

Railway Turnout Machines (RTMs) are mission-critical components of the
railway transportation infrastructure, responsible for directing trains onto
desired tracks. For safety assurance applications, especially in early-warning
scenarios, RTM faults are expected to be detected as early as possible on a
continuous 7x24 basis. However, limited emphasis has been placed on distributed
model inference frameworks that can meet the inference latency and reliability
requirements of such mission critical fault diagnosis systems. In this paper,
an edge-cloud collaborative early-warning system is proposed to enable
real-time and downtime-tolerant fault diagnosis of RTMs, providing a new
paradigm for the deployment of models in safety-critical scenarios. Firstly, a
modular fault diagnosis model is designed specifically for distributed
deployment, which utilizes a hierarchical architecture consisting of the prior
knowledge module, subordinate classifiers, and a fusion layer for enhanced
accuracy and parallelism. Then, a cloud-edge collaborative framework leveraging
pipeline parallelism, namely CEC-PA, is developed to minimize the overhead
resulting from distributed task execution and context exchange by strategically
partitioning and offloading model components across cloud and edge.
Additionally, an election consensus mechanism is implemented within CEC-PA to
ensure system robustness during coordinator node downtime. Comparative
experiments and ablation studies are conducted to validate the effectiveness of
the proposed distributed fault diagnosis approach. Our ensemble-based fault
diagnosis model achieves a remarkable 97.4% accuracy on a real-world dataset
collected by Nanjing Metro in Jiangsu Province, China. Meanwhile, CEC-PA
demonstrates superior recovery proficiency during node disruptions and speed-up
ranging from 1.98x to 7.93x in total inference time compared to its
counterparts.

摘要：鐵路轉轍機 (RTM) 是鐵路運輸基礎設施中至關重要的組成部分，負責將列車導向所需的軌道。對於安全保證應用，特別是在預警場景中，預計 RTM 故障應在連續 7x24 的基礎上盡早被檢測出來。然而，針對分佈式模型推理框架的關注有限，而這些框架可以滿足此類任務關鍵故障診斷系統的推理延遲和可靠性要求。在本文中，提出了一個邊緣雲協作預警系統，以實現 RTM 的實時和耐停機故障診斷，為在安全關鍵場景中部署模型提供了一個新的範例。首先，專門設計了一個模組化故障診斷模型以進行分佈式部署，該模型採用分層架構，包括先驗知識模組、從屬分類器和一個融合層，以增強準確性和並行性。然後，開發了一個利用管道並行性的雲邊協作框架，即 CEC-PA，通過在雲和邊緣策略性地分割和卸載模型組件，以最小化分佈式任務執行和上下文交換產生的開銷。此外，在 CEC-PA 內實施了一個選舉共識機制，以確保協調器節點停機期間的系統健壯性。進行了比較實驗和消融研究，以驗證所提出的分佈式故障診斷方法的有效性。我們的基於集合的故障診斷模型在中國江蘇省南京地鐵收集的真實世界資料集上實現了 97.4% 的顯著準確度。與此同時，CEC-PA 在節點中斷期間表現出優異的恢復能力，與其對應部分相比，總推理時間的加速範圍為 1.98 倍至 7.93 倍。

##### **Regress, Don't Guess -- A Regression-like Loss on Number Tokens for Language Models**
2411.02083v1 by Jonas Zausinger, Lars Pennig, Kacper Chlodny, Vincent Limbach, Anna Ketteler, Thorben Prein, Vishwa Mohan Singh, Michael Morris Danziger, Jannis Born

While language models have exceptional capabilities at text generation, they
lack a natural inductive bias for emitting numbers and thus struggle in tasks
involving reasoning over quantities, especially arithmetics. This has
particular relevance in scientific datasets where combinations of text and
numerical data are abundant. One fundamental limitation is the nature of the CE
loss, which assumes a nominal (categorical) scale and thus cannot convey
proximity between generated number tokens. As a remedy, we here present two
versions of a number token loss. The first is based on an $L_p$ loss between
the ground truth token value and the weighted sum of the predicted class
probabilities. The second loss minimizes the Wasserstein-1 distance between the
distribution of the predicted output probabilities and the ground truth
distribution. These regression-like losses can easily be added to any language
model and extend the CE objective during training. We compare the proposed
schemes on a mathematics dataset against existing tokenization, encoding, and
decoding schemes for improving number representation in language models. Our
results reveal a significant improvement in numerical accuracy when equipping a
standard T5 model with the proposed loss schemes.

摘要：雖然語言模型在文本生成方面有非凡的能力，但它們缺乏發出數字的自然歸納偏誤，因此在涉及數量推理的任務中會遇到困難，特別是算術。這在科學數據集中尤其相關，因為文本和數字數據的組合很豐富。一個基本限制是 CE 損失的本質，它假設一個名義（分類）尺度，因此無法傳達生成的數字令牌之間的接近程度。作為補救措施，我們在此提出了數字令牌損失的兩個版本。第一個基於 $L_p$ 損失，介於基本事實令牌值和預測類別概率的加權和之間。第二個損失最小化預測輸出概率分佈和基本事實分佈之間的 Wasserstein-1 距離。這些類似迴歸的損失可以輕鬆添加到任何語言模型中，並在訓練期間擴展 CE 目標。我們在數學數據集上比較所提出的方案與現有的標記化、編碼和解碼方案，以改善語言模型中的數字表示。我們的結果表明，當使用建議的損失方案為標準 T5 模型配備時，數字準確度顯著提高。

##### **Collaborative Cognitive Diagnosis with Disentangled Representation Learning for Learner Modeling**
2411.02066v1 by Weibo Gao, Qi Liu, Linan Yue, Fangzhou Yao, Hao Wang, Yin Gu, Zheng Zhang

Learners sharing similar implicit cognitive states often display comparable
observable problem-solving performances. Leveraging collaborative connections
among such similar learners proves valuable in comprehending human learning.
Motivated by the success of collaborative modeling in various domains, such as
recommender systems, we aim to investigate how collaborative signals among
learners contribute to the diagnosis of human cognitive states (i.e., knowledge
proficiency) in the context of intelligent education. The primary challenges
lie in identifying implicit collaborative connections and disentangling the
entangled cognitive factors of learners for improved explainability and
controllability in learner Cognitive Diagnosis (CD). However, there has been no
work on CD capable of simultaneously modeling collaborative and disentangled
cognitive states. To address this gap, we present Coral, a Collaborative
cognitive diagnosis model with disentangled representation learning.
Specifically, Coral first introduces a disentangled state encoder to achieve
the initial disentanglement of learners' states. Subsequently, a meticulously
designed collaborative representation learning procedure captures collaborative
signals. It dynamically constructs a collaborative graph of learners by
iteratively searching for optimal neighbors in a context-aware manner. Using
the constructed graph, collaborative information is extracted through node
representation learning. Finally, a decoding process aligns the initial
cognitive states and collaborative states, achieving co-disentanglement with
practice performance reconstructions. Extensive experiments demonstrate the
superior performance of Coral, showcasing significant improvements over
state-of-the-art methods across several real-world datasets. Our code is
available at https://github.com/bigdata-ustc/Coral.

摘要：<paragraph>具有相似隐含认知状态的学习者通常表现出可比的
可观察问题解决能力。利用此类相似学习者之间的协作联系
在理解人类学习方面被证明是有价值的。受协作建模在各个领域的成功启发，例如
推荐系统，我们旨在研究学习者之间的协作信号如何有助于诊断人类认知状态（即知识
熟练程度）在智能教育的背景下。主要挑战在于识别隐含的协作联系并解开
学习者的纠缠认知因素，以提高学习者认知诊断 (CD) 中的可解释性和可控性。然而，尚未
有 CD 能够同时对协作和解开的认知状态进行建模。为了解决这一差距，我们提出了 Coral，一种协作
认知诊断模型，具有解开的表示学习。具体来说，Coral 首先引入了一个解开的状态编码器来实现
学习者状态的初始解开。随后，精心设计的协作表示学习过程捕获协作
信号。它通过以上下文感知的方式迭代搜索最优邻居来动态构建学习者的协作图。使用
构建的图，通过节点表示学习提取协作信息。最后，解码过程对齐初始
认知状态和协作状态，通过实践性能重建实现共解开。大量的实验证明了 Coral 的
卓越性能，展示了在几个真实世界数据集上对最先进方法的显着改进。我们的代码可在 https://github.com/bigdata-ustc/Coral 获得。</paragraph>

##### **Scalable Efficient Training of Large Language Models with Low-dimensional Projected Attention**
2411.02063v1 by Xingtai Lv, Ning Ding, Kaiyan Zhang, Ermo Hua, Ganqu Cui, Bowen Zhou

Improving the effectiveness and efficiency of large language models (LLMs)
simultaneously is a critical yet challenging research goal. In this paper, we
find that low-rank pre-training, normally considered as efficient methods that
will compromise performance, can be scalably effective when reduced parameters
are precisely targeted. Specifically, applying the low-dimensional module only
to the attention layer -- resolves this issue and enhances both effectiveness
and efficiency. We refer to this structure as Low-dimensional Projected
Attention (LPA) and provide an explanatory analysis. Through extensive
experimentation at parameter scales of 130M, 370M, and scaling up to 3B, we
have validated the effectiveness and scalability of LPA. Our results show that
LPA model can save up to 12.4% in time while achieving an approximate 5%
improvement in test perplexity (ppl) and on downstream tasks compared with the
vanilla Transformer.

摘要：同時提升大型語言模型 (LLM) 的效能和效率，是一項重要卻艱鉅的研究目標。在本文中，我們發現低秩預訓練，通常被視為會影響效能的有效率方法，當精確鎖定參數時，可以有效地擴充。具體來說，僅將低維度模組應用於注意力層，可以解決此問題，並提升效能和效率。我們將此結構稱為低維度投影注意力 (LPA)，並提供說明性分析。透過在 130M、370M 的參數規模進行廣泛的實驗，並擴充到 3B，我們驗證了 LPA 的效能和可擴充性。我們的結果顯示，與原始 Transformer 相比，LPA 模型可以節省多達 12.4% 的時間，同時在測試困惑度 (ppl) 和下游任務中獲得約 5% 的提升。

##### **TableGPT2: A Large Multimodal Model with Tabular Data Integration**
2411.02059v1 by Aofeng Su, Aowen Wang, Chao Ye, Chen Zhou, Ga Zhang, Guangcheng Zhu, Haobo Wang, Haokai Xu, Hao Chen, Haoze Li, Haoxuan Lan, Jiaming Tian, Jing Yuan, Junbo Zhao, Junlin Zhou, Kaizhe Shou, Liangyu Zha, Lin Long, Liyao Li, Pengzuo Wu, Qi Zhang, Qingyi Huang, Saisai Yang, Tao Zhang, Wentao Ye, Wufang Zhu, Xiaomeng Hu, Xijun Gu, Xinjie Sun, Xiang Li, Yuhang Yang, Zhiqing Xiao

The emergence of models like GPTs, Claude, LLaMA, and Qwen has reshaped AI
applications, presenting vast new opportunities across industries. Yet, the
integration of tabular data remains notably underdeveloped, despite its
foundational role in numerous real-world domains.
  This gap is critical for three main reasons. First, database or data
warehouse data integration is essential for advanced applications; second, the
vast and largely untapped resource of tabular data offers immense potential for
analysis; and third, the business intelligence domain specifically demands
adaptable, precise solutions that many current LLMs may struggle to provide.
  In response, we introduce TableGPT2, a model rigorously pre-trained and
fine-tuned with over 593.8K tables and 2.36M high-quality query-table-output
tuples, a scale of table-related data unprecedented in prior research. This
extensive training enables TableGPT2 to excel in table-centric tasks while
maintaining strong general language and coding abilities.
  One of TableGPT2's key innovations is its novel table encoder, specifically
designed to capture schema-level and cell-level information. This encoder
strengthens the model's ability to handle ambiguous queries, missing column
names, and irregular tables commonly encountered in real-world applications.
Similar to visual language models, this pioneering approach integrates with the
decoder to form a robust large multimodal model.
  We believe the results are compelling: over 23 benchmarking metrics,
TableGPT2 achieves an average performance improvement of 35.20% in the 7B model
and 49.32% in the 72B model over prior benchmark-neutral LLMs, with robust
general-purpose capabilities intact.

摘要：<paragraph>GPT、Claude、LLaMA 和 Qwen 等模型的出现重塑了 AI
应用程序，为各行各业带来了广阔的新机遇。然而，
尽管表格数据在众多现实世界领域中扮演着基础性角色，但
其集成却仍然明显不成熟。
这种差距至关重要，主要有三个原因。首先，数据库或数据
仓库数据集成对于高级应用程序至关重要；其次，
大量且很大程度上尚未开发的表格数据资源为
分析提供了巨大的潜力；第三，商业智能领域尤其需要
许多当前 LLM 可能难以提供的适应性强、精确的解决方案。
为此，我们引入了 TableGPT2，这是一个经过严格预训练和
微调的模型，拥有超过 593.8K 张表格和 2.36M 个高质量的查询-表格-输出
元组，这是先前研究中前所未有的表格相关数据规模。这种
广泛的训练使 TableGPT2 能够在以表格为中心的
任务中表现出色，同时保持强大的通用语言和编码能力。
TableGPT2 的一项关键创新是其新颖的表格编码器，专门
设计用于捕获模式级别和单元格级别信息。此编码器
增强了模型处理模棱两可的查询、缺少列名和
现实世界应用程序中常见的非规则表格的能力。
类似于视觉语言模型，这种开创性方法与
解码器集成，形成一个强大的大型多模态模型。
我们相信结果令人信服：在 23 个基准测试指标上，
TableGPT2 在 7B 模型中实现了 35.20% 的平均性能提升，在 72B 模型中实现了 49.32% 的提升，并且保持了强大的
通用功能。</paragraph>

##### **Enhancing ID-based Recommendation with Large Language Models**
2411.02041v1 by Lei Chen, Chen Gao, Xiaoyi Du, Hengliang Luo, Depeng Jin, Yong Li, Meng Wang

Large Language Models (LLMs) have recently garnered significant attention in
various domains, including recommendation systems. Recent research leverages
the capabilities of LLMs to improve the performance and user modeling aspects
of recommender systems. These studies primarily focus on utilizing LLMs to
interpret textual data in recommendation tasks. However, it's worth noting that
in ID-based recommendations, textual data is absent, and only ID data is
available. The untapped potential of LLMs for ID data within the ID-based
recommendation paradigm remains relatively unexplored. To this end, we
introduce a pioneering approach called "LLM for ID-based Recommendation"
(LLM4IDRec). This innovative approach integrates the capabilities of LLMs while
exclusively relying on ID data, thus diverging from the previous reliance on
textual data. The basic idea of LLM4IDRec is that by employing LLM to augment
ID data, if augmented ID data can improve recommendation performance, it
demonstrates the ability of LLM to interpret ID data effectively, exploring an
innovative way for the integration of LLM in ID-based recommendation. We
evaluate the effectiveness of our LLM4IDRec approach using three widely-used
datasets. Our results demonstrate a notable improvement in recommendation
performance, with our approach consistently outperforming existing methods in
ID-based recommendation by solely augmenting input data.

摘要：大型語言模型 (LLM) 最近在各種領域中獲得了顯著的關注，包括推薦系統。最近的研究利用 LLM 的功能來改善推薦系統的效能和使用者建模面向。這些研究主要專注於利用 LLM 來詮釋推薦任務中的文字資料。然而，值得注意的是，在基於 ID 的推薦中，文字資料是不存在的，而且只有 ID 資料可用。LLM 在基於 ID 的推薦範例中對 ID 資料的未開發潛力仍然相對未被探討。為此，我們引入一種稱為「用於基於 ID 的推薦的 LLM」(LLM4IDRec) 的先驅方法。這種創新的方法整合了 LLM 的功能，同時僅依賴於 ID 資料，因此與先前依賴文字資料的方法不同。LLM4IDRec 的基本概念是，透過使用 LLM 來擴充 ID 資料，如果擴充後的 ID 資料可以改善推薦效能，這就證明了 LLM 有效詮釋 ID 資料的能力，探索了將 LLM 整合到基於 ID 的推薦中的一種創新方式。我們使用三個廣泛使用的資料集評估了我們的 LLM4IDRec 方法的有效性。我們的結果證明了推薦效能的顯著提升，我們的這種方法透過僅擴充輸入資料，始終優於現有的基於 ID 的推薦方法。

##### **Explainable cognitive decline detection in free dialogues with a Machine Learning approach based on pre-trained Large Language Models**
2411.02036v1 by Francisco de Arriba-Pérez, Silvia García-Méndez, Javier Otero-Mosquera, Francisco J. González-Castaño

Cognitive and neurological impairments are very common, but only a small
proportion of affected individuals are diagnosed and treated, partly because of
the high costs associated with frequent screening. Detecting pre-illness stages
and analyzing the progression of neurological disorders through effective and
efficient intelligent systems can be beneficial for timely diagnosis and early
intervention. We propose using Large Language Models to extract features from
free dialogues to detect cognitive decline. These features comprise high-level
reasoning content-independent features (such as comprehension, decreased
awareness, increased distraction, and memory problems). Our solution comprises
(i) preprocessing, (ii) feature engineering via Natural Language Processing
techniques and prompt engineering, (iii) feature analysis and selection to
optimize performance, and (iv) classification, supported by automatic
explainability. We also explore how to improve Chatgpt's direct cognitive
impairment prediction capabilities using the best features in our models.
Evaluation metrics obtained endorse the effectiveness of a mixed approach
combining feature extraction with Chatgpt and a specialized Machine Learning
model to detect cognitive decline within free-form conversational dialogues
with older adults. Ultimately, our work may facilitate the development of an
inexpensive, non-invasive, and rapid means of detecting and explaining
cognitive decline.

摘要：認知和神經障礙非常常見，但只有少數受影響的個人被診斷和治療，部分原因是因為頻繁篩檢相關的高成本。透過有效且高效的智慧系統偵測疾病前期階段並分析神經疾病的進程，有助於及時診斷和早期介入。我們建議使用大型語言模型從自由對話中萃取特徵，以偵測認知能力下降。這些特徵包含高階推理內容無關的特徵（例如理解力、意識下降、分心增加和記憶力問題）。我們的解決方案包含 (i) 前處理、(ii) 透過自然語言處理技術和提示工程進行特徵工程、(iii) 特徵分析和選擇以最佳化效能，以及 (iv) 分類，由自動解釋能力支援。我們也探索如何使用我們模型中的最佳特徵來改善 Chatgpt 的直接認知障礙預測能力。取得的評估指標認可了結合特徵萃取、Chatgpt 和特殊機器學習模型的混合方法在偵測老年人自由形式對話中的認知能力下降方面的有效性。最終，我們的研究可能促進開發一種經濟實惠、非侵入性和快速的方法，以偵測和解釋認知能力下降。

##### **CTEFM-VC: Zero-Shot Voice Conversion Based on Content-Aware Timbre Ensemble Modeling and Flow Matching**
2411.02026v1 by Yu Pan, Yuguang Yang, Jixun Yao, Jianhao Ye, Hongbin Zhou, Lei Ma, Jianjun Zhao

Zero-shot voice conversion (VC) aims to transform the timbre of a source
speaker into any previously unseen target speaker, while preserving the
original linguistic content. Despite notable progress, attaining a degree of
speaker similarity and naturalness on par with ground truth recordings
continues to pose great challenge. In this paper, we propose CTEFM-VC, a
zero-shot VC framework that leverages Content-aware Timbre Ensemble modeling
and Flow Matching. Specifically, CTEFM-VC disentangles utterances into
linguistic content and timbre representations, subsequently utilizing a
conditional flow matching model and a vocoder to reconstruct the
mel-spectrogram and waveform. To enhance its timbre modeling capability and the
naturalness of generated speech, we propose a context-aware timbre ensemble
modeling approach that adaptively integrates diverse speaker verification
embeddings and enables the joint utilization of linguistic and timbre features
through a cross-attention module. Experiments show that our CTEFM-VC system
surpasses state-of-the-art VC methods in both speaker similarity and
naturalness by at least 18.5% and 7.0%.

摘要：零樣本語音轉換 (VC) 旨在將來源說話者的音色轉換為任何先前未見的目標說話者，同時保留原始語言內容。儘管取得顯著進展，但要達到與地面實況錄音相當的說話者相似度和自然度，仍然是一項巨大的挑戰。在本文中，我們提出 CTEFM-VC，一個零樣本 VC 框架，它利用內容感知音色合奏建模和流匹配。具體來說，CTEFN-VC 將語句解開為語言內容和音色表示，隨後利用條件流匹配模型和編碼器來重建梅爾譜圖和波形。為了增強其音色建模能力和生成語音的自然度，我們提出了一種上下文感知音色合奏建模方法，它自適應地整合了不同的說話者驗證嵌入，並通過跨注意力模組實現語言和音色特徵的聯合利用。實驗表明，我們的 CTEFM-VC 系統在說話者相似度和自然度方面都超越了最先進的 VC 方法，至少分別提高了 18.5% 和 7.0%。

##### **Shortcut Learning in In-Context Learning: A Survey**
2411.02018v1 by Rui Song, Yingji Li, Fausto Giunchiglia, Hao Xu

Shortcut learning refers to the phenomenon where models employ simple,
non-robust decision rules in practical tasks, which hinders their
generalization and robustness. With the rapid development of large language
models (LLMs) in recent years, an increasing number of studies have shown the
impact of shortcut learning on LLMs. This paper provides a novel perspective to
review relevant research on shortcut learning in In-Context Learning (ICL). It
conducts a detailed exploration of the types of shortcuts in ICL tasks, their
causes, available benchmarks, and strategies for mitigating shortcuts. Based on
corresponding observations, it summarizes the unresolved issues in existing
research and attempts to outline the future research landscape of shortcut
learning.

摘要：捷徑學習是指模型在實際任務中採用簡單、不穩健的決策規則的現象，這阻礙了它們的泛化和穩健性。隨著近年來大型語言模型 (LLM) 的快速發展，越來越多的研究表明捷徑學習對 LLM 的影響。本文提供了一個新穎的觀點來回顧情境學習 (ICL) 中關於捷徑學習的相关研究。它對 ICL 任務中的捷徑類型、它們的原因、可用的基準和減輕捷徑的策略進行了詳細探討。根據相應的觀察，它總結了現有研究中未解決的問題，並試圖概述捷徑學習的未來研究前景。

##### **Foundations and Recent Trends in Multimodal Mobile Agents: A Survey**
2411.02006v1 by Biao Wu, Yanda Li, Meng Fang, Zirui Song, Zhiwei Zhang, Yunchao Wei, Ling Chen

Mobile agents are essential for automating tasks in complex and dynamic
mobile environments. As foundation models evolve, the demands for agents that
can adapt in real-time and process multimodal data have grown. This survey
provides a comprehensive review of mobile agent technologies, focusing on
recent advancements that enhance real-time adaptability and multimodal
interaction. Recent evaluation benchmarks have been developed better to capture
the static and interactive environments of mobile tasks, offering more accurate
assessments of agents' performance. We then categorize these advancements into
two main approaches: prompt-based methods, which utilize large language models
(LLMs) for instruction-based task execution, and training-based methods, which
fine-tune multimodal models for mobile-specific applications. Additionally, we
explore complementary technologies that augment agent performance. By
discussing key challenges and outlining future research directions, this survey
offers valuable insights for advancing mobile agent technologies. A
comprehensive resource list is available at
https://github.com/aialt/awesome-mobile-agents

摘要：行動代理對於在複雜且動態的行動環境中自動化任務至關重要。隨著基礎模型的演進，對於能夠即時適應並處理多模態資料的代理的需求也隨之增加。本調查提供行動代理技術的全面回顧，重點在於增強即時適應性和多模態互動的最新進展。最近的評估基準已開發得更好，以捕捉行動任務的靜態和互動環境，提供更準確的代理效能評估。然後，我們將這些進展分類為兩種主要方法：基於提示的方法，它利用大型語言模型 (LLM) 進行基於指令的任務執行，以及基於訓練的方法，它微調多模態模型以進行特定於行動的應用。此外，我們探討了增強代理效能的補充技術。透過討論關鍵挑戰並概述未來的研究方向，本調查為推進行動代理技術提供了寶貴的見解。可以在 https://github.com/aialt/awesome-mobile-agents 找到全面的資源清單

##### **Against Multifaceted Graph Heterogeneity via Asymmetric Federated Prompt Learning**
2411.02003v1 by Zhuoning Guo, Ruiqian Han, Hao Liu

Federated Graph Learning (FGL) aims to collaboratively and privately optimize
graph models on divergent data for different tasks. A critical challenge in FGL
is to enable effective yet efficient federated optimization against
multifaceted graph heterogeneity to enhance mutual performance. However,
existing FGL works primarily address graph data heterogeneity and perform
incapable of graph task heterogeneity. To address the challenge, we propose a
Federated Graph Prompt Learning (FedGPL) framework to efficiently enable
prompt-based asymmetric graph knowledge transfer between multifaceted
heterogeneous federated participants. Generally, we establish a split federated
framework to preserve universal and domain-specific graph knowledge,
respectively. Moreover, we develop two algorithms to eliminate task and data
heterogeneity for advanced federated knowledge preservation. First, a
Hierarchical Directed Transfer Aggregator (HiDTA) delivers cross-task
beneficial knowledge that is hierarchically distilled according to the
directional transferability. Second, a Virtual Prompt Graph (VPG) adaptively
generates graph structures to enhance data utility by distinguishing dominant
subgraphs and neutralizing redundant ones. We conduct theoretical analyses and
extensive experiments to demonstrate the significant accuracy and efficiency
effectiveness of FedGPL against multifaceted graph heterogeneity compared to
state-of-the-art baselines on large-scale federated graph datasets.

摘要：联邦图学习 (FGL) 旨在针对不同的任务在发散的数据上协作且私下优化图模型。FGL 中的一个关键挑战是针对多方面的图异质性启用有效且高效的联邦优化，以增强相互性能。然而，现有的 FGL 工作主要解决图数据异质性，并且无法执行图任务异质性。为了应对这一挑战，我们提出了一个联邦图提示学习 (FedGPL) 框架，以有效地实现基于提示的多方面异构联邦参与者之间的非对称图知识转移。一般来说，我们建立了一个分割联邦框架，分别保留通用和特定于域的图知识。此外，我们开发了两种算法来消除任务和数据异质性，以实现高级联邦知识保留。首先，一个分层定向传输聚合器 (HiDTA) 提供根据定向可转移性分层提取的跨任务有益知识。其次，一个虚拟提示图 (VPG) 自适应地生成图结构，通过区分主导子图并中和冗余子图来增强数据效用。我们进行了理论分析和广泛的实验，以证明 FedGPL 在多方面图异质性方面的显着准确性和有效性，与大规模联邦图数据集上的最先进基线相比。

##### **Culinary Class Wars: Evaluating LLMs using ASH in Cuisine Transfer Task**
2411.01996v1 by Hoonick Lee, Mogan Gim, Donghyeon Park, Donghee Choi, Jaewoo Kang

The advent of Large Language Models (LLMs) have shown promise in various
creative domains, including culinary arts. However, many LLMs still struggle to
deliver the desired level of culinary creativity, especially when tasked with
adapting recipes to meet specific cultural requirements. This study focuses on
cuisine transfer-applying elements of one cuisine to another-to assess LLMs'
culinary creativity. We employ a diverse set of LLMs to generate and evaluate
culturally adapted recipes, comparing their evaluations against LLM and human
judgments. We introduce the ASH (authenticity, sensitivity, harmony) benchmark
to evaluate LLMs' recipe generation abilities in the cuisine transfer task,
assessing their cultural accuracy and creativity in the culinary domain. Our
findings reveal crucial insights into both generative and evaluative
capabilities of LLMs in the culinary domain, highlighting strengths and
limitations in understanding and applying cultural nuances in recipe creation.
The code and dataset used in this project will be openly available in
\url{http://github.com/dmis-lab/CulinaryASH}.

摘要：大型語言模型 (LLM) 的出現已在各種創意領域中展現出前景，包括料理藝術。然而，許多 LLM 仍難以提供所需的料理創意水準，特別是在需要調整食譜以符合特定文化需求時。本研究專注於料理轉移，將一種料理的元素應用到另一種料理中，以評估 LLM 的料理創意。我們採用多元的 LLM 來產生並評估經過文化調整的食譜，並將其評估與 LLM 和人類的判斷進行比較。我們導入 ASH（真實性、敏感性、和諧性）基準來評估 LLM 在料理轉移任務中的食譜產生能力，評估其在料理領域中的文化準確性和創意性。我們的研究結果揭露了 LLM 在料理領域中產生和評估能力的重要見解，突顯了在食譜創作中理解和應用文化細微差的優點和限制。本專案中使用的程式碼和資料集將在 \url{http://github.com/dmis-lab/CulinaryASH} 中開放取得。

##### **Understanding Variational Autoencoders with Intrinsic Dimension and Information Imbalance**
2411.01978v1 by Charles Camboulin, Diego Doimo, Aldo Glielmo

This work presents an analysis of the hidden representations of Variational
Autoencoders (VAEs) using the Intrinsic Dimension (ID) and the Information
Imbalance (II). We show that VAEs undergo a transition in behaviour once the
bottleneck size is larger than the ID of the data, manifesting in a double
hunchback ID profile and a qualitative shift in information processing as
captured by the II. Our results also highlight two distinct training phases for
architectures with sufficiently large bottleneck sizes, consisting of a rapid
fit and a slower generalisation, as assessed by a differentiated behaviour of
ID, II, and KL loss. These insights demonstrate that II and ID could be
valuable tools for aiding architecture search, for diagnosing underfitting in
VAEs, and, more broadly, they contribute to advancing a unified understanding
of deep generative models through geometric analysis.

摘要：本研究使用内在维度 (ID) 和信息不平衡 (II) 分析变分自动编码器 (VAE) 的隐藏表征。我们表明，一旦瓶颈大小大于数据的 ID，VAE 的行为就会发生转变，表现为双驼峰 ID 轮廓和 II 捕获的信息处理的质变。我们的结果还强调了具有足够大瓶颈大小的架构的两个不同的训练阶段，包括快速拟合和较慢泛化，如 ID、II 和 KL 损失的不同行为所评估的那样。这些见解表明，II 和 ID 可能是辅助架构搜索、诊断 VAE 中的欠拟合的宝贵工具，而且更广泛地说，它们有助于通过几何分析促进对深度生成模型的统一理解。

##### **Active Gaze Behavior Boosts Self-Supervised Object Learning**
2411.01969v1 by Zhengyang Yu, Arthur Aubret, Marcel C. Raabe, Jane Yang, Chen Yu, Jochen Triesch

Due to significant variations in the projection of the same object from
different viewpoints, machine learning algorithms struggle to recognize the
same object across various perspectives. In contrast, toddlers quickly learn to
recognize objects from different viewpoints with almost no supervision. Recent
works argue that toddlers develop this ability by mapping close-in-time visual
inputs to similar representations while interacting with objects. High acuity
vision is only available in the central visual field, which may explain why
toddlers (much like adults) constantly move their gaze around during such
interactions. It is unclear whether/how much toddlers curate their visual
experience through these eye movements to support learning object
representations. In this work, we explore whether a bio inspired visual
learning model can harness toddlers' gaze behavior during a play session to
develop view-invariant object recognition. Exploiting head-mounted eye tracking
during dyadic play, we simulate toddlers' central visual field experience by
cropping image regions centered on the gaze location. This visual stream feeds
a time-based self-supervised learning algorithm. Our experiments demonstrate
that toddlers' gaze strategy supports the learning of invariant object
representations. Our analysis also reveals that the limited size of the central
visual field where acuity is high is crucial for this. We further find that
toddlers' visual experience elicits more robust representations compared to
adults' mostly because toddlers look at objects they hold themselves for longer
bouts. Overall, our work reveals how toddlers' gaze behavior supports
self-supervised learning of view-invariant object recognition.

摘要：由於同一個物體從不同視角投影時變化很大，機器學習演算法很難辨識不同視角的同一個物體。相反地，幼兒幾乎沒有監督就能快速學會從不同視角辨識物體。最近的研究指出，幼兒透過在與物體互動時將接近時間的視覺輸入對應到類似的表徵，來培養這種能力。高解析度視覺只存在於中央視覺場中，這或許可以解釋為何幼兒（很像成人）在這種互動過程中會不斷轉動視線。目前尚不清楚幼兒是否/如何透過這些眼球運動來策劃他們的視覺經驗，以支持學習物體表徵。在這項研究中，我們探討受生物啟發的視覺學習模型是否能利用幼兒在遊戲過程中注視的行為，來發展觀點不變的物體辨識。我們在雙人遊戲中利用頭戴式眼球追蹤技術，模擬幼兒的中央視覺場經驗，方法是裁剪以注視位置為中心的影像區域。這個視覺串流提供給基於時間的自監督學習演算法。我們的實驗證明幼兒的注視策略有助於學習不變的物體表徵。我們的分析也揭示，高解析度中央視覺場的有限大小對此至關重要。我們進一步發現，與成人相比，幼兒的視覺經驗引發了更強健的表徵，主要原因是幼兒會長時間注視他們拿在手中的物體。總的來說，我們的研究揭示了幼兒的注視行為如何支援觀點不變的物體辨識的自監督學習。

##### **V-CAS: A Realtime Vehicle Anti Collision System Using Vision Transformer on Multi-Camera Streams**
2411.01963v1 by Muhammad Waqas Ashraf, Ali Hassan, Imad Ali Shah

This paper introduces a real-time Vehicle Collision Avoidance System (V-CAS)
designed to enhance vehicle safety through adaptive braking based on
environmental perception. V-CAS leverages the advanced vision-based transformer
model RT-DETR, DeepSORT tracking, speed estimation, brake light detection, and
an adaptive braking mechanism. It computes a composite collision risk score
based on vehicles' relative accelerations, distances, and detected braking
actions, using brake light signals and trajectory data from multiple camera
streams to improve scene perception. Implemented on the Jetson Orin Nano, V-CAS
enables real-time collision risk assessment and proactive mitigation through
adaptive braking. A comprehensive training process was conducted on various
datasets for comparative analysis, followed by fine-tuning the selected object
detection model using transfer learning. The system's effectiveness was
rigorously evaluated on the Car Crash Dataset (CCD) from YouTube and through
real-time experiments, achieving over 98% accuracy with an average proactive
alert time of 1.13 seconds. Results indicate significant improvements in object
detection and tracking, enhancing collision avoidance compared to traditional
single-camera methods. This research demonstrates the potential of low-cost,
multi-camera embedded vision transformer systems to advance automotive safety
through enhanced environmental perception and proactive collision avoidance
mechanisms.

摘要：本文介紹了一種即時車輛防撞系統 (V-CAS)，旨在透過基於環境感知的自適應煞車來提升車輛安全性。V-CAS 利用先進的基於視覺的 Transformer 模型 RT-DETR、DeepSORT 追蹤、速度估計、煞車燈偵測，以及自適應煞車機制。它會根據車輛的相對加速度、距離和偵測到的煞車動作，計算出一個複合碰撞風險評分，並使用來自多個攝影機串流的煞車燈訊號和軌跡資料來改善場景感知。V-CAS 實作於 Jetson Orin Nano 上，可透過自適應煞車進行即時碰撞風險評估和主動減緩。在各種資料集上進行了全面的訓練流程以進行比較分析，接著使用遷移學習微調所選的物件偵測模型。系統的有效性在 YouTube 的汽車碰撞資料集 (CCD) 和即時實驗中經過嚴格評估，準確率超過 98%，平均主動警示時間為 1.13 秒。結果顯示，與傳統的單一攝影機方法相比，物件偵測和追蹤有顯著的改善，增強了防撞能力。本研究展示了低成本、多攝影機嵌入式視覺 Transformer 系統的潛力，可透過增強的環境感知和主動防撞機制來提升汽車安全性。

##### **HACD: Harnessing Attribute Semantics and Mesoscopic Structure for Community Detection**
2411.01947v1 by Anran Zhang, Xingfen Wang, Yuhan Zhao

Community detection plays a pivotal role in uncovering closely connected
subgraphs, aiding various real-world applications such as recommendation
systems and anomaly detection. With the surge of rich information available for
entities in real-world networks, the community detection problem in attributed
networks has attracted widespread attention. While previous research has
effectively leveraged network topology and attribute information for attributed
community detection, these methods overlook two critical issues: (i) the
semantic similarity between node attributes within the community, and (ii) the
inherent mesoscopic structure, which differs from the pairwise connections of
the micro-structure. To address these limitations, we propose HACD, a novel
attributed community detection model based on heterogeneous graph attention
networks. HACD treats node attributes as another type of node, constructs
attributed networks into heterogeneous graph structures and employs
attribute-level attention mechanisms to capture semantic similarity.
Furthermore, HACD introduces a community membership function to explore
mesoscopic community structures, enhancing the robustness of detected
communities. Extensive experiments demonstrate the effectiveness and efficiency
of HACD, outperforming state-of-the-art methods in attributed community
detection tasks. Our code is publicly available at
https://github.com/Anniran1/HACD1-wsdm.

摘要：社群偵測在揭露緊密連結的子圖中扮演著舉足輕重的角色，協助各種實際應用，例如推薦系統和異常偵測。隨著實際世界網路中實體可用的豐富資訊激增，屬性網路中的社群偵測問題引起了廣泛關注。雖然先前的研究已有效利用網路拓撲和屬性資訊來進行屬性社群偵測，但這些方法忽略了兩個關鍵問題：(i) 社群內節點屬性之間的語意相似性，以及 (ii) 與微結構的成對連接不同的固有中觀結構。為了解決這些限制，我們提出了 HACD，一種基於異質圖注意力網路的新型屬性社群偵測模型。HACD 將節點屬性視為另一種節點類型，將屬性網路建構為異質圖結構，並採用屬性層級注意力機制來擷取語意相似性。此外，HACD 引入了社群成員資格函數來探索中觀社群結構，增強了已偵測社群的穩健性。廣泛的實驗證明了 HACD 的有效性和效率，在屬性社群偵測任務中優於最先進的方法。我們的程式碼可在 https://github.com/Anniran1/HACD1-wsdm 公開取得。

##### **Exploring the Landscape for Generative Sequence Models for Specialized Data Synthesis**
2411.01929v1 by Mohammad Zbeeb, Mohammad Ghorayeb, Mariam Salman

Artificial Intelligence (AI) research often aims to develop models that
generalize reliably across complex datasets, yet this remains challenging in
fields where data is scarce, intricate, or inaccessible. This paper introduces
a novel approach leveraging three generative models of varying complexity to
synthesize one of the most demanding structured datasets: Malicious Network
Traffic. Our approach transforms numerical data into text, reframing data
generation as a language modeling task, which enhances data regularization and
significantly improves generalization and the quality of the synthetic data.
Extensive statistical analyses demonstrate that our method surpasses
state-of-the-art generative models in producing high-fidelity synthetic data.
Additionally, we conduct a comprehensive study on synthetic data applications,
effectiveness, and evaluation strategies, offering valuable insights into its
role across various domains. Our code and pre-trained models are openly
accessible at
https://github.com/Moe-Zbeeb/Exploring-the-landscape-for-generative-models-for-specialized-data-generation,
enabling further exploration and application of our methodology.
  Index Terms: Data synthesis, machine learning, traffic generation,
privacy-preserving data, generative models.

摘要：人工智慧 (AI) 研究通常旨在開發在複雜資料集上可靠地泛化的模型，然而在資料稀少、複雜或無法取得的領域中，這仍然具有挑戰性。本文介紹了一種新穎的方法，利用三種不同複雜度的生成模型來合成最具挑戰性的結構化資料集之一：惡意網路流量。我們的做法將數值資料轉換為文字，將資料產生重新定義為語言建模任務，這增強了資料正規化，並顯著改善了泛化和合成資料的品質。廣泛的統計分析證明，我們的方法在產生高保真合成資料方面超越了最先進的生成模型。此外，我們對合成資料應用、效能和評估策略進行了全面的研究，提供了對其在各種領域中角色的寶貴見解。我們的程式碼和預先訓練的模型在 https://github.com/Moe-Zbeeb/Exploring-the-landscape-for-generative-models-for-specialized-data-generation 上公開，可進一步探索和應用我們的技術。
索引詞：資料合成、機器學習、流量產生、隱私保護資料、生成模型。

##### **Fairness-Utilization Trade-off in Wireless Networks with Explainable Kolmogorov-Arnold Networks**
2411.01924v1 by Masoud Shokrnezhad, Hamidreza Mazandarani, Tarik Taleb

The effective distribution of user transmit powers is essential for the
significant advancements that the emergence of 6G wireless networks brings. In
recent studies, Deep Neural Networks (DNNs) have been employed to address this
challenge. However, these methods frequently encounter issues regarding
fairness and computational inefficiency when making decisions, rendering them
unsuitable for future dynamic services that depend heavily on the participation
of each individual user. To address this gap, this paper focuses on the
challenge of transmit power allocation in wireless networks, aiming to optimize
$\alpha$-fairness to balance network utilization and user equity. We introduce
a novel approach utilizing Kolmogorov-Arnold Networks (KANs), a class of
machine learning models that offer low inference costs compared to traditional
DNNs through superior explainability. The study provides a comprehensive
problem formulation, establishing the NP-hardness of the power allocation
problem. Then, two algorithms are proposed for dataset generation and
decentralized KAN training, offering a flexible framework for achieving various
fairness objectives in dynamic 6G environments. Extensive numerical simulations
demonstrate the effectiveness of our approach in terms of fairness and
inference cost. The results underscore the potential of KANs to overcome the
limitations of existing DNN-based methods, particularly in scenarios that
demand rapid adaptation and fairness.

摘要：有效分配使用者傳輸功率對於 6G 無線網路的出現所帶來的重大進展至關重要。在最近的研究中，深度神經網路 (DNN) 已被用於解決此挑戰。然而，這些方法在做出決策時經常遇到公平性和運算效率低下的問題，使其不適合依賴每個個別使用者參與的未來動態服務。為了解決此差距，本文重點探討無線網路中傳輸功率分配的挑戰，目標是最佳化 $\alpha$-公平性，以平衡網路使用率和使用者公平性。我們引入一種利用 Kolmogorov-Arnold 網路 (KAN) 的新方法，這是一種機器學習模型，透過優異的可解釋性，與傳統 DNN 相比提供了較低的推論成本。本研究提供了全面的問題表述，建立了功率分配問題的 NP 難度。然後，提出了兩個演算法用於資料集生成和分散式 KAN 訓練，提供了一個靈活的架構，用於在動態 6G 環境中實現各種公平性目標。廣泛的數值模擬證明了我們的方法在公平性和推論成本方面的有效性。結果強調了 KAN 克服現有基於 DNN 的方法的限制的潛力，特別是在需要快速適應和公平性的場景中。

##### **LE-PDE++: Mamba for accelerating PDEs Simulations**
2411.01897v1 by Aoming Liang, Zhaoyang Mu, Qi liu, Ruipeng Li, Mingming Ge, Dixia Fan

Partial Differential Equations are foundational in modeling science and
natural systems such as fluid dynamics and weather forecasting. The Latent
Evolution of PDEs method is designed to address the computational intensity of
classical and deep learning-based PDE solvers by proposing a scalable and
efficient alternative. To enhance the efficiency and accuracy of LE-PDE, we
incorporate the Mamba model, an advanced machine learning model known for its
predictive efficiency and robustness in handling complex dynamic systems with a
progressive learning strategy. The LE-PDE was tested on several benchmark
problems. The method demonstrated a marked reduction in computational time
compared to traditional solvers and standalone deep learning models while
maintaining high accuracy in predicting system behavior over time. Our method
doubles the inference speed compared to the LE-PDE while retaining the same
level of parameter efficiency, making it well-suited for scenarios requiring
long-term predictions.

摘要：偏微分方程式是建模科學和自然系統（例如流體動力學和天氣預測）的基礎。偏微分方程式方法的潛在演化旨在通過提出可擴展且高效的替代方案來解決基於經典和深度學習的偏微分方程式求解器的計算強度。為了提高 LE-PDE 的效率和準確性，我們結合了 Mamba 模型，這是一種先進的機器學習模型，以其在處理具有漸進學習策略的複雜動態系統方面的預測效率和穩健性而聞名。LE-PDE 已在幾個基準問題上進行了測試。與傳統求解器和獨立深度學習模型相比，該方法顯著減少了計算時間，同時在隨著時間推移預測系統行為方面保持了高準確性。我們的模型將推理速度提高了一倍，同時保持了相同的參數效率，使其非常適合需要長期預測的場景。

##### **MBDRes-U-Net: Multi-Scale Lightweight Brain Tumor Segmentation Network**
2411.01896v1 by Longfeng Shen, Yanqi Hou, Jiacong Chen, Liangjin Diao, Yaxi Duan

Accurate segmentation of brain tumors plays a key role in the diagnosis and
treatment of brain tumor diseases. It serves as a critical technology for
quantifying tumors and extracting their features. With the increasing
application of deep learning methods, the computational burden has become
progressively heavier. To achieve a lightweight model with good segmentation
performance, this study proposes the MBDRes-U-Net model using the
three-dimensional (3D) U-Net codec framework, which integrates multibranch
residual blocks and fused attention into the model. The computational burden of
the model is reduced by the branch strategy, which effectively uses the rich
local features in multimodal images and enhances the segmentation performance
of subtumor regions. Additionally, during encoding, an adaptive weighted
expansion convolution layer is introduced into the multi-branch residual block,
which enriches the feature expression and improves the segmentation accuracy of
the model. Experiments on the Brain Tumor Segmentation (BraTS) Challenge 2018
and 2019 datasets show that the architecture could maintain a high precision of
brain tumor segmentation while considerably reducing the calculation
overhead.Our code is released at
https://github.com/Huaibei-normal-university-cv-laboratory/mbdresunet

摘要：準確分割腦腫瘤在腦腫瘤疾病的診斷和治療中扮演著關鍵的角色。它作為量化腫瘤並萃取其特徵的關鍵技術。隨著深度學習方法的應用日益增加，運算負擔也變得越來越重。為了達成具備良好分割效能的輕量級模型，本研究提出使用三維 (3D) U-Net 編解碼器架構的 MBDRes-U-Net 模型，將多支路殘差區塊和融合注意力整合到模型中。模型的運算負擔透過分支策略降低，有效利用多模態影像中的豐富局部特徵，並提升次腫瘤區域的分割效能。此外，在編碼過程中，自適應加權擴張卷積層被引入多支路殘差區塊中，豐富特徵表達並提升模型的分割準確度。在腦腫瘤分割 (BraTS) 挑戰 2018 和 2019 資料集上的實驗顯示，此架構可以在大幅降低運算開銷的同時，維持腦腫瘤分割的高準確度。我們的程式碼已於 https://github.com/Huaibei-normal-university-cv-laboratory/mbdresunet 發布

##### **LiDAttack: Robust Black-box Attack on LiDAR-based Object Detection**
2411.01889v1 by Jinyin Chen, Danxin Liao, Sheng Xiang, Haibin Zheng

Since DNN is vulnerable to carefully crafted adversarial examples,
adversarial attack on LiDAR sensors have been extensively studied. We introduce
a robust black-box attack dubbed LiDAttack. It utilizes a genetic algorithm
with a simulated annealing strategy to strictly limit the location and number
of perturbation points, achieving a stealthy and effective attack. And it
simulates scanning deviations, allowing it to adapt to dynamic changes in real
world scenario variations. Extensive experiments are conducted on 3 datasets
(i.e., KITTI, nuScenes, and self-constructed data) with 3 dominant object
detection models (i.e., PointRCNN, PointPillar, and PV-RCNN++). The results
reveal the efficiency of the LiDAttack when targeting a wide range of object
detection models, with an attack success rate (ASR) up to 90%.

摘要：由於 DNN 容易受到精心製作的對抗性範例影響，
對 LiDAR 感測器的對抗性攻擊已廣泛研究。我們介紹
一種名為 LiDAttack 的強健黑盒攻擊。它利用具有模擬退火策略的遺傳演算法來嚴格限制擾動點的位置和數量，從而實現隱蔽且有效的攻擊。它模擬掃描偏差，使其能夠適應現實世界場景變化中的動態變化。在 3 個資料集（即 KITTI、nuScenes 和自建資料）上進行了廣泛的實驗，其中包含 3 個主要的物件偵測模型（即 PointRCNN、PointPillar 和 PV-RCNN++）。結果顯示 LiDAttack 在針對各種物件偵測模型時效率極高，攻擊成功率 (ASR) 高達 90%。

##### **Can Language Models Learn to Skip Steps?**
2411.01855v1 by Tengxiao Liu, Qipeng Guo, Xiangkun Hu, Cheng Jiayang, Yue Zhang, Xipeng Qiu, Zheng Zhang

Trained on vast corpora of human language, language models demonstrate
emergent human-like reasoning abilities. Yet they are still far from true
intelligence, which opens up intriguing opportunities to explore the parallels
of humans and model behaviors. In this work, we study the ability to skip steps
in reasoning - a hallmark of human expertise developed through practice. Unlike
humans, who may skip steps to enhance efficiency or to reduce cognitive load,
models do not inherently possess such motivations to minimize reasoning steps.
To address this, we introduce a controlled framework that stimulates
step-skipping behavior by iteratively refining models to generate shorter and
accurate reasoning paths. Empirical results indicate that models can develop
the step skipping ability under our guidance. Moreover, after fine-tuning on
expanded datasets that include both complete and skipped reasoning sequences,
the models can not only resolve tasks with increased efficiency without
sacrificing accuracy, but also exhibit comparable and even enhanced
generalization capabilities in out-of-domain scenarios. Our work presents the
first exploration into human-like step-skipping ability and provides fresh
perspectives on how such cognitive abilities can benefit AI models.

摘要：在海量的人类语言语料库训练下，语言模型表现出
新兴的人类推理能力。然而，它们仍然远未达到真正的
智能，这为探索人类和模型行为的相似之处提供了有趣的
机会。在这项工作中，我们研究了跳过推理步骤的能力
——这是通过实践培养的人类专业知识的标志。与人类不同，
人类可能会跳过步骤以提高效率或减少认知负荷，
模型本身并不具备最小化推理步骤的动机。
为了解决这个问题，我们引入了一个受控框架，该框架通过
迭代优化模型来生成更短且准确的推理路径，从而激发
跳步行为。实证结果表明，在我们的指导下，模型可以发展
出跳步能力。此外，在微调包含完整和跳过推理序列的
扩展数据集后，这些模型不仅可以在不牺牲准确性的情况下
以更高的效率解决任务，而且在域外场景中还表现出可比的
甚至增强的泛化能力。我们的工作首次探索了类人跳步能力，
并提供了关于此类认知能力如何使人工智能模型受益的新
视角。

##### **Leveraging Label Semantics and Meta-Label Refinement for Multi-Label Question Classification**
2411.01841v1 by Shi Dong, Xiaobei Niu, Rui Zhong, Zhifeng Wang, Mingzhang Zuo

Accurate annotation of educational resources is critical in the rapidly
advancing field of online education due to the complexity and volume of
content. Existing classification methods face challenges with semantic overlap
and distribution imbalance of labels in the multi-label context, which impedes
effective personalized learning and resource recommendation. This paper
introduces RR2QC, a novel Retrieval Reranking method To multi-label Question
Classification by leveraging label semantics and meta-label refinement.
Firstly, RR2QC leverages semantic relationships within and across label groups
to enhance pre-training strategie in multi-label context. Next, a class center
learning task is introduced, integrating label texts into downstream training
to ensure questions consistently align with label semantics, retrieving the
most relevant label sequences. Finally, this method decomposes labels into
meta-labels and trains a meta-label classifier to rerank the retrieved label
sequences. In doing so, RR2QC enhances the understanding and prediction
capability of long-tail labels by learning from meta-labels frequently
appearing in other labels. Addtionally, a Math LLM is used to generate
solutions for questions, extracting latent information to further refine the
model's insights. Experimental results demonstrate that RR2QC outperforms
existing classification methods in Precision@k and F1 scores across multiple
educational datasets, establishing it as a potent enhancement for online
educational content utilization.

摘要：<paragraph>在快速發展的線上教育領域中，準確標註教育資源至關重要，這是因為內容的複雜性和數量。現有的分類方法在多標籤情境中面臨語意重疊和標籤分佈不平衡的挑戰，這阻礙了有效的個人化學習和資源推薦。本文介紹了 RR2QC，一種新穎的檢索重新排序方法，通過利用標籤語意和元標籤優化來進行多標籤問題分類。首先，RR2QC 利用標籤組內部和組間的語義關係來增強多標籤情境中的預訓練策略。接下來，引入了類別中心學習任務，將標籤文字整合到下游訓練中，以確保問題始終與標籤語意保持一致，並檢索最相關的標籤序列。最後，此方法將標籤分解為元標籤，並訓練元標籤分類器對檢索到的標籤序列進行重新排序。這樣一來，RR2QC 通過學習經常出現在其他標籤中的元標籤，增強了對長尾標籤的理解和預測能力。此外，數學 LLM 用於為問題生成解決方案，提取潛在資訊以進一步優化模型的見解。實驗結果表明，RR2QC 在多個教育資料集中的 Precision@k 和 F1 分數方面優於現有的分類方法，確立了其作為線上教育內容利用的強大增強功能。</paragraph>

##### **TriG-NER: Triplet-Grid Framework for Discontinuous Named Entity Recognition**
2411.01839v1 by Rina Carines Cabral, Soyeon Caren Han, Areej Alhassan, Riza Batista-Navarro, Goran Nenadic, Josiah Poon

Discontinuous Named Entity Recognition (DNER) presents a challenging problem
where entities may be scattered across multiple non-adjacent tokens, making
traditional sequence labelling approaches inadequate. Existing methods
predominantly rely on custom tagging schemes to handle these discontinuous
entities, resulting in models tightly coupled to specific tagging strategies
and lacking generalisability across diverse datasets. To address these
challenges, we propose TriG-NER, a novel Triplet-Grid Framework that introduces
a generalisable approach to learning robust token-level representations for
discontinuous entity extraction. Our framework applies triplet loss at the
token level, where similarity is defined by word pairs existing within the same
entity, effectively pulling together similar and pushing apart dissimilar ones.
This approach enhances entity boundary detection and reduces the dependency on
specific tagging schemes by focusing on word-pair relationships within a
flexible grid structure. We evaluate TriG-NER on three benchmark DNER datasets
and demonstrate significant improvements over existing grid-based
architectures. These results underscore our framework's effectiveness in
capturing complex entity structures and its adaptability to various tagging
schemes, setting a new benchmark for discontinuous entity extraction.

摘要：不連續命名實體辨識 (DNER) 提出了一個具有挑戰性的問題，其中實體可能散布在多個非相鄰的標記中，導致傳統的序列標籤方法不足。現有方法主要依賴於自訂標記方案來處理這些不連續的實體，導致模型與特定標記策略緊密結合，並且缺乏跨不同資料集的泛化能力。為了應對這些挑戰，我們提出了 TriG-NER，這是一個新穎的三元組網格框架，它引入了一種可泛化的學習方法，用於為不連續實體萃取產生強健的標記層級表示。我們的框架在標記層級套用三元組損失，其中相似性由存在於同一個實體內的字詞對定義，有效地將相似者拉在一起，並將不相似的者推開。這種方法透過專注於靈活網格結構中字詞對的關係，增強了實體邊界偵測，並減少了對特定標記方案的依賴性。我們在三個基準 DNER 資料集上評估 TriG-NER，並展示出比現有的基於網格的架構有顯著的改進。這些結果強調了我們的框架在擷取複雜實體結構和適應各種標記方案方面的有效性，為不連續實體萃取設定了一個新的基準。

##### **Align-SLM: Textless Spoken Language Models with Reinforcement Learning from AI Feedback**
2411.01834v1 by Guan-Ting Lin, Prashanth Gurunath Shivakumar, Aditya Gourav, Yile Gu, Ankur Gandhe, Hung-yi Lee, Ivan Bulyko

While textless Spoken Language Models (SLMs) have shown potential in
end-to-end speech-to-speech modeling, they still lag behind text-based Large
Language Models (LLMs) in terms of semantic coherence and relevance. This work
introduces the Align-SLM framework, which leverages preference optimization
inspired by Reinforcement Learning with AI Feedback (RLAIF) to enhance the
semantic understanding of SLMs. Our approach generates multiple speech
continuations from a given prompt and uses semantic metrics to create
preference data for Direct Preference Optimization (DPO). We evaluate the
framework using ZeroSpeech 2021 benchmarks for lexical and syntactic modeling,
the spoken version of the StoryCloze dataset for semantic coherence, and other
speech generation metrics, including the GPT4-o score and human evaluation.
Experimental results show that our method achieves state-of-the-art performance
for SLMs on most benchmarks, highlighting the importance of preference
optimization to improve the semantics of SLMs.

摘要：儘管無文字的口說語言模型 (SLM) 已在端對端口語轉換模型中展現潛力，它們在語意連貫性和相關性方面仍落後於基於文字的大型語言模型 (LLM)。本研究引入了 Align-SLM 架構，它利用了受強化學習和 AI 回饋 (RLAIF) 啟發的偏好最佳化，以增強 SLM 的語意理解。我們的做法會從給定的提示產生多個語音延續，並使用語意指標為直接偏好最佳化 (DPO) 建立偏好資料。我們使用 ZeroSpeech 2021 基準對架構進行評估，用於詞彙和句法建模，StoryCloze 資料集的口語版本用於語意連貫性，以及其他語音產生指標，包括 GPT4-o 分數和人類評估。實驗結果顯示，我們的做法在多數基準上達到了 SLM 的最新效能，突顯了偏好最佳化對於改善 SLM 語意的重要性。

##### **DiffuMask-Editor: A Novel Paradigm of Integration Between the Segmentation Diffusion Model and Image Editing to Improve Segmentation Ability**
2411.01819v1 by Bo Gao, Fangxu Xing, Daniel Tang

Semantic segmentation models, like mask2former, often demand a substantial
amount of manually annotated data, which is time-consuming and inefficient to
acquire. Leveraging state-of-the-art text-to-image models like Midjourney and
Stable Diffusion has emerged as an effective strategy for automatically
generating synthetic data instead of human annotations. However, prior
approaches have been constrained to synthesizing single-instance images due to
the instability inherent in generating multiple instances with Stable
Diffusion. To expand the domains and diversity of synthetic datasets, this
paper introduces a novel paradigm named DiffuMask-Editor, which combines the
Diffusion Model for Segmentation with Image Editing. By integrating multiple
objects into images using Text2Image models, our method facilitates the
creation of more realistic datasets that closely resemble open-world settings
while simultaneously generating accurate masks. Our approach significantly
reduces the laborious effort associated with manual annotation while ensuring
precise mask generation. Experimental results demonstrate that synthetic data
generated by DiffuMask-Editor enable segmentation methods to achieve superior
performance compared to real data. Particularly in zero-shot backgrounds,
DiffuMask-Editor achieves new state-of-the-art results on Unseen classes of VOC
2012. The code and models will be publicly available soon.

摘要：語義分割模型（如 mask2former）通常需要大量人工標註資料，而取得這些資料耗時且低效率。善用最先進的文字轉圖像模型（如 Midjourney 和 Stable Diffusion）已成為自動產生合成資料（而非人工標註）的有效策略。然而，先前的做法受限於合成單一實例圖像，因為在 Stable Diffusion 中產生多個實例時會產生不穩定性。為了擴展合成資料集的領域和多樣性，本文提出一個名為 DiffuMask-Editor 的新範例，它結合了用於分割的擴散模型與影像編輯。我們的做法透過使用 Text2Image 模型將多個物件整合到圖像中，有助於建立更逼真的資料集，這些資料集與開放世界設定非常相似，同時產生精確的遮罩。我們的做法大幅減少了與人工標註相關的繁瑣工作，同時確保產生精確的遮罩。實驗結果顯示，由 DiffuMask-Editor 產生的合成資料讓分割方法能達成比真實資料更好的效能。特別是在零次背景中，DiffuMask-Editor 在 VOC 2012 的未見類別中達成新的最先進結果。程式碼和模型將很快公開。

##### **Can Language Models Enable In-Context Database?**
2411.01807v1 by Yu Pan, Hongfeng Yu, Tianjiao Zhao, Jianxin Sun

Large language models (LLMs) are emerging as few-shot learners capable of
handling a variety of tasks, including comprehension, planning, reasoning,
question answering, arithmetic calculations, and more. At the core of these
capabilities is LLMs' proficiency in representing and understanding structural
or semi-structural data, such as tables and graphs. Numerous studies have
demonstrated that reasoning on tabular data or graphs is not only feasible for
LLMs but also gives a promising research direction which treats these data as
in-context data. The lightweight and human readable characteristics of
in-context database can potentially make it an alternative for the traditional
database in typical RAG (Retrieval Augmented Generation) settings. However,
almost all current work focuses on static in-context data, which does not allow
dynamic update. In this paper, to enable dynamic database update, delta
encoding of database is proposed. We explore how data stored in traditional
RDBMS can be encoded as in-context text and evaluate LLMs' proficiency for CRUD
(Create, Read, Update and Delete) operations on in-context databases. A
benchmark named InConDB is presented and extensive experiments are conducted to
show the performance of different language models in enabling in-context
database by varying the database encoding method, prompting method, operation
type and input data distribution, revealing both the proficiency and
limitations.

摘要：大型語言模型 (LLM) 逐漸成為僅需少量範例就能處理各種任務的學習者，包括理解、規劃、推理、問答、算術計算等。這些能力的核心是 LLM 在表示和理解結構化或半結構化資料（例如表格和圖形）方面的能力。許多研究已證明，LLM 不僅可以推論表格資料或圖形，還提供了一個有前景的研究方向，將這些資料視為語境資料。語境資料庫的輕量級和人類可讀取特性有可能使其成為典型 RAG（檢索擴充生成）設定中傳統資料庫的替代方案。然而，幾乎所有目前的工作都專注於靜態語境資料，這不允許動態更新。在本文中，為了實現動態資料庫更新，提出了資料庫的 delta 編碼。我們探討了如何將儲存在傳統 RDBMS 中的資料編碼為語境文字，並評估 LLM 在語境資料庫上進行 CRUD（建立、讀取、更新和刪除）操作的能力。提出了名為 InConDB 的基準，並進行了廣泛的實驗，以顯示不同語言模型在通過改變資料庫編碼方法、提示方法、操作類型和輸入資料分佈來啟用語境資料庫方面的效能，揭示了能力和限制。

##### **Constrained Human-AI Cooperation: An Inclusive Embodied Social Intelligence Challenge**
2411.01796v1 by Weihua Du, Qiushi Lyu, Jiaming Shan, Zhenting Qi, Hongxin Zhang, Sunli Chen, Andi Peng, Tianmin Shu, Kwonjoon Lee, Behzad Dariush, Chuang Gan

We introduce Constrained Human-AI Cooperation (CHAIC), an inclusive embodied
social intelligence challenge designed to test social perception and
cooperation in embodied agents. In CHAIC, the goal is for an embodied agent
equipped with egocentric observations to assist a human who may be operating
under physical constraints -- e.g., unable to reach high places or confined to
a wheelchair -- in performing common household or outdoor tasks as efficiently
as possible. To achieve this, a successful helper must: (1) infer the human's
intents and constraints by following the human and observing their behaviors
(social perception), and (2) make a cooperative plan tailored to the human
partner to solve the task as quickly as possible, working together as a team
(cooperative planning). To benchmark this challenge, we create four new agents
with real physical constraints and eight long-horizon tasks featuring both
indoor and outdoor scenes with various constraints, emergency events, and
potential risks. We benchmark planning- and learning-based baselines on the
challenge and introduce a new method that leverages large language models and
behavior modeling. Empirical evaluations demonstrate the effectiveness of our
benchmark in enabling systematic assessment of key aspects of machine social
intelligence. Our benchmark and code are publicly available at this URL:
https://github.com/UMass-Foundation-Model/CHAIC.

摘要：我們提出受限人類人工智慧合作 (CHAIC)，這是一項包容性的具身社交智慧挑戰，旨在測試具身代理的社交認知和合作。在 CHAIC 中，目標是讓具備自我中心觀察能力的具身代理協助可能在身體限制下操作的人類——例如，無法觸及高處或只能坐在輪椅上——盡可能有效地執行常見的家務或戶外任務。為達成此目標，成功的助手必須：(1) 通過追蹤人類並觀察其行為來推斷人類的意圖和限制（社交認知），以及 (2) 制定適合人類夥伴的合作計畫，以盡可能快速地解決任務，並作為一個團隊合作（合作計畫）。為了對此挑戰進行基準測試，我們使用實際身體限制創建了四個新代理，以及八項長時程任務，其中包含具有各種限制、緊急事件和潛在風險的室內和室外場景。我們在挑戰中對基於計畫和學習的基準線進行基準測試，並引入一種利用大型語言模型和行為建模的新方法。實證評估證明了我們的基準在啟用對機器社交智慧關鍵方面的系統評估方面的有效性。我們的基準和程式碼在此 URL 公開提供：https://github.com/UMass-Foundation-Model/CHAIC。

##### **Thinking Forward and Backward: Effective Backward Planning with Large Language Models**
2411.01790v1 by Allen Z. Ren, Brian Ichter, Anirudha Majumdar

Large language models (LLMs) have exhibited remarkable reasoning and planning
capabilities. Most prior work in this area has used LLMs to reason through
steps from an initial to a goal state or criterion, thereby effectively
reasoning in a forward direction. Nonetheless, many planning problems exhibit
an inherent asymmetry such that planning backward from the goal is
significantly easier -- for example, if there are bottlenecks close to the
goal. We take inspiration from this observation and demonstrate that this bias
holds for LLM planning as well: planning performance in one direction
correlates with the planning complexity of the problem in that direction.
However, our experiments also reveal systematic biases which lead to poor
planning in the backward direction. With this knowledge, we propose a backward
planning algorithm for LLMs that first flips the problem and then plans forward
in the flipped problem. This helps avoid the backward bias, generate more
diverse candidate plans, and exploit asymmetries between the forward and
backward directions in planning problems -- we find that combining planning in
both directions with self-verification improves the overall planning success
rates by 4-24% in three planning domains.

摘要：大型語言模型 (LLM) 已展現出卓越的推理和規劃能力。這個領域中大多數先前的研究都使用 LLM 推理從初始狀態到目標狀態或準則的步驟，從而有效地向前推理。儘管如此，許多規劃問題都展現出固有的不對稱性，從目標向後規劃顯著容易許多，例如，如果接近目標時出現瓶頸。我們從這個觀察中獲得靈感，並證明這種偏差也適用於 LLM 規劃：單一方向的規劃效能與該方向問題的規劃複雜度相關。然而，我們的實驗也揭示了導致向後規劃不佳的系統偏差。有了這個知識，我們提出了一種 LLM 向後規劃演算法，它首先翻轉問題，然後在翻轉的問題中向前規劃。這有助於避免向後偏差，產生更多樣化的候選規劃，並利用規劃問題中向前和向後方向之間的不對稱性，我們發現將雙向規劃與自我驗證相結合，在三個規劃領域中將整體規劃成功率提高了 4-24%。

##### **Context Parallelism for Scalable Million-Token Inference**
2411.01783v1 by Amy, Yang, Jingyi Yang, Aya Ibrahim, Xinfeng Xie, Bangsheng Tang, Grigory Sizov, Jongsoo Park, Jianyu Huang

We present context parallelism for long-context large language model
inference, which achieves near-linear scaling for long-context prefill latency
with up to 128 H100 GPUs across 16 nodes. Particularly, our method achieves 1M
context prefill with Llama3 405B model in 77s (93% parallelization efficiency,
63% FLOPS utilization) and 128K context prefill in 3.8s. We develop two
lossless exact ring attention variants: pass-KV and pass-Q to cover a wide
range of use cases with the state-of-the-art performance: full prefill,
persistent KV prefill and decode. Benchmarks on H100 GPU hosts inter-connected
with RDMA and TCP both show similar scalability for long-context prefill,
demonstrating that our method scales well using common commercial data center
with medium-to-low inter-host bandwidth.

摘要：我們提出了用於長語境大語言模型推論的語境平行，在 16 個節點上使用多達 128 個 H100 GPU，可實現長語境預填載延遲的近線性縮放。特別是，我們的模型在 77 秒內使用 Llama3 405B 模型實現了 100 萬語境預填載（93% 並行效率，63% FLOPS 利用率）和在 3.8 秒內實現了 128K 語境預填載。我們開發了兩個無損耗精確環注意變體：pass-KV 和 pass-Q，以涵蓋廣泛的用例，並具有最先進的性能：完全預填載、持續 KV 預填載和解碼。在與 RDMA 和 TCP 互連的 H100 GPU 主機上的基準測試都顯示了長語境預填載的類似可擴展性，證明了我們的模型使用具有中低主機間頻寬的常見商用數據中心時可很好地擴展。

##### **Eurekaverse: Environment Curriculum Generation via Large Language Models**
2411.01775v1 by William Liang, Sam Wang, Hung-Ju Wang, Osbert Bastani, Dinesh Jayaraman, Yecheng Jason Ma

Recent work has demonstrated that a promising strategy for teaching robots a
wide range of complex skills is by training them on a curriculum of
progressively more challenging environments. However, developing an effective
curriculum of environment distributions currently requires significant
expertise, which must be repeated for every new domain. Our key insight is that
environments are often naturally represented as code. Thus, we probe whether
effective environment curriculum design can be achieved and automated via code
generation by large language models (LLM). In this paper, we introduce
Eurekaverse, an unsupervised environment design algorithm that uses LLMs to
sample progressively more challenging, diverse, and learnable environments for
skill training. We validate Eurekaverse's effectiveness in the domain of
quadrupedal parkour learning, in which a quadruped robot must traverse through
a variety of obstacle courses. The automatic curriculum designed by Eurekaverse
enables gradual learning of complex parkour skills in simulation and can
successfully transfer to the real-world, outperforming manual training courses
designed by humans.

摘要：最近的研究表明，教導機器人各種複雜技能的一個有前途的策略是，對它們進行漸進式更具挑戰性的環境課程訓練。然而，開發有效的環境分佈課程目前需要大量的專業知識，而且必須針對每個新領域重複進行。我們的關鍵見解是，環境通常以程式碼自然呈現。因此，我們探討是否能透過大型語言模型 (LLM) 的程式碼生成來實現並自動化有效的環境課程設計。在本文中，我們介紹了 Eurekaverse，一種無監督的環境設計演算法，它使用 LLM 來取樣漸進式更具挑戰性、多樣化且可學習的環境，以進行技能訓練。我們在四足跑酷學習領域驗證了 Eurekaverse 的有效性，其中四足機器人必須穿越各種障礙賽道。Eurekaverse 設計的自動課程能夠在模擬中逐步學習複雜的跑酷技能，並且可以成功轉移到現實世界，優於人類設計的手動訓練課程。

##### **Towards Pedagogical LLMs with Supervised Fine Tuning for Computing Education**
2411.01765v1 by Alexandra Vassar, Jake Renzella, Emily Ross, Andrew Taylor

This paper investigates supervised fine-tuning of large language models
(LLMs) to improve their pedagogical alignment in computing education,
addressing concerns that LLMs may hinder learning outcomes. The project
utilised a proprietary dataset of 2,500 high quality question/answer pairs from
programming course forums, and explores two research questions: the suitability
of university course forums in contributing to fine-tuning datasets, and how
supervised fine-tuning can improve LLMs' alignment with educational principles
such as constructivism. Initial findings suggest benefits in pedagogical
alignment of LLMs, with deeper evaluations required.

摘要：本文研究了大型語言模型 (LLM) 的監督微調，以改善其在計算教育中的教學對齊，解決了 LLM 可能阻礙學習成果的擔憂。該專案使用了一個包含 2,500 個高品質問答配對的專有資料集，這些配對來自程式設計課程論壇，並探討了兩個研究問題：大學課程論壇在促進微調資料集方面的適用性，以及監督微調如何能改善 LLM 與建構主義等教育原則的一致性。初步發現表明 LLM 的教學對齊有益，需要進行更深入的評估。

##### **Mitigating Spurious Correlations via Disagreement Probability**
2411.01757v1 by Hyeonggeun Han, Sehwan Kim, Hyungjun Joo, Sangwoo Hong, Jungwoo Lee

Models trained with empirical risk minimization (ERM) are prone to be biased
towards spurious correlations between target labels and bias attributes, which
leads to poor performance on data groups lacking spurious correlations. It is
particularly challenging to address this problem when access to bias labels is
not permitted. To mitigate the effect of spurious correlations without bias
labels, we first introduce a novel training objective designed to robustly
enhance model performance across all data samples, irrespective of the presence
of spurious correlations. From this objective, we then derive a debiasing
method, Disagreement Probability based Resampling for debiasing (DPR), which
does not require bias labels. DPR leverages the disagreement between the target
label and the prediction of a biased model to identify bias-conflicting
samples-those without spurious correlations-and upsamples them according to the
disagreement probability. Empirical evaluations on multiple benchmarks
demonstrate that DPR achieves state-of-the-art performance over existing
baselines that do not use bias labels. Furthermore, we provide a theoretical
analysis that details how DPR reduces dependency on spurious correlations.

摘要：使用經驗風險最小化 (ERM) 訓練的模型容易偏向於目標標籤和偏差屬性之間的虛假關聯，這會導致在缺乏虛假關聯的資料群組上表現不佳。當無法取得偏差標籤時，要解決這個問題特別具有挑戰性。為了在沒有偏差標籤的情況下減輕虛假關聯的影響，我們首先提出一個新的訓練目標，旨在穩健地提升所有資料樣本的模型效能，而不管是否存在虛假關聯。從這個目標，我們接著推導出一個去偏差方法，基於不一致機率的重新抽樣去偏差 (DPR)，它不需要偏差標籤。DPR 利用目標標籤和偏差模型預測之間的不一致，來找出偏差衝突的樣本（那些沒有虛假關聯的樣本），並根據不一致機率對它們進行上採樣。在多個基準測試上的實證評估證明，DPR 達到了現有基線的最佳效能，而這些基線沒有使用偏差標籤。此外，我們提供了理論分析，詳細說明 DPR 如何降低對虛假關聯的依賴性。

##### **RAGViz: Diagnose and Visualize Retrieval-Augmented Generation**
2411.01751v1 by Tevin Wang, Jingyuan He, Chenyan Xiong

Retrieval-augmented generation (RAG) combines knowledge from domain-specific
sources into large language models to ground answer generation. Current RAG
systems lack customizable visibility on the context documents and the model's
attentiveness towards such documents. We propose RAGViz, a RAG diagnosis tool
that visualizes the attentiveness of the generated tokens in retrieved
documents. With a built-in user interface, retrieval index, and Large Language
Model (LLM) backbone, RAGViz provides two main functionalities: (1) token and
document-level attention visualization, and (2) generation comparison upon
context document addition and removal. As an open-source toolkit, RAGViz can be
easily hosted with a custom embedding model and HuggingFace-supported LLM
backbone. Using a hybrid ANN (Approximate Nearest Neighbor) index,
memory-efficient LLM inference tool, and custom context snippet method, RAGViz
operates efficiently with a median query time of about 5 seconds on a moderate
GPU node. Our code is available at https://github.com/cxcscmu/RAGViz. A demo
video of RAGViz can be found at https://youtu.be/cTAbuTu6ur4.

摘要：檢索增強生成 (RAG) 將來自特定領域來源的知識結合到大型語言模型中，以建立答案生成。目前的 RAG 系統缺乏對脈絡文件和模型對此類文件的關注度的可自訂可視化。我們提出 RAGViz，這是一個 RAG 診斷工具，用於視覺化檢索文件中生成代碼的關注度。RAGViz 有一個內建使用者介面、檢索索引和大型語言模型 (LLM) 主幹，提供兩個主要功能：(1) 代碼和文件層級的關注度視覺化，以及 (2) 在加入和移除脈絡文件後進行生成比較。作為一個開源工具包，RAGViz 可以輕鬆地使用自訂嵌入模型和 HuggingFace 支援的 LLM 主幹進行主機。透過使用混合 ANN (近似最近鄰) 索引、記憶體效率良好的 LLM 推論工具和自訂脈絡片段方法，RAGViz 在中等 GPU 節點上以約 5 秒的中位數查詢時間有效率地運作。我們的程式碼可在 https://github.com/cxcscmu/RAGViz 取得。RAGViz 的示範影片可在 https://youtu.be/cTAbuTu6ur4 找到。

##### **DynaSaur: Large Language Agents Beyond Predefined Actions**
2411.01747v1 by Dang Nguyen, Viet Dac Lai, Seunghyun Yoon, Ryan A. Rossi, Handong Zhao, Ruiyi Zhang, Puneet Mathur, Nedim Lipka, Yu Wang, Trung Bui, Franck Dernoncourt, Tianyi Zhou

Existing LLM agent systems typically select actions from a fixed and
predefined set at every step. While this approach is effective in closed,
narrowly-scoped environments, we argue that it presents two major challenges
when deploying LLM agents in real-world scenarios: (1) selecting from a fixed
set of actions significantly restricts the planning and acting capabilities of
LLM agents, and (2) this approach requires substantial human effort to
enumerate and implement all possible actions, which becomes impractical in
complex environments with a vast number of potential actions. In this work, we
propose an LLM agent framework that enables the dynamic creation and
composition of actions in an online manner. In this framework, the agent
interacts with the environment by generating and executing programs written in
a general-purpose programming language at each step. Furthermore, generated
actions are accumulated over time for future reuse. Our extensive experiments
on the GAIA benchmark demonstrate that this framework offers significantly
greater flexibility and outperforms previous methods. Notably, it allows an LLM
agent to recover in scenarios where no relevant action exists in the predefined
set or when existing actions fail due to unforeseen edge cases. At the time of
writing, we hold the top position on the GAIA public leaderboard. Our code can
be found in
\href{https://github.com/adobe-research/dynasaur}{https://github.com/adobe-research/dynasaur}.

摘要：現有的 LLM 代理系統通常會在每一步從一個固定的且預先定義好的集合中選擇動作。雖然這種方法在封閉的、範圍狹窄的環境中很有效，但我們認為在現實場景中部署 LLM 代理時，它會出現兩個主要挑戰：(1) 從一個固定的動作集合中選擇會顯著限制 LLM 代理的規劃和行動能力，以及 (2) 這種方法需要大量的人力來列舉和實作所有可能的動作，這在具有大量潛在動作的複雜環境中會變得不切實際。在這項工作中，我們提出了一個 LLM 代理架構，它能以線上方式動態建立和組合動作。在這個架構中，代理透過在每一步產生和執行以通用程式語言編寫的程式，與環境互動。此外，產生的動作會隨著時間累積，以便未來重複使用。我們在 GAIA  benchmark 上進行的廣泛實驗證明了這個架構提供了顯著更高的靈活性，並且優於先前的各種方法。值得注意的是，它允許 LLM 代理在預定義集合中不存在相關動作或現有動作因無法預見的邊緣案例而失敗時復原。在撰寫本文時，我們在 GAIA 公開排行榜上名列前茅。我們的程式碼可以在
\href{https://github.com/adobe-research/dynasaur}{https://github.com/adobe-research/dynasaur} 中找到。

##### **xDiT: an Inference Engine for Diffusion Transformers (DiTs) with Massive Parallelism**
2411.01738v1 by Jiarui Fang, Jinzhe Pan, Xibo Sun, Aoyu Li, Jiannan Wang

Diffusion models are pivotal for generating high-quality images and videos.
Inspired by the success of OpenAI's Sora, the backbone of diffusion models is
evolving from U-Net to Transformer, known as Diffusion Transformers (DiTs).
However, generating high-quality content necessitates longer sequence lengths,
exponentially increasing the computation required for the attention mechanism,
and escalating DiTs inference latency. Parallel inference is essential for
real-time DiTs deployments, but relying on a single parallel method is
impractical due to poor scalability at large scales. This paper introduces
xDiT, a comprehensive parallel inference engine for DiTs. After thoroughly
investigating existing DiTs parallel approaches, xDiT chooses Sequence Parallel
(SP) and PipeFusion, a novel Patch-level Pipeline Parallel method, as
intra-image parallel strategies, alongside CFG parallel for inter-image
parallelism. xDiT can flexibly combine these parallel approaches in a hybrid
manner, offering a robust and scalable solution. Experimental results on two
8xL40 GPUs (PCIe) nodes interconnected by Ethernet and an 8xA100 (NVLink) node
showcase xDiT's exceptional scalability across five state-of-the-art DiTs.
Notably, we are the first to demonstrate DiTs scalability on Ethernet-connected
GPU clusters. xDiT is available at https://github.com/xdit-project/xDiT.

摘要：擴散模型對於生成高品質影像和影片至關重要。
受 OpenAI 的 Sora 成功啟發，擴散模型的骨幹從 U-Net 演進到 Transformer，稱為擴散 Transformer（DiT）。
然而，生成高品質內容需要更長的序列長度，這會使注意力機制所需的運算呈指數成長，並增加 DiT 推論延遲。並行推論對於 DiT 的即時部署至關重要，但由於在大型規模下可擴充性不佳，因此依賴單一並行方法並不實際。本文介紹 xDiT，這是一個 DiT 的全面並行推論引擎。在徹底調查現有的 DiT 並行方法後，xDiT 選擇序列並行（SP）和 PipeFusion，這是一種新穎的區塊級管道並行方法，作為影像內並行策略，以及 CFG 並行作為影像間並行。xDiT 可以靈活地以混合方式結合這些並行方法，提供強健且可擴充的解決方案。在兩個透過乙太網路互連的 8xL40 GPU（PCIe）節點和一個 8xA100（NVLink）節點上的實驗結果展示了 xDiT 在五個最先進的 DiT 上的出色可擴充性。值得注意的是，我們是第一個展示 DiT 在乙太網路連接的 GPU 集群上可擴充性的人。xDiT 可在 https://github.com/xdit-project/xDiT 取得。

##### **Rethinking Weight Decay for Robust Fine-Tuning of Foundation Models**
2411.01713v1 by Junjiao Tian, Chengyue Huang, Zsolt Kira

Modern optimizers such as AdamW, equipped with momentum and adaptive learning
rate, are designed to escape local minima and explore the vast parameter space.
This exploration is beneficial for finding good loss basins when training from
scratch. It is not necessarily ideal when resuming from a powerful foundation
model because it can lead to large deviations from the pre-trained
initialization and, consequently, worse robustness and generalization. At the
same time, strong regularization on all parameters can lead to under-fitting.
We hypothesize that selectively regularizing the parameter space is the key to
fitting and retraining the pre-trained knowledge. This paper proposes a new
weight decay technique, Selective Projection Decay (SPD), that selectively
imposes a strong penalty on certain layers while allowing others to change
freely. Intuitively, SPD expands and contracts the parameter search space for
layers with consistent and inconsistent loss reduction, respectively.
Experimentally, when equipped with SPD, Adam consistently provides better
in-distribution generalization and out-of-distribution robustness performance
on multiple popular vision and language benchmarks. Code available
at~\url{https://github.com/GT-RIPL/Selective-Projection-Decay.git}

摘要：現代的最佳化器，例如 AdamW，配備動量和自適應學習率，旨在逃離局部最小值並探索廣大的參數空間。這種探索對於在從頭開始訓練時找到良好的損失盆地是有益的。從強大的基礎模型中恢復時，這並不一定是理想的，因為它可能導致與預訓練初始化產生很大的偏差，從而導致更差的魯棒性和泛化性。同時，對所有參數進行強正則化可能會導致欠擬合。我們假設選擇性地正則化參數空間是擬合和重新訓練預訓練知識的關鍵。本文提出了一種新的權重衰減技術，選擇性投影衰減 (SPD)，它有選擇地對某些層施加強懲罰，同時允許其他層自由變化。直觀地說，SPD 分別擴展和收縮了具有持續和不一致損失減少的層的參數搜索空間。在實驗中，當配備了 SPD 時，Adam 在多個流行的視覺和語言基準上始終提供更好的分佈內泛化和分佈外魯棒性性能。代碼可在~\url{https://github.com/GT-RIPL/Selective-Projection-Decay.git} 中獲得

##### **SPES: Spectrogram Perturbation for Explainable Speech-to-Text Generation**
2411.01710v1 by Dennis Fucci, Marco Gaido, Beatrice Savoldi, Matteo Negri, Mauro Cettolo, Luisa Bentivogli

Spurred by the demand for interpretable models, research on eXplainable AI
for language technologies has experienced significant growth, with feature
attribution methods emerging as a cornerstone of this progress. While prior
work in NLP explored such methods for classification tasks and textual
applications, explainability intersecting generation and speech is lagging,
with existing techniques failing to account for the autoregressive nature of
state-of-the-art models and to provide fine-grained, phonetically meaningful
explanations. We address this gap by introducing Spectrogram Perturbation for
Explainable Speech-to-text Generation (SPES), a feature attribution technique
applicable to sequence generation tasks with autoregressive models. SPES
provides explanations for each predicted token based on both the input
spectrogram and the previously generated tokens. Extensive evaluation on speech
recognition and translation demonstrates that SPES generates explanations that
are faithful and plausible to humans.

摘要：在可解釋模型需求的驅使下，語言技術的 eXplainable AI 研究已大幅成長，其中特徵歸因方法成為這項進展的基石。雖然先前的 NLP 研究探索了此類方法，用於分類任務和文字應用，但可解釋性與生成和語音的交集仍有待加強，現有技術無法考量最先進模型的自動回歸性質，也無法提供細緻且在語音學上有意義的解釋。我們透過導入可解釋語音轉文字生成的光譜圖擾動 (SPES) 來解決這個差距，這是一種特徵歸因技術，適用於具有自動回歸模型的序列生成任務。SPES 提供每個預測詞彙的解釋，根據輸入光譜圖和先前生成的詞彙。在語音辨識和翻譯方面的廣泛評估證明，SPES 生成的解釋對人類來說是忠實且合理的。

##### **Investigating Large Language Models for Complex Word Identification in Multilingual and Multidomain Setups**
2411.01706v1 by Răzvan-Alexandru Smădu, David-Gabriel Ion, Dumitru-Clementin Cercel, Florin Pop, Mihaela-Claudia Cercel

Complex Word Identification (CWI) is an essential step in the lexical
simplification task and has recently become a task on its own. Some variations
of this binary classification task have emerged, such as lexical complexity
prediction (LCP) and complexity evaluation of multi-word expressions (MWE).
Large language models (LLMs) recently became popular in the Natural Language
Processing community because of their versatility and capability to solve
unseen tasks in zero/few-shot settings. Our work investigates LLM usage,
specifically open-source models such as Llama 2, Llama 3, and Vicuna v1.5, and
closed-source, such as ChatGPT-3.5-turbo and GPT-4o, in the CWI, LCP, and MWE
settings. We evaluate zero-shot, few-shot, and fine-tuning settings and show
that LLMs struggle in certain conditions or achieve comparable results against
existing methods. In addition, we provide some views on meta-learning combined
with prompt learning. In the end, we conclude that the current state of LLMs
cannot or barely outperform existing methods, which are usually much smaller.

摘要：複雜詞彙識別 (CWI) 是詞彙簡化任務中不可或缺的步驟，最近已成為一項獨立的任務。此二元分類任務出現了一些變化，例如詞彙複雜度預測 (LCP) 和多詞表達 (MWE) 的複雜度評估。大型語言模型 (LLM) 近期在自然語言處理社群中廣受歡迎，因為它們具有多功能性，並有能力在零次/少次嘗試的設定中解決未見過的問題。我們的研究探討了 LLM 的使用，特別是開放原始碼模型，例如 Llama 2、Llama 3 和 Vicuna v1.5，以及閉源模型，例如 ChatGPT-3.5-turbo 和 GPT-4o，在 CWI、LCP 和 MWE 設定中。我們評估了零次、少次和微調設定，並顯示 LLM 在某些條件下會遇到困難，或與現有方法相比獲得相當的結果。此外，我們提供了一些關於元學習結合提示學習的觀點。最後，我們得出結論，LLM 的當前狀態無法或僅能勉強優於現有方法，而現有方法通常小得多。

##### **Data Extraction Attacks in Retrieval-Augmented Generation via Backdoors**
2411.01705v1 by Yuefeng Peng, Junda Wang, Hong Yu, Amir Houmansadr

Despite significant advancements, large language models (LLMs) still struggle
with providing accurate answers when lacking domain-specific or up-to-date
knowledge. Retrieval-Augmented Generation (RAG) addresses this limitation by
incorporating external knowledge bases, but it also introduces new attack
surfaces. In this paper, we investigate data extraction attacks targeting the
knowledge databases of RAG systems. We demonstrate that previous attacks on RAG
largely depend on the instruction-following capabilities of LLMs, and that
simple fine-tuning can reduce the success rate of such attacks to nearly zero.
This makes these attacks impractical since fine-tuning is a common practice
when deploying LLMs in specific domains. To further reveal the vulnerability,
we propose to backdoor RAG, where a small portion of poisoned data is injected
during the fine-tuning phase to create a backdoor within the LLM. When this
compromised LLM is integrated into a RAG system, attackers can exploit specific
triggers in prompts to manipulate the LLM to leak documents from the retrieval
database. By carefully designing the poisoned data, we achieve both verbatim
and paraphrased document extraction. We show that with only 3\% poisoned data,
our method achieves an average success rate of 79.7\% in verbatim extraction on
Llama2-7B, with a ROUGE-L score of 64.21, and a 68.6\% average success rate in
paraphrased extraction, with an average ROUGE score of 52.6 across four
datasets. These results underscore the privacy risks associated with the supply
chain when deploying RAG systems.

摘要：儘管有顯著的進展，大型語言模型 (LLM) 在缺乏特定領域或最新的知識時，仍然難以提供準確的答案。檢索增強生成 (RAG) 透過納入外部知識庫來解決此限制，但它也引入了新的攻擊面。在本文中，我們調查針對 RAG 系統知識庫的資料提取攻擊。我們證明，先前對 RAG 的攻擊在很大程度上取決於 LLM 的指令遵循能力，而且簡單的微調可以將此類攻擊的成功率降低到接近於零。這使得這些攻擊不切實際，因為微調是將 LLM 部署到特定領域的常見做法。為了進一步揭示漏洞，我們建議後門 RAG，在微調階段注入一小部分中毒資料，以在 LLM 中建立後門。當這個受損的 LLM 整合到 RAG 系統中時，攻擊者可以利用提示中的特定觸發器，操縱 LLM 從檢索資料庫中洩露文件。透過仔細設計中毒資料，我們實現逐字和轉述的文檔提取。我們表明，我們的模型只有 3% 的中毒資料，在 Llama2-7B 上的逐字提取中，平均成功率達到 79.7%，ROUGE-L 分數為 64.21，在轉述提取中平均成功率為 68.6%，在四個資料集中的平均 ROUGE 分數為 52.6。這些結果強調了在部署 RAG 系統時，供應鏈相關的隱私風險。

##### **UniGuard: Towards Universal Safety Guardrails for Jailbreak Attacks on Multimodal Large Language Models**
2411.01703v1 by Sejoon Oh, Yiqiao Jin, Megha Sharma, Donghyun Kim, Eric Ma, Gaurav Verma, Srijan Kumar

Multimodal large language models (MLLMs) have revolutionized vision-language
understanding but are vulnerable to multimodal jailbreak attacks, where
adversaries meticulously craft inputs to elicit harmful or inappropriate
responses. We propose UniGuard, a novel multimodal safety guardrail that
jointly considers the unimodal and cross-modal harmful signals. UniGuard is
trained such that the likelihood of generating harmful responses in a toxic
corpus is minimized, and can be seamlessly applied to any input prompt during
inference with minimal computational costs. Extensive experiments demonstrate
the generalizability of UniGuard across multiple modalities and attack
strategies. It demonstrates impressive generalizability across multiple
state-of-the-art MLLMs, including LLaVA, Gemini Pro, GPT-4, MiniGPT-4, and
InstructBLIP, thereby broadening the scope of our solution.

摘要：多模態大型語言模型 (MLLM) 徹底改變了視覺語言理解，但容易受到多模態越獄攻擊，其中對手精心製作輸入以引發有害或不適當的回應。我們提出 UniGuard，這是一個新穎的多模態安全護欄，它共同考慮了單模態和跨模態的有害訊號。UniGuard 接受訓練，將在有毒語料庫中產生有害回應的可能性降至最低，並且可以在推理過程中無縫應用於任何輸入提示，同時將運算成本降至最低。廣泛的實驗證明了 UniGuard 在多種模態和攻擊策略中的泛化能力。它展示了在多個最先進的 MLLM 中令人印象深刻的泛化能力，包括 LLaVA、Gemini Pro、GPT-4、MiniGPT-4 和 InstructBLIP，從而擴大了我們解決方案的範圍。

##### **Unlocking the Theory Behind Scaling 1-Bit Neural Networks**
2411.01663v1 by Majid Daliri, Zhao Song, Chiwun Yang

Recently, 1-bit Large Language Models (LLMs) have emerged, showcasing an
impressive combination of efficiency and performance that rivals traditional
LLMs. Research by Wang et al. (2023); Ma et al. (2024) indicates that the
performance of these 1-bit LLMs progressively improves as the number of
parameters increases, hinting at the potential existence of a Scaling Law for
1-bit Neural Networks. In this paper, we present the first theoretical result
that rigorously establishes this scaling law for 1-bit models. We prove that,
despite the constraint of weights restricted to $\{-1, +1\}$, the dynamics of
model training inevitably align with kernel behavior as the network width
grows. This theoretical breakthrough guarantees convergence of the 1-bit model
to an arbitrarily small loss as width increases. Furthermore, we introduce the
concept of the generalization difference, defined as the gap between the
outputs of 1-bit networks and their full-precision counterparts, and
demonstrate that this difference maintains a negligible level as network width
scales. Building on the work of Kaplan et al. (2020), we conclude by examining
how the training loss scales as a power-law function of the model size, dataset
size, and computational resources utilized for training. Our findings
underscore the promising potential of scaling 1-bit neural networks, suggesting
that int1 could become the standard in future neural network precision.

摘要：<paragraph>最近，1 位大型語言模型 (LLM) 浮現，展示出令人印象深刻的效率和效能結合，可媲美傳統 LLM。王等人 (2023)；馬等人 (2024) 的研究指出，這些 1 位 LLM 的效能會隨著參數數量增加而逐步提升，暗示 1 位神經網路存在規模律的可能性。在本文中，我們提出第一個理論結果，嚴謹地建立 1 位模型的規模律。我們證明，儘管權重限制在 $\{-1, +1\}$ 的約束下，模型訓練的動態會隨著網路寬度增加而不可避免地與核心的行為一致。這個理論突破保證 1 位模型的收斂性，讓損失隨著寬度增加而任意地變小。此外，我們提出泛化差異的概念，定義為 1 位網路和它們的完全精確度對應物之間的輸出差距，並證明這個差異會隨著網路寬度規模而維持在可忽略的層級。建立在 Kaplan 等人 (2020) 的研究上，我們最後探討訓練損失如何以冪律函數的形式隨著模型大小、資料集大小和用於訓練的計算資源而規模化。我們的發現強調規模化 1 位神經網路的潛力，表明 int1 可能會成為未來神經網路精度的標準。</paragraph>

##### **Diagnosing Medical Datasets with Training Dynamics**
2411.01653v1 by Laura Wenderoth

This study explores the potential of using training dynamics as an automated
alternative to human annotation for evaluating the quality of training data.
The framework used is Data Maps, which classifies data points into categories
such as easy-to-learn, hard-to-learn, and ambiguous (Swayamdipta et al., 2020).
Swayamdipta et al. (2020) highlight that difficult-to-learn examples often
contain errors, and ambiguous cases significantly impact model training. To
confirm the reliability of these findings, we replicated the experiments using
a challenging dataset, with a focus on medical question answering. In addition
to text comprehension, this field requires the acquisition of detailed medical
knowledge, which further complicates the task. A comprehensive evaluation was
conducted to assess the feasibility and transferability of the Data Maps
framework to the medical domain. The evaluation indicates that the framework is
unsuitable for addressing datasets' unique challenges in answering medical
questions.

摘要：本研究探討使用訓練動態作為自動化替代方案，以評估訓練資料品質，以取代人工標註。所使用的架構為資料地圖，其將資料點分類為易於學習、難以學習和模稜兩可等類別（Swayamdipta 等人，2020 年）。Swayamdipta 等人（2020 年）強調，難以學習的範例通常包含錯誤，而模稜兩可的情況會對模型訓練產生重大影響。為了確認這些發現的可靠性，我們使用具有挑戰性的資料集複製了實驗，重點放在醫學問題解答上。除了文字理解之外，這個領域還需要獲取詳細的醫學知識，這進一步使任務複雜化。我們進行了全面的評估，以評估資料地圖架構在醫學領域的可行性和可轉移性。評估結果表明，該架構不適合解決資料集在回答醫學問題時面臨的獨特挑戰。

##### **Optimizing Gastrointestinal Diagnostics: A CNN-Based Model for VCE Image Classification**
2411.01652v1 by Vaneeta Ahlawat, Rohit Sharma, Urush

In recent years, the diagnosis of gastrointestinal (GI) diseases has advanced
greatly with the advent of high-tech video capsule endoscopy (VCE) technology,
which allows for non-invasive observation of the digestive system. The MisaHub
Capsule Vision Challenge encourages the development of vendor-independent
artificial intelligence models that can autonomously classify GI anomalies from
VCE images. This paper presents CNN architecture designed specifically for
multiclass classification of ten gut pathologies, including angioectasia,
bleeding, erosion, erythema, foreign bodies, lymphangiectasia, polyps, ulcers,
and worms as well as their normal state.

摘要：近年来，随着高科技视频胶囊内窥镜（VCE）技术的出现，胃肠（GI）疾病的诊断取得了很大进展，该技术允许对消化系统进行无创观察。MisaHub 胶囊视觉挑战鼓励开发独立于供应商的人工智能模型，该模型可以自主地从 VCE 图像中对 GI 异常进行分类。本文介绍了专门为十种肠道疾病的多类分类而设计的 CNN 架构，包括血管扩张、出血、糜烂、红斑、异物、淋巴管扩张、息肉、溃疡和蠕虫以及它们的正常状态。

##### **Optical Flow Representation Alignment Mamba Diffusion Model for Medical Video Generation**
2411.01647v1 by Zhenbin Wang, Lei Zhang, Lituan Wang, Minjuan Zhu, Zhenwei Zhang

Medical video generation models are expected to have a profound impact on the
healthcare industry, including but not limited to medical education and
training, surgical planning, and simulation. Current video diffusion models
typically build on image diffusion architecture by incorporating temporal
operations (such as 3D convolution and temporal attention). Although this
approach is effective, its oversimplification limits spatio-temporal
performance and consumes substantial computational resources. To counter this,
we propose Medical Simulation Video Generator (MedSora), which incorporates
three key elements: i) a video diffusion framework integrates the advantages of
attention and Mamba, balancing low computational load with high-quality video
generation, ii) an optical flow representation alignment method that implicitly
enhances attention to inter-frame pixels, and iii) a video variational
autoencoder (VAE) with frequency compensation addresses the information loss of
medical features that occurs when transforming pixel space into latent features
and then back to pixel frames. Extensive experiments and applications
demonstrate that MedSora exhibits superior visual quality in generating medical
videos, outperforming the most advanced baseline methods. Further results and
code are available at https://wongzbb.github.io/MedSora

摘要：醫療影片生成模型預計將對醫療保健產業產生深遠的影響，包括但不限於醫學教育和訓練、手術規劃和模擬。目前的影片擴散模型通常建立在影像擴散架構上，並結合時間運算（例如 3D 摺積和時間注意力）。儘管此方法有效，但其過於簡化限制了時空效能，並消耗大量的運算資源。為了解決這個問題，我們提出醫學模擬影片生成器 (MedSora)，它結合了三個關鍵要素：i) 一個影片擴散架構整合了注意力和 Mamba 的優點，在低運算負載和高品質影片生成之間取得平衡，ii) 一個光流表示對齊方法，可以隱含地增強對影格間像素的注意力，以及 iii) 一個具有頻率補償的影片變異自動編碼器 (VAE)，用於解決在將像素空間轉換為潛在特徵，然後再轉回像素影格時發生的醫療特徵資訊遺失問題。廣泛的實驗和應用證明，MedSora 在生成醫療影片方面展現出優異的視覺品質，優於最先進的基準方法。進一步的結果和程式碼可以在 https://wongzbb.github.io/MedSora 取得

##### **Enriching Tabular Data with Contextual LLM Embeddings: A Comprehensive Ablation Study for Ensemble Classifiers**
2411.01645v1 by Gjergji Kasneci, Enkelejda Kasneci

Feature engineering is crucial for optimizing machine learning model
performance, particularly in tabular data classification tasks. Leveraging
advancements in natural language processing, this study presents a systematic
approach to enrich tabular datasets with features derived from large language
model embeddings. Through a comprehensive ablation study on diverse datasets,
we assess the impact of RoBERTa and GPT-2 embeddings on ensemble classifiers,
including Random Forest, XGBoost, and CatBoost. Results indicate that
integrating embeddings with traditional numerical and categorical features
often enhances predictive performance, especially on datasets with class
imbalance or limited features and samples, such as UCI Adult, Heart Disease,
Titanic, and Pima Indian Diabetes, with improvements particularly notable in
XGBoost and CatBoost classifiers. Additionally, feature importance analysis
reveals that LLM-derived features frequently rank among the most impactful for
the predictions. This study provides a structured approach to embedding-based
feature enrichment and illustrates its benefits in ensemble learning for
tabular data.

摘要：特徵工程對於最佳化機器學習模型效能至關重要，特別是在表格資料分類任務中。本研究利用自然語言處理的進展，提出一個系統性的方法，以從大型語言模型嵌入中衍生的特徵來豐富表格資料集。透過對不同資料集進行全面的消融研究，我們評估 RoBERTa 和 GPT-2 嵌入對整體分類器的影響，包括隨機森林、XGBoost 和 CatBoost。結果表明，將嵌入與傳統數值和類別特徵整合通常會增強預測效能，特別是在類別不平衡或特徵和樣本有限的資料集上，例如 UCI Adult、Heart Disease、Titanic 和 Pima Indian Diabetes，其中 XGBoost 和 CatBoost 分類器的改進特別顯著。此外，特徵重要性分析顯示，LLM 衍生的特徵經常在預測中排名最高。本研究提供了一個基於嵌入的特徵豐富的結構化方法，並說明了其在表格資料的整體學習中的好處。

##### **EcoAct: Economic Agent Determines When to Register What Action**
2411.01643v1 by Shaokun Zhang, Jieyu Zhang, Dujian Ding, Mirian Hipolito Garcia, Ankur Mallick, Daniel Madrigal, Menglin Xia, Victor Rühle, Qingyun Wu, Chi Wang

Recent advancements have enabled Large Language Models (LLMs) to function as
agents that can perform actions using external tools. This requires
registering, i.e., integrating tool information into the LLM context prior to
taking actions. Current methods indiscriminately incorporate all candidate
tools into the agent's context and retain them across multiple reasoning steps.
This process remains opaque to LLM agents and is not integrated into their
reasoning procedures, leading to inefficiencies due to increased context length
from irrelevant tools. To address this, we introduce EcoAct, a tool using
algorithm that allows LLMs to selectively register tools as needed, optimizing
context use. By integrating the tool registration process into the reasoning
procedure, EcoAct reduces computational costs by over 50% in multiple steps
reasoning tasks while maintaining performance, as demonstrated through
extensive experiments. Moreover, it can be plugged into any reasoning pipeline
with only minor modifications to the prompt, making it applicable to LLM agents
now and future.

摘要：最近的進展已讓大型語言模型 (LLM) 能夠作為代理，使用外部工具執行動作。這需要註冊，也就是在採取動作之前將工具資訊整合到 LLM 背景中。目前的技術會不加區分地將所有候選工具納入代理的背景中，並在多個推理步驟中保留它們。這個過程對 LLM 代理來說仍然不透明，而且未整合到其推理程序中，導致因不相關工具而增加的背景長度而造成效率低下。為了解決這個問題，我們引入了 EcoAct，一個使用演算法的工具，讓 LLM 能夠根據需要有選擇地註冊工具，最佳化背景使用。透過將工具註冊程序整合到推理程序中，EcoAct 在多步驟推理任務中將計算成本降低了 50% 以上，同時維持效能，如透過廣泛的實驗所證明的。此外，它可以插入任何推理管道，僅需對提示進行微小的修改，使其適用於現在和未來的 LLM 代理。

##### **Know Where You're Uncertain When Planning with Multimodal Foundation Models: A Formal Framework**
2411.01639v1 by Neel P. Bhatt, Yunhao Yang, Rohan Siva, Daniel Milan, Ufuk Topcu, Zhangyang Wang

Multimodal foundation models offer a promising framework for robotic
perception and planning by processing sensory inputs to generate actionable
plans. However, addressing uncertainty in both perception (sensory
interpretation) and decision-making (plan generation) remains a critical
challenge for ensuring task reliability. We present a comprehensive framework
to disentangle, quantify, and mitigate these two forms of uncertainty. We first
introduce a framework for uncertainty disentanglement, isolating perception
uncertainty arising from limitations in visual understanding and decision
uncertainty relating to the robustness of generated plans.
  To quantify each type of uncertainty, we propose methods tailored to the
unique properties of perception and decision-making: we use conformal
prediction to calibrate perception uncertainty and introduce
Formal-Methods-Driven Prediction (FMDP) to quantify decision uncertainty,
leveraging formal verification techniques for theoretical guarantees. Building
on this quantification, we implement two targeted intervention mechanisms: an
active sensing process that dynamically re-observes high-uncertainty scenes to
enhance visual input quality and an automated refinement procedure that
fine-tunes the model on high-certainty data, improving its capability to meet
task specifications. Empirical validation in real-world and simulated robotic
tasks demonstrates that our uncertainty disentanglement framework reduces
variability by up to 40% and enhances task success rates by 5% compared to
baselines. These improvements are attributed to the combined effect of both
interventions and highlight the importance of uncertainty disentanglement which
facilitates targeted interventions that enhance the robustness and reliability
of autonomous systems.

摘要：多模态基础模型提供了一个有前途的机器人框架，通过处理传感器输入来生成可操作的计划，从而实现机器人感知和规划。然而，在感知（传感器解释）和决策制定（计划生成）中解决不确定性仍然是确保任务可靠性的关键挑战。我们提出了一个全面的框架来解开、量化和减轻这两种形式的不确定性。我们首先引入了一个不确定性解缠框架，分离了由于视觉理解的局限性而产生的感知不确定性和与生成计划的鲁棒性相关的决策不确定性。为了量化每种类型的不确定性，我们提出了针对感知和决策制定独特属性量身定制的方法：我们使用保形预测来校准感知不确定性，并引入形式方法驱动的预测 (FMDP) 来量化决策不确定性，利用形式验证技术来获得理论保证。在此量化的基础上，我们实施了两种有针对性的干预机制：一个主动感知过程，动态地重新观察高不确定性场景以提高视觉输入质量，以及一个自动细化程序，该程序在高确定性数据上对模型进行微调，提高其满足任务规范的能力。在真实世界和模拟机器人任务中的经验验证表明，与基线相比，我们的不确定性解缠框架将可变性降低了高达 40%，并将任务成功率提高了 5%。这些改进归因于两种干预措施的综合作用，并突出了不确定性解缠的重要性，它促进了有针对性的干预措施，从而增强了自主系统的鲁棒性和可靠性。

##### **Leveraging Microservices Architecture for Dynamic Pricing in the Travel Industry: Algorithms, Scalability, and Impact on Revenue and Customer Satisfaction**
2411.01636v1 by Biman Barua, M. Shamim Kaiser

This research investigates the implementation of a real-time,
microservices-oriented dynamic pricing system for the travel sector. The system
is designed to address factors such as demand, competitor pricing, and other
external circumstances in real-time. Both controlled simulation and real-life
application showed a respectable gain of 22% in revenue generation and a 17%
improvement in pricing response time which concern the issues of scaling and
flexibility of classical pricing mechanisms. Demand forecasting, competitor
pricing strategies, and event-based pricing were implemented as separate
microservices to enhance their scalability and reduce resource consumption by
30% during peak loads. Customers were also more content as depicted by a 15%
increase in satisfaction score post-implementation given the appreciation of
more appropriate pricing. This research enhances the existing literature with
practical illustrations of the possible application of microservices technology
in developing dynamic pricing solutions in a complex and data-driven context.
There exist however areas for improvement for instance inter-service latency
and the need for extensive real-time data pipelines. The present research goes
on to suggest combining these with direct data capture from customer behavior
at the same time as machine learning capacity developments in pricing
algorithms to assist in more accurate real time pricing. It is determined that
the use of microservices is a reasonable and efficient model for dynamic
pricing, allowing the tourism sector to employ evidence-based and customer
centric pricing techniques, which ensures that their profits are not
jeopardized because of the need for customers.

摘要：本研究探討實作一個即時、微服務導向的動態定價系統，適用於旅遊業。此系統旨在即時處理需求、競爭對手定價和其他外部環境等因素。受控模擬和實際應用均顯示營收產生增加22%，定價反應時間改善17%，這涉及傳統定價機制的擴充性和彈性問題。需求預測、競爭對手定價策略和基於事件的定價實作為獨立微服務，以提升其擴充性並在尖峰負載期間減少30%的資源消耗。客戶也較為滿意，從實作後滿意度分數增加15%可見一斑，這是因為更適當的定價獲得了肯定。本研究以實用範例說明微服務技術在複雜且資料驅動的環境中開發動態定價解決方案的可能應用，進而豐富了現有文獻。然而，仍有進步空間，例如服務間延遲和對大量即時資料管線的需求。本研究進一步建議將這些需求與直接從客戶行為擷取資料結合，同時在定價演算法中發展機器學習能力，以協助更準確的即時定價。研究結果確定，使用微服務是一種合理且有效的動態定價模式，可讓旅遊業採用以證據為基礎且以客戶為中心的定價技術，確保其利潤不會因客戶需求而受到影響。

##### **Counterfactual explainability of black-box prediction models**
2411.01625v1 by Zijun Gao, Qingyuan Zhao

It is crucial to be able to explain black-box prediction models to use them
effectively and safely in practice. Most existing tools for model explanations
are associational rather than causal, and we use two paradoxical examples to
show that such explanations are generally inadequate. Motivated by the concept
of genetic heritability in twin studies, we propose a new notion called
counterfactual explainability for black-box prediction models. Counterfactual
explainability has three key advantages: (1) it leverages counterfactual
outcomes and extends methods for global sensitivity analysis (such as
functional analysis of variance and Sobol's indices) to a causal setting; (2)
it is defined not only for the totality of a set of input factors but also for
their interactions (indeed, it is a probability measure on a whole
``explanation algebra''); (3) it also applies to dependent input factors whose
causal relationship can be modeled by a directed acyclic graph, thus
incorporating causal mechanisms into the explanation.

摘要：能夠解釋黑箱預測模型對於在實務上有效且安全地使用它們至關重要。現有的模型解釋工具大多是聯想性的，而非因果性的，而我們使用兩個自相矛盾的範例來說明這種解釋通常是不充分的。受到雙胞胎研究中遺傳遺傳率的概念啟發，我們提出一個新的概念，稱為黑箱預測模型的反事實可解釋性。反事實可解釋性有三個關鍵優點： (1) 它利用反事實結果，並將全局敏感度分析的方法（例如變異數的函數分析和 Sobol 指數）擴展到因果設定； (2) 它不僅定義於一組輸入因素的總和，也定義於它們的交互作用（事實上，它是對整個「解釋代數」的機率測度）； (3) 它也適用於因果關係可以用有向無環圖建模的依賴輸入因素，因此將因果機制納入解釋中。

##### **FilterNet: Harnessing Frequency Filters for Time Series Forecasting**
2411.01623v1 by Kun Yi, Jingru Fei, Qi Zhang, Hui He, Shufeng Hao, Defu Lian, Wei Fan

While numerous forecasters have been proposed using different network
architectures, the Transformer-based models have state-of-the-art performance
in time series forecasting. However, forecasters based on Transformers are
still suffering from vulnerability to high-frequency signals, efficiency in
computation, and bottleneck in full-spectrum utilization, which essentially are
the cornerstones for accurately predicting time series with thousands of
points. In this paper, we explore a novel perspective of enlightening signal
processing for deep time series forecasting. Inspired by the filtering process,
we introduce one simple yet effective network, namely FilterNet, built upon our
proposed learnable frequency filters to extract key informative temporal
patterns by selectively passing or attenuating certain components of time
series signals. Concretely, we propose two kinds of learnable filters in the
FilterNet: (i) Plain shaping filter, that adopts a universal frequency kernel
for signal filtering and temporal modeling; (ii) Contextual shaping filter,
that utilizes filtered frequencies examined in terms of its compatibility with
input signals for dependency learning. Equipped with the two filters, FilterNet
can approximately surrogate the linear and attention mappings widely adopted in
time series literature, while enjoying superb abilities in handling
high-frequency noises and utilizing the whole frequency spectrum that is
beneficial for forecasting. Finally, we conduct extensive experiments on eight
time series forecasting benchmarks, and experimental results have demonstrated
our superior performance in terms of both effectiveness and efficiency compared
with state-of-the-art methods. Code is available at this repository:
$\href{https://github.com/aikunyi/FilterNet}{\small\text{this https URL.}}$

摘要：<paragraph>儘管已經提出使用不同網路架構的許多預測器，但基於 Transformer 的模型在時間序列預測方面具有最先進的效能。然而，基於 Transformer 的預測器仍然容易受到高頻訊號、計算效率和全頻譜利用的瓶頸影響，這基本上是準確預測具有數千個點的時間序列的基石。在本文中，我們探索了啟發信號處理以進行深度時間序列預測的新觀點。受過濾流程的啟發，我們引入了一個簡單但有效的網路，即 FilterNet，建立在我們提出的可學習頻率濾波器之上，透過選擇性地通過或衰減時間序列訊號的某些組成部分來提取關鍵資訊性的時間模式。具體來說，我們在 FilterNet 中提出了兩種可學習濾波器：(i) 純粹形狀濾波器，採用通用頻率核進行信號濾波和時間建模；(ii) 上下文形狀濾波器，利用根據與輸入訊號的相容性檢查的濾波頻率進行依賴學習。FilterNet 具備這兩種濾波器，可以近似替代時間序列文獻中廣泛採用的線性和注意力對應，同時在處理高頻雜訊和利用對預測有益的整個頻率譜方面具有極佳的能力。最後，我們對八個時間序列預測基準進行了廣泛的實驗，實驗結果證明了我們在有效性和效率方面都優於最先進的方法。程式碼可以在這個儲存庫中取得：
$\href{https://github.com/aikunyi/FilterNet}{\small\text{這個 https 網址。}}$</paragraph>

##### **VQ-Map: Bird's-Eye-View Map Layout Estimation in Tokenized Discrete Space via Vector Quantization**
2411.01618v1 by Yiwei Zhang, Jin Gao, Fudong Ge, Guan Luo, Bing Li, Zhaoxiang Zhang, Haibin Ling, Weiming Hu

Bird's-eye-view (BEV) map layout estimation requires an accurate and full
understanding of the semantics for the environmental elements around the ego
car to make the results coherent and realistic. Due to the challenges posed by
occlusion, unfavourable imaging conditions and low resolution,
\emph{generating} the BEV semantic maps corresponding to corrupted or invalid
areas in the perspective view (PV) is appealing very recently. \emph{The
question is how to align the PV features with the generative models to
facilitate the map estimation}. In this paper, we propose to utilize a
generative model similar to the Vector Quantized-Variational AutoEncoder
(VQ-VAE) to acquire prior knowledge for the high-level BEV semantics in the
tokenized discrete space. Thanks to the obtained BEV tokens accompanied with a
codebook embedding encapsulating the semantics for different BEV elements in
the groundtruth maps, we are able to directly align the sparse backbone image
features with the obtained BEV tokens from the discrete representation learning
based on a specialized token decoder module, and finally generate high-quality
BEV maps with the BEV codebook embedding serving as a bridge between PV and
BEV. We evaluate the BEV map layout estimation performance of our model, termed
VQ-Map, on both the nuScenes and Argoverse benchmarks, achieving 62.2/47.6 mean
IoU for surround-view/monocular evaluation on nuScenes, as well as 73.4 IoU for
monocular evaluation on Argoverse, which all set a new record for this map
layout estimation task. The code and models are available on
\url{https://github.com/Z1zyw/VQ-Map}.

摘要：鳥瞰圖 (BEV) 地圖配置估計需要準確且充分了解自我車輛周圍環境元素的語義，才能讓結果連貫且逼真。由於遮擋、不利的影像條件和低解析度所帶來的挑戰，最近產生對應於透視圖 (PV) 中損壞或無效區域的 BEV 語義地圖非常有吸引力。問題是如何將 PV 特徵與生成模型對齊，以利於地圖估計。在本文中，我們建議利用類似於向量量化變分自動編碼器 (VQ-VAE) 的生成模型，在標記化的離散空間中獲取 BEV 高層級語義的先驗知識。由於獲得的 BEV 標記附帶一個代碼簿嵌入，其中封裝了地面實況地圖中不同 BEV 元素的語義，我們能夠直接將稀疏主幹影像特徵與從基於離散表示學習的獲得 BEV 標記對齊，最後生成高品質的 BEV 地圖，其中 BEV 代碼簿嵌入作為 PV 和 BEV 之間的橋樑。我們在 nuScenes 和 Argoverse 基準上評估了我們模型（稱為 VQ-Map）的 BEV 地圖配置估計效能，在 nuScenes 上的環景/單眼評估中達到 62.2/47.6 的平均 IoU，以及在 Argoverse 上的單眼評估中達到 73.4 的 IoU，這些都為此地圖配置估計任務創下了新的紀錄。程式碼和模型可在 https://github.com/Z1zyw/VQ-Map 上取得。

##### **Ontology Population using LLMs**
2411.01612v1 by Sanaz Saki Norouzi, Adrita Barua, Antrea Christou, Nikita Gautam, Andrew Eells, Pascal Hitzler, Cogan Shimizu

Knowledge graphs (KGs) are increasingly utilized for data integration,
representation, and visualization. While KG population is critical, it is often
costly, especially when data must be extracted from unstructured text in
natural language, which presents challenges, such as ambiguity and complex
interpretations. Large Language Models (LLMs) offer promising capabilities for
such tasks, excelling in natural language understanding and content generation.
However, their tendency to ``hallucinate'' can produce inaccurate outputs.
Despite these limitations, LLMs offer rapid and scalable processing of natural
language data, and with prompt engineering and fine-tuning, they can
approximate human-level performance in extracting and structuring data for KGs.
This study investigates LLM effectiveness for the KG population, focusing on
the Enslaved.org Hub Ontology. In this paper, we report that compared to the
ground truth, LLM's can extract ~90% of triples, when provided a modular
ontology as guidance in the prompts.

摘要：知識圖譜 (KG) 愈來愈多用於資料整合、表示和視覺化。儘管 KG 填充至關重要，但它通常很昂貴，特別是在必須從自然語言中非結構化文字中提取資料時，這會帶來挑戰，例如歧義和複雜的詮釋。大型語言模型 (LLM) 為此類任務提供了有前景的能力，擅長自然語言理解和內容生成。然而，它們「產生幻覺」的傾向可能會產生不準確的輸出。儘管有這些限制，LLM 提供了自然語言資料的快速且可擴充處理，並且透過提示工程和微調，它們可以近似人類層級的效能，以提取和建構 KG 的資料。本研究調查 LLM 對 KG 填充的有效性，重點關注 Enslaved.org Hub Ontology。在本文中，我們報告與真實情況相比，當在提示中提供模組化本体作為指導時，LLM 可以提取約 90% 的三元組。

