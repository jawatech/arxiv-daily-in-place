{"2407.09025": {"publish_time": "2024-07-12", "title": "SpreadsheetLLM: Encoding Spreadsheets for Large Language Models", "paper_summary": "Spreadsheets, with their extensive two-dimensional grids, various layouts,\nand diverse formatting options, present notable challenges for large language\nmodels (LLMs). In response, we introduce SpreadsheetLLM, pioneering an\nefficient encoding method designed to unleash and optimize LLMs' powerful\nunderstanding and reasoning capability on spreadsheets. Initially, we propose a\nvanilla serialization approach that incorporates cell addresses, values, and\nformats. However, this approach was limited by LLMs' token constraints, making\nit impractical for most applications. To tackle this challenge, we develop\nSheetCompressor, an innovative encoding framework that compresses spreadsheets\neffectively for LLMs. It comprises three modules: structural-anchor-based\ncompression, inverse index translation, and data-format-aware aggregation. It\nsignificantly improves performance in spreadsheet table detection task,\noutperforming the vanilla approach by 25.6% in GPT4's in-context learning\nsetting. Moreover, fine-tuned LLM with SheetCompressor has an average\ncompression ratio of 25 times, but achieves a state-of-the-art 78.9% F1 score,\nsurpassing the best existing models by 12.3%. Finally, we propose Chain of\nSpreadsheet for downstream tasks of spreadsheet understanding and validate in a\nnew and demanding spreadsheet QA task. We methodically leverage the inherent\nlayout and structure of spreadsheets, demonstrating that SpreadsheetLLM is\nhighly effective across a variety of spreadsheet tasks.", "paper_summary_zh": "<paragraph>\u8a66\u7b97\u8868\u53ca\u5176\u5ee3\u6cdb\u7684\u4e8c\u7dad\u683c\u7dda\u3001\u5404\u5f0f\u914d\u7f6e\u548c\u591a\u6a23\u683c\u5f0f\u9078\u9805\uff0c\u5c0d\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u800c\u8a00\u69cb\u6210\u986f\u8457\u7684\u6311\u6230\u3002\u70ba\u4e86\u89e3\u6c7a\u6b64\u554f\u984c\uff0c\u6211\u5011\u5f15\u9032\u4e86 SpreadsheetLLM\uff0c\u958b\u5275\u4e00\u7a2e\u9ad8\u6548\u7de8\u78bc\u65b9\u6cd5\uff0c\u65e8\u5728\u91cb\u653e\u548c\u512a\u5316 LLM \u5728\u8a66\u7b97\u8868\u4e0a\u7684\u5f37\u5927\u7406\u89e3\u548c\u63a8\u7406\u80fd\u529b\u3002\u6700\u521d\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u9999\u8349\u5e8f\u5217\u5316\u65b9\u6cd5\uff0c\u5176\u4e2d\u5305\u542b\u5132\u5b58\u683c\u5730\u5740\u3001\u503c\u548c\u683c\u5f0f\u3002\u7136\u800c\uff0c\u6b64\u65b9\u6cd5\u53d7\u5230 LLM \u4ee4\u724c\u9650\u5236\uff0c\u9019\u4f7f\u5f97\u5b83\u4e0d\u9069\u7528\u65bc\u5927\u591a\u6578\u61c9\u7528\u7a0b\u5f0f\u3002\u70ba\u4e86\u61c9\u5c0d\u6b64\u6311\u6230\uff0c\u6211\u5011\u958b\u767c\u4e86 SheetCompressor\uff0c\u9019\u662f\u4e00\u500b\u5275\u65b0\u7684\u7de8\u78bc\u67b6\u69cb\uff0c\u53ef\u6709\u6548\u58d3\u7e2e LLM \u7684\u8a66\u7b97\u8868\u3002\u5b83\u5305\u542b\u4e09\u500b\u6a21\u7d44\uff1a\u57fa\u65bc\u7d50\u69cb\u9328\u9ede\u7684\u58d3\u7e2e\u3001\u53cd\u5411\u7d22\u5f15\u8f49\u63db\u548c\u8cc7\u6599\u683c\u5f0f\u611f\u77e5\u805a\u5408\u3002\u5b83\u986f\u8457\u6539\u5584\u4e86\u8a66\u7b97\u8868\u8868\u683c\u5075\u6e2c\u4efb\u52d9\u7684\u6548\u80fd\uff0c\u5728 GPT4 \u7684\u60c5\u5883\u5b78\u7fd2\u8a2d\u5b9a\u4e2d\uff0c\u6bd4\u9999\u8349\u65b9\u6cd5\u63d0\u5347\u4e86 25.6%\u3002\u6b64\u5916\uff0c\u4f7f\u7528 SheetCompressor \u5fae\u8abf\u7684 LLM \u5e73\u5747\u58d3\u7e2e\u6bd4\u70ba 25 \u500d\uff0c\u4f46\u9054\u5230\u4e86\u6700\u5148\u9032\u7684 78.9% F1 \u5206\u6578\uff0c\u6bd4\u73fe\u6709\u6700\u4f73\u6a21\u578b\u9ad8\u51fa 12.3%\u3002\u6700\u5f8c\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u8a66\u7b97\u8868\u93c8\uff0c\u7528\u65bc\u8a66\u7b97\u8868\u7406\u89e3\u7684\u4e0b\u6e38\u4efb\u52d9\uff0c\u4e26\u5728\u4e00\u500b\u65b0\u7684\u3001\u8981\u6c42\u56b4\u82db\u7684\u8a66\u7b97\u8868\u554f\u7b54\u4efb\u52d9\u4e2d\u9a57\u8b49\u3002\u6211\u5011\u6709\u689d\u7406\u5730\u5229\u7528\u8a66\u7b97\u8868\u7684\u5167\u5728\u914d\u7f6e\u548c\u7d50\u69cb\uff0c\u8b49\u660e SpreadsheetLLM \u5728\u5404\u7a2e\u8a66\u7b97\u8868\u4efb\u52d9\u4e2d\u90fd\u975e\u5e38\u6709\u6548\u3002</paragraph>", "author": "Yuzhang Tian et.al.", "authors": "Yuzhang Tian, Jianbo Zhao, Haoyu Dong, Junyu Xiong, Shiyu Xia, Mengyu Zhou, Yun Lin, Jos\u00e9 Cambronero, Yeye He, Shi Han, Dongmei Zhang", "id": "2407.09025v1", "paper_url": "http://arxiv.org/abs/2407.09025v1", "repo": "null"}}