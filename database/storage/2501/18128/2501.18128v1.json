{"2501.18128": {"publish_time": "2025-01-30", "title": "Unraveling the Capabilities of Language Models in News Summarization", "paper_summary": "Given the recent introduction of multiple language models and the ongoing\ndemand for improved Natural Language Processing tasks, particularly\nsummarization, this work provides a comprehensive benchmarking of 20 recent\nlanguage models, focusing on smaller ones for the news summarization task. In\nthis work, we systematically test the capabilities and effectiveness of these\nmodels in summarizing news article texts which are written in different styles\nand presented in three distinct datasets. Specifically, we focus in this study\non zero-shot and few-shot learning settings and we apply a robust evaluation\nmethodology that combines different evaluation concepts including automatic\nmetrics, human evaluation, and LLM-as-a-judge. Interestingly, including\ndemonstration examples in the few-shot learning setting did not enhance models'\nperformance and, in some cases, even led to worse quality of the generated\nsummaries. This issue arises mainly due to the poor quality of the gold\nsummaries that have been used as reference summaries, which negatively impacts\nthe models' performance. Furthermore, our study's results highlight the\nexceptional performance of GPT-3.5-Turbo and GPT-4, which generally dominate\ndue to their advanced capabilities. However, among the public models evaluated,\ncertain models such as Qwen1.5-7B, SOLAR-10.7B-Instruct-v1.0, Meta-Llama-3-8B\nand Zephyr-7B-Beta demonstrated promising results. These models showed\nsignificant potential, positioning them as competitive alternatives to large\nmodels for the task of news summarization.", "paper_summary_zh": "\u9274\u4e8e\u6700\u8fd1\u63a8\u51fa\u4e86\u591a\u8bed\u8a00\u6a21\u578b\uff0c\u5e76\u4e14\u5bf9\u6539\u8fdb\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4efb\u52a1\uff08\u5c24\u5176\u662f\u6458\u8981\uff09\u7684\u9700\u6c42\u4e0d\u65ad\u589e\u957f\uff0c\u8fd9\u9879\u5de5\u4f5c\u5bf9 20 \u4e2a\u6700\u8fd1\u7684\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u4e86\u5168\u9762\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u91cd\u70b9\u5173\u6ce8\u9488\u5bf9\u65b0\u95fb\u6458\u8981\u4efb\u52a1\u7684\u8f83\u5c0f\u6a21\u578b\u3002\u5728\u8fd9\u9879\u5de5\u4f5c\u4e2d\uff0c\u6211\u4eec\u7cfb\u7edf\u5730\u6d4b\u8bd5\u4e86\u8fd9\u4e9b\u6a21\u578b\u5728\u603b\u7ed3\u4ee5\u4e0d\u540c\u98ce\u683c\u64b0\u5199\u5e76\u5448\u73b0\u5728\u4e09\u4e2a\u4e0d\u540c\u6570\u636e\u96c6\u4e2d\u7684\u65b0\u95fb\u6587\u7ae0\u6587\u672c\u65b9\u9762\u7684\u80fd\u529b\u548c\u6709\u6548\u6027\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u6211\u4eec\u5728\u8fd9\u9879\u7814\u7a76\u4e2d\u4e13\u6ce8\u4e8e\u96f6\u6837\u672c\u548c\u5c11\u6837\u672c\u5b66\u4e60\u8bbe\u7f6e\uff0c\u5e76\u4e14\u6211\u4eec\u5e94\u7528\u4e86\u4e00\u79cd\u7a33\u5065\u7684\u8bc4\u4f30\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u7ed3\u5408\u4e86\u4e0d\u540c\u7684\u8bc4\u4f30\u6982\u5ff5\uff0c\u5305\u62ec\u81ea\u52a8\u6307\u6807\u3001\u4eba\u5de5\u8bc4\u4f30\u548c LLM \u4f5c\u4e3a\u8bc4\u59d4\u3002\u6709\u8da3\u7684\u662f\uff0c\u5728\u5c11\u6837\u672c\u5b66\u4e60\u8bbe\u7f6e\u4e2d\u5305\u542b\u6f14\u793a\u793a\u4f8b\u5e76\u6ca1\u6709\u63d0\u9ad8\u6a21\u578b\u7684\u6027\u80fd\uff0c\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u751a\u81f3\u5bfc\u81f4\u751f\u6210\u6458\u8981\u7684\u8d28\u91cf\u4e0b\u964d\u3002\u8fd9\u4e2a\u95ee\u9898\u4e3b\u8981\u662f\u56e0\u4e3a\u7528\u4f5c\u53c2\u8003\u6458\u8981\u7684\u9ec4\u91d1\u6458\u8981\u8d28\u91cf\u8f83\u5dee\uff0c\u8fd9\u4f1a\u5bf9\u6a21\u578b\u7684\u6027\u80fd\u4ea7\u751f\u8d1f\u9762\u5f71\u54cd\u3002\u6b64\u5916\uff0c\u6211\u4eec\u7814\u7a76\u7684\u7ed3\u679c\u7a81\u51fa\u4e86 GPT-3.5-Turbo \u548c GPT-4 \u7684\u5353\u8d8a\u6027\u80fd\uff0c\u5b83\u4eec\u901a\u5e38\u7531\u4e8e\u5176\u9ad8\u7ea7\u529f\u80fd\u800c\u5360\u636e\u4e3b\u5bfc\u5730\u4f4d\u3002\u7136\u800c\uff0c\u5728\u8bc4\u4f30\u7684\u516c\u5171\u6a21\u578b\u4e2d\uff0c\u67d0\u4e9b\u6a21\u578b\uff08\u4f8b\u5982 Qwen1.5-7B\u3001SOLAR-10.7B-Instruct-v1.0\u3001Meta-Llama-3-8B \u548c Zephyr-7B-Beta\uff09\u5c55\u793a\u4e86\u6709\u5e0c\u671b\u7684\u7ed3\u679c\u3002\u8fd9\u4e9b\u6a21\u578b\u663e\u793a\u51fa\u5de8\u5927\u7684\u6f5c\u529b\uff0c\u5c06\u5b83\u4eec\u5b9a\u4f4d\u4e3a\u65b0\u95fb\u6458\u8981\u4efb\u52a1\u4e2d\u5927\u578b\u6a21\u578b\u7684\u6709\u7ade\u4e89\u529b\u7684\u66ff\u4ee3\u54c1\u3002", "author": "Abdurrahman Odaba\u015f\u0131 et.al.", "authors": "Abdurrahman Odaba\u015f\u0131, G\u00f6ksel Biricik", "id": "2501.18128v1", "paper_url": "http://arxiv.org/abs/2501.18128v1", "repo": "null"}}