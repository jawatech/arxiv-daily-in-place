
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-12-03**|**Scaling BERT Models for Turkish Automatic Punctuation and Capitalization Correction**|Abdulkader Saoud et.al.|[2412.02698v1](http://arxiv.org/abs/2412.02698v1)|null|
|**2024-12-03**|**Taming Scalable Visual Tokenizer for Autoregressive Image Generation**|Fengyuan Shi et.al.|[2412.02692v1](http://arxiv.org/abs/2412.02692v1)|null|
|**2024-12-03**|**T-REG: Preference Optimization with Token-Level Reward Regularization**|Wenxuan Zhou et.al.|[2412.02685v1](http://arxiv.org/abs/2412.02685v1)|null|
|**2024-12-03**|**AniGS: Animatable Gaussian Avatar from a Single Image with Inconsistent Gaussian Reconstruction**|Lingteng Qiu et.al.|[2412.02684v1](http://arxiv.org/abs/2412.02684v1)|null|
|**2024-12-03**|**The Asymptotic Behavior of Attention in Transformers**|Álvaro Rodríguez Abella et.al.|[2412.02682v1](http://arxiv.org/abs/2412.02682v1)|null|
|**2024-12-03**|**Mind the Gap: Examining the Self-Improvement Capabilities of Large Language Models**|Yuda Song et.al.|[2412.02674v1](http://arxiv.org/abs/2412.02674v1)|null|
|**2024-12-03**|**Probing the statistical properties of enriched co-occurrence networks**|Diego R. Amancio et.al.|[2412.02664v1](http://arxiv.org/abs/2412.02664v1)|null|
|**2024-12-03**|**Adaptive Informed Deep Neural Networks for Power Flow Analysis**|Zeynab Kaseb et.al.|[2412.02659v1](http://arxiv.org/abs/2412.02659v1)|null|
|**2024-12-03**|**QA-TOOLBOX: Conversational Question-Answering for process task guidance in manufacturing**|Ramesh Manuvinakurike et.al.|[2412.02638v1](http://arxiv.org/abs/2412.02638v1)|null|
|**2024-12-03**|**Words and Action: Modeling Linguistic Leadership in #BlackLivesMatter Communities**|Dani Roytburg et.al.|[2412.02637v1](http://arxiv.org/abs/2412.02637v1)|null|
|**2024-12-03**|**Scaling Image Tokenizers with Grouped Spherical Quantization**|Jiangtao Wang et.al.|[2412.02632v1](http://arxiv.org/abs/2412.02632v1)|[link](https://github.com/helmholtzai-fzj/flex_gen)|
|**2024-12-03**|**Time-Reversal Provides Unsupervised Feedback to LLMs**|Yerram Varun et.al.|[2412.02626v1](http://arxiv.org/abs/2412.02626v1)|null|
|**2024-12-03**|**Medical Multimodal Foundation Models in Clinical Diagnosis and Treatment: Applications, Challenges, and Future Directions**|Kai Sun et.al.|[2412.02621v1](http://arxiv.org/abs/2412.02621v1)|null|
|**2024-12-03**|**Improving Dynamic Object Interactions in Text-to-Video Generation with AI Feedback**|Hiroki Furuta et.al.|[2412.02617v1](http://arxiv.org/abs/2412.02617v1)|null|
|**2024-12-03**|**GLM-4-Voice: Towards Intelligent and Human-Like End-to-End Spoken Chatbot**|Aohan Zeng et.al.|[2412.02612v1](http://arxiv.org/abs/2412.02612v1)|[link](https://github.com/thudm/glm-4-voice)|
|**2024-12-03**|**AV-Odyssey Bench: Can Your Multimodal LLMs Really Understand Audio-Visual Information?**|Kaixiong Gong et.al.|[2412.02611v1](http://arxiv.org/abs/2412.02611v1)|null|
|**2024-12-03**|**AI-Driven Resource Allocation Framework for Microservices in Hybrid Cloud Platforms**|Biman Barua et.al.|[2412.02610v1](http://arxiv.org/abs/2412.02610v1)|null|
|**2024-12-03**|**Interpretable Company Similarity with Sparse Autoencoders**|Marco Molinari et.al.|[2412.02605v1](http://arxiv.org/abs/2412.02605v1)|null|
|**2024-12-03**|**CEGI: Measuring the trade-off between efficiency and carbon emissions for SLMs and VLMs**|Abhas Kumar et.al.|[2412.02602v1](http://arxiv.org/abs/2412.02602v1)|null|
|**2024-12-03**|**Nemotron-CC: Transforming Common Crawl into a Refined Long-Horizon Pretraining Dataset**|Dan Su et.al.|[2412.02595v1](http://arxiv.org/abs/2412.02595v1)|null|
|**2024-12-03**|**PrefixLLM: LLM-aided Prefix Circuit Design**|Weihua Xiao et.al.|[2412.02594v1](http://arxiv.org/abs/2412.02594v1)|null|
|**2024-12-03**|**Explainable CTR Prediction via LLM Reasoning**|Xiaohan Yu et.al.|[2412.02588v1](http://arxiv.org/abs/2412.02588v1)|null|
|**2024-12-03**|**Factored space models: Towards causality between levels of abstraction**|Scott Garrabrant et.al.|[2412.02579v1](http://arxiv.org/abs/2412.02579v1)|null|
|**2024-12-03**|**Segmentation of Coronary Artery Stenosis in X-ray Angiography using Mamba Models**|Ali Rostami et.al.|[2412.02568v1](http://arxiv.org/abs/2412.02568v1)|null|
|**2024-12-03**|**Semantic Tokens in Retrieval Augmented Generation**|Joel Suro et.al.|[2412.02563v1](http://arxiv.org/abs/2412.02563v1)|null|
|**2024-12-03**|**Patent-CR: A Dataset for Patent Claim Revision**|Lekang Jiang et.al.|[2412.02549v1](http://arxiv.org/abs/2412.02549v1)|null|
|**2024-12-03**|**Graph-Powered Defense: Controller Area Network Intrusion Detection for Unmanned Aerial Vehicles**|Reek Majumder et.al.|[2412.02539v1](http://arxiv.org/abs/2412.02539v1)|null|
|**2024-12-03**|**WEM-GAN: Wavelet transform based facial expression manipulation**|Dongya Sun et.al.|[2412.02530v1](http://arxiv.org/abs/2412.02530v1)|null|
|**2024-12-03**|**Bias Analysis of AI Models for Undergraduate Student Admissions**|Kelly Van Busum et.al.|[2412.02528v1](http://arxiv.org/abs/2412.02528v1)|null|
|**2024-12-03**|**LLMForecaster: Improving Seasonal Event Forecasts with Unstructured Textual Data**|Hanyu Zhang et.al.|[2412.02525v1](http://arxiv.org/abs/2412.02525v1)|null|
|**2024-12-03**|**FCL-ViT: Task-Aware Attention Tuning for Continual Learning**|Anestis Kaimakamidis et.al.|[2412.02509v1](http://arxiv.org/abs/2412.02509v1)|null|
|**2024-12-03**|**Towards Rich Emotions in 3D Avatars: A Text-to-3D Avatar Generation Benchmark**|Haidong Xu et.al.|[2412.02508v1](http://arxiv.org/abs/2412.02508v1)|[link](https://github.com/walkermitty/emoava)|
|**2024-12-03**|**OODFace: Benchmarking Robustness of Face Recognition under Common Corruptions and Appearance Variations**|Caixin Kang et.al.|[2412.02479v1](http://arxiv.org/abs/2412.02479v1)|null|
|**2024-12-03**|**DP-2Stage: Adapting Language Models as Differentially Private Tabular Data Generators**|Tejumade Afonja et.al.|[2412.02467v1](http://arxiv.org/abs/2412.02467v1)|null|
|**2024-12-03**|**Gracefully Filtering Backdoor Samples for Generative Large Language Models without Retraining**|Zongru Wu et.al.|[2412.02454v1](http://arxiv.org/abs/2412.02454v1)|[link](https://github.com/zrw00/graceful)|
|**2024-12-03**|**BYE: Build Your Encoder with One Sequence of Exploration Data for Long-Term Dynamic Scene Understanding**|Chenguang Huang et.al.|[2412.02449v1](http://arxiv.org/abs/2412.02449v1)|null|
|**2024-12-03**|**GerPS-Compare: Comparing NER methods for legal norm analysis**|Sarah T. Bachinger et.al.|[2412.02427v1](http://arxiv.org/abs/2412.02427v1)|null|
|**2024-12-03**|**Knowledge-Enhanced Conversational Recommendation via Transformer-based Sequential Modelling**|Jie Zou et.al.|[2412.02415v1](http://arxiv.org/abs/2412.02415v1)|null|
|**2024-12-03**|**VISTA: A Panoramic View of Neural Representations**|Tom White et.al.|[2412.02412v1](http://arxiv.org/abs/2412.02412v1)|null|
|**2024-12-03**|**A Multi-Agent Framework for Extensible Structured Text Generation in PLCs**|Donghao Yang et.al.|[2412.02410v1](http://arxiv.org/abs/2412.02410v1)|null|
|**2024-12-03**|**Four Guiding Principles for Modeling Causal Domain Knowledge: A Case Study on Brainstorming Approaches for Urban Blight Analysis**|Houssam Razouk et.al.|[2412.02400v1](http://arxiv.org/abs/2412.02400v1)|null|
|**2024-12-03**|**OMENN: One Matrix to Explain Neural Networks**|Adam Wróbel et.al.|[2412.02399v1](http://arxiv.org/abs/2412.02399v1)|null|
|**2024-12-03**|**HERO: Hint-Based Efficient and Reliable Query Optimizer**|Sergey Zinchenko et.al.|[2412.02372v1](http://arxiv.org/abs/2412.02372v1)|[link](https://github.com/zinchse/hero)|
|**2024-12-03**|**TSCheater: Generating High-Quality Tibetan Adversarial Texts via Visual Similarity**|Xi Cao et.al.|[2412.02371v1](http://arxiv.org/abs/2412.02371v1)|null|
|**2024-12-03**|**ScImage: How Good Are Multimodal Large Language Models at Scientific Text-to-Image Generation?**|Leixin Zhang et.al.|[2412.02368v1](http://arxiv.org/abs/2412.02368v1)|null|
|**2024-12-03**|**Multi-Granularity Tibetan Textual Adversarial Attack Method Based on Masked Language Model**|Xi Cao et.al.|[2412.02343v1](http://arxiv.org/abs/2412.02343v1)|null|
|**2024-12-03**|**Reinforcement learning to learn quantum states for Heisenberg scaling accuracy**|Jeongwoo Jae et.al.|[2412.02334v1](http://arxiv.org/abs/2412.02334v1)|null|
|**2024-12-03**|**Sample Efficient Robot Learning in Supervised Effect Prediction Tasks**|Mehmet Arda Eren et.al.|[2412.02331v1](http://arxiv.org/abs/2412.02331v1)|null|
|**2024-12-03**|**Pay Attention to the Robustness of Chinese Minority Language Models! Syllable-level Textual Adversarial Attack on Tibetan Script**|Xi Cao et.al.|[2412.02323v1](http://arxiv.org/abs/2412.02323v1)|null|
|**2024-12-03**|**Enhanced Photovoltaic Power Forecasting: An iTransformer and LSTM-Based Model Integrating Temporal and Covariate Interactions**|Guang Wu et.al.|[2412.02302v1](http://arxiv.org/abs/2412.02302v1)|null|
|**2024-12-03**|**Large Multimodal Agents for Accurate Phishing Detection with Enhanced Token Optimization and Cost Reduction**|Fouad Trad et.al.|[2412.02301v1](http://arxiv.org/abs/2412.02301v1)|null|
|**2024-12-03**|**Deep Matrix Factorization with Adaptive Weights for Multi-View Clustering**|Yasser Khalafaoui et.al.|[2412.02292v1](http://arxiv.org/abs/2412.02292v1)|null|
|**2024-12-03**|**Conformal Symplectic Optimization for Stable Reinforcement Learning**|Yao Lyu et.al.|[2412.02291v1](http://arxiv.org/abs/2412.02291v1)|null|
|**2024-12-03**|**Characterizing Information Shared by Participants to Coding Challenges: The Case of Advent of Code**|Francesco Cauteruccio et.al.|[2412.02290v1](http://arxiv.org/abs/2412.02290v1)|null|
|**2024-12-03**|**GQWformer: A Quantum-based Transformer for Graph Representation Learning**|Lei Yu et.al.|[2412.02285v1](http://arxiv.org/abs/2412.02285v1)|null|
|**2024-12-03**|**AH-OCDA: Amplitude-based Curriculum Learning and Hopfield Segmentation Model for Open Compound Domain Adaptation**|Jaehyun Choi et.al.|[2412.02280v1](http://arxiv.org/abs/2412.02280v1)|null|
|**2024-12-03**|**A Comprehensive Evaluation of Large Language Models on Aspect-Based Sentiment Analysis**|Changzhi Zhou et.al.|[2412.02279v1](http://arxiv.org/abs/2412.02279v1)|null|
|**2024-12-03**|**MediaSpin: Exploring Media Bias Through Fine-Grained Analysis of News Headlines**|Preetika Verma et.al.|[2412.02271v1](http://arxiv.org/abs/2412.02271v1)|null|
|**2024-12-03**|**Sustainable Self-evolution Adversarial Training**|Wenxuan Wang et.al.|[2412.02270v1](http://arxiv.org/abs/2412.02270v1)|null|
|**2024-12-03**|**Connecting Large Language Models with Blockchain: Advancing the Evolution of Smart Contracts from Automation to Intelligence**|Youquan Xian et.al.|[2412.02263v1](http://arxiv.org/abs/2412.02263v1)|null|
|**2024-12-03**|**VideoGen-of-Thought: A Collaborative Framework for Multi-Shot Video Generation**|Mingzhe Zheng et.al.|[2412.02259v1](http://arxiv.org/abs/2412.02259v1)|null|
|**2024-12-03**|**Compressing KV Cache for Long-Context LLM Inference with Inter-Layer Attention Similarity**|Da Ma et.al.|[2412.02252v1](http://arxiv.org/abs/2412.02252v1)|null|
|**2024-12-03**|**Selective Reviews of Bandit Problems in AI via a Statistical View**|Pengjie Zhou et.al.|[2412.02251v1](http://arxiv.org/abs/2412.02251v1)|null|
|**2024-12-03**|**U-Net in Medical Image Segmentation: A Review of Its Applications Across Modalities**|Fnu Neha et.al.|[2412.02242v1](http://arxiv.org/abs/2412.02242v1)|null|
|**2024-12-03**|**Cross-Attention Head Position Patterns Can Align with Human Visual Concepts in Text-to-Image Generative Models**|Jungwon Park et.al.|[2412.02237v1](http://arxiv.org/abs/2412.02237v1)|null|
|**2024-12-03**|**BANER: Boundary-Aware LLMs for Few-Shot Named Entity Recognition**|Quanjiang Guo et.al.|[2412.02228v1](http://arxiv.org/abs/2412.02228v1)|[link](https://github.com/uestc-gqj/baner)|
|**2024-12-03**|**Deep learning approach for predicting the replicator equation in evolutionary game theory**|Advait Chandorkar et.al.|[2412.02222v1](http://arxiv.org/abs/2412.02222v1)|null|
|**2024-12-03**|**Unlocking Tuning-Free Few-Shot Adaptability in Visual Foundation Models by Recycling Pre-Tuned LoRAs**|Zixuan Hu et.al.|[2412.02220v1](http://arxiv.org/abs/2412.02220v1)|null|
|**2024-12-03**|**Recovering implicit physics model under real-world constraints**|Ayan Banerjee et.al.|[2412.02215v1](http://arxiv.org/abs/2412.02215v1)|null|
|**2024-12-03**|**DataLab: A Unifed Platform for LLM-Powered Business Intelligence**|Luoxuan Weng et.al.|[2412.02205v1](http://arxiv.org/abs/2412.02205v1)|null|
|**2024-12-03**|**LayoutVLM: Differentiable Optimization of 3D Layout via Vision-Language Models**|Fan-Yun Sun et.al.|[2412.02193v1](http://arxiv.org/abs/2412.02193v1)|null|
|**2024-12-03**|**Comparative Performance of Machine Learning Algorithms for Early Genetic Disorder and Subclass Classification**|Abu Bakar Siddik et.al.|[2412.02189v1](http://arxiv.org/abs/2412.02189v1)|null|
|**2024-12-03**|**VideoICL: Confidence-based Iterative In-context Learning for Out-of-Distribution Video Understanding**|Kangsan Kim et.al.|[2412.02186v1](http://arxiv.org/abs/2412.02186v1)|[link](https://github.com/kangsankim07/videoicl)|
|**2024-12-03**|**Generalizing Weisfeiler-Lehman Kernels to Subgraphs**|Dongkwan Kim et.al.|[2412.02181v1](http://arxiv.org/abs/2412.02181v1)|[link](https://github.com/dongkwan-kim/wlks)|
|**2024-12-03**|**Anatomically-Grounded Fact Checking of Automated Chest X-ray Reports**|R. Mahmood et.al.|[2412.02177v1](http://arxiv.org/abs/2412.02177v1)|null|
|**2024-12-03**|**Keeping Experts in the Loop: Expert-Guided Optimization for Clinical Data Classification using Large Language Models**|Nader Karayanni et.al.|[2412.02173v1](http://arxiv.org/abs/2412.02173v1)|null|
|**2024-12-03**|**VISCO: Benchmarking Fine-Grained Critique and Correction Towards Self-Improvement in Visual Reasoning**|Xueqing Wu et.al.|[2412.02172v1](http://arxiv.org/abs/2412.02172v1)|null|
|**2024-12-03**|**A Theoretical Framework for Acoustic Neighbor Embeddings**|Woojay Jeon et.al.|[2412.02164v1](http://arxiv.org/abs/2412.02164v1)|null|
|**2024-12-03**|**Jailbreak Defense in a Narrow Domain: Limitations of Existing Methods and a New Transcript-Classifier Approach**|Tony T. Wang et.al.|[2412.02159v1](http://arxiv.org/abs/2412.02159v1)|null|
|**2024-12-03**|**CausalMob: Causal Human Mobility Prediction with LLMs-derived Human Intentions toward Public Events**|Xiaojie Yang et.al.|[2412.02155v1](http://arxiv.org/abs/2412.02155v1)|null|
|**2024-12-03**|**Revisiting the Initial Steps in Adaptive Gradient Descent Optimization**|Abulikemu Abuduweili et.al.|[2412.02153v1](http://arxiv.org/abs/2412.02153v1)|null|
|**2024-12-03**|**Leveraging Large Language Models for Comparative Literature Summarization with Reflective Incremental Mechanisms**|Fernando Gabriela Garcia et.al.|[2412.02149v1](http://arxiv.org/abs/2412.02149v1)|null|
|**2024-12-03**|**Personalized Multimodal Large Language Models: A Survey**|Junda Wu et.al.|[2412.02142v1](http://arxiv.org/abs/2412.02142v1)|null|
|**2024-12-03**|**WSI-LLaVA: A Multimodal Large Language Model for Whole Slide Image**|Yuci Liang et.al.|[2412.02141v1](http://arxiv.org/abs/2412.02141v1)|null|
|**2024-12-03**|**Misalignment of Semantic Relation Knowledge between WordNet and Human Intuition**|Zhihan Cao et.al.|[2412.02138v1](http://arxiv.org/abs/2412.02138v1)|null|
|**2024-12-03**|**Benchmarking symbolic regression constant optimization schemes**|L. G. A dos Reis et.al.|[2412.02126v1](http://arxiv.org/abs/2412.02126v1)|null|
|**2024-12-03**|**OmniCreator: Self-Supervised Unified Generation with Universal Editing**|Haodong Chen et.al.|[2412.02114v1](http://arxiv.org/abs/2412.02114v1)|null|
|**2024-12-03**|**Trust & Safety of LLMs and LLMs in Trust & Safety**|Doohee You et.al.|[2412.02113v1](http://arxiv.org/abs/2412.02113v1)|null|
|**2024-12-03**|**Explainable and Interpretable Multimodal Large Language Models: A Comprehensive Survey**|Yunkai Dang et.al.|[2412.02104v1](http://arxiv.org/abs/2412.02104v1)|null|
|**2024-12-03**|**Improving Language Transfer Capability of Decoder-only Architecture in Multilingual Neural Machine Translation**|Zhi Qu et.al.|[2412.02101v1](http://arxiv.org/abs/2412.02101v1)|null|
|**2024-12-03**|**AccDiffusion v2: Towards More Accurate Higher-Resolution Diffusion Extrapolation**|Zhihang Lin et.al.|[2412.02099v1](http://arxiv.org/abs/2412.02099v1)|[link](https://github.com/lzhxmu/accdiffusion_v2)|
|**2024-12-03**|**Evolution of Collective AI Beyond Individual Optimization**|Ryosuke Takata et.al.|[2412.02085v1](http://arxiv.org/abs/2412.02085v1)|null|
|**2024-12-03**|**Comparative Analysis of Black-Box and White-Box Machine Learning Model in Phishing Detection**|Abdullah Fajar et.al.|[2412.02084v1](http://arxiv.org/abs/2412.02084v1)|null|
|**2024-12-03**|**Implementing An Artificial Quantum Perceptron**|Ashutosh Hathidara et.al.|[2412.02083v1](http://arxiv.org/abs/2412.02083v1)|null|
|**2024-12-03**|**Let's Think Var-by-Var: Large Language Models Enable Ad Hoc Probabilistic Reasoning**|Shepard Xia et.al.|[2412.02081v1](http://arxiv.org/abs/2412.02081v1)|null|
|**2024-12-03**|**Construction and optimization of health behavior prediction model for the elderly in smart elderly care**|Qian Guo et.al.|[2412.02062v1](http://arxiv.org/abs/2412.02062v1)|null|
|**2024-12-03**|**BN-AuthProf: Benchmarking Machine Learning for Bangla Author Profiling on Social Media Texts**|Raisa Tasnim et.al.|[2412.02058v1](http://arxiv.org/abs/2412.02058v1)|[link](https://github.com/crusnic-corp/BN-AuthProf)|
|**2024-12-03**|**A Multi-way Parallel Named Entity Annotated Corpus for English, Tamil and Sinhala**|Surangika Ranathunga et.al.|[2412.02056v1](http://arxiv.org/abs/2412.02056v1)|null|
|**2024-12-03**|**Impact of Data Snooping on Deep Learning Models for Locating Vulnerabilities in Lifted Code**|Gary A. McCully et.al.|[2412.02048v1](http://arxiv.org/abs/2412.02048v1)|null|
|**2024-12-03**|**Future of Information Retrieval Research in the Age of Generative AI**|James Allan et.al.|[2412.02043v1](http://arxiv.org/abs/2412.02043v1)|null|

#### Abstracts
##### **Scaling BERT Models for Turkish Automatic Punctuation and Capitalization Correction**
2412.02698v1 by Abdulkader Saoud, Mahmut Alomeyr, Himmet Toprak Kesgin, Mehmet Fatih Amasyali

This paper investigates the effectiveness of BERT based models for automated
punctuation and capitalization corrections in Turkish texts across five
distinct model sizes. The models are designated as Tiny, Mini, Small, Medium,
and Base. The design and capabilities of each model are tailored to address the
specific challenges of the Turkish language, with a focus on optimizing
performance while minimizing computational overhead. The study presents a
systematic comparison of the performance metrics precision, recall, and F1
score of each model, offering insights into their applicability in diverse
operational contexts. The results demonstrate a significant improvement in text
readability and accuracy as model size increases, with the Base model achieving
the highest correction precision. This research provides a comprehensive guide
for selecting the appropriate model size based on specific user needs and
computational resources, establishing a framework for deploying these models in
real-world applications to enhance the quality of written Turkish.

摘要：本論文探討了基於 BERT 的模型在五種不同模型規模的土耳其語文本中自動標點符號和大小寫更正的有效性。這些模型分別被指定為 Tiny、Mini、Small、Medium 和 Base。每個模型的設計和功能都針對土耳其語的特定挑戰量身打造，重點在於優化效能並最大程度地減少運算負擔。本研究對每個模型的效能指標（準確度、召回率和 F1 分數）進行了系統性的比較，深入了解它們在不同操作環境中的適用性。結果表明，隨著模型規模的增大，文本的可讀性和準確性顯著提高，其中 Base 模型實現了最高的更正準確度。本研究為根據特定使用者需求和運算資源選擇適當的模型規模提供了全面的指南，建立了一個在實際應用中部署這些模型以提高土耳其語書面品質的框架。

##### **Taming Scalable Visual Tokenizer for Autoregressive Image Generation**
2412.02692v1 by Fengyuan Shi, Zhuoyan Luo, Yixiao Ge, Yujiu Yang, Ying Shan, Limin Wang

Existing vector quantization (VQ) methods struggle with scalability, largely
attributed to the instability of the codebook that undergoes partial updates
during training. The codebook is prone to collapse as utilization decreases,
due to the progressively widening distribution gap between non-activated codes
and visual features. To solve the problem, we propose Index Backpropagation
Quantization (IBQ), a new VQ method for the joint optimization of all codebook
embeddings and the visual encoder. Applying a straight-through estimator on the
one-hot categorical distribution between the encoded feature and codebook, all
codes are differentiable and maintain a consistent latent space with the visual
encoder. IBQ enables scalable training of visual tokenizers and, for the first
time, achieves a large-scale codebook ($2^{18}$) with high dimension ($256$)
and high utilization. Experiments on the standard ImageNet benchmark
demonstrate the scalability and superiority of IBQ, achieving competitive
results on both reconstruction ($1.00$ rFID) and autoregressive visual
generation ($2.05$ gFID). The code and models are available at
https://github.com/TencentARC/SEED-Voken.

摘要：現有的向量量化 (VQ) 方法難以擴充，這在很大程度上歸因於在訓練期間進行部分更新的碼本的不穩定性。由於未激活碼和視覺特徵之間的分布差距逐漸擴大，因此碼本容易隨著利用率的降低而崩潰。為了解決這個問題，我們提出了索引反向傳播量化 (IBQ)，這是一種新的 VQ 方法，用於所有碼本嵌入和視覺編碼器的聯合最佳化。在編碼特徵和碼本之間的一熱類別分佈上應用直通估計器，所有碼都是可微分的，並與視覺編碼器保持一致的潛在空間。IBQ 能夠擴充視覺標記化的訓練，並且首次實現了具有高維度 ($256$) 和高利用率的大規模碼本 ($2^{18}$)。在標準 ImageNet 基準上的實驗證明了 IBQ 的可擴充性和優越性，在重建 ($1.00$ rFID) 和自迴歸視覺生成 ($2.05$ gFID) 上都取得了有競爭力的結果。代碼和模型可在 https://github.com/TencentARC/SEED-Voken 獲得。

##### **T-REG: Preference Optimization with Token-Level Reward Regularization**
2412.02685v1 by Wenxuan Zhou, Shujian Zhang, Lingxiao Zhao, Tao Meng

Reinforcement learning from human feedback (RLHF) has been crucial in
aligning large language models (LLMs) with human values. Traditionally, RLHF
involves generating responses to a query and using a reward model to assign a
reward to the entire response. However, this approach faces challenges due to
its reliance on a single, sparse reward, which makes it challenging for the
model to identify which parts of the sequence contribute most significantly to
the final reward. Recent methods have attempted to address this limitation by
introducing token-level rewards. However, these methods often rely on either a
trained credit assignment model or AI annotators, raising concerns about the
quality and reliability of the rewards. In this paper, we propose token-level
reward regularization (T-REG), a novel approach that leverages both
sequence-level and token-level rewards for preference optimization. Harnessing
the self-refinement capabilities of LLMs, our method uses contrastive prompting
to enable LLMs to self-generate token-level rewards. These self-generated
rewards then act as reward regularization, guiding the model to more
effectively distribute sequence-level rewards across tokens. This facilitates
better token-level credit assignment and enhances alignment performance.
Experiments on the instruction following benchmarks, including Alpaca Eval 2
and Arena-Hard, show that our method consistently outperforms baseline methods
by up to 3.8% and 4.4%, respectively. We will release the code and models at
https://github.com/wzhouad/T-REG.

摘要：人類回饋強化學習 (RLHF) 在將大型語言模型 (LLM) 與人類價值觀保持一致方面至關重要。傳統上，RLHF 涉及對查詢產生回應，並使用獎勵模型對整個回應分配獎勵。然而，這種方法由於依賴於單一的、稀疏的獎勵而面臨挑戰，這使得模型難以識別序列的哪些部分對最終獎勵的貢獻最大。最近的方法已嘗試通過引入令牌級別獎勵來解決此限制。然而，這些方法通常依賴於訓練有素的信用分配模型或 AI 注解器，從而引發了對獎勵的質量和可靠性的擔憂。在本文中，我們提出了令牌級別獎勵正則化 (T-REG)，這是一種新穎的方法，它利用序列級別和令牌級別獎勵進行偏好優化。利用 LLM 的自我優化能力，我們的模型使用對比提示來使 LLM 能夠自我產生令牌級別獎勵。這些自我產生的獎勵隨後充當獎勵正則化，指導模型更有效地將序列級別獎勵分配到令牌中。這促進了更好的令牌級別信用分配，並增強了對齊性能。在指令遵循基準測試（包括 Alpaca Eval 2 和 Arena-Hard）上的實驗表明，我們的模型始終優於基準模型，分別高達 3.8% 和 4.4%。我們將在 https://github.com/wzhouad/T-REG 上發布程式碼和模型。

##### **AniGS: Animatable Gaussian Avatar from a Single Image with Inconsistent Gaussian Reconstruction**
2412.02684v1 by Lingteng Qiu, Shenhao Zhu, Qi Zuo, Xiaodong Gu, Yuan Dong, Junfei Zhang, Chao Xu, Zhe Li, Weihao Yuan, Liefeng Bo, Guanying Chen, Zilong Dong

Generating animatable human avatars from a single image is essential for
various digital human modeling applications. Existing 3D reconstruction methods
often struggle to capture fine details in animatable models, while generative
approaches for controllable animation, though avoiding explicit 3D modeling,
suffer from viewpoint inconsistencies in extreme poses and computational
inefficiencies. In this paper, we address these challenges by leveraging the
power of generative models to produce detailed multi-view canonical pose
images, which help resolve ambiguities in animatable human reconstruction. We
then propose a robust method for 3D reconstruction of inconsistent images,
enabling real-time rendering during inference. Specifically, we adapt a
transformer-based video generation model to generate multi-view canonical pose
images and normal maps, pretraining on a large-scale video dataset to improve
generalization. To handle view inconsistencies, we recast the reconstruction
problem as a 4D task and introduce an efficient 3D modeling approach using 4D
Gaussian Splatting. Experiments demonstrate that our method achieves
photorealistic, real-time animation of 3D human avatars from in-the-wild
images, showcasing its effectiveness and generalization capability.

摘要：從單一影像產生可動態化的真人化身對於各種數位人類建模應用來說至關重要。現有的 3D 重建方法在動態化模型中捕捉精細細節時往往會遇到困難，而用於可控動態化的生成方法儘管避免了明確的 3D 建模，但在極端姿勢和計算效率方面存在視點不一致的問題。在本文中，我們透過利用生成模型的力量來產生詳細的多視圖標準姿勢影像，解決動態化人類重建中的模糊性，來解決這些挑戰。接著，我們提出一個用於不一致影像的 3D 重建穩健方法，讓推論期間能夠即時渲染。具體來說，我們調整一個基於轉換器的影片生成模型，以產生多視圖標準姿勢影像和法線貼圖，並在一個大規模的影片資料集上進行預訓練以改善泛化能力。為了處理視點不一致的問題，我們將重建問題重新定義為一個 4D 任務，並使用 4D 高斯噴灑法引入一個高效的 3D 建模方法。實驗證明，我們的這個方法可以從自然影像中實現 3D 真人化身的照片寫實即時動畫，展示了它的有效性和泛化能力。

##### **The Asymptotic Behavior of Attention in Transformers**
2412.02682v1 by Álvaro Rodríguez Abella, João Pedro Silvestre, Paulo Tabuada

A key component of transformers is the attention mechanism orchestrating how
each token influences the propagation of every other token through a
transformer. In this paper we provide a rigorous, mathematical analysis of the
asymptotic properties of attention in transformers. Although we present several
results based on different assumptions, all of them point to the same
conclusion, all tokens asymptotically converge to each other, a phenomenon that
has been empirically reported in the literature. Our findings are carefully
compared with existing theoretical results and illustrated by simulations and
experimental studies using the GPT-2 model.

摘要：Transformer的關鍵組成部分是注意力機制，它協調每個符號如何通過Transformer影響每個其他符號的傳播。在本文中，我們提供了對Transformer中注意力的漸近性質的嚴謹數學分析。雖然我們基於不同的假設提出了幾個結果，但它們都指向同一個結論，所有符號都漸近地收斂到彼此，這是一個在文獻中已經通過經驗報導的現象。我們的發現與現有的理論結果進行了仔細比較，並通過使用 GPT-2 模型的模擬和實驗研究進行了說明。

##### **Mind the Gap: Examining the Self-Improvement Capabilities of Large Language Models**
2412.02674v1 by Yuda Song, Hanlin Zhang, Carson Eisenach, Sham Kakade, Dean Foster, Udaya Ghai

Self-improvement is a mechanism in Large Language Model (LLM) pre-training,
post-training and test-time inference. We explore a framework where the model
verifies its own outputs, filters or reweights data based on this verification,
and distills the filtered data. Despite several empirical successes, a
fundamental understanding is still lacking. In this work, we initiate a
comprehensive, modular and controlled study on LLM self-improvement. We provide
a mathematical formulation for self-improvement, which is largely governed by a
quantity which we formalize as the generation-verification gap. Through
experiments with various model families and tasks, we discover a scaling
phenomenon of self-improvement -- a variant of the generation-verification gap
scales monotonically with the model pre-training flops. We also examine when
self-improvement is possible, an iterative self-improvement procedure, and ways
to improve its performance. Our findings not only advance understanding of LLM
self-improvement with practical implications, but also open numerous avenues
for future research into its capabilities and boundaries.

摘要：自我提升是大语言模型 (LLM) 预训练、后训练和测试时间推理中的机制。我们探索了一个框架，其中模型验证其自己的输出，根据此验证过滤或重新加权数据，并提取过滤后的数据。尽管取得了一些经验上的成功，但仍然缺乏基本的理解。在这项工作中，我们对 LLM 自我提升发起了一项全面、模块化且受控的研究。我们为自我提升提供了一个数学公式，该公式在很大程度上由我们形式化为生成验证差距的数量所控制。通过对各种模型系列和任务的实验，我们发现了自我提升的缩放现象——生成验证差距的一个变体与模型预训练 flops 单调缩放。我们还检查了自我提升何时可能，迭代自我提升过程以及提高其性能的方法。我们的发现不仅促进了对 LLM 自我提升的理解并具有实际意义，而且还为未来对其能力和界限的研究开辟了众多途径。

##### **Probing the statistical properties of enriched co-occurrence networks**
2412.02664v1 by Diego R. Amancio, Jeaneth Machicao, Laura V. C. Quispe

Recent studies have explored the addition of virtual edges to word
co-occurrence networks using word embeddings to enhance graph representations,
particularly for short texts. While these enriched networks have demonstrated
some success, the impact of incorporating semantic edges into traditional
co-occurrence networks remains uncertain. This study investigates two key
statistical properties of text-based network models. First, we assess whether
network metrics can effectively distinguish between meaningless and meaningful
texts. Second, we analyze whether these metrics are more sensitive to syntactic
or semantic aspects of the text. Our results show that incorporating virtual
edges can have positive and negative effects, depending on the specific network
metric. For instance, the informativeness of the average shortest path and
closeness centrality improves in short texts, while the clustering
coefficient's informativeness decreases as more virtual edges are added.
Additionally, we found that including stopwords affects the statistical
properties of enriched networks. Our results can serve as a guideline for
determining which network metrics are most appropriate for specific
applications, depending on the typical text size and the nature of the problem.

摘要：<paragraph>最近的研究探索了使用詞嵌入將虛擬邊緣添加到詞共現網路，以增強圖形表示，特別是對於簡短文字。儘管這些豐富的網路已展示出一些成功，但將語義邊緣納入傳統共現網路的影響仍然不確定。本研究探討了基於文字的網路模型的兩個關鍵統計屬性。首先，我們評估網路指標是否能有效區分無意義和有意義的文字。其次，我們分析這些指標是否對文字的句法或語義方面更敏感。我們的結果顯示，納入虛擬邊緣可能會產生正面和負面影響，具體取決於特定的網路指標。例如，平均最短路徑和接近中心性的資訊量在簡短文字中有所改善，而隨著添加更多虛擬邊緣，群集係數的資訊量會降低。此外，我們發現包含停止詞會影響豐富網路的統計屬性。我們的結果可作為指南，用於確定哪些網路指標最適合特定應用，具體取決於典型的文字大小和問題的性質。</paragraph>

##### **Adaptive Informed Deep Neural Networks for Power Flow Analysis**
2412.02659v1 by Zeynab Kaseb, Stavros Orfanoudakis, Pedro P. Vergara, Peter Palensky

This study introduces PINN4PF, an end-to-end deep learning architecture for
power flow (PF) analysis that effectively captures the nonlinear dynamics of
large-scale modern power systems. The proposed neural network (NN) architecture
consists of two important advancements in the training pipeline: (A) a
double-head feed-forward NN that aligns with PF analysis, including an
activation function that adjusts to active and reactive power consumption
patterns, and (B) a physics-based loss function that partially incorporates
power system topology information. The effectiveness of the proposed
architecture is illustrated through 4-bus, 15-bus, 290-bus, and 2224-bus test
systems and is evaluated against two baselines: a linear regression model (LR)
and a black-box NN (MLP). The comparison is based on (i) generalization
ability, (ii) robustness, (iii) impact of training dataset size on
generalization ability, (iv) accuracy in approximating derived PF quantities
(specifically line current, line active power, and line reactive power), and
(v) scalability. Results demonstrate that PINN4PF outperforms both baselines
across all test systems by up to two orders of magnitude not only in terms of
direct criteria, e.g., generalization ability but also in terms of
approximating derived physical quantities.

摘要：本研究引入了 PINN4PF，這是一種端對端深度學習架構，用於電力流 (PF) 分析，有效捕捉大規模現代電力系統的非線性動態。所提出的神經網路 (NN) 架構包含訓練管道中的兩項重要進展：(A) 雙頭前饋 NN，與 PF 分析保持一致，包括調整為有功和無功功率消耗模式的激活函數，以及 (B) 部分納入電力系統拓撲資訊的基於物理的損失函數。所提出的架構的有效性透過 4-母線、15-母線、290-母線和 2224-母線測試系統來說明，並針對兩個基準進行評估：線性回歸模型 (LR) 和黑箱 NN (MLP)。比較基於 (i) 泛化能力，(ii) 穩健性，(iii) 訓練資料集大小對泛化能力的影響，(iv) 近似衍生 PF 量（特別是線路電流、線路有功功率和線路無功功率）的準確度，以及 (v) 可擴充性。結果表明，PINN4PF 在所有測試系統中都優於兩個基準，不僅在直接標準（例如泛化能力）方面，而且在近似衍生物理量方面，都高出兩個數量級。

##### **QA-TOOLBOX: Conversational Question-Answering for process task guidance in manufacturing**
2412.02638v1 by Ramesh Manuvinakurike, Elizabeth Watkins, Celal Savur, Anthony Rhodes, Sovan Biswas, Gesem Gudino Mejia, Richard Beckwith, Saurav Sahay, Giuseppe Raffa, Lama Nachman

In this work we explore utilizing LLMs for data augmentation for
manufacturing task guidance system. The dataset consists of representative
samples of interactions with technicians working in an advanced manufacturing
setting. The purpose of this work to explore the task, data augmentation for
the supported tasks and evaluating the performance of the existing LLMs. We
observe that that task is complex requiring understanding from procedure
specification documents, actions and objects sequenced temporally. The dataset
consists of 200,000+ question/answer pairs that refer to the spec document and
are grounded in narrations and/or video demonstrations. We compared the
performance of several popular open-sourced LLMs by developing a baseline using
each LLM and then compared the responses in a reference-free setting using
LLM-as-a-judge and compared the ratings with crowd-workers whilst validating
the ratings with experts.

摘要：在這項工作中，我們探討利用 LLM 來增強製造任務指導系統的數據。該數據集包含與在先進製造環境中工作的技術人員互動的代表性範例。這項工作的目的是探討任務、支持任務的數據增強以及評估現有 LLM 的效能。我們觀察到任務很複雜，需要從程序規範文件、動作和時序排列的物件中理解。該數據集包含 200,000 個以上的問題/答案對，這些對應於規格文件，並以旁白和/或影片示範為基礎。我們透過使用每個 LLM 來開發基準，比較了幾個流行的開源 LLM 的效能，然後在無參考的設定中使用 LLM 作為評審員比較回應，並與群眾工作者比較評分，同時由專家驗證評分。

##### **Words and Action: Modeling Linguistic Leadership in #BlackLivesMatter Communities**
2412.02637v1 by Dani Roytburg, Deborah Olorunisola, Sandeep Soni, Lauren Klein

In this project, we describe a method of modeling semantic leadership across
a set of communities associated with the #BlackLivesMatter movement, which has
been informed by qualitative research on the structure of social media and
Black Twitter in particular. We describe our bespoke approaches to
time-binning, community clustering, and connecting communities over time, as
well as our adaptation of state-of-the-art approaches to semantic change
detection and semantic leadership induction. We find substantial evidence of
the leadership role of BLM activists and progressives, as well as Black
celebrities. We also find evidence of the sustained engagement of the
conservative community with this discourse, suggesting an alternative
explanation for how we arrived at the present moment, in which "anti-woke" and
"anti-CRT" bills are being enacted nationwide.

摘要：在這個專案中，我們描述了一種跨越與 #BlackLivesMatter 運動相關的社群建模語意領導的方法，這個方法由社群媒體結構和特別是黑人推特上的定性研究提供資訊。我們描述了我們對時間分組、社群分群和社群隨著時間推移的連接的客製化方法，以及我們對語意變更偵測和語意領導歸納的最新方法的改編。我們發現了 BLM 行動者和進步主義者以及黑人名人領導角色的實質證據。我們也發現保守社群持續參與這場論述的證據，這表明我們如何到達現在的時刻的另一種解釋，其中「反覺醒」和「反 CRT」法案正在全國各地制定。

##### **Scaling Image Tokenizers with Grouped Spherical Quantization**
2412.02632v1 by Jiangtao Wang, Zhen Qin, Yifan Zhang, Vincent Tao Hu, Björn Ommer, Rania Briq, Stefan Kesselheim

Vision tokenizers have gained a lot of attraction due to their scalability
and compactness; previous works depend on old-school GAN-based hyperparameters,
biased comparisons, and a lack of comprehensive analysis of the scaling
behaviours. To tackle those issues, we introduce Grouped Spherical Quantization
(GSQ), featuring spherical codebook initialization and lookup regularization to
constrain codebook latent to a spherical surface. Our empirical analysis of
image tokenizer training strategies demonstrates that GSQ-GAN achieves superior
reconstruction quality over state-of-the-art methods with fewer training
iterations, providing a solid foundation for scaling studies. Building on this,
we systematically examine the scaling behaviours of GSQ, specifically in latent
dimensionality, codebook size, and compression ratios, and their impact on
model performance. Our findings reveal distinct behaviours at high and low
spatial compression levels, underscoring challenges in representing
high-dimensional latent spaces. We show that GSQ can restructure
high-dimensional latent into compact, low-dimensional spaces, thus enabling
efficient scaling with improved quality. As a result, GSQ-GAN achieves a 16x
down-sampling with a reconstruction FID (rFID) of 0.50.

摘要：視覺代幣化器由於其可擴展性和緊湊性而備受關注；先前的作品依賴於舊式的基於 GAN 的超參數、有偏差的比較以及缺乏對擴展行為的全面分析。為了解決這些問題，我們引入了分組球面量化 (GSQ)，其特點是球面碼本初始化和查找正則化，以將碼本潛在約束到球面。我們對圖像代幣化器訓練策略的實證分析表明，GSQ-GAN 在較少的訓練迭代中實現了優於最先進方法的重建品質，為擴展研究提供了堅實的基礎。在此基礎上，我們系統地檢驗了 GSQ 的擴展行為，特別是在潛在維度、碼本大小和壓縮比率中，以及它們對模型效能的影響。我們的發現揭示了在高和低空間壓縮級別下的不同行為，強調了表示高維潛在空間的挑戰。我們表明，GSQ 可以將高維潛在重組為緊湊的低維空間，從而實現高效的擴展和提高品質。因此，GSQ-GAN 以 0.50 的重建 FID (rFID) 實現了 16 倍的下採樣。

##### **Time-Reversal Provides Unsupervised Feedback to LLMs**
2412.02626v1 by Yerram Varun, Rahul Madhavan, Sravanti Addepalli, Arun Suggala, Karthikeyan Shanmugam, Prateek Jain

Large Language Models (LLMs) are typically trained to predict in the forward
direction of time. However, recent works have shown that prompting these models
to look back and critique their own generations can produce useful feedback.
Motivated by this, we explore the question of whether LLMs can be empowered to
think (predict and score) backwards to provide unsupervised feedback that
complements forward LLMs. Towards this, we introduce Time Reversed Language
Models (TRLMs), which can score and generate queries when conditioned on
responses, effectively functioning in the reverse direction of time. Further,
to effectively infer in the response to query direction, we pre-train and
fine-tune a language model (TRLM-Ba) in the reverse token order from scratch.
We show empirically (and theoretically in a stylized setting) that
time-reversed models can indeed complement forward model predictions when used
to score the query given response for re-ranking multiple forward generations.
We obtain up to 5\% improvement on the widely used AlpacaEval Leaderboard over
the competent baseline of best-of-N re-ranking using self log-perplexity
scores. We further show that TRLM scoring outperforms conventional forward
scoring of response given query, resulting in significant gains in applications
such as citation generation and passage retrieval. We next leverage the
generative ability of TRLM to augment or provide unsupervised feedback to input
safety filters of LLMs, demonstrating a drastic reduction in false negative
rate with negligible impact on false positive rates against several attacks
published on the popular JailbreakBench leaderboard.

摘要：大型語言模型（LLM）通常會接受訓練以預測時間的正向方向。然而，最近的研究表明，提示這些模型回顧並批評它們自己的世代可以產生有用的回饋。受此啟發，我們探討了 LLM 能否被賦予向後思考（預測和評分）的能力，以提供補充正向 LLM 的無監督回饋。為此，我們引入了時間反向語言模型（TRLM），它可以在回應的條件下評分和產生查詢，有效地運作於時間的反向。此外，為了有效地推論對查詢方向的回應，我們從頭開始以反向符號順序預先訓練和微調語言模型（TRLM-Ba）。我們透過經驗（以及在樣式化設定中的理論）表明，時間反向模型確實可以在用於評分查詢給定的回應以重新排列多個正向生成時，補充正向模型預測。我們在廣泛使用的 AlpacaEval 排行榜上獲得了高達 5% 的改進，優於使用自我對數困惑度評分的最佳 N 次重新排列的基準。我們進一步表明，TRLM 評分優於對給定查詢的傳統正向評分，從而顯著提升了引用生成和段落檢索等應用。接下來，我們利用 TRLM 的生成能力來擴充或提供無監督回饋給 LLM 的輸入安全過濾器，證明在針對流行的 JailbreakBench 排行榜上發布的幾次攻擊中，假陰性率大幅降低，而假陽性率幾乎沒有影響。

##### **Medical Multimodal Foundation Models in Clinical Diagnosis and Treatment: Applications, Challenges, and Future Directions**
2412.02621v1 by Kai Sun, Siyan Xue, Fuchun Sun, Haoran Sun, Yu Luo, Ling Wang, Siyuan Wang, Na Guo, Lei Liu, Tian Zhao, Xinzhou Wang, Lei Yang, Shuo Jin, Jun Yan, Jiahong Dong

Recent advancements in deep learning have significantly revolutionized the
field of clinical diagnosis and treatment, offering novel approaches to improve
diagnostic precision and treatment efficacy across diverse clinical domains,
thus driving the pursuit of precision medicine. The growing availability of
multi-organ and multimodal datasets has accelerated the development of
large-scale Medical Multimodal Foundation Models (MMFMs). These models, known
for their strong generalization capabilities and rich representational power,
are increasingly being adapted to address a wide range of clinical tasks, from
early diagnosis to personalized treatment strategies. This review offers a
comprehensive analysis of recent developments in MMFMs, focusing on three key
aspects: datasets, model architectures, and clinical applications. We also
explore the challenges and opportunities in optimizing multimodal
representations and discuss how these advancements are shaping the future of
healthcare by enabling improved patient outcomes and more efficient clinical
workflows.

摘要：深度學習的最新進展大幅革新了臨床診斷和治療領域，提供了改善各種臨床領域診斷精準度和治療效果的新方法，進而推動精準醫療的追求。多器官和多模態資料集的可用性日益增加，加速了大規模醫療多模態基礎模型 (MMFM) 的發展。這些模型以其強大的概化能力和豐富的表徵能力而聞名，正日益被改編以解決廣泛的臨床任務，從早期診斷到個人化治療策略。本篇評論提供了對 MMFM 近期發展的全面分析，重點關注三個關鍵面向：資料集、模型架構和臨床應用。我們也探討了最佳化多模態表徵的挑戰和機會，並討論這些進展如何透過改善患者預後和更有效率的臨床工作流程，形塑醫療保健的未來。

##### **Improving Dynamic Object Interactions in Text-to-Video Generation with AI Feedback**
2412.02617v1 by Hiroki Furuta, Heiga Zen, Dale Schuurmans, Aleksandra Faust, Yutaka Matsuo, Percy Liang, Sherry Yang

Large text-to-video models hold immense potential for a wide range of
downstream applications. However, these models struggle to accurately depict
dynamic object interactions, often resulting in unrealistic movements and
frequent violations of real-world physics. One solution inspired by large
language models is to align generated outputs with desired outcomes using
external feedback. This enables the model to refine its responses autonomously,
eliminating extensive manual data collection. In this work, we investigate the
use of feedback to enhance the object dynamics in text-to-video models. We aim
to answer a critical question: what types of feedback, paired with which
specific self-improvement algorithms, can most effectively improve text-video
alignment and realistic object interactions? We begin by deriving a unified
probabilistic objective for offline RL finetuning of text-to-video models. This
perspective highlights how design elements in existing algorithms like KL
regularization and policy projection emerge as specific choices within a
unified framework. We then use derived methods to optimize a set of text-video
alignment metrics (e.g., CLIP scores, optical flow), but notice that they often
fail to align with human perceptions of generation quality. To address this
limitation, we propose leveraging vision-language models to provide more
nuanced feedback specifically tailored to object dynamics in videos. Our
experiments demonstrate that our method can effectively optimize a wide variety
of rewards, with binary AI feedback driving the most significant improvements
in video quality for dynamic interactions, as confirmed by both AI and human
evaluations. Notably, we observe substantial gains when using reward signals
derived from AI feedback, particularly in scenarios involving complex
interactions between multiple objects and realistic depictions of objects
falling.

摘要：大型文本到影片模型在廣泛的下游應用中具有巨大潛力。然而，這些模型難以準確描繪動態物體交互，經常導致不切實際的動作和頻繁違反現實世界物理定律。一種受大型語言模型啟發的解決方案是使用外部回饋將生成的輸出與預期的結果對齊。這使模型能夠自主優化其回應，從而消除廣泛的手動數據收集。在這項工作中，我們研究了使用回饋來增強文本到影片模型中的物體動態。我們旨在回答一個關鍵問題：哪種類型的回饋與哪些具體的自完善演算法配對，可以最有效地改善文本影片對齊和逼真的物體交互？我們首先為文本到影片模型的離線 RL 微調推導出一個統一的機率目標。此觀點強調了現有演算法中的設計元素，例如 KL 正規化和策略投影，如何作為統一架構中的特定選擇出現。然後，我們使用衍生方法來最佳化一組文本影片對齊指標（例如 CLIP 分數、光流），但注意到它們通常無法與人類對生成品質的感知相符。為了解決這個限制，我們建議利用視覺語言模型來提供更細緻的回饋，特別針對影片中的物體動態。我們的實驗表明，我們的模型可以有效最佳化各種獎勵，其中二元 AI 回饋在影片品質中推動了動態交互方面最顯著的改善，這由 AI 和人類評估證實。值得注意的是，我們在使用源自 AI 回饋的獎勵信號時觀察到顯著的收益，特別是在涉及多個物體之間複雜交互和物體下落逼真描繪的情境中。

##### **GLM-4-Voice: Towards Intelligent and Human-Like End-to-End Spoken Chatbot**
2412.02612v1 by Aohan Zeng, Zhengxiao Du, Mingdao Liu, Kedong Wang, Shengmin Jiang, Lei Zhao, Yuxiao Dong, Jie Tang

We introduce GLM-4-Voice, an intelligent and human-like end-to-end spoken
chatbot. It supports both Chinese and English, engages in real-time voice
conversations, and varies vocal nuances such as emotion, intonation, speech
rate, and dialect according to user instructions. GLM-4-Voice uses an ultra-low
bitrate (175bps), single-codebook speech tokenizer with 12.5Hz frame rate
derived from an automatic speech recognition (ASR) model by incorporating a
vector-quantized bottleneck into the encoder. To efficiently transfer knowledge
from text to speech modalities, we synthesize speech-text interleaved data from
existing text pre-training corpora using a text-to-token model. We continue
pre-training from the pre-trained text language model GLM-4-9B with a
combination of unsupervised speech data, interleaved speech-text data, and
supervised speech-text data, scaling up to 1 trillion tokens, achieving
state-of-the-art performance in both speech language modeling and spoken
question answering. We then fine-tune the pre-trained model with high-quality
conversational speech data, achieving superior performance compared to existing
baselines in both conversational ability and speech quality. The open models
can be accessed through https://github.com/THUDM/GLM-4-Voice and
https://huggingface.co/THUDM/glm-4-voice-9b.

摘要：<paragraph>我們推出 GLM-4-Voice，一款智慧且擬人的端對端語音聊天機器人。它支援中文和英文，進行即時語音對話，並根據使用者的指示調整語音的細微差別，例如情緒、語調、語速和方言。GLM-4-Voice 使用超低位元率 (175bps)、單碼本語音分詞器，具有 12.5Hz 幀率，源自於自動語音辨識 (ASR) 模型，方法是將向量量化瓶頸納入編碼器中。為了有效率地將知識從文字傳輸到語音模式，我們使用文字到代碼模型，從現有的文字預訓練語料庫中合成語音文字交錯資料。我們繼續使用預訓練文字語言模型 GLM-4-9B 進行預訓練，並結合非監督式語音資料、交錯語音文字資料，以及監督式語音文字資料，擴充到 1 兆個代碼，在語音語言建模和語音問答中達成最先進的表現。然後，我們使用高品質對話語音資料微調預訓練模型，在對話能力和語音品質上都達成比現有基準更好的表現。開放模型可透過 https://github.com/THUDM/GLM-4-Voice 和 https://huggingface.co/THUDM/glm-4-voice-9b 存取。</paragraph>

##### **AV-Odyssey Bench: Can Your Multimodal LLMs Really Understand Audio-Visual Information?**
2412.02611v1 by Kaixiong Gong, Kaituo Feng, Bohao Li, Yibing Wang, Mofan Cheng, Shijia Yang, Jiaming Han, Benyou Wang, Yutong Bai, Zhuoran Yang, Xiangyu Yue

Recently, multimodal large language models (MLLMs), such as GPT-4o, Gemini
1.5 Pro, and Reka Core, have expanded their capabilities to include vision and
audio modalities. While these models demonstrate impressive performance across
a wide range of audio-visual applications, our proposed DeafTest reveals that
MLLMs often struggle with simple tasks humans find trivial: 1) determining
which of two sounds is louder, and 2) determining which of two sounds has a
higher pitch. Motivated by these observations, we introduce AV-Odyssey Bench, a
comprehensive audio-visual benchmark designed to assess whether those MLLMs can
truly understand the audio-visual information. This benchmark encompasses 4,555
carefully crafted problems, each incorporating text, visual, and audio
components. To successfully infer answers, models must effectively leverage
clues from both visual and audio inputs. To ensure precise and objective
evaluation of MLLM responses, we have structured the questions as
multiple-choice, eliminating the need for human evaluation or LLM-assisted
assessment. We benchmark a series of closed-source and open-source models and
summarize the observations. By revealing the limitations of current models, we
aim to provide useful insight for future dataset collection and model
development.

摘要：最近，多模态大型语言模型 (MLLM)，例如 GPT-4o、Gemini 1.5 Pro 和 Reka Core，已扩展其功能，包括视觉和音频模态。虽然这些模型在广泛的视听应用中表现出令人印象深刻的性能，但我们提出的 DeafTest 表明，MLLM 通常难以完成人类认为微不足道的简单任务：1) 确定两个声音中哪个声音更响亮，以及 2) 确定两个声音中哪个声音更高。受这些观察结果的启发，我们引入了 AV-Odyssey Bench，这是一个全面的视听基准，旨在评估这些 MLLM 是否真正能够理解视听信息。此基准包含 4,555 个精心设计的问题，每个问题都包含文本、视觉和音频组件。为了成功推断答案，模型必须有效利用视觉和音频输入的线索。为了确保对 MLLM 响应进行精确和客观的评估，我们已将问题构建为多项选择题，从而无需人工评估或 LLM 辅助评估。我们对一系列闭源和开源模型进行了基准测试，并总结了观察结果。通过揭示当前模型的局限性，我们旨在为未来的数据集收集和模型开发提供有用的见解。

##### **AI-Driven Resource Allocation Framework for Microservices in Hybrid Cloud Platforms**
2412.02610v1 by Biman Barua, M. Shamim Kaiser

The increasing demand for scalable, efficient resource management in hybrid
cloud environments has led to the exploration of AI-driven approaches for
dynamic resource allocation. This paper presents an AI-driven framework for
resource allocation among microservices in hybrid cloud platforms. The
framework employs reinforcement learning (RL)-based resource utilization
optimization to reduce costs and improve performance. The framework integrates
AI models with cloud management tools to respond to challenges of dynamic
scaling and cost-efficient low-latency service delivery. The reinforcement
learning model continuously adjusts provisioned resources as required by the
microservices and predicts the future consumption trends to minimize both
under- and over-provisioning of resources. Preliminary simulation results
indicate that using AI in the provision of resources related to costs can
reduce expenditure by up to 30-40% compared to manual provisioning and
threshold-based auto-scaling approaches. It is also estimated that the
efficiency in resource utilization is expected to improve by 20%-30% with a
corresponding latency cut of 15%-20% during the peak demand periods. This study
compares the AI-driven approach with existing static and rule-based resource
allocation methods, demonstrating the capability of this new model to
outperform them in terms of flexibility and real-time interests. The results
indicate that reinforcement learning can make optimization of hybrid cloud
platforms even better, offering a 25-35% improvement in cost efficiency and the
power of scaling for microservice-based applications. The proposed framework is
a strong and scalable solution to managing cloud resources in dynamic and
performance-critical environments.

摘要：<paragraph>混合云端環境中對於可擴充、有效率資源管理的日益需求，導致了對人工智慧驅動方法在動態資源分配上的探索。本文提出一個人工智慧驅動的架構，用於混合雲端平台中微服務的資源分配。此架構採用強化學習 (RL) 為基礎的資源使用率最佳化，以降低成本並提升效能。此架構整合人工智慧模型與雲端管理工具，以回應動態擴充和成本效益低延遲服務傳遞的挑戰。強化學習模型會持續調整微服務所需的配置資源，並預測未來的消耗趨勢，以將資源配置不足和過度配置的狀況減至最低。初步的模擬結果顯示，在資源配置中使用人工智慧可以將成本降低 30-40%，相比於手動配置和基於閾值的自動擴充方法。此外，估計資源使用率的效率預計將提升 20%-30%，在需求高峰期時相應減少 15%-20% 的延遲。本研究將人工智慧驅動的方法與現有的靜態和基於規則的資源分配方法進行比較，證明了此新模型在靈活性與即時利益方面的優異表現。結果顯示，強化學習可以進一步最佳化混合雲端平台，為基於微服務的應用程式提供 25-35% 的成本效益改善和擴充能力。所提出的架構是管理動態和效能至上的環境中雲端資源的強大且可擴充的解決方案。</paragraph>

##### **Interpretable Company Similarity with Sparse Autoencoders**
2412.02605v1 by Marco Molinari, Vladimir Tregubiak, Victor Shao, Abhimanyu Pandey, Mateusz Mikolajczak, Sebastião Kuznetsov Ryder Torres Pereira

Determining company similarity is a vital task in finance, underpinning
hedging, risk management, portfolio diversification, and more. Practitioners
often rely on sector and industry classifications to gauge similarity, such as
SIC-codes and GICS-codes, the former being used by the U.S. Securities and
Exchange Commission (SEC), and the latter widely used by the investment
community. Clustering embeddings of company descriptions has been proposed as a
potential technique for determining company similarity, but the lack of
interpretability in token embeddings poses a significant barrier to adoption in
high-stakes contexts. Sparse Autoencoders have shown promise in enhancing the
interpretability of Large Language Models by decomposing LLM activations into
interpretable features. In this paper, we explore the use of SAE features in
measuring company similarity and benchmark them against (1) SIC codes and (2)
Major Group codes. We conclude that SAE features can reproduce and even surpass
sector classifications in quantifying fundamental characteristics of companies,
evaluated by the correlation of monthly returns, a proxy for similarity, and
PnL from cointegration.

摘要：確定公司相似性是金融領域的一項重要任務，它支撐著避險、風險管理、投資組合多元化等。實務工作者通常依賴產業和行業分類來評估相似性，例如 SIC 代碼和 GICS 代碼，前者由美國證券交易委員會 (SEC) 使用，而後者則廣泛用於投資界。將公司描述的嵌入式分群已被提出作為確定公司相似性的潛在技術，但標記嵌入式的可解釋性不足，對在高風險環境中採用此技術構成重大障礙。稀疏自動編碼器已展現出增強大型語言模型可解釋性的潛力，方法是將 LLM 激活分解為可解釋特徵。在本文中，我們探討了在衡量公司相似性時使用 SAE 特徵，並將其與 (1) SIC 代碼和 (2) 主要群組代碼進行比較。我們得出的結論是，SAE 特徵可以複製甚至超越產業分類，以量化公司的基本特徵，這由每月報酬率相關性（相似性的代理指標）和協整的損益來評估。

##### **CEGI: Measuring the trade-off between efficiency and carbon emissions for SLMs and VLMs**
2412.02602v1 by Abhas Kumar, Kapil Pathak, Rajesh Kavuru, Prabhakar Srinivasan

This paper analyzes the performance of Small Language Models (SLMs) and
Vision Language Models (VLMs) and evaluates the trade-off between model
performance and carbon emissions across 4 essential tasks: Image Captioning,
Visual Question Answering (VQA), Dialogue Summarization and Text-to-SQL
conversion. Various SLMs and VLMs belonging to the Qwen and LLaMA architecture
family are chosen and variants based on model size in terms of the number of
parameters, quantization level and fine-tuning parameters are evaluated. The
model variant's performance and carbon emissions are calculated. To quantify
the trade-off between model performance and carbon emissions, we introduce a
novel metric called CEGI (Carbon Efficient Gain Index). This metric represents
the carbon emission per unit percentage gain per million trainable parameters .
This metric provides a normalized measure to compare model's efficiency in
terms of performance improvement relative to their environmental cost. The
experiment's outcome demonstrates that fine-tuning SLMs and VLMs can achieve
performance levels comparable to Large Language Models (LLMs) while producing
significantly less carbon emissions. Our findings suggest that the marginal
gains in accuracy from larger models do not justify the substantial increase in
carbon emissions. Leveraging lower-bit quantization levels, the proposed metric
further enhances energy efficiency without compromising performance. This study
highlights balancing high performance and environmental sustainability. It
offers a valuable metric for selecting models suitable for
environmentally-friendly AI development.

摘要：本文分析了小型语言模型 (SLM) 和视觉语言模型 (VLM) 的性能，并评估了 4 项基本任务中的模型性能和碳排放之间的权衡：图像字幕、视觉问答 (VQA)、对话摘要和文本到 SQL 转换。选择了属于 Qwen 和 LLaMA 架构系列的各种 SLM 和 VLM，并根据参数数量、量化级别和微调参数等指标评估了基于模型大小的变体。计算了模型变体的性能和碳排放。为了量化模型性能和碳排放之间的权衡，我们引入了一个称为 CEGI（碳效率收益指数）的新指标。此指标表示每百万个可训练参数的单位百分比收益的碳排放。该指标提供了一个标准化的衡量标准，用于比较模型在性能提升方面的效率相对于其环境成本。实验结果表明，微调 SLM 和 VLM 可以实现与大型语言模型 (LLM) 相当的性能水平，同时产生明显更少的碳排放。我们的研究结果表明，更大模型的准确性边际收益并不能证明碳排放的显着增加。通过利用低位量化级别，所提出的指标在不影响性能的情况下进一步提高了能源效率。本研究强调了平衡高性能和环境可持续性。它为选择适合环境友好型人工智能开发的模型提供了有价值的指标。

##### **Nemotron-CC: Transforming Common Crawl into a Refined Long-Horizon Pretraining Dataset**
2412.02595v1 by Dan Su, Kezhi Kong, Ying Lin, Joseph Jennings, Brandon Norick, Markus Kliegl, Mostofa Patwary, Mohammad Shoeybi, Bryan Catanzaro

Recent English Common Crawl datasets like FineWeb-Edu and DCLM achieved
significant benchmark gains via aggressive model-based filtering, but at the
cost of removing 90% of data. This limits their suitability for long token
horizon training, such as 15T tokens for Llama 3.1. In this paper, we show how
to achieve better trade-offs between accuracy and data quantity by a
combination of classifier ensembling, synthetic data rephrasing, and reduced
reliance on heuristic filters. When training 8B parameter models for 1T tokens,
using a high-quality subset of our data improves MMLU by 5.6 over DCLM,
demonstrating the efficacy of our methods for boosting accuracies over a
relatively short token horizon. Furthermore, our full 6.3T token dataset
matches DCLM on MMLU, but contains four times more unique real tokens than
DCLM. This unlocks state-of-the-art training over a long token horizon: an 8B
parameter model trained for 15T tokens, of which 7.2T came from our dataset, is
better than the Llama 3.1 8B model: +5 on MMLU, +3.1 on ARC-Challenge, and +0.5
on average across ten diverse tasks. The dataset is available at
https://data.commoncrawl.org/contrib/Nemotron/Nemotron-CC/index.html

摘要：最近的 English Common Crawl 資料集，例如 FineWeb-Edu 和 DCLM，透過積極的基於模型的篩選，獲得了顯著的基準收益，但代價是移除 90% 的資料。這限制了它們適用於長期代碼訓練，例如 Llama 3.1 的 15T 代碼。在本文中，我們展示如何透過分類器集成、合成資料改寫和減少依賴啟發式過濾器，在準確度和資料數量之間取得更好的折衷。在針對 1T 代碼訓練 8B 參數模型時，使用我們資料中的高品質子集，將 MMLU 提升 5.6，高於 DCLM，證明了我們的方法在提升準確度方面的效力，代碼範圍相對較短。此外，我們完整的 6.3T 代碼資料集在 MMLU 上與 DCLM 相符，但包含比 DCLM 多四倍的獨特真實代碼。這解鎖了在長期代碼範圍內進行最先進的訓練：針對 15T 代碼訓練的 8B 參數模型，其中 7.2T 來自我們的資料集，優於 Llama 3.1 8B 模型：MMLU +5，ARC-Challenge +3.1，以及在十項不同的任務中平均 +0.5。資料集可在 https://data.commoncrawl.org/contrib/Nemotron/Nemotron-CC/index.html 取得

##### **PrefixLLM: LLM-aided Prefix Circuit Design**
2412.02594v1 by Weihua Xiao, Venkata Sai Charan Putrevu, Raghu Vamshi Hemadri, Siddharth Garg, Ramesh Karri

Prefix circuits are fundamental components in digital adders, widely used in
digital systems due to their efficiency in calculating carry signals.
Synthesizing prefix circuits with minimized area and delay is crucial for
enhancing the performance of modern computing systems. Recently, large language
models (LLMs) have demonstrated a surprising ability to perform text generation
tasks. We propose PrefixLLM, that leverages LLMs for prefix circuit synthesis.
PrefixLLM transforms the prefix circuit synthesis task into a structured text
generation problem, termed the Structured Prefix Circuit Representation (SPCR),
and introduces an iterative framework to automatically and accurately generate
valid SPCRs. We further present a design space exploration (DSE) framework that
uses LLMs to iteratively search for area and delay optimized prefix circuits.
Compared to state-of-the-art, PrefixLLM can reduce the area by 3.70% under the
same delay constraint. This work highlights the use of LLMs in the synthesis of
arithmetic circuits, which can be transformed into the structured text
generation.

摘要：前綴電路是數位加法器中的基本元件，由於其在計算進位訊號方面的效率，廣泛用於數位系統中。
以最小面積和延遲合成前綴電路對於增強現代計算系統的效能至關重要。最近，大型語言模型 (LLM) 已展現出執行文字生成任務的驚人能力。我們提出 PrefixLLM，它利用 LLM 來合成前綴電路。
PrefixLLM 將前綴電路合成任務轉換為結構化文字生成問題，稱為結構化前綴電路表示 (SPCR)，並引入一個反覆運算架構，以自動且準確地產生有效的 SPCR。我們進一步提出一個設計空間探索 (DSE) 架構，它使用 LLM 來反覆運算搜尋面積和延遲最佳化的前綴電路。
與現有技術相比，PrefixLLM 可以減少 3.70% 的面積，同時延遲約束相同。這項工作突顯了 LLM 在算術電路合成中的應用，這可以轉換為結構化文字生成。

##### **Explainable CTR Prediction via LLM Reasoning**
2412.02588v1 by Xiaohan Yu, Li Zhang, Chong Chen

Recommendation Systems have become integral to modern user experiences, but
lack transparency in their decision-making processes. Existing explainable
recommendation methods are hindered by reliance on a post-hoc paradigm, wherein
explanation generators are trained independently of the underlying recommender
models. This paradigm necessitates substantial human effort in data
construction and raises concerns about explanation reliability. In this paper,
we present ExpCTR, a novel framework that integrates large language model based
explanation generation directly into the CTR prediction process. Inspired by
recent advances in reinforcement learning, we employ two carefully designed
reward mechanisms, LC alignment, which ensures explanations reflect user
intentions, and IC alignment, which maintains consistency with traditional
ID-based CTR models. Our approach incorporates an efficient training paradigm
with LoRA and a three-stage iterative process. ExpCTR circumvents the need for
extensive explanation datasets while fostering synergy between CTR prediction
and explanation generation. Experimental results demonstrate that ExpCTR
significantly enhances both recommendation accuracy and interpretability across
three real-world datasets.

摘要：推薦系統已成為現代使用者體驗中不可或缺的一部分，但其決策過程缺乏透明度。現有的可解釋推薦方法受到事後範式的依賴所阻礙，其中解釋產生器與基礎推薦模型獨立訓練。此範式需要大量的人力進行資料建構，並引發對解釋可靠性的疑慮。在本文中，我們提出 ExpCTR，一種新穎的架構，將基於大型語言模型的解釋產生直接整合到 CTR 預測過程中。受到強化學習最近進展的啟發，我們採用兩種精心設計的獎勵機制，LC 對齊，確保解釋反映使用者的意圖，以及 IC 對齊，維持與傳統基於 ID 的 CTR 模型的一致性。我們的做法結合了使用 LoRA 的有效訓練範例和三階段反覆運算。ExpCTR 迴避了對廣泛解釋資料集的需求，同時促進 CTR 預測和解釋產生之間的協同作用。實驗結果證明，ExpCTR 在三個真實世界資料集中顯著提升了推薦準確性和可解釋性。

##### **Factored space models: Towards causality between levels of abstraction**
2412.02579v1 by Scott Garrabrant, Matthias Georg Mayer, Magdalena Wache, Leon Lang, Sam Eisenstat, Holger Dell

Causality plays an important role in understanding intelligent behavior, and
there is a wealth of literature on mathematical models for causality, most of
which is focused on causal graphs. Causal graphs are a powerful tool for a wide
range of applications, in particular when the relevant variables are known and
at the same level of abstraction. However, the given variables can also be
unstructured data, like pixels of an image. Meanwhile, the causal variables,
such as the positions of objects in the image, can be arbitrary deterministic
functions of the given variables. Moreover, the causal variables may form a
hierarchy of abstractions, in which the macro-level variables are deterministic
functions of the micro-level variables. Causal graphs are limited when it comes
to modeling this kind of situation. In the presence of deterministic
relationships there is generally no causal graph that satisfies both the Markov
condition and the faithfulness condition. We introduce factored space models as
an alternative to causal graphs which naturally represent both probabilistic
and deterministic relationships at all levels of abstraction. Moreover, we
introduce structural independence and establish that it is equivalent to
statistical independence in every distribution that factorizes over the
factored space. This theorem generalizes the classical soundness and
completeness theorem for d-separation.

摘要：因果关系在理解智能行为中扮演着重要的角色，并且有大量的关于因果关系数学模型的文献，其中大部分都集中在因果图上。因果图是适用于广泛应用的强大工具，尤其是在相关变量已知并且处于同一抽象级别时。然而，给定的变量也可以是无结构数据，例如图像的像素。同时，因果变量（例如图像中物体的坐标）可以是给定变量的任意确定性函数。此外，因果变量可以形成一个抽象层次结构，其中宏观变量是微观变量的确定性函数。在对这种情况进行建模时，因果图是有限的。在存在确定性关系的情况下，通常没有因果图同时满足马尔可夫条件和忠实条件。我们引入分解空间模型作为因果图的替代方案，它自然地表示所有抽象级别的概率和确定性关系。此外，我们引入了结构独立性，并确立了它在分解空间上分解的每个分布中都等效于统计独立性。这个定理概括了 d 分离的经典健全性和完备性定理。

##### **Segmentation of Coronary Artery Stenosis in X-ray Angiography using Mamba Models**
2412.02568v1 by Ali Rostami, Fatemeh Fouladi, Hedieh Sajedi

Coronary artery disease stands as one of the primary contributors to global
mortality rates. The automated identification of coronary artery stenosis from
X-ray images plays a critical role in the diagnostic process for coronary heart
disease. This task is challenging due to the complex structure of coronary
arteries, intrinsic noise in X-ray images, and the fact that stenotic coronary
arteries appear narrow and blurred in X-ray angiographies. This study employs
five different variants of the Mamba-based model and one variant of the Swin
Transformer-based model, primarily based on the U-Net architecture, for the
localization of stenosis in Coronary artery disease. Our best results showed an
F1 score of 68.79% for the U-Mamba BOT model, representing an 11.8% improvement
over the semi-supervised approach.

摘要：冠狀動脈疾病是全球死亡率的主要原因之一。從 X 光影像中自動辨識冠狀動脈狹窄在冠狀動脈心臟疾病的診斷過程中扮演著至關重要的角色。此項任務具有挑戰性，原因在於冠狀動脈的結構複雜、X 光影像中有固有雜訊，而且狹窄的冠狀動脈在 X 光血管攝影中會顯得狹窄且模糊。本研究採用五種不同變體的 Mamba 模型和一種基於 Swin Transformer 的模型變體，主要基於 U-Net 架構，用於定位冠狀動脈疾病中的狹窄。我們的最佳結果顯示，U-Mamba BOT 模型的 F1 分數為 68.79%，比半監督式方法提升了 11.8%。

##### **Semantic Tokens in Retrieval Augmented Generation**
2412.02563v1 by Joel Suro

Retrieval-Augmented Generation (RAG) architectures have recently garnered
significant attention for their ability to improve truth grounding and
coherence in natural language processing tasks. However, the reliability of RAG
systems in producing accurate answers diminishes as the volume of data they
access increases. Even with smaller datasets, these systems occasionally fail
to address simple queries. This issue arises from their dependence on
state-of-the-art large language models (LLMs), which can introduce uncertainty
into the system's outputs. In this work, I propose a novel Comparative RAG
system that introduces an evaluator module to bridge the gap between
probabilistic RAG systems and deterministically verifiable responses. The
evaluator compares external recommendations with the retrieved document chunks,
adding a decision-making layer that enhances the system's reliability. This
approach ensures that the chunks retrieved are both semantically relevant and
logically consistent with deterministic insights, thereby improving the
accuracy and overall efficiency of RAG systems. This framework paves the way
for more reliable and scalable question-answering applications in domains
requiring high precision and verifiability.

摘要：檢索增強生成（RAG）架構最近因其改善自然語言處理任務中真實依據和連貫性的能力而備受關注。然而，隨著 RAG 系統存取的資料量增加，其產生準確答案的可靠性會下降。即使在較小的資料集，這些系統偶爾也無法解決簡單的查詢。此問題源於它們依賴於最先進的大語言模型（LLM），這可能會為系統的輸出引入不確定性。在這項工作中，我提出了一個新穎的比較式 RAG 系統，它引入了一個評估器模組來彌合機率式 RAG 系統和確定性可驗證回應之間的差距。評估器將外部建議與檢索到的文件區塊進行比較，增加了一個決策層，以增強系統的可靠性。這種方法確保檢索到的區塊在語義上相關且在邏輯上與確定性見解一致，從而提高 RAG 系統的準確性和整體效率。此架構為在需要高精度和可驗證性的領域中建立更可靠且可擴充的問答應用程式鋪平了道路。

##### **Patent-CR: A Dataset for Patent Claim Revision**
2412.02549v1 by Lekang Jiang, Pascal A Scherz, Stephan Goetz

This paper presents Patent-CR, the first dataset created for the patent claim
revision task in English. It includes both initial patent applications rejected
by patent examiners and the final granted versions. Unlike normal text revision
tasks that predominantly focus on enhancing sentence quality, such as grammar
correction and coherence improvement, patent claim revision aims at ensuring
the claims meet stringent legal criteria. These criteria are beyond novelty and
inventiveness, including clarity of scope, technical accuracy, language
precision, and legal robustness. We assess various large language models (LLMs)
through professional human evaluation, including general LLMs with different
sizes and architectures, text revision models, and domain-specific models. Our
results indicate that LLMs often bring ineffective edits that deviate from the
target revisions. In addition, domain-specific models and the method of
fine-tuning show promising results. Notably, GPT-4 outperforms other tested
LLMs, but further revisions are still necessary to reach the examination
standard. Furthermore, we demonstrate the inconsistency between automated and
human evaluation results, suggesting that GPT-4-based automated evaluation has
the highest correlation with human judgment. This dataset, along with our
preliminary empirical research, offers invaluable insights for further
exploration in patent claim revision.

摘要：本文提出了 Patent-CR，这是第一个为英文专利申请修改任务创建的数据集。它包括专利审查员拒绝的初始专利申请和最终授予的版本。与主要关注于提高句子质量（例如语法纠正和连贯性改进）的普通文本修改任务不同，专利申请修改旨在确保申请符合严格的法律标准。这些标准超出了新颖性和创造性，包括范围的清晰度、技术准确性、语言精确性和法律稳健性。我们通过专业的人工评估来评估各种大型语言模型 (LLM)，包括具有不同大小和架构的通用 LLM、文本修改模型和特定领域的模型。我们的结果表明，LLM 经常带来无效的编辑，偏离目标修改。此外，特定领域的模型和微调方法显示出有希望的结果。值得注意的是，GPT-4 优于其他经过测试的 LLM，但仍需要进一步修改才能达到审查标准。此外，我们展示了自动评估和人工评估结果之间的不一致性，表明基于 GPT-4 的自动评估与人工判断的相关性最高。该数据集以及我们初步的实证研究为专利申请修改的进一步探索提供了宝贵的见解。

##### **Graph-Powered Defense: Controller Area Network Intrusion Detection for Unmanned Aerial Vehicles**
2412.02539v1 by Reek Majumder, Gurcan Comert, David Werth, Adrian Gale, Mashrur Chowdhury, M Sabbir Salek

The network of services, including delivery, farming, and environmental
monitoring, has experienced exponential expansion in the past decade with
Unmanned Aerial Vehicles (UAVs). Yet, UAVs are not robust enough against
cyberattacks, especially on the Controller Area Network (CAN) bus. The CAN bus
is a general-purpose vehicle-bus standard to enable microcontrollers and
in-vehicle computers to interact, primarily connecting different Electronic
Control Units (ECUs). In this study, we focus on solving some of the most
critical security weaknesses in UAVs by developing a novel graph-based
intrusion detection system (IDS) leveraging the Uncomplicated Application-level
Vehicular Communication and Networking (UAVCAN) protocol. First, we decode CAN
messages based on UAVCAN protocol specification; second, we present a
comprehensive method of transforming tabular UAVCAN messages into graph
structures. Lastly, we apply various graph-based machine learning models for
detecting cyber-attacks on the CAN bus, including graph convolutional neural
networks (GCNNs), graph attention networks (GATs), Graph Sample and Aggregate
Networks (GraphSAGE), and graph structure-based transformers. Our findings show
that inductive models such as GATs, GraphSAGE, and graph-based transformers can
achieve competitive and even better accuracy than transductive models like
GCNNs in detecting various types of intrusions, with minimum information on
protocol specification, thus providing a generic robust solution for CAN bus
security for the UAVs. We also compared our results with baseline single-layer
Long Short-Term Memory (LSTM) and found that all our graph-based models perform
better without using any decoded features based on the UAVCAN protocol,
highlighting higher detection performance with protocol-independent capability.

摘要：<paragraph>包括遞送、農業和環境監控在內的服務網路在過去十年中，隨著無人機 (UAV) 的使用而經歷了指數級的擴展。然而，無人機在對抗網路攻擊方面不夠強大，特別是在控制器區域網路 (CAN) 總線上。CAN 總線是一個通用車輛總線標準，用於使微控制器和車載電腦能夠互動，主要連接不同的電子控制單元 (ECU)。在本研究中，我們專注於透過開發一種新穎的基於圖形入侵偵測系統 (IDS) 來解決無人機中一些最關鍵的安全弱點，並利用了簡易應用層車輛通訊和網路 (UAVCAN) 協定。首先，我們根據 UAVCAN 協定規範解碼 CAN 訊息；其次，我們提出了一個將表格化 UAVCAN 訊息轉換為圖形結構的全面方法。最後，我們應用各種基於圖形的機器學習模型來偵測 CAN 總線上的網路攻擊，包括圖形卷積神經網路 (GCNN)、圖形注意力網路 (GAT)、圖形採樣和聚合網路 (GraphSAGE) 以及基於圖形結構的轉換器。我們的研究結果表明，GAT、GraphSAGE 和基於圖形的轉換器等歸納模型在偵測各種類型的入侵時，可以達到與 GCNN 等轉導模型相當甚至更好的準確度，且對協定規範的資訊最少，從而為無人機的 CAN 總線安全性提供了一個通用的強大解決方案。我們還將我們的結果與基線單層長短期記憶 (LSTM) 進行了比較，發現我們所有的基於圖形的模型在不使用任何基於 UAVCAN 協定的解碼特徵的情況下都能表現得更好，突顯了具有協定獨立功能的更高的偵測效能。</paragraph>

##### **WEM-GAN: Wavelet transform based facial expression manipulation**
2412.02530v1 by Dongya Sun, Yunfei Hu, Xianzhe Zhang, Yingsong Hu

Facial expression manipulation aims to change human facial expressions
without affecting face recognition. In order to transform the facial
expressions to target expressions, previous methods relied on expression labels
to guide the manipulation process. However, these methods failed to preserve
the details of facial features, which causes the weakening or the loss of
identity information in the output image. In our work, we propose WEM-GAN, in
short for wavelet-based expression manipulation GAN, which puts more efforts on
preserving the details of the original image in the editing process. Firstly,
we take advantage of the wavelet transform technique and combine it with our
generator with a U-net autoencoder backbone, in order to improve the
generator's ability to preserve more details of facial features. Secondly, we
also implement the high-frequency component discriminator, and use
high-frequency domain adversarial loss to further constrain the optimization of
our model, providing the generated face image with more abundant details.
Additionally, in order to narrow the gap between generated facial expressions
and target expressions, we use residual connections between encoder and
decoder, while also using relative action units (AUs) several times. Extensive
qualitative and quantitative experiments have demonstrated that our model
performs better in preserving identity features, editing capability, and image
generation quality on the AffectNet dataset. It also shows superior performance
in metrics such as Average Content Distance (ACD) and Expression Distance (ED).

摘要：人臉表情操縱旨在改變人類人臉表情，同時不影響人臉辨識。為了將人臉表情轉換為目標表情，先前的做法依賴表情標籤來引導操縱過程。然而，這些方法無法保留人臉特徵的細節，這會導致輸出影像中身分資訊減弱或遺失。在我們的研究中，我們提出了 WEM-GAN，簡稱小波表情操縱 GAN，它在編輯過程中投入更多心力來保留原始影像的細節。首先，我們利用小波轉換技術，並將其與我們的生成器結合使用 U-net 自動編碼器主幹，以提升生成器保留更多人臉特徵細節的能力。其次，我們也實作了高頻分量判別器，並使用高頻域對抗損失進一步約束模型的最佳化，讓生成的臉部影像擁有更豐富的細節。此外，為了縮小生成的臉部表情與目標表情之間的差距，我們在編碼器和解碼器之間使用殘差連接，同時也多次使用相對動作單元 (AU)。廣泛的定性和定量實驗已證明，我們的模型在保留身分特徵、編輯能力和 AffectNet 資料集上的影像生成品質方面表現得更好。它在平均內容距離 (ACD) 和表情距離 (ED) 等指標上也展現出優異的表現。

##### **Bias Analysis of AI Models for Undergraduate Student Admissions**
2412.02528v1 by Kelly Van Busum, Shiaofen Fang

Bias detection and mitigation is an active area of research in machine
learning. This work extends previous research done by the authors to provide a
rigorous and more complete analysis of the bias found in AI predictive models.
Admissions data spanning six years was used to create an AI model to determine
whether a given student would be directly admitted into the School of Science
under various scenarios at a large urban research university. During this time,
submission of standardized test scores as part of an application became
optional which led to interesting questions about the impact of standardized
test scores on admission decisions. We developed and analyzed AI models to
understand which variables are important in admissions decisions, and how the
decision to exclude test scores affects the demographics of the students who
are admitted. We then evaluated the predictive models to detect and analyze
biases these models may carry with respect to three variables chosen to
represent sensitive populations: gender, race, and whether a student was the
first in his or her family to attend college. We also extended our analysis to
show that the biases detected were persistent. Finally, we included several
fairness metrics in our analysis and discussed the uses and limitations of
these metrics.

摘要：偏見偵測和緩解是機器學習研究中的活躍領域。這項工作延伸了作者先前所做的研究，提供了對 AI 預測模型中發現的偏見進行嚴謹且更完整的分析。橫跨六年的入學數據被用於建立 AI 模型，以確定在大型都市研究型大學的各種情況下，特定學生是否會被直接錄取到理學院。在此期間，標準化考試成績的提交成為申請的一部分變得具有選擇性，這引發了關於標準化考試成績對錄取決定的影響的有趣問題。我們開發並分析了 AI 模型，以了解哪些變數在錄取決策中很重要，以及排除考試成績的決定如何影響被錄取學生的統計資料。然後，我們評估預測模型以偵測並分析這些模型可能對代表敏感群體的變數所帶來的偏見：性別、種族，以及學生是否為其家族中第一位就讀大學者。我們也擴展分析以顯示所偵測到的偏見是持續存在的。最後，我們在分析中納入了幾個公平性指標，並討論了這些指標的用途和限制。

##### **LLMForecaster: Improving Seasonal Event Forecasts with Unstructured Textual Data**
2412.02525v1 by Hanyu Zhang, Chuck Arvin, Dmitry Efimov, Michael W. Mahoney, Dominique Perrault-Joncas, Shankar Ramasubramanian, Andrew Gordon Wilson, Malcolm Wolff

Modern time-series forecasting models often fail to make full use of rich
unstructured information about the time series themselves. This lack of proper
conditioning can lead to obvious model failures; for example, models may be
unaware of the details of a particular product, and hence fail to anticipate
seasonal surges in customer demand in the lead up to major exogenous events
like holidays for clearly relevant products. To address this shortcoming, this
paper introduces a novel forecast post-processor -- which we call LLMForecaster
-- that fine-tunes large language models (LLMs) to incorporate unstructured
semantic and contextual information and historical data to improve the
forecasts from an existing demand forecasting pipeline. In an industry-scale
retail application, we demonstrate that our technique yields statistically
significantly forecast improvements across several sets of products subject to
holiday-driven demand surges.

摘要：現代時序預測模型通常無法充分利用時序本身豐富的非結構化資訊。這種缺乏適當的條件設定可能會導致明顯的模型失敗；例如，模型可能不知道特定產品的詳細資訊，因此無法預測在主要外生事件（例如與產品明顯相關的節日）前夕客戶需求的季節性激增。為了解決這個缺點，本文介紹了一種新穎的預測後處理器，我們稱之為 LLMForecaster，它微調大型語言模型 (LLM) 以納入非結構化語義和上下文資訊以及歷史資料，以改善現有需求預測管線的預測。在產業規模的零售應用中，我們證明了我們的技術在受節日驅動的需求激增的幾組產品中產生了統計上顯著的預測改進。

##### **FCL-ViT: Task-Aware Attention Tuning for Continual Learning**
2412.02509v1 by Anestis Kaimakamidis, Ioannis Pitas

Continual Learning (CL) involves adapting the prior Deep Neural Network (DNN)
knowledge to new tasks, without forgetting the old ones. However, modern CL
techniques focus on provisioning memory capabilities to existing DNN models
rather than designing new ones that are able to adapt according to the task at
hand. This paper presents the novel Feedback Continual Learning Vision
Transformer (FCL-ViT) that uses a feedback mechanism to generate real-time
dynamic attention features tailored to the current task. The FCL-ViT operates
in two Phases. In phase 1, the generic image features are produced and
determine where the Transformer should attend on the current image. In phase 2,
task-specific image features are generated that leverage dynamic attention. To
this end, Tunable self-Attention Blocks (TABs) and Task Specific Blocks (TSBs)
are introduced that operate in both phases and are responsible for tuning the
TABs attention, respectively. The FCL-ViT surpasses state-of-the-art
performance on Continual Learning compared to benchmark methods, while
retaining a small number of trainable DNN parameters.

摘要：持續學習 (CL) 涉及將先前的深度神經網路 (DNN) 知識適應到新任務，而不會忘記舊任務。然而，現代 CL 技術著重於為現有的 DNN 模型提供記憶能力，而不是設計能夠根據手邊任務進行調整的新模型。本文提出了一種新穎的回饋持續學習視覺Transformer (FCL-ViT)，它使用回饋機制來產生針對當前任務量身定制的即時動態注意特徵。FCL-ViT 分為兩個階段運作。在階段 1 中，產生通用影像特徵，並確定Transformer應注意當前影像的哪個部分。在階段 2 中，產生利用動態注意力的特定任務影像特徵。為此，引入了在兩個階段中運作的可調整自注意力區塊 (TAB) 和特定任務區塊 (TSB)，它們分別負責調整 TAB 注意力。與基準方法相比，FCL-ViT 在持續學習方面超越了最先進的效能，同時保留了少量的可訓練 DNN 參數。

##### **Towards Rich Emotions in 3D Avatars: A Text-to-3D Avatar Generation Benchmark**
2412.02508v1 by Haidong Xu, Meishan Zhang, Hao Ju, Zhedong Zheng, Hongyuan Zhu, Erik Cambria, Min Zhang, Hao Fei

Producing emotionally dynamic 3D facial avatars with text derived from spoken
words (Emo3D) has been a pivotal research topic in 3D avatar generation. While
progress has been made in general-purpose 3D avatar generation, the exploration
of generating emotional 3D avatars remains scarce, primarily due to the
complexities of identifying and rendering rich emotions from spoken words. This
paper reexamines Emo3D generation and draws inspiration from human processes,
breaking down Emo3D into two cascading steps: Text-to-3D Expression Mapping
(T3DEM) and 3D Avatar Rendering (3DAR). T3DEM is the most crucial step in
determining the quality of Emo3D generation and encompasses three key
challenges: Expression Diversity, Emotion-Content Consistency, and Expression
Fluidity. To address these challenges, we introduce a novel benchmark to
advance research in Emo3D generation. First, we present EmoAva, a large-scale,
high-quality dataset for T3DEM, comprising 15,000 text-to-3D expression
mappings that characterize the aforementioned three challenges in Emo3D
generation. Furthermore, we develop various metrics to effectively evaluate
models against these identified challenges. Next, to effectively model the
consistency, diversity, and fluidity of human expressions in the T3DEM step, we
propose the Continuous Text-to-Expression Generator, which employs an
autoregressive Conditional Variational Autoencoder for expression code
generation, enhanced with Latent Temporal Attention and Expression-wise
Attention mechanisms. Finally, to further enhance the 3DAR step on rendering
higher-quality subtle expressions, we present the Globally-informed Gaussian
Avatar (GiGA) model. GiGA incorporates a global information mechanism into 3D
Gaussian representations, enabling the capture of subtle micro-expressions and
seamless transitions between emotional states.

摘要：<paragraph>透過口說文字產生情緒動態 3D 人臉化身（Emo3D）一直是 3D 化身生成的關鍵研究主題。儘管在一般用途的 3D 化身生成方面已取得進展，但生成情緒化 3D 化身的探索仍然稀少，這主要是因為從口說文字中識別和呈現豐富情緒的複雜性。本文重新探討 Emo3D 生成並從人類過程中汲取靈感，將 Emo3D 分解為兩個串聯步驟：文字到 3D 表情對應（T3DEM）和 3D 化身渲染（3DAR）。T3DEM 是決定 Emo3D 生成品質的最關鍵步驟，並包含三個主要挑戰：表情多樣性、情緒內容一致性，以及表情流暢度。為了應對這些挑戰，我們引入了一個新基準來推進 Emo3D 生成的研究。首先，我們展示 EmoAva，一個適用於 T3DEM 的大型、高品質資料集，包含 15,000 個文字到 3D 表情對應，這些對應描述了 Emo3D 生成中上述三個挑戰。此外，我們開發了各種指標來針對這些已確定的挑戰有效評估模型。接下來，為了在 T3DEM 步驟中有效地模擬人類表情的一致性、多樣性和流暢度，我們提出了連續文字到表情生成器，它採用自迴歸條件變異自動編碼器來生成表情代碼，並透過潛在時間注意力和表情注意力機制進行強化。最後，為了進一步增強 3DAR 步驟以渲染更高品質的細微表情，我們提出了全球資訊高斯化身（GiGA）模型。GiGA 將全球資訊機制整合到 3D 高斯表示中，能夠捕捉細微的微表情和情緒狀態之間的無縫過渡。</paragraph>

##### **OODFace: Benchmarking Robustness of Face Recognition under Common Corruptions and Appearance Variations**
2412.02479v1 by Caixin Kang, Yubo Chen, Shouwei Ruan, Shiji Zhao, Ruochen Zhang, Jiayi Wang, Shan Fu, Xingxing Wei

With the rise of deep learning, facial recognition technology has seen
extensive research and rapid development. Although facial recognition is
considered a mature technology, we find that existing open-source models and
commercial algorithms lack robustness in certain real-world Out-of-Distribution
(OOD) scenarios, raising concerns about the reliability of these systems. In
this paper, we introduce OODFace, which explores the OOD challenges faced by
facial recognition models from two perspectives: common corruptions and
appearance variations. We systematically design 30 OOD scenarios across 9 major
categories tailored for facial recognition. By simulating these challenges on
public datasets, we establish three robustness benchmarks: LFW-C/V, CFP-FP-C/V,
and YTF-C/V. We then conduct extensive experiments on 19 different facial
recognition models and 3 commercial APIs, along with extended experiments on
face masks, Vision-Language Models (VLMs), and defense strategies to assess
their robustness. Based on the results, we draw several key insights,
highlighting the vulnerability of facial recognition systems to OOD data and
suggesting possible solutions. Additionally, we offer a unified toolkit that
includes all corruption and variation types, easily extendable to other
datasets. We hope that our benchmarks and findings can provide guidance for
future improvements in facial recognition model robustness.

摘要：隨著深度學習的興起，人臉辨識技術已見廣泛的研究和快速發展。儘管人臉辨識被認為是成熟的技術，我們發現現有的開源模型和商業演算法在某些真實世界的 Out-of-Distribution (OOD) 場景中缺乏穩健性，對這些系統的可靠性提出質疑。在本文中，我們介紹了 OODFace，它從兩個角度探討人臉辨識模型面臨的 OOD 挑戰：常見的破壞和外觀變化。我們系統性地針對人臉辨識設計了 9 個主要類別中的 30 個 OOD 場景。透過在公開資料集上模擬這些挑戰，我們建立了三個穩健性基準：LFW-C/V、CFP-FP-C/V 和 YTF-C/V。然後，我們對 19 種不同的人臉辨識模型和 3 個商業 API 進行了廣泛的實驗，並對口罩、視覺語言模型 (VLM) 和防禦策略進行了延伸實驗，以評估其穩健性。根據結果，我們得出幾個關鍵見解，強調了人臉辨識系統對 OOD 資料的脆弱性，並提出可能的解決方案。此外，我們提供了一個統一的工具包，其中包含所有破壞和變異類型，可輕鬆延伸到其他資料集。我們希望我們的基準和發現能為未來的人臉辨識模型穩健性改進提供指導。

##### **DP-2Stage: Adapting Language Models as Differentially Private Tabular Data Generators**
2412.02467v1 by Tejumade Afonja, Hui-Po Wang, Raouf Kerkouche, Mario Fritz

Generating tabular data under differential privacy (DP) protection ensures
theoretical privacy guarantees but poses challenges for training machine
learning models, primarily due to the need to capture complex structures under
noisy supervision signals. Recently, pre-trained Large Language Models (LLMs)
-- even those at the scale of GPT-2 -- have demonstrated great potential in
synthesizing tabular data. However, their applications under DP constraints
remain largely unexplored. In this work, we address this gap by applying DP
techniques to the generation of synthetic tabular data. Our findings shows that
LLMs face difficulties in generating coherent text when fine-tuned with DP, as
privacy budgets are inefficiently allocated to non-private elements like table
structures. To overcome this, we propose \ours, a two-stage fine-tuning
framework for differentially private tabular data generation. The first stage
involves non-private fine-tuning on a pseudo dataset, followed by DP
fine-tuning on a private dataset. Our empirical results show that this approach
improves performance across various settings and metrics compared to directly
fine-tuned LLMs in DP contexts. We release our code and setup at
https://github.com/tejuafonja/DP-2Stage.

摘要：在差分隐私 (DP) 保护下生成表格数据可确保理论隐私保证，但对训练机器学习模型构成了挑战，这主要是由于需要在有噪声的监督信号下捕获复杂结构。最近，预训练的大语言模型 (LLM)——即使是 GPT-2 规模的模型——已在合成表格数据方面展示出巨大潜力。然而，它们在 DP 约束下的应用在很大程度上仍未得到探索。在这项工作中，我们通过将 DP 技术应用于合成表格数据的生成来解决这一差距。我们的研究结果表明，当使用 DP 微调时，LLM 在生成连贯文本方面面临困难，因为隐私预算被低效地分配给表格结构等非私有元素。为了克服这一点，我们提出了 \ours，这是一个用于差分隐私表格数据生成的二阶段微调框架。第一阶段涉及在伪数据集上进行非私有微调，然后在私有数据集上进行 DP 微调。我们的实证结果表明，与在 DP 环境中直接微调的 LLM 相比，这种方法在各种设置和指标上都提高了性能。我们在 https://github.com/tejuafonja/DP-2Stage 上发布了我们的代码和设置。

##### **Gracefully Filtering Backdoor Samples for Generative Large Language Models without Retraining**
2412.02454v1 by Zongru Wu, Pengzhou Cheng, Lingyong Fang, Zhuosheng Zhang, Gongshen Liu

Backdoor attacks remain significant security threats to generative large
language models (LLMs). Since generative LLMs output sequences of
high-dimensional token logits instead of low-dimensional classification logits,
most existing backdoor defense methods designed for discriminative models like
BERT are ineffective for generative LLMs. Inspired by the observed differences
in learning behavior between backdoor and clean mapping in the frequency space,
we transform gradients of each training sample, directly influencing parameter
updates, into the frequency space. Our findings reveal a distinct separation
between the gradients of backdoor and clean samples in the frequency space.
Based on this phenomenon, we propose Gradient Clustering in the Frequency Space
for Backdoor Sample Filtering (GraCeFul), which leverages sample-wise gradients
in the frequency space to effectively identify backdoor samples without
requiring retraining LLMs. Experimental results show that GraCeFul outperforms
baselines significantly. Notably, GraCeFul exhibits remarkable computational
efficiency, achieving nearly 100% recall and F1 scores in identifying backdoor
samples, reducing the average success rate of various backdoor attacks to 0%
with negligible drops in clean accuracy across multiple free-style question
answering datasets. Additionally, GraCeFul generalizes to Llama-2 and Vicuna.
The codes are publicly available at https://github.com/ZrW00/GraceFul.

摘要：後門攻擊仍然是生成式大型語言模型 (LLM) 的重大安全威脅。由於生成式 LLM 輸出高維度標記 logit 的序列，而不是低維度分類 logit，因此大多數現有的後門防禦方法（例如針對 BERT 等判別模型而設計的方法）對生成式 LLM 而言是無效的。受後門和乾淨對應之間在頻率空間中學習行為的觀察差異啟發，我們將每個訓練樣本的梯度（直接影響參數更新）轉換到頻率空間。我們的研究結果揭示了後門和乾淨樣本在頻率空間中梯度之間的明顯區別。基於此現象，我們提出了頻率空間中的梯度聚類用於後門樣本過濾 (GraCeFul)，它利用頻率空間中逐樣本梯度來有效識別後門樣本，而無需重新訓練 LLM。實驗結果表明，GraCeFul 的表現顯著優於基準。值得注意的是，GraCeFul 展現出顯著的計算效率，在識別後門樣本時實現了接近 100% 的召回率和 F1 分數，將各種後門攻擊的平均成功率降低到 0%，同時在多個自由式問題解答資料集中的乾淨準確度幾乎沒有下降。此外，GraCeFul 還適用於 Llama-2 和 Vicuna。程式碼已公開發布於 https://github.com/ZrW00/GraceFul。

##### **BYE: Build Your Encoder with One Sequence of Exploration Data for Long-Term Dynamic Scene Understanding**
2412.02449v1 by Chenguang Huang, Shengchao Yan, Wolfram Burgard

Dynamic scene understanding remains a persistent challenge in robotic
applications. Early dynamic mapping methods focused on mitigating the negative
influence of short-term dynamic objects on camera motion estimation by masking
or tracking specific categories, which often fall short in adapting to
long-term scene changes. Recent efforts address object association in long-term
dynamic environments using neural networks trained on synthetic datasets, but
they still rely on predefined object shapes and categories. Other methods
incorporate visual, geometric, or semantic heuristics for the association but
often lack robustness. In this work, we introduce BYE, a class-agnostic,
per-scene point cloud encoder that removes the need for predefined categories,
shape priors, or extensive association datasets. Trained on only a single
sequence of exploration data, BYE can efficiently perform object association in
dynamically changing scenes. We further propose an ensembling scheme combining
the semantic strengths of Vision Language Models (VLMs) with the scene-specific
expertise of BYE, achieving a 7% improvement and a 95% success rate in object
association tasks. Code and dataset are available at
https://byencoder.github.io.

摘要：動態場景理解在機器人應用中仍然是一個持續的挑戰。早期動態對應方法專注於透過遮蔽或追蹤特定類別來減輕短期動態物件對相機動作估計的負面影響，而這通常無法適應長期場景變化。最近的研究使用在合成資料集上訓練的神經網路來解決長期動態環境中的物件關聯問題，但它們仍然依賴於預先定義的物件形狀和類別。其他方法將視覺、幾何或語義啟發法納入關聯中，但通常缺乏穩健性。在這項工作中，我們介紹了 BYE，一個與類別無關、針對場景的點雲編碼器，它消除了對預先定義類別、形狀先驗或廣泛關聯資料集的需求。BYE 只在單一探索資料序列上訓練，就能有效地在動態變化的場景中執行物件關聯。我們進一步提出了一個集成方案，結合了視覺語言模型 (VLM) 的語義優勢和 BYE 的場景特定專業知識，在物件關聯任務中實現了 7% 的改進和 95% 的成功率。程式碼和資料集可在 https://byencoder.github.io/ 取得。

##### **GerPS-Compare: Comparing NER methods for legal norm analysis**
2412.02427v1 by Sarah T. Bachinger, Christoph Unger, Robin Erd, Leila Feddoul, Clara Lachenmaier, Sina Zarrieß, Birgitta König-Ries

We apply NER to a particular sub-genre of legal texts in German: the genre of
legal norms regulating administrative processes in public service
administration. The analysis of such texts involves identifying stretches of
text that instantiate one of ten classes identified by public service
administration professionals. We investigate and compare three methods for
performing Named Entity Recognition (NER) to detect these classes: a Rule-based
system, deep discriminative models, and a deep generative model. Our results
show that Deep Discriminative models outperform both the Rule-based system as
well as the Deep Generative model, the latter two roughly performing equally
well, outperforming each other in different classes. The main cause for this
somewhat surprising result is arguably the fact that the classes used in the
analysis are semantically and syntactically heterogeneous, in contrast to the
classes used in more standard NER tasks. Deep Discriminative models appear to
be better equipped for dealing with this heterogenerity than both generic LLMs
and human linguists designing rule-based NER systems.

摘要：我們將 NER 應用於德語中的一個特定法律文本子類型：公務行政中規範行政程序的法律規範類型。此類文本的分析涉及識別由公務行政專業人員識別的十個類別之一的文本範圍。我們研究並比較了三種執行命名實體識別 (NER) 以檢測這些類別的方法：基於規則的系統、深度判別模型和深度生成模型。我們的結果表明，深度判別模型優於基於規則的系統和深度生成模型，後兩者表現大致相同，在不同的類別中表現優於對方。這個有點令人驚訝的結果的主要原因可能是用於分析的類別在語義和句法上是異質的，這與用於更標準的 NER 任務的類別形成對比。與設計基於規則的 NER 系統的一般 LLM 和人類語言學家相比，深度判別模型似乎更適合處理這種異質性。

##### **Knowledge-Enhanced Conversational Recommendation via Transformer-based Sequential Modelling**
2412.02415v1 by Jie Zou, Aixin Sun, Cheng Long, Evangelos Kanoulas

In conversational recommender systems (CRSs), conversations usually involve a
set of items and item-related entities or attributes, e.g., director is a
related entity of a movie. These items and item-related entities are often
mentioned along the development of a dialog, leading to potential sequential
dependencies among them. However, most of existing CRSs neglect these potential
sequential dependencies. In this article, we first propose a Transformer-based
sequential conversational recommendation method, named TSCR, to model the
sequential dependencies in the conversations to improve CRS. In TSCR, we
represent conversations by items and the item-related entities, and construct
user sequences to discover user preferences by considering both the mentioned
items and item-related entities. Based on the constructed sequences, we deploy
a Cloze task to predict the recommended items along a sequence. Meanwhile, in
certain domains, knowledge graphs formed by the items and their related
entities are readily available, which provide various different kinds of
associations among them. Given that TSCR does not benefit from such knowledge
graphs, we then propose a knowledge graph enhanced version of TSCR, called
TSCRKG. In specific, we leverage the knowledge graph to offline initialize our
model TSCRKG, and augment the user sequence of conversations (i.e., sequence of
the mentioned items and item-related entities in the conversation) with
multi-hop paths in the knowledge graph. Experimental results demonstrate that
our TSCR model significantly outperforms state-of-the-art baselines, and the
enhanced version TSCRKG further improves recommendation performance on top of
TSCR.

摘要：<paragraph>在會話式推薦系統 (CRS) 中，對話通常包含一組項目和與項目相關的實體或屬性，例如導演是電影的相關實體。這些項目和與項目相關的實體通常會在對話的發展過程中被提及，導致它們之間存在潛在的順序依賴性。然而，大多數現有的 CRS 都忽略了這些潛在的順序依賴性。在本文中，我們首先提出了一個基於 Transformer 的順序會話推薦方法，稱為 TSCR，以對話中的順序依賴性進行建模，以改進 CRS。在 TSCR 中，我們通過項目和與項目相關的實體來表示對話，並構建使用者序列，以通過考慮提到的項目和與項目相關的實體來發現使用者的偏好。根據構建的序列，我們部署一個完形填空任務來預測序列中的推薦項目。同時，在某些領域，由項目及其相關實體形成的知識圖很容易獲得，它們提供了各種不同的關聯。鑑於 TSCR 沒有從這樣的知識圖中受益，因此我們提出了 TSCR 的知識圖增強版本，稱為 TSCRKG。具體來說，我們利用知識圖離線初始化我們的模型 TSCRKG，並使用知識圖中的多跳路徑擴充對話的使用者序列（即對話中提到的項目和與項目相關的實體的序列）。實驗結果表明，我們的 TSCR 模型顯著優於最先進的基準，並且增強版本 TSCRKG 進一步改進了 TSCR 上的推薦性能。</paragraph>

##### **VISTA: A Panoramic View of Neural Representations**
2412.02412v1 by Tom White

We present VISTA (Visualization of Internal States and Their Associations), a
novel pipeline for visually exploring and interpreting neural network
representations. VISTA addresses the challenge of analyzing vast
multidimensional spaces in modern machine learning models by mapping
representations into a semantic 2D space. The resulting collages visually
reveal patterns and relationships within internal representations. We
demonstrate VISTA's utility by applying it to sparse autoencoder latents
uncovering new properties and interpretations. We review the VISTA methodology,
present findings from our case study ( https://got.drib.net/latents/ ), and
discuss implications for neural network interpretability across various domains
of machine learning.

摘要：我們提出 VISTA（內部狀態及其關聯的可視化），這是一個用於視覺化探索和詮釋神經網路表徵的新穎管道。VISTA 透過將表徵對應到語義 2D 空間，來解決分析現代機器學習模型中廣大高維空間的挑戰。產生的拼貼圖像視覺化揭露了內部表徵中的模式和關係。我們透過將 VISTA 應用到稀疏自動編碼器潛在變數，來展示其效用，進而揭示新的特性和詮釋。我們回顧 VISTA 方法論，展示我們的案例研究（ https://got.drib.net/latents/ ）的發現，並討論 VISTA 對各種機器學習領域中神經網路可解釋性的影響。

##### **A Multi-Agent Framework for Extensible Structured Text Generation in PLCs**
2412.02410v1 by Donghao Yang, Aolang Wu, Tianyi Zhang, Li Zhang, Fang Liu, Xiaoli Lian, Yuming Ren, Jiaji Tian

Programmable Logic Controllers (PLCs) are microcomputers essential for
automating factory operations. Structured Text (ST), a high-level language
adhering to the IEC 61131-3 standard, is pivotal for PLCs due to its ability to
express logic succinctly and to seamlessly integrate with other languages
within the same standard. However, vendors develop their own customized
versions of ST, and the lack of comprehensive and standardized documentation
for the full semantics of ST has contributed to inconsistencies in how the
language is implemented. Consequently, the steep learning curve associated with
ST, combined with ever-evolving industrial requirements, presents significant
challenges for developers. In response to these issues, we present AutoPLC, an
LLM-based approach designed to automate the generation of vendor-specific ST
code. To facilitate effective code generation, we first built a comprehensive
knowledge base, including Rq2ST Case Library (requirements and corresponding
implementations) and Instruction libraries. Then we developed a retrieval
module to incorporate the domain-specific knowledge by identifying pertinent
cases and instructions, guiding the LLM to generate code that meets the
requirements. In order to verify and improve the quality of the generated code,
we designed an adaptable code checker. If errors are detected, we initiate an
iterative self-improvement process to instruct the LLM to revise the generated
code. We evaluate AutoPLC's performance against seven state-of-the-art
baselines using three benchmarks, one for open-source basic ST and two for
commercial Structured Control Language (SCL) from Siemens. The results show
that our approach consistently achieves superior performance across all
benchmarks. Ablation study emphasizes the significance of our modules. Further
manual analysis confirm the practical utility of the ST code generated by
AutoPLC.

摘要：可程式邏輯控制器 (PLC) 是工廠自動化作業中不可或缺的微電腦。結構化文字 (ST) 是一種遵循 IEC 61131-3 標準的高階語言，由於其能夠簡潔地表達邏輯並與同一個標準中的其他語言無縫整合，因此對於 PLC 至關重要。然而，供應商開發了自己的自訂 ST 版本，而且缺乏全面且標準化的 ST 語意文件，導致語言實作方式不一致。因此，與 ST 相關的陡峭學習曲線，加上不斷變化的產業需求，對開發人員來說構成重大挑戰。為了回應這些問題，我們提出了 AutoPLC，這是一種基於 LLM 的方法，旨在自動產生特定供應商的 ST 程式碼。為了促進有效的程式碼產生，我們首先建立了一個全面的知識庫，包括 Rq2ST 案例程式庫（需求和對應的實作）和指令程式庫。然後，我們開發了一個擷取模組，透過識別相關的案例和指令來納入特定領域的知識，引導 LLM 產生符合需求的程式碼。為了驗證和提升所產生程式碼的品質，我們設計了一個適應性程式碼檢查器。如果偵測到錯誤，我們會啟動一個反覆的自體改善程序，指示 LLM 修改所產生的程式碼。我們使用三個基準對 AutoPLC 的效能進行評估，其中一個基準是開放原始碼的基本 ST，另外兩個基準是來自西門子的商業結構化控制語言 (SCL)。結果顯示，我們的做法在所有基準中持續達成卓越的效能。消融研究強調了我們模組的重要性。進一步的手動分析確認了 AutoPLC 所產生的 ST 程式碼的實用性。

##### **Four Guiding Principles for Modeling Causal Domain Knowledge: A Case Study on Brainstorming Approaches for Urban Blight Analysis**
2412.02400v1 by Houssam Razouk, Michael Leitner, Roman Kern

Urban blight is a problem of high interest for planning and policy making.
Researchers frequently propose theories about the relationships between urban
blight indicators, focusing on relationships reflecting causality. In this
paper, we improve on the integration of domain knowledge in the analysis of
urban blight by introducing four rules for effective modeling of causal domain
knowledge. The findings of this study reveal significant deviation from causal
modeling guidelines by investigating cognitive maps developed for urban blight
analysis. These findings provide valuable insights that will inform future work
on urban blight, ultimately enhancing our understanding of urban blight complex
interactions.

摘要：都市衰敗是一個高度引起規劃和政策制定興趣的問題。
研究人員經常提出有關都市衰敗指標間關係的理論，專注於反映因果關係的關係。在本文中，我們透過引入四條有效建模因果領域知識的規則，改善都市衰敗分析中領域知識的整合。本研究的發現揭示了透過研究為都市衰敗分析而開發的認知地圖，顯著偏離因果建模指南。這些發現提供了有價值的見解，將為未來關於都市衰敗的研究提供資訊，最終增進我們對都市衰敗複雜互動的理解。

##### **OMENN: One Matrix to Explain Neural Networks**
2412.02399v1 by Adam Wróbel, Mikołaj Janusz, Bartosz Zieliński, Dawid Rymarczyk

Deep Learning (DL) models are often black boxes, making their decision-making
processes difficult to interpret. This lack of transparency has driven
advancements in eXplainable Artificial Intelligence (XAI), a field dedicated to
clarifying the reasoning behind DL model predictions. Among these,
attribution-based methods such as LRP and GradCAM are widely used, though they
rely on approximations that can be imprecise.
  To address these limitations, we introduce One Matrix to Explain Neural
Networks (OMENN), a novel post-hoc method that represents a neural network as a
single, interpretable matrix for each specific input. This matrix is
constructed through a series of linear transformations that represent the
processing of the input by each successive layer in the neural network. As a
result, OMENN provides locally precise, attribution-based explanations of the
input across various modern models, including ViTs and CNNs. We present a
theoretical analysis of OMENN based on dynamic linearity property and validate
its effectiveness with extensive tests on two XAI benchmarks, demonstrating
that OMENN is competitive with state-of-the-art methods.

摘要：深度學習 (DL) 模型通常是黑盒子，這使得它們的決策制定過程難以解釋。這種透明度的缺乏推動了可解釋人工智慧 (XAI) 的進展，XAI 是致力於釐清 DL 模型預測背後推理的領域。其中，基於歸因的方法（例如 LRP 和 GradCAM）被廣泛使用，儘管它們依賴於可能不精確的近似。
為了解決這些限制，我們引入了 One Matrix to Explain Neural Networks (OMENN)，這是一種新穎的後設法，它將神經網路表示為針對每個特定輸入的單一可解釋矩陣。此矩陣是透過一系列線性轉換建構的，這些轉換表示神經網路中每個後續層處理輸入的方式。因此，OMENN 提供了局部精確的、基於歸因的輸入解釋，適用於各種現代模型，包括 ViT 和 CNN。我們基於動態線性屬性對 OMENN 進行了理論分析，並透過在兩個 XAI 基準上進行廣泛測試驗證了其有效性，證明了 OMENN 具有與最先進方法相媲美的競爭力。

##### **HERO: Hint-Based Efficient and Reliable Query Optimizer**
2412.02372v1 by Sergey Zinchenko, Sergey Iazov

We propose a novel model for learned query optimization which provides query
hints leading to better execution plans. The model addresses the three key
challenges in learned hint-based query optimization: reliable hint
recommendation (ensuring non-degradation of query latency), efficient hint
exploration, and fast inference. We provide an in-depth analysis of existing
NN-based approaches to hint-based optimization and experimentally confirm the
named challenges for them. Our alternative solution consists of a new inference
schema based on an ensemble of context-aware models and a graph storage for
reliable hint suggestion and fast inference, and a budget-controlled training
procedure with a local search algorithm that solves the issue of exponential
search space exploration. In experiments on standard benchmarks, our model
demonstrates optimization capability close to the best achievable with
coarse-grained hints. Controlling the degree of parallelism (query dop) in
addition to operator-related hints enables our model to achieve 3x latency
improvement on JOB benchmark which sets a new standard for optimization. Our
model is interpretable and easy to debug, which is particularly important for
deployment in production.

摘要：我們提出一個新穎的學習查詢最佳化模型，提供查詢提示，以產生更好的執行計畫。該模型解決了基於學習提示的查詢最佳化中的三大關鍵挑戰：可靠提示建議（確保查詢延遲不降低）、有效提示探索和快速推論。我們深入分析了現有的基於 NN 的提示式最佳化方法，並透過實驗驗證了它們所面對的挑戰。我們的替代方案包括一個基於情境感知模型和圖形儲存的新推論架構，用於可靠提示建議和快速推論，以及一個預算控制訓練程序，其中包含一個局部搜尋演算法，用於解決指數搜尋空間探索的問題。在標準基準測試中，我們的模型展示了接近可使用粗略提示達成的最佳最佳化能力。除了與運算子相關的提示外，控制平行度（查詢 dop）使我們的模型能夠在 JOB 基準測試中實現 3 倍的延遲改善，為最佳化設定了新的標準。我們的模型具有可解釋性和易於除錯，這對於在生產中部署特別重要。

##### **TSCheater: Generating High-Quality Tibetan Adversarial Texts via Visual Similarity**
2412.02371v1 by Xi Cao, Quzong Gesang, Yuan Sun, Nuo Qun, Tashi Nyima

Language models based on deep neural networks are vulnerable to textual
adversarial attacks. While rich-resource languages like English are receiving
focused attention, Tibetan, a cross-border language, is gradually being studied
due to its abundant ancient literature and critical language strategy.
Currently, there are several Tibetan adversarial text generation methods, but
they do not fully consider the textual features of Tibetan script and
overestimate the quality of generated adversarial texts. To address this issue,
we propose a novel Tibetan adversarial text generation method called TSCheater,
which considers the characteristic of Tibetan encoding and the feature that
visually similar syllables have similar semantics. This method can also be
transferred to other abugidas, such as Devanagari script. We utilize a
self-constructed Tibetan syllable visual similarity database called TSVSDB to
generate substitution candidates and adopt a greedy algorithm-based scoring
mechanism to determine substitution order. After that, we conduct the method on
eight victim language models. Experimentally, TSCheater outperforms existing
methods in attack effectiveness, perturbation magnitude, semantic similarity,
visual similarity, and human acceptance. Finally, we construct the first
Tibetan adversarial robustness evaluation benchmark called AdvTS, which is
generated by existing methods and proofread by humans.

摘要：基於深度神經網路的語言模型容易受到文字對抗攻擊。雖然像英語這種資源豐富的語言正受到關注，但藏語作為跨境語言，由於其豐富的古代文獻和重要的語言策略，正逐漸受到研究。目前，有幾種藏語對抗文本生成方法，但它們並未充分考慮藏文文字的特徵，並且高估了生成的對抗文本的質量。為了解決這個問題，我們提出了一種名為 TSCheater 的新型藏語對抗文本生成方法，它考慮了藏文編碼的特徵以及視覺上相似的音節具有相似的語義這一特徵。此方法也可以轉移到其他音節文字，例如天城文。我們利用一個自建的藏文音節視覺相似度資料庫 TSVSDB 來生成替換候選項，並採用基於貪婪演算法的評分機制來確定替換順序。之後，我們對八個受害語言模型執行此方法。實驗表明，TSCheater 在攻擊有效性、擾動幅度、語義相似性、視覺相似性和人類接受度方面優於現有方法。最後，我們構建了第一個藏語對抗魯棒性評估基準，稱為 AdvTS，它是由現有方法生成並由人工校對的。

##### **ScImage: How Good Are Multimodal Large Language Models at Scientific Text-to-Image Generation?**
2412.02368v1 by Leixin Zhang, Steffen Eger, Yinjie Cheng, Weihe Zhai, Jonas Belouadi, Christoph Leiter, Simone Paolo Ponzetto, Fahimeh Moafian, Zhixue Zhao

Multimodal large language models (LLMs) have demonstrated impressive
capabilities in generating high-quality images from textual instructions.
However, their performance in generating scientific images--a critical
application for accelerating scientific progress--remains underexplored. In
this work, we address this gap by introducing ScImage, a benchmark designed to
evaluate the multimodal capabilities of LLMs in generating scientific images
from textual descriptions. ScImage assesses three key dimensions of
understanding: spatial, numeric, and attribute comprehension, as well as their
combinations, focusing on the relationships between scientific objects (e.g.,
squares, circles). We evaluate five models, GPT-4o, Llama, AutomaTikZ, Dall-E,
and StableDiffusion, using two modes of output generation: code-based outputs
(Python, TikZ) and direct raster image generation. Additionally, we examine
four different input languages: English, German, Farsi, and Chinese. Our
evaluation, conducted with 11 scientists across three criteria (correctness,
relevance, and scientific accuracy), reveals that while GPT-4o produces outputs
of decent quality for simpler prompts involving individual dimensions such as
spatial, numeric, or attribute understanding in isolation, all models face
challenges in this task, especially for more complex prompts.

摘要：多模态大型语言模型 (LLM) 已展示出从文本指令生成高质量图像的强大功能。然而，它们在生成科学图像（加速科学进步的关键应用）方面的表现仍未得到充分探索。在这项工作中，我们通过引入 ScImage 来解决这一差距，ScImage 是一个基准，旨在评估 LLM 在根据文本描述生成科学图像方面多模态能力。ScImage 评估了理解的三个关键维度：空间、数字和属性理解，以及它们的组合，重点关注科学对象（例如，正方形、圆形）之间的关系。我们使用两种输出生成模式评估了五个模型，GPT-4o、Llama、AutomaTikZ、Dall-E 和 StableDiffusion：基于代码的输出（Python、TikZ）和直接光栅图像生成。此外，我们还研究了四种不同的输入语言：英语、德语、波斯语和中文。我们的评估由 11 位科学家根据三个标准（正确性、相关性和科学准确性）进行，结果表明，虽然 GPT-4o 为涉及单个维度（例如空间、数字或属性理解）的简单提示生成了质量不错的输出，但所有模型在这一任务中都面临挑战，尤其是对于更复杂的提示。

##### **Multi-Granularity Tibetan Textual Adversarial Attack Method Based on Masked Language Model**
2412.02343v1 by Xi Cao, Nuo Qun, Quzong Gesang, Yulei Zhu, Trashi Nyima

In social media, neural network models have been applied to hate speech
detection, sentiment analysis, etc., but neural network models are susceptible
to adversarial attacks. For instance, in a text classification task, the
attacker elaborately introduces perturbations to the original texts that hardly
alter the original semantics in order to trick the model into making different
predictions. By studying textual adversarial attack methods, the robustness of
language models can be evaluated and then improved. Currently, most of the
research in this field focuses on English, and there is also a certain amount
of research on Chinese. However, there is little research targeting Chinese
minority languages. With the rapid development of artificial intelligence
technology and the emergence of Chinese minority language models, textual
adversarial attacks become a new challenge for the information processing of
Chinese minority languages. In response to this situation, we propose a
multi-granularity Tibetan textual adversarial attack method based on masked
language models called TSTricker. We utilize the masked language models to
generate candidate substitution syllables or words, adopt the scoring mechanism
to determine the substitution order, and then conduct the attack method on
several fine-tuned victim models. The experimental results show that TSTricker
reduces the accuracy of the classification models by more than 28.70% and makes
the classification models change the predictions of more than 90.60% of the
samples, which has an evidently higher attack effect than the baseline method.

摘要：在社交媒體中，神經網路模型已被應用於仇恨言論偵測、情緒分析等，但神經網路模型容易受到對抗攻擊。例如，在文本分類任務中，攻擊者精心對原始文本進行擾動，幾乎不會改變原始語義，以誘使模型做出不同的預測。通過研究文本對抗攻擊方法，可以評估語言模型的魯棒性，然後進行改進。目前，該領域的大部分研究都集中在英語上，並且對中文也有一定的研究。然而，針對中文少數民族語言的研究很少。隨著人工智能技術的快速發展和中文少數民族語言模型的出現，文本對抗攻擊成為中文少數民族語言信息處理的新挑戰。針對這一情況，我們提出了一種基於遮蔽語言模型的多粒度藏文文本對抗攻擊方法，稱為 TSTricker。我們利用遮蔽語言模型生成候選替換音節或詞彙，採用評分機制確定替換順序，然後對幾個微調後的受害者模型進行攻擊方法。實驗結果表明，TSTricker 將分類模型的準確率降低了 28.70% 以上，並使分類模型改變了 90.60% 以上樣本的預測，其攻擊效果顯著高於基準方法。

##### **Reinforcement learning to learn quantum states for Heisenberg scaling accuracy**
2412.02334v1 by Jeongwoo Jae, Jeonghoon Hong, Jinho Choo, Yeong-Dae Kwon

Learning quantum states is a crucial task for realizing the potential of
quantum information technology. Recently, neural approaches have emerged as
promising methods for learning quantum states. We propose a meta-learning model
that employs reinforcement learning (RL) to optimize the process of learning
quantum states. For learning quantum states, our scheme trains a Hardware
efficient ansatz with a blackbox optimization algorithm, called evolution
strategy (ES). To enhance the efficiency of ES, a RL agent dynamically adjusts
the hyperparameters of ES. To facilitate the RL training, we introduce an
action repetition strategy inspired by curriculum learning. The RL agent
significantly improves the sample efficiency of learning random quantum states,
and achieves infidelity scaling close to the Heisenberg limit. We showcase that
the RL agent trained using 3-qubit states can be generalized to learning up to
5-qubit states. These results highlight the utility of RL-driven meta-learning
to enhance the efficiency and generalizability of learning quantum states. Our
approach can be applicable to improve quantum control, quantum optimization,
and quantum machine learning.

摘要：學習量子態對於實現量子資訊技術的潛力至關重要。最近，神經網路方法已成為學習量子態的有前途方法。我們提出了一個元學習模型，它採用強化學習 (RL) 來優化學習量子態的過程。對於學習量子態，我們的方案使用一個黑盒最佳化演算法，稱為演化策略 (ES)，來訓練一個硬體有效率的 ansatz。為了提高 ES 的效率，RL 代理會動態調整 ES 的超參數。為了促進 RL 訓練，我們引入了一個受課程學習啟發的動作重複策略。RL 代理顯著地提高了學習隨機量子態的樣本效率，並且實現了接近海森堡極限的不忠實度縮放。我們展示了使用 3 個量子位元態訓練的 RL 代理可以推廣到學習多達 5 個量子位元態。這些結果突顯了 RL 驅動的元學習在提高學習量子態的效率和泛化性方面的效用。我們的做法可以應用於改進量子控制、量子最佳化和量子機器學習。

##### **Sample Efficient Robot Learning in Supervised Effect Prediction Tasks**
2412.02331v1 by Mehmet Arda Eren, Erhan Oztop

In self-supervised robot learning, robots actively explore their environments
and generate data by acting on entities in the environment. Therefore, an
exploration policy is desired that ensures sample efficiency to minimize robot
execution costs while still providing accurate learning. For this purpose, the
robotic community has adopted Intrinsic Motivation (IM)-based approaches such
as Learning Progress (LP). On the machine learning front, Active Learning (AL)
has been used successfully, especially for classification tasks. In this work,
we develop a novel AL framework geared towards robotics regression tasks, such
as action-effect prediction and, more generally, for world model learning,
which we call MUSEL - Model Uncertainty for Sample Efficient Learning. MUSEL
aims to extract model uncertainty from the total uncertainty estimate given by
a suitable learning engine by making use of earning progress and input
diversity and use it to improve sample efficiency beyond the state-of-the-art
action-effect prediction methods. We demonstrate the feasibility of our model
by using a Stochastic Variational Gaussian Process (SVGP) as the learning
engine and testing the system on a set of robotic experiments in simulation.
The efficacy of MUSEL is demonstrated by comparing its performance to standard
methods used in robot action-effect learning. In a robotic tabletop environment
in which a robot manipulator is tasked with learning the effect of its actions,
the experiments show that MUSEL facilitates higher accuracy in learning action
effects while ensuring sample efficiency.

摘要：在自監督機器人學習中，機器人主動探索其環境，並通過對環境中的實體採取行動來生成資料。因此，需要一個探索政策來確保取樣效率，以最小化機器人執行成本，同時仍然提供準確的學習。為此，機器人社群採用了基於內在動機 (IM) 的方法，例如學習進度 (LP)。在機器學習方面，主動學習 (AL) 已成功使用，特別是對於分類任務。在這項工作中，我們開發了一個新穎的 AL 框架，針對機器人迴歸任務，例如動作效果預測，更一般來說，針對世界模型學習，我們稱之為 MUSEL - 模型不確定性，用於取樣高效學習。MUSEL 旨在透過利用學習進度和輸入多樣性，從適當學習引擎提供的總不確定性估計中提取模型不確定性，並用它來改善取樣效率，超越最先進的動作效果預測方法。我們使用隨機變異高斯過程 (SVGP) 作為學習引擎，並在模擬中的一組機器人實驗上測試系統，證明了我們模型的可行性。MUSEL 的功效透過將其效能與機器人動作效果學習中使用的標準方法進行比較來證明。在機器人桌面環境中，機器人操作器被指派學習其動作的效果，實驗表明 MUSEL 在學習動作效果時促進了更高的準確性，同時確保了取樣效率。

##### **Pay Attention to the Robustness of Chinese Minority Language Models! Syllable-level Textual Adversarial Attack on Tibetan Script**
2412.02323v1 by Xi Cao, Dolma Dawa, Nuo Qun, Trashi Nyima

The textual adversarial attack refers to an attack method in which the
attacker adds imperceptible perturbations to the original texts by elaborate
design so that the NLP (natural language processing) model produces false
judgments. This method is also used to evaluate the robustness of NLP models.
Currently, most of the research in this field focuses on English, and there is
also a certain amount of research on Chinese. However, to the best of our
knowledge, there is little research targeting Chinese minority languages.
Textual adversarial attacks are a new challenge for the information processing
of Chinese minority languages. In response to this situation, we propose a
Tibetan syllable-level black-box textual adversarial attack called TSAttacker
based on syllable cosine distance and scoring mechanism. And then, we conduct
TSAttacker on six models generated by fine-tuning two PLMs (pre-trained
language models) for three downstream tasks. The experiment results show that
TSAttacker is effective and generates high-quality adversarial samples. In
addition, the robustness of the involved models still has much room for
improvement.

摘要：文本对抗攻擊是指攻擊者通過精心設計向原始文本中添加難以察覺的擾動，從而使 NLP（自然語言處理）模型產生錯誤判斷的攻擊方法。此方法也用於評估 NLP 模型的魯棒性。目前，該領域的大多數研究都集中在英語上，並且還有一些關於中文的研究。然而，據我們所知，針對中國少數民族語言的研究很少。文本對抗攻擊對中國少數民族語言的信息處理提出了新的挑戰。針對這一情況，我們提出了一種基於音節餘弦距離和評分機制的藏語音節級別黑盒文本對抗攻擊，稱為 TSAttacker。然後，我們對通過微調兩個 PLM（預訓練語言模型）為三個下游任務生成的六個模型進行了 TSAttacker。實驗結果表明，TSAttacker 是有效的，並且生成了高質量的對抗樣本。此外，所涉及模型的魯棒性仍有很大的改進空間。

##### **Enhanced Photovoltaic Power Forecasting: An iTransformer and LSTM-Based Model Integrating Temporal and Covariate Interactions**
2412.02302v1 by Guang Wu, Yun Wang, Qian Zhou, Ziyang Zhang

Accurate photovoltaic (PV) power forecasting is critical for integrating
renewable energy sources into the grid, optimizing real-time energy management,
and ensuring energy reliability amidst increasing demand. However, existing
models often struggle with effectively capturing the complex relationships
between target variables and covariates, as well as the interactions between
temporal dynamics and multivariate data, leading to suboptimal forecasting
accuracy. To address these challenges, we propose a novel model architecture
that leverages the iTransformer for feature extraction from target variables
and employs long short-term memory (LSTM) to extract features from covariates.
A cross-attention mechanism is integrated to fuse the outputs of both models,
followed by a Kolmogorov-Arnold network (KAN) mapping for enhanced
representation. The effectiveness of the proposed model is validated using
publicly available datasets from Australia, with experiments conducted across
four seasons. Results demonstrate that the proposed model effectively capture
seasonal variations in PV power generation and improve forecasting accuracy.

摘要：精準的光電 (PV) 電力預測對於將再生能源整合到電網、最佳化即時能源管理，以及在需求增加的情況下確保能源可靠性至關重要。然而，現有的模型通常難以有效捕捉目標變數和協變數之間的複雜關係，以及時間動態和多變量資料之間的交互作用，導致次佳的預測準確度。為了應對這些挑戰，我們提出了一種新穎的模型架構，該架構利用 iTransformer 從目標變數中提取特徵，並採用長短期記憶 (LSTM) 從協變數中提取特徵。整合了一個交叉注意機制來融合兩個模型的輸出，然後進行 Kolmogorov-Arnold 網路 (KAN) 對應以增強表示。所提出的模型的有效性使用來自澳洲的公開可用資料集進行驗證，並在四季進行實驗。結果表明，所提出的模型有效地捕捉了光電電力產生的季節變化，並提高了預測準確度。

##### **Large Multimodal Agents for Accurate Phishing Detection with Enhanced Token Optimization and Cost Reduction**
2412.02301v1 by Fouad Trad, Ali Chehab

With the rise of sophisticated phishing attacks, there is a growing need for
effective and economical detection solutions. This paper explores the use of
large multimodal agents, specifically Gemini 1.5 Flash and GPT-4o mini, to
analyze both URLs and webpage screenshots via APIs, thus avoiding the
complexities of training and maintaining AI systems. Our findings indicate that
integrating these two data types substantially enhances detection performance
over using either type alone. However, API usage incurs costs per query that
depend on the number of input and output tokens. To address this, we propose a
two-tiered agentic approach: initially, one agent assesses the URL, and if
inconclusive, a second agent evaluates both the URL and the screenshot. This
method not only maintains robust detection performance but also significantly
reduces API costs by minimizing unnecessary multi-input queries. Cost analysis
shows that with the agentic approach, GPT-4o mini can process about 4.2 times
as many websites per $100 compared to the multimodal approach (107,440 vs.
25,626), and Gemini 1.5 Flash can process about 2.6 times more websites
(2,232,142 vs. 862,068). These findings underscore the significant economic
benefits of the agentic approach over the multimodal method, providing a viable
solution for organizations aiming to leverage advanced AI for phishing
detection while controlling expenses.

摘要：隨著網路釣魚攻擊手法日益精進，對於有效且經濟的偵測解決方案的需求也與日俱增。本論文探討使用大型多模態代理，特別是 Gemini 1.5 Flash 和 GPT-4o mini，透過 API 分析網址和網頁截圖，從而避免訓練和維護 AI 系統的複雜性。我們的研究結果顯示，整合這兩種資料類型可大幅提升偵測效能，優於僅使用單一類型。然而，API 使用會產生每次查詢的成本，取決於輸入和輸出符號的數量。為了解決這個問題，我們提出一個兩層代理方法：最初，一個代理評估網址，如果結果不確定，第二個代理會評估網址和截圖。此方法不僅維持穩健的偵測效能，也透過將不必要的輸入多重查詢降至最低，大幅降低 API 成本。成本分析顯示，使用代理方法，GPT-4o mini 每 100 美元可處理約 4.2 倍的網站，相較於多模態方法（107,440 對 25,626）；而 Gemini 1.5 Flash 可處理約 2.6 倍的網站（2,232,142 對 862,068）。這些發現凸顯了代理方法相較於多模態方法的顯著經濟效益，為組織提供了一個可行的解決方案，讓他們能夠在控制支出的同時，利用先進的 AI 進行網路釣魚偵測。

##### **Deep Matrix Factorization with Adaptive Weights for Multi-View Clustering**
2412.02292v1 by Yasser Khalafaoui, Basarab Matei, Martino Lovisetto, Nistor Grozavu

Recently, deep matrix factorization has been established as a powerful model
for unsupervised tasks, achieving promising results, especially for multi-view
clustering. However, existing methods often lack effective feature selection
mechanisms and rely on empirical hyperparameter selection. To address these
issues, we introduce a novel Deep Matrix Factorization with Adaptive Weights
for Multi-View Clustering (DMFAW). Our method simultaneously incorporates
feature selection and generates local partitions, enhancing clustering results.
Notably, the features weights are controlled and adjusted by a parameter that
is dynamically updated using Control Theory inspired mechanism, which not only
improves the model's stability and adaptability to diverse datasets but also
accelerates convergence. A late fusion approach is then proposed to align the
weighted local partitions with the consensus partition. Finally, the
optimization problem is solved via an alternating optimization algorithm with
theoretically guaranteed convergence. Extensive experiments on benchmark
datasets highlight that DMFAW outperforms state-of-the-art methods in terms of
clustering performance.

摘要：最近，深度矩阵分解已被确立为无监督任务的强大模型，在多视图聚类方面取得了有希望的结果。然而，现有方法通常缺乏有效的特征选择机制，并依赖于经验超参数选择。为了解决这些问题，我们引入了一种用于多视图聚类的新型自适应权重深度矩阵分解（DMFAW）。我们的方法同时结合了特征选择并生成了局部分区，从而增强了聚类结果。值得注意的是，特征权重由一个参数控制和调整，该参数使用受控制理论启发的机制动态更新，这不仅提高了模型对不同数据集的稳定性和适应性，而且还加速了收敛。然后提出了一种后期融合方法，以将加权局部分区与共识分区对齐。最后，通过交替优化算法解决了优化问题，该算法具有理论保证的收敛性。基准数据集上的大量实验表明，DMFAW 在聚类性能方面优于最先进的方法。

##### **Conformal Symplectic Optimization for Stable Reinforcement Learning**
2412.02291v1 by Yao Lyu, Xiangteng Zhang, Shengbo Eben Li, Jingliang Duan, Letian Tao, Qing Xu, Lei He, Keqiang Li

Training deep reinforcement learning (RL) agents necessitates overcoming the
highly unstable nonconvex stochastic optimization inherent in the
trial-and-error mechanism. To tackle this challenge, we propose a
physics-inspired optimization algorithm called relativistic adaptive gradient
descent (RAD), which enhances long-term training stability. By conceptualizing
neural network (NN) training as the evolution of a conformal Hamiltonian
system, we present a universal framework for transferring long-term stability
from conformal symplectic integrators to iterative NN updating rules, where the
choice of kinetic energy governs the dynamical properties of resulting
optimization algorithms. By utilizing relativistic kinetic energy, RAD
incorporates principles from special relativity and limits parameter updates
below a finite speed, effectively mitigating abnormal gradient influences.
Additionally, RAD models NN optimization as the evolution of a multi-particle
system where each trainable parameter acts as an independent particle with an
individual adaptive learning rate. We prove RAD's sublinear convergence under
general nonconvex settings, where smaller gradient variance and larger batch
sizes contribute to tighter convergence. Notably, RAD degrades to the
well-known adaptive moment estimation (ADAM) algorithm when its speed
coefficient is chosen as one and symplectic factor as a small positive value.
Experimental results show RAD outperforming nine baseline optimizers with five
RL algorithms across twelve environments, including standard benchmarks and
challenging scenarios. Notably, RAD achieves up to a 155.1% performance
improvement over ADAM in Atari games, showcasing its efficacy in stabilizing
and accelerating RL training.

摘要：<paragraph>訓練深度強化學習 (RL) 代理需要克服試錯機制中高度不穩定的非凸隨機最佳化。為了應對這個挑戰，我們提出了一種受物理啟發的最佳化演算法，稱為相對論適應梯度下降 (RAD)，它增強了長期訓練的穩定性。透過將神經網路 (NN) 訓練概念化為共形哈密頓系統的演化，我們提出了一個通用框架，用於將共形辛積分器的長期穩定性轉移到反覆 NN 更新規則，其中動能的選擇支配了所產生最佳化演算法的動態特性。透過利用相對論動能，RAD 納入了狹義相對論的原理，並將參數更新限制在有限速度以下，有效地減輕異常梯度影響。此外，RAD 將 NN 最佳化建模為多粒子系統的演化，其中每個可訓練參數都作為一個獨立粒子，具有單獨的適應性學習率。我們證明了 RAD 在一般非凸設定下的次線性收斂，其中較小的梯度變異和較大的批次大小有助於更緊密的收斂。值得注意的是，當 RAD 的速度係數選擇為 1，辛因子選擇為一個小的正值時，RAD 會退化為眾所周知的適應性矩估計 (ADAM) 演算法。實驗結果表明，RAD 在十二個環境中使用五種 RL 演算法，優於九種基線最佳化器，包括標準基準和具挑戰性的場景。值得注意的是，RAD 在 Atari 遊戲中比 ADAM 提升了高達 155.1% 的效能，展示了其在穩定和加速 RL 訓練方面的效力。</paragraph>

##### **Characterizing Information Shared by Participants to Coding Challenges: The Case of Advent of Code**
2412.02290v1 by Francesco Cauteruccio, Enrico Corradini, Luca Virgili

Advent of Code (AoC from now on) is a popular coding challenge requiring to
solve programming puzzles for a variety of skill sets and levels. AoC follows
the advent calendar, therefore it is an annual challenge that lasts for 25
days. AoC participants usually post their solutions on social networks and
discuss them online. These challenges are interesting to study since they could
highlight the adoption of new tools, the evolution of the developer community,
or the technological requirements of well-known companies. For these reasons,
we first create a dataset of the 2019-2021 AoC editions containing the
discussion threads made on the subreddit {\tt /r/adventofcode}. Then, we
propose a model based on stream graphs to best study this context, where we
represent its most important actors through time: participants, comments, and
programming languages. Thanks to our model, we investigate user participation,
adoption of new programming languages during a challenge and between two of
them, and resiliency of programming languages based on a Stack Overflow survey.
We find that the top-used programming languages are almost the same in the
three years, pointing out their importance. Moreover, participants tend to keep
the same programming language for the whole challenge, while the ones attending
two AoCs usually change it in the next one. Finally, we observe interesting
results about the programming languages that are ``Popular'' or ``Loved''
according to the Stack Overflow survey. Firstly, these are the ones adopted for
the longest time in an AoC edition, thanks to which users have a high chance of
reaching the end of the challenge. Secondly, they are the most chosen when a
participant decides to change programming language during the same challenge.

摘要：降臨節密碼（以下簡稱 AoC）是一項流行的編碼挑戰，需要解決各種技能組和等級的程式設計謎題。AoC 遵循降臨曆，因此是一項為期 25 天的年度挑戰。AoC 參與者通常在社群網路上發布他們的解決方案，並在網路上討論它們。這些挑戰很有趣，因為它們可以突顯新工具的採用、開發人員社群的演進，或知名公司的技術需求。基於這些原因，我們首先建立一個包含在 subreddit {\tt /r/adventofcode} 上進行討論串的 2019-2021 年 AoC 版本資料集。然後，我們提出一個基於串流圖的模型來最佳研究此背景，其中我們隨著時間呈現其最重要的參與者：參與者、留言和程式語言。透過我們的模型，我們調查使用者參與度、在挑戰期間和兩者之間採用新程式語言的情況，以及根據 Stack Overflow 調查對程式語言的復原力。我們發現三年來最常用的程式語言幾乎相同，指出了它們的重要性。此外，參與者傾向於在整個挑戰中使用相同的程式語言，而參加兩個 AoC 的參與者通常會在下一場比賽中更換程式語言。最後，我們觀察到關於根據 Stack Overflow 調查被歸類為「熱門」或「喜愛」的程式語言的一些有趣結果。首先，這些程式語言是 AoC 版本中採用最久的程式語言，因此使用者有很高的機會完成挑戰。其次，當參與者決定在同一個挑戰中更改程式語言時，它們是最常被選用的程式語言。

##### **GQWformer: A Quantum-based Transformer for Graph Representation Learning**
2412.02285v1 by Lei Yu, Hongyang Chen, Jingsong Lv, Linyao Yang

Graph Transformers (GTs) have demonstrated significant advantages in graph
representation learning through their global attention mechanisms. However, the
self-attention mechanism in GTs tends to neglect the inductive biases inherent
in graph structures, making it chanllenging to effectively capture essential
structural information. To address this issue, we propose a novel approach that
integrate graph inductive bias into self-attention mechanisms by leveraging
quantum technology for structural encoding. In this paper, we introduce the
Graph Quantum Walk Transformer (GQWformer), a groundbreaking GNN framework that
utilizes quantum walks on attributed graphs to generate node quantum states.
These quantum states encapsulate rich structural attributes and serve as
inductive biases for the transformer, thereby enabling the generation of more
meaningful attention scores. By subsequently incorporating a recurrent neural
network, our design amplifies the model's ability to focus on both local and
global information. We conducted comprehensive experiments across five publicly
available datasets to evaluate the effectiveness of our model. These results
clearly indicate that GQWformer outperforms existing state-of-the-art graph
classification algorithms. These findings highlight the significant potential
of integrating quantum computing methodologies with traditional GNNs to advance
the field of graph representation learning, providing a promising direction for
future research and applications.

摘要：圖形Transformer (GT) 已透過其全球注意力機制證明了在圖形表示學習中的顯著優勢。然而，GT 中的自我注意力機制傾向於忽略圖形結構中固有的歸納偏差，這使得有效擷取必要的結構資訊變得具有挑戰性。為了解決這個問題，我們提出了一種新方法，透過利用量子技術進行結構編碼，將圖形歸納偏差整合到自我注意力機制中。在本文中，我們介紹了圖形量子漫步Transformer (GQWformer)，這是一個突破性的 GNN 框架，它利用帶屬性圖形上的量子漫步來產生節點量子態。這些量子態包含豐富的結構屬性，並作為Transformer的歸納偏差，從而能夠產生更有意義的注意力分數。透過後續整合遞迴神經網路，我們的設計擴大了模型關注局部和全局資訊的能力。我們在五個公開可用的資料集上進行了全面的實驗，以評估我們模型的有效性。這些結果清楚地表明，GQWformer 優於現有的最先進圖形分類演算法。這些發現突顯了將量子運算方法與傳統 GNN 整合以推動圖形表示學習領域的巨大潛力，為未來的研究和應用提供了有希望的方向。

##### **AH-OCDA: Amplitude-based Curriculum Learning and Hopfield Segmentation Model for Open Compound Domain Adaptation**
2412.02280v1 by Jaehyun Choi, Junwon Ko, Dong-Jae Lee, Junmo Kim

Open compound domain adaptation (OCDA) is a practical domain adaptation
problem that consists of a source domain, target compound domain, and unseen
open domain. In this problem, the absence of domain labels and pixel-level
segmentation labels for both compound and open domains poses challenges to the
direct application of existing domain adaptation and generalization methods. To
address this issue, we propose Amplitude-based curriculum learning and a
Hopfield segmentation model for Open Compound Domain Adaptation (AH-OCDA). Our
method comprises two complementary components: 1) amplitude-based curriculum
learning and 2) Hopfield segmentation model. Without prior knowledge of target
domains within the compound domains, amplitude-based curriculum learning
gradually induces the semantic segmentation model to adapt from the near-source
compound domain to the far-source compound domain by ranking unlabeled compound
domain images through Fast Fourier Transform (FFT). Additionally, the Hopfield
segmentation model maps segmentation feature distributions from arbitrary
domains to the feature distributions of the source domain. AH-OCDA achieves
state-of-the-art performance on two OCDA benchmarks and extended open domains,
demonstrating its adaptability to continuously changing compound domains and
unseen open domains.

摘要：開放複合領域適應 (OCDA) 是一個實用的領域適應問題，包含一個來源領域、目標複合領域和未見開放領域。在這個問題中，複合和開放領域都缺乏領域標籤和像素級分割標籤，這對現有領域適應和泛化方法的直接應用構成挑戰。為了解決這個問題，我們提出基於振幅的課程學習和霍普菲爾德分割模型，用於開放複合領域適應 (AH-OCDA)。我們的模型包含兩個互補的組成部分：1) 基於振幅的課程學習和 2) 霍普菲爾德分割模型。在沒有複合領域中目標領域的先驗知識下，基於振幅的課程學習逐漸引導語意分割模型通過快速傅立葉轉換 (FFT) 對未標記複合領域影像進行排名，從近來源複合領域適應到遠來源複合領域。此外，霍普菲爾德分割模型將任意領域的分割特徵分佈映射到來源領域的特徵分佈。AH-OCDA 在兩個 OCDA 基準和擴展開放領域上實現了最先進的效能，證明了其適應不斷變化的複合領域和未見開放領域的能力。

##### **A Comprehensive Evaluation of Large Language Models on Aspect-Based Sentiment Analysis**
2412.02279v1 by Changzhi Zhou, Dandan Song, Yuhang Tian, Zhijing Wu, Hao Wang, Xinyu Zhang, Jun Yang, Ziyi Yang, Shuhao Zhang

Recently, Large Language Models (LLMs) have garnered increasing attention in
the field of natural language processing, revolutionizing numerous downstream
tasks with powerful reasoning and generation abilities. For example, In-Context
Learning (ICL) introduces a fine-tuning-free paradigm, allowing out-of-the-box
LLMs to execute downstream tasks by analogy learning without any fine-tuning.
Besides, in a fine-tuning-dependent paradigm where substantial training data
exists, Parameter-Efficient Fine-Tuning (PEFT), as the cost-effective methods,
enable LLMs to achieve excellent performance comparable to full fine-tuning.
  However, these fascinating techniques employed by LLMs have not been fully
exploited in the ABSA field. Previous works probe LLMs in ABSA by merely using
randomly selected input-output pairs as demonstrations in ICL, resulting in an
incomplete and superficial evaluation. In this paper, we shed light on a
comprehensive evaluation of LLMs in the ABSA field, involving 13 datasets, 8
ABSA subtasks, and 6 LLMs. Specifically, we design a unified task formulation
to unify ``multiple LLMs for multiple ABSA subtasks in multiple paradigms.''
For the fine-tuning-dependent paradigm, we efficiently fine-tune LLMs using
instruction-based multi-task learning. For the fine-tuning-free paradigm, we
propose 3 demonstration selection strategies to stimulate the few-shot
abilities of LLMs. Our extensive experiments demonstrate that LLMs achieve a
new state-of-the-art performance compared to fine-tuned Small Language Models
(SLMs) in the fine-tuning-dependent paradigm. More importantly, in the
fine-tuning-free paradigm where SLMs are ineffective, LLMs with ICL still
showcase impressive potential and even compete with fine-tuned SLMs on some
ABSA subtasks.

摘要：<paragraph>最近，大型语言模型 (LLM) 在自然语言处理领域备受关注，其强大的推理和生成能力彻底改变了众多下游任务。例如，语境学习 (ICL) 引入了一种无微调范例，允许开箱即用的 LLM 通过类比学习执行下游任务，而无需任何微调。此外，在存在大量训练数据的微调相关范例中，作为一种经济高效的方法，参数高效微调 (PEFT) 使 LLM 能够实现与完全微调相当的出色性能。
然而，LLM 所采用的这些引人入胜的技术尚未在 ABSA 领域得到充分利用。先前的研究通过在 ICL 中仅使用随机选择的输入输出对作为演示来探究 ABSA 中的 LLM，从而导致评估不完整且肤浅。在本文中，我们重点对 ABSA 领域中的 LLM 进行了全面评估，涉及 13 个数据集、8 个 ABSA 子任务和 6 个 LLM。具体来说，我们设计了一个统一的任务公式，以统一“多个范例中的多个 ABSA 子任务的多个 LLM”。对于微调相关范例，我们使用基于指令的多任务学习有效地微调 LLM。对于无微调范例，我们提出了 3 种演示选择策略来激发 LLM 的小样本能力。我们的广泛实验表明，与微调相关范例中的微调小型语言模型 (SLM) 相比，LLM 实现了新的最先进性能。更重要的是，在 SLM 无效的无微调范例中，带有 ICL 的 LLM 仍然展示出令人印象深刻的潜力，甚至在某些 ABSA 子任务上与微调的 SLM 竞争。</paragraph>

##### **MediaSpin: Exploring Media Bias Through Fine-Grained Analysis of News Headlines**
2412.02271v1 by Preetika Verma, Kokil Jaidka

In this paper, we introduce the MediaSpin dataset aiming to help in the
development of models that can detect different forms of media bias present in
news headlines, developed through human-supervised and -validated Large
Language Model (LLM) labeling of media bias. This corpus comprises 78,910 pairs
of news headlines and annotations with explanations of the 13 distinct types of
media bias categories assigned. We demonstrate the usefulness of our dataset
for automated bias detection in news edits.

摘要：在本文中，我們介紹 MediaSpin 資料集，旨在協助開發模型，以偵測新聞標題中存在的不同形式媒體偏見，此資料集是透過人工監督和驗證的大型語言模型 (LLM) 標記媒體偏見而開發。這個語料庫包含 78,910 對新聞標題和註解，並說明了 13 種類型的媒體偏見類別。我們展示了我們的資料集在新聞編輯中自動偏見偵測的效用。

##### **Sustainable Self-evolution Adversarial Training**
2412.02270v1 by Wenxuan Wang, Chenglei Wang, Huihui Qi, Menghao Ye, Xuelin Qian, Peng Wang, Yanning Zhang

With the wide application of deep neural network models in various computer
vision tasks, there has been a proliferation of adversarial example generation
strategies aimed at deeply exploring model security. However, existing
adversarial training defense models, which rely on single or limited types of
attacks under a one-time learning process, struggle to adapt to the dynamic and
evolving nature of attack methods. Therefore, to achieve defense performance
improvements for models in long-term applications, we propose a novel
Sustainable Self-Evolution Adversarial Training (SSEAT) framework.
Specifically, we introduce a continual adversarial defense pipeline to realize
learning from various kinds of adversarial examples across multiple stages.
Additionally, to address the issue of model catastrophic forgetting caused by
continual learning from ongoing novel attacks, we propose an adversarial data
replay module to better select more diverse and key relearning data.
Furthermore, we design a consistency regularization strategy to encourage
current defense models to learn more from previously trained ones, guiding them
to retain more past knowledge and maintain accuracy on clean samples. Extensive
experiments have been conducted to verify the efficacy of the proposed SSEAT
defense method, which demonstrates superior defense performance and
classification accuracy compared to competitors.

摘要：隨著深度神經網路模型在各種電腦視覺任務中的廣泛應用，對抗範例產生策略大量增生，旨在深入探索模型安全性。然而，現有的對抗訓練防禦模型依賴於一次性學習過程中單一或有限類型的攻擊，難以適應攻擊方法的動態和演化特性。因此，為了在長期應用中實現模型的防禦性能改進，我們提出了一個新穎的可持續自我演化對抗訓練 (SSEAT) 框架。具體來說，我們引入了一個持續的對抗防禦管道，以實現從多個階段的各種對抗範例中進行學習。此外，為了解決持續學習持續的新攻擊導致的模型災難性遺忘問題，我們提出了一個對抗數據重放模組，以更好地選擇更多樣化和關鍵的重新學習數據。此外，我們設計了一種一致性正則化策略，以鼓勵當前的防禦模型更多地從先前訓練的模型中學習，指導它們保留更多過去的知識並在乾淨樣本上保持準確性。已經進行了廣泛的實驗來驗證所提出的 SSEAT 防禦方法的功效，與競爭對手相比，它展示了卓越的防禦性能和分類準確性。

##### **Connecting Large Language Models with Blockchain: Advancing the Evolution of Smart Contracts from Automation to Intelligence**
2412.02263v1 by Youquan Xian, Xueying Zeng, Duancheng Xuan, Danping Yang, Chunpei Li, Peng Fan, Peng Liu

Blockchain smart contracts have catalyzed the development of decentralized
applications across various domains, including decentralized finance. However,
due to constraints in computational resources and the prevalence of data silos,
current smart contracts face significant challenges in fully leveraging the
powerful capabilities of Large Language Models (LLMs) for tasks such as
intelligent analysis and reasoning. To address this gap, this paper proposes
and implements a universal framework for integrating LLMs with blockchain data,
{\sysname}, effectively overcoming the interoperability barriers between
blockchain and LLMs. By combining semantic relatedness with truth discovery
methods, we introduce an innovative data aggregation approach, {\funcname},
which significantly enhances the accuracy and trustworthiness of data generated
by LLMs. To validate the framework's effectiveness, we construct a dataset
consisting of three types of questions, capturing Q\&A interactions between 10
oracle nodes and 5 LLM models. Experimental results demonstrate that, even with
40\% malicious nodes, the proposed solution improves data accuracy by an
average of 17.74\% compared to the optimal baseline. This research not only
provides an innovative solution for the intelligent enhancement of smart
contracts but also highlights the potential for deep integration between LLMs
and blockchain technology, paving the way for more intelligent and complex
applications of smart contracts in the future.

摘要：區塊鏈智慧合約催化了各種領域中去中心化應用的發展，包括去中心化金融。然而，由於運算資源的限制和資料孤島的普遍存在，目前的智慧合約在充分利用大型語言模型 (LLM) 的強大功能來執行諸如智慧分析和推理等任務時，面臨著重大的挑戰。為了解決這個差距，本文提出並實作了一個將 LLM 與區塊鏈資料整合的通用架構，{\sysname}，有效地克服了區塊鏈和 LLM 之間的互操作性障礙。透過結合語義關聯性與真實發現方法，我們引進了一種創新的資料彙整方法，{\funcname}，它顯著地提升了 LLM 所產生資料的準確性和可信度。為了驗證架構的有效性，我們建構了一個由三種類型的問題組成的資料集，擷取了 10 個神諭節點和 5 個 LLM 模型之間的問答互動。實驗結果表明，即使有 40% 的惡意節點，與最佳基準線相比，所提出的解決方案將資料準確度平均提高了 17.74%。這項研究不僅為智慧合約的智慧增強提供了創新的解決方案，也突顯了 LLM 和區塊鏈技術之間深度整合的潛力，為未來更智慧、更複雜的智慧合約應用鋪路。

##### **VideoGen-of-Thought: A Collaborative Framework for Multi-Shot Video Generation**
2412.02259v1 by Mingzhe Zheng, Yongqi Xu, Haojian Huang, Xuran Ma, Yexin Liu, Wenjie Shu, Yatian Pang, Feilong Tang, Qifeng Chen, Harry Yang, Ser-Nam Lim

Current video generation models excel at generating short clips but still
struggle with creating multi-shot, movie-like videos. Existing models trained
on large-scale data on the back of rich computational resources are
unsurprisingly inadequate for maintaining a logical storyline and visual
consistency across multiple shots of a cohesive script since they are often
trained with a single-shot objective. To this end, we propose
VideoGen-of-Thought (VGoT), a collaborative and training-free architecture
designed specifically for multi-shot video generation. VGoT is designed with
three goals in mind as follows. Multi-Shot Video Generation: We divide the
video generation process into a structured, modular sequence, including (1)
Script Generation, which translates a curt story into detailed prompts for each
shot; (2) Keyframe Generation, responsible for creating visually consistent
keyframes faithful to character portrayals; and (3) Shot-Level Video
Generation, which transforms information from scripts and keyframes into shots;
(4) Smoothing Mechanism that ensures a consistent multi-shot output. Reasonable
Narrative Design: Inspired by cinematic scriptwriting, our prompt generation
approach spans five key domains, ensuring logical consistency, character
development, and narrative flow across the entire video. Cross-Shot
Consistency: We ensure temporal and identity consistency by leveraging
identity-preserving (IP) embeddings across shots, which are automatically
created from the narrative. Additionally, we incorporate a cross-shot smoothing
mechanism, which integrates a reset boundary that effectively combines latent
features from adjacent shots, resulting in smooth transitions and maintaining
visual coherence throughout the video. Our experiments demonstrate that VGoT
surpasses existing video generation methods in producing high-quality,
coherent, multi-shot videos.

摘要：<paragraph>當前的影片生成模型擅長生成短片段，但仍難以製作多鏡頭、電影般的影片。現有的模型在大量的資料訓練下，仰賴於豐富的運算資源，不足以維持邏輯故事線和視覺一致性貫穿於一個連貫劇本的多個鏡頭中，因為它們通常是使用單鏡頭目標訓練的。為此，我們提出 VideoGen-of-Thought (VGoT)，一種專門為多鏡頭影片生成設計的協作式且無需訓練的架構。VGoT 的設計考量了以下三個目標。多鏡頭影片生成：我們將影片生成過程劃分為一個結構化的模組化順序，包括：(1) 劇本生成，將簡短的故事轉換為每個鏡頭的詳細提示；(2) 關鍵影格生成，負責製作視覺一致且忠於角色描繪的關鍵影格；(3) 鏡頭級影片生成，將腳本和關鍵影格中的資訊轉換為鏡頭；(4) 平滑機制，確保一致的多鏡頭輸出。合理的敘事設計：我們的提示生成方法受到電影劇本寫作的啟發，涵蓋了五個關鍵領域，確保整個影片的邏輯一致性、角色發展和敘事流暢。跨鏡頭一致性：我們透過鏡頭間的恆等性保留 (IP) 嵌入來確保時間和身分一致性，這些嵌入會自動從敘事中建立。此外，我們納入一個跨鏡頭平滑機制，整合一個重置邊界，有效地結合相鄰鏡頭的潛在特徵，產生平滑的過渡並在整個影片中維持視覺一致性。我們的實驗證明，VGoT 在製作高品質、連貫、多鏡頭影片方面超越了現有的影片生成方法。</paragraph>

##### **Compressing KV Cache for Long-Context LLM Inference with Inter-Layer Attention Similarity**
2412.02252v1 by Da Ma, Lu Chen, Situo Zhang, Yuxun Miao, Su Zhu, Zhi Chen, Hongshen Xu, Hanqi Li, Shuai Fan, Lei Pan, Kai Yu

The increasing context window size in Large Language Models (LLMs), such as
the GPT and LLaMA series, has improved their ability to tackle complex,
long-text tasks, but at the cost of inference efficiency, particularly
regarding memory and computational complexity. Existing methods, including
selective token retention and window-based attention, improve efficiency but
risk discarding important tokens needed for future text generation. In this
paper, we propose an approach that enhances LLM efficiency without token loss
by reducing the memory and computational load of less important tokens, rather
than discarding them.We address two challenges: 1) investigating the
distribution of important tokens in the context, discovering recent tokens are
more important than distant tokens in context, and 2) optimizing resources for
distant tokens by sharing attention scores across layers. The experiments show
that our method saves $35\%$ KV cache without compromising the performance.

摘要：大型語言模型（LLM），例如 GPT 和 LLaMA 系列，其不斷增加的上下文窗口大小改善了它們處理複雜、長文本任務的能力，但代價是推論效率，特別是在記憶體和運算複雜性方面。現有方法，包括選擇性保留標記和基於窗口的注意力，可以提高效率，但有風險會丟棄未來文本生成所需的標記。在本文中，我們提出了一種方法，它可以透過減少不重要標記的記憶體和運算負載，而不是丟棄它們，來增強 LLM 效率，而不會損失標記。我們解決了兩個挑戰：1) 調查上下文中重要標記的分布，發現最近的標記比上下文中較遠的標記更重要，以及 2) 透過在各層之間共享注意力分數，來優化遠端標記的資源。實驗顯示，我們的這種方法節省了 35% 的 KV 快取，而不會損害效能。

##### **Selective Reviews of Bandit Problems in AI via a Statistical View**
2412.02251v1 by Pengjie Zhou, Haoyu Wei, Huiming Zhang

Reinforcement Learning (RL) is a widely researched area in artificial
intelligence that focuses on teaching agents decision-making through
interactions with their environment. A key subset includes stochastic
multi-armed bandit (MAB) and continuum-armed bandit (SCAB) problems, which
model sequential decision-making under uncertainty. This review outlines the
foundational models and assumptions of bandit problems, explores non-asymptotic
theoretical tools like concentration inequalities and minimax regret bounds,
and compares frequentist and Bayesian algorithms for managing
exploration-exploitation trade-offs. We also extend the discussion to $K$-armed
contextual bandits and SCAB, examining their methodologies, regret analyses,
and discussing the relation between the SCAB problems and the functional data
analysis. Finally, we highlight recent advances and ongoing challenges in the
field.

摘要：強化學習 (RL) 是人工智慧中廣泛研究的領域，專注於透過與環境互動來教授代理決策制定。一個關鍵子集包括隨機多臂賭博機 (MAB) 和連續臂賭博機 (SCAB) 問題，它們對不確定性下的順序決策制定進行建模。本篇評論概述了賭博機問題的基本模型和假設，探討了非漸近理論工具（如集中不等式和極小極大後悔邊界），並比較了管理探索 - 利用權衡的頻率論和貝氏演算法。我們還將討論擴展到 K 臂情境賭博機和 SCAB，檢視它們的方法、後悔分析，並討論 SCAB 問題與函式資料分析之間的關係。最後，我們重點介紹了該領域的最新進展和持續挑戰。

##### **U-Net in Medical Image Segmentation: A Review of Its Applications Across Modalities**
2412.02242v1 by Fnu Neha, Deepshikha Bhati, Deepak Kumar Shukla, Sonavi Makarand Dalvi, Nikolaos Mantzou, Safa Shubbar

Medical imaging is essential in healthcare to provide key insights into
patient anatomy and pathology, aiding in diagnosis and treatment. Non-invasive
techniques such as X-ray, Magnetic Resonance Imaging (MRI), Computed Tomography
(CT), and Ultrasound (US), capture detailed images of organs, tissues, and
abnormalities. Effective analysis of these images requires precise segmentation
to delineate regions of interest (ROI), such as organs or lesions. Traditional
segmentation methods, relying on manual feature-extraction, are labor-intensive
and vary across experts. Recent advancements in Artificial Intelligence (AI)
and Deep Learning (DL), particularly convolutional models such as U-Net and its
variants (U-Net++ and U-Net 3+), have transformed medical image segmentation
(MIS) by automating the process and enhancing accuracy. These models enable
efficient, precise pixel-wise classification across various imaging modalities,
overcoming the limitations of manual segmentation. This review explores various
medical imaging techniques, examines the U-Net architectures and their
adaptations, and discusses their application across different modalities. It
also identifies common challenges in MIS and proposes potential solutions.

摘要：醫療影像在醫療保健中至關重要，可提供患者解剖結構和病理學的重要見解，有助於診斷和治療。X 光、磁振造影 (MRI)、電腦斷層掃描 (CT) 和超音波 (US) 等非侵入式技術，可捕捉器官、組織和異常的詳細影像。有效分析這些影像需要精確的分割，以描繪感興趣區域 (ROI)，例如器官或病灶。傳統的分割方法依賴於手動特徵萃取，既費時又因專家而異。人工智慧 (AI) 和深度學習 (DL) 的最新進展，特別是 U-Net 和其變體 (U-Net++ 和 U-Net 3+) 等卷積模型，已透過自動化流程和提高準確度，轉變了醫療影像分割 (MIS)。這些模型能跨越各種影像模式進行有效且精確的逐像素分類，克服了手動分割的限制。本篇評論探討了各種醫療影像技術，審查了 U-Net 架構及其改編，並討論了它們在不同模式中的應用。它也找出了 MIS 中常見的挑戰，並提出了潛在的解決方案。

##### **Cross-Attention Head Position Patterns Can Align with Human Visual Concepts in Text-to-Image Generative Models**
2412.02237v1 by Jungwon Park, Jungmin Ko, Dongnam Byun, Jangwon Suh, Wonjong Rhee

Recent text-to-image diffusion models leverage cross-attention layers, which
have been effectively utilized to enhance a range of visual generative tasks.
However, our understanding of cross-attention layers remains somewhat limited.
In this study, we present a method for constructing Head Relevance Vectors
(HRVs) that align with useful visual concepts. An HRV for a given visual
concept is a vector with a length equal to the total number of cross-attention
heads, where each element represents the importance of the corresponding head
for the given visual concept. We develop and employ an ordered weakening
analysis to demonstrate the effectiveness of HRVs as interpretable features. To
demonstrate the utility of HRVs, we propose concept strengthening and concept
adjusting methods and apply them to enhance three visual generative tasks. We
show that misinterpretations of polysemous words in image generation can be
corrected in most cases, five challenging attributes in image editing can be
successfully modified, and catastrophic neglect in multi-concept generation can
be mitigated. Overall, our work provides an advancement in understanding
cross-attention layers and introduces new approaches for fine-controlling these
layers at the head level.

摘要：<paragraph>近期的文本到图像扩散模型利用交叉注意层，这已被有效地用于增强一系列视觉生成任务。然而，我们对交叉注意层的理解仍然有些局限。在这项研究中，我们提出了一种构建与有用视觉概念一致的头相关向量 (HRV) 的方法。给定视觉概念的 HRV 是一个向量，其长度等于交叉注意头的总数，其中每个元素表示给定视觉概念的对应头的权重。我们开发并采用有序弱化分析来证明 HRV 作为可解释特征的有效性。为了展示 HRV 的实用性，我们提出了概念强化和概念调整方法，并将它们应用于增强三种视觉生成任务。我们表明，在大多数情况下都可以纠正图像生成中多义词的误解，可以成功修改图像编辑中的五个具有挑战性的属性，并且可以减轻多概念生成中的灾难性忽略。总体而言，我们的工作提高了对交叉注意层的理解，并引入了在头级别精细控制这些层的新方法。</paragraph>

##### **BANER: Boundary-Aware LLMs for Few-Shot Named Entity Recognition**
2412.02228v1 by Quanjiang Guo, Yihong Dong, Ling Tian, Zhao Kang, Yu Zhang, Sijie Wang

Despite the recent success of two-stage prototypical networks in few-shot
named entity recognition (NER), challenges such as over/under-detected false
spans in the span detection stage and unaligned entity prototypes in the type
classification stage persist. Additionally, LLMs have not proven to be
effective few-shot information extractors in general. In this paper, we propose
an approach called Boundary-Aware LLMs for Few-Shot Named Entity Recognition to
address these issues. We introduce a boundary-aware contrastive learning
strategy to enhance the LLM's ability to perceive entity boundaries for
generalized entity spans. Additionally, we utilize LoRAHub to align information
from the target domain to the source domain, thereby enhancing adaptive
cross-domain classification capabilities. Extensive experiments across various
benchmarks demonstrate that our framework outperforms prior methods, validating
its effectiveness. In particular, the proposed strategies demonstrate
effectiveness across a range of LLM architectures. The code and data are
released on https://github.com/UESTC-GQJ/BANER.

摘要：儘管雙階段原型網路在少量樣本命名實體識別 (NER) 中獲得近期成功，但跨度偵測階段中偵測過多/過少錯誤跨度以及類型分類階段中不對齊實體原型等挑戰依然存在。此外，LLM 已被證實無法普遍有效地萃取少量樣本資訊。在本文中，我們提出一個稱為少量樣本命名實體識別邊界感知 LLM 的方法來解決這些問題。我們引入邊界感知對比學習策略，以增強 LLM 感知實體邊界的能力，進而產生一般化的實體跨度。此外，我們使用 LoRAHub 將目標網域的資訊與來源網域對齊，藉此增強適應性跨網域分類能力。透過各種基準的廣泛實驗證明，我們的架構優於先前的各種方法，驗證其有效性。特別是，提出的策略證明了其在各種 LLM 架構中的有效性。程式碼和資料已發布於 https://github.com/UESTC-GQJ/BANER。

##### **Deep learning approach for predicting the replicator equation in evolutionary game theory**
2412.02222v1 by Advait Chandorkar

This paper presents a physics-informed deep learning approach for predicting
the replicator equation, allowing accurate forecasting of population dynamics.
This methodological innovation allows us to derive governing differential or
difference equations for systems that lack explicit mathematical models. We
used the SINDy model first introduced by Fasel, Kaiser, Kutz, Brunton, and
Brunt 2016a to get the replicator equation, which will significantly advance
our understanding of evolutionary biology, economic systems, and social
dynamics. By refining predictive models across multiple disciplines, including
ecology, social structures, and moral behaviours, our work offers new insights
into the complex interplay of variables shaping evolutionary outcomes in
dynamic systems

摘要：本文提出了一種基於物理的深度學習方法，用於預測複製方程式，從而準確預測人口動態。這種方法論創新使我們能夠推導缺乏明確數學模型的系統的控制微分或差分方程式。我們首先使用 Fasel、Kaiser、Kutz、Brunton 和 Brunt 2016a 引入的 SINDy 模型來獲取複製方程式，這將顯著提升我們對進化生物學、經濟系統和社會動態的理解。通過改進跨越多個學科（包括生態學、社會結構和道德行為）的預測模型，我們的研究為塑造動態系統中進化結果的變量之間的複雜相互作用提供了新的見解。

##### **Unlocking Tuning-Free Few-Shot Adaptability in Visual Foundation Models by Recycling Pre-Tuned LoRAs**
2412.02220v1 by Zixuan Hu, Yongxian Wei, Li Shen, Chun Yuan, Dacheng Tao

Large Language Models (LLMs) such as ChatGPT demonstrate strong few-shot
adaptability without requiring fine-tuning, positioning them ideal for
data-limited and real-time applications. However, this adaptability has not yet
been replicated in current Visual Foundation Models (VFMs), which require
explicit fine-tuning with sufficient tuning data. Besides, the
pretraining-finetuning paradigm has led to the surge of numerous task-specific
modular components, such as Low-Rank Adaptation (LoRA). For the first time, we
explore the potential of reusing diverse pre-tuned LoRAs without accessing
their original training data, to achieve tuning-free few-shot adaptation in
VFMs. Our framework, LoRA Recycle, distills a meta-LoRA from diverse pre-tuned
LoRAs with a meta-learning objective, using surrogate data generated inversely
from pre-tuned LoRAs themselves. The VFM, once equipped with the meta-LoRA, is
empowered to solve new few-shot tasks in a single forward pass, akin to the
in-context learning of LLMs. Additionally, we incorporate a double-efficient
mechanism tailored to our framework, significantly accelerating the
meta-training process while maintaining or even improving performance.
Extensive experiments across various few-shot classification benchmarks across
both in- and cross-domain scenarios demonstrate the superiority of our
framework.

摘要：大型語言模型 (LLM)，例如 ChatGPT，展示了強大的小樣本適應性，而不需要微調，使其成為數據受限和實時應用程序的理想選擇。然而，這種適應性尚未在當前的視覺基礎模型 (VFM) 中複製，後者需要使用足夠的調整數據進行明確的微調。此外，預訓練微調範例導致大量特定任務模組化組件激增，例如低秩適應 (LoRA)。我們首次探索了在不訪問其原始訓練數據的情況下重複使用各種預調 LoRA 的潛力，以在 VFM 中實現無需調整的小樣本適應。我們的框架 LoRA Recycle 從各種預調 LoRA 中提取一個元 LoRA，並使用從預調 LoRA 本身反向生成的替代數據，使用元學習目標。一旦配備了元 LoRA，VFM 便能夠在單次前向傳遞中解決新的少樣本任務，類似於 LLM 的情境學習。此外，我們結合了一種專門針對我們框架的雙重高效機制，顯著加速了元訓練過程，同時保持或甚至提高了性能。跨各種少樣本分類基準的廣泛實驗，無論是在域內還是跨域場景中，都證明了我們框架的優越性。

##### **Recovering implicit physics model under real-world constraints**
2412.02215v1 by Ayan Banerjee, Sandeep K. S. Gupta

Recovering a physics-driven model, i.e. a governing set of equations of the
underlying dynamical systems, from the real-world data has been of recent
interest. Most existing methods either operate on simulation data with
unrealistically high sampling rates or require explicit measurements of all
system variables, which is not amenable in real-world deployments. Moreover,
they assume the timestamps of external perturbations to the physical system are
known a priori, without uncertainty, implicitly discounting any sensor
time-synchronization or human reporting errors. In this paper, we propose a
novel liquid time constant neural network (LTC-NN) based architecture to
recover underlying model of physical dynamics from real-world data. The
automatic differentiation property of LTC-NN nodes overcomes problems
associated with low sampling rates, the input dependent time constant in the
forward pass of the hidden layer of LTC-NN nodes creates a massive search space
of implicit physical dynamics, the physics model solver based data
reconstruction loss guides the search for the correct set of implicit dynamics,
and the use of the dropout regularization in the dense layer ensures extraction
of the sparsest model. Further, to account for the perturbation timing error,
we utilize dense layer nodes to search through input shifts that results in the
lowest reconstruction loss. Experiments on four benchmark dynamical systems,
three with simulation data and one with the real-world data show that the
LTC-NN architecture is more accurate in recovering implicit physics model
coefficients than the state-of-the-art sparse model recovery approaches. We
also introduce four additional case studies (total eight) on real-life medical
examples in simulation and with real-world clinical data to show effectiveness
of our approach in recovering underlying model in practice.

摘要：<paragraph>從真實世界資料中還原物理驅動模型，即基礎動態系統的控制方程式組，一直是近期的研究重點。現有方法大多在具有非現實高取樣率的模擬資料上執行，或需要所有系統變數的明確測量值，這在真實世界的部署中並不可行。此外，這些方法假設對物理系統的外部擾動的時間戳是先驗已知的，且沒有不確定性，隱含地忽略了任何感測器時間同步或人為回報錯誤。在本文中，我們提出了一種基於新穎液態時間常數神經網路 (LTC-NN) 的架構，以從真實世界資料中還原物理動態的基礎模型。LTC-NN 節點的自動微分特性克服了與低取樣率相關的問題，LTC-NN 節點隱藏層的前向傳遞中輸入依賴的時間常數會產生一個巨大的隱式物理動態搜尋空間，基於物理模型求解器的資料重建損失引導了對正確隱式動態集的搜尋，並且在稠密層中使用中斷正則化確保了最稀疏模型的提取。此外，為了考慮擾動計時錯誤，我們利用稠密層節點來搜尋輸入位移，這將導致最低的重建損失。在四個基準動態系統（三個使用模擬資料，一個使用真實世界資料）上的實驗表明，LTC-NN 架構在恢復隱式物理模型係數方面比最先進的稀疏模型恢復方法更準確。我們還介紹了四個額外的案例研究（總共八個），這些研究涉及模擬中的真實醫療範例和真實世界的臨床資料，以展示我們的做法在實務中恢復基礎模型的有效性。</paragraph>

##### **DataLab: A Unifed Platform for LLM-Powered Business Intelligence**
2412.02205v1 by Luoxuan Weng, Yinghao Tang, Yingchaojie Feng, Zhuo Chang, Peng Chen, Ruiqin Chen, Haozhe Feng, Chen Hou, Danqing Huang, Yang Li, Huaming Rao, Haonan Wang, Canshi Wei, Xiaofeng Yang, Yuhui Zhang, Yifeng Zheng, Xiuqi Huang, Minfeng Zhu, Yuxin Ma, Bin Cui, Wei Chen

Business intelligence (BI) transforms large volumes of data within modern
organizations into actionable insights for informed decision-making. Recently,
large language model (LLM)-based agents have streamlined the BI workflow by
automatically performing task planning, reasoning, and actions in executable
environments based on natural language (NL) queries. However, existing
approaches primarily focus on individual BI tasks such as NL2SQL and NL2VIS.
The fragmentation of tasks across different data roles and tools lead to
inefficiencies and potential errors due to the iterative and collaborative
nature of BI. In this paper, we introduce DataLab, a unified BI platform that
integrates a one-stop LLM-based agent framework with an augmented computational
notebook interface. DataLab supports a wide range of BI tasks for different
data roles by seamlessly combining LLM assistance with user customization
within a single environment. To achieve this unification, we design a domain
knowledge incorporation module tailored for enterprise-specific BI tasks, an
inter-agent communication mechanism to facilitate information sharing across
the BI workflow, and a cell-based context management strategy to enhance
context utilization efficiency in BI notebooks. Extensive experiments
demonstrate that DataLab achieves state-of-the-art performance on various BI
tasks across popular research benchmarks. Moreover, DataLab maintains high
effectiveness and efficiency on real-world datasets from Tencent, achieving up
to a 58.58% increase in accuracy and a 61.65% reduction in token cost on
enterprise-specific BI tasks.

摘要：商業智慧（BI）將現代組織中大量的資料轉換為可操作的見解，以供明智決策。最近，基於大型語言模型（LLM）的代理簡化了 BI 工作流程，根據自然語言（NL）查詢在可執行環境中自動執行任務規劃、推理和動作。然而，現有方法主要關注個別 BI 任務，例如 NL2SQL 和 NL2VIS。由於 BI 的迭代和協作性質，任務在不同資料角色和工具之間的分散導致低效率和潛在錯誤。在本文中，我們介紹了 DataLab，一個統一的 BI 平台，它將一站式 LLM 代理框架與增強計算筆記本介面整合在一起。DataLab 支援各種 BI 任務，適用於不同的資料角色，透過在單一環境中無縫結合 LLM 協助與使用者自訂來達成。為了實現這種統一，我們設計了一個針對企業特定 BI 任務量身打造的領域知識整合模組、一個代理間通訊機制以利於在 BI 工作流程中分享資訊，以及一個基於單元的內容管理策略以增強 BI 筆記本中的內容使用效率。廣泛的實驗證明，DataLab 在各種 BI 任務上達到了最先進的效能，橫跨熱門研究基準。此外，DataLab 在騰訊的真實世界資料集上保持了高效率和高成效，在企業特定 BI 任務上達到了準確度提高 58.58% 和令牌成本減少 61.65%。

##### **LayoutVLM: Differentiable Optimization of 3D Layout via Vision-Language Models**
2412.02193v1 by Fan-Yun Sun, Weiyu Liu, Siyi Gu, Dylan Lim, Goutam Bhat, Federico Tombari, Manling Li, Nick Haber, Jiajun Wu

Open-universe 3D layout generation arranges unlabeled 3D assets conditioned
on language instruction. Large language models (LLMs) struggle with generating
physically plausible 3D scenes and adherence to input instructions,
particularly in cluttered scenes. We introduce LayoutVLM, a framework and scene
layout representation that exploits the semantic knowledge of Vision-Language
Models (VLMs) and supports differentiable optimization to ensure physical
plausibility. LayoutVLM employs VLMs to generate two mutually reinforcing
representations from visually marked images, and a self-consistent decoding
process to improve VLMs spatial planning. Our experiments show that LayoutVLM
addresses the limitations of existing LLM and constraint-based approaches,
producing physically plausible 3D layouts better aligned with the semantic
intent of input language instructions. We also demonstrate that fine-tuning
VLMs with the proposed scene layout representation extracted from existing
scene datasets can improve performance.

摘要：開放宇宙 3D 佈局生成會根據語言指令排列未標籤的 3D 資產。大型語言模型 (LLM) 努力產生物理上合理的 3D 場景，並遵守輸入指令，特別是在雜亂的場景中。我們引入了 LayoutVLM，這是一個框架和場景佈局表示，它利用了視覺語言模型 (VLM) 的語義知識，並支援可微分最佳化以確保物理合理性。LayoutVLM 使用 VLM 從視覺標記影像中產生兩個相互強化的表示，以及一個自我一致的解碼過程來改善 VLM 的空間規劃。我們的實驗表明，LayoutVLM 解决了現有 LLM 和基於約束的方法的限制，產生了與輸入語言指令的語義意圖更一致的物理上合理的 3D 佈局。我們還證明，使用從現有場景資料集提取的提議場景佈局表示微調 VLM 可以改善效能。

##### **Comparative Performance of Machine Learning Algorithms for Early Genetic Disorder and Subclass Classification**
2412.02189v1 by Abu Bakar Siddik, Faisal R. Badal, Afroza Islam

A great deal of effort has been devoted to discovering a particular genetic
disorder, but its classification across a broad spectrum of disorder classes
and types remains elusive. Early diagnosis of genetic disorders enables timely
interventions and improves outcomes. This study implements machine learning
models using basic clinical indicators measurable at birth or infancy to enable
diagnosis in preliminary life stages. Supervised learning algorithms were
implemented on a dataset of 22083 instances with 42 features like family
history, newborn metrics, and basic lab tests. Extensive hyperparameter tuning,
feature engineering, and selection were undertaken. Two multi-class classifiers
were developed: one for predicting disorder classes (mitochondrial,
multifactorial, and single-gene) and one for subtypes (9 disorders).
Performance was evaluated using accuracy, precision, recall, and the F1-score.
The CatBoost classifier achieved the highest accuracy of 77% for predicting
genetic disorder classes. For subtypes, SVM attained a maximum accuracy of 80%.
The study demonstrates the feasibility of using basic clinical data in machine
learning models for early categorization and diagnosis across various genetic
disorders. Applying ML with basic clinical indicators can enable timely
interventions once validated on larger datasets. It is necessary to conduct
further studies to improve model performance on this dataset.

摘要：<paragraph>許多研究致力於發現特定遺傳性疾病，但其在廣泛的疾病類型和分類中的分類仍然難以捉摸。遺傳性疾病的早期診斷能及時介入並改善結果。本研究實作機器學習模型，使用出生或嬰兒時期可測量的基本臨床指標，以在生命的早期階段進行診斷。監督式學習演算法實作在一個包含 22083 個實例的資料集上，其中包含 42 個特徵，例如家族史、新生兒指標和基本實驗室檢驗。進行了廣泛的超參數調整、特徵工程和選擇。開發了兩個多類別分類器：一個用於預測疾病類型（粒線體、多因素和單基因），另一個用於預測亞型（9 種疾病）。使用準確度、精確度、召回率和 F1 分數評估效能。CatBoost 分類器在預測遺傳性疾病類型方面達到了 77% 的最高準確度。對於亞型，SVM 達到了 80% 的最高準確度。本研究證明了在機器學習模型中使用基本臨床資料進行早期分類和診斷各種遺傳性疾病的可行性。將機器學習應用於基本臨床指標，可以在較大的資料集上驗證後及時進行干預。有必要進行進一步的研究以改善此資料集上的模型效能。</paragraph>

##### **VideoICL: Confidence-based Iterative In-context Learning for Out-of-Distribution Video Understanding**
2412.02186v1 by Kangsan Kim, Geon Park, Youngwan Lee, Woongyeong Yeo, Sung Ju Hwang

Recent advancements in video large multimodal models (LMMs) have
significantly improved their video understanding and reasoning capabilities.
However, their performance drops on out-of-distribution (OOD) tasks that are
underrepresented in training data. Traditional methods like fine-tuning on OOD
datasets are impractical due to high computational costs. While In-context
learning (ICL) with demonstration examples has shown promising generalization
performance in language tasks and image-language tasks without fine-tuning,
applying ICL to video-language tasks faces challenges due to the limited
context length in Video LMMs, as videos require longer token lengths. To
address these issues, we propose VideoICL, a novel video in-context learning
framework for OOD tasks that introduces a similarity-based relevant example
selection strategy and a confidence-based iterative inference approach. This
allows to select the most relevant examples and rank them based on similarity,
to be used for inference. If the generated response has low confidence, our
framework selects new examples and performs inference again, iteratively
refining the results until a high-confidence response is obtained. This
approach improves OOD video understanding performance by extending effective
context length without incurring high costs. The experimental results on
multiple benchmarks demonstrate significant performance gains, especially in
domain-specific scenarios, laying the groundwork for broader video
comprehension applications. Code will be released at
https://github.com/KangsanKim07/VideoICL

摘要：近期影片多模態大型模型 (LMM) 的進步大幅提升了影片理解和推理能力。然而，在訓練資料中代表性不足的分布外 (OOD) 任務上，其效能會下降。微調 OOD 資料集等傳統方法因高運算成本而不切實際。儘管在語言任務和影像語言任務中，情境內學習 (ICL) 已透過示範範例展現出良好的概化效能，且無需微調，但由於影片 LMM 中的有限情境長度，將 ICL 應用於影片語言任務時會面臨挑戰，因為影片需要較長的標記長度。為了解決這些問題，我們提出 VideoICL，一個針對 OOD 任務的影片情境內學習框架，其中引入了基於相似性的相關範例選取策略和基於信心的反覆推論方法。這允許根據相似性選取最相關的範例並對其進行排序，以用於推論。如果產生的回應具有低信心，我們的框架會選取新的範例並再次執行推論，反覆改善結果，直到獲得高信心的回應。此方法透過擴充有效的內容長度，在不產生高成本的情況下改善 OOD 影片理解效能。在多個基準上的實驗結果證明了顯著的效能提升，特別是在特定領域的情境中，為更廣泛的影片理解應用奠定了基礎。程式碼將在 https://github.com/KangsanKim07/VideoICL 發布

##### **Generalizing Weisfeiler-Lehman Kernels to Subgraphs**
2412.02181v1 by Dongkwan Kim, Alice Oh

Subgraph representation learning has been effective in solving various
real-world problems. However, current graph neural networks (GNNs) produce
suboptimal results for subgraph-level tasks due to their inability to capture
complex interactions within and between subgraphs. To provide a more expressive
and efficient alternative, we propose WLKS, a Weisfeiler-Lehman (WL) kernel
generalized for subgraphs by applying the WL algorithm on induced $k$-hop
neighborhoods. We combine kernels across different $k$-hop levels to capture
richer structural information that is not fully encoded in existing models. Our
approach can balance expressiveness and efficiency by eliminating the need for
neighborhood sampling. In experiments on eight real-world and synthetic
benchmarks, WLKS significantly outperforms leading approaches on five datasets
while reducing training time, ranging from 0.01x to 0.25x compared to the
state-of-the-art.

摘要：子圖表示學習在解決各種現實問題上已展現其效用。然而，現有的圖神經網路 (GNN) 由於無法捕捉子圖內部和子圖之間的複雜互動，因此在子圖層級任務中產生的結果並非最佳。為了提供更具表達力和效率的替代方案，我們提出了 WLKS，這是一種 Weisfeiler-Lehman (WL) 核心，透過將 WL 演算法套用在感應 $k$-跳鄰域上，進而推廣到子圖。我們結合不同 $k$-跳層級的核，以捕捉現有模型中未完全編碼的更豐富結構資訊。我們的做法能透過消除鄰域抽樣的必要性，進而平衡表現力和效率。在八個真實世界和合成基準測試的實驗中，WLKS 在五個資料集上顯著優於領先的方法，同時縮短訓練時間，與現有技術相比，範圍從 0.01x 到 0.25x。

##### **Anatomically-Grounded Fact Checking of Automated Chest X-ray Reports**
2412.02177v1 by R. Mahmood, K. C. L. Wong, D. M. Reyes, N. D'Souza, L. Shi, J. Wu, P. Kaviani, M. Kalra, G. Wang, P. Yan, T. Syeda-Mahmood

With the emergence of large-scale vision-language models, realistic radiology
reports may be generated using only medical images as input guided by simple
prompts. However, their practical utility has been limited due to the factual
errors in their description of findings. In this paper, we propose a novel
model for explainable fact-checking that identifies errors in findings and
their locations indicated through the reports. Specifically, we analyze the
types of errors made by automated reporting methods and derive a new synthetic
dataset of images paired with real and fake descriptions of findings and their
locations from a ground truth dataset. A new multi-label cross-modal
contrastive regression network is then trained on this datsaset. We evaluate
the resulting fact-checking model and its utility in correcting reports
generated by several SOTA automated reporting tools on a variety of benchmark
datasets with results pointing to over 40\% improvement in report quality
through such error detection and correction.

摘要：隨著大規模視覺語言模型的出現，僅使用醫療影像作為輸入，並透過簡單提示引導，即可產生逼真的放射科報告。然而，由於其對發現的描述有事實上的錯誤，因此其實際效用受到限制。在本文中，我們提出了一個用於可解釋事實查核的新模型，該模型可識別報告中發現的錯誤及其位置。具體來說，我們分析了自動化報告方法所產生的錯誤類型，並從真實資料集中衍生出一個新的合成影像資料集，其中配對了發現及其位置的真實和虛假描述。然後在這個資料集上訓練一個新的多標籤跨模態對比回歸網路。我們評估了產生的事實查核模型及其在更正由多個 SOTA 自動化報告工具在各種基準資料集上產生的報告中的效用，結果表明透過這種錯誤偵測和更正，報告品質獲得了超過 40% 的提升。

##### **Keeping Experts in the Loop: Expert-Guided Optimization for Clinical Data Classification using Large Language Models**
2412.02173v1 by Nader Karayanni, Aya Awwad, Chein-Lien Hsiao, Surish P Shanmugam

Since the emergence of Large Language Models (LLMs), the challenge of
effectively leveraging their potential in healthcare has taken center stage. A
critical barrier to using LLMs for extracting insights from unstructured
clinical notes lies in the prompt engineering process. Despite its pivotal role
in determining task performance, a clear framework for prompt optimization
remains absent. Current methods to address this gap take either a manual prompt
refinement approach, where domain experts collaborate with prompt engineers to
create an optimal prompt, which is time-intensive and difficult to scale, or
through employing automatic prompt optimizing approaches, where the value of
the input of domain experts is not fully realized. To address this, we propose
StructEase, a novel framework that bridges the gap between automation and the
input of human expertise in prompt engineering. A core innovation of the
framework is SamplEase, an iterative sampling algorithm that identifies
high-value cases where expert feedback drives significant performance
improvements. This approach minimizes expert intervention, to effectively
enhance classification outcomes. This targeted approach reduces labeling
redundancy, mitigates human error, and enhances classification outcomes. We
evaluated the performance of StructEase using a dataset of de-identified
clinical narratives from the US National Electronic Injury Surveillance System
(NEISS), demonstrating significant gains in classification performance compared
to current methods. Our findings underscore the value of expert integration in
LLM workflows, achieving notable improvements in F1 score while maintaining
minimal expert effort. By combining transparency, flexibility, and scalability,
StructEase sets the foundation for a framework to integrate expert input into
LLM workflows in healthcare and beyond.

摘要：自大型語言模型 (LLM) 出現以來，有效利用其在醫療保健中的潛力的挑戰已成為重中之重。使用 LLM 從非結構化臨床筆記中提取見解的一個關鍵障礙在於提示工程過程。儘管它在確定任務績效中扮演著舉足輕重的角色，但仍缺乏明確的提示最佳化框架。目前解決此差距的方法採用手動提示優化方法，其中領域專家與提示工程師合作建立最佳提示，這非常耗時且難以擴展，或透過採用自動提示最佳化方法，其中領域專家的輸入價值並未充分實現。為了解決這個問題，我們提出了 StructEase，這是一個新穎的框架，它彌合了自動化與提示工程中人類專業知識輸入之間的差距。該框架的核心創新是 SamplEase，這是一種迭代式抽樣演算法，它識別出專家回饋能顯著提升績效的高價值案例。這種方法將專家介入降到最低，以有效提升分類結果。這種有針對性的方法減少了標籤冗餘，減輕了人為錯誤，並提升了分類結果。我們使用來自美國國家電子傷害監測系統 (NEISS) 的去識別化臨床敘述資料集評估了 StructEase 的績效，與目前的方法相比，分類績效有了顯著的提升。我們的研究結果強調了專家整合在 LLM 工作流程中的價值，在維持最少專家工作量的同時，達到了 F1 分數的顯著提升。透過結合透明度、彈性和可擴展性，StructEase 為一個框架奠定了基礎，將專家輸入整合到醫療保健及其他領域的 LLM 工作流程中。

##### **VISCO: Benchmarking Fine-Grained Critique and Correction Towards Self-Improvement in Visual Reasoning**
2412.02172v1 by Xueqing Wu, Yuheng Ding, Bingxuan Li, Pan Lu, Da Yin, Kai-Wei Chang, Nanyun Peng

The ability of large vision-language models (LVLMs) to critique and correct
their reasoning is an essential building block towards their self-improvement.
However, a systematic analysis of such capabilities in LVLMs is still lacking.
We propose VISCO, the first benchmark to extensively analyze the fine-grained
critique and correction capabilities of LVLMs. Compared to existing work that
uses a single scalar value to critique the entire reasoning [4], VISCO features
dense and fine-grained critique, requiring LVLMs to evaluate the correctness of
each step in the chain-of-thought and provide natural language explanations to
support their judgments. Extensive evaluation of 24 LVLMs demonstrates that
human-written critiques significantly enhance the performance after correction,
showcasing the potential of the self-improvement strategy. However, the
model-generated critiques are less helpful and sometimes detrimental to the
performance, suggesting that critique is the crucial bottleneck. We identified
three common patterns in critique failures: failure to critique visual
perception, reluctance to "say no", and exaggerated assumption of error
propagation. To address these issues, we propose an effective LookBack strategy
that revisits the image to verify each piece of information in the initial
reasoning. LookBack significantly improves critique and correction performance
by up to 13.5%.

摘要：大型視覺語言模型 (LVLMs) 批判和修正其推理能力是其自我提升的重要基石。
然而，對於 LVLMs 中此類能力的系統分析仍然缺乏。
我們提出 VISCO，這是第一個廣泛分析 LVLMs 細粒度批判和修正能力的基準測試。
與使用單一標量值來批判整個推理 [4] 的現有工作相比，VISCO 具有密集且細粒度的批判，要求 LVLMs 評估思想鏈中每個步驟的正確性，並提供自然語言解釋以支持其判斷。對 24 個 LVLMs 的廣泛評估表明，人為編寫的批判在修正後顯著提升了效能，展示了自我提升策略的潛力。
然而，模型產生的批判較不具幫助，有時甚至對效能有害，這表明批判是關鍵瓶頸。我們在批判失敗中發現了三種常見模式：無法批判視覺感知、不願意「說不」，以及誇大錯誤傳播的假設。為了解決這些問題，我們提出了一種有效的回顧策略，重新檢視影像以驗證初始推理中的每條資訊。回顧策略顯著提升了批判和修正效能，最高達 13.5%。

##### **A Theoretical Framework for Acoustic Neighbor Embeddings**
2412.02164v1 by Woojay Jeon

This paper provides a theoretical framework for interpreting acoustic
neighbor embeddings, which are representations of the phonetic content of
variable-width audio or text in a fixed-dimensional embedding space. A
probabilistic interpretation of the distances between embeddings is proposed,
based on a general quantitative definition of phonetic similarity between
words. This provides us a framework for understanding and applying the
embeddings in a principled manner. Theoretical and empirical evidence to
support an approximation of uniform cluster-wise isotropy are shown, which
allows us to reduce the distances to simple Euclidean distances. Four
experiments that validate the framework and demonstrate how it can be applied
to diverse problems are described. Nearest-neighbor search between audio and
text embeddings can give isolated word classification accuracy that is
identical to that of finite state transducers (FSTs) for vocabularies as large
as 500k. Embedding distances give accuracy with 0.5% point difference compared
to phone edit distances in out-of-vocabulary word recovery, as well as
producing clustering hierarchies identical to those derived from human
listening experiments in English dialect clustering. The theoretical framework
also allows us to use the embeddings to predict the expected confusion of
device wake-up words. All source code and pretrained models are provided.

摘要：本文提供了一個理論架構，用於詮釋聲學鄰近嵌入，這是變寬音訊或文字的語音內容在固定維度嵌入空間中的表示。基於詞語之間語音相似性的通用定量定義，提出了嵌入距離的機率詮釋。這為我們提供了一個以有原則的方式理解和應用嵌入的框架。顯示了支持均勻簇級各向同性的近似值的理論和經驗證據，這使我們能夠將距離簡化為簡單的歐幾里得距離。描述了四個驗證該框架並展示如何將其應用於各種問題的實驗。音訊和文字嵌入之間的最近鄰搜尋可以提供與有限狀態轉換器 (FST) 相同的孤立詞分類準確度，對於詞彙量高達 500k 的詞彙表而言。嵌入距離在詞彙外單字復原中提供與音素編輯距離相比準確度差異為 0.5% 的準確度，並產生與人類聆聽實驗中衍生的群集層級相同的群集層級。理論框架也允許我們使用嵌入來預測裝置喚醒字的預期混淆。提供所有原始碼和預訓練模型。

##### **Jailbreak Defense in a Narrow Domain: Limitations of Existing Methods and a New Transcript-Classifier Approach**
2412.02159v1 by Tony T. Wang, John Hughes, Henry Sleight, Rylan Schaeffer, Rajashree Agrawal, Fazl Barez, Mrinank Sharma, Jesse Mu, Nir Shavit, Ethan Perez

Defending large language models against jailbreaks so that they never engage
in a broadly-defined set of forbidden behaviors is an open problem. In this
paper, we investigate the difficulty of jailbreak-defense when we only want to
forbid a narrowly-defined set of behaviors. As a case study, we focus on
preventing an LLM from helping a user make a bomb. We find that popular
defenses such as safety training, adversarial training, and input/output
classifiers are unable to fully solve this problem. In pursuit of a better
solution, we develop a transcript-classifier defense which outperforms the
baseline defenses we test. However, our classifier defense still fails in some
circumstances, which highlights the difficulty of jailbreak-defense even in a
narrow domain.

摘要：如何防止大型語言模型越獄，讓它們永遠不會從事廣義定義的一組違規行為，這是一個開放性的問題。在本文中，我們探討了在我們只想禁止一組定義狹窄的行為時，越獄防禦的難度。作為一個案例研究，我們專注於防止 LLM 幫助使用者製造炸彈。我們發現，安全訓練、對抗訓練和輸入/輸出分類器等流行防禦措施無法完全解決這個問題。為了追求更好的解決方案，我們開發了一種轉錄分類器防禦措施，其優於我們測試的基準防禦措施。然而，我們的分類器防禦在某些情況下仍然會失敗，這突顯了即使在狹窄的領域中，越獄防禦的難度。

##### **CausalMob: Causal Human Mobility Prediction with LLMs-derived Human Intentions toward Public Events**
2412.02155v1 by Xiaojie Yang, Hangli Ge, Jiawei Wang, Zipei Fan, Renhe Jiang, Ryosuke Shibasaki, Noboru Koshizuka

Large-scale human mobility exhibits spatial and temporal patterns that can
assist policymakers in decision making. Although traditional prediction models
attempt to capture these patterns, they often interfered by non-periodic public
events, such as disasters and occasional celebrations. Since regular human
mobility patterns are heavily affected by these events, estimating their causal
effects is critical to accurate mobility predictions. Although news articles
provide unique perspectives on these events in an unstructured format,
processing is a challenge. In this study, we propose a causality-augmented
prediction model, called \textbf{CausalMob}, to analyze the causal effects of
public events. We first utilize large language models (LLMs) to extract human
intentions from news articles and transform them into features that act as
causal treatments. Next, the model learns representations of spatio-temporal
regional covariates from multiple data sources to serve as confounders for
causal inference. Finally, we present a causal effect estimation framework to
ensure event features remain independent of confounders during prediction.
Based on large-scale real-world data, the experimental results show that the
proposed model excels in human mobility prediction, outperforming
state-of-the-art models.

摘要：大規模的人類流動性展現出空間和時間模式，可以協助決策者進行決策。儘管傳統預測模型嘗試捕捉這些模式，但它們經常受到非週期性公共事件的干擾，例如災害和偶爾的慶祝活動。由於定期的人類流動模式受到這些事件的嚴重影響，因此估計其因果關係對於準確的流動性預測至關重要。儘管新聞文章以非結構化格式對這些事件提供了獨特的觀點，但處理它們是一項挑戰。在這項研究中，我們提出了一個因果增強預測模型，稱為\textbf{CausalMob}，以分析公共事件的因果關係。我們首先利用大型語言模型 (LLM) 從新聞文章中提取人類意圖，並將它們轉換為充當因果處理的功能。接下來，該模型從多個數據源學習時空區域協變數的表示，作為因果推論的混雜因素。最後，我們提出了一個因果效應估計框架，以確保事件特徵在預測過程中保持獨立於混雜因素。根據大規模的真實世界數據，實驗結果表明，所提出的模型在人類流動性預測方面表現出色，優於最先進的模型。

##### **Revisiting the Initial Steps in Adaptive Gradient Descent Optimization**
2412.02153v1 by Abulikemu Abuduweili, Changliu Liu

Adaptive gradient optimization methods, such as Adam, are prevalent in
training deep neural networks across diverse machine learning tasks due to
their ability to achieve faster convergence. However, these methods often
suffer from suboptimal generalization compared to stochastic gradient descent
(SGD) and exhibit instability, particularly when training Transformer models.
In this work, we show the standard initialization of the second-order moment
estimation ($v_0 =0$) as a significant factor contributing to these
limitations. We introduce simple yet effective solutions: initializing the
second-order moment estimation with non-zero values, using either data-driven
or random initialization strategies. Empirical evaluations demonstrate that our
approach not only stabilizes convergence but also enhances the final
performance of adaptive gradient optimizers. Furthermore, by adopting the
proposed initialization strategies, Adam achieves performance comparable to
many recently proposed variants of adaptive gradient optimization methods,
highlighting the practical impact of this straightforward modification.

摘要：自適應梯度最佳化方法，例如 Adam，在各種機器學習任務中訓練深度神經網路時很普遍，因為它們能夠更快速收斂。然而，這些方法與隨機梯度下降 (SGD) 相比，通常會產生次佳的泛化性，並表現出不穩定性，特別是在訓練 Transformer 模型時。在這項工作中，我們展示了二階矩估計的標準初始化 ($v_0 =0$) 是導致這些限制的重要因素。我們引入了簡單但有效的解決方案：使用非零值初始化二階矩估計，使用資料驅動或隨機初始化策略。經驗評估表明，我們的做法不僅穩定收斂，還增強了自適應梯度最佳化器的最終效能。此外，透過採用建議的初始化策略，Adam 達到了與許多最近提出的自適應梯度最佳化方法變體相當的效能，突顯了這種簡單修改的實際影響。

##### **Leveraging Large Language Models for Comparative Literature Summarization with Reflective Incremental Mechanisms**
2412.02149v1 by Fernando Gabriela Garcia, Spencer Burns, Harrison Fuller

In this paper, we introduce ChatCite, a novel method leveraging large
language models (LLMs) for generating comparative literature summaries. The
ability to summarize research papers with a focus on key comparisons between
studies is an essential task in academic research. Existing summarization
models, while effective at generating concise summaries, fail to provide deep
comparative insights. ChatCite addresses this limitation by incorporating a
multi-step reasoning mechanism that extracts critical elements from papers,
incrementally builds a comparative summary, and refines the output through a
reflective memory process. We evaluate ChatCite on a custom dataset,
CompLit-LongContext, consisting of 1000 research papers with annotated
comparative summaries. Experimental results show that ChatCite outperforms
several baseline methods, including GPT-4, BART, T5, and CoT, across various
automatic evaluation metrics such as ROUGE and the newly proposed G-Score.
Human evaluation further confirms that ChatCite generates more coherent,
insightful, and fluent summaries compared to these baseline models. Our method
provides a significant advancement in automatic literature review generation,
offering researchers a powerful tool for efficiently comparing and synthesizing
scientific research.

摘要：在本文中，我們介紹了 ChatCite，一種利用大型語言模型 (LLM) 生成比較文學摘要的新方法。摘要研究論文並專注於研究之間的關鍵比較的能力，是學術研究中的一項重要任務。現有的摘要模型雖然能夠產生簡潔的摘要，但無法提供深入的比較見解。ChatCite 通過整合一個多步驟推理機制來解決這個限制，該機制從論文中提取關鍵元素，逐步建立一個比較摘要，並通過反思記憶過程優化輸出。我們在一個自訂資料集 CompLit-LongContext 上評估 ChatCite，該資料集包含 1000 篇帶有註解比較摘要的研究論文。實驗結果表明，ChatCite 在各種自動評估指標（例如 ROUGE 和新提出的 G-Score）中優於多種基線方法，包括 GPT-4、BART、T5 和 CoT。人工評估進一步證實，與這些基線模型相比，ChatCite 生成的摘要更具連貫性、洞察力和流暢性。我們的這項方法在自動文獻回顧生成方面取得了重大進展，為研究人員提供了一個強大的工具，可以高效地比較和綜合科學研究。

##### **Personalized Multimodal Large Language Models: A Survey**
2412.02142v1 by Junda Wu, Hanjia Lyu, Yu Xia, Zhehao Zhang, Joe Barrow, Ishita Kumar, Mehrnoosh Mirtaheri, Hongjie Chen, Ryan A. Rossi, Franck Dernoncourt, Tong Yu, Ruiyi Zhang, Jiuxiang Gu, Nesreen K. Ahmed, Yu Wang, Xiang Chen, Hanieh Deilamsalehy, Namyong Park, Sungchul Kim, Huanrui Yang, Subrata Mitra, Zhengmian Hu, Nedim Lipka, Dang Nguyen, Yue Zhao, Jiebo Luo, Julian McAuley

Multimodal Large Language Models (MLLMs) have become increasingly important
due to their state-of-the-art performance and ability to integrate multiple
data modalities, such as text, images, and audio, to perform complex tasks with
high accuracy. This paper presents a comprehensive survey on personalized
multimodal large language models, focusing on their architecture, training
methods, and applications. We propose an intuitive taxonomy for categorizing
the techniques used to personalize MLLMs to individual users, and discuss the
techniques accordingly. Furthermore, we discuss how such techniques can be
combined or adapted when appropriate, highlighting their advantages and
underlying rationale. We also provide a succinct summary of personalization
tasks investigated in existing research, along with the evaluation metrics
commonly used. Additionally, we summarize the datasets that are useful for
benchmarking personalized MLLMs. Finally, we outline critical open challenges.
This survey aims to serve as a valuable resource for researchers and
practitioners seeking to understand and advance the development of personalized
multimodal large language models.

摘要：多模態大型語言模型 (MLLM) 由於其最先進的效能和整合多種資料模式（例如文字、影像和音訊）以高準確度執行複雜任務的能力，變得越來越重要。本文針對個人化多模態大型語言模型提出全面的調查，重點在於其架構、訓練方法和應用。我們提出一個直覺的分類法，用於分類用於將 MLLM 個人化為個別使用者的技術，並據此討論這些技術。此外，我們討論如何適當地結合或調整這些技術，強調其優點和背後的原理。我們也簡要總結現有研究中調查的個人化任務，以及常用的評量指標。此外，我們總結了用於對個人化 MLLM 進行基準測試的有用資料集。最後，我們概述重要的開放性挑戰。本調查旨在為尋求了解和推進個人化多模態大型語言模型發展的研究人員和從業人員提供有價值的資源。

##### **WSI-LLaVA: A Multimodal Large Language Model for Whole Slide Image**
2412.02141v1 by Yuci Liang, Xinheng Lyu, Meidan Ding, Wenting Chen, Jipeng Zhang, Yuexiang Ren, Xiangjian He, Song Wu, Sen Yang, Xiyue Wang, Xiaohan Xing, Linlin Shen

Recent advancements in computational pathology have produced patch-level
Multi-modal Large Language Models (MLLMs), but these models are limited by
their inability to analyze whole slide images (WSIs) comprehensively and their
tendency to bypass crucial morphological features that pathologists rely on for
diagnosis. To address these challenges, we first introduce WSI-Bench, a
large-scale morphology-aware benchmark containing 180k VQA pairs from 9,850
WSIs across 30 cancer types, designed to evaluate MLLMs' understanding of
morphological characteristics crucial for accurate diagnosis. Building upon
this benchmark, we present WSI-LLaVA, a novel framework for gigapixel WSI
understanding that employs a three-stage training approach: WSI-text alignment,
feature space alignment, and task-specific instruction tuning. To better assess
model performance in pathological contexts, we develop two specialized WSI
metrics: WSI-Precision and WSI-Relevance. Experimental results demonstrate that
WSI-LLaVA outperforms existing models across all capability dimensions, with a
significant improvement in morphological analysis, establishing a clear
correlation between morphological understanding and diagnostic accuracy.

摘要：近期在計算病理學的進展中，產生了區塊層級的多模態大型語言模型 (MLLM)，但這些模型的限制在於無法全面分析全切片影像 (WSI)，且傾向於忽略病理學家在診斷時依賴的重要形態特徵。為了應對這些挑戰，我們首先推出 WSI-Bench，一個大型且重視形態的基準，包含來自 30 種癌症類型、9,850 個 WSI 的 18 萬個 VQA 配對，旨在評估 MLLM 對形態特徵的理解，這些特徵對於準確診斷至關重要。在此基準之上，我們提出 WSI-LLaVA，一個用於理解吉像素 WSI 的新框架，採用三階段訓練方法：WSI-文本比對、特徵空間比對和特定任務指令調整。為了在病理學背景下更好地評估模型效能，我們開發了兩個專門的 WSI 指標：WSI-精準度和 WSI-相關性。實驗結果表明，WSI-LLaVA 在所有效能面向都優於現有模型，在形態分析方面有顯著的進步，確立了形態理解與診斷準確性之間的明確關聯性。

##### **Misalignment of Semantic Relation Knowledge between WordNet and Human Intuition**
2412.02138v1 by Zhihan Cao, Hiroaki Yamada, Simone Teufel, Takenobu Tokunaga

WordNet provides a carefully constructed repository of semantic relations,
created by specialists. But there is another source of information on semantic
relations, the intuition of language users. We present the first systematic
study of the degree to which these two sources are aligned. Investigating the
cases of misalignment could make proper use of WordNet and facilitate its
improvement. Our analysis which uses templates to elicit responses from human
participants, reveals a general misalignment of semantic relation knowledge
between WordNet and human intuition. Further analyses find a systematic pattern
of mismatch among synonymy and taxonomic relations~(hypernymy and hyponymy),
together with the fact that WordNet path length does not serve as a reliable
indicator of human intuition regarding hypernymy or hyponymy relations.

摘要：WordNet 提供了一個由專家建立的語義關係資料庫，內容經過仔細建構。但語義關係還有另一個資訊來源，也就是語言使用者的直覺。我們提出了第一個系統性研究，探討這兩個來源的對齊程度。研究對齊不佳的案例，可以妥善利用 WordNet 並促進其改進。我們的分析使用範本來引導人類參與者提供回應，結果顯示 WordNet 與人類直覺之間的語義關係知識存在普遍的不對齊。進一步的分析發現同義詞和分類關係（上位詞和下位詞）之間存在系統性的不匹配模式，此外，WordNet 路徑長度並非人類直覺對於上位詞或下位詞關係的可靠指標。

##### **Benchmarking symbolic regression constant optimization schemes**
2412.02126v1 by L. G. A dos Reis, V. L. P. S. Caminha, T. J. P. Penna

Symbolic regression is a machine learning technique, and it has seen many
advancements in recent years, especially in genetic programming approaches
(GPSR). Furthermore, it has been known for many years that constant
optimization of parameters, during the evolutionary search, greatly increases
GPSR performance However, different authors approach such tasks differently and
no consensus exists regarding which methods perform best. In this work, we
evaluate eight different parameter optimization methods, applied during
evolutionary search, over ten known benchmark problems, in two different
scenarios. We also propose using an under-explored metric called Tree Edit
Distance (TED), aiming to identify symbolic accuracy. In conjunction with
classical error measures, we develop a combined analysis of model performance
in symbolic regression. We then show that different constant optimization
methods perform better in certain scenarios and that there is no overall best
choice for every problem. Finally, we discuss how common metric decisions may
be biased and appear to generate better models in comparison.

摘要：符號回歸是一種機器學習技術，近年來已在遺傳程式設計方法 (GPSR) 中獲得許多進展。此外，多年來眾所周知，在演化搜尋期間持續最佳化參數會大幅提升 GPSR 效能。然而，不同的作者以不同的方式處理此類任務，對於哪種方法效能最佳尚未達成共識。在這項研究中，我們評估在演化搜尋期間應用的八種不同的參數最佳化方法，針對十個已知的基準問題，在兩種不同的情境中進行評估。我們也建議使用一種稱為樹狀編輯距離 (TED) 的未充分探討量度，目標是找出符號精確度。結合傳統的誤差量度，我們針對符號回歸中的模型效能進行綜合分析。接著我們顯示，不同的常數最佳化方法在特定情境中效能較佳，而且對於每個問題並無整體最佳選擇。最後，我們討論常見的量度決策如何產生偏誤，並在比較中呈現出較佳的模型。

##### **OmniCreator: Self-Supervised Unified Generation with Universal Editing**
2412.02114v1 by Haodong Chen, Lan Wang, Harry Yang, Ser-Nam Lim

We introduce OmniCreator, a novel framework that can conduct text-prompted
unified (image+video) generation as well as editing all in one place.
OmniCreator acquires generative and universal editing capabilities in a
self-supervised manner, taking original text-video pairs as conditions while
utilizing the same video as a denoising target to learn the semantic
correspondence between video and text. During inference, when presented with a
text prompt and a video, OmniCreator is capable of generating a target that is
faithful to both, achieving a universal editing effect that is unconstrained as
opposed to existing editing work that primarily focuses on certain editing
types or relies on additional controls (e.g., structural conditions, attention
features, or DDIM inversion). On the other hand, when presented with a text
prompt only, OmniCreator becomes generative, producing high-quality video as a
result of the semantic correspondence learned. Importantly, we found that the
same capabilities extend to images as is, making OmniCreator a truly unified
framework. Further, due to the lack of existing generative video editing
benchmarks, we introduce the OmniBench-99 dataset, designed to evaluate the
performance of generative video editing models comprehensively. Extensive
experiments demonstrate that OmniCreator exhibits substantial superiority over
all other models.

摘要：<paragraph>我們介紹 OmniCreator，一種新穎的框架，它可以在一個地方執行文字提示的統一（影像 + 影片）生成以及編輯。OmniCreator 以自監督的方式獲得生成和通用編輯功能，將原始文字影片對作為條件，同時利用相同的影片作為去噪目標，以學習影片和文字之間的語義對應。在推理期間，當提供文字提示和影片時，OmniCreator 能夠生成一個忠於兩者的目標，實現通用編輯效果，不受現有編輯工作的限制，而現有編輯工作主要集中在某些編輯類型或依賴額外的控制（例如結構條件、注意特徵或 DDIM 反演）。另一方面，當僅提供文字提示時，OmniCreator 會變得具有生成性，產生高品質的影片，這是因為學習到的語義對應。重要的是，我們發現相同的機能也延伸到影像，使 OmniCreator 成為一個真正的統一框架。此外，由於缺乏現有的生成影片編輯基準，我們引入了 OmniBench-99 資料集，旨在全面評估生成影片編輯模型的效能。廣泛的實驗證明，OmniCreator 在所有其他模型中表現出顯著的優越性。</paragraph>

##### **Trust & Safety of LLMs and LLMs in Trust & Safety**
2412.02113v1 by Doohee You, Dan Chon

In recent years, Large Language Models (LLMs) have garnered considerable
attention for their remarkable abilities in natural language processing tasks.
However, their widespread adoption has raised concerns pertaining to trust and
safety. This systematic review investigates the current research landscape on
trust and safety in LLMs, with a particular focus on the novel application of
LLMs within the field of Trust and Safety itself. We delve into the
complexities of utilizing LLMs in domains where maintaining trust and safety is
paramount, offering a consolidated perspective on this emerging trend.\
  By synthesizing findings from various studies, we identify key challenges and
potential solutions, aiming to benefit researchers and practitioners seeking to
understand the nuanced interplay between LLMs and Trust and Safety.
  This review provides insights on best practices for using LLMs in Trust and
Safety, and explores emerging risks such as prompt injection and jailbreak
attacks. Ultimately, this study contributes to a deeper understanding of how
LLMs can be effectively and responsibly utilized to enhance trust and safety in
the digital realm.

摘要：近年來，大型語言模型 (LLM) 因其在自然語言處理任務中的卓越能力而備受關注。然而，它們的廣泛採用引發了關於信任和安全的擔憂。這項系統性回顧調查了 LLM 中信任和安全方面的當前研究現況，特別關注 LLM 在信任和安全領域本身的新穎應用。我們深入探討在維護信任和安全至關重要的領域中利用 LLM 的複雜性，對這一新興趨勢提供了綜合觀點。
通過綜合各種研究的發現，我們找出關鍵挑戰和潛在解決方案，旨在讓尋求了解 LLM 與信任和安全之間細微交互作用的研究人員和從業者受益。
本回顧提供了在信任和安全中使用 LLM 的最佳實務見解，並探討了提示注入和越獄攻擊等新興風險。最終，這項研究有助於更深入地了解如何有效且負責任地利用 LLM 來增強數位領域的信任和安全。

##### **Explainable and Interpretable Multimodal Large Language Models: A Comprehensive Survey**
2412.02104v1 by Yunkai Dang, Kaichen Huang, Jiahao Huo, Yibo Yan, Sirui Huang, Dongrui Liu, Mengxi Gao, Jie Zhang, Chen Qian, Kun Wang, Yong Liu, Jing Shao, Hui Xiong, Xuming Hu

The rapid development of Artificial Intelligence (AI) has revolutionized
numerous fields, with large language models (LLMs) and computer vision (CV)
systems driving advancements in natural language understanding and visual
processing, respectively. The convergence of these technologies has catalyzed
the rise of multimodal AI, enabling richer, cross-modal understanding that
spans text, vision, audio, and video modalities. Multimodal large language
models (MLLMs), in particular, have emerged as a powerful framework,
demonstrating impressive capabilities in tasks like image-text generation,
visual question answering, and cross-modal retrieval. Despite these
advancements, the complexity and scale of MLLMs introduce significant
challenges in interpretability and explainability, essential for establishing
transparency, trustworthiness, and reliability in high-stakes applications.
This paper provides a comprehensive survey on the interpretability and
explainability of MLLMs, proposing a novel framework that categorizes existing
research across three perspectives: (I) Data, (II) Model, (III) Training \&
Inference. We systematically analyze interpretability from token-level to
embedding-level representations, assess approaches related to both architecture
analysis and design, and explore training and inference strategies that enhance
transparency. By comparing various methodologies, we identify their strengths
and limitations and propose future research directions to address unresolved
challenges in multimodal explainability. This survey offers a foundational
resource for advancing interpretability and transparency in MLLMs, guiding
researchers and practitioners toward developing more accountable and robust
multimodal AI systems.

摘要：<paragraph>人工智慧 (AI) 的快速發展，已經徹底改變了許多領域，其中大型語言模型 (LLM) 和電腦視覺 (CV) 系統分別推動了自然語言理解和視覺處理的進展。這些技術的融合催化了多模態 AI 的興起，實現了跨模態的豐富理解，涵蓋文字、視覺、音訊和視訊模態。特別是多模態大型語言模型 (MLLM)，已經成為一個強大的架構，在影像文字生成、視覺問題解答和跨模態檢索等任務中展現了令人印象深刻的能力。儘管有這些進展，MLLM 的複雜性和規模在可解釋性和可說明性方面帶來了重大的挑戰，而這對於在高風險應用中建立透明度、可信度和可靠性至關重要。本文提供了對 MLLM 的可解釋性和可說明性的全面調查，提出了一個新的架構，將現有的研究分為三個觀點：(I) 資料、(II) 模型、(III) 訓練和推理。我們系統地分析了從符號層級到嵌入層級的表示的可解釋性，評估與架構分析和設計相關的方法，並探討了增強透明度的訓練和推理策略。透過比較各種方法，我們找出它們的優點和限制，並提出未來的研究方向，以解決多模態可說明性中尚未解決的挑戰。本調查提供了一個基礎資源，用於推進 MLLM 的可解釋性和透明度，引導研究人員和實務人員開發更負責任、更強大的多模態 AI 系統。</paragraph>

##### **Improving Language Transfer Capability of Decoder-only Architecture in Multilingual Neural Machine Translation**
2412.02101v1 by Zhi Qu, Yiran Wang, Chenchen Ding, Hideki Tanaka, Masao Utiyama, Taro Watanabe

Existing multilingual neural machine translation (MNMT) approaches mainly
focus on improving models with the encoder-decoder architecture to translate
multiple languages. However, decoder-only architecture has been explored less
in MNMT due to its underperformance when trained on parallel data solely. In
this work, we attribute the issue of the decoder-only architecture to its lack
of language transfer capability. Specifically, the decoder-only architecture is
insufficient in encoding source tokens with the target language features. We
propose dividing the decoding process into two stages so that target tokens are
explicitly excluded in the first stage to implicitly boost the transfer
capability across languages. Additionally, we impose contrastive learning on
translation instructions, resulting in improved performance in zero-shot
translation. We conduct experiments on TED-19 and OPUS-100 datasets,
considering both training from scratch and fine-tuning scenarios. Experimental
results show that, compared to the encoder-decoder architecture, our methods
not only perform competitively in supervised translations but also achieve
improvements of up to 3.39 BLEU, 6.99 chrF++, 3.22 BERTScore, and 4.81 COMET in
zero-shot translations.

摘要：現有的多語言神經機器翻譯 (MNMT) 方法主要專注於改進具有編碼器-解碼器架構的模型，以翻譯多種語言。然而，由於僅在平行數據上訓練時效能不佳，因此在 MNMT 中較少探討僅解碼器架構。在這項工作中，我們將僅解碼器架構的問題歸因於其缺乏語言轉移能力。具體來說，僅解碼器架構不足以使用目標語言功能對源代幣進行編碼。我們建議將解碼過程分為兩個階段，以便在第一階段明確排除目標代幣，從而隱式提升跨語言的轉移能力。此外，我們對翻譯說明施加對比學習，從而提高零次學習翻譯的效能。我們在 TED-19 和 OPUS-100 資料集上進行實驗，同時考慮從頭訓練和微調場景。實驗結果表明，與編碼器-解碼器架構相比，我們的模型不僅在監督式翻譯中具有競爭力，而且在零次學習翻譯中，BLEU、chrF++、BERTScore 和 COMET 分別提高了 3.39、6.99、3.22 和 4.81。

##### **AccDiffusion v2: Towards More Accurate Higher-Resolution Diffusion Extrapolation**
2412.02099v1 by Zhihang Lin, Mingbao Lin, Wengyi Zhan, Rongrong Ji

Diffusion models suffer severe object repetition and local distortion when
the inference resolution differs from its pre-trained resolution. We propose
AccDiffusion v2, an accurate method for patch-wise higher-resolution diffusion
extrapolation without training. Our in-depth analysis in this paper shows that
using an identical text prompt for different patches leads to repetitive
generation, while the absence of a prompt undermines image details. In
response, our AccDiffusion v2 novelly decouples the vanilla image-content-aware
prompt into a set of patch-content-aware prompts, each of which serves as a
more precise description of a patch. Further analysis reveals that local
distortion arises from inaccurate descriptions in prompts about the local
structure of higher-resolution images. To address this issue, AccDiffusion v2,
for the first time, introduces an auxiliary local structural information
through ControlNet during higher-resolution diffusion extrapolation aiming to
mitigate the local distortions. Finally, our analysis indicates that global
semantic information is conducive to suppressing both repetitive generation and
local distortion. Hence, our AccDiffusion v2 further proposes dilated sampling
with window interaction for better global semantic information during
higher-resolution diffusion extrapolation. We conduct extensive experiments,
including both quantitative and qualitative comparisons, to demonstrate the
efficacy of our AccDiffusion v2. The quantitative comparison shows that
AccDiffusion v2 achieves state-of-the-art performance in image generation
extrapolation without training. The qualitative comparison intuitively
illustrates that AccDiffusion v2 effectively suppresses the issues of
repetitive generation and local distortion in image generation extrapolation.
Our code is available at \url{https://github.com/lzhxmu/AccDiffusion_v2}.

摘要：擴散模型在推論解析度與預訓練解析度不同時，會出現嚴重的物件重複和局部扭曲。我們提出 AccDiffusion v2，這是一種準確的方法，可進行區塊式高解析度擴散外推，無需訓練。我們在本文中的深入分析顯示，對不同的區塊使用相同的文字提示會導致重複產生，而沒有提示會損害影像細節。為了解決此問題，我們的 AccDiffusion v2 新穎地將香草影像內容感知提示解耦為一組區塊內容感知提示，每個提示都是一個區塊的更精確描述。進一步的分析表明，局部扭曲是由於提示中對高解析度影像局部結構的不準確描述造成的。為了解決這個問題，AccDiffusion v2 首次在高解析度擴散外推過程中透過 ControlNet 引入了輔助局部結構資訊，旨在減輕局部扭曲。最後，我們的分析表明，全局語義資訊有助於抑制重複產生和局部扭曲。因此，我們的 AccDiffusion v2 進一步提出了擴充採樣和視窗互動，以在高解析度擴散外推過程中獲得更好的全局語義資訊。我們進行了廣泛的實驗，包括量化和質化比較，以證明我們的 AccDiffusion v2 的效能。量化比較顯示，AccDiffusion v2 在影像產生外推中達到了最先進的效能，無需訓練。質化比較直觀地說明了 AccDiffusion v2 有效地抑制了影像產生外推中重複產生和局部扭曲的問題。我們的程式碼可在 \url{https://github.com/lzhxmu/AccDiffusion_v2} 取得。

##### **Evolution of Collective AI Beyond Individual Optimization**
2412.02085v1 by Ryosuke Takata, Yujin Tang, Yingtao Tian, Norihiro Maruyama, Hiroki Kojima, Takashi Ikegami

This study investigates collective behaviors that emerge from a group of
homogeneous individuals optimized for a specific capability. We created a group
of simple, identical neural network based agents modeled after
chemotaxis-driven vehicles that follow pheromone trails and examined
multi-agent simulations using clones of these evolved individuals. Our results
show that the evolution of individuals led to population differentiation.
Surprisingly, we observed that collective fitness significantly changed during
later evolutionary stages, despite maintained high individual performance and
simplified neural architectures. This decline occurred when agents developed
reduced sensor-motor coupling, suggesting that over-optimization of individual
agents almost always lead to less effective group behavior. Our research
investigates how individual differentiation can evolve through what
evolutionary pathways.

摘要：本研究探討從一群針對特定能力最佳化的同質個體中出現的集體行為。我們建立了一組簡單、相同的類神經網路，根據化學趨性驅動的載具建模，這些載具遵循費洛蒙軌跡，並使用這些演化個體的複製體檢查多主體模擬。我們的結果顯示，個體的演化導致了族群分化。令人驚訝的是，我們觀察到集體適應度在後期的演化階段發生顯著變化，儘管維持了高個體表現和簡化的神經結構。當主體發展出較弱的感測器-運動耦合時，發生了這種衰退，這表明個體主體的過度最佳化幾乎總是導致較無效的群體行為。我們的研究探討了個體分化如何透過哪些演化途徑演化。

##### **Comparative Analysis of Black-Box and White-Box Machine Learning Model in Phishing Detection**
2412.02084v1 by Abdullah Fajar, Setiadi Yazid, Indra Budi

Background: Explainability in phishing detection model can support a further
solution of phishing attack mitigation by increasing trust and understanding
how phishing can be detected. Objective: The aims of this study to determine
and best recommendation to apply an approach which has several components with
abilities to fulfil the critical needs Methods: A methodology starting with
analyzing both black-box and white-box models to get the pros and cons
specifically in phishing detection. The conclusion of the analysis will be
validated by experiment using a set of well-known algorithms and public
phishing datasets. Experimental metrics covers 3 measurements such as
predictive accuracy and explainability metrics. Conclusion: Both models are
comparable in terms of interpretability and consistency, with room for
improvement in diverse datasets. EBM as an example of white-box model is
generally better suited for applications requiring explainability and
actionable insights. Finally, each model, white-box and black-box model has
positive and negative aspects both for performance metric and for explainable
metric. It is important to consider the objective of model usage.

摘要：背景：網路釣魚偵測模型中的可解釋性可以支援進一步的網路釣魚攻擊緩解解決方案，方法是增加信任度並了解如何偵測網路釣魚。目標：本研究的目標是決定並最佳建議應用一種方法，該方法具有多項組成部分，具備滿足關鍵需求的能力。方法：一種方法從分析黑盒和白盒模型開始，以獲得利弊，特別是在網路釣魚偵測中。分析結論將透過使用一組眾所周知的演算法和公開網路釣魚資料集進行實驗驗證。實驗指標涵蓋 3 項測量，例如預測準確度和可解釋性指標。結論：這兩種模型在可解釋性和一致性方面具有可比性，在不同的資料集中有改進空間。EBM 作為白盒模型的一個範例，通常更適合需要可解釋性和可行見解的應用程式。最後，白盒模型和黑盒模型這兩種模型在效能指標和可解釋指標方面都有正面和負面面向。考慮模型使用的目標非常重要。

##### **Implementing An Artificial Quantum Perceptron**
2412.02083v1 by Ashutosh Hathidara, Lalit Pandey

A Perceptron is a fundamental building block of a neural network. The
flexibility and scalability of perceptron make it ubiquitous in building
intelligent systems. Studies have shown the efficacy of a single neuron in
making intelligent decisions. Here, we examined and compared two perceptrons
with distinct mechanisms, and developed a quantum version of one of those
perceptrons. As a part of this modeling, we implemented the quantum circuit for
an artificial perception, generated a dataset, and simulated the training.
Through these experiments, we show that there is an exponential growth
advantage and test different qubit versions. Our findings show that this
quantum model of an individual perceptron can be used as a pattern classifier.
For the second type of model, we provide an understanding to design and
simulate a spike-dependent quantum perceptron. Our code is available at
\url{https://github.com/ashutosh1919/quantum-perceptron}

摘要：感知器是神经網路的基本組成部分。感知器的靈活性與可擴充性使其在建構智慧系統時無所不在。研究已顯示單一神經元在做出智慧決策時的效能。在此，我們檢視並比較了兩種具有不同機制的感知器，並開發了其中一種感知器的量子版本。作為此建模的一部分，我們實作了人工感知的量子電路，生成了資料集，並模擬了訓練。透過這些實驗，我們顯示出有指數成長的優勢，並測試了不同的量子位元版本。我們的研究結果顯示，這種個別感知器的量子模型可用作模式分類器。對於第二種類型的模型，我們提供了解，以設計和模擬尖峰依賴量子感知器。我們的程式碼可於\url{https://github.com/ashutosh1919/quantum-perceptron}取得

##### **Let's Think Var-by-Var: Large Language Models Enable Ad Hoc Probabilistic Reasoning**
2412.02081v1 by Shepard Xia, Brian Lu, Jason Eisner

A hallmark of intelligence is the ability to flesh out underspecified
situations using "common sense." We propose to extract that common sense from
large language models (LLMs), in a form that can feed into probabilistic
inference. We focus our investigation on $\textit{guesstimation}$ questions
such as "How much are Airbnb listings in Newark, NJ?" Formulating a sensible
answer without access to data requires drawing on, and integrating, bits of
common knowledge about how $\texttt{Price}$ and $\texttt{Location}$ may relate
to other variables, such as $\texttt{Property Type}$. Our framework answers
such a question by synthesizing an $\textit{ad hoc}$ probabilistic model. First
we prompt an LLM to propose a set of random variables relevant to the question,
followed by moment constraints on their joint distribution. We then optimize
the joint distribution $p$ within a log-linear family to maximize the overall
constraint satisfaction. Our experiments show that LLMs can successfully be
prompted to propose reasonable variables, and while the proposed numerical
constraints can be noisy, jointly optimizing for their satisfaction reconciles
them. When evaluated on probabilistic questions derived from three real-world
tabular datasets, we find that our framework performs comparably to a direct
prompting baseline in terms of total variation distance from the dataset
distribution, and is similarly robust to noise.

摘要：智能的标志是能够运用「常识」来充实未明确说明的情况。我们提议从大型语言模型 (LLM) 中提取常识，并将其转换成可供概率推理使用的形式。我们专注于调查「估算」问题，例如「新泽西州纽瓦克的 Airbnb 房源价格是多少？」。在没有数据的情况下 формулировать разумный ответ需要利用并整合关于 $\texttt{Price}$ 和 $\texttt{Location}$ 如何与其他变量（例如 $\texttt{Property Type}$）相关的零碎常识。我们的框架通过综合一个 $\textit{ad hoc}$ 概率模型来回答此类问题。首先，我们提示 LLM 提出一组与问题相关的随机变量，然后对其联合分布施加矩约束。然后，我们在对数线性族中优化联合分布 $p$，以最大化整体约束满足度。我们的实验表明，可以成功提示 LLM 提出合理的变量，并且虽然提出的数值约束可能会产生噪声，但对它们的满足度进行联合优化可以协调它们。在根据三个真实世界表格数据集派生的概率问题进行评估时，我们发现我们的框架在与数据集分布的总变异距离方面与直接提示基线表现相当，并且对噪声具有类似的鲁棒性。

##### **Construction and optimization of health behavior prediction model for the elderly in smart elderly care**
2412.02062v1 by Qian Guo, Peiyuan Chen

With the intensification of global aging, health management of the elderly
has become a focus of social attention. This study designs and implements a
smart elderly care service model to address issues such as data diversity,
health status complexity, long-term dependence and data loss, sudden changes in
behavior, and data privacy in the prediction of health behaviors of the
elderly. The model achieves accurate prediction and dynamic management of
health behaviors of the elderly through modules such as multimodal data fusion,
data loss processing, nonlinear prediction, emergency detection, and privacy
protection. In the experimental design, based on multi-source data sets and
market research results, the model demonstrates excellent performance in health
behavior prediction, emergency detection, and personalized services. The
experimental results show that the model can effectively improve the accuracy
and robustness of health behavior prediction and meet the actual application
needs in the field of smart elderly care. In the future, with the integration
of more data and further optimization of technology, the model will provide
more powerful technical support for smart elderly care services.

摘要：隨著全球高齡化加劇，老年人的健康管理已成為社會關注的焦點。本研究設計並實作一個智慧老人照護服務模型，以解決老人健康行為預測中的資料異質性、健康狀態複雜性、長期依賴性與資料流失、行為突變、資料隱私等問題。該模型透過多模態資料融合、資料流失處理、非線性預測、緊急事件偵測、隱私保護等模組，達到老人健康行為的精準預測與動態管理。在實驗設計上，基於多來源資料集與市場調查結果，該模型在健康行為預測、緊急事件偵測、個人化服務等方面均展現出優異的表現。實驗結果顯示，該模型能有效提升健康行為預測的準確性與魯棒性，並滿足智慧老人照護領域的實際應用需求。未來隨著更多資料的整合與技術的進一步優化，該模型將為智慧老人照護服務提供更強大的技術支撐。

##### **BN-AuthProf: Benchmarking Machine Learning for Bangla Author Profiling on Social Media Texts**
2412.02058v1 by Raisa Tasnim, Mehanaz Chowdhury, Md Ataur Rahman

Author profiling, the analysis of texts to uncover attributes such as gender
and age of the author, has become essential with the widespread use of social
media platforms. This paper focuses on author profiling in the Bangla language,
aiming to extract valuable insights about anonymous authors based on their
writing style on social media. The primary objective is to introduce and
benchmark the performance of machine learning approaches on a newly created
Bangla Author Profiling dataset, BN-AuthProf. The dataset comprises 30,131
social media posts from 300 authors, labeled by their age and gender. Authors'
identities and sensitive information were anonymized to ensure privacy. Various
classical machine learning and deep learning techniques were employed to
evaluate the dataset. For gender classification, the best accuracy achieved was
80% using Support Vector Machine (SVM), while a Multinomial Naive Bayes (MNB)
classifier achieved the best F1 score of 0.756. For age classification, MNB
attained a maximum accuracy score of 91% with an F1 score of 0.905. This
research highlights the effectiveness of machine learning in gender and age
classification for Bangla author profiling, with practical implications
spanning marketing, security, forensic linguistics, education, and criminal
investigations, considering privacy and biases.

摘要：作者描繪，文本分析以揭露作者的屬性，例如性別
與年齡，已隨著社群媒體平台的廣泛使用而變得必要。本文專注於孟加拉語的作者描繪，
旨在根據作者在社群媒體上的寫作風格，萃取關於匿名作者的寶貴見解。主要目標是介紹並
基準機器學習方法在一個新建立的孟加拉語作者描繪資料集 BN-AuthProf 上的表現。資料集包含來自 300 位作者的 30,131 篇社群媒體貼文，並標記了他們的年齡和性別。作者的
身分和敏感資訊已匿名化以確保隱私。採用了各種傳統機器學習和深度學習技術來
評估資料集。對於性別分類，使用支援向量機 (SVM) 達到了 80% 的最佳準確度，而多項式樸素貝氏 (MNB)
分類器達到了 0.756 的最佳 F1 分數。對於年齡分類，MNB 達到了 91% 的最大準確度分數，F1 分數為 0.905。本
研究強調了機器學習在孟加拉語作者描繪中的性別和年齡分類的有效性，並考慮了隱私和偏差，涵蓋了行銷、安全、法庭語言學、教育和犯罪
調查的實際應用。

##### **A Multi-way Parallel Named Entity Annotated Corpus for English, Tamil and Sinhala**
2412.02056v1 by Surangika Ranathunga, Asanka Ranasinghea, Janaka Shamala, Ayodya Dandeniyaa, Rashmi Galappaththia, Malithi Samaraweeraa

This paper presents a multi-way parallel English-Tamil-Sinhala corpus
annotated with Named Entities (NEs), where Sinhala and Tamil are low-resource
languages. Using pre-trained multilingual Language Models (mLMs), we establish
new benchmark Named Entity Recognition (NER) results on this dataset for
Sinhala and Tamil. We also carry out a detailed investigation on the NER
capabilities of different types of mLMs. Finally, we demonstrate the utility of
our NER system on a low-resource Neural Machine Translation (NMT) task. Our
dataset is publicly released: https://github.com/suralk/multiNER.

摘要：本文提出了一个多向並行的英語-泰米爾語-僧伽羅語語料庫，其中註解了命名實體 (NE)，而僧伽羅語和泰米爾語是低資源語言。使用預先訓練的多語言語言模型 (mLMs)，我們在這個資料集上為僧伽羅語和泰米爾語建立了新的基準命名實體識別 (NER) 結果。我們還對不同類型 mLMs 的 NER 能力進行了詳細調查。最後，我們展示了我們的 NER 系統在低資源神經機器翻譯 (NMT) 任務中的效用。我們的資料集已公開發布：https://github.com/suralk/multiNER。

##### **Impact of Data Snooping on Deep Learning Models for Locating Vulnerabilities in Lifted Code**
2412.02048v1 by Gary A. McCully, John D. Hastings, Shengjie Xu

This study examines the impact of data snooping on neural networks for
vulnerability detection in lifted code, building on previous research which
used word2vec, and unidirectional and bidirectional transformer-based
embeddings. The research specifically focuses on how model performance is
affected when embedding models are trained on datasets, including samples also
used for neural network training and validation. The results show that
introducing data snooping did not significantly alter model performance,
suggesting that data snooping had a minimal impact or that samples randomly
dropped as part of the methodology contained hidden features critical to
achieving optimal performance. In addition, the findings reinforce the
conclusions of previous research, which found that models trained with GPT-2
embeddings consistently outperformed neural networks trained with other
embeddings. The fact that this holds even when data snooping is introduced into
the embedding model indicates GPT-2's robustness in representing complex code
features, even under less-than-ideal conditions.

摘要：本研究探討了資料窺探對神經網路在提升程式碼中進行漏洞偵測的影響，並建立在先前使用 word2vec、單向和雙向轉換器為基礎的嵌入式研究上。研究特別關注在嵌入模型於資料集上進行訓練時，模型效能如何受到影響，其中包含用於神經網路訓練和驗證的範例。結果顯示，引入資料窺探並未顯著改變模型效能，這表示資料窺探的影響很小，或是作為方法論一部分而隨機刪除的範例包含了達成最佳效能所不可或缺的隱藏特徵。此外，這些發現強化了先前研究的結論，即使用 GPT-2 嵌入訓練的模型始終優於使用其他嵌入訓練的神經網路。即使在嵌入模型中引入資料窺探，這項發現仍然成立，這表示 GPT-2 在表示複雜程式碼特徵方面具有穩健性，即使在不理想的條件下也是如此。

##### **Future of Information Retrieval Research in the Age of Generative AI**
2412.02043v1 by James Allan, Eunsol Choi, Daniel P. Lopresti, Hamed Zamani

In the fast-evolving field of information retrieval (IR), the integration of
generative AI technologies such as large language models (LLMs) is transforming
how users search for and interact with information. Recognizing this paradigm
shift at the intersection of IR and generative AI (IR-GenAI), a visioning
workshop supported by the Computing Community Consortium (CCC) was held in July
2024 to discuss the future of IR in the age of generative AI. This workshop
convened 44 experts in information retrieval, natural language processing,
human-computer interaction, and artificial intelligence from academia,
industry, and government to explore how generative AI can enhance IR and vice
versa, and to identify the major challenges and opportunities in this rapidly
advancing field.
  This report contains a summary of discussions as potentially important
research topics and contains a list of recommendations for academics, industry
practitioners, institutions, evaluation campaigns, and funding agencies.

摘要：在快速演進的資訊檢索 (IR) 領域中，整合大型語言模型 (LLM) 等生成式 AI 技術，正在轉變使用者搜尋和與資訊互動的方式。為了了解 IR 和生成式 AI (IR-GenAI) 交會處的典範轉移，由運算社群聯盟 (CCC) 支持的願景工作坊於 2024 年 7 月舉行，以探討生成式 AI 時代的 IR 未來。此工作坊召集了來自學術界、產業和政府的 44 位資訊檢索、自然語言處理、人機互動和人工智慧專家，探討生成式 AI 如何增強 IR，反之亦然，並找出這個快速發展領域中的重大挑戰和機會。這份報告包含了討論摘要，作為潛在重要的研究主題，並包含一連串建議，提供給學術界、產業從業者、機構、評鑑活動和資助機構。

