{"2412.06693": {"publish_time": "2024-12-09", "title": "OmniEvalKit: A Modular, Lightweight Toolbox for Evaluating Large Language Model and its Omni-Extensions", "paper_summary": "The rapid advancements in Large Language Models (LLMs) have significantly\nexpanded their applications, ranging from multilingual support to\ndomain-specific tasks and multimodal integration. In this paper, we present\nOmniEvalKit, a novel benchmarking toolbox designed to evaluate LLMs and their\nomni-extensions across multilingual, multidomain, and multimodal capabilities.\nUnlike existing benchmarks that often focus on a single aspect, OmniEvalKit\nprovides a modular, lightweight, and automated evaluation system. It is\nstructured with a modular architecture comprising a Static Builder and Dynamic\nData Flow, promoting the seamless integration of new models and datasets.\nOmniEvalKit supports over 100 LLMs and 50 evaluation datasets, covering\ncomprehensive evaluations across thousands of model-dataset combinations.\nOmniEvalKit is dedicated to creating an ultra-lightweight and fast-deployable\nevaluation framework, making downstream applications more convenient and\nversatile for the AI community.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u5feb\u901f\u9032\u6b65\u5927\u5e45\u64f4\u5c55\u4e86\u5b83\u5011\u7684\u61c9\u7528\uff0c\u5f9e\u591a\u8a9e\u8a00\u652f\u63f4\u5230\u7279\u5b9a\u9818\u57df\u4efb\u52d9\u548c\u591a\u6a21\u614b\u6574\u5408\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa OmniEvalKit\uff0c\u9019\u662f\u4e00\u500b\u65b0\u7a4e\u7684\u57fa\u6e96\u6e2c\u8a66\u5de5\u5177\u7bb1\uff0c\u65e8\u5728\u8a55\u4f30 LLM \u53ca\u5176\u5728\u591a\u8a9e\u8a00\u3001\u591a\u9818\u57df\u548c\u591a\u6a21\u614b\u80fd\u529b\u4e0a\u7684\u5168\u65b9\u4f4d\u64f4\u5c55\u3002\u8207\u901a\u5e38\u53ea\u95dc\u6ce8\u55ae\u4e00\u65b9\u9762\u7684\u73fe\u6709\u57fa\u6e96\u6e2c\u8a66\u4e0d\u540c\uff0cOmniEvalKit \u63d0\u4f9b\u4e86\u4e00\u500b\u6a21\u7d44\u5316\u3001\u8f15\u91cf\u5316\u4e14\u81ea\u52d5\u5316\u7684\u8a55\u4f30\u7cfb\u7d71\u3002\u5b83\u63a1\u7528\u6a21\u7d44\u5316\u67b6\u69cb\uff0c\u5305\u542b\u975c\u614b\u5efa\u69cb\u5668\u548c\u52d5\u614b\u8cc7\u6599\u6d41\u7a0b\uff0c\u4fc3\u9032\u65b0\u6a21\u578b\u548c\u8cc7\u6599\u96c6\u7684\u7121\u7e2b\u6574\u5408\u3002OmniEvalKit \u652f\u63f4\u8d85\u904e 100 \u500b LLM \u548c 50 \u500b\u8a55\u4f30\u8cc7\u6599\u96c6\uff0c\u6db5\u84cb\u6578\u5343\u500b\u6a21\u578b\u8cc7\u6599\u96c6\u7d44\u5408\u7684\u5168\u9762\u8a55\u4f30\u3002OmniEvalKit \u81f4\u529b\u65bc\u5efa\u7acb\u4e00\u500b\u8d85\u8f15\u91cf\u7d1a\u4e14\u5feb\u901f\u90e8\u7f72\u7684\u8a55\u4f30\u67b6\u69cb\uff0c\u8b93\u4e0b\u6e38\u61c9\u7528\u7a0b\u5f0f\u5c0d AI \u793e\u7fa4\u4f86\u8aaa\u66f4\u52a0\u4fbf\u5229\u4e14\u591a\u529f\u80fd\u3002", "author": "Yi-Kai Zhang et.al.", "authors": "Yi-Kai Zhang, Xu-Xiang Zhong, Shiyin Lu, Qing-Guo Chen, De-Chuan Zhan, Han-Jia Ye", "id": "2412.06693v1", "paper_url": "http://arxiv.org/abs/2412.06693v1", "repo": "null"}}