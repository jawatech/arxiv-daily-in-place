{"2501.01691": {"publish_time": "2025-01-03", "title": "VidFormer: A novel end-to-end framework fused by 3DCNN and Transformer for Video-based Remote Physiological Measurement", "paper_summary": "Remote physiological signal measurement based on facial videos, also known as\nremote photoplethysmography (rPPG), involves predicting changes in facial\nvascular blood flow from facial videos. While most deep learning-based methods\nhave achieved good results, they often struggle to balance performance across\nsmall and large-scale datasets due to the inherent limitations of convolutional\nneural networks (CNNs) and Transformer. In this paper, we introduce VidFormer,\na novel end-to-end framework that integrates 3-Dimension Convolutional Neural\nNetwork (3DCNN) and Transformer models for rPPG tasks. Initially, we conduct an\nanalysis of the traditional skin reflection model and subsequently introduce an\nenhanced model for the reconstruction of rPPG signals. Based on this improved\nmodel, VidFormer utilizes 3DCNN and Transformer to extract local and global\nfeatures from input data, respectively. To enhance the spatiotemporal feature\nextraction capabilities of VidFormer, we incorporate temporal-spatial attention\nmechanisms tailored for both 3DCNN and Transformer. Additionally, we design a\nmodule to facilitate information exchange and fusion between the 3DCNN and\nTransformer. Our evaluation on five publicly available datasets demonstrates\nthat VidFormer outperforms current state-of-the-art (SOTA) methods. Finally, we\ndiscuss the essential roles of each VidFormer module and examine the effects of\nethnicity, makeup, and exercise on its performance.", "paper_summary_zh": "\u57fa\u65bc\u9762\u90e8\u5f71\u7247\u7684\u9060\u7aef\u751f\u7406\u8a0a\u865f\u6e2c\u91cf\uff0c\u4e5f\u7a31\u70ba\u9060\u7aef\u5149\u96fb\u5bb9\u7a4d\u63cf\u8a18\u6cd5 (rPPG)\uff0c\u6d89\u53ca\u5f9e\u9762\u90e8\u5f71\u7247\u9810\u6e2c\u9762\u90e8\u8840\u7ba1\u8840\u6d41\u7684\u8b8a\u5316\u3002\u96d6\u7136\u5927\u591a\u6578\u57fa\u65bc\u6df1\u5ea6\u5b78\u7fd2\u7684\u65b9\u6cd5\u90fd\u7372\u5f97\u4e86\u826f\u597d\u7684\u7d50\u679c\uff0c\u4f46\u7531\u65bc\u5377\u7a4d\u795e\u7d93\u7db2\u8def (CNN) \u548c Transformer \u7684\u56fa\u6709\u9650\u5236\uff0c\u5b83\u5011\u901a\u5e38\u96e3\u4ee5\u5e73\u8861\u5c0f\u898f\u6a21\u548c\u5927\u578b\u8cc7\u6599\u96c6\u7684\u6548\u80fd\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u4ecb\u7d39 VidFormer\uff0c\u9019\u662f\u4e00\u500b\u6574\u5408 3D \u5377\u7a4d\u795e\u7d93\u7db2\u8def (3DCNN) \u548c Transformer \u6a21\u578b\u4ee5\u9032\u884c rPPG \u4efb\u52d9\u7684\u65b0\u578b\u7aef\u5c0d\u7aef\u67b6\u69cb\u3002\u6700\u521d\uff0c\u6211\u5011\u5c0d\u50b3\u7d71\u7684\u76ae\u819a\u53cd\u5c04\u6a21\u578b\u9032\u884c\u5206\u6790\uff0c\u96a8\u5f8c\u5f15\u5165\u4e00\u500b\u589e\u5f37\u6a21\u578b\u4f86\u91cd\u5efa rPPG \u8a0a\u865f\u3002\u57fa\u65bc\u9019\u500b\u6539\u9032\u7684\u6a21\u578b\uff0cVidFormer \u5206\u5225\u5229\u7528 3DCNN \u548c Transformer \u5f9e\u8f38\u5165\u8cc7\u6599\u4e2d\u63d0\u53d6\u5c40\u90e8\u548c\u5168\u57df\u7279\u5fb5\u3002\u70ba\u4e86\u589e\u5f37 VidFormer \u7684\u6642\u7a7a\u7279\u5fb5\u63d0\u53d6\u80fd\u529b\uff0c\u6211\u5011\u7d50\u5408\u4e86\u5c08\u9580\u91dd\u5c0d 3DCNN \u548c Transformer \u8a2d\u8a08\u7684\u6642\u7a7a\u6ce8\u610f\u529b\u6a5f\u5236\u3002\u6b64\u5916\uff0c\u6211\u5011\u8a2d\u8a08\u4e86\u4e00\u500b\u6a21\u7d44\u4f86\u4fc3\u9032 3DCNN \u548c Transformer \u4e4b\u9593\u7684\u8cc7\u8a0a\u4ea4\u63db\u548c\u878d\u5408\u3002\u6211\u5011\u5c0d\u4e94\u500b\u516c\u958b\u53ef\u7528\u7684\u8cc7\u6599\u96c6\u7684\u8a55\u4f30\u8868\u660e\uff0cVidFormer \u512a\u65bc\u76ee\u524d\u7684\u6700\u65b0\u6280\u8853 (SOTA) \u65b9\u6cd5\u3002\u6700\u5f8c\uff0c\u6211\u5011\u8a0e\u8ad6\u4e86 VidFormer \u5404\u500b\u6a21\u7d44\u7684\u57fa\u672c\u4f5c\u7528\uff0c\u4e26\u63a2\u8a0e\u4e86\u7a2e\u65cf\u3001\u5316\u599d\u548c\u904b\u52d5\u5c0d\u5176\u6548\u80fd\u7684\u5f71\u97ff\u3002", "author": "Jiachen Li et.al.", "authors": "Jiachen Li, Shisheng Guo, Longzhen Tang, Cuolong Cui, Lingjiang Kong, Xiaobo Yang", "id": "2501.01691v1", "paper_url": "http://arxiv.org/abs/2501.01691v1", "repo": "null"}}