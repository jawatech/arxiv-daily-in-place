{"2405.03958": {"publish_time": "2024-05-07", "title": "Simple Drop-in LoRA Conditioning on Attention Layers Will Improve Your Diffusion Model", "paper_summary": "Current state-of-the-art diffusion models employ U-Net architectures\ncontaining convolutional and (qkv) self-attention layers. The U-Net processes\nimages while being conditioned on the time embedding input for each sampling\nstep and the class or caption embedding input corresponding to the desired\nconditional generation. Such conditioning involves scale-and-shift operations\nto the convolutional layers but does not directly affect the attention layers.\nWhile these standard architectural choices are certainly effective, not\nconditioning the attention layers feels arbitrary and potentially suboptimal.\nIn this work, we show that simply adding LoRA conditioning to the attention\nlayers without changing or tuning the other parts of the U-Net architecture\nimproves the image generation quality. For example, a drop-in addition of LoRA\nconditioning to EDM diffusion model yields FID scores of 1.91/1.75 for\nunconditional and class-conditional CIFAR-10 generation, improving upon the\nbaseline of 1.97/1.79.", "paper_summary_zh": "\u76ee\u524d\u6700\u5148\u9032\u7684\u64f4\u6563\u6a21\u578b\u63a1\u7528 U-Net \u67b6\u69cb\uff0c\u5305\u542b\u5377\u7a4d\u548c (qkv) \u81ea\u6ce8\u610f\u529b\u5c64\u3002U-Net \u8655\u7406\u5f71\u50cf\u6642\uff0c\u6703\u6839\u64da\u6bcf\u500b\u63a1\u6a23\u6b65\u9a5f\u7684\u6642\u9593\u5167\u5d4c\u8f38\u5165\u548c\u5c0d\u61c9\u65bc\u6240\u9700\u689d\u4ef6\u5f0f\u751f\u6210\u7684\u985e\u5225\u6216\u6a19\u984c\u5167\u5d4c\u8f38\u5165\u9032\u884c\u8abf\u6574\u3002\u9019\u7a2e\u8abf\u6574\u6d89\u53ca\u5c0d\u5377\u7a4d\u5c64\u9032\u884c\u7e2e\u653e\u548c\u5e73\u79fb\u64cd\u4f5c\uff0c\u4f46\u4e0d\u6703\u76f4\u63a5\u5f71\u97ff\u6ce8\u610f\u529b\u5c64\u3002\u96d6\u7136\u9019\u4e9b\u6a19\u6e96\u67b6\u69cb\u9078\u64c7\u80af\u5b9a\u6709\u6548\uff0c\u4f46\u5c0d\u6ce8\u610f\u529b\u5c64\u4e0d\u9032\u884c\u8abf\u6574\u611f\u89ba\u5f88\u96a8\u610f\uff0c\u800c\u4e14\u6f5b\u5728\u6b21\u512a\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u5c55\u793a\u4e86\u50c5\u5c07 LoRA \u8abf\u6574\u65b0\u589e\u5230\u6ce8\u610f\u529b\u5c64\uff0c\u800c\u4e0d\u6703\u6539\u8b8a\u6216\u8abf\u6574 U-Net \u67b6\u69cb\u7684\u5176\u4ed6\u90e8\u5206\uff0c\u5c31\u80fd\u63d0\u5347\u5f71\u50cf\u751f\u6210\u54c1\u8cea\u3002\u4f8b\u5982\uff0c\u5c07 LoRA \u8abf\u6574\u65b0\u589e\u5230 EDM \u64f4\u6563\u6a21\u578b\u4e2d\uff0c\u5c31\u6703\u7522\u751f\u7121\u689d\u4ef6\u548c\u985e\u5225\u689d\u4ef6 CIFAR-10 \u751f\u6210\u7684 FID \u5206\u6578\u70ba 1.91/1.75\uff0c\u512a\u65bc 1.97/1.79 \u7684\u57fa\u6e96\u3002", "author": "Joo Young Choi et.al.", "authors": "Joo Young Choi, Jaesung R. Park, Inkyu Park, Jaewoong Cho, Albert No, Ernest K. Ryu", "id": "2405.03958v1", "paper_url": "http://arxiv.org/abs/2405.03958v1", "repo": "null"}}