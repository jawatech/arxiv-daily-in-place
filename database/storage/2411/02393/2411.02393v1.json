{"2411.02393": {"publish_time": "2024-11-04", "title": "Adaptive Length Image Tokenization via Recurrent Allocation", "paper_summary": "Current vision systems typically assign fixed-length representations to\nimages, regardless of the information content. This contrasts with human\nintelligence - and even large language models - which allocate varying\nrepresentational capacities based on entropy, context and familiarity. Inspired\nby this, we propose an approach to learn variable-length token representations\nfor 2D images. Our encoder-decoder architecture recursively processes 2D image\ntokens, distilling them into 1D latent tokens over multiple iterations of\nrecurrent rollouts. Each iteration refines the 2D tokens, updates the existing\n1D latent tokens, and adaptively increases representational capacity by adding\nnew tokens. This enables compression of images into a variable number of\ntokens, ranging from 32 to 256. We validate our tokenizer using reconstruction\nloss and FID metrics, demonstrating that token count aligns with image entropy,\nfamiliarity and downstream task requirements. Recurrent token processing with\nincreasing representational capacity in each iteration shows signs of token\nspecialization, revealing potential for object / part discovery.", "paper_summary_zh": "\u76ee\u524d\u7684\u8996\u89ba\u7cfb\u7d71\u901a\u5e38\u6703\u5c07\u56fa\u5b9a\u9577\u5ea6\u7684\u8868\u5fb5\u5206\u914d\u7d66\u5f71\u50cf\uff0c\u800c\u4e0d\u7ba1\u8cc7\u8a0a\u5167\u5bb9\u70ba\u4f55\u3002\u9019\u8207\u4eba\u985e\u7684\u667a\u6167\u2014\u2014\u751a\u81f3\u662f\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u2014\u2014\u5f62\u6210\u5c0d\u6bd4\uff0c\u5f8c\u8005\u6703\u6839\u64da\u71b5\u3001\u8108\u7d61\u548c\u719f\u6089\u5ea6\u5206\u914d\u4e0d\u540c\u7684\u8868\u5fb5\u5bb9\u91cf\u3002\u53d7\u5230\u9019\u9ede\u555f\u767c\uff0c\u6211\u5011\u63d0\u51fa\u4e00\u500b\u65b9\u6cd5\u4f86\u5b78\u7fd2 2D \u5f71\u50cf\u7684\u53ef\u8b8a\u9577\u5ea6\u6a19\u8a18\u8868\u5fb5\u3002\u6211\u5011\u7684\u7de8\u78bc\u5668-\u89e3\u78bc\u5668\u67b6\u69cb\u6703\u905e\u8ff4\u8655\u7406 2D \u5f71\u50cf\u6a19\u8a18\uff0c\u5c07\u5b83\u5011\u5728\u905e\u8ff4\u5c55\u958b\u7684\u591a\u6b21\u8fed\u4ee3\u4e2d\u63d0\u7149\u6210 1D \u6f5b\u5728\u6a19\u8a18\u3002\u6bcf\u6b21\u8fed\u4ee3\u90fd\u6703\u7cbe\u7149 2D \u6a19\u8a18\u3001\u66f4\u65b0\u73fe\u6709\u7684 1D \u6f5b\u5728\u6a19\u8a18\uff0c\u4e26\u900f\u904e\u65b0\u589e\u6a19\u8a18\u4f86\u9069\u61c9\u6027\u5730\u589e\u52a0\u8868\u5fb5\u5bb9\u91cf\u3002\u9019\u80fd\u5c07\u5f71\u50cf\u58d3\u7e2e\u6210\u6578\u91cf\u53ef\u8b8a\u7684\u6a19\u8a18\uff0c\u7bc4\u570d\u5f9e 32 \u5230 256\u3002\u6211\u5011\u4f7f\u7528\u91cd\u5efa\u640d\u5931\u548c FID \u6307\u6a19\u9a57\u8b49\u6211\u5011\u7684\u6a19\u8a18\u5668\uff0c\u8b49\u660e\u6a19\u8a18\u6578\u91cf\u8207\u5f71\u50cf\u71b5\u3001\u719f\u6089\u5ea6\u548c\u4e0b\u6e38\u4efb\u52d9\u9700\u6c42\u76f8\u7b26\u3002\u5728\u6bcf\u6b21\u8fed\u4ee3\u4e2d\uff0c\u905e\u8ff4\u6a19\u8a18\u8655\u7406\u6703\u96a8\u8457\u8868\u5fb5\u5bb9\u91cf\u7684\u589e\u52a0\u800c\u986f\u793a\u6a19\u8a18\u5c08\u696d\u5316\u7684\u8de1\u8c61\uff0c\u63ed\u793a\u4e86\u7269\u4ef6/\u90e8\u5206\u767c\u73fe\u7684\u6f5b\u529b\u3002", "author": "Shivam Duggal et.al.", "authors": "Shivam Duggal, Phillip Isola, Antonio Torralba, William T. Freeman", "id": "2411.02393v1", "paper_url": "http://arxiv.org/abs/2411.02393v1", "repo": "https://github.com/shivamduggal4/adaptive-length-tokenizer"}}