{"2409.12150": {"publish_time": "2024-09-18", "title": "Decoding Style: Efficient Fine-Tuning of LLMs for Image-Guided Outfit Recommendation with Preference", "paper_summary": "Personalized outfit recommendation remains a complex challenge, demanding\nboth fashion compatibility understanding and trend awareness. This paper\npresents a novel framework that harnesses the expressive power of large\nlanguage models (LLMs) for this task, mitigating their \"black box\" and static\nnature through fine-tuning and direct feedback integration. We bridge the item\nvisual-textual gap in items descriptions by employing image captioning with a\nMultimodal Large Language Model (MLLM). This enables the LLM to extract style\nand color characteristics from human-curated fashion images, forming the basis\nfor personalized recommendations. The LLM is efficiently fine-tuned on the\nopen-source Polyvore dataset of curated fashion images, optimizing its ability\nto recommend stylish outfits. A direct preference mechanism using negative\nexamples is employed to enhance the LLM's decision-making process. This creates\na self-enhancing AI feedback loop that continuously refines recommendations in\nline with seasonal fashion trends. Our framework is evaluated on the Polyvore\ndataset, demonstrating its effectiveness in two key tasks: fill-in-the-blank,\nand complementary item retrieval. These evaluations underline the framework's\nability to generate stylish, trend-aligned outfit suggestions, continuously\nimproving through direct feedback. The evaluation results demonstrated that our\nproposed framework significantly outperforms the base LLM, creating more\ncohesive outfits. The improved performance in these tasks underscores the\nproposed framework's potential to enhance the shopping experience with accurate\nsuggestions, proving its effectiveness over the vanilla LLM based outfit\ngeneration.", "paper_summary_zh": "<paragraph>\u500b\u4eba\u5316\u670d\u88dd\u63a8\u85a6\u4ecd\u7136\u662f\u4e00\u9805\u8907\u96dc\u7684\u6311\u6230\uff0c\u65e2\u9700\u8981\u5c0d\u6642\u5c1a\u76f8\u5bb9\u6027\u6709\u6df1\u5165\u7684\u4e86\u89e3\uff0c\u53c8\u9700\u8981\u4e86\u89e3\u8da8\u52e2\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u500b\u65b0\u7a4e\u7684\u6846\u67b6\uff0c\u5229\u7528\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u8868\u9054\u80fd\u529b\u4f86\u57f7\u884c\u9019\u9805\u4efb\u52d9\uff0c\u900f\u904e\u5fae\u8abf\u548c\u76f4\u63a5\u56de\u994b\u6574\u5408\u4f86\u6e1b\u8f15\u5176\u300c\u9ed1\u76d2\u5b50\u300d\u548c\u975c\u614b\u6027\u8cea\u3002\u6211\u5011\u900f\u904e\u4f7f\u7528\u5177\u6709\u591a\u6a21\u614b\u5927\u578b\u8a9e\u8a00\u6a21\u578b (MLLM) \u7684\u5f71\u50cf\u6a19\u984c\uff0c\u4f86\u5f4c\u5408\u9805\u76ee\u8996\u89ba\u8207\u6587\u5b57\u5728\u9805\u76ee\u63cf\u8ff0\u4e2d\u7684\u5dee\u8ddd\u3002\u9019\u4f7f LLM \u80fd\u5920\u5f9e\u4eba\u5de5\u7b56\u5c55\u7684\u6642\u5c1a\u5f71\u50cf\u4e2d\u63d0\u53d6\u98a8\u683c\u548c\u8272\u5f69\u7279\u5fb5\uff0c\u4f5c\u70ba\u500b\u4eba\u5316\u63a8\u85a6\u7684\u57fa\u790e\u3002LLM \u5728\u7b56\u5c55\u6642\u5c1a\u5f71\u50cf\u7684\u958b\u6e90 Polyvore \u8cc7\u6599\u96c6\u4e0a\u9032\u884c\u4e86\u9ad8\u6548\u7684\u5fae\u8abf\uff0c\u512a\u5316\u4e86\u5176\u63a8\u85a6\u6642\u5c1a\u670d\u88dd\u7684\u80fd\u529b\u3002\u4f7f\u7528\u8ca0\u9762\u7bc4\u4f8b\u7684\u76f4\u63a5\u504f\u597d\u6a5f\u5236\u88ab\u7528\u4f86\u589e\u5f37 LLM \u7684\u6c7a\u7b56\u904e\u7a0b\u3002\u9019\u5275\u9020\u4e86\u4e00\u500b\u81ea\u6211\u589e\u5f37\u7684 AI \u56de\u994b\u8ff4\u8def\uff0c\u6839\u64da\u5b63\u7bc0\u6027\u6642\u5c1a\u8da8\u52e2\u4e0d\u65b7\u512a\u5316\u63a8\u85a6\u3002\u6211\u5011\u7684\u6846\u67b6\u5728 Polyvore \u8cc7\u6599\u96c6\u4e0a\u9032\u884c\u4e86\u8a55\u4f30\uff0c\u8b49\u660e\u4e86\u5176\u5728\u5169\u500b\u95dc\u9375\u4efb\u52d9\u4e2d\u7684\u6709\u6548\u6027\uff1a\u586b\u7a7a\u548c\u4e92\u88dc\u9805\u76ee\u6aa2\u7d22\u3002\u9019\u4e9b\u8a55\u4f30\u5f37\u8abf\u4e86\u8a72\u6846\u67b6\u751f\u6210\u6642\u5c1a\u3001\u7b26\u5408\u8da8\u52e2\u7684\u670d\u88dd\u5efa\u8b70\u7684\u80fd\u529b\uff0c\u4e26\u900f\u904e\u76f4\u63a5\u56de\u994b\u4e0d\u65b7\u6539\u9032\u3002\u8a55\u4f30\u7d50\u679c\u8868\u660e\uff0c\u6211\u5011\u63d0\u51fa\u7684\u6846\u67b6\u986f\u8457\u512a\u65bc\u57fa\u790e LLM\uff0c\u5275\u9020\u51fa\u66f4\u5177\u51dd\u805a\u529b\u7684\u670d\u88dd\u3002\u5728\u9019\u4e9b\u4efb\u52d9\u4e2d\u6539\u9032\u7684\u6548\u80fd\u7a81\u986f\u4e86\u6240\u63d0\u51fa\u7684\u6846\u67b6\u5728\u900f\u904e\u6e96\u78ba\u7684\u5efa\u8b70\u589e\u5f37\u8cfc\u7269\u9ad4\u9a57\u65b9\u9762\u7684\u6f5b\u529b\uff0c\u8b49\u660e\u4e86\u5176\u512a\u65bc\u57fa\u65bc\u9999\u8349 LLM \u7684\u670d\u88dd\u751f\u6210\u7684\u6548\u80fd\u3002</paragraph>", "author": "Najmeh Forouzandehmehr et.al.", "authors": "Najmeh Forouzandehmehr, Nima Farrokhsiar, Ramin Giahi, Evren Korpeoglu, Kannan Achan", "id": "2409.12150v1", "paper_url": "http://arxiv.org/abs/2409.12150v1", "repo": "null"}}