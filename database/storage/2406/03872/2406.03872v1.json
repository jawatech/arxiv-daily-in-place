{"2406.03872": {"publish_time": "2024-06-06", "title": "BLSP-Emo: Towards Empathetic Large Speech-Language Models", "paper_summary": "The recent release of GPT-4o showcased the potential of end-to-end multimodal\nmodels, not just in terms of low latency but also in their ability to\nunderstand and generate expressive speech with rich emotions. While the details\nare unknown to the open research community, it likely involves significant\namounts of curated data and compute, neither of which is readily accessible. In\nthis paper, we present BLSP-Emo (Bootstrapped Language-Speech Pretraining with\nEmotion support), a novel approach to developing an end-to-end speech-language\nmodel capable of understanding both semantics and emotions in speech and\ngenerate empathetic responses. BLSP-Emo utilizes existing speech recognition\n(ASR) and speech emotion recognition (SER) datasets through a two-stage\nprocess. The first stage focuses on semantic alignment, following recent work\non pretraining speech-language models using ASR data. The second stage performs\nemotion alignment with the pretrained speech-language model on an emotion-aware\ncontinuation task constructed from SER data. Our experiments demonstrate that\nthe BLSP-Emo model excels in comprehending speech and delivering empathetic\nresponses, both in instruction-following tasks and conversations.", "paper_summary_zh": "GPT-4o \u6700\u8fd1\u767c\u5e03\u5c55\u793a\u4e86\u7aef\u5230\u7aef\u591a\u6a21\u614b\u6a21\u578b\u7684\u6f5b\u529b\uff0c\u4e0d\u50c5\u5728\u4f4e\u5ef6\u9072\u65b9\u9762\uff0c\u9084\u5728\u7406\u89e3\u548c\u751f\u6210\u5177\u6709\u8c50\u5bcc\u60c5\u611f\u7684\u8868\u9054\u6027\u8a9e\u8a00\u65b9\u9762\u3002\u96d6\u7136\u7d30\u7bc0\u5c0d\u958b\u653e\u7814\u7a76\u793e\u7fa4\u800c\u8a00\u672a\u77e5\uff0c\u4f46\u5b83\u53ef\u80fd\u6d89\u53ca\u5927\u91cf\u7684\u7b56\u5c55\u8cc7\u6599\u548c\u904b\u7b97\uff0c\u800c\u9019\u5169\u8005\u90fd\u4e0d\u662f\u5bb9\u6613\u53d6\u5f97\u7684\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa BLSP-Emo\uff08\u5f15\u5c0e\u8a9e\u8a00\u8a9e\u97f3\u9810\u8a13\u7df4\uff0c\u5177\u5099\u60c5\u611f\u652f\u63f4\uff09\uff0c\u9019\u662f\u4e00\u7a2e\u958b\u767c\u7aef\u5230\u7aef\u8a9e\u97f3\u8a9e\u8a00\u6a21\u578b\u7684\u65b0\u65b9\u6cd5\uff0c\u80fd\u5920\u7406\u89e3\u8a9e\u97f3\u4e2d\u7684\u8a9e\u610f\u548c\u60c5\u611f\uff0c\u4e26\u7522\u751f\u540c\u7406\u5fc3\u7684\u56de\u61c9\u3002BLSP-Emo \u900f\u904e\u5169\u968e\u6bb5\u6d41\u7a0b\u5229\u7528\u73fe\u6709\u7684\u8a9e\u97f3\u8fa8\u8b58 (ASR) \u548c\u8a9e\u97f3\u60c5\u611f\u8fa8\u8b58 (SER) \u8cc7\u6599\u96c6\u3002\u7b2c\u4e00\u968e\u6bb5\u8457\u91cd\u65bc\u8a9e\u610f\u5c0d\u9f4a\uff0c\u9075\u5faa\u6700\u8fd1\u4f7f\u7528 ASR \u8cc7\u6599\u9810\u8a13\u7df4\u8a9e\u97f3\u8a9e\u8a00\u6a21\u578b\u7684\u7814\u7a76\u3002\u7b2c\u4e8c\u968e\u6bb5\u4f7f\u7528\u5f9e SER \u8cc7\u6599\u5efa\u69cb\u7684\u60c5\u611f\u611f\u77e5\u5ef6\u7e8c\u4efb\u52d9\uff0c\u5c0d\u9810\u8a13\u7df4\u7684\u8a9e\u97f3\u8a9e\u8a00\u6a21\u578b\u57f7\u884c\u60c5\u611f\u5c0d\u9f4a\u3002\u6211\u5011\u7684\u5be6\u9a57\u8b49\u660e\uff0cBLSP-Emo \u6a21\u578b\u5728\u7406\u89e3\u8a9e\u97f3\u548c\u63d0\u4f9b\u540c\u7406\u5fc3\u56de\u61c9\u65b9\u9762\u8868\u73fe\u51fa\u8272\uff0c\u7121\u8ad6\u662f\u5728\u9075\u5faa\u6307\u4ee4\u7684\u4efb\u52d9\u6216\u5c0d\u8a71\u4e2d\u3002", "author": "Chen Wang et.al.", "authors": "Chen Wang, Minpeng Liao, Zhongqiang Huang, Junhong Wu, Chengqing Zong, Jiajun Zhang", "id": "2406.03872v1", "paper_url": "http://arxiv.org/abs/2406.03872v1", "repo": "null"}}