{"2502.07752": {"publish_time": "2025-02-11", "title": "Towards Efficient Optimizer Design for LLM via Structured Fisher Approximation with a Low-Rank Extension", "paper_summary": "Designing efficient optimizers for large language models (LLMs) with\nlow-memory requirements and fast convergence is an important and challenging\nproblem. This paper makes a step towards the systematic design of such\noptimizers through the lens of structured Fisher information matrix (FIM)\napproximation. We show that many state-of-the-art efficient optimizers can be\nviewed as solutions to FIM approximation (under the Frobenius norm) with\nspecific structural assumptions. Building on these insights, we propose two\ndesign recommendations of practical efficient optimizers for LLMs, involving\nthe careful selection of structural assumptions to balance generality and\nefficiency, and enhancing memory efficiency of optimizers with general\nstructures through a novel low-rank extension framework. We demonstrate how to\nuse each design approach by deriving new memory-efficient optimizers: Row and\nColumn Scaled SGD (RACS) and Adaptive low-dimensional subspace estimation\n(Alice). Experiments on LLaMA pre-training (up to 1B parameters) validate the\neffectiveness, showing faster and better convergence than existing\nmemory-efficient baselines and Adam with little memory overhead. Notably, Alice\nachieves better than 2x faster convergence over Adam, while RACS delivers\nstrong performance on the 1B model with SGD-like memory.", "paper_summary_zh": "<paragraph>\u8a2d\u8a08\u5177\u6709\u4f4e\u8a18\u61b6\u9ad4\u9700\u6c42\u548c\u5feb\u901f\u6536\u6582\u7684\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u9ad8\u6548\u6700\u4f73\u5316\u5668\u662f\u4e00\u500b\u91cd\u8981\u4e14\u5177\u6709\u6311\u6230\u6027\u7684\u554f\u984c\u3002\u672c\u6587\u900f\u904e\u7d50\u69cb\u5316 Fisher \u8cc7\u8a0a\u77e9\u9663 (FIM) \u8fd1\u4f3c\u7684\u89c0\u9ede\uff0c\u671d\u8457\u7cfb\u7d71\u5316\u8a2d\u8a08\u6b64\u985e\u6700\u4f73\u5316\u5668\u9081\u51fa\u4e86\u4e00\u6b65\u3002\u6211\u5011\u8b49\u660e\u8a31\u591a\u6700\u5148\u9032\u7684\u9ad8\u6548\u6700\u4f73\u5316\u5668\u53ef\u4ee5\u8996\u70ba FIM \u8fd1\u4f3c\uff08\u5728 Frobenius \u7bc4\u6578\u4e0b\uff09\u7684\u89e3\uff0c\u4e26\u5177\u6709\u7279\u5b9a\u7684\u7d50\u69cb\u5047\u8a2d\u3002\u57fa\u65bc\u9019\u4e9b\u898b\u89e3\uff0c\u6211\u5011\u63d0\u51fa\u4e86 LLM \u7684\u5169\u500b\u5be6\u7528\u9ad8\u6548\u6700\u4f73\u5316\u5668\u8a2d\u8a08\u5efa\u8b70\uff0c\u5305\u62ec\u4ed4\u7d30\u9078\u64c7\u7d50\u69cb\u5047\u8a2d\u4ee5\u5e73\u8861\u901a\u7528\u6027\u548c\u6548\u7387\uff0c\u4ee5\u53ca\u900f\u904e\u65b0\u7a4e\u7684\u4f4e\u79e9\u64f4\u5145\u6846\u67b6\u589e\u5f37\u4e00\u822c\u7d50\u69cb\u6700\u4f73\u5316\u5668\u7684\u8a18\u61b6\u9ad4\u6548\u7387\u3002\u6211\u5011\u900f\u904e\u63a8\u5c0e\u65b0\u7684\u8a18\u61b6\u9ad4\u9ad8\u6548\u6700\u4f73\u5316\u5668\u4f86\u5c55\u793a\u5982\u4f55\u4f7f\u7528\u6bcf\u7a2e\u8a2d\u8a08\u65b9\u6cd5\uff1a\u5217\u548c\u6b04\u7e2e\u653e SGD (RACS) \u548c\u81ea\u9069\u61c9\u4f4e\u7dad\u5b50\u7a7a\u9593\u4f30\u8a08 (Alice)\u3002\u5728 LLaMA \u9810\u8a13\u7df4\uff08\u9ad8\u9054 1B \u53c3\u6578\uff09\u4e0a\u7684\u5be6\u9a57\u9a57\u8b49\u4e86\u5176\u6709\u6548\u6027\uff0c\u986f\u793a\u6bd4\u73fe\u6709\u7684\u8a18\u61b6\u9ad4\u9ad8\u6548\u57fa\u6e96\u548c Adam \u66f4\u5feb\u4e14\u66f4\u597d\u7684\u6536\u6582\uff0c\u4e14\u8a18\u61b6\u9ad4\u958b\u92b7\u5f88\u5c0f\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0cAlice \u7684\u6536\u6582\u901f\u5ea6\u6bd4 Adam \u5feb 2 \u500d\u4ee5\u4e0a\uff0c\u800c RACS \u5247\u5728 1B \u6a21\u578b\u4e0a\u63d0\u4f9b\u985e\u4f3c SGD \u7684\u8a18\u61b6\u9ad4\u7684\u5f37\u52c1\u6548\u80fd\u3002</paragraph>", "author": "Wenbo Gong et.al.", "authors": "Wenbo Gong, Meyer Scetbon, Chao Ma, Edward Meeds", "id": "2502.07752v2", "paper_url": "http://arxiv.org/abs/2502.07752v2", "repo": "null"}}