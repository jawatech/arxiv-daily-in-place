{"2412.15563": {"publish_time": "2024-12-20", "title": "In-context Continual Learning Assisted by an External Continual Learner", "paper_summary": "Existing continual learning (CL) methods mainly rely on fine-tuning or\nadapting large language models (LLMs). They still suffer from catastrophic\nforgetting (CF). Little work has been done to exploit in-context learning (ICL)\nto leverage the extensive knowledge within LLMs for CL without updating any\nparameters. However, incrementally learning each new task in ICL necessitates\nadding training examples from each class of the task to the prompt, which\nhampers scalability as the prompt length increases. This issue not only leads\nto excessively long prompts that exceed the input token limit of the underlying\nLLM but also degrades the model's performance due to the overextended context.\nTo address this, we introduce InCA, a novel approach that integrates an\nexternal continual learner (ECL) with ICL to enable scalable CL without CF. The\nECL is built incrementally to pre-select a small subset of likely classes for\neach test instance. By restricting the ICL prompt to only these selected\nclasses, InCA prevents prompt lengths from becoming excessively long, while\nmaintaining high performance. Experimental results demonstrate that InCA\nsignificantly outperforms existing CL baselines, achieving substantial\nperformance gains.", "paper_summary_zh": "\u73fe\u6709\u7684\u6301\u7e8c\u5b78\u7fd2 (CL) \u65b9\u6cd5\u4e3b\u8981\u4f9d\u8cf4\u5fae\u8abf\u6216\u8abf\u6574\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM)\u3002\u5b83\u5011\u4ecd\u7136\u6703\u767c\u751f\u707d\u96e3\u6027\u907a\u5fd8 (CF)\u3002\u9bae\u5c11\u6709\u7814\u7a76\u5229\u7528\u60c5\u5883\u5b78\u7fd2 (ICL) \u4f86\u5229\u7528 LLM \u4e2d\u7684\u5ee3\u6cdb\u77e5\u8b58\u9032\u884c CL\uff0c\u800c\u7121\u9700\u66f4\u65b0\u4efb\u4f55\u53c3\u6578\u3002\u7136\u800c\uff0c\u5728 ICL \u4e2d\u9010\u6b65\u5b78\u7fd2\u6bcf\u9805\u65b0\u4efb\u52d9\u90fd\u9700\u8981\u5c07\u6bcf\u500b\u4efb\u52d9\u985e\u5225\u7684\u8a13\u7df4\u7bc4\u4f8b\u65b0\u589e\u5230\u63d0\u793a\u4e2d\uff0c\u9019\u6703\u96a8\u8457\u63d0\u793a\u9577\u5ea6\u589e\u52a0\u800c\u963b\u7919\u53ef\u64f4\u5145\u6027\u3002\u6b64\u554f\u984c\u4e0d\u50c5\u6703\u5c0e\u81f4\u904e\u9577\u7684\u63d0\u793a\uff0c\u8d85\u904e\u57fa\u790e LLM \u7684\u8f38\u5165\u6b0a\u6756\u9650\u5236\uff0c\u9084\u6703\u56e0\u70ba\u904e\u9577\u7684\u5167\u5bb9\u800c\u964d\u4f4e\u6a21\u578b\u7684\u6548\u80fd\u3002\u70ba\u4e86\u89e3\u6c7a\u6b64\u554f\u984c\uff0c\u6211\u5011\u5f15\u9032 InCA\uff0c\u9019\u662f\u4e00\u7a2e\u5275\u65b0\u7684\u65b9\u6cd5\uff0c\u5c07\u5916\u90e8\u6301\u7e8c\u5b78\u7fd2\u5668 (ECL) \u8207 ICL \u6574\u5408\uff0c\u4ee5\u555f\u7528\u7121 CF \u7684\u53ef\u64f4\u5145 CL\u3002ECL \u9010\u6f38\u5efa\u7f6e\uff0c\u4ee5\u9810\u5148\u9078\u64c7\u6bcf\u500b\u6e2c\u8a66\u5be6\u4f8b\u4e2d\u4e00\u5c0f\u90e8\u5206\u53ef\u80fd\u7684\u985e\u5225\u3002\u900f\u904e\u5c07 ICL \u63d0\u793a\u9650\u5236\u5728\u9019\u4e9b\u9078\u5b9a\u7684\u985e\u5225\u4e2d\uff0cInCA \u53ef\u9632\u6b62\u63d0\u793a\u9577\u5ea6\u904e\u9577\uff0c\u540c\u6642\u7dad\u6301\u9ad8\u6548\u80fd\u3002\u5be6\u9a57\u7d50\u679c\u8b49\u660e\uff0cInCA \u660e\u986f\u512a\u65bc\u73fe\u6709\u7684 CL \u57fa\u6e96\uff0c\u4e26\u7372\u5f97\u986f\u8457\u7684\u6548\u80fd\u63d0\u5347\u3002", "author": "Saleh Momeni et.al.", "authors": "Saleh Momeni, Sahisnu Mazumder, Zixuan Ke, Bing Liu", "id": "2412.15563v1", "paper_url": "http://arxiv.org/abs/2412.15563v1", "repo": "null"}}