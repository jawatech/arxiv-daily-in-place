{"2405.15092": {"publish_time": "2024-05-23", "title": "Dissociation of Faithful and Unfaithful Reasoning in LLMs", "paper_summary": "Large language models (LLMs) improve their performance in downstream tasks\nwhen they generate Chain of Thought reasoning text before producing an answer.\nOur research investigates how LLMs recover from errors in Chain of Thought,\nreaching the correct final answer despite mistakes in the reasoning text.\nThrough analysis of these error recovery behaviors, we find evidence for\nunfaithfulness in Chain of Thought, but we also identify many clear examples of\nfaithful error recovery behaviors. We identify factors that shift LLM recovery\nbehavior: LLMs recover more frequently from obvious errors and in contexts that\nprovide more evidence for the correct answer. However, unfaithful recoveries\nshow the opposite behavior, occurring more frequently for more difficult error\npositions. Our results indicate that there are distinct mechanisms driving\nfaithful and unfaithful error recoveries. Our results challenge the view that\nLLM reasoning is a uniform, coherent process.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5728\u7522\u751f\u7b54\u6848\u4e4b\u524d\u751f\u6210\u601d\u7dad\u93c8\u63a8\u7406\u6587\u5b57\u6642\uff0c\u6703\u63d0\u5347\u5176\u5728\u4e0b\u6e38\u4efb\u52d9\u4e2d\u7684\u8868\u73fe\u3002\n\u6211\u5011\u7684\u7814\u7a76\u63a2\u8a0e LLM \u5982\u4f55\u5f9e\u601d\u7dad\u93c8\u4e2d\u7684\u932f\u8aa4\u4e2d\u5fa9\u539f\uff0c\u5118\u7ba1\u63a8\u7406\u6587\u5b57\u6709\u932f\u8aa4\uff0c\u4f46\u4ecd\u80fd\u5f97\u5230\u6b63\u78ba\u7684\u6700\u7d42\u7b54\u6848\u3002\n\u900f\u904e\u5206\u6790\u9019\u4e9b\u932f\u8aa4\u5fa9\u539f\u884c\u70ba\uff0c\u6211\u5011\u627e\u5230\u4e86\u601d\u7dad\u93c8\u4e2d\u4e0d\u5fe0\u5be6\u7684\u8b49\u64da\uff0c\u4f46\u6211\u5011\u4e5f\u627e\u5230\u4e86\u8a31\u591a\u6e05\u6670\u7684\u5fe0\u5be6\u932f\u8aa4\u5fa9\u539f\u884c\u70ba\u7bc4\u4f8b\u3002\u6211\u5011\u627e\u51fa\u5f71\u97ff LLM \u5fa9\u539f\u884c\u70ba\u7684\u56e0\u7d20\uff1aLLM \u5f9e\u660e\u986f\u7684\u932f\u8aa4\u4e2d\u5fa9\u539f\u7684\u983b\u7387\u8f03\u9ad8\uff0c\u4e14\u5728\u63d0\u4f9b\u66f4\u591a\u6b63\u78ba\u7b54\u6848\u8b49\u64da\u7684\u8108\u7d61\u4e2d\u5fa9\u539f\u3002\u7136\u800c\uff0c\u4e0d\u5fe0\u5be6\u7684\u5fa9\u539f\u884c\u70ba\u8868\u73fe\u76f8\u53cd\uff0c\u5728\u8f03\u56f0\u96e3\u7684\u932f\u8aa4\u4f4d\u7f6e\u4e2d\u5fa9\u539f\u7684\u983b\u7387\u8f03\u9ad8\u3002\u6211\u5011\u7684\u7d50\u679c\u8868\u660e\uff0c\u6709\u4e0d\u540c\u7684\u6a5f\u5236\u9a45\u52d5\u5fe0\u5be6\u548c\u4e0d\u5fe0\u5be6\u7684\u932f\u8aa4\u5fa9\u539f\u3002\u6211\u5011\u7684\u7d50\u679c\u6311\u6230\u4e86 LLM \u63a8\u7406\u662f\u4e00\u500b\u7d71\u4e00\u3001\u9023\u8cab\u904e\u7a0b\u7684\u89c0\u9ede\u3002", "author": "Evelyn Yee et.al.", "authors": "Evelyn Yee, Alice Li, Chenyu Tang, Yeon Ho Jung, Ramamohan Paturi, Leon Bergen", "id": "2405.15092v1", "paper_url": "http://arxiv.org/abs/2405.15092v1", "repo": "https://github.com/coterrorrecovery/coterrorrecovery"}}