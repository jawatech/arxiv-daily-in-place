{"2405.18719": {"publish_time": "2024-05-29", "title": "Contextual Position Encoding: Learning to Count What's Important", "paper_summary": "The attention mechanism is a critical component of Large Language Models\n(LLMs) that allows tokens in a sequence to interact with each other, but is\norder-invariant. Incorporating position encoding (PE) makes it possible to\naddress by position, such as attending to the i-th token. However, current PE\nmethods use token counts to derive position, and thus cannot generalize to\nhigher levels of abstraction, such as attending to the i-th sentence. In this\npaper, we propose a new position encoding method, Contextual Position Encoding\n(CoPE), that allows positions to be conditioned on context by incrementing\nposition only on certain tokens determined by the model. This allows more\ngeneral position addressing such as attending to the $i$-th particular word,\nnoun, or sentence. We show that CoPE can solve the selective copy, counting and\nFlip-Flop tasks where popular position embeddings fail, and improves perplexity\non language modeling and coding tasks.", "paper_summary_zh": "\u6ce8\u610f\u529b\u673a\u5236\u662f\u5927\u578b\u8bed\u8a00\u6a21\u578b (LLM) \u4e2d\u7684\u5173\u952e\u7ec4\u4ef6\uff0c\u5b83\u5141\u8bb8\u5e8f\u5217\u4e2d\u7684\u6807\u8bb0\u76f8\u4e92\u4ea4\u4e92\uff0c\u4f46\u4e0e\u987a\u5e8f\u65e0\u5173\u3002\u5408\u5e76\u4f4d\u7f6e\u7f16\u7801 (PE) \u53ef\u4ee5\u6309\u4f4d\u7f6e\u8fdb\u884c\u5bfb\u5740\uff0c\u4f8b\u5982\u5173\u6ce8\u7b2c i \u4e2a\u6807\u8bb0\u3002\u4f46\u662f\uff0c\u5f53\u524d\u7684 PE \u65b9\u6cd5\u4f7f\u7528\u6807\u8bb0\u8ba1\u6570\u6765\u63a8\u5bfc\u51fa\u4f4d\u7f6e\uff0c\u56e0\u6b64\u65e0\u6cd5\u6982\u62ec\u5230\u66f4\u9ad8\u7684\u62bd\u8c61\u7ea7\u522b\uff0c\u4f8b\u5982\u5173\u6ce8\u7b2c i \u4e2a\u53e5\u5b50\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u4f4d\u7f6e\u7f16\u7801\u65b9\u6cd5\uff0c\u5373\u4e0a\u4e0b\u6587\u4f4d\u7f6e\u7f16\u7801 (CoPE)\uff0c\u5b83\u5141\u8bb8\u4f4d\u7f6e\u901a\u8fc7\u4ec5\u5728\u6a21\u578b\u786e\u5b9a\u7684\u67d0\u4e9b\u6807\u8bb0\u4e0a\u589e\u52a0\u4f4d\u7f6e\u6765\u6839\u636e\u4e0a\u4e0b\u6587\u8fdb\u884c\u8c03\u8282\u3002\u8fd9\u5141\u8bb8\u66f4\u901a\u7528\u7684\u4f4d\u7f6e\u5bfb\u5740\uff0c\u4f8b\u5982\u5173\u6ce8\u7b2c i \u4e2a\u7279\u5b9a\u5355\u8bcd\u3001\u540d\u8bcd\u6216\u53e5\u5b50\u3002\u6211\u4eec\u8868\u660e\uff0cCoPE \u53ef\u4ee5\u89e3\u51b3\u9009\u62e9\u6027\u590d\u5236\u3001\u8ba1\u6570\u548c\u89e6\u53d1\u5668\u4efb\u52a1\uff0c\u800c\u6d41\u884c\u7684\u4f4d\u7f6e\u5d4c\u5165\u4f1a\u5931\u8d25\uff0c\u5e76\u4e14\u53ef\u4ee5\u63d0\u9ad8\u8bed\u8a00\u5efa\u6a21\u548c\u7f16\u7801\u4efb\u52a1\u7684\u56f0\u60d1\u5ea6\u3002", "author": "Olga Golovneva et.al.", "authors": "Olga Golovneva, Tianlu Wang, Jason Weston, Sainbayar Sukhbaatar", "id": "2405.18719v1", "paper_url": "http://arxiv.org/abs/2405.18719v1", "repo": "null"}}