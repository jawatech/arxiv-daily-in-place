{"2502.05084": {"publish_time": "2025-02-07", "title": "ChallengeMe: An Adversarial Learning-enabled Text Summarization Framework", "paper_summary": "The astonishing performance of large language models (LLMs) and their\nremarkable achievements in production and daily life have led to their\nwidespread application in collaborative tasks. However, current large models\nface challenges such as hallucination and lack of specificity in content\ngeneration in vertical domain tasks. Inspired by the contrast and\nclassification mechanisms in human cognitive processes, this paper constructs\nan adversarial learning-based prompt framework named ChallengeMe, which\nincludes three cascaded solutions: generation prompts, evaluation prompts, and\nfeedback optimization. In this process, we designed seven core optimization\ndimensions and set the threshold for adversarial learning. The results of mixed\ncase studies on the text summarization task show that the proposed framework\ncan generate more accurate and fluent text summaries compared to the current\nadvanced mainstream LLMs.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u9a5a\u4eba\u8868\u73fe\u53ca\u5176\u5728\u751f\u7522\u548c\u65e5\u5e38\u751f\u6d3b\u4e2d\u7684\u986f\u8457\u6210\u5c31\uff0c\u5df2\u5c0e\u81f4\u5b83\u5011\u5ee3\u6cdb\u61c9\u7528\u65bc\u5354\u4f5c\u4efb\u52d9\u4e2d\u3002\u7136\u800c\uff0c\u7576\u524d\u5927\u578b\u6a21\u578b\u9762\u81e8\u6311\u6230\uff0c\u4f8b\u5982\u5728\u5782\u76f4\u9818\u57df\u4efb\u52d9\u4e2d\u5167\u5bb9\u751f\u6210\u51fa\u73fe\u5e7b\u89ba\u548c\u7f3a\u4e4f\u5177\u9ad4\u6027\u3002\u53d7\u4eba\u985e\u8a8d\u77e5\u904e\u7a0b\u4e2d\u5c0d\u6bd4\u548c\u5206\u985e\u6a5f\u5236\u7684\u555f\u767c\uff0c\u672c\u6587\u69cb\u5efa\u4e86\u4e00\u500b\u540d\u70ba ChallengeMe \u7684\u5c0d\u6297\u6027\u5b78\u7fd2\u63d0\u793a\u6846\u67b6\uff0c\u5176\u4e2d\u5305\u62ec\u4e09\u500b\u7d1a\u806f\u89e3\u6c7a\u65b9\u6848\uff1a\u751f\u6210\u63d0\u793a\u3001\u8a55\u4f30\u63d0\u793a\u548c\u53cd\u994b\u512a\u5316\u3002\u5728\u6b64\u904e\u7a0b\u4e2d\uff0c\u6211\u5011\u8a2d\u8a08\u4e86\u4e03\u500b\u6838\u5fc3\u512a\u5316\u7dad\u5ea6\uff0c\u4e26\u8a2d\u5b9a\u4e86\u5c0d\u6297\u6027\u5b78\u7fd2\u7684\u95be\u503c\u3002\u5728\u6587\u672c\u6458\u8981\u4efb\u52d9\u4e0a\u6df7\u5408\u6848\u4f8b\u7814\u7a76\u7684\u7d50\u679c\u8868\u660e\uff0c\u8207\u7576\u524d\u5148\u9032\u7684\u4e3b\u6d41 LLM \u76f8\u6bd4\uff0c\u6240\u63d0\u51fa\u7684\u6846\u67b6\u53ef\u4ee5\u751f\u6210\u66f4\u6e96\u78ba\u3001\u66f4\u6d41\u66a2\u7684\u6587\u672c\u6458\u8981\u3002", "author": "Xiaoyu Deng et.al.", "authors": "Xiaoyu Deng, Ye Zhang, Tianmin Guo, Yongzhe Zhang, Zhengjian Kang, Hang Yang", "id": "2502.05084v1", "paper_url": "http://arxiv.org/abs/2502.05084v1", "repo": "null"}}