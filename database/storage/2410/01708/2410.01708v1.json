{"2410.01708": {"publish_time": "2024-10-02", "title": "Examining the Role of Relationship Alignment in Large Language Models", "paper_summary": "The rapid development and deployment of Generative AI in social settings\nraise important questions about how to optimally personalize them for users\nwhile maintaining accuracy and realism. Based on a Facebook public post-comment\ndataset, this study evaluates the ability of Llama 3.0 (70B) to predict the\nsemantic tones across different combinations of a commenter's and poster's\ngender, age, and friendship closeness and to replicate these differences in\nLLM-generated comments.\n  The study consists of two parts: Part I assesses differences in semantic\ntones across social relationship categories, and Part II examines the\nsimilarity between comments generated by Llama 3.0 (70B) and human comments\nfrom Part I given public Facebook posts as input. Part I results show that\nincluding social relationship information improves the ability of a model to\npredict the semantic tone of human comments. However, Part II results show that\neven without including social context information in the prompt, LLM-generated\ncomments and human comments are equally sensitive to social context, suggesting\nthat LLMs can comprehend semantics from the original post alone. When we\ninclude all social relationship information in the prompt, the similarity\nbetween human comments and LLM-generated comments decreases. This inconsistency\nmay occur because LLMs did not include social context information as part of\ntheir training data. Together these results demonstrate the ability of LLMs to\ncomprehend semantics from the original post and respond similarly to human\ncomments, but also highlights their limitations in generalizing personalized\ncomments through prompting alone.", "paper_summary_zh": "<paragraph>\u751f\u6210\u5f0f AI \u5728\u793e\u4ea4\u73af\u5883\u4e2d\u7684\u5feb\u901f\u53d1\u5c55\u548c\u90e8\u7f72\u5f15\u53d1\u4e86\u5173\u4e8e\u5982\u4f55\u9488\u5bf9\u7528\u6237\u5bf9\u5176\u8fdb\u884c\u6700\u4f73\u4e2a\u6027\u5316\u5b9a\u5236\u540c\u65f6\u4fdd\u6301\u51c6\u786e\u6027\u548c\u771f\u5b9e\u6027\u7684\u91cd\u8981\u95ee\u9898\u3002\u57fa\u4e8e Facebook \u516c\u5171\u5e16\u5b50\u8bc4\u8bba\u6570\u636e\u96c6\uff0c\u672c\u7814\u7a76\u8bc4\u4f30\u4e86 Llama 3.0 (70B) \u6839\u636e\u8bc4\u8bba\u8005\u548c\u53d1\u5e16\u8005\u7684\u6027\u522b\u3001\u5e74\u9f84\u548c\u4eb2\u5bc6\u5ea6\u7ec4\u5408\u9884\u6d4b\u8bed\u4e49\u8bed\u6c14\u7684\u80fd\u529b\uff0c\u4ee5\u53ca\u5728 LLM \u751f\u6210\u7684\u8bc4\u8bba\u4e2d\u590d\u5236\u8fd9\u4e9b\u5dee\u5f02\u7684\u80fd\u529b\u3002\n\u672c\u7814\u7a76\u5305\u62ec\u4e24\u90e8\u5206\uff1a\u7b2c\u4e00\u90e8\u5206\u8bc4\u4f30\u4e86\u4e0d\u540c\u793e\u4ea4\u5173\u7cfb\u7c7b\u522b\u4e2d\u8bed\u4e49\u8bed\u6c14\u7684\u5dee\u5f02\uff0c\u7b2c\u4e8c\u90e8\u5206\u68c0\u67e5\u4e86 Llama 3.0 (70B) \u751f\u6210\u7684\u8bc4\u8bba\u4e0e\u7b2c\u4e00\u90e8\u5206\u4e2d\u7ed9\u5b9a\u516c\u5171 Facebook \u5e16\u5b50\u4f5c\u4e3a\u8f93\u5165\u7684\u4eba\u7c7b\u8bc4\u8bba\u4e4b\u95f4\u7684\u76f8\u4f3c\u6027\u3002\u7b2c\u4e00\u90e8\u5206\u7684\u7ed3\u679c\u8868\u660e\uff0c\u5305\u542b\u793e\u4ea4\u5173\u7cfb\u4fe1\u606f\u53ef\u4ee5\u63d0\u9ad8\u6a21\u578b\u9884\u6d4b\u4eba\u7c7b\u8bc4\u8bba\u8bed\u4e49\u8bed\u6c14\u7684\u80fd\u529b\u3002\u7136\u800c\uff0c\u7b2c\u4e8c\u90e8\u5206\u7684\u7ed3\u679c\u8868\u660e\uff0c\u5373\u4f7f\u6ca1\u6709\u5728\u63d0\u793a\u4e2d\u5305\u542b\u793e\u4ea4\u80cc\u666f\u4fe1\u606f\uff0cLLM \u751f\u6210\u7684\u8bc4\u8bba\u548c\u4eba\u7c7b\u8bc4\u8bba\u5bf9\u793e\u4ea4\u80cc\u666f\u540c\u6837\u654f\u611f\uff0c\u8fd9\u8868\u660e LLM \u53ef\u4ee5\u4ec5\u4ece\u539f\u59cb\u5e16\u5b50\u4e2d\u7406\u89e3\u8bed\u4e49\u3002\u5f53\u6211\u4eec\u5728\u63d0\u793a\u4e2d\u5305\u542b\u6240\u6709\u793e\u4ea4\u5173\u7cfb\u4fe1\u606f\u65f6\uff0c\u4eba\u7c7b\u8bc4\u8bba\u548c LLM \u751f\u6210\u7684\u8bc4\u8bba\u4e4b\u95f4\u7684\u76f8\u4f3c\u6027\u4f1a\u964d\u4f4e\u3002\u8fd9\u79cd\u4e0d\u4e00\u81f4\u6027\u53ef\u80fd\u662f\u56e0\u4e3a LLM \u6ca1\u6709\u5c06\u793e\u4ea4\u80cc\u666f\u4fe1\u606f\u4f5c\u4e3a\u5176\u8bad\u7ec3\u6570\u636e\u7684\u4e00\u90e8\u5206\u3002\u8fd9\u4e9b\u7ed3\u679c\u5171\u540c\u8bc1\u660e\u4e86 LLM \u4ece\u539f\u59cb\u5e16\u5b50\u4e2d\u7406\u89e3\u8bed\u4e49\u5e76\u5bf9\u4eba\u7c7b\u8bc4\u8bba\u505a\u51fa\u7c7b\u4f3c\u53cd\u5e94\u7684\u80fd\u529b\uff0c\u4f46\u4e5f\u7a81\u51fa\u4e86\u5b83\u4eec\u4ec5\u901a\u8fc7\u63d0\u793a\u6765\u6982\u62ec\u4e2a\u6027\u5316\u8bc4\u8bba\u7684\u5c40\u9650\u6027\u3002</paragraph>", "author": "Kristen M. Altenburger et.al.", "authors": "Kristen M. Altenburger, Hongda Jiang, Robert E. Kraut, Yi-Chia Wang, Jane Dwivedi-Yu", "id": "2410.01708v1", "paper_url": "http://arxiv.org/abs/2410.01708v1", "repo": "null"}}