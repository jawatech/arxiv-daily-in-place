
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-09-24**|**Articulated Object Manipulation using Online Axis Estimation with SAM2-Based Tracking**|Xi Wang et.al.|[2409.16287v1](http://arxiv.org/abs/2409.16287v1)|null|
|**2024-09-24**|**Fields of The World: A Machine Learning Benchmark Dataset For Global Agricultural Field Boundary Segmentation**|Hannah Kerner et.al.|[2409.16252v1](http://arxiv.org/abs/2409.16252v1)|null|
|**2024-09-24**|**A fast and sound tagging method for discontinuous named-entity recognition**|Caio Corro et.al.|[2409.16243v1](http://arxiv.org/abs/2409.16243v1)|null|
|**2024-09-24**|**LLM Echo Chamber: personalized and automated disinformation**|Tony Ma et.al.|[2409.16241v1](http://arxiv.org/abs/2409.16241v1)|[link](https://github.com/iamtonymwt/echo_chamber)|
|**2024-09-24**|**Efficiently Learning Probabilistic Logical Models by Cheaply Ranking Mined Rules**|Jonathan Feldstein et.al.|[2409.16238v1](http://arxiv.org/abs/2409.16238v1)|null|
|**2024-09-24**|**EuroLLM: Multilingual Language Models for Europe**|Pedro Henrique Martins et.al.|[2409.16235v1](http://arxiv.org/abs/2409.16235v1)|null|
|**2024-09-24**|**Predicting Deterioration in Mild Cognitive Impairment with Survival Transformers, Extreme Gradient Boosting and Cox Proportional Hazard Modelling**|Henry Musto et.al.|[2409.16231v1](http://arxiv.org/abs/2409.16231v1)|null|
|**2024-09-24**|**Fine-Tuning is Fine, if Calibrated**|Zheda Mai et.al.|[2409.16223v1](http://arxiv.org/abs/2409.16223v1)|null|
|**2024-09-24**|**Towards Enhancing Linked Data Retrieval in Conversational UIs using Large Language Models**|Omar Mussa et.al.|[2409.16220v1](http://arxiv.org/abs/2409.16220v1)|null|
|**2024-09-24**|**Problem-oriented AutoML in Clustering**|Matheus Camilo da Silva et.al.|[2409.16218v1](http://arxiv.org/abs/2409.16218v1)|null|
|**2024-09-24**|**Facial Expression-Enhanced TTS: Combining Face Representation and Emotion Intensity for Adaptive Speech**|Yunji Chu et.al.|[2409.16203v1](http://arxiv.org/abs/2409.16203v1)|null|
|**2024-09-24**|**CJEval: A Benchmark for Assessing Large Language Models Using Chinese Junior High School Exam Data**|Qian-Wen Zhang et.al.|[2409.16202v2](http://arxiv.org/abs/2409.16202v2)|[link](https://github.com/smilewhc/cjeval)|
|**2024-09-24**|**Leveraging Estimated Transferability Over Human Intuition for Model Selection in Text Ranking**|Jun Bai et.al.|[2409.16198v1](http://arxiv.org/abs/2409.16198v1)|null|
|**2024-09-24**|**HelloBench: Evaluating Long Text Generation Capabilities of Large Language Models**|Haoran Que et.al.|[2409.16191v1](http://arxiv.org/abs/2409.16191v1)|[link](https://github.com/quehry/hellobench)|
|**2024-09-24**|**Cyber Knowledge Completion Using Large Language Models**|Braden K Webb et.al.|[2409.16176v1](http://arxiv.org/abs/2409.16176v1)|null|
|**2024-09-24**|**Merging LoRAs like Playing LEGO: Pushing the Modularity of LoRA to Extremes Through Rank-Wise Clustering**|Ziyu Zhao et.al.|[2409.16167v1](http://arxiv.org/abs/2409.16167v1)|null|
|**2024-09-24**|**EnIGMA: Enhanced Interactive Generative Model Agent for CTF Challenges**|Talor Abramovich et.al.|[2409.16165v1](http://arxiv.org/abs/2409.16165v1)|[link](https://github.com/princeton-nlp/swe-agent)|
|**2024-09-24**|**Controlling Risk of Retrieval-augmented Generation: A Counterfactual Prompting Framework**|Lu Chen et.al.|[2409.16146v1](http://arxiv.org/abs/2409.16146v1)|null|
|**2024-09-24**|**Seeing Faces in Things: A Model and Dataset for Pareidolia**|Mark Hamilton et.al.|[2409.16143v1](http://arxiv.org/abs/2409.16143v1)|null|
|**2024-09-24**|**HA-FGOVD: Highlighting Fine-grained Attributes via Explicit Linear Composition for Open-Vocabulary Object Detection**|Yuqi Ma et.al.|[2409.16136v1](http://arxiv.org/abs/2409.16136v1)|null|
|**2024-09-24**|**Implicit assessment of language learning during practice as accurate as explicit testing**|Jue Hou et.al.|[2409.16133v1](http://arxiv.org/abs/2409.16133v1)|null|
|**2024-09-24**|**Analyzing Probabilistic Methods for Evaluating Agent Capabilities**|Axel HÃ¸jmark et.al.|[2409.16125v1](http://arxiv.org/abs/2409.16125v1)|null|
|**2024-09-24**|**MOSS: Enabling Code-Driven Evolution and Context Management for AI Agents**|Ming Zhu et.al.|[2409.16120v1](http://arxiv.org/abs/2409.16120v1)|[link](https://github.com/ghost-in-moss/ghostos)|
|**2024-09-24**|**Scenario of Use Scheme: Threat Model Specification for Speaker Privacy Protection in the Medical Domain**|Mehtab Ur Rahman et.al.|[2409.16106v1](http://arxiv.org/abs/2409.16106v1)|null|
|**2024-09-24**|**Neuromorphic Drone Detection: an Event-RGB Multimodal Approach**|Gabriele Magrini et.al.|[2409.16099v1](http://arxiv.org/abs/2409.16099v1)|null|
|**2024-09-24**|**Exploring Hint Generation Approaches in Open-Domain Question Answering**|Jamshid Mozafari et.al.|[2409.16096v1](http://arxiv.org/abs/2409.16096v1)|[link](https://github.com/datascienceuibk/hintqa)|
|**2024-09-24**|**From Pixels to Words: Leveraging Explainability in Face Recognition through Interactive Natural Language Processing**|Ivan DeAndres-Tame et.al.|[2409.16089v1](http://arxiv.org/abs/2409.16089v1)|null|
|**2024-09-24**|**Online Multi-level Contrastive Representation Distillation for Cross-Subject fNIRS Emotion Recognition**|Zhili Lai et.al.|[2409.16081v1](http://arxiv.org/abs/2409.16081v1)|null|
|**2024-09-24**|**Leveraging Mixture of Experts for Improved Speech Deepfake Detection**|Viola Negroni et.al.|[2409.16077v1](http://arxiv.org/abs/2409.16077v1)|null|
|**2024-09-24**|**Towards Robust Object Detection: Identifying and Removing Backdoors via Module Inconsistency Analysis**|Xianda Zhang et.al.|[2409.16057v1](http://arxiv.org/abs/2409.16057v1)|null|
|**2024-09-24**|**Adversarial Watermarking for Face Recognition**|Yuguang Yao et.al.|[2409.16056v1](http://arxiv.org/abs/2409.16056v1)|null|
|**2024-09-24**|**Whole-body end-effector pose tracking**|Tifanny Portela et.al.|[2409.16048v1](http://arxiv.org/abs/2409.16048v1)|null|
|**2024-09-24**|**LTNtorch: PyTorch Implementation of Logic Tensor Networks**|Tommaso Carraro et.al.|[2409.16045v1](http://arxiv.org/abs/2409.16045v1)|[link](https://github.com/tommasocarraro/ltntorch)|
|**2024-09-24**|**Time-MoE: Billion-Scale Time Series Foundation Models with Mixture of Experts**|Xiaoming Shi et.al.|[2409.16040v1](http://arxiv.org/abs/2409.16040v1)|[link](https://github.com/time-moe/time-moe)|
|**2024-09-24**|**Grounded Computation & Consciousness: A Framework for Exploring Consciousness in Machines & Other Organisms**|Ryan Williams et.al.|[2409.16036v1](http://arxiv.org/abs/2409.16036v1)|null|
|**2024-09-24**|**Deep chroma compression of tone-mapped images**|Xenios Milidonis et.al.|[2409.16032v1](http://arxiv.org/abs/2409.16032v1)|[link](https://github.com/DeepCamera/HDR-chroma-compression)|
|**2024-09-24**|**Unlocking Markets: A Multilingual Benchmark to Cross-Market Question Answering**|Yifei Yuan et.al.|[2409.16025v1](http://arxiv.org/abs/2409.16025v1)|null|
|**2024-09-24**|**Bridging Environments and Language with Rendering Functions and Vision-Language Models**|Theo Cachet et.al.|[2409.16024v1](http://arxiv.org/abs/2409.16024v1)|null|
|**2024-09-24**|**AI Can Be Cognitively Biased: An Exploratory Study on Threshold Priming in LLM-Based Batch Relevance Assessment**|Nuo Chen et.al.|[2409.16022v1](http://arxiv.org/abs/2409.16022v1)|null|
|**2024-09-24**|**Bridging Speech and Text: Enhancing ASR with Pinyin-to-Character Pre-training in LLMs**|Yang Yuhang et.al.|[2409.16005v1](http://arxiv.org/abs/2409.16005v1)|null|
|**2024-09-24**|**Artificial Human Intelligence: The role of Humans in the Development of Next Generation AI**|Suayb S. Arslan et.al.|[2409.16001v1](http://arxiv.org/abs/2409.16001v1)|null|
|**2024-09-24**|**Improvements to SDXL in NovelAI Diffusion V3**|Juan Ossa et.al.|[2409.15997v1](http://arxiv.org/abs/2409.15997v1)|null|
|**2024-09-24**|**DataGpt-SQL-7B: An Open-Source Language Model for Text-to-SQL**|Lixia Wu et.al.|[2409.15985v1](http://arxiv.org/abs/2409.15985v1)|null|
|**2024-09-24**|**Leveraging Unsupervised Learning for Cost-Effective Visual Anomaly Detection**|Yunbo Long et.al.|[2409.15980v1](http://arxiv.org/abs/2409.15980v1)|null|
|**2024-09-24**|**Finetuning LLMs for Comparative Assessment Tasks**|Vatsal Raina et.al.|[2409.15979v1](http://arxiv.org/abs/2409.15979v1)|null|
|**2024-09-24**|**StyleSinger 2: Zero-Shot Singing Voice Synthesis with Style Transfer and Multi-Level Style Control**|Yu Zhang et.al.|[2409.15977v1](http://arxiv.org/abs/2409.15977v1)|[link](https://github.com/AaronZ345/StyleSinger2)|
|**2024-09-24**|**Disentangling Age and Identity with a Mutual Information Minimization Approach for Cross-Age Speaker Verification**|Fengrun Zhang et.al.|[2409.15974v1](http://arxiv.org/abs/2409.15974v1)|null|
|**2024-09-24**|**Creating Healthy Friction: Determining Stakeholder Requirements of Job Recommendation Explanations**|Roan Schellingerhout et.al.|[2409.15971v1](http://arxiv.org/abs/2409.15971v1)|[link](https://github.com/roan-schellingerhout/evaluating_job_recommendations)|
|**2024-09-24**|**ASD-Diffusion: Anomalous Sound Detection with Diffusion Models**|Fengrun Zhang et.al.|[2409.15957v1](http://arxiv.org/abs/2409.15957v1)|null|
|**2024-09-24**|**Historical Trajectory Assisted Zeroth-Order Federated Optimization**|Xiaoyu He et.al.|[2409.15955v2](http://arxiv.org/abs/2409.15955v2)|null|
|**2024-09-24**|**Beats of Bias: Analyzing Lyrics with Topic Modeling and Gender Bias Measurements**|Danqing Chen et.al.|[2409.15949v1](http://arxiv.org/abs/2409.15949v1)|null|
|**2024-09-24**|**TSFeatLIME: An Online User Study in Enhancing Explainability in Univariate Time Series Forecasting**|Hongnan Ma et.al.|[2409.15950v1](http://arxiv.org/abs/2409.15950v1)|[link](https://github.com/ts-xai/whyforecast)|
|**2024-09-24**|**Automated test generation to evaluate tool-augmented LLMs as conversational AI agents**|Samuel Arcadinho et.al.|[2409.15934v1](http://arxiv.org/abs/2409.15934v1)|null|
|**2024-09-24**|**SLIMER-IT: Zero-Shot NER on Italian Language**|Andrew Zamai et.al.|[2409.15933v1](http://arxiv.org/abs/2409.15933v1)|[link](https://github.com/andrewzamai/slimer_it)|
|**2024-09-24**|**Multilingual Transfer and Domain Adaptation for Low-Resource Languages of Spain**|Yuanchang Luo et.al.|[2409.15924v1](http://arxiv.org/abs/2409.15924v1)|null|
|**2024-09-24**|**Planning in the Dark: LLM-Symbolic Planning Pipeline without Experts**|Sukai Huang et.al.|[2409.15915v1](http://arxiv.org/abs/2409.15915v1)|null|
|**2024-09-24**|**Explaining word embeddings with perfect fidelity: Case study in research impact prediction**|Lucie Dvorackova et.al.|[2409.15912v1](http://arxiv.org/abs/2409.15912v1)|null|
|**2024-09-24**|**A Modular-based Strategy for Mitigating Gradient Conflicts in Simultaneous Speech Translation**|Xiaoqian Liu et.al.|[2409.15911v1](http://arxiv.org/abs/2409.15911v1)|null|
|**2024-09-24**|**Enhancing IoT based Plant Health Monitoring through Advanced Human Plant Interaction using Large Language Models and Mobile Applications**|Kriti Agarwal et.al.|[2409.15910v1](http://arxiv.org/abs/2409.15910v1)|null|
|**2024-09-24**|**Enhancing Text-to-SQL Capabilities of Large Language Models via Domain Database Knowledge Injection**|Xingyu Ma et.al.|[2409.15907v1](http://arxiv.org/abs/2409.15907v1)|null|
|**2024-09-24**|**Boosting Code-Switching ASR with Mixture of Experts Enhanced Speech-Conditioned LLM**|Fengrun Zhang et.al.|[2409.15905v1](http://arxiv.org/abs/2409.15905v1)|null|
|**2024-09-24**|**Konstruktor: A Strong Baseline for Simple Knowledge Graph Question Answering**|Maria Lysyuk et.al.|[2409.15902v1](http://arxiv.org/abs/2409.15902v1)|[link](https://github.com/s-nlp/konstruktor)|
|**2024-09-24**|**Symmetries and Expressive Requirements for Learning General Policies**|Dominik Drexler et.al.|[2409.15892v1](http://arxiv.org/abs/2409.15892v1)|null|
|**2024-09-24**|**HLB: Benchmarking LLMs' Humanlikeness in Language Use**|Xufeng Duan et.al.|[2409.15890v1](http://arxiv.org/abs/2409.15890v1)|null|
|**2024-09-24**|**Machine Translation Advancements of Low-Resource Indian Languages by Transfer Learning**|Bin Wei et.al.|[2409.15879v1](http://arxiv.org/abs/2409.15879v1)|null|
|**2024-09-24**|**Whisper in Medusa's Ear: Multi-head Efficient Decoding for Transformer-based ASR**|Yael Segal-Feldman et.al.|[2409.15869v1](http://arxiv.org/abs/2409.15869v1)|null|
|**2024-09-24**|**Privacy Evaluation Benchmarks for NLP Models**|Wei Huang et.al.|[2409.15868v2](http://arxiv.org/abs/2409.15868v2)|[link](https://github.com/user2311717757/nlp_doctor)|
|**2024-09-24**|**In-Context Ensemble Improves Video-Language Models for Low-Level Workflow Understanding from Human Demonstrations**|Moucheng Xu et.al.|[2409.15867v2](http://arxiv.org/abs/2409.15867v2)|[link](https://github.com/moucheng2017/action-labelling)|
|**2024-09-24**|**BeSimulator: A Large Language Model Powered Text-based Behavior Simulator**|Jianan Wang et.al.|[2409.15865v1](http://arxiv.org/abs/2409.15865v1)|null|
|**2024-09-24**|**A Zero-Shot Open-Vocabulary Pipeline for Dialogue Understanding**|Abdulfattah Safa et.al.|[2409.15861v1](http://arxiv.org/abs/2409.15861v1)|[link](https://github.com/gglab-ku/open-vocab-dialogue-understanding)|
|**2024-09-24**|**Identification For Control Based on Neural Networks: Approximately Linearizable Models**|Maxime Thieffry et.al.|[2409.15858v1](http://arxiv.org/abs/2409.15858v1)|null|
|**2024-09-24**|**iGAiVA: Integrated Generative AI and Visual Analytics in a Machine Learning Workflow for Text Classification**|Yuanzhe Jin et.al.|[2409.15848v1](http://arxiv.org/abs/2409.15848v1)|[link](https://github.com/mattjin19/rbf)|
|**2024-09-24**|**Adaptive Learn-then-Test: Statistically Valid and Efficient Hyperparameter Selection**|Matteo Zecchin et.al.|[2409.15844v1](http://arxiv.org/abs/2409.15844v1)|null|
|**2024-09-24**|**From Passive Watching to Active Learning: Empowering Proactive Participation in Digital Classrooms with AI Video Assistant**|Anna Bodonhelyi et.al.|[2409.15843v1](http://arxiv.org/abs/2409.15843v1)|null|
|**2024-09-24**|**Unveiling Language Competence Neurons: A Psycholinguistic Approach to Model Interpretability**|Xufeng Duan et.al.|[2409.15827v1](http://arxiv.org/abs/2409.15827v1)|null|
|**2024-09-24**|**Empirical Insights on Fine-Tuning Large Language Models for Question-Answering**|Junjie Ye et.al.|[2409.15825v1](http://arxiv.org/abs/2409.15825v1)|null|
|**2024-09-24**|**Supervised Fine-Tuning: An Activation Pattern Optimization Process for Attention Heads**|Yang Zhao et.al.|[2409.15820v1](http://arxiv.org/abs/2409.15820v1)|null|
|**2024-09-24**|**SwiftDossier: Tailored Automatic Dossier for Drug Discovery with LLMs and Agents**|Gabriele Fossi et.al.|[2409.15817v1](http://arxiv.org/abs/2409.15817v1)|null|
|**2024-09-24**|**AsthmaBot: Multi-modal, Multi-Lingual Retrieval Augmented Generation For Asthma Patient Support**|Adil Bahaj et.al.|[2409.15815v1](http://arxiv.org/abs/2409.15815v1)|null|
|**2024-09-24**|**Interactive Example-based Explanations to Improve Health Professionals' Onboarding with AI for Human-AI Collaborative Decision Making**|Min Hun Lee et.al.|[2409.15814v1](http://arxiv.org/abs/2409.15814v1)|null|
|**2024-09-24**|**Layer-wise Model Merging for Unsupervised Domain Adaptation in Segmentation Tasks**|Roberto Alcover-Couso et.al.|[2409.15813v1](http://arxiv.org/abs/2409.15813v1)|null|
|**2024-09-24**|**CLSP: High-Fidelity Contrastive Language-State Pre-training for Agent State Representation**|Fuxian Huang et.al.|[2409.15806v1](http://arxiv.org/abs/2409.15806v1)|null|
|**2024-09-24**|**NER-Luxury: Named entity recognition for the fashion and luxury domain**|Akim Mousterou et.al.|[2409.15804v1](http://arxiv.org/abs/2409.15804v1)|null|
|**2024-09-24**|**Towards Universal Large-Scale Foundational Model for Natural Gas Demand Forecasting**|Xinxing Zhou et.al.|[2409.15794v1](http://arxiv.org/abs/2409.15794v1)|null|
|**2024-09-24**|**Small Language Models: Survey, Measurements, and Insights**|Zhenyan Lu et.al.|[2409.15790v1](http://arxiv.org/abs/2409.15790v1)|null|
|**2024-09-24**|**CHBench: A Chinese Dataset for Evaluating Health in Large Language Models**|Chenlu Guo et.al.|[2409.15766v1](http://arxiv.org/abs/2409.15766v1)|[link](https://github.com/tracyguo2001/chbench)|
|**2024-09-24**|**Spatial-Temporal Mixture-of-Graph-Experts for Multi-Type Crime Prediction**|Ziyang Wu et.al.|[2409.15764v1](http://arxiv.org/abs/2409.15764v1)|null|
|**2024-09-24**|**IRSC: A Zero-shot Evaluation Benchmark for Information Retrieval through Semantic Comprehension in Retrieval-Augmented Generation Scenarios**|Hai Lin et.al.|[2409.15763v1](http://arxiv.org/abs/2409.15763v1)|null|
|**2024-09-24**|**XTRUST: On the Multilingual Trustworthiness of Large Language Models**|Yahan Li et.al.|[2409.15762v1](http://arxiv.org/abs/2409.15762v1)|[link](https://github.com/lluckyyh/xtrust)|
|**2024-09-24**|**TFG: Unified Training-Free Guidance for Diffusion Models**|Haotian Ye et.al.|[2409.15761v1](http://arxiv.org/abs/2409.15761v1)|null|
|**2024-09-24**|**The Roles of Generative Artificial Intelligence in Internet of Electric Vehicles**|Hanwen Zhang et.al.|[2409.15750v1](http://arxiv.org/abs/2409.15750v1)|null|
|**2024-09-24**|**Automated Assessment of Multimodal Answer Sheets in the STEM domain**|Rajlaxmi Patil et.al.|[2409.15749v1](http://arxiv.org/abs/2409.15749v1)|null|
|**2024-09-24**|**Training Neural Networks for Modularity aids Interpretability**|Satvik Golechha et.al.|[2409.15747v1](http://arxiv.org/abs/2409.15747v1)|null|
|**2024-09-24**|**Real-Time Pedestrian Detection on IoT Edge Devices: A Lightweight Deep Learning Approach**|Muhammad Dany Alfikri et.al.|[2409.15740v1](http://arxiv.org/abs/2409.15740v1)|null|
|**2024-09-24**|**EvoFA: Evolvable Fast Adaptation for EEG Emotion Recognition**|Ming Jin et.al.|[2409.15733v1](http://arxiv.org/abs/2409.15733v1)|null|
|**2024-09-24**|**Learning Multiple Probabilistic Decisions from Latent World Model in Autonomous Driving**|Lingyu Xiao et.al.|[2409.15730v1](http://arxiv.org/abs/2409.15730v1)|null|
|**2024-09-24**|**Sequential Learning in the Dense Associative Memory**|Hayden McAlister et.al.|[2409.15729v1](http://arxiv.org/abs/2409.15729v1)|null|
|**2024-09-24**|**LLM-Cure: LLM-based Competitor User Review Analysis for Feature Enhancement**|Maram Assi et.al.|[2409.15724v1](http://arxiv.org/abs/2409.15724v1)|null|
|**2024-09-24**|**Federated Large Language Models: Current Progress and Future Directions**|Yuhang Yao et.al.|[2409.15723v1](http://arxiv.org/abs/2409.15723v1)|null|
|**2024-09-24**|**Adversarial Federated Consensus Learning for Surface Defect Classification Under Data Heterogeneity in IIoT**|Jixuan Cui et.al.|[2409.15711v1](http://arxiv.org/abs/2409.15711v1)|null|

#### Abstracts
##### **Articulated Object Manipulation using Online Axis Estimation with SAM2-Based Tracking**
2409.16287v1 by Xi Wang, Tianxing Chen, Qiaojun Yu, Tianling Xu, Zanxin Chen, Yiting Fu, Cewu Lu, Yao Mu, Ping Luo

Articulated object manipulation requires precise object interaction, where
the object's axis must be carefully considered. Previous research employed
interactive perception for manipulating articulated objects, but typically,
open-loop approaches often suffer from overlooking the interaction dynamics. To
address this limitation, we present a closed-loop pipeline integrating
interactive perception with online axis estimation from segmented 3D point
clouds. Our method leverages any interactive perception technique as a
foundation for interactive perception, inducing slight object movement to
generate point cloud frames of the evolving dynamic scene. These point clouds
are then segmented using Segment Anything Model 2 (SAM2), after which the
moving part of the object is masked for accurate motion online axis estimation,
guiding subsequent robotic actions. Our approach significantly enhances the
precision and efficiency of manipulation tasks involving articulated objects.
Experiments in simulated environments demonstrate that our method outperforms
baseline approaches, especially in tasks that demand precise axis-based
control. Project Page:
https://hytidel.github.io/video-tracking-for-axis-estimation/.

æè¦ï¼é°æ¥ç©ä½æä½éè¦ç²¾ç¡®çç©ä½äº¤äºï¼å¶ä¸­å¿é¡»ä»ç»èèç©ä½çè½´ãååçç ç©¶å©ç¨äº¤äºå¼æç¥æ¥æä½é°æ¥ç©ä½ï¼ä½éå¸¸ï¼å¼ç¯æ¹æ³ç»å¸¸ä¼å¿½ç¥äº¤äºå¨æãä¸ºäºè§£å³è¿ä¸éå¶ï¼æä»¬æåºäºä¸ä¸ªé­ç¯ç®¡éï¼å°äº¤äºå¼æç¥ä¸åæ®µ 3D ç¹äºçå¨çº¿è½´ä¼°è®¡ç¸ç»åãæä»¬çæ¹æ³å©ç¨ä»»ä½äº¤äºå¼æç¥ææ¯ä½ä¸ºäº¤äºå¼æç¥çåºç¡ï¼è¯±å¯¼è½»å¾®çç©ä½è¿å¨ä»¥çæä¸æ­ååçå¨æåºæ¯çç¹äºå¸§ãç¶åä½¿ç¨ Segment Anything Model 2 (SAM2) å¯¹è¿äºç¹äºè¿è¡åæ®µï¼ä¹åå¯¹ç©ä½çç§»å¨é¨åè¿è¡æ©ç å¤çä»¥è¿è¡ç²¾ç¡®çè¿å¨å¨çº¿è½´ä¼°è®¡ï¼æå¯¼åç»­çæºå¨äººå¨ä½ãæä»¬çæ¹æ³æ¾çæé«äºæ¶åé°æ¥ç©ä½çæä½ä»»å¡çç²¾åº¦åæçãæ¨¡æç¯å¢ä¸­çå®éªè¡¨æï¼æä»¬çæ¹æ³ä¼äºåºçº¿æ¹æ³ï¼å°¤å¶æ¯å¨éè¦åºäºç²¾ç¡®è½´çæ§å¶çä»»å¡ä¸­ãé¡¹ç®é¡µé¢ï¼
https://hytidel.github.io/video-tracking-for-axis-estimation/ã

##### **Fields of The World: A Machine Learning Benchmark Dataset For Global Agricultural Field Boundary Segmentation**
2409.16252v1 by Hannah Kerner, Snehal Chaudhari, Aninda Ghosh, Caleb Robinson, Adeel Ahmad, Eddie Choi, Nathan Jacobs, Chris Holmes, Matthias Mohr, Rahul Dodhia, Juan M. Lavista Ferres, Jennifer Marcus

Crop field boundaries are foundational datasets for agricultural monitoring
and assessments but are expensive to collect manually. Machine learning (ML)
methods for automatically extracting field boundaries from remotely sensed
images could help realize the demand for these datasets at a global scale.
However, current ML methods for field instance segmentation lack sufficient
geographic coverage, accuracy, and generalization capabilities. Further,
research on improving ML methods is restricted by the lack of labeled datasets
representing the diversity of global agricultural fields. We present Fields of
The World (FTW) -- a novel ML benchmark dataset for agricultural field instance
segmentation spanning 24 countries on four continents (Europe, Africa, Asia,
and South America). FTW is an order of magnitude larger than previous datasets
with 70,462 samples, each containing instance and semantic segmentation masks
paired with multi-date, multi-spectral Sentinel-2 satellite images. We provide
results from baseline models for the new FTW benchmark, show that models
trained on FTW have better zero-shot and fine-tuning performance in held-out
countries than models that aren't pre-trained with diverse datasets, and show
positive qualitative zero-shot results of FTW models in a real-world scenario
-- running on Sentinel-2 scenes over Ethiopia.

æè¦ï¼ä½ç©ç°çç·æ¯è¾²æ¥­ç£æ¸¬åè©ä¼°çåºæ¬è³æéï¼ä½äººå·¥æ¶éææ¬æè²´ãæ©å¨å­¸ç¿ (ML) æ¹æ³å¯èªåå¾éæ¸¬å½±åä¸­èåç°çç·ï¼æå©æ¼å¨å¨çè¦æ¨¡å¯¦ç¾éäºè³æéçéæ±ãç¶èï¼ç®åçç°åå¯¦ä¾åå² ML æ¹æ³ç¼ºä¹è¶³å¤ çå°çè¦èç¯åãæºç¢ºåº¦åæ¦åè½åãæ­¤å¤ï¼æ¹å ML æ¹æ³çç ç©¶åå°æ¨è¨è³æéç¼ºä¹ä»£è¡¨å¨çè¾²æ¥­ç°åå¤æ¨£æ§çéå¶ãæåæåºä¸çç°é (FTW)ââä¸ç¨®æ°ç ML åºæºè³æéï¼ç¨æ¼æ©«è·¨åå¤§æ´² (æ­æ´²ãéæ´²ãäºæ´²ååç¾æ´²) 24 ååå®¶çè¾²æ¥­ç°åå¯¦ä¾åå²ãFTW çè¦æ¨¡æ¯ååçè³æéå¤§ä¸åæ¸éç´ï¼æ 70,462 åæ¨£æ¬ï¼æ¯åæ¨£æ¬é½åå«å¯¦ä¾åèªç¾©åå²é®ç½©ï¼ä¸¦èå¤æ¥æãå¤åè­ Sentinel-2 è¡æå½±åéå°ãæåæä¾äºæ°ç FTW åºæºçåºæºæ¨¡åçµæï¼é¡¯ç¤ºå¨ FTW ä¸è¨ç·´çæ¨¡åå¨æªè¦éè³æçåå®¶ä¸­æææ¯æªç¶å¤æ¨£åè³æéé åè¨ç·´çæ¨¡åæ´å¥½çé¶æ¬¡å­¸ç¿åå¾®èª¿æè½ï¼ä¸¦å¨çå¯¦ä¸ççå ´æ¯ä¸­é¡¯ç¤º FTW æ¨¡åçæ­£é¢å®æ§é¶æ¬¡å­¸ç¿çµæââå¨è¡£ç´¢æ¯äºä¸å·è¡ Sentinel-2 å ´æ¯ã

##### **A fast and sound tagging method for discontinuous named-entity recognition**
2409.16243v1 by Caio Corro

We introduce a novel tagging scheme for discontinuous named entity
recognition based on an explicit description of the inner structure of
discontinuous mentions. We rely on a weighted finite state automaton for both
marginal and maximum a posteriori inference. As such, our method is sound in
the sense that (1) well-formedness of predicted tag sequences is ensured via
the automaton structure and (2) there is an unambiguous mapping between
well-formed sequences of tags and (discontinuous) mentions. We evaluate our
approach on three English datasets in the biomedical domain, and report
comparable results to state-of-the-art while having a way simpler and faster
model.

æè¦ï¼æåå¼å¥ä¸ç¨®æ°ç©çæ¨è¨æ¹æ¡ï¼ç¨æ¼ä¸é£çºçå½åå¯¦é«è­å¥ï¼æ­¤æ¹æ¡åºæ¼ä¸é£çºæåçå§é¨çµæ§çæç¢ºæè¿°ãæåä¾è³´æ¼å æ¬æéçæèªåæ©ï¼ç¨æ¼ééåæå¤§å¾é©æ¨çãå æ­¤ï¼æåçæ¨¡åå¨ä»¥ä¸æç¾©ä¸æ¯å®åçï¼(1) é æ¸¬æ¨ç±¤åºåçè¯å¥½å½¢ææ§ééèªåæ©çµæ§å¾å°ä¿è­ï¼(2) æ¨ç±¤çè¯å¥½å½¢æåºåå (ä¸é£çº) æåä¹éå­å¨æç¢ºçå°æãæåå¨çç©é«å­¸é åçä¸ä¸ªè±æè³æéä¸è©ä¼°äºæåçæ¹æ³ï¼ä¸¦å ±åäºèæåé²æè¡ç¸ç¶ççµæï¼åææææ´ç°¡å®ãæ´å¿«éçæ¨¡åã

##### **LLM Echo Chamber: personalized and automated disinformation**
2409.16241v1 by Tony Ma

Recent advancements have showcased the capabilities of Large Language Models
like GPT4 and Llama2 in tasks such as summarization, translation, and content
review. However, their widespread use raises concerns, particularly around the
potential for LLMs to spread persuasive, humanlike misinformation at scale,
which could significantly influence public opinion. This study examines these
risks, focusing on LLMs ability to propagate misinformation as factual. To
investigate this, we built the LLM Echo Chamber, a controlled digital
environment simulating social media chatrooms, where misinformation often
spreads. Echo chambers, where individuals only interact with like minded
people, further entrench beliefs. By studying malicious bots spreading
misinformation in this environment, we can better understand this phenomenon.
We reviewed current LLMs, explored misinformation risks, and applied sota
finetuning techniques. Using Microsoft phi2 model, finetuned with our custom
dataset, we generated harmful content to create the Echo Chamber. This setup,
evaluated by GPT4 for persuasiveness and harmfulness, sheds light on the
ethical concerns surrounding LLMs and emphasizes the need for stronger
safeguards against misinformation.

æè¦ï¼æè¿çé²å±å±ç¤ºäºå¤§åèªè¨æ¨¡å (LLM) çè½åï¼ä¾å¦ GPT4 å Llama2ï¼å¨æè¦ãç¿»è­¯åå§å®¹å¯©æ¥ç­ä»»åä¸­çæç¨ãç¶èï¼å®åçå»£æ³ä½¿ç¨å¼ç¼äºææï¼ç¹å¥æ¯ LLM å¯è½å¤§è¦æ¨¡æ£å¸å·æèªªæåçãé¡ä¼¼äººé¡çé¯èª¤è¨æ¯ï¼éå¯è½æé¡¯èå½±é¿å¬ç¾è¼¿è«ãæ¬ç ç©¶æ¢è¨äºéäºé¢¨éªï¼éé»éæ³¨ LLM å°é¯èª¤è¨æ¯å³æ­çºäºå¯¦çè½åãçºäºèª¿æ¥éä¸é»ï¼æåå»ºç«äº LLM åé³å®¤ï¼ä¸ååæ§çæ¸ä½ç°å¢ï¼æ¨¡æ¬ç¤¾ç¾¤åªé«èå¤©å®¤ï¼é¯èª¤è¨æ¯éå¸¸å¨å¶ä¸­æ£å¸ãåé³å®¤ï¼åäººåªèå¿åéåçäººäºåï¼é²ä¸æ­¥å æ·±äºä¿¡å¿µãééç ç©¶å¨éç¨®ç°å¢ä¸­æ£å¸é¯èª¤è¨æ¯çæ¡ææ©å¨äººï¼æåå¯ä»¥æ´å¥½å°çè§£éç¨®ç¾è±¡ãæååé¡§äºç®åç LLMï¼æ¢è¨äºé¯èª¤è¨æ¯çé¢¨éªï¼ä¸¦æç¨ sota å¾®èª¿æè¡ãä½¿ç¨ Microsoft phi2 æ¨¡åï¼ä½¿ç¨æåçèªè¨è³æéé²è¡å¾®èª¿ï¼æåçæäºæå®³å§å®¹ä»¥å»ºç«åé³å®¤ãæ­¤è¨­å®ç± GPT4 è©ä¼°å¶èªªæååå±å®³æ§ï¼æ­ç¤ºäºåç¹ LLM çéå¾·åé¡ï¼ä¸¦å¼·èª¿äºå°æé¯èª¤è¨æ¯éè¦æ´å¼·æåçä¿éæªæ½ã

##### **Efficiently Learning Probabilistic Logical Models by Cheaply Ranking Mined Rules**
2409.16238v1 by Jonathan Feldstein, Dominic Phillips, Efthymia Tsamoura

Probabilistic logical models are a core component of neurosymbolic AI and are
important models in their own right for tasks that require high explainability.
Unlike neural networks, logical models are often handcrafted using domain
expertise, making their development costly and prone to errors. While there are
algorithms that learn logical models from data, they are generally
prohibitively expensive, limiting their applicability in real-world settings.
In this work, we introduce precision and recall for logical rules and define
their composition as rule utility -- a cost-effective measure to evaluate the
predictive power of logical models. Further, we introduce SPECTRUM, a scalable
framework for learning logical models from relational data. Its scalability
derives from a linear-time algorithm that mines recurrent structures in the
data along with a second algorithm that, using the cheap utility measure,
efficiently ranks rules built from these structures. Moreover, we derive
theoretical guarantees on the utility of the learnt logical model. As a result,
SPECTRUM learns more accurate logical models orders of magnitude faster than
previous methods on real-world datasets.

æè¦ï¼æ©çéè¼¯æ¨¡åæ¯ç¥ç¶ç¬¦è AI çæ ¸å¿çµæé¨åï¼èä¸æ¬èº«å°±æ¯éè¦é«å¯è§£éæ§çä»»åä¸­éè¦çæ¨¡åãèç¥ç¶ç¶²è·¯ä¸åï¼éè¼¯æ¨¡åéå¸¸ä½¿ç¨é åå°æ¥­ç¥è­æå·¥æé ï¼éä½¿å¾å¶éç¼ææ¬é«æä¸å®¹æåºé¯ãéç¶æå¾è³æä¸­å­¸ç¿éè¼¯æ¨¡åçæ¼ç®æ³ï¼ä½å®åéå¸¸ææ¬é«å¾ä»¤äººé£ä»¥æ¥åï¼éå¶äºå®åå¨å¯¦éç°å¢ä¸­çæç¨æ§ãå¨éé å·¥ä½ä¸­ï¼æåå¼å¥äºéè¼¯è¦åçæºç¢ºåº¦åå¬åçï¼ä¸¦å°å®åççµåå®ç¾©çºè¦åæç¨ï¼éæ¯ä¸ç¨®è©ä¼°éè¼¯æ¨¡åé æ¸¬è½åçç¶æ¿ææçæ¹æ³ãæ­¤å¤ï¼æåéå¼å¥äº SPECTRUMï¼éæ¯ä¸åå¾éè¯è³æä¸­å­¸ç¿éè¼¯æ¨¡åçå¯æ´åæ¡æ¶ãå®çå¯æ´åæ§ä¾èªæ¼ä¸åç·æ§æéæ¼ç®æ³ï¼è©²æ¼ç®æ³ææ¢åè³æä¸­çéè¿´çµæ§ï¼ä»¥åä¸åä½¿ç¨ä¾¿å®æç¨æ¸¬éå¼ææå°å¾éäºçµæ§å»ºç«çè¦åé²è¡æåºçç¬¬äºåæ¼ç®æ³ãæ­¤å¤ï¼æåéæ¨å°åºéæ¼å­¸ç¿éè¼¯æ¨¡åæç¨ççè«ä¿è­ãå æ­¤ï¼SPECTRUM æ¯ååçå¯¦åè³æéæ¹æ³å¿«ä¸å¥½å¹¾åæ¸éç´ï¼å¯ä»¥å­¸ç¿æ´æºç¢ºçéè¼¯æ¨¡åã

##### **EuroLLM: Multilingual Language Models for Europe**
2409.16235v1 by Pedro Henrique Martins, Patrick Fernandes, JoÃ£o Alves, Nuno M. Guerreiro, Ricardo Rei, Duarte M. Alves, JosÃ© Pombal, Amin Farajian, Manuel Faysse, Mateusz Klimaszewski, Pierre Colombo, Barry Haddow, JosÃ© G. C. de Souza, Alexandra Birch, AndrÃ© F. T. Martins

The quality of open-weight LLMs has seen significant improvement, yet they
remain predominantly focused on English. In this paper, we introduce the
EuroLLM project, aimed at developing a suite of open-weight multilingual LLMs
capable of understanding and generating text in all official European Union
languages, as well as several additional relevant languages. We outline the
progress made to date, detailing our data collection and filtering process, the
development of scaling laws, the creation of our multilingual tokenizer, and
the data mix and modeling configurations. Additionally, we release our initial
models: EuroLLM-1.7B and EuroLLM-1.7B-Instruct and report their performance on
multilingual general benchmarks and machine translation.

æè¦ï¼éæ¾æ¬é LLM çåè³ªå·²å¤§å¹æåï¼ä½å®åä»ä¸»è¦éå°è±èªãå¨æ¬æä¸­ï¼æåä»ç´¹ EuroLLM è¨ç«ï¼å¶ç®æ¨æ¯éç¼ä¸å¥éæ¾æ¬éå¤èªè¨ LLMï¼è½å¤ çè§£ä¸¦ç¢çæææ­çå®æ¹èªè¨ä»¥åå¶ä»æ¸ç¨®ç¸éèªè¨çæå­ãæåæ¦è¿°è³ä»çé²åº¦ï¼è©³ç´°èªªææåçè³ææ¶éåç¯©é¸ç¨åºãç¸®æ¾å®å¾çç¼å±ãå¤èªè¨åè©å¨çå»ºç«ï¼ä»¥åè³æçµååå»ºæ¨¡è¨­å®ãæ­¤å¤ï¼æåç¼å¸æåçåå§æ¨¡åï¼EuroLLM-1.7B å EuroLLM-1.7B-Instructï¼ä¸¦å ±åå®åå¨å¤èªè¨ä¸è¬åºæºåæ©å¨ç¿»è­¯ä¸çè¡¨ç¾ã

##### **Predicting Deterioration in Mild Cognitive Impairment with Survival Transformers, Extreme Gradient Boosting and Cox Proportional Hazard Modelling**
2409.16231v1 by Henry Musto, Daniel Stamate, Doina Logofatu, Daniel Stahl

The paper proposes a novel approach of survival transformers and extreme
gradient boosting models in predicting cognitive deterioration in individuals
with mild cognitive impairment (MCI) using metabolomics data in the ADNI
cohort. By leveraging advanced machine learning and transformer-based
techniques applied in survival analysis, the proposed approach highlights the
potential of these techniques for more accurate early detection and
intervention in Alzheimer's dementia disease. This research also underscores
the importance of non-invasive biomarkers and innovative modelling tools in
enhancing the accuracy of dementia risk assessments, offering new avenues for
clinical practice and patient care. A comprehensive Monte Carlo simulation
procedure consisting of 100 repetitions of a nested cross-validation in which
models were trained and evaluated, indicates that the survival machine learning
models based on Transformer and XGBoost achieved the highest mean C-index
performances, namely 0.85 and 0.8, respectively, and that they are superior to
the conventional survival analysis Cox Proportional Hazards model which
achieved a mean C-Index of 0.77. Moreover, based on the standard deviations of
the C-Index performances obtained in the Monte Carlo simulation, we established
that both survival machine learning models above are more stable than the
conventional statistical model.

æè¦ï¼éç¯è«ææåºäºä¸ç¨®æ°çæ¹æ³ï¼ä½¿ç¨ ADNI éä¼ä¸­çä»£è¬çµå­¸è³æï¼å¨èªç¥åè½è¼å¾®åæ (MCI) çåé«ä¸­é æ¸¬èªç¥æ¡åï¼éç¨®æ¹æ³çµåäºçå­è½æå¨åæ¥µç«¯æ¢¯åº¦æåæ¨¡åãééå©ç¨é²éæ©å¨å­¸ç¿ååºæ¼è½æå¨çæè¡ï¼æç¨æ¼å­æ´»åæï¼æåºçæ¹æ³çªé¡¯äºéäºæè¡å¨é¿è²æµ·é»çå¤±æºçä¸­æ´æºç¢ºçæ©ææª¢æ¸¬åå¹²é çæ½åãéé ç ç©¶ä¹å¼·èª¿äºéä¾µå¥æ§çç©æ¨è¨ååµæ°å»ºæ¨¡å·¥å·å¨æåå¤±æºçé¢¨éªè©ä¼°æºç¢ºåº¦ä¸­çéè¦æ§ï¼çºè¨åºå¯¦ååçäººç§è­·æä¾äºæ°éå¾ãä¸ååå« 100 æ¬¡å·¢çäº¤åé©è­éè¤çç¶åèå°å¡ç¾æ¨¡æ¬ç¨åºï¼å¶ä¸­æ¨¡åç¶éè¨ç·´åè©ä¼°ï¼é¡¯ç¤ºåºæ¼è½æå¨å XGBoost ççå­æ©å¨å­¸ç¿æ¨¡åéå°äºæé«çå¹³å C ææ¸è¡¨ç¾ï¼åå¥çº 0.85 å 0.8ï¼èä¸å®ååªæ¼å³çµ±ççå­åæ Cox æ¯ä¾é¢¨éªæ¨¡åï¼å¾èçå¹³å C ææ¸çº 0.77ãæ­¤å¤ï¼æ ¹æèå°å¡ç¾æ¨¡æ¬ä¸­ç²å¾ç C ææ¸è¡¨ç¾çæ¨æºå·®ï¼æåç¢ºç«äºä¸è¿°å©ç¨®çå­æ©å¨å­¸ç¿æ¨¡åé½æ¯å³çµ±ççµ±è¨æ¨¡åæ´ç©©å®ã

##### **Fine-Tuning is Fine, if Calibrated**
2409.16223v1 by Zheda Mai, Arpita Chowdhury, Ping Zhang, Cheng-Hao Tu, Hong-You Chen, Vardaan Pahuja, Tanya Berger-Wolf, Song Gao, Charles Stewart, Yu Su, Wei-Lun Chao

Fine-tuning is arguably the most straightforward way to tailor a pre-trained
model (e.g., a foundation model) to downstream applications, but it also comes
with the risk of losing valuable knowledge the model had learned in
pre-training. For example, fine-tuning a pre-trained classifier capable of
recognizing a large number of classes to master a subset of classes at hand is
shown to drastically degrade the model's accuracy in the other classes it had
previously learned. As such, it is hard to further use the fine-tuned model
when it encounters classes beyond the fine-tuning data. In this paper, we
systematically dissect the issue, aiming to answer the fundamental question,
''What has been damaged in the fine-tuned model?'' To our surprise, we find
that the fine-tuned model neither forgets the relationship among the other
classes nor degrades the features to recognize these classes. Instead, the
fine-tuned model often produces more discriminative features for these other
classes, even if they were missing during fine-tuning! {What really hurts the
accuracy is the discrepant logit scales between the fine-tuning classes and the
other classes}, implying that a simple post-processing calibration would bring
back the pre-trained model's capability and at the same time unveil the feature
improvement over all classes. We conduct an extensive empirical study to
demonstrate the robustness of our findings and provide preliminary explanations
underlying them, suggesting new directions for future theoretical analysis. Our
code is available at
https://github.com/OSU-MLB/Fine-Tuning-Is-Fine-If-Calibrated.

æè¦ï¼å¾®èª¿ç¡çæ¯éå°é åè¨ç·´æ¨¡åï¼ä¾å¦åºç¤æ¨¡åï¼ä»¥é©æä¸æ¸¸æç¨æç´æ¥çæ¹æ³ï¼ä½å®ä¹ä¼´é¨èå¤±å»æ¨¡åå¨é åè¨ç·´ä¸­å­¸å°çå¯¶è²´ç¥è­çé¢¨éªãä¾å¦ï¼å¾®èª¿ä¸åé åè¨ç·´çåé¡å¨ï¼å®è½å¤ è­å¥å¤§éçé¡å¥ï¼ä»¥ææ¡æéçé¡å¥å­éï¼éå·²è¢«è­ææå¤§å¹éä½æ¨¡åå¨ååå­¸å°çå¶ä»é¡å¥ä¸­çæºç¢ºåº¦ãå æ­¤ï¼ç¶å¾®èª¿æ¨¡åéå°å¾®èª¿æ¸æä¹å¤çé¡å¥æï¼å¾é£é²ä¸æ­¥ä½¿ç¨å®ãå¨æ¬æä¸­ï¼æåç³»çµ±æ§å°åæäºéååé¡ï¼æ¨å¨åç­éååºæ¬åé¡ï¼ãå¾®èª¿æ¨¡åä¸­æå£äºä»éº¼ï¼ãä»¤æåé©è¨çæ¯ï¼æåç¼ç¾å¾®èª¿æ¨¡åæ¢ä¸æå¿è¨å¶ä»é¡å¥ä¹éçéä¿ï¼ä¹ä¸æéä½è­å¥éäºé¡å¥çç¹å¾µãç¸åï¼å¾®èª¿æ¨¡åéå¸¸æçºéäºå¶ä»é¡å¥ç¢çæ´å¤å·åå¥æ§çç¹å¾µï¼å³ä½¿å®åå¨å¾®èª¿éç¨ä¸­ç¼ºå¤±ï¼{çæ­£æå®³æºç¢ºåº¦çæ¯å¾®èª¿é¡å¥åå¶å®é¡å¥ä¹éä¸åç logit å°ºåº¦}ï¼éæå³èä¸åç°¡å®çå¾èçæ ¡æºå°æå¸¶åé åè¨ç·´æ¨¡åçè½åï¼åææ­ç¤ºææé¡å¥çç¹å¾µæ¹é²ãæåé²è¡äºä¸é å»£æ³çå¯¦è­ç ç©¶ï¼ä»¥è­ææåç¼ç¾çç©©å¥æ§ï¼ä¸¦æä¾äºå®åèå¾çåæ­¥è§£éï¼çºæªä¾ççè«åææåºäºæ°çæ¹åãæåçç¨å¼ç¢¼å¯ä»¥å¨ https://github.com/OSU-MLB/Fine-Tuning-Is-Fine-If-Calibrated åå¾ã

##### **Towards Enhancing Linked Data Retrieval in Conversational UIs using Large Language Models**
2409.16220v1 by Omar Mussa, Omer Rana, BenoÃ®t Goossens, Pablo Orozco-Terwengel, Charith Perera

Despite the recent broad adoption of Large Language Models (LLMs) across
various domains, their potential for enriching information systems in
extracting and exploring Linked Data (LD) and Resource Description Framework
(RDF) triplestores has not been extensively explored. This paper examines the
integration of LLMs within existing systems, emphasising the enhancement of
conversational user interfaces (UIs) and their capabilities for data extraction
by producing more accurate SPARQL queries without the requirement for model
retraining. Typically, conversational UI models necessitate retraining with the
introduction of new datasets or updates, limiting their functionality as
general-purpose extraction tools. Our approach addresses this limitation by
incorporating LLMs into the conversational UI workflow, significantly enhancing
their ability to comprehend and process user queries effectively. By leveraging
the advanced natural language understanding capabilities of LLMs, our method
improves RDF entity extraction within web systems employing conventional
chatbots. This integration facilitates a more nuanced and context-aware
interaction model, critical for handling the complex query patterns often
encountered in RDF datasets and Linked Open Data (LOD) endpoints. The
evaluation of this methodology shows a marked enhancement in system
expressivity and the accuracy of responses to user queries, indicating a
promising direction for future research in this area. This investigation not
only underscores the versatility of LLMs in enhancing existing information
systems but also sets the stage for further explorations into their potential
applications within more specialised domains of web information systems.

æè¦ï¼åç®¡å¤§åèªè¨æ¨¡å (LLM) è¿æå»£æ³å°è¢«æ¡ç¨æ¼åç¨®é åï¼å®åå¨è±å¯è³è¨ç³»çµ±ä¸­èååæ¢ç´¢é£çµè³æ (LD) åè³æºæè¿°æ¶æ§ (RDF) ä¸è¯å²å­åº«çæ½åå°æªè¢«å»£æ³æ¢è¨ãæ¬ææ¢è¨å¨ç¾æç³»çµ±ä¸­æ´å LLMï¼å¼·èª¿å°è©±å¼ä½¿ç¨èä»é¢ (UI) çå¼·åï¼ä»¥åå®åå¨ç¡ééæ°è¨ç·´æ¨¡åçææ³ä¸ç¢çæ´ç²¾ç¢ºç SPARQL æ¥è©¢ï¼ä»¥é²è¡è³æèåçè½åãä¸è¬ä¾èªªï¼å°è©±å¼ UI æ¨¡åéè¦å¨å¼å¥æ°çè³æéææ´æ°æéæ°è¨ç·´ï¼ééå¶äºå®åä½çºéç¨èåå·¥å·çåè½ãæåçåæ³ééå° LLM æ´åå°å°è©±å¼ UI å·¥ä½æµç¨ä¸­ä¾è§£æ±ºéåéå¶ï¼å¤§å¹æåå®åçè§£åææèçä½¿ç¨èæ¥è©¢çè½åãééå©ç¨ LLM çé²éèªç¶èªè¨çè§£è½åï¼æåçåæ³æ¹åäºæ¡ç¨å³çµ±èå¤©æ©å¨äººçç¶²è·¯ç³»çµ±ä¸­ç RDF å¯¦é«èåãéç¨®æ´åä¿æäºä¸åæ´ç´°ç·»ä¸å·åæå¢æç¥çäºåæ¨¡åï¼éå°æ¼èç RDF è³æéåé£çµéæ¾è³æ (LOD) ç«¯é»ä¸­ç¶å¸¸éå°çè¤éæ¥è©¢æ¨¡å¼è³ééè¦ãå°æ­¤æ¹æ³çè©ä¼°é¡¯ç¤ºç³»çµ±è¡¨éè½ååå°ä½¿ç¨èæ¥è©¢åæçæºç¢ºåº¦é½æé¡¯èçæåï¼éè¡¨ç¤ºæ­¤é åæªä¾çç ç©¶æææéåæ¹åç¼å±ãéé èª¿æ¥ä¸åå¼·èª¿äº LLM å¨å¼·åç¾æè³è¨ç³»çµ±æ¹é¢çå¤åè½æ§ï¼ä¹çºé²ä¸æ­¥æ¢ç´¢å®åå¨æ´å°æ¥­çç¶²è·¯è³è¨ç³»çµ±é åä¸­çæ½å¨æç¨å¥ å®äºåºç¤ã

##### **Problem-oriented AutoML in Clustering**
2409.16218v1 by Matheus Camilo da Silva, Gabriel Marques Tavares, Eric Medvet, Sylvio Barbon Junior

The Problem-oriented AutoML in Clustering (PoAC) framework introduces a
novel, flexible approach to automating clustering tasks by addressing the
shortcomings of traditional AutoML solutions. Conventional methods often rely
on predefined internal Clustering Validity Indexes (CVIs) and static
meta-features, limiting their adaptability and effectiveness across diverse
clustering tasks. In contrast, PoAC establishes a dynamic connection between
the clustering problem, CVIs, and meta-features, allowing users to customize
these components based on the specific context and goals of their task. At its
core, PoAC employs a surrogate model trained on a large meta-knowledge base of
previous clustering datasets and solutions, enabling it to infer the quality of
new clustering pipelines and synthesize optimal solutions for unseen datasets.
Unlike many AutoML frameworks that are constrained by fixed evaluation metrics
and algorithm sets, PoAC is algorithm-agnostic, adapting seamlessly to
different clustering problems without requiring additional data or retraining.
Experimental results demonstrate that PoAC not only outperforms
state-of-the-art frameworks on a variety of datasets but also excels in
specific tasks such as data visualization, and highlight its ability to
dynamically adjust pipeline configurations based on dataset complexity.

æè¦ï¼åé¡å°åå¼å¢éèªååæ©å¨å­¸ç¿ (PoAC) æ¶æ§å°å¥äºä¸ç¨®
æ°ç©ä¸å½æ§çæ¹æ³ä¾èªååå¢éä»»åï¼è§£æ±ºå³çµ±èªååæ©å¨å­¸ç¿
è§£æ±ºæ¹æ¡çç¼ºé»ãå³çµ±æ¹æ³éå¸¸ä¾è³´é åå®ç¾©çå§é¨å¢éæææ§
ææ¨ (CVI) åéæåç¹å¾µï¼ééå¶äºå¶å¨ä¸åå¢éä»»åä¸­çé©æ
æ§åæææ§ãç¸åï¼PoAC å¨å¢éåé¡ãCVI ååç¹å¾µä¹éå»ºç«äº
åæé£æ¥ï¼ä½¿ç¨æ¶è½å¤ æ ¹æå¶ä»»åçç¹å®èæ¯åç®æ¨èªè¨éäº
çµæé¨åãPoAC çæ ¸å¿æ¡ç¨ä¸åä»£çæ¨¡åï¼è©²æ¨¡åè¨ç·´æ¼ä¸å
å¤§ååç¥è­åº«ï¼å¶ä¸­åå«ååçå¢éè³æéåè§£æ±ºæ¹æ¡ï¼ä½¿å¶è½
å¤ æ¨æ·æ°å¢éç®¡ç·çåè³ªï¼ä¸¦çºæªè¦è³æéç¶åæä½³è§£æ±ºæ¹æ¡ã
èè¨±å¤åéæ¼åºå®è©ä¼°ææ¨åæ¼ç®æ³éçèªååæ©å¨å­¸ç¿æ¶æ§
ä¸åï¼PoAC èæ¼ç®æ³ç¡éï¼è½ç¡ç¸«å°é©æä¸åçå¢éåé¡ï¼è
ç¡éé¡å¤è³ææéæ°è¨ç·´ãå¯¦é©çµæè­æï¼PoAC ä¸åå¨åç¨®è³æ
éä¸åªæ¼æåé²çæ¶æ§ï¼èä¸å¨ç¹å®ä»»åï¼ä¾å¦è³æè¦è¦ºåï¼ä¸­
ä¹è¡¨ç¾åºè²ï¼ä¸¦çªé¡¯äºå¶æ ¹æè³æéè¤éæ§åæèª¿æ´ç®¡ç·çµæç
è½åã

##### **Facial Expression-Enhanced TTS: Combining Face Representation and Emotion Intensity for Adaptive Speech**
2409.16203v1 by Yunji Chu, Yunseob Shim, Unsang Park

We propose FEIM-TTS, an innovative zero-shot text-to-speech (TTS) model that
synthesizes emotionally expressive speech, aligned with facial images and
modulated by emotion intensity. Leveraging deep learning, FEIM-TTS transcends
traditional TTS systems by interpreting facial cues and adjusting to emotional
nuances without dependence on labeled datasets. To address sparse
audio-visual-emotional data, the model is trained using LRS3, CREMA-D, and MELD
datasets, demonstrating its adaptability. FEIM-TTS's unique capability to
produce high-quality, speaker-agnostic speech makes it suitable for creating
adaptable voices for virtual characters. Moreover, FEIM-TTS significantly
enhances accessibility for individuals with visual impairments or those who
have trouble seeing. By integrating emotional nuances into TTS, our model
enables dynamic and engaging auditory experiences for webcomics, allowing
visually impaired users to enjoy these narratives more fully. Comprehensive
evaluation evidences its proficiency in modulating emotion and intensity,
advancing emotional speech synthesis and accessibility. Samples are available
at: https://feim-tts.github.io/.

æè¦ï¼æåæåº FEIM-TTSï¼éæ¯ä¸ååµæ°çé¶æ¬¡å­¸ç¿æå­è½èªé³ (TTS) æ¨¡åï¼å®å¯ä»¥åæå¯æææè¡¨éåçèªé³ï¼èé¢é¨å½±åå°é½ï¼ä¸¦æ ¹ææç·å¼·åº¦é²è¡èª¿æ´ãFEIM-TTS ééæ·±åº¦å­¸ç¿è¶è¶å³çµ±ç TTS ç³»çµ±ï¼å®å¯ä»¥è§£è®é¢é¨ç·ç´¢ä¸¦èª¿æ´æç·ç´°å¾®å·®å¥ï¼èç¡éä¾è³´æ¨è¨è³æéãçºäºèçç¨ççè¦è½æç·è³æï¼æ­¤æ¨¡åä½¿ç¨ LRS3ãCREMA-D å MELD è³æéé²è¡è¨ç·´ï¼å±ç¾å¶é©ææ§ãFEIM-TTS å·æç¨ç¹çè½åï¼å¯ä»¥ç¢çé«åè³ªãèèªªè©±èç¡éçèªé³ï¼éä½¿å¶é©ç¨æ¼çºèæ¬è§è²åµé å¯é©æçè²é³ãæ­¤å¤ï¼FEIM-TTS å¤§å¹æåäºè¦éäººå£«ææè¦ååé¡èçç¡éç¤æ§ãééå°æç·ç´°å¾®å·®å¥æ´åå° TTS ä¸­ï¼æåçæ¨¡åè½çºç¶²è·¯æ¼«ç«å¸¶ä¾åæä¸å¼äººå¥åçè½è¦ºé«é©ï¼è®è¦éä½¿ç¨èè½æ´ååäº«åéäºæäºãå¨é¢çè©ä¼°è­æäºå¶å¨èª¿æ´æç·åå¼·åº¦æ¹é¢çè½åï¼é²èæ¨åäºæç·èªé³åæåç¡éç¤æ§ãç¯ä¾å¯å¨ä»¥ä¸ç¶²ååå¾ï¼https://feim-tts.github.io/ã

##### **CJEval: A Benchmark for Assessing Large Language Models Using Chinese Junior High School Exam Data**
2409.16202v2 by Qian-Wen Zhang, Haochen Wang, Fang Li, Siyu An, Lingfeng Qiao, Liangcai Gao, Di Yin, Xing Sun

Online education platforms have significantly transformed the dissemination
of educational resources by providing a dynamic and digital infrastructure.
With the further enhancement of this transformation, the advent of Large
Language Models (LLMs) has elevated the intelligence levels of these platforms.
However, current academic benchmarks provide limited guidance for real-world
industry scenarios. This limitation arises because educational applications
require more than mere test question responses. To bridge this gap, we
introduce CJEval, a benchmark based on Chinese Junior High School Exam
Evaluations. CJEval consists of 26,136 samples across four application-level
educational tasks covering ten subjects. These samples include not only
questions and answers but also detailed annotations such as question types,
difficulty levels, knowledge concepts, and answer explanations. By utilizing
this benchmark, we assessed LLMs' potential applications and conducted a
comprehensive analysis of their performance by fine-tuning on various
educational tasks. Extensive experiments and discussions have highlighted the
opportunities and challenges of applying LLMs in the field of education.

æè¦ï¼ç·ä¸æè²å¹³å°ééæä¾åæä¸æ¸ä½çåºç¤å»ºè¨­ï¼å¤§å¹è½è®äºæè²è³æºçå³æ­æ¹å¼ãé¨èéé è½åçé²ä¸æ­¥å å¼·ï¼å¤§åèªè¨æ¨¡å (LLM) çåºç¾æåäºéäºå¹³å°çæºæ§å±¤ç´ãç¶èï¼ç®åçå­¸è¡åºæºåæä¾æéçæå¼ï¼ç¨æ¼çå¯¦ä¸ççç¢æ¥­æå¢ãéåéå¶çç¢çï¼æ¯å çºæè²æç¨ç¨å¼éè¦çä¸åªæ¯å®ç´çæ¸¬é©åé¡è§£ç­ãçºäºå½è£éåå·®è·ï¼æåå¼å¥äº CJEvalï¼ä¸ååºæ¼ä¸­ååä¸­èè©¦è©éçåºæºãCJEval åå«äº 26,136 åç¯ä¾ï¼æ¶µèäºååç§ç®çååæç¨å±¤ç´æè²ä»»åãéäºç¯ä¾ä¸ååæ¬é¡ç®åç­æ¡ï¼ä¹åå«äºè©³ç´°çè¨»è§£ï¼ä¾å¦é¡åãé£åº¦ç­ç´ãç¥è­æ¦å¿µåç­æ¡èªªæãééå©ç¨éååºæºï¼æåè©ä¼°äº LLM çæ½å¨æç¨ï¼ä¸¦ééå¾®èª¿åç¨®æè²ä»»åï¼å°å¶æè½é²è¡äºå¨é¢çåæãå»£æ³çå¯¦é©åè¨è«çªé¡¯äºå¨æè²é åæç¨ LLM çæ©æåææ°ã

##### **Leveraging Estimated Transferability Over Human Intuition for Model Selection in Text Ranking**
2409.16198v1 by Jun Bai, Zhuofan Chen, Zhenzi Li, Hanhua Hong, Jianfei Zhang, Chen Li, Chenghua Lin, Wenge Rong

Text ranking has witnessed significant advancements, attributed to the
utilization of dual-encoder enhanced by Pre-trained Language Models (PLMs).
Given the proliferation of available PLMs, selecting the most effective one for
a given dataset has become a non-trivial challenge. As a promising alternative
to human intuition and brute-force fine-tuning, Transferability Estimation (TE)
has emerged as an effective approach to model selection. However, current TE
methods are primarily designed for classification tasks, and their estimated
transferability may not align well with the objectives of text ranking. To
address this challenge, we propose to compute the expected rank as
transferability, explicitly reflecting the model's ranking capability.
Furthermore, to mitigate anisotropy and incorporate training dynamics, we
adaptively scale isotropic sentence embeddings to yield an accurate expected
rank score. Our resulting method, Adaptive Ranking Transferability (AiRTran),
can effectively capture subtle differences between models. On challenging model
selection scenarios across various text ranking datasets, it demonstrates
significant improvements over previous classification-oriented TE methods,
human intuition, and ChatGPT with minor time consumption.

æè¦ï¼ææ¬æåå·²è¦è­é¡¯èé²å±ï¼éæ­¸åæ¼ç±é è¨ç·´èªè¨æ¨¡å (PLM) å¢å¼·çéç·¨ç¢¼å¨å©ç¨ã
éæ¼ç¾æ PLM çæ¿å¢ï¼çºç¹å®è³æéé¸ææææç PLM å·²æçºä¸é éå¡çææ°ãä½çºäººé¡ç´è¦ºåè »åå¾®èª¿çæå¸æçæ¿ä»£æ¹æ¡ï¼å¯è½ç§»æ§ä¼°è¨ (TE) å·²æçºæ¨¡åé¸æçä¸ç¨®æææ¹æ³ãç¶èï¼ç®åç TE æ¹æ³ä¸»è¦è¨­è¨ç¨æ¼åé¡ä»»åï¼ä¸å¶ä¼°è¨çå¯è½ç§»æ§å¯è½èææ¬æåçç®æ¨ä¸ç¬¦ãçºäºæå°éä¸ææ°ï¼æåæè­°å°é ææåè¨ç®çºå¯è½ç§»æ§ï¼æç¢ºåæ æ¨¡åçæåè½åã
æ­¤å¤ï¼çºäºæ¸è¼ç°æ¹ç°æ§ä¸¦ç´å¥è¨ç·´åæï¼æåèªé©æå°èª¿æ´åååæ§å¥å­åµå¥ä»¥ç¢çæºç¢ºçé ææååæ¸ãæåç±æ­¤ç¢ççæ¹æ³ï¼èªé©ææåå¯è½ç§»æ§ (AiRTran)ï¼å¯ä»¥æææææ¨¡åä¹éçç´°å¾®å·®ç°ãå¨åç¨®ææ¬æåè³æéä¸­çå·æææ°æ§çæ¨¡åé¸æå ´æ¯ä¸­ï¼å®å±ç¤ºäºç¸è¼æ¼ååçåé¡å°å TE æ¹æ³ãäººé¡ç´è¦ºå ChatGPT çé¡¯èæ¹é²ï¼ä¸èæè¼å°ã

##### **HelloBench: Evaluating Long Text Generation Capabilities of Large Language Models**
2409.16191v1 by Haoran Que, Feiyu Duan, Liqun He, Yutao Mou, Wangchunshu Zhou, Jiaheng Liu, Wenge Rong, Zekun Moore Wang, Jian Yang, Ge Zhang, Junran Peng, Zhaoxiang Zhang, Songyang Zhang, Kai Chen

In recent years, Large Language Models (LLMs) have demonstrated remarkable
capabilities in various tasks (e.g., long-context understanding), and many
benchmarks have been proposed. However, we observe that long text generation
capabilities are not well investigated. Therefore, we introduce the
Hierarchical Long Text Generation Benchmark (HelloBench), a comprehensive,
in-the-wild, and open-ended benchmark to evaluate LLMs' performance in
generating long text. Based on Bloom's Taxonomy, HelloBench categorizes long
text generation tasks into five subtasks: open-ended QA, summarization, chat,
text completion, and heuristic text generation. Besides, we propose
Hierarchical Long Text Evaluation (HelloEval), a human-aligned evaluation
method that significantly reduces the time and effort required for human
evaluation while maintaining a high correlation with human evaluation. We have
conducted extensive experiments across around 30 mainstream LLMs and observed
that the current LLMs lack long text generation capabilities. Specifically,
first, regardless of whether the instructions include explicit or implicit
length constraints, we observe that most LLMs cannot generate text that is
longer than 4000 words. Second, we observe that while some LLMs can generate
longer text, many issues exist (e.g., severe repetition and quality
degradation). Third, to demonstrate the effectiveness of HelloEval, we compare
HelloEval with traditional metrics (e.g., ROUGE, BLEU, etc.) and LLM-as-a-Judge
methods, which show that HelloEval has the highest correlation with human
evaluation. We release our code in https://github.com/Quehry/HelloBench.

æè¦ï¼è¿å¹´æ¥ï¼å¤§è¯­è¨æ¨¡å (LLM) å¨åç§ä»»å¡ï¼ä¾å¦ï¼é¿ææ¬çè§£ï¼ä¸­å±ç°åºéå¡çè½åï¼å¹¶ä¸å·²ç»æåºäºè®¸å¤åºåãç¶èï¼æä»¬è§å¯å°é¿ææ¬çæè½åå°æªå¾å°ååç ç©¶ãå æ­¤ï¼æä»¬å¼å¥äºåå±é¿ææ¬çæåºå (HelloBench)ï¼è¿æ¯ä¸ä¸ªå¨é¢ãçå®çãå¼æ¾å¼çåºåï¼ç¨äºè¯ä¼° LLM å¨çæé¿ææ¬æ¹é¢çæ§è½ãåºäºå¸é²å§åç±»æ³ï¼HelloBench å°é¿ææ¬çæä»»å¡åä¸ºäºä¸ªå­ä»»å¡ï¼å¼æ¾å¼é®ç­ãæè¦ãèå¤©ãææ¬å®æåå¯åå¼ææ¬çæãæ­¤å¤ï¼æä»¬æåºäºåå±é¿ææ¬è¯ä¼° (HelloEval)ï¼è¿æ¯ä¸ç§ä¸äººç±»ä¸è´çè¯ä¼°æ¹æ³ï¼å®æ¾èåå°äºäººç±»è¯ä¼°æéçæ¶é´åç²¾åï¼åæ¶ä¿æä¸äººç±»è¯ä¼°çé«åº¦ç¸å³æ§ãæä»¬å¯¹å¤§çº¦ 30 ä¸ªä¸»æµ LLM è¿è¡äºå¹¿æ³çå®éªï¼å¹¶è§å¯å°å½åç LLM ç¼ºä¹é¿ææ¬çæè½åãå·ä½æ¥è¯´ï¼é¦åï¼æ è®ºæä»¤æ¯å¦åå«æç¡®æéå«çé¿åº¦éå¶ï¼æä»¬è§å¯å°å¤§å¤æ° LLM é½æ æ³çæé¿åº¦è¶è¿ 4000 å­çææ¬ãå¶æ¬¡ï¼æä»¬è§å¯å°è½ç¶ä¸äº LLM å¯ä»¥çææ´é¿çææ¬ï¼ä½å­å¨è®¸å¤é®é¢ï¼ä¾å¦ï¼ä¸¥éçéå¤åè´¨éä¸éï¼ãç¬¬ä¸ï¼ä¸ºäºè¯æ HelloEval çæææ§ï¼æä»¬å° HelloEval ä¸ä¼ ç»ææ ï¼ä¾å¦ï¼ROUGEãBLEU ç­ï¼å LLM-as-a-Judge æ¹æ³è¿è¡äºæ¯è¾ï¼ç»æè¡¨æ HelloEval ä¸äººç±»è¯ä¼°çç¸å³æ§æé«ãæä»¬å¨ https://github.com/Quehry/HelloBench ä¸­åå¸äºæä»¬çä»£ç ã

##### **Cyber Knowledge Completion Using Large Language Models**
2409.16176v1 by Braden K Webb, Sumit Purohit, Rounak Meyur

The integration of the Internet of Things (IoT) into Cyber-Physical Systems
(CPSs) has expanded their cyber-attack surface, introducing new and
sophisticated threats with potential to exploit emerging vulnerabilities.
Assessing the risks of CPSs is increasingly difficult due to incomplete and
outdated cybersecurity knowledge. This highlights the urgent need for
better-informed risk assessments and mitigation strategies. While previous
efforts have relied on rule-based natural language processing (NLP) tools to
map vulnerabilities, weaknesses, and attack patterns, recent advancements in
Large Language Models (LLMs) present a unique opportunity to enhance
cyber-attack knowledge completion through improved reasoning, inference, and
summarization capabilities. We apply embedding models to encapsulate
information on attack patterns and adversarial techniques, generating mappings
between them using vector embeddings. Additionally, we propose a
Retrieval-Augmented Generation (RAG)-based approach that leverages pre-trained
models to create structured mappings between different taxonomies of threat
patterns. Further, we use a small hand-labeled dataset to compare the proposed
RAG-based approach to a baseline standard binary classification model. Thus,
the proposed approach provides a comprehensive framework to address the
challenge of cyber-attack knowledge graph completion.

æè¦ï¼ç©è¯ç¶² (IoT) èç¶²è·¯å¯¦é«ç³»çµ± (CPS) çæ´åæ´å¤§äºå¶ç¶²è·¯æ»æé¢ï¼å¼å¥äºæ°çåè¤éçå¨èï¼å·æå©ç¨æ°èæ¼æ´çæ½åãç±æ¼ç¶²è·¯å®å¨ç¥è­ä¸å®æ´ä¸éæï¼è©ä¼° CPS çé¢¨éªè®å¾è¶ä¾è¶å°é£ãéçªé¡¯äºè¿«åéè¦æ´å®åçé¢¨éªè©ä¼°åç·©è§£ç­ç¥ãéç¶ååçåªåä¾è³´æ¼åºæ¼è¦åçèªç¶èªè¨èç (NLP) å·¥å·ä¾ç¹ªè£½æ¼æ´ãå¼±é»åæ»ææ¨¡å¼ï¼ä½å¤§åèªè¨æ¨¡å (LLM) çææ°é²å±æä¾äºä¸åç¨ç¹çæ©æï¼å¯ä»¥ééæ¹é²çæ¨çãæ¨è«åæè¦è½åä¾å¢å¼·ç¶²è·¯æ»æç¥è­çå®æåº¦ãæåæç¨åµå¥æ¨¡åä¾å°è£æéæ»ææ¨¡å¼åå°ææè¡çè³è¨ï¼ä½¿ç¨åéåµå¥å¨å®åä¹éç¢çå°æéä¿ãæ­¤å¤ï¼æåæåºäºä¸ååºæ¼æª¢ç´¢å¢å¼·çæ (RAG) çæ¹æ³ï¼è©²æ¹æ³å©ç¨é åè¨ç·´çæ¨¡åå¨å¨èæ¨¡å¼çä¸ååé¡æ³ä¹éå»ºç«çµæ§åçå°æéä¿ãæ­¤å¤ï¼æåä½¿ç¨ä¸åå°åçæåæ¨è¨è³æéä¾æ¯è¼ææåºçåºæ¼ RAG çæ¹æ³èåºç·æ¨æºäºååé¡æ¨¡åãå æ­¤ï¼ææåºçæ¹æ³æä¾äºä¸åå¨é¢çæ¶æ§ä¾è§£æ±ºç¶²è·¯æ»æç¥è­åå®æçææ°ã

##### **Merging LoRAs like Playing LEGO: Pushing the Modularity of LoRA to Extremes Through Rank-Wise Clustering**
2409.16167v1 by Ziyu Zhao, Tao Shen, Didi Zhu, Zexi Li, Jing Su, Xuwu Wang, Kun Kuang, Fei Wu

Low-Rank Adaptation (LoRA) has emerged as a popular technique for fine-tuning
large language models (LLMs) to various domains due to its modular design and
widespread availability on platforms like Huggingface. This modularity has
sparked interest in combining multiple LoRAs to enhance LLM capabilities.
However, existing methods for LoRA composition primarily focus on task-specific
adaptations that require additional training, and current model merging
techniques often fail to fully leverage LoRA's modular nature, leading to
parameter interference and performance degradation. In this paper, we
investigate the feasibility of disassembling and reassembling multiple LoRAs at
a finer granularity, analogous to assembling LEGO blocks. We introduce the
concept of Minimal Semantic Units (MSUs), where the parameters corresponding to
each rank in LoRA function as independent units. These MSUs demonstrate
permutation invariance and concatenation-summation equivalence properties,
enabling flexible combinations to create new LoRAs. Building on these insights,
we propose the LoRA-LEGO framework. This framework conducts rank-wise parameter
clustering by grouping MSUs from different LoRAs into $k$ clusters. The
centroid of each cluster serves as a representative MSU, enabling the assembly
of a merged LoRA with an adjusted rank of $k$. Additionally, we apply a dual
reweighting strategy to optimize the scale of the merged LoRA. Experiments
across various benchmarks demonstrate that our method outperforms existing
approaches in LoRA merging.

æè¦ï¼ä½ç§©é©æ (LoRA) å·²æçºä¸ç¨®å»£åæ­¡è¿çæè¡ï¼ç¨æ¼å¾®èª¿å¤§åèªè¨æ¨¡å (LLM) ä»¥é©æåç¨®é åï¼éæ¯å çºå®å·ææ¨¡çµåè¨­è¨ï¼ä¸å¨ Huggingface ç­å¹³å°ä¸å»£æ³å¯ç¨ãéç¨®æ¨¡çµåå¼èµ·äºäººåå°çµåå¤å LoRA ä»¥å¢å¼· LLM è½åçèè¶£ãç¶èï¼ç¾æç LoRA çµææ¹æ³ä¸»è¦éä¸­æ¼éè¦é¡å¤è¨ç·´çç¹å®ä»»åé©æï¼èç¶åçæ¨¡ååä½µæè¡éå¸¸ç¡æ³ååå©ç¨ LoRA çæ¨¡çµåç¹æ§ï¼å°è´åæ¸å¹²æ¾åæè½ä¸éãå¨æ¬æä¸­ï¼æåæ¢è¨äºä»¥æ´ç²¾ç´°çç²åº¦åè§£åéæ°çµè£å¤å LoRA çå¯è¡æ§ï¼é¡ä¼¼æ¼çµè£æ¨é«ç©æ¨ãæåå¼å¥äºæå°èªç¾©å®å (MSU) çæ¦å¿µï¼å¶ä¸­å°ææ¼ LoRA ä¸­æ¯åç§©çåæ¸ä½çºç¨ç«å®åéä½ãéäº MSU å±ç¤ºäºæåä¸è®æ§åä¸²æ¥å ç¸½ç­å¹æ§ï¼åè¨±éæ´»çµåä»¥åµå»ºæ°ç LoRAãåºæ¼éäºè¦è§£ï¼æåæåºäº LoRA-LEGO æ¡æ¶ãæ­¤æ¡æ¶ééå°ä¾èªä¸å LoRA ç MSU åçµå° $k$ åå¢éä¸­ï¼å·è¡ç§©ç´åæ¸åç¾¤ãæ¯åå¢éçè³ªå¿ä½çºä¸åå·ä»£è¡¨æ§ç MSUï¼åè¨±çµè£ä¸åç§©èª¿æ´çº $k$ çåä½µ LoRAãæ­¤å¤ï¼æåæç¨éééæ°å æ¬ç­ç¥ä¾æä½³ååä½µ LoRA çè¦æ¨¡ãå¨åç¨®åºæºæ¸¬è©¦ä¸­çå¯¦é©è¡¨æï¼æåçæ¨¡åå¨ LoRA åä½µä¸­åªæ¼ç¾ææ¹æ³ã

##### **EnIGMA: Enhanced Interactive Generative Model Agent for CTF Challenges**
2409.16165v1 by Talor Abramovich, Meet Udeshi, Minghao Shao, Kilian Lieret, Haoran Xi, Kimberly Milner, Sofija Jancheska, John Yang, Carlos E. Jimenez, Farshad Khorrami, Prashanth Krishnamurthy, Brendan Dolan-Gavitt, Muhammad Shafique, Karthik Narasimhan, Ramesh Karri, Ofir Press

Although language model (LM) agents are demonstrating growing potential in
many domains, their success in cybersecurity has been limited due to simplistic
design and the lack of fundamental features for this domain. We present EnIGMA,
an LM agent for autonomously solving Capture The Flag (CTF) challenges. EnIGMA
introduces new Agent-Computer Interfaces (ACIs) to improve the success rate on
CTF challenges. We establish the novel Interactive Agent Tool concept, which
enables LM agents to run interactive command-line utilities essential for these
challenges. Empirical analysis of EnIGMA on over 350 CTF challenges from three
different benchmarks indicates that providing a robust set of new tools with
demonstration of their usage helps the LM solve complex problems and achieves
state-of-the-art results on the NYU CTF and Intercode-CTF benchmarks. Finally,
we discuss insights on ACI design and agent behavior on cybersecurity tasks
that highlight the need to adapt real-world tools for LM agents.

æè¦ï¼åç®¡èªè¨æ¨¡å (LM) ä»£çå¨è¨±å¤é åå±ç¾åºè¶ä¾è¶å¤§çæ½åï¼ä½ç±æ¼è¨­è¨éæ¼ç°¡åä»¥åç¼ºä¹æ­¤é åçåºæ¬åè½ï¼å®åå¨ç¶²è·¯å®å¨æ¹é¢çæååå°éå¶ãæåæåº EnIGMAï¼ä¸ç¨®ç¨æ¼èªä¸»è§£æ±ºå¥ªæ (CTF) ææ°ç LM ä»£çãEnIGMA å¼é²æ°çä»£çé»è¦ä»é¢ (ACI)ï¼ä»¥æé« CTF ææ°çæåçãæåå»ºç«äºæ°ç©çäºåä»£çå·¥å·æ¦å¿µï¼ä½¿ LM ä»£çè½å¤ å·è¡å°éäºææ°è³ééè¦çäºåå¼å½ä»¤åå¬ç¨ç¨å¼ãEnIGMA å¨ä¾èªä¸åä¸ååºæºçä¸ç¾äºåå¤å CTF ææ°ä¸­çå¯¦è­åæè¡¨æï¼æä¾ä¸çµå¼·å¤§çæ°å·¥å·ä¸¦ç¤ºç¯å¶ç¨æ³ï¼æå©æ¼ LM è§£æ±ºè¤éåé¡ï¼ä¸¦å¨ NYU CTF å Intercode-CTF åºæºä¸åå¾æåé²çææãæå¾ï¼æåè¨è«äº ACI è¨­è¨åç¶²è·¯å®å¨ä»»åä¸­ä»£çè¡çºçè¦è§£ï¼éäºè¦è§£çªé¡¯äºçº LM ä»£çèª¿æ´çå¯¦ä¸çå·¥å·çå¿è¦æ§ã

##### **Controlling Risk of Retrieval-augmented Generation: A Counterfactual Prompting Framework**
2409.16146v1 by Lu Chen, Ruqing Zhang, Jiafeng Guo, Yixing Fan, Xueqi Cheng

Retrieval-augmented generation (RAG) has emerged as a popular solution to
mitigate the hallucination issues of large language models. However, existing
studies on RAG seldom address the issue of predictive uncertainty, i.e., how
likely it is that a RAG model's prediction is incorrect, resulting in
uncontrollable risks in real-world applications. In this work, we emphasize the
importance of risk control, ensuring that RAG models proactively refuse to
answer questions with low confidence. Our research identifies two critical
latent factors affecting RAG's confidence in its predictions: the quality of
the retrieved results and the manner in which these results are utilized. To
guide RAG models in assessing their own confidence based on these two latent
factors, we develop a counterfactual prompting framework that induces the
models to alter these factors and analyzes the effect on their answers. We also
introduce a benchmarking procedure to collect answers with the option to
abstain, facilitating a series of experiments. For evaluation, we introduce
several risk-related metrics and the experimental results demonstrate the
effectiveness of our approach.

æè¦ï¼æª¢ç´¢å¢å¼·çæ (RAG) å·²æçºä¸ç¨®æµè¡çè§£æ±ºæ¹æ¡ï¼ç¨æ¼æ¸è¼å¤§åèªè¨æ¨¡åçå¹»è¦ºåé¡ãç¶èï¼ç¾æç RAG ç ç©¶å¾å°æ¢è¨é æ¸¬ä¸ç¢ºå®æ§çåé¡ï¼å³ RAG æ¨¡åçé æ¸¬ä¸æ­£ç¢ºçå¯è½æ§æå¤å¤§ï¼éæå°è´ç¾å¯¦ä¸çæç¨ä¸­çé¢¨éªç¡æ³æ§å¶ãå¨éé å·¥ä½ä¸­ï¼æåå¼·èª¿é¢¨éªæ§å¶çéè¦æ§ï¼ç¢ºä¿ RAG æ¨¡åä¸»åæçµåç­ä¿¡å¿è¼ä½çåé¡ãæåçç ç©¶ç¢ºå®äºå½±é¿ RAG å°å¶é æ¸¬ä¿¡å¿çå©åééµæ½å¨å ç´ ï¼æª¢ç´¢çµæçåè³ªåå©ç¨éäºçµæçæ¹å¼ãçºäºæå° RAG æ¨¡åæ ¹æéå©åæ½å¨å ç´ è©ä¼°èªå·±çä¿¡å¿ï¼æåéç¼äºä¸ååäºå¯¦æç¤ºæ¡æ¶ï¼èªå°æ¨¡åæ¹è®éäºå ç´ ï¼ä¸¦åæå°å¶ç­æ¡çå½±é¿ãæåéå¼å¥äºä¸ååºæºç¨åºä¾æ¶éå·ææ£æ¬é¸é çç­æ¡ï¼å¾èä¿é²äºä¸ç³»åå¯¦é©ãçºäºè©ä¼°ï¼æåå¼å¥äºå¹¾åèé¢¨éªç¸éçææ¨ï¼å¯¦é©çµæè­æäºæåæ¹æ³çæææ§ã

##### **Seeing Faces in Things: A Model and Dataset for Pareidolia**
2409.16143v1 by Mark Hamilton, Simon Stent, Vasha DuTell, Anne Harrington, Jennifer Corbett, Ruth Rosenholtz, William T. Freeman

The human visual system is well-tuned to detect faces of all shapes and
sizes. While this brings obvious survival advantages, such as a better chance
of spotting unknown predators in the bush, it also leads to spurious face
detections. ``Face pareidolia'' describes the perception of face-like structure
among otherwise random stimuli: seeing faces in coffee stains or clouds in the
sky. In this paper, we study face pareidolia from a computer vision
perspective. We present an image dataset of ``Faces in Things'', consisting of
five thousand web images with human-annotated pareidolic faces. Using this
dataset, we examine the extent to which a state-of-the-art human face detector
exhibits pareidolia, and find a significant behavioral gap between humans and
machines. We find that the evolutionary need for humans to detect animal faces,
as well as human faces, may explain some of this gap. Finally, we propose a
simple statistical model of pareidolia in images. Through studies on human
subjects and our pareidolic face detectors we confirm a key prediction of our
model regarding what image conditions are most likely to induce pareidolia.
Dataset and Website: https://aka.ms/faces-in-things

æè¦ï¼äººé¡çè¦è¦ºç³»çµ±éå¸¸æé·åµæ¸¬åç¨®å½¢çåå¤§å°çèå­ãåç®¡éå¸¶ä¾é¡¯èæè¦ççå­åªå¢ï¼ä¾å¦å¨å¢æä¸­ç¼ç¾æªç¥æ é£èçæ©ææ´å¤§ï¼ä½ä¹å°è´é¯èª¤çèå­åµæ¸¬ã**èé¨é¯è¦**æè¿°å¨å¶ä»é¨æ©åºæ¿ä¸­æç¥å°é¡ä¼¼èå­ççµæ§ï¼å¨åå¡æ¼¬æå¤©ç©ºä¸­çé²æµä¸­çå°èå­ãå¨æ¬æä¸­ï¼æåå¾é»è¦è¦è¦ºçè§åº¦ç ç©¶èé¨é¯è¦ãæåæä¾ä¸å**äºç©ä¸­çèå­**å½±åè³æéï¼å¶ä¸­åå«äºåå¼µæ¨è¨»æé¡ä¼¼äººé¡èå­çç¶²è·¯åçãä½¿ç¨éåè³æéï¼æåæª¢è¦æåé²çäººèåµæ¸¬å¨å±ç¾èé¨é¯è¦çç¨åº¦ï¼ä¸¦ç¼ç¾äººé¡åæ©å¨ä¹éæé¡¯èçè¡çºå·®ç°ãæåç¼ç¾äººé¡å¨æ¼åä¸éè¦åµæ¸¬åç©èå­åäººé¡èå­ï¼éå¯è½æ¯é ææ­¤å·®ç°çé¨ååå ãæå¾ï¼æåæåºä¸åç°¡å®çå½±åé¯è¦çµ±è¨æ¨¡åãééå°äººé¡åè©¦èåæåçé¡ä¼¼èå­åµæ¸¬å¨é²è¡ç ç©¶ï¼æåç¢ºèªäºæåçæ¨¡åéæ¼æå¯è½èªç¼é¯è¦çå½±åæ¢ä»¶çéè¦é æ¸¬ãè³æéåç¶²ç«ï¼https://aka.ms/faces-in-things

##### **HA-FGOVD: Highlighting Fine-grained Attributes via Explicit Linear Composition for Open-Vocabulary Object Detection**
2409.16136v1 by Yuqi Ma, Mengyin Liu, Chao Zhu, Xu-Cheng Yin

Open-vocabulary object detection (OVD) models are considered to be Large
Multi-modal Models (LMM), due to their extensive training data and a large
number of parameters. Mainstream OVD models prioritize object coarse-grained
category rather than focus on their fine-grained attributes, e.g., colors or
materials, thus failed to identify objects specified with certain attributes.
However, OVD models are pretrained on large-scale image-text pairs with rich
attribute words, whose latent feature space can represent the global text
feature as a linear composition of fine-grained attribute tokens without
highlighting them. Therefore, we propose in this paper a universal and explicit
approach for frozen mainstream OVD models that boosts their attribute-level
detection capabilities by highlighting fine-grained attributes in explicit
linear space. Firstly, a LLM is leveraged to highlight attribute words within
the input text as a zero-shot prompted task. Secondly, by strategically
adjusting the token masks, the text encoders of OVD models extract both global
text and attribute-specific features, which are then explicitly composited as
two vectors in linear space to form the new attribute-highlighted feature for
detection tasks, where corresponding scalars are hand-crafted or learned to
reweight both two vectors. Notably, these scalars can be seamlessly transferred
among different OVD models, which proves that such an explicit linear
composition is universal. Empirical evaluation on the FG-OVD dataset
demonstrates that our proposed method uniformly improves fine-grained
attribute-level OVD of various mainstream models and achieves new
state-of-the-art performance.

æè¦ï¼éæ¾è©å½ç©ä»¶åµæ¸¬ (OVD) æ¨¡åè¢«è¦çºå¤§åå¤æ¨¡ææ¨¡å (LMM)ï¼å çºå®åçè¨ç·´è³æå»£æ³ï¼ä¸åæ¸æ¸éé¾å¤§ãä¸»æµ OVD æ¨¡ååªåèéç©ä»¶ç²ç¥çé¡å¥ï¼èéå°æ³¨æ¼å®åçç´°ç·»å±¬æ§ï¼ä¾å¦é¡è²ææè³ªï¼å æ­¤ç¡æ³è­å¥å·æç¹å®å±¬æ§çç©ä»¶ãç¶èï¼OVD æ¨¡åç¶éé åè¨ç·´ï¼ææåå«è±å¯å±¬æ§å­è©çå¤§è¦æ¨¡å½±åæå­éå°ï¼å¶æ½å¨ç¹å¾µç©ºéå¯ä»¥å°æ´é«æå­ç¹å¾µè¡¨ç¤ºçºç´°ç·»å±¬æ§æ¨è¨çç·æ§çµåï¼èä¸æå¼·èª¿å®åãå æ­¤ï¼æåå¨éç¯è«æä¸­æåºä¸åéç¨çæç¢ºæ¹æ³ï¼é©ç¨æ¼åçµçä¸»æµ OVD æ¨¡åï¼ééå¨æç¢ºçç·æ§ç©ºéä¸­å¼·èª¿ç´°ç·»å±¬æ§ï¼æåå®åçå±¬æ§å±¤ç´åµæ¸¬è½åãé¦åï¼å©ç¨ LLM å¨è¼¸å¥æå­ä¸­å¼·èª¿å±¬æ§å­è©ï¼ä½çºé¶æ¬¡æç¤ºä»»åãå¶æ¬¡ï¼ééç­ç¥æ§å°èª¿æ´æ¨è¨é®ç½©ï¼OVD æ¨¡åçæå­ç·¨ç¢¼å¨ææ·åæ´é«æå­åç¹å®å±¬æ§çç¹å¾µï¼ç¶å¾å¨ç·æ§ç©ºéä¸­æç¢ºå°å°å®åçµåæå©ååéï¼ä»¥å½¢ææ°çå±¬æ§å¼·èª¿ç¹å¾µï¼ç¨æ¼åµæ¸¬ä»»åï¼å¶ä¸­å°æçç´éæ¯æå·¥è£½ä½æå­¸ç¿èå¾ï¼ç¨æ¼éæ°å æ¬éå©ååéãå¼å¾æ³¨æçæ¯ï¼éäºç´éå¯ä»¥å¨ä¸åç OVD æ¨¡åä¹éç¡ç¸«å³è¼¸ï¼éè­æäºéç¨®æç¢ºçç·æ§çµåæ¯éç¨çãå¨ FG-OVD è³æéä¸çå¯¦è­è©ä¼°é¡¯ç¤ºï¼æåæåºçæ¹æ³ä¸è´å°æ¹åäºåç¨®ä¸»æµæ¨¡åçç´°ç·»å±¬æ§å±¤ç´ OVDï¼ä¸¦éå°äºæ°çæåé²æè½ã

##### **Implicit assessment of language learning during practice as accurate as explicit testing**
2409.16133v1 by Jue Hou, Anisia Katinskaia, Anh-Duc Vu, Roman Yangarber

Assessment of proficiency of the learner is an essential part of Intelligent
Tutoring Systems (ITS). We use Item Response Theory (IRT) in computer-aided
language learning for assessment of student ability in two contexts: in test
sessions, and in exercises during practice sessions. Exhaustive testing across
a wide range of skills can provide a detailed picture of proficiency, but may
be undesirable for a number of reasons. Therefore, we first aim to replace
exhaustive tests with efficient but accurate adaptive tests. We use learner
data collected from exhaustive tests under imperfect conditions, to train an
IRT model to guide adaptive tests. Simulations and experiments with real
learner data confirm that this approach is efficient and accurate. Second, we
explore whether we can accurately estimate learner ability directly from the
context of practice with exercises, without testing. We transform learner data
collected from exercise sessions into a form that can be used for IRT modeling.
This is done by linking the exercises to {\em linguistic constructs}; the
constructs are then treated as "items" within IRT. We present results from
large-scale studies with thousands of learners. Using teacher assessments of
student ability as "ground truth," we compare the estimates obtained from tests
vs. those from exercises. The experiments confirm that the IRT models can
produce accurate ability estimation based on exercises.

æè¦ï¼è©éå­¸ççè½åæ¯æºæ§åæå­¸ç³»çµ±ï¼ITSï¼çå¿è¦é¨åãæåå¨é»è¦è¼å©èªè¨å­¸ç¿ä¸­ä½¿ç¨é ç®åæçè«ï¼IRTï¼ï¼å¨å©ç¨®æå¢ä¸­è©éå­¸ççè½åï¼å¨æ¸¬é©æï¼ä»¥åå¨ç·´ç¿æç¨ä¸­çç·´ç¿ãå¨åç¨®æè½ä¸­é²è¡è©³ç¡çæ¸¬è©¦ï¼å¯ä»¥æä¾è½åçè©³ç´°ååï¼ä½å¯è½å çºè¨±å¤åå èä¸å¯åãå æ­¤ï¼æåé¦åç®æ¨æ¯ä½¿ç¨ææä¸ç²¾ç¢ºçé©ææ§æ¸¬é©ï¼ä¾åä»£è©³ç¡çæ¸¬é©ãæåä½¿ç¨å¨ä¸å®ç¾æ¢ä»¶ä¸å¾è©³ç¡æ¸¬é©ä¸­æ¶éå°çå­¸ç¿èè³æï¼ä¾è¨ç·´ä¸å IRT æ¨¡åï¼ä»¥å¼å°é©ææ§æ¸¬é©ãæ¨¡æ¬åä½¿ç¨çå¯¦å­¸ç¿èè³æçå¯¦é©ï¼è­å¯¦æ­¤æ¹æ³ææä¸ç²¾ç¢ºãå¶æ¬¡ï¼æåæ¢ç´¢æ¯å¦å¯ä»¥å¨æ²ææ¸¬é©çææ³ä¸ï¼ç´æ¥å¾ç·´ç¿ç·´ç¿çèçµ¡ä¸­ï¼ç²¾ç¢ºå°ä¼°è¨å­¸ç¿èçè½åãæåå°å¾ç·´ç¿æç¨ä¸­æ¶éçå­¸ç¿èè³æï¼è½ææå¯ç¨æ¼ IRT å»ºæ¨¡çå½¢å¼ãéæ¯ééå°ç·´ç¿é£çµå°ãèªè¨å»ºæ§ãä¾å®æçï¼ç¶å¾å°å»ºæ§è¦çº IRT ä¸­çãé ç®ããæåæä¾ä¾èªæ¸ååå­¸ç¿èçå¤§è¦æ¨¡ç ç©¶çµæãä½¿ç¨æå¸«å°å­¸çè½åçè©éä½çºãåºæ¬äºå¯¦ãï¼æåæ¯è¼å¾æ¸¬é©ä¸­ç²å¾çä¼°è¨å¼èå¾ç·´ç¿ä¸­ç²å¾çä¼°è¨å¼ãå¯¦é©è­å¯¦ï¼IRT æ¨¡åå¯ä»¥æ ¹æç·´ç¿ç¢çç²¾ç¢ºçè½åä¼°è¨ã

##### **Analyzing Probabilistic Methods for Evaluating Agent Capabilities**
2409.16125v1 by Axel HÃ¸jmark, Govind Pimpale, Arjun Panickssery, Marius Hobbhahn, JÃ©rÃ©my Scheurer

To mitigate risks from AI systems, we need to assess their capabilities
accurately. This is especially difficult in cases where capabilities are only
rarely displayed. Phuong et al. propose two methods that aim to obtain better
estimates of the probability of an AI agent successfully completing a given
task. The milestone method decomposes tasks into subtasks, aiming to improve
overall success rate estimation, while the expert best-of-N method leverages
human guidance as a proxy for the model's independent performance.
  Our analysis of these methods as Monte Carlo estimators reveals that while
both effectively reduce variance compared to naive Monte Carlo sampling, they
also introduce bias. Experimental results demonstrate that the milestone method
underestimates true solve rates for many real-world tasks due to its
constraining assumptions. The expert best-of-N method exhibits even more severe
underestimation across all tasks, attributed to an inherently flawed
re-weighting factor. To enhance the accuracy of capability estimates of AI
agents on difficult tasks, we suggest future work should leverage the rich
literature on Monte Carlo Estimators.

æè¦ï¼çºäºéä½ AI ç³»çµ±çé¢¨éªï¼æåéè¦æºç¢ºè©ä¼°å¶åè½ãå¨åè½åå¶ç¾é¡¯ç¤ºçææ³ä¸ï¼éå°¤å¶å°é£ãPhuong ç­äººæåºäºå©ç¨®æ¹æ³ï¼æ¨å¨ç²å¾ AI ä»£çæåå®æç¹å®ä»»åçæ©ççæ´å¥½ä¼°è¨ãéç¨ç¢æ¹æ³å°ä»»ååè§£çºå­ä»»åï¼æ¨å¨æé«æ´é«æåçä¼°è¨ï¼èå°å®¶æä½³ N æ¹æ³åå©ç¨äººé¡æå°ä½çºæ¨¡åç¨ç«æ§è½çä»£çãæåå°éäºæ¹æ³ä½çºèå°å¡ç¾ä¼°è¨å¨çåæè¡¨æï¼éç¶å©èé½ææå°éä½äºèæ¨¸ç´ èå°å¡ç¾æ½æ¨£ç¸æ¯çè®ç°ï¼ä½å®åä¹å¼å¥äºåå·®ãå¯¦é©çµæè¡¨æï¼ç±æ¼å¶ç´ææ§åè¨­ï¼éç¨ç¢æ¹æ³ä½ä¼°äºè¨±å¤å¯¦éä»»åççå¯¦æ±è§£çãå°å®¶æä½³ N æ¹æ³å¨ææä»»åä¸­è¡¨ç¾åºæ´å´éçä½ä¼°ï¼éæ­¸å æ¼åºæçæç¼ºé·çéæ°å æ¬å å­ãçºäºæé« AI ä»£çå¨å°é£ä»»åä¸­çè½åä¼°è¨çæºç¢ºæ§ï¼æåå»ºè­°æªä¾çç ç©¶æå©ç¨èå°å¡ç¾ä¼°è¨å¨çè±å¯æç»ã

##### **MOSS: Enabling Code-Driven Evolution and Context Management for AI Agents**
2409.16120v1 by Ming Zhu, Yi Zhou

Developing AI agents powered by large language models (LLMs) faces
significant challenges in achieving true Turing completeness and adaptive,
code-driven evolution. Current approaches often generate code independently of
its runtime context, relying heavily on the LLM's memory, which results in
inefficiencies and limits adaptability. Manual protocol development in sandbox
environments further constrains the agent's autonomous adaptability. Crucially,
achieving consistency in code and context across multi-turn interactions and
ensuring isolation of local variables within each interaction remains an
unsolved problem.
  We introduce MOSS (llM-oriented Operating System Simulation), a novel
framework that addresses these challenges by integrating code generation with a
dynamic context management system. MOSS ensures consistency and adaptability by
using a mechanism that maintains the Python context across interactions,
including isolation of local variables and preservation of runtime integrity.
At its core, the framework employs an Inversion of Control (IoC) container in
conjunction with decorators to enforce the least knowledge principle, allowing
agents to focus on abstract interfaces rather than concrete implementations.
This facilitates seamless integration of new tools and libraries, enables
runtime instance replacement, and reduces prompt complexity, providing a "what
you see is what you get" environment for the agent.
  Through a series of case studies, we show how this framework can enhance the
efficiency and capabilities of agent development and highlight its advantages
in moving towards Turing-complete agents capable of evolving through code.

æè¦ï¼éç¼ç±å¤§åèªè¨æ¨¡åï¼LLMï¼é©åçäººå·¥æºæ§ä»£çç¨å¼å¨å¯¦ç¾çæ­£çåéå®åæ§ä»¥åé©ææ§ãä»¥ç¨å¼ç¢¼çºå°åçæ¼åæ¹é¢é¢è¨éå¤§ææ°ãç®åçåæ³éå¸¸ç¨ç«æ¼å¶å·è¡æéä¸ä¸æç¢çç¨å¼ç¢¼ï¼å´éä¾è³´ LLM çè¨æ¶é«ï¼éæå°è´æçä½ä¸ä¸¦éå¶é©ææ§ãæ²çç°å¢ä¸­çæååå®éç¼é²ä¸æ­¥éå¶äºä»£çç¨å¼çèªä¸»é©ææ§ãè³ééè¦çæ¯ï¼å¨å¤è¼ªäºåä¸­å¯¦ç¾ç¨å¼ç¢¼åä¸ä¸æçç¸å®¹æ§ï¼ä¸¦ç¢ºä¿æ¯åäºåä¸­å±é¨è®æ¸çéé¢ä»ç¶æ¯ä¸åæªè§£æ±ºçåé¡ã
æåå¼å¥äº MOSSï¼é¢å llM çä½æ¥­ç³»çµ±æ¨¡æ¬ï¼ï¼éæ¯ä¸åæ°ç©çæ¶æ§ï¼å®ééå°ç¨å¼ç¢¼ç¢çèåæä¸ä¸æç®¡çç³»çµ±æ´åä¾è§£æ±ºéäºææ°ãMOSS ééä½¿ç¨ä¸ç¨®å¨äºåä¸­ç¶­è­· Python ä¸ä¸æçæ©å¶ä¾ç¢ºä¿ç¸å®¹æ§åé©ææ§ï¼åæ¬éé¢å±é¨è®æ¸åä¿çå·è¡æéå®æ´æ§ãå¨æ ¸å¿é¨åï¼è©²æ¶æ§æ¡ç¨æ§å¶åè½ (IoC) å®¹å¨ï¼ä¸¦çµåè£é£¾å¨ä¾å¼·å¶å·è¡æå°ç¥è­ååï¼è®ä»£çç¨å¼è½å¤ å°æ³¨æ¼æ½è±¡ä»é¢ï¼èä¸æ¯å·é«å¯¦ä½ãéä¿é²äºæ°å·¥å·åå½å¼åº«çç¡ç¸«æ´åï¼æ¯æ´å·è¡æéå¯¦ä¾æ¿æï¼ä¸¦éä½æç¤ºè¤éæ§ï¼çºä»£çç¨å¼æä¾ãæè¦å³æå¾ãçç°å¢ã
ééä¸ç³»åæ¡ä¾ç ç©¶ï¼æåå±ç¤ºäºéåæ¶æ§å¦ä½å¢å¼·ä»£çç¨å¼éç¼çæçåè½åï¼ä¸¦å¼·èª¿å¶å¨æåè½å¤ ééç¨å¼ç¢¼æ¼åçåéå®åä»£çç¨å¼éé²çåªå¢ã

##### **Scenario of Use Scheme: Threat Model Specification for Speaker Privacy Protection in the Medical Domain**
2409.16106v1 by Mehtab Ur Rahman, Martha Larson, Louis ten Bosch, Cristian Tejedor-GarcÃ­a

Speech recordings are being more frequently used to detect and monitor
disease, leading to privacy concerns. Beyond cryptography, protection of speech
can be addressed by approaches, such as perturbation, disentanglement, and
re-synthesis, that eliminate sensitive information of the speaker, leaving the
information necessary for medical analysis purposes. In order for such privacy
protective approaches to be developed, clear and systematic specifications of
assumptions concerning medical settings and the needs of medical professionals
are necessary. In this paper, we propose a Scenario of Use Scheme that
incorporates an Attacker Model, which characterizes the adversary against whom
the speaker's privacy must be defended, and a Protector Model, which specifies
the defense. We discuss the connection of the scheme with previous work on
speech privacy. Finally, we present a concrete example of a specified Scenario
of Use and a set of experiments about protecting speaker data against gender
inference attacks while maintaining utility for Parkinson's detection.

æè¦ï¼èªé³éé³æ­£è¶ä¾è¶å¸¸è¢«ç¨æ¼åµæ¸¬åç£æ§ç¾çï¼éå¼ç¼äºé±ç§åé¡ãé¤äºå¯ç¢¼å­¸ä¹å¤ï¼èªé³ä¿è­·éå¯ä»¥ééæ¾åãè§£ç³¾çºåéæ°åæç­æ¹æ³ä¾èçï¼éäºæ¹æ³æ¶é¤äºèªªè©±èçææè³è¨ï¼åªçä¸é«çåæç®çæéçè³è¨ãçºäºéç¼åºæ­¤é¡é±ç§ä¿è­·æ¹æ³ï¼å¿é æç¢ºä¸ç³»çµ±æ§å°èªªææéé«çç°å¢åé«çå°æ¥­äººå¡éæ±çåè¨­ãå¨æ¬æä¸­ï¼æåæåºäºä¸åä½¿ç¨æå¢æ¹æ¡ï¼å¶ä¸­åå«ä¸åæ»æèæ¨¡åï¼å®æè¿°äºèªªè©±èé±ç§å¿é é²ç¯çå°æï¼ä»¥åä¸åä¿è­·èæ¨¡åï¼å®æå®äºé²ç¦¦æªæ½ãæåè¨è«äºè©²æ¹æ¡èååéæ¼èªé³é±ç§çç ç©¶ä¹éçéè¯ãæå¾ï¼æåæä¾äºä¸åå·é«çæå®ä½¿ç¨æå¢ç¯ä¾ï¼ä»¥åä¸çµéæ¼å¨ç¶­æå¸éæ£®æ°çåµæ¸¬æç¨çåæä¿è­·èªªè©±èè³æåæ¼æ§å¥æ¨è«æ»æçå¯¦é©ã

##### **Neuromorphic Drone Detection: an Event-RGB Multimodal Approach**
2409.16099v1 by Gabriele Magrini, Federico Becattini, Pietro Pala, Alberto Del Bimbo, Antonio Porta

In recent years, drone detection has quickly become a subject of extreme
interest: the potential for fast-moving objects of contained dimensions to be
used for malicious intents or even terrorist attacks has posed attention to the
necessity for precise and resilient systems for detecting and identifying such
elements. While extensive literature and works exist on object detection based
on RGB data, it is also critical to recognize the limits of such modality when
applied to UAVs detection. Detecting drones indeed poses several challenges
such as fast-moving objects and scenes with a high dynamic range or, even
worse, scarce illumination levels. Neuromorphic cameras, on the other hand, can
retain precise and rich spatio-temporal information in situations that are
challenging for RGB cameras. They are resilient to both high-speed moving
objects and scarce illumination settings, while prone to suffer a rapid loss of
information when the objects in the scene are static. In this context, we
present a novel model for integrating both domains together, leveraging
multimodal data to take advantage of the best of both worlds. To this end, we
also release NeRDD (Neuromorphic-RGB Drone Detection), a novel
spatio-temporally synchronized Event-RGB Drone detection dataset of more than
3.5 hours of multimodal annotated recordings.

æè¦ï¼è¿å¹´æ¥ï¼æ äººæºæ£æµå·²è¿éæä¸ºæåº¦å³æ³¨çä¸»é¢ï¼å°ºå¯¸åéçå¿«éç§»å¨ç©ä½å¯è½è¢«ç¨äºæ¶æç®ççè³ææè¢­å»ï¼è¿å¼èµ·äºäººä»¬å¯¹ç¨äºæ£æµåè¯å«æ­¤ç±»åç´ çç²¾ç¡®ä¸æå¼¹æ§çç³»ç»çå¿è¦æ§çå³æ³¨ãè½ç¶åºäº RGB æ°æ®çå¯¹è±¡æ£æµå­å¨å¤§éæç®åèä½ï¼ä½å¨å°å¶åºç¨äºæ äººæºæ£æµæ¶ï¼è®¤è¯å°è¿ç§æ¹å¼çå±éæ§ä¹è³å³éè¦ãæ£æµæ äººæºç¡®å®ä¼å¸¦æ¥ä¸äºææï¼ä¾å¦å¿«éç§»å¨çç©ä½åå·æé«å¨æèå´çåºæ¯ï¼æèæ´ç³çæ¯ï¼åç§æ°´å¹³ä¸è¶³ãå¦ä¸æ¹é¢ï¼ç¥ç»å½¢æç¸æºå¯ä»¥å¨å¯¹äº RGB ç¸æºèè¨å·ææææ§çæåµä¸ä¿çç²¾ç¡®ä¸ä¸°å¯çæ¶ç©ºä¿¡æ¯ãå®ä»¬æ¢è½æµå¾¡é«éç§»å¨çç©ä½ï¼åè½æµå¾¡åç§ä¸è¶³çæåµï¼ä½å½åºæ¯ä¸­çç©ä½éæ­¢æ¶ï¼å®ä»¬å®¹æè¿éä¸¢å¤±ä¿¡æ¯ãå¨æ­¤èæ¯ä¸ï¼æä»¬æåºäºä¸ç§å°è¿ä¸¤ä¸ªåéæå¨ä¸èµ·çæ°é¢æ¨¡åï¼å©ç¨å¤æ¨¡ææ°æ®æ¥ååå©ç¨ä¸¤å¨å¶ç¾çä¼å¿ãä¸ºæ­¤ï¼æä»¬è¿åå¸äº NeRDDï¼ç¥ç»å½¢æ RGB æ äººæºæ£æµï¼ï¼è¿æ¯ä¸ä¸ªæ°é¢çæ¶ç©ºåæ­¥äºä»¶ RGB æ äººæºæ£æµæ°æ®éï¼å¶ä¸­åå«è¶è¿ 3.5 å°æ¶çå¤æ¨¡ææ æ³¨è®°å½ã

##### **Exploring Hint Generation Approaches in Open-Domain Question Answering**
2409.16096v1 by Jamshid Mozafari, Abdelrahman Abdallah, Bhawna Piryani, Adam Jatowt

Automatic Question Answering (QA) systems rely on contextual information to
provide accurate answers. Commonly, contexts are prepared through either
retrieval-based or generation-based methods. The former involves retrieving
relevant documents from a corpus like Wikipedia, whereas the latter uses
generative models such as Large Language Models (LLMs) to generate the context.
In this paper, we introduce a novel context preparation approach called HINTQA,
which employs Automatic Hint Generation (HG) techniques. Unlike traditional
methods, HINTQA prompts LLMs to produce hints about potential answers for the
question rather than generating relevant context. We evaluate our approach
across three QA datasets including TriviaQA, NaturalQuestions, and Web
Questions, examining how the number and order of hints impact performance. Our
findings show that the HINTQA surpasses both retrieval-based and
generation-based approaches. We demonstrate that hints enhance the accuracy of
answers more than retrieved and generated contexts.

æè¦ï¼èªååç­ (QA) ç³»çµ±ä¾è³´ä¸ä¸æè³è¨æä¾ç²¾ç¢ºç­æ¡ãä¸è¬ä¾èªªï¼ä¸ä¸ææ¯ééæ·åå¼æçæå¼æ¹æ³æºåçãåèæ¶åå¾ç¶­åºç¾ç§ç­èªæåº«ä¸­æ·åç¸éæä»¶ï¼èå¾èä½¿ç¨çæå¼æ¨¡åï¼ä¾å¦å¤§åèªè¨æ¨¡å (LLM)ï¼ä¾ç¢çä¸ä¸æãå¨æ¬æä¸­ï¼æåä»ç´¹ä¸ç¨®ç¨±çº HINTQA çæ°ç©ä¸ä¸ææºåæ¹æ³ï¼å®æ¡ç¨èªåæç¤ºçæ (HG) æè¡ãèå³çµ±æ¹æ³ä¸åï¼HINTQA ææç¤º LLM ç¢çæéåé¡æ½å¨ç­æ¡çæç¤ºï¼èä¸æ¯ç¢çç¸éçä¸ä¸æãæåå¨ä¸å QA è³æéï¼åæ¬ TriviaQAãNaturalQuestions å Web Questionsï¼ä¸­è©ä¼°æåçåæ³ï¼æ¢è¨æç¤ºçæ¸éåé åºå¦ä½å½±é¿æè½ãæåçç ç©¶çµæé¡¯ç¤ºï¼HINTQA è¶è¶äºåºæ¼æ·åååºæ¼çæçå©ç¨®æ¹æ³ãæåè­ææç¤ºæ¯æ·ååçæçä¸ä¸ææ´è½å¢å¼·ç­æ¡çæºç¢ºæ§ã

##### **From Pixels to Words: Leveraging Explainability in Face Recognition through Interactive Natural Language Processing**
2409.16089v1 by Ivan DeAndres-Tame, Muhammad Faisal, Ruben Tolosana, Rouqaiah Al-Refai, Ruben Vera-Rodriguez, Philipp TerhÃ¶rst

Face Recognition (FR) has advanced significantly with the development of deep
learning, achieving high accuracy in several applications. However, the lack of
interpretability of these systems raises concerns about their accountability,
fairness, and reliability. In the present study, we propose an interactive
framework to enhance the explainability of FR models by combining
model-agnostic Explainable Artificial Intelligence (XAI) and Natural Language
Processing (NLP) techniques. The proposed framework is able to accurately
answer various questions of the user through an interactive chatbot. In
particular, the explanations generated by our proposed method are in the form
of natural language text and visual representations, which for example can
describe how different facial regions contribute to the similarity measure
between two faces. This is achieved through the automatic analysis of the
output's saliency heatmaps of the face images and a BERT question-answering
model, providing users with an interface that facilitates a comprehensive
understanding of the FR decisions. The proposed approach is interactive,
allowing the users to ask questions to get more precise information based on
the user's background knowledge. More importantly, in contrast to previous
studies, our solution does not decrease the face recognition performance. We
demonstrate the effectiveness of the method through different experiments,
highlighting its potential to make FR systems more interpretable and
user-friendly, especially in sensitive applications where decision-making
transparency is crucial.

æè¦ï¼äººèè¾¨è­ (FR) å·²é¨èæ·±åº¦å­¸ç¿çç¼å±èé²æ­¥è¨±å¤ï¼å¨å¤é æç¨ä¸­éå°å¾é«çæºç¢ºåº¦ãç¶èï¼éäºç³»çµ±ç¼ºä¹å¯è§£éæ§ï¼å¼ç¼äºå°å¶è²¬ä»»ãå¬å¹³æ§åå¯é æ§ççæ®ãå¨æ¬ç ç©¶ä¸­ï¼æåæåºä¸åäºåå¼æ¶æ§ï¼ééçµåèæ¨¡åç¡éçå¯è§£éäººå·¥æºæ§ (XAI) åèªç¶èªè¨èç (NLP) æè¡ï¼ä¾å¢å¼· FR æ¨¡åçå¯è§£éæ§ãææåºçæ¶æ§è½å¤ ééäºåå¼èå¤©æ©å¨äººï¼ç²¾ç¢ºåç­ä½¿ç¨èçåç¨®åé¡ãç¹å¥æ¯ï¼æåææåºçæ¹æ³æç¢ççè§£éï¼æ¯ä»¥èªç¶èªè¨æå­åè¦è¦ºè¡¨ç¤ºçå½¢å¼åç¾ï¼ä¾å¦å¯ä»¥æè¿°ä¸åèé¨ååå¦ä½å½±é¿å©å¼µèä¹éçç¸ä¼¼åº¦éåº¦ãéæ¯ééèªååæèé¨å½±åçé¡¯èç±é»åå BERT åç­æ¨¡åä¾éæï¼çºä½¿ç¨èæä¾ä¸åä»é¢ï¼ä»¥å©å¨é¢çè§£ FR æ±ºç­ãææåºçæ¹æ³å·æäºåæ§ï¼åè¨±ä½¿ç¨èæåï¼ä»¥æ ¹æä½¿ç¨èçèæ¯ç¥è­åå¾æ´ç²¾ç¢ºçè³è¨ãæ´éè¦çæ¯ï¼èååçç ç©¶ç¸æ¯ï¼æåçè§£æ±ºæ¹æ¡ä¸¦æªéä½äººèè¾¨è­æè½ãæåééä¸åçå¯¦é©ï¼è­ææ­¤æ¹æ³çæææ§ï¼å¼·èª¿å¶è® FR ç³»çµ±æ´å·å¯è§£éæ§åä½¿ç¨èååæ§çæ½åï¼ç¹å¥æ¯å¨æ±ºç­éæåº¦è³ééè¦çæææç¨ä¸­ã

##### **Online Multi-level Contrastive Representation Distillation for Cross-Subject fNIRS Emotion Recognition**
2409.16081v1 by Zhili Lai, Chunmei Qing, Junpeng Tan, Wanxiang Luo, Xiangmin Xu

Utilizing functional near-infrared spectroscopy (fNIRS) signals for emotion
recognition is a significant advancement in understanding human emotions.
However, due to the lack of artificial intelligence data and algorithms in this
field, current research faces the following challenges: 1) The portable
wearable devices have higher requirements for lightweight models; 2) The
objective differences of physiology and psychology among different subjects
aggravate the difficulty of emotion recognition. To address these challenges,
we propose a novel cross-subject fNIRS emotion recognition method, called the
Online Multi-level Contrastive Representation Distillation framework (OMCRD).
Specifically, OMCRD is a framework designed for mutual learning among multiple
lightweight student networks. It utilizes multi-level fNIRS feature extractor
for each sub-network and conducts multi-view sentimental mining using
physiological signals. The proposed Inter-Subject Interaction Contrastive
Representation (IS-ICR) facilitates knowledge transfer for interactions between
student models, enhancing cross-subject emotion recognition performance. The
optimal student network can be selected and deployed on a wearable device. Some
experimental results demonstrate that OMCRD achieves state-of-the-art results
in emotional perception and affective imagery tasks.

æè¦ï¼å©ç¨åè½æ§è¿ç´å¤ç·åè­ (fNIRS) ä¿¡èé²è¡æç·è¾¨è­ï¼æ¯çè§£äººé¡æç·çä¸å¤§é²å±ãç¶èï¼ç±æ¼è©²é åç¼ºä¹äººå·¥æºæ§æ¸æåæ¼ç®æ³ï¼ç®åçç ç©¶é¢è¨ä»¥ä¸ææ°ï¼1) å¯æå¼ç©¿æ´å¼è£ç½®å°è¼éåæ¨¡åæè¼é«è¦æ±ï¼2) ä¸ååè©¦èä¹éççåå¿ççå®¢è§å·®ç°å åäºæç·è¾¨è­çé£åº¦ãçºäºæå°éäºææ°ï¼æåæåºäºä¸ç¨®æ°ç©çè·¨åè©¦è fNIRS æç·è¾¨è­æ¹æ³ï¼ç¨±çºç·ä¸å¤å±¤å°æ¯è¡¨å¾µè¸é¤¾æ¡æ¶ (OMCRD)ãå·é«ä¾èªªï¼OMCRD æ¯çºå¤åè¼éç´å­¸çç¶²è·¯ä¹éçç¸äºå­¸ç¿èè¨­è¨çæ¡æ¶ãå®çºæ¯åå­ç¶²è·¯å©ç¨å¤å±¤ç´ fNIRS ç¹å¾µèåå¨ï¼ä¸¦ä½¿ç¨ççä¿¡èé²è¡å¤è¦è§æç·ææãææåºçè·¨åè©¦èäºåå°æ¯è¡¨å¾µ (IS-ICR) ä¿é²äºå­¸çæ¨¡åä¹éäºåçç¥è­å³éï¼å¢å¼·äºè·¨åè©¦èçæç·è¾¨è­æè½ãå¯ä»¥é¸ææä½³çå­¸çç¶²è·¯ä¸¦é¨ç½²å¨å¯ç©¿æ´å¼è£ç½®ä¸ãä¸äºå¯¦é©çµæè¡¨æï¼OMCRD å¨æç·æç¥åæææè±¡ä»»åä¸­åå¾äºæåé²çææã

##### **Leveraging Mixture of Experts for Improved Speech Deepfake Detection**
2409.16077v1 by Viola Negroni, Davide Salvi, Alessandro Ilic Mezza, Paolo Bestagini, Stefano Tubaro

Speech deepfakes pose a significant threat to personal security and content
authenticity. Several detectors have been proposed in the literature, and one
of the primary challenges these systems have to face is the generalization over
unseen data to identify fake signals across a wide range of datasets. In this
paper, we introduce a novel approach for enhancing speech deepfake detection
performance using a Mixture of Experts architecture. The Mixture of Experts
framework is well-suited for the speech deepfake detection task due to its
ability to specialize in different input types and handle data variability
efficiently. This approach offers superior generalization and adaptability to
unseen data compared to traditional single models or ensemble methods.
Additionally, its modular structure supports scalable updates, making it more
flexible in managing the evolving complexity of deepfake techniques while
maintaining high detection accuracy. We propose an efficient, lightweight
gating mechanism to dynamically assign expert weights for each input,
optimizing detection performance. Experimental results across multiple datasets
demonstrate the effectiveness and potential of our proposed approach.

æè¦ï¼èªé³æ·±åº¦é åå°åäººå®å¨åå§å®¹çå¯¦æ§æ§æéå¤§å¨èãæç»ä¸­å·²æåºå¤ç¨®æª¢æ¸¬å¨ï¼èéäºç³»çµ±é¢è¨çä¸»è¦ææ°ä¹ä¸æ¯å¨åç¨®è³æéä¸è­å¥åè¨èï¼ä»¥æ¦åæªè¦éçè³æãå¨æ¬æä¸­ï¼æåä»ç´¹äºä¸ç¨®æ°æ¹æ³ï¼ä½¿ç¨å°å®¶æ··åæ¶æ§ä¾å¢å¼·èªé³æ·±åº¦é åæª¢æ¸¬æè½ãå°å®¶æ··åæ¶æ§éå¸¸é©åèªé³æ·±åº¦é åæª¢æ¸¬ä»»åï¼å çºå®è½å¤ éå°ä¸åçè¼¸å¥é¡åé²è¡å°éèçï¼ä¸¦ææèçè³æè®ç°æ§ãèå³çµ±å®ä¸æ¨¡åæéææ¹æ³ç¸æ¯ï¼éç¨®æ¹æ³æä¾äºå°æªè¦éè³æçåè¶æ¦ååé©ææ§ãæ­¤å¤ï¼å¶æ¨¡çµåçµæ§æ¯æ´å¯æ´åæ´æ°ï¼ä½¿å¶å¨ç®¡çæ·±åº¦é åæè¡ä¸æ·æ¼è®çè¤éæ§çåæï¼æ´éæ´»å°ç¶­æé«æª¢æ¸¬æºç¢ºåº¦ãæåæåºäºä¸ç¨®ææä¸è¼éçéæ§æ©å¶ï¼ç¨æ¼åæåéæ¯åè¼¸å¥çå°å®¶æ¬éï¼ä»¥æä½³åæª¢æ¸¬æè½ãè·¨å¤åè³æéçå¯¦é©çµæè­æäºæåæåºçæ¹æ³çæææ§åæ½åã

##### **Towards Robust Object Detection: Identifying and Removing Backdoors via Module Inconsistency Analysis**
2409.16057v1 by Xianda Zhang, Siyuan Liang

Object detection models, widely used in security-critical applications, are
vulnerable to backdoor attacks that cause targeted misclassifications when
triggered by specific patterns. Existing backdoor defense techniques, primarily
designed for simpler models like image classifiers, often fail to effectively
detect and remove backdoors in object detectors. We propose a backdoor defense
framework tailored to object detection models, based on the observation that
backdoor attacks cause significant inconsistencies between local modules'
behaviors, such as the Region Proposal Network (RPN) and classification head.
By quantifying and analyzing these inconsistencies, we develop an algorithm to
detect backdoors. We find that the inconsistent module is usually the main
source of backdoor behavior, leading to a removal method that localizes the
affected module, resets its parameters, and fine-tunes the model on a small
clean dataset. Extensive experiments with state-of-the-art two-stage object
detectors show our method achieves a 90% improvement in backdoor removal rate
over fine-tuning baselines, while limiting clean data accuracy loss to less
than 4%. To the best of our knowledge, this work presents the first approach
that addresses both the detection and removal of backdoors in two-stage object
detection models, advancing the field of securing these complex systems against
backdoor attacks.

æè¦ï¼ç©ä»¶åµæ¸¬æ¨¡åå»£æ³ç¨æ¼å®å¨ééµæç¨ä¸­ï¼å®¹æåå°å¾éæ»æï¼ç¶è§¸ç¼ç¹å®æ¨¡å¼æï¼æå°è´ç®æ¨é¯èª¤åé¡ãç¾æçå¾éé²ç¦¦æè¡ï¼ä¸»è¦æ¯éå°å½±ååé¡å¨ç­è¼ç°¡å®çæ¨¡åè¨­è¨ï¼éå¸¸ç¡æ³ææåµæ¸¬ä¸¦ç§»é¤ç©ä»¶åµæ¸¬å¨ä¸­çå¾éãæåæåºä¸åéå°ç©ä»¶åµæ¸¬æ¨¡åéèº«æé çå¾éé²ç¦¦æ¶æ§ï¼æ ¹æå¾éæ»ææå°è´ååå»ºè­°ç¶²è·¯ (RPN) ååé¡é ­ç­å±é¨æ¨¡çµè¡çºåºç¾é¡¯èä¸ä¸è´çè§å¯çµæãéééåååæéäºä¸ä¸è´æ§ï¼æåéç¼äºä¸ç¨®æ¼ç®æ³ä¾åµæ¸¬å¾éãæåç¼ç¾ä¸ä¸è´çæ¨¡çµéå¸¸æ¯å¾éè¡çºçä¸»è¦ä¾æºï¼å°è´ä¸ç¨®ç§»é¤æ¹æ³ï¼è©²æ¹æ³ææ¾åºåå½±é¿çæ¨¡çµï¼éè¨­å¶åæ¸ï¼ä¸¦å¨å°åä¹¾æ·¨è³æéä¸å¾®èª¿æ¨¡åãä½¿ç¨æåé²çå©éæ®µç©ä»¶åµæ¸¬å¨é²è¡çå»£æ³å¯¦é©é¡¯ç¤ºï¼æåçæ¹æ³å¨å¾éç§»é¤çæ¹é¢æ¯å¾®èª¿åºç·æåäº 90%ï¼åæå°ä¹¾æ·¨è³ææºç¢ºåº¦æå¤±éå¶å¨ä½æ¼ 4%ãææåæç¥ï¼éé å·¥ä½æåºäºç¬¬ä¸åèçå©éæ®µç©ä»¶åµæ¸¬æ¨¡åä¸­å¾éåµæ¸¬åç§»é¤çæ¹æ³ï¼æ¨é²äºä¿è­·éäºè¤éç³»çµ±åæ¼å¾éæ»æçé åã

##### **Adversarial Watermarking for Face Recognition**
2409.16056v1 by Yuguang Yao, Anil Jain, Sijia Liu

Watermarking is an essential technique for embedding an identifier (i.e.,
watermark message) within digital images to assert ownership and monitor
unauthorized alterations. In face recognition systems, watermarking plays a
pivotal role in ensuring data integrity and security. However, an adversary
could potentially interfere with the watermarking process, significantly
impairing recognition performance. We explore the interaction between
watermarking and adversarial attacks on face recognition models. Our findings
reveal that while watermarking or input-level perturbation alone may have a
negligible effect on recognition accuracy, the combined effect of watermarking
and perturbation can result in an adversarial watermarking attack,
significantly degrading recognition performance. Specifically, we introduce a
novel threat model, the adversarial watermarking attack, which remains stealthy
in the absence of watermarking, allowing images to be correctly recognized
initially. However, once watermarking is applied, the attack is activated,
causing recognition failures. Our study reveals a previously unrecognized
vulnerability: adversarial perturbations can exploit the watermark message to
evade face recognition systems. Evaluated on the CASIA-WebFace dataset, our
proposed adversarial watermarking attack reduces face matching accuracy by
67.2% with an $\ell_\infty$ norm-measured perturbation strength of ${2}/{255}$
and by 95.9% with a strength of ${4}/{255}$.

æè¦ï¼æµ®æ°´å°æ¯ä¸ç¨®å°è­å¥ç¢¼ï¼å³æµ®æ°´å°è¨æ¯ï¼åµå¥æ¸ä½å½±åä¸­çåºæ¬æè¡ï¼ç¨æ¼ä¸»å¼µæææ¬ä¸¦ç£æ§æªç¶ææ¬çè®æ´ãå¨äººèè¾¨è­ç³»çµ±ä¸­ï¼æµ®æ°´å°å¨ç¢ºä¿è³æå®æ´æ§åå®å¨æ§æ¹é¢æ®æ¼èééµè§è²ãç¶èï¼å°æå¯è½æå¹²æ¾æµ®æ°´å°èçç¨åºï¼å´éæå®³è¾¨è­æè½ãæåæ¢è¨æµ®æ°´å°èå°ææ§æ»æå¨äººèè¾¨è­æ¨¡åä¹éçäºåãæåçç ç©¶çµæé¡¯ç¤ºï¼éç¶åæµ®æ°´å°æè¼¸å¥å±¤æ¾åå°è¾¨è­æºç¢ºåº¦å¯è½å½±é¿çå¾®ï¼ä½æµ®æ°´å°åæ¾åçç¶åææå¯è½æå°è´å°ææ§æµ®æ°´å°æ»æï¼å¤§å¹éä½è¾¨è­æè½ãå·é«ä¾èªªï¼æåå¼å¥äºä¸ç¨®æ°çå¨èæ¨¡åï¼å³å°ææ§æµ®æ°´å°æ»æï¼å¨æ²ææµ®æ°´å°çææ³ä¸ä»ç¶é±å½¢ï¼è®å½±åæåå¯ä»¥è¢«æ­£ç¢ºè¾¨è­ãç¶èï¼ä¸æ¦å¥ç¨æµ®æ°´å°ï¼æ»æå°±æè¢«ååï¼å°è´è¾¨è­å¤±æãæåçç ç©¶æ­é²äºä¸åä»¥åæªè¢«ç¼ç¾çæ¼æ´ï¼å°ææ§æ¾åå¯ä»¥å©ç¨æµ®æ°´å°è¨æ¯ä¾è¦é¿äººèè¾¨è­ç³»çµ±ãå¨ CASIA-WebFace è³æéä¸é²è¡è©ä¼°ï¼æåæåºçå°ææ§æµ®æ°´å°æ»æå°äººèéå°æºç¢ºåº¦éä½äº 67.2%ï¼$\ell_\infty$ ç¯æ¸æ¸¬éæ¾åå¼·åº¦çº ${2}/{255}$ï¼å¼·åº¦çº ${4}/{255}$ æéä½äº 95.9%ã

##### **Whole-body end-effector pose tracking**
2409.16048v1 by Tifanny Portela, Andrei Cramariuc, Mayank Mittal, Marco Hutter

Combining manipulation with the mobility of legged robots is essential for a
wide range of robotic applications. However, integrating an arm with a mobile
base significantly increases the system's complexity, making precise
end-effector control challenging. Existing model-based approaches are often
constrained by their modeling assumptions, leading to limited robustness.
Meanwhile, recent Reinforcement Learning (RL) implementations restrict the
arm's workspace to be in front of the robot or track only the position to
obtain decent tracking accuracy. In this work, we address these limitations by
introducing a whole-body RL formulation for end-effector pose tracking in a
large workspace on rough, unstructured terrains. Our proposed method involves a
terrain-aware sampling strategy for the robot's initial configuration and
end-effector pose commands, as well as a game-based curriculum to extend the
robot's operating range. We validate our approach on the ANYmal quadrupedal
robot with a six DoF robotic arm. Through our experiments, we show that the
learned controller achieves precise command tracking over a large workspace and
adapts across varying terrains such as stairs and slopes. On deployment, it
achieves a pose-tracking error of 2.64 cm and 3.64 degrees, outperforming
existing competitive baselines.

æè¦ï¼çµåæç¸±èæ©å¨äººè¿é¨ç§»åè½åå°æ¼å»£æ³çæ©å¨äººæç¨ä¾èªªè³ééè¦ãç¶èï¼å°æèèç§»ååºåº§æ´åå¨ä¸èµ·æå¤§å¹å¢å ç³»çµ±çè¤éæ§ï¼ä½¿å¾ç²¾ç¢ºçæ«ç«¯å·è¡å¨æ§å¶å·æææ°æ§ãç¾æçåºæ¼æ¨¡åçæ¹æ³éå¸¸åå°å¶å»ºæ¨¡åè¨­çéå¶ï¼å°è´ç©©å¥æ§æéãèæ­¤åæï¼æè¿çå¼·åå­¸ç¿ (RL) å¯¦ä½éå¶äºæèçå·¥ä½ç©ºéå¨æ©å¨äººåé¢ï¼æåè¿½è¹¤ä½ç½®ä»¥ç²å¾è¯å¥½çè¿½è¹¤æºç¢ºåº¦ãå¨éé å·¥ä½ä¸­ï¼æåééå¼å¥ä¸åå¨èº«é« RL å¬å¼ä¾è§£æ±ºéäºéå¶ï¼ä»¥å¨ç²ç³ãéçµæ§åå°å½¢ä¸çå¤§åå·¥ä½ç©ºéä¸­è¿½è¹¤æ«ç«¯å·è¡å¨çå§¿å¢ãæåæåºçæ¹æ³åå«ä¸åéå°æ©å¨äººåå§çµæåæ«ç«¯å·è¡å¨å§¿å¢æä»¤çå°å½¢æç¥åæ¨£ç­ç¥ï¼ä»¥åä¸ååºæ¼éæ²çèª²ç¨ï¼ä»¥æ´å±æ©å¨äººçæä½ç¯åãæåå¨éåå­åèªç±åº¦æ©å¨äººæèç ANYmal åè¶³æ©å¨äººä¸é©è­äºæåçåæ³ãééæåçå¯¦é©ï¼æåå±ç¤ºäºå­¸ç¿çæ§å¶å¨å¨ä¸åå¤§åå·¥ä½ç©ºéä¸­å¯¦ç¾ç²¾ç¢ºçæä»¤è¿½è¹¤ï¼ä¸¦é©ææ¨æ¢¯åæå¡ç­åç¨®å°å½¢ãå¨é¨ç½²æï¼å®å¯¦ç¾äº 2.64 å¬åå 3.64 åº¦çå§¿å¢è¿½è¹¤èª¤å·®ï¼åªæ¼ç¾æçç«¶ç­åºæºã

##### **LTNtorch: PyTorch Implementation of Logic Tensor Networks**
2409.16045v1 by Tommaso Carraro, Luciano Serafini, Fabio Aiolli

Logic Tensor Networks (LTN) is a Neuro-Symbolic framework that effectively
incorporates deep learning and logical reasoning. In particular, LTN allows
defining a logical knowledge base and using it as the objective of a neural
model. This makes learning by logical reasoning possible as the parameters of
the model are optimized by minimizing a loss function composed of a set of
logical formulas expressing facts about the learning task. The framework learns
via gradient-descent optimization. Fuzzy logic, a relaxation of classical logic
permitting continuous truth values in the interval [0,1], makes this learning
possible. Specifically, the training of an LTN consists of three steps.
Firstly, (1) the training data is used to ground the formulas. Then, (2) the
formulas are evaluated, and the loss function is computed. Lastly, (3) the
gradients are back-propagated through the logical computational graph, and the
weights of the neural model are changed so the knowledge base is maximally
satisfied. LTNtorch is the fully documented and tested PyTorch implementation
of Logic Tensor Networks. This paper presents the formalization of LTN and how
LTNtorch implements it. Moreover, it provides a basic binary classification
example.

æè¦ï¼éè¼¯å¼µéç¶²è·¯ (LTN) æ¯ä¸åç¥ç¶ç¬¦èæ¡æ¶ï¼ææå°æ´åäºæ·±åº¦å­¸ç¿åéè¼¯æ¨çãç¹å¥æ¯ï¼LTN åè¨±å®ç¾©éè¼¯ç¥è­åº«ï¼ä¸¦å°å¶ç¨ä½ç¥ç¶æ¨¡åçç®æ¨ãéä½¿å¾éééè¼¯æ¨çé²è¡å­¸ç¿æçºå¯è½ï¼å çºæ¨¡åçåæ¸æ¯ééæå°åç±ä¸çµè¡¨éå­¸ç¿ä»»åäºå¯¦çéè¼¯å¬å¼çµæçæå¤±å½æ¸ä¾åªåçãè©²æ¡æ¶ééæ¢¯åº¦ä¸éåªåé²è¡å­¸ç¿ãæ¨¡ç³éè¼¯æ¯ç¶å¸éè¼¯çæ¾å¯¬ï¼åè¨±å¨ [0,1] åéå§é£çºçå¼ï¼éä½¿å¾éç¨®å­¸ç¿æçºå¯è½ãå·é«ä¾èªªï¼LTN çè¨ç·´åå«ä¸åæ­¥é©ãé¦åï¼(1) è¨ç·´æ¸æç¨æ¼å»ºç«å¬å¼ãç¶å¾ï¼(2) è©ä¼°å¬å¼ï¼ä¸¦è¨ç®æå¤±å½æ¸ãæå¾ï¼(3) æ¢¯åº¦éééè¼¯è¨ç®åååå³æ­ï¼ä¸¦ä¸ç¥ç¶æ¨¡åçæ¬éè¢«æ¹è®ï¼å æ­¤ç¥è­åº«å¾å°æå¤§æ»¿è¶³ãLTNtorch æ¯ Logic Tensor Networks ç¶éååæä»¶ååæ¸¬è©¦ç PyTorch å¯¦ä½ãæ¬æä»ç´¹äº LTN çå½¢å¼åï¼ä»¥å LTNtorch å¦ä½å¯¦ä½å®ãæ­¤å¤ï¼å®éæä¾äºä¸ååºæ¬çäºååé¡ç¯ä¾ã

##### **Time-MoE: Billion-Scale Time Series Foundation Models with Mixture of Experts**
2409.16040v1 by Xiaoming Shi, Shiyu Wang, Yuqi Nie, Dianqi Li, Zhou Ye, Qingsong Wen, Ming Jin

Deep learning for time series forecasting has seen significant advancements
over the past decades. However, despite the success of large-scale pre-training
in language and vision domains, pre-trained time series models remain limited
in scale and operate at a high cost, hindering the development of larger
capable forecasting models in real-world applications. In response, we
introduce Time-MoE, a scalable and unified architecture designed to pre-train
larger, more capable forecasting foundation models while reducing inference
costs. By leveraging a sparse mixture-of-experts (MoE) design, Time-MoE
enhances computational efficiency by activating only a subset of networks for
each prediction, reducing computational load while maintaining high model
capacity. This allows Time-MoE to scale effectively without a corresponding
increase in inference costs. Time-MoE comprises a family of decoder-only
transformer models that operate in an auto-regressive manner and support
flexible forecasting horizons with varying input context lengths. We
pre-trained these models on our newly introduced large-scale data Time-300B,
which spans over 9 domains and encompassing over 300 billion time points. For
the first time, we scaled a time series foundation model up to 2.4 billion
parameters, achieving significantly improved forecasting precision. Our results
validate the applicability of scaling laws for training tokens and model size
in the context of time series forecasting. Compared to dense models with the
same number of activated parameters or equivalent computation budgets, our
models consistently outperform them by large margin. These advancements
position Time-MoE as a state-of-the-art solution for tackling real-world time
series forecasting challenges with superior capability, efficiency, and
flexibility.

æè¦ï¼<paragraph>å¨éå»çå¹¾åå¹´ä¸­ï¼æéåºåé æ¸¬çæ·±åº¦å­¸ç¿æäºé¡¯èçé²å±ãç¶èï¼åç®¡å¨èªè¨åè¦è¦ºé ååå¾äºå¤§è¦æ¨¡é è¨ç·´çæåï¼ä½é è¨ç·´çæéåºåæ¨¡åå¨è¦æ¨¡ä¸ä»ç¶æéï¼ä¸¦ä¸éä½ææ¬å¾é«ï¼é»ç¤äºå¨å¯¦éæç¨ä¸­éç¼æ´å¤§è½åçé æ¸¬æ¨¡åãçºäºè§£æ±ºéååé¡ï¼æåå¼å¥äº Time-MoEï¼éæ¯ä¸åå¯æ´åä¸çµ±ä¸çæ¶æ§ï¼æ¨å¨é è¨ç·´æ´å¤§ãæ´æè½åçé æ¸¬åºç¤æ¨¡åï¼åæéä½æ¨çææ¬ãééå©ç¨ç¨ççæ··åå°å®¶ (MoE) è¨­è¨ï¼Time-MoE åéå°æ¯åé æ¸¬åç¨ä¸åå­ç¶²è·¯ï¼é²èæé«éç®æçï¼å¨ç¶­æé«æ¨¡åå®¹éçåæéä½éç®è² è¼ãéè® Time-MoE è½å¤ æææ´åï¼èæ¨çææ¬ä¸æé¨ä¹å¢å ãTime-MoE åå«ä¸ç³»ååè§£ç¢¼å¨çTransformeræ¨¡åï¼éäºæ¨¡åä»¥èªè¿´æ­¸çæ¹å¼éä½ï¼ä¸¦æ¯æ´å·æä¸åè¼¸å¥å§å®¹é·åº¦çå½æ§é æ¸¬ç¯åãæåå¨æåæ°æ¨åºç Time-300B å¤§åè³æéä¸é è¨ç·´äºéäºæ¨¡åï¼è©²è³æéæ¶µèäº 9 åé åï¼åå«è¶é 3000 ååæéé»ãæåé¦æ¬¡å°æéåºååºç¤æ¨¡åæ´åå° 24 åååæ¸ï¼å¤§å¹æåäºé æ¸¬ç²¾åº¦ãæåççµæé©è­äºå¨æéåºåé æ¸¬ä¸­ï¼è¨ç·´ token åæ¨¡åå¤§å°çè¦æ¨¡å®å¾çé©ç¨æ§ãèå·æç¸åæ¸éå·²åç¨åæ¸æç­æéç®é ç®çç¨ å¯æ¨¡åç¸æ¯ï¼æåçæ¨¡åå§çµä»¥å¾å¤§çå¹åº¦åªæ¼å®åãéäºé²å±è® Time-MoE æçºè§£æ±ºå¯¦éæéåºåé æ¸¬ææ°çææ°è§£æ±ºæ¹æ¡ï¼å·ååè¶çæ§è½ãæçåéæ´»æ§ã</paragraph>

##### **Grounded Computation & Consciousness: A Framework for Exploring Consciousness in Machines & Other Organisms**
2409.16036v1 by Ryan Williams

Computational modeling is a critical tool for understanding consciousness,
but is it enough on its own? This paper discusses the necessity for an
ontological basis of consciousness, and introduces a formal framework for
grounding computational descriptions into an ontological substrate. Utilizing
this technique, a method is demonstrated for estimating the difference in
qualitative experience between two systems. This framework has wide
applicability to computational theories of consciousness.

æè¦ï¼è¨ç®æ¨¡åæ¯äºè§£æè­çééµå·¥å·ï¼
ä½å®æ¬èº«æ¯å¦è¶³å¤ ï¼æ¬æè¨è«äºæè­çæ¬é«åºç¤çå¿è¦æ§ï¼ä¸¦ä»ç´¹äºä¸åå°è¨ç®æè¿°åºç¤åå°æ¬é«åºåºçæ­£å¼æ¡æ¶ãå©ç¨æ­¤æè¡ï¼å±ç¤ºäºä¸ç¨®ä¼°è¨å©åç³»çµ±ä¹éå®æ§é«é©å·®ç°çæ¹æ³ãæ­¤æ¡æ¶å»£æ³é©ç¨æ¼æè­çè¨ç®çè«ã

##### **Deep chroma compression of tone-mapped images**
2409.16032v1 by Xenios Milidonis, Francesco Banterle, Alessandro Artusi

Acquisition of high dynamic range (HDR) images is thriving due to the
increasing use of smart devices and the demand for high-quality output.
Extensive research has focused on developing methods for reducing the luminance
range in HDR images using conventional and deep learning-based tone mapping
operators to enable accurate reproduction on conventional 8 and 10-bit digital
displays. However, these methods often fail to account for pixels that may lie
outside the target display's gamut, resulting in visible chromatic distortions
or color clipping artifacts. Previous studies suggested that a gamut management
step ensures that all pixels remain within the target gamut. However, such
approaches are computationally expensive and cannot be deployed on devices with
limited computational resources. We propose a generative adversarial network
for fast and reliable chroma compression of HDR tone-mapped images. We design a
loss function that considers the hue property of generated images to improve
color accuracy, and train the model on an extensive image dataset. Quantitative
experiments demonstrate that the proposed model outperforms state-of-the-art
image generation and enhancement networks in color accuracy, while a subjective
study suggests that the generated images are on par or superior to those
produced by conventional chroma compression methods in terms of visual quality.
Additionally, the model achieves real-time performance, showing promising
results for deployment on devices with limited computational resources.

æè¦ï¼ç±æ¼æºæ§è£ç½®ä½¿ç¨çæåï¼ä¸å°é«åè³ªè¼¸åºæéæ±ï¼å æ­¤é«åæç¯å (HDR) å½±åçåå¾æ­£è¬åç¼å±ä¸­ãå»£æ³çç ç©¶å°æ³¨æ¼éç¼ä½¿ç¨å³çµ±ååºæ¼æ·±åº¦å­¸ç¿çè²èª¿å°æéç®å­ï¼ä»¥ç¸®æ¸ HDR å½±åä¸­çäº®åº¦ç¯åçæ¹æ³ï¼ä»¥å¨å³çµ±ç 8 å 10 ä½åæ¸ä½é¡¯ç¤ºå¨ä¸é²è¡ç²¾ç¢ºçéç¾ãç¶èï¼éäºæ¹æ³éå¸¸ç¡æ³èéå¯è½ä½æ¼ç®æ¨é¡¯ç¤ºå¨è²åä¹å¤çåç´ ï¼å°è´å¯è¦çè²åº¦å¤±çæè²å½©è£åªçäººå·¥è£½åãååçç ç©¶å»ºè­°ï¼è²åç®¡çæ­¥é©å¯ç¢ºä¿ææåç´ é½ä½æ¼ç®æ¨è²åå§ãç¶èï¼æ­¤é¡æ¹æ³å¨éç®ä¸ææ¬é«æï¼ä¸ç¡æ³é¨ç½²å¨éç®è³æºæéçè£ç½®ä¸ãæåæåºäºä¸åç¨æ¼ HDR è²èª¿å°æå½±åå¿«éä¸å¯é çè²åº¦å£ç¸®ççæå°æç¶²è·¯ãæåè¨­è¨äºä¸åèéçæå½±åè²ç¸å±¬æ§çæå¤±å½æ¸ï¼ä»¥æ¹åè²å½©æºç¢ºåº¦ï¼ä¸¦å¨å»£æ³çå½±åè³æéä¸è¨ç·´æ¨¡åãå®éå¯¦é©è­æï¼ææåºçæ¨¡åå¨è²å½©æºç¢ºåº¦æ¹é¢åªæ¼ç¾æçå½±åçæåå¢å¼·ç¶²è·¯ï¼èä¸»è§ç ç©¶åè¡¨æï¼å¨è¦è¦ºåè³ªæ¹é¢ï¼çæçå½±åèå³çµ±è²åº¦å£ç¸®æ¹æ³ç¢ççå½±åä¸ç¸ä¸ä¸ï¼çè³æ´åªãæ­¤å¤ï¼è©²æ¨¡åå¯¦ç¾äºå³ææè½ï¼é¡¯ç¤ºåºå¨éç®è³æºæéçè£ç½®ä¸é¨ç½²ç promising çµæã

##### **Unlocking Markets: A Multilingual Benchmark to Cross-Market Question Answering**
2409.16025v1 by Yifei Yuan, Yang Deng, Anders SÃ¸gaard, Mohammad Aliannejadi

Users post numerous product-related questions on e-commerce platforms,
affecting their purchase decisions. Product-related question answering (PQA)
entails utilizing product-related resources to provide precise responses to
users. We propose a novel task of Multilingual Cross-market Product-based
Question Answering (MCPQA) and define the task as providing answers to
product-related questions in a main marketplace by utilizing information from
another resource-rich auxiliary marketplace in a multilingual context. We
introduce a large-scale dataset comprising over 7 million questions from 17
marketplaces across 11 languages. We then perform automatic translation on the
Electronics category of our dataset, naming it as McMarket. We focus on two
subtasks: review-based answer generation and product-related question ranking.
For each subtask, we label a subset of McMarket using an LLM and further
evaluate the quality of the annotations via human assessment. We then conduct
experiments to benchmark our dataset, using models ranging from traditional
lexical models to LLMs in both single-market and cross-market scenarios across
McMarket and the corresponding LLM subset. Results show that incorporating
cross-market information significantly enhances performance in both tasks.

æè¦ï¼<paragraph>ç¨æ¶å¨é»å­ååå¹³å°ä¸ç¼å¸è¨±å¤èç¢åç¸éçåé¡ï¼å½±é¿å¶è³¼è²·æ±ºç­ãèç¢åç¸éçåé¡åç­ (PQA) æå³èå©ç¨èç¢åç¸éçè³æºä¾åç¨æ¶æä¾ç²¾ç¢ºçåæãæåæåºäºä¸åå¤èªè¨è·¨å¸å ´ç¢ååé¡åç­ (MCPQA) çæ°ä»»åï¼ä¸¦å°è©²ä»»åå®ç¾©çºå©ç¨å¤èªè¨ç°å¢ä¸­å¦ä¸åè³æºè±å¯çè¼å©å¸å ´ä¸­çä¿¡æ¯ä¾åç­ä¸»è¦å¸å ´ä¸­èç¢åç¸éçåé¡ãæåå¼å¥äºä¸åå¤§åæ¸æéï¼å¶ä¸­åå«ä¾èª 11 ç¨®èªè¨ç 17 åå¸å ´ç 700 å¤è¬ååé¡ãç¶å¾ï¼æåå°æ¸æéçé»å­ç¢åé¡å¥é²è¡èªåç¿»è­¯ï¼ä¸¦å°å¶å½åçº McMarketãæåå°æ³¨æ¼å©åå­ä»»åï¼åºæ¼è©è«çç­æ¡çæåèç¢åç¸éçåé¡æåãå°æ¼æ¯åå­ä»»åï¼æåä½¿ç¨ LLM æ¨è¨ McMarket çä¸åå­éï¼ä¸¦ééäººå·¥è©ä¼°é²ä¸æ­¥è©ä¼°è¨»éçè³ªéãç¶å¾ï¼æåä½¿ç¨å¾å³çµ±è©å½æ¨¡åå° LLM çæ¨¡åå¨ McMarket åç¸æç LLM å­éä¸­é²è¡å®ä¸å¸å ´åè·¨å¸å ´å ´æ¯çåºæºæ¸¬è©¦ï¼ä»¥å°æåçæ¸æéé²è¡åºæºæ¸¬è©¦ãçµæè¡¨æï¼å¨å©åä»»åä¸­ï¼åä½µè·¨å¸å ´ä¿¡æ¯é¡¯èæé«äºæ§è½ã</paragraph>

##### **Bridging Environments and Language with Rendering Functions and Vision-Language Models**
2409.16024v1 by Theo Cachet, Christopher R. Dance, Olivier Sigaud

Vision-language models (VLMs) have tremendous potential for grounding
language, and thus enabling language-conditioned agents (LCAs) to perform
diverse tasks specified with text. This has motivated the study of LCAs based
on reinforcement learning (RL) with rewards given by rendering images of an
environment and evaluating those images with VLMs. If single-task RL is
employed, such approaches are limited by the cost and time required to train a
policy for each new task. Multi-task RL (MTRL) is a natural alternative, but
requires a carefully designed corpus of training tasks and does not always
generalize reliably to new tasks. Therefore, this paper introduces a novel
decomposition of the problem of building an LCA: first find an environment
configuration that has a high VLM score for text describing a task; then use a
(pretrained) goal-conditioned policy to reach that configuration. We also
explore several enhancements to the speed and quality of VLM-based LCAs,
notably, the use of distilled models, and the evaluation of configurations from
multiple viewpoints to resolve the ambiguities inherent in a single 2D view. We
demonstrate our approach on the Humanoid environment, showing that it results
in LCAs that outperform MTRL baselines in zero-shot generalization, without
requiring any textual task descriptions or other forms of environment-specific
annotation during training.
  Videos and an interactive demo can be found at
https://europe.naverlabs.com/text2control

æè¦ï¼è¦è¦ºèªè¨æ¨¡å (VLM) å·æå°èªè¨åºç¤åçå·¨å¤§æ½åï¼å¾èä½¿èªè¨æ¢ä»¶ä»£ç (LCA) è½å¤ å·è¡ç¨æå­æå®çåç¨®ä»»åãéä¿ä½¿äºåºæ¼å¼·åå­¸ç¿ (RL) ç LCA çç ç©¶ï¼å¶çåµæ¯ééæ¸²æç°å¢çå½±åä¸¦ä½¿ç¨ VLM è©ä¼°éäºå½±åèçµ¦äºçãå¦ææ¡ç¨å®ä¸ä»»å RLï¼æ­¤é¡æ¹æ³æåå°è¨ç·´æ¯åæ°ä»»åçç­ç¥æéçææ¬åæéçéå¶ãå¤ä»»å RL (MTRL) æ¯ä¸ç¨®èªç¶çæ¿ä»£æ¹æ¡ï¼ä½éè¦ä»ç´°è¨­è¨çè¨ç·´ä»»åèªæåº«ï¼ä¸¦ä¸ä¸¦ä¸ç¸½æ¯è½å¯é å°æ¨å»£å°æ°ä»»åãå æ­¤ï¼æ¬æä»ç´¹äºä¸åæ°ç©ç LCA å»ºæ§åé¡åè§£ï¼é¦åæ¾å°ä¸åç°å¢éç½®ï¼å¶å·ææè¿°ä»»åæå­çé« VLM åæ¸ï¼ç¶å¾ä½¿ç¨ï¼é è¨ç·´çï¼ç®æ¨æ¢ä»¶ç­ç¥ä¾éæè©²éç½®ãæåéæ¢ç´¢äºåºæ¼ VLM ç LCA çéåº¦ååè³ªçå¹¾é å¼·åï¼ç¹å¥æ¯è¸é¤¾æ¨¡åçä½¿ç¨ï¼ä»¥åå¾å¤åè¦é»è©ä¼°éç½®ä»¥è§£æ±ºå®ä¸ 2D è¦åä¸­åºæçæ¨¡ç³æ§ãæåå¨é¡äººç°å¢ä¸­å±ç¤ºäºæåçåæ³ï¼è¡¨æå®ç¢çç LCA å¨é¶æ¬¡å­¸ç¿æ³åä¸­åªæ¼ MTRL åºæºï¼èç¡éå¨è¨ç·´æéè¦æ±ä»»ä½æå­ä»»åæè¿°æå¶ä»å½¢å¼çç°å¢ç¹å®è¨»è§£ãå¯ä»¥å¨ https://europe.naverlabs.com/text2control æ¾å°å½±çåäºåå¼ç¤ºç¯ã

##### **AI Can Be Cognitively Biased: An Exploratory Study on Threshold Priming in LLM-Based Batch Relevance Assessment**
2409.16022v1 by Nuo Chen, Jiqun Liu, Xiaoyu Dong, Qijiong Liu, Tetsuya Sakai, Xiao-Ming Wu

Cognitive biases are systematic deviations in thinking that lead to
irrational judgments and problematic decision-making, extensively studied
across various fields. Recently, large language models (LLMs) have shown
advanced understanding capabilities but may inherit human biases from their
training data. While social biases in LLMs have been well-studied, cognitive
biases have received less attention, with existing research focusing on
specific scenarios. The broader impact of cognitive biases on LLMs in various
decision-making contexts remains underexplored. We investigated whether LLMs
are influenced by the threshold priming effect in relevance judgments, a core
task and widely-discussed research topic in the Information Retrieval (IR)
coummunity. The priming effect occurs when exposure to certain stimuli
unconsciously affects subsequent behavior and decisions. Our experiment
employed 10 topics from the TREC 2019 Deep Learning passage track collection,
and tested AI judgments under different document relevance scores, batch
lengths, and LLM models, including GPT-3.5, GPT-4, LLaMa2-13B and LLaMa2-70B.
Results showed that LLMs tend to give lower scores to later documents if
earlier ones have high relevance, and vice versa, regardless of the combination
and model used. Our finding demonstrates that LLM%u2019s judgments, similar to
human judgments, are also influenced by threshold priming biases, and suggests
that researchers and system engineers should take into account potential
human-like cognitive biases in designing, evaluating, and auditing LLMs in IR
tasks and beyond.

æè¦ï¼<paragraph>èªç¥åå·®æ¯æèä¸­ç³»çµ±æ§çåå·®ï¼æå°è´ä¸çæ§çå¤æ·åæåé¡çæ±ºç­å¶å®ï¼å¨åç¨®é åä¸­å»£æ³ç ç©¶ãæè¿ï¼å¤§åèªè¨æ¨¡å (LLM) å·²å±ç¾åºé²éççè§£è½åï¼ä½å¯è½æå¾å¶è¨ç·´è³æç¹¼æ¿äººé¡çåè¦ãéç¶ LLM ä¸­çç¤¾æåè¦å·²è¢«å»£æ³ç ç©¶ï¼ä½èªç¥åè¦è¼å°åå°éæ³¨ï¼ç¾æçç ç©¶èéæ¼ç¹å®æå¢ãèªç¥åè¦å° LLM å¨åç¨®æ±ºç­å¶å®æå¢ä¸­çæ´å»£æ³å½±é¿ä»æªååæ¢è¨ãæåèª¿æ¥äº LLM æ¯å¦åå°ç¸éå¤æ·ä¸­çé¾å¼ååææçå½±é¿ï¼éæ¯è³è¨æª¢ç´¢ (IR) ç¤¾ç¾¤ä¸­ä¸é æ ¸å¿ä»»ååå»£æ³è¨è«çç ç©¶ä¸»é¡ãç¶æ¥è§¸å°æäºåºæ¿æï¼ååæææç¼çï¼ç¡æè­å°å½±é¿å¾çºè¡çºåæ±ºç­ãæåçå¯¦é©æ¡ç¨äº TREC 2019 æ·±åº¦å­¸ç¿æ®µè½è»éæ¶éä¸­ç 10 åä¸»é¡ï¼ä¸¦å¨ä¸åçæä»¶ç¸éæ§è©åãæ¹æ¬¡é·åº¦å LLM æ¨¡åï¼åæ¬ GPT-3.5ãGPT-4ãLLaMa2-13B å LLaMa2-70Bï¼ä¸æ¸¬è©¦ AI å¤æ·ãçµæé¡¯ç¤ºï¼å¦æè¼æ©çæä»¶å·æé«ç¸éæ§ï¼LLM å¾åæ¼çµ¦äºè¼å¾çæä»¶è¼ä½åæ¸ï¼åä¹äº¦ç¶ï¼ç¡è«ä½¿ç¨åªç¨®çµååæ¨¡åãæåçç¼ç¾è­æï¼èäººé¡å¤æ·é¡ä¼¼ï¼LLM çå¤æ·ä¹åå°é¾å¼åååå·®çå½±é¿ï¼ä¸¦è¡¨æç ç©¶äººå¡åç³»çµ±å·¥ç¨å¸«å¨è¨­è¨ãè©ä¼°åç¨½æ ¸ IR ä»»ååå¶ä»ä»»åä¸­ç LLM æï¼æèæ®æ½å¨çäººé¡èªç¥åå·®ã</paragraph>

##### **Bridging Speech and Text: Enhancing ASR with Pinyin-to-Character Pre-training in LLMs**
2409.16005v1 by Yang Yuhang, Peng Yizhou, Eng Siong Chng, Xionghu Zhong

The integration of large language models (LLMs) with pre-trained speech
models has opened up new avenues in automatic speech recognition (ASR). While
LLMs excel in multimodal understanding tasks, effectively leveraging their
capabilities for ASR remains a significant challenge. This paper presents a
novel training approach to enhance LLM performance in ASR tasks. We propose
pre-training LLMs on Pinyin embedding sequences, which represent pronunciation
features, to generate corresponding Chinese characters. This step enables the
LLM to adapt to generating text from pronunciation features before encountering
real speech data. Furthermore, we fine-tune the LoRA parameters to enhance the
LLM's understanding of speech modality information. In AISHELL-1 corpus, our
approach yields a 9.5% relative improvement in ASR tasks compared to the
baseline without Pinyi-to-Character pre-training. Additionally, incorporating
auxiliary text data for Pinyi-to-Character pre-training further boosts
performance, achieving a 19.0% relative improvement.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) èé è¨ç·´èªé³æ¨¡åçæ´åï¼çºèªåèªé³è¾¨è­ (ASR) éåäºæ°çéå¾ãåç®¡ LLM å¨å¤æ¨¡æçè§£ä»»åä¸­è¡¨ç¾åºè²ï¼ä½ææå©ç¨å¶åè½é²è¡ ASR ä»ç¶æ¯ä¸é éå¤§ææ°ãæ¬ææåºäºä¸ç¨®æ°ç©çè¨ç·´æ¹æ³ï¼ä»¥å¢å¼· LLM å¨ ASR ä»»åä¸­çè¡¨ç¾ãæåå»ºè­°å¨è¡¨ç¤ºç¼é³ç¹å¾µçæ¼é³åµå¥åºåä¸é è¨ç·´ LLMï¼ä»¥ç¢çç¸æçä¸­ææ¼¢å­ãæ­¤æ­¥é©ä½¿ LLM è½å¤ å¨éå°çå¯¦èªé³æ¸æä¹åï¼é©æå¾ç¼é³ç¹å¾µç¢çææ¬ãæ­¤å¤ï¼æåå¾®èª¿ LoRA åæ¸ä»¥å¢å¼· LLM å°èªé³æ¨¡æè³è¨ççè§£ãå¨ AISHELL-1 èªæåº«ä¸­ï¼èæ²ææ¼é³è½æçºå­åçé è¨ç·´çåºæºç¸æ¯ï¼æåçåæ³å¨ ASR ä»»åä¸­ç¢çäº 9.5% çç¸å°æ¹é²ãæ­¤å¤ï¼å°è¼å©ææ¬æ¸æç´å¥æ¼é³è½æçºå­åçé è¨ç·´é²ä¸æ­¥æåäºæè½ï¼éå°äº 19.0% çç¸å°æ¹é²ã

##### **Artificial Human Intelligence: The role of Humans in the Development of Next Generation AI**
2409.16001v1 by Suayb S. Arslan

Human intelligence, the most evident and accessible form of source of
reasoning, hosted by biological hardware, has evolved and been refined over
thousands of years, positioning itself today to create new artificial forms and
preparing to self--design their evolutionary path forward. Beginning with the
advent of foundation models, the rate at which human and artificial
intelligence interact with each other has surpassed any anticipated
quantitative figures. The close engagement led to both bits of intelligence to
be impacted in various ways, which naturally resulted in complex confluences
that warrant close scrutiny. In the sequel, we shall explore the interplay
between human and machine intelligence, focusing on the crucial role humans
play in developing ethical, responsible, and robust intelligent systems. We
slightly delve into interesting aspects of implementation inspired by the
mechanisms underlying neuroscience and human cognition. Additionally, we
propose future perspectives, capitalizing on the advantages of symbiotic
designs to suggest a human-centered direction for next-generation AI
development. We finalize this evolving document with a few thoughts and open
questions yet to be addressed by the broader community.

æè¦ï¼äººé¡æºæ§æ¯æ¨çææé¡¯ä¸å¯å¾çä¾æºå½¢å¼ï¼ç±çç©ç¡¬é«ææ¿è¼ï¼æ­·ç¶æ¸åå¹´çæ¼åèç²¾é²ï¼å¦ä»å·²è½åµé åºæ°çå½¢å¼ï¼ä¸¦æºåèªè¡è¨­è¨å¶æªä¾çæ¼åè·¯å¾ãå¾åºç¤æ¨¡åçåºç¾éå§ï¼äººé¡èäººå·¥æºæ§äºåçéåº¦å·²è¶è¶ä»»ä½é æçæ¸éæ¸å­ãç·å¯çäºåè®éå©ç¨®æºæ§ä»¥åç¨®æ¹å¼ç¢çå½±é¿ï¼èªç¶èç¶å°ç¢çäºè¤éçå¯æµï¼å¼å¾ä»ç´°æ¢ç©¶ãå¨å¾çºé¨åï¼æåå°æ¢è¨äººé¡èæ©å¨æºæ§ä¹éçäº¤äºä½ç¨ï¼éé»éæ³¨äººé¡å¨éç¼å«çãè² è²¬ä»»ä¸å¼·å¥çæºæ§ç³»çµ±ä¸­ææ®æ¼çééµè§è²ãæåå°ç¨å¾®æ·±å¥æ¢è¨åç¥ç¶ç§å­¸åäººé¡èªç¥æ©å¶åç¼çå¯¦ä½æè¶£é¢åãæ­¤å¤ï¼æåæåºæªä¾çè§é»ï¼å©ç¨å±çè¨­è¨çåªå¢ï¼çºä¸ä¸ä»£ AI ç¼å±æåºä»¥äººçºä¸­å¿çæ¹éãæåä»¥ä¸äºæ³æ³åéæ¾æ§åé¡çºéä»½ä¸æ·æ¼åçæä»¶ä½çµï¼éäºåé¡ä»æå¾æ´å»£æ³çç¤¾ç¾¤ä¾æ¢è¨ã

##### **Improvements to SDXL in NovelAI Diffusion V3**
2409.15997v1 by Juan Ossa, Eren DoÄan, Alex Birch, F. Johnson

In this technical report, we document the changes we made to SDXL in the
process of training NovelAI Diffusion V3, our state of the art anime image
generation model.

æè¦ï¼å¨æ­¤æè¡å ±åä¸­ï¼æåè¨éäºå¨è¨ç·´ NovelAI Diffusion V3 çéç¨ä¸­å° SDXL æåçè®æ´ï¼éæ¯æåæåé²çåæ¼«å½±åçææ¨¡åã

##### **DataGpt-SQL-7B: An Open-Source Language Model for Text-to-SQL**
2409.15985v1 by Lixia Wu, Peng Li, Junhong Lou, Lei Fu

In addressing the pivotal role of translating natural language queries into
SQL commands, we propose a suite of compact, fine-tuned models and self-refine
mechanisms to democratize data access and analysis for non-expert users,
mitigating risks associated with closed-source Large Language Models.
Specifically, we constructed a dataset of over 20K sample for Text-to-SQL as
well as the preference dateset, to improve the efficiency in the domain of SQL
generation. To further ensure code validity, a code corrector was integrated
into the model. Our system, DataGpt-sql, achieved 87.2\% accuracy on the
spider-dev, respectively, showcasing the effectiveness of our solution in
text-to-SQL conversion tasks. Our code, data, and models are available at
\url{https://github.com/CainiaoTechAi/datagpt-sql-7b}

æè¦ï¼å¨è§£æ±ºå°èªç¶èªè¨æ¥è©¢è½æçº SQL æä»¤çééµè§è²æï¼æåæåºäºä¸å¥ç¶éå¾®èª¿çç²¾ç°¡æ¨¡ååèªæç²¾çæ©å¶ï¼ä»¥æ°ä¸»åéå°å®¶ä½¿ç¨èçè³æå­åååæï¼ä¸¦éä½èå°éåå§ç¢¼å¤§åèªè¨æ¨¡åç¸éçé¢¨éªãå·é«ä¾èªªï¼æåå»ºæ§äºä¸åè¶é 20K åç¯ä¾çè³æéï¼ç¨æ¼æå­è½ SQL ä»¥ååå¥½è³æéï¼ä»¥æå SQL ç¢çé åçæçãçºäºé²ä¸æ­¥ç¢ºä¿ç¨å¼ç¢¼çæææ§ï¼æåå°ç¨å¼ç¢¼æ ¡æ­£å¨æ´åå°æ¨¡åä¸­ãæåçç³»çµ± DataGpt-sql å¨ spider-dev ä¸éå°äº 87.2% çæºç¢ºåº¦ï¼åå¥å±ç¤ºäºæåçè§£æ±ºæ¹æ¡å¨æå­è½ SQL è½æä»»åä¸­çæææ§ãæåçç¨å¼ç¢¼ãè³æåæ¨¡åå¯å¨ \url{https://github.com/CainiaoTechAi/datagpt-sql-7b} åå¾

##### **Leveraging Unsupervised Learning for Cost-Effective Visual Anomaly Detection**
2409.15980v1 by Yunbo Long, Zhengyang Ling, Sam Brook, Duncan McFarlane, Alexandra Brintrup

Traditional machine learning-based visual inspection systems require
extensive data collection and repetitive model training to improve accuracy.
These systems typically require expensive camera, computing equipment and
significant machine learning expertise, which can substantially burden small
and medium-sized enterprises. This study explores leveraging unsupervised
learning methods with pre-trained models and low-cost hardware to create a
cost-effective visual anomaly detection system. The research aims to develop a
low-cost visual anomaly detection solution that uses minimal data for model
training while maintaining generalizability and scalability. The system
utilises unsupervised learning models from Anomalib and is deployed on
affordable Raspberry Pi hardware through openVINO. The results show that this
cost-effective system can complete anomaly defection training and inference on
a Raspberry Pi in just 90 seconds using only 10 normal product images,
achieving an F1 macro score exceeding 0.95. While the system is slightly
sensitive to environmental changes like lighting, product positioning, or
background, it remains a swift and economical method for factory automation
inspection for small and medium-sized manufacturers

æè¦ï¼å³çµ±çæ©å¨å­¸ç¿è¦è¦ºæª¢æ¸¬ç³»çµ±éè¦å»£æ³çè³ææ¶éåéè¤çæ¨¡åè¨ç·´æè½æé«æºç¢ºåº¦ãéäºç³»çµ±éå¸¸éè¦æè²´çç¸æ©ãéç®è¨­ååå¤§éçæ©å¨å­¸ç¿å°æ¥­ç¥è­ï¼éå¯è½æå°ä¸­å°åä¼æ¥­é æéå¤§è² æãæ¬ç ç©¶æ¢è¨äºå©ç¨éç£ç£å¼å­¸ç¿æ¹æ³ãé è¨ç·´æ¨¡ååä½ææ¬ç¡¬é«ä¾å»ºç«ä¸åå·ææ¬æççè¦è¦ºç°å¸¸åµæ¸¬ç³»çµ±ãè©²ç ç©¶æ¨å¨éç¼ä¸åä½ææ¬çè¦è¦ºç°å¸¸åµæ¸¬è§£æ±ºæ¹æ¡ï¼å¨ç¶­æå¯æ¦åæ§åå¯æ´åæ§çåæï¼ä½¿ç¨æå°çè³æé²è¡æ¨¡åè¨ç·´ãè©²ç³»çµ±å©ç¨ Anomalib çéç£ç£å¼å­¸ç¿æ¨¡åï¼ä¸¦éé openVINO é¨ç½²å¨ç¶æ¿å¯¦æ ç Raspberry Pi ç¡¬é«ä¸ãçµæé¡¯ç¤ºï¼éåå·ææ¬æççç³»çµ±åä½¿ç¨ 10 å¼µæ­£å¸¸çç¢ååçï¼å°±è½å¨ Raspberry Pi ä¸å®æç°å¸¸ç¼ºé·è¨ç·´åæ¨è«ï¼åªé 90 ç§ï¼å³å¯éå°è¶é 0.95 ç F1 å·¨éåæ¸ãéç¶è©²ç³»çµ±å°ç°å¢è®åï¼ä¾å¦åç·ãç¢åå®ä½æèæ¯ï¼ç¥å¾®ææï¼ä½å®ä»ç¶æ¯ä¸­å°åè£½é åé²è¡å·¥å» èªååæª¢æ¸¬çå¿«éä¸ç¶æ¿çæ¹æ³

##### **Finetuning LLMs for Comparative Assessment Tasks**
2409.15979v1 by Vatsal Raina, Adian Liusie, Mark Gales

Automated assessment in natural language generation is a challenging task.
Instruction-tuned large language models (LLMs) have shown promise in
reference-free evaluation, particularly through comparative assessment.
However, the quadratic computational complexity of pairwise comparisons limits
its scalability. To address this, efficient comparative assessment has been
explored by applying comparative strategies on zero-shot LLM probabilities. We
propose a framework for finetuning LLMs for comparative assessment to align the
model's output with the target distribution of comparative probabilities. By
training on soft probabilities, our approach improves state-of-the-art
performance while maintaining high performance with an efficient subset of
comparisons.

æè¦ï¼èªç¶èªè¨çæä¸­çèªååè©ä¼°æ¯ä¸é å·æææ°æ§çä»»åã
ç¶éæä»¤èª¿æ´çå¤§åèªè¨æ¨¡å (LLM) å¨ç¡åèè©ä¼°ä¸­å±ç¾åºåæ¯ï¼ç¹å¥æ¯ééæ¯è¼æ§è©ä¼°ã
ç¶èï¼æå°æ¯è¼äºæ¬¡è¨ç®è¤éåº¦éå¶äºå¶å¯æ´åæ§ãçºäºè§£æ±ºéååé¡ï¼ééå¨é¶æ¬¡å­¸ç¿ LLM æ©çä¸æç¨æ¯è¼ç­ç¥ï¼æ¢ç´¢äºææççæ¯è¼æ§è©ä¼°ãæåæåºäºä¸åç¨æ¼æ¯è¼æ§è©ä¼°çå¾®èª¿ LLM æ¶æ§ï¼ä»¥å°æ¨¡åçè¼¸åºèæ¯è¼æ©ççç®æ¨åä½å°é½ãééå¨è»æ©çä¸é²è¡è¨ç·´ï¼æåçåæ³æ¹åäºæåé²çæè½ï¼åæå¨ææççæ¯è¼å­éä¸­ç¶­æé«æè½ã

##### **StyleSinger 2: Zero-Shot Singing Voice Synthesis with Style Transfer and Multi-Level Style Control**
2409.15977v1 by Yu Zhang, Ziyue Jiang, Ruiqi Li, Changhao Pan, Jinzheng He, Rongjie Huang, Chuxin Wang, Zhou Zhao

Zero-shot singing voice synthesis (SVS) with style transfer and style control
aims to generate high-quality singing voices with unseen timbres and styles
(including singing method, emotion, rhythm, technique, and pronunciation) from
audio and text prompts. However, the multifaceted nature of singing styles
poses a significant challenge for effective modeling, transfer, and control.
Furthermore, current SVS models often fail to generate singing voices rich in
stylistic nuances for unseen singers. To address these challenges, we introduce
StyleSinger 2, the first zero-shot SVS model for style transfer across
cross-lingual speech and singing styles, along with multi-level style control.
Specifically, StyleSinger 2 proposes three primary modules: 1) the clustering
style encoder employs a clustering vector quantization model to stably condense
style information into a compact latent space; 2) the Style and Duration
Language Model (S\&D-LM) concurrently predicts style information and phoneme
duration, which benefits both; 3) the style adaptive decoder uses a novel
mel-style adaptive normalization method to generate singing voices with
enhanced details. Experimental results show that StyleSinger 2 outperforms all
baseline models in synthesis quality, singer similarity, and style
controllability across various tasks, including zero-shot style transfer,
multi-level style control, cross-lingual style transfer, and speech-to-singing
style transfer. Singing voice samples can be accessed at
https://stylesinger2.github.io/.

æè¦ï¼é¶æ¨£æ¬æ­å±è²é³åæ (SVS)ï¼å·åé¢¨æ ¼è½ç§»åé¢¨æ ¼æ§å¶ï¼æ¨å¨æ ¹æé³è¨åæå­æç¤ºçæå·ææªè¦é³è²åé¢¨æ ¼ï¼åæ¬æ­å±æ¹å¼ãæç·ãç¯å¥ãæå·§åç¼é³ï¼çé«åè³ªæ­å±è²é³ãç¶èï¼æ­å±é¢¨æ ¼çå¤æ¨£æ§å°ææçå»ºæ¨¡ãè½ç§»åæ§å¶æ§æäºéå¤§ææ°ãæ­¤å¤ï¼ç®åç SVS æ¨¡åéå¸¸ç¡æ³çºæªè¦æ­æçæå¯æé¢¨æ ¼ç´°å¾®å·®å«çæ­å±è²é³ãçºäºæå°éäºææ°ï¼æåå¼å¥äº StyleSinger 2ï¼éæ¯ç¬¬ä¸åè·¨èªè¨èªé³åæ­å±é¢¨æ ¼é²è¡é¢¨æ ¼è½ç§»çé¶æ¨£æ¬ SVS æ¨¡åï¼ä¸¦å·åå¤ç´é¢¨æ ¼æ§å¶ãå·é«ä¾èªªï¼StyleSinger 2 æåºä¸åä¸»è¦æ¨¡çµï¼1) èé¡é¢¨æ ¼ç·¨ç¢¼å¨æ¡ç¨èé¡åééåæ¨¡åï¼å°é¢¨æ ¼è³è¨ç©©å®å°æ¿ç¸®å°ä¸åç·æ¹çæ½å¨ç©ºéï¼2) é¢¨æ ¼åæçºæéèªè¨æ¨¡å (S&D-LM) åæé æ¸¬é¢¨æ ¼è³è¨åé³ç´ æçºæéï¼éå°å©èé½æå©ï¼3) é¢¨æ ¼èªé©æè§£ç¢¼å¨ä½¿ç¨ä¸ç¨®æ°ç©ç mel é¢¨æ ¼èªé©ææ­£è¦åæ¹æ³ï¼ä»¥çæå·æå¢å¼·ç´°ç¯çæ­å±è²é³ãå¯¦é©çµæè¡¨æï¼å¨é¶æ¨£æ¬é¢¨æ ¼è½ç§»ãå¤ç´é¢¨æ ¼æ§å¶ãè·¨èªè¨é¢¨æ ¼è½ç§»åèªé³å°æ­å±é¢¨æ ¼è½ç§»ç­åç¨®ä»»åä¸­ï¼StyleSinger 2 å¨åæåè³ªãæ­æç¸ä¼¼æ§åé¢¨æ ¼å¯æ§æ§æ¹é¢é½åªæ¼ææåºç·æ¨¡åãå¯ä»¥å¨ https://stylesinger2.github.io/ è¨ªåæ­å±è²é³ç¯ä¾ã

##### **Disentangling Age and Identity with a Mutual Information Minimization Approach for Cross-Age Speaker Verification**
2409.15974v1 by Fengrun Zhang, Wangjin Zhou, Yiming Liu, Wang Geng, Yahui Shan, Chen Zhang

There has been an increasing research interest in cross-age speaker
verification~(CASV). However, existing speaker verification systems perform
poorly in CASV due to the great individual differences in voice caused by
aging. In this paper, we propose a disentangled representation learning
framework for CASV based on mutual information~(MI) minimization. In our
method, a backbone model is trained to disentangle the identity- and
age-related embeddings from speaker information, and an MI estimator is trained
to minimize the correlation between age- and identity-related embeddings via MI
minimization, resulting in age-invariant speaker embeddings. Furthermore, by
using the age gaps between positive and negative samples, we propose an
aging-aware MI minimization loss function that allows the backbone model to
focus more on the vocal changes with large age gaps. Experimental results show
that the proposed method outperforms other methods on multiple Cross-Age test
sets of Vox-CA.

æè¦ï¼è¿å¹´ä¾ï¼è·¨å¹´é½¡èªªè©±èé©è­ (CASV) çç ç©¶èè¶£èæ¥ä¿±å¢ãç¶èï¼ç±æ¼èåå°è´è²é³ç¢çæ¥µå¤§çåé«å·®ç°ï¼ç¾æçèªªè©±èé©è­ç³»çµ±å¨ CASV ä¸­è¡¨ç¾ä¸ä½³ãå¨æ¬æä¸­ï¼æåæåºäºä¸ååºæ¼äºä¿¡æ¯ (MI) æå°åç CASV è§£ç³¾çºè¡¨ç¤ºå­¸ç¿æ¡æ¶ãå¨æåçæ¨¡åä¸­ï¼è¨ç·´ä¸åä¸»å¹¹æ¨¡åå¾èªªè©±èè³è¨ä¸­è§£ç³¾çºèº«ä»½åå¹´é½¡ç¸éçåµå¥ï¼ä¸¦è¨ç·´ä¸å MI ä¼°è¨å¨éé MI æå°åä¾æå°åå¹´é½¡åèº«ä»½ç¸éåµå¥ä¹éçç¸éæ§ï¼ç¢çèå¹´é½¡ç¡éçèªªè©±èåµå¥ãæ­¤å¤ï¼ééä½¿ç¨æ­£è² æ¨£æ¬ä¹éçå¹´é½¡å·®è·ï¼æåæåºäºä¸åèåæç¥ MI æå°åæå¤±å½æ¸ï¼è®ä¸»å¹¹æ¨¡åè½æ´å°æ³¨æ¼å¹´é½¡å·®è·å¤§çè²é³è®åãå¯¦é©çµæè¡¨æï¼ææåºçæ¹æ³å¨ Vox-CA çå¤åè·¨å¹´é½¡æ¸¬è©¦éä¸­åªæ¼å¶ä»æ¹æ³ã

##### **Creating Healthy Friction: Determining Stakeholder Requirements of Job Recommendation Explanations**
2409.15971v1 by Roan Schellingerhout, Francesco Barile, Nava Tintarev

The increased use of information retrieval in recruitment, primarily through
job recommender systems (JRSs), can have a large impact on job seekers,
recruiters, and companies. As a result, such systems have been determined to be
high-risk in recent legislature. This requires JRSs to be trustworthy and
transparent, allowing stakeholders to understand why specific recommendations
were made. To fulfill this requirement, the stakeholders' exact preferences and
needs need to be determined. To do so, we evaluated an explainable job
recommender system using a realistic, task-based, mixed-design user study
(n=30) in which stakeholders had to make decisions based on the model's
explanations. This mixed-methods evaluation consisted of two objective metrics
- correctness and efficiency, along with three subjective metrics - trust,
transparency, and usefulness. These metrics were evaluated twice per
participant, once using real explanations and once using random explanations.
The study included a qualitative analysis following a think-aloud protocol
while performing tasks adapted to each stakeholder group. We find that
providing stakeholders with real explanations does not significantly improve
decision-making speed and accuracy. Our results showed a non-significant trend
for the real explanations to outperform the random ones on perceived trust,
usefulness, and transparency of the system for all stakeholder types. We
determine that stakeholders benefit more from interacting with explanations as
decision support capable of providing healthy friction, rather than as
previously-assumed persuasive tools.

æè¦ï¼è³è¨æª¢ç´¢å¨æåä¸­çä½¿ç¨æ¥çå¢å ï¼ä¸»è¦æ¯ééå·¥ä½æ¨è¦ç³»çµ± (JRS)ï¼éå¯è½æå°æ±è·èãæåäººå¡åå¬å¸ç¢çéå¤§å½±é¿ãå æ­¤ï¼æ­¤é¡ç³»çµ±å¨æè¿çç«æ³ä¸­å·²è¢«èªå®çºé«é¢¨éªãéè¦æ± JRS å¼å¾ä¿¡è³´ä¸éæï¼è®å©å®³éä¿äººäºè§£çºä½æåºç¹å®å»ºè­°ãçºæ»¿è¶³æ­¤è¦æ±ï¼éè¦ç¢ºå®å©å®³éä¿äººçç¢ºååå¥½åéæ±ãçºæ­¤ï¼æåä½¿ç¨ä¸åç¾å¯¦çãåºæ¼ä»»åçãæ··åè¨­è¨ä½¿ç¨èç ç©¶ (n=30) ä¾è©ä¼°ä¸åå¯è§£éçå·¥ä½æ¨è¦ç³»çµ±ï¼å¶ä¸­å©å®³éä¿äººå¿é æ ¹ææ¨¡åçè§£éååºæ±ºç­ãéç¨®æ··åæ¹æ³è©ä¼°åå«å©åå®¢è§ææ¨ - æ­£ç¢ºæ§åæçï¼ä»¥åä¸åä¸»è§ææ¨ - ä¿¡ä»»ãéæåº¦åæç¨æ§ãéäºææ¨æ¯ä½åèèè©ä¼°å©æ¬¡ï¼ä¸æ¬¡ä½¿ç¨çå¯¦è§£éï¼ä¸æ¬¡ä½¿ç¨é¨æ©è§£éãè©²ç ç©¶åæ¬å¨å·è¡é©ææ¯åå©å®³éä¿äººçµå¥çä»»åæéµå¾ªæèåºè²åå®çå®æ§åæãæåç¼ç¾ï¼åå©å®³éä¿äººæä¾çå¯¦è§£éä¸¦æªé¡¯èæé«æ±ºç­éåº¦åæºç¢ºæ§ãæåççµæé¡¯ç¤ºï¼å°æ¼ææå©å®³éä¿äººé¡åï¼çå¯¦è§£éå¨ç³»çµ±çæç¥ä¿¡ä»»åº¦ãæç¨æ§åéæåº¦æ¹é¢åªæ¼é¨æ©è§£éçè¶¨å¢ä¸é¡¯èãæåç¢ºå®ï¼å©å®³éä¿äººå¾èè§£éäºåä¸­åçæ´å¤ï¼å çºè§£éä½çºæ±ºç­æ¯æ´è½å¤ æä¾æççæ©æ¦ï¼èä¸æ¯åååè¨­çèªªæå·¥å·ã

##### **ASD-Diffusion: Anomalous Sound Detection with Diffusion Models**
2409.15957v1 by Fengrun Zhang, Xiang Xie, Kai Guo

Unsupervised Anomalous Sound Detection (ASD) aims to design a generalizable
method that can be used to detect anomalies when only normal sounds are given.
In this paper, Anomalous Sound Detection based on Diffusion Models
(ASD-Diffusion) is proposed for ASD in real-world factories. In our pipeline,
the anomalies in acoustic features are reconstructed from their noisy corrupted
features into their approximate normal pattern. Secondly, a post-processing
anomalies filter algorithm is proposed to detect anomalies that exhibit
significant deviation from the original input after reconstruction.
Furthermore, denoising diffusion implicit model is introduced to accelerate the
inference speed by a longer sampling interval of the denoising process. The
proposed method is innovative in the application of diffusion models as a new
scheme. Experimental results on the development set of DCASE 2023 challenge
task 2 outperform the baseline by 7.75%, demonstrating the effectiveness of the
proposed method.

æè¦ï¼ç¡ç£ç£ç°å¸¸é³è¨åµæ¸¬ (ASD) çç®æ¨æ¯è¨­è¨ä¸åå¯æ¦æ¬çæ¹æ³ï¼å¯ç¨æ¼å¨åªææ­£å¸¸é³è¨çææ³ä¸åµæ¸¬ç°å¸¸ãå¨æ¬æä¸­ï¼æåºäºåºæ¼æ´æ£æ¨¡åçç°å¸¸é³è¨åµæ¸¬ (ASD-Diffusion) ä¾é²è¡çå¯¦ä¸çå·¥å» ä¸­ç ASDãå¨æåçç®¡éä¸­ï¼æå°é³è¨ç¹å¾µä¸­çç°å¸¸å¾å¶éè¨ç ´å£ç¹å¾µéå»ºæå¶è¿ä¼¼çæ­£å¸¸æ¨¡å¼ãå¶æ¬¡ï¼æåºäºä¸åå¾èçç°å¸¸éæ¿¾å¨æ¼ç®æ³ï¼ç¨æ¼åµæ¸¬å¨éå»ºå¾èåå§è¼¸å¥æé¡¯èåå·®çç°å¸¸ãæ­¤å¤ï¼å¼å¥äºå»åªæ´æ£é±å¼æ¨¡åï¼ä»¥ééå»åªéç¨æ´é·çåæ¨£ééä¾å éæ¨è«éåº¦ãææåºçæ¹æ³å¨å°æ´æ£æ¨¡åæç¨çºæ°æ¹æ¡æ¹é¢å·æåµæ°æ§ãå¨ DCASE 2023 ææ°ä»»å 2 çéç¼éä¸çå¯¦é©çµææ¯åºæºé«åº 7.75%ï¼è­æäºææåºæ¹æ³çæææ§ã

##### **Historical Trajectory Assisted Zeroth-Order Federated Optimization**
2409.15955v2 by Xiaoyu He, Chenlin Wu, Zike Li, Zibin Zheng

Federated learning is a distributed learning framework which enables clients
to train models individually and to upload their model updates for aggregation.
The local training process heavily relies on distributed gradient descent
techniques. In the situation where gradient information is not available, the
gradients need to be estimated from zeroth-order information, which typically
involves computing finite-differences along isotropic random directions. This
method suffers from high estimation errors, as the geometric features of the
objective landscape may be overlooked during the isotropic sampling. In this
work, we propose a non-isotropic sampling method to improve the gradient
estimation procedure. Gradients in our method are estimated in a subspace
spanned by historical trajectories of solutions, aiming to encourage the
exploration of promising regions and hence improve the convergence. We
implement this method in zeroth-order federated settings, and show that the
convergence rate aligns with existing ones while introducing no significant
overheads in communication or local computation. The effectiveness of our
proposal is verified on several numerical experiments in comparison to several
commonly-used zeroth-order federated optimization algorithms.

æè¦ï¼è¯é¦å¼å­¸ç¿æ¯ä¸ç¨®åæ£å¼å­¸ç¿æ¶æ§ï¼å®è®å®¢æ¶ç«¯è½å¤ åå¥è¨ç·´æ¨¡åï¼ä¸¦ä¸å³ä»åçæ¨¡åæ´æ°ä»¥é²è¡å½ç¸½ã
æ¬å°çè¨ç·´ç¨åºæ¥µåº¦ä¾è³´åæ£å¼æ¢¯åº¦ä¸éæè¡ãå¨ç¡æ³åå¾æ¢¯åº¦è³è¨çææ³ä¸ï¼éè¦å¾é¶éè³è¨ä¼°è¨æ¢¯åº¦ï¼ééå¸¸éè¦æ²¿èåååæ§é¨æ©æ¹åè¨ç®æéå·®åãéç¨®æ¹æ³ææè¼é«çä¼°è¨èª¤å·®ï¼å çºå¨åååæ§æ½æ¨£æéå¯è½æå¿½ç¥ç®æ¨æ¯è§çå¹¾ä½ç¹å¾µãå¨æ­¤é å·¥ä½ä¸­ï¼æåæåºäºä¸ç¨®éåååæ§æ½æ¨£æ¹æ³ä¾æ¹åæ¢¯åº¦ä¼°è¨ç¨åºãæåçæ¹æ³ä¸­çæ¢¯åº¦æ¯å¨ç±è§£çæ­·å²è»è·¡ææ§æçå­ç©ºéä¸­ä¼°è¨çï¼æ¨å¨é¼åµæ¢ç´¢æåæ¯çååï¼å¾èæ¹åæ¶ææ§ãæåå¨é¶éè¯é¦å¼è¨­å®ä¸­å¯¦ä½æ­¤æ¹æ³ï¼ä¸¦è¡¨ææ¶æéåº¦èç¾ææ¹æ³ä¸è´ï¼åæå¨éè¨ææ¬å°éç®ä¸­ä¸æå¼å¥ä»»ä½é¡¯èçéé·ãèå¹¾åå¸¸ç¨çé¶éè¯é¦å¼æä½³åæ¼ç®æ³ç¸æ¯ï¼æåçå»ºè­°å¨å¹¾åæ¸å¼å¯¦é©ä¸­é©è­äºå¶æææ§ã

##### **Beats of Bias: Analyzing Lyrics with Topic Modeling and Gender Bias Measurements**
2409.15949v1 by Danqing Chen, Adithi Satish, Rasul Khanbayov, Carolin M. Schuster, Georg Groh

This paper uses topic modeling and bias measurement techniques to analyze and
determine gender bias in English song lyrics. We utilize BERTopic to cluster
537,553 English songs into distinct topics and chart their development over
time. Our analysis shows the thematic shift in song lyrics over the years, from
themes of romance to the increasing sexualization of women in songs. We observe
large amounts of profanity and misogynistic lyrics on various topics,
especially in the overall biggest cluster. Furthermore, to analyze gender bias
across topics and genres, we employ the Single Category Word Embedding
Association Test (SC-WEAT) to compute bias scores for the word embeddings
trained on the most popular topics as well as for each genre. We find that
words related to intelligence and strength tend to show a male bias across
genres, as opposed to appearance and weakness words, which are more
female-biased; however, a closer look also reveals differences in biases across
topics.

æè¦ï¼éç¯è«æä½¿ç¨ä¸»é¡å»ºæ¨¡ååèª¤æ¸¬éæè¡ä¾åæåç¢ºå®è±ææ­æ²æ­è©ä¸­çæ§å¥åè¦ãæåå©ç¨ BERTopic å° 537,553 é¦è±ææ­æ²åé¡æä¸åçä¸»é¡ï¼ä¸¦ç¹ªè£½å®åé¨æéçç¼å±ãæåçåæé¡¯ç¤ºäºæ­æ²æ­è©ä¸­ä¸»é¡çè½è®ï¼å¾æµªæ¼«çä¸»é¡å°æ­æ²ä¸­å¥³æ§çæ§åç¨åº¦è¶ä¾è¶é«ãæåè§å¯å°å¤§éè¤»çåå­å¥³çæ­è©åºç¾å¨åç¨®ä¸»é¡ä¸­ï¼ç¹å¥æ¯å¨æ´é«æå¤§çç¾¤éä¸­ãæ­¤å¤ï¼çºäºåæä¸åä¸»é¡åé¡å¥ä¸­çæ§å¥åè¦ï¼æåæ¡ç¨å®ä¸é¡å¥è©åµå¥éè¯æ¸¬è©¦ (SC-WEAT) ä¾è¨ç®å¨æç±éä¸»é¡ä»¥åæ¯åé¡å¥ä¸­è¨ç·´çè©åµå¥çåè¦åæ¸ãæåç¼ç¾èæºåååéç¸éçè©å½å¨ä¸åé¡å¥ä¸­å¾å¾è¡¨ç¾åºç·æ§åè¦ï¼èèå¤è²åå¼±é»ç¸éçè©å½åæ´ååå¥³æ§ï¼ç¶èï¼æ´ä»ç´°çè§å¯ä¹æ­ç¤ºäºä¸åä¸»é¡ä¹éåè¦çå·®ç°ã

##### **TSFeatLIME: An Online User Study in Enhancing Explainability in Univariate Time Series Forecasting**
2409.15950v1 by Hongnan Ma, Kevin McAreavey, Weiru Liu

Time series forecasting, while vital in various applications, often employs
complex models that are difficult for humans to understand. Effective
explainable AI techniques are crucial to bridging the gap between model
predictions and user understanding. This paper presents a framework -
TSFeatLIME, extending TSLIME, tailored specifically for explaining univariate
time series forecasting. TSFeatLIME integrates an auxiliary feature into the
surrogate model and considers the pairwise Euclidean distances between the
queried time series and the generated samples to improve the fidelity of the
surrogate models. However, the usefulness of such explanations for human beings
remains an open question. We address this by conducting a user study with 160
participants through two interactive interfaces, aiming to measure how
individuals from different backgrounds can simulate or predict model output
changes in the treatment group and control group. Our results show that the
surrogate model under the TSFeatLIME framework is able to better simulate the
behaviour of the black-box considering distance, without sacrificing accuracy.
In addition, the user study suggests that the explanations were significantly
more effective for participants without a computer science background.

æè¦ï¼æéåºåé æ¸¬éç¶å¨åç¨®æç¨ä¸­è³ééè¦ï¼ä½éå¸¸æ¡ç¨äººé¡é£ä»¥çè§£çè¤éæ¨¡åãææçå¯è§£é AI æè¡å°æ¼ç¸®å°æ¨¡åé æ¸¬åä½¿ç¨èçè§£ä¹éçå·®è·è³ééè¦ãæ¬ææåºäºä¸åæ¡æ¶ - TSFeatLIMEï¼æ´å± TSLIMEï¼å°éç¨æ¼è§£éå®è®æ¸æéåºåé æ¸¬ãTSFeatLIME å°è¼å©ç¹å¾µæ´åå°æ¿ä»£æ¨¡åä¸­ï¼ä¸¦èæ®æ¥è©¢æéåºåèçææ¨£æ¬ä¹éçæå°æ­å¹¾éå¾è·é¢ï¼ä»¥æé«æ¿ä»£æ¨¡åçä¿çåº¦ãç¶èï¼æ­¤é¡è§£éå°äººé¡çæç¨æ§ä»ç¶æ¯ä¸åéæ¾çåé¡ãæåééä¸ååå« 160 ååèèçä½¿ç¨èç ç©¶ä¾è§£æ±ºéååé¡ï¼ééå©åäºåä»é¢ï¼æ¨å¨è¡¡éä¸åèæ¯çåäººå¦ä½æ¨¡æ¬æé æ¸¬æ²»ççµåå°ç§çµä¸­çæ¨¡åè¼¸åºè®åãæåççµæè¡¨æï¼TSFeatLIME æ¡æ¶ä¸çæ¿ä»£æ¨¡åè½å¤ å¨ä¸ç§ç²æºç¢ºæ§çææ³ä¸ï¼æ´å¥½å°æ¨¡æ¬é»ç®±èæ®è·é¢çè¡çºãæ­¤å¤ï¼ä½¿ç¨èç ç©¶è¡¨æï¼å°æ¼æ²æé»è¦ç§å­¸èæ¯çåèèä¾èªªï¼éäºè§£éé¡¯èå°æ´ææã

##### **Automated test generation to evaluate tool-augmented LLMs as conversational AI agents**
2409.15934v1 by Samuel Arcadinho, David Aparicio, Mariana Almeida

Tool-augmented LLMs are a promising approach to create AI agents that can
have realistic conversations, follow procedures, and call appropriate
functions. However, evaluating them is challenging due to the diversity of
possible conversations, and existing datasets focus only on single interactions
and function-calling. We present a test generation pipeline to evaluate LLMs as
conversational AI agents. Our framework uses LLMs to generate diverse tests
grounded on user-defined procedures. For that, we use intermediate graphs to
limit the LLM test generator's tendency to hallucinate content that is not
grounded on input procedures, and enforces high coverage of the possible
conversations. Additionally, we put forward ALMITA, a manually curated dataset
for evaluating AI agents in customer support, and use it to evaluate existing
LLMs. Our results show that while tool-augmented LLMs perform well in single
interactions, they often struggle to handle complete conversations. While our
focus is on customer support, our method is general and capable of AI agents
for different domains.

æè¦ï¼å·¥å·å¢å¼ºç LLM æ¯ä¸ç§å¾æåéçæ¹æ³ï¼å¯ä»¥åå»ºè½å¤è¿è¡ç°å®å¯¹è¯ãéµå¾ªç¨åºåè°ç¨éå½å½æ°ç AI ä»£çãç¶èï¼ç±äºå¯¹è¯çå¤æ ·æ§ï¼å¯¹å®ä»¬è¿è¡è¯ä¼°å·ææææ§ï¼èä¸ç°æçæ°æ®éåªå³æ³¨åä¸ªäº¤äºåå½æ°è°ç¨ãæä»¬æåºäºä¸ä¸ªæµè¯çæç®¡éï¼ä»¥è¯ä¼° LLM ä½ä¸ºä¼è¯å¼ AI ä»£çãæä»¬çæ¡æ¶ä½¿ç¨ LLM çæåºäºç¨æ·å®ä¹çç¨åºçå¤æ ·åæµè¯ãä¸ºæ­¤ï¼æä»¬ä½¿ç¨ä¸­é´å¾å½¢æ¥éå¶ LLM æµè¯çæå¨çæä¸åºäºè¾å¥ç¨åºçå¹»è§åå®¹çå¾åï¼å¹¶å¼ºå¶å¯¹å¯è½çå¯¹è¯è¿è¡é«è¦ççãæ­¤å¤ï¼æä»¬æåºäº ALMITAï¼è¿æ¯ä¸ä¸ªæå¨ç­åçæ°æ®éï¼ç¨äºè¯ä¼°å®¢æ·æ¯æä¸­ç AI ä»£çï¼å¹¶ä½¿ç¨å®æ¥è¯ä¼°ç°æç LLMãæä»¬çç»æè¡¨æï¼è½ç¶å·¥å·å¢å¼ºç LLM å¨åä¸ªäº¤äºä¸­è¡¨ç°è¯å¥½ï¼ä½å®ä»¬éå¸¸é¾ä»¥å¤çå®æ´çå¯¹è¯ãè½ç¶æä»¬çéç¹æ¯å®¢æ·æ¯æï¼ä½æä»¬çæ¹æ³æ¯éç¨çï¼å¹¶ä¸è½å¤ä¸ºä¸åé¢åç AI ä»£çæä¾æ¯æã

##### **SLIMER-IT: Zero-Shot NER on Italian Language**
2409.15933v1 by Andrew Zamai, Leonardo Rigutini, Marco Maggini, Andrea Zugarini

Traditional approaches to Named Entity Recognition (NER) frame the task into
a BIO sequence labeling problem. Although these systems often excel in the
downstream task at hand, they require extensive annotated data and struggle to
generalize to out-of-distribution input domains and unseen entity types. On the
contrary, Large Language Models (LLMs) have demonstrated strong zero-shot
capabilities. While several works address Zero-Shot NER in English, little has
been done in other languages. In this paper, we define an evaluation framework
for Zero-Shot NER, applying it to the Italian language. Furthermore, we
introduce SLIMER-IT, the Italian version of SLIMER, an instruction-tuning
approach for zero-shot NER leveraging prompts enriched with definition and
guidelines. Comparisons with other state-of-the-art models, demonstrate the
superiority of SLIMER-IT on never-seen-before entity tags.

æè¦ï¼å³çµ±å½åå¯¦é«è­å¥ (NER) æ¹æ³å°ä»»åè¨­å®çº BIO åºåæ¨ç±¤åé¡ãåç®¡éäºç³»çµ±éå¸¸å¨æéçä¸æ¸¸ä»»åä¸­è¡¨ç¾åºè²ï¼ä½å®åéè¦å¤§éçè¨»è§£è³æï¼ä¸¦ä¸é£ä»¥æ¨å»£å°åå¸å¤è¼¸å¥ç¶²ååæªè¦å¯¦é«é¡åãç¸åå°ï¼å¤§åèªè¨æ¨¡å (LLM) å·²å±ç¾å¼·å¤§çé¶æ¬¡å­¸ç¿è½åãåç®¡æå¹¾é å·¥ä½æ¢è¨è±æçé¶æ¬¡å­¸ç¿ NERï¼ä½å¶ä»èªè¨çç ç©¶å»å¾å°ãå¨æ¬æä¸­ï¼æåå®ç¾©äºé¶æ¬¡å­¸ç¿ NER çè©éæ¶æ§ï¼ä¸¦å°å¶æç¨æ¼ç¾©å¤§å©èªãæ­¤å¤ï¼æåå¼å¥äº SLIMER-ITï¼å®æ¯ SLIMER çç¾©å¤§å©èªçæ¬ï¼ä¸ç¨®ç¨æ¼é¶æ¬¡å­¸ç¿ NER çæä»¤èª¿æ´æ¹æ³ï¼å©ç¨è±å¯äºå®ç¾©åæºåçæç¤ºãèå¶ä»æåé²æ¨¡åçæ¯è¼è­æäº SLIMER-IT å¨åææªè¦çå¯¦é«æ¨ç±¤ä¸çåªè¶æ§ã

##### **Multilingual Transfer and Domain Adaptation for Low-Resource Languages of Spain**
2409.15924v1 by Yuanchang Luo, Zhanglin Wu, Daimeng Wei, Hengchao Shang, Zongyao Li, Jiaxin Guo, Zhiqiang Rao, Shaojun Li, Jinlong Yang, Yuhao Xie, Jiawei Zheng Bin Wei, Hao Yang

This article introduces the submission status of the Translation into
Low-Resource Languages of Spain task at (WMT 2024) by Huawei Translation
Service Center (HW-TSC). We participated in three translation tasks: spanish to
aragonese (es-arg), spanish to aranese (es-arn), and spanish to asturian
(es-ast). For these three translation tasks, we use training strategies such as
multilingual transfer, regularized dropout, forward translation and back
translation, labse denoising, transduction ensemble learning and other
strategies to neural machine translation (NMT) model based on training deep
transformer-big architecture. By using these enhancement strategies, our
submission achieved a competitive result in the final evaluation.

æè¦ï¼éç¯æç« ä»ç´¹äºè¯çºç¿»è­¯æåä¸­å¿ (HW-TSC) å¨ (WMT 2024) çè¥¿ç­çèªç¿»è­¯æä½è³æºèªè¨ä»»åçæäº¤çæãæååèäºä¸åç¿»è­¯ä»»åï¼è¥¿ç­çèªç¿»è­¯æäºæå²¡èª (es-arg)ãè¥¿ç­çèªç¿»è­¯æé¿è­èª (es-arn) åè¥¿ç­çèªç¿»è­¯æé¿æ¯åéäºèª (es-ast)ãå°æ¼éä¸åç¿»è­¯ä»»åï¼æåä½¿ç¨å¤èªè¨è½ç§»ãæ­£è¦åä¸­æ·ãååç¿»è­¯åååç¿»è­¯ãlabse å»åªãè½æéåå­¸ç¿ç­è¨ç·´ç­ç¥ï¼ä»¥ååºæ¼è¨ç·´æ·±åº¦è®æå¨å¤§æ¶æ§çç¥ç¶æ©å¨ç¿»è­¯ (NMT) æ¨¡åãèç±ä½¿ç¨éäºå¢å¼·ç­ç¥ï¼æåçæäº¤å¨æçµè©ä¼°ä¸­ç²å¾äºæç«¶ç­åççµæã

##### **Planning in the Dark: LLM-Symbolic Planning Pipeline without Experts**
2409.15915v1 by Sukai Huang, Nir Lipovetzky, Trevor Cohn

Large Language Models (LLMs) have shown promise in solving natural
language-described planning tasks, but their direct use often leads to
inconsistent reasoning and hallucination. While hybrid LLM-symbolic planning
pipelines have emerged as a more robust alternative, they typically require
extensive expert intervention to refine and validate generated action schemas.
It not only limits scalability but also introduces a potential for biased
interpretation, as a single expert's interpretation of ambiguous natural
language descriptions might not align with the user's actual intent. To address
this, we propose a novel approach that constructs an action schema library to
generate multiple candidates, accounting for the diverse possible
interpretations of natural language descriptions. We further introduce a
semantic validation and ranking module that automatically filter and rank the
generated schemas and plans without expert-in-the-loop. The experiments showed
our pipeline maintains superiority in planning over the direct LLM planning
approach. These findings demonstrate the feasibility of a fully automated
end-to-end LLM-symbolic planner that requires no expert intervention, opening
up the possibility for a broader audience to engage with AI planning with less
prerequisite of domain expertise.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨è§£æ±ºèªç¶èªè¨æè¿°çè¦åä»»åæ¹é¢å±ç¾äºåæ¯ï¼ä½å¶ç´æ¥ä½¿ç¨éå¸¸æå°è´ä¸ä¸è´çæ¨çåå¹»è¦ºãéç¶æ··å LLM-ç¬¦èè¦åç®¡éå·²æçºä¸ç¨®æ´å¼·å¥çæ¿ä»£æ¹æ¡ï¼ä½å®åéå¸¸éè¦å»£æ³çå°å®¶ä»å¥ä¾åªååé©è­ç¢ççåä½ç¶±è¦ãéä¸åéå¶äºå¯æ´åæ§ï¼éå¼å¥äºåå·®è§£éçå¯è½æ§ï¼å çºå®ä¸å°å®¶å°æ¨¡æ£±å©å¯çèªç¶èªè¨æè¿°çè§£éå¯è½èä½¿ç¨èçå¯¦éæåä¸ç¬¦ãçºäºè§£æ±ºéååé¡ï¼æåæåºäºä¸ç¨®æ°ç©çæ¹æ³ï¼è©²æ¹æ³æ§å»ºäºä¸ååä½ç¶±è¦åº«ï¼ä»¥ç¢çå¤ååé¸èï¼ä¸¦èæ®èªç¶èªè¨æè¿°çåç¨®å¯è½è§£éãæåé²ä¸æ­¥å¼å¥äºä¸åèªç¾©é©è­åæåæ¨¡çµï¼è©²æ¨¡çµèªåéæ¿¾åæåç¢ççç¶±è¦åè¨ç«ï¼èç¡éå°å®¶åèãå¯¦é©è¡¨æï¼æåçç®¡éå¨è¦åä¸­ä¿æäºåªæ¼ç´æ¥ LLM è¦åæ¹æ³çåªå¢ãéäºç¼ç¾è­æäºå®å¨èªååçç«¯å°ç«¯ LLM-ç¬¦èè¦åå¨çå¯è¡æ§ï¼è©²è¦åå¨ä¸éè¦å°å®¶ä»å¥ï¼éçºæ´å»£æ³çåç¾åè AI è¦åæä¾äºå¯è½æ§ï¼èç¡éå·åé åå°æ¥­ç¥è­çåæ±ºæ¢ä»¶ã

##### **Explaining word embeddings with perfect fidelity: Case study in research impact prediction**
2409.15912v1 by Lucie Dvorackova, Marcin P. Joachimiak, Michal Cerny, Adriana Kubecova, Vilem Sklenak, Tomas Kliegr

Best performing approaches for scholarly document quality prediction are
based on embedding models, which do not allow direct explanation of classifiers
as distinct words no longer correspond to the input features for model
training. Although model-agnostic explanation methods such as Local
interpretable model-agnostic explanations (LIME) can be applied, these produce
results with questionable correspondence to the ML model. We introduce a new
feature importance method, Self-model Rated Entities (SMER), for logistic
regression-based classification models trained on word embeddings. We show that
SMER has theoretically perfect fidelity with the explained model, as its
prediction corresponds exactly to the average of predictions for individual
words in the text. SMER allows us to reliably determine which words or entities
positively contribute to predicting impactful articles. Quantitative and
qualitative evaluation is performed through five diverse experiments conducted
on 50.000 research papers from the CORD-19 corpus. Through an AOPC curve
analysis, we experimentally demonstrate that SMER produces better explanations
than LIME for logistic regression.

æè¦ï¼å­¸è¡æä»¶åè³ªé æ¸¬è¡¨ç¾æä½³çæ¹æ³æ¯åºæ¼åµå¥æ¨¡åï¼éä¸åè¨±å°åé¡å¨é²è¡ç´æ¥è§£éï¼å çºä¸åçå®å­ä¸åå°ææ¼æ¨¡åè¨ç·´çè¼¸å¥ç¹å¾µãåç®¡èæ¨¡åç¡éçè§£éæ¹æ³ï¼ä¾å¦å±é¨å¯è§£éæ¨¡åç¡éè§£é (LIME)ï¼å¯ä»¥æç¨ï¼ä½éäºæ¹æ³æç¢çè ML æ¨¡åçå°æéä¿å¯çççµæãæåéå°ä»¥è©åµå¥çºåºç¤è¨ç·´çéè¼¯è¿´æ­¸åé¡æ¨¡åï¼å¼å¥ä¸ç¨®æ°çç¹å¾µéè¦æ§æ¹æ³ï¼å³èªæè©ç´å¯¦é« (SMER)ãæåè­æ SMER å¨çè«ä¸èæè§£éçæ¨¡åå·æå®ç¾çä¿çåº¦ï¼å çºå®çé æ¸¬å®å¨å°ææ¼æå­ä¸­åå¥å®å­é æ¸¬çå¹³åå¼ãSMER è®æåè½å¤ å¯é å°ç¢ºå®åªäºå®å­æå¯¦é«å°é æ¸¬æå½±é¿åçæç« ææ­£åè²¢ç»ãééå¨ CORD-19 èªæåº«ä¸­ 50,000 ç¯ç ç©¶è«æä¸é²è¡çäºé ä¸åçå¯¦é©ï¼å·è¡å®éåå®æ§è©ä¼°ãéé AOPC æ²ç·åæï¼æåå¯¦é©æ§å°è­æ SMER ç¢çæ¯ LIME æ´å¥½çéè¼¯è¿´æ­¸è§£éã

##### **A Modular-based Strategy for Mitigating Gradient Conflicts in Simultaneous Speech Translation**
2409.15911v1 by Xiaoqian Liu, Yangfan Du, Jianjin Wang, Yuan Ge, Chen Xu, Tong Xiao, Guocheng Chen, Jingbo Zhu

Simultaneous Speech Translation (SimulST) involves generating target language
text while continuously processing streaming speech input, presenting
significant real-time challenges. Multi-task learning is often employed to
enhance SimulST performance but introduces optimization conflicts between
primary and auxiliary tasks, potentially compromising overall efficiency. The
existing model-level conflict resolution methods are not well-suited for this
task which exacerbates inefficiencies and leads to high GPU memory consumption.
To address these challenges, we propose a Modular Gradient Conflict Mitigation
(MGCM) strategy that detects conflicts at a finer-grained modular level and
resolves them utilizing gradient projection. Experimental results demonstrate
that MGCM significantly improves SimulST performance, particularly under medium
and high latency conditions, achieving a 0.68 BLEU score gain in offline tasks.
Additionally, MGCM reduces GPU memory consumption by over 95\% compared to
other conflict mitigation methods, establishing it as a robust solution for
SimulST tasks.

æè¦ï¼åæ­¥èªé³ç¿»è­¯ï¼SimulSTï¼æ¶åå¨æçºèçä¸²æµèªé³è¼¸å¥æç¢çç®æ¨èªè¨ææ¬ï¼å¸¶ä¾é¡¯èçå³æææ°ãå¤ä»»åå­¸ç¿éå¸¸ç¨æ¼å¢å¼· SimulST æè½ï¼ä½æå¨ä¸»è¦ä»»ååè¼å©ä»»åä¹éç¢çæä½³åè¡çªï¼å¯è½æå®³æ´é«æçãç¾æçæ¨¡åå±¤ç´è¡çªè§£æ±ºæ¹æ³ä¸¦ä¸é©åæ­¤ä»»åï¼éæå åä½æçä¸¦å°è´é« GPU è¨æ¶é«æ¶èãçºäºæå°éäºææ°ï¼æåæåºäºä¸åæ¨¡çµåæ¢¯åº¦è¡çªç·©è§£ï¼MGCMï¼ç­ç¥ï¼å®å¯ä»¥å¨æ´ç´°ç²åº¦çæ¨¡çµå±¤ç´åµæ¸¬è¡çªï¼ä¸¦å©ç¨æ¢¯åº¦æå½±ä¾è§£æ±ºéäºè¡çªãå¯¦é©çµæè­æï¼MGCM å¤§å¹æ¹åäº SimulST æè½ï¼å°¤å¶æ¯å¨ä¸­é«å»¶é²æ¢ä»¶ä¸ï¼å¨é¢ç·ä»»åä¸­ç²å¾ 0.68 ç BLEU åæ¸å¢çãæ­¤å¤ï¼èå¶ä»è¡çªç·©è§£æ¹æ³ç¸æ¯ï¼MGCM å° GPU è¨æ¶é«æ¶èéä½äº 95% ä»¥ä¸ï¼ä½¿å¶æçº SimulST ä»»åçå¼·å¤§è§£æ±ºæ¹æ¡ã

##### **Enhancing IoT based Plant Health Monitoring through Advanced Human Plant Interaction using Large Language Models and Mobile Applications**
2409.15910v1 by Kriti Agarwal, Samhruth Ananthanarayanan, Srinitish Srinivasan, Abirami S

This paper presents the development of a novel plant communication
application that allows plants to "talk" to humans using real-time sensor data
and AI-powered language models. Utilizing soil sensors that track moisture,
temperature, and nutrient levels, the system feeds this data into the Gemini
API, where it is processed and transformed into natural language insights about
the plant's health and "mood." Developed using Flutter, Firebase, and
ThingSpeak, the app offers a seamless user experience with real-time
interaction capabilities. By fostering human-plant connectivity, this system
enhances plant care practices, promotes sustainability, and introduces
innovative applications for AI and IoT technologies in both personal and
agricultural contexts. The paper explores the technical architecture, system
integration, and broader implications of AI-driven plant communication.

æè¦ï¼æ¬æä»ç´¹äºä¸æ¬¾æ°ç©çæ¤ç©æºéæç¨ç¨å¼çéç¼ï¼å®åè¨±æ¤ç©å©ç¨å³æææ¸¬å¨è³æå AI èªè¨æ¨¡åèäººé¡ãå°è©±ããç³»çµ±å©ç¨è¿½è¹¤æ°´åãæº«åº¦åé¤åå«éçåå£¤ææ¸¬å¨ï¼å°éäºè³æè¼¸å¥ Gemini APIï¼ä¸¦å¨å¶ä¸­é²è¡èçï¼è½ææéæ¼æ¤ç©å¥åº·åãæç·ãçèªç¶èªè¨è¦è§£ãæ­¤æç¨ç¨å¼ä½¿ç¨ FlutterãFirebase å ThingSpeak éç¼ï¼æä¾èå³æäºååè½ç¡ç¸«æ¥è»çä½¿ç¨èé«é©ãééä¿é²äººèæ¤ç©çé£çµï¼æ­¤ç³»çµ±æåäºæ¤ç©ç§è­·æ¹å¼ï¼ä¿é²æ°¸çºæ§ï¼ä¸¦å¨åäººåè¾²æ¥­æå¢ä¸­å¼é²äº AI å IoT æè¡çåµæ°æç¨ãæ¬ææ¢è¨äº AI é©åçæ¤ç©æºéæè¡æ¶æ§ãç³»çµ±æ´ååæ´å»£æ³çææ¶µã

##### **Enhancing Text-to-SQL Capabilities of Large Language Models via Domain Database Knowledge Injection**
2409.15907v1 by Xingyu Ma, Xin Tian, Lingxiang Wu, Xuepeng Wang, Xueming Tang, Jinqiao Wang

Text-to-SQL is a subtask in semantic parsing that has seen rapid progress
with the evolution of Large Language Models (LLMs). However, LLMs face
challenges due to hallucination issues and a lack of domain-specific database
knowledge(such as table schema and cell values). As a result, they can make
errors in generating table names, columns, and matching values to the correct
columns in SQL statements. This paper introduces a method of knowledge
injection to enhance LLMs' ability to understand schema contents by
incorporating prior knowledge. This approach improves their performance in
Text-to-SQL tasks. Experimental results show that pre-training LLMs on
domain-specific database knowledge and fine-tuning them on downstream
Text-to-SQL tasks significantly improves the Execution Match (EX) and Exact
Match (EM) metrics across various models. This effectively reduces errors in
generating column names and matching values to the columns. Furthermore, the
knowledge-injected models can be applied to many downstream Text-to-SQL tasks,
demonstrating the generalizability of the approach presented in this paper.

æè¦ï¼ææ¬å° SQL æ¯è¯­ä¹è§£æä¸­çä¸ä¸ªå­ä»»å¡ï¼éçå¤§åè¯­è¨æ¨¡å (LLM) çåå±ï¼å®åå¾äºå¿«éè¿å±ãç¶èï¼LLM é¢ä¸´çå¹»è§é®é¢åç¼ºä¹ç¹å®äºé¢åçæ°æ®åºç¥è¯ï¼ä¾å¦è¡¨æ¨¡å¼åååæ ¼å¼ï¼çææãå æ­¤ï¼å®ä»¬å¨çæè¡¨åç§°ãååå°å¼å¹éå° SQL è¯­å¥ä¸­çæ­£ç¡®åæ¶å¯è½ä¼åºéãæ¬æä»ç»äºä¸ç§ç¥è¯æ³¨å¥æ¹æ³ï¼éè¿çº³å¥åéªç¥è¯æ¥å¢å¼º LLM çè§£æ¨¡å¼åå®¹çè½åãè¿ç§æ¹æ³æé«äºå®ä»¬å¨ææ¬å° SQL ä»»å¡ä¸­çæ§è½ãå®éªç»æè¡¨æï¼éå¯¹ç¹å®äºé¢åçæ°æ®åºç¥è¯å¯¹ LLM è¿è¡é¢è®­ç»ï¼å¹¶å¨ä¸æ¸¸ææ¬å° SQL ä»»å¡ä¸­å¯¹å®ä»¬è¿è¡å¾®è°ï¼æ¾èæé«äºåç§æ¨¡åçæ§è¡å¹é (EX) åç²¾ç¡®å¹é (EM) ææ ãè¿ææå°åå°äºå¨çæååç§°åå°å¼å¹éå°åæ¶åºç°çéè¯¯ãæ­¤å¤ï¼æ³¨å¥ç¥è¯çæ¨¡åå¯ä»¥åºç¨äºè®¸å¤ä¸æ¸¸ææ¬å° SQL ä»»å¡ï¼å±ç¤ºäºæ¬ææåºçæ¹æ³çæ³åæ§ã

##### **Boosting Code-Switching ASR with Mixture of Experts Enhanced Speech-Conditioned LLM**
2409.15905v1 by Fengrun Zhang, Wang Geng, Hukai Huang, Cheng Yi, He Qu

In this paper, we introduce a speech-conditioned Large Language Model (LLM)
integrated with a Mixture of Experts (MoE) based connector to address the
challenge of Code-Switching (CS) in Automatic Speech Recognition (ASR).
Specifically, we propose an Insertion and Deletion of Interruption Token (IDIT)
mechanism for better transfer text generation ability of LLM to speech
recognition task. We also present a connecter with MoE architecture that
manages multiple languages efficiently. To further enhance the collaboration of
multiple experts and leverage the understanding capabilities of LLM, we propose
a two-stage progressive training strategy: 1) The connector is unfrozen and
trained with language-specialized experts to map speech representations to the
text space. 2) The connector and LLM LoRA adaptor are trained with the proposed
IDIT mechanism and all experts are activated to learn general representations.
Experimental results demonstrate that our method significantly outperforms
state-of-the-art models, including end-to-end and large-scale audio-language
models.

æè¦ï¼å¨æ¬æä¸­ï¼æåä»ç´¹äºä¸åèªé³æ¢ä»¶åçå·¨éèªè¨æ¨¡å (LLM)ï¼å®èåºæ¼å°å®¶æ··å (MoE) çé£æ¥å¨æ´åï¼ä»¥è§£æ±ºèªåèªé³è­å¥ (ASR) ä¸­çä»£ç¢¼è½æ (CS) ææ°ãå·é«ä¾èªªï¼æåæåºäºä¸åä¸­æ·æ¨è¨çæå¥ååªé¤ (IDIT) æ©å¶ï¼ä»¥æé« LLM å°ææ¬çæè½åè½ç§»å°èªé³è­å¥ä»»åçè½åãæåéæåºäºä¸åå·æ MoE æ¶æ§çé£æ¥å¨ï¼å®å¯ä»¥ææå°ç®¡çå¤ç¨®èªè¨ãçºäºé²ä¸æ­¥å¢å¼·å¤åå°å®¶çåä½ä¸¦å©ç¨ LLM ççè§£è½åï¼æåæåºäºå©éæ®µæ¼¸é²å¼è¨ç·´ç­ç¥ï¼1) é£æ¥å¨è¢«è§£åä¸¦èèªè¨å°å®¶ä¸èµ·è¨ç·´ï¼ä»¥å°èªé³è¡¨ç¤ºæ å°å°ææ¬ç©ºéã2) é£æ¥å¨å LLM LoRA é©éå¨ä½¿ç¨å»ºè­°ç IDIT æ©å¶é²è¡è¨ç·´ï¼ä¸¦ä¸ææå°å®¶é½è¢«æ¿æ´»ä»¥å­¸ç¿ä¸è¬è¡¨ç¤ºãå¯¦é©çµæè¡¨æï¼æåçæ¨¡åæé¡¯åªæ¼æåé²çæ¨¡åï¼åæ¬ç«¯å°ç«¯åå¤§è¦æ¨¡é³é »èªè¨æ¨¡åã

##### **Konstruktor: A Strong Baseline for Simple Knowledge Graph Question Answering**
2409.15902v1 by Maria Lysyuk, Mikhail Salnikov, Pavel Braslavski, Alexander Panchenko

While being one of the most popular question types, simple questions such as
"Who is the author of Cinderella?", are still not completely solved.
Surprisingly, even the most powerful modern Large Language Models are prone to
errors when dealing with such questions, especially when dealing with rare
entities. At the same time, as an answer may be one hop away from the question
entity, one can try to develop a method that uses structured knowledge graphs
(KGs) to answer such questions. In this paper, we introduce Konstruktor - an
efficient and robust approach that breaks down the problem into three steps:
(i) entity extraction and entity linking, (ii) relation prediction, and (iii)
querying the knowledge graph. Our approach integrates language models and
knowledge graphs, exploiting the power of the former and the interpretability
of the latter. We experiment with two named entity recognition and entity
linking methods and several relation detection techniques. We show that for
relation detection, the most challenging step of the workflow, a combination of
relation classification/generation and ranking outperforms other methods. We
report Konstruktor's strong results on four datasets.

æè¦ï¼åç®¡æ¯æå¸¸è¦çåé¡é¡åä¹ä¸ï¼ä½è«¸å¦ãç°å§å¨çä½èæ¯èª°ï¼ãéé¡ç°¡å®çåé¡ä»æªå®å¨ç²å¾è§£ç­ãä»¤äººé©è¨çæ¯ï¼å³ä½¿æ¯æå¼·å¤§çç¾ä»£å¤§åèªè¨æ¨¡åå¨èçæ­¤é¡åé¡æä¹å®¹æåºé¯ï¼ç¹å¥æ¯å¨èçç½è¦å¯¦é«æãèæ­¤åæï¼ç±æ¼ç­æ¡å¯è½è·é¢åé¡å¯¦é«åä¸æ­¥ä¹éï¼å æ­¤å¯ä»¥åè©¦éç¼ä¸ç¨®ä½¿ç¨çµæ§åç¥è­åè­ (KG) ä¾åç­æ­¤é¡åé¡çæ¹æ³ãå¨æ¬æä¸­ï¼æåä»ç´¹ Konstruktor - ä¸ç¨®é«æä¸å¼·å¤§çæ¹æ³ï¼å®å°åé¡åè§£çºä¸åæ­¥é©ï¼(i) å¯¦é«èååå¯¦é«é£çµã(ii) éä¿é æ¸¬ä»¥å (iii) æ¥è©¢ç¥è­åè­ãæåçåæ³æ´åäºèªè¨æ¨¡ååç¥è­åè­ï¼ç¼æ®äºåèçè½ååå¾èçå¯è§£éæ§ãæåå¯¦é©äºå©ç¨®å½åå¯¦é«è­å¥åå¯¦é«é£çµæ¹æ³ä»¥åå¤ç¨®éä¿åµæ¸¬æè¡ãæåè¡¨æï¼å°æ¼éä¿åµæ¸¬ï¼ä¹å°±æ¯å·¥ä½æµç¨ä¸­æå·ææ°æ§çæ­¥é©ï¼éä¿åé¡/çæåæåç¸çµåççµååªæ¼å¶ä»æ¹æ³ãæåå ±åäº Konstruktor å¨ååè³æéä¸çå¼·åææã

##### **Symmetries and Expressive Requirements for Learning General Policies**
2409.15892v1 by Dominik Drexler, Simon StÃ¥hlberg, Blai Bonet, Hector Geffner

State symmetries play an important role in planning and generalized planning.
In the first case, state symmetries can be used to reduce the size of the
search; in the second, to reduce the size of the training set. In the case of
general planning, however, it is also critical to distinguish non-symmetric
states, i.e., states that represent non-isomorphic relational structures.
However, while the language of first-order logic distinguishes non-symmetric
states, the languages and architectures used to represent and learn general
policies do not. In particular, recent approaches for learning general policies
use state features derived from description logics or learned via graph neural
networks (GNNs) that are known to be limited by the expressive power of C_2,
first-order logic with two variables and counting. In this work, we address the
problem of detecting symmetries in planning and generalized planning and use
the results to assess the expressive requirements for learning general policies
over various planning domains. For this, we map planning states to plain
graphs, run off-the-shelf algorithms to determine whether two states are
isomorphic with respect to the goal, and run coloring algorithms to determine
if C_2 features computed logically or via GNNs distinguish non-isomorphic
states. Symmetry detection results in more effective learning, while the
failure to detect non-symmetries prevents general policies from being learned
at all in certain domains.

æè¦ï¼çæå°ç¨±æ§å¨è¦ååå»£ç¾©è¦åä¸­æ®æ¼èéè¦çè§è²ã
å¨ç¬¬ä¸ç¨®ææ³ä¸­ï¼çæå°ç¨±æ§å¯ç¨æ¼ç¸®å°æå°çè¦æ¨¡ï¼å¨ç¬¬äºç¨®ææ³ä¸­ï¼å¯ç¨æ¼ç¸®å°è¨ç·´éçè¦æ¨¡ãç¶èï¼å¨å»£ç¾©è¦åçææ³ä¸­ï¼ååéå°ç¨±çæï¼å³è¡¨ç¤ºéåæ§éä¿çµæ§ççæï¼ä¹å¾éè¦ãç¶èï¼éç¶ä¸ééè¼¯çèªè¨ååäºéå°ç¨±çæï¼ä½ç¨æ¼è¡¨ç¤ºåå­¸ç¿ä¸è¬ç­ç¥çèªè¨åæ¶æ§å»æ²æãç¹å¥æ¯ï¼æè¿ç¨æ¼å­¸ç¿ä¸è¬ç­ç¥çæ¹æ³ä½¿ç¨å¾æè¿°éè¼¯ä¸­è¡çççæç¹å¾µï¼æééåç¥ç¶ç¶²è·¯ (GNN) å­¸ç¿ï¼å·²ç¥éäºç¹å¾µåå°å·æå©åè®æ¸åè¨æ¸çä¸ééè¼¯ C_2 çè¡¨éè½åéå¶ãå¨éé å·¥ä½ä¸­ï¼æåè§£æ±ºäºå¨è¦ååå»£ç¾©è¦åä¸­æª¢æ¸¬å°ç¨±æ§çåé¡ï¼ä¸¦ä½¿ç¨çµæè©ä¼°å¨åç¨®è¦åé åä¸­å­¸ç¿ä¸è¬ç­ç¥çè¡¨ééæ±ãçºæ­¤ï¼æåå°è¦åçææ å°å°å¹³é¢åå½¢ï¼å·è¡ç¾æçæ¼ç®æ³ä¾ç¢ºå®å©åçææ¯å¦ç¸å°æ¼ç®æ¨åæ§ï¼ä¸¦å·è¡èè²æ¼ç®æ³ä¾ç¢ºå®éééè¼¯æ GNN è¨ç®ç C_2 ç¹å¾µæ¯å¦ååéåæ§çæãå°ç¨±æ§æª¢æ¸¬æå¸¶ä¾æ´ææçå­¸ç¿ï¼èç¡æ³æª¢æ¸¬éå°ç¨±æ§åæå®å¨é»æ­¢å¨æäºé åä¸­å­¸ç¿ä¸è¬ç­ç¥ã

##### **HLB: Benchmarking LLMs' Humanlikeness in Language Use**
2409.15890v1 by Xufeng Duan, Bei Xiao, Xuemei Tang, Zhenguang G. Cai

As synthetic data becomes increasingly prevalent in training language models,
particularly through generated dialogue, concerns have emerged that these
models may deviate from authentic human language patterns, potentially losing
the richness and creativity inherent in human communication. This highlights
the critical need to assess the humanlikeness of language models in real-world
language use. In this paper, we present a comprehensive humanlikeness benchmark
(HLB) evaluating 20 large language models (LLMs) using 10 psycholinguistic
experiments designed to probe core linguistic aspects, including sound, word,
syntax, semantics, and discourse (see
https://huggingface.co/spaces/XufengDuan/HumanLikeness). To anchor these
comparisons, we collected responses from over 2,000 human participants and
compared them to outputs from the LLMs in these experiments.
  For rigorous evaluation, we developed a coding algorithm that accurately
identified language use patterns, enabling the extraction of response
distributions for each task. By comparing the response distributions between
human participants and LLMs, we quantified humanlikeness through distributional
similarity. Our results reveal fine-grained differences in how well LLMs
replicate human responses across various linguistic levels. Importantly, we
found that improvements in other performance metrics did not necessarily lead
to greater humanlikeness, and in some cases, even resulted in a decline. By
introducing psycholinguistic methods to model evaluation, this benchmark offers
the first framework for systematically assessing the humanlikeness of LLMs in
language use.

æè¦ï¼é¨èåæè³æå¨è¨ç·´èªè¨æ¨¡åä¸­è®å¾è¶ä¾è¶æ®éï¼ç¹å¥æ¯ééç¢ççå°è©±ï¼äººåéå§æå¿éäºæ¨¡åå¯è½æåé¢çå¯¦çäººé¡èªè¨æ¨¡å¼ï¼æ½å¨åªå¤±äººé¡æºéä¸­åºæçè±å¯æ§ååµé åãéå¸é¡¯äºå¨ç¾å¯¦ä¸ççèªè¨ä½¿ç¨ä¸­è©ä¼°èªè¨æ¨¡åçäººé¡ç¸ä¼¼æ§çééµéæ±ãå¨æ¬æä¸­ï¼æåæåºäºä¸åå¨é¢çé¡äººåºæº (HLB)ï¼ä½¿ç¨ 10 åå¿çèªè¨å­¸å¯¦é©è©ä¼° 20 åå¤§åèªè¨æ¨¡å (LLM)ï¼éäºå¯¦é©æ¨å¨æ¢è¨æ ¸å¿èªè¨å­¸æ¹é¢ï¼åæ¬è²é³ãè©å½ãå¥æ³ãèªç¾©åèªç¯ï¼è«åé± https://huggingface.co/spaces/XufengDuan/HumanLikenessï¼ãçºäºåºå®éäºæ¯è¼ï¼æåæ¶éäºä¾èª 2,000 å¤åäººé¡åèèçåæï¼ä¸¦å¨éäºå¯¦é©ä¸­å°å®åè LLM çè¼¸åºé²è¡æ¯è¼ãçºäºé²è¡å´è¬¹çè©ä¼°ï¼æåéç¼äºä¸ç¨®ç·¨ç¢¼æ¼ç®æ³ï¼å¯ä»¥æºç¢ºè­å¥èªè¨ä½¿ç¨æ¨¡å¼ï¼å¾èè½å¤ æåæ¯åä»»åçåæåä½ãééæ¯è¼äººé¡åèèå LLM ä¹éçåæåä½ï¼æåééåä½ç¸ä¼¼æ§éåäºé¡äººåº¦ãæåççµææ­ç¤ºäº LLM å¨ä¸åèªè¨å±¤ç´è¤è£½äººé¡åæçç´°å¾®å·®ç°ãéè¦çæ¯ï¼æåç¼ç¾å¶ä»æè½ææ¨çæ¹é²ä¸¦ä¸ä¸å®æå°è´æ´é«çé¡äººåº¦ï¼å¨æäºææ³ä¸ï¼çè³æå°è´ä¸éãééå°å¿çèªè¨å­¸æ¹æ³å¼å¥æ¨¡åè©ä¼°ï¼æ­¤åºæºæä¾äºç¬¬ä¸åç³»çµ±æ§è©ä¼° LLM å¨èªè¨ä½¿ç¨ä¸­é¡äººåº¦çæ¶æ§ã

##### **Machine Translation Advancements of Low-Resource Indian Languages by Transfer Learning**
2409.15879v1 by Bin Wei, Jiawei Zhen, Zongyao Li, Zhanglin Wu, Daimeng Wei, Jiaxin Guo, Zhiqiang Rao, Shaojun Li, Yuanchang Luo, Hengchao Shang, Jinlong Yang, Yuhao Xie, Hao Yang

This paper introduces the submission by Huawei Translation Center (HW-TSC) to
the WMT24 Indian Languages Machine Translation (MT) Shared Task. To develop a
reliable machine translation system for low-resource Indian languages, we
employed two distinct knowledge transfer strategies, taking into account the
characteristics of the language scripts and the support available from existing
open-source models for Indian languages. For Assamese(as) and Manipuri(mn), we
fine-tuned the existing IndicTrans2 open-source model to enable bidirectional
translation between English and these languages. For Khasi (kh) and Mizo (mz),
We trained a multilingual model as a baseline using bilingual data from these
four language pairs, along with an additional about 8kw English-Bengali
bilingual data, all of which share certain linguistic features. This was
followed by fine-tuning to achieve bidirectional translation between English
and Khasi, as well as English and Mizo. Our transfer learning experiments
produced impressive results: 23.5 BLEU for en-as, 31.8 BLEU for en-mn, 36.2
BLEU for as-en, and 47.9 BLEU for mn-en on their respective test sets.
Similarly, the multilingual model transfer learning experiments yielded
impressive outcomes, achieving 19.7 BLEU for en-kh, 32.8 BLEU for en-mz, 16.1
BLEU for kh-en, and 33.9 BLEU for mz-en on their respective test sets. These
results not only highlight the effectiveness of transfer learning techniques
for low-resource languages but also contribute to advancing machine translation
capabilities for low-resource Indian languages.

æè¦ï¼éç¯è«æä»ç´¹äºè¯çºç¿»è­¯ä¸­å¿ (HW-TSC) æäº¤çµ¦ WMT24 å°åº¦èªè¨æ©å¨ç¿»è­¯ (MT) å±äº«ä»»åçå§å®¹ãçºäºéç¼ä¸åéå°ä½è³æºå°åº¦èªè¨çå¯é æ©å¨ç¿»è­¯ç³»çµ±ï¼æåæ¡ç¨äºå©ç¨®ä¸åçç¥è­è½ç§»ç­ç¥ï¼ä¸¦èéå°èªè¨è³æ¬çç¹æ§ä»¥åç¾æå°åº¦èªè¨éæºæ¨¡åæä¾çæ¯æ´ãå°æ¼é¿è©å§èª (as) åæ¼å°¼æ®ç¾èª (mn)ï¼æåå¾®èª¿äºç¾æç IndicTrans2 éæºæ¨¡åï¼ä»¥å¯¦ç¾è±èªåéäºèªè¨ä¹éçéåç¿»è­¯ãå°æ¼å¡è¥¿èª (kh) åç±³ä½èª (mz)ï¼æåä½¿ç¨éåç¨®èªè¨å°çéèªè³æè¨ç·´äºä¸åå¤èªè¨æ¨¡åä½çºåºæºï¼ä»¥åå¤§ç´ 8kw çè±èª-å­å æèªéèªè³æï¼ææéäºé½å·æä¸äºèªè¨ç¹å¾µãæ¥èé²è¡å¾®èª¿ï¼ä»¥å¯¦ç¾è±èªåå¡è¥¿èªä¹éçéåç¿»è­¯ï¼ä»¥åè±èªåç±³ä½èªä¹éçéåç¿»è­¯ãæåçé·ç§»å­¸ç¿å¯¦é©ç¢çäºä»¤äººå°è±¡æ·±å»ççµæï¼å¨åèªçæ¸¬è©¦éä¸­ï¼en-as ç BLEU çº 23.5ãen-mn ç BLEU çº 31.8ãas-en ç BLEU çº 36.2ï¼ä»¥å mn-en ç BLEU çº 47.9ãåæ¨£å°ï¼å¤èªè¨æ¨¡åé·ç§»å­¸ç¿å¯¦é©ä¹ç¢çäºä»¤äººå°è±¡æ·±å»çææï¼å¨åèªçæ¸¬è©¦éä¸­ï¼en-kh ç BLEU çº 19.7ãen-mz ç BLEU çº 32.8ãkh-en ç BLEU çº 16.1ï¼ä»¥å mz-en ç BLEU çº 33.9ãéäºçµæä¸åçªé¡¯äºé·ç§»å­¸ç¿æè¡å°ä½è³æºèªè¨çæææ§ï¼ä¹çºæåä½è³æºå°åº¦èªè¨çæ©å¨ç¿»è­¯è½åååºäºè²¢ç»ã

##### **Whisper in Medusa's Ear: Multi-head Efficient Decoding for Transformer-based ASR**
2409.15869v1 by Yael Segal-Feldman, Aviv Shamsian, Aviv Navon, Gill Hetz, Joseph Keshet

Large transformer-based models have significant potential for speech
transcription and translation. Their self-attention mechanisms and parallel
processing enable them to capture complex patterns and dependencies in audio
sequences. However, this potential comes with challenges, as these large and
computationally intensive models lead to slow inference speeds. Various
optimization strategies have been proposed to improve performance, including
efficient hardware utilization and algorithmic enhancements. In this paper, we
introduce Whisper-Medusa, a novel approach designed to enhance processing speed
with minimal impact on Word Error Rate (WER). The proposed model extends the
OpenAI's Whisper architecture by predicting multiple tokens per iteration,
resulting in a 50% reduction in latency. We showcase the effectiveness of
Whisper-Medusa across different learning setups and datasets.

æè¦ï¼å¤§åTransformeræ¨¡åå¨èªé³è½éåç¿»è­¯æ¹é¢å·æå·¨å¤§æ½åãå®åçèªææ³¨ææ©å¶åä¸¦è¡èçä½¿å®åè½å¤ ææé³è¨åºåä¸­çè¤éæ¨¡å¼åä¾è³´éä¿ãç¶èï¼éç¨®æ½åä¹å¸¶ä¾ææ°ï¼å çºéäºå¤§åä¸è¨ç®å¯éçæ¨¡åæå°è´ç·©æ¢çæ¨çéåº¦ãå·²ç¶æåºäºåç¨®æä½³åç­ç¥ä¾æ¹åæè½ï¼åæ¬ææççç¡¬é«å©ç¨åæ¼ç®æ³å¼·åãå¨æ¬æä¸­ï¼æåä»ç´¹äº Whisper-Medusaï¼éæ¯ä¸ç¨®æ°ç©çæ¹æ³ï¼æ¨å¨æé«èçéåº¦ï¼åæå°å­åé¯èª¤ç (WER) çå½±é¿æå°ãææåºçæ¨¡åééæ¯æ¬¡çä»£é æ¸¬å¤åä»£ç¢¼ï¼æ´åäº OpenAI ç Whisper æ¶æ§ï¼å¾èå°å»¶é²æ¸å°äº 50%ãæåå±ç¤ºäº Whisper-Medusa å¨ä¸åå­¸ç¿è¨­å®åè³æéä¸­çæææ§ã

##### **Privacy Evaluation Benchmarks for NLP Models**
2409.15868v2 by Wei Huang, Yinggui Wang, Cen Chen

By inducing privacy attacks on NLP models, attackers can obtain sensitive
information such as training data and model parameters, etc. Although
researchers have studied, in-depth, several kinds of attacks in NLP models,
they are non-systematic analyses. It lacks a comprehensive understanding of the
impact caused by the attacks. For example, we must consider which scenarios can
apply to which attacks, what the common factors are that affect the performance
of different attacks, the nature of the relationships between different
attacks, and the influence of various datasets and models on the effectiveness
of the attacks, etc. Therefore, we need a benchmark to holistically assess the
privacy risks faced by NLP models. In this paper, we present a privacy attack
and defense evaluation benchmark in the field of NLP, which includes the
conventional/small models and large language models (LLMs). This benchmark
supports a variety of models, datasets, and protocols, along with standardized
modules for comprehensive evaluation of attacks and defense strategies. Based
on the above framework, we present a study on the association between auxiliary
data from different domains and the strength of privacy attacks. And we provide
an improved attack method in this scenario with the help of Knowledge
Distillation (KD). Furthermore, we propose a chained framework for privacy
attacks. Allowing a practitioner to chain multiple attacks to achieve a
higher-level attack objective. Based on this, we provide some defense and
enhanced attack strategies. The code for reproducing the results can be found
at https://github.com/user2311717757/nlp_doctor.

æè¦ï¼<paragraph>ééå° NLP æ¨¡åç¼åé±ç§æ»æï¼æ»æèå¯ä»¥åå¾è¨ç·´è³æãæ¨¡ååæ¸ç­ææè³è¨ãåç®¡ç ç©¶äººå¡æ·±å¥ç ç©¶äº NLP æ¨¡åä¸­åç¨®æ»æï¼ä½éäºåæä¸¦éç³»çµ±æ§çãå®ç¼ºä¹å°æ»ææé æå½±é¿çå¨é¢çè§£ãä¾å¦ï¼æåå¿é èæ®åªäºå ´æ¯å¯ä»¥æç¨æ¼åªäºæ»æãå½±é¿ä¸åæ»ææè½çå±åå ç´ æ¯ä»éº¼ãä¸åæ»æä¹ééä¿çæ§è³ªä»¥ååç¨®è³æéåæ¨¡åå°æ»ææææ§çå½±é¿ç­ãå æ­¤ï¼æåéè¦ä¸ååºæºä¾å¨é¢è©ä¼° NLP æ¨¡åé¢è¨çé±ç§é¢¨éªãå¨æ¬æä¸­ï¼æåæåºäº NLP é åä¸­çé±ç§æ»æåé²ç¦¦è©ä¼°åºæºï¼å¶ä¸­åæ¬å³çµ±/å°åæ¨¡ååå¤§èªè¨æ¨¡å (LLM)ãæ­¤åºæºæ¯æ´åç¨®æ¨¡åãè³æéååå®ï¼ä»¥åç¨æ¼å¨é¢è©ä¼°æ»æåé²ç¦¦ç­ç¥çæ¨æºåæ¨¡çµãåºæ¼ä¸è¿°æ¶æ§ï¼æåæåºäºä¸é éæ¼ä¸åé åçè¼å©è³æèé±ç§æ»æå¼·åº¦ä¹ééè¯æ§çç ç©¶ãæåå¨éç¨®ææ³ä¸æä¾äºä¸ç¨®æ¹è¯çæ»ææ¹æ³ï¼ä¸¦åå©ç¥è­è¸é¤¾ (KD) ä¾é²è¡ãæ­¤å¤ï¼æåæåºäºé±ç§æ»æçéå¼æ¶æ§ãåè¨±å¾æ¥­äººå¡éæ¥å¤åæ»æä»¥éææ´é«ç´å¥çæ»æç®æ¨ãåºæ¼æ­¤ï¼æåæä¾äºä¸äºé²ç¦¦åå¢å¼·æ»æç­ç¥ãå¯ä»¥å¨ https://github.com/user2311717757/nlp_doctor ä¸­æ¾å°éç¾çµæçç¨å¼ç¢¼ã</paragraph>

##### **In-Context Ensemble Improves Video-Language Models for Low-Level Workflow Understanding from Human Demonstrations**
2409.15867v2 by Moucheng Xu, Evangelos Chatzaroulas, Luc McCutcheon, Abdul Ahad, Hamzah Azeem, Janusz Marecki, Ammar Anwar

A Standard Operating Procedure (SOP) defines a low-level, step-by-step
written guide for a business software workflow based on a video demonstration.
SOPs are a crucial step toward automating end-to-end software workflows.
Manually creating SOPs can be time-consuming. Recent advancements in large
video-language models offer the potential for automating SOP generation by
analyzing recordings of human demonstrations. However, current large
video-language models face challenges with zero-shot SOP generation. We explore
in-context learning with video-language models for SOP generation. We report
that in-context learning sometimes helps video-language models at SOP
generation. We then propose an in-context ensemble learning to further enhance
the capabilities of the models in SOP generation.

æè¦ï¼æ¨æºä½æ¥­ç¨åº (SOP) å®ç¾©äºåºæ¼å½±çç¤ºç¯çæ¥­åè»é«å·¥ä½æµç¨çä½éãéæ­¥æ¸é¢æåãSOP æ¯èªååç«¯å°ç«¯è»é«å·¥ä½æµç¨çééµæ­¥é©ãæåå»ºç« SOP å¯è½éå¸¸èæãå¤§åè¦è¨èªè¨æ¨¡åçææ°é²å±æä¾äºééåæäººé¡ç¤ºç¯çéè£½å§å®¹ä¾èªåå SOP çæçå¯è½æ§ãä½æ¯ï¼ç®åçå¤§åè¦è¨èªè¨æ¨¡åå¨é¶æ¬¡å­¸ç¿ SOP çæææéå°ææ°ãæåæ¢è¨äºä½¿ç¨è¦è¨èªè¨æ¨¡åé²è¡æå¢å§å­¸ç¿ä»¥çæ SOPãæåå ±åèªªï¼æå¢å§å­¸ç¿æææå©æ¼è¦è¨èªè¨æ¨¡åçæ SOPãç¶å¾ï¼æåæåºäºä¸ç¨®æå¢å§éæå­¸ç¿ï¼ä»¥é²ä¸æ­¥å¢å¼·æ¨¡åå¨ SOP çæä¸­çè½åã

##### **BeSimulator: A Large Language Model Powered Text-based Behavior Simulator**
2409.15865v1 by Jianan Wang, Bin Li, Xueying Wang, Fu Li, Yunlong Wu, Juan Chen, Xiaodong Yi

Traditional robot simulators focus on physical process modeling and realistic
rendering, often suffering from high computational costs, inefficiencies, and
limited adaptability. To handle this issue, we propose Behavior Simulation in
robotics to emphasize checking the behavior logic of robots and achieving
sufficient alignment between the outcome of robot actions and real scenarios.
In this paper, we introduce BeSimulator, a modular and novel LLM-powered
framework, as an attempt towards behavior simulation in the context of
text-based environments. By constructing text-based virtual environments and
performing semantic-level simulation, BeSimulator can generalize across
scenarios and achieve long-horizon complex simulation. Inspired by human
cognition processes, it employs a "consider-decide-capture-transfer"
methodology, termed Chain of Behavior Simulation, which excels at analyzing
action feasibility and state transitions. Additionally, BeSimulator
incorporates code-driven reasoning to enable arithmetic operations and enhance
reliability, as well as integrates reflective feedback to refine simulation.
Based on our manually constructed behavior-tree-based simulation benchmark
BTSIMBENCH, our experiments show a significant performance improvement in
behavior simulation compared to baselines, ranging from 14.7% to 26.6%.

æè¦ï¼å³çµ±æ©å¨äººæ¨¡æ¬å¨å°æ³¨æ¼ç©çç¨åºå»ºæ¨¡åé¼ççæ¸²æï¼éå¸¸æé¢è¨é«éç®ææ¬ãä½æçåé©ææ§æéç­åé¡ãçºäºèçéååé¡ï¼æåæåºæ©å¨äººçè¡çºæ¨¡æ¬ï¼ä»¥å¼·èª¿æª¢æ¥æ©å¨äººçè¡çºéè¼¯ï¼ä¸¦å¨æ©å¨äººåä½ççµæåçå¯¦å ´æ¯ä¹ééæååçä¸è´æ§ãå¨æ¬æä¸­ï¼æåä»ç´¹äº BeSimulatorï¼ä¸åæ¨¡çµåä¸æ°ç©ç LLM é©åæ¶æ§ï¼ä½çºå¨åºæ¼æå­çç°å¢ä¸­é²è¡è¡çºæ¨¡æ¬çåè©¦ãééå»ºæ§åºæ¼æå­çèæ¬ç°å¢ä¸¦å·è¡èªç¾©å±¤ç´çæ¨¡æ¬ï¼BeSimulator è½å¤ å¨åç¨®å ´æ¯ä¸­é²è¡æ¦åï¼ä¸¦éæé·æç¨è¤éçæ¨¡æ¬ãåå°äººé¡èªç¥éç¨çåç¼ï¼å®æ¡ç¨ãèæ®-æ±ºå®-æ·å-å³è¼¸ãçæ¹æ³ï¼ç¨±çºè¡çºæ¨¡æ¬éï¼æé·åæåä½å¯è¡æ§åçæè½æãæ­¤å¤ï¼BeSimulator çµåäºç¨å¼ç¢¼é©åçæ¨çï¼ä»¥åç¨ç®è¡éç®ä¸¦å¢å¼·å¯é æ§ï¼ä¸¦æ´ååææ§åé¥ä»¥æ¹åæ¨¡æ¬ãæ ¹ææåæåå»ºæ§çè¡çºæ¨¹çºåºç¤çæ¨¡æ¬åºæº BTSIMBENCHï¼æåçå¯¦é©é¡¯ç¤ºï¼èåºç·ç¸æ¯ï¼è¡çºæ¨¡æ¬çæè½æé¡¯èçæåï¼ç¯åå¾ 14.7% å° 26.6%ã

##### **A Zero-Shot Open-Vocabulary Pipeline for Dialogue Understanding**
2409.15861v1 by Abdulfattah Safa, GÃ¶zde GÃ¼l Åahin

Dialogue State Tracking (DST) is crucial for understanding user needs and
executing appropriate system actions in task-oriented dialogues. Majority of
existing DST methods are designed to work within predefined ontologies and
assume the availability of gold domain labels, struggling with adapting to new
slots values. While Large Language Models (LLMs)-based systems show promising
zero-shot DST performance, they either require extensive computational
resources or they underperform existing fully-trained systems, limiting their
practicality. To address these limitations, we propose a zero-shot,
open-vocabulary system that integrates domain classification and DST in a
single pipeline. Our approach includes reformulating DST as a
question-answering task for less capable models and employing self-refining
prompts for more adaptable ones. Our system does not rely on fixed slot values
defined in the ontology allowing the system to adapt dynamically. We compare
our approach with existing SOTA, and show that it provides up to 20% better
Joint Goal Accuracy (JGA) over previous methods on datasets like Multi-WOZ 2.1,
with up to 90% fewer requests to the LLM API.

æè¦ï¼å°è©±çæè¿½è¹¤ (DST) å°æ¼çè§£ä½¿ç¨èéæ±åå¨ä»»åå°åå°è©±ä¸­å·è¡é©ç¶çç³»çµ±åä½è³ééè¦ãå¤§å¤æ¸ç¾æç DST æ¹æ³é½æ¯è¨­è¨å¨é å®ç¾©çæ¬ä½ä¸­éä½ï¼ä¸¦åè¨­æé»éé åæ¨ç±¤å¯ç¨ï¼é£ä»¥é©ææ°çæ§½å¼ãéç¶åºæ¼å¤§åèªè¨æ¨¡å (LLM) çç³»çµ±é¡¯ç¤ºåºæå¸æçé¶æ¬¡å­¸ç¿ DST æè½ï¼ä½å®åéè¦å¤§éçè¨ç®è³æºææè½ä½æ¼ç¾æçå®å¨è¨ç·´ç³»çµ±ï¼éå¶äºå®åçå¯¦ç¨æ§ãçºäºè§£æ±ºéäºéå¶ï¼æåæåºäºä¸åé¶æ¬¡å­¸ç¿ãéæ¾è©å½ç³»çµ±ï¼å®å°é ååé¡å DST æ´åå¨ä¸åå®ä¸çç®¡ç·ä¸­ãæåçåæ³åæ¬å° DST éæ°è¡¨è¿°çºä¸ååé¡åç­ä»»åï¼ä»¥é©ç¨æ¼è½åè¼å¼±çæ¨¡åï¼ä¸¦æ¡ç¨èªæç²¾é²æç¤ºï¼ä»¥é©ç¨æ¼é©ææ§è¼å¼·çæ¨¡åãæåçç³»çµ±ä¸ä¾è³´æ¬ä½ä¸­å®ç¾©çåºå®æ§½å¼ï¼åè¨±ç³»çµ±åæé©æãæåå°æåçåæ³èç¾æç SOTA é²è¡æ¯è¼ï¼ä¸¦é¡¯ç¤ºå®å¨ Multi-WOZ 2.1 ç­è³æéä¸æä¾æ¯ååæ¹æ³é«é 20% çè¯åç®æ¨æºç¢ºåº¦ (JGA)ï¼å° LLM API çè«æ±æ¸å°äº 90%ã

##### **Identification For Control Based on Neural Networks: Approximately Linearizable Models**
2409.15858v1 by Maxime Thieffry, Alexandre Hache, Mohamed Yagoubi, Philippe Chevrel

This work presents a control-oriented identification scheme for efficient
control design and stability analysis of nonlinear systems. Neural networks are
used to identify a discrete-time nonlinear state-space model to approximate
time-domain input-output behavior of a nonlinear system. The network is
constructed such that the identified model is approximately linearizable by
feedback, ensuring that the control law trivially follows from the learning
stage. After the identification and quasi-linearization procedures, linear
control theory comes at hand to design robust controllers and study stability
of the closed-loop system. The effectiveness and interest of the methodology
are illustrated throughout the paper on popular benchmarks for system
identification.

æè¦ï¼æ¬ç ç©¶æåºä¸åä»¥æ§å¶çºå°åçè­å¥æ¹æ¡ï¼ç¨æ¼éç·æ§ç³»çµ±çæææ§å¶è¨­è¨åç©©å®æ§åæãç¥ç¶ç¶²è·¯ç¨æ¼è­å¥é¢æ£æééç·æ§çæç©ºéæ¨¡åï¼ä»¥é¼è¿éç·æ§ç³»çµ±çæåè¼¸å¥è¼¸åºè¡çºãç¶²è·¯çå»ºæ§æ¹å¼ä½¿å¾è­å¥åºçæ¨¡åå¯ééåé¥è¿ä¼¼ç·æ§åï¼ç¢ºä¿æ§å¶å¾å¯ä»¥è¼æå°å¾å­¸ç¿éæ®µä¸­å¾å°ãå¨è­å¥åæºç·æ§åç¨åºå¾ï¼ç·æ§æ§å¶çè«å¯ä»¥è¨­è¨åºç©©å¥çæ§å¶å¨ï¼ä¸¦ç ç©¶éè¿´è·¯ç³»çµ±çç©©å®æ§ãæ¬æèªªæäºæ­¤æ¹æ³çæææ§åè¶£å³æ§ï¼ä¸¦å¨ç³»çµ±è­å¥çç±éåºæºä¸é²è¡èªªæã

##### **iGAiVA: Integrated Generative AI and Visual Analytics in a Machine Learning Workflow for Text Classification**
2409.15848v1 by Yuanzhe Jin, Adrian Carrasco-Revilla, Min Chen

In developing machine learning (ML) models for text classification, one
common challenge is that the collected data is often not ideally distributed,
especially when new classes are introduced in response to changes of data and
tasks. In this paper, we present a solution for using visual analytics (VA) to
guide the generation of synthetic data using large language models. As VA
enables model developers to identify data-related deficiency, data synthesis
can be targeted to address such deficiency. We discuss different types of data
deficiency, describe different VA techniques for supporting their
identification, and demonstrate the effectiveness of targeted data synthesis in
improving model accuracy. In addition, we present a software tool, iGAiVA,
which maps four groups of ML tasks into four VA views, integrating generative
AI and VA into an ML workflow for developing and improving text classification
models.

æè¦ï¼å¨éç¼ç¨æ¼æå­åé¡çæ©å¨å­¸ç¿ (ML) æ¨¡åæï¼ä¸åå¸¸è¦çææ°æ¯æ¶éå°çè³æéå¸¸åä½ä¸çæ³ï¼ç¹å¥æ¯å¨éå°è³æåä»»åçè®æ´å¼å¥æ°é¡å¥æãå¨æ¬æä¸­ï¼æåæåºäºä¸åä½¿ç¨è¦è¦ºåæ (VA) ä¾å¼å°ä½¿ç¨å¤§åèªè¨æ¨¡åç¢çåæè³æçè§£æ±ºæ¹æ¡ãç±æ¼ VA è½è®æ¨¡åéç¼äººå¡è­å¥èè³æç¸éçç¼ºé·ï¼å æ­¤è³æåæå¯ä»¥éå°è§£æ±ºæ­¤é¡ç¼ºé·ãæåè¨è«äºä¸åé¡åçè³æç¼ºé·ï¼æè¿°äºç¨æ¼æ¯æ´å¶è­å¥çä¸å VA æè¡ï¼ä¸¦å±ç¤ºäºéå°æ§è³æåæå¨æ¹åæ¨¡åæºç¢ºæ§æ¹é¢çæææ§ãæ­¤å¤ï¼æåæåºäºè»é«å·¥å· iGAiVAï¼å®å°åçµ ML ä»»åå°æå°åå VA æª¢è¦ï¼å°çæå¼ AI å VA æ´åå° ML å·¥ä½æµç¨ä¸­ï¼ç¨æ¼éç¼åæ¹åæå­åé¡æ¨¡åã

##### **Adaptive Learn-then-Test: Statistically Valid and Efficient Hyperparameter Selection**
2409.15844v1 by Matteo Zecchin, Osvaldo Simeone

We introduce adaptive learn-then-test (aLTT), an efficient hyperparameter
selection procedure that provides finite-sample statistical guarantees on the
population risk of AI models. Unlike the existing learn-then-test (LTT)
technique, which relies on conventional p-value-based multiple hypothesis
testing (MHT), aLTT implements sequential data-dependent MHT with early
termination by leveraging e-processes. As a result, aLTT can reduce the number
of testing rounds, making it particularly well-suited for scenarios in which
testing is costly or presents safety risks. Apart from maintaining statistical
validity, in applications such as online policy selection for offline
reinforcement learning and hyperparameter tuning for engineering systems, aLTT
is shown to achieve the same performance as LTT while requiring only a fraction
of the testing rounds.

æè¦ï¼æåå¼é²èªé©æåå­¸ç¿åæ¸¬è©¦ (aLTT)ï¼éæ¯ä¸ç¨®ææççè¶åæ¸é¸æç¨åºï¼å¯æä¾ AI æ¨¡åæç¾¤é¢¨éªçæéæ¨£æ¬çµ±è¨ä¿è­ãèä¾è³´å³çµ±åºæ¼ p å¼çå¤éåè¨­æª¢å® (MHT) çç¾æåå­¸ç¿åæ¸¬è©¦ (LTT) æè¡ä¸åï¼aLTT ééåç¨ e ç¨åºå¯¦ä½é åºè³æä¾è³´å MHTï¼ä¸¦ææ©çµæ­¢ãå æ­¤ï¼aLTT å¯ä»¥æ¸å°æ¸¬è©¦ååæ¸ï¼ä½¿å¶ç¹å¥é©ç¨æ¼æ¸¬è©¦ææ¬é«ææå­å¨å®å¨é¢¨éªçå ´æ¯ãé¤äºç¶­æçµ±è¨æåº¦ä¹å¤ï¼å¨é¢ç·å¼·åå­¸ç¿çç·ä¸æ¿ç­é¸æåå·¥ç¨ç³»çµ±çè¶åæ¸èª¿æ´ç­æç¨ä¸­ï¼aLTT å·²è¢«è­æå¯ä»¥éæè LTT ç¸åçæè½ï¼åæåªä½¿ç¨ä¸å°é¨åçæ¸¬è©¦ååã

##### **From Passive Watching to Active Learning: Empowering Proactive Participation in Digital Classrooms with AI Video Assistant**
2409.15843v1 by Anna Bodonhelyi, Enkeleda Thaqi, SÃ¼leyman Ãzdel, Efe Bozkir, Enkelejda Kasneci

In online education, innovative tools are crucial for enhancing learning
outcomes. SAM (Study with AI Mentor) is an advanced platform that integrates
educational videos with a context-aware chat interface powered by large
language models. SAM encourages students to ask questions and explore unclear
concepts in real-time, offering personalized, context-specific assistance,
including explanations of formulas, slides, and images. In a crowdsourced user
study involving 140 participants, SAM was evaluated through pre- and
post-knowledge tests, comparing a group using SAM with a control group. The
results demonstrated that SAM users achieved greater knowledge gains, with a
96.8% answer accuracy. Participants also provided positive feedback on SAM's
usability and effectiveness. SAM's proactive approach to learning not only
enhances learning outcomes but also empowers students to take full ownership of
their educational experience, representing a promising future direction for
online learning tools.

æè¦ï¼å¨ç·ä¸æè²ä¸­ï¼åµæ°çå·¥å·å°æ¼æåå­¸ç¿ææè³ééè¦ãSAMï¼èAIå°å¸«ä¸èµ·å­¸ç¿ï¼æ¯ä¸åé²éå¹³å°ï¼å®å°æè²å½±çèç±å¤§åèªè¨æ¨¡åé©åçæå¢æç¥èå¤©ä»é¢æ´åå¨ä¸èµ·ãSAMé¼åµå­¸çæåä¸¦å³ææ¢ç´¢ä¸æ¸æ¥çæ¦å¿µï¼æä¾åäººåçãç¹å®æ¼æå¢çåå©ï¼åæ¬å¬å¼ãæå½±çåå½±åçèªªæãå¨ä¸åæ¶å140ååèèçç¾¤ç¾å¤åä½¿ç¨èç ç©¶ä¸­ï¼SAMééäºååäºå¾çç¥è­æ¸¬é©é²è¡è©ä¼°ï¼æ¯è¼ä½¿ç¨SAMççµå¥èå°ç§çµãçµæé¡¯ç¤ºï¼SAMä½¿ç¨èç²å¾äºæ´å¤§çç¥è­æ¶çï¼ç­é¡æºç¢ºåº¦çº96.8%ãåèèä¹å°SAMçå¯ç¨æ§åæææ§æä¾äºæ­£é¢çåé¥ãSAMç©æ¥µä¸»åçå­¸ç¿æ¹å¼ä¸åè½æåå­¸ç¿ææï¼éè½è®å­¸çå°èªå·±çæè²ç¶é©ææå®å¨çä¸»å°æ¬ï¼éä»£è¡¨äºç·ä¸å­¸ç¿å·¥å·ä¸åæåéçæªä¾æ¹åã

##### **Unveiling Language Competence Neurons: A Psycholinguistic Approach to Model Interpretability**
2409.15827v1 by Xufeng Duan, Xinyu Zhou, Bei Xiao, Zhenguang G. Cai

As large language models (LLMs) become advance in their linguistic capacity,
understanding how they capture aspects of language competence remains a
significant challenge. This study therefore employs psycholinguistic paradigms,
which are well-suited for probing deeper cognitive aspects of language
processing, to explore neuron-level representations in language model across
three tasks: sound-shape association, sound-gender association, and implicit
causality. Our findings indicate that while GPT-2-XL struggles with the
sound-shape task, it demonstrates human-like abilities in both sound-gender
association and implicit causality. Targeted neuron ablation and activation
manipulation reveal a crucial relationship: when GPT-2-XL displays a linguistic
ability, specific neurons correspond to that competence; conversely, the
absence of such an ability indicates a lack of specialized neurons. This study
is the first to utilize psycholinguistic experiments to investigate deep
language competence at the neuron level, providing a new level of granularity
in model interpretability and insights into the internal mechanisms driving
language ability in transformer based LLMs.

æè¦ï¼é¨èå¤§åèªè¨æ¨¡å (LLM) å¨èªè¨è½åä¸çé²æ­¥ï¼
äºè§£å®åå¦ä½ææèªè¨è½åçååé¢åä»ç¶æ¯ä¸é éå¤§çææ°ãå æ­¤ï¼æ¬ç ç©¶æ¡ç¨å¿çèªè¨å­¸ç¯ä¾ï¼
ééå¸¸é©åæ¢è¨èªè¨èççæ´æ·±å±¤èªç¥é¢åï¼ä»¥æ¢ç´¢èªè¨æ¨¡åå¨ä»¥ä¸ä¸é ä»»åä¸­çç¥ç¶åå±¤ç´è¡¨å¾µï¼é³å½¢è¯æ³ãé³æ§è¯æ³åå§é±å æéä¿ãæåçç ç©¶çµæè¡¨æï¼åç®¡ GPT-2-XL å¨é³å½¢ä»»åä¸­è¡¨ç¾ä¸ä½³ï¼ä½å¨é³æ§è¯æ³åå§é±å æéä¿ä¸­é½å±ç¾åºé¡ä¼¼äººé¡çè½åãéå°ç¥ç¶åçæ¶èåæ´»åæä½æ­ç¤ºäºä¸åééµéä¿ï¼ç¶ GPT-2-XL å±ç¾åºèªè¨è½åæï¼ç¹å®ç¥ç¶åæå°æå°è©²è½åï¼åä¹ï¼ç¼ºä¹éç¨®è½åè¡¨ç¤ºç¼ºä¹å°éçç¥ç¶åãæ¬ç ç©¶é¦æ¬¡å©ç¨å¿çèªè¨å­¸å¯¦é©ä¾æ¢è¨ç¥ç¶åå±¤ç´çæ·±åº¦èªè¨è½åï¼å¨æ¨¡åå¯è§£éæ§åè¦è§£æ¹é¢æä¾äºæ°çç´°ç·»ç¨åº¦ï¼æ·±å¥æ¢è¨äºåºæ¼ Transformer ç LLM ä¸­é©åèªè¨è½åçå§é¨æ©å¶ã

##### **Empirical Insights on Fine-Tuning Large Language Models for Question-Answering**
2409.15825v1 by Junjie Ye, Yuming Yang, Qi Zhang, Tao Gui, Xuanjing Huang, Peng Wang, Zhongchao Shi, Jianping Fan

Large language models (LLMs) encode extensive world knowledge through
pre-training on massive datasets, which can then be fine-tuned for the
question-answering (QA) task. However, effective strategies for fine-tuning
LLMs for the QA task remain largely unexplored. To address this gap, we
categorize supervised fine-tuning (SFT) data based on the extent of knowledge
memorized by the pretrained LLMs and conduct a series of empirical analyses.
Our experiments, involving four LLMs from three different model families, focus
on three key factors: the amount of data required for SFT, the impact of
different SFT datasets on model performance, and how data requirements vary
across LLMs. The results show that as few as 60 data points during the SFT
stage can activate the knowledge encoded during pre-training, enabling LLMs to
perform the QA task. Additionally, SFT with data of varying memory levels has a
significant impact on LLM performance, with the optimal dataset differing based
on the specific model being fine-tuned. Future research will delve deeper into
the mechanisms underlying these phenomena.

æè¦ï¼å¤§åèªè¨æ¨¡åï¼LLMï¼ééå¤§éè³æéçé è¨ç·´ç·¨ç¢¼å»£æ³çä¸çç¥è­ï¼ç¶å¾å¯ä»¥éå°åç­ï¼QAï¼ä»»åé²è¡å¾®èª¿ãç¶èï¼éå° QA ä»»åå¾®èª¿ LLM çææç­ç¥å¨å¾å¤§ç¨åº¦ä¸ä»æªæ¢ç´¢ãçºäºè§£æ±ºéåå·®è·ï¼æåæ ¹æé è¨ç·´ LLM è¨æ¶çç¥è­ç¨åº¦å°ç£ç£å¼å¾®èª¿ï¼SFTï¼è³æé²è¡åé¡ï¼ä¸¦é²è¡ä¸ç³»åå¯¦è­åæãæåçå¯¦é©æ¶åä¾èªä¸åä¸åæ¨¡åå®¶æçåå LLMï¼éé»éæ³¨ä¸åééµå ç´ ï¼SFT æéçè³æéãä¸å SFT è³æéå°æ¨¡åæè½çå½±é¿ï¼ä»¥åè³æéæ±å¦ä½å  LLM èç°ãçµæé¡¯ç¤ºï¼å¨ SFT éæ®µä¸­ï¼åªè¦ 60 åè³æé»å°±è½ååé è¨ç·´æéç·¨ç¢¼çç¥è­ï¼è® LLM è½å·è¡ QA ä»»åãæ­¤å¤ï¼ä½¿ç¨å·æä¸åè¨æ¶å±¤ç´è³æç SFT å° LLM æè½æé¡¯èå½±é¿ï¼æä½³è³æéææ ¹æè¦å¾®èª¿çç¹å®æ¨¡åèææä¸åãæªä¾çç ç©¶å°æ·±å¥æ¢è¨éäºç¾è±¡èå¾çæ©å¶ã

##### **Supervised Fine-Tuning: An Activation Pattern Optimization Process for Attention Heads**
2409.15820v1 by Yang Zhao, Li Du, Xiao Ding, Kai Xiong, Ting Liu, Bing Qin

Though demonstrating promising potential, LLMs' performance on complex tasks,
such as advanced mathematics and complex disease diagnosis is still
unsatisfactory. A key issue is the present LLMs learn in a data-driven schema,
while the instruction dataset about these complex tasks is both scarce and hard
to collect or construct. On the contrary, a prominent phenomenon is that LLMs
can learn rather fast on those simpler tasks with adequate prior knowledge
captured during pretraining stage. Thus, if the prerequisite and mechanism of
such rapid generalization could be elucidated, it could be highly beneficial in
enhancing the efficiency and effectiveness of the LLM's ability to learn
complex tasks. Thus, in this paper, we employ a gradient-based method, to
dissect the process that the SFT process adapts LLMs to downstream tasks via
the perspective of attention patterns. We find that: (1) LLMs selectively
activate task-specific attention heads during SFT; (2) activation patterns for
complex tasks are combinations of basic task patterns; and (3) changes in a few
parameters can significantly impact activation patterns after SFT on a small
number of samples. Based on these insights, we conduct experiments to examine
whether these conclusions could effectively enhance the efficiency and
effectiveness of SFT, particularly in handling complex tasks and when
instructional resources are scarce. Our research not only uncovers the
underlying reasons behind LLMs' rapid learning and generalization mechanisms
but also provides practical solutions for addressing data challenges in complex
and specialized tasks.

æè¦ï¼åç®¡å±ç¤ºäºæå¸æçæ½åï¼ä½ LLM å¨è¤éä»»åä¸çè¡¨ç¾ï¼ä¾å¦é²éæ¸å­¸åè¤éç¾çè¨ºæ·ï¼ä»ç¶ä¸ä»¤äººæ»¿æãä¸åééµåé¡æ¯ç®åç LLM ä»¥è³æé©åçæ¨¡å¼å­¸ç¿ï¼èéæ¼éäºè¤éä»»åçæä»¤è³æéæ¢ç¨å°åé£ä»¥æ¶éæå»ºæ§ãç¸åï¼ä¸åé¡¯èçç¾è±¡æ¯ï¼LLM è½å¨é è¨ç·´éæ®µæ·åçè¶³å¤ ååç¥è­ä¸ï¼å¨é£äºè¼ç°¡å®çä»»åä¸å¿«éå­¸ç¿ãå æ­¤ï¼å¦æå¯ä»¥é¡æéç¨®å¿«éæ¦åçåææ¢ä»¶åæ©å¶ï¼å®å¯è½å°æé« LLM å­¸ç¿è¤éä»»åçè½åçæçåæææ§å¤§æå¹«å©ãå æ­¤ï¼å¨æ¬æä¸­ï¼æåæ¡ç¨åºæ¼æ¢¯åº¦ççæ¹æ³ï¼å¾æ³¨æåæ¨¡å¼çè§åº¦åæ SFT éç¨é©æ LLM å°ä¸æ¸¸ä»»åçéç¨ãæåç¼ç¾ï¼(1) LLM å¨ SFT æéé¸ææ§å°ååç¹å®æ¼ä»»åçæ³¨æåé ­ï¼(2) è¤éä»»åçååæ¨¡å¼æ¯åºæ¬ä»»åæ¨¡å¼ççµåï¼(3) å°æ¸åæ¸çè®åæé¡¯èå½±é¿ SFT å¾å¨å°æ¸æ¨£æ¬ä¸çååæ¨¡å¼ãåºæ¼éäºè¦è§£ï¼æåé²è¡å¯¦é©ä»¥æª¢é©éäºçµè«æ¯å¦è½æææé« SFT çæçåæææ§ï¼ç¹å¥æ¯å¨èçè¤éä»»ååæä»¤è³æºç¨ç¼ºæãæåçç ç©¶ä¸åæ­ç¤ºäº LLM å¿«éå­¸ç¿åæ¦åæ©å¶èå¾çåºæ¬åå ï¼éçºè§£æ±ºè¤éåå°æ¥­ä»»åä¸­çè³æææ°æä¾äºå¯¦ç¨çè§£æ±ºæ¹æ¡ã

##### **SwiftDossier: Tailored Automatic Dossier for Drug Discovery with LLMs and Agents**
2409.15817v1 by Gabriele Fossi, Youssef Boulaimen, Leila Outemzabet, Nathalie Jeanray, Stephane Gerart, Sebastien Vachenc, Joanna Giemza, Salvatore Raieli

The advancement of artificial intelligence algorithms has expanded their
application to several fields such as the biomedical domain. Artificial
intelligence systems, including Large Language Models (LLMs), can be
particularly advantageous in drug discovery, which is a very long and expensive
process. However, LLMs by themselves lack in-depth knowledge about specific
domains and can generate factually incorrect information. Moreover, they are
not able to perform more complex actions that imply the usage of external
tools. Our work is focused on these two issues. Firstly, we show how the
implementation of an advanced RAG system can help the LLM to generate more
accurate answers to drug-discovery-related questions. The results show that the
answers generated by the LLM with the RAG system surpass in quality the answers
produced by the model without RAG. Secondly, we show how to create an automatic
target dossier using LLMs and incorporating them with external tools that they
can use to execute more intricate tasks to gather data such as accessing
databases and executing code. The result is a production-ready target dossier
containing the acquired information summarized into a PDF and a PowerPoint
presentation.

æè¦ï¼äººå·¥æºæ§æ¼ç®æ³çé²æ­¥æ´å±äºå®åå¨çç©é«å­¸é åç­å¤åé åçæç¨ãäººå·¥æºæ§ç³»çµ±ï¼åæ¬å¤§åèªè¨æ¨¡å (LLM)ï¼å¨è¥ç©ç¼ç¾æ¹é¢ç¹å¥æå©ï¼èéæ¯ä¸åéå¸¸æ¼«é·ä¸æè²´çéç¨ãç¶èï¼LLM æ¬èº«ç¼ºä¹ç¹å®é åçæ·±å¥ç¥è­ï¼ä¸¦ä¸å¯è½æç¢çäºå¯¦ä¸æ­£ç¢ºçè³è¨ãæ­¤å¤ï¼å®åç¡æ³å·è¡æ´è¤éçåä½ï¼éæå³èä½¿ç¨å¤é¨å·¥å·ãæåçç ç©¶éé»å¨æ¼éå©ååé¡ãé¦åï¼æåå±ç¤ºäºé²é RAG ç³»çµ±çå¯¦ä½å¦ä½åå© LLM ç¢çæ´æºç¢ºçç­æ¡ä¾åç­èè¥ç©ç¼ç¾ç¸éçåé¡ãçµæé¡¯ç¤ºï¼ä½¿ç¨ RAG ç³»çµ±ç LLM æç¢ççç­æ¡åè³ªè¶è¶äºæ²æ RAG çæ¨¡åæç¢ççç­æ¡ãå¶æ¬¡ï¼æåå±ç¤ºäºå¦ä½ä½¿ç¨ LLM å»ºç«èªååç®æ¨æªæ¡ï¼ä¸¦å°å®åèå¤é¨å·¥å·æ´åï¼ä»¥ä¾¿å®åè½å¤ å·è¡æ´è¤éçä»»åä¾æ¶éè³æï¼ä¾å¦å­åè³æåº«åå·è¡ç¨å¼ç¢¼ãçµææ¯ä¸åå¯ä¾çç¢ä½¿ç¨çç®æ¨æªæ¡ï¼å¶ä¸­åå«åå¾çè³è¨ï¼ä¸¦æè¦æ PDF å PowerPoint ç°¡å ±ã

##### **AsthmaBot: Multi-modal, Multi-Lingual Retrieval Augmented Generation For Asthma Patient Support**
2409.15815v1 by Adil Bahaj, Mounir Ghogho

Asthma rates have risen globally, driven by environmental and lifestyle
factors. Access to immediate medical care is limited, particularly in
developing countries, necessitating automated support systems. Large Language
Models like ChatGPT (Chat Generative Pre-trained Transformer) and Gemini have
advanced natural language processing in general and question answering in
particular, however, they are prone to producing factually incorrect responses
(i.e. hallucinations). Retrieval-augmented generation systems, integrating
curated documents, can improve large language models' performance and reduce
the incidence of hallucination. We introduce AsthmaBot, a multi-lingual,
multi-modal retrieval-augmented generation system for asthma support.
Evaluation of an asthma-related frequently asked questions dataset shows
AsthmaBot's efficacy. AsthmaBot has an added interactive and intuitive
interface that integrates different data modalities (text, images, videos) to
make it accessible to the larger public. AsthmaBot is available online via
\url{asthmabot.datanets.org}.

æè¦ï¼æ°£åç¼ççå¨å¨çä¸åï¼åå å¨æ¼ç°å¢åçæ´»æ¹å¼çå ç´ ãç«å³ç²å¾é«çç§è­·çç®¡éæéï¼ç¹å¥æ¯å¨éç¼ä¸­åå®¶ï¼éä½¿å¾èªååæ¯æ´ç³»çµ±è®å¾å¿è¦ãå¤§åèªè¨æ¨¡åï¼ä¾å¦ ChatGPTï¼Chat Generative Pre-trained Transformerï¼å Geminiï¼å·²æåä¸è¬èªç¶èªè¨èçåç¹å¥æ¯åç­çé²å±ï¼ç¶èï¼å®åå®¹æç¢çäºå¯¦ä¸ä¸æ­£ç¢ºçåæï¼å³å¹»è¦ºï¼ãæ·åå¢å¼·çæç³»çµ±ï¼æ´åç­å±æä»¶ï¼å¯ä»¥æåå¤§åèªè¨æ¨¡åçæè½ä¸¦æ¸å°å¹»è¦ºç¼ççæ©çãæåä»ç´¹ AsthmaBotï¼ä¸åå¤èªè¨ãå¤æ¨¡ææ·åå¢å¼·çæç³»çµ±ï¼ç¨æ¼æ°£åæ¯æ´ãè©ä¼°èæ°£åç¸éçå¸¸è¦åé¡è³æéé¡¯ç¤º AsthmaBot çæè½ãAsthmaBot æä¸åé¡å¤çäºåä¸ç´è¦ºçä»é¢ï¼å®æ´åä¸åçè³ææ¨¡å¼ï¼æå­ãåçãå½±çï¼ï¼ä½¿å¶è½è®æ´å¤å¤§ç¾ä½¿ç¨ãAsthmaBot å¯éé \url{asthmabot.datanets.org} ç·ä¸åå¾ã

##### **Interactive Example-based Explanations to Improve Health Professionals' Onboarding with AI for Human-AI Collaborative Decision Making**
2409.15814v1 by Min Hun Lee, Renee Bao Xuan Ng, Silvana Xinyi Choo, Shamala Thilarajah

A growing research explores the usage of AI explanations on user's decision
phases for human-AI collaborative decision-making. However, previous studies
found the issues of overreliance on `wrong' AI outputs. In this paper, we
propose interactive example-based explanations to improve health professionals'
onboarding with AI for their better reliance on AI during AI-assisted
decision-making. We implemented an AI-based decision support system that
utilizes a neural network to assess the quality of post-stroke survivors'
exercises and interactive example-based explanations that systematically
surface the nearest neighborhoods of a test/task sample from the training set
of the AI model to assist users' onboarding with the AI model. To investigate
the effect of interactive example-based explanations, we conducted a study with
domain experts, health professionals to evaluate their performance and reliance
on AI. Our interactive example-based explanations during onboarding assisted
health professionals in having a better reliance on AI and making a higher
ratio of making `right' decisions and a lower ratio of `wrong' decisions than
providing only feature-based explanations during the decision-support phase.
Our study discusses new challenges of assisting user's onboarding with AI for
human-AI collaborative decision-making.

æè¦ï¼è¶ä¾è¶å¤ç ç©¶æ¢è¨å¨äººé¡è AI åä½æ±ºç­æï¼ä½¿ç¨ AI è§£éå°ä½¿ç¨èæ±ºç­éæ®µçå½±é¿ãç¶èï¼ååçç ç©¶ç¼ç¾éåº¦ä¾è³´ãé¯èª¤ãç AI è¼¸åºçåé¡ãå¨æ¬æä¸­ï¼æåæåºäºåå¼ç¯ä¾çºåºç¤çè§£éï¼ä»¥æ¹åé«çå°æ¥­äººå¡è AI çæ´åï¼è®ä»åå¨ AI è¼å©æ±ºç­æè½æ´ä¾è³´ AIãæåå¯¦ä½äºä¸ååºæ¼ AI çæ±ºç­æ¯æ´ç³»çµ±ï¼å®å©ç¨ç¥ç¶ç¶²è·¯è©ä¼°ä¸­é¢¨å¾åå­èéåçåè³ªï¼ä¸¦å©ç¨äºåå¼ç¯ä¾çºåºç¤çè§£éï¼ç³»çµ±æ§å°å¾ AI æ¨¡åçè¨ç·´éä¸­æ¾åºæ¸¬è©¦/ä»»åç¯ä¾æè¿çé°åï¼ä»¥åå©ä½¿ç¨èè AI æ¨¡åæ´åãçºäºæ¢è¨äºåå¼ç¯ä¾çºåºç¤çè§£éçææï¼æåé²è¡äºä¸é ç ç©¶ï¼æ¾ä¾é åå°å®¶åé«çå°æ¥­äººå¡è©ä¼°ä»åçè¡¨ç¾èå° AI çä¾è³´ãæåå¨æ´åæéæä¾çäºåå¼ç¯ä¾çºåºç¤çè§£éï¼åå©é«çå°æ¥­äººå¡æ´ä¾è³´ AIï¼ä¸¦ä¸å¨æ±ºç­æ¯æ´éæ®µä¸­ååºãæ­£ç¢ºãæ±ºç­çæ¯çè¼é«ï¼èååºãé¯èª¤ãæ±ºç­çæ¯çè¼ä½ï¼åªæ¼åªæä¾åºæ¼ç¹å¾µçè§£éãæåçç ç©¶æ¢è¨äºå¨äººé¡è AI åä½æ±ºç­æï¼åå©ä½¿ç¨èè AI æ´åçæ°ææ°ã

##### **Layer-wise Model Merging for Unsupervised Domain Adaptation in Segmentation Tasks**
2409.15813v1 by Roberto Alcover-Couso, Juan C. SanMiguel, Marcos Escudero-ViÃ±olo, Jose M MartÃ­nez

Merging parameters of multiple models has resurfaced as an effective strategy
to enhance task performance and robustness, but prior work is limited by the
high costs of ensemble creation and inference. In this paper, we leverage the
abundance of freely accessible trained models to introduce a cost-free approach
to model merging. It focuses on a layer-wise integration of merged models,
aiming to maintain the distinctiveness of the task-specific final layers while
unifying the initial layers, which are primarily associated with feature
extraction. This approach ensures parameter consistency across all layers,
essential for boosting performance. Moreover, it facilitates seamless
integration of knowledge, enabling effective merging of models from different
datasets and tasks. Specifically, we investigate its applicability in
Unsupervised Domain Adaptation (UDA), an unexplored area for model merging, for
Semantic and Panoptic Segmentation. Experimental results demonstrate
substantial UDA improvements without additional costs for merging
same-architecture models from distinct datasets ($\uparrow 2.6\%$ mIoU) and
different-architecture models with a shared backbone ($\uparrow 6.8\%$ mIoU).
Furthermore, merging Semantic and Panoptic Segmentation models increases mPQ by
$\uparrow 7\%$. These findings are validated across a wide variety of UDA
strategies, architectures, and datasets.

æè¦ï¼<paragraph>åä½µå¤åæ¨¡åçåæ¸å·²éæ°æµ®ç¾çºä¸ç¨®ææçç­ç¥ï¼ç¨ä»¥æåä»»åæè½èç©©å¥æ§ï¼ä½ååçç ç©¶åéæ¼æ´é«å»ºç«èæ¨è«çé«ææ¬ãå¨æ¬æä¸­ï¼æåå©ç¨å¤§éåè²»åå¾çå·²è¨ç·´æ¨¡åï¼å°å¥ä¸ç¨®ç¡ææ¬çæ¨¡ååä½µæ¹æ³ãå®å°æ³¨æ¼åä½µæ¨¡åçéå±¤æ´åï¼ç®æ¨å¨æ¼ç¶­æç¹å®ä»»åçæçµå±¤çç¨ç¹æ§ï¼åæçµ±ä¸æåçå±¤ï¼éäºå±¤ä¸»è¦èç¹å¾µèåç¸éãéç¨®æ¹æ³ç¢ºä¿ææå±¤çåæ¸ä¸è´æ§ï¼éå°æ¼æåæè½è³ééè¦ãæ­¤å¤ï¼å®ä¿é²ç¥è­çç¡ç¸«æ´åï¼è®ä¾èªä¸åè³æéåä»»åçæ¨¡åå¾ä»¥ææåä½µãå·é«ä¾èªªï¼æåæ¢è¨å¶å¨æ¨¡ååä½µçæªæ¢ç´¢é åä¸­ç¨æ¼ç¡ç£ç£åé©æ (UDA) çé©ç¨æ§ï¼ä»¥é²è¡èªç¾©åå¨æ¯åå²ãå¯¦é©çµæé¡¯ç¤ºï¼å¨ä¸å¢å åä½µææ¬çææ³ä¸ï¼å¤§å¹æ¹å UDAï¼åæ¬ä¾èªä¸åè³æéçç¸åæ¶æ§æ¨¡åï¼mIoU æå 2.6%ï¼åå·æå±ç¨ä¸»å¹¹çä¸åæ¶æ§æ¨¡åï¼mIoU æå 6.8%ï¼ãæ­¤å¤ï¼åä½µèªç¾©åå¨æ¯åå²æ¨¡åå° mPQ æå 7%ãéäºç¼ç¾å·²ééåç¨® UDA ç­ç¥ãæ¶æ§åè³æéé©è­ã</paragraph>

##### **CLSP: High-Fidelity Contrastive Language-State Pre-training for Agent State Representation**
2409.15806v1 by Fuxian Huang, Qi Zhang, Shaopeng Zhai, Jie Wang, Tianyi Zhang, Haoran Zhang, Ming Zhou, Yu Liu, Yu Qiao

With the rapid development of artificial intelligence, multimodal learning
has become an important research area. For intelligent agents, the state is a
crucial modality to convey precise information alongside common modalities like
images, videos, and language. This becomes especially clear with the broad
adoption of reinforcement learning and multimodal large language models.
Nevertheless, the representation of state modality still lags in development.
To this end, we propose a High-Fidelity Contrastive Language-State Pre-training
(CLSP) method, which can accurately encode state information into general
representations for both reinforcement learning and multimodal large language
models. Specifically, we first design a pre-training task based on the
classification to train an encoder with coarse-grained information. Next, we
construct data pairs of states and language descriptions, utilizing the
pre-trained encoder to initialize the CLSP encoder. Then, we deploy contrastive
learning to train the CLSP encoder to effectively represent precise state
information. Additionally, we enhance the representation of numerical
information using the Random Fourier Features (RFF) method for high-fidelity
mapping. Extensive experiments demonstrate the superior precision and
generalization capabilities of our representation, achieving outstanding
results in text-state retrieval, reinforcement learning navigation tasks, and
multimodal large language model understanding.

æè¦ï¼é¨èäººå·¥æºæ§çå¿«éç¼å±ï¼å¤æ¨¡æå­¸ç¿å·²æçºéè¦çç ç©¶é åãå°æ¼æºæ§åä»£çèè¨ï¼çææ¯ä¸ç¨®è³ééè¦çæ¨¡æï¼å¯ç¨æ¼å³éç²¾ç¢ºçè³è¨ï¼ä»¥åå½±åãå½±çåèªè¨ç­å¸¸è¦æ¨¡æãéå¨å»£æ³æ¡ç¨å¼·åå­¸ç¿åå¤æ¨¡æå¤§åèªè¨æ¨¡åçææ³ä¸å°¤å¶æé¡¯ãåç®¡å¦æ­¤ï¼çææ¨¡æçè¡¨ç¤ºå½¢å¼å¨ç¼å±ä¸ä»è½å¾ãçºæ­¤ï¼æåæåºäºä¸ç¨®é«ä¿çå°æ¯èªè¨çæé è¨ç·´ (CLSP) æ¹æ³ï¼å¯ä»¥å°çæè³è¨æºç¢ºç·¨ç¢¼æä¸è¬è¡¨ç¤ºï¼ä»¥ç¨æ¼å¼·åå­¸ç¿åå¤æ¨¡æå¤§åèªè¨æ¨¡åãå·é«ä¾èªªï¼æåé¦åè¨­è¨ä¸ååºæ¼åé¡çé è¨ç·´ä»»åï¼ä»¥è¨ç·´ä¸åå·æç²ç²åº¦è³è¨çç·¨ç¢¼å¨ãæ¥ä¸ä¾ï¼æåå»ºæ§çæåèªè¨æè¿°çè³æå°ï¼å©ç¨é è¨ç·´çç·¨ç¢¼å¨åå§å CLSP ç·¨ç¢¼å¨ãç¶å¾ï¼æåé¨ç½²å°æ¯å­¸ç¿ä¾è¨ç·´ CLSP ç·¨ç¢¼å¨ï¼ä»¥ææè¡¨ç¤ºç²¾ç¢ºççæè³è¨ãæ­¤å¤ï¼æåä½¿ç¨é¨æ©åç«èç¹å¾µ (RFF) æ¹æ³å¢å¼·æ¸å¼è³è¨çè¡¨ç¤ºï¼ä»¥é²è¡é«ä¿çæ å°ãå¤§éçå¯¦é©è­æäºæåè¡¨ç¤ºå½¢å¼çåªç°ç²¾ç¢ºåº¦åæ¦æ¬è½åï¼å¨æå­çææª¢ç´¢ãå¼·åå­¸ç¿å°èªä»»ååå¤æ¨¡æå¤§åèªè¨æ¨¡åçè§£æ¹é¢åå¾äºååºçææã

##### **NER-Luxury: Named entity recognition for the fashion and luxury domain**
2409.15804v1 by Akim Mousterou

In this study, we address multiple challenges of developing a named-entity
recognition model in English for the fashion and luxury industry, namely the
entity disambiguation, French technical jargon in multiple sub-sectors,
scarcity of the ESG methodology, and a disparate company structures of the
sector with small and medium-sized luxury houses to large conglomerate
leveraging economy of scale.
  In this work, we introduce a taxonomy of 36+ entity types with a
luxury-oriented annotation scheme, and create a dataset of more than 40K
sentences respecting a clear hierarchical classification. We also present five
supervised fine-tuned models NER-Luxury for fashion, beauty, watches, jewelry,
fragrances, cosmetics, and overall luxury, focusing equally on the aesthetic
side and the quantitative side.
  In an additional experiment, we compare in a quantitative empirical
assessment of the NER performance of our models against the state-of-the-art
open-source large language models that show promising results and highlights
the benefits of incorporating a bespoke NER model in existing machine learning
pipelines.

æè¦ï¼å¨æ¬æ¬¡ç ç©¶ä¸­ï¼æä»¬è§£å³äºéå¯¹æ¶å°åå¥¢ä¾åè¡ä¸ä»¥è±è¯­å¼åå½åå®ä½è¯å«æ¨¡åçå¤é¡¹ææï¼å³å®ä½æ¶æ­§ãå¤ä¸ªå­è¡ä¸çæ³è¯­ææ¯æ¯è¯­ãESG æ¹æ³è®ºçç¨ç¼ºæ§ä»¥åè¯¥è¡ä¸ä¸­ä»å°ååä¸­åå¥¢ä¾åå¬å¸å°å©ç¨è§æ¨¡ç»æµçå¤§åéå¢çå·®å¼åå¬å¸ç»æã
å¨è¿é¡¹å·¥ä½ä¸­ï¼æä»¬å¼å¥äºä¸ä¸ªåå« 36+ ç§å®ä½ç±»åçåç±»æ³ï¼å¹¶éç¨ä»¥å¥¢ä¾åä¸ºå¯¼åçæ³¨éæ¹æ¡ï¼åå»ºäºä¸ä¸ªåå«è¶è¿ 40K ä¸ªå¥å­çæ°æ®éï¼è¿äºå¥å­éµå¾ªæ¸æ°çåå±åç±»ãæä»¬è¿å±ç¤ºäºäºä¸ªéå¯¹æ¶å°ãç¾å®¹ãæè¡¨ãç å®ãé¦æ°´ãåå¦ååæ´ä½å¥¢ä¾åçç»è¿çç£çå¾®è°æ¨¡å NER-Luxuryï¼è¿äºæ¨¡ååæ ·æ³¨éç¾å­¦æ¹é¢åå®éæ¹é¢ã
å¨éå å®éªä¸­ï¼æä»¬å¯¹æ¨¡åç NER æ§è½è¿è¡äºå®éç»éªè¯ä¼°ï¼å¹¶å°å¶ä¸æ¾ç¤ºåºæå¸æçç»æçææ°å¼æºå¤§åè¯­è¨æ¨¡åè¿è¡äºæ¯è¾ï¼å¹¶çªåºäºå¨ç°ææºå¨å­¦ä¹ ç®¡éä¸­åå¹¶å®å¶ NER æ¨¡åçå¥½å¤ã

##### **Towards Universal Large-Scale Foundational Model for Natural Gas Demand Forecasting**
2409.15794v1 by Xinxing Zhou, Jiaqi Ye, Shubao Zhao, Ming Jin, Zhaoxiang Hou, Chengyi Yang, Zengxiang Li, Yanlong Wen, Xiaojie Yuan

In the context of global energy strategy, accurate natural gas demand
forecasting is crucial for ensuring efficient resource allocation and
operational planning. Traditional forecasting methods struggle to cope with the
growing complexity and variability of gas consumption patterns across diverse
industries and commercial sectors. To address these challenges, we propose the
first foundation model specifically tailored for natural gas demand
forecasting. Foundation models, known for their ability to generalize across
tasks and datasets, offer a robust solution to the limitations of traditional
methods, such as the need for separate models for different customer segments
and their limited generalization capabilities. Our approach leverages
contrastive learning to improve prediction accuracy in real-world scenarios,
particularly by tackling issues such as noise in historical consumption data
and the potential misclassification of similar data samples, which can lead to
degradation in the quaility of the representation and thus the accuracy of
downstream forecasting tasks. By integrating advanced noise filtering
techniques within the contrastive learning framework, our model enhances the
quality of learned representations, leading to more accurate predictions.
Furthermore, the model undergoes industry-specific fine-tuning during
pretraining, enabling it to better capture the unique characteristics of gas
consumption across various sectors. We conducted extensive experiments using a
large-scale dataset from ENN Group, which includes data from over 10,000
industrial, commercial, and welfare-related customers across multiple regions.
Our model outperformed existing state-of-the-art methods, demonstrating a
relative improvement in MSE by 3.68\% and in MASE by 6.15\% compared to the
best available model.

æè¦ï¼å¨å¨çè½æºç­ç¥çèçµ¡ä¸ï¼æºç¢ºçå¤©ç¶æ°£éæ±é æ¸¬å°æ¼ç¢ºä¿ææççè³æºéç½®åçéè¨ç«è³ééè¦ãå³çµ±çé æ¸¬æ¹æ³é£ä»¥æå°ä¸åç¢æ¥­ååæ¥­é¨éä¸­å¤©ç¶æ°£æ¶è²»æ¨¡å¼æ¥çå¢é·ä¸å¤è®çè¤éæ§ãçºäºæå°éäºææ°ï¼æåæåºäºç¬¬ä¸åå°ééå°å¤©ç¶æ°£éæ±é æ¸¬éèº«æé çåºç¤æ¨¡åãåºç¤æ¨¡åä»¥å¶è·¨ä»»ååè³æéçæ³åè½åèèåï¼çºå³çµ±æ¹æ³çéå¶æä¾äºå¼·å¥çè§£æ±ºæ¹æ¡ï¼ä¾å¦éè¦éå°ä¸åçå®¢æ¶åéå»ºç«åå¥æ¨¡åä»¥åå®åæéçæ³åè½åãæåçåæ³å©ç¨å°æ¯å­¸ç¿ä¾æåå¯¦éæå¢ä¸­çé æ¸¬æºç¢ºåº¦ï¼ç¹å¥æ¯ééè§£æ±ºæ­·å²æ¶è²»è³æä¸­çéè¨åé¡ä¼¼è³ææ¨£æ¬æ½å¨çé¯èª¤åé¡ç­åé¡ï¼éäºåé¡å¯è½æå°è´è¡¨å¾µåè³ªä¸éï¼é²èå½±é¿ä¸æ¸¸é æ¸¬ä»»åçæºç¢ºåº¦ãééå¨å°æ¯å­¸ç¿æ¶æ§ä¸­æ´åé²ééè¨éæ¿¾æè¡ï¼æåçæ¨¡åå¢å¼·äºå­¸ç¿è¡¨å¾µçåè³ªï¼é²èç¢çæ´æºç¢ºçé æ¸¬ãæ­¤å¤ï¼æ­¤æ¨¡åå¨é è¨ç·´æéæé²è¡ç¹å®ç¢æ¥­çå¾®èª¿ï¼ä½¿å¶è½å¤ æ´å¥½å°æ·åååé¨éä¸­å¤©ç¶æ°£æ¶èçç¨ç¹ç¹å¾µãæåä½¿ç¨ä¾èª ENN éåçå¤§è¦æ¨¡è³æéé²è¡äºå»£æ³çå¯¦é©ï¼å¶ä¸­åå«ä¾èªå¤åå°åè¶é 10,000 åå·¥æ¥­ãåæ¥­åç¦å©ç¸éå®¢æ¶çè³æãæåçæ¨¡ååªæ¼ç¾æçæåé²æ¹æ³ï¼èç¾ææä½³æ¨¡åç¸æ¯ï¼MSE çç¸å°æ¹åå¹åº¦çº 3.68%ï¼è MASE çç¸å°æ¹åå¹åº¦çº 6.15%ã

##### **Small Language Models: Survey, Measurements, and Insights**
2409.15790v1 by Zhenyan Lu, Xiang Li, Dongqi Cai, Rongjie Yi, Fangming Liu, Xiwen Zhang, Nicholas D. Lane, Mengwei Xu

Small language models (SLMs), despite their widespread adoption in modern
smart devices, have received significantly less academic attention compared to
their large language model (LLM) counterparts, which are predominantly deployed
in data centers and cloud environments. While researchers continue to improve
the capabilities of LLMs in the pursuit of artificial general intelligence, SLM
research aims to make machine intelligence more accessible, affordable, and
efficient for everyday tasks. Focusing on transformer-based, decoder-only
language models with 100M-5B parameters, we survey 59 state-of-the-art
open-source SLMs, analyzing their technical innovations across three axes:
architectures, training datasets, and training algorithms. In addition, we
evaluate their capabilities in various domains, including commonsense
reasoning, in-context learning, mathematics, and coding. To gain further
insight into their on-device runtime costs, we benchmark their inference
latency and memory footprints. Through in-depth analysis of our benchmarking
data, we offer valuable insights to advance research in this field.

æè¦ï¼åç®¡å°åèªè¨æ¨¡å (SLM) å·²å»£æ³éç¨æ¼ç¾ä»£æºæ§è£ç½®ï¼ä½èä¸»è¦é¨ç½²æ¼è³æä¸­å¿åé²ç«¯ç°å¢çå¤§åèªè¨æ¨¡å (LLM) ç¸æ¯ï¼å­¸è¡çå°å°åèªè¨æ¨¡åçéæ³¨å»å°å¾å¤ãåç®¡ç ç©¶äººå¡æçºæå LLM çåè½ï¼ä»¥è¿½æ±äººå·¥éç¨æºæ§ï¼ä½ SLM ç ç©¶çç®æ¨æ¯è®æ©å¨æºæ§æ´å¹³æè¿äººãæ´å¯¦æ ï¼ä¸æ´ææçå°å·è¡æ¥å¸¸ä»»åãæåéå°å·å 100M-5B åæ¸çåºæ¼è½æå¨ãåè§£ç¢¼å¨çèªè¨æ¨¡åï¼èª¿æ¥äº 59 åæåé²çéæº SLMï¼åæå®åå¨æ¶æ§ãè¨ç·´è³æéåè¨ç·´æ¼ç®æ³éä¸åé¢åä¸çæè¡åµæ°ãæ­¤å¤ï¼æåè©ä¼°äºå®åå¨åç¨®é åçè½åï¼åæ¬å¸¸è­æ¨çãæå¢å­¸ç¿ãæ¸å­¸åç·¨ç¢¼ãçºäºé²ä¸æ­¥äºè§£å®åå¨è£ç½®ä¸çå·è¡æéææ¬ï¼æåå°å®åçæ¨è«å»¶é²åè¨æ¶é«ä½¿ç¨éé²è¡äºåºæºæ¸¬è©¦ãééå°åºæºæ¸¬è©¦è³æçæ·±å¥åæï¼æåæä¾äºå¯¶è²´çè¦è§£ï¼ä»¥æ¨åæ­¤é åçç ç©¶ã

##### **CHBench: A Chinese Dataset for Evaluating Health in Large Language Models**
2409.15766v1 by Chenlu Guo, Nuo Xu, Yi Chang, Yuan Wu

With the rapid development of large language models (LLMs), assessing their
performance on health-related inquiries has become increasingly essential. It
is critical that these models provide accurate and trustworthy health
information, as their application in real-world contexts--where misinformation
can have serious consequences for individuals seeking medical advice and
support--depends on their reliability. In this work, we present CHBench, the
first comprehensive Chinese Health-related Benchmark designed to evaluate LLMs'
capabilities in understanding physical and mental health across diverse
scenarios. CHBench includes 6,493 entries related to mental health and 2,999
entries focused on physical health, covering a broad spectrum of topics. This
dataset serves as a foundation for evaluating Chinese LLMs' capacity to
comprehend and generate accurate health-related information. Our extensive
evaluations of four popular Chinese LLMs demonstrate that there remains
considerable room for improvement in their understanding of health-related
information. The code is available at https://github.com/TracyGuo2001/CHBench.

æè¦ï¼é¨èå¤§åèªè¨æ¨¡å (LLM) çå¿«éç¼å±ï¼è©ä¼°å¶å¨èå¥åº·ç¸éçæ¥è©¢ä¸çè¡¨ç¾è®å¾è¶ä¾è¶éè¦ãéäºæ¨¡åæä¾æºç¢ºä¸å¯ä¿¡è³´çå¥åº·è³è¨è³ééè¦ï¼å çºå®åå¨ç¾å¯¦ä¸ççæç¨ä¸­ââé¯èª¤è³è¨å¯è½æå°å°æ±é«çå»ºè­°åæ¯æ´çåäººé æå´éå¾æââåæ±ºæ¼å®åçå¯é æ§ãå¨éé å·¥ä½ä¸­ï¼æåæåºäº CHBenchï¼éæ¯ç¬¬ä¸åå¨é¢çä¸­æå¥åº·ç¸éåºæºï¼æ¨å¨è©ä¼° LLM å¨åç¨®å ´æ¯ä¸­çè§£èº«å¿å¥åº·ççè½åãCHBench åå« 6,493 åèå¿çå¥åº·ç¸éçæ¢ç®å 2,999 åéæ³¨èº«é«å¥åº·çæ¢ç®ï¼æ¶µèå»£æ³çä¸»é¡ãæ­¤è³æéä½çºè©ä¼°ä¸­æ LLM çè§£åç¢çæºç¢ºå¥åº·ç¸éè³è¨çè½åçåºç¤ãæåå°ååæµè¡çä¸­æ LLM çå»£æ³è©ä¼°è¡¨æï¼å¨çè§£èå¥åº·ç¸éçè³è¨æ¹é¢ä»æå¾å¤§çæ¹é²ç©ºéãç¨å¼ç¢¼å¯å¨ https://github.com/TracyGuo2001/CHBench åå¾ã

##### **Spatial-Temporal Mixture-of-Graph-Experts for Multi-Type Crime Prediction**
2409.15764v1 by Ziyang Wu, Fan Liu, Jindong Han, Yuxuan Liang, Hao Liu

As various types of crime continue to threaten public safety and economic
development, predicting the occurrence of multiple types of crimes becomes
increasingly vital for effective prevention measures. Although extensive
efforts have been made, most of them overlook the heterogeneity of different
crime categories and fail to address the issue of imbalanced spatial
distribution. In this work, we propose a Spatial-Temporal
Mixture-of-Graph-Experts (ST-MoGE) framework for collective multiple-type crime
prediction. To enhance the model's ability to identify diverse spatial-temporal
dependencies and mitigate potential conflicts caused by spatial-temporal
heterogeneity of different crime categories, we introduce an attentive-gated
Mixture-of-Graph-Experts (MGEs) module to capture the distinctive and shared
crime patterns of each crime category. Then, we propose Cross-Expert
Contrastive Learning(CECL) to update the MGEs and force each expert to focus on
specific pattern modeling, thereby reducing blending and redundancy.
Furthermore, to address the issue of imbalanced spatial distribution, we
propose a Hierarchical Adaptive Loss Re-weighting (HALR) approach to eliminate
biases and insufficient learning of data-scarce regions. To evaluate the
effectiveness of our methods, we conduct comprehensive experiments on two
real-world crime datasets and compare our results with twelve advanced
baselines. The experimental results demonstrate the superiority of our methods.

æè¦ï¼é¨èåç¨®ç¯ç½ªæçºå¨èå¬å±å®å¨åç¶æ¿ç¼å±ï¼é æ¸¬å¤ç¨®é¡åç¯ç½ªçç¼çå°æ¼ææçé é²æªæ½è®å¾è¶ä¾è¶éè¦ãåç®¡ä»åºäºå·¨å¤§çåªåï¼ä½å¤§å¤æ¸é½å¿½è¦äºä¸åç¯ç½ªé¡å¥çç°è³ªæ§ï¼ä¸¦ä¸æªè½è§£æ±ºç©ºéåä½ä¸å¹³è¡¡çåé¡ãå¨éé å·¥ä½ä¸­ï¼æåæåºäºä¸åæç©ºæ··ååå°å®¶ (ST-MoGE) æ¡æ¶ï¼ç¨æ¼æ¶éå¤ç¨®é¡åçç¯ç½ªé æ¸¬ãçºäºå¢å¼·æ¨¡åè­å¥ä¸åæç©ºä¾è³´æ§çè½åä¸¦æ¸è¼ç±ä¸åç¯ç½ªé¡å¥çæç©ºç°è³ªæ§å¼èµ·çæ½å¨è¡çªï¼æåå¼å¥äºä¸åå°æ³¨éæ§æ··ååå°å®¶ (MGE) æ¨¡çµä¾æ·åæ¯åç¯ç½ªé¡å¥çç¨ç¹åå±ç¨ç¯ç½ªæ¨¡å¼ãç¶å¾ï¼æåæåºè·¨å°å®¶å°æ¯å­¸ç¿ (CECL) ä¾æ´æ° MGE ä¸¦è¿«ä½¿æ¯åå°å®¶å°æ³¨æ¼ç¹å®çæ¨¡å¼å»ºæ¨¡ï¼å¾èæ¸å°æ··åååé¤ãæ­¤å¤ï¼çºäºè§£æ±ºç©ºéåä½ä¸å¹³è¡¡çåé¡ï¼æåæåºäºä¸ç¨®åå±¤èªé©ææå¤±éæ°å æ¬ (HALR) æ¹æ³ï¼ä»¥æ¶é¤åå·®åè³æç¨å°ååçå­¸ç¿ä¸è¶³ãçºäºè©ä¼°æåæ¹æ³çæææ§ï¼æåå°å©åçå¯¦ä¸ççç¯ç½ªè³æéé²è¡äºå¨é¢çå¯¦é©ï¼ä¸¦å°æåççµæèåäºååé²çåºæºé²è¡äºæ¯è¼ãå¯¦é©çµæè­æäºæåæ¹æ³çåªè¶æ§ã

##### **IRSC: A Zero-shot Evaluation Benchmark for Information Retrieval through Semantic Comprehension in Retrieval-Augmented Generation Scenarios**
2409.15763v1 by Hai Lin, Shaoxiong Zhan, Junyou Su, Haitao Zheng, Hui Wang

In Retrieval-Augmented Generation (RAG) tasks using Large Language Models
(LLMs), the quality of retrieved information is critical to the final output.
This paper introduces the IRSC benchmark for evaluating the performance of
embedding models in multilingual RAG tasks. The benchmark encompasses five
retrieval tasks: query retrieval, title retrieval, part-of-paragraph retrieval,
keyword retrieval, and summary retrieval. Our research addresses the current
lack of comprehensive testing and effective comparison methods for embedding
models in RAG scenarios. We introduced new metrics: the Similarity of Semantic
Comprehension Index (SSCI) and the Retrieval Capability Contest Index (RCCI),
and evaluated models such as Snowflake-Arctic, BGE, GTE, and M3E. Our
contributions include: 1) the IRSC benchmark, 2) the SSCI and RCCI metrics, and
3) insights into the cross-lingual limitations of embedding models. The IRSC
benchmark aims to enhance the understanding and development of accurate
retrieval systems in RAG tasks. All code and datasets are available at:
https://github.com/Jasaxion/IRSC\_Benchmark

æè¦ï¼å¨ä½¿ç¨å¤§åè¯­è¨æ¨¡å (LLM) çæ£ç´¢å¢å¼ºçæ (RAG) ä»»å¡ä¸­ï¼æ£ç´¢ä¿¡æ¯çè´¨éå¯¹æç»è¾åºè³å³éè¦ãæ¬æä»ç»äº IRSC åºåï¼ç¨äºè¯ä¼°åµå¥æ¨¡åå¨å¤è¯­è¨ RAG ä»»å¡ä¸­çæ§è½ãè¯¥åºååå«äºä¸ªæ£ç´¢ä»»å¡ï¼æ¥è¯¢æ£ç´¢ãæ é¢æ£ç´¢ãæ®µè½é¨åæ£ç´¢ãå³é®è¯æ£ç´¢åæè¦æ£ç´¢ãæä»¬çç ç©¶è§£å³äºå½å RAG åºæ¯ä¸­åµå¥æ¨¡åç¼ºä¹å¨é¢æµè¯åæææ¯è¾æ¹æ³çé®é¢ãæä»¬å¼å¥äºæ°çææ ï¼è¯­ä¹çè§£ç¸ä¼¼æ§ææ° (SSCI) åæ£ç´¢è½åç«èµææ° (RCCI)ï¼å¹¶è¯ä¼°äº Snowflake-ArcticãBGEãGTE å M3E ç­æ¨¡åãæä»¬çè´¡ç®åæ¬ï¼1) IRSC åºåï¼2) SSCI å RCCI ææ ï¼ä»¥å 3) å¯¹åµå¥æ¨¡åè·¨è¯­è¨éå¶çè§è§£ãIRSC åºåæ¨å¨å¢å¼ºå¯¹ RAG ä»»å¡ä¸­åç¡®æ£ç´¢ç³»ç»ççè§£åå¼åãææä»£ç åæ°æ®éé½å¯ä»¥å¨ä»¥ä¸ä½ç½®è·å¾ï¼https://github.com/Jasaxion/IRSC\_Benchmark

##### **XTRUST: On the Multilingual Trustworthiness of Large Language Models**
2409.15762v1 by Yahan Li, Yi Wang, Yi Chang, Yuan Wu

Large language models (LLMs) have demonstrated remarkable capabilities across
a range of natural language processing (NLP) tasks, capturing the attention of
both practitioners and the broader public. A key question that now preoccupies
the AI community concerns the capabilities and limitations of these models,
with trustworthiness emerging as a central issue, particularly as LLMs are
increasingly applied in sensitive fields like healthcare and finance, where
errors can have serious consequences. However, most previous studies on the
trustworthiness of LLMs have been limited to a single language, typically the
predominant one in the dataset, such as English. In response to the growing
global deployment of LLMs, we introduce XTRUST, the first comprehensive
multilingual trustworthiness benchmark. XTRUST encompasses a diverse range of
topics, including illegal activities, hallucination, out-of-distribution (OOD)
robustness, physical and mental health, toxicity, fairness, misinformation,
privacy, and machine ethics, across 10 different languages. Using XTRUST, we
conduct an empirical evaluation of the multilingual trustworthiness of five
widely used LLMs, offering an in-depth analysis of their performance across
languages and tasks. Our results indicate that many LLMs struggle with certain
low-resource languages, such as Arabic and Russian, highlighting the
considerable room for improvement in the multilingual trustworthiness of
current language models. The code is available at
https://github.com/LluckyYH/XTRUST.

æè¦ï¼å¤§åèªè¨æ¨¡åï¼LLMï¼å·²å¨åç¨®èªç¶èªè¨èçï¼NLPï¼ä»»åä¸­å±ç¾åºéå¡çè½åï¼å¸å¼äºå¾æ¥­èåå»£å¤§æ°ç¾çéæ³¨ãç¾å¨ AI ç¤¾ç¾¤æéæ³¨çä¸åééµåé¡æ¯éäºæ¨¡åçè½ååéå¶ï¼å¶ä¸­å¯ä¿¡åº¦æ¯ä¸åæ ¸å¿åé¡ï¼ç¹å¥æ¯ LLM æä¾æå¤ç¨æ¼é«çä¿å¥åéèç­ææé åï¼é¯èª¤å¯è½æé æå´éå¾æãç¶èï¼å¤§å¤æ¸ååéæ¼ LLM å¯ä¿¡åº¦çç ç©¶é½åéæ¼å®ä¸èªè¨ï¼éå¸¸æ¯è³æéä¸­ä½ä¸»å°å°ä½çèªè¨ï¼ä¾å¦è±èªãçºäºå æ LLM å¨å¨çé¨ç½²çæé·ï¼æåå¼å¥äº XTRUSTï¼éæ¯ç¬¬ä¸åç¶åæ§çå¤èªè¨å¯ä¿¡åº¦åºæºãXTRUST æ¶µèäºåç¨®ä¸»é¡ï¼åæ¬éæ³æ´»åãå¹»è¦ºãåå¸å¤ï¼OODï¼ç©©å¥æ§ãèº«å¿å¥åº·ãæ¯æ§ãå¬å¹³æ§ãé¯èª¤è³è¨ãé±ç§åæ©å¨å«çï¼æ©«è·¨ 10 ç¨®ä¸åçèªè¨ãä½¿ç¨ XTRUSTï¼æåå°äºåå»£æ³ä½¿ç¨ç LLM é²è¡äºå¤èªè¨å¯ä¿¡åº¦çå¯¦è­è©ä¼°ï¼æ·±å¥åæäºå®åå¨ä¸åèªè¨åä»»åä¸­çè¡¨ç¾ãæåççµæè¡¨æï¼è¨±å¤ LLM é£ä»¥æä»æäºä½è³æºèªè¨ï¼ä¾å¦é¿æä¼¯èªåä¿èªï¼çªé¡¯äºç¶åèªè¨æ¨¡åçå¤èªè¨å¯ä¿¡åº¦æå¾å¤§çæ¹é²ç©ºéãç¨å¼ç¢¼å¯å¨ https://github.com/LluckyYH/XTRUST åå¾ã

##### **TFG: Unified Training-Free Guidance for Diffusion Models**
2409.15761v1 by Haotian Ye, Haowei Lin, Jiaqi Han, Minkai Xu, Sheng Liu, Yitao Liang, Jianzhu Ma, James Zou, Stefano Ermon

Given an unconditional diffusion model and a predictor for a target property
of interest (e.g., a classifier), the goal of training-free guidance is to
generate samples with desirable target properties without additional training.
Existing methods, though effective in various individual applications, often
lack theoretical grounding and rigorous testing on extensive benchmarks. As a
result, they could even fail on simple tasks, and applying them to a new
problem becomes unavoidably difficult. This paper introduces a novel
algorithmic framework encompassing existing methods as special cases, unifying
the study of training-free guidance into the analysis of an algorithm-agnostic
design space. Via theoretical and empirical investigation, we propose an
efficient and effective hyper-parameter searching strategy that can be readily
applied to any downstream task. We systematically benchmark across 7 diffusion
models on 16 tasks with 40 targets, and improve performance by 8.5% on average.
Our framework and benchmark offer a solid foundation for conditional generation
in a training-free manner.

æè¦ï¼çµ¦å®ä¸åç¡æ¢ä»¶æ´æ£æ¨¡ååä¸åç®æ¨å±¬æ§çé æ¸¬å¨ï¼ä¾å¦ï¼ä¸ååé¡å¨ï¼ï¼ç¡è¨ç·´æå°çç®æ¨æ¯çæå·æçæ³ç®æ¨å±¬æ§çæ¨£æ¬ï¼èç¡éé¡å¤çè¨ç·´ãç¾ææ¹æ³éç¶å¨åç¨®åå¥æç¨ä¸­å¾ææï¼ä½éå¸¸ç¼ºä¹çè«ä¾æï¼ä¸¦ä¸å¨å»£æ³çåºæºä¸é²è¡å´æ ¼çæ¸¬è©¦ãå æ­¤ï¼å®åçè³å¯è½å¨ç°¡å®çä»»åä¸å¤±æï¼ä¸¦ä¸å°å®åæç¨æ¼æ°åé¡ä¸å¯é¿åå°è®å¾å°é£ãæ¬æä»ç´¹äºä¸åæ°ç©çæ¼ç®æ³æ¡æ¶ï¼å°ç¾ææ¹æ³ä½çºç¹ä¾ï¼å°ç¡è¨ç·´æå°çç ç©¶çµ±ä¸å°æ¼ç®æ³ä¸å¯ç¥çè¨­è¨ç©ºéçåæä¸­ãééçè«åå¯¦è­èª¿æ¥ï¼æåæåºäºä¸åææçä¸ææçè¶åæ¸æå°ç­ç¥ï¼å¯ä»¥å¾å®¹æå°æç¨æ¼ä»»ä½ä¸æ¸¸ä»»åãæåç³»çµ±å°å° 7 åæ´æ£æ¨¡åé²è¡åºæºæ¸¬è©¦ï¼æ¶µè 16 åä»»åå 40 åç®æ¨ï¼ä¸¦å¹³åæé«äº 8.5% çæè½ãæåçæ¡æ¶ååºæºçºç¡è¨ç·´æ¹å¼çæ¢ä»¶çææä¾äºä¸åç©©åºçåºç¤ã

##### **The Roles of Generative Artificial Intelligence in Internet of Electric Vehicles**
2409.15750v1 by Hanwen Zhang, Dusit Niyato, Wei Zhang, Changyuan Zhao, Hongyang Du, Abbas Jamalipour, Sumei Sun, Yiyang Pei

With the advancement of generative artificial intelligence (GenAI) models,
their capability to generate content is seeing significant enhancement, leading
to widespread applications in the field of data generation and forecasting.
Furthermore, GenAI has strong capabilities in data modeling and analysis, which
enhances Internet of electric vehicles (IoEV) applications in various aspects.
In this paper, we investigate and survey applications of GenAI in the IoEV.
Specifically, we categorize GenAI for IoEV into four different layers namely,
EV's battery layer, individual electric vehicle (EV) layer, smart grid with EV
layer, and security layer. We first introduce various GenAI techniques used in
each layer of IoEV applications. Subsequently, public datasets available for
training the GenAI models are summarized. Finally, we provide recommendations
for future directions. This survey not only categorizes the applications of
GenAI in IoEV across different layers but also serves as a valuable resource
for researchers and practitioners by highlighting the design and implementation
challenges within each layer. Furthermore, it provides a roadmap for future
research directions, enabling the development of more robust and efficient IoEV
systems through the integration of advanced GenAI techniques.

æè¦ï¼é¨èçæå¼äººå·¥æºæ§ï¼GenAIï¼æ¨¡åçé²æ­¥ï¼å®åçæå§å®¹çè½åé¡¯èå¢å¼·ï¼é²èå»£æ³æç¨æ¼è³æçæåé æ¸¬é åãæ­¤å¤ï¼GenAI å¨è³æå»ºæ¨¡ååææ¹é¢å·æå¼·å¤§åè½ï¼éå¨åæ¹é¢å¢å¼·äºé»åè»è¼ç©è¯ç¶²ï¼IoEVï¼æç¨ãå¨æ¬æä¸­ï¼æåæ¢è¨åèª¿æ¥ GenAI å¨ IoEV ä¸­çæç¨ãå·é«ä¾èªªï¼æåå° IoEV ç GenAI åçºååä¸åçå±¤ç´ï¼å³é»åè»çé»æ± å±¤ãåå¥é»åè»ï¼EVï¼å±¤ãå·åé»åè»çæºæ§é»ç¶²å±¤åå®å¨å±¤ãæåé¦åä»ç´¹å¨ IoEV æç¨ä¸­ååå±¤ç´æä½¿ç¨çåç¨® GenAI æè¡ãé¨å¾ï¼æåç¸½çµäºå¯ç¨æ¼è¨ç·´ GenAI æ¨¡åçå¬éè³æéãæå¾ï¼æåæä¾æªä¾æ¹åçå»ºè­°ãéé èª¿æ¥ä¸ååé¡äº GenAI å¨ IoEV ä¸­è·¨ä¸åå±¤ç´çæç¨ï¼ä¹ééå¼·èª¿åå±¤ç´å§çè¨­è¨åå¯¦ä½ææ°ï¼ä½çºç ç©¶äººå¡åå¾æ¥­äººå¡çå¯¶è²´è³æºãæ­¤å¤ï¼å®éæä¾äºæªä¾ç ç©¶æ¹åçè·¯ç·åï¼ééæ´ååé²ç GenAI æè¡ï¼è½éç¼åºæ´å¼·å¤§ä¸æ´ææçç IoEV ç³»çµ±ã

##### **Automated Assessment of Multimodal Answer Sheets in the STEM domain**
2409.15749v1 by Rajlaxmi Patil, Aditya Ashutosh Kulkarni, Ruturaj Ghatage, Sharvi Endait, Geetanjali Kale, Raviraj Joshi

In the domain of education, the integration of,technology has led to a
transformative era, reshaping traditional,learning paradigms. Central to this
evolution is the automation,of grading processes, particularly within the STEM
domain encompassing Science, Technology, Engineering, and Mathematics.,While
efforts to automate grading have been made in subjects,like Literature, the
multifaceted nature of STEM assessments,presents unique challenges, ranging
from quantitative analysis,to the interpretation of handwritten diagrams. To
address these,challenges, this research endeavors to develop efficient and
reliable grading methods through the implementation of automated,assessment
techniques using Artificial Intelligence (AI). Our,contributions lie in two key
areas: firstly, the development of a,robust system for evaluating textual
answers in STEM, leveraging,sample answers for precise comparison and grading,
enabled by,advanced algorithms and natural language processing
techniques.,Secondly, a focus on enhancing diagram evaluation,
particularly,flowcharts, within the STEM context, by transforming diagrams,into
textual representations for nuanced assessment using a,Large Language Model
(LLM). By bridging the gap between,visual representation and semantic meaning,
our approach ensures accurate evaluation while minimizing manual
intervention.,Through the integration of models such as CRAFT for
text,extraction and YoloV5 for object detection, coupled with LLMs,like
Mistral-7B for textual evaluation, our methodology facilitates,comprehensive
assessment of multimodal answer sheets. This,paper provides a detailed account
of our methodology, challenges,encountered, results, and implications,
emphasizing the potential,of AI-driven approaches in revolutionizing grading
practices in,STEM education.

æè¦ï¼<paragraph>å¨æè²é åï¼ç§æçæ´åå¸¶ä¾äºè®é©æ§çæä»£ï¼éå¡äºå³çµ±çå­¸ç¿æ¨¡å¼ãéåæ¼è®çæ ¸å¿æ¯è©åéç¨çèªååï¼ç¹å¥æ¯å¨æ¶µèç§å­¸ãæè¡ãå·¥ç¨åæ¸å­¸ç STEM é åä¸­ãéç¶å¨æå­¸ç­ç§ç®ä¸­å·²ç¶ååºèªååè©åçåªåï¼ä½ STEM è©ä¼°çå¤æ¹é¢æ§è³ªæåºäºç¨ç¹ææ°ï¼å¾éååæå°æå¯«åè¡¨çè§£è®ãçºäºæå°éäºææ°ï¼æ¬ç ç©¶è´åæ¼ééå¯¦æ½ä½¿ç¨äººå·¥æºæ§ (AI) çèªååè©ä¼°æè¡ä¾éç¼é«æä¸å¯é çè©åæ¹æ³ãæåçè²¢ç»å¨å©åééµé åï¼é¦åï¼éç¼ä¸åç¨æ¼è©ä¼° STEM ä¸­çæå­ç­æ¡çå¥å¨ç³»çµ±ï¼å©ç¨ç¯ä¾ç­æ¡é²è¡ç²¾ç¢ºæ¯è¼åè©åï¼ä¸¦ç±åé²çæ¼ç®æ³åèªç¶èªè¨èçæè¡æ¯æ´ãå¶æ¬¡ï¼å°æ³¨æ¼å¢å¼·åè¡¨è©ä¼°ï¼ç¹å¥æ¯ STEM èçµ¡ä¸­çæµç¨åï¼ééå°åè¡¨è½æçºæå­è¡¨ç¤ºï¼ä»¥ä½¿ç¨å¤§åèªè¨æ¨¡å (LLM) é²è¡ç´°ç·»è©ä¼°ãééå½åè¦è¦ºè¡¨ç¤ºåèªç¾©æç¾©ä¹éçå·®è·ï¼æåçåæ³ç¢ºä¿äºæºç¢ºçè©ä¼°ï¼åææå¤§éåº¦å°æ¸å°äººå·¥å¹²é ãééæ´åç¨æ¼æå­èåç CRAFT åç¨æ¼ç©ä»¶åµæ¸¬ç YoloV5 ç­æ¨¡åï¼ä»¥åç¨æ¼æå­è©ä¼°ç Mistral-7B ç­ LLMï¼æåçåæ³ä¿é²äºå°å¤æ¨¡æç­é¡ç´çå¨é¢è©ä¼°ãæ¬æè©³ç´°èªªæäºæåçæ¹æ³ãéå°çææ°ãçµæåå½±é¿ï¼å¼·èª¿äº AI é©åæ¹æ³å¨é©æ° STEM æè²ä¸­çè©åå¯¦åæ¹é¢çæ½åã</paragraph>

##### **Training Neural Networks for Modularity aids Interpretability**
2409.15747v1 by Satvik Golechha, Dylan Cope, Nandi Schoots

An approach to improve network interpretability is via clusterability, i.e.,
splitting a model into disjoint clusters that can be studied independently. We
find pretrained models to be highly unclusterable and thus train models to be
more modular using an ``enmeshment loss'' function that encourages the
formation of non-interacting clusters. Using automated interpretability
measures, we show that our method finds clusters that learn different,
disjoint, and smaller circuits for CIFAR-10 labels. Our approach provides a
promising direction for making neural networks easier to interpret.

æè¦ï¼ä¸ç¨®æ¹åç¶²è·¯å¯è§£éæ§çæ¹æ³æ¯ééç¾¤éæ§ï¼ä¹å°±æ¯å°æ¨¡ååå²æå¯ç¨ç«ç ç©¶çä¸åç¾¤éãæåç¼ç¾é åè¨ç·´çæ¨¡åé«åº¦ä¸å¯ç¾¤éï¼å æ­¤ä½¿ç¨ãç³¾çºæå¤±ãå½æ¸è¨ç·´æ¨¡åï¼ä»¥ä¿é²éäº¤äºç¾¤éçå½¢æãä½¿ç¨èªååå¯è§£éæ§åº¦éï¼æåå±ç¤ºäºæåçæ¨¡åå¯æ¾å°å­¸ç¿ä¸åãä¸ç¸äº¤ä¸è¼å°çè¿´è·¯ï¼ä»¥åå¾ CIFAR-10 æ¨ç±¤ãæåçæ¹æ³çºè®ç¥ç¶ç¶²è·¯æ´å®¹æè§£éæä¾äºä¸åæåæ¯çæ¹åã

##### **Real-Time Pedestrian Detection on IoT Edge Devices: A Lightweight Deep Learning Approach**
2409.15740v1 by Muhammad Dany Alfikri, Rafael Kaliski

Artificial intelligence (AI) has become integral to our everyday lives.
Computer vision has advanced to the point where it can play the safety critical
role of detecting pedestrians at road intersections in intelligent
transportation systems and alert vehicular traffic as to potential collisions.
Centralized computing analyzes camera feeds and generates alerts for nearby
vehicles. However, real-time applications face challenges such as latency,
limited data transfer speeds, and the risk of life loss. Edge servers offer a
potential solution for real-time applications, providing localized computing
and storage resources and lower response times. Unfortunately, edge servers
have limited processing power. Lightweight deep learning (DL) techniques enable
edge servers to utilize compressed deep neural network (DNN) models.
  The research explores implementing a lightweight DL model on Artificial
Intelligence of Things (AIoT) edge devices. An optimized You Only Look Once
(YOLO) based DL model is deployed for real-time pedestrian detection, with
detection events transmitted to the edge server using the Message Queuing
Telemetry Transport (MQTT) protocol. The simulation results demonstrate that
the optimized YOLO model can achieve real-time pedestrian detection, with a
fast inference speed of 147 milliseconds, a frame rate of 2.3 frames per
second, and an accuracy of 78%, representing significant improvements over
baseline models.

æè¦ï¼äººå·¥æºæ§ (AI) å·²æçºæåæ¥å¸¸çæ´»ä¸å¯æç¼ºçä¸é¨åã
é»è¦è¦è¦ºå·²é²æ­¥å°å¯ä»¥æ®æ¼å®å¨ééµçè§è²ï¼å¨æºæ§éè¼¸ç³»çµ±ä¸­åµæ¸¬è·¯å£è¡äººï¼ä¸¦å°è»è¼äº¤éç¼åºæ½å¨ç¢°æè­¦ç¤ºã
éä¸­å¼éç®åæç¸æ©å½±åï¼ä¸¦çºéè¿è»è¼ç¢çè­¦ç¤ºã
ç¶èï¼å³ææç¨ç¨å¼é¢è¨è«¸å¦å»¶é²ãè³æå³è¼¸éåº¦åéåçå½æå¤±é¢¨éªç­ææ°ã
éç·£ä¼ºæå¨æä¾å³ææç¨ç¨å¼çæ½å¨è§£æ±ºæ¹æ¡ï¼æä¾å¨å°åéç®åå²å­è³æºï¼ä»¥åè¼ä½çåææéã
ä¸å¹¸çæ¯ï¼éç·£ä¼ºæå¨å·ææéçèçè½åã
è¼éç´æ·±åº¦å­¸ç¿ (DL) æè¡è®éç·£ä¼ºæå¨è½å¤ å©ç¨å£ç¸®æ·±åº¦ç¥ç¶ç¶²è·¯ (DNN) æ¨¡åã
æ­¤ç ç©¶æ¢è¨å¨äººå·¥æºæ§ç©è¯ç¶² (AIoT) éç·£è£ç½®ä¸å¯¦ä½è¼éç´ DL æ¨¡åã
é¨ç½²æä½³ååªçä¸æ¬¡ (YOLO) çºåºç¤ç DL æ¨¡åï¼é²è¡å³æè¡äººåµæ¸¬ï¼ä¸¦ä½¿ç¨è¨æ¯ä½åéæ¸¬å³è¼¸ (MQTT) åå®å°åµæ¸¬äºä»¶å³è¼¸è³éç·£ä¼ºæå¨ã
æ¨¡æ¬çµæé¡¯ç¤ºï¼æä½³å YOLO æ¨¡åå¯ä»¥éæå³æè¡äººåµæ¸¬ï¼æ¨è«éåº¦å¿«ï¼çº 147 æ¯«ç§ï¼æ¯ç§ 2.3 å¹çå¹çå 78% çæºç¢ºåº¦ï¼ä»£è¡¨ç¸è¼æ¼åºæºæ¨¡åæé¡¯èçé²æ­¥ã

##### **EvoFA: Evolvable Fast Adaptation for EEG Emotion Recognition**
2409.15733v1 by Ming Jin, Danni Zhang, Gangming Zhao, Changde Du, Jinpeng Li

Electroencephalography (EEG)-based emotion recognition has gained significant
traction due to its accuracy and objectivity. However, the non-stationary
nature of EEG signals leads to distribution drift over time, causing severe
performance degradation when the model is reused. While numerous domain
adaptation (DA) approaches have been proposed in recent years to address this
issue, their reliance on large amounts of target data for calibration restricts
them to offline scenarios, rendering them unsuitable for real-time
applications. To address this challenge, this paper proposes Evolvable Fast
Adaptation (EvoFA), an online adaptive framework tailored for EEG data. EvoFA
organically integrates the rapid adaptation of Few-Shot Learning (FSL) and the
distribution matching of Domain Adaptation (DA) through a two-stage
generalization process. During the training phase, a robust base meta-learning
model is constructed for strong generalization. In the testing phase, a
designed evolvable meta-adaptation module iteratively aligns the marginal
distribution of target (testing) data with the evolving source (training) data
within a model-agnostic meta-learning framework, enabling the model to learn
the evolving trends of testing data relative to training data and improving
online testing performance. Experimental results demonstrate that EvoFA
achieves significant improvements compared to the basic FSL method and previous
online methods. The introduction of EvoFA paves the way for broader adoption of
EEG-based emotion recognition in real-world applications. Our code will be
released upon publication.

æè¦ï¼<paragraph>åºæ¼è¦é»å (EEG) çæç·è¾¨è­ç±æ¼å¶æºç¢ºæ§åå®¢è§æ§èç²å¾é¡¯èçéæ³¨ãç¶èï¼EEG è¨èçéå¹³ç©©ç¹æ§æå°è´åå¸é¨æéæ¼ç§»ï¼å°è´æ¨¡åéè¤ä½¿ç¨ææè½å´éä¸éãéç¶è¿å¹´ä¾å·²æåºè¨±å¤é åé©æ (DA) æ¹æ³ä¾è§£æ±ºæ­¤åé¡ï¼ä½å®åä¾è³´æ¼å¤§éç®æ¨è³æé²è¡æ ¡æ­£ï¼éå¶å®ååéæ¼é¢ç·å ´æ¯ï¼ä½¿å¶ä¸é©åæ¼å³ææç¨ç¨å¼ãçºäºæå°æ­¤ææ°ï¼æ¬ææåºå¯æ¼åçå¿«éé©æ (EvoFA)ï¼éæ¯ä¸åéå° EEG è³æéèº«æé çç·ä¸é©ææ§æ¶æ§ãEvoFA ééå©éæ®µçæ¦åéç¨ï¼ææ©æ´åäºå°éæ¨£æ¬å­¸ç¿ (FSL) çå¿«éé©æåé åé©æ (DA) çåå¸å¹éãå¨è¨ç·´éæ®µï¼æ§å»ºä¸åç©©å¥çåºæ¬åå­¸ç¿æ¨¡åä»¥é²è¡å¼·å¤§çæ¦åãå¨æ¸¬è©¦éæ®µï¼ä¸åè¨­è¨å¥½çå¯æ¼ååé©ææ¨¡çµæå¨ä¸åèæ¨¡åç¡éçåå­¸ç¿æ¶æ§ä¸­ï¼åè¦æ¯å°ç®æ¨ï¼æ¸¬è©¦ï¼è³æçééåå¸èæ¼åçä¾æºï¼è¨ç·´ï¼è³æï¼ä½¿æ¨¡åè½å¤ å­¸ç¿æ¸¬è©¦è³æç¸å°æ¼è¨ç·´è³æçæ¼åè¶¨å¢ï¼ä¸¦æ¹åç·ä¸æ¸¬è©¦æè½ãå¯¦é©çµæè¡¨æï¼èåºæ¬ FSL æ¹æ³åååçç·ä¸æ¹æ³ç¸æ¯ï¼EvoFA ç²å¾é¡¯èçæ¹åãEvoFA çå°å¥çº EEG åºæ¼æç·è¾¨è­å¨å¯¦éæç¨ä¸­æ´å»£æ³çæ¡ç¨éªå¹³äºéè·¯ãæåçç¨å¼ç¢¼å°å¨åºçå¾ç¼å¸ã</paragraph>

##### **Learning Multiple Probabilistic Decisions from Latent World Model in Autonomous Driving**
2409.15730v1 by Lingyu Xiao, Jiang-Jiang Liu, Sen Yang, Xiaofan Li, Xiaoqing Ye, Wankou Yang, Jingdong Wang

The autoregressive world model exhibits robust generalization capabilities in
vectorized scene understanding but encounters difficulties in deriving actions
due to insufficient uncertainty modeling and self-delusion. In this paper, we
explore the feasibility of deriving decisions from an autoregressive world
model by addressing these challenges through the formulation of multiple
probabilistic hypotheses. We propose LatentDriver, a framework models the
environment's next states and the ego vehicle's possible actions as a mixture
distribution, from which a deterministic control signal is then derived. By
incorporating mixture modeling, the stochastic nature of decisionmaking is
captured. Additionally, the self-delusion problem is mitigated by providing
intermediate actions sampled from a distribution to the world model.
Experimental results on the recently released close-loop benchmark Waymax
demonstrate that LatentDriver surpasses state-of-the-art reinforcement learning
and imitation learning methods, achieving expert-level performance. The code
and models will be made available at
https://github.com/Sephirex-X/LatentDriver.

æè¦ï¼èªè¿´æ­¸ä¸çæ¨¡åå¨åéåå ´æ¯çè§£ä¸­å±ç¾åºç©©å¥çæ³åè½åï¼ä½ç±æ¼ä¸ç¢ºå®æ§å»ºæ¨¡åèªææ¬ºé¨ä¸è¶³ï¼èå¨æ¨å°åä½æéå°å°é£ãå¨æ¬æä¸­ï¼æåééå¤åæ©çåè¨­çå¬å¼åï¼æ¢è¨å¾èªè¿´æ­¸ä¸çæ¨¡åä¸­æ¨å°æ±ºç­çå¯è¡æ§ãæåæåº LatentDriverï¼ä¸åæ¶æ§å°ç°å¢çå¾çºçæåèªæè»è¼çå¯è½åä½å»ºæ¨¡çºæ··ååä½ï¼ç¶å¾å¾ä¸­æ¨å°åºç¢ºå®æ§çæ§å¶è¨èãééç´å¥æ··åå»ºæ¨¡ï¼ææäºæ±ºç­çé¨æ©æ§è³ªãæ­¤å¤ï¼ééæä¾å¾åä½ä¸­åæ¨£çä¸­éåä½çµ¦ä¸çæ¨¡åï¼ä¾æ¸è¼èªææ¬ºé¨åé¡ãå¨æè¿ç¼å¸çéè¿´è·¯åºæº Waymax ä¸çå¯¦é©çµæè­æï¼LatentDriver è¶è¶äºæåé²çå¼·åå­¸ç¿åæ¨¡ä»¿å­¸ç¿æ¹æ³ï¼éå°äºå°å®¶ç´çè¡¨ç¾ãç¨å¼ç¢¼åæ¨¡åå°å¨ https://github.com/Sephirex-X/LatentDriver ä¸æä¾ã

##### **Sequential Learning in the Dense Associative Memory**
2409.15729v1 by Hayden McAlister, Anthony Robins, Lech Szymanski

Sequential learning involves learning tasks in a sequence, and proves
challenging for most neural networks. Biological neural networks regularly
conquer the sequential learning challenge and are even capable of transferring
knowledge both forward and backwards between tasks. Artificial neural networks
often totally fail to transfer performance between tasks, and regularly suffer
from degraded performance or catastrophic forgetting on previous tasks. Models
of associative memory have been used to investigate the discrepancy between
biological and artificial neural networks due to their biological ties and
inspirations, of which the Hopfield network is perhaps the most studied model.
The Dense Associative Memory, or modern Hopfield network, generalizes the
Hopfield network, allowing for greater capacities and prototype learning
behaviors, while still retaining the associative memory structure. We
investigate the performance of the Dense Associative Memory in sequential
learning problems, and benchmark various sequential learning techniques in the
network. We give a substantial review of the sequential learning space with
particular respect to the Hopfield network and associative memories, as well as
describe the techniques we implement in detail. We also draw parallels between
the classical and Dense Associative Memory in the context of sequential
learning, and discuss the departures from biological inspiration that may
influence the utility of the Dense Associative Memory as a tool for studying
biological neural networks. We present our findings, and show that existing
sequential learning methods can be applied to the Dense Associative Memory to
improve sequential learning performance.

æè¦ï¼åºåå­¸ç¿æ¶åæé åºå­¸ç¿ä»»åï¼ä¸¦è­æå°å¤§å¤æ¸ç¥ç¶ç¶²è·¯èè¨å·æææ°æ§ãçç©ç¥ç¶ç¶²è·¯å®æåæåºåå­¸ç¿ææ°ï¼çè³è½å¤ å¨ä»»åä¹éååååå¾å³éç¥è­ãäººå·¥ç¥ç¶ç¶²è·¯éå¸¸ç¡æ³å¨ä»»åä¹éå³éæè½ï¼ä¸¦ä¸ç¶å¸¸é­åæè½ä¸éæååä»»åçç½é£æ§éºå¿ãè¯æ³è¨æ¶æ¨¡åå·²è¢«ç¨æ¼ç ç©¶çç©åäººå·¥ç¥ç¶ç¶²è·¯ä¹éçå·®ç°ï¼å çºå®åå·æçç©è¯ç¹«åéæï¼å¶ä¸­éæ®è²ç¾å¾·ç¶²è·¯å¯è½æ¯ç ç©¶æå¤çæ¨¡åãå¯éè¯æ³è¨æ¶æç¾ä»£éæ®è²ç¾å¾·ç¶²è·¯æ¦æ¬äºéæ®è²ç¾å¾·ç¶²è·¯ï¼åè¨±æ´å¤§çå®¹éåååå­¸ç¿è¡çºï¼åæä»ä¿çè¯æ³è¨æ¶çµæ§ãæåç ç©¶å¯éè¯æ³è¨æ¶å¨åºåå­¸ç¿åé¡ä¸­çæè½ï¼ä¸¦å¨ç¶²è·¯ä¸­å°åç¨®åºåå­¸ç¿æè¡é²è¡åºæºæ¸¬è©¦ãæåå°åºåå­¸ç¿ç©ºéé²è¡äºå¯¦è³ªæ§åé¡§ï¼ç¹å¥æ¯éæ¼éæ®è²ç¾å¾·ç¶²è·¯åè¯æ³è¨æ¶ï¼ä¸¦è©³ç´°æè¿°äºæåå¯¦ä½çæè¡ãæåéå¨åºåå­¸ç¿çèæ¯ä¸æç¹ªäºç¶å¸åå¯éè¯æ³è¨æ¶ä¹éçç¸ä¼¼ä¹èï¼ä¸¦è¨è«äºå¯è½å½±é¿å¯éè¯æ³è¨æ¶ä½çºç ç©¶çç©ç¥ç¶ç¶²è·¯å·¥å·çæç¨ççç©éæåé¢ãæåæåºæåçç¼ç¾ï¼ä¸¦è¡¨æç¾æçåºåå­¸ç¿æ¹æ³å¯ä»¥æç¨æ¼å¯éè¯æ³è¨æ¶ä»¥æ¹ååºåå­¸ç¿æè½ã

##### **LLM-Cure: LLM-based Competitor User Review Analysis for Feature Enhancement**
2409.15724v1 by Maram Assi, Safwat Hassan, Ying Zou

The exponential growth of the mobile app market underscores the importance of
constant innovation and rapid response to user demands. As user satisfaction is
paramount to the success of a mobile application (app), developers typically
rely on user reviews, which represent user feedback that includes ratings and
comments to identify areas for improvement. However, the sheer volume of user
reviews poses challenges in manual analysis, necessitating automated
approaches. Existing automated approaches either analyze only the target apps
reviews, neglecting the comparison of similar features to competitors or fail
to provide suggestions for feature enhancement. To address these gaps, we
propose a Large Language Model (LLM)-based Competitive User Review Analysis for
Feature Enhancement) (LLM-Cure), an approach powered by LLMs to automatically
generate suggestion s for mobile app feature improvements. More specifically,
LLM-Cure identifies and categorizes features within reviews by applying LLMs.
When provided with a complaint in a user review, LLM-Cure curates highly rated
(4 and 5 stars) reviews in competing apps related to the complaint and proposes
potential improvements tailored to the target application. We evaluate LLM-Cure
on 1,056,739 reviews of 70 popular Android apps. Our evaluation demonstrates
that LLM-Cure significantly outperforms the state-of-the-art approaches in
assigning features to reviews by up to 13% in F1-score, up to 16% in recall and
up to 11% in precision. Additionally, LLM-Cure demonstrates its capability to
provide suggestions for resolving user complaints. We verify the suggestions
using the release notes that reflect the changes of features in the target
mobile app. LLM-Cure achieves a promising average of 73% of the implementation
of the provided suggestions.

æè¦ï¼è¡åæç¨ç¨å¼å¸å ´çææ¸åæé·ï¼çªé¡¯äºæçºåµæ°åå¿«éåæä½¿ç¨èéæ±çéè¦æ§ãç±æ¼ä½¿ç¨èæ»¿æåº¦å°æ¼è¡åæç¨ç¨å¼ (app) çæåè³ééè¦ï¼éç¼äººå¡éå¸¸ä¾è³´ä½¿ç¨èè©è«ï¼å¶ä¸­åæ¬è©ååè©è«ï¼ä»¥æ¾åºéè¦æ¹é²çå°æ¹ãç¶èï¼é¾å¤§çä½¿ç¨èè©è«éå°æååææ§æææ°ï¼å æ­¤éè¦èªååæ¹æ³ãç¾æçèªååæ¹æ³åªåæç®æ¨æç¨ç¨å¼çè©è«ï¼å¿½ç¥äºèç«¶ç­å°æçé¡ä¼¼åè½æ¯è¼ï¼æç¡æ³æä¾åè½å¢å¼·å»ºè­°ãçºäºè§£æ±ºéäºå·®è·ï¼æåæåºäºä¸ååºæ¼å¤§åèªè¨æ¨¡å (LLM) çç«¶ç­æ§ä½¿ç¨èè©è«åæï¼ç¨æ¼åè½å¢å¼· (LLM-Cure)ï¼ä¸ç¨®ç± LLM é©åçæ¹æ³ï¼å¯èªåç¢çéå°è¡åæç¨ç¨å¼åè½æ¹é²çå»ºè­°ãæ´å·é«å°èªªï¼LLM-Cure ééæç¨ LLM ä¾è­å¥ååé¡è©è«ä¸­çåè½ãç¶ä½¿ç¨èè©è«ä¸­åºç¾æ±æ¨æï¼LLM-Cure ææ´çèæ±æ¨ç¸éçç«¶ç­æç¨ç¨å¼ä¸­è©åå¾é«ç (4 å 5 æ) è©è«ï¼ä¸¦æåºéå°ç®æ¨æç¨ç¨å¼éèº«æé çæ½å¨æ¹é²å»ºè­°ãæåå¨ 70 åç±é Android æç¨ç¨å¼ç 1,056,739 åè©è«ä¸è©ä¼° LLM-Cureãæåçè©ä¼°é¡¯ç¤ºï¼LLM-Cure å¨å°åè½åéçµ¦è©è«æ¹é¢æé¡¯åªæ¼æåé²çæ¹æ³ï¼F1 åæ¸æé«äº 13%ï¼å¬åçæé«äº 16%ï¼æºç¢ºçæé«äº 11%ãæ­¤å¤ï¼LLM-Cure å±ç¤ºäºå¶æä¾è§£æ±ºä½¿ç¨èæ±æ¨å»ºè­°çè½åãæåä½¿ç¨åæ ç®æ¨è¡åæç¨ç¨å¼ä¸­åè½è®æ´ççæ¬èªªæä¾é©è­éäºå»ºè­°ãLLM-Cure éå°äºä»¤äººæ»¿æçå¹³å 73% çææä¾å»ºè­°çå¯¦æ½çã

##### **Federated Large Language Models: Current Progress and Future Directions**
2409.15723v1 by Yuhang Yao, Jianyi Zhang, Junda Wu, Chengkai Huang, Yu Xia, Tong Yu, Ruiyi Zhang, Sungchul Kim, Ryan Rossi, Ang Li, Lina Yao, Julian McAuley, Yiran Chen, Carlee Joe-Wong

Large language models are rapidly gaining popularity and have been widely
adopted in real-world applications. While the quality of training data is
essential, privacy concerns arise during data collection. Federated learning
offers a solution by allowing multiple clients to collaboratively train LLMs
without sharing local data. However, FL introduces new challenges, such as
model convergence issues due to heterogeneous data and high communication
costs. A comprehensive study is required to address these challenges and guide
future research. This paper surveys Federated learning for LLMs (FedLLM),
highlighting recent advances and future directions. We focus on two key
aspects: fine-tuning and prompt learning in a federated setting, discussing
existing work and associated research challenges. We finally propose potential
research directions for federated LLMs, including pre-training and how LLMs can
further enhance federated learning.

æè¦ï¼å¤§åèªè¨æ¨¡åæ­£è¿éç²å¾æ®åï¼ä¸¦å·²å»£æ³æç¨æ¼å¯¦éæç¨ä¸­ãåç®¡è¨ç·´è³æçåè³ªè³ééè¦ï¼ä½å¨è³ææ¶ééç¨ä¸­å»ç¢çäºé±ç§åé¡ãè¯é¦å­¸ç¿æä¾äºä¸ç¨®è§£æ±ºæ¹æ¡ï¼åè¨±å¤åç¨æ¶ç«¯å¨ä¸å±äº«æ¬å°è³æçææ³ä¸åä½è¨ç·´ LLMãç¶èï¼FL å¼å¥äºæ°çææ°ï¼ä¾å¦ç±æ¼ç°è³ªè³æåé«éè¨ææ¬èç¢ççæ¨¡åæ¶æåé¡ãéè¦é²è¡ä¸é å¨é¢ç ç©¶ä¾è§£æ±ºéäºææ°ä¸¦æå°æªä¾çç ç©¶ãæ¬æèª¿æ¥äº LLM çè¯é¦å­¸ç¿ (FedLLM)ï¼éé»ä»ç´¹äºè¿æçé²å±åæªä¾çæ¹åãæåå°æ³¨æ¼å©åééµæ¹é¢ï¼å¨è¯é¦è¨­å®ä¸­é²è¡å¾®èª¿åæç¤ºå­¸ç¿ï¼è¨è«ç¾æå·¥ä½åç¸éçç ç©¶ææ°ãæå¾ï¼æåéå°è¯é¦ LLM æåºæ½å¨çç ç©¶æ¹åï¼åæ¬é è¨ç·´ä»¥å LLM å¦ä½é²ä¸æ­¥å¢å¼·è¯é¦å­¸ç¿ã

##### **Adversarial Federated Consensus Learning for Surface Defect Classification Under Data Heterogeneity in IIoT**
2409.15711v1 by Jixuan Cui, Jun Li, Zhen Mei, Yiyang Ni, Wen Chen, Zengxiang Li

The challenge of data scarcity hinders the application of deep learning in
industrial surface defect classification (SDC), as it's difficult to collect
and centralize sufficient training data from various entities in Industrial
Internet of Things (IIoT) due to privacy concerns. Federated learning (FL)
provides a solution by enabling collaborative global model training across
clients while maintaining privacy. However, performance may suffer due to data
heterogeneity--discrepancies in data distributions among clients. In this
paper, we propose a novel personalized FL (PFL) approach, named Adversarial
Federated Consensus Learning (AFedCL), for the challenge of data heterogeneity
across different clients in SDC. First, we develop a dynamic consensus
construction strategy to mitigate the performance degradation caused by data
heterogeneity. Through adversarial training, local models from different
clients utilize the global model as a bridge to achieve distribution alignment,
alleviating the problem of global knowledge forgetting. Complementing this
strategy, we propose a consensus-aware aggregation mechanism. It assigns
aggregation weights to different clients based on their efficacy in global
knowledge learning, thereby enhancing the global model's generalization
capabilities. Finally, we design an adaptive feature fusion module to further
enhance global knowledge utilization efficiency. Personalized fusion weights
are gradually adjusted for each client to optimally balance global and local
features, tailored to their individual global knowledge learning efficacy.
Compared with state-of-the-art FL methods like FedALA, the proposed AFedCL
method achieves an accuracy increase of up to 5.67% on three SDC datasets.

æè¦ï¼<paragraph>è³æç¨å°çææ°é»ç¤äºæ·±åº¦å­¸ç¿å¨å·¥æ¥­è¡¨é¢ç¼ºé·åé¡ (SDC) ä¸­çæç¨ï¼å çºç±æ¼é±ç§åé¡ï¼é£ä»¥å¾å·¥æ¥­ç©è¯ç¶² (IIoT) ä¸­çååå¯¦é«æ¶éåéä¸­è¶³å¤ çè¨ç·´è³æãè¯é¦å­¸ç¿ (FL) æä¾äºä¸åè§£æ±ºæ¹æ¡ï¼å®è®å®¢æ¶ç«¯è½å¤ é²è¡åä½å¼å¨çæ¨¡åè¨ç·´ï¼åæç¶­è­·é±ç§ãç¶èï¼ç±æ¼è³æç°è³ªæ§ï¼å³å®¢æ¶ç«¯ä¹éè³æåä½çå·®ç°ï¼æè½å¯è½æåå°å½±é¿ãå¨æ¬æä¸­ï¼æåæåºäºä¸ç¨®åçºå°æè¯é¦å±è­å­¸ç¿ (AFedCL) çæ°åæ§å FL (PFL) æ¹æ³ï¼ç¨æ¼è§£æ±º SDC ä¸­ä¸åå®¢æ¶ç«¯ä¹éè³æç°è³ªæ§çææ°ãé¦åï¼æåéç¼äºä¸ç¨®åæå±è­æ§å»ºç­ç¥ï¼ä»¥æ¸è¼è³æç°è³ªæ§é æçæè½ä¸éãééå°æè¨ç·´ï¼ä¾èªä¸åå®¢æ¶ç«¯çæ¬å°æ¨¡åå©ç¨å¨çæ¨¡åä½çºæ©æ¨ä¾å¯¦ç¾åä½å°é½ï¼ç·©è§£äºå¨çç¥è­éºå¿çåé¡ãçºäºè£åæ­¤ç­ç¥ï¼æåæåºäºä¸åå±è­æç¥èåæ©å¶ãå®æ ¹æä¸åå®¢æ¶ç«¯å¨å¨çç¥è­å­¸ç¿ä¸­çæè½çºå¶åéèåæ¬éï¼å¾èå¢å¼·å¨çæ¨¡åçæ¦åè½åãæå¾ï¼æåè¨­è¨äºä¸åèªé©æç¹å¾µèåæ¨¡çµï¼ä»¥é²ä¸æ­¥æé«å¨çç¥è­å©ç¨æçãéå°æ¯åå®¢æ¶ç«¯éæ¼¸èª¿æ´åæ§åèåæ¬éï¼ä»¥æä½³å¹³è¡¡å¨çåæ¬å°ç¹å¾µï¼ä¸¦æ ¹æå¶åå¥çå¨çç¥è­å­¸ç¿æè½é²è¡èª¿æ´ãè FedALA ç­æåé²ç FL æ¹æ³ç¸æ¯ï¼ææåºç AFedCL æ¹æ³å¨ä¸å SDC è³æéä¸å¯¦ç¾äºé«é 5.67% çæºç¢ºåº¦æåã</paragraph>

