{"2501.05783": {"publish_time": "2025-01-10", "title": "UV-Attack: Physical-World Adversarial Attacks for Person Detection via Dynamic-NeRF-based UV Mapping", "paper_summary": "In recent research, adversarial attacks on person detectors using patches or\nstatic 3D model-based texture modifications have struggled with low success\nrates due to the flexible nature of human movement. Modeling the 3D\ndeformations caused by various actions has been a major challenge. Fortunately,\nadvancements in Neural Radiance Fields (NeRF) for dynamic human modeling offer\nnew possibilities. In this paper, we introduce UV-Attack, a groundbreaking\napproach that achieves high success rates even with extensive and unseen human\nactions. We address the challenge above by leveraging dynamic-NeRF-based UV\nmapping. UV-Attack can generate human images across diverse actions and\nviewpoints, and even create novel actions by sampling from the SMPL parameter\nspace. While dynamic NeRF models are capable of modeling human bodies,\nmodifying clothing textures is challenging because they are embedded in neural\nnetwork parameters. To tackle this, UV-Attack generates UV maps instead of RGB\nimages and modifies the texture stacks. This approach enables real-time texture\nedits and makes the attack more practical. We also propose a novel Expectation\nover Pose Transformation loss (EoPT) to improve the evasion success rate on\nunseen poses and views. Our experiments show that UV-Attack achieves a 92.75%\nattack success rate against the FastRCNN model across varied poses in dynamic\nvideo settings, significantly outperforming the state-of-the-art AdvCamou\nattack, which only had a 28.50% ASR. Moreover, we achieve 49.5% ASR on the\nlatest YOLOv8 detector in black-box settings. This work highlights the\npotential of dynamic NeRF-based UV mapping for creating more effective\nadversarial attacks on person detectors, addressing key challenges in modeling\nhuman movement and texture modification.", "paper_summary_zh": "<paragraph>\u5728\u6700\u8fd1\u7684\u7814\u7a76\u4e2d\uff0c\u4f7f\u7528\u8cbc\u7247\u6216\u975c\u614b 3D \u6a21\u578b\u70ba\u57fa\u790e\u7684\u7d0b\u7406\u4fee\u6539\u5c0d\u4eba\u7269\u5075\u6e2c\u5668\u7684\u5c0d\u6297\u6027\u653b\u64ca\uff0c\u7531\u65bc\u4eba\u985e\u52d5\u4f5c\u7684\u9748\u6d3b\u6027\u800c\u96e3\u4ee5\u7372\u5f97\u9ad8\u6210\u529f\u7387\u3002\u5efa\u6a21\u7531\u5404\u7a2e\u52d5\u4f5c\u9020\u6210\u7684 3D \u8b8a\u5f62\u4e00\u76f4\u662f\u4e00\u9805\u91cd\u5927\u6311\u6230\u3002\u5e78\u904b\u7684\u662f\uff0c\u795e\u7d93\u8f3b\u5c04\u5834 (NeRF) \u5728\u52d5\u614b\u4eba\u985e\u5efa\u6a21\u65b9\u9762\u7684\u9032\u6b65\u70ba\u6211\u5011\u63d0\u4f9b\u4e86\u65b0\u7684\u53ef\u80fd\u6027\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u4ecb\u7d39\u4e86 UV-Attack\uff0c\u9019\u662f\u4e00\u7a2e\u7a81\u7834\u6027\u7684\u65b9\u6cd5\uff0c\u5373\u4f7f\u5728\u5ee3\u6cdb\u4e14\u672a\u77e5\u7684\u4eba\u985e\u52d5\u4f5c\u4e0b\u4e5f\u80fd\u9054\u5230\u9ad8\u6210\u529f\u7387\u3002\u6211\u5011\u901a\u904e\u5229\u7528\u57fa\u65bc\u52d5\u614b NeRF \u7684 UV \u5c0d\u61c9\u4f86\u89e3\u6c7a\u4e0a\u8ff0\u6311\u6230\u3002UV-Attack \u53ef\u4ee5\u751f\u6210\u8de8\u8d8a\u4e0d\u540c\u52d5\u4f5c\u548c\u8996\u89d2\u7684\u4eba\u985e\u5f71\u50cf\uff0c\u751a\u81f3\u53ef\u4ee5\u900f\u904e\u5f9e SMPL \u53c3\u6578\u7a7a\u9593\u4e2d\u53d6\u6a23\u4f86\u5275\u9020\u65b0\u52d5\u4f5c\u3002\u96d6\u7136\u52d5\u614b NeRF \u6a21\u578b\u80fd\u5920\u5efa\u6a21\u4eba\u9ad4\uff0c\u4f46\u4fee\u6539\u670d\u88dd\u7d0b\u7406\u5177\u6709\u6311\u6230\u6027\uff0c\u56e0\u70ba\u5b83\u5011\u5d4c\u5165\u5728\u795e\u7d93\u7db2\u8def\u53c3\u6578\u4e2d\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0cUV-Attack \u751f\u6210\u4e86 UV \u5c0d\u61c9\u800c\u4e0d\u662f RGB \u5f71\u50cf\uff0c\u4e26\u4fee\u6539\u4e86\u7d0b\u7406\u5806\u758a\u3002\u9019\u7a2e\u65b9\u6cd5\u5141\u8a31\u5373\u6642\u7d0b\u7406\u7de8\u8f2f\uff0c\u4e26\u4f7f\u653b\u64ca\u66f4\u5177\u5be6\u7528\u6027\u3002\u6211\u5011\u9084\u63d0\u51fa\u4e86\u4e00\u500b\u65b0\u7684\u59ff\u52e2\u8f49\u63db\u640d\u5931\u671f\u671b (EoPT)\uff0c\u4ee5\u63d0\u9ad8\u5728\u672a\u77e5\u59ff\u52e2\u548c\u8996\u89d2\u4e0a\u7684\u898f\u907f\u6210\u529f\u7387\u3002\u6211\u5011\u7684\u5be6\u9a57\u8868\u660e\uff0cUV-Attack \u5728\u52d5\u614b\u8996\u8a0a\u8a2d\u5b9a\u4e2d\u91dd\u5c0d FastRCNN \u6a21\u578b\u9054\u5230\u4e86 92.75% \u7684\u653b\u64ca\u6210\u529f\u7387\uff0c\u986f\u8457\u512a\u65bc\u6700\u5148\u9032\u7684 AdvCamou \u653b\u64ca\uff0c\u5f8c\u8005\u7684 ASR \u50c5\u70ba 28.50%\u3002\u6b64\u5916\uff0c\u6211\u5011\u5728\u9ed1\u76d2\u8a2d\u5b9a\u4e2d\u91dd\u5c0d\u6700\u65b0\u7684 YOLOv8 \u5075\u6e2c\u5668\u9054\u5230\u4e86 49.5% \u7684 ASR\u3002\u9019\u9805\u5de5\u4f5c\u7a81\u986f\u4e86\u57fa\u65bc\u52d5\u614b NeRF \u7684 UV \u5c0d\u61c9\u5728\u5275\u9020\u66f4\u6709\u6548\u5c0d\u6297\u4eba\u7269\u5075\u6e2c\u5668\u7684\u653b\u64ca\u65b9\u9762\u7684\u6f5b\u529b\uff0c\u89e3\u6c7a\u4e86\u5efa\u6a21\u4eba\u985e\u52d5\u4f5c\u548c\u7d0b\u7406\u4fee\u6539\u4e2d\u7684\u95dc\u9375\u6311\u6230\u3002</paragraph>", "author": "Yanjie Li et.al.", "authors": "Yanjie Li, Wenxuan Zhang, Kaisheng Liang, Bin Xiao", "id": "2501.05783v1", "paper_url": "http://arxiv.org/abs/2501.05783v1", "repo": "null"}}