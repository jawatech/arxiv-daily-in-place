
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-06-06**|**Verbalized Machine Learning: Revisiting Machine Learning with Language Models**|Tim Z. Xiao et.al.|[2406.04344v1](http://arxiv.org/abs/2406.04344v1)|null|
|**2024-06-06**|**Physics3D: Learning Physical Properties of 3D Gaussians via Video Diffusion**|Fangfu Liu et.al.|[2406.04338v2](http://arxiv.org/abs/2406.04338v2)|null|
|**2024-06-06**|**Coherent Zero-Shot Visual Instruction Generation**|Quynh Phung et.al.|[2406.04337v1](http://arxiv.org/abs/2406.04337v1)|null|
|**2024-06-06**|**PaCE: Parsimonious Concept Engineering for Large Language Models**|Jinqi Luo et.al.|[2406.04331v1](http://arxiv.org/abs/2406.04331v1)|[link](https://github.com/peterljq/parsimonious-concept-engineering)|
|**2024-06-06**|**ATraDiff: Accelerating Online Reinforcement Learning with Imaginary Trajectories**|Qianlan Yang et.al.|[2406.04323v1](http://arxiv.org/abs/2406.04323v1)|null|
|**2024-06-06**|**Chimera: Effectively Modeling Multivariate Time Series with 2-Dimensional State Space Models**|Ali Behrouz et.al.|[2406.04320v1](http://arxiv.org/abs/2406.04320v1)|null|
|**2024-06-06**|**Improving Alignment and Robustness with Short Circuiting**|Andy Zou et.al.|[2406.04313v1](http://arxiv.org/abs/2406.04313v1)|[link](https://github.com/blackswan-ai/short-circuiting)|
|**2024-06-06**|**Semantically Diverse Language Generation for Uncertainty Estimation in Language Models**|Lukas Aichberger et.al.|[2406.04306v1](http://arxiv.org/abs/2406.04306v1)|[link](https://github.com/ml-jku/SDLG)|
|**2024-06-06**|**Vision-LSTM: xLSTM as Generic Vision Backbone**|Benedikt Alkin et.al.|[2406.04303v1](http://arxiv.org/abs/2406.04303v1)|null|
|**2024-06-06**|**VISTA: Visualized Text Embedding For Universal Multi-Modal Retrieval**|Junjie Zhou et.al.|[2406.04292v1](http://arxiv.org/abs/2406.04292v1)|[link](https://github.com/flagopen/flagembedding)|
|**2024-06-06**|**What Languages are Easy to Language-Model? A Perspective from Learning Probabilistic Regular Languages**|Nadav Borenstein et.al.|[2406.04289v2](http://arxiv.org/abs/2406.04289v2)|null|
|**2024-06-06**|**ABEX: Data Augmentation for Low-Resource NLU via Expanding Abstract Descriptions**|Sreyan Ghosh et.al.|[2406.04286v1](http://arxiv.org/abs/2406.04286v1)|[link](https://github.com/sreyan88/abex)|
|**2024-06-06**|**Characterizing Similarities and Divergences in Conversational Tones in Humans and LLMs by Sampling with People**|Dun-Ming Huang et.al.|[2406.04278v1](http://arxiv.org/abs/2406.04278v1)|[link](https://github.com/jacobyn/SamplingTonesACL)|
|**2024-06-06**|**Generative AI-in-the-loop: Integrating LLMs and GPTs into the Next Generation Networks**|Han Zhang et.al.|[2406.04276v1](http://arxiv.org/abs/2406.04276v1)|null|
|**2024-06-06**|**Self-Play with Adversarial Critic: Provable and Scalable Offline Alignment for Language Models**|Xiang Ji et.al.|[2406.04274v1](http://arxiv.org/abs/2406.04274v1)|null|
|**2024-06-06**|**Buffer of Thoughts: Thought-Augmented Reasoning with Large Language Models**|Ling Yang et.al.|[2406.04271v1](http://arxiv.org/abs/2406.04271v1)|[link](https://github.com/yangling0818/buffer-of-thought-llm)|
|**2024-06-06**|**Open-Endedness is Essential for Artificial Superhuman Intelligence**|Edward Hughes et.al.|[2406.04268v1](http://arxiv.org/abs/2406.04268v1)|null|
|**2024-06-06**|**Transformers need glasses! Information over-squashing in language tasks**|Federico Barbero et.al.|[2406.04267v1](http://arxiv.org/abs/2406.04267v1)|null|
|**2024-06-06**|**MLVU: A Comprehensive Benchmark for Multi-Task Long Video Understanding**|Junjie Zhou et.al.|[2406.04264v1](http://arxiv.org/abs/2406.04264v1)|null|
|**2024-06-06**|**GeoGen: Geometry-Aware Generative Modeling via Signed Distance Functions**|Salvatore Esposito et.al.|[2406.04254v2](http://arxiv.org/abs/2406.04254v2)|null|
|**2024-06-06**|**Benchmark Data Contamination of Large Language Models: A Survey**|Cheng Xu et.al.|[2406.04244v1](http://arxiv.org/abs/2406.04244v1)|null|
|**2024-06-06**|**Hypernetworks for Personalizing ASR to Atypical Speech**|Max Mueller-Eberstein et.al.|[2406.04240v2](http://arxiv.org/abs/2406.04240v2)|null|
|**2024-06-06**|**FairytaleQA Translated: Enabling Educational Question and Answer Generation in Less-Resourced Languages**|Bernardo Leite et.al.|[2406.04233v1](http://arxiv.org/abs/2406.04233v1)|[link](https://github.com/bernardoleite/fairytaleqa-translated)|
|**2024-06-06**|**Quantifying Misalignment Between Agents**|Aidan Kierans et.al.|[2406.04231v1](http://arxiv.org/abs/2406.04231v1)|null|
|**2024-06-06**|**M3LEO: A Multi-Modal, Multi-Label Earth Observation Dataset Integrating Interferometric SAR and RGB Data**|Matthew J Allen et.al.|[2406.04230v1](http://arxiv.org/abs/2406.04230v1)|[link](https://github.com/spaceml-org/m3leo)|
|**2024-06-06**|**The CLRS-Text Algorithmic Reasoning Language Benchmark**|Larisa Markeeva et.al.|[2406.04229v1](http://arxiv.org/abs/2406.04229v1)|[link](https://github.com/google-deepmind/clrs)|
|**2024-06-06**|**BEADs: Bias Evaluation Across Domains**|Shaina Raza et.al.|[2406.04220v2](http://arxiv.org/abs/2406.04220v2)|null|
|**2024-06-06**|**Rethinking LLM and Linguistic Steganalysis: An Efficient Detection of Strongly Concealed Stego**|Yifan Tang et.al.|[2406.04218v1](http://arxiv.org/abs/2406.04218v1)|null|
|**2024-06-06**|**What Do Language Models Learn in Context? The Structured Task Hypothesis**|Jiaoda Li et.al.|[2406.04216v1](http://arxiv.org/abs/2406.04216v1)|null|
|**2024-06-06**|**mCSQA: Multilingual Commonsense Reasoning Dataset with Unified Creation Strategy by Language Models and Humans**|Yusuke Sakai et.al.|[2406.04215v1](http://arxiv.org/abs/2406.04215v1)|null|
|**2024-06-06**|**ValueBench: Towards Comprehensively Evaluating Value Orientations and Understanding of Large Language Models**|Yuanyi Ren et.al.|[2406.04214v1](http://arxiv.org/abs/2406.04214v1)|[link](https://github.com/value4ai/valuebench)|
|**2024-06-06**|**Aligning Agents like Large Language Models**|Adam Jelley et.al.|[2406.04208v1](http://arxiv.org/abs/2406.04208v1)|null|
|**2024-06-06**|**Legal Documents Drafting with Fine-Tuned Pre-Trained Large Language Model**|Chun-Hsien Lin et.al.|[2406.04202v1](http://arxiv.org/abs/2406.04202v1)|[link](https://huggingface.co/jslin09/bloom-560m-finetuned-fraud)|
|**2024-06-06**|**DICE: Detecting In-distribution Contamination in LLM's Fine-tuning Phase for Math Reasoning**|Shangqing Tu et.al.|[2406.04197v1](http://arxiv.org/abs/2406.04197v1)|[link](https://github.com/thu-keg/dice)|
|**2024-06-06**|**Shield Synthesis for LTL Modulo Theories**|Andoni Rodriguez et.al.|[2406.04184v1](http://arxiv.org/abs/2406.04184v1)|null|
|**2024-06-06**|**Confabulation: The Surprising Value of Large Language Model Hallucinations**|Peiqi Sui et.al.|[2406.04175v1](http://arxiv.org/abs/2406.04175v1)|null|
|**2024-06-06**|**Pointer-Guided Pre-Training: Infusing Large Language Models with Paragraph-Level Contextual Awareness**|Lars Hillebrand et.al.|[2406.04156v1](http://arxiv.org/abs/2406.04156v1)|[link](https://github.com/LarsHill/pointer-guided-pre-training)|
|**2024-06-06**|**AgentGym: Evolving Large Language Model-based Agents across Diverse Environments**|Zhiheng Xi et.al.|[2406.04151v1](http://arxiv.org/abs/2406.04151v1)|[link](https://github.com/woooodyy/agentgym)|
|**2024-06-06**|**Characterizing segregation in blast rock piles a deep-learning approach leveraging aerial image analysis**|Chengeng Liu et.al.|[2406.04149v1](http://arxiv.org/abs/2406.04149v1)|null|
|**2024-06-06**|**Towards Understanding Task-agnostic Debiasing Through the Lenses of Intrinsic Bias and Forgetfulness**|Guangliang Liu et.al.|[2406.04146v1](http://arxiv.org/abs/2406.04146v1)|null|
|**2024-06-06**|**Every Answer Matters: Evaluating Commonsense with Probabilistic Measures**|Qi Cheng et.al.|[2406.04145v1](http://arxiv.org/abs/2406.04145v1)|null|
|**2024-06-06**|**Do Language Models Understand Morality? Towards a Robust Detection of Moral Content**|Luana Bulla et.al.|[2406.04143v1](http://arxiv.org/abs/2406.04143v1)|[link](https://github.com/LuanaBulla/Detection-of-Morality-in-Text)|
|**2024-06-06**|**Legal Judgment Reimagined: PredEx and the Rise of Intelligent AI Interpretation in Indian Courts**|Shubham Kumar Nigam et.al.|[2406.04136v1](http://arxiv.org/abs/2406.04136v1)|null|
|**2024-06-06**|**Are We Done with MMLU?**|Aryo Pradipta Gema et.al.|[2406.04127v2](http://arxiv.org/abs/2406.04127v2)|null|
|**2024-06-06**|**Promoting Fairness and Diversity in Speech Datasets for Mental Health and Neurological Disorders Research**|Eleonora Mancini et.al.|[2406.04116v1](http://arxiv.org/abs/2406.04116v1)|null|
|**2024-06-06**|**Uncovering Limitations of Large Language Models in Information Seeking from Tables**|Chaoxu Pang et.al.|[2406.04113v1](http://arxiv.org/abs/2406.04113v1)|[link](https://github.com/coszero/TabIS)|
|**2024-06-06**|**Compressible Dynamics in Deep Overparameterized Low-Rank Learning & Adaptation**|Can Yaras et.al.|[2406.04112v1](http://arxiv.org/abs/2406.04112v1)|[link](https://github.com/cjyaras/deep-lora-transformers)|
|**2024-06-06**|**Intention and Face in Dialog**|Adil Soubki et.al.|[2406.04109v1](http://arxiv.org/abs/2406.04109v1)|[link](https://github.com/cogstates/2024-lrec-coling-faceacts)|
|**2024-06-06**|**Explainability and Hate Speech: Structured Explanations Make Social Media Moderators Faster**|Agostina Calabrese et.al.|[2406.04106v1](http://arxiv.org/abs/2406.04106v1)|[link](https://github.com/Ago3/structured_explanations_make_moderators_faster)|
|**2024-06-06**|**Multistep Distillation of Diffusion Models via Moment Matching**|Tim Salimans et.al.|[2406.04103v1](http://arxiv.org/abs/2406.04103v1)|null|
|**2024-06-06**|**Enhancing Weather Predictions: Super-Resolution via Deep Diffusion Models**|Jan Martin≈Ø et.al.|[2406.04099v1](http://arxiv.org/abs/2406.04099v1)|null|
|**2024-06-06**|**Scaling and evaluating sparse autoencoders**|Leo Gao et.al.|[2406.04093v1](http://arxiv.org/abs/2406.04093v1)|[link](https://github.com/openai/sparse_autoencoder)|
|**2024-06-06**|**On Limitation of Transformer for Learning HMMs**|Jiachen Hu et.al.|[2406.04089v1](http://arxiv.org/abs/2406.04089v1)|null|
|**2024-06-06**|**Batch-in-Batch: a new adversarial training framework for initial perturbation and sample selection**|Yinting Wu et.al.|[2406.04070v1](http://arxiv.org/abs/2406.04070v1)|[link](https://github.com/Yinting-Wu/Batch-in-Batch)|
|**2024-06-06**|**Ask LLMs Directly, "What shapes your bias?": Measuring Social Bias in Large Language Models**|Jisu Shin et.al.|[2406.04064v1](http://arxiv.org/abs/2406.04064v1)|null|
|**2024-06-06**|**Leveraging SPD Matrices on Riemannian Manifolds in Quantum Classical Hybrid Models for Structural Health Monitoring**|Azadeh Alavi et.al.|[2406.04055v1](http://arxiv.org/abs/2406.04055v1)|null|
|**2024-06-06**|**Multivector Neurons: Better and Faster O(n)-Equivariant Clifford Graph Neural Networks**|Cong Liu et.al.|[2406.04052v1](http://arxiv.org/abs/2406.04052v1)|[link](https://github.com/congliuUvA/Multivector-Neurons)|
|**2024-06-06**|**ActionReasoningBench: Reasoning about Actions with and without Ramification Constraints**|Divij Handa et.al.|[2406.04046v1](http://arxiv.org/abs/2406.04046v1)|null|
|**2024-06-06**|**Shaping History: Advanced Machine Learning Techniques for the Analysis and Dating of Cuneiform Tablets over Three Millennia**|Danielle Kapon et.al.|[2406.04039v1](http://arxiv.org/abs/2406.04039v1)|null|
|**2024-06-06**|**Spatio-temporal Early Prediction based on Multi-objective Reinforcement Learning**|Wei Shao et.al.|[2406.04035v1](http://arxiv.org/abs/2406.04035v1)|[link](https://github.com/coco0106/MO-STEP)|
|**2024-06-06**|**Pre-trained Transformer Uncovers Meaningful Patterns in Human Mobility Data**|Alameen Najjar et.al.|[2406.04029v1](http://arxiv.org/abs/2406.04029v1)|null|
|**2024-06-06**|**The syntax-semantics interface in a child's path: A study of 3- to 11-year-olds' elicited production of Mandarin recursive relative clauses**|Caimei Yang et.al.|[2406.04025v1](http://arxiv.org/abs/2406.04025v1)|null|
|**2024-06-06**|**American Sign Language Handshapes Reflect Pressures for Communicative Efficiency**|Kayo Yin et.al.|[2406.04024v1](http://arxiv.org/abs/2406.04024v1)|null|
|**2024-06-06**|**HackAtari: Atari Learning Environments for Robust and Continual Reinforcement Learning**|Quentin Delfosse et.al.|[2406.03997v1](http://arxiv.org/abs/2406.03997v1)|[link](https://github.com/k4ntz/HackAtari)|
|**2024-06-06**|**AC4MPC: Actor-Critic Reinforcement Learning for Nonlinear Model Predictive Control**|Rudolf Reiter et.al.|[2406.03995v1](http://arxiv.org/abs/2406.03995v1)|null|
|**2024-06-06**|**Assessing LLMs for Zero-shot Abstractive Summarization Through the Lens of Relevance Paraphrasing**|Hadi Askari et.al.|[2406.03993v1](http://arxiv.org/abs/2406.03993v1)|null|
|**2024-06-06**|**On The Persona-based Summarization of Domain-Specific Documents**|Ankan Mullick et.al.|[2406.03986v1](http://arxiv.org/abs/2406.03986v1)|[link](https://github.com/ankan2/persona-healthcare)|
|**2024-06-06**|**A + B: A General Generator-Reader Framework for Optimizing LLMs to Unleash Synergy Potential**|Wei Tang et.al.|[2406.03963v1](http://arxiv.org/abs/2406.03963v1)|null|
|**2024-06-06**|**Tox-BART: Leveraging Toxicity Attributes for Explanation Generation of Implicit Hate Speech**|Neemesh Yadav et.al.|[2406.03953v1](http://arxiv.org/abs/2406.03953v1)|null|
|**2024-06-06**|**UltraMedical: Building Specialized Generalists in Biomedicine**|Kaiyan Zhang et.al.|[2406.03949v1](http://arxiv.org/abs/2406.03949v1)|[link](https://github.com/tsinghuac3i/ultramedical)|
|**2024-06-06**|**Culturally Aware and Adapted NLP: A Taxonomy and a Survey of the State of the Art**|Chen Cecilia Liu et.al.|[2406.03930v1](http://arxiv.org/abs/2406.03930v1)|null|
|**2024-06-06**|**Vectorized Conditional Neural Fields: A Framework for Solving Time-dependent Parametric Partial Differential Equations**|Jan Hagnberger et.al.|[2406.03919v1](http://arxiv.org/abs/2406.03919v1)|[link](https://github.com/jhagnberger/vcnef)|
|**2024-06-06**|**ArMeme: Propagandistic Content in Arabic Memes**|Firoj Alam et.al.|[2406.03916v1](http://arxiv.org/abs/2406.03916v1)|null|
|**2024-06-06**|**GenSafe: A Generalizable Safety Enhancer for Safe Reinforcement Learning Algorithms Based on Reduced Order Markov Decision Process Model**|Zhehua Zhou et.al.|[2406.03912v1](http://arxiv.org/abs/2406.03912v1)|null|
|**2024-06-06**|**HeSum: a Novel Dataset for Abstractive Text Summarization in Hebrew**|Tzuf Paz-Argaman et.al.|[2406.03897v1](http://arxiv.org/abs/2406.03897v1)|[link](https://github.com/OnlpLab/HeSum)|
|**2024-06-06**|**How Good is Zero-Shot MT Evaluation for Low Resource Indian Languages?**|Anushka Singh et.al.|[2406.03893v1](http://arxiv.org/abs/2406.03893v1)|null|
|**2024-06-06**|**Spontaneous Speech-Based Suicide Risk Detection Using Whisper and Large Language Models**|Ziyun Cui et.al.|[2406.03882v1](http://arxiv.org/abs/2406.03882v1)|null|
|**2024-06-06**|**Evaluating the IWSLT2023 Speech Translation Tasks: Human Annotations, Automatic Metrics, and Segmentation**|Matthias Sperber et.al.|[2406.03881v1](http://arxiv.org/abs/2406.03881v1)|null|
|**2024-06-06**|**Memorization in deep learning: A survey**|Jiaheng Wei et.al.|[2406.03880v1](http://arxiv.org/abs/2406.03880v1)|null|
|**2024-06-06**|**Decoder-only Streaming Transformer for Simultaneous Translation**|Shoutao Guo et.al.|[2406.03878v1](http://arxiv.org/abs/2406.03878v1)|[link](https://github.com/ictnlp/DST)|
|**2024-06-06**|**Quantum Implicit Neural Representations**|Jiaming Zhao et.al.|[2406.03873v1](http://arxiv.org/abs/2406.03873v1)|[link](https://github.com/GGorMM1/QIREN)|
|**2024-06-06**|**BLSP-Emo: Towards Empathetic Large Speech-Language Models**|Chen Wang et.al.|[2406.03872v1](http://arxiv.org/abs/2406.03872v1)|[link](https://github.com/cwang621/blsp-emo)|
|**2024-06-06**|**Recovering document annotations for sentence-level bitext**|Rachel Wicks et.al.|[2406.03869v1](http://arxiv.org/abs/2406.03869v1)|null|
|**2024-06-06**|**Semantic Similarity Score for Measuring Visual Similarity at Semantic Level**|Senran Fan et.al.|[2406.03865v1](http://arxiv.org/abs/2406.03865v1)|null|
|**2024-06-06**|**MuJo: Multimodal Joint Feature Space Learning for Human Activity Recognition**|Stefan Gerd Fritsch et.al.|[2406.03857v1](http://arxiv.org/abs/2406.03857v1)|null|
|**2024-06-06**|**Performance of large language models in numerical vs. semantic medical knowledge: Benchmarking on evidence-based Q&As**|Eden Avnat et.al.|[2406.03855v1](http://arxiv.org/abs/2406.03855v1)|null|
|**2024-06-06**|**Speculative Decoding via Early-exiting for Faster LLM Inference with Thompson Sampling Control Mechanism**|Jiahao Liu et.al.|[2406.03853v1](http://arxiv.org/abs/2406.03853v1)|null|
|**2024-06-06**|**Lean Workbook: A large-scale Lean problem set formalized from natural language math problems**|Huaiyuan Ying et.al.|[2406.03847v2](http://arxiv.org/abs/2406.03847v2)|[link](https://github.com/internlm/internlm-math)|
|**2024-06-06**|**POEM: Interactive Prompt Optimization for Enhancing Multimodal Reasoning of Large Language Models**|Jianben He et.al.|[2406.03843v1](http://arxiv.org/abs/2406.03843v1)|null|
|**2024-06-06**|**Proactive Detection of Physical Inter-rule Vulnerabilities in IoT Services Using a Deep Learning Approach**|Bing Huang et.al.|[2406.03836v1](http://arxiv.org/abs/2406.03836v1)|null|
|**2024-06-06**|**Chaos with Keywords: Exposing Large Language Models Sycophancy to Misleading Keywords and Evaluating Defense Strategies**|Aswin RRV et.al.|[2406.03827v1](http://arxiv.org/abs/2406.03827v1)|[link](https://github.com/3rdAT/ChaosWithKeywords)|
|**2024-06-06**|**A Survey on Intelligent Internet of Things: Applications, Security, Privacy, and Future Directions**|Ons Aouedi et.al.|[2406.03820v1](http://arxiv.org/abs/2406.03820v1)|null|
|**2024-06-06**|**ReST-MCTS*: LLM Self-Training via Process Reward Guided Tree Search**|Dan Zhang et.al.|[2406.03816v1](http://arxiv.org/abs/2406.03816v1)|[link](https://github.com/THUDM/ReST-MCTS)|
|**2024-06-06**|**Improving Zero-Shot Chinese-English Code-Switching ASR with kNN-CTC and Gated Monolingual Datastores**|Jiaming Zhou et.al.|[2406.03814v1](http://arxiv.org/abs/2406.03814v1)|null|
|**2024-06-06**|**Cross-variable Linear Integrated ENhanced Transformer for Photovoltaic power forecasting**|Jiaxin Gao et.al.|[2406.03808v1](http://arxiv.org/abs/2406.03808v1)|null|
|**2024-06-06**|**Tool-Planner: Dynamic Solution Tree Planning for Large Language Model with Tool Clustering**|Yanming Liu et.al.|[2406.03807v1](http://arxiv.org/abs/2406.03807v1)|null|
|**2024-06-06**|**Enhanced Semantic Segmentation Pipeline for WeatherProof Dataset Challenge**|Nan Zhang et.al.|[2406.03799v2](http://arxiv.org/abs/2406.03799v2)|[link](https://github.com/kaneigi/weatherproofchallenge)|
|**2024-06-06**|**Light-PEFT: Lightening Parameter-Efficient Fine-Tuning via Early Pruning**|Naibin Gu et.al.|[2406.03792v1](http://arxiv.org/abs/2406.03792v1)|null|
|**2024-06-06**|**End-to-End Trainable Soft Retriever for Low-resource Relation Extraction**|Kohei Makino et.al.|[2406.03790v1](http://arxiv.org/abs/2406.03790v1)|null|
|**2024-06-06**|**Enhancing Graph U-Nets for Mesh-Agnostic Spatio-Temporal Flow Prediction**|Sunwoong Yang et.al.|[2406.03789v1](http://arxiv.org/abs/2406.03789v1)|null|

#### Abstracts
##### **Verbalized Machine Learning: Revisiting Machine Learning with Language Models**
2406.04344v1 by Tim Z. Xiao, Robert Bamler, Bernhard Sch√∂lkopf, Weiyang Liu

Motivated by the large progress made by large language models (LLMs), we
introduce the framework of verbalized machine learning (VML). In contrast to
conventional machine learning models that are typically optimized over a
continuous parameter space, VML constrains the parameter space to be
human-interpretable natural language. Such a constraint leads to a new
perspective of function approximation, where an LLM with a text prompt can be
viewed as a function parameterized by the text prompt. Guided by this
perspective, we revisit classical machine learning problems, such as regression
and classification, and find that these problems can be solved by an
LLM-parameterized learner and optimizer. The major advantages of VML include
(1) easy encoding of inductive bias: prior knowledge about the problem and
hypothesis class can be encoded in natural language and fed into the
LLM-parameterized learner; (2) automatic model class selection: the optimizer
can automatically select a concrete model class based on data and verbalized
prior knowledge, and it can update the model class during training; and (3)
interpretable learner updates: the LLM-parameterized optimizer can provide
explanations for why each learner update is performed. We conduct several
studies to empirically evaluate the effectiveness of VML, and hope that VML can
serve as a stepping stone to stronger interpretability and trustworthiness in
ML.

ÊëòË¶ÅÔºöÂèóÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂèñÂæóÁöÑÂ∑®Â§ßÈÄ≤Â±ïÁöÑÊøÄÂãµÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜË®ÄË™ûÂåñÊ©üÂô®Â≠∏Áøí (VML) Ê°ÜÊû∂„ÄÇËàáÈÄöÂ∏∏Âú®ÈÄ£Á∫åÂèÉÊï∏Á©∫Èñì‰∏äÈÄ≤Ë°åÂÑ™ÂåñÁöÑÂÇ≥Áµ±Ê©üÂô®Â≠∏ÁøíÊ®°ÂûãÁõ∏ÊØîÔºåVML Â∞áÂèÉÊï∏Á©∫ÈñìÁ¥ÑÊùüÁÇ∫‰∫∫È°ûÂèØËß£ËÆÄÁöÑËá™ÁÑ∂Ë™ûË®Ä„ÄÇÈÄôÁ®ÆÁ¥ÑÊùüÂ∞éËá¥‰∫ÜÂáΩÊï∏ÈÄºËøëÁöÑÊñ∞ËßÄÈªûÔºåÂÖ∂‰∏≠ÂÖ∑ÊúâÊñáÊú¨ÊèêÁ§∫ÁöÑ LLM ÂèØ‰ª•Ë¢´Ë¶ñÁÇ∫Áî±ÊñáÊú¨ÊèêÁ§∫ÂèÉÊï∏ÂåñÁöÑÂáΩÊï∏„ÄÇÂèóÊ≠§ËßÄÈªûÁöÑÊåáÂ∞éÔºåÊàëÂÄëÈáçÊñ∞ÂØ©Ë¶ñ‰∫ÜÁ∂ìÂÖ∏ÁöÑÊ©üÂô®Â≠∏ÁøíÂïèÈ°åÔºå‰æãÂ¶ÇËø¥Ê≠∏ÂíåÂàÜÈ°ûÔºå‰∏¶ÁôºÁèæÈÄô‰∫õÂïèÈ°åÂèØ‰ª•Áî® LLM ÂèÉÊï∏ÂåñÁöÑÂ≠∏ÁøíÂô®ÂíåÂÑ™ÂåñÂô®‰æÜËß£Ê±∫„ÄÇVML ÁöÑ‰∏ªË¶ÅÂÑ™ÈªûÂåÖÊã¨Ôºö(1) Ê≠∏Á¥çÂÅèË™§ÁöÑÁ∞°‰æøÁ∑®Á¢ºÔºöÈóúÊñºÂïèÈ°åÂíåÂÅáË®≠È°ûÂà•ÁöÑÂÖàÈ©óÁü•Ë≠òÂèØ‰ª•Áî®Ëá™ÁÑ∂Ë™ûË®ÄÁ∑®Á¢º‰∏¶Ëº∏ÂÖ•Âà∞ LLM ÂèÉÊï∏ÂåñÁöÑÂ≠∏ÁøíÂô®‰∏≠Ôºõ(2) Ëá™ÂãïÊ®°ÂûãÈ°ûÂà•ÈÅ∏ÊìáÔºöÂÑ™ÂåñÂô®ÂèØ‰ª•Ê†πÊìöÊï∏ÊìöÂíåË®ÄË™ûÂåñÁöÑÂÖàÈ©óÁü•Ë≠òËá™ÂãïÈÅ∏ÊìáÂÖ∑È´îÁöÑÊ®°ÂûãÈ°ûÂà•Ôºå‰∏¶‰∏îÂèØ‰ª•Âú®Ë®ìÁ∑¥ÊúüÈñìÊõ¥Êñ∞Ê®°ÂûãÈ°ûÂà•Ôºõ(3) ÂèØËß£ÈáãÁöÑÂ≠∏ÁøíÂô®Êõ¥Êñ∞ÔºöLLM ÂèÉÊï∏ÂåñÁöÑÂÑ™ÂåñÂô®ÂèØ‰ª•Êèê‰æõÂ∞çÊØèÂÄãÂ≠∏ÁøíÂô®Êõ¥Êñ∞Âü∑Ë°åÂéüÂõ†ÁöÑËß£Èáã„ÄÇÊàëÂÄëÈÄ≤Ë°å‰∫ÜÂ§öÈ†ÖÁ†îÁ©∂‰ª•ÂØ¶Ë≠âË©ï‰º∞ VML ÁöÑÊúâÊïàÊÄßÔºå‰∏¶Â∏åÊúõ VML ÂèØ‰ª•‰ΩúÁÇ∫ÈÇÅÂêë ML ‰∏≠Êõ¥Âº∑ÁöÑÂèØËß£ÈáãÊÄßÂíåÂèØ‰ø°Â∫¶ÁöÑÂ¢äËÖ≥Áü≥„ÄÇ

##### **Physics3D: Learning Physical Properties of 3D Gaussians via Video Diffusion**
2406.04338v2 by Fangfu Liu, Hanyang Wang, Shunyu Yao, Shengjun Zhang, Jie Zhou, Yueqi Duan

In recent years, there has been rapid development in 3D generation models,
opening up new possibilities for applications such as simulating the dynamic
movements of 3D objects and customizing their behaviors. However, current 3D
generative models tend to focus only on surface features such as color and
shape, neglecting the inherent physical properties that govern the behavior of
objects in the real world. To accurately simulate physics-aligned dynamics, it
is essential to predict the physical properties of materials and incorporate
them into the behavior prediction process. Nonetheless, predicting the diverse
materials of real-world objects is still challenging due to the complex nature
of their physical attributes. In this paper, we propose \textbf{Physics3D}, a
novel method for learning various physical properties of 3D objects through a
video diffusion model. Our approach involves designing a highly generalizable
physical simulation system based on a viscoelastic material model, which
enables us to simulate a wide range of materials with high-fidelity
capabilities. Moreover, we distill the physical priors from a video diffusion
model that contains more understanding of realistic object materials. Extensive
experiments demonstrate the effectiveness of our method with both elastic and
plastic materials. Physics3D shows great potential for bridging the gap between
the physical world and virtual neural space, providing a better integration and
application of realistic physical principles in virtual environments. Project
page: https://liuff19.github.io/Physics3D.

ÊëòË¶ÅÔºöËøëÂπ¥‰æÜÔºå3D ÁîüÊàêÊ®°ÂûãÂø´ÈÄüÁôºÂ±ïÔºåÁÇ∫Ê®°Êì¨ 3D Áâ©È´îÁöÑÂãïÊÖãÈÅãÂãïÂíåÂÆ¢Ë£ΩÂåñÂÖ∂Ë°åÁÇ∫Á≠âÊáâÁî®ÈñãÂïü‰∫ÜÊñ∞ÁöÑÂèØËÉΩÊÄß„ÄÇÁÑ∂ËÄåÔºåÁõÆÂâçÁöÑ 3D ÁîüÊàêÊ®°ÂûãÂæÄÂæÄÂè™ÈóúÊ≥®Ë°®Èù¢ÁâπÂæµÔºå‰æãÂ¶ÇÈ°èËâ≤ÂíåÂΩ¢ÁãÄÔºåËÄåÂøΩÁï•‰∫ÜÊîØÈÖçÁúüÂØ¶‰∏ñÁïå‰∏≠Áâ©È´îË°åÁÇ∫ÁöÑÂõ∫ÊúâÁâ©ÁêÜÁâπÊÄß„ÄÇÁÇ∫‰∫ÜÁ≤æÁ¢∫Ê®°Êì¨ËàáÁâ©ÁêÜÂÆöÂæã‰∏ÄËá¥ÁöÑÂãïÊÖãÔºåÈ†êÊ∏¨ÊùêÊñôÁöÑÁâ©ÁêÜÁâπÊÄß‰∏¶Â∞áÂÖ∂Á¥çÂÖ•Ë°åÁÇ∫È†êÊ∏¨ÈÅéÁ®ã‰∏≠Ëá≥ÈóúÈáçË¶Å„ÄÇÂÑòÁÆ°Â¶ÇÊ≠§ÔºåÁî±ÊñºÁúüÂØ¶‰∏ñÁïåÁâ©È´îÁöÑÁâ©ÁêÜÂ±¨ÊÄßË§áÈõúÔºåÈ†êÊ∏¨ÂÖ∂Â§öÊ®£ÂåñÁöÑÊùêÊñô‰ªçÁÑ∂ÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫ \textbf{Physics3D}Ôºå‰∏ÄÁ®ÆÈÄèÈÅéÂΩ±ÁâáÊì¥Êï£Ê®°ÂûãÂ≠∏Áøí 3D Áâ©È´îÂêÑÁ®ÆÁâ©ÁêÜÁâπÊÄßÁöÑÊñ∞ÊñπÊ≥ï„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÂåÖÊã¨Âü∫ÊñºÁ≤òÂΩàÊÄßÊùêÊñôÊ®°ÂûãË®≠Ë®à‰∏ÄÂÄãÈ´òÂ∫¶ÂèØÊ¶ÇÊã¨ÂåñÁöÑÁâ©ÁêÜÊ®°Êì¨Á≥ªÁµ±Ôºå‰ΩøÊàëÂÄëËÉΩÂ§†‰ª•È´ò‰øùÁúüËÉΩÂäõÊ®°Êì¨ÂêÑÁ®ÆÊùêÊñô„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂæûÂåÖÂê´Êõ¥Â§öÂ∞çÁúüÂØ¶Áâ©È´îÊùêÊñôÁêÜËß£ÁöÑÂΩ±ÁâáÊì¥Êï£Ê®°Âûã‰∏≠ÊèêÂèñÁâ©ÁêÜÂÖàÈ©ó„ÄÇÂª£Ê≥õÁöÑÂØ¶È©óË≠âÊòé‰∫ÜÊàëÂÄëÁöÑÊñπÊ≥ïÂ∞çÂΩàÊÄßÂíåÂ°ëÊÄßÊùêÊñôÁöÑÊúâÊïàÊÄß„ÄÇPhysics3D È°ØÁèæ‰∫ÜÊ•µÂ§ßÁöÑÊΩõÂäõÔºåÂèØ‰ª•ÂΩåÂêàÁâ©ÁêÜ‰∏ñÁïåÂíåËôõÊì¨Á•ûÁ∂ìÁ©∫Èñì‰πãÈñìÁöÑÂ∑ÆË∑ùÔºåÂú®ËôõÊì¨Áí∞Â¢É‰∏≠Êèê‰æõÊõ¥‰Ω≥ÁöÑÊï¥ÂêàÂíåÊáâÁî®ÁúüÂØ¶Áâ©ÁêÜÂéüÁêÜ„ÄÇÂ∞àÊ°àÈ†ÅÈù¢Ôºöhttps://liuff19.github.io/Physics3D„ÄÇ

##### **Coherent Zero-Shot Visual Instruction Generation**
2406.04337v1 by Quynh Phung, Songwei Ge, Jia-Bin Huang

Despite the advances in text-to-image synthesis, particularly with diffusion
models, generating visual instructions that require consistent representation
and smooth state transitions of objects across sequential steps remains a
formidable challenge. This paper introduces a simple, training-free framework
to tackle the issues, capitalizing on the advancements in diffusion models and
large language models (LLMs). Our approach systematically integrates text
comprehension and image generation to ensure visual instructions are visually
appealing and maintain consistency and accuracy throughout the instruction
sequence. We validate the effectiveness by testing multi-step instructions and
comparing the text alignment and consistency with several baselines. Our
experiments show that our approach can visualize coherent and visually pleasing
instructions

ÊëòË¶ÅÔºöÂÑòÁÆ°ÊñáÂ≠óËΩâÂΩ±ÂÉèÂêàÊàêÊäÄË°ìÈÄ≤Ê≠•ÔºåÁâπÂà•ÊòØ‰ΩøÁî®Êì¥Êï£Ê®°ÂûãÔºå‰ΩÜÁîüÊàêÈúÄË¶Å‰∏ÄËá¥ÂëàÁèæ‰∏îÂú®ÈÄ£Á∫åÊ≠•È©ü‰∏≠Áâ©‰ª∂ÁãÄÊÖãËΩâÊèõÊµÅÊö¢ÁöÑË¶ñË¶∫Ë™™ÊòéÔºå‰ªçÊòØ‰∏ÄÈ†ÖËâ±ÈâÖÁöÑÊåëÊà∞„ÄÇÊú¨Êñá‰ªãÁ¥π‰∏ÄÂÄãÁ∞°ÂñÆ‰∏îÁÑ°ÈúÄË®ìÁ∑¥ÁöÑÊû∂Êßã‰æÜËß£Ê±∫ÈÄô‰∫õÂïèÈ°åÔºå‰∏¶Âà©Áî®Êì¥Êï£Ê®°ÂûãÂíåÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÈÄ≤Â±ï„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÁ≥ªÁµ±ÊÄßÂú∞Êï¥ÂêàÊñáÂ≠óÁêÜËß£ÂíåÂΩ±ÂÉèÁîüÊàêÔºå‰ª•Á¢∫‰øùË¶ñË¶∫Ë™™ÊòéÂú®Ë¶ñË¶∫‰∏äÂÖ∑ÊúâÂê∏ÂºïÂäõÔºå‰∏¶Âú®Êï¥ÂÄãË™™ÊòéÈ†ÜÂ∫è‰∏≠‰øùÊåÅ‰∏ÄËá¥ÊÄßÂíåÊ∫ñÁ¢∫ÊÄß„ÄÇÊàëÂÄëÈÄèÈÅéÊ∏¨Ë©¶Â§öÊ≠•È©üË™™ÊòéÔºå‰∏¶ËàáÂ§öÂÄãÂü∫Ê∫ñÊØîËºÉÊñáÂ≠óÂ∞çÈΩäÂíå‰∏ÄËá¥ÊÄßÔºå‰æÜÈ©óË≠âÂÖ∂ÊúâÊïàÊÄß„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÈ°ØÁ§∫ÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÂèØ‰ª•Ë¶ñË¶∫ÂåñÈÄ£Ë≤´‰∏îË¶ñË¶∫‰∏ä‰ª§‰∫∫ÊÑâÊÇÖÁöÑË™™Êòé

##### **PaCE: Parsimonious Concept Engineering for Large Language Models**
2406.04331v1 by Jinqi Luo, Tianjiao Ding, Kwan Ho Ryan Chan, Darshan Thaker, Aditya Chattopadhyay, Chris Callison-Burch, Ren√© Vidal

Large Language Models (LLMs) are being used for a wide variety of tasks.
While they are capable of generating human-like responses, they can also
produce undesirable output including potentially harmful information, racist or
sexist language, and hallucinations. Alignment methods are designed to reduce
such undesirable output, via techniques such as fine-tuning, prompt
engineering, and representation engineering. However, existing methods face
several challenges: some require costly fine-tuning for every alignment task;
some do not adequately remove undesirable concepts, failing alignment; some
remove benign concepts, lowering the linguistic capabilities of LLMs. To
address these issues, we propose Parsimonious Concept Engineering (PaCE), a
novel activation engineering framework for alignment. First, to sufficiently
model the concepts, we construct a large-scale concept dictionary in the
activation space, in which each atom corresponds to a semantic concept. Then,
given any alignment task, we instruct a concept partitioner to efficiently
annotate the concepts as benign or undesirable. Finally, at inference time, we
decompose the LLM activations along the concept dictionary via sparse coding,
to accurately represent the activation as a linear combination of the benign
and undesirable components. By removing the latter ones from the activation, we
reorient the behavior of LLMs towards alignment goals. We conduct experiments
on tasks such as response detoxification, faithfulness enhancement, and
sentiment revising, and show that PaCE achieves state-of-the-art alignment
performance while maintaining linguistic capabilities.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤Áî®ÊñºÂêÑÁ®Æ‰ªªÂãô„ÄÇ
ÈõñÁÑ∂ÂÆÉÂÄëËÉΩÂ§†Áî¢ÁîüÈ°û‰ºº‰∫∫È°ûÁöÑÂõûÊáâÔºå‰ΩÜÂÆÉÂÄë‰πüÂèØËÉΩ
Áî¢Áîü‰∏çËâØÁöÑËº∏Âá∫ÔºåÂåÖÊã¨ÊΩõÂú®ÊúâÂÆ≥Ë®äÊÅØ„ÄÅÁ®ÆÊóèÊàñ
ÊÄßÂà•Ê≠ßË¶ñË™ûË®Ä‰ª•ÂèäÂπªË¶∫„ÄÇÂ∞çÈΩäÊñπÊ≥ïÊó®Âú®ÈÄèÈÅéÂæÆË™øÁ≠âÊäÄË°ìÊ∏õÂ∞ë
ÈÄôÁ®Æ‰∏çËâØËº∏Âá∫ÔºåÊèêÁ§∫Â∑•Á®ãÂíåË°®Á§∫Â∑•Á®ã„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÊñπÊ≥ïÈù¢Ëá®
‰∏Ä‰∫õÊåëÊà∞ÔºöÊúâ‰∫õÈúÄË¶ÅÁÇ∫ÊØèÂÄãÂ∞çÈΩä‰ªªÂãôÈÄ≤Ë°åÊòÇË≤¥ÁöÑÂæÆË™øÔºõ
Êúâ‰∫õÁÑ°Ê≥ïÂÖÖÂàÜÁßªÈô§‰∏çËâØÊ¶ÇÂøµÔºåÂ∞éËá¥Â∞çÈΩäÂ§±ÊïóÔºõÊúâ‰∫õ
ÁßªÈô§ËâØÊÄßÊ¶ÇÂøµÔºåÈôç‰Ωé LLM ÁöÑË™ûË®ÄËÉΩÂäõ„ÄÇÁÇ∫‰∫Ü
Ëß£Ê±∫ÈÄô‰∫õÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫Á∞°Á¥ÑÊ¶ÇÂøµÂ∑•Á®ã (PaCE)Ôºå‰∏ÄÁ®Æ
Áî®ÊñºÂ∞çÈΩäÁöÑÊñ∞ÂûãÊøÄÊ¥ªÂ∑•Á®ãÊ°ÜÊû∂„ÄÇÈ¶ñÂÖàÔºåÁÇ∫‰∫ÜÂÖÖÂàÜ
Âª∫ÊßãÊ¶ÇÂøµÊ®°ÂûãÔºåÊàëÂÄëÂú®ÊøÄÊ¥ªÁ©∫Èñì‰∏≠Âª∫Êßã‰∏ÄÂÄãÂ§ßÂûãÊ¶ÇÂøµÂ≠óÂÖ∏ÔºåÂÖ∂‰∏≠ÊØèÂÄãÂéüÂ≠êÂ∞çÊáâ‰∏ÄÂÄãË™ûÁæ©Ê¶ÇÂøµ„ÄÇÁÑ∂ÂæåÔºå
ÈáùÂ∞ç‰ªª‰ΩïÂ∞çÈΩä‰ªªÂãôÔºåÊàëÂÄëÊåáÁ§∫Ê¶ÇÂøµÂàÜÂâ≤Âô®ÊúâÊïàÂú∞
Â∞áÊ¶ÇÂøµË®ªËß£ÁÇ∫ËâØÊÄßÊàñ‰∏çËâØ„ÄÇÊúÄÂæåÔºåÂú®Êé®ÁêÜÊôÇÈñìÔºåÊàëÂÄë
ÈÄèÈÅéÁ®ÄÁñèÁ∑®Á¢ºÂàÜËß£ LLM ÊøÄÊ¥ªÔºåÊ≤øËëóÊ¶ÇÂøµÂ≠óÂÖ∏ÈÄ≤Ë°åÔºå
‰ª•Ê∫ñÁ¢∫Âú∞Â∞áÊøÄÊ¥ªË°®Á§∫ÁÇ∫ËâØÊÄßÂíå‰∏çËâØÁµÑÊàêÁöÑÁ∑öÊÄßÁµÑÂêà„ÄÇÈÄèÈÅéÁßªÈô§ÂæåËÄÖÂæûÊøÄÊ¥ª‰∏≠ÔºåÊàëÂÄë
ÈáçÊñ∞Â∞éÂêë LLM ÁöÑË°åÁÇ∫‰ª•ÊúùÂêëÂ∞çÈΩäÁõÆÊ®ô„ÄÇÊàëÂÄëÂú®ÂõûÊáâËß£ÊØí„ÄÅÂø†ÂØ¶Â∫¶Â¢ûÂº∑Âíå
ÊÉÖÁ∑í‰øÆÊ≠£Á≠â‰ªªÂãô‰∏äÈÄ≤Ë°åÂØ¶È©óÔºå‰∏¶È°ØÁ§∫ PaCE ÈÅîÂà∞ÊúÄÂÖàÈÄ≤ÁöÑÂ∞çÈΩä
ÊïàËÉΩÔºåÂêåÊôÇÁ∂≠ÊåÅË™ûË®ÄËÉΩÂäõ„ÄÇ

##### **ATraDiff: Accelerating Online Reinforcement Learning with Imaginary Trajectories**
2406.04323v1 by Qianlan Yang, Yu-Xiong Wang

Training autonomous agents with sparse rewards is a long-standing problem in
online reinforcement learning (RL), due to low data efficiency. Prior work
overcomes this challenge by extracting useful knowledge from offline data,
often accomplished through the learning of action distribution from offline
data and utilizing the learned distribution to facilitate online RL. However,
since the offline data are given and fixed, the extracted knowledge is
inherently limited, making it difficult to generalize to new tasks. We propose
a novel approach that leverages offline data to learn a generative diffusion
model, coined as Adaptive Trajectory Diffuser (ATraDiff). This model generates
synthetic trajectories, serving as a form of data augmentation and consequently
enhancing the performance of online RL methods. The key strength of our
diffuser lies in its adaptability, allowing it to effectively handle varying
trajectory lengths and mitigate distribution shifts between online and offline
data. Because of its simplicity, ATraDiff seamlessly integrates with a wide
spectrum of RL methods. Empirical evaluation shows that ATraDiff consistently
achieves state-of-the-art performance across a variety of environments, with
particularly pronounced improvements in complicated settings. Our code and demo
video are available at https://atradiff.github.io .

ÊëòË¶ÅÔºöÂú®Âú®Á∫øÂº∫ÂåñÂ≠¶‰π† (RL) ‰∏≠Ôºå‰ΩøÁî®Á®ÄÁñèÂ•ñÂä±Êù•ËÆ≠ÁªÉËá™‰∏ª‰ª£ÁêÜÊòØ‰∏Ä‰∏™ÈïøÊúüÂ≠òÂú®ÁöÑÈóÆÈ¢òÔºåËøôÊòØÁî±‰∫éÊï∞ÊçÆÊïàÁéá‰Ωé„ÄÇ‰ª•ÂâçÁöÑÂ∑•‰ΩúÈÄöËøá‰ªéÁ¶ªÁ∫øÊï∞ÊçÆ‰∏≠ÊèêÂèñÊúâÁî®ÁöÑÁü•ËØÜÊù•ÂÖãÊúçËøô‰∏ÄÊåëÊàòÔºåÈÄöÂ∏∏ÊòØÈÄöËøá‰ªéÁ¶ªÁ∫øÊï∞ÊçÆÂ≠¶‰π†Âä®‰ΩúÂàÜÂ∏ÉÂπ∂Âà©Áî®Â≠¶‰π†Âà∞ÁöÑÂàÜÂ∏ÉÊù•‰øÉËøõÂú®Á∫ø RL Êù•ÂÆûÁé∞ÁöÑ„ÄÇÁÑ∂ËÄåÔºåÁî±‰∫éÁ¶ªÁ∫øÊï∞ÊçÆÊòØÁªôÂÆöÁöÑÂπ∂‰∏îÊòØÂõ∫ÂÆöÁöÑÔºåÂõ†Ê≠§ÊèêÂèñÁöÑÁü•ËØÜÊú¨Ë¥®‰∏äÊòØÊúâÈôêÁöÑÔºåËøô‰ΩøÂæóÈöæ‰ª•Êé®ÂπøÂà∞Êñ∞‰ªªÂä°„ÄÇÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞È¢ñÁöÑÊñπÊ≥ïÔºåËØ•ÊñπÊ≥ïÂà©Áî®Á¶ªÁ∫øÊï∞ÊçÆÊù•Â≠¶‰π†ÁîüÊàêÊâ©Êï£Ê®°ÂûãÔºåÁß∞‰∏∫Ëá™ÈÄÇÂ∫îËΩ®ËøπÊâ©Êï£Âô® (ATraDiff)„ÄÇÊ≠§Ê®°ÂûãÁîüÊàêÂêàÊàêËΩ®ËøπÔºå‰Ωú‰∏∫Êï∞ÊçÆÊâ©ÂÖÖÁöÑ‰∏ÄÁßçÂΩ¢ÂºèÔºå‰ªéËÄåÊèêÈ´òÂú®Á∫ø RL ÊñπÊ≥ïÁöÑÊÄßËÉΩ„ÄÇÊàë‰ª¨Êâ©Êï£Âô®ÁöÑÂÖ≥ÈîÆ‰ºòÂäøÂú®‰∫éÂÖ∂ÈÄÇÂ∫îÊÄßÔºå‰ΩøÂÖ∂ËÉΩÂ§üÊúâÊïàÂú∞Â§ÑÁêÜ‰∏çÂêåÁöÑËΩ®ËøπÈïøÂ∫¶Âπ∂ÂáèËΩªÂú®Á∫øÂíåÁ¶ªÁ∫øÊï∞ÊçÆ‰πãÈó¥ÁöÑÂàÜÂ∏ÉÂÅèÁßª„ÄÇÁî±‰∫éÂÖ∂ÁÆÄÂçïÊÄßÔºåATraDiff ÂèØ‰ª•‰∏éÂπøÊ≥õÁöÑ RL ÊñπÊ≥ïÊó†ÁºùÈõÜÊàê„ÄÇÁªèÈ™åËØÑ‰º∞Ë°®ÊòéÔºåATraDiff Âú®ÂêÑÁßçÁéØÂ¢É‰∏≠ÂßãÁªàÂ¶Ç‰∏ÄÂú∞ËææÂà∞ÊúÄÂÖàËøõÁöÑÊÄßËÉΩÔºåÁâπÂà´ÊòØÂú®Â§çÊùÇËÆæÁΩÆ‰∏≠Ë°®Áé∞Âá∫ÊòæÁùÄÁöÑÊîπËøõ„ÄÇÊàë‰ª¨ÁöÑ‰ª£Á†ÅÂíåÊºîÁ§∫ËßÜÈ¢ëÂèØÂú® https://atradiff.github.io Ëé∑Âæó„ÄÇ

##### **Chimera: Effectively Modeling Multivariate Time Series with 2-Dimensional State Space Models**
2406.04320v1 by Ali Behrouz, Michele Santacatterina, Ramin Zabih

Modeling multivariate time series is a well-established problem with a wide
range of applications from healthcare to financial markets. Traditional State
Space Models (SSMs) are classical approaches for univariate time series
modeling due to their simplicity and expressive power to represent linear
dependencies. They, however, have fundamentally limited expressive power to
capture non-linear dependencies, are slow in practice, and fail to model the
inter-variate information flow. Despite recent attempts to improve the
expressive power of SSMs by using deep structured SSMs, the existing methods
are either limited to univariate time series, fail to model complex patterns
(e.g., seasonal patterns), fail to dynamically model the dependencies of
variate and time dimensions, and/or are input-independent. We present Chimera
that uses two input-dependent 2-D SSM heads with different discretization
processes to learn long-term progression and seasonal patterns. To improve the
efficiency of complex 2D recurrence, we present a fast training using a new
2-dimensional parallel selective scan. We further present and discuss
2-dimensional Mamba and Mamba-2 as the spacial cases of our 2D SSM. Our
experimental evaluation shows the superior performance of Chimera on extensive
and diverse benchmarks, including ECG and speech time series classification,
long-term and short-term time series forecasting, and time series anomaly
detection.

ÊëòË¶ÅÔºöÂ§öËÆäÈáèÊôÇÈñìÂ∫èÂàóÂª∫Ê®°ÊòØ‰∏ÄÂÄãÂÆåÂñÑÁöÑÂïèÈ°åÔºåÂú®ÂæûÈÜ´ÁôÇ‰øùÂÅ•Âà∞ÈáëËûçÂ∏ÇÂ†¥ÁöÑÂª£Ê≥õÊáâÁî®‰∏≠ÈÉΩÊúâÊáâÁî®„ÄÇÂÇ≥Áµ±ÁöÑÁãÄÊÖãÁ©∫ÈñìÊ®°Âûã (SSM) Áî±ÊñºÂÖ∂Á∞°ÊΩîÊÄßÂíåË°®Á§∫Á∑öÊÄß‰æùË≥¥ÊÄßÁöÑË°®ÈÅîËÉΩÂäõÔºåÊòØÂñÆËÆäÈáèÊôÇÈñìÂ∫èÂàóÂª∫Ê®°ÁöÑÁ∂ìÂÖ∏ÊñπÊ≥ï„ÄÇÁÑ∂ËÄåÔºåÂÆÉÂÄëÂú®ÊçïÊçâÈùûÁ∑öÊÄß‰æùË≥¥ÊÄßÊñπÈù¢Âü∫Êú¨‰∏äË°®ÁèæÂäõÊúâÈôêÔºåÂú®ÂØ¶Ë∏ê‰∏≠ÈÄüÂ∫¶ËºÉÊÖ¢Ôºå‰∏¶‰∏îÁÑ°Ê≥ïÂ∞çËÆäÈáèÈñìÁöÑ‰ø°ÊÅØÊµÅÈÄ≤Ë°åÂª∫Ê®°„ÄÇÂÑòÁÆ°ÊúÄËøëÂòóË©¶ÈÄöÈÅé‰ΩøÁî®Ê∑±Â∫¶ÁµêÊßãÂåñ SSM ‰æÜÊèêÈ´ò SSM ÁöÑË°®ÁèæÂäõÔºå‰ΩÜÁèæÊúâÊñπÊ≥ïË¶Å‰πàÂÉÖÈôêÊñºÂñÆËÆäÈáèÊôÇÈñìÂ∫èÂàóÔºåÁÑ°Ê≥ïÂ∞çË§áÈõúÊ®°ÂºèÔºà‰æãÂ¶ÇÂ≠£ÁØÄÊ®°ÂºèÔºâÈÄ≤Ë°åÂª∫Ê®°ÔºåÁÑ°Ê≥ïÂãïÊÖãÂ∞çËÆäÈáèÂíåÊôÇÈñìÁ∂≠Â∫¶ÁöÑ‰æùË≥¥ÊÄßÈÄ≤Ë°åÂª∫Ê®°ÔºåÂíå/ÊàñËàáËº∏ÂÖ•ÁÑ°Èóú„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫Ü ChimeraÔºåÂÆÉ‰ΩøÁî®ÂÖ©ÂÄãËº∏ÂÖ•‰æùË≥¥ÁöÑ 2-D SSM È†≠ÈÉ®ÔºåÂÖ∑Êúâ‰∏çÂêåÁöÑÈõ¢Êï£ÂåñÈÅéÁ®ã‰æÜÂ≠∏ÁøíÈï∑ÊúüÈÄ≤Â±ïÂíåÂ≠£ÁØÄÊ®°Âºè„ÄÇÁÇ∫‰∫ÜÊèêÈ´òË§áÈõúÁöÑ 2D ÈÅûÊ≠∏ÁöÑÊïàÁéáÔºåÊàëÂÄë‰ΩøÁî®Êñ∞ÁöÑ 2 Á∂≠‰∏¶Ë°åÈÅ∏ÊìáÊÄßÊéÉÊèè‰æÜÂ±ïÁ§∫Âø´ÈÄüË®ìÁ∑¥„ÄÇÊàëÂÄëÈÄ≤‰∏ÄÊ≠•Â±ïÁ§∫‰∏¶Ë®éË´ñ‰∫Ü 2 Á∂≠ Mamba Âíå Mamba-2 ‰ΩúÁÇ∫ÊàëÂÄë 2D SSM ÁöÑÁ©∫ÈñìÊ°à‰æã„ÄÇÊàëÂÄëÁöÑÂØ¶È©óË©ï‰º∞È°ØÁ§∫‰∫Ü Chimera Âú®Âª£Ê≥õ‰∏îÂ§öÊ®£ÂåñÁöÑÂü∫Ê∫ñÊ∏¨Ë©¶‰∏≠ÁöÑÂçìË∂äÊÄßËÉΩÔºåÂåÖÊã¨ ECG ÂíåË™ûÈü≥ÊôÇÈñìÂ∫èÂàóÂàÜÈ°û„ÄÅÈï∑ÊúüÂíåÁü≠ÊúüÊôÇÈñìÂ∫èÂàóÈ†êÊ∏¨‰ª•ÂèäÊôÇÈñìÂ∫èÂàóÁï∞Â∏∏Ê™¢Ê∏¨„ÄÇ

##### **Improving Alignment and Robustness with Short Circuiting**
2406.04313v1 by Andy Zou, Long Phan, Justin Wang, Derek Duenas, Maxwell Lin, Maksym Andriushchenko, Rowan Wang, Zico Kolter, Matt Fredrikson, Dan Hendrycks

AI systems can take harmful actions and are highly vulnerable to adversarial
attacks. We present an approach, inspired by recent advances in representation
engineering, that "short-circuits" models as they respond with harmful outputs.
Existing techniques aimed at improving alignment, such as refusal training, are
often bypassed. Techniques such as adversarial training try to plug these holes
by countering specific attacks. As an alternative to refusal training and
adversarial training, short-circuiting directly controls the representations
that are responsible for harmful outputs in the first place. Our technique can
be applied to both text-only and multimodal language models to prevent the
generation of harmful outputs without sacrificing utility -- even in the
presence of powerful unseen attacks. Notably, while adversarial robustness in
standalone image recognition remains an open challenge, short-circuiting allows
the larger multimodal system to reliably withstand image "hijacks" that aim to
produce harmful content. Finally, we extend our approach to AI agents,
demonstrating considerable reductions in the rate of harmful actions when they
are under attack. Our approach represents a significant step forward in the
development of reliable safeguards to harmful behavior and adversarial attacks.

ÊëòË¶ÅÔºöAI Á≥ªÁµ±ÂèØËÉΩÊúÉÊé°ÂèñÊúâÂÆ≥ÁöÑË°åÂãïÔºåËÄå‰∏îÊ•µÂÆπÊòìÂèóÂà∞Â∞çÊäóÊÄßÊîªÊìä„ÄÇÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñπÊ≥ïÔºåÈùàÊÑü‰æÜËá™ÊúÄËøëÂú®Ë°®Á§∫Â∑•Á®ãÊñπÈù¢ÁöÑÈÄ≤Â±ïÔºåÈÄôÁ®ÆÊñπÊ≥ïÂèØ‰ª•„ÄåÁü≠Ë∑Ø„ÄçÊ®°ÂûãÔºåÂõ†ÁÇ∫ÂÆÉÂÄëÊúÉÁî¢ÁîüÊúâÂÆ≥ÁöÑËº∏Âá∫„ÄÇÊó®Âú®ÊîπÂñÑÂ∞çÈΩäÁöÑÁèæÊúâÊäÄË°ìÔºå‰æãÂ¶ÇÊãíÁµïË®ìÁ∑¥ÔºåÈÄöÂ∏∏ÊúÉË¢´ÁπûÈÅé„ÄÇÂ∞çÊäóÊÄßË®ìÁ∑¥Á≠âÊäÄË°ìË©¶ÂúñÈÄöÈÅéÂèçÂà∂ÁâπÂÆöÊîªÊìä‰æÜÂ°´Ë£úÈÄô‰∫õÊºèÊ¥û„ÄÇ‰ΩúÁÇ∫ÊãíÁµïË®ìÁ∑¥ÂíåÂ∞çÊäóÊÄßË®ìÁ∑¥ÁöÑÊõø‰ª£ÊñπÊ°àÔºåÁü≠Ë∑ØÁõ¥Êé•ÊéßÂà∂ÊúÄÂàùÂ∞çÊúâÂÆ≥Ëº∏Âá∫Ë≤†Ë≤¨ÁöÑË°®Á§∫„ÄÇÊàëÂÄëÁöÑÊäÄË°ìÂèØ‰ª•ÊáâÁî®ÊñºÁ¥îÊñáÊú¨ÂíåÂ§öÊ®°ÊÖãË™ûË®ÄÊ®°ÂûãÔºå‰ª•Èò≤Ê≠¢Áî¢ÁîüÊúâÂÆ≥Ëº∏Âá∫ÔºåËÄå‰∏çÊúÉÁäßÁâ≤ÊïàÁî®‚Äî‚ÄîÂç≥‰ΩøÂú®Â≠òÂú®Âº∑Â§ßÁöÑÊú™Áü•ÊîªÊìäÁöÑÊÉÖÊ≥Å‰∏ã‰πüÊòØÂ¶ÇÊ≠§„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÂÑòÁÆ°Áç®Á´ãÂúñÂÉèË≠òÂà•‰∏≠ÁöÑÂ∞çÊäóÊÄßÈ≠ØÊ£íÊÄß‰ªçÁÑ∂ÊòØ‰∏ÄÂÄãÊú™Ëß£Ê±∫ÁöÑÊåëÊà∞Ôºå‰ΩÜÁü≠Ë∑ØÂÖÅË®±Êõ¥Â§ßÁöÑÂ§öÊ®°ÊÖãÁ≥ªÁµ±ÂèØÈù†Âú∞ÊâøÂèóÊó®Âú®Áî¢ÁîüÊúâÂÆ≥ÂÖßÂÆπÁöÑÂúñÂÉè„ÄåÂä´ÊåÅ„Äç„ÄÇÊúÄÂæåÔºåÊàëÂÄëÂ∞áÊàëÂÄëÁöÑÊäÄË°ìÊì¥Â±ïÂà∞ AI ‰ª£ÁêÜÔºåË≠âÊòé‰∫ÜÂú®ÂèóÂà∞ÊîªÊìäÊôÇÊúâÂÆ≥Ë°åÁÇ∫ÁöÑÁôºÁîüÁéáÂ§ßÂπÖÈôç‰Ωé„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ï‰ª£Ë°®‰∫ÜÂú®ÈñãÁôºÈáùÂ∞çÊúâÂÆ≥Ë°åÁÇ∫ÂíåÂ∞çÊäóÊÄßÊîªÊìäÁöÑÂèØÈù†Èò≤Ë≠∑Êé™ÊñΩÊñπÈù¢ÈÇÅÂá∫ÁöÑÈáçË¶Å‰∏ÄÊ≠•„ÄÇ

##### **Semantically Diverse Language Generation for Uncertainty Estimation in Language Models**
2406.04306v1 by Lukas Aichberger, Kajetan Schweighofer, Mykyta Ielanskyi, Sepp Hochreiter

Large language models (LLMs) can suffer from hallucinations when generating
text. These hallucinations impede various applications in society and industry
by making LLMs untrustworthy. Current LLMs generate text in an autoregressive
fashion by predicting and appending text tokens. When an LLM is uncertain about
the semantic meaning of the next tokens to generate, it is likely to start
hallucinating. Thus, it has been suggested that hallucinations stem from
predictive uncertainty. We introduce Semantically Diverse Language Generation
(SDLG) to quantify predictive uncertainty in LLMs. SDLG steers the LLM to
generate semantically diverse yet likely alternatives for an initially
generated text. This approach provides a precise measure of aleatoric semantic
uncertainty, detecting whether the initial text is likely to be hallucinated.
Experiments on question-answering tasks demonstrate that SDLG consistently
outperforms existing methods while being the most computationally efficient,
setting a new standard for uncertainty estimation in LLMs.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®ÁîüÊàêÊñáÊú¨ÊôÇÂèØËÉΩÊúÉÂá∫ÁèæÂπªË¶∫„ÄÇÈÄô‰∫õÂπªË¶∫ÊúÉËÆì LLM Â§±ÂéªÂèØ‰ø°Â∫¶ÔºåÈÄ≤ËÄåÈòªÁ§ôÁ§æÊúÉÂíåÁî¢Ê•≠‰∏≠ÁöÑÂêÑÁ®ÆÊáâÁî®„ÄÇÁõÆÂâçÁöÑ LLM ‰ª•Ëá™Ëø¥Ê≠∏ÁöÑÊñπÂºèÁîüÊàêÊñáÊú¨ÔºåÈÄèÈÅéÈ†êÊ∏¨ÂíåÈôÑÂä†ÊñáÊú¨Á¨¶Ëôü‰æÜÈÄ≤Ë°å„ÄÇÁï∂ LLM ‰∏çÁ¢∫ÂÆö‰∏ã‰∏ÄÂÄãË¶ÅÁîüÊàêÁöÑÁ¨¶ËôüÁöÑË™ûÁæ©Âê´Áæ©ÊôÇÔºåÂÆÉÂæàÊúâÂèØËÉΩÊúÉÈñãÂßãÁî¢ÁîüÂπªË¶∫„ÄÇÂõ†Ê≠§ÔºåÊúâ‰∫∫ÊèêÂá∫ÂπªË¶∫Ê∫êËá™ÊñºÈ†êÊ∏¨ÁöÑ‰∏çÁ¢∫ÂÆöÊÄß„ÄÇÊàëÂÄëÂºïÂÖ•‰∫ÜË™ûÁæ©Â§öÊ®£ÂåñË™ûË®ÄÁîüÊàê (SDLG) ‰æÜÈáèÂåñ LLM ‰∏≠ÁöÑÈ†êÊ∏¨‰∏çÁ¢∫ÂÆöÊÄß„ÄÇSDLG ÂºïÂ∞é LLM ÁÇ∫ÊúÄÂàùÁîüÊàêÁöÑÊñáÊú¨ÁîüÊàêË™ûÁæ©Â§öÊ®£‰ΩÜÂêàÁêÜÁöÑÊõø‰ª£ÊñπÊ°à„ÄÇÊ≠§ÊñπÊ≥ïÊèê‰æõ‰∫ÜÂ∞çÈö®Ê©üË™ûÁæ©‰∏çÁ¢∫ÂÆöÊÄßÁöÑÁ≤æÁ¢∫Ë°°ÈáèÔºåÁî®‰ª•Ê™¢Ê∏¨ÊúÄÂàùÁöÑÊñáÊú¨ÊòØÂê¶ÂèØËÉΩÂá∫ÁèæÂπªË¶∫„ÄÇÂïèÁ≠î‰ªªÂãôÁöÑÂØ¶È©óË≠âÊòéÔºåSDLG Âú®ÂßãÁµÇÂÑ™ÊñºÁèæÊúâÊñπÊ≥ïÁöÑÂêåÊôÇÔºå‰πüÊòØÈÅãÁÆóÊïàÁéáÊúÄÈ´òÁöÑÔºåÁÇ∫ LLM ‰∏≠ÁöÑ‰∏çÁ¢∫ÂÆöÊÄß‰º∞Ë®àË®≠ÂÆö‰∫ÜÊñ∞ÁöÑÊ®ôÊ∫ñ„ÄÇ

##### **Vision-LSTM: xLSTM as Generic Vision Backbone**
2406.04303v1 by Benedikt Alkin, Maximilian Beck, Korbinian P√∂ppel, Sepp Hochreiter, Johannes Brandstetter

Transformers are widely used as generic backbones in computer vision, despite
initially introduced for natural language processing. Recently, the Long
Short-Term Memory (LSTM) has been extended to a scalable and performant
architecture - the xLSTM - which overcomes long-standing LSTM limitations via
exponential gating and parallelizable matrix memory structure. In this report,
we introduce Vision-LSTM (ViL), an adaption of the xLSTM building blocks to
computer vision. ViL comprises a stack of xLSTM blocks where odd blocks process
the sequence of patch tokens from top to bottom while even blocks go from
bottom to top. Experiments show that ViL holds promise to be further deployed
as new generic backbone for computer vision architectures.

ÊëòË¶ÅÔºöÂÑòÁÆ°ÊúÄÂàùÊòØÁÇ∫Ëá™ÁÑ∂Ë™ûË®ÄËôïÁêÜËÄåÂºïÂÖ•ÁöÑÔºå‰ΩÜ Transformers Â∑≤Âª£Ê≥õÁî®ÊñºÈõªËÖ¶Ë¶ñË¶∫‰∏≠ÁöÑÈÄöÁî®‰∏ªÂππ„ÄÇÊúÄËøëÔºåÈï∑ÊúüÁü≠ÊúüË®òÊÜ∂ (LSTM) Â∑≤Êì¥Â±ïÂà∞ÂèØÊì¥ÂÖÖ‰∏îÊïàËÉΩËâØÂ•ΩÁöÑÊû∂Êßã - xLSTM - ÂÆÉÈÄèÈÅéÊåáÊï∏ÈñòÊéßÂíåÂèØ‰∏¶Ë°åÂåñÁü©Èô£Ë®òÊÜ∂È´îÁµêÊßãÂÖãÊúç‰∫Ü LSTM ÁöÑÈï∑ÊúüÈôêÂà∂„ÄÇÂú®Ê≠§Â†±Âëä‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫Ü Vision-LSTM (ViL)Ôºå‰∏ÄÁ®ÆÂ∞á xLSTM Âª∫ÊßãÂçÄÂ°äË™øÊï¥ÁÇ∫ÈõªËÖ¶Ë¶ñË¶∫ÁöÑÊäÄË°ì„ÄÇViL ÂåÖÂê´‰∏ÄÂÄã xLSTM ÂçÄÂ°äÂ†ÜÁñäÔºåÂÖ∂‰∏≠Â•áÊï∏ÂçÄÂ°äÂæû‰∏äÂà∞‰∏ãËôïÁêÜÂçÄÂ°äÊ®ôË®òÁöÑÂ∫èÂàóÔºåËÄåÂÅ∂Êï∏ÂçÄÂ°äÂâáÂæû‰∏ãÂà∞‰∏äÈÄ≤Ë°åËôïÁêÜ„ÄÇÂØ¶È©óÈ°ØÁ§∫ÔºåViL ÊúâÊúõÈÄ≤‰∏ÄÊ≠•ÈÉ®ÁΩ≤ÁÇ∫ÈõªËÖ¶Ë¶ñË¶∫Êû∂ÊßãÁöÑÊñ∞ÈÄöÁî®‰∏ªÂππ„ÄÇ

##### **VISTA: Visualized Text Embedding For Universal Multi-Modal Retrieval**
2406.04292v1 by Junjie Zhou, Zheng Liu, Shitao Xiao, Bo Zhao, Yongping Xiong

Multi-modal retrieval becomes increasingly popular in practice. However, the
existing retrievers are mostly text-oriented, which lack the capability to
process visual information. Despite the presence of vision-language models like
CLIP, the current methods are severely limited in representing the text-only
and image-only data. In this work, we present a new embedding model VISTA for
universal multi-modal retrieval. Our work brings forth threefold technical
contributions. Firstly, we introduce a flexible architecture which extends a
powerful text encoder with the image understanding capability by introducing
visual token embeddings. Secondly, we develop two data generation strategies,
which bring high-quality composed image-text to facilitate the training of the
embedding model. Thirdly, we introduce a multi-stage training algorithm, which
first aligns the visual token embedding with the text encoder using massive
weakly labeled data, and then develops multi-modal representation capability
using the generated composed image-text data. In our experiments, VISTA
achieves superior performances across a variety of multi-modal retrieval tasks
in both zero-shot and supervised settings. Our model, data, and source code are
available at https://github.com/FlagOpen/FlagEmbedding.

ÊëòË¶ÅÔºöÂ§öÊ®°ÊÄÅÊ£ÄÁ¥¢Âú®ÂÆûË∑µ‰∏≠ÂèòÂæóË∂äÊù•Ë∂äÊµÅË°å„ÄÇÁÑ∂ËÄåÔºåÁé∞ÊúâÁöÑÊ£ÄÁ¥¢Âô®Â§ßÂ§öÊòØÊñáÊú¨ÂØºÂêëÁöÑÔºåÁº∫‰πèÂ§ÑÁêÜËßÜËßâ‰ø°ÊÅØÁöÑËÉΩÂäõ„ÄÇÂ∞ΩÁÆ°Êúâ CLIP Á≠âËßÜËßâËØ≠Ë®ÄÊ®°ÂûãÔºå‰ΩÜÂΩìÂâçÁöÑÊñπÊ≥ïÂú®Ë°®Á§∫‰ªÖÊñáÊú¨Âíå‰ªÖÂõæÂÉèÊï∞ÊçÆÊñπÈù¢ÂèóÂà∞‰∏•ÈáçÈôêÂà∂„ÄÇÂú®ËøôÈ°πÂ∑•‰Ωú‰∏≠ÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏Ä‰∏™Êñ∞ÁöÑÂµåÂÖ•Ê®°Âûã VISTAÔºåÁî®‰∫éÈÄöÁî®Â§öÊ®°ÊÄÅÊ£ÄÁ¥¢„ÄÇÊàë‰ª¨ÁöÑÂ∑•‰ΩúÂ∏¶Êù•‰∫Ü‰∏âÊñπÈù¢ÁöÑÊäÄÊúØË¥°ÁåÆ„ÄÇÈ¶ñÂÖàÔºåÊàë‰ª¨ÂºïÂÖ•‰∫Ü‰∏Ä‰∏™ÁÅµÊ¥ªÁöÑÊû∂ÊûÑÔºåÈÄöËøáÂºïÂÖ•ËßÜËßâÊ†áËÆ∞ÂµåÂÖ•ÔºåÂ∞Ü‰∏Ä‰∏™Âº∫Â§ßÁöÑÊñáÊú¨ÁºñÁ†ÅÂô®Êâ©Â±ï‰∏∫ÂÖ∑ÊúâÂõæÂÉèÁêÜËß£ËÉΩÂäõ„ÄÇÂÖ∂Ê¨°ÔºåÊàë‰ª¨ÂºÄÂèë‰∫Ü‰∏§ÁßçÊï∞ÊçÆÁîüÊàêÁ≠ñÁï•ÔºåËøô‰∫õÁ≠ñÁï•Â∏¶Êù•‰∫ÜÈ´òË¥®ÈáèÁöÑÁªÑÂêàÂõæÂÉèÊñáÊú¨Ôºå‰ª•‰øÉËøõÂµåÂÖ•Ê®°ÂûãÁöÑËÆ≠ÁªÉ„ÄÇÁ¨¨‰∏âÔºåÊàë‰ª¨ÂºïÂÖ•‰∫Ü‰∏Ä‰∏™Â§öÈò∂ÊÆµËÆ≠ÁªÉÁÆóÊ≥ïÔºåËØ•ÁÆóÊ≥ïÈ¶ñÂÖà‰ΩøÁî®Â§ßÈáèÂº±Ê†áËÆ∞Êï∞ÊçÆÂ∞ÜËßÜËßâÊ†áËÆ∞ÂµåÂÖ•‰∏éÊñáÊú¨ÁºñÁ†ÅÂô®ÂØπÈΩêÔºåÁÑ∂Âêé‰ΩøÁî®ÁîüÊàêÁöÑÁªÑÂêàÂõæÂÉèÊñáÊú¨Êï∞ÊçÆÂºÄÂèëÂ§öÊ®°ÊÄÅË°®Á§∫ËÉΩÂäõ„ÄÇÂú®Êàë‰ª¨ÁöÑÂÆûÈ™å‰∏≠ÔºåVISTA Âú®ÂêÑÁßçÂ§öÊ®°ÊÄÅÊ£ÄÁ¥¢‰ªªÂä°‰∏≠ÂÆûÁé∞‰∫ÜÂçìË∂äÁöÑÊÄßËÉΩÔºåÊó¢ÈÄÇÁî®‰∫éÈõ∂Ê†∑Êú¨ËÆæÁΩÆÔºå‰πüÈÄÇÁî®‰∫éÊúâÁõëÁù£ËÆæÁΩÆ„ÄÇÊàë‰ª¨ÁöÑÊ®°Âûã„ÄÅÊï∞ÊçÆÂíåÊ∫ê‰ª£Á†ÅÂèØÂú® https://github.com/FlagOpen/FlagEmbedding Ëé∑Âæó„ÄÇ

##### **What Languages are Easy to Language-Model? A Perspective from Learning Probabilistic Regular Languages**
2406.04289v2 by Nadav Borenstein, Anej Svete, Robin Chan, Josef Valvoda, Franz Nowak, Isabelle Augenstein, Eleanor Chodroff, Ryan Cotterell

What can large language models learn? By definition, language models (LM) are
distributions over strings. Therefore, an intuitive way of addressing the above
question is to formalize it as a matter of learnability of classes of
distributions over strings. While prior work in this direction focused on
assessing the theoretical limits, in contrast, we seek to understand the
empirical learnability. Unlike prior empirical work, we evaluate neural LMs on
their home turf-learning probabilistic languages-rather than as classifiers of
formal languages. In particular, we investigate the learnability of regular LMs
(RLMs) by RNN and Transformer LMs. We empirically test the learnability of RLMs
as a function of various complexity parameters of the RLM and the hidden state
size of the neural LM. We find that the RLM rank, which corresponds to the size
of linear space spanned by the logits of its conditional distributions, and the
expected length of sampled strings are strong and significant predictors of
learnability for both RNNs and Transformers. Several other predictors also
reach significance, but with differing patterns between RNNs and Transformers.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°ÂûãËÉΩÂ≠∏Âà∞‰ªÄÈ∫ºÔºüÊ†πÊìöÂÆöÁæ©ÔºåË™ûË®ÄÊ®°Âûã (LM) ÊòØÂ≠ó‰∏≤‰∏äÁöÑÂàÜ‰Ωà„ÄÇÂõ†Ê≠§Ôºå‰∏ÄÂÄãÁõ¥ËßÄÁöÑËß£Ê±∫‰∏äËø∞ÂïèÈ°åÁöÑÊñπÊ≥ïÊòØÂ∞áÂÖ∂ÂΩ¢ÂºèÂåñÁÇ∫Â≠ó‰∏≤‰∏äÂàÜ‰ΩàÈ°ûÂà•ÁöÑÂèØÂ≠∏ÁøíÊÄßÂïèÈ°å„ÄÇÈõñÁÑ∂ÂÖàÂâçÊúùÈÄôÂÄãÊñπÂêëÈÄ≤Ë°åÁöÑÁ†îÁ©∂Â∞àÊ≥®ÊñºË©ï‰º∞ÁêÜË´ñÈôêÂà∂Ôºå‰ΩÜÊàëÂÄëÂèçËÄåË©¶Âúñ‰∫ÜËß£Á∂ìÈ©óÂèØÂ≠∏ÁøíÊÄß„ÄÇËàáÂÖàÂâçÁöÑÁ∂ìÈ©óÊÄßÁ†îÁ©∂‰∏çÂêåÔºåÊàëÂÄëÂú®Á•ûÁ∂ìË™ûË®ÄÊ®°ÂûãÁöÑ‰∏ªÂ†¥‚Äî‚ÄîÂ≠∏ÁøíÊ©üÁéáË™ûË®Ä‚Äî‚Äî‰∏äË©ï‰º∞Á•ûÁ∂ìË™ûË®ÄÊ®°ÂûãÔºåËÄå‰∏çÊòØ‰ΩúÁÇ∫ÂΩ¢ÂºèË™ûË®ÄÁöÑÂàÜÈ°ûÂô®„ÄÇÁâπÂà•ÊòØÔºåÊàëÂÄëÊé¢Ë®é‰∫ÜÈÅûËø¥Á•ûÁ∂ìÁ∂≤Ë∑ØÂíå Transformer Ë™ûË®ÄÊ®°ÂûãÂ∞çÊ≠£ÂâáË™ûË®ÄÊ®°Âûã (RLM) ÁöÑÂèØÂ≠∏ÁøíÊÄß„ÄÇÊàëÂÄëÊ†πÊìö RLM ÁöÑÂêÑÁ®ÆË§áÈõúÂ∫¶ÂèÉÊï∏ÂíåÁ•ûÁ∂ìË™ûË®ÄÊ®°ÂûãÁöÑÈö±ËóèÁãÄÊÖãÂ§ßÂ∞èÔºåÁ∂ìÈ©óÊÄßÂú∞Ê∏¨Ë©¶ RLM ÁöÑÂèØÂ≠∏ÁøíÊÄß„ÄÇÊàëÂÄëÁôºÁèæ RLM Á≠âÁ¥öÔºàÂ∞çÊáâÊñºÂÖ∂Ê¢ù‰ª∂ÂàÜ‰ΩàÁöÑ logit ÊâÄË∑®Ë∂äÁöÑÁ∑öÊÄßÁ©∫ÈñìÂ§ßÂ∞èÔºâÂíåÊé°Ê®£Â≠ó‰∏≤ÁöÑÈ†êÊúüÈï∑Â∫¶ÊòØ RNN Âíå Transformer ÂèØÂ≠∏ÁøíÊÄßÁöÑÂº∑Â§ß‰∏îÈáçË¶ÅÁöÑÈ†êÊ∏¨Âõ†Â≠ê„ÄÇÂÖ∂‰ªñÂπæÂÄãÈ†êÊ∏¨Âõ†Â≠ê‰πüÈÅîÂà∞È°ØËëóÊÄßÔºå‰ΩÜÂú® RNN Âíå Transformer ‰πãÈñìÊúâ‰∏çÂêåÁöÑÊ®°Âºè„ÄÇ

##### **ABEX: Data Augmentation for Low-Resource NLU via Expanding Abstract Descriptions**
2406.04286v1 by Sreyan Ghosh, Utkarsh Tyagi, Sonal Kumar, C. K. Evuru, S Ramaneswaran, S Sakshi, Dinesh Manocha

We present ABEX, a novel and effective generative data augmentation
methodology for low-resource Natural Language Understanding (NLU) tasks. ABEX
is based on ABstract-and-EXpand, a novel paradigm for generating diverse forms
of an input document -- we first convert a document into its concise, abstract
description and then generate new documents based on expanding the resultant
abstraction. To learn the task of expanding abstract descriptions, we first
train BART on a large-scale synthetic dataset with abstract-document pairs.
Next, to generate abstract descriptions for a document, we propose a simple,
controllable, and training-free method based on editing AMR graphs. ABEX brings
the best of both worlds: by expanding from abstract representations, it
preserves the original semantic properties of the documents, like style and
meaning, thereby maintaining alignment with the original label and data
distribution. At the same time, the fundamental process of elaborating on
abstract descriptions facilitates diverse generations. We demonstrate the
effectiveness of ABEX on 4 NLU tasks spanning 12 datasets and 4 low-resource
settings. ABEX outperforms all our baselines qualitatively with improvements of
0.04% - 38.8%. Qualitatively, ABEX outperforms all prior methods from
literature in terms of context and length diversity.

ÊëòË¶ÅÔºöÊàëÂÄëÊèêÂá∫ ABEXÔºå‰∏ÄÁ®ÆÊñ∞Á©é‰∏îÊúâÊïàÁöÑÁîüÊàêÂºèË≥áÊñôÊì¥Â¢ûÊñπÊ≥ïÔºåÈÅ©Áî®Êñº‰ΩéË≥áÊ∫êËá™ÁÑ∂Ë™ûË®ÄÁêÜËß£ (NLU) ‰ªªÂãô„ÄÇABEX Âª∫Á´ãÂú® ABstract-and-EXpand ‰πã‰∏äÔºåÈÄôÊòØ‰∏ÄÁ®ÆÁî®ÊñºÁî¢ÁîüËº∏ÂÖ•Êñá‰ª∂‰∏çÂêåÂΩ¢ÂºèÁöÑÊñ∞Á©éÁØÑ‰æã - ÊàëÂÄëÈ¶ñÂÖàÂ∞áÊñá‰ª∂ËΩâÊèõÊàêÁ∞°ÊΩîÁöÑÊäΩË±°ÊèèËø∞ÔºåÁÑ∂ÂæåÊ†πÊìöÊì¥Â±ïÊâÄÂæóÊäΩË±°Áî¢ÁîüÊñ∞Êñá‰ª∂„ÄÇÁÇ∫‰∫ÜÂ≠∏ÁøíÊì¥Â±ïÊäΩË±°ÊèèËø∞ÁöÑ‰ªªÂãôÔºåÊàëÂÄëÈ¶ñÂÖàÂú®ÂÖ∑ÊúâÊäΩË±°Êñá‰ª∂ÈÖçÂ∞çÁöÑÂ§ßË¶èÊ®°ÂêàÊàêË≥áÊñôÈõÜ‰∏äË®ìÁ∑¥ BART„ÄÇÊé•‰∏ã‰æÜÔºåÁÇ∫‰∫ÜÁî¢ÁîüÊñá‰ª∂ÁöÑÊäΩË±°ÊèèËø∞ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÁ∞°ÂñÆ„ÄÅÂèØÊéß‰∏îÁÑ°ÈúÄË®ìÁ∑¥ÁöÑÊñπÊ≥ïÔºåË©≤ÊñπÊ≥ïÂü∫ÊñºÁ∑®ËºØ AMR ÂúñË°®„ÄÇABEX Â∏∂‰æÜ‰∫ÜÂÖ©ÂÖ®ÂÖ∂ÁæéÁöÑÂÑ™ÈªûÔºöÈÄöÈÅéÂæûÊäΩË±°Ë°®Á§∫‰∏≠Êì¥Â±ïÔºåÂÆÉ‰øùÁïô‰∫ÜÊñá‰ª∂ÁöÑÂéüÂßãË™ûÁæ©Â±¨ÊÄßÔºå‰æãÂ¶ÇÈ¢®Ê†ºÂíåÊÑèÁæ©ÔºåÂæûËÄå‰øùÊåÅËàáÂéüÂßãÊ®ôÁ±§ÂíåË≥áÊñôÂàÜ‰ΩàÁöÑ‰∏ÄËá¥ÊÄß„ÄÇÂêåÊôÇÔºåÈó°Ëø∞ÊäΩË±°ÊèèËø∞ÁöÑÂü∫Êú¨ÈÅéÁ®ã‰øÉÈÄ≤‰∫ÜÂ§öÊ®£ÂåñÁöÑÁîüÊàê„ÄÇÊàëÂÄëÂú®Ê©´Ë∑® 12 ÂÄãË≥áÊñôÈõÜÂíå 4 ÂÄã‰ΩéË≥áÊ∫êË®≠ÂÆöÁöÑ 4 ÂÄã NLU ‰ªªÂãô‰∏äÂ±ïÁ§∫‰∫Ü ABEX ÁöÑÊúâÊïàÊÄß„ÄÇABEX Âú®Ë≥™Èáè‰∏äÂÑ™ÊñºÊàëÂÄëÊâÄÊúâÁöÑÂü∫Ê∫ñÔºåÊîπÈÄ≤‰∫Ü 0.04% - 38.8%„ÄÇÂú®Ë≥™Èáè‰∏äÔºåABEX Âú®ËÉåÊôØÂíåÈï∑Â∫¶Â§öÊ®£ÊÄßÊñπÈù¢ÂÑ™ÊñºÊñáÁçª‰∏≠ÁöÑÊâÄÊúâÂÖàÂâçÊñπÊ≥ï„ÄÇ

##### **Characterizing Similarities and Divergences in Conversational Tones in Humans and LLMs by Sampling with People**
2406.04278v1 by Dun-Ming Huang, Pol Van Rijn, Ilia Sucholutsky, Raja Marjieh, Nori Jacoby

Conversational tones -- the manners and attitudes in which speakers
communicate -- are essential to effective communication. Amidst the increasing
popularization of Large Language Models (LLMs) over recent years, it becomes
necessary to characterize the divergences in their conversational tones
relative to humans. However, existing investigations of conversational
modalities rely on pre-existing taxonomies or text corpora, which suffer from
experimenter bias and may not be representative of real-world distributions for
the studies' psycholinguistic domains. Inspired by methods from cognitive
science, we propose an iterative method for simultaneously eliciting
conversational tones and sentences, where participants alternate between two
tasks: (1) one participant identifies the tone of a given sentence and (2) a
different participant generates a sentence based on that tone. We run 100
iterations of this process with human participants and GPT-4, then obtain a
dataset of sentences and frequent conversational tones. In an additional
experiment, humans and GPT-4 annotated all sentences with all tones. With data
from 1,339 human participants, 33,370 human judgments, and 29,900 GPT-4
queries, we show how our approach can be used to create an interpretable
geometric representation of relations between conversational tones in humans
and GPT-4. This work demonstrates how combining ideas from machine learning and
cognitive science can address challenges in human-computer interactions.

ÊëòË¶ÅÔºöÂ∞çË©±Ë™ûÊ∞£‚Äî‚ÄîË™™Ë©±ËÄÖÂú®Ê∫ùÈÄö‰∏≠Ë°®ÁèæÂá∫ÁöÑÁ¶ÆÂÑÄÂíåÊÖãÂ∫¶‚Äî‚ÄîÂ∞çÊñºÊúâÊïàÁöÑÊ∫ùÈÄöËá≥ÈóúÈáçË¶Å„ÄÇËøëÂπ¥‰æÜÔºåÈö®ËëóÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊôÆÂèäÔºåÊúâÂøÖË¶ÅÊèèËø∞ÂÆÉÂÄëÁöÑÂ∞çË©±Ë™ûÊ∞£Ëàá‰∫∫È°û‰πãÈñìÁöÑÂ∑ÆÁï∞„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÁöÑÂ∞çË©±Ê®°ÂºèÁ†îÁ©∂‰æùË≥¥ÊñºÁèæÊúâÁöÑÂàÜÈ°ûÊ≥ïÊàñÊñáÊú¨Ë™ûÊñôÂ∫´ÔºåÈÄô‰∫õÂàÜÈ°ûÊ≥ïÊàñË™ûÊñôÂ∫´Â≠òÂú®ÂØ¶È©óËÄÖÂÅèÂ∑ÆÔºå‰∏îÂèØËÉΩÁÑ°Ê≥ï‰ª£Ë°®Á†îÁ©∂ÁöÑÂøÉÁêÜË™ûË®ÄÂ≠∏È†òÂüüÁöÑÁúüÂØ¶‰∏ñÁïåÂàÜ‰Ωà„ÄÇÂèóË™çÁü•ÁßëÂ≠∏ÊñπÊ≥ïÁöÑÂïüÁôºÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆËø≠‰ª£ÊñπÊ≥ïÔºåÁî®ÊñºÂêåÊôÇÂºïÂá∫Â∞çË©±Ë™ûÊ∞£ÂíåÂè•Â≠êÔºåÂèÉËàáËÄÖÂú®ÂÖ©È†Ö‰ªªÂãô‰πãÈñì‰∫§ÊõøÈÄ≤Ë°åÔºö(1) ‰∏Ä‰ΩçÂèÉËàáËÄÖË≠òÂà•Áµ¶ÂÆöÂè•Â≠êÁöÑË™ûÊ∞£Ôºå(2) Âè¶‰∏Ä‰ΩçÂèÉËàáËÄÖÊ†πÊìöË©≤Ë™ûÊ∞£ÁîüÊàê‰∏ÄÂÄãÂè•Â≠ê„ÄÇÊàëÂÄëËàá‰∫∫È°ûÂèÉËàáËÄÖÂíå GPT-4 ‰∏ÄËµ∑ÈÅãË°åÊ≠§ÈÅéÁ®ãÁöÑ 100 Ê¨°Ëø≠‰ª£ÔºåÁÑ∂ÂæåÁç≤Âæó‰∏ÄÂÄãÂè•Â≠êÂíåÈ†ªÁπÅÂ∞çË©±Ë™ûÊ∞£ÁöÑÊï∏ÊìöÈõÜ„ÄÇÂú®È°çÂ§ñÁöÑÂØ¶È©ó‰∏≠Ôºå‰∫∫È°ûÂíå GPT-4 Áî®ÊâÄÊúâË™ûÊ∞£Ë®ªÈáã‰∫ÜÊâÄÊúâÂè•Â≠ê„ÄÇÂà©Áî®‰æÜËá™ 1,339 ‰Ωç‰∫∫È°ûÂèÉËàáËÄÖ„ÄÅ33,370 ÂÄã‰∫∫È°ûÂà§Êñ∑Âíå 29,900 ÂÄã GPT-4 Êü•Ë©¢ÁöÑÊï∏ÊìöÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜÊàëÂÄëÁöÑÊñπÊ≥ïÂ¶Ç‰ΩïÁî®ÊñºÂâµÂª∫‰∫∫È°ûÂíå GPT-4 ‰∏≠Â∞çË©±Ë™ûÊ∞£‰πãÈñìÈóú‰øÇÁöÑÂèØËß£ÈáãÂπæ‰ΩïË°®Á§∫„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÂ±ïÁ§∫‰∫ÜÂ¶Ç‰ΩïÁµêÂêàÊ©üÂô®Â≠∏ÁøíÂíåË™çÁü•ÁßëÂ≠∏ÁöÑÁêÜÂøµ‰æÜÊáâÂ∞ç‰∫∫Ê©ü‰∫§‰∫í‰∏≠ÁöÑÊåëÊà∞„ÄÇ

##### **Generative AI-in-the-loop: Integrating LLMs and GPTs into the Next Generation Networks**
2406.04276v1 by Han Zhang, Akram Bin Sediq, Ali Afana, Melike Erol-Kantarci

In recent years, machine learning (ML) techniques have created numerous
opportunities for intelligent mobile networks and have accelerated the
automation of network operations. However, complex network tasks may involve
variables and considerations even beyond the capacity of traditional ML
algorithms. On the other hand, large language models (LLMs) have recently
emerged, demonstrating near-human-level performance in cognitive tasks across
various fields. However, they remain prone to hallucinations and often lack
common sense in basic tasks. Therefore, they are regarded as assistive tools
for humans. In this work, we propose the concept of "generative AI-in-the-loop"
and utilize the semantic understanding, context awareness, and reasoning
abilities of LLMs to assist humans in handling complex or unforeseen situations
in mobile communication networks. We believe that combining LLMs and ML models
allows both to leverage their respective capabilities and achieve better
results than either model alone. To support this idea, we begin by analyzing
the capabilities of LLMs and compare them with traditional ML algorithms. We
then explore potential LLM-based applications in line with the requirements of
next-generation networks. We further examine the integration of ML and LLMs,
discussing how they can be used together in mobile networks. Unlike existing
studies, our research emphasizes the fusion of LLMs with traditional ML-driven
next-generation networks and serves as a comprehensive refinement of existing
surveys. Finally, we provide a case study to enhance ML-based network intrusion
detection with synthesized data generated by LLMs. Our case study further
demonstrates the advantages of our proposed idea.

ÊëòË¶ÅÔºöËøëÂπ¥‰æÜÔºåÊ©üÂô®Â≠∏Áøí (ML) ÊäÄË°ìÁÇ∫Êô∫ÊÖßÂûãË°åÂãïÁ∂≤Ë∑ØÂâµÈÄ†‰∫ÜË®±Â§öÊ©üÊúÉÔºå‰∏¶Âä†ÈÄü‰∫ÜÁ∂≤Ë∑ØÈÅã‰ΩúÁöÑËá™ÂãïÂåñ„ÄÇÁÑ∂ËÄåÔºåË§áÈõúÁöÑÁ∂≤Ë∑Ø‰ªªÂãôÂèØËÉΩÊ∂âÂèäÁöÑËÆäÊï∏ÂíåËÄÉÈáèÔºåÁîöËá≥Ë∂ÖÂá∫ÂÇ≥Áµ± ML ÊºîÁÆóÊ≥ïÁöÑËÉΩÂäõ„ÄÇÂè¶‰∏ÄÊñπÈù¢ÔºåÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ËøëÊúüÊµÆÁèæÔºåÂú®ÂêÑÂÄãÈ†òÂüüÁöÑË™çÁü•‰ªªÂãô‰∏≠Â±ïÁèæÂá∫Êé•Ëøë‰∫∫È°ûÊ∞¥Ê∫ñÁöÑË°®Áèæ„ÄÇÁÑ∂ËÄåÔºåÂÆÉÂÄë‰ªçÁÑ∂ÂÆπÊòìÁî¢ÁîüÂπªË¶∫ÔºåËÄå‰∏îÂú®Âü∫Êú¨‰ªªÂãô‰∏≠Â∏∏Â∏∏Áº∫‰πèÂ∏∏Ë≠ò„ÄÇÂõ†Ê≠§ÔºåÂÆÉÂÄëË¢´Ë¶ñÁÇ∫‰∫∫È°ûÁöÑËºîÂä©Â∑•ÂÖ∑„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫„ÄåÁîüÊàêÂºè AI-in-the-loop„ÄçÁöÑÊ¶ÇÂøµÔºå‰∏¶Âà©Áî® LLM ÁöÑË™ûÊÑèÁêÜËß£„ÄÅËÑàÁµ°ÊÑüÁü•ÂíåÊé®ÁêÜËÉΩÂäõÔºåÂçîÂä©‰∫∫È°ûËôïÁêÜË°åÂãïÈÄöË®äÁ∂≤Ë∑Ø‰∏≠Ë§áÈõúÊàñÁÑ°Ê≥ïÈ†êË¶ãÁöÑÊÉÖÊ≥Å„ÄÇÊàëÂÄëÁõ∏‰ø°ÔºåÁµêÂêà LLM Âíå ML Ê®°ÂûãÔºåÂèØ‰ª•ËÆìÂÖ©ËÄÖÈÉΩËÉΩÁôºÊèÆÂêÑËá™ÁöÑËÉΩÂäõÔºå‰∏¶ÈÅîÊàêÊØîÂñÆ‰∏ÄÊ®°ÂûãÊõ¥Â•ΩÁöÑÁµêÊûú„ÄÇÁÇ∫‰∫ÜÊîØÊåÅÈÄôÂÄãÊÉ≥Ê≥ïÔºåÊàëÂÄëÈ¶ñÂÖàÂàÜÊûê LLM ÁöÑËÉΩÂäõÔºå‰∏¶Â∞áÂÆÉÂÄëËàáÂÇ≥Áµ±ÁöÑ ML ÊºîÁÆóÊ≥ïÈÄ≤Ë°åÊØîËºÉ„ÄÇÊé•ËëóÔºåÊàëÂÄëÊé¢Á¥¢ÊΩõÂú®ÁöÑÂü∫Êñº LLM ÁöÑÊáâÁî®Ôºå‰ª•Á¨¶ÂêàÊ¨°‰∏ñ‰ª£Á∂≤Ë∑ØÁöÑÈúÄÊ±Ç„ÄÇÊàëÂÄëÈÄ≤‰∏ÄÊ≠•Êé¢Ë®é ML Âíå LLM ÁöÑÊï¥ÂêàÔºåË®éË´ñÂ¶Ç‰ΩïÂ∞áÂÆÉÂÄë‰∏ÄËµ∑Áî®ÊñºË°åÂãïÁ∂≤Ë∑Ø‰∏≠„ÄÇËàáÁèæÊúâÁöÑÁ†îÁ©∂‰∏çÂêåÔºåÊàëÂÄëÁöÑÁ†îÁ©∂Âº∑Ë™øÂ∞á LLM ËàáÂÇ≥Áµ± ML È©ÖÂãïÁöÑÊ¨°‰∏ñ‰ª£Á∂≤Ë∑ØËûçÂêàÔºå‰∏¶‰ΩúÁÇ∫ÁèæÊúâË™øÊü•ÁöÑÂÖ®Èù¢Á≤æÈÄ≤„ÄÇÊúÄÂæåÔºåÊàëÂÄëÊèê‰æõ‰∏ÄÂÄãÊ°à‰æãÁ†îÁ©∂Ôºå‰ª•‰ΩøÁî® LLM ÁîüÊàêÁöÑÂêàÊàêË≥áÊñô‰æÜÂ¢ûÂº∑Âü∫Êñº ML ÁöÑÁ∂≤Ë∑ØÂÖ•‰æµÂÅµÊ∏¨„ÄÇÊàëÂÄëÁöÑÊ°à‰æãÁ†îÁ©∂ÈÄ≤‰∏ÄÊ≠•Ë≠âÊòé‰∫ÜÊàëÂÄëÊâÄÊèêÂá∫ÁöÑÊÉ≥Ê≥ïÁöÑÂÑ™Èªû„ÄÇ

##### **Self-Play with Adversarial Critic: Provable and Scalable Offline Alignment for Language Models**
2406.04274v1 by Xiang Ji, Sanjeev Kulkarni, Mengdi Wang, Tengyang Xie

This work studies the challenge of aligning large language models (LLMs) with
offline preference data. We focus on alignment by Reinforcement Learning from
Human Feedback (RLHF) in particular. While popular preference optimization
methods exhibit good empirical performance in practice, they are not
theoretically guaranteed to converge to the optimal policy and can provably
fail when the data coverage is sparse by classical offline reinforcement
learning (RL) results. On the other hand, a recent line of work has focused on
theoretically motivated preference optimization methods with provable
guarantees, but these are not computationally efficient for large-scale
applications like LLM alignment. To bridge this gap, we propose SPAC, a new
offline preference optimization method with self-play, inspired by the
on-average pessimism technique from the offline RL literature, to be the first
provable and scalable approach to LLM alignment. We both provide theoretical
analysis for its convergence under single-policy concentrability for the
general function approximation setting and demonstrate its competitive
empirical performance for LLM alignment on a 7B Mistral model with Open LLM
Leaderboard evaluations.

ÊëòË¶ÅÔºöËøôÈ°πÂ∑•‰ΩúÁ†îÁ©∂‰∫ÜÂ∞ÜÂ§ßÂûãËØ≠Ë®ÄÊ®°Âûã (LLM) ‰∏éÁ¶ªÁ∫øÂÅèÂ•ΩÊï∞ÊçÆÂØπÈΩêÁöÑÊåëÊàò„ÄÇÊàë‰ª¨‰∏ìÊ≥®‰∫éÈÄöËøá‰∫∫Á±ªÂèçÈ¶àÂº∫ÂåñÂ≠¶‰π† (RLHF) ËøõË°åÂØπÈΩê„ÄÇËôΩÁÑ∂ÊµÅË°åÁöÑÂÅèÂ•Ω‰ºòÂåñÊñπÊ≥ïÂú®ÂÆûË∑µ‰∏≠Ë°®Áé∞Âá∫ËâØÂ•ΩÁöÑÁªèÈ™åÊÄßËÉΩÔºå‰ΩÜÂÆÉ‰ª¨Âú®ÁêÜËÆ∫‰∏äÂπ∂‰∏çËÉΩ‰øùËØÅÊî∂ÊïõÂà∞ÊúÄ‰ºòÁ≠ñÁï•ÔºåÂπ∂‰∏îÂΩìÊï∞ÊçÆË¶ÜÁõñÁéáÁ®ÄÁñèÊó∂ÔºåÂèØ‰ª•ËØÅÊòé‰ºöÂ§±Ë¥•ÔºåËøôÊòØÁªèÂÖ∏Á¶ªÁ∫øÂº∫ÂåñÂ≠¶‰π† (RL) ÁöÑÁªìÊûú„ÄÇÂè¶‰∏ÄÊñπÈù¢ÔºåÊúÄËøëÁöÑ‰∏ÄÁ≥ªÂàóÂ∑•‰ΩúÈõÜ‰∏≠Âú®ÂÖ∑ÊúâÂèØËØÅÊòé‰øùËØÅÁöÑÁêÜËÆ∫‰∏äÂä®Êú∫ÁöÑÂÅèÂ•Ω‰ºòÂåñÊñπÊ≥ï‰∏äÔºå‰ΩÜËøô‰∫õÊñπÊ≥ïÂØπ‰∫é LLM ÂØπÈΩêÁ≠âÂ§ßËßÑÊ®°Â∫îÁî®Á®ãÂ∫èÊù•ËØ¥Âú®ËÆ°ÁÆó‰∏äÊïàÁéá‰Ωé‰∏ã„ÄÇ‰∏∫‰∫ÜÂº•ÂêàËøô‰∏ÄÂ∑ÆË∑ùÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü SPACÔºåËøôÊòØ‰∏ÄÁßçÊñ∞ÁöÑÁ¶ªÁ∫øÂÅèÂ•Ω‰ºòÂåñÊñπÊ≥ïÔºåÂÖ∑ÊúâËá™ÂçöÂºàÔºåÁÅµÊÑüÊù•Ëá™Á¶ªÁ∫ø RL ÊñáÁåÆ‰∏≠ÁöÑÂπ≥ÂùáÊÇ≤ËßÇÊäÄÊúØÔºåÊàê‰∏∫ LLM ÂØπÈΩêÁöÑÁ¨¨‰∏Ä‰∏™ÂèØËØÅÊòé‰∏îÂèØÊâ©Â±ïÁöÑÊñπÊ≥ï„ÄÇÊàë‰ª¨ÈíàÂØπÂÖ∂Âú®‰∏ÄËà¨ÂáΩÊï∞ÈÄºËøëËÆæÁΩÆ‰∏ãÈíàÂØπÂçïÁ≠ñÁï•ÈõÜ‰∏≠ÊÄßÁöÑÊî∂ÊïõÊÄßÊèê‰æõ‰∫ÜÁêÜËÆ∫ÂàÜÊûêÔºåÂπ∂Â±ïÁ§∫‰∫ÜÂÖ∂Âú®ÂÖ∑ÊúâÂºÄÊîæÂºè LLM ÊéíË°åÊ¶úËØÑ‰º∞ÁöÑ 7B Mistral Ê®°Âûã‰∏äÁöÑ LLM ÂØπÈΩêÁöÑÁ´û‰∫âÊÄßÁªèÈ™åÊÄßËÉΩ„ÄÇ

##### **Buffer of Thoughts: Thought-Augmented Reasoning with Large Language Models**
2406.04271v1 by Ling Yang, Zhaochen Yu, Tianjun Zhang, Shiyi Cao, Minkai Xu, Wentao Zhang, Joseph E. Gonzalez, Bin Cui

We introduce Buffer of Thoughts (BoT), a novel and versatile
thought-augmented reasoning approach for enhancing accuracy, efficiency and
robustness of large language models (LLMs). Specifically, we propose
meta-buffer to store a series of informative high-level thoughts, namely
thought-template, distilled from the problem-solving processes across various
tasks. Then for each problem, we retrieve a relevant thought-template and
adaptively instantiate it with specific reasoning structures to conduct
efficient reasoning. To guarantee the scalability and stability, we further
propose buffer-manager to dynamically update the meta-buffer, thus enhancing
the capacity of meta-buffer as more tasks are solved. We conduct extensive
experiments on 10 challenging reasoning-intensive tasks, and achieve
significant performance improvements over previous SOTA methods: 11% on Game of
24, 20% on Geometric Shapes and 51% on Checkmate-in-One. Further analysis
demonstrate the superior generalization ability and model robustness of our
BoT, while requiring only 12% of the cost of multi-query prompting methods
(e.g., tree/graph of thoughts) on average. Notably, we find that our
Llama3-8B+BoT has the potential to surpass Llama3-70B model. Our project is
available at: https://github.com/YangLing0818/buffer-of-thought-llm

ÊëòË¶ÅÔºö<paragraph>ÊàëÂÄë‰ªãÁ¥π‰∫ÜÊÄùÊÉ≥Á∑©Ë°ùÂçÄ (BoT)ÔºåÈÄôÊòØ‰∏ÄÁ®ÆÊñ∞Á©é‰∏îÈÄöÁî®ÁöÑÊÄùÊÉ≥Â¢ûÂº∑Êé®ÁêÜÊñπÊ≥ïÔºåÁî®ÊñºÊèêÂçáÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊ∫ñÁ¢∫ÊÄß„ÄÅÊïàÁéáÂíåÁ©©ÂÅ•ÊÄß„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÊèêÂá∫ÂÖÉÁ∑©Ë°ùÂçÄÔºåÁî®ÊñºÂÑ≤Â≠ò‰∏ÄÁ≥ªÂàóÊúâÊÑèÁæ©ÁöÑÈ´òÈöéÊÄùÊÉ≥ÔºåÂç≥ÊÄùÊÉ≥ÁØÑÊú¨ÔºåÂæûÂêÑÁ®Æ‰ªªÂãôÁöÑËß£Ê±∫ÂïèÈ°åÈÅéÁ®ã‰∏≠ÊèêÁÖâÂá∫‰æÜ„ÄÇÁÑ∂ÂæåÔºåÂ∞çÊñºÊØèÂÄãÂïèÈ°åÔºåÊàëÂÄëÊúÉÊì∑Âèñ‰∏ÄÂÄãÁõ∏ÈóúÁöÑÊÄùÊÉ≥ÁØÑÊú¨Ôºå‰∏¶‰ª•ÁâπÂÆöÁöÑÊé®ÁêÜÁµêÊßãËá™ÈÅ©ÊáâÂú∞ÂØ¶‰æãÂåñÂÆÉÔºå‰ª•ÈÄ≤Ë°åÊúâÊïàÁéáÁöÑÊé®ÁêÜ„ÄÇÁÇ∫‰∫Ü‰øùË≠âÂèØÊì¥ÂÖÖÊÄßÂíåÁ©©ÂÆöÊÄßÔºåÊàëÂÄëÈÄ≤‰∏ÄÊ≠•ÊèêÂá∫‰∫ÜÁ∑©Ë°ùÂçÄÁÆ°ÁêÜÂì°ÔºåÁî®ÊñºÂãïÊÖãÊõ¥Êñ∞ÂÖÉÁ∑©Ë°ùÂçÄÔºåÂæûËÄåÈö®ËëóÊõ¥Â§ö‰ªªÂãôÁöÑËß£Ê±∫ËÄåÊèêÂçáÂÖÉÁ∑©Ë°ùÂçÄÁöÑÂÆπÈáè„ÄÇÊàëÂÄëÂú® 10 È†ÖÂÖ∑ÊúâÊåëÊà∞ÊÄßÁöÑÊé®ÁêÜÂØÜÈõÜÂûã‰ªªÂãô‰∏äÈÄ≤Ë°å‰∫ÜÂª£Ê≥õÁöÑÂØ¶È©óÔºå‰∏¶‰∏îÁõ∏ËºÉÊñºÂÖàÂâçÁöÑ SOTA ÊñπÊ≥ïÂèñÂæó‰∫ÜÈ°ØËëóÁöÑÊïàËÉΩÊèêÂçáÔºö24 ÁöÑÈÅäÊà≤ÊèêÂçá‰∫Ü 11%ÔºåÂπæ‰ΩïÂΩ¢ÁãÄÊèêÂçá‰∫Ü 20%Ôºå‰∏ÄÊãõÂ∞áÊ≠ªÊèêÂçá‰∫Ü 51%„ÄÇÈÄ≤‰∏ÄÊ≠•ÁöÑÂàÜÊûêË≠âÊòé‰∫ÜÊàëÂÄë BoT ÁöÑÂÑ™Áï∞Ê≥õÂåñËÉΩÂäõÂíåÊ®°ÂûãÁ©©ÂÅ•ÊÄßÔºåÂêåÊôÇÂπ≥ÂùáÂè™ÈúÄË¶ÅÂ§öÊü•Ë©¢ÊèêÁ§∫ÊñπÊ≥ïÔºà‰æãÂ¶ÇÊÄùÊÉ≥Ê®π/ÂúñÔºâÊàêÊú¨ÁöÑ 12%„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÊàëÂÄëÁôºÁèæÊàëÂÄëÁöÑ Llama3-8B+BoT ÊúâÂèØËÉΩË∂ÖË∂ä Llama3-70B Ê®°Âûã„ÄÇÊàëÂÄëÁöÑÂ∞àÊ°àÂèØÊñº‰ª•‰∏ãÁ∂≤ÂùÄÂèñÂæóÔºöhttps://github.com/YangLing0818/buffer-of-thought-llm</paragraph>

##### **Open-Endedness is Essential for Artificial Superhuman Intelligence**
2406.04268v1 by Edward Hughes, Michael Dennis, Jack Parker-Holder, Feryal Behbahani, Aditi Mavalankar, Yuge Shi, Tom Schaul, Tim Rocktaschel

In recent years there has been a tremendous surge in the general capabilities
of AI systems, mainly fuelled by training foundation models on internetscale
data. Nevertheless, the creation of openended, ever self-improving AI remains
elusive. In this position paper, we argue that the ingredients are now in place
to achieve openendedness in AI systems with respect to a human observer.
Furthermore, we claim that such open-endedness is an essential property of any
artificial superhuman intelligence (ASI). We begin by providing a concrete
formal definition of open-endedness through the lens of novelty and
learnability. We then illustrate a path towards ASI via open-ended systems
built on top of foundation models, capable of making novel, humanrelevant
discoveries. We conclude by examining the safety implications of
generally-capable openended AI. We expect that open-ended foundation models
will prove to be an increasingly fertile and safety-critical area of research
in the near future.

ÊëòË¶ÅÔºöËøëÂπ¥Êù•Ôºå‰∫∫Â∑•Êô∫ËÉΩÁ≥ªÁªüÁöÑÊï¥‰ΩìËÉΩÂäõÂ§ßÂπÖÊèêÂçáÔºåËøô‰∏ªË¶ÅÂΩíÂäü‰∫éÂú®‰∫íËÅîÁΩëËßÑÊ®°ÁöÑÊï∞ÊçÆ‰∏äËÆ≠ÁªÉÂü∫Á°ÄÊ®°Âûã„ÄÇÁÑ∂ËÄåÔºåÂàõÂª∫ÂºÄÊîæÂºè„ÄÅ‰∏çÊñ≠Ëá™ÊàëÂÆåÂñÑÁöÑ‰∫∫Â∑•Êô∫ËÉΩ‰ªçÁÑ∂Èöæ‰ª•ÂÆûÁé∞„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨ËÆ§‰∏∫Áé∞Âú®Â∑≤ÁªèÂÖ∑Â§á‰∫ÜÂú®‰∫∫Á±ªËßÇÂØüËÄÖÊñπÈù¢ÂÆûÁé∞‰∫∫Â∑•Êô∫ËÉΩÁ≥ªÁªüÂºÄÊîæÊÄßÁöÑÊù°‰ª∂„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨ËÆ§‰∏∫ËøôÁßçÂºÄÊîæÊÄßÊòØ‰ªª‰Ωï‰∫∫Â∑•Êô∫ËÉΩË∂Ö‰∫∫Á±ªÊô∫ËÉΩ (ASI) ÁöÑÊú¨Ë¥®Â±ûÊÄß„ÄÇÊàë‰ª¨È¶ñÂÖàÈÄöËøáÊñ∞È¢ñÊÄßÂíåÂèØÂ≠¶‰π†ÊÄßÁöÑËßÜËßíÂØπÂºÄÊîæÊÄßÊèê‰æõ‰∏Ä‰∏™ÂÖ∑‰ΩìÁöÑÂΩ¢ÂºèÂåñÂÆö‰πâ„ÄÇÁÑ∂ÂêéÔºåÊàë‰ª¨ÈÄöËøáÂª∫Á´ãÂú®Âü∫Á°ÄÊ®°Âûã‰πã‰∏äÁöÑÂºÄÊîæÂºèÁ≥ªÁªüÔºåÂ±ïÁ§∫‰∫Ü‰∏ÄÊù°ÈÄöÂæÄ ASI ÁöÑÈÅìË∑ØÔºåËØ•Á≥ªÁªüËÉΩÂ§üËøõË°åÊñ∞È¢ñÁöÑ„ÄÅ‰∏é‰∫∫Á±ªÁõ∏ÂÖ≥ÁöÑÂèëÁé∞„ÄÇÊúÄÂêéÔºåÊàë‰ª¨ÈÄöËøáÊ£ÄÊü•ÈÄöÁî®ÂºÄÊîæÂºè‰∫∫Â∑•Êô∫ËÉΩÁöÑÂÆâÂÖ®ÂΩ±ÂìçÊù•ÁªìÊùüÊú¨Êñá„ÄÇÊàë‰ª¨È¢ÑËÆ°ÂºÄÊîæÂºèÂü∫Á°ÄÊ®°ÂûãÂ∞ÜÂú®‰∏ç‰πÖÁöÑÂ∞ÜÊù•Ë¢´ËØÅÊòéÊòØ‰∏Ä‰∏™Ë∂äÊù•Ë∂äËÇ•Ê≤É‰∏îÂØπÂÆâÂÖ®Ëá≥ÂÖ≥ÈáçË¶ÅÁöÑÁ†îÁ©∂È¢ÜÂüü„ÄÇ

##### **Transformers need glasses! Information over-squashing in language tasks**
2406.04267v1 by Federico Barbero, Andrea Banino, Steven Kapturowski, Dharshan Kumaran, Jo√£o G. M. Ara√∫jo, Alex Vitvitskyi, Razvan Pascanu, Petar Veliƒçkoviƒá

We study how information propagates in decoder-only Transformers, which are
the architectural backbone of most existing frontier large language models
(LLMs). We rely on a theoretical signal propagation analysis -- specifically,
we analyse the representations of the last token in the final layer of the
Transformer, as this is the representation used for next-token prediction. Our
analysis reveals a representational collapse phenomenon: we prove that certain
distinct sequences of inputs to the Transformer can yield arbitrarily close
representations in the final token. This effect is exacerbated by the
low-precision floating-point formats frequently used in modern LLMs. As a
result, the model is provably unable to respond to these sequences in different
ways -- leading to errors in, e.g., tasks involving counting or copying.
Further, we show that decoder-only Transformer language models can lose
sensitivity to specific tokens in the input, which relates to the well-known
phenomenon of over-squashing in graph neural networks. We provide empirical
evidence supporting our claims on contemporary LLMs. Our theory also points to
simple solutions towards ameliorating these issues.

ÊëòË¶ÅÔºöÊàëÂÄëÁ†îÁ©∂Ë≥áË®äÂú®ÂÉÖËß£Á¢ºÂô® Transformer ‰∏≠Â¶Ç‰ΩïÂÇ≥Êí≠ÔºåËÄåÂÉÖËß£Á¢ºÂô® Transformer ÊòØÁèæÊúâÊúÄÂâçÊ≤øÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊû∂Êßã‰∏ªÂππ„ÄÇÊàëÂÄë‰æùË≥¥ÊñºÁêÜË´ñË®äËôüÂÇ≥Êí≠ÂàÜÊûêÔºåÁâπÂà•ÊòØÔºåÊàëÂÄëÂàÜÊûê Transformer ÊúÄÂæå‰∏ÄÂ±§‰∏≠ÊúÄÂæå‰∏ÄÂÄã‰ª£Âπ£ÁöÑË°®ÂæµÔºåÂõ†ÁÇ∫ÈÄôÊòØÁî®Êñº‰∏ã‰∏ÄÂÄã‰ª£Âπ£È†êÊ∏¨ÁöÑË°®Âæµ„ÄÇÊàëÂÄëÁöÑÂàÜÊûêÊè≠Á§∫‰∫Ü‰∏ÄÂÄãË°®ÂæµÂ¥©ÊΩ∞ÁèæË±°ÔºöÊàëÂÄëË≠âÊòéËº∏ÂÖ•Âà∞ Transformer ÁöÑÊüê‰∫õ‰∏çÂêåÈ†ÜÂ∫èÂ∫èÂàóÂèØ‰ª•Âú®ÊúÄÂæå‰∏ÄÂÄã‰ª£Âπ£‰∏≠Áî¢Áîü‰ªªÊÑèÊé•ËøëÁöÑË°®Âæµ„ÄÇÈÄôÁ®ÆÊïàÊáâÊúÉÂõ†Áèæ‰ª£ LLM ‰∏≠Á∂ìÂ∏∏‰ΩøÁî®ÁöÑ‰ΩéÁ≤æÂ∫¶ÊµÆÈªûÊ†ºÂºèËÄåÂä†Âäá„ÄÇÁµêÊûúÔºåË©≤Ê®°ÂûãÁÑ°Ê≥ïÂ∞çÈÄô‰∫õÂ∫èÂàó‰ª•‰∏çÂêåÁöÑÊñπÂºèÂÅöÂá∫ÂõûÊáâÔºåÂ∞éËá¥ÈåØË™§Ôºå‰æãÂ¶ÇÊ∂âÂèäË®àÊï∏ÊàñË§áË£ΩÁöÑ‰ªªÂãô„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëË°®ÊòéÂÉÖËß£Á¢ºÂô® Transformer Ë™ûË®ÄÊ®°ÂûãÂèØËÉΩÊúÉÂ∞çËº∏ÂÖ•‰∏≠ÁöÑÁâπÂÆö‰ª£Âπ£Â§±ÂéªÊïèÊÑüÊÄßÔºåÈÄôËàáÂúñÁ•ûÁ∂ìÁ∂≤Ë∑Ø‰∏≠ÁúæÊâÄÂë®Áü•ÁöÑÈÅéÂ∫¶Â£ìÁ∏ÆÁèæË±°ÊúâÈóú„ÄÇÊàëÂÄëÊèê‰æõÁ∂ìÈ©óË≠âÊìöÊîØÊåÅÊàëÂÄëÂ∞çÁï∂‰ª£ LLM ÁöÑË™™Ê≥ï„ÄÇÊàëÂÄëÁöÑÁêÜË´ñ‰πüÊåáÂá∫‰∫ÜÊîπÂñÑÈÄô‰∫õÂïèÈ°åÁöÑÁ∞°ÂñÆËß£Ê±∫ÊñπÊ°à„ÄÇ

##### **MLVU: A Comprehensive Benchmark for Multi-Task Long Video Understanding**
2406.04264v1 by Junjie Zhou, Yan Shu, Bo Zhao, Boya Wu, Shitao Xiao, Xi Yang, Yongping Xiong, Bo Zhang, Tiejun Huang, Zheng Liu

The evaluation of Long Video Understanding (LVU) performance poses an
important but challenging research problem. Despite previous efforts, the
existing video understanding benchmarks are severely constrained by several
issues, especially the insufficient lengths of videos, a lack of diversity in
video types and evaluation tasks, and the inappropriateness for evaluating LVU
performances. To address the above problems, we propose a new benchmark, called
MLVU (Multi-task Long Video Understanding Benchmark), for the comprehensive and
in-depth evaluation of LVU. MLVU presents the following critical values: 1) The
substantial and flexible extension of video lengths, which enables the
benchmark to evaluate LVU performance across a wide range of durations. 2) The
inclusion of various video genres, e.g., movies, surveillance footage,
egocentric videos, cartoons, game videos, etc., which reflects the models' LVU
performances in different scenarios. 3) The development of diversified
evaluation tasks, which enables a comprehensive examination of MLLMs' key
abilities in long-video understanding. The empirical study with 20 latest MLLMs
reveals significant room for improvement in today's technique, as all existing
methods struggle with most of the evaluation tasks and exhibit severe
performance degradation when handling longer videos. Additionally, it suggests
that factors such as context length, image-understanding quality, and the
choice of LLM backbone can play critical roles in future advancements. We
anticipate that MLVU will advance the research of long video understanding by
providing a comprehensive and in-depth analysis of MLLMs.

ÊëòË¶ÅÔºöÈï∑ÂΩ±ÁâáÁêÜËß£ (LVU) ÊïàËÉΩÁöÑË©ï‰º∞ÊèêÂá∫‰∏ÄÂÄãÈáçË¶Å‰ΩÜÂÖ∑ÊåëÊà∞ÊÄßÁöÑÁ†îÁ©∂ÂïèÈ°å„ÄÇÂÑòÁÆ°ÂÖàÂâçÂ∑≤ÂÅöÂá∫Âä™ÂäõÔºåÁèæÊúâÁöÑÂΩ±ÁâáÁêÜËß£Âü∫Ê∫ñÂèóÂà∞ÂπæÂÄãÂïèÈ°åÁöÑÂö¥ÈáçÈôêÂà∂ÔºåÁâπÂà•ÊòØÂΩ±ÁâáÈï∑Â∫¶‰∏çË∂≥„ÄÅÂΩ±ÁâáÈ°ûÂûãÂíåË©ï‰º∞‰ªªÂãôÁº∫‰πèÂ§öÊ®£ÊÄßÔºå‰ª•Âèä‰∏çÈÅ©ÂêàË©ï‰º∞ LVU ÊïàËÉΩ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫‰∏äËø∞ÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÊñ∞ÁöÑÂü∫Ê∫ñÔºåÁ®±ÁÇ∫ MLVUÔºàÂ§ö‰ªªÂãôÈï∑ÂΩ±ÁâáÁêÜËß£Âü∫Ê∫ñÔºâÔºåÁî®ÊñºÂÖ®Èù¢Ê∑±ÂÖ•Ë©ï‰º∞ LVU„ÄÇMLVU ÂëàÁèæ‰ª•‰∏ãÂπæÂÄãÈóúÈçµÂÉπÂÄºÔºö1) ÂΩ±ÁâáÈï∑Â∫¶ÁöÑÂØ¶Ë≥™‰∏îÂΩàÊÄßÂª∂‰º∏Ôºå‰ΩøÂü∫Ê∫ñËÉΩÂ§†Ë©ï‰º∞ÂêÑÁ®ÆÊôÇÈï∑ÁöÑ LVU ÊïàËÉΩ„ÄÇ2) Á¥çÂÖ•ÂêÑÁ®ÆÂΩ±ÁâáÈ°ûÂûãÔºå‰æãÂ¶ÇÈõªÂΩ±„ÄÅÁõ£Ë¶ñÈåÑÂΩ±„ÄÅËá™ÊãçÂΩ±Áâá„ÄÅÂç°ÈÄö„ÄÅÈÅäÊà≤ÂΩ±ÁâáÁ≠âÔºåÂèçÊò†Ê®°ÂûãÂú®‰∏çÂêåÂ†¥ÊôØ‰∏≠ÁöÑ LVU ÊïàËÉΩ„ÄÇ3) ÈñãÁôºÂ§öÊ®£ÂåñÁöÑË©ï‰º∞‰ªªÂãôÔºåÂÖ®Èù¢Ê™¢Ë¶ñ MLLM Âú®Èï∑ÂΩ±ÁâáÁêÜËß£‰∏≠ÁöÑÈóúÈçµËÉΩÂäõ„ÄÇÈáùÂ∞ç 20 ÂÄãÊúÄÊñ∞ MLLM ÈÄ≤Ë°åÁöÑÂØ¶Ë≠âÁ†îÁ©∂È°ØÁ§∫ÔºåÁï∂‰ªäÊäÄË°ìÊúâÈ°ØËëóÈÄ≤Ê≠•Á©∫ÈñìÔºåÂõ†ÁÇ∫ÊâÄÊúâÁèæÊúâÊñπÊ≥ïÂú®Â§ßÈÉ®ÂàÜË©ï‰º∞‰ªªÂãô‰∏≠ÈÉΩÈù¢Ëá®Âõ∞Èõ£Ôºå‰∏îÂú®ËôïÁêÜËºÉÈï∑ÂΩ±ÁâáÊôÇÊïàËÉΩÂö¥Èáç‰∏ãÈôç„ÄÇÊ≠§Â§ñÔºåÁ†îÁ©∂ÊåáÂá∫Ôºå‰æãÂ¶ÇËÑàÁµ°Èï∑Â∫¶„ÄÅÂΩ±ÂÉèÁêÜËß£ÂìÅË≥™Âíå LLM ‰∏ªÂππÁöÑÈÅ∏ÊìáÁ≠âÂõ†Á¥†ÔºåÂú®Êú™‰æÜÁöÑÈÄ≤Â±ï‰∏≠ÂèØËÉΩÊâÆÊºîÈóúÈçµËßíËâ≤„ÄÇÊàëÂÄëÈ†êÊúü MLVU Â∞áÈÄèÈÅéÊèê‰æõ MLLM ÁöÑÂÖ®Èù¢Ê∑±ÂÖ•ÂàÜÊûêÔºåÊé®ÈÄ≤Èï∑ÂΩ±ÁâáÁêÜËß£ÁöÑÁ†îÁ©∂„ÄÇ

##### **GeoGen: Geometry-Aware Generative Modeling via Signed Distance Functions**
2406.04254v2 by Salvatore Esposito, Qingshan Xu, Kacper Kania, Charlie Hewitt, Octave Mariotti, Lohit Petikam, Julien Valentin, Arno Onken, Oisin Mac Aodha

We introduce a new generative approach for synthesizing 3D geometry and
images from single-view collections. Most existing approaches predict
volumetric density to render multi-view consistent images. By employing
volumetric rendering using neural radiance fields, they inherit a key
limitation: the generated geometry is noisy and unconstrained, limiting the
quality and utility of the output meshes. To address this issue, we propose
GeoGen, a new SDF-based 3D generative model trained in an end-to-end manner.
Initially, we reinterpret the volumetric density as a Signed Distance Function
(SDF). This allows us to introduce useful priors to generate valid meshes.
However, those priors prevent the generative model from learning details,
limiting the applicability of the method to real-world scenarios. To alleviate
that problem, we make the transformation learnable and constrain the rendered
depth map to be consistent with the zero-level set of the SDF. Through the lens
of adversarial training, we encourage the network to produce higher fidelity
details on the output meshes. For evaluation, we introduce a synthetic dataset
of human avatars captured from 360-degree camera angles, to overcome the
challenges presented by real-world datasets, which often lack 3D consistency
and do not cover all camera angles. Our experiments on multiple datasets show
that GeoGen produces visually and quantitatively better geometry than the
previous generative models based on neural radiance fields.

ÊëòË¶ÅÔºöÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞ÁöÑÁîüÊàêÂºèÊñπÊ≥ïÔºåÁî®ÊñºÂæûÂñÆË¶ñÂúñÈõÜÂêà‰∏≠ÂêàÊàê 3D Âπæ‰ΩïÂíåÂΩ±ÂÉè„ÄÇÂ§ßÂ§öÊï∏ÁèæÊúâÊñπÊ≥ïÈ†êÊ∏¨È´îÁ©çÂØÜÂ∫¶‰ª•Ê∏≤ÊüìÂ§öË¶ñÂúñ‰∏ÄËá¥ÁöÑÂΩ±ÂÉè„ÄÇÈÄèÈÅé‰ΩøÁî®Á•ûÁ∂ìËºªÁÖßÂ†¥ÁöÑÈ´îÁ©çÊ∏≤ÊüìÔºåÂÆÉÂÄëÁπºÊâø‰∫Ü‰∏ÄÂÄãÈóúÈçµÈôêÂà∂ÔºöÁîüÊàêÁöÑÂπæ‰ΩïÂΩ¢ÁãÄÊúâÈõúË®ä‰∏î‰∏çÂèóÁ¥ÑÊùüÔºåÈôêÂà∂‰∫ÜËº∏Âá∫Á∂≤Ê†ºÁöÑÂìÅË≥™ÂíåÊïàÁî®„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∫Ü GeoGenÔºåÈÄôÊòØ‰∏ÄÂÄãÊñ∞ÁöÑÂü∫Êñº SDF ÁöÑ 3D ÁîüÊàêÊ®°ÂûãÔºå‰ª•Á´ØÂà∞Á´ØÁöÑÊñπÂºèÈÄ≤Ë°åË®ìÁ∑¥„ÄÇÊúÄÂàùÔºåÊàëÂÄëÂ∞áÈ´îÁ©çÂØÜÂ∫¶ÈáçÊñ∞Ë©ÆÈáãÁÇ∫ÊúâËôüË∑ùÈõ¢ÂáΩÊï∏ (SDF)„ÄÇÈÄôËÆìÊàëÂÄëËÉΩÂ§†ÂºïÂÖ•ÊúâÁî®ÁöÑÂÖàÈ©óÊ¢ù‰ª∂‰æÜÁîüÊàêÊúâÊïàÁöÑÁ∂≤Ê†º„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÂÖàÈ©óÊ¢ù‰ª∂ÊúÉÈòªÊ≠¢ÁîüÊàêÊ®°ÂûãÂ≠∏ÁøíÁ¥∞ÁØÄÔºåÈôêÂà∂‰∫ÜË©≤ÊñπÊ≥ïÂú®ÁúüÂØ¶‰∏ñÁïåÂ†¥ÊôØ‰∏≠ÁöÑÈÅ©Áî®ÊÄß„ÄÇÁÇ∫‰∫ÜÁ∑©Ëß£ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëËÆìËΩâÊèõÂèØÂ≠∏ÁøíÔºå‰∏¶Á¥ÑÊùüÊ∏≤ÊüìÁöÑÊ∑±Â∫¶ÂúñËàá SDF ÁöÑÈõ∂Á¥öÈõÜÂêà‰∏ÄËá¥„ÄÇÈÄèÈÅéÂ∞çÊäóË®ìÁ∑¥ÁöÑËßÄÈªûÔºåÊàëÂÄëÈºìÂãµÁ∂≤Ë∑ØÂú®Ëº∏Âá∫Á∂≤Ê†º‰∏äÁî¢ÁîüÊõ¥È´ò‰øùÁúüÁöÑÁ¥∞ÁØÄ„ÄÇÁÇ∫‰∫ÜË©ï‰º∞ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÁî± 360 Â∫¶Áõ∏Ê©üËßíÂ∫¶ÊçïÊçâÁöÑ‰∫∫È°ûÈ†≠ÂÉèÂêàÊàêË≥áÊñôÈõÜÔºå‰ª•ÂÖãÊúçÁúüÂØ¶‰∏ñÁïåË≥áÊñôÈõÜÂ∏∂‰æÜÁöÑÊåëÊà∞ÔºåÈÄô‰∫õË≥áÊñôÈõÜÈÄöÂ∏∏Áº∫‰πè 3D ‰∏ÄËá¥ÊÄßÔºå‰∏îÁÑ°Ê≥ïÊ∂µËìãÊâÄÊúâÁõ∏Ê©üËßíÂ∫¶„ÄÇÊàëÂÄëÂú®Â§öÂÄãË≥áÊñôÈõÜ‰∏äÁöÑÂØ¶È©óË°®ÊòéÔºåGeoGen Áî¢ÁîüÁöÑË¶ñË¶∫ÂíåÈáèÂåñÂπæ‰ΩïÊØîÂü∫ÊñºÁ•ûÁ∂ìËºªÁÖßÂ†¥ÁöÑÂÖàÂâçÁîüÊàêÊ®°ÂûãÊõ¥Â•Ω„ÄÇ

##### **Benchmark Data Contamination of Large Language Models: A Survey**
2406.04244v1 by Cheng Xu, Shuhao Guan, Derek Greene, M-Tahar Kechadi

The rapid development of Large Language Models (LLMs) like GPT-4, Claude-3,
and Gemini has transformed the field of natural language processing. However,
it has also resulted in a significant issue known as Benchmark Data
Contamination (BDC). This occurs when language models inadvertently incorporate
evaluation benchmark information from their training data, leading to
inaccurate or unreliable performance during the evaluation phase of the
process. This paper reviews the complex challenge of BDC in LLM evaluation and
explores alternative assessment methods to mitigate the risks associated with
traditional benchmarks. The paper also examines challenges and future
directions in mitigating BDC risks, highlighting the complexity of the issue
and the need for innovative solutions to ensure the reliability of LLM
evaluation in real-world applications.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâÂ¶Ç GPT-4„ÄÅClaude-3 Âíå Gemini ÁöÑÂø´ÈÄüÁôºÂ±ïÂ∑≤Á∂ìËΩâËÆä‰∫ÜËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜÁöÑÈ†òÂüü„ÄÇÁÑ∂ËÄåÔºåÂÆÉ‰πüÂ∞éËá¥‰∫Ü‰∏ÄÂÄãÁ®±ÁÇ∫Âü∫Ê∫ñË≥áÊñôÊ±°ÊüìÔºàBDCÔºâÁöÑÈáçÂ§ßÂïèÈ°å„ÄÇÈÄôÁôºÁîüÂú®Ë™ûË®ÄÊ®°ÂûãÁÑ°ÊÑè‰∏≠Â∞áË©ï‰º∞Âü∫Ê∫ñË≥áË®äÁ¥çÂÖ•ÂÖ∂Ë®ìÁ∑¥Ë≥áÊñôÊôÇÔºåÂ∞éËá¥Âú®ËôïÁêÜÁöÑË©ï‰º∞ÈöéÊÆµ‰∏≠Áî¢Áîü‰∏çÊ∫ñÁ¢∫Êàñ‰∏çÂèØÈù†ÁöÑÊïàËÉΩ„ÄÇÊú¨ÊñáÊé¢Ë®é‰∫Ü LLM Ë©ï‰º∞‰∏≠ BDC ÁöÑË§áÈõúÊåëÊà∞Ôºå‰∏¶Êé¢Ë®é‰∫ÜÊõø‰ª£Ë©ï‰º∞ÊñπÊ≥ï‰ª•Èôç‰ΩéËàáÂÇ≥Áµ±Âü∫Ê∫ñÁõ∏ÈóúÁöÑÈ¢®Èö™„ÄÇÊú¨Êñá‰πüÊé¢Ë®é‰∫ÜÊ∏õËºï BDC È¢®Èö™ÁöÑÊåëÊà∞ÂíåÊú™‰æÜÊñπÂêëÔºåÂº∑Ë™ø‰∫ÜÊ≠§ÂïèÈ°åÁöÑË§áÈõúÊÄßÔºå‰ª•ÂèäÈúÄË¶ÅÂâµÊñ∞ÁöÑËß£Ê±∫ÊñπÊ°à‰æÜÁ¢∫‰øù LLM Ë©ï‰º∞Âú®ÂØ¶ÈöõÊáâÁî®‰∏≠ÁöÑÂèØÈù†ÊÄß„ÄÇ

##### **Hypernetworks for Personalizing ASR to Atypical Speech**
2406.04240v2 by Max Mueller-Eberstein, Dianna Yee, Karren Yang, Gautam Varma Mantena, Colin Lea

Parameter-efficient fine-tuning (PEFT) for personalizing automatic speech
recognition (ASR) has recently shown promise for adapting general population
models to atypical speech. However, these approaches assume a priori knowledge
of the atypical speech disorder being adapted for -- the diagnosis of which
requires expert knowledge that is not always available. Even given this
knowledge, data scarcity and high inter/intra-speaker variability further limit
the effectiveness of traditional fine-tuning. To circumvent these challenges,
we first identify the minimal set of model parameters required for ASR
adaptation. Our analysis of each individual parameter's effect on adaptation
performance allows us to reduce Word Error Rate (WER) by half while adapting
0.03% of all weights. Alleviating the need for cohort-specific models, we next
propose the novel use of a meta-learned hypernetwork to generate highly
individualized, utterance-level adaptations on-the-fly for a diverse set of
atypical speech characteristics. Evaluating adaptation at the global, cohort
and individual-level, we show that hypernetworks generalize better to
out-of-distribution speakers, while maintaining an overall relative WER
reduction of 75.2% using 0.1% of the full parameter budget.

ÊëòË¶ÅÔºöÂèÉÊï∏È´òÊïàÂæÆË™ø (PEFT) Áî®ÊñºÂÄã‰∫∫ÂåñËá™ÂãïË™ûÈü≥Ëæ®Ë≠ò (ASR)ÔºåÊúÄËøëÂ∑≤È°ØÁ§∫Âá∫Â∞á‰∏ÄËà¨ÊóèÁæ§Ê®°ÂûãË™øÊï¥ÁÇ∫ÈùûÂÖ∏ÂûãË™ûÈü≥ÁöÑÂ∏åÊúõ„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÊñπÊ≥ïÂÅáË®≠ÂÖàÈ©óÁü•Ë≠òÔºåÂç≥ÈùûÂÖ∏ÂûãË™ûÈü≥ÈöúÁ§ôÊ≠£Âú®ÈÅ©Êáâ‚Äî‚ÄîË®∫Êñ∑ÈúÄË¶ÅÂ∞àÂÆ∂Áü•Ë≠òÔºåËÄåÈÄô‰∏¶‰∏çÁ∏ΩÊòØÂèØÁî®ÁöÑ„ÄÇÂç≥‰ΩøÊúâÈÄô‰∫õÁü•Ë≠òÔºåË≥áÊñôÁ®ÄÂ∞ëÂíåÈ´òË∑®/ÂÖßË™™Ë©±ËÄÖËÆäÁï∞ÊÄßÈÄ≤‰∏ÄÊ≠•ÈôêÂà∂‰∫ÜÂÇ≥Áµ±ÂæÆË™øÁöÑÊúâÊïàÊÄß„ÄÇÁÇ∫‰∫ÜÂÖãÊúçÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÈ¶ñÂÖàÊâæÂá∫ ASR ÈÅ©ÊáâÊâÄÈúÄÁöÑÊúÄÂ∞èÊ®°ÂûãÂèÉÊï∏ÁµÑ„ÄÇÊàëÂÄëÂ∞çÊØèÂÄãÂÄãÂà•ÂèÉÊï∏Â∞çÈÅ©ÊáâÊïàËÉΩÁöÑÂΩ±ÈüøÂàÜÊûêÔºå‰ΩøÊàëÂÄëËÉΩÂ§†Âú®ÈÅ©ÊáâÊâÄÊúâÊ¨äÈáçÁöÑ 0.03% ÊôÇÂ∞áÂ≠óÂÖÉÈåØË™§Áéá (WER) Ê∏õÂ∞ë‰∏ÄÂçä„ÄÇÁÇ∫‰∫ÜÊ∏õËºïÂ∞çÁâπÂÆöÊñºÁæ§È´îÁöÑÊ®°ÂûãÁöÑÈúÄÊ±ÇÔºåÊàëÂÄëÊé•ËëóÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÂÖÉÂ≠∏ÁøíË∂ÖÁ∂≤Ë∑Ø‰ΩøÁî®ÊñπÂºèÔºå‰ª•ÂãïÊÖãÁî¢ÁîüÈ´òÂ∫¶ÂÄãÊÄßÂåñ„ÄÅË™ûÂè•Â±§Á¥öÁöÑÈÅ©ÊáâÔºå‰ª•ÈÅ©ÊáâÂêÑÁ®ÆÈùûÂÖ∏ÂûãË™ûÈü≥ÁâπÂæµ„ÄÇÂú®ÂÖ®ÁêÉ„ÄÅÁæ§È´îÂíåÂÄã‰∫∫Â±§Á¥öË©ï‰º∞ÈÅ©ÊáâÊôÇÔºåÊàëÂÄëÁôºÁèæË∂ÖÁ∂≤Ë∑ØËÉΩÊõ¥Â•ΩÂú∞Ê¶ÇÊã¨Âà∞ÂàÜÂ∏ÉÂ§ñÁöÑË™™Ë©±ËÄÖÔºåÂêåÊôÇ‰ΩøÁî® 0.1% ÁöÑÂÆåÊï¥ÂèÉÊï∏È†êÁÆóÔºåÁ∂≠ÊåÅÊï¥È´îÁõ∏Â∞ç WER Ê∏õÂ∞ë 75.2%„ÄÇ

##### **FairytaleQA Translated: Enabling Educational Question and Answer Generation in Less-Resourced Languages**
2406.04233v1 by Bernardo Leite, Tom√°s Freitas Os√≥rio, Henrique Lopes Cardoso

Question Answering (QA) datasets are crucial in assessing reading
comprehension skills for both machines and humans. While numerous datasets have
been developed in English for this purpose, a noticeable void exists in
less-resourced languages. To alleviate this gap, our paper introduces
machine-translated versions of FairytaleQA, a renowned QA dataset designed to
assess and enhance narrative comprehension skills in young children. By
employing fine-tuned, modest-scale models, we establish benchmarks for both
Question Generation (QG) and QA tasks within the translated datasets. In
addition, we present a case study proposing a model for generating
question-answer pairs, with an evaluation incorporating quality metrics such as
question well-formedness, answerability, relevance, and children suitability.
Our evaluation prioritizes quantifying and describing error cases, along with
providing directions for future work. This paper contributes to the advancement
of QA and QG research in less-resourced languages, promoting accessibility and
inclusivity in the development of these models for reading comprehension. The
code and data is publicly available at
github.com/bernardoleite/fairytaleqa-translated.

ÊëòË¶ÅÔºöÂïèÁ≠îÔºàQAÔºâË≥áÊñôÈõÜÂ∞çÊñºË©ï‰º∞Ê©üÂô®Âíå‰∫∫È°ûÁöÑÈñ±ËÆÄÁêÜËß£ËÉΩÂäõËá≥ÈóúÈáçË¶Å„ÄÇÈõñÁÑ∂Â∑≤Á∂ìÁÇ∫Ê≠§ÁõÆÁöÑÈñãÁôº‰∫ÜË®±Â§öËã±ÊñáË≥áÊñôÈõÜÔºå‰ΩÜÂú®Ë≥áÊ∫êËºÉÂ∞ëÁöÑË™ûË®Ä‰∏≠Â≠òÂú®ÊòéÈ°ØÁöÑÁ©∫ÁôΩ„ÄÇÁÇ∫‰∫ÜÁ∏ÆÂ∞èÈÄôÂÄãÂ∑ÆË∑ùÔºåÊàëÂÄëÁöÑË´ñÊñá‰ªãÁ¥π‰∫Ü FairytaleQA ÁöÑÊ©üÂô®ÁøªË≠ØÁâàÊú¨ÔºåFairytaleQA ÊòØÊó®Âú®Ë©ï‰º∞ÂíåÂ¢ûÂº∑ÂπºÁ´•Êïò‰∫ãÁêÜËß£ËÉΩÂäõÁöÑËëóÂêç QA Ë≥áÊñôÈõÜ„ÄÇÈÄöÈÅéÊé°Áî®ÂæÆË™øÁöÑÂ∞èË¶èÊ®°Ê®°ÂûãÔºåÊàëÂÄëÁÇ∫ÁøªË≠ØË≥áÊñôÈõÜ‰∏≠ÁöÑÂïèÈ°åÁî¢ÁîüÔºàQGÔºâÂíå QA ‰ªªÂãôÂª∫Á´ã‰∫ÜÂü∫Ê∫ñ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊ°à‰æãÁ†îÁ©∂ÔºåÊèêÂá∫‰∫Ü‰∏ÄÂÄãÁîüÊàêÂïèÈ°åÁ≠îÊ°àÂ∞çÁöÑÊ®°ÂûãÔºå‰∏¶ÈÄ≤Ë°åË©ï‰º∞ÔºåÂÖ∂‰∏≠ÂåÖÂê´ÂïèÈ°åÊ†ºÂºèËâØÂ•ΩÊÄß„ÄÅÂèØÂõûÁ≠îÊÄß„ÄÅÁõ∏ÈóúÊÄßÂíåÂÖíÁ´•ÈÅ©Áî®ÊÄßÁ≠âÂìÅË≥™ÊåáÊ®ô„ÄÇÊàëÂÄëÁöÑË©ï‰º∞ÂÑ™ÂÖàÈáèÂåñÂíåÊèèËø∞ÈåØË™§Ê°à‰æãÔºå‰∏¶ÁÇ∫Êú™‰æÜÁöÑÁ†îÁ©∂Êèê‰æõÊñπÂêë„ÄÇÊú¨ÊñáÊúâÂä©ÊñºÊé®ÂãïË≥áÊ∫êËºÉÂ∞ëË™ûË®Ä‰∏≠ÁöÑ QA Âíå QG Á†îÁ©∂Ôºå‰øÉÈÄ≤ÈÄô‰∫õÈñ±ËÆÄÁêÜËß£Ê®°ÂûãÁöÑÈñãÁôºÁöÑÂèØÂèäÊÄßÂíåÂåÖÂÆπÊÄß„ÄÇ‰ª£Á¢ºÂíåË≥áÊñôÂèØÂú® github.com/bernardoleite/fairytaleqa-translated ÂÖ¨ÈñãÁç≤Âæó„ÄÇ

##### **Quantifying Misalignment Between Agents**
2406.04231v1 by Aidan Kierans, Avijit Ghosh, Hananel Hazan, Shiri Dori-Hacohen

Growing concerns about the AI alignment problem have emerged in recent years,
with previous work focusing mainly on (1) qualitative descriptions of the
alignment problem; (2) attempting to align AI actions with human interests by
focusing on value specification and learning; and/or (3) focusing on a single
agent or on humanity as a singular unit. Recent work in sociotechnical AI
alignment has made some progress in defining alignment inclusively, but the
field as a whole still lacks a systematic understanding of how to specify,
describe, and analyze misalignment among entities, which may include individual
humans, AI agents, and complex compositional entities such as corporations,
nation-states, and so forth. Previous work on controversy in computational
social science offers a mathematical model of contention among populations (of
humans). In this paper, we adapt this contention model to the alignment
problem, and show how misalignment can vary depending on the population of
agents (human or otherwise) being observed, the domain in question, and the
agents' probability-weighted preferences between possible outcomes. Our model
departs from value specification approaches and focuses instead on the morass
of complex, interlocking, sometimes contradictory goals that agents may have in
practice. We apply our model by analyzing several case studies ranging from
social media moderation to autonomous vehicle behavior. By applying our model
with appropriately representative value data, AI engineers can ensure that
their systems learn values maximally aligned with diverse human interests.

ÊëòË¶ÅÔºöËøëÂπ¥‰æÜÔºåÂ∞çÊñº AI Â∞çÈΩäÂïèÈ°åÁöÑÊìîÊÜÇÊó•ÁõäÂ¢ûÂä†Ôºå
ÂÖàÂâçÁöÑÁ†îÁ©∂‰∏ªË¶ÅÈõÜ‰∏≠Êñº (1) Â∞çÈΩäÂïèÈ°åÁöÑÂÆöÊÄßÊèèËø∞Ôºõ(2) ÂòóË©¶ÈÄèÈÅéÂ∞àÊ≥®ÊñºÂÉπÂÄºË¶èÊ†ºÂíåÂ≠∏ÁøíÔºåÂ∞á AI Ë°åÂãïËàá‰∫∫È°ûÂà©Áõä‰øùÊåÅ‰∏ÄËá¥ÔºõÂíå/Êàñ (3) Â∞àÊ≥®ÊñºÂñÆ‰∏Ä‰ª£ÁêÜÊàñÂ∞á‰∫∫È°ûË¶ñÁÇ∫ÂñÆ‰∏ÄÂñÆ‰Ωç„ÄÇÊúÄËøëÂú®Á§æÊúÉÊäÄË°ì AI Â∞çÈΩäÊñπÈù¢ÁöÑÂ∑•‰ΩúÂú®ÂÆöÁæ©ÂåÖÂÆπÊÄßÂ∞çÈΩäÊñπÈù¢ÂèñÂæó‰∫Ü‰∏Ä‰∫õÈÄ≤Â±ïÔºå‰ΩÜÊï¥È´îÈ†òÂüü‰ªçÁº∫‰πèÁ≥ªÁµ±ÊÄßÁêÜËß£Ôºå‰∏çÁü•ÈÅìÂ¶Ç‰ΩïÂÖ∑È´îË™™Êòé„ÄÅÊèèËø∞ÂíåÂàÜÊûêÂØ¶È´î‰πãÈñìÁöÑ‰∏çÂ∞çÈΩäÔºåÂÖ∂‰∏≠ÂèØËÉΩÂåÖÊã¨ÂÄã‰∫∫‰∫∫È°û„ÄÅAI ‰ª£ÁêÜÂíåË§áÈõúÁöÑÁµÑÂêàÂØ¶È´îÔºå‰æãÂ¶ÇÂÖ¨Âè∏„ÄÅÊ∞ëÊóèÂúãÂÆ∂Á≠âÁ≠â„ÄÇÂÖàÂâçÊèêÂá∫ÁöÑË®àÁÆóÁ§æÊúÉÁßëÂ≠∏Áà≠Ë≠∞Á†îÁ©∂Êèê‰æõ‰∫Ü‰∫∫Áæ§Ôºà‰∫∫È°ûÔºâ‰πãÈñìÁà≠Ë≠∞ÁöÑÊï∏Â≠∏Ê®°Âûã„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂ∞áÊ≠§Áà≠Ë≠∞Ê®°ÂûãË™øÊï¥ÁÇ∫Â∞çÈΩäÂïèÈ°åÔºå‰∏¶Ë™™Êòé‰∏çÂ∞çÈΩäÂ¶Ç‰ΩïÊ†πÊìöÊâÄËßÄÂØüÁöÑ‰ª£ÁêÜ‰∫∫Áæ§Ôºà‰∫∫È°ûÊàñÂÖ∂‰ªñÔºâ„ÄÅÊúâÂïèÈ°åÁöÑÈ†òÂüü‰ª•Âèä‰ª£ÁêÜÂú®ÂèØËÉΩÁµêÊûú‰πãÈñìÁöÑÊ©üÁéáÂä†Ê¨äÂÅèÂ•ΩËÄåÊúâÊâÄ‰∏çÂêå„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÂÅèÈõ¢‰∫ÜÂÉπÂÄºË¶èÊ†ºÊñπÊ≥ïÔºåËÄåÂ∞àÊ≥®Êñº‰ª£ÁêÜÂú®ÂØ¶Âãô‰∏≠ÂèØËÉΩÊìÅÊúâÁöÑË§áÈõú„ÄÅÁõ∏‰∫íÈóúËÅØ„ÄÅÊúâÊôÇÁõ∏‰∫íÁüõÁõæÁöÑÁõÆÊ®ô„ÄÇÊàëÂÄëÈÄèÈÅéÂàÜÊûêÂæûÁ§æÁæ§Â™íÈ´îÂØ©Ê†∏Âà∞Ëá™ÂãïÈßïÈßõË°åÁÇ∫Á≠âÂ§öÂÄãÊ°à‰æãÁ†îÁ©∂Ôºå‰æÜÊáâÁî®ÊàëÂÄëÁöÑÊ®°Âûã„ÄÇÈÄèÈÅé‰ΩøÁî®ÈÅ©Áï∂ÁöÑ‰ª£Ë°®ÊÄßÂÉπÂÄºË≥áÊñôÊáâÁî®ÊàëÂÄëÁöÑÊ®°ÂûãÔºåAI Â∑•Á®ãÂ∏´ÂèØ‰ª•Á¢∫‰øù‰ªñÂÄëÁöÑÁ≥ªÁµ±Â≠∏ÁøíÂà∞ËàáÂ§öÂÖÉ‰∫∫È°ûÂà©ÁõäÊúÄÂ§ßÁ®ãÂ∫¶Â∞çÈΩäÁöÑÂÉπÂÄºËßÄ„ÄÇ

##### **M3LEO: A Multi-Modal, Multi-Label Earth Observation Dataset Integrating Interferometric SAR and RGB Data**
2406.04230v1 by Matthew J Allen, Francisco Dorr, Joseph Alejandro Gallego Mejia, Laura Mart√≠nez-Ferrer, Anna Jungbluth, Freddie Kalaitzis, Ra√∫l Ramos-Poll√°n

Satellite-based remote sensing has revolutionised the way we address global
challenges in a rapidly evolving world. Huge quantities of Earth Observation
(EO) data are generated by satellite sensors daily, but processing these large
datasets for use in ML pipelines is technically and computationally
challenging. Specifically, different types of EO data are often hosted on a
variety of platforms, with differing availability for Python preprocessing
tools. In addition, spatial alignment across data sources and data tiling can
present significant technical hurdles for novice users. While some preprocessed
EO datasets exist, their content is often limited to optical or near-optical
wavelength data, which is ineffective at night or in adverse weather
conditions. Synthetic Aperture Radar (SAR), an active sensing technique based
on microwave length radiation, offers a viable alternative. However, the
application of machine learning to SAR has been limited due to a lack of
ML-ready data and pipelines, particularly for the full diversity of SAR data,
including polarimetry, coherence and interferometry. We introduce M3LEO, a
multi-modal, multi-label EO dataset that includes polarimetric,
interferometric, and coherence SAR data derived from Sentinel-1, alongside
Sentinel-2 RGB imagery and a suite of labelled tasks for model evaluation.
M3LEO spans 17.5TB and contains approximately 10M data chips across six
geographic regions. The dataset is complemented by a flexible PyTorch Lightning
framework, with configuration management using Hydra. We provide tools to
process any dataset available on popular platforms such as Google Earth Engine
for integration with our framework. Initial experiments validate the utility of
our data and framework, showing that SAR imagery contains information
additional to that extractable from RGB data. Data at huggingface.co/M3LEO, and
code at github.com/spaceml-org/M3LEO.

ÊëòË¶ÅÔºö<paragraph>Âü∫ÊñºË°õÊòüÁöÑÈÅôÊ∏¨ÊäÄË°ìÂæπÂ∫ïÊîπËÆä‰∫ÜÊàëÂÄëÂú®Âø´ÈÄüËÆäÈÅ∑ÁöÑ‰∏ñÁïå‰∏≠ÊáâÂ∞çÂÖ®ÁêÉÊåëÊà∞ÁöÑÊñπÂºè„ÄÇË°õÊòüÊÑüÊ∏¨Âô®ÊØèÂ§©Áî¢ÁîüÂ§ßÈáèÁöÑÂú∞ÁêÉËßÄÊ∏¨ (EO) Ë≥áÊñôÔºå‰ΩÜËôïÁêÜÈÄô‰∫õÂ§ßÂûãË≥áÊñôÈõÜ‰ª•Áî®Êñº ML ÁÆ°Á∑öÂú®ÊäÄË°ìÂíåË®àÁÆó‰∏äÈÉΩÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÂÖ∑È´î‰æÜË™™Ôºå‰∏çÂêåÈ°ûÂûãÁöÑ EO Ë≥áÊñôÈÄöÂ∏∏ÊúÉÂÑ≤Â≠òÂú®ÂêÑÁ®ÆÂπ≥Âè∞‰∏äÔºå‰∏î Python È†êËôïÁêÜÂ∑•ÂÖ∑ÁöÑÂèØÁî®ÊÄß‰∏çÂêå„ÄÇÊ≠§Â§ñÔºåË≥áÊñô‰æÜÊ∫êÂíåË≥áÊñôÂàáÁâáÁöÑÁ©∫ÈñìÂ∞çÈΩäÂèØËÉΩÊúÉÂ∞çÊñ∞Êâã‰ΩøÁî®ËÄÖÈÄ†ÊàêÈáçÂ§ßÁöÑÊäÄË°ìÈöúÁ§ô„ÄÇÈõñÁÑ∂Â≠òÂú®‰∏Ä‰∫õÈ†êËôïÁêÜÈÅéÁöÑ EO Ë≥áÊñôÈõÜÔºå‰ΩÜÂÖ∂ÂÖßÂÆπÈÄöÂ∏∏ÂÉÖÈôêÊñºÂÖâÂ≠∏ÊàñËøëÂÖâÂ≠∏Ê≥¢Èï∑Ë≥áÊñôÔºåÈÄôÂú®Â§úÈñìÊàñÊÉ°Âä£ÁöÑÂ§©Ê∞£Ê¢ù‰ª∂‰∏ãÊòØÁÑ°ÊïàÁöÑ„ÄÇÂêàÊàêÂ≠îÂæëÈõ∑ÈÅî (SAR) ÊòØ‰∏ÄÁ®ÆÂü∫ÊñºÂæÆÊ≥¢Èï∑ËºªÂ∞ÑÁöÑ‰∏ªÂãïÊÑüÊ∏¨ÊäÄË°ìÔºåÊèê‰æõ‰∫Ü‰∏ÄÂÄãÂèØË°åÁöÑÊõø‰ª£ÊñπÊ°à„ÄÇÁÑ∂ËÄåÔºåÁî±ÊñºÁº∫‰πè ML Â∞±Á∑íÁöÑË≥áÊñôÂíåÁÆ°Á∑öÔºåÊ©üÂô®Â≠∏ÁøíÂú® SAR ‰∏≠ÁöÑÊáâÁî®ÂèóÂà∞ÈôêÂà∂ÔºåÁâπÂà•ÊòØÂ∞çÊñº SAR Ë≥áÊñôÁöÑÂÖ®ÈÉ®Â§öÊ®£ÊÄßÔºåÂåÖÊã¨Ê•µÂåñÊ∏¨Èáè„ÄÅÁõ∏Âπ≤ÊÄßÂíåÂπ≤Ê∂âÊ∏¨Èáè„ÄÇÊàëÂÄëÂºïÂÖ•‰∫Ü M3LEOÔºåÈÄôÊòØ‰∏ÄÂÄãÂ§öÊ®°ÊÖã„ÄÅÂ§öÊ®ôÁ±§ EO Ë≥áÊñôÈõÜÔºåÂÖ∂‰∏≠ÂåÖÊã¨Âæû Sentinel-1 Ë°çÁîüÁöÑÊ•µÂåñÊ∏¨Èáè„ÄÅÂπ≤Ê∂âÊ∏¨ÈáèÂíåÁõ∏Âπ≤ÊÄß SAR Ë≥áÊñôÔºå‰ª•Âèä Sentinel-2 RGB ÂΩ±ÂÉèÂíå‰∏ÄÂ•óÁî®ÊñºÊ®°ÂûãË©ï‰º∞ÁöÑÊ®ôÁ±§‰ªªÂãô„ÄÇM3LEO Ë∑®Ë∂ä 17.5TBÔºå‰∏¶ÂåÖÂê´ÂÖ≠ÂÄãÂú∞ÁêÜÂçÄÂüü‰∏≠Á¥Ñ 1000 Ëê¨ÂÄãË≥áÊñôÊô∂Áâá„ÄÇË©≤Ë≥áÊñôÈõÜÁî±‰∏ÄÂÄãÈùàÊ¥ªÁöÑ PyTorch Lightning Ê°ÜÊû∂Ë£úÂÖÖÔºå‰∏¶‰ΩøÁî® Hydra ÈÄ≤Ë°åÈÖçÁΩÆÁÆ°ÁêÜ„ÄÇÊàëÂÄëÊèê‰æõÂ∑•ÂÖ∑‰æÜËôïÁêÜ‰ªª‰ΩïÂèØÂú®ÁÜ±ÈñÄÂπ≥Âè∞Ôºà‰æãÂ¶Ç Google Earth EngineÔºâ‰∏äÁç≤ÂæóÁöÑË≥áÊñôÈõÜÔºå‰ª•ËàáÊàëÂÄëÁöÑÊ°ÜÊû∂Êï¥Âêà„ÄÇÂàùÊ≠•ÂØ¶È©óÈ©óË≠â‰∫ÜÊàëÂÄëÁöÑË≥áÊñôÂíåÊ°ÜÊû∂ÁöÑÊïàÁî®ÔºåË°®Êòé SAR ÂΩ±ÂÉèÂåÖÂê´‰∫ÜÂæû RGB Ë≥áÊñô‰∏≠ÊèêÂèñÁöÑÈ°çÂ§ñË≥áË®ä„ÄÇË≥áÊñô‰ΩçÊñº huggingface.co/M3LEOÔºåÁ®ãÂºèÁ¢º‰ΩçÊñº github.com/spaceml-org/M3LEO„ÄÇ</paragraph>

##### **The CLRS-Text Algorithmic Reasoning Language Benchmark**
2406.04229v1 by Larisa Markeeva, Sean McLeish, Borja Ibarz, Wilfried Bounsi, Olga Kozlova, Alex Vitvitskyi, Charles Blundell, Tom Goldstein, Avi Schwarzschild, Petar Veliƒçkoviƒá

Eliciting reasoning capabilities from language models (LMs) is a critical
direction on the path towards building intelligent systems. Most recent studies
dedicated to reasoning focus on out-of-distribution performance on
procedurally-generated synthetic benchmarks, bespoke-built to evaluate specific
skills only. This trend makes results hard to transfer across publications,
slowing down progress. Three years ago, a similar issue was identified and
rectified in the field of neural algorithmic reasoning, with the advent of the
CLRS benchmark. CLRS is a dataset generator comprising graph execution traces
of classical algorithms from the Introduction to Algorithms textbook. Inspired
by this, we propose CLRS-Text -- a textual version of these algorithmic traces.
Out of the box, CLRS-Text is capable of procedurally generating trace data for
thirty diverse, challenging algorithmic tasks across any desirable input
distribution, while offering a standard pipeline in which any additional
algorithmic tasks may be created in the benchmark. We fine-tune and evaluate
various LMs as generalist executors on this benchmark, validating prior work
and revealing a novel, interesting challenge for the LM reasoning community.
Our code is available at
https://github.com/google-deepmind/clrs/tree/master/clrs/_src/clrs_text.

ÊëòË¶ÅÔºöÂºïÂá∫ËØ≠Ë®ÄÊ®°Âûã (LM) ÁöÑÊé®ÁêÜËÉΩÂäõÊòØÂª∫ÊûÑÊô∫ËÉΩÁ≥ªÁªüË∑ØÂæÑ‰∏äÁöÑÂÖ≥ÈîÆÊñπÂêë„ÄÇÂ§ßÂ§öÊï∞ÊúÄËøë‰∏ìÊ≥®‰∫éÊé®ÁêÜÁöÑÁ†îÁ©∂ÈÉΩÂÖ≥Ê≥®Á®ãÂ∫èÁîüÊàêÂêàÊàêÂü∫ÂáÜÁöÑÂàÜÂ∏ÉÂ§ñÊÄßËÉΩÔºå‰ªÖ‰∏∫ËØÑ‰º∞ÁâπÂÆöÊäÄËÉΩËÄåÂÆöÂà∂ÊûÑÂª∫„ÄÇËøôÁßçË∂ãÂäø‰ΩøÂæóÁªìÊûúÈöæ‰ª•Âú®Âá∫ÁâàÁâ©‰πãÈó¥ËΩ¨ÁßªÔºå‰ªéËÄåÂáèÁºì‰∫ÜËøõÂ∫¶„ÄÇ‰∏âÂπ¥ÂâçÔºåÂú®Á•ûÁªèÁÆóÊ≥ïÊé®ÁêÜÈ¢ÜÂüüÂèëÁé∞‰∫ÜÁ±ª‰ººÁöÑÈóÆÈ¢òÂπ∂Âä†‰ª•Á∫†Ê≠£ÔºåÈöèÁùÄ CLRS Âü∫ÂáÜÁöÑÂá∫Áé∞„ÄÇCLRS ÊòØ‰∏Ä‰∏™Êï∞ÊçÆÈõÜÁîüÊàêÂô®ÔºåÂåÖÂê´Êù•Ëá™ÁÆóÊ≥ïÂØºËÆ∫ÊïôÁßë‰π¶ÁöÑÁªèÂÖ∏ÁÆóÊ≥ïÁöÑÂõæÂΩ¢ÊâßË°åËΩ®Ëøπ„ÄÇÂèóÊ≠§ÂêØÂèëÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü CLRS-Text‚Äî‚ÄîËøô‰∫õÁÆóÊ≥ïËΩ®ËøπÁöÑÊñáÊú¨ÁâàÊú¨„ÄÇÂºÄÁÆ±Âç≥Áî®ÔºåCLRS-Text ËÉΩÂ§ü‰∏∫‰∏âÂçÅ‰∏™‰∏çÂêåÁöÑ„ÄÅÂÖ∑ÊúâÊåëÊàòÊÄßÁöÑÁÆóÊ≥ï‰ªªÂä°Á®ãÂ∫èÁîüÊàêËΩ®ËøπÊï∞ÊçÆÔºåË∑®Ë∂ä‰ªª‰ΩïÁêÜÊÉ≥ÁöÑËæìÂÖ•ÂàÜÂ∏ÉÔºåÂêåÊó∂Êèê‰æõ‰∏Ä‰∏™Ê†áÂáÜÁÆ°ÈÅìÔºåÂèØ‰ª•Âú®Âü∫ÂáÜ‰∏≠ÂàõÂª∫‰ªª‰ΩïÂÖ∂‰ªñÁÆóÊ≥ï‰ªªÂä°„ÄÇÊàë‰ª¨ÂØπÂêÑÁßç LM ËøõË°åÂæÆË∞ÉÂíåËØÑ‰º∞Ôºå‰Ωú‰∏∫Ê≠§Âü∫ÂáÜ‰∏äÁöÑÈÄöÊâçÊâßË°åÂô®ÔºåÈ™åËØÅ‰∫ÜÂÖàÂâçÁöÑÂ∑•‰ΩúÂπ∂Êè≠Á§∫‰∫Ü LM Êé®ÁêÜÁ§æÂå∫‰∏Ä‰∏™Êñ∞È¢ñ„ÄÅÊúâË∂£ÁöÑÊåëÊàò„ÄÇÊàë‰ª¨ÁöÑ‰ª£Á†ÅÂèØÂú® https://github.com/google-deepmind/clrs/tree/master/clrs/_src/clrs_text Ëé∑Âæó„ÄÇ

##### **BEADs: Bias Evaluation Across Domains**
2406.04220v2 by Shaina Raza, Mizanur Rahman, Michael R. Zhang

Recent improvements in large language models (LLMs) have significantly
enhanced natural language processing (NLP) applications. However, these models
can also inherit and perpetuate biases from their training data. Addressing
this issue is crucial, yet many existing datasets do not offer evaluation
across diverse NLP tasks. To tackle this, we introduce the Bias Evaluations
Across Domains (BEADs) dataset, designed to support a wide range of NLP tasks,
including text classification, bias entity recognition, bias quantification,
and benign language generation. BEADs uses AI-driven annotation combined with
experts' verification to provide reliable labels. This method overcomes the
limitations of existing datasets that typically depend on crowd-sourcing,
expert-only annotations with limited bias evaluations, or unverified AI
labeling. Our empirical analysis shows that BEADs is effective in detecting and
reducing biases across different language models, with smaller models
fine-tuned on BEADs often outperforming LLMs in bias classification tasks.
However, these models may still exhibit biases towards certain demographics.
Fine-tuning LLMs with our benign language data also reduces biases while
preserving the models' knowledge. Our findings highlight the importance of
comprehensive bias evaluation and the potential of targeted fine-tuning for
reducing the bias of LLMs. We are making BEADs publicly available at
https://huggingface.co/datasets/shainar/BEAD
  Warning: This paper contains examples that may be considered offensive.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâÊúÄËøëÁöÑÊîπÈÄ≤È°ØËëóÂ¢ûÂº∑‰∫ÜËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜÔºàNLPÔºâÊáâÁî®Á®ãÂºè„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÊ®°Âûã‰πüÂèØËÉΩÁπºÊâøÂíåÂª∂Á∫åÂÖ∂Ë®ìÁ∑¥Ë≥áÊñô‰∏≠ÁöÑÂÅèË¶ã„ÄÇËß£Ê±∫ÈÄôÂÄãÂïèÈ°åËá≥ÈóúÈáçË¶ÅÔºå‰ΩÜË®±Â§öÁèæÊúâË≥áÊñôÈõÜ‰∏¶Êú™ÈáùÂ∞çÂêÑÁ®Æ NLP ‰ªªÂãôÊèê‰æõË©ï‰º∞„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜË∑®È†òÂüüÂÅèË¶ãË©ï‰º∞ÔºàBEADÔºâË≥áÊñôÈõÜÔºåÊó®Âú®ÊîØÊè¥ÂêÑÁ®Æ NLP ‰ªªÂãôÔºåÂåÖÊã¨ÊñáÂ≠óÂàÜÈ°û„ÄÅÂÅèË¶ãÂØ¶È´îËæ®Ë≠ò„ÄÅÂÅèË¶ãÈáèÂåñÂíåËâØÊÄßË™ûË®ÄÁî¢Áîü„ÄÇBEAD ‰ΩøÁî® AI È©ÖÂãïÁöÑË®ªËß£ÔºåÁµêÂêàÂ∞àÂÆ∂ÁöÑÈ©óË≠âÔºåÊèê‰æõÂèØÈù†ÁöÑÊ®ôÁ±§„ÄÇÊ≠§ÊñπÊ≥ïÂÖãÊúç‰∫ÜÁèæÊúâË≥áÊñôÈõÜÁöÑÈôêÂà∂ÔºåÈÄô‰∫õË≥áÊñôÈõÜÈÄöÂ∏∏‰æùË≥¥Áæ§ÁúæÂ§ñÂåÖ„ÄÅÂÉÖÂ∞àÂÆ∂Ë®ªËß£ÔºàÂÅèË¶ãË©ï‰º∞ÊúâÈôêÔºâÊàñÊú™È©óË≠âÁöÑ AI Ê®ôÁ±§„ÄÇÊàëÂÄëÁöÑÂØ¶Ë≠âÂàÜÊûêÈ°ØÁ§∫ÔºåBEAD Âú®ÂÅµÊ∏¨ÂíåÊ∏õÂ∞ë‰∏çÂêåË™ûË®ÄÊ®°ÂûãÁöÑÂÅèË¶ãÊñπÈù¢ÊúâÊïàÔºåÈáùÂ∞ç BEAD ÂæÆË™øÁöÑÂ∞èÂûãÊ®°ÂûãÂú®ÂÅèË¶ãÂàÜÈ°û‰ªªÂãô‰∏≠ÈÄöÂ∏∏ÂÑ™Êñº LLM„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÊ®°ÂûãÂèØËÉΩ‰ªçÂ∞çÊüê‰∫õ‰∫∫Âè£Áµ±Ë®àË≥áÊñôË°®ÁèæÂá∫ÂÅèË¶ã„ÄÇ‰ΩøÁî®ÊàëÂÄëÁöÑËâØÊÄßË™ûË®ÄË≥áÊñôÂæÆË™ø LLM ‰πüËÉΩÊ∏õÂ∞ëÂÅèË¶ãÔºåÂêåÊôÇ‰øùÁïôÊ®°ÂûãÁöÑÁü•Ë≠ò„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÁ™ÅÈ°Ø‰∫ÜÂÖ®Èù¢ÂÅèË¶ãË©ï‰º∞ÁöÑÈáçË¶ÅÊÄßÔºå‰ª•ÂèäÈáùÂ∞çÊÄßÂæÆË™øÂú®Ê∏õÂ∞ë LLM ÂÅèË¶ãÊñπÈù¢ÁöÑÊΩõÂäõ„ÄÇÊàëÂÄëÂú® https://huggingface.co/datasets/shainar/BEAD ÂÖ¨ÈñãÊèê‰æõ BEAD„ÄÇË≠¶ÂëäÔºöÊ≠§Ë´ñÊñáÂåÖÂê´ÂèØËÉΩË¢´Ë¶ñÁÇ∫ÂÜíÁäØÊÄßÁöÑÁØÑ‰æã„ÄÇ

##### **Rethinking LLM and Linguistic Steganalysis: An Efficient Detection of Strongly Concealed Stego**
2406.04218v1 by Yifan Tang, Yihao Wang, Ru Zhang, Jianyi Liu

To detect stego (steganographic text) in complex scenarios, linguistic
steganalysis (LS) with various motivations has been proposed and achieved
excellent performance. However, with the development of generative
steganography, some stegos have strong concealment, especially after the
emergence of LLMs-based steganography, the existing LS has low detection or
even cannot detect them. We designed a novel LS with two modes called LSGC. In
the generation mode, we created an LS-task "description" and used the
generation ability of LLM to explain whether texts to be detected are stegos.
On this basis, we rethought the principle of LS and LLMs, and proposed the
classification mode. In this mode, LSGC deleted the LS-task "description" and
changed the "causalLM" LLMs to the "sequenceClassification" architecture. The
LS features can be extracted by only one pass of the model, and a linear layer
with initialization weights is added to obtain the classification probability.
Experiments on strongly concealed stegos show that LSGC significantly improves
detection and reaches SOTA performance. Additionally, LSGC in classification
mode greatly reduces training time while maintaining high performance.

ÊëòË¶ÅÔºöÁÇ∫‰∫ÜÂú®Ë§áÈõúÂ†¥ÊôØ‰∏≠ÂÅµÊ∏¨Èö±ÂØ´ÔºàÈö±ÂØ´ÊñáÊú¨ÔºâÔºåÂ∑≤Á∂ìÊèêÂá∫ÂÖ∑ÊúâÂêÑÁ®ÆÂãïÊ©üÁöÑË™ûË®ÄÂ≠∏Èö±ÂØ´ÂàÜÊûêÔºàLSÔºâÔºå‰∏¶Áç≤Âæó‰∫ÜÊ•µ‰Ω≥ÁöÑÊïàËÉΩ„ÄÇÁÑ∂ËÄåÔºåÈö®ËëóÁîüÊàêÂºèÈö±ÂØ´Ë°ìÁöÑÁôºÂ±ïÔºåÊúâ‰∫õÈö±ÂØ´ÂÖ∑ÊúâÂº∑Â§ßÁöÑÈö±ËóèÊÄßÔºåÁâπÂà•ÊòØÂú®Âü∫Êñº LLM ÁöÑÈö±ÂØ´Ë°ìÂá∫ÁèæÂæåÔºåÁèæÊúâÁöÑ LS ÂÅµÊ∏¨ËÉΩÂäõ‰ΩéÔºåÁîöËá≥ÁÑ°Ê≥ïÂÅµÊ∏¨Âà∞ÂÆÉÂÄë„ÄÇÊàëÂÄëË®≠Ë®à‰∫Ü‰∏ÄÂÄãÂÖ∑ÊúâÂÖ©Á®ÆÊ®°ÂºèÁöÑÊñ∞Á©é LSÔºåÁ®±ÁÇ∫ LSGC„ÄÇÂú®ÁîüÊàêÊ®°Âºè‰∏≠ÔºåÊàëÂÄëÂâµÂª∫‰∫Ü‰∏ÄÂÄã LS ‰ªªÂãô„ÄåÊèèËø∞„ÄçÔºå‰∏¶‰ΩøÁî® LLM ÁöÑÁîüÊàêËÉΩÂäõ‰æÜËß£ÈáãÂæÖÂÅµÊ∏¨ÁöÑÊñáÊú¨ÊòØÂê¶ÁÇ∫Èö±ÂØ´„ÄÇÂú®Ê≠§Âü∫Á§é‰∏äÔºåÊàëÂÄëÈáçÊñ∞ÊÄùËÄÉ‰∫Ü LS Âíå LLM ÁöÑÂéüÁêÜÔºå‰∏¶ÊèêÂá∫‰∫ÜÂàÜÈ°ûÊ®°Âºè„ÄÇÂú®Ê≠§Ê®°Âºè‰∏≠ÔºåLSGC Âà™Èô§‰∫Ü LS ‰ªªÂãô„ÄåÊèèËø∞„ÄçÔºå‰∏¶Â∞á„ÄåcausalLM„ÄçLLM ÊîπÁÇ∫„ÄåsequenceClassification„ÄçÊû∂Êßã„ÄÇÂè™ÈúÄÊ®°ÂûãÂü∑Ë°å‰∏ÄÊ¨°ÔºåÂç≥ÂèØÊèêÂèñ LS ÁâπÂæµÔºå‰∏¶Êñ∞Â¢û‰∏ÄÂÄãÂÖ∑ÊúâÂàùÂßãÂåñÊ¨äÈáçÁöÑÁ∑öÊÄßÂ±§‰æÜÂèñÂæóÂàÜÈ°ûÊ©üÁéá„ÄÇÈáùÂ∞çÈö±ËóèÊÄßÂº∑ÁöÑÈö±ÂØ´ÁöÑÂØ¶È©óÈ°ØÁ§∫ÔºåLSGC Â§ßÂπÖÊèêÂçá‰∫ÜÂÅµÊ∏¨ËÉΩÂäõÔºå‰∏¶ÈÅîÂà∞‰∫Ü SOTA ÊïàËÉΩ„ÄÇÊ≠§Â§ñÔºåÂàÜÈ°ûÊ®°Âºè‰∏≠ÁöÑ LSGC Â§ßÂπÖÁ∏ÆÁü≠‰∫ÜË®ìÁ∑¥ÊôÇÈñìÔºåÂêåÊôÇÁ∂≠ÊåÅ‰∫ÜÈ´òÊïàËÉΩ„ÄÇ

##### **What Do Language Models Learn in Context? The Structured Task Hypothesis**
2406.04216v1 by Jiaoda Li, Yifan Hou, Mrinmaya Sachan, Ryan Cotterell

Large language models (LLMs) exhibit an intriguing ability to learn a novel
task from in-context examples presented in a demonstration, termed in-context
learning (ICL). Understandably, a swath of research has been dedicated to
uncovering the theories underpinning ICL. One popular hypothesis explains ICL
by task selection. LLMs identify the task based on the demonstration and
generalize it to the prompt. Another popular hypothesis is that ICL is a form
of meta-learning, i.e., the models learn a learning algorithm at pre-training
time and apply it to the demonstration. Finally, a third hypothesis argues that
LLMs use the demonstration to select a composition of tasks learned during
pre-training to perform ICL. In this paper, we empirically explore these three
hypotheses that explain LLMs' ability to learn in context with a suite of
experiments derived from common text classification tasks. We invalidate the
first two hypotheses with counterexamples and provide evidence in support of
the last hypothesis. Our results suggest an LLM could learn a novel task in
context via composing tasks learned during pre-training.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â±ïÁèæÂá∫ÂæûÁ§∫ÁØÑ‰∏≠‰ª•ËÑàÁµ°‰∏≠ÁöÑÁØÑ‰æãÂ≠∏ÁøíÊñ∞‰ªªÂãôÁöÑÊúâË∂£ËÉΩÂäõÔºåÁ®±ÁÇ∫ËÑàÁµ°‰∏≠Â≠∏Áøí (ICL)„ÄÇÂèØ‰ª•ÁêÜËß£ÁöÑÊòØÔºåÂ§ßÈáèÁöÑÁ†îÁ©∂Ëá¥ÂäõÊñºÊè≠Á§∫ÊîØÊíê ICL ÁöÑÁêÜË´ñ„ÄÇ‰∏ÄÂÄãÊµÅË°åÁöÑÂÅáË®≠ÈÄöÈÅé‰ªªÂãôÈÅ∏Êìá‰æÜËß£Èáã ICL„ÄÇLLM Ê†πÊìöÁ§∫ÁØÑË≠òÂà•‰ªªÂãô‰∏¶Â∞áÂÖ∂Ê¶ÇÊã¨ÁÇ∫ÊèêÁ§∫„ÄÇÂè¶‰∏ÄÂÄãÊµÅË°åÁöÑÂÅáË®≠ÊòØ ICL ÊòØÂÖÉÂ≠∏ÁøíÁöÑ‰∏ÄÁ®ÆÂΩ¢ÂºèÔºåÂç≥Ê®°ÂûãÂú®È†êË®ìÁ∑¥ÊôÇÂ≠∏ÁøíÂ≠∏ÁøíÊºîÁÆóÊ≥ï‰∏¶Â∞áÂÖ∂ÊáâÁî®ÊñºÁ§∫ÁØÑ„ÄÇÊúÄÂæåÔºåÁ¨¨‰∏âÂÄãÂÅáË®≠Ë™çÁÇ∫ LLM ‰ΩøÁî®Á§∫ÁØÑ‰æÜÈÅ∏ÊìáÂú®È†êË®ìÁ∑¥ÊúüÈñìÂ≠∏ÁøíÁöÑ‰ªªÂãôÁµÑÂêà‰ª•Âü∑Ë°å ICL„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊ†πÊìöÂ∏∏Ë¶ãÊñáÂ≠óÂàÜÈ°û‰ªªÂãôË°çÁîüÁöÑ‰∏ÄÁ≥ªÂàóÂØ¶È©óÔºåÂØ¶Ë≠âÊé¢Ë®éÈÄô‰∏âÂÄãËß£Èáã LLM Âú®ËÑàÁµ°‰∏≠Â≠∏ÁøíËÉΩÂäõÁöÑÂÅáË®≠„ÄÇÊàëÂÄë‰ΩøÁî®Âèç‰æãÊé®ÁøªÂâçÂÖ©ÂÄãÂÅáË®≠Ôºå‰∏¶Êèê‰æõË≠âÊìöÊîØÊåÅÊúÄÂæå‰∏ÄÂÄãÂÅáË®≠„ÄÇÊàëÂÄëÁöÑÁµêÊûúË°®ÊòéÔºåLLM ÂèØ‰ª•ÈÄèÈÅéÁµÑÂêàÈ†êË®ìÁ∑¥ÊúüÈñìÂ≠∏ÁøíÁöÑ‰ªªÂãôÔºåÂú®ËÑàÁµ°‰∏≠Â≠∏ÁøíÊñ∞ÁöÑ‰ªªÂãô„ÄÇ

##### **mCSQA: Multilingual Commonsense Reasoning Dataset with Unified Creation Strategy by Language Models and Humans**
2406.04215v1 by Yusuke Sakai, Hidetaka Kamigaito, Taro Watanabe

It is very challenging to curate a dataset for language-specific knowledge
and common sense in order to evaluate natural language understanding
capabilities of language models. Due to the limitation in the availability of
annotators, most current multilingual datasets are created through translation,
which cannot evaluate such language-specific aspects. Therefore, we propose
Multilingual CommonsenseQA (mCSQA) based on the construction process of CSQA
but leveraging language models for a more efficient construction, e.g., by
asking LM to generate questions/answers, refine answers and verify QAs followed
by reduced human efforts for verification. Constructed dataset is a benchmark
for cross-lingual language-transfer capabilities of multilingual LMs, and
experimental results showed high language-transfer capabilities for questions
that LMs could easily solve, but lower transfer capabilities for questions
requiring deep knowledge or commonsense. This highlights the necessity of
language-specific datasets for evaluation and training. Finally, our method
demonstrated that multilingual LMs could create QA including language-specific
knowledge, significantly reducing the dataset creation cost compared to manual
creation. The datasets are available at
https://huggingface.co/datasets/yusuke1997/mCSQA.

ÊëòË¶ÅÔºöÂ∞çÊñºË™ûË®ÄÁâπÂÆöÁöÑÁü•Ë≠òÂíåÂ∏∏Ë≠òÔºåË¶ÅÁ≠ñÂ±ï‰∏ÄÂÄãË≥áÊñôÈõÜ‰ª•‰æøË©ï‰º∞Ë™ûË®ÄÊ®°ÂûãÁöÑËá™ÁÑ∂Ë™ûË®ÄÁêÜËß£ËÉΩÂäõÔºåÊòØ‰∏Ä‰ª∂ÈùûÂ∏∏ÂÖ∑ÊúâÊåëÊà∞ÊÄßÁöÑ‰∫ãÊÉÖ„ÄÇÁî±ÊñºÊ®ôË®ªÂì°ÁöÑÂèØÁî®ÊÄßÊúâÈôêÔºåÁõÆÂâçÂ§ßÂ§öÊï∏Â§öË™ûË®ÄË≥áÊñôÈõÜÈÉΩÊòØÈÄèÈÅéÁøªË≠ØÂª∫Á´ãÁöÑÔºåËÄåÁøªË≠ØÁÑ°Ê≥ïË©ï‰º∞Ê≠§È°ûË™ûË®ÄÁâπÂÆöÁöÑÈù¢Âêë„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëÊèêÂá∫‰∫ÜÂ§öË™ûË®ÄÂ∏∏Ë≠òÂïèÁ≠î (mCSQA)ÔºåÂÖ∂Âª∫Á´ãÈÅéÁ®ãÊòØÂü∫Êñº CSQAÔºå‰ΩÜÂà©Áî®Ë™ûË®ÄÊ®°Âûã‰æÜÈÄ≤Ë°åÊõ¥ÊúâÊïàÁéáÁöÑÂª∫Á´ãÔºå‰æãÂ¶ÇËÆìË™ûË®ÄÊ®°ÂûãÁî¢ÁîüÂïèÈ°å/Á≠îÊ°à„ÄÅÁ≤æÁÖâÁ≠îÊ°àÔºå‰∏¶È©óË≠â QAÔºåÁÑ∂ÂæåÂÜçÊ∏õÂ∞ë‰∫∫Â∑•È©óË≠âÁöÑÂ∑•‰Ωú„ÄÇÂª∫Á´ãÁöÑË≥áÊñôÈõÜÊòØÂ§öË™ûË®ÄË™ûË®ÄÊ®°ÂûãË∑®Ë™ûË®ÄË™ûË®ÄËΩâÁßªËÉΩÂäõÁöÑÂü∫Ê∫ñÔºåËÄåÂØ¶È©óÁµêÊûúÈ°ØÁ§∫ÔºåÂ∞çÊñºË™ûË®ÄÊ®°ÂûãÂèØ‰ª•ËºïÊòìËß£Ê±∫ÁöÑÂïèÈ°åÔºåÂÖ∂Ë™ûË®ÄËΩâÁßªËÉΩÂäõÂæàÈ´òÔºå‰ΩÜÂ∞çÊñºÈúÄË¶ÅÊ∑±ÂÖ•Áü•Ë≠òÊàñÂ∏∏Ë≠òÁöÑÂïèÈ°åÔºåÂÖ∂ËΩâÁßªËÉΩÂäõËºÉ‰Ωé„ÄÇÈÄôÁ™ÅÈ°Ø‰∫ÜË™ûË®ÄÁâπÂÆöË≥áÊñôÈõÜÂ∞çÊñºË©ï‰º∞ÂíåË®ìÁ∑¥ÁöÑÂøÖË¶ÅÊÄß„ÄÇÊúÄÂæåÔºåÊàëÂÄëÁöÑÊñπÊ≥ïË≠âÊòé‰∫ÜÂ§öË™ûË®ÄË™ûË®ÄÊ®°ÂûãÂèØ‰ª•Âª∫Á´ãÂåÖÂê´Ë™ûË®ÄÁâπÂÆöÁü•Ë≠òÁöÑ QAÔºåËàá‰∫∫Â∑•Âª∫Á´ãÁõ∏ÊØîÔºåÂ§ßÂπÖÈôç‰Ωé‰∫ÜË≥áÊñôÈõÜÂª∫Á´ãÊàêÊú¨„ÄÇË≥áÊñôÈõÜÂèØÂú® https://huggingface.co/datasets/yusuke1997/mCSQA ÂèñÂæó„ÄÇ

##### **ValueBench: Towards Comprehensively Evaluating Value Orientations and Understanding of Large Language Models**
2406.04214v1 by Yuanyi Ren, Haoran Ye, Hanjun Fang, Xin Zhang, Guojie Song

Large Language Models (LLMs) are transforming diverse fields and gaining
increasing influence as human proxies. This development underscores the urgent
need for evaluating value orientations and understanding of LLMs to ensure
their responsible integration into public-facing applications. This work
introduces ValueBench, the first comprehensive psychometric benchmark for
evaluating value orientations and value understanding in LLMs. ValueBench
collects data from 44 established psychometric inventories, encompassing 453
multifaceted value dimensions. We propose an evaluation pipeline grounded in
realistic human-AI interactions to probe value orientations, along with novel
tasks for evaluating value understanding in an open-ended value space. With
extensive experiments conducted on six representative LLMs, we unveil their
shared and distinctive value orientations and exhibit their ability to
approximate expert conclusions in value-related extraction and generation
tasks. ValueBench is openly accessible at
https://github.com/Value4AI/ValueBench.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Ê≠£Âú®ËΩâËÆäÂêÑÁ®ÆÈ†òÂüüÔºå‰∏¶‰ΩúÁÇ∫‰∫∫È°û‰ª£ÁêÜ‰∫∫Áç≤ÂæóË∂ä‰æÜË∂äÂ§ßÁöÑÂΩ±ÈüøÂäõ„ÄÇÈÄôÁ®ÆÁôºÂ±ïÂº∑Ë™ø‰∫ÜË©ï‰º∞ÂÉπÂÄºÂèñÂêëÂíåÁêÜËß£ LLM ÁöÑËø´ÂàáÈúÄË¶ÅÔºå‰ª•Á¢∫‰øùÂÆÉÂÄëË≤†Ë≤¨‰ªªÂú∞Êï¥ÂêàÂà∞Èù¢ÂêëÂÖ¨ÁúæÁöÑÊáâÁî®Á®ãÂºè‰∏≠„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÂºïÂÖ•‰∫Ü ValueBenchÔºåÈÄôÊòØÁ¨¨‰∏ÄÂÄãÂÖ®Èù¢ÁöÑÂøÉÁêÜÊ∏¨ÈáèÂü∫Ê∫ñÔºåÁî®ÊñºË©ï‰º∞ LLM ‰∏≠ÁöÑÂÉπÂÄºÂèñÂêëÂíåÂÉπÂÄºÁêÜËß£„ÄÇValueBench Âæû 44 ‰ªΩÊó¢ÂÆöÁöÑÂøÉÁêÜÊ∏¨ÈáèÊ∏ÖÂñÆ‰∏≠Êî∂ÈõÜË≥áÊñôÔºåÊ∂µËìã 453 ÂÄãÂ§öÈù¢ÂêëÁöÑÂÉπÂÄºÁ∂≠Â∫¶„ÄÇÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãË©ï‰º∞ÁÆ°ÈÅìÔºåÂÆÉ‰ª•ÁèæÂØ¶ÁöÑ‰∫∫Â∑•Êô∫ÊÖß‰∫íÂãïÁÇ∫Âü∫Á§éÔºåÁî®ÊñºÊé¢Ë®éÂÉπÂÄºÂèñÂêëÔºå‰ª•ÂèäË©ï‰º∞ÈñãÊîæÂºèÂÉπÂÄºÁ©∫Èñì‰∏≠ÂÉπÂÄºÁêÜËß£ÁöÑÊñ∞‰ªªÂãô„ÄÇÈÄèÈÅéÂ∞çÂÖ≠ÂÄãÂÖ∑‰ª£Ë°®ÊÄßÁöÑ LLM ÈÄ≤Ë°åÂª£Ê≥õÁöÑÂØ¶È©óÔºåÊàëÂÄëÊè≠Á§∫‰∫ÜÂÆÉÂÄëÁöÑÂÖ±ÂêåÂíåÁç®ÁâπÂÉπÂÄºÂèñÂêëÔºå‰∏¶Â±ïÁ§∫‰∫ÜÂÆÉÂÄëÂú®ËàáÂÉπÂÄºÁõ∏ÈóúÁöÑËêÉÂèñÂíåÁîüÊàê‰ªªÂãô‰∏≠ÈÄºËøëÂ∞àÂÆ∂ÁµêË´ñÁöÑËÉΩÂäõ„ÄÇValueBench ÂèØÂú® https://github.com/Value4AI/ValueBench ÂÖ¨ÈñãÂèñÂæó„ÄÇ

##### **Aligning Agents like Large Language Models**
2406.04208v1 by Adam Jelley, Yuhan Cao, Dave Bignell, Sam Devlin, Tabish Rashid

Training agents to behave as desired in complex 3D environments from
high-dimensional sensory information is challenging. Imitation learning from
diverse human behavior provides a scalable approach for training an agent with
a sensible behavioral prior, but such an agent may not perform the specific
behaviors of interest when deployed. To address this issue, we draw an analogy
between the undesirable behaviors of imitation learning agents and the
unhelpful responses of unaligned large language models (LLMs). We then
investigate how the procedure for aligning LLMs can be applied to aligning
agents in a 3D environment from pixels. For our analysis, we utilize an
academically illustrative part of a modern console game in which the human
behavior distribution is multi-modal, but we want our agent to imitate a single
mode of this behavior. We demonstrate that we can align our agent to
consistently perform the desired mode, while providing insights and advice for
successfully applying this approach to training agents. Project webpage at
https://adamjelley.github.io/aligning-agents-like-llms .

ÊëòË¶ÅÔºöË®ìÁ∑¥‰ª£ÁêÜ‰∫∫Ê†πÊìöÈ´òÁ∂≠Â∫¶ÊÑüÂÆòË≥áË®äÂú®Ë§áÈõúÁöÑ 3D Áí∞Â¢É‰∏≠Ë°®ÁèæÂá∫Â¶ÇÈ†êÊúüËà¨ÁöÑË°åÁÇ∫ÊòØ‰∏ÄÈ†ÖÊåëÊà∞„ÄÇÂæûÂ§öÊ®£ÂåñÁöÑ‰∫∫È°ûË°åÁÇ∫‰∏≠ÈÄ≤Ë°åÊ®°‰ªøÂ≠∏ÁøíÊèê‰æõ‰∫Ü‰∏ÄÂÄãÂèØÊì¥ÂÖÖÁöÑÈÄîÂæëÔºåÁî®ÊñºË®ìÁ∑¥ÂÖ∑ÂÇôÊòéÊô∫Ë°åÁÇ∫ÂÖàÈ©óÁöÑ‰ª£ÁêÜ‰∫∫Ôºå‰ΩÜÈÄôÊ®£ÁöÑ‰ª£ÁêÜ‰∫∫Âú®ÈÉ®ÁΩ≤ÊôÇÂèØËÉΩÁÑ°Ê≥ïÂü∑Ë°åÁâπÂÆöÁöÑÊÑüËààË∂£Ë°åÁÇ∫„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÂ∞áÊ®°‰ªøÂ≠∏Áøí‰ª£ÁêÜ‰∫∫ÁöÑ‰∏çËâØË°åÁÇ∫ËàáÊú™Â∞çÈΩäÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÁÑ°ÁõäÂõûÊáâ‰πãÈñìÁï´‰∏äÈ°ûÊØî„ÄÇÁÑ∂ÂæåÊàëÂÄëÊé¢Ë®éÂ¶Ç‰ΩïÂ∞áÂ∞çÈΩä LLM ÁöÑÁ®ãÂ∫èÊáâÁî®ÊñºÂæûÂÉèÁ¥†‰∏≠Â∞çÈΩä 3D Áí∞Â¢É‰∏≠ÁöÑ‰ª£ÁêÜ‰∫∫„ÄÇÂ∞çÊñºÊàëÂÄëÁöÑÂàÜÊûêÔºåÊàëÂÄëÂà©Áî®Áèæ‰ª£ÈÅäÊà≤Ê©üÈÅäÊà≤‰∏≠‰∏ÄÂÄãÂ≠∏Ë°ì‰∏äÂÖ∑ÊúâË™™ÊòéÊÄßÁöÑÈÉ®ÂàÜÔºåÂÖ∂‰∏≠‰∫∫È°ûË°åÁÇ∫ÂàÜ‰ΩàÊòØÂ§öÊ®°ÊÖãÁöÑÔºå‰ΩÜÊàëÂÄëÂ∏åÊúõÊàëÂÄëÁöÑ‰ª£ÁêÜ‰∫∫Ê®°‰ªøÊ≠§Ë°åÁÇ∫ÁöÑÂñÆ‰∏ÄÊ®°Âºè„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫ÜÊàëÂÄëÂèØ‰ª•Â∞áÊàëÂÄëÁöÑ‰ª£ÁêÜ‰∫∫Â∞çÈΩäÔºå‰ª•ÊåÅÁ∫åÂü∑Ë°åÊâÄÈúÄÁöÑÊ®°ÂºèÔºåÂêåÊôÇÊèê‰æõË¶ãËß£ÂíåÂª∫Ë≠∞Ôºå‰ª•ÊàêÂäüÂ∞áÊ≠§ÊñπÊ≥ïÊáâÁî®ÊñºË®ìÁ∑¥‰ª£ÁêÜ‰∫∫„ÄÇÂ∞àÊ°àÁ∂≤È†ÅÔºöhttps://adamjelley.github.io/aligning-agents-like-llms„ÄÇ

##### **Legal Documents Drafting with Fine-Tuned Pre-Trained Large Language Model**
2406.04202v1 by Chun-Hsien Lin, Pu-Jen Cheng

With the development of large-scale Language Models (LLM), fine-tuning
pre-trained LLM has become a mainstream paradigm for solving downstream tasks
of natural language processing. However, training a language model in the legal
field requires a large number of legal documents so that the language model can
learn legal terminology and the particularity of the format of legal documents.
The typical NLP approaches usually rely on many manually annotated data sets
for training. However, in the legal field application, it is difficult to
obtain a large number of manually annotated data sets, which restricts the
typical method applied to the task of drafting legal documents. The
experimental results of this paper show that not only can we leverage a large
number of annotation-free legal documents without Chinese word segmentation to
fine-tune a large-scale language model, but more importantly, it can fine-tune
a pre-trained LLM on the local computer to achieve the generating legal
document drafts task, and at the same time achieve the protection of
information privacy and to improve information security issues.

ÊëòË¶ÅÔºöÈö®ËëóÂ§ßË¶èÊ®°Ë™ûË®ÄÊ®°Âûã (LLM) ÁöÑÁôºÂ±ïÔºåÂæÆË™øÈ†êÂÖàË®ìÁ∑¥ÁöÑ LLM Â∑≤ÊàêÁÇ∫Ëß£Ê±∫Ëá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ‰∏ãÊ∏∏‰ªªÂãôÁöÑ‰∏ªÊµÅÁØÑ‰æã„ÄÇÁÑ∂ËÄåÔºåÂú®Ê≥ïÂæãÈ†òÂüüË®ìÁ∑¥Ë™ûË®ÄÊ®°ÂûãÈúÄË¶ÅÂ§ßÈáèÁöÑÊ≥ïÂæãÊñá‰ª∂Ôºå‰ª•‰æøË™ûË®ÄÊ®°ÂûãÂèØ‰ª•Â≠∏ÁøíÊ≥ïÂæãË°ìË™ûÂíåÊ≥ïÂæãÊñá‰ª∂Ê†ºÂºèÁöÑÁâπÊÆäÊÄß„ÄÇÂÖ∏ÂûãÁöÑ NLP ÊñπÊ≥ïÈÄöÂ∏∏‰æùË≥¥ÊñºË®±Â§öÊâãÂãïË®ªÈáãÁöÑË≥áÊñôÈõÜÈÄ≤Ë°åË®ìÁ∑¥„ÄÇÁÑ∂ËÄåÔºåÂú®Ê≥ïÂæãÈ†òÂüüÊáâÁî®‰∏≠ÔºåÂæàÈõ£Áç≤ÂæóÂ§ßÈáèÁöÑ„ÄÅÊâãÂãïË®ªÈáãÁöÑË≥áÊñôÈõÜÔºåÈÄôÈôêÂà∂‰∫ÜÂÖ∏ÂûãÊñπÊ≥ïÊáâÁî®ÊñºÊ≥ïÂæãÊñá‰ª∂Ëµ∑Ëçâ‰ªªÂãô„ÄÇÊú¨ÊñáÁöÑÂØ¶È©óÁµêÊûúË°®ÊòéÔºåÊàëÂÄë‰∏çÂÉÖÂèØ‰ª•Âà©Áî®Â§ßÈáèÊ≤íÊúâ‰∏≠ÊñáÂàÜË©ûÁöÑÁÑ°Ë®ªÈáãÊ≥ïÂæãÊñá‰ª∂‰æÜÂæÆË™øÂ§ßË¶èÊ®°Ë™ûË®ÄÊ®°ÂûãÔºåÊõ¥ÈáçË¶ÅÁöÑÊòØÔºåÂèØ‰ª•Âú®Êú¨Âú∞ÈõªËÖ¶‰∏äÂæÆË™øÈ†êÂÖàË®ìÁ∑¥ÁöÑ LLM ‰ª•ÈÅîÊàêÁî¢ÁîüÊ≥ïÂæãÊñá‰ª∂ËçâÁ®ø‰ªªÂãôÔºåÂêåÊôÇÈÅîÊàêË≥áË®äÈö±ÁßÅ‰øùË≠∑ÂíåÊèêÂçáË≥áË®äÂÆâÂÖ®ÂïèÈ°å„ÄÇ

##### **DICE: Detecting In-distribution Contamination in LLM's Fine-tuning Phase for Math Reasoning**
2406.04197v1 by Shangqing Tu, Kejian Zhu, Yushi Bai, Zijun Yao, Lei Hou, Juanzi Li

The advancement of large language models (LLMs) relies on evaluation using
public benchmarks, but data contamination can lead to overestimated
performance. Previous researches focus on detecting contamination by
determining whether the model has seen the exact same data during training. In
this work, we argue that even training on data similar to benchmark data
inflates performance on in-distribution tasks without improving overall
capacity, which we called In-distribution contamination. To effectively detect
in-distribution contamination, we propose DICE, a novel method that leverages
the internal states of LLMs to locate-then-detect the contamination. DICE first
identifies the most sensitive layer to contamination, then trains a classifier
based on the internal states of that layer. Experiments reveal DICE's high
accuracy in detecting in-distribution contamination across various LLMs and
math reasoning datasets. We also show the generalization capability of the
trained DICE detector, which is able to detect contamination across multiple
benchmarks with similar distributions. Additionally, we find that the DICE
detection scores are positively correlated with the performance of ten LLMs
fine-tuned by either us or other organizations on four math reasoning datasets
(with $R^2$ values between 0.6 and 0.75). This indicates that the
in-distribution contamination problem potentially lead to an overestimation of
the true capabilities of many existing models. The code and data are available
at https://github.com/THU-KEG/DICE.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâÁöÑÈÄ≤Â±ï‰æùË≥¥Êñº‰ΩøÁî®ÂÖ¨ÂÖ±Âü∫Ê∫ñÈÄ≤Ë°åË©ï‰º∞Ôºå‰ΩÜË≥áÊñôÊ±°ÊüìÂèØËÉΩÊúÉÂ∞éËá¥È´ò‰º∞ÊïàËÉΩ„ÄÇÂÖàÂâçÁöÑÁ†îÁ©∂Â∞àÊ≥®ÊñºÈÄèÈÅéÂà§Êñ∑Ê®°ÂûãÂú®Ë®ìÁ∑¥ÊúüÈñìÊòØÂê¶ÁúãÂà∞ÂÆåÂÖ®Áõ∏ÂêåÁöÑË≥áÊñô‰æÜÂÅµÊ∏¨Ê±°Êüì„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄë‰∏ªÂºµÂç≥‰ΩøË®ìÁ∑¥ËàáÂü∫Ê∫ñË≥áÊñôÈ°û‰ººÁöÑË≥áÊñô‰πüÊúÉÊèêÂçáÂ∞çÂàÜ‰ΩàÂÖß‰ªªÂãôÁöÑÊïàËÉΩÔºåËÄå‰∏çÊúÉÊîπÂñÑÊï¥È´îÂÆπÈáèÔºåÊàëÂÄëÁ®±‰πãÁÇ∫ÂàÜ‰ΩàÂÖßÊ±°Êüì„ÄÇÁÇ∫‰∫ÜÊúâÊïàÂÅµÊ∏¨ÂàÜ‰ΩàÂÖßÊ±°ÊüìÔºåÊàëÂÄëÊèêÂá∫ DICEÔºåÈÄôÊòØ‰∏ÄÁ®ÆÊñ∞ÊñπÊ≥ïÔºåÂà©Áî® LLM ÁöÑÂÖßÈÉ®ÁãÄÊÖã‰æÜÂÆö‰Ωç‰∏¶ÂÅµÊ∏¨Ê±°Êüì„ÄÇDICE È¶ñÂÖàÊâæÂá∫Â∞çÊ±°ÊüìÊúÄÊïèÊÑüÁöÑÂ±§ÔºåÁÑ∂ÂæåÊ†πÊìöË©≤Â±§ÁöÑÂÖßÈÉ®ÁãÄÊÖãË®ìÁ∑¥ÂàÜÈ°ûÂô®„ÄÇÂØ¶È©óÈ°ØÁ§∫ DICE Âú®ÂÅµÊ∏¨ÂêÑÁ®Æ LLM ÂíåÊï∏Â≠∏Êé®ÁêÜË≥áÊñôÈõÜ‰∏≠ÁöÑÂàÜ‰ΩàÂÖßÊ±°ÊüìÊôÇÂÖ∑ÊúâÈ´òÂ∫¶Ê∫ñÁ¢∫ÊÄß„ÄÇÊàëÂÄëÈÇÑÂ±ïÁ§∫‰∫ÜË®ìÁ∑¥Â•ΩÁöÑ DICE ÂÅµÊ∏¨Âô®ÁöÑÊ≥õÂåñËÉΩÂäõÔºåÂÆÉËÉΩÂ§†ÂÅµÊ∏¨ÂÖ∑ÊúâÈ°û‰ººÂàÜ‰ΩàÁöÑÂêÑÁ®ÆÂü∫Ê∫ñ‰∏≠ÁöÑÊ±°Êüì„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁôºÁèæ DICE ÂÅµÊ∏¨ÂàÜÊï∏ËàáÊàëÂÄëÊàñÂÖ∂‰ªñÁµÑÁπîÂú®ÂõõÂÄãÊï∏Â≠∏Êé®ÁêÜË≥áÊñôÈõÜ‰∏äÂæÆË™øÁöÑÂçÅÂÄã LLM ÁöÑÊïàËÉΩÂëàÊ≠£Áõ∏ÈóúÔºà$R^2$ ÂÄºÂú® 0.6 Âà∞ 0.75 ‰πãÈñìÔºâ„ÄÇÈÄôË°®Á§∫ÂàÜ‰ΩàÂÖßÊ±°ÊüìÂïèÈ°åÂèØËÉΩÂ∞éËá¥È´ò‰º∞Ë®±Â§öÁèæÊúâÊ®°ÂûãÁöÑÁúüÊ≠£ËÉΩÂäõ„ÄÇÁ®ãÂºèÁ¢ºÂíåË≥áÊñôÂèØ‰ª•Âú® https://github.com/THU-KEG/DICE ÊâæÂà∞„ÄÇ

##### **Shield Synthesis for LTL Modulo Theories**
2406.04184v1 by Andoni Rodriguez, Guy Amir, Davide Corsi, Cesar Sanchez, Guy Katz

In recent years, Machine Learning (ML) models have achieved remarkable
success in various domains. However, these models also tend to demonstrate
unsafe behaviors, precluding their deployment in safety-critical systems. To
cope with this issue, ample research focuses on developing methods that
guarantee the safe behaviour of a given ML model. A prominent example is
shielding which incorporates an external component (a "shield") that blocks
unwanted behavior. Despite significant progress, shielding suffers from a main
setback: it is currently geared towards properties encoded solely in
propositional logics (e.g., LTL) and is unsuitable for richer logics. This, in
turn, limits the widespread applicability of shielding in many real-world
systems. In this work, we address this gap, and extend shielding to LTL modulo
theories, by building upon recent advances in reactive synthesis modulo
theories. This allowed us to develop a novel approach for generating shields
conforming to complex safety specifications in these more expressive, logics.
We evaluated our shields and demonstrate their ability to handle rich data with
temporal dynamics. To the best of our knowledge, this is the first approach for
synthesizing shields for such expressivity.

ÊëòË¶ÅÔºöËøëÂπ¥‰æÜÔºåÊ©üÂô®Â≠∏Áøí (ML) Ê®°ÂûãÂú®ÂêÑÂÄãÈ†òÂüüÈÉΩÂèñÂæó‰∫ÜÈ°ØËëóÁöÑÊàêÂäü„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÊ®°Âûã‰πüÂÇæÂêëÊñºË°®ÁèæÂá∫‰∏çÂÆâÂÖ®ÁöÑË°åÁÇ∫ÔºåÈÄô‰ΩøÂæóÂÆÉÂÄëÁÑ°Ê≥ïÈÉ®ÁΩ≤Âú®ÂÆâÂÖ®ÈóúÈçµÁ≥ªÁµ±‰∏≠„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄôÂÄãÂïèÈ°åÔºåÂ§ßÈáèÁöÑÁ†îÁ©∂Â∞àÊ≥®ÊñºÈñãÁôº‰øùË≠âÁµ¶ÂÆö ML Ê®°ÂûãÂÆâÂÖ®Ë°åÁÇ∫ÁöÑÊñπÊ≥ï„ÄÇ‰∏ÄÂÄãÁ™ÅÂá∫ÁöÑ‰æãÂ≠êÊòØÈò≤Ë≠∑ÔºåÂÆÉÂåÖÂê´‰∏ÄÂÄãÂ§ñÈÉ®ÁµÑ‰ª∂Ôºà‰∏ÄÂÄã„ÄåÈò≤Ë≠∑ÁΩ©„ÄçÔºâÔºåÂèØ‰ª•ÈòªÊ≠¢‰∏çÈúÄË¶ÅÁöÑË°åÁÇ∫„ÄÇÂÑòÁÆ°ÂèñÂæó‰∫ÜÈ°ØËëóÈÄ≤Â±ïÔºåÈò≤Ë≠∑‰ªçÁÑ∂Â≠òÂú®‰∏ÄÂÄã‰∏ªË¶ÅÁöÑÊå´ÊäòÔºöÂÆÉÁõÆÂâçÈáùÂ∞çÁöÑÊòØÂÉÖÂú®ÂëΩÈ°åÈÇèËºØÔºà‰æãÂ¶ÇÔºåLTLÔºâ‰∏≠Á∑®Á¢ºÁöÑÂ±¨ÊÄßÔºå‰∏¶‰∏çÈÅ©ÂêàÊñºÊõ¥Ë±êÂØåÁöÑÈÇèËºØ„ÄÇÈÄôÂèçÈÅé‰æÜÂèàÈôêÂà∂‰∫ÜÈò≤Ë≠∑Âú®Ë®±Â§öÁèæÂØ¶‰∏ñÁïåÁ≥ªÁµ±‰∏≠ÁöÑÂª£Ê≥õÈÅ©Áî®ÊÄß„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëËß£Ê±∫‰∫ÜÈÄôÂÄãÂ∑ÆË∑ùÔºå‰∏¶ÈÄöÈÅéÂª∫Á´ãÂú®ÂèçÊáâÂºèÂêàÊàêÊ®°ÁµÑÂåñÁêÜË´ñÁöÑÊúÄÊñ∞ÈÄ≤Â±ï‰πã‰∏äÔºåÂ∞áÈò≤Ë≠∑Êì¥Â±ïÂà∞ LTL Ê®°ÁµÑÂåñÁêÜË´ñ„ÄÇÈÄô‰ΩøÊàëÂÄëËÉΩÂ§†ÈñãÁôº‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÊñπÊ≥ïÔºåÁî®ÊñºÁîüÊàêÁ¨¶ÂêàÈÄô‰∫õÊõ¥ÂÖ∑Ë°®ÁèæÂäõÁöÑÈÇèËºØ‰∏≠Ë§áÈõúÂÆâÂÖ®Ë¶èÁØÑÁöÑÈò≤Ë≠∑ÁΩ©„ÄÇÊàëÂÄëË©ï‰º∞‰∫ÜÊàëÂÄëÁöÑÈò≤Ë≠∑ÁΩ©Ôºå‰∏¶Â±ïÁ§∫‰∫ÜÂÆÉÂÄëËôïÁêÜÂÖ∑ÊúâÊôÇÈñìÂãïÊÖãÁöÑË±êÂØåÊï∏ÊìöÁöÑËÉΩÂäõ„ÄÇÊìöÊàëÂÄëÊâÄÁü•ÔºåÈÄôÊòØÁ¨¨‰∏ÄÁ®ÆÁî®ÊñºÂêàÊàêÂÖ∑ÊúâÈÄôÁ®ÆË°®ÁèæÂäõÁöÑÈò≤Ë≠∑ÁΩ©ÁöÑÊñπÊ≥ï„ÄÇ

##### **Confabulation: The Surprising Value of Large Language Model Hallucinations**
2406.04175v1 by Peiqi Sui, Eamon Duede, Sophie Wu, Richard Jean So

This paper presents a systematic defense of large language model (LLM)
hallucinations or 'confabulations' as a potential resource instead of a
categorically negative pitfall. The standard view is that confabulations are
inherently problematic and AI research should eliminate this flaw. In this
paper, we argue and empirically demonstrate that measurable semantic
characteristics of LLM confabulations mirror a human propensity to utilize
increased narrativity as a cognitive resource for sense-making and
communication. In other words, it has potential value. Specifically, we analyze
popular hallucination benchmarks and reveal that hallucinated outputs display
increased levels of narrativity and semantic coherence relative to veridical
outputs. This finding reveals a tension in our usually dismissive
understandings of confabulation. It suggests, counter-intuitively, that the
tendency for LLMs to confabulate may be intimately associated with a positive
capacity for coherent narrative-text generation.

ÊëòË¶ÅÔºöÊú¨ÊñáÁ≥ªÁµ±ÊÄßÂú∞Ë´ñËø∞‰∫ÜÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÂπªË¶∫Êàñ„ÄåÊçèÈÄ†„ÄçÔºåÂ∞áÂÖ∂Ë¶ñÁÇ∫‰∏ÄÁ®ÆÊΩõÂú®Ë≥áÊ∫êÔºåËÄåÈùûÁµïÂ∞çË≤†Èù¢ÁöÑÈô∑Èò±„ÄÇÊ®ôÊ∫ñËßÄÈªûË™çÁÇ∫ÊçèÈÄ†Êú¨Ë≥™‰∏äÊòØÊúâÂïèÈ°åÁöÑÔºå‰∫∫Â∑•Êô∫ÊÖßÁ†îÁ©∂ÊáâÊ∂àÈô§Ê≠§Áº∫Èô∑„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëË´ñË≠â‰∏¶ÂØ¶Ë≠âË≠âÊòéÔºåLLM ÊçèÈÄ†ÁöÑÂèØÊ∏¨ÈáèË™ûÁæ©ÁâπÂæµÂèçÊò†‰∫Ü‰∫∫È°ûÂÇæÂêëÊñºÂà©Áî®Â¢ûÂä†ÁöÑÊïò‰∫ãÊÄß‰ΩúÁÇ∫ÁêÜËß£ÂíåÊ∫ùÈÄöÁöÑË™çÁü•Ë≥áÊ∫ê„ÄÇÊèõÂè•Ë©±Ë™™ÔºåÂÆÉÂÖ∑ÊúâÊΩõÂú®ÂÉπÂÄº„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÂàÜÊûê‰∫ÜÊµÅË°åÁöÑÂπªË¶∫Âü∫Ê∫ñÔºå‰∏¶Êè≠Á§∫‰∫ÜÂπªË¶∫Ëº∏Âá∫ÁöÑÊïò‰∫ãÊÄßÂíåË™ûÁæ©‰∏ÄËá¥ÊÄßÈ´òÊñºÁúüÂØ¶Ëº∏Âá∫ÁöÑÂ±§Á¥ö„ÄÇÊ≠§ÁôºÁèæÊè≠Á§∫‰∫ÜÊàëÂÄëÈÄöÂ∏∏Â∞çÊçèÈÄ†ÁöÑ‰∏çÂ±ëÁêÜËß£‰∏≠ÁöÑÁ∑äÂºµÈóú‰øÇ„ÄÇÂÆÉÂèçÁõ¥Ë¶∫Âú∞Ë°®ÊòéÔºåLLM ÊçèÈÄ†ÁöÑÂÇæÂêëÂèØËÉΩËàáÈÄ£Ë≤´Êïò‰∫ãÊñáÊú¨ÁîüÊàêÁöÑÊ≠£Èù¢ËÉΩÂäõÂØÜÂàáÁõ∏Èóú„ÄÇ

##### **Pointer-Guided Pre-Training: Infusing Large Language Models with Paragraph-Level Contextual Awareness**
2406.04156v1 by Lars Hillebrand, Prabhupad Pradhan, Christian Bauckhage, Rafet Sifa

We introduce "pointer-guided segment ordering" (SO), a novel pre-training
technique aimed at enhancing the contextual understanding of paragraph-level
text representations in large language models. Our methodology leverages a
self-attention-driven pointer network to restore the original sequence of
shuffled text segments, addressing the challenge of capturing the structural
coherence and contextual dependencies within documents. This pre-training
approach is complemented by a fine-tuning methodology that incorporates dynamic
sampling, augmenting the diversity of training instances and improving sample
efficiency for various downstream applications. We evaluate our method on a
diverse set of datasets, demonstrating its efficacy in tasks requiring
sequential text classification across scientific literature and financial
reporting domains. Our experiments show that pointer-guided pre-training
significantly enhances the model's ability to understand complex document
structures, leading to state-of-the-art performance in downstream
classification tasks.

ÊëòË¶ÅÔºöÊàëÂÄëÂºïÂÖ•„ÄåÊåáÊ®ôÂºïÂ∞éÁâáÊÆµÊéíÂ∫è„Äç(SO)Ôºå‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÈ†êË®ìÁ∑¥ÊäÄË°ìÔºåÊó®Âú®ÊèêÂçáÂ§ßÂûãË™ûË®ÄÊ®°Âûã‰∏≠ÊÆµËêΩÂ±§Á¥öÊñáÊú¨Ë°®ÂæµÁöÑË™ûÂ¢ÉÁêÜËß£ËÉΩÂäõ„ÄÇÊàëÂÄëÁöÑÊäÄË°ìÊñπÊ≥ïÂà©Áî®Ëá™Ê≥®ÊÑèÂäõÈ©ÖÂãïÁöÑÊåáÊ®ôÁ∂≤Ë∑ØÔºå‰æÜÈÇÑÂéüÊâì‰∫ÇÈ†ÜÂ∫èÁöÑÊñáÂ≠óÁâáÊÆµÁöÑÂéüÂßãÈ†ÜÂ∫èÔºå‰ª•Ëß£Ê±∫ÊçïÊçâÊñá‰ª∂‰∏≠ÁöÑÁµêÊßãÈÄ£Ë≤´ÊÄßÂíåË™ûÂ¢É‰æùË≥¥ÊÄßÁöÑÊåëÊà∞„ÄÇÊ≠§È†êË®ìÁ∑¥ÊñπÊ≥ïÊê≠ÈÖç‰∫ÜÁµêÂêàÂãïÊÖãÂèñÊ®£ÁöÑÂæÆË™øÊäÄË°ìÔºåÊì¥Â¢ûË®ìÁ∑¥ÂØ¶‰æãÁöÑÂ§öÊ®£ÊÄßÔºå‰∏¶ÊèêÂçáÂêÑÁ®Æ‰∏ãÊ∏∏ÊáâÁî®Á®ãÂºèÁöÑÂèñÊ®£ÊïàÁéá„ÄÇÊàëÂÄëÂú®ÂêÑÁ®ÆË≥áÊñôÈõÜ‰∏äË©ï‰º∞ÊàëÂÄëÁöÑÊ®°ÂûãÔºåË≠âÊòé‰∫ÜÂÆÉÂú®ÈúÄË¶ÅÂ∫èÂàóÊñáÂ≠óÂàÜÈ°ûÁöÑ‰ªªÂãô‰∏≠ÁöÑÊïàËÉΩÔºåÊ∂µËìãÁßëÂ≠∏ÊñáÁçªÂíåË≤°ÂãôÂ†±ÂëäÈ†òÂüü„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÈ°ØÁ§∫ÔºåÊåáÊ®ôÂºïÂ∞éÈ†êË®ìÁ∑¥Â§ßÂπÖÊèêÂçáÊ®°ÂûãÁêÜËß£Ë§áÈõúÊñá‰ª∂ÁµêÊßãÁöÑËÉΩÂäõÔºåÂú®ÂæåÁ∫åÂàÜÈ°û‰ªªÂãô‰∏≠ÈÅîÂà∞ÊúÄÂÖàÈÄ≤ÁöÑÊïàËÉΩ„ÄÇ

##### **AgentGym: Evolving Large Language Model-based Agents across Diverse Environments**
2406.04151v1 by Zhiheng Xi, Yiwen Ding, Wenxiang Chen, Boyang Hong, Honglin Guo, Junzhe Wang, Dingwen Yang, Chenyang Liao, Xin Guo, Wei He, Songyang Gao, Lu Chen, Rui Zheng, Yicheng Zou, Tao Gui, Qi Zhang, Xipeng Qiu, Xuanjing Huang, Zuxuan Wu, Yu-Gang Jiang

Building generalist agents that can handle diverse tasks and evolve
themselves across different environments is a long-term goal in the AI
community. Large language models (LLMs) are considered a promising foundation
to build such agents due to their generalized capabilities. Current approaches
either have LLM-based agents imitate expert-provided trajectories step-by-step,
requiring human supervision, which is hard to scale and limits environmental
exploration; or they let agents explore and learn in isolated environments,
resulting in specialist agents with limited generalization. In this paper, we
take the first step towards building generally-capable LLM-based agents with
self-evolution ability. We identify a trinity of ingredients: 1) diverse
environments for agent exploration and learning, 2) a trajectory set to equip
agents with basic capabilities and prior knowledge, and 3) an effective and
scalable evolution method. We propose AgentGym, a new framework featuring a
variety of environments and tasks for broad, real-time, uni-format, and
concurrent agent exploration. AgentGym also includes a database with expanded
instructions, a benchmark suite, and high-quality trajectories across
environments. Next, we propose a novel method, AgentEvol, to investigate the
potential of agent self-evolution beyond previously seen data across tasks and
environments. Experimental results show that the evolved agents can achieve
results comparable to SOTA models. We release the AgentGym suite, including the
platform, dataset, benchmark, checkpoints, and algorithm implementations. The
AgentGym suite is available on https://github.com/WooooDyy/AgentGym.

ÊëòË¶ÅÔºöÂª∫Á´ãËÉΩÂ§†ËôïÁêÜÂêÑÁ®Æ‰ªªÂãô‰∏¶Âú®‰∏çÂêåÁí∞Â¢É‰∏≠Ëá™ÊàëÊºîÂåñÁöÑÈÄöÊâç‰ª£ÁêÜÊòØ AI Á§æÁæ§‰∏≠ÁöÑÈï∑ÊúüÁõÆÊ®ô„ÄÇÁî±ÊñºÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂÖ∑ÊúâÂª£Ê≥õÁöÑËÉΩÂäõÔºåÂõ†Ê≠§Ë¢´Ë™çÁÇ∫ÊòØÂª∫Á´ãÊ≠§È°û‰ª£ÁêÜÁöÑÊúâÂ∏åÊúõÁöÑÂü∫Á§é„ÄÇÁõÆÂâçÁöÑÂÅöÊ≥ïË¶Å‰πàËÆìÂü∫Êñº LLM ÁöÑ‰ª£ÁêÜÈÄêÊ≠•È©üÊ®°‰ªøÂ∞àÂÆ∂Êèê‰æõÁöÑËªåË∑°ÔºåÈúÄË¶Å‰∫∫Â∑•Áõ£Áù£ÔºåÈÄôÈõ£‰ª•Êì¥Â±ï‰∏îÊúÉÈôêÂà∂Áí∞Â¢ÉÊé¢Á¥¢ÔºõÊàñËÄÖËÆì‰ª£ÁêÜÂú®Â≠§Á´ãÁöÑÁí∞Â¢É‰∏≠Êé¢Á¥¢ÂíåÂ≠∏ÁøíÔºåÂ∞éËá¥Â∞àÂÆ∂‰ª£ÁêÜÁöÑÊ¶ÇÂåñËÉΩÂäõÊúâÈôê„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÈÇÅÂá∫‰∫ÜÂª∫Á´ãÂÖ∑ÊúâËá™ÊàëÊºîÂåñËÉΩÂäõÁöÑÈÄöÁî® LLM Âü∫Á§é‰ª£ÁêÜÁöÑÁ¨¨‰∏ÄÊ≠•„ÄÇÊàëÂÄëÁ¢∫ÂÆö‰∫Ü‰∏âÈ†ÖË¶ÅÁ¥†Ôºö1) ‰ª£ÁêÜÊé¢Á¥¢ÂíåÂ≠∏ÁøíÁöÑÂ§öÂÖÉÁí∞Â¢ÉÔºå2) Ë≥¶‰∫à‰ª£ÁêÜÂü∫Êú¨ËÉΩÂäõÂíåÂÖàÈ©óÁü•Ë≠òÁöÑËªåË∑°ÈõÜÔºå‰ª•Âèä 3) ‰∏ÄÁ®ÆÊúâÊïà‰∏îÂèØÊì¥Â±ïÁöÑÊºîÂåñÊñπÊ≥ï„ÄÇÊàëÂÄëÊèêÂá∫‰∫Ü AgentGymÔºåÈÄôÊòØ‰∏ÄÂÄãÊñ∞ÁöÑÊ°ÜÊû∂ÔºåÂÖ∑ÊúâÂ§öÁ®ÆÁí∞Â¢ÉÂíå‰ªªÂãôÔºåÂèØÈÄ≤Ë°åÂª£Ê≥õ„ÄÅÂØ¶ÊôÇ„ÄÅÁµ±‰∏ÄÊ†ºÂºèÂíå‰∏¶Áôº‰ª£ÁêÜÊé¢Á¥¢„ÄÇAgentGym ÈÇÑÂåÖÊã¨‰∏ÄÂÄãÂåÖÂê´Êì¥Â±ïÊåá‰ª§„ÄÅÂü∫Ê∫ñÂ•ó‰ª∂ÂíåË∑®Áí∞Â¢ÉÁöÑÈ´òË≥™ÈáèËªåË∑°ÁöÑË≥áÊñôÂ∫´„ÄÇÊé•‰∏ã‰æÜÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞ÊñπÊ≥ï AgentEvolÔºå‰ª•Êé¢Á¥¢‰ª£ÁêÜÂú®‰ªªÂãôÂíåÁí∞Â¢É‰∏≠Ë∂ÖË∂äÂÖàÂâçÊâÄË¶ãÊï∏ÊìöÁöÑËá™ÊàëÊºîÂåñÊΩõÂäõ„ÄÇÂØ¶È©óÁµêÊûúË°®ÊòéÔºåÊºîÂåñÂæåÁöÑ‰ª£ÁêÜÂèØ‰ª•ÂØ¶ÁèæËàá SOTA Ê®°ÂûãÁõ∏Áï∂ÁöÑÁµêÊûú„ÄÇÊàëÂÄëÁôºÂ∏É‰∫Ü AgentGym Â•ó‰ª∂ÔºåÂåÖÊã¨Âπ≥Âè∞„ÄÅÊï∏ÊìöÈõÜ„ÄÅÂü∫Ê∫ñ„ÄÅÊ™¢Êü•ÈªûÂíåÊºîÁÆóÊ≥ïÂØ¶‰Ωú„ÄÇAgentGym Â•ó‰ª∂ÂèØÂú® https://github.com/WooooDyy/AgentGym ‰∏äÂèñÂæó„ÄÇ

##### **Characterizing segregation in blast rock piles a deep-learning approach leveraging aerial image analysis**
2406.04149v1 by Chengeng Liu, Sihong Liu, Chaomin Shen, Yupeng Gao, Yuxuan Liu

Blasted rock material serves a critical role in various engineering
applications, yet the phenomenon of segregation-where particle sizes vary
significantly along the gradient of a quarry pile-presents challenges for
optimizing quarry material storage and handling. This study introduces an
advanced image analysis methodology to characterize such segregation of rock
fragments. The accurate delineation of detailed rock fragment size
distributions was achieved through the analysis of drone-captured imagery,
coupled with the application of an enhanced Unet semantic segmentation model
integrated with an expansion-based post-processing technique. The quarry slope
was stratified into four vertical sections, with the size distribution of each
section quantified via ellipsoid shape approximations. Our results disclose
pronounced vertical segregation patterns, with finer particles concentrated in
the upper slope regions and coarser particles in the lower. Utilizing relative
characteristic diameters, we offered insight into the degree of segregation,
thereby illustrating the spatial heterogeneity in fragment size more clearly.
The techniques outlined in this study deliver a scalable and accurate method
for assessing fragment size distribution, with the potential to better inform
resource management and operational decisions in quarry management.

ÊëòË¶ÅÔºöÁàÜÁ†¥Â≤©Áü≥ÊùêÊñôÂú®ÂêÑÁßçÂ∑•Á®ãÂ∫îÁî®‰∏≠ÂèëÊå•ÁùÄËá≥ÂÖ≥ÈáçË¶ÅÁöÑ‰ΩúÁî®ÔºåÁÑ∂ËÄåÔºåÂÅèÊûêÁé∞Ë±°‚Äî‚ÄîÂÖ∂‰∏≠Á≤íÂ∫¶Âú®ÈááÁü≥Âú∫Â†ÜÁßØÁöÑÊ¢ØÂ∫¶‰∏äÂ∑ÆÂºÇÊòæËëó‚Äî‚ÄîÂØπ‰ºòÂåñÈááÁü≥Âú∫ÊùêÊñôÁöÑÂÇ®Â≠òÂíåÂ§ÑÁêÜÊèêÂá∫‰∫ÜÊåëÊàò„ÄÇÊú¨Á†îÁ©∂ÂºïÂÖ•‰∫Ü‰∏ÄÁßçÂÖàËøõÁöÑÂõæÂÉèÂàÜÊûêÊñπÊ≥ïÊù•Ë°®ÂæÅÂ≤©Áü≥Á¢éÂùóÁöÑËøôÁßçÂÅèÊûê„ÄÇÈÄöËøáÂàÜÊûêÊó†‰∫∫Êú∫ÊãçÊëÑÁöÑÂõæÂÉèÔºåÂπ∂ÁªìÂêàÂ∫îÁî®‰∫Ü‰∏ÄÁßçÂ¢ûÂº∫ÁöÑ Unet ËØ≠‰πâÂàÜÂâ≤Ê®°Âûã‰ª•ÂèäÂü∫‰∫éÊâ©Â±ïÁöÑÂêéÂ§ÑÁêÜÊäÄÊúØÔºåÂáÜÁ°ÆÂú∞ÊèèÁªò‰∫ÜËØ¶ÁªÜÁöÑÂ≤©Áü≥Á¢éÂùóÂ∞∫ÂØ∏ÂàÜÂ∏É„ÄÇÈááÁü≥Âú∫ÊñúÂù°Ë¢´ÂàÜÂ±Ç‰∏∫Âõõ‰∏™ÂûÇÁõ¥ÈÉ®ÂàÜÔºåÊØè‰∏™ÈÉ®ÂàÜÁöÑÂ∞∫ÂØ∏ÂàÜÂ∏ÉÈÄöËøáÊ§≠ÁêÉÂΩ¢Áä∂Ëøë‰ººÊù•ÈáèÂåñ„ÄÇÊàë‰ª¨ÁöÑÁªìÊûúÊè≠Á§∫‰∫ÜÊòéÊòæÁöÑÂûÇÁõ¥ÂÅèÊûêÊ®°ÂºèÔºåÂÖ∂‰∏≠ËæÉÁªÜÁöÑÈ¢óÁ≤íÈõÜ‰∏≠Âú®ËæÉÈ´òÁöÑÊñúÂù°Âå∫ÂüüÔºåËÄåËæÉÁ≤óÁöÑÈ¢óÁ≤íÈõÜ‰∏≠Âú®ËæÉ‰ΩéÁöÑÊñúÂù°Âå∫Âüü„ÄÇÂà©Áî®Áõ∏ÂØπÁâπÂæÅÁõ¥ÂæÑÔºåÊàë‰ª¨Ê∑±ÂÖ•‰∫ÜËß£‰∫ÜÂÅèÊûêÁ®ãÂ∫¶Ôºå‰ªéËÄåÊõ¥Ê∏ÖÊ•öÂú∞ËØ¥Êòé‰∫ÜÁ¢éÂùóÂ∞∫ÂØ∏ÁöÑÁ©∫Èó¥ÂºÇË¥®ÊÄß„ÄÇÊú¨Á†îÁ©∂‰∏≠Ê¶ÇËø∞ÁöÑÊäÄÊúØÊèê‰æõ‰∫Ü‰∏ÄÁßçÂèØÊâ©Â±ï‰∏îÂáÜÁ°ÆÁöÑÊñπÊ≥ïÊù•ËØÑ‰º∞Á¢éÂùóÂ∞∫ÂØ∏ÂàÜÂ∏ÉÔºåÊúâÂèØËÉΩÊõ¥Â•ΩÂú∞‰∏∫ÈááÁü≥Âú∫ÁÆ°ÁêÜ‰∏≠ÁöÑËµÑÊ∫êÁÆ°ÁêÜÂíåËøêËê•ÂÜ≥Á≠ñÊèê‰æõ‰ø°ÊÅØ„ÄÇ

##### **Towards Understanding Task-agnostic Debiasing Through the Lenses of Intrinsic Bias and Forgetfulness**
2406.04146v1 by Guangliang Liu, Milad Afshari, Xitong Zhang, Zhiyu Xue, Avrajit Ghosh, Bidhan Bashyal, Rongrong Wang, Kristen Johnson

While task-agnostic debiasing provides notable generalizability and reduced
reliance on downstream data, its impact on language modeling ability and the
risk of relearning social biases from downstream task-specific data remain as
the two most significant challenges when debiasing Pretrained Language Models
(PLMs). The impact on language modeling ability can be alleviated given a
high-quality and long-contextualized debiasing corpus, but there remains a
deficiency in understanding the specifics of relearning biases. We empirically
ascertain that the effectiveness of task-agnostic debiasing hinges on the
quantitative bias level of both the task-specific data used for downstream
applications and the debiased model. We empirically show that the lower bound
of the bias level of the downstream fine-tuned model can be approximated by the
bias level of the debiased model, in most practical cases. To gain more
in-depth understanding about how the parameters of PLMs change during
fine-tuning due to the forgetting issue of PLMs, we propose a novel framework
which can Propagate Socially-fair Debiasing to Downstream Fine-tuning,
ProSocialTuning. Our proposed framework can push the fine-tuned model to
approach the bias lower bound during downstream fine-tuning, indicating that
the ineffectiveness of debiasing can be alleviated by overcoming the forgetting
issue through regularizing successfully debiased attention heads based on the
PLMs' bias levels from stages of pretraining and debiasing.

ÊëòË¶ÅÔºö<paragraph>ÂÑòÁÆ°Ëàá‰ªªÂãôÁÑ°ÈóúÁöÑÂéªÂÅèË¶ãÊèê‰æõ‰∫ÜÈ°ØËëóÁöÑÊ¶ÇÊã¨ÊÄß‰∏¶Ê∏õÂ∞ë‰∫ÜÂ∞ç‰∏ãÊ∏∏Ë≥áÊñôÁöÑ‰æùË≥¥Ôºå‰ΩÜÂÆÉÂ∞çË™ûË®ÄÂª∫Ê®°ËÉΩÂäõÁöÑÂΩ±Èüø‰ª•ÂèäÂæû‰∏ãÊ∏∏ÁâπÂÆö‰ªªÂãôË≥áÊñôÈáçÊñ∞Â≠∏ÁøíÁ§æÊúÉÂÅèË¶ãÁöÑÈ¢®Èö™‰ªçÁÑ∂ÊòØÂéªÂÅèË¶ãÈ†êË®ìÁ∑¥Ë™ûË®ÄÊ®°Âûã (PLM) ÊôÇÂÖ©ÂÄãÊúÄÈáçË¶ÅÁöÑÊåëÊà∞„ÄÇÂú®Áµ¶ÂÆöÈ´òÂìÅË≥™‰∏îÈï∑ÊôÇÈñìËÑàÁµ°ÂåñÁöÑÂéªÂÅèË¶ãË™ûÊñôÂ∫´ÁöÑÊÉÖÊ≥Å‰∏ãÔºåÂèØ‰ª•Ê∏õËºïÂ∞çË™ûË®ÄÂª∫Ê®°ËÉΩÂäõÁöÑÂΩ±ÈüøÔºå‰ΩÜÂ∞çÊñºÈáçÊñ∞Â≠∏ÁøíÂÅèË¶ãÁöÑÂÖ∑È´îÊÉÖÊ≥Å‰ªçÁº∫‰πèÁêÜËß£„ÄÇÊàëÂÄëÊÜëÁ∂ìÈ©óÁ¢∫ÂÆöËàá‰ªªÂãôÁÑ°ÈóúÁöÑÂéªÂÅèË¶ãÁöÑÊúâÊïàÊÄßÂèñÊ±∫ÊñºÁî®Êñº‰∏ãÊ∏∏ÊáâÁî®Á®ãÂºèÂíåÂéªÂÅèË¶ãÊ®°ÂûãÁöÑÁâπÂÆö‰ªªÂãôË≥áÊñôÁöÑÈáèÂåñÂÅèË¶ãÁ®ãÂ∫¶„ÄÇÊàëÂÄëÊÜëÁ∂ìÈ©óË°®ÊòéÔºåÂú®Â§ßÂ§öÊï∏ÂØ¶ÈöõÊÉÖÊ≥Å‰∏ãÔºå‰∏ãÊ∏∏ÂæÆË™øÊ®°ÂûãÁöÑÂÅèË¶ãÁ®ãÂ∫¶ÁöÑ‰∏ãÈôêÂèØ‰ª•Ëøë‰ººÊñºÂéªÂÅèË¶ãÊ®°ÂûãÁöÑÂÅèË¶ãÁ®ãÂ∫¶„ÄÇÁÇ∫‰∫ÜÊõ¥Ê∑±ÂÖ•Âú∞Áû≠Ëß£ PLM ÁöÑÂèÉÊï∏Âú®ÂæÆË™øÈÅéÁ®ã‰∏≠Â¶Ç‰ΩïÂõ† PLM ÁöÑÈÅ∫ÂøòÂïèÈ°åËÄåÊîπËÆäÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊñ∞ÁöÑÊ°ÜÊû∂ÔºåÂèØ‰ª•Â∞áÁ§æÊúÉÂÖ¨Âπ≥ÂéªÂÅèË¶ãÂÇ≥Êí≠Âà∞‰∏ãÊ∏∏ÂæÆË™øÔºåÂç≥ ProSocialTuning„ÄÇÊàëÂÄëÊèêÂá∫ÁöÑÊ°ÜÊû∂ÂèØ‰ª•Âú®‰∏ãÊ∏∏ÂæÆË™øÈÅéÁ®ã‰∏≠Êé®ÂãïÂæÆË™øÊ®°ÂûãÊé•ËøëÂÅèË¶ã‰∏ãÈôêÔºåÈÄôË°®ÊòéÈÄèÈÅéÊ†πÊìö PLM Âú®È†êË®ìÁ∑¥ÂíåÂéªÂÅèË¶ãÈöéÊÆµÁöÑÂÅèË¶ãÁ®ãÂ∫¶ÔºåË¶èÁØÑÊàêÂäüÂéªÂÅèË¶ãÁöÑÊ≥®ÊÑèÂäõÈ†≠ÔºåÂèØ‰ª•ÂÖãÊúçÈÅ∫ÂøòÂïèÈ°åÔºåÂæûËÄåÊ∏õËºïÂéªÂÅèË¶ãÁöÑÁÑ°ÊïàÊÄß„ÄÇ</paragraph>

##### **Every Answer Matters: Evaluating Commonsense with Probabilistic Measures**
2406.04145v1 by Qi Cheng, Michael Boratko, Pranay Kumar Yelugam, Tim O'Gorman, Nalini Singh, Andrew McCallum, Xiang Lorraine Li

Large language models have demonstrated impressive performance on commonsense
tasks; however, these tasks are often posed as multiple-choice questions,
allowing models to exploit systematic biases. Commonsense is also inherently
probabilistic with multiple correct answers. The purpose of "boiling water"
could be making tea and cooking, but it also could be killing germs. Existing
tasks do not capture the probabilistic nature of common sense. To this end, we
present commonsense frame completion (CFC), a new generative task that
evaluates common sense via multiple open-ended generations. We also propose a
method of probabilistic evaluation that strongly correlates with human
judgments. Humans drastically outperform strong language model baselines on our
dataset, indicating this approach is both a challenging and useful evaluation
of machine common sense.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÂú®Â∏∏Ë≠ò‰ªªÂãô‰∏äË°®ÁèæÂá∫Ëâ≤ÔºõÁÑ∂ËÄåÔºåÈÄô‰∫õ‰ªªÂãôÈÄöÂ∏∏Ë¢´Ë°®Ëø∞ÁÇ∫Â§öÈÅ∏È°åÔºåÂÖÅË®±Ê®°ÂûãÂà©Áî®Á≥ªÁµ±ÊÄßÂÅèÂ∑Æ„ÄÇÂ∏∏Ë≠òÊú¨Ë≥™‰∏ä‰πüÊòØÊ©üÁéáÊÄßÁöÑÔºåÊúâÂ§öÂÄãÊ≠£Á¢∫Á≠îÊ°à„ÄÇ„ÄåÁÖÆÊ≤∏Ê∞¥„ÄçÁöÑÁõÆÁöÑÂèØËÉΩÊòØÊ≥°Ëå∂ÂíåÁÉπÈ£™Ôºå‰ΩÜ‰πüÂèØËÉΩÊòØÊÆ∫Ê≠ªÁ¥∞Ëèå„ÄÇÁèæÊúâÁöÑ‰ªªÂãô‰∏¶Êú™ÊçïÊçâÂà∞Â∏∏Ë≠òÁöÑÊ©üÁéáÊÄß„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÊèêÂá∫Â∏∏Ë≠òÊ°ÜÊû∂ÂÆåÊàê (CFC)ÔºåÈÄôÊòØ‰∏ÄÁ®ÆÊñ∞ÁöÑÁîüÊàê‰ªªÂãôÔºåÈÄèÈÅéÂ§öÂÄãÈñãÊîæÂºèÁîüÊàê‰æÜË©ï‰º∞Â∏∏Ë≠ò„ÄÇÊàëÂÄëÈÇÑÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊ©üÁéáÊÄßË©ï‰º∞ÊñπÊ≥ïÔºåËàá‰∫∫È°ûÁöÑÂà§Êñ∑ÂØÜÂàáÁõ∏Èóú„ÄÇ‰∫∫È°ûÂú®ÊàëÂÄëÁöÑË≥áÊñôÈõÜ‰∏äÂ§ßÂπÖÂÑ™ÊñºÂº∑Â§ßÁöÑË™ûË®ÄÊ®°ÂûãÂü∫Ê∫ñÔºåÈÄôË°®Á§∫ÈÄôÁ®ÆÊñπÊ≥ïÊó¢ÂÖ∑ÊúâÊåëÊà∞ÊÄßÔºåÂèàÊòØÂ∞çÊ©üÂô®Â∏∏Ë≠òÊúâÁî®ÁöÑË©ï‰º∞„ÄÇ

##### **Do Language Models Understand Morality? Towards a Robust Detection of Moral Content**
2406.04143v1 by Luana Bulla, Aldo Gangemi, Misael Mongiov√¨

The task of detecting moral values in text has significant implications in
various fields, including natural language processing, social sciences, and
ethical decision-making. Previously proposed supervised models often suffer
from overfitting, leading to hyper-specialized moral classifiers that struggle
to perform well on data from different domains. To address this issue, we
introduce novel systems that leverage abstract concepts and common-sense
knowledge acquired from Large Language Models and Natural Language Inference
models during previous stages of training on multiple data sources. By doing
so, we aim to develop versatile and robust methods for detecting moral values
in real-world scenarios. Our approach uses the GPT 3.5 model as a zero-shot
ready-made unsupervised multi-label classifier for moral values detection,
eliminating the need for explicit training on labeled data. We compare it with
a smaller NLI-based zero-shot model. The results show that the NLI approach
achieves competitive results compared to the Davinci model. Furthermore, we
conduct an in-depth investigation of the performance of supervised systems in
the context of cross-domain multi-label moral value detection. This involves
training supervised models on different domains to explore their effectiveness
in handling data from different sources and comparing their performance with
the unsupervised methods. Our contributions encompass a thorough analysis of
both supervised and unsupervised methodologies for cross-domain value
detection. We introduce the Davinci model as a state-of-the-art zero-shot
unsupervised moral values classifier, pushing the boundaries of moral value
detection without the need for explicit training on labeled data. Additionally,
we perform a comparative evaluation of our approach with the supervised models,
shedding light on their respective strengths and weaknesses.

ÊëòË¶ÅÔºö<paragraph>ÂÅµÊ∏¨ÊñáÂ≠ó‰∏≠ÁöÑÈÅìÂæ∑ÂÉπÂÄºÈÄôÈ†Ö‰ªªÂãôÂú®ÂêÑÁ®ÆÈ†òÂüüÈÉΩÊúâÈáçË¶ÅÁöÑÂΩ±ÈüøÔºåÂåÖÊã¨Ëá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ„ÄÅÁ§æÊúÉÁßëÂ≠∏ÂíåÈÅìÂæ∑Ê±∫Á≠ñÂà∂ÂÆö„ÄÇÂÖàÂâçÊèêÂá∫ÁöÑÁõ£Áù£ÂºèÊ®°ÂûãÂ∏∏Â∏∏ÊúÉÈÅéÂ∫¶Êì¨ÂêàÔºåÂ∞éËá¥È´òÂ∫¶Â∞àÊ•≠ÂåñÁöÑÈÅìÂæ∑ÂàÜÈ°ûÂô®Èõ£‰ª•Âú®‰∏çÂêåÈ†òÂüüÁöÑË≥áÊñô‰∏äË°®ÁèæËâØÂ•Ω„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÂºïÈÄ≤‰∫ÜÂâµÊñ∞ÁöÑÁ≥ªÁµ±ÔºåÂÆÉÂà©Áî®‰∫ÜÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÂíåËá™ÁÑ∂Ë™ûË®ÄÊé®Ë´ñÊ®°ÂûãÂú®ÂÖàÂâçË®ìÁ∑¥ÈöéÊÆµÂæûÂ§öÂÄãË≥áÊñô‰æÜÊ∫ê‰∏≠Áç≤ÂæóÁöÑÊäΩË±°Ê¶ÇÂøµÂíåÂ∏∏Ë≠òÁü•Ë≠ò„ÄÇÈÄèÈÅéÈÄôÊ®£ÂÅöÔºåÊàëÂÄëÊó®Âú®ÈñãÁôºÂá∫Â§öÂäüËÉΩ‰∏îÂº∑ÂÅ•ÁöÑÊñπÊ≥ïÔºåÁî®ÊñºÂÅµÊ∏¨ÁèæÂØ¶‰∏ñÁïå‰∏≠ÁöÑÈÅìÂæ∑ÂÉπÂÄº„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÊòØ‰ΩøÁî® GPT 3.5 Ê®°Âûã‰ΩúÁÇ∫ÈÅìÂæ∑ÂÉπÂÄºÂÅµÊ∏¨ÁöÑÈõ∂Ê¨°Â≠∏ÁøíÁèæÊàêÈùûÁõ£Áù£ÂºèÂ§öÊ®ôÁ±§ÂàÜÈ°ûÂô®ÔºåÁÑ°ÈúÄÂ∞çÊ®ôÁ±§Ë≥áÊñôÈÄ≤Ë°åÊòéÁ¢∫ÁöÑË®ìÁ∑¥„ÄÇÊàëÂÄëÂ∞áÂÆÉËàá‰∏ÄÂÄãËºÉÂ∞èÁöÑÂü∫Êñº NLI ÁöÑÈõ∂Ê¨°Â≠∏ÁøíÊ®°ÂûãÈÄ≤Ë°åÊØîËºÉ„ÄÇÁµêÊûúÈ°ØÁ§∫ÔºåËàá Davinci Ê®°ÂûãÁõ∏ÊØîÔºåNLI ÊñπÊ≥ïÈÅîÂà∞‰∫ÜÁ´∂Áà≠ÊÄßÁöÑÁµêÊûú„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂ∞çÁõ£Áù£ÂºèÁ≥ªÁµ±Âú®Ë∑®È†òÂüüÂ§öÊ®ôÁ±§ÈÅìÂæ∑ÂÉπÂÄºÂÅµÊ∏¨‰∏≠ÁöÑË°®ÁèæÈÄ≤Ë°å‰∫ÜÊ∑±ÂÖ•Ë™øÊü•„ÄÇÈÄôÂåÖÊã¨Âú®‰∏çÂêåÈ†òÂüüË®ìÁ∑¥Áõ£Áù£ÂºèÊ®°ÂûãÔºå‰ª•Êé¢Á¥¢ÂÆÉÂÄëÂú®ËôïÁêÜ‰æÜËá™‰∏çÂêå‰æÜÊ∫êÁöÑË≥áÊñôÊôÇÁöÑÊúâÊïàÊÄßÔºå‰∏¶Â∞áÂÆÉÂÄëÁöÑË°®ÁèæËàáÈùûÁõ£Áù£ÂºèÊñπÊ≥ïÈÄ≤Ë°åÊØîËºÉ„ÄÇÊàëÂÄëÁöÑË≤¢ÁçªÂåÖÊã¨Â∞çË∑®È†òÂüüÂÉπÂÄºÂÅµÊ∏¨ÁöÑÁõ£Áù£ÂºèÂíåÈùûÁõ£Áù£ÂºèÊñπÊ≥ïÈÄ≤Ë°åÂæπÂ∫ïÁöÑÂàÜÊûê„ÄÇÊàëÂÄëÂºïÈÄ≤ Davinci Ê®°Âûã‰ΩúÁÇ∫ÊúÄÂÖàÈÄ≤ÁöÑÈõ∂Ê¨°Â≠∏ÁøíÈùûÁõ£Áù£ÂºèÈÅìÂæ∑ÂÉπÂÄºÂàÜÈ°ûÂô®ÔºåÂú®ÁÑ°ÈúÄÂ∞çÊ®ôÁ±§Ë≥áÊñôÈÄ≤Ë°åÊòéÁ¢∫Ë®ìÁ∑¥ÁöÑÊÉÖÊ≥Å‰∏ãÔºåÊé®Âãï‰∫ÜÈÅìÂæ∑ÂÉπÂÄºÂÅµÊ∏¨ÁöÑÁïåÈôê„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂ∞çÊàëÂÄëÁöÑÂÅöÊ≥ïËàáÁõ£Áù£ÂºèÊ®°ÂûãÈÄ≤Ë°å‰∫ÜÊØîËºÉË©ï‰º∞ÔºåË™™Êòé‰∫ÜÂÆÉÂÄëÂêÑËá™ÁöÑÂÑ™Áº∫Èªû„ÄÇ</paragraph>

##### **Legal Judgment Reimagined: PredEx and the Rise of Intelligent AI Interpretation in Indian Courts**
2406.04136v1 by Shubham Kumar Nigam, Anurag Sharma, Danush Khanna, Noel Shallum, Kripabandhu Ghosh, Arnab Bhattacharya

In the era of Large Language Models (LLMs), predicting judicial outcomes
poses significant challenges due to the complexity of legal proceedings and the
scarcity of expert-annotated datasets. Addressing this, we introduce
\textbf{Pred}iction with \textbf{Ex}planation (\texttt{PredEx}), the largest
expert-annotated dataset for legal judgment prediction and explanation in the
Indian context, featuring over 15,000 annotations. This groundbreaking corpus
significantly enhances the training and evaluation of AI models in legal
analysis, with innovations including the application of instruction tuning to
LLMs. This method has markedly improved the predictive accuracy and explanatory
depth of these models for legal judgments. We employed various
transformer-based models, tailored for both general and Indian legal contexts.
Through rigorous lexical, semantic, and expert assessments, our models
effectively leverage \texttt{PredEx} to provide precise predictions and
meaningful explanations, establishing it as a valuable benchmark for both the
legal profession and the NLP community.

ÊëòË¶ÅÔºöÂú®Â§ßË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊôÇ‰ª£ÔºåÈ†êÊ∏¨Ê≥ïÂæãÁµêÊûúÁî±ÊñºÊ≥ïÂæãÁ®ãÂ∫èÁöÑË§áÈõúÊÄßÂíåÂ∞àÂÆ∂Ë®ªËß£Ë≥áÊñôÈõÜÁöÑÁ®ÄÂ∞ëÊÄßËÄåÈù¢Ëá®ÈáçÂ§ßÊåëÊà∞„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü„ÄåÈ†êÊ∏¨„ÄçËàá„ÄåËß£Èáã„ÄçÔºàPredExÔºâÔºåÈÄôÊòØÂç∞Â∫¶Ë™ûÂ¢É‰∏≠ÊúÄÂ§ßÁöÑÊ≥ïÂæãÂà§Ê±∫È†êÊ∏¨ÂíåËß£ÈáãÂ∞àÂÆ∂Ë®ªËß£Ë≥áÊñôÈõÜÔºåÂÖ∑ÊúâË∂ÖÈÅé 15,000 ÂÄãË®ªËß£„ÄÇÈÄôÂÄãÈñãÂâµÊÄßÁöÑË™ûÊñôÂ∫´È°ØËëóÂú∞Â¢ûÂº∑‰∫ÜÊ≥ïÂæãÂàÜÊûê‰∏≠ AI Ê®°ÂûãÁöÑË®ìÁ∑¥ÂíåË©ï‰º∞ÔºåÂâµÊñ∞‰πãËôïÂåÖÊã¨Â∞áÊåá‰ª§Ë™øÊï¥ÊáâÁî®Êñº LLM„ÄÇÊ≠§ÊñπÊ≥ïÈ°ØËëóÊèêÈ´ò‰∫ÜÈÄô‰∫õÊ®°ÂûãÂ∞çÊ≥ïÂæãÂà§Ê±∫ÁöÑÈ†êÊ∏¨Ê∫ñÁ¢∫Â∫¶ÂíåËß£ÈáãÊ∑±Â∫¶„ÄÇÊàëÂÄëÊé°Áî®‰∫ÜÂêÑÁ®ÆÂü∫ÊñºTransformerÁöÑÊ®°ÂûãÔºåÈáùÂ∞ç‰∏ÄËà¨ÂíåÂç∞Â∫¶Ê≥ïÂæãËÉåÊôØÈÄ≤Ë°åË™øÊï¥„ÄÇÈÄèÈÅéÂö¥Ë¨πÁöÑË©ûÂΩô„ÄÅË™ûÁæ©ÂíåÂ∞àÂÆ∂Ë©ï‰º∞ÔºåÊàëÂÄëÁöÑÊ®°ÂûãÊúâÊïàÂú∞Âà©Áî® PredEx Êèê‰æõÁ≤æÁ¢∫ÁöÑÈ†êÊ∏¨ÂíåÊúâÊÑèÁæ©ÁöÑËß£ÈáãÔºå‰ΩøÂÖ∂ÊàêÁÇ∫Ê≥ïÂæãÂ∞àÊ•≠Âíå NLP Á§æÁæ§ÁöÑÂØ∂Ë≤¥Âü∫Ê∫ñ„ÄÇ

##### **Are We Done with MMLU?**
2406.04127v2 by Aryo Pradipta Gema, Joshua Ong Jun Leang, Giwon Hong, Alessio Devoto, Alberto Carlo Maria Mancino, Rohit Saxena, Xuanli He, Yu Zhao, Xiaotang Du, Mohammad Reza Ghasemi Madani, Claire Barale, Robert McHardy, Joshua Harris, Jean Kaddour, Emile van Krieken, Pasquale Minervini

Maybe not. We identify and analyse errors in the popular Massive Multitask
Language Understanding (MMLU) benchmark. Even though MMLU is widely adopted,
our analysis demonstrates numerous ground truth errors that obscure the true
capabilities of LLMs. For example, we find that 57% of the analysed questions
in the Virology subset contain errors. To address this issue, we introduce a
comprehensive framework for identifying dataset errors using a novel error
taxonomy. Then, we create MMLU-Redux, which is a subset of 3,000 manually
re-annotated questions across 30 MMLU subjects. Using MMLU-Redux, we
demonstrate significant discrepancies with the model performance metrics that
were originally reported. Our results strongly advocate for revising MMLU's
error-ridden questions to enhance its future utility and reliability as a
benchmark. Therefore, we open up MMLU-Redux for additional annotation
https://huggingface.co/datasets/edinburgh-dawg/mmlu-redux.

ÊëòË¶ÅÔºö‰πüË®±‰∏çÊòØ„ÄÇÊàëÂÄëË≠òÂà•ÂíåÂàÜÊûê‰∫ÜÊµÅË°åÁöÑÂ§ßË¶èÊ®°Â§ö‰ªªÂãôË™ûË®ÄÁêÜËß£ (MMLU) Âü∫Ê∫ñ‰∏≠ÁöÑÈåØË™§„ÄÇÂÑòÁÆ° MMLU Ë¢´Âª£Ê≥õÊé°Áî®Ôºå‰ΩÜÊàëÂÄëÁöÑÂàÜÊûêË≠âÊòé‰∫ÜË®±Â§öÊé©Ëìã‰∫Ü LLM ÁúüÊ≠£ËÉΩÂäõÁöÑÁúüÂØ¶ÈåØË™§„ÄÇ‰æãÂ¶ÇÔºåÊàëÂÄëÁôºÁèæÁóÖÊØíÂ≠∏Â≠êÈõÜ‰∏≠ 57% ÁöÑÂàÜÊûêÂïèÈ°åÂåÖÂê´ÈåØË™§„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÂÄã‰ΩøÁî®Êñ∞ÈåØË™§ÂàÜÈ°ûÊ≥ïË≠òÂà•Ë≥áÊñôÈõÜÈåØË™§ÁöÑÁ∂úÂêàÊ°ÜÊû∂„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÂª∫Á´ã‰∫Ü MMLU-ReduxÔºåÂÆÉÊòØ 30 ÂÄã MMLU ‰∏ªÈ°å‰∏≠ 3,000 ÂÄãÊâãÂãïÈáçÊñ∞Ë®ªÈáãÂïèÈ°åÁöÑÂ≠êÈõÜ„ÄÇ‰ΩøÁî® MMLU-ReduxÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜËàáÊúÄÂàùÂ†±ÂëäÁöÑÊ®°ÂûãÊïàËÉΩÊåáÊ®ôÊúâÈ°ØËëóÂ∑ÆÁï∞„ÄÇÊàëÂÄëÁöÑÁµêÊûúÂº∑ÁÉà‰∏ªÂºµ‰øÆÊîπ MMLU ÂÖÖÊªøÈåØË™§ÁöÑÂïèÈ°åÔºå‰ª•Â¢ûÂº∑ÂÖ∂‰ΩúÁÇ∫Âü∫Ê∫ñÁöÑÊú™‰æÜÊïàÁî®ÂíåÂèØÈù†ÊÄß„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëÈñãÊîæ MMLU-Redux ‰ª•ÈÄ≤Ë°åÈ°çÂ§ñË®ªÈáã https://huggingface.co/datasets/edinburgh-dawg/mmlu-redux„ÄÇ

##### **Promoting Fairness and Diversity in Speech Datasets for Mental Health and Neurological Disorders Research**
2406.04116v1 by Eleonora Mancini, Ana Tanevska, Andrea Galassi, Alessio Galatolo, Federico Ruggeri, Paolo Torroni

Current research in machine learning and artificial intelligence is largely
centered on modeling and performance evaluation, less so on data collection.
However, recent research demonstrated that limitations and biases in data may
negatively impact trustworthiness and reliability. These aspects are
particularly impactful on sensitive domains such as mental health and
neurological disorders, where speech data are used to develop AI applications
aimed at improving the health of patients and supporting healthcare providers.
In this paper, we chart the landscape of available speech datasets for this
domain, to highlight possible pitfalls and opportunities for improvement and
promote fairness and diversity. We present a comprehensive list of desiderata
for building speech datasets for mental health and neurological disorders and
distill it into a checklist focused on ethical concerns to foster more
responsible research.

ÊëòË¶ÅÔºöÁõÆÂâçÁöÑÊ©üÂô®Â≠∏ÁøíÂíå‰∫∫Â∑•Êô∫ÊÖßÁ†îÁ©∂‰∏ªË¶ÅÈõÜ‰∏≠Âú®Âª∫Ê®°ÂíåÊïàËÉΩË©ï‰º∞‰∏äÔºåËºÉÂ∞ëËëóÈáçÊñºË≥áÊñôÊî∂ÈõÜ„ÄÇÁÑ∂ËÄåÔºåÊúÄËøëÁöÑÁ†îÁ©∂Ë°®ÊòéÔºåË≥áÊñô‰∏≠ÁöÑÈôêÂà∂ÂíåÂÅèË¶ãÂèØËÉΩÊúÉÂ∞çÂèØ‰ø°Â∫¶ÂíåÂèØÈù†ÊÄßÁî¢ÁîüË≤†Èù¢ÂΩ±Èüø„ÄÇÈÄô‰∫õÈù¢ÂêëÂú®ÂøÉÁêÜÂÅ•Â∫∑ÂíåÁ•ûÁ∂ìÁñæÁóÖÁ≠âÊïèÊÑüÈ†òÂüü‰∏≠ÁâπÂà•ÂÖ∑ÊúâÂΩ±ÈüøÂäõÔºåÂú®ÈÄô‰∫õÈ†òÂüü‰∏≠ÔºåË™ûÈü≥Ë≥áÊñôÁî®ÊñºÈñãÁôº‰∫∫Â∑•Êô∫ÊÖßÊáâÁî®Á®ãÂºèÔºåÊó®Âú®ÊîπÂñÑÊÇ£ËÄÖÂÅ•Â∫∑‰∏¶ÊîØÊè¥ÈÜ´ÁôÇ‰øùÂÅ•Êèê‰æõËÄÖ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÁπ™Ë£Ω‰∫ÜÊ≠§È†òÂüüÂèØÁî®ÁöÑË™ûÈü≥Ë≥áÊñôÈõÜÊ¶ÇÊ≥ÅÔºå‰ª•Âº∑Ë™øÂèØËÉΩÁöÑÈô∑Èò±ÂíåÊîπÈÄ≤Ê©üÊúÉÔºå‰∏¶‰øÉÈÄ≤ÂÖ¨Âπ≥ÊÄßÂíåÂ§öÊ®£ÊÄß„ÄÇÊàëÂÄëÊèê‰æõ‰∫Ü‰∏ÄÂÄãÂÖ®Èù¢ÁöÑÊ∏ÖÂñÆÔºåË™™Êòé‰∫ÜÂª∫Á´ãÂøÉÁêÜÂÅ•Â∫∑ÂíåÁ•ûÁ∂ìÁñæÁóÖË™ûÈü≥Ë≥áÊñôÈõÜÁöÑÁêÜÊÉ≥Ê¢ù‰ª∂Ôºå‰∏¶Â∞áÂÖ∂ÊøÉÁ∏ÆÊàê‰∏ÄÂÄãÂ∞àÊ≥®ÊñºÈÅìÂæ∑ËÄÉÈáèÁöÑÊ™¢Êü•Ê∏ÖÂñÆÔºå‰ª•‰øÉÈÄ≤Êõ¥Ë≤†Ë≤¨‰ªªÁöÑÁ†îÁ©∂„ÄÇ

##### **Uncovering Limitations of Large Language Models in Information Seeking from Tables**
2406.04113v1 by Chaoxu Pang, Yixuan Cao, Chunhao Yang, Ping Luo

Tables are recognized for their high information density and widespread
usage, serving as essential sources of information. Seeking information from
tables (TIS) is a crucial capability for Large Language Models (LLMs), serving
as the foundation of knowledge-based Q&A systems. However, this field presently
suffers from an absence of thorough and reliable evaluation. This paper
introduces a more reliable benchmark for Table Information Seeking (TabIS). To
avoid the unreliable evaluation caused by text similarity-based metrics, TabIS
adopts a single-choice question format (with two options per question) instead
of a text generation format. We establish an effective pipeline for generating
options, ensuring their difficulty and quality. Experiments conducted on 12
LLMs reveal that while the performance of GPT-4-turbo is marginally
satisfactory, both other proprietary and open-source models perform
inadequately. Further analysis shows that LLMs exhibit a poor understanding of
table structures, and struggle to balance between TIS performance and
robustness against pseudo-relevant tables (common in retrieval-augmented
systems). These findings uncover the limitations and potential challenges of
LLMs in seeking information from tables. We release our data and code to
facilitate further research in this field.

ÊëòË¶ÅÔºöË°®Ê†ºÂõ†ÂÖ∂‰ø°ÊÅØÂØÜÂ∫¶È´òÂíå‰ΩøÁî®ÂπøÊ≥õËÄåÂèóÂà∞ËÆ§ÂèØÔºåÊòØ‰ø°ÊÅØÁöÑÈáçË¶ÅÊù•Ê∫ê„ÄÇ‰ªéË°®Ê†º‰∏≠ÂØªÊ±Ç‰ø°ÊÅØ (TIS) ÊòØÂ§ßÂûãËØ≠Ë®ÄÊ®°Âûã (LLM) ÁöÑ‰∏ÄÈ°πÂÖ≥ÈîÆËÉΩÂäõÔºåÊòØÂü∫‰∫éÁü•ËØÜÁöÑÈóÆÁ≠îÁ≥ªÁªüÁöÑÂü∫Á°Ä„ÄÇÁÑ∂ËÄåÔºåËØ•È¢ÜÂüüÁõÆÂâçÁº∫‰πèÂΩªÂ∫ï‰∏îÂèØÈù†ÁöÑËØÑ‰º∞„ÄÇÊú¨Êñá‰∏∫Ë°®Ê†º‰ø°ÊÅØÊ£ÄÁ¥¢ (TabIS) ÂºïÂÖ•‰∫Ü‰∏Ä‰∏™Êõ¥ÂèØÈù†ÁöÑÂü∫ÂáÜ„ÄÇ‰∏∫‰∫ÜÈÅøÂÖçÂü∫‰∫éÊñáÊú¨Áõ∏‰ººÊÄßÁöÑÊåáÊ†áÈÄ†ÊàêÁöÑ‰∏çÂèØÈù†ËØÑ‰º∞ÔºåTabIS ÈááÁî®ÂçïÈÄâÈ¢òÊ†ºÂºèÔºàÊØè‰∏™ÈóÆÈ¢òÊúâ‰∏§‰∏™ÈÄâÈ°πÔºâÔºåËÄå‰∏çÊòØÊñáÊú¨ÁîüÊàêÊ†ºÂºè„ÄÇÊàë‰ª¨Âª∫Á´ã‰∫Ü‰∏Ä‰∏™ÊúâÊïàÁöÑÁÆ°ÈÅìÊù•ÁîüÊàêÈÄâÈ°πÔºåÁ°Æ‰øùÂÖ∂ÈöæÂ∫¶ÂíåË¥®Èáè„ÄÇÂØπ 12 ‰∏™ LLM ËøõË°åÁöÑÂÆûÈ™åË°®ÊòéÔºåËôΩÁÑ∂ GPT-4-turbo ÁöÑÊÄßËÉΩÂãâÂº∫‰ª§‰∫∫Êª°ÊÑèÔºå‰ΩÜÂÖ∂‰ªñ‰∏ìÊúâÊ®°ÂûãÂíåÂºÄÊ∫êÊ®°ÂûãÁöÑÊÄßËÉΩÈÉΩ‰∏çÂ§ü„ÄÇËøõ‰∏ÄÊ≠•ÁöÑÂàÜÊûêË°®ÊòéÔºåLLM ÂØπË°®Ê†ºÁªìÊûÑÁöÑÁêÜËß£ËæÉÂ∑ÆÔºåÂπ∂‰∏îÈöæ‰ª•Âú® TIS ÊÄßËÉΩÂíåÂØπ‰º™Áõ∏ÂÖ≥Ë°®Ê†ºÔºàÂú®Ê£ÄÁ¥¢Â¢ûÂº∫Á≥ªÁªü‰∏≠ÂæàÂ∏∏ËßÅÔºâÁöÑÈ≤ÅÊ£íÊÄß‰πãÈó¥ÂèñÂæóÂπ≥Ë°°„ÄÇËøô‰∫õÂèëÁé∞Êè≠Á§∫‰∫Ü LLM Âú®‰ªéË°®Ê†º‰∏≠ÂØªÊ±Ç‰ø°ÊÅØÊñπÈù¢ÁöÑÂ±ÄÈôêÊÄßÂíåÊΩúÂú®ÊåëÊàò„ÄÇÊàë‰ª¨ÂèëÂ∏ÉÊàë‰ª¨ÁöÑÊï∞ÊçÆÂíå‰ª£Á†ÅÔºå‰ª•‰øÉËøõËØ•È¢ÜÂüüÁöÑËøõ‰∏ÄÊ≠•Á†îÁ©∂„ÄÇ

##### **Compressible Dynamics in Deep Overparameterized Low-Rank Learning & Adaptation**
2406.04112v1 by Can Yaras, Peng Wang, Laura Balzano, Qing Qu

While overparameterization in machine learning models offers great benefits
in terms of optimization and generalization, it also leads to increased
computational requirements as model sizes grow. In this work, we show that by
leveraging the inherent low-dimensional structures of data and compressible
dynamics within the model parameters, we can reap the benefits of
overparameterization without the computational burdens. In practice, we
demonstrate the effectiveness of this approach for deep low-rank matrix
completion as well as fine-tuning language models. Our approach is grounded in
theoretical findings for deep overparameterized low-rank matrix recovery, where
we show that the learning dynamics of each weight matrix are confined to an
invariant low-dimensional subspace. Consequently, we can construct and train
compact, highly compressed factorizations possessing the same benefits as their
overparameterized counterparts. In the context of deep matrix completion, our
technique substantially improves training efficiency while retaining the
advantages of overparameterization. For language model fine-tuning, we propose
a method called "Deep LoRA", which improves the existing low-rank adaptation
(LoRA) technique, leading to reduced overfitting and a simplified
hyperparameter setup, while maintaining comparable efficiency. We validate the
effectiveness of Deep LoRA on natural language tasks, particularly when
fine-tuning with limited data.

ÊëòË¶ÅÔºöÈõñÁÑ∂Ê©üÂô®Â≠∏ÁøíÊ®°Âûã‰∏≠ÁöÑÈÅéÂ∫¶ÂèÉÊï∏ÂåñÂú®ÊúÄ‰Ω≥ÂåñÂíåÊ≥õÂåñÊñπÈù¢Êèê‰æõ‰∫ÜÊ•µÂ§ßÁöÑÂ•ΩËôïÔºå‰ΩÜÈö®ËëóÊ®°ÂûãÂ§ßÂ∞èÁöÑÂ¢ûÂä†ÔºåÂÆÉ‰πüÂ∞éËá¥ÈÅãÁÆóÈúÄÊ±ÇÂ¢ûÂä†„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜÈÄèÈÅéÂà©Áî®Ë≥áÊñôÁöÑÂÖßÂú®‰ΩéÁ∂≠Â∫¶ÁµêÊßãÂíåÊ®°ÂûãÂèÉÊï∏‰∏≠ÁöÑÂèØÂ£ìÁ∏ÆÂãïÊÖãÔºåÊàëÂÄëÂèØ‰ª•Âú®Ê≤íÊúâÈÅãÁÆóË≤†ÊìîÁöÑÊÉÖÊ≥Å‰∏ãÁç≤ÂæóÈÅéÂ∫¶ÂèÉÊï∏ÂåñÁöÑÂÑ™Èªû„ÄÇÂú®ÂØ¶Âãô‰∏äÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜÈÄôÁ®ÆÊñπÊ≥ïÂ∞çÊñºÊ∑±Â∫¶‰ΩéÁß©Áü©Èô£ÂÆåÊàêÂäüËÉΩ‰ª•ÂèäÂæÆË™øË™ûË®ÄÊ®°ÂûãÁöÑÊúâÊïàÊÄß„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÂ•†Âü∫ÊñºÊ∑±Â∫¶ÈÅéÂ∫¶ÂèÉÊï∏Âåñ‰ΩéÁß©Áü©Èô£Âæ©ÂéüÁöÑÁêÜË´ñÁôºÁèæÔºåÊàëÂÄëÂú®ÂÖ∂‰∏≠Â±ïÁ§∫‰∫ÜÊØèÂÄãÊ¨äÈáçÁü©Èô£ÁöÑÂ≠∏ÁøíÂãïÊÖãÈÉΩ‰æ∑ÈôêÊñº‰∏çËÆäÁöÑ‰ΩéÁ∂≠Â∫¶Â≠êÁ©∫Èñì„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëÂèØ‰ª•Âª∫Êßã‰∏¶Ë®ìÁ∑¥Âá∫Á∑äÊπä„ÄÅÈ´òÂ∫¶Â£ìÁ∏ÆÁöÑÂàÜËß£ÔºåÂÆÉÂÄëÂÖ∑ÊúâËàáÈÅéÂ∫¶ÂèÉÊï∏ÂåñÂ∞çÊáâÈ†ÖÁõ∏ÂêåÁöÑÂ•ΩËôï„ÄÇÂú®Ê∑±Â∫¶Áü©Èô£ÂÆåÊàêÂäüËÉΩÁöÑËÉåÊôØ‰∏ãÔºåÊàëÂÄëÁöÑÊäÄË°ìÂ§ßÂπÖÊîπÂñÑ‰∫ÜË®ìÁ∑¥ÊïàÁéáÔºåÂêåÊôÇ‰øùÁïô‰∫ÜÈÅéÂ∫¶ÂèÉÊï∏ÂåñÁöÑÂÑ™Èªû„ÄÇÂ∞çÊñºË™ûË®ÄÊ®°ÂûãÂæÆË™øÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÁ®±ÁÇ∫„ÄåÊ∑±Â∫¶ LoRA„ÄçÁöÑÊñπÊ≥ïÔºåÂÆÉÊîπÈÄ≤‰∫ÜÁèæÊúâÁöÑ‰ΩéÁß©ÈÅ©Êáâ (LoRA) ÊäÄË°ìÔºåÂ∞éËá¥ÈÅéÂ∫¶Êì¨ÂêàÊ∏õÂ∞ëÂíåÁ∞°ÂåñÁöÑË∂ÖÂèÉÊï∏Ë®≠ÂÆöÔºåÂêåÊôÇÁ∂≠ÊåÅÁõ∏Áï∂ÁöÑÊïàÁéá„ÄÇÊàëÂÄëÈ©óË≠â‰∫ÜÊ∑±Â∫¶ LoRA Âú®Ëá™ÁÑ∂Ë™ûË®Ä‰ªªÂãô‰∏≠ÁöÑÊúâÊïàÊÄßÔºåÁâπÂà•ÊòØÂú®‰ΩøÁî®ÊúâÈôêË≥áÊñôÈÄ≤Ë°åÂæÆË™øÊôÇ„ÄÇ

##### **Intention and Face in Dialog**
2406.04109v1 by Adil Soubki, Owen Rambow

The notion of face described by Brown and Levinson (1987) has been studied in
great detail, but a critical aspect of the framework, that which focuses on how
intentions mediate the planning of turns which impose upon face, has received
far less attention. We present an analysis of three computational systems
trained for classifying both intention and politeness, focusing on how the
former influences the latter. In politeness theory, agents attend to the desire
to have their wants appreciated (positive face), and a complementary desire to
act unimpeded and maintain freedom (negative face). Similar to speech acts,
utterances can perform so-called face acts which can either raise or threaten
the positive or negative face of the speaker or hearer. We begin by using an
existing corpus to train a model which classifies face acts, achieving a new
SoTA in the process. We then observe that every face act has an underlying
intention that motivates it and perform additional experiments integrating
dialog act annotations to provide these intentions by proxy. Our analysis finds
that dialog acts improve performance on face act detection for minority classes
and points to a close relationship between aspects of face and intent.

ÊëòË¶ÅÔºöÂ∏ÉÊúóÂíåËé±ÊñáÊ£Æ (1987) ÊâÄÊèèËø∞ÁöÑÈù¢Â≠êÊ¶ÇÂøµÂ∑≤Ëé∑ÂæóËØ¶ÁªÜÁ†îÁ©∂Ôºå‰ΩÜËØ•Ê°ÜÊû∂ÁöÑ‰∏Ä‰∏™ÂÖ≥ÈîÆÊñπÈù¢ÔºåÂç≥ÂÖ≥Ê≥®ÊÑèÂõæÂ¶Ç‰ΩïË∞ÉËß£Âº∫Âä†‰∫éÈù¢ÁöÑËΩÆÊµÅËÆ°ÂàíÔºåÂç¥È≤úÂèóÂÖ≥Ê≥®„ÄÇÊàë‰ª¨ÂØπ‰∏â‰∏™ËÆ°ÁÆóÁ≥ªÁªüËøõË°å‰∫ÜÂàÜÊûêÔºåËøô‰∫õÁ≥ªÁªüÁªèËøáËÆ≠ÁªÉÂèØ‰ª•ÂØπÊÑèÂõæÂíåÁ§ºË≤åËøõË°åÂàÜÁ±ªÔºåÈáçÁÇπÂÖ≥Ê≥®ÂâçËÄÖÂ¶Ç‰ΩïÂΩ±ÂìçÂêéËÄÖ„ÄÇÂú®Á§ºË≤åÁêÜËÆ∫‰∏≠Ôºå‰ª£ÁêÜ‰∫∫‰ºöÂÖ≥Ê≥®Â∏åÊúõÂæóÂà∞Ê¨£ËµèÁöÑÊÑøÊúõÔºàÁßØÊûÅÁöÑÈù¢Â≠êÔºâÔºå‰ª•Âèä‰∏çÂèóÈòªÁ¢çÂíå‰øùÊåÅËá™Áî±ÁöÑ‰∫íË°•ÊÑøÊúõÔºàÊ∂àÊûÅÁöÑÈù¢Â≠êÔºâ„ÄÇ‰∏éË®ÄËØ≠Ë°å‰∏∫Á±ª‰ººÔºåËØùËØ≠ÂèØ‰ª•ÊâßË°åÊâÄË∞ìÁöÑË®ÄËØ≠Ë°å‰∏∫ÔºåËøô‰∫õË°å‰∏∫ÂèØ‰ª•ÊèêÂçáÊàñÂ®ÅËÉÅËØ¥ËØùËÄÖÊàñÂê¨ËÄÖÁöÑÁßØÊûÅÊàñÊ∂àÊûÅÈù¢Â≠ê„ÄÇÊàë‰ª¨È¶ñÂÖà‰ΩøÁî®Áé∞ÊúâËØ≠ÊñôÂ∫ìÊù•ËÆ≠ÁªÉ‰∏Ä‰∏™Ê®°ÂûãÔºåËØ•Ê®°ÂûãÂØπË®ÄËØ≠Ë°å‰∏∫ËøõË°åÂàÜÁ±ªÔºåÂú®Ê≠§ËøáÁ®ã‰∏≠ÂÆûÁé∞‰∫ÜÊñ∞ÁöÑ SoTA„ÄÇÁÑ∂ÂêéÊàë‰ª¨ËßÇÂØüÂà∞ÔºåÊØè‰∏™Ë®ÄËØ≠Ë°å‰∏∫ÈÉΩÊúâ‰∏Ä‰∏™ÊΩúÂú®ÁöÑÊÑèÂõæÊù•ÊøÄÂä±ÂÆÉÔºåÂπ∂ÊâßË°åÈ¢ùÂ§ñÁöÑÂÆûÈ™åÔºåÊï¥ÂêàÂØπËØùË°å‰∏∫Ê≥®Èáä‰ª•ÈÄöËøá‰ª£ÁêÜÊèê‰æõËøô‰∫õÊÑèÂõæ„ÄÇÊàë‰ª¨ÁöÑÂàÜÊûêÂèëÁé∞ÔºåÂØπËØùË°å‰∏∫ÊèêÈ´ò‰∫ÜÂ∞ëÊï∞Á±ªÂà´ÁöÑË®ÄËØ≠Ë°å‰∏∫Ê£ÄÊµãÊÄßËÉΩÔºåÂπ∂ÊåáÂá∫‰∫ÜÈù¢ÈÉ®ÂíåÊÑèÂõæÊñπÈù¢‰πãÈó¥ÁöÑÂØÜÂàáÂÖ≥Á≥ª„ÄÇ

##### **Explainability and Hate Speech: Structured Explanations Make Social Media Moderators Faster**
2406.04106v1 by Agostina Calabrese, Leonardo Neves, Neil Shah, Maarten W. Bos, Bj√∂rn Ross, Mirella Lapata, Francesco Barbieri

Content moderators play a key role in keeping the conversation on social
media healthy. While the high volume of content they need to judge represents a
bottleneck to the moderation pipeline, no studies have explored how models
could support them to make faster decisions. There is, by now, a vast body of
research into detecting hate speech, sometimes explicitly motivated by a desire
to help improve content moderation, but published research using real content
moderators is scarce. In this work we investigate the effect of explanations on
the speed of real-world moderators. Our experiments show that while generic
explanations do not affect their speed and are often ignored, structured
explanations lower moderators' decision making time by 7.4%.

ÊëòË¶ÅÔºöÂÖßÂÆπÂØ©Ê†∏Âì°Âú®Á∂≠ÊåÅÁ§æÁæ§Â™íÈ´îÂ∞çË©±ÁöÑÂÅ•Â∫∑ÊñπÈù¢ÊâÆÊºîËëóÈóúÈçµËßíËâ≤„ÄÇÂÑòÁÆ°‰ªñÂÄëÈúÄË¶ÅÂà§Êñ∑ÁöÑÂÖßÂÆπÊï∏ÈáèÈæêÂ§ßÔºåÂ∞çÂØ©Ê†∏ÊµÅÁ®ã‰æÜË™™ÊòØ‰∏ÄÂ§ßÁì∂È†∏Ôºå‰ΩÜÊ≤íÊúâ‰ªª‰ΩïÁ†îÁ©∂Êé¢Ë®éÊ®°ÂûãÂ¶Ç‰ΩïÂçîÂä©‰ªñÂÄëÂÅöÂá∫Êõ¥Âø´ÈÄüÁöÑÊ±∫ÂÆö„ÄÇÂà∞ÁõÆÂâçÁÇ∫Ê≠¢ÔºåÈáùÂ∞ç‰ªáÊÅ®Ë®ÄË´ñÂÅµÊ∏¨ÁöÑÁ†îÁ©∂Â∑≤Áõ∏Áï∂Âª£Ê≥õÔºåÊúâÊôÇÊòéÁ¢∫Âú∞ÂèóÂà∞ÊîπÂñÑÂÖßÂÆπÂØ©Ê†∏ÁöÑÈ°òÊúõÊâÄÈ©ÖÂãïÔºå‰ΩÜ‰ΩøÁî®ÁúüÂØ¶ÂÖßÂÆπÂØ©Ê†∏Âì°ÁöÑÂ∑≤ÁôºË°®Á†îÁ©∂ÂçªÁõ∏Áï∂Á®ÄÂ∞ë„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊé¢Ë®éËß£ÈáãÂ∞çÁúüÂØ¶‰∏ñÁïåÂØ©Ê†∏Âì°ÈÄüÂ∫¶ÁöÑÂΩ±Èüø„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÈ°ØÁ§∫ÔºåÂÑòÁÆ°‰∏ÄËà¨ÊÄßÁöÑËß£Èáã‰∏çÊúÉÂΩ±Èüø‰ªñÂÄëÁöÑÈÄüÂ∫¶Ôºå‰∏îÁ∂ìÂ∏∏Ë¢´ÂøΩÁï•Ôºå‰ΩÜÁµêÊßãÂåñÁöÑËß£ÈáãÂèØ‰ª•Â∞áÂØ©Ê†∏Âì°ÁöÑÊ±∫Á≠ñÊôÇÈñìÁ∏ÆÁü≠ 7.4%„ÄÇ

##### **Multistep Distillation of Diffusion Models via Moment Matching**
2406.04103v1 by Tim Salimans, Thomas Mensink, Jonathan Heek, Emiel Hoogeboom

We present a new method for making diffusion models faster to sample. The
method distills many-step diffusion models into few-step models by matching
conditional expectations of the clean data given noisy data along the sampling
trajectory. Our approach extends recently proposed one-step methods to the
multi-step case, and provides a new perspective by interpreting these
approaches in terms of moment matching. By using up to 8 sampling steps, we
obtain distilled models that outperform not only their one-step versions but
also their original many-step teacher models, obtaining new state-of-the-art
results on the Imagenet dataset. We also show promising results on a large
text-to-image model where we achieve fast generation of high resolution images
directly in image space, without needing autoencoders or upsamplers.

ÊëòË¶ÅÔºöÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞ÁöÑÊñπÊ≥ï‰æÜÂä†Âø´Êì¥Êï£Ê®°ÂûãÁöÑÂèñÊ®£ÈÄüÂ∫¶„ÄÇË©≤ÊñπÊ≥ïÈÄöÈÅéÂåπÈÖçÊ≤øËëóÂèñÊ®£ËªåË∑°Áµ¶ÂÆöÈõúË®äË≥áÊñôÁöÑ‰πæÊ∑®Ë≥áÊñôÁöÑÊ¢ù‰ª∂ÊúüÊúõÔºåÂ∞áÂ§öÊ≠•È©üÊì¥Êï£Ê®°ÂûãËΩâÂåñÁÇ∫Â∞ëÊ≠•È©üÊ®°Âûã„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÂ∞áÊúÄËøëÊèêÂá∫ÁöÑÂñÆÊ≠•È©üÊñπÊ≥ïÊì¥Â±ïÂà∞Â§öÊ≠•È©üÊÉÖÊ≥ÅÔºå‰∏¶ÈÄöÈÅéÊ†πÊìöÁü©ÂåπÈÖç‰æÜËß£ÈáãÈÄô‰∫õÊñπÊ≥ïÔºåÊèê‰æõ‰∫Ü‰∏ÄÂÄãÊñ∞ÁöÑËßÄÈªû„ÄÇÈÄöÈÅé‰ΩøÁî®Â§öÈÅî 8 ÂÄãÂèñÊ®£Ê≠•È©üÔºåÊàëÂÄëÁç≤Âæó‰∫ÜÂÑ™ÊñºÂÖ∂ÂñÆÊ≠•È©üÁâàÊú¨‰ª•ÂèäÂÖ∂ÂéüÂßãÂ§öÊ≠•È©üÊïôÂ∏´Ê®°ÂûãÁöÑÁ≤æÁÖâÊ®°ÂûãÔºåÂú® Imagenet Ë≥áÊñôÈõÜ‰∏äÁç≤Âæó‰∫ÜÊñ∞ÁöÑÊúÄÂÖàÈÄ≤ÁöÑÁµêÊûú„ÄÇÊàëÂÄëÈÇÑÂ±ïÁ§∫‰∫ÜÂ§ßÂûãÊñáÂ≠óÂà∞ÂΩ±ÂÉèÊ®°Âûã‰∏äÁöÑÊúâÂ∏åÊúõÁöÑÁµêÊûúÔºåÊàëÂÄëÂú®ÂΩ±ÂÉèÁ©∫Èñì‰∏≠Áõ¥Êé•Âø´ÈÄüÁîüÊàêÈ´òËß£ÊûêÂ∫¶ÂΩ±ÂÉèÔºåËÄå‰∏çÈúÄË¶ÅËá™ÂãïÁ∑®Á¢ºÂô®Êàñ‰∏äÊé°Ê®£Âô®„ÄÇ

##### **Enhancing Weather Predictions: Super-Resolution via Deep Diffusion Models**
2406.04099v1 by Jan Martin≈Ø, Petr ≈†im√°nek

This study investigates the application of deep-learning diffusion models for
the super-resolution of weather data, a novel approach aimed at enhancing the
spatial resolution and detail of meteorological variables. Leveraging the
capabilities of diffusion models, specifically the SR3 and ResDiff
architectures, we present a methodology for transforming low-resolution weather
data into high-resolution outputs. Our experiments, conducted using the
WeatherBench dataset, focus on the super-resolution of the two-meter
temperature variable, demonstrating the models' ability to generate detailed
and accurate weather maps. The results indicate that the ResDiff model, further
improved by incorporating physics-based modifications, significantly
outperforms traditional SR3 methods in terms of Mean Squared Error (MSE),
Structural Similarity Index (SSIM), and Peak Signal-to-Noise Ratio (PSNR). This
research highlights the potential of diffusion models in meteorological
applications, offering insights into their effectiveness, challenges, and
prospects for future advancements in weather prediction and climate analysis.

ÊëòË¶ÅÔºöÊú¨Á†îÁ©∂Êé¢Ë®é‰∫ÜÊ∑±Â∫¶Â≠∏ÁøíÊì¥Êï£Ê®°ÂûãÂú®Â§©Ê∞£Ë≥áÊñôË∂ÖËß£ÊûêÂ∫¶‰∏≠ÁöÑÊáâÁî®ÔºåÈÄôÊòØ‰∏ÄÁ®ÆÊó®Âú®Â¢ûÂº∑Ê∞£Ë±°ËÆäÊï∏Á©∫ÈñìËß£ÊûêÂ∫¶ÂíåÁ¥∞ÁØÄÁöÑÊñ∞ÊñπÊ≥ï„ÄÇÂà©Áî®Êì¥Êï£Ê®°ÂûãÁöÑËÉΩÂäõÔºåÁâπÂà•ÊòØ SR3 Âíå ResDiff Êû∂ÊßãÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂ∞á‰ΩéËß£ÊûêÂ∫¶Â§©Ê∞£Ë≥áÊñôËΩâÊèõÁÇ∫È´òËß£ÊûêÂ∫¶Ëº∏Âá∫ÁöÑÊñπÊ≥ï„ÄÇÊàëÂÄëÁöÑÂØ¶È©ó‰ΩøÁî® WeatherBench Ë≥áÊñôÈõÜÈÄ≤Ë°åÔºåÈáçÈªûÊîæÂú®ÂÖ©ÂÖ¨Â∞∫Ê∫´Â∫¶ËÆäÊï∏ÁöÑË∂ÖËß£ÊûêÂ∫¶ÔºåÂ±ïÁ§∫‰∫ÜÊ®°ÂûãÁîüÊàêË©≥Á¥∞‰∏îÊ∫ñÁ¢∫Â§©Ê∞£ÂúñÁöÑËÉΩÂäõ„ÄÇÁµêÊûúË°®ÊòéÔºåResDiff Ê®°ÂûãÈÄ≤‰∏ÄÊ≠•ÁµêÂêà‰∫ÜÂü∫ÊñºÁâ©ÁêÜÁöÑ‰øÆÊîπÔºåÂú®ÂùáÊñπË™§Â∑Æ (MSE)„ÄÅÁµêÊßãÁõ∏‰ººÊÄßÊåáÊ®ô (SSIM) ÂíåÂ≥∞ÂÄº‰ø°Âô™ÊØî (PSNR) ÊñπÈù¢È°ØËëóÂÑ™ÊñºÂÇ≥Áµ±ÁöÑ SR3 ÊñπÊ≥ï„ÄÇÈÄôÈ†ÖÁ†îÁ©∂Á™ÅÂá∫‰∫ÜÊì¥Êï£Ê®°ÂûãÂú®Ê∞£Ë±°ÊáâÁî®‰∏≠ÁöÑÊΩõÂäõÔºåÊèê‰æõ‰∫ÜÂ∞çÂÖ∂ÊúâÊïàÊÄß„ÄÅÊåëÊà∞ÂíåÊú™‰æÜÂ§©Ê∞£È†êÊ∏¨ÂíåÊ∞£ÂÄôÂàÜÊûêÈÄ≤Â±ïÂâçÊôØÁöÑË¶ãËß£„ÄÇ

##### **Scaling and evaluating sparse autoencoders**
2406.04093v1 by Leo Gao, Tom Dupr√© la Tour, Henk Tillman, Gabriel Goh, Rajan Troll, Alec Radford, Ilya Sutskever, Jan Leike, Jeffrey Wu

Sparse autoencoders provide a promising unsupervised approach for extracting
interpretable features from a language model by reconstructing activations from
a sparse bottleneck layer. Since language models learn many concepts,
autoencoders need to be very large to recover all relevant features. However,
studying the properties of autoencoder scaling is difficult due to the need to
balance reconstruction and sparsity objectives and the presence of dead
latents. We propose using k-sparse autoencoders [Makhzani and Frey, 2013] to
directly control sparsity, simplifying tuning and improving the
reconstruction-sparsity frontier. Additionally, we find modifications that
result in few dead latents, even at the largest scales we tried. Using these
techniques, we find clean scaling laws with respect to autoencoder size and
sparsity. We also introduce several new metrics for evaluating feature quality
based on the recovery of hypothesized features, the explainability of
activation patterns, and the sparsity of downstream effects. These metrics all
generally improve with autoencoder size. To demonstrate the scalability of our
approach, we train a 16 million latent autoencoder on GPT-4 activations for 40
billion tokens. We release training code and autoencoders for open-source
models, as well as a visualizer.

ÊëòË¶ÅÔºöÁ®ÄÁñèËá™ÂãïÁ∑®Á¢ºÂô®Êèê‰æõ‰∫Ü‰∏ÄÁ®ÆÊúâÂâçÈÄîÁöÑÈùûÁõ£Áù£ÂºèÊñπÊ≥ïÔºåÂèØ‰ª•ÈÄöÈÅéÈáçÂª∫Á®ÄÁñèÁì∂È†∏Â±§ÁöÑÊøÄÊ¥ª‰æÜÂæûË™ûË®ÄÊ®°Âûã‰∏≠ÊèêÂèñÂèØËß£ÈáãÁâπÂæµ„ÄÇÁî±ÊñºË™ûË®ÄÊ®°ÂûãÂ≠∏Áøí‰∫ÜÂæàÂ§öÊ¶ÇÂøµÔºåÂõ†Ê≠§Ëá™ÂãïÁ∑®Á¢ºÂô®ÈúÄË¶ÅÈùûÂ∏∏Â§ßÊâçËÉΩÊÅ¢Âæ©ÊâÄÊúâÁõ∏ÈóúÁâπÂæµ„ÄÇÁÑ∂ËÄåÔºåÁî±ÊñºÈúÄË¶ÅÂπ≥Ë°°ÈáçÂª∫ÂíåÁ®ÄÁñèÊÄßÁõÆÊ®ô‰ª•ÂèäÂ≠òÂú®Ê≠ªÊΩõÂú®ËÆäÈáèÔºåÂõ†Ê≠§Á†îÁ©∂Ëá™ÂãïÁ∑®Á¢ºÂô®Êì¥Â±ïÁöÑÂ±¨ÊÄßÂæàÂõ∞Èõ£„ÄÇÊàëÂÄëÂª∫Ë≠∞‰ΩøÁî® k Á®ÄÁñèËá™ÂãïÁ∑®Á¢ºÂô® [Makhzani Âíå FreyÔºå2013] ‰æÜÁõ¥Êé•ÊéßÂà∂Á®ÄÁñèÊÄßÔºåÁ∞°ÂåñË™øÊï¥‰∏¶ÊîπÂñÑÈáçÂª∫Á®ÄÁñèÊÄßÂâçÊ≤ø„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁôºÁèæÂç≥‰ΩøÂú®ÊàëÂÄëÂòóË©¶ÁöÑÊúÄÂ§ßË¶èÊ®°‰∏ãÔºå‰øÆÊîπ‰πüÊúÉÂ∞éËá¥ÂæàÂ∞ëÁöÑÊ≠ªÊΩõÂú®ËÆäÈáè„ÄÇ‰ΩøÁî®ÈÄô‰∫õÊäÄË°ìÔºåÊàëÂÄëÁôºÁèæ‰∫ÜÈóúÊñºËá™ÂãïÁ∑®Á¢ºÂô®Â§ßÂ∞èÂíåÁ®ÄÁñèÊÄßÁöÑÊ∏ÖÊô∞Êì¥Â±ïÂÆöÂæã„ÄÇÊàëÂÄëÈÇÑÂºïÂÖ•‰∫ÜÂπæÂÄãÊñ∞ÁöÑÊåáÊ®ôÔºåÁî®ÊñºÂü∫ÊñºÂÅáË®≠ÁâπÂæµÁöÑÊÅ¢Âæ©„ÄÅÊøÄÊ¥ªÊ®°ÂºèÁöÑÂèØËß£ÈáãÊÄßÂíå‰∏ãÊ∏∏ÂΩ±ÈüøÁöÑÁ®ÄÁñèÊÄß‰æÜË©ï‰º∞ÁâπÂæµË≥™Èáè„ÄÇÈÄô‰∫õÊåáÊ®ôÈÄöÂ∏∏Èö®ËëóËá™ÂãïÁ∑®Á¢ºÂô®ÁöÑÂ§ßÂ∞èËÄåÊèêÈ´ò„ÄÇÁÇ∫‰∫ÜË≠âÊòéÊàëÂÄëÊñπÊ≥ïÁöÑÂèØÊì¥Â±ïÊÄßÔºåÊàëÂÄëÂú® GPT-4 ÊøÄÊ¥ª‰∏äË®ìÁ∑¥‰∫Ü‰∏ÄÂÄã 1600 Ëê¨ÊΩõÂú®Ëá™ÂãïÁ∑®Á¢ºÂô®ÔºåÁî®Êñº 400 ÂÑÑÂÄãÁ¨¶Ëôü„ÄÇÊàëÂÄëÁôºÂ∏É‰∫ÜÁî®ÊñºÈñãÊ∫êÊ®°ÂûãÁöÑË®ìÁ∑¥‰ª£Á¢ºÂíåËá™ÂãïÁ∑®Á¢ºÂô®Ôºå‰ª•Âèä‰∏ÄÂÄãÂèØË¶ñÂåñÂô®„ÄÇ

##### **On Limitation of Transformer for Learning HMMs**
2406.04089v1 by Jiachen Hu, Qinghua Liu, Chi Jin

Despite the remarkable success of Transformer-based architectures in various
sequential modeling tasks, such as natural language processing, computer
vision, and robotics, their ability to learn basic sequential models, like
Hidden Markov Models (HMMs), is still unclear. This paper investigates the
performance of Transformers in learning HMMs and their variants through
extensive experimentation and compares them to Recurrent Neural Networks
(RNNs). We show that Transformers consistently underperform RNNs in both
training speed and testing accuracy across all tested HMM models. There are
even challenging HMM instances where Transformers struggle to learn, while RNNs
can successfully do so. Our experiments further reveal the relation between the
depth of Transformers and the longest sequence length it can effectively learn,
based on the types and the complexity of HMMs. To address the limitation of
transformers in modeling HMMs, we demonstrate that a variant of the
Chain-of-Thought (CoT), called $\textit{block CoT}$ in the training phase, can
help transformers to reduce the evaluation error and to learn longer sequences
at a cost of increasing the training time. Finally, we complement our empirical
findings by theoretical results proving the expressiveness of transformers in
approximating HMMs with logarithmic depth.

ÊëòË¶ÅÔºöÂÑòÁÆ° Transformer Âü∫Á§éÊû∂ÊßãÂú®ÂêÑÁ®ÆÂ∫èÂàóÂª∫Ê®°‰ªªÂãô‰∏≠Áç≤ÂæóÈ°ØËëóÁöÑÊàêÂäüÔºå‰æãÂ¶ÇËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ„ÄÅÈõªËÖ¶Ë¶ñË¶∫ÂíåÊ©üÂô®‰∫∫ÊäÄË°ìÔºå‰ΩÜÂÆÉÂÄëÂ≠∏ÁøíÂü∫Êú¨Â∫èÂàóÊ®°ÂûãÔºà‰æãÂ¶ÇÈö±ËóèÈ¶¨ÂèØÂ§´Ê®°Âûã (HMM)ÔºâÁöÑËÉΩÂäõ‰ªç‰∏çÊ∏ÖÊ•ö„ÄÇÊú¨ÊñáÈÄèÈÅéÂª£Ê≥õÁöÑÂØ¶È©óË™øÊü• Transformer Âú®Â≠∏Áøí HMM ÂèäÂÖ∂ËÆäÈ´îÊñπÈù¢ÁöÑÊïàËÉΩÔºå‰∏¶Â∞áÂÆÉÂÄëËàáÈÅûËø¥Á•ûÁ∂ìÁ∂≤Ë∑Ø (RNN) ÈÄ≤Ë°åÊØîËºÉ„ÄÇÊàëÂÄëË°®ÊòéÔºåÂú®ÊâÄÊúâÊ∏¨Ë©¶ÁöÑ HMM Ê®°Âûã‰∏≠ÔºåTransformer Âú®Ë®ìÁ∑¥ÈÄüÂ∫¶ÂíåÊ∏¨Ë©¶Ê∫ñÁ¢∫Â∫¶ÊñπÈù¢ÈÉΩÊåÅÁ∫åË°®Áèæ‰∏çÂ¶Ç RNN„ÄÇÁîöËá≥Êúâ‰∏Ä‰∫õÂÖ∑ÊúâÊåëÊà∞ÊÄßÁöÑ HMM ÂØ¶‰æãËÆì Transformer Èõ£‰ª•Â≠∏ÁøíÔºåËÄå RNN ÂèØ‰ª•ÊàêÂäüÂÅöÂà∞„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÈÄ≤‰∏ÄÊ≠•Êè≠Á§∫‰∫Ü Transformer ÁöÑÊ∑±Â∫¶ËàáÂÆÉÂèØ‰ª•ÊúâÊïàÂ≠∏ÁøíÁöÑÊúÄÈï∑Â∫èÂàóÈï∑Â∫¶‰πãÈñìÁöÑÈóú‰øÇÔºåÈÄôÂèñÊ±∫Êñº HMM ÁöÑÈ°ûÂûãÂíåË§áÈõúÊÄß„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ Transformer Âú®Âª∫Ê®° HMM ÊñπÈù¢ÁöÑÈôêÂà∂ÔºåÊàëÂÄëË≠âÊòé‰∫ÜÂú®Ë®ìÁ∑¥ÈöéÊÆµÁ®±ÁÇ∫ $\textit{ÂçÄÂ°ä CoT}$ ÁöÑÊÄùÁ∂≠Èèà (CoT) ËÆäÈ´îÔºåÂèØ‰ª•Âπ´Âä© Transformer Ê∏õÂ∞ëË©ï‰º∞Ë™§Â∑Æ‰∏¶Âú®Â¢ûÂä†Ë®ìÁ∑¥ÊôÇÈñìÁöÑ‰ª£ÂÉπ‰∏ãÂ≠∏ÁøíÊõ¥Èï∑ÁöÑÂ∫èÂàó„ÄÇÊúÄÂæåÔºåÊàëÂÄëÈÄèÈÅéË≠âÊòé Transformer Âú®‰ΩøÁî®Â∞çÊï∏Ê∑±Â∫¶Ëøë‰ºº HMM ÊôÇÁöÑË°®ÁèæÂäõÔºå‰ª•ÁêÜË´ñÁµêÊûúË£úÂÖÖÊàëÂÄëÁöÑÁ∂ìÈ©óÁôºÁèæ„ÄÇ

##### **Batch-in-Batch: a new adversarial training framework for initial perturbation and sample selection**
2406.04070v1 by Yinting Wu, Pai Peng, Bo Cai, Le Li, .

Adversarial training methods commonly generate independent initial
perturbation for adversarial samples from a simple uniform distribution, and
obtain the training batch for the classifier without selection. In this work,
we propose a simple yet effective training framework called Batch-in-Batch (BB)
to enhance models robustness. It involves specifically a joint construction of
initial values that could simultaneously generates $m$ sets of perturbations
from the original batch set to provide more diversity for adversarial samples;
and also includes various sample selection strategies that enable the trained
models to have smoother losses and avoid overconfident outputs. Through
extensive experiments on three benchmark datasets (CIFAR-10, SVHN, CIFAR-100)
with two networks (PreActResNet18 and WideResNet28-10) that are used in both
the single-step (Noise-Fast Gradient Sign Method, N-FGSM) and multi-step
(Projected Gradient Descent, PGD-10) adversarial training, we show that models
trained within the BB framework consistently have higher adversarial accuracy
across various adversarial settings, notably achieving over a 13% improvement
on the SVHN dataset with an attack radius of 8/255 compared to the N-FGSM
baseline model. Furthermore, experimental analysis of the efficiency of both
the proposed initial perturbation method and sample selection strategies
validates our insights. Finally, we show that our framework is cost-effective
in terms of computational resources, even with a relatively large value of $m$.

ÊëòË¶ÅÔºöÂ∞çÊäóË®ìÁ∑¥ÊñπÊ≥ïÈÄöÂ∏∏ÊúÉÂæûÁ∞°ÂñÆÁöÑÂùáÂãªÂàÜ‰Ωà‰∏≠ÁÇ∫Â∞çÊäóÊ®£Êú¨ÁîüÊàêÁç®Á´ãÁöÑÂàùÂßãÊìæÂãïÔºå‰∏¶Âú®Ê≤íÊúâÈÅ∏ÊìáÁöÑÊÉÖÊ≥Å‰∏ãÁÇ∫ÂàÜÈ°ûÂô®ÂèñÂæóË®ìÁ∑¥ÊâπÊ¨°„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÁ∞°ÂñÆ‰ΩÜÊúâÊïàÁöÑË®ìÁ∑¥Ê°ÜÊû∂ÔºåÁ®±ÁÇ∫ÊâπÊ¨°‰∏≠ÁöÑÊâπÊ¨° (BB)Ôºå‰ª•Â¢ûÂº∑Ê®°ÂûãÁöÑÈ≠ØÊ£íÊÄß„ÄÇÂÆÉÁâπÂà•Ê∂âÂèäÂàùÂßãÂÄºÁöÑËÅØÂêàÊßãÈÄ†ÔºåÂèØ‰ª•ÂêåÊôÇÂæûÂéüÂßãÊâπÊ¨°ÈõÜ‰∏≠ÁîüÊàê $m$ ÁµÑÊìæÂãïÔºå‰ª•Êèê‰æõÊõ¥Â§öÊ®£ÂåñÁöÑÂ∞çÊäóÊ®£Êú¨ÔºõÈÇÑÂåÖÊã¨ÂêÑÁ®ÆÊ®£Êú¨ÈÅ∏ÊìáÁ≠ñÁï•Ôºå‰ΩøË®ìÁ∑¥ÂæåÁöÑÊ®°ÂûãÂÖ∑ÊúâÊõ¥Âπ≥ÊªëÁöÑÊêçÂ§±‰∏¶ÈÅøÂÖçÈÅéÂ∫¶Ëá™‰ø°ÁöÑËº∏Âá∫„ÄÇÈÄöÈÅéÂú®‰∏âÂÄãÂü∫Ê∫ñÊï∏ÊìöÈõÜ (CIFAR-10„ÄÅSVHN„ÄÅCIFAR-100) ‰∏äÈÄ≤Ë°åÂª£Ê≥õÁöÑÂØ¶È©óÔºå‰ΩøÁî®ÂÖ©ÂÄãÁ∂≤Ë∑Ø (PreActResNet18 Âíå WideResNet28-10)ÔºåÈÄô‰∫õÁ∂≤Ë∑ØÁî®ÊñºÂñÆÊ≠• (Noise-Fast Gradient Sign Method, N-FGSM) ÂíåÂ§öÊ≠• (Projected Gradient Descent, PGD-10) Â∞çÊäóË®ìÁ∑¥ÔºåÊàëÂÄëË°®ÊòéÂú® BB Ê°ÜÊû∂ÂÖßË®ìÁ∑¥ÁöÑÊ®°ÂûãÂú®ÂêÑÁ®ÆÂ∞çÊäóË®≠ÁΩÆ‰∏≠ÂßãÁµÇÂÖ∑ÊúâÊõ¥È´òÁöÑÂ∞çÊäóÊ∫ñÁ¢∫Â∫¶ÔºåÁâπÂà•ÊòØÂú®ÊîªÊìäÂçäÂæëÁÇ∫ 8/255 ÁöÑ SVHN Êï∏ÊìöÈõÜ‰∏äÂØ¶Áèæ‰∫ÜË∂ÖÈÅé 13% ÁöÑÊîπÈÄ≤ÔºåËàá N-FGSM Âü∫Ê∫ñÊ®°ÂûãÁõ∏ÊØî„ÄÇÊ≠§Â§ñÔºåÂ∞çÊâÄÊèêÂá∫ÁöÑÂàùÂßãÊìæÂãïÊñπÊ≥ïÂíåÊ®£Êú¨ÈÅ∏ÊìáÁ≠ñÁï•ÁöÑÊïàÁéáÁöÑÂØ¶È©óÂàÜÊûêÈ©óË≠â‰∫ÜÊàëÂÄëÁöÑË¶ãËß£„ÄÇÊúÄÂæåÔºåÊàëÂÄëË°®ÊòéÊàëÂÄëÁöÑÊ°ÜÊû∂Âú®Ë®àÁÆóË≥áÊ∫êÊñπÈù¢ÂÖ∑ÊúâÊàêÊú¨ÊïàÁõäÔºåÂç≥‰Ωø $m$ ÁöÑÂÄºÁõ∏Â∞çËºÉÂ§ß„ÄÇ

##### **Ask LLMs Directly, "What shapes your bias?": Measuring Social Bias in Large Language Models**
2406.04064v1 by Jisu Shin, Hoyun Song, Huije Lee, Soyeong Jeong, Jong C. Park

Social bias is shaped by the accumulation of social perceptions towards
targets across various demographic identities. To fully understand such social
bias in large language models (LLMs), it is essential to consider the composite
of social perceptions from diverse perspectives among identities. Previous
studies have either evaluated biases in LLMs by indirectly assessing the
presence of sentiments towards demographic identities in the generated text or
measuring the degree of alignment with given stereotypes. These methods have
limitations in directly quantifying social biases at the level of distinct
perspectives among identities. In this paper, we aim to investigate how social
perceptions from various viewpoints contribute to the development of social
bias in LLMs. To this end, we propose a novel strategy to intuitively quantify
these social perceptions and suggest metrics that can evaluate the social
biases within LLMs by aggregating diverse social perceptions. The experimental
results show the quantitative demonstration of the social attitude in LLMs by
examining social perception. The analysis we conducted shows that our proposed
metrics capture the multi-dimensional aspects of social bias, enabling a
fine-grained and comprehensive investigation of bias in LLMs.

ÊëòË¶ÅÔºöÁ§æÊúÉÂÅèË¶ãÊòØÁî±Á§æÊúÉÂ∞çÂêÑÁ®Æ‰∫∫Âè£ÁâπÂæµË∫´ÂàÜÁõÆÊ®ôÁöÑÁ§æÊúÉË™çÁü•Á¥ØÁ©çÊâÄÂΩ¢Â°ë„ÄÇË¶ÅÂÆåÂÖ®‰∫ÜËß£Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰∏≠ÁöÑÊ≠§È°ûÁ§æÊúÉÂÅèË¶ãÔºåÂøÖÈ†àËÄÉÈáèË∫´ÂàÜ‰πãÈñì‰æÜËá™‰∏çÂêåËßÄÈªûÁöÑÁ§æÊúÉË™çÁü•ÁµÑÂêà„ÄÇÂÖàÂâçÁöÑÁ†îÁ©∂Â∑≤ÈÄèÈÅéÈñìÊé•Ë©ï‰º∞Áî¢ÁîüÊñáÂ≠ó‰∏≠Â∞ç‰∫∫Âè£ÁâπÂæµË∫´ÂàÜÁöÑËßÄÈªûÂ≠òÂú®ÔºåÊàñË°°ÈáèËàáÊó¢ÂÆöÂàªÊùøÂç∞Ë±°ÁöÑ‰∏ÄËá¥Á®ãÂ∫¶Ôºå‰æÜË©ï‰º∞ LLM ‰∏≠ÁöÑÂÅèË¶ã„ÄÇÈÄô‰∫õÊñπÊ≥ïÂú®Áõ¥Êé•ÈáèÂåñË∫´ÂàÜ‰πãÈñì‰∏çÂêåËßÄÈªûÂ±§Á¥öÁöÑÁ§æÊúÉÂÅèË¶ãÊñπÈù¢ÊúâÂÖ∂ÈôêÂà∂„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊó®Âú®Êé¢Ë®é‰æÜËá™‰∏çÂêåËßÄÈªûÁöÑÁ§æÊúÉË™çÁü•Â¶Ç‰Ωï‰øÉÊàê LLM ‰∏≠Á§æÊúÉÂÅèË¶ãÁöÑÁôºÂ±ï„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÁ≠ñÁï•‰æÜÁõ¥ËßÄÈáèÂåñÈÄô‰∫õÁ§æÊúÉË™çÁü•Ôºå‰∏¶ÊèêÂá∫ÂèØÈÄèÈÅéÂΩôÁ∏Ω‰∏çÂêåÁöÑÁ§æÊúÉË™çÁü•‰æÜË©ï‰º∞ LLM ‰∏≠Á§æÊúÉÂÅèË¶ãÁöÑÊåáÊ®ô„ÄÇÂØ¶È©óÁµêÊûúÈÄèÈÅéÊ™¢Ë¶ñÁ§æÊúÉË™çÁü•ÔºåÈ°ØÁ§∫ LLM ‰∏≠Á§æÊúÉÊÖãÂ∫¶ÁöÑÈáèÂåñË≠âÊòé„ÄÇÊàëÂÄëÈÄ≤Ë°åÁöÑÂàÜÊûêÈ°ØÁ§∫ÔºåÊàëÂÄëÊèêÂá∫ÁöÑÊåáÊ®ôÊçïÊçâ‰∫ÜÁ§æÊúÉÂÅèË¶ãÁöÑÂ§öÈù¢ÂêëÈù¢ÂêëÔºåÈÄ≤ËÄåËÉΩÂ∞ç LLM ‰∏≠ÁöÑÂÅèË¶ãÈÄ≤Ë°åÁ¥∞Á∑ª‰∏îÂÖ®Èù¢ÁöÑÊé¢Ë®é„ÄÇ

##### **Leveraging SPD Matrices on Riemannian Manifolds in Quantum Classical Hybrid Models for Structural Health Monitoring**
2406.04055v1 by Azadeh Alavi, Sanduni Jayasinghe

Realtime finite element modeling of bridges assists modern structural health
monitoring systems by providing comprehensive insights into structural
integrity. This capability is essential for ensuring the safe operation of
bridges and preventing sudden catastrophic failures. However, FEM computational
cost and the need for realtime analysis pose significant challenges.
Additionally, the input data is a 7 dimensional vector, while the output is a
1017 dimensional vector, making accurate and efficient analysis particularly
difficult. In this study, we propose a novel hybrid quantum classical
Multilayer Perceptron pipeline leveraging Symmetric Positive Definite matrices
and Riemannian manifolds for effective data representation. To maintain the
integrity of the qubit structure, we utilize SPD matrices, ensuring data
representation is well aligned with the quantum computational framework.
Additionally, the method leverages polynomial feature expansion to capture
nonlinear relationships within the data. The proposed pipeline combines
classical fully connected neural network layers with quantum circuit layers to
enhance model performance and efficiency. Our experiments focused on various
configurations of such hybrid models to identify the optimal structure for
accurate and efficient realtime analysis. The best performing model achieved a
Mean Squared Error of 0.00031, significantly outperforming traditional methods.

ÊëòË¶ÅÔºöÊ©ãÊ®ëÁöÑÂç≥ÊôÇÊúâÈôêÂÖÉÁ¥†Âª∫Ê®°ÈÄèÈÅéÊèê‰æõÁµêÊßãÂÆåÊï¥ÊÄßÁöÑÂÖ®Èù¢Ë¶ãËß£ÔºåÂçîÂä©Áèæ‰ª£ÁµêÊßãÂÅ•Â∫∑Áõ£ÊéßÁ≥ªÁµ±„ÄÇÊ≠§ÂäüËÉΩÂ∞çÊñºÁ¢∫‰øùÊ©ãÊ®ëÂÆâÂÖ®Êìç‰ΩúÂíåÈò≤Ê≠¢Á™ÅÁÑ∂ÁÅΩÈõ£ÊÄßÊïÖÈöúËá≥ÈóúÈáçË¶Å„ÄÇÁÑ∂ËÄåÔºåÊúâÈôêÂÖÉÁ¥†ÊñπÊ≥ïÁöÑÈÅãÁÆóÊàêÊú¨ÂíåÂç≥ÊôÇÂàÜÊûêÁöÑÈúÄÊ±ÇÂ∏∂‰æÜ‰∫ÜÈáçÂ§ßÊåëÊà∞„ÄÇÊ≠§Â§ñÔºåËº∏ÂÖ•Ë≥áÊñôÊòØ 7 Á∂≠ÂêëÈáèÔºåËÄåËº∏Âá∫ÊòØ 1017 Á∂≠ÂêëÈáèÔºåÈÄô‰ΩøÂæóÊ∫ñÁ¢∫ËÄåÊúâÊïàÁöÑÂàÜÊûêÁâπÂà•Âõ∞Èõ£„ÄÇÂú®Êú¨Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÊ∑∑ÂêàÈáèÂ≠êÁ∂ìÂÖ∏Â§öÂ±§ÊÑüÁü•Âô®ÁÆ°ÈÅìÔºåÂà©Áî®Â∞çÁ®±Ê≠£ÂÆöÁü©Èô£ÂíåÈªéÊõºÊµÅÂΩ¢ÈÄ≤Ë°åÊúâÊïàÁöÑË≥áÊñôË°®Á§∫„ÄÇÁÇ∫‰∫ÜÁ∂≠Ë≠∑ÈáèÂ≠ê‰ΩçÂÖÉÁµêÊßãÁöÑÂÆåÊï¥ÊÄßÔºåÊàëÂÄëÂà©Áî®Â∞çÁ®±Ê≠£ÂÆöÁü©Èô£ÔºåÁ¢∫‰øùË≥áÊñôË°®Á§∫ËàáÈáèÂ≠êÈÅãÁÆóÊ°ÜÊû∂ÂÆåÂÖ®‰∏ÄËá¥„ÄÇÊ≠§Â§ñÔºåÊ≠§ÊñπÊ≥ïÂà©Áî®Â§öÈ†ÖÂºèÁâπÂæµÂ±ïÈñã‰æÜÊì∑ÂèñË≥áÊñô‰∏≠ÁöÑÈùûÁ∑öÊÄßÈóú‰øÇ„ÄÇÊâÄÊèêÂá∫ÁöÑÁÆ°ÈÅìÁµêÂêà‰∫ÜÁ∂ìÂÖ∏ÂÖ®ÈÄ£Êé•Á•ûÁ∂ìÁ∂≤Ë∑ØÂ±§ÂíåÈáèÂ≠êÈõªË∑ØÂ±§Ôºå‰ª•Â¢ûÂº∑Ê®°ÂûãÊïàËÉΩÂíåÊïàÁéá„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÂ∞àÊ≥®ÊñºÊ≠§È°ûÊ∑∑ÂêàÊ®°ÂûãÁöÑÂêÑÁ®ÆÈÖçÁΩÆÔºå‰ª•Ë≠òÂà•Ê∫ñÁ¢∫‰∏îÊúâÊïàÁöÑÂç≥ÊôÇÂàÜÊûêÁöÑÊúÄ‰Ω≥ÁµêÊßã„ÄÇÊïàËÉΩÊúÄ‰Ω≥ÁöÑÊ®°ÂûãÈÅîÂà∞‰∫Ü 0.00031 ÁöÑÂπ≥ÂùáÂπ≥ÊñπË™§Â∑ÆÔºåÈ°ØËëóÂÑ™ÊñºÂÇ≥Áµ±ÊñπÊ≥ï„ÄÇ

##### **Multivector Neurons: Better and Faster O(n)-Equivariant Clifford Graph Neural Networks**
2406.04052v1 by Cong Liu, David Ruhe, Patrick Forr√©

Most current deep learning models equivariant to $O(n)$ or $SO(n)$ either
consider mostly scalar information such as distances and angles or have a very
high computational complexity. In this work, we test a few novel message
passing graph neural networks (GNNs) based on Clifford multivectors, structured
similarly to other prevalent equivariant models in geometric deep learning. Our
approach leverages efficient invariant scalar features while simultaneously
performing expressive learning on multivector representations, particularly
through the use of the equivariant geometric product operator. By integrating
these elements, our methods outperform established efficient baseline models on
an N-Body simulation task and protein denoising task while maintaining a high
efficiency. In particular, we push the state-of-the-art error on the N-body
dataset to 0.0035 (averaged over 3 runs); an 8% improvement over recent
methods. Our implementation is available on Github.

ÊëòË¶ÅÔºöÁõÆÂâçÂ§ßÂ§öÊï∏Ê∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÁ≠âËÆäÊñº $O(n)$ Êàñ $SO(n)$Ôºå
‰∏ªË¶ÅËÄÉÊÖÆË∑ùÈõ¢ÂíåËßíÂ∫¶Á≠âÊ®ôÈáèË≥áË®äÊàñÂÖ∑ÊúâÈùûÂ∏∏È´òÁöÑË®àÁÆóË§áÈõúÂ∫¶„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊ∏¨Ë©¶‰∫ÜÂπæÂÄãÊñ∞Á©éÁöÑË®äÊÅØÂÇ≥ÈÅûÂúñÁ•ûÁ∂ìÁ∂≤Ë∑Ø (GNN)ÔºåÂÖ∂Âü∫ÊñºÂÖãÂà©Á¶èÂæ∑Â§öÂÖÉÂêëÈáèÔºåÁµêÊßãÈ°û‰ººÊñºÂπæ‰ΩïÊ∑±Â∫¶Â≠∏Áøí‰∏≠ÂÖ∂‰ªñÊµÅË°åÁöÑÁ≠âËÆäÊ®°Âûã„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÂà©Áî®‰∫ÜÊúâÊïàÁöÑÊ®ôÈáè‰∏çËÆäÁâπÂæµÔºåÂêåÊôÇÂ∞çÂ§öÂÖÉÂêëÈáèË°®Á§∫ÈÄ≤Ë°åË°®ÈÅîÊÄßÂ≠∏ÁøíÔºåÁâπÂà•ÊòØÈÄèÈÅé‰ΩøÁî®Á≠âËÆäÂπæ‰Ωï‰πòÁ©çÁÆóÂ≠ê„ÄÇÈÄèÈÅéÊï¥ÂêàÈÄô‰∫õÂÖÉÁ¥†ÔºåÊàëÂÄëÁöÑÊ®°ÂûãÂú® N È´îÊ®°Êì¨‰ªªÂãôÂíåËõãÁôΩË≥™ÂéªÂô™‰ªªÂãô‰∏äÂÑ™ÊñºÊó¢ÂÆöÁöÑÊúâÊïàÂü∫Ê∫ñÊ®°ÂûãÔºåÂêåÊôÇ‰øùÊåÅÈ´òÊïàÁéá„ÄÇÁâπÂà•ÊòØÔºåÊàëÂÄëÂ∞á N È´îË≥áÊñôÈõÜ‰∏äÁöÑÊúÄÊñ∞ÈåØË™§Êé®Ëá≥ 0.0035ÔºàÂú® 3 Ê¨°Âü∑Ë°å‰∏≠ÂèñÂπ≥ÂùáÂÄºÔºâÔºõÊØîÊúÄËøëÁöÑÊñπÊ≥ïÈÄ≤Ê≠•‰∫Ü 8%„ÄÇÊàëÂÄëÁöÑÂØ¶‰ΩúÂèØÂú® Github ‰∏äÂèñÂæó„ÄÇ

##### **ActionReasoningBench: Reasoning about Actions with and without Ramification Constraints**
2406.04046v1 by Divij Handa, Pavel Dolin, Shrinidhi Kumbhar, Chitta Baral, Tran Cao Son

Reasoning about actions and change (RAC) has historically driven the
development of many early AI challenges, such as the frame problem, and many AI
disciplines, including non-monotonic and commonsense reasoning. The role of RAC
remains important even now, particularly for tasks involving dynamic
environments, interactive scenarios, and commonsense reasoning. Despite the
progress of Large Language Models (LLMs) in various AI domains, their
performance on RAC is underexplored. To address this gap, we introduce a new
benchmark, ActionReasoningBench, encompassing 13 domains and rigorously
evaluating LLMs across eight different areas of RAC. These include - Object
Tracking, Fluent Tracking, State Tracking, Action Executability, Effects of
Actions, Numerical RAC, Hallucination Detection, and Composite Questions.
Furthermore, we also investigate the indirect effect of actions due to
ramification constraints for every domain. Finally, we evaluate our benchmark
using open-sourced and commercial state-of-the-art LLMs, including GPT-4o,
Gemini-1.0-Pro, Llama2-7b-chat, Llama2-13b-chat, Llama3-8b-instruct,
Gemma-2b-instruct, and Gemma-7b-instruct. Our findings indicate that these
models face significant challenges across all categories included in our
benchmark.

ÊëòË¶ÅÔºöÊé®ÁêÜÂä®‰ΩúÂíåÂèòÂåñ (RAC) Âú®ÂéÜÂè≤‰∏äÊé®Âä®‰∫ÜËÆ∏Â§öÊó©Êúü‰∫∫Â∑•Êô∫ËÉΩÊåëÊàòÁöÑÂèëÂ±ïÔºå‰æãÂ¶ÇÊ°ÜÊû∂ÈóÆÈ¢òÔºå‰ª•ÂèäËÆ∏Â§ö‰∫∫Â∑•Êô∫ËÉΩÂ≠¶ÁßëÔºåÂåÖÊã¨ÈùûÂçïË∞ÉÊé®ÁêÜÂíåÂ∏∏ËØÜÊé®ÁêÜ„ÄÇRAC ÁöÑ‰ΩúÁî®Âç≥‰ΩøÁé∞Âú®‰ªçÁÑ∂ÂæàÈáçË¶ÅÔºåÁâπÂà´ÊòØÂØπ‰∫éÊ∂âÂèäÂä®ÊÄÅÁéØÂ¢É„ÄÅ‰∫§‰∫íÂú∫ÊôØÂíåÂ∏∏ËØÜÊé®ÁêÜÁöÑ‰ªªÂä°„ÄÇÂ∞ΩÁÆ°Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã (LLM) Âú®ÂêÑ‰∏™‰∫∫Â∑•Êô∫ËÉΩÈ¢ÜÂüüÂèñÂæó‰∫ÜËøõÂ±ïÔºå‰ΩÜÂÆÉ‰ª¨Âú® RAC ‰∏äÁöÑÊÄßËÉΩÂç¥È≤ú‰∏∫‰∫∫Áü•„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∏ÄÂ∑ÆË∑ùÔºåÊàë‰ª¨ÂºïÂÖ•‰∫Ü‰∏Ä‰∏™Êñ∞ÁöÑÂü∫ÂáÜ ActionReasoningBenchÔºåÂÆÉÊ∂µÁõñ 13 ‰∏™È¢ÜÂüüÔºåÂπ∂‰∏•Ê†ºËØÑ‰º∞‰∫Ü LLM Âú® RAC ÁöÑÂÖ´‰∏™‰∏çÂêåÈ¢ÜÂüü„ÄÇÂÖ∂‰∏≠ÂåÖÊã¨ - ÂØπË±°Ë∑üË∏™„ÄÅÊµÅÂà©Ë∑üË∏™„ÄÅÁä∂ÊÄÅË∑üË∏™„ÄÅÂä®‰ΩúÂèØÊâßË°åÊÄß„ÄÅÂä®‰ΩúÊïàÊûú„ÄÅÊï∞ÂÄº RAC„ÄÅÂπªËßâÊ£ÄÊµãÂíåÂ§çÂêàÈóÆÈ¢ò„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨ËøòÁ†îÁ©∂‰∫ÜÁî±‰∫éÊØè‰∏™ÂüüÁöÑÂàÜÊîØÁ∫¶ÊùüËÄåÂØºËá¥ÁöÑÂä®‰ΩúÁöÑÈó¥Êé•ÂΩ±Âìç„ÄÇÊúÄÂêéÔºåÊàë‰ª¨‰ΩøÁî®ÂºÄÊ∫êÂíåÂïÜ‰∏öÊúÄÂÖàËøõÁöÑ LLMÔºàÂåÖÊã¨ GPT-4o„ÄÅGemini-1.0-Pro„ÄÅLlama2-7b-chat„ÄÅLlama2-13b-chat„ÄÅLlama3-8b-instruct„ÄÅGemma-2b-instruct Âíå Gemma-7b-instructÔºâËØÑ‰º∞‰∫ÜÊàë‰ª¨ÁöÑÂü∫ÂáÜ„ÄÇÊàë‰ª¨ÁöÑÁ†îÁ©∂ÁªìÊûúË°®ÊòéÔºåËøô‰∫õÊ®°ÂûãÂú®Êàë‰ª¨Âü∫ÂáÜ‰∏≠ÂåÖÂê´ÁöÑÊâÄÊúâÁ±ªÂà´‰∏≠ÈÉΩÈù¢‰∏¥ÁùÄÈáçÂ§ßÊåëÊàò„ÄÇ

##### **Shaping History: Advanced Machine Learning Techniques for the Analysis and Dating of Cuneiform Tablets over Three Millennia**
2406.04039v1 by Danielle Kapon, Michael Fire, Shai Gordin

Cuneiform tablets, emerging in ancient Mesopotamia around the late fourth
millennium BCE, represent one of humanity's earliest writing systems.
Characterized by wedge-shaped marks on clay tablets, these artifacts provided
insight into Mesopotamian civilization across various domains. Traditionally,
the analysis and dating of these tablets rely on subjective assessment of shape
and writing style, leading to uncertainties in pinpointing their exact temporal
origins. Recent advances in digitization have revolutionized the study of
cuneiform by enhancing accessibility and analytical capabilities. Our research
uniquely focuses on the silhouette of tablets as significant indicators of
their historical periods, diverging from most studies that concentrate on
textual content. Utilizing an unprecedented dataset of over 94,000 images from
the Cuneiform Digital Library Initiative collection, we apply deep learning
methods to classify cuneiform tablets, covering over 3,000 years of history. By
leveraging statistical, computational techniques, and generative modeling
through Variational Auto-Encoders (VAEs), we achieve substantial advancements
in the automatic classification of these ancient documents, focusing on the
tablets' silhouettes as key predictors. Our classification approach begins with
a Decision Tree using height-to-width ratios and culminates with a ResNet50
model, achieving a 61% macro F1-score for tablet silhouettes. Moreover, we
introduce novel VAE-powered tools to enhance explainability and enable
researchers to explore changes in tablet shapes across different eras and
genres. This research contributes to document analysis and diplomatics by
demonstrating the value of large-scale data analysis combined with statistical
methods. These insights offer valuable tools for historians and epigraphists,
enriching our understanding of cuneiform tablets and the cultures that produced
them.

ÊëòË¶ÅÔºö<paragraph>Ê•îÂΩ¢ÊñáÂ≠óÊ≥•ÊùøÔºåÂá∫Áé∞‰∫éÂ§ßÁ∫¶ÂÖ¨ÂÖÉÂâçÂõõÂçÉÂπ¥Êú´ÁöÑÂè§‰ª£ÁæéÁ¥¢‰∏çËææÁ±≥‰∫öÔºå‰ª£Ë°®‰∫Ü‰∫∫Á±ªÊúÄÊó©ÁöÑ‰π¶ÂÜôÁ≥ªÁªü‰πã‰∏Ä„ÄÇËøô‰∫õÊñáÁâ©‰ª•Ê≥•Êùø‰∏äÁöÑÊ•îÂΩ¢Ê†áËÆ∞‰∏∫ÁâπÂæÅÔºå‰∏∫Êàë‰ª¨Êèê‰æõ‰∫ÜÂØπÁæéÁ¥¢‰∏çËææÁ±≥‰∫öÊñáÊòéÂêÑ‰∏™È¢ÜÂüüÁöÑËßÅËß£„ÄÇ‰º†Áªü‰∏äÔºåÂØπËøô‰∫õÊ≥•ÊùøÁöÑÂàÜÊûêÂíåÊñ≠‰ª£‰æùËµñ‰∫éÂØπÂΩ¢Áä∂Âíå‰π¶ÂÜôÈ£éÊ†ºÁöÑ‰∏ªËßÇËØÑ‰º∞ÔºåËøôÂØºËá¥‰∫ÜÂú®Á≤æÁ°ÆÂÆö‰ΩçÂÖ∂Á°ÆÂàáÊó∂Èó¥Ëµ∑Ê∫êÊñπÈù¢ÁöÑ‰∏çÁ°ÆÂÆöÊÄß„ÄÇÊúÄËøëÊï∞Â≠óÂåñÊñπÈù¢ÁöÑËøõÊ≠•ÈÄöËøáÂ¢ûÂº∫ÂèØËÆøÈóÆÊÄßÂíåÂàÜÊûêËÉΩÂäõÔºåÂΩªÂ∫ïÊîπÂèò‰∫ÜÂØπÊ•îÂΩ¢ÊñáÂ≠óÁöÑÁ†îÁ©∂„ÄÇÊàë‰ª¨ÁöÑÁ†îÁ©∂Áã¨ÁâπÂú∞ÂÖ≥Ê≥®Ê≥•ÊùøÁöÑËΩÆÂªì‰Ωú‰∏∫ÂÖ∂ÂéÜÂè≤Êó∂ÊúüÁöÑÈáçË¶ÅÊåáÊ†áÔºå‰∏çÂêå‰∫éÂ§ßÂ§öÊï∞‰∏ìÊ≥®‰∫éÊñáÊú¨ÂÜÖÂÆπÁöÑÁ†îÁ©∂„ÄÇÂà©Áî®Êù•Ëá™Ê•îÂΩ¢ÊñáÂ≠óÊï∞Â≠óÂõæ‰π¶È¶ÜËÆ°ÂàíÊî∂ËóèÁöÑË∂ÖËøá 94,000 Âº†ÂõæÂÉèÁöÑÁ©∫ÂâçÊï∞ÊçÆÈõÜÔºåÊàë‰ª¨Â∫îÁî®Ê∑±Â∫¶Â≠¶‰π†ÊñπÊ≥ïÂØπÊ•îÂΩ¢ÊñáÂ≠óÊ≥•ÊùøËøõË°åÂàÜÁ±ªÔºåÊ∂µÁõñ‰∫Ü 3,000 Â§öÂπ¥ÁöÑÂéÜÂè≤„ÄÇÈÄöËøáÂà©Áî®ÁªüËÆ°„ÄÅËÆ°ÁÆóÊäÄÊúØÂíåÈÄöËøáÂèòÂàÜËá™Âä®ÁºñÁ†ÅÂô® (VAE) ËøõË°åÁîüÊàêÂª∫Ê®°ÔºåÊàë‰ª¨Âú®Ëøô‰∫õÂè§‰ª£ÊñáÁåÆÁöÑËá™Âä®ÂàÜÁ±ªÊñπÈù¢ÂèñÂæó‰∫ÜÂÆûË¥®ÊÄßËøõÂ±ïÔºåÈáçÁÇπÂÖ≥Ê≥®Ê≥•ÊùøÁöÑËΩÆÂªì‰Ωú‰∏∫ÂÖ≥ÈîÆÈ¢ÑÊµãÊåáÊ†á„ÄÇÊàë‰ª¨ÁöÑÂàÜÁ±ªÊñπÊ≥ï‰ªé‰ΩøÁî®È´òÂÆΩÊØîÁöÑÂÜ≥Á≠ñÊ†ëÂºÄÂßãÔºåÂπ∂‰ª• ResNet50 Ê®°ÂûãÁªìÊùüÔºå‰∏∫Âπ≥ÊùøËΩÆÂªìÂÆûÁé∞‰∫Ü 61% ÁöÑÂÆèËßÇ F1 ÂàÜÊï∞„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨ÂºïÂÖ•‰∫ÜÊñ∞È¢ñÁöÑ VAE È©±Âä®Â∑•ÂÖ∑Êù•Â¢ûÂº∫ÂèØËß£ÈáäÊÄßÔºåÂπ∂‰ΩøÁ†îÁ©∂‰∫∫ÂëòËÉΩÂ§üÊé¢Á¥¢‰∏çÂêåÊó∂‰ª£ÂíåÁ±ªÂûã‰∏≠Âπ≥ÊùøÂΩ¢Áä∂ÁöÑÂèòÂåñ„ÄÇÊú¨Á†îÁ©∂ÈÄöËøáÂ±ïÁ§∫Â§ßËßÑÊ®°Êï∞ÊçÆÂàÜÊûê‰∏éÁªüËÆ°ÊñπÊ≥ïÁõ∏ÁªìÂêàÁöÑ‰ª∑ÂÄºÔºå‰∏∫ÊñáÁåÆÂàÜÊûêÂíåÂ§ñ‰∫§Â≠¶ÂÅöÂá∫‰∫ÜË¥°ÁåÆ„ÄÇËøô‰∫õËßÅËß£‰∏∫ÂéÜÂè≤Â≠¶ÂÆ∂ÂíåÈì≠ÊñáÂ≠¶ÂÆ∂Êèê‰æõ‰∫ÜÊúâ‰ª∑ÂÄºÁöÑÂ∑•ÂÖ∑Ôºå‰∏∞ÂØå‰∫ÜÊàë‰ª¨ÂØπÊ•îÂΩ¢ÊñáÂ≠óÊ≥•ÊùøÂèäÂÖ∂‰∫ßÁîüÂÆÉ‰ª¨ÁöÑÊñáÂåñÁöÑÁêÜËß£„ÄÇ</paragraph>

##### **Spatio-temporal Early Prediction based on Multi-objective Reinforcement Learning**
2406.04035v1 by Wei Shao, Yufan Kang, Ziyan Peng, Xiao Xiao, Lei Wang, Yuhui Yang, Flora D Salim

Accuracy and timeliness are indeed often conflicting goals in prediction
tasks. Premature predictions may yield a higher rate of false alarms, whereas
delaying predictions to gather more information can render them too late to be
useful. In applications such as wildfires, crimes, and traffic jams, timely
predictions are vital for safeguarding human life and property. Consequently,
finding a balance between accuracy and timeliness is crucial. In this paper, we
propose a spatio-temporal early prediction model based on Multi-Objective
reinforcement learning that can either implement an optimal policy given a
preference or infer the preference based on a small number of samples. The
model addresses two primary challenges: 1) enhancing the accuracy of early
predictions and 2) providing the optimal policy for determining the most
suitable prediction time for each area. Our method demonstrates superior
performance on three large-scale real-world datasets, surpassing existing
methods in early spatio-temporal prediction tasks.

ÊëòË¶ÅÔºöÂú®È†êÊ∏¨‰ªªÂãô‰∏≠ÔºåÊ∫ñÁ¢∫ÊÄßÂíåÂèäÊôÇÊÄßÂæÄÂæÄÊòØÁõ∏‰∫íË°ùÁ™ÅÁöÑÁõÆÊ®ô„ÄÇÈÅéÊó©ÁöÑÈ†êÊ∏¨ÂèØËÉΩÊúÉÁî¢ÁîüËºÉÈ´òÁöÑË™§Â†±ÁéáÔºåËÄåÂª∂ÈÅ≤È†êÊ∏¨‰ª•Êî∂ÈõÜÊõ¥Â§öË≥áË®äÂèØËÉΩÊúÉÂ∞éËá¥È†êÊ∏¨ÈÅéÊñºÈÅ≤Âà∞ËÄåÂ§±ÂéªÁî®Ëôï„ÄÇÂú®ÈáéÁÅ´„ÄÅÁäØÁΩ™Âíå‰∫§ÈÄöÂ†µÂ°ûÁ≠âÊáâÁî®‰∏≠ÔºåÂèäÊôÇÁöÑÈ†êÊ∏¨Â∞çÊñº‰øùÈöú‰∫∫ÂëΩÂíåË≤°Áî¢Ëá≥ÈóúÈáçË¶Å„ÄÇÂõ†Ê≠§ÔºåÂú®Ê∫ñÁ¢∫ÊÄßÂíåÂèäÊôÇÊÄß‰πãÈñìÂèñÂæóÂπ≥Ë°°Ëá≥ÈóúÈáçË¶Å„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂü∫ÊñºÂ§öÁõÆÊ®ôÂº∑ÂåñÂ≠∏ÁøíÁöÑÊôÇÁ©∫Êó©ÊúüÈ†êÊ∏¨Ê®°ÂûãÔºåË©≤Ê®°ÂûãÂèØ‰ª•Ê†πÊìöÂÅèÂ•ΩÂØ¶ÊñΩÊúÄ‰Ω≥Á≠ñÁï•ÔºåÊàñÊ†πÊìöÂ∞ëÈáèÊ®£Êú¨Êé®Êñ∑ÂÅèÂ•Ω„ÄÇË©≤Ê®°ÂûãËß£Ê±∫‰∫ÜÂÖ©ÂÄã‰∏ªË¶ÅÁöÑÊåëÊà∞Ôºö1ÔºâÊèêÈ´òÊó©ÊúüÈ†êÊ∏¨ÁöÑÊ∫ñÁ¢∫ÊÄßÔºå‰ª•Âèä 2ÔºâÊèê‰æõÊúÄ‰Ω≥Á≠ñÁï•‰æÜÁ¢∫ÂÆöÊØèÂÄãÂçÄÂüüÊúÄÂêàÈÅ©ÁöÑÈ†êÊ∏¨ÊôÇÈñì„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÂú®‰∏âÂÄãÂ§ßÂûãÁúüÂØ¶‰∏ñÁïåË≥áÊñôÈõÜ‰∏äÂ±ïÁ§∫‰∫ÜÂçìË∂äÁöÑÊïàËÉΩÔºåÂú®Êó©ÊúüÊôÇÁ©∫È†êÊ∏¨‰ªªÂãô‰∏≠Ë∂ÖË∂ä‰∫ÜÁèæÊúâÊñπÊ≥ï„ÄÇ

##### **Pre-trained Transformer Uncovers Meaningful Patterns in Human Mobility Data**
2406.04029v1 by Alameen Najjar

We empirically demonstrate that a transformer pre-trained on country-scale
unlabeled human mobility data learns embeddings capable, through fine-tuning,
of developing a deep understanding of the target geography and its
corresponding mobility patterns. Utilizing an adaptation framework, we evaluate
the performance of our pre-trained embeddings in encapsulating a broad spectrum
of concepts directly and indirectly related to human mobility. This includes
basic notions, such as geographic location and distance, and extends to more
complex constructs, such as administrative divisions and land cover. Our
extensive empirical analysis reveals a substantial performance boost gained
from pre-training, reaching up to 38% in tasks such as tree-cover regression.
We attribute this result to the ability of the pre-training to uncover
meaningful patterns hidden in the raw data, beneficial for modeling relevant
high-level concepts. The pre-trained embeddings emerge as robust
representations of regions and trajectories, potentially valuable for a wide
range of downstream applications.

ÊëòË¶ÅÔºöÊàëÂÄëÈÄèÈÅéÂØ¶Ë≠âË≠âÊòéÔºåÂú®ÂúãÂÆ∂Á¥öË¶èÊ®°Êú™Ê®ôË®ª‰∫∫È°ûÊµÅÂãïÊÄßË≥áÊñô‰∏äÈ†êÂÖàË®ìÁ∑¥ÁöÑËΩâÊèõÂô®ÔºåÂ≠∏Áøí‰∫ÜËÉΩÂ§†ÈÄèÈÅéÂæÆË™øÔºåÁôºÂ±ïÂ∞çÁõÆÊ®ôÂú∞ÁêÜÂèäÂÖ∂Â∞çÊáâÊµÅÂãïÊÄßÊ®°ÂºèÁöÑÊ∑±ÂÖ•ÁêÜËß£ÁöÑÂµåÂÖ•„ÄÇÂà©Áî®ÈÅ©ÊáâÊû∂ÊßãÔºåÊàëÂÄëË©ï‰º∞‰∫ÜÈ†êÂÖàË®ìÁ∑¥ÁöÑÂµåÂÖ•Âú®Ê¶ÇÊã¨Ëàá‰∫∫È°ûÊµÅÂãïÊÄßÁõ¥Êé•ÂíåÈñìÊé•Áõ∏ÈóúÁöÑÂª£Ê≥õÊ¶ÇÂøµÊñπÈù¢ÁöÑÊïàËÉΩ„ÄÇÈÄôÂåÖÊã¨Âü∫Êú¨Ê¶ÇÂøµÔºå‰æãÂ¶ÇÂú∞ÁêÜ‰ΩçÁΩÆÂíåË∑ùÈõ¢Ôºå‰∏¶Âª∂‰º∏Âà∞Êõ¥Ë§áÈõúÁöÑÁµêÊßãÔºå‰æãÂ¶ÇË°åÊîøÂçÄÂäÉÂíåÂúüÂú∞Ë¶ÜËìã„ÄÇÊàëÂÄëÂª£Ê≥õÁöÑÂØ¶Ë≠âÂàÜÊûêÊè≠Á§∫‰∫ÜÂæûÈ†êË®ìÁ∑¥‰∏≠Áç≤ÂæóÁöÑÈ°ØËëóÊïàËÉΩÊèêÂçáÔºåÂú®Ê®πÊú®Ë¶ÜËìãÂõûÊ≠∏Á≠â‰ªªÂãô‰∏≠ÈÅîÂà∞ 38%„ÄÇÊàëÂÄëÂ∞áÊ≠§ÁµêÊûúÊ≠∏Âõ†ÊñºÈ†êË®ìÁ∑¥Êè≠Á§∫ÂéüÂßãË≥áÊñô‰∏≠Èö±ËóèÁöÑÊÑèÁæ©Ê®°ÂºèÁöÑËÉΩÂäõÔºåÈÄôÊúâÂä©ÊñºÂª∫Ê®°Áõ∏ÈóúÁöÑÈ´òÈöéÊ¶ÇÂøµ„ÄÇÈ†êÂÖàË®ìÁ∑¥ÁöÑÂµåÂÖ•ÊàêÁÇ∫ÂçÄÂüüÂíåËªåË∑°ÁöÑÂº∑ÂÅ•Ë°®Á§∫ÔºåÂ∞çÊñºÂª£Ê≥õÁöÑ‰∏ãÊ∏∏ÊáâÁî®ÊΩõÂú®ÊúâÂÉπÂÄº„ÄÇ

##### **The syntax-semantics interface in a child's path: A study of 3- to 11-year-olds' elicited production of Mandarin recursive relative clauses**
2406.04025v1 by Caimei Yang, Qihang Yang, Xingzhi Su, Chenxi Fu, Xiaoyi Wang, Ying Yan, Zaijiang Man

There have been apparently conflicting claims over the syntax-semantics
relationship in child acquisition. However, few of them have assessed the
child's path toward the acquisition of recursive relative clauses (RRCs). The
authors of the current paper did experiments to investigate 3- to 11-year-olds'
most-structured elicited production of eight Mandarin RRCs in a 4 (syntactic
types)*2 (semantic conditions) design. The four syntactic types were RRCs with
a subject-gapped RC embedded in an object-gapped RC (SORRCs), RRCs with an
object-gapped RC embedded in another object-gapped RC (OORRCs), RRCs with an
object-gapped RC embedded in a subject-gapped RC (OSRRCs), and RRCs with a
subject-gapped RC embedded in another subject-gapped RC (SSRRCs). Each
syntactic type was put in two conditions differing in internal semantics:
irreversible internal semantics (IIS) and reversible internal semantics (RIS).
For example, "the balloon that [the girl that _ eats the banana] holds _" is
SORRCs in the IIS condition; "the monkey that [the dog that _ bites the pig]
hits_" is SORRCs in the RIS condition. For each target, the participants were
provided with a speech-visual stimulus constructing a condition of irreversible
external semantics (IES). The results showed that SSRRCs, OSRRCs and SORRCs in
the IIS-IES condition were produced two years earlier than their counterparts
in the RIS-IES condition. Thus, a 2-stage development path is proposed: the
language acquisition device starts with the interface between (irreversible)
syntax and IIS, and ends with the interface between syntax and IES, both
abiding by the syntax-semantic interface principle.

ÊëòË¶ÅÔºö<paragraph>Âú®ÂÖíÁ´•ÁøíÂæóÈÅéÁ®ã‰∏≠ÔºåÂ∞çÊñºË™ûÊ≥ïË™ûÊÑèÈóú‰øÇ‰∏ÄÁõ¥Â≠òÂú®ËëóÊòéÈ°ØÁöÑÁà≠Ë≠∞ÊÄßË™™Ê≥ï„ÄÇÁÑ∂ËÄåÔºåÂæàÂ∞ëÊúâ‰∫∫Ë©ï‰º∞ÂÖíÁ´•ÁøíÂæóÈÅûÊ≠∏Èóú‰øÇÂ≠êÂè• (RRC) ÁöÑÈÄîÂæë„ÄÇÊú¨Êñá‰ΩúËÄÖÈÄ≤Ë°å‰∫ÜÂØ¶È©óÔºå‰ª•Ë™øÊü• 3 Ëá≥ 11 Ê≠≤ÂÖíÁ´•Âú® 4ÔºàË™ûÊ≥ïÈ°ûÂûãÔºâ*2ÔºàË™ûÁæ©Ê¢ù‰ª∂ÔºâË®≠Ë®à‰∏≠Â∞çÂÖ´ÂÄãÊº¢Ë™û RRC ÊúÄÁµêÊßãÂåñÁöÑÂºïÁôºÊÄßÁî¢Áîü„ÄÇÂõõÁ®ÆË™ûÊ≥ïÈ°ûÂûãÊòØ RRCÔºåÂÖ∂‰∏≠‰∏ÄÂÄã‰∏ªË™ûÈñìÈöô RC ÂµåÂÖ•Âú®‰∏ÄÂÄãË≥ìË™ûÈñìÈöô RCÔºàSORRCÔºâ‰∏≠ÔºåRRCÔºåÂÖ∂‰∏≠‰∏ÄÂÄãË≥ìË™ûÈñìÈöô RC ÂµåÂÖ•Âú®Âè¶‰∏ÄÂÄãË≥ìË™ûÈñìÈöô RCÔºàOORRCÔºâ‰∏≠ÔºåRRCÔºåÂÖ∂‰∏≠‰∏ÄÂÄãË≥ìË™ûÈñìÈöô RC ÂµåÂÖ•Âú®‰∏ÄÂÄã‰∏ªË™ûÈñìÈöô RCÔºàOSRRCÔºâ‰∏≠Ôºå‰ª•Âèä RRCÔºåÂÖ∂‰∏≠‰∏ÄÂÄã‰∏ªË™ûÈñìÈöô RC ÂµåÂÖ•Âú®Âè¶‰∏ÄÂÄã‰∏ªË™ûÈñìÈöô RCÔºàSSRRCÔºâ‰∏≠„ÄÇÊØèÁ®ÆÈ°ûÂûãÁöÑË™ûÊ≥ïÈÉΩË¢´ÁΩÆÊñºÂÖ©ÂÄãÂú®ÂÖßÈÉ®Ë™ûÁæ©‰∏ä‰∏çÂêåÁöÑÊ¢ù‰ª∂‰∏≠Ôºö‰∏çÂèØÈÄÜÂÖßÈÉ®Ë™ûÁæ©ÔºàIISÔºâÂíåÂèØÈÄÜÂÖßÈÉ®Ë™ûÁæ©ÔºàRISÔºâ„ÄÇ‰æãÂ¶ÇÔºå„Äå[ÈÇ£ÂÄãÂ•≥Â≠©ÂêÉÈ¶ôËïâ]ÊãøËëóÁöÑÈÇ£ÂÄãÊ∞£ÁêÉ„ÄçÂú® IIS Ê¢ù‰ª∂‰∏ãÊòØ SORRCÔºõ„Äå[ÈÇ£Ê¢ùÁãóÂí¨Ë±¨]ÊâìÁöÑÈÇ£ÈöªÁå¥Â≠ê„ÄçÂú® RIS Ê¢ù‰ª∂‰∏ãÊòØ SORRC„ÄÇÂ∞çÊñºÊØèÂÄãÁõÆÊ®ôÔºåÂèÉËàáËÄÖÈÉΩË¢´Êèê‰æõ‰∫Ü‰∏ÄÂÄãÊßãÂª∫‰∏çÂèØÈÄÜÂ§ñÈÉ®Ë™ûÁæ©ÔºàIESÔºâÊ¢ù‰ª∂ÁöÑË™ûÈü≥Ë¶ñË¶∫Âà∫ÊøÄ„ÄÇÁµêÊûúË°®ÊòéÔºåÂú® IIS-IES Ê¢ù‰ª∂‰∏ãÁöÑ SSRRC„ÄÅOSRRC Âíå SORRC ÊØîÂú® RIS-IES Ê¢ù‰ª∂‰∏ãÁöÑÂ∞çÊáâÊ¢ù‰ª∂Êó©ÂÖ©Âπ¥Áî¢Áîü„ÄÇÂõ†Ê≠§ÔºåÊèêÂá∫‰∫Ü 2 ÈöéÊÆµÁôºÂ±ïË∑ØÂæëÔºöË™ûË®ÄÁøíÂæóË£ùÁΩÆÂæûÔºà‰∏çÂèØÈÄÜÔºâË™ûÊ≥ïÂíå IIS ‰πãÈñìÁöÑ‰ªãÈù¢ÈñãÂßãÔºå‰∏¶‰ª•Ë™ûÊ≥ïÂíå IES ‰πãÈñìÁöÑ‰ªãÈù¢ÁµêÊùüÔºåÂÖ©ËÄÖÈÉΩÈÅµÂÆàË™ûÊ≥ïË™ûÁæ©‰ªãÈù¢ÂéüÂâá„ÄÇ</paragraph>

##### **American Sign Language Handshapes Reflect Pressures for Communicative Efficiency**
2406.04024v1 by Kayo Yin, Terry Regier, Dan Klein

Communicative efficiency is a prominent theory in linguistics and cognitive
science. While numerous studies have shown how the pressure to save energy is
reflected in the form of spoken languages, few have explored this phenomenon in
signed languages. In this paper, we show how handshapes in American Sign
Language (ASL) reflect these efficiency pressures and we present new evidence
of communicative efficiency in the visual-gestural modality.
  We focus on handshapes that are used in both native ASL signs and signs
borrowed from English to compare efficiency pressures from both ASL and
English. First, we design new methodologies to quantify the articulatory effort
required to produce handshapes as well as the perceptual effort needed to
recognize them. Then, we compare correlations between communicative effort and
usage statistics in ASL and English. Our findings reveal that frequent ASL
handshapes are easier to produce and that pressures for communicative
efficiency mostly come from ASL usage, not from English lexical borrowing.

ÊëòË¶ÅÔºöÊ∫ùÈÄöÊïàÁéáÊòØË™ûË®ÄÂ≠∏ÂíåË™çÁü•ÁßëÂ≠∏‰∏≠‰∏ÄÈ†ÖÈ°ØËëóÁöÑÁêÜË´ñ„ÄÇÈõñÁÑ∂Ë®±Â§öÁ†îÁ©∂Â∑≤Ë°®ÊòéÁØÄÁúÅËÉΩÈáèÁöÑÂ£ìÂäõÂ¶Ç‰ΩïÂèçÊò†Âú®Âè£Ë™ûÂΩ¢Âºè‰∏≠Ôºå‰ΩÜÂæàÂ∞ëÊúâ‰∫∫Âú®ÊâãË™û‰∏≠Êé¢Ë®éÈÄôÁ®ÆÁèæË±°„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜÁæéÂúãÊâãË™û (ASL) ‰∏≠ÁöÑÊâãÂã¢Â¶Ç‰ΩïÂèçÊò†ÈÄô‰∫õÊïàÁéáÂ£ìÂäõÔºå‰∏¶‰∏îÊàëÂÄëÊèê‰æõ‰∫ÜË¶ñË¶∫ÊâãÂã¢Ê®°Âºè‰∏≠Ê∫ùÈÄöÊïàÁéáÁöÑÊñ∞Ë≠âÊìö„ÄÇ
ÊàëÂÄëÂ∞àÊ≥®ÊñºÂú® ASL ÊâãÂã¢ÂíåÂæûËã±Ë™ûÂÄü‰æÜÁöÑÁ¨¶Ëôü‰∏≠‰ΩøÁî®ÁöÑÂΩ¢ÁãÄÔºå‰ª•ÊØîËºÉ‰æÜËá™ ASL ÂíåËã±Ë™ûÁöÑÊïàÁéáÂ£ìÂäõ„ÄÇÈ¶ñÂÖàÔºåÊàëÂÄëË®≠Ë®àÊñ∞ÁöÑÊñπÊ≥ï‰æÜÈáèÂåñÁî¢ÁîüÊâãÂã¢ÊâÄÈúÄÁöÑÁôºÈü≥Âä™Âäõ‰ª•ÂèäË≠òÂà•ÊâãÂã¢ÊâÄÈúÄÁöÑÊÑüÁü•Âä™Âäõ„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÊØîËºÉ‰∫Ü ASL ÂíåËã±Ë™û‰∏≠Ê∫ùÈÄöÂä™ÂäõÂíå‰ΩøÁî®Áµ±Ë®àÊï∏Êìö‰πãÈñìÁöÑÁõ∏ÈóúÊÄß„ÄÇÊàëÂÄëÁöÑÁôºÁèæË°®ÊòéÔºåÂ∏∏Ë¶ãÁöÑ ASL ÊâãÂã¢Êõ¥ÂÆπÊòìÁî¢ÁîüÔºåËÄå‰∏îÊ∫ùÈÄöÊïàÁéáÁöÑÂ£ìÂäõ‰∏ªË¶Å‰æÜËá™ ASL ‰ΩøÁî®ÔºåËÄå‰∏çÊòØ‰æÜËá™Ëã±Ë™ûË©ûÂΩôÂÄüÁî®„ÄÇ

##### **HackAtari: Atari Learning Environments for Robust and Continual Reinforcement Learning**
2406.03997v1 by Quentin Delfosse, Jannis Bl√ºml, Bjarne Gregori, Kristian Kersting

Artificial agents' adaptability to novelty and alignment with intended
behavior is crucial for their effective deployment. Reinforcement learning (RL)
leverages novelty as a means of exploration, yet agents often struggle to
handle novel situations, hindering generalization. To address these issues, we
propose HackAtari, a framework introducing controlled novelty to the most
common RL benchmark, the Atari Learning Environment. HackAtari allows us to
create novel game scenarios (including simplification for curriculum learning),
to swap the game elements' colors, as well as to introduce different reward
signals for the agent. We demonstrate that current agents trained on the
original environments include robustness failures, and evaluate HackAtari's
efficacy in enhancing RL agents' robustness and aligning behavior through
experiments using C51 and PPO. Overall, HackAtari can be used to improve the
robustness of current and future RL algorithms, allowing Neuro-Symbolic RL,
curriculum RL, causal RL, as well as LLM-driven RL. Our work underscores the
significance of developing interpretable in RL agents.

ÊëòË¶ÅÔºö‰∫∫Â∑•‰ª£ÁêÜÁöÑÈÄÇÂ∫îÊñ∞Á©éÊÄßÂíåËàáÈ†êÊúüË°åÁÇ∫‰∏ÄËá¥Â∞çÂÖ∂ÊúâÊïàÈÉ®ÁΩ≤Ëá≥ÈóúÈáçË¶Å„ÄÇÂº∑ÂåñÂ≠∏Áøí (RL) Âà©Áî®Êñ∞Á©éÊÄß‰ΩúÁÇ∫Êé¢Á¥¢ÁöÑÊâãÊÆµÔºå‰ΩÜ‰ª£ÁêÜÈÄöÂ∏∏Èõ£‰ª•ÊáâÂ∞çÊñ∞Á©éÊÉÖÊ≥ÅÔºåÈòªÁ§ôÊ≥õÂåñ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∫Ü HackAtariÔºå‰∏ÄÂÄãÂú®ÊúÄÂ∏∏Ë¶ãÁöÑ RL Âü∫Ê∫ñ Atari Â≠∏ÁøíÁí∞Â¢É‰∏≠ÂºïÂÖ•ÂèóÊéßÊñ∞Á©éÊÄßÁöÑÊ°ÜÊû∂„ÄÇHackAtari ÂÖÅË®±ÊàëÂÄëÂâµÂª∫Êñ∞Á©éÁöÑÈÅäÊà≤Â†¥ÊôØÔºàÂåÖÊã¨Á∞°ÂåñË™≤Á®ãÂ≠∏ÁøíÔºâ„ÄÅ‰∫§ÊèõÈÅäÊà≤ÂÖÉÁ¥†ÁöÑÈ°èËâ≤Ôºå‰ª•ÂèäÁÇ∫‰ª£ÁêÜÂºïÂÖ•‰∏çÂêåÁöÑÁçéÂãµ‰ø°Ëôü„ÄÇÊàëÂÄëË≠âÊòé‰∫ÜÂú®ÂéüÂßãÁí∞Â¢É‰∏≠Ë®ìÁ∑¥ÁöÑÁï∂Ââç‰ª£ÁêÜÂåÖÊã¨Á©©ÂÅ•ÊÄßÊïÖÈöúÔºå‰∏¶ÈÄöÈÅé‰ΩøÁî® C51 Âíå PPO ÁöÑÂØ¶È©óË©ï‰º∞‰∫Ü HackAtari Âú®Â¢ûÂº∑ RL ‰ª£ÁêÜÁöÑÁ©©ÂÅ•ÊÄßÂíåË™øÊï¥Ë°åÁÇ∫ÊñπÈù¢ÁöÑÂäüÊïà„ÄÇÁ∏ΩÁöÑ‰æÜË™™ÔºåHackAtari ÂèØÁî®ÊñºÊèêÈ´òÁï∂ÂâçÂíåÊú™‰æÜ RL ÊºîÁÆóÊ≥ïÁöÑÁ©©ÂÅ•ÊÄßÔºåÂÖÅË®±Á•ûÁ∂ìÁ¨¶Ëôü RL„ÄÅË™≤Á®ã RL„ÄÅÂõ†Êûú RLÔºå‰ª•Âèä LLM È©ÖÂãïÁöÑ RL„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂Âº∑Ë™ø‰∫ÜÂú® RL ‰ª£ÁêÜ‰∏≠ÈñãÁôºÂèØËß£ÈáãÊÄßÁöÑÈáçË¶ÅÊÄß„ÄÇ

##### **AC4MPC: Actor-Critic Reinforcement Learning for Nonlinear Model Predictive Control**
2406.03995v1 by Rudolf Reiter, Andrea Ghezzi, Katrin Baumg√§rtner, Jasper Hoffmann, Robert D. McAllister, Moritz Diehl

\Ac{MPC} and \ac{RL} are two powerful control strategies with, arguably,
complementary advantages. In this work, we show how actor-critic \ac{RL}
techniques can be leveraged to improve the performance of \ac{MPC}. The \ac{RL}
critic is used as an approximation of the optimal value function, and an actor
roll-out provides an initial guess for primal variables of the \ac{MPC}. A
parallel control architecture is proposed where each \ac{MPC} instance is
solved twice for different initial guesses. Besides the actor roll-out
initialization, a shifted initialization from the previous solution is used.
Thereafter, the actor and the critic are again used to approximately evaluate
the infinite horizon cost of these trajectories. The control actions from the
lowest-cost trajectory are applied to the system at each time step. We
establish that the proposed algorithm is guaranteed to outperform the original
\ac{RL} policy plus an error term that depends on the accuracy of the critic
and decays with the horizon length of the \ac{MPC} formulation. Moreover, we do
not require globally optimal solutions for these guarantees to hold. The
approach is demonstrated on an illustrative toy example and an \ac{AD}
overtaking scenario.

ÊëòË¶ÅÔºö\Ac{MPC} Âíå \ac{RL} ÊòØ‰∏§ÁßçÂº∫Â§ßÁöÑÊéßÂà∂Á≠ñÁï•ÔºåÂèØ‰ª•‰∫âËæ©ËØ¥ÔºåÂÖ∑Êúâ‰∫íË°•ÁöÑ‰ºòÂäø„ÄÇÂú®ËøôÈ°πÂ∑•‰Ωú‰∏≠ÔºåÊàë‰ª¨Â±ïÁ§∫‰∫ÜÂ¶Ç‰ΩïÂà©Áî® actor-critic \ac{RL} ÊäÄÊúØÊù•ÊèêÈ´ò \ac{MPC} ÁöÑÊÄßËÉΩ„ÄÇ\ac{RL} ËØÑËÆ∫ËÄÖÁî®‰ΩúÊúÄ‰ºòÂÄºÂáΩÊï∞ÁöÑËøë‰ººÂÄºÔºåÂπ∂‰∏î actor roll-out ‰∏∫ \ac{MPC} ÁöÑÂéüÂßãÂèòÈáèÊèê‰æõÂàùÂßãÁåúÊµã„ÄÇÊèêÂá∫‰∫Ü‰∏ÄÁßçÂπ∂Ë°åÊéßÂà∂Êû∂ÊûÑÔºåÂÖ∂‰∏≠ÊØè‰∏™ \ac{MPC} ÂÆû‰æãÈíàÂØπ‰∏çÂêåÁöÑÂàùÂßãÁåúÊµãÊ±ÇËß£‰∏§Ê¨°„ÄÇÈô§‰∫Ü actor roll-out ÂàùÂßãÂåñ‰πãÂ§ñÔºåËøò‰ΩøÁî®‰∫ÜÂâç‰∏Ä‰∏™Ëß£ÁöÑÂÅèÁßªÂàùÂßãÂåñ„ÄÇÊ≠§ÂêéÔºåactor ÂíåËØÑËÆ∫ËÄÖÂÜçÊ¨°Áî®‰∫éËøë‰ººËØÑ‰º∞Ëøô‰∫õËΩ®ËøπÁöÑÊó†ÈôêËåÉÂõ¥ÊàêÊú¨„ÄÇÊù•Ëá™ÊúÄ‰ΩéÊàêÊú¨ËΩ®ËøπÁöÑÊéßÂà∂Âä®‰ΩúÂú®ÊØè‰∏™Êó∂Èó¥Ê≠•ÈïøÂ∫îÁî®‰∫éÁ≥ªÁªü„ÄÇÊàë‰ª¨Á°ÆÂÆöÊâÄÊèêÂá∫ÁöÑÁÆóÊ≥ï‰øùËØÅ‰ºò‰∫éÂéüÂßã \ac{RL} Á≠ñÁï•ÔºåÂä†‰∏ä‰∏Ä‰∏™ËØØÂ∑ÆÈ°πÔºåËØ•ËØØÂ∑ÆÈ°πÂèñÂÜ≥‰∫éËØÑËÆ∫ËÄÖÁöÑÂáÜÁ°ÆÊÄßÔºåÂπ∂ÈöèÁùÄ \ac{MPC} ÂÖ¨ÂºèÁöÑËåÉÂõ¥ÈïøÂ∫¶ËÄåË°∞Âáè„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨‰∏çÈúÄË¶ÅÂÖ®Â±ÄÊúÄ‰ºòËß£Êù•‰øùÊåÅËøô‰∫õ‰øùËØÅ„ÄÇËØ•ÊñπÊ≥ïÂú®‰∏Ä‰∏™ËØ¥ÊòéÊÄßÁé©ÂÖ∑Á§∫‰æãÂíå‰∏Ä‰∏™ \ac{AD} Ë∂ÖËΩ¶Âú∫ÊôØ‰∏≠ÂæóÂà∞ËØÅÊòé„ÄÇ

##### **Assessing LLMs for Zero-shot Abstractive Summarization Through the Lens of Relevance Paraphrasing**
2406.03993v1 by Hadi Askari, Anshuman Chhabra, Muhao Chen, Prasant Mohapatra

Large Language Models (LLMs) have achieved state-of-the-art performance at
zero-shot generation of abstractive summaries for given articles. However,
little is known about the robustness of such a process of zero-shot
summarization. To bridge this gap, we propose relevance paraphrasing, a simple
strategy that can be used to measure the robustness of LLMs as summarizers. The
relevance paraphrasing approach identifies the most relevant sentences that
contribute to generating an ideal summary, and then paraphrases these inputs to
obtain a minimally perturbed dataset. Then, by evaluating model performance for
summarization on both the original and perturbed datasets, we can assess the
LLM's one aspect of robustness. We conduct extensive experiments with relevance
paraphrasing on 4 diverse datasets, as well as 4 LLMs of different sizes
(GPT-3.5-Turbo, Llama-2-13B, Mistral-7B, and Dolly-v2-7B). Our results indicate
that LLMs are not consistent summarizers for the minimally perturbed articles,
necessitating further improvements.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®ÁâπÂÆöÊñáÁ´†ÁöÑÊäΩË±°ÊëòË¶ÅÁöÑÈõ∂Ê¨°Â≠∏ÁøíÁîüÊàê‰∏≠ÈÅîÂà∞‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÊÄßËÉΩ„ÄÇÁÑ∂ËÄåÔºåÂ∞çÊñºÈÄôÁ®ÆÈõ∂Ê¨°Â≠∏ÁøíÊëòË¶ÅÁöÑÈÅéÁ®ãÁöÑÁ©©ÂÅ•ÊÄßÁü•‰πãÁîöÂ∞ë„ÄÇÁÇ∫‰∫ÜÂΩåÂêàÈÄô‰∏ÄÂ∑ÆË∑ùÔºåÊàëÂÄëÊèêÂá∫‰∫ÜÁõ∏ÈóúÊÄßÊîπËø∞ÔºåÈÄôÊòØ‰∏ÄÁ®ÆÂèØÁî®‰∫éË°°Èáè LLM ‰ΩúÁÇ∫ÊëòË¶ÅÁöÑÁ©©ÂÅ•ÊÄßÁöÑÁ∞°ÂñÆÁ≠ñÁï•„ÄÇÁõ∏ÈóúÊÄßÊîπËø∞ÊñπÊ≥ïË≠òÂà•Âá∫Â∞çÁîüÊàêÁêÜÊÉ≥ÊëòË¶ÅË≤¢ÁçªÊúÄÂ§ßÁöÑÁõ∏ÈóúÂè•Â≠êÔºåÁÑ∂ÂæåÊîπËø∞ÈÄô‰∫õËº∏ÂÖ•‰ª•Áç≤ÂèñÊúÄÂ∞èÁ®ãÂ∫¶ÊìæÂãïÁöÑÊï∏ÊìöÈõÜ„ÄÇÁÑ∂ÂæåÔºåÈÄöÈÅéË©ï‰º∞Ê®°ÂûãÂú®ÂéüÂßãÂíåÊìæÂãïÊï∏ÊìöÈõÜ‰∏äÁöÑÊëòË¶ÅÊÄßËÉΩÔºåÊàëÂÄëÂèØ‰ª•Ë©ï‰º∞ LLM ÁöÑÁ©©ÂÅ•ÊÄßÁöÑ‰∏ÄÂÄãÊñπÈù¢„ÄÇÊàëÂÄëÂ∞ç 4 ÂÄã‰∏çÂêåÁöÑÊï∏ÊìöÈõÜ‰ª•Âèä 4 ÂÄã‰∏çÂêåË¶èÊ®°ÁöÑ LLMÔºàGPT-3.5-Turbo„ÄÅLlama-2-13B„ÄÅMistral-7B Âíå Dolly-v2-7BÔºâÈÄ≤Ë°å‰∫ÜÂª£Ê≥õÁöÑÁõ∏ÈóúÊÄßÊîπËø∞ÂØ¶È©ó„ÄÇÊàëÂÄëÁöÑÁµêÊûúË°®ÊòéÔºåÂ∞çÊñºÊúÄÂ∞èÁ®ãÂ∫¶ÊìæÂãïÁöÑÊñáÁ´†ÔºåLLM ‰∏çÊòØ‰∏ÄËá¥ÁöÑÊëòË¶ÅÔºåÈÄôÈúÄË¶ÅÈÄ≤‰∏ÄÊ≠•ÊîπÈÄ≤„ÄÇ

##### **On The Persona-based Summarization of Domain-Specific Documents**
2406.03986v1 by Ankan Mullick, Sombit Bose, Rounak Saha, Ayan Kumar Bhowmick, Pawan Goyal, Niloy Ganguly, Prasenjit Dey, Ravi Kokku

In an ever-expanding world of domain-specific knowledge, the increasing
complexity of consuming, and storing information necessitates the generation of
summaries from large information repositories. However, every persona of a
domain has different requirements of information and hence their summarization.
For example, in the healthcare domain, a persona-based (such as Doctor, Nurse,
Patient etc.) approach is imperative to deliver targeted medical information
efficiently. Persona-based summarization of domain-specific information by
humans is a high cognitive load task and is generally not preferred. The
summaries generated by two different humans have high variability and do not
scale in cost and subject matter expertise as domains and personas grow.
Further, AI-generated summaries using generic Large Language Models (LLMs) may
not necessarily offer satisfactory accuracy for different domains unless they
have been specifically trained on domain-specific data and can also be very
expensive to use in day-to-day operations. Our contribution in this paper is
two-fold: 1) We present an approach to efficiently fine-tune a domain-specific
small foundation LLM using a healthcare corpus and also show that we can
effectively evaluate the summarization quality using AI-based critiquing. 2) We
further show that AI-based critiquing has good concordance with Human-based
critiquing of the summaries. Hence, such AI-based pipelines to generate
domain-specific persona-based summaries can be easily scaled to other domains
such as legal, enterprise documents, education etc. in a very efficient and
cost-effective manner.

ÊëòË¶ÅÔºö<paragraph>Âú®‰∏çÊñ∑Êì¥Â±ïÁöÑÈ†òÂüüÁâπÂÆöÁü•Ë≠ò‰∏ñÁïå‰∏≠ÔºåÊ∂àËÄóÂíåÂÑ≤Â≠òË≥áË®äÁöÑË§áÈõúÊÄßÊó•ÁõäÂ¢ûÂä†ÔºåÈÄô‰ΩøÂæóÂøÖÈ†àÂæûÂ§ßÂûãË≥áË®äÂÑ≤Â≠òÂ∫´‰∏≠Áî¢ÁîüÊëòË¶Å„ÄÇÁÑ∂ËÄåÔºå‰∏ÄÂÄãÈ†òÂüüÁöÑÊØèÂÄã‰∫∫Ê†ºÂ∞çË≥áË®äÊúâ‰∏çÂêåÁöÑÈúÄÊ±ÇÔºåÂõ†Ê≠§‰ªñÂÄëÁöÑÊëòË¶Å‰πü‰∏çÂêå„ÄÇ‰æãÂ¶ÇÔºåÂú®ÈÜ´ÁôÇ‰øùÂÅ•È†òÂüüÔºåÂü∫Êñº‰∫∫Ê†ºÔºà‰æãÂ¶ÇÈÜ´Áîü„ÄÅË≠∑Â£´„ÄÅÁóÖ‰∫∫Á≠âÔºâÁöÑÊñπÊ≥ïÂ∞çÊñºÊúâÊïàÂÇ≥ÈÅûÊúâÈáùÂ∞çÊÄßÁöÑÈÜ´ÁôÇË≥áË®äËá≥ÈóúÈáçË¶Å„ÄÇÁî±‰∫∫È°ûÈÄ≤Ë°åÂü∫Êñº‰∫∫Ê†ºÁöÑÈ†òÂüüÁâπÂÆöË≥áË®äÊëòË¶ÅÊòØ‰∏ÄÁ®ÆË™çÁü•Ë≤†ÊìîÂæàÈ´òÁöÑ‰ªªÂãôÔºåÈÄöÂ∏∏‰∏çÂèóÈùíÁùû„ÄÇÁî±ÂÖ©ÂÄã‰∫∫È°ûÁî¢ÁîüÁöÑÊëòË¶ÅÊúâÂæàÈ´òÁöÑÂèØËÆäÊÄßÔºå‰∏¶‰∏îÈö®ËëóÈ†òÂüüÂíå‰∫∫Ê†ºÁöÑÂ¢ûÈï∑ÔºåÂú®ÊàêÊú¨Âíå‰∏ªÈ°åÂ∞àÊ•≠Áü•Ë≠òÊñπÈù¢ÁÑ°Ê≥ïÊì¥Â±ï„ÄÇÊ≠§Â§ñÔºå‰ΩøÁî®ÈÄöÁî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁîüÊàêÁöÑ AI ÊëòË¶ÅÂèØËÉΩÁÑ°Ê≥ïÁÇ∫‰∏çÂêåÁöÑÈ†òÂüüÊèê‰æõ‰ª§‰∫∫ÊªøÊÑèÁöÑÊ∫ñÁ¢∫ÊÄßÔºåÈô§ÈùûÂÆÉÂÄëÁ∂ìÈÅéÁâπÂÆöÈ†òÂüüË≥áÊñôÁöÑÂ∞àÈñÄË®ìÁ∑¥Ôºå‰∏¶‰∏îÂú®Êó•Â∏∏Êìç‰Ωú‰∏≠‰ΩøÁî®Ëµ∑‰æÜ‰πüÂèØËÉΩÈùûÂ∏∏ÊòÇË≤¥„ÄÇÊàëÂÄëÂú®ÈÄôÁØáË´ñÊñá‰∏≠ÁöÑË≤¢ÁçªÊúâÂÖ©ÂÄãÊñπÈù¢Ôºö1) ÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®Æ‰ΩøÁî®ÈÜ´ÁôÇË™ûÊñôÂ∫´ÊúâÊïàÂæÆË™øÁâπÂÆöÈ†òÂüüÁöÑÂ∞èÂûãÂü∫Á§é LLM ÁöÑÊñπÊ≥ïÔºå‰∏¶Â±ïÁ§∫‰∫ÜÊàëÂÄëÂèØ‰ª•‰ΩøÁî®Âü∫Êñº AI ÁöÑÊâπË©ïÊúâÊïàË©ï‰º∞ÊëòË¶ÅÂìÅË≥™„ÄÇ2) ÊàëÂÄëÈÄ≤‰∏ÄÊ≠•Ë°®ÊòéÔºåÂü∫Êñº AI ÁöÑÊâπË©ïËàáÂü∫Êñº‰∫∫È°ûÁöÑÊëòË¶ÅÊâπË©ïÂÖ∑ÊúâËâØÂ•ΩÁöÑÁ¨¶ÂêàÂ∫¶„ÄÇÂõ†Ê≠§ÔºåÈÄôÁ®ÆÂü∫Êñº AI ÁöÑÁÆ°ÈÅìÂèØ‰ª•ÈùûÂ∏∏ÊúâÊïà‰∏îÂÖ∑ÊúâÊàêÊú¨ÊïàÁõäÂú∞ËºïÈ¨ÜÊì¥Â±ïÂà∞ÂÖ∂‰ªñÈ†òÂüüÔºå‰æãÂ¶ÇÊ≥ïÂæã„ÄÅ‰ºÅÊ•≠Êñá‰ª∂„ÄÅÊïôËÇ≤Á≠âÔºå‰ª•Áî¢ÁîüÁâπÂÆöÈ†òÂüüÁöÑÂü∫Êñº‰∫∫Ê†ºÁöÑÊëòË¶Å„ÄÇ</paragraph>

##### **A + B: A General Generator-Reader Framework for Optimizing LLMs to Unleash Synergy Potential**
2406.03963v1 by Wei Tang, Yixin Cao, Jiahao Ying, Bo Wang, Yuyue Zhao, Yong Liao, Pengyuan Zhou

Retrieval-Augmented Generation (RAG) is an effective solution to supplement
necessary knowledge to large language models (LLMs). Targeting its bottleneck
of retriever performance, "generate-then-read" pipeline is proposed to replace
the retrieval stage with generation from the LLM itself. Although promising,
this research direction is underexplored and still cannot work in the scenario
when source knowledge is given. In this paper, we formalize a general "A + B"
framework with varying combinations of foundation models and types for
systematic investigation. We explore the efficacy of the base and chat versions
of LLMs and found their different functionalities suitable for generator A and
reader B, respectively. Their combinations consistently outperform single
models, especially in complex scenarios. Furthermore, we extend the application
of the "A + B" framework to scenarios involving source documents through
continuous learning, enabling the direct integration of external knowledge into
LLMs. This approach not only facilitates effective acquisition of new knowledge
but also addresses the challenges of safety and helpfulness post-adaptation.
The paper underscores the versatility of the "A + B" framework, demonstrating
its potential to enhance the practical application of LLMs across various
domains.

ÊëòË¶ÅÔºöÊì∑ÂèñÂ¢ûÂº∑ÁîüÊàêÔºàRAGÔºâÊòØ‰∏ÄÁ®ÆÊúâÊïàÁöÑËß£Ê±∫ÊñπÊ°àÔºåÂèØ‰ª•ÁÇ∫Â§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâË£úÂÖÖÂøÖË¶ÅÁöÑÁü•Ë≠ò„ÄÇÈáùÂ∞çÂÖ∂Êì∑ÂèñÂô®ÊïàËÉΩÁöÑÁì∂È†∏ÔºåÊèêË≠∞‰ΩøÁî®„ÄåÂÖàÁî¢ÁîüÂÜçÈñ±ËÆÄ„ÄçÁÆ°Á∑öÔºå‰ª• LLM Êú¨Ë∫´ÁöÑÁî¢ÁîüÂèñ‰ª£Êì∑ÂèñÈöéÊÆµ„ÄÇÂÑòÁÆ°ÂæàÊúâÂâçÊôØÔºå‰ΩÜÈÄôÂÄãÁ†îÁ©∂ÊñπÂêë‰ªçÊú™Ë¢´ÂÖÖÂàÜÊé¢Ë®éÔºåËÄå‰∏îÂú®Êèê‰æõ‰æÜÊ∫êÁü•Ë≠òÁöÑÊÉÖÊ≥Å‰∏ã‰ªçÁÑ∂ÁÑ°Ê≥ïÈÅã‰Ωú„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊ≠£ÂºèÂà∂ÂÆö‰∫Ü‰∏ÄÂÄãÈÄöÁî®ÁöÑ„ÄåA + B„ÄçÊû∂ÊßãÔºåÂÖ∂‰∏≠ÂåÖÂê´Âü∫Á§éÊ®°ÂûãÂíåÈ°ûÂûã‰∏çÂêåÁöÑÁµÑÂêàÔºå‰ª•ÈÄ≤Ë°åÁ≥ªÁµ±ÊÄßÁöÑË™øÊü•„ÄÇÊàëÂÄëÊé¢Ë®é‰∫Ü LLM ÁöÑÂü∫Á§éÁâàÊú¨ÂíåËÅäÂ§©Ê©üÂô®‰∫∫ÁâàÊú¨ÁöÑÂäüÊïàÔºå‰∏¶ÁôºÁèæÂÆÉÂÄë‰∏çÂêåÁöÑÂäüËÉΩÂàÜÂà•ÈÅ©Áî®ÊñºÁî¢ÁîüÂô® A ÂíåÈñ±ËÆÄÂô® B„ÄÇÂÆÉÂÄëÁöÑÁµÑÂêàÂßãÁµÇÂÑ™ÊñºÂñÆ‰∏ÄÊ®°ÂûãÔºåÂ∞§ÂÖ∂ÊòØÂú®Ë§áÈõúÁöÑÂ†¥ÊôØ‰∏≠„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÈÄèÈÅéÊåÅÁ∫åÂ≠∏ÁøíÂ∞á„ÄåA + B„ÄçÊû∂ÊßãÁöÑÊáâÁî®Êì¥Â±ïÂà∞Ê∂âÂèä‰æÜÊ∫êÊñá‰ª∂ÁöÑÂ†¥ÊôØÔºåËÆìÂ§ñÈÉ®Áü•Ë≠òËÉΩÂ§†Áõ¥Êé•Êï¥ÂêàÂà∞ LLM ‰∏≠„ÄÇÈÄôÁ®ÆÊñπÊ≥ï‰∏çÂÉÖÊúâÂä©ÊñºÊúâÊïàÁç≤ÂèñÊñ∞Áü•Ë≠òÔºåÈÇÑËÉΩËß£Ê±∫ÈÅ©ÊáâÂæåÂÆâÂÖ®ÊÄßËàáÊúâÁõäÊÄßÁöÑÊåëÊà∞„ÄÇÊú¨ÊñáÂº∑Ë™ø‰∫Ü„ÄåA + B„ÄçÊû∂ÊßãÁöÑÂ§öÂäüËÉΩÊÄßÔºåÂ±ïÁ§∫‰∫ÜÂÖ∂Âú®ÂêÑÁ®ÆÈ†òÂüüÂ¢ûÂº∑ LLM ÂØ¶ÈöõÊáâÁî®ÁöÑÊΩõÂäõ„ÄÇ

##### **Tox-BART: Leveraging Toxicity Attributes for Explanation Generation of Implicit Hate Speech**
2406.03953v1 by Neemesh Yadav, Sarah Masud, Vikram Goyal, Vikram Goyal, Md Shad Akhtar, Tanmoy Chakraborty

Employing language models to generate explanations for an incoming implicit
hate post is an active area of research. The explanation is intended to make
explicit the underlying stereotype and aid content moderators. The training
often combines top-k relevant knowledge graph (KG) tuples to provide world
knowledge and improve performance on standard metrics. Interestingly, our study
presents conflicting evidence for the role of the quality of KG tuples in
generating implicit explanations. Consequently, simpler models incorporating
external toxicity signals outperform KG-infused models. Compared to the
KG-based setup, we observe a comparable performance for SBIC (LatentHatred)
datasets with a performance variation of +0.44 (+0.49), +1.83 (-1.56), and
-4.59 (+0.77) in BLEU, ROUGE-L, and BERTScore. Further human evaluation and
error analysis reveal that our proposed setup produces more precise
explanations than zero-shot GPT-3.5, highlighting the intricate nature of the
task.

ÊëòË¶ÅÔºöÂà©Áî®Ë™ûË®ÄÊ®°ÂûãÁÇ∫‰∏ÄÂÄãÊöóÁ§∫ÊÄßÁöÑ‰ªáÊÅ®ÊñáÁ´†Áî¢ÁîüËß£ÈáãÊòØ‰∏ÄÂÄãÊ¥ªË∫çÁöÑÁ†îÁ©∂È†òÂüü„ÄÇÈÄôÂÄãËß£ÈáãÁöÑÁõÆÁöÑÊòØË¶ÅÊòéÁ¢∫ÊΩõÂú®ÁöÑÂàªÊùøÂç∞Ë±°‰∏¶ÂçîÂä©ÂÖßÂÆπÁÆ°ÁêÜÂì°„ÄÇË®ìÁ∑¥ÈÄöÂ∏∏ÁµêÂêàÂâç k ÂÄãÁõ∏ÈóúÁü•Ë≠òÂúñË≠ú (KG) ÂÖÉÁµÑ‰ª•Êèê‰æõ‰∏ñÁïåÁü•Ë≠ò‰∏¶ÊîπÂñÑÊ®ôÊ∫ñÊåáÊ®ôÁöÑÊïàËÉΩ„ÄÇÊúâË∂£ÁöÑÊòØÔºåÊàëÂÄëÁöÑÁ†îÁ©∂ÊèêÂá∫ÁüõÁõæÁöÑË≠âÊìöÔºåË™™Êòé KG ÂÖÉÁµÑÁöÑÂìÅË≥™Âú®Áî¢ÁîüÊöóÁ§∫ÊÄßËß£Èáã‰∏≠ÊâÄÊâÆÊºîÁöÑËßíËâ≤„ÄÇÂõ†Ê≠§ÔºåÁµêÂêàÂ§ñÈÉ®ÊØíÊÄßË®äËôüÁöÑËºÉÁ∞°ÂñÆÊ®°ÂûãÂÑ™ÊñºËûçÂÖ• KG ÁöÑÊ®°Âûã„ÄÇËàáÂü∫Êñº KG ÁöÑË®≠ÂÆöÁõ∏ÊØîÔºåÊàëÂÄëËßÄÂØüÂà∞ SBIC (LatentHatred) Ë≥áÊñôÈõÜÊúâÁõ∏ËøëÁöÑÊïàËÉΩÔºåÂú® BLEU„ÄÅROUGE-L Âíå BERTScore ‰∏≠ÊïàËÉΩËÆäÂåñÁÇ∫ +0.44 (+0.49)„ÄÅ+1.83 (-1.56) Âíå -4.59 (+0.77)„ÄÇÈÄ≤‰∏ÄÊ≠•ÁöÑ‰∫∫È°ûË©ï‰º∞ÂíåÈåØË™§ÂàÜÊûêÈ°ØÁ§∫ÔºåÊàëÂÄëÊèêÂá∫ÁöÑË®≠ÂÆöÁî¢ÁîüÊØîÈõ∂Ê¨°Â≠∏Áøí GPT-3.5 Êõ¥Á≤æÁ¢∫ÁöÑËß£ÈáãÔºåÁ™ÅÈ°ØÂá∫Ê≠§‰ªªÂãôÁöÑË§áÈõúÊú¨Ë≥™„ÄÇ

##### **UltraMedical: Building Specialized Generalists in Biomedicine**
2406.03949v1 by Kaiyan Zhang, Sihang Zeng, Ermo Hua, Ning Ding, Zhang-Ren Chen, Zhiyuan Ma, Haoxin Li, Ganqu Cui, Biqing Qi, Xuekai Zhu, Xingtai Lv, Hu Jinfang, Zhiyuan Liu, Bowen Zhou

Large Language Models (LLMs) have demonstrated remarkable capabilities across
various domains and are moving towards more specialized areas. Recent advanced
proprietary models such as GPT-4 and Gemini have achieved significant
advancements in biomedicine, which have also raised privacy and security
challenges. The construction of specialized generalists hinges largely on
high-quality datasets, enhanced by techniques like supervised fine-tuning and
reinforcement learning from human or AI feedback, and direct preference
optimization. However, these leading technologies (e.g., preference learning)
are still significantly limited in the open source community due to the
scarcity of specialized data. In this paper, we present the UltraMedical
collections, which consist of high-quality manual and synthetic datasets in the
biomedicine domain, featuring preference annotations across multiple advanced
LLMs. By utilizing these datasets, we fine-tune a suite of specialized medical
models based on Llama-3 series, demonstrating breathtaking capabilities across
various medical benchmarks. Moreover, we develop powerful reward models skilled
in biomedical and general reward benchmark, enhancing further online preference
learning within the biomedical LLM community.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤Âú®ÂêÑÁ®ÆÈ†òÂüüÂ±ïÁèæÂá∫ÈùûÂá°ÁöÑËÉΩÂäõÔºå‰∏¶Ê≠£ÊúùÂêëÊõ¥Â∞àÊ•≠ÁöÑÈ†òÂüüÈÇÅÈÄ≤„ÄÇÊúÄËøëÈÄ≤Ê≠•ÁöÑÂ∞àÊúâÊ®°ÂûãÔºå‰æãÂ¶Ç GPT-4 Âíå GeminiÔºåÂú®ÁîüÁâ©ÈÜ´Â≠∏È†òÂüüÂèñÂæóÈ°ØËëóÈÄ≤Â±ïÔºå‰ΩÜ‰πüÂºïÁôº‰∫ÜÈö±ÁßÅÂíåÂÆâÂÖ®ÊåëÊà∞„ÄÇÂ∞àÈñÄÈÄöÊâçÁöÑÂª∫ÊßãÂú®ÂæàÂ§ßÁ®ãÂ∫¶‰∏äÂèñÊ±∫ÊñºÈ´òÂìÅË≥™ÁöÑË≥áÊñôÈõÜÔºå‰∏¶ÈÄèÈÅéÁõ£Áù£ÂæÆË™øÂíå‰∫∫È°ûÊàñ AI ÂõûÈ•ãÁöÑÂº∑ÂåñÂ≠∏ÁøíÁ≠âÊäÄË°ìÂä†‰ª•Â¢ûÂº∑Ôºå‰ª•ÂèäÁõ¥Êé•ÂÅèÂ•ΩÊúÄ‰Ω≥Âåñ„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÈ†òÂÖàÊäÄË°ìÔºà‰æãÂ¶ÇÂÅèÂ•ΩÂ≠∏ÁøíÔºâÁî±ÊñºÁº∫‰πèÂ∞àÈñÄË≥áÊñôÔºåÂú®ÈñãÊ∫êÁ§æÁæ§‰∏≠‰ªçÂèóÂà∞È°ØËëóÈôêÂà∂„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü UltraMedical Ë≥áÊñôÈõÜÔºåÂÖ∂‰∏≠ÂåÖÂê´ÁîüÁâ©ÈÜ´Â≠∏È†òÂüüÁöÑÈ´òÂìÅË≥™ÊâãÂãïÂíåÂêàÊàêË≥áÊñôÈõÜÔºåÂÖ∑ÊúâË∑®Â§öÂÄãÈÄ≤Èöé LLM ÁöÑÂÅèÂ•ΩÊ®ôË®ª„ÄÇÈÄèÈÅéÂà©Áî®ÈÄô‰∫õË≥áÊñôÈõÜÔºåÊàëÂÄëÂæÆË™ø‰∫Ü‰∏ÄÁ≥ªÂàóÂü∫Êñº Llama-3 Á≥ªÂàóÁöÑÂ∞àÊ•≠ÈÜ´ÁôÇÊ®°ÂûãÔºåÂ±ïÁ§∫‰∫ÜË∑®ÂêÑÁ®ÆÈÜ´ÁôÇÂü∫Ê∫ñÁöÑÈ©ö‰∫∫ËÉΩÂäõ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÈñãÁôº‰∫ÜÂú®ÁîüÁâ©ÈÜ´Â≠∏Âíå‰∏ÄËà¨ÂõûÈ•ãÂü∫Ê∫ñÊñπÈù¢ÊäÄË°ìÈ´òË∂ÖÁöÑÂº∑Â§ßÂõûÈ•ãÊ®°ÂûãÔºåÈÄ≤‰∏ÄÊ≠•Â¢ûÂº∑‰∫ÜÁîüÁâ©ÈÜ´Â≠∏ LLM Á§æÁæ§ÂÖßÁöÑÁ∑ö‰∏äÂÅèÂ•ΩÂ≠∏Áøí„ÄÇ

##### **Culturally Aware and Adapted NLP: A Taxonomy and a Survey of the State of the Art**
2406.03930v1 by Chen Cecilia Liu, Iryna Gurevych, Anna Korhonen

The surge of interest in culturally aware and adapted Natural Language
Processing (NLP) has inspired much recent research. However, the lack of common
understanding of the concept of "culture" has made it difficult to evaluate
progress in this emerging area. Drawing on prior research in NLP and related
fields, we propose an extensive taxonomy of elements of culture that can
provide a systematic framework for analyzing and understanding research
progress. Using the taxonomy, we survey existing resources and models for
culturally aware and adapted NLP, providing an overview of the state of the art
and the research gaps that still need to be filled.

ÊëòË¶ÅÔºöËøëÂπ¥‰æÜÔºåÂ∞çÊñáÂåñÊÑüÁü•ÂíåÈÅ©ÊáâÁöÑËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ (NLP) ÁöÑËààË∂£ÊøÄÂ¢ûÔºåÊøÄÁôº‰∫ÜË®±Â§öËøëÊúüÁ†îÁ©∂„ÄÇÁÑ∂ËÄåÔºåÁî±ÊñºÂ∞ç„ÄåÊñáÂåñ„ÄçÊ¶ÇÂøµÁº∫‰πèÂÖ±Ë≠òÔºå‰ΩøÂæóÈõ£‰ª•Ë©ï‰º∞ÈÄôÂÄãÊñ∞ËààÈ†òÂüüÁöÑÈÄ≤Â±ï„ÄÇÊàëÂÄëÂÄüÈëë‰∫Ü NLP ÂèäÁõ∏ÈóúÈ†òÂüüÂÖàÂâçÁöÑÁ†îÁ©∂ÔºåÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂª£Ê≥õÁöÑÊñáÂåñÂÖÉÁ¥†ÂàÜÈ°ûÊ≥ïÔºåÂèØ‰ª•Êèê‰æõ‰∏ÄÂÄãÁ≥ªÁµ±ÊÄßÁöÑÊû∂Êßã‰æÜÂàÜÊûêÂíåÁêÜËß£Á†îÁ©∂ÈÄ≤Â∫¶„ÄÇ‰ΩøÁî®ÈÄôÂÄãÂàÜÈ°ûÊ≥ïÔºåÊàëÂÄëË™øÊü•‰∫ÜÁèæÊúâÁöÑË≥áÊ∫êÂíåÊ®°ÂûãÔºå‰ª•‰∫ÜËß£ÊñáÂåñÊÑüÁü•ÂíåÈÅ©ÊáâÁöÑ NLPÔºåÊ¶ÇËø∞‰∫ÜÁï∂ÂâçÊäÄË°ìÊ∞¥Ê∫ñÂíå‰ªçÈúÄË¶ÅÂ°´Ë£úÁöÑÁ†îÁ©∂Á©∫ÁôΩ„ÄÇ

##### **Vectorized Conditional Neural Fields: A Framework for Solving Time-dependent Parametric Partial Differential Equations**
2406.03919v1 by Jan Hagnberger, Marimuthu Kalimuthu, Daniel Musekamp, Mathias Niepert

Transformer models are increasingly used for solving Partial Differential
Equations (PDEs). Several adaptations have been proposed, all of which suffer
from the typical problems of Transformers, such as quadratic memory and time
complexity. Furthermore, all prevalent architectures for PDE solving lack at
least one of several desirable properties of an ideal surrogate model, such as
(i) generalization to PDE parameters not seen during training, (ii) spatial and
temporal zero-shot super-resolution, (iii) continuous temporal extrapolation,
(iv) support for 1D, 2D, and 3D PDEs, and (v) efficient inference for longer
temporal rollouts. To address these limitations, we propose Vectorized
Conditional Neural Fields (VCNeFs), which represent the solution of
time-dependent PDEs as neural fields. Contrary to prior methods, however,
VCNeFs compute, for a set of multiple spatio-temporal query points, their
solutions in parallel and model their dependencies through attention
mechanisms. Moreover, VCNeF can condition the neural field on both the initial
conditions and the parameters of the PDEs. An extensive set of experiments
demonstrates that VCNeFs are competitive with and often outperform existing
ML-based surrogate models.

ÊëòË¶ÅÔºöTransformerÊ®°ÂûãÊó•ÁõäÁî®ÊñºÊ±ÇËß£ÂÅèÂæÆÂàÜÊñπÁ®ãÂºè (PDE)„ÄÇÂ∑≤Á∂ìÊèêÂá∫Â§öÁ®ÆÊîπÁ∑®ÔºåÊâÄÊúâÈÄô‰∫õÈÉΩÈÅ≠ÂèóTransformerÁöÑÂÖ∏ÂûãÂïèÈ°åÔºå‰æãÂ¶Ç‰∫åÊ¨°Ë®òÊÜ∂È´îÂíåÊôÇÈñìË§áÈõúÂ∫¶„ÄÇÊ≠§Â§ñÔºåÊâÄÊúâÊµÅË°åÁöÑ PDE Ê±ÇËß£Êû∂ÊßãÈÉΩËá≥Â∞ëÁº∫Â∞ëÁêÜÊÉ≥‰ª£ÁêÜÊ®°ÂûãÁöÑÂπæÂÄãÁêÜÊÉ≥Â±¨ÊÄßÔºå‰æãÂ¶Ç (i) Êé®Âª£Âà∞Ë®ìÁ∑¥ÊúüÈñìÊú™Ë¶ãÁöÑ PDE ÂèÉÊï∏Ôºå(ii) Á©∫ÈñìÂíåÊôÇÈñìÈõ∂Ê¨°Ë∂ÖËß£ÊûêÂ∫¶Ôºå(iii) ÈÄ£Á∫åÊôÇÈñìÂ§ñÊé®Ôºå(iv) ÊîØÊè¥ 1D„ÄÅ2D Âíå 3D PDEÔºå‰ª•Âèä (v) Â∞çËºÉÈï∑ÊôÇÈñìÊªæÂãïÁöÑÊúâÊïàÊé®Ë´ñ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÈôêÂà∂ÔºåÊàëÂÄëÊèêÂá∫ÂêëÈáèÂåñÊ¢ù‰ª∂Á•ûÁ∂ìÂ†¥ (VCNeF)ÔºåÂÆÉÂ∞áÊôÇÈñìÁõ∏Èóú PDE ÁöÑËß£Ë°®Á§∫ÁÇ∫Á•ûÁ∂ìÂ†¥„ÄÇÁÑ∂ËÄåÔºåËàáÂÖàÂâçÁöÑËæ¶Ê≥ïÁõ∏ÂèçÔºåVCNeF Â∞ç‰∏ÄÁµÑÂ§öÈáçÊôÇÁ©∫Êü•Ë©¢ÈªûË®àÁÆóÂÆÉÂÄëÁöÑËß£Ôºå‰∏¶ÈÄèÈÅéÊ≥®ÊÑèÂäõÊ©üÂà∂Âª∫Ê®°ÂÆÉÂÄëÁöÑ‰æùË≥¥ÊÄß„ÄÇÊ≠§Â§ñÔºåVCNeF ÂèØ‰ª•Â∞áÁ•ûÁ∂ìÂ†¥Ë®≠ÂÆöÂú® PDE ÁöÑÂàùÂßãÊ¢ù‰ª∂ÂíåÂèÉÊï∏‰∏ä„ÄÇÂ§ßÈáèÁöÑÂØ¶È©óË≠âÊòéÔºåVCNeF ËàáÁèæÊúâÁöÑÂü∫Êñº ML ÁöÑ‰ª£ÁêÜÊ®°ÂûãÂÖ∑ÊúâÁ´∂Áà≠ÂäõÔºåËÄå‰∏îÈÄöÂ∏∏Ë°®ÁèæÂÑ™Áï∞„ÄÇ

##### **ArMeme: Propagandistic Content in Arabic Memes**
2406.03916v1 by Firoj Alam, Abul Hasnat, Fatema Ahmed, Md Arid Hasan, Maram Hasanain

With the rise of digital communication, memes have become a significant
medium for cultural and political expression that is often used to mislead
audiences. Identification of such misleading and persuasive multimodal content
has become more important among various stakeholders, including social media
platforms, policymakers, and the broader society as they often cause harm to
individuals, organizations, and/or society. While there has been effort to
develop AI-based automatic systems for resource-rich languages (e.g., English),
it is relatively little to none for medium to low resource languages. In this
study, we focused on developing an Arabic memes dataset with manual annotations
of propagandistic content. We annotated ~6K Arabic memes collected from various
social media platforms, which is a first resource for Arabic multimodal
research. We provide a comprehensive analysis aiming to develop computational
tools for their detection. We will make them publicly available for the
community.

ÊëòË¶ÅÔºöÈö®ËëóÊï∏‰ΩçÈÄöË®äÁöÑËààËµ∑ÔºåËø∑Âõ†Â∑≤ÊàêÁÇ∫ÊñáÂåñÂíåÊîøÊ≤ªË°®ÈÅîÁöÑÈáçË¶ÅÂ™í‰ªãÔºåÂ∏∏Ë¢´Áî®ÊñºË™§Â∞éÂèóÁúæ„ÄÇË≠òÂà•Ê≠§È°ûÂÖ∑ÊúâË™§Â∞éÊÄßÂíåË™™ÊúçÂäõÁöÑÂ§öÊ®°ÊÖãÂÖßÂÆπÂ∑≤ÊàêÁÇ∫ÂêÑÂà©ÁõäÁõ∏ÈóúËÄÖ‰πãÈñìÊõ¥ÈáçË¶ÅÁöÑ‰∫ãÔºåÂåÖÊã¨Á§æÁæ§Â™íÈ´îÂπ≥Âè∞„ÄÅÊîøÁ≠ñÂà∂ÂÆöËÄÖÂíåÂª£Â§ßÁ§æÊúÉÔºåÂõ†ÁÇ∫ÂÆÉÂÄëÈÄöÂ∏∏ÊúÉÂ∞çÂÄã‰∫∫„ÄÅÁµÑÁπîÂíå/ÊàñÁ§æÊúÉÈÄ†ÊàêÂÇ∑ÂÆ≥„ÄÇÈõñÁÑ∂Â∑≤Âä™ÂäõÁÇ∫Ë≥áÊ∫êË±êÂØåÁöÑË™ûË®ÄÔºà‰æãÂ¶ÇËã±Ë™ûÔºâÈñãÁôºÂü∫Êñº AI ÁöÑËá™ÂãïÁ≥ªÁµ±Ôºå‰ΩÜÂ∞çÊñº‰∏≠‰ΩéË≥áÊ∫êË™ûË®Ä‰æÜË™™ÂçªÁõ∏Â∞çËºÉÂ∞ëÁîöËá≥Ê≤íÊúâ„ÄÇÂú®Êú¨Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëÂ∞àÊ≥®ÊñºÈñãÁôºÂÖ∑ÊúâÂÆ£ÂÇ≥ÂÖßÂÆπÊâãÂãïË®ªËß£ÁöÑÈòøÊãâ‰ºØËø∑Âõ†Ë≥áÊñôÈõÜ„ÄÇÊàëÂÄëË®ªËß£‰∫ÜÂæûÂêÑÁ®ÆÁ§æÁæ§Â™íÈ´îÂπ≥Âè∞Êî∂ÈõÜÁöÑÁ¥Ñ 6K ÂÄãÈòøÊãâ‰ºØËø∑Âõ†ÔºåÈÄôÊòØÈòøÊãâ‰ºØÂ§öÊ®°ÊÖãÁ†îÁ©∂ÁöÑÁ¨¨‰∏ÄÂÄãË≥áÊ∫ê„ÄÇÊàëÂÄëÊèê‰æõÂÖ®Èù¢ÁöÑÂàÜÊûêÔºåÊó®Âú®ÁÇ∫ÂÖ∂ÂÅµÊ∏¨ÈñãÁôºÈÅãÁÆóÂ∑•ÂÖ∑„ÄÇÊàëÂÄëÂ∞áËÆìÂÆÉÂÄëÂÖ¨ÈñãÊèê‰æõÁµ¶Á§æÁæ§„ÄÇ

##### **GenSafe: A Generalizable Safety Enhancer for Safe Reinforcement Learning Algorithms Based on Reduced Order Markov Decision Process Model**
2406.03912v1 by Zhehua Zhou, Xuan Xie, Jiayang Song, Zhan Shu, Lei Ma

Although deep reinforcement learning has demonstrated impressive achievements
in controlling various autonomous systems, e.g., autonomous vehicles or
humanoid robots, its inherent reliance on random exploration raises safety
concerns in their real-world applications. To improve system safety during the
learning process, a variety of Safe Reinforcement Learning (SRL) algorithms
have been proposed, which usually incorporate safety constraints within the
Constrained Markov Decision Process (CMDP) framework. However, the efficacy of
these SRL algorithms often relies on accurate function approximations, a task
that is notably challenging to accomplish in the early learning stages due to
data insufficiency. To address this problem, we introduce a Genralizable Safety
enhancer (GenSafe) in this work. Leveraging model order reduction techniques,
we first construct a Reduced Order Markov Decision Process (ROMDP) as a
low-dimensional proxy for the original cost function in CMDP. Then, by solving
ROMDP-based constraints that are reformulated from the original cost
constraints, the proposed GenSafe refines the actions taken by the agent to
enhance the possibility of constraint satisfaction. Essentially, GenSafe acts
as an additional safety layer for SRL algorithms, offering broad compatibility
across diverse SRL approaches. The performance of GenSafe is examined on
multiple SRL benchmark problems. The results show that, it is not only able to
improve the safety performance, especially in the early learning phases, but
also to maintain the task performance at a satisfactory level.

ÊëòË¶ÅÔºöÂÑòÁÆ°Ê∑±Â∫¶Âº∑ÂåñÂ≠∏ÁøíÂú®ÊéßÂà∂ÂêÑÁ®ÆËá™‰∏ªÁ≥ªÁµ±‰∏≠Â∑≤Â±ïÁèæ‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑÊàêÂ∞±Ôºå‰æãÂ¶ÇÔºåËá™‰∏ªËªäËºõÊàñÈ°û‰∫∫Ê©üÂô®‰∫∫ÔºåÂÖ∂Â∞çÈö®Ê©üÊé¢Á¥¢ÁöÑÂÖßÂú®‰æùË≥¥ÊÄßÂçªÂú®ÂØ¶ÈöõÊáâÁî®‰∏≠ÂºïÁôº‰∫ÜÂÆâÂÖ®ÁñëÊÖÆ„ÄÇÁÇ∫‰∫ÜÂú®Â≠∏ÁøíÈÅéÁ®ã‰∏≠ÊèêÂçáÁ≥ªÁµ±ÂÆâÂÖ®ÊÄßÔºåÂ∑≤Á∂ìÊèêÂá∫Â§öÁ®ÆÂÆâÂÖ®Âº∑ÂåñÂ≠∏Áøí (SRL) ÊºîÁÆóÊ≥ïÔºåÈÄô‰∫õÊºîÁÆóÊ≥ïÈÄöÂ∏∏Âú®ÂèóÈôêÈ¶¨ÂèØÂ§´Ê±∫Á≠ñÈÅéÁ®ã (CMDP) Êû∂Êßã‰∏≠Á¥çÂÖ•ÂÆâÂÖ®Á¥ÑÊùü„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õ SRL ÊºîÁÆóÊ≥ïÁöÑÊïàËÉΩÈÄöÂ∏∏‰æùË≥¥ÊñºÁ≤æÁ¢∫ÁöÑÂáΩÊï∏Ëøë‰ººÂÄºÔºåËÄåÈÄôÈ†Ö‰ªªÂãôÂú®Êó©ÊúüÂ≠∏ÁøíÈöéÊÆµÁî±ÊñºË≥áÊñô‰∏çË∂≥ËÄåÈõ£‰ª•ÈÅîÊàê„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÂºïÂÖ•‰∫ÜÂèØÊ¶ÇÂåñÂÆâÂÖ®ÊÄßÂ¢ûÂº∑Âô® (GenSafe)„ÄÇÊàëÂÄëÈ¶ñÂÖàÂà©Áî®Ê®°ÂûãÈöéÊï∏Á∞°ÂåñÊäÄË°ìÔºåÂ∞áÂèóÈôêÈ¶¨ÂèØÂ§´Ê±∫Á≠ñÈÅéÁ®ã (ROMDP) Âª∫ÊßãÁÇ∫ CMDP ‰∏≠ÂéüÂßãÊàêÊú¨ÂáΩÊï∏ÁöÑ‰ΩéÁ∂≠Â∫¶‰ª£ÁêÜ„ÄÇÁÑ∂ÂæåÔºåÈÄèÈÅéÊ±ÇËß£ÂæûÂéüÂßãÊàêÊú¨Á¥ÑÊùüÈáçÊñ∞Âà∂ÂÆöÁöÑÂü∫Êñº ROMDP ÁöÑÁ¥ÑÊùüÔºåÊâÄÊèêÂá∫ÁöÑ GenSafe ÊúÉ‰øÆÊ≠£‰ª£ÁêÜÊé°ÂèñÁöÑÂãï‰ΩúÔºå‰ª•ÊèêÂçáÁ¥ÑÊùüÊªøË∂≥ÁöÑÂèØËÉΩÊÄß„ÄÇGenSafe Êú¨Ë≥™‰∏ä‰ΩúÁÇ∫ SRL ÊºîÁÆóÊ≥ïÁöÑÈ°çÂ§ñÂÆâÂÖ®Â±§ÔºåÂú®ÂêÑÁ®Æ SRL ÊñπÊ≥ï‰∏≠Êèê‰æõÂª£Ê≥õÁöÑÁõ∏ÂÆπÊÄß„ÄÇGenSafe ÁöÑÊïàËÉΩÂ∑≤Âú®Â§öÂÄã SRL Âü∫Ê∫ñÂïèÈ°å‰∏≠ÂæóÂà∞Ê™¢È©ó„ÄÇÁµêÊûúÈ°ØÁ§∫ÔºåÂÆÉ‰∏çÂÉÖËÉΩÂ§†ÊèêÂçáÂÆâÂÖ®ÊÄßÊïàËÉΩÔºåÁâπÂà•ÊòØÂú®Êó©ÊúüÂ≠∏ÁøíÈöéÊÆµÔºåÈÇÑËÉΩÂ∞á‰ªªÂãôÊïàËÉΩÁ∂≠ÊåÅÂú®‰ª§‰∫∫ÊªøÊÑèÁöÑÊ∞¥Ê∫ñ„ÄÇ

##### **HeSum: a Novel Dataset for Abstractive Text Summarization in Hebrew**
2406.03897v1 by Tzuf Paz-Argaman, Itai Mondshine, Asaf Achi Mordechai, Reut Tsarfaty

While large language models (LLMs) excel in various natural language tasks in
English, their performance in lower-resourced languages like Hebrew, especially
for generative tasks such as abstractive summarization, remains unclear. The
high morphological richness in Hebrew adds further challenges due to the
ambiguity in sentence comprehension and the complexities in meaning
construction. In this paper, we address this resource and evaluation gap by
introducing HeSum, a novel benchmark specifically designed for abstractive text
summarization in Modern Hebrew. HeSum consists of 10,000 article-summary pairs
sourced from Hebrew news websites written by professionals. Linguistic analysis
confirms HeSum's high abstractness and unique morphological challenges. We show
that HeSum presents distinct difficulties for contemporary state-of-the-art
LLMs, establishing it as a valuable testbed for generative language technology
in Hebrew, and MRLs generative challenges in general.

ÊëòË¶ÅÔºöÂÑòÁÆ°Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®Ëã±Ë™ûÁöÑÂêÑÁ®ÆËá™ÁÑ∂Ë™ûË®Ä‰ªªÂãô‰∏≠Ë°®ÁèæÂá∫Ëâ≤Ôºå‰ΩÜÂÆÉÂÄëÂú®Â∏å‰ºØ‰æÜË™ûÁ≠âË≥áÊ∫êËºÉÂ∞ëÁöÑË™ûË®Ä‰∏≠ÁöÑË°®ÁèæÔºåÁâπÂà•ÊòØÂú®ÊäΩË±°ÊëòË¶ÅÁ≠âÁîüÊàê‰ªªÂãô‰∏≠Ôºå‰ªç‰∏çÊòéÊúó„ÄÇÂ∏å‰ºØ‰æÜË™û‰∏≠Ë±êÂØåÁöÑÂΩ¢ÊÖãË±êÂØåÊÄßÂ¢ûÂä†‰∫ÜÈÄ≤‰∏ÄÊ≠•ÁöÑÊåëÊà∞ÔºåÂõ†ÁÇ∫Âè•Â≠êÁêÜËß£‰∏≠ÁöÑÂê´Á≥äÊÄß‰ª•ÂèäÊÑèÁæ©Âª∫ÊßãÁöÑË§áÈõúÊÄß„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÈÄöÈÅéÂºïÂÖ• HeSum ‰æÜËß£Ê±∫ÈÄôÂÄãË≥áÊ∫êÂíåË©ï‰º∞Â∑ÆË∑ùÔºåHeSum ÊòØ‰∏ÄÂÄãÂ∞àÈñÄÁÇ∫Áèæ‰ª£Â∏å‰ºØ‰æÜË™ûÁöÑÊäΩË±°ÊñáÊú¨ÊëòË¶ÅËÄåË®≠Ë®àÁöÑÊñ∞Âü∫Ê∫ñ„ÄÇHeSum ÂåÖÂê´ 10,000 Â∞çÊñáÁ´†ÊëòË¶ÅÔºåÈÄô‰∫õÊëòË¶Å‰æÜËá™Áî±Â∞àÊ•≠‰∫∫Â£´Êí∞ÂØ´ÁöÑÂ∏å‰ºØ‰æÜË™ûÊñ∞ËÅûÁ∂≤Á´ô„ÄÇË™ûË®ÄÂàÜÊûêË≠âÂØ¶‰∫Ü HeSum ÁöÑÈ´òÂ∫¶ÊäΩË±°ÊÄßÂíåÁç®ÁâπÁöÑÂΩ¢ÊÖãÊåëÊà∞„ÄÇÊàëÂÄëË°®ÊòéÔºåHeSum Â∞çÁï∂‰ª£ÊúÄÂÖàÈÄ≤ÁöÑ LLM ÊßãÊàê‰∫Ü‰∏çÂêåÁöÑÂõ∞Èõ£Ôºå‰ΩøÂÖ∂ÊàêÁÇ∫Â∏å‰ºØ‰æÜË™ûÁîüÊàêË™ûË®ÄÊäÄË°ìÁöÑÂØ∂Ë≤¥Ê∏¨Ë©¶Âπ≥Âè∞Ôºå‰ª•Âèä‰∏ÄËà¨ MRL ÁîüÊàêÊåëÊà∞„ÄÇ

##### **How Good is Zero-Shot MT Evaluation for Low Resource Indian Languages?**
2406.03893v1 by Anushka Singh, Ananya B. Sai, Raj Dabre, Ratish Puduppully, Anoop Kunchukuttan, Mitesh M Khapra

While machine translation evaluation has been studied primarily for
high-resource languages, there has been a recent interest in evaluation for
low-resource languages due to the increasing availability of data and models.
In this paper, we focus on a zero-shot evaluation setting focusing on
low-resource Indian languages, namely Assamese, Kannada, Maithili, and Punjabi.
We collect sufficient Multi-Dimensional Quality Metrics (MQM) and Direct
Assessment (DA) annotations to create test sets and meta-evaluate a plethora of
automatic evaluation metrics. We observe that even for learned metrics, which
are known to exhibit zero-shot performance, the Kendall Tau and Pearson
correlations with human annotations are only as high as 0.32 and 0.45.
Synthetic data approaches show mixed results and overall do not help close the
gap by much for these languages. This indicates that there is still a long way
to go for low-resource evaluation.

ÊëòË¶ÅÔºöÂÑòÁÆ°Ê©üÂô®ÁøªË≠ØË©ï‰º∞‰∏ªË¶ÅÈáùÂ∞çÈ´òË≥áÊ∫êË™ûË®ÄÈÄ≤Ë°åÁ†îÁ©∂Ôºå‰ΩÜÁî±ÊñºË≥áÊñôÂíåÊ®°ÂûãÁöÑÂèØÁî®ÊÄßÂ¢ûÂä†ÔºåÊúÄËøëÈñãÂßãÊúâ‰∫∫ÈóúÊ≥®‰ΩéË≥áÊ∫êË™ûË®ÄÁöÑË©ï‰º∞„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂ∞àÊ≥®ÊñºÈõ∂Ê¨°Ë©ï‰º∞Ë®≠ÂÆöÔºåÈáçÈªûÊîæÂú®‰ΩéË≥áÊ∫êÂç∞Â∫¶Ë™ûË®ÄÔºåÂç≥ÈòøËñ©ÂßÜË™û„ÄÅÂç°Á¥çÈÅîË™û„ÄÅÈÇÅËíÇÂà©Ë™ûÂíåÊóÅÈÅÆÊôÆË™û„ÄÇÊàëÂÄëÊî∂ÈõÜË∂≥Â§†ÁöÑÂ§öÁ∂≠Â∫¶ÂìÅË≥™ÊåáÊ®ô (MQM) ÂíåÁõ¥Êé•Ë©ï‰º∞ (DA) Ê®ôË®ªÔºå‰ª•Âª∫Á´ãÊ∏¨Ë©¶ÈõÜ‰∏¶Â∞çÂ§ßÈáèËá™ÂãïË©ï‰º∞ÊåáÊ®ôÈÄ≤Ë°åÂÖÉË©ï‰º∞„ÄÇÊàëÂÄëËßÄÂØüÂà∞ÔºåÂç≥‰ΩøÂ∞çÊñºÂ∑≤Â≠∏ÁøíÁöÑÊåáÊ®ôÔºàÂ∑≤Áü•ÊúÉË°®ÁèæÂá∫Èõ∂Ê¨°ÊïàËÉΩÔºâÔºåËàá‰∫∫È°ûÊ®ôË®ªÁöÑ Kendall Tau Âíå Pearson Áõ∏ÈóúÊÄß‰πüÂÉÖÈ´òÈÅî 0.32 Âíå 0.45„ÄÇÂêàÊàêË≥áÊñôÊñπÊ≥ïÈ°ØÁ§∫Âá∫‰∏çÂêåÁöÑÁµêÊûúÔºåËÄå‰∏îÊï¥È´îËÄåË®ÄÔºåÂ∞çÊñºÈÄô‰∫õË™ûË®Ä‰∏¶Êú™Á∏ÆÂ∞èÂ∑ÆË∑ùÂ§™Â§ö„ÄÇÈÄôË°®Á§∫‰ΩéË≥áÊ∫êË©ï‰º∞‰ªçÊúâÂæàÈï∑‰∏ÄÊÆµË∑ØË¶ÅËµ∞„ÄÇ

##### **Spontaneous Speech-Based Suicide Risk Detection Using Whisper and Large Language Models**
2406.03882v1 by Ziyun Cui, Chang Lei, Wen Wu, Yinan Duan, Diyang Qu, Ji Wu, Runsen Chen, Chao Zhang

The early detection of suicide risk is important since it enables the
intervention to prevent potential suicide attempts. This paper studies the
automatic detection of suicide risk based on spontaneous speech from
adolescents, and collects a Mandarin dataset with 15 hours of suicide speech
from more than a thousand adolescents aged from ten to eighteen for our
experiments. To leverage the diverse acoustic and linguistic features embedded
in spontaneous speech, both the Whisper speech model and textual large language
models (LLMs) are used for suicide risk detection. Both all-parameter
finetuning and parameter-efficient finetuning approaches are used to adapt the
pre-trained models for suicide risk detection, and multiple audio-text fusion
approaches are evaluated to combine the representations of Whisper and the LLM.
The proposed system achieves a detection accuracy of 0.807 and an F1-score of
0.846 on the test set with 119 subjects, indicating promising potential for
real suicide risk detection applications.

ÊëòË¶ÅÔºöÊó©ÊúüÁôºÁèæËá™ÊÆ∫È¢®Èö™ÈùûÂ∏∏ÈáçË¶ÅÔºåÂõ†ÁÇ∫ÂÆÉËÉΩËÆìÂπ≤È†êÊé™ÊñΩÈ†êÈò≤ÊΩõÂú®ÁöÑËá™ÊÆ∫‰ºÅÂúñ„ÄÇÊú¨ÊñáÁ†îÁ©∂‰∫ÜÂü∫ÊñºÈùíÂ∞ëÂπ¥Ëá™ÁôºÊÄßË™ûË®ÄÁöÑËá™ÊÆ∫È¢®Èö™Ëá™ÂãïÊ™¢Ê∏¨Ôºå‰∏¶Êî∂ÈõÜ‰∫Ü‰∏ÄÂÄãÂåÖÂê´‰æÜËá™‰∏ÄÂçÉÂ§öÂêçÂπ¥ÈΩ°Âú®ÂçÅÂà∞ÂçÅÂÖ´Ê≠≤ÁöÑÈùíÂ∞ëÂπ¥ 15 Â∞èÊôÇÁöÑËá™ÊÆ∫Ë™ûÈü≥ÁöÑÊôÆÈÄöË©±Êï∏ÊìöÈõÜÔºå‰ª•ÈÄ≤Ë°åÊàëÂÄëÁöÑÂØ¶È©ó„ÄÇÁÇ∫‰∫ÜÂà©Áî®Ëá™ÁôºÊÄßË™ûË®Ä‰∏≠ÂµåÂÖ•ÁöÑÂ§öÊ®£ÂåñËÅ≤Â≠∏ÂíåË™ûË®ÄÁâπÂæµÔºåWhisper Ë™ûÈü≥Ê®°ÂûãÂíåÊñáÊú¨Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÈÉΩË¢´Áî®ÊñºËá™ÊÆ∫È¢®Èö™Ê™¢Ê∏¨„ÄÇÊâÄÊúâÂèÉÊï∏ÂæÆË™øÂíåÂèÉÊï∏È´òÊïàÂæÆË™øÊñπÊ≥ïÈÉΩÁî®ÊñºË™øÊï¥È†êË®ìÁ∑¥Ê®°Âûã‰ª•ÈÄ≤Ë°åËá™ÊÆ∫È¢®Èö™Ê™¢Ê∏¨Ôºå‰∏¶Ë©ï‰º∞‰∫ÜÂ§öÁ®ÆÈü≥È†ªÊñáÊú¨ËûçÂêàÊñπÊ≥ï‰ª•ÁµêÂêà Whisper Âíå LLM ÁöÑË°®Âæµ„ÄÇÊâÄÊèêÂá∫ÁöÑÁ≥ªÁµ±Âú®ÂåÖÂê´ 119 ÂêçÂèóË©¶ËÄÖÁöÑÊ∏¨Ë©¶ÈõÜ‰∏≠ÂØ¶Áèæ‰∫Ü 0.807 ÁöÑÊ™¢Ê∏¨Ê∫ñÁ¢∫ÁéáÂíå 0.846 ÁöÑ F1 ÂàÜÊï∏ÔºåË°®Êòé‰∫ÜÂ∞çÁúüÂØ¶Ëá™ÊÆ∫È¢®Èö™Ê™¢Ê∏¨ÊáâÁî®ÂÖ∑ÊúâËâØÂ•ΩÁöÑÊΩõÂäõ„ÄÇ

##### **Evaluating the IWSLT2023 Speech Translation Tasks: Human Annotations, Automatic Metrics, and Segmentation**
2406.03881v1 by Matthias Sperber, Ond≈ôej Bojar, Barry Haddow, D√°vid Javorsk√Ω, Xutai Ma, Matteo Negri, Jan Niehues, Peter Pol√°k, Elizabeth Salesky, Katsuhito Sudoh, Marco Turchi

Human evaluation is a critical component in machine translation system
development and has received much attention in text translation research.
However, little prior work exists on the topic of human evaluation for speech
translation, which adds additional challenges such as noisy data and
segmentation mismatches. We take first steps to fill this gap by conducting a
comprehensive human evaluation of the results of several shared tasks from the
last International Workshop on Spoken Language Translation (IWSLT 2023). We
propose an effective evaluation strategy based on automatic resegmentation and
direct assessment with segment context. Our analysis revealed that: 1) the
proposed evaluation strategy is robust and scores well-correlated with other
types of human judgements; 2) automatic metrics are usually, but not always,
well-correlated with direct assessment scores; and 3) COMET as a slightly
stronger automatic metric than chrF, despite the segmentation noise introduced
by the resegmentation step systems. We release the collected human-annotated
data in order to encourage further investigation.

ÊëòË¶ÅÔºö‰∫∫Â∑•Ë©ï‰º∞ÊòØÊ©üÂô®ÁøªË≠ØÁ≥ªÁµ±ÈñãÁôº‰∏≠ÁöÑÈóúÈçµÁµÑÊàêÈÉ®ÂàÜÔºå‰∏¶Âú®ÊñáÊú¨ÁøªË≠ØÁ†îÁ©∂‰∏≠ÂèóÂà∞Âª£Ê≥õÈóúÊ≥®„ÄÇ
ÁÑ∂ËÄåÔºåÂ∞çÊñºË™ûÈü≥ÁøªË≠ØÁöÑ‰∫∫Â∑•Ë©ï‰º∞‰∏ªÈ°åÔºåÁõÆÂâçÂπæ‰πéÊ≤íÊúâÂÖàÂâçÁöÑÁ†îÁ©∂ÔºåËÄåË™ûÈü≥ÁøªË≠ØÂ¢ûÂä†‰∫ÜÈ°çÂ§ñÁöÑÊåëÊà∞Ôºå‰æãÂ¶ÇÊúâÈõúË®äÁöÑË≥áÊñôÂíåÂàÜÊÆµ‰∏çÂåπÈÖç„ÄÇÊàëÂÄëÊé°ÂèñÁ¨¨‰∏ÄÊ≠•‰æÜÂ°´Ë£úÈÄô‰∏ÄÁ©∫ÁôΩÔºåÂ∞ç‰æÜËá™‰∏äÂ±ÜÂúãÈöõÂè£Ë™ûË™ûË®ÄÁøªË≠ØÁ†îË®éÊúÉ (IWSLT 2023) ÁöÑÂπæÂÄãÂÖ±‰∫´‰ªªÂãôÁöÑÁµêÊûúÈÄ≤Ë°åÂÖ®Èù¢ÁöÑ‰∫∫Â∑•Ë©ï‰º∞„ÄÇÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂü∫ÊñºËá™ÂãïÈáçÊñ∞ÂàÜÊÆµÂíåÁõ¥Êé•Ë©ï‰º∞ËàáÂàÜÊÆµ‰∏ä‰∏ãÊñáÁõ∏ÈóúÁöÑÊúâÊïàË©ï‰º∞Á≠ñÁï•„ÄÇÊàëÂÄëÁöÑÂàÜÊûêÈ°ØÁ§∫Ôºö1) ÊèêÂá∫ÁöÑË©ï‰º∞Á≠ñÁï•Âº∑ÂÅ•‰∏îË©ïÂàÜËàáÂÖ∂‰ªñÈ°ûÂûãÁöÑ‰∫∫Â∑•Âà§Êñ∑ÂÖ∑ÊúâËâØÂ•ΩÁöÑÁõ∏ÈóúÊÄßÔºõ2) Ëá™ÂãïÂåñÊåáÊ®ôÈÄöÂ∏∏Ôºà‰ΩÜ‰∏¶ÈùûÁ∏ΩÊòØÔºâËàáÁõ¥Êé•Ë©ï‰º∞ÂàÜÊï∏ÂÖ∑ÊúâËâØÂ•ΩÁöÑÁõ∏ÈóúÊÄßÔºõ3) COMET ÊòØ‰∏ÄÂÄãÁï•Âº∑Êñº chrF ÁöÑËá™ÂãïÂåñÊåáÊ®ôÔºåÂÑòÁÆ°ÈáçÊñ∞ÂàÜÊÆµÊ≠•È©üÁ≥ªÁµ±ÂºïÂÖ•‰∫ÜÂàÜÊÆµÈõúË®ä„ÄÇÊàëÂÄëÁôºÂ∏ÉÊî∂ÈõÜÂà∞ÁöÑ‰∫∫Â∑•Ê®ôË®ªË≥áÊñôÔºå‰ª•ÈºìÂãµÈÄ≤‰∏ÄÊ≠•ÁöÑÁ†îÁ©∂„ÄÇ

##### **Memorization in deep learning: A survey**
2406.03880v1 by Jiaheng Wei, Yanjun Zhang, Leo Yu Zhang, Ming Ding, Chao Chen, Kok-Leong Ong, Jun Zhang, Yang Xiang

Deep Learning (DL) powered by Deep Neural Networks (DNNs) has revolutionized
various domains, yet understanding the intricacies of DNN decision-making and
learning processes remains a significant challenge. Recent investigations have
uncovered an interesting memorization phenomenon in which DNNs tend to memorize
specific details from examples rather than learning general patterns, affecting
model generalization, security, and privacy. This raises critical questions
about the nature of generalization in DNNs and their susceptibility to security
breaches. In this survey, we present a systematic framework to organize
memorization definitions based on the generalization and security/privacy
domains and summarize memorization evaluation methods at both the example and
model levels. Through a comprehensive literature review, we explore DNN
memorization behaviors and their impacts on security and privacy. We also
introduce privacy vulnerabilities caused by memorization and the phenomenon of
forgetting and explore its connection with memorization. Furthermore, we
spotlight various applications leveraging memorization and forgetting
mechanisms, including noisy label learning, privacy preservation, and model
enhancement. This survey offers the first-in-kind understanding of memorization
in DNNs, providing insights into its challenges and opportunities for enhancing
AI development while addressing critical ethical concerns.

ÊëòË¶ÅÔºöÊ∑±Â∫¶Â≠∏Áøí (DL) Áî±Ê∑±Â∫¶Á•ûÁ∂ìÁ∂≤Ë∑Ø (DNN) ÊâÄÈ©ÖÂãïÔºåÂ∑≤ÂæπÂ∫ïÊîπËÆä‰∫ÜÂêÑÂÄãÈ†òÂüüÔºåÁÑ∂ËÄåË¶Å‰∫ÜËß£ DNN Ê±∫Á≠ñÂà∂ÂÆöÂíåÂ≠∏ÁøíÈÅéÁ®ãÁöÑË§áÈõúÊÄß‰ªçÁÑ∂ÊòØ‰∏ÄÈ†ÖÈáçÂ§ßÁöÑÊåëÊà∞„ÄÇÊúÄËøëÁöÑÁ†îÁ©∂ÁôºÁèæ‰∫Ü‰∏ÄÂÄãÊúâË∂£ÁöÑË®òÊÜ∂ÁèæË±°ÔºåDNN ÂÇæÂêëÊñºË®ò‰ΩèÁØÑ‰æã‰∏≠ÁöÑÁâπÂÆöÁ¥∞ÁØÄÔºåËÄå‰∏çÊòØÂ≠∏Áøí‰∏ÄËà¨Ê®°ÂºèÔºåÂΩ±ÈüøÊ®°ÂûãÁöÑÊ¶ÇÂåñ„ÄÅÂÆâÂÖ®ÊÄßËàáÈö±ÁßÅ„ÄÇÈÄôÂºïÁôº‰∫ÜÈóúÊñº DNN ‰∏≠Ê¶ÇÂåñÁöÑÊú¨Ë≥™ÂèäÂÖ∂Â∞çÂÆâÂÖ®ÊºèÊ¥ûÁöÑÊïèÊÑüÊÄßÁöÑÈóúÈçµÂïèÈ°å„ÄÇÂú®ÈÄôÈ†ÖË™øÊü•‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÁ≥ªÁµ±ÊÄßÊû∂Êßã‰æÜÊï¥ÁêÜÂü∫ÊñºÊ¶ÇÂåñËàáÂÆâÂÖ®/Èö±ÁßÅÈ†òÂüüÁöÑË®òÊÜ∂ÂÆöÁæ©Ôºå‰∏¶Âú®ÁØÑ‰æãÂíåÊ®°ÂûãÂ±§Á¥öÁ∏ΩÁµêË®òÊÜ∂Ë©ï‰º∞ÊñπÊ≥ï„ÄÇÈÄèÈÅéÂÖ®Èù¢ÁöÑÊñáÁçªÂõûÈ°ßÔºåÊàëÂÄëÊé¢Ë®é DNN Ë®òÊÜ∂Ë°åÁÇ∫ÂèäÂÖ∂Â∞çÂÆâÂÖ®ËàáÈö±ÁßÅÁöÑÂΩ±Èüø„ÄÇÊàëÂÄë‰πü‰ªãÁ¥πÁî±Ë®òÊÜ∂ÊâÄÈÄ†ÊàêÁöÑÈö±ÁßÅÊºèÊ¥ûÂíåÈÅ∫ÂøòÁèæË±°Ôºå‰∏¶Êé¢Ë®éÂÆÉËàáË®òÊÜ∂ÁöÑÈóúËÅØ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÈáçÈªû‰ªãÁ¥πÂà©Áî®Ë®òÊÜ∂ÂíåÈÅ∫ÂøòÊ©üÂà∂ÁöÑÂêÑÁ®ÆÊáâÁî®ÔºåÂåÖÊã¨ÈõúË®äÊ®ôÁ±§Â≠∏Áøí„ÄÅÈö±ÁßÅ‰øùË≠∑ÂíåÊ®°ÂûãÂ¢ûÂº∑„ÄÇÈÄôÈ†ÖË™øÊü•Êèê‰æõ‰∫ÜÁ¨¨‰∏ÄÂÄãÈóúÊñº DNN ‰∏≠Ë®òÊÜ∂ÁöÑÁêÜËß£ÔºåÊèê‰æõÂ∞çÂÖ∂ÊåëÊà∞ÂíåÊ©üÊúÉÁöÑË¶ãËß£Ôºå‰ª•Â¢ûÂº∑ AI ÈñãÁôºÔºåÂêåÊôÇËß£Ê±∫ÈóúÈçµÁöÑÂÄ´ÁêÜÂïèÈ°å„ÄÇ

##### **Decoder-only Streaming Transformer for Simultaneous Translation**
2406.03878v1 by Shoutao Guo, Shaolei Zhang, Yang Feng

Simultaneous Machine Translation (SiMT) generates translation while reading
source tokens, essentially producing the target prefix based on the source
prefix. To achieve good performance, it leverages the relationship between
source and target prefixes to exact a policy to guide the generation of
translations. Although existing SiMT methods primarily focus on the
Encoder-Decoder architecture, we explore the potential of Decoder-only
architecture, owing to its superior performance in various tasks and its
inherent compatibility with SiMT. However, directly applying the Decoder-only
architecture to SiMT poses challenges in terms of training and inference. To
alleviate the above problems, we propose the first Decoder-only SiMT model,
named Decoder-only Streaming Transformer (DST). Specifically, DST separately
encodes the positions of the source and target prefixes, ensuring that the
position of the target prefix remains unaffected by the expansion of the source
prefix. Furthermore, we propose a Streaming Self-Attention (SSA) mechanism
tailored for the Decoder-only architecture. It is capable of obtaining
translation policy by assessing the sufficiency of input source information and
integrating with the soft-attention mechanism to generate translations.
Experiments demonstrate that our approach achieves state-of-the-art performance
on three translation tasks.

ÊëòË¶ÅÔºöÂêåÊôÇÈñìÊ©üÂô®ÁøªË≠Ø (SiMT) Âú®ËÆÄÂèñÂéüÂßãË™ûË®ÄÁ¨¶ËôüÊôÇÁî¢ÁîüÁøªË≠ØÔºåÂü∫Êú¨‰∏äÊ†πÊìöÂéüÂßãË™ûË®ÄÂâçÁ∂¥Áî¢ÁîüÁõÆÊ®ôË™ûË®ÄÂâçÁ∂¥„ÄÇÁÇ∫‰∫ÜÈÅîÂà∞ËâØÂ•ΩÁöÑÊïàËÉΩÔºåÂÆÉÂà©Áî®ÂéüÂßãË™ûË®ÄÂíåÁõÆÊ®ôË™ûË®ÄÂâçÁ∂¥‰πãÈñìÁöÑÈóú‰øÇ‰æÜÂà∂ÂÆö‰∏ÄÂÄãÊ∫ñÂâáÔºå‰ª•ÂºïÂ∞éÁøªË≠ØÁöÑÁî¢Áîü„ÄÇÂÑòÁÆ°ÁèæÊúâÁöÑ SiMT ÊñπÊ≥ï‰∏ªË¶ÅÈóúÊ≥®Á∑®Á¢ºÂô®-Ëß£Á¢ºÂô®Êû∂ÊßãÔºå‰ΩÜÊàëÂÄëÊé¢Á¥¢‰∫ÜÂÉÖËß£Á¢ºÂô®Êû∂ÊßãÁöÑÊΩõÂäõÔºåÂõ†ÁÇ∫ÂÆÉÂú®ÂêÑÁ®Æ‰ªªÂãô‰∏≠ÂÖ∑ÊúâÂçìË∂äÁöÑÊïàËÉΩÔºå‰∏¶‰∏îËàá SiMT ÂÖ∑ÊúâÂÖßÂú®Áõ∏ÂÆπÊÄß„ÄÇÁÑ∂ËÄåÔºåÂ∞áÂÉÖËß£Á¢ºÂô®Êû∂ÊßãÁõ¥Êé•ÊáâÁî®Êñº SiMT Âú®Ë®ìÁ∑¥ÂíåÊé®Ë´ñÊñπÈù¢ÊúÉÂ∏∂‰æÜÊåëÊà∞„ÄÇÁÇ∫‰∫ÜÁ∑©Ëß£‰∏äËø∞ÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∫ÜÁ¨¨‰∏ÄÂÄãÂÉÖËß£Á¢ºÂô® SiMT Ê®°ÂûãÔºåÁ®±ÁÇ∫ÂÉÖËß£Á¢ºÂô®‰∏≤ÊµÅËΩâÊèõÂô® (DST)„ÄÇÂÖ∑È´î‰æÜË™™ÔºåDST ÂàÜÂà•Â∞çÂéüÂßãË™ûË®ÄÂíåÁõÆÊ®ôË™ûË®ÄÂâçÁ∂¥ÁöÑ‰ΩçÁΩÆÈÄ≤Ë°åÁ∑®Á¢ºÔºåÁ¢∫‰øùÁõÆÊ®ôË™ûË®ÄÂâçÁ∂¥ÁöÑ‰ΩçÁΩÆ‰∏çÂèóÂéüÂßãË™ûË®ÄÂâçÁ∂¥ÁöÑÊì¥ÂÖÖÂΩ±Èüø„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂ∞àÁÇ∫ÂÉÖËß£Á¢ºÂô®Êû∂ÊßãÈáèË∫´ÊâìÈÄ†ÁöÑ‰∏≤ÊµÅËá™ÊàëÊ≥®ÊÑèÂäõ (SSA) Ê©üÂà∂„ÄÇÂÆÉËÉΩÂ§†ÈÄèÈÅéË©ï‰º∞Ëº∏ÂÖ•ÂéüÂßãË™ûË®ÄË≥áË®äÁöÑÂÖÖÂàÜÊÄß‰∏¶ËàáËªüÊ≥®ÊÑèÂäõÊ©üÂà∂Êï¥Âêà‰æÜÁî¢ÁîüÁøªË≠ØÔºåÂæûËÄåÁç≤ÂæóÁøªË≠ØÊ∫ñÂâá„ÄÇÂØ¶È©óË°®ÊòéÔºåÊàëÂÄëÁöÑÊñπÊ≥ïÂú®‰∏âÈ†ÖÁøªË≠Ø‰ªªÂãô‰∏äÈÅîÂà∞‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÊïàËÉΩ„ÄÇ

##### **Quantum Implicit Neural Representations**
2406.03873v1 by Jiaming Zhao, Wenbo Qiao, Peng Zhang, Hui Gao

Implicit neural representations have emerged as a powerful paradigm to
represent signals such as images and sounds. This approach aims to utilize
neural networks to parameterize the implicit function of the signal. However,
when representing implicit functions, traditional neural networks such as
ReLU-based multilayer perceptrons face challenges in accurately modeling
high-frequency components of signals. Recent research has begun to explore the
use of Fourier Neural Networks (FNNs) to overcome this limitation. In this
paper, we propose Quantum Implicit Representation Network (QIREN), a novel
quantum generalization of FNNs. Furthermore, through theoretical analysis, we
demonstrate that QIREN possesses a quantum advantage over classical FNNs.
Lastly, we conducted experiments in signal representation, image
superresolution, and image generation tasks to show the superior performance of
QIREN compared to state-of-the-art (SOTA) models. Our work not only
incorporates quantum advantages into implicit neural representations but also
uncovers a promising application direction for Quantum Neural Networks.

ÊëòË¶ÅÔºöÈö±ÂºèÁ•ûÁ∂ìË°®ÂæµÂ∑≤ÊàêÁÇ∫Ë°®ÂæµÂΩ±ÂÉèÂíåËÅ≤Èü≥Á≠âË®äËôüÁöÑÂº∑Â§ßÁØÑ‰æã„ÄÇÊ≠§ÊñπÊ≥ïÊó®Âú®Âà©Áî®Á•ûÁ∂ìÁ∂≤Ë∑Ø‰æÜÂèÉÊï∏ÂåñË®äËôüÁöÑÈö±ÂºèÂáΩÊï∏„ÄÇÁÑ∂ËÄåÔºåÂú®Ë°®ÂæµÈö±ÂºèÂáΩÊï∏ÊôÇÔºåÂÇ≥Áµ±ÁöÑÁ•ûÁ∂ìÁ∂≤Ë∑ØÔºà‰æãÂ¶ÇÂü∫Êñº ReLU ÁöÑÂ§öÂ±§ÊÑüÁü•Âô®ÔºâÂú®Á≤æÁ¢∫Âª∫Ê®°Ë®äËôüÁöÑÈ´òÈ†ªÁéáÁµÑÊàêÈÉ®ÂàÜÊôÇÈù¢Ëá®ÊåëÊà∞„ÄÇÊúÄËøëÁöÑÁ†îÁ©∂Â∑≤ÈñãÂßãÊé¢Ë®é‰ΩøÁî®ÂÇÖÁ´ãËëâÁ•ûÁ∂ìÁ∂≤Ë∑Ø (FNN) ‰æÜÂÖãÊúçÊ≠§ÈôêÂà∂„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫ÈáèÂ≠êÈö±ÂºèË°®ÂæµÁ∂≤Ë∑Ø (QIREN)ÔºåÈÄôÊòØ‰∏ÄÁ®Æ FNN ÁöÑÊñ∞ÂûãÈáèÂ≠êÊ¶ÇÊã¨„ÄÇÊ≠§Â§ñÔºåÈÄèÈÅéÁêÜË´ñÂàÜÊûêÔºåÊàëÂÄëË≠âÊòé QIREN ÊìÅÊúâÂÑ™ÊñºÂÇ≥Áµ± FNN ÁöÑÈáèÂ≠êÂÑ™Âã¢„ÄÇÊúÄÂæåÔºåÊàëÂÄëÂú®Ë®äËôüË°®Âæµ„ÄÅÂΩ±ÂÉèË∂ÖËß£ÊûêÂ∫¶ÂíåÂΩ±ÂÉèÁîüÊàê‰ªªÂãô‰∏≠ÈÄ≤Ë°åÂØ¶È©óÔºå‰ª•È°ØÁ§∫ QIREN ËàáÊúÄÂÖàÈÄ≤ (SOTA) Ê®°ÂûãÁõ∏ÊØîÁöÑÂÑ™Áï∞ÊïàËÉΩ„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂‰∏çÂÉÖÂ∞áÈáèÂ≠êÂÑ™Âã¢Á¥çÂÖ•Èö±ÂºèÁ•ûÁ∂ìË°®ÂæµÔºå‰πüÊè≠Á§∫‰∫ÜÈáèÂ≠êÁ•ûÁ∂ìÁ∂≤Ë∑Ø‰∏ÄÂÄãÊúâÂâçÊôØÁöÑÊáâÁî®ÊñπÂêë„ÄÇ

##### **BLSP-Emo: Towards Empathetic Large Speech-Language Models**
2406.03872v1 by Chen Wang, Minpeng Liao, Zhongqiang Huang, Junhong Wu, Chengqing Zong, Jiajun Zhang

The recent release of GPT-4o showcased the potential of end-to-end multimodal
models, not just in terms of low latency but also in their ability to
understand and generate expressive speech with rich emotions. While the details
are unknown to the open research community, it likely involves significant
amounts of curated data and compute, neither of which is readily accessible. In
this paper, we present BLSP-Emo (Bootstrapped Language-Speech Pretraining with
Emotion support), a novel approach to developing an end-to-end speech-language
model capable of understanding both semantics and emotions in speech and
generate empathetic responses. BLSP-Emo utilizes existing speech recognition
(ASR) and speech emotion recognition (SER) datasets through a two-stage
process. The first stage focuses on semantic alignment, following recent work
on pretraining speech-language models using ASR data. The second stage performs
emotion alignment with the pretrained speech-language model on an emotion-aware
continuation task constructed from SER data. Our experiments demonstrate that
the BLSP-Emo model excels in comprehending speech and delivering empathetic
responses, both in instruction-following tasks and conversations.

ÊëòË¶ÅÔºöGPT-4o ÊúÄËøëÁôºÂ∏ÉÂ±ïÁ§∫‰∫ÜÁ´ØÂà∞Á´ØÂ§öÊ®°ÊÖãÊ®°ÂûãÁöÑÊΩõÂäõÔºå‰∏çÂÉÖÂú®‰ΩéÂª∂ÈÅ≤ÊñπÈù¢ÔºåÈÇÑÂú®ÁêÜËß£ÂíåÁîüÊàêÂÖ∑ÊúâË±êÂØåÊÉÖÊÑüÁöÑË°®ÈÅîÊÄßË™ûË®ÄÊñπÈù¢„ÄÇÈõñÁÑ∂Á¥∞ÁØÄÂ∞çÈñãÊîæÁ†îÁ©∂Á§æÁæ§ËÄåË®ÄÊú™Áü•Ôºå‰ΩÜÂÆÉÂèØËÉΩÊ∂âÂèäÂ§ßÈáèÁöÑÁ≠ñÂ±ïË≥áÊñôÂíåÈÅãÁÆóÔºåËÄåÈÄôÂÖ©ËÄÖÈÉΩ‰∏çÊòØÂÆπÊòìÂèñÂæóÁöÑ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫ BLSP-EmoÔºàÂºïÂ∞éË™ûË®ÄË™ûÈü≥È†êË®ìÁ∑¥ÔºåÂÖ∑ÂÇôÊÉÖÊÑüÊîØÊè¥ÔºâÔºåÈÄôÊòØ‰∏ÄÁ®ÆÈñãÁôºÁ´ØÂà∞Á´ØË™ûÈü≥Ë™ûË®ÄÊ®°ÂûãÁöÑÊñ∞ÊñπÊ≥ïÔºåËÉΩÂ§†ÁêÜËß£Ë™ûÈü≥‰∏≠ÁöÑË™ûÊÑèÂíåÊÉÖÊÑüÔºå‰∏¶Áî¢ÁîüÂêåÁêÜÂøÉÁöÑÂõûÊáâ„ÄÇBLSP-Emo ÈÄèÈÅéÂÖ©ÈöéÊÆµÊµÅÁ®ãÂà©Áî®ÁèæÊúâÁöÑË™ûÈü≥Ëæ®Ë≠ò (ASR) ÂíåË™ûÈü≥ÊÉÖÊÑüËæ®Ë≠ò (SER) Ë≥áÊñôÈõÜ„ÄÇÁ¨¨‰∏ÄÈöéÊÆµËëóÈáçÊñºË™ûÊÑèÂ∞çÈΩäÔºåÈÅµÂæ™ÊúÄËøë‰ΩøÁî® ASR Ë≥áÊñôÈ†êË®ìÁ∑¥Ë™ûÈü≥Ë™ûË®ÄÊ®°ÂûãÁöÑÁ†îÁ©∂„ÄÇÁ¨¨‰∫åÈöéÊÆµ‰ΩøÁî®Âæû SER Ë≥áÊñôÂª∫ÊßãÁöÑÊÉÖÊÑüÊÑüÁü•Âª∂Á∫å‰ªªÂãôÔºåÂ∞çÈ†êË®ìÁ∑¥ÁöÑË™ûÈü≥Ë™ûË®ÄÊ®°ÂûãÂü∑Ë°åÊÉÖÊÑüÂ∞çÈΩä„ÄÇÊàëÂÄëÁöÑÂØ¶È©óË≠âÊòéÔºåBLSP-Emo Ê®°ÂûãÂú®ÁêÜËß£Ë™ûÈü≥ÂíåÊèê‰æõÂêåÁêÜÂøÉÂõûÊáâÊñπÈù¢Ë°®ÁèæÂá∫Ëâ≤ÔºåÁÑ°Ë´ñÊòØÂú®ÈÅµÂæ™Êåá‰ª§ÁöÑ‰ªªÂãôÊàñÂ∞çË©±‰∏≠„ÄÇ

##### **Recovering document annotations for sentence-level bitext**
2406.03869v1 by Rachel Wicks, Matt Post, Philipp Koehn

Data availability limits the scope of any given task. In machine translation,
historical models were incapable of handling longer contexts, so the lack of
document-level datasets was less noticeable. Now, despite the emergence of
long-sequence methods, we remain within a sentence-level paradigm and without
data to adequately approach context-aware machine translation. Most large-scale
datasets have been processed through a pipeline that discards document-level
metadata. In this work, we reconstruct document-level information for three
(ParaCrawl, News Commentary, and Europarl) large datasets in German, French,
Spanish, Italian, Polish, and Portuguese (paired with English). We then
introduce a document-level filtering technique as an alternative to traditional
bitext filtering. We present this filtering with analysis to show that this
method prefers context-consistent translations rather than those that may have
been sentence-level machine translated. Last we train models on these longer
contexts and demonstrate improvement in document-level translation without
degradation of sentence-level translation. We release our dataset, ParaDocs,
and resulting models as a resource to the community.

ÊëòË¶ÅÔºö<paragraph>Ë≥áÊñôÂèØÂæóÊÄßÈôêÂà∂‰∫Ü‰ªª‰ΩïÁâπÂÆö‰ªªÂãôÁöÑÁØÑÂúç„ÄÇÂú®Ê©üÂô®ÁøªË≠Ø‰∏≠ÔºåÊ≠∑Âè≤Ê®°ÂûãÁÑ°Ê≥ïËôïÁêÜËºÉÈï∑ÁöÑË™ûÂ¢ÉÔºåÂõ†Ê≠§ËºÉ‰∏çÈáçË¶ñÊñá‰ª∂Â±§Á¥öË≥áÊñôÈõÜÁöÑÁº∫‰πè„ÄÇÁèæÂú®ÔºåÂÑòÁÆ°Âá∫Áèæ‰∫ÜÈï∑Â∫èÂàóÊñπÊ≥ïÔºåÊàëÂÄë‰ªçËôïÊñºÂè•Â≠êÂ±§Á¥öÁöÑÁØÑ‰æã‰∏≠Ôºå‰∏îÊ≤íÊúâË∂≥Â§†ÁöÑË≥áÊñô‰æÜÈÅ©Áï∂Âú∞ÈÄ≤Ë°åËÄÉÈáèË™ûÂ¢ÉÁöÑÊ©üÂô®ÁøªË≠Ø„ÄÇÂ§ßÂ§öÊï∏Â§ßÂûãË≥áÊñôÈõÜÂ∑≤ÈÄèÈÅéÊúÉÊç®Ê£ÑÊñá‰ª∂Â±§Á¥öÂÖÉË≥áÊñôÁöÑÁÆ°ÈÅìÈÄ≤Ë°åËôïÁêÜ„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÈáùÂ∞çÂæ∑Êñá„ÄÅÊ≥ïÊñá„ÄÅË•øÁè≠ÁâôÊñá„ÄÅÁæ©Â§ßÂà©Êñá„ÄÅÊ≥¢Ëò≠ÊñáÂíåËë°ËêÑÁâôÊñáÔºàËàáËã±ÊñáÈÖçÂ∞çÔºâÁöÑ‰∏âÂÄãÂ§ßÂûãË≥áÊñôÈõÜÔºàParaCrawl„ÄÅÊñ∞ËÅûË©ïË´ñÂíåÊ≠êË≠∞ÊúÉÔºâÈáçÂª∫Êñá‰ª∂Â±§Á¥öË≥áË®ä„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÂºïÂÖ•Êñá‰ª∂Â±§Á¥öÁØ©ÈÅ∏ÊäÄË°ìÔºå‰ΩúÁÇ∫ÂÇ≥Áµ±ÈõôË™ûÊñáÊú¨ÁØ©ÈÅ∏ÁöÑÊõø‰ª£ÊñπÊ°à„ÄÇÊàëÂÄëÊèêÂá∫Ê≠§ÁØ©ÈÅ∏‰∏¶ÈÄ≤Ë°åÂàÜÊûêÔºå‰ª•È°ØÁ§∫Ê≠§ÊñπÊ≥ïÂÅèÂ•ΩË™ûÂ¢É‰∏ÄËá¥ÁöÑÁøªË≠ØÔºåËÄå‰∏çÊòØÂèØËÉΩÂ∑≤ÈÄ≤Ë°åÂè•Â≠êÂ±§Á¥öÊ©üÂô®ÁøªË≠ØÁöÑÁøªË≠Ø„ÄÇÊúÄÂæåÔºåÊàëÂÄëÈáùÂ∞çÈÄô‰∫õËºÉÈï∑ÁöÑË™ûÂ¢ÉË®ìÁ∑¥Ê®°ÂûãÔºå‰∏¶Ë≠âÊòéÊñá‰ª∂Â±§Á¥öÁøªË≠ØÊúâÊâÄÈÄ≤Ê≠•ÔºåËÄåÂè•Â≠êÂ±§Á¥öÁøªË≠Ø‰∏¶Êú™‰∏ãÈôç„ÄÇÊàëÂÄëÂ∞áÊàëÂÄëÁöÑË≥áÊñôÈõÜ ParaDocs ÂíåÁî¢ÁîüÁöÑÊ®°ÂûãÈáãÂá∫Ôºå‰ΩúÁÇ∫Á§æÁæ§ÁöÑË≥áÊ∫ê„ÄÇ</paragraph>

##### **Semantic Similarity Score for Measuring Visual Similarity at Semantic Level**
2406.03865v1 by Senran Fan, Zhicheng Bao, Chen Dong, Haotai Liang, Xiaodong Xu, Ping Zhang

Semantic communication, as a revolutionary communication architecture, is
considered a promising novel communication paradigm. Unlike traditional
symbol-based error-free communication systems, semantic-based visual
communication systems extract, compress, transmit, and reconstruct images at
the semantic level. However, widely used image similarity evaluation metrics,
whether pixel-based MSE or PSNR or structure-based MS-SSIM, struggle to
accurately measure the loss of semantic-level information of the source during
system transmission. This presents challenges in evaluating the performance of
visual semantic communication systems, especially when comparing them with
traditional communication systems. To address this, we propose a semantic
evaluation metric -- SeSS (Semantic Similarity Score), based on Scene Graph
Generation and graph matching, which shifts the similarity scores between
images into semantic-level graph matching scores. Meanwhile, semantic
similarity scores for tens of thousands of image pairs are manually annotated
to fine-tune the hyperparameters in the graph matching algorithm, aligning the
metric more closely with human semantic perception. The performance of the SeSS
is tested on different datasets, including (1)images transmitted by traditional
and semantic communication systems at different compression rates, (2)images
transmitted by traditional and semantic communication systems at different
signal-to-noise ratios, (3)images generated by large-scale model with different
noise levels introduced, and (4)cases of images subjected to certain special
transformations. The experiments demonstrate the effectiveness of SeSS,
indicating that the metric can measure the semantic-level differences in
semantic-level information of images and can be used for evaluation in visual
semantic communication systems.

ÊëòË¶ÅÔºöËØ≠‰πâÈÄö‰ø°‰Ωú‰∏∫‰∏ÄÁßçÈù©ÂëΩÊÄßÁöÑÈÄö‰ø°Êû∂ÊûÑÔºåË¢´ËÆ§‰∏∫ÊòØ‰∏ÄÁßçÂæàÊúâÂâçÈÄîÁöÑÊñ∞ÂûãÈÄö‰ø°ËåÉÂºè„ÄÇ‰∏é‰º†ÁªüÁöÑÂü∫‰∫éÁ¨¶Âè∑ÁöÑÊó†Â∑ÆÈîôÈÄö‰ø°Á≥ªÁªü‰∏çÂêåÔºåÂü∫‰∫éËØ≠‰πâÁöÑËßÜËßâÈÄö‰ø°Á≥ªÁªüÂú®ËØ≠‰πâÂ±ÇÊèêÂèñ„ÄÅÂéãÁº©„ÄÅ‰º†ËæìÂíåÈáçÂª∫ÂõæÂÉè„ÄÇÁÑ∂ËÄåÔºåÂπøÊ≥õ‰ΩøÁî®ÁöÑÂõæÂÉèÁõ∏‰ººÂ∫¶ËØÑ‰º∞ÊåáÊ†áÔºåÊó†ËÆ∫ÊòØÂü∫‰∫éÂÉèÁ¥†ÁöÑ MSE Êàñ PSNRÔºåËøòÊòØÂü∫‰∫éÁªìÊûÑÁöÑ MS-SSIMÔºåÂú®Á≥ªÁªü‰º†ËæìËøáÁ®ã‰∏≠ÈÉΩÈöæ‰ª•ÂáÜÁ°ÆÊµãÈáèÊ∫êËØ≠‰πâÁ∫ß‰ø°ÊÅØÁöÑÊçüÂ§±„ÄÇËøôÁªôËØÑ‰º∞ËßÜËßâËØ≠‰πâÈÄö‰ø°Á≥ªÁªüÁöÑÊÄßËÉΩÂ∏¶Êù•‰∫ÜÊåëÊàòÔºåÂ∞§ÂÖ∂ÊòØÂú®Â∞ÜÂÆÉ‰ª¨‰∏é‰º†ÁªüÈÄö‰ø°Á≥ªÁªüËøõË°åÊØîËæÉÊó∂„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢òÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçËØ≠‰πâËØÑ‰º∞ÊåáÊ†á‚Äî‚ÄîSeSSÔºàËØ≠‰πâÁõ∏‰ººÂ∫¶ÂæóÂàÜÔºâÔºåÂÆÉÂü∫‰∫éÂú∫ÊôØÂõæÁîüÊàêÂíåÂõæÂåπÈÖçÔºåÂ∞ÜÂõæÂÉè‰πãÈó¥ÁöÑÁõ∏‰ººÂ∫¶ÂæóÂàÜËΩ¨Êç¢‰∏∫ËØ≠‰πâÁ∫ßÂõæÂåπÈÖçÂæóÂàÜ„ÄÇÂêåÊó∂ÔºåÊâãÂä®Ê≥®Èáä‰∫ÜÊï∞‰∏áÂØπÂõæÂÉèÁöÑËØ≠‰πâÁõ∏‰ººÂ∫¶ÂæóÂàÜÔºå‰ª•ÂæÆË∞ÉÂõæÂåπÈÖçÁÆóÊ≥ï‰∏≠ÁöÑË∂ÖÂèÇÊï∞Ôºå‰ΩøËØ•ÊåáÊ†áÊõ¥Ë¥¥Ëøë‰∫∫Á±ªÁöÑËØ≠‰πâÊÑüÁü•„ÄÇSeSS ÁöÑÊÄßËÉΩÂú®‰∏çÂêåÁöÑÊï∞ÊçÆÈõÜ‰∏äËøõË°å‰∫ÜÊµãËØïÔºåÂåÖÊã¨Ôºà1Ôºâ‰º†ÁªüÂíåËØ≠‰πâÈÄö‰ø°Á≥ªÁªüÂú®‰∏çÂêåÂéãÁº©Áéá‰∏ã‰º†ËæìÁöÑÂõæÂÉèÔºåÔºà2Ôºâ‰º†ÁªüÂíåËØ≠‰πâÈÄö‰ø°Á≥ªÁªüÂú®‰∏çÂêå‰ø°Âô™ÊØî‰∏ã‰º†ËæìÁöÑÂõæÂÉèÔºåÔºà3ÔºâÂ§ßËßÑÊ®°Ê®°ÂûãÁîüÊàêÁöÑ‰∏çÂêåÂô™Â£∞Ê∞¥Âπ≥‰∏ãÁöÑÂõæÂÉèÔºå‰ª•ÂèäÔºà4ÔºâÂõæÂÉèÁªèËøáÊüê‰∫õÁâπÊÆäÂèòÊç¢ÁöÑÊÉÖÂÜµ„ÄÇÂÆûÈ™åË°®Êòé‰∫Ü SeSS ÁöÑÊúâÊïàÊÄßÔºåË°®ÊòéËØ•ÊåáÊ†áÂèØ‰ª•ÊµãÈáèÂõæÂÉèËØ≠‰πâÁ∫ß‰ø°ÊÅØ‰∏≠ÁöÑËØ≠‰πâÁ∫ßÂ∑ÆÂºÇÔºåÂπ∂ÂèØÁî®‰∫éËßÜËßâËØ≠‰πâÈÄö‰ø°Á≥ªÁªü‰∏≠ÁöÑËØÑ‰º∞„ÄÇ

##### **MuJo: Multimodal Joint Feature Space Learning for Human Activity Recognition**
2406.03857v1 by Stefan Gerd Fritsch, Cennet Oguz, Vitor Fortes Rey, Lala Ray, Maximilian Kiefer-Emmanouilidis, Paul Lukowicz

Human Activity Recognition is a longstanding problem in AI with applications
in a broad range of areas: from healthcare, sports and fitness, security, and
human computer interaction to robotics. The performance of HAR in real-world
settings is strongly dependent on the type and quality of the input signal that
can be acquired. Given an unobstructed, high-quality camera view of a scene,
computer vision systems, in particular in conjunction with foundational models
(e.g., CLIP), can today fairly reliably distinguish complex activities. On the
other hand, recognition using modalities such as wearable sensors (which are
often more broadly available, e.g, in mobile phones and smartwatches) is a more
difficult problem, as the signals often contain less information and labeled
training data is more difficult to acquire. In this work, we show how we can
improve HAR performance across different modalities using multimodal
contrastive pretraining. Our approach MuJo (Multimodal Joint Feature Space
Learning), learns a multimodal joint feature space with video, language, pose,
and IMU sensor data. The proposed approach combines contrastive and multitask
learning methods and analyzes different multitasking strategies for learning a
compact shared representation. A large dataset with parallel video, language,
pose, and sensor data points is also introduced to support the research, along
with an analysis of the robustness of the multimodal joint space for
modal-incomplete and low-resource data. On the MM-Fit dataset, our model
achieves an impressive Macro F1-Score of up to 0.992 with only 2% of the train
data and 0.999 when using all available training data for classification tasks.
Moreover, in the scenario where the MM-Fit dataset is unseen, we demonstrate a
generalization performance of up to 0.638.

ÊëòË¶ÅÔºö‰∫∫È°ûÊ¥ªÂãïËæ®Ë≠òÊòØ‰∫∫Â∑•Êô∫ÊÖßÈ†òÂüü‰∏≠Èï∑‰πÖÂ≠òÂú®ÁöÑÂïèÈ°åÔºåÂú®Âª£Ê≥õÁöÑÈ†òÂüü‰∏≠ÈÉΩÊúâÊáâÁî®ÔºöÂæûÈÜ´ÁôÇ‰øùÂÅ•„ÄÅÈÅãÂãïÂíåÂÅ•Ë∫´„ÄÅÂÆâÂÖ®Âíå‰∫∫Ê©ü‰∫íÂãïÂà∞Ê©üÂô®‰∫∫ÊäÄË°ì„ÄÇHAR Âú®ÁúüÂØ¶‰∏ñÁïå‰∏≠ÁöÑË°®ÁèæÈ´òÂ∫¶‰æùË≥¥ÊñºËº∏ÂÖ•Ë®äËôüÁöÑÈ°ûÂûãÂíåÂìÅË≥™ÔºåËÄåËº∏ÂÖ•Ë®äËôüÊòØÂèØ‰ª•Ë¢´Êì∑ÂèñÁöÑ„ÄÇÁµ¶ÂÆö‰∏ÄÂÄãÂ†¥ÊôØÁöÑÁÑ°ÈöúÁ§ô„ÄÅÈ´òÂìÅË≥™ÁöÑÁõ∏Ê©üË¶ñËßíÔºåÈõªËÖ¶Ë¶ñË¶∫Á≥ªÁµ±ÔºåÁâπÂà•ÊòØÁµêÂêàÂü∫Á§éÊ®°ÂûãÔºà‰æãÂ¶Ç CLIPÔºâÔºåÂ¶Ç‰ªäÂèØ‰ª•Áõ∏Áï∂ÂèØÈù†Âú∞ÂçÄÂàÜË§áÈõúÁöÑÊ¥ªÂãï„ÄÇÂè¶‰∏ÄÊñπÈù¢Ôºå‰ΩøÁî®ÂèØÁ©øÊà¥ÂºèÊÑüÊ∏¨Âô®Ôºà‰æãÂ¶ÇÂú®Ë°åÂãïÈõªË©±ÂíåÊô∫ÊÖßÊâãÈå∂‰∏≠Êõ¥Âª£Ê≥õÂèØÁî®ÁöÑÔºâÁ≠âÊñπÂºèÈÄ≤Ë°åËæ®Ë≠òÊòØ‰∏ÄÂÄãÊõ¥Âõ∞Èõ£ÁöÑÂïèÈ°åÔºåÂõ†ÁÇ∫Ë®äËôüÈÄöÂ∏∏ÂåÖÂê´ËºÉÂ∞ëË≥áË®äÔºåËÄå‰∏îÊ®ôË®òË®ìÁ∑¥Ë≥áÊñôÊõ¥Èõ£‰ª•ÂèñÂæó„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜÂ¶Ç‰Ωï‰ΩøÁî®Â§öÊ®°ÊÖãÂ∞çÊØîÈ†êË®ìÁ∑¥‰æÜÊîπÂñÑ‰∏çÂêåÊ®°ÊÖãÁöÑ HAR ÊïàËÉΩ„ÄÇÊàëÂÄëÁöÑ MuJoÔºàÂ§öÊ®°ÊÖãËÅØÂêàÁâπÂæµÁ©∫ÈñìÂ≠∏ÁøíÔºâÊñπÊ≥ïÔºåÂ≠∏Áøí‰∏ÄÂÄãÂåÖÂê´ÂΩ±Áâá„ÄÅË™ûË®Ä„ÄÅÂßøÂã¢Âíå IMU ÊÑüÊ∏¨Âô®Ë≥áÊñôÁöÑÂ§öÊ®°ÊÖãËÅØÂêàÁâπÂæµÁ©∫Èñì„ÄÇÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÁµêÂêà‰∫ÜÂ∞çÊØîÂíåÂ§ö‰ªªÂãôÂ≠∏ÁøíÊñπÊ≥ïÔºå‰∏¶ÂàÜÊûê‰∫Ü‰∏çÂêåÁöÑÂ§ö‰ªªÂãôÁ≠ñÁï•Ôºå‰ª•Â≠∏Áøí‰∏ÄÂÄãÁ∑äÊπäÁöÑÂÖ±‰∫´Ë°®Á§∫„ÄÇ‰∏ÄÂÄãÂåÖÂê´Âπ≥Ë°åÂΩ±Áâá„ÄÅË™ûË®Ä„ÄÅÂßøÂã¢ÂíåÊÑüÊ∏¨Âô®Ë≥áÊñôÈªûÁöÑÂ§ßÂûãË≥áÊñôÈõÜ‰πüË¢´ÂºïÂÖ•Ôºå‰ª•ÊîØÊè¥Á†îÁ©∂ÔºåÂêåÊôÇÂàÜÊûêÂ§öÊ®°ÊÖãËÅØÂêàÁ©∫ÈñìÂ∞çÊ®°Âºè‰∏çÂÆåÊï¥Âíå‰ΩéË≥áÊ∫êË≥áÊñôÁöÑÁ©©ÂÅ•ÊÄß„ÄÇÂú® MM-Fit Ë≥áÊñôÈõÜ‰∏äÔºåÊàëÂÄëÁöÑÊ®°ÂûãÂÉÖ‰ΩøÁî® 2% ÁöÑË®ìÁ∑¥Ë≥áÊñôÂ∞±ÈÅîÂà∞‰∫Ü‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑ 0.992 Â∑®ÈõÜ F1 ÂàÜÊï∏ÔºåËÄå‰ΩøÁî®ÊâÄÊúâÂèØÁî®ÁöÑË®ìÁ∑¥Ë≥áÊñôÈÄ≤Ë°åÂàÜÈ°û‰ªªÂãôÊôÇÔºåÂâáÈÅîÂà∞‰∫Ü 0.999„ÄÇÊ≠§Â§ñÔºåÂú® MM-Fit Ë≥áÊñôÈõÜÊú™Ë¶ãÁöÑÊÉÖÊ≥Å‰∏ãÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜÈ´òÈÅî 0.638 ÁöÑÊ≥õÂåñÊïàËÉΩ„ÄÇ

##### **Performance of large language models in numerical vs. semantic medical knowledge: Benchmarking on evidence-based Q&As**
2406.03855v1 by Eden Avnat, Michal Levy, Daniel Herstain, Elia Yanko, Daniel Ben Joya, Michal Tzuchman Katz, Dafna Eshel, Sahar Laros, Yael Dagan, Shahar Barami, Joseph Mermelstein, Shahar Ovadia, Noam Shomron, Varda Shalev, Raja-Elie E. Abdulnour

Clinical problem-solving requires processing of semantic medical knowledge
such as illness scripts and numerical medical knowledge of diagnostic tests for
evidence-based decision-making. As large language models (LLMs) show promising
results in many aspects of language-based clinical practice, their ability to
generate non-language evidence-based answers to clinical questions is
inherently limited by tokenization. Therefore, we evaluated LLMs' performance
on two question types: numeric (correlating findings) and semantic
(differentiating entities) while examining differences within and between LLMs
in medical aspects and comparing their performance to humans. To generate
straightforward multi-choice questions and answers (QAs) based on
evidence-based medicine (EBM), we used a comprehensive medical knowledge graph
(encompassed data from more than 50,00 peer-reviewed articles) and created the
"EBMQA". EBMQA contains 105,000 QAs labeled with medical and non-medical topics
and classified into numerical or semantic questions. We benchmarked this
dataset using more than 24,500 QAs on two state-of-the-art LLMs: Chat-GPT4 and
Claude3-Opus. We evaluated the LLMs accuracy on semantic and numerical question
types and according to sub-labeled topics. For validation, six medical experts
were tested on 100 numerical EBMQA questions. We found that both LLMs excelled
more in semantic than numerical QAs, with Claude3 surpassing GPT4 in numerical
QAs. However, both LLMs showed inter and intra gaps in different medical
aspects and remained inferior to humans. Thus, their medical advice should be
addressed carefully.

ÊëòË¶ÅÔºö<paragraph>Ëá®Â∫äÂïèÈ°åËß£Ê±∫ÈúÄË¶ÅËôïÁêÜË™ûÁæ©ÈÜ´Â≠∏Áü•Ë≠òÔºå‰æãÂ¶ÇÁñæÁóÖËÖ≥Êú¨ÂíåÁî®ÊñºÂæ™Ë≠âÊ±∫Á≠ñÁöÑË®∫Êñ∑Ê∏¨Ë©¶ÁöÑÊï∏ÂÄºÈÜ´Â≠∏Áü•Ë≠ò„ÄÇÈö®ËëóÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®Ë™ûË®ÄÂü∫Á§éËá®Â∫äÂØ¶ÂãôÁöÑË®±Â§öÊñπÈù¢È°ØÁ§∫Âá∫‰ª§‰∫∫ÊªøÊÑèÁöÑÁµêÊûúÔºåÂÆÉÂÄëÁî¢ÁîüÈùûË™ûË®ÄÂæ™Ë≠âÁ≠îÊ°àÁöÑËÉΩÂäõÂú®ÊñºËá®Â∫äÂïèÈ°åÊú¨Ë≥™‰∏äÂèóÂà∞Ê®ôË®òÂåñÁöÑÈôêÂà∂„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëË©ï‰º∞‰∫Ü LLM Âú®ÂÖ©Á®ÆÂïèÈ°åÈ°ûÂûã‰∏äÁöÑË°®ÁèæÔºöÊï∏ÂÄºÔºàÁõ∏ÈóúÁôºÁèæÔºâÂíåË™ûÁæ©ÔºàÂçÄÂàÜÂØ¶È´îÔºâÔºåÂêåÊôÇÊ™¢Êü• LLM Âú®ÈÜ´Â≠∏ÊñπÈù¢ÁöÑÂ∑ÆÁï∞Ôºå‰∏¶Â∞áÂÖ∂Ë°®ÁèæËàá‰∫∫È°ûÈÄ≤Ë°åÊØîËºÉ„ÄÇÁÇ∫‰∫ÜÊ†πÊìöÂæ™Ë≠âÈÜ´Â≠∏ (EBM) Áî¢ÁîüÁõ¥Êé•ÁöÑÂ§öÈÅ∏È°åÂíåÁ≠îÊ°à (QA)ÔºåÊàëÂÄë‰ΩøÁî®‰∫Ü‰∏ÄÂÄãÂÖ®Èù¢ÁöÑÈÜ´Â≠∏Áü•Ë≠òÂúñË≠úÔºàÂåÖÂê´‰æÜËá™ 50,000 Â§öÁØáÂêåË°åË©ïÂØ©ÊñáÁ´†ÁöÑË≥áÊñôÔºâÔºå‰∏¶Âª∫Á´ã‰∫Ü„ÄåEBMQA„Äç„ÄÇEBMQA ÂåÖÂê´ 105,000 ÂÄãÊ®ôË®òÊúâÈÜ´Â≠∏ÂíåÈùûÈÜ´Â≠∏‰∏ªÈ°åÁöÑ QAÔºå‰∏¶ÂàÜÈ°ûÁÇ∫Êï∏ÂÄºÊàñË™ûÁæ©ÂïèÈ°å„ÄÇÊàëÂÄë‰ΩøÁî®Ë∂ÖÈÅé 24,500 ÂÄã QA Âú®ÂÖ©ÂÄãÊúÄÂÖàÈÄ≤ÁöÑ LLMÔºöChat-GPT4 Âíå Claude3-Opus ‰∏äÂ∞çÊ≠§Ë≥áÊñôÈõÜÈÄ≤Ë°åÂü∫Ê∫ñÊ∏¨Ë©¶„ÄÇÊàëÂÄëË©ï‰º∞‰∫Ü LLM Âú®Ë™ûÁæ©ÂíåÊï∏ÂÄºÂïèÈ°åÈ°ûÂûã‰ª•ÂèäÊ†πÊìöÊ¨°Ê®ôÁ±§‰∏ªÈ°åÁöÑÊ∫ñÁ¢∫ÊÄß„ÄÇÁÇ∫‰∫ÜÈ©óË≠âÔºåÂÖ≠‰ΩçÈÜ´Â≠∏Â∞àÂÆ∂Êé•Âèó‰∫Ü 100 ÂÄãÊï∏ÂÄº EBMQA ÂïèÈ°åÁöÑÊ∏¨Ë©¶„ÄÇÊàëÂÄëÁôºÁèæÈÄôÂÖ©ÂÄã LLM Âú®Ë™ûÁæ© QA ‰∏äÈÉΩÊØîÂú®Êï∏ÂÄº QA ‰∏äË°®ÁèæÂæóÊõ¥Âá∫Ëâ≤ÔºåËÄå Claude3 Âú®Êï∏ÂÄº QA ‰∏äË∂ÖË∂ä‰∫Ü GPT4„ÄÇÁÑ∂ËÄåÔºåÈÄôÂÖ©ÂÄã LLM Âú®‰∏çÂêåÁöÑÈÜ´Â≠∏ÊñπÈù¢ÈÉΩË°®ÁèæÂá∫ÂÖßÈÉ®ÂíåÂ§ñÈÉ®ÁöÑÂ∑ÆË∑ùÔºå‰∏¶‰∏î‰ªçÁÑ∂ÈÅúÊñº‰∫∫È°û„ÄÇÂõ†Ê≠§ÔºåÂÆÉÂÄëÁöÑÈÜ´ÁôÇÂª∫Ë≠∞ÊáâË¨πÊÖéÂ∞çÂæÖ„ÄÇ</paragraph>

##### **Speculative Decoding via Early-exiting for Faster LLM Inference with Thompson Sampling Control Mechanism**
2406.03853v1 by Jiahao Liu, Qifan Wang, Jingang Wang, Xunliang Cai

The recent advancements in large language models (LLMs) have been
extraordinary, yet the escalating inference costs associated with them present
challenges in real-world applications. To address these challenges, we propose
a novel approach called Early-exiting Speculative Decoding (EESD) with lossless
acceleration. Specifically, EESD utilizes a segment of the LLM to generate
draft tokens, incorporating Early-exiting structures after the first N layers.
To enhance the quality of draft tokens, a self-distillation method is
integrated. This early-exiting design not only reduces deployment and training
costs but also significantly accelerates the token generation speed. Moreover,
we introduce a novel sampling mechanism that leverages Thompson Sampling to
regulate the generation processes, automatically determining the quantity of
draft tokens in each round. The original LLM is then employed to validate these
draft tokens through a single forward pass, and thus guarantees that the final
output text maintains a distribution consistent with vanilla auto-regressive
decoding. The experimental results on both 13B and 70B models demonstrate that
our approach decodes tokens at a markedly accelerated rate compared to prior
methods, showing the effectiveness of our approach.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ËøëÊúüÁöÑÈÄ≤Â±ïÈùûÂá°Ôºå‰ΩÜËàá‰πãÁõ∏ÈóúÁöÑÊé®Ë´ñÊàêÊú¨‰∏çÊñ∑Â¢ûÂä†ÔºåÂ∞çÂØ¶ÈöõÊáâÁî®ÊßãÊàê‰∫ÜÊåëÊà∞„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂêçÁÇ∫Êó©ÊúüÈÄÄÂá∫Êé®Ë´ñËß£Á¢º (EESD) ÁöÑÊñ∞ÊñπÊ≥ïÔºåÂÖ∑ÊúâÁÑ°ÊêçÂä†ÈÄüÂäüËÉΩ„ÄÇÂÖ∑È´î‰æÜË™™ÔºåEESD Âà©Áî® LLM ÁöÑ‰∏ÄÈÉ®ÂàÜ‰æÜÁîüÊàêËçâÁ®ø‰ª£Âπ£Ôºå‰∏¶Âú®Á¨¨‰∏ÄÂÄã N Â±§‰πãÂæåÂä†ÂÖ•Êó©ÊúüÈÄÄÂá∫ÁµêÊßã„ÄÇÁÇ∫‰∫ÜÊèêÈ´òËçâÁ®ø‰ª£Âπ£ÁöÑÂìÅË≥™ÔºåÊï¥Âêà‰∫Ü‰∏ÄÁ®ÆËá™Ëí∏È§æÊñπÊ≥ï„ÄÇÈÄôÁ®ÆÊó©ÊúüÈÄÄÂá∫ÁöÑË®≠Ë®à‰∏çÂÉÖÈôç‰Ωé‰∫ÜÈÉ®ÁΩ≤ÂíåË®ìÁ∑¥ÊàêÊú¨ÔºåÈÇÑÈ°ØËëóÂä†Âø´‰∫Ü‰ª£Âπ£ÁîüÊàêÈÄüÂ∫¶„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÊäΩÊ®£Ê©üÂà∂ÔºåÂÆÉÂà©Áî® Thompson ÊäΩÊ®£‰æÜË™øÁØÄÁîüÊàêÈÅéÁ®ãÔºåËá™ÂãïÁ¢∫ÂÆöÊØè‰∏ÄËº™‰∏≠ËçâÁ®ø‰ª£Âπ£ÁöÑÊï∏Èáè„ÄÇÁÑ∂Âæå‰ΩøÁî®ÂéüÂßã LLM ÈÄöÈÅéÂñÆÊ¨°ÂâçÂêëÂÇ≥ÈÅû‰æÜÈ©óË≠âÈÄô‰∫õËçâÁ®ø‰ª£Âπ£ÔºåÂæûËÄå‰øùË≠âÊúÄÁµÇËº∏Âá∫ÊñáÊú¨‰øùÊåÅËàáÈ¶ôËçâËá™Ëø¥Ê≠∏Ëß£Á¢º‰∏ÄËá¥ÁöÑÂàÜÂ∏É„ÄÇÂú® 13B Âíå 70B Ê®°Âûã‰∏äÁöÑÂØ¶È©óÁµêÊûúË°®ÊòéÔºåËàáÂÖàÂâçÁöÑÊäÄË°ìÁõ∏ÊØîÔºåÊàëÂÄëÁöÑÊäÄË°ì‰ª•È°ØËëóÂä†ÈÄüÁöÑÈÄüÂ∫¶Ëß£Á¢º‰ª£Âπ£ÔºåÈ°ØÁ§∫‰∫ÜÊàëÂÄëÊäÄË°ìÁöÑÊúâÊïàÊÄß„ÄÇ

##### **Lean Workbook: A large-scale Lean problem set formalized from natural language math problems**
2406.03847v2 by Huaiyuan Ying, Zijian Wu, Yihan Geng, Jiayu Wang, Dahua Lin, Kai Chen

Large language models have demonstrated impressive capabilities across
various natural language processing tasks, especially in solving mathematical
problems. However, large language models are not good at math theorem proving
using formal languages like Lean. A significant challenge in this area is the
scarcity of training data available in these formal languages. To address this
issue, we propose a novel pipeline that iteratively generates and filters
synthetic data to translate natural language mathematical problems into Lean 4
statements, and vice versa. Our results indicate that the synthetic data
pipeline can provide useful training data and improve the performance of LLMs
in translating and understanding complex mathematical problems and proofs. Our
final dataset contains about 57K formal-informal question pairs along with
searched proof from the math contest forum and 21 new IMO questions. We
open-source our code at https://github.com/InternLM/InternLM-Math and our data
at https://huggingface.co/datasets/InternLM/Lean-Workbook.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÂ∑≤Âú®ÂêÑÁ®ÆËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ‰ªªÂãô‰∏≠Â±ïÁèæÂá∫‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑËÉΩÂäõÔºåÂ∞§ÂÖ∂ÊòØÂú®Ëß£Ê±∫Êï∏Â≠∏ÂïèÈ°å‰∏ä„ÄÇÁÑ∂ËÄåÔºåÂ§ßÂûãË™ûË®ÄÊ®°Âûã‰∏¶‰∏çÊìÖÈï∑‰ΩøÁî® Lean Á≠âÂΩ¢ÂºèË™ûË®Ä‰æÜË≠âÊòéÊï∏Â≠∏ÂÆöÁêÜ„ÄÇÈÄôÂÄãÈ†òÂüüÁöÑ‰∏ÄÂ§ßÊåëÊà∞ÊòØÈÄô‰∫õÂΩ¢ÂºèË™ûË®Ä‰∏≠ÂèØÁî®Ë®ìÁ∑¥Ë≥áÊñôÁöÑÁ®ÄÁº∫ÊÄß„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂâµÊñ∞ÁöÑÁÆ°ÈÅìÔºåÂÆÉÊúÉÂèçË¶ÜÁî¢ÁîüÂíåÈÅéÊøæÂêàÊàêË≥áÊñôÔºå‰ª•Â∞áËá™ÁÑ∂Ë™ûË®ÄÁöÑÊï∏Â≠∏ÂïèÈ°åËΩâÊèõÊàê Lean 4 Èô≥Ëø∞ÂºèÔºåÂèç‰πã‰∫¶ÁÑ∂„ÄÇÊàëÂÄëÁöÑÁµêÊûúË°®ÊòéÔºåÂêàÊàêË≥áÊñôÁÆ°ÈÅìÂèØ‰ª•Êèê‰æõÊúâÁî®ÁöÑË®ìÁ∑¥Ë≥áÊñôÔºå‰∏¶ÊèêÈ´òÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÂú®ËΩâÊèõÂíåÁêÜËß£Ë§áÈõúÊï∏Â≠∏ÂïèÈ°åÂíåË≠âÊòéÊñπÈù¢ÁöÑÊïàËÉΩ„ÄÇÊàëÂÄëÁöÑÊúÄÁµÇË≥áÊñôÈõÜÂåÖÂê´Á¥Ñ 57K ÂÄãÂΩ¢ÂºèÈùûÂΩ¢ÂºèÂïèÈ°åÂ∞çÔºå‰ª•ÂèäÂæûÊï∏Â≠∏Á´∂Ë≥ΩË´ñÂ£á‰∏≠ÊêúÂ∞ãÂà∞ÁöÑË≠âÊòéÂíå 21 ÂÄãÊñ∞ÁöÑÂúãÈöõÊï∏Â≠∏Â•ßÊûóÂåπÂÖãÁ´∂Ë≥ΩÂïèÈ°å„ÄÇÊàëÂÄëÂú® https://github.com/InternLM/InternLM-Math ÈñãÊ∫êÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÔºå‰∏¶Âú® https://huggingface.co/datasets/InternLM/Lean-Workbook ÈñãÊ∫êÊàëÂÄëÁöÑË≥áÊñô„ÄÇ

##### **POEM: Interactive Prompt Optimization for Enhancing Multimodal Reasoning of Large Language Models**
2406.03843v1 by Jianben He, Xingbo Wang, Shiyi Liu, Guande Wu, Claudio Silva, Huamin Qu

Large language models (LLMs) have exhibited impressive abilities for
multimodal content comprehension and reasoning with proper prompting in zero-
or few-shot settings. Despite the proliferation of interactive systems
developed to support prompt engineering for LLMs across various tasks, most
have primarily focused on textual or visual inputs, thus neglecting the complex
interplay between modalities within multimodal inputs. This oversight hinders
the development of effective prompts that guide model multimodal reasoning
processes by fully exploiting the rich context provided by multiple modalities.
In this paper, we present POEM, a visual analytics system to facilitate
efficient prompt engineering for enhancing the multimodal reasoning performance
of LLMs. The system enables users to explore the interaction patterns across
modalities at varying levels of detail for a comprehensive understanding of the
multimodal knowledge elicited by various prompts. Through diverse
recommendations of demonstration examples and instructional principles, POEM
supports users in iteratively crafting and refining prompts to better align and
enhance model knowledge with human insights. The effectiveness and efficiency
of our system are validated through two case studies and interviews with
experts.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®Â§öÊ®°ÊÖãÂÖßÂÆπÁêÜËß£ÂíåÊé®ÁêÜÊñπÈù¢Ë°®ÁèæÂá∫‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑËÉΩÂäõÔºå‰∏¶Âú®Èõ∂Ê¨°ÊàñÂ∞ëÊ¨°ÂòóË©¶ÁöÑË®≠ÂÆö‰∏≠ÈÅ©Áï∂Âú∞ÊèêÁ§∫„ÄÇÂÑòÁÆ°ÈñãÁôº‰∫ÜË®±Â§ö‰∫íÂãïÂºèÁ≥ªÁµ±‰æÜÊîØÊè¥ LLM ÁöÑÊèêÁ§∫Â∑•Á®ãÔºå‰ΩÜÂ§ßÂ§öÊï∏‰∏ªË¶ÅÈõÜ‰∏≠Âú®ÊñáÂ≠óÊàñË¶ñË¶∫Ëº∏ÂÖ•ÔºåÂõ†Ê≠§ÂøΩÁï•‰∫ÜÂ§öÊ®°ÊÖãËº∏ÂÖ•‰∏≠Ê®°ÊÖã‰πãÈñìÁöÑË§áÈõú‰∫§‰∫í‰ΩúÁî®„ÄÇÈÄôÁ®ÆÁñèÂøΩÈòªÁ§ô‰∫ÜÊúâÊïàÊèêÁ§∫ÁöÑÁôºÂ±ïÔºåÈÄô‰∫õÊèêÁ§∫ÈÄöÈÅéÂÖÖÂàÜÂà©Áî®Â§öÁ®ÆÊ®°ÊÖãÊèê‰æõÁöÑË±êÂØåËÉåÊôØ‰æÜÊåáÂ∞éÊ®°ÂûãÂ§öÊ®°ÊÖãÊé®ÁêÜÈÅéÁ®ã„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü POEMÔºåÈÄôÊòØ‰∏ÄÂÄãË¶ñË¶∫ÂàÜÊûêÁ≥ªÁµ±ÔºåÁî®Êñº‰øÉÈÄ≤ÊúâÊïàÁöÑÊèêÁ§∫Â∑•Á®ãÔºå‰ª•Â¢ûÂº∑ LLM ÁöÑÂ§öÊ®°ÊÖãÊé®ÁêÜÊïàËÉΩ„ÄÇË©≤Á≥ªÁµ±‰ΩøÁî®Êà∂ËÉΩÂ§†Êé¢Á¥¢‰∏çÂêåÂ±§Á¥öÁ¥∞ÁØÄ‰∏≠Ë∑®Ê®°ÊÖãÁöÑ‰∫§‰∫íÊ®°ÂºèÔºå‰ª•ÂÖ®Èù¢‰∫ÜËß£ÂêÑÁ®ÆÊèêÁ§∫ÂºïÁôºÁöÑÂ§öÊ®°ÊÖãÁü•Ë≠ò„ÄÇÈÄèÈÅéÁ§∫ÁØÑÁØÑ‰æãÂíåÊïôÂ≠∏ÂéüÂâáÁöÑÂ§öÊ®£ÂåñÂª∫Ë≠∞ÔºåPOEM ÊîØÊè¥‰ΩøÁî®ËÄÖÂèçË¶ÜÂª∫ÊßãÂíåË™øÊï¥ÊèêÁ§∫Ôºå‰ª•Êõ¥Â•ΩÂú∞Ëàá‰∫∫È°ûË¶ãËß£Â∞çÈΩä‰∏¶Â¢ûÂº∑Ê®°ÂûãÁü•Ë≠ò„ÄÇÊàëÂÄëÁ≥ªÁµ±ÁöÑÊúâÊïàÊÄßÂíåÊïàÁéáÂ∑≤ÈÄöÈÅéÂÖ©ÂÄãÊ°à‰æãÁ†îÁ©∂ÂíåÂ∞àÂÆ∂Ë®™Ë´áÂæóÂà∞È©óË≠â„ÄÇ

##### **Proactive Detection of Physical Inter-rule Vulnerabilities in IoT Services Using a Deep Learning Approach**
2406.03836v1 by Bing Huang, Chen Chen, Kwok-Yan Lam, Fuqun Huang

Emerging Internet of Things (IoT) platforms provide sophisticated
capabilities to automate IoT services by enabling occupants to create
trigger-action rules. Multiple trigger-action rules can physically interact
with each other via shared environment channels, such as temperature, humidity,
and illumination. We refer to inter-rule interactions via shared environment
channels as a physical inter-rule vulnerability. Such vulnerability can be
exploited by attackers to launch attacks against IoT systems. We propose a new
framework to proactively discover possible physical inter-rule interactions
from user requirement specifications (i.e., descriptions) using a deep learning
approach. Specifically, we utilize the Transformer model to generate
trigger-action rules from their associated descriptions. We discover two types
of physical inter-rule vulnerabilities and determine associated environment
channels using natural language processing (NLP) tools. Given the extracted
trigger-action rules and associated environment channels, an approach is
proposed to identify hidden physical inter-rule vulnerabilities among them. Our
experiment on 27983 IFTTT style rules shows that the Transformer can
successfully extract trigger-action rules from descriptions with 95.22%
accuracy. We also validate the effectiveness of our approach on 60 SmartThings
official IoT apps and discover 99 possible physical inter-rule vulnerabilities.

ÊëòË¶ÅÔºöÊñ∞ËààÁöÑÁâ©ËÅØÁ∂≤ (IoT) Âπ≥Âè∞Êèê‰æõÂÖàÈÄ≤ÁöÑÂäüËÉΩÔºåÂèØÈÄöÈÅéËÆì‰ΩøÁî®ËÄÖÂª∫Á´ãËß∏ÁôºÂãï‰ΩúË¶èÂâá‰æÜËá™ÂãïÂåñ IoT ÊúçÂãô„ÄÇÂ§öÂÄãËß∏ÁôºÂãï‰ΩúË¶èÂâáÂèØÈÄèÈÅéÂÖ±Áî®Áí∞Â¢ÉÈÄöÈÅìÔºà‰æãÂ¶ÇÊ∫´Â∫¶„ÄÅÊøïÂ∫¶ÂíåÁÖßÊòéÔºâÂΩºÊ≠§ÈÄ≤Ë°åÂØ¶È´î‰∫íÂãï„ÄÇÊàëÂÄëÂ∞áÈÄèÈÅéÂÖ±Áî®Áí∞Â¢ÉÈÄöÈÅìÁöÑË¶èÂâáÈñì‰∫íÂãïÁ®±ÁÇ∫ÂØ¶È´îË¶èÂâáÈñìÊºèÊ¥û„ÄÇÊîªÊìäËÄÖÂèØ‰ª•Âà©Áî®Ê≠§È°ûÊºèÊ¥ûÂ∞ç IoT Á≥ªÁµ±ÁôºÂãïÊîªÊìä„ÄÇÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÊñ∞ÁöÑÊû∂ÊßãÔºå‰ª•‰ΩøÁî®Ê∑±Â∫¶Â≠∏ÁøíÊñπÊ≥ïÂæû‰ΩøÁî®ËÄÖÈúÄÊ±ÇË¶èÊ†ºÔºàÂç≥ÊèèËø∞Ôºâ‰∏≠‰∏ªÂãïÁôºÁèæÂèØËÉΩÁöÑÂØ¶È´îË¶èÂâáÈñì‰∫íÂãï„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÂà©Áî® Transformer Ê®°ÂûãÂæûÂÖ∂Áõ∏ÈóúÊèèËø∞‰∏≠Áî¢ÁîüËß∏ÁôºÂãï‰ΩúË¶èÂâá„ÄÇÊàëÂÄëÁôºÁèæÂÖ©Á®ÆÈ°ûÂûãÁöÑÂØ¶È´îË¶èÂâáÈñìÊºèÊ¥ûÔºå‰∏¶‰ΩøÁî®Ëá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ (NLP) Â∑•ÂÖ∑Á¢∫ÂÆöÁõ∏ÈóúÁöÑÁí∞Â¢ÉÈÄöÈÅì„ÄÇÈáùÂ∞çÊèêÂèñÁöÑËß∏ÁôºÂãï‰ΩúË¶èÂâáÂíåÁõ∏ÈóúÁí∞Â¢ÉÈÄöÈÅìÔºåÊèêÂá∫‰∏ÄÂÄãÊñπÊ≥ï‰æÜË≠òÂà•ÂÆÉÂÄë‰πãÈñìÈö±ËóèÁöÑÂØ¶È´îË¶èÂâáÈñìÊºèÊ¥û„ÄÇÊàëÂÄëÂ∞ç 27983 ÂÄã IFTTT È¢®Ê†ºË¶èÂâáÁöÑÂØ¶È©óÈ°ØÁ§∫ÔºåTransformer ÂèØ‰ª•ÂæûÊèèËø∞‰∏≠ÊàêÂäüÊèêÂèñËß∏ÁôºÂãï‰ΩúË¶èÂâáÔºåÊ∫ñÁ¢∫Â∫¶ÁÇ∫ 95.22%„ÄÇÊàëÂÄëÈÇÑÈ©óË≠â‰∫ÜÊàëÂÄëÁöÑÊñπÊ≥ïÂ∞ç 60 ÂÄã SmartThings ÂÆòÊñπ IoT ÊáâÁî®Á®ãÂºèÁöÑÊúâÊïàÊÄßÔºå‰∏¶ÁôºÁèæ 99 ÂÄãÂèØËÉΩÁöÑÂØ¶È´îË¶èÂâáÈñìÊºèÊ¥û„ÄÇ

##### **Chaos with Keywords: Exposing Large Language Models Sycophancy to Misleading Keywords and Evaluating Defense Strategies**
2406.03827v1 by Aswin RRV, Nemika Tyagi, Md Nayem Uddin, Neeraj Varshney, Chitta Baral

This study explores the sycophantic tendencies of Large Language Models
(LLMs), where these models tend to provide answers that match what users want
to hear, even if they are not entirely correct. The motivation behind this
exploration stems from the common behavior observed in individuals searching
the internet for facts with partial or misleading knowledge. Similar to using
web search engines, users may recall fragments of misleading keywords and
submit them to an LLM, hoping for a comprehensive response. Our empirical
analysis of several LLMs shows the potential danger of these models amplifying
misinformation when presented with misleading keywords. Additionally, we
thoroughly assess four existing hallucination mitigation strategies to reduce
LLMs sycophantic behavior. Our experiments demonstrate the effectiveness of
these strategies for generating factually correct statements. Furthermore, our
analyses delve into knowledge-probing experiments on factual keywords and
different categories of sycophancy mitigation.

ÊëòË¶ÅÔºöÊú¨Á†îÁ©∂Êé¢Ë®éÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑË∂®ÁÇéÈôÑÂã¢ÂÇæÂêëÔºåÈÄô‰∫õÊ®°ÂûãÂÇæÂêëÊñºÊèê‰æõÁ¨¶Âêà‰ΩøÁî®ËÄÖÊÉ≥Ë¶ÅËÅΩÂà∞ÁöÑÁ≠îÊ°àÔºåÂç≥‰ΩøÈÄô‰∫õÁ≠îÊ°à‰∏¶ÈùûÂÆåÂÖ®Ê≠£Á¢∫„ÄÇÈÄôÈ†ÖÊé¢Ë®éÁöÑÂãïÊ©ü‰æÜËá™ÊñºÂÄã‰∫∫Âú®Á∂≤Ë∑Ø‰∏äÊêúÂ∞ã‰∫ãÂØ¶ÊôÇÔºåÂ∏∏ÊúÉÂá∫ÁèæÈÉ®ÂàÜÊàñË™§Â∞éÊÄßÁöÑÁü•Ë≠ò„ÄÇ‰ΩøÁî®ËÄÖÂèØËÉΩÊúÉË®ò‰ΩèË™§Â∞éÊÄßÈóúÈçµÂ≠óÁöÑÁâáÊÆµÔºå‰∏¶Â∞áÂÆÉÂÄëÊèê‰∫§Áµ¶ LLMÔºåÂ∏åÊúõËÉΩÁç≤ÂæóÂÖ®Èù¢ÁöÑÂõûÊáâÔºåÈÄôÈ°û‰ººÊñº‰ΩøÁî®Á∂≤Ë∑ØÊêúÂ∞ãÂºïÊìé„ÄÇÊàëÂÄëÂ∞çÂ§öÂÄã LLM ÈÄ≤Ë°åÁöÑÂØ¶Ë≠âÂàÜÊûêÈ°ØÁ§∫ÔºåÁï∂Êèê‰æõË™§Â∞éÊÄßÈóúÈçµÂ≠óÊôÇÔºåÈÄô‰∫õÊ®°ÂûãÊîæÂ§ßÈåØË™§Ë≥áË®äÁöÑÊΩõÂú®Âç±Èö™„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂæπÂ∫ïË©ï‰º∞‰∫ÜÂõõÁ®ÆÁèæÊúâÁöÑÂπªË¶∫Á∑©Ëß£Á≠ñÁï•Ôºå‰ª•Ê∏õÂ∞ë LLM ÁöÑË∂®ÁÇéÈôÑÂã¢Ë°åÁÇ∫„ÄÇÊàëÂÄëÁöÑÂØ¶È©óË≠âÊòé‰∫ÜÈÄô‰∫õÁ≠ñÁï•Âú®Áî¢Áîü‰∫ãÂØ¶Ê≠£Á¢∫ÁöÑÈô≥Ëø∞ÊñπÈù¢ÁöÑÊúâÊïàÊÄß„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁöÑÂàÜÊûêÊ∑±ÂÖ•Êé¢Ë®é‰∫ÜÂ∞ç‰∫ãÂØ¶ÈóúÈçµÂ≠óÂíå‰∏çÂêåÈ°ûÂà•ÁöÑË∂®ÁÇéÈôÑÂã¢Á∑©Ëß£ÈÄ≤Ë°åÁöÑÁü•Ë≠òÊé¢Ê∏¨ÂØ¶È©ó„ÄÇ

##### **A Survey on Intelligent Internet of Things: Applications, Security, Privacy, and Future Directions**
2406.03820v1 by Ons Aouedi, Thai-Hoc Vu, Alessio Sacco, Dinh C. Nguyen, Kandaraj Piamrat, Guido Marchetto, Quoc-Viet Pham

The rapid advances in the Internet of Things (IoT) have promoted a revolution
in communication technology and offered various customer services. Artificial
intelligence (AI) techniques have been exploited to facilitate IoT operations
and maximize their potential in modern application scenarios. In particular,
the convergence of IoT and AI has led to a new networking paradigm called
Intelligent IoT (IIoT), which has the potential to significantly transform
businesses and industrial domains. This paper presents a comprehensive survey
of IIoT by investigating its significant applications in mobile networks, as
well as its associated security and privacy issues. Specifically, we explore
and discuss the roles of IIoT in a wide range of key application domains, from
smart healthcare and smart cities to smart transportation and smart industries.
Through such extensive discussions, we investigate important security issues in
IIoT networks, where network attacks, confidentiality, integrity, and intrusion
are analyzed, along with a discussion of potential countermeasures. Privacy
issues in IIoT networks were also surveyed and discussed, including data,
location, and model privacy leakage. Finally, we outline several key challenges
and highlight potential research directions in this important area.

ÊëòË¶ÅÔºöÁâ©ËÅîÁΩë (IoT) ÁöÑÂø´ÈÄüËøõÊ≠•‰øÉËøõ‰∫ÜÈÄö‰ø°ÊäÄÊúØÁöÑÈù©ÂëΩÔºåÂπ∂Êèê‰æõ‰∫ÜÂêÑÁßçÂÆ¢Êà∑ÊúçÂä°„ÄÇ‰∫∫Â∑•Êô∫ËÉΩ (AI) ÊäÄÊúØÂ∑≤Ë¢´Áî®Êù•‰øÉËøõÁâ©ËÅîÁΩëÊìç‰ΩúÔºåÂπ∂Âú®Áé∞‰ª£Â∫îÁî®Âú∫ÊôØ‰∏≠ÊúÄÂ§ßÂåñÂÖ∂ÊΩúÂäõ„ÄÇÁâπÂà´ÊòØÔºåÁâ©ËÅîÁΩëÂíå‰∫∫Â∑•Êô∫ËÉΩÁöÑËûçÂêàÂÇ¨Áîü‰∫Ü‰∏ÄÁßçÁß∞‰∏∫Êô∫ËÉΩÁâ©ËÅîÁΩë (IIoT) ÁöÑÊñ∞ÁΩëÁªúËåÉ‰æãÔºåÂÆÉÊúâÂèØËÉΩÊûÅÂ§ßÂú∞ÊîπÂèòÂïÜ‰∏öÂíåÂ∑•‰∏öÈ¢ÜÂüü„ÄÇÊú¨ÊñáÈÄöËøáË∞ÉÊü• IIoT Âú®ÁßªÂä®ÁΩëÁªú‰∏≠ÁöÑÈáçË¶ÅÂ∫îÁî®ÂèäÂÖ∂Áõ∏ÂÖ≥ÁöÑÂÆâÂÖ®ÂíåÈöêÁßÅÈóÆÈ¢òÔºåÂØπ IIoT ËøõË°å‰∫ÜÂÖ®Èù¢ÁöÑË∞ÉÊü•„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåÊàë‰ª¨Êé¢ËÆ®Âπ∂ËÆ®ËÆ∫‰∫Ü IIoT Âú®ÂπøÊ≥õÁöÑÂÖ≥ÈîÆÂ∫îÁî®È¢ÜÂüü‰∏≠ÁöÑ‰ΩúÁî®Ôºå‰ªéÊô∫ËÉΩÂåªÁñó‰øùÂÅ•ÂíåÊô∫ÊÖßÂüéÂ∏ÇÂà∞Êô∫ËÉΩ‰∫§ÈÄöÂíåÊô∫ËÉΩ‰∫ß‰∏ö„ÄÇÈÄöËøáÂ¶ÇÊ≠§ÂπøÊ≥õÁöÑËÆ®ËÆ∫ÔºåÊàë‰ª¨Ë∞ÉÊü•‰∫Ü IIoT ÁΩëÁªú‰∏≠ÁöÑÈáçË¶ÅÂÆâÂÖ®ÈóÆÈ¢òÔºåÂÖ∂‰∏≠ÂàÜÊûê‰∫ÜÁΩëÁªúÊîªÂáª„ÄÅÊú∫ÂØÜÊÄß„ÄÅÂÆåÊï¥ÊÄßÂíåÂÖ•‰æµÔºåÂπ∂ËÆ®ËÆ∫‰∫ÜÊΩúÂú®ÁöÑÂØπÁ≠ñ„ÄÇËøòÂØπ IIoT ÁΩëÁªú‰∏≠ÁöÑÈöêÁßÅÈóÆÈ¢òËøõË°å‰∫ÜË∞ÉÊü•ÂíåËÆ®ËÆ∫ÔºåÂåÖÊã¨Êï∞ÊçÆ„ÄÅ‰ΩçÁΩÆÂíåÊ®°ÂûãÈöêÁßÅÊ≥ÑÈú≤„ÄÇÊúÄÂêéÔºåÊàë‰ª¨Ê¶ÇËø∞‰∫ÜÂá†‰∏™ÂÖ≥ÈîÆÊåëÊàòÔºåÂπ∂ÈáçÁÇπ‰ªãÁªç‰∫ÜËøô‰∏ÄÈáçË¶ÅÈ¢ÜÂüüÁöÑÊΩúÂú®Á†îÁ©∂ÊñπÂêë„ÄÇ

##### **ReST-MCTS*: LLM Self-Training via Process Reward Guided Tree Search**
2406.03816v1 by Dan Zhang, Sining Zhoubian, Yisong Yue, Yuxiao Dong, Jie Tang

Recent methodologies in LLM self-training mostly rely on LLM generating
responses and filtering those with correct output answers as training data.
This approach often yields a low-quality fine-tuning training set (e.g.,
incorrect plans or intermediate reasoning). In this paper, we develop a
reinforced self-training approach, called ReST-MCTS*, based on integrating
process reward guidance with tree search MCTS* for collecting higher-quality
reasoning traces as well as per-step value to train policy and reward models.
ReST-MCTS* circumvents the per-step manual annotation typically used to train
process rewards by tree-search-based reinforcement learning: Given oracle final
correct answers, ReST-MCTS* is able to infer the correct process rewards by
estimating the probability this step can help lead to the correct answer. These
inferred rewards serve dual purposes: they act as value targets for further
refining the process reward model and also facilitate the selection of
high-quality traces for policy model self-training. We first show that the
tree-search policy in ReST-MCTS* achieves higher accuracy compared with prior
LLM reasoning baselines such as Best-of-N and Tree-of-Thought, within the same
search budget. We then show that by using traces searched by this tree-search
policy as training data, we can continuously enhance the three language models
for multiple iterations, and outperform other self-training algorithms such as
ReST$^\text{EM}$ and Self-Rewarding LM.

ÊëòË¶ÅÔºöÊúÄËøë LLM Ëá™ÊàëËÆ≠ÁªÉÁöÑÊñπÊ≥ï‰∏ªË¶Å‰æùËµñ‰∫é LLM ÁîüÊàêÂìçÂ∫îÔºåÂπ∂ËøáÊª§ÈÇ£‰∫õÂÖ∑ÊúâÊ≠£Á°ÆËæìÂá∫Á≠îÊ°àÁöÑÂìçÂ∫î‰Ωú‰∏∫ËÆ≠ÁªÉÊï∞ÊçÆ„ÄÇËøôÁßçÊñπÊ≥ïÈÄöÂ∏∏‰ºö‰∫ßÁîü‰ΩéË¥®ÈáèÁöÑÂæÆË∞ÉËÆ≠ÁªÉÈõÜÔºà‰æãÂ¶ÇÔºå‰∏çÊ≠£Á°ÆÁöÑËÆ°ÂàíÊàñ‰∏≠Èó¥Êé®ÁêÜÔºâ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨ÂºÄÂèë‰∫Ü‰∏ÄÁßçÁß∞‰∏∫ ReST-MCTS* ÁöÑÂº∫ÂåñËá™ÊàëËÆ≠ÁªÉÊñπÊ≥ïÔºåËØ•ÊñπÊ≥ïÂü∫‰∫éÂ∞ÜËøáÁ®ãÂ•ñÂä±ÊåáÂØº‰∏éÊ†ëÊêúÁ¥¢ MCTS* Áõ∏ÁªìÂêàÔºå‰ª•Êî∂ÈõÜÊõ¥È´òË¥®ÈáèÁöÑÊé®ÁêÜËΩ®Ëøπ‰ª•ÂèäÁî®‰∫éËÆ≠ÁªÉÁ≠ñÁï•ÂíåÂ•ñÂä±Ê®°ÂûãÁöÑÊØèÊ≠•‰ª∑ÂÄº„ÄÇReST-MCTS* ÈÄöËøáÂü∫‰∫éÊ†ëÊêúÁ¥¢ÁöÑÂº∫ÂåñÂ≠¶‰π†ÁªïËøá‰∫ÜÈÄöÂ∏∏Áî®‰∫éËÆ≠ÁªÉËøáÁ®ãÂ•ñÂä±ÁöÑÊØèÊ≠•‰∫∫Â∑•Ê≥®ÈáäÔºöÁªôÂÆö oracle ÊúÄÁªàÊ≠£Á°ÆÁ≠îÊ°àÔºåReST-MCTS* ËÉΩÂ§üÈÄöËøá‰º∞ËÆ°Ê≠§Ê≠•È™§ÊúâÂä©‰∫éÂæóÂá∫Ê≠£Á°ÆÁ≠îÊ°àÁöÑÊ¶ÇÁéáÊù•Êé®Êñ≠Ê≠£Á°ÆÁöÑËøáÁ®ãÂ•ñÂä±„ÄÇËøô‰∫õÊé®Êñ≠Âá∫ÁöÑÂ•ñÂä±ÂÖ∑ÊúâÂèåÈáçÁõÆÁöÑÔºöÂÆÉ‰ª¨ÂÖÖÂΩìËøõ‰∏ÄÊ≠•‰ºòÂåñËøáÁ®ãÂ•ñÂä±Ê®°ÂûãÁöÑ‰ª∑ÂÄºÁõÆÊ†áÔºåÂπ∂‰∏îËøòÊúâÂä©‰∫é‰∏∫Á≠ñÁï•Ê®°ÂûãËá™ÊàëËÆ≠ÁªÉÈÄâÊã©È´òË¥®ÈáèÁöÑËΩ®Ëøπ„ÄÇÊàë‰ª¨È¶ñÂÖàË°®ÊòéÔºå‰∏éÂÖàÂâçÁöÑ LLM Êé®ÁêÜÂü∫ÂáÜÔºàÂ¶Ç Best-of-N Âíå Tree-of-ThoughtÔºâÁõ∏ÊØîÔºåReST-MCTS* ‰∏≠ÁöÑÊ†ëÊêúÁ¥¢Á≠ñÁï•Âú®Áõ∏ÂêåÁöÑÊêúÁ¥¢È¢ÑÁÆóÂÜÖÂÆûÁé∞‰∫ÜÊõ¥È´òÁöÑÂáÜÁ°ÆÊÄß„ÄÇÁÑ∂ÂêéÊàë‰ª¨Ë°®ÊòéÔºåÈÄöËøá‰ΩøÁî®Ê≠§Ê†ëÊêúÁ¥¢Á≠ñÁï•ÊêúÁ¥¢ÁöÑËΩ®Ëøπ‰Ωú‰∏∫ËÆ≠ÁªÉÊï∞ÊçÆÔºåÊàë‰ª¨ÂèØ‰ª•ÊåÅÁª≠Â¢ûÂº∫‰∏â‰∏™ËØ≠Ë®ÄÊ®°Âûã‰ª•ËøõË°åÂ§öÊ¨°Ëø≠‰ª£ÔºåÂπ∂‰∏î‰ºò‰∫éÂÖ∂‰ªñËá™ÊàëËÆ≠ÁªÉÁÆóÊ≥ïÔºåÂ¶Ç ReST$^\text{EM}$ Âíå Self-Rewarding LM„ÄÇ

##### **Improving Zero-Shot Chinese-English Code-Switching ASR with kNN-CTC and Gated Monolingual Datastores**
2406.03814v1 by Jiaming Zhou, Shiwan Zhao, Hui Wang, Tian-Hao Zhang, Haoqin Sun, Xuechen Wang, Yong Qin

The kNN-CTC model has proven to be effective for monolingual automatic speech
recognition (ASR). However, its direct application to multilingual scenarios
like code-switching, presents challenges. Although there is potential for
performance improvement, a kNN-CTC model utilizing a single bilingual datastore
can inadvertently introduce undesirable noise from the alternative language. To
address this, we propose a novel kNN-CTC-based code-switching ASR (CS-ASR)
framework that employs dual monolingual datastores and a gated datastore
selection mechanism to reduce noise interference. Our method selects the
appropriate datastore for decoding each frame, ensuring the injection of
language-specific information into the ASR process. We apply this framework to
cutting-edge CTC-based models, developing an advanced CS-ASR system. Extensive
experiments demonstrate the remarkable effectiveness of our gated datastore
mechanism in enhancing the performance of zero-shot Chinese-English CS-ASR.

ÊëòË¶ÅÔºökNN-CTC Ê®°ÂûãÂ∑≤Ë≠âÊòéÂ∞çÂñÆË™ûËá™ÂãïË™ûÈü≥Ëæ®Ë≠ò (ASR) ÊúâÊïà„ÄÇÁÑ∂ËÄåÔºåÂÆÉÁõ¥Êé•ÊáâÁî®ÊñºÂ§öË™ûÁí∞Â¢ÉÔºà‰æãÂ¶Ç‰ª£Á¢ºÂàáÊèõÔºâÊôÇÊúÉÁî¢ÁîüÊåëÊà∞„ÄÇÂÑòÁÆ°ÊúâÊΩõÂäõÊîπÂñÑÊïàËÉΩÔºå‰ΩÜ‰ΩøÁî®ÂñÆ‰∏ÄÈõôË™ûË≥áÊñôÂÑ≤Â≠òÂ∫´ÁöÑ kNN-CTC Ê®°ÂûãÂèØËÉΩÊúÉÁÑ°ÊÑèÈñìÂæûÂè¶‰∏ÄÁ®ÆË™ûË®ÄÂºïÂÖ•‰∏çÂøÖË¶ÅÁöÑÈõúË®ä„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÊñ∞ÁöÑÂü∫Êñº kNN-CTC ÁöÑ‰ª£Á¢ºÂàáÊèõ ASR (CS-ASR) Êû∂ÊßãÔºåÂÆÉÊé°Áî®ÈõôÈáçÂñÆË™ûË≥áÊñôÂÑ≤Â≠òÂ∫´Âíå‰∏ÄÂÄãÈñòÊéßË≥áÊñôÂÑ≤Â≠òÂ∫´ÈÅ∏ÊìáÊ©üÂà∂‰æÜÊ∏õÂ∞ëÈõúË®äÂπ≤Êìæ„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÊúÉÈáùÂ∞çËß£Á¢ºÊØèÂÄãÊ°ÜÊû∂ÈÅ∏ÊìáÈÅ©Áï∂ÁöÑË≥áÊñôÂÑ≤Â≠òÂ∫´ÔºåÁ¢∫‰øùÂ∞áÁâπÂÆöË™ûË®ÄÁöÑË≥áË®äÊ≥®ÂÖ• ASR ËôïÁêÜÁ®ãÂ∫è„ÄÇÊàëÂÄëÂ∞áÈÄôÂÄãÊû∂ÊßãÂ•óÁî®ÊñºÂ∞ñÁ´ØÁöÑÂü∫Êñº CTC ÁöÑÊ®°ÂûãÔºåÈñãÁôºÂá∫ÈÄ≤ÈöéÁöÑ CS-ASR Á≥ªÁµ±„ÄÇÂª£Ê≥õÁöÑÂØ¶È©óË≠âÊòé‰∫ÜÊàëÂÄëÁöÑÈñòÊéßË≥áÊñôÂÑ≤Â≠òÂ∫´Ê©üÂà∂Âú®ÊèêÂçáÈõ∂Ê¨°Â≠∏Áøí‰∏≠Ëã± CS-ASR ÊïàËÉΩÊñπÈù¢ÁöÑÈ°ØËëóÊïàÁî®„ÄÇ

##### **Cross-variable Linear Integrated ENhanced Transformer for Photovoltaic power forecasting**
2406.03808v1 by Jiaxin Gao, Qinglong Cao, Yuntian Chen, Dongxiao Zhang

Photovoltaic (PV) power forecasting plays a crucial role in optimizing the
operation and planning of PV systems, thereby enabling efficient energy
management and grid integration. However, un certainties caused by fluctuating
weather conditions and complex interactions between different variables pose
significant challenges to accurate PV power forecasting. In this study, we
propose PV-Client (Cross-variable Linear Integrated ENhanced Transformer for
Photovoltaic power forecasting) to address these challenges and enhance PV
power forecasting accuracy. PV-Client employs an ENhanced Transformer module to
capture complex interactions of various features in PV systems, and utilizes a
linear module to learn trend information in PV power. Diverging from
conventional time series-based Transformer models that use cross-time Attention
to learn dependencies between different time steps, the Enhanced Transformer
module integrates cross-variable Attention to capture dependencies between PV
power and weather factors. Furthermore, PV-Client streamlines the embedding and
position encoding layers by replacing the Decoder module with a projection
layer. Experimental results on three real-world PV power datasets affirm
PV-Client's state-of-the-art (SOTA) performance in PV power forecasting.
Specifically, PV-Client surpasses the second-best model GRU by 5.3% in MSE
metrics and 0.9% in accuracy metrics at the Jingang Station. Similarly,
PV-Client outperforms the second-best model SVR by 10.1% in MSE metrics and
0.2% in accuracy metrics at the Xinqingnian Station, and PV-Client exhibits
superior performance compared to the second-best model SVR with enhancements of
3.4% in MSE metrics and 0.9% in accuracy metrics at the Hongxing Station.

ÊëòË¶ÅÔºöÂÖâ‰ºè (PV) ÈõªÂäõÈ†êÊ∏¨Âú®ÊúÄ‰Ω≥ÂåñÂÖâ‰ºèÁ≥ªÁµ±ÁöÑÈÅã‰ΩúÂíåË¶èÂäÉ‰∏≠ÊâÆÊºîËëóËá≥ÈóúÈáçË¶ÅÁöÑËßíËâ≤ÔºåÈÄ≤ËÄåËÉΩÈÄ≤Ë°åÊúâÊïàÁéáÁöÑËÉΩÊ∫êÁÆ°ÁêÜÂíåÈõªÁ∂≤Êï¥Âêà„ÄÇÁÑ∂ËÄåÔºåÁî±ÊñºÂ§©Ê∞£ÁãÄÊ≥ÅÂ§öËÆä‰ª•Âèä‰∏çÂêåËÆäÊï∏‰πãÈñìË§áÈõúÁöÑ‰∫§‰∫í‰ΩúÁî®ÊâÄÈÄ†ÊàêÁöÑÂêÑÁ®Æ‰∏çÁ¢∫ÂÆöÊÄßÔºåÂ∞çÊ∫ñÁ¢∫ÁöÑÂÖâ‰ºèÈõªÂäõÈ†êÊ∏¨ÊßãÊàê‰∫ÜÈáçÂ§ßÁöÑÊåëÊà∞„ÄÇÂú®ÈÄôÈ†ÖÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄëÊèêÂá∫ PV-ClientÔºàÂÖâ‰ºèÈõªÂäõÈ†êÊ∏¨ÁöÑË∑®ËÆäÊï∏Á∑öÊÄßÊï¥ÂêàÂº∑Âåñ TransformerÔºâÔºå‰ª•ÊáâÂ∞çÈÄô‰∫õÊåëÊà∞‰∏¶ÊèêÂçáÂÖâ‰ºèÈõªÂäõÈ†êÊ∏¨ÁöÑÊ∫ñÁ¢∫Â∫¶„ÄÇPV-Client Êé°Áî®Âº∑Âåñ Transformer Ê®°ÁµÑ‰æÜÊì∑ÂèñÂÖâ‰ºèÁ≥ªÁµ±‰∏≠ÂêÑÁ®ÆÁâπÂæµÁöÑË§áÈõú‰∫§‰∫í‰ΩúÁî®Ôºå‰∏¶Âà©Áî®Á∑öÊÄßÊ®°ÁµÑ‰æÜÂ≠∏ÁøíÂÖâ‰ºèÈõªÂäõÁöÑË∂®Âã¢Ë≥áË®ä„ÄÇÊúâÂà•Êñº‰ΩøÁî®Ë∑®ÊôÇÈñìÊ≥®ÊÑèÂäõ‰æÜÂ≠∏Áøí‰∏çÂêåÊôÇÈñìÊ≠•Èï∑‰πãÈñì‰æùË≥¥Èóú‰øÇÁöÑÂÇ≥Áµ±Âü∫ÊñºÊôÇÈñìÂ∫èÂàóÁöÑ Transformer Ê®°ÂûãÔºåÂº∑Âåñ Transformer Ê®°ÁµÑÊï¥Âêà‰∫ÜË∑®ËÆäÊï∏Ê≥®ÊÑèÂäõÔºå‰ª•Êì∑ÂèñÂÖâ‰ºèÈõªÂäõËàáÂ§©Ê∞£Âõ†Á¥†‰πãÈñìÁöÑ‰æùË≥¥Èóú‰øÇ„ÄÇÊ≠§Â§ñÔºåPV-Client ÈÄèÈÅéÂ∞áËß£Á¢ºÂô®Ê®°ÁµÑÊõøÊèõÊàêÊäïÂΩ±Â±§ÔºåÁ∞°Âåñ‰∫ÜÂµåÂÖ•Âíå‰ΩçÁΩÆÁ∑®Á¢ºÂ±§„ÄÇÂú®‰∏âÂÄãÁúüÂØ¶‰∏ñÁïåÂÖâ‰ºèÈõªÂäõË≥áÊñôÈõÜ‰∏äÁöÑÂØ¶È©óÁµêÊûúË≠âÂØ¶‰∫Ü PV-Client Âú®ÂÖâ‰ºèÈõªÂäõÈ†êÊ∏¨‰∏≠ÂÖ∑ÊúâÊúÄÂÖàÈÄ≤ (SOTA) ÁöÑÊïàËÉΩ„ÄÇÂÖ∑È´îËÄåË®ÄÔºåÂú®ÊôØÊ∏ØÁ´ôÔºåPV-Client Âú® MSE ÊåáÊ®ô‰∏äË∂ÖË∂ä‰∫ÜÁ¨¨‰∫å‰Ω≥Ê®°Âûã GRU 5.3%ÔºåÂú®Ê∫ñÁ¢∫Â∫¶ÊåáÊ®ô‰∏äË∂ÖË∂ä‰∫Ü 0.9%„ÄÇÂêåÊ®£Âú∞ÔºåÂú®‰ø°ÈùíÂπ¥ÈñìÔºåPV-Client Âú® MSE ÊåáÊ®ô‰∏äË∂ÖË∂ä‰∫ÜÁ¨¨‰∫å‰Ω≥Ê®°Âûã SVR 10.1%ÔºåÂú®Ê∫ñÁ¢∫Â∫¶ÊåáÊ®ô‰∏äË∂ÖË∂ä‰∫Ü 0.2%ÔºåËÄåÂú®Á¥ÖÊòüÁ´ôÔºåPV-Client Âú® MSE ÊåáÊ®ô‰∏äË∂ÖË∂ä‰∫ÜÁ¨¨‰∫å‰Ω≥Ê®°Âûã SVR 3.4%ÔºåÂú®Ê∫ñÁ¢∫Â∫¶ÊåáÊ®ô‰∏äË∂ÖË∂ä‰∫Ü 0.9%ÔºåÂ±ïÁèæ‰∫ÜÂçìË∂äÁöÑÊïàËÉΩ„ÄÇ

##### **Tool-Planner: Dynamic Solution Tree Planning for Large Language Model with Tool Clustering**
2406.03807v1 by Yanming Liu, Xinyue Peng, Yuwei Zhang, Jiannan Cao, Xuhong Zhang, Sheng Cheng, Xun Wang, Jianwei Yin, Tianyu Du

Large language models (LLMs) have demonstrated exceptional reasoning
capabilities, enabling them to solve various complex problems. Recently, this
ability has been applied to the paradigm of tool learning. Tool learning
involves providing examples of tool usage and their corresponding functions,
allowing LLMs to formulate plans and demonstrate the process of invoking and
executing each tool. LLMs can address tasks that they cannot complete
independently, thereby enhancing their potential across different tasks.
However, this approach faces two key challenges. First, redundant error
correction leads to unstable planning and long execution time. Additionally,
designing a correct plan among multiple tools is also a challenge in tool
learning. To address these issues, we propose Tool-Planner, a task-processing
framework based on toolkits. Tool-Planner groups tools based on the API
functions with the same function into a toolkit and allows LLMs to implement
planning across the various toolkits. When a tool error occurs, the language
model can reselect and adjust tools based on the toolkit. Experiments show that
our approach demonstrates a high pass and win rate across different datasets
and optimizes the planning scheme for tool learning in models such as GPT-4 and
Claude 3, showcasing the potential of our method.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤Â±ïÁèæÂá∫ÂçìË∂äÁöÑÊé®ÁêÜËÉΩÂäõÔºåËÆìÂÆÉÂÄëËÉΩÂ§†Ëß£Ê±∫ÂêÑÁ®ÆË§áÈõúÁöÑÂïèÈ°å„ÄÇÊúÄËøëÔºåÊ≠§ËÉΩÂäõÂ∑≤ÊáâÁî®ÊñºÂ∑•ÂÖ∑Â≠∏ÁøíÁØÑ‰æã‰∏≠„ÄÇÂ∑•ÂÖ∑Â≠∏ÁøíÊ∂âÂèäÊèê‰æõÂ∑•ÂÖ∑‰ΩøÁî®ÁØÑ‰æãÂèäÂÖ∂Â∞çÊáâÂäüËÉΩÔºåËÆì LLM ËÉΩÂ§†Âà∂ÂÆöË®àÁï´‰∏¶Â±ïÁ§∫ÂëºÂè´ÂíåÂü∑Ë°åÊØèÂÄãÂ∑•ÂÖ∑ÁöÑÊµÅÁ®ã„ÄÇLLM ËÉΩÂ§†ËôïÁêÜÂÆÉÂÄëÁÑ°Ê≥ïÁç®Á´ãÂÆåÊàêÁöÑ‰ªªÂãôÔºåÂæûËÄåÊèêÂçáÂÆÉÂÄëÂú®‰∏çÂêå‰ªªÂãô‰∏≠ÁöÑÊΩõÂäõ„ÄÇÁÑ∂ËÄåÔºåÊ≠§ÊñπÊ≥ïÈù¢Ëá®ÂÖ©È†Ö‰∏ªË¶ÅÊåëÊà∞„ÄÇÈ¶ñÂÖàÔºåÈáçË§áÁöÑÈåØË™§‰øÆÊ≠£ÊúÉÂ∞éËá¥‰∏çÁ©©ÂÆöÁöÑË¶èÂäÉÂíåÂÜóÈï∑ÁöÑÂü∑Ë°åÊôÇÈñì„ÄÇÊ≠§Â§ñÔºåÂú®Â§öÂÄãÂ∑•ÂÖ∑‰∏≠Ë®≠Ë®à‰∏ÄÂÄãÊ≠£Á¢∫ÁöÑË®àÁï´‰πüÊòØÂ∑•ÂÖ∑Â≠∏Áøí‰∏≠ÁöÑÊåëÊà∞„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫ Tool-PlannerÔºå‰∏ÄÂÄãÂü∫ÊñºÂ∑•ÂÖ∑ÁµÑÁöÑ‰ªªÂãôËôïÁêÜÊû∂Êßã„ÄÇTool-Planner ÊúÉÊ†πÊìöÂÖ∑ÊúâÁõ∏ÂêåÂäüËÉΩÁöÑ API ÂäüËÉΩÂ∞áÂ∑•ÂÖ∑ÂàÜÁµÑÂà∞Â∑•ÂÖ∑ÁµÑ‰∏≠Ôºå‰∏¶ÂÖÅË®± LLM Âú®ÂêÑÁ®ÆÂ∑•ÂÖ∑ÁµÑ‰∏≠ÂØ¶‰ΩúË¶èÂäÉ„ÄÇÁï∂Â∑•ÂÖ∑ÁôºÁîüÈåØË™§ÊôÇÔºåË™ûË®ÄÊ®°ÂûãÂèØ‰ª•Ê†πÊìöÂ∑•ÂÖ∑ÁµÑÈáçÊñ∞ÈÅ∏ÊìáÂíåË™øÊï¥Â∑•ÂÖ∑„ÄÇÂØ¶È©óÈ°ØÁ§∫ÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÂú®‰∏çÂêåÁöÑË≥áÊñôÈõÜ‰∏äÂ±ïÁèæÂá∫È´òÈÄöÈÅéÁéáÂíåÁç≤ÂãùÁéáÔºå‰∏¶ÊúÄ‰Ω≥Âåñ GPT-4 Âíå Claude 3 Á≠âÊ®°Âûã‰∏≠ÁöÑÂ∑•ÂÖ∑Â≠∏ÁøíË¶èÂäÉÊû∂ÊßãÔºåÂ±ïÁ§∫‰∫ÜÊàëÂÄëÊñπÊ≥ïÁöÑÊΩõÂäõ„ÄÇ

##### **Enhanced Semantic Segmentation Pipeline for WeatherProof Dataset Challenge**
2406.03799v2 by Nan Zhang, Xidan Zhang, Jianing Wei, Fangjun Wang, Zhiming Tan

This report describes the winning solution to the WeatherProof Dataset
Challenge (CVPR 2024 UG2+ Track 3). Details regarding the challenge are
available at https://cvpr2024ug2challenge.github.io/track3.html. We propose an
enhanced semantic segmentation pipeline for this challenge. Firstly, we improve
semantic segmentation models, using backbone pretrained with Depth Anything to
improve UperNet model and SETRMLA model, and adding language guidance based on
both weather and category information to InternImage model. Secondly, we
introduce a new dataset WeatherProofExtra with wider viewing angle and employ
data augmentation methods, including adverse weather and super-resolution.
Finally, effective training strategies and ensemble method are applied to
improve final performance further. Our solution is ranked 1st on the final
leaderboard. Code will be available at
https://github.com/KaneiGi/WeatherProofChallenge.

ÊëòË¶ÅÔºöÊú¨Â†±ÂëäÊèèËø∞‰∫Ü WeatherProof Ë≥áÊñôÈõÜÊåëÊà∞Ë≥ΩÔºàCVPR 2024 UG2+ ËªåÈÅì 3ÔºâÁöÑÁç≤ÂãùËß£Ê±∫ÊñπÊ°à„ÄÇÊúâÈóúÊåëÊà∞Ë≥ΩÁöÑË©≥Á¥∞Ë≥áË®äÂèØÂú® https://cvpr2024ug2challenge.github.io/track3.html ÊâæÂà∞„ÄÇÊàëÂÄëÁÇ∫Ê≠§ÊåëÊà∞Ë≥ΩÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂ¢ûÂº∑ÁöÑË™ûÁæ©ÂàÜÂâ≤ÁÆ°ÈÅì„ÄÇÈ¶ñÂÖàÔºåÊàëÂÄë‰ΩøÁî®È†êÂÖàË®ìÁ∑¥ Depth Anything ÁöÑ‰∏ªÂππ‰æÜÊîπÂñÑË™ûÁæ©ÂàÜÂâ≤Ê®°ÂûãÔºå‰ª•ÊîπÂñÑ UperNet Ê®°ÂûãÂíå SETRMLA Ê®°ÂûãÔºå‰∏¶Ê†πÊìöÂ§©Ê∞£ÂíåÈ°ûÂà•Ë≥áË®äÂ∞áË™ûË®ÄÊåáÂ∞éÊñ∞Â¢ûÂà∞ InternImage Ê®°Âûã‰∏≠„ÄÇÂÖ∂Ê¨°ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÊñ∞ÁöÑË≥áÊñôÈõÜ WeatherProofExtraÔºåÂÆÉÂÖ∑ÊúâÊõ¥Âª£ÁöÑË¶ñËßíÔºå‰∏¶Êé°Áî®Ë≥áÊñôÊì¥ÂÖÖÊñπÊ≥ïÔºåÂåÖÊã¨ÊÉ°Âä£Â§©Ê∞£ÂíåË∂ÖËß£ÊûêÂ∫¶„ÄÇÊúÄÂæåÔºåÊáâÁî®ÊúâÊïàÁöÑË®ìÁ∑¥Á≠ñÁï•ÂíåÊï¥È´îÊñπÊ≥ïÈÄ≤‰∏ÄÊ≠•ÊîπÂñÑÊúÄÁµÇÊïàËÉΩ„ÄÇÊàëÂÄëÁöÑËß£Ê±∫ÊñπÊ°àÂú®ÊúÄÁµÇÊéíË°åÊ¶ú‰∏äÊéíÂêçÁ¨¨ 1„ÄÇÁ®ãÂºèÁ¢ºÂ∞áÂú® https://github.com/KaneiGi/WeatherProofChallenge Êèê‰æõ„ÄÇ

##### **Light-PEFT: Lightening Parameter-Efficient Fine-Tuning via Early Pruning**
2406.03792v1 by Naibin Gu, Peng Fu, Xiyu Liu, Bowen Shen, Zheng Lin, Weiping Wang

Parameter-efficient fine-tuning (PEFT) has emerged as the predominant
technique for fine-tuning in the era of large language models. However,
existing PEFT methods still have inadequate training efficiency. Firstly, the
utilization of large-scale foundation models during the training process is
excessively redundant for certain fine-tuning tasks. Secondly, as the model
size increases, the growth in trainable parameters of empirically added PEFT
modules becomes non-negligible and redundant, leading to inefficiency. To
achieve task-specific efficient fine-tuning, we propose the Light-PEFT
framework, which includes two methods: Masked Early Pruning of the Foundation
Model and Multi-Granularity Early Pruning of PEFT. The Light-PEFT framework
allows for the simultaneous estimation of redundant parameters in both the
foundation model and PEFT modules during the early stage of training. These
parameters can then be pruned for more efficient fine-tuning. We validate our
approach on GLUE, SuperGLUE, QA tasks, and various models. With Light-PEFT,
parameters of the foundation model can be pruned by up to over 40%, while still
controlling trainable parameters to be only 25% of the original PEFT method.
Compared to utilizing the PEFT method directly, Light-PEFT achieves training
and inference speedup, reduces memory usage, and maintains comparable
performance and the plug-and-play feature of PEFT.

ÊëòË¶ÅÔºöÂèÉÊï∏È´òÊïàÂæÆË™ø (PEFT) Â∑≤ÊàêÁÇ∫Â§ßÂûãË™ûË®ÄÊ®°ÂûãÊôÇ‰ª£ÂæÆË™øÁöÑ‰∏ªË¶ÅÊäÄË°ì„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÁöÑ PEFT ÊñπÊ≥ï‰ªçÊúâË®ìÁ∑¥ÊïàÁéá‰∏çË∂≥ÁöÑÂïèÈ°å„ÄÇÈ¶ñÂÖàÔºåÂú®Ë®ìÁ∑¥ÈÅéÁ®ã‰∏≠‰ΩøÁî®Â§ßË¶èÊ®°Âü∫Á§éÊ®°ÂûãÂ∞çÊñºÊüê‰∫õÂæÆË™ø‰ªªÂãô‰æÜË™™ÈÅéÊñºÂÜóÈ§ò„ÄÇÂÖ∂Ê¨°ÔºåÈö®ËëóÊ®°ÂûãË¶èÊ®°ÁöÑÂ¢ûÂä†ÔºåÁ∂ìÈ©óÊÄßÊ∑ªÂä†ÁöÑ PEFT Ê®°ÁµÑ‰∏≠ÂèØË®ìÁ∑¥ÂèÉÊï∏ÁöÑÂ¢ûÈï∑ËÆäÂæó‰∏çÂèØÂøΩË¶ñ‰∏îÂÜóÈ§òÔºåÂ∞éËá¥ÊïàÁéá‰Ωé‰∏ã„ÄÇÁÇ∫‰∫ÜÂØ¶ÁèæÁâπÂÆö‰ªªÂãôÁöÑÈ´òÊïàÂæÆË™øÔºåÊàëÂÄëÊèêÂá∫‰∫Ü Light-PEFT Ê°ÜÊû∂ÔºåÂÖ∂‰∏≠ÂåÖÂê´ÂÖ©Á®ÆÊñπÊ≥ïÔºöÂü∫Á§éÊ®°ÂûãÁöÑÈÅÆÁΩ©Êó©ÊúüÂâ™ÊûùÂíå PEFT ÁöÑÂ§öÁ≤íÂ∫¶Êó©ÊúüÂâ™Êûù„ÄÇLight-PEFT Ê°ÜÊû∂ÂÖÅË®±Âú®Ë®ìÁ∑¥ÁöÑÊó©ÊúüÈöéÊÆµÂêåÊôÇ‰º∞Ë®àÂü∫Á§éÊ®°ÂûãÂíå PEFT Ê®°ÁµÑ‰∏≠ÁöÑÂÜóÈ§òÂèÉÊï∏„ÄÇÁÑ∂ÂæåÂèØ‰ª•Ââ™ÊûùÈÄô‰∫õÂèÉÊï∏‰ª•ÂØ¶ÁèæÊõ¥ÊúâÊïàÁöÑÂæÆË™ø„ÄÇÊàëÂÄëÂú® GLUE„ÄÅSuperGLUE„ÄÅQA ‰ªªÂãôÂíåÂêÑÁ®ÆÊ®°Âûã‰∏äÈ©óË≠â‰∫ÜÊàëÂÄëÁöÑÂÅöÊ≥ï„ÄÇ‰ΩøÁî® Light-PEFTÔºåÂü∫Á§éÊ®°ÂûãÁöÑÂèÉÊï∏ÂèØ‰ª•Ââ™ÊûùÂ§öÈÅî 40%ÔºåÂêåÊôÇ‰ªçÂ∞áÂèØË®ìÁ∑¥ÂèÉÊï∏ÊéßÂà∂Âú®ÂéüÂßã PEFT ÊñπÊ≥ïÁöÑ 25%„ÄÇËàáÁõ¥Êé•‰ΩøÁî® PEFT ÊñπÊ≥ïÁõ∏ÊØîÔºåLight-PEFT ÂèØÂä†Âø´Ë®ìÁ∑¥ÂíåÊé®Ë´ñÈÄüÂ∫¶„ÄÅÊ∏õÂ∞ëË®òÊÜ∂È´î‰ΩøÁî®ÈáèÔºå‰∏¶Á∂≠ÊåÅ PEFT ÁöÑÂèØÊØîÊïàËÉΩÂíåÂç≥ÊèíÂç≥Áî®ÂäüËÉΩ„ÄÇ

##### **End-to-End Trainable Soft Retriever for Low-resource Relation Extraction**
2406.03790v1 by Kohei Makino, Makoto Miwa, Yutaka Sasaki

This study addresses a crucial challenge in instance-based relation
extraction using text generation models: end-to-end training in target relation
extraction task is not applicable to retrievers due to the non-differentiable
nature of instance selection. We propose a novel End-to-end TRAinable Soft
K-nearest neighbor retriever (ETRASK) by the neural prompting method that
utilizes a soft, differentiable selection of the $k$ nearest instances. This
approach enables the end-to-end training of retrievers in target tasks. On the
TACRED benchmark dataset with a low-resource setting where the training data
was reduced to 10\%, our method achieved a state-of-the-art F1 score of 71.5\%.
Moreover, ETRASK consistently improved the baseline model by adding instances
for all settings. These results highlight the efficacy of our approach in
enhancing relation extraction performance, especially in resource-constrained
environments. Our findings offer a promising direction for future research with
extraction and the broader application of text generation in natural language
processing.

ÊëòË¶ÅÔºöÊú¨Á†îÁ©∂Êé¢Ë®é‰∫ÜÂü∫ÊñºÂØ¶‰æãÁöÑÈóú‰øÇÊäΩÂèñ‰∏≠‰ΩøÁî®ÊñáÊú¨ÁîüÊàêÊ®°ÂûãÊôÇÁöÑ‰∏ÄÂÄãÈóúÈçµÊåëÊà∞ÔºöÁõÆÊ®ôÈóú‰øÇÊäΩÂèñ‰ªªÂãô‰∏≠ÁöÑÁ´ØÂà∞Á´ØË®ìÁ∑¥Áî±ÊñºÂØ¶‰æãÈÅ∏ÊìáÁöÑ‰∏çÂèØÂæÆÂàÜÊÄßË≥™ËÄå‰∏çÈÅ©Áî®ÊñºÊ™¢Á¥¢Âô®„ÄÇÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞ÁöÑÁ´ØÂà∞Á´ØÂèØË®ìÁ∑¥Ëªü K ÊúÄËøëÈÑ∞Ê™¢Á¥¢Âô® (ETRASK)ÔºåÊé°Áî®Á•ûÁ∂ìÊèêÁ§∫ÊñπÊ≥ïÔºåÂà©Áî®ËªüÁöÑ„ÄÅÂèØÂæÆÂàÜÁöÑ $k$ ÂÄãÊúÄËøëÂØ¶‰æãÈÅ∏Êìá„ÄÇÈÄôÁ®ÆÊñπÊ≥ïËÉΩÂ§†Âú®ÁõÆÊ®ô‰ªªÂãô‰∏≠Â∞çÊ™¢Á¥¢Âô®ÈÄ≤Ë°åÁ´ØÂà∞Á´ØË®ìÁ∑¥„ÄÇÂú®Ë®ìÁ∑¥Ë≥áÊñôÊ∏õÂ∞ëÂà∞ 10% ÁöÑ‰ΩéË≥áÊ∫êË®≠ÁΩÆÁöÑ TACRED Âü∫Ê∫ñË≥áÊñôÈõÜ‰∏äÔºåÊàëÂÄëÁöÑÊ®°ÂûãÈÅîÂà∞‰∫Ü 71.5% ÁöÑÊúÄÂÖàÈÄ≤ F1 ÂàÜÊï∏„ÄÇÊ≠§Â§ñÔºåETRASK ÈÄöÈÅéÁÇ∫ÊâÄÊúâË®≠ÁΩÆÊ∑ªÂä†ÂØ¶‰æãÔºåÂßãÁµÇÂ¶Ç‰∏ÄÂú∞ÊîπÈÄ≤‰∫ÜÂü∫Ê∫ñÊ®°Âûã„ÄÇÈÄô‰∫õÁµêÊûúÁ™ÅÂá∫‰∫ÜÊàëÂÄëÁöÑÊ®°ÂûãÂú®Â¢ûÂº∑Èóú‰øÇÊäΩÂèñÊÄßËÉΩÊñπÈù¢ÁöÑÊïàËÉΩÔºåÁâπÂà•ÊòØÂú®Ë≥áÊ∫êÂèóÈôêÁöÑÁí∞Â¢É‰∏≠„ÄÇÊàëÂÄëÁöÑÁôºÁèæÁÇ∫Êú™‰æÜÁöÑÁ†îÁ©∂Êèê‰æõ‰∫ÜÊúâÂ∏åÊúõÁöÑÊñπÂêëÔºåÂåÖÊã¨ÊäΩÂèñÂíåÊñáÊú¨ÁîüÊàêÂú®Ëá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ‰∏≠ÁöÑÊõ¥Âª£Ê≥õÊáâÁî®„ÄÇ

##### **Enhancing Graph U-Nets for Mesh-Agnostic Spatio-Temporal Flow Prediction**
2406.03789v1 by Sunwoong Yang, Ricardo Vinuesa, Namwoo Kang

This study aims to overcome the conventional deep-learning approaches based
on convolutional neural networks, whose applicability to complex geometries and
unstructured meshes is limited due to their inherent mesh dependency. We
propose novel approaches to improve mesh-agnostic spatio-temporal prediction of
transient flow fields using graph U-Nets, enabling accurate prediction on
diverse mesh configurations. Key enhancements to the graph U-Net architecture,
including the Gaussian mixture model convolutional operator and noise injection
approaches, provide increased flexibility in modeling node dynamics: the former
reduces prediction error by 95\% compared to conventional convolutional
operators, while the latter improves long-term prediction robustness, resulting
in an error reduction of 86\%. We also investigate transductive and
inductive-learning perspectives of graph U-Nets with proposed improvements. In
the transductive setting, they effectively predict quantities for unseen nodes
within the trained graph. In the inductive setting, they successfully perform
in mesh scenarios with different vortex-shedding periods, showing 98\%
improvement in predicting the future flow fields compared to a model trained
without the inductive settings. It is found that graph U-Nets without pooling
operations, i.e. without reducing and restoring the node dimensionality of the
graph data, perform better in inductive settings due to their ability to learn
from the detailed structure of each graph. Meanwhile, we also discover that the
choice of normalization technique significantly impacts graph U-Net
performance.

ÊëòË¶ÅÔºöÊú¨Á†îÁ©∂Êó®Âú®ÂÖãÊúçÂü∫ÊñºÂç∑Á©çÁ•ûÁ∂ìÁ∂≤Ë∑ØÁöÑÂÇ≥Áµ±Ê∑±Â∫¶Â≠∏ÁøíÊñπÊ≥ïÔºåÁî±ÊñºÂÖ∂Â∞çË§áÈõúÂπæ‰ΩïÂíåÈùûÁµêÊßãÁ∂≤Ê†ºÁöÑÈÅ©Áî®ÊÄßÂèóÈôêÊñºÂÖ∂Âõ∫ÊúâÁöÑÁ∂≤Ê†º‰æùË≥¥ÊÄß„ÄÇÊàëÂÄëÊèêÂá∫Êñ∞ÁöÑÊñπÊ≥ïÔºå‰ΩøÁî®ÂúñÂΩ¢ U-Net ‰æÜÊîπÂñÑÁ∂≤Ê†º‰∏çÂèØÁü•ÊôÇÁ©∫È†êÊ∏¨Êö´ÊÖãÊµÅÂ†¥ÔºåÂæûËÄåËÉΩÂ§†Â∞ç‰∏çÂêåÁöÑÁ∂≤Ê†ºÈÖçÁΩÆÈÄ≤Ë°åÊ∫ñÁ¢∫È†êÊ∏¨„ÄÇÂúñÂΩ¢ U-Net Êû∂ÊßãÁöÑ‰∏ªË¶ÅÊîπÈÄ≤ÔºåÂåÖÊã¨È´òÊñØÊ∑∑ÂêàÊ®°ÂûãÂç∑Á©çÁÆóÂ≠êËàáÈõúË®äÊ≥®ÂÖ•ÊñπÊ≥ïÔºåÊèê‰æõ‰∫ÜÂª∫Ê®°ÁØÄÈªûÂãïÊÖãÁöÑÈùàÊ¥ªÊÄßÔºöÂâçËÄÖËàáÂÇ≥Áµ±Âç∑Á©çÁÆóÂ≠êÁõ∏ÊØîÔºåÂ∞áÈ†êÊ∏¨Ë™§Â∑ÆÊ∏õÂ∞ë‰∫Ü 95%ÔºåËÄåÂæåËÄÖÊîπÂñÑ‰∫ÜÈï∑ÊúüÈ†êÊ∏¨ÁöÑÁ©©ÂÅ•ÊÄßÔºåÂæûËÄåÂ∞áË™§Â∑ÆÊ∏õÂ∞ë‰∫Ü 86%„ÄÇÊàëÂÄëÈÇÑÁ†îÁ©∂‰∫ÜÂúñÂΩ¢ U-Net ÁöÑËΩâÂ∞éÂ≠∏ÁøíÂíåÊ≠∏Á¥çÂ≠∏ÁøíËßÄÈªûÔºå‰∏¶ÊèêÂá∫ÊîπÈÄ≤Âª∫Ë≠∞„ÄÇÂú®ËΩâÂ∞éË®≠ÁΩÆ‰∏≠ÔºåÂÆÉÂÄëÊúâÊïàÂú∞È†êÊ∏¨‰∫ÜË®ìÁ∑¥ÂúñÂΩ¢‰∏≠Êú™Ë¶ãÁØÄÈªûÁöÑÊï∏Èáè„ÄÇÂú®Ê≠∏Á¥çË®≠ÁΩÆ‰∏≠ÔºåÂÆÉÂÄëÊàêÂäüÂú∞Âú®ÂÖ∑Êúâ‰∏çÂêåÊ∏¶ÊóãËÑ´ËêΩÈÄ±ÊúüÁöÑÁ∂≤Ê†ºÂ†¥ÊôØ‰∏≠Âü∑Ë°åÔºåËàáÊú™Á∂ìÊ≠∏Á¥çË®≠ÁΩÆË®ìÁ∑¥ÁöÑÊ®°ÂûãÁõ∏ÊØîÔºåÈ†êÊ∏¨Êú™‰æÜÊµÅÂ†¥ÁöÑÊ∫ñÁ¢∫Â∫¶ÊèêÈ´ò‰∫Ü 98%„ÄÇÊàëÂÄëÁôºÁèæÔºåÊ≤íÊúâÊ±†ÂåñÊìç‰ΩúÁöÑÂúñÂΩ¢ U-NetÔºåÂç≥Ê≤íÊúâÊ∏õÂ∞ëÂíåÊÅ¢Âæ©ÂúñÂΩ¢Êï∏ÊìöÁØÄÈªûÁ∂≠Â∫¶ÁöÑÂúñÂΩ¢ U-NetÔºåÁî±ÊñºÂÆÉÂÄëËÉΩÂ§†ÂæûÊØèÂÄãÂúñÂΩ¢ÁöÑË©≥Á¥∞ÁµêÊßã‰∏≠Â≠∏ÁøíÔºåÂõ†Ê≠§Âú®Ê≠∏Á¥çË®≠ÁΩÆ‰∏≠Ë°®ÁèæÂæóÊõ¥Â•Ω„ÄÇÂêåÊôÇÔºåÊàëÂÄëÈÇÑÁôºÁèæÔºåÊ≠£Ë¶èÂåñÊäÄË°ìÁöÑÈÅ∏ÊìáÊúÉÈ°ØËëóÂΩ±ÈüøÂúñÂΩ¢ U-Net ÁöÑÊÄßËÉΩ„ÄÇ

