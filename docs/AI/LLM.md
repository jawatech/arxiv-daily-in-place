
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2025-01-10**|**Model Alignment Search**|Satchel Grant et.al.|[2501.06164v1](http://arxiv.org/abs/2501.06164v1)|null|
|**2025-01-10**|**xLSTM-SENet: xLSTM for Single-Channel Speech Enhancement**|Nikolai Lund Kühne et.al.|[2501.06146v1](http://arxiv.org/abs/2501.06146v1)|null|
|**2025-01-10**|**Multilingual Performance of a Multimodal Artificial Intelligence System on Multisubject Physics Concept Inventories**|Gerd Kortemeyer et.al.|[2501.06143v1](http://arxiv.org/abs/2501.06143v1)|null|
|**2025-01-10**|**Emergent Symbol-like Number Variables in Artificial Neural Networks**|Satchel Grant et.al.|[2501.06141v1](http://arxiv.org/abs/2501.06141v1)|null|
|**2025-01-10**|**Supervision policies can shape long-term risk management in general-purpose AI models**|Manuel Cebrian et.al.|[2501.06137v1](http://arxiv.org/abs/2501.06137v1)|[link](https://github.com/manuelcebrianramos/llm_supervision_policies)|
|**2025-01-10**|**CoDriveVLM: VLM-Enhanced Urban Cooperative Dispatching and Motion Planning for Future Autonomous Mobility on Demand Systems**|Haichao Liu et.al.|[2501.06132v1](http://arxiv.org/abs/2501.06132v1)|null|
|**2025-01-10**|**Contextual ASR Error Handling with LLMs Augmentation for Goal-Oriented Conversational AI**|Yuya Asano et.al.|[2501.06129v1](http://arxiv.org/abs/2501.06129v1)|null|
|**2025-01-10**|**Merging Feed-Forward Sublayers for Compressed Transformers**|Neha Verma et.al.|[2501.06126v1](http://arxiv.org/abs/2501.06126v1)|[link](https://github.com/nverma1/merging-ffs-compression)|
|**2025-01-10**|**Fleurs-SLU: A Massively Multilingual Benchmark for Spoken Language Understanding**|Fabian David Schmidt et.al.|[2501.06117v1](http://arxiv.org/abs/2501.06117v1)|null|
|**2025-01-10**|**From Conversation to Automation: Leveraging Large Language Models to Analyze Strategies in Problem Solving Therapy**|Elham Aghakhani et.al.|[2501.06101v1](http://arxiv.org/abs/2501.06101v1)|null|
|**2025-01-10**|**Explaining Deep Learning-based Anomaly Detection in Energy Consumption Data by Focusing on Contextually Relevant Data**|Mohammad Noorchenarboo et.al.|[2501.06099v1](http://arxiv.org/abs/2501.06099v1)|null|
|**2025-01-10**|**All AI Models are Wrong, but Some are Optimal**|Akhil S Anand et.al.|[2501.06086v1](http://arxiv.org/abs/2501.06086v1)|null|
|**2025-01-10**|**Scale-up Unlearnable Examples Learning with High-Performance Computing**|Yanfan Zhu et.al.|[2501.06080v1](http://arxiv.org/abs/2501.06080v1)|null|
|**2025-01-10**|**Explaining k-Nearest Neighbors: Abductive and Counterfactual Explanations**|Pablo Barceló et.al.|[2501.06078v1](http://arxiv.org/abs/2501.06078v1)|null|
|**2025-01-10**|**Distilling Calibration via Conformalized Credal Inference**|Jiayi Huang et.al.|[2501.06066v1](http://arxiv.org/abs/2501.06066v1)|null|
|**2025-01-10**|**Benchmarking Rotary Position Embeddings for Automatic Speech Recognition**|Shucong Zhang et.al.|[2501.06051v1](http://arxiv.org/abs/2501.06051v1)|null|
|**2025-01-10**|**AI-powered virtual tissues from spatial proteomics for clinical diagnostics and biomedical discovery**|Johann Wenckstern et.al.|[2501.06039v1](http://arxiv.org/abs/2501.06039v1)|null|
|**2025-01-10**|**How to Tune a Multilingual Encoder Model for Germanic Languages: A Study of PEFT, Full Fine-Tuning, and Language Adapters**|Romina Oji et.al.|[2501.06025v1](http://arxiv.org/abs/2501.06025v1)|[link](https://github.com/rominaoji/german-language-adapter)|
|**2025-01-10**|**BRIGHT: A globally distributed multimodal building damage assessment dataset with very-high-resolution for all-weather disaster response**|Hongruixuan Chen et.al.|[2501.06019v1](http://arxiv.org/abs/2501.06019v1)|[link](https://github.com/chenhongruixuan/bright)|
|**2025-01-10**|**Addressing speaker gender bias in large scale speech translation systems**|Shubham Bansal et.al.|[2501.05989v1](http://arxiv.org/abs/2501.05989v1)|null|
|**2025-01-10**|**Hermit Kingdom Through the Lens of Multiple Perspectives: A Case Study of LLM Hallucination on North Korea**|Eunjung Cho et.al.|[2501.05981v1](http://arxiv.org/abs/2501.05981v1)|null|
|**2025-01-10**|**Towards Early Prediction of Self-Supervised Speech Model Performance**|Ryan Whetten et.al.|[2501.05966v1](http://arxiv.org/abs/2501.05966v1)|null|
|**2025-01-10**|**Finnish SQuAD: A Simple Approach to Machine Translation of Span Annotations**|Emil Nuutinen et.al.|[2501.05963v1](http://arxiv.org/abs/2501.05963v1)|null|
|**2025-01-10**|**Effective faking of verbal deception detection with target-aligned adversarial attacks**|Bennett Kleinberg et.al.|[2501.05962v1](http://arxiv.org/abs/2501.05962v1)|null|
|**2025-01-10**|**Scalable Vision Language Model Training via High Quality Data Curation**|Hongyuan Dong et.al.|[2501.05952v1](http://arxiv.org/abs/2501.05952v1)|null|
|**2025-01-10**|**Universal-2-TF: Robust All-Neural Text Formatting for ASR**|Yash Khare et.al.|[2501.05948v1](http://arxiv.org/abs/2501.05948v1)|null|
|**2025-01-10**|**DiffuSETS: 12-lead ECG Generation Conditioned on Clinical Text Reports and Patient-Specific Information**|Yongfan Lai et.al.|[2501.05932v1](http://arxiv.org/abs/2501.05932v1)|null|
|**2025-01-10**|**Towards Backdoor Stealthiness in Model Parameter Space**|Xiaoyun Xu et.al.|[2501.05928v1](http://arxiv.org/abs/2501.05928v1)|[link](https://github.com/xiaoyunxxy/parameter_backdoor)|
|**2025-01-10**|**LLMs Reproduce Stereotypes of Sexual and Gender Minorities**|Ruby Ostrow et.al.|[2501.05926v1](http://arxiv.org/abs/2501.05926v1)|null|
|**2025-01-10**|**Navigating Tomorrow: Reliably Assessing Large Language Models Performance on Future Event Prediction**|Petraq Nako et.al.|[2501.05925v1](http://arxiv.org/abs/2501.05925v1)|null|
|**2025-01-10**|**Affordably Fine-tuned LLMs Provide Better Answers to Course-specific MCQs**|Bianca Raimondi et.al.|[2501.05891v1](http://arxiv.org/abs/2501.05891v1)|[link](https://github.com/biancaraimondi/llama2_for_mcqs)|
|**2025-01-10**|**EDNet: Edge-Optimized Small Target Detection in UAV Imagery -- Faster Context Attention, Better Feature Fusion, and Hardware Acceleration**|Zhifan Song et.al.|[2501.05885v1](http://arxiv.org/abs/2501.05885v1)|null|
|**2025-01-10**|**VideoRAG: Retrieval-Augmented Generation over Video Corpus**|Soyeong Jeong et.al.|[2501.05874v1](http://arxiv.org/abs/2501.05874v1)|null|
|**2025-01-10**|**ConSim: Measuring Concept-Based Explanations' Effectiveness with Automated Simulatability**|Antonin Poché et.al.|[2501.05855v1](http://arxiv.org/abs/2501.05855v1)|[link](https://github.com/anonymousconsim/consim)|
|**2025-01-10**|**Annealing Machine-assisted Learning of Graph Neural Network for Combinatorial Optimization**|Pablo Loyola et.al.|[2501.05845v1](http://arxiv.org/abs/2501.05845v1)|null|
|**2025-01-10**|**Diffusion Models for Smarter UAVs: Decision-Making and Modeling**|Yousef Emami et.al.|[2501.05819v1](http://arxiv.org/abs/2501.05819v1)|null|
|**2025-01-10**|**IndoNLP 2025: Shared Task on Real-Time Reverse Transliteration for Romanized Indo-Aryan languages**|Deshan Sumanathilaka et.al.|[2501.05816v1](http://arxiv.org/abs/2501.05816v1)|null|
|**2025-01-10**|**Real-Time Integrated Dispatching and Idle Fleet Steering with Deep Reinforcement Learning for A Meal Delivery Platform**|Jingyi Cheng et.al.|[2501.05808v1](http://arxiv.org/abs/2501.05808v1)|null|
|**2025-01-10**|**Alignment without Over-optimization: Training-Free Solution for Diffusion Models**|Sunwoo Kim et.al.|[2501.05803v1](http://arxiv.org/abs/2501.05803v1)|[link](https://github.com/krafton-ai/das)|
|**2025-01-10**|**Robust Counterfactual Explanations under Model Multiplicity Using Multi-Objective Optimization**|Keita Kinjo et.al.|[2501.05795v1](http://arxiv.org/abs/2501.05795v1)|null|
|**2025-01-10**|**Understanding Impact of Human Feedback via Influence Functions**|Taywon Min et.al.|[2501.05790v1](http://arxiv.org/abs/2501.05790v1)|[link](https://github.com/mintaywon/if_rlhf)|
|**2025-01-10**|**MARS6: A Small and Robust Hierarchical-Codec Text-to-Speech Model**|Matthew Baas et.al.|[2501.05787v1](http://arxiv.org/abs/2501.05787v1)|null|
|**2025-01-10**|**UV-Attack: Physical-World Adversarial Attacks for Person Detection via Dynamic-NeRF-based UV Mapping**|Yanjie Li et.al.|[2501.05783v1](http://arxiv.org/abs/2501.05783v1)|null|
|**2025-01-10**|**Halal or Not: Knowledge Graph Completion for Predicting Cultural Appropriateness of Daily Products**|Van Thuy Hoang et.al.|[2501.05768v1](http://arxiv.org/abs/2501.05768v1)|[link](https://github.com/nslab-cuk/halal-or-not)|
|**2025-01-10**|**Migician: Revealing the Magic of Free-Form Multi-Image Grounding in Multimodal Large Language Models**|You Li et.al.|[2501.05767v1](http://arxiv.org/abs/2501.05767v1)|null|
|**2025-01-10**|**Controlling Large Language Models Through Concept Activation Vectors**|Hanyu Zhang et.al.|[2501.05764v1](http://arxiv.org/abs/2501.05764v1)|null|
|**2025-01-10**|**Semantic Exploration with Adaptive Gating for Efficient Problem Solving with Language Models**|Sungjae Lee et.al.|[2501.05752v1](http://arxiv.org/abs/2501.05752v1)|null|
|**2025-01-10**|**Bridging Dialects: Translating Standard Bangla to Regional Variants Using Neural Models**|Md. Arafat Alam Khandaker et.al.|[2501.05749v1](http://arxiv.org/abs/2501.05749v1)|null|
|**2025-01-10**|**Element-wise Attention Is All You Need**|Guoxin Feng et.al.|[2501.05730v1](http://arxiv.org/abs/2501.05730v1)|null|
|**2025-01-10**|**Enabling Scalable Oversight via Self-Evolving Critic**|Zhengyang Tang et.al.|[2501.05727v1](http://arxiv.org/abs/2501.05727v1)|null|
|**2025-01-10**|**Zero-shot Shark Tracking and Biometrics from Aerial Imagery**|Chinmay K Lalgudi et.al.|[2501.05717v1](http://arxiv.org/abs/2501.05717v1)|null|
|**2025-01-10**|**How to Enable Effective Cooperation Between Humans and NLP Models: A Survey of Principles, Formalizations, and Beyond**|Chen Huang et.al.|[2501.05714v1](http://arxiv.org/abs/2501.05714v1)|null|
|**2025-01-10**|**Multi-Step Reasoning in Korean and the Emergent Mirage**|Guijin Son et.al.|[2501.05712v1](http://arxiv.org/abs/2501.05712v1)|null|
|**2025-01-10**|**Multiagent Finetuning: Self Improvement with Diverse Reasoning Chains**|Vighnesh Subramaniam et.al.|[2501.05707v1](http://arxiv.org/abs/2501.05707v1)|null|
|**2025-01-10**|**Linguistic Entity Masking to Improve Cross-Lingual Representation of Multilingual Language Models for Low-Resource Languages**|Aloka Fernando et.al.|[2501.05700v1](http://arxiv.org/abs/2501.05700v1)|null|
|**2025-01-10**|**Overcoming Language Priors for Visual Question Answering Based on Knowledge Distillation**|Daowan Peng et.al.|[2501.05690v1](http://arxiv.org/abs/2501.05690v1)|null|
|**2025-01-10**|**EXION: Exploiting Inter- and Intra-Iteration Output Sparsity for Diffusion Models**|Jaehoon Heo et.al.|[2501.05680v1](http://arxiv.org/abs/2501.05680v1)|null|
|**2025-01-10**|**Facilitate Collaboration between Large Language Model and Task-specific Model for Time Series Anomaly Detection**|Feiyi Chen et.al.|[2501.05675v1](http://arxiv.org/abs/2501.05675v1)|null|
|**2025-01-10**|**Network Diffuser for Placing-Scheduling Service Function Chains with Inverse Demonstration**|Zuyuan Zhang et.al.|[2501.05673v1](http://arxiv.org/abs/2501.05673v1)|null|
|**2025-01-10**|**TransPlace: Transferable Circuit Global Placement via Graph Neural Network**|Yunbo Hou et.al.|[2501.05667v1](http://arxiv.org/abs/2501.05667v1)|null|
|**2025-01-10**|**Learning to Measure Quantum Neural Networks**|Samuel Yen-Chi Chen et.al.|[2501.05663v1](http://arxiv.org/abs/2501.05663v1)|null|
|**2025-01-10**|**Cascaded Self-Evaluation Augmented Training for Efficient Multimodal Large Language Models**|Zheqi Lv et.al.|[2501.05662v1](http://arxiv.org/abs/2501.05662v1)|null|
|**2025-01-10**|**Collaboration of Large Language Models and Small Recommendation Models for Device-Cloud Recommendation**|Zheqi Lv et.al.|[2501.05647v1](http://arxiv.org/abs/2501.05647v1)|null|
|**2025-01-10**|**Efficient Representations for High-Cardinality Categorical Variables in Machine Learning**|Zixuan Liang et.al.|[2501.05646v1](http://arxiv.org/abs/2501.05646v1)|null|
|**2025-01-10**|**Iconicity in Large Language Models**|Anna Marklová et.al.|[2501.05643v1](http://arxiv.org/abs/2501.05643v1)|null|
|**2025-01-10**|**Automating Date Format Detection for Data Visualization**|Zixuan Liang et.al.|[2501.05640v1](http://arxiv.org/abs/2501.05640v1)|null|
|**2025-01-10**|**The Impact of Model Scaling on Seen and Unseen Language Performance**|Rhitabrat Pokharel et.al.|[2501.05629v1](http://arxiv.org/abs/2501.05629v1)|null|
|**2025-01-09**|**Watermarking Graph Neural Networks via Explanations for Ownership Protection**|Jane Downer et.al.|[2501.05614v1](http://arxiv.org/abs/2501.05614v1)|null|
|**2025-01-09**|**Harmonizing Metadata of Language Resources for Enhanced Querying and Accessibility**|Zixuan Liang et.al.|[2501.05606v1](http://arxiv.org/abs/2501.05606v1)|null|
|**2025-01-09**|**Advancing Personalized Learning Analysis via an Innovative Domain Knowledge Informed Attention-based Knowledge Tracing Method**|Shubham Kose et.al.|[2501.05605v1](http://arxiv.org/abs/2501.05605v1)|null|
|**2025-01-09**|**Exploring Large Language Models for Translating Romanian Computational Problems into English**|Adrian Marius Dumitran et.al.|[2501.05601v1](http://arxiv.org/abs/2501.05601v1)|null|
|**2025-01-09**|**Approximate Supervised Object Distance Estimation on Unmanned Surface Vehicles**|Benjamin Kiefer et.al.|[2501.05567v1](http://arxiv.org/abs/2501.05567v1)|null|
|**2025-01-09**|**Vision-Language Models for Autonomous Driving: CLIP-Based Dynamic Scene Understanding**|Mohammed Elhenawy et.al.|[2501.05566v1](http://arxiv.org/abs/2501.05566v1)|null|
|**2025-01-09**|**Soup to go: mitigating forgetting during continual learning with model averaging**|Anat Kleiman et.al.|[2501.05559v1](http://arxiv.org/abs/2501.05559v1)|null|
|**2025-01-09**|**Improving Zero-Shot Object-Level Change Detection by Incorporating Visual Correspondence**|Hung Huy Nguyen et.al.|[2501.05555v1](http://arxiv.org/abs/2501.05555v1)|[link](https://github.com/anguyen8/image-diff)|
|**2025-01-09**|**LLMQuoter: Enhancing RAG Capabilities Through Efficient Quote Extraction From Large Contexts**|Yuri Facanha Bezerra et.al.|[2501.05554v1](http://arxiv.org/abs/2501.05554v1)|[link](https://github.com/yurifacanha/llmquoter)|
|**2025-01-09**|**The dynamics of meaning through time: Assessment of Large Language Models**|Mohamed Taher Alrefaie et.al.|[2501.05552v1](http://arxiv.org/abs/2501.05552v1)|null|
|**2025-01-09**|**OVO-Bench: How Far is Your Video-LLMs from Real-World Online Video Understanding?**|Yifei Li et.al.|[2501.05510v1](http://arxiv.org/abs/2501.05510v1)|[link](https://github.com/joeleelyf/ovo-bench)|
|**2025-01-09**|**ReFocus: Visual Editing as a Chain of Thought for Structured Image Understanding**|Xingyu Fu et.al.|[2501.05452v1](http://arxiv.org/abs/2501.05452v1)|null|
|**2025-01-09**|**An Empirical Study of Autoregressive Pre-training from Videos**|Jathushan Rajasegaran et.al.|[2501.05453v1](http://arxiv.org/abs/2501.05453v1)|null|
|**2025-01-09**|**Consistent Flow Distillation for Text-to-3D Generation**|Runjie Yan et.al.|[2501.05445v1](http://arxiv.org/abs/2501.05445v1)|null|
|**2025-01-09**|**A survey of textual cyber abuse detection using cutting-edge language models and large language models**|Jose A. Diaz-Garcia et.al.|[2501.05443v1](http://arxiv.org/abs/2501.05443v1)|null|
|**2025-01-09**|**Progressive Growing of Video Tokenizers for Highly Compressed Latent Spaces**|Aniruddha Mahapatra et.al.|[2501.05442v1](http://arxiv.org/abs/2501.05442v1)|null|
|**2025-01-09**|**The more polypersonal the better -- a short look on space geometry of fine-tuned layers**|Sergei Kudriashov et.al.|[2501.05503v1](http://arxiv.org/abs/2501.05503v1)|null|
|**2025-01-09**|**LongProc: Benchmarking Long-Context Language Models on Long Procedural Generation**|Xi Ye et.al.|[2501.05414v1](http://arxiv.org/abs/2501.05414v1)|null|
|**2025-01-09**|**Atlas: A Novel Pathology Foundation Model by Mayo Clinic, Charité, and Aignostics**|Maximilian Alber et.al.|[2501.05409v2](http://arxiv.org/abs/2501.05409v2)|null|
|**2025-01-09**|**TimeRL: Efficient Deep Reinforcement Learning with Polyhedral Dependence Graphs**|Pedro F. Silvestre et.al.|[2501.05408v1](http://arxiv.org/abs/2501.05408v1)|null|
|**2025-01-09**|**TimeDP: Learning to Generate Multi-Domain Time Series with Domain Prompts**|Yu-Hao Huang et.al.|[2501.05403v1](http://arxiv.org/abs/2501.05403v1)|null|
|**2025-01-09**|**BRATI: Bidirectional Recurrent Attention for Time-Series Imputation**|Armando Collado-Villaverde et.al.|[2501.05401v1](http://arxiv.org/abs/2501.05401v1)|null|
|**2025-01-09**|**Mechanistic understanding and validation of large AI models with SemanticLens**|Maximilian Dreyer et.al.|[2501.05398v1](http://arxiv.org/abs/2501.05398v1)|null|
|**2025-01-09**|**FairCode: Evaluating Social Bias of LLMs in Code Generation**|Yongkang Du et.al.|[2501.05396v1](http://arxiv.org/abs/2501.05396v1)|[link](https://github.com/yongkdu/faircode)|
|**2025-01-09**|**Spatial Information Integration in Small Language Models for Document Layout Generation and Classification**|Pablo Melendez et.al.|[2501.05497v1](http://arxiv.org/abs/2501.05497v1)|null|
|**2025-01-09**|**Large Physics Models: Towards a collaborative approach with Large Language Models and Foundation Models**|Kristian G. Barman et.al.|[2501.05382v1](http://arxiv.org/abs/2501.05382v1)|null|
|**2025-01-09**|**Developing a Foundation of Vector Symbolic Architectures Using Category Theory**|Nolan P Shaw et.al.|[2501.05368v1](http://arxiv.org/abs/2501.05368v1)|null|
|**2025-01-09**|**Search-o1: Agentic Search-Enhanced Large Reasoning Models**|Xiaoxi Li et.al.|[2501.05366v1](http://arxiv.org/abs/2501.05366v1)|[link](https://github.com/sunnynexus/search-o1)|
|**2025-01-09**|**On Corrigibility and Alignment in Multi Agent Games**|Edmund Dable-Heath et.al.|[2501.05360v1](http://arxiv.org/abs/2501.05360v1)|null|
|**2025-01-09**|**FedSA: A Unified Representation Learning via Semantic Anchors for Prototype-based Federated Learning**|Yanbing Zhou et.al.|[2501.05496v1](http://arxiv.org/abs/2501.05496v1)|null|
|**2025-01-09**|**Stream Aligner: Efficient Sentence-Level Alignment via Distribution Induction**|Hantao Lou et.al.|[2501.05336v1](http://arxiv.org/abs/2501.05336v1)|[link](https://github.com/htlou/stream-aligner)|
|**2025-01-09**|**The Bakers and Millers Game with Restricted Locations**|Simon Krogmann et.al.|[2501.05334v1](http://arxiv.org/abs/2501.05334v1)|null|
|**2025-01-09**|**AnCoGen: Analysis, Control and Generation of Speech with a Masked Autoencoder**|Samir Sadok et.al.|[2501.05332v1](http://arxiv.org/abs/2501.05332v1)|null|

#### Abstracts
##### **Model Alignment Search**
2501.06164v1 by Satchel Grant

When can we say that two neural systems are the same? The answer to this
question is goal-dependent, and it is often addressed through correlative
methods such as Representational Similarity Analysis (RSA) and Centered Kernel
Alignment (CKA). What do we miss when we forgo causal explorations, and how can
we target specific types of similarity? In this work, we introduce Model
Alignment Search (MAS), a method for causally exploring distributed
representational similarity. The method learns invertible linear
transformations that align a subspace between two distributed networks'
representations where causal information can be freely interchanged. We first
show that the method can be used to transfer specific causal variables, such as
the number of items in a counting task, between networks with different
training seeds. We then explore open questions in number cognition by comparing
different types of numeric representations in models trained on structurally
different numeric tasks. We then explore differences between MAS vs preexisting
causal similarity methods, showing MAS to be more resistant to unwanted
exchanges. Lastly, we introduce a counterfactual latent auxiliary loss function
that helps shape causally relevant alignments even in cases where we do not
have causal access to one of the two models for training.

摘要：<paragraph>在什麼情況下，我們可以說兩個神經系統相同？這個問題的答案取決於目標，並且通常透過相關方法來解決，例如表徵相似性分析 (RSA) 和中心核對齊 (CKA)。當我們放棄因果探索時，我們錯過了什麼？我們如何針對特定類型的相似性？在這項工作中，我們引入了模型對齊搜尋 (MAS)，一種用於因果探索分佈式表徵相似性的方法。該方法學習可逆線性轉換，以對齊兩個分佈式網路的表徵之間的子空間，其中因果資訊可以自由交換。我們首先表明，該方法可用於在具有不同訓練種子的網路之間傳輸特定因果變數，例如計數任務中的項目數量。然後，我們透過比較在結構上不同的數值任務中訓練的模型中不同類型的數值表徵，來探討數字認知中的開放問題。然後，我們探討 MAS 與現有的因果相似性方法之間的差異，顯示 MAS 對不需要的交換具有更高的抵抗力。最後，我們引入了一個反事實潛在輔助損失函數，即使在我們無法透過因果關係存取兩個模型之一進行訓練的情況下，也能幫助塑造因果相關對齊。</paragraph>

##### **xLSTM-SENet: xLSTM for Single-Channel Speech Enhancement**
2501.06146v1 by Nikolai Lund Kühne, Jan Østergaard, Jesper Jensen, Zheng-Hua Tan

While attention-based architectures, such as Conformers, excel in speech
enhancement, they face challenges such as scalability with respect to input
sequence length. In contrast, the recently proposed Extended Long Short-Term
Memory (xLSTM) architecture offers linear scalability. However, xLSTM-based
models remain unexplored for speech enhancement. This paper introduces
xLSTM-SENet, the first xLSTM-based single-channel speech enhancement system. A
comparative analysis reveals that xLSTM-and notably, even LSTM-can match or
outperform state-of-the-art Mamba- and Conformer-based systems across various
model sizes in speech enhancement on the VoiceBank+Demand dataset. Through
ablation studies, we identify key architectural design choices such as
exponential gating and bidirectionality contributing to its effectiveness. Our
best xLSTM-based model, xLSTM-SENet2, outperforms state-of-the-art Mamba- and
Conformer-based systems on the Voicebank+DEMAND dataset.

摘要：基於注意力的架構，例如 Conformers，在語音增強方面表現出色，但它們在輸入序列長度方面面臨可擴充性等挑戰。相比之下，最近提出的擴展長短期記憶 (xLSTM) 架構提供了線性可擴充性。然而，基於 xLSTM 的模型在語音增強方面仍未得到探索。本文介紹了 xLSTM-SENet，這是第一個基於 xLSTM 的單通道語音增強系統。比較分析表明，xLSTM 甚至 LSTM 可以與最先進的基於 Mamba 和 Conformer 的系統相匹配或優於它們，這適用於 VoiceBank+Demand 資料集上的語音增強中的各種模型大小。通過消融研究，我們確定了關鍵的架構設計選擇，例如指數閘控和雙向性，這些選擇有助於提高其有效性。我們最好的基於 xLSTM 的模型 xLSTM-SENet2 在 Voicebank+DEMAND 資料集上優於最先進的基於 Mamba 和 Conformer 的系統。

##### **Multilingual Performance of a Multimodal Artificial Intelligence System on Multisubject Physics Concept Inventories**
2501.06143v1 by Gerd Kortemeyer, Marina Babayeva, Giulia Polverini, Bor Gregorcic, Ralf Widenhorn

We investigate the multilingual and multimodal performance of a large
language model-based artificial intelligence (AI) system, GPT-4o, on a diverse
set of physics concept inventories spanning multiple languages and subject
areas. The inventories taken from the PhysPort website cover the classical
physics topics of mechanics, electromagnetism, optics, and thermodynamics as
well as relativity, quantum mechanics, astronomy, mathematics, and laboratory
skills. Unlike previous text-only studies, we uploaded the inventories as
images mirroring what a student would see on paper, assessing the system's
multimodal functionality. The AI is prompted in English and autonomously
chooses the language of its response - either remaining in the nominal language
of the test, switching entirely to English, or mixing languages - revealing
adaptive behavior dependent on linguistic complexity and data availability. Our
results indicate some variation in performance across subject areas, with
laboratory skills standing out as the area of poorest performance. Furthermore,
the AI's performance on questions that require visual interpretation of images
is worse than on purely text-based questions. Questions that are difficult for
the AI tend to be that way invariably of the inventory language. We also find
large variations in performance across languages, with some appearing to
benefit substantially from language switching, a phenomenon similar to
code-switching ofhuman speakers. Overall, comparing the obtained AI results to
the existing literature, we find that the AI system outperforms average
undergraduate students post-instruction in all subject areas but laboratory
skills.

摘要：<paragraph>我們調查了一個大型語言模型基礎的人工智慧 (AI) 系統 GPT-4o 在多語言和多模式的表現，它涵蓋了多種語言和主題領域的物理概念清單。從 PhysPort 網站取得的清單涵蓋了力學、電磁學、光學和熱力學等經典物理主題，以及相對論、量子力學、天文學、數學和實驗室技能。與先前的純文字研究不同，我們將清單上傳為圖像，反映學生在紙本上看到的內容，評估系統的多模式功能。AI 以英語提示，並自主選擇其回應的語言 - 留在測驗的名義語言、完全切換為英語或混合語言 - 顯示出適應性行為，取決於語言複雜性和資料可用性。我們的結果表明，不同科目領域的表現有所不同，其中實驗室技能表現最差。此外，AI 在需要視覺解讀圖像的問題上的表現比純文字問題差。對 AI 來說困難的問題往往與清單語言無關。我們還發現不同語言的表現差異很大，有些語言似乎從語言切換中受益匪淺，這是一種類似於人類說話者代碼切換的現象。總體而言，將獲得的 AI 結果與現有文獻進行比較，我們發現 AI 系統在所有科目領域（實驗室技能除外）的表現都優於平均大學生在教學後的表現。</paragraph>

##### **Emergent Symbol-like Number Variables in Artificial Neural Networks**
2501.06141v1 by Satchel Grant, Noah D. Goodman, James L. McClelland

What types of numeric representations emerge in Neural Networks (NNs)? To
what degree do NNs induce abstract, mutable, slot-like numeric variables, and
in what situations do these representations emerge? How do these
representations change over learning, and how can we understand the neural
implementations in ways that are unified across different NNs? In this work, we
approach these questions by first training sequence based neural systems using
Next Token Prediction (NTP) objectives on numeric tasks. We then seek to
understand the neural solutions through the lens of causal abstractions or
symbolic algorithms. We use a combination of causal interventions and
visualization methods to find that artificial neural models do indeed develop
analogs of interchangeable, mutable, latent number variables purely from the
NTP objective. We then ask how variations on the tasks and model architectures
affect the models' learned solutions to find that these symbol-like numeric
representations do not form for every variant of the task, and transformers
solve the problem in a notably different way than their recurrent counterparts.
We then show how the symbol-like variables change over the course of training
to find a strong correlation between the models' task performance and the
alignment of their symbol-like representations. Lastly, we show that in all
cases, some degree of gradience exists in these neural symbols, highlighting
the difficulty of finding simple, interpretable symbolic stories of how neural
networks perform numeric tasks. Taken together, our results are consistent with
the view that neural networks can approximate interpretable symbolic programs
of number cognition, but the particular program they approximate and the extent
to which they approximate it can vary widely, depending on the network
architecture, training data, extent of training, and network size.

摘要：在神經網路 (NNs) 中會出現哪些類型的數值表示法？NNs 在多大程度上會誘發抽象、可變、類似槽的數值變數，以及在哪些情況下會出現這些表示法？這些表示法如何隨著學習而改變，以及我們如何以統一於不同 NNs 的方式理解神經實現？在這項工作中，我們透過使用下一個代幣預測 (NTP) 目標在數值任務上訓練基於序列的神經系統，來探討這些問題。然後，我們試圖透過因果抽象或符號演算法的觀點來理解神經解決方案。我們使用因果介入和視覺化方法的組合，發現人工神經模型確實會發展出可互換、可變、潛在數字變數的類比，純粹來自 NTP 目標。然後，我們詢問任務和模型架構的變化如何影響模型學習的解決方案，發現這些類比符號的數值表示法並非針對任務的每個變體形成，而Transformer以一種明顯不同於其遞迴對應物的方式解決問題。然後，我們展示類比符號的變數如何在訓練過程中改變，以找出模型的任務效能與其類比符號表示法的一致性之間的強相關性。最後，我們表明在所有情況下，這些神經符號都存在某種程度的梯度，突顯了找到簡單、可解釋的符號故事（說明神經網路如何執行數值任務）的難度。綜合起來，我們的結果與神經網路可以近似數值認知的可解釋符號程式的神經網路觀點一致，但它們近似的特定程式和近似程度會根據網路架構、訓練資料、訓練程度和網路大小而有很大差異。

##### **Supervision policies can shape long-term risk management in general-purpose AI models**
2501.06137v1 by Manuel Cebrian, Emilia Gomez, David Fernandez Llorca

The rapid proliferation and deployment of General-Purpose AI (GPAI) models,
including large language models (LLMs), present unprecedented challenges for AI
supervisory entities. We hypothesize that these entities will need to navigate
an emergent ecosystem of risk and incident reporting, likely to exceed their
supervision capacity. To investigate this, we develop a simulation framework
parameterized by features extracted from the diverse landscape of risk,
incident, or hazard reporting ecosystems, including community-driven platforms,
crowdsourcing initiatives, and expert assessments. We evaluate four supervision
policies: non-prioritized (first-come, first-served), random selection,
priority-based (addressing the highest-priority risks first), and
diversity-prioritized (balancing high-priority risks with comprehensive
coverage across risk types). Our results indicate that while priority-based and
diversity-prioritized policies are more effective at mitigating high-impact
risks, particularly those identified by experts, they may inadvertently neglect
systemic issues reported by the broader community. This oversight can create
feedback loops that amplify certain types of reporting while discouraging
others, leading to a skewed perception of the overall risk landscape. We
validate our simulation results with several real-world datasets, including one
with over a million ChatGPT interactions, of which more than 150,000
conversations were identified as risky. This validation underscores the complex
trade-offs inherent in AI risk supervision and highlights how the choice of
risk management policies can shape the future landscape of AI risks across
diverse GPAI models used in society.

摘要：通用人工智能 (GPAI) 模型（包括大型语言模型 (LLM)) 的快速普及和部署对人工智能监管实体提出了前所未有的挑战。我们假设这些实体需要在风险和事件报告的新兴生态系统中进行导航，这可能会超出其监管能力。为了调查这一点，我们开发了一个模拟框架，该框架由从风险、事件或危害报告生态系统的多样化格局中提取的特征参数化，包括社区驱动的平台、众包计划和专家评估。我们评估了四种监管政策：非优先级（先到先得）、随机选择、基于优先级（首先解决最高优先级的风险）和基于多样性优先级（平衡高优先级风险与全面覆盖所有风险类型）。我们的结果表明，虽然基于优先级和基于多样性优先级的政策在减轻高影响风险方面更有效，特别是专家确定的风险，但它们可能会无意中忽视更广泛社区报告的系统性问题。这种疏忽可能会产生反馈循环，放大某些类型的报告，同时阻止其他类型的报告，从而导致对整体风险格局的感知出现偏差。我们使用多个真实世界数据集验证了我们的模拟结果，其中一个数据集包含一百万次 ChatGPT 交互，其中超过 150,000 次对话被识别为有风险的。此验证强调了人工智能风险监管中固有的复杂权衡，并强调了风险管理政策的选择如何塑造社会中使用的各种 GPAI 模型的未来人工智能风险格局。

##### **CoDriveVLM: VLM-Enhanced Urban Cooperative Dispatching and Motion Planning for Future Autonomous Mobility on Demand Systems**
2501.06132v1 by Haichao Liu, Ruoyu Yao, Wenru Liu, Zhenmin Huang, Shaojie Shen, Jun Ma

The increasing demand for flexible and efficient urban transportation
solutions has spotlighted the limitations of traditional Demand Responsive
Transport (DRT) systems, particularly in accommodating diverse passenger needs
and dynamic urban environments. Autonomous Mobility-on-Demand (AMoD) systems
have emerged as a promising alternative, leveraging connected and autonomous
vehicles (CAVs) to provide responsive and adaptable services. However, existing
methods primarily focus on either vehicle scheduling or path planning, which
often simplify complex urban layouts and neglect the necessity for simultaneous
coordination and mutual avoidance among CAVs. This oversimplification poses
significant challenges to the deployment of AMoD systems in real-world
scenarios. To address these gaps, we propose CoDriveVLM, a novel framework that
integrates high-fidelity simultaneous dispatching and cooperative motion
planning for future AMoD systems. Our method harnesses Vision-Language Models
(VLMs) to enhance multi-modality information processing, and this enables
comprehensive dispatching and collision risk evaluation. The VLM-enhanced CAV
dispatching coordinator is introduced to effectively manage complex and
unforeseen AMoD conditions, thus supporting efficient scheduling
decision-making. Furthermore, we propose a scalable decentralized cooperative
motion planning method via consensus alternating direction method of
multipliers (ADMM) focusing on collision risk evaluation and decentralized
trajectory optimization. Simulation results demonstrate the feasibility and
robustness of CoDriveVLM in various traffic conditions, showcasing its
potential to significantly improve the fidelity and effectiveness of AMoD
systems in future urban transportation networks. The code is available at
https://github.com/henryhcliu/CoDriveVLM.git.

摘要：隨著對靈活且有效率的城市交通解決方案的需求不斷增加，突顯了傳統需求反應式運輸 (DRT) 系統的限制，特別是在適應不同的乘客需求和動態的城市環境方面。自主按需行動 (AMoD) 系統已成為一種有前途的替代方案，利用連網和自動駕駛車輛 (CAV) 來提供反應靈敏且適應性強的服務。然而，現有方法主要專注於車輛排程或路徑規劃，這通常會簡化複雜的城市佈局，並忽略 CAV 之間同時協調和相互避讓的必要性。這種過度簡化對 AMoD 系統在現實世界場景中的部署提出了重大挑戰。為了解決這些差距，我們提出了 CoDriveVLM，這是一個創新的框架，整合了高保真同時調度和協調運動規劃，以供未來的 AMoD 系統使用。我們的技術利用視覺語言模型 (VLM) 來增強多模態資訊處理，並能進行全面的調度和碰撞風險評估。引入了 VLM 增強的 CAV 調度協調器，以有效管理複雜且無法預見的 AMoD 情況，從而支援有效的排程決策制定。此外，我們透過共識交替方向乘數法 (ADMM) 提出了一種可擴充的分散式協調運動規劃方法，專注於碰撞風險評估和分散式軌跡最佳化。模擬結果證明了 CoDriveVLM 在各種交通狀況下的可行性和穩健性，展示了其在未來城市交通網路中顯著提升 AMoD 系統保真度和有效性的潛力。程式碼可在 https://github.com/henryhcliu/CoDriveVLM.git 取得。

##### **Contextual ASR Error Handling with LLMs Augmentation for Goal-Oriented Conversational AI**
2501.06129v1 by Yuya Asano, Sabit Hassan, Paras Sharma, Anthony Sicilia, Katherine Atwell, Diane Litman, Malihe Alikhani

General-purpose automatic speech recognition (ASR) systems do not always
perform well in goal-oriented dialogue. Existing ASR correction methods rely on
prior user data or named entities. We extend correction to tasks that have no
prior user data and exhibit linguistic flexibility such as lexical and
syntactic variations. We propose a novel context augmentation with a large
language model and a ranking strategy that incorporates contextual information
from the dialogue states of a goal-oriented conversational AI and its tasks.
Our method ranks (1) n-best ASR hypotheses by their lexical and semantic
similarity with context and (2) context by phonetic correspondence with ASR
hypotheses. Evaluated in home improvement and cooking domains with real-world
users, our method improves recall and F1 of correction by 34% and 16%,
respectively, while maintaining precision and false positive rate. Users rated
.8-1 point (out of 5) higher when our correction method worked properly, with
no decrease due to false positives.

摘要：通用自動語音辨識 (ASR) 系統在目標導向對話中並不總是表現良好。現有的 ASR 校正方法依賴於先前的使用者資料或命名實體。我們將校正擴展到沒有先前的使用者資料且展現語言彈性的任務，例如詞彙和句法變化。我們提出一個新的脈絡增強，使用大型語言模型和排名策略，將來自目標導向對話式 AI 和其任務的對話狀態的脈絡資訊納入其中。我們的模型會依據其與脈絡的詞彙和語意相似性對 (1) n 個最佳 ASR 假設進行排名，以及依據與 ASR 假設的音標對應對 (2) 脈絡進行排名。在實際使用者參與的家居改善和烹飪領域中進行評估，我們的模型分別改善了校正的召回率和 F1 分數 34% 和 16%，同時維持準確度和假陽性率。當我們的校正方法正常運作時，使用者評分高出 0.8-1 分（滿分 5 分），且不會因為假陽性而降低評分。

##### **Merging Feed-Forward Sublayers for Compressed Transformers**
2501.06126v1 by Neha Verma, Kenton Murray, Kevin Duh

With the rise and ubiquity of larger deep learning models, the need for
high-quality compression techniques is growing in order to deploy these models
widely. The sheer parameter count of these models makes it difficult to fit
them into the memory constraints of different hardware. In this work, we
present a novel approach to model compression by merging similar parameter
groups within a model, rather than pruning away less important parameters.
Specifically, we select, align, and merge separate feed-forward sublayers in
Transformer models, and test our method on language modeling, image
classification, and machine translation. With our method, we demonstrate
performance comparable to the original models while combining more than a third
of model feed-forward sublayers, and demonstrate improved performance over a
strong layer-pruning baseline. For instance, we can remove over 21% of total
parameters from a Vision Transformer, while maintaining 99% of its original
performance. Additionally, we observe that some groups of feed-forward
sublayers exhibit high activation similarity, which may help explain their
surprising mergeability.

摘要：隨著大型深度學習模型的興起和普及，為了廣泛部署這些模型，對高品質壓縮技術的需求與日俱增。這些模型的參數數量龐大，難以符合不同硬體的記憶體限制。在這項工作中，我們提出了一種新的模型壓縮方法，透過合併模型中相似的參數組，而不是剪除較不重要的參數。具體來說，我們在 Transformer 模型中選擇、對齊和合併獨立的前饋子層，並在語言建模、影像分類和機器翻譯上測試我們的模型。使用我們的模型，我們展示了與原始模型相當的效能，同時合併了超過三分之一的模型前饋子層，並展示了比強大的層剪枝基準更好的效能。例如，我們可以從 Vision Transformer 中移除超過 21% 的總參數，同時維持其 99% 的原始效能。此外，我們觀察到某些前饋子層組展現出高度的激活相似性，這可能有助於解釋它們令人驚訝的可合併性。

##### **Fleurs-SLU: A Massively Multilingual Benchmark for Spoken Language Understanding**
2501.06117v1 by Fabian David Schmidt, Ivan Vulić, Goran Glavaš, David Ifeoluwa Adelani

While recent multilingual automatic speech recognition models claim to
support thousands of languages, ASR for low-resource languages remains highly
unreliable due to limited bimodal speech and text training data. Better
multilingual spoken language understanding (SLU) can strengthen massively the
robustness of multilingual ASR by levering language semantics to compensate for
scarce training data, such as disambiguating utterances via context or
exploiting semantic similarities across languages. Even more so, SLU is
indispensable for inclusive speech technology in roughly half of all living
languages that lack a formal writing system. However, the evaluation of
multilingual SLU remains limited to shallower tasks such as intent
classification or language identification. To address this, we present
Fleurs-SLU, a multilingual SLU benchmark that encompasses topical speech
classification in 102 languages and multiple-choice question answering through
listening comprehension in 92 languages. We extensively evaluate both
end-to-end speech classification models and cascaded systems that combine
speech-to-text transcription with subsequent classification by large language
models on Fleurs-SLU. Our results show that cascaded systems exhibit greater
robustness in multilingual SLU tasks, though speech encoders can achieve
competitive performance in topical speech classification when appropriately
pre-trained. We further find a strong correlation between robust multilingual
ASR, effective speech-to-text translation, and strong multilingual SLU,
highlighting the mutual benefits between acoustic and semantic speech
representations.

摘要：儘管最近的多語言自動語音辨識模型宣稱支援數千種語言，但由於語音和文字訓練資料有限，低資源語言的 ASR 仍然高度不可靠。更好的多語言口語語言理解 (SLU) 可以透過利用語言語意來彌補稀少的訓練資料，例如透過語境消除歧義的語句或利用跨語言的語意相似性，大幅強化多語言 ASR 的穩健性。更重要的是，SLU 對於大約一半缺乏正式書寫系統的現存語言而言，對於包容性語音技術不可或缺。然而，多語言 SLU 的評量仍然侷限於較淺層的任務，例如意圖分類或語言辨識。為了解決這個問題，我們提出 Fleurs-SLU，這是一個多語言 SLU 基準，包含 102 種語言的主題語音分類，以及透過聆聽理解進行 92 種語言的多選題問答。我們廣泛評估了端對端語音分類模型和串接系統，這些系統結合語音轉文字轉錄，以及大型語言模型在 Fleurs-SLU 上的後續分類。我們的結果顯示，串接系統在多語言 SLU 任務中展現出更大的穩健性，儘管語音編碼器在適當預先訓練時，可以在主題語音分類中達成有競爭力的表現。我們進一步發現穩健的多語言 ASR、有效的語音轉文字翻譯，以及強大的多語言 SLU 之間存在強烈的關聯性，突顯了音訊和語意語音表徵之間的相互效益。

##### **From Conversation to Automation: Leveraging Large Language Models to Analyze Strategies in Problem Solving Therapy**
2501.06101v1 by Elham Aghakhani, Lu Wang, Karla T. Washington, George Demiris, Jina Huh-Yoo, Rezvaneh Rezapour

Problem-solving therapy (PST) is a structured psychological approach that
helps individuals manage stress and resolve personal issues by guiding them
through problem identification, solution brainstorming, decision-making, and
outcome evaluation. As mental health care increasingly integrates technologies
like chatbots and large language models (LLMs), understanding how PST can be
effectively automated is important. This study leverages anonymized therapy
transcripts to analyze and classify therapeutic interventions using various
LLMs and transformer-based models. Our results show that GPT-4o achieved the
highest accuracy (0.76) in identifying PST strategies, outperforming other
models. Additionally, we introduced a new dimension of communication strategies
that enhances the current PST framework, offering deeper insights into
therapist-client interactions. This research demonstrates the potential of LLMs
to automate complex therapeutic dialogue analysis, providing a scalable,
efficient tool for mental health interventions. Our annotation framework can
enhance the accessibility, effectiveness, and personalization of PST,
supporting therapists in real-time with more precise, targeted interventions.

摘要：問題解決療法 (PST) 是一種結構化的心理方法，透過引導個人識別問題、集思廣益解決方案、做出決策和評估結果，協助他們管理壓力和解決個人問題。隨著心理健康照護日益整合聊天機器人和大型語言模型 (LLM) 等技術，了解如何有效自動化 PST 非常重要。本研究利用匿名化的治療記錄，使用各種 LLM 和基於轉換器的模型來分析和分類治療介入措施。我們的結果顯示，GPT-4o 在識別 PST 策略方面達到了最高的準確度 (0.76)，優於其他模型。此外，我們引入了一個新的溝通策略面向，增強了當前的 PST 框架，提供了對治療師與客戶互動的更深入見解。這項研究展示了 LLM 在自動化複雜治療對話分析方面的潛力，為心理健康介入提供了一個可擴展且有效率的工具。我們的註解框架可以增強 PST 的可及性、有效性和個人化，並以更精確、更有針對性的介入措施即時支援治療師。

##### **Explaining Deep Learning-based Anomaly Detection in Energy Consumption Data by Focusing on Contextually Relevant Data**
2501.06099v1 by Mohammad Noorchenarboo, Katarina Grolinger

Detecting anomalies in energy consumption data is crucial for identifying
energy waste, equipment malfunction, and overall, for ensuring efficient energy
management. Machine learning, and specifically deep learning approaches, have
been greatly successful in anomaly detection; however, they are black-box
approaches that do not provide transparency or explanations. SHAP and its
variants have been proposed to explain these models, but they suffer from high
computational complexity (SHAP) or instability and inconsistency (e.g., Kernel
SHAP). To address these challenges, this paper proposes an explainability
approach for anomalies in energy consumption data that focuses on
context-relevant information. The proposed approach leverages existing
explainability techniques, focusing on SHAP variants, together with global
feature importance and weighted cosine similarity to select background dataset
based on the context of each anomaly point. By focusing on the context and most
relevant features, this approach mitigates the instability of explainability
algorithms. Experimental results across 10 different machine learning models,
five datasets, and five XAI techniques, demonstrate that our method reduces the
variability of explanations providing consistent explanations. Statistical
analyses confirm the robustness of our approach, showing an average reduction
in variability of approximately 38% across multiple datasets.

摘要：偵測能源消耗資料中的異常值對於找出能源浪費、設備故障至關重要，總體而言，這有助於確保能源管理的效率。機器學習，尤其是深度學習方法，在異常偵測方面已獲得極大的成功；然而，這些方法是黑箱方法，不提供透明度或解釋。SHAP 及其變體已被提出用於解釋這些模型，但它們存在高運算複雜度（SHAP）或不穩定和不一致（例如，Kernel SHAP）的問題。為了應對這些挑戰，本文提出了一種針對能源消耗資料異常值的解釋性方法，重點在於與背景相關的資訊。所提出的方法利用現有的解釋性技術，重點在於 SHAP 變體，並結合全域特徵重要性和加權餘弦相似性，以根據每個異常點的背景選擇背景資料集。透過關注背景和最相關的特徵，這種方法減輕了可解釋性演算法的不穩定性。針對 10 種不同的機器學習模型、5 個資料集和 5 種 XAI 技術的實驗結果證明，我們的模型降低了解釋的一致性，提供了穩定的解釋。統計分析確認了我們方法的穩健性，顯示出在多個資料集中，變異性平均降低約 38%。

##### **All AI Models are Wrong, but Some are Optimal**
2501.06086v1 by Akhil S Anand, Shambhuraj Sawant, Dirk Reinhardt, Sebastien Gros

AI models that predict the future behavior of a system (a.k.a. predictive AI
models) are central to intelligent decision-making. However, decision-making
using predictive AI models often results in suboptimal performance. This is
primarily because AI models are typically constructed to best fit the data, and
hence to predict the most likely future rather than to enable high-performance
decision-making. The hope that such prediction enables high-performance
decisions is neither guaranteed in theory nor established in practice. In fact,
there is increasing empirical evidence that predictive models must be tailored
to decision-making objectives for performance. In this paper, we establish
formal (necessary and sufficient) conditions that a predictive model (AI-based
or not) must satisfy for a decision-making policy established using that model
to be optimal. We then discuss their implications for building predictive AI
models for sequential decision-making.

摘要：預測系統未來行為的 AI 模型（又稱預測式 AI 模型）是智慧決策制定的核心。然而，使用預測式 AI 模型進行決策制定通常會導致次佳的績效。這是因為 AI 模型通常被建構為最適合資料，因此預測最可能的未來，而不是為了實現高績效的決策制定。這種預測能實現高績效決策的期望在理論上並未獲得保證，在實務上也未被證實。事實上，越來越多的實證證據顯示，預測模型必須根據決策制定目標進行調整，才能發揮效用。在本文中，我們建立正式（必要且充分）條件，預測模型（無論是否基於 AI）必須滿足這些條件，才能使用該模型建立的決策制定政策達到最佳化。然後我們討論其對建構用於序貫決策制定的預測式 AI 模型的影響。

##### **Scale-up Unlearnable Examples Learning with High-Performance Computing**
2501.06080v1 by Yanfan Zhu, Issac Lyngaas, Murali Gopalakrishnan Meena, Mary Ellen I. Koran, Bradley Malin, Daniel Moyer, Shunxing Bao, Anuj Kapadia, Xiao Wang, Bennett Landman, Yuankai Huo

Recent advancements in AI models are structured to retain user interactions,
which could inadvertently include sensitive healthcare data. In the healthcare
field, particularly when radiologists use AI-driven diagnostic tools hosted on
online platforms, there is a risk that medical imaging data may be repurposed
for future AI training without explicit consent, spotlighting critical privacy
and intellectual property concerns around healthcare data usage. Addressing
these privacy challenges, a novel approach known as Unlearnable Examples (UEs)
has been introduced, aiming to make data unlearnable to deep learning models. A
prominent method within this area, called Unlearnable Clustering (UC), has
shown improved UE performance with larger batch sizes but was previously
limited by computational resources. To push the boundaries of UE performance
with theoretically unlimited resources, we scaled up UC learning across various
datasets using Distributed Data Parallel (DDP) training on the Summit
supercomputer. Our goal was to examine UE efficacy at high-performance
computing (HPC) levels to prevent unauthorized learning and enhance data
security, particularly exploring the impact of batch size on UE's
unlearnability. Utilizing the robust computational capabilities of the Summit,
extensive experiments were conducted on diverse datasets such as Pets,
MedMNist, Flowers, and Flowers102. Our findings reveal that both overly large
and overly small batch sizes can lead to performance instability and affect
accuracy. However, the relationship between batch size and unlearnability
varied across datasets, highlighting the necessity for tailored batch size
strategies to achieve optimal data protection. Our results underscore the
critical role of selecting appropriate batch sizes based on the specific
characteristics of each dataset to prevent learning and ensure data security in
deep learning applications.

摘要：<paragraph>最近在 AI 模型中的進展被建構為保留使用者互動，
這可能無意間包含敏感的醫療保健資料。在醫療保健
領域，特別是當放射科醫師使用線上平台上提供的 AI 驅動診斷工具時，有風險是醫療影像資料可能會被重新用於未來的 AI 訓練，而未經明確同意，這突顯了與醫療保健資料使用相關的隱私和智慧財產權問題。為了應對
這些隱私挑戰，已導入一種稱為不可學習範例 (UE) 的新方法，旨在讓資料對深度學習模型不可學習。這個領域內一種著名的稱為不可學習聚類 (UC) 的方法，已顯示出在較大的批次大小下有改善的 UE 效能，但先前受到運算資源的限制。為了在理論上無限制資源的情況下推動 UE 效能的界線，我們在 Summit 超級電腦上使用分散式資料平行 (DDP) 訓練，擴大了各種資料集的 UC 學習。我們的目標是檢查 UE 在高效能運算 (HPC) 層級的效能，以防止未經授權的學習，並增強資料安全性，特別是探討批次大小對 UE 不可學習性的影響。利用 Summit 強大的運算能力，在各種資料集上進行了廣泛的實驗，例如 Pets、MedMNist、Flowers 和 Flowers102。我們的研究結果顯示，過大或過小的批次大小都可能導致效能不穩定，並影響準確度。然而，批次大小與不可學習性之間的關係在各個資料集之間有所不同，這突顯了根據特定資料集的特徵量身打造批次大小策略以達成最佳資料保護的必要性。我們的結果強調了根據每個資料集的特定特徵選擇適當批次大小以防止學習，並確保深度學習應用程式中資料安全性的關鍵作用。</paragraph>

##### **Explaining k-Nearest Neighbors: Abductive and Counterfactual Explanations**
2501.06078v1 by Pablo Barceló, Alexander Kozachinskiy, Miguel Romero Orth, Bernardo Subercaseaux, José Verschae

Despite the wide use of $k$-Nearest Neighbors as classification models, their
explainability properties remain poorly understood from a theoretical
perspective. While nearest neighbors classifiers offer interpretability from a
"data perspective", in which the classification of an input vector $\bar{x}$ is
explained by identifying the vectors $\bar{v}_1, \ldots, \bar{v}_k$ in the
training set that determine the classification of $\bar{x}$, we argue that such
explanations can be impractical in high-dimensional applications, where each
vector has hundreds or thousands of features and it is not clear what their
relative importance is. Hence, we focus on understanding nearest neighbor
classifications through a "feature perspective", in which the goal is to
identify how the values of the features in $\bar{x}$ affect its classification.
Concretely, we study abductive explanations such as "minimum sufficient
reasons", which correspond to sets of features in $\bar{x}$ that are enough to
guarantee its classification, and "counterfactual explanations" based on the
minimum distance feature changes one would have to perform in $\bar{x}$ to
change its classification. We present a detailed landscape of positive and
negative complexity results for counterfactual and abductive explanations,
distinguishing between discrete and continuous feature spaces, and considering
the impact of the choice of distance function involved. Finally, we show that
despite some negative complexity results, Integer Quadratic Programming and SAT
solving allow for computing explanations in practice.

摘要：儘管 $k$-最近鄰廣泛用於分類模型，但從理論角度來看，其可解釋性特性仍未被充分理解。雖然最近鄰分類器提供「資料觀點」的可解釋性，其中輸入向量 $\bar{x}$ 的分類透過識別訓練集中決定 $\bar{x}$ 分類的向量 $\bar{v}_1, \ldots, \bar{v}_k$ 來解釋，我們認為此類解釋在高維度應用中可能不切實際，因為每個向量有數百或數千個特徵，且不清楚它們的相對重要性為何。因此，我們專注於透過「特徵觀點」了解最近鄰分類，其中目標是識別 $\bar{x}$ 中特徵的值如何影響其分類。具體來說，我們研究演繹解釋，例如「最小充分理由」，這對應於 $\bar{x}$ 中足以保證其分類的特徵集合，以及基於最小距離特徵變化的「反事實解釋」，這些變化必須在 $\bar{x}$ 中執行才能改變其分類。我們針對反事實和演繹解釋提出正負複雜度結果的詳細概況，區分離散和連續特徵空間，並考慮所涉及距離函數選擇的影響。最後，我們表明儘管有些負面複雜度結果，但整數二次規劃和 SAT 求解允許在實務中計算解釋。

##### **Distilling Calibration via Conformalized Credal Inference**
2501.06066v1 by Jiayi Huang, Sangwoo Park, Nicola Paoletti, Osvaldo Simeone

Deploying artificial intelligence (AI) models on edge devices involves a
delicate balance between meeting stringent complexity constraints, such as
limited memory and energy resources, and ensuring reliable performance in
sensitive decision-making tasks. One way to enhance reliability is through
uncertainty quantification via Bayesian inference. This approach, however,
typically necessitates maintaining and running multiple models in an ensemble,
which may exceed the computational limits of edge devices. This paper
introduces a low-complexity methodology to address this challenge by distilling
calibration information from a more complex model. In an offline phase,
predictive probabilities generated by a high-complexity cloud-based model are
leveraged to determine a threshold based on the typical divergence between the
cloud and edge models. At run time, this threshold is used to construct credal
sets -- ranges of predictive probabilities that are guaranteed, with a
user-selected confidence level, to include the predictions of the cloud model.
The credal sets are obtained through thresholding of a divergence measure in
the simplex of predictive probabilities. Experiments on visual and language
tasks demonstrate that the proposed approach, termed Conformalized Distillation
for Credal Inference (CD-CI), significantly improves calibration performance
compared to low-complexity Bayesian methods, such as Laplace approximation,
making it a practical and efficient solution for edge AI deployments.

摘要：在邊緣裝置上部署人工智慧 (AI) 模型涉及在滿足嚴格的複雜性限制（例如有限的記憶體和能源資源）與確保在敏感的決策任務中表現可靠之間取得微妙的平衡。一種增強可靠性的方法是透過貝氏推論進行不確定性量化。然而，這種方法通常需要在一個整體中維護和執行多個模型，這可能會超過邊緣裝置的運算限制。本文介紹了一種低複雜度的技術，透過從一個更複雜的模型中萃取校正資訊來應對這個挑戰。在離線階段，由一個高複雜度的雲端模型產生的預測機率被用於根據雲端模型和邊緣模型之間的典型差異來確定一個閾值。在執行階段，這個閾值被用於建構可信集合——預測機率的範圍，保證在使用者選擇的信心水準下包含雲端模型的預測。可信集合是透過在預測機率的單純形中對一個差異測量進行閾值處理而獲得的。在視覺和語言任務上的實驗表明，所提出的方法（稱為可信推論的共形化萃取 (CD-CI)）與低複雜度的貝氏方法（例如拉普拉斯近似）相比，顯著改善了校正效能，使其成為邊緣 AI 部署的實用且有效率的解決方案。

##### **Benchmarking Rotary Position Embeddings for Automatic Speech Recognition**
2501.06051v1 by Shucong Zhang, Titouan Parcollet, Rogier van Dalen, Sourav Bhattacharya

Rotary Position Embedding (RoPE) encodes relative and absolute positional
information in Transformer-based models through rotation matrices applied to
input vectors within sequences. While RoPE has demonstrated superior
performance compared to other positional embedding technologies in natural
language processing tasks, its effectiveness in speech processing applications
remains understudied. In this work, we conduct a comprehensive evaluation of
RoPE across diverse automatic speech recognition (ASR) tasks. Our experimental
results demonstrate that for ASR tasks, RoPE consistently achieves lower error
rates compared to the currently widely used relative positional embedding. To
facilitate further research, we release the implementation and all experimental
recipes through the SpeechBrain toolkit.

摘要：旋轉位置嵌入 (RoPE) 透過應用於序列中輸入向量的旋轉矩陣，對 Transformer 為基礎的模型中的相對和絕對位置資訊進行編碼。雖然 RoPE 已在自然語言處理任務中展現出優於其他位置嵌入技術的優異效能，但在語音處理應用中的效能仍未獲得充分研究。在這項工作中，我們對 RoPE 進行了全面的評估，涵蓋各種自動語音辨識 (ASR) 任務。我們的實驗結果顯示，對於 ASR 任務，與目前廣泛使用的相對位置嵌入相比，RoPE 持續達成較低的錯誤率。為了促進進一步的研究，我們透過 SpeechBrain 工具包釋出實作和所有實驗範例。

##### **AI-powered virtual tissues from spatial proteomics for clinical diagnostics and biomedical discovery**
2501.06039v1 by Johann Wenckstern, Eeshaan Jain, Kiril Vasilev, Matteo Pariset, Andreas Wicki, Gabriele Gut, Charlotte Bunne

Spatial proteomics technologies have transformed our understanding of complex
tissue architectures by enabling simultaneous analysis of multiple molecular
markers and their spatial organization. The high dimensionality of these data,
varying marker combinations across experiments and heterogeneous study designs
pose unique challenges for computational analysis. Here, we present Virtual
Tissues (VirTues), a foundation model framework for biological tissues that
operates across the molecular, cellular and tissue scale. VirTues introduces
innovations in transformer architecture design, including a novel tokenization
scheme that captures both spatial and marker dimensions, and attention
mechanisms that scale to high-dimensional multiplex data while maintaining
interpretability. Trained on diverse cancer and non-cancer tissue datasets,
VirTues demonstrates strong generalization capabilities without task-specific
fine-tuning, enabling cross-study analysis and novel marker integration. As a
generalist model, VirTues outperforms existing approaches across clinical
diagnostics, biological discovery and patient case retrieval tasks, while
providing insights into tissue function and disease mechanisms.

摘要：空間蛋白質組學技術透過同時分析多個分子標記及其空間組織，轉變了我們對複雜組織結構的理解。這些數據的高維度、實驗中不同的標記組合和異質的研究設計，對計算分析構成了獨特的挑戰。在此，我們提出虛擬組織 (VirTues)，一個適用於分子、細胞和組織層級的生物組織基礎模型架構。VirTues 在Transformer架構設計中引進創新，包括一種新的標記化架構，它捕捉空間和標記維度，以及在維持可解釋性的同時擴展到高維度多重數據的注意力機制。VirTues 在多樣化的癌症和非癌症組織數據集上訓練，展示了強大的泛化能力，無需特定任務微調，從而實現跨研究分析和新的標記整合。作為一個通才模型，VirTues 在臨床診斷、生物發現和患者病例檢索任務中優於現有方法，同時提供了組織功能和疾病機制的見解。

##### **How to Tune a Multilingual Encoder Model for Germanic Languages: A Study of PEFT, Full Fine-Tuning, and Language Adapters**
2501.06025v1 by Romina Oji, Jenny Kunz

This paper investigates the optimal use of the multilingual encoder model
mDeBERTa for tasks in three Germanic languages -- German, Swedish, and
Icelandic -- representing varying levels of presence and likely data quality in
mDeBERTas pre-training data. We compare full fine-tuning with the
parameter-efficient fine-tuning (PEFT) methods LoRA and Pfeiffer bottleneck
adapters, finding that PEFT is more effective for the higher-resource language,
German. However, results for Swedish and Icelandic are less consistent. We also
observe differences between tasks: While PEFT tends to work better for question
answering, full fine-tuning is preferable for named entity recognition.
Inspired by previous research on modular approaches that combine task and
language adapters, we evaluate the impact of adding PEFT modules trained on
unstructured text, finding that this approach is not beneficial.

摘要：本文探討多語言編碼器模型 mDeBERTa 在三種日耳曼語系語言（德語、瑞典語和冰島語）中的最佳使用方式，這些語言代表了 mDeBERTa 預訓練數據中存在程度和可能數據品質的不同層級。我們將全微調與參數有效微調 (PEFT) 方法 LoRA 和 Pfeiffer 瓶頸適配器進行比較，發現 PEFT 對資源較多的語言德語更有效。然而，瑞典語和冰島語的結果較不一致。我們也觀察到任務之間的差異：雖然 PEFT 傾向於在問答中表現得更好，但全微調則較適合命名實體辨識。受先前結合任務和語言適配器之模組化方法研究的啟發，我們評估了在非結構化文字上訓練的 PEFT 模組加入後的影響，發現此方法並無益處。

##### **BRIGHT: A globally distributed multimodal building damage assessment dataset with very-high-resolution for all-weather disaster response**
2501.06019v1 by Hongruixuan Chen, Jian Song, Olivier Dietrich, Clifford Broni-Bediako, Weihao Xuan, Junjue Wang, Xinlei Shao, Yimin Wei, Junshi Xia, Cuiling Lan, Konrad Schindler, Naoto Yokoya

Disaster events occur around the world and cause significant damage to human
life and property. Earth observation (EO) data enables rapid and comprehensive
building damage assessment (BDA), an essential capability in the aftermath of a
disaster to reduce human casualties and to inform disaster relief efforts.
Recent research focuses on the development of AI models to achieve accurate
mapping of unseen disaster events, mostly using optical EO data. However,
solutions based on optical data are limited to clear skies and daylight hours,
preventing a prompt response to disasters. Integrating multimodal (MM) EO data,
particularly the combination of optical and SAR imagery, makes it possible to
provide all-weather, day-and-night disaster responses. Despite this potential,
the development of robust multimodal AI models has been constrained by the lack
of suitable benchmark datasets. In this paper, we present a BDA dataset using
veRy-hIGH-resoluTion optical and SAR imagery (BRIGHT) to support AI-based
all-weather disaster response. To the best of our knowledge, BRIGHT is the
first open-access, globally distributed, event-diverse MM dataset specifically
curated to support AI-based disaster response. It covers five types of natural
disasters and two types of man-made disasters across 12 regions worldwide, with
a particular focus on developing countries where external assistance is most
needed. The optical and SAR imagery in BRIGHT, with a spatial resolution
between 0.3-1 meters, provides detailed representations of individual
buildings, making it ideal for precise BDA. In our experiments, we have tested
seven advanced AI models trained with our BRIGHT to validate the
transferability and robustness. The dataset and code are available at
https://github.com/ChenHongruixuan/BRIGHT. BRIGHT also serves as the official
dataset for the 2025 IEEE GRSS Data Fusion Contest.

摘要：<paragraph>全球各地都會發生災害事件，對人類生命和財產造成重大損害。地球觀測 (EO) 資料能快速且全面地進行建築物損害評估 (BDA)，這是災後減少人員傷亡和提供救災資訊的重要能力。最近的研究重點在於開發 AI 模型，以準確繪製未見災害事件的地圖，大多使用光學 EO 資料。然而，基於光學資料的解決方案僅限於晴朗的天空和白天時段，無法對災害做出及時反應。整合多模式 (MM) EO 資料，特別是光學和 SAR 影像的組合，就能提供全天候、晝夜不間斷的災害應變能力。儘管有此潛力，但合適的基準資料集不足，限制了健全多模式 AI 模型的發展。在本文中，我們提出一個使用極高解析度光學和 SAR 影像 (BRIGHT) 的 BDA 資料集，以支援基於 AI 的全天候災害應變。據我們所知，BRIGHT 是第一個開放取用、全球分佈、事件多樣的 MM 資料集，專門策劃用於支援基於 AI 的災害應變。它涵蓋了全球 12 個地區的五種類型自然災害和兩種人為災害，特別關注最需要外部援助的開發中國家。BRIGHT 中的光學和 SAR 影像具有 0.3-1 公尺之間的空間解析度，提供個別建築物的詳細表示，非常適合精確的 BDA。在我們的實驗中，我們測試了七個使用我們的 BRIGHT 訓練的高階 AI 模型，以驗證其可轉移性和健全性。資料集和程式碼可在 https://github.com/ChenHongruixuan/BRIGHT 取得。BRIGHT 也作為 2025 IEEE GRSS 資料融合競賽的官方資料集。</paragraph>

##### **Addressing speaker gender bias in large scale speech translation systems**
2501.05989v1 by Shubham Bansal, Vikas Joshi, Harveen Chadha, Rupeshkumar Mehta, Jinyu Li

This study addresses the issue of speaker gender bias in Speech Translation
(ST) systems, which can lead to offensive and inaccurate translations. The
masculine bias often found in large-scale ST systems is typically perpetuated
through training data derived from Machine Translation (MT) systems. Our
approach involves two key steps. First, we employ Large Language Models (LLMs)
to rectify translations based on the speaker's gender in a cost-effective
manner. Second, we fine-tune the ST model with the corrected data, enabling the
model to generate gender-specific translations directly from audio cues,
without the need for explicit gender input. Additionally, we propose a
three-mode fine-tuned model for scenarios where the speaker's gender is either
predefined or should not be inferred from speech cues. We demonstrate a 70%
improvement in translations for female speakers compared to our baseline and
other large-scale ST systems, such as Seamless M4T and Canary, on the MuST-SHE
test set.

摘要：本研究探討了語音翻譯 (ST) 系統中的說話者性別偏見問題，這可能會導致冒犯性和不準確的翻譯。在大型 ST 系統中常見的男性偏見通常會透過從機器翻譯 (MT) 系統衍生的訓練資料而持續存在。我們的做法包含兩個關鍵步驟。首先，我們採用大型語言模型 (LLM) 以經濟有效的方式根據說話者的性別修正翻譯。其次，我們使用校正後的資料微調 ST 模型，使模型能夠直接從音訊提示產生性別特定的翻譯，而不需要明確的性別輸入。此外，我們針對說話者的性別預先定義或不應從語音提示中推論的情況，提出了一個三模式微調模型。與我們的基準和其他大型 ST 系統（例如 Seamless M4T 和 Canary）相比，我們在 MuST-SHE 測試集中展示了女性說話者翻譯的 70% 改進。

##### **Hermit Kingdom Through the Lens of Multiple Perspectives: A Case Study of LLM Hallucination on North Korea**
2501.05981v1 by Eunjung Cho, Won Ik Cho, Soomin Seo

Hallucination in large language models (LLMs) remains a significant challenge
for their safe deployment, particularly due to its potential to spread
misinformation. Most existing solutions address this challenge by focusing on
aligning the models with credible sources or by improving how models
communicate their confidence (or lack thereof) in their outputs. While these
measures may be effective in most contexts, they may fall short in scenarios
requiring more nuanced approaches, especially in situations where access to
accurate data is limited or determining credible sources is challenging. In
this study, we take North Korea - a country characterised by an extreme lack of
reliable sources and the prevalence of sensationalist falsehoods - as a case
study. We explore and evaluate how some of the best-performing multilingual
LLMs and specific language-based models generate information about North Korea
in three languages spoken in countries with significant geo-political
interests: English (United States, United Kingdom), Korean (South Korea), and
Mandarin Chinese (China). Our findings reveal significant differences,
suggesting that the choice of model and language can lead to vastly different
understandings of North Korea, which has important implications given the
global security challenges the country poses.

摘要：大型語言模型 (LLM) 中的幻覺仍然是其安全部署的一項重大挑戰，特別是因為它有可能散播錯誤訊息。現有的解決方案大多透過將模型與可信來源對齊，或透過改善模型傳達其對輸出結果的信心（或缺乏信心）來解決此挑戰。雖然這些措施在大部分情況下可能有效，但它們在需要更細緻方法的情況下可能會不足，特別是在無法取得準確資料或難以確定可信來源的情況下。在本研究中，我們以北韓為例，這個國家特徵是極度缺乏可靠來源和盛行聳人聽聞的虛假資訊。我們探討並評估一些表現最佳的多語言 LLM 和特定語言模型如何用三種語言產生有關北韓的資訊，而這三種語言是在具有重大地緣政治利益的國家所使用的：英語（美國、英國）、韓語（南韓）和華語（中國）。我們的研究結果揭示了顯著的差異，這表示模型和語言的選擇可能會導致對北韓有截然不同的理解，而這在考量到該國構成的全球安全挑戰時具有重要的意義。

##### **Towards Early Prediction of Self-Supervised Speech Model Performance**
2501.05966v1 by Ryan Whetten, Lucas Maison, Titouan Parcollet, Marco Dinarelli, Yannick Estève

In Self-Supervised Learning (SSL), pre-training and evaluation are resource
intensive. In the speech domain, current indicators of the quality of SSL
models during pre-training, such as the loss, do not correlate well with
downstream performance. Consequently, it is often difficult to gauge the final
downstream performance in a cost efficient manner during pre-training. In this
work, we propose unsupervised efficient methods that give insights into the
quality of the pre-training of SSL speech models, namely, measuring the cluster
quality and rank of the embeddings of the SSL model. Results show that measures
of cluster quality and rank correlate better with downstream performance than
the pre-training loss with only one hour of unlabeled audio, reducing the need
for GPU hours and labeled data in SSL model evaluation.

摘要：在自監督學習 (SSL) 中，預訓練和評估需要大量資源。在語音領域，預訓練期間 SSL 模型品質的當前指標（例如損失）與下游效能並無良好的關聯性。因此，在預訓練期間，通常難以以成本效益的方式評估最終的下游效能。在這項工作中，我們提出非監督的有效方法，可深入了解 SSL 語音模型預訓練的品質，即測量 SSL 模型的嵌入叢集品質和等級。結果顯示，與僅有一小時未標記音訊的預訓練損失相比，叢集品質和等級的測量與下游效能有更好的關聯性，減少了 SSL 模型評估中對 GPU 小時和標記資料的需求。

##### **Finnish SQuAD: A Simple Approach to Machine Translation of Span Annotations**
2501.05963v1 by Emil Nuutinen, Iiro Rastas, Filip Ginter

We apply a simple method to machine translate datasets with span-level
annotation using the DeepL MT service and its ability to translate formatted
documents. Using this method, we produce a Finnish version of the SQuAD2.0
question answering dataset and train QA retriever models on this new dataset.
We evaluate the quality of the dataset and more generally the MT method through
direct evaluation, indirect comparison to other similar datasets, a
backtranslation experiment, as well as through the performance of downstream
trained QA models. In all these evaluations, we find that the method of
transfer is not only simple to use but produces consistently better translated
data. Given its good performance on the SQuAD dataset, it is likely the method
can be used to translate other similar span-annotated datasets for other tasks
and languages as well. All code and data is available under an open license:
data at HuggingFace TurkuNLP/squad_v2_fi, code on GitHub TurkuNLP/squad2-fi,
and model at HuggingFace TurkuNLP/bert-base-finnish-cased-squad2.

摘要：我們運用一個簡單的方法，使用 DeepL MT 服務及其翻譯格式化文件的能
力，將具有區間層級註解的資料集進行機器翻譯。使用此方法，我們製作
了 SQuAD2.0 問答資料集的芬蘭語版本，並在這個新資料集上訓練 QA 檢
索模型。我們透過直接評估、與其他類似資料集的間接比較、反向翻譯
實驗，以及下游訓練的 QA 模型的效能，評估資料集的品質，以及更廣泛
的 MT 方法。在所有這些評估中，我們發現轉移方法不僅易於使用，而且
能產生一致更好的翻譯資料。鑑於它在 SQuAD 資料集上的良好效能，此
方法很可能可被用於翻譯其他類似的區間註解資料集，以供其他任務和
語言使用。所有程式碼和資料均在開放授權下提供：HuggingFace TurkuNLP/squad_v2_fi 上的資料、GitHub TurkuNLP/squad2-fi 上的程式碼，以及 HuggingFace TurkuNLP/bert-base-finnish-cased-squad2 上的模型。

##### **Effective faking of verbal deception detection with target-aligned adversarial attacks**
2501.05962v1 by Bennett Kleinberg, Riccardo Loconte, Bruno Verschuere

Background: Deception detection through analysing language is a promising
avenue using both human judgments and automated machine learning judgments. For
both forms of credibility assessment, automated adversarial attacks that
rewrite deceptive statements to appear truthful pose a serious threat. Methods:
We used a dataset of 243 truthful and 262 fabricated autobiographical stories
in a deception detection task for humans and machine learning models. A large
language model was tasked to rewrite deceptive statements so that they appear
truthful. In Study 1, humans who made a deception judgment or used the
detailedness heuristic and two machine learning models (a fine-tuned language
model and a simple n-gram model) judged original or adversarial modifications
of deceptive statements. In Study 2, we manipulated the target alignment of the
modifications, i.e. tailoring the attack to whether the statements would be
assessed by humans or computer models. Results: When adversarial modifications
were aligned with their target, human (d=-0.07 and d=-0.04) and machine
judgments (51% accuracy) dropped to the chance level. When the attack was not
aligned with the target, both human heuristics judgments (d=0.30 and d=0.36)
and machine learning predictions (63-78%) were significantly better than
chance. Conclusions: Easily accessible language models can effectively help
anyone fake deception detection efforts both by humans and machine learning
models. Robustness against adversarial modifications for humans and machines
depends on that target alignment. We close with suggestions on advancing
deception research with adversarial attack designs.

摘要：<paragraph>背景：透過分析語言來偵測欺騙，是一個有前途的方法，它同時運用人類判斷和自動機器學習判斷。對於這兩種形式的可信度評估，自動對抗攻擊會改寫欺騙性陳述以使其看起來真實，這會造成嚴重的威脅。方法：我們在人類和機器學習模型的欺騙偵測任務中，使用了一個包含 243 個真實和 262 個虛構自傳故事的資料集。一個大型語言模型被賦予任務，要改寫欺騙性陳述，使其看起來真實。在研究 1 中，做出欺騙判斷或使用詳細啟發法的人類，以及兩個機器學習模型（一個微調語言模型和一個簡單的 n-gram 模型），判斷了欺騙性陳述的原始修改或對抗性修改。在研究 2 中，我們操縱了修改的目標對齊，也就是針對陳述將由人類或電腦模型評估來調整攻擊。結果：當對抗性修改與其目標對齊時，人類（d=-0.07 和 d=-0.04）和機器判斷（51% 準確度）下降到機率層級。當攻擊沒有與目標對齊時，人類啟發法判斷（d=0.30 和 d=0.36）和機器學習預測（63-78%）都顯著優於機率。結論：容易取得的語言模型可以有效幫助任何人偽造人類和機器學習模型的欺騙偵測工作。人類和機器對抗性修改的穩健性取決於目標對齊。我們以關於使用對抗攻擊設計推進欺騙研究的建議作結。</paragraph>

##### **Scalable Vision Language Model Training via High Quality Data Curation**
2501.05952v1 by Hongyuan Dong, Zijian Kang, Weijie Yin, Xiao Liang, Chao Feng, Jiao Ran

In this paper, we introduce SAIL-VL (ScAlable Vision Language Model TraIning
via High QuaLity Data Curation), an open-source vision language model (VLM) of
state-of-the-art (SOTA) performance with 2B parameters. We introduce three key
improvements that contribute to SAIL-VL's leading performance: (1) Scalable
high-quality visual understanding data construction: We implement a visual
understanding data construction pipeline, which enables hundred-million-scale
high-quality recaption data annotation. Equipped with this pipeline, we curate
SAIL-Caption, a large-scale caption dataset with large quantity and the highest
data quality compared with opensource caption datasets. (2) Scalable
Pretraining with High-Quality Visual Understanding Data: We scale SAIL-VL's
pretraining budget up to 131B tokens and show that even a 2B VLM benefits from
scaled up training data sizes, exhibiting expected data size scaling laws in
visual understanding and instruction following performance. (3) Scalable SFT
via quantity and quality scaling: We introduce general guidance for instruction
data curation to scale up instruction data continuously, allowing us to
construct a large SFT dataset with the highest quality. To further improve
SAIL-VL's performance, we propose quality scaling, a multi-stage training
recipe with curriculum learning, to improve model performance scaling curves
w.r.t. data sizes from logarithmic to be near-linear. SAIL-VL obtains the
highest average score in 19 commonly used benchmarks in our evaluation and
achieves top1 performance among VLMs of comparable sizes on OpenCompass
(https://rank.opencompass.org.cn/leaderboard-multimodal). We release our
SAIL-VL-2B model at HuggingFace
(https://huggingface.co/BytedanceDouyinContent/SAIL-VL-2B).

摘要：<paragraph>在本文中，我們介紹了 SAIL-VL（通過高品質數據策展進行可擴展的視覺語言模型訓練），這是一個具有 2B 參數的最新技術 (SOTA) 性能的開源視覺語言模型 (VLM)。我們介紹了有助於 SAIL-VL 領先性能的三項關鍵改進：(1) 可擴展的高品質視覺理解數據構建：我們實作了一個視覺理解數據構建管道，可以進行億級規模的高品質重新標題數據註解。利用這個管道，我們策劃了 SAIL-Caption，這是一個與開源標題數據集相比，數量龐大且數據品質最高的大規模標題數據集。(2) 使用高品質視覺理解數據進行可擴展預訓練：我們將 SAIL-VL 的預訓練預算擴展到 131B 個符號，並顯示即使是 2B VLM 也能從擴展的訓練數據規模中受益，在視覺理解和指令遵循性能方面表現出預期的數據規模擴展定律。(3) 通過數量和品質擴展的可擴展 SFT：我們為指令數據策展引入了通用指導，以持續擴展指令數據，讓我們能夠構建一個品質最高的 SFT 數據集。為了進一步提升 SAIL-VL 的性能，我們提出了品質擴展，一種具有課程學習的多階段訓練配方，以改善模型性能擴展曲線，從對數到接近線性，相對於數據規模。SAIL-VL 在我們的評估中獲得了 19 個常用基準測試中的最高平均分，並在 OpenCompass（https://rank.opencompass.org.cn/leaderboard-multimodal）上取得了與同等規模的 VLM 相比的頂尖性能。我們在 HuggingFace（https://huggingface.co/BytedanceDouyinContent/SAIL-VL-2B）上發布了我們的 SAIL-VL-2B 模型。</paragraph>

##### **Universal-2-TF: Robust All-Neural Text Formatting for ASR**
2501.05948v1 by Yash Khare, Taufiquzzaman Peyash, Andrea Vanzo, Takuya Yoshioka

This paper introduces an all-neural text formatting (TF) model designed for
commercial automatic speech recognition (ASR) systems, encompassing punctuation
restoration (PR), truecasing, and inverse text normalization (ITN). Unlike
traditional rule-based or hybrid approaches, this method leverages a two-stage
neural architecture comprising a multi-objective token classifier and a
sequence-to-sequence (seq2seq) model. This design minimizes computational costs
and reduces hallucinations while ensuring flexibility and robustness across
diverse linguistic entities and text domains. Developed as part of the
Universal-2 ASR system, the proposed method demonstrates superior performance
in TF accuracy, computational efficiency, and perceptual quality, as validated
through comprehensive evaluations using both objective and subjective methods.
This work underscores the importance of holistic TF models in enhancing ASR
usability in practical settings.

摘要：本文介紹了一種全神經文本格式化 (TF) 模型，專為商業自動語音辨識 (ASR) 系統而設計，涵蓋標點符號復原 (PR)、真大小寫和反向文字正規化 (ITN)。與傳統的基於規則或混合方法不同，此方法利用了一個兩階段神經架構，包含一個多目標標記分類器和一個序列到序列 (seq2seq) 模型。此設計將運算成本降到最低，並減少幻覺，同時確保靈活性，並在不同的語言實體和文字領域中具有穩健性。此建議方法作為 Universal-2 ASR 系統的一部分開發，在 TF 準確度、運算效率和感知品質方面表現出優異的效能，並透過使用客觀和主觀方法進行全面評估來驗證。這項工作強調了整體 TF 模型在提升 ASR 在實際設定中的可用性方面的重要性。

##### **DiffuSETS: 12-lead ECG Generation Conditioned on Clinical Text Reports and Patient-Specific Information**
2501.05932v1 by Yongfan Lai, Jiabo Chen, Deyun Zhang, Yue Wang, Shijia Geng, Hongyan Li, Shenda Hong

Heart disease remains a significant threat to human health. As a non-invasive
diagnostic tool, the electrocardiogram (ECG) is one of the most widely used
methods for cardiac screening. However, the scarcity of high-quality ECG data,
driven by privacy concerns and limited medical resources, creates a pressing
need for effective ECG signal generation. Existing approaches for generating
ECG signals typically rely on small training datasets, lack comprehensive
evaluation frameworks, and overlook potential applications beyond data
augmentation. To address these challenges, we propose DiffuSETS, a novel
framework capable of generating ECG signals with high semantic alignment and
fidelity. DiffuSETS accepts various modalities of clinical text reports and
patient-specific information as inputs, enabling the creation of clinically
meaningful ECG signals. Additionally, to address the lack of standardized
evaluation in ECG generation, we introduce a comprehensive benchmarking
methodology to assess the effectiveness of generative models in this domain.
Our model achieve excellent results in tests, proving its superiority in the
task of ECG generation. Furthermore, we showcase its potential to mitigate data
scarcity while exploring novel applications in cardiology education and medical
knowledge discovery, highlighting the broader impact of our work.

摘要：心脏病仍然是人类健康的一大威胁。作为一种非侵入性诊断工具，心电图 (ECG) 是心脏筛查最广泛使用的方法之一。然而，由于隐私问题和医疗资源有限，高质量 ECG 数据的稀缺对有效的 ECG 信号生成提出了迫切需求。现有用于生成 ECG 信号的方法通常依赖于小型训练数据集，缺乏全面的评估框架，并且忽视了数据增强之外的潜在应用。为了应对这些挑战，我们提出了 DiffuSETS，这是一个能够生成具有高度语义对齐和保真度的 ECG 信号的新框架。DiffuSETS 接受各种形式的临床文本报告和患者特定信息作为输入，从而能够创建具有临床意义的 ECG 信号。此外，为了解决 ECG 生成中缺乏标准化评估的问题，我们引入了一种全面的基准测试方法来评估生成模型在此领域的有效性。我们的模型在测试中取得了优异的成果，证明了其在 ECG 生成任务中的优越性。此外，我们展示了其在缓解数据稀缺的同时在心脏病学教育和医学知识发现中探索新应用的潜力，突出了我们工作的更广泛影响。

##### **Towards Backdoor Stealthiness in Model Parameter Space**
2501.05928v1 by Xiaoyun Xu, Zhuoran Liu, Stefanos Koffas, Stjepan Picek

Recent research on backdoor stealthiness focuses mainly on indistinguishable
triggers in input space and inseparable backdoor representations in feature
space, aiming to circumvent backdoor defenses that examine these respective
spaces. However, existing backdoor attacks are typically designed to resist a
specific type of backdoor defense without considering the diverse range of
defense mechanisms. Based on this observation, we pose a natural question: Are
current backdoor attacks truly a real-world threat when facing diverse
practical defenses?
  To answer this question, we examine 12 common backdoor attacks that focus on
input-space or feature-space stealthiness and 17 diverse representative
defenses. Surprisingly, we reveal a critical blind spot: Backdoor attacks
designed to be stealthy in input and feature spaces can be mitigated by
examining backdoored models in parameter space. To investigate the underlying
causes behind this common vulnerability, we study the characteristics of
backdoor attacks in the parameter space. Notably, we find that input- and
feature-space attacks introduce prominent backdoor-related neurons in parameter
space, which are not thoroughly considered by current backdoor attacks. Taking
comprehensive stealthiness into account, we propose a novel supply-chain attack
called Grond. Grond limits the parameter changes by a simple yet effective
module, Adversarial Backdoor Injection (ABI), which adaptively increases the
parameter-space stealthiness during the backdoor injection. Extensive
experiments demonstrate that Grond outperforms all 12 backdoor attacks against
state-of-the-art (including adaptive) defenses on CIFAR-10, GTSRB, and a subset
of ImageNet. In addition, we show that ABI consistently improves the
effectiveness of common backdoor attacks.

摘要：<paragraph>最近針對後門隱匿性的研究主要集中在輸入空間中無法區分的觸發器和特徵空間中無法分離的後門表示，目的是規避檢查這些各自空間的後門防禦措施。然而，現有的後門攻擊通常設計為抵抗特定類型的後門防禦，而不會考慮各種防禦機制。基於此觀察，我們提出了一個自然的問題：在面對各種實際防禦時，當前的後門攻擊是否真的是一個現實世界的威脅？
為了回答這個問題，我們研究了 12 種常見的後門攻擊，這些攻擊專注於輸入空間或特徵空間隱匿性，以及 17 種不同的代表性防禦。令人驚訝的是，我們發現了一個關鍵的盲點：設計為在輸入和特徵空間中隱匿的後門攻擊可以通過在參數空間中檢查後門模型來減輕。為了調查這種常見漏洞背後的基本原因，我們研究了後門攻擊在參數空間中的特徵。值得注意的是，我們發現輸入和特徵空間攻擊在參數空間中引入了突出的後門相關神經元，而當前的後門攻擊並沒有徹底考慮這些神經元。考慮到全面的隱匿性，我們提出了一種名為 Grond 的新型供應鏈攻擊。Grond 通過一個簡單但有效的模塊（對抗後門注入 (ABI)）限制參數更改，該模塊會在後門注入期間自適應地增加參數空間隱匿性。大量實驗表明，在 CIFAR-10、GTSRB 和 ImageNet 的子集上，Grond 優於所有 12 種針對最先進（包括自適應）防禦的後門攻擊。此外，我們表明 ABI 始終如一地提高了常見後門攻擊的有效性。</paragraph>

##### **LLMs Reproduce Stereotypes of Sexual and Gender Minorities**
2501.05926v1 by Ruby Ostrow, Adam Lopez

A large body of research has found substantial gender bias in NLP systems.
Most of this research takes a binary, essentialist view of gender: limiting its
variation to the categories _men_ and _women_, conflating gender with sex, and
ignoring different sexual identities. But gender and sexuality exist on a
spectrum, so in this paper we study the biases of large language models (LLMs)
towards sexual and gender minorities beyond binary categories. Grounding our
study in a widely used psychological framework -- the Stereotype Content Model
-- we demonstrate that English-language survey questions about social
perceptions elicit more negative stereotypes of sexual and gender minorities
from LLMs, just as they do from humans. We then extend this framework to a more
realistic use case: text generation. Our analysis shows that LLMs generate
stereotyped representations of sexual and gender minorities in this setting,
raising concerns about their capacity to amplify representational harms in
creative writing, a widely promoted use case.

摘要：大量研究發現 NLP 系統存在顯著的性別偏見。
這類研究大多採用二元、本質主義的性別觀點：將其變異限制在「男性」和「女性」的類別中，將性別與性混為一談，並忽略不同的性認同。但性別和性存在於一個光譜中，因此在本文中，我們研究大型語言模型 (LLM) 對超越二元類別的性少數和性別少數的偏見。我們以廣泛使用的社會心理學架構——刻板印象內容模型——為基礎，證明了英語語言中關於社會認知的調查問題會引發 LLM 對性少數和性別少數產生更多負面的刻板印象，就像人類一樣。然後，我們將這個架構擴展到更實際的用例：文本生成。我們的分析表明，LLM 在這種情況下會產生性少數和性別少數的刻板印象，令人擔憂它們在創意寫作（一種廣泛推廣的用例）中放大表徵性傷害的能力。

##### **Navigating Tomorrow: Reliably Assessing Large Language Models Performance on Future Event Prediction**
2501.05925v1 by Petraq Nako, Adam Jatowt

Predicting future events is an important activity with applications across
multiple fields and domains. For example, the capacity to foresee stock market
trends, natural disasters, business developments, or political events can
facilitate early preventive measures and uncover new opportunities. Multiple
diverse computational methods for attempting future predictions, including
predictive analysis, time series forecasting, and simulations have been
proposed. This study evaluates the performance of several large language models
(LLMs) in supporting future prediction tasks, an under-explored domain. We
assess the models across three scenarios: Affirmative vs. Likelihood
questioning, Reasoning, and Counterfactual analysis. For this, we create a
dataset1 by finding and categorizing news articles based on entity type and its
popularity. We gather news articles before and after the LLMs training cutoff
date in order to thoroughly test and compare model performance. Our research
highlights LLMs potential and limitations in predictive modeling, providing a
foundation for future improvements.

摘要：預測未來事件是一項重要的活動，在多個領域和範疇中都有應用。例如，預見股市趨勢、自然災害、商業發展或政治事件的能力可以促進早期預防措施並發現新的機會。已經提出了多種不同的計算方法來嘗試預測未來，包括預測分析、時間序列預測和模擬。這項研究評估了多個大型語言模型 (LLM) 在支援未來預測任務中的表現，這是一個尚未充分探索的領域。我們在三種情境中評估這些模型：肯定與可能性提問、推理和反事實分析。為此，我們透過根據實體類型及其受歡迎程度來尋找和分類新聞文章來建立一個資料集 1。我們收集 LLM 訓練截止日期之前和之後的新聞文章，以便徹底測試和比較模型效能。我們的研究重點說明了 LLM 在預測模型中的潛力與限制，為未來的改進奠定基礎。

##### **Affordably Fine-tuned LLMs Provide Better Answers to Course-specific MCQs**
2501.05891v1 by Bianca Raimondi, Saverio Giallorenzo, Maurizio Gabbrielli

In education, the capability of generating human-like text of Large Language
Models (LLMs) inspired work on how they can increase the efficiency of learning
and teaching. We study the affordability of these models for educators and
students by investigating how LLMs answer multiple-choice questions (MCQs) with
respect to hardware constraints and refinement techniques. We explore this
space by using generic pre-trained LLMs (the 7B, 13B, and 70B variants of
LLaMA-2) to answer 162 undergraduate-level MCQs from a course on Programming
Languages (PL) -- the MCQ dataset is a contribution of this work, which we make
publicly available. Specifically, we dissect how different factors, such as
using readily-available material -- (parts of) the course's textbook -- for
fine-tuning and quantisation (to decrease resource usage) can change the
accuracy of the responses. The main takeaway is that smaller textbook-based
fine-tuned models outperform generic larger ones (whose pre-training requires
conspicuous resources), making the usage of LLMs for answering MCQs resource-
and material-wise affordable.

摘要：在教育中，生成类似人类文本的大型语言模型 (LLM) 的能力激发了人们对如何提高学习和教学效率的研究。我们通过调查 LLM 如何在硬件限制和优化技术方面回答多项选择题 (MCQ) 来研究这些模型对教育者和学生的可负担性。我们通过使用通用的预训练 LLM（LLaMA-2 的 7B、13B 和 70B 变体）来探索这个空间，以回答来自编程语言 (PL) 课程的 162 个本科生级别的 MCQ——MCQ 数据集是这项工作的贡献，我们公开提供。具体来说，我们剖析了不同因素如何改变响应的准确性，例如使用现成的材料——（课程教科书的）部分——进行微调和量化（以减少资源使用）。最主要的收获是，较小的基于教科书的微调模型优于通用的较大模型（其预训练需要显着的资源），这使得使用 LLM 来回答 MCQ 在资源和材料方面变得可负担。

##### **EDNet: Edge-Optimized Small Target Detection in UAV Imagery -- Faster Context Attention, Better Feature Fusion, and Hardware Acceleration**
2501.05885v1 by Zhifan Song, Yuan Zhang, Abd Al Rahman M. Abu Ebayyeh

Detecting small targets in drone imagery is challenging due to low
resolution, complex backgrounds, and dynamic scenes. We propose EDNet, a novel
edge-target detection framework built on an enhanced YOLOv10 architecture,
optimized for real-time applications without post-processing. EDNet
incorporates an XSmall detection head and a Cross Concat strategy to improve
feature fusion and multi-scale context awareness for detecting tiny targets in
diverse environments. Our unique C2f-FCA block employs Faster Context Attention
to enhance feature extraction while reducing computational complexity. The WIoU
loss function is employed for improved bounding box regression. With seven
model sizes ranging from Tiny to XL, EDNet accommodates various deployment
environments, enabling local real-time inference and ensuring data privacy.
Notably, EDNet achieves up to a 5.6% gain in mAP@50 with significantly fewer
parameters. On an iPhone 12, EDNet variants operate at speeds ranging from 16
to 55 FPS, providing a scalable and efficient solution for edge-based object
detection in challenging drone imagery. The source code and pre-trained models
are available at: https://github.com/zsniko/EDNet.

摘要：由於解析度低、背景複雜且場景動態，在無人機影像中偵測小型目標是一項挑戰。我們提出 EDNet，一個建構在增強的 YOLOv10 架構上的新型邊緣目標偵測架構，針對即時應用進行最佳化，無需後處理。EDNet 結合一個 XSmall 偵測頭和一個 Cross Concat 策略，以改善特徵融合和多尺度背景感知，用於在各種環境中偵測微小目標。我們獨特的 C2f-FCA 區塊採用 Faster Context Attention 來增強特徵萃取，同時降低運算複雜度。WIoU 損失函數用於改善邊界框回歸。EDNet 有七種型號尺寸，從 Tiny 到 XL，可適應各種部署環境，支援本地即時推論並確保資料隱私。值得注意的是，EDNet 在 mAP@50 中獲得高達 5.6% 的增益，而參數卻明顯減少。在 iPhone 12 上，EDNet 變體運作速度範圍從 16 到 55 FPS，為具挑戰性的無人機影像中的邊緣物件偵測提供可擴充且高效的解決方案。原始程式碼和預先訓練的模型可在 https://github.com/zsniko/EDNet 取得。

##### **VideoRAG: Retrieval-Augmented Generation over Video Corpus**
2501.05874v1 by Soyeong Jeong, Kangsan Kim, Jinheon Baek, Sung Ju Hwang

Retrieval-Augmented Generation (RAG) is a powerful strategy to address the
issue of generating factually incorrect outputs in foundation models by
retrieving external knowledge relevant to queries and incorporating it into
their generation process. However, existing RAG approaches have primarily
focused on textual information, with some recent advancements beginning to
consider images, and they largely overlook videos, a rich source of multimodal
knowledge capable of representing events, processes, and contextual details
more effectively than any other modality. While a few recent studies explore
the integration of videos in the response generation process, they either
predefine query-associated videos without retrieving them according to queries,
or convert videos into the textual descriptions without harnessing their
multimodal richness. To tackle these, we introduce VideoRAG, a novel framework
that not only dynamically retrieves relevant videos based on their relevance
with queries but also utilizes both visual and textual information of videos in
the output generation. Further, to operationalize this, our method revolves
around the recent advance of Large Video Language Models (LVLMs), which enable
the direct processing of video content to represent it for retrieval and
seamless integration of the retrieved videos jointly with queries. We
experimentally validate the effectiveness of VideoRAG, showcasing that it is
superior to relevant baselines.

摘要：檢索增強產生 (RAG) 是一種強大的策略，可用於解決基礎模型中產生事實錯誤輸出的問題，方法是檢索與查詢相關的外部知識並將其納入其產生過程中。然而，現有的 RAG 方法主要集中在文字資訊上，有些最近的進展開始考慮影像，而且它們在很大程度上忽略了影片，這是一種豐富的多模態知識來源，能夠比任何其他模態更有效地呈現事件、流程和背景細節。雖然最近的一些研究探討了在回應產生過程中整合影片，但它們要不預先定義與查詢相關的影片，而不根據查詢檢索它們，要不將影片轉換為文字描述，而沒有利用它們的多模態豐富性。為了解決這些問題，我們引入了 VideoRAG，這是一個新穎的框架，它不僅根據影片與查詢的相關性動態檢索相關影片，而且在輸出產生中同時利用影片的視覺和文字資訊。此外，為了操作化這一點，我們的方法圍繞著大型影片語言模型 (LVLMs) 的最新進展，它能夠直接處理影片內容，以表示它用於檢索和無縫整合檢索到的影片與查詢。我們透過實驗驗證了 VideoRAG 的有效性，展示出它優於相關基準。

##### **ConSim: Measuring Concept-Based Explanations' Effectiveness with Automated Simulatability**
2501.05855v1 by Antonin Poché, Alon Jacovi, Agustin Martin Picard, Victor Boutin, Fanny Jourdan

Concept-based explanations work by mapping complex model computations to
human-understandable concepts. Evaluating such explanations is very difficult,
as it includes not only the quality of the induced space of possible concepts
but also how effectively the chosen concepts are communicated to users.
Existing evaluation metrics often focus solely on the former, neglecting the
latter. We introduce an evaluation framework for measuring concept explanations
via automated simulatability: a simulator's ability to predict the explained
model's outputs based on the provided explanations. This approach accounts for
both the concept space and its interpretation in an end-to-end evaluation.
Human studies for simulatability are notoriously difficult to enact,
particularly at the scale of a wide, comprehensive empirical evaluation (which
is the subject of this work). We propose using large language models (LLMs) as
simulators to approximate the evaluation and report various analyses to make
such approximations reliable. Our method allows for scalable and consistent
evaluation across various models and datasets. We report a comprehensive
empirical evaluation using this framework and show that LLMs provide consistent
rankings of explanation methods. Code available at
https://github.com/AnonymousConSim/ConSim

摘要：概念型解釋透過將複雜的模型運算對應到人類可以理解的概念來運作。評估這種解釋非常困難，因為它不僅包括可能的概念誘發空間的品質，還包括選擇的概念有效傳達給使用者的程度。現有的評估指標通常只關注前者，而忽略後者。我們引入一個評估架構，透過自動模擬性來衡量概念解釋：模擬器根據提供的解釋預測已解釋模型的輸出。這種方法同時考量了概念空間及其在端到端評估中的詮釋。眾所周知，模擬性的人類研究難以制定，特別是在廣泛、全面的實證評估的規模上（這是這項工作的重點）。我們建議使用大型語言模型 (LLM) 作為模擬器來近似評估並報告各種分析，以使此類近似值更可靠。我們的模型允許跨各種模型和資料集進行可擴充且一致的評估。我們使用這個架構報告了一個全面的實證評估，並顯示 LLM 提供了一致的解釋方法排名。程式碼可在 https://github.com/AnonymousConSim/ConSim 取得

##### **Annealing Machine-assisted Learning of Graph Neural Network for Combinatorial Optimization**
2501.05845v1 by Pablo Loyola, Kento Hasegawa, Andres Hoyos-Idobro, Kazuo Ono, Toyotaro Suzumura, Yu Hirate, Masanao Yamaoka

While Annealing Machines (AM) have shown increasing capabilities in solving
complex combinatorial problems, positioning themselves as a more immediate
alternative to the expected advances of future fully quantum solutions, there
are still scaling limitations. In parallel, Graph Neural Networks (GNN) have
been recently adapted to solve combinatorial problems, showing competitive
results and potentially high scalability due to their distributed nature. We
propose a merging approach that aims at retaining both the accuracy exhibited
by AMs and the representational flexibility and scalability of GNNs. Our model
considers a compression step, followed by a supervised interaction where
partial solutions obtained from the AM are used to guide local GNNs from where
node feature representations are obtained and combined to initialize an
additional GNN-based solver that handles the original graph's target problem.
Intuitively, the AM can solve the combinatorial problem indirectly by infusing
its knowledge into the GNN. Experiments on canonical optimization problems show
that the idea is feasible, effectively allowing the AM to solve size problems
beyond its original limits.

摘要：雖然退火機器 (AM) 在解決複雜組合問題方面展現出越來越強大的能力，並將自己定位為未來完全量子解決方案預期進展中更直接的替代方案，但仍存在擴充限制。與此同時，圖神經網路 (GNN) 最近已改編為解決組合問題，由於其分佈式性質，展現出競爭力的結果和潛在的高擴充性。我們提出了一種合併方法，旨在保留 AM 展現的準確性以及 GNN 的表示靈活性與擴充性。我們的模型考慮了一個壓縮步驟，接著是一個監督互動，其中從 AM 獲得的部分解決方案用於引導局部 GNN，從中獲得節點特徵表示並結合起來，以初始化一個額外的基於 GNN 的求解器來處理原始圖形的目標問題。直觀上，AM 可以透過將其知識注入 GNN 來間接解決組合問題。在典型最佳化問題上的實驗顯示，這個想法是可行的，有效地允許 AM 解決超出其原始限制的大小問題。

##### **Diffusion Models for Smarter UAVs: Decision-Making and Modeling**
2501.05819v1 by Yousef Emami, Hao Zhou, Luis Almeida, Kai Li

Unmanned Aerial Vehicles (UAVs) are increasingly adopted in modern
communication networks. However, challenges in decision-making and digital
modeling continue to impede their rapid advancement. Reinforcement Learning
(RL) algorithms face limitations such as low sample efficiency and limited data
versatility, further magnified in UAV communication scenarios. Moreover,
Digital Twin (DT) modeling introduces substantial decision-making and data
management complexities. RL models, often integrated into DT frameworks,
require extensive training data to achieve accurate predictions. In contrast to
traditional approaches that focus on class boundaries, Diffusion Models (DMs),
a new class of generative AI, learn the underlying probability distribution
from the training data and can generate trustworthy new patterns based on this
learned distribution. This paper explores the integration of DMs with RL and DT
to effectively address these challenges. By combining the data generation
capabilities of DMs with the decision-making framework of RL and the modeling
accuracy of DT, the integration improves the adaptability and real-time
performance of UAV communication. Moreover, the study shows how DMs can
alleviate data scarcity, improve policy networks, and optimize dynamic
modeling, providing a robust solution for complex UAV communication scenarios.

摘要：無人機（UAV）在現代通信網路中日益普及。然而，決策制定和數位建模的挑戰持續阻礙其快速進展。強化學習（RL）演算法面臨低樣本效率和有限資料通用性等限制，在無人機通訊場景中進一步放大。此外，數位孿生（DT）建模引入了大量的決策制定和資料管理複雜性。RL 模型通常整合到 DT 框架中，需要大量的訓練資料才能實現準確的預測。與專注於類別邊界的傳統方法不同，擴散模型（DM）是一種新的生成式 AI，它從訓練資料中學習基礎機率分佈，並可以根據此學習分佈產生可信賴的新模式。本文探討了 DM 與 RL 和 DT 的整合，以有效應對這些挑戰。通過將 DM 的資料生成能力與 RL 的決策制定框架和 DT 的建模準確性相結合，整合改善了無人機通訊的適應性和即時效能。此外，研究表明 DM 如何緩解資料短缺、改善策略網路，並最佳化動態建模，為複雜的無人機通訊場景提供穩健的解決方案。

##### **IndoNLP 2025: Shared Task on Real-Time Reverse Transliteration for Romanized Indo-Aryan languages**
2501.05816v1 by Deshan Sumanathilaka, Isuri Anuradha, Ruvan Weerasinghe, Nicholas Micallef, Julian Hough

The paper overviews the shared task on Real-Time Reverse Transliteration for
Romanized Indo-Aryan languages. It focuses on the reverse transliteration of
low-resourced languages in the Indo-Aryan family to their native scripts.
Typing Romanized Indo-Aryan languages using ad-hoc transliterals and achieving
accurate native scripts are complex and often inaccurate processes with the
current keyboard systems. This task aims to introduce and evaluate a real-time
reverse transliterator that converts Romanized Indo-Aryan languages to their
native scripts, improving the typing experience for users. Out of 11 registered
teams, four teams participated in the final evaluation phase with
transliteration models for Sinhala, Hindi and Malayalam. These proposed
solutions not only solve the issue of ad-hoc transliteration but also empower
low-resource language usability in the digital arena.

摘要：這篇論文概述了羅馬化印度-雅利安語的實時反轉轉寫共享任務。重點在於將印度-雅利安語系中資源匱乏的語言反轉轉寫成其母語文字。使用臨時轉寫符號輸入羅馬化印度-雅利安語，並使用目前的鍵盤系統達成準確的母語文字，這些過程複雜且經常不準確。此任務旨在介紹和評估一個實時的反轉轉寫器，將羅馬化印度-雅利安語轉換成其母語文字，改善使用者的輸入體驗。11 個已註冊的團隊中，有 4 個團隊參與了最終評估階段，並提供了針對僧伽羅語、印地語和馬拉雅拉姆語的轉寫模型。這些提出的解決方案不僅解決了臨時轉寫的問題，也提升了數位領域中資源匱乏語言的可用性。

##### **Real-Time Integrated Dispatching and Idle Fleet Steering with Deep Reinforcement Learning for A Meal Delivery Platform**
2501.05808v1 by Jingyi Cheng, Shadi Sharif Azadeh

To achieve high service quality and profitability, meal delivery platforms
like Uber Eats and Grubhub must strategically operate their fleets to ensure
timely deliveries for current orders while mitigating the consequential impacts
of suboptimal decisions that leads to courier understaffing in the future. This
study set out to solve the real-time order dispatching and idle courier
steering problems for a meal delivery platform by proposing a reinforcement
learning (RL)-based strategic dual-control framework. To address the inherent
sequential nature of these problems, we model both order dispatching and
courier steering as Markov Decision Processes. Trained via a deep reinforcement
learning (DRL) framework, we obtain strategic policies by leveraging the
explicitly predicted demands as part of the inputs. In our dual-control
framework, the dispatching and steering policies are iteratively trained in an
integrated manner. These forward-looking policies can be executed in real-time
and provide decisions while jointly considering the impacts on local and
network levels. To enhance dispatching fairness, we propose convolutional deep
Q networks to construct fair courier embeddings. To simultaneously rebalance
the supply and demand within the service network, we propose to utilize
mean-field approximated supply-demand knowledge to reallocate idle couriers at
the local level. Utilizing the policies generated by the RL-based strategic
dual-control framework, we find the delivery efficiency and fairness of
workload distribution among couriers have been improved, and under-supplied
conditions have been alleviated within the service network. Our study sheds
light on designing an RL-based framework to enable forward-looking real-time
operations for meal delivery platforms and other on-demand services.

摘要：<paragraph>為了達到高服務品質和獲利能力，外送平台如 Uber Eats 和 Grubhub 必須策略性地營運其車隊，以確保現有訂單能準時送達，同時降低次優決策造成的後續影響，避免未來快遞人員人手不足。本研究著手解決外送平台的即時訂單派送和閒置快遞員導航問題，並提出一個基於強化學習 (RL) 的策略性雙重控制架構。為了處理這些問題中固有的順序性質，我們將訂單派送和快遞員導航建模為馬可夫決策過程。透過深度強化學習 (DRL) 架構進行訓練，我們透過利用明確預測的需求作為輸入的一部分，獲得策略性政策。在我們的雙重控制架構中，派送和導航政策會以整合的方式進行反覆訓練。這些前瞻性的政策可以在即時執行，並在共同考量對區域和網路層級的影響時提供決策。為了提升派送公平性，我們提出卷積深度 Q 網路來建構公平的快遞員嵌入。為了同時在服務網路中重新平衡供需，我們提出利用平均場近似供需知識，在區域層級重新配置閒置快遞員。利用 RL 基於策略性雙重控制架構產生的政策，我們發現快遞員之間的工作負載分配的配送效率和公平性獲得改善，並且在服務網路中緩解了供應不足的狀況。我們的研究有助於設計一個基於 RL 的架構，以實現外送平台和其他隨選服務的前瞻性即時運作。</paragraph>

##### **Alignment without Over-optimization: Training-Free Solution for Diffusion Models**
2501.05803v1 by Sunwoo Kim, Minkyu Kim, Dongmin Park

Diffusion models excel in generative tasks, but aligning them with specific
objectives while maintaining their versatility remains challenging. Existing
fine-tuning methods often suffer from reward over-optimization, while
approximate guidance approaches fail to optimize target rewards effectively.
Addressing these limitations, we propose a training-free sampling method based
on Sequential Monte Carlo (SMC) to sample from the reward-aligned target
distribution. Our approach, tailored for diffusion sampling and incorporating
tempering techniques, achieves comparable or superior target rewards to
fine-tuning methods while preserving diversity and cross-reward generalization.
We demonstrate its effectiveness in single-reward optimization, multi-objective
scenarios, and online black-box optimization. This work offers a robust
solution for aligning diffusion models with diverse downstream objectives
without compromising their general capabilities. Code is available at
https://github.com/krafton-ai/DAS .

摘要：擴散模型在生成任務中表現出色，但要在保持其多功能性的同時，將它們與特定目標保持一致仍然具有挑戰性。現有的微調方法通常會因獎勵過度最佳化而受苦，而近似指導方法無法有效最佳化目標獎勵。針對這些限制，我們提出了一種基於序貫蒙地卡羅 (SMC) 的無訓練取樣方法，以從獎勵對齊目標分佈中取樣。我們的方法專門針對擴散取樣並結合回火技術，可實現與微調方法相當或更佳的目標獎勵，同時保留多樣性和跨獎勵泛化性。我們展示了其在單一獎勵最佳化、多目標場景和線上黑盒最佳化中的有效性。這項工作為在不損害擴散模型一般功能性的情況下，將其與不同的下游目標保持一致，提供了一個強大的解決方案。程式碼可在 https://github.com/krafton-ai/DAS 取得。

##### **Robust Counterfactual Explanations under Model Multiplicity Using Multi-Objective Optimization**
2501.05795v1 by Keita Kinjo

In recent years, explainability in machine learning has gained importance. In
this context, counterfactual explanation (CE), which is an explanation method
that uses examples, has attracted attention. However, it has been pointed out
that CE is not robust when there are multiple machine-learning models. These
problems are important when using machine learning to make safe decisions. In
this paper, we propose robust CEs that introduce a new viewpoint - Pareto
improvement - and a method that uses multi-objective optimization to generate
it. To evaluate the proposed method, we conducted experiments using both
simulated and actual data. The results demonstrate that the proposed method is
robust and useful. We believe that this research will contribute to a wide
range of research areas, such as explainability in machine learning,
decision-making, and action planning based on machine learning.

摘要：近年来，机器学习中的可解释性变得越来越重要。在此背景下，使用示例的解释方法反事实解释（CE）引起了关注。然而，有观点指出，当存在多个机器学习模型时，CE 并不稳健。在使用机器学习做出安全决策时，这些问题非常重要。在本文中，我们提出了稳健的 CE，它引入了一个新的观点 - 帕累托改进 - 以及一种使用多目标优化来生成它的方法。为了评估所提出的方法，我们使用模拟数据和实际数据进行了实验。结果表明，所提出的方法是稳健且有用的。我们相信，这项研究将有助于机器学习中的可解释性、基于机器学习的决策制定和行动规划等广泛的研究领域。

##### **Understanding Impact of Human Feedback via Influence Functions**
2501.05790v1 by Taywon Min, Haeone Lee, Hanho Ryu, Yongchan Kwon, Kimin Lee

In Reinforcement Learning from Human Feedback (RLHF), it is crucial to learn
suitable reward models from human feedback to align large language models
(LLMs) with human intentions. However, human feedback can often be noisy,
inconsistent, or biased, especially when evaluating complex responses. Such
feedback can lead to misaligned reward signals, potentially causing unintended
side effects during the RLHF process. To address these challenges, we explore
the use of influence functions to measure the impact of human feedback on the
performance of reward models. We propose a compute-efficient approximation
method that enables the application of influence functions to LLM-based reward
models and large-scale preference datasets. In our experiments, we demonstrate
two key applications of influence functions: (1) detecting common forms of
labeler bias in human feedback datasets and (2) guiding labelers to refine
their strategies to align more closely with expert feedback. By quantifying the
impact of human feedback on reward models, we believe that influence functions
can enhance feedback interpretability and contribute to scalable oversight in
RLHF, helping labelers provide more accurate and consistent feedback. Source
code is available at https://github.com/mintaywon/IF_RLHF

摘要：在人類回饋強化學習 (RLHF) 中，從人類回饋學習合適的獎勵模型以將大型語言模型 (LLM) 與人類意圖保持一致至關重要。然而，人類回饋通常會很雜亂、不一致或有偏見，特別是在評估複雜回應時。這種回饋可能會導致獎勵信號錯位，潛在會在 RLHF 過程中造成意想不到的副作用。為了應對這些挑戰，我們探索使用影響函數來衡量人類回饋對獎勵模型效能的影響。我們提出一個運算效率近似法，讓影響函數能夠應用於基於 LLM 的獎勵模型和大規模偏好資料集。在我們的實驗中，我們展示了影響函數的兩個關鍵應用：(1) 偵測人類回饋資料集中常見的標籤員偏見形式，以及 (2) 引導標籤員改善其策略以更貼近專家回饋。透過量化人類回饋對獎勵模型的影響，我們相信影響函數可以增強回饋可解釋性，並有助於 RLHF 中可擴充的監督，幫助標籤員提供更準確且一致的回饋。原始程式碼可於 https://github.com/mintaywon/IF_RLHF 取得

##### **MARS6: A Small and Robust Hierarchical-Codec Text-to-Speech Model**
2501.05787v1 by Matthew Baas, Pieter Scholtz, Arnav Mehta, Elliott Dyson, Akshat Prakash, Herman Kamper

Codec-based text-to-speech (TTS) models have shown impressive quality with
zero-shot voice cloning abilities. However, they often struggle with more
expressive references or complex text inputs. We present MARS6, a robust
encoder-decoder transformer for rapid, expressive TTS. MARS6 is built on recent
improvements in spoken language modelling. Utilizing a hierarchical setup for
its decoder, new speech tokens are processed at a rate of only 12 Hz, enabling
efficient modelling of long-form text while retaining reconstruction quality.
We combine several recent training and inference techniques to reduce
repetitive generation and improve output stability and quality. This enables
the 70M-parameter MARS6 to achieve similar performance to models many times
larger. We show this in objective and subjective evaluations, comparing TTS
output quality and reference speaker cloning ability. Project page:
https://camb-ai.github.io/mars6-turbo/

摘要：基於編解碼器的文字轉語音 (TTS) 模型展現了令人印象深刻的品質，並具備零次學習的語音複製能力。然而，它們在更具表現力的參考或複雜的文字輸入時，常常會遇到困難。我們提出 MARS6，一個強健的編碼器-解碼器轉換器，用於快速、具表現力的 TTS。MARS6 建立在口語語言建模的最新進展之上。利用其解碼器的階層式設定，新的語音代碼以僅 12 Hz 的速率處理，讓長篇文字能有效率地建模，同時保留重建品質。我們結合了幾種最新的訓練和推論技術，以減少重複產生，並提升輸出穩定性和品質。這讓擁有 70M 參數的 MARS6 能夠達成與大上好幾倍的模型相似的效能。我們在客觀和主觀評估中顯示了這一點，比較了 TTS 輸出品質和參考揚聲器複製能力。專案頁面：https://camb-ai.github.io/mars6-turbo/

##### **UV-Attack: Physical-World Adversarial Attacks for Person Detection via Dynamic-NeRF-based UV Mapping**
2501.05783v1 by Yanjie Li, Wenxuan Zhang, Kaisheng Liang, Bin Xiao

In recent research, adversarial attacks on person detectors using patches or
static 3D model-based texture modifications have struggled with low success
rates due to the flexible nature of human movement. Modeling the 3D
deformations caused by various actions has been a major challenge. Fortunately,
advancements in Neural Radiance Fields (NeRF) for dynamic human modeling offer
new possibilities. In this paper, we introduce UV-Attack, a groundbreaking
approach that achieves high success rates even with extensive and unseen human
actions. We address the challenge above by leveraging dynamic-NeRF-based UV
mapping. UV-Attack can generate human images across diverse actions and
viewpoints, and even create novel actions by sampling from the SMPL parameter
space. While dynamic NeRF models are capable of modeling human bodies,
modifying clothing textures is challenging because they are embedded in neural
network parameters. To tackle this, UV-Attack generates UV maps instead of RGB
images and modifies the texture stacks. This approach enables real-time texture
edits and makes the attack more practical. We also propose a novel Expectation
over Pose Transformation loss (EoPT) to improve the evasion success rate on
unseen poses and views. Our experiments show that UV-Attack achieves a 92.75%
attack success rate against the FastRCNN model across varied poses in dynamic
video settings, significantly outperforming the state-of-the-art AdvCamou
attack, which only had a 28.50% ASR. Moreover, we achieve 49.5% ASR on the
latest YOLOv8 detector in black-box settings. This work highlights the
potential of dynamic NeRF-based UV mapping for creating more effective
adversarial attacks on person detectors, addressing key challenges in modeling
human movement and texture modification.

摘要：<paragraph>在最近的研究中，使用貼片或靜態 3D 模型為基礎的紋理修改對人物偵測器的對抗性攻擊，由於人類動作的靈活性而難以獲得高成功率。建模由各種動作造成的 3D 變形一直是一項重大挑戰。幸運的是，神經輻射場 (NeRF) 在動態人類建模方面的進步為我們提供了新的可能性。在本文中，我們介紹了 UV-Attack，這是一種突破性的方法，即使在廣泛且未知的人類動作下也能達到高成功率。我們通過利用基於動態 NeRF 的 UV 對應來解決上述挑戰。UV-Attack 可以生成跨越不同動作和視角的人類影像，甚至可以透過從 SMPL 參數空間中取樣來創造新動作。雖然動態 NeRF 模型能夠建模人體，但修改服裝紋理具有挑戰性，因為它們嵌入在神經網路參數中。為了解決這個問題，UV-Attack 生成了 UV 對應而不是 RGB 影像，並修改了紋理堆疊。這種方法允許即時紋理編輯，並使攻擊更具實用性。我們還提出了一個新的姿勢轉換損失期望 (EoPT)，以提高在未知姿勢和視角上的規避成功率。我們的實驗表明，UV-Attack 在動態視訊設定中針對 FastRCNN 模型達到了 92.75% 的攻擊成功率，顯著優於最先進的 AdvCamou 攻擊，後者的 ASR 僅為 28.50%。此外，我們在黑盒設定中針對最新的 YOLOv8 偵測器達到了 49.5% 的 ASR。這項工作突顯了基於動態 NeRF 的 UV 對應在創造更有效對抗人物偵測器的攻擊方面的潛力，解決了建模人類動作和紋理修改中的關鍵挑戰。</paragraph>

##### **Halal or Not: Knowledge Graph Completion for Predicting Cultural Appropriateness of Daily Products**
2501.05768v1 by Van Thuy Hoang, Tien-Bach-Thanh Do, Jinho Seo, Seung Charlie Kim, Luong Vuong Nguyen, Duong Nguyen Minh Huy, Hyeon-Ju Jeon, O-Joun Lee

The growing demand for halal cosmetic products has exposed significant
challenges, especially in Muslim-majority countries. Recently, various machine
learning-based strategies, e.g., image-based methods, have shown remarkable
success in predicting the halal status of cosmetics. However, these methods
mainly focus on analyzing the discrete and specific ingredients within separate
cosmetics, which ignore the high-order and complex relations between cosmetics
and ingredients. To address this problem, we propose a halal cosmetic
recommendation framework, namely HaCKG, that leverages a knowledge graph of
cosmetics and their ingredients to explicitly model and capture the
relationships between cosmetics and their components. By representing cosmetics
and ingredients as entities within the knowledge graph, HaCKG effectively
learns the high-order and complex relations between entities, offering a robust
method for predicting halal status. Specifically, we first construct a cosmetic
knowledge graph representing the relations between various cosmetics,
ingredients, and their properties. We then propose a pre-trained relational
graph attention network model with residual connections to learn the structural
relation between entities in the knowledge graph. The pre-trained model is then
fine-tuned on downstream cosmetic data to predict halal status. Extensive
experiments on the cosmetic dataset over halal prediction tasks demonstrate the
superiority of our model over state-of-the-art baselines.

摘要：清真化妝品產品需求日益增加，已暴露出重大挑戰，特別是在穆斯林占多數的國家。最近，各種基於機器學習的策略（例如基於影像的方法）已在預測化妝品的清真狀態方面展現顯著的成功。然而，這些方法主要側重於分析單獨化妝品中的離散和特定成分，而忽略了化妝品與成分之間的高階和複雜關係。為了解決這個問題，我們提出了一個清真化妝品推薦架構，即 HaCKG，它利用化妝品及其成分的知識圖譜來明確建模和捕捉化妝品及其組成部分之間的關係。透過將化妝品和成分表示為知識圖譜中的實體，HaCKG 有效地學習了實體之間的高階和複雜關係，提供了一種用於預測清真狀態的強健方法。具體來說，我們首先構建一個化妝品知識圖譜，表示各種化妝品、成分及其屬性之間的關係。然後，我們提出一個預先訓練的關係圖注意力網路模型，並具備殘差連接，以學習知識圖譜中實體之間的結構關係。然後，針對下游化妝品資料微調預先訓練的模型，以預測清真狀態。在化妝品資料集上進行的廣泛實驗，針對清真預測任務證明了我們模型優於最先進的基準。

##### **Migician: Revealing the Magic of Free-Form Multi-Image Grounding in Multimodal Large Language Models**
2501.05767v1 by You Li, Heyu Huang, Chi Chen, Kaiyu Huang, Chao Huang, Zonghao Guo, Zhiyuan Liu, Jinan Xu, Yuhua Li, Ruixuan Li, Maosong Sun

The recent advancement of Multimodal Large Language Models (MLLMs) has
significantly improved their fine-grained perception of single images and
general comprehension across multiple images. However, existing MLLMs still
face challenges in achieving precise grounding in complex multi-image
scenarios. To address this, we first explore a Chain-of-Thought (CoT) framework
that integrates single-image grounding with multi-image comprehension. While
partially effective, it remains unstable and struggles to capture abstract
visual information due to its non-end-to-end nature. Therefore, we introduce
Migician, the first multi-image grounding model capable of performing free-form
and accurate grounding across multiple images. To support this, we present the
MGrounding-630k dataset, which comprises data for several multi-image grounding
tasks derived from existing datasets, along with newly generated free-form
grounding instruction-following data. Furthermore, we propose MIG-Bench, a
comprehensive benchmark specifically designed for evaluating multi-image
grounding capabilities. Experimental results demonstrate that our model
achieves significantly superior multi-image grounding capabilities,
outperforming the best existing MLLMs by 21.61% and even surpassing much larger
70B models. Our code, model, dataset, and benchmark are fully open-sourced.

摘要：多模态大语言模型 (MLLM) 近期取得进展，显著改善了它们对单张图像的细粒度感知和跨多张图像的一般理解。然而，现有的 MLLM 在实现复杂多图像场景中的精确接地时仍面临挑战。为了解决这个问题，我们首先探索了一个思想链 (CoT) 框架，它将单图像接地与多图像理解相集成。尽管部分有效，但它仍然不稳定，并且由于其非端到端特性而难以捕捉抽象视觉信息。因此，我们引入了 Migician，这是第一个能够跨多张图像执行自由形式和准确接地的多图像接地模型。为了支持这一点，我们提出了 MGrounding-630k 数据集，其中包含了从现有数据集中派生的几个多图像接地任务的数据，以及新生成的自由形式接地指令遵循数据。此外，我们提出了 MIG-Bench，这是一个专门设计用于评估多图像接地能力的综合基准。实验结果表明，我们的模型实现了明显优越的多图像接地能力，比现有的最佳 MLLM 提高了 21.61%，甚至超过了更大的 70B 模型。我们的代码、模型、数据集和基准是完全开源的。

##### **Controlling Large Language Models Through Concept Activation Vectors**
2501.05764v1 by Hanyu Zhang, Xiting Wang, Chengao Li, Xiang Ao, Qing He

As large language models (LLMs) are widely deployed across various domains,
the ability to control their generated outputs has become more critical. This
control involves aligning LLMs outputs with human values and ethical principles
or customizing LLMs on specific topics or styles for individual users. Existing
controlled generation methods either require significant computational
resources and extensive trial-and-error or provide coarse-grained control. In
this paper, we propose Generation with Concept Activation Vector (GCAV), a
lightweight model control framework that ensures accurate control without
requiring resource-extensive fine-tuning. Specifically, GCAV first trains a
concept activation vector for specified concepts to be controlled, such as
toxicity. During inference, GCAV steers the concept vector in LLMs, for
example, by removing the toxicity concept vector from the activation layers.
Control experiments from different perspectives, including toxicity reduction,
sentiment control, linguistic style, and topic control, demonstrate that our
framework achieves state-of-the-art performance with granular control, allowing
for fine-grained adjustments of both the steering layers and the steering
magnitudes for individual samples.

摘要：隨著大型語言模型 (LLM) 廣泛部署於各個領域，控制其產出結果的能力變得更加重要。這種控制涉及將 LLM 產出與人類價值觀和道德原則保持一致，或針對特定主題或風格為個別使用者自訂 LLM。現有的受控產生方法需要大量的運算資源和廣泛的試誤，或提供粗略的控制。在本文中，我們提出概念啟用向量生成 (GCAV)，這是一個輕量級模型控制架構，可確保精確控制，無需耗費資源的微調。具體來說，GCAV 首先訓練一個概念啟用向量，用於控制指定概念，例如毒性。在推理過程中，GCAV 引導 LLM 中的概念向量，例如，透過從啟用層中移除毒性概念向量。從不同角度進行的控制實驗，包括毒性降低、情緒控制、語言風格和主題控制，證明我們的架構以精細控制實現了最先進的效能，允許對個別範例的引導層和引導幅度進行細微調整。

##### **Semantic Exploration with Adaptive Gating for Efficient Problem Solving with Language Models**
2501.05752v1 by Sungjae Lee, Hyejin Park, Jaechang Kim, Jungseul Ok

Recent advancements in large language models (LLMs) have shown remarkable
potential in various complex tasks requiring multi-step reasoning methods like
tree search to explore diverse reasoning paths. However, existing methods often
suffer from computational inefficiency and redundancy. First, they overlook the
diversity of task difficulties, leading to unnecessarily extensive searches
even for easy tasks. Second, they neglect the semantics of reasoning paths,
resulting in redundant exploration of semantically identical paths. To address
these limitations, we propose Semantic Exploration with Adaptive Gating (SEAG),
a computationally efficient method. SEAG employs an adaptive gating mechanism
that dynamically decides whether to conduct a tree search, based on the
confidence level of answers from a preceding simple reasoning method.
Furthermore, its tree-based exploration consolidates semantically identical
reasoning steps, reducing redundant explorations while maintaining or even
improving accuracy. Our extensive experiments demonstrate that SEAG
significantly improves accuracy by 4.3% on average while requiring only 31% of
computational costs compared to existing tree search-based methods on complex
reasoning benchmarks including GSM8K and ARC with diverse language models such
as Llama2, Llama3, and Mistral.

摘要：大型語言模型 (LLM) 的最新進展在各種複雜任務中展現出顯著的潛力，這些任務需要像樹狀搜尋等多步驟推理方法來探索不同的推理路徑。然而，現有方法經常會遇到運算效率低和冗餘的問題。首先，它們忽略了任務難度的差異性，導致即使對於簡單的任務也會進行不必要的廣泛搜尋。其次，它們忽略了推理路徑的語義，導致對語義相同的路徑進行重複探索。為了解決這些限制，我們提出語義探索與自適應閘控 (SEAG)，這是一種運算效率高的方法。SEAG 採用自適應閘控機制，根據前一個簡單推理方法的答案信心等級，動態決定是否進行樹狀搜尋。此外，它的基於樹的探索整合了語義相同的推理步驟，減少了重複探索，同時維持或甚至提高了準確性。我們的廣泛實驗表明，在複雜的推理基準上，包括 GSM8K 和 ARC，SEAG 使用 Llama2、Llama3 和 Mistral 等多種語言模型，平均準確度提高了 4.3%，同時僅需現有基於樹狀搜尋的方法 31% 的運算成本。

##### **Bridging Dialects: Translating Standard Bangla to Regional Variants Using Neural Models**
2501.05749v1 by Md. Arafat Alam Khandaker, Ziyan Shirin Raha, Bidyarthi Paul, Tashreef Muhammad

The Bangla language includes many regional dialects, adding to its cultural
richness. The translation of Bangla Language into regional dialects presents a
challenge due to significant variations in vocabulary, pronunciation, and
sentence structure across regions like Chittagong, Sylhet, Barishal, Noakhali,
and Mymensingh. These dialects, though vital to local identities, lack of
representation in technological applications. This study addresses this gap by
translating standard Bangla into these dialects using neural machine
translation (NMT) models, including BanglaT5, mT5, and mBART50. The work is
motivated by the need to preserve linguistic diversity and improve
communication among dialect speakers. The models were fine-tuned using the
"Vashantor" dataset, containing 32,500 sentences across various dialects, and
evaluated through Character Error Rate (CER) and Word Error Rate (WER) metrics.
BanglaT5 demonstrated superior performance with a CER of 12.3% and WER of
15.7%, highlighting its effectiveness in capturing dialectal nuances. The
outcomes of this research contribute to the development of inclusive language
technologies that support regional dialects and promote linguistic diversity.

摘要：孟加拉語包含許多地區方言，增加了其文化豐富度。由於吉大港、錫爾赫特、巴里薩爾、諾阿卡利和邁門辛等地區的詞彙、發音和句子結構存在顯著差異，因此將孟加拉語翻譯成地區方言是一個挑戰。儘管這些方言對當地認同至關重要，但在技術應用中卻缺乏代表性。本研究通過使用神經機器翻譯 (NMT) 模型（包括 BanglaT5、mT5 和 mBART50）將標準孟加拉語翻譯成這些方言，從而解決了這一差距。這項工作的動機是需要保留語言多樣性和改善方言使用者之間的溝通。使用包含各種方言的 32,500 個句子的「Vashantor」數據集對模型進行微調，並通過字元錯誤率 (CER) 和詞彙錯誤率 (WER) 指標進行評估。BanglaT5 表現出優異的性能，CER 為 12.3%，WER 為 15.7%，突顯了其在捕捉方言細微差別方面的有效性。本研究的成果有助於開發支持地區方言和促進語言多樣性的包容性語言技術。

##### **Element-wise Attention Is All You Need**
2501.05730v1 by Guoxin Feng

The self-attention (SA) mechanism has demonstrated superior performance
across various domains, yet it suffers from substantial complexity during both
training and inference. The next-generation architecture, aiming at retaining
the competitive performance of SA while achieving low-cost inference and
efficient long-sequence training, primarily focuses on three approaches: linear
attention, linear RNNs, and state space models. Although these approaches
achieve reduced complexity than SA, they all have built-in performance
degradation factors, such as diminished “spikiness” and compression of
historical information. In contrast to these approaches, we propose a novel
element-wise attention mechanism, which uses the element-wise squared Euclidean
distance, instead of the dot product operation, to compute similarity and
approximates the quadratic complexity term $\exp(q_{ic}k_{jc})$ with a Taylor
polynomial. This design achieves remarkable efficiency: during training, the
element-wise attention has a complexity of $\mathcal{O}(tLD)$, making
long-sequence training both computationally and memory efficient, where $L$ is
the sequence length, $D$ is the feature dimension, and $t$ is the highest order
of the polynomial; during inference, it can be reformulated as recurrent neural
networks, achieving a inference complexity of $\mathcal{O}(tD)$. Furthermore,
the element-wise attention circumvents the performance degradation factors
present in these approaches and achieves performance comparable to SA in both
causal and non-causal forms.

摘要：自注意力 (SA) 機制在各個領域都展現出卓越的效能，然而在訓練和推論期間都飽受複雜性的困擾。新一代架構旨在保留 SA 的競爭效能，同時實現低成本推論和高效長序列訓練，主要專注於三種方法：線性注意力、線性遞迴神經網路和狀態空間模型。儘管這些方法達到了比 SA 更低的複雜性，但它們都有內建的效能降低因素，例如降低的「尖峰性」和歷史資訊的壓縮。與這些方法相反，我們提出了一種新穎的逐元素注意力機制，它使用逐元素平方歐幾里得距離（而非點積運算）來計算相似度，並使用泰勒多項式逼近二次複雜度項 $\exp(q_{ic}k_{jc})$。此設計達到了顯著的效率：在訓練期間，逐元素注意力具有 $\mathcal{O}(tLD)$ 的複雜度，使得長序列訓練在計算和記憶體方面都更有效率，其中 $L$ 是序列長度，$D$ 是特徵維度，而 $t$ 是多項式的最高階次；在推論期間，它可以被重新表述為遞迴神經網路，達到 $\mathcal{O}(tD)$ 的推論複雜度。此外，逐元素注意力迴避了這些方法中存在的效能降低因素，並在因果和非因果形式中都達到了與 SA 相當的效能。

##### **Enabling Scalable Oversight via Self-Evolving Critic**
2501.05727v1 by Zhengyang Tang, Ziniu Li, Zhenyang Xiao, Tian Ding, Ruoyu Sun, Benyou Wang, Dayiheng Liu, Fei Huang, Tianyu Liu, Bowen Yu, Junyang Lin

Despite their remarkable performance, the development of Large Language
Models (LLMs) faces a critical challenge in scalable oversight: providing
effective feedback for tasks where human evaluation is difficult or where LLMs
outperform humans. While there is growing interest in using LLMs for critique,
current approaches still rely on human annotations or more powerful models,
leaving the issue of enhancing critique capabilities without external
supervision unresolved. We introduce SCRIT (Self-evolving CRITic), a framework
that enables genuine self-evolution of critique abilities. Technically, SCRIT
self-improves by training on synthetic data, generated by a contrastive-based
self-critic that uses reference solutions for step-by-step critique, and a
self-validation mechanism that ensures critique quality through correction
outcomes. Implemented with Qwen2.5-72B-Instruct, one of the most powerful LLMs,
SCRIT achieves up to a 10.3\% improvement on critique-correction and error
identification benchmarks. Our analysis reveals that SCRIT's performance scales
positively with data and model size, outperforms alternative approaches, and
benefits critically from its self-validation component.

摘要：儘管大型語言模型 (LLM) 表現非凡，但其開發在可擴充監督方面面臨嚴峻挑戰：提供有效回饋以執行人類評估困難或 LLM 優於人類的任務。儘管使用 LLM 進行批判越來越受到關注，但目前的做法仍依賴於人工標註或更強大的模型，因此未能解決在沒有外部監督的情況下提升批判能力的問題。我們推出 SCRIT (自我演化的 CRITic)，這是一個框架，可實現批判能力的真正自我演化。在技術上，SCRIT 透過訓練合成數據來自我提升，這些數據是由對比式自我批判者生成的，該批判者使用參考解答進行逐步批判，以及透過修正結果確保批判品質的自我驗證機制。SCRIT 使用最強大的 LLM 之一 Qwen2.5-72B-Instruct 實作，在批判修正和錯誤辨識基準上取得高達 10.3% 的進步。我們的分析顯示，SCRIT 的效能與資料和模型大小成正比，優於其他方法，並從其自我驗證元件中獲得重大效益。

##### **Zero-shot Shark Tracking and Biometrics from Aerial Imagery**
2501.05717v1 by Chinmay K Lalgudi, Mark E Leone, Jaden V Clark, Sergio Madrigal-Mora, Mario Espinoza

The recent widespread adoption of drones for studying marine animals provides
opportunities for deriving biological information from aerial imagery. The
large scale of imagery data acquired from drones is well suited for machine
learning (ML) analysis. Development of ML models for analyzing marine animal
aerial imagery has followed the classical paradigm of training, testing, and
deploying a new model for each dataset, requiring significant time, human
effort, and ML expertise. We introduce Frame Level ALIgment and tRacking
(FLAIR), which leverages the video understanding of Segment Anything Model 2
(SAM2) and the vision-language capabilities of Contrastive Language-Image
Pre-training (CLIP). FLAIR takes a drone video as input and outputs
segmentation masks of the species of interest across the video. Notably, FLAIR
leverages a zero-shot approach, eliminating the need for labeled data, training
a new model, or fine-tuning an existing model to generalize to other species.
With a dataset of 18,000 drone images of Pacific nurse sharks, we trained
state-of-the-art object detection models to compare against FLAIR. We show that
FLAIR massively outperforms these object detectors and performs competitively
against two human-in-the-loop methods for prompting SAM2, achieving a Dice
score of 0.81. FLAIR readily generalizes to other shark species without
additional human effort and can be combined with novel heuristics to
automatically extract relevant information including length and tailbeat
frequency. FLAIR has significant potential to accelerate aerial imagery
analysis workflows, requiring markedly less human effort and expertise than
traditional machine learning workflows, while achieving superior accuracy. By
reducing the effort required for aerial imagery analysis, FLAIR allows
scientists to spend more time interpreting results and deriving insights about
marine ecosystems.

摘要：無人機廣泛用於研究海洋動物，提供了從航拍影像中獲取生物資訊的機會。從無人機取得的大規模影像資料非常適合進行機器學習 (ML) 分析。開發用於分析海洋動物航拍影像的 ML 模型遵循訓練、測試和部署新模型的傳統範例，需要大量時間、人力和 ML 專業知識。我們引入了 Frame Level ALIgment and tRacking (FLAIR)，它利用了 Segment Anything Model 2 (SAM2) 的視訊理解和對比語言影像預訓練 (CLIP) 的視覺語言功能。FLAIR 以無人機視訊為輸入，並輸出視訊中感興趣物種的分割遮罩。值得注意的是，FLAIR 利用零次學習方法，消除了對標籤資料、訓練新模型或微調現有模型以推廣到其他物種的需求。使用包含 18,000 張太平洋護士鯊無人機影像的資料集，我們訓練了最先進的物件偵測模型，以與 FLAIR 進行比較。我們表明 FLAIR 大幅優於這些物件偵測器，並針對兩種提示 SAM2 的人機互動方法進行競爭，達到 0.81 的 Dice 分數。FLAIR 可以輕鬆推廣到其他鯊魚物種，而無需額外的人力，並且可以與新穎的啟發式方法相結合，以自動提取相關資訊，包括長度和尾鰭拍動頻率。FLAIR 具有顯著的潛力，可以加速航拍影像分析工作流程，與傳統機器學習工作流程相比，所需的人力和專業知識明顯減少，同時還能實現更高的準確度。透過減少航拍影像分析所需的工作，FLAIR 讓科學家可以花更多時間詮釋結果並從海洋生態系統中獲取見解。

##### **How to Enable Effective Cooperation Between Humans and NLP Models: A Survey of Principles, Formalizations, and Beyond**
2501.05714v1 by Chen Huang, Yang Deng, Wenqiang Lei, Jiancheng Lv, Tat-Seng Chua, Jimmy Xiangji Huang

With the advancement of large language models (LLMs), intelligent models have
evolved from mere tools to autonomous agents with their own goals and
strategies for cooperating with humans. This evolution has birthed a novel
paradigm in NLP, i.e., human-model cooperation, that has yielded remarkable
progress in numerous NLP tasks in recent years. In this paper, we take the
first step to present a thorough review of human-model cooperation, exploring
its principles, formalizations, and open challenges. In particular, we
introduce a new taxonomy that provides a unified perspective to summarize
existing approaches. Also, we discuss potential frontier areas and their
corresponding challenges. We regard our work as an entry point, paving the way
for more breakthrough research in this regard.

摘要：隨著大型語言模型 (LLM) 的進步，智慧型模型已從單純的工具演變為具有自身目標和策略，能與人類合作的自主代理人。這項演進在自然語言處理 (NLP) 領域催生了一種新典範，即人機合作，近年來在許多自然語言處理任務中取得顯著進展。在本文中，我們踏出第一步，全面回顧人機合作，探討其原則、形式化和開放性挑戰。特別是，我們引入了一種新的分類法，提供了一個統一的觀點來總結現有方法。此外，我們討論了潛在的前沿領域及其相應的挑戰。我們認為我們的研究是一個切入點，為這方面的更多突破性研究鋪路。

##### **Multi-Step Reasoning in Korean and the Emergent Mirage**
2501.05712v1 by Guijin Son, Hyunwoo Ko, Dasol Choi

We introduce HRMCR (HAE-RAE Multi-Step Commonsense Reasoning), a benchmark
designed to evaluate large language models' ability to perform multi-step
reasoning in culturally specific contexts, focusing on Korean. The questions
are automatically generated via templates and algorithms, requiring LLMs to
integrate Korean cultural knowledge into sequential reasoning steps. Consistent
with prior observations on emergent abilities, our experiments reveal that
models trained on fewer than \(2 \cdot 10^{25}\) training FLOPs struggle to
solve any questions, showing near-zero performance. Beyond this threshold,
performance improves sharply. State-of-the-art models (e.g., O1) still score
under 50\%, underscoring the difficulty of our tasks. Notably, stepwise
analysis suggests the observed emergent behavior may stem from compounding
errors across multiple steps rather than reflecting a genuinely new capability.
We publicly release the benchmark and commit to regularly updating the dataset
to prevent contamination.

摘要：我們推出 HRMCR（HAE-RAE 多步驟常識推理），這是一項基準，用於評估大型語言模型在特定文化背景下執行多步驟推理的能力，重點關注韓語。這些問題是透過範本和演算法自動產生的，要求大型語言模型將韓語文化知識整合到循序推理步驟中。與之前對新興能力的觀察一致，我們的實驗顯示，訓練資料少於 \(2 \cdot 10^{25}\) 訓練 FLOP 的模型難以解決任何問題，表現接近於零。超過這個閾值後，效能大幅提升。最先進的模型（例如 O1）仍低於 50%，凸顯了我們任務的難度。值得注意的是，逐步分析表明觀察到的新興行為可能源於多個步驟中的複合錯誤，而不是反映真正的新能力。我們公開發布基準，並承諾定期更新資料集以防止污染。

##### **Multiagent Finetuning: Self Improvement with Diverse Reasoning Chains**
2501.05707v1 by Vighnesh Subramaniam, Yilun Du, Joshua B. Tenenbaum, Antonio Torralba, Shuang Li, Igor Mordatch

Large language models (LLMs) have achieved remarkable performance in recent
years but are fundamentally limited by the underlying training data. To improve
models beyond the training data, recent works have explored how LLMs can be
used to generate synthetic data for autonomous self-improvement. However,
successive steps of self-improvement can reach a point of diminishing returns.
In this work, we propose a complementary approach towards self-improvement
where finetuning is applied to a multiagent society of language models. A group
of language models, all starting from the same base model, are independently
specialized by updating each one using data generated through multiagent
interactions among the models. By training each model on independent sets of
data, we illustrate how this approach enables specialization across models and
diversification over the set of models. As a result, our overall system is able
to preserve diverse reasoning chains and autonomously improve over many more
rounds of fine-tuning than single-agent self-improvement methods. We
quantitatively illustrate the efficacy of the approach across a wide suite of
reasoning tasks.

摘要：大型語言模型 (LLM) 近年來取得了顯著的表現，但其根本上受到基礎訓練資料的限制。為了改進訓練資料之外的模型，最近的研究探討了 LLM 如何用於生成合成資料以進行自主自我改善。然而，連續的自我改善步驟可能會達到報酬遞減的程度。在這項工作中，我們提出了一個互補的自改善方法，其中微調應用於語言模型的多主體社會。一群語言模型，全部從同一個基礎模型開始，透過使用模型之間的多主體互動所產生的資料來更新每個模型，獨立地進行專門化。透過訓練每個模型使用獨立的資料集，我們說明了這種方法如何讓模型之間能夠進行專門化，以及模型集合的多樣化。因此，我們的整體系統能夠保留不同的推理鏈，並在比單一主體自我改善方法更多的微調回合中自主改善。我們透過廣泛的推理任務量化說明了這種方法的效能。

##### **Linguistic Entity Masking to Improve Cross-Lingual Representation of Multilingual Language Models for Low-Resource Languages**
2501.05700v1 by Aloka Fernando, Surangika Ranathunga

Multilingual Pre-trained Language models (multiPLMs), trained on the Masked
Language Modelling (MLM) objective are commonly being used for cross-lingual
tasks such as bitext mining. However, the performance of these models is still
suboptimal for low-resource languages (LRLs). To improve the language
representation of a given multiPLM, it is possible to further pre-train it.
This is known as continual pre-training. Previous research has shown that
continual pre-training with MLM and subsequently with Translation Language
Modelling (TLM) improves the cross-lingual representation of multiPLMs.
However, during masking, both MLM and TLM give equal weight to all tokens in
the input sequence, irrespective of the linguistic properties of the tokens. In
this paper, we introduce a novel masking strategy, Linguistic Entity Masking
(LEM) to be used in the continual pre-training step to further improve the
cross-lingual representations of existing multiPLMs. In contrast to MLM and
TLM, LEM limits masking to the linguistic entity types nouns, verbs and named
entities, which hold a higher prominence in a sentence. Secondly, we limit
masking to a single token within the linguistic entity span thus keeping more
context, whereas, in MLM and TLM, tokens are masked randomly. We evaluate the
effectiveness of LEM using three downstream tasks, namely bitext mining,
parallel data curation and code-mixed sentiment analysis using three
low-resource language pairs English-Sinhala, English-Tamil, and Sinhala-Tamil.
Experiment results show that continually pre-training a multiPLM with LEM
outperforms a multiPLM continually pre-trained with MLM+TLM for all three
tasks.

摘要：多語言預訓練語言模型 (multiPLM) 在遮罩語言模型 (MLM) 目標上進行訓練，通常用於跨語言任務，例如雙語文本挖掘。然而，這些模型的效能對於低資源語言 (LRL) 來說仍然次佳。若要改善給定 multiPLM 的語言表徵，可以進一步對其進行預訓練。這稱為持續預訓練。先前的研究顯示，使用 MLM 進行持續預訓練，然後使用翻譯語言模型 (TLM) 進行持續預訓練，可以改善 multiPLM 的跨語言表徵。然而，在遮罩期間，MLM 和 TLM 都會給予輸入序列中的所有符號相等的權重，而不考慮符號的語言特性。在本文中，我們引入了新的遮罩策略，語言實體遮罩 (LEM)，用於持續預訓練步驟，以進一步改善現有 multiPLM 的跨語言表徵。與 MLM 和 TLM 相比，LEM 將遮罩限制在語言實體類型名詞、動詞和命名實體，這些類型在句子中具有較高的重要性。其次，我們將遮罩限制在語言實體範圍內的單一符號，從而保留更多內容，而在 MLM 和 TLM 中，符號會隨機遮罩。我們使用三個下游任務評估 LEM 的效能，即雙語文本挖掘、平行資料整理和使用三對低資源語言英語-僧伽羅語、英語-泰米爾語和僧伽羅語-泰米爾語進行的代碼混合情緒分析。實驗結果顯示，使用 LEM 持續預訓練 multiPLM 在所有三個任務中的表現都優於使用 MLM+TLM 持續預訓練的 multiPLM。

##### **Overcoming Language Priors for Visual Question Answering Based on Knowledge Distillation**
2501.05690v1 by Daowan Peng, Wei Wei

Previous studies have pointed out that visual question answering (VQA) models
are prone to relying on language priors for answer predictions. In this
context, predictions often depend on linguistic shortcuts rather than a
comprehensive grasp of multimodal knowledge, which diminishes their
generalization ability. In this paper, we propose a novel method, namely, KDAR,
leveraging knowledge distillation to address the prior-dependency dilemmas
within the VQA task. Specifically, the regularization effect facilitated by
soft labels from a well-trained teacher is employed to penalize overfitting to
the most common answers. The soft labels, which serve a regularization role,
also provide semantic guidance that narrows the range of candidate answers.
Additionally, we design an adaptive sample-wise reweighting learning strategy
to further mitigate bias by dynamically adjusting the importance of each
sample. Experimental results demonstrate that our method enhances performance
in both OOD and IID settings. Our method achieves state-of-the-art performance
on the VQA-CPv2 out-of-distribution (OOD) benchmark, significantly
outperforming previous state-of-the-art approaches.

摘要：先前的研究指出，視覺問答 (VQA) 模型容易依賴語言先驗來預測答案。在此背景下，預測通常依賴於語言捷徑，而不是對多模態知識的全面掌握，這降低了它們的泛化能力。在本文中，我們提出了一種新方法，即 KDAR，利用知識蒸餾來解決 VQA 任務中的先驗依賴困境。具體來說，利用訓練有素的教師提供的軟標籤所促進的正則化效應來懲罰對最常見答案的過度擬合。充當正則化角色的軟標籤還提供了語義指導，縮小了候選答案的範圍。此外，我們設計了一種自適應的逐樣本重新加權學習策略，通過動態調整每個樣本的重要性來進一步減輕偏差。實驗結果表明，我們的模型在 OOD 和 IID 設置中都增強了性能。我們的模型在 VQA-CPv2 異構分佈 (OOD) 基準上實現了最先進的性能，顯著優於先前的最先進方法。

##### **EXION: Exploiting Inter- and Intra-Iteration Output Sparsity for Diffusion Models**
2501.05680v1 by Jaehoon Heo, Adiwena Putra, Jieon Yoon, Sungwoong Yune, Hangyeol Lee, Ji-Hoon Kim, Joo-Young Kim

Over the past few years, diffusion models have emerged as novel AI solutions,
generating diverse multi-modal outputs from text prompts. Despite their
capabilities, they face challenges in computing, such as excessive latency and
energy consumption due to their iterative architecture. Although prior works
specialized in transformer acceleration can be applied, the iterative nature of
diffusion models remains unresolved. In this paper, we present EXION, the first
SW-HW co-designed diffusion accelerator that solves the computation challenges
by exploiting the unique inter- and intra-iteration output sparsity in
diffusion models. To this end, we propose two SW-level optimizations. First, we
introduce the FFN-Reuse algorithm that identifies and skips redundant
computations in FFN layers across different iterations (inter-iteration
sparsity). Second, we use a modified eager prediction method that employs
two-step leading-one detection to accurately predict the attention score,
skipping unnecessary computations within an iteration (intra-iteration
sparsity). We also introduce a novel data compaction mechanism named ConMerge,
which can enhance HW utilization by condensing and merging sparse matrices into
compact forms. Finally, it has a dedicated HW architecture that supports the
above sparsity-inducing algorithms, translating high output sparsity into
improved energy efficiency and performance. To verify the feasibility of the
EXION, we first demonstrate that it has no impact on accuracy in various types
of multi-modal diffusion models. We then instantiate EXION in both server- and
edge-level settings and compare its performance against GPUs with similar
specifications. Our evaluation shows that EXION achieves dramatic improvements
in performance and energy efficiency by 3.2-379.3x and 45.1-3067.6x compared to
a server GPU and by 42.6-1090.9x and 196.9-4668.2x compared to an edge GPU.

摘要：在過去幾年，擴散模型已成為新穎的人工智慧解決方案，從文字提示中產生多樣化的多模態輸出。儘管有這些功能，但由於其反覆運算架構，它們在運算上仍面臨挑戰，例如過長的延遲和能源消耗。儘管可以應用先前專精於Transformer加速的工作，但擴散模型的反覆運算性質仍未解決。在本文中，我們提出 EXION，這是第一個 SW-HW 共同設計的擴散加速器，它透過利用擴散模型中獨特的迭代間和迭代內輸出稀疏性來解決運算挑戰。為此，我們提出兩種 SW 層級最佳化。首先，我們引入 FFN-Reuse 演算法，它識別並略過不同迭代中 FFN 層中的重複運算（迭代間稀疏性）。其次，我們使用一種修改的熱切預測方法，它採用兩步領先一偵測來準確預測注意力分數，略過迭代中不必要的運算（迭代內稀疏性）。我們還引入一種名為 ConMerge 的新穎資料壓縮機制，它可以透過將稀疏矩陣壓縮並合併成緊湊形式來提高 HW 利用率。最後，它有一個專用的 HW 架構，支援上述稀疏性誘導演算法，將高輸出稀疏性轉化為更高的能源效率和效能。為了驗證 EXION 的可行性，我們首先證明它對各種類型多模態擴散模型的準確性沒有影響。然後，我們在伺服器和邊緣層級設定中實例化 EXION，並將其效能與具有類似規格的 GPU 進行比較。我們的評估顯示，與伺服器 GPU 相比，EXION 在效能和能源效率方面取得顯著進步，分別提高了 3.2-379.3 倍和 45.1-3067.6 倍；與邊緣 GPU 相比，則分別提高了 42.6-1090.9 倍和 196.9-4668.2 倍。

##### **Facilitate Collaboration between Large Language Model and Task-specific Model for Time Series Anomaly Detection**
2501.05675v1 by Feiyi Chen, Leilei Zhang, Guansong Pang, Roger Zimmermann, Shuiguang Deng

In anomaly detection, methods based on large language models (LLMs) can
incorporate expert knowledge, while task-specific smaller models excel at
extracting normal patterns and detecting value fluctuations. Inspired by the
human nervous system, where the brain stores expert knowledge and the
peripheral nervous system and spinal cord handle specific tasks like withdrawal
and knee-jerk reflexes, we propose CoLLaTe, a framework designed to facilitate
collaboration between LLMs and task-specific models, leveraging the strengths
of both.
  In this work, we first formulate the collaboration process and identify two
key challenges in the collaboration between LLMs and task-specific models: (1)
the misalignment between the expression domains of LLMs and smaller models, and
(2) error accumulation arising from the predictions of both models.
  To address these challenges, we introduce two key components in CoLLaTe: the
alignment module and the collaborative loss function. Through theoretical
analysis and experimental validation, we demonstrate that these components
effectively mitigate the identified challenges and achieve better performance
than LLM based methods and task-specific smaller model.

摘要：在異常偵測中，基於大型語言模型 (LLM) 的方法可納入專家知識，而特定於任務的較小模型則擅長提取正常模式和偵測價值波動。受人類神經系統的啟發，其中大腦儲存專家知識，而周邊神經系統和脊髓處理特定任務，例如撤回和膝跳反射，我們提出 CoLLaTe，一個旨在促進 LLM 和特定於任務的模型之間協作的框架，利用兩者的優勢。
在這項工作中，我們首先制定協作流程，並找出 LLM 和特定於任務的模型之間協作中的兩個主要挑戰：(1) LLM 和較小模型的表達領域之間的不一致，以及 (2) 來自兩個模型預測的誤差累積。
為了應對這些挑戰，我們在 CoLLaTe 中引入了兩個關鍵組成部分：對齊模組和協作損失函數。透過理論分析和實驗驗證，我們證明這些組成部分有效地減輕了已識別的挑戰，並比基於 LLM 的方法和特定於任務的較小模型獲得更好的效能。

##### **Network Diffuser for Placing-Scheduling Service Function Chains with Inverse Demonstration**
2501.05673v1 by Zuyuan Zhang, Vaneet Aggarwal, Tian Lan

Network services are increasingly managed by considering chained-up virtual
network functions and relevant traffic flows, known as the Service Function
Chains (SFCs). To deal with sequential arrivals of SFCs in an online fashion,
we must consider two closely-coupled problems - an SFC placement problem that
maps SFCs to servers/links in the network and an SFC scheduling problem that
determines when each SFC is executed. Solving the whole SFC problem targeting
these two optimizations jointly is extremely challenging. In this paper, we
propose a novel network diffuser using conditional generative modeling for this
SFC placing-scheduling optimization. Recent advances in generative AI and
diffusion models have made it possible to generate high-quality images/videos
and decision trajectories from language description. We formulate the SFC
optimization as a problem of generating a state sequence for planning and
perform graph diffusion on the state trajectories to enable extraction of SFC
decisions, with SFC optimization constraints and objectives as conditions. To
address the lack of demonstration data due to NP-hardness and exponential
problem space of the SFC optimization, we also propose a novel and somewhat
maverick approach -- Rather than solving instances of this difficult
optimization, we start with randomly-generated solutions as input, and then
determine appropriate SFC optimization problems that render these solutions
feasible. This inverse demonstration enables us to obtain sufficient expert
demonstrations, i.e., problem-solution pairs, through further optimization. In
our numerical evaluations, the proposed network diffuser outperforms learning
and heuristic baselines, by $\sim$20\% improvement in SFC reward and $\sim$50\%
reduction in SFC waiting time and blocking rate.

摘要：網路服務越來越透過考慮串連的虛擬網路功能和相關流量進行管理，稱為服務功能鏈 (SFC)。為了以線上方式處理 SFC 的順序到達，我們必須考慮兩個緊密結合的問題：將 SFC 對應到網路中的伺服器/連結的 SFC 配置問題，以及決定每個 SFC 何時執行的 SFC 排程問題。同時針對這兩個最佳化來解決整個 SFC 問題極具挑戰性。在本文中，我們提出一個使用條件生成模型的創新網路擴散器，用於此 SFC 配置排程最佳化。生成式 AI 和擴散模型的最新進展使得從語言描述中產生高品質的影像/影片和決策軌跡成為可能。我們將 SFC 最佳化制定為產生一個狀態序列的問題，用於規劃，並對狀態軌跡執行圖形擴散，以提取 SFC 決策，並以 SFC 最佳化約束和目標作為條件。為了解決由於 NP 難度和 SFC 最佳化的指數問題空間而導致的示範資料不足，我們也提出一個創新且有點特立獨行的做法：不是解決這個困難最佳化的實例，而是從隨機產生的解作為輸入開始，然後決定適當的 SFC 最佳化問題，讓這些解可行。這個逆向示範讓我們能夠透過進一步最佳化，獲得足夠的專家示範，也就是問題解決配對。在我們的數值評估中，所提出的網路擴散器優於學習和啟發式基準，SFC 獎勵提升了約 20%，SFC 等待時間和封鎖率降低了約 50%。

##### **TransPlace: Transferable Circuit Global Placement via Graph Neural Network**
2501.05667v1 by Yunbo Hou, Haoran Ye, Yingxue Zhang, Siyuan Xu, Guojie Song

Global placement, a critical step in designing the physical layout of
computer chips, is essential to optimize chip performance. Prior global
placement methods optimize each circuit design individually from scratch. Their
neglect of transferable knowledge limits solution efficiency and chip
performance as circuit complexity drastically increases. This study presents
TransPlace, a global placement framework that learns to place millions of
mixed-size cells in continuous space. TransPlace introduces i) Netlist Graph to
efficiently model netlist topology, ii) Cell-flow and relative position
encoding to learn SE(2)-invariant representation, iii) a tailored graph neural
network architecture for informed parameterization of placement knowledge, and
iv) a two-stage strategy for coarse-to-fine placement. Compared to
state-of-the-art placement methods, TransPlace-trained on a few high-quality
placements-can place unseen circuits with 1.2x speedup while reducing
congestion by 30%, timing by 9%, and wirelength by 5%.

摘要：全球佈局是設計電腦晶片實體配置的關鍵步驟，對最佳化晶片效能至關重要。先前的全球佈局方法會從頭開始個別最佳化每個電路設計。隨著電路複雜性大幅增加，這些方法忽略可轉移知識，限制了解決方案效率和晶片效能。本研究提出 TransPlace，一個全球佈局架構，學習將數百萬個混合大小的單元放置在連續空間中。TransPlace 導入 i) 網表圖，以有效率的方式建立網表拓撲，ii) 單元流程和相對位置編碼，以學習 SE(2) 不變表示，iii) 一個客製化圖形神經網路架構，用於佈局知識的明智參數化，以及 iv) 一個用於粗略到精細佈局的兩階段策略。與現有最先進的佈局方法相比，在少數幾個高品質佈局上訓練的 TransPlace，可以將未見過的電路放置速度提升 1.2 倍，同時將擁塞減少 30%、時序減少 9%，以及線長減少 5%。

##### **Learning to Measure Quantum Neural Networks**
2501.05663v1 by Samuel Yen-Chi Chen, Huan-Hsin Tseng, Hsin-Yi Lin, Shinjae Yoo

The rapid progress in quantum computing (QC) and machine learning (ML) has
attracted growing attention, prompting extensive research into quantum machine
learning (QML) algorithms to solve diverse and complex problems. Designing
high-performance QML models demands expert-level proficiency, which remains a
significant obstacle to the broader adoption of QML. A few major hurdles
include crafting effective data encoding techniques and parameterized quantum
circuits, both of which are crucial to the performance of QML models.
Additionally, the measurement phase is frequently overlooked-most current QML
models rely on pre-defined measurement protocols that often fail to account for
the specific problem being addressed. We introduce a novel approach that makes
the observable of the quantum system-specifically, the Hermitian
matrix-learnable. Our method features an end-to-end differentiable learning
framework, where the parameterized observable is trained alongside the ordinary
quantum circuit parameters simultaneously. Using numerical simulations, we show
that the proposed method can identify observables for variational quantum
circuits that lead to improved outcomes, such as higher classification
accuracy, thereby boosting the overall performance of QML models.

摘要：量子運算 (QC) 和機器學習 (ML) 的快速進展已引起越來越多的關注，促使人們廣泛研究量子機器學習 (QML) 演算法，以解決多樣且複雜的問題。設計高性能 QML 模型需要專家級的熟練度，這仍然是 QML 更廣泛採用的重大障礙。一些主要的障礙包括製作有效的資料編碼技術和參數化量子電路，這兩者對於 QML 模型的性能至關重要。此外，測量階段經常被忽視 - 大多數當前的 QML 模型依賴於預先定義的測量協定，這些協定通常無法解決具體問題。我們引入了一種新穎的方法，它使量子系統的可觀察性（特別是 Hermitian 矩陣）可學習。我們的模型特點是一個端到端可微分學習框架，其中參數化可觀察性與常規量子電路參數同時訓練。使用數值模擬，我們表明所提出的方法可以識別變分量子電路的可觀察性，從而導致改進的結果，例如更高的分類準確度，從而提高 QML 模型的整體性能。

##### **Cascaded Self-Evaluation Augmented Training for Efficient Multimodal Large Language Models**
2501.05662v1 by Zheqi Lv, Wenkai Wang, Jiawei Wang, Shengyu Zhang, Fei Wu

Efficient Multimodal Large Language Models (EMLLMs) have rapidly advanced
recently. Incorporating Chain-of-Thought (CoT) reasoning and step-by-step
self-evaluation has improved their performance. However, limited parameters
often hinder EMLLMs from effectively using self-evaluation during inference.
Key challenges include synthesizing evaluation data, determining its quantity,
optimizing training and inference strategies, and selecting appropriate
prompts.
  To address these issues, we introduce Self-Evaluation Augmented Training
(SEAT). SEAT uses more powerful EMLLMs for CoT reasoning, data selection, and
evaluation generation, then trains EMLLMs with the synthesized data. However,
handling long prompts and maintaining CoT reasoning quality are problematic.
Therefore, we propose Cascaded Self-Evaluation Augmented Training (Cas-SEAT),
which breaks down lengthy prompts into shorter, task-specific cascaded prompts
and reduces costs for resource-limited settings. During data synthesis, we
employ open-source 7B-parameter EMLLMs and annotate a small dataset with short
prompts.
  Experiments demonstrate that Cas-SEAT significantly boosts EMLLMs'
self-evaluation abilities, improving performance by 19.68%, 55.57%, and 46.79%
on the MathVista, Math-V, and We-Math datasets, respectively. Additionally, our
Cas-SEAT Dataset serves as a valuable resource for future research in enhancing
EMLLM self-evaluation.

摘要：<paragraph>高效多模态大型语言模型 (EMLLM) 近期快速发展。纳入思维链 (CoT) 推理和逐步自我评估已改善其性能。然而，有限的参数通常会阻碍 EMLLM 在推理过程中有效地使用自我评估。主要挑战包括综合评估数据、确定其数量、优化训练和推理策略以及选择适当的提示。
为了解决这些问题，我们引入了自我评估增强训练 (SEAT)。SEAT 使用更强大的 EMLLM 进行 CoT 推理、数据选择和评估生成，然后使用综合数据训练 EMLLM。然而，处理长提示和维持 CoT 推理质量是有问题的。因此，我们提出了级联自我评估增强训练 (Cas-SEAT)，它将冗长的提示分解为更短、特定于任务的级联提示，并降低了对资源有限的设置的成本。在数据综合期间，我们采用开源 7B 参数 EMLLM，并使用短提示注释一个小数据集。
实验表明，Cas-SEAT 显着提高了 EMLLM 的自我评估能力，分别在 MathVista、Math-V 和 We-Math 数据集上将性能提高了 19.68%、55.57% 和 46.79%。此外，我们的 Cas-SEAT 数据集可作为增强 EMLLM 自我评估的未来研究的宝贵资源。</paragraph>

##### **Collaboration of Large Language Models and Small Recommendation Models for Device-Cloud Recommendation**
2501.05647v1 by Zheqi Lv, Tianyu Zhan, Wenjie Wang, Xinyu Lin, Shengyu Zhang, Wenqiao Zhang, Jiwei Li, Kun Kuang, Fei Wu

Large Language Models (LLMs) for Recommendation (LLM4Rec) is a promising
research direction that has demonstrated exceptional performance in this field.
However, its inability to capture real-time user preferences greatly limits the
practical application of LLM4Rec because (i) LLMs are costly to train and infer
frequently, and (ii) LLMs struggle to access real-time data (its large number
of parameters poses an obstacle to deployment on devices). Fortunately, small
recommendation models (SRMs) can effectively supplement these shortcomings of
LLM4Rec diagrams by consuming minimal resources for frequent training and
inference, and by conveniently accessing real-time data on devices.
  In light of this, we designed the Device-Cloud LLM-SRM Collaborative
Recommendation Framework (LSC4Rec) under a device-cloud collaboration setting.
LSC4Rec aims to integrate the advantages of both LLMs and SRMs, as well as the
benefits of cloud and edge computing, achieving a complementary synergy. We
enhance the practicability of LSC4Rec by designing three strategies:
collaborative training, collaborative inference, and intelligent request.
During training, LLM generates candidate lists to enhance the ranking ability
of SRM in collaborative scenarios and enables SRM to update adaptively to
capture real-time user interests. During inference, LLM and SRM are deployed on
the cloud and on the device, respectively. LLM generates candidate lists and
initial ranking results based on user behavior, and SRM get reranking results
based on the candidate list, with final results integrating both LLM's and
SRM's scores. The device determines whether a new candidate list is needed by
comparing the consistency of the LLM's and SRM's sorted lists. Our
comprehensive and extensive experimental analysis validates the effectiveness
of each strategy in LSC4Rec.

摘要：大型语言模型（LLM）用于推荐（LLM4Rec）是一个有前景的研究方向，已在该领域展示出卓越的性能。然而，其无法捕捉实时用户偏好的能力极大地限制了 LLM4Rec 的实际应用，因为 (i) LLM 的训练和推理成本很高，而且经常进行，并且 (ii) LLM 难以访问实时数据（其大量参数对设备部署构成了障碍）。幸运的是，小型推荐模型（SRM）可以通过消耗最少的资源进行频繁训练和推理，并方便地访问设备上的实时数据，从而有效地弥补了 LLM4Rec 图表的这些缺点。有鉴于此，我们在设备云协作设置下设计了设备云 LLM-SRM 协作推荐框架（LSC4Rec）。LSC4Rec 旨在整合 LLM 和 SRM 的优势，以及云和边缘计算的优势，实现互补协同作用。我们通过设计三种策略来增强 LSC4Rec 的实用性：协作训练、协作推理和智能请求。在训练期间，LLM 生成候选列表以增强 SRM 在协作场景中的排序能力，并使 SRM 能够自适应地更新以捕捉实时用户兴趣。在推理期间，LLM 和 SRM 分别部署在云端和设备上。LLM 根据用户行为生成候选列表和初始排名结果，SRM 根据候选列表获得重新排名结果，最终结果整合了 LLM 和 SRM 的分数。设备通过比较 LLM 和 SRM 排序列表的一致性来确定是否需要新的候选列表。我们全面而广泛的实验分析验证了 LSC4Rec 中每种策略的有效性。

##### **Efficient Representations for High-Cardinality Categorical Variables in Machine Learning**
2501.05646v1 by Zixuan Liang

High\-cardinality categorical variables pose significant challenges in
machine learning, particularly in terms of computational efficiency and model
interpretability. Traditional one\-hot encoding often results in
high\-dimensional sparse feature spaces, increasing the risk of overfitting and
reducing scalability. This paper introduces novel encoding techniques,
including means encoding, low\-rank encoding, and multinomial logistic
regression encoding, to address these challenges. These methods leverage
sufficient representations to generate compact and informative embeddings of
categorical data. We conduct rigorous theoretical analyses and empirical
validations on diverse datasets, demonstrating significant improvements in
model performance and computational efficiency compared to baseline methods.
The proposed techniques are particularly effective in domains requiring
scalable solutions for large datasets, paving the way for more robust and
efficient applications in machine learning.

摘要：高基數分類變數在機器學習中造成重大挑戰，尤其是在計算效率和模型可解釋性方面。傳統的一熱編碼通常會產生高維稀疏特徵空間，增加過度擬合的風險並降低可擴充性。本文介紹了新穎的編碼技術，包括均值編碼、低秩編碼和多項邏輯迴歸編碼，以應對這些挑戰。這些方法利用充足的表示來產生分類資料的緊湊且有資訊的嵌入。我們對不同的資料集進行嚴謹的理論分析和實證驗證，證明與基線方法相比，模型效能和計算效率有顯著的改善。所提出的技術在需要針對大型資料集提供可擴充解決方案的領域特別有效，為機器學習中更強大且更有效的應用鋪路。

##### **Iconicity in Large Language Models**
2501.05643v1 by Anna Marklová, Jiří Milička, Leonid Ryvkin, Ľudmila Lacková Bennet, Libuše Kormaníková

Lexical iconicity, a direct relation between a word's meaning and its form,
is an important aspect of every natural language, most commonly manifesting
through sound-meaning associations. Since Large language models' (LLMs') access
to both meaning and sound of text is only mediated (meaning through textual
context, sound through written representation, further complicated by
tokenization), we might expect that the encoding of iconicity in LLMs would be
either insufficient or significantly different from human processing. This
study addresses this hypothesis by having GPT-4 generate highly iconic
pseudowords in artificial languages. To verify that these words actually carry
iconicity, we had their meanings guessed by Czech and German participants
(n=672) and subsequently by LLM-based participants (generated by GPT-4 and
Claude 3.5 Sonnet). The results revealed that humans can guess the meanings of
pseudowords in the generated iconic language more accurately than words in
distant natural languages and that LLM-based participants are even more
successful than humans in this task. This core finding is accompanied by
several additional analyses concerning the universality of the generated
language and the cues that both human and LLM-based participants utilize.

摘要：語彙標誌性，詞彙意義與形式之間的直接關係，是每種自然語言的重要面向，最常見的表現方式是透過聲音與意義的聯想。由於大型語言模型 (LLM) 對文字的意義和聲音的存取僅透過中介（意義透過文字脈絡，聲音透過書面表述，進一步複雜化的是進行標記化），我們可以預期 LLM 中標誌性的編碼會不足，或與人類處理方式有顯著差異。本研究透過讓 GPT-4 在人工語言中產生高度標誌性的偽詞來探討這個假設。為了驗證這些詞彙實際上具有標誌性，我們請捷克和德國參與者 (n=672) 猜測它們的意義，隨後再請基於 LLM 的參與者 (由 GPT-4 和 Claude 3.5 Sonnet 產生) 猜測。結果顯示，人類猜測在所產生標誌性語言中偽詞的意義，比猜測遠距離自然語言中詞彙的意義更準確，而且基於 LLM 的參與者在這個任務中比人類更成功。這個核心發現伴隨著幾個額外的分析，關於所產生語言的普遍性，以及人類和基於 LLM 的參與者所利用的線索。

##### **Automating Date Format Detection for Data Visualization**
2501.05640v1 by Zixuan Liang

Data preparation, specifically date parsing, is a significant bottleneck in
analytic workflows. To address this, we present two algorithms, one based on
minimum entropy and the other on natural language modeling that automatically
derive date formats from string data. These algorithms achieve over 90%
accuracy on a large corpus of data columns, streamlining the data preparation
process within visualization environments. The minimal entropy approach is
particularly fast, providing interactive feedback. Our methods simplify date
format extraction, making them suitable for integration into data visualization
tools and databases.

摘要：資料準備，特別是日期解析，是分析工作流程中一個重大的瓶頸。為了解決這個問題，我們提出兩種演算法，一種基於最小熵，另一種基於自然語言模型，可以自動從字串資料中推導出日期格式。這些演算法在大量資料欄位上達到超過 90% 的準確度，簡化了視覺化環境中的資料準備程序。最小熵方法特別快速，可提供互動回饋。我們的這些方法簡化了日期格式提取，使其適合整合到資料視覺化工具和資料庫中。

##### **The Impact of Model Scaling on Seen and Unseen Language Performance**
2501.05629v1 by Rhitabrat Pokharel, Sina Bagheri Nezhad, Ameeta Agrawal, Suresh Singh

The rapid advancement of Large Language Models (LLMs), particularly those
trained on multilingual corpora, has intensified the need for a deeper
understanding of their performance across a diverse range of languages and
model sizes. Our research addresses this critical need by studying the
performance and scaling behavior of multilingual LLMs in text classification
and machine translation tasks across 204 languages. We systematically examine
both seen and unseen languages across three model families of varying sizes in
zero-shot and few-shot settings. Our findings show significant differences in
scaling behavior between zero-shot and two-shot scenarios, with striking
disparities in performance between seen and unseen languages. Model scale has
little effect on zero-shot performance, which remains mostly flat. However, in
two-shot settings, larger models show clear linear improvements in multilingual
text classification. For translation tasks, however, only the instruction-tuned
model showed clear benefits from scaling. Our analysis also suggests that
overall resource levels, not just the proportions of pretraining languages, are
better predictors of model performance, shedding light on what drives
multilingual LLM effectiveness.

摘要：大型語言模型 (LLM) 的快速進展，尤其是那些在多語言語料庫上訓練的模型，加劇了對它們在各種語言和模型規模中表現的更深入理解的需求。我們的研究通過研究多語言 LLM 在 204 種語言的文本分類和機器翻譯任務中的表現和規模化行為來滿足這一關鍵需求。我們系統地檢查了在零次學習和少次學習設置中三個不同規模的模型系列中的已見和未見語言。我們的研究結果顯示，零次學習和兩次學習場景之間的規模化行為存在顯著差異，已見和未見語言之間的表現存在顯著差異。模型規模對零次學習表現影響不大，表現基本持平。然而，在兩次學習設置中，較大的模型在多語言文本分類中顯示出明顯的線性改進。然而，對於翻譯任務，只有經過指令調整的模型才顯示出規模化的明顯好處。我們的分析還表明，整體資源水平，而不仅仅是預訓練語言的比例，是模型表現的更好預測指標，這揭示了多語言 LLM 效能的驅動力。

##### **Watermarking Graph Neural Networks via Explanations for Ownership Protection**
2501.05614v1 by Jane Downer, Ren Wang, Binghui Wang

Graph Neural Networks (GNNs) are the mainstream method to learn pervasive
graph data and are widely deployed in industry, making their intellectual
property valuable. However, protecting GNNs from unauthorized use remains a
challenge. Watermarking, which embeds ownership information into a model, is a
potential solution. However, existing watermarking methods have two key
limitations: First, almost all of them focus on non-graph data, with
watermarking GNNs for complex graph data largely unexplored. Second, the de
facto backdoor-based watermarking methods pollute training data and induce
ownership ambiguity through intentional misclassification. Our
explanation-based watermarking inherits the strengths of backdoor-based methods
(e.g., robust to watermark removal attacks), but avoids data pollution and
eliminates intentional misclassification. In particular, our method learns to
embed the watermark in GNN explanations such that this unique watermark is
statistically distinct from other potential solutions, and ownership claims
must show statistical significance to be verified. We theoretically prove that,
even with full knowledge of our method, locating the watermark is an NP-hard
problem. Empirically, our method manifests robustness to removal attacks like
fine-tuning and pruning. By addressing these challenges, our approach marks a
significant advancement in protecting GNN intellectual property.

摘要：圖神經網路 (GNN) 是學習普遍圖形資料的主流方法，並廣泛部署於產業中，使其智慧財產權具有價值。然而，保護 GNN 免於未經授權使用仍然是一項挑戰。將所有權資訊嵌入模型中的浮水印是一種潛在的解決方案。然而，現有的浮水印方法有兩個關鍵限制：首先，幾乎所有方法都專注於非圖形資料，而針對複雜圖形資料的浮水印 GNN 仍未充分探索。其次，事實上的基於後門的浮水印方法會污染訓練資料，並透過故意錯誤分類引發所有權模糊性。我們基於解釋的浮水印繼承了基於後門方法的優點（例如，對浮水印移除攻擊的強健性），但避免了資料污染並消除了故意的錯誤分類。特別是，我們的模型學習將浮水印嵌入 GNN 解釋中，使得這個獨特的浮水印在統計上與其他潛在解法有別，而所有權主張必須顯示統計顯著性才能得到驗證。我們在理論上證明，即使完全瞭解我們的模型，定位浮水印也是一個 NP 難問題。根據經驗，我們的模型表現出對微調和剪枝等移除攻擊的強健性。透過解決這些挑戰，我們的模型標誌著保護 GNN 智慧財產權的重大進展。

##### **Harmonizing Metadata of Language Resources for Enhanced Querying and Accessibility**
2501.05606v1 by Zixuan Liang

This paper addresses the harmonization of metadata from diverse repositories
of language resources (LRs). Leveraging linked data and RDF techniques, we
integrate data from multiple sources into a unified model based on DCAT and
META-SHARE OWL ontology. Our methodology supports text-based search, faceted
browsing, and advanced SPARQL queries through Linghub, a newly developed
portal. Real user queries from the Corpora Mailing List (CML) were evaluated to
assess Linghub capability to satisfy actual user needs. Results indicate that
while some limitations persist, many user requests can be successfully
addressed. The study highlights significant metadata issues and advocates for
adherence to open vocabularies and standards to enhance metadata harmonization.
This initial research underscores the importance of API-based access to LRs,
promoting machine usability and data subset extraction for specific purposes,
paving the way for more efficient and standardized LR utilization.

摘要：本論文探討來自不同語言資源 (LRs) 儲存庫的元資料調和。我們利用連結資料和 RDF 技術，將來自多個來源的資料整合到一個統一的模型中，該模型基於 DCAT 和 META-SHARE OWL ontology。我們的 methodology 支援透過 Linghub（一個新開發的入口網站）進行基於文字的搜尋、分面瀏覽和進階 SPARQL 查詢。我們評估了來自 Corpora Mailing List (CML) 的真實使用者查詢，以評估 Linghub 滿足實際使用者需求的能力。結果顯示，雖然仍存在一些限制，但許多使用者要求都能獲得成功的處理。本研究突顯了重要的元資料問題，並倡導遵循開放詞彙和標準，以增強元資料調和。這項初步研究強調了基於 API 存取 LR 的重要性，促進機器可用性和資料子集萃取以達成特定目的，為更有效率和標準化的 LR 使用鋪路。

##### **Advancing Personalized Learning Analysis via an Innovative Domain Knowledge Informed Attention-based Knowledge Tracing Method**
2501.05605v1 by Shubham Kose, Jin Wei-Kocsis

Emerging Knowledge Tracing (KT) models, particularly deep learning and
attention-based Knowledge Tracing, have shown great potential in realizing
personalized learning analysis via prediction of students' future performance
based on their past interactions. The existing methods mainly focus on
immediate past interactions or individual concepts without accounting for
dependencies between knowledge concept, referred as knowledge concept routes,
that can be critical to advance the understanding the students' learning
outcomes. To address this, in this paper, we propose an innovative
attention-based method by effectively incorporating the domain knowledge of
knowledge concept routes in the given curriculum. Additionally, we leverage
XES3G5M dataset, a benchmark dataset with rich auxiliary information for
knowledge concept routes, to evaluate and compare the performance of our
proposed method to the seven State-of-the-art (SOTA) deep learning models.

摘要：新興知識追蹤 (KT) 模型，特別是深度學習和基於注意力的知識追蹤，在透過預測學生的未來表現，根據他們的過去互動，實現個人化學習分析方面，已展現出巨大的潛力。現有方法主要關注於最近的過去互動或個別概念，而不考慮知識概念之間的依賴性，稱為知識概念路線，這對於進一步了解學生的學習成果至關重要。為了解決這個問題，在本文中，我們提出了一種創新的基於注意力的方法，通過有效地將給定課程中的知識概念路線的領域知識整合進來。此外，我們利用 XES3G5M 資料集，一個具有豐富輔助資訊的知識概念路線基準資料集，來評估和比較我們提出的方法與七種最先進 (SOTA) 深度學習模型的效能。

##### **Exploring Large Language Models for Translating Romanian Computational Problems into English**
2501.05601v1 by Adrian Marius Dumitran, Adrian-Catalin Badea, Stefan-Gabriel Muscalu, Angela-Liliana Dumitran, Stefan-Cosmin Dascalescu, Radu-Sebastian Amarie

Recent studies have suggested that large language models (LLMs) underperform
on mathematical and computer science tasks when these problems are translated
from Romanian into English, compared to their original Romanian format.
Accurate translation is critical for applications ranging from automatic
translations in programming competitions to the creation of high-quality
educational materials, as well as minimizing errors or fraud in human
translations. This study shows that robust large language models (LLMs) can
maintain or even enhance their performance in translating less common languages
when given well-structured prompts. Our findings suggest that LLMs, with
appropriate supervision, can be reliably used for the automatic translation of
IOI (International Olympiad in Informatics)-style tasks. We evaluate several
translation methods across multiple LLMs, including OpenRoLLM, Llama 3.1 8B,
Llama 3.2 3B and GPT-4o, assessing their translation accuracy and performance
stability through repeated runs. Additionally, we augment the OJI (Romanian
County-Level Informatics Olympiad) Romanian dataset with accurate English
translations, enhancing its utility for future LLM training and evaluation.
Through detailed syntactic and semantic analyses, we confirm that with human
oversight, LLMs can serve as a viable solution for multilingual
problem-solving. We also compare the translation quality of LLMs against human
translators, as evaluated by a certified expert, underscoring the potential of
LLMs in realworld scenarios.

摘要：最近的研究表明，當這些問題從羅馬尼亞語翻譯成英語時，大型語言模型 (LLM) 在數學和電腦科學任務上的表現不如其原始的羅馬尼亞語格式。
準確的翻譯對於從程式設計競賽中的自動翻譯到建立高品質的教育材料，以及將人類翻譯中的錯誤或欺詐行為減到最低等各種應用至關重要。
本研究表明，當給予結構良好的提示時，強大的大型語言模型 (LLM) 可以維持或甚至增強其在翻譯較不常見的語言方面的表現。
我們的研究結果表明，在適當的監督下，LLM 可以可靠地用於自動翻譯 IOI（國際資訊學奧林匹克競賽）風格的任務。
我們評估了多個 LLM 中的幾種翻譯方法，包括 OpenRoLLM、Llama 3.1 8B、Llama 3.2 3B 和 GPT-4o，通過重複執行來評估它們的翻譯準確性和性能穩定性。
此外，我們用準確的英語翻譯來擴充 OJI（羅馬尼亞縣級資訊學奧林匹克競賽）羅馬尼亞語資料集，以增強其對未來 LLM 訓練和評估的實用性。
透過詳細的句法和語義分析，我們確認在人類監督下，LLM 可以作為多語言問題解決的可行方案。
我們還將 LLM 的翻譯品質與人類翻譯員進行比較，並由認證專家評估，強調了 LLM 在真實世界場景中的潛力。

##### **Approximate Supervised Object Distance Estimation on Unmanned Surface Vehicles**
2501.05567v1 by Benjamin Kiefer, Yitong Quan, Andreas Zell

Unmanned surface vehicles (USVs) and boats are increasingly important in
maritime operations, yet their deployment is limited due to costly sensors and
complexity. LiDAR, radar, and depth cameras are either costly, yield sparse
point clouds or are noisy, and require extensive calibration. Here, we
introduce a novel approach for approximate distance estimation in USVs using
supervised object detection. We collected a dataset comprising images with
manually annotated bounding boxes and corresponding distance measurements.
Leveraging this data, we propose a specialized branch of an object detection
model, not only to detect objects but also to predict their distances from the
USV. This method offers a cost-efficient and intuitive alternative to
conventional distance measurement techniques, aligning more closely with human
estimation capabilities. We demonstrate its application in a marine assistance
system that alerts operators to nearby objects such as boats, buoys, or other
waterborne hazards.

摘要：無人水面載具 (USV) 和船隻在海事作業中越來越重要，但由於感測器成本高昂且複雜，因此部署受到限制。LiDAR、雷達和深度相機不是成本高昂，就是產生稀疏點雲或有雜訊，且需要廣泛校正。在此，我們介紹一種使用監督物件偵測在 USV 中進行近似距離估計的新穎方法。我們收集了一個包含手動標註邊界框和對應距離測量的影像資料集。利用這些資料，我們提出一個物件偵測模型的專用分支，不僅可以偵測物件，還可以預測它們與 USV 的距離。此方法提供了一個經濟且直觀的替代方案，用於傳統距離測量技術，更貼近人類的估計能力。我們展示了它在海上輔助系統中的應用，該系統會對附近的物體（例如船隻、浮標或其他水域危害）向操作員發出警報。

##### **Vision-Language Models for Autonomous Driving: CLIP-Based Dynamic Scene Understanding**
2501.05566v1 by Mohammed Elhenawy, Huthaifa I. Ashqar, Andry Rakotonirainy, Taqwa I. Alhadidi, Ahmed Jaber, Mohammad Abu Tami

Scene understanding is essential for enhancing driver safety, generating
human-centric explanations for Automated Vehicle (AV) decisions, and leveraging
Artificial Intelligence (AI) for retrospective driving video analysis. This
study developed a dynamic scene retrieval system using Contrastive
Language-Image Pretraining (CLIP) models, which can be optimized for real-time
deployment on edge devices. The proposed system outperforms state-of-the-art
in-context learning methods, including the zero-shot capabilities of GPT-4o,
particularly in complex scenarios. By conducting frame-level analysis on the
Honda Scenes Dataset, which contains a collection of about 80 hours of
annotated driving videos capturing diverse real-world road and weather
conditions, our study highlights the robustness of CLIP models in learning
visual concepts from natural language supervision. Results also showed that
fine-tuning the CLIP models, such as ViT-L/14 and ViT-B/32, significantly
improved scene classification, achieving a top F1 score of 91.1%. These results
demonstrate the ability of the system to deliver rapid and precise scene
recognition, which can be used to meet the critical requirements of Advanced
Driver Assistance Systems (ADAS). This study shows the potential of CLIP models
to provide scalable and efficient frameworks for dynamic scene understanding
and classification. Furthermore, this work lays the groundwork for advanced
autonomous vehicle technologies by fostering a deeper understanding of driver
behavior, road conditions, and safety-critical scenarios, marking a significant
step toward smarter, safer, and more context-aware autonomous driving systems.

摘要：場景理解對於提升駕駛安全、為自動駕駛車輛 (AV) 決策產生以人為中心的解釋，以及利用人工智慧 (AI) 進行回顧性駕駛影片分析至關重要。本研究使用對比語言影像預訓練 (CLIP) 模型開發了一個動態場景檢索系統，該系統可以針對邊緣裝置上的即時部署進行最佳化。所提出的系統優於最先進的脈絡學習方法，包括 GPT-4o 的零次學習能力，特別是在複雜場景中。透過對 Honda 場景資料集進行逐幀分析，其中包含約 80 小時的標註駕駛影片，捕捉到多樣化的真實世界道路和天氣狀況，我們的研究突顯了 CLIP 模型在從自然語言監督中學習視覺概念的穩健性。結果也顯示，微調 CLIP 模型（例如 ViT-L/14 和 ViT-B/32）顯著改善了場景分類，達到了 91.1% 的最高 F1 分數。這些結果證明了系統提供快速且精確場景辨識的能力，可滿足先進駕駛輔助系統 (ADAS) 的關鍵需求。本研究顯示了 CLIP 模型提供可擴充且有效率的架構，用於動態場景理解和分類的潛力。此外，這項工作透過促進對駕駛行為、道路狀況和安全關鍵場景的更深入了解，為先進的自動駕駛車輛技術奠定了基礎，標誌著朝向更智慧、更安全且更具脈絡感知的自動駕駛系統邁出了重要一步。

##### **Soup to go: mitigating forgetting during continual learning with model averaging**
2501.05559v1 by Anat Kleiman, Gintare Karolina Dziugaite, Jonathan Frankle, Sham Kakade, Mansheej Paul

In continual learning, where task data arrives in a sequence, fine-tuning on
later tasks will often lead to performance degradation on earlier tasks. This
is especially pronounced when these tasks come from diverse domains. In this
setting, how can we mitigate catastrophic forgetting of earlier tasks and
retain what the model has learned with minimal computational expenses? Inspired
by other merging methods, and L2-regression, we propose Sequential Fine-tuning
with Averaging (SFA), a method that merges currently training models with
earlier checkpoints during the course of training. SOTA approaches typically
maintain a data buffer of past tasks or impose a penalty at each gradient step.
In contrast, our method achieves comparable results without the need to store
past data, or multiple copies of parameters for each gradient step.
Furthermore, our method outperforms common merging techniques such as Task
Arithmetic, TIES Merging, and WiSE-FT, as well as other penalty methods like L2
and Elastic Weight Consolidation. In turn, our method offers insight into the
benefits of merging partially-trained models during training across both image
and language domains.

摘要：在持續學習中，任務資料以序列形式出現，後續任務的微調通常會導致先前任務的效能下降。當這些任務來自不同的領域時，這種情況尤其明顯。在此設定中，我們如何減輕先前任務的災難性遺忘，並以最小的運算成本保留模型所學到的知識？受到其他合併方法和 L2 回歸的啟發，我們提出序貫微調與平均 (SFA)，這是一種在訓練過程中將目前訓練的模型與較早的檢查點合併的方法。現有技術通常會維護過去任務的資料緩衝區，或在每個梯度步驟中施加懲罰。相比之下，我們的方法在不需要儲存過去資料或每個梯度步驟的參數多個副本的情況下，就能達成相當的結果。此外，我們的優於常見的合併技術，例如任務算術、TIES 合併和 WiSE-FT，以及其他懲罰方法，例如 L2 和彈性權重合併。反過來，我們的優勢在於在影像和語言領域的訓練過程中，合併部分訓練模型的好處。

##### **Improving Zero-Shot Object-Level Change Detection by Incorporating Visual Correspondence**
2501.05555v1 by Hung Huy Nguyen, Pooyan Rahmanzadehgervi, Long Mail, Anh Totti Nguyen

Detecting object-level changes between two images across possibly different
views is a core task in many applications that involve visual inspection or
camera surveillance. Existing change-detection approaches suffer from three
major limitations: (1) lack of evaluation on image pairs that contain no
changes, leading to unreported false positive rates; (2) lack of
correspondences (\ie, localizing the regions before and after a change); and
(3) poor zero-shot generalization across different domains. To address these
issues, we introduce a novel method that leverages change correspondences (a)
during training to improve change detection accuracy, and (b) at test time, to
minimize false positives. That is, we harness the supervision labels of where
an object is added or removed to supervise change detectors, improving their
accuracy over previous work by a large margin. Our work is also the first to
predict correspondences between pairs of detected changes using estimated
homography and the Hungarian algorithm. Our model demonstrates superior
performance over existing methods, achieving state-of-the-art results in change
detection and change correspondence accuracy across both in-distribution and
zero-shot benchmarks.

摘要：偵測兩個影像之間的物件層級變動，在視覺檢查或攝影機監控等許多應用中都是核心任務。現有的變動偵測方法有三個主要的限制：(1) 缺乏對不含變動的影像對進行評估，導致未報告的假陽性率；(2) 缺乏對應關係（即，在變動前後定位區域）；以及 (3) 在不同領域的零次學習泛化能力差。為了解決這些問題，我們引入一種新方法，利用變動對應關係：(a) 在訓練期間提升變動偵測準確度，以及 (b) 在測試時，將假陽性降到最低。也就是說，我們利用物件新增或移除位置的監督標籤來監督變動偵測器，大幅提升其準確度，優於先前的研究。我們的研究也是第一個使用估計單應性和匈牙利演算法來預測偵測變動對之間的對應關係。我們的模型展現出優於現有方法的效能，在變動偵測和變動對應準確度方面，在分配內和零次學習基準測試中均達到最先進的結果。

##### **LLMQuoter: Enhancing RAG Capabilities Through Efficient Quote Extraction From Large Contexts**
2501.05554v1 by Yuri Facanha Bezerra, Li Weigang

We introduce LLMQuoter, a lightweight, distillation-based model designed to
enhance Retrieval Augmented Generation (RAG) by extracting the most relevant
textual evidence for downstream reasoning tasks. Built on the LLaMA-3B
architecture and fine-tuned with Low-Rank Adaptation (LoRA) on a 15,000-sample
subset of HotpotQA, LLMQuoter adopts a "quote-first-then-answer" strategy,
efficiently identifying key quotes before passing curated snippets to reasoning
models. This workflow reduces cognitive overhead and outperforms full-context
approaches like Retrieval-Augmented Fine-Tuning (RAFT), achieving over 20-point
accuracy gains across both small and large language models. By leveraging
knowledge distillation from a high-performing teacher model, LLMQuoter achieves
competitive results in a resource-efficient fine-tuning setup. It democratizes
advanced RAG capabilities, delivering significant performance improvements
without requiring extensive model retraining. Our results highlight the
potential of distilled quote-based reasoning to streamline complex workflows,
offering a scalable and practical solution for researchers and practitioners
alike.

摘要：我們推出 LLMQuoter，這是一個輕量級的、基於蒸餾的模型，旨在透過擷取與下游推理任務最相關的文字證據來增強檢索擴增生成 (RAG)。LLMQuoter 建立在 LLaMA-3B 架構上，並使用低秩適應 (LoRA) 在 HotpotQA 的 15,000 個樣本子集上進行微調，採用「先引用再回答」策略，在將精選片段傳遞給推理模型之前，有效識別關鍵引用。這個工作流程減少了認知負擔，並且優於全內容方法，例如檢索擴增微調 (RAFT)，在小型和大型語言模型中都獲得超過 20 點的準確度提升。透過利用高性能教師模型的知識蒸餾，LLMQuoter 在資源效率微調設定中取得了競爭力的結果。它民主化了進階 RAG 功能，在不需要廣泛模型重新訓練的情況下，提供了顯著的性能改進。我們的結果突顯了基於引用的蒸餾推理在簡化複雜工作流程方面的潛力，為研究人員和從業人員提供了一個可擴充且實用的解決方案。

##### **The dynamics of meaning through time: Assessment of Large Language Models**
2501.05552v1 by Mohamed Taher Alrefaie, Fatty Salem, Nour Eldin Morsy, Nada Samir, Mohamed Medhat Gaber

Understanding how large language models (LLMs) grasp the historical context
of concepts and their semantic evolution is essential in advancing artificial
intelligence and linguistic studies. This study aims to evaluate the
capabilities of various LLMs in capturing temporal dynamics of meaning,
specifically how they interpret terms across different time periods. We analyze
a diverse set of terms from multiple domains, using tailored prompts and
measuring responses through both objective metrics (e.g., perplexity and word
count) and subjective human expert evaluations. Our comparative analysis
includes prominent models like ChatGPT, GPT-4, Claude, Bard, Gemini, and Llama.
Findings reveal marked differences in each model's handling of historical
context and semantic shifts, highlighting both strengths and limitations in
temporal semantic understanding. These insights offer a foundation for refining
LLMs to better address the evolving nature of language, with implications for
historical text analysis, AI design, and applications in digital humanities.

摘要：了解大型語言模型 (LLM) 如何掌握概念的歷史脈絡及其語義演化對於推進人工智能和語言學研究至關重要。本研究旨在評估各種 LLM 在捕捉意義的時序動態方面的能力，特別是它們如何詮釋不同時期的術語。我們使用量身打造的提示，並透過客觀指標（例如困惑度和字數）和主觀的人類專家評估來分析來自多個領域的多樣化術語。我們的比較分析包括 ChatGPT、GPT-4、Claude、Bard、Gemini 和 Llama 等知名模型。研究結果揭示了每個模型在處理歷史脈絡和語義轉變方面的顯著差異，突出了時序語義理解的優點和缺點。這些見解為改進 LLM 提供了基礎，以更好地應對語言的演化本質，並對歷史文本分析、AI 設計和數位人文應用產生影響。

##### **OVO-Bench: How Far is Your Video-LLMs from Real-World Online Video Understanding?**
2501.05510v1 by Yifei Li, Junbo Niu, Ziyang Miao, Chunjiang Ge, Yuanhang Zhou, Qihao He, Xiaoyi Dong, Haodong Duan, Shuangrui Ding, Rui Qian, Pan Zhang, Yuhang Zang, Yuhang Cao, Conghui He, Jiaqi Wang

Temporal Awareness, the ability to reason dynamically based on the timestamp
when a question is raised, is the key distinction between offline and online
video LLMs. Unlike offline models, which rely on complete videos for static,
post hoc analysis, online models process video streams incrementally and
dynamically adapt their responses based on the timestamp at which the question
is posed. Despite its significance, temporal awareness has not been adequately
evaluated in existing benchmarks. To fill this gap, we present OVO-Bench
(Online-VideO-Benchmark), a novel video benchmark that emphasizes the
importance of timestamps for advanced online video understanding capability
benchmarking. OVO-Bench evaluates the ability of video LLMs to reason and
respond to events occurring at specific timestamps under three distinct
scenarios: (1) Backward tracing: trace back to past events to answer the
question. (2) Real-time understanding: understand and respond to events as they
unfold at the current timestamp. (3) Forward active responding: delay the
response until sufficient future information becomes available to answer the
question accurately. OVO-Bench comprises 12 tasks, featuring 644 unique videos
and approximately human-curated 2,800 fine-grained meta-annotations with
precise timestamps. We combine automated generation pipelines with human
curation. With these high-quality samples, we further developed an evaluation
pipeline to systematically query video LLMs along the video timeline.
Evaluations of nine Video-LLMs reveal that, despite advancements on traditional
benchmarks, current models struggle with online video understanding, showing a
significant gap compared to human agents. We hope OVO-Bench will drive progress
in video LLMs and inspire future research in online video reasoning. Our
benchmark and code can be accessed at https://github.com/JoeLeelyf/OVO-Bench.

摘要：時間感知，即根據問題提出的時間戳進行動態推理的能力，是在線和離線影片 LLM 之間的主要區別。與依賴完整影片進行靜態事後分析的離線模型不同，在線模型會遞增地處理影片串流，並根據問題提出的時間戳動態調整其回應。儘管時間感知很重要，但在現有基準測試中尚未得到充分評估。為了填補這一空白，我們提出了 OVO-Bench（Online-VideO-Benchmark），這是一個新穎的影片基準測試，強調時間戳對於先進的在線影片理解能力基準測試的重要性。OVO-Bench 評估影片 LLM 在三種不同情況下對特定時間戳發生的事件進行推理和回應的能力：(1) 向後追溯：追溯過去的事件以回答問題。(2) 實時理解：理解並回應在當前時間戳展開的事件。(3) 前向主動回應：延遲回應，直到有足夠的未來資訊可用於準確回答問題。OVO-Bench 包含 12 項任務，具有 644 個獨特的影片和約 2,800 個經過人工策劃的精細化元註解，並附有精確的時間戳。我們將自動化生成管道與人工策劃相結合。有了這些高品質的範例，我們進一步開發了一個評估管道，以系統地查詢影片 LLM 沿著影片時間軸。對九個 Video-LLM 的評估表明，儘管在傳統基準測試方面取得了進展，但目前的模型在在線影片理解方面仍存在困難，與人類代理相比存在顯著差距。我們希望 OVO-Bench 能夠推動影片 LLM 的進展，並激勵未來在線影片推理的研究。我們的基準測試和程式碼可以在 https://github.com/JoeLeelyf/OVO-Bench 取得。

##### **ReFocus: Visual Editing as a Chain of Thought for Structured Image Understanding**
2501.05452v1 by Xingyu Fu, Minqian Liu, Zhengyuan Yang, John Corring, Yijuan Lu, Jianwei Yang, Dan Roth, Dinei Florencio, Cha Zhang

Structured image understanding, such as interpreting tables and charts,
requires strategically refocusing across various structures and texts within an
image, forming a reasoning sequence to arrive at the final answer. However,
current multimodal large language models (LLMs) lack this multihop selective
attention capability. In this work, we introduce ReFocus, a simple yet
effective framework that equips multimodal LLMs with the ability to generate
"visual thoughts" by performing visual editing on the input image through code,
shifting and refining their visual focuses. Specifically, ReFocus enables
multimodal LLMs to generate Python codes to call tools and modify the input
image, sequentially drawing boxes, highlighting sections, and masking out
areas, thereby enhancing the visual reasoning process. We experiment upon a
wide range of structured image understanding tasks involving tables and charts.
ReFocus largely improves performance on all tasks over GPT-4o without visual
editing, yielding an average gain of 11.0% on table tasks and 6.8% on chart
tasks. We present an in-depth analysis of the effects of different visual
edits, and reasons why ReFocus can improve the performance without introducing
additional information. Further, we collect a 14k training set using ReFocus,
and prove that such visual chain-of-thought with intermediate information
offers a better supervision than standard VQA data, reaching a 8.0% average
gain over the same model trained with QA pairs and 2.6% over CoT.

摘要：結構化影像理解，例如詮釋表格和圖表，需要在影像中的各種結構和文字中策略性地重新聚焦，形成推理序列才能得出最終答案。然而，目前的多模態大型語言模型 (LLM) 缺乏這種多跳選擇性注意力的能力。在這項工作中，我們引入了 ReFocus，一個簡單但有效的框架，它賦予多模態 LLM 透過程式碼對輸入影像進行視覺編輯、轉移和優化其視覺焦點的能力，以產生「視覺思考」。具體來說，ReFocus 能讓多模態 LLM 產生 Python 程式碼來呼叫工具並修改輸入影像，循序漸進地繪製方塊、重點標示區段，以及遮蔽區域，從而增強視覺推理過程。我們在涉及表格和圖表的各種結構化影像理解任務中進行實驗。ReFocus 大幅提升了 GPT-4o 在所有任務上的表現，在沒有視覺編輯的情況下，在表格任務上平均提升了 11.0%，在圖表任務上提升了 6.8%。我們對不同視覺編輯的效果進行了深入分析，並說明了 ReFocus 如何在不引入額外資訊的情況下提升表現的原因。此外，我們使用 ReFocus 收集了一個 14k 訓練集，並證明這種包含中間資訊的視覺思考鏈比標準的 VQA 資料提供了更好的監督，在使用 QA 對訓練的相同模型上平均提升了 8.0%，在 CoT 上提升了 2.6%。

##### **An Empirical Study of Autoregressive Pre-training from Videos**
2501.05453v1 by Jathushan Rajasegaran, Ilija Radosavovic, Rahul Ravishankar, Yossi Gandelsman, Christoph Feichtenhofer, Jitendra Malik

We empirically study autoregressive pre-training from videos. To perform our
study, we construct a series of autoregressive video models, called Toto. We
treat videos as sequences of visual tokens and train transformer models to
autoregressively predict future tokens. Our models are pre-trained on a diverse
dataset of videos and images comprising over 1 trillion visual tokens. We
explore different architectural, training, and inference design choices. We
evaluate the learned visual representations on a range of downstream tasks
including image recognition, video classification, object tracking, and
robotics. Our results demonstrate that, despite minimal inductive biases,
autoregressive pre-training leads to competitive performance across all
benchmarks. Finally, we find that scaling our video models results in similar
scaling curves to those seen in language models, albeit with a different rate.
More details at https://brjathu.github.io/toto/

摘要：我們實證研究影片的回歸前訓練。為了執行我們的研究，我們建構了一系列回歸影片模型，稱為 Toto。我們將影片視為視覺符號序列，並訓練Transformer模型以回歸預測未來符號。我們的模型在超過 1 兆個視覺符號的多元影片和影像資料集上進行預訓練。我們探索不同的架構、訓練和推論設計選項。我們在各種下游任務上評估學習到的視覺表徵，包括影像辨識、影片分類、物件追蹤和機器人技術。我們的結果證明，儘管歸納偏誤最少，回歸前訓練仍能讓所有基準測試的效能具有競爭力。最後，我們發現擴充我們的影片模型會產生與語言模型中看到的類似擴充曲線，儘管速率不同。更多詳情請參閱 https://brjathu.github.io/toto/

##### **Consistent Flow Distillation for Text-to-3D Generation**
2501.05445v1 by Runjie Yan, Yinbo Chen, Xiaolong Wang

Score Distillation Sampling (SDS) has made significant strides in distilling
image-generative models for 3D generation. However, its
maximum-likelihood-seeking behavior often leads to degraded visual quality and
diversity, limiting its effectiveness in 3D applications. In this work, we
propose Consistent Flow Distillation (CFD), which addresses these limitations.
We begin by leveraging the gradient of the diffusion ODE or SDE sampling
process to guide the 3D generation. From the gradient-based sampling
perspective, we find that the consistency of 2D image flows across different
viewpoints is important for high-quality 3D generation. To achieve this, we
introduce multi-view consistent Gaussian noise on the 3D object, which can be
rendered from various viewpoints to compute the flow gradient. Our experiments
demonstrate that CFD, through consistent flows, significantly outperforms
previous methods in text-to-3D generation.

摘要：分數蒸餾採樣 (SDS) 在蒸餾用於 3D 生成的影像生成模型方面取得了重大進展。然而，它尋求最大似然的行为通常會導致視覺品質和多樣性降低，限制了它在 3D 應用中的效能。在這項工作中，我們提出了一致流蒸餾 (CFD)，來解決這些限制。我們首先利用擴散 ODE 或 SDE 採樣程序的梯度來引導 3D 生成。從基於梯度的採樣觀點來看，我們發現不同視角的 2D 影像流的一致性對於高品質的 3D 生成非常重要。為了達成此目的，我們在 3D 物件上引入了多視圖一致的高斯雜訊，可以從各種視角渲染它來計算流梯度。我們的實驗證明，CFD 透過一致的流，在文字轉 3D 生成中顯著優於先前的各種方法。

##### **A survey of textual cyber abuse detection using cutting-edge language models and large language models**
2501.05443v1 by Jose A. Diaz-Garcia, Joao Paulo Carvalho

The success of social media platforms has facilitated the emergence of
various forms of online abuse within digital communities. This abuse manifests
in multiple ways, including hate speech, cyberbullying, emotional abuse,
grooming, and sexting. In this paper, we present a comprehensive analysis of
the different forms of abuse prevalent in social media, with a particular focus
on how emerging technologies, such as Language Models (LMs) and Large Language
Models (LLMs), are reshaping both the detection and generation of abusive
content within these networks. We delve into the mechanisms through which
social media abuse is perpetuated, exploring the psychological and social
impact. Additionally, we examine the dual role of advanced language
models-highlighting their potential to enhance automated detection systems for
abusive behavior while also acknowledging their capacity to generate harmful
content. This paper aims to contribute to the ongoing discourse on online
safety and ethics, offering insights into the evolving landscape of cyberabuse
and the technological innovations that both mitigate and exacerbate it.

摘要：社群媒體平台的成功促成了數位社群中各種形式網路霸凌的出現。這種霸凌以多種方式表現，包括仇恨言論、網路霸凌、情緒虐待、誘騙和性簡訊。在本文中，我們對社群媒體中普遍存在的不同形式的霸凌進行了全面的分析，特別關注了新興技術（例如語言模型 (LM) 和大型語言模型 (LLM)）如何重新塑造這些網路中攻擊性內容的偵測和產生。我們深入探討了社群媒體霸凌持續存在的方式，探討了心理和社會影響。此外，我們探討了進階語言模型的雙重角色，強調了它們增強自動偵測系統以偵測攻擊性行為的潛力，同時也承認它們產生有害內容的能力。本文旨在為網路安全和道德的持續討論做出貢獻，提供對網路霸凌演變態勢的見解，以及減輕和加劇網路霸凌的技術創新。

##### **Progressive Growing of Video Tokenizers for Highly Compressed Latent Spaces**
2501.05442v1 by Aniruddha Mahapatra, Long Mai, Yitian Zhang, David Bourgin, Feng Liu

Video tokenizers are essential for latent video diffusion models, converting
raw video data into spatiotemporally compressed latent spaces for efficient
training. However, extending state-of-the-art video tokenizers to achieve a
temporal compression ratio beyond 4x without increasing channel capacity poses
significant challenges. In this work, we propose an alternative approach to
enhance temporal compression. We find that the reconstruction quality of
temporally subsampled videos from a low-compression encoder surpasses that of
high-compression encoders applied to original videos. This indicates that
high-compression models can leverage representations from lower-compression
models. Building on this insight, we develop a bootstrapped
high-temporal-compression model that progressively trains high-compression
blocks atop well-trained lower-compression models. Our method includes a
cross-level feature-mixing module to retain information from the pretrained
low-compression model and guide higher-compression blocks to capture the
remaining details from the full video sequence. Evaluation of video benchmarks
shows that our method significantly improves reconstruction quality while
increasing temporal compression compared to direct extensions of existing video
tokenizers. Furthermore, the resulting compact latent space effectively trains
a video diffusion model for high-quality video generation with a reduced token
budget.

摘要：影片分词器对于潜影片扩散模型至关重要，它将影片原始资料转换为时空压缩潜空间，以利于有效率的训练。然而，将最先进的影片分词器延伸到在不增加通道容量的情况下，实现超过 4 倍的时间压缩比，会带来重大的挑战。在这项研究中，我们提出了一种增强时间压缩的替代方法。我们发现，低压缩编码器中时间子采样的影片的重建质量，胜过应用于原始影片的高压缩编码器。这表示高压缩模型可以利用低压缩模型的表示。基于此见解，我们开发了一个自举高时间压缩模型，它在训练良好的低压缩模型之上，逐步训练高压缩区块。我们的方法包含了一个跨层级特征混合模块，以保留预先训练的低压缩模型中的信息，并引导更高的压缩区块捕捉完整影片序列中剩余的细节。影片基准的评估显示，我们的方法大幅改善了重建质量，同时与现有影片分词器的直接延伸相比，增加了时间压缩。此外，产生的紧凑潜空间有效地训练了一个影片扩散模型，用于高质量影片生成，同时减少了标记预算。

##### **The more polypersonal the better -- a short look on space geometry of fine-tuned layers**
2501.05503v1 by Sergei Kudriashov, Veronika Zykova, Angelina Stepanova, Yakov Raskind, Eduard Klyshinsky

The interpretation of deep learning models is a rapidly growing field, with
particular interest in language models. There are various approaches to this
task, including training simpler models to replicate neural network predictions
and analyzing the latent space of the model. The latter method allows us to not
only identify patterns in the model's decision-making process, but also
understand the features of its internal structure. In this paper, we analyze
the changes in the internal representation of the BERT model when it is trained
with additional grammatical modules and data containing new grammatical
structures (polypersonality). We find that adding a single grammatical layer
causes the model to separate the new and old grammatical systems within itself,
improving the overall performance on perplexity metrics.

摘要：深度學習模型的詮釋是一個快速成長的領域，特別是語言模型。有各種方法可以執行這項任務，包括訓練較簡單的模型來複製神經網路的預測，以及分析模型的潛在空間。後一種方法不僅讓我們找出模型決策過程中的模式，還能了解其內部結構的特徵。在本文中，我們分析了 BERT 模型在使用額外的語法模組和包含新語法結構（多重人格）的資料訓練後，其內部表徵的變化。我們發現，加入單一的語法層會讓模型將其內部的新舊語法系統分開，進而提升困惑度衡量指標的整體表現。

##### **LongProc: Benchmarking Long-Context Language Models on Long Procedural Generation**
2501.05414v1 by Xi Ye, Fangcong Yin, Yinghui He, Joie Zhang, Howard Yen, Tianyu Gao, Greg Durrett, Danqi Chen

Existing benchmarks for evaluating long-context language models (LCLMs)
primarily focus on long-context recall, requiring models to produce short
responses based on a few critical snippets while processing thousands of
irrelevant tokens. We introduce LongProc (Long Procedural Generation), a new
benchmark that requires both the integration of highly dispersed information
and long-form generation. LongProc consists of six diverse procedural
generation tasks, such as extracting structured information from HTML pages
into a TSV format and executing complex search procedures to create travel
plans. These tasks challenge LCLMs by testing their ability to follow detailed
procedural instructions, synthesize and reason over dispersed information, and
generate structured, long-form outputs (up to 8K tokens). Furthermore, as these
tasks adhere to deterministic procedures and yield structured outputs, they
enable reliable rule-based evaluation. We evaluate 17 LCLMs on LongProc across
three difficulty levels, with maximum numbers of output tokens set at 500, 2K,
and 8K. Notably, while all tested models claim a context window size above 32K
tokens, open-weight models typically falter on 2K-token tasks, and
closed-source models like GPT-4o show significant degradation on 8K-token
tasks. Further analysis reveals that LCLMs struggle to maintain long-range
coherence in long-form generations. These findings highlight critical
limitations in current LCLMs and suggest substantial room for improvement. Data
and code available at: https://princeton-pli.github.io/LongProc

摘要：現有的用於評估長語境語言模型 (LCLM) 的基準主要集中在長語境召回上，要求模型根據幾個關鍵片段產生簡短的回應，同時處理數千個不相關的符號。我們引入了 LongProc（長程序生成），這是一個新的基準，它需要高度分散的資訊整合和長格式生成。LongProc 包含六項不同的程序生成任務，例如將結構化資訊從 HTML 頁面提取到 TSV 格式，以及執行複雜的搜尋程序來建立旅遊計畫。這些任務透過測試 LCLM 遵循詳細程序說明、綜合和推理分散資訊以及生成結構化、長格式輸出（最多 8K 個符號）的能力，對其提出挑戰。此外，由於這些任務遵循確定性的程序並產生結構化的輸出，因此它們能進行可靠的基於規則的評估。我們在三個難度等級上對 17 個 LCLM 進行 LongProc 評估，將輸出符號的最大數量設定為 500、2K 和 8K。值得注意的是，雖然所有測試的模型都宣稱其語境窗口大小超過 32K 個符號，但開放權重模型通常在 2K 符號任務中失敗，而像 GPT-4o 這樣的閉源模型在 8K 符號任務中表現出顯著下降。進一步的分析表明，LCLM 難以在長格式生成中維持長程相干性。這些發現突顯了當前 LCLM 的關鍵限制，並表明有很大的改進空間。資料和程式碼可於以下網址取得：https://princeton-pli.github.io/LongProc

##### **Atlas: A Novel Pathology Foundation Model by Mayo Clinic, Charité, and Aignostics**
2501.05409v2 by Maximilian Alber, Stephan Tietz, Jonas Dippel, Timo Milbich, Timothée Lesort, Panos Korfiatis, Moritz Krügener, Beatriz Perez Cancer, Neelay Shah, Alexander Möllers, Philipp Seegerer, Alexandra Carpen-Amarie, Kai Standvoss, Gabriel Dernbach, Edwin de Jong, Simon Schallenberg, Andreas Kunft, Helmut Hoffer von Ankershoffen, Gavin Schaeferle, Patrick Duffy, Matt Redlon, Philipp Jurmeister, David Horst, Lukas Ruff, Klaus-Robert Müller, Frederick Klauschen, Andrew Norgan

Recent advances in digital pathology have demonstrated the effectiveness of
foundation models across diverse applications. In this report, we present
Atlas, a novel vision foundation model based on the RudolfV approach. Our model
was trained on a dataset comprising 1.2 million histopathology whole slide
images, collected from two medical institutions: Mayo Clinic and Charit\'e -
Universt\"atsmedizin Berlin. Comprehensive evaluations show that Atlas achieves
state-of-the-art performance across twenty-one public benchmark datasets, even
though it is neither the largest model by parameter count nor by training
dataset size.

摘要：最近在數位病理學的進展已展現基礎模型在各種應用上的有效性。在此報告中，我們提出 Atlas，一種基於 RudolfV 方法的新穎視覺基礎模型。我們的模型訓練於一個包含 120 萬張組織病理全玻片影像的資料集，這些影像收集自兩個醫療機構：梅約診所和柏林夏里特大學醫學中心。全面的評估顯示，Atlas 在 21 個公開基準資料集上達到了最先進的效能，即使它既不是參數數量最大的模型，也不是訓練資料集規模最大的模型。

##### **TimeRL: Efficient Deep Reinforcement Learning with Polyhedral Dependence Graphs**
2501.05408v1 by Pedro F. Silvestre, Peter Pietzuch

Modern deep learning (DL) workloads increasingly use complex deep
reinforcement learning (DRL) algorithms that generate training data within the
learning loop. This results in programs with several nested loops and dynamic
data dependencies between tensors. While DL systems with eager execution
support such dynamism, they lack the optimizations and smart scheduling of
graph-based execution. Graph-based execution, however, cannot express dynamic
tensor shapes, instead requiring the use of multiple static subgraphs. Either
execution model for DRL thus leads to redundant computation, reduced
parallelism, and less efficient memory management.
  We describe TimeRL, a system for executing dynamic DRL programs that combines
the dynamism of eager execution with the whole-program optimizations and
scheduling of graph-based execution. TimeRL achieves this by introducing the
declarative programming model of recurrent tensors, which allows users to
define dynamic dependencies as intuitive recurrence equations. TimeRL
translates recurrent tensors into a polyhedral dependence graph (PDG) with
dynamic dependencies as symbolic expressions. Through simple PDG
transformations, TimeRL applies whole-program optimizations, such as automatic
vectorization, incrementalization, and operator fusion. The PDG also allows for
the computation of an efficient program-wide execution schedule, which decides
on buffer deallocations, buffer donations, and GPU/CPU memory swapping. We show
that TimeRL executes current DRL algorithms up to 47$\times$ faster than
existing DRL systems, while using 16$\times$ less GPU peak memory.

摘要：現代深度學習 (DL) 工作負載日益使用複雜的深度強化學習 (DRL) 演算法，在學習迴圈中產生訓練資料。這會產生具有多個巢狀迴圈和張量之間動態資料相依性的程式。雖然具有熱切執行功能的 DL 系統支援這種動態性，但它們缺乏圖形化執行最佳化和智慧化排程。然而，圖形化執行無法表達動態張量形狀，反而需要使用多個靜態子圖形。因此，DRL 的任一執行模型都會導致重複運算、降低並行度和記憶體管理效率不彰。
我們描述 TimeRL，這是一個用於執行動態 DRL 程式的系統，它結合了熱切執行的動態性與圖形化執行的全程式最佳化和排程。TimeRL 透過引入遞迴張量的宣告式程式設計模型來達成此一目標，使用戶能夠將動態相依性定義為直覺的遞迴方程式。TimeRL 將遞迴張量轉換為具有動態相依性（作為符號表達式）的多面體相依圖形 (PDG)。透過簡單的 PDG 轉換，TimeRL 套用全程式最佳化，例如自動向量化、遞增化和運算子融合。PDG 也允許計算出有效的全程式執行排程，決定緩衝區取消配置、緩衝區捐贈和 GPU/CPU 記憶體交換。我們顯示 TimeRL 執行目前的 DRL 演算法速度比現有的 DRL 系統快達 47 倍，同時使用少 16 倍的 GPU 峰值記憶體。

##### **TimeDP: Learning to Generate Multi-Domain Time Series with Domain Prompts**
2501.05403v1 by Yu-Hao Huang, Chang Xu, Yueying Wu, Wu-Jun Li, Jiang Bian

Time series generation models are crucial for applications like data
augmentation and privacy preservation. Most existing time series generation
models are typically designed to generate data from one specified domain. While
leveraging data from other domain for better generalization is proved to work
in other application areas, this approach remains challenging for time series
modeling due to the large divergence in patterns among different real world
time series categories. In this paper, we propose a multi-domain time series
diffusion model with domain prompts, named TimeDP. In TimeDP, we utilize a time
series semantic prototype module which defines time series prototypes to
represent time series basis, each prototype vector serving as "word"
representing some elementary time series feature. A prototype assignment module
is applied to extract the extract domain specific prototype weights, for
learning domain prompts as generation condition. During sampling, we extract
"domain prompt" with few-shot samples from the target domain and use the domain
prompts as condition to generate time series samples. Experiments demonstrate
that our method outperforms baselines to provide the state-of-the-art in-domain
generation quality and strong unseen domain generation capability.

摘要：時間序列生成模型對於資料擴充和隱私保護等應用至關重要。現有的時間序列生成模型通常設計用於從一個指定領域生成資料。雖然利用其他領域的資料以獲得更好的泛化能力被證明在其他應用領域有效，但這種方法對於時間序列建模來說仍然具有挑戰性，因為不同現實世界時間序列類別之間的模式差異很大。在本文中，我們提出了一個帶有領域提示的多領域時間序列擴散模型，名為 TimeDP。在 TimeDP 中，我們利用了一個時間序列語義原型模組，它定義了時間序列原型以表示時間序列基礎，每個原型向量作為「詞彙」表示一些基本的時間序列特徵。應用原型分配模組來提取提取領域特定的原型權重，以學習領域提示作為生成條件。在採樣過程中，我們從目標領域中提取少數樣本的「領域提示」，並使用領域提示作為條件來生成時間序列樣本。實驗表明，我們的方法優於基準，在領域內生成品質和強大的未知領域生成能力方面提供最先進的技術。

##### **BRATI: Bidirectional Recurrent Attention for Time-Series Imputation**
2501.05401v1 by Armando Collado-Villaverde, Pablo Muñoz, Maria D. R-Moreno

Missing data in time-series analysis poses significant challenges, affecting
the reliability of downstream applications. Imputation, the process of
estimating missing values, has emerged as a key solution. This paper introduces
BRATI, a novel deep-learning model designed to address multivariate time-series
imputation by combining Bidirectional Recurrent Networks and Attention
mechanisms. BRATI processes temporal dependencies and feature correlations
across long and short time horizons, utilizing two imputation blocks that
operate in opposite temporal directions. Each block integrates recurrent layers
and attention mechanisms to effectively resolve long-term dependencies.
  We evaluate BRATI on three real-world datasets under diverse missing-data
scenarios: randomly missing values, fixed-length missing sequences, and
variable-length missing sequences. Our findings demonstrate that BRATI
consistently outperforms state-of-the-art models, delivering superior accuracy
and robustness in imputing multivariate time-series data.

摘要：時序分析中遺失的資料會造成重大的挑戰，影響下游應用程式的可靠性。估計遺失值這個過程稱為內插，已成為一項關鍵的解決方案。本文介紹 BRATI，這是一種新穎的深度學習模型，旨在透過結合雙向遞迴網路和注意力機制來解決多變量時序內插。BRATI 處理跨長短時間範圍的時間依賴性和特徵相關性，利用兩個以相反時間方向運作的內插區塊。每個區塊整合遞迴層和注意力機制，以有效解決長期依賴性。我們在三組真實世界資料集上評估 BRATI，這些資料集具有多樣化的遺失資料情境：隨機遺失值、固定長度遺失序列和變動長度遺失序列。我們的研究結果顯示，BRATI 在內插多變量時序資料方面始終優於現有技術模型，提供更佳的準確性和穩健性。

##### **Mechanistic understanding and validation of large AI models with SemanticLens**
2501.05398v1 by Maximilian Dreyer, Jim Berend, Tobias Labarta, Johanna Vielhaben, Thomas Wiegand, Sebastian Lapuschkin, Wojciech Samek

Unlike human-engineered systems such as aeroplanes, where each component's
role and dependencies are well understood, the inner workings of AI models
remain largely opaque, hindering verifiability and undermining trust. This
paper introduces SemanticLens, a universal explanation method for neural
networks that maps hidden knowledge encoded by components (e.g., individual
neurons) into the semantically structured, multimodal space of a foundation
model such as CLIP. In this space, unique operations become possible, including
(i) textual search to identify neurons encoding specific concepts, (ii)
systematic analysis and comparison of model representations, (iii) automated
labelling of neurons and explanation of their functional roles, and (iv) audits
to validate decision-making against requirements. Fully scalable and operating
without human input, SemanticLens is shown to be effective for debugging and
validation, summarizing model knowledge, aligning reasoning with expectations
(e.g., adherence to the ABCDE-rule in melanoma classification), and detecting
components tied to spurious correlations and their associated training data. By
enabling component-level understanding and validation, the proposed approach
helps bridge the "trust gap" between AI models and traditional engineered
systems. We provide code for SemanticLens on
https://github.com/jim-berend/semanticlens and a demo on
https://semanticlens.hhi-research-insights.eu.

摘要：與飛機等由人類設計的系統不同，飛機每個組件的角色和依賴性都清楚明瞭，而 AI 模型的內部運作在很大程度上仍不透明，這阻礙了可驗證性並破壞了信任。本文介紹了 SemanticLens，這是一種針對神經網路的通用解釋方法，它將組件（例如個別神經元）編碼的隱藏知識映射到基礎模型（例如 CLIP）的語義結構化多模態空間中。在這個空間中，可以進行獨特的操作，包括 (i) 文字搜尋以識別編碼特定概念的神經元，(ii) 系統分析和比較模型表示，(iii) 自動標記神經元並解釋其功能角色，以及 (iv) 稽核以驗證決策制定是否符合要求。SemanticLens 完全可擴展且在沒有人工輸入的情況下運行，已證明其在除錯和驗證、總結模型知識、將推理與期望保持一致（例如，遵守黑色素瘤分類中的 ABCDE 規則）以及檢測與虛假相關性和其關聯訓練資料相關的組件方面是有效的。通過實現組件級別的理解和驗證，所提出的方法有助於彌合 AI 模型與傳統工程系統之間的「信任差距」。我們在 https://github.com/jim-berend/semanticlens 上提供了 SemanticLens 的程式碼，並在 https://semanticlens.hhi-research-insights.eu 上提供了示範。

##### **FairCode: Evaluating Social Bias of LLMs in Code Generation**
2501.05396v1 by Yongkang Du, Jen-tse Huang, Jieyu Zhao, Lu Lin

Large language models (LLMs) have demonstrated significant capability in code
generation, drawing increasing attention to the evaluation of the quality and
safety of their outputs. However, research on bias in code generation remains
limited. Existing studies typically assess bias by applying malicious prompts
or reapply tasks and dataset for discriminative models. Given that LLMs are
often aligned with human values and that prior datasets are not fully optimized
for code-related tasks, there is a pressing need for benchmarks specifically
designed for evaluating code models. In this study, we introduce FairCode, a
novel benchmark for evaluating bias in code generation. FairCode comprises two
tasks: function implementation and test case generation, each evaluating social
bias through diverse scenarios. Additionally, we propose a new metric,
FairScore, to assess model performance on this benchmark. We conduct
experiments on widely used LLMs and provide a comprehensive analysis of the
results. The findings reveal that all tested LLMs exhibit bias. The code is
available at https://github.com/YongkDu/FairCode.

摘要：大型語言模型 (LLM) 已展現出生成程式碼的顯著能力，並越來越關注其輸出的品質和安全性評估。然而，關於程式碼生成偏差的研究仍然有限。現有研究通常透過套用惡意提示或重新套用任務和資料集來評估偏差，以進行區辨模型。鑑於 LLM 通常與人類價值觀一致，且先前的資料集並未針對程式碼相關任務進行完全最佳化，因此迫切需要專門用於評估程式碼模型的基準。在此研究中，我們介紹了 FairCode，這是一個用於評估程式碼生成偏差的新基準。FairCode 包含兩個任務：函式實作和測試案例生成，每個任務都透過不同的場景評估社會偏差。此外，我們提出了一個新的指標 FairScore，用於評估模型在此基準上的效能。我們對廣泛使用的 LLM 進行實驗，並對結果進行全面分析。研究結果顯示，所有受測的 LLM 都表現出偏差。程式碼可在 https://github.com/YongkDu/FairCode 取得。

##### **Spatial Information Integration in Small Language Models for Document Layout Generation and Classification**
2501.05497v1 by Pablo Melendez, Clemens Havas

Document layout understanding is a field of study that analyzes the spatial
arrangement of information in a document hoping to understand its structure and
layout. Models such as LayoutLM (and its subsequent iterations) can understand
semi-structured documents with SotA results; however, the lack of open
semi-structured data is a limitation in itself. While semi-structured data is
common in everyday life (balance sheets, purchase orders, receipts), there is a
lack of public datasets for training machine learning models for this type of
document. In this investigation we propose a method to generate new, synthetic,
layout information that can help overcoming this data shortage. According to
our results, the proposed method performs better than LayoutTransformer,
another popular layout generation method. We also show that, in some scenarios,
text classification can improve when supported by bounding box information.

摘要：文件配置理解是一个研究领域，它分析文件中的空间信息配置，并希望了解其结构和配置。LayoutLM（及其后续迭代）等模型可以理解半结构化文件，并具有 SotA 结果；但是，缺少开放的半结构化数据本身就是一种限制。虽然半结构化数据在日常生活中很常见（资产负债表、采购订单、收据），但缺乏用于训练机器学习模型的公共数据集来处理此类文件。在本次调查中，我们提出了一种生成新的合成配置信息的方法，这有助于克服数据短缺问题。根据我们的结果，所提出的方法比 LayoutTransformer（另一种流行的配置生成方法）表现得更好。我们还表明，在某些情况下，当由边界框信息支持时，文本分类可以得到改善。

##### **Large Physics Models: Towards a collaborative approach with Large Language Models and Foundation Models**
2501.05382v1 by Kristian G. Barman, Sascha Caron, Emily Sullivan, Henk W. de Regt, Roberto Ruiz de Austri, Mieke Boon, Michael Färber, Stefan Fröse, Faegheh Hasibi, Andreas Ipp, Rukshak Kapoor, Gregor Kasieczka, Daniel Kostić, Michael Krämer, Tobias Golling, Luis G. Lopez, Jesus Marco, Sydney Otten, Pawel Pawlowski, Pietro Vischia, Erik Weber, Christoph Weniger

This paper explores ideas and provides a potential roadmap for the
development and evaluation of physics-specific large-scale AI models, which we
call Large Physics Models (LPMs). These models, based on foundation models such
as Large Language Models (LLMs) - trained on broad data - are tailored to
address the demands of physics research. LPMs can function independently or as
part of an integrated framework. This framework can incorporate specialized
tools, including symbolic reasoning modules for mathematical manipulations,
frameworks to analyse specific experimental and simulated data, and mechanisms
for synthesizing theories and scientific literature. We begin by examining
whether the physics community should actively develop and refine dedicated
models, rather than relying solely on commercial LLMs. We then outline how LPMs
can be realized through interdisciplinary collaboration among experts in
physics, computer science, and philosophy of science. To integrate these models
effectively, we identify three key pillars: Development, Evaluation, and
Philosophical Reflection. Development focuses on constructing models capable of
processing physics texts, mathematical formulations, and diverse physical data.
Evaluation assesses accuracy and reliability by testing and benchmarking.
Finally, Philosophical Reflection encompasses the analysis of broader
implications of LLMs in physics, including their potential to generate new
scientific understanding and what novel collaboration dynamics might arise in
research. Inspired by the organizational structure of experimental
collaborations in particle physics, we propose a similarly interdisciplinary
and collaborative approach to building and refining Large Physics Models. This
roadmap provides specific objectives, defines pathways to achieve them, and
identifies challenges that must be addressed to realise physics-specific large
scale AI models.

摘要：本文探討想法，並為物理特定的大規模 AI 模型（我們稱之為大型物理模型，LPM）的開發和評估提供潛在的路線圖。這些模型基於大型語言模型（LLM）等基礎模型，使用廣泛的數據進行訓練，並專門針對物理研究的需求進行調整。LPM 可以獨立運行，或作為整合架構的一部分。此架構可以整合專用工具，包括用於數學運算的符號推理模組、用於分析特定實驗和模擬數據的架構，以及用於綜合理論和科學文獻的機制。我們首先探討物理界是否應該積極開發和改進專用模型，而不是僅依賴商業 LLM。然後，我們概述如何透過物理學、電腦科學和科學哲學方面的專家之間的跨領域合作來實現 LPM。為了有效整合這些模型，我們找出三個關鍵支柱：開發、評估和哲學反思。開發的重點在於建構能夠處理物理文本、數學公式和各種物理數據的模型。評估透過測試和基準測試來評估準確性和可靠性。最後，哲學反思包含分析 LLM 在物理學中更廣泛的影響，包括它們產生新的科學理解的潛力，以及在研究中可能出現什麼新的合作動態。受到粒子物理學中實驗合作的組織結構啟發，我們提出一個類似跨領域和合作的方法來建構和改進大型物理模型。此路線圖提供了具體目標，定義了達成目標的途徑，並找出實現物理特定的大規模 AI 模型時必須解決的挑戰。

##### **Developing a Foundation of Vector Symbolic Architectures Using Category Theory**
2501.05368v1 by Nolan P Shaw, P Michael Furlong, Britt Anderson, Jeff Orchard

At the risk of overstating the case, connectionist approaches to machine
learning, i.e. neural networks, are enjoying a small vogue right now. However,
these methods require large volumes of data and produce models that are
uninterpretable to humans. An alternative framework that is compatible with
neural networks and gradient-based learning, but explicitly models
compositionality, is Vector Symbolic Architectures (VSAs). VSAs are a family of
algebras on high-dimensional vector representations. They arose in cognitive
science from the need to unify neural processing and the kind of symbolic
reasoning that humans perform. While machine learning methods have benefited
from category theoretical analyses, VSAs have not yet received similar
treatment. In this paper, we present a first attempt at applying category
theory to VSAs. Specifically, we conduct a brief literature survey
demonstrating the lacking intersection of these two topics, provide a list of
desiderata for VSAs, and propose that VSAs may be understood as a (division)
rig in a category enriched over a monoid in Met (the category of Lawvere metric
spaces). This final contribution suggests that VSAs may be generalised beyond
current implementations. It is our hope that grounding VSAs in category theory
will lead to more rigorous connections with other research, both within and
beyond, learning and cognition.

摘要：<paragraph>即使誇大其詞，聯結主義方法對機器學習來說，也就是神經網路，目前正盛行著。然而，這些方法需要大量的資料，並產生人類無法理解的模型。一種與神經網路和基於梯度的學習相容，但明確建構組合性的替代架構，是向量符號架構 (VSA)。VSA 是一組關於高維度向量表示的代數。它們源於認知科學，目的是統一神經處理和人類執行的符號推理。雖然機器學習方法受益於範疇理論分析，但 VSA 尚未獲得類似的處理。在本文中，我們首次嘗試將範疇理論應用於 VSA。具體來說，我們進行了一項簡短的文獻調查，說明這兩個主題缺乏交集，提供了 VSA 的理想清單，並提出 VSA 可以理解為一個 (除法) 範疇中的 rig，該範疇豐富於 Met 中的單元 (Lawvere 度量空間的範疇)。這個最終貢獻表明 VSA 可以概括到目前的實作之外。我們希望將 VSA 基於範疇理論將有助於與其他研究建立更嚴謹的連結，無論是在學習和認知的範疇內或外。</paragraph>

##### **Search-o1: Agentic Search-Enhanced Large Reasoning Models**
2501.05366v1 by Xiaoxi Li, Guanting Dong, Jiajie Jin, Yuyao Zhang, Yujia Zhou, Yutao Zhu, Peitian Zhang, Zhicheng Dou

Large reasoning models (LRMs) like OpenAI-o1 have demonstrated impressive
long stepwise reasoning capabilities through large-scale reinforcement
learning. However, their extended reasoning processes often suffer from
knowledge insufficiency, leading to frequent uncertainties and potential
errors. To address this limitation, we introduce \textbf{Search-o1}, a
framework that enhances LRMs with an agentic retrieval-augmented generation
(RAG) mechanism and a Reason-in-Documents module for refining retrieved
documents. Search-o1 integrates an agentic search workflow into the reasoning
process, enabling dynamic retrieval of external knowledge when LRMs encounter
uncertain knowledge points. Additionally, due to the verbose nature of
retrieved documents, we design a separate Reason-in-Documents module to deeply
analyze the retrieved information before injecting it into the reasoning chain,
minimizing noise and preserving coherent reasoning flow. Extensive experiments
on complex reasoning tasks in science, mathematics, and coding, as well as six
open-domain QA benchmarks, demonstrate the strong performance of Search-o1.
This approach enhances the trustworthiness and applicability of LRMs in complex
reasoning tasks, paving the way for more reliable and versatile intelligent
systems. The code is available at
\url{https://github.com/sunnynexus/Search-o1}.

摘要：大型推理模型（LRM），例如 OpenAI-o1，已通过大规模强化学习展示了令人印象深刻的长步推理能力。然而，它们扩展的推理过程通常会受到知识不足的影响，从而导致频繁的不确定性和潜在的错误。为了解决这个限制，我们引入了 \textbf{Search-o1}，这是一个框架，它通过代理检索增强生成（RAG）机制和用于精炼检索到的文档的文档中推理模块来增强 LRM。Search-o1 将代理搜索工作流集成到推理过程中，使 LRM 在遇到不确定的知识点时能够动态检索外部知识。此外，由于检索到的文档冗长，我们设计了一个单独的文档中推理模块，以便在将检索到的信息注入推理链之前对其进行深入分析，最大程度地减少噪音并保持连贯的推理流程。在科学、数学和编码中的复杂推理任务以及六个开放域 QA 基准上的大量实验表明了 Search-o1 的强大性能。这种方法增强了 LRM 在复杂推理任务中的可信度和适用性，为更可靠和通用的智能系统铺平了道路。代码可在 \url{https://github.com/sunnynexus/Search-o1} 获得。

##### **On Corrigibility and Alignment in Multi Agent Games**
2501.05360v1 by Edmund Dable-Heath, Boyko Vodenicharski, James Bishop

Corrigibility of autonomous agents is an under explored part of system
design, with previous work focusing on single agent systems. It has been
suggested that uncertainty over the human preferences acts to keep the agents
corrigible, even in the face of human irrationality. We present a general
framework for modelling corrigibility in a multi-agent setting as a 2 player
game in which the agents always have a move in which they can ask the human for
supervision. This is formulated as a Bayesian game for the purpose of
introducing uncertainty over the human beliefs. We further analyse two specific
cases. First, a two player corrigibility game, in which we want corrigibility
displayed in both agents for both common payoff (monotone) games and harmonic
games. Then we investigate an adversary setting, in which one agent is
considered to be a `defending' agent and the other an `adversary'. A general
result is provided for what belief over the games and human rationality the
defending agent is required to have to induce corrigibility.

摘要：自主代理的可修正性是系统设计中尚未探索的部分，以前的工作重点放在单代理系统上。有人提出，对人类偏好的不确定性有助于保持代理的可修正性，即使面对人类的不理性。我们提出了一个通用的框架，用于在多代理环境中对可修正性进行建模，作为一种 2 人游戏，其中代理始终可以采取行动，要求人类进行监督。这被表述为贝叶斯博弈，目的是引入对人类信念的不确定性。我们进一步分析了两个具体案例。首先，一个双人可修正性游戏，我们希望在共同收益（单调）游戏和协调游戏中显示两个代理的可修正性。然后，我们调查了一个对抗环境，其中一个代理被认为是“防御”代理，另一个代理被认为是“对抗”代理。提供了一个一般结果，说明防御代理需要对游戏和人类理性的信念是什么，才能诱导可修正性。

##### **FedSA: A Unified Representation Learning via Semantic Anchors for Prototype-based Federated Learning**
2501.05496v1 by Yanbing Zhou, Xiangmou Qu, Chenlong You, Jiyang Zhou, Jingyue Tang, Xin Zheng, Chunmao Cai, Yingbo Wu

Prototype-based federated learning has emerged as a promising approach that
shares lightweight prototypes to transfer knowledge among clients with data
heterogeneity in a model-agnostic manner. However, existing methods often
collect prototypes directly from local models, which inevitably introduce
inconsistencies into representation learning due to the biased data
distributions and differing model architectures among clients. In this paper,
we identify that both statistical and model heterogeneity create a vicious
cycle of representation inconsistency, classifier divergence, and skewed
prototype alignment, which negatively impacts the performance of clients. To
break the vicious cycle, we propose a novel framework named Federated Learning
via Semantic Anchors (FedSA) to decouple the generation of prototypes from
local representation learning. We introduce a novel perspective that uses
simple yet effective semantic anchors serving as prototypes to guide local
models in learning consistent representations. By incorporating semantic
anchors, we further propose anchor-based regularization with margin-enhanced
contrastive learning and anchor-based classifier calibration to correct feature
extractors and calibrate classifiers across clients, achieving intra-class
compactness and inter-class separability of prototypes while ensuring
consistent decision boundaries. We then update the semantic anchors with these
consistent and discriminative prototypes, which iteratively encourage clients
to collaboratively learn a unified data representation with robust
generalization. Extensive experiments under both statistical and model
heterogeneity settings show that FedSA significantly outperforms existing
prototype-based FL methods on various classification tasks.

摘要：基於原型的聯邦學習已成為一種有前景的方法，它以與模型無關的方式共享輕量級原型，以便在具有數據異質性的客戶端之間傳輸知識。然而，現有方法通常直接從本地模型收集原型，這不可避免地會由於客戶端之間有偏差的數據分佈和不同的模型架構而導致表示學習中的不一致性。在本文中，我們發現統計異質性和模型異質性都會造成表示不一致、分類器差異和原型對齊偏差的惡性循環，這對客戶端的性能產生負面影響。為了打破這個惡性循環，我們提出了一個名為通過語義錨點進行聯邦學習（FedSA）的新框架，以將原型的生成與本地表示學習解耦。我們引入了一個新觀點，使用簡單但有效的語義錨點作為原型，以指導本地模型學習一致的表示。通過結合語義錨點，我們進一步提出基於錨點的正則化，帶有增強邊界的對比學習和基於錨點的分類器校準，以校正特徵提取器和校準客戶端的分類器，實現原型的類內緊湊性和類間可分離性，同時確保一致的決策邊界。然後，我們使用這些一致且有區別性的原型更新語義錨點，這反復鼓勵客戶端協作學習統一的數據表示，並具有強大的泛化能力。在統計和模型異質性設置下的廣泛實驗表明，FedSA 在各種分類任務上顯著優於現有的基於原型的 FL 方法。

##### **Stream Aligner: Efficient Sentence-Level Alignment via Distribution Induction**
2501.05336v1 by Hantao Lou, Jiaming Ji, Kaile Wang, Yaodong Yang

The rapid advancement of large language models (LLMs) has led to significant
improvements in their capabilities, but also to increased concerns about their
alignment with human values and intentions. Current alignment strategies,
including adaptive training and inference-time methods, have demonstrated
potential in this area. However, these approaches still struggle to balance
deployment complexity and capability across various tasks and difficulties. In
this work, we introduce the Streaming Distribution Induce Aligner (Stream
Aligner), a novel alignment paradigm that combines efficiency with enhanced
performance in various tasks throughout the generation process. Stream Aligner
achieves dynamic sentence-level correction by using a small model to learn the
preferences of the suffix sentence, iteratively correcting the suffix sentence
output by the upstream model, and then using the corrected sentence to replace
the suffix sentence in subsequent generations. Compared to Aligner, our
experiments demonstrate that Stream Aligner reduces reliance on the
capabilities of additional models, enhances the reasoning abilities of LLMs,
and decreases latency during user interaction. Specifically, Stream Aligner-2B
model has achieved an improvement of 76.1% in helpfulness, 36.0% in
harmlessness on the tested Llama2-70B-chat model, and Stream Aligner-8B has
achieved an improvement of 3.5% on the math ability of the tested
Llama3-70B-Instruct model.

摘要：大型語言模型 (LLM) 的快速進展已顯著提升其能力，但也引發更多關於其與人類價值觀和意圖一致性的疑慮。目前的對齊策略，包括適應性訓練和推論時間方法，已在此領域展現潛力。然而，這些方法仍難以在各種任務和難度中取得部署複雜度和能力的平衡。在本文中，我們介紹了串流分佈誘導對齊器 (Stream Aligner)，這是一種新穎的對齊範例，結合了效率與在整個生成過程中各種任務中增強的效能。Stream Aligner 透過使用小型模型來學習後綴句子的偏好，反覆修正上游模型輸出的後綴句子，然後使用修正過的句子取代後續生成中的後綴句子，進而達成動態的句子層級修正。與 Aligner 相比，我們的實驗證明 Stream Aligner 減少了對其他模型能力的依賴，增強了 LLM 的推理能力，並降低了使用者互動期間的延遲。具體而言，Stream Aligner-2B 模型在有益性方面提升了 76.1%，在無害性方面提升了 36.0%，在測試的 Llama2-70B-chat 模型上，而 Stream Aligner-8B 則在測試的 Llama3-70B-Instruct 模型的數學能力方面提升了 3.5%。

##### **The Bakers and Millers Game with Restricted Locations**
2501.05334v1 by Simon Krogmann, Pascal Lenzner, Alexander Skopalik

We study strategic location choice by customers and sellers, termed the
Bakers and Millers Game in the literature. In our generalized setting, each
miller can freely choose any location for setting up a mill, while each baker
is restricted in the choice of location for setting up a bakery. For optimal
bargaining power, a baker would like to select a location with many millers to
buy flour from and with little competition from other bakers. Likewise, a
miller aims for a location with many bakers and few competing millers. Thus,
both types of agents choose locations to optimize the ratio of agents of
opposite type divided by agents of the same type at their chosen location.
Originally raised in the context of Fractional Hedonic Games, the Bakers and
Millers Game has applications that range from commerce to product design.
  We study the impact of location restrictions on the properties of the game.
While pure Nash equilibria trivially exist in the setting without location
restrictions, we show via a sophisticated, efficient algorithm that even the
more challenging restricted setting admits equilibria. Moreover, the computed
equilibrium approximates the optimal social welfare by a factor of at most
$2\left(\frac{e}{e-1}\right)$. Furthermore, we give tight bounds on the price
of anarchy/stability.
  On the conceptual side, the location choice feature adds a new layer to the
standard setting of Hedonic Games, in the sense that agents that select the
same location form a coalition. This allows to naturally restrict the possible
coalitions that can be formed. With this, our model generalizes simple
symmetric Fractional Hedonic Games on complete bipartite valuation graphs and
also Hedonic Diversity Games with utilities single-peaked at 0. We believe that
this generalization is also a very interesting direction for other types of
Hedonic Games.

摘要：<paragraph>我們研究由客戶和賣方進行的策略性位置選擇，在文獻中稱為麵包師和磨坊主的遊戲。在我們概括的設定中，每個磨坊主可以自由選擇任何位置來設置磨坊，而每個麵包師在選擇設置麵包店的時受到地點限制。為了獲得最佳的議價能力，麵包師希望選擇一個有許多磨坊主可以購買麵粉且與其他麵包師競爭較少的地點。同樣地，磨坊主會選擇一個有許多麵包師且競爭對手較少的磨坊主的地點。因此，這兩種類型的代理人都會選擇地點來優化在他們所選擇的地點，相反類型的代理人與相同類型的代理人的比例。最初在分數享樂遊戲的背景下提出，麵包師和磨坊主的遊戲有從商業到產品設計的廣泛應用。我們研究地點限制對遊戲屬性的影響。雖然在沒有地點限制的設定中，純納許均衡顯然存在，但我們透過一種複雜、有效的演算法證明，即使在更具挑戰性的受限設定中也能承認均衡。此外，計算出的均衡以最多 $2\left(\frac{e}{e-1}\right)$ 的因子近似最佳社會福利。此外，我們對無政府狀態/穩定的價格給予嚴格的限制。在概念方面，地點選擇功能為享樂遊戲的標準設定增加了一層，在於選擇相同地點的代理人會組成一個聯盟。這允許自然地限制可以形成的可能聯盟。有了這個，我們的模型概括了在完整理論二分圖估值圖表上的簡單對稱分數享樂遊戲，以及在 0 處單峰的享樂多樣性遊戲。我們相信這個概括對於其他類型的享樂遊戲來說也是一個非常有趣的發展方向。</paragraph>

##### **AnCoGen: Analysis, Control and Generation of Speech with a Masked Autoencoder**
2501.05332v1 by Samir Sadok, Simon Leglaive, Laurent Girin, Gaël Richard, Xavier Alameda-Pineda

This article introduces AnCoGen, a novel method that leverages a masked
autoencoder to unify the analysis, control, and generation of speech signals
within a single model. AnCoGen can analyze speech by estimating key attributes,
such as speaker identity, pitch, content, loudness, signal-to-noise ratio, and
clarity index. In addition, it can generate speech from these attributes and
allow precise control of the synthesized speech by modifying them. Extensive
experiments demonstrated the effectiveness of AnCoGen across speech
analysis-resynthesis, pitch estimation, pitch modification, and speech
enhancement.

摘要：本文介紹了 AnCoGen，一種新方法，它利用掩蔽式自動編碼器在單一模型中統一語音信號的分析、控制和生成。AnCoGen 可以透過估計關鍵屬性來分析語音，例如說話者身分、音高、內容、響度、信噪比和清晰度指標。此外，它可以從這些屬性生成語音，並透過修改它們來精確控制合成的語音。大量的實驗證明了 AnCoGen 在語音分析再合成、音高估計、音高修改和語音增強方面的有效性。

