{"2405.18400": {"publish_time": "2024-05-28", "title": "Superposed Decoding: Multiple Generations from a Single Autoregressive Inference Pass", "paper_summary": "Many applications today provide users with multiple auto-complete drafts as\nthey type, including GitHub's code completion, Gmail's smart compose, and\nApple's messaging auto-suggestions. Under the hood, language models support\nthis by running an autoregressive inference pass to provide a draft.\nConsequently, providing $k$ drafts to the user requires running an expensive\nlanguage model $k$ times. To alleviate the computation cost of running $k$\ninference passes, we propose Superposed Decoding, a new decoding algorithm that\ngenerates $k$ drafts at the computation cost of one autoregressive inference\npass. We achieve this by feeding a superposition of the most recent token\nembeddings from the $k$ drafts as input to the next decoding step of the\nlanguage model. At every inference step we combine the $k$ drafts with the\ntop-$k$ tokens to get $k^2$ new drafts and cache the $k$ most likely options,\nusing an n-gram interpolation with minimal compute overhead to filter out\nincoherent generations. Our experiments show that $k$ drafts from Superposed\nDecoding are at least as coherent and factual as Nucleus Sampling and Greedy\nDecoding respectively, while being at least $2.44\\times$ faster for $k\\ge3$. In\na compute-normalized setting, user evaluations demonstrably favor text\ngenerated by Superposed Decoding over Nucleus Sampling. Code and more examples\nopen-sourced at https://github.com/RAIVNLab/SuperposedDecoding.", "paper_summary_zh": "\u73fe\u4eca\u8a31\u591a\u61c9\u7528\u7a0b\u5f0f\u5728\u4f7f\u7528\u8005\u8f38\u5165\u6642\u6703\u63d0\u4f9b\u591a\u500b\u81ea\u52d5\u5b8c\u6210\u8349\u7a3f\uff0c\u5305\u62ec GitHub \u7684\u7a0b\u5f0f\u78bc\u5b8c\u6210\u3001Gmail \u7684\u667a\u6167\u64b0\u5beb\uff0c\u4ee5\u53ca Apple \u7684\u8a0a\u606f\u81ea\u52d5\u5efa\u8b70\u3002\u5728\u5e95\u5c64\uff0c\u8a9e\u8a00\u6a21\u578b\u6703\u57f7\u884c\u81ea\u8ff4\u6b78\u63a8\u8ad6\uff0c\u63d0\u4f9b\u8349\u7a3f\u4f86\u652f\u63f4\u6b64\u529f\u80fd\u3002\u56e0\u6b64\uff0c\u63d0\u4f9b $k$ \u500b\u8349\u7a3f\u7d66\u4f7f\u7528\u8005\u9700\u8981\u57f7\u884c\u6602\u8cb4\u7684\u8a9e\u8a00\u6a21\u578b $k$ \u6b21\u3002\u70ba\u4e86\u6e1b\u8f15\u57f7\u884c $k$ \u6b21\u63a8\u8ad6\u7684\u904b\u7b97\u6210\u672c\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u758a\u52a0\u89e3\u78bc\uff0c\u4e00\u7a2e\u65b0\u7684\u89e3\u78bc\u6f14\u7b97\u6cd5\uff0c\u5b83\u4ee5\u4e00\u6b21\u81ea\u8ff4\u6b78\u63a8\u8ad6\u7684\u904b\u7b97\u6210\u672c\u7522\u751f $k$ \u500b\u8349\u7a3f\u3002\u6211\u5011\u900f\u904e\u5c07 $k$ \u500b\u8349\u7a3f\u4e2d\u6700\u65b0\u7684 token \u5d4c\u5165\u7684\u758a\u52a0\u4f5c\u70ba\u8f38\u5165\uff0c\u63d0\u4f9b\u7d66\u8a9e\u8a00\u6a21\u578b\u7684\u4e0b\u4e00\u500b\u89e3\u78bc\u6b65\u9a5f\uff0c\u4f86\u9054\u6210\u6b64\u76ee\u7684\u3002\u5728\u6bcf\u500b\u63a8\u8ad6\u6b65\u9a5f\u4e2d\uff0c\u6211\u5011\u5c07 $k$ \u500b\u8349\u7a3f\u8207\u524d $k$ \u500b token \u7d50\u5408\uff0c\u4ee5\u53d6\u5f97 $k^2$ \u500b\u65b0\u8349\u7a3f\uff0c\u4e26\u5feb\u53d6 $k$ \u500b\u6700\u53ef\u80fd\u7684\u9078\u9805\uff0c\u4f7f\u7528 n-gram \u63d2\u503c\u6cd5\uff0c\u4ee5\u6700\u5c0f\u7684\u904b\u7b97\u958b\u92b7\u4f86\u904e\u6ffe\u6389\u4e0d\u9023\u8cab\u7684\u7522\u751f\u7d50\u679c\u3002\u6211\u5011\u7684\u5be6\u9a57\u986f\u793a\uff0c\u758a\u52a0\u89e3\u78bc\u7522\u751f\u7684 $k$ \u500b\u8349\u7a3f\u81f3\u5c11\u8207\u6838\u53d6\u6a23\u548c\u8caa\u5a6a\u89e3\u78bc\u4e00\u6a23\u9023\u8cab\u4e14\u771f\u5be6\uff0c\u540c\u6642\u5c0d\u65bc $k\\ge3$ \u81f3\u5c11\u5feb\u4e0a $2.44$ \u500d\u3002\u5728\u904b\u7b97\u6b63\u898f\u5316\u7684\u8a2d\u5b9a\u4e2d\uff0c\u4f7f\u7528\u8005\u8a55\u4f30\u660e\u986f\u504f\u597d\u758a\u52a0\u89e3\u78bc\u7522\u751f\u7684\u6587\u5b57\uff0c\u52dd\u904e\u6838\u53d6\u6a23\u3002\u7a0b\u5f0f\u78bc\u548c\u66f4\u591a\u7bc4\u4f8b\u5df2\u5728 https://github.com/RAIVNLab/SuperposedDecoding \u958b\u6e90\u3002", "author": "Ethan Shen et.al.", "authors": "Ethan Shen, Alan Fan, Sarah M Pratt, Jae Sung Park, Matthew Wallingford, Sham M. Kakade, Ari Holtzman, Ranjay Krishna, Ali Farhadi, Aditya Kusupati", "id": "2405.18400v2", "paper_url": "http://arxiv.org/abs/2405.18400v2", "repo": "https://github.com/raivnlab/superposeddecoding"}}