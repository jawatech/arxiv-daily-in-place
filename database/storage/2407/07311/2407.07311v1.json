{"2407.07311": {"publish_time": "2024-07-10", "title": "ViTime: A Visual Intelligence-Based Foundation Model for Time Series Forecasting", "paper_summary": "The success of large pretrained models in natural language processing (NLP)\nand computer vision (CV) has opened new avenues for constructing foundation\nmodels for time series forecasting (TSF). Traditional TSF foundation models\nrely heavily on numerical data fitting. In contrast, the human brain is\ninherently skilled at processing visual information, prefer predicting future\ntrends by observing visualized sequences. From a biomimetic perspective,\nutilizing models to directly process numerical sequences might not be the most\neffective route to achieving Artificial General Intelligence (AGI). This paper\nproposes ViTime, a novel Visual Intelligence-based foundation model for TSF.\nViTime overcomes the limitations of numerical time series data fitting by\nutilizing visual data processing paradigms and employs a innovative data\nsynthesis method during training, called Real Time Series (RealTS). Experiments\non a diverse set of previously unseen forecasting datasets demonstrate that\nViTime achieves state-of-the-art zero-shot performance, even surpassing the\nbest individually trained supervised models in some situations. These findings\nsuggest that visual intelligence can significantly enhance time series analysis\nand forecasting, paving the way for more advanced and versatile models in the\nfield. The code for our framework is accessible at\nhttps://github.com/IkeYang/ViTime.", "paper_summary_zh": "\u5927\u578b\u9810\u8a13\u7df4\u6a21\u578b\u5728\u81ea\u7136\u8a9e\u8a00\u8655\u7406 (NLP) \u548c\u96fb\u8166\u8996\u89ba (CV) \u4e2d\u7684\u6210\u529f\uff0c\u70ba\u5efa\u69cb\u6642\u9593\u5e8f\u5217\u9810\u6e2c (TSF) \u7684\u57fa\u790e\u6a21\u578b\u958b\u555f\u4e86\u65b0\u9014\u5f91\u3002\u50b3\u7d71\u7684 TSF \u57fa\u790e\u6a21\u578b\u56b4\u91cd\u4f9d\u8cf4\u6578\u5b57\u8cc7\u6599\u64ec\u5408\u3002\u76f8\u53cd\u5730\uff0c\u4eba\u8166\u5929\u751f\u64c5\u9577\u8655\u7406\u8996\u89ba\u8cc7\u8a0a\uff0c\u504f\u597d\u900f\u904e\u89c0\u5bdf\u8996\u89ba\u5316\u5e8f\u5217\u4f86\u9810\u6e2c\u672a\u4f86\u8da8\u52e2\u3002\u5f9e\u4eff\u751f\u5b78\u7684\u89d2\u5ea6\u4f86\u770b\uff0c\u4f7f\u7528\u6a21\u578b\u76f4\u63a5\u8655\u7406\u6578\u5b57\u5e8f\u5217\u53ef\u80fd\u4e0d\u662f\u5be6\u73fe\u4eba\u5de5\u901a\u7528\u667a\u6167 (AGI) \u7684\u6700\u6709\u6548\u9014\u5f91\u3002\u672c\u6587\u63d0\u51fa ViTime\uff0c\u4e00\u7a2e\u57fa\u65bc\u8996\u89ba\u667a\u6167\u7684\u65b0\u578b TSF \u57fa\u790e\u6a21\u578b\u3002ViTime \u900f\u904e\u5229\u7528\u8996\u89ba\u8cc7\u6599\u8655\u7406\u7bc4\u4f8b\uff0c\u514b\u670d\u4e86\u6578\u5b57\u6642\u9593\u5e8f\u5217\u8cc7\u6599\u64ec\u5408\u7684\u9650\u5236\uff0c\u4e26\u5728\u8a13\u7df4\u671f\u9593\u63a1\u7528\u5275\u65b0\u7684\u8cc7\u6599\u5408\u6210\u65b9\u6cd5\uff0c\u7a31\u70ba Real Time Series (RealTS)\u3002\u5728\u5404\u7a2e\u5148\u524d\u672a\u898b\u904e\u7684\u9810\u6e2c\u8cc7\u6599\u96c6\u4e0a\u9032\u884c\u7684\u5be6\u9a57\u8b49\u660e\uff0cViTime \u9054\u5230\u4e86\u6700\u5148\u9032\u7684\u96f6\u6b21\u5b78\u7fd2\u6548\u80fd\uff0c\u751a\u81f3\u5728\u67d0\u4e9b\u60c5\u6cc1\u4e0b\u8d85\u8d8a\u4e86\u500b\u5225\u8a13\u7df4\u7684\u6700\u4f73\u76e3\u7763\u6a21\u578b\u3002\u9019\u4e9b\u767c\u73fe\u8868\u660e\uff0c\u8996\u89ba\u667a\u6167\u53ef\u4ee5\u986f\u8457\u589e\u5f37\u6642\u9593\u5e8f\u5217\u5206\u6790\u548c\u9810\u6e2c\uff0c\u70ba\u8a72\u9818\u57df\u66f4\u5148\u9032\u4e14\u591a\u529f\u80fd\u7684\u6a21\u578b\u92ea\u5e73\u9053\u8def\u3002\u6211\u5011\u67b6\u69cb\u7684\u7a0b\u5f0f\u78bc\u53ef\u65bc https://github.com/IkeYang/ViTime \u53d6\u5f97\u3002", "author": "Luoxiao Yang et.al.", "authors": "Luoxiao Yang, Yun Wang, Xinqi Fan, Israel Cohen, Yue Zhao, Zijun Zhang", "id": "2407.07311v1", "paper_url": "http://arxiv.org/abs/2407.07311v1", "repo": "https://github.com/ikeyang/vitime"}}