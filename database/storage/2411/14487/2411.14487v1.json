{"2411.14487": {"publish_time": "2024-11-20", "title": "Ensuring Safety and Trust: Analyzing the Risks of Large Language Models in Medicine", "paper_summary": "The remarkable capabilities of Large Language Models (LLMs) make them\nincreasingly compelling for adoption in real-world healthcare applications.\nHowever, the risks associated with using LLMs in medical applications have not\nbeen systematically characterized. We propose using five key principles for\nsafe and trustworthy medical AI: Truthfulness, Resilience, Fairness,\nRobustness, and Privacy, along with ten specific aspects. Under this\ncomprehensive framework, we introduce a novel MedGuard benchmark with 1,000\nexpert-verified questions. Our evaluation of 11 commonly used LLMs shows that\nthe current language models, regardless of their safety alignment mechanisms,\ngenerally perform poorly on most of our benchmarks, particularly when compared\nto the high performance of human physicians. Despite recent reports indicate\nthat advanced LLMs like ChatGPT can match or even exceed human performance in\nvarious medical tasks, this study underscores a significant safety gap,\nhighlighting the crucial need for human oversight and the implementation of AI\nsafety guardrails.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u64c1\u6709\u975e\u51e1\u7684\u80fd\u529b\uff0c\u4f7f\u5176\u5728\u5be6\u969b\u91ab\u7642\u4fdd\u5065\u61c9\u7528\u4e2d\u8d8a\u4f86\u8d8a\u5f15\u4eba\u6ce8\u76ee\u3002\n\u7136\u800c\uff0c\u5728\u91ab\u7642\u61c9\u7528\u4e2d\u4f7f\u7528 LLM \u76f8\u95dc\u7684\u98a8\u96aa\u5c1a\u672a\u5f97\u5230\u7cfb\u7d71\u6027\u7684\u63cf\u8ff0\u3002\u6211\u5011\u5efa\u8b70\u4f7f\u7528\u4e94\u9805\u95dc\u9375\u539f\u5247\uff0c\u4ee5\u78ba\u4fdd\u91ab\u7642 AI \u7684\u5b89\u5168\u548c\u53ef\u4fe1\u8cf4\uff1a\u771f\u5be6\u6027\u3001\u5f48\u6027\u3001\u516c\u5e73\u6027\u3001\u7a69\u5065\u6027\u548c\u96b1\u79c1\uff0c\u4ee5\u53ca\u5341\u500b\u5177\u9ad4\u65b9\u9762\u3002\u5728\u9019\u500b\u5168\u9762\u7684\u67b6\u69cb\u4e0b\uff0c\u6211\u5011\u5f15\u5165\u4e86\u4e00\u500b\u65b0\u7684 MedGuard \u57fa\u6e96\uff0c\u5176\u4e2d\u5305\u542b 1,000 \u500b\u7531\u5c08\u5bb6\u9a57\u8b49\u7684\u554f\u984c\u3002\u6211\u5011\u5c0d 11 \u500b\u5e38\u7528 LLM \u7684\u8a55\u4f30\u8868\u660e\uff0c\u7121\u8ad6\u5176\u5b89\u5168\u5c0d\u9f4a\u6a5f\u5236\u5982\u4f55\uff0c\u7576\u524d\u7684\u8a9e\u8a00\u6a21\u578b\u5728\u6211\u5011\u5927\u591a\u6578\u57fa\u6e96\u6e2c\u8a66\u4e2d\u8868\u73fe\u666e\u904d\u4e0d\u4f73\uff0c\u7279\u5225\u662f\u8207\u4eba\u985e\u91ab\u751f\u7684\u9ad8\u8868\u73fe\u76f8\u6bd4\u6642\u3002\u5118\u7ba1\u6700\u8fd1\u7684\u5831\u544a\u8868\u660e\uff0c\u50cf ChatGPT \u9019\u6a23\u7684\u5148\u9032 LLM \u5728\u5404\u7a2e\u91ab\u7642\u4efb\u52d9\u4e2d\u53ef\u4ee5\u9054\u5230\u6216\u751a\u81f3\u8d85\u904e\u4eba\u985e\u7684\u8868\u73fe\uff0c\u4f46\u9019\u9805\u7814\u7a76\u5f37\u8abf\u4e86\u4e00\u500b\u91cd\u5927\u7684\u5b89\u5168\u5dee\u8ddd\uff0c\u7a81\u986f\u4e86\u4eba\u985e\u76e3\u7763\u548c\u5be6\u65bd AI \u5b89\u5168\u8b77\u6b04\u7684\u95dc\u9375\u9700\u6c42\u3002", "author": "Yifan Yang et.al.", "authors": "Yifan Yang, Qiao Jin, Robert Leaman, Xiaoyu Liu, Guangzhi Xiong, Maame Sarfo-Gyamfi, Changlin Gong, Santiago Ferri\u00e8re-Steinert, W. John Wilbur, Xiaojun Li, Jiaxin Yuan, Bang An, Kelvin S. Castro, Francisco Erramuspe \u00c1lvarez, Mat\u00edas Stockle, Aidong Zhang, Furong Huang, Zhiyong Lu", "id": "2411.14487v1", "paper_url": "http://arxiv.org/abs/2411.14487v1", "repo": "null"}}