{"2406.13433": {"publish_time": "2024-06-19", "title": "Certificates of Differential Privacy and Unlearning for Gradient-Based Training", "paper_summary": "Proper data stewardship requires that model owners protect the privacy of\nindividuals' data used during training. Whether through anonymization with\ndifferential privacy or the use of unlearning in non-anonymized settings, the\ngold-standard techniques for providing privacy guarantees can come with\nsignificant performance penalties or be too weak to provide practical\nassurances. In part, this is due to the fact that the guarantee provided by\ndifferential privacy represents the worst-case privacy leakage for any\nindividual, while the true privacy leakage of releasing the prediction for a\ngiven individual might be substantially smaller or even, as we show,\nnon-existent. This work provides a novel framework based on convex relaxations\nand bounds propagation that can compute formal guarantees (certificates) that\nreleasing specific predictions satisfies $\\epsilon=0$ privacy guarantees or do\nnot depend on data that is subject to an unlearning request. Our framework\noffers a new verification-centric approach to privacy and unlearning\nguarantees, that can be used to further engender user trust with tighter\nprivacy guarantees, provide formal proofs of robustness to certain membership\ninference attacks, identify potentially vulnerable records, and enhance current\nunlearning approaches. We validate the effectiveness of our approach on tasks\nfrom financial services, medical imaging, and natural language processing.", "paper_summary_zh": "\u9069\u7576\u7684\u8cc7\u6599\u7ba1\u7406\u8981\u6c42\u6a21\u578b\u64c1\u6709\u8005\u4fdd\u8b77\u500b\u4eba\u5728\u8a13\u7df4\u671f\u9593\u6240\u4f7f\u7528\u8cc7\u6599\u7684\u96b1\u79c1\u3002\u7121\u8ad6\u662f\u900f\u904e\u5177\u6709\u5dee\u5206\u96b1\u79c1\u7684\u533f\u540d\u5316\u6216\u662f\u5728\u975e\u533f\u540d\u5316\u8a2d\u5b9a\u4e2d\u4f7f\u7528\u5fd8\u8a18\uff0c\u63d0\u4f9b\u96b1\u79c1\u4fdd\u8b49\u7684\u9ec3\u91d1\u6a19\u6e96\u6280\u8853\u90fd\u53ef\u80fd\u4f34\u96a8\u8457\u986f\u8457\u7684\u6548\u80fd\u640d\u5931\uff0c\u6216\u904e\u65bc\u8584\u5f31\u800c\u7121\u6cd5\u63d0\u4f9b\u5be6\u969b\u4fdd\u8b49\u3002\u90e8\u5206\u539f\u56e0\u5728\u65bc\uff0c\u5dee\u5206\u96b1\u79c1\u63d0\u4f9b\u7684\u4fdd\u8b49\u4ee3\u8868\u4efb\u4f55\u500b\u4eba\u7684\u6700\u5dee\u60c5\u6cc1\u96b1\u79c1\u6d29\u6f0f\uff0c\u800c\u91cb\u51fa\u7d66\u5b9a\u500b\u4eba\u9810\u6e2c\u7684\u771f\u5be6\u96b1\u79c1\u6d29\u6f0f\u53ef\u80fd\u5927\u5e45\u6e1b\u5c11\uff0c\u751a\u81f3\u5982\u6211\u5011\u6240\u5c55\u793a\u7684\uff0c\u4e0d\u5b58\u5728\u3002\u9019\u9805\u5de5\u4f5c\u63d0\u4f9b\u4e00\u500b\u65b0\u7684\u67b6\u69cb\uff0c\u57fa\u65bc\u51f8\u5f1b\u8c6b\u548c\u908a\u754c\u50b3\u64ad\uff0c\u53ef\u4ee5\u8a08\u7b97\u5f62\u5f0f\u5316\u4fdd\u8b49\uff08\u8b49\u660e\uff09\uff0c\u91cb\u51fa\u7279\u5b9a\u9810\u6e2c\u6eff\u8db3 $\\epsilon=0$ \u96b1\u79c1\u4fdd\u8b49\uff0c\u6216\u4e0d\u4f9d\u8cf4\u65bc\u53d7\u5fd8\u8a18\u8981\u6c42\u7d04\u675f\u7684\u8cc7\u6599\u3002\u6211\u5011\u7684\u67b6\u69cb\u63d0\u4f9b\u4e00\u500b\u65b0\u7684\u4ee5\u9a57\u8b49\u70ba\u4e2d\u5fc3\u7684\u96b1\u79c1\u548c\u5fd8\u8a18\u4fdd\u8b49\u65b9\u6cd5\uff0c\u53ef\u7528\u65bc\u9032\u4e00\u6b65\u63d0\u5347\u4f7f\u7528\u8005\u5c0d\u66f4\u56b4\u683c\u96b1\u79c1\u4fdd\u8b49\u7684\u4fe1\u4efb\uff0c\u63d0\u4f9b\u5c0d\u7279\u5b9a\u6210\u54e1\u63a8\u8ad6\u653b\u64ca\u7684\u6b63\u5f0f\u7a69\u5065\u6027\u8b49\u660e\uff0c\u8b58\u5225\u6f5b\u5728\u7684\u8106\u5f31\u8a18\u9304\uff0c\u4e26\u589e\u5f37\u76ee\u524d\u7684\u5fd8\u8a18\u65b9\u6cd5\u3002\u6211\u5011\u5728\u91d1\u878d\u670d\u52d9\u3001\u91ab\u5b78\u5f71\u50cf\u548c\u81ea\u7136\u8a9e\u8a00\u8655\u7406\u7684\u4efb\u52d9\u4e2d\u9a57\u8b49\u4e86\u6211\u5011\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "author": "Matthew Wicker et.al.", "authors": "Matthew Wicker, Philip Sosnin, Adrianna Janik, Mark N. M\u00fcller, Adrian Weller, Calvin Tsay", "id": "2406.13433v1", "paper_url": "http://arxiv.org/abs/2406.13433v1", "repo": "null"}}