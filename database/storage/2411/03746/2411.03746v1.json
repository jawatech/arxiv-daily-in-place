{"2411.03746": {"publish_time": "2024-11-06", "title": "Optimal Defenses Against Gradient Reconstruction Attacks", "paper_summary": "Federated Learning (FL) is designed to prevent data leakage through\ncollaborative model training without centralized data storage. However, it\nremains vulnerable to gradient reconstruction attacks that recover original\ntraining data from shared gradients. To optimize the trade-off between data\nleakage and utility loss, we first derive a theoretical lower bound of\nreconstruction error (among all attackers) for the two standard methods: adding\nnoise, and gradient pruning. We then customize these two defenses to be\nparameter- and model-specific and achieve the optimal trade-off between our\nobtained reconstruction lower bound and model utility. Experimental results\nvalidate that our methods outperform Gradient Noise and Gradient Pruning by\nprotecting the training data better while also achieving better utility.", "paper_summary_zh": "\u806f\u90a6\u5b78\u7fd2 (FL) \u65e8\u5728\u900f\u904e\u5354\u4f5c\u6a21\u578b\u8a13\u7df4\u4f86\u9632\u6b62\u8cc7\u6599\u5916\u6d29\uff0c\u800c\u7121\u9700\u96c6\u4e2d\u5f0f\u8cc7\u6599\u5132\u5b58\u3002\u4f46\u662f\uff0c\u5b83\u4ecd\u7136\u5bb9\u6613\u53d7\u5230\u68af\u5ea6\u91cd\u5efa\u653b\u64ca\uff0c\u8a72\u653b\u64ca\u6703\u5f9e\u5171\u4eab\u68af\u5ea6\u4e2d\u6062\u5fa9\u539f\u59cb\u8a13\u7df4\u8cc7\u6599\u3002\u70ba\u4e86\u6700\u4f73\u5316\u8cc7\u6599\u5916\u6d29\u548c\u6548\u7528\u640d\u5931\u4e4b\u9593\u7684\u6298\u8877\uff0c\u6211\u5011\u9996\u5148\u91dd\u5c0d\u9019\u5169\u7a2e\u6a19\u6e96\u65b9\u6cd5\u63a8\u5c0e\u51fa\u91cd\u5efa\u8aa4\u5dee\u7684\u7406\u8ad6\u4e0b\u9650\uff08\u5728\u6240\u6709\u653b\u64ca\u8005\u4e2d\uff09\uff1a\u52a0\u5165\u96dc\u8a0a\u548c\u68af\u5ea6\u4fee\u526a\u3002\u7136\u5f8c\uff0c\u6211\u5011\u81ea\u8a02\u9019\u5169\u7a2e\u9632\u79a6\u63aa\u65bd\uff0c\u4f7f\u5176\u7279\u5b9a\u65bc\u53c3\u6578\u548c\u6a21\u578b\uff0c\u4e26\u5728\u6211\u5011\u7372\u5f97\u7684\u91cd\u5efa\u4e0b\u9650\u548c\u6a21\u578b\u6548\u7528\u4e4b\u9593\u53d6\u5f97\u6700\u4f73\u6298\u8877\u3002\u5be6\u9a57\u7d50\u679c\u9a57\u8b49\u6211\u5011\u7684\u6a21\u578b\u900f\u904e\u66f4\u4f73\u5730\u4fdd\u8b77\u8a13\u7df4\u8cc7\u6599\uff0c\u540c\u6642\u4e5f\u80fd\u9054\u5230\u66f4\u597d\u7684\u6548\u7528\uff0c\u5f9e\u800c\u512a\u65bc\u68af\u5ea6\u96dc\u8a0a\u548c\u68af\u5ea6\u4fee\u526a\u3002", "author": "Yuxiao Chen et.al.", "authors": "Yuxiao Chen, Gamze G\u00fcrsoy, Qi Lei", "id": "2411.03746v1", "paper_url": "http://arxiv.org/abs/2411.03746v1", "repo": "https://github.com/cyx78/optimal_defenses_against_gradient_reconstruction_attacks"}}