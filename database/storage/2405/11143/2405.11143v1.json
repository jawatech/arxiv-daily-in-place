{"2405.11143": {"publish_time": "2024-05-20", "title": "OpenRLHF: An Easy-to-use, Scalable and High-performance RLHF Framework", "paper_summary": "As large language models (LLMs) continue to grow by scaling laws,\nreinforcement learning from human feedback (RLHF) has gained significant\nattention due to its outstanding performance. However, unlike pretraining or\nfine-tuning a single model, scaling reinforcement learning from human feedback\n(RLHF) for training large language models poses coordination challenges across\nfour models. We present OpenRLHF, an open-source framework enabling efficient\nRLHF scaling. Unlike existing RLHF frameworks that co-locate four models on the\nsame GPUs, OpenRLHF re-designs scheduling for the models beyond 70B parameters\nusing Ray, vLLM, and DeepSpeed, leveraging improved resource utilization and\ndiverse training approaches. Integrating seamlessly with Hugging Face, OpenRLHF\nprovides an out-of-the-box solution with optimized algorithms and launch\nscripts, which ensures user-friendliness. OpenRLHF implements RLHF, DPO,\nrejection sampling, and other alignment techniques. Empowering state-of-the-art\nLLM development, OpenRLHF's code is available at\nhttps://github.com/OpenLLMAI/OpenRLHF.", "paper_summary_zh": "\u96a8\u8457\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7e7c\u7e8c\u900f\u904e\u898f\u6a21\u6cd5\u5247\u6210\u9577\uff0c\n\u5f9e\u4eba\u985e\u56de\u994b\u4e2d\u9032\u884c\u5f37\u5316\u5b78\u7fd2 (RLHF) \u56e0\u70ba\u5176\u5091\u51fa\u7684\u8868\u73fe\u800c\u53d7\u5230\u5ee3\u6cdb\u95dc\u6ce8\u3002\n\u7136\u800c\uff0c\u8207\u9810\u8a13\u7df4\u6216\u5fae\u8abf\u55ae\u4e00\u6a21\u578b\u4e0d\u540c\uff0c\u91dd\u5c0d\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u8a13\u7df4\u800c\u5f9e\u4eba\u985e\u56de\u994b\u4e2d\u9032\u884c\u5f37\u5316\u5b78\u7fd2 (RLHF) \u6703\u5728\u56db\u500b\u6a21\u578b\u9593\u9020\u6210\u5354\u8abf\u4e0a\u7684\u6311\u6230\u3002\u6211\u5011\u63d0\u51fa OpenRLHF\uff0c\u4e00\u500b\u958b\u653e\u539f\u59cb\u78bc\u67b6\u69cb\uff0c\u53ef\u5be6\u73fe\u9ad8\u6548\u80fd\u7684 RLHF \u64f4\u5145\u3002\u8207\u5c07\u56db\u500b\u6a21\u578b\u5171\u7f6e\u65bc\u540c\u4e00 GPU \u4e0a\u7684\u73fe\u6709 RLHF \u67b6\u69cb\u4e0d\u540c\uff0cOpenRLHF \u900f\u904e Ray\u3001vLLM \u548c DeepSpeed \u91cd\u65b0\u8a2d\u8a08\u8d85\u904e 70B \u53c3\u6578\u7684\u6a21\u578b\u6392\u7a0b\uff0c\u5584\u7528\u6539\u5584\u7684\u8cc7\u6e90\u5229\u7528\u7387\u548c\u591a\u6a23\u5316\u7684\u8a13\u7df4\u65b9\u6cd5\u3002OpenRLHF \u8207 Hugging Face \u7121\u7e2b\u6574\u5408\uff0c\u63d0\u4f9b\u958b\u7bb1\u5373\u7528\u7684\u89e3\u6c7a\u65b9\u6848\uff0c\u5305\u542b\u6700\u4f73\u5316\u6f14\u7b97\u6cd5\u548c\u555f\u52d5\u6307\u4ee4\u78bc\uff0c\u78ba\u4fdd\u4f7f\u7528\u8005\u53cb\u5584\u3002OpenRLHF \u5be6\u4f5c RLHF\u3001DPO\u3001\u62d2\u7d55\u63a1\u6a23\u548c\u5176\u4ed6\u5c0d\u9f4a\u6280\u8853\u3002OpenRLHF \u7684\u7a0b\u5f0f\u78bc\u8ce6\u80fd\u6700\u5148\u9032\u7684 LLM \u958b\u767c\uff0c\u53ef\u65bc https://github.com/OpenLLMAI/OpenRLHF \u53d6\u5f97\u3002", "author": "Jian Hu et.al.", "authors": "Jian Hu, Xibin Wu, Weixun Wang, Xianyu, Dehao Zhang, Yu Cao", "id": "2405.11143v1", "paper_url": "http://arxiv.org/abs/2405.11143v1", "repo": "https://github.com/OpenLLMAI/OpenRLHF"}}