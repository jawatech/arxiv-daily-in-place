{"2412.18196": {"publish_time": "2024-12-24", "title": "Robustness-aware Automatic Prompt Optimization", "paper_summary": "The performance of Large Language Models (LLMs) is based on the quality of\nthe prompts and the semantic and structural integrity information of the input\ndata. However, current prompt generation methods primarily focus on generating\nprompts for clean input data, often overlooking the impact of perturbed inputs\non prompt performance. To address this limitation, we propose BATprompt (By\nAdversarial Training prompt), a novel method for prompt generation designed to\nwithstand input perturbations (such as typos in the input). Inspired by\nadversarial training techniques, BATprompt demonstrates strong performance on a\nvariety of perturbed tasks through a two-step process: adversarial perturbation\nand iterative optimization on unperturbed input via LLM. Unlike conventional\nadversarial attack methods, BATprompt avoids reliance on real gradients or\nmodel parameters. Instead, it leverages the advanced reasoning, language\nunderstanding and self reflection capabilities of LLMs to simulate gradients,\nguiding the generation of adversarial perturbations and optimizing prompt\nperformance. In our experiments, we evaluate BATprompt on multiple datasets\nacross both language understanding and generation tasks. The results indicate\nthat BATprompt outperforms existing prompt generation methods, delivering\nsuperior robustness and performance under diverse perturbation scenarios.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u6548\u80fd\u53d6\u6c7a\u65bc\u63d0\u793a\u7684\u54c1\u8cea\uff0c\u4ee5\u53ca\u8f38\u5165\u8cc7\u6599\u7684\u8a9e\u610f\u548c\u7d50\u69cb\u5b8c\u6574\u6027\u8cc7\u8a0a\u3002\u7136\u800c\uff0c\u76ee\u524d\u7684\u63d0\u793a\u7522\u751f\u65b9\u6cd5\u4e3b\u8981\u5c08\u6ce8\u65bc\u70ba\u4e7e\u6de8\u7684\u8f38\u5165\u8cc7\u6599\u7522\u751f\u63d0\u793a\uff0c\u5e38\u5e38\u5ffd\u7565\u64fe\u52d5\u8f38\u5165\u5c0d\u63d0\u793a\u6548\u80fd\u7684\u5f71\u97ff\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u9650\u5236\uff0c\u6211\u5011\u63d0\u51fa BATprompt\uff08\u5c0d\u6297\u8a13\u7df4\u63d0\u793a\uff09\uff0c\u9019\u662f\u4e00\u7a2e\u65b0\u7a4e\u7684\u63d0\u793a\u7522\u751f\u65b9\u6cd5\uff0c\u65e8\u5728\u627f\u53d7\u8f38\u5165\u64fe\u52d5\uff08\u4f8b\u5982\u8f38\u5165\u4e2d\u7684\u932f\u5b57\uff09\u3002\u53d7\u5230\u5c0d\u6297\u8a13\u7df4\u6280\u8853\u7684\u555f\u767c\uff0cBATprompt \u900f\u904e\u4e00\u500b\u5169\u6b65\u9a5f\u7684\u904e\u7a0b\u5728\u5404\u7a2e\u64fe\u52d5\u4efb\u52d9\u4e0a\u5c55\u73fe\u5f37\u5927\u7684\u6548\u80fd\uff1a\u5c0d\u6297\u64fe\u52d5\u548c\u900f\u904e LLM \u5c0d\u672a\u64fe\u52d5\u8f38\u5165\u9032\u884c\u53cd\u8986\u6700\u4f73\u5316\u3002\u8207\u50b3\u7d71\u7684\u5c0d\u6297\u653b\u64ca\u65b9\u6cd5\u4e0d\u540c\uff0cBATprompt \u907f\u514d\u4f9d\u8cf4\u771f\u5be6\u68af\u5ea6\u6216\u6a21\u578b\u53c3\u6578\u3002\u76f8\u53cd\u5730\uff0c\u5b83\u5229\u7528 LLM \u7684\u9032\u968e\u63a8\u7406\u3001\u8a9e\u8a00\u7406\u89e3\u548c\u81ea\u6211\u53cd\u7701\u80fd\u529b\u4f86\u6a21\u64ec\u68af\u5ea6\uff0c\u5f15\u5c0e\u5c0d\u6297\u64fe\u52d5\u7684\u7522\u751f\u4e26\u6700\u4f73\u5316\u63d0\u793a\u6548\u80fd\u3002\u5728\u6211\u5011\u7684\u5be6\u9a57\u4e2d\uff0c\u6211\u5011\u5728\u8de8\u8a9e\u8a00\u7406\u89e3\u548c\u7522\u751f\u4efb\u52d9\u7684\u591a\u500b\u8cc7\u6599\u96c6\u4e0a\u8a55\u4f30 BATprompt\u3002\u7d50\u679c\u8868\u660e\uff0cBATprompt \u512a\u65bc\u73fe\u6709\u7684\u63d0\u793a\u7522\u751f\u65b9\u6cd5\uff0c\u5728\u4e0d\u540c\u7684\u64fe\u52d5\u5834\u666f\u4e0b\u63d0\u4f9b\u5353\u8d8a\u7684\u7a69\u5065\u6027\u548c\u6548\u80fd\u3002", "author": "Zeru Shi et.al.", "authors": "Zeru Shi, Zhenting Wang, Yongye Su, Weidi Luo, Fan Yang, Yongfeng Zhang", "id": "2412.18196v1", "paper_url": "http://arxiv.org/abs/2412.18196v1", "repo": "https://github.com/vanpe20/BATprompt"}}