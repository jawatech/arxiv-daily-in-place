{"2410.23242": {"publish_time": "2024-10-30", "title": "A little less conversation, a little more action, please: Investigating the physical common-sense of LLMs in a 3D embodied environment", "paper_summary": "As general-purpose tools, Large Language Models (LLMs) must often reason\nabout everyday physical environments. In a question-and-answer capacity,\nunderstanding the interactions of physical objects may be necessary to give\nappropriate responses. Moreover, LLMs are increasingly used as reasoning\nengines in agentic systems, designing and controlling their action sequences.\nThe vast majority of research has tackled this issue using static benchmarks,\ncomprised of text or image-based questions about the physical world. However,\nthese benchmarks do not capture the complexity and nuance of real-life physical\nprocesses. Here we advocate for a second, relatively unexplored, approach:\n'embodying' the LLMs by granting them control of an agent within a 3D\nenvironment. We present the first embodied and cognitively meaningful\nevaluation of physical common-sense reasoning in LLMs. Our framework allows\ndirect comparison of LLMs with other embodied agents, such as those based on\nDeep Reinforcement Learning, and human and non-human animals. We employ the\nAnimal-AI (AAI) environment, a simulated 3D virtual laboratory, to study\nphysical common-sense reasoning in LLMs. For this, we use the AAI Testbed, a\nsuite of experiments that replicate laboratory studies with non-human animals,\nto study physical reasoning capabilities including distance estimation,\ntracking out-of-sight objects, and tool use. We demonstrate that\nstate-of-the-art multi-modal models with no finetuning can complete this style\nof task, allowing meaningful comparison to the entrants of the 2019 Animal-AI\nOlympics competition and to human children. Our results show that LLMs are\ncurrently outperformed by human children on these tasks. We argue that this\napproach allows the study of physical reasoning using ecologically valid\nexperiments drawn directly from cognitive science, improving the predictability\nand reliability of LLMs.", "paper_summary_zh": "\u4f5c\u70ba\u901a\u7528\u5de5\u5177\uff0c\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5fc5\u9808\u7d93\u5e38\u63a8\u8ad6\u65e5\u5e38\u7269\u7406\u74b0\u5883\u3002\u5728\u554f\u7b54\u80fd\u529b\u4e2d\uff0c\u4e86\u89e3\u7269\u7406\u7269\u9ad4\u7684\u4ea4\u4e92\u4f5c\u7528\u53ef\u80fd\u662f\u7d66\u51fa\u9069\u7576\u56de\u61c9\u6240\u5fc5\u9700\u7684\u3002\u6b64\u5916\uff0cLLM \u6b63\u5728\u8d8a\u4f86\u8d8a\u591a\u5730\u7528\u4f5c\u4ee3\u7406\u7cfb\u7d71\u4e2d\u7684\u63a8\u7406\u5f15\u64ce\uff0c\u8a2d\u8a08\u548c\u63a7\u5236\u5176\u52d5\u4f5c\u5e8f\u5217\u3002\u7d55\u5927\u591a\u6578\u7814\u7a76\u4f7f\u7528\u975c\u614b\u57fa\u6e96\u4f86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u9019\u4e9b\u57fa\u6e96\u5305\u542b\u6709\u95dc\u7269\u7406\u4e16\u754c\u7684\u57fa\u65bc\u6587\u672c\u6216\u5716\u50cf\u7684\u554f\u984c\u3002\u7136\u800c\uff0c\u9019\u4e9b\u57fa\u6e96\u4e26\u672a\u6355\u6349\u5230\u73fe\u5be6\u7269\u7406\u904e\u7a0b\u7684\u8907\u96dc\u6027\u548c\u7d30\u5fae\u5dee\u5225\u3002\u5728\u9019\u88e1\uff0c\u6211\u5011\u63d0\u5021\u7b2c\u4e8c\u7a2e\u76f8\u5c0d\u672a\u7d93\u63a2\u7d22\u7684\u65b9\u6cd5\uff1a\u201c\u5177\u8eab\u5316\u201d LLM\uff0c\u8b93\u5b83\u5011\u63a7\u5236 3D \u74b0\u5883\u4e2d\u7684\u4ee3\u7406\u3002\u6211\u5011\u63d0\u51fa\u4e86\u5c0d LLM \u4e2d\u7269\u7406\u5e38\u8b58\u63a8\u7406\u7684\u7b2c\u4e00\u500b\u5177\u8eab\u5316\u548c\u8a8d\u77e5\u6709\u610f\u7fa9\u7684\u8a55\u4f30\u3002\u6211\u5011\u7684\u6846\u67b6\u5141\u8a31\u5c07 LLM \u8207\u5176\u4ed6\u5177\u8eab\u5316\u4ee3\u7406\u9032\u884c\u76f4\u63a5\u6bd4\u8f03\uff0c\u4f8b\u5982\u57fa\u65bc\u6df1\u5ea6\u5f37\u5316\u5b78\u7fd2\u7684\u4ee3\u7406\uff0c\u4ee5\u53ca\u4eba\u985e\u548c\u975e\u4eba\u985e\u52d5\u7269\u3002\u6211\u5011\u63a1\u7528 Animal-AI (AAI) \u74b0\u5883\uff0c\u4e00\u500b\u6a21\u64ec\u7684 3D \u865b\u64ec\u5be6\u9a57\u5ba4\uff0c\u4f86\u7814\u7a76 LLM \u4e2d\u7684\u7269\u7406\u5e38\u8b58\u63a8\u7406\u3002\u70ba\u6b64\uff0c\u6211\u5011\u4f7f\u7528 AAI \u6e2c\u8a66\u5e73\u53f0\uff0c\u4e00\u7d44\u5be6\u9a57\uff0c\u8907\u88fd\u4e86\u5c0d\u975e\u4eba\u985e\u52d5\u7269\u7684\u5be6\u9a57\u5ba4\u7814\u7a76\uff0c\u4ee5\u7814\u7a76\u7269\u7406\u63a8\u7406\u80fd\u529b\uff0c\u5305\u62ec\u8ddd\u96e2\u4f30\u8a08\u3001\u8ffd\u8e64\u8996\u7dda\u5916\u7269\u9ad4\u548c\u5de5\u5177\u4f7f\u7528\u3002\u6211\u5011\u8b49\u660e\u4e86\u6c92\u6709\u5fae\u8abf\u7684\u6700\u65b0\u591a\u6a21\u614b\u6a21\u578b\u53ef\u4ee5\u5b8c\u6210\u9019\u7a2e\u98a8\u683c\u7684\u4efb\u52d9\uff0c\u5141\u8a31\u8207 2019 \u5e74\u52d5\u7269\u4eba\u5de5\u667a\u80fd\u5967\u6797\u5339\u514b\u7af6\u8cfd\u7684\u53c3\u8cfd\u8005\u548c\u4eba\u985e\u5152\u7ae5\u9032\u884c\u6709\u610f\u7fa9\u7684\u6bd4\u8f03\u3002\u6211\u5011\u7684\u7d50\u679c\u8868\u660e\uff0c\u5728\u9019\u4e9b\u4efb\u52d9\u4e0a\uff0c\u4eba\u985e\u5152\u7ae5\u76ee\u524d\u8868\u73fe\u512a\u65bc LLM\u3002\u6211\u5011\u8a8d\u70ba\uff0c\u9019\u7a2e\u65b9\u6cd5\u5141\u8a31\u4f7f\u7528\u76f4\u63a5\u5f9e\u8a8d\u77e5\u79d1\u5b78\u4e2d\u63d0\u53d6\u7684\u751f\u614b\u5b78\u4e0a\u6709\u6548\u5be6\u9a57\u4f86\u7814\u7a76\u7269\u7406\u63a8\u7406\uff0c\u5f9e\u800c\u63d0\u9ad8 LLM \u7684\u53ef\u9810\u6e2c\u6027\u548c\u53ef\u9760\u6027\u3002", "author": "Matteo G. Mecattaf et.al.", "authors": "Matteo G. Mecattaf, Ben Slater, Marko Te\u0161i\u0107, Jonathan Prunty, Konstantinos Voudouris, Lucy G. Cheke", "id": "2410.23242v1", "paper_url": "http://arxiv.org/abs/2410.23242v1", "repo": "null"}}