{"2410.17883": {"publish_time": "2024-10-23", "title": "Lightweight Neural App Control", "paper_summary": "This paper introduces a novel mobile phone control architecture, termed ``app\nagents\", for efficient interactions and controls across various Android apps.\nThe proposed Lightweight Multi-modal App Control (LiMAC) takes as input a\ntextual goal and a sequence of past mobile observations, such as screenshots\nand corresponding UI trees, to generate precise actions. To address the\ncomputational constraints inherent to smartphones, within LiMAC, we introduce a\nsmall Action Transformer (AcT) integrated with a fine-tuned vision-language\nmodel (VLM) for real-time decision-making and task execution. We evaluate LiMAC\non two open-source mobile control datasets, demonstrating the superior\nperformance of our small-form-factor approach against fine-tuned versions of\nopen-source VLMs, such as Florence2 and Qwen2-VL. It also significantly\noutperforms prompt engineering baselines utilising closed-source foundation\nmodels like GPT-4o. More specifically, LiMAC increases the overall action\naccuracy by up to 19% compared to fine-tuned VLMs, and up to 42% compared to\nprompt-engineering baselines.", "paper_summary_zh": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7a4e\u7684\u624b\u6a5f\u63a7\u5236\u67b6\u69cb\uff0c\u7a31\u70ba\u300c\u61c9\u7528\u7a0b\u5f0f\u4ee3\u7406\u300d\uff0c\u4ee5\u5728\u5404\u7a2e Android \u61c9\u7528\u7a0b\u5f0f\u4e2d\u9032\u884c\u6709\u6548\u7387\u7684\u4e92\u52d5\u548c\u63a7\u5236\u3002\u6240\u63d0\u51fa\u7684\u8f15\u91cf\u7d1a\u591a\u6a21\u614b\u61c9\u7528\u7a0b\u5f0f\u63a7\u5236 (LiMAC) \u5c07\u6587\u5b57\u76ee\u6a19\u548c\u4e00\u7cfb\u5217\u904e\u53bb\u7684\u624b\u6a5f\u89c0\u5bdf\u7d50\u679c\u4f5c\u70ba\u8f38\u5165\uff0c\u4f8b\u5982\u87a2\u5e55\u622a\u5716\u548c\u5c0d\u61c9\u7684 UI \u6a39\u72c0\u7d50\u69cb\uff0c\u4ee5\u7522\u751f\u7cbe\u78ba\u7684\u52d5\u4f5c\u3002\u70ba\u4e86\u8655\u7406\u667a\u6167\u578b\u624b\u6a5f\u56fa\u6709\u7684\u904b\u7b97\u9650\u5236\uff0c\u6211\u5011\u5728 LiMAC \u4e2d\u5f15\u5165\u4e86\u4e00\u500b\u5c0f\u578b\u52d5\u4f5c\u8f49\u63db\u5668 (AcT)\uff0c\u4e26\u6574\u5408\u4e86\u4e00\u500b\u5fae\u8abf\u5f8c\u7684\u8996\u89ba\u8a9e\u8a00\u6a21\u578b (VLM)\uff0c\u4ee5\u9032\u884c\u5373\u6642\u6c7a\u7b56\u548c\u4efb\u52d9\u57f7\u884c\u3002\u6211\u5011\u5728\u5169\u500b\u958b\u6e90\u7684\u624b\u6a5f\u63a7\u5236\u8cc7\u6599\u96c6\u4e0a\u8a55\u4f30 LiMAC\uff0c\u8b49\u660e\u6211\u5011\u7684\u5c0f\u578b\u5316\u65b9\u6cd5\u512a\u65bc\u5fae\u8abf\u5f8c\u7684\u958b\u6e90 VLM \u7248\u672c\uff0c\u4f8b\u5982 Florence2 \u548c Qwen2-VL\u3002\u5b83\u4e5f\u660e\u986f\u512a\u65bc\u5229\u7528\u5c01\u9589\u539f\u59cb\u78bc\u57fa\u790e\u6a21\u578b\uff08\u4f8b\u5982 GPT-4o\uff09\u7684\u63d0\u793a\u5de5\u7a0b\u57fa\u6e96\u3002\u66f4\u5177\u9ad4\u5730\u8aaa\uff0c\u8207\u5fae\u8abf\u5f8c\u7684 VLM \u76f8\u6bd4\uff0cLiMAC \u5c07\u6574\u9ad4\u52d5\u4f5c\u6e96\u78ba\u5ea6\u63d0\u9ad8\u4e86 19%\uff0c\u8207\u63d0\u793a\u5de5\u7a0b\u57fa\u6e96\u76f8\u6bd4\uff0c\u63d0\u9ad8\u4e86 42%\u3002", "author": "Filippos Christianos et.al.", "authors": "Filippos Christianos, Georgios Papoudakis, Thomas Coste, Jianye Hao, Jun Wang, Kun Shao", "id": "2410.17883v1", "paper_url": "http://arxiv.org/abs/2410.17883v1", "repo": "null"}}