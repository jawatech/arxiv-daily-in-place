
### Medical
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-08-13**|**Model Counting in the Wild**|Arijit Shaw et.al.|[2408.07059v1](http://arxiv.org/abs/2408.07059v1)|null|
|**2024-08-13**|**KAN You See It? KANs and Sentinel for Effective and Explainable Crop Field Segmentation**|Daniele Rege Cambrin et.al.|[2408.07040v1](http://arxiv.org/abs/2408.07040v1)|null|
|**2024-08-13**|**PathInsight: Instruction Tuning of Multimodal Datasets and Models for Intelligence Assisted Diagnosis in Histopathology**|Xiaomin Wu et.al.|[2408.07037v1](http://arxiv.org/abs/2408.07037v1)|null|
|**2024-08-13**|**Diagnosis extraction from unstructured Dutch echocardiogram reports using span- and document-level characteristic classification**|Bauke Arends et.al.|[2408.06930v1](http://arxiv.org/abs/2408.06930v1)|null|
|**2024-08-13**|**BMFT: Achieving Fairness via Bias-based Weight Masking Fine-tuning**|Yuyang Xue et.al.|[2408.06890v1](http://arxiv.org/abs/2408.06890v1)|null|
|**2024-08-12**|**Synthetic Patient-Physician Dialogue Generation from Clinical Notes Using LLM**|Trisha Das et.al.|[2408.06285v1](http://arxiv.org/abs/2408.06285v1)|null|
|**2024-08-12**|**Decentralized Health Intelligence Network (DHIN)**|Abraham Nash et.al.|[2408.06240v3](http://arxiv.org/abs/2408.06240v3)|null|
|**2024-08-12**|**ACCELERATION: Sequentially-scanning DECT Imaging Using High Temporal Resolution Image Reconstruction And Temporal Extrapolation**|Qiaoxin Li et.al.|[2408.06163v1](http://arxiv.org/abs/2408.06163v1)|null|
|**2024-08-12**|**Med42-v2: A Suite of Clinical LLMs**|Cl√©ment Christophe et.al.|[2408.06142v1](http://arxiv.org/abs/2408.06142v1)|null|
|**2024-08-11**|**Real-Time Drowsiness Detection Using Eye Aspect Ratio and Facial Landmark Detection**|Varun Shiva Krishna Rupani et.al.|[2408.05836v1](http://arxiv.org/abs/2408.05836v1)|null|
|**2024-08-11**|**TC-KANRecon: High-Quality and Accelerated MRI Reconstruction via Adaptive KAN Mechanisms and Intelligent Feature Scaling**|Ruiquan Ge et.al.|[2408.05705v1](http://arxiv.org/abs/2408.05705v1)|[link](https://github.com/lcbkmm/tc-kanrecon)|
|**2024-08-11**|**A Novel Momentum-Based Deep Learning Techniques for Medical Image Classification and Segmentation**|Koushik Biswas et.al.|[2408.05692v1](http://arxiv.org/abs/2408.05692v1)|null|
|**2024-08-10**|**Mitigating Metropolitan Carbon Emissions with Dynamic Eco-driving at Scale**|Vindula Jayawardana et.al.|[2408.05609v1](http://arxiv.org/abs/2408.05609v1)|null|
|**2024-08-09**|**Beyond the Eye: A Relational Model for Early Dementia Detection Using Retinal OCTA Images**|Shouyue Liu et.al.|[2408.05117v1](http://arxiv.org/abs/2408.05117v1)|null|
|**2024-08-09**|**RT-Surv: Improving Mortality Prediction After Radiotherapy with Large Language Model Structuring of Large-Scale Unstructured Electronic Health Records**|Sangjoon Park et.al.|[2408.05074v1](http://arxiv.org/abs/2408.05074v1)|null|
|**2024-08-09**|**CROCODILE: Causality aids RObustness via COntrastive DIsentangled LEarning**|Gianluca Carloni et.al.|[2408.04949v1](http://arxiv.org/abs/2408.04949v1)|[link](https://github.com/gianlucarloni/crocodile)|
|**2024-08-09**|**Unleashing Artificial Cognition: Integrating Multiple AI Systems**|Muntasir Adnan et.al.|[2408.04910v3](http://arxiv.org/abs/2408.04910v3)|[link](https://github.com/TheOpenSI/cognitive_AI_experiments)|
|**2024-08-09**|**Ensemble BERT: A student social network text sentiment classification model based on ensemble learning and BERT architecture**|Kai Jiang et.al.|[2408.04849v1](http://arxiv.org/abs/2408.04849v1)|null|
|**2024-08-08**|**Towards Synergistic Deep Learning Models for Volumetric Cirrhotic Liver Segmentation in MRIs**|Vandan Gorade et.al.|[2408.04491v1](http://arxiv.org/abs/2408.04491v1)|null|
|**2024-08-08**|**Advancing oncology with federated learning: transcending boundaries in breast, lung, and prostate cancer. A systematic review**|Anshu Ankolekar et.al.|[2408.05249v1](http://arxiv.org/abs/2408.05249v1)|null|
|**2024-08-08**|**Non-maximizing policies that fulfill multi-criterion aspirations in expectation**|Simon Dima et.al.|[2408.04385v1](http://arxiv.org/abs/2408.04385v1)|null|
|**2024-08-08**|**AI-Driven Chatbot for Intrusion Detection in Edge Networks: Enhancing Cybersecurity with Ethical User Consent**|Mugheez Asif et.al.|[2408.04281v1](http://arxiv.org/abs/2408.04281v1)|null|
|**2024-08-08**|**Dynamic Fog Computing for Enhanced LLM Execution in Medical Applications**|Philipp Zagar et.al.|[2408.04680v1](http://arxiv.org/abs/2408.04680v1)|null|
|**2024-08-08**|**The Data Addition Dilemma**|Judy Hanwen Shen et.al.|[2408.04154v1](http://arxiv.org/abs/2408.04154v1)|[link](https://github.com/the-chen-lab/data-addition-dilemma)|
|**2024-08-08**|**Enhancing Healthcare through Large Language Models: A Study on Medical Question Answering**|Haoran Yu et.al.|[2408.04138v1](http://arxiv.org/abs/2408.04138v1)|null|
|**2024-08-07**|**Can Rule-Based Insights Enhance LLMs for Radiology Report Classification? Introducing the RadPrompt Methodology**|Panagiotis Fytas et.al.|[2408.04121v1](http://arxiv.org/abs/2408.04121v1)|null|
|**2024-08-07**|**Multimodal Gender Fairness in Depression Prediction: Insights on Data from the USA & China**|Joseph Cameron et.al.|[2408.04026v1](http://arxiv.org/abs/2408.04026v1)|null|
|**2024-08-07**|**Inter-Series Transformer: Attending to Products in Time Series Forecasting**|Rares Cristian et.al.|[2408.03872v1](http://arxiv.org/abs/2408.03872v1)|null|
|**2024-08-07**|**HiQuE: Hierarchical Question Embedding Network for Multimodal Depression Detection**|Juho Jung et.al.|[2408.03648v1](http://arxiv.org/abs/2408.03648v1)|null|
|**2024-08-07**|**Improving the quality of Persian clinical text with a novel spelling correction system**|Seyed Mohammad Sadegh Dashti et.al.|[2408.03622v1](http://arxiv.org/abs/2408.03622v1)|null|
|**2024-08-06**|**Identifying treatment response subgroups in observational time-to-event data**|Vincent Jeanselme et.al.|[2408.03463v1](http://arxiv.org/abs/2408.03463v1)|null|
|**2024-08-06**|**Combining Diverse Information for Coordinated Action: Stochastic Bandit Algorithms for Heterogeneous Agents**|Lucia Gordon et.al.|[2408.03405v1](http://arxiv.org/abs/2408.03405v1)|[link](https://github.com/lgordon99/heterogeneous-stochastic-bandits)|
|**2024-08-06**|**MLC-GCN: Multi-Level Generated Connectome Based GCN for AD Analysis**|Wenqi Zhu et.al.|[2408.03358v1](http://arxiv.org/abs/2408.03358v1)|null|
|**2024-08-06**|**Personalizing Federated Instrument Segmentation with Visual Trait Priors in Robotic Surgery**|Jialang Xu et.al.|[2408.03208v1](http://arxiv.org/abs/2408.03208v1)|null|
|**2024-08-06**|**The Use of Large Language Models (LLM) for Cyber Threat Intelligence (CTI) in Cybercrime Forums**|Vanessa Clairoux-Trepanier et.al.|[2408.03354v2](http://arxiv.org/abs/2408.03354v2)|null|
|**2024-08-06**|**VizECGNet: Visual ECG Image Network for Cardiovascular Diseases Classification with Multi-Modal Training and Knowledge Distillation**|Ju-Hyeon Nam et.al.|[2408.02888v1](http://arxiv.org/abs/2408.02888v1)|null|
|**2024-08-05**|**VisionUnite: A Vision-Language Foundation Model for Ophthalmology Enhanced with Clinical Knowledge**|Zihan Li et.al.|[2408.02865v1](http://arxiv.org/abs/2408.02865v1)|[link](https://github.com/HUANGLIZI/VisionUnite)|
|**2024-08-05**|**Multistain Pretraining for Slide Representation Learning in Pathology**|Guillaume Jaume et.al.|[2408.02859v1](http://arxiv.org/abs/2408.02859v1)|[link](https://github.com/mahmoodlab/madeleine)|
|**2024-08-05**|**The Literature Review Network: An Explainable Artificial Intelligence for Systematic Literature Reviews, Meta-analyses, and Method Development**|Joshua Morriss et.al.|[2408.05239v1](http://arxiv.org/abs/2408.05239v1)|null|
|**2024-08-05**|**A Review on Organ Deformation Modeling Approaches for Reliable Surgical Navigation using Augmented Reality**|Zheng Han et.al.|[2408.02713v1](http://arxiv.org/abs/2408.02713v1)|null|
|**2024-08-05**|**Enhancing Medical Learning and Reasoning Systems: A Boxology-Based Comparative Analysis of Design Patterns**|Chi Him Ng et.al.|[2408.02709v1](http://arxiv.org/abs/2408.02709v1)|null|
|**2024-08-05**|**Bayesian Kolmogorov Arnold Networks (Bayesian_KANs): A Probabilistic Approach to Enhance Accuracy and Interpretability**|Masoud Muhammed Hassan et.al.|[2408.02706v1](http://arxiv.org/abs/2408.02706v1)|null|
|**2024-08-05**|**Active Sensing of Knee Osteoarthritis Progression with Reinforcement Learning**|Khanh Nguyen et.al.|[2408.02349v1](http://arxiv.org/abs/2408.02349v1)|null|
|**2024-08-04**|**MetaWearS: A Shortcut in Wearable Systems Lifecycle with Only a Few Shots**|Alireza Amirshahi et.al.|[2408.01988v1](http://arxiv.org/abs/2408.01988v1)|null|
|**2024-08-04**|**DiReCT: Diagnostic Reasoning for Clinical Notes via Large Language Models**|Bowen Wang et.al.|[2408.01933v2](http://arxiv.org/abs/2408.01933v2)|null|
|**2024-08-03**|**MALADE: Orchestration of LLM-powered Agents with Retrieval Augmented Generation for Pharmacovigilance**|Jihye Choi et.al.|[2408.01869v1](http://arxiv.org/abs/2408.01869v1)|[link](https://github.com/jihyechoi77/malade)|
|**2024-08-03**|**Building Trust in Mental Health Chatbots: Safety Metrics and LLM-Based Evaluation Tools**|Jung In Park et.al.|[2408.04650v1](http://arxiv.org/abs/2408.04650v1)|null|
|**2024-08-03**|**ST-SACLF: Style Transfer Informed Self-Attention Classifier for Bias-Aware Painting Classification**|Mridula Vijendran et.al.|[2408.01827v1](http://arxiv.org/abs/2408.01827v1)|null|
|**2024-08-03**|**Advancing Mental Health Pre-Screening: A New Custom GPT for Psychological Distress Assessment**|Jinwen Tang et.al.|[2408.01614v1](http://arxiv.org/abs/2408.01614v1)|null|
|**2024-08-02**|**Conformal Diffusion Models for Individual Treatment Effect Estimation and Inference**|Hengrui Cai et.al.|[2408.01582v1](http://arxiv.org/abs/2408.01582v1)|null|
|**2024-08-02**|**High-Throughput Phenotyping of Clinical Text Using Large Language Models**|Daniel B. Hier et.al.|[2408.01214v1](http://arxiv.org/abs/2408.01214v1)|null|
|**2024-08-02**|**Optimizing Variational Quantum Circuits Using Metaheuristic Strategies in Reinforcement Learning**|Michael K√∂lle et.al.|[2408.01187v1](http://arxiv.org/abs/2408.01187v1)|null|
|**2024-08-02**|**Six Dragons Fly Again: Reviving 15th-Century Korean Court Music with Transformers and Novel Encoding**|Danbinaerin Han et.al.|[2408.01096v1](http://arxiv.org/abs/2408.01096v1)|null|
|**2024-08-01**|**CIResDiff: A Clinically-Informed Residual Diffusion Model for Predicting Idiopathic Pulmonary Fibrosis Progression**|Caiwen Jiang et.al.|[2408.00938v2](http://arxiv.org/abs/2408.00938v2)|null|
|**2024-08-01**|**Parkinson's Disease Detection from Resting State EEG using Multi-Head Graph Structure Learning with Gradient Weighted Graph Attention Explanations**|Christopher Neves et.al.|[2408.00906v1](http://arxiv.org/abs/2408.00906v1)|null|
|**2024-08-01**|**UlRe-NeRF: 3D Ultrasound Imaging through Neural Rendering with Ultrasound Reflection Direction Parameterization**|Ziwen Guo et.al.|[2408.00860v2](http://arxiv.org/abs/2408.00860v2)|null|
|**2024-08-01**|**Segment anything model 2: an application to 2D and 3D medical images**|Haoyu Dong et.al.|[2408.00756v2](http://arxiv.org/abs/2408.00756v2)|null|
|**2024-08-01**|**Leaf Angle Estimation using Mask R-CNN and LETR Vision Transformer**|Venkat Margapuri et.al.|[2408.00749v1](http://arxiv.org/abs/2408.00749v1)|null|
|**2024-08-01**|**Improving Retrieval-Augmented Generation in Medicine with Iterative Follow-up Questions**|Guangzhi Xiong et.al.|[2408.00727v1](http://arxiv.org/abs/2408.00727v1)|null|
|**2024-08-01**|**Point-supervised Brain Tumor Segmentation with Box-prompted MedSAM**|Xiaofeng Liu et.al.|[2408.00706v1](http://arxiv.org/abs/2408.00706v1)|null|
|**2024-08-01**|**HBot: A Chatbot for Healthcare Applications in Traditional Chinese Medicine Based on Human Body 3D Visualization**|Bolin Zhang et.al.|[2408.00481v1](http://arxiv.org/abs/2408.00481v1)|null|
|**2024-08-01**|**Securing the Diagnosis of Medical Imaging: An In-depth Analysis of AI-Resistant Attacks**|Angona Biswas et.al.|[2408.00348v1](http://arxiv.org/abs/2408.00348v1)|null|
|**2024-08-01**|**Advancing Medical Image Segmentation: Morphology-Driven Learning with Diffusion Transformer**|Sungmin Kang et.al.|[2408.00347v1](http://arxiv.org/abs/2408.00347v1)|null|
|**2024-07-31**|**S-SYNTH: Knowledge-Based, Synthetic Generation of Skin Images**|Andrea Kim et.al.|[2408.00191v1](http://arxiv.org/abs/2408.00191v1)|null|
|**2024-07-31**|**A Taxonomy of Stereotype Content in Large Language Models**|Gandalf Nicolas et.al.|[2408.00162v1](http://arxiv.org/abs/2408.00162v1)|null|
|**2024-07-31**|**Preference-Based Abstract Argumentation for Case-Based Reasoning (with Appendix)**|Adam Gould et.al.|[2408.00108v2](http://arxiv.org/abs/2408.00108v2)|null|
|**2024-07-31**|**A Federated Learning-Friendly Approach for Parameter-Efficient Fine-Tuning of SAM in 3D Segmentation**|Mothilal Asokan et.al.|[2407.21739v1](http://arxiv.org/abs/2407.21739v1)|null|
|**2024-07-31**|**Synthetic Simplicity: Unveiling Bias in Medical Data Augmentation**|Krishan Agyakari Raja Babu et.al.|[2407.21674v1](http://arxiv.org/abs/2407.21674v1)|null|
|**2024-07-31**|**Quality Control for Radiology Report Generation Models via Auxiliary Auditing Components**|Hermione Warr et.al.|[2407.21638v1](http://arxiv.org/abs/2407.21638v1)|null|
|**2024-07-31**|**Optimizing Disease Prediction with Artificial Intelligence Driven Feature Selection and Attention Networks**|D. Dhinakaran et.al.|[2408.03151v1](http://arxiv.org/abs/2408.03151v1)|null|
|**2024-07-31**|**Voxel Scene Graph for Intracranial Hemorrhage**|Antoine P. Sanner et.al.|[2407.21580v1](http://arxiv.org/abs/2407.21580v1)|null|
|**2024-07-31**|**Expanding the Medical Decathlon dataset: segmentation of colon and colorectal cancer from computed tomography images**|I. M. Chernenkiy et.al.|[2407.21516v1](http://arxiv.org/abs/2407.21516v1)|null|
|**2024-07-31**|**Explainable and Controllable Motion Curve Guided Cardiac Ultrasound Video Generation**|Junxuan Yu et.al.|[2407.21490v1](http://arxiv.org/abs/2407.21490v1)|null|
|**2024-07-31**|**Deep Learning-Based Longitudinal Prediction of Childhood Myopia Progression Using Fundus Image Sequences and Baseline Refraction Data**|Mengtian Kang et.al.|[2407.21467v1](http://arxiv.org/abs/2407.21467v1)|null|
|**2024-07-31**|**Prompting Medical Large Vision-Language Models to Diagnose Pathologies by Visual Question Answering**|Danfeng Guo et.al.|[2407.21368v1](http://arxiv.org/abs/2407.21368v1)|null|
|**2024-07-31**|**MIST: A Simple and Scalable End-To-End 3D Medical Imaging Segmentation Framework**|Adrian Celaya et.al.|[2407.21343v1](http://arxiv.org/abs/2407.21343v1)|null|
|**2024-07-31**|**Patient-centered data science: an integrative framework for evaluating and predicting clinical outcomes in the digital health era**|Mohsen Amoei et.al.|[2408.02677v1](http://arxiv.org/abs/2408.02677v1)|null|
|**2024-07-31**|**Robust Box Prompt based SAM for Medical Image Segmentation**|Yuhao Huang et.al.|[2407.21284v1](http://arxiv.org/abs/2407.21284v1)|null|
|**2024-07-31**|**Unlocking the Potential of Binding Corporate Rules (BCRs) in Health Data Transfers**|Marcelo Corrales Compagnucci et.al.|[2407.21281v1](http://arxiv.org/abs/2407.21281v1)|null|
|**2024-07-31**|**FreqTSF: Time Series Forecasting Via Simulating Frequency Kramer-Kronig Relations**|Rujia Shen et.al.|[2407.21275v1](http://arxiv.org/abs/2407.21275v1)|null|
|**2024-07-31**|**Enhanced Uncertainty Estimation in Ultrasound Image Segmentation with MSU-Net**|Rohini Banerjee et.al.|[2407.21273v1](http://arxiv.org/abs/2407.21273v1)|null|
|**2024-07-30**|**Domain Shift Analysis in Chest Radiographs Classification in a Veterans Healthcare Administration Population**|Mayanka Chandrashekar et.al.|[2407.21149v1](http://arxiv.org/abs/2407.21149v1)|null|
|**2024-07-30**|**Zero Shot Health Trajectory Prediction Using Transformer**|Pawel Renc et.al.|[2407.21124v1](http://arxiv.org/abs/2407.21124v1)|null|
|**2024-07-30**|**CLEFT: Language-Image Contrastive Learning with Efficient Large Language Model and Prompt Fine-Tuning**|Yuexi Du et.al.|[2407.21011v1](http://arxiv.org/abs/2407.21011v1)|[link](https://github.com/xypb/cleft)|
|**2024-07-30**|**Federated Knowledge Recycling: Privacy-Preserving Synthetic Data Sharing**|Eugenio Lomurno et.al.|[2407.20830v1](http://arxiv.org/abs/2407.20830v1)|null|
|**2024-07-30**|**Interpretable Pre-Trained Transformers for Heart Time-Series Data**|Harry J. Davies et.al.|[2407.20775v2](http://arxiv.org/abs/2407.20775v2)|[link](https://github.com/harryjdavies/heartgpt)|
|**2024-07-30**|**Architectural Influence on Variational Quantum Circuits in Multi-Agent Reinforcement Learning: Evolutionary Strategies for Optimization**|Michael K√∂lle et.al.|[2407.20739v1](http://arxiv.org/abs/2407.20739v1)|null|
|**2024-07-29**|**Dense Self-Supervised Learning for Medical Image Segmentation**|Maxime Seince et.al.|[2407.20395v1](http://arxiv.org/abs/2407.20395v1)|null|
|**2024-07-29**|**Classification, Regression and Segmentation directly from k-Space in Cardiac MRI**|Ruochen Li et.al.|[2407.20108v1](http://arxiv.org/abs/2407.20108v1)|null|
|**2024-07-29**|**Robust Conformal Volume Estimation in 3D Medical Images**|Benjamin Lambert et.al.|[2407.19938v1](http://arxiv.org/abs/2407.19938v1)|[link](https://github.com/benolmbrt/wcp_miccai)|
|**2024-07-29**|**Yucca: A Deep Learning Framework For Medical Image Analysis**|Sebastian N√∏rgaard Llambias et.al.|[2407.19888v1](http://arxiv.org/abs/2407.19888v1)|[link](https://github.com/sllambias/yucca)|
|**2024-07-29**|**CollectiveSFT: Scaling Large Language Models for Chinese Medical Benchmark with Collective Instructions in Healthcare**|Jingwei Zhu et.al.|[2407.19705v2](http://arxiv.org/abs/2407.19705v2)|[link](https://github.com/cas-siat-xinhai/collectivesft)|
|**2024-07-29**|**Beyond Metrics: A Critical Analysis of the Variability in Large Language Model Evaluation Frameworks**|Marco AF Pimentel et.al.|[2407.21072v1](http://arxiv.org/abs/2407.21072v1)|null|
|**2024-07-29**|**Urban Traffic Accident Risk Prediction Revisited: Regionality, Proximity, Similarity and Sparsity**|Minxiao Chen et.al.|[2407.19668v1](http://arxiv.org/abs/2407.19668v1)|[link](https://github.com/faceless0124/mghstn)|
|**2024-07-28**|**Overcoming Uncertain Incompleteness for Robust Multimodal Sequential Diagnosis Prediction via Knowledge Distillation and Random Data Erasing**|Heejoon Koo et.al.|[2407.19540v1](http://arxiv.org/abs/2407.19540v1)|null|
|**2024-07-28**|**Nudging Consent and the New Opt Out System to the Processing of Health Data in England**|Janos Meszaros et.al.|[2407.19447v1](http://arxiv.org/abs/2407.19447v1)|null|
|**2024-07-28**|**ASI-Seg: Audio-Driven Surgical Instrument Segmentation with Surgeon Intention Understanding**|Zhen Chen et.al.|[2407.19435v1](http://arxiv.org/abs/2407.19435v1)|[link](https://github.com/zonmgin-zhang/asi-seg)|
|**2024-07-28**|**A Generic Review of Integrating Artificial Intelligence in Cognitive Behavioral Therapy**|Meng Jiang et.al.|[2407.19422v1](http://arxiv.org/abs/2407.19422v1)|null|
|**2024-07-28**|**Empowering Clinicians with Medical Decision Transformers: A Framework for Sepsis Treatment**|Aamer Abdul Rahman et.al.|[2407.19380v1](http://arxiv.org/abs/2407.19380v1)|null|
|**2024-07-28**|**Learning to Select the Best Forecasting Tasks for Clinical Outcome Prediction**|Yuan Xue et.al.|[2407.19359v1](http://arxiv.org/abs/2407.19359v1)|null|

#### Abstracts
##### **Model Counting in the Wild**
2408.07059v1 by Arijit Shaw, Kuldeep S. Meel

Model counting is a fundamental problem in automated reasoning with
applications in probabilistic inference, network reliability, neural network
verification, and more. Although model counting is computationally intractable
from a theoretical perspective due to its #P-completeness, the past decade has
seen significant progress in developing state-of-the-art model counters to
address scalability challenges.
  In this work, we conduct a rigorous assessment of the scalability of model
counters in the wild. To this end, we surveyed 11 application domains and
collected an aggregate of 2262 benchmarks from these domains. We then evaluated
six state-of-the-art model counters on these instances to assess scalability
and runtime performance.
  Our empirical evaluation demonstrates that the performance of model counters
varies significantly across different application domains, underscoring the
need for careful selection by the end user. Additionally, we investigated the
behavior of different counters with respect to two parameters suggested by the
model counting community, finding only a weak correlation. Our analysis
highlights the challenges and opportunities for portfolio-based approaches in
model counting.

ÊëòË¶ÅÔºöÊ®°ÂûãË®àÊï∏ÊòØËá™ÂãïÊé®ÁêÜ‰∏≠ÁöÑÂü∫Êú¨ÂïèÈ°åÔºåÂú®Ê©üÁéáÊé®Ë´ñ„ÄÅÁ∂≤Ë∑ØÂèØÈù†Â∫¶„ÄÅÁ•ûÁ∂ìÁ∂≤Ë∑ØÈ©óË≠âÁ≠âÈ†òÂüüÊúâÂÖ∂ÊáâÁî®„ÄÇÂÑòÁÆ°Ê®°ÂûãË®àÊï∏Âú®ÁêÜË´ñ‰∏äÂõ†ÂÖ∂ #P-completeness ËÄåÂú®Ë®àÁÆó‰∏äÈõ£‰ª•ËôïÁêÜÔºåÈÅéÂéªÂçÅÂπ¥‰æÜÔºåÂú®ÈñãÁôºÊúÄÂÖàÈÄ≤ÁöÑÊ®°ÂûãË®àÊï∏Âô®‰ª•Ëß£Ê±∫ÂèØÊì¥ÂÖÖÊÄßÊåëÊà∞ÊñπÈù¢Â∑≤ÂèñÂæóÈ°ØËëóÈÄ≤Â±ï„ÄÇ
Âú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂ∞çÊ®°ÂûãË®àÊï∏Âô®ÁöÑÂèØÊì¥ÂÖÖÊÄßÈÄ≤Ë°å‰∫ÜÂö¥Ë¨πÁöÑË©ï‰º∞„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëË™øÊü•‰∫Ü 11 ÂÄãÊáâÁî®È†òÂüüÔºå‰∏¶ÂæûÈÄô‰∫õÈ†òÂüüÊî∂ÈõÜ‰∫Ü 2262 ÂÄãÂü∫Ê∫ñ„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÂú®ÈÄô‰∫õÂØ¶‰æã‰∏äË©ï‰º∞‰∫ÜÂÖ≠ÂÄãÊúÄÂÖàÈÄ≤ÁöÑÊ®°ÂûãË®àÊï∏Âô®Ôºå‰ª•Ë©ï‰º∞ÂèØÊì¥ÂÖÖÊÄßÂíåÂü∑Ë°åÊôÇÈñìÊïàËÉΩ„ÄÇ
ÊàëÂÄëÁöÑÂØ¶Ë≠âË©ï‰º∞Ë°®ÊòéÔºåÊ®°ÂûãË®àÊï∏Âô®ÁöÑÊïàËÉΩÂõ†‰∏çÂêåÁöÑÊáâÁî®È†òÂüüËÄåÁï∞ÔºåÈÄôÂá∏È°Ø‰∫ÜÊúÄÁµÇ‰ΩøÁî®ËÄÖ‰ªîÁ¥∞ÈÅ∏ÊìáÁöÑÂøÖË¶ÅÊÄß„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁ†îÁ©∂‰∫Ü‰∏çÂêåË®àÊï∏Âô®Áõ∏Â∞çÊñºÊ®°ÂûãË®àÊï∏Á§æÁæ§Âª∫Ë≠∞ÁöÑÂÖ©ÂÄãÂèÉÊï∏ÁöÑË°åÁÇ∫ÔºåÁôºÁèæÂè™ÊúâÂæÆÂº±ÁöÑÁõ∏ÈóúÊÄß„ÄÇÊàëÂÄëÁöÑÂàÜÊûêÈáçÈªûË™™Êòé‰∫ÜÊ®°ÂûãË®àÊï∏‰∏≠Âü∫ÊñºÊäïË≥áÁµÑÂêàÁöÑÊñπÊ≥ïÊâÄÈù¢Ëá®ÁöÑÊåëÊà∞ÂíåÊ©üÊúÉ„ÄÇ

##### **KAN You See It? KANs and Sentinel for Effective and Explainable Crop Field Segmentation**
2408.07040v1 by Daniele Rege Cambrin, Eleonora Poeta, Eliana Pastor, Tania Cerquitelli, Elena Baralis, Paolo Garza

Segmentation of crop fields is essential for enhancing agricultural
productivity, monitoring crop health, and promoting sustainable practices. Deep
learning models adopted for this task must ensure accurate and reliable
predictions to avoid economic losses and environmental impact. The newly
proposed Kolmogorov-Arnold networks (KANs) offer promising advancements in the
performance of neural networks. This paper analyzes the integration of KAN
layers into the U-Net architecture (U-KAN) to segment crop fields using
Sentinel-2 and Sentinel-1 satellite images and provides an analysis of the
performance and explainability of these networks. Our findings indicate a 2\%
improvement in IoU compared to the traditional full-convolutional U-Net model
in fewer GFLOPs. Furthermore, gradient-based explanation techniques show that
U-KAN predictions are highly plausible and that the network has a very high
ability to focus on the boundaries of cultivated areas rather than on the areas
themselves. The per-channel relevance analysis also reveals that some channels
are irrelevant to this task.

ÊëòË¶ÅÔºöËæ≤‰ΩúÁâ©Áî∞ÂçÄÂàÜÂâ≤Â∞çÊñºÊèêÂçáËæ≤Ê•≠ÁîüÁî¢Âäõ„ÄÅÁõ£Êéß‰ΩúÁâ©ÂÅ•Â∫∑Âíå‰øÉÈÄ≤Ê∞∏Á∫åÂØ¶ÂãôËá≥ÈóúÈáçË¶Å„ÄÇÊé°Áî®ÊñºÊ≠§‰ªªÂãôÁöÑÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÂøÖÈ†àÁ¢∫‰øùÊ∫ñÁ¢∫‰∏îÂèØÈù†ÁöÑÈ†êÊ∏¨Ôºå‰ª•ÈÅøÂÖçÁ∂ìÊøüÊêçÂ§±ÂíåÁí∞Â¢ÉÂΩ±Èüø„ÄÇÊñ∞ÊèêÂá∫ÁöÑÊüØÁàæËé´Âì•Ê¥õÂ§´-ÈòøË´æÂæ∑Á∂≤Ë∑Ø (KAN) ÁÇ∫Á•ûÁ∂ìÁ∂≤Ë∑ØÁöÑÊïàËÉΩÊèê‰æõ‰∫ÜÊúâÂ∏åÊúõÁöÑÈÄ≤Â±ï„ÄÇÊú¨ÊñáÂàÜÊûêÂ∞á KAN Â±§Êï¥ÂêàÂà∞ U-Net Êû∂Êßã (U-KAN) ‰∏≠Ôºå‰ª•‰ΩøÁî® Sentinel-2 Âíå Sentinel-1 Ë°õÊòüÂΩ±ÂÉèÂàÜÂâ≤Ëæ≤‰ΩúÁâ©Áî∞ÂçÄÔºå‰∏¶Êèê‰æõÂ∞çÈÄô‰∫õÁ∂≤Ë∑ØÊïàËÉΩÂíåÂèØËß£ÈáãÊÄßÁöÑÂàÜÊûê„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÈ°ØÁ§∫ÔºåËàáÂÇ≥Áµ±ÁöÑÂÖ®Âç∑Á©ç U-Net Ê®°ÂûãÁõ∏ÊØîÔºåIoU ÊèêÂçá‰∫Ü 2%ÔºåËÄå GFLOP ËºÉÂ∞ë„ÄÇÊ≠§Â§ñÔºåÂü∫ÊñºÊ¢ØÂ∫¶ÁöÑËß£ÈáãÊäÄË°ìÈ°ØÁ§∫ U-KAN È†êÊ∏¨ÈùûÂ∏∏ÂêàÁêÜÔºåËÄå‰∏îÁ∂≤Ë∑ØÈùûÂ∏∏ÊúâËÉΩÂäõÂ∞àÊ≥®ÊñºËÄï‰ΩúÂçÄÂüüÁöÑÈÇäÁïåÔºåËÄå‰∏çÊòØÂçÄÂüüÊú¨Ë∫´„ÄÇÊØèÂÄãÈÄöÈÅìÈóúËÅØÊÄßÂàÜÊûê‰πüÈ°ØÁ§∫ÔºåÊúâ‰∫õÈÄöÈÅìËàáÊ≠§‰ªªÂãôÁÑ°Èóú„ÄÇ

##### **PathInsight: Instruction Tuning of Multimodal Datasets and Models for Intelligence Assisted Diagnosis in Histopathology**
2408.07037v1 by Xiaomin Wu, Rui Xu, Pengchen Wei, Wenkang Qin, Peixiang Huang, Ziheng Li, Lin Luo

Pathological diagnosis remains the definitive standard for identifying
tumors. The rise of multimodal large models has simplified the process of
integrating image analysis with textual descriptions. Despite this advancement,
the substantial costs associated with training and deploying these complex
multimodal models, together with a scarcity of high-quality training datasets,
create a significant divide between cutting-edge technology and its application
in the clinical setting. We had meticulously compiled a dataset of
approximately 45,000 cases, covering over 6 different tasks, including the
classification of organ tissues, generating pathology report descriptions, and
addressing pathology-related questions and answers. We have fine-tuned
multimodal large models, specifically LLaVA, Qwen-VL, InternLM, with this
dataset to enhance instruction-based performance. We conducted a qualitative
assessment of the capabilities of the base model and the fine-tuned model in
performing image captioning and classification tasks on the specific dataset.
The evaluation results demonstrate that the fine-tuned model exhibits
proficiency in addressing typical pathological questions. We hope that by
making both our models and datasets publicly available, they can be valuable to
the medical and research communities.

ÊëòË¶ÅÔºöÁóÖÁêÜË®∫Êñ∑‰ªçÁÑ∂ÊòØË≠òÂà•ËÖ´Áò§ÁöÑÊòéÁ¢∫Ê®ôÊ∫ñ„ÄÇÂ§öÊ®°ÊÖãÂ§ßÂûãÊ®°ÂûãÁöÑËààËµ∑Á∞°Âåñ‰∫ÜÂ∞áÂΩ±ÂÉèÂàÜÊûêËàáÊñáÂ≠óÊèèËø∞Êï¥ÂêàÁöÑÈÅéÁ®ã„ÄÇÂÑòÁÆ°ÊúâÊ≠§ÈÄ≤Â±ïÔºå‰ΩÜË®ìÁ∑¥ÂíåÈÉ®ÁΩ≤ÈÄô‰∫õË§áÈõúÁöÑÂ§öÊ®°ÊÖãÊ®°ÂûãÁõ∏ÈóúÁöÑÈæêÂ§ßÊàêÊú¨Ôºå‰ª•ÂèäÁº∫‰πèÈ´òÂìÅË≥™ÁöÑË®ìÁ∑¥Ë≥áÊñôÈõÜÔºåÂ∞éËá¥Â∞ñÁ´ØÊäÄË°ìËàáÂÖ∂Âú®Ëá®Â∫äÁí∞Â¢É‰∏≠ÁöÑÊáâÁî®‰πãÈñìÁî¢Áîü‰∫ÜÈ°ØËëóÁöÑÂ∑ÆË∑ù„ÄÇÊàëÂÄëÂ∑≤Á¥∞ÂøÉÁ∑®Âà∂‰∫Ü‰∏ÄÂÄãÂåÖÂê´Á¥Ñ 45,000 ÂÄãÊ°à‰æãÁöÑË≥áÊñôÈõÜÔºåÊ∂µËìã 6 È†Ö‰∏çÂêåÁöÑ‰ªªÂãôÔºåÂåÖÊã¨Âô®ÂÆòÁµÑÁπîÂàÜÈ°û„ÄÅÁî¢ÁîüÁóÖÁêÜÂ†±ÂëäÊèèËø∞Ôºå‰ª•ÂèäÂõûÁ≠îËàáÁóÖÁêÜÁõ∏ÈóúÁöÑÂïèÈ°å„ÄÇÊàëÂÄë‰ΩøÁî®ÈÄôÂÄãË≥áÊñôÈõÜÂæÆË™ø‰∫ÜÂ§öÊ®°ÊÖãÂ§ßÂûãÊ®°ÂûãÔºåÁâπÂà•ÊòØ LLaVA„ÄÅQwen-VL„ÄÅInternLMÔºå‰ª•Â¢ûÂº∑Âü∫ÊñºÊåá‰ª§ÁöÑÊïàËÉΩ„ÄÇÊàëÂÄëÂ∞çÂü∫Á§éÊ®°ÂûãÂíåÂæÆË™øÊ®°ÂûãÂú®ÁâπÂÆöË≥áÊñôÈõÜ‰∏äÂü∑Ë°åÂΩ±ÂÉèÊ®ôÈ°åÂíåÂàÜÈ°û‰ªªÂãôÁöÑËÉΩÂäõÈÄ≤Ë°å‰∫ÜÂÆöÊÄßË©ï‰º∞„ÄÇË©ï‰º∞ÁµêÊûúË°®ÊòéÔºåÂæÆË™øÊ®°ÂûãÂú®ÂõûÁ≠îÂÖ∏ÂûãÁóÖÁêÜÂïèÈ°åÊñπÈù¢Ë°®ÁèæÂá∫ÁÜüÁ∑¥Â∫¶„ÄÇÊàëÂÄëÂ∏åÊúõÈÄèÈÅéÂÖ¨ÈñãÊàëÂÄëÁöÑÊ®°ÂûãÂíåË≥áÊñôÈõÜÔºåÂÆÉÂÄëËÉΩÂ∞çÈÜ´ÁôÇÂíåÁ†îÁ©∂Á§æÁæ§ÊúâÂÉπÂÄº„ÄÇ

##### **Diagnosis extraction from unstructured Dutch echocardiogram reports using span- and document-level characteristic classification**
2408.06930v1 by Bauke Arends, Melle Vessies, Dirk van Osch, Arco Teske, Pim van der Harst, Ren√© van Es, Bram van Es

Clinical machine learning research and AI driven clinical decision support
models rely on clinically accurate labels. Manually extracting these labels
with the help of clinical specialists is often time-consuming and expensive.
This study tests the feasibility of automatic span- and document-level
diagnosis extraction from unstructured Dutch echocardiogram reports.
  We included 115,692 unstructured echocardiogram reports from the UMCU a large
university hospital in the Netherlands. A randomly selected subset was manually
annotated for the occurrence and severity of eleven commonly described cardiac
characteristics. We developed and tested several automatic labelling techniques
at both span and document levels, using weighted and macro F1-score, precision,
and recall for performance evaluation. We compared the performance of span
labelling against document labelling methods, which included both direct
document classifiers and indirect document classifiers that rely on span
classification results.
  The SpanCategorizer and MedRoBERTa.nl models outperformed all other span and
document classifiers, respectively. The weighted F1-score varied between
characteristics, ranging from 0.60 to 0.93 in SpanCategorizer and 0.96 to 0.98
in MedRoBERTa.nl. Direct document classification was superior to indirect
document classification using span classifiers. SetFit achieved competitive
document classification performance using only 10\% of the training data.
Utilizing a reduced label set yielded near-perfect document classification
results.
  We recommend using our published SpanCategorizer and MedRoBERTa.nl models for
span- and document-level diagnosis extraction from Dutch echocardiography
reports. For settings with limited training data, SetFit may be a promising
alternative for document classification.

ÊëòË¶ÅÔºö<paragraph>Ëá®Â∫äÊ©üÂô®Â≠∏ÁøíÁ†îÁ©∂Âíå AI È©ÖÂãïÁöÑËá®Â∫äÊ±∫Á≠ñÊîØÊè¥Ê®°Âûã‰æùË≥¥ÊñºËá®Â∫äÁ≤æÁ¢∫Ê®ôÁ±§„ÄÇÂú®Ëá®Â∫äÂ∞àÂÆ∂ÁöÑÂçîÂä©‰∏ãÊâãÂãïÊèêÂèñÈÄô‰∫õÊ®ôÁ±§ÈÄöÂ∏∏Êó¢ËÄóÊôÇÂèàÊòÇË≤¥„ÄÇÊú¨Á†îÁ©∂Ê∏¨Ë©¶‰∫ÜÂæûÈùûÁµêÊßãÂåñËç∑Ëò≠Ë∂ÖÈü≥Ê≥¢ÂøÉÂãïÂúñÂ†±Âëä‰∏≠Ëá™ÂãïÊèêÂèñË∑®Â∫¶ÂíåÊñá‰ª∂Á¥öÂà•Ë®∫Êñ∑ÁöÑÂèØË°åÊÄß„ÄÇÊàëÂÄëÁ¥çÂÖ•‰∫Ü‰æÜËá™Ëç∑Ëò≠‰∏ÄÂÆ∂Â§ßÂûãÂ§ßÂ≠∏ÈÜ´Èô¢ UMCU ÁöÑ 115,692 ‰ªΩÈùûÁµêÊßãÂåñË∂ÖÈü≥Ê≥¢ÂøÉÂãïÂúñÂ†±Âëä„ÄÇÊâãÂãïË®ªËß£‰∫Ü‰∏ÄÂÄãÈö®Ê©üÈÅ∏ÂèñÁöÑÂ≠êÈõÜÔºå‰ª•‰∫ÜËß£ÂçÅ‰∏ÄÁ®ÆÂ∏∏Ë¶ãÊèèËø∞ÁöÑÂøÉËáüÁâπÂæµÁöÑÁôºÁîüÂíåÂö¥ÈáçÁ®ãÂ∫¶„ÄÇÊàëÂÄëÈñãÁôº‰∏¶Ê∏¨Ë©¶‰∫ÜË∑®Â∫¶ÂíåÊñá‰ª∂Á¥öÂà•ÁöÑÂπæÁ®ÆËá™ÂãïÊ®ôÁ±§ÊäÄË°ìÔºå‰ΩøÁî®Âä†Ê¨äÂíåÂ∑®ÈõÜ F1 ÂàÜÊï∏„ÄÅÁ≤æÁ¢∫Â∫¶ÂíåÂè¨ÂõûÁéáÈÄ≤Ë°åÊïàËÉΩË©ï‰º∞„ÄÇÊàëÂÄëÊØîËºÉ‰∫ÜË∑®Â∫¶Ê®ôÁ±§Áõ∏Â∞çÊñºÊñá‰ª∂Ê®ôÁ±§ÊñπÊ≥ïÁöÑÊïàËÉΩÔºåÂÖ∂‰∏≠ÂåÖÊã¨Áõ¥Êé•Êñá‰ª∂ÂàÜÈ°ûÂô®Âíå‰æùË≥¥ÊñºË∑®Â∫¶ÂàÜÈ°ûÁµêÊûúÁöÑÈñìÊé•Êñá‰ª∂ÂàÜÈ°ûÂô®„ÄÇSpanCategorizer Âíå MedRoBERTa.nl Ê®°ÂûãÂàÜÂà•ÂÑ™ÊñºÊâÄÊúâÂÖ∂‰ªñË∑®Â∫¶ÂíåÊñá‰ª∂ÂàÜÈ°ûÂô®„ÄÇÂä†Ê¨ä F1 ÂàÜÊï∏Âõ†ÁâπÂæµËÄåÁï∞ÔºåÂú® SpanCategorizer ‰∏≠‰ªãÊñº 0.60 Âà∞ 0.93ÔºåÂú® MedRoBERTa.nl ‰∏≠‰ªãÊñº 0.96 Âà∞ 0.98„ÄÇ‰ΩøÁî®Ë∑®Â∫¶ÂàÜÈ°ûÂô®ÁöÑÈñìÊé•Êñá‰ª∂ÂàÜÈ°û‰∏çÂ¶ÇÁõ¥Êé•Êñá‰ª∂ÂàÜÈ°û„ÄÇSetFit ÂÉÖ‰ΩøÁî® 10% ÁöÑË®ìÁ∑¥Ë≥áÊñôÂ∞±ÈÅîÂà∞‰∫ÜÊúâÁ´∂Áà≠ÂäõÁöÑÊñá‰ª∂ÂàÜÈ°ûÊïàËÉΩ„ÄÇÂà©Áî®Ê∏õÂ∞ëÁöÑÊ®ôÁ±§ÁµÑÁî¢Áîü‰∫ÜËøë‰πéÂÆåÁæéÁöÑÊñá‰ª∂ÂàÜÈ°ûÁµêÊûú„ÄÇÊàëÂÄëÂª∫Ë≠∞‰ΩøÁî®ÊàëÂÄëÁôºÂ∏ÉÁöÑ SpanCategorizer Âíå MedRoBERTa.nl Ê®°ÂûãÂæûËç∑Ëò≠Ë∂ÖÈü≥Ê≥¢ÂøÉÂãïÂúñÂ†±Âëä‰∏≠ÊèêÂèñË∑®Â∫¶ÂíåÊñá‰ª∂Á¥öÂà•Ë®∫Êñ∑„ÄÇÂ∞çÊñºË®ìÁ∑¥Ë≥áÊñôÊúâÈôêÁöÑË®≠ÂÆöÔºåSetFit ÂèØËÉΩÊòØ‰∏ÄÁ®ÆÊúâÂâçÈÄîÁöÑÊñá‰ª∂ÂàÜÈ°ûÊõø‰ª£ÊñπÊ°à„ÄÇ</paragraph>

##### **BMFT: Achieving Fairness via Bias-based Weight Masking Fine-tuning**
2408.06890v1 by Yuyang Xue, Junyu Yan, Raman Dutt, Fasih Haider, Jingshuai Liu, Steven McDonagh, Sotirios A. Tsaftaris

Developing models with robust group fairness properties is paramount,
particularly in ethically sensitive domains such as medical diagnosis. Recent
approaches to achieving fairness in machine learning require a substantial
amount of training data and depend on model retraining, which may not be
practical in real-world scenarios. To mitigate these challenges, we propose
Bias-based Weight Masking Fine-Tuning (BMFT), a novel post-processing method
that enhances the fairness of a trained model in significantly fewer epochs
without requiring access to the original training data. BMFT produces a mask
over model parameters, which efficiently identifies the weights contributing
the most towards biased predictions. Furthermore, we propose a two-step
debiasing strategy, wherein the feature extractor undergoes initial fine-tuning
on the identified bias-influenced weights, succeeded by a fine-tuning phase on
a reinitialised classification layer to uphold discriminative performance.
Extensive experiments across four dermatological datasets and two sensitive
attributes demonstrate that BMFT outperforms existing state-of-the-art (SOTA)
techniques in both diagnostic accuracy and fairness metrics. Our findings
underscore the efficacy and robustness of BMFT in advancing fairness across
various out-of-distribution (OOD) settings. Our code is available at:
https://github.com/vios-s/BMFT

ÊëòË¶ÅÔºö<paragraph>ÈñãÁôºÂÖ∑ÊúâÁ©©ÂÅ•Áæ§ÁµÑÂÖ¨Âπ≥ÊÄßÁâπÊÄßÁöÑÊ®°ÂûãËá≥ÈóúÈáçË¶ÅÔºåÁâπÂà•ÊòØÂú®ÈÜ´ÁôÇË®∫Êñ∑Á≠âÈÅìÂæ∑ÊïèÊÑüÈ†òÂüü„ÄÇÊúÄËøëÂØ¶ÁèæÊ©üÂô®Â≠∏ÁøíÂÖ¨Âπ≥ÊÄßÁöÑÊñπÊ≥ïÈúÄË¶ÅÂ§ßÈáèÁöÑË®ìÁ∑¥Ë≥áÊñôÔºå‰∏¶‰∏î‰æùË≥¥ÊñºÊ®°ÂûãÂÜçË®ìÁ∑¥ÔºåÈÄôÂú®ÁèæÂØ¶ÊÉÖÊ≥Å‰∏≠ÂèØËÉΩ‰∏çÂàáÂØ¶Èöõ„ÄÇÁÇ∫‰∫ÜÁ∑©Ëß£ÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÊèêÂá∫‰∫ÜÂü∫ÊñºÂÅèÂ∑ÆÁöÑÊ¨äÈáçÈÅÆÁΩ©ÂæÆË™ø (BMFT)ÔºåÈÄôÊòØ‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÂæåËôïÁêÜÊñπÊ≥ïÔºåÂèØ‰ª•Âú®È°ØËëóÊõ¥Â∞ëÁöÑËº™Ê¨°‰∏≠Â¢ûÂº∑Ë®ìÁ∑¥Ê®°ÂûãÁöÑÂÖ¨Âπ≥ÊÄßÔºåËÄåÁÑ°ÈúÄË®™ÂïèÂéüÂßãË®ìÁ∑¥Ë≥áÊñô„ÄÇBMFT Âú®Ê®°ÂûãÂèÉÊï∏‰∏äÁî¢Áîü‰∏ÄÂÄãÈÅÆÁΩ©ÔºåÊúâÊïàÂú∞Ë≠òÂà•Âá∫Â∞çÂÅèÂ∑ÆÈ†êÊ∏¨Ë≤¢ÁçªÊúÄÂ§ßÁöÑÊ¨äÈáç„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂÖ©Ê≠•ÂéªÂÅèÁ≠ñÁï•ÔºåÂÖ∂‰∏≠ÁâπÂæµÊèêÂèñÂô®Â∞çË≠òÂà•Âá∫ÁöÑÂÅèÂ∑ÆÂΩ±ÈüøÊ¨äÈáçÈÄ≤Ë°åÂàùÂßãÂæÆË™øÔºåÁÑ∂ÂæåÂú®ÈáçÊñ∞ÂàùÂßãÂåñÁöÑÂàÜÈ°ûÂ±§‰∏äÈÄ≤Ë°åÂæÆË™øÈöéÊÆµ‰ª•Á∂≠ÊåÅÂçÄÂàÜÊïàËÉΩ„ÄÇÂú®ÂõõÂÄãÁöÆËÜöÁßëË≥áÊñôÈõÜÂíåÂÖ©ÂÄãÊïèÊÑüÂ±¨ÊÄßÁöÑÂª£Ê≥õÂØ¶È©ó‰∏≠Ë≠âÊòéÔºåBMFT Âú®Ë®∫Êñ∑Ê∫ñÁ¢∫ÊÄßÂíåÂÖ¨Âπ≥ÊÄßÊåáÊ®ô‰∏äÈÉΩÂÑ™ÊñºÁèæÊúâÁöÑÊúÄÂÖàÈÄ≤ (SOTA) ÊäÄË°ì„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÂº∑Ë™ø‰∫Ü BMFT Âú®Êé®ÈÄ≤ÂêÑÁ®ÆÈùûÂàÜ‰Ωà (OOD) Ë®≠ÂÆö‰∏≠ÁöÑÂÖ¨Âπ≥ÊÄßÊñπÈù¢ÁöÑÊïàÂäõÂíåÁ©©ÂÅ•ÊÄß„ÄÇÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÂèØÂú®‰ª•‰∏ã‰ΩçÁΩÆÁç≤ÂæóÔºö
https://github.com/vios-s/BMFT</paragraph>

##### **Synthetic Patient-Physician Dialogue Generation from Clinical Notes Using LLM**
2408.06285v1 by Trisha Das, Dina Albassam, Jimeng Sun

Medical dialogue systems (MDS) enhance patient-physician communication,
improve healthcare accessibility, and reduce costs. However, acquiring suitable
data to train these systems poses significant challenges. Privacy concerns
prevent the use of real conversations, necessitating synthetic alternatives.
Synthetic dialogue generation from publicly available clinical notes offers a
promising solution to this issue, providing realistic data while safeguarding
privacy. Our approach, SynDial, uses a single LLM iteratively with zero-shot
prompting and a feedback loop to generate and refine high-quality synthetic
dialogues. The feedback consists of weighted evaluation scores for similarity
and extractiveness. The iterative process ensures dialogues meet predefined
thresholds, achieving superior extractiveness as a result of the feedback loop.
Additionally, evaluation shows that the generated dialogues excel in factuality
metric compared to the baselines and has comparable diversity scores with GPT4.

ÊëòË¶ÅÔºöÈÜ´ÁôÇÂ∞çË©±Á≥ªÁµ± (MDS) ÂèØÂ¢ûÂº∑ÁóÖÊÇ£ËàáÈÜ´Â∏´ÁöÑÊ∫ùÈÄö„ÄÅÊîπÂñÑÈÜ´ÁôÇ‰øùÂÅ•ÁöÑÂèØËøëÊÄßÔºå‰∏¶Èôç‰ΩéÊàêÊú¨„ÄÇÁÑ∂ËÄåÔºåÂèñÂæóÈÅ©Áï∂ÁöÑË≥áÊñô‰æÜË®ìÁ∑¥ÈÄô‰∫õÁ≥ªÁµ±ÊúÉÈÄ†ÊàêÈáçÂ§ßÁöÑÊåëÊà∞„ÄÇÈö±ÁßÅÂïèÈ°åÊúÉÂ¶®Á§ôÁúüÂØ¶Â∞çË©±ÁöÑ‰ΩøÁî®ÔºåÂõ†Ê≠§ÈúÄË¶ÅÂêàÊàêÊõø‰ª£ÊñπÊ°à„ÄÇÂæûÂÖ¨ÈñãÂèØÂèñÂæóÁöÑËá®Â∫äÁ≠ÜË®òÁîüÊàêÂêàÊàêÂ∞çË©±Êèê‰æõ‰∫ÜÈÄôÂÄãÂïèÈ°å‰∏ÄÂÄãÊúâÂâçÊôØÁöÑËß£Ê±∫ÊñπÊ°àÔºåÂú®‰øùË≠∑Èö±ÁßÅÁöÑÂêåÊôÇÊèê‰æõÁúüÂØ¶ÁöÑË≥áÊñô„ÄÇÊàëÂÄëÁöÑ SynDial ÊñπÊ≥ï‰ΩøÁî®ÂñÆ‰∏Ä LLM ÈÄèÈÅéÈõ∂Ê¨°ÊèêÁ§∫ÂíåÂõûÈ•ãËø¥Ë∑ØÔºåÂèçË¶ÜÁîüÊàêÂíåÊîπÂñÑÈ´òÂìÅË≥™ÁöÑÂêàÊàêÂ∞çË©±„ÄÇÂõûÈ•ãÂåÖÂê´Áõ∏‰ººÊÄßÂíåÊäΩÂèñÊÄßÁöÑÂä†Ê¨äË©ïÂàÜ„ÄÇÂèçË¶ÜÁöÑÁ®ãÂ∫èÂèØÁ¢∫‰øùÂ∞çË©±Á¨¶ÂêàÈ†êÂÖàÂÆöÁæ©ÁöÑÈñæÂÄºÔºå‰∏¶Âõ†ÂõûÈ•ãËø¥Ë∑ØËÄåÈÅîÊàêÂÑ™Áï∞ÁöÑÊäΩÂèñÊÄß„ÄÇÊ≠§Â§ñÔºåË©ï‰º∞È°ØÁ§∫ÁîüÊàêÁöÑÂ∞çË©±Âú®‰∫ãÂØ¶ÊÄßÊåáÊ®ô‰∏äÂÑ™ÊñºÂü∫Ê∫ñÔºå‰∏îËàá GPT4 ÂÖ∑ÊúâÁõ∏Áï∂ÁöÑÂ§öÊ®£ÊÄßË©ïÂàÜ„ÄÇ

##### **Decentralized Health Intelligence Network (DHIN)**
2408.06240v3 by Abraham Nash

Decentralized Health Intelligence Network (DHIN) is a theoretical framework
addressing significant challenges of health data sovereignty and AI utilization
in healthcare caused by data fragmentation across providers and institutions.
It establishes a sovereign architecture for healthcare provision as a
prerequisite to a sovereign health network, then facilitates effective AI
utilization by overcoming barriers to accessing diverse medical data sources.
This comprehensive framework leverages: 1) self-sovereign identity architecture
coupled with a personal health record (PHR) as a prerequisite for health data
sovereignty; 2) a scalable federated learning (FL) protocol implemented on a
public blockchain for decentralized AI training in healthcare, where health
data remains with participants and only model parameter updates are shared; and
3) a scalable, trustless rewards mechanism to incentivize participation and
ensure fair reward distribution. This framework ensures that no entity can
prevent or control access to training on health data offered by participants or
determine financial benefits, as these processes operate on a public blockchain
with an immutable record and without a third party. It supports effective AI
training in healthcare, allowing patients to maintain control over their health
data, benefit financially, and contribute to a decentralized, scalable
ecosystem that leverages collective AI to develop beneficial healthcare
algorithms. Patients receive rewards into their digital wallets as an incentive
to opt-in to the FL protocol, with a long-term roadmap to funding decentralized
insurance solutions. This approach introduces a novel, self-financed healthcare
model that adapts to individual needs, complements existing systems, and
redefines universal coverage. It highlights the potential to transform
healthcare data management and AI utilization while empowering patients.

ÊëòË¶ÅÔºöÂàÜÊï£ÂºèÂÅ•Â∫∑ÊÉÖÂ†±Á∂≤Ë∑Ø (DHIN) ÊòØÂÄãÁêÜË´ñÊû∂ÊßãÔºå
Áî®‰æÜËß£Ê±∫ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠Âõ†Ë≥áÊñôÂàÜÊï£Âú®ÂêÑÂÄã‰æõÊáâÂïÜÂíåÊ©üÊßãËÄåÁî¢ÁîüÁöÑÂÅ•Â∫∑Ë≥áÊñô‰∏ªÊ¨äÂíå AI ‰ΩøÁî®ÁöÑÈáçÂ§ßÊåëÊà∞„ÄÇ
ÂÆÉÂª∫Á´ã‰∫Ü‰∏ÄÂÄã‰∏ªÊ¨äÊû∂Êßã‰æÜÊèê‰æõÈÜ´ÁôÇ‰øùÂÅ•Ôºå‰ΩúÁÇ∫‰∏ªÊ¨äÂÅ•Â∫∑Á∂≤Ë∑ØÁöÑÂÖàÊ±∫Ê¢ù‰ª∂ÔºåÁÑ∂ÂæåÈÄèÈÅéÂÖãÊúçÂèñÂæóÂ§öÊ®£ÂåñÈÜ´ÁôÇË≥áÊñô‰æÜÊ∫êÁöÑÈöúÁ§ôÔºå‰øÉÈÄ≤ÊúâÊïàÁöÑ AI ‰ΩøÁî®„ÄÇ
ÈÄôÂÄãÂÖ®Èù¢ÁöÑÊû∂ÊßãÂà©Áî®Ôºö1) Ëá™‰∏ªÊ¨äË∫´ÂàÜÊû∂ÊßãÔºåÁµêÂêàÂÄã‰∫∫ÂÅ•Â∫∑Á¥ÄÈåÑ (PHR) ‰ΩúÁÇ∫ÂÅ•Â∫∑Ë≥áÊñô‰∏ªÊ¨äÁöÑÂÖàÊ±∫Ê¢ù‰ª∂Ôºõ2) Âú®ÂÖ¨ÂÖ±ÂçÄÂ°äÈèà‰∏äÂØ¶‰ΩúÁöÑÂèØÊì¥ÂÖÖËÅØÂêàÂ≠∏Áøí (FL) ÂçîÂÆöÔºåÁî®ÊñºÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÁöÑÂàÜÊï£Âºè AI Ë®ìÁ∑¥ÔºåÂÖ∂‰∏≠ÂÅ•Â∫∑Ë≥áÊñô‰ªçÁî±ÂèÉËàáËÄÖÊåÅÊúâÔºåÂè™ÊúâÊ®°ÂûãÂèÉÊï∏Êõ¥Êñ∞ÊúÉË¢´ÂàÜ‰∫´Ôºõ3) ÂèØÊì¥ÂÖÖÁöÑ„ÄÅÁÑ°‰ø°‰ªªÁöÑÁçéÂãµÊ©üÂà∂ÔºåÁî®ÊñºÊøÄÂãµÂèÉËàá‰∏¶Á¢∫‰øùÂÖ¨Âπ≥ÁöÑÁçéÂãµÂàÜÈÖç„ÄÇÈÄôÂÄãÊû∂ÊßãÁ¢∫‰øùÊ≤íÊúâ‰ªª‰ΩïÂØ¶È´îÂèØ‰ª•ÈòªÊ≠¢ÊàñÊéßÂà∂ÂèÉËàáËÄÖÊèê‰æõÁöÑÂÅ•Â∫∑Ë≥áÊñôË®ìÁ∑¥Â≠òÂèñÔºåÊàñÊ±∫ÂÆöË≤°ÂãôÂà©ÁõäÔºåÂõ†ÁÇ∫ÈÄô‰∫õÁ®ãÂ∫èÊòØÂú®ÂÖ¨ÂÖ±ÂçÄÂ°äÈèà‰∏äÈÅã‰ΩúÔºåÂÖ∑Êúâ‰∏çÂèØËÆäÊõ¥ÁöÑÁ¥ÄÈåÑÔºåËÄå‰∏îÊ≤íÊúâÁ¨¨‰∏âÊñπ„ÄÇÂÆÉÊîØÊè¥Âú®ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÈÄ≤Ë°åÊúâÊïàÁöÑ AI Ë®ìÁ∑¥ÔºåËÆìÊÇ£ËÄÖÂèØ‰ª•Á∂≠ÊåÅÂ∞çÂÖ∂ÂÅ•Â∫∑Ë≥áÊñôÁöÑÊéßÂà∂Ê¨äÔºåÁç≤ÂæóË≤°ÂãôÂà©ÁõäÔºå‰∏¶Ë≤¢ÁçªÂà∞‰∏ÄÂÄãÂàÜÊï£Âºè„ÄÅÂèØÊì¥ÂÖÖÁöÑÁîüÊÖãÁ≥ªÁµ±ÔºåÂà©Áî®ÈõÜÈ´î AI ‰æÜÈñãÁôºÊúâÁõäÁöÑÈÜ´ÁôÇ‰øùÂÅ•ÊºîÁÆóÊ≥ï„ÄÇÊÇ£ËÄÖÊúÉÊî∂Âà∞ÁçéÂãµÂà∞‰ªñÂÄëÁöÑÊï∏‰ΩçÈå¢ÂåÖ‰∏≠Ôºå‰ΩúÁÇ∫ÈÅ∏ÊìáÂä†ÂÖ• FL ÂçîÂÆöÁöÑË™òÂõ†ÔºåÈï∑ÊúüÁõÆÊ®ôÊòØÁÇ∫ÂàÜÊï£Âºè‰øùÈö™Ëß£Ê±∫ÊñπÊ°àÊèê‰æõË≥áÈáë„ÄÇÈÄôÁ®ÆÊñπÊ≥ïÂºïÈÄ≤‰∫Ü‰∏ÄÂÄãÊñ∞Á©éÁöÑ„ÄÅËá™ÊàëË≥áÂä©ÁöÑÈÜ´ÁôÇ‰øùÂÅ•Ê®°ÂºèÔºåÂèØ‰ª•ÈÅ©ÊáâÂÄãÂà•ÈúÄÊ±ÇÔºåË£úÂÖÖÁèæÊúâÁ≥ªÁµ±Ôºå‰∏¶ÈáçÊñ∞ÂÆöÁæ©ÂÖ®Ê∞ëÂÅ•‰øù„ÄÇÂÆÉÁ™ÅÈ°Ø‰∫ÜËΩâÂûãÈÜ´ÁôÇ‰øùÂÅ•Ë≥áÊñôÁÆ°ÁêÜÂíå AI ‰ΩøÁî®ÁöÑÊΩõÂäõÔºåÂêåÊôÇË≥¶‰∫àÊÇ£ËÄÖÊ¨äÂäõ„ÄÇ

##### **ACCELERATION: Sequentially-scanning DECT Imaging Using High Temporal Resolution Image Reconstruction And Temporal Extrapolation**
2408.06163v1 by Qiaoxin Li, Dong Liang, Yinsheng Li

Dual-energy computed tomography (DECT) has been widely used to obtain
quantitative elemental composition of imaged subjects for personalized and
precise medical diagnosis. Compared with existing high-end DECT leveraging
advanced X-ray source and/or detector technologies, the use of the
sequentially-scanning data acquisition scheme to implement DECT may make
broader impact on clinical practice because this scheme requires no specialized
hardware designs. However, since the concentration of iodinated contrast agent
in the imaged subject varies over time, sequentially-scanned data sets acquired
at two tube potentials are temporally inconsistent. As existing material
decomposition approaches for DECT assume that the data sets acquired at two
tube potentials are temporally consistent, the violation of this assumption
results in inaccurate quantification accuracy of iodine concentration. In this
work, we developed a technique to achieve sequentially-scanning DECT imaging
using high temporal resolution image reconstruction and temporal extrapolation,
ACCELERATION in short, to address the technical challenge induced by temporal
inconsistency of sequentially-scanned data sets and improve iodine
quantification accuracy in sequentially-scanning DECT. ACCELERATION has been
validated and evaluated using numerical simulation data sets generated from
clinical human subject exams. Results demonstrated the improvement of iodine
quantification accuracy using ACCELERATION.

ÊëòË¶ÅÔºöÈõôËÉΩÈõªËÖ¶Êñ∑Â±§ÊéÉÊèè (DECT) Â∑≤Âª£Ê≥õÁî®ÊñºÂèñÂæóÂΩ±ÂÉèÂåñÂèóË©¶ËÄÖÁöÑÂÆöÈáèÂÖÉÁ¥†ÁµÑÊàêÔºå‰ª•ÈÄ≤Ë°åÂÄã‰∫∫Âåñ‰∏îÁ≤æÁ¢∫ÁöÑÈÜ´ÁôÇË®∫Êñ∑„ÄÇËàáÂà©Áî®ÂÖàÈÄ≤ X ÂÖâÊ∫êÂíå/ÊàñÂÅµÊ∏¨Âô®ÊäÄË°ìÁöÑÁèæÊúâÈ´òÈöé DECT Áõ∏ÊØîÔºå‰ΩøÁî®ÈÄ£Á∫åÊéÉÊèèË≥áÊñôÊì∑ÂèñÊñπÊ°à‰æÜÂØ¶‰Ωú DECT ÂèØËÉΩÂ∞çËá®Â∫äÂØ¶ÂãôÈÄ†ÊàêÊõ¥Âª£Ê≥õÁöÑÂΩ±ÈüøÔºåÂõ†ÁÇ∫Ê≠§ÊñπÊ°à‰∏çÈúÄË¶ÅÂ∞àÈñÄÁöÑÁ°¨È´îË®≠Ë®à„ÄÇÁÑ∂ËÄåÔºåÁî±ÊñºÂΩ±ÂÉèÂåñÂèóË©¶ËÄÖ‰∏≠Á¢òÂåñÂ∞çÊØîÂäëÁöÑÊøÉÂ∫¶ÊúÉÈö®ËëóÊôÇÈñìËÄåËÆäÂåñÔºåÂõ†Ê≠§Âú®ÂÖ©ÂÄãÁÆ°Èõª‰Ωç‰∏ãÊì∑ÂèñÁöÑÈÄ£Á∫åÊéÉÊèèË≥áÊñôÈõÜÂú®ÊôÇÈñì‰∏ä‰∏¶‰∏ç‰∏ÄËá¥„ÄÇÁî±Êñº DECT ÁèæÊúâÁöÑÊùêÊñôÂàÜËß£ÊñπÊ≥ïÂÅáË®≠Âú®ÂÖ©ÂÄãÁÆ°Èõª‰Ωç‰∏ãÊì∑ÂèñÁöÑË≥áÊñôÈõÜÂú®ÊôÇÈñì‰∏äÊòØ‰∏ÄËá¥ÁöÑÔºåÂõ†Ê≠§ÈÅïÂèçÊ≠§ÂÅáË®≠ÊúÉÂ∞éËá¥Á¢òÊøÉÂ∫¶ÁöÑÂÆöÈáèÊ∫ñÁ¢∫Â∫¶‰∏çÊ∫ñÁ¢∫„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÈñãÁôº‰∫Ü‰∏ÄÁ®ÆÊäÄË°ìÔºå‰ΩøÁî®È´òÊôÇÈñìËß£ÊûêÂ∫¶ÂΩ±ÂÉèÈáçÂª∫ÂíåÊôÇÈñìÂ§ñÊé®Ê≥ï‰æÜÈÅîÊàêÈÄ£Á∫åÊéÉÊèè DECT ÂΩ±ÂÉèÔºåÁ∞°Á®± ACCELERATIONÔºå‰ª•Ëß£Ê±∫ÈÄ£Á∫åÊéÉÊèèË≥áÊñôÈõÜÁöÑÊôÇÈñì‰∏ç‰∏ÄËá¥ÊÄßÊâÄÈÄ†ÊàêÁöÑÊäÄË°ìÊåëÊà∞Ôºå‰∏¶ÊîπÂñÑÈÄ£Á∫åÊéÉÊèè DECT ‰∏≠ÁöÑÁ¢òÂÆöÈáèÊ∫ñÁ¢∫Â∫¶„ÄÇACCELERATION Â∑≤‰ΩøÁî®ÂæûËá®Â∫ä‰∫∫È´îÂèóË©¶ËÄÖÊ™¢Êü•‰∏≠Áî¢ÁîüÁöÑÊï∏ÂÄºÊ®°Êì¨Ë≥áÊñôÈõÜÈÄ≤Ë°åÈ©óË≠âÂíåË©ï‰º∞„ÄÇÁµêÊûúË≠âÊòé‰ΩøÁî® ACCELERATION ÂèØÊîπÂñÑÁ¢òÂÆöÈáèÊ∫ñÁ¢∫Â∫¶„ÄÇ

##### **Med42-v2: A Suite of Clinical LLMs**
2408.06142v1 by Cl√©ment Christophe, Praveen K Kanithi, Tathagata Raha, Shadab Khan, Marco AF Pimentel

Med42-v2 introduces a suite of clinical large language models (LLMs) designed
to address the limitations of generic models in healthcare settings. These
models are built on Llama3 architecture and fine-tuned using specialized
clinical data. They underwent multi-stage preference alignment to effectively
respond to natural prompts. While generic models are often preference-aligned
to avoid answering clinical queries as a precaution, Med42-v2 is specifically
trained to overcome this limitation, enabling its use in clinical settings.
Med42-v2 models demonstrate superior performance compared to the original
Llama3 models in both 8B and 70B parameter configurations and GPT-4 across
various medical benchmarks. These LLMs are developed to understand clinical
queries, perform reasoning tasks, and provide valuable assistance in clinical
environments. The models are now publicly available at
\href{https://huggingface.co/m42-health}{https://huggingface.co/m42-health}.

ÊëòË¶ÅÔºöMed42-v2 ÂºïÈÄ≤‰∫Ü‰∏ÄÂ•óËá®Â∫äÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM)ÔºåÊó®Âú®Ëß£Ê±∫ÈÜ´ÁôÇ‰øùÂÅ•Áí∞Â¢É‰∏≠ÈÄöÁî®Ê®°ÂûãÁöÑÈôêÂà∂„ÄÇÈÄô‰∫õÊ®°ÂûãÂª∫Á´ãÂú® Llama3 Êû∂Êßã‰∏äÔºå‰∏¶‰ΩøÁî®Â∞àÊ•≠Ëá®Â∫äË≥áÊñôÈÄ≤Ë°åÂæÆË™ø„ÄÇÂÆÉÂÄëÁ∂ìÊ≠∑‰∫ÜÂ§öÈöéÊÆµÂÅèÂ•ΩË™øÊï¥Ôºå‰ª•ÊúâÊïàÂõûÊáâËá™ÁÑ∂ÊèêÁ§∫„ÄÇÈõñÁÑ∂ÈÄöÁî®Ê®°ÂûãÈÄöÂ∏∏ÂÅèÂ•ΩË™øÊï¥ÁÇ∫ÈÅøÂÖçÈ†êÈò≤ÊÄßÂõûÁ≠îËá®Â∫äÊü•Ë©¢Ôºå‰ΩÜ Med42-v2 Á∂ìÈÅéÁâπÂà•Ë®ìÁ∑¥‰ª•ÂÖãÊúçÊ≠§ÈôêÂà∂Ôºå‰ΩøÂÖ∂ËÉΩÂ§†Âú®Ëá®Â∫äÁí∞Â¢É‰∏≠‰ΩøÁî®„ÄÇËàáÂéüÂßã Llama3 Ê®°ÂûãÁõ∏ÊØîÔºåMed42-v2 Ê®°ÂûãÂú® 8B Âíå 70B ÂèÉÊï∏ÈÖçÁΩÆ‰ª•Âèä GPT-4 ‰∏≠Ë°®ÁèæÂá∫ÂÑ™Áï∞ÁöÑÊïàËÉΩÔºåÊ©´Ë∑®ÂêÑÁ®ÆÈÜ´ÁôÇÂü∫Ê∫ñ„ÄÇÈÄô‰∫õ LLM Ë¢´ÈñãÁôºÁî®ÊñºÁêÜËß£Ëá®Â∫äÊü•Ë©¢„ÄÅÂü∑Ë°åÊé®ÁêÜ‰ªªÂãôÔºå‰∏¶Âú®Ëá®Â∫äÁí∞Â¢É‰∏≠Êèê‰æõÊúâÂÉπÂÄºÁöÑÂçîÂä©„ÄÇÈÄô‰∫õÊ®°ÂûãÁèæÂú®Â∑≤Êñº \href{https://huggingface.co/m42-health}{https://huggingface.co/m42-health} ÂÖ¨ÈñãÊèê‰æõ„ÄÇ

##### **Real-Time Drowsiness Detection Using Eye Aspect Ratio and Facial Landmark Detection**
2408.05836v1 by Varun Shiva Krishna Rupani, Velpooru Venkata Sai Thushar, Kondadi Tejith

Drowsiness detection is essential for improving safety in areas such as
transportation and workplace health. This study presents a real-time system
designed to detect drowsiness using the Eye Aspect Ratio (EAR) and facial
landmark detection techniques. The system leverages Dlibs pre-trained shape
predictor model to accurately detect and monitor 68 facial landmarks, which are
used to compute the EAR. By establishing a threshold for the EAR, the system
identifies when eyes are closed, indicating potential drowsiness. The process
involves capturing a live video stream, detecting faces in each frame,
extracting eye landmarks, and calculating the EAR to assess alertness. Our
experiments show that the system reliably detects drowsiness with high accuracy
while maintaining low computational demands. This study offers a strong
solution for real-time drowsiness detection, with promising applications in
driver monitoring and workplace safety. Future research will investigate
incorporating additional physiological and contextual data to further enhance
detection accuracy and reliability.

ÊëòË¶ÅÔºöÁûåÁù°Ê™¢Ê∏¨Â∞çÊñºÊîπÂñÑÈÅãËº∏ÂíåËÅ∑Â†¥ÂÅ•Â∫∑Á≠âÈ†òÂüüÁöÑÂÆâÂÖ®Ëá≥ÈóúÈáçË¶Å„ÄÇÊú¨Á†îÁ©∂ÊèêÂá∫‰∏ÄÂÄãÂç≥ÊôÇÁ≥ªÁµ±ÔºåÊó®Âú®‰ΩøÁî®ÁúºÁùõÈï∑ÂØ¨ÊØî (EAR) ÂíåÈù¢ÈÉ®ÁâπÂæµÊ™¢Ê∏¨ÊäÄË°ì‰æÜÊ™¢Ê∏¨ÁûåÁù°„ÄÇË©≤Á≥ªÁµ±Âà©Áî® Dlibs È†êÂÖàË®ìÁ∑¥ÁöÑÂΩ¢ÁãÄÈ†êÊ∏¨Ê®°Âûã‰æÜÊ∫ñÁ¢∫Ê™¢Ê∏¨ÂíåÁõ£Êéß 68 ÂÄãÈù¢ÈÉ®ÁâπÂæµÔºåÈÄô‰∫õÁâπÂæµÁî®ÊñºË®àÁÆó EAR„ÄÇÈÄöÈÅéÁÇ∫ EAR Ë®≠ÂÆö‰∏ÄÂÄãÈñæÂÄºÔºåË©≤Á≥ªÁµ±ÂèØ‰ª•Ë≠òÂà•ÁúºÁùõÈñâ‰∏äÁöÑÊôÇÈñìÔºåË°®ÊòéÂèØËÉΩÊúâÁûåÁù°„ÄÇÈÄôÂÄãÈÅéÁ®ãÂåÖÊã¨Êì∑ÂèñÂç≥ÊôÇË¶ñË®ä‰∏≤ÊµÅ„ÄÅÊ™¢Ê∏¨ÊØè‰∏ÄÂπÄ‰∏≠ÁöÑËáâÈÉ®„ÄÅÊèêÂèñÁúºÁùõÁâπÂæµÔºå‰∏¶Ë®àÁÆó EAR ‰æÜË©ï‰º∞Ë≠¶Ë¶∫ÊÄß„ÄÇÊàëÂÄëÁöÑÂØ¶È©óË°®ÊòéÔºåË©≤Á≥ªÁµ±ÂèØ‰ª•ÂèØÈù†Âú∞Ê™¢Ê∏¨ÁûåÁù°ÔºåÊ∫ñÁ¢∫Â∫¶È´òÔºåÂêåÊôÇ‰øùÊåÅ‰ΩéÈÅãÁÆóÈúÄÊ±Ç„ÄÇÊú¨Á†îÁ©∂ÁÇ∫Âç≥ÊôÇÁûåÁù°Ê™¢Ê∏¨Êèê‰æõ‰∫Ü‰∏ÄÂÄãÂº∑Â§ßÁöÑËß£Ê±∫ÊñπÊ°àÔºåÂú®ÈßïÈßõÂì°Áõ£ÊéßÂíåËÅ∑Â†¥ÂÆâÂÖ®ÊñπÈù¢ÊúâÂª£Ê≥õÁöÑÊáâÁî®ÂâçÊôØ„ÄÇÊú™‰æÜÁöÑÁ†îÁ©∂Â∞áÊé¢Ë®éÊï¥ÂêàÈ°çÂ§ñÁöÑÁîüÁêÜÂíåÁí∞Â¢ÉË≥áÊñôÔºå‰ª•ÈÄ≤‰∏ÄÊ≠•ÊèêÈ´òÊ™¢Ê∏¨Ê∫ñÁ¢∫Â∫¶ÂíåÂèØÈù†ÊÄß„ÄÇ

##### **TC-KANRecon: High-Quality and Accelerated MRI Reconstruction via Adaptive KAN Mechanisms and Intelligent Feature Scaling**
2408.05705v1 by Ruiquan Ge, Xiao Yu, Yifei Chen, Fan Jia, Shenghao Zhu, Guanyu Zhou, Yiyu Huang, Chenyan Zhang, Dong Zeng, Changmiao Wang, Qiegen Liu, Shanzhou Niu

Magnetic Resonance Imaging (MRI) has become essential in clinical diagnosis
due to its high resolution and multiple contrast mechanisms. However, the
relatively long acquisition time limits its broader application. To address
this issue, this study presents an innovative conditional guided diffusion
model, named as TC-KANRecon, which incorporates the Multi-Free U-KAN (MF-UKAN)
module and a dynamic clipping strategy. TC-KANRecon model aims to accelerate
the MRI reconstruction process through deep learning methods while maintaining
the quality of the reconstructed images. The MF-UKAN module can effectively
balance the tradeoff between image denoising and structure preservation.
Specifically, it presents the multi-head attention mechanisms and scalar
modulation factors, which significantly enhances the model's robustness and
structure preservation capabilities in complex noise environments. Moreover,
the dynamic clipping strategy in TC-KANRecon adjusts the cropping interval
according to the sampling steps, thereby mitigating image detail loss typically
caused by traditional cropping methods and enriching the visual features of the
images. Furthermore, the MC-Model module incorporates full-sampling k-space
information, realizing efficient fusion of conditional information, enhancing
the model's ability to process complex data, and improving the realism and
detail richness of reconstructed images. Experimental results demonstrate that
the proposed method outperforms other MRI reconstruction methods in both
qualitative and quantitative evaluations. Notably, TC-KANRecon method exhibits
excellent reconstruction results when processing high-noise, low-sampling-rate
MRI data. Our source code is available at
https://github.com/lcbkmm/TC-KANRecon.

ÊëòË¶ÅÔºöÁ£ÅÊåØÈÄ†ÂΩ±ÔºàMRIÔºâÁî±ÊñºÂÖ∂È´òËß£ÊûêÂ∫¶ÂíåÂ§öÈáçÂ∞çÊØîÊ©üÂà∂ÔºåÂ∑≤ÊàêÁÇ∫Ëá®Â∫äË®∫Êñ∑‰∏≠‰∏çÂèØÊàñÁº∫ÁöÑÊäÄË°ì„ÄÇÁÑ∂ËÄåÔºåÁõ∏Â∞çËºÉÈï∑ÁöÑÊì∑ÂèñÊôÇÈñìÈôêÂà∂‰∫ÜÂÖ∂Êõ¥Âª£Ê≥õÁöÑÊáâÁî®„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊú¨Á†îÁ©∂ÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂâµÊñ∞ÁöÑÊ¢ù‰ª∂ÂºïÂ∞éÊì¥Êï£Ê®°ÂûãÔºåÁ®±ÁÇ∫ TC-KANReconÔºåÂÆÉÁµêÂêà‰∫ÜÂ§öËá™Áî± U-KANÔºàMF-UKANÔºâÊ®°ÁµÑÂíå‰∏ÄÂÄãÂãïÊÖãË£ÅÂâ™Á≠ñÁï•„ÄÇTC-KANRecon Ê®°ÂûãÊó®Âú®ÈÄèÈÅéÊ∑±Â∫¶Â≠∏ÁøíÊñπÊ≥ïÂä†ÈÄü MRI ÈáçÂª∫ÈÅéÁ®ãÔºåÂêåÊôÇ‰øùÊåÅÈáçÂª∫ÂΩ±ÂÉèÁöÑÂìÅË≥™„ÄÇMF-UKAN Ê®°ÁµÑÂèØ‰ª•ÊúâÊïàÂπ≥Ë°°ÂΩ±ÂÉèÂéªÂô™ÂíåÁµêÊßã‰øùÁïô‰πãÈñìÁöÑÂèñÊç®„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÂÆÉÂëàÁèæÂ§öÈ†≠Ê≥®ÊÑèÂäõÊ©üÂà∂ÂíåÊ®ôÈáèË™øË£ΩÂõ†Â≠êÔºåÈÄôÈ°ØËëóÂ¢ûÂº∑‰∫ÜÊ®°ÂûãÂú®Ë§áÈõúÂô™ËÅ≤Áí∞Â¢É‰∏≠ÁöÑÁ©©ÂÅ•ÊÄßÂíåÁµêÊßã‰øùÁïôËÉΩÂäõ„ÄÇÊ≠§Â§ñÔºåTC-KANRecon ‰∏≠ÁöÑÂãïÊÖãË£ÅÂâ™Á≠ñÁï•Ê†πÊìöÂèñÊ®£Ê≠•È©üË™øÊï¥Ë£ÅÂâ™ÈñìÈöîÔºåÂæûËÄåÊ∏õËºïÂÇ≥Áµ±Ë£ÅÂâ™ÊñπÊ≥ïÈÄöÂ∏∏ÈÄ†ÊàêÁöÑÂΩ±ÂÉèÁ¥∞ÁØÄÊêçÂ§±Ôºå‰∏¶Ë±êÂØåÂΩ±ÂÉèÁöÑË¶ñË¶∫ÁâπÂæµ„ÄÇÊ≠§Â§ñÔºåMC-Model Ê®°ÁµÑÁµêÂêà‰∫ÜÂÖ®ÂèñÊ®£ k Á©∫ÈñìË≥áË®äÔºåÂØ¶ÁèæÊ¢ù‰ª∂Ë≥áË®äÁöÑÊúâÊïàËûçÂêàÔºåÂ¢ûÂº∑‰∫ÜÊ®°ÂûãËôïÁêÜË§áÈõúË≥áÊñôÁöÑËÉΩÂäõÔºå‰∏¶ÊîπÂñÑ‰∫ÜÈáçÂª∫ÂΩ±ÂÉèÁöÑÁúüÂØ¶ÊÑüÂíåÁ¥∞ÁØÄË±êÂØåÂ∫¶„ÄÇÂØ¶È©óÁµêÊûúË°®ÊòéÔºåÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÂú®ÂÆöÊÄßÂíåÂÆöÈáèË©ï‰º∞‰∏≠ÈÉΩÂÑ™ÊñºÂÖ∂‰ªñ MRI ÈáçÂª∫ÊñπÊ≥ï„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåTC-KANRecon ÊñπÊ≥ïÂú®ËôïÁêÜÈ´òÈõúË®ä„ÄÅ‰ΩéÂèñÊ®£Áéá MRI Ë≥áÊñôÊôÇË°®ÁèæÂá∫ÂÑ™Áï∞ÁöÑÈáçÂª∫ÁµêÊûú„ÄÇÊàëÂÄëÁöÑÂéüÂßãÁ®ãÂºèÁ¢ºÂèØÂú® https://github.com/lcbkmm/TC-KANRecon ÂèñÂæó„ÄÇ

##### **A Novel Momentum-Based Deep Learning Techniques for Medical Image Classification and Segmentation**
2408.05692v1 by Koushik Biswas, Ridal Pal, Shaswat Patel, Debesh Jha, Meghana Karri, Amit Reza, Gorkem Durak, Alpay Medetalibeyoglu, Matthew Antalek, Yury Velichko, Daniela Ladner, Amir Borhani, Ulas Bagci

Accurately segmenting different organs from medical images is a critical
prerequisite for computer-assisted diagnosis and intervention planning. This
study proposes a deep learning-based approach for segmenting various organs
from CT and MRI scans and classifying diseases. Our study introduces a novel
technique integrating momentum within residual blocks for enhanced training
dynamics in medical image analysis. We applied our method in two distinct
tasks: segmenting liver, lung, & colon data and classifying abdominal pelvic CT
and MRI scans. The proposed approach has shown promising results, outperforming
state-of-the-art methods on publicly available benchmarking datasets. For
instance, in the lung segmentation dataset, our approach yielded significant
enhancements over the TransNetR model, including a 5.72% increase in dice
score, a 5.04% improvement in mean Intersection over Union (mIoU), an 8.02%
improvement in recall, and a 4.42% improvement in precision. Hence,
incorporating momentum led to state-of-the-art performance in both segmentation
and classification tasks, representing a significant advancement in the field
of medical imaging.

ÊëòË¶ÅÔºöÊ∫ñÁ¢∫Âú∞ÂæûÈÜ´ÁôÇÂΩ±ÂÉè‰∏≠ÂàÜÂâ≤Âá∫‰∏çÂêåÁöÑÂô®ÂÆòÔºåÊòØÈõªËÖ¶ËºîÂä©Ë®∫Êñ∑Âíå‰ªãÂÖ•Ë¶èÂäÉÁöÑÈóúÈçµÂÖàÊ±∫Ê¢ù‰ª∂„ÄÇÊú¨Á†îÁ©∂ÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂü∫ÊñºÊ∑±Â∫¶Â≠∏ÁøíÁöÑÊñπÊ≥ïÔºåÁî®ÊñºÂàÜÂâ≤ CT Âíå MRI ÊéÉÊèè‰∏≠ÁöÑÂêÑÁ®ÆÂô®ÂÆò‰∏¶Â∞çÁñæÁóÖÈÄ≤Ë°åÂàÜÈ°û„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÂºïÂÖ•‰∫Ü‰∏ÄÁ®ÆÊñ∞ÊäÄË°ìÔºåÂ∞áÂãïÈáèÊï¥ÂêàÂà∞ÊÆòÂ∑ÆÂ°ä‰∏≠Ôºå‰ª•Â¢ûÂº∑ÈÜ´ÁôÇÂΩ±ÂÉèÂàÜÊûê‰∏≠ÁöÑË®ìÁ∑¥ÂãïÊÖã„ÄÇÊàëÂÄëÂ∞áÊñπÊ≥ïÊáâÁî®ÊñºÂÖ©ÂÄã‰∏çÂêåÁöÑ‰ªªÂãôÔºöÂàÜÂâ≤ËÇùËáü„ÄÅËÇ∫ËáüÂíåÁµêËÖ∏Ë≥áÊñôÔºå‰ª•ÂèäÂ∞çËÖπÈÉ®È™®ÁõÜ CT Âíå MRI ÊéÉÊèèÈÄ≤Ë°åÂàÜÈ°û„ÄÇÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÂ∑≤È°ØÁ§∫Âá∫ÊúâÂ∏åÊúõÁöÑÁµêÊûúÔºåÂú®ÂÖ¨ÈñãÁöÑÂü∫Ê∫ñË≥áÊñôÈõÜ‰∏äÂÑ™ÊñºÊúÄÂÖàÈÄ≤ÁöÑÊñπÊ≥ï„ÄÇ‰æãÂ¶ÇÔºåÂú®ËÇ∫ÈÉ®ÂàÜÂâ≤Ë≥áÊñôÈõÜ‰∏≠ÔºåÊàëÂÄëÁöÑÊ®°ÂûãÊØî TransNetR Ê®°ÂûãÁî¢Áîü‰∫ÜÈ°ØËëóÁöÑÊèêÂçáÔºåÂåÖÊã¨È™∞Â≠ê‰øÇÊï∏Â¢ûÂä†‰∫Ü 5.72%ÔºåÂπ≥ÂùáËÅØÂêà‰∫§ÈõÜ (mIoU) ÊèêÈ´ò‰∫Ü 5.04%ÔºåÂè¨ÂõûÁéáÊèêÈ´ò‰∫Ü 8.02%ÔºåÁ≤æÂ∫¶ÊèêÈ´ò‰∫Ü 4.42%„ÄÇÂõ†Ê≠§ÔºåÁµêÂêàÂãïÈáèÂú®ÂàÜÂâ≤ÂíåÂàÜÈ°û‰ªªÂãô‰∏≠ÈÉΩÂ∏∂‰æÜ‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÊïàËÉΩÔºå‰ª£Ë°®‰∫ÜÈÜ´ÁôÇÂΩ±ÂÉèÈ†òÂüüÁöÑÈáçÂ§ßÈÄ≤Â±ï„ÄÇ

##### **Mitigating Metropolitan Carbon Emissions with Dynamic Eco-driving at Scale**
2408.05609v1 by Vindula Jayawardana, Baptiste Freydt, Ao Qu, Cameron Hickert, Edgar Sanchez, Catherine Tang, Mark Taylor, Blaine Leonard, Cathy Wu

The sheer scale and diversity of transportation make it a formidable sector
to decarbonize. Here, we consider an emerging opportunity to reduce carbon
emissions: the growing adoption of semi-autonomous vehicles, which can be
programmed to mitigate stop-and-go traffic through intelligent speed commands
and, thus, reduce emissions. But would such dynamic eco-driving move the needle
on climate change? A comprehensive impact analysis has been out of reach due to
the vast array of traffic scenarios and the complexity of vehicle emissions. We
address this challenge with large-scale scenario modeling efforts and by using
multi-task deep reinforcement learning with a carefully designed network
decomposition strategy. We perform an in-depth prospective impact assessment of
dynamic eco-driving at 6,011 signalized intersections across three major US
metropolitan cities, simulating a million traffic scenarios. Overall, we find
that vehicle trajectories optimized for emissions can cut city-wide
intersection carbon emissions by 11-22%, without harming throughput or safety,
and with reasonable assumptions, equivalent to the national emissions of Israel
and Nigeria, respectively. We find that 10% eco-driving adoption yields 25%-50%
of the total reduction, and nearly 70% of the benefits come from 20% of
intersections, suggesting near-term implementation pathways. However, the
composition of this high-impact subset of intersections varies considerably
across different adoption levels, with minimal overlap, calling for careful
strategic planning for eco-driving deployments. Moreover, the impact of
eco-driving, when considered jointly with projections of vehicle
electrification and hybrid vehicle adoption remains significant. More broadly,
this work paves the way for large-scale analysis of traffic externalities, such
as time, safety, and air quality, and the potential impact of solution
strategies.

ÊëòË¶ÅÔºö<paragraph>ÈÅãËº∏Ê•≠ÁöÑË¶èÊ®°ÂíåÂ§öÊ®£ÊÄß‰ΩøÂÖ∂ÊàêÁÇ∫‰∏ÄÂÄãÈõ£‰ª•ËÑ´Á¢≥ÁöÑÁî¢Ê•≠„ÄÇÂú®Ê≠§ÔºåÊàëÂÄëËÄÉÊÖÆ‰∏ÄÂÄãÊñ∞ËààÁöÑÊ©üÊúÉ‰æÜÊ∏õÂ∞ëÁ¢≥ÊéíÊîæÔºöÂçäËá™ÂãïËªäËºõÁöÑÊé°Áî®Êó•ÁõäÂ¢ûÂä†ÔºåÈÄô‰∫õËªäËºõÂèØÈÄèÈÅéÊô∫ÊÖßÂûãÈÄüÂ∫¶Êåá‰ª§‰æÜÁ∑®Á®ã‰ª•Ê∏õÂ∞ëËµ∞Ëµ∞ÂÅúÂÅúÁöÑ‰∫§ÈÄöÔºåÂæûËÄåÊ∏õÂ∞ëÊéíÊîæ„ÄÇ‰ΩÜÈÄôÁ®ÆÂãïÊÖãÁîüÊÖãÈßïÈßõÊòØÂê¶ÊúÉÂ∞çÊ∞£ÂÄôËÆäÈÅ∑Áî¢ÁîüÂΩ±ÈüøÔºüÁî±Êñº‰∫§ÈÄöÁãÄÊ≥ÅÁúæÂ§ö‰∏îËªäËºõÊéíÊîæË§áÈõúÔºåÂõ†Ê≠§ÁÑ°Ê≥ïÈÄ≤Ë°åÂÖ®Èù¢ÁöÑÂΩ±ÈüøÂàÜÊûê„ÄÇÊàëÂÄëÈÄèÈÅéÂ§ßË¶èÊ®°ÊÉÖÂ¢ÉÂª∫Ê®°Â∑•‰ΩúÂíå‰ΩøÁî®Â§ö‰ªªÂãôÊ∑±Â∫¶Âº∑ÂåñÂ≠∏ÁøíÔºå‰ª•ÂèäÁ≤æÂøÉË®≠Ë®àÁöÑÁ∂≤Ë∑ØÂàÜËß£Á≠ñÁï•‰æÜÊáâÂ∞çÈÄôÈ†ÖÊåëÊà∞„ÄÇÊàëÂÄëÂ∞çÁæéÂúã‰∏âÂ§ßÈÉΩÊúÉÂüéÂ∏Ç 6,011 ÂÄãÊúâ‰ø°ËôüÁöÑ‰∫§ÂèâË∑ØÂè£ÈÄ≤Ë°åÊ∑±ÂÖ•ÁöÑÂâçÁûªÊÄßÂΩ±ÈüøË©ï‰º∞ÔºåÊ®°Êì¨‰∏ÄÁôæËê¨ÂÄã‰∫§ÈÄöÁãÄÊ≥Å„ÄÇÁ∏ΩÈ´îËÄåË®ÄÔºåÊàëÂÄëÁôºÁèæÈáùÂ∞çÊéíÊîæÈáèÊúÄ‰Ω≥ÂåñÁöÑËªäËºõËªåË∑°ÂèØ‰ª•Ê∏õÂ∞ë 11-22% ÁöÑÂüéÂ∏Ç‰∫§ÂèâË∑ØÂè£Á¢≥ÊéíÊîæÔºåËÄå‰∏çÊúÉÊêçÂÆ≥ÂêûÂêêÈáèÊàñÂÆâÂÖ®ÊÄßÔºå‰∏îÊ†πÊìöÂêàÁêÜÁöÑÂÅáË®≠ÔºåÂàÜÂà•Á≠âÊñº‰ª•Ëâ≤ÂàóÂíåÂ•àÂèäÂà©‰∫ûÁöÑÂúãÂÆ∂ÊéíÊîæÈáè„ÄÇÊàëÂÄëÁôºÁèæ 10% ÁöÑÁîüÊÖãÈßïÈßõÊé°Áî®ÁéáÊúÉÁî¢ÁîüÁ∏ΩÊ∏õÈáèÁöÑ 25%-50%ÔºåËÄåËøë 70% ÁöÑÂ•ΩËôï‰æÜËá™ 20% ÁöÑ‰∫§ÂèâË∑ØÂè£ÔºåÈÄôË°®Êòé‰∫ÜËøëÊúüÁöÑÂØ¶ÊñΩÈÄîÂæë„ÄÇÁÑ∂ËÄåÔºåÈÄôÂÄãÈ´òÂΩ±Èüø‰∫§ÂèâË∑ØÂè£Â≠êÈõÜÁöÑÁµÑÊàêÂú®‰∏çÂêåÁöÑÊé°Áî®Áéá‰πãÈñìËÆäÂåñÂæàÂ§ßÔºåÈáçÁñäÊÄßÂæàÂ∞èÔºåÈÄôÈúÄË¶Å‰ªîÁ¥∞ÁöÑÁ≠ñÁï•ÊÄßË¶èÂäÉ‰æÜÈÄ≤Ë°åÁîüÊÖãÈßïÈßõÈÉ®ÁΩ≤„ÄÇÊ≠§Â§ñÔºåÁîüÊÖãÈßïÈßõÁöÑÂΩ±ÈüøÔºåÂú®ËàáËªäËºõÈõªÊ∞£ÂåñÂíåÊ∑∑ÂêàÂãïÂäõËªäËºõÊé°Áî®ÁéáÁöÑÈ†êÊ∏¨ÂÖ±ÂêåËÄÉÈáèÊôÇÔºå‰ªçÁÑ∂È°ØËëó„ÄÇÊõ¥Âª£Ê≥õËÄåË®ÄÔºåÈÄôÈ†ÖÂ∑•‰ΩúÁÇ∫Â§ßË¶èÊ®°ÂàÜÊûê‰∫§ÈÄöÂ§ñÈÉ®ÊÄßÔºà‰æãÂ¶ÇÊôÇÈñì„ÄÅÂÆâÂÖ®ÊÄßÂíåÁ©∫Ê∞£ÂìÅË≥™Ôºâ‰ª•ÂèäËß£Ê±∫Á≠ñÁï•ÁöÑÊΩõÂú®ÂΩ±ÈüøÈã™Âπ≥‰∫ÜÈÅìË∑Ø„ÄÇ</paragraph>

##### **Beyond the Eye: A Relational Model for Early Dementia Detection Using Retinal OCTA Images**
2408.05117v1 by Shouyue Liu, Jinkui Hao, Yonghuai Liu, Huazhu Fu, Xinyu Guo, Shuting Zhang, Yitian Zhao

Early detection of dementia, such as Alzheimer's disease (AD) or mild
cognitive impairment (MCI), is essential to enable timely intervention and
potential treatment. Accurate detection of AD/MCI is challenging due to the
high complexity, cost, and often invasive nature of current diagnostic
techniques, which limit their suitability for large-scale population screening.
Given the shared embryological origins and physiological characteristics of the
retina and brain, retinal imaging is emerging as a potentially rapid and
cost-effective alternative for the identification of individuals with or at
high risk of AD. In this paper, we present a novel PolarNet+ that uses retinal
optical coherence tomography angiography (OCTA) to discriminate early-onset AD
(EOAD) and MCI subjects from controls. Our method first maps OCTA images from
Cartesian coordinates to polar coordinates, allowing approximate sub-region
calculation to implement the clinician-friendly early treatment of diabetic
retinopathy study (ETDRS) grid analysis. We then introduce a multi-view module
to serialize and analyze the images along three dimensions for comprehensive,
clinically useful information extraction. Finally, we abstract the sequence
embedding into a graph, transforming the detection task into a general graph
classification problem. A regional relationship module is applied after the
multi-view module to excavate the relationship between the sub-regions. Such
regional relationship analyses validate known eye-brain links and reveal new
discriminative patterns.

ÊëòË¶ÅÔºöÊó©ÊúüÂÅµÊ∏¨Â§±Êô∫ÁóáÔºå‰æãÂ¶ÇÈòøËå≤Êµ∑ÈªòÁóá (AD) ÊàñËºïÂ∫¶Ë™çÁü•ÈöúÁ§ô (MCI)ÔºåÂ∞çÊñºÂèäÊôÇ‰ªãÂÖ•ÂíåÊΩõÂú®Ê≤ªÁôÇËá≥ÈóúÈáçË¶Å„ÄÇÁî±ÊñºÁõÆÂâçË®∫Êñ∑ÊäÄË°ìÁöÑË§áÈõúÊÄßÈ´ò„ÄÅÊàêÊú¨È´òÔºå‰∏îÂ∏∏Â∏∏ÂÖ∑Êúâ‰æµÂÖ•ÊÄßÔºåÂõ†Ê≠§Ê∫ñÁ¢∫ÂÅµÊ∏¨ AD/MCI Ê•µÂÖ∑ÊåëÊà∞ÊÄßÔºåÈÄô‰πüÈôêÂà∂‰∫ÜÂÖ∂Áî®ÊñºÂ§ßË¶èÊ®°‰∫∫Áæ§ÁØ©Ê™¢ÁöÑÈÅ©Áî®ÊÄß„ÄÇËÄÉÈáèÂà∞Ë¶ñÁ∂≤ËÜúÂíåËÖ¶ÈÉ®ÂÖ∑ÊúâÁõ∏ÂêåÁöÑËÉöËÉéËµ∑Ê∫êÂíåÁîüÁêÜÁâπÊÄßÔºåË¶ñÁ∂≤ËÜúÂΩ±ÂÉèÊ≠£ÈÄêÊº∏ÊàêÁÇ∫‰∏ÄÁ®ÆÊΩõÂú®ÁöÑÂø´ÈÄü‰∏îÂÖ∑ÊàêÊú¨ÊïàÁõäÁöÑÊõø‰ª£ÊñπÊ°àÔºåÁî®ÊñºÊâæÂá∫ÁΩπÊÇ£ AD ÊàñÂÖ∑ÊúâÈ´òÈ¢®Èö™ÁöÑÂÄã‰∫∫„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂâµÊñ∞ÁöÑ PolarNet+ÔºåÂÆÉ‰ΩøÁî®Ë¶ñÁ∂≤ËÜúÂÖâÂ≠∏Áõ∏Âπ≤Êñ∑Â±§Ë°ÄÁÆ°ÈÄ†ÂΩ± (OCTA) ‰æÜÂçÄÂàÜÊó©ÁôºÊÄß AD (EOAD) Âíå MCI ÂèóË©¶ËÄÖËàáÂ∞çÁÖßÁµÑ„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÈ¶ñÂÖàÂ∞á OCTA ÂΩ±ÂÉèÂæûÁ¨õÂç°ÁàæÂùêÊ®ôËΩâÊèõÁÇ∫Ê•µÂùêÊ®ôÔºåËÆìËøë‰ººÂ≠êÂçÄÂüüË®àÁÆóÂæó‰ª•ÂØ¶‰ΩúÔºåÈÄ≤ËÄåÂü∑Ë°åÂ∞çËá®Â∫äÈÜ´Â∏´ÂèãÂñÑÁöÑÁ≥ñÂ∞øÁóÖË¶ñÁ∂≤ËÜúÁóÖËÆäÊó©ÊúüÊ≤ªÁôÇÁ†îÁ©∂ (ETDRS) Ê†ºÁ∑öÂàÜÊûê„ÄÇÊé•ËëóÔºåÊàëÂÄëÂºïÂÖ•‰∏ÄÂÄãÂ§öË¶ñÂúñÊ®°ÁµÑÔºåÁî®Êñº‰∏≤ÂàóÂåñ‰∏¶Ê≤øËëó‰∏âÂÄãÂêëÂ∫¶ÂàÜÊûêÂΩ±ÂÉèÔºå‰ª•ÈÄ≤Ë°åÂÖ®Èù¢ÁöÑ„ÄÅËá®Â∫ä‰∏äÊúâÁî®ÁöÑË≥áË®äËêÉÂèñ„ÄÇÊúÄÂæåÔºåÊàëÂÄëÂ∞áÂ∫èÂàóÂµåÂÖ•ÊäΩË±°ÂåñÁÇ∫‰∏ÄÂÄãÂúñÂΩ¢ÔºåÂ∞áÂÅµÊ∏¨‰ªªÂãôËΩâÊèõÁÇ∫‰∏ÄÂÄãÈÄöÁî®ÁöÑÂúñÂΩ¢ÂàÜÈ°ûÂïèÈ°å„ÄÇÂú®Â§öË¶ñÂúñÊ®°ÁµÑÂæåÊáâÁî®ÂçÄÂüüÈóú‰øÇÊ®°ÁµÑÔºå‰ª•Êé¢Ë®éÂ≠êÂçÄÂüü‰πãÈñìÁöÑÈóú‰øÇ„ÄÇÊ≠§È°ûÂçÄÂüüÈóú‰øÇÂàÜÊûêÈ©óË≠â‰∫ÜÂ∑≤Áü•ÁöÑË¶ñÁ∂≤ËÜúËàáËÖ¶ÈÉ®ÈóúËÅØÔºå‰∏¶Êè≠Á§∫‰∫ÜÊñ∞ÁöÑÂà§Âà•Ê®°Âºè„ÄÇ

##### **RT-Surv: Improving Mortality Prediction After Radiotherapy with Large Language Model Structuring of Large-Scale Unstructured Electronic Health Records**
2408.05074v1 by Sangjoon Park, Chan Woo Wee, Seo Hee Choi, Kyung Hwan Kim, Jee Suk Chang, Hong In Yoon, Ik Jae Lee, Yong Bae Kim, Jaeho Cho, Ki Chang Keum, Chang Geol Lee, Hwa Kyung Byun, Woong Sub Koom

Accurate patient selection is critical in radiotherapy (RT) to prevent
ineffective treatments. Traditional survival prediction models, relying on
structured data, often lack precision. This study explores the potential of
large language models (LLMs) to structure unstructured electronic health record
(EHR) data, thereby improving survival prediction accuracy through
comprehensive clinical information integration. Data from 34,276 patients
treated with RT at Yonsei Cancer Center between 2013 and 2023 were analyzed,
encompassing both structured and unstructured data. An open-source LLM was used
to structure the unstructured EHR data via single-shot learning, with its
performance compared against a domain-specific medical LLM and a smaller
variant. Survival prediction models were developed using statistical, machine
learning, and deep learning approaches, incorporating both structured and
LLM-structured data. Clinical experts evaluated the accuracy of the
LLM-structured data. The open-source LLM achieved 87.5% accuracy in structuring
unstructured EHR data without additional training, significantly outperforming
the domain-specific medical LLM, which reached only 35.8% accuracy. Larger LLMs
were more effective, particularly in extracting clinically relevant features
like general condition and disease extent, which closely correlated with
patient survival. Incorporating LLM-structured clinical features into survival
prediction models significantly improved accuracy, with the C-index of deep
learning models increasing from 0.737 to 0.820. These models also became more
interpretable by emphasizing clinically significant factors. This study shows
that general-domain LLMs, even without specific medical training, can
effectively structure large-scale unstructured EHR data, substantially
enhancing the accuracy and interpretability of clinical predictive models.

ÊëòË¶ÅÔºö<paragraph>Âú®ÊîæÂ∞ÑÊ≤ªÁôÇ‰∏≠ÔºåÊ∫ñÁ¢∫ÁöÑÊÇ£ËÄÖÈÅ∏ÊìáËá≥ÈóúÈáçË¶ÅÔºå‰ª•Èò≤Ê≠¢ÁÑ°ÊïàÁöÑÊ≤ªÁôÇ„ÄÇÂÇ≥Áµ±ÁöÑÂ≠òÊ¥ªÈ†êÊ∏¨Ê®°Âûã‰æùË≥¥ÊñºÁµêÊßãÂåñË≥áÊñôÔºåÈÄöÂ∏∏Áº∫‰πèÁ≤æÁ¢∫Â∫¶„ÄÇÊú¨Á†îÁ©∂Êé¢Ë®é‰∫ÜÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁµêÊßãÂåñÈùûÁµêÊßãÂåñÈõªÂ≠êÂÅ•Â∫∑Ë®òÈåÑ (EHR) Ë≥áÊñôÁöÑÊΩõÂäõÔºåÂæûËÄåÈÄöÈÅéÂÖ®Èù¢ÁöÑËá®Â∫äË≥áË®äÊï¥Âêà‰æÜÊèêÈ´òÂ≠òÊ¥ªÈ†êÊ∏¨Ê∫ñÁ¢∫Â∫¶„ÄÇÂàÜÊûê‰∫Ü 2013 Âπ¥Ëá≥ 2023 Âπ¥ÈñìÂú®Âª∂‰∏ñÁôåÁóá‰∏≠ÂøÉÊé•ÂèóÊîæÂ∞ÑÊ≤ªÁôÇÁöÑ 34,276 ÂêçÊÇ£ËÄÖÁöÑË≥áÊñôÔºåÂåÖÊã¨ÁµêÊßãÂåñÂíåÈùûÁµêÊßãÂåñË≥áÊñô„ÄÇ‰ΩøÁî®ÈñãÊ∫ê LLM ÈÄöÈÅéÂñÆÊ¨°Â≠∏Áøí‰æÜÁµêÊßãÂåñÈùûÁµêÊßãÂåñ EHR Ë≥áÊñôÔºå‰∏¶Â∞áÂÖ∂ÊïàËÉΩËàáÁâπÂÆöÈ†òÂüüÁöÑÈÜ´ÁôÇ LLM ÂíåËºÉÂ∞èÁöÑËÆäÈ´îÈÄ≤Ë°åÊØîËºÉ„ÄÇÂ≠òÊ¥ªÈ†êÊ∏¨Ê®°ÂûãÊòØ‰ΩøÁî®Áµ±Ë®à„ÄÅÊ©üÂô®Â≠∏ÁøíÂíåÊ∑±Â∫¶Â≠∏ÁøíÊñπÊ≥ïÈñãÁôºÁöÑÔºåÁµêÂêà‰∫ÜÁµêÊßãÂåñÂíå LLM ÁµêÊßãÂåñÁöÑË≥áÊñô„ÄÇËá®Â∫äÂ∞àÂÆ∂Ë©ï‰º∞‰∫Ü LLM ÁµêÊßãÂåñË≥áÊñôÁöÑÊ∫ñÁ¢∫ÊÄß„ÄÇÈñãÊ∫ê LLM Âú®‰∏çÈÄ≤Ë°åÈ°çÂ§ñË®ìÁ∑¥ÁöÑÊÉÖÊ≥Å‰∏ãÔºåÁµêÊßãÂåñÈùûÁµêÊßãÂåñ EHR Ë≥áÊñôÁöÑÊ∫ñÁ¢∫Â∫¶ÈÅîÂà∞ 87.5%ÔºåÈ°ØËëóÂÑ™ÊñºÁâπÂÆöÈ†òÂüüÁöÑÈÜ´ÁôÇ LLMÔºåÂæåËÄÖÁöÑÊ∫ñÁ¢∫Â∫¶ÂÉÖÈÅîÂà∞ 35.8%„ÄÇËºÉÂ§ßÁöÑ LLM Êõ¥ÊúâÊïàÔºåÁâπÂà•ÊòØÂú®ÊèêÂèñËá®Â∫äÁõ∏ÈóúÁâπÂæµÊñπÈù¢Ôºå‰æãÂ¶Ç‰∏ÄËà¨ÁãÄÊ≥ÅÂíåÁñæÁóÖÁ®ãÂ∫¶ÔºåÈÄôËàáÊÇ£ËÄÖÂ≠òÊ¥ªÁéáÂØÜÂàáÁõ∏Èóú„ÄÇÂ∞á LLM ÁµêÊßãÂåñÁöÑËá®Â∫äÁâπÂæµÁ¥çÂÖ•Â≠òÊ¥ªÈ†êÊ∏¨Ê®°ÂûãÈ°ØËëóÊèêÈ´ò‰∫ÜÊ∫ñÁ¢∫ÊÄßÔºåÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÁöÑ C ÊåáÊï∏Âæû 0.737 ÊèêÈ´òÂà∞ 0.820„ÄÇÈÄô‰∫õÊ®°Âûã‰πüËÆäÂæóÊõ¥ÂÖ∑ÂèØËß£ÈáãÊÄßÔºåÂõ†ÁÇ∫ÂÆÉÂÄëÂº∑Ë™ø‰∫ÜËá®Â∫ä‰∏äÈáçË¶ÅÁöÑÂõ†Á¥†„ÄÇÊú¨Á†îÁ©∂Ë°®ÊòéÔºåÂç≥‰ΩøÊ≤íÊúâÂÖ∑È´îÁöÑÈÜ´ÁôÇË®ìÁ∑¥ÔºåÈÄöÁî®È†òÂüüÁöÑ LLM ‰πüÂèØ‰ª•ÊúâÊïàÂú∞ÁµêÊßãÂåñÂ§ßË¶èÊ®°ÁöÑÈùûÁµêÊßãÂåñ EHR Ë≥áÊñôÔºåÂæûËÄåÈ°ØËëóÊèêÈ´òËá®Â∫äÈ†êÊ∏¨Ê®°ÂûãÁöÑÊ∫ñÁ¢∫ÊÄßÂíåÂèØËß£ÈáãÊÄß„ÄÇ</paragraph>

##### **CROCODILE: Causality aids RObustness via COntrastive DIsentangled LEarning**
2408.04949v1 by Gianluca Carloni, Sotirios A Tsaftaris, Sara Colantonio

Due to domain shift, deep learning image classifiers perform poorly when
applied to a domain different from the training one. For instance, a classifier
trained on chest X-ray (CXR) images from one hospital may not generalize to
images from another hospital due to variations in scanner settings or patient
characteristics. In this paper, we introduce our CROCODILE framework, showing
how tools from causality can foster a model's robustness to domain shift via
feature disentanglement, contrastive learning losses, and the injection of
prior knowledge. This way, the model relies less on spurious correlations,
learns the mechanism bringing from images to prediction better, and outperforms
baselines on out-of-distribution (OOD) data. We apply our method to multi-label
lung disease classification from CXRs, utilizing over 750000 images from four
datasets. Our bias-mitigation method improves domain generalization and
fairness, broadening the applicability and reliability of deep learning models
for a safer medical image analysis. Find our code at:
https://github.com/gianlucarloni/crocodile.

ÊëòË¶ÅÔºöÁî±ÊñºÈ†òÂüüËΩâÊèõÔºåÊ∑±Â∫¶Â≠∏ÁøíÂúñÂÉèÂàÜÈ°ûÂô®Âú®ÊáâÁî®ÊñºËàáË®ìÁ∑¥‰∏çÂêåÁöÑÈ†òÂüüÊôÇË°®Áèæ‰∏ç‰Ω≥„ÄÇ‰æãÂ¶ÇÔºåÈáùÂ∞ç‰∏ÄÂÆ∂ÈÜ´Èô¢ÁöÑËÉ∏ÈÉ® X ÂÖâÔºàCXRÔºâÂΩ±ÂÉèË®ìÁ∑¥ÁöÑÂàÜÈ°ûÂô®ÔºåÁî±ÊñºÊéÉÊèèÂÑÄË®≠ÂÆöÊàñÊÇ£ËÄÖÁâπÂæµÁöÑÂ∑ÆÁï∞ÔºåÂèØËÉΩÁÑ°Ê≥ïÊ¶ÇÂåñÂà∞Âè¶‰∏ÄÂÆ∂ÈÜ´Èô¢ÁöÑÂΩ±ÂÉè„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥πÊàëÂÄëÁöÑ CROCODILE Ê°ÜÊû∂ÔºåÂ±ïÁ§∫Âõ†ÊûúÂ∑•ÂÖ∑Â¶Ç‰ΩïÈÄèÈÅéÁâπÂæµËß£Á≥æÁ∫è„ÄÅÂ∞çÊØîÂ≠∏ÁøíÊêçÂ§±ÂíåÊ≥®ÂÖ•ÂÖàÈ©óÁü•Ë≠ò‰æÜ‰øÉÈÄ≤Ê®°ÂûãÂ∞çÈ†òÂüüËΩâÊèõÁöÑÁ©©ÂÅ•ÊÄß„ÄÇÈÄôÊ®£‰∏Ä‰æÜÔºåÊ®°ÂûãËºÉ‰∏ç‰æùË≥¥ËôõÂÅáÁõ∏ÈóúÊÄßÔºåËÉΩÊõ¥Â•ΩÂú∞Â≠∏ÁøíÂæûÂΩ±ÂÉèÂà∞È†êÊ∏¨ÁöÑÊ©üÂà∂Ôºå‰∏¶Âú®ÂàÜ‰ΩàÂ§ñÔºàOODÔºâË≥áÊñô‰∏äÂÑ™ÊñºÂü∫Á∑ö„ÄÇÊàëÂÄëÂ∞áÊàëÂÄëÁöÑÊ®°ÂûãÊáâÁî®Êñº CXR ÁöÑÂ§öÊ®ôÁ±§ËÇ∫ÈÉ®ÁñæÁóÖÂàÜÈ°ûÔºåÂà©Áî®‰æÜËá™ÂõõÂÄãË≥áÊñôÈõÜÁöÑË∂ÖÈÅé 750,000 ÂºµÂΩ±ÂÉè„ÄÇÊàëÂÄëÁöÑÂÅèÂ∑ÆÁ∑©Ëß£ÊñπÊ≥ïÊîπÂñÑ‰∫ÜÈ†òÂüüÊ¶ÇÂåñÂíåÂÖ¨Âπ≥ÊÄßÔºåÊì¥Â§ß‰∫ÜÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÂú®Êõ¥ÂÆâÂÖ®ÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÊûê‰∏≠ÁöÑÈÅ©Áî®ÊÄßÂíåÂèØÈù†ÊÄß„ÄÇÂú®‰ª•‰∏ãÁ∂≤ÂùÄÊâæÂà∞ÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÔºöhttps://github.com/gianlucarloni/crocodile„ÄÇ

##### **Unleashing Artificial Cognition: Integrating Multiple AI Systems**
2408.04910v3 by Muntasir Adnan, Buddhi Gamage, Zhiwei Xu, Damith Herath, Carlos C. N. Kuhn

In this study, we present an innovative fusion of language models and query
analysis techniques to unlock cognition in artificial intelligence. Our system
seamlessly integrates a Chess engine with a language model, enabling it to
predict moves and provide strategic explanations. Leveraging a vector database
to achieve retrievable answer generation, our OpenSI AI system elucidates its
decision-making process, bridging the gap between raw computation and
human-like understanding. Our choice of Chess as the demonstration environment
underscores the versatility of our approach. Beyond Chess, our system holds
promise for diverse applications, from medical diagnostics to financial
forecasting.

ÊëòË¶ÅÔºöÂú®Êú¨Ê¨°Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫ÜË™ûË®ÄÊ®°ÂûãÂíåÊü•Ë©¢ÂàÜÊûêÊäÄË°ìÁöÑÂâµÊñ∞ËûçÂêàÔºå‰ª•Ëß£Èéñ‰∫∫Â∑•Êô∫ÊÖß‰∏≠ÁöÑË™çÁü•„ÄÇÊàëÂÄëÁöÑÁ≥ªÁµ±Â∞áË•øÊ¥ãÊ£ãÂºïÊìéËàáË™ûË®ÄÊ®°ÂûãÁÑ°Á∏´Êï¥ÂêàÔºå‰ΩøÂÖ∂ËÉΩÂ§†È†êÊ∏¨Ê£ãÊ≠•‰∏¶Êèê‰æõÁ≠ñÁï•Ë™™Êòé„ÄÇÊàëÂÄëÁöÑ OpenSI AI Á≥ªÁµ±Âà©Áî®ÂêëÈáèË≥áÊñôÂ∫´‰æÜÈÅîÊàêÂèØÊì∑ÂèñÁ≠îÊ°àÁöÑÁî¢ÁîüÔºåÈó°ÊòéÂÖ∂Ê±∫Á≠ñÈÅéÁ®ãÔºåÁ∏ÆÂ∞è‰∫ÜÂéüÂßãÈÅãÁÆóËàáÈ°û‰∫∫ÁêÜËß£‰πãÈñìÁöÑÂ∑ÆË∑ù„ÄÇÊàëÂÄëÈÅ∏ÊìáË•øÊ¥ãÊ£ã‰ΩúÁÇ∫Á§∫ÁØÑÁí∞Â¢ÉÔºåÁ™ÅÈ°Ø‰∫ÜÊàëÂÄëÊñπÊ≥ïÁöÑÂ§öÂäüËÉΩÊÄß„ÄÇÈô§‰∫ÜË•øÊ¥ãÊ£ã‰πãÂ§ñÔºåÊàëÂÄëÁöÑÁ≥ªÁµ±ÊúâÊúõÊáâÁî®ÊñºÂêÑÁ®ÆÈ†òÂüüÔºåÂæûÈÜ´ÁôÇË®∫Êñ∑Âà∞Ë≤°ÂãôÈ†êÊ∏¨„ÄÇ

##### **Ensemble BERT: A student social network text sentiment classification model based on ensemble learning and BERT architecture**
2408.04849v1 by Kai Jiang, Honghao Yang, Yuexian Wang, Qianru Chen, Yiming Luo

The mental health assessment of middle school students has always been one of
the focuses in the field of education. This paper introduces a new ensemble
learning network based on BERT, employing the concept of enhancing model
performance by integrating multiple classifiers. We trained a range of
BERT-based learners, which combined using the majority voting method. We
collect social network text data of middle school students through China's
Weibo and apply the method to the task of classifying emotional tendencies in
middle school students' social network texts. Experimental results suggest that
the ensemble learning network has a better performance than the base model and
the performance of the ensemble learning model, consisting of three
single-layer BERT models, is barely the same as a three-layer BERT model but
requires 11.58% more training time. Therefore, in terms of balancing prediction
effect and efficiency, the deeper BERT network should be preferred for
training. However, for interpretability, network ensembles can provide
acceptable solutions.

ÊëòË¶ÅÔºö‰∏≠Â≠∏ÁîüÂøÉÁêÜÂÅ•Â∫∑Ë©ï‰º∞‰∏ÄÁõ¥ÊòØÊïôËÇ≤È†òÂüüÁöÑÈóúÊ≥®ÈáçÈªû‰πã‰∏Ä„ÄÇÊú¨Êñá‰ªãÁ¥π‰∫Ü‰∏ÄÂÄãÂü∫Êñº BERT ÁöÑÊñ∞ÈõÜÊàêÂ≠∏ÁøíÁ∂≤Ë∑ØÔºåÊé°Áî®Êï¥ÂêàÂ§öÂÄãÂàÜÈ°ûÂô®ÁöÑÊ¶ÇÂøµ‰æÜÊèêÂçáÊ®°ÂûãÊïàËÉΩ„ÄÇÊàëÂÄëË®ìÁ∑¥‰∫Ü‰∏ÄÁ≥ªÂàóÂü∫Êñº BERT ÁöÑÂ≠∏ÁøíÂô®Ôºå‰∏¶‰ΩøÁî®Â§öÊï∏Ê±∫ÊäïÁ•®Ê≥ïÈÄ≤Ë°åÁµÑÂêà„ÄÇÊàëÂÄëÈÄèÈÅé‰∏≠ÂúãÂæÆÂçöÊî∂ÈõÜ‰∏≠Â≠∏ÁîüÁöÑÁ§æÁæ§Á∂≤Ë∑ØÊñáÂ≠óË≥áÊñôÔºå‰∏¶Â∞áÊ≠§ÊñπÊ≥ïÊáâÁî®ÊñºÂàÜÈ°û‰∏≠Â≠∏ÁîüÁ§æÁæ§Á∂≤Ë∑ØÊñáÂ≠óÁöÑÊÉÖÁ∑íÂÇæÂêëÁöÑ‰ªªÂãô‰∏≠„ÄÇÂØ¶È©óÁµêÊûúË°®ÊòéÔºåÈõÜÊàêÂ≠∏ÁøíÁ∂≤Ë∑ØÁöÑÊïàËÉΩÂÑ™ÊñºÂü∫Á§éÊ®°ÂûãÔºå‰∏îÁî±‰∏âÂÄãÂñÆÂ±§ BERT Ê®°ÂûãÁµÑÊàêÁöÑÈõÜÊàêÂ≠∏ÁøíÊ®°ÂûãÁöÑÊïàËÉΩËàá‰∏âÂ±§ BERT Ê®°ÂûãÂπæ‰πéÁõ∏ÂêåÔºå‰ΩÜË®ìÁ∑¥ÊôÇÈñìÂçªÂ§ö‰∫Ü 11.58%„ÄÇÂõ†Ê≠§ÔºåÂú®Âπ≥Ë°°È†êÊ∏¨ÊïàÊûúÂíåÊïàÁéáÊñπÈù¢ÔºåÊáâÂÑ™ÂÖàËÄÉÊÖÆËºÉÊ∑±ÁöÑ BERT Á∂≤Ë∑ØÈÄ≤Ë°åË®ìÁ∑¥„ÄÇÁÑ∂ËÄåÔºåÂ∞çÊñºÂèØËß£ÈáãÊÄßËÄåË®ÄÔºåÁ∂≤Ë∑ØÈõÜÊàêÂèØ‰ª•Êèê‰æõÂèØÊé•ÂèóÁöÑËß£Ê±∫ÊñπÊ°à„ÄÇ

##### **Towards Synergistic Deep Learning Models for Volumetric Cirrhotic Liver Segmentation in MRIs**
2408.04491v1 by Vandan Gorade, Onkar Susladkar, Gorkem Durak, Elif Keles, Ertugrul Aktas, Timurhan Cebeci, Alpay Medetalibeyoglu, Daniela Ladner, Debesh Jha, Ulas Bagci

Liver cirrhosis, a leading cause of global mortality, requires precise
segmentation of ROIs for effective disease monitoring and treatment planning.
Existing segmentation models often fail to capture complex feature interactions
and generalize across diverse datasets. To address these limitations, we
propose a novel synergistic theory that leverages complementary latent spaces
for enhanced feature interaction modeling. Our proposed architecture,
nnSynergyNet3D integrates continuous and discrete latent spaces for 3D volumes
and features auto-configured training. This approach captures both fine-grained
and coarse features, enabling effective modeling of intricate feature
interactions. We empirically validated nnSynergyNet3D on a private dataset of
628 high-resolution T1 abdominal MRI scans from 339 patients. Our model
outperformed the baseline nnUNet3D by approximately 2%. Additionally, zero-shot
testing on healthy liver CT scans from the public LiTS dataset demonstrated
superior cross-modal generalization capabilities. These results highlight the
potential of synergistic latent space models to improve segmentation accuracy
and robustness, thereby enhancing clinical workflows by ensuring consistency
across CT and MRI modalities.

ÊëòË¶ÅÔºöËÇùÁ°¨ÂåñÊòØÂÖ®ÁêÉÊ≠ª‰∫°ÁöÑ‰∏ªË¶ÅÂéüÂõ†ÔºåÈúÄË¶ÅÂØπ ROI ËøõË°åÁ≤æÁ°ÆÂàÜÂâ≤Ôºå‰ª•ËøõË°åÊúâÊïàÁöÑÁñæÁóÖÁõëÊµãÂíåÊ≤ªÁñóËÆ°Âàí„ÄÇÁé∞ÊúâÁöÑÂàÜÂâ≤Ê®°ÂûãÈÄöÂ∏∏Êó†Ê≥ïÊçïÊçâÂ§çÊùÇÁöÑÁâπÂæÅ‰∫§‰∫íÔºåÂπ∂Âú®‰∏çÂêåÁöÑÊï∞ÊçÆÈõÜ‰∏äËøõË°åÊ≥õÂåñ„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∫õÈôêÂà∂ÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞È¢ñÁöÑÂçèÂêåÁêÜËÆ∫ÔºåËØ•ÁêÜËÆ∫Âà©Áî®‰∫íË°•ÁöÑÊΩúÂú®Á©∫Èó¥Êù•Â¢ûÂº∫ÁâπÂæÅ‰∫§‰∫íÂª∫Ê®°„ÄÇÊàë‰ª¨ÊèêÂá∫ÁöÑÊû∂ÊûÑ nnSynergyNet3D ÈõÜÊàê‰∫ÜËøûÁª≠ÂíåÁ¶ªÊï£ÁöÑÊΩúÂú®Á©∫Èó¥ÔºåÁî®‰∫é 3D ‰ΩìÁßØÔºåÂπ∂ÂÖ∑ÊúâËá™Âä®ÈÖçÁΩÆÁöÑËÆ≠ÁªÉ„ÄÇËøôÁßçÊñπÊ≥ïÊçïÊçâÂà∞‰∫ÜÁªÜÁ≤íÂ∫¶ÂíåÁ≤óÁ≤íÂ∫¶ÁâπÂæÅÔºå‰ªéËÄåËÉΩÂ§üÊúâÊïàÂú∞ÂØπÂ§çÊùÇÁöÑÁâπÂæÅ‰∫§‰∫íËøõË°åÂª∫Ê®°„ÄÇÊàë‰ª¨Ê†πÊçÆ 339 ÂêçÊÇ£ËÄÖÁöÑ 628 ‰∏™È´òÂàÜËæ®Áéá T1 ËÖπÈÉ® MRI Êâ´ÊèèÁöÑÁßÅÊúâÊï∞ÊçÆÈõÜÂØπ nnSynergyNet3D ËøõË°å‰∫ÜÂÆûËØÅÈ™åËØÅ„ÄÇÊàë‰ª¨ÁöÑÊ®°ÂûãÊØîÂü∫Á∫ø nnUNet3D ÁöÑÊÄßËÉΩÊèêÈ´ò‰∫ÜÂ§ßÁ∫¶ 2%„ÄÇÊ≠§Â§ñÔºåÂú®Êù•Ëá™ÂÖ¨ÂÖ± LiTS Êï∞ÊçÆÈõÜÁöÑÂÅ•Â∫∑ËÇùËÑè CT Êâ´Êèè‰∏äËøõË°åÈõ∂Ê†∑Êú¨ÊµãËØïËØÅÊòé‰∫ÜÂÖ∂ÂçìË∂äÁöÑË∑®Ê®°ÊÄÅÊ≥õÂåñËÉΩÂäõ„ÄÇËøô‰∫õÁªìÊûúÁ™ÅÂá∫‰∫ÜÂçèÂêåÊΩúÂú®Á©∫Èó¥Ê®°ÂûãÂú®ÊèêÈ´òÂàÜÂâ≤Á≤æÂ∫¶ÂíåÈ≤ÅÊ£íÊÄßÊñπÈù¢ÁöÑÊΩúÂäõÔºå‰ªéËÄåÈÄöËøáÁ°Æ‰øù CT Âíå MRI Ê®°ÊÄÅÁöÑ‰∏ÄËá¥ÊÄßÊù•Â¢ûÂº∫‰∏¥Â∫äÂ∑•‰ΩúÊµÅÁ®ã„ÄÇ

##### **Advancing oncology with federated learning: transcending boundaries in breast, lung, and prostate cancer. A systematic review**
2408.05249v1 by Anshu Ankolekar, Sebastian Boie, Maryam Abdollahyan, Emanuela Gadaleta, Seyed Alireza Hasheminasab, Guang Yang, Charles Beauville, Nikolaos Dikaios, George Anthony Kastis, Michael Bussmann, Sara Khalid, Hagen Kruger, Philippe Lambin, Giorgos Papanastasiou

Federated Learning (FL) has emerged as a promising solution to address the
limitations of centralised machine learning (ML) in oncology, particularly in
overcoming privacy concerns and harnessing the power of diverse, multi-center
data. This systematic review synthesises current knowledge on the
state-of-the-art FL in oncology, focusing on breast, lung, and prostate cancer.
Distinct from previous surveys, our comprehensive review critically evaluates
the real-world implementation and impact of FL on cancer care, demonstrating
its effectiveness in enhancing ML generalisability, performance and data
privacy in clinical settings and data. We evaluated state-of-the-art advances
in FL, demonstrating its growing adoption amid tightening data privacy
regulations. FL outperformed centralised ML in 15 out of the 25 studies
reviewed, spanning diverse ML models and clinical applications, and
facilitating integration of multi-modal information for precision medicine.
Despite the current challenges identified in reproducibility, standardisation
and methodology across studies, the demonstrable benefits of FL in harnessing
real-world data and addressing clinical needs highlight its significant
potential for advancing cancer research. We propose that future research should
focus on addressing these limitations and investigating further advanced FL
methods, to fully harness data diversity and realise the transformative power
of cutting-edge FL in cancer care.

ÊëòË¶ÅÔºöËÅØÈÇ¶Â≠∏Áøí (FL) Â∑≤ÊàêÁÇ∫‰∫ÜËß£Ê±∫ËÖ´Áò§Â≠∏‰∏≠ÈõÜ‰∏≠ÂºèÊ©üÂô®Â≠∏Áøí (ML) ÈôêÂà∂ÁöÑÊúâÂâçÈÄîÁöÑËß£Ê±∫ÊñπÊ°àÔºåÁâπÂà•ÊòØÂú®ÂÖãÊúçÈö±ÁßÅÂïèÈ°åÂíåÂà©Áî®Â§ö‰∏≠ÂøÉÁï∞Ë≥™Ë≥áÊñôÁöÑÂäõÈáèÊñπÈù¢„ÄÇÈÄôÈ†ÖÁ≥ªÁµ±ÊÄßÂõûÈ°ßÁ∂úÂêà‰∫ÜËÖ´Áò§Â≠∏‰∏≠ÊúÄÊñ∞ FL ÁöÑÁèæÊúâÁü•Ë≠òÔºåÈáçÈªûÈóúÊ≥®‰π≥Áôå„ÄÅËÇ∫ÁôåÂíåÂâçÂàóËÖ∫Áôå„ÄÇËàáÂÖàÂâçÁöÑË™øÊü•‰∏çÂêåÔºåÊàëÂÄëÁöÑÂÖ®Èù¢ÂõûÈ°ßÊâπÂà§ÊÄßÂú∞Ë©ï‰º∞‰∫Ü FL Âú®ÁôåÁóáÁÖßË≠∑‰∏≠ÁöÑÂØ¶ÈöõÂü∑Ë°åÂíåÂΩ±ÈüøÔºåË≠âÊòé‰∫ÜÂÆÉÂú®Â¢ûÂº∑ ML ÁöÑÊ¶ÇÊã¨ÊÄß„ÄÅÊïàËÉΩÂíåËá®Â∫äÁí∞Â¢ÉÂíåË≥áÊñô‰∏≠ÁöÑË≥áÊñôÈö±ÁßÅÊñπÈù¢ÁöÑÊúâÊïàÊÄß„ÄÇÊàëÂÄëË©ï‰º∞‰∫Ü FL ÁöÑÊúÄÊñ∞ÈÄ≤Â±ïÔºåË≠âÊòé‰∫ÜÂÆÉÂú®Êó•ÁõäÂö¥Ê†ºÁöÑË≥áÊñôÈö±ÁßÅÊ≥ïË¶è‰∏≠Áç≤ÂæóË∂ä‰æÜË∂äÂª£Ê≥õÁöÑÊé°Áî®„ÄÇÂú®ÊâÄÂõûÈ°ßÁöÑ 25 È†ÖÁ†îÁ©∂‰∏≠ÔºåFL Âú® 15 È†ÖÁ†îÁ©∂‰∏≠ÂÑ™ÊñºÈõÜ‰∏≠Âºè MLÔºåÊ∂µËìã‰∫ÜÂ§öÁ®Æ ML Ê®°ÂûãÂíåËá®Â∫äÊáâÁî®Ôºå‰∏¶‰øÉÈÄ≤‰∫ÜÂ§öÊ®°ÂºèË≥áË®äÊï¥Âêà‰ª•ÈÄ≤Ë°åÁ≤æÊ∫ñÈÜ´ÁôÇ„ÄÇÂÑòÁÆ°Âú®ÂêÑÈ†ÖÁ†îÁ©∂‰∏≠ÁôºÁèæ‰∫ÜÂÜçÁèæÊÄß„ÄÅÊ®ôÊ∫ñÂåñÂíåÊñπÊ≥ïÊñπÈù¢ÁöÑÁèæÊúâÊåëÊà∞Ôºå‰ΩÜ FL Âú®Âà©Áî®ÁúüÂØ¶‰∏ñÁïåË≥áÊñôÂíåËß£Ê±∫Ëá®Â∫äÈúÄÊ±ÇÊñπÈù¢Â∑≤Â±ïÁèæÂá∫ÁöÑÂ•ΩËôïÁ™ÅÈ°Ø‰∫ÜÂÖ∂Âú®Êé®ÈÄ≤ÁôåÁóáÁ†îÁ©∂ÊñπÈù¢ÁöÑÂ∑®Â§ßÊΩõÂäõ„ÄÇÊàëÂÄëÂª∫Ë≠∞Êú™‰æÜÁöÑÁ†îÁ©∂ÊáâÈáçÈªûËß£Ê±∫ÈÄô‰∫õÈôêÂà∂Ôºå‰∏¶ÈÄ≤‰∏ÄÊ≠•Á†îÁ©∂ÂÖàÈÄ≤ÁöÑ FL ÊñπÊ≥ïÔºå‰ª•ÂÖÖÂàÜÂà©Áî®Ë≥áÊñôÁöÑÂ§öÊ®£ÊÄßÔºå‰∏¶ÂØ¶ÁèæÂ∞ñÁ´Ø FL Âú®ÁôåÁóáÁÖßË≠∑‰∏≠ÁöÑËΩâÂåñÂäõÈáè„ÄÇ

##### **Non-maximizing policies that fulfill multi-criterion aspirations in expectation**
2408.04385v1 by Simon Dima, Simon Fischer, Jobst Heitzig, Joss Oliver

In dynamic programming and reinforcement learning, the policy for the
sequential decision making of an agent in a stochastic environment is usually
determined by expressing the goal as a scalar reward function and seeking a
policy that maximizes the expected total reward. However, many goals that
humans care about naturally concern multiple aspects of the world, and it may
not be obvious how to condense those into a single reward function.
Furthermore, maximization suffers from specification gaming, where the obtained
policy achieves a high expected total reward in an unintended way, often taking
extreme or nonsensical actions.
  Here we consider finite acyclic Markov Decision Processes with multiple
distinct evaluation metrics, which do not necessarily represent quantities that
the user wants to be maximized. We assume the task of the agent is to ensure
that the vector of expected totals of the evaluation metrics falls into some
given convex set, called the aspiration set. Our algorithm guarantees that this
task is fulfilled by using simplices to approximate feasibility sets and
propagate aspirations forward while ensuring they remain feasible. It has
complexity linear in the number of possible state-action-successor triples and
polynomial in the number of evaluation metrics. Moreover, the explicitly
non-maximizing nature of the chosen policy and goals yields additional degrees
of freedom, which can be used to apply heuristic safety criteria to the choice
of actions. We discuss several such safety criteria that aim to steer the agent
towards more conservative behavior.

ÊëòË¶ÅÔºöÂú®ÂãïÊÖãË¶èÂäÉÂíåÂº∑ÂåñÂ≠∏Áøí‰∏≠Ôºå‰ª£ÁêÜ‰∫∫Âú®Èö®Ê©üÁí∞Â¢É‰∏≠ÈÄ≤Ë°åÈ†ÜÂ∫èÊ±∫Á≠ñÁöÑÁ≠ñÁï•ÈÄöÂ∏∏ÈÄöÈÅéÂ∞áÁõÆÊ®ôË°®ÈÅîÁÇ∫Ê®ôÈáèÁçéÂãµÂáΩÊï∏‰∏¶Â∞ãÊ±ÇÊúÄÂ§ßÂåñÈ†êÊúüÁ∏ΩÁçéÂãµÁöÑÁ≠ñÁï•‰æÜÁ¢∫ÂÆö„ÄÇÁÑ∂ËÄåÔºå‰∫∫È°ûÈóúÂøÉÁöÑË®±Â§öÁõÆÊ®ôËá™ÁÑ∂Ê∂âÂèä‰∏ñÁïåÁöÑÂ§öÂÄãÊñπÈù¢Ôºå‰∏¶‰∏îÂèØËÉΩ‰∏¶‰∏çÊ∏ÖÊ•öÂ¶Ç‰ΩïÂ∞áÈÄô‰∫õÁõÆÊ®ôÊøÉÁ∏ÆÊàêÂñÆ‰∏ÄÁöÑÁçéÂãµÂáΩÊï∏„ÄÇÊ≠§Â§ñÔºåÊúÄÂ§ßÂåñÊúÉÂèóÂà∞Ë¶èÁØÑÂçöÂºàÁöÑÂΩ±ÈüøÔºåÂÖ∂‰∏≠Áç≤ÂæóÁöÑÁ≠ñÁï•‰ª•ÊÑèÂ§ñÁöÑÊñπÂºèÂØ¶Áèæ‰∫ÜÂæàÈ´òÁöÑÈ†êÊúüÁ∏ΩÁçéÂãµÔºåÈÄöÂ∏∏Êé°ÂèñÊ•µÁ´ØÊàñËçíË¨¨ÁöÑË°åÂãï„ÄÇ
Âú®ÈÄôË£°ÔºåÊàëÂÄëËÄÉÊÖÆÂÖ∑ÊúâÂ§öÂÄã‰∏çÂêåË©ï‰º∞ÊåáÊ®ôÁöÑÊúâÈôêÁÑ°Áí∞È¶¨ÂèØÂ§´Ê±∫Á≠ñÈÅéÁ®ãÔºåÈÄô‰∫õÊåáÊ®ô‰∏ç‰∏ÄÂÆöË°®Á§∫Áî®Êà∂Â∏åÊúõÊúÄÂ§ßÂåñÁöÑÊï∏Èáè„ÄÇÊàëÂÄëÂÅáË®≠‰ª£ÁêÜ‰∫∫ÁöÑ‰ªªÂãôÊòØÁ¢∫‰øùË©ï‰º∞ÊåáÊ®ôÈ†êÊúüÁ∏ΩÈáèÁöÑÂêëÈáèËêΩÂÖ•ÊüêÂÄãÁµ¶ÂÆöÁöÑÂá∏ÈõÜÔºåÁ®±ÁÇ∫È°òÊúõÈõÜ„ÄÇÊàëÂÄëÁöÑÊºîÁÆóÊ≥ï‰øùË≠âÈÄöÈÅé‰ΩøÁî®ÂñÆÂΩ¢‰æÜÈÄºËøëÂèØË°åÈõÜ‰∏¶Âú®Á¢∫‰øùÂèØË°åÊÄßÁöÑÂêåÊôÇÂêëÂâçÂÇ≥Êí≠È°òÊúõ‰æÜÂÆåÊàêÊ≠§‰ªªÂãô„ÄÇÂÆÉÁöÑË§áÈõúÂ∫¶ËàáÂèØËÉΩÁöÑÁãÄÊÖã-Âãï‰Ωú-ÂæåÁπº‰∏âÂÖÉÁµÑÁöÑÊï∏ÈáèÂëàÁ∑öÊÄßÈóú‰øÇÔºåËàáË©ï‰º∞ÊåáÊ®ôÁöÑÊï∏ÈáèÂëàÂ§öÈ†ÖÂºèÈóú‰øÇ„ÄÇÊ≠§Â§ñÔºåÊâÄÈÅ∏Á≠ñÁï•ÂíåÁõÆÊ®ôÁöÑÈ°ØÂºèÈùûÊúÄÂ§ßÂåñÊÄßË≥™Áî¢Áîü‰∫ÜÈ°çÂ§ñÁöÑËá™Áî±Â∫¶ÔºåÂèØÁî®ÊñºÂ∞áÂïüÁôºÂºèÂÆâÂÖ®Ê∫ñÂâáÊáâÁî®ÊñºÂãï‰ΩúÁöÑÈÅ∏Êìá„ÄÇÊàëÂÄëË®éË´ñ‰∫ÜÂπæÂÄãÈÄôÊ®£ÁöÑÂÆâÂÖ®Ê∫ñÂâáÔºåÊó®Âú®ÂºïÂ∞é‰ª£ÁêÜ‰∫∫Êé°ÂèñÊõ¥‰øùÂÆàÁöÑË°åÁÇ∫„ÄÇ

##### **AI-Driven Chatbot for Intrusion Detection in Edge Networks: Enhancing Cybersecurity with Ethical User Consent**
2408.04281v1 by Mugheez Asif, Abdul Manan, Abdul Moiz ur Rehman, Mamoona Naveed Asghar, Muhammad Umair

In today's contemporary digital landscape, chatbots have become indispensable
tools across various sectors, streamlining customer service, providing personal
assistance, automating routine tasks, and offering health advice. However,
their potential remains underexplored in the realm of network security,
particularly for intrusion detection. To bridge this gap, we propose an
architecture chatbot specifically designed to enhance security within edge
networks specifically for intrusion detection. Leveraging advanced machine
learning algorithms, this chatbot will monitor network traffic to identify and
mitigate potential intrusions. By securing the network environment using an
edge network managed by a Raspberry Pi module and ensuring ethical user consent
promoting transparency and trust, this innovative solution aims to safeguard
sensitive data and maintain a secure workplace, thereby addressing the growing
need for robust network security measures in the digital age.

ÊëòË¶ÅÔºöÂú®Áï∂‰ªäÁöÑÁèæ‰ª£Êï∏‰ΩçÁí∞Â¢É‰∏≠ÔºåËÅäÂ§©Ê©üÂô®‰∫∫Â∑≤ÊàêÁÇ∫ÂêÑÂÄãÁî¢Ê•≠‰∏çÂèØÊàñÁº∫ÁöÑÂ∑•ÂÖ∑ÔºåÁ∞°ÂåñÂÆ¢Êà∂ÊúçÂãô„ÄÅÊèê‰æõÂÄã‰∫∫ÂçîÂä©„ÄÅËá™ÂãïÂåñ‰æãË°åÂ∑•‰Ωú‰∏¶Êèê‰æõÂÅ•Â∫∑Âª∫Ë≠∞„ÄÇÁÑ∂ËÄåÔºåÂÆÉÂÄëÂú®Á∂≤Ë∑ØÂÆâÂÖ®È†òÂüüÁöÑÊΩõÂäõ‰ªçÊú™ÂæóÂà∞ÂÖÖÂàÜÊé¢Á¥¢ÔºåÁâπÂà•ÊòØÂú®ÂÖ•‰æµÂÅµÊ∏¨ÊñπÈù¢„ÄÇÁÇ∫‰∫ÜÂΩåË£úÈÄôÂÄãÂ∑ÆË∑ùÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂ∞àÈñÄË®≠Ë®àÁî®ÊñºÂ¢ûÂº∑ÈÇäÁ∑£Á∂≤Ë∑ØÂÖßÈÉ®ÂÆâÂÖ®ÊÄßÁöÑÊû∂ÊßãËÅäÂ§©Ê©üÂô®‰∫∫ÔºåÁâπÂà•ÊòØÁî®ÊñºÂÖ•‰æµÂÅµÊ∏¨„ÄÇÈÄèÈÅéÂà©Áî®ÂÖàÈÄ≤ÁöÑÊ©üÂô®Â≠∏ÁøíÊºîÁÆóÊ≥ïÔºåÊ≠§ËÅäÂ§©Ê©üÂô®‰∫∫Â∞áÁõ£ÊéßÁ∂≤Ë∑ØÊµÅÈáè‰ª•Ë≠òÂà•ÂíåÊ∏õËºïÊΩõÂú®ÂÖ•‰æµ„ÄÇÈÄèÈÅé‰ΩøÁî®Áî± Raspberry Pi Ê®°ÁµÑÁÆ°ÁêÜÁöÑÈÇäÁ∑£Á∂≤Ë∑Ø‰æÜ‰øùË≠∑Á∂≤Ë∑ØÁí∞Â¢ÉÔºå‰∏¶Á¢∫‰øùÂêà‰πéÈÅìÂæ∑ÁöÑ‰ΩøÁî®ËÄÖÂêåÊÑè‰ª•‰øÉÈÄ≤ÈÄèÊòéÂ∫¶Âíå‰ø°‰ªªÔºåÈÄôÂÄãÂâµÊñ∞ÁöÑËß£Ê±∫ÊñπÊ°àÊó®Âú®‰øùË≠∑ÊïèÊÑüË≥áÊñô‰∏¶Á∂≠Ë≠∑‰∏ÄÂÄãÂÆâÂÖ®ÁöÑÂ∑•‰ΩúÂ†¥ÊâÄÔºåÂæûËÄåÊªøË∂≥Êï∏‰ΩçÊôÇ‰ª£Â∞çÂº∑Â§ßÁ∂≤Ë∑ØÂÆâÂÖ®Êé™ÊñΩÊó•ÁõäÂ¢ûÈï∑ÁöÑÈúÄÊ±Ç„ÄÇ

##### **Dynamic Fog Computing for Enhanced LLM Execution in Medical Applications**
2408.04680v1 by Philipp Zagar, Vishnu Ravi, Lauren Aalami, Stephan Krusche, Oliver Aalami, Paul Schmiedmayer

The ability of large language models (LLMs) to transform, interpret, and
comprehend vast quantities of heterogeneous data presents a significant
opportunity to enhance data-driven care delivery. However, the sensitive nature
of protected health information (PHI) raises valid concerns about data privacy
and trust in remote LLM platforms. In addition, the cost associated with
cloud-based artificial intelligence (AI) services continues to impede
widespread adoption. To address these challenges, we propose a shift in the LLM
execution environment from opaque, centralized cloud providers to a
decentralized and dynamic fog computing architecture. By executing open-weight
LLMs in more trusted environments, such as the user's edge device or a fog
layer within a local network, we aim to mitigate the privacy, trust, and
financial challenges associated with cloud-based LLMs. We further present
SpeziLLM, an open-source framework designed to facilitate rapid and seamless
leveraging of different LLM execution layers and lowering barriers to LLM
integration in digital health applications. We demonstrate SpeziLLM's broad
applicability across six digital health applications, showcasing its
versatility in various healthcare settings.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâËΩâÊèõ„ÄÅË©ÆÈáãÂíåÁêÜËß£Â§ßÈáèÁï∞Ë≥™Ë≥áÊñôÁöÑËÉΩÂäõÔºåÁÇ∫ÊèêÂçáË≥áÊñôÈ©ÖÂãïÁöÑÁÖßË≠∑Êèê‰æõÈ°ØËëóÁöÑÂ•ëÊ©ü„ÄÇÁÑ∂ËÄåÔºåÂèó‰øùË≠∑ÂÅ•Â∫∑Ë≥áË®äÔºàPHIÔºâÁöÑÊïèÊÑüÊÄßË≥™ÂºïÁôº‰∫ÜÂ∞çË≥áÊñôÈö±ÁßÅÂíåÂ∞çÈÅ†Á´Ø LLM Âπ≥Âè∞‰ø°‰ªªÁöÑÊ≠£Áï∂ÁñëÊÖÆ„ÄÇÊ≠§Â§ñÔºåËàáÈõ≤Á´Ø‰∫∫Â∑•Êô∫ÊÖßÔºàAIÔºâÊúçÂãôÁõ∏ÈóúÁöÑÊàêÊú¨ÊåÅÁ∫åÈòªÁ§ôÂª£Ê≥õÊé°Áî®„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÂª∫Ë≠∞Â∞á LLM Âü∑Ë°åÁí∞Â¢ÉÂæû‰∏çÈÄèÊòéÁöÑÈõÜ‰∏≠ÂºèÈõ≤Á´Ø‰æõÊáâÂïÜËΩâÁßªÂà∞ÂàÜÊï£ÂºèÂãïÊÖãÈúßÈÅãÁÆóÊû∂Êßã„ÄÇÈÄèÈÅéÂú®Êõ¥Âèó‰ø°‰ªªÁöÑÁí∞Â¢É‰∏≠Âü∑Ë°åÈñãÊîæÊ¨äÈáçÁöÑ LLMÔºå‰æãÂ¶Ç‰ΩøÁî®ËÄÖÁöÑÈÇäÁ∑£Ë£ùÁΩÆÊàñÂçÄÂüüÁ∂≤Ë∑ØÂÖßÁöÑÈúßÂ±§ÔºåÊàëÂÄëÊó®Âú®Ê∏õËºïËàáÈõ≤Á´Ø LLM Áõ∏ÈóúÁöÑÈö±ÁßÅ„ÄÅ‰ø°‰ªªÂíåË≤°ÂãôÊåëÊà∞„ÄÇÊàëÂÄëÈÄ≤‰∏ÄÊ≠•ÊèêÂá∫ SpeziLLMÔºå‰∏ÄÂÄãÈñãÊîæÂéüÂßãÁ¢ºÊû∂ÊßãÔºåÊó®Âú®‰øÉÈÄ≤Âø´ÈÄü‰∏îÁÑ°Á∏´Âú∞Âà©Áî®‰∏çÂêåÁöÑ LLM Âü∑Ë°åÂ±§Ôºå‰∏¶Èôç‰Ωé LLM Êï¥ÂêàÂú®Êï∏‰ΩçÂÅ•Â∫∑ÊáâÁî®Á®ãÂºèÁöÑÈöúÁ§ô„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫Ü SpeziLLM Âú®ÂÖ≠ÂÄãÊï∏‰ΩçÂÅ•Â∫∑ÊáâÁî®Á®ãÂºè‰∏≠ÁöÑÂª£Ê≥õÈÅ©Áî®ÊÄßÔºåÂ±ïÁ§∫‰∫ÜÂÖ∂Âú®ÂêÑÁ®ÆÈÜ´ÁôÇ‰øùÂÅ•Áí∞Â¢É‰∏≠ÁöÑÂ§öÂäüËÉΩÊÄß„ÄÇ

##### **The Data Addition Dilemma**
2408.04154v1 by Judy Hanwen Shen, Inioluwa Deborah Raji, Irene Y. Chen

In many machine learning for healthcare tasks, standard datasets are
constructed by amassing data across many, often fundamentally dissimilar,
sources. But when does adding more data help, and when does it hinder progress
on desired model outcomes in real-world settings? We identify this situation as
the \textit{Data Addition Dilemma}, demonstrating that adding training data in
this multi-source scaling context can at times result in reduced overall
accuracy, uncertain fairness outcomes, and reduced worst-subgroup performance.
We find that this possibly arises from an empirically observed trade-off
between model performance improvements due to data scaling and model
deterioration from distribution shift. We thus establish baseline strategies
for navigating this dilemma, introducing distribution shift heuristics to guide
decision-making on which data sources to add in data scaling, in order to yield
the expected model performance improvements. We conclude with a discussion of
the required considerations for data collection and suggestions for studying
data composition and scale in the age of increasingly larger models.

ÊëòË¶ÅÔºöÂú®Ë®±Â§öÈÜ´ÁôÇ‰øùÂÅ•‰ªªÂãôÁöÑÊ©üÂô®Â≠∏Áøí‰∏≠ÔºåÊ®ôÊ∫ñË≥áÊñôÈõÜÊòØÈÄèÈÅéÊî∂ÈõÜ‰æÜËá™Ë®±Â§öÈÄöÂ∏∏Ê†πÊú¨‰∏çÂêåÁöÑ‰æÜÊ∫êÁöÑË≥áÊñôËÄåÂª∫ÊßãÁöÑ„ÄÇ‰ΩÜÊòØÔºå‰ΩïÊôÇÊñ∞Â¢ûÊõ¥Â§öË≥áÊñôÊúâÂπ´Âä©ÔºåËÄå‰ΩïÊôÇÊúÉÈòªÁ§ôÂú®ÁèæÂØ¶‰∏ñÁïåË®≠ÂÆö‰∏≠ÈÅîÊàêÈ†êÊúüÁöÑÊ®°ÂûãÊàêÊûúÔºüÊàëÂÄëÂ∞áÊ≠§ÊÉÖÊ≥ÅË™çÂÆöÁÇ∫„ÄåË≥áÊñôÊñ∞Â¢ûÂõ∞Â¢É„ÄçÔºåË≠âÊòéÂú®Ê≠§Â§ö‰æÜÊ∫êÊì¥ÂÖÖÁöÑËÉåÊôØ‰∏ãÊñ∞Â¢ûË®ìÁ∑¥Ë≥áÊñôÔºåÊúâÊôÇÂèØËÉΩÊúÉÂ∞éËá¥Êï¥È´îÊ∫ñÁ¢∫Â∫¶Èôç‰Ωé„ÄÅ‰∏çÁ¢∫ÂÆöÁöÑÂÖ¨Âπ≥ÊÄßÁµêÊûúÔºå‰ª•ÂèäÊúÄÂ∑ÆÂ≠êÁæ§È´îÊïàËÉΩÈôç‰Ωé„ÄÇÊàëÂÄëÁôºÁèæÈÄôÂèØËÉΩÊòØÁî±ÊñºË≥áÊñôÊì¥ÂÖÖÂ∞éËá¥ÁöÑÊ®°ÂûãÊïàËÉΩÊèêÂçáËàáÂàÜÈÖçËΩâÁßªÂ∞éËá¥ÁöÑÊ®°ÂûãÂä£Âåñ‰πãÈñìÁöÑÁ∂ìÈ©óÊÄßÊ¨äË°°ÊâÄËá¥„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëÂª∫Á´ã‰∫ÜÊáâÂ∞çÊ≠§Âõ∞Â¢ÉÁöÑÂü∫Êú¨Á≠ñÁï•ÔºåÂºïÂÖ•‰∫ÜÂàÜÈÖçËΩâÁßªÂïüÁôºÊ≥ïÔºå‰ª•ÊåáÂ∞éÊúâÈóúÂú®Ë≥áÊñôÊì¥ÂÖÖ‰∏≠Êñ∞Â¢ûÂì™‰∫õË≥áÊñô‰æÜÊ∫êÁöÑÊ±∫Á≠ñÂà∂ÂÆöÔºå‰ª•Áî¢ÁîüÈ†êÊúüÁöÑÊ®°ÂûãÊïàËÉΩÊèêÂçá„ÄÇÊàëÂÄëÊúÄÂæåË®éË´ñ‰∫ÜË≥áÊñôÊî∂ÈõÜÊâÄÈúÄÁöÑËÄÉÈáèÂõ†Á¥†Ôºå‰∏¶Âª∫Ë≠∞Á†îÁ©∂Ë≥áÊñôÁµÑÊàêÂíåË¶èÊ®°Âú®Ê®°ÂûãË¶èÊ®°Êó•ÁõäÊì¥Â§ßÁöÑÊôÇ‰ª£„ÄÇ

##### **Enhancing Healthcare through Large Language Models: A Study on Medical Question Answering**
2408.04138v1 by Haoran Yu, Chang Yu, Zihan Wang, Dongxian Zou, Hao Qin

In recent years, the application of Large Language Models (LLMs) in
healthcare has shown significant promise in improving the accessibility and
dissemination of medical knowledge. This paper presents a detailed study of
various LLMs trained on the MedQuAD medical question-answering dataset, with a
focus on identifying the most effective model for providing accurate medical
information. Among the models tested, the Sentence-t5 combined with Mistral 7B
demonstrated superior performance, achieving a precision score of 0.762. This
model's enhanced capabilities are attributed to its advanced pretraining
techniques, robust architecture, and effective prompt construction
methodologies. By leveraging these strengths, the Sentence-t5 + Mistral 7B
model excels in understanding and generating precise medical answers. Our
findings highlight the potential of integrating sophisticated LLMs in medical
contexts to facilitate efficient and accurate medical knowledge retrieval, thus
significantly enhancing patient education and support.

ÊëòË¶ÅÔºöËøëÂπ¥‰æÜÔºåÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÁöÑÊáâÁî®Â∑≤Â±ïÁèæÂá∫È°ØËëóÁöÑÂ∏åÊúõÔºåÂèØÊîπÂñÑÈÜ´ÁôÇÁü•Ë≠òÁöÑÂèØÂèäÊÄßÂíåÂÇ≥Êí≠„ÄÇÊú¨ÊñáÈáùÂ∞çÂú® MedQuAD ÈÜ´ÁôÇÂïèÁ≠îË≥áÊñôÈõÜ‰∏äË®ìÁ∑¥ÁöÑÂêÑÁ®Æ LLM ÈÄ≤Ë°åË©≥Á¥∞Á†îÁ©∂ÔºåÈáçÈªûÂú®ÊñºÊâæÂá∫Êèê‰æõÊ∫ñÁ¢∫ÈÜ´ÁôÇË≥áË®äÊúÄÊúâÊïàÁöÑÊ®°Âûã„ÄÇÂú®Ê∏¨Ë©¶ÁöÑÊ®°Âûã‰∏≠ÔºåSentence-t5 ÁµêÂêà Mistral 7B Ë°®ÁèæÂÑ™Áï∞ÔºåÈÅîÂà∞ 0.762 ÁöÑÁ≤æÊ∫ñÂ∫¶ÂàÜÊï∏„ÄÇÊ≠§Ê®°ÂûãÁöÑÂ¢ûÂº∑ÂäüËÉΩÊ≠∏ÂäüÊñºÂÖ∂ÂÖàÈÄ≤ÁöÑÈ†êË®ìÁ∑¥ÊäÄË°ì„ÄÅÂº∑Â§ßÁöÑÊû∂ÊßãÂíåÊúâÊïàÁöÑÊèêÁ§∫Âª∫ÊßãÊñπÊ≥ï„ÄÇSentence-t5 + Mistral 7B Ê®°ÂûãËóâÁî±ÈÅãÁî®ÈÄô‰∫õÂÑ™Âã¢ÔºåÂú®ÁêÜËß£ÂíåÁî¢ÁîüÁ≤æÁ¢∫ÁöÑÈÜ´ÁôÇÁ≠îÊ°àÊñπÈù¢Ë°®ÁèæÂá∫Ëâ≤„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÁ™ÅÈ°Ø‰∫ÜÂ∞áË§áÈõúÁöÑ LLM Êï¥ÂêàÂà∞ÈÜ´ÁôÇËÉåÊôØ‰∏≠ÁöÑÊΩõÂäõÔºå‰ª•‰øÉÈÄ≤ÊúâÊïàÁéá‰∏îÊ∫ñÁ¢∫ÁöÑÈÜ´ÁôÇÁü•Ë≠òÊì∑ÂèñÔºåÈÄ≤ËÄåÈ°ØËëóÊèêÂçáÁóÖÊÇ£ÊïôËÇ≤ÂíåÊîØÊåÅ„ÄÇ

##### **Can Rule-Based Insights Enhance LLMs for Radiology Report Classification? Introducing the RadPrompt Methodology**
2408.04121v1 by Panagiotis Fytas, Anna Breger, Ian Selby, Simon Baker, Shahab Shahipasand, Anna Korhonen

Developing imaging models capable of detecting pathologies from chest X-rays
can be cost and time-prohibitive for large datasets as it requires supervision
to attain state-of-the-art performance. Instead, labels extracted from
radiology reports may serve as distant supervision since these are routinely
generated as part of clinical practice. Despite their widespread use, current
rule-based methods for label extraction rely on extensive rule sets that are
limited in their robustness to syntactic variability. To alleviate these
limitations, we introduce RadPert, a rule-based system that integrates an
uncertainty-aware information schema with a streamlined set of rules, enhancing
performance. Additionally, we have developed RadPrompt, a multi-turn prompting
strategy that leverages RadPert to bolster the zero-shot predictive
capabilities of large language models, achieving a statistically significant
improvement in weighted average F1 score over GPT-4 Turbo. Most notably,
RadPrompt surpasses both its underlying models, showcasing the synergistic
potential of LLMs with rule-based models. We have evaluated our methods on two
English Corpora: the MIMIC-CXR gold-standard test set and a gold-standard
dataset collected from the Cambridge University Hospitals.

ÊëòË¶ÅÔºöÈñãÁôºÂá∫ËÉΩÂ§†ÂæûËÉ∏ÈÉ® X ÂÖâÊ™¢Ê∏¨ÁóÖÁêÜÁöÑÂΩ±ÂÉèÊ®°ÂûãÔºåÂ∞çÊñºÂ§ßÂûãË≥áÊñôÈõÜ‰æÜË™™ÔºåÂú®ÊàêÊú¨ÂíåÊôÇÈñì‰∏äÈÉΩÂèØËÉΩÊòØÁ¶ÅÊ≠¢ÁöÑÔºåÂõ†ÁÇ∫ÂÆÉÈúÄË¶ÅÁõ£Áù£ÊâçËÉΩÈÅîÂà∞ÊúÄÂÖàÈÄ≤ÁöÑÊïàËÉΩ„ÄÇÁõ∏ÂèçÂú∞ÔºåÂæûÊîæÂ∞ÑÁßëÂ†±Âëä‰∏≠ÊèêÂèñÁöÑÊ®ôÁ±§ÂèØ‰ª•Áî®‰ΩúÈÅ†Á´ØÁõ£Áù£ÔºåÂõ†ÁÇ∫ÈÄô‰∫õÊ®ôÁ±§ÈÄöÂ∏∏‰ΩúÁÇ∫Ëá®Â∫äÂØ¶ÂãôÁöÑ‰∏ÄÈÉ®ÂàÜËÄåÁî¢Áîü„ÄÇÂÑòÁÆ°Âª£Ê≥õ‰ΩøÁî®Ôºå‰ΩÜÁõÆÂâçÁî®ÊñºÊ®ôÁ±§ÊèêÂèñÁöÑÂü∫ÊñºË¶èÂâáÁöÑÊñπÊ≥ï‰æùË≥¥ÊñºÂª£Ê≥õÁöÑË¶èÂâáÈõÜÔºåÂÖ∂Â∞çË™ûÊ≥ïËÆäÁï∞ÁöÑÂÅ•Â£ØÊÄßÊúâÈôê„ÄÇÁÇ∫‰∫ÜÊ∏õËºïÈÄô‰∫õÈôêÂà∂ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü RadPertÔºåÈÄôÊòØ‰∏ÄÂÄãÂü∫ÊñºË¶èÂâáÁöÑÁ≥ªÁµ±ÔºåÂÆÉÂ∞á‰∏ÄÂÄã‰∏çÁ¢∫ÂÆöÊÄßÊÑüÁü•Ë≥áË®äÊû∂ÊßãËàá‰∏ÄÁµÑÁ∞°ÂåñÁöÑË¶èÂâáÊï¥ÂêàÂú®‰∏ÄËµ∑ÔºåÂæûËÄåÂ¢ûÂº∑‰∫ÜÊïàËÉΩ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÈÇÑÈñãÁôº‰∫Ü RadPromptÔºåÈÄôÊòØ‰∏ÄÂÄãÂ§öËº™ÊèêÁ§∫Á≠ñÁï•ÔºåÂÆÉÂà©Áî® RadPert ‰æÜÂä†Âº∑Â§ßÂûãË™ûË®ÄÊ®°ÂûãÁöÑÈõ∂Ê¨°Â≠∏ÁøíÈ†êÊ∏¨ËÉΩÂäõÔºåÂú®Âä†Ê¨äÂπ≥Âùá F1 ÂàÜÊï∏‰∏äÂØ¶Áèæ‰∫ÜÁõ∏Â∞çÊñº GPT-4 Turbo ÁöÑÁµ±Ë®àÈ°ØËëóÊîπÈÄ≤„ÄÇÊúÄÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåRadPrompt Ë∂ÖË∂ä‰∫ÜÂÖ∂Âü∫Á§éÊ®°ÂûãÔºåÂ±ïÁ§∫‰∫ÜÂü∫ÊñºË¶èÂâáÁöÑÊ®°ÂûãËàá LLM ÁöÑÂçîÂêåÊΩõÂäõ„ÄÇÊàëÂÄëÂ∑≤Âú®ÂÖ©ÂÄãËã±ÊñáË™ûÊñôÂ∫´‰∏äË©ï‰º∞‰∫ÜÊàëÂÄëÁöÑÊñπÊ≥ïÔºöMIMIC-CXR ÈªÉÈáëÊ®ôÊ∫ñÊ∏¨Ë©¶ÈõÜÂíåÂæûÂäçÊ©ãÂ§ßÂ≠∏ÈÜ´Èô¢Êî∂ÈõÜÁöÑÈªÉÈáëÊ®ôÊ∫ñË≥áÊñôÈõÜ„ÄÇ

##### **Multimodal Gender Fairness in Depression Prediction: Insights on Data from the USA & China**
2408.04026v1 by Joseph Cameron, Jiaee Cheong, Micol Spitale, Hatice Gunes

Social agents and robots are increasingly being used in wellbeing settings.
However, a key challenge is that these agents and robots typically rely on
machine learning (ML) algorithms to detect and analyse an individual's mental
wellbeing. The problem of bias and fairness in ML algorithms is becoming an
increasingly greater source of concern. In concurrence, existing literature has
also indicated that mental health conditions can manifest differently across
genders and cultures. We hypothesise that the representation of features
(acoustic, textual, and visual) and their inter-modal relations would vary
among subjects from different cultures and genders, thus impacting the
performance and fairness of various ML models. We present the very first
evaluation of multimodal gender fairness in depression manifestation by
undertaking a study on two different datasets from the USA and China. We
undertake thorough statistical and ML experimentation and repeat the
experiments for several different algorithms to ensure that the results are not
algorithm-dependent. Our findings indicate that though there are differences
between both datasets, it is not conclusive whether this is due to the
difference in depression manifestation as hypothesised or other external
factors such as differences in data collection methodology. Our findings
further motivate a call for a more consistent and culturally aware data
collection process in order to address the problem of ML bias in depression
detection and to promote the development of fairer agents and robots for
wellbeing.

ÊëòË¶ÅÔºöÁ§æÁæ§‰ª£ÁêÜ‰∫∫ÂíåÊ©üÂô®‰∫∫Âú®Âπ∏Á¶èÊÑüË®≠ÂÆö‰∏≠Ê≠£Ë∂ä‰æÜË∂äÂª£Ê≥õÂú∞Ë¢´‰ΩøÁî®„ÄÇ
ÁÑ∂ËÄåÔºå‰∏ÄÂÄãÈóúÈçµÁöÑÊåëÊà∞ÊòØÈÄô‰∫õ‰ª£ÁêÜ‰∫∫ÂíåÊ©üÂô®‰∫∫ÈÄöÂ∏∏‰æùË≥¥Ê©üÂô®Â≠∏Áøí (ML) ÊºîÁÆóÊ≥ï‰æÜÂÅµÊ∏¨ÂíåÂàÜÊûêÂÄã‰∫∫ÂøÉÁêÜÂÅ•Â∫∑„ÄÇML ÊºîÁÆóÊ≥ï‰∏≠ÁöÑÂÅèÂ∑ÆÂíåÂÖ¨Âπ≥ÊÄßÂïèÈ°åÊ≠£ÊàêÁÇ∫Ë∂ä‰æÜË∂äÂ§ßÁöÑÈóúÊ≥®‰æÜÊ∫ê„ÄÇÂêåÊôÇÔºåÁèæÊúâÊñáÁçª‰πüÊåáÂá∫ÂøÉÁêÜÂÅ•Â∫∑ÁãÄÊ≥ÅÊúÉÂú®‰∏çÂêåÊÄßÂà•ÂíåÊñáÂåñ‰∏≠‰ª•‰∏çÂêåÁöÑÊñπÂºèÈ°ØÁèæ„ÄÇÊàëÂÄëÂÅáË®≠ÁâπÂæµÔºàËÅ≤Èü≥„ÄÅÊñáÂ≠óÂíåË¶ñË¶∫ÔºâÁöÑÂëàÁèæÂèäÂÖ∂Ë∑®Ê®°ÊÖãÈóú‰øÇÊúÉÂõ†‰∏çÂêåÊñáÂåñÂíåÊÄßÂà•ÁöÑÂèóË©¶ËÄÖËÄåÁï∞ÔºåÂæûËÄåÂΩ±ÈüøÂêÑÁ®Æ ML Ê®°ÂûãÁöÑÊïàËÉΩÂíåÂÖ¨Âπ≥ÊÄß„ÄÇÊàëÂÄëÈÄèÈÅéÂ∞ç‰æÜËá™ÁæéÂúãÂíå‰∏≠ÂúãÁöÑÂÖ©ÂÄã‰∏çÂêåË≥áÊñôÈõÜÈÄ≤Ë°åÁ†îÁ©∂ÔºåÊèêÂá∫È¶ñÊ¨°Â∞çÊÜÇÈ¨±ÁóáË°®ÁèæÁöÑÂ§öÊ®°ÊÖãÊÄßÂà•ÂÖ¨Âπ≥ÊÄßË©ï‰º∞„ÄÇÊàëÂÄëÈÄ≤Ë°åÂæπÂ∫ïÁöÑÁµ±Ë®àÂíå ML ÂØ¶È©óÔºå‰∏¶ÈáùÂ∞çÂ§öÁ®Æ‰∏çÂêåÁöÑÊºîÁÆóÊ≥ïÈáçË§áÂØ¶È©óÔºå‰ª•Á¢∫‰øùÁµêÊûú‰∏ç‰æùË≥¥ÊñºÊºîÁÆóÊ≥ï„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúË°®ÊòéÔºåÂÑòÁÆ°ÂÖ©ÂÄãË≥áÊñôÈõÜ‰πãÈñìÂ≠òÂú®Â∑ÆÁï∞Ôºå‰ΩÜÁÑ°Ê≥ïÁ¢∫ÂÆöÈÄôÊòØÂê¶ÊòØÁî±ÊñºÂÅáË®≠ÁöÑÊÜÇÈ¨±ÁóáË°®ÁèæÂ∑ÆÁï∞ÊàñÂÖ∂‰ªñÂ§ñÈÉ®Âõ†Á¥†Ôºà‰æãÂ¶ÇË≥áÊñôÊî∂ÈõÜÊñπÊ≥ïÁöÑÂ∑ÆÁï∞ÔºâÊâÄÈÄ†Êàê„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÈÄ≤‰∏ÄÊ≠•ÂëºÁ±≤Êé°Áî®Êõ¥‰∏ÄËá¥‰∏îÂÖ∑ÊúâÊñáÂåñÊÑèË≠òÁöÑË≥áÊñôÊî∂ÈõÜÁ®ãÂ∫èÔºå‰ª•Ëß£Ê±∫ÊÜÇÈ¨±ÁóáÂÅµÊ∏¨‰∏≠ÁöÑ ML ÂÅèÂ∑ÆÂïèÈ°åÔºå‰∏¶‰øÉÈÄ≤ÈñãÁôºÊõ¥ÂÖ¨Âπ≥ÁöÑ‰ª£ÁêÜ‰∫∫ÂíåÊ©üÂô®‰∫∫Ôºå‰ª•ÊèêÂçáÂπ∏Á¶èÊÑü„ÄÇ

##### **Inter-Series Transformer: Attending to Products in Time Series Forecasting**
2408.03872v1 by Rares Cristian, Pavithra Harsha, Clemente Ocejo, Georgia Perakis, Brian Quanz, Ioannis Spantidakis, Hamza Zerhouni

Time series forecasting is an important task in many fields ranging from
supply chain management to weather forecasting. Recently, Transformer neural
network architectures have shown promising results in forecasting on common
time series benchmark datasets. However, application to supply chain demand
forecasting, which can have challenging characteristics such as sparsity and
cross-series effects, has been limited.
  In this work, we explore the application of Transformer-based models to
supply chain demand forecasting. In particular, we develop a new
Transformer-based forecasting approach using a shared, multi-task per-time
series network with an initial component applying attention across time series,
to capture interactions and help address sparsity. We provide a case study
applying our approach to successfully improve demand prediction for a medical
device manufacturing company. To further validate our approach, we also apply
it to public demand forecasting datasets as well and demonstrate competitive to
superior performance compared to a variety of baseline and state-of-the-art
forecast methods across the private and public datasets.

ÊëòË¶ÅÔºöÊôÇÈñìÂ∫èÂàóÈ†êÊ∏¨Âú®Ë®±Â§öÈ†òÂüü‰∏≠ÈÉΩÊòØ‰∏ÄÈ†ÖÈáçË¶ÅÁöÑ‰ªªÂãôÔºåÂæû‰æõÊáâÈèàÁÆ°ÁêÜÂà∞Â§©Ê∞£È†êÊ∏¨ÈÉΩÊúâÊ∂âÂèä„ÄÇÊúÄËøëÔºåTransformer Á•ûÁ∂ìÁ∂≤Ë∑ØÊû∂ÊßãÂú®Â∏∏Ë¶ãÊôÇÈñìÂ∫èÂàóÂü∫Ê∫ñË≥áÊñôÈõÜÁöÑÈ†êÊ∏¨‰∏≠Â±ïÁèæ‰∫Ü‰ª§‰∫∫ÊªøÊÑèÁöÑÊàêÊûú„ÄÇÁÑ∂ËÄåÔºåÊáâÁî®Êñº‰æõÊáâÈèàÈúÄÊ±ÇÈ†êÊ∏¨ÁöÑÁØÑÁñáÂèóÂà∞ÈôêÂà∂ÔºåÂõ†ÁÇ∫‰æõÊáâÈèàÈúÄÊ±ÇÈ†êÊ∏¨ÂèØËÉΩÂÖ∑ÊúâÁ®ÄÁñèÊÄßÂíåË∑®Á≥ªÂàóÊïàÊáâÁ≠âÂÖ∑ÊåëÊà∞ÊÄßÁöÑÁâπÂæµ„ÄÇ
  Âú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊé¢Ë®é‰∫ÜÂ∞áÂü∫Êñº Transformer ÁöÑÊ®°ÂûãÊáâÁî®Êñº‰æõÊáâÈèàÈúÄÊ±ÇÈ†êÊ∏¨„ÄÇÁâπÂà•ÊòØÔºåÊàëÂÄëÈñãÁôº‰∫Ü‰∏ÄÁ®ÆÊñ∞ÁöÑÂü∫Êñº Transformer ÁöÑÈ†êÊ∏¨ÊñπÊ≥ïÔºå‰ΩøÁî®‰∏ÄÂÄãÂÖ±Áî®ÁöÑ„ÄÅÊØèÂÄãÊôÇÈñìÂ∫èÂàóÁöÑÂ§ö‰ªªÂãôÁ∂≤Ë∑ØÔºå‰∏¶Âú®ÂàùÂßãÂÖÉ‰ª∂‰∏≠Â•óÁî®Ë∑®ÊôÇÈñìÂ∫èÂàóÁöÑÊ≥®ÊÑèÂäõÔºå‰ª•Êì∑Âèñ‰∫íÂãï‰∏¶ÂçîÂä©Ëß£Ê±∫Á®ÄÁñèÊÄßÂïèÈ°å„ÄÇÊàëÂÄëÊèê‰æõ‰∫Ü‰∏ÄÂÄãÊ°à‰æãÁ†îÁ©∂ÔºåÊáâÁî®ÊàëÂÄëÁöÑÂÅöÊ≥ïÊàêÂäüÊîπÂñÑ‰∫Ü‰∏ÄÂÆ∂ÈÜ´ÁôÇÂô®ÊùêË£ΩÈÄ†ÂÖ¨Âè∏ÁöÑÈúÄÊ±ÇÈ†êÊ∏¨„ÄÇÁÇ∫‰∫ÜÈÄ≤‰∏ÄÊ≠•È©óË≠âÊàëÂÄëÁöÑÂÅöÊ≥ïÔºåÊàëÂÄë‰πüÂ∞áÂÖ∂ÊáâÁî®ÊñºÂÖ¨ÈñãÁöÑÈúÄÊ±ÇÈ†êÊ∏¨Ë≥áÊñôÈõÜÔºå‰∏¶Ë≠âÊòéËàáÂêÑÁ®ÆÂü∫Á∑öÂíåÊúÄÂÖàÈÄ≤ÁöÑÈ†êÊ∏¨ÊñπÊ≥ïÁõ∏ÊØîÔºåÂú®ÁßÅÊúâÂíåÂÖ¨ÈñãË≥áÊñôÈõÜ‰∏≠ÁöÑË°®ÁèæÂÖ∑ÊúâÁ´∂Áà≠ÂäõÊàñÂÑ™ÊñºÈÄô‰∫õÊñπÊ≥ï„ÄÇ

##### **HiQuE: Hierarchical Question Embedding Network for Multimodal Depression Detection**
2408.03648v1 by Juho Jung, Chaewon Kang, Jeewoo Yoon, Seungbae Kim, Jinyoung Han

The utilization of automated depression detection significantly enhances
early intervention for individuals experiencing depression. Despite numerous
proposals on automated depression detection using recorded clinical interview
videos, limited attention has been paid to considering the hierarchical
structure of the interview questions. In clinical interviews for diagnosing
depression, clinicians use a structured questionnaire that includes routine
baseline questions and follow-up questions to assess the interviewee's
condition. This paper introduces HiQuE (Hierarchical Question Embedding
network), a novel depression detection framework that leverages the
hierarchical relationship between primary and follow-up questions in clinical
interviews. HiQuE can effectively capture the importance of each question in
diagnosing depression by learning mutual information across multiple
modalities. We conduct extensive experiments on the widely-used clinical
interview data, DAIC-WOZ, where our model outperforms other state-of-the-art
multimodal depression detection models and emotion recognition models,
showcasing its clinical utility in depression detection.

ÊëòË¶ÅÔºöËá™ÂãïÊÜÇÈ¨±ÁóáÂÅµÊ∏¨ÁöÑÂà©Áî®È°ØËëóÊèêÂçá‰∫ÜÊÜÇÈ¨±ÁóáÊÇ£ËÄÖÁöÑÊó©Êúü‰ªãÂÖ•„ÄÇÂÑòÁÆ°ÊúâË®±Â§ö‰ΩøÁî®ÈåÑË£ΩËá®Â∫äË®™Ë´áÂΩ±ÁâáÁöÑËá™ÂãïÊÜÇÈ¨±ÁóáÂÅµÊ∏¨ÊèêÊ°àÔºå‰ΩÜÂ∞çÊñºËÄÉÈáèË®™Ë´áÂïèÈ°åÁöÑÈöéÂ±§ÁµêÊßãÈÄôÊñπÈù¢ÂçªÈÆÆÂ∞ëÈóúÊ≥®„ÄÇÂú®Áî®ÊñºË®∫Êñ∑ÊÜÇÈ¨±ÁóáÁöÑËá®Â∫äË®™Ë´á‰∏≠ÔºåËá®Â∫äÈÜ´Â∏´ÊúÉ‰ΩøÁî®ÂåÖÂê´‰æãË°åÂü∫Ê∫ñÂïèÈ°åÂíåËøΩËπ§ÂïèÈ°åÁöÑÁµêÊßãÂåñÂïèÂç∑‰æÜË©ï‰º∞ÂèóË®™ËÄÖÁöÑÁãÄÊ≥Å„ÄÇÊú¨Êñá‰ªãÁ¥π‰∫Ü HiQuEÔºàÈöéÂ±§ÂºèÂïèÈ°åÂµåÂÖ•Á∂≤Ë∑ØÔºâÔºåÈÄôÊòØ‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÊÜÇÈ¨±ÁóáÂÅµÊ∏¨Êû∂ÊßãÔºåÂÆÉÂà©Áî®‰∫ÜËá®Â∫äË®™Ë´á‰∏≠‰∏ªË¶ÅÂïèÈ°åÂíåËøΩËπ§ÂïèÈ°å‰πãÈñìÁöÑÈöéÂ±§Èóú‰øÇ„ÄÇHiQuE ËÉΩÂ§†ÈÄèÈÅéÂ≠∏ÁøíÂ§öÁ®ÆÊñπÂºè‰πãÈñìÁöÑ‰∫íÊÉ†Ë≥áË®äÔºåÊúâÊïàÂú∞Êì∑ÂèñÊØèÂÄãÂïèÈ°åÂú®ÊÜÇÈ¨±ÁóáË®∫Êñ∑‰∏≠ÁöÑÈáçË¶ÅÊÄß„ÄÇÊàëÂÄëÂú®Âª£Ê≥õ‰ΩøÁî®ÁöÑËá®Â∫äË®™Ë´áË≥áÊñô DAIC-WOZ ‰∏äÈÄ≤Ë°å‰∫ÜÂª£Ê≥õÁöÑÂØ¶È©óÔºåÊàëÂÄëÁöÑÊ®°ÂûãÂÑ™ÊñºÂÖ∂‰ªñÊúÄÂÖàÈÄ≤ÁöÑÂ§öÊ®°ÊÖãÊÜÇÈ¨±ÁóáÂÅµÊ∏¨Ê®°ÂûãÂíåÊÉÖÁ∑íËæ®Ë≠òÊ®°ÂûãÔºåÂ±ïÁ§∫‰∫ÜÂÖ∂Âú®ÊÜÇÈ¨±ÁóáÂÅµÊ∏¨‰∏≠ÁöÑËá®Â∫äÊïàÁî®„ÄÇ

##### **Improving the quality of Persian clinical text with a novel spelling correction system**
2408.03622v1 by Seyed Mohammad Sadegh Dashti, Seyedeh Fatemeh Dashti

Background: The accuracy of spelling in Electronic Health Records (EHRs) is a
critical factor for efficient clinical care, research, and ensuring patient
safety. The Persian language, with its abundant vocabulary and complex
characteristics, poses unique challenges for real-word error correction. This
research aimed to develop an innovative approach for detecting and correcting
spelling errors in Persian clinical text.
  Methods: Our strategy employs a state-of-the-art pre-trained model that has
been meticulously fine-tuned specifically for the task of spelling correction
in the Persian clinical domain. This model is complemented by an innovative
orthographic similarity matching algorithm, PERTO, which uses visual similarity
of characters for ranking correction candidates.
  Results: The evaluation of our approach demonstrated its robustness and
precision in detecting and rectifying word errors in Persian clinical text. In
terms of non-word error correction, our model achieved an F1-Score of 90.0%
when the PERTO algorithm was employed. For real-word error detection, our model
demonstrated its highest performance, achieving an F1-Score of 90.6%.
Furthermore, the model reached its highest F1-Score of 91.5% for real-word
error correction when the PERTO algorithm was employed.
  Conclusions: Despite certain limitations, our method represents a substantial
advancement in the field of spelling error detection and correction for Persian
clinical text. By effectively addressing the unique challenges posed by the
Persian language, our approach paves the way for more accurate and efficient
clinical documentation, contributing to improved patient care and safety.
Future research could explore its use in other areas of the Persian medical
domain, enhancing its impact and utility.

ÊëòË¶ÅÔºöËÉåÊôØÔºöÈõªÂ≠êÁóÖÊ≠∑ (EHR) ‰∏≠ÊãºÂØ´ÁöÑÊ∫ñÁ¢∫ÊÄßÊòØÊúâÊïàËá®Â∫äÁÖßË≠∑„ÄÅÁ†îÁ©∂ÂíåÁ¢∫‰øùÊÇ£ËÄÖÂÆâÂÖ®ÊÄßÁöÑÈóúÈçµÂõ†Á¥†„ÄÇÊ≥¢ÊñØË™ûÊìÅÊúâË±êÂØåÁöÑË©ûÂΩôÂíåË§áÈõúÁöÑÁâπÂæµÔºåÂ∞çÁúüÂØ¶‰∏ñÁïåÁöÑÈåØË™§Êõ¥Ê≠£ÊèêÂá∫‰∫ÜÁç®ÁâπÁöÑÊåëÊà∞„ÄÇÊú¨Á†îÁ©∂Êó®Âú®ÈñãÁôº‰∏ÄÁ®ÆÂâµÊñ∞ÁöÑÊñπÊ≥ï‰æÜÂÅµÊ∏¨ÂíåÊõ¥Ê≠£Ê≥¢ÊñØË™ûËá®Â∫äÊñáÊú¨‰∏≠ÁöÑÊãºÂØ´ÈåØË™§„ÄÇ
ÊñπÊ≥ïÔºöÊàëÂÄëÁöÑÁ≠ñÁï•Êé°Áî®‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÈ†êË®ìÁ∑¥Ê®°ÂûãÔºåË©≤Ê®°ÂûãÁ∂ìÈÅéÁ≤æÂøÉÂæÆË™øÔºåÂ∞àÈñÄÁî®ÊñºÊ≥¢ÊñØË™ûËá®Â∫äÈ†òÂüü‰∏≠ÁöÑÊãºÂØ´Êõ¥Ê≠£‰ªªÂãô„ÄÇÊ≠§Ê®°ÂûãÁî±ÂâµÊñ∞ÁöÑÊ≠£Â≠óÊ≥ïÁõ∏‰ººÊÄßÂåπÈÖçÊºîÁÆóÊ≥ï PERTO Ë£úÂÖÖÔºåË©≤ÊºîÁÆóÊ≥ï‰ΩøÁî®Â≠óÂÖÉÁöÑË¶ñË¶∫Áõ∏‰ººÊÄß‰æÜÂ∞çÊõ¥Ê≠£ÂÄôÈÅ∏È†ÖÈÄ≤Ë°åÊéíÂêç„ÄÇ
ÁµêÊûúÔºöÂ∞çÊàëÂÄëÊñπÊ≥ïÁöÑË©ï‰º∞Ë≠âÊòé‰∫ÜÂÖ∂Âú®ÂÅµÊ∏¨ÂíåÁ≥æÊ≠£Ê≥¢ÊñØË™ûËá®Â∫äÊñáÊú¨‰∏≠ÁöÑÊñáÂ≠óÈåØË™§ÊñπÈù¢ÁöÑÁ©©ÂÅ•ÊÄßÂíåÊ∫ñÁ¢∫ÊÄß„ÄÇÂú®ÈùûÊñáÂ≠óÈåØË™§Êõ¥Ê≠£ÊñπÈù¢ÔºåÁï∂‰ΩøÁî® PERTO ÊºîÁÆóÊ≥ïÊôÇÔºåÊàëÂÄëÁöÑÊ®°ÂûãÂØ¶Áèæ‰∫Ü 90.0% ÁöÑ F1 ÂàÜÊï∏„ÄÇÂ∞çÊñºÁúüÂØ¶‰∏ñÁïåÁöÑÈåØË™§ÂÅµÊ∏¨ÔºåÊàëÂÄëÁöÑÊ®°ÂûãÂ±ïÁ§∫‰∫ÜÂÖ∂ÊúÄÈ´òÁöÑÊïàËÉΩÔºåÂØ¶Áèæ‰∫Ü 90.6% ÁöÑ F1 ÂàÜÊï∏„ÄÇÊ≠§Â§ñÔºåÁï∂‰ΩøÁî® PERTO ÊºîÁÆóÊ≥ïÊôÇÔºåË©≤Ê®°ÂûãÈÅîÂà∞‰∫ÜÂÖ∂ÊúÄÈ´òÁöÑ F1 ÂàÜÊï∏ 91.5%ÔºåÁî®ÊñºÁúüÂØ¶‰∏ñÁïåÁöÑÈåØË™§Êõ¥Ê≠£„ÄÇ
ÁµêË´ñÔºöÂÑòÁÆ°Â≠òÂú®Êüê‰∫õÈôêÂà∂Ôºå‰ΩÜÊàëÂÄëÁöÑÊ®°Âûã‰ª£Ë°®‰∫ÜÊ≥¢ÊñØË™ûËá®Â∫äÊñáÊú¨ÊãºÂØ´ÈåØË™§ÂÅµÊ∏¨ÂíåÊõ¥Ê≠£È†òÂüüÁöÑÈáçÂ§ßÈÄ≤Â±ï„ÄÇÈÄèÈÅéÊúâÊïàËß£Ê±∫Ê≥¢ÊñØË™ûÊâÄÂ∏∂‰æÜÁöÑÁç®ÁâπÊåëÊà∞ÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÁÇ∫Êõ¥Ê∫ñÁ¢∫ÂíåÊúâÊïàÁöÑËá®Â∫äÊñá‰ª∂Èã™Ë∑ØÔºåÊúâÂä©ÊñºÊîπÂñÑÊÇ£ËÄÖÁÖßË≠∑ÂíåÂÆâÂÖ®ÊÄß„ÄÇÊú™‰æÜÁöÑÁ†îÁ©∂ÂèØ‰ª•Êé¢Ë®éÂÖ∂Âú®Ê≥¢ÊñØË™ûÈÜ´Â≠∏È†òÂüüÂÖ∂‰ªñÈ†òÂüüÁöÑÊáâÁî®Ôºå‰ª•Â¢ûÂº∑ÂÖ∂ÂΩ±ÈüøÂäõÂíåÂØ¶Áî®ÊÄß„ÄÇ

##### **Identifying treatment response subgroups in observational time-to-event data**
2408.03463v1 by Vincent Jeanselme, Chang Ho Yoon, Fabian Falck, Brian Tom, Jessica Barrett

Identifying patient subgroups with different treatment responses is an
important task to inform medical recommendations, guidelines, and the design of
future clinical trials. Existing approaches for subgroup analysis primarily
focus on Randomised Controlled Trials (RCTs), in which treatment assignment is
randomised. Furthermore, the patient cohort of an RCT is often constrained by
cost, and is not representative of the heterogeneity of patients likely to
receive treatment in real-world clinical practice. Therefore, when applied to
observational studies, such approaches suffer from significant statistical
biases because of the non-randomisation of treatment. Our work introduces a
novel, outcome-guided method for identifying treatment response subgroups in
observational studies. Our approach assigns each patient to a subgroup
associated with two time-to-event distributions: one under treatment and one
under control regime. It hence positions itself in between individualised and
average treatment effect estimation. The assumptions of our model result in a
simple correction of the statistical bias from treatment non-randomisation
through inverse propensity weighting. In experiments, our approach
significantly outperforms the current state-of-the-art method for
outcome-guided subgroup analysis in both randomised and observational treatment
regimes.

ÊëòË¶ÅÔºöË≠òÂà•ÂÖ∑Êúâ‰∏çÂêåÊ≤ªÁôÇÂèçÊáâÁöÑÊÇ£ËÄÖÂ≠êÁæ§ÊòØÁÇ∫ÈÜ´ÁôÇÂª∫Ë≠∞„ÄÅÊåáÂçóÂíåÊú™‰æÜËá®Â∫äË©¶È©óÁöÑË®≠Ë®àÊèê‰æõË≥áË®äÁöÑ‰∏ÄÈ†ÖÈáçË¶Å‰ªªÂãô„ÄÇÁèæÊúâÁöÑÂ≠êÁæ§ÂàÜÊûêÊñπÊ≥ï‰∏ªË¶ÅÈõÜ‰∏≠ÊñºÈö®Ê©üÂ∞çÁÖßË©¶È©ó (RCT)ÔºåÂÖ∂‰∏≠Ê≤ªÁôÇÂàÜÈÖçÊòØÈö®Ê©üÁöÑ„ÄÇÊ≠§Â§ñÔºåRCT ÁöÑÊÇ£ËÄÖÁæ§È´îÈÄöÂ∏∏ÂèóÂà∞ÊàêÊú¨ÁöÑÈôêÂà∂Ôºå‰∏îÁÑ°Ê≥ï‰ª£Ë°®Âú®ÁèæÂØ¶‰∏ñÁïåËá®Â∫äÂØ¶Âãô‰∏≠ÂèØËÉΩÊé•ÂèóÊ≤ªÁôÇÁöÑÊÇ£ËÄÖÁï∞Ë≥™ÊÄß„ÄÇÂõ†Ê≠§ÔºåÁï∂ÊáâÁî®ÊñºËßÄÂØüÊÄßÁ†îÁ©∂ÊôÇÔºåÊ≠§È°ûÊñπÊ≥ïÊúÉÂõ†Ê≤ªÁôÇÁöÑÈùûÈö®Ê©üÂåñËÄåÁî¢ÁîüÈ°ØËëóÁöÑÁµ±Ë®àÂÅèÂ∑Æ„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÂºïÂÖ•‰∫Ü‰∏ÄÁ®ÆÊñ∞ÁöÑ„ÄÅÁµêÊûúÂ∞éÂêëÁöÑÊñπÊ≥ïÔºåÁî®ÊñºË≠òÂà•ËßÄÂØüÊÄßÁ†îÁ©∂‰∏≠ÁöÑÊ≤ªÁôÇÂèçÊáâÂ≠êÁæ§„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÊòØÂ∞áÊØèÂÄãÊÇ£ËÄÖÂàÜÈÖçÂà∞‰∏ÄÂÄãÂ≠êÁæ§ÔºåË©≤Â≠êÁæ§ËàáÂÖ©ÂÄã‰∫ã‰ª∂ÁôºÁîüÊôÇÈñìÂàÜÈÖçÁõ∏ÈóúÔºö‰∏ÄÂÄãÂú®Ê≤ªÁôÇ‰∏ãÔºåÂè¶‰∏ÄÂÄãÂú®Â∞çÁÖßÊ©üÂà∂‰∏ã„ÄÇÂõ†Ê≠§ÔºåÂÆÉ‰ªãÊñºÂÄãÂà•ÂåñÂíåÂπ≥ÂùáÊ≤ªÁôÇÊïàÊûú‰º∞Ë®à‰πãÈñì„ÄÇÊàëÂÄëÊ®°ÂûãÁöÑÂÅáË®≠Â∞éËá¥ÈÄöÈÅéÈÄÜÂêëÂÇæÂêëÂä†Ê¨äÂ∞ç‰æÜËá™Ê≤ªÁôÇÈùûÈö®Ê©üÂåñÁöÑÁµ±Ë®àÂÅèÂ∑ÆÈÄ≤Ë°åÁ∞°ÂñÆÊ†°Ê≠£„ÄÇÂú®ÂØ¶È©ó‰∏≠ÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÂú®Èö®Ê©üÂíåËßÄÂØüÊÄßÊ≤ªÁôÇÊ©üÂà∂‰∏≠ÈÉΩÈ°ØËëóÂÑ™ÊñºÁï∂ÂâçÊúÄÂÖàÈÄ≤ÁöÑÁµêÊûúÂ∞éÂêëÂ≠êÁæ§ÂàÜÊûêÊñπÊ≥ï„ÄÇ

##### **Combining Diverse Information for Coordinated Action: Stochastic Bandit Algorithms for Heterogeneous Agents**
2408.03405v1 by Lucia Gordon, Esther Rolf, Milind Tambe

Stochastic multi-agent multi-armed bandits typically assume that the rewards
from each arm follow a fixed distribution, regardless of which agent pulls the
arm. However, in many real-world settings, rewards can depend on the
sensitivity of each agent to their environment. In medical screening, disease
detection rates can vary by test type; in preference matching, rewards can
depend on user preferences; and in environmental sensing, observation quality
can vary across sensors. Since past work does not specify how to allocate
agents of heterogeneous but known sensitivity of these types in a stochastic
bandit setting, we introduce a UCB-style algorithm, Min-Width, which aggregates
information from diverse agents. In doing so, we address the joint challenges
of (i) aggregating the rewards, which follow different distributions for each
agent-arm pair, and (ii) coordinating the assignments of agents to arms.
Min-Width facilitates efficient collaboration among heterogeneous agents,
exploiting the known structure in the agents' reward functions to weight their
rewards accordingly. We analyze the regret of Min-Width and conduct
pseudo-synthetic and fully synthetic experiments to study the performance of
different levels of information sharing. Our results confirm that the gains to
modeling agent heterogeneity tend to be greater when the sensitivities are more
varied across agents, while combining more information does not always improve
performance.

ÊëòË¶ÅÔºöÈö®Ê©üÂ§öÊô∫ËÉΩÈ´îÂ§öËáÇË≥≠ÂæíÈÄöÂ∏∏ÂÅáË®≠ÊØèÂÄãÊâãËáÇÁöÑÂõûÂ†±ÈÅµÂæ™Âõ∫ÂÆöÂàÜ‰ΩàÔºåÁÑ°Ë´ñÂì™ÂÄãÊô∫ËÉΩÈ´îÊãâÂãïÊâãËáÇ„ÄÇÁÑ∂ËÄåÔºåÂú®Ë®±Â§öÁúüÂØ¶‰∏ñÁïåË®≠ÂÆö‰∏≠ÔºåÂõûÂ†±ÂèØËÉΩÂèñÊ±∫ÊñºÊØèÂÄãÊô∫ËÉΩÈ´îÂ∞çÂÖ∂Áí∞Â¢ÉÁöÑÊïèÊÑüÂ∫¶„ÄÇÂú®ÈÜ´Â≠∏ÁØ©Ê™¢‰∏≠ÔºåÁñæÁóÖÊ™¢Ê∏¨ÁéáÊúÉÂõ†Ê∏¨Ë©¶È°ûÂûãËÄåÁï∞ÔºõÂú®ÂÅèÂ•ΩÂåπÈÖç‰∏≠ÔºåÂõûÂ†±ÂèØËÉΩÂèñÊ±∫Êñº‰ΩøÁî®ËÄÖÂÅèÂ•ΩÔºõÂú®Áí∞Â¢ÉÊÑüÊ∏¨‰∏≠ÔºåËßÄÂØüÂìÅË≥™ÂèØËÉΩÂõ†ÊÑüÊ∏¨Âô®ËÄåÁï∞„ÄÇÁî±ÊñºÈÅéÂéªÁöÑÂ∑•‰ΩúÊú™Ë™™ÊòéÂ¶Ç‰ΩïÈÖçÁΩÆÈÄô‰∫õÈ°ûÂûãÁï∞Ë≥™‰ΩÜÂ∑≤Áü•ÊïèÊÑüÂ∫¶ÁöÑÊô∫ËÉΩÈ´îÂú®Èö®Ê©üË≥≠ÂæíË®≠ÂÆö‰∏≠ÔºåÊàëÂÄëÂºïÂÖ•‰∏ÄÁ®Æ UCB È¢®Ê†ºÊºîÁÆóÊ≥ïÔºåMin-WidthÔºåÂÆÉÊúÉÂΩôÁ∏Ω‰æÜËá™‰∏çÂêåÊô∫ËÉΩÈ´îÁöÑË≥áË®ä„ÄÇÂú®ÈÄôÊ®£ÂÅöÁöÑÈÅéÁ®ã‰∏≠ÔºåÊàëÂÄëËß£Ê±∫‰∫Ü (i) ÂΩôÁ∏ΩÂõûÂ†±ÁöÑÂÖ±ÂêåÊåëÊà∞ÔºåÈÄô‰∫õÂõûÂ†±ÈÅµÂæ™ÊØèÂÄãÊô∫ËÉΩÈ´îÊâãËáÇÈÖçÂ∞çÁöÑ‰∏çÂêåÂàÜ‰ΩàÔºå‰ª•Âèä (ii) ÂçîË™øÂ∞áÊô∫ËÉΩÈ´îÊåáÂÆöÁµ¶ÊâãËáÇ„ÄÇMin-Width ‰øÉÈÄ≤Áï∞Ë≥™Êô∫ËÉΩÈ´î‰πãÈñìÁöÑÊúâÊïàÂçî‰ΩúÔºåÂà©Áî®Êô∫ËÉΩÈ´îÂõûÂ†±ÂáΩÊï∏‰∏≠ÁöÑÂ∑≤Áü•ÁµêÊßã‰æÜÈÅ©Áï∂Âú∞Âä†Ê¨äÂÖ∂ÂõûÂ†±„ÄÇÊàëÂÄëÂàÜÊûê Min-Width ÁöÑÈÅ∫ÊÜæÔºå‰∏¶ÈÄ≤Ë°åÂÅΩÂêàÊàêÂíåÂÆåÂÖ®ÂêàÊàêÂØ¶È©ó‰æÜÁ†îÁ©∂‰∏çÂêåÂ±§Á¥öË≥áË®äÂÖ±‰∫´ÁöÑÊïàËÉΩ„ÄÇÊàëÂÄëÁöÑÁµêÊûúË≠âÂØ¶ÔºåÁï∂ÊïèÊÑüÂ∫¶Âú®‰∏çÂêåÊô∫ËÉΩÈ´îÈñìÂ∑ÆÁï∞ËºÉÂ§ßÊôÇÔºåÂ∞çÊô∫ËÉΩÈ´îÁï∞Ë≥™ÊÄßÂª∫Ê®°ÁöÑÊî∂ÁõäÂæÄÂæÄËºÉÈ´òÔºåËÄåÁµêÂêàÊõ¥Â§öË≥áË®ä‰∏¶‰∏çÁ∏ΩÊòØÊúÉÊîπÂñÑÊïàËÉΩ„ÄÇ

##### **MLC-GCN: Multi-Level Generated Connectome Based GCN for AD Analysis**
2408.03358v1 by Wenqi Zhu, Yinghua Fu, Ze Wang

Alzheimer's Disease (AD) is a currently incurable neurodegeneartive disease.
Accurately detecting AD, especially in the early stage, represents a high
research priority. AD is characterized by progressive cognitive impairments
that are related to alterations in brain functional connectivity (FC). Based on
this association, many studies have been published over the decades using FC
and machine learning to differentiate AD from healthy aging. The most recent
development in this detection method highlights the use of graph neural network
(GNN) as the brain functionality analysis. In this paper, we proposed a stack
of spatio-temporal feature extraction and graph generation based AD
classification model using resting state fMRI. The proposed multi-level
generated connectome (MLC) based graph convolutional network (GCN) (MLC-GCN)
contains a multi-graph generation block and a GCN prediction block. The
multi-graph generation block consists of a hierarchy of spatio-temporal feature
extraction layers for extracting spatio-temporal rsfMRI features at different
depths and building the corresponding connectomes. The GCN prediction block
takes the learned multi-level connectomes to build and optimize GCNs at each
level and concatenates the learned graphical features as the final predicting
features for AD classification. Through independent cohort validations, MLC-GCN
shows better performance for differentiating MCI, AD, and normal aging than
state-of-art GCN and rsfMRI based AD classifiers. The proposed MLC-GCN also
showed high explainability in terms of learning clinically reasonable
connectome node and connectivity features from two independent datasets. While
we only tested MLC-GCN on AD, the basic rsfMRI-based multi-level learned GCN
based outcome prediction strategy is valid for other diseases or clinical
outcomes.

ÊëòË¶ÅÔºöÈòøËå≤Êµ∑ÈªòÁóá (AD) ÊòØ‰∏ÄÁ®ÆÁõÆÂâçÁÑ°Ê≥ïÊ≤ªÁôíÁöÑÁ•ûÁ∂ìÈÄÄÂåñÊÄßÁñæÁóÖ„ÄÇ
Ê∫ñÁ¢∫Âú∞ÂÅµÊ∏¨ ADÔºåÁâπÂà•ÊòØÂú®Êó©ÊúüÈöéÊÆµÔºå‰ª£Ë°®‰∏ÄÈ†ÖÈ´òÂ∫¶ÁöÑÁ†îÁ©∂ÂÑ™ÂÖà‰∫ãÈ†Ö„ÄÇAD ÁöÑÁâπÂæµÊòØÊúÉÈÄêÊº∏Ë™çÁü•ÂäüËÉΩÂèóÊêçÔºåÈÄôËàáËÖ¶ÈÉ®ÂäüËÉΩÈÄ£Êé•ÊÄß (FC) ÁöÑÊîπËÆäÊúâÈóú„ÄÇÂü∫ÊñºÈÄôÁ®ÆÈóúËÅØÔºåÂú®ÈÅéÂéªÁöÑÊï∏ÂçÅÂπ¥‰∏≠ÔºåË®±Â§öÁ†îÁ©∂Â∑≤‰ΩøÁî® FC ÂíåÊ©üÂô®Â≠∏Áøí‰æÜÂçÄÂàÜ AD ÂíåÂÅ•Â∫∑ËÄÅÂåñ„ÄÇÈÄôÁ®ÆÂÅµÊ∏¨ÊñπÊ≥ïÁöÑÊúÄÊñ∞ÁôºÂ±ïÔºåÁ™ÅÈ°Ø‰∫Ü‰ΩøÁî®ÂúñÁ•ûÁ∂ìÁ∂≤Ë∑Ø (GNN) ‰ΩúÁÇ∫ËÖ¶ÈÉ®ÂäüËÉΩÂàÜÊûê„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂ†ÜÁñäÁöÑÊôÇÁ©∫ÁâπÂæµËêÉÂèñÂíåÂúñÂΩ¢ÁîüÊàêÔºåÂü∫Êñº AD ÂàÜÈ°ûÊ®°ÂûãÔºå‰ΩøÁî®ÈùúÊ≠¢ÁãÄÊÖã fMRI„ÄÇÊâÄÊèêÂá∫ÁöÑÂ§öÂ±§Á¥öÁîüÊàêÈÄ£Êé•ÁµÑ (MLC) Âü∫ÊñºÂúñÂΩ¢Âç∑Á©çÁ∂≤Ë∑Ø (GCN) (MLC-GCN) ÂåÖÂê´‰∏ÄÂÄãÂ§öÂúñÂΩ¢ÁîüÊàêÂçÄÂ°äÂíå‰∏ÄÂÄã GCN È†êÊ∏¨ÂçÄÂ°ä„ÄÇÂ§öÂúñÂΩ¢ÁîüÊàêÂçÄÂ°äÂåÖÂê´‰∏ÄÂÄãÊôÇÁ©∫ÁâπÂæµËêÉÂèñÂ±§ÁöÑÈöéÂ±§ÔºåÁî®ÊñºËêÉÂèñ‰∏çÂêåÊ∑±Â∫¶‰∏ãÁöÑÊôÇÁ©∫ rsfMRI ÁâπÂæµÔºå‰∏¶Âª∫Á´ãÂ∞çÊáâÁöÑÈÄ£Êé•ÁµÑ„ÄÇGCN È†êÊ∏¨ÂçÄÂ°äÊé°Áî®Â∑≤Â≠∏ÁøíÁöÑÂ§öÂ±§Á¥öÈÄ£Êé•ÁµÑÔºåÂú®ÊØèÂÄãÂ±§Á¥öÂª∫Á´ã‰∏¶ÊúÄ‰Ω≥Âåñ GCNÔºå‰∏¶Â∞áÂ∑≤Â≠∏ÁøíÁöÑÂúñÂΩ¢ÁâπÂæµ‰∏≤ËÅØÊàêÁî®Êñº AD ÂàÜÈ°ûÁöÑÊúÄÁµÇÈ†êÊ∏¨ÁâπÂæµ„ÄÇÈÄèÈÅéÁç®Á´ãÁöÑÁæ§ÁµÑÈ©óË≠âÔºåMLC-GCN Âú®ÂçÄÂàÜ MCI„ÄÅAD ÂíåÊ≠£Â∏∏ËÄÅÂåñÊñπÈù¢ÔºåË°®ÁèæÂÑ™ÊñºÊúÄÂÖàÈÄ≤ÁöÑ GCN ÂíåÂü∫Êñº rsfMRI ÁöÑ AD ÂàÜÈ°ûÂô®„ÄÇÊâÄÊèêÂá∫ÁöÑ MLC-GCN ‰πüÂú®ÂæûÂÖ©ÂÄãÁç®Á´ãÁöÑË≥áÊñôÈõÜ‰∏≠Â≠∏ÁøíËá®Â∫ä‰∏äÂêàÁêÜÁöÑÈÄ£Êé•ÁµÑÁØÄÈªûÂíåÈÄ£Êé•ÁâπÂæµÊñπÈù¢ÔºåË°®ÁèæÂá∫È´òÂ∫¶ÁöÑÂèØËß£ÈáãÊÄß„ÄÇÈõñÁÑ∂ÊàëÂÄëÂè™Âú® AD ‰∏äÊ∏¨Ë©¶ MLC-GCNÔºå‰ΩÜÂü∫Êú¨ÁöÑÂü∫Êñº rsfMRI ÁöÑÂ§öÂ±§Á¥öÂ≠∏Áøí GCN Âü∫ÊñºÁµêÊûúÈ†êÊ∏¨Á≠ñÁï•ÔºåÂ∞çÂÖ∂‰ªñÁñæÁóÖÊàñËá®Â∫äÁµêÊûúÊúâÊïà„ÄÇ

##### **Personalizing Federated Instrument Segmentation with Visual Trait Priors in Robotic Surgery**
2408.03208v1 by Jialang Xu, Jiacheng Wang, Lequan Yu, Danail Stoyanov, Yueming Jin, Evangelos B. Mazomenos

Personalized federated learning (PFL) for surgical instrument segmentation
(SIS) is a promising approach. It enables multiple clinical sites to
collaboratively train a series of models in privacy, with each model tailored
to the individual distribution of each site. Existing PFL methods rarely
consider the personalization of multi-headed self-attention, and do not account
for appearance diversity and instrument shape similarity, both inherent in
surgical scenes. We thus propose PFedSIS, a novel PFL method with visual trait
priors for SIS, incorporating global-personalized disentanglement (GPD),
appearance-regulation personalized enhancement (APE), and shape-similarity
global enhancement (SGE), to boost SIS performance in each site. GPD represents
the first attempt at head-wise assignment for multi-headed self-attention
personalization. To preserve the unique appearance representation of each site
and gradually leverage the inter-site difference, APE introduces appearance
regulation and provides customized layer-wise aggregation solutions via
hypernetworks for each site's personalized parameters. The mutual shape
information of instruments is maintained and shared via SGE, which enhances the
cross-style shape consistency on the image level and computes the
shape-similarity contribution of each site on the prediction level for updating
the global parameters. PFedSIS outperforms state-of-the-art methods with +1.51%
Dice, +2.11% IoU, -2.79 ASSD, -15.55 HD95 performance gains. The corresponding
code and models will be released at https://github.com/wzjialang/PFedSIS.

ÊëòË¶ÅÔºö<paragraph>ÈáùÂ∞çÊâãË°ìÂô®Ê¢∞ÂàÜÂâ≤ÔºàSISÔºâÁöÑÂÄã‰∫∫ÂåñËÅØÈÇ¶Â≠∏ÁøíÔºàPFLÔºâÊòØ‰∏ÄÁ®ÆÊúâÂâçÊôØÁöÑÊñπÊ≥ï„ÄÇÂÆÉËÆìÂ§öÂÄãËá®Â∫äÂú∞ÈªûËÉΩÂ§†Âú®Èö±ÁßÅÁöÑÊ¢ù‰ª∂‰∏ãÂÖ±ÂêåË®ìÁ∑¥‰∏ÄÁ≥ªÂàóÊ®°ÂûãÔºåÊØèÂÄãÊ®°ÂûãÈÉΩÊ†πÊìöÊØèÂÄãÂú∞ÈªûÁöÑÂÄãÂà•ÂàÜ‰ΩàÈÄ≤Ë°åË™øÊï¥„ÄÇÁèæÊúâÁöÑ PFL ÊñπÊ≥ïÂæàÂ∞ëËÄÉÊÖÆÂ§öÈ†≠Ëá™ÊàëÊ≥®ÊÑèÂäõÁöÑÂÄã‰∫∫ÂåñÔºåËÄå‰∏îÊ≤íÊúâËÄÉÊÖÆÂ§ñËßÄÁöÑÂ§öÊ®£ÊÄßÂíåÂô®Ê¢∞ÂΩ¢ÁãÄÁöÑÁõ∏‰ººÊÄßÔºåÈÄôÂÖ©ËÄÖÈÉΩÂ≠òÂú®ÊñºÊâãË°ìÂ†¥ÊôØ‰∏≠„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü PFedSISÔºåÈÄôÊòØ‰∏ÄÁ®ÆÂÖ∑ÊúâË¶ñË¶∫ÁâπÂæµÂÖàÈ©óÁöÑ SIS ÁöÑÊñ∞Âûã PFL ÊñπÊ≥ïÔºåÂÆÉÁµêÂêà‰∫ÜÂÖ®Â±ÄÂÄãÊÄßÂåñËß£Á≥æÁ∫èÔºàGPDÔºâ„ÄÅÂ§ñËßÄË™øÁØÄÂÄãÊÄßÂåñÂ¢ûÂº∑ÔºàAPEÔºâÂíåÂΩ¢ÁãÄÁõ∏‰ººÊÄßÂÖ®Â±ÄÂ¢ûÂº∑ÔºàSGEÔºâÔºå‰ª•ÊèêÂçáÊØèÂÄãÂú∞ÈªûÁöÑ SIS ÊïàËÉΩ„ÄÇGPD ‰ª£Ë°®‰∫ÜÈáùÂ∞çÂ§öÈ†≠Ëá™ÊàëÊ≥®ÊÑèÂäõÂÄãÊÄßÂåñÈÄ≤Ë°åÈ†≠ÈÉ®ÂàÜÈÖçÁöÑÈ¶ñÊ¨°ÂòóË©¶„ÄÇÁÇ∫‰∫Ü‰øùÁïôÊØèÂÄãÂú∞ÈªûÁöÑÁç®ÁâπÂ§ñËßÄË°®Á§∫‰∏¶ÈÄêÊº∏Âà©Áî®Âú∞ÈªûÈñìÁöÑÂ∑ÆÁï∞ÔºåAPE ÂºïÂÖ•‰∫ÜÂ§ñËßÄË™øÁØÄÔºå‰∏¶ÈÄèÈÅéË∂ÖÁ∂≤Ë∑ØÁÇ∫ÊØèÂÄãÂú∞ÈªûÁöÑÂÄãÊÄßÂåñÂèÉÊï∏Êèê‰æõËá™Ë®ÇÁöÑÈÄêÂ±§ËÅöÂêàËß£Ê±∫ÊñπÊ°à„ÄÇÂô®Ê¢∞ÁöÑÁõ∏‰∫íÂΩ¢ÁãÄË≥áË®äÈÄèÈÅé SGE ÈÄ≤Ë°åÁ∂≠Ë≠∑ÂíåÂÖ±‰∫´ÔºåÈÄôÂ¢ûÂº∑‰∫ÜÂΩ±ÂÉèÂ±§Á¥ö‰∏äÁöÑË∑®È¢®Ê†ºÂΩ¢ÁãÄ‰∏ÄËá¥ÊÄßÔºå‰∏¶Ë®àÁÆóÊØèÂÄãÂú∞ÈªûÂú®È†êÊ∏¨Â±§Á¥ö‰∏äÁöÑÂΩ¢ÁãÄÁõ∏‰ººÊÄßË≤¢ÁçªÔºå‰ª•Êõ¥Êñ∞ÂÖ®Â±ÄÂèÉÊï∏„ÄÇPFedSIS Âú®È™∞Â≠êÁ≥ªÊï∏‰∏äÂÑ™ÊñºÁèæÊúâÊúÄÂÖàÈÄ≤ÁöÑÊñπÊ≥ïÔºåÂàÜÂà•ÊèêÂçá‰∫Ü +1.51%„ÄÅIoU ÊèêÂçá‰∫Ü +2.11%„ÄÅASSD Èôç‰Ωé‰∫Ü -2.79„ÄÅHD95 ÊïàËÉΩÊèêÂçá‰∫Ü -15.55„ÄÇÂ∞çÊáâÁöÑÁ®ãÂºèÁ¢ºÂíåÊ®°ÂûãÂ∞áÂú® https://github.com/wzjialang/PFedSIS ‰∏äÁôºÂ∏É„ÄÇ</paragraph>

##### **The Use of Large Language Models (LLM) for Cyber Threat Intelligence (CTI) in Cybercrime Forums**
2408.03354v2 by Vanessa Clairoux-Trepanier, Isa-May Beauchamp, Estelle Ruellan, Masarah Paquet-Clouston, Serge-Olivier Paquette, Eric Clay

Large language models (LLMs) can be used to analyze cyber threat intelligence
(CTI) data from cybercrime forums, which contain extensive information and key
discussions about emerging cyber threats. However, to date, the level of
accuracy and efficiency of LLMs for such critical tasks has yet to be
thoroughly evaluated. Hence, this study assesses the accuracy of an LLM system
built on the OpenAI GPT-3.5-turbo model [7] to extract CTI information. To do
so, a random sample of 500 daily conversations from three cybercrime forums,
XSS, Exploit_in, and RAMP, was extracted, and the LLM system was instructed to
summarize the conversations and code 10 key CTI variables, such as whether a
large organization and/or a critical infrastructure is being targeted. Then,
two coders reviewed each conversation and evaluated whether the information
extracted by the LLM was accurate. The LLM system performed strikingly well,
with an average accuracy score of 98%. Various ways to enhance the model were
uncovered, such as the need to help the LLM distinguish between stories and
past events, as well as being careful with verb tenses in prompts.
Nevertheless, the results of this study highlight the efficiency and relevance
of using LLMs for cyber threat intelligence.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂèØÁî®ÊñºÂàÜÊûêÁ∂≤Ë∑ØÁäØÁΩ™Ë´ñÂ£á‰∏≠ÁöÑÁ∂≤Ë∑ØÂ®ÅËÑÖÊÉÖÂ†± (CTI) Ë≥áÊñôÔºåÂÖ∂‰∏≠ÂåÖÂê´ÊúâÈóúÊñ∞ËààÁ∂≤Ë∑ØÂ®ÅËÑÖÁöÑË±êÂØåË≥áË®äÂíåÈóúÈçµË®éË´ñ„ÄÇÁÑ∂ËÄåÔºåÂà∞ÁõÆÂâçÁÇ∫Ê≠¢ÔºåLLM Â∞çÊ≠§È°ûÈóúÈçµ‰ªªÂãôÁöÑÊ∫ñÁ¢∫ÊÄßÂíåÊïàÁéáÂ∞öÊú™ÂæóÂà∞ÂæπÂ∫ïË©ï‰º∞„ÄÇÂõ†Ê≠§ÔºåÊú¨Á†îÁ©∂Ë©ï‰º∞‰∫ÜÂª∫Á´ãÂú® OpenAI GPT-3.5-turbo Ê®°Âûã [7] ‰∏äÁöÑ LLM Á≥ªÁµ±ÊèêÂèñ CTI Ë≥áË®äÁöÑÊ∫ñÁ¢∫ÊÄß„ÄÇÁÇ∫Ê≠§ÔºåÂæû‰∏âÂÄãÁ∂≤Ë∑ØÁäØÁΩ™Ë´ñÂ£á XSS„ÄÅExploit_in Âíå RAMP ‰∏≠Èö®Ê©üÊäΩÂèñ‰∫Ü 500 ÂÄãÊØèÊó•Â∞çË©±Ôºå‰∏¶ÊåáÁ§∫ LLM Á≥ªÁµ±Á∏ΩÁµêÂ∞çË©±‰∏¶Á∑®Á¢º 10 ÂÄãÈóúÈçµ CTI ËÆäÊï∏Ôºå‰æãÂ¶ÇÊòØÂê¶ÈáùÂ∞çÂ§ßÂûãÁµÑÁπîÂíå/ÊàñÈóúÈçµÂü∫Á§éË®≠ÊñΩ„ÄÇÁÑ∂ÂæåÔºåÂÖ©ÂÄãÁ∑®Á¢ºÂô®Ê™¢Èñ±ÊØèÂÄãÂ∞çË©±‰∏¶Ë©ï‰º∞ LLM ÊèêÂèñÁöÑË≥áË®äÊòØÂê¶Ê∫ñÁ¢∫„ÄÇLLM Á≥ªÁµ±Ë°®ÁèæÂá∫Ëâ≤ÔºåÂπ≥ÂùáÊ∫ñÁ¢∫Â∫¶ÂàÜÊï∏ÁÇ∫ 98%„ÄÇÁôºÁèæ‰∫ÜÂ¢ûÂº∑Ê®°ÂûãÁöÑÂêÑÁ®ÆÊñπÊ≥ïÔºå‰æãÂ¶ÇÈúÄË¶ÅÂπ´Âä© LLM ÂçÄÂàÜÊïÖ‰∫ãÂíåÈÅéÂéª‰∫ã‰ª∂Ôºå‰ª•ÂèäÂú®ÊèêÁ§∫‰∏≠Â∞èÂøÉ‰ΩøÁî®ÊôÇÊÖã„ÄÇÂÑòÁÆ°Â¶ÇÊ≠§ÔºåÊú¨Á†îÁ©∂ÁöÑÁµêÊûúÁ™ÅÈ°Ø‰∫Ü‰ΩøÁî® LLM ÈÄ≤Ë°åÁ∂≤Ë∑ØÂ®ÅËÑÖÊÉÖÂ†±ÁöÑÊïàÁéáÂíåÁõ∏ÈóúÊÄß„ÄÇ

##### **VizECGNet: Visual ECG Image Network for Cardiovascular Diseases Classification with Multi-Modal Training and Knowledge Distillation**
2408.02888v1 by Ju-Hyeon Nam, Seo-Hyung Park, Su Jung Kim, Sang-Chul Lee

An electrocardiogram (ECG) captures the heart's electrical signal to assess
various heart conditions. In practice, ECG data is stored as either digitized
signals or printed images. Despite the emergence of numerous deep learning
models for digitized signals, many hospitals prefer image storage due to cost
considerations. Recognizing the unavailability of raw ECG signals in many
clinical settings, we propose VizECGNet, which uses only printed ECG graphics
to determine the prognosis of multiple cardiovascular diseases. During
training, cross-modal attention modules (CMAM) are used to integrate
information from two modalities - image and signal, while self-modality
attention modules (SMAM) capture inherent long-range dependencies in ECG data
of each modality. Additionally, we utilize knowledge distillation to improve
the similarity between two distinct predictions from each modality stream. This
innovative multi-modal deep learning architecture enables the utilization of
only ECG images during inference. VizECGNet with image input achieves higher
performance in precision, recall, and F1-Score compared to signal-based ECG
classification models, with improvements of 3.50%, 8.21%, and 7.38%,
respectively.

ÊëòË¶ÅÔºöÂøÉÈõªÂúñ (ECG) ÂèØÊì∑ÂèñÂøÉËáüÁöÑÈõªÊ∞£Ë®äËôüÔºåÁî®ÊñºË©ï‰º∞ÂêÑÁ®ÆÂøÉËáüÁñæÁóÖ„ÄÇÂØ¶Èöõ‰∏äÔºåÂøÉÈõªÂúñË≥áÊñôÂÑ≤Â≠òÂú®Êï∏‰ΩçÂåñË®äËôüÊàñÂàóÂç∞ÂΩ±ÂÉè‰∏≠„ÄÇÂÑòÁÆ°Â∑≤Âá∫ÁèæË®±Â§öÈáùÂ∞çÊï∏‰ΩçÂåñË®äËôüÁöÑÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÔºå‰ΩÜË®±Â§öÈÜ´Èô¢Âü∫ÊñºÊàêÊú¨ËÄÉÈáèÔºå‰ªçÂÅèÂ•ΩÂΩ±ÂÉèÂÑ≤Â≠ò„ÄÇÈëëÊñºË®±Â§öËá®Â∫äÁí∞Â¢É‰∏≠Áº∫‰πèÂéüÂßãÂøÉÈõªÂúñË®äËôüÔºåÊàëÂÄëÊèêÂá∫ VizECGNetÔºåÂÆÉÂÉÖ‰ΩøÁî®ÂàóÂç∞ÁöÑÂøÉÈõªÂúñÂúñÂΩ¢‰æÜÂà§Êñ∑Â§öÁ®ÆÂøÉË°ÄÁÆ°ÁñæÁóÖÁöÑÈ†êÂæå„ÄÇÂú®Ë®ìÁ∑¥ÊúüÈñìÔºåË∑®Ê®°ÊÖãÊ≥®ÊÑèÂäõÊ®°ÁµÑ (CMAM) Áî®ÊñºÊï¥Âêà‰æÜËá™ÂÖ©Á®ÆÊ®°ÊÖãÔºàÂΩ±ÂÉèÂíåË®äËôüÔºâÁöÑË≥áË®äÔºåËÄåËá™ÊàëÊ®°ÊÖãÊ≥®ÊÑèÂäõÊ®°ÁµÑ (SMAM) ÂâáÊì∑ÂèñÊØèÂÄãÊ®°ÊÖã‰∏≠ÂøÉÈõªÂúñË≥áÊñô‰∏≠Âõ∫ÊúâÁöÑÈï∑Á®ã‰æùË≥¥ÊÄß„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂà©Áî®Áü•Ë≠òËêÉÂèñ‰æÜÊîπÂñÑÊØèÂÄãÊ®°ÊÖã‰∏≤ÊµÅ‰∏≠ÂÖ©ÂÄã‰∏çÂêåÈ†êÊ∏¨‰πãÈñìÁöÑÁõ∏‰ººÊÄß„ÄÇÈÄôÁ®ÆÂâµÊñ∞ÁöÑÂ§öÊ®°ÊÖãÊ∑±Â∫¶Â≠∏ÁøíÊû∂ÊßãÔºåÂèØ‰ª•Âú®Êé®Ë´ñÊúüÈñìÂÉÖ‰ΩøÁî®ÂøÉÈõªÂúñÂΩ±ÂÉè„ÄÇËàáÂü∫ÊñºË®äËôüÁöÑÂøÉÈõªÂúñÂàÜÈ°ûÊ®°ÂûãÁõ∏ÊØîÔºåËº∏ÂÖ•ÂΩ±ÂÉèÁöÑ VizECGNet Âú®Á≤æÊ∫ñÂ∫¶„ÄÅÂè¨ÂõûÁéáÂíå F1 ÂàÜÊï∏ÊñπÈù¢Áç≤ÂæóÊõ¥È´òÁöÑÊïàËÉΩÔºåÂàÜÂà•ÊèêÂçá‰∫Ü 3.50%„ÄÅ8.21% Âíå 7.38%„ÄÇ

##### **VisionUnite: A Vision-Language Foundation Model for Ophthalmology Enhanced with Clinical Knowledge**
2408.02865v1 by Zihan Li, Diping Song, Zefeng Yang, Deming Wang, Fei Li, Xiulan Zhang, Paul E. Kinahan, Yu Qiao

The need for improved diagnostic methods in ophthalmology is acute,
especially in the less developed regions with limited access to specialists and
advanced equipment. Therefore, we introduce VisionUnite, a novel
vision-language foundation model for ophthalmology enhanced with clinical
knowledge. VisionUnite has been pretrained on an extensive dataset comprising
1.24 million image-text pairs, and further refined using our proposed MMFundus
dataset, which includes 296,379 high-quality fundus image-text pairs and
889,137 simulated doctor-patient dialogue instances. Our experiments indicate
that VisionUnite outperforms existing generative foundation models such as
GPT-4V and Gemini Pro. It also demonstrates diagnostic capabilities comparable
to junior ophthalmologists. VisionUnite performs well in various clinical
scenarios including open-ended multi-disease diagnosis, clinical explanation,
and patient interaction, making it a highly versatile tool for initial
ophthalmic disease screening. VisionUnite can also serve as an educational aid
for junior ophthalmologists, accelerating their acquisition of knowledge
regarding both common and rare ophthalmic conditions. VisionUnite represents a
significant advancement in ophthalmology, with broad implications for
diagnostics, medical education, and understanding of disease mechanisms.

ÊëòË¶ÅÔºöÁúºÁßëË®∫Êñ∑ÊñπÊ≥ïÊîπËâØÁöÑÂøÖË¶ÅÊÄßÂçÅÂàÜËø´ÂàáÔºåÁâπÂà•ÊòØÂú®ËºÉ‰∏çÁôºÈÅîÂú∞ÂçÄÔºåÈÇ£Ë£°Â∞àÁßëÈÜ´Â∏´ÂíåÂÖàÈÄ≤Ë®≠ÂÇôÂèñÂæó‰∏çÊòì„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëÂºïÈÄ≤ VisionUniteÔºå‰∏ÄÁ®ÆÊñ∞Á©éÁöÑË¶ñË¶∫Ë™ûË®ÄÂü∫Á§éÊ®°ÂûãÔºå‰∏¶‰ª•Ëá®Â∫äÁü•Ë≠òÂº∑ÂåñÁúºÁßë„ÄÇVisionUnite Â∑≤Âú®ÂåÖÂê´ 124 Ëê¨ÂºµÂΩ±ÂÉèÊñáÂ≠óÂ∞çÁöÑÂ§ßÂûãË≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÈ†êË®ìÁ∑¥Ôºå‰∏¶ÈÄèÈÅéÊàëÂÄëÂª∫Ë≠∞ÁöÑ MMFundus Ë≥áÊñôÈõÜÈÄ≤‰∏ÄÊ≠•ÂÑ™ÂåñÔºåÂÖ∂‰∏≠ÂåÖÂê´ 296,379 ÂºµÈ´òÂìÅË≥™ÁúºÂ∫ïÂΩ±ÂÉèÊñáÂ≠óÂ∞çÂíå 889,137 ÂÄãÊ®°Êì¨ÁöÑÈÜ´Â∏´ÁóÖÊÇ£Â∞çË©±ÂØ¶‰æã„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÊåáÂá∫ VisionUnite ÂÑ™ÊñºÁèæÊúâÁöÑÁîüÊàêÂºèÂü∫Á§éÊ®°ÂûãÔºå‰æãÂ¶Ç GPT-4V Âíå Gemini Pro„ÄÇÂÆÉ‰πüÂ±ïÁèæÂá∫ËàáÂàùÈöéÁúºÁßëÈÜ´Â∏´Áõ∏Áï∂ÁöÑË®∫Êñ∑ËÉΩÂäõ„ÄÇVisionUnite Âú®ÂêÑÁ®ÆËá®Â∫äÊÉÖÂ¢É‰∏≠Ë°®ÁèæËâØÂ•ΩÔºåÂåÖÊã¨ÈñãÊîæÂºèÂ§öÁñæÁóÖË®∫Êñ∑„ÄÅËá®Â∫äË™™ÊòéÂíåÁóÖÊÇ£‰∫íÂãïÔºå‰ΩøÂÖ∂ÊàêÁÇ∫ÂàùÊ≠•ÁúºÁßëÁñæÁóÖÁØ©Ê™¢ÁöÑÈ´òÂ∫¶Â§öÂäüËÉΩÂ∑•ÂÖ∑„ÄÇVisionUnite ‰πüÂèØÁî®‰ΩúÂàùÈöéÁúºÁßëÈÜ´Â∏´ÁöÑÊïôËÇ≤ËºîÂä©Â∑•ÂÖ∑ÔºåÂä†ÈÄü‰ªñÂÄëÂ∞çÊñºÂ∏∏Ë¶ãÂíåÁΩïË¶ãÁúºÁßëÁñæÁóÖÁü•Ë≠òÁöÑÁøíÂæó„ÄÇVisionUnite ‰ª£Ë°®‰∫ÜÁúºÁßëÁöÑÈáçÂ§ßÈÄ≤Â±ïÔºåÂ∞çË®∫Êñ∑„ÄÅÈÜ´Â≠∏ÊïôËÇ≤ÂíåÁñæÁóÖÊ©üËΩâÁöÑÁêÜËß£ÂÖ∑ÊúâÂª£Ê≥õÁöÑÂΩ±Èüø„ÄÇ

##### **Multistain Pretraining for Slide Representation Learning in Pathology**
2408.02859v1 by Guillaume Jaume, Anurag Vaidya, Andrew Zhang, Andrew H. Song, Richard J. Chen, Sharifa Sahai, Dandan Mo, Emilio Madrigal, Long Phi Le, Faisal Mahmood

Developing self-supervised learning (SSL) models that can learn universal and
transferable representations of H&E gigapixel whole-slide images (WSIs) is
becoming increasingly valuable in computational pathology. These models hold
the potential to advance critical tasks such as few-shot classification, slide
retrieval, and patient stratification. Existing approaches for slide
representation learning extend the principles of SSL from small images (e.g.,
224 x 224 patches) to entire slides, usually by aligning two different
augmentations (or views) of the slide. Yet the resulting representation remains
constrained by the limited clinical and biological diversity of the views.
Instead, we postulate that slides stained with multiple markers, such as
immunohistochemistry, can be used as different views to form a rich
task-agnostic training signal. To this end, we introduce Madeleine, a
multimodal pretraining strategy for slide representation learning. Madeleine is
trained with a dual global-local cross-stain alignment objective on large
cohorts of breast cancer samples (N=4,211 WSIs across five stains) and kidney
transplant samples (N=12,070 WSIs across four stains). We demonstrate the
quality of slide representations learned by Madeleine on various downstream
evaluations, ranging from morphological and molecular classification to
prognostic prediction, comprising 21 tasks using 7,299 WSIs from multiple
medical centers. Code is available at https://github.com/mahmoodlab/MADELEINE.

ÊëòË¶ÅÔºöÈñãÁôºËá™Áõ£Áù£Â≠∏Áøí (SSL) Ê®°ÂûãÔºåÂèØ‰ª•Â≠∏Áøí H&E ÂêâÂÉèÁ¥†ÂÖ®ÂàáÁâáÂΩ±ÂÉè (WSI) ÁöÑÈÄöÁî®‰∏îÂèØËΩâÁßªË°®Á§∫ÔºåÂú®Ë®àÁÆóÁóÖÁêÜÂ≠∏‰∏≠Ê≠£ËÆäÂæóË∂ä‰æÜË∂äÊúâÂÉπÂÄº„ÄÇÈÄô‰∫õÊ®°ÂûãÊúâÊΩõÂäõÊé®ÈÄ≤ÈóúÈçµ‰ªªÂãôÔºå‰æãÂ¶ÇÂ∞ëÊ¨°ÂàÜÈ°û„ÄÅÂàáÁâáÊ™¢Á¥¢ÂíåÊÇ£ËÄÖÂàÜÂ±§„ÄÇÁèæÊúâÁöÑÂàáÁâáË°®Á§∫Â≠∏ÁøíÊñπÊ≥ïÂ∞á SSL ÁöÑÂéüÁêÜÂæûÂ∞èÂΩ±ÂÉèÔºà‰æãÂ¶Ç 224 x 224 Ë£ú‰∏ÅÔºâÂª∂‰º∏Âà∞Êï¥ÂÄãÂàáÁâáÔºåÈÄöÂ∏∏ÈÄèÈÅéÂ∞çÈΩäÂàáÁâáÁöÑÂÖ©ÂÄã‰∏çÂêåÊì¥Â¢ûÔºàÊàñË¶ñÂúñÔºâ„ÄÇÁÑ∂ËÄåÔºåÁîüÊàêÁöÑË°®Á§∫‰ªçÂèóÂà∞Ë¶ñÂúñÊúâÈôêÁöÑËá®Â∫äÂíåÁîüÁâ©Â§öÊ®£ÊÄßÁöÑÈôêÂà∂„ÄÇÁõ∏ÂèçÔºåÊàëÂÄëÂÅáË®≠‰ΩøÁî®Â§öÁ®ÆÊ®ôË®òÊüìËâ≤ÁöÑÂàáÁâáÔºå‰æãÂ¶ÇÂÖçÁñ´ÁµÑÁπîÂåñÂ≠∏ÊüìËâ≤ÔºåÂèØ‰ª•Áî®‰Ωú‰∏çÂêåÁöÑË¶ñÂúñ‰æÜÂΩ¢ÊàêË±êÂØåÁöÑËàá‰ªªÂãôÁÑ°ÈóúÁöÑË®ìÁ∑¥Ë®äËôü„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄë‰ªãÁ¥π MadeleineÔºå‰∏ÄÁ®ÆÁî®ÊñºÂàáÁâáË°®Á§∫Â≠∏ÁøíÁöÑÂ§öÊ®°ÂºèÈ†êË®ìÁ∑¥Á≠ñÁï•„ÄÇMadeleine ‰ΩøÁî®ÈõôÈáçÂÖ®Â±Ä-Â±ÄÈÉ®Ë∑®ÊüìËâ≤Â∞çÈΩäÁõÆÊ®ôÂú®Â§ßÈáè‰π≥ÁôåÊ®£Êú¨ÔºàN=4,211 ÂÄãÊ©´Ë∑®‰∫îÁ®ÆÊüìËâ≤ÁöÑ WSIÔºâÂíåËÖéËáüÁßªÊ§çÊ®£Êú¨ÔºàN=12,070 ÂÄãÊ©´Ë∑®ÂõõÁ®ÆÊüìËâ≤ÁöÑ WSIÔºâ‰∏äÈÄ≤Ë°åË®ìÁ∑¥„ÄÇÊàëÂÄëÂú®ÂêÑÁ®Æ‰∏ãÊ∏∏Ë©ï‰º∞‰∏≠Â±ïÁ§∫‰∫Ü Madeleine Â≠∏ÁøíÁöÑÂàáÁâáË°®Á§∫ÁöÑÂìÅË≥™ÔºåÂæûÂΩ¢ÊÖãÂíåÂàÜÂ≠êÂàÜÈ°ûÂà∞È†êÂæåÈ†êÊ∏¨ÔºåÂåÖÊã¨‰ΩøÁî®‰æÜËá™Â§öÂÄãÈÜ´ÁôÇ‰∏≠ÂøÉÁöÑ 7,299 ÂÄã WSI ÁöÑ 21 È†Ö‰ªªÂãô„ÄÇÁ®ãÂºèÁ¢ºÂèØÂú® https://github.com/mahmoodlab/MADELEINE ÂèñÂæó„ÄÇ

##### **The Literature Review Network: An Explainable Artificial Intelligence for Systematic Literature Reviews, Meta-analyses, and Method Development**
2408.05239v1 by Joshua Morriss, Tod Brindle, Jessica Bah R√∂sman, Daniel Reibsamen, Andreas Enz

Systematic literature reviews are the highest quality of evidence in
research. However, the review process is hindered by significant resource and
data constraints. The Literature Review Network (LRN) is the first of its kind
explainable AI platform adhering to PRISMA 2020 standards, designed to automate
the entire literature review process. LRN was evaluated in the domain of
surgical glove practices using 3 search strings developed by experts to query
PubMed. A non-expert trained all LRN models. Performance was benchmarked
against an expert manual review. Explainability and performance metrics
assessed LRN's ability to replicate the experts' review. Concordance was
measured with the Jaccard index and confusion matrices. Researchers were
blinded to the other's results until study completion. Overlapping studies were
integrated into an LRN-generated systematic review. LRN models demonstrated
superior classification accuracy without expert training, achieving 84.78% and
85.71% accuracy. The highest performance model achieved high interrater
reliability (k = 0.4953) and explainability metrics, linking 'reduce',
'accident', and 'sharp' with 'double-gloving'. Another LRN model covered 91.51%
of the relevant literature despite diverging from the non-expert's judgments (k
= 0.2174), with the terms 'latex', 'double' (gloves), and 'indication'. LRN
outperformed the manual review (19,920 minutes over 11 months), reducing the
entire process to 288.6 minutes over 5 days. This study demonstrates that
explainable AI does not require expert training to successfully conduct
PRISMA-compliant systematic literature reviews like an expert. LRN summarized
the results of surgical glove studies and identified themes that were nearly
identical to the clinical researchers' findings. Explainable AI can accurately
expedite our understanding of clinical practices, potentially revolutionizing
healthcare research.

ÊëòË¶ÅÔºöÁ≥ªÁµ±ÊÄßÊñáÁçªÂõûÈ°ßÊòØÁ†îÁ©∂‰∏≠Ë≠âÊìöÂìÅË≥™ÊúÄÈ´òÁöÑ„ÄÇÁÑ∂ËÄåÔºåÂõûÈ°ßÈÅéÁ®ãÂèóÂà∞È°ØËëóË≥áÊ∫êÂíåË≥áÊñôÈôêÂà∂ÁöÑÈòªÁ§ô„ÄÇÊñáÁçªÂõûÈ°ßÁ∂≤Ë∑Ø (LRN) ÊòØÁ¨¨‰∏ÄÂÄãÈÅµÂæ™ PRISMA 2020 Ê®ôÊ∫ñÁöÑÂèØËß£Èáã AI Âπ≥Âè∞ÔºåÊó®Âú®Ëá™ÂãïÂåñÊï¥ÂÄãÊñáÁçªÂõûÈ°ßÈÅéÁ®ã„ÄÇLRN Âú®Â§ñÁßëÊâãÂ•óÂØ¶ÂãôÈ†òÂüü‰∏≠ÈÄ≤Ë°åË©ï‰º∞Ôºå‰ΩøÁî®Â∞àÂÆ∂ÈñãÁôºÁöÑ 3 ÂÄãÊêúÂ∞ãÂ≠ó‰∏≤‰æÜÊü•Ë©¢ PubMed„ÄÇÈùûÂ∞àÂÆ∂Ë®ìÁ∑¥ÊâÄÊúâ LRN Ê®°Âûã„ÄÇÊïàËÉΩ‰ª•Â∞àÂÆ∂ÊâãÂãïÂõûÈ°ß‰ΩúÁÇ∫Âü∫Ê∫ñ„ÄÇÂèØËß£ÈáãÊÄßÂíåÊïàËÉΩÊåáÊ®ôË©ï‰º∞ LRN Ë§áË£ΩÂ∞àÂÆ∂ÂõûÈ°ßÁöÑËÉΩÂäõ„ÄÇ‰∏ÄËá¥ÊÄß‰ª• Jaccard ÊåáÊï∏ÂíåÊ∑∑Ê∑ÜÁü©Èô£Ê∏¨Èáè„ÄÇÁ†îÁ©∂‰∫∫Âì°Âú®Á†îÁ©∂ÂÆåÊàêÂâçÂ∞çÂΩºÊ≠§ÁöÑÁµêÊûú‰øùÂØÜ„ÄÇÈáçÁñäÁöÑÁ†îÁ©∂Êï¥ÂêàÂà∞ LRN ÁîüÊàêÁöÑÁ≥ªÁµ±ÊÄßÂõûÈ°ß‰∏≠„ÄÇLRN Ê®°ÂûãÂú®Ê≤íÊúâÂ∞àÂÆ∂Ë®ìÁ∑¥ÁöÑÊÉÖÊ≥Å‰∏ãÂ±ïÁèæÂá∫ÂÑ™Áï∞ÁöÑÂàÜÈ°ûÊ∫ñÁ¢∫ÁéáÔºåÈÅîÂà∞ 84.78% Âíå 85.71% ÁöÑÊ∫ñÁ¢∫Áéá„ÄÇÊïàËÉΩÊúÄÈ´òÁöÑÊ®°ÂûãÈÅîÂà∞‰∫ÜÈ´òË©ïÂàÜËÄÖÈñì‰ø°Ë≥¥Â∫¶ (k = 0.4953) ÂíåÂèØËß£ÈáãÊÄßÊåáÊ®ôÔºåÂ∞á„ÄåÊ∏õÂ∞ë„Äç„ÄÅ„ÄåÊÑèÂ§ñ„ÄçÂíå„ÄåÈä≥Âà©„ÄçËàá„ÄåÈõôÈáçÊà¥ÊâãÂ•ó„ÄçÈÄ£ÁµêÂú®‰∏ÄËµ∑„ÄÇÂè¶‰∏ÄÂÄã LRN Ê®°ÂûãÊ∂µËìã‰∫Ü 91.51% ÁöÑÁõ∏ÈóúÊñáÁçªÔºåÂÑòÁÆ°ËàáÈùûÂ∞àÂÆ∂ÁöÑÂà§Êñ∑‰∏çÂêå (k = 0.2174)Ôºå‰ΩÜÂåÖÂê´‰∫Ü„Äå‰π≥ËÜ†„Äç„ÄÅ„ÄåÈõôÈáç„ÄçÔºàÊâãÂ•óÔºâÂíå„ÄåÈÅ©ÊáâÁóá„ÄçÁ≠âË©ûÂΩô„ÄÇLRN ÂÑ™ÊñºÊâãÂãïÂõûÈ°ßÔºà11 ÂÄãÊúàË∂ÖÈÅé 19,920 ÂàÜÈêòÔºâÔºåÂ∞áÊï¥ÂÄãÈÅéÁ®ãÁ∏ÆÁü≠ÁÇ∫ 5 Â§©Ë∂ÖÈÅé 288.6 ÂàÜÈêò„ÄÇÈÄôÈ†ÖÁ†îÁ©∂È°ØÁ§∫ÔºåÂèØËß£ÈáãÁöÑ AI ‰∏çÈúÄË¶ÅÂ∞àÂÆ∂Ë®ìÁ∑¥Âç≥ÂèØÊàêÂäüÈÄ≤Ë°åÂ∞àÂÆ∂Á≠âÁ¥öÁöÑ PRISMA Áõ∏ÂÆπÁ≥ªÁµ±ÊÄßÊñáÁçªÂõûÈ°ß„ÄÇLRN Á∏ΩÁµê‰∫ÜÂ§ñÁßëÊâãÂ•óÁ†îÁ©∂ÁöÑÁµêÊûúÔºå‰∏¶ÊâæÂá∫ËàáËá®Â∫äÁ†îÁ©∂‰∫∫Âì°ÁôºÁèæÂπæ‰πéÁõ∏ÂêåÁöÑ‰∏ªÈ¢ò„ÄÇÂèØËß£ÈáãÁöÑ AI ÂèØ‰ª•Ê∫ñÁ¢∫Âú∞Âä†Âø´ÊàëÂÄëÂ∞çËá®Â∫äÂØ¶ÂãôÁöÑÁêÜËß£ÔºåÊúâÊΩõÂäõÈù©Êñ∞ÈÜ´ÁôÇ‰øùÂÅ•Á†îÁ©∂„ÄÇ

##### **A Review on Organ Deformation Modeling Approaches for Reliable Surgical Navigation using Augmented Reality**
2408.02713v1 by Zheng Han, Qi Dou

Augmented Reality (AR) holds the potential to revolutionize surgical
procedures by allowing surgeons to visualize critical structures within the
patient's body. This is achieved through superimposing preoperative organ
models onto the actual anatomy. Challenges arise from dynamic deformations of
organs during surgery, making preoperative models inadequate for faithfully
representing intraoperative anatomy. To enable reliable navigation in augmented
surgery, modeling of intraoperative deformation to obtain an accurate alignment
of the preoperative organ model with the intraoperative anatomy is
indispensable. Despite the existence of various methods proposed to model
intraoperative organ deformation, there are still few literature reviews that
systematically categorize and summarize these approaches. This review aims to
fill this gap by providing a comprehensive and technical-oriented overview of
modeling methods for intraoperative organ deformation in augmented reality in
surgery. Through a systematic search and screening process, 112 closely
relevant papers were included in this review. By presenting the current status
of organ deformation modeling methods and their clinical applications, this
review seeks to enhance the understanding of organ deformation modeling in
AR-guided surgery, and discuss the potential topics for future advancements.

ÊëòË¶ÅÔºöÊì¥Â¢ûÂØ¶Â¢É (AR) ÂÖ∑ÊúâÈÄèÈÅéËÆìÂ§ñÁßëÈÜ´ÁîüÂèØË¶ñÂåñÊÇ£ËÄÖÈ´îÂÖßÈóúÈçµÁµêÊßã‰æÜÈù©Êñ∞Â§ñÁßëÊâãË°ìÁ®ãÂ∫èÁöÑÊΩõÂäõ„ÄÇÈÄôÊòØÈÄèÈÅéÂ∞áË°ìÂâçÂô®ÂÆòÊ®°ÂûãÁñäÂä†Âà∞ÂØ¶ÈöõËß£ÂâñÁµêÊßã‰∏ä‰æÜÂØ¶ÁèæÁöÑ„ÄÇÊâãË°ìÈÅéÁ®ã‰∏≠Âô®ÂÆòÁöÑÂãïÊÖãËÆäÂΩ¢Â∏∂‰æÜ‰∫ÜÊåëÊà∞ÔºåÈÄô‰ΩøÂæóË°ìÂâçÊ®°Âûã‰∏çË∂≥‰ª•Âø†ÂØ¶Âú∞ÂëàÁèæË°ì‰∏≠Ëß£ÂâñÁµêÊßã„ÄÇÁÇ∫‰∫ÜÂú®Êì¥Â¢ûÊâãË°ì‰∏≠ÂØ¶ÁèæÂèØÈù†ÁöÑÂ∞éËà™ÔºåÂ∞çË°ì‰∏≠ËÆäÂΩ¢ÈÄ≤Ë°åÂª∫Ê®°‰ª•Áç≤ÂæóË°ìÂâçÂô®ÂÆòÊ®°ÂûãËàáË°ì‰∏≠Ëß£ÂâñÁµêÊßãÁöÑÊ∫ñÁ¢∫Â∞çÈΩäÊòØ‰∏çÂèØÊàñÁº∫ÁöÑ„ÄÇÂÑòÁÆ°Â≠òÂú®ÂêÑÁ®ÆÁî®ÊñºÂª∫Ê®°Ë°ì‰∏≠Âô®ÂÆòËÆäÂΩ¢ÁöÑÊñπÊ≥ïÔºå‰ΩÜÁ≥ªÁµ±Âú∞Â∞çÈÄô‰∫õÊñπÊ≥ïÈÄ≤Ë°åÂàÜÈ°ûÂíåÁ∏ΩÁµêÁöÑÊñáÁçªÂõûÈ°ß‰ªçÁÑ∂ÂæàÂ∞ë„ÄÇÊú¨Á∂úËø∞Êó®Âú®ÈÄöÈÅéÊèê‰æõÂ∞çÊì¥Â¢ûÂØ¶Â¢ÉÊâãË°ì‰∏≠Ë°ì‰∏≠Âô®ÂÆòËÆäÂΩ¢ÁöÑÂª∫Ê®°ÊñπÊ≥ïÁöÑÂÖ®Èù¢‰∏îÊäÄË°ìÂ∞éÂêëÁöÑÊ¶ÇËø∞‰æÜÂ°´Ë£úÈÄô‰∏ÄÁ©∫ÁôΩ„ÄÇÈÄöÈÅéÁ≥ªÁµ±ÁöÑÊêúÂ∞ãÂíåÁØ©ÈÅ∏ÈÅéÁ®ãÔºåÊú¨Á∂úËø∞Á¥çÂÖ•‰∫Ü 112 ÁØáÂØÜÂàáÁõ∏ÈóúÁöÑË´ñÊñá„ÄÇÈÄöÈÅéÂëàÁèæÂô®ÂÆòËÆäÂΩ¢Âª∫Ê®°ÊñπÊ≥ïÁöÑÁèæÁãÄÂèäÂÖ∂Ëá®Â∫äÊáâÁî®ÔºåÊú¨Á∂úËø∞Êó®Âú®Âä†Ê∑±Â∞ç AR ÂºïÂ∞éÊâãË°ì‰∏≠Âô®ÂÆòËÆäÂΩ¢Âª∫Ê®°ÁöÑÁêÜËß£Ôºå‰∏¶Êé¢Ë®éÊú™‰æÜÈÄ≤Â±ïÁöÑÊΩõÂú®‰∏ªÈ°å„ÄÇ

##### **Enhancing Medical Learning and Reasoning Systems: A Boxology-Based Comparative Analysis of Design Patterns**
2408.02709v1 by Chi Him Ng

This study analyzes hybrid AI systems' design patterns and their
effectiveness in clinical decision-making using the boxology framework. It
categorizes and copares various architectures combining machine learning and
rule-based reasoning to provide insights into their structural foundations and
healthcare applications. Addressing two main questions, how to categorize these
systems againts established design patterns and how to extract insights through
comparative analysis, the study uses design patterns from software engineering
to understand and optimize healthcare AI systems. Boxology helps identify
commonalities and create reusable solutions, enhancing these systems'
scalability, reliability, and performance. Five primary architectures are
examined: REML, MLRB, RBML, RMLT, and PERML. Each has unique strengths and
weaknesses, highlighting the need for tailored approaches in clinical tasks.
REML excels in high-accuracy prediction for datasets with limited data; MLRB in
handling large datasets and complex data integration; RBML in explainability
and trustworthiness; RMLT in managing high-dimensional data; and PERML, though
limited in analysis, shows promise in urgent care scenarios. The study
introduces four new patterns, creates five abstract categorization patterns,
and refines those five further to specific systems. These contributions enhance
Boxlogy's taxonomical organization and offer novel approaches to integrating
expert knowledge with machine learning. Boxology's structured, modular apporach
offers significant advantages in developing and analyzing hybrid AI systems,
revealing commonalities, and promoting reusable solutions. In conclusion, this
study underscores hybrid AI systems' crucial role in advancing healthcare and
Boxology's potential to drive further innovation in AI integration, ultimately
improving clinical decision support and patient outcomes.

ÊëòË¶ÅÔºöÊú¨Á†îÁ©∂‰ΩøÁî®ÁõíÂ≠êÂ≠∏Ê°ÜÊû∂ÂàÜÊûêÊ∑∑Âêà‰∫∫Â∑•Êô∫ÊÖßÁ≥ªÁµ±ÁöÑË®≠Ë®àÊ®°ÂºèÂèäÂÖ∂Âú®Ëá®Â∫äÊ±∫Á≠ñ‰∏≠ÁöÑÊúâÊïàÊÄß„ÄÇÂÆÉÂàÜÈ°û‰∏¶ÊØîËºÉÁµêÂêàÊ©üÂô®Â≠∏ÁøíÂíåÂü∫ÊñºË¶èÂâáÁöÑÊé®ÁêÜÁöÑÂêÑÁ®ÆÊû∂ÊßãÔºå‰ª•Ê∑±ÂÖ•‰∫ÜËß£ÂÖ∂ÁµêÊßãÂü∫Á§éÂíåÈÜ´ÁôÇ‰øùÂÅ•ÊáâÁî®„ÄÇÈáùÂ∞çÂÖ©ÂÄã‰∏ªË¶ÅÂïèÈ°åÔºåÂ¶Ç‰ΩïÊ†πÊìöÊó¢ÂÆöÁöÑË®≠Ë®àÊ®°ÂºèÂ∞çÈÄô‰∫õÁ≥ªÁµ±ÈÄ≤Ë°åÂàÜÈ°ûÔºå‰ª•ÂèäÂ¶Ç‰ΩïÈÄöÈÅéÊØîËºÉÂàÜÊûêÊèêÂèñË¶ãËß£ÔºåÊú¨Á†îÁ©∂‰ΩøÁî®ËªüÈ´îÂ∑•Á®ã‰∏≠ÁöÑË®≠Ë®àÊ®°Âºè‰æÜ‰∫ÜËß£ÂíåÂÑ™ÂåñÈÜ´ÁôÇ‰øùÂÅ•‰∫∫Â∑•Êô∫ÊÖßÁ≥ªÁµ±„ÄÇÁõíÂ≠êÂ≠∏ÊúâÂä©ÊñºË≠òÂà•ÂÖ±ÊÄß‰∏¶Âª∫Á´ãÂèØÈáçË§á‰ΩøÁî®ÁöÑËß£Ê±∫ÊñπÊ°àÔºåÂæûËÄåÂ¢ûÂº∑ÈÄô‰∫õÁ≥ªÁµ±ÁöÑÂèØÊì¥ÂÖÖÊÄß„ÄÅÂèØÈù†ÊÄßÂíåÊïàËÉΩ„ÄÇÊ™¢Êü•‰∫Ü‰∫îÁ®Æ‰∏ªË¶ÅÁöÑÊû∂ÊßãÔºöREML„ÄÅMLRB„ÄÅRBML„ÄÅRMLT Âíå PERML„ÄÇÊØèÁ®ÆÊû∂ÊßãÈÉΩÊúâÁç®ÁâπÁöÑÂÑ™Áº∫ÈªûÔºåÂº∑Ë™ø‰∫ÜÂú®Ëá®Â∫ä‰ªªÂãô‰∏≠ÈúÄË¶ÅÈáèË∫´ÊâìÈÄ†ÁöÑÊñπÊ≥ï„ÄÇREML Âú®Ë≥áÊñôÊúâÈôêÁöÑË≥áÊñôÈõÜ‰∏≠Ë°®ÁèæÂá∫È´òÁ≤æÂ∫¶ÁöÑÈ†êÊ∏¨ÔºõMLRB Âú®ËôïÁêÜÂ§ßÂûãË≥áÊñôÈõÜÂíåË§áÈõúË≥áÊñôÊï¥ÂêàÊñπÈù¢Ë°®ÁèæÂá∫Ëâ≤ÔºõRBML Âú®ÂèØËß£ÈáãÊÄßÂíåÂèØ‰ø°Â∫¶ÊñπÈù¢Ë°®ÁèæÂá∫Ëâ≤ÔºõRMLT Âú®ÁÆ°ÁêÜÈ´òÁ∂≠Ë≥áÊñôÊñπÈù¢Ë°®ÁèæÂá∫Ëâ≤ÔºõËÄå PERML ÂÑòÁÆ°Âú®ÂàÜÊûêÊñπÈù¢ÊúâÈôêÔºå‰ΩÜÂú®Á∑äÊÄ•ÁÖßË≠∑Â†¥ÊôØ‰∏≠Ë°®ÁèæÂá∫ÊΩõÂäõ„ÄÇÊú¨Á†îÁ©∂ÂºïÂÖ•‰∫ÜÂõõÁ®ÆÊñ∞Ê®°ÂºèÔºåÂª∫Á´ã‰∫Ü‰∫îÁ®ÆÊäΩË±°ÂàÜÈ°ûÊ®°ÂºèÔºå‰∏¶ÈÄ≤‰∏ÄÊ≠•Â∞áÈÄô‰∫îÁ®ÆÊ®°ÂºèÁ¥∞ÂåñÁÇ∫ÂÖ∑È´îÁöÑÁ≥ªÁµ±„ÄÇÈÄô‰∫õË≤¢ÁçªÂ¢ûÂº∑‰∫ÜÁõíÂ≠êÂ≠∏ÁöÑÂàÜÈ°ûÁµÑÁπîÔºå‰∏¶Êèê‰æõ‰∫ÜÂ∞áÂ∞àÂÆ∂Áü•Ë≠òËàáÊ©üÂô®Â≠∏ÁøíÊï¥ÂêàÁöÑÊñ∞ÊñπÊ≥ï„ÄÇÁõíÂ≠êÂ≠∏ÁöÑÁµêÊßãÂåñ„ÄÅÊ®°ÁµÑÂåñÊñπÊ≥ïÂú®ÈñãÁôºÂíåÂàÜÊûêÊ∑∑Âêà‰∫∫Â∑•Êô∫ÊÖßÁ≥ªÁµ±„ÄÅÊè≠Á§∫ÂÖ±ÊÄß‰ª•ÂèäÊé®Âª£ÂèØÈáçË§á‰ΩøÁî®ÁöÑËß£Ê±∫ÊñπÊ°àÊñπÈù¢ÂÖ∑ÊúâÈ°ØËëóÂÑ™Âã¢„ÄÇÁ∏Ω‰πãÔºåÊú¨Á†îÁ©∂Âº∑Ë™ø‰∫ÜÊ∑∑Âêà‰∫∫Â∑•Êô∫ÊÖßÁ≥ªÁµ±Âú®Êé®ÈÄ≤ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÁöÑÈóúÈçµ‰ΩúÁî®Ôºå‰ª•ÂèäÁõíÂ≠êÂ≠∏Âú®Êé®Âãï‰∫∫Â∑•Êô∫ÊÖßÊï¥ÂêàÈÄ≤‰∏ÄÊ≠•ÂâµÊñ∞ÊñπÈù¢ÁöÑÊΩõÂäõÔºåÊúÄÁµÇÊîπÂñÑËá®Â∫äÊ±∫Á≠ñÊîØÊè¥ÂíåÊÇ£ËÄÖÁöÑÊ≤ªÁôÇÊàêÊûú„ÄÇ

##### **Bayesian Kolmogorov Arnold Networks (Bayesian_KANs): A Probabilistic Approach to Enhance Accuracy and Interpretability**
2408.02706v1 by Masoud Muhammed Hassan

Because of its strong predictive skills, deep learning has emerged as an
essential tool in many industries, including healthcare. Traditional deep
learning models, on the other hand, frequently lack interpretability and omit
to take prediction uncertainty into account two crucial components of clinical
decision making. In order to produce explainable and uncertainty aware
predictions, this study presents a novel framework called Bayesian Kolmogorov
Arnold Networks (BKANs), which combines the expressive capacity of Kolmogorov
Arnold Networks with Bayesian inference. We employ BKANs on two medical
datasets, which are widely used benchmarks for assessing machine learning
models in medical diagnostics: the Pima Indians Diabetes dataset and the
Cleveland Heart Disease dataset. Our method provides useful insights into
prediction confidence and decision boundaries and outperforms traditional deep
learning models in terms of prediction accuracy. Moreover, BKANs' capacity to
represent aleatoric and epistemic uncertainty guarantees doctors receive more
solid and trustworthy decision support. Our Bayesian strategy improves the
interpretability of the model and considerably minimises overfitting, which is
important for tiny and imbalanced medical datasets, according to experimental
results. We present possible expansions to further use BKANs in more
complicated multimodal datasets and address the significance of these
discoveries for future research in building reliable AI systems for healthcare.
This work paves the way for a new paradigm in deep learning model deployment in
vital sectors where transparency and reliability are crucial.

ÊëòË¶ÅÔºöÁî±ÊñºÂÖ∂Âº∑Â§ßÁöÑÈ†êÊ∏¨ËÉΩÂäõÔºåÊ∑±Â∫¶Â≠∏ÁøíÂ∑≤ÊàêÁÇ∫Ë®±Â§öÁî¢Ê•≠‰∏≠‰∏çÂèØÊàñÁº∫ÁöÑÂ∑•ÂÖ∑ÔºåÂåÖÊã¨ÈÜ´ÁôÇ‰øùÂÅ•„ÄÇÁÑ∂ËÄåÔºåÂÇ≥Áµ±ÁöÑÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÈÄöÂ∏∏Áº∫‰πèÂèØËß£ÈáãÊÄßÔºå‰∏¶‰∏îÂøΩÁï•‰∫ÜÂ∞áÈ†êÊ∏¨‰∏çÁ¢∫ÂÆöÊÄßÁ¥çÂÖ•ËÄÉÈáèÔºåËÄåÈÄôÂÖ©ÂÄãÂõ†Á¥†ÊòØËá®Â∫äÊ±∫Á≠ñÂà∂ÂÆöÁöÑÈóúÈçµÁµÑÊàêÈÉ®ÂàÜ„ÄÇÁÇ∫‰∫ÜÁî¢ÁîüÂèØËß£Èáã‰∏îÂÖ∑Êúâ‰∏çÁ¢∫ÂÆöÊÄßÊÑèË≠òÁöÑÈ†êÊ∏¨ÔºåÊú¨Á†îÁ©∂ÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂêçÁÇ∫Ë≤ùÊ∞èÊüØÁàæËé´Âì•Ê¥õÂ§´ÈòøË´æÂæ∑Á∂≤Ë∑Ø (BKAN) ÁöÑÊñ∞Êû∂ÊßãÔºåÂÆÉÁµêÂêà‰∫ÜÊüØÁàæËé´Âì•Ê¥õÂ§´ÈòøË´æÂæ∑Á∂≤Ë∑ØÁöÑË°®ÈÅîËÉΩÂäõËàáË≤ùÊ∞èÊé®Ë´ñ„ÄÇÊàëÂÄëÂú®ÂÖ©ÂÄãÈÜ´Â≠∏Ë≥áÊñôÈõÜ‰∏ä‰ΩøÁî® BKANÔºåÈÄô‰∫õË≥áÊñôÈõÜÊòØË©ï‰º∞Ê©üÂô®Â≠∏ÁøíÊ®°ÂûãÂú®ÈÜ´Â≠∏Ë®∫Êñ∑‰∏≠ÁöÑÂª£Ê≥õ‰ΩøÁî®Âü∫Ê∫ñÔºöÁöÆÈ¶¨Âç∞Á¨¨ÂÆâ‰∫∫Á≥ñÂ∞øÁóÖË≥áÊñôÈõÜÂíåÂÖãÈáåÂ§´Ëò≠ÂøÉËáüÁóÖË≥áÊñôÈõÜ„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÊèê‰æõ‰∫ÜÂ∞çÈ†êÊ∏¨‰ø°ÂøÉÂíåÊ±∫Á≠ñÈÇäÁïåÁöÑÊúâÁõäË¶ãËß£Ôºå‰∏¶‰∏îÂú®È†êÊ∏¨Ê∫ñÁ¢∫Â∫¶ÊñπÈù¢ÂÑ™ÊñºÂÇ≥Áµ±ÁöÑÊ∑±Â∫¶Â≠∏ÁøíÊ®°Âûã„ÄÇÊ≠§Â§ñÔºåBKAN Ë°®ÁèæÈö®Ê©üÂíåË™çË≠ò‰∏çÁ¢∫ÂÆöÊÄßÁöÑËÉΩÂäõÔºåÂèØÁ¢∫‰øùÈÜ´ÁîüÁç≤ÂæóÊõ¥ÂèØÈù†‰∏îÂÄºÂæó‰ø°Ë≥¥ÁöÑÊ±∫Á≠ñÊîØÊè¥„ÄÇÊ†πÊìöÂØ¶È©óÁµêÊûúÔºåÊàëÂÄëÁöÑË≤ùÊ∞èÁ≠ñÁï•ÊèêÈ´ò‰∫ÜÊ®°ÂûãÁöÑÂèØËß£ÈáãÊÄßÔºå‰∏¶Â§ßÂπÖÊ∏õÂ∞ë‰∫ÜÈÅéÂ∫¶Êì¨ÂêàÔºåÈÄôÂ∞çÊñºÂ∞èÂûã‰∏î‰∏çÂπ≥Ë°°ÁöÑÈÜ´Â≠∏Ë≥áÊñôÈõÜÈùûÂ∏∏ÈáçË¶Å„ÄÇÊàëÂÄëÊèêÂá∫‰∫ÜÂèØËÉΩÁöÑÊì¥ÂÖÖÂäüËÉΩÔºå‰ª•ÈÄ≤‰∏ÄÊ≠•Â∞á BKAN Áî®ÊñºÊõ¥Ë§áÈõúÁöÑÂ§öÊ®°ÂºèË≥áÊñôÈõÜÔºå‰∏¶Êé¢Ë®éÈÄô‰∫õÁôºÁèæÂ∞çÊñºÊú™‰æÜÂª∫Á´ãÂèØÈù†ÁöÑÈÜ´ÁôÇ‰øùÂÅ• AI Á≥ªÁµ±Á†îÁ©∂ÁöÑÈáçË¶ÅÊÄß„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÁÇ∫Ê∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÈÉ®ÁΩ≤Âú®ÈÄèÊòéÂ∫¶ÂíåÂèØÈù†ÊÄßËá≥ÈóúÈáçË¶ÅÁöÑÈáçË¶ÅÈ†òÂüü‰∏≠ÈñãÂïü‰∫Ü‰∏ÄÂÄãÊñ∞ÁöÑÂÖ∏ÁØÑ„ÄÇ

##### **Active Sensing of Knee Osteoarthritis Progression with Reinforcement Learning**
2408.02349v1 by Khanh Nguyen, Huy Hoang Nguyen, Egor Panfilov, Aleksei Tiulpin

Osteoarthritis (OA) is the most common musculoskeletal disease, which has no
cure. Knee OA (KOA) is one of the highest causes of disability worldwide, and
it costs billions of United States dollars to the global community. Prediction
of KOA progression has been of high interest to the community for years, as it
can advance treatment development through more efficient clinical trials and
improve patient outcomes through more efficient healthcare utilization.
Existing approaches for predicting KOA, however, are predominantly static, i.e.
consider data from a single time point to predict progression many years into
the future, and knee level, i.e. consider progression in a single joint only.
Due to these and related reasons, these methods fail to deliver the level of
predictive performance, which is sufficient to result in cost savings and
better patient outcomes. Collecting extensive data from all patients on a
regular basis could address the issue, but it is limited by the high cost at a
population level. In this work, we propose to go beyond static prediction
models in OA, and bring a novel Active Sensing (AS) approach, designed to
dynamically follow up patients with the objective of maximizing the number of
informative data acquisitions, while minimizing their total cost over a period
of time. Our approach is based on Reinforcement Learning (RL), and it leverages
a novel reward function designed specifically for AS of disease progression in
more than one part of a human body. Our method is end-to-end, relies on
multi-modal Deep Learning, and requires no human input at inference time.
Throughout an exhaustive experimental evaluation, we show that using RL can
provide a higher monetary benefit when compared to state-of-the-art baselines.

ÊëòË¶ÅÔºöÈ™®ÈóúÁØÄÁÇé (OA) ÊòØ‰∏ÄÁ®ÆÊúÄÂ∏∏Ë¶ãÁöÑËÇåËÇâÈ™®È™ºÁñæÁóÖÔºåÁõÆÂâçÂ∞öÁÑ°Ëó•ÂèØÈÜ´„ÄÇËÜùÈóúÁØÄÈ™®ÈóúÁØÄÁÇé (KOA) ÊòØÂÖ®ÁêÉÊÆòÁñæÁöÑÈ¶ñË¶ÅÂéüÂõ†‰πã‰∏ÄÔºå‰∏¶‰ΩøÂÖ®ÁêÉÁ§æÊúÉÊêçÂ§±Êï∏ÂçÅÂÑÑÁæéÂÖÉ„ÄÇÂ§öÂπ¥‰æÜÔºåÈ†êÊ∏¨ KOA ÁöÑÈÄ≤Â±ï‰∏ÄÁõ¥ÊòØÁ§æÊúÉÈóúÊ≥®ÁöÑÈáçÈªûÔºåÂõ†ÁÇ∫ÂÆÉÂèØ‰ª•ÈÄèÈÅéÊõ¥ÊúâÊïàÁöÑËá®Â∫äË©¶È©óÊé®ÈÄ≤Ê≤ªÁôÇÁöÑÁôºÂ±ïÔºå‰∏¶ÈÄèÈÅéÊõ¥ÊúâÊïàÁéáÁöÑÈÜ´ÁôÇ‰øùÂÅ•Âà©Áî®‰æÜÊîπÂñÑÊÇ£ËÄÖÁöÑÈ†êÂæå„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÁöÑ KOA È†êÊ∏¨ÊñπÊ≥ï‰∏ªË¶ÅÈÉΩÊòØÈùúÊÖãÁöÑÔºå‰πüÂ∞±ÊòØË™™ÔºåÂÉÖËÄÉÊÖÆÂñÆ‰∏ÄÊôÇÈñìÈªûÁöÑÊï∏Êìö‰æÜÈ†êÊ∏¨Êú™‰æÜÂ§öÂπ¥ÁöÑÈÄ≤Â±ïÔºåËÄå‰∏îÊòØËÜùËìãÂ±§Èù¢ÁöÑÔºå‰πüÂ∞±ÊòØË™™ÔºåÂÉÖËÄÉÊÖÆÂñÆ‰∏ÄÈóúÁØÄÁöÑÈÄ≤Â±ï„ÄÇÁî±ÊñºÈÄô‰∫õÂéüÂõ†ÂíåÂÖ∂‰ªñÁõ∏ÈóúÂéüÂõ†ÔºåÈÄô‰∫õÊñπÊ≥ïÁÑ°Ê≥ïÊèê‰æõË∂≥Â§†ÁöÑÈ†êÊ∏¨ÊïàËÉΩÔºå‰ª•Ëá¥ÊñºÁÑ°Ê≥ïÁØÄÁúÅÊàêÊú¨‰∏¶ÊîπÂñÑÊÇ£ËÄÖÁöÑÈ†êÂæå„ÄÇÂÆöÊúüÂæûÊâÄÊúâÊÇ£ËÄÖË∫´‰∏äÊî∂ÈõÜÂª£Ê≥õÁöÑÊï∏ÊìöÂèØ‰ª•Ëß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºå‰ΩÜÈÄôÊúÉÂèóÂà∞‰∫∫Âè£Â±§Á¥öÁöÑÈ´òÊàêÊú¨ÊâÄÈôêÂà∂„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÂª∫Ë≠∞Ë∂ÖË∂ä OA ‰∏≠ÁöÑÈùúÊÖãÈ†êÊ∏¨Ê®°ÂûãÔºå‰∏¶ÊèêÂá∫‰∏ÄÂÄãÂâµÊñ∞ÁöÑ‰∏ªÂãïÊÑüÊ∏¨ (AS) ÊñπÊ≥ïÔºåÊó®Âú®ÂãïÊÖãËøΩËπ§ÊÇ£ËÄÖÔºåÁõÆÊ®ôÊòØÊúÄÂ§ßÂåñÂÖ∑ÊúâË≥áË®äÊÄßÁöÑÊï∏ÊìöÊì∑ÂèñÊ¨°Êï∏ÔºåÂêåÊôÇÂú®‰∏ÄÊÆµÊôÇÈñìÂÖßÂ∞áÂÖ∂Á∏ΩÊàêÊú¨ÈôçËá≥ÊúÄ‰Ωé„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÊòØÂü∫ÊñºÂº∑ÂåñÂ≠∏Áøí (RL)Ôºå‰∏¶Âà©Áî®Â∞àÈñÄÁÇ∫‰∫∫È°ûË∫´È´îÂ§öÂÄãÈÉ®‰ΩçÁöÑÁñæÁóÖÈÄ≤Â±ïÁöÑ AS ÊâÄË®≠Ë®àÁöÑÊñ∞ÂûãÂõûÈ•ãÂáΩÊï∏„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÊòØÁ´ØÂà∞Á´ØÁöÑÔºå‰æùË≥¥ÊñºÂ§öÊ®°ÊÖãÊ∑±Â∫¶Â≠∏ÁøíÔºå‰∏¶‰∏îÂú®Êé®Ë´ñÊôÇÈñì‰∏çÈúÄË¶Å‰∫∫Â∑•Ëº∏ÂÖ•„ÄÇÂú®Ë©≥Áõ°ÁöÑÂØ¶È©óË©ï‰º∞‰∏≠ÔºåÊàëÂÄëË°®ÊòéËàáÊúÄÂÖàÈÄ≤ÁöÑÂü∫Ê∫ñÁõ∏ÊØîÔºå‰ΩøÁî® RL ÂèØ‰ª•Êèê‰æõÊõ¥È´òÁöÑÈáëÈå¢ÊïàÁõä„ÄÇ

##### **MetaWearS: A Shortcut in Wearable Systems Lifecycle with Only a Few Shots**
2408.01988v1 by Alireza Amirshahi, Maedeh H. Toosi, Siamak Mohammadi, Stefano Albini, Pasquale Davide Schiavone, Giovanni Ansaloni, Amir Aminifar, David Atienza

Wearable systems provide continuous health monitoring and can lead to early
detection of potential health issues. However, the lifecycle of wearable
systems faces several challenges. First, effective model training for new
wearable devices requires substantial labeled data from various subjects
collected directly by the wearable. Second, subsequent model updates require
further extensive labeled data for retraining. Finally, frequent model updating
on the wearable device can decrease the battery life in long-term data
monitoring. Addressing these challenges, in this paper, we propose MetaWearS, a
meta-learning method to reduce the amount of initial data collection required.
Moreover, our approach incorporates a prototypical updating mechanism,
simplifying the update process by modifying the class prototype rather than
retraining the entire model. We explore the performance of MetaWearS in two
case studies, namely, the detection of epileptic seizures and the detection of
atrial fibrillation. We show that by fine-tuning with just a few samples, we
achieve 70% and 82% AUC for the detection of epileptic seizures and the
detection of atrial fibrillation, respectively. Compared to a conventional
approach, our proposed method performs better with up to 45% AUC. Furthermore,
updating the model with only 16 minutes of additional labeled data increases
the AUC by up to 5.3%. Finally, MetaWearS reduces the energy consumption for
model updates by 456x and 418x for epileptic seizure and AF detection,
respectively.

ÊëòË¶ÅÔºö<paragraph>Á©øÊà¥ÂºèÁ≥ªÁµ±Êèê‰æõÊåÅÁ∫åÁöÑÂÅ•Â∫∑Áõ£Ê∏¨Ôºå‰∏¶ÂèØÂèäÊó©ÂÅµÊ∏¨ÊΩõÂú®ÁöÑÂÅ•Â∫∑ÂïèÈ°å„ÄÇÁÑ∂ËÄåÔºåÁ©øÊà¥ÂºèÁ≥ªÁµ±ÁöÑÁîüÂëΩÈÄ±ÊúüÈù¢Ëá®ÂπæÂÄãÊåëÊà∞„ÄÇÈ¶ñÂÖàÔºåÊñ∞Á©øÊà¥ÂºèË£ùÁΩÆÁöÑÊúâÊïàÊ®°ÂûãË®ìÁ∑¥ÈúÄË¶ÅÂæûÂêÑÁ®ÆÂèóË©¶ËÄÖÊî∂ÈõÜÁöÑÂ§ßÈáèÊ®ôÁ±§Ë≥áÊñôÔºå‰∏îË≥áÊñôÂøÖÈ†àÁõ¥Êé•Áî±Á©øÊà¥ÂºèË£ùÁΩÆÊî∂ÈõÜ„ÄÇÂÖ∂Ê¨°ÔºåÂæåÁ∫åÁöÑÊ®°ÂûãÊõ¥Êñ∞ÈúÄË¶ÅÈÄ≤‰∏ÄÊ≠•ÁöÑÂ§ßÈáèÊ®ôÁ±§Ë≥áÊñôÊâçËÉΩÈáçÊñ∞Ë®ìÁ∑¥„ÄÇÊúÄÂæåÔºåÁ©øÊà¥ÂºèË£ùÁΩÆ‰∏äÈ†ªÁπÅÁöÑÊ®°ÂûãÊõ¥Êñ∞ÊúÉÁ∏ÆÁü≠Èï∑ÊúüË≥áÊñôÁõ£Ê∏¨ÁöÑÈõªÊ±†Á∫åËà™Âäõ„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÂú®Êú¨Êñá‰∏≠ÊèêÂá∫ MetaWearSÔºåÈÄôÊòØ‰∏ÄÁ®ÆÂÖÉÂ≠∏ÁøíÊñπÊ≥ïÔºåÂèØÊ∏õÂ∞ëÊâÄÈúÄÁöÑÂàùÂßãË≥áÊñôÊî∂ÈõÜÈáè„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁöÑÊñπÊ≥ïÁµêÂêà‰∫Ü‰∏ÄÂÄãÂéüÂûãÊõ¥Êñ∞Ê©üÂà∂ÔºåÈÄèÈÅé‰øÆÊîπÈ°ûÂà•ÂéüÂûãËÄåÈùûÈáçÊñ∞Ë®ìÁ∑¥Êï¥ÂÄãÊ®°Âûã‰æÜÁ∞°ÂåñÊõ¥Êñ∞ÈÅéÁ®ã„ÄÇÊàëÂÄëÂú®ÂÖ©ÂÄãÊ°à‰æãÁ†îÁ©∂‰∏≠Êé¢Ë®é MetaWearS ÁöÑÊïàËÉΩÔºåÂàÜÂà•ÊòØÁô≤ÁôáÁôº‰ΩúÂÅµÊ∏¨ÂíåÂøÉÊàøÈ°´ÂãïÂÅµÊ∏¨„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫ÜÈÄèÈÅéÂæÆË™øÂÉÖÂ∞ëÊï∏Ê®£Êú¨ÔºåÊàëÂÄëÂàÜÂà•Âú®Áô≤ÁôáÁôº‰ΩúÂÅµÊ∏¨ÂíåÂøÉÊàøÈ°´ÂãïÂÅµÊ∏¨‰∏≠ÈÅîÂà∞ 70% Âíå 82% ÁöÑ AUC„ÄÇËàáÂÇ≥Áµ±ÊñπÊ≥ïÁõ∏ÊØîÔºåÊàëÂÄëÊèêÂá∫ÁöÑÊñπÊ≥ïË°®ÁèæÊõ¥Â•ΩÔºåAUC ÊúÄÈ´òÂèØÈÅî 45%„ÄÇÊ≠§Â§ñÔºåÂÉÖ‰ΩøÁî® 16 ÂàÜÈêòÁöÑÈ°çÂ§ñÊ®ôÁ±§Ë≥áÊñôÊõ¥Êñ∞Ê®°ÂûãÔºåÂç≥ÂèØÂ∞á AUC ÊèêÈ´òÂ§öÈÅî 5.3%„ÄÇÊúÄÂæåÔºåMetaWearS ÂàÜÂà•Â∞áÁô≤ÁôáÁôº‰ΩúÂíåÂøÉÊàøÈ°´ÂãïÂÅµÊ∏¨ÁöÑÊ®°ÂûãÊõ¥Êñ∞ËÉΩËÄóÈôç‰Ωé‰∫Ü 456 ÂÄçÂíå 418 ÂÄç„ÄÇ</paragraph>

##### **DiReCT: Diagnostic Reasoning for Clinical Notes via Large Language Models**
2408.01933v2 by Bowen Wang, Jiuyang Chang, Yiming Qian, Guoxin Chen, Junhao Chen, Zhouqiang Jiang, Jiahao Zhang, Yuta Nakashima, Hajime Nagahara

Large language models (LLMs) have recently showcased remarkable capabilities,
spanning a wide range of tasks and applications, including those in the medical
domain. Models like GPT-4 excel in medical question answering but may face
challenges in the lack of interpretability when handling complex tasks in real
clinical settings. We thus introduce the diagnostic reasoning dataset for
clinical notes (DiReCT), aiming at evaluating the reasoning ability and
interpretability of LLMs compared to human doctors. It contains 511 clinical
notes, each meticulously annotated by physicians, detailing the diagnostic
reasoning process from observations in a clinical note to the final diagnosis.
Additionally, a diagnostic knowledge graph is provided to offer essential
knowledge for reasoning, which may not be covered in the training data of
existing LLMs. Evaluations of leading LLMs on DiReCT bring out a significant
gap between their reasoning ability and that of human doctors, highlighting the
critical need for models that can reason effectively in real-world clinical
scenarios.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÊúÄËøëÂ±ïÁ§∫‰∫ÜÈùûÂá°ÁöÑËÉΩÂäõÔºåÊ∂µËìãÂª£Ê≥õÁöÑ‰ªªÂãôÂíåÊáâÁî®ÔºåÂåÖÊã¨ÈÜ´ÁôÇÈ†òÂüüÁöÑ‰ªªÂãôÂíåÊáâÁî®„ÄÇGPT-4 Á≠âÊ®°ÂûãÂú®ÈÜ´ÁôÇÂïèÈ°åËß£Á≠îÊñπÈù¢Ë°®ÁèæÂá∫Ëâ≤Ôºå‰ΩÜÂú®ËôïÁêÜÂØ¶ÈöõËá®Â∫äÂ†¥ÊôØ‰∏≠ÁöÑË§áÈõú‰ªªÂãôÊôÇÔºåÂèØËÉΩÊúÉÈù¢Ëá®Áº∫‰πèÂèØËß£ÈáãÊÄßÁöÑÊåëÊà∞„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜËá®Â∫äÁ≠ÜË®òË®∫Êñ∑Êé®ÁêÜÊï∏ÊìöÈõÜ (DiReCT)ÔºåÊó®Âú®Ë©ï‰º∞ LLM Ëàá‰∫∫È°ûÈÜ´ÁîüÁõ∏ÊØîÁöÑÊé®ÁêÜËÉΩÂäõÂíåÂèØËß£ÈáãÊÄß„ÄÇÂÆÉÂåÖÂê´ 511 ÂÄãËá®Â∫äÁ≠ÜË®òÔºåÊØèÂÄãÁ≠ÜË®òÈÉΩÁ∂ìÈÅéÈÜ´Áîü‰ªîÁ¥∞Ë®ªËß£ÔºåË©≥Á¥∞Ë™™Êòé‰∫ÜÂæûËá®Â∫äÁ≠ÜË®ò‰∏≠ÁöÑËßÄÂØüÁµêÊûúÂà∞ÊúÄÁµÇË®∫Êñ∑ÁöÑË®∫Êñ∑Êé®ÁêÜÈÅéÁ®ã„ÄÇÊ≠§Â§ñÔºåÈÇÑÊèê‰æõ‰∫ÜË®∫Êñ∑Áü•Ë≠òÂúñË≠úÔºå‰ª•Êèê‰æõÊé®ÁêÜÊâÄÈúÄÁöÑÂü∫Êú¨Áü•Ë≠òÔºåÈÄôÂèØËÉΩÊú™Ê∂µËìãÂú®ÁèæÊúâ LLM ÁöÑË®ìÁ∑¥Êï∏Êìö‰∏≠„ÄÇÂú® DiReCT ‰∏äÂ∞çÈ†òÂÖàÁöÑ LLM ÈÄ≤Ë°åË©ï‰º∞ÔºåÁôºÁèæÂÆÉÂÄëÁöÑÊé®ÁêÜËÉΩÂäõËàá‰∫∫È°ûÈÜ´ÁîüÁöÑÊé®ÁêÜËÉΩÂäõ‰πãÈñìÂ≠òÂú®È°ØËëóÂ∑ÆË∑ùÔºåÈÄôÁ™ÅÈ°Ø‰∫ÜÂú®ÁèæÂØ¶‰∏ñÁïåÁöÑËá®Â∫äÂ†¥ÊôØ‰∏≠ËÉΩÂ§†ÊúâÊïàÊé®ÁêÜÁöÑÊ®°ÂûãÁöÑÈóúÈçµÈúÄÊ±Ç„ÄÇ

##### **MALADE: Orchestration of LLM-powered Agents with Retrieval Augmented Generation for Pharmacovigilance**
2408.01869v1 by Jihye Choi, Nils Palumbo, Prasad Chalasani, Matthew M. Engelhard, Somesh Jha, Anivarya Kumar, David Page

In the era of Large Language Models (LLMs), given their remarkable text
understanding and generation abilities, there is an unprecedented opportunity
to develop new, LLM-based methods for trustworthy medical knowledge synthesis,
extraction and summarization. This paper focuses on the problem of
Pharmacovigilance (PhV), where the significance and challenges lie in
identifying Adverse Drug Events (ADEs) from diverse text sources, such as
medical literature, clinical notes, and drug labels. Unfortunately, this task
is hindered by factors including variations in the terminologies of drugs and
outcomes, and ADE descriptions often being buried in large amounts of narrative
text. We present MALADE, the first effective collaborative multi-agent system
powered by LLM with Retrieval Augmented Generation for ADE extraction from drug
label data. This technique involves augmenting a query to an LLM with relevant
information extracted from text resources, and instructing the LLM to compose a
response consistent with the augmented data. MALADE is a general LLM-agnostic
architecture, and its unique capabilities are: (1) leveraging a variety of
external sources, such as medical literature, drug labels, and FDA tools (e.g.,
OpenFDA drug information API), (2) extracting drug-outcome association in a
structured format along with the strength of the association, and (3) providing
explanations for established associations. Instantiated with GPT-4 Turbo or
GPT-4o, and FDA drug label data, MALADE demonstrates its efficacy with an Area
Under ROC Curve of 0.90 against the OMOP Ground Truth table of ADEs. Our
implementation leverages the Langroid multi-agent LLM framework and can be
found at https://github.com/jihyechoi77/malade.

ÊëòË¶ÅÔºöÂú®Â§ßËØ≠Ë®ÄÊ®°Âûã (LLM) Êó∂‰ª£ÔºåÈâ¥‰∫éÂÖ∂ÂçìË∂äÁöÑÊñáÊú¨ÁêÜËß£ÂíåÁîüÊàêËÉΩÂäõÔºåÂá∫Áé∞‰∫Ü‰∏Ä‰∏™ÂâçÊâÄÊú™ÊúâÁöÑÊú∫‰ºöÔºåÂèØ‰ª•ÂºÄÂèëÂü∫‰∫é LLM ÁöÑÊñ∞ÊñπÊ≥ïÔºåÁî®‰∫éÂèØ‰ø°ÁöÑÂåªÂ≠¶Áü•ËØÜÁªºÂêà„ÄÅÊèêÂèñÂíåÊëòË¶Å„ÄÇÊú¨ÊñáÈáçÁÇπÂÖ≥Ê≥®ËçØÁâ©Ë≠¶Êàí (PhV) ÁöÑÈóÆÈ¢òÔºåÂÖ∂ÈáçË¶ÅÊÄßÂíåÊåëÊàòÂú®‰∫é‰ªéÂêÑÁßçÊñáÊú¨Êù•Ê∫êÔºàÂ¶ÇÂåªÂ≠¶ÊñáÁåÆ„ÄÅ‰∏¥Â∫äÁ¨îËÆ∞ÂíåËçØÁâ©Ê†áÁ≠æÔºâ‰∏≠ËØÜÂà´‰∏çËâØËçØÁâ©‰∫ã‰ª∂ (ADE)„ÄÇ‰∏çÂπ∏ÁöÑÊòØÔºåËøôÈ°π‰ªªÂä°ÂèóÂà∞Â§öÁßçÂõ†Á¥†ÁöÑÈòªÁ¢çÔºåÂåÖÊã¨ËçØÁâ©ÂíåÁªìÊûúÊúØËØ≠ÁöÑÂèòÂåñÔºå‰ª•Âèä ADE ÊèèËø∞ÈÄöÂ∏∏ÂüãÊ≤°Âú®Â§ßÈáèÂèôËø∞ÊÄßÊñáÊú¨‰∏≠„ÄÇÊàë‰ª¨Â±ïÁ§∫‰∫Ü MALADEÔºåËøôÊòØÁ¨¨‰∏Ä‰∏™ÊúâÊïàÁöÑÂçè‰ΩúÂ§öÊô∫ËÉΩ‰ΩìÁ≥ªÁªüÔºåÁî± LLM Êèê‰æõÊîØÊåÅÔºåÂπ∂‰ΩøÁî®Ê£ÄÁ¥¢Â¢ûÂº∫ÁîüÊàêÊù•‰ªéËçØÁâ©Ê†áÁ≠æÊï∞ÊçÆ‰∏≠ÊèêÂèñ ADE„ÄÇÊ≠§ÊäÄÊúØÊ∂âÂèä‰ΩøÁî®‰ªéÊñáÊú¨ËµÑÊ∫ê‰∏≠ÊèêÂèñÁöÑÁõ∏ÂÖ≥‰ø°ÊÅØÊù•Êâ©ÂÖÖÂØπ LLM ÁöÑÊü•ËØ¢ÔºåÂπ∂ÊåáÁ§∫ LLM ÁºñÂÜô‰∏éÊâ©ÂÖÖÊï∞ÊçÆ‰∏ÄËá¥ÁöÑÂìçÂ∫î„ÄÇMALADE ÊòØ‰∏ÄÁßçÈÄöÁî®ÁöÑ LLM ‰∏çÂèØÁü•Êû∂ÊûÑÔºåÂÖ∂Áã¨ÁâπÂäüËÉΩÂåÖÊã¨Ôºö(1) Âà©Áî®ÂêÑÁßçÂ§ñÈÉ®Êù•Ê∫êÔºå‰æãÂ¶ÇÂåªÂ≠¶ÊñáÁåÆ„ÄÅËçØÁâ©Ê†áÁ≠æÂíå FDA Â∑•ÂÖ∑Ôºà‰æãÂ¶Ç OpenFDA ËçØÁâ©‰ø°ÊÅØ APIÔºâÔºå(2) ‰ª•ÁªìÊûÑÂåñÊ†ºÂºèÊèêÂèñËçØÁâ©-ÁªìÊûúÂÖ≥ËÅî‰ª•ÂèäÂÖ≥ËÅîÂº∫Â∫¶Ôºå‰ª•Âèä (3) ‰∏∫Â∑≤Âª∫Á´ãÁöÑÂÖ≥ËÅîÊèê‰æõËß£Èáä„ÄÇMALADE ‰ΩøÁî® GPT-4 Turbo Êàñ GPT-4o ‰ª•Âèä FDA ËçØÁâ©Ê†áÁ≠æÊï∞ÊçÆÂÆû‰æãÂåñÔºåÂπ∂ÈÄöËøáÈíàÂØπ ADE ÁöÑ OMOP Âü∫Êú¨‰∫ãÂÆûË°®Ôºå‰ª• 0.90 ÁöÑ ROC Êõ≤Á∫ø‰∏ãÈù¢ÁßØËØÅÊòé‰∫ÜÂÖ∂ÊúâÊïàÊÄß„ÄÇÊàë‰ª¨ÁöÑÂÆûÁé∞Âà©Áî®‰∫Ü Langroid Â§öÊô∫ËÉΩ‰Ωì LLM Ê°ÜÊû∂ÔºåÂèØ‰ª•Âú® https://github.com/jihyechoi77/malade ‰∏≠ÊâæÂà∞„ÄÇ

##### **Building Trust in Mental Health Chatbots: Safety Metrics and LLM-Based Evaluation Tools**
2408.04650v1 by Jung In Park, Mahyar Abbasian, Iman Azimi, Dawn Bounds, Angela Jun, Jaesu Han, Robert McCarron, Jessica Borelli, Jia Li, Mona Mahmoudi, Carmen Wiedenhoeft, Amir Rahmani

Objective: This study aims to develop and validate an evaluation framework to
ensure the safety and reliability of mental health chatbots, which are
increasingly popular due to their accessibility, human-like interactions, and
context-aware support. Materials and Methods: We created an evaluation
framework with 100 benchmark questions and ideal responses, and five guideline
questions for chatbot responses. This framework, validated by mental health
experts, was tested on a GPT-3.5-turbo-based chatbot. Automated evaluation
methods explored included large language model (LLM)-based scoring, an agentic
approach using real-time data, and embedding models to compare chatbot
responses against ground truth standards. Results: The results highlight the
importance of guidelines and ground truth for improving LLM evaluation
accuracy. The agentic method, dynamically accessing reliable information,
demonstrated the best alignment with human assessments. Adherence to a
standardized, expert-validated framework significantly enhanced chatbot
response safety and reliability. Discussion: Our findings emphasize the need
for comprehensive, expert-tailored safety evaluation metrics for mental health
chatbots. While LLMs have significant potential, careful implementation is
necessary to mitigate risks. The superior performance of the agentic approach
underscores the importance of real-time data access in enhancing chatbot
reliability. Conclusion: The study validated an evaluation framework for mental
health chatbots, proving its effectiveness in improving safety and reliability.
Future work should extend evaluations to accuracy, bias, empathy, and privacy
to ensure holistic assessment and responsible integration into healthcare.
Standardized evaluations will build trust among users and professionals,
facilitating broader adoption and improved mental health support through
technology.

ÊëòË¶ÅÔºö<paragraph>ÁõÆÊ®ôÔºöÊú¨Á†îÁ©∂Êó®Âú®ÈñãÁôºÂíåÈ©óË≠â‰∏ÄÂÄãË©ï‰º∞Êû∂ÊßãÔºå‰ª•Á¢∫‰øùÂøÉÁêÜÂÅ•Â∫∑ËÅäÂ§©Ê©üÂô®‰∫∫ÁöÑÂÆâÂÖ®ÊÄßËàáÂèØÈù†ÊÄßÔºåÁî±ÊñºÂÖ∂ÂèØÂèäÊÄß„ÄÅÊì¨‰∫∫ÂåñÁöÑ‰∫íÂãï‰ª•ÂèäÊÉÖÂ¢ÉÊÑüÁü•ÊîØÊè¥ÔºåÈÄô‰∫õËÅäÂ§©Ê©üÂô®‰∫∫Ê≠£ËÆäÂæóË∂ä‰æÜË∂äÂèóÊ≠°Ëøé„ÄÇÊùêÊñôËàáÊñπÊ≥ïÔºöÊàëÂÄëÂª∫Á´ã‰∫Ü‰∏ÄÂÄãË©ï‰º∞Êû∂ÊßãÔºåÂÖ∂‰∏≠ÂåÖÂê´ 100 ÂÄãÂü∫Ê∫ñÂïèÈ°åÂíåÁêÜÊÉ≥ÂõûÊáâÔºå‰ª•ÂèäÈáùÂ∞çËÅäÂ§©Ê©üÂô®‰∫∫ÂõûÊáâÁöÑ‰∫îÂÄãÊåáÂçóÂïèÈ°å„ÄÇÈÄôÂÄãÊû∂ÊßãÁ∂ìÈÅéÂøÉÁêÜÂÅ•Â∫∑Â∞àÂÆ∂È©óË≠âÔºå‰∏¶Âú®‰∏ÄÂÄãÂü∫Êñº GPT-3.5-turbo ÁöÑËÅäÂ§©Ê©üÂô®‰∫∫‰∏äÈÄ≤Ë°åÊ∏¨Ë©¶„ÄÇÊé¢Ë®éÁöÑËá™ÂãïË©ï‰º∞ÊñπÊ≥ïÂåÖÊã¨Âü∫ÊñºÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑË©ïÂàÜ„ÄÅ‰ΩøÁî®Âç≥ÊôÇË≥áÊñôÁöÑËÉΩÂãïÊñπÊ≥ïÔºå‰ª•ÂèäÂ∞áËÅäÂ§©Ê©üÂô®‰∫∫ÂõûÊáâËàáÂü∫Êú¨‰∫ãÂØ¶Ê®ôÊ∫ñÈÄ≤Ë°åÊØîËºÉÁöÑÂµåÂÖ•ÂºèÊ®°Âûã„ÄÇÁµêÊûúÔºöÁµêÊûúÂº∑Ë™ø‰∫ÜÊ∫ñÂâáÂíåÂü∫Êú¨‰∫ãÂØ¶Â∞çÊñºÊèêÂçá LLM Ë©ï‰º∞Ê∫ñÁ¢∫ÊÄßÁöÑÈáçË¶ÅÊÄß„ÄÇËÉΩÂãïÊñπÊ≥ïÂãïÊÖãÂú∞Â≠òÂèñÂèØÈù†Ë≥áË®äÔºåË≠âÊòéËàá‰∫∫È°ûË©ï‰º∞ÊúÄÁÇ∫‰∏ÄËá¥„ÄÇÈÅµÂæ™Ê®ôÊ∫ñÂåñ‰∏îÁ∂ìÈÅéÂ∞àÂÆ∂È©óË≠âÁöÑÊû∂ÊßãÔºåÈ°ØËëóÊèêÂçá‰∫ÜËÅäÂ§©Ê©üÂô®‰∫∫ÂõûÊáâÁöÑÂÆâÂÖ®ÊÄßËàáÂèØÈù†ÊÄß„ÄÇË®éË´ñÔºöÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÂº∑Ë™ø‰∫ÜÈáùÂ∞çÂøÉÁêÜÂÅ•Â∫∑ËÅäÂ§©Ê©üÂô®‰∫∫Âà∂ÂÆöÂÖ®Èù¢‰∏îÂ∞àÂÆ∂ÈáèË∫´ÊâìÈÄ†ÁöÑÂÆâÂÖ®Ë©ï‰º∞ÊåáÊ®ôÁöÑÂøÖË¶ÅÊÄß„ÄÇÂÑòÁÆ° LLM ÂÖ∑ÊúâÈ°ØËëóÁöÑÊΩõÂäõÔºå‰ΩÜ‰ªçÈúÄË¶ÅË¨πÊÖéÂØ¶ÊñΩ‰ª•Èôç‰ΩéÈ¢®Èö™„ÄÇËÉΩÂãïÊñπÊ≥ïÁöÑÂÑ™Áï∞Ë°®ÁèæÁ™ÅÈ°Ø‰∫ÜÂç≥ÊôÇË≥áÊñôÂ≠òÂèñÂ∞çÊñºÊèêÂçáËÅäÂ§©Ê©üÂô®‰∫∫ÂèØÈù†ÊÄßÁöÑÈáçË¶ÅÊÄß„ÄÇÁµêË´ñÔºöÊú¨Á†îÁ©∂È©óË≠â‰∫Ü‰∏ÄÂÄãÈáùÂ∞çÂøÉÁêÜÂÅ•Â∫∑ËÅäÂ§©Ê©üÂô®‰∫∫ÁöÑË©ï‰º∞Êû∂ÊßãÔºåË≠âÊòéÂÖ∂Âú®ÊèêÂçáÂÆâÂÖ®ÊÄßËàáÂèØÈù†ÊÄßÊñπÈù¢ÁöÑÊúâÊïàÊÄß„ÄÇÊú™‰æÜÁöÑÁ†îÁ©∂ÊáâÂ∞áË©ï‰º∞Êì¥Â±ïËá≥Ê∫ñÁ¢∫ÊÄß„ÄÅÂÅèË¶ã„ÄÅÂêåÁêÜÂøÉÂíåÈö±ÁßÅÔºå‰ª•Á¢∫‰øùÂÖ®Èù¢ÁöÑË©ï‰º∞Ôºå‰∏¶Ë≤†Ë≤¨‰ªªÂú∞Êï¥ÂêàËá≥ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠„ÄÇÊ®ôÊ∫ñÂåñÁöÑË©ï‰º∞Â∞áÂª∫Á´ã‰ΩøÁî®ËÄÖÂíåÂ∞àÊ•≠‰∫∫Â£´‰πãÈñìÁöÑ‰ø°‰ªªÔºå‰øÉÈÄ≤Êõ¥Âª£Ê≥õÁöÑÊé°Áî®Ôºå‰∏¶ÈÄèÈÅéÁßëÊäÄÊîπÂñÑÂøÉÁêÜÂÅ•Â∫∑ÊîØÊè¥„ÄÇ</paragraph>

##### **ST-SACLF: Style Transfer Informed Self-Attention Classifier for Bias-Aware Painting Classification**
2408.01827v1 by Mridula Vijendran, Frederick W. B. Li, Jingjing Deng, Hubert P. H. Shum

Painting classification plays a vital role in organizing, finding, and
suggesting artwork for digital and classic art galleries. Existing methods
struggle with adapting knowledge from the real world to artistic images during
training, leading to poor performance when dealing with different datasets. Our
innovation lies in addressing these challenges through a two-step process.
First, we generate more data using Style Transfer with Adaptive Instance
Normalization (AdaIN), bridging the gap between diverse styles. Then, our
classifier gains a boost with feature-map adaptive spatial attention modules,
improving its understanding of artistic details. Moreover, we tackle the
problem of imbalanced class representation by dynamically adjusting augmented
samples. Through a dual-stage process involving careful hyperparameter search
and model fine-tuning, we achieve an impressive 87.24\% accuracy using the
ResNet-50 backbone over 40 training epochs. Our study explores quantitative
analyses that compare different pretrained backbones, investigates model
optimization through ablation studies, and examines how varying augmentation
levels affect model performance. Complementing this, our qualitative
experiments offer valuable insights into the model's decision-making process
using spatial attention and its ability to differentiate between easy and
challenging samples based on confidence ranking.

ÊëòË¶ÅÔºöÁπ™Áï´ÂàÜÈ°ûÂú®ÁµÑÁπî„ÄÅÂ∞ãÊâæÂíåÂª∫Ë≠∞Êï∏‰ΩçÂíåÁ∂ìÂÖ∏ËóùÂªäÁöÑËóùË°ìÂìÅ‰∏≠ÊâÆÊºîÈáçË¶ÅÁöÑËßíËâ≤„ÄÇÁèæÊúâÁöÑÊñπÊ≥ïÂú®Ë®ìÁ∑¥ÊôÇÈõ£‰ª•Â∞áÁèæÂØ¶‰∏ñÁïåÁöÑÁü•Ë≠òÈÅ©ÊáâÂà∞ËóùË°ìÂúñÂÉè‰∏≠ÔºåÂ∞éËá¥Âú®ËôïÁêÜ‰∏çÂêåË≥áÊñôÈõÜÊôÇÊïàËÉΩ‰∏ç‰Ω≥„ÄÇÊàëÂÄëÁöÑÂâµÊñ∞Âú®ÊñºÈÄèÈÅéÂÖ©Ê≠•È©üÁöÑÁ®ãÂ∫è‰æÜËß£Ê±∫ÈÄô‰∫õÊåëÊà∞„ÄÇÈ¶ñÂÖàÔºåÊàëÂÄë‰ΩøÁî®ÂÖ∑ÊúâËá™ÈÅ©ÊáâÂØ¶‰æãÊ≠£Ë¶èÂåñ (AdaIN) ÁöÑÈ¢®Ê†ºËΩâÁßª‰æÜÁî¢ÁîüÊõ¥Â§öË≥áÊñôÔºåÂΩåÂêà‰∫Ü‰∏çÂêåÈ¢®Ê†º‰πãÈñìÁöÑÂ∑ÆË∑ù„ÄÇÊé•ËëóÔºåÊàëÂÄëÁöÑÂàÜÈ°ûÂô®ÈÄèÈÅéÂÖ∑ÂÇôÁâπÂæµÂúñËá™ÈÅ©ÊáâÁ©∫ÈñìÊ≥®ÊÑèÂäõÊ®°ÁµÑËÄåÁç≤ÂæóÊèêÂçáÔºåÈÄ≤ËÄåÊîπÂñÑÂÖ∂Â∞çËóùË°ìÁ¥∞ÁØÄÁöÑÁêÜËß£„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÈÄèÈÅéÂãïÊÖãË™øÊï¥Êì¥ÂÖÖÊ®£Êú¨‰æÜËß£Ê±∫È°ûÂà•Ë°®Á§∫‰∏çÂπ≥Ë°°ÁöÑÂïèÈ°å„ÄÇÈÄèÈÅé‰∏ÄÂÄãÊ∂âÂèä‰ªîÁ¥∞ÁöÑË∂ÖÂèÉÊï∏ÊêúÂ∞ãÂíåÊ®°ÂûãÂæÆË™øÁöÑÈõôÈöéÊÆµÁ®ãÂ∫èÔºåÊàëÂÄë‰ΩøÁî® ResNet-50 ‰∏ªÂππÂú®Ë∂ÖÈÅé 40 ÂÄãË®ìÁ∑¥ÊôÇÊúüÈÅîÂà∞‰∫Ü‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑ 87.24% Ê∫ñÁ¢∫Â∫¶„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂Êé¢Ë®é‰∫ÜÊØîËºÉ‰∏çÂêåÈ†êË®ìÁ∑¥‰∏ªÂππÁöÑÂÆöÈáèÂàÜÊûêÔºåÈÄèÈÅéÊ∂àËûçÁ†îÁ©∂‰æÜÊé¢Ë®éÊ®°ÂûãÊúÄ‰Ω≥ÂåñÔºå‰∏¶Ê™¢Ë¶ñ‰∏çÂêåÁöÑÊì¥ÂÖÖÂ±§Á¥öÂ¶Ç‰ΩïÂΩ±ÈüøÊ®°ÂûãÊïàËÉΩ„ÄÇ‰ΩúÁÇ∫Ë£úÂÖÖÔºåÊàëÂÄëÁöÑÂÆöÊÄßÂØ¶È©óÈÄèÈÅéÁ©∫ÈñìÊ≥®ÊÑèÂäõÊèê‰æõ‰∫ÜÊúâÂÉπÂÄºÁöÑË¶ãËß£Ôºå‰∫ÜËß£Ê®°ÂûãÁöÑÊ±∫Á≠ñÂà∂ÂÆöÁ®ãÂ∫èÔºå‰ª•ÂèäÂÆÉÊ†πÊìö‰ø°ÂøÉÊéíÂêç‰æÜÂçÄÂàÜÂÆπÊòìÂíåÂõ∞Èõ£Ê®£Êú¨ÁöÑËÉΩÂäõ„ÄÇ

##### **Advancing Mental Health Pre-Screening: A New Custom GPT for Psychological Distress Assessment**
2408.01614v1 by Jinwen Tang, Yi Shang

This study introduces 'Psycho Analyst', a custom GPT model based on OpenAI's
GPT-4, optimized for pre-screening mental health disorders. Enhanced with
DSM-5, PHQ-8, detailed data descriptions, and extensive training data, the
model adeptly decodes nuanced linguistic indicators of mental health disorders.
It utilizes a dual-task framework that includes binary classification and a
three-stage PHQ-8 score computation involving initial assessment, detailed
breakdown, and independent assessment, showcasing refined analytic
capabilities. Validation with the DAIC-WOZ dataset reveals F1 and Macro-F1
scores of 0.929 and 0.949, respectively, along with the lowest MAE and RMSE of
2.89 and 3.69 in PHQ-8 scoring. These results highlight the model's precision
and transformative potential in enhancing public mental health support,
improving accessibility, cost-effectiveness, and serving as a second opinion
for professionals.

ÊëòË¶ÅÔºöÊú¨Á†îÁ©∂Êé®Âá∫‰∫Ü„ÄåÂøÉÁêÜÂàÜÊûêÂ∏´„ÄçÔºå‰∏ÄÂÄãÂü∫Êñº OpenAI ÁöÑ GPT-4 ÁöÑËá™Ë®Ç GPT Ê®°ÂûãÔºåÈáùÂ∞çÂøÉÁêÜÂÅ•Â∫∑ÈöúÁ§ôÁöÑÈ†êÁØ©ÈÅ∏ËÄåÊúÄ‰Ω≥Âåñ„ÄÇÊ≠§Ê®°ÂûãÁ∂ìÈÅé DSM-5„ÄÅPHQ-8„ÄÅË©≥Á¥∞Ë≥áÊñôÊèèËø∞ÂíåÂª£Ê≥õË®ìÁ∑¥Ë≥áÊñôÁöÑÂº∑ÂåñÔºåËÉΩÁÜüÁ∑¥Âú∞Ëß£Á¢ºÂøÉÁêÜÂÅ•Â∫∑ÈöúÁ§ôÁöÑÁ¥∞ÂæÆË™ûË®ÄÊåáÊ®ô„ÄÇÂÆÉÊé°Áî®‰∏ÄÂÄãÈõô‰ªªÂãôÊû∂ÊßãÔºåÂåÖÊã¨‰∫åÂÖÉÂàÜÈ°ûÂíå‰∏ÄÂÄã‰∏âÈöéÊÆµ PHQ-8 ÂàÜÊï∏Ë®àÁÆóÔºåÊ∂âÂèäÂàùÊ≠•Ë©ï‰º∞„ÄÅË©≥Á¥∞Á¥∞ÂàÜÂíåÁç®Á´ãË©ï‰º∞ÔºåÂ±ïÁ§∫‰∫ÜÁ≤æÁ∑ªÁöÑÂàÜÊûêËÉΩÂäõ„ÄÇ‰ΩøÁî® DAIC-WOZ Ë≥áÊñôÈõÜÈÄ≤Ë°åÈ©óË≠âÔºåF1 ÂíåÂ∑®ÈõÜ F1 ÂàÜÊï∏ÂàÜÂà•ÁÇ∫ 0.929 Âíå 0.949ÔºåPHQ-8 Ë©ïÂàÜ‰∏≠ÁöÑ MAE Âíå RMSE ÊúÄ‰ΩéÔºåÂàÜÂà•ÁÇ∫ 2.89 Âíå 3.69„ÄÇÈÄô‰∫õÁµêÊûúÁ™ÅÈ°Ø‰∫ÜÊ≠§Ê®°ÂûãÂú®ÊèêÂçáÂÖ¨ÁúæÂøÉÁêÜÂÅ•Â∫∑ÊîØÊåÅ„ÄÅÊîπÂñÑÂèØÂèäÊÄß„ÄÅÊàêÊú¨ÊïàÁõäÔºå‰ª•Âèä‰ΩúÁÇ∫Â∞àÊ•≠‰∫∫Â£´ÁöÑÁ¨¨‰∫åÊÑèË¶ãÊñπÈù¢ÁöÑÁ≤æÊ∫ñÂ∫¶ÂíåËÆäÈù©ÊΩõÂäõ„ÄÇ

##### **Conformal Diffusion Models for Individual Treatment Effect Estimation and Inference**
2408.01582v1 by Hengrui Cai, Huaqing Jin, Lexin Li

Estimating treatment effects from observational data is of central interest
across numerous application domains. Individual treatment effect offers the
most granular measure of treatment effect on an individual level, and is the
most useful to facilitate personalized care. However, its estimation and
inference remain underdeveloped due to several challenges. In this article, we
propose a novel conformal diffusion model-based approach that addresses those
intricate challenges. We integrate the highly flexible diffusion modeling, the
model-free statistical inference paradigm of conformal inference, along with
propensity score and covariate local approximation that tackle distributional
shifts. We unbiasedly estimate the distributions of potential outcomes for
individual treatment effect, construct an informative confidence interval, and
establish rigorous theoretical guarantees. We demonstrate the competitive
performance of the proposed method over existing solutions through extensive
numerical studies.

ÊëòË¶ÅÔºöÂæûËßÄÂØüË≥áÊñô‰∏≠‰º∞Ë®àÊ≤ªÁôÇÊïàÊûúÂú®Ë®±Â§öÊáâÁî®È†òÂüü‰∏≠ÈÉΩÈùûÂ∏∏ÈáçË¶Å„ÄÇÂÄãÂà•Ê≤ªÁôÇÊïàÊûúÊèê‰æõ‰∫ÜÂÄã‰∫∫Â±§Á¥öÊúÄÁ¥∞Á∑ªÁöÑÊ≤ªÁôÇÊïàÊûúË°°ÈáèÔºå‰∏îÊúÄÊúâÂä©Êñº‰øÉÈÄ≤ÂÄã‰∫∫ÂåñÁÖßË≠∑„ÄÇÁÑ∂ËÄåÔºåÁî±ÊñºÊúâË®±Â§öÊåëÊà∞ÔºåÂÖ∂‰º∞Ë®àÂíåÊé®Ë´ñ‰ªçËôïÊñºÁôºÂ±ï‰∏çË∂≥ÁöÑÁãÄÊÖã„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫ÜÂâµÊñ∞ÁöÑÂÖ±ÂΩ¢Êì¥Êï£Ê®°ÂûãÁÇ∫Âü∫Á§éÁöÑÊñπÊ≥ïÔºå‰æÜÂõ†ÊáâÈÄô‰∫õË§áÈõúÁöÑÊåëÊà∞„ÄÇÊàëÂÄëÊï¥Âêà‰∫ÜÈ´òÂ∫¶ÂΩàÊÄßÁöÑÊì¥Êï£Ê®°Âûã„ÄÅÂÖ±ÂΩ¢Êé®Ë´ñÁöÑÁÑ°Ê®°ÂûãÁµ±Ë®àÊé®Ë´ñÁØÑ‰æãÔºå‰ª•ÂèäËôïÁêÜÂàÜ‰ΩàËΩâÁßªÁöÑÂÇæÂêëÂæóÂàÜÂíåÂçîËÆäÊï∏Â±ÄÈÉ®Ëøë‰ºº„ÄÇÊàëÂÄëÁÑ°ÂÅè‰º∞Ë®àÂÄãÂà•Ê≤ªÁôÇÊïàÊûúÁöÑÊΩõÂú®ÁµêÊûúÂàÜ‰ΩàÔºåÂª∫ÊßãÊúâÊÑèÁæ©ÁöÑ‰ø°ÂøÉÂçÄÈñìÔºå‰∏¶Âª∫Á´ãÂö¥Ë¨πÁöÑÁêÜË´ñ‰øùË≠â„ÄÇÊàëÂÄëÈÄèÈÅéÂª£Ê≥õÁöÑÊï∏ÂÄºÁ†îÁ©∂ÔºåÂ±ïÁ§∫‰∫ÜÊâÄÊèêÂá∫ÊñπÊ≥ïÁõ∏ËºÉÊñºÁèæÊúâËß£Ê±∫ÊñπÊ°àÁöÑÁ´∂Áà≠Âäõ„ÄÇ

##### **High-Throughput Phenotyping of Clinical Text Using Large Language Models**
2408.01214v1 by Daniel B. Hier, S. Ilyas Munzir, Anne Stahlfeld, Tayo Obafemi-Ajayi, Michael D. Carrithers

High-throughput phenotyping automates the mapping of patient signs to
standardized ontology concepts and is essential for precision medicine. This
study evaluates the automation of phenotyping of clinical summaries from the
Online Mendelian Inheritance in Man (OMIM) database using large language
models. Due to their rich phenotype data, these summaries can be surrogates for
physician notes. We conduct a performance comparison of GPT-4 and
GPT-3.5-Turbo. Our results indicate that GPT-4 surpasses GPT-3.5-Turbo in
identifying, categorizing, and normalizing signs, achieving concordance with
manual annotators comparable to inter-rater agreement. Despite some limitations
in sign normalization, the extensive pre-training of GPT-4 results in high
performance and generalizability across several phenotyping tasks while
obviating the need for manually annotated training data. Large language models
are expected to be the dominant method for automating high-throughput
phenotyping of clinical text.

ÊëòË¶ÅÔºöÈ´òÈÄöÈáèË°®ÂûãËá™ÂãïÂåñÂ∞áÊÇ£ËÄÖÁóáÁãÄÂ∞çÊáâÂà∞Ê®ôÊ∫ñÂåñÊú¨‰ΩìÊ¶ÇÂøµÔºåÂ∞çÊñºÁ≤æÊ∫ñÈÜ´ÁôÇËá≥ÈóúÈáçË¶Å„ÄÇÊú¨Á†îÁ©∂Ë©ï‰º∞‰ΩøÁî®Â§ßÂûãË™ûË®ÄÊ®°ÂûãËá™ÂãïÂåñ‰æÜËá™‰∫∫È°ûÂ≠üÂæ∑ÁàæÈÅ∫ÂÇ≥Á∑ö‰∏äÔºàOMIMÔºâË≥áÊñôÂ∫´ÁöÑËá®Â∫äÊëòË¶ÅË°®Âûã„ÄÇÁî±ÊñºÂÖ∂Ë±êÂØåÁöÑË°®ÂûãË≥áÊñôÔºåÈÄô‰∫õÊëòË¶ÅÂèØ‰ª•‰ΩúÁÇ∫ÈÜ´Â∏´ÂÇôÂøòÈåÑÁöÑÊõø‰ª£ÂìÅ„ÄÇÊàëÂÄëÂ∞ç GPT-4 Âíå GPT-3.5-Turbo ÈÄ≤Ë°åÊïàËÉΩÊØîËºÉ„ÄÇÊàëÂÄëÁöÑÁµêÊûúÈ°ØÁ§∫ÔºåGPT-4 Âú®Ë≠òÂà•„ÄÅÂàÜÈ°ûÂíåÊ®ôÊ∫ñÂåñÁóáÁãÄÊñπÈù¢ÂÑ™Êñº GPT-3.5-TurboÔºåËàáÊâãÂãïË®ªËß£ËÄÖÁöÑÁ¨¶ÂêàÂ∫¶ÂèØÂ™≤ÁæéË©ïÂàÜËÄÖÈñìÁöÑ‰∏ÄËá¥ÊÄß„ÄÇÂÑòÁÆ°Âú®ÁóáÁãÄÊ®ôÊ∫ñÂåñÊñπÈù¢Êúâ‰∏Ä‰∫õÈôêÂà∂Ôºå‰ΩÜ GPT-4 ÁöÑÂª£Ê≥õÈ†êË®ìÁ∑¥Âú®Â§öÈ†ÖË°®Âûã‰ªªÂãô‰∏≠‰ªçËÉΩÂ∏∂‰æÜÈ´òÊïàËÉΩÂíåÊ¶ÇÊã¨ÊÄßÔºåÂêåÊôÇÁÑ°ÈúÄÊâãÂãïË®ªËß£ÁöÑË®ìÁ∑¥Ë≥áÊñô„ÄÇÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÈ†êË®àÂ∞áÊàêÁÇ∫Ëá™ÂãïÂåñËá®Â∫äÊñáÂ≠óÈ´òÈÄöÈáèË°®ÂûãÁöÑ‰∏ªË¶ÅÊñπÊ≥ï„ÄÇ

##### **Optimizing Variational Quantum Circuits Using Metaheuristic Strategies in Reinforcement Learning**
2408.01187v1 by Michael K√∂lle, Daniel Seidl, Maximilian Zorn, Philipp Altmann, Jonas Stein, Thomas Gabor

Quantum Reinforcement Learning (QRL) offers potential advantages over
classical Reinforcement Learning, such as compact state space representation
and faster convergence in certain scenarios. However, practical benefits
require further validation. QRL faces challenges like flat solution landscapes,
where traditional gradient-based methods are inefficient, necessitating the use
of gradient-free algorithms. This work explores the integration of
metaheuristic algorithms -- Particle Swarm Optimization, Ant Colony
Optimization, Tabu Search, Genetic Algorithm, Simulated Annealing, and Harmony
Search -- into QRL. These algorithms provide flexibility and efficiency in
parameter optimization. Evaluations in $5\times5$ MiniGrid Reinforcement
Learning environments show that, all algorithms yield near-optimal results,
with Simulated Annealing and Particle Swarm Optimization performing best. In
the Cart Pole environment, Simulated Annealing, Genetic Algorithms, and
Particle Swarm Optimization achieve optimal results, while the others perform
slightly better than random action selection. These findings demonstrate the
potential of Particle Swarm Optimization and Simulated Annealing for efficient
QRL learning, emphasizing the need for careful algorithm selection and
adaptation.

ÊëòË¶ÅÔºöÈáèÂ≠êÂº∑ÂåñÂ≠∏Áøí (QRL) ÊØîÂÇ≥Áµ±Âº∑ÂåñÂ≠∏ÁøíÂÖ∑ÊúâÊΩõÂú®ÂÑ™Âã¢Ôºå‰æãÂ¶ÇÁ∑äÊπäÁöÑÁãÄÊÖãÁ©∫ÈñìË°®Á§∫ÂíåÂú®Êüê‰∫õÊÉÖÊ≥Å‰∏ãÊõ¥Âø´ÁöÑÊî∂ÊñÇÈÄüÂ∫¶„ÄÇÁÑ∂ËÄåÔºåÂØ¶ÈöõÂ•ΩËôïÈúÄË¶ÅÈÄ≤‰∏ÄÊ≠•È©óË≠â„ÄÇQRL Èù¢Ëá®Âπ≥Âù¶ÁöÑËß£Ê±∫ÊñπÊ°àÁí∞Â¢ÉÁ≠âÊåëÊà∞ÔºåÂÇ≥Áµ±ÁöÑÂü∫ÊñºÊ¢ØÂ∫¶ÁöÑÁÆóÊ≥ïÊïàÁéá‰Ωé‰∏ãÔºåÂõ†Ê≠§ÈúÄË¶Å‰ΩøÁî®ÁÑ°Ê¢ØÂ∫¶ÁÆóÊ≥ï„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÊé¢Ë®é‰∫ÜÂÖÉÂïüÁôºÂºèÊºîÁÆóÊ≥ïÔºàÁ≤íÂ≠êÁæ§ÊúÄ‰Ω≥Âåñ„ÄÅËüªÁæ§ÊúÄ‰Ω≥Âåñ„ÄÅÁ¶ÅÂøåÊêúÂ∞ã„ÄÅÈÅ∫ÂÇ≥ÊºîÁÆóÊ≥ï„ÄÅÊ®°Êì¨ÈÄÄÁÅ´ÂíåÂíåË´ßÊêúÂ∞ãÔºâÊï¥ÂêàÂà∞ QRL ‰∏≠„ÄÇÈÄô‰∫õÊºîÁÆóÊ≥ïÂú®ÂèÉÊï∏ÊúÄ‰Ω≥Âåñ‰∏≠Êèê‰æõ‰∫ÜÈùàÊ¥ªÊÄßËàáÊïàÁéá„ÄÇÂú® $5\times5$ MiniGrid Âº∑ÂåñÂ≠∏ÁøíÁí∞Â¢É‰∏≠ÁöÑË©ï‰º∞È°ØÁ§∫ÔºåÊâÄÊúâÊºîÁÆóÊ≥ïÈÉΩÁî¢ÁîüËøë‰πéÊúÄ‰Ω≥ÁöÑÁµêÊûúÔºåÂÖ∂‰∏≠Ê®°Êì¨ÈÄÄÁÅ´ÂíåÁ≤íÂ≠êÁæ§ÊúÄ‰Ω≥ÂåñË°®ÁèæÊúÄ‰Ω≥„ÄÇÂú®Ê°øÈà¥Áí∞Â¢É‰∏≠ÔºåÊ®°Êì¨ÈÄÄÁÅ´„ÄÅÈÅ∫ÂÇ≥ÊºîÁÆóÊ≥ïÂíåÁ≤íÂ≠êÁæ§ÊúÄ‰Ω≥ÂåñÂØ¶ÁèæÊúÄ‰Ω≥ÁµêÊûúÔºåËÄåÂÖ∂‰ªñÊºîÁÆóÊ≥ïÁöÑÊïàËÉΩÁï•ÂÑ™ÊñºÈö®Ê©üÂãï‰ΩúÈÅ∏Êìá„ÄÇÈÄô‰∫õÁôºÁèæË≠âÊòé‰∫ÜÁ≤íÂ≠êÁæ§ÊúÄ‰Ω≥ÂåñÂíåÊ®°Êì¨ÈÄÄÁÅ´Âú®ÊúâÊïàÁéáÁöÑ QRL Â≠∏Áøí‰∏≠ÁöÑÊΩõÂäõÔºåÂº∑Ë™ø‰∫Ü‰ªîÁ¥∞ÈÅ∏ÊìáÂíåË™øÊï¥ÊºîÁÆóÊ≥ïÁöÑÂøÖË¶ÅÊÄß„ÄÇ

##### **Six Dragons Fly Again: Reviving 15th-Century Korean Court Music with Transformers and Novel Encoding**
2408.01096v1 by Danbinaerin Han, Mark Gotham, Dongmin Kim, Hannah Park, Sihun Lee, Dasaem Jeong

We introduce a project that revives a piece of 15th-century Korean court
music, Chihwapyeong and Chwipunghyeong, composed upon the poem Songs of the
Dragon Flying to Heaven. One of the earliest examples of Jeongganbo, a Korean
musical notation system, the remaining version only consists of a rudimentary
melody. Our research team, commissioned by the National Gugak (Korean
Traditional Music) Center, aimed to transform this old melody into a
performable arrangement for a six-part ensemble. Using Jeongganbo data acquired
through bespoke optical music recognition, we trained a BERT-like masked
language model and an encoder-decoder transformer model. We also propose an
encoding scheme that strictly follows the structure of Jeongganbo and denotes
note durations as positions. The resulting machine-transformed version of
Chihwapyeong and Chwipunghyeong were evaluated by experts and performed by the
Court Music Orchestra of National Gugak Center. Our work demonstrates that
generative models can successfully be applied to traditional music with limited
training data if combined with careful design.

ÊëòË¶ÅÔºöÊàëÂÄë‰ªãÁ¥π‰∫Ü‰∏ÄÂÄãÂæ©Âéü 15 ‰∏ñÁ¥ÄÈüìÂúãÂÆÆÂª∑Èü≥Ê®ÇÁöÑÂ∞àÊ°àÔºåÂç≥„ÄäÈ£õÈæçÊ≠å„ÄãÁöÑ„ÄäÈõâÂíåÊãç„ÄãÂíå„ÄäÂêπÈ¢®Ë©†„Äã„ÄÇÈÄôÊòØÈüìÂúãÈü≥Ê®ÇË®òË≠úÊ≥ï„ÄåÊ≠£Âπ≤Ë≠ú„ÄçÊúÄÊó©ÁöÑÁØÑ‰æã‰πã‰∏ÄÔºåÁèæÂ≠òÁâàÊú¨ÂÉÖÂåÖÂê´Âü∫Êú¨ÁöÑÊóãÂæã„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÂúòÈöäÂèóÂúãÂÆ∂ÂúãÊ®Ç‰∏≠ÂøÉÂßîË®óÔºåÊó®Âú®Â∞áÈÄôÈ¶ñÂè§ËÄÅÁöÑÊóãÂæãËΩâÂåñÁÇ∫ÂÖ≠‰∫∫ÂêàÂ•èÁöÑË°®ÊºîÁ∑®Êéí„ÄÇÊàëÂÄë‰ΩøÁî®ÈÄèÈÅéÂÆ¢Ë£ΩÂåñÂÖâÂ≠∏Èü≥Ê®ÇËæ®Ë≠òÂèñÂæóÁöÑÊ≠£Âπ≤Ë≠úË≥áÊñôÔºåË®ìÁ∑¥‰∫Ü‰∏ÄÂÄãÈ°û‰ºº BERT ÁöÑÈÅÆËîΩË™ûË®ÄÊ®°ÂûãÂíå‰∏ÄÂÄãÁ∑®Á¢ºÂô®-Ëß£Á¢ºÂô®ËΩâÊèõÂô®Ê®°Âûã„ÄÇÊàëÂÄëÈÇÑÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÁ∑®Á¢ºÊñπÊ°àÔºåÂÆÉÂö¥Ê†ºÈÅµÂæ™Ê≠£Âπ≤Ë≠úÁöÑÁµêÊßãÔºå‰∏¶Â∞áÈü≥Á¨¶ÊôÇÂÄºÊ®ôÁ§∫ÁÇ∫‰ΩçÁΩÆ„ÄÇÁî±Ê©üÂô®ËΩâÊèõÂæåÁöÑ„ÄäÈõâÂíåÊãç„ÄãÂíå„ÄäÂêπÈ¢®Ë©†„ÄãÁî±Â∞àÂÆ∂Ë©ï‰º∞Ôºå‰∏¶Áî±ÂúãÂÆ∂ÂúãÊ®Ç‰∏≠ÂøÉÁöÑÂÆÆÂª∑Èü≥Ê®ÇÊ®ÇÂúòÊºîÂ•è„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂Ë≠âÊòéÔºåÂ¶ÇÊûúÂ∞áÁîüÊàêÊ®°ÂûãËàáË¨πÊÖéÁöÑË®≠Ë®àÁµêÂêàÔºåÂç≥‰ΩøË®ìÁ∑¥Ë≥áÊñôÊúâÈôêÔºå‰πüËÉΩÊàêÂäüÊáâÁî®ÊñºÂÇ≥Áµ±Èü≥Ê®Ç„ÄÇ

##### **CIResDiff: A Clinically-Informed Residual Diffusion Model for Predicting Idiopathic Pulmonary Fibrosis Progression**
2408.00938v2 by Caiwen Jiang, Xiaodan Xing, Zaixin Ou, Mianxin Liu, Walsh Simon, Guang Yang, Dinggang Shen

The progression of Idiopathic Pulmonary Fibrosis (IPF) significantly
correlates with higher patient mortality rates. Early detection of IPF
progression is critical for initiating timely treatment, which can effectively
slow down the advancement of the disease. However, the current clinical
criteria define disease progression requiring two CT scans with a one-year
interval, presenting a dilemma: a disease progression is identified only after
the disease has already progressed. To this end, in this paper, we develop a
novel diffusion model to accurately predict the progression of IPF by
generating patient's follow-up CT scan from the initial CT scan. Specifically,
from the clinical prior knowledge, we tailor improvements to the traditional
diffusion model and propose a Clinically-Informed Residual Diffusion model,
called CIResDiff. The key innovations of CIResDiff include 1) performing the
target region pre-registration to align the lung regions of two CT scans at
different time points for reducing the generation difficulty, 2) adopting the
residual diffusion instead of traditional diffusion to enable the model focus
more on differences (i.e., lesions) between the two CT scans rather than the
largely identical anatomical content, and 3) designing the clinically-informed
process based on CLIP technology to integrate lung function information which
is highly relevant to diagnosis into the reverse process for assisting
generation. Extensive experiments on clinical data demonstrate that our
approach can outperform state-of-the-art methods and effectively predict the
progression of IPF.

ÊëòË¶ÅÔºöÁâπÁôºÊÄßËÇ∫Á∫ñÁ∂≠Âåñ (IPF) ÁöÑÈÄ≤Á®ãËàáËºÉÈ´òÁöÑÊÇ£ËÄÖÊ≠ª‰∫°ÁéáÈ°ØËëóÁõ∏Èóú„ÄÇÊó©ÊúüÂÅµÊ∏¨ IPF ÈÄ≤Á®ãÂ∞çÊñºÂèäÊôÇÈñãÂßãÊ≤ªÁôÇËá≥ÈóúÈáçË¶ÅÔºåËÄåÊ≤ªÁôÇÂèØ‰ª•ÊúâÊïàÊ∏õÁ∑©ÁñæÁóÖÁöÑÈÄ≤Â±ï„ÄÇÁÑ∂ËÄåÔºåÁõÆÂâçÁöÑËá®Â∫äÊ®ôÊ∫ñÂÆöÁæ©ÁñæÁóÖÈÄ≤Á®ãÈúÄË¶ÅÂÖ©Ê¨°Áõ∏Èöî‰∏ÄÂπ¥ÁöÑÈõªËÖ¶Êñ∑Â±§ÊéÉÊèèÔºåÈÄôÈÄ†Êàê‰∫ÜÂÖ©Èõ£ÔºöÂè™ÊúâÂú®ÁñæÁóÖÂ∑≤Á∂ìÈÄ≤Â±ïÂæåÊâçËÉΩË≠òÂà•Âá∫ÁñæÁóÖÈÄ≤Á®ã„ÄÇÁÇ∫Ê≠§ÔºåÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÈñãÁôº‰∫Ü‰∏ÄÂÄãÂâµÊñ∞ÁöÑÊì¥Êï£Ê®°ÂûãÔºåÈÄöÈÅéÂæûÂàùÂßãÈõªËÖ¶Êñ∑Â±§ÊéÉÊèèÁîüÊàêÊÇ£ËÄÖÁöÑÂæåÁ∫åÈõªËÖ¶Êñ∑Â±§ÊéÉÊèèÔºå‰æÜÊ∫ñÁ¢∫È†êÊ∏¨ IPF ÁöÑÈÄ≤Á®ã„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊ†πÊìöËá®Â∫äÂÖàÈ©óÁü•Ë≠òÔºåÊàëÂÄëÂ∞çÂÇ≥Áµ±Êì¥Êï£Ê®°ÂûãÈÄ≤Ë°å‰∫ÜÊîπÈÄ≤Ôºå‰∏¶ÊèêÂá∫‰∫ÜËá®Â∫äÁü•ÊÉÖÊÆòÂ∑ÆÊì¥Êï£Ê®°ÂûãÔºåÁ®±ÁÇ∫ CIResDiff„ÄÇCIResDiff ÁöÑÈóúÈçµÂâµÊñ∞ÂåÖÊã¨Ôºö1) Âü∑Ë°åÁõÆÊ®ôÂçÄÂüüÈ†êË®ªÂÜäÔºå‰ª•Â∞çÈΩä‰∏çÂêåÊôÇÈñìÈªûÁöÑÂÖ©Ê¨°ÈõªËÖ¶Êñ∑Â±§ÊéÉÊèèÁöÑËÇ∫ÈÉ®ÂçÄÂüüÔºå‰ª•Èôç‰ΩéÁîüÊàêÈõ£Â∫¶Ôºõ2) Êé°Áî®ÊÆòÂ∑ÆÊì¥Êï£ËÄå‰∏çÊòØÂÇ≥Áµ±Êì¥Êï£Ôºå‰ΩøÊ®°ÂûãÊõ¥Â∞àÊ≥®ÊñºÂÖ©Ê¨°ÈõªËÖ¶Êñ∑Â±§ÊéÉÊèè‰πãÈñìÁöÑÂ∑ÆÁï∞ÔºàÂç≥ÁóÖÁÅ∂ÔºâÔºåËÄå‰∏çÊòØÂú®ÂæàÂ§ßÁ®ãÂ∫¶‰∏äÁõ∏ÂêåÁöÑËß£ÂâñÁµêÊßãÔºõ3) Ë®≠Ë®àÂü∫Êñº CLIP ÊäÄË°ìÁöÑËá®Â∫äÁü•ÊÉÖÊµÅÁ®ãÔºåÂ∞áËàáË®∫Êñ∑È´òÂ∫¶Áõ∏ÈóúÁöÑËÇ∫ÂäüËÉΩË≥áË®äÊï¥ÂêàÂà∞ÈÄÜÂêëÈÅéÁ®ã‰∏≠Ôºå‰ª•ÂçîÂä©ÁîüÊàê„ÄÇËá®Â∫äÊï∏ÊìöÁöÑÂ§ßÈáèÂØ¶È©óË°®ÊòéÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÂèØ‰ª•ÂÑ™ÊñºÊúÄÂÖàÈÄ≤ÁöÑÊñπÊ≥ïÔºå‰∏¶ÊúâÊïàÈ†êÊ∏¨ IPF ÁöÑÈÄ≤Á®ã„ÄÇ

##### **Parkinson's Disease Detection from Resting State EEG using Multi-Head Graph Structure Learning with Gradient Weighted Graph Attention Explanations**
2408.00906v1 by Christopher Neves, Yong Zeng, Yiming Xiao

Parkinson's disease (PD) is a debilitating neurodegenerative disease that has
severe impacts on an individual's quality of life. Compared with structural and
functional MRI-based biomarkers for the disease, electroencephalography (EEG)
can provide more accessible alternatives for clinical insights. While deep
learning (DL) techniques have provided excellent outcomes, many techniques fail
to model spatial information and dynamic brain connectivity, and face
challenges in robust feature learning, limited data sizes, and poor
explainability. To address these issues, we proposed a novel graph neural
network (GNN) technique for explainable PD detection using resting state EEG.
Specifically, we employ structured global convolutions with contrastive
learning to better model complex features with limited data, a novel multi-head
graph structure learner to capture the non-Euclidean structure of EEG data, and
a head-wise gradient-weighted graph attention explainer to offer neural
connectivity insights. We developed and evaluated our method using the UC San
Diego Parkinson's disease EEG dataset, and achieved 69.40% detection accuracy
in subject-wise leave-one-out cross-validation while generating intuitive
explanations for the learnt graph topology.

ÊëòË¶ÅÔºöÂ∏ïÈáëÊ£ÆÊ∞èÁóáÔºàPDÔºâÊòØ‰∏ÄÁßçË°∞Âº±ÊÄßÁ•ûÁªèÈÄÄË°åÊÄßÁñæÁóÖÔºåÂØπ‰∏™‰∫∫ÁöÑÁîüÊ¥ªË¥®ÈáèÊúâ‰∏•ÈáçÂΩ±Âìç„ÄÇ‰∏éÁî®‰∫éËØ•ÁñæÁóÖÁöÑÁªìÊûÑÊÄßÂíåÂäüËÉΩÊÄß MRI ÁîüÁâ©Ê†áËÆ∞Áâ©Áõ∏ÊØîÔºåËÑëÁîµÂõæ (EEG) ÂèØ‰ª•Êèê‰æõÊõ¥Êòì‰∫éËé∑ÂèñÁöÑ‰∏¥Â∫äËßÅËß£Êõø‰ª£ÊñπÊ°à„ÄÇËôΩÁÑ∂Ê∑±Â∫¶Â≠¶‰π† (DL) ÊäÄÊúØÊèê‰æõ‰∫ÜÂçìË∂äÁöÑÁªìÊûúÔºå‰ΩÜËÆ∏Â§öÊäÄÊúØÊú™ËÉΩÂØπÁ©∫Èó¥‰ø°ÊÅØÂíåÂä®ÊÄÅÂ§ßËÑëËøûÊé•ËøõË°åÂª∫Ê®°ÔºåÂπ∂‰∏îÂú®Á®≥ÂÅ•ÁâπÂæÅÂ≠¶‰π†„ÄÅÊúâÈôêÁöÑÊï∞ÊçÆÂ§ßÂ∞èÂíåËæÉÂ∑ÆÁöÑÂèØËß£ÈáäÊÄßÊñπÈù¢Èù¢‰∏¥ÊåëÊàò„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∫õÈóÆÈ¢òÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞È¢ñÁöÑÂõæÁ•ûÁªèÁΩëÁªú (GNN) ÊäÄÊúØÔºåÁî®‰∫é‰ΩøÁî®ÈùôÊÅØÁä∂ÊÄÅËÑëÁîµÂõæËøõË°åÂèØËß£ÈáäÁöÑ PD Ê£ÄÊµã„ÄÇÂÖ∑‰ΩìËÄåË®ÄÔºåÊàë‰ª¨ÈááÁî®ÂÖ∑ÊúâÂØπÊØîÂ≠¶‰π†ÁöÑÁªìÊûÑÂåñÂÖ®Â±ÄÂç∑ÁßØÊù•Êõ¥Â•ΩÂú∞ÂØπÂÖ∑ÊúâÊúâÈôêÊï∞ÊçÆÁöÑÂ§çÊùÇÁâπÂæÅËøõË°åÂª∫Ê®°ÔºåÈááÁî®Êñ∞È¢ñÁöÑÂ§öÂ§¥ÂõæÁªìÊûÑÂ≠¶‰π†Âô®Êù•ÊçïËé∑ËÑëÁîµÂõæÊï∞ÊçÆÁöÑÈùûÊ¨ßÂá†ÈáåÂæóÁªìÊûÑÔºå‰ª•ÂèäÈááÁî®Â§¥ÊùÉÈáçÊ¢ØÂ∫¶ÂõæÊ≥®ÊÑèËß£ÈáäÂô®Êù•Êèê‰æõÁ•ûÁªèËøûÊé•ËßÅËß£„ÄÇÊàë‰ª¨‰ΩøÁî®Âä†Â∑ûÂ§ßÂ≠¶Âú£Âú∞‰∫öÂì•ÂàÜÊ†°Â∏ïÈáëÊ£ÆÊ∞èÁóáËÑëÁîµÂõæÊï∞ÊçÆÈõÜÂºÄÂèëÂπ∂ËØÑ‰º∞‰∫ÜÊàë‰ª¨ÁöÑÊñπÊ≥ïÔºåÂπ∂Âú®ÊåâÂèóËØïËÄÖÁïô‰∏ÄÊ≥ï‰∫§ÂèâÈ™åËØÅ‰∏≠ÂÆûÁé∞‰∫Ü 69.40% ÁöÑÊ£ÄÊµãÂáÜÁ°ÆÁéáÔºåÂêåÊó∂‰∏∫Â≠¶‰π†Âà∞ÁöÑÂõæÊãìÊâëÁîüÊàêÁõ¥ËßÇÁöÑËß£Èáä„ÄÇ

##### **UlRe-NeRF: 3D Ultrasound Imaging through Neural Rendering with Ultrasound Reflection Direction Parameterization**
2408.00860v2 by Ziwen Guo, Zi Fang, Zhuang Fu

Three-dimensional ultrasound imaging is a critical technology widely used in
medical diagnostics. However, traditional 3D ultrasound imaging methods have
limitations such as fixed resolution, low storage efficiency, and insufficient
contextual connectivity, leading to poor performance in handling complex
artifacts and reflection characteristics. Recently, techniques based on NeRF
(Neural Radiance Fields) have made significant progress in view synthesis and
3D reconstruction, but there remains a research gap in high-quality ultrasound
imaging. To address these issues, we propose a new model, UlRe-NeRF, which
combines implicit neural networks and explicit ultrasound volume rendering into
an ultrasound neural rendering architecture. This model incorporates reflection
direction parameterization and harmonic encoding, using a directional MLP
module to generate view-dependent high-frequency reflection intensity
estimates, and a spatial MLP module to produce the medium's physical property
parameters. These parameters are used in the volume rendering process to
accurately reproduce the propagation and reflection behavior of ultrasound
waves in the medium. Experimental results demonstrate that the UlRe-NeRF model
significantly enhances the realism and accuracy of high-fidelity ultrasound
image reconstruction, especially in handling complex medium structures.

ÊëòË¶ÅÔºö‰∏âÁ∂≠Ë∂ÖÈü≥Ê≥¢ÂΩ±ÂÉèÊòØ‰∏ÄÈ†ÖÂª£Ê≥õÁî®ÊñºÈÜ´ÁôÇË®∫Êñ∑ÁöÑÈáçË¶ÅÊäÄË°ì„ÄÇÁÑ∂ËÄåÔºåÂÇ≥Áµ±ÁöÑ 3D Ë∂ÖÈü≥Ê≥¢ÂΩ±ÂÉèÊñπÊ≥ïÊúâËß£ÊûêÂ∫¶Âõ∫ÂÆö„ÄÅÂÑ≤Â≠òÊïàÁéá‰Ωé„ÄÅËÑàÁµ°ÈÄ£Êé•ÊÄß‰∏çË∂≥Á≠âÈôêÂà∂ÔºåÂ∞éËá¥Âú®ËôïÁêÜË§áÈõúÁöÑÂÅΩÂΩ±ÂíåÂèçÂ∞ÑÁâπÊÄßÊôÇÊïàËÉΩ‰∏ç‰Ω≥„ÄÇÊúÄËøëÔºåÂü∫Êñº NeRFÔºàÁ•ûÁ∂ìËºªÁÖßÂ†¥ÔºâÁöÑÊäÄË°ìÂú®Ë¶ñÂúñÂêàÊàêÂíå 3D ÈáçÂª∫ÊñπÈù¢ÂèñÂæóÈáçÂ§ßÈÄ≤Â±ïÔºå‰ΩÜÈ´òÂìÅË≥™Ë∂ÖÈü≥Ê≥¢ÂΩ±ÂÉè‰ªçÂ≠òÂú®Á†îÁ©∂Á©∫ÁôΩ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞ÁöÑÊ®°Âûã UlRe-NeRFÔºåÂÆÉÂ∞áÈö±ÂºèÁ•ûÁ∂ìÁ∂≤Ë∑ØÂíåÊòéÁ¢∫ÁöÑË∂ÖÈü≥Ê≥¢È´îÁ©çÊ∏≤ÊüìÁµêÂêàÂà∞Ë∂ÖÈü≥Ê≥¢Á•ûÁ∂ìÊ∏≤ÊüìÊû∂Êßã‰∏≠„ÄÇÊ≠§Ê®°ÂûãÁµêÂêà‰∫ÜÂèçÂ∞ÑÊñπÂêëÂèÉÊï∏ÂåñÂíåË´ßÊ≥¢Á∑®Á¢ºÔºå‰ΩøÁî®ÊñπÂêëÊÄß MLP Ê®°ÁµÑ‰æÜÁî¢ÁîüË¶ñËßí‰æùË≥¥ÁöÑÈ´òÈ†ªÁéáÂèçÂ∞ÑÂº∑Â∫¶‰º∞Ë®àÔºå‰∏¶‰ΩøÁî®Á©∫Èñì MLP Ê®°ÁµÑ‰æÜÁî¢Áîü‰ªãË≥™ÁöÑÁâ©ÁêÜÂ±¨ÊÄßÂèÉÊï∏„ÄÇÈÄô‰∫õÂèÉÊï∏Áî®ÊñºÈ´îÁ©çÊ∏≤ÊüìÈÅéÁ®ã‰∏≠Ôºå‰ª•Ê∫ñÁ¢∫ÈáçÁèæË∂ÖÈü≥Ê≥¢Âú®‰ªãË≥™‰∏≠ÁöÑÂÇ≥Êí≠ÂíåÂèçÂ∞ÑË°åÁÇ∫„ÄÇÂØ¶È©óÁµêÊûúË≠âÊòéÔºåUlRe-NeRF Ê®°ÂûãÈ°ØËëóÊèêÂçá‰∫ÜÈ´ò‰øùÁúüË∂ÖÈü≥Ê≥¢ÂΩ±ÂÉèÈáçÂª∫ÁöÑÁúüÂØ¶ÊÄßÂíåÊ∫ñÁ¢∫ÊÄßÔºåÁâπÂà•ÊòØÂú®ËôïÁêÜË§áÈõú‰ªãË≥™ÁµêÊßãÊôÇ„ÄÇ

##### **Segment anything model 2: an application to 2D and 3D medical images**
2408.00756v2 by Haoyu Dong, Hanxue Gu, Yaqian Chen, Jichen Yang, Maciej A. Mazurowski

Segment Anything Model (SAM) has gained significant attention because of its
ability to segment varous objects in images given a prompt. The recently
developed SAM 2 has extended this ability to video inputs. This opens an
opportunity to apply SAM to 3D images, one of the fundamental tasks in the
medical imaging field. In this paper, we extensively evaluate SAM 2's ability
to segment both 2D and 3D medical images by first collecting 18 medical imaging
datasets, including common 3D modalities such as computed tomography (CT),
magnetic resonance imaging (MRI), and positron emission tomography (PET) as
well as 2D modalities such as X-ray and ultrasound. Two evaluation pipelines of
SAM 2 are considered: (1) multi-frame 3D segmentation, where prompts are
provided to one or multiple slice(s) selected from the volume, and (2)
single-frame 2D segmentation, where prompts are provided to each slice. The
former is only applicable to 3D modalities, while the latter applies to both 2D
and 3D modalities. Our results show that SAM 2 exhibits similar performance as
SAM under single-frame 2D segmentation, and has variable performance under
multi-frame 3D segmentation depending on the choices of slices to annotate, the
direction of the propagation, the predictions utilized during the propagation,
etc.

ÊëòË¶ÅÔºöÂàÜÊÆµ‰ªª‰ΩïÊ®°Âûã (SAM) Âõ†ÂÖ∂Ê†πÊìöÊèêÁ§∫ÂàÜÊÆµÂúñÂÉè‰∏≠ÁöÑ‰∏çÂêåÁâ©‰ª∂ÁöÑËÉΩÂäõËÄåÂèóÂà∞Âª£Ê≥õÈóúÊ≥®„ÄÇÊúÄËøëÈñãÁôºÁöÑ SAM 2 Â∑≤Â∞áÊ≠§ËÉΩÂäõÊì¥Â±ïÂà∞ÂΩ±ÁâáËº∏ÂÖ•„ÄÇÈÄôÁÇ∫Â∞á SAM ÊáâÁî®Êñº 3D ÂΩ±ÂÉèÈñãÂïü‰∫ÜÊ©üÊúÉÔºåÈÄôÊòØÈÜ´Â≠∏ÂΩ±ÂÉèÈ†òÂüüÁöÑÂü∫Êú¨‰ªªÂãô‰πã‰∏Ä„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂª£Ê≥õË©ï‰º∞‰∫Ü SAM 2 ÂàÜÊÆµ 2D Âíå 3D ÈÜ´Â≠∏ÂΩ±ÂÉèÁöÑËÉΩÂäõÔºåÈ¶ñÂÖàÊî∂ÈõÜ‰∫Ü 18 ÂÄãÈÜ´Â≠∏ÂΩ±ÂÉèË≥áÊñôÈõÜÔºåÂåÖÊã¨Â∏∏Ë¶ãÁöÑ 3D Ê®°ÂºèÔºå‰æãÂ¶ÇÈõªËÖ¶Êñ∑Â±§ÊéÉÊèè (CT)„ÄÅÁ£ÅÊåØÈÄ†ÂΩ± (MRI) ÂíåÊ≠£Â≠êÁôºÂ∞ÑÊñ∑Â±§ÊéÉÊèè (PET)Ôºå‰ª•Âèä 2D Ê®°ÂºèÔºå‰æãÂ¶Ç X Â∞ÑÁ∑öÂíåË∂ÖÈü≥Ê≥¢„ÄÇËÄÉÊÖÆ‰∫Ü SAM 2 ÁöÑÂÖ©ÂÄãË©ï‰º∞ÁÆ°ÈÅìÔºö(1) Â§öÂπÄ 3D ÂàÜÊÆµÔºåÂÖ∂‰∏≠ÊèêÁ§∫Êèê‰æõÁµ¶ÂæûÈ´îÁ©ç‰∏≠ÈÅ∏ÊìáÁöÑ‰∏ÄÂÄãÊàñÂ§öÂÄãÂàáÁâáÔºå‰ª•Âèä (2) ÂñÆÂπÄ 2D ÂàÜÊÆµÔºåÂÖ∂‰∏≠ÊèêÁ§∫Êèê‰æõÁµ¶ÊØèÂÄãÂàáÁâá„ÄÇÂâçËÄÖÂÉÖÈÅ©Áî®Êñº 3D Ê®°ÂºèÔºåËÄåÂæåËÄÖÈÅ©Áî®Êñº 2D Âíå 3D Ê®°Âºè„ÄÇÊàëÂÄëÁöÑÁµêÊûúË°®ÊòéÔºåSAM 2 Âú®ÂñÆÂπÄ 2D ÂàÜÊÆµ‰∏ãÁöÑË°®ÁèæËàá SAM È°û‰ººÔºå‰∏¶‰∏îÂú®Â§öÂπÄ 3D ÂàÜÊÆµ‰∏ãÁöÑË°®ÁèæÊúÉÊ†πÊìöË¶ÅÊ®ôË®ªÁöÑÂàáÁâáÈÅ∏Êìá„ÄÅÂÇ≥Êí≠ÊñπÂêë„ÄÅÂÇ≥Êí≠ÊúüÈñì‰ΩøÁî®ÁöÑÈ†êÊ∏¨Á≠âËÄåÊúâÊâÄ‰∏çÂêå„ÄÇ

##### **Leaf Angle Estimation using Mask R-CNN and LETR Vision Transformer**
2408.00749v1 by Venkat Margapuri, Prapti Thapaliya, Trevor Rife

Modern day studies show a high degree of correlation between high yielding
crop varieties and plants with upright leaf angles. It is observed that plants
with upright leaf angles intercept more light than those without upright leaf
angles, leading to a higher rate of photosynthesis. Plant scientists and
breeders benefit from tools that can directly measure plant parameters in the
field i.e. on-site phenotyping. The estimation of leaf angles by manual means
in a field setting is tedious and cumbersome. We mitigate the tedium using a
combination of the Mask R-CNN instance segmentation neural network, and Line
Segment Transformer (LETR), a vision transformer. The proposed Computer Vision
(CV) pipeline is applied on two image datasets, Summer 2015-Ames ULA and Summer
2015- Ames MLA, with a combined total of 1,827 plant images collected in the
field using FieldBook, an Android application aimed at on-site phenotyping. The
leaf angles estimated by the proposed pipeline on the image datasets are
compared to two independent manual measurements using ImageJ, a Java-based
image processing program developed at the National Institutes of Health and the
Laboratory for Optical and Computational Instrumentation. The results, when
compared for similarity using the Cosine Similarity measure, exhibit 0.98
similarity scores on both independent measurements of Summer 2015-Ames ULA and
Summer 2015-Ames MLA image datasets, demonstrating the feasibility of the
proposed pipeline for on-site measurement of leaf angles.

ÊëòË¶ÅÔºö<paragraph>Áèæ‰ª£Á†îÁ©∂È°ØÁ§∫ÔºåÈ´òÁî¢Èáè‰ΩúÁâ©ÂìÅÁ®ÆÂíåËëâÁâáËßíÂ∫¶Áõ¥Á´ãÁöÑÊ§çÁâ©‰πãÈñìÊúâÈ´òÂ∫¶Áõ∏ÈóúÊÄß„ÄÇËßÄÂØüÂà∞ËëâÁâáËßíÂ∫¶Áõ¥Á´ãÁöÑÊ§çÁâ©ÊØîËëâÁâáËßíÂ∫¶‰∏çÁõ¥Á´ãÁöÑÊ§çÁâ©ÊîîÊà™Êõ¥Â§öÂÖâÁ∑öÔºåÂæûËÄåÂ∞éËá¥Êõ¥È´òÁöÑÂÖâÂêà‰ΩúÁî®ÈÄüÁéá„ÄÇÊ§çÁâ©ÁßëÂ≠∏ÂÆ∂ÂíåËÇ≤Á®ÆËÄÖÂèóÁõäÊñºÂèØ‰ª•Âú®Áî∞ÈñìÁõ¥Êé•Ê∏¨ÈáèÊ§çÁâ©ÂèÉÊï∏ÁöÑÂ∑•ÂÖ∑ÔºåÂç≥ÁèæÂ†¥Ë°®ÂûãÂàÜÊûê„ÄÇÂú®Áî∞ÈñìÁí∞Â¢É‰∏≠ÈÄöÈÅéÊâãÂãïÊñπÂºè‰º∞Ë®àËëâÁâáËßíÂ∫¶Êó¢ÁπÅÁë£ÂèàÈ∫ªÁÖ©„ÄÇÊàëÂÄë‰ΩøÁî® Mask R-CNN ÂØ¶‰æãÂàÜÂâ≤Á•ûÁ∂ìÁ∂≤Ë∑ØÂíåÁ∑öÊÆµTransformer (LETR)Ôºà‰∏ÄÁ®ÆË¶ñË¶∫TransformerÔºâÁöÑÁµÑÂêà‰æÜÊ∏õËºïÁπÅÁë£ÊÄß„ÄÇÊâÄÊèêÂá∫ÁöÑË®àÁÆóÊ©üË¶ñË¶∫ (CV) ÁÆ°Á∑öÊáâÁî®ÊñºÂÖ©ÂÄãÂúñÂÉèË≥áÊñôÈõÜÔºåSummer 2015-Ames ULA Âíå Summer 2015- Ames MLAÔºåÁ∏ΩÂÖ±ÂåÖÂê´ 1,827 ÂºµÊ§çÁâ©ÂúñÂÉèÔºåÈÄô‰∫õÂúñÂÉèÊòØÂú®Áî∞Èñì‰ΩøÁî® FieldBookÔºà‰∏ÄÁ®ÆÈáùÂ∞çÁèæÂ†¥Ë°®ÂûãÂàÜÊûêÁöÑ Android ÊáâÁî®Á®ãÂºèÔºâÊî∂ÈõÜÁöÑ„ÄÇ‰ΩøÁî®ÊâÄÊèêÂá∫ÁöÑÁÆ°Á∑ö‰º∞Ë®àÁöÑÂúñÂÉèË≥áÊñôÈõÜ‰∏äÁöÑËëâÁâáËßíÂ∫¶Ëàá‰ΩøÁî® ImageJÔºà‰∏ÄÁ®ÆÁî±ÁæéÂúãÂúãÂÆ∂Ë°õÁîüÁ†îÁ©∂Èô¢ÂíåÂÖâÂ≠∏ÂíåË®àÁÆóÂÑÄÂô®ÂØ¶È©óÂÆ§ÈñãÁôºÁöÑÂü∫Êñº Java ÁöÑÂΩ±ÂÉèËôïÁêÜÁ®ãÂºèÔºâÈÄ≤Ë°åÁöÑÂÖ©Ê¨°Áç®Á´ãÊâãÂãïÊ∏¨ÈáèÈÄ≤Ë°åÊØîËºÉ„ÄÇÂ∞áÁµêÊûú‰ΩøÁî®È§òÂº¶Áõ∏‰ººÂ∫¶Ê∏¨ÈáèÈÄ≤Ë°åÁõ∏‰ººÊÄßÊØîËºÉÊôÇÔºåÂú® Summer 2015-Ames ULA Âíå Summer 2015-Ames MLA ÂΩ±ÂÉèË≥áÊñôÈõÜÁöÑÂÖ©Ê¨°Áç®Á´ãÊ∏¨Èáè‰∏≠ÈÉΩÈ°ØÁ§∫Âá∫ 0.98 ÁöÑÁõ∏‰ººÂ∫¶ÂàÜÊï∏ÔºåË≠âÊòé‰∫ÜÊâÄÊèêÂá∫ÁöÑÁÆ°Á∑öÁî®ÊñºÁèæÂ†¥Ê∏¨ÈáèËëâÁâáËßíÂ∫¶ÁöÑÂèØË°åÊÄß„ÄÇ</paragraph>

##### **Improving Retrieval-Augmented Generation in Medicine with Iterative Follow-up Questions**
2408.00727v1 by Guangzhi Xiong, Qiao Jin, Xiao Wang, Minjia Zhang, Zhiyong Lu, Aidong Zhang

The emergent abilities of large language models (LLMs) have demonstrated
great potential in solving medical questions. They can possess considerable
medical knowledge, but may still hallucinate and are inflexible in the
knowledge updates. While Retrieval-Augmented Generation (RAG) has been proposed
to enhance the medical question-answering capabilities of LLMs with external
knowledge bases, it may still fail in complex cases where multiple rounds of
information-seeking are required. To address such an issue, we propose
iterative RAG for medicine (i-MedRAG), where LLMs can iteratively ask follow-up
queries based on previous information-seeking attempts. In each iteration of
i-MedRAG, the follow-up queries will be answered by a vanilla RAG system and
they will be further used to guide the query generation in the next iteration.
Our experiments show the improved performance of various LLMs brought by
i-MedRAG compared with vanilla RAG on complex questions from clinical vignettes
in the United States Medical Licensing Examination (USMLE), as well as various
knowledge tests in the Massive Multitask Language Understanding (MMLU) dataset.
Notably, our zero-shot i-MedRAG outperforms all existing prompt engineering and
fine-tuning methods on GPT-3.5, achieving an accuracy of 69.68\% on the MedQA
dataset. In addition, we characterize the scaling properties of i-MedRAG with
different iterations of follow-up queries and different numbers of queries per
iteration. Our case studies show that i-MedRAG can flexibly ask follow-up
queries to form reasoning chains, providing an in-depth analysis of medical
questions. To the best of our knowledge, this is the first-of-its-kind study on
incorporating follow-up queries into medical RAG.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâÁöÑÊñ∞ËààËÉΩÂäõÂ∑≤Ë≠âÊòéÂú®Ëß£Ê±∫ÈÜ´ÁôÇÂïèÈ°åÊñπÈù¢ÂÖ∑ÊúâÂ∑®Â§ßÊΩõÂäõ„ÄÇÂÆÉÂÄëÂèØËÉΩÊìÅÊúâÂ§ßÈáèÁöÑÈÜ´ÁôÇÁü•Ë≠òÔºå‰ΩÜ‰ªçÂèØËÉΩÁî¢ÁîüÂπªË¶∫Ôºå‰∏¶‰∏îÂú®Áü•Ë≠òÊõ¥Êñ∞ÊñπÈù¢Áº∫‰πèÈùàÊ¥ªÊÄß„ÄÇÈõñÁÑ∂Â∑≤ÊèêÂá∫Ê™¢Á¥¢Â¢ûÂº∑ÁîüÊàêÔºàRAGÔºâ‰ª•Âà©Áî®Â§ñÈÉ®Áü•Ë≠òÂ∫´Â¢ûÂº∑ LLM ÁöÑÈÜ´ÁôÇÂïèÈ°åËß£Á≠îËÉΩÂäõÔºå‰ΩÜÂú®ÈúÄË¶ÅÂ§öËº™‰ø°ÊÅØÊ™¢Á¥¢ÁöÑË§áÈõúÊÉÖÊ≥Å‰∏ãÔºåÂÆÉ‰ªçÂèØËÉΩÂ§±Êïó„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∫ÜÁî®ÊñºÈÜ´ÁôÇÁöÑËø≠‰ª£ RAGÔºài-MedRAGÔºâÔºåÂÖ∂‰∏≠ LLM ÂèØ‰ª•Ê†πÊìöÂÖàÂâçÁöÑ‰ø°ÊÅØÊ™¢Á¥¢ÂòóË©¶ÂèçË¶ÜË©¢ÂïèÂæåÁ∫åÊü•Ë©¢„ÄÇÂú® i-MedRAG ÁöÑÊØèÊ¨°Ëø≠‰ª£‰∏≠ÔºåÂæåÁ∫åÊü•Ë©¢Â∞áÁî±Âü∫Êú¨ÁöÑ RAG Á≥ªÁµ±ÂõûÁ≠îÔºå‰∏¶‰∏îÂÆÉÂÄëÂ∞áÈÄ≤‰∏ÄÊ≠•Áî®ÊñºÊåáÂ∞é‰∏ã‰∏ÄÊ¨°Ëø≠‰ª£‰∏≠ÁöÑÊü•Ë©¢ÁîüÊàê„ÄÇÊàëÂÄëÁöÑÂØ¶È©óË°®ÊòéÔºåËàáÁæéÂúãÈÜ´Â≠∏Âü∑ÁÖßËÄÉË©¶ÔºàUSMLEÔºâ‰∏≠Ëá®Â∫äÂ∞èÊèíÂúñ‰∏≠ÁöÑË§áÈõúÂïèÈ°å‰ª•Âèä Massive Multitask Language UnderstandingÔºàMMLUÔºâÊï∏ÊìöÈõÜ‰∏≠ÂêÑÁ®ÆÁü•Ë≠òÊ∏¨Ë©¶‰∏≠ÁöÑÂü∫Êú¨ RAG Áõ∏ÊØîÔºåi-MedRAG Â∏∂‰æÜÁöÑÂêÑÁ®Æ LLM ÁöÑÊîπÈÄ≤ÊÄßËÉΩ„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÊàëÂÄëÁöÑÈõ∂Ê¨°Â≠∏Áøí i-MedRAG Âú® GPT-3.5 ‰∏äÂÑ™ÊñºÊâÄÊúâÁèæÊúâÁöÑÊèêÁ§∫Â∑•Á®ãÂíåÂæÆË™øÊñπÊ≥ïÔºåÂú® MedQA Êï∏ÊìöÈõÜ‰∏äÈÅîÂà∞‰∫Ü 69.68% ÁöÑÊ∫ñÁ¢∫Áéá„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèèËø∞‰∫Ü i-MedRAG ÁöÑÊì¥Â±ïÂ±¨ÊÄßÔºåÂåÖÊã¨‰∏çÂêåÁöÑÂæåÁ∫åÊü•Ë©¢Ëø≠‰ª£ÂíåÊØèÂÄãËø≠‰ª£ÁöÑ‰∏çÂêåÊü•Ë©¢Êï∏Èáè„ÄÇÊàëÂÄëÁöÑÊ°à‰æãÁ†îÁ©∂Ë°®ÊòéÔºåi-MedRAG ÂèØ‰ª•ÈùàÊ¥ªÂú∞Ë©¢ÂïèÂæåÁ∫åÊü•Ë©¢‰ª•ÂΩ¢ÊàêÊé®ÁêÜÈèàÔºåÂæûËÄåÂ∞çÈÜ´ÁôÇÂïèÈ°åÈÄ≤Ë°åÊ∑±ÂÖ•ÂàÜÊûê„ÄÇÊìöÊàëÂÄëÊâÄÁü•ÔºåÈÄôÊòØÁ¨¨‰∏ÄÂÄãÂ∞áÂæåÁ∫åÊü•Ë©¢Á¥çÂÖ•ÈÜ´ÁôÇ RAG ÁöÑÂêåÈ°ûÁ†îÁ©∂„ÄÇ

##### **Point-supervised Brain Tumor Segmentation with Box-prompted MedSAM**
2408.00706v1 by Xiaofeng Liu, Jonghye Woo, Chao Ma, Jinsong Ouyang, Georges El Fakhri

Delineating lesions and anatomical structure is important for image-guided
interventions. Point-supervised medical image segmentation (PSS) has great
potential to alleviate costly expert delineation labeling. However, due to the
lack of precise size and boundary guidance, the effectiveness of PSS often
falls short of expectations. Although recent vision foundational models, such
as the medical segment anything model (MedSAM), have made significant
advancements in bounding-box-prompted segmentation, it is not straightforward
to utilize point annotation, and is prone to semantic ambiguity. In this
preliminary study, we introduce an iterative framework to facilitate
semantic-aware point-supervised MedSAM. Specifically, the semantic box-prompt
generator (SBPG) module has the capacity to convert the point input into
potential pseudo bounding box suggestions, which are explicitly refined by the
prototype-based semantic similarity. This is then succeeded by a prompt-guided
spatial refinement (PGSR) module that harnesses the exceptional
generalizability of MedSAM to infer the segmentation mask, which also updates
the box proposal seed in SBPG. Performance can be progressively improved with
adequate iterations. We conducted an evaluation on BraTS2018 for the
segmentation of whole brain tumors and demonstrated its superior performance
compared to traditional PSS methods and on par with box-supervised methods.

ÊëòË¶ÅÔºöÊèèÁπ™ÁóÖÁÅ∂ÂíåËß£ÂâñÁµêÊßãÂ∞çÊñºÂΩ±ÂÉèÂ∞éÂºï‰ªãÂÖ•ÈùûÂ∏∏ÈáçË¶Å„ÄÇÈªûÁõ£Áù£ÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÂâ≤ÔºàPSSÔºâÂÖ∑ÊúâÊ∏õËºïÊòÇË≤¥ÁöÑÂ∞àÂÆ∂ÊèèÁπ™Ê®ôÁ±§ÁöÑÂ∑®Â§ßÊΩõÂäõ„ÄÇÁÑ∂ËÄåÔºåÁî±ÊñºÁº∫‰πèÁ≤æÁ¢∫ÁöÑÂ§ßÂ∞èÂíåÈÇäÁïåÂºïÂ∞éÔºåPSS ÁöÑÊúâÊïàÊÄßÈÄöÂ∏∏‰ΩéÊñºÈ†êÊúü„ÄÇÂÑòÁÆ°ÊúÄËøëÁöÑË¶ñË¶∫Âü∫Á§éÊ®°ÂûãÔºå‰æãÂ¶ÇÈÜ´Â≠∏ÂàÜÂâ≤‰ªª‰ΩïÊ®°ÂûãÔºàMedSAMÔºâÔºåÂú®ÈÇäÁïåÊ°ÜÊèêÁ§∫ÂàÜÂâ≤ÊñπÈù¢ÂèñÂæó‰∫ÜÈáçÂ§ßÈÄ≤Â±ïÔºå‰ΩÜÂà©Áî®ÈªûË®ªÈáã‰∏¶‰∏çÂÆπÊòìÔºåËÄå‰∏îÂÆπÊòìÁî¢ÁîüË™ûÁæ©Ê≠ßÁæ©„ÄÇÂú®ÈÄôÈ†ÖÂàùÊ≠•Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÂÄãËø≠‰ª£Ê°ÜÊû∂‰æÜ‰øÉÈÄ≤Ë™ûÁæ©ÊÑüÁü•ÈªûÁõ£Áù£ MedSAM„ÄÇÂÖ∑È´î‰æÜË™™ÔºåË™ûÁæ©Ê°ÜÊèêÁ§∫ÁîüÊàêÂô®ÔºàSBPGÔºâÊ®°ÁµÑËÉΩÂ§†Â∞áÈªûËº∏ÂÖ•ËΩâÊèõÁÇ∫ÊΩõÂú®ÁöÑÂÅΩÈÇäÁïåÊ°ÜÂª∫Ë≠∞ÔºåÈÄô‰∫õÂª∫Ë≠∞Áî±Âü∫ÊñºÂéüÂûãÁöÑË™ûÁæ©Áõ∏‰ººÊÄßÊòéÁ¢∫Á¥∞Âåñ„ÄÇÁÑ∂ÂæåÔºåÁî±ÊèêÁ§∫ÂºïÂ∞éÁöÑÁ©∫ÈñìÁ¥∞ÂåñÔºàPGSRÔºâÊ®°ÁµÑÁπºÊâøÔºåÂÆÉÂà©Áî® MedSAM ÁöÑÂá∫Ëâ≤ÂèØÊ¶ÇÂåñÊÄß‰æÜÊé®Êñ∑ÂàÜÂâ≤ËíôÁâàÔºåÈÄô‰πüÊúÉÊõ¥Êñ∞ SBPG ‰∏≠ÁöÑÊ°ÜÂª∫Ë≠∞Á®ÆÂ≠ê„ÄÇÈÄöÈÅéÂÖÖÂàÜÁöÑËø≠‰ª£ÂèØ‰ª•ÈÄêÊ≠•ÊèêÈ´òÊÄßËÉΩ„ÄÇÊàëÂÄëÂ∞ç BraTS2018 ÈÄ≤Ë°å‰∫ÜÂÖ®ËÖ¶ËÖ´Áò§ÂàÜÂâ≤Ë©ï‰º∞Ôºå‰∏¶Ë≠âÊòéÂÖ∂ÊÄßËÉΩÂÑ™ÊñºÂÇ≥Áµ±ÁöÑ PSS ÊñπÊ≥ïÔºå‰∏¶‰∏îËàáÊ°ÜÁõ£Áù£ÊñπÊ≥ïÁõ∏Áï∂„ÄÇ

##### **HBot: A Chatbot for Healthcare Applications in Traditional Chinese Medicine Based on Human Body 3D Visualization**
2408.00481v1 by Bolin Zhang, Zhiwei Yi, Jiahao Wang, Dianbo Sui, Zhiying Tu, Dianhui Chu

The unique diagnosis and treatment techniques and remarkable clinical
efficacy of traditional Chinese medicine (TCM) make it play an important role
in the field of elderly care and healthcare, especially in the rehabilitation
of some common chronic diseases of the elderly. Therefore, building a TCM
chatbot for healthcare application will help users obtain consultation services
in a direct and natural way. However, concepts such as acupuncture points
(acupoints) and meridians involved in TCM always appear in the consultation,
which cannot be displayed intuitively. To this end, we develop a
\textbf{h}ealthcare chat\textbf{bot} (HBot) based on a human body model in 3D
and knowledge graph, which provides conversational services such as knowledge
Q\&A, prescription recommendation, moxibustion therapy recommendation, and
acupoint search. When specific acupoints are involved in the conversations
between user and HBot, the 3D body will jump to the corresponding acupoints and
highlight them. Moreover, Hbot can also be used in training scenarios to
accelerate the teaching process of TCM by intuitively displaying acupuncture
points and knowledge cards. The demonstration video is available at
https://www.youtube.com/watch?v=UhQhutSKkTU . Our code and dataset are publicly
available at Gitee: https://gitee.com/plabrolin/interactive-3d-acup.git

ÊëòË¶ÅÔºö‰∏≠ÈÜ´Áç®ÁâπÁöÑË®∫Ê≤ªÊâãÊ≥ïÂíåÈ°ØËëóÁöÑËá®Â∫äÁôÇÊïàÔºåÂú®ËÄÅÂπ¥ÁÖßË≠∑Ëàá‰øùÂÅ•È†òÂüü‰∏≠ÊâÆÊºîËëóÈáçË¶ÅÁöÑËßíËâ≤ÔºåÁâπÂà•ÊòØÂú®ËÄÅÂπ¥‰∫∫Â∏∏Ë¶ãÊÖ¢ÊÄßÁñæÁóÖÁöÑÂæ©ÂÅ•‰∏ä„ÄÇÂõ†Ê≠§ÔºåÂª∫Êßã‰∏ÄÂÄã‰∏≠ÈÜ´ÈÜ´ÁôÇÁÖßË≠∑ËÅäÂ§©Ê©üÂô®‰∫∫ÔºåÂ∞áÊúâÂä©Êñº‰ΩøÁî®ËÄÖ‰ª•Áõ¥Êé•‰∏îËá™ÁÑ∂ÁöÑÊñπÂºèÂèñÂæóË´ÆË©¢ÊúçÂãô„ÄÇÁÑ∂ËÄåÔºå‰∏≠ÈÜ´ÊâÄÊ∂âÂèäÁöÑÁ©¥‰Ωç„ÄÅÁ∂ìÁµ°Á≠âÊ¶ÇÂøµÔºåÂú®Ë´ÆË©¢ÊôÇÁ∏ΩÊòØÊúÉÂá∫ÁèæÔºåËÄåÈÄô‰∫õÁÑ°Ê≥ïÁõ¥ËßÄÂú∞È°ØÁ§∫Âá∫‰æÜ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÈñãÁôº‰∫Ü‰∏ÄÂÄãÂü∫Êñº 3D ‰∫∫È´îÊ®°ÂûãÂíåÁü•Ë≠òÂúñË≠úÁöÑÈÜ´ÁôÇÁÖßË≠∑ËÅäÂ§©Ê©üÂô®‰∫∫ÔºàHBotÔºâÔºåÂÆÉÊèê‰æõ‰∫ÜÁü•Ë≠òÂïèÁ≠î„ÄÅËôïÊñπÊé®Ëñ¶„ÄÅËâæÁÅ∏ÁôÇÊ≥ïÊé®Ëñ¶ÂíåÁ©¥‰ΩçÊü•Ë©¢Á≠âÂ∞çË©±ÊúçÂãô„ÄÇÁï∂‰ΩøÁî®ËÄÖËàá HBot ÁöÑÂ∞çË©±‰∏≠Ê∂âÂèäÂà∞ÂÖ∑È´îÁ©¥‰ΩçÊôÇÔºå3D ‰∫∫È´îÊúÉË∑≥ËΩâÂà∞Â∞çÊáâÁöÑÁ©¥‰Ωç‰∏¶Â∞áÂÖ∂È´ò‰∫ÆÈ°ØÁ§∫„ÄÇÊ≠§Â§ñÔºåHBot ÈÇÑÂèØ‰ª•Áî®ÊñºÂüπË®ìÂ†¥ÊôØ‰∏≠ÔºåÈÄöÈÅéÁõ¥ËßÄÂú∞È°ØÁ§∫Á©¥‰ΩçÂíåÁü•Ë≠òÂç°ÁâáÔºå‰æÜÂä†ÈÄü‰∏≠ÈÜ´ÊïôÂ≠∏ÁöÑÈÄ≤Á®ã„ÄÇÁ§∫ÁØÑÂΩ±ÁâáÂèØÊñº https://www.youtube.com/watch?v=UhQhutSKkTU ÂèñÂæó„ÄÇÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÂíåË≥áÊñôÈõÜÂ∑≤Êñº Gitee ÂÖ¨ÈñãÔºöhttps://gitee.com/plabrolin/interactive-3d-acup.git

##### **Securing the Diagnosis of Medical Imaging: An In-depth Analysis of AI-Resistant Attacks**
2408.00348v1 by Angona Biswas, MD Abdullah Al Nasim, Kishor Datta Gupta, Roy George, Abdur Rashid

Machine learning (ML) is a rapidly developing area of medicine that uses
significant resources to apply computer science and statistics to medical
issues. ML's proponents laud its capacity to handle vast, complicated, and
erratic medical data. It's common knowledge that attackers might cause
misclassification by deliberately creating inputs for machine learning
classifiers. Research on adversarial examples has been extensively conducted in
the field of computer vision applications. Healthcare systems are thought to be
highly difficult because of the security and life-or-death considerations they
include, and performance accuracy is very important. Recent arguments have
suggested that adversarial attacks could be made against medical image analysis
(MedIA) technologies because of the accompanying technology infrastructure and
powerful financial incentives. Since the diagnosis will be the basis for
important decisions, it is essential to assess how strong medical DNN tasks are
against adversarial attacks. Simple adversarial attacks have been taken into
account in several earlier studies. However, DNNs are susceptible to more risky
and realistic attacks. The present paper covers recent proposed adversarial
attack strategies against DNNs for medical imaging as well as countermeasures.
In this study, we review current techniques for adversarial imaging attacks,
detections. It also encompasses various facets of these techniques and offers
suggestions for the robustness of neural networks to be improved in the future.

ÊëòË¶ÅÔºöÊ©üÂô®Â≠∏Áøí (ML) ÊòØÈÜ´Â≠∏È†òÂüü‰∏≠Âø´ÈÄüÁôºÂ±ïÁöÑ‰∏ÄÂÄãÈ†òÂüüÔºåÂÆÉÂà©Áî®Â§ßÈáèÁöÑË≥áÊ∫êÂ∞áÈõªËÖ¶ÁßëÂ≠∏ÂíåÁµ±Ë®àÂ≠∏ÊáâÁî®ÊñºÈÜ´ÁôÇÂïèÈ°å„ÄÇML ÁöÑÊîØÊåÅËÄÖËÆöÊèöÂÆÉËôïÁêÜÂ§ßÈáè„ÄÅË§áÈõú‰∏î‰∏çË¶èÂâáÈÜ´ÁôÇË≥áÊñôÁöÑËÉΩÂäõ„ÄÇÁúæÊâÄÂë®Áü•ÔºåÊîªÊìäËÄÖÂèØËÉΩÊúÉÈÄèÈÅéÊïÖÊÑèÁÇ∫Ê©üÂô®Â≠∏ÁøíÂàÜÈ°ûÂô®Âª∫Á´ãËº∏ÂÖ•‰æÜÂ∞éËá¥ÈåØË™§ÂàÜÈ°û„ÄÇÂ∞çÊäóÁØÑ‰æãÁöÑÁ†îÁ©∂Â∑≤Âú®ÈõªËÖ¶Ë¶ñË¶∫ÊáâÁî®È†òÂüü‰∏≠Âª£Ê≥õÈÄ≤Ë°å„ÄÇÈÜ´ÁôÇ‰øùÂÅ•Á≥ªÁµ±Ë¢´Ë™çÁÇ∫ÈùûÂ∏∏Âõ∞Èõ£ÔºåÂõ†ÁÇ∫ÂÆÉÂÄëÂåÖÂê´ÂÆâÂÖ®ÊÄßÂèäÁîüÊ≠ªÊî∏ÈóúÁöÑËÄÉÈáèÔºå‰∏îÊïàËÉΩÊ∫ñÁ¢∫ÊÄßÈùûÂ∏∏ÈáçË¶Å„ÄÇÊúÄËøëÁöÑË´ñÈªûË°®ÊòéÔºåÁî±Êñº‰º¥Èö®ËÄå‰æÜÁöÑÊäÄË°ìÂü∫Á§éË®≠ÊñΩÂíåÂº∑Â§ßÁöÑË≤°ÂãôË™òÂõ†ÔºåÂ∞çÊäóÊîªÊìäÂèØËÉΩÊúÉÈáùÂ∞çÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÊûê (MedIA) ÊäÄË°ìÈÄ≤Ë°å„ÄÇÁî±ÊñºË®∫Êñ∑Â∞áÊàêÁÇ∫ÈáçË¶ÅÊ±∫Á≠ñÁöÑÂü∫Á§éÔºåÂõ†Ê≠§Ë©ï‰º∞ÈÜ´ÁôÇ DNN ‰ªªÂãôÂ∞çÊäóÊîªÊìäÁöÑÂº∑Âº±ÈùûÂ∏∏ÈáçË¶Å„ÄÇÂú®ÂÖàÂâçÁöÑÂ§öÈ†ÖÁ†îÁ©∂‰∏≠Â∑≤ËÄÉÊÖÆ‰∫ÜÁ∞°ÂñÆÁöÑÂ∞çÊäóÊîªÊìä„ÄÇÁÑ∂ËÄåÔºåDNN ÂÆπÊòìÂèóÂà∞È¢®Èö™Êõ¥È´ò‰∏îÊõ¥ÈÄºÁúüÁöÑÊîªÊìä„ÄÇÊú¨ÊñáÊ∂µËìã‰∫ÜÈáùÂ∞çÁî®ÊñºÈÜ´Â≠∏ÂΩ±ÂÉèÁöÑ DNN ÊâÄÊèêÂá∫ÁöÑÊúÄÊñ∞Â∞çÊäóÊîªÊìäÁ≠ñÁï•‰ª•ÂèäÂ∞çÁ≠ñ„ÄÇÂú®Êú¨Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëÂõûÈ°ß‰∫ÜÁï∂ÂâçÂ∞çÊäóÂΩ±ÂÉèÊîªÊìäÁöÑÊäÄË°ìÂíåÊ™¢Ê∏¨ÊñπÊ≥ï„ÄÇÂÆÉÈÇÑÂåÖÂê´‰∫ÜÈÄô‰∫õÊäÄË°ìÁöÑÂêÑÂÄãÊñπÈù¢Ôºå‰∏¶Êèê‰æõ‰∫ÜÊîπÈÄ≤Á•ûÁ∂ìÁ∂≤Ë∑ØÂú®Êú™‰æÜÂº∑ÂÅ•ÊÄßÁöÑÂª∫Ë≠∞„ÄÇ

##### **Advancing Medical Image Segmentation: Morphology-Driven Learning with Diffusion Transformer**
2408.00347v1 by Sungmin Kang, Jaeha Song, Jihie Kim

Understanding the morphological structure of medical images and precisely
segmenting the region of interest or abnormality is an important task that can
assist in diagnosis. However, the unique properties of medical imaging make
clear segmentation difficult, and the high cost and time-consuming task of
labeling leads to a coarse-grained representation of ground truth. Facing with
these problems, we propose a novel Diffusion Transformer Segmentation (DTS)
model for robust segmentation in the presence of noise. We propose an
alternative to the dominant Denoising U-Net encoder through experiments
applying a transformer architecture, which captures global dependency through
self-attention. Additionally, we propose k-neighbor label smoothing, reverse
boundary attention, and self-supervised learning with morphology-driven
learning to improve the ability to identify complex structures. Our model,
which analyzes the morphological representation of images, shows better results
than the previous models in various medical imaging modalities, including CT,
MRI, and lesion images.

ÊëòË¶ÅÔºö‰∫ÜËß£ÈÜ´Â≠∏ÂΩ±ÂÉèÁöÑÂΩ¢ÊÖãÁµêÊßã‰∏¶Á≤æÁ¢∫ÂàÜÂâ≤ÊÑüËààË∂£ÊàñÁï∞Â∏∏ÂçÄÂüüÊòØ‰∏ÄÈ†ÖÈáçË¶ÅÁöÑ‰ªªÂãôÔºåÊúâÂä©ÊñºË®∫Êñ∑„ÄÇÁÑ∂ËÄåÔºåÈÜ´Â≠∏ÂΩ±ÂÉèÁöÑÁç®ÁâπÂ±¨ÊÄß‰ΩøÂæóÊ∏ÖÊô∞ÁöÑÂàÜÂâ≤ËÆäÂæóÂõ∞Èõ£ÔºåËÄåÊ®ôÁ±§ÁöÑÈ´òÊàêÊú¨ÂíåËÄóÊôÇ‰ªªÂãôÂ∞éËá¥‰∫ÜÂú∞Èù¢ÂØ¶Ê≥ÅÁöÑÁ≤óÁï•Ë°®Á§∫„ÄÇÈù¢Â∞çÈÄô‰∫õÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊñ∞ÁöÑÊì¥Êï£TransformerÂàÜÂâ≤ÔºàDTSÔºâÊ®°ÂûãÔºåÁî®ÊñºÂú®ÊúâÂô™ËÅ≤ÁöÑÊÉÖÊ≥Å‰∏ãÈÄ≤Ë°åÁ©©ÂÅ•ÂàÜÂâ≤„ÄÇÊàëÂÄëÈÄöÈÅéÊáâÁî®ÊçïÁç≤ÂÖ®Â±Ä‰æùË≥¥ÊÄßÁöÑËá™Ê≥®ÊÑèÂäõTransformerÊû∂ÊßãÔºåÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊõø‰ª£‰∏ªÊµÅÂéªÂô™ U-Net Á∑®Á¢ºÂô®ÁöÑÊñπÊ°à„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèêÂá∫‰∫Ü k ËøëÈÑ∞Ê®ôÁ±§Âπ≥Êªë„ÄÅÂèçÂêëÈÇäÁïåÊ≥®ÊÑèÂäõÔºå‰ª•Âèä‰ΩøÁî®ÂΩ¢ÊÖãÈ©ÖÂãïÂ≠∏ÁøíÁöÑËá™Áõ£Áù£Â≠∏ÁøíÔºå‰ª•ÊèêÈ´òË≠òÂà•Ë§áÈõúÁµêÊßãÁöÑËÉΩÂäõ„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÂàÜÊûê‰∫ÜÂΩ±ÂÉèÁöÑÂΩ¢ÊÖãË°®Á§∫ÔºåÂú®ÂêÑÁ®ÆÈÜ´Â≠∏ÂΩ±ÂÉèÊñπÂºè‰∏≠È°ØÁ§∫Âá∫ÊØî‰ª•ÂâçÊ®°ÂûãÊõ¥Â•ΩÁöÑÁµêÊûúÔºåÂåÖÊã¨ CT„ÄÅMRI ÂíåÁóÖÁÅ∂ÂΩ±ÂÉè„ÄÇ

##### **S-SYNTH: Knowledge-Based, Synthetic Generation of Skin Images**
2408.00191v1 by Andrea Kim, Niloufar Saharkhiz, Elena Sizikova, Miguel Lago, Berkman Sahiner, Jana Delfino, Aldo Badano

Development of artificial intelligence (AI) techniques in medical imaging
requires access to large-scale and diverse datasets for training and
evaluation. In dermatology, obtaining such datasets remains challenging due to
significant variations in patient populations, illumination conditions, and
acquisition system characteristics. In this work, we propose S-SYNTH, the first
knowledge-based, adaptable open-source skin simulation framework to rapidly
generate synthetic skin, 3D models and digitally rendered images, using an
anatomically inspired multi-layer, multi-component skin and growing lesion
model. The skin model allows for controlled variation in skin appearance, such
as skin color, presence of hair, lesion shape, and blood fraction among other
parameters. We use this framework to study the effect of possible variations on
the development and evaluation of AI models for skin lesion segmentation, and
show that results obtained using synthetic data follow similar comparative
trends as real dermatologic images, while mitigating biases and limitations
from existing datasets including small dataset size, lack of diversity, and
underrepresentation.

ÊëòË¶ÅÔºö‰∫∫Â∑•Êô∫ÊÖß (AI) ÊäÄË°ìÂú®ÈÜ´Â≠∏ÂΩ±ÂÉèÊñπÈù¢ÁöÑÁôºÂ±ïÈúÄË¶ÅÂèñÂæóÂ§ßË¶èÊ®°‰∏îÂ§öÂÖÉÁöÑË≥áÊñôÈõÜÔºå‰ª•ÈÄ≤Ë°åË®ìÁ∑¥ÂíåË©ï‰º∞„ÄÇÂú®ÁöÆËÜöÁßë‰∏≠ÔºåÂèñÂæóÊ≠§È°ûË≥áÊñôÈõÜ‰ªçÁÑ∂ÂÖ∑ÊúâÊåëÊà∞ÊÄßÔºåÂéüÂõ†Âú®ÊñºÊÇ£ËÄÖÊóèÁæ§„ÄÅÁÖßÊòéÊ¢ù‰ª∂ÂíåÂèñÂæóÁ≥ªÁµ±ÁâπÊÄßÊúâÈ°ØËëóÁöÑËÆäÂåñ„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫ S-SYNTHÔºåÈÄôÊòØÁ¨¨‰∏ÄÂÄãÂü∫ÊñºÁü•Ë≠ò„ÄÅÂèØÈÅ©ÊáâÁöÑÈñãÊîæÂéüÂßãÁ¢ºÁöÆËÜöÊ®°Êì¨Êû∂ÊßãÔºåÂèØ‰ΩøÁî®Ëß£ÂâñÂ≠∏ÂïüÁôºÁöÑÂ§öÂ±§„ÄÅÂ§öÁµÑÊàêÁöÆËÜöÂíåÁîüÈï∑ÁóÖÁÅ∂Ê®°ÂûãÔºåÂø´ÈÄüÁî¢ÁîüÂêàÊàêÁöÆËÜö„ÄÅ3D Ê®°ÂûãÂíåÊï∏‰ΩçÊ∏≤ÊüìÂΩ±ÂÉè„ÄÇÁöÆËÜöÊ®°ÂûãÂÖÅË®±ÊéßÂà∂ÁöÆËÜöÂ§ñËßÄÁöÑËÆäÂåñÔºå‰æãÂ¶ÇËÜöËâ≤„ÄÅÊØõÈ´ÆÂ≠òÂú®„ÄÅÁóÖÁÅ∂ÂΩ¢ÁãÄÂíåË°ÄÊ∂≤ÊØî‰æãÁ≠âÂèÉÊï∏„ÄÇÊàëÂÄë‰ΩøÁî®ÈÄôÂÄãÊû∂Êßã‰æÜÁ†îÁ©∂ÂèØËÉΩÁöÑËÆäÂåñÂ∞çÁöÆËÜöÁóÖÁÅ∂ÂàÜÂâ≤ AI Ê®°ÂûãÁöÑÈñãÁôºÂíåË©ï‰º∞ÁöÑÂΩ±ÈüøÔºå‰∏¶È°ØÁ§∫‰ΩøÁî®ÂêàÊàêË≥áÊñôÂèñÂæóÁöÑÁµêÊûúÈÅµÂæ™ËàáÁúüÂØ¶ÁöÆËÜöÁßëÂΩ±ÂÉèÈ°û‰ººÁöÑÊØîËºÉË∂®Âã¢ÔºåÂêåÊôÇÊ∏õËºïÁèæÊúâË≥áÊñôÈõÜÁöÑÂÅèÂ∑ÆÂíåÈôêÂà∂ÔºåÂåÖÊã¨Ë≥áÊñôÈõÜË¶èÊ®°Â∞è„ÄÅÁº∫‰πèÂ§öÂÖÉÊÄß‰ª•Âèä‰ª£Ë°®ÊÄß‰∏çË∂≥„ÄÇ

##### **A Taxonomy of Stereotype Content in Large Language Models**
2408.00162v1 by Gandalf Nicolas, Aylin Caliskan

This study introduces a taxonomy of stereotype content in contemporary large
language models (LLMs). We prompt ChatGPT 3.5, Llama 3, and Mixtral 8x7B, three
powerful and widely used LLMs, for the characteristics associated with 87
social categories (e.g., gender, race, occupations). We identify 14 stereotype
dimensions (e.g., Morality, Ability, Health, Beliefs, Emotions), accounting for
~90% of LLM stereotype associations. Warmth and Competence facets were the most
frequent content, but all other dimensions were significantly prevalent.
Stereotypes were more positive in LLMs (vs. humans), but there was significant
variability across categories and dimensions. Finally, the taxonomy predicted
the LLMs' internal evaluations of social categories (e.g., how
positively/negatively the categories were represented), supporting the
relevance of a multidimensional taxonomy for characterizing LLM stereotypes.
Our findings suggest that high-dimensional human stereotypes are reflected in
LLMs and must be considered in AI auditing and debiasing to minimize
unidentified harms from reliance in low-dimensional views of bias in LLMs.

ÊëòË¶ÅÔºöÊú¨Á†îÁ©∂ÈáùÂ∞çÁï∂‰ª£Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰∏≠ÁöÑÂàªÊùøÂç∞Ë±°ÂÖßÂÆπÈÄ≤Ë°åÂàÜÈ°û„ÄÇÊàëÂÄëÊèêÁ§∫ ChatGPT 3.5„ÄÅLlama 3 Âíå Mixtral 8x7B ÈÄô‰∏âÁ®ÆÂº∑Â§ß‰∏îÂª£Ê≥õ‰ΩøÁî®ÁöÑ LLMÔºå‰∫ÜËß£Ëàá 87 ÂÄãÁ§æÊúÉÈ°ûÂà•Ôºà‰æãÂ¶ÇÊÄßÂà•„ÄÅÁ®ÆÊóè„ÄÅËÅ∑Ê•≠ÔºâÁõ∏ÈóúÁöÑÁâπÂæµ„ÄÇÊàëÂÄëË≠òÂà•Âá∫ 14 ÂÄãÂàªÊùøÂç∞Ë±°Èù¢ÂêëÔºà‰æãÂ¶ÇÈÅìÂæ∑„ÄÅËÉΩÂäõ„ÄÅÂÅ•Â∫∑„ÄÅ‰ø°‰ª∞„ÄÅÊÉÖÁ∑íÔºâÔºåÁ¥Ñ‰Ωî LLM ÂàªÊùøÂç∞Ë±°ÈóúËÅØÁöÑ 90%„ÄÇÊ∫´ÊöñÂíåËÉΩÂäõÈù¢ÂêëÊòØÊúÄÈ†ªÁπÅÁöÑÂÖßÂÆπÔºå‰ΩÜÊâÄÊúâÂÖ∂‰ªñÈù¢ÂêëÈÉΩÂæàÊôÆÈÅç„ÄÇLLM ‰∏≠ÁöÑÂàªÊùøÂç∞Ë±°ÊØî‰∫∫È°ûÊõ¥Ê≠£Èù¢Ôºå‰ΩÜ‰∏çÂêåÈ°ûÂà•ÂíåÈù¢Âêë‰πãÈñìÂ≠òÂú®È°ØËëóÂ∑ÆÁï∞„ÄÇÊúÄÂæåÔºåÂàÜÈ°ûÊ≥ïÈ†êÊ∏¨‰∫Ü LLM Â∞çÁ§æÊúÉÈ°ûÂà•ÁöÑÂÖßÈÉ®Ë©ï‰º∞Ôºà‰æãÂ¶ÇÈ°ûÂà•ÁöÑÊ≠£Èù¢/Ë≤†Èù¢ÂëàÁèæÊñπÂºèÔºâÔºåÊîØÊåÅ‰∫Ü‰ΩøÁî®Â§öÁ∂≠ÂàÜÈ°ûÊ≥ï‰æÜË°®Âæµ LLM ÂàªÊùøÂç∞Ë±°ÁöÑÁõ∏ÈóúÊÄß„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúË°®ÊòéÔºåÈ´òÁ∂≠Â∫¶ÁöÑ‰∫∫È°ûÂàªÊùøÂç∞Ë±°ÂèçÊò†Âú® LLM ‰∏≠Ôºå‰∏¶‰∏îÂøÖÈ†àÂú® AI Á®ΩÊ†∏ÂíåÊ∂àÈô§ÂÅèË¶ã‰∏≠Âä†‰ª•ËÄÉÊÖÆÔºå‰ª•Â∞á‰æùË≥¥ LLM ‰∏≠ÂÅèË¶ãÁöÑ‰ΩéÁ∂≠Â∫¶ËßÄÈªûÈÄ†ÊàêÁöÑÊú™Ë≠òÂà•Âç±ÂÆ≥ÈôçÂà∞ÊúÄ‰Ωé„ÄÇ

##### **Preference-Based Abstract Argumentation for Case-Based Reasoning (with Appendix)**
2408.00108v2 by Adam Gould, Guilherme Paulino-Passos, Seema Dadhania, Matthew Williams, Francesca Toni

In the pursuit of enhancing the efficacy and flexibility of interpretable,
data-driven classification models, this work introduces a novel incorporation
of user-defined preferences with Abstract Argumentation and Case-Based
Reasoning (CBR). Specifically, we introduce Preference-Based Abstract
Argumentation for Case-Based Reasoning (which we call AA-CBR-P), allowing users
to define multiple approaches to compare cases with an ordering that specifies
their preference over these comparison approaches. We prove that the model
inherently follows these preferences when making predictions and show that
previous abstract argumentation for case-based reasoning approaches are
insufficient at expressing preferences over constituents of an argument. We
then demonstrate how this can be applied to a real-world medical dataset
sourced from a clinical trial evaluating differing assessment methods of
patients with a primary brain tumour. We show empirically that our approach
outperforms other interpretable machine learning models on this dataset.

ÊëòË¶ÅÔºöÁÇ∫‰∫ÜÊèêÂçáÂèØËß£Èáã„ÄÅË≥áÊñôÈ©ÖÂãïÂàÜÈ°ûÊ®°ÂûãÁöÑÊïàËÉΩÂíåÈùàÊ¥ªÊÄßÔºåÊ≠§Á†îÁ©∂ÂºïÂÖ•‰∫Ü‰ΩøÁî®ËÄÖËá™Ë®ÇÂÅèÂ•ΩËàáÊäΩË±°Ë´ñË≠âÂíåÊ°à‰æãÂü∫Á§éÊé®ÁêÜ (CBR) ÁöÑÊñ∞ÁµêÂêà„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜÊ°à‰æãÂü∫Á§éÊé®ÁêÜÁöÑÂÅèÂ•ΩÂü∫Á§éÊäΩË±°Ë´ñË≠â (ÊàëÂÄëÁ®±‰πãÁÇ∫ AA-CBR-P)ÔºåÂÖÅË®±‰ΩøÁî®ËÄÖÂÆöÁæ©Â§öÁ®ÆÊñπÊ≥ï‰æÜÊØîËºÉÊ°à‰æãÔºå‰∏¶ÈÄèÈÅéÊéíÂ∫è‰æÜÊåáÂÆö‰ªñÂÄëÂ∞çÈÄô‰∫õÊØîËºÉÊñπÊ≥ïÁöÑÂÅèÂ•Ω„ÄÇÊàëÂÄëË≠âÊòé‰∫ÜÊ≠§Ê®°ÂûãÂú®ÈÄ≤Ë°åÈ†êÊ∏¨ÊôÇÊúÉËá™ÁÑ∂ÈÅµÂæ™ÈÄô‰∫õÂÅèÂ•ΩÔºå‰∏¶È°ØÁ§∫ÂÖàÂâçÊ°à‰æãÂü∫Á§éÊé®ÁêÜÁöÑÊäΩË±°Ë´ñË≠âÊñπÊ≥ï‰∏çË∂≥‰ª•Ë°®ÈÅîÂ∞çË´ñË≠âÁµÑÊàêÁöÑÂÅèÂ•Ω„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜÂ¶Ç‰ΩïÂ∞áÊ≠§ÊñπÊ≥ïÊáâÁî®ÊñºÂØ¶ÈöõÁöÑÈÜ´ÁôÇË≥áÊñôÈõÜÔºåË©≤Ë≥áÊñôÈõÜ‰æÜËá™Ë©ï‰º∞ÂéüÁôºÊÄßËÖ¶ËÖ´Áò§ÊÇ£ËÄÖ‰∏çÂêåË©ï‰º∞ÊñπÊ≥ïÁöÑËá®Â∫äË©¶È©ó„ÄÇÊàëÂÄëÁ∂ìÈ©óÊÄßÂú∞Ë≠âÊòéÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÂú®ÈÄôÂÄãË≥áÊñôÈõÜ‰∏äÂÑ™ÊñºÂÖ∂‰ªñÂèØËß£ÈáãÁöÑÊ©üÂô®Â≠∏ÁøíÊ®°Âûã„ÄÇ

##### **A Federated Learning-Friendly Approach for Parameter-Efficient Fine-Tuning of SAM in 3D Segmentation**
2407.21739v1 by Mothilal Asokan, Joseph Geo Benjamin, Mohammad Yaqub, Karthik Nandakumar

Adapting foundation models for medical image analysis requires finetuning
them on a considerable amount of data because of extreme distribution shifts
between natural (source) data used for pretraining and medical (target) data.
However, collecting task-specific medical data for such finetuning at a central
location raises many privacy concerns. Although Federated learning (FL)
provides an effective means for training on private decentralized data,
communication costs in federating large foundation models can quickly become a
significant bottleneck, impacting the solution's scalability. In this work, we
address this problem of efficient communication while ensuring effective
learning in FL by combining the strengths of Parameter-Efficient Fine-tuning
(PEFT) with FL. Specifically, we study plug-and-play Low-Rank Adapters (LoRA)
in a federated manner to adapt the Segment Anything Model (SAM) for 3D medical
image segmentation. Unlike prior works that utilize LoRA and finetune the
entire decoder, we critically analyze the contribution of each granular
component of SAM on finetuning performance. Thus, we identify specific layers
to be federated that are very efficient in terms of communication cost while
producing on-par accuracy. Our experiments show that retaining the parameters
of the SAM model (including most of the decoder) in their original state during
adaptation is beneficial because fine-tuning on small datasets tends to distort
the inherent capabilities of the underlying foundation model. On Fed-KiTS, our
approach decreases communication cost (~48x) compared to full fine-tuning while
increasing performance (~6% Dice score) in 3D segmentation tasks. Our approach
performs similar to SAMed while achieving ~2.8x reduction in communication and
parameters to be finetuned. We further validate our approach with experiments
on Fed-IXI and Prostate MRI datasets.

ÊëòË¶ÅÔºö<paragraph>Áî±ÊñºÈ†êË®ìÁ∑¥ÊâÄÁî®ÁöÑËá™ÁÑ∂Ôºà‰æÜÊ∫êÔºâË≥áÊñôÂíåÈÜ´ÁôÇÔºàÁõÆÊ®ôÔºâË≥áÊñô‰πãÈñìÁöÑÊ•µÁ´ØÂàÜ‰ΩàËΩâÁßªÔºåÂõ†Ê≠§Â∞áÂü∫Á§éÊ®°ÂûãË™øÊï¥Áî®ÊñºÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÊûêÈúÄË¶ÅÂú®Â§ßÈáèË≥áÊñô‰∏äÂ∞çÂÖ∂ÈÄ≤Ë°åÂæÆË™ø„ÄÇ
ÁÑ∂ËÄåÔºåÂú®‰∏≠ÂøÉ‰ΩçÁΩÆÊî∂ÈõÜÊ≠§È°ûÂæÆË™øÁöÑÁâπÂÆö‰ªªÂãôÈÜ´ÁôÇË≥áÊñôÊúÉÂºïÁôºË®±Â§öÈö±ÁßÅÂïèÈ°å„ÄÇÂÑòÁÆ°ËÅØÂêàÂ≠∏Áøí (FL) Êèê‰æõ‰∫Ü‰∏ÄÁ®ÆÂú®ÁßÅÊúâÂàÜÊï£ÂºèË≥áÊñô‰∏äÈÄ≤Ë°åË®ìÁ∑¥ÁöÑÊúâÊïàÊñπÊ≥ïÔºå‰ΩÜÂú®ËÅØÂêàÂ§ßÂûãÂü∫Á§éÊ®°ÂûãÊôÇÔºåÈÄöË®äÊàêÊú¨ÂèØËÉΩÊúÉËøÖÈÄüÊàêÁÇ∫‰∏ÄÂÄãÈáçÂ§ßÁì∂È†∏ÔºåÂΩ±ÈüøËß£Ê±∫ÊñπÊ°àÁöÑÂèØÊì¥ÂÖÖÊÄß„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÈÄöÈÅéÁµêÂêàÂèÉÊï∏È´òÊïàÂæÆË™ø (PEFT) Âíå FL ÁöÑÂÑ™Âã¢ÔºåËß£Ê±∫‰∫ÜÂú®Á¢∫‰øù FL ‰∏≠ÊúâÊïàÂ≠∏ÁøíÁöÑÂêåÊôÇÈÄ≤Ë°åÈ´òÊïàÈÄöË®äÁöÑÂïèÈ°å„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄë‰ª•ËÅØÂêàÁöÑÊñπÂºèÁ†îÁ©∂Âç≥ÊèíÂç≥Áî®‰ΩéÁß©ÈÅ©ÈÖçÂô® (LoRA)Ôºå‰ª•Ë™øÊï¥ÂçÄÊÆµ‰ªª‰ΩïÊ®°Âûã (SAM) ‰ª•ÈÄ≤Ë°å 3D ÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÂâ≤„ÄÇËàáÂà©Áî® LoRA ÂíåÂæÆË™øÊï¥ÂÄãËß£Á¢ºÂô®ÁöÑÂÖàÂâçÂ∑•‰Ωú‰∏çÂêåÔºåÊàëÂÄëÊâπÂà§ÊÄßÂú∞ÂàÜÊûê‰∫Ü SAM ÁöÑÊØèÂÄãÁ≤íÁãÄÁµÑÊàêÈÉ®ÂàÜÂ∞çÂæÆË™øÊïàËÉΩÁöÑË≤¢Áçª„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëÁ¢∫ÂÆö‰∫ÜÂú®ÈÄöË®äÊàêÊú¨ÊñπÈù¢ÈùûÂ∏∏È´òÊïàÁöÑÁâπÂÆöÂ±§ÔºåÂêåÊôÇÁî¢Áîü‰∫ÜÂêåÁ≠âÁöÑÊ∫ñÁ¢∫Â∫¶„ÄÇÊàëÂÄëÁöÑÂØ¶È©óË°®ÊòéÔºåÂú®Ë™øÊï¥ÈÅéÁ®ã‰∏≠Â∞á SAM Ê®°ÂûãÁöÑÂèÉÊï∏ÔºàÂåÖÊã¨Â§ßÈÉ®ÂàÜËß£Á¢ºÂô®Ôºâ‰øùÁïôÂú®ÂÖ∂ÂéüÂßãÁãÄÊÖãÊòØÊúâÁõäÁöÑÔºåÂõ†ÁÇ∫Âú®Â∞èÂûãË≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÂæÆË™øÂæÄÂæÄÊúÉÊâ≠Êõ≤Âü∫Á§éÊ®°ÂûãÁöÑÂÖßÂú®ËÉΩÂäõ„ÄÇÂú® Fed-KiTS ‰∏äÔºåËàáÂÆåÂÖ®ÂæÆË™øÁõ∏ÊØîÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÈôç‰Ωé‰∫ÜÈÄöË®äÊàêÊú¨ÔºàÁ¥Ñ 48 ÂÄçÔºâÔºåÂêåÊôÇÊèêÈ´ò‰∫Ü 3D ÂàÜÂâ≤‰ªªÂãô‰∏≠ÁöÑÊïàËÉΩÔºàÁ¥Ñ 6% ÁöÑÈ™∞Â≠êÂàÜÊï∏Ôºâ„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïËàá SAMed È°û‰ººÔºåÂêåÊôÇÂ∞áÈÄöË®äÂíåÂæÖÂæÆË™øÂèÉÊï∏Ê∏õÂ∞ë‰∫ÜÁ¥Ñ 2.8 ÂÄç„ÄÇÊàëÂÄëÈÄ≤‰∏ÄÊ≠•ÈÄöÈÅéÂú® Fed-IXI Âíå Prostate MRI Ë≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÂØ¶È©óÈ©óË≠â‰∫ÜÊàëÂÄëÁöÑÂÅöÊ≥ï„ÄÇ</paragraph>

##### **Synthetic Simplicity: Unveiling Bias in Medical Data Augmentation**
2407.21674v1 by Krishan Agyakari Raja Babu, Rachana Sathish, Mrunal Pattanaik, Rahul Venkataramani

Synthetic data is becoming increasingly integral in data-scarce fields such
as medical imaging, serving as a substitute for real data. However, its
inherent statistical characteristics can significantly impact downstream tasks,
potentially compromising deployment performance. In this study, we empirically
investigate this issue and uncover a critical phenomenon: downstream neural
networks often exploit spurious distinctions between real and synthetic data
when there is a strong correlation between the data source and the task label.
This exploitation manifests as \textit{simplicity bias}, where models overly
rely on superficial features rather than genuine task-related complexities.
Through principled experiments, we demonstrate that the source of data (real
vs.\ synthetic) can introduce spurious correlating factors leading to poor
performance during deployment when the correlation is absent. We first
demonstrate this vulnerability on a digit classification task, where the model
spuriously utilizes the source of data instead of the digit to provide an
inference. We provide further evidence of this phenomenon in a medical imaging
problem related to cardiac view classification in echocardiograms, particularly
distinguishing between 2-chamber and 4-chamber views. Given the increasing role
of utilizing synthetic datasets, we hope that our experiments serve as
effective guidelines for the utilization of synthetic datasets in model
training.

ÊëòË¶ÅÔºöÂêàÊàêË≥áÊñôÂú®Ë≥áÊñôÁ®ÄÂ∞ëÁöÑÈ†òÂüü‰∏≠ËÆäÂæóË∂ä‰æÜË∂ä‰∏çÂèØÊàñÁº∫Ôºå‰æãÂ¶ÇÈÜ´Â≠∏ÂΩ±ÂÉèÔºåÁî®‰ΩúÁúüÂØ¶Ë≥áÊñôÁöÑÊõø‰ª£ÂìÅ„ÄÇÁÑ∂ËÄåÔºåÂÖ∂ÂÖßÂú®ÁöÑÁµ±Ë®àÁâπÊÄßÊúÉÈ°ØËëóÂΩ±Èüø‰∏ãÊ∏∏‰ªªÂãôÔºåÂèØËÉΩÊêçÂÆ≥ÈÉ®ÁΩ≤ÊïàËÉΩ„ÄÇÂú®Êú¨Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëÂØ¶Ë≠âË™øÊü•Ê≠§ÂïèÈ°åÔºå‰∏¶Êè≠Èú≤‰∏ÄÂÄãÈóúÈçµÁèæË±°ÔºöÁï∂Ë≥áÊñô‰æÜÊ∫êËàá‰ªªÂãôÊ®ôÁ±§‰πãÈñìÊúâÂæàÂº∑ÁöÑÁõ∏ÈóúÊÄßÊôÇÔºå‰∏ãÊ∏∏Á•ûÁ∂ìÁ∂≤Ë∑ØÈÄöÂ∏∏ÊúÉÂà©Áî®ÁúüÂØ¶Ë≥áÊñôËàáÂêàÊàêË≥áÊñô‰πãÈñìÁöÑËôõÂÅáÂçÄÂà•„ÄÇÈÄôÁ®ÆÂà©Áî®Ë°®ÁèæÁÇ∫„ÄåÁ∞°ÂåñÂÅèÂ∑Æ„ÄçÔºåÂÖ∂‰∏≠Ê®°ÂûãÈÅéÂ∫¶‰æùË≥¥Ë°®Èù¢ÁâπÂæµÔºåËÄå‰∏çÊòØÁúüÊ≠£ÁöÑËàá‰ªªÂãôÁõ∏ÈóúÁöÑË§áÈõúÊÄß„ÄÇÈÄèÈÅéÊúâÂéüÂâáÁöÑÂØ¶È©óÔºåÊàëÂÄëË≠âÊòéË≥áÊñô‰æÜÊ∫êÔºàÁúüÂØ¶Ë≥áÊñôËàáÂêàÊàêË≥áÊñôÔºâÂèØËÉΩÊúÉÂºïÂÖ•ËôõÂÅáÁöÑÁõ∏ÈóúÂõ†Á¥†ÔºåÂ∞éËá¥Âú®Áõ∏ÈóúÊÄß‰∏çÂ≠òÂú®ÊôÇÈÉ®ÁΩ≤ÊúüÈñìÊïàËÉΩ‰∏ç‰Ω≥„ÄÇÊàëÂÄëÈ¶ñÂÖàÂú®Êï∏Â≠óÂàÜÈ°û‰ªªÂãô‰∏≠Ë≠âÊòéÊ≠§ÊºèÊ¥ûÔºåÂÖ∂‰∏≠Ê®°ÂûãËôõÂÅáÂú∞Âà©Áî®Ë≥áÊñô‰æÜÊ∫êËÄåÈùûÊï∏Â≠ó‰æÜÊèê‰æõÊé®Ë´ñ„ÄÇÊàëÂÄëÂú®ËàáË∂ÖÈü≥Ê≥¢ÂøÉËáüË¶ñÈáéÂàÜÈ°ûÁõ∏ÈóúÁöÑÈÜ´Â≠∏ÂΩ±ÂÉèÂïèÈ°å‰∏≠ÈÄ≤‰∏ÄÊ≠•Êèê‰æõÊ≠§ÁèæË±°ÁöÑË≠âÊìöÔºåÁâπÂà•ÊòØÂçÄÂàÜ‰∫åËÖîÂíåÂõõËÖîË¶ñÈáé„ÄÇÈëëÊñºÂêàÊàêË≥áÊñôÈõÜÁöÑ‰ΩøÁî®ËßíËâ≤Êó•ÁõäÂ¢ûÂä†ÔºåÊàëÂÄëÂ∏åÊúõÊàëÂÄëÁöÑÂØ¶È©óËÉΩ‰ΩúÁÇ∫Âú®Ê®°ÂûãË®ìÁ∑¥‰∏≠Âà©Áî®ÂêàÊàêË≥áÊñôÈõÜÁöÑÊúâÊïàÊåáÂçó„ÄÇ

##### **Quality Control for Radiology Report Generation Models via Auxiliary Auditing Components**
2407.21638v1 by Hermione Warr, Yasin Ibrahim, Daniel R. McGowan, Konstantinos Kamnitsas

Automation of medical image interpretation could alleviate bottlenecks in
diagnostic workflows, and has become of particular interest in recent years due
to advancements in natural language processing. Great strides have been made
towards automated radiology report generation via AI, yet ensuring clinical
accuracy in generated reports is a significant challenge, hindering deployment
of such methods in clinical practice. In this work we propose a quality control
framework for assessing the reliability of AI-generated radiology reports with
respect to semantics of diagnostic importance using modular auxiliary auditing
components (AC). Evaluating our pipeline on the MIMIC-CXR dataset, our findings
show that incorporating ACs in the form of disease-classifiers can enable
auditing that identifies more reliable reports, resulting in higher F1 scores
compared to unfiltered generated reports. Additionally, leveraging the
confidence of the AC labels further improves the audit's effectiveness.

ÊëòË¶ÅÔºöÈÜ´ÁôÇÂΩ±ÂÉèÂà§ËÆÄÁöÑËá™ÂãïÂåñÂèØ‰ª•Ê∏õËºïË®∫Êñ∑Â∑•‰ΩúÊµÅÁ®ã‰∏≠ÁöÑÁì∂È†∏Ôºå‰∏¶‰∏îÁî±ÊñºËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜÁöÑÈÄ≤Ê≠•ÔºåÂú®ËøëÂπ¥‰æÜÁâπÂà•ÂèóÂà∞ÈáçË¶ñ„ÄÇÂú®ÈÄèÈÅé AI Ëá™ÂãïÁîüÊàêÊîæÂ∞ÑÁ∑öÂ†±ÂëäÊñπÈù¢Â∑≤Á∂ìÂèñÂæó‰∫ÜÈï∑Ë∂≥ÁöÑÈÄ≤Â±ïÔºåÁÑ∂ËÄåÁ¢∫‰øùÁîüÊàêÂ†±ÂëäÁöÑËá®Â∫äÊ∫ñÁ¢∫ÊÄßÊòØ‰∏ÄÈ†ÖÈáçÂ§ßÁöÑÊåëÊà∞ÔºåÈòªÁ§ô‰∫ÜÊ≠§È°ûÊñπÊ≥ïÂú®Ëá®Â∫äÂØ¶Âãô‰∏≠ÁöÑÈÉ®ÁΩ≤„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂìÅË≥™ÊéßÂà∂Êû∂ÊßãÔºåÁî®ÊñºË©ï‰º∞ AI ÁîüÊàêÁöÑÊîæÂ∞ÑÁ∑öÂ†±ÂëäÁöÑÂèØÈù†ÊÄßÔºå‰∏¶‰ΩøÁî®Ê®°ÁµÑÂåñËºîÂä©Á®ΩÊ†∏ÂÖÉ‰ª∂ (AC) ÈáùÂ∞çË®∫Êñ∑ÈáçË¶ÅÊÄßÁöÑË™ûÁæ©ÈÄ≤Ë°åË©ï‰º∞„ÄÇÂú® MIMIC-CXR Ë≥áÊñôÈõÜ‰∏äË©ï‰º∞ÊàëÂÄëÁöÑÁÆ°ÈÅìÔºåÊàëÂÄëÁöÑÁôºÁèæÈ°ØÁ§∫Ôºå‰ª•ÁñæÁóÖÂàÜÈ°ûÂô®ÁöÑÂΩ¢ÂºèÁ¥çÂÖ• AC ÂèØ‰ª•ÂïüÁî®Á®ΩÊ†∏Ôºå‰ª•Ë≠òÂà•Êõ¥ÂèØÈù†ÁöÑÂ†±ÂëäÔºåËàáÊú™Á∂ìÁØ©ÈÅ∏ÁöÑÁîüÊàêÂ†±ÂëäÁõ∏ÊØîÔºåÊúÉÁî¢ÁîüÊõ¥È´òÁöÑ F1 ÂàÜÊï∏„ÄÇÊ≠§Â§ñÔºåÈÄ≤‰∏ÄÊ≠•Âà©Áî® AC Ê®ôÁ±§ÁöÑ‰ø°ÂøÉÂèØ‰ª•ÊèêÈ´òÁ®ΩÊ†∏ÁöÑÊúâÊïàÊÄß„ÄÇ

##### **Optimizing Disease Prediction with Artificial Intelligence Driven Feature Selection and Attention Networks**
2408.03151v1 by D. Dhinakaran, S. Edwin Raja, M. Thiyagarajan, J. Jeno Jasmine, P. Raghavan

The rapid integration of machine learning methodologies in healthcare has
ignited innovative strategies for disease prediction, particularly with the
vast repositories of Electronic Health Records (EHR) data. This article delves
into the realm of multi-disease prediction, presenting a comprehensive study
that introduces a pioneering ensemble feature selection model. This model,
designed to optimize learning systems, combines statistical, deep, and
optimally selected features through the innovative Stabilized Energy Valley
Optimization with Enhanced Bounds (SEV-EB) algorithm. The objective is to
achieve unparalleled accuracy and stability in predicting various disorders.
This work proposes an advanced ensemble model that synergistically integrates
statistical, deep, and optimally selected features. This combination aims to
enhance the predictive power of the model by capturing diverse aspects of the
health data. At the heart of the proposed model lies the SEV-EB algorithm, a
novel approach to optimal feature selection. The algorithm introduces enhanced
bounds and stabilization techniques, contributing to the robustness and
accuracy of the overall prediction model. To further elevate the predictive
capabilities, an HSC-AttentionNet is introduced. This network architecture
combines deep temporal convolution capabilities with LSTM, allowing the model
to capture both short-term patterns and long-term dependencies in health data.
Rigorous evaluations showcase the remarkable performance of the proposed model.
Achieving a 95% accuracy and 94% F1-score in predicting various disorders, the
model surpasses traditional methods, signifying a significant advancement in
disease prediction accuracy. The implications of this research extend beyond
the confines of academia.

ÊëòË¶ÅÔºö<paragraph>Ê©üÂô®Â≠∏ÁøíÊñπÊ≥ïÂú®ÈÜ´ÁôÇ‰øùÂÅ•È†òÂüüÁöÑÂø´ÈÄüÊï¥ÂêàÔºåÈªûÁáÉ‰∫ÜÁñæÁóÖÈ†êÊ∏¨ÁöÑÂâµÊñ∞Á≠ñÁï•ÔºåÁâπÂà•ÊòØÈõªÂ≠êÂÅ•Â∫∑Ë®òÈåÑ (EHR) Ë≥áÊñôÁöÑÈæêÂ§ßÂÑ≤Â≠òÂ∫´„ÄÇÊú¨ÊñáÊ∑±ÂÖ•Êé¢Ë®éÂ§öÁñæÁóÖÈ†êÊ∏¨ÁöÑÈ†òÂüüÔºåÊèêÂá∫‰∫Ü‰∏ÄÈ†ÖÂÖ®Èù¢ÁöÑÁ†îÁ©∂Ôºå‰ªãÁ¥π‰∫Ü‰∏ÄÂÄãÈñãÂâµÊÄßÁöÑÈõÜÊàêÁâπÂæµÈÅ∏ÊìáÊ®°Âûã„ÄÇÈÄôÂÄãÊ®°ÂûãÊó®Âú®ÂÑ™ÂåñÂ≠∏ÁøíÁ≥ªÁµ±ÔºåÁµêÂêàÁµ±Ë®à„ÄÅÊ∑±Â∫¶ÂíåÊúÄ‰Ω≥ÈÅ∏ÊìáÁöÑÁâπÂæµÔºåÈÄèÈÅéÂâµÊñ∞ÁöÑÁ©©ÂÆöËÉΩÈáèË∞∑ÂÑ™ÂåñËàáÂ¢ûÂº∑ÈÇäÁïå (SEV-EB) ÊºîÁÆóÊ≥ï„ÄÇÁõÆÊ®ôÊòØÂú®È†êÊ∏¨ÂêÑÁ®ÆÁñæÁóÖÊôÇÈÅîÂà∞ÁÑ°ËàáÂÄ´ÊØîÁöÑÊ∫ñÁ¢∫ÊÄßÂíåÁ©©ÂÆöÊÄß„ÄÇÈÄôÈ†ÖÁ†îÁ©∂ÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂÖàÈÄ≤ÁöÑÈõÜÊàêÊ®°ÂûãÔºåÂçîÂêåÊï¥ÂêàÁµ±Ë®à„ÄÅÊ∑±Â∫¶ÂíåÊúÄ‰Ω≥ÈÅ∏ÊìáÁöÑÁâπÂæµ„ÄÇÈÄôÁ®ÆÁµÑÂêàÊó®Âú®ÈÄèÈÅéÊì∑ÂèñÂÅ•Â∫∑Ë≥áÊñôÁöÑ‰∏çÂêåÈù¢ÂêëÔºå‰æÜÂ¢ûÂº∑Ê®°ÂûãÁöÑÈ†êÊ∏¨ËÉΩÂäõ„ÄÇÊâÄÊèêÂá∫ÁöÑÊ®°ÂûãÊ†∏ÂøÉÂú®Êñº SEV-EB ÊºîÁÆóÊ≥ïÔºå‰∏ÄÁ®ÆÊúÄ‰Ω≥ÁâπÂæµÈÅ∏ÊìáÁöÑÊñ∞ÊñπÊ≥ï„ÄÇË©≤ÊºîÁÆóÊ≥ïÂºïÂÖ•‰∫ÜÂ¢ûÂº∑ÁöÑÈÇäÁïåÂíåÁ©©ÂÆöÊäÄË°ìÔºåÊúâÂä©ÊñºÊï¥È´îÈ†êÊ∏¨Ê®°ÂûãÁöÑÁ©©ÂÅ•ÊÄßÂíåÊ∫ñÁ¢∫ÊÄß„ÄÇÁÇ∫‰∫ÜÈÄ≤‰∏ÄÊ≠•ÊèêÂçáÈ†êÊ∏¨ËÉΩÂäõÔºåÂºïÂÖ•‰∫Ü HSC-AttentionNet„ÄÇÈÄôÂÄãÁ∂≤Ë∑ØÊû∂ÊßãÁµêÂêà‰∫ÜÊ∑±Â∫¶ÊôÇÈñìÂç∑Á©çÂäüËÉΩËàá LSTMÔºå‰ΩøÊ®°ÂûãËÉΩÂ§†Êì∑ÂèñÂÅ•Â∫∑Ë≥áÊñô‰∏≠ÁöÑÁü≠ÊúüÊ®°ÂºèÂíåÈï∑Êúü‰æùË≥¥ÊÄß„ÄÇÂö¥Ë¨πÁöÑË©ï‰º∞Â±ïÁ§∫‰∫ÜÊâÄÊèêÂá∫Ê®°ÂûãÁöÑÂçìË∂äÊïàËÉΩ„ÄÇÂú®È†êÊ∏¨ÂêÑÁ®ÆÁñæÁóÖÊôÇÈÅîÂà∞ 95% ÁöÑÊ∫ñÁ¢∫Â∫¶Âíå 94% ÁöÑ F1 ÂàÜÊï∏ÔºåË©≤Ê®°ÂûãË∂ÖË∂ä‰∫ÜÂÇ≥Áµ±ÊñπÊ≥ïÔºåÊ®ôË™åËëóÁñæÁóÖÈ†êÊ∏¨Ê∫ñÁ¢∫ÊÄßÁöÑÈáçÂ§ßÈÄ≤Â±ï„ÄÇÈÄôÈ†ÖÁ†îÁ©∂ÁöÑÊÑèÁæ©Ë∂ÖË∂ä‰∫ÜÂ≠∏Ë°ìÁïå„ÄÇ</paragraph>

##### **Voxel Scene Graph for Intracranial Hemorrhage**
2407.21580v1 by Antoine P. Sanner, Nils F. Grauhan, Marc A. Brockmann, Ahmed E. Othman, Anirban Mukhopadhyay

Patients with Intracranial Hemorrhage (ICH) face a potentially
life-threatening condition, and patient-centered individualized treatment
remains challenging due to possible clinical complications. Deep-Learning-based
methods can efficiently analyze the routinely acquired head CTs to support the
clinical decision-making. The majority of early work focuses on the detection
and segmentation of ICH, but do not model the complex relations between ICH and
adjacent brain structures. In this work, we design a tailored object detection
method for ICH, which we unite with segmentation-grounded Scene Graph
Generation (SGG) methods to learn a holistic representation of the clinical
cerebral scene. To the best of our knowledge, this is the first application of
SGG for 3D voxel images. We evaluate our method on two head-CT datasets and
demonstrate that our model can recall up to 74% of clinically relevant
relations. This work lays the foundation towards SGG for 3D voxel data. The
generated Scene Graphs can already provide insights for the clinician, but are
also valuable for all downstream tasks as a compact and interpretable
representation.

ÊëòË¶ÅÔºöËÖ¶Âá∫Ë°Ä (ICH) ÊÇ£ËÄÖÈù¢Ëá®ÂèØËÉΩÂç±ÂèäÁîüÂëΩÁöÑÁãÄÊ≥ÅÔºåÁî±ÊñºÂèØËÉΩÁöÑËá®Â∫ä‰ΩµÁôºÁóáÔºå‰ª•ÊÇ£ËÄÖÁÇ∫‰∏≠ÂøÉÁöÑÂÄã‰∫∫ÂåñÊ≤ªÁôÇ‰ªçÁÑ∂ÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÂü∫ÊñºÊ∑±Â∫¶Â≠∏ÁøíÁöÑÊñπÊ≥ïÂèØ‰ª•ÊúâÊïàÂàÜÊûêÂ∏∏Ë¶èÁç≤ÂæóÁöÑÈ†≠ÈÉ®ÈõªËÖ¶Êñ∑Â±§ÊéÉÊèèÔºå‰ª•ÊîØÊåÅËá®Â∫äÊ±∫Á≠ñÂà∂ÂÆö„ÄÇÂ§ßÂ§öÊï∏Êó©ÊúüÂ∑•‰ΩúÈÉΩÈõÜ‰∏≠Âú® ICH ÁöÑÊ™¢Ê∏¨ÂíåÂàÜÂâ≤Ôºå‰ΩÜÊ≤íÊúâÂ∞ç ICH ÂíåÁõ∏ÈÑ∞Â§ßËÖ¶ÁµêÊßã‰πãÈñìÁöÑË§áÈõúÈóú‰øÇÈÄ≤Ë°åÂª∫Ê®°„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëË®≠Ë®à‰∫Ü‰∏ÄÁ®ÆÈáùÂ∞ç ICH ÁöÑÂÆ¢Ë£ΩÂåñÁõÆÊ®ôÊ™¢Ê∏¨ÊñπÊ≥ïÔºåÊàëÂÄëÂ∞áÂÖ∂ËàáÂü∫ÊñºÂàÜÂâ≤ÁöÑÂ†¥ÊôØÂúñÁîüÊàê (SGG) ÊñπÊ≥ïÁµêÂêàÔºå‰ª•Â≠∏ÁøíËá®Â∫äËÖ¶ÈÉ®Â†¥ÊôØÁöÑÊï¥È´îË°®Âæµ„ÄÇÊìöÊàëÂÄëÊâÄÁü•ÔºåÈÄôÊòØ SGG Á¨¨‰∏ÄÊ¨°ÊáâÁî®Êñº 3D È´îÁ¥†ÂΩ±ÂÉè„ÄÇÊàëÂÄëÂú®ÂÖ©ÂÄãÈ†≠ÈÉ®ÈõªËÖ¶Êñ∑Â±§ÊéÉÊèèÊï∏ÊìöÈõÜ‰∏äË©ï‰º∞ÊàëÂÄëÁöÑÊ®°ÂûãÔºå‰∏¶Ë≠âÊòéÊàëÂÄëÁöÑÊ®°ÂûãÂèØ‰ª•Âè¨ÂõûÈ´òÈÅî 74% ÁöÑËá®Â∫äÁõ∏ÈóúÈóú‰øÇ„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÁÇ∫ 3D È´îÁ¥†Êï∏ÊìöÁöÑ SGG Â•†ÂÆö‰∫ÜÂü∫Á§é„ÄÇÁîüÊàêÁöÑÂ†¥ÊôØÂúñÂ∑≤Á∂ìÂèØ‰ª•ÁÇ∫Ëá®Â∫äÈÜ´ÁîüÊèê‰æõË¶ãËß£Ôºå‰ΩÜÂ∞çÊñºÊâÄÊúâ‰∏ãÊ∏∏‰ªªÂãôËÄåË®ÄÔºåÂÆÉ‰πüÊòØ‰∏ÄÁ®ÆÁ≤æÁ∞°‰∏îÂèØËß£ÈáãÁöÑË°®ÂæµÔºåÂõ†Ê≠§ÈùûÂ∏∏ÊúâÂÉπÂÄº„ÄÇ

##### **Expanding the Medical Decathlon dataset: segmentation of colon and colorectal cancer from computed tomography images**
2407.21516v1 by I. M. Chernenkiy, Y. A. Drach, S. R. Mustakimova, V. V. Kazantseva, N. A. Ushakov, S. K. Efetov, M. V. Feldsherov

Colorectal cancer is the third-most common cancer in the Western Hemisphere.
The segmentation of colorectal and colorectal cancer by computed tomography is
an urgent problem in medicine. Indeed, a system capable of solving this problem
will enable the detection of colorectal cancer at early stages of the disease,
facilitate the search for pathology by the radiologist, and significantly
accelerate the process of diagnosing the disease. However, scientific
publications on medical image processing mostly use closed, non-public data.
This paper presents an extension of the Medical Decathlon dataset with
colorectal markups in order to improve the quality of segmentation algorithms.
An experienced radiologist validated the data, categorized it into subsets by
quality, and published it in the public domain. Based on the obtained results,
we trained neural network models of the UNet architecture with 5-part
cross-validation and achieved a Dice metric quality of $0.6988 \pm 0.3$. The
published markups will improve the quality of colorectal cancer detection and
simplify the radiologist's job for study description.

ÊëòË¶ÅÔºöÂ§ßËÖ∏ÁôåÊòØË•øÂçäÁêÉÁ¨¨‰∏âÂ∏∏Ë¶ãÁöÑÁôåÁóá„ÄÇ
Âà©Áî®ÈõªËÖ¶Êñ∑Â±§ÊéÉÊèèÂ∞çÂ§ßËÖ∏ÁôåËàáÂ§ßËÖ∏ÁôåÈÄ≤Ë°åÂàÜÊÆµÊòØÈÜ´Â≠∏‰∏äÁöÑÁ∑äÊÄ•ÂïèÈ°å„ÄÇ‰∫ãÂØ¶‰∏äÔºå‰∏ÄÂÄãËÉΩÂ§†Ëß£Ê±∫ÈÄôÂÄãÂïèÈ°åÁöÑÁ≥ªÁµ±Â∞áËÉΩÂ§†Âú®ÁñæÁóÖÁöÑÊó©ÊúüÈöéÊÆµÂÅµÊ∏¨Â§ßËÖ∏ÁôåÔºåÂçîÂä©ÊîæÂ∞ÑÁßëÈÜ´Â∏´Â∞ãÊâæÁóÖÁêÜÔºå‰∏¶È°ØËëóÂä†ÈÄüË®∫Êñ∑ÁñæÁóÖÁöÑÈÅéÁ®ã„ÄÇÁÑ∂ËÄåÔºåÈóúÊñºÈÜ´Â≠∏ÂΩ±ÂÉèËôïÁêÜÁöÑÁßëÂ≠∏ÂàäÁâ©Â§ßÂ§ö‰ΩøÁî®Â∞ÅÈñâ„ÄÅÈùûÂÖ¨ÈñãÁöÑË≥áÊñô„ÄÇÈÄôÁØáË´ñÊñáÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂ∏∂ÊúâÂ§ßËÖ∏Ê®ôË®òÁöÑÈÜ´Â≠∏ÂçÅÈ†ÖÂÖ®ËÉΩË≥áÊñôÈõÜÁöÑÂª∂‰º∏Ôºå‰ª•ÊèêÈ´òÂàÜÊÆµÊºîÁÆóÊ≥ïÁöÑÂìÅË≥™„ÄÇ‰∏Ä‰ΩçÁ∂ìÈ©óË±êÂØåÁöÑÊîæÂ∞ÑÁßëÈÜ´Â∏´È©óË≠â‰∫ÜË≥áÊñôÔºåÂ∞áÂÖ∂‰æùÂìÅË≥™ÂàÜÈ°ûÊàêÂ≠êÈõÜÔºå‰∏¶Â∞áÂÖ∂ÁôºÂ∏ÉÂú®ÂÖ¨ÂÖ±È†òÂüü„ÄÇÊ†πÊìöÁç≤ÂæóÁöÑÁµêÊûúÔºåÊàëÂÄëË®ìÁ∑¥‰∫ÜÂÖ∑Êúâ 5 ÈÉ®ÂàÜ‰∫§ÂèâÈ©óË≠âÁöÑ UNet Êû∂ÊßãÁöÑÁ•ûÁ∂ìÁ∂≤Ë∑ØÊ®°ÂûãÔºå‰∏¶ÈÅîÂà∞‰∫Ü $0.6988 \pm 0.3$ ÁöÑ Dice ÊåáÊ®ôÂìÅË≥™„ÄÇÁôºÂ∏ÉÁöÑÊ®ôË®òÂ∞áÊèêÈ´òÂ§ßËÖ∏ÁôåÂÅµÊ∏¨ÁöÑÂìÅË≥™Ôºå‰∏¶Á∞°ÂåñÊîæÂ∞ÑÁßëÈÜ´Â∏´Á†îÁ©∂ÊèèËø∞ÁöÑÂ∑•‰Ωú„ÄÇ

##### **Explainable and Controllable Motion Curve Guided Cardiac Ultrasound Video Generation**
2407.21490v1 by Junxuan Yu, Rusi Chen, Yongsong Zhou, Yanlin Chen, Yaofei Duan, Yuhao Huang, Han Zhou, Tan Tao, Xin Yang, Dong Ni

Echocardiography video is a primary modality for diagnosing heart diseases,
but the limited data poses challenges for both clinical teaching and machine
learning training. Recently, video generative models have emerged as a
promising strategy to alleviate this issue. However, previous methods often
relied on holistic conditions during generation, hindering the flexible
movement control over specific cardiac structures. In this context, we propose
an explainable and controllable method for echocardiography video generation,
taking an initial frame and a motion curve as guidance. Our contributions are
three-fold. First, we extract motion information from each heart substructure
to construct motion curves, enabling the diffusion model to synthesize
customized echocardiography videos by modifying these curves. Second, we
propose the structure-to-motion alignment module, which can map semantic
features onto motion curves across cardiac structures. Third, The
position-aware attention mechanism is designed to enhance video consistency
utilizing Gaussian masks with structural position information. Extensive
experiments on three echocardiography datasets show that our method outperforms
others regarding fidelity and consistency. The full code will be released at
https://github.com/mlmi-2024-72/ECM.

ÊëòË¶ÅÔºöË∂ÖÈü≥Ê≥¢ÂøÉÂãïÂúñÂΩ±ÁâáÊòØË®∫Êñ∑ÂøÉËáüÁñæÁóÖÁöÑ‰∏ªË¶ÅÊñπÂºèÔºå
‰ΩÜÊúâÈôêÁöÑÊï∏ÊìöÂ∞çËá®Â∫äÊïôÂ≠∏ÂíåÊ©üÂô®Â≠∏ÁøíË®ìÁ∑¥ÈÉΩÊßãÊàêÊåëÊà∞„ÄÇÊúÄËøëÔºåÂΩ±ÁâáÁîüÊàêÊ®°ÂûãÂ∑≤ÊàêÁÇ∫Á∑©Ëß£Ê≠§ÂïèÈ°åÁöÑ‰∏ÄÁ®ÆÊúâÂâçÈÄîÁöÑÁ≠ñÁï•„ÄÇÁÑ∂ËÄåÔºåÂÖàÂâçÁöÑËæ¶Ê≥ïÂú®ÁîüÊàêÈÅéÁ®ã‰∏≠ÈÄöÂ∏∏‰æùË≥¥Êï¥È´îÊ¢ù‰ª∂ÔºåÈòªÁ§ô‰∫ÜÂ∞çÁâπÂÆöÂøÉËáüÁµêÊßãÁöÑÈùàÊ¥ªÈÅãÂãïÊéßÂà∂„ÄÇÂú®Ê≠§ËÉåÊôØ‰∏ãÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂèØËß£Èáã‰∏îÂèØÊéßÁöÑË∂ÖÈü≥Ê≥¢ÂøÉÂãïÂúñÂΩ±ÁâáÁîüÊàêÊñπÊ≥ïÔºå‰ª•ÂàùÂßãÂπÄÂíåÈÅãÂãïÊõ≤Á∑ö‰ΩúÁÇ∫ÊåáÂ∞é„ÄÇÊàëÂÄëÁöÑË≤¢ÁçªÊúâ‰∏âÊñπÈù¢„ÄÇÈ¶ñÂÖàÔºåÊàëÂÄëÂæûÊØèÂÄãÂøÉËáüÂ≠êÁµêÊßã‰∏≠ÊèêÂèñÈÅãÂãïË≥áË®ä‰ª•Âª∫ÊßãÈÅãÂãïÊõ≤Á∑öÔºåËÆìÊì¥Êï£Ê®°ÂûãËÉΩÂ§†ÈÄèÈÅé‰øÆÊîπÈÄô‰∫õÊõ≤Á∑ö‰æÜÂêàÊàêÂÆ¢Ë£ΩÂåñÁöÑË∂ÖÈü≥Ê≥¢ÂøÉÂãïÂúñÂΩ±Áâá„ÄÇÂÖ∂Ê¨°ÔºåÊàëÂÄëÊèêÂá∫‰∫ÜÁµêÊßãÂà∞ÈÅãÂãïÂ∞çÈΩäÊ®°ÁµÑÔºåÂÆÉÂèØ‰ª•Â∞áË™ûÁæ©ÁâπÂæµÂ∞çÊáâÂà∞ÂøÉËáüÁµêÊßã‰∏≠ÁöÑÈÅãÂãïÊõ≤Á∑ö„ÄÇÁ¨¨‰∏âÔºå‰ΩçÁΩÆÊÑüÁü•Ê≥®ÊÑèÂäõÊ©üÂà∂Êó®Âú®Âà©Áî®ÂÖ∑ÊúâÁµêÊßã‰ΩçÁΩÆË≥áË®äÁöÑÈ´òÊñØÈÅÆÁΩ©‰æÜÂ¢ûÂº∑ÂΩ±ÁâáÁöÑ‰∏ÄËá¥ÊÄß„ÄÇÂú®‰∏âÂÄãË∂ÖÈü≥Ê≥¢ÂøÉÂãïÂúñË≥áÊñôÈõÜ‰∏äÁöÑÂª£Ê≥õÂØ¶È©óÈ°ØÁ§∫ÔºåÊàëÂÄëÁöÑËæ¶Ê≥ïÂú®‰øùÁúüÂ∫¶Âíå‰∏ÄËá¥ÊÄßÊñπÈù¢ÂÑ™ÊñºÂÖ∂‰ªñËæ¶Ê≥ï„ÄÇÂÆåÊï¥Á®ãÂºèÁ¢ºÂ∞áÂú® https://github.com/mlmi-2024-72/ECM ‰∏äÈáãÂá∫„ÄÇ

##### **Deep Learning-Based Longitudinal Prediction of Childhood Myopia Progression Using Fundus Image Sequences and Baseline Refraction Data**
2407.21467v1 by Mengtian Kang, Yansong Hu, Shuo Gao, Yuanyuan Liu, Hongbei Meng, Xuemeng Li, Xuhang Chen, Hubin Zhao, Jing Fu, Guohua Hu, Wei Wang, Yanning Dai, Arokia Nathan, Peter Smielewski, Ningli Wang, Shiming Li

Childhood myopia constitutes a significant global health concern. It exhibits
an escalating prevalence and has the potential to evolve into severe,
irreversible conditions that detrimentally impact familial well-being and
create substantial economic costs. Contemporary research underscores the
importance of precisely predicting myopia progression to enable timely and
effective interventions, thereby averting severe visual impairment in children.
Such predictions predominantly rely on subjective clinical assessments, which
are inherently biased and resource-intensive, thus hindering their widespread
application. In this study, we introduce a novel, high-accuracy method for
quantitatively predicting the myopic trajectory and myopia risk in children
using only fundus images and baseline refraction data. This approach was
validated through a six-year longitudinal study of 3,408 children in Henan,
utilizing 16,211 fundus images and corresponding refractive data. Our method
based on deep learning demonstrated predictive accuracy with an error margin of
0.311D per year and AUC scores of 0.944 and 0.995 for forecasting the risks of
developing myopia and high myopia, respectively. These findings confirm the
utility of our model in supporting early intervention strategies and in
significantly reducing healthcare costs, particularly by obviating the need for
additional metadata and repeated consultations. Furthermore, our method was
designed to rely only on fundus images and refractive error data, without the
need for meta data or multiple inquiries from doctors, strongly reducing the
associated medical costs and facilitating large-scale screening. Our model can
even provide good predictions based on only a single time measurement.
Consequently, the proposed method is an important means to reduce medical
inequities caused by economic disparities.

ÊëòË¶ÅÔºöÂÖíÁ´•ËøëË¶ñÊßãÊàêÂÖ®ÁêÉÈáçË¶ÅÁöÑÂÅ•Â∫∑ÂïèÈ°å„ÄÇÂÆÉÈ°ØÁ§∫Âá∫Êó•ÁõäÂ¢ûÂä†ÁöÑÁõõË°åÁéáÔºå‰∏¶ÂèØËÉΩÊºîËÆäÊàêÂö¥Èáç„ÄÅ‰∏çÂèØÈÄÜËΩâÁöÑÁãÄÊ≥ÅÔºåÂ∞çÂÆ∂Â∫≠Á¶èÁ•âÈÄ†Êàê‰∏çÂà©ÂΩ±ÈüøÔºå‰∏¶Áî¢ÁîüÂ§ßÈáèÁöÑÁ∂ìÊøüÊàêÊú¨„ÄÇÁèæ‰ª£Á†îÁ©∂Âº∑Ë™øÁ≤æÊ∫ñÈ†êÊ∏¨ËøëË¶ñÈÄ≤Â±ïÁöÑÈáçË¶ÅÊÄßÔºå‰ª•ÂØ¶ÁèæÂèäÊôÇÊúâÊïàÁöÑÂπ≤È†êÔºåÂæûËÄåÈÅøÂÖçÂÖíÁ´•Âá∫ÁèæÂö¥ÈáçÁöÑË¶ñÂäõÊêçÂÆ≥„ÄÇÊ≠§È°ûÈ†êÊ∏¨‰∏ªË¶Å‰æùË≥¥‰∏ªËßÄÁöÑËá®Â∫äË©ï‰º∞ÔºåÂÖ∂Êú¨Ë∫´ÂÖ∑ÊúâÂÅèË¶ã‰∏îË≥áÊ∫êÂØÜÈõÜÔºåÂæûËÄåÈòªÁ§ô‰∫ÜÂÆÉÂÄëÁöÑÂª£Ê≥õÊáâÁî®„ÄÇÂú®Êú¨Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©é„ÄÅÈ´òÁ≤æÁ¢∫Â∫¶ÁöÑÊñπÊ≥ïÔºåÂÉÖ‰ΩøÁî®ÁúºÂ∫ïÂúñÂÉèÂíåÂü∫Á∑öÂ±àÂÖâÊï∏ÊìöÔºåÂ∞±ËÉΩÂÆöÈáèÈ†êÊ∏¨ÂÖíÁ´•ÁöÑËøëË¶ñËªåË∑°ÂíåËøëË¶ñÈ¢®Èö™„ÄÇÈÄôÁ®ÆÊñπÊ≥ïÈÄöÈÅéÂ∞çÊ≤≥ÂçóÁúÅ 3,408 ÂêçÂÖíÁ´•ÈÄ≤Ë°åÁÇ∫ÊúüÂÖ≠Âπ¥ÁöÑÁ∏±ÂêëÁ†îÁ©∂ÔºåÂà©Áî® 16,211 ÂºµÁúºÂ∫ïÂúñÂÉèÂíåÁõ∏ÊáâÁöÑÂ±àÂÖâÊï∏ÊìöÈÄ≤Ë°å‰∫ÜÈ©óË≠â„ÄÇÊàëÂÄëÂü∫ÊñºÊ∑±Â∫¶Â≠∏ÁøíÁöÑÊñπÊ≥ïÂ±ïÁ§∫‰∫ÜÈ†êÊ∏¨Ê∫ñÁ¢∫Â∫¶ÔºåÂπ¥Ë™§Â∑ÆÁØÑÂúçÁÇ∫ 0.311DÔºåÈ†êÊ∏¨ÁôºÁîüËøëË¶ñÂíåÈ´òÂ∫¶ËøëË¶ñÁöÑÈ¢®Èö™ÁöÑ AUC ÂàÜÊï∏ÂàÜÂà•ÁÇ∫ 0.944 Âíå 0.995„ÄÇÈÄô‰∫õÁôºÁèæË≠âÂØ¶‰∫ÜÊàëÂÄëÁöÑÊ®°ÂûãÂú®ÊîØÊåÅÊó©ÊúüÂπ≤È†êÁ≠ñÁï•ÂíåÈ°ØËëóÈôç‰ΩéÈÜ´ÁôÇ‰øùÂÅ•ÊàêÊú¨ÊñπÈù¢ÁöÑÊïàÁî®ÔºåÁâπÂà•ÊòØÈÄöÈÅéÊ∂àÈô§Â∞çÈ°çÂ§ñÂÖÉÊï∏ÊìöÂíåÈáçË§áË´ÆË©¢ÁöÑÈúÄË¶Å„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁöÑÊñπÊ≥ïË¢´Ë®≠Ë®àÁÇ∫ÂÉÖ‰æùË≥¥ÁúºÂ∫ïÂúñÂÉèÂíåÂ±àÂÖâ‰∏çÊ≠£Êï∏ÊìöÔºåËÄåÁÑ°ÈúÄÂÖÉÊï∏ÊìöÊàñÈÜ´ÁîüÁöÑÂ§öÊ¨°Ë©¢ÂïèÔºåÂæûËÄåÂ§ßÂ§ßÈôç‰Ωé‰∫ÜÁõ∏ÈóúÁöÑÈÜ´ÁôÇÊàêÊú¨Ôºå‰∏¶‰øÉÈÄ≤‰∫ÜÂ§ßË¶èÊ®°ÁØ©Êü•„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÁîöËá≥ÂèØ‰ª•ÂÉÖÊ†πÊìöÂñÆÊ¨°ÊôÇÈñìÊ∏¨ÈáèÊèê‰æõËâØÂ•ΩÁöÑÈ†êÊ∏¨„ÄÇÂõ†Ê≠§ÔºåÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÊòØÊ∏õÂ∞ëÁî±Á∂ìÊøüÂ∑ÆË∑ùÈÄ†ÊàêÁöÑÈÜ´ÁôÇ‰∏çÂπ≥Á≠âÁöÑÈáçË¶ÅÊâãÊÆµ„ÄÇ

##### **Prompting Medical Large Vision-Language Models to Diagnose Pathologies by Visual Question Answering**
2407.21368v1 by Danfeng Guo, Demetri Terzopoulos

Large Vision-Language Models (LVLMs) have achieved significant success in
recent years, and they have been extended to the medical domain. Although
demonstrating satisfactory performance on medical Visual Question Answering
(VQA) tasks, Medical LVLMs (MLVLMs) suffer from the hallucination problem,
which makes them fail to diagnose complex pathologies. Moreover, they readily
fail to learn minority pathologies due to imbalanced training data. We propose
two prompting strategies for MLVLMs that reduce hallucination and improve VQA
performance. In the first strategy, we provide a detailed explanation of the
queried pathology. In the second strategy, we fine-tune a cheap, weak learner
to achieve high performance on a specific metric, and textually provide its
judgment to the MLVLM. Tested on the MIMIC-CXR-JPG and Chexpert datasets, our
methods significantly improve the diagnostic F1 score, with the highest
increase being 0.27. We also demonstrate that our prompting strategies can be
extended to general LVLM domains. Based on POPE metrics, it effectively
suppresses the false negative predictions of existing LVLMs and improves Recall
by approximately 0.07.

ÊëòË¶ÅÔºöÂ§ßÂûãË¶ñË¶∫Ë™ûË®ÄÊ®°Âûã (LVLMs) Âú®ËøëÂπ¥‰æÜÂèñÂæóÈ°ØËëóÁöÑÊàêÂäüÔºå‰∏¶Â∑≤Êì¥Â±ïÂà∞ÈÜ´ÁôÇÈ†òÂüü„ÄÇÂÑòÁÆ°Âú®ÈÜ´Â≠∏Ë¶ñË¶∫ÂïèÁ≠î (VQA) ‰ªªÂãô‰∏≠Ë°®Áèæ‰ª§‰∫∫ÊªøÊÑèÔºå‰ΩÜÈÜ´Â≠∏ LVLMs (MLVLMs) ‰ªçÂ≠òÂú®ÂπªË¶∫ÂïèÈ°åÔºåÂ∞éËá¥ÂÆÉÂÄëÁÑ°Ê≥ïË®∫Êñ∑Âá∫Ë§áÈõúÁöÑÁóÖÁêÜ„ÄÇÊ≠§Â§ñÔºåÁî±ÊñºË®ìÁ∑¥Ë≥áÊñô‰∏çÂπ≥Ë°°ÔºåÂÆÉÂÄëÂæàÂÆπÊòìÁÑ°Ê≥ïÂ≠∏ÁøíÂ∞ëÊï∏ÁóÖÁêÜ„ÄÇÊàëÂÄëÊèêÂá∫ÂÖ©Á®ÆÈáùÂ∞ç MLVLMs ÁöÑÊèêÁ§∫Á≠ñÁï•Ôºå‰ª•Ê∏õÂ∞ëÂπªË¶∫‰∏¶ÊîπÂñÑ VQA ÊïàËÉΩ„ÄÇÂú®Á¨¨‰∏ÄÂÄãÁ≠ñÁï•‰∏≠ÔºåÊàëÂÄëÊèê‰æõÊü•Ë©¢ÁóÖÁêÜÁöÑË©≥Á¥∞Ë™™Êòé„ÄÇÂú®Á¨¨‰∫åÂÄãÁ≠ñÁï•‰∏≠ÔºåÊàëÂÄëÂæÆË™ø‰∏ÄÂÄã‰æøÂÆú„ÄÅÊïàËÉΩ‰∏ç‰Ω≥ÁöÑÂ≠∏ÁøíÂô®Ôºå‰ª•Âú®ÁâπÂÆöÊåáÊ®ô‰∏äÁç≤ÂæóÈ´òÊïàËÉΩÔºå‰∏¶‰ª•ÊñáÂ≠óÊñπÂºèÂêë MLVLM Êèê‰æõÂÖ∂Âà§Êñ∑„ÄÇÂú® MIMIC-CXR-JPG Âíå Chexpert Ë≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÊ∏¨Ë©¶ÂæåÔºåÊàëÂÄëÁöÑÊ®°ÂûãÈ°ØËëóÊîπÂñÑ‰∫ÜË®∫Êñ∑ F1 ÂàÜÊï∏ÔºåÊúÄÈ´òÊèêÂçáÂπÖÂ∫¶ÁÇ∫ 0.27„ÄÇÊàëÂÄëÈÇÑÂ±ïÁ§∫‰∫ÜÊàëÂÄëÁöÑÊèêÁ§∫Á≠ñÁï•ÂèØ‰ª•Êì¥Â±ïÂà∞‰∏ÄËà¨ÁöÑ LVLM È†òÂüü„ÄÇÊ†πÊìö POPE ÊåáÊ®ôÔºåÂÆÉÊúâÊïàÂú∞ÊäëÂà∂‰∫ÜÁèæÊúâ LVLMs ÁöÑÂÅáÈô∞ÊÄßÈ†êÊ∏¨Ôºå‰∏¶Â∞áÂè¨ÂõûÁéáÊèêÈ´ò‰∫ÜÁ¥Ñ 0.07„ÄÇ

##### **MIST: A Simple and Scalable End-To-End 3D Medical Imaging Segmentation Framework**
2407.21343v1 by Adrian Celaya, Evan Lim, Rachel Glenn, Brayden Mi, Alex Balsells, Tucker Netherton, Caroline Chung, Beatrice Riviere, David Fuentes

Medical imaging segmentation is a highly active area of research, with deep
learning-based methods achieving state-of-the-art results in several
benchmarks. However, the lack of standardized tools for training, testing, and
evaluating new methods makes the comparison of methods difficult. To address
this, we introduce the Medical Imaging Segmentation Toolkit (MIST), a simple,
modular, and end-to-end medical imaging segmentation framework designed to
facilitate consistent training, testing, and evaluation of deep learning-based
medical imaging segmentation methods. MIST standardizes data analysis,
preprocessing, and evaluation pipelines, accommodating multiple architectures
and loss functions. This standardization ensures reproducible and fair
comparisons across different methods. We detail MIST's data format
requirements, pipelines, and auxiliary features and demonstrate its efficacy
using the BraTS Adult Glioma Post-Treatment Challenge dataset. Our results
highlight MIST's ability to produce accurate segmentation masks and its
scalability across multiple GPUs, showcasing its potential as a powerful tool
for future medical imaging research and development.

ÊëòË¶ÅÔºöÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÂâ≤ÊòØ‰∏ÄÂÄãÈ´òÂ∫¶Ê¥ªË∫çÁöÑÁ†îÁ©∂È†òÂüüÔºåÊ∑±Â∫¶Â≠∏ÁøíÊñπÊ≥ïÂú®Â§öÂÄãÂü∫Ê∫ñÊ∏¨Ë©¶‰∏≠ÂèñÂæó‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÊàêÊûú„ÄÇÁÑ∂ËÄåÔºåÁº∫‰πèÊ®ôÊ∫ñÂåñÁöÑË®ìÁ∑¥„ÄÅÊ∏¨Ë©¶ÂíåË©ï‰º∞Êñ∞ÊñπÊ≥ïÁöÑÂ∑•ÂÖ∑Ôºå‰ΩøÂæóÊñπÊ≥ïÁöÑÊØîËºÉËÆäÂæóÂõ∞Èõ£„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÂâ≤Â∑•ÂÖ∑ÂåÖ (MIST)Ôºå‰∏ÄÂÄãÁ∞°ÂñÆ„ÄÅÊ®°ÁµÑÂåñÂíåÁ´ØÂ∞çÁ´ØÁöÑÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÂâ≤Ê°ÜÊû∂ÔºåÊó®Âú®‰øÉÈÄ≤Âü∫ÊñºÊ∑±Â∫¶Â≠∏ÁøíÁöÑÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÂâ≤ÊñπÊ≥ïÁöÑ‰∏ÄËá¥Ë®ìÁ∑¥„ÄÅÊ∏¨Ë©¶ÂíåË©ï‰º∞„ÄÇMIST Ê®ôÊ∫ñÂåñ‰∫ÜÊï∏ÊìöÂàÜÊûê„ÄÅÈ†êËôïÁêÜÂíåË©ï‰º∞ÁÆ°ÈÅìÔºåÂÆπÁ¥çÂ§öÁ®ÆÊû∂ÊßãÂíåÊêçÂ§±ÂáΩÊï∏„ÄÇÈÄôÁ®ÆÊ®ôÊ∫ñÂåñÁ¢∫‰øù‰∫Ü‰∏çÂêåÊñπÊ≥ï‰πãÈñìÂèØÈáçÁèæ‰∏îÂÖ¨Âπ≥ÁöÑÊØîËºÉ„ÄÇÊàëÂÄëË©≥Á¥∞Ë™™Êòé‰∫Ü MIST ÁöÑÊï∏ÊìöÊ†ºÂºèË¶ÅÊ±Ç„ÄÅÁÆ°ÈÅìÂíåËºîÂä©ÂäüËÉΩÔºå‰∏¶‰ΩøÁî® BraTS Êàê‰∫∫Á•ûÁ∂ìËÜ†Ë≥™Áò§Ê≤ªÁôÇÂæåÊåëÊà∞Êï∏ÊìöÈõÜÂ±ïÁ§∫‰∫ÜÂÆÉÁöÑÂäüÊïà„ÄÇÊàëÂÄëÁöÑÁµêÊûúÁ™ÅÈ°Ø‰∫Ü MIST Áî¢ÁîüÊ∫ñÁ¢∫ÂàÜÂâ≤ÈÅÆÁΩ©ÁöÑËÉΩÂäõ‰ª•ÂèäÂÆÉË∑®Â§öÂÄã GPU ÁöÑÂèØÊì¥Â±ïÊÄßÔºåÂ±ïÁ§∫‰∫ÜÂÆÉ‰ΩúÁÇ∫Êú™‰æÜÈÜ´Â≠∏ÂΩ±ÂÉèÁ†îÁ©∂ÂíåÈñãÁôºÁöÑÊúâÂäõÂ∑•ÂÖ∑ÁöÑÊΩõÂäõ„ÄÇ

##### **Patient-centered data science: an integrative framework for evaluating and predicting clinical outcomes in the digital health era**
2408.02677v1 by Mohsen Amoei, Dan Poenaru

This study proposes a novel, integrative framework for patient-centered data
science in the digital health era. We developed a multidimensional model that
combines traditional clinical data with patient-reported outcomes, social
determinants of health, and multi-omic data to create comprehensive digital
patient representations. Our framework employs a multi-agent artificial
intelligence approach, utilizing various machine learning techniques including
large language models, to analyze complex, longitudinal datasets. The model
aims to optimize multiple patient outcomes simultaneously while addressing
biases and ensuring generalizability. We demonstrate how this framework can be
implemented to create a learning healthcare system that continuously refines
strategies for optimal patient care. This approach has the potential to
significantly improve the translation of digital health innovations into
real-world clinical benefits, addressing current limitations in AI-driven
healthcare models.

ÊëòË¶ÅÔºöÊú¨Á†îÁ©∂ÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂâµÊñ∞ÁöÑ„ÄÅÊï¥ÂêàÊÄßÁöÑÊû∂ÊßãÔºåÁî®ÊñºÊï∏‰ΩçÂÅ•Â∫∑ÊôÇ‰ª£ÁöÑ‰ª•ÊÇ£ËÄÖÁÇ∫‰∏≠ÂøÉÁöÑË≥áÊñôÁßëÂ≠∏„ÄÇÊàëÂÄëÈñãÁôº‰∫Ü‰∏ÄÂÄãÂ§öÈù¢ÂêëÊ®°ÂûãÔºåÁµêÂêàÂÇ≥Áµ±ÁöÑËá®Â∫äË≥áÊñô„ÄÅÊÇ£ËÄÖÂõûÂ†±ÁöÑÁµêÊûú„ÄÅÂÅ•Â∫∑ÁöÑÁ§æÊúÉÊ±∫ÂÆöÂõ†Á¥†ÂíåÂ§öÁµÑÂ≠∏Ë≥áÊñôÔºå‰ª•Âª∫Á´ãÂÖ®Èù¢ÁöÑÊï∏‰ΩçÊÇ£ËÄÖË°®Âæµ„ÄÇÊàëÂÄëÁöÑÊû∂ÊßãÊé°Áî®Â§ö‰∏ªÈ´î‰∫∫Â∑•Êô∫ÊÖßÊñπÊ≥ïÔºåÂà©Áî®ÂêÑÁ®ÆÊ©üÂô®Â≠∏ÁøíÊäÄË°ìÔºåÂåÖÊã¨Â§ßÂûãË™ûË®ÄÊ®°ÂûãÔºå‰æÜÂàÜÊûêË§áÈõúÁöÑÁ∏±ÂêëË≥áÊñôÈõÜ„ÄÇË©≤Ê®°ÂûãÊó®Âú®ÂêåÊôÇÊúÄ‰Ω≥ÂåñÂ§öÂÄãÊÇ£ËÄÖÁµêÊûúÔºåÂêåÊôÇËß£Ê±∫ÂÅèÂ∑Æ‰∏¶Á¢∫‰øùÂèØÊ¶ÇÂåñÊÄß„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫ÜÂ¶Ç‰ΩïÂØ¶‰ΩúÊ≠§Êû∂ÊßãÔºå‰ª•Âª∫Á´ã‰∏ÄÂÄãÊåÅÁ∫åÂÑ™ÂåñÊúÄ‰Ω≥ÊÇ£ËÄÖÁÖßË≠∑Á≠ñÁï•ÁöÑÂ≠∏ÁøíÂûãÈÜ´ÁôÇ‰øùÂÅ•Á≥ªÁµ±„ÄÇÊ≠§ÊñπÊ≥ïÊúâÂèØËÉΩÈ°ØËëóÊîπÂñÑÊï∏‰ΩçÂÅ•Â∫∑ÂâµÊñ∞ÁöÑËΩâË≠ØÔºå‰ΩøÂÖ∂ÊàêÁÇ∫ÁúüÂØ¶‰∏ñÁïåÁöÑËá®Â∫äÊïàÁõäÔºåËß£Ê±∫ AI È©ÖÂãïÁöÑÈÜ´ÁôÇ‰øùÂÅ•Ê®°Âûã‰∏≠ÁöÑÁï∂ÂâçÈôêÂà∂„ÄÇ

##### **Robust Box Prompt based SAM for Medical Image Segmentation**
2407.21284v1 by Yuhao Huang, Xin Yang, Han Zhou, Yan Cao, Haoran Dou, Fajin Dong, Dong Ni

The Segment Anything Model (SAM) can achieve satisfactory segmentation
performance under high-quality box prompts. However, SAM's robustness is
compromised by the decline in box quality, limiting its practicality in
clinical reality. In this study, we propose a novel Robust Box prompt based SAM
(\textbf{RoBox-SAM}) to ensure SAM's segmentation performance under prompts
with different qualities. Our contribution is three-fold. First, we propose a
prompt refinement module to implicitly perceive the potential targets, and
output the offsets to directly transform the low-quality box prompt into a
high-quality one. We then provide an online iterative strategy for further
prompt refinement. Second, we introduce a prompt enhancement module to
automatically generate point prompts to assist the box-promptable segmentation
effectively. Last, we build a self-information extractor to encode the prior
information from the input image. These features can optimize the image
embeddings and attention calculation, thus, the robustness of SAM can be
further enhanced. Extensive experiments on the large medical segmentation
dataset including 99,299 images, 5 modalities, and 25 organs/targets validated
the efficacy of our proposed RoBox-SAM.

ÊëòË¶ÅÔºöÂàÜÊÆµ‰ªª‰ΩïÊ®°Âûã (SAM) ÂèØ‰ª•Âú®È´òË¥®ÈáèÊ°ÜÊèêÁ§∫‰∏ãÂÆûÁé∞‰ª§‰∫∫Êª°ÊÑèÁöÑÂàÜÊÆµÊÄßËÉΩ„ÄÇÁÑ∂ËÄåÔºåSAM ÁöÑÈ≤ÅÊ£íÊÄßÂõ†Ê°ÜË¥®ÈáèÁöÑ‰∏ãÈôçËÄåÂèóÂà∞ÊçüÂÆ≥ÔºåÈôêÂà∂‰∫ÜÂÖ∂Âú®‰∏¥Â∫äÁé∞ÂÆû‰∏≠ÁöÑÂÆûÁî®ÊÄß„ÄÇÂú®ËøôÈ°πÁ†îÁ©∂‰∏≠ÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏Ä‰∏™Âü∫‰∫é SAM ÁöÑÊñ∞ÂûãÈ≤ÅÊ£íÊ°ÜÊèêÁ§∫Ôºà**RoBox-SAM**ÔºâÔºå‰ª•Á°Æ‰øù SAM Âú®ÂÖ∑Êúâ‰∏çÂêåË¥®ÈáèÁöÑÊèêÁ§∫‰∏ãÁöÑÂàÜÊÆµÊÄßËÉΩ„ÄÇÊàë‰ª¨ÁöÑË¥°ÁåÆÊòØ‰∏âÊñπÈù¢ÁöÑ„ÄÇÈ¶ñÂÖàÔºåÊàë‰ª¨ÊèêÂá∫‰∏Ä‰∏™ÊèêÁ§∫‰ºòÂåñÊ®°ÂùóÔºå‰ª•ÈöêÂºèÊÑüÁü•ÊΩúÂú®ÁõÆÊ†áÔºåÂπ∂ËæìÂá∫ÂÅèÁßªÈáèÔºå‰ª•Áõ¥Êé•Â∞Ü‰ΩéË¥®ÈáèÊ°ÜÊèêÁ§∫ËΩ¨Êç¢‰∏∫È´òË¥®ÈáèÊèêÁ§∫„ÄÇÁÑ∂ÂêéÔºåÊàë‰ª¨Êèê‰æõ‰∫Ü‰∏Ä‰∏™Âú®Á∫øËø≠‰ª£Á≠ñÁï•Ôºå‰ª•‰æøËøõ‰∏ÄÊ≠•‰ºòÂåñÊèêÁ§∫„ÄÇÂÖ∂Ê¨°ÔºåÊàë‰ª¨ÂºïÂÖ•‰∫Ü‰∏Ä‰∏™ÊèêÁ§∫Â¢ûÂº∫Ê®°ÂùóÔºå‰ª•Ëá™Âä®ÁîüÊàêÁÇπÊèêÁ§∫Ôºå‰ª•ÊúâÊïàÂú∞ËæÖÂä©Ê°ÜÊèêÁ§∫ÂàÜÊÆµ„ÄÇÊúÄÂêéÔºåÊàë‰ª¨ÊûÑÂª∫‰∫Ü‰∏Ä‰∏™Ëá™‰ø°ÊÅØÊèêÂèñÂô®Ôºå‰ª•ÂØπÊù•Ëá™ËæìÂÖ•ÂõæÂÉèÁöÑÂÖàÈ™å‰ø°ÊÅØËøõË°åÁºñÁ†Å„ÄÇËøô‰∫õÁâπÂæÅÂèØ‰ª•‰ºòÂåñÂõæÂÉèÂµåÂÖ•ÂíåÊ≥®ÊÑèÂäõËÆ°ÁÆóÔºåÂõ†Ê≠§ÔºåÂèØ‰ª•Ëøõ‰∏ÄÊ≠•Â¢ûÂº∫ SAM ÁöÑÈ≤ÅÊ£íÊÄß„ÄÇÂú®ÂåÖÊã¨ 99,299 Âº†ÂõæÂÉè„ÄÅ5 ÁßçÊñπÂºèÂíå 25 ‰∏™Âô®ÂÆò/ÁõÆÊ†áÁöÑÂ§ßÂûãÂåªÂ≠¶ÂàÜÊÆµÊï∞ÊçÆÈõÜ‰∏äËøõË°åÁöÑÂπøÊ≥õÂÆûÈ™åÈ™åËØÅ‰∫ÜÊàë‰ª¨ÊèêÂá∫ÁöÑ RoBox-SAM ÁöÑÂäüÊïà„ÄÇ

##### **Unlocking the Potential of Binding Corporate Rules (BCRs) in Health Data Transfers**
2407.21281v1 by Marcelo Corrales Compagnucci, Mark Fenwick, Helena Haapio

This chapter explores the essential role of Binding Corporate Rules (BCRs) in
managing and facilitating secure health data transfers within corporate groups
under the EU General Data Protection Regulation (GDPR). BCRs are tailored to
ensure compliance with the GDPR and similar international data protection laws,
presenting a flexible mechanism for transferring sensitive health and genomic
data. The chapter situates BCRs within the broader spectrum of the GDPR
international data transfer mechanisms, addressing the unique challenges posed
by the sensitive nature of health data and the increased adoption of AI
technologies. The European Data Protection Board (EDPB) Recommendations 1/2022
on BCRs, issued following the Schrems II decision, are critically analyzed,
highlighting their stringent requirements and the need for a balanced approach
that prioritizes data protection and an AI governance framework. The chapter
outlines the BCR approval process, stressing the importance of streamlining
this process to encourage broader adoption. It underscores the necessity of a
multidisciplinary approach in developing BCRs, incorporating recently adopted
international standards and frameworks, which offer valuable guidance for
organizations to build trustworthy AI management systems. They guarantee the
ethical development, deployment, and operation of AI, which is essential for
its successful integration and the broader digital transformation. In
conclusion, BCRs are positioned as essential tools for secure health data
management, fostering transparency, accountability, and collaboration across
international borders. The chapter calls for proactive measures to incentivize
BCR adoption, streamline approval processes, and promote more innovative
approaches, ensuring BCRs remain a robust mechanism for global data protection
and compliance.

ÊëòË¶ÅÔºö<paragraph>Ê≠§Á´†Êé¢Ë®éÁ¥ÑÊùü‰ºÅÊ•≠Ë¶èÂâá (BCR) Âú®Ê≠êÁõü‰∏ÄËà¨Ë≥áÊñô‰øùË≠∑Ê¢ù‰æã (GDPR) ‰∏ãÁÆ°ÁêÜÂíå‰øÉÈÄ≤‰ºÅÊ•≠ÈõÜÂúòÂÖßÈÉ®ÂÆâÂÖ®ÂÅ•Â∫∑Ë≥áÊñôÂÇ≥Ëº∏ÁöÑÂü∫Êú¨ËßíËâ≤„ÄÇBCR Â∞àÈñÄÁî®ÊñºÁ¢∫‰øùÁ¨¶Âêà GDPR ÂíåÈ°û‰ººÁöÑÂúãÈöõË≥áÊñô‰øùË≠∑Ê≥ïÔºåÊèê‰æõÂÇ≥Ëº∏ÊïèÊÑüÂÅ•Â∫∑ÂíåÂü∫Âõ†ÁµÑË≥áÊñôÁöÑÂΩàÊÄßÊ©üÂà∂„ÄÇÊ≠§Á´†Â∞á BCR ÂÆö‰ΩçÂú® GDPR ÂúãÈöõË≥áÊñôÂÇ≥Ëº∏Ê©üÂà∂ÁöÑÊõ¥Âª£Ê≥õÁØÑÂúçÂÖßÔºåËß£Ê±∫ÂÅ•Â∫∑Ë≥áÊñôÊïèÊÑüÊÄßË≥™Âíå AI ÊäÄË°ìÊé°Áî®Â¢ûÂä†ÊâÄÂ∏∂‰æÜÁöÑÁç®ÁâπÊåëÊà∞„ÄÇÊ≠êÊ¥≤Ë≥áÊñô‰øùË≠∑ÂßîÂì°ÊúÉ (EDPB) Âú® Schrems II Ê±∫ÂÆöÂæåÁôºÂ∏ÉÁöÑ BCR Âª∫Ë≠∞ 1/2022 ÂèóÂà∞Âö¥Ê†ºÂàÜÊûêÔºåÂº∑Ë™øÂÖ∂Âö¥Ê†ºË¶ÅÊ±ÇÂíåÂπ≥Ë°°ÊñπÊ≥ïÁöÑÂøÖË¶ÅÊÄßÔºåË©≤ÊñπÊ≥ïÂÑ™ÂÖàËÄÉÊÖÆË≥áÊñô‰øùË≠∑Âíå AI Ê≤ªÁêÜÊû∂Êßã„ÄÇÊ≠§Á´†Ê¶ÇËø∞ BCR Ê†∏ÂáÜÁ®ãÂ∫èÔºåÂº∑Ë™øÁ∞°ÂåñÊ≠§Á®ãÂ∫è‰ª•ÈºìÂãµÊõ¥Âª£Ê≥õÊé°Áî®ÁöÑÈáçË¶ÅÊÄß„ÄÇÂÆÉÂº∑Ë™øÂú®ÈñãÁôº BCR ÊôÇÊé°Áî®Â§öÂ≠∏ÁßëÊñπÊ≥ïÁöÑÂøÖË¶ÅÊÄßÔºåÂåÖÊã¨ÊúÄËøëÊé°Áî®ÁöÑÂúãÈöõÊ®ôÊ∫ñÂíåÊû∂ÊßãÔºåÈÄô‰∫õÊ®ôÊ∫ñÂíåÊû∂ÊßãÁÇ∫ÁµÑÁπîÂª∫Á´ãÂèØ‰ø°Ë≥¥ÁöÑ AI ÁÆ°ÁêÜÁ≥ªÁµ±Êèê‰æõ‰∫ÜÂØ∂Ë≤¥ÁöÑÊåáÂ∞é„ÄÇÂÆÉÂÄë‰øùË≠â AI ÁöÑÈÅìÂæ∑ÈñãÁôº„ÄÅÈÉ®ÁΩ≤ÂíåÈÅã‰ΩúÔºåÈÄôÂ∞çÂÖ∂ÊàêÂäüÊï¥ÂêàÂíåÊõ¥Âª£Ê≥õÁöÑÊï∏‰ΩçËΩâÂûãËá≥ÈóúÈáçË¶Å„ÄÇÁµêË´ñÊòØÔºåBCR Ë¢´ÂÆö‰ΩçÁÇ∫ÂÆâÂÖ®ÂÅ•Â∫∑Ë≥áÊñôÁÆ°ÁêÜÁöÑÂü∫Êú¨Â∑•ÂÖ∑Ôºå‰øÉÈÄ≤Ë∑®ÂúãÁïåÁöÑÈÄèÊòéÂ∫¶„ÄÅÂïèË≤¨Âà∂ÂíåÂçî‰Ωú„ÄÇÊ≠§Á´†ÂëºÁ±≤Êé°ÂèñÁ©çÊ•µÊé™ÊñΩ‰æÜÊøÄÂãµ BCR Êé°Áî®„ÄÅÁ∞°ÂåñÊ†∏ÂáÜÁ®ãÂ∫èÔºå‰∏¶‰øÉÈÄ≤Êõ¥ÂÖ∑ÂâµÊñ∞ÁöÑÊñπÊ≥ïÔºåÁ¢∫‰øù BCR ‰ªçÁÑ∂ÊòØÂÖ®ÁêÉË≥áÊñô‰øùË≠∑ÂíåÂêàË¶èÊÄßÁöÑÂº∑Â§ßÊ©üÂà∂„ÄÇ</paragraph>

##### **FreqTSF: Time Series Forecasting Via Simulating Frequency Kramer-Kronig Relations**
2407.21275v1 by Rujia Shen, Liangliang Liu, Boran Wang, Yi Guan, Yang Yang, Jingchi Jiang

Time series forecasting (TSF) is immensely important in extensive
applications, such as electricity transformation, financial trade, medical
monitoring, and smart agriculture. Although Transformer-based methods can
handle time series data, their ability to predict long-term time series is
limited due to the ``anti-order" nature of the self-attention mechanism. To
address this problem, we focus on frequency domain to weaken the impact of
order in TSF and propose the FreqBlock, where we first obtain frequency
representations through the Frequency Transform Module. Subsequently, a newly
designed Frequency Cross Attention is used to obtian enhanced frequency
representations between the real and imaginary parts, thus establishing a link
between the attention mechanism and the inherent Kramer-Kronig relations
(KKRs). Our backbone network, FreqTSF, adopts a residual structure by
concatenating multiple FreqBlocks to simulate KKRs in the frequency domain and
avoid degradation problems. On a theoretical level, we demonstrate that the
proposed two modules can significantly reduce the time and memory complexity
from $\mathcal{O}(L^2)$ to $\mathcal{O}(L)$ for each FreqBlock computation.
Empirical studies on four benchmark datasets show that FreqTSF achieves an
overall relative MSE reduction of 15\% and an overall relative MAE reduction of
11\% compared to the state-of-the-art methods. The code will be available soon.

ÊëòË¶ÅÔºöÊôÇÈñìÂ∫èÂàóÈ†êÊ∏¨ (TSF) Âú®Âª£Ê≥õÁöÑÊáâÁî®‰∏≠ÈùûÂ∏∏ÈáçË¶ÅÔºå‰æãÂ¶ÇÈõªÂäõËΩâÊèõ„ÄÅÈáëËûç‰∫§Êòì„ÄÅÈÜ´ÁôÇÁõ£ÊéßÂíåÊô∫ÊÖßËæ≤Ê•≠„ÄÇÈõñÁÑ∂Âü∫Êñº Transformer ÁöÑÊñπÊ≥ïÂèØ‰ª•ËôïÁêÜÊôÇÈñìÂ∫èÂàóË≥áÊñôÔºå‰ΩÜÁî±ÊñºËá™Ê≥®ÊÑèÂäõÊ©üÂà∂ÁöÑ„ÄåÂèçÂ∫è„ÄçÁâπÊÄßÔºåÂÆÉÂÄëÈ†êÊ∏¨Èï∑ÊúüÊôÇÈñìÂ∫èÂàóÁöÑËÉΩÂäõÂèóÂà∞ÈôêÂà∂„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÂ∞àÊ≥®ÊñºÈ†ªÂüü‰ª•Ê∏õÂº± TSF ‰∏≠È†ÜÂ∫èÁöÑÂΩ±ÈüøÔºå‰∏¶ÊèêÂá∫ FreqBlockÔºåÊàëÂÄëÈ¶ñÂÖàÈÄèÈÅéÈ†ªÁéáËΩâÊèõÊ®°ÁµÑÂèñÂæóÈ†ªÁéáË°®Á§∫„ÄÇÈö®ÂæåÔºå‰ΩøÁî®Êñ∞Ë®≠Ë®àÁöÑÈ†ªÁéá‰∫§ÂèâÊ≥®ÊÑèÂäõ‰æÜÁç≤ÂæóÂØ¶ÈÉ®ÂíåËôõÈÉ®‰πãÈñìÂ¢ûÂº∑ÁöÑÈ†ªÁéáË°®Á§∫ÔºåÂæûËÄåÂª∫Á´ãÊ≥®ÊÑèÂäõÊ©üÂà∂ÂíåÂõ∫Êúâ Kramer-Kronig Èóú‰øÇ (KKR) ‰πãÈñìÁöÑÈÄ£Áµê„ÄÇÊàëÂÄëÁöÑÈ™®ÂππÁ∂≤Ë∑Ø FreqTSF Êé°Áî®ÊÆòÂ∑ÆÁµêÊßãÔºåÈÄèÈÅé‰∏≤Êé•Â§öÂÄã FreqBlock ‰æÜÊ®°Êì¨È†ªÂüü‰∏≠ÁöÑ KKR ‰∏¶ÈÅøÂÖçÈÄÄÂåñÂïèÈ°å„ÄÇÂú®ÁêÜË´ñÂ±§Èù¢‰∏äÔºåÊàëÂÄëË≠âÊòéÊâÄÊèêÂá∫ÁöÑÂÖ©ÂÄãÊ®°ÁµÑÂèØ‰ª•È°ØËëóÈôç‰ΩéÊØèÂÄã FreqBlock Ë®àÁÆóÁöÑÊôÇÈñìÂíåË®òÊÜ∂È´îË§áÈõúÂ∫¶ÔºåÂæû $\mathcal{O}(L^2)$ Èôç‰ΩéÂà∞ $\mathcal{O}(L)$„ÄÇÂú®ÂõõÂÄãÂü∫Ê∫ñË≥áÊñôÈõÜ‰∏äÁöÑÂØ¶Ë≠âÁ†îÁ©∂È°ØÁ§∫ÔºåËàáÊúÄÂÖàÈÄ≤ÁöÑÊñπÊ≥ïÁõ∏ÊØîÔºåFreqTSF ÁöÑÊï¥È´îÁõ∏Â∞ç MSE Èôç‰Ωé 15%ÔºåÊï¥È´îÁõ∏Â∞ç MAE Èôç‰Ωé 11%„ÄÇÁ®ãÂºèÁ¢ºÂ∞áÂæàÂø´Êé®Âá∫„ÄÇ

##### **Enhanced Uncertainty Estimation in Ultrasound Image Segmentation with MSU-Net**
2407.21273v1 by Rohini Banerjee, Cecilia G. Morales, Artur Dubrawski

Efficient intravascular access in trauma and critical care significantly
impacts patient outcomes. However, the availability of skilled medical
personnel in austere environments is often limited. Autonomous robotic
ultrasound systems can aid in needle insertion for medication delivery and
support non-experts in such tasks. Despite advances in autonomous needle
insertion, inaccuracies in vessel segmentation predictions pose risks.
Understanding the uncertainty of predictive models in ultrasound imaging is
crucial for assessing their reliability. We introduce MSU-Net, a novel
multistage approach for training an ensemble of U-Nets to yield accurate
ultrasound image segmentation maps. We demonstrate substantial improvements,
18.1% over a single Monte Carlo U-Net, enhancing uncertainty evaluations, model
transparency, and trustworthiness. By highlighting areas of model certainty,
MSU-Net can guide safe needle insertions, empowering non-experts to accomplish
such tasks.

ÊëòË¶ÅÔºöÂú®ÂâµÂÇ∑ÂíåÈáçÁóáÁÖßË≠∑‰∏≠ÔºåÊúâÊïàÁöÑË°ÄÁÆ°ÂÖßÈÄöË∑ØÊúÉÈ°ØËëóÂΩ±ÈüøÁóÖÊÇ£ÁöÑÊ≤ªÁôÇÁµêÊûú„ÄÇÁÑ∂ËÄåÔºåÂú®ÊÉ°Âä£ÁöÑÁí∞Â¢É‰∏≠ÔºåÁÜüÁ∑¥ÁöÑÈÜ´ÁôÇ‰∫∫Âì°ÂæÄÂæÄ‰∏çË∂≥„ÄÇËá™‰∏ªÊ©üÂô®‰∫∫Ë∂ÖÈü≥Ê≥¢Á≥ªÁµ±ÂèØ‰ª•ÂçîÂä©ÈáùÈ†≠ÊèíÂÖ•Ôºå‰ª•Êèê‰æõËó•Áâ©‰∏¶ÊîØÊè¥ÈùûÂ∞àÂÆ∂Âü∑Ë°åÊ≠§È°û‰ªªÂãô„ÄÇÂÑòÁÆ°Ëá™‰∏ªÈáùÈ†≠ÊèíÂÖ•ÊäÄË°ìÈÄ≤Ê≠•Ôºå‰ΩÜË°ÄÁÆ°ÂàÜÂâ≤È†êÊ∏¨ÁöÑ‰∏çÊ∫ñÁ¢∫ÊÄßÊúÉÈÄ†ÊàêÈ¢®Èö™„ÄÇ‰∫ÜËß£Ë∂ÖÈü≥Ê≥¢ÂΩ±ÂÉè‰∏≠È†êÊ∏¨Ê®°ÂûãÁöÑ‰∏çÁ¢∫ÂÆöÊÄßÔºåÂ∞çÊñºË©ï‰º∞ÂÖ∂ÂèØÈù†ÊÄßËá≥ÈóúÈáçË¶Å„ÄÇÊàëÂÄëÂºïÈÄ≤ MSU-NetÔºåÈÄôÊòØ‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÂ§öÈöéÊÆµÊñπÊ≥ïÔºåÁî®ÊñºË®ìÁ∑¥‰∏ÄÁµÑ U-Net ‰ª•Áî¢ÁîüÊ∫ñÁ¢∫ÁöÑË∂ÖÈü≥Ê≥¢ÂΩ±ÂÉèÂàÜÂâ≤Âúñ„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫ÜÂ§ßÂπÖÊîπÂñÑÔºåÊØîÂñÆ‰∏ÄÁöÑËíôÂú∞Âç°ÁæÖ U-Net ÊîπÂñÑ‰∫Ü 18.1%ÔºåÂ¢ûÂº∑‰∫Ü‰∏çÁ¢∫ÂÆöÊÄßË©ï‰º∞„ÄÅÊ®°ÂûãÈÄèÊòéÂ∫¶ÂíåÂèØ‰ø°Â∫¶„ÄÇÈÄèÈÅéÂº∑Ë™øÊ®°ÂûãÁ¢∫ÂÆöÊÄßÁöÑÂçÄÂüüÔºåMSU-Net ÂèØ‰ª•ÂºïÂ∞éÂÆâÂÖ®ÁöÑÈáùÈ†≠ÊèíÂÖ•ÔºåËÆìÈùûÂ∞àÂÆ∂‰πüËÉΩÂü∑Ë°åÊ≠§È°û‰ªªÂãô„ÄÇ

##### **Domain Shift Analysis in Chest Radiographs Classification in a Veterans Healthcare Administration Population**
2407.21149v1 by Mayanka Chandrashekar, Ian Goethert, Md Inzamam Ul Haque, Benjamin McMahon, Sayera Dhaubhadel, Kathryn Knight, Joseph Erdos, Donna Reagan, Caroline Taylor, Peter Kuzmak, John Michael Gaziano, Eileen McAllister, Lauren Costa, Yuk-Lam Ho, Kelly Cho, Suzanne Tamang, Samah Fodeh-Jarad, Olga S. Ovchinnikova, Amy C. Justice, Jacob Hinkle, Ioana Danciu

Objectives: This study aims to assess the impact of domain shift on chest
X-ray classification accuracy and to analyze the influence of ground truth
label quality and demographic factors such as age group, sex, and study year.
Materials and Methods: We used a DenseNet121 model pretrained MIMIC-CXR dataset
for deep learning-based multilabel classification using ground truth labels
from radiology reports extracted using the CheXpert and CheXbert Labeler. We
compared the performance of the 14 chest X-ray labels on the MIMIC-CXR and
Veterans Healthcare Administration chest X-ray dataset (VA-CXR). The VA-CXR
dataset comprises over 259k chest X-ray images spanning between the years 2010
and 2022. Results: The validation of ground truth and the assessment of
multi-label classification performance across various NLP extraction tools
revealed that the VA-CXR dataset exhibited lower disagreement rates than the
MIMIC-CXR datasets. Additionally, there were notable differences in AUC scores
between models utilizing CheXpert and CheXbert. When evaluating multi-label
classification performance across different datasets, minimal domain shift was
observed in unseen datasets, except for the label "Enlarged Cardiomediastinum."
The study year's subgroup analyses exhibited the most significant variations in
multi-label classification model performance. These findings underscore the
importance of considering domain shifts in chest X-ray classification tasks,
particularly concerning study years. Conclusion: Our study reveals the
significant impact of domain shift and demographic factors on chest X-ray
classification, emphasizing the need for improved transfer learning and
equitable model development. Addressing these challenges is crucial for
advancing medical imaging and enhancing patient care.

ÊëòË¶ÅÔºö<paragraph>ÁõÆÊ®ôÔºöÊú¨Á†îÁ©∂Êó®Âú®Ë©ï‰º∞È†òÂüüËΩâÁßªÂ∞çËÉ∏ÈÉ® X ÂÖâÂàÜÈ°ûÁ≤æÂ∫¶ÁöÑÂΩ±ÈüøÔºå‰∏¶ÂàÜÊûêÂü∫Êú¨‰∫ãÂØ¶Ê®ôÁ±§ÂìÅË≥™ÂíåÂπ¥ÈΩ°ÁµÑ„ÄÅÊÄßÂà•ÂíåÁ†îÁ©∂Âπ¥‰ªΩÁ≠â‰∫∫Âè£Âõ†Á¥†ÁöÑÂΩ±Èüø„ÄÇ
ÊùêÊñôÂíåÊñπÊ≥ïÔºöÊàëÂÄë‰ΩøÁî® DenseNet121 Ê®°ÂûãÈ†êË®ìÁ∑¥ MIMIC-CXR Ë≥áÊñôÈõÜÔºå‰ΩøÁî®Âæû‰ΩøÁî® CheXpert Âíå CheXbert Ê®ôÁ±§Âô®ÂæûÊîæÂ∞ÑÁßëÂ†±Âëä‰∏≠ÊèêÂèñÁöÑÂü∫Êú¨‰∫ãÂØ¶Ê®ôÁ±§ÈÄ≤Ë°åÂü∫ÊñºÊ∑±Â∫¶Â≠∏ÁøíÁöÑÂ§öÊ®ôÁ±§ÂàÜÈ°û„ÄÇÊàëÂÄëÊØîËºÉ‰∫Ü MIMIC-CXR ÂíåÈÄÄ‰ºçËªç‰∫∫ÂÅ•Â∫∑ÁÆ°ÁêÜÂ±ÄËÉ∏ÈÉ® X ÂÖâË≥áÊñôÈõÜ (VA-CXR) ‰∏ä 14 ÂÄãËÉ∏ÈÉ® X ÂÖâÊ®ôÁ±§ÁöÑÊÄßËÉΩ„ÄÇVA-CXR Ë≥áÊñôÈõÜÂåÖÂê´Ë∂ÖÈÅé 259k ÂºµËÉ∏ÈÉ® X ÂÖâÂΩ±ÂÉèÔºåÊôÇÈñìË∑®Â∫¶ÁÇ∫ 2010 Âπ¥Ëá≥ 2022 Âπ¥„ÄÇÁµêÊûúÔºöÂü∫Êú¨‰∫ãÂØ¶ÁöÑÈ©óË≠âÂíåÂ∞çÂêÑÁ®Æ NLP ÊèêÂèñÂ∑•ÂÖ∑ÁöÑÂ§öÊ®ôÁ±§ÂàÜÈ°ûÊÄßËÉΩÁöÑË©ï‰º∞È°ØÁ§∫ÔºåVA-CXR Ë≥áÊñôÈõÜË°®ÁèæÂá∫ÁöÑÂàÜÊ≠ßÁéá‰ΩéÊñº MIMIC-CXR Ë≥áÊñôÈõÜ„ÄÇÊ≠§Â§ñÔºå‰ΩøÁî® CheXpert Âíå CheXbert ÁöÑÊ®°Âûã‰πãÈñìÁöÑ AUC ÂæóÂàÜÂ≠òÂú®È°ØËëóÂ∑ÆÁï∞„ÄÇÂú®Ë©ï‰º∞‰∏çÂêåË≥áÊñôÈõÜ‰∏äÁöÑÂ§öÊ®ôÁ±§ÂàÜÈ°ûÊÄßËÉΩÊôÇÔºåÈô§‰∫ÜÊ®ôÁ±§„ÄåÂøÉÁ∏±ÈöîÂ¢ûÂ§ß„Äç‰πãÂ§ñÔºåÂú®Êú™Ë¶ãË≥áÊñôÈõÜ‰∏≠ËßÄÂØüÂà∞ÁöÑÈ†òÂüüËΩâÁßªÂæàÂ∞è„ÄÇÁ†îÁ©∂Âπ¥‰ªΩÁöÑÂ≠êÁæ§ÂàÜÊûêÈ°ØÁ§∫ÔºåÂ§öÊ®ôÁ±§ÂàÜÈ°ûÊ®°ÂûãÊÄßËÉΩËÆäÂåñÊúÄÂ§ß„ÄÇÈÄô‰∫õÁôºÁèæÂº∑Ë™ø‰∫ÜÂú®ËÉ∏ÈÉ® X ÂÖâÂàÜÈ°û‰ªªÂãô‰∏≠ËÄÉÊÖÆÈ†òÂüüËΩâÁßªÁöÑÈáçË¶ÅÊÄßÔºåÁâπÂà•ÊòØÈóúÊñºÁ†îÁ©∂Âπ¥‰ªΩ„ÄÇÁµêË´ñÔºöÊàëÂÄëÁöÑÁ†îÁ©∂Êè≠Á§∫‰∫ÜÈ†òÂüüËΩâÁßªÂíå‰∫∫Âè£Âõ†Á¥†Â∞çËÉ∏ÈÉ® X ÂÖâÂàÜÈ°ûÁöÑÈ°ØËëóÂΩ±ÈüøÔºåÂº∑Ë™ø‰∫ÜÊîπÈÄ≤ÈÅ∑ÁßªÂ≠∏ÁøíÂíåÂÖ¨Âπ≥Ê®°ÂûãÈñãÁôºÁöÑÂøÖË¶ÅÊÄß„ÄÇÊáâÂ∞çÈÄô‰∫õÊåëÊà∞Â∞çÊñºÊé®ÈÄ≤ÈÜ´Â≠∏ÂΩ±ÂÉèÂíåÂä†Âº∑ÊÇ£ËÄÖË≠∑ÁêÜËá≥ÈóúÈáçË¶Å„ÄÇ</paragraph>

##### **Zero Shot Health Trajectory Prediction Using Transformer**
2407.21124v1 by Pawel Renc, Yugang Jia, Anthony E. Samir, Jaroslaw Was, Quanzheng Li, David W. Bates, Arkadiusz Sitek

Integrating modern machine learning and clinical decision-making has great
promise for mitigating healthcare's increasing cost and complexity. We
introduce the Enhanced Transformer for Health Outcome Simulation (ETHOS), a
novel application of the transformer deep-learning architecture for analyzing
high-dimensional, heterogeneous, and episodic health data. ETHOS is trained
using Patient Health Timelines (PHTs)-detailed, tokenized records of health
events-to predict future health trajectories, leveraging a zero-shot learning
approach. ETHOS represents a significant advancement in foundation model
development for healthcare analytics, eliminating the need for labeled data and
model fine-tuning. Its ability to simulate various treatment pathways and
consider patient-specific factors positions ETHOS as a tool for care
optimization and addressing biases in healthcare delivery. Future developments
will expand ETHOS' capabilities to incorporate a wider range of data types and
data sources. Our work demonstrates a pathway toward accelerated AI development
and deployment in healthcare.

ÊëòË¶ÅÔºöÊï¥ÂêàÁèæ‰ª£Ê©üÂô®Â≠∏ÁøíËàáËá®Â∫äÊ±∫Á≠ñÂà∂ÂÆöÂ∞çÊñºÊ∏õËºïÈÜ´ÁôÇ‰øùÂÅ•Êó•ÁõäÂ¢ûÂä†ÁöÑÊàêÊú¨ÂíåË§áÈõúÊÄßÂÖ∑ÊúâÂæàÂ§ßÁöÑÂâçÊôØ„ÄÇÊàëÂÄëÂºïÂÖ•‰∫ÜÂÅ•Â∫∑ÁµêÊûúÊ®°Êì¨ÁöÑÂ¢ûÂº∑ÂºèTransformerÔºàETHOSÔºâÔºåÈÄôÊòØ‰∏ÄÁ®ÆTransformerÊ∑±Â∫¶Â≠∏ÁøíÊû∂ÊßãÁöÑÊñ∞Á©éÊáâÁî®ÔºåÁî®ÊñºÂàÜÊûêÈ´òÁ∂≠„ÄÅÁï∞Ë≥™‰∏îÊÉÖÁØÄÊÄßÁöÑÂÅ•Â∫∑Êï∏Êìö„ÄÇETHOS ‰ΩøÁî®ÊÇ£ËÄÖÂÅ•Â∫∑ÊôÇÈñìËª∏ (PHT) ÈÄ≤Ë°åË®ìÁ∑¥ÔºåPHT ÊòØÂÅ•Â∫∑‰∫ã‰ª∂ÁöÑË©≥Á¥∞„ÄÅÊ®ôË®òÂåñË®òÈåÑÔºåÁî®ÊñºÈ†êÊ∏¨Êú™‰æÜÁöÑÂÅ•Â∫∑ËªåË∑°Ôºå‰∏¶Âà©Áî®Èõ∂Ê¨°Â≠∏ÁøíÊñπÊ≥ï„ÄÇETHOS ‰ª£Ë°®‰∫ÜÈÜ´ÁôÇ‰øùÂÅ•ÂàÜÊûêÂü∫Á§éÊ®°ÂûãÈñãÁôºÁöÑÈáçÂ§ßÈÄ≤Â±ïÔºåÊ∂àÈô§‰∫ÜÂ∞çÊ®ôË®òÊï∏ÊìöÂíåÊ®°ÂûãÂæÆË™øÁöÑÈúÄÊ±Ç„ÄÇÂÆÉÊ®°Êì¨ÂêÑÁ®ÆÊ≤ªÁôÇÈÄîÂæë‰∏¶ËÄÉÊÖÆÊÇ£ËÄÖÁâπÂÆöÂõ†Á¥†ÁöÑËÉΩÂäõÔºå‰Ωø ETHOS ÊàêÁÇ∫ÂÑ™ÂåñÁÖßË≠∑ÂíåËß£Ê±∫ÈÜ´ÁôÇ‰øùÂÅ•Êèê‰æõ‰∏≠ÂÅèÂ∑ÆÁöÑÂ∑•ÂÖ∑„ÄÇÊú™‰æÜÁöÑÁôºÂ±ïÂ∞áÊì¥Â±ï ETHOS ÁöÑÂäüËÉΩÔºå‰ª•Á¥çÂÖ•Êõ¥Âª£Ê≥õÁöÑÊï∏ÊìöÈ°ûÂûãÂíåÊï∏Êìö‰æÜÊ∫ê„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂Â±ïÁ§∫‰∫Ü‰∏ÄÊ¢ùÂä†ÈÄüÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ AI ÈñãÁôºÂíåÈÉ®ÁΩ≤ÁöÑÈÄîÂæë„ÄÇ

##### **CLEFT: Language-Image Contrastive Learning with Efficient Large Language Model and Prompt Fine-Tuning**
2407.21011v1 by Yuexi Du, Brian Chang, Nicha C. Dvornek

Recent advancements in Contrastive Language-Image Pre-training (CLIP) have
demonstrated notable success in self-supervised representation learning across
various tasks. However, the existing CLIP-like approaches often demand
extensive GPU resources and prolonged training times due to the considerable
size of the model and dataset, making them poor for medical applications, in
which large datasets are not always common. Meanwhile, the language model
prompts are mainly manually derived from labels tied to images, potentially
overlooking the richness of information within training samples. We introduce a
novel language-image Contrastive Learning method with an Efficient large
language model and prompt Fine-Tuning (CLEFT) that harnesses the strengths of
the extensive pre-trained language and visual models. Furthermore, we present
an efficient strategy for learning context-based prompts that mitigates the gap
between informative clinical diagnostic data and simple class labels. Our
method demonstrates state-of-the-art performance on multiple chest X-ray and
mammography datasets compared with various baselines. The proposed parameter
efficient framework can reduce the total trainable model size by 39% and reduce
the trainable language model to only 4% compared with the current BERT encoder.

ÊëòË¶ÅÔºöÂ∞çÊØîË™ûË®ÄÂΩ±ÂÉèÈ†êË®ìÁ∑¥ (CLIP) ÁöÑÊúÄÊñ∞ÈÄ≤Â±ïÂ∑≤Â±ïÁèæÂá∫Âú®ÂêÑÈ†Ö‰ªªÂãô‰∏≠‰ª•Ëá™ÊàëÁõ£Áù£Ë°®ÂæµÂ≠∏ÁøíÁç≤ÂæóÈ°ØËëóÊàêÂäüÁöÑÊàêÊûú„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÁöÑ CLIP È°û‰ººÊñπÊ≥ïÈÄöÂ∏∏ÈúÄË¶ÅÂ§ßÈáèÁöÑ GPU Ë≥áÊ∫êÂíåÊº´Èï∑ÁöÑË®ìÁ∑¥ÊôÇÈñìÔºåÂõ†ÁÇ∫Ê®°ÂûãÂíåË≥áÊñôÈõÜÁöÑË¶èÊ®°ÈæêÂ§ßÔºåÈÄô‰ΩøÂæóÂÆÉÂÄë‰∏çÈÅ©ÂêàÈÜ´ÁôÇÊáâÁî®ÔºåÂõ†ÁÇ∫ÈÜ´ÁôÇÊáâÁî®‰∏≠‰∏¶‰∏çÁ∏ΩÊòØÊúÉÊúâÂ§ßÂûãË≥áÊñôÈõÜ„ÄÇÂêåÊôÇÔºåË™ûË®ÄÊ®°ÂûãÊèêÁ§∫‰∏ªË¶Å‰æÜËá™ËàáÂΩ±ÂÉèÁõ∏ÈóúÁöÑÊ®ôÁ±§ÔºåËÄåÊâãÂãïË°çÁîüÔºåÈÄôÂèØËÉΩÊúÉÂøΩÁï•Ë®ìÁ∑¥Ê®£Êú¨‰∏≠Ë±êÂØåÁöÑË≥áË®ä„ÄÇÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÊñ∞Á©éÁöÑË™ûË®ÄÂΩ±ÂÉèÂ∞çÊØîÂ≠∏ÁøíÊñπÊ≥ïÔºåÂÖ∂‰∏≠ÂåÖÂê´‰∏ÄÂÄãÈ´òÊïàÁöÑÂ§ßË™ûË®ÄÊ®°ÂûãÂíåÊèêÁ§∫ÂæÆË™ø (CLEFT)ÔºåÂÆÉÂà©Áî®‰∫ÜÂª£Ê≥õÈ†êË®ìÁ∑¥ÁöÑË™ûË®ÄÂíåË¶ñË¶∫Ê®°ÂûãÁöÑÂÑ™Âã¢„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÂ≠∏ÁøíÂü∫ÊñºËÑàÁµ°ÊèêÁ§∫ÁöÑÊúâÊïàÁ≠ñÁï•Ôºå‰ª•Á∏ÆÂ∞èË≥áË®äË±êÂØåÁöÑËá®Â∫äË®∫Êñ∑Ë≥áÊñôÂíåÁ∞°ÂñÆÈ°ûÂà•Ê®ôÁ±§‰πãÈñìÁöÑÂ∑ÆË∑ù„ÄÇËàáÂêÑÁ®ÆÂü∫Ê∫ñÁõ∏ÊØîÔºåÊàëÂÄëÁöÑÊ®°ÂûãÂú®Â§öÂÄãËÉ∏ÈÉ® X ÂÖâÂíå‰π≥ÊàøÊîùÂΩ±Ë≥áÊñôÈõÜ‰∏äÂ±ïÁèæÂá∫ÊúÄÂÖàÈÄ≤ÁöÑÊïàËÉΩ„ÄÇÊâÄÊèêÂá∫ÁöÑÂèÉÊï∏ÊúâÊïàÊû∂ÊßãÂèØ‰ª•Â∞áÁ∏ΩÈ´îÂèØË®ìÁ∑¥Ê®°ÂûãÂ§ßÂ∞èÊ∏õÂ∞ë 39%Ôºå‰∏¶Â∞áÂèØË®ìÁ∑¥Ë™ûË®ÄÊ®°ÂûãÊ∏õÂ∞ëÂà∞ÂÉÖ 4%ÔºåËàáÁõÆÂâçÁöÑ BERT Á∑®Á¢ºÂô®Áõ∏ÊØî„ÄÇ

##### **Federated Knowledge Recycling: Privacy-Preserving Synthetic Data Sharing**
2407.20830v1 by Eugenio Lomurno, Matteo Matteucci

Federated learning has emerged as a paradigm for collaborative learning,
enabling the development of robust models without the need to centralise
sensitive data. However, conventional federated learning techniques have
privacy and security vulnerabilities due to the exposure of models, parameters
or updates, which can be exploited as an attack surface. This paper presents
Federated Knowledge Recycling (FedKR), a cross-silo federated learning approach
that uses locally generated synthetic data to facilitate collaboration between
institutions. FedKR combines advanced data generation techniques with a dynamic
aggregation process to provide greater security against privacy attacks than
existing methods, significantly reducing the attack surface. Experimental
results on generic and medical datasets show that FedKR achieves competitive
performance, with an average improvement in accuracy of 4.24% compared to
training models from local data, demonstrating particular effectiveness in data
scarcity scenarios.

ÊëòË¶ÅÔºöËÅØÈÇ¶Â≠∏ÁøíÂ∑≤ÊàêÁÇ∫Âçî‰ΩúÂ≠∏ÁøíÁöÑÂÖ∏ÁØÑÔºå
ÁÑ°ÈúÄÈõÜ‰∏≠ÊïèÊÑüË≥áÊñôÂç≥ÂèØÈñãÁôºÁ©©ÂÅ•Ê®°Âûã„ÄÇÁÑ∂ËÄåÔºåÁî±ÊñºÊ®°Âûã„ÄÅÂèÉÊï∏
ÊàñÊõ¥Êñ∞ÁöÑÂÖ¨ÈñãÔºåÂÇ≥Áµ±ÁöÑËÅØÈÇ¶Â≠∏ÁøíÊäÄË°ìÂÖ∑ÊúâÈö±ÁßÅÂíåÂÆâÂÖ®ÊºèÊ¥ûÔºåÂèØÁî®‰ΩúÊîªÊìäÈù¢„ÄÇÊú¨ÊñáÊèêÂá∫
ËÅØÈÇ¶Áü•Ë≠òÂÜçÂà©Áî® (FedKR)Ôºå‰∏ÄÁ®ÆË∑®Â≠§Â≥∂ÁöÑËÅØÈÇ¶Â≠∏ÁøíÊñπÊ≥ï
‰ΩøÁî®Êú¨Âú∞ÁîüÊàêÁöÑÂêàÊàêË≥áÊñô‰æÜ‰øÉÈÄ≤
Ê©üÊßã‰πãÈñìÁöÑÂêà‰Ωú„ÄÇFedKR Â∞áÂÖàÈÄ≤ÁöÑË≥áÊñôÁîüÊàêÊäÄË°ìËàáÂãïÊÖã
ËÅöÂêàÈÅéÁ®ãÁõ∏ÁµêÂêàÔºå‰ª•Êèê‰æõÊØî
ÁèæÊúâÊñπÊ≥ïÊõ¥ËÉΩÊäµÁ¶¶Èö±ÁßÅÊîªÊìäÁöÑÂÆâÂÖ®‰øùÈöúÔºåÂ§ßÂπÖÁ∏ÆÂ∞èÊîªÊìäÈù¢„ÄÇÂØ¶È©ó
ÁµêÊûúÈ°ØÁ§∫ÔºåÂú®‰∏ÄËà¨ÂíåÈÜ´ÁôÇË≥áÊñôÈõÜ‰∏äÔºåFedKR ÈÅîÂà∞Á´∂Áà≠Âäõ
Ë°®ÁèæÔºåËàáË®ìÁ∑¥Ê®°ÂûãÁõ∏ÊØîÔºåÊ∫ñÁ¢∫ÁéáÂπ≥ÂùáÊèêÂçá 4.24%
‰æÜËá™Êú¨Âú∞Ë≥áÊñôÔºåÂú®Ë≥áÊñôÁ®ÄÁº∫ÁöÑÊÉÖÊ≥Å‰∏ãÂ±ïÁèæÂá∫ÁâπÂà•ÁöÑÊúâÊïàÊÄß„ÄÇ

##### **Interpretable Pre-Trained Transformers for Heart Time-Series Data**
2407.20775v2 by Harry J. Davies, James Monsen, Danilo P. Mandic

Decoder-only transformers are the backbone of the popular generative
pre-trained transformer (GPT) series of large language models. In this work, we
employ this framework to the analysis of clinical heart time-series data, to
create two pre-trained general purpose cardiac models, termed PPG-PT and
ECG-PT. We place a special emphasis on making both such pre-trained models
fully interpretable. This is achieved firstly through aggregate attention maps
which show that, in order to make predictions, the model focuses on similar
points in previous cardiac cycles and gradually broadens its attention in
deeper layers. Next, we show that tokens with the same value, which occur at
different distinct points in the electrocardiography (ECG) and
photoplethysmography (PPG) cycle, form separate clusters in high dimensional
space. The clusters form according to phase, as the tokens propagate through
the transformer blocks. Finally, we highlight that individual attention heads
respond to specific physiologically relevent features, such as the dicrotic
notch in PPG and the P-wave in ECG. It is also demonstrated that these
pre-trained models are straightforward to fine-tune for tasks such as
classification of atrial fibrillation (AF), and beat detection in
photoplethysmography. For the example of AF, the fine-tuning took 11 minutes of
computer time, and achieved the respective leave-one-subject-out AUCs of 0.99
and 0.93 for ECG and PPG within the MIMIC Perform AF dataset. In addition, the
fine-tuned beat detector achieved a state-of-the-art F1 score of 98%, as well
as uniquely providing a beat confidence level which acts as a signal quality
estimator. Importantly, the fine-tuned models for AF screening are also fully
explainable, with attention shifting to regions in the context that are
strongly indicative of atrial fibrillation.

ÊëòË¶ÅÔºö<paragraph>ÂÉÖËß£Á¢ºÂô®TransformerÊòØÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÁÜ±ÈñÄÁîüÊàêÂºèÈ†êË®ìÁ∑¥Transformer (GPT) Á≥ªÂàóÁöÑÊ†∏ÂøÉ„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÂ∞áÊ≠§Êû∂ÊßãÊáâÁî®ÊñºËá®Â∫äÂøÉËáüÊôÇÈñìÂ∫èÂàóË≥áÊñôÂàÜÊûêÔºå‰ª•Âª∫Á´ãÂÖ©ÂÄãÈ†êË®ìÁ∑¥ÈÄöÁî®ÂøÉËáüÊ®°ÂûãÔºåÁ®±ÁÇ∫ PPG-PT Âíå ECG-PT„ÄÇÊàëÂÄëÁâπÂà•Âº∑Ë™øËÆìÈÄôÂÖ©ÂÄãÈ†êË®ìÁ∑¥Ê®°ÂûãÂÆåÂÖ®ÂèØËß£Èáã„ÄÇÈÄôÈ¶ñÂÖàÊòØÈÄèÈÅéÁ∏ΩÈ´îÊ≥®ÊÑèÂúñÂØ¶ÁèæÁöÑÔºåÂÆÉÈ°ØÁ§∫Ê®°ÂûãÁÇ∫‰∫ÜÂÅöÂá∫È†êÊ∏¨ÔºåÊúÉÂ∞àÊ≥®ÊñºÂÖàÂâçÂøÉËáüÈÄ±Êúü‰∏≠ÁöÑÈ°û‰ººÈªûÔºå‰∏¶Âú®Êõ¥Ê∑±Â±§ÁöÑÂ±§Á¥öÈÄêÊº∏Êì¥Â§ßÂÖ∂Ê≥®ÊÑèÁØÑÂúç„ÄÇÊé•‰∏ã‰æÜÔºåÊàëÂÄëÈ°ØÁ§∫Âú®ÂøÉÈõªÂúñ (ECG) ÂíåÂÖâÈõªÂÆπÁ©çÊèèË®òÊ≥ï (PPG) ÈÄ±Êúü‰∏≠Êñº‰∏çÂêåÁâπÂÆöÈªûÂá∫ÁèæÁöÑÂÖ∑ÊúâÁõ∏ÂêåÂÄºÁöÑ‰ª£Âπ£ÔºåÊúÉÂú®È´òÁ∂≠Á©∫Èñì‰∏≠ÂΩ¢ÊàêÁç®Á´ãÁöÑÁæ§ÈõÜ„ÄÇÁæ§ÈõÜÊúÉÊ†πÊìöÁõ∏‰ΩçÂΩ¢ÊàêÔºåÂõ†ÁÇ∫‰ª£Âπ£ÊúÉÈÄèÈÅéTransformerÂçÄÂ°äÂÇ≥Êí≠„ÄÇÊúÄÂæåÔºåÊàëÂÄëÂº∑Ë™øÂÄãÂà•Ê≥®ÊÑèÊ¨äÈáçÊúÉÂ∞çÁâπÂÆöÁöÑÁîüÁêÜÁõ∏ÈóúÁâπÂæµÂÅöÂá∫ÂõûÊáâÔºå‰æãÂ¶Ç PPG ‰∏≠ÁöÑ‰∫åÂ∞ñÁº∫Âè£Âíå ECG ‰∏≠ÁöÑ P Ê≥¢„ÄÇ‰πüÂ∑≤Ë≠âÂØ¶ÈÄô‰∫õÈ†êË®ìÁ∑¥Ê®°ÂûãÂæàÂÆπÊòìÈáùÂ∞ç‰ªªÂãôÈÄ≤Ë°åÂæÆË™øÔºå‰æãÂ¶ÇÂøÉÊàøÈ°´Âãï (AF) ÂàÜÈ°ûÂíåÂÖâÈõªÂÆπÁ©çÊèèË®òÊ≥ï‰∏≠ÁöÑÁØÄÊãçÂÅµÊ∏¨„ÄÇ‰ª• AF ÁÇ∫‰æãÔºåÂæÆË™øËÄóÊôÇ 11 ÂàÜÈêòÁöÑÈõªËÖ¶ÊôÇÈñìÔºå‰∏¶Âú® MIMIC Perform AF Ë≥áÊñôÈõÜ‰∏≠ÂàÜÂà•ÈÅîÊàê ECG Âíå PPG ÁöÑÁïô‰∏ÄÊ≥ï AUC ÁÇ∫ 0.99 Âíå 0.93„ÄÇÊ≠§Â§ñÔºåÂæÆË™øÁØÄÊãçÂÅµÊ∏¨Âô®ÈÅîÂà∞‰∫Ü 98% ÁöÑÊúÄÊñ∞ F1 ÂàÜÊï∏Ôºå‰∏¶Áç®ÁâπÂú∞Êèê‰æõ‰∫Ü‰∏ÄÂÄãÁØÄÊãç‰ø°ÂøÉÁ≠âÁ¥öÔºå‰ΩúÁÇ∫Ë®äËôüÂìÅË≥™‰º∞Ë®àÂô®„ÄÇÈáçË¶ÅÁöÑÊòØÔºåÈáùÂ∞ç AF ÁØ©Ê™¢ÈÄ≤Ë°åÂæÆË™øÁöÑÊ®°Âûã‰πüÂÆåÂÖ®ÂèØËß£ÈáãÔºåÊ≥®ÊÑèÂäõÊúÉËΩâÁßªÂà∞Êñá‰∏≠Âº∑ÁÉàÊåáÁ§∫ÂøÉÊàøÈ°´ÂãïÁöÑÂçÄÂüü„ÄÇ</paragraph>

##### **Architectural Influence on Variational Quantum Circuits in Multi-Agent Reinforcement Learning: Evolutionary Strategies for Optimization**
2407.20739v1 by Michael K√∂lle, Karola Schneider, Sabrina Egger, Felix Topp, Thomy Phan, Philipp Altmann, Jonas N√º√ülein, Claudia Linnhoff-Popien

In recent years, Multi-Agent Reinforcement Learning (MARL) has found
application in numerous areas of science and industry, such as autonomous
driving, telecommunications, and global health. Nevertheless, MARL suffers
from, for instance, an exponential growth of dimensions. Inherent properties of
quantum mechanics help to overcome these limitations, e.g., by significantly
reducing the number of trainable parameters. Previous studies have developed an
approach that uses gradient-free quantum Reinforcement Learning and
evolutionary optimization for variational quantum circuits (VQCs) to reduce the
trainable parameters and avoid barren plateaus as well as vanishing gradients.
This leads to a significantly better performance of VQCs compared to classical
neural networks with a similar number of trainable parameters and a reduction
in the number of parameters by more than 97 \% compared to similarly good
neural networks. We extend an approach of K\"olle et al. by proposing a
Gate-Based, a Layer-Based, and a Prototype-Based concept to mutate and
recombine VQCs. Our results show the best performance for mutation-only
strategies and the Gate-Based approach. In particular, we observe a
significantly better score, higher total and own collected coins, as well as a
superior own coin rate for the best agent when evaluated in the Coin Game
environment.

ÊëòË¶ÅÔºöËøëÂπ¥‰æÜÔºåÂ§öÊô∫ËÉΩÈ´îÂº∑ÂåñÂ≠∏Áøí (MARL) Â∑≤Âú®ÁßëÂ≠∏ÂíåÁî¢Ê•≠ÁöÑË®±Â§öÈ†òÂüü‰∏≠ÊâæÂà∞ÊáâÁî®Ôºå‰æãÂ¶ÇËá™ÂãïÈßïÈßõ„ÄÅÈõª‰ø°ÂíåÂÖ®ÁêÉÂÅ•Â∫∑„ÄÇÂÑòÁÆ°Â¶ÇÊ≠§ÔºåMARL ÈÇÑÊòØÊúÉÂèóÂà∞‰æãÂ¶ÇÁ∂≠Â∫¶ÊåáÊï∏ÊàêÈï∑Á≠âÂïèÈ°åÁöÑÂΩ±Èüø„ÄÇÈáèÂ≠êÂäõÂ≠∏ÁöÑÂÖßÂú®ÁâπÊÄßÊúâÂä©ÊñºÂÖãÊúçÈÄô‰∫õÈôêÂà∂Ôºå‰æãÂ¶ÇÔºåÈÄèÈÅéÂ§ßÂπÖÊ∏õÂ∞ëÂèØË®ìÁ∑¥ÂèÉÊï∏ÁöÑÊï∏Èáè„ÄÇÂÖàÂâçÁöÑÁ†îÁ©∂Â∑≤ÈñãÁôºÂá∫‰∏ÄÁ®ÆÊñπÊ≥ïÔºåË©≤ÊñπÊ≥ï‰ΩøÁî®ÁÑ°Ê¢ØÂ∫¶ÁöÑÈáèÂ≠êÂº∑ÂåñÂ≠∏ÁøíÂíåËÆäÂàÜÈáèÂ≠êÈõªË∑Ø (VQC) ÁöÑÊºîÂåñÊúÄ‰Ω≥ÂåñÔºå‰ª•Ê∏õÂ∞ëÂèØË®ìÁ∑¥ÂèÉÊï∏‰∏¶ÈÅøÂÖçË≤ßÁò†È´òÂéüÂíåÊ¢ØÂ∫¶Ê∂àÂ§±„ÄÇËàáÂÖ∑ÊúâÈ°û‰ººÂèØË®ìÁ∑¥ÂèÉÊï∏Êï∏ÈáèÁöÑÂÇ≥Áµ±Á•ûÁ∂ìÁ∂≤Ë∑ØÁõ∏ÊØîÔºåÈÄôÊúÉËÆì VQC ÁöÑÊïàËÉΩÈ°ØËëóÊèêÂçáÔºåËÄå‰∏îËàáÂêåÊ®£ÂÑ™ËâØÁöÑÁ•ûÁ∂ìÁ∂≤Ë∑ØÁõ∏ÊØîÔºåÂèÉÊï∏Êï∏ÈáèÊ∏õÂ∞ë‰∫ÜË∂ÖÈÅé 97%„ÄÇÊàëÂÄëÊì¥ÂÖÖ‰∫Ü K\"olle Á≠â‰∫∫ÁöÑÊñπÊ≥ïÔºåÊèêÂá∫‰∏ÄÂÄãÂü∫ÊñºÈñò„ÄÅÂü∫ÊñºÂ±§ÂíåÂü∫ÊñºÂéüÂûãÁöÑÊ¶ÇÂøµ‰æÜËÆäÁï∞ÂíåÈáçÁµÑ VQC„ÄÇÊàëÂÄëÁöÑÁµêÊûúÈ°ØÁ§∫ÔºåÂÉÖËÆäÁï∞Á≠ñÁï•ÂíåÂü∫ÊñºÈñòÁöÑÊñπÊ≥ïÂÖ∑ÊúâÊúÄ‰Ω≥ÊïàËÉΩ„ÄÇÁâπÂà•ÊòØÔºåÊàëÂÄëËßÄÂØüÂà∞Âú® Coin Game Áí∞Â¢É‰∏≠ÈÄ≤Ë°åË©ï‰º∞ÊôÇÔºåÊúÄ‰Ω≥Êô∫ËÉΩÈ´îÁöÑÂæóÂàÜÈ°ØËëóÊèêÂçá„ÄÅÁ∏ΩË®àÂíåËá™Â∑±Êî∂ÈõÜÁöÑÈáëÂπ£Êï∏ÈáèËºÉÈ´òÔºå‰ª•ÂèäËá™Â∑±ÁöÑÈáëÂπ£ÊØîÁéáËºÉÈ´ò„ÄÇ

##### **Dense Self-Supervised Learning for Medical Image Segmentation**
2407.20395v1 by Maxime Seince, Loic Le Folgoc, Luiz Augusto Facury de Souza, Elsa Angelini

Deep learning has revolutionized medical image segmentation, but it relies
heavily on high-quality annotations. The time, cost and expertise required to
label images at the pixel-level for each new task has slowed down widespread
adoption of the paradigm. We propose Pix2Rep, a self-supervised learning (SSL)
approach for few-shot segmentation, that reduces the manual annotation burden
by learning powerful pixel-level representations directly from unlabeled
images. Pix2Rep is a novel pixel-level loss and pre-training paradigm for
contrastive SSL on whole images. It is applied to generic encoder-decoder deep
learning backbones (e.g., U-Net). Whereas most SSL methods enforce invariance
of the learned image-level representations under intensity and spatial image
augmentations, Pix2Rep enforces equivariance of the pixel-level
representations. We demonstrate the framework on a task of cardiac MRI
segmentation. Results show improved performance compared to existing semi- and
self-supervised approaches; and a 5-fold reduction in the annotation burden for
equivalent performance versus a fully supervised U-Net baseline. This includes
a 30% (resp. 31%) DICE improvement for one-shot segmentation under
linear-probing (resp. fine-tuning). Finally, we also integrate the novel
Pix2Rep concept with the Barlow Twins non-contrastive SSL, which leads to even
better segmentation performance.

ÊëòË¶ÅÔºöÊ∑±Â∫¶Â≠∏ÁøíÂæπÂ∫ïÊîπËÆä‰∫ÜÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÂâ≤Ôºå‰ΩÜÂÆÉÊ•µÂ∫¶‰æùË≥¥ÊñºÈ´òÂìÅË≥™ÁöÑË®ªËß£„ÄÇÁÇ∫ÊØèÂÄãÊñ∞‰ªªÂãôÊ®ôË®òÂÉèÁ¥†Â±§Á¥öÁöÑÂΩ±ÂÉèÊâÄÈúÄÁöÑÊôÇÈñì„ÄÅÊàêÊú¨ÂíåÂ∞àÊ•≠Áü•Ë≠òÔºåÂ∑≤Ê∏õÁ∑©‰∫ÜÁØÑ‰æãÁöÑÂª£Ê≥õÊé°Áî®„ÄÇÊàëÂÄëÊèêÂá∫ Pix2RepÔºå‰∏ÄÁ®ÆÈáùÂ∞çÂ∞ëÊ¨°ÂàÜÂâ≤ÁöÑËá™Áõ£Áù£ÂºèÂ≠∏Áøí (SSL) ÊñπÊ≥ïÔºåÂèØÈÄèÈÅéÁõ¥Êé•ÂæûÊú™Ê®ôË®òÁöÑÂΩ±ÂÉè‰∏≠Â≠∏ÁøíÂº∑Â§ßÁöÑÂÉèÁ¥†Â±§Á¥öË°®Á§∫Ôºå‰æÜÊ∏õËºïÊâãÂãïË®ªËß£Ë≤†Êìî„ÄÇPix2Rep ÊòØ‰∏ÄÁ®ÆÈáùÂ∞çÂÆåÊï¥ÂΩ±ÂÉèÂ∞çÊØîÂºè SSL ÁöÑÊñ∞Á©éÂÉèÁ¥†Â±§Á¥öÊêçÂ§±ÂíåÈ†êË®ìÁ∑¥ÁØÑ‰æã„ÄÇÂÆÉË¢´ÊáâÁî®ÊñºÈÄöÁî®Á∑®Á¢ºÂô®-Ëß£Á¢ºÂô®Ê∑±Â∫¶Â≠∏Áøí‰∏ªÂππ (‰æãÂ¶Ç U-Net)„ÄÇÂ§ßÂ§öÊï∏ SSL ÊñπÊ≥ïÂº∑Âà∂Â≠∏ÁøíÁöÑÂΩ±ÂÉèÂ±§Á¥öË°®Á§∫Âú®Âº∑Â∫¶ÂíåÁ©∫ÈñìÂΩ±ÂÉèÊì¥ÂÖÖ‰∏ãÂÖ∑Êúâ‰∏çËÆäÊÄßÔºåËÄå Pix2Rep ÂâáÂº∑Âà∂ÂÉèÁ¥†Â±§Á¥öË°®Á§∫ÂÖ∑ÊúâÁ≠âËÆäÊÄß„ÄÇÊàëÂÄëÂú®ÂøÉËáü MRI ÂàÜÂâ≤‰ªªÂãô‰∏≠Â±ïÁ§∫‰∫ÜÈÄôÂÄãÊû∂Êßã„ÄÇÁµêÊûúÈ°ØÁ§∫ËàáÁèæÊúâÁöÑÂçäÁõ£Áù£ÂºèÂíåËá™Áõ£Áù£ÂºèÊñπÊ≥ïÁõ∏ÊØîÔºåÊïàËÉΩÊúâÊâÄÊèêÂçáÔºõ‰∏îÂú®ËàáÂÆåÂÖ®Áõ£Áù£Âºè U-Net Âü∫Ê∫ñÂÖ∑ÊúâÁõ∏ÂêåÊïàËÉΩÁöÑÊÉÖÊ≥Å‰∏ãÔºåË®ªËß£Ë≤†ÊìîÊ∏õÂ∞ë‰∫Ü 5 ÂÄç„ÄÇÈÄôÂåÖÊã¨Âú®Á∑öÊÄßÊé¢Ê∏¨ (resp. ÂæÆË™ø) ‰∏ãÔºåÂñÆÊ¨°ÂàÜÂâ≤ÁöÑ DICE ÊèêÂçá‰∫Ü 30% (resp. 31%)„ÄÇÊúÄÂæåÔºåÊàëÂÄë‰πüÂ∞áÊñ∞Á©éÁöÑ Pix2Rep Ê¶ÇÂøµËàá Barlow Twins ÈùûÂ∞çÊØîÂºè SSL Êï¥ÂêàÔºåÈÄôÂ∞éËá¥‰∫ÜÊõ¥Â•ΩÁöÑÂàÜÂâ≤ÊïàËÉΩ„ÄÇ

##### **Classification, Regression and Segmentation directly from k-Space in Cardiac MRI**
2407.20108v1 by Ruochen Li, Jiazhen Pan, Youxiang Zhu, Juncheng Ni, Daniel Rueckert

Cardiac Magnetic Resonance Imaging (CMR) is the gold standard for diagnosing
cardiovascular diseases. Clinical diagnoses predominantly rely on
magnitude-only Digital Imaging and Communications in Medicine (DICOM) images,
omitting crucial phase information that might provide additional diagnostic
benefits. In contrast, k-space is complex-valued and encompasses both magnitude
and phase information, while humans cannot directly perceive. In this work, we
propose KMAE, a Transformer-based model specifically designed to process
k-space data directly, eliminating conventional intermediary conversion steps
to the image domain. KMAE can handle critical cardiac disease classification,
relevant phenotype regression, and cardiac morphology segmentation tasks. We
utilize this model to investigate the potential of k-space-based diagnosis in
cardiac MRI. Notably, this model achieves competitive classification and
regression performance compared to image-domain methods e.g. Masked
Autoencoders (MAEs) and delivers satisfactory segmentation performance with a
myocardium dice score of 0.884. Last but not least, our model exhibits robust
performance with consistent results even when the k-space is 8* undersampled.
We encourage the MR community to explore the untapped potential of k-space and
pursue end-to-end, automated diagnosis with reduced human intervention.

ÊëòË¶ÅÔºöÂøÉËáüÁ£ÅÊåØÈÄ†ÂΩ± (CMR) ÊòØË®∫Êñ∑ÂøÉË°ÄÁÆ°ÁñæÁóÖÁöÑÈªÉÈáëÊ®ôÊ∫ñ„ÄÇËá®Â∫äË®∫Êñ∑‰∏ªË¶Å‰æùË≥¥ÊñºÈÜ´Â≠∏Êï∏‰ΩçÂΩ±ÂÉèÂíåÈÄöË®ä (DICOM) ÂΩ±ÂÉèÁöÑÂπÖÂ∫¶ÔºåËÄåÂøΩÁï•‰∫ÜÂèØËÉΩÊèê‰æõÈ°çÂ§ñË®∫Êñ∑Â•ΩËôïÁöÑÈóúÈçµÁõ∏‰ΩçË≥áË®ä„ÄÇÁõ∏ËºÉ‰πã‰∏ãÔºåk Á©∫ÈñìÊòØË§áÊï∏ÂÄº‰∏îÂåÖÂê´ÂπÖÂ∫¶ÂíåÁõ∏‰ΩçË≥áË®äÔºå‰ΩÜ‰∫∫È°ûÁÑ°Ê≥ïÁõ¥Êé•ÊÑüÁü•„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫ KMAEÔºå‰∏ÄÁ®ÆÁâπÂà•Ë®≠Ë®àÁî®ÊñºÁõ¥Êé•ËôïÁêÜ k Á©∫ÈñìË≥áÊñôÁöÑ Transformer Âü∫Á§éÊ®°ÂûãÔºåÊ∂àÈô§‰∫ÜËΩâÊèõÂà∞ÂΩ±ÂÉèÈ†òÂüüÁöÑÂÇ≥Áµ±‰∏≠‰ªãÊ≠•È©ü„ÄÇKMAE ÂèØ‰ª•ËôïÁêÜÈóúÈçµÁöÑÂøÉËáüÁñæÁóÖÂàÜÈ°û„ÄÅÁõ∏ÈóúË°®ÂûãÂõûÊ≠∏ÂíåÂøÉËáüÂΩ¢ÊÖãÂàÜÂâ≤‰ªªÂãô„ÄÇÊàëÂÄëÂà©Áî®Ê≠§Ê®°ÂûãÊé¢Ë®é k Á©∫ÈñìÂü∫Á§éË®∫Êñ∑Âú®ÂøÉËáü MRI ‰∏≠ÁöÑÊΩõÂäõ„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåËàáÂΩ±ÂÉèÈ†òÂüüÊñπÊ≥ïÔºà‰æãÂ¶ÇÈÅÆÁΩ©ÂºèËá™ÂãïÁ∑®Á¢ºÂô® (MAE)ÔºâÁõ∏ÊØîÔºåÊ≠§Ê®°ÂûãÈÅîÂà∞‰∫ÜÁ´∂Áà≠ÊÄßÁöÑÂàÜÈ°ûÂíåÂõûÊ≠∏ÊïàËÉΩÔºå‰∏¶‰ª• 0.884 ÁöÑÂøÉËÇåÈ™∞Â≠êÂàÜÊï∏Êèê‰æõ‰∫Ü‰ª§‰∫∫ÊªøÊÑèÁöÑÂàÜÂâ≤ÊïàËÉΩ„ÄÇÊúÄÂæå‰ΩÜ‰∏¶ÈùûÊúÄ‰∏çÈáçË¶ÅÁöÑ‰∏ÄÈªûÊòØÔºåÂç≥‰ΩøÂú® k Á©∫Èñì‰∏çË∂≥Êé°Ê®£ 8* ÊôÇÔºåÊàëÂÄëÁöÑÊ®°Âûã‰πüËÉΩÂ±ïÁèæÁ©©ÂÅ•ÁöÑÊïàËÉΩÂíå‰∏ÄËá¥ÁöÑÁµêÊûú„ÄÇÊàëÂÄëÈºìÂãµÊ†∏Á£ÅÂÖ±ÊåØÁ§æÁæ§Êé¢Á¥¢ k Á©∫ÈñìÁöÑÊú™ÈñãÁôºÊΩõÂäõÔºå‰∏¶ËøΩÊ±ÇÊ∏õÂ∞ë‰∫∫ÁÇ∫Âπ≤È†êÁöÑÁ´ØÂà∞Á´ØËá™ÂãïÂåñË®∫Êñ∑„ÄÇ

##### **Robust Conformal Volume Estimation in 3D Medical Images**
2407.19938v1 by Benjamin Lambert, Florence Forbes, Senan Doyle, Michel Dojat

Volumetry is one of the principal downstream applications of 3D medical image
segmentation, for example, to detect abnormal tissue growth or for surgery
planning. Conformal Prediction is a promising framework for uncertainty
quantification, providing calibrated predictive intervals associated with
automatic volume measurements. However, this methodology is based on the
hypothesis that calibration and test samples are exchangeable, an assumption
that is in practice often violated in medical image applications. A weighted
formulation of Conformal Prediction can be framed to mitigate this issue, but
its empirical investigation in the medical domain is still lacking. A potential
reason is that it relies on the estimation of the density ratio between the
calibration and test distributions, which is likely to be intractable in
scenarios involving high-dimensional data. To circumvent this, we propose an
efficient approach for density ratio estimation relying on the compressed
latent representations generated by the segmentation model. Our experiments
demonstrate the efficiency of our approach to reduce the coverage error in the
presence of covariate shifts, in both synthetic and real-world settings. Our
implementation is available at https://github.com/benolmbrt/wcp_miccai

ÊëòË¶ÅÔºöÈ´îÁ©çÊ∏¨ÈáèÊòØ 3D ÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÂâ≤ÁöÑ‰∏ªË¶Å‰∏ãÊ∏∏ÊáâÁî®‰πã‰∏ÄÔºå‰æãÂ¶ÇÁî®ÊñºÂÅµÊ∏¨Áï∞Â∏∏ÁµÑÁπîÁîüÈï∑ÊàñÊâãË°ìË¶èÂäÉ„ÄÇÂÖ±ÂΩ¢È†êÊ∏¨ÊòØ‰∏ÄÂÄãÊúâÂâçÈÄîÁöÑ‰∏çÁ¢∫ÂÆöÊÄßÈáèÂåñÊû∂ÊßãÔºåÊèê‰æõËàáËá™ÂãïÈ´îÁ©çÈáèÊ∏¨Áõ∏ÈóúÁöÑÊ†°Ê≠£È†êÊ∏¨ÂçÄÈñì„ÄÇÁÑ∂ËÄåÔºåÊ≠§ÊñπÊ≥ïÂü∫ÊñºÊ†°Ê≠£ÂíåÊ∏¨Ë©¶Ê®£Êú¨ÂèØ‰∫§ÊèõÁöÑÂÅáË®≠ÔºåËÄåÊ≠§ÂÅáË®≠Âú®ÂØ¶Âãô‰∏äÁ∂ìÂ∏∏Âú®ÈÜ´Â≠∏ÂΩ±ÂÉèÊáâÁî®‰∏≠ÈÅ≠Âà∞Á†¥Â£û„ÄÇÂÖ±ÂΩ¢È†êÊ∏¨ÁöÑÂä†Ê¨äÂÖ¨ÂºèÂèØ‰ª•Ë¢´Âª∫Êßã‰æÜÊ∏õËºïÊ≠§ÂïèÈ°åÔºå‰ΩÜÂÖ∂Âú®ÈÜ´Â≠∏È†òÂüüÁöÑÁ∂ìÈ©óË™øÊü•‰ªçÁÑ∂‰∏çË∂≥„ÄÇ‰∏ÄÂÄãÊΩõÂú®ÂéüÂõ†ÊòØÂÆÉ‰æùË≥¥ÊñºÊ†°Ê≠£ÂíåÊ∏¨Ë©¶ÂàÜ‰Ωà‰πãÈñìÁöÑÂØÜÂ∫¶ÊØî‰º∞Ë®àÔºåÈÄôÂú®Ê∂âÂèäÈ´òÁ∂≠Â∫¶Ë≥áÊñôÁöÑÂ†¥ÊôØ‰∏≠ÂèØËÉΩÊòØÊ£òÊâãÁöÑ„ÄÇÁÇ∫‰∫ÜËø¥ÈÅøÊ≠§ÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÊúâÊïàÁéáÁöÑÂØÜÂ∫¶ÊØî‰º∞Ë®àÊñπÊ≥ïÔºå‰æùË≥¥ÊñºÂàÜÂâ≤Ê®°ÂûãÁî¢ÁîüÁöÑÂ£ìÁ∏ÆÊΩõÂú®Ë°®Á§∫„ÄÇÊàëÂÄëÁöÑÂØ¶È©óË≠âÊòé‰∫ÜÊàëÂÄëÁöÑÊñπÊ≥ïÂú®ÂêàÊàêÂíåÁúüÂØ¶‰∏ñÁïåË®≠ÂÆö‰∏≠Ê∏õÂ∞ëÂÖ±ËÆäÁï∞Êï∏ÂÅèÁßªÂ≠òÂú®ÊôÇÁöÑË¶ÜËìãÁéáË™§Â∑ÆÁöÑÊïàÁéá„ÄÇÊàëÂÄëÁöÑÂØ¶‰ΩúÂèØ‰ª•Âú® https://github.com/benolmbrt/wcp_miccai ÂèñÂæó

##### **Yucca: A Deep Learning Framework For Medical Image Analysis**
2407.19888v1 by Sebastian N√∏rgaard Llambias, Julia Machnio, Asbj√∏rn Munk, Jakob Ambsdorf, Mads Nielsen, Mostafa Mehdipour Ghazi

Medical image analysis using deep learning frameworks has advanced healthcare
by automating complex tasks, but many existing frameworks lack flexibility,
modularity, and user-friendliness. To address these challenges, we introduce
Yucca, an open-source AI framework available at
https://github.com/Sllambias/yucca, designed specifically for medical imaging
applications and built on PyTorch and PyTorch Lightning. Yucca features a
three-tiered architecture: Functional, Modules, and Pipeline, providing a
comprehensive and customizable solution. Evaluated across diverse tasks such as
cerebral microbleeds detection, white matter hyperintensity segmentation, and
hippocampus segmentation, Yucca achieves state-of-the-art results,
demonstrating its robustness and versatility. Yucca offers a powerful,
flexible, and user-friendly platform for medical image analysis, inviting
community contributions to advance its capabilities and impact.

ÊëòË¶ÅÔºö‰ΩøÁî®Ê∑±Â∫¶Â≠∏ÁøíÊ°ÜÊû∂ÈÄ≤Ë°åÁöÑÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÊûêÂ∑≤Á∂ìÈÄöÈÅéËá™ÂãïÂåñË§áÈõú‰ªªÂãôÊé®Âãï‰∫ÜÈÜ´ÁôÇ‰øùÂÅ•ÁöÑÈÄ≤Ê≠•Ôºå‰ΩÜË®±Â§öÁèæÊúâÊ°ÜÊû∂Áº∫‰πèÈùàÊ¥ªÊÄß„ÄÅÊ®°ÁµÑÂåñÂíå‰ΩøÁî®ËÄÖÂèãÂñÑÊÄß„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü YuccaÔºå‰∏ÄÂÄãÈñãÊîæÂéüÂßãÁ¢ºÁöÑ AI Ê°ÜÊû∂ÔºåÂèØÊñº https://github.com/Sllambias/yucca ÂèñÂæóÔºåÂ∞àÈñÄÁÇ∫ÈÜ´Â≠∏ÂΩ±ÂÉèÊáâÁî®Ë®≠Ë®àÔºå‰∏¶Âª∫Á´ãÂú® PyTorch Âíå PyTorch Lightning ‰πã‰∏ä„ÄÇYucca ÂÖ∑Êúâ‰∏âÂ±§Êû∂ÊßãÔºöÂäüËÉΩ„ÄÅÊ®°ÁµÑÂíåÁÆ°Á∑öÔºåÊèê‰æõÂÖ®Èù¢‰∏îÂèØËá™Ë®ÇÁöÑËß£Ê±∫ÊñπÊ°à„ÄÇÂú®ÂêÑÁ®Æ‰ªªÂãô‰∏≠ÈÄ≤Ë°åË©ï‰º∞Ôºå‰æãÂ¶ÇËÖ¶ÂæÆÂá∫Ë°ÄÂÅµÊ∏¨„ÄÅÁôΩË≥™È´òË®äËôüÂàÜÂâ≤ÂíåÊµ∑È¶¨ÂàÜÂâ≤ÔºåYucca ÈÅîÂà∞‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÁµêÊûúÔºåË≠âÊòé‰∫ÜÂÆÉÁöÑÁ©©ÂÅ•ÊÄßÂíåÂ§öÂäüËÉΩÊÄß„ÄÇYucca Êèê‰æõ‰∫Ü‰∏ÄÂÄãÂº∑Â§ß„ÄÅÈùàÊ¥ª‰∏î‰ΩøÁî®ËÄÖÂèãÂñÑÁöÑÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÊûêÂπ≥Âè∞ÔºåÊ≠°ËøéÁ§æÁæ§Ë≤¢Áçª‰ª•ÊèêÂçáÂÖ∂ËÉΩÂäõÂíåÂΩ±ÈüøÂäõ„ÄÇ

##### **CollectiveSFT: Scaling Large Language Models for Chinese Medical Benchmark with Collective Instructions in Healthcare**
2407.19705v2 by Jingwei Zhu, Minghuan Tan, Min Yang, Ruixue Li, Hamid Alinejad-Rokny

The rapid progress in Large Language Models (LLMs) has prompted the creation
of numerous benchmarks to evaluate their capabilities.This study focuses on the
Comprehensive Medical Benchmark in Chinese (CMB), showcasing how dataset
diversity and distribution in supervised fine-tuning (SFT) may enhance LLM
performance.Remarkably, We successfully trained a smaller base model to achieve
scores comparable to larger models, indicating that a diverse and
well-distributed dataset can optimize performance regardless of model size.This
study suggests that even smaller models may reach high performance levels with
carefully curated and varied datasets. By integrating a wide range of
instructional content, our approach addresses potential issues such as data
quality inconsistencies. Our results imply that a broader spectrum of training
data may enhance a model's ability to generalize and perform effectively across
different medical scenarios, highlighting the importance of dataset quality and
diversity in fine-tuning processes. We open-source the model for future
research at https://github.com/CAS-SIAT-XinHai/CollectiveSFT

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÂø´ÈÄüÈÄ≤Â±ï‰øÉÊàê‰∫ÜË®±Â§öÂü∫Ê∫ñÁöÑÂª∫Á´ãÔºå‰ª•Ë©ï‰º∞ÂÆÉÂÄëÁöÑËÉΩÂäõ„ÄÇÊú¨Á†îÁ©∂Â∞àÊ≥®Êñº‰∏≠ÊñáÁ∂úÂêàÈÜ´ÁôÇÂü∫Ê∫ñ (CMB)ÔºåÂ±ïÁ§∫‰∫ÜÁõ£Áù£ÂæÆË™ø (SFT) ‰∏≠ÁöÑË≥áÊñôÈõÜÂ§öÊ®£ÊÄßÂíåÂàÜ‰ΩàÂ¶Ç‰ΩïÂ¢ûÂº∑ LLM ÊïàËÉΩ„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÊàëÂÄëÊàêÂäüÂú∞Ë®ìÁ∑¥‰∫Ü‰∏ÄÂÄãËºÉÂ∞èÁöÑÂü∫Á§éÊ®°ÂûãÔºå‰ª•ÈÅîÂà∞ËàáËºÉÂ§ßÂûãÊ®°ÂûãÁõ∏Áï∂ÁöÑÂàÜÊï∏ÔºåÈÄôË°®Êòé‰∏ÄÂÄãÂ§öÊ®£Âåñ‰∏îÂàÜ‰ΩàËâØÂ•ΩÁöÑË≥áÊñôÈõÜÂèØ‰ª•ÊúÄ‰Ω≥ÂåñÊïàËÉΩÔºåËÄåËàáÊ®°ÂûãÂ§ßÂ∞èÁÑ°Èóú„ÄÇÊú¨Á†îÁ©∂Ë°®ÊòéÔºåÂç≥‰ΩøÊòØËºÉÂ∞èÁöÑÊ®°ÂûãÔºåÂè™Ë¶Å‰ΩøÁî®Á∂ìÈÅé‰ªîÁ¥∞Á≠ñÂäÉ‰∏îÂ§öÊ®£ÂåñÁöÑË≥áÊñôÈõÜÔºå‰πüËÉΩÈÅîÂà∞È´òÊ∞¥Ê∫ñÁöÑÊïàËÉΩ„ÄÇÈÄèÈÅéÊï¥ÂêàÂª£Ê≥õÁöÑÊïôÂ≠∏ÂÖßÂÆπÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïËß£Ê±∫‰∫ÜË≥áÊñôÂìÅË≥™‰∏ç‰∏ÄËá¥Á≠âÊΩõÂú®ÂïèÈ°å„ÄÇÊàëÂÄëÁöÑÁµêÊûúË°®ÊòéÔºåÊõ¥Âª£Ê≥õÁöÑË®ìÁ∑¥Ë≥áÊñôÁØÑÂúçÂèØËÉΩÊúÉÂ¢ûÂº∑Ê®°ÂûãÂú®‰∏çÂêåÈÜ´ÁôÇÂ†¥ÊôØ‰∏≠Ê¶ÇÊã¨ÂíåÊúâÊïàÂü∑Ë°åÁöÑËÉΩÂäõÔºåÁ™ÅÈ°Ø‰∫ÜË≥áÊñôÈõÜÂìÅË≥™ÂíåÂ§öÊ®£ÊÄßÂú®ÂæÆË™øÈÅéÁ®ã‰∏≠ÊâÆÊºîÁöÑÈáçË¶ÅËßíËâ≤„ÄÇÊàëÂÄëÂú® https://github.com/CAS-SIAT-XinHai/CollectiveSFT ÈñãÊ∫êÊ≠§Ê®°Âûã‰ª•‰æõÂ∞á‰æÜÁ†îÁ©∂„ÄÇ

##### **Beyond Metrics: A Critical Analysis of the Variability in Large Language Model Evaluation Frameworks**
2407.21072v1 by Marco AF Pimentel, Cl√©ment Christophe, Tathagata Raha, Prateek Munjal, Praveen K Kanithi, Shadab Khan

As large language models (LLMs) continue to evolve, the need for robust and
standardized evaluation benchmarks becomes paramount. Evaluating the
performance of these models is a complex challenge that requires careful
consideration of various linguistic tasks, model architectures, and
benchmarking methodologies. In recent years, various frameworks have emerged as
noteworthy contributions to the field, offering comprehensive evaluation tests
and benchmarks for assessing the capabilities of LLMs across diverse domains.
This paper provides an exploration and critical analysis of some of these
evaluation methodologies, shedding light on their strengths, limitations, and
impact on advancing the state-of-the-art in natural language processing.

ÊëòË¶ÅÔºöÈö®ËëóÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÊåÅÁ∫åÊºîÈÄ≤ÔºåÂ∞çÊñºÂÅ•ÂÖ®‰∏îÊ®ôÊ∫ñÂåñÁöÑË©ï‰º∞Âü∫Ê∫ñÁöÑÈúÄÊ±ÇËÆäÂæóËá≥ÈóúÈáçË¶Å„ÄÇË©ï‰º∞ÈÄô‰∫õÊ®°ÂûãÁöÑÊïàËÉΩÊòØ‰∏ÄÈ†ÖË§áÈõúÁöÑÊåëÊà∞ÔºåÈúÄË¶Å‰ªîÁ¥∞ËÄÉÈáèÂêÑÁ®ÆË™ûË®Ä‰ªªÂãô„ÄÅÊ®°ÂûãÊû∂ÊßãÂíåÂü∫Ê∫ñÊñπÊ≥ï„ÄÇËøëÂπ¥‰æÜÔºåÂêÑÁ®ÆÊû∂ÊßãÂ∑≤ÊàêÁÇ∫Ë©≤È†òÂüüÁöÑÈ°ØËëóË≤¢ÁçªÔºåÊèê‰æõÂÖ®Èù¢ÁöÑË©ï‰º∞Ê∏¨Ë©¶ÂíåÂü∫Ê∫ñÔºåÁî®ÊñºË©ï‰º∞ LLM Âú®‰∏çÂêåÈ†òÂüüÁöÑËÉΩÂäõ„ÄÇÊú¨ÊñáÊé¢Ë®é‰∏¶ÊâπÂà§ÊÄßÂú∞ÂàÜÊûêÂÖ∂‰∏≠‰∏Ä‰∫õË©ï‰º∞ÊñπÊ≥ïÔºåÈó°ÊòéÂÖ∂ÂÑ™Èªû„ÄÅÈôêÂà∂ÂíåÂ∞çËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜÈ†òÂüüÈÄ≤Ê≠•ÁöÑÂΩ±Èüø„ÄÇ

##### **Urban Traffic Accident Risk Prediction Revisited: Regionality, Proximity, Similarity and Sparsity**
2407.19668v1 by Minxiao Chen, Haitao Yuan, Nan Jiang, Zhifeng Bao, Shangguang Wang

Traffic accidents pose a significant risk to human health and property
safety. Therefore, to prevent traffic accidents, predicting their risks has
garnered growing interest. We argue that a desired prediction solution should
demonstrate resilience to the complexity of traffic accidents. In particular,
it should adequately consider the regional background, accurately capture both
spatial proximity and semantic similarity, and effectively address the sparsity
of traffic accidents. However, these factors are often overlooked or difficult
to incorporate. In this paper, we propose a novel multi-granularity
hierarchical spatio-temporal network. Initially, we innovate by incorporating
remote sensing data, facilitating the creation of hierarchical
multi-granularity structure and the comprehension of regional background. We
construct multiple high-level risk prediction tasks to enhance model's ability
to cope with sparsity. Subsequently, to capture both spatial proximity and
semantic similarity, region feature and multi-view graph undergo encoding
processes to distill effective representations. Additionally, we propose
message passing and adaptive temporal attention module that bridges different
granularities and dynamically captures time correlations inherent in traffic
accident patterns. At last, a multivariate hierarchical loss function is
devised considering the complexity of the prediction purpose. Extensive
experiments on two real datasets verify the superiority of our model against
the state-of-the-art methods.

ÊëòË¶ÅÔºö‰∫§ÈÄö‰∫ãÊïÖÂ∞ç‰∫∫È°ûÂÅ•Â∫∑ÂíåË≤°Áî¢ÂÆâÂÖ®ÊßãÊàêÈáçÂ§ßÈ¢®Èö™„ÄÇÂõ†Ê≠§ÔºåÈ†êÊ∏¨‰∫§ÈÄö‰∫ãÊïÖÈ¢®Èö™Â∑≤ÂºïËµ∑Ë∂ä‰æÜË∂äÂ§ßÁöÑËààË∂£„ÄÇÊàëÂÄëË™çÁÇ∫ÔºåÁêÜÊÉ≥ÁöÑÈ†êÊ∏¨Ëß£Ê±∫ÊñπÊ°àÊáâÂ±ïÁèæÂá∫Â∞ç‰∫§ÈÄö‰∫ãÊïÖË§áÈõúÊÄßÁöÑÈüåÊÄß„ÄÇÂÖ∑È´îËÄåË®ÄÔºåÂÆÉÊáâÂÖÖÂàÜËÄÉÊÖÆÂçÄÂüüËÉåÊôØÔºåÊ∫ñÁ¢∫ÊçïÊçâÁ©∫ÈñìÊé•ËøëÂ∫¶ÂíåË™ûÁæ©Áõ∏‰ººÊÄßÔºå‰∏¶ÊúâÊïàËß£Ê±∫‰∫§ÈÄö‰∫ãÊïÖÁöÑÁ®ÄÁñèÊÄß„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÂõ†Á¥†ÈÄöÂ∏∏Ë¢´ÂøΩË¶ñÊàñÈõ£‰ª•Á¥çÂÖ•„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊñ∞Á©éÁöÑÂ§öÁ≤íÂ∫¶ÂàÜÂ±§ÊôÇÁ©∫Á∂≤Ë∑Ø„ÄÇÊúÄÂàùÔºåÊàëÂÄëÂâµÊñ∞Âú∞Á¥çÂÖ•‰∫ÜÈÅôÊÑüÊï∏ÊìöÔºå‰øÉËøõ‰∫ÜÂàÜÂ±§Â§öÁ≤íÂ∫¶ÁµêÊßãÁöÑÂâµÂª∫ÂíåÂçÄÂüüËÉåÊôØÁöÑÁêÜËß£„ÄÇÊàëÂÄëÊßãÂª∫‰∫ÜÂ§öÂÄãÈ´òÁ¥öÈ¢®Èö™È†êÊ∏¨‰ªªÂãôÔºå‰ª•Â¢ûÂº∑Ê®°ÂûãÊáâÂ∞çÁ®ÄÁñèÊÄßÁöÑËÉΩÂäõ„ÄÇÈö®ÂæåÔºåÁÇ∫‰∫ÜÊçïÊçâÁ©∫ÈñìÊé•ËøëÂ∫¶ÂíåË™ûÁæ©Áõ∏‰ººÊÄßÔºåÂçÄÂüüÁâπÂæµÂíåÂ§öË¶ñÂúñÂúñË°®Á∂ìÈÅéÁ∑®Á¢ºÈÅéÁ®ãÔºå‰ª•ÊèêÂèñÊúâÊïàÁöÑË°®Á§∫„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèêÂá∫‰∫ÜÊ∂àÊÅØÂÇ≥ÈÅûÂíåËá™ÈÅ©ÊáâÊôÇÈñìÊ≥®ÊÑèÂäõÊ®°ÁµÑÔºåÂÆÉÊû∂Ëµ∑‰∫Ü‰∏çÂêåÁ≤íÂ∫¶‰πãÈñìÁöÑÊ©ãÊ®ëÔºå‰∏¶ÂãïÊÖãÊçïÊçâ‰∫§ÈÄö‰∫ãÊïÖÊ®°Âºè‰∏≠Âõ∫ÊúâÁöÑÊôÇÈñìÁõ∏ÈóúÊÄß„ÄÇÊúÄÂæåÔºåËÄÉÊÖÆÂà∞È†êÊ∏¨ÁõÆÁöÑÁöÑË§áÈõúÊÄßÔºåË®≠Ë®à‰∫Ü‰∏ÄÂÄãÂ§öËÆäÈáèÂàÜÂ±§ÊêçÂ§±ÂáΩÊï∏„ÄÇÂú®ÂÖ©ÂÄãÁúüÂØ¶Êï∏ÊìöÈõÜ‰∏äÁöÑÂ§ßÈáèÂØ¶È©óÈ©óË≠â‰∫ÜÊàëÂÄëÊ®°ÂûãÂÑ™ÊñºÊúÄÂÖàÈÄ≤ÊñπÊ≥ïÁöÑÂÑ™Ë∂äÊÄß„ÄÇ

##### **Overcoming Uncertain Incompleteness for Robust Multimodal Sequential Diagnosis Prediction via Knowledge Distillation and Random Data Erasing**
2407.19540v1 by Heejoon Koo

In this paper, we present NECHO v2, a novel framework designed to enhance the
predictive accuracy of multimodal sequential patient diagnoses under uncertain
missing visit sequences, a common challenge in clinical settings. Firstly, we
modify NECHO to handle uncertain modality representation dominance under the
imperfect data. Next, we develop a systematic knowledge distillation by
employing the modified NECHO as both teacher and student. It encompasses a
modality-wise contrastive and hierarchical distillation, transformer
representation random distillation, along with other distillations to align
representations tightly and effectively. We also utilise random erasing on
individual data points within sequences during both training and distillation
of teacher to lightly simulate scenario with missing visit information to
foster effective knowledge transfer. As a result, NECHO v2 verifies itself by
showing superiority in multimodal sequential diagnosis prediction on both
balanced and imbalanced incomplete settings on multimodal healthcare data.

ÊëòË¶ÅÔºöÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü NECHO v2Ôºå‰∏ÄÂÄãÊñ∞Á©éÁöÑÊ°ÜÊû∂ÔºåÊó®Âú®Â¢ûÂº∑Â§öÊ®°ÊÖãÈ†ÜÂ∫èÊÇ£ËÄÖË®∫Êñ∑ÁöÑÈ†êÊ∏¨Ê∫ñÁ¢∫Â∫¶ÔºåÂú®Ëá®Â∫äÁí∞Â¢É‰∏≠Â∏∏Ë¶ãÁöÑÊåëÊà∞ÊòØ‰∏çÁ¢∫ÂÆöÈÅ∫ÊºèÁöÑË®™ÂïèÂ∫èÂàó„ÄÇÈ¶ñÂÖàÔºåÊàëÂÄë‰øÆÊîπ NECHO ‰ª•ËôïÁêÜ‰∏çÂÆåÁæéÊï∏Êìö‰∏ãÁöÑ‰∏çÁ¢∫ÂÆöÊ®°ÊÖãË°®Á§∫ÂÑ™Âã¢„ÄÇÊé•‰∏ã‰æÜÔºåÊàëÂÄëÈÄöÈÅé‰ΩøÁî®‰øÆÊîπÂæåÁöÑ NECHO ‰ΩúÁÇ∫ÊïôÂ∏´ÂíåÂ≠∏Áîü‰æÜÈñãÁôºÁ≥ªÁµ±ÁöÑÁü•Ë≠òÊèêÁÖâ„ÄÇÂÆÉÂåÖÂê´Ê®°ÊÖãÂ∞çÊØîÂíåÂàÜÂ±§ÊèêÁÖâ„ÄÅTransformerË°®Á§∫Èö®Ê©üÊèêÁÖâ‰ª•ÂèäÂÖ∂‰ªñÊèêÁÖâÔºå‰ª•Á∑äÂØÜÊúâÊïàÂú∞Â∞çÈΩäË°®Á§∫„ÄÇÊàëÂÄëÈÇÑÂú®Ë®ìÁ∑¥ÂíåÊïôÂ∏´ÊèêÁÖâÈÅéÁ®ã‰∏≠Â∞çÂ∫èÂàó‰∏≠ÁöÑÂÄãÂà•Êï∏ÊìöÈªû‰ΩøÁî®Èö®Ê©üÊì¶Èô§Ôºå‰ª•ËºïÂæÆÊ®°Êì¨ÈÅ∫ÊºèË®™Âïè‰ø°ÊÅØÁöÑÂ†¥ÊôØÔºå‰ª•‰øÉÈÄ≤ÊúâÊïàÁöÑÁü•Ë≠òÂÇ≥ÈÅû„ÄÇÂõ†Ê≠§ÔºåNECHO v2 ÈÄöÈÅéÂú®Â§öÊ®°ÊÖãÈÜ´ÁôÇ‰øùÂÅ•Êï∏ÊìöÁöÑÂπ≥Ë°°Âíå‰∏çÂπ≥Ë°°‰∏çÂÆåÊï¥Ë®≠ÁΩÆ‰∏äÈ°ØÁ§∫Â§öÊ®°ÊÖãÈ†ÜÂ∫èË®∫Êñ∑È†êÊ∏¨ÁöÑÂÑ™Ë∂äÊÄß‰æÜÈ©óË≠âËá™Ë∫´„ÄÇ

##### **Nudging Consent and the New Opt Out System to the Processing of Health Data in England**
2407.19447v1 by Janos Meszaros, Chih-hsing Ho, Marcelo Corrales Compagnucci

This chapter examines the challenges of the revised opt out system and the
secondary use of health data in England. The analysis of this data could be
very valuable for science and medical treatment as well as for the discovery of
new drugs. For this reason, the UK government established the care.data program
in 2013. The aim of the project was to build a central nationwide database for
research and policy planning. However, the processing of personal data was
planned without proper public engagement. Research has suggested that IT
companies, such as in the Google DeepMind deal case, had access to other kinds
of sensitive data and failed to comply with data protection law. Since May
2018, the government has launched the national data opt out system with the
hope of regaining public trust. Nevertheless, there are no evidence of
significant changes in the ND opt out, compared to the previous opt out system.
Neither in the use of secondary data, nor in the choices that patients can
make. The only notorious difference seems to be in the way that these options
are communicated and framed to the patients. Most importantly, according to the
new ND opt out, the type 1 opt out option, which is the only choice that truly
stops data from being shared outside direct care, will be removed in 2020.
According to the Behavioral Law and Economics literature (Nudge Theory),
default rules, such as the revised opt out system in England, are very
powerful, because people tend to stick to the default choices made readily
available to them. The crucial question analyzed in this chapter is whether it
is desirable for the UK government to stop promoting the type 1 opt outs, and
whether this could be seen as a kind of hard paternalism.

ÊëòË¶ÅÔºö<paragraph>Êú¨Á´†Êé¢Ë®é‰∫ÜËã±Âúã‰øÆÊîπÂæåÁöÑÈÄÄÂá∫Ê©üÂà∂Âíå‰∫åÊ¨°‰ΩøÁî®ÂÅ•Â∫∑Ë≥áÊñôÊâÄÈù¢Ëá®ÁöÑÊåëÊà∞„ÄÇÂàÜÊûêÈÄô‰∫õË≥áÊñôÂ∞çÊñºÁßëÂ≠∏ÂíåÈÜ´ÁôÇÊ≤ªÁôÇ‰ª•ÂèäÁôºÁèæÊñ∞Ëó•Áâ©ËÄåË®ÄÔºåÂèØËÉΩÈùûÂ∏∏ÊúâÂÉπÂÄº„ÄÇÂü∫ÊñºÊ≠§ÂéüÂõ†ÔºåËã±ÂúãÊîøÂ∫úÊñº 2013 Âπ¥Âª∫Á´ã‰∫Ü care.data Ë®àÁï´„ÄÇË©≤Â∞àÊ°àÁöÑÁõÆÊ®ôÊòØÂª∫Á´ã‰∏ÄÂÄãÂÖ®ÂúãÊÄßÁöÑ‰∏≠Â§ÆË≥áÊñôÂ∫´Ôºå‰ª•ÈÄ≤Ë°åÁ†îÁ©∂ÂíåÊîøÁ≠ñË¶èÂäÉ„ÄÇÁÑ∂ËÄåÔºåÂÄã‰∫∫Ë≥áÊñôÁöÑËôïÁêÜÊòØÂú®Ê≤íÊúâÈÅ©Áï∂ÂÖ¨ÁúæÂèÉËàáÁöÑÊÉÖÊ≥Å‰∏ãÈÄ≤Ë°åË¶èÂäÉÁöÑ„ÄÇÁ†îÁ©∂Ë°®ÊòéÔºå‰æãÂ¶ÇÂú® Google DeepMind ‰∫§ÊòìÊ°à‰æã‰∏≠ÔºåIT ÂÖ¨Âè∏ÂèØ‰ª•Â≠òÂèñÂÖ∂‰ªñÈ°ûÂûãÁöÑÊïèÊÑüË≥áÊñôÔºå‰∏îÊú™ËÉΩÈÅµÂÆàË≥áÊñô‰øùË≠∑Ê≥ï„ÄÇËá™ 2018 Âπ¥ 5 Êúà‰ª•‰æÜÔºåÊîøÂ∫úÂ∑≤Êé®Âá∫ÂÖ®ÂúãË≥áÊñôÈÄÄÂá∫Ê©üÂà∂ÔºåÂ∏åÊúõËÉΩÈáçÊñ∞Áç≤ÂæóÂÖ¨Áúæ‰ø°‰ªª„ÄÇÂÑòÁÆ°Â¶ÇÊ≠§ÔºåËàáÂÖàÂâçÁöÑÈÄÄÂá∫Ê©üÂà∂Áõ∏ÊØîÔºå‰∏¶ÁÑ°Ë≠âÊìöÈ°ØÁ§∫ÂÖ®ÂúãË≥áÊñôÈÄÄÂá∫Ê©üÂà∂ÊúâÈ°ØËëóËÆäÂåñ„ÄÇÁÑ°Ë´ñÊòØÂú®‰∫åÊ¨°Ë≥áÊñôÁöÑ‰ΩøÁî®‰∏äÔºåÊàñÊòØÂú®ÊÇ£ËÄÖÂèØ‰ª•ÂÅöÂá∫ÁöÑÈÅ∏Êìá‰∏äÔºåÁöÜÊòØÂ¶ÇÊ≠§„ÄÇÂîØ‰∏ÄÈ°ØËëóÁöÑÂ∑ÆÁï∞‰ºº‰πéÂú®ÊñºÈÄô‰∫õÈÅ∏È†ÖÁöÑÊ∫ùÈÄöÂíåÂÇ≥ÈÅîÊñπÂºè„ÄÇÊúÄÈáçË¶ÅÁöÑÊòØÔºåÊ†πÊìöÊñ∞ÁöÑÂÖ®ÂúãË≥áÊñôÈÄÄÂá∫Ê©üÂà∂ÔºåÈ°ûÂûã 1 ÈÄÄÂá∫ÈÅ∏È†ÖÔºàÈÄôÊòØÂîØ‰∏ÄÁúüÊ≠£ËÉΩÈòªÊ≠¢Ë≥áÊñôÂú®Áõ¥Êé•ÁÖßË≠∑‰πãÂ§ñË¢´ÂàÜ‰∫´ÁöÑÈÅ∏È†ÖÔºâÂ∞áÊñº 2020 Âπ¥Ë¢´ÁßªÈô§„ÄÇÊ†πÊìöË°åÁÇ∫Ê≥ïËàáÁ∂ìÊøüÂ≠∏ÊñáÁçªÔºàÊé®Ë´ñÁêÜË´ñÔºâÔºåÈ†êË®≠Ë¶èÂâáÔºà‰æãÂ¶ÇËã±Âúã‰øÆÊîπÂæåÁöÑÈÄÄÂá∫Ê©üÂà∂ÔºâÈùûÂ∏∏ÊúâÊïàÔºåÂõ†ÁÇ∫‰∫∫ÂÄëÂÇæÂêëÊñºÂ†ÖÊåÅÂÆπÊòìÂèñÂæóÁöÑÈ†êË®≠ÈÅ∏È†Ö„ÄÇÊú¨Á´†ÂàÜÊûêÁöÑÈóúÈçµÂïèÈ°åÊòØÔºåËã±ÂúãÊîøÂ∫úÂÅúÊ≠¢Êé®Âª£È°ûÂûã 1 ÈÄÄÂá∫ÊòØÂê¶ÂèØÂèñÔºå‰ª•ÂèäÈÄôÊòØÂê¶ÂèØ‰ª•Ë¶ñÁÇ∫‰∏ÄÁ®ÆÂö¥Âé≤ÁöÑÁà∂Ê¨ä‰∏ªÁæ©„ÄÇ</paragraph>

##### **ASI-Seg: Audio-Driven Surgical Instrument Segmentation with Surgeon Intention Understanding**
2407.19435v1 by Zhen Chen, Zongming Zhang, Wenwu Guo, Xingjian Luo, Long Bai, Jinlin Wu, Hongliang Ren, Hongbin Liu

Surgical instrument segmentation is crucial in surgical scene understanding,
thereby facilitating surgical safety. Existing algorithms directly detected all
instruments of pre-defined categories in the input image, lacking the
capability to segment specific instruments according to the surgeon's
intention. During different stages of surgery, surgeons exhibit varying
preferences and focus toward different surgical instruments. Therefore, an
instrument segmentation algorithm that adheres to the surgeon's intention can
minimize distractions from irrelevant instruments and assist surgeons to a
great extent. The recent Segment Anything Model (SAM) reveals the capability to
segment objects following prompts, but the manual annotations for prompts are
impractical during the surgery. To address these limitations in operating
rooms, we propose an audio-driven surgical instrument segmentation framework,
named ASI-Seg, to accurately segment the required surgical instruments by
parsing the audio commands of surgeons. Specifically, we propose an
intention-oriented multimodal fusion to interpret the segmentation intention
from audio commands and retrieve relevant instrument details to facilitate
segmentation. Moreover, to guide our ASI-Seg segment of the required surgical
instruments, we devise a contrastive learning prompt encoder to effectively
distinguish the required instruments from the irrelevant ones. Therefore, our
ASI-Seg promotes the workflow in the operating rooms, thereby providing
targeted support and reducing the cognitive load on surgeons. Extensive
experiments are performed to validate the ASI-Seg framework, which reveals
remarkable advantages over classical state-of-the-art and medical SAMs in both
semantic segmentation and intention-oriented segmentation. The source code is
available at https://github.com/Zonmgin-Zhang/ASI-Seg.

ÊëòË¶ÅÔºöÊâãË°ìÂô®Ê¢∞ÂàÜÂâ≤Â∞çÊñºÊâãË°ìÂ†¥ÊôØÁêÜËß£Ëá≥ÈóúÈáçË¶ÅÔºå
ÂæûËÄå‰øÉÈÄ≤ÊâãË°ìÂÆâÂÖ®„ÄÇÁèæÊúâÊºîÁÆóÊ≥ïÁõ¥Êé•ÂÅµÊ∏¨Ëº∏ÂÖ•ÂΩ±ÂÉè‰∏≠ÊâÄÊúâÈ†êÂÆöÁæ©È°ûÂà•ÁöÑÂô®Ê¢∞ÔºåÁº∫‰πèÊ†πÊìöÂ§ñÁßëÈÜ´Â∏´ÊÑèÂúñÂàÜÂâ≤ÁâπÂÆöÂô®Ê¢∞ÁöÑËÉΩÂäõ„ÄÇÂú®ÊâãË°ìÁöÑ‰∏çÂêåÈöéÊÆµÔºåÂ§ñÁßëÈÜ´Â∏´ÊúÉÂ∞ç‰∏çÂêåÁöÑÊâãË°ìÂô®Ê¢∞Ë°®ÁèæÂá∫‰∏çÂêåÁöÑÂÅèÂ•ΩÂíåÈóúÊ≥®„ÄÇÂõ†Ê≠§Ôºå‰∏ÄÁ®ÆÈÅµÂæ™Â§ñÁßëÈÜ´Â∏´ÊÑèÂúñÁöÑÂô®Ê¢∞ÂàÜÂâ≤ÊºîÁÆóÊ≥ïÂèØ‰ª•ÊúÄÂ§ßÁ®ãÂ∫¶Âú∞Ê∏õÂ∞ëËàáÊâãË°ìÁÑ°ÈóúÁöÑÂô®Ê¢∞ÁöÑÂπ≤ÊìæÔºå‰∏¶Âú®ÂæàÂ§ßÁ®ãÂ∫¶‰∏äÂçîÂä©Â§ñÁßëÈÜ´Â∏´„ÄÇÊúÄËøëÁöÑ Segment Anything Model (SAM) Êè≠Á§∫‰∫ÜÊ†πÊìöÊèêÁ§∫ÂàÜÂâ≤Áâ©‰ª∂ÁöÑËÉΩÂäõÔºå‰ΩÜÊèêÁ§∫ÁöÑÊâãÂãïË®ªËß£Âú®ÊâãË°ìÈÅéÁ®ã‰∏≠‰∏çÂàáÂØ¶Èöõ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÊâãË°ìÂÆ§‰∏≠ÁöÑÈÄô‰∫õÈôêÂà∂ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÈü≥Ë®äÈ©ÖÂãïÁöÑÊâãË°ìÂô®Ê¢∞ÂàÜÂâ≤Êû∂ÊßãÔºåÁ®±ÁÇ∫ ASI-SegÔºåÈÄöÈÅéËß£ÊûêÂ§ñÁßëÈÜ´Â∏´ÁöÑÈü≥Ë®äÂëΩ‰ª§‰æÜÊ∫ñÁ¢∫ÂàÜÂâ≤ÊâÄÈúÄÁöÑÂô®Ê¢∞„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊÑèÂúñÂ∞éÂêëÁöÑÂ§öÊ®°ÊÖãËûçÂêàÔºåÂæûÈü≥Ë®äÂëΩ‰ª§‰∏≠Ëß£ÈáãÂàÜÂâ≤ÊÑèÂúñ‰∏¶Ê™¢Á¥¢Áõ∏ÈóúÂô®Ê¢∞Á¥∞ÁØÄ‰ª•Âà©ÊñºÂàÜÂâ≤„ÄÇÊ≠§Â§ñÔºåÁÇ∫‰∫ÜÊåáÂ∞éÊàëÂÄëÁöÑ ASI-Seg ÂàÜÂâ≤ÊâÄÈúÄÁöÑÂô®Ê¢∞ÔºåÊàëÂÄëË®≠Ë®à‰∫Ü‰∏ÄÂÄãÂ∞çÊØîÂ≠∏ÁøíÊèêÁ§∫Á∑®Á¢ºÂô®Ôºå‰ª•ÊúâÊïàÂçÄÂàÜÊâÄÈúÄÁöÑÂô®Ê¢∞Âíå‰∏çÁõ∏ÈóúÁöÑÂô®Ê¢∞„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëÁöÑ ASI-Seg ‰øÉÈÄ≤‰∫ÜÊâãË°ìÂÆ§‰∏≠ÁöÑÂ∑•‰ΩúÊµÅÁ®ãÔºåÂæûËÄåÊèê‰æõ‰∫ÜÊúâÈáùÂ∞çÊÄßÁöÑÊîØÊè¥Ôºå‰∏¶Èôç‰Ωé‰∫ÜÂ§ñÁßëÈÜ´Â∏´ÁöÑË™çÁü•Ë≤†Êìî„ÄÇÈÄ≤Ë°å‰∫ÜÂ§ßÈáèÁöÑÂØ¶È©ó‰æÜÈ©óË≠â ASI-Seg Êû∂ÊßãÔºåÈÄôÊè≠Á§∫‰∫ÜÂú®Ë™ûÁæ©ÂàÜÂâ≤ÂíåÊÑèÂúñÂ∞éÂêëÂàÜÂâ≤‰∏≠ÔºåËàáÂÇ≥Áµ±ÁöÑÊúÄÊñ∞ÊäÄË°ìÂíåÈÜ´Â≠∏ SAM Áõ∏ÊØîÔºåÂÆÉÂÖ∑ÊúâÈ°ØËëóÁöÑÂÑ™Âã¢„ÄÇÂéüÂßãÁ¢ºÂèØÂú® https://github.com/Zonmgin-Zhang/ASI-Seg Áç≤Âæó„ÄÇ

##### **A Generic Review of Integrating Artificial Intelligence in Cognitive Behavioral Therapy**
2407.19422v1 by Meng Jiang, Qing Zhao, Jianqiang Li, Fan Wang, Tianyu He, Xinyan Cheng, Bing Xiang Yang, Grace W. K. Ho, Guanghui Fu

Cognitive Behavioral Therapy (CBT) is a well-established intervention for
mitigating psychological issues by modifying maladaptive cognitive and
behavioral patterns. However, delivery of CBT is often constrained by resource
limitations and barriers to access. Advancements in artificial intelligence
(AI) have provided technical support for the digital transformation of CBT.
Particularly, the emergence of pre-training models (PTMs) and large language
models (LLMs) holds immense potential to support, augment, optimize and
automate CBT delivery. This paper reviews the literature on integrating AI into
CBT interventions. We begin with an overview of CBT. Then, we introduce the
integration of AI into CBT across various stages: pre-treatment, therapeutic
process, and post-treatment. Next, we summarized the datasets relevant to some
CBT-related tasks. Finally, we discuss the benefits and current limitations of
applying AI to CBT. We suggest key areas for future research, highlighting the
need for further exploration and validation of the long-term efficacy and
clinical utility of AI-enhanced CBT. The transformative potential of AI in
reshaping the practice of CBT heralds a new era of more accessible, efficient,
and personalized mental health interventions.

ÊëòË¶ÅÔºöË™çÁü•Ë°åÁÇ∫ÁôÇÊ≥ï (CBT) ÊòØ‰∏ÄÁ®ÆÂÆåÂñÑÁöÑÂπ≤È†êÊé™ÊñΩÔºåÈÄèÈÅéË™øÊï¥ÈÅ©Êáâ‰∏çËâØÁöÑË™çÁü•ÂíåË°åÁÇ∫Ê®°Âºè‰æÜÊ∏õËºïÂøÉÁêÜÂïèÈ°å„ÄÇÁÑ∂ËÄåÔºåCBT ÁöÑÊèê‰æõÂæÄÂæÄÂèóÂà∞Ë≥áÊ∫êÈôêÂà∂ÂíåÁç≤ÂèñÈöúÁ§ôÁöÑÈôêÂà∂„ÄÇ‰∫∫Â∑•Êô∫ÊÖß (AI) ÁöÑÈÄ≤Ê≠•ÁÇ∫ CBT ÁöÑÊï∏‰ΩçËΩâÂûãÊèê‰æõ‰∫ÜÊäÄË°ìÊîØÊè¥„ÄÇÁâπÂà•ÊòØÔºåÈ†êË®ìÁ∑¥Ê®°Âûã (PTM) ÂíåÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÂá∫ÁèæÂÖ∑ÊúâÂ∑®Â§ßÁöÑÊΩõÂäõÔºåÂèØ‰ª•ÊîØÊè¥„ÄÅÊì¥ÂÖÖ„ÄÅÊúÄ‰Ω≥ÂåñÂíåËá™ÂãïÂåñ CBT ÁöÑÊèê‰æõ„ÄÇÊú¨ÊñáÂõûÈ°ß‰∫ÜÂ∞á AI Êï¥ÂêàÂà∞ CBT Âπ≤È†êÊé™ÊñΩÁöÑÊñáÁçª„ÄÇÊàëÂÄëÂæû CBT ÁöÑÊ¶ÇËø∞ÈñãÂßã„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄë‰ªãÁ¥π‰∫ÜÂú®ÂêÑÁ®ÆÈöéÊÆµÂ∞á AI Êï¥ÂêàÂà∞ CBT ‰∏≠ÔºöÊ≤ªÁôÇÂâç„ÄÅÊ≤ªÁôÇÈÅéÁ®ãÂíåÊ≤ªÁôÇÂæå„ÄÇÊé•‰∏ã‰æÜÔºåÊàëÂÄëÁ∏ΩÁµê‰∫ÜËàá‰∏Ä‰∫õ CBT Áõ∏Èóú‰ªªÂãôÁõ∏ÈóúÁöÑË≥áÊñôÈõÜ„ÄÇÊúÄÂæåÔºåÊàëÂÄëË®éË´ñ‰∫ÜÂ∞á AI ÊáâÁî®Êñº CBT ÁöÑÂ•ΩËôïÂíåÁõÆÂâçÁöÑÈôêÂà∂„ÄÇÊàëÂÄëÂª∫Ë≠∞Êú™‰æÜÁ†îÁ©∂ÁöÑ‰∏ªË¶ÅÈ†òÂüüÔºåÂº∑Ë™øÈúÄË¶ÅÈÄ≤‰∏ÄÊ≠•Êé¢Á¥¢ÂíåÈ©óË≠â AI Â¢ûÂº∑ CBT ÁöÑÈï∑ÊúüÁôÇÊïàÂíåËá®Â∫äÊïàÁî®„ÄÇAI Âú®ÈáçÂ°ë CBT ÂØ¶Âãô‰∏≠ÁöÑËΩâÂåñÊΩõÂäõÈ†êÁ§∫Ëëó‰∏ÄÂÄãÊñ∞ÁöÑÊôÇ‰ª£ÔºåÂç≥Êõ¥ÊòìÊñºÂèñÂæó„ÄÅÊõ¥ÊúâÊïàÁéáÂíåÊõ¥ÂÄã‰∫∫ÂåñÁöÑÂøÉÁêÜÂÅ•Â∫∑Âπ≤È†êÊé™ÊñΩ„ÄÇ

##### **Empowering Clinicians with Medical Decision Transformers: A Framework for Sepsis Treatment**
2407.19380v1 by Aamer Abdul Rahman, Pranav Agarwal, Rita Noumeir, Philippe Jouvet, Vincent Michalski, Samira Ebrahimi Kahou

Offline reinforcement learning has shown promise for solving tasks in
safety-critical settings, such as clinical decision support. Its application,
however, has been limited by the lack of interpretability and interactivity for
clinicians. To address these challenges, we propose the medical decision
transformer (MeDT), a novel and versatile framework based on the
goal-conditioned reinforcement learning paradigm for sepsis treatment
recommendation. MeDT uses the decision transformer architecture to learn a
policy for drug dosage recommendation. During offline training, MeDT utilizes
collected treatment trajectories to predict administered treatments for each
time step, incorporating known treatment outcomes, target acuity scores, past
treatment decisions, and current and past medical states. This analysis enables
MeDT to capture complex dependencies among a patient's medical history,
treatment decisions, outcomes, and short-term effects on stability. Our
proposed conditioning uses acuity scores to address sparse reward issues and to
facilitate clinician-model interactions, enhancing decision-making. Following
training, MeDT can generate tailored treatment recommendations by conditioning
on the desired positive outcome (survival) and user-specified short-term
stability improvements. We carry out rigorous experiments on data from the
MIMIC-III dataset and use off-policy evaluation to demonstrate that MeDT
recommends interventions that outperform or are competitive with existing
offline reinforcement learning methods while enabling a more interpretable,
personalized and clinician-directed approach.

ÊëòË¶ÅÔºöÈõ¢Á∑öÂº∑ÂåñÂ≠∏ÁøíÂ∑≤Â±ïÁèæÂá∫Ëß£Ê±∫Ë´∏Â¶ÇËá®Â∫äÊ±∫Á≠ñÊîØÊè¥Á≠âÂÆâÂÖ®ÈóúÈçµË®≠ÂÆö‰∏≠‰ªªÂãôÁöÑÊΩõÂäõ„ÄÇÁÑ∂ËÄåÔºåÂÖ∂ÊáâÁî®ÂèóÂà∞Ëá®Â∫äÈÜ´Â∏´Â∞çÂèØËß£ÈáãÊÄßÂíå‰∫íÂãïÊÄßÁöÑÁº∫‰πèÊâÄÈôêÂà∂„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÊèêÂá∫‰∫ÜÈÜ´ÁôÇÊ±∫Á≠ñËΩâÊèõÂô® (MeDT)ÔºåÈÄôÊòØ‰∏ÄÂÄãÂü∫ÊñºÁõÆÊ®ôÊ¢ù‰ª∂Âº∑ÂåñÂ≠∏ÁøíÁØÑ‰æãÁöÑÊñ∞Á©é‰∏îÂ§öÂäüËÉΩÁöÑÊû∂ÊßãÔºåÁî®ÊñºÊïóË°ÄÁóáÊ≤ªÁôÇÂª∫Ë≠∞„ÄÇMeDT ‰ΩøÁî®Ê±∫Á≠ñËΩâÊèõÂô®Êû∂Êßã‰æÜÂ≠∏ÁøíËó•Áâ©ÂäëÈáèÂª∫Ë≠∞ÁöÑÊîøÁ≠ñ„ÄÇÂú®Èõ¢Á∑öË®ìÁ∑¥ÊúüÈñìÔºåMeDT Âà©Áî®Êî∂ÈõÜÁöÑÊ≤ªÁôÇËªåË∑°‰æÜÈ†êÊ∏¨ÊØèÂÄãÊôÇÈñìÊ≠•È©üÁöÑÁÆ°ÁêÜÊ≤ªÁôÇÔºå‰∏¶Á¥çÂÖ•Â∑≤Áü•ÁöÑÊ≤ªÁôÇÁµêÊûú„ÄÅÁõÆÊ®ôÂö¥ÈáçÁ®ãÂ∫¶Ë©ïÂàÜ„ÄÅÈÅéÂéªÁöÑÊ≤ªÁôÇÊ±∫Á≠ñ‰ª•ÂèäÁï∂ÂâçÂíåÈÅéÂéªÁöÑÈÜ´ÁôÇÁãÄÊÖã„ÄÇÊ≠§ÂàÜÊûê‰Ωø MeDT ËÉΩÂ§†ÊçïÊçâÊÇ£ËÄÖÁóÖÂè≤„ÄÅÊ≤ªÁôÇÊ±∫Á≠ñ„ÄÅÁµêÊûú‰ª•ÂèäÂ∞çÁ©©ÂÆöÊÄßÁöÑÁü≠ÊúüÂΩ±Èüø‰πãÈñìÁöÑË§áÈõú‰æùË≥¥Èóú‰øÇ„ÄÇÊàëÂÄëÊèêÂá∫ÁöÑÊ¢ù‰ª∂‰ΩøÁî®Âö¥ÈáçÁ®ãÂ∫¶Ë©ïÂàÜ‰æÜËß£Ê±∫Á®ÄÁñèÁçéÂãµÂïèÈ°å‰∏¶‰øÉÈÄ≤Ëá®Â∫äÈÜ´Â∏´ËàáÊ®°ÂûãÁöÑ‰∫íÂãïÔºåÂæûËÄåÂ¢ûÂº∑Ê±∫Á≠ñÂà∂ÂÆö„ÄÇÂú®Ë®ìÁ∑¥‰πãÂæåÔºåMeDT ÂèØ‰ª•ÈÄöÈÅé‰ª•ÊâÄÈúÄÁöÑÊ≠£Èù¢ÁµêÊûúÔºàÂ≠òÊ¥ªÔºâÂíå‰ΩøÁî®ËÄÖÊåáÂÆöÁöÑÁü≠ÊúüÁ©©ÂÆöÊÄßÊîπÂñÑÁÇ∫Ê¢ù‰ª∂‰æÜÁî¢ÁîüÈáèË∫´ÊâìÈÄ†ÁöÑÊ≤ªÁôÇÂª∫Ë≠∞„ÄÇÊàëÂÄëÂ∞ç‰æÜËá™ MIMIC-III Ë≥áÊñôÈõÜÁöÑË≥áÊñôÈÄ≤Ë°å‰∫ÜÂö¥Ê†ºÁöÑÂØ¶È©óÔºå‰∏¶‰ΩøÁî®ÈùûÁ≠ñÁï•Ë©ï‰º∞‰æÜË≠âÊòé MeDT Êé®Ëñ¶ÁöÑÂπ≤È†êÊé™ÊñΩÂÑ™ÊñºÊàñËàáÁèæÊúâÁöÑÈõ¢Á∑öÂº∑ÂåñÂ≠∏ÁøíÊñπÊ≥ïÂÖ∑ÊúâÁ´∂Áà≠ÂäõÔºåÂêåÊôÇÂØ¶Áèæ‰∫ÜÊõ¥ÂÖ∑ÂèØËß£ÈáãÊÄß„ÄÅÂÄãÊÄßÂåñÂíåËá®Â∫äÈÜ´Â∏´ÊåáÂ∞éÁöÑÊñπÊ≥ï„ÄÇ

##### **Learning to Select the Best Forecasting Tasks for Clinical Outcome Prediction**
2407.19359v1 by Yuan Xue, Nan Du, Anne Mottram, Martin Seneviratne, Andrew M. Dai

We propose to meta-learn an a self-supervised patient trajectory forecast
learning rule by meta-training on a meta-objective that directly optimizes the
utility of the patient representation over the subsequent clinical outcome
prediction. This meta-objective directly targets the usefulness of a
representation generated from unlabeled clinical measurement forecast for later
supervised tasks.
  The meta-learned can then be directly used in target risk prediction, and the
limited available samples can be used for further fine-tuning the model
performance. The effectiveness of our approach is tested on a real open source
patient EHR dataset MIMIC-III. We are able to demonstrate that our
attention-based patient state representation approach can achieve much better
performance for predicting target risk with low resources comparing with both
direct supervised learning and pretraining with all-observation trajectory
forecast.

ÊëòË¶ÅÔºöÊàëÂÄëÊèêË≠∞ÈÄèÈÅéÂÖÉË®ìÁ∑¥‰æÜÂÖÉÂ≠∏Áøí‰∏ÄÂÄãËá™ÊàëÁõ£Áù£ÁöÑÊÇ£ËÄÖËªåË∑°È†êÊ∏¨Â≠∏ÁøíË¶èÂâáÔºå‰∏¶ÈÄèÈÅéÂÖÉÁõÆÊ®ôÁõ¥Êé•ÊúÄ‰Ω≥ÂåñÊÇ£ËÄÖË°®ÂæµÂú®ÂæåÁ∫åËá®Â∫äÁµêÊûúÈ†êÊ∏¨‰∏≠ÁöÑÊïàÁî®„ÄÇÊ≠§ÂÖÉÁõÆÊ®ôÁõ¥Êé•ÈáùÂ∞çÂæûÊú™Ê®ôË®òÁöÑËá®Â∫äÊ∏¨ÈáèÈ†êÊ∏¨ÊâÄÁî¢ÁîüÁöÑË°®ÂæµÂú®ÂæåÁ∫åÁõ£Áù£Âºè‰ªªÂãô‰∏≠ÁöÑÊïàÁî®„ÄÇ
ÂÖÉÂ≠∏ÁøíÂæåÔºåÂèØ‰ª•Áõ¥Êé•Áî®ÊñºÁõÆÊ®ôÈ¢®Èö™È†êÊ∏¨Ôºå‰∏îÂèØ‰ΩøÁî®ÊúâÈôêÁöÑÂèØÁî®Ê®£Êú¨ÈÄ≤‰∏ÄÊ≠•ÂæÆË™øÊ®°ÂûãÊïàËÉΩ„ÄÇÊàëÂÄëÁöÑÊñπÊ≥ï‰πãÊúâÊïàÊÄßÂ∑≤Âú®‰∏ÄÂÄãÁúüÂØ¶ÁöÑÈñãÊîæÂéüÂßãÁ¢ºÊÇ£ËÄÖÈõªÂ≠êÁóÖÊ≠∑Ë≥áÊñôÈõÜ MIMIC-III ‰∏äÈÄ≤Ë°åÊ∏¨Ë©¶„ÄÇÊàëÂÄëËÉΩÂ§†Ë≠âÊòéÔºåËàáÁõ¥Êé•Áõ£Áù£ÂºèÂ≠∏ÁøíÂíå‰ΩøÁî®ÊâÄÊúâËßÄÂØüËªåË∑°È†êÊ∏¨ÈÄ≤Ë°åÈ†êË®ìÁ∑¥Áõ∏ÊØîÔºåÊàëÂÄëÂü∫ÊñºÊ≥®ÊÑèÂäõÁöÑÊÇ£ËÄÖÁãÄÊÖãË°®ÂæµÊñπÊ≥ïÂèØ‰ª•ÈÅîÂà∞Êõ¥Â•ΩÁöÑÁõÆÊ®ôÈ¢®Èö™È†êÊ∏¨ÊïàËÉΩÔºå‰∏îË≥áÊ∫êÈúÄÊ±ÇËºÉ‰Ωé„ÄÇ

