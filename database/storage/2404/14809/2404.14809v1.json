{"2404.14809": {"publish_time": "2024-04-23", "title": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "paper_summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics.", "paper_summary_zh": "\u5716\u5f62\u662f\u4e00\u7a2e\u57fa\u672c\u8cc7\u6599\u6a21\u578b\uff0c\u7528\u65bc\u8868\u793a\u793e\u6703\u548c\u81ea\u7136\u754c\u4e2d\u5404\u7a2e\u5be6\u9ad4\u53ca\u5176\u8907\u96dc\u95dc\u4fc2\uff0c\u4f8b\u5982\u793e\u4ea4\u7db2\u8def\u3001\u904b\u8f38\u7db2\u8def\u3001\u91d1\u878d\u7db2\u8def\u548c\u751f\u7269\u91ab\u5b78\u7cfb\u7d71\u3002\u6700\u8fd1\uff0c\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5c55\u793a\u4e86\u5f37\u5927\u7684\u6982\u62ec\u80fd\u529b\uff0c\u53ef\u4ee5\u8655\u7406\u5404\u7a2e NLP \u548c\u591a\u6a21\u5f0f\u4efb\u52d9\uff0c\u4ee5\u56de\u7b54\u4f7f\u7528\u8005\u7684\u4efb\u610f\u554f\u984c\u548c\u7279\u5b9a\u9818\u57df\u7684\u5167\u5bb9\u751f\u6210\u3002\u8207\u5716\u5f62\u5b78\u7fd2\u6a21\u578b\u76f8\u6bd4\uff0cLLM \u5728\u89e3\u6c7a\u5716\u5f62\u4efb\u52d9\u7684\u6982\u62ec\u6311\u6230\u65b9\u9762\u4eab\u6709\u512a\u8d8a\u7684\u512a\u52e2\uff0c\u56e0\u70ba\u5b83\u6d88\u9664\u4e86\u8a13\u7df4\u5716\u5f62\u5b78\u7fd2\u6a21\u578b\u7684\u9700\u8981\u4e26\u964d\u4f4e\u4e86\u4eba\u5de5\u8a3b\u89e3\u7684\u6210\u672c\u3002\u5728\u9019\u9805\u8abf\u67e5\u4e2d\uff0c\u6211\u5011\u5c0d\u73fe\u6709\u7684 LLM \u5728\u5716\u5f62\u8cc7\u6599\u4e0a\u7684\u7814\u7a76\u9032\u884c\u4e86\u5168\u9762\u7684\u8abf\u67e5\uff0c\u7e3d\u7d50\u4e86\u7531\u5148\u9032 LLM \u6a21\u578b\u89e3\u6c7a\u7684\u76f8\u95dc\u5716\u5f62\u5206\u6790\u4efb\u52d9\uff0c\u4e26\u6307\u51fa\u4e86\u73fe\u6709\u7684\u5269\u9918\u6311\u6230\u548c\u672a\u4f86\u65b9\u5411\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u6211\u5011\u7814\u7a76\u4e86\u57fa\u65bc LLM \u7684\u751f\u6210\u5716\u5f62\u5206\u6790 (LLM-GGA) \u7684\u95dc\u9375\u554f\u984c\uff0c\u5206\u70ba\u4e09\u985e\uff1a\u57fa\u65bc LLM \u7684\u5716\u5f62\u67e5\u8a62\u8655\u7406 (LLM-GQP)\u3001\u57fa\u65bc LLM \u7684\u5716\u5f62\u63a8\u7406\u548c\u5b78\u7fd2 (LLM-GIL) \u4ee5\u53ca\u57fa\u65bc\u5716\u5f62 LLM \u7684\u61c9\u7528\u7a0b\u5f0f\u3002LLM-GQP \u5c08\u6ce8\u65bc\u5716\u5f62\u5206\u6790\u6280\u8853\u548c LLM \u63d0\u793a\u7684\u6574\u5408\uff0c\u5305\u62ec\u5716\u5f62\u7406\u89e3\u548c\u57fa\u65bc\u77e5\u8b58\u5716\u8b5c (KG) \u7684\u64f4\u589e\u6aa2\u7d22\uff0c\u800c LLM-GIL \u5c08\u6ce8\u65bc\u5728\u5716\u5f62\u4e0a\u5b78\u7fd2\u548c\u63a8\u7406\uff0c\u5305\u62ec\u5716\u5f62\u5b78\u7fd2\u3001\u5716\u5f62\u5f62\u6210\u63a8\u7406\u548c\u5716\u5f62\u8868\u793a\u3002\u6211\u5011\u7e3d\u7d50\u4e86\u6574\u5408\u5230 LLM \u4e2d\u4ee5\u8655\u7406\u4e0d\u540c\u5716\u5f62\u4e0b\u6e38\u4efb\u52d9\u7684\u6709\u7528\u63d0\u793a\u3002\u6b64\u5916\uff0c\u6211\u5011\u7e3d\u7d50\u4e86 LLM \u6a21\u578b\u8a55\u4f30\u3001\u57fa\u6e96\u8cc7\u6599\u96c6/\u4efb\u52d9\u4ee5\u53ca LLM \u6a21\u578b\u7684\u6df1\u5165\u512a\u7f3a\u9ede\u5206\u6790\u3002\u6211\u5011\u9084\u63a2\u8a0e\u4e86 LLM \u548c\u5716\u5f62\u5206\u6790\u9019\u500b\u4ee4\u4eba\u8208\u596e\u7684\u8de8\u5b78\u79d1\u7814\u7a76\u9818\u57df\u4e2d\u7684\u958b\u653e\u554f\u984c\u548c\u672a\u4f86\u65b9\u5411\u3002", "author": "Wenbo Shang et.al.", "authors": "Wenbo Shang, Xin Huang", "id": "2404.14809v1", "paper_url": "http://arxiv.org/abs/2404.14809v1", "repo": "null"}}