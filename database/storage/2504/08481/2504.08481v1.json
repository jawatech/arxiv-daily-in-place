{"2504.08481": {"publish_time": "2025-04-11", "title": "A Hybrid Fully Convolutional CNN-Transformer Model for Inherently Interpretable Medical Image Classification", "paper_summary": "In many medical imaging tasks, convolutional neural networks (CNNs)\nefficiently extract local features hierarchically. More recently, vision\ntransformers (ViTs) have gained popularity, using self-attention mechanisms to\ncapture global dependencies, but lacking the inherent spatial localization of\nconvolutions. Therefore, hybrid models combining CNNs and ViTs have been\ndeveloped to combine the strengths of both architectures. However, such hybrid\nCNN-ViT models are difficult to interpret, which hinders their application in\nmedical imaging. In this work, we introduce an interpretable-by-design hybrid\nfully convolutional CNN-Transformer architecture for medical image\nclassification. Unlike widely used post-hoc saliency methods for ViTs, our\napproach generates faithful and localized evidence maps that directly reflect\nthe model's decision process. We evaluated our method on two medical image\nclassification tasks using color fundus images. Our model not only achieves\nstate-of-the-art predictive performance compared to both black-box and\ninterpretable models but also provides class-specific sparse evidence maps in a\nsingle forward pass. The code is available at:\nhttps://anonymous.4open.science/r/Expl-CNN-Transformer/.", "paper_summary_zh": "\u5728\u8a31\u591a\u91ab\u5b78\u5f71\u50cf\u4efb\u52d9\u4e2d\uff0c\u5377\u7a4d\u795e\u7d93\u7db2\u7d61 (CNN)\u53ef\u4ee5\u6709\u6548\u5730\u5206\u5c64\u63d0\u53d6\u5c40\u90e8\u7279\u5fb5\u3002\u8fd1\u5e74\u4f86\uff0c\u8996\u89baTransformer (ViT) \u8b8a\u5f97\u8d8a\u4f86\u8d8a\u6d41\u884c\uff0c\u5b83\u4f7f\u7528\u81ea\u6ce8\u610f\u529b\u6a5f\u5236\u4f86\u6355\u6349\u5168\u5c40\u4f9d\u8cf4\u95dc\u4fc2\uff0c\u4f46\u7f3a\u4e4f\u5377\u7a4d\u56fa\u6709\u7684\u7a7a\u9593\u5b9a\u4f4d\u80fd\u529b\u3002\u56e0\u6b64\uff0c\u4eba\u5011\u958b\u767c\u4e86\u7d50\u5408 CNN \u548c ViT \u7684\u6df7\u5408\u6a21\u578b\uff0c\u4ee5\u7d50\u5408\u5169\u7a2e\u67b6\u69cb\u7684\u512a\u52e2\u3002\u7136\u800c\uff0c\u9019\u7a2e\u6df7\u5408CNN-ViT \u6a21\u578b\u96e3\u4ee5\u89e3\u91cb\uff0c\u9019\u963b\u7919\u4e86\u5b83\u5011\u5728\u91ab\u5b78\u5f71\u50cf\u4e2d\u7684\u61c9\u7528\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u4ecb\u7d39\u4e86\u4e00\u7a2e\u7528\u65bc\u91ab\u5b78\u5f71\u50cf\u5206\u985e\u7684\u53ef\u89e3\u91cb\u7684\u6df7\u5408\u5168\u5377\u7a4d CNN-Transformer \u67b6\u69cb\u3002\u8207 ViT \u5ee3\u6cdb\u4f7f\u7528\u7684\u5f8c\u8655\u7406\u986f\u8457\u6027\u65b9\u6cd5\u4e0d\u540c\uff0c\u6211\u5011\u7684\u65b9\u6cd5\u751f\u6210\u5fe0\u5be6\u4e14\u5c40\u90e8\u5316\u7684\u8b49\u64da\u5716\uff0c\u76f4\u63a5\u53cd\u6620\u6a21\u578b\u7684\u6c7a\u7b56\u904e\u7a0b\u3002\u6211\u5011\u5728\u5169\u500b\u91ab\u5b78\u5f71\u50cf\u5206\u985e\u4efb\u52d9\u4e2d\u4f7f\u7528\u5f69\u8272\u773c\u5e95\u5716\u50cf\u8a55\u4f30\u4e86\u6211\u5011\u7684\u65b9\u6cd5\u3002\u8207\u9ed1\u76d2\u6a21\u578b\u548c\u53ef\u89e3\u91cb\u6a21\u578b\u76f8\u6bd4\uff0c\u6211\u5011\u7684\u6a21\u578b\u4e0d\u50c5\u9054\u5230\u4e86\u6700\u5148\u9032\u7684\u9810\u6e2c\u6027\u80fd\uff0c\u800c\u4e14\u9084\u5728\u55ae\u6b21\u524d\u5411\u50b3\u905e\u4e2d\u63d0\u4f9b\u4e86\u7279\u5b9a\u985e\u5225\u7684\u7a00\u758f\u8b49\u64da\u5716\u3002\u4ee3\u78bc\u53ef\u5728\u4ee5\u4e0b\u7db2\u5740\u7372\u5f97\uff1ahttps://anonymous.4open.science/r/Expl-CNN-Transformer/\u3002\n", "author": "Kerol Djoumessi et.al.", "authors": "Kerol Djoumessi, Samuel Ofosu Mensah, Philipp Berens", "id": "2504.08481v1", "paper_url": "http://arxiv.org/abs/2504.08481v1", "repo": "null"}}