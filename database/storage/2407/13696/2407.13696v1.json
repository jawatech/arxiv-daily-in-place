{"2407.13696": {"publish_time": "2024-07-18", "title": "Benchmark Agreement Testing Done Right: A Guide for LLM Benchmark Evaluation", "paper_summary": "Recent advancements in Language Models (LMs) have catalyzed the creation of\nmultiple benchmarks, designed to assess these models' general capabilities. A\ncrucial task, however, is assessing the validity of the benchmarks themselves.\nThis is most commonly done via Benchmark Agreement Testing (BAT), where new\nbenchmarks are validated against established ones using some agreement metric\n(e.g., rank correlation). Despite the crucial role of BAT for benchmark\nbuilders and consumers, there are no standardized procedures for such agreement\ntesting. This deficiency can lead to invalid conclusions, fostering mistrust in\nbenchmarks and upending the ability to properly choose the appropriate\nbenchmark to use. By analyzing over 40 prominent benchmarks, we demonstrate how\nsome overlooked methodological choices can significantly influence BAT results,\npotentially undermining the validity of conclusions. To address these\ninconsistencies, we propose a set of best practices for BAT and demonstrate how\nutilizing these methodologies greatly improves BAT robustness and validity. To\nfoster adoption and facilitate future research,, we introduce BenchBench, a\npython package for BAT, and release the BenchBench-leaderboard, a\nmeta-benchmark designed to evaluate benchmarks using their peers. Our findings\nunderscore the necessity for standardized BAT, ensuring the robustness and\nvalidity of benchmark evaluations in the evolving landscape of language model\nresearch.\n  BenchBench Package: https://github.com/IBM/BenchBench\n  Leaderboard: https://huggingface.co/spaces/per/BenchBench", "paper_summary_zh": "<paragraph>\u8a9e\u8a00\u6a21\u578b (LM) \u7684\u6700\u65b0\u9032\u5c55\u50ac\u5316\u4e86\u591a\u500b\u57fa\u6e96\u7684\u5efa\u7acb\uff0c\u9019\u4e9b\u57fa\u6e96\u65e8\u5728\u8a55\u4f30\u9019\u4e9b\u6a21\u578b\u7684\u4e00\u822c\u80fd\u529b\u3002\u7136\u800c\uff0c\u4e00\u9805\u81f3\u95dc\u91cd\u8981\u7684\u4efb\u52d9\u662f\u8a55\u4f30\u57fa\u6e96\u672c\u8eab\u7684\u6709\u6548\u6027\u3002\u9019\u901a\u5e38\u901a\u904e\u57fa\u6e96\u5354\u8b70\u6e2c\u8a66 (BAT) \u4f86\u5b8c\u6210\uff0c\u5176\u4e2d\u4f7f\u7528\u4e00\u4e9b\u5354\u8b70\u6307\u6a19\uff08\u4f8b\u5982\uff0c\u7b49\u7d1a\u76f8\u95dc\u6027\uff09\u6839\u64da\u5df2\u5efa\u7acb\u7684\u57fa\u6e96\u9a57\u8b49\u65b0\u7684\u57fa\u6e96\u3002\u5118\u7ba1 BAT \u5c0d\u57fa\u6e96\u69cb\u5efa\u8005\u548c\u6d88\u8cbb\u8005\u626e\u6f14\u8457\u81f3\u95dc\u91cd\u8981\u7684\u89d2\u8272\uff0c\u4f46\u5c0d\u65bc\u6b64\u985e\u5354\u8b70\u6e2c\u8a66\u4e26\u6c92\u6709\u6a19\u6e96\u5316\u7684\u7a0b\u5e8f\u3002\u9019\u7a2e\u7f3a\u9677\u53ef\u80fd\u6703\u5c0e\u81f4\u7121\u6548\u7684\u7d50\u8ad6\uff0c\u9020\u6210\u5c0d\u57fa\u6e96\u7684\u4e0d\u4fe1\u4efb\uff0c\u4e26\u7834\u58de\u9069\u7576\u5730\u9078\u64c7\u9069\u7576\u57fa\u6e96\u4f7f\u7528\u7684\u80fd\u529b\u3002\u901a\u904e\u5206\u6790\u8d85\u904e 40 \u500b\u91cd\u8981\u7684\u57fa\u6e96\uff0c\u6211\u5011\u5c55\u793a\u4e86\u4e00\u4e9b\u88ab\u5ffd\u8996\u7684\u65b9\u6cd5\u8ad6\u9078\u64c7\u5982\u4f55\u986f\u8457\u5f71\u97ff BAT \u7d50\u679c\uff0c\u4e26\u53ef\u80fd\u7834\u58de\u7d50\u8ad6\u7684\u6709\u6548\u6027\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u4e9b\u4e0d\u4e00\u81f4\u4e4b\u8655\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u5957 BAT \u7684\u6700\u4f73\u5be6\u52d9\u7bc4\u4f8b\uff0c\u4e26\u5c55\u793a\u4e86\u5229\u7528\u9019\u4e9b\u65b9\u6cd5\u8ad6\u5982\u4f55\u5927\u5e45\u6539\u5584 BAT \u7684\u7a69\u5065\u6027\u548c\u6709\u6548\u6027\u3002\u70ba\u4e86\u4fc3\u9032\u63a1\u7528\u548c\u4fc3\u9032\u672a\u4f86\u7684\u7814\u7a76\uff0c\u6211\u5011\u5f15\u5165\u4e86 BenchBench\uff0c\u4e00\u500b\u7528\u65bc BAT \u7684 python \u5957\u4ef6\uff0c\u4e26\u767c\u5e03\u4e86 BenchBench-leaderboard\uff0c\u4e00\u500b\u5143\u57fa\u6e96\uff0c\u65e8\u5728\u4f7f\u7528\u540c\u5115\u8a55\u4f30\u57fa\u6e96\u3002\u6211\u5011\u7684\u767c\u73fe\u5f37\u8abf\u4e86\u6a19\u6e96\u5316 BAT \u7684\u5fc5\u8981\u6027\uff0c\u78ba\u4fdd\u4e86\u57fa\u6e96\u8a55\u4f30\u5728\u8a9e\u8a00\u6a21\u578b\u7814\u7a76\u4e0d\u65b7\u8b8a\u5316\u7684\u74b0\u5883\u4e2d\u7684\u7a69\u5065\u6027\u548c\u6709\u6548\u6027\u3002\nBenchBench \u5957\u4ef6\uff1ahttps://github.com/IBM/BenchBench\n\u6392\u884c\u699c\uff1ahttps://huggingface.co/spaces/per/BenchBench</paragraph>", "author": "Yotam Perlitz et.al.", "authors": "Yotam Perlitz, Ariel Gera, Ofir Arviv, Asaf Yehudai, Elron Bandel, Eyal Shnarch, Michal Shmueli-Scheuer, Leshem Choshen", "id": "2407.13696v1", "paper_url": "http://arxiv.org/abs/2407.13696v1", "repo": "https://github.com/ibm/benchbench"}}