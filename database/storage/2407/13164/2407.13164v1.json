{"2407.13164": {"publish_time": "2024-07-18", "title": "Translate-and-Revise: Boosting Large Language Models for Constrained Translation", "paper_summary": "Imposing constraints on machine translation systems presents a challenging\nissue because these systems are not trained to make use of constraints in\ngenerating adequate, fluent translations. In this paper, we leverage the\ncapabilities of large language models (LLMs) for constrained translation, given\nthat LLMs can easily adapt to this task by taking translation instructions and\nconstraints as prompts. However, LLMs cannot always guarantee the adequacy of\ntranslation, and, in some cases, ignore the given constraints. This is in part\nbecause LLMs might be overly confident in their predictions, overriding the\ninfluence of the constraints. To overcome this overiding behaviour, we propose\nto add a revision process that encourages LLMs to correct the outputs by\nprompting them about the constraints that have not yet been met. We evaluate\nour approach on four constrained translation tasks, encompassing both lexical\nand structural constraints in multiple constraint domains. Experiments show\n15\\% improvement in constraint-based translation accuracy over standard LLMs\nand the approach also significantly outperforms neural machine translation\n(NMT) state-of-the-art methods.", "paper_summary_zh": "\u5c0d\u6a5f\u5668\u7ffb\u8b6f\u7cfb\u7d71\u65bd\u52a0\u9650\u5236\u662f\u4e00\u500b\u5177\u6709\u6311\u6230\u6027\u7684\u554f\u984c\uff0c\u56e0\u70ba\u9019\u4e9b\u7cfb\u7d71\u4e26\u672a\u7d93\u904e\u8a13\u7df4\uff0c\u7121\u6cd5\u5229\u7528\u9650\u5236\u4f86\u7522\u751f\u9069\u7576\u4e14\u6d41\u66a2\u7684\u7ffb\u8b6f\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u5229\u7528\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u80fd\u529b\u4f86\u9032\u884c\u53d7\u9650\u7ffb\u8b6f\uff0c\u56e0\u70ba LLM \u53ef\u4ee5\u900f\u904e\u5c07\u7ffb\u8b6f\u8aaa\u660e\u548c\u9650\u5236\u4f5c\u70ba\u63d0\u793a\uff0c\u8f15\u9b06\u9069\u61c9\u9019\u9805\u4efb\u52d9\u3002\u7136\u800c\uff0cLLM \u7121\u6cd5\u7e3d\u662f\u4fdd\u8b49\u7ffb\u8b6f\u7684\u5145\u5206\u6027\uff0c\u4e26\u4e14\u5728\u67d0\u4e9b\u60c5\u6cc1\u4e0b\u6703\u5ffd\u7565\u7d66\u5b9a\u7684\u9650\u5236\u3002\u9019\u90e8\u5206\u662f\u56e0\u70ba LLM \u53ef\u80fd\u904e\u5ea6\u81ea\u4fe1\u65bc\u81ea\u5df1\u7684\u9810\u6e2c\uff0c\u800c\u5ffd\u8996\u4e86\u9650\u5236\u7684\u5f71\u97ff\u3002\u70ba\u4e86\u514b\u670d\u9019\u7a2e\u904e\u5ea6\u884c\u70ba\uff0c\u6211\u5011\u5efa\u8b70\u589e\u52a0\u4e00\u500b\u4fee\u8a02\u7a0b\u5e8f\uff0c\u9f13\u52f5 LLM \u900f\u904e\u63d0\u793a\u5c1a\u672a\u6eff\u8db3\u7684\u9650\u5236\u4f86\u4fee\u6b63\u8f38\u51fa\u3002\u6211\u5011\u5728\u56db\u9805\u53d7\u9650\u7ffb\u8b6f\u4efb\u52d9\u4e2d\u8a55\u4f30\u6211\u5011\u7684\u505a\u6cd5\uff0c\u6db5\u84cb\u591a\u500b\u9650\u5236\u9818\u57df\u4e2d\u7684\u8a5e\u5f59\u548c\u7d50\u69cb\u9650\u5236\u3002\u5be6\u9a57\u986f\u793a\uff0c\u8207\u6a19\u6e96 LLM \u76f8\u6bd4\uff0c\u57fa\u65bc\u7d04\u675f\u7684\u7ffb\u8b6f\u6e96\u78ba\u5ea6\u63d0\u9ad8\u4e86 15%\uff0c\u4e26\u4e14\u8a72\u65b9\u6cd5\u4e5f\u986f\u8457\u512a\u65bc\u795e\u7d93\u6a5f\u5668\u7ffb\u8b6f (NMT) \u7684\u6700\u65b0\u65b9\u6cd5\u3002", "author": "Pengcheng Huang et.al.", "authors": "Pengcheng Huang, Yongyu Mu, Yuzhang Wu, Bei Li, Chunyang Xiao, Tong Xiao, Jingbo Zhu", "id": "2407.13164v1", "paper_url": "http://arxiv.org/abs/2407.13164v1", "repo": "null"}}