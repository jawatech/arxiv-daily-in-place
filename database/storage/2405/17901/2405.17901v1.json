{"2405.17901": {"publish_time": "2024-05-28", "title": "Near-Infrared and Low-Rank Adaptation of Vision Transformers in Remote Sensing", "paper_summary": "Plant health can be monitored dynamically using multispectral sensors that\nmeasure Near-Infrared reflectance (NIR). Despite this potential, obtaining and\nannotating high-resolution NIR images poses a significant challenge for\ntraining deep neural networks. Typically, large networks pre-trained on the RGB\ndomain are utilized to fine-tune infrared images. This practice introduces a\ndomain shift issue because of the differing visual traits between RGB and NIR\nimages.As an alternative to fine-tuning, a method called low-rank adaptation\n(LoRA) enables more efficient training by optimizing rank-decomposition\nmatrices while keeping the original network weights frozen. However, existing\nparameter-efficient adaptation strategies for remote sensing images focus on\nRGB images and overlook domain shift issues in the NIR domain. Therefore, this\nstudy investigates the potential benefits of using vision transformer (ViT)\nbackbones pre-trained in the RGB domain, with low-rank adaptation for\ndownstream tasks in the NIR domain. Extensive experiments demonstrate that\nemploying LoRA with pre-trained ViT backbones yields the best performance for\ndownstream tasks applied to NIR images.", "paper_summary_zh": "\u5229\u7528\u6d4b\u91cf\u8fd1\u7ea2\u5916\u53cd\u5c04 (NIR) \u7684\u591a\u5149\u8c31\u4f20\u611f\u5668\uff0c\u53ef\u4ee5\u52a8\u6001\u76d1\u6d4b\u690d\u7269\u5065\u5eb7\u3002\u5c3d\u7ba1\u6709\u6b64\u6f5c\u529b\uff0c\u4f46\u83b7\u53d6\u548c\u6ce8\u91ca\u9ad8\u5206\u8fa8\u7387 NIR \u56fe\u50cf\u5bf9\u8bad\u7ec3\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u6784\u6210\u4e86\u91cd\u5927\u6311\u6218\u3002\u901a\u5e38\uff0c\u5229\u7528\u9884\u5148\u5728 RGB \u57df\u4e0a\u8bad\u7ec3\u7684\u5927\u578b\u7f51\u7edc\u6765\u5fae\u8c03\u7ea2\u5916\u56fe\u50cf\u3002\u7531\u4e8e RGB \u548c NIR \u56fe\u50cf\u4e4b\u95f4\u7684\u89c6\u89c9\u7279\u5f81\u4e0d\u540c\uff0c\u8fd9\u79cd\u505a\u6cd5\u5f15\u5165\u4e86\u57df\u504f\u79fb\u95ee\u9898\u3002\u4f5c\u4e3a\u5fae\u8c03\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u4e00\u79cd\u79f0\u4e3a\u4f4e\u79e9\u9002\u5e94 (LoRA) \u7684\u65b9\u6cd5\u901a\u8fc7\u4f18\u5316\u79e9\u5206\u89e3\u77e9\u9635\u540c\u65f6\u4fdd\u6301\u539f\u59cb\u7f51\u7edc\u6743\u91cd\u51bb\u7ed3\uff0c\u4ece\u800c\u5b9e\u73b0\u66f4\u6709\u6548\u7684\u8bad\u7ec3\u3002\u7136\u800c\uff0c\u73b0\u6709\u7684\u7528\u4e8e\u9065\u611f\u56fe\u50cf\u7684\u53c2\u6570\u9ad8\u6548\u9002\u5e94\u7b56\u7565\u4e13\u6ce8\u4e8e RGB \u56fe\u50cf\uff0c\u800c\u5ffd\u7565\u4e86 NIR \u57df\u4e2d\u7684\u57df\u504f\u79fb\u95ee\u9898\u3002\u56e0\u6b64\uff0c\u672c\u7814\u7a76\u8c03\u67e5\u4e86\u5728 RGB \u57df\u4e2d\u9884\u5148\u8bad\u7ec3\u7684\u89c6\u89c9\u8f6c\u6362\u5668 (ViT) \u4e3b\u5e72\u4f7f\u7528\u4f4e\u79e9\u9002\u5e94\u5728 NIR \u57df\u7684\u4e0b\u6e38\u4efb\u52a1\u4e2d\u4f7f\u7528\u89c6\u89c9\u8f6c\u6362\u5668 (ViT) \u4e3b\u5e72\u7684\u6f5c\u5728\u4f18\u52bf\u3002\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0c\u5c06 LoRA \u4e0e\u9884\u5148\u8bad\u7ec3\u7684 ViT \u4e3b\u5e72\u7ed3\u5408\u4f7f\u7528\uff0c\u53ef\u4e3a\u5e94\u7528\u4e8e NIR \u56fe\u50cf\u7684\u4e0b\u6e38\u4efb\u52a1\u5e26\u6765\u6700\u4f73\u6027\u80fd\u3002", "author": "Irem Ulku et.al.", "authors": "Irem Ulku, O. Ozgur Tanriover, Erdem Akag\u00fcnd\u00fcz", "id": "2405.17901v1", "paper_url": "http://arxiv.org/abs/2405.17901v1", "repo": "null"}}