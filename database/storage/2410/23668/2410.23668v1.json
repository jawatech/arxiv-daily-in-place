{"2410.23668": {"publish_time": "2024-10-31", "title": "Kernel Looping: Eliminating Synchronization Boundaries for Peak Inference Performance", "paper_summary": "Token generation speed is critical to power the next wave of AI inference\napplications. GPUs significantly underperform during token generation due to\nsynchronization overheads at kernel boundaries, utilizing only 21% of their\npeak memory bandwidth. While recent dataflow architectures mitigate these\noverheads by enabling aggressive fusion of decoder layers into a single kernel,\nthey too leave performance on the table due to synchronization penalties at\nlayer boundaries.\n  This paper presents kernel looping, a specialized global optimization\ntechnique which exploits an optimization opportunity brought by combining the\nunique layer-level fusion possible in modern dataflow architectures with the\nrepeated layer structure found in language models. Kernel looping eliminates\nsynchronization costs between consecutive calls to the same kernel by\ntransforming these calls into a single call to a modified kernel containing a\npipelined outer loop. We evaluate kernel looping on the SambaNova SN40L\nReconfigurable Dataflow Unit (RDU), a commercial dataflow accelerator for AI.\nExperiments demonstrate that kernel looping speeds up the decode phase of a\nwide array of powerful open-source models by up to 2.2$\\times$ on SN40L. Kernel\nlooping allows scaling of decode performance over multiple SN40L sockets,\nachieving speedups of up to 2.5$\\times$. Finally, kernel looping enables SN40L\nto achieve over 90% of peak performance on 8 and 16 sockets and achieve a\nspeedup of up to 3.7$\\times$ over DGX H100. Kernel looping, as well as the\nmodels evaluated in this paper, are deployed in production in a commercial AI\ninference cloud.", "paper_summary_zh": "\u6b0a\u6756\u7522\u751f\u901f\u5ea6\u5c0d\u65bc\u63a8\u52d5\u4e0b\u6ce2 AI \u63a8\u8ad6\u61c9\u7528\u81f3\u95dc\u91cd\u8981\u3002GPU \u5728\u6b0a\u6756\u7522\u751f\u671f\u9593\u6703\u56e0\u70ba\u6838\u5fc3\u908a\u754c\u7684\u540c\u6b65\u958b\u92b7\u800c\u5927\u5e45\u5ea6\u8868\u73fe\u4e0d\u4f73\uff0c\u50c5\u4f7f\u7528\u5176\u5cf0\u503c\u8a18\u61b6\u9ad4\u983b\u5bec\u7684 21%\u3002\u5118\u7ba1\u6700\u8fd1\u7684\u8cc7\u6599\u6d41\u7a0b\u67b6\u69cb\u900f\u904e\u8b93\u89e3\u78bc\u5668\u5c64\u7a4d\u6975\u878d\u5408\u6210\u55ae\u4e00\u6838\u5fc3\u4f86\u6e1b\u8f15\u9019\u4e9b\u958b\u92b7\uff0c\u4f46\u5b83\u5011\u4e5f\u6703\u56e0\u70ba\u5c64\u908a\u754c\u7684\u540c\u6b65\u61f2\u7f70\u800c\u8b93\u6548\u80fd\u505c\u6eef\u4e0d\u524d\u3002\n\u672c\u6587\u63d0\u51fa\u6838\u5fc3\u8ff4\u5708\uff0c\u9019\u662f\u4e00\u7a2e\u5c08\u9580\u7684\u5168\u7403\u6700\u4f73\u5316\u6280\u8853\uff0c\u5b83\u5229\u7528\u73fe\u4ee3\u8cc7\u6599\u6d41\u7a0b\u67b6\u69cb\u4e2d\u53ef\u80fd\u51fa\u73fe\u7684\u7368\u7279\u5c64\u7d1a\u878d\u5408\u4ee5\u53ca\u8a9e\u8a00\u6a21\u578b\u4e2d\u767c\u73fe\u7684\u91cd\u8907\u5c64\u7d1a\u7d50\u69cb\uff0c\u4f86\u5229\u7528\u6700\u4f73\u5316\u6a5f\u6703\u3002\u6838\u5fc3\u8ff4\u5708\u900f\u904e\u5c07\u9019\u4e9b\u547c\u53eb\u8f49\u63db\u6210\u5c0d\u5305\u542b\u7ba1\u7dda\u5316\u5916\u5c64\u8ff4\u5708\u7684\u4fee\u6539\u6838\u5fc3\u4e4b\u55ae\u4e00\u547c\u53eb\uff0c\u6d88\u9664\u4e86\u5c0d\u540c\u4e00\u500b\u6838\u5fc3\u9023\u7e8c\u547c\u53eb\u4e4b\u9593\u7684\u540c\u6b65\u6210\u672c\u3002\u6211\u5011\u5728 SambaNova SN40L \u53ef\u91cd\u65b0\u914d\u7f6e\u8cc7\u6599\u6d41\u7a0b\u55ae\u5143 (RDU) \u4e0a\u8a55\u4f30\u6838\u5fc3\u8ff4\u5708\uff0c\u9019\u662f\u4e00\u7a2e\u7528\u65bc AI \u7684\u5546\u7528\u8cc7\u6599\u6d41\u7a0b\u52a0\u901f\u5668\u3002\u5be6\u9a57\u8b49\u660e\uff0c\u6838\u5fc3\u8ff4\u5708\u5728 SN40L \u4e0a\u5c07\u5404\u7a2e\u5f37\u5927\u958b\u653e\u539f\u59cb\u78bc\u6a21\u578b\u7684\u89e3\u78bc\u968e\u6bb5\u52a0\u901f\u4e86 2.2 \u500d\u3002\u6838\u5fc3\u8ff4\u5708\u5141\u8a31\u5728\u591a\u500b SN40L \u63d2\u69fd\u4e0a\u64f4\u5c55\u89e3\u78bc\u6548\u80fd\uff0c\u52a0\u901f\u901f\u5ea6\u6700\u9ad8\u53ef\u9054 2.5 \u500d\u3002\u6700\u5f8c\uff0c\u6838\u5fc3\u8ff4\u5708\u8b93 SN40L \u5728 8 \u500b\u548c 16 \u500b\u63d2\u69fd\u4e0a\u9054\u5230\u8d85\u904e 90% \u7684\u5cf0\u503c\u6548\u80fd\uff0c\u4e26\u5728 DGX H100 \u4e0a\u52a0\u901f\u6700\u9ad8\u9054 3.7 \u500d\u3002\u6838\u5fc3\u8ff4\u5708\u4ee5\u53ca\u672c\u6587\u8a55\u4f30\u7684\u6a21\u578b\u90fd\u5df2\u90e8\u7f72\u5728\u5546\u7528 AI \u63a8\u8ad6\u96f2\u7aef\u7684\u751f\u7522\u74b0\u5883\u4e2d\u3002", "author": "David Koeplinger et.al.", "authors": "David Koeplinger, Darshan Gandhi, Pushkar Nandkar, Nathan Sheeley, Matheen Musaddiq, Leon Zhang, Reid Goodbar, Matthew Shaffer, Han Wang, Angela Wang, Mingran Wang, Raghu Prabhakar", "id": "2410.23668v1", "paper_url": "http://arxiv.org/abs/2410.23668v1", "repo": "null"}}