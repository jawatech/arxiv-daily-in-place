{"2406.02524": {"publish_time": "2024-06-04", "title": "CheckEmbed: Effective Verification of LLM Solutions to Open-Ended Tasks", "paper_summary": "Large Language Models (LLMs) are revolutionizing various domains, yet\nverifying their answers remains a significant challenge, especially for\nintricate open-ended tasks such as consolidation, summarization, and extraction\nof knowledge. In this work, we propose CheckEmbed: an accurate, scalable, and\nsimple LLM verification approach. CheckEmbed is driven by a straightforward yet\npowerful idea: in order to compare LLM solutions to one another or to the\nground-truth, compare their corresponding answer-level embeddings obtained with\na model such as GPT Text Embedding Large. This reduces a complex textual answer\nto a single embedding, facilitating straightforward, fast, and meaningful\nverification. We develop a comprehensive verification pipeline implementing the\nCheckEmbed methodology. The CheckEmbed pipeline also comes with metrics for\nassessing the truthfulness of the LLM answers, such as embedding heatmaps and\ntheir summaries. We show how to use these metrics for deploying practical\nengines that decide whether an LLM answer is satisfactory or not. We apply the\npipeline to real-world document analysis tasks, including term extraction and\ndocument summarization, showcasing significant improvements in accuracy,\ncost-effectiveness, and runtime performance compared to existing token-,\nsentence-, and fact-level schemes such as BERTScore or SelfCheckGPT.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u6b63\u5728\u9769\u65b0\u5404\u500b\u9818\u57df\uff0c\u7136\u800c\u9a57\u8b49\u5176\u7b54\u6848\u4ecd\u7136\u662f\u4e00\u9805\u91cd\u5927\u7684\u6311\u6230\uff0c\u7279\u5225\u662f\u5c0d\u65bc\u8907\u96dc\u7684\u958b\u653e\u5f0f\u4efb\u52d9\uff0c\u4f8b\u5982\u6574\u5408\u3001\u6458\u8981\u548c\u77e5\u8b58\u8403\u53d6\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u63d0\u51fa CheckEmbed\uff1a\u4e00\u7a2e\u6e96\u78ba\u3001\u53ef\u64f4\u5145\u4e14\u7c21\u55ae\u7684 LLM \u9a57\u8b49\u65b9\u6cd5\u3002CheckEmbed \u7531\u4e00\u500b\u7c21\u55ae\u4f46\u5f37\u5927\u7684\u6982\u5ff5\u9a45\u52d5\uff1a\u70ba\u4e86\u5c07 LLM \u7b54\u6848\u5f7c\u6b64\u6bd4\u8f03\u6216\u8207\u771f\u5be6\u60c5\u6cc1\u6bd4\u8f03\uff0c\u8acb\u5c07\u5b83\u5011\u4f7f\u7528 GPT \u6587\u5b57\u5d4c\u5165\u5927\u578b\u7b49\u6a21\u578b\u7372\u5f97\u7684\u5c0d\u61c9\u7b54\u6848\u5c64\u7d1a\u5d4c\u5165\u6bd4\u8f03\u3002\u9019\u5c07\u8907\u96dc\u7684\u6587\u5b57\u7b54\u6848\u7c21\u5316\u70ba\u55ae\u4e00\u5d4c\u5165\uff0c\u4fc3\u9032\u76f4\u63a5\u3001\u5feb\u901f\u4e14\u6709\u610f\u7fa9\u7684\u9a57\u8b49\u3002\u6211\u5011\u958b\u767c\u4e86\u4e00\u500b\u5168\u9762\u7684\u9a57\u8b49\u7ba1\u9053\uff0c\u5be6\u4f5c CheckEmbed \u65b9\u6cd5\u8ad6\u3002CheckEmbed \u7ba1\u9053\u9084\u9644\u5e36\u7528\u65bc\u8a55\u4f30 LLM \u7b54\u6848\u771f\u5be6\u6027\u7684\u6307\u6a19\uff0c\u4f8b\u5982\u5d4c\u5165\u71b1\u5716\u53ca\u5176\u6458\u8981\u3002\u6211\u5011\u5c55\u793a\u5982\u4f55\u4f7f\u7528\u9019\u4e9b\u6307\u6a19\u4f86\u90e8\u7f72\u5be6\u969b\u5f15\u64ce\uff0c\u4ee5\u6c7a\u5b9a LLM \u7b54\u6848\u662f\u5426\u4ee4\u4eba\u6eff\u610f\u3002\u6211\u5011\u5c07\u7ba1\u9053\u61c9\u7528\u65bc\u771f\u5be6\u4e16\u754c\u7684\u6587\u4ef6\u5206\u6790\u4efb\u52d9\uff0c\u5305\u62ec\u8853\u8a9e\u8403\u53d6\u548c\u6587\u4ef6\u6458\u8981\uff0c\u8207\u73fe\u6709\u7684\u57fa\u65bc\u8a5e\u5143\u3001\u53e5\u5b50\u548c\u4e8b\u5be6\u7684\u65b9\u6848\uff08\u4f8b\u5982 BERTScore \u6216 SelfCheckGPT\uff09\u76f8\u6bd4\uff0c\u5c55\u793a\u4e86\u5728\u6e96\u78ba\u6027\u3001\u6210\u672c\u6548\u76ca\u548c\u57f7\u884c\u6642\u9593\u6548\u80fd\u65b9\u9762\u7684\u986f\u8457\u6539\u9032\u3002", "author": "Maciej Besta et.al.", "authors": "Maciej Besta, Lorenzo Paleari, Ales Kubicek, Piotr Nyczyk, Robert Gerstenberger, Patrick Iff, Tomasz Lehmann, Hubert Niewiadomski, Torsten Hoefler", "id": "2406.02524v1", "paper_url": "http://arxiv.org/abs/2406.02524v1", "repo": "null"}}