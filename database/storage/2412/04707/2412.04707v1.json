{"2412.04707": {"publish_time": "2024-12-06", "title": "Parametric-ControlNet: Multimodal Control in Foundation Models for Precise Engineering Design Synthesis", "paper_summary": "This paper introduces a generative model designed for multimodal control over\ntext-to-image foundation generative AI models such as Stable Diffusion,\nspecifically tailored for engineering design synthesis. Our model proposes\nparametric, image, and text control modalities to enhance design precision and\ndiversity. Firstly, it handles both partial and complete parametric inputs\nusing a diffusion model that acts as a design autocomplete co-pilot, coupled\nwith a parametric encoder to process the information. Secondly, the model\nutilizes assembly graphs to systematically assemble input component images,\nwhich are then processed through a component encoder to capture essential\nvisual data. Thirdly, textual descriptions are integrated via CLIP encoding,\nensuring a comprehensive interpretation of design intent. These diverse inputs\nare synthesized through a multimodal fusion technique, creating a joint\nembedding that acts as the input to a module inspired by ControlNet. This\nintegration allows the model to apply robust multimodal control to foundation\nmodels, facilitating the generation of complex and precise engineering designs.\nThis approach broadens the capabilities of AI-driven design tools and\ndemonstrates significant advancements in precise control based on diverse data\nmodalities for enhanced design generation.", "paper_summary_zh": "\u672c\u6587\u4ecb\u7d39\u4e00\u500b\u751f\u6210\u6a21\u578b\uff0c\u65e8\u5728\u5c0d Stable Diffusion \u7b49\u591a\u6a21\u614b\u63a7\u5236\u6587\u672c\u5230\u5f71\u50cf\u57fa\u790e\u751f\u6210\u5f0f AI \u6a21\u578b\u9032\u884c\u63a7\u5236\uff0c\u7279\u5225\u91dd\u5c0d\u5de5\u7a0b\u8a2d\u8a08\u5408\u6210\u91cf\u8eab\u6253\u9020\u3002\u6211\u5011\u7684\u6a21\u578b\u63d0\u51fa\u53c3\u6578\u3001\u5f71\u50cf\u548c\u6587\u5b57\u63a7\u5236\u6a21\u5f0f\uff0c\u4ee5\u589e\u5f37\u8a2d\u8a08\u7cbe\u5ea6\u548c\u591a\u6a23\u6027\u3002\u9996\u5148\uff0c\u5b83\u4f7f\u7528\u4e00\u500b\u64f4\u6563\u6a21\u578b\u8655\u7406\u90e8\u5206\u548c\u5b8c\u6574\u7684\u53c3\u6578\u8f38\u5165\uff0c\u8a72\u6a21\u578b\u5145\u7576\u8a2d\u8a08\u81ea\u52d5\u5b8c\u6210\u526f\u99d5\u99db\uff0c\u4e26\u7d50\u5408\u4e00\u500b\u53c3\u6578\u7de8\u78bc\u5668\u4f86\u8655\u7406\u8cc7\u8a0a\u3002\u5176\u6b21\uff0c\u8a72\u6a21\u578b\u5229\u7528\u7d44\u88dd\u5716\u7cfb\u7d71\u6027\u5730\u7d44\u88dd\u8f38\u5165\u5143\u4ef6\u5f71\u50cf\uff0c\u7136\u5f8c\u900f\u904e\u5143\u4ef6\u7de8\u78bc\u5668\u8655\u7406\u9019\u4e9b\u5f71\u50cf\u4ee5\u64f7\u53d6\u5fc5\u8981\u7684\u8996\u89ba\u8cc7\u6599\u3002\u7b2c\u4e09\uff0c\u6587\u5b57\u63cf\u8ff0\u900f\u904e CLIP \u7de8\u78bc\u9032\u884c\u6574\u5408\uff0c\u78ba\u4fdd\u5c0d\u8a2d\u8a08\u610f\u5716\u9032\u884c\u5168\u9762\u8a6e\u91cb\u3002\u9019\u4e9b\u591a\u5143\u8f38\u5165\u900f\u904e\u591a\u6a21\u614b\u878d\u5408\u6280\u8853\u9032\u884c\u5408\u6210\uff0c\u5efa\u7acb\u4e00\u500b\u806f\u5408\u5d4c\u5165\uff0c\u4f5c\u70ba\u53d7 ControlNet \u555f\u767c\u6a21\u7d44\u7684\u8f38\u5165\u3002\u9019\u7a2e\u6574\u5408\u8b93\u6a21\u578b\u80fd\u5c0d\u57fa\u790e\u6a21\u578b\u5957\u7528\u5f37\u5927\u7684\u591a\u6a21\u614b\u63a7\u5236\uff0c\u4fc3\u9032\u751f\u6210\u8907\u96dc\u4e14\u7cbe\u78ba\u7684\u5de5\u7a0b\u8a2d\u8a08\u3002\u9019\u7a2e\u65b9\u6cd5\u64f4\u5c55\u4e86 AI \u9a45\u52d5\u8a2d\u8a08\u5de5\u5177\u7684\u80fd\u529b\uff0c\u4e26\u5c55\u793a\u4e86\u57fa\u65bc\u591a\u5143\u8cc7\u6599\u6a21\u5f0f\u7684\u7cbe\u78ba\u63a7\u5236\u5728\u589e\u5f37\u8a2d\u8a08\u751f\u6210\u65b9\u9762\u7684\u986f\u8457\u9032\u5c55\u3002", "author": "Rui Zhou et.al.", "authors": "Rui Zhou, Yanxia Zhang, Chenyang Yuan, Frank Permenter, Nikos Arechiga, Matt Klenk, Faez Ahmed", "id": "2412.04707v1", "paper_url": "http://arxiv.org/abs/2412.04707v1", "repo": "null"}}