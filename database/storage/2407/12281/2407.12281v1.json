{"2407.12281": {"publish_time": "2024-07-17", "title": "Turning Generative Models Degenerate: The Power of Data Poisoning Attacks", "paper_summary": "The increasing use of large language models (LLMs) trained by third parties\nraises significant security concerns. In particular, malicious actors can\nintroduce backdoors through poisoning attacks to generate undesirable outputs.\nWhile such attacks have been extensively studied in image domains and\nclassification tasks, they remain underexplored for natural language generation\n(NLG) tasks. To address this gap, we conduct an investigation of various\npoisoning techniques targeting the LLM's fine-tuning phase via prefix-tuning, a\nParameter Efficient Fine-Tuning (PEFT) method. We assess their effectiveness\nacross two generative tasks: text summarization and text completion; and we\nalso introduce new metrics to quantify the success and stealthiness of such NLG\npoisoning attacks. Through our experiments, we find that the prefix-tuning\nhyperparameters and trigger designs are the most crucial factors to influence\nattack success and stealthiness. Moreover, we demonstrate that existing popular\ndefenses are ineffective against our poisoning attacks. Our study presents the\nfirst systematic approach to understanding poisoning attacks targeting NLG\ntasks during fine-tuning via PEFT across a wide range of triggers and attack\nsettings. We hope our findings will aid the AI security community in developing\neffective defenses against such threats.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u4f7f\u7528\u589e\u52a0\uff0c\u7531\u7b2c\u4e09\u65b9\u57f9\u8a13\uff0c\u5f15\u8d77\u4e86\u91cd\u8981\u7684\u5b89\u5168\u554f\u984c\u3002\u7279\u5225\u662f\uff0c\u60e1\u610f\u884c\u70ba\u8005\u53ef\u4ee5\u900f\u904e\u6295\u6bd2\u653b\u64ca\u5c0e\u5165\u5f8c\u9580\uff0c\u4ee5\u7522\u751f\u4e0d\u826f\u7684\u8f38\u51fa\u3002\u96d6\u7136\u9019\u7a2e\u653b\u64ca\u5df2\u5728\u5f71\u50cf\u9818\u57df\u548c\u5206\u985e\u4efb\u52d9\u4e2d\u5ee3\u6cdb\u7814\u7a76\uff0c\u4f46\u5c0d\u65bc\u81ea\u7136\u8a9e\u8a00\u751f\u6210 (NLG) \u4efb\u52d9\u4ecd\u672a\u5145\u5206\u63a2\u8a0e\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u5dee\u8ddd\uff0c\u6211\u5011\u91dd\u5c0d\u900f\u904e\u524d\u7db4\u8abf\u6574\u4f86\u9396\u5b9a LLM \u5fae\u8abf\u968e\u6bb5\u7684\u5404\u7a2e\u6295\u6bd2\u6280\u8853\u9032\u884c\u8abf\u67e5\uff0c\u4e00\u7a2e\u53c3\u6578\u6709\u6548\u5fae\u8abf (PEFT) \u65b9\u6cd5\u3002\u6211\u5011\u8a55\u4f30\u5b83\u5011\u5728\u5169\u500b\u751f\u6210\u4efb\u52d9\u4e2d\u7684\u6709\u6548\u6027\uff1a\u6587\u5b57\u6458\u8981\u548c\u6587\u5b57\u5b8c\u6210\uff1b\u4e26\u4e14\u6211\u5011\u4e5f\u5f15\u9032\u65b0\u7684\u6307\u6a19\u4f86\u91cf\u5316\u9019\u7a2e NLG \u6295\u6bd2\u653b\u64ca\u7684\u6210\u529f\u548c\u96b1\u5bc6\u6027\u3002\u900f\u904e\u6211\u5011\u7684\u5be6\u9a57\uff0c\u6211\u5011\u767c\u73fe\u524d\u7db4\u8abf\u6574\u8d85\u53c3\u6578\u548c\u89f8\u767c\u5668\u8a2d\u8a08\u662f\u5f71\u97ff\u653b\u64ca\u6210\u529f\u548c\u96b1\u5bc6\u6027\u7684\u6700\u91cd\u8981\u56e0\u7d20\u3002\u6b64\u5916\uff0c\u6211\u5011\u8b49\u660e\u73fe\u6709\u7684\u6d41\u884c\u9632\u79a6\u63aa\u65bd\u5c0d\u6211\u5011\u7684\u6295\u6bd2\u653b\u64ca\u7121\u6548\u3002\u6211\u5011\u7684\u7814\u7a76\u63d0\u51fa\u4e86\u7b2c\u4e00\u500b\u7cfb\u7d71\u5316\u7684\u65b9\u6cd5\u4f86\u7406\u89e3\u5728\u900f\u904e PEFT \u5fae\u8abf\u671f\u9593\u9396\u5b9a NLG \u4efb\u52d9\u7684\u6295\u6bd2\u653b\u64ca\uff0c\u6db5\u84cb\u5ee3\u6cdb\u7684\u89f8\u767c\u5668\u548c\u653b\u64ca\u8a2d\u5b9a\u3002\u6211\u5011\u5e0c\u671b\u6211\u5011\u7684\u767c\u73fe\u5c07\u6709\u52a9\u65bc AI \u5b89\u5168\u793e\u7fa4\u958b\u767c\u5c0d\u6297\u6b64\u985e\u5a01\u8105\u7684\u6709\u6548\u9632\u79a6\u63aa\u65bd\u3002", "author": "Shuli Jiang et.al.", "authors": "Shuli Jiang, Swanand Ravindra Kadhe, Yi Zhou, Farhan Ahmed, Ling Cai, Nathalie Baracaldo", "id": "2407.12281v1", "paper_url": "http://arxiv.org/abs/2407.12281v1", "repo": "null"}}