{"2408.04303": {"publish_time": "2024-08-08", "title": "Trans-Tokenization and Cross-lingual Vocabulary Transfers: Language Adaptation of LLMs for Low-Resource NLP", "paper_summary": "The development of monolingual language models for low and mid-resource\nlanguages continues to be hindered by the difficulty in sourcing high-quality\ntraining data. In this study, we present a novel cross-lingual vocabulary\ntransfer strategy, trans-tokenization, designed to tackle this challenge and\nenable more efficient language adaptation. Our approach focuses on adapting a\nhigh-resource monolingual LLM to an unseen target language by initializing the\ntoken embeddings of the target language using a weighted average of\nsemantically similar token embeddings from the source language. For this, we\nleverage a translation resource covering both the source and target languages.\nWe validate our method with the Tweeties, a series of trans-tokenized LLMs, and\ndemonstrate their competitive performance on various downstream tasks across a\nsmall but diverse set of languages. Additionally, we introduce Hydra LLMs,\nmodels with multiple swappable language modeling heads and embedding tables,\nwhich further extend the capabilities of our trans-tokenization strategy. By\ndesigning a Hydra LLM based on the multilingual model TowerInstruct, we\ndeveloped a state-of-the-art machine translation model for Tatar, in a\nzero-shot manner, completely bypassing the need for high-quality parallel data.\nThis breakthrough is particularly significant for low-resource languages like\nTatar, where high-quality parallel data is hard to come by. By lowering the\ndata and time requirements for training high-quality models, our\ntrans-tokenization strategy allows for the development of LLMs for a wider\nrange of languages, especially those with limited resources. We hope that our\nwork will inspire further research and collaboration in the field of\ncross-lingual vocabulary transfer and contribute to the empowerment of\nlanguages on a global scale.", "paper_summary_zh": "<paragraph>\u4f4e\u8cc7\u6e90\u548c\u4e2d\u8cc7\u6e90\u8a9e\u8a00\u7684\u55ae\u8a9e\u8a9e\u8a00\u6a21\u578b\u7684\u958b\u767c\uff0c\u6301\u7e8c\u53d7\u5230\u9ad8\u54c1\u8cea\u8a13\u7df4\u8cc7\u6599\u4f86\u6e90\u7684\u56f0\u96e3\u6240\u963b\u7919\u3002\u5728\u9019\u9805\u7814\u7a76\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u65b0\u7a4e\u7684\u8de8\u8a9e\u8a00\u8a5e\u5f59\u8f49\u79fb\u7b56\u7565\uff0c\u7a31\u70ba\u8de8\u6a19\u8a18\u5316\uff0c\u65e8\u5728\u89e3\u6c7a\u9019\u500b\u6311\u6230\uff0c\u4e26\u5be6\u73fe\u66f4\u6709\u6548\u7387\u7684\u8a9e\u8a00\u9069\u61c9\u3002\u6211\u5011\u7684\u505a\u6cd5\u8457\u91cd\u65bc\u900f\u904e\u4f7f\u7528\u4f86\u81ea\u4f86\u6e90\u8a9e\u8a00\u7684\u8a9e\u7fa9\u76f8\u4f3c\u6a19\u8a18\u5d4c\u5165\u7684\u52a0\u6b0a\u5e73\u5747\u503c\uff0c\u5c07\u9ad8\u8cc7\u6e90\u55ae\u8a9e LLM \u9069\u61c9\u5230\u672a\u898b\u7684\u76ee\u6a19\u8a9e\u8a00\uff0c\u4f86\u521d\u59cb\u5316\u76ee\u6a19\u8a9e\u8a00\u7684\u6a19\u8a18\u5d4c\u5165\u3002\u70ba\u6b64\uff0c\u6211\u5011\u5229\u7528\u6db5\u84cb\u4f86\u6e90\u8a9e\u8a00\u548c\u76ee\u6a19\u8a9e\u8a00\u7684\u7ffb\u8b6f\u8cc7\u6e90\u3002\u6211\u5011\u4f7f\u7528\u4e00\u7cfb\u5217\u8de8\u6a19\u8a18\u5316 LLM\uff0c\u4e5f\u5c31\u662f Tweeties\uff0c\u9a57\u8b49\u6211\u5011\u7684\u6a21\u578b\uff0c\u4e26\u5728\u5404\u7a2e\u4e0b\u6e38\u4efb\u52d9\u4e2d\uff0c\u65bc\u4e00\u7d44\u6578\u91cf\u5c11\u4f46\u591a\u6a23\u5316\u7684\u8a9e\u8a00\u4e2d\uff0c\u5c55\u793a\u51fa\u5b83\u5011\u5177\u6709\u7af6\u722d\u529b\u7684\u8868\u73fe\u3002\u6b64\u5916\uff0c\u6211\u5011\u5f15\u5165\u4e86 Hydra LLM\uff0c\u9019\u662f\u4e00\u7a2e\u5177\u6709\u591a\u500b\u53ef\u4ea4\u63db\u8a9e\u8a00\u6a21\u578b\u982d\u548c\u5d4c\u5165\u8868\u7684\u6a21\u578b\uff0c\u9032\u4e00\u6b65\u64f4\u5c55\u4e86\u6211\u5011\u7684\u8de8\u6a19\u8a18\u5316\u7b56\u7565\u7684\u529f\u80fd\u3002\u900f\u904e\u6839\u64da\u591a\u8a9e\u8a00\u6a21\u578b TowerInstruct \u8a2d\u8a08 Hydra LLM\uff0c\u6211\u5011\u958b\u767c\u4e86\u4e00\u500b\u6700\u5148\u9032\u7684\u97c3\u977c\u8a9e\u6a5f\u5668\u7ffb\u8b6f\u6a21\u578b\uff0c\u4ee5\u96f6\u6b21\u5b78\u7fd2\u7684\u65b9\u5f0f\uff0c\u5b8c\u5168\u7e5e\u904e\u5c0d\u9ad8\u54c1\u8cea\u5e73\u884c\u8cc7\u6599\u7684\u9700\u6c42\u3002\u5c0d\u65bc\u50cf\u97c3\u977c\u8a9e\u9019\u7a2e\u9ad8\u54c1\u8cea\u5e73\u884c\u8cc7\u6599\u96e3\u4ee5\u53d6\u5f97\u7684\u4f4e\u8cc7\u6e90\u8a9e\u8a00\u800c\u8a00\uff0c\u9019\u500b\u7a81\u7834\u7279\u5225\u91cd\u8981\u3002\u900f\u904e\u964d\u4f4e\u8a13\u7df4\u9ad8\u54c1\u8cea\u6a21\u578b\u7684\u8cc7\u6599\u548c\u6642\u9593\u9700\u6c42\uff0c\u6211\u5011\u7684\u8de8\u6a19\u8a18\u5316\u7b56\u7565\u5141\u8a31\u70ba\u66f4\u591a\u8a9e\u8a00\u958b\u767c LLM\uff0c\u7279\u5225\u662f\u90a3\u4e9b\u8cc7\u6e90\u6709\u9650\u7684\u8a9e\u8a00\u3002\u6211\u5011\u5e0c\u671b\u6211\u5011\u7684\u7814\u7a76\u80fd\u6fc0\u52f5\u8de8\u8a9e\u8a00\u8a5e\u5f59\u8f49\u79fb\u9818\u57df\u9032\u4e00\u6b65\u7684\u7814\u7a76\u548c\u5408\u4f5c\uff0c\u4e26\u6709\u52a9\u65bc\u5728\u5168\u7403\u7bc4\u570d\u5167\u8ce6\u80fd\u8a9e\u8a00\u3002</paragraph>", "author": "Fran\u00e7ois Remy et.al.", "authors": "Fran\u00e7ois Remy, Pieter Delobelle, Hayastan Avetisyan, Alfiya Khabibullina, Miryam de Lhoneux, Thomas Demeester", "id": "2408.04303v1", "paper_url": "http://arxiv.org/abs/2408.04303v1", "repo": "https://github.com/lagom-nlp/transtokenizer"}}