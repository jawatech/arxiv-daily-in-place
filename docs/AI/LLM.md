
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-12-20**|**MotiF: Making Text Count in Image Animation with Motion Focal Loss**|Shijie Wang et.al.|[2412.16153v1](http://arxiv.org/abs/2412.16153v1)|null|
|**2024-12-20**|**Offline Reinforcement Learning for LLM Multi-Step Reasoning**|Huaijie Wang et.al.|[2412.16145v1](http://arxiv.org/abs/2412.16145v1)|null|
|**2024-12-20**|**Can LLMs Obfuscate Code? A Systematic Analysis of Large Language Models into Assembly Code Obfuscation**|Seyedreza Mohseni et.al.|[2412.16135v1](http://arxiv.org/abs/2412.16135v1)|null|
|**2024-12-20**|**PromptOptMe: Error-Aware Prompt Compression for LLM-based MT Evaluation Metrics**|Daniil Larionov et.al.|[2412.16120v1](http://arxiv.org/abs/2412.16120v1)|null|
|**2024-12-20**|**Convolutional Deep Operator Networks for Learning Nonlinear Focused Ultrasound Wave Propagation in Heterogeneous Spinal Cord Anatomy**|Avisha Kumar et.al.|[2412.16118v1](http://arxiv.org/abs/2412.16118v1)|[link](https://github.com/avishakumar21/nonlinear-fus-with-neural-operators)|
|**2024-12-20**|**Demystifying the Potential of ChatGPT-4 Vision for Construction Progress Monitoring**|Ahmet Bahaddin Ersoz et.al.|[2412.16108v1](http://arxiv.org/abs/2412.16108v1)|null|
|**2024-12-20**|**Logical Consistency of Large Language Models in Fact-checking**|Bishwamittra Ghosh et.al.|[2412.16100v1](http://arxiv.org/abs/2412.16100v1)|null|
|**2024-12-20**|**Explainable AI for Multivariate Time Series Pattern Exploration: Latent Space Visual Analytics with Time Fusion Transformer and Variational Autoencoders in Power Grid Event Diagnosis**|Haowen Xu et.al.|[2412.16098v1](http://arxiv.org/abs/2412.16098v1)|null|
|**2024-12-20**|**The Evolution of LLM Adoption in Industry Data Curation Practices**|Crystal Qian et.al.|[2412.16089v1](http://arxiv.org/abs/2412.16089v1)|null|
|**2024-12-20**|**Towards Interpretable Radiology Report Generation via Concept Bottlenecks using a Multi-Agentic RAG**|Hasan Md Tusfiqur Alam et.al.|[2412.16086v1](http://arxiv.org/abs/2412.16086v1)|[link](https://github.com/tifat58/irr-with-cbm-rag)|
|**2024-12-20**|**Formal Mathematical Reasoning: A New Frontier in AI**|Kaiyu Yang et.al.|[2412.16075v1](http://arxiv.org/abs/2412.16075v1)|null|
|**2024-12-20**|**Label-Efficient Data Augmentation with Video Diffusion Models for Guidewire Segmentation in Cardiac Fluoroscopy**|Shaoyan Pan et.al.|[2412.16050v1](http://arxiv.org/abs/2412.16050v1)|null|
|**2024-12-20**|**Applying Predictive Analytics to Occupational Health and Safety in India**|Ritwik Raj Saxena et.al.|[2412.16038v1](http://arxiv.org/abs/2412.16038v1)|null|
|**2024-12-20**|**A Framework for Streaming Event-Log Prediction in Business Processes**|Benedikt Bollig et.al.|[2412.16032v1](http://arxiv.org/abs/2412.16032v1)|null|
|**2024-12-20**|**The Only Way is Ethics: A Guide to Ethical Research with Large Language Models**|Eddie L. Ungless et.al.|[2412.16022v1](http://arxiv.org/abs/2412.16022v1)|[link](https://github.com/mxeddie/ethics-whitepaper)|
|**2024-12-20**|**Choose Your Explanation: A Comparison of SHAP and GradCAM in Human Activity Recognition**|Felix Tempel et.al.|[2412.16003v1](http://arxiv.org/abs/2412.16003v1)|[link](https://github.com/deepinmotion/shapgcn)|
|**2024-12-20**|**CNN-LSTM Hybrid Deep Learning Model for Remaining Useful Life Estimation**|Muthukumar G et.al.|[2412.15998v1](http://arxiv.org/abs/2412.15998v1)|null|
|**2024-12-20**|**Data-Centric Improvements for Enhancing Multi-Modal Understanding in Spoken Conversation Modeling**|Maximillian Chen et.al.|[2412.15995v1](http://arxiv.org/abs/2412.15995v1)|null|
|**2024-12-20**|**Fearful Falcons and Angry Llamas: Emotion Category Annotations of Arguments by Humans and LLMs**|Lynn Greschner et.al.|[2412.15993v1](http://arxiv.org/abs/2412.15993v1)|null|
|**2024-12-20**|**BabyHGRN: Exploring RNNs for Sample-Efficient Training of Language Models**|Patrick Haller et.al.|[2412.15978v1](http://arxiv.org/abs/2412.15978v1)|null|
|**2024-12-20**|**Self-Supervised Radiograph Anatomical Region Classification -- How Clean Is Your Real-World Data?**|Simon Langer et.al.|[2412.15967v1](http://arxiv.org/abs/2412.15967v1)|null|
|**2024-12-20**|**From General to Specific: Tailoring Large Language Models for Personalized Healthcare**|Ruize Shi et.al.|[2412.15957v1](http://arxiv.org/abs/2412.15957v1)|null|
|**2024-12-20**|**Trust Calibration in IDEs: Paving the Way for Widespread Adoption of AI Refactoring**|Markus Borg et.al.|[2412.15948v1](http://arxiv.org/abs/2412.15948v1)|null|
|**2024-12-20**|**Reframing Image Difference Captioning with BLIP2IDC and Synthetic Augmentation**|Gautier Evennou et.al.|[2412.15939v1](http://arxiv.org/abs/2412.15939v1)|null|
|**2024-12-20**|**Watertox: The Art of Simplicity in Universal Attacks A Cross-Model Framework for Robust Adversarial Generation**|Zhenghao Gao et.al.|[2412.15924v1](http://arxiv.org/abs/2412.15924v1)|null|
|**2024-12-20**|**Less is More: Towards Green Code Large Language Models via Unified Structural Pruning**|Guang Yang et.al.|[2412.15921v1](http://arxiv.org/abs/2412.15921v1)|null|
|**2024-12-20**|**Development of a Large-scale Dataset of Chest Computed Tomography Reports in Japanese and a High-performance Finding Classification Model**|Yosuke Yamagishi et.al.|[2412.15907v1](http://arxiv.org/abs/2412.15907v1)|null|
|**2024-12-20**|**What Are Step-Level Reward Models Rewarding? Counterintuitive Findings from MCTS-Boosted Mathematical Reasoning**|Yiran Ma et.al.|[2412.15904v1](http://arxiv.org/abs/2412.15904v1)|null|
|**2024-12-20**|**On the Suitability of pre-trained foundational LLMs for Analysis in German Legal Education**|Lorenz Wendlinger et.al.|[2412.15902v1](http://arxiv.org/abs/2412.15902v1)|null|
|**2024-12-20**|**A Thorough Investigation into the Application of Deep CNN for Enhancing Natural Language Processing Capabilities**|Chang Weng et.al.|[2412.15900v1](http://arxiv.org/abs/2412.15900v1)|null|
|**2024-12-20**|**TelcoLM: collecting data, adapting, and benchmarking language models for the telecommunication domain**|Camille Barboule et.al.|[2412.15891v1](http://arxiv.org/abs/2412.15891v1)|null|
|**2024-12-20**|**AI-in-the-loop: The future of biomedical visual analytics applications in the era of AI**|Katja Bühler et.al.|[2412.15876v1](http://arxiv.org/abs/2412.15876v1)|null|
|**2024-12-20**|**Align Anything: Training All-Modality Models to Follow Instructions with Language Feedback**|Jiaming Ji et.al.|[2412.15838v1](http://arxiv.org/abs/2412.15838v1)|[link](https://github.com/pku-alignment/align-anything)|
|**2024-12-20**|**Enriching Social Science Research via Survey Item Linking**|Tornike Tsereteli et.al.|[2412.15831v1](http://arxiv.org/abs/2412.15831v1)|[link](https://github.com/e-tornike/sil)|
|**2024-12-20**|**S$^2$DN: Learning to Denoise Unconvincing Knowledge for Inductive Knowledge Graph Completion**|Tengfei Ma et.al.|[2412.15822v1](http://arxiv.org/abs/2412.15822v1)|null|
|**2024-12-20**|**$π$-yalli: un nouveau corpus pour le nahuatl**|Juan-Manuel Torres-Moreno et.al.|[2412.15821v1](http://arxiv.org/abs/2412.15821v1)|null|
|**2024-12-20**|**WebLLM: A High-Performance In-Browser LLM Inference Engine**|Charlie F. Ruan et.al.|[2412.15803v1](http://arxiv.org/abs/2412.15803v1)|[link](https://github.com/mlc-ai/web-llm)|
|**2024-12-20**|**Bi-directional Mapping of Morphology Metrics and 3D City Blocks for Enhanced Characterization and Generation of Urban Form**|Chenyi Cai et.al.|[2412.15801v1](http://arxiv.org/abs/2412.15801v1)|null|
|**2024-12-20**|**Ensembling Large Language Models with Process Reward-Guided Tree Search for Better Complex Reasoning**|Sungjin Park et.al.|[2412.15797v1](http://arxiv.org/abs/2412.15797v1)|null|
|**2024-12-20**|**GraphSeqLM: A Unified Graph Language Framework for Omic Graph Learning**|Heming Zhang et.al.|[2412.15790v1](http://arxiv.org/abs/2412.15790v1)|null|
|**2024-12-20**|**Learning from Impairment: Leveraging Insights from Clinical Linguistics in Language Modelling Research**|Dominique Brunato et.al.|[2412.15785v1](http://arxiv.org/abs/2412.15785v1)|null|
|**2024-12-20**|**Linguistic Features Extracted by GPT-4 Improve Alzheimer's Disease Detection based on Spontaneous Speech**|Jonathan Heitz et.al.|[2412.15772v1](http://arxiv.org/abs/2412.15772v1)|[link](https://github.com/jheitz/coling2025_gpt_paper)|
|**2024-12-20**|**Critique of Impure Reason: Unveiling the reasoning behaviour of medical Large Language Models**|Shamus Sim et.al.|[2412.15748v1](http://arxiv.org/abs/2412.15748v1)|null|
|**2024-12-20**|**Fine-tuning Whisper on Low-Resource Languages for Real-World Applications**|Vincenzo Timmel et.al.|[2412.15726v1](http://arxiv.org/abs/2412.15726v1)|[link](https://github.com/i4ds/whisper-finetune)|
|**2024-12-20**|**AutoLife: Automatic Life Journaling with Smartphones and LLMs**|Huatao Xu et.al.|[2412.15714v1](http://arxiv.org/abs/2412.15714v1)|null|
|**2024-12-20**|**Contrastive Learning for Task-Independent SpeechLLM-Pretraining**|Maike Züfle et.al.|[2412.15712v1](http://arxiv.org/abs/2412.15712v1)|null|
|**2024-12-20**|**MacLight: Multi-scene Aggregation Convolutional Learning for Traffic Signal Control**|Sunbowen Lee et.al.|[2412.15703v1](http://arxiv.org/abs/2412.15703v1)|[link](https://github.com/Aegis1863/MacLight)|
|**2024-12-20**|**Collaborative Gym: A Framework for Enabling and Evaluating Human-Agent Collaboration**|Yijia Shao et.al.|[2412.15701v1](http://arxiv.org/abs/2412.15701v1)|null|
|**2024-12-20**|**Variability Need Not Imply Error: The Case of Adequate but Semantically Distinct Responses**|Evgenia Ilia et.al.|[2412.15683v1](http://arxiv.org/abs/2412.15683v1)|[link](https://github.com/evgeniael/probar)|
|**2024-12-20**|**AI-generated Image Quality Assessment in Visual Communication**|Yu Tian et.al.|[2412.15677v1](http://arxiv.org/abs/2412.15677v1)|null|
|**2024-12-20**|**Adaptable and Precise: Enterprise-Scenario LLM Function-Calling Capability Training Pipeline**|Guancheng Zeng et.al.|[2412.15660v1](http://arxiv.org/abs/2412.15660v1)|null|
|**2024-12-20**|**MathSpeech: Leveraging Small LMs for Accurate Conversion in Mathematical Speech-to-Formula**|Sieun Hyeon et.al.|[2412.15655v1](http://arxiv.org/abs/2412.15655v1)|[link](https://github.com/hyeonsieun/mathspeech)|
|**2024-12-20**|**Error-driven Data-efficient Large Multimodal Model Tuning**|Barry Menglong Yao et.al.|[2412.15652v1](http://arxiv.org/abs/2412.15652v1)|null|
|**2024-12-20**|**Can Input Attributions Interpret the Inductive Reasoning Process Elicited in In-Context Learning?**|Mengyu Ye et.al.|[2412.15628v1](http://arxiv.org/abs/2412.15628v1)|null|
|**2024-12-20**|**JailPO: A Novel Black-box Jailbreak Framework via Preference Optimization against Aligned LLMs**|Hongyi Li et.al.|[2412.15623v1](http://arxiv.org/abs/2412.15623v1)|null|
|**2024-12-20**|**TouchASP: Elastic Automatic Speech Perception that Everyone Can Touch**|Xingchen Song et.al.|[2412.15622v1](http://arxiv.org/abs/2412.15622v1)|null|
|**2024-12-20**|**Modeling Autonomous Shifts Between Focus State and Mind-Wandering Using a Predictive-Coding-Inspired Variational RNN Model**|Henrique Oyama et.al.|[2412.15620v1](http://arxiv.org/abs/2412.15620v1)|null|
|**2024-12-20**|**Understanding Individual Agent Importance in Multi-Agent System via Counterfactual Reasoning**|Chen Jianming et.al.|[2412.15619v1](http://arxiv.org/abs/2412.15619v1)|null|
|**2024-12-20**|**Microservices-Based Framework for Predictive Analytics and Real-time Performance Enhancement in Travel Reservation Systems**|Biman Barua et.al.|[2412.15616v1](http://arxiv.org/abs/2412.15616v1)|null|
|**2024-12-20**|**Multi-modal Agent Tuning: Building a VLM-Driven Agent for Efficient Tool Usage**|Zhi Gao et.al.|[2412.15606v1](http://arxiv.org/abs/2412.15606v1)|null|
|**2024-12-20**|**Don't Do RAG: When Cache-Augmented Generation is All You Need for Knowledge Tasks**|Brian J Chan et.al.|[2412.15605v1](http://arxiv.org/abs/2412.15605v1)|null|
|**2024-12-20**|**Dynamic Label Name Refinement for Few-Shot Dialogue Intent Classification**|Gyutae Park et.al.|[2412.15603v1](http://arxiv.org/abs/2412.15603v1)|null|
|**2024-12-20**|**SODor: Long-Term EEG Partitioning for Seizure Onset Detection**|Zheng Chen et.al.|[2412.15598v1](http://arxiv.org/abs/2412.15598v1)|null|
|**2024-12-20**|**Mask-RadarNet: Enhancing Transformer With Spatial-Temporal Semantic Context for Radar Object Detection in Autonomous Driving**|Yuzhi Wu et.al.|[2412.15595v1](http://arxiv.org/abs/2412.15595v1)|null|
|**2024-12-20**|**Template-Driven LLM-Paraphrased Framework for Tabular Math Word Problem Generation**|Xiaoqiang Kang et.al.|[2412.15594v1](http://arxiv.org/abs/2412.15594v1)|[link](https://github.com/jason8kang/tell)|
|**2024-12-20**|**Machine Learning Techniques for Pattern Recognition in High-Dimensional Data Mining**|Pochun Li et.al.|[2412.15593v1](http://arxiv.org/abs/2412.15593v1)|null|
|**2024-12-20**|**Pre-training Graph Neural Networks on Molecules by Using Subgraph-Conditioned Graph Information Bottleneck**|Van Thuy Hoang et.al.|[2412.15589v1](http://arxiv.org/abs/2412.15589v1)|null|
|**2024-12-20**|**NeSyCoCo: A Neuro-Symbolic Concept Composer for Compositional Generalization**|Danial Kamali et.al.|[2412.15588v1](http://arxiv.org/abs/2412.15588v1)|null|
|**2024-12-20**|**Score-based Generative Diffusion Models for Social Recommendations**|Chengyi Liu et.al.|[2412.15579v1](http://arxiv.org/abs/2412.15579v1)|[link](https://github.com/anonymous-coderepository/score-based-generative-diffusion-models-for-social-recommendations-sgsr)|
|**2024-12-20**|**Continual Learning Using a Kernel-Based Method Over Foundation Models**|Saleh Momeni et.al.|[2412.15571v1](http://arxiv.org/abs/2412.15571v1)|[link](https://github.com/salehmomeni/klda)|
|**2024-12-20**|**In-context Continual Learning Assisted by an External Continual Learner**|Saleh Momeni et.al.|[2412.15563v1](http://arxiv.org/abs/2412.15563v1)|null|
|**2024-12-20**|**MORTAR: Metamorphic Multi-turn Testing for LLM-based Dialogue Systems**|Guoxiang Guo et.al.|[2412.15557v1](http://arxiv.org/abs/2412.15557v1)|null|
|**2024-12-20**|**Architecture-Aware Learning Curve Extrapolation via Graph Ordinary Differential Equation**|Yanna Ding et.al.|[2412.15554v1](http://arxiv.org/abs/2412.15554v1)|null|
|**2024-12-20**|**NGQA: A Nutritional Graph Question Answering Benchmark for Personalized Health-aware Nutritional Reasoning**|Zheyuan Zhang et.al.|[2412.15547v1](http://arxiv.org/abs/2412.15547v1)|null|
|**2024-12-20**|**VLM-RL: A Unified Vision Language Models and Reinforcement Learning Framework for Safe Autonomous Driving**|Zilin Huang et.al.|[2412.15544v1](http://arxiv.org/abs/2412.15544v1)|null|
|**2024-12-20**|**ChangeDiff: A Multi-Temporal Change Detection Data Generator with Flexible Text Prompts via Diffusion Model**|Qi Zang et.al.|[2412.15541v1](http://arxiv.org/abs/2412.15541v1)|[link](https://github.com/dzhaoxd/changediff)|
|**2024-12-20**|**MRAG: A Modular Retrieval Framework for Time-Sensitive Question Answering**|Zhang Siyue et.al.|[2412.15540v1](http://arxiv.org/abs/2412.15540v1)|null|
|**2024-12-20**|**Improved Forecasts of Global Extreme Marine Heatwaves Through a Physics-guided Data-driven Approach**|Ruiqi Shu et.al.|[2412.15532v1](http://arxiv.org/abs/2412.15532v1)|null|
|**2024-12-20**|**XRAG: eXamining the Core -- Benchmarking Foundational Components in Advanced Retrieval-Augmented Generation**|Qianren Mao et.al.|[2412.15529v1](http://arxiv.org/abs/2412.15529v1)|null|
|**2024-12-20**|**HREF: Human Response-Guided Evaluation of Instruction Following in Language Models**|Xinxi Lyu et.al.|[2412.15524v1](http://arxiv.org/abs/2412.15524v1)|null|
|**2024-12-20**|**InstructOCR: Instruction Boosting Scene Text Spotting**|Chen Duan et.al.|[2412.15523v1](http://arxiv.org/abs/2412.15523v1)|null|
|**2024-12-20**|**RESQUE: Quantifying Estimator to Task and Distribution Shift for Sustainable Model Reusability**|Vishwesh Sangarya et.al.|[2412.15511v1](http://arxiv.org/abs/2412.15511v1)|[link](https://github.com/jekimlab/aaai2025resque)|
|**2024-12-20**|**ADEQA: A Question Answer based approach for joint ADE-Suspect Extraction using Sequence-To-Sequence Transformers**|Vinayak Arannil et.al.|[2412.15510v1](http://arxiv.org/abs/2412.15510v1)|null|
|**2024-12-20**|**Mitigating Social Bias in Large Language Models: A Multi-Objective Approach within a Multi-Agent Framework**|Zhenjie Xu et.al.|[2412.15504v1](http://arxiv.org/abs/2412.15504v1)|null|
|**2024-12-20**|**Humanlike Cognitive Patterns as Emergent Phenomena in Large Language Models**|Zhisheng Tang et.al.|[2412.15501v1](http://arxiv.org/abs/2412.15501v1)|null|
|**2024-12-20**|**A Robust Prototype-Based Network with Interpretable RBF Classifier Foundations**|Sascha Saralajew et.al.|[2412.15499v1](http://arxiv.org/abs/2412.15499v1)|null|
|**2024-12-20**|**The First Multilingual Model For The Detection of Suicide Texts**|Rodolfo Zevallos et.al.|[2412.15498v1](http://arxiv.org/abs/2412.15498v1)|null|
|**2024-12-20**|**Lexicography Saves Lives (LSL): Automatically Translating Suicide-Related Language**|Annika Marie Schoene et.al.|[2412.15497v1](http://arxiv.org/abs/2412.15497v1)|null|
|**2024-12-20**|**TL-Training: A Task-Feature-Based Framework for Training Large Language Models in Tool Use**|Junjie Ye et.al.|[2412.15495v1](http://arxiv.org/abs/2412.15495v1)|[link](https://github.com/junjie-ye/tl-training)|
|**2024-12-20**|**Multi-LLM Text Summarization**|Jiangnan Fang et.al.|[2412.15487v1](http://arxiv.org/abs/2412.15487v1)|null|
|**2024-12-20**|**Task-Specific Preconditioner for Cross-Domain Few-Shot Learning**|Suhyun Kang et.al.|[2412.15483v1](http://arxiv.org/abs/2412.15483v1)|null|
|**2024-12-20**|**Continual Learning Using Only Large Language Model Prompting**|Jiabao Qiu et.al.|[2412.15479v1](http://arxiv.org/abs/2412.15479v1)|null|
|**2024-12-20**|**A Review of the Marathi Natural Language Processing**|Asang Dani et.al.|[2412.15471v1](http://arxiv.org/abs/2412.15471v1)|null|
|**2024-12-20**|**Non-Uniform Parameter-Wise Model Merging**|Albert Manuel Orozco Camacho et.al.|[2412.15467v1](http://arxiv.org/abs/2412.15467v1)|null|
|**2024-12-19**|**TalkWithMachines: Enhancing Human-Robot Interaction for Interpretable Industrial Robotics Through Large/Vision Language Models**|Ammar N. Abbas et.al.|[2412.15462v1](http://arxiv.org/abs/2412.15462v1)|null|
|**2024-12-19**|**Northeastern Uni at Multilingual Counterspeech Generation: Enhancing Counter Speech Generation with LLM Alignment through Direct Preference Optimization**|Sahil Wadhwa et.al.|[2412.15453v1](http://arxiv.org/abs/2412.15453v1)|null|
|**2024-12-19**|**Fietje: An open, efficient LLM for Dutch**|Bram Vanroy et.al.|[2412.15450v1](http://arxiv.org/abs/2412.15450v1)|null|
|**2024-12-19**|**AI-Enhanced Sensemaking: Exploring the Design of a Generative AI-Based Assistant to Support Genetic Professionals**|Angela Mastrianni et.al.|[2412.15444v1](http://arxiv.org/abs/2412.15444v1)|null|
|**2024-12-19**|**SKETCH: Structured Knowledge Enhanced Text Comprehension for Holistic Retrieval**|Aakash Mahalingam et.al.|[2412.15443v1](http://arxiv.org/abs/2412.15443v1)|null|
|**2024-12-19**|**Energy consumption of code small language models serving with runtime engines and execution providers**|Francisco Durán et.al.|[2412.15441v1](http://arxiv.org/abs/2412.15441v1)|null|

#### Abstracts
##### **MotiF: Making Text Count in Image Animation with Motion Focal Loss**
2412.16153v1 by Shijie Wang, Samaneh Azadi, Rohit Girdhar, Saketh Rambhatla, Chen Sun, Xi Yin

Text-Image-to-Video (TI2V) generation aims to generate a video from an image
following a text description, which is also referred to as text-guided image
animation. Most existing methods struggle to generate videos that align well
with the text prompts, particularly when motion is specified. To overcome this
limitation, we introduce MotiF, a simple yet effective approach that directs
the model's learning to the regions with more motion, thereby improving the
text alignment and motion generation. We use optical flow to generate a motion
heatmap and weight the loss according to the intensity of the motion. This
modified objective leads to noticeable improvements and complements existing
methods that utilize motion priors as model inputs. Additionally, due to the
lack of a diverse benchmark for evaluating TI2V generation, we propose TI2V
Bench, a dataset consists of 320 image-text pairs for robust evaluation. We
present a human evaluation protocol that asks the annotators to select an
overall preference between two videos followed by their justifications. Through
a comprehensive evaluation on TI2V Bench, MotiF outperforms nine open-sourced
models, achieving an average preference of 72%. The TI2V Bench is released in
https://wang-sj16.github.io/motif/.

摘要：文本影像轉影片 (TI2V) 生成旨在根據文字描述從影像產生影片，這也稱為文字引導影像動畫。現有的方法大多難以產生與文字提示相符的影片，特別是在指定動作時。為了克服這個限制，我們引入了 MotiF，這是一種簡單但有效的方法，可以將模型的學習引導至動作較多的區域，從而改善文字對齊和動作產生。我們使用光流來產生動作熱圖，並根據動作強度加權損失。這個修改過的目標導致明顯的改善，並補充了將動作先驗用作模型輸入的現有方法。此外，由於缺乏用於評估 TI2V 生成的多元基準，我們提出了 TI2V Bench，一個由 320 個影像文字對組成的資料集，用於穩健評估。我們提出了一種人類評估協定，要求註解者在兩個影片之間選擇一個整體偏好，然後說明其理由。透過對 TI2V Bench 的全面評估，MotiF 優於九個開源模型，平均偏好達到 72%。TI2V Bench 已在 https://wang-sj16.github.io/motif/ 中發布。

##### **Offline Reinforcement Learning for LLM Multi-Step Reasoning**
2412.16145v1 by Huaijie Wang, Shibo Hao, Hanze Dong, Shenao Zhang, Yilin Bao, Ziran Yang, Yi Wu

Improving the multi-step reasoning ability of large language models (LLMs)
with offline reinforcement learning (RL) is essential for quickly adapting them
to complex tasks. While Direct Preference Optimization (DPO) has shown promise
in aligning LLMs with human preferences, it is less suitable for multi-step
reasoning tasks because (1) DPO relies on paired preference data, which is not
readily available for multi-step reasoning tasks, and (2) it treats all tokens
uniformly, making it ineffective for credit assignment in multi-step reasoning
tasks, which often come with sparse reward. In this work, we propose OREO
(Offline Reasoning Optimization), an offline RL method for enhancing LLM
multi-step reasoning. Building on insights from previous works of maximum
entropy reinforcement learning, it jointly learns a policy model and value
function by optimizing the soft Bellman Equation. We show in principle that it
reduces the need to collect pairwise data and enables better credit assignment.
Empirically, OREO surpasses existing offline learning methods on multi-step
reasoning benchmarks, including mathematical reasoning tasks (GSM8K, MATH) and
embodied agent control (ALFWorld). The approach can be extended to a
multi-iteration framework when additional resources are available. Furthermore,
the learned value function can be leveraged to guide the tree search for free,
which can further boost performance during test time.

摘要：<paragraph>透過離線強化學習 (RL) 來提升大型語言模型 (LLM) 的多步驟推理能力，對於讓 LLM 能快速適應複雜的任務至關重要。雖然直接偏好最佳化 (DPO) 已展現出讓 LLM 與人類偏好保持一致的潛力，但它較不適合多步驟推理任務，原因有：(1) DPO 依賴配對偏好資料，而此類資料不易取得；(2) DPO 一視同仁地對待所有符號，這使得它在多步驟推理任務中無法有效進行信用分配，而多步驟推理任務通常伴隨著稀疏的獎勵。在此研究中，我們提出 OREO (離線推理最佳化)，這是一種離線 RL 方法，用於增強 LLM 的多步驟推理。透過建構於最大熵強化學習先前的研究見解，它透過最佳化軟 Bellman 方程式，同時學習政策模型和價值函數。我們在原理上證明，它減少了收集成對資料的需求，並能進行更好的信用分配。根據經驗，OREO 在多步驟推理基準上超越了現有的離線學習方法，包括數學推理任務 (GSM8K、MATH) 和具身代理控制 (ALFWorld)。當有額外資源時，此方法可以延伸到多重反覆運算架構。此外，學習到的價值函數可以被利用來免費引導樹狀搜尋，這可以在測試期間進一步提升效能。</paragraph>

##### **Can LLMs Obfuscate Code? A Systematic Analysis of Large Language Models into Assembly Code Obfuscation**
2412.16135v1 by Seyedreza Mohseni, Seyedali Mohammadi, Deepa Tilwani, Yash Saxena, Gerald Ndwula, Sriram Vema, Edward Raff, Manas Gaur

Malware authors often employ code obfuscations to make their malware harder
to detect. Existing tools for generating obfuscated code often require access
to the original source code (e.g., C++ or Java), and adding new obfuscations is
a non-trivial, labor-intensive process. In this study, we ask the following
question: Can Large Language Models (LLMs) potentially generate a new
obfuscated assembly code? If so, this poses a risk to anti-virus engines and
potentially increases the flexibility of attackers to create new obfuscation
patterns. We answer this in the affirmative by developing the MetamorphASM
benchmark comprising MetamorphASM Dataset (MAD) along with three code
obfuscation techniques: dead code, register substitution, and control flow
change. The MetamorphASM systematically evaluates the ability of LLMs to
generate and analyze obfuscated code using MAD, which contains 328,200
obfuscated assembly code samples. We release this dataset and analyze the
success rate of various LLMs (e.g., GPT-3.5/4, GPT-4o-mini, Starcoder,
CodeGemma, CodeLlama, CodeT5, and LLaMA 3.1) in generating obfuscated assembly
code. The evaluation was performed using established information-theoretic
metrics and manual human review to ensure correctness and provide the
foundation for researchers to study and develop remediations to this risk. The
source code can be found at the following GitHub link:
https://github.com/mohammadi-ali/MetamorphASM.

摘要：<paragraph>惡意軟體作者經常使用程式碼混淆技術，讓他們的惡意軟體更難被偵測到。現有的混淆程式碼產生工具通常需要取得原始原始碼（例如，C++ 或 Java），而新增新的混淆技術是一個不平凡且費工的過程。在這項研究中，我們提出以下問題：大型語言模型 (LLM) 是否有可能產生新的混淆組合碼？如果是這樣，這對防毒軟體引擎構成風險，並可能增加攻擊者建立新的混淆模式的靈活性。我們透過開發包含 MetamorphASM 資料集 (MAD) 的 MetamorphASM 基準，以及三種程式碼混淆技術：無效程式碼、暫存器替換和控制流程變更，來肯定地回答這個問題。MetamorphASM 系統性地評估 LLM 使用 MAD 產生和分析混淆程式碼的能力，其中包含 328,200 個混淆組合碼範例。我們釋出此資料集，並分析各種 LLM（例如，GPT-3.5/4、GPT-4o-mini、Starcoder、CodeGemma、CodeLlama、CodeT5 和 LLaMA 3.1）在產生混淆組合碼中的成功率。評估是使用已建立的資訊理論指標和人工審查進行，以確保正確性並為研究人員研究和開發針對此風險的補救措施提供基礎。原始碼可以在以下 GitHub 連結找到：https://github.com/mohammadi-ali/MetamorphASM。</paragraph>

##### **PromptOptMe: Error-Aware Prompt Compression for LLM-based MT Evaluation Metrics**
2412.16120v1 by Daniil Larionov, Steffen Eger

Evaluating the quality of machine-generated natural language content is a
challenging task in Natural Language Processing (NLP). Recently, large language
models (LLMs) like GPT-4 have been employed for this purpose, but they are
computationally expensive due to the extensive token usage required by complex
evaluation prompts. In this paper, we propose a prompt optimization approach
that uses a smaller, fine-tuned language model to compress input data for
evaluation prompt, thus reducing token usage and computational cost when using
larger LLMs for downstream evaluation. Our method involves a two-stage
fine-tuning process: supervised fine-tuning followed by preference optimization
to refine the model's outputs based on human preferences. We focus on Machine
Translation (MT) evaluation and utilize the GEMBA-MQM metric as a starting
point. Our results show a $2.37\times$ reduction in token usage without any
loss in evaluation quality. This work makes state-of-the-art LLM-based metrics
like GEMBA-MQM more cost-effective and efficient, enhancing their accessibility
for broader use.

摘要：評估機器產生的自然語言內容品質是自然語言處理 (NLP) 中的一項挑戰性任務。最近，GPT-4 等大型語言模型 (LLM) 已被用於此目的，但由於複雜的評估提示需要大量使用符號，因此它們在計算上很昂貴。在本文中，我們提出了一種提示最佳化方法，它使用較小的微調語言模型來壓縮輸入資料以進行評估提示，從而減少使用符號和在使用較大的 LLM 進行下游評估時的計算成本。我們的做法包括一個兩階段微調過程：監督微調，然後是偏好最佳化，以根據人類偏好微調模型的輸出。我們專注於機器翻譯 (MT) 評估，並利用 GEMBA-MQM 指標作為起點。我們的結果顯示符號使用量減少了 2.37 倍，而評估品質沒有任何損失。這項工作使基於 LLM 的最先進指標（例如 GEMBA-MQM）更具成本效益和效率，並提高了它們在更廣泛使用中的可及性。

##### **Convolutional Deep Operator Networks for Learning Nonlinear Focused Ultrasound Wave Propagation in Heterogeneous Spinal Cord Anatomy**
2412.16118v1 by Avisha Kumar, Xuzhe Zhi, Zan Ahmad, Minglang Yin, Amir Manbachi

Focused ultrasound (FUS) therapy is a promising tool for optimally targeted
treatment of spinal cord injuries (SCI), offering submillimeter precision to
enhance blood flow at injury sites while minimizing impact on surrounding
tissues. However, its efficacy is highly sensitive to the placement of the
ultrasound source, as the spinal cord's complex geometry and acoustic
heterogeneity distort and attenuate the FUS signal. Current approaches rely on
computer simulations to solve the governing wave propagation equations and
compute patient-specific pressure maps using ultrasound images of the spinal
cord anatomy. While accurate, these high-fidelity simulations are
computationally intensive, taking up to hours to complete parameter sweeps,
which is impractical for real-time surgical decision-making. To address this
bottleneck, we propose a convolutional deep operator network (DeepONet) to
rapidly predict FUS pressure fields in patient spinal cords. Unlike
conventional neural networks, DeepONets are well equipped to approximate the
solution operator of the parametric partial differential equations (PDEs) that
govern the behavior of FUS waves with varying initial and boundary conditions
(i.e., new transducer locations or spinal cord geometries) without requiring
extensive simulations. Trained on simulated pressure maps across diverse
patient anatomies, this surrogate model achieves real-time predictions with
only a 2% loss on the test set, significantly accelerating the modeling of
nonlinear physical systems in heterogeneous domains. By facilitating rapid
parameter sweeps in surgical settings, this work provides a crucial step toward
precise and individualized solutions in neurosurgical treatments.

摘要：聚焦超音波 (FUS) 治療是一種有望用於脊髓損傷 (SCI) 的最佳目標治療，它提供亞毫米精準度，可在損傷部位增強血流，同時將對周圍組織的影響降至最低。然而，其效能對超音波來源的放置高度敏感，因為脊髓的複雜幾何形狀和聲學異質性會扭曲和衰減 FUS 訊號。目前的做法依賴電腦模擬來解決控制波傳播方程式，並使用脊髓解剖結構的超音波影像計算特定於患者的壓力圖。儘管準確，但這些高保真模擬在運算上很密集，需要花費數小時才能完成參數掃描，這對於即時手術決策而言並不切實際。為了解決這個瓶頸，我們提出一個卷積深度算子網路 (DeepONet)，以便快速預測患者脊髓中的 FUS 壓力場。與傳統的神經網路不同，DeepONet 具備良好的設備，可近似控制參數偏微分方程式 (PDE) 的解算算子，這些方程式控制 FUS 波在不同的初始和邊界條件下的行為（即新的換能器位置或脊髓幾何形狀），而不需要廣泛的模擬。在模擬壓力圖上訓練各種患者解剖結構，此代理模型可實現即時預測，測試組的損失僅為 2%，大幅加速異質領域中非線性物理系統的建模。透過促進手術設定中的快速參數掃描，這項工作為神經外科治療中的精確且個別化的解決方案提供了關鍵的一步。

##### **Demystifying the Potential of ChatGPT-4 Vision for Construction Progress Monitoring**
2412.16108v1 by Ahmet Bahaddin Ersoz

The integration of Large Vision-Language Models (LVLMs) such as OpenAI's
GPT-4 Vision into various sectors has marked a significant evolution in the
field of artificial intelligence, particularly in the analysis and
interpretation of visual data. This paper explores the practical application of
GPT-4 Vision in the construction industry, focusing on its capabilities in
monitoring and tracking the progress of construction projects. Utilizing
high-resolution aerial imagery of construction sites, the study examines how
GPT-4 Vision performs detailed scene analysis and tracks developmental changes
over time. The findings demonstrate that while GPT-4 Vision is proficient in
identifying construction stages, materials, and machinery, it faces challenges
with precise object localization and segmentation. Despite these limitations,
the potential for future advancements in this technology is considerable. This
research not only highlights the current state and opportunities of using LVLMs
in construction but also discusses future directions for enhancing the model's
utility through domain-specific training and integration with other computer
vision techniques and digital twins.

摘要：大型視覺語言模型 (LVLMs) 如 OpenAI 的 GPT-4 Vision 整合到各個領域，標誌著人工智慧領域的重大演進，特別是在視覺資料的分析和詮釋方面。本文探討 GPT-4 Vision 在建築產業的實際應用，重點在於其監控和追蹤建築專案進度的能力。本研究利用建築工地的解析度航照影像，探討 GPT-4 Vision 如何執行詳細場景分析，並追蹤時間演進的變化。研究結果顯示，雖然 GPT-4 Vision 能熟練地辨識施工階段、材料和機械，但在精確的物件定位和分割方面仍有挑戰。儘管有這些限制，這項技術未來進展的潛力仍相當可觀。本研究不僅重點說明 LVLMs 在建築業的現況和機會，也討論了透過特定領域訓練和與其他電腦視覺技術和數位分身整合來增強模型效用的未來方向。

##### **Logical Consistency of Large Language Models in Fact-checking**
2412.16100v1 by Bishwamittra Ghosh, Sarah Hasan, Naheed Anjum Arafat, Arijit Khan

In recent years, large language models (LLMs) have demonstrated significant
success in performing varied natural language tasks such as language
translation, question-answering, summarizing, fact-checking, etc. Despite LLMs'
impressive ability to generate human-like texts, LLMs are infamous for their
inconsistent responses -- a meaning-preserving change in the input query
results in an inconsistent response and attributes to vulnerabilities of LLMs
such as hallucination, jailbreaking, etc. Consequently, existing research
focuses on simple paraphrasing-based consistency assessment of LLMs, and
ignores complex queries that necessitates an even better understanding of
logical reasoning by an LLM. Our work therefore addresses the logical
inconsistency of LLMs under complex logical queries with primitive logical
operators, e.g., negation, conjunction, and disjunction. As a test bed, we
consider retrieval-augmented LLMs on a fact-checking task involving
propositional logic queries from real-world knowledge graphs (KGs). Our
contributions are three-fold. Benchmark: We introduce three logical
fact-checking datasets over KGs for community development towards logically
consistent LLMs. Assessment: We propose consistency measures of LLMs on
propositional logic queries as input and demonstrate that existing LLMs lack
logical consistency, specially on complex queries. Improvement: We employ
supervised fine-tuning to improve the logical consistency of LLMs on the
complex fact-checking task with KG contexts.

摘要：近年來，大型語言模型 (LLM) 在執行各種自然語言任務（例如語言翻譯、問答、摘要、事實查核等）方面展現出顯著的成功。儘管 LLM 能產生類似人類的文字，但 LLM 以其不一致的回應而臭名昭著——輸入查詢中一個保意改變會導致不一致的回應，並歸因於 LLM 的漏洞，例如幻覺、越獄等。因此，現有的研究專注於 LLM 的基於簡單改寫的一致性評估，而忽略了需要 LLM 更深入理解邏輯推理的複雜查詢。因此，我們的研究解決了 LLM 在具有基本邏輯運算元（例如否定、合取和析取）的複雜邏輯查詢下的邏輯不一致性。作為一個測試平台，我們考慮在一個涉及來自真實世界知識圖譜 (KG) 的命題邏輯查詢的事實查核任務中，檢索增強的 LLM。我們的貢獻有三方面。基準：我們在 KG 上引入了三個邏輯事實查核數據集，以促進社區開發邏輯一致的 LLM。評估：我們提出了 LLM 在命題邏輯查詢作為輸入上的一致性測量，並證明現有的 LLM 缺乏邏輯一致性，特別是在複雜查詢上。改進：我們採用監督微調來提高 LLM 在具有 KG 背景的複雜事實查核任務上的邏輯一致性。

##### **Explainable AI for Multivariate Time Series Pattern Exploration: Latent Space Visual Analytics with Time Fusion Transformer and Variational Autoencoders in Power Grid Event Diagnosis**
2412.16098v1 by Haowen Xu, Ali Boyaci, Jianming Lian, Aaron Wilson

Detecting and analyzing complex patterns in multivariate time-series data is
crucial for decision-making in urban and environmental system operations.
However, challenges arise from the high dimensionality, intricate complexity,
and interconnected nature of complex patterns, which hinder the understanding
of their underlying physical processes. Existing AI methods often face
limitations in interpretability, computational efficiency, and scalability,
reducing their applicability in real-world scenarios. This paper proposes a
novel visual analytics framework that integrates two generative AI models, Time
Fusion Transformer (TFT) and Variational Autoencoders (VAEs), to reduce complex
patterns into lower-dimensional latent spaces and visualize them in 2D using
dimensionality reduction techniques such as PCA, t-SNE, and UMAP with DBSCAN.
These visualizations, presented through coordinated and interactive views and
tailored glyphs, enable intuitive exploration of complex multivariate temporal
patterns, identifying patterns' similarities and uncover their potential
correlations for a better interpretability of the AI outputs. The framework is
demonstrated through a case study on power grid signal data, where it
identifies multi-label grid event signatures, including faults and anomalies
with diverse root causes. Additionally, novel metrics and visualizations are
introduced to validate the models and evaluate the performance, efficiency, and
consistency of latent maps generated by TFT and VAE under different
configurations. These analyses provide actionable insights for model parameter
tuning and reliability improvements. Comparative results highlight that TFT
achieves shorter run times and superior scalability to diverse time-series data
shapes compared to VAE. This work advances fault diagnosis in multivariate time
series, fostering explainable AI to support critical system operations.

摘要：<paragraph>偵測並分析多變量時序資料中的複雜模式，對於都市和環境系統操作的決策制定至關重要。然而，挑戰來自於高維度、複雜的複雜性以及複雜模式的相互關聯性，這阻礙了對其底層物理程序的理解。現有的 AI 方法經常在可解釋性、運算效率和可擴充性方面面臨限制，降低了它們在實際場景中的適用性。本文提出了一個新的視覺分析框架，整合了兩個生成式 AI 模型，時間融合Transformer (TFT) 和變分自動編碼器 (VAE)，將複雜模式簡化為低維潛在空間，並使用降維技術（例如 PCA、t-SNE 和 UMAP 與 DBSCAN）將其視覺化為 2D。這些視覺化透過協調和互動的視圖以及客製化的符號呈現，可以直觀地探索複雜的多變量時間模式，識別模式的相似性並揭示它們的潛在關聯性，以更好地解釋 AI 輸出。該框架透過電網信號資料的案例研究進行展示，其中識別了多標籤電網事件特徵，包括具有不同根本原因的故障和異常。此外，引入了新的指標和視覺化來驗證模型並評估 TFT 和 VAE 在不同配置下產生的潛在映射的效能、效率和一致性。這些分析提供了可行的見解，用於模型參數調整和可靠性改進。比較結果強調，與 VAE 相比，TFT 在執行時間較短且對各種時序資料形狀的可擴充性較高。這項工作推動了多變量時序中的故障診斷，促進可解釋的 AI 以支援關鍵系統操作。</paragraph>

##### **The Evolution of LLM Adoption in Industry Data Curation Practices**
2412.16089v1 by Crystal Qian, Michael Xieyang Liu, Emily Reif, Grady Simon, Nada Hussein, Nathan Clement, James Wexler, Carrie J. Cai, Michael Terry, Minsuk Kahng

As large language models (LLMs) grow increasingly adept at processing
unstructured text data, they offer new opportunities to enhance data curation
workflows. This paper explores the evolution of LLM adoption among
practitioners at a large technology company, evaluating the impact of LLMs in
data curation tasks through participants' perceptions, integration strategies,
and reported usage scenarios. Through a series of surveys, interviews, and user
studies, we provide a timely snapshot of how organizations are navigating a
pivotal moment in LLM evolution. In Q2 2023, we conducted a survey to assess
LLM adoption in industry for development tasks (N=84), and facilitated expert
interviews to assess evolving data needs (N=10) in Q3 2023. In Q2 2024, we
explored practitioners' current and anticipated LLM usage through a user study
involving two LLM-based prototypes (N=12). While each study addressed distinct
research goals, they revealed a broader narrative about evolving LLM usage in
aggregate. We discovered an emerging shift in data understanding from
heuristic-first, bottom-up approaches to insights-first, top-down workflows
supported by LLMs. Furthermore, to respond to a more complex data landscape,
data practitioners now supplement traditional subject-expert-created 'golden
datasets' with LLM-generated 'silver' datasets and rigorously validated 'super
golden' datasets curated by diverse experts. This research sheds light on the
transformative role of LLMs in large-scale analysis of unstructured data and
highlights opportunities for further tool development.

摘要：<paragraph>隨著大型語言模型 (LLM) 在處理非結構化文字資料方面的能力日益增進，它們為增強資料策展工作流程提供了新的機會。本文探討了 LLM 在大型科技公司實務工作者間的採用演進，透過參與者的認知、整合策略和回報的使用情境，評估 LLM 在資料策展任務中的影響。透過一系列的調查、訪談和使用者研究，我們提供了組織如何應對 LLM 演化中關鍵時刻的即時概況。在 2023 年第二季，我們進行了一項調查，以評估產業中 LLM 在開發任務中的採用（N=84），並於 2023 年第三季進行專家訪談，以評估不斷變化的資料需求（N=10）。在 2024 年第二季，我們透過一項涉及兩個基於 LLM 的原型之使用者研究，探討了實務工作者目前和預期的 LLM 使用情況（N=12）。雖然每項研究都針對不同的研究目標，但它們揭示了關於 LLM 使用演進的更廣泛敘述。我們發現資料理解從啟發式優先的由下而上方法，轉變為見解優先的由上而下工作流程，而這仰賴 LLM 的支援。此外，為了應對更複雜的資料環境，資料實務工作者現在使用 LLM 生成的「銀色」資料集，以及由不同領域專家策展並經過嚴格驗證的「超級金色」資料集，來補充傳統由主題專家建立的「黃金」資料集。本研究闡明了 LLM 在非結構化資料的大規模分析中扮演的變革性角色，並強調了進一步工具開發的機會。</paragraph>

##### **Towards Interpretable Radiology Report Generation via Concept Bottlenecks using a Multi-Agentic RAG**
2412.16086v1 by Hasan Md Tusfiqur Alam, Devansh Srivastav, Md Abdul Kadir, Daniel Sonntag

Deep learning has advanced medical image classification, but interpretability
challenges hinder its clinical adoption. This study enhances interpretability
in Chest X-ray (CXR) classification by using concept bottleneck models (CBMs)
and a multi-agent Retrieval-Augmented Generation (RAG) system for report
generation. By modeling relationships between visual features and clinical
concepts, we create interpretable concept vectors that guide a multi-agent RAG
system to generate radiology reports, enhancing clinical relevance,
explainability, and transparency. Evaluation of the generated reports using an
LLM-as-a-judge confirmed the interpretability and clinical utility of our
model's outputs. On the COVID-QU dataset, our model achieved 81% classification
accuracy and demonstrated robust report generation performance, with five key
metrics ranging between 84% and 90%. This interpretable multi-agent framework
bridges the gap between high-performance AI and the explainability required for
reliable AI-driven CXR analysis in clinical settings.

摘要：深度學習已進步了醫學影像分類，但可解釋性挑戰阻礙了其臨床採用。本研究透過使用概念瓶頸模型 (CBM) 和多重代理檢索增強生成 (RAG) 系統進行報告生成，增強了胸部 X 光 (CXR) 分類的可解釋性。透過對視覺特徵和臨床概念之間的關係進行建模，我們建立了可解釋的概念向量，用來引導多重代理 RAG 系統生成放射科報告，以增強臨床相關性、可解釋性和透明性。使用 LLM 作為判斷者對生成的報告進行評估，確認了我們模型輸出的可解釋性和臨床實用性。在 COVID-QU 資料集上，我們的模型達到了 81% 的分類準確度，並展示了強健的報告生成效能，五項關鍵指標介於 84% 到 90% 之間。這個可解釋的多重代理架構彌合了高性能 AI 與在臨床環境中進行可靠 AI 驅動 CXR 分析所需的可解釋性之間的差距。

##### **Formal Mathematical Reasoning: A New Frontier in AI**
2412.16075v1 by Kaiyu Yang, Gabriel Poesia, Jingxuan He, Wenda Li, Kristin Lauter, Swarat Chaudhuri, Dawn Song

AI for Mathematics (AI4Math) is not only intriguing intellectually but also
crucial for AI-driven discovery in science, engineering, and beyond. Extensive
efforts on AI4Math have mirrored techniques in NLP, in particular, training
large language models on carefully curated math datasets in text form. As a
complementary yet less explored avenue, formal mathematical reasoning is
grounded in formal systems such as proof assistants, which can verify the
correctness of reasoning and provide automatic feedback. In this position
paper, we advocate for formal mathematical reasoning and argue that it is
indispensable for advancing AI4Math to the next level. In recent years, we have
seen steady progress in using AI to perform formal reasoning, including core
tasks such as theorem proving and autoformalization, as well as emerging
applications such as verifiable generation of code and hardware designs.
However, significant challenges remain to be solved for AI to truly master
mathematics and achieve broader impact. We summarize existing progress, discuss
open challenges, and envision critical milestones to measure future success. At
this inflection point for formal mathematical reasoning, we call on the
research community to come together to drive transformative advancements in
this field.

摘要：數學人工智慧 (AI4Math) 不僅在智力上引人入勝，對於科學、工程等領域中的人工智慧驅動發現也至關重要。對於 AI4Math 的廣泛研究反映了自然語言處理中的技術，特別是訓練大型語言模型，使用經過仔細策展的數學資料集，以文字形式呈現。作為一種相輔相成但較少探索的途徑，形式化數學推理基於形式化系統，例如證明輔助工具，它可以驗證推理的正確性並提供自動回饋。在此立場文件中，我們提倡形式化數學推理，並論證其對於將 AI4Math 提升到下一個層級至關重要。近年來，我們看到使用人工智慧執行形式化推理的進展穩定，包括定理證明和自動形式化等核心任務，以及可驗證的程式碼和硬體設計產生等新興應用。然而，要使人工智慧真正掌握數學並發揮更廣泛的影響，仍有重要的挑戰有待解決。我們總結現有的進展，討論開放性的挑戰，並設想衡量未來成功的關鍵里程碑。在形式化數學推理的這個轉捩點，我們呼籲研究社群共同努力，推動這個領域的變革性進展。

##### **Label-Efficient Data Augmentation with Video Diffusion Models for Guidewire Segmentation in Cardiac Fluoroscopy**
2412.16050v1 by Shaoyan Pan, Yikang Liu, Lin Zhao, Eric Z. Chen, Xiao Chen, Terrence Chen, Shanhui Sun

The accurate segmentation of guidewires in interventional cardiac fluoroscopy
videos is crucial for computer-aided navigation tasks. Although deep learning
methods have demonstrated high accuracy and robustness in wire segmentation,
they require substantial annotated datasets for generalizability, underscoring
the need for extensive labeled data to enhance model performance. To address
this challenge, we propose the Segmentation-guided Frame-consistency Video
Diffusion Model (SF-VD) to generate large collections of labeled fluoroscopy
videos, augmenting the training data for wire segmentation networks. SF-VD
leverages videos with limited annotations by independently modeling scene
distribution and motion distribution. It first samples the scene distribution
by generating 2D fluoroscopy images with wires positioned according to a
specified input mask, and then samples the motion distribution by progressively
generating subsequent frames, ensuring frame-to-frame coherence through a
frame-consistency strategy. A segmentation-guided mechanism further refines the
process by adjusting wire contrast, ensuring a diverse range of visibility in
the synthesized image. Evaluation on a fluoroscopy dataset confirms the
superior quality of the generated videos and shows significant improvements in
guidewire segmentation.

摘要：介入式心脏透視影片中導引線的精確分割對於電腦輔助導航任務至關重要。儘管深度學習方法在導線分割中展現出高準確度和強健性，但它們需要大量的標註資料集才能進行概化，強調了需要廣泛的標籤資料來提升模型效能。為了應對這個挑戰，我們提出分割引導的影格一致性影片擴散模型 (SF-VD) 來產生大量的標註透視影片，擴充導線分割網路的訓練資料。SF-VD 利用有限標註的影片，透過獨立建模場景分佈和動作分佈。它首先透過根據指定的輸入遮罩產生帶有導線的 2D 透視影像來取樣場景分佈，然後透過逐步產生後續影格來取樣動作分佈，確保影格間的一致性，並透過影格一致性策略來達成。分割引導的機制進一步透過調整導線對比來改善流程，確保合成影像中能有不同的可視範圍。在透視資料集上的評估證實了所產生影片的優異品質，並顯示出導線分割的顯著改善。

##### **Applying Predictive Analytics to Occupational Health and Safety in India**
2412.16038v1 by Ritwik Raj Saxena

Predictive analytics is revolutionizing occupational health and safety (OHS).
It offers evidence-based insights. These insights enable proactive risk
management and informed, data-driven decision-making in organizational
settings. This paper explores the key components of predictive analytics in
OHS, beginning with data collection, management, and preparation, and moving
through to advanced predictive modelling techniques. We emphasize the
importance of data integrity through processes such as missing value
imputation, anomaly detection, and feature engineering to ensure accurate model
predictions. Risk prioritization identifies and ranks hazards across various
factors, including employee behaviours, organizational policies, environmental
conditions, and operational practices. We posit that insights derived from
predictive models must be effectively interpreted and implemented. These
insights guide organizations to focus on high-impact areas for accident
prevention and resource optimization. The integration of predictive analytics
in OHS brings notable benefits, including enhanced decision-making, greater
operational efficiency, cost savings, and improved compliance with safety
standards. We examine applications of predictive analytics in OHS in Indian
settings. India has the largest workforce in the world, and the predominance of
it is in the informal sector - a sector largely unprotected by the already
inadequate OHS laws. Ethical considerations, data privacy concerns, and the
risk of overdependence on predictive models are discussed. We conclude with a
discussion on the potential for predictive analytics to create a data-oriented,
adaptive approach to OHS in India. We posit that, using predictive analytics,
India can develop high safety standards while traversing the complexities of
its workforce setting.

摘要：預測分析正在革新職業健康與安全 (OHS)。
它提供基於證據的見解。這些見解能讓組織環境中的風險管理更具前瞻性，並能做出明智的、資料驅動的決策。本文探討了 OHS 中預測分析的關鍵組成部分，從資料收集、管理和準備開始，並進展到進階預測建模技術。我們強調資料完整性的重要性，透過遺失值插補、異常偵測和特徵工程等流程來確保準確的模型預測。風險優先順序會根據員工行為、組織政策、環境條件和作業慣例等各種因素來識別和排名危害。我們認為，從預測模型中得出的見解必須得到有效的詮釋和實施。這些見解引導組織專注於事故預防和資源最佳化的影響重大領域。預測分析在 OHS 中的整合帶來了顯著的優勢，包括增強決策制定、提高營運效率、節省成本和改善對安全標準的遵循。我們探討了預測分析在印度環境中 OHS 中的應用。印度擁有全球最大的勞動力，其中大部分屬於非正式部門，這個部門在很大程度上不受本已不足的 OHS 法律保護。本文討論了倫理考量、資料隱私問題和過度依賴預測模型的風險。我們最後討論了預測分析在印度創造以資料為導向、適應性強的 OHS 方法的潛力。我們認為，透過使用預測分析，印度可以在其勞動力環境的複雜性中發展出高安全標準。

##### **A Framework for Streaming Event-Log Prediction in Business Processes**
2412.16032v1 by Benedikt Bollig, Matthias Függer, Thomas Nowak

We present a Python-based framework for event-log prediction in streaming
mode, enabling predictions while data is being generated by a business process.
The framework allows for easy integration of streaming algorithms, including
language models like n-grams and LSTMs, and for combining these predictors
using ensemble methods.
  Using our framework, we conducted experiments on various well-known
process-mining data sets and compared classical batch with streaming mode.
Though, in batch mode, LSTMs generally achieve the best performance, there is
often an n-gram whose accuracy comes very close. Combining basic models in
ensemble methods can even outperform LSTMs. The value of basic models with
respect to LSTMs becomes even more apparent in streaming mode, where LSTMs
generally lack accuracy in the early stages of a prediction run, while basic
methods make sensible predictions immediately.

摘要：我們提出一個基於 Python 的架構，用於串流模式中的事件記錄預測，並在商業流程產生資料時進行預測。
此架構允許輕鬆整合串流演算法，包括語言模型（例如 n-grams 和 LSTM），並使用整體方法結合這些預測器。
使用我們的架構，我們對各種著名的流程探勘資料集進行了實驗，並比較了傳統批次處理模式和串流模式。
儘管在批次處理模式中，LSTM 通常能達到最佳效能，但通常有 n-gram 的準確度非常接近。在整體方法中結合基本模型甚至可以優於 LSTM。在串流模式中，基本模型相對於 LSTM 的價值變得更加明顯，在預測執行的早期階段，LSTM 通常缺乏準確度，而基本方法會立即做出明智的預測。

##### **The Only Way is Ethics: A Guide to Ethical Research with Large Language Models**
2412.16022v1 by Eddie L. Ungless, Nikolas Vitsakis, Zeerak Talat, James Garforth, Björn Ross, Arno Onken, Atoosa Kasirzadeh, Alexandra Birch

There is a significant body of work looking at the ethical considerations of
large language models (LLMs): critiquing tools to measure performance and
harms; proposing toolkits to aid in ideation; discussing the risks to workers;
considering legislation around privacy and security etc. As yet there is no
work that integrates these resources into a single practical guide that focuses
on LLMs; we attempt this ambitious goal. We introduce 'LLM Ethics Whitepaper',
which we provide as an open and living resource for NLP practitioners, and
those tasked with evaluating the ethical implications of others' work. Our goal
is to translate ethics literature into concrete recommendations and
provocations for thinking with clear first steps, aimed at computer scientists.
'LLM Ethics Whitepaper' distils a thorough literature review into clear Do's
and Don'ts, which we present also in this paper. We likewise identify useful
toolkits to support ethical work. We refer the interested reader to the full
LLM Ethics Whitepaper, which provides a succinct discussion of ethical
considerations at each stage in a project lifecycle, as well as citations for
the hundreds of papers from which we drew our recommendations. The present
paper can be thought of as a pocket guide to conducting ethical research with
LLMs.

摘要：有大量研究探討大型語言模型 (LLM) 的道德考量：批判用於衡量效能和危害的工具；提出有助於發想點子的工具組；討論對工作者的風險；考量與隱私和安全相關的法規等。目前尚未有將這些資源整合到單一實用指南中的研究，而我們嘗試達成這個雄心勃勃的目標。我們推出「LLM 倫理白皮書」，我們將其提供給 NLP 從業人員和負責評估他人工作中倫理意涵的人員，作為開放且活的資源。我們的目標是將倫理文獻轉化為具體的建議和思考的挑釁，並針對電腦科學家提出明確的第一步。LLM 倫理白皮書將徹底的文獻回顧提煉成明確的應為和不應為，我們也會在本文中呈現。我們同樣找出有助於倫理工作的有用工具組。我們請有興趣的讀者參閱完整的 LLM 倫理白皮書，其中簡潔地討論專案生命週期中每個階段的倫理考量，以及我們從中汲取建議的數百篇論文的引文。本文可被視為使用 LLM 進行倫理研究的口袋指南。

##### **Choose Your Explanation: A Comparison of SHAP and GradCAM in Human Activity Recognition**
2412.16003v1 by Felix Tempel, Daniel Groos, Espen Alexander F. Ihlen, Lars Adde, Inga Strümke

Explaining machine learning (ML) models using eXplainable AI (XAI) techniques
has become essential to make them more transparent and trustworthy. This is
especially important in high-stakes domains like healthcare, where
understanding model decisions is critical to ensure ethical, sound, and
trustworthy outcome predictions. However, users are often confused about which
explanability method to choose for their specific use case. We present a
comparative analysis of widely used explainability methods, Shapley Additive
Explanations (SHAP) and Gradient-weighted Class Activation Mapping (GradCAM),
within the domain of human activity recognition (HAR) utilizing graph
convolutional networks (GCNs). By evaluating these methods on skeleton-based
data from two real-world datasets, including a healthcare-critical cerebral
palsy (CP) case, this study provides vital insights into both approaches'
strengths, limitations, and differences, offering a roadmap for selecting the
most appropriate explanation method based on specific models and applications.
We quantitatively and quantitatively compare these methods, focusing on feature
importance ranking, interpretability, and model sensitivity through
perturbation experiments. While SHAP provides detailed input feature
attribution, GradCAM delivers faster, spatially oriented explanations, making
both methods complementary depending on the application's requirements. Given
the importance of XAI in enhancing trust and transparency in ML models,
particularly in sensitive environments like healthcare, our research
demonstrates how SHAP and GradCAM could complement each other to provide more
interpretable and actionable model explanations.

摘要：<paragraph>使用可解釋 AI (XAI) 技術說明機器學習 (ML) 模型已成為讓模型更透明和值得信賴的必要條件。這在醫療保健等高風險領域中特別重要，其中理解模型決策對於確保道德、健全和值得信賴的結果預測至關重要。然而，使用者常常對於針對其特定使用案例選擇哪種可解釋性方法感到困惑。我們提出對廣泛使用的可解釋性方法、Shapley 可加性解釋 (SHAP) 和梯度加權類別激活映射 (GradCAM) 進行比較分析，在人類活動識別 (HAR) 領域內利用圖形卷積網路 (GCN)。透過在兩個真實世界資料集中的基於骨架的資料上評估這些方法，包括醫療保健至關重要的腦性麻痺 (CP) 案例，本研究提供了對兩種方法的優點、限制和差異的重要見解，提供了一個根據特定模型和應用程式選擇最合適的解釋方法的路線圖。我們定量和定性地比較這些方法，重點關注特徵重要性排名、可解釋性和透過擾動實驗進行的模型敏感度。雖然 SHAP 提供了詳細的輸入特徵歸因，但 GradCAM 提供了更快速、更具空間導向的解釋，這使得兩種方法根據應用程式的需求互補。鑑於 XAI 在增強 ML 模型中信任和透明度的重要性，特別是在醫療保健等敏感環境中，我們的研究展示了 SHAP 和 GradCAM 如何相互補充以提供更具可解釋性和可操作性的模型解釋。</paragraph>

##### **CNN-LSTM Hybrid Deep Learning Model for Remaining Useful Life Estimation**
2412.15998v1 by Muthukumar G, Jyosna Philip

Remaining Useful Life (RUL) of a component or a system is defined as the
length from the current time to the end of the useful life. Accurate RUL
estimation plays a crucial role in Predictive Maintenance applications.
Traditional regression methods, both linear and non-linear, have struggled to
achieve high accuracy in this domain. While Convolutional Neural Networks
(CNNs) have shown improved accuracy, they often overlook the sequential nature
of the data, relying instead on features derived from sliding windows. Since
RUL prediction inherently involves multivariate time series analysis, robust
sequence learning is essential. In this work, we propose a hybrid approach
combining Convolutional Neural Networks with Long Short-Term Memory (LSTM)
networks for RUL estimation. Although CNN-based LSTM models have been applied
to sequence prediction tasks in financial forecasting, this is the first
attempt to adopt this approach for RUL estimation in prognostics. In this
approach, CNN is first employed to efficiently extract features from the data,
followed by LSTM, which uses these extracted features to predict RUL. This
method effectively leverages sensor sequence information, uncovering hidden
patterns within the data, even under multiple operating conditions and fault
scenarios. Our results demonstrate that the hybrid CNN-LSTM model achieves the
highest accuracy, offering a superior score compared to the other methods.

摘要：剩餘使用壽命 (RUL) 是指組件或系統從當前時間到使用壽命結束的時間長度。準確的 RUL 估計在預測性維護應用中扮演著至關重要的角色。傳統的迴歸方法，包括線性和非線性方法，在這個領域中難以達到高準確度。卷積神經網路 (CNN) 雖然顯示出更高的準確度，但它們常常忽略資料的順序特性，而是依賴於從滑動視窗衍生的特徵。由於 RUL 預測本質上涉及多變量時間序列分析，因此穩健的序列學習至關重要。在這項工作中，我們提出了一種混合方法，將卷積神經網路與長短期記憶 (LSTM) 網路結合起來，用於 RUL 估計。雖然基於 CNN 的 LSTM 模型已應用於財務預測中的序列預測任務，但這是首次嘗試採用這種方法來進行預測中的 RUL 估計。在此方法中，首先使用 CNN 從資料中有效提取特徵，然後使用 LSTM，它使用這些提取的特徵來預測 RUL。此方法有效地利用感測器序列資訊，揭示資料中的隱藏模式，即使在多種操作條件和故障情況下也是如此。我們的結果表明，混合 CNN-LSTM 模型達到了最高的準確度，與其他方法相比，提供了更高的分數。

##### **Data-Centric Improvements for Enhancing Multi-Modal Understanding in Spoken Conversation Modeling**
2412.15995v1 by Maximillian Chen, Ruoxi Sun, Sercan Ö. Arık

Conversational assistants are increasingly popular across diverse real-world
applications, highlighting the need for advanced multimodal speech modeling.
Speech, as a natural mode of communication, encodes rich user-specific
characteristics such as speaking rate and pitch, making it critical for
effective interaction. Our work introduces a data-centric customization
approach for efficiently enhancing multimodal understanding in conversational
speech modeling. Central to our contributions is a novel multi-task learning
paradigm that involves designing auxiliary tasks to utilize a small amount of
speech data. Our approach achieves state-of-the-art performance on the
Spoken-SQuAD benchmark, using only 10% of the training data with open-weight
models, establishing a robust and efficient framework for audio-centric
conversational modeling. We also introduce ASK-QA, the first dataset for
multi-turn spoken dialogue with ambiguous user requests and dynamic evaluation
inputs. Code and data forthcoming.

摘要：對話式助理在各種真實世界應用中越來越受歡迎，突顯了對進階多模態語音建模的需求。
語音作為一種自然的溝通模式，編碼了使用者特有的豐富特徵，例如說話速度和音高，使其對於有效互動至關重要。
我們的研究引入了一種以資料為中心的客製化方法，以有效增強對話式語音建模中的多模態理解。
我們貢獻的核心是一個新穎的多任務學習範例，其中涉及設計輔助任務，以利用少量的語音資料。
我們的做法在 Spoken-SQuAD 基準上達到了最先進的效能，僅使用 10% 的訓練資料和開放權重模型，建立了一個強大且有效的以音訊為中心的對話式建模架構。
我們還推出了 ASK-QA，這是第一個針對多回合口語對話的資料集，其中包含模稜兩可的使用者要求和動態評估輸入。
程式碼和資料即將推出。

##### **Fearful Falcons and Angry Llamas: Emotion Category Annotations of Arguments by Humans and LLMs**
2412.15993v1 by Lynn Greschner, Roman Klinger

Arguments evoke emotions, influencing the effect of the argument itself. Not
only the emotional intensity but also the category influence the argument's
effects, for instance, the willingness to adapt stances. While binary
emotionality has been studied in arguments, there is no work on discrete
emotion categories (e.g., "Anger") in such data. To fill this gap, we
crowdsource subjective annotations of emotion categories in a German argument
corpus and evaluate automatic LLM-based labeling methods. Specifically, we
compare three prompting strategies (zero-shot, one-shot, chain-of-thought) on
three large instruction-tuned language models (Falcon-7b-instruct,
Llama-3.1-8B-instruct, GPT-4o-mini). We further vary the definition of the
output space to be binary (is there emotionality in the argument?),
closed-domain (which emotion from a given label set is in the argument?), or
open-domain (which emotion is in the argument?). We find that emotion
categories enhance the prediction of emotionality in arguments, emphasizing the
need for discrete emotion annotations in arguments. Across all prompt settings
and models, automatic predictions show a high recall but low precision for
predicting anger and fear, indicating a strong bias toward negative emotions.

摘要：論點會引發情緒，影響論點本身的效果。不僅情緒強度，類別也會影響論點的效果，例如調整立場的意願。雖然二元情緒性已經在論點中被研究過，但沒有關於此類數據中離散情緒類別（例如「憤怒」）的研究。為了填補這個空白，我們在德語論點語料庫中眾包了情緒類別的主觀註釋，並評估了基於自動 LLM 的標籤方法。具體來說，我們比較了三種提示策略（零次學習、一次學習、思考鏈）在三個經過大量指令微調的語言模型（Falcon-7b-instruct、Llama-3.1-8B-instruct、GPT-4o-mini）上。我們進一步改變了輸出空間的定義，使其為二元（論點中是否存在情緒性？）、封閉域（論點中存在給定標籤集中的哪種情緒？）、或開放域（論點中存在哪種情緒？）。我們發現情緒類別增強了對論點中情緒性的預測，強調了在論點中進行離散情緒註釋的必要性。在所有提示設定和模型中，自動預測顯示出高召回率但低準確度，用於預測憤怒和恐懼，這表明對負面情緒有很強的偏見。

##### **BabyHGRN: Exploring RNNs for Sample-Efficient Training of Language Models**
2412.15978v1 by Patrick Haller, Jonas Golde, Alan Akbik

This paper explores the potential of recurrent neural networks (RNNs) and
other subquadratic architectures as competitive alternatives to
transformer-based models in low-resource language modeling scenarios. We
utilize HGRN2 (Qin et al., 2024), a recently proposed RNN-based architecture,
and comparatively evaluate its effectiveness against transformer-based
baselines and other subquadratic architectures (LSTM, xLSTM, Mamba). Our
experimental results show that BABYHGRN, our HGRN2 language model, outperforms
transformer-based models in both the 10M and 100M word tracks of the challenge,
as measured by their performance on the BLiMP, EWoK, GLUE and BEAR benchmarks.
Further, we show the positive impact of knowledge distillation. Our findings
challenge the prevailing focus on transformer architectures and indicate the
viability of RNN-based models, particularly in resource-constrained
environments.

摘要：這篇論文探討了遞迴神經網路 (RNN) 和其他次二次架構作為低資源語言建模場景中基於Transformer的模型的競爭替代方案的潛力。我們利用 HGRN2 (Qin et al., 2024)，一種最近提出的基於 RNN 的架構，並比較評估其對基於Transformer的基線和其他次二次架構 (LSTM、xLSTM、Mamba) 的有效性。我們的實驗結果表明，我們的 HGRN2 語言模型 BABYHGRN 在挑戰的 10M 和 100M 字詞軌道中都優於基於Transformer的模型，如其在 BLiMP、EWoK、GLUE 和 BEAR 基準上的效能所測量。此外，我們展示了知識萃取的正面影響。我們的發現挑戰了對Transformer架構的普遍關注，並表明基於 RNN 的模型的可行性，特別是在資源受限的環境中。

##### **Self-Supervised Radiograph Anatomical Region Classification -- How Clean Is Your Real-World Data?**
2412.15967v1 by Simon Langer, Jessica Ritter, Rickmer Braren, Daniel Rueckert, Paul Hager

Modern deep learning-based clinical imaging workflows rely on accurate labels
of the examined anatomical region. Knowing the anatomical region is required to
select applicable downstream models and to effectively generate cohorts of high
quality data for future medical and machine learning research efforts. However,
this information may not be available in externally sourced data or generally
contain data entry errors. To address this problem, we show the effectiveness
of self-supervised methods such as SimCLR and BYOL as well as supervised
contrastive deep learning methods in assigning one of 14 anatomical region
classes in our in-house dataset of 48,434 skeletal radiographs. We achieve a
strong linear evaluation accuracy of 96.6% with a single model and 97.7% using
an ensemble approach. Furthermore, only a few labeled instances (1% of the
training set) suffice to achieve an accuracy of 92.2%, enabling usage in
low-label and thus low-resource scenarios. Our model can be used to correct
data entry mistakes: a follow-up analysis of the test set errors of our
best-performing single model by an expert radiologist identified 35% incorrect
labels and 11% out-of-domain images. When accounted for, the radiograph
anatomical region labelling performance increased -- without and with an
ensemble, respectively -- to a theoretical accuracy of 98.0% and 98.8%.

摘要：現代的深度學習臨床影像工作流程依賴於檢查解剖區域的準確標籤。了解解剖區域是必要的，用於選擇適用的下游模型，並有效地為未來的醫療和機器學習研究工作生成高品質資料群組。然而，此資訊可能無法在外部來源的資料中取得，或通常包含資料輸入錯誤。為了解決這個問題，我們展示了自監督方法（例如 SimCLR 和 BYOL）以及監督對比深度學習方法在我們內部 48,434 張骨骼 X 光片的資料集中分配 14 個解剖區域類別之一的有效性。我們使用單一模型達到了 96.6% 的強線性評估準確度，並使用整體方法達到了 97.7%。此外，僅有少數標記實例（訓練組的 1%）就足以達到 92.2% 的準確度，這使得在標籤少且資源少的情況下使用成為可能。我們的模型可用於更正資料輸入錯誤：由專業放射科醫師對我們效能最佳的單一模型的測試組錯誤進行後續分析，識別出 35% 的錯誤標籤和 11% 的領域外影像。在考慮到的情況下，X 光片解剖區域標籤效能提高了（分別在沒有和有整體的情況下）達到 98.0% 和 98.8% 的理論準確度。

##### **From General to Specific: Tailoring Large Language Models for Personalized Healthcare**
2412.15957v1 by Ruize Shi, Hong Huang, Wei Zhou, Kehan Yin, Kai Zhao, Yun Zhao

The rapid development of large language models (LLMs) has transformed many
industries, including healthcare. However, previous medical LLMs have largely
focused on leveraging general medical knowledge to provide responses, without
accounting for patient variability and lacking true personalization at the
individual level. To address this, we propose a novel method called
personalized medical language model (PMLM), which explores and optimizes
personalized LLMs through recommendation systems and reinforcement learning
(RL). Specifically, by utilizing self-informed and peer-informed
personalization, PMLM captures changes in behaviors and preferences to design
initial personalized prompts tailored to individual needs. We further refine
these initial personalized prompts through RL, ultimately enhancing the
precision of LLM guidance. Notably, the personalized prompt are hard prompt,
which grants PMLM high adaptability and reusability, allowing it to directly
leverage high-quality proprietary LLMs. We evaluate PMLM using real-world
obstetrics and gynecology data, and the experimental results demonstrate that
PMLM achieves personalized responses, and it provides more refined and
individualized services, offering a potential way for personalized medical
LLMs.

摘要：大型語言模型 (LLM) 的快速發展已轉變許多產業，包括醫療保健。然而，先前的醫療 LLM 主要專注於利用一般醫療知識提供回應，並未考量病患的變異性，且缺乏個人層級的真正個人化。為了解決此問題，我們提出了一種稱為個人化醫療語言模型 (PMLM) 的新方法，透過推薦系統和強化學習 (RL) 來探索和最佳化個人化的 LLM。具體來說，PMLM 透過利用自我知情和同儕知情的個人化，擷取行為和偏好的變化，以設計符合個人需求的初始個人化提示。我們進一步透過 RL 調整這些初始個人化提示，最終提升 LLM 指導的精確度。值得注意的是，個人化提示是硬提示，這賦予 PMLM 高度的適應性和可重複使用性，使其能夠直接利用高品質的專有 LLM。我們使用真實世界的產科和婦科資料評估 PMLM，實驗結果顯示 PMLM 達到了個人化的回應，並提供了更精緻和個人化的服務，為個人化的醫療 LLM 提供了一種潛在的方法。

##### **Trust Calibration in IDEs: Paving the Way for Widespread Adoption of AI Refactoring**
2412.15948v1 by Markus Borg

In the software industry, the drive to add new features often overshadows the
need to improve existing code. Large Language Models (LLMs) offer a new
approach to improving codebases at an unprecedented scale through AI-assisted
refactoring. However, LLMs come with inherent risks such as braking changes and
the introduction of security vulnerabilities. We advocate for encapsulating the
interaction with the models in IDEs and validating refactoring attempts using
trustworthy safeguards. However, equally important for the uptake of AI
refactoring is research on trust development. In this position paper, we
position our future work based on established models from research on human
factors in automation. We outline action research within CodeScene on
development of 1) novel LLM safeguards and 2) user interaction that conveys an
appropriate level of trust. The industry collaboration enables large-scale
repository analysis and A/B testing to continuously guide the design of our
research interventions.

摘要：在軟體產業中，新增功能的驅動力通常會蓋過改善現有程式碼的需求。大型語言模型 (LLM) 提供一種新的方法，透過 AI 輔助重構，以前所未有的規模改善程式碼庫。然而，LLM 伴隨著固有的風險，例如中斷變更和引入安全性漏洞。我們提倡將與模型的互動封裝在 IDE 中，並使用可信賴的防護措施驗證重構嘗試。然而，對於 AI 重構的採用而言，同樣重要的是對信任發展的研究。在這個立場文件中，我們根據自動化中人為因素研究中的既定模型，定位我們的未來工作。我們概述了 CodeScene 中的行動研究，關於 1) 新穎的 LLM 防護措施的開發和 2) 傳達適當信任層級的使用者互動。產業合作能進行大規模儲存庫分析和 A/B 測試，以持續引導我們研究介入的設計。

##### **Reframing Image Difference Captioning with BLIP2IDC and Synthetic Augmentation**
2412.15939v1 by Gautier Evennou, Antoine Chaffin, Vivien Chappelier, Ewa Kijak

The rise of the generative models quality during the past years enabled the
generation of edited variations of images at an important scale. To counter the
harmful effects of such technology, the Image Difference Captioning (IDC) task
aims to describe the differences between two images. While this task is
successfully handled for simple 3D rendered images, it struggles on real-world
images. The reason is twofold: the training data-scarcity, and the difficulty
to capture fine-grained differences between complex images. To address those
issues, we propose in this paper a simple yet effective framework to both adapt
existing image captioning models to the IDC task and augment IDC datasets. We
introduce BLIP2IDC, an adaptation of BLIP2 to the IDC task at low computational
cost, and show it outperforms two-streams approaches by a significant margin on
real-world IDC datasets. We also propose to use synthetic augmentation to
improve the performance of IDC models in an agnostic fashion. We show that our
synthetic augmentation strategy provides high quality data, leading to a
challenging new dataset well-suited for IDC named Syned1.

摘要：在過去幾年中，生成式模型品質的提升促成了大量編輯過後的影像變體產生。為了對抗這種技術的有害影響，影像差異標題（IDC）任務旨在描述兩張影像之間的差異。雖然這個任務對於簡單的 3D 渲染影像處理得很好，但它在真實世界的影像上卻有困難。原因有兩個：訓練資料的稀少性，以及難以捕捉複雜影像之間的細微差異。為了解決這些問題，我們在這篇論文中提出了一個簡單但有效的架構，既能將現有的影像標題模型調整到 IDC 任務，又能擴充 IDC 資料集。我們引入了 BLIP2IDC，這是 BLIP2 在低計算成本下調整到 IDC 任務的結果，並展示它在真實世界的 IDC 資料集上以顯著的幅度優於雙串流方法。我們還建議使用合成擴充以不可知的方式來提升 IDC 模型的效能。我們展示出我們的合成擴充策略提供了高品質的資料，造就了一個非常適合 IDC 的具有挑戰性的新資料集，名為 Syned1。

##### **Watertox: The Art of Simplicity in Universal Attacks A Cross-Model Framework for Robust Adversarial Generation**
2412.15924v1 by Zhenghao Gao, Shengjie Xu, Meixi Chen, Fangyao Zhao

Contemporary adversarial attack methods face significant limitations in
cross-model transferability and practical applicability. We present Watertox,
an elegant adversarial attack framework achieving remarkable effectiveness
through architectural diversity and precision-controlled perturbations. Our
two-stage Fast Gradient Sign Method combines uniform baseline perturbations
($\epsilon_1 = 0.1$) with targeted enhancements ($\epsilon_2 = 0.4$). The
framework leverages an ensemble of complementary architectures, from VGG to
ConvNeXt, synthesizing diverse perspectives through an innovative voting
mechanism. Against state-of-the-art architectures, Watertox reduces model
accuracy from 70.6% to 16.0%, with zero-shot attacks achieving up to 98.8%
accuracy reduction against unseen architectures. These results establish
Watertox as a significant advancement in adversarial methodologies, with
promising applications in visual security systems and CAPTCHA generation.

摘要：當代對抗攻擊方法在跨模型可傳輸性和實際應用性方面面臨重大限制。我們提出 Watertox，一種優雅的對抗攻擊框架，通過架構多樣性和精確控制的擾動實現顯著的有效性。我們的兩階段快速梯度符號方法結合了統一基準擾動（\(\epsilon_1 = 0.1\)) 和目標增強（\(\epsilon_2 = 0.4\))。該框架利用了從 VGG 到 ConvNeXt 的互補架構集合，通過創新的投票機制綜合了不同的觀點。針對最先進的架構，Watertox 將模型準確率從 70.6% 降低到 16.0%，零次攻擊對未見架構實現高達 98.8% 的準確率降低。這些結果確立了 Watertox 在對抗方法學中的重大進步，在視覺安全系統和 CAPTCHA 生成中具有廣闊的應用前景。

##### **Less is More: Towards Green Code Large Language Models via Unified Structural Pruning**
2412.15921v1 by Guang Yang, Yu Zhou, Xiangyu Zhang, Wei Cheng, Ke Liu, Xiang Chen, Terry Yue Zhuo, Taolue Chen

The extensive application of Large Language Models (LLMs) in generative
coding tasks has raised concerns due to their high computational demands and
energy consumption. Unlike previous structural pruning methods designed for
classification models that deal with lowdimensional classification logits,
generative Code LLMs produce high-dimensional token logit sequences, making
traditional pruning objectives inherently limited. Moreover, existing single
component pruning approaches further constrain the effectiveness when applied
to generative Code LLMs. In response, we propose Flab-Pruner, an innovative
unified structural pruning method that combines vocabulary, layer, and
Feed-Forward Network (FFN) pruning. This approach effectively reduces model
parameters while maintaining performance. Additionally, we introduce a
customized code instruction data strategy for coding tasks to enhance the
performance recovery efficiency of the pruned model. Through extensive
evaluations on three state-of-the-art Code LLMs across multiple generative
coding tasks, the results demonstrate that Flab-Pruner retains 97% of the
original performance after pruning 22% of the parameters and achieves the same
or even better performance after post-training. The pruned models exhibit
significant improvements in storage, GPU usage, computational efficiency, and
environmental impact, while maintaining well robustness. Our research provides
a sustainable solution for green software engineering and promotes the
efficient deployment of LLMs in real-world generative coding intelligence
applications.

摘要：大型語言模型 (LLM) 在生成式編碼任務中的廣泛應用引起了人們的關注，因為它們的高計算需求和能源消耗。與為處理低維分類邏輯而設計的先前結構修剪方法不同，生成式程式碼 LLM 會產生高維的權杖邏輯序列，使得傳統的修剪目標本質上受到限制。此外，現有的單元件修剪方法在應用於生成式程式碼 LLM 時進一步限制了其有效性。為了解決這個問題，我們提出了 Flab-Pruner，一種創新的統一結構修剪方法，結合詞彙、層和前饋網路 (FFN) 修剪。這種方法有效地減少了模型參數，同時保持了性能。此外，我們為編碼任務引入了一種自訂的程式碼指令資料策略，以提高修剪模型的效能恢復效率。透過對三個最先進的程式碼 LLM 在多個生成式編碼任務上進行廣泛評估，結果表明 Flab-Pruner 在修剪 22% 的參數後仍保留了 97% 的原始效能，並在後訓練後達到了相同甚至更好的效能。修剪後的模型在儲存、GPU 使用率、計算效率和環境影響方面表現出顯著的改進，同時保持了良好的穩健性。我們的研究為綠色軟體工程提供了一個永續的解決方案，並促進了 LLM 在真實世界的生成式編碼智慧應用中的高效部署。

##### **Development of a Large-scale Dataset of Chest Computed Tomography Reports in Japanese and a High-performance Finding Classification Model**
2412.15907v1 by Yosuke Yamagishi, Yuta Nakamura, Tomohiro Kikuchi, Yuki Sonoda, Hiroshi Hirakawa, Shintaro Kano, Satoshi Nakamura, Shouhei Hanaoka, Takeharu Yoshikawa, Osamu Abe

Background: Recent advances in large language models highlight the need for
high-quality multilingual medical datasets. While Japan leads globally in CT
scanner deployment and utilization, the lack of large-scale Japanese radiology
datasets has hindered the development of specialized language models for
medical imaging analysis. Objective: To develop a comprehensive Japanese CT
report dataset through machine translation and establish a specialized language
model for structured finding classification. Additionally, to create a
rigorously validated evaluation dataset through expert radiologist review.
Methods: We translated the CT-RATE dataset (24,283 CT reports from 21,304
patients) into Japanese using GPT-4o mini. The training dataset consisted of
22,778 machine-translated reports, while the validation dataset included 150
radiologist-revised reports. We developed CT-BERT-JPN based on
"tohoku-nlp/bert-base-japanese-v3" architecture for extracting 18 structured
findings from Japanese radiology reports. Results: Translation metrics showed
strong performance with BLEU scores of 0.731 and 0.690, and ROUGE scores
ranging from 0.770 to 0.876 for Findings and from 0.748 to 0.857 for Impression
sections. CT-BERT-JPN demonstrated superior performance compared to GPT-4o in
11 out of 18 conditions, including lymphadenopathy (+14.2%), interlobular
septal thickening (+10.9%), and atelectasis (+7.4%). The model maintained F1
scores exceeding 0.95 in 14 out of 18 conditions and achieved perfect scores in
four conditions. Conclusions: Our study establishes a robust Japanese CT report
dataset and demonstrates the effectiveness of a specialized language model for
structured finding classification. The hybrid approach of machine translation
and expert validation enables the creation of large-scale medical datasets
while maintaining high quality.

摘要：背景：大型語言模型的最新進展凸顯了對高品質多語言醫療資料集的需求。日本在 CT 掃描儀的部署和使用方面處於全球領先地位，但缺乏大規模的日語放射科資料集阻礙了針對醫學影像分析的專門語言模型的開發。目標：透過機器翻譯開發一個全面的日語 CT 報告資料集，並建立一個專門的語言模型，用於結構化結果分類。此外，透過專家放射科醫師的審查，建立一個嚴格驗證的評估資料集。方法：我們使用 GPT-4o mini 將 CT-RATE 資料集（來自 21,304 名患者的 24,283 份 CT 報告）翻譯成日語。訓練資料集包含 22,778 份機器翻譯報告，而驗證資料集包含 150 份放射科醫師修改過的報告。我們基於「tohoku-nlp/bert-base-japanese-v3」架構開發了 CT-BERT-JPN，用於從日語放射科報告中提取 18 項結構化結果。結果：翻譯指標顯示強勁的表現，BLEU 分數為 0.731 和 0.690，而 ROUGE 分數從結果的 0.770 到 0.876，從印象部分的 0.748 到 0.857 不等。與 GPT-4o 相比，CT-BERT-JPN 在 18 種情況中的 11 種情況下表現出優異的表現，包括淋巴腺病變（+14.2%）、小葉間隔增厚（+10.9%）和肺不張（+7.4%）。該模型在 18 種情況中的 14 種情況下維持 F1 分數超過 0.95，並在四種情況下達到完美分數。結論：我們的研究建立了一個強大的日語 CT 報告資料集，並展示了一個專門的語言模型在結構化結果分類方面的有效性。機器翻譯和專家驗證的混合方法能夠建立大規模的醫療資料集，同時保持高品質。

##### **What Are Step-Level Reward Models Rewarding? Counterintuitive Findings from MCTS-Boosted Mathematical Reasoning**
2412.15904v1 by Yiran Ma, Zui Chen, Tianqiao Liu, Mi Tian, Zhuo Liu, Zitao Liu, Weiqi Luo

Step-level reward models (SRMs) can significantly enhance mathematical
reasoning performance through process supervision or step-level preference
alignment based on reinforcement learning. The performance of SRMs is pivotal,
as they serve as critical guidelines, ensuring that each step in the reasoning
process is aligned with desired outcomes. Recently, AlphaZero-like methods,
where Monte Carlo Tree Search (MCTS) is employed for automatic step-level
preference annotation, have proven particularly effective. However, the precise
mechanisms behind the success of SRMs remain largely unexplored. To address
this gap, this study delves into the counterintuitive aspects of SRMs,
particularly focusing on MCTS-based approaches. Our findings reveal that the
removal of natural language descriptions of thought processes has minimal
impact on the efficacy of SRMs. Furthermore, we demonstrate that SRMs are adept
at assessing the complex logical coherence present in mathematical language
while having difficulty in natural language. These insights provide a nuanced
understanding of the core elements that drive effective step-level reward
modeling in mathematical reasoning. By shedding light on these mechanisms, this
study offers valuable guidance for developing more efficient and streamlined
SRMs, which can be achieved by focusing on the crucial parts of mathematical
reasoning.

摘要：分步獎勵模型 (SRM) 可透過過程監督或基於強化學習的分步偏好調整，顯著提升數學推理效能。SRM 的效能至關重要，因為它們作為關鍵指南，確保推理過程中每一步都與預期結果一致。近來，採用蒙地卡羅樹狀搜尋 (MCTS) 進行自動分步偏好註解的 AlphaZero 類似方法已證明特別有效。然而，SRM 成功背後確切的機制在很大程度上仍未探討。為了解決這個差距，本研究深入探討 SRM 的反直覺面向，特別關注基於 MCTS 的方法。我們的研究結果顯示，移除自然語言對思考過程的描述，對 SRM 的效能影響甚微。此外，我們證明 SRM 能夠評估數學語言中存在的複雜邏輯一致性，但處理自然語言時則有困難。這些見解提供了對驅動數學推理中有效分步獎勵建模的核心元素的細緻理解。透過闡明這些機制，本研究為開發更有效率且簡化的 SRM 提供有價值的指導，而這可透過專注於數學推理的關鍵部分來達成。

##### **On the Suitability of pre-trained foundational LLMs for Analysis in German Legal Education**
2412.15902v1 by Lorenz Wendlinger, Christian Braun, Abdullah Al Zubaer, Simon Alexander Nonn, Sarah Großkopf, Christofer Fellicious, Michael Granitzer

We show that current open-source foundational LLMs possess instruction
capability and German legal background knowledge that is sufficient for some
legal analysis in an educational context. However, model capability breaks down
in very specific tasks, such as the classification of "Gutachtenstil" appraisal
style components, or with complex contexts, such as complete legal opinions.
Even with extended context and effective prompting strategies, they cannot
match the Bag-of-Words baseline. To combat this, we introduce a Retrieval
Augmented Generation based prompt example selection method that substantially
improves predictions in high data availability scenarios. We further evaluate
the performance of pre-trained LLMs on two standard tasks for argument mining
and automated essay scoring and find it to be more adequate. Throughout,
pre-trained LLMs improve upon the baseline in scenarios with little or no
labeled data with Chain-of-Thought prompting further helping in the zero-shot
case.

摘要：我們展示當前開源基礎 LLM 擁有教學能力和足夠的德國法律背景知識，足以進行教育背景下的一些法律分析。然而，模型能力會在非常具體的任務中崩潰，例如「Gutachtenstil」評估風格組成的分類，或在複雜的背景下，例如完整的法律意見。即使在擴展的背景和有效的提示策略下，它們也無法與詞袋基準相匹配。為了解決這個問題，我們引入了一個基於檢索增強生成提示範例選擇方法，該方法在高資料可用性場景中大幅改進了預測。我們進一步評估了預先訓練的 LLM 在論證挖掘和自動化論文評分的兩個標準任務上的表現，並發現它更為適當。始終，預先訓練的 LLM 在資料標記少或沒有資料標記的場景中改進了基準，而思考鏈提示進一步幫助了零次學習的情況。

##### **A Thorough Investigation into the Application of Deep CNN for Enhancing Natural Language Processing Capabilities**
2412.15900v1 by Chang Weng, Scott Rood, Mehdi Ali Ramezani, Amir Aslani, Reza Zarrab, Wang Zwuo, Sanjeev Salimans, Tim Satheesh

Natural Language Processing (NLP) is widely used in fields like machine
translation and sentiment analysis. However, traditional NLP models struggle
with accuracy and efficiency. This paper introduces Deep Convolutional Neural
Networks (DCNN) into NLP to address these issues. By integrating DCNN, machine
learning (ML) algorithms, and generative adversarial networks (GAN), the study
improves language understanding, reduces ambiguity, and enhances task
performance. The high-performance NLP model shows a 10% improvement in
segmentation accuracy and a 4% increase in recall rate compared to traditional
models. This integrated approach excels in tasks such as word segmentation,
part-of-speech tagging, machine translation, and text classification, offering
better recognition accuracy and processing efficiency.

摘要：自然語言處理 (NLP) 廣泛用於機器翻譯和情緒分析等領域。然而，傳統 NLP 模型在準確性和效率方面面臨挑戰。本文將深度卷積神經網路 (DCNN) 引入 NLP 以解決這些問題。透過整合 DCNN、機器學習 (ML) 演算法和生成對抗網路 (GAN)，本研究改善了語言理解、減少了歧義，並提升了任務效能。高性能 NLP 模型在分詞準確度方面提升了 10%，召回率方面提升了 4%，優於傳統模型。這種整合方法在詞彙分詞、詞性標記、機器翻譯和文本分類等任務中表現出色，提供了更好的辨識準確度和處理效率。

##### **TelcoLM: collecting data, adapting, and benchmarking language models for the telecommunication domain**
2412.15891v1 by Camille Barboule, Viet-Phi Huynh, Adrien Bufort, Yoan Chabot, Géraldine Damnati, Gwénolé Lecorvé

Despite outstanding processes in many tasks, Large Language Models (LLMs)
still lack accuracy when dealing with highly technical domains. Especially,
telecommunications (telco) is a particularly challenging domain due the large
amount of lexical, semantic and conceptual peculiarities. Yet, this domain
holds many valuable use cases, directly linked to industrial needs. Hence, this
paper studies how LLMs can be adapted to the telco domain. It reports our
effort to (i) collect a massive corpus of domain-specific data (800M tokens,
80K instructions), (ii) perform adaptation using various methodologies, and
(iii) benchmark them against larger generalist models in downstream tasks that
require extensive knowledge of telecommunications. Our experiments on
Llama-2-7b show that domain-adapted models can challenge the large generalist
models. They also suggest that adaptation can be restricted to a unique
instruction-tuning step, dicarding the need for any fine-tuning on raw texts
beforehand.

摘要：儘管大型語言模型 (LLM) 在許多任務中擁有出色的處理程序，但在處理高度技術領域時仍缺乏準確性。特別是電信 (telco) 由於大量的詞彙、語義和概念特性，因此是一個特別具有挑戰性的領域。然而，這個領域擁有許多有價值的用例，與產業需求直接相關。因此，本文探討如何將 LLM 適應到電信領域。報告我們 (i) 收集大量特定領域的資料 (800M 個代幣、80K 個指令)、(ii) 使用各種方法執行適應，以及 (iii) 在需要廣泛電信知識的下游任務中，將它們與更大的通用模型進行比較。我們在 Llama-2-7b 上的實驗顯示，領域適應模型可以挑戰大型通用模型。它們還表明，適應可以限制在一個獨特的指令調整步驟中，事先無需對原始文字進行任何微調。

##### **AI-in-the-loop: The future of biomedical visual analytics applications in the era of AI**
2412.15876v1 by Katja Bühler, Thomas Höllt, Thomas Schulz, Pere-Pau Vázquez

AI is the workhorse of modern data analytics and omnipresent across many
sectors. Large Language Models and multi-modal foundation models are today
capable of generating code, charts, visualizations, etc. How will these massive
developments of AI in data analytics shape future data visualizations and
visual analytics workflows? What is the potential of AI to reshape methodology
and design of future visual analytics applications? What will be our role as
visualization researchers in the future? What are opportunities, open
challenges and threats in the context of an increasingly powerful AI? This
Visualization Viewpoint discusses these questions in the special context of
biomedical data analytics as an example of a domain in which critical decisions
are taken based on complex and sensitive data, with high requirements on
transparency, efficiency, and reliability. We map recent trends and
developments in AI on the elements of interactive visualization and visual
analytics workflows and highlight the potential of AI to transform biomedical
visualization as a research field. Given that agency and responsibility have to
remain with human experts, we argue that it is helpful to keep the focus on
human-centered workflows, and to use visual analytics as a tool for integrating
``AI-in-the-loop''. This is in contrast to the more traditional term
``human-in-the-loop'', which focuses on incorporating human expertise into
AI-based systems.

摘要：人工智慧是現代資料分析中的主力，並普遍存在於許多產業中。大型語言模型和多模態基礎模型現在能夠產生程式碼、圖表、視覺化等。資料分析中人工智慧的這些巨大發展將如何形塑未來的資料視覺化和視覺分析工作流程？人工智慧在重塑未來視覺分析應用程式的技術和設計方面有哪些潛力？未來身為視覺化研究人員，我們將扮演什麼角色？在人工智慧日益強大的背景下，有哪些機會、公開挑戰和威脅？本視覺觀點在生物醫學資料分析的特殊背景下探討這些問題，作為一個基於複雜且敏感資料做出關鍵決策的領域範例，對透明度、效率和可靠性有很高的要求。我們將人工智慧的最新趨勢和發展對應到互動式視覺化和視覺分析工作流程的元素，並強調人工智慧將生物醫學視覺化轉變為研究領域的潛力。由於自主權和責任必須留給人類專家，我們認為將焦點放在以人為中心的流程上，並將視覺分析用作整合「人工智慧在迴路中」的工具是有幫助的。這與更傳統的術語「人在迴路中」形成對比，後者專注於將人類專業知識納入基於人工智慧的系統中。

##### **Align Anything: Training All-Modality Models to Follow Instructions with Language Feedback**
2412.15838v1 by Jiaming Ji, Jiayi Zhou, Hantao Lou, Boyuan Chen, Donghai Hong, Xuyao Wang, Wenqi Chen, Kaile Wang, Rui Pan, Jiahao Li, Mohan Wang, Josef Dai, Tianyi Qiu, Hua Xu, Dong Li, Weipeng Chen, Jun Song, Bo Zheng, Yaodong Yang

Reinforcement learning from human feedback (RLHF) has proven effective in
enhancing the instruction-following capabilities of large language models;
however, it remains underexplored in the cross-modality domain. As the number
of modalities increases, aligning all-modality models with human intentions --
such as instruction following -- becomes a pressing challenge. In this work, we
make the first attempt to fine-tune all-modality models (i.e. input and output
with any modality, also named any-to-any models) using human preference data
across all modalities (including text, image, audio, and video), ensuring its
behavior aligns with human intentions. This endeavor presents several
challenges. First, there is no large-scale all-modality human preference data
in existing open-source resources, as most datasets are limited to specific
modalities, predominantly text and image. Secondly, the effectiveness of binary
preferences in RLHF for post-training alignment in complex all-modality
scenarios remains an unexplored area. Finally, there is a lack of a systematic
framework to evaluate the capabilities of all-modality models, particularly
regarding modality selection and synergy. To address these challenges, we
propose the align-anything framework, which includes meticulously annotated
200k all-modality human preference data. Then, we introduce an alignment method
that learns from unified language feedback, effectively capturing complex
modality-specific human preferences and enhancing the model's
instruction-following capabilities. Furthermore, to assess performance
improvements in all-modality models after post-training alignment, we construct
a challenging all-modality capability evaluation framework -- eval-anything.
All data, models, and code frameworks have been open-sourced for the community.
For more details, please refer to
https://github.com/PKU-Alignment/align-anything.

摘要：<paragraph>透過人類回饋的增強學習 (RLHF) 已被證實能有效提升大型語言模型遵循指令的能力；然而，在跨模態領域中仍未被充分探索。隨著模態數量的增加，使所有模態模型與人類意圖保持一致（例如遵循指令）成了一項迫切的挑戰。在這項工作中，我們首次嘗試使用所有模態（包括文字、影像、音訊和影片）的人類偏好資料微調所有模態模型（即輸入和輸出具有任何模態，也稱為任意對任意模型），確保其行為與人類意圖保持一致。這項努力提出了幾個挑戰。首先，現有的開放原始碼資源中沒有大規模的所有模態人類偏好資料，因為大多數資料集都限於特定模態，主要是文字和影像。其次，在複雜的所有模態情境中，RLHF 中二元偏好對後訓練對齊的有效性仍是一個未經探索的領域。最後，缺乏系統性的架構來評估所有模態模型的能力，特別是關於模態選擇和協同效應。為了應對這些挑戰，我們提出了 align-anything 架構，其中包含仔細註解的 20 萬個所有模態人類偏好資料。然後，我們引入了一種對齊方法，從統一的語言回饋中學習，有效捕捉複雜的特定於模態的人類偏好，並增強模型的指令遵循能力。此外，為了評估後訓練對齊後所有模態模型的效能改善，我們建構了一個具有挑戰性的所有模態能力評估架構——eval-anything。所有資料、模型和程式碼架構都已開放原始碼供社群使用。如需更多詳細資訊，請參閱 https://github.com/PKU-Alignment/align-anything。</paragraph>

##### **Enriching Social Science Research via Survey Item Linking**
2412.15831v1 by Tornike Tsereteli, Daniel Ruffinelli, Simone Paolo Ponzetto

Questions within surveys, called survey items, are used in the social
sciences to study latent concepts, such as the factors influencing life
satisfaction. Instead of using explicit citations, researchers paraphrase the
content of the survey items they use in-text. However, this makes it
challenging to find survey items of interest when comparing related work.
Automatically parsing and linking these implicit mentions to survey items in a
knowledge base can provide more fine-grained references. We model this task,
called Survey Item Linking (SIL), in two stages: mention detection and entity
disambiguation. Due to an imprecise definition of the task, existing datasets
used for evaluating the performance for SIL are too small and of low-quality.
We argue that latent concepts and survey item mentions should be
differentiated. To this end, we create a high-quality and richly annotated
dataset consisting of 20,454 English and German sentences. By benchmarking deep
learning systems for each of the two stages independently and sequentially, we
demonstrate that the task is feasible, but observe that errors propagate from
the first stage, leading to a lower overall task performance. Moreover,
mentions that require the context of multiple sentences are more challenging to
identify for models in the first stage. Modeling the entire context of a
document and combining the two stages into an end-to-end system could mitigate
these problems in future work, and errors could additionally be reduced by
collecting more diverse data and by improving the quality of the knowledge
base. The data and code are available at https://github.com/e-tornike/SIL .

摘要：<paragraph>在社會科學中，調查中的問題（稱為調查項目）用於研究潛在概念，例如影響生活滿意度的因素。研究人員沒有使用明確的引文，而是對他們在文中使用的調查項目的內容進行改寫。然而，在比較相關工作時，這使得找到有興趣的調查項目變得具有挑戰性。自動解析並將這些隱含提及與知識庫中的調查項目連結起來可以提供更精細的參考。我們將此任務稱為調查項目連結（SIL），分為兩個階段：提及偵測和實體消除歧義。由於任務定義不精確，用於評估 SIL 效能的現有資料集太小且品質低落。我們認為潛在概念和調查項目提及應該區分開來。為此，我們建立了一個高品質且豐富註解的資料集，包含 20,454 個英文和德文句子。透過獨立且順序地對兩個階段的深度學習系統進行基準測試，我們證明了此任務的可行性，但觀察到錯誤從第一階段傳播，導致整體任務效能降低。此外，需要多個句子背景的提及對於第一階段的模型來說更具挑戰性。建模文件的整個背景並將兩個階段結合到端到端系統中可以緩解未來工作中的這些問題，此外，透過收集更多樣化的資料和提高知識庫的品質，可以進一步減少錯誤。資料和程式碼可在 https://github.com/e-tornike/SIL 取得。</paragraph>

##### **S$^2$DN: Learning to Denoise Unconvincing Knowledge for Inductive Knowledge Graph Completion**
2412.15822v1 by Tengfei Ma, Yujie Chen, Liang Wang, Xuan Lin, Bosheng Song, Xiangxiang Zeng

Inductive Knowledge Graph Completion (KGC) aims to infer missing facts
between newly emerged entities within knowledge graphs (KGs), posing a
significant challenge. While recent studies have shown promising results in
inferring such entities through knowledge subgraph reasoning, they suffer from
(i) the semantic inconsistencies of similar relations, and (ii) noisy
interactions inherent in KGs due to the presence of unconvincing knowledge for
emerging entities. To address these challenges, we propose a Semantic
Structure-aware Denoising Network (S$^2$DN) for inductive KGC. Our goal is to
learn adaptable general semantics and reliable structures to distill consistent
semantic knowledge while preserving reliable interactions within KGs.
Specifically, we introduce a semantic smoothing module over the enclosing
subgraphs to retain the universal semantic knowledge of relations. We
incorporate a structure refining module to filter out unreliable interactions
and offer additional knowledge, retaining robust structure surrounding target
links. Extensive experiments conducted on three benchmark KGs demonstrate that
S$^2$DN surpasses the performance of state-of-the-art models. These results
demonstrate the effectiveness of S$^2$DN in preserving semantic consistency and
enhancing the robustness of filtering out unreliable interactions in
contaminated KGs.

摘要：歸納知識圖譜完成功能（KGC）旨在推論知識圖譜（KG）中新出現實體之間的遺失事實，這是一個重大的挑戰。雖然最近的研究表明通過知識子圖推理推論此類實體的結果很有希望，但它們存在（i）相似關係的語義不一致，以及（ii）由於存在針對新興實體的不可信知識，因此 KG 中固有的雜訊交互。為了應對這些挑戰，我們提出了用於歸納 KGC 的語義結構感知去噪網路（S$^2$DN）。我們的目標是學習適應性的通用語義和可靠的結構，以在保留 KG 內部可靠交互的同時提取一致的語義知識。具體來說，我們在封閉子圖上引入了一個語義平滑模組，以保留關係的通用語義知識。我們整合了一個結構精煉模組，以過濾掉不可靠的交互並提供額外的知識，從而保留目標鏈接周圍的強健結構。在三個基準 KG 上進行的廣泛實驗表明 S$^2$DN 超越了最先進模型的效能。這些結果證明了 S$^2$DN 在保留語義一致性和增強過濾受污染 KG 中不可靠交互的穩健性方面的有效性。

##### **$π$-yalli: un nouveau corpus pour le nahuatl**
2412.15821v1 by Juan-Manuel Torres-Moreno, Juan-José Guzmán-Landa, Graham Ranger, Martha Lorena Avendaño Garrido, Miguel Figueroa-Saavedra, Ligia Quintana-Torres, Carlos-Emiliano González-Gallardo, Elvys Linhares Pontes, Patricia Velázquez Morales, Luis-Gil Moreno Jiménez

The NAHU$^2$ project is a Franco-Mexican collaboration aimed at building the
$\pi$-YALLI corpus adapted to machine learning, which will subsequently be used
to develop computer resources for the Nahuatl language. Nahuatl is a language
with few computational resources, even though it is a living language spoken by
around 2 million people. We have decided to build $\pi$-YALLI, a corpus that
will enable to carry out research on Nahuatl in order to develop Language
Models (LM), whether dynamic or not, which will make it possible to in turn
enable the development of Natural Language Processing (NLP) tools such as: a) a
grapheme unifier, b) a word segmenter, c) a POS grammatical analyser, d) a
content-based Automatic Text Summarization; and possibly, e) a translator
translator (probabilistic or learning-based).

摘要：NAHU$^2$ 專案是一個法墨合作，旨在建立適用於機器學習的 $\pi$-YALLI 語料庫，隨後將用於開發納瓦特爾語的電腦資源。納瓦特爾語是一種計算資源稀少的語言，儘管它是一種有約 200 萬人使用的現存語言。我們決定建立 $\pi$-YALLI，這是一個語料庫，將能夠進行納瓦特爾語研究，以開發語言模型 (LM)，無論動態與否，這將進而能夠開發自然語言處理 (NLP) 工具，例如：a) 音素統一器，b) 字詞分詞器，c) POS 語法分析器，d) 基於內容的自動摘要；以及可能，e) 一個翻譯器（基於機率或學習）。

##### **WebLLM: A High-Performance In-Browser LLM Inference Engine**
2412.15803v1 by Charlie F. Ruan, Yucheng Qin, Xun Zhou, Ruihang Lai, Hongyi Jin, Yixin Dong, Bohan Hou, Meng-Shiun Yu, Yiyan Zhai, Sudeep Agarwal, Hangrui Cao, Siyuan Feng, Tianqi Chen

Advancements in large language models (LLMs) have unlocked remarkable
capabilities. While deploying these models typically requires server-grade GPUs
and cloud-based inference, the recent emergence of smaller open-source models
and increasingly powerful consumer devices have made on-device deployment
practical. The web browser as a platform for on-device deployment is
universally accessible, provides a natural agentic environment, and
conveniently abstracts out the different backends from diverse device vendors.
To address this opportunity, we introduce WebLLM, an open-source JavaScript
framework that enables high-performance LLM inference entirely within web
browsers. WebLLM provides an OpenAI-style API for seamless integration into web
applications, and leverages WebGPU for efficient local GPU acceleration and
WebAssembly for performant CPU computation. With machine learning compilers
MLC-LLM and Apache TVM, WebLLM leverages optimized WebGPU kernels, overcoming
the absence of performant WebGPU kernel libraries. Evaluations show that WebLLM
can retain up to 80% native performance on the same device, with room to
further close the gap. WebLLM paves the way for universally accessible,
privacy-preserving, personalized, and locally powered LLM applications in web
browsers. The code is available at: https://github.com/mlc-ai/web-llm.

摘要：大型語言模型 (LLM) 的進步已經解鎖了非凡的能力。雖然部署這些模型通常需要伺服器級 GPU 和基於雲端的推論，但近期出現了較小的開源模型和越來越強大的消費性裝置，讓裝置上部署變得切合實際。網路瀏覽器作為裝置上部署的平台，具有普遍的可存取性，提供了一個自然的代理環境，並便利地抽象化了來自不同裝置供應商的不同後端。為了應對這個機會，我們引入了 WebLLM，一個開源的 JavaScript 框架，可以在網路瀏覽器中完全進行高性能 LLM 推論。WebLLM 提供了一個 OpenAI 風格的 API，可以無縫整合到網路應用程式中，並利用 WebGPU 進行高效的本地 GPU 加速，以及利用 WebAssembly 進行高效的 CPU 計算。透過機器學習編譯器 MLC-LLM 和 Apache TVM，WebLLM 利用了最佳化的 WebGPU 核，克服了沒有高效能 WebGPU 核函式庫的問題。評估顯示 WebLLM 可以保留高達 80% 的原生效能，並有進一步縮小差距的空間。WebLLM 為網路瀏覽器中普遍可存取、注重隱私、個人化且由本地驅動的 LLM 應用程式鋪平了道路。程式碼可在 https://github.com/mlc-ai/web-llm 取得。

##### **Bi-directional Mapping of Morphology Metrics and 3D City Blocks for Enhanced Characterization and Generation of Urban Form**
2412.15801v1 by Chenyi Cai, Biao Li, Qiyan Zhang, Xiao Wang, Filip Biljecki, Pieter Herthogs

Urban morphology, examining city spatial configurations, links urban design
to sustainability. Morphology metrics play a fundamental role in
performance-driven computational urban design (CUD) which integrates urban form
generation, performance evaluation and optimization. However, a critical gap
remains between performance evaluation and complex urban form generation,
caused by the disconnection between morphology metrics and urban form,
particularly in metric-to-form workflows. It prevents the application of
optimized metrics to generate improved urban form with enhanced urban
performance. Formulating morphology metrics that not only effectively
characterize complex urban forms but also enable the reconstruction of diverse
forms is of significant importance. This paper highlights the importance of
establishing a bi-directional mapping between morphology metrics and complex
urban form to enable the integration of urban form generation with performance
evaluation. We present an approach that can 1) formulate morphology metrics to
both characterize urban forms and in reverse, retrieve diverse similar 3D urban
forms, and 2) evaluate the effectiveness of morphology metrics in representing
3D urban form characteristics of blocks by comparison. We demonstrate the
methodology with 3D urban models of New York City, covering 14,248 blocks. We
use neural networks and information retrieval for morphology metric encoding,
urban form clustering and morphology metric evaluation. We identified an
effective set of morphology metrics for characterizing block-scale urban forms
through comparison. The proposed methodology tightly couples complex urban
forms with morphology metrics, hence it can enable a seamless and bidirectional
relationship between urban form generation and optimization in
performance-driven urban design towards sustainable urban design and planning.

摘要：<paragraph>城市形態學探討城市空間配置，將城市設計與永續性連結在一起。形態指標在以效能為導向的計算城市設計（CUD）中扮演著基本的角色，而計算城市設計整合了城市形態生成、效能評估與最佳化。然而，效能評估與複雜的城市形態生成之間仍存在著一個關鍵的差距，其原因在於形態指標與城市形態之間的脫節，特別是在指標到形態的工作流程中。這阻礙了最佳化指標的應用，無法產生具有增強城市效能的優化城市形態。制定不僅能有效表徵複雜城市形態，還能重建多樣化形態的形態指標至關重要。本文強調了建立形態指標與複雜城市形態之間的雙向對應關係的重要性，以實現城市形態生成與效能評估的整合。我們提出了一種方法，可以 1）制定形態指標，既能表徵城市形態，又能反向擷取多樣化的類似 3D 城市形態，以及 2）透過比較評估形態指標在表示街廓 3D 城市形態特徵方面的有效性。我們以涵蓋 14,248 個街廓的紐約市 3D 城市模型展示了該方法。我們使用神經網路和資訊檢索進行形態指標編碼、城市形態聚類和形態指標評估。我們透過比較找出一個有效的形態指標集合，用於表徵街廓尺度的城市形態。所提出的方法將複雜的城市形態與形態指標緊密結合，因此它可以在以效能為導向的城市設計中實現城市形態生成與最佳化之間的無縫雙向關係，朝向永續的城市設計與規劃。</paragraph>

##### **Ensembling Large Language Models with Process Reward-Guided Tree Search for Better Complex Reasoning**
2412.15797v1 by Sungjin Park, Xiao Liu, Yeyun Gong, Edward Choi

Despite recent advances in large language models, open-source models often
struggle to consistently perform well on complex reasoning tasks. Existing
ensemble methods, whether applied at the token or output levels, fail to
address these challenges. In response, we present Language model Ensemble with
Monte Carlo Tree Search (LE-MCTS), a novel framework for process-level
ensembling of language models. LE-MCTS formulates step-by-step reasoning with
an ensemble of language models as a Markov decision process. In this framework,
states represent intermediate reasoning paths, while actions consist of
generating the next reasoning step using one of the language models selected
from a predefined pool. Guided by a process-based reward model, LE-MCTS
performs a tree search over the reasoning steps generated by different language
models, identifying the most accurate reasoning chain. Experimental results on
five mathematical reasoning benchmarks demonstrate that our approach
outperforms both single language model decoding algorithms and language model
ensemble methods. Notably, LE-MCTS improves performance by 3.6% and 4.3% on the
MATH and MQA datasets, respectively, highlighting its effectiveness in solving
complex reasoning problems.

摘要：儘管大型語言模型近期有長足進展，但開放原始碼模型在複雜推理任務中常無法持續表現良好。現有的整體方法，無論應用於符號或輸出層級，都無法應對這些挑戰。為了解決此問題，我們提出了語言模型整體與蒙地卡羅樹狀搜尋 (LE-MCTS)，這是一個創新的框架，用於語言模型的流程層級整體。LE-MCTS 將使用語言模型整體進行逐步推理，制定為馬可夫決策流程。在此框架中，狀態代表中間推理路徑，而動作則包含使用從預定義池中選取的語言模型之一來產生下一個推理步驟。在基於流程的獎勵模型的指導下，LE-MCTS 會針對不同語言模型產生的推理步驟執行樹狀搜尋，找出最準確的推理鏈。在五個數學推理基準上的實驗結果顯示，我們的做法優於單一語言模型解碼演算法和語言模型整體方法。值得注意的是，LE-MCTS 分別在 MATH 和 MQA 資料集上將效能提升了 3.6% 和 4.3%，突顯其在解決複雜推理問題上的有效性。

##### **GraphSeqLM: A Unified Graph Language Framework for Omic Graph Learning**
2412.15790v1 by Heming Zhang, Di Huang, Yixin Chen, Fuhai Li

The integration of multi-omic data is pivotal for understanding complex
diseases, but its high dimensionality and noise present significant challenges.
Graph Neural Networks (GNNs) offer a robust framework for analyzing large-scale
signaling pathways and protein-protein interaction networks, yet they face
limitations in expressivity when capturing intricate biological relationships.
To address this, we propose Graph Sequence Language Model (GraphSeqLM), a
framework that enhances GNNs with biological sequence embeddings generated by
Large Language Models (LLMs). These embeddings encode structural and biological
properties of DNA, RNA, and proteins, augmenting GNNs with enriched features
for analyzing sample-specific multi-omic data. By integrating topological,
sequence-derived, and biological information, GraphSeqLM demonstrates superior
predictive accuracy and outperforms existing methods, paving the way for more
effective multi-omic data integration in precision medicine.

摘要：整合多組學資料對於理解複雜疾病至關重要，但其高維度和雜訊會造成顯著的挑戰。圖神經網路 (GNN) 提供了一個強健的架構，用於分析大規模信號路徑和蛋白質-蛋白質交互網路，然而它們在捕捉複雜的生物關係時，在表現力方面面臨限制。為了解決這個問題，我們提出了圖序列語言模型 (GraphSeqLM)，一個增強 GNN 的架構，透過大型語言模型 (LLM) 生成的生物序列嵌入。這些嵌入編碼了 DNA、RNA 和蛋白質的結構和生物特性，透過豐富的特性擴充 GNN，用於分析特定樣本的多組學資料。透過整合拓撲、序列衍生和生物資訊，GraphSeqLM 展現了優越的預測準確度，並優於現有方法，為精準醫療中更有效的多組學資料整合鋪路。

##### **Learning from Impairment: Leveraging Insights from Clinical Linguistics in Language Modelling Research**
2412.15785v1 by Dominique Brunato

This position paper investigates the potential of integrating insights from
language impairment research and its clinical treatment to develop
human-inspired learning strategies and evaluation frameworks for language
models (LMs). We inspect the theoretical underpinnings underlying some
influential linguistically motivated training approaches derived from
neurolinguistics and, particularly, aphasiology, aimed at enhancing the
recovery and generalization of linguistic skills in aphasia treatment, with a
primary focus on those targeting the syntactic domain. We highlight how these
insights can inform the design of rigorous assessments for LMs, specifically in
their handling of complex syntactic phenomena, as well as their implications
for developing human-like learning strategies, aligning with efforts to create
more sustainable and cognitively plausible natural language processing (NLP)
models.

摘要：此立場文件探討了整合語言障礙研究及其臨床治療的見解，以開發受人類啟發的學習策略和語言模型 (LM) 的評估架構。我們檢視了某些有影響力的語言學動機訓練方法的理論基礎，這些方法源自神經語言學，尤其是失語症學，旨在增強失語症治療中語言技能的恢復和概括，重點關注那些針對句法領域的方法。我們強調這些見解如何能為 LM 的嚴謹評估設計提供資訊，特別是在處理複雜句法現象時，以及它們對開發類人學習策略的影響，與創造更永續且認知上合理的自然語言處理 (NLP) 模型的努力相一致。

##### **Linguistic Features Extracted by GPT-4 Improve Alzheimer's Disease Detection based on Spontaneous Speech**
2412.15772v1 by Jonathan Heitz, Gerold Schneider, Nicolas Langer

Alzheimer's Disease (AD) is a significant and growing public health concern.
Investigating alterations in speech and language patterns offers a promising
path towards cost-effective and non-invasive early detection of AD on a large
scale. Large language models (LLMs), such as GPT, have enabled powerful new
possibilities for semantic text analysis. In this study, we leverage GPT-4 to
extract five semantic features from transcripts of spontaneous patient speech.
The features capture known symptoms of AD, but they are difficult to quantify
effectively using traditional methods of computational linguistics. We
demonstrate the clinical significance of these features and further validate
one of them ("Word-Finding Difficulties") against a proxy measure and human
raters. When combined with established linguistic features and a Random Forest
classifier, the GPT-derived features significantly improve the detection of AD.
Our approach proves effective for both manually transcribed and automatically
generated transcripts, representing a novel and impactful use of recent
advancements in LLMs for AD speech analysis.

摘要：阿茲海默症 (AD) 是個重大的且持續增加的公共衛生問題。
調查言語和語言模式的變化提供了一個有前景的途徑，可以大規模地對 AD 進行經濟有效且非侵入性的早期偵測。大型語言模型 (LLM)，例如 GPT，已經為語義文字分析開啟了強大的新可能性。在這項研究中，我們利用 GPT-4 從自發性患者言語的轉錄中提取五個語義特徵。這些特徵捕捉了 AD 的已知症狀，但使用傳統的計算語言學方法很難有效地量化它們。我們展示了這些特徵的臨床意義，並進一步驗證了其中一個特徵（「詞彙尋找困難」）與代理測量和人類評分員的結果。當與既定的語言特徵和隨機森林分類器結合時，GPT 衍生的特徵顯著改善了 AD 的偵測。我們的做法證明了手動轉錄和自動產生的轉錄都是有效的，這代表了 LLM 在 AD 語言分析中最新進展的一種新穎且有影響力的應用。

##### **Critique of Impure Reason: Unveiling the reasoning behaviour of medical Large Language Models**
2412.15748v1 by Shamus Sim, Tyrone Chen

Background: Despite the current ubiquity of Large Language Models (LLMs)
across the medical domain, there is a surprising lack of studies which address
their reasoning behaviour. We emphasise the importance of understanding
reasoning behaviour as opposed to high-level prediction accuracies, since it is
equivalent to explainable AI (XAI) in this context. In particular, achieving
XAI in medical LLMs used in the clinical domain will have a significant impact
across the healthcare sector. Results: Therefore, we define the concept of
reasoning behaviour in the specific context of medical LLMs. We then categorise
and discuss the current state of the art of methods which evaluate reasoning
behaviour in medical LLMs. Finally, we propose theoretical frameworks which can
empower medical professionals or machine learning engineers to gain insight
into the low-level reasoning operations of these previously obscure models.
Conclusion: The subsequent increased transparency and trust in medical machine
learning models by clinicians as well as patients will accelerate the
integration, application as well as further development of medical AI for the
healthcare system as a whole

摘要：背景：儘管大型語言模型 (LLM) 目前在醫療領域無所不在，但令人驚訝的是，探討其推理行為的研究卻相當缺乏。我們強調了解推理行為而非高層級的預測準確度非常重要，因為在這種情況下，這等同於可解釋 AI (XAI)。尤其是在臨床領域中使用的醫療 LLM 中實現 XAI，將對整個醫療保健產業產生重大影響。結果：因此，我們在醫療 LLM 的特定背景下定義了推理行為的概念。接著我們分類並探討當前評估醫療 LLM 中推理行為的方法的最新技術。最後，我們提出理論架構，讓醫療專業人員或機器學習工程師得以深入了解這些先前模糊模型的低層級推理運算。結論：臨床醫生和患者對醫療機器學習模型的透明度和信任度隨之提升，將加速醫療 AI 在整個醫療保健系統中的整合、應用和進一步發展。

##### **Fine-tuning Whisper on Low-Resource Languages for Real-World Applications**
2412.15726v1 by Vincenzo Timmel, Claudio Paonessa, Reza Kakooee, Manfred Vogel, Daniel Perruchoud

This paper presents a new approach to fine-tuning OpenAI's Whisper model for
low-resource languages by introducing a novel data generation method that
converts sentence-level data into a long-form corpus, using Swiss German as a
case study. Non-sentence-level data, which could improve the performance of
long-form audio, is difficult to obtain and often restricted by copyright laws.
Our method bridges this gap by transforming more accessible sentence-level data
into a format that preserves the model's ability to handle long-form audio and
perform segmentation without requiring non-sentence-level data. Our data
generation process improves performance in several real-world applications and
leads to the development of a new state-of-the-art speech-to-text (STT) model
for Swiss German. We compare our model with a non-fine-tuned Whisper and our
previous state-of-the-art Swiss German STT models, where our new model achieves
higher BLEU scores. Our results also indicate that the proposed method is
adaptable to other low-resource languages, supported by written guidance and
code that allows the creation of fine-tuned Whisper models, which keep
segmentation capabilities and allow the transcription of longer audio files
using only sentence-level data with high quality.

摘要：本文提出了一種微調 OpenAI 的 Whisper 模型的新方法，適用於資源匱乏的語言，方法是引入一種新穎的資料產生方法，將句子層級的資料轉換為長篇語料庫，並以瑞士德語作為案例研究。非句子層級的資料可能會改善長篇音訊的效能，但難以取得，且通常受到著作權法的限制。我們的做法透過將較容易取得的句子層級資料轉換為一種格式，來彌補這個差距，這種格式能保留模型處理長篇音訊和執行分段的能力，而不需要非句子層級的資料。我們的資料產生程序改善了多種真實世界應用程式的效能，並導致開發出一個新的瑞士德語語音轉文字 (STT) 最先進模型。我們將我們的模型與未微調的 Whisper 和我們先前最先進的瑞士德語 STT 模型進行比較，我們的模型獲得更高的 BLEU 分數。我們的結果還表明，所提出的方法適用於其他資源匱乏的語言，並受書面指南和程式碼支援，這些指南和程式碼允許建立微調的 Whisper 模型，這些模型保留分段功能，並允許僅使用高品質的句子層級資料轉錄較長的音訊檔案。

##### **AutoLife: Automatic Life Journaling with Smartphones and LLMs**
2412.15714v1 by Huatao Xu, Panron Tong, Mo Li, Mani Srivastava

This paper introduces a novel mobile sensing application - life journaling -
designed to generate semantic descriptions of users' daily lives. We present
AutoLife, an automatic life journaling system based on commercial smartphones.
AutoLife only inputs low-cost sensor data (without photos or audio) from
smartphones and can automatically generate comprehensive life journals for
users. To achieve this, we first derive time, motion, and location contexts
from multimodal sensor data, and harness the zero-shot capabilities of Large
Language Models (LLMs), enriched with commonsense knowledge about human lives,
to interpret diverse contexts and generate life journals. To manage the task
complexity and long sensing duration, a multilayer framework is proposed, which
decomposes tasks and seamlessly integrates LLMs with other techniques for life
journaling. This study establishes a real-life dataset as a benchmark and
extensive experiment results demonstrate that AutoLife produces accurate and
reliable life journals.

摘要：本文介紹了一項新穎的行動感測應用程式——生活日誌，旨在產生使用者的日常生活語意描述。我們展示 AutoLife，一個基於商用智慧型手機的自動生活日誌系統。AutoLife 僅輸入來自智慧型手機的低成本感測器資料（不含照片或音訊），並且可以自動為使用者產生全面的生活日誌。為達成此目的，我們首先從多模式感測器資料中衍生時間、動作和位置脈絡，並利用大型語言模型 (LLM) 的零次學習能力，豐富人類生活的常識知識，以詮釋不同的脈絡並產生生活日誌。為了管理任務複雜性和長時間感測，提出一個多層架構，它分解任務並將 LLM 與其他生活日誌技術無縫整合。本研究建立一個真實生活資料集作為基準，廣泛的實驗結果證明 AutoLife 產生準確且可靠的生活日誌。

##### **Contrastive Learning for Task-Independent SpeechLLM-Pretraining**
2412.15712v1 by Maike Züfle, Jan Niehues

Large language models (LLMs) excel in natural language processing but
adapting these LLMs to speech processing tasks efficiently is not
straightforward. Direct task-specific fine-tuning is limited by overfitting
risks, data requirements, and computational costs. To address these challenges,
we propose a scalable, two-stage training approach: (1) A task-independent
speech pretraining stage using contrastive learning to align text and speech
representations over all layers, followed by (2) a task-specific fine-tuning
stage requiring minimal data. This approach outperforms traditional ASR
pretraining and enables the model to surpass models specialized on speech
translation and question answering while being trained on only 10% of the
task-specific data.

摘要：大型語言模型 (LLM) 在自然語言處理方面表現出色，但將這些 LLM 有效地改編到語音處理任務並不容易。直接針對特定任務進行微調會受到過度擬合風險、資料需求和運算成本的限制。為了應對這些挑戰，我們提出了一種可擴充的兩階段訓練方法：(1) 使用對比學習來調整文本和語音表示，在所有層面上進行與任務無關的語音預訓練階段，然後 (2) 進行需要最少資料的特定任務微調階段。這種方法優於傳統的 ASR 預訓練，並使模型能夠超越專門針對語音翻譯和問題解答的模型，同時只使用 10% 的特定任務資料進行訓練。

##### **MacLight: Multi-scene Aggregation Convolutional Learning for Traffic Signal Control**
2412.15703v1 by Sunbowen Lee, Hongqin Lyu, Yicheng Gong, Yingying Sun, Chao Deng

Reinforcement learning methods have proposed promising traffic signal control
policy that can be trained on large road networks. Current SOTA methods model
road networks as topological graph structures, incorporate graph attention into
deep Q-learning, and merge local and global embeddings to improve policy.
However, graph-based methods are difficult to parallelize, resulting in huge
time overhead. Moreover, none of the current peer studies have deployed dynamic
traffic systems for experiments, which is far from the actual situation.
  In this context, we propose Multi-Scene Aggregation Convolutional Learning
for traffic signal control (MacLight), which offers faster training speeds and
more stable performance. Our approach consists of two main components. The
first is the global representation, where we utilize variational autoencoders
to compactly compress and extract the global representation. The second
component employs the proximal policy optimization algorithm as the backbone,
allowing value evaluation to consider both local features and global embedding
representations. This backbone model significantly reduces time overhead and
ensures stability in policy updates. We validated our method across multiple
traffic scenarios under both static and dynamic traffic systems. Experimental
results demonstrate that, compared to general and domian SOTA methods, our
approach achieves superior stability, optimized convergence levels and the
highest time efficiency. The code is under
https://github.com/Aegis1863/MacLight.

摘要：強化學習方法已提出有望的交通號誌控制策略，可以在大型道路網路中進行訓練。當前 SOTA 方法將道路網路建模為拓撲圖結構，將圖注意力納入深度 Q 學習，並合併局部和全局嵌入以改善策略。然而，基於圖形的方法難以並行化，導致巨大的時間開銷。此外，目前沒有任何同行研究為實驗部署動態交通系統，這遠離實際情況。
在此背景下，我們提出用於交通號誌控制的多場景聚合卷積學習 (MacLight)，它提供了更快的訓練速度和更穩定的效能。我們的做法包含兩個主要組成部分。第一個是全局表示，我們在其中利用變分自動編碼器來壓縮和提取全局表示。第二個組件採用近端策略優化演算法作為主幹，允許價值評估同時考慮局部特徵和全局嵌入表示。此主幹模型顯著減少時間開銷，並確保策略更新的穩定性。我們在靜態和動態交通系統下跨多個交通場景驗證了我們的方法。實驗結果表明，與一般和領域 SOTA 方法相比，我們的做法實現了卓越的穩定性、最佳的收斂水準和最高的時間效率。程式碼在 https://github.com/Aegis1863/MacLight。

##### **Collaborative Gym: A Framework for Enabling and Evaluating Human-Agent Collaboration**
2412.15701v1 by Yijia Shao, Vinay Samuel, Yucheng Jiang, John Yang, Diyi Yang

Recent advancements in language models (LMs) have sparked growing interest in
developing LM agents. While fully autonomous agents could excel in many
scenarios, numerous use cases inherently require them to collaborate with
humans due to humans' latent preferences, domain expertise, or need for
control. To facilitate the study of human-agent collaboration, we present
Collaborative Gym (Co-Gym), a general framework enabling asynchronous,
tripartite interaction among agents, humans, and task environments. We
instantiate Co-Gym with three representative tasks in both simulated and
real-world conditions, and propose an evaluation framework that assesses both
the collaboration outcomes and processes. Our findings reveal that
collaborative agents consistently outperform their fully autonomous
counterparts in task performance within those delivered cases, achieving win
rates of 86% in Travel Planning, 74% in Tabular Analysis, and 66% in Related
Work when evaluated by real users. However, our study also highlights
significant challenges in developing collaborative agents, requiring
advancements in core aspects of intelligence -- communication capabilities,
situational awareness, and balancing autonomy and human control.

摘要：語言模型 (LM) 的最新進展激發了開發 LM 代理的興趣。雖然全自動代理可以在許多情境中表現出色，但許多使用案例本質上要求它們與人類合作，因為人類的潛在偏好、領域專業知識或對控制的需求。為了促進對人類代理協作的研究，我們提出了協作健身房 (Co-Gym)，一個通用框架，讓代理、人類和任務環境之間能夠進行非同步的三方互動。我們在模擬和現實世界條件下使用三個代表性任務實例化 Co-Gym，並提出一個評估協作成果和過程的評估框架。我們的研究結果表明，在這些已交付的案例中，協作代理始終優於其全自動對應物，在旅行規劃中實現 86% 的獲勝率，在表格分析中實現 74% 的獲勝率，在相關工作中實現 66% 的獲勝率，經由真實用戶評估。然而，我們的研究也強調了開發協作代理的重大挑戰，需要在智能的核心方面取得進展，包括溝通能力、情境感知以及平衡自主性和人類控制。

##### **Variability Need Not Imply Error: The Case of Adequate but Semantically Distinct Responses**
2412.15683v1 by Evgenia Ilia, Wilker Aziz

With the broader use of language models (LMs) comes the need to estimate
their ability to respond reliably to prompts (e.g., are generated responses
likely to be correct?). Uncertainty quantification tools (notions of confidence
and entropy, i.a.) can be used to that end (e.g., to reject a response when the
model is `uncertain'). For example, Kuhn et al. (semantic entropy; 2022b)
regard semantic variation amongst sampled responses as evidence that the model
`struggles' with the prompt and that the LM is likely to err. We argue that
semantic variability need not imply error--this being especially intuitive in
open-ended settings, where prompts elicit multiple adequate but semantically
distinct responses. Hence, we propose to annotate sampled responses for their
adequacy to the prompt (e.g., using a classifier) and estimate the Probability
the model assigns to Adequate Responses (PROBAR), which we then regard as an
indicator of the model's reliability at the instance level. We evaluate PROBAR
as a measure of confidence in selective prediction with OPT models (in two QA
datasets and in next-word prediction, for English) and find PROBAR to
outperform semantic entropy across prompts with varying degrees of
ambiguity/open-endedness.

摘要：隨著語言模型 (LM) 的廣泛使用，需要評估它們可靠回應提示的能力（例如，產生的回應是否可能正確？）。不確定量化工具（包括置信度和熵的概念）可用於此目的（例如，在模型「不確定」時拒絕回應）。例如，Kuhn 等人（語義熵；2022b）將取樣回應之間的語義變異視為模型「難以」解決提示的證據，且 LM 可能會出錯。我們認為語義變異不一定表示錯誤，這在開放式設定中特別直觀，在這種設定中，提示會引出多個充分但語義上不同的回應。因此，我們建議為取樣回應加上註解，說明它們是否充分回應提示（例如，使用分類器），並估計模型分配給充分回應的機率 (PROBAR)，然後我們將其視為模型在實例層級可靠性的指標。我們評估 PROBAR 作為對使用 OPT 模型進行選擇性預測的信心指標（在兩個問答資料集和英文的下一字預測中），並發現 PROBAR 在不同程度的模糊性/開放性的提示中優於語義熵。

##### **AI-generated Image Quality Assessment in Visual Communication**
2412.15677v1 by Yu Tian, Yixuan Li, Baoliang Chen, Hanwei Zhu, Shiqi Wang, Sam Kwong

Assessing the quality of artificial intelligence-generated images (AIGIs)
plays a crucial role in their application in real-world scenarios. However,
traditional image quality assessment (IQA) algorithms primarily focus on
low-level visual perception, while existing IQA works on AIGIs overemphasize
the generated content itself, neglecting its effectiveness in real-world
applications. To bridge this gap, we propose AIGI-VC, a quality assessment
database for AI-Generated Images in Visual Communication, which studies the
communicability of AIGIs in the advertising field from the perspectives of
information clarity and emotional interaction. The dataset consists of 2,500
images spanning 14 advertisement topics and 8 emotion types. It provides
coarse-grained human preference annotations and fine-grained preference
descriptions, benchmarking the abilities of IQA methods in preference
prediction, interpretation, and reasoning. We conduct an empirical study of
existing representative IQA methods and large multi-modal models on the AIGI-VC
dataset, uncovering their strengths and weaknesses.

摘要：評估人工智慧產生影像 (AIGI) 的品質在實際場景中的應用扮演著至關重要的角色。然而，傳統的影像品質評估 (IQA) 演算法主要專注於低階視覺感知，而現有的 AIGI IQA 作品過度強調產生內容本身，忽略了其在實際應用中的有效性。為了彌補這個差距，我們提出了 AIGI-VC，一個用於視覺溝通中人工智慧產生影像的品質評估資料庫，從資訊清晰度和情緒互動的角度研究 AIGI 在廣告領域的傳達能力。此資料集包含 2,500 張橫跨 14 個廣告主題和 8 種情緒類型的影像。它提供了粗略的人類偏好註解和細緻的偏好說明，基準測試了 IQA 方法在偏好預測、詮釋和推理中的能力。我們對現有的代表性 IQA 方法和大型多模式模型在 AIGI-VC 資料集上進行實證研究，揭露了它們的優缺點。

##### **Adaptable and Precise: Enterprise-Scenario LLM Function-Calling Capability Training Pipeline**
2412.15660v1 by Guancheng Zeng, Wentao Ding, Beining Xu, Chi Zhang, Wenqiang Han, Gang Li, Jingjing Mo, Pengxu Qiu, Xinran Tao, Wang Tao, Haowen Hu

Enterprises possess a vast array of API assets scattered across various
functions, forming the backbone of existing business processes. By leveraging
these APIs as functional tools, enterprises can design diverse,
scenario-specific agent applications, driven by on-premise function-calling
models as the core engine. However, generic models often fail to meet
enterprise requirements in terms of computational efficiency, output accuracy,
and stability, necessitating scenario-specific adaptation. In this paper, we
propose a training pipeline for function-calling capabilities tailored to
real-world business scenarios. This pipeline includes the synthesis and
augmentation of scenario-specific function-calling data, model fine-tuning, and
performance evaluation and analysis. Using this pipeline, we generated 1,260
fully AI-generated samples and 1,035 augmented manually-labeled samples in
digital HR agent scenario. The Qwen2.5-Coder-7B-Instruct model was employed as
the base model and fine-tuned using the LoRA method on four GPUs with 24GB
VRAM. Our fine-tuned model demonstrated outstanding performance in evaluations
and practical applications, surpassing GPT-4 and GPT-4o in accuracy on the test
set. These results validate the reliability of the proposed pipeline for
training scenario-specific function-calling models.

摘要：企業擁有廣泛的 API 資產，散佈於各種功能中，形成現有業務流程的骨幹。透過利用這些 API 作為功能工具，企業可以設計多樣化的、特定於場景的代理應用程式，以內部函式呼叫模型作為核心引擎。然而，通用模型通常無法滿足企業在運算效率、輸出準確度和穩定性方面的需求，因此需要特定於場景的調整。在本文中，我們提出了一個針對實際業務場景量身打造的函式呼叫能力訓練管道。此管道包括合成和擴充特定於場景的函式呼叫資料、模型微調，以及效能評估和分析。使用這個管道，我們在數位人力資源代理場景中生成了 1,260 個完全由 AI 生成的範例和 1,035 個擴充的手動標記範例。Qwen2.5-Coder-7B-Instruct 模型被用作基礎模型，並使用 LoRA 方法在四個具有 24GB VRAM 的 GPU 上進行微調。我們微調後的模型在評估和實際應用中展現出傑出的效能，在測試集上的準確度超越了 GPT-4 和 GPT-4o。這些結果驗證了所提出的管道對於訓練特定於場景的函式呼叫模型的可靠性。

##### **MathSpeech: Leveraging Small LMs for Accurate Conversion in Mathematical Speech-to-Formula**
2412.15655v1 by Sieun Hyeon, Kyudan Jung, Jaehee Won, Nam-Joon Kim, Hyun Gon Ryu, Hyuk-Jae Lee, Jaeyoung Do

In various academic and professional settings, such as mathematics lectures
or research presentations, it is often necessary to convey mathematical
expressions orally. However, reading mathematical expressions aloud without
accompanying visuals can significantly hinder comprehension, especially for
those who are hearing-impaired or rely on subtitles due to language barriers.
For instance, when a presenter reads Euler's Formula, current Automatic Speech
Recognition (ASR) models often produce a verbose and error-prone textual
description (e.g., e to the power of i x equals cosine of x plus i
$\textit{side}$ of x), instead of the concise $\LaTeX{}$ format (i.e., $ e^{ix}
= \cos(x) + i\sin(x) $), which hampers clear understanding and communication.
To address this issue, we introduce MathSpeech, a novel pipeline that
integrates ASR models with small Language Models (sLMs) to correct errors in
mathematical expressions and accurately convert spoken expressions into
structured $\LaTeX{}$ representations. Evaluated on a new dataset derived from
lecture recordings, MathSpeech demonstrates $\LaTeX{}$ generation capabilities
comparable to leading commercial Large Language Models (LLMs), while leveraging
fine-tuned small language models of only 120M parameters. Specifically, in
terms of CER, BLEU, and ROUGE scores for $\LaTeX{}$ translation, MathSpeech
demonstrated significantly superior capabilities compared to GPT-4o. We
observed a decrease in CER from 0.390 to 0.298, and higher ROUGE/BLEU scores
compared to GPT-4o.

摘要：<paragraph>在各種學術和專業場合，例如數學課程或研究簡報中，通常需要口頭傳達數學表達式。然而，在沒有附帶視覺輔助的情況下朗讀數學表達式會顯著阻礙理解，特別是對於聽力受損或因語言障礙而依賴字幕的人。例如，當簡報者朗讀歐拉公式時，目前的自動語音辨識 (ASR) 模型通常會產生冗長且容易出錯的文字描述（例如，e 的 i 次方 x 等於 x 的餘弦加上 i$\textit{側}$ x），而不是簡潔的 $\LaTeX{}$ 格式（即 $ e^{ix} = \cos(x) + i\sin(x) $），這會阻礙清晰的理解和溝通。為了解決這個問題，我們引入了 MathSpeech，這是一個新穎的管道，它將 ASR 模型與小型語言模型 (sLM) 整合在一起，以修正數學表達式中的錯誤，並將口語表達式準確轉換為結構化的 $\LaTeX{}$ 表示。在從演講錄音中衍生的新資料集上進行評估，MathSpeech 展示了與領先的商業大型語言模型 (LLM) 相當的 $\LaTeX{}$ 生成能力，同時僅利用了 1.2 億個參數的微調小型語言模型。具體來說，在 $\LaTeX{}$ 翻譯的 CER、BLEU 和 ROUGE 分數方面，MathSpeech 展示了與 GPT-4o 相比顯著優越的能力。我們觀察到 CER 從 0.390 下降到 0.298，並且與 GPT-4o 相比具有更高的 ROUGE/BLEU 分數。</paragraph>

##### **Error-driven Data-efficient Large Multimodal Model Tuning**
2412.15652v1 by Barry Menglong Yao, Qifan Wang, Lifu Huang

Large Multimodal Models (LMMs) have demonstrated impressive performance
across numerous academic benchmarks. However, fine-tuning still remains
essential to achieve satisfactory performance on downstream tasks, while the
task-specific tuning samples are usually not readily available or expensive and
time-consuming to obtain. To address this, we propose an error-driven
data-efficient tuning framework that aims to efficiently adapt generic LMMs to
newly emerging tasks without requiring any task-specific training samples. In
our approach, a generic LMM, acting as a student model, is first evaluated on a
small validation set of the target task, and then a more powerful model, acting
as a teacher model, identifies the erroneous steps within the student model's
reasoning steps and analyzes its capability gaps from fully addressing the
target task. Based on these gaps, targeted training samples are further
retrieved from existing task-agnostic datasets to tune the student model and
tailor it to the target task. We perform extensive experiments across three
different training data scales and seven tasks, demonstrating that our training
paradigm significantly and efficiently improves LMM's performance on downstream
tasks, achieving an average performance boost of 7.01%.

摘要：大型多模态模型 (LMM) 在众多学术基准上展现出令人印象深刻的性能。然而，微调仍然是实现下游任务令人满意的性能所必需的，而特定于任务的微调样本通常不容易获得，或者获得成本高且耗时。为了解决这个问题，我们提出了一种错误驱动的、数据高效的微调框架，旨在有效地将通用 LMM 调整到新兴任务，而无需任何特定于任务的训练样本。在我们的方法中，首先在目标任务的小型验证集上评估一个通用 LMM（充当学生模型），然后一个更强大的模型（充当教师模型）识别学生模型推理步骤中的错误步骤，并分析其能力差距，无法完全解决目标任务。基于这些差距，从现有的与任务无关的数据集中进一步检索目标训练样本，以微调学生模型并将其定制为目标任务。我们在三种不同的训练数据规模和七个任务上进行了广泛的实验，证明我们的训练范例显着且有效地提高了 LMM 在下游任务上的性能，平均性能提升了 7.01%。

##### **Can Input Attributions Interpret the Inductive Reasoning Process Elicited in In-Context Learning?**
2412.15628v1 by Mengyu Ye, Tatsuki Kuribayashi, Goro Kobayashi, Jun Suzuki

Elucidating the rationale behind neural models' outputs has been challenging
in the machine learning field, which is indeed applicable in this age of large
language models (LLMs) and in-context learning (ICL). When it comes to
estimating input attributions (IA), ICL poses a new issue of interpreting which
example in the prompt, consisting of a set of examples, contributed to
identifying the task/rule to be solved. To this end, in this paper, we
introduce synthetic diagnostic tasks inspired by the poverty of the stimulus
design in inductive reasoning; here, most in-context examples are ambiguous
w.r.t. their underlying rule, and one critical example disambiguates the task
demonstrated. The question is whether conventional IA methods can identify such
an example in interpreting the inductive reasoning process in ICL. Our
experiments provide several practical findings; for example, a certain simple
IA method works the best, and the larger the model, the generally harder it is
to interpret the ICL with gradient-based IA methods.

摘要：闡明神經模型輸出的基本原理一直是機器學習領域的挑戰，這在大型語言模型 (LLM) 和情境學習 (ICL) 的時代確實適用。在估計輸入歸因 (IA) 時，ICL 提出了一個新的問題，即解釋提示中的哪個範例（由一組範例組成）有助於識別要解決的任務/規則。為此，在本文中，我們引入了受歸納推理中刺激設計的貧乏性啟發的合成診斷任務；在這裡，大多數情境範例在其底層規則方面都是模稜兩可的，而一個關鍵範例消除了任務演示的歧義。問題在於傳統的 IA 方法是否可以在解釋 ICL 中的歸納推理過程中識別這樣的範例。我們的實驗提供了幾個實用的發現；例如，某種簡單的 IA 方法效果最好，而且模型越大，通常使用基於梯度的 IA 方法解釋 ICL 就越困難。

##### **JailPO: A Novel Black-box Jailbreak Framework via Preference Optimization against Aligned LLMs**
2412.15623v1 by Hongyi Li, Jiawei Ye, Jie Wu, Tianjie Yan, Chu Wang, Zhixin Li

Large Language Models (LLMs) aligned with human feedback have recently
garnered significant attention. However, it remains vulnerable to jailbreak
attacks, where adversaries manipulate prompts to induce harmful outputs.
Exploring jailbreak attacks enables us to investigate the vulnerabilities of
LLMs and further guides us in enhancing their security. Unfortunately, existing
techniques mainly rely on handcrafted templates or generated-based
optimization, posing challenges in scalability, efficiency and universality. To
address these issues, we present JailPO, a novel black-box jailbreak framework
to examine LLM alignment. For scalability and universality, JailPO meticulously
trains attack models to automatically generate covert jailbreak prompts.
Furthermore, we introduce a preference optimization-based attack method to
enhance the jailbreak effectiveness, thereby improving efficiency. To analyze
model vulnerabilities, we provide three flexible jailbreak patterns. Extensive
experiments demonstrate that JailPO not only automates the attack process while
maintaining effectiveness but also exhibits superior performance in efficiency,
universality, and robustness against defenses compared to baselines.
Additionally, our analysis of the three JailPO patterns reveals that attacks
based on complex templates exhibit higher attack strength, whereas covert
question transformations elicit riskier responses and are more likely to bypass
defense mechanisms.

摘要：大型語言模型 (LLM) 與人類回饋相符，最近受到廣泛關注。然而，它仍然容易受到越獄攻擊，其中對手操縱提示以誘發有害輸出。探索越獄攻擊使我們能夠調查 LLM 的漏洞，並進一步指導我們加強其安全性。遺憾的是，現有的技術主要依賴於手工製作的範本或基於生成的最佳化，在可擴充性、效率和通用性方面構成挑戰。為了解決這些問題，我們提出了 JailPO，一個新穎的黑盒越獄框架，用於檢查 LLM 對齊。對於可擴充性和通用性，JailPO 精心訓練攻擊模型以自動生成秘密越獄提示。此外，我們引入基於偏好最佳化的攻擊方法來增強越獄效果，從而提高效率。為了分析模型漏洞，我們提供了三種靈活的越獄模式。廣泛的實驗表明，JailPO 不僅自動化攻擊過程，同時保持有效性，而且在效率、通用性和對抗基線防禦的穩健性方面表現出優異的性能。此外，我們對這三種 JailPO 模式的分析表明，基於複雜範本的攻擊表現出較高的攻擊強度，而秘密問題轉換引發較高風險的回應，並且更有可能繞過防禦機制。

##### **TouchASP: Elastic Automatic Speech Perception that Everyone Can Touch**
2412.15622v1 by Xingchen Song, Chengdong Liang, Binbin Zhang, Pengshen Zhang, ZiYu Wang, Youcheng Ma, Menglong Xu, Lin Wang, Di Wu, Fuping Pan, Dinghao Zhou, Zhendong Peng

Large Automatic Speech Recognition (ASR) models demand a vast number of
parameters, copious amounts of data, and significant computational resources
during the training process. However, such models can merely be deployed on
high-compute cloud platforms and are only capable of performing speech
recognition tasks. This leads to high costs and restricted capabilities. In
this report, we initially propose the elastic mixture of the expert (eMoE)
model. This model can be trained just once and then be elastically scaled in
accordance with deployment requirements. Secondly, we devise an unsupervised
data creation and validation procedure and gather millions of hours of audio
data from diverse domains for training. Using these two techniques, our system
achieves elastic deployment capabilities while reducing the Character Error
Rate (CER) on the SpeechIO testsets from 4.98\% to 2.45\%. Thirdly, our model
is not only competent in Mandarin speech recognition but also proficient in
multilingual, multi-dialect, emotion, gender, and sound event perception. We
refer to this as Automatic Speech Perception (ASP), and the perception results
are presented in the experimental section.

摘要：大型自動語音辨識 (ASR) 模型在訓練過程中需要大量的參數、大量的資料，以及大量的運算資源。然而，這些模型只能部署在高運算雲端平台上，而且只能執行語音辨識任務。這會導致成本高昂且功能受限。在本報告中，我們首先提出專家彈性混合 (eMoE) 模型。此模型可以訓練一次，然後根據部署需求進行彈性擴充。其次，我們設計了一個非監督式資料建立和驗證程序，並從不同的領域收集了數百萬小時的音訊資料進行訓練。使用這兩種技術，我們的系統在降低 SpeechIO 測試集的字元錯誤率 (CER) 從 4.98% 到 2.45% 的同時，實現了彈性部署功能。第三，我們的模型不僅勝任普通話語音辨識，而且精通多語言、多方言、情緒、性別和聲音事件感知。我們將其稱為自動語音感知 (ASP)，並在實驗部分呈現感知結果。

##### **Modeling Autonomous Shifts Between Focus State and Mind-Wandering Using a Predictive-Coding-Inspired Variational RNN Model**
2412.15620v1 by Henrique Oyama, Jun Tani

The current study investigates possible neural mechanisms underling
autonomous shifts between focus state and mind-wandering by conducting model
simulation experiments. On this purpose, we modeled perception processes of
continuous sensory sequences using our previous proposed variational RNN model
which was developed based on the free energy principle. The current study
extended this model by introducing an adaptation mechanism of a meta-level
parameter, referred to as the meta-prior $\mathbf{w}$, which regulates the
complexity term in the free energy. Our simulation experiments demonstrated
that autonomous shifts between focused perception and mind-wandering take place
when $\mathbf{w}$ switches between low and high values associated with decrease
and increase of the average reconstruction error over the past window. In
particular, high $\mathbf{w}$ prioritized top-down predictions while low
$\mathbf{w}$ emphasized bottom-up sensations. This paper explores how our
experiment results align with existing studies and highlights their potential
for future research.

摘要：本研究透過進行模型模擬實驗，探討在專注狀態和心智遊走之間的自主轉換背後可能的神經機制。基於此目的，我們使用先前提出的變異 RNN 模型模擬感知連續感官序列的過程，該模型是根據自由能原理開發的。本研究透過引入元層級參數的適應機制，將此模型加以延伸，此參數稱為元先驗 $\mathbf{w}$，用於調節自由能中的複雜性項。我們的模擬實驗證明，當 $\mathbf{w}$ 在與過去視窗中平均重建誤差的減少和增加相關的低值和高值之間切換時，會發生專注感知和心智遊走之間的自主轉換。特別是，高 $\mathbf{w}$ 優先自上而下的預測，而低 $\mathbf{w}$ 則強調自下而上的感覺。本文探討我們的實驗結果如何與現有研究一致，並強調其在未來研究中的潛力。

##### **Understanding Individual Agent Importance in Multi-Agent System via Counterfactual Reasoning**
2412.15619v1 by Chen Jianming, Wang Yawen, Wang Junjie, Xie Xiaofei, Hu jun, Wang Qing, Xu Fanjiang

Explaining multi-agent systems (MAS) is urgent as these systems become
increasingly prevalent in various applications. Previous work has proveided
explanations for the actions or states of agents, yet falls short in
understanding the black-boxed agent's importance within a MAS and the overall
team strategy. To bridge this gap, we propose EMAI, a novel agent-level
explanation approach that evaluates the individual agent's importance. Inspired
by counterfactual reasoning, a larger change in reward caused by the randomized
action of agent indicates its higher importance. We model it as a MARL problem
to capture interactions across agents. Utilizing counterfactual reasoning, EMAI
learns the masking agents to identify important agents. Specifically, we define
the optimization function to minimize the reward difference before and after
action randomization and introduce sparsity constraints to encourage the
exploration of more action randomization of agents during training. The
experimental results in seven multi-agent tasks demonstratee that EMAI achieves
higher fidelity in explanations than baselines and provides more effective
guidance in practical applications concerning understanding policies, launching
attacks, and patching policies.

摘要：說明多代理系統 (MAS) 很緊急，因為這些系統在各種應用中越來越普遍。先前的研究已經提供了代理的動作或狀態的說明，但對於理解黑盒代理在 MAS 和整體團隊策略中的重要性還不足夠。為了彌補這個差距，我們提出了 EMAI，這是一種新穎的代理級別說明方法，用於評估個別代理的重要性。受到反事實推理的啟發，代理的隨機動作導致的獎勵的較大變化表明其重要性較高。我們將其建模為 MARL 問題，以捕捉代理之間的交互。利用反事實推理，EMAI 學習遮罩代理來識別重要代理。具體來說，我們定義優化函數，以最小化動作隨機化前後的獎勵差異，並引入稀疏約束，以鼓勵在訓練期間探索更多代理的動作隨機化。在七項多代理任務中的實驗結果表明，EMAI 在說明方面比基準線實現了更高的保真度，並在理解策略、發動攻擊和修補策略的實際應用中提供了更有效的指導。

##### **Microservices-Based Framework for Predictive Analytics and Real-time Performance Enhancement in Travel Reservation Systems**
2412.15616v1 by Biman Barua, M. Shamim Kaiser

The paper presents a framework of microservices-based architecture dedicated
to enhancing the performance of real-time travel reservation systems using the
power of predictive analytics. Traditional monolithic systems are bad at
scaling and performing with high loads, causing backup resources to be
underutilized along with delays. To overcome the above-stated problems, we
adopt a modularization approach in decoupling system components into
independent services that can grow or shrink according to demand. Our framework
also includes real-time predictive analytics, through machine learning models,
that optimize forecasting customer demand, dynamic pricing, as well as system
performance. With an experimental evaluation applying the approach, we could
show that the framework impacts metrics of performance such as response time,
throughput, transaction rate of success, and prediction accuracy compared to
their conventional counterparts. Not only does the microservices approach
improve scalability and fault tolerance like a usual architecture, but it also
brings along timely and accurate predictions, which imply a greater customer
satisfaction and efficiency of operation. The integration of real-time
analytics would lead to more intelligent decision-making, thereby improving the
response of the system along with the reliability it holds. A scalable,
efficient framework is offered by such a system to address the modern
challenges imposed by any form of travel reservation system while considering
other complex, data-driven industries as future applications. Future work will
be an investigation of advanced AI models and edge processing to further
improve the performance and robustness of the systems employed.

摘要：本文提出了一個基於微服務的架構，專門用於提升即時旅遊預訂系統的效能，並利用預測分析的力量。傳統的單體系統在擴充和執行高負載時表現不佳，導致備援資源未被充分利用，並伴隨著延遲。為了克服上述問題，我們採用模組化方式將系統元件解耦成獨立的服務，這些服務可以根據需求增長或縮減。我們的架構還包括即時預測分析，透過機器學習模型，最佳化預測客戶需求、動態定價，以及系統效能。透過採用此方法進行實驗評估，我們可以證明此架構會影響效能指標，例如回應時間、吞吐量、交易成功率和預測準確度，與傳統的對應架構相比。微服務方法不僅像一般架構那樣改善擴充性和容錯能力，還帶來及時且準確的預測，這意味著客戶滿意度和營運效率更高。整合即時分析將導致更明智的決策制定，從而改善系統的回應以及它所具有的可靠性。這樣的系統提供了一個可擴充、高效的架構，用於解決任何形式的旅遊預訂系統所帶來的現代挑戰，同時將其他複雜的資料驅動產業視為未來的應用。未來的研究將探討進階 AI 模型和邊緣處理，以進一步提升所採用系統的效能和穩健性。

##### **Multi-modal Agent Tuning: Building a VLM-Driven Agent for Efficient Tool Usage**
2412.15606v1 by Zhi Gao, Bofei Zhang, Pengxiang Li, Xiaojian Ma, Tao Yuan, Yue Fan, Yuwei Wu, Yunde Jia, Song-Chun Zhu, Qing Li

The advancement of large language models (LLMs) prompts the development of
multi-modal agents, which are used as a controller to call external tools,
providing a feasible way to solve practical tasks. In this paper, we propose a
multi-modal agent tuning method that automatically generates multi-modal
tool-usage data and tunes a vision-language model (VLM) as the controller for
powerful tool-usage reasoning. To preserve the data quality, we prompt the
GPT-4o mini model to generate queries, files, and trajectories, followed by
query-file and trajectory verifiers. Based on the data synthesis pipeline, we
collect the MM-Traj dataset that contains 20K tasks with trajectories of tool
usage. Then, we develop the T3-Agent via \underline{T}rajectory
\underline{T}uning on VLMs for \underline{T}ool usage using MM-Traj.
Evaluations on the GTA and GAIA benchmarks show that the T3-Agent consistently
achieves improvements on two popular VLMs: MiniCPM-V-8.5B and {Qwen2-VL-7B},
which outperforms untrained VLMs by $20\%$, showing the effectiveness of the
proposed data synthesis pipeline, leading to high-quality data for tool-usage
capabilities.

摘要：大型語言模型 (LLM) 的進步促使了多模態代理的發展，這些代理用作控制器來呼叫外部工具，提供了解決實際任務的可行方式。在本文中，我們提出了一種多模態代理調整方法，該方法自動生成多模態工具使用數據，並調整視覺語言模型 (VLM) 作為強大工具使用推理的控制器。為了保留數據質量，我們提示 GPT-4o 迷你模型生成查詢、文件和軌跡，然後再使用查詢文件和軌跡驗證器。根據數據合成管道，我們收集了 MM-Traj 數據集，其中包含 20K 個具有工具使用軌跡的任務。然後，我們通過使用 MM-Traj 在 VLM 上進行軌跡調整，開發了 T3-Agent，用於工具使用。對 GTA 和 GAIA 基準的評估表明，T3-Agent 在兩個流行的 VLM 上持續取得改進：MiniCPM-V-8.5B 和 {Qwen2-VL-7B}，其優於未訓練的 VLM 20%，顯示了所提出的數據合成管道的有效性，從而為工具使用能力提供了高質量的數據。

##### **Don't Do RAG: When Cache-Augmented Generation is All You Need for Knowledge Tasks**
2412.15605v1 by Brian J Chan, Chao-Ting Chen, Jui-Hung Cheng, Hen-Hsen Huang

Retrieval-augmented generation (RAG) has gained traction as a powerful
approach for enhancing language models by integrating external knowledge
sources. However, RAG introduces challenges such as retrieval latency,
potential errors in document selection, and increased system complexity. With
the advent of large language models (LLMs) featuring significantly extended
context windows, this paper proposes an alternative paradigm, cache-augmented
generation (CAG) that bypasses real-time retrieval. Our method involves
preloading all relevant resources, especially when the documents or knowledge
for retrieval are of a limited and manageable size, into the LLM's extended
context and caching its runtime parameters. During inference, the model
utilizes these preloaded parameters to answer queries without additional
retrieval steps. Comparative analyses reveal that CAG eliminates retrieval
latency and minimizes retrieval errors while maintaining context relevance.
Performance evaluations across multiple benchmarks highlight scenarios where
long-context LLMs either outperform or complement traditional RAG pipelines.
These findings suggest that, for certain applications, particularly those with
a constrained knowledge base, CAG provide a streamlined and efficient
alternative to RAG, achieving comparable or superior results with reduced
complexity.

摘要：擷取增強生成 (RAG) 作為一種強大的方法，透過整合外部知識來源來增強語言模型，已獲得廣泛採用。然而，RAG 引入了諸如擷取延遲、文件選取潛在錯誤和系統複雜性增加等挑戰。隨著具備顯著延伸內容視窗的大型語言模型 (LLM) 的出現，本文提出了一種替代範例，快取增強生成 (CAG)，它繞過了即時擷取。我們的做法涉及預先載入所有相關資源，尤其是當文件或擷取知識的規模有限且可控時，載入到 LLM 的延伸內容和快取其執行時期參數中。在推論期間，模型利用這些預先載入的參數來回答查詢，而無需額外的擷取步驟。比較分析顯示，CAG 消除了擷取延遲並將擷取錯誤降到最低，同時維持內容相關性。跨多個基準的效能評估突出了長內容 LLM 優於或補充傳統 RAG 管線的場景。這些發現表明，對於某些應用，特別是那些具有受限知識庫的應用，CAG 提供了一個簡化且有效的 RAG 替代方案，在降低複雜性的情況下實現了相當或更佳的結果。

##### **Dynamic Label Name Refinement for Few-Shot Dialogue Intent Classification**
2412.15603v1 by Gyutae Park, Ingeol Baek, ByeongJeong Kim, Joongbo Shin, Hwanhee Lee

Dialogue intent classification aims to identify the underlying purpose or
intent of a user's input in a conversation. Current intent classification
systems encounter considerable challenges, primarily due to the vast number of
possible intents and the significant semantic overlap among similar intent
classes. In this paper, we propose a novel approach to few-shot dialogue intent
classification through in-context learning, incorporating dynamic label
refinement to address these challenges. Our method retrieves relevant examples
for a test input from the training set and leverages a large language model to
dynamically refine intent labels based on semantic understanding, ensuring that
intents are clearly distinguishable from one another. Experimental results
demonstrate that our approach effectively resolves confusion between
semantically similar intents, resulting in significantly enhanced performance
across multiple datasets compared to baselines. We also show that our method
generates more interpretable intent labels, and has a better semantic coherence
in capturing underlying user intents compared to baselines.

摘要：對話意圖分類旨在識別使用者在對話中輸入內容的底層目的或意圖。目前的意圖分類系統會遇到相當大的挑戰，主要是因為可能的意圖數量龐大，以及類似的意圖類別之間存在顯著的語意重疊。在本文中，我們提出了一種透過情境學習進行少量樣本對話意圖分類的新方法，並結合動態標籤精煉來應對這些挑戰。我們的做法會從訓練集中擷取測試輸入相關的範例，並利用大型語言模型根據語意理解動態精煉意圖標籤，確保意圖彼此之間有明顯區別。實驗結果證明，與基準線相比，我們的做法有效解決了語意相似意圖之間的混淆，導致在多個資料集中的效能顯著提升。我們也證明了，我們的做法會產生更多可解釋的意圖標籤，並且在捕捉底層使用者意圖方面具有更好的語意一致性，優於基準線。

##### **SODor: Long-Term EEG Partitioning for Seizure Onset Detection**
2412.15598v1 by Zheng Chen, Yasuko Matsubara, Yasushi Sakurai, Jimeng Sun

Deep learning models have recently shown great success in classifying
epileptic patients using EEG recordings. Unfortunately, classification-based
methods lack a sound mechanism to detect the onset of seizure events. In this
work, we propose a two-stage framework, \method, that explicitly models seizure
onset through a novel task formulation of subsequence clustering. Given an EEG
sequence, the framework first learns a set of second-level embeddings with
label supervision. It then employs model-based clustering to explicitly capture
long-term temporal dependencies in EEG sequences and identify meaningful
subsequences. Epochs within a subsequence share a common cluster assignment
(normal or seizure), with cluster or state transitions representing successful
onset detections. Extensive experiments on three datasets demonstrate that our
method can correct misclassifications, achieving 5%-11% classification
improvements over other baselines and accurately detecting seizure onsets.

摘要：深度學習模型最近在使用腦電圖記錄對癲癇患者進行分類方面取得了巨大的成功。不幸的是，基於分類的方法缺乏檢測癲癇發作發作的健全機制。在這項工作中，我們提出了一個兩階段框架，\method，它通過子序列聚類的新任務表述明確地模擬癲癇發作。給定一個腦電圖序列，該框架首先學習一組具有標籤監督的二級嵌入。然後，它採用基於模型的聚類來明確捕獲腦電圖序列中的長期時間依賴性，並識別有意義的子序列。子序列中的各個時期共享一個公共群集分配（正常或癲癇發作），群集或狀態轉換表示成功的發作檢測。在三個數據集上的大量實驗表明，我們的模型可以糾正錯誤分類，與其他基準相比，分類改進了 5%-11%，並準確檢測癲癇發作。

##### **Mask-RadarNet: Enhancing Transformer With Spatial-Temporal Semantic Context for Radar Object Detection in Autonomous Driving**
2412.15595v1 by Yuzhi Wu, Jun Liu, Guangfeng Jiang, Weijian Liu, Danilo Orlando

As a cost-effective and robust technology, automotive radar has seen steady
improvement during the last years, making it an appealing complement to
commonly used sensors like camera and LiDAR in autonomous driving. Radio
frequency data with rich semantic information are attracting more and more
attention. Most current radar-based models take radio frequency image sequences
as the input. However, these models heavily rely on convolutional neural
networks and leave out the spatial-temporal semantic context during the
encoding stage. To solve these problems, we propose a model called
Mask-RadarNet to fully utilize the hierarchical semantic features from the
input radar data. Mask-RadarNet exploits the combination of interleaved
convolution and attention operations to replace the traditional architecture in
transformer-based models. In addition, patch shift is introduced to the
Mask-RadarNet for efficient spatial-temporal feature learning. By shifting part
of patches with a specific mosaic pattern in the temporal dimension,
Mask-RadarNet achieves competitive performance while reducing the computational
burden of the spatial-temporal modeling. In order to capture the
spatial-temporal semantic contextual information, we design the class masking
attention module (CMAM) in our encoder. Moreover, a lightweight auxiliary
decoder is added to our model to aggregate prior maps generated from the CMAM.
Experiments on the CRUW dataset demonstrate the superiority of the proposed
method to some state-of-the-art radar-based object detection algorithms. With
relatively lower computational complexity and fewer parameters, the proposed
Mask-RadarNet achieves higher recognition accuracy for object detection in
autonomous driving.

摘要：作為一種經濟且強大的技術，汽車雷達在過去幾年中穩步改進，使其成為自動駕駛中相機和 LiDAR 等常用感測器的誘人補充。具有豐富語義資訊的無線電頻率數據正吸引越來越多的關注。目前大多數基於雷達的模型將無線電頻率影像序列作為輸入。然而，這些模型嚴重依賴卷積神經網路，並在編碼階段遺漏了時空語義背景。為了解決這些問題，我們提出了一個名為 Mask-RadarNet 的模型，以充分利用輸入雷達數據中的階層語義特徵。Mask-RadarNet 利用交錯卷積和注意力運算的組合來替換基於Transformer的模型中的傳統架構。此外，Patch Shift 被引入 Mask-RadarNet 以進行有效的時空特徵學習。通過在時間維度中使用特定的馬賽克模式轉移部分 Patch，Mask-RadarNet 在降低時空建模的計算負擔的同時實現了有競爭力的性能。為了擷取時空語義背景資訊，我們在編碼器中設計了類別遮罩注意力模組 (CMAM)。此外，我們的模型中還新增了一個輕量級輔助解碼器，以聚合從 CMAM 生成的先驗地圖。CRUW 資料集上的實驗證明了所提出的方法優於一些最先進的基於雷達的物體偵測演算法。在計算複雜度和參數相對較低的情況下，所提出的 Mask-RadarNet 在自動駕駛中的物體偵測中實現了更高的辨識準確度。

##### **Template-Driven LLM-Paraphrased Framework for Tabular Math Word Problem Generation**
2412.15594v1 by Xiaoqiang Kang, Zimu Wang, Xiaobo Jin, Wei Wang, Kaizhu Huang, Qiufeng Wang

Solving tabular math word problems (TMWPs) has become a critical role in
evaluating the mathematical reasoning ability of large language models (LLMs),
where large-scale TMWP samples are commonly required for LLM fine-tuning. Since
the collection of high-quality TMWP datasets is costly and time-consuming,
recent research has concentrated on automatic TMWP generation. However, current
generated samples usually suffer from issues of either correctness or
diversity. In this paper, we propose a Template-driven LLM-paraphrased (TeLL)
framework for generating high-quality TMWP samples with diverse backgrounds and
accurate tables, questions, answers, and solutions. To this end, we first
extract templates from existing real samples to generate initial problems,
ensuring correctness. Then, we adopt an LLM to extend templates and paraphrase
problems, obtaining diverse TMWP samples. Furthermore, we find the reasoning
annotation is important for solving TMWPs. Therefore, we propose to enrich each
solution with illustrative reasoning steps. Through the proposed framework, we
construct a high-quality dataset TabMWP-TeLL by adhering to the question types
in the TabMWP dataset, and we conduct extensive experiments on a variety of
LLMs to demonstrate the effectiveness of TabMWP-TeLL in improving TMWP solving
performance. The code and data of this paper are available at:
https://github.com/Jason8Kang/TELL.

摘要：<paragraph>解決表格數學文字題 (TMWP) 已成為評估大型語言模型 (LLM) 的數學推理能力的一項關鍵角色，其中通常需要大規模的 TMWP 樣本進行 LLM 微調。由於收集高品質的 TMWP 資料集既昂貴又費時，因此最近的研究集中在自動化 TMWP 生成上。然而，目前產生的樣本通常會遇到正確性或多樣性的問題。在本文中，我們提出一個由範本驅動的 LLM 釋義 (TeLL) 架構，用於生成具有多樣化背景和準確表格、問題、答案和解決方案的高品質 TMWP 樣本。為此，我們首先從現有的真實樣本中提取範本以生成初始問題，確保正確性。然後，我們採用 LLM 來擴充範本和釋義問題，獲得多樣化的 TMWP 樣本。此外，我們發現推理註解對於解決 TMWP 非常重要。因此，我們建議用說明性的推理步驟豐富每個解決方案。透過所提出的架構，我們構建了一個高品質的資料集 TabMWP-TeLL，並遵循 TabMWP 資料集中的問題類型，並對各種 LLM 進行廣泛的實驗，以證明 TabMWP-TeLL 在改善 TMWP 解決效能方面的有效性。本文的程式碼和資料可在以下位置取得：
https://github.com/Jason8Kang/TELL。</paragraph>

##### **Machine Learning Techniques for Pattern Recognition in High-Dimensional Data Mining**
2412.15593v1 by Pochun Li

This paper proposes a frequent pattern data mining algorithm based on support
vector machine (SVM), aiming to solve the performance bottleneck of traditional
frequent pattern mining algorithms in high-dimensional and sparse data
environments. By converting the frequent pattern mining task into a
classification problem, the SVM model is introduced to improve the accuracy and
robustness of pattern extraction. In terms of method design, the kernel
function is used to map the data to a high-dimensional feature space, so as to
construct the optimal classification hyperplane, realize the nonlinear
separation of patterns and the accurate mining of frequent items. In the
experiment, two public datasets, Retail and Mushroom, were selected to compare
and analyze the proposed algorithm with traditional FP-Growth, FP-Tree,
decision tree and random forest models. The experimental results show that the
algorithm in this paper is significantly better than the traditional model in
terms of three key indicators: support, confidence and lift, showing strong
pattern recognition ability and rule extraction effect. The study shows that
the SVM model has excellent performance advantages in an environment with high
data sparsity and a large number of transactions, and can effectively cope with
complex pattern mining tasks. At the same time, this paper also points out the
potential direction of future research, including the introduction of deep
learning and ensemble learning frameworks to further improve the scalability
and adaptability of the algorithm. This research not only provides a new idea
for frequent pattern mining, but also provides important technical support for
solving pattern discovery and association rule mining problems in practical
applications.

摘要：<paragraph>本文提出了一種基於支持向量機 (SVM) 的頻繁模式數據挖掘演算法，旨在解決傳統頻繁模式挖掘演算法在高維度和稀疏數據環境中的效能瓶頸。通過將頻繁模式挖掘任務轉換為分類問題，引入了 SVM 模型以提高模式提取的準確性和穩健性。在方法設計方面，利用核函數將數據映射到高維度特徵空間，從而構造最優分類超平面，實現模式的非線性分離和頻繁項的準確挖掘。在實驗中，選取了兩個公開數據集 Retail 和 Mushroom，對所提出的演算法與傳統的 FP-Growth、FP-Tree、決策樹和隨機森林模型進行了比較和分析。實驗結果表明，本文演算法在支持度、可信度和提升度三個關鍵指標上均顯著優於傳統模型，表現出強大的模式識別能力和規則提取效果。研究表明，SVM 模型在數據稀疏度高、交易量大的環境中具有優異的效能優勢，能有效應對複雜的模式挖掘任務。同時，本文也指出了未來研究的潛在方向，包括引入深度學習和集成學習框架以進一步提高演算法的可擴展性和適應性。本研究不僅為頻繁模式挖掘提供了新思路，也為解決實際應用中的模式發現和關聯規則挖掘問題提供了重要的技術支撐。</paragraph>

##### **Pre-training Graph Neural Networks on Molecules by Using Subgraph-Conditioned Graph Information Bottleneck**
2412.15589v1 by Van Thuy Hoang, O-Joun Lee

This study aims to build a pre-trained Graph Neural Network (GNN) model on
molecules without human annotations or prior knowledge. Although various
attempts have been proposed to overcome limitations in acquiring labeled
molecules, the previous pre-training methods still rely on semantic subgraphs,
i.e., functional groups. Only focusing on the functional groups could overlook
the graph-level distinctions. The key challenge to build a pre-trained GNN on
molecules is how to (1) generate well-distinguished graph-level representations
and (2) automatically discover the functional groups without prior knowledge.
To solve it, we propose a novel Subgraph-conditioned Graph Information
Bottleneck, named S-CGIB, for pre-training GNNs to recognize core subgraphs
(graph cores) and significant subgraphs. The main idea is that the graph cores
contain compressed and sufficient information that could generate
well-distinguished graph-level representations and reconstruct the input graph
conditioned on significant subgraphs across molecules under the S-CGIB
principle. To discover significant subgraphs without prior knowledge about
functional groups, we propose generating a set of functional group candidates,
i.e., ego networks, and using an attention-based interaction between the graph
core and the candidates. Despite being identified from self-supervised
learning, our learned subgraphs match the real-world functional groups.
Extensive experiments on molecule datasets across various domains demonstrate
the superiority of S-CGIB.

摘要：本研究旨在建立一個預訓練圖形神經網路 (GNN) 模型，在分子上無需人工註解或先驗知識。雖然已提出各種嘗試來克服獲取標記分子的限制，但先前的預訓練方法仍然依賴於語義子圖，即官能基。僅關注官能基可能會忽略圖形層面的區別。在分子上建立預訓練 GNN 的關鍵挑戰是如何 (1) 生成區分良好的圖形層面表示，以及 (2) 在沒有先驗知識的情況下自動發現官能基。為了解決此問題，我們提出一個名為 S-CGIB 的新子圖條件圖形資訊瓶頸，用於預訓練 GNN 以識別核心子圖（圖形核心）和重要子圖。主要想法是圖形核心包含壓縮且足夠的資訊，可以在 S-CGIB 原則下生成區分良好的圖形層面表示，並根據分子上的重要子圖重建輸入圖形。為了在沒有關於官能基的先驗知識的情況下發現重要子圖，我們建議生成一組官能基候選，即自我網路，並使用基於注意力的圖形核心和候選之間的交互作用。儘管從自我監督學習中識別出來，但我們學習到的子圖與現實世界的官能基相匹配。跨越各種領域的分子資料集上的廣泛實驗證明了 S-CGIB 的優越性。

##### **NeSyCoCo: A Neuro-Symbolic Concept Composer for Compositional Generalization**
2412.15588v1 by Danial Kamali, Elham J. Barezi, Parisa Kordjamshidi

Compositional generalization is crucial for artificial intelligence agents to
solve complex vision-language reasoning tasks. Neuro-symbolic approaches have
demonstrated promise in capturing compositional structures, but they face
critical challenges: (a) reliance on predefined predicates for symbolic
representations that limit adaptability, (b) difficulty in extracting
predicates from raw data, and (c) using non-differentiable operations for
combining primitive concepts. To address these issues, we propose NeSyCoCo, a
neuro-symbolic framework that leverages large language models (LLMs) to
generate symbolic representations and map them to differentiable neural
computations. NeSyCoCo introduces three innovations: (a) augmenting natural
language inputs with dependency structures to enhance the alignment with
symbolic representations, (b) employing distributed word representations to
link diverse, linguistically motivated logical predicates to neural modules,
and (c) using the soft composition of normalized predicate scores to align
symbolic and differentiable reasoning. Our framework achieves state-of-the-art
results on the ReaSCAN and CLEVR-CoGenT compositional generalization benchmarks
and demonstrates robust performance with novel concepts in the CLEVR-SYN
benchmark.

摘要：組合式泛化對於人工智慧代理人解決複雜的視覺語言推理任務至關重要。神經符號方法已證明在捕捉組合結構方面很有前景，但它們面臨嚴峻的挑戰：(a) 依賴於限制適應性的符號表示的預定義謂詞，(b) 難以從原始資料中提取謂詞，以及 (c) 使用不可微分的運算來組合原始概念。為了解決這些問題，我們提出了 NeSyCoCo，一個神經符號框架，它利用大型語言模型 (LLM) 來產生符號表示並將它們映射到可微分的類神經運算。NeSyCoCo 引入了三項創新：(a) 用依賴結構擴充自然語言輸入，以增強與符號表示的一致性，(b) 使用分散的詞語表示將不同的、受語言激勵的邏輯謂詞連結到神經模組，以及 (c) 使用正規化謂詞分數的軟組合來對齊符號和可微分的推理。我們的框架在 ReaSCAN 和 CLEVR-CoGenT 組合式泛化基準上達到了最先進的結果，並在 CLEVR-SYN 基準中展示了新概念的強大效能。

##### **Score-based Generative Diffusion Models for Social Recommendations**
2412.15579v1 by Chengyi Liu, Jiahao Zhang, Shijie Wang, Wenqi Fan, Qing Li

With the prevalence of social networks on online platforms, social
recommendation has become a vital technique for enhancing personalized
recommendations. The effectiveness of social recommendations largely relies on
the social homophily assumption, which presumes that individuals with social
connections often share similar preferences. However, this foundational premise
has been recently challenged due to the inherent complexity and noise present
in real-world social networks. In this paper, we tackle the low social
homophily challenge from an innovative generative perspective, directly
generating optimal user social representations that maximize consistency with
collaborative signals. Specifically, we propose the Score-based Generative
Model for Social Recommendation (SGSR), which effectively adapts the Stochastic
Differential Equation (SDE)-based diffusion models for social recommendations.
To better fit the recommendation context, SGSR employs a joint curriculum
training strategy to mitigate challenges related to missing supervision signals
and leverages self-supervised learning techniques to align knowledge across
social and collaborative domains. Extensive experiments on real-world datasets
demonstrate the effectiveness of our approach in filtering redundant social
information and improving recommendation performance.

摘要：隨著社群網路在線上平台的盛行，社群推薦已成為增強個人化推薦的重要技術。社群推薦的有效性在很大程度上依賴於社群同質性假設，該假設認為具有社群連結的個人通常有類似的偏好。然而，由於現實世界的社群網路固有的複雜性和雜訊，這個基本前提最近受到挑戰。在本文中，我們從創新的生成觀點來應對社群同質性低落的挑戰，直接生成最佳使用者社群表徵，以最大化與協同訊號的一致性。具體來說，我們提出了基於計分的社群推薦生成模型 (SGSR)，它有效地調整了基於隨機微分方程 (SDE) 的擴散模型以進行社群推薦。為了更好地適應推薦情境，SGSR 採用聯合課程訓練策略來緩解與遺失監督訊號相關的挑戰，並利用自我監督學習技術來調整社群和協同領域的知識。在真實世界資料集上的大量實驗證明了我們的方法在過濾冗餘社群資訊和改善推薦效能方面的有效性。

##### **Continual Learning Using a Kernel-Based Method Over Foundation Models**
2412.15571v1 by Saleh Momeni, Sahisnu Mazumder, Bing Liu

Continual learning (CL) learns a sequence of tasks incrementally. This paper
studies the challenging CL setting of class-incremental learning (CIL). CIL has
two key challenges: catastrophic forgetting (CF) and inter-task class
separation (ICS). Despite numerous proposed methods, these issues remain
persistent obstacles. This paper proposes a novel CIL method, called Kernel
Linear Discriminant Analysis (KLDA), that can effectively avoid CF and ICS
problems. It leverages only the powerful features learned in a foundation model
(FM). However, directly using these features proves suboptimal. To address
this, KLDA incorporates the Radial Basis Function (RBF) kernel and its Random
Fourier Features (RFF) to enhance the feature representations from the FM,
leading to improved performance. When a new task arrives, KLDA computes only
the mean for each class in the task and updates a shared covariance matrix for
all learned classes based on the kernelized features. Classification is
performed using Linear Discriminant Analysis. Our empirical evaluation using
text and image classification datasets demonstrates that KLDA significantly
outperforms baselines. Remarkably, without relying on replay data, KLDA
achieves accuracy comparable to joint training of all classes, which is
considered the upper bound for CIL performance. The KLDA code is available at
https://github.com/salehmomeni/klda.

摘要：持續學習 (CL) 遞增地學習一連串任務。本文探討類別遞增學習 (CIL) 的具挑戰性 CL 設定。CIL 有兩個主要挑戰：災難性遺忘 (CF) 和任務間類別分離 (ICS)。儘管提出了許多方法，但這些問題仍然是持續存在的障礙。本文提出了一種新的 CIL 方法，稱為核線性判別分析 (KLDA)，可以有效避免 CF 和 ICS 問題。它只利用在基礎模型 (FM) 中學習到的強大特徵。但是，直接使用這些特徵被證明次佳。為了解決這個問題，KLDA 結合了徑向基函數 (RBF) 核及其隨機傅立葉特徵 (RFF) 來增強 FM 的特徵表示，從而提高效能。當新任務到達時，KLDA 只計算任務中每個類別的平均值，並根據核特徵更新所有已學習類別的共享協方差矩陣。分類是使用線性判別分析執行的。我們使用文字和影像分類資料集進行的實證評估表明，KLDA 明顯優於基準。值得注意的是，在不依賴重播資料的情況下，KLDA 達到了與所有類別聯合訓練相當的準確度，這被認為是 CIL 效能的上限。KLDA 程式碼可於 https://github.com/salehmomeni/klda 取得。

##### **In-context Continual Learning Assisted by an External Continual Learner**
2412.15563v1 by Saleh Momeni, Sahisnu Mazumder, Zixuan Ke, Bing Liu

Existing continual learning (CL) methods mainly rely on fine-tuning or
adapting large language models (LLMs). They still suffer from catastrophic
forgetting (CF). Little work has been done to exploit in-context learning (ICL)
to leverage the extensive knowledge within LLMs for CL without updating any
parameters. However, incrementally learning each new task in ICL necessitates
adding training examples from each class of the task to the prompt, which
hampers scalability as the prompt length increases. This issue not only leads
to excessively long prompts that exceed the input token limit of the underlying
LLM but also degrades the model's performance due to the overextended context.
To address this, we introduce InCA, a novel approach that integrates an
external continual learner (ECL) with ICL to enable scalable CL without CF. The
ECL is built incrementally to pre-select a small subset of likely classes for
each test instance. By restricting the ICL prompt to only these selected
classes, InCA prevents prompt lengths from becoming excessively long, while
maintaining high performance. Experimental results demonstrate that InCA
significantly outperforms existing CL baselines, achieving substantial
performance gains.

摘要：現有的持續學習 (CL) 方法主要依賴微調或調整大型語言模型 (LLM)。它們仍然會發生災難性遺忘 (CF)。鮮少有研究利用情境學習 (ICL) 來利用 LLM 中的廣泛知識進行 CL，而無需更新任何參數。然而，在 ICL 中逐步學習每項新任務都需要將每個任務類別的訓練範例新增到提示中，這會隨著提示長度增加而阻礙可擴充性。此問題不僅會導致過長的提示，超過基礎 LLM 的輸入權杖限制，還會因為過長的內容而降低模型的效能。為了解決此問題，我們引進 InCA，這是一種創新的方法，將外部持續學習器 (ECL) 與 ICL 整合，以啟用無 CF 的可擴充 CL。ECL 逐漸建置，以預先選擇每個測試實例中一小部分可能的類別。透過將 ICL 提示限制在這些選定的類別中，InCA 可防止提示長度過長，同時維持高效能。實驗結果證明，InCA 明顯優於現有的 CL 基準，並獲得顯著的效能提升。

##### **MORTAR: Metamorphic Multi-turn Testing for LLM-based Dialogue Systems**
2412.15557v1 by Guoxiang Guo, Aldeida Aleti, Neelofar Neelofar, Chakkrit Tantithamthavorn

With the widespread application of LLM-based dialogue systems in daily life,
quality assurance has become more important than ever. Recent research has
successfully introduced methods to identify unexpected behaviour in single-turn
scenarios. However, multi-turn dialogue testing remains underexplored, with the
Oracle problem in multi-turn testing posing a persistent challenge for dialogue
system developers and researchers. In this paper, we propose MORTAR, a
MetamORphic multi-TuRn diAlogue testing appRoach, which mitigates the test
oracle problem in the assessment of LLM-based dialogue systems. MORTAR
automates the generation of follow-up question-answer (QA) dialogue test cases
with multiple dialogue-level perturbations and metamorphic relations. MORTAR
employs a novel knowledge graph-based dialogue information model which
effectively generates perturbed dialogue test datasets and detects bugs of
multi-turn dialogue systems in a low-cost manner. The proposed approach does
not require an LLM as a judge, eliminating potential of any biases in the
evaluation step. According to the experiment results on multiple LLM-based
dialogue systems and comparisons with single-turn metamorphic testing
approaches, MORTAR explores more unique bugs in LLM-based dialogue systems,
especially for severe bugs that MORTAR detects up to four times more unique
bugs than the most effective existing metamorphic testing approach.

摘要：隨著基於 LLM 的對話系統在日常生活中廣泛應用，品質保證比以往任何時候都更為重要。最近的研究已成功引入方法來識別單輪場景中的意外行為。然而，多輪對話測試仍未得到充分探索，多輪測試中的 Oracle 問題對話系統開發人員和研究人員構成了持續的挑戰。在本文中，我們提出 MORTAR，一種變形多輪對話測試應用方法，它減輕了在基於 LLM 的對話系統評估中的測試 Oracle 問題。MORTAR 自動生成後續問題回答 (QA) 對話測試案例，具有多個對話層級擾動和變形關係。MORTAR 採用新穎的基於知識圖譜的對話資訊模型，它有效地生成擾動的對話測試資料集，並以低成本的方式偵測多輪對話系統的錯誤。所提出的方法不需要 LLM 作為評審，消除了評估步驟中任何偏見的可能性。根據對多個基於 LLM 的對話系統的實驗結果以及與單輪變形測試方法的比較，MORTAR 探索了基於 LLM 的對話系統中更多獨特的錯誤，特別是對於嚴重的錯誤，MORTAR 偵測到的獨特錯誤比最有效的現有變形測試方法多達四倍。

##### **Architecture-Aware Learning Curve Extrapolation via Graph Ordinary Differential Equation**
2412.15554v1 by Yanna Ding, Zijie Huang, Xiao Shou, Yihang Guo, Yizhou Sun, Jianxi Gao

Learning curve extrapolation predicts neural network performance from early
training epochs and has been applied to accelerate AutoML, facilitating
hyperparameter tuning and neural architecture search. However, existing methods
typically model the evolution of learning curves in isolation, neglecting the
impact of neural network (NN) architectures, which influence the loss landscape
and learning trajectories. In this work, we explore whether incorporating
neural network architecture improves learning curve modeling and how to
effectively integrate this architectural information. Motivated by the
dynamical system view of optimization, we propose a novel architecture-aware
neural differential equation model to forecast learning curves continuously. We
empirically demonstrate its ability to capture the general trend of fluctuating
learning curves while quantifying uncertainty through variational parameters.
Our model outperforms current state-of-the-art learning curve extrapolation
methods and pure time-series modeling approaches for both MLP and CNN-based
learning curves. Additionally, we explore the applicability of our method in
Neural Architecture Search scenarios, such as training configuration ranking.

摘要：學習曲線外推法從早期訓練時期預測神經網路效能，並已應用於加速自動機器學習，促進超參數調整和神經架構搜尋。然而，現有方法通常孤立地建構學習曲線的演進模型，忽略了神經網路 (NN) 架構的影響，而這些架構會影響損失情況和學習軌跡。在這項工作中，我們探討將神經網路架構納入考量是否能改善學習曲線建模，以及如何有效整合此架構資訊。基於最佳化的動態系統觀點，我們提出一個創新的、具備架構感知能力的神經微分方程模型，以持續預測學習曲線。我們透過變異參數量化不確定性，實證展示其捕捉波動學習曲線一般趨勢的能力。我們的模型優於目前最先進的學習曲線外推法和純時序建模方法，適用於基於多層感知器 (MLP) 和卷積神經網路 (CNN) 的學習曲線。此外，我們探討了我們的方法在神經架構搜尋場景中的適用性，例如訓練組態排名。

##### **NGQA: A Nutritional Graph Question Answering Benchmark for Personalized Health-aware Nutritional Reasoning**
2412.15547v1 by Zheyuan Zhang, Yiyang Li, Nhi Ha Lan Le, Zehong Wang, Tianyi Ma, Vincent Galassi, Keerthiram Murugesan, Nuno Moniz, Werner Geyer, Nitesh V Chawla, Chuxu Zhang, Yanfang Ye

Diet plays a critical role in human health, yet tailoring dietary reasoning
to individual health conditions remains a major challenge. Nutrition Question
Answering (QA) has emerged as a popular method for addressing this problem.
However, current research faces two critical limitations. On one hand, the
absence of datasets involving user-specific medical information severely limits
\textit{personalization}. This challenge is further compounded by the wide
variability in individual health needs. On the other hand, while large language
models (LLMs), a popular solution for this task, demonstrate strong reasoning
abilities, they struggle with the domain-specific complexities of personalized
healthy dietary reasoning, and existing benchmarks fail to capture these
challenges. To address these gaps, we introduce the Nutritional Graph Question
Answering (NGQA) benchmark, the first graph question answering dataset designed
for personalized nutritional health reasoning. NGQA leverages data from the
National Health and Nutrition Examination Survey (NHANES) and the Food and
Nutrient Database for Dietary Studies (FNDDS) to evaluate whether a food is
healthy for a specific user, supported by explanations of the key contributing
nutrients. The benchmark incorporates three question complexity settings and
evaluates reasoning across three downstream tasks. Extensive experiments with
LLM backbones and baseline models demonstrate that the NGQA benchmark
effectively challenges existing models. In sum, NGQA addresses a critical
real-world problem while advancing GraphQA research with a novel
domain-specific benchmark.

摘要：飲食在人類健康中扮演著至關重要的角色，然而根據個人健康狀況調整飲食推理仍然是一項重大的挑戰。營養問題問答 (QA) 已成為解決此問題的流行方法。不過，目前的研究面臨兩項重大的限制。一方面，缺乏包含使用者特定醫療資訊的資料集嚴重限制了「個人化」。這個挑戰進一步受到個人健康需求廣泛變異的影響。另一方面，雖然大型語言模型 (LLM) 是此任務的熱門解決方案，展示出強大的推理能力，但它們在個人化健康飲食推理的特定領域複雜性上仍有困難，而現有的基準也無法捕捉這些挑戰。為了解決這些差距，我們引入了營養圖表問答 (NGQA) 基準，這是第一個專為個人化營養健康推理設計的圖表問答資料集。NGQA 利用國家健康與營養檢查調查 (NHANES) 和飲食研究食物與營養資料庫 (FNDDS) 的資料，評估食物是否對特定使用者健康，並說明主要貢獻營養素。此基準納入了三個問題複雜度設定，並評估三個下游任務的推理。使用 LLM 主幹和基線模型進行的廣泛實驗證明，NGQA 基準有效挑戰了現有模型。總之，NGQA 解決了一個重大的現實世界問題，同時透過新穎的特定領域基準推動了 GraphQA 研究。

##### **VLM-RL: A Unified Vision Language Models and Reinforcement Learning Framework for Safe Autonomous Driving**
2412.15544v1 by Zilin Huang, Zihao Sheng, Yansong Qu, Junwei You, Sikai Chen

In recent years, reinforcement learning (RL)-based methods for learning
driving policies have gained increasing attention in the autonomous driving
community and have achieved remarkable progress in various driving scenarios.
However, traditional RL approaches rely on manually engineered rewards, which
require extensive human effort and often lack generalizability. To address
these limitations, we propose \textbf{VLM-RL}, a unified framework that
integrates pre-trained Vision-Language Models (VLMs) with RL to generate reward
signals using image observation and natural language goals. The core of VLM-RL
is the contrasting language goal (CLG)-as-reward paradigm, which uses positive
and negative language goals to generate semantic rewards. We further introduce
a hierarchical reward synthesis approach that combines CLG-based semantic
rewards with vehicle state information, improving reward stability and offering
a more comprehensive reward signal. Additionally, a batch-processing technique
is employed to optimize computational efficiency during training. Extensive
experiments in the CARLA simulator demonstrate that VLM-RL outperforms
state-of-the-art baselines, achieving a 10.5\% reduction in collision rate, a
104.6\% increase in route completion rate, and robust generalization to unseen
driving scenarios. Furthermore, VLM-RL can seamlessly integrate almost any
standard RL algorithms, potentially revolutionizing the existing RL paradigm
that relies on manual reward engineering and enabling continuous performance
improvements. The demo video and code can be accessed at:
https://zilin-huang.github.io/VLM-RL-website.

摘要：近年来，基于强化学习 (RL) 的学习驾驶策略的方法在自动驾驶社区中受到越来越多的关注，并在各种驾驶场景中取得了显著进展。然而，传统的 RL 方法依赖于人工设计的奖励，这需要大量的人力，并且通常缺乏泛化性。为了解决这些限制，我们提出了 \textbf{VLM-RL}，这是一个统一的框架，它将预先训练的视觉语言模型 (VLM) 与 RL 集成在一起，以使用图像观察和自然语言目标生成奖励信号。VLM-RL 的核心是对比语言目标 (CLG) 作为奖励的范例，它使用积极和消极的语言目标来生成语义奖励。我们进一步引入了一种分层奖励合成方法，它将基于 CLG 的语义奖励与车辆状态信息相结合，从而提高了奖励稳定性并提供了更全面的奖励信号。此外，在训练期间采用批处理技术来优化计算效率。在 CARLA 模拟器中进行的广泛实验表明，VLM-RL 优于最先进的基准，碰撞率降低了 10.5%，路线完成率提高了 104.6%，并且对看不见的驾驶场景具有鲁棒的泛化能力。此外，VLM-RL 可以无缝集成几乎任何标准 RL 算法，有可能彻底改变依赖于手动奖励工程的现有 RL 范例，并实现持续的性能改进。可以在以下网址访问演示视频和代码：https://zilin-huang.github.io/VLM-RL-website。

##### **ChangeDiff: A Multi-Temporal Change Detection Data Generator with Flexible Text Prompts via Diffusion Model**
2412.15541v1 by Qi Zang, Jiayi Yang, Shuang Wang, Dong Zhao, Wenjun Yi, Zhun Zhong

Data-driven deep learning models have enabled tremendous progress in change
detection (CD) with the support of pixel-level annotations. However, collecting
diverse data and manually annotating them is costly, laborious, and
knowledge-intensive. Existing generative methods for CD data synthesis show
competitive potential in addressing this issue but still face the following
limitations: 1) difficulty in flexibly controlling change events, 2) dependence
on additional data to train the data generators, 3) focus on specific change
detection tasks. To this end, this paper focuses on the semantic CD (SCD) task
and develops a multi-temporal SCD data generator ChangeDiff by exploring
powerful diffusion models. ChangeDiff innovatively generates change data in two
steps: first, it uses text prompts and a text-to-layout (T2L) model to create
continuous layouts, and then it employs layout-to-image (L2I) to convert these
layouts into images. Specifically, we propose multi-class distribution-guided
text prompts (MCDG-TP), allowing for layouts to be generated flexibly through
controllable classes and their corresponding ratios. Subsequently, to
generalize the T2L model to the proposed MCDG-TP, a class distribution
refinement loss is further designed as training supervision. %For the former, a
multi-classdistribution-guided text prompt (MCDG-TP) is proposed to complement
via controllable classes and ratios. To generalize the text-to-image diffusion
model to the proposed MCDG-TP, a class distribution refinement loss is designed
as training supervision. For the latter, MCDG-TP in three modes is proposed to
synthesize new layout masks from various texts. Our generated data shows
significant progress in temporal continuity, spatial diversity, and quality
realism, empowering change detectors with accuracy and transferability. The
code is available at https://github.com/DZhaoXd/ChangeDiff

摘要：<paragraph>資料驅動深度學習模型在變更偵測 (CD) 中實現了巨大的進展，並在像素級註解的支援下進行。然而，收集多樣化的資料並手動註解它們既昂貴又費力，且需要專業知識。現有的 CD 資料合成生成方法顯示了解決此問題的競爭潛力，但仍面臨以下限制：1) 難以靈活控制變更事件，2) 依賴額外資料來訓練資料產生器，3) 專注於特定的變更偵測任務。為此，本文專注於語義 CD (SCD) 任務，並透過探索強大的擴散模型開發了多時序 SCD 資料產生器 ChangeDiff。ChangeDiff 創新地分兩步產生變更資料：首先，它使用文字提示和文字轉版面 (T2L) 模型來建立連續版面，然後採用版面轉影像 (L2I) 將這些版面轉換為影像。具體來說，我們提出了多類別分佈引導文字提示 (MCDG-TP)，允許透過可控制的類別及其對應比率靈活地產生版面。隨後，為了將 T2L 模型推廣到所提出的 MCDG-TP，進一步設計了類別分佈調整損失作為訓練監督。對於前者，提出了多類別分佈引導文字提示 (MCDG-TP) 以透過可控制的類別和比率進行補充。為了將文字轉影像擴散模型推廣到所提出的 MCDG-TP，設計了類別分佈調整損失作為訓練監督。對於後者，提出了三種模式的 MCDG-TP，以從各種文字中合成新的版面遮罩。我們產生的資料在時間連續性、空間多樣性和品質真實性方面顯示出顯著的進展，賦予變更偵測器準確性和可轉移性。程式碼可於 https://github.com/DZhaoXd/ChangeDiff 取得</paragraph>

##### **MRAG: A Modular Retrieval Framework for Time-Sensitive Question Answering**
2412.15540v1 by Zhang Siyue, Xue Yuxiang, Zhang Yiming, Wu Xiaobao, Luu Anh Tuan, Zhao Chen

Understanding temporal relations and answering time-sensitive questions is
crucial yet a challenging task for question-answering systems powered by large
language models (LLMs). Existing approaches either update the parametric
knowledge of LLMs with new facts, which is resource-intensive and often
impractical, or integrate LLMs with external knowledge retrieval (i.e.,
retrieval-augmented generation). However, off-the-shelf retrievers often
struggle to identify relevant documents that require intensive temporal
reasoning. To systematically study time-sensitive question answering, we
introduce the TempRAGEval benchmark, which repurposes existing datasets by
incorporating temporal perturbations and gold evidence labels. As anticipated,
all existing retrieval methods struggle with these temporal reasoning-intensive
questions. We further propose Modular Retrieval (MRAG), a trainless framework
that includes three modules: (1) Question Processing that decomposes question
into a main content and a temporal constraint; (2) Retrieval and Summarization
that retrieves evidence and uses LLMs to summarize according to the main
content; (3) Semantic-Temporal Hybrid Ranking that scores each evidence
summarization based on both semantic and temporal relevance. On TempRAGEval,
MRAG significantly outperforms baseline retrievers in retrieval performance,
leading to further improvements in final answer accuracy.

摘要：理解時間關係和回答時間敏感問題對於由大型語言模型 (LLM) 支援的問題回答系統至關重要，但卻是一項具有挑戰性的任務。現有方法會使用新事實更新 LLM 的參數化知識，這需要大量資源且通常不切實際，或將 LLM 與外部知識擷取整合（即擷取增強生成）。然而，現成的擷取器通常難以識別需要大量時間推理相關文件。為了系統性地研究時間敏感問題回答，我們引入了 TempRAGEval 基準，它透過整合時間擾動和黃金證據標籤，重新利用現有資料集。正如預期，所有現有擷取方法都難以處理這些時間推理密集的問題。我們進一步提出模組化擷取 (MRAG)，這是一個無訓練架構，包含三個模組：(1) 問題處理，將問題分解成主要內容和時間約束；(2) 擷取和摘要，擷取證據並使用 LLM 根據主要內容進行摘要；(3) 語義時間混合排名，根據語義和時間相關性對每個證據摘要進行評分。在 TempRAGEval 上，MRAG 在擷取效能上顯著優於基準擷取器，進而提升最終答案準確性。

##### **Improved Forecasts of Global Extreme Marine Heatwaves Through a Physics-guided Data-driven Approach**
2412.15532v1 by Ruiqi Shu, Hao Wu, Yuan Gao, Fanghua Xu, Ruijian Gou, Xiaomeng Huang

The unusually warm sea surface temperature events known as marine heatwaves
(MHWs) have a profound impact on marine ecosystems. Accurate prediction of
extreme MHWs has significant scientific and financial worth. However, existing
methods still have certain limitations, especially in the most extreme MHWs. In
this study, to address these issues, based on the physical nature of MHWs, we
created a novel deep learning neural network that is capable of accurate 10-day
MHW forecasting. Our framework significantly improves the forecast ability of
extreme MHWs through two specially designed modules inspired by numerical
models: a coupler and a probabilistic data argumentation. The coupler simulates
the driving effect of atmosphere on MHWs while the probabilistic data
argumentation approaches significantly boost the forecast ability of extreme
MHWs based on the idea of ensemble forecast. Compared with traditional
numerical prediction, our framework has significantly higher accuracy and
requires fewer computational resources. What's more, explainable AI methods
show that wind forcing is the primary driver of MHW evolution and reveal its
relation with air-sea heat exchange. Overall, our model provides a framework
for understanding MHWs' driving processes and operational forecasts in the
future.

摘要：異常溫暖的海面溫度事件，即海洋熱浪 (MHW)，對海洋生態系統產生深遠的影響。準確預測極端 MHW 具有重要的科學和經濟價值。然而，現有方法仍存在一定的局限性，特別是在最極端的 MHW 中。在本研究中，為了解決這些問題，基於 MHW 的物理特性，我們創建了一個新的深度學習神經網路，它能夠準確預測 10 天的 MHW。我們的框架通過兩個特別設計的受數值模型啟發的模組，顯著提高了極端 MHW 的預測能力：一個耦合器和一個概率數據論證。耦合器模擬了大氣對 MHW 的驅動效應，而概率數據論證基於集合預測的思想，顯著提高了極端 MHW 的預測能力。與傳統的數值預測相比，我們的框架具有顯著更高的準確度，並且需要更少的計算資源。此外，可解釋的 AI 方法表明，風力強迫是 MHW 演化的主要驅動力，並揭示了它與空氣-海洋熱交換的關係。總的來說，我們的模型為理解 MHW 的驅動過程和未來的操作預測提供了一個框架。

##### **XRAG: eXamining the Core -- Benchmarking Foundational Components in Advanced Retrieval-Augmented Generation**
2412.15529v1 by Qianren Mao, Yangyifei Luo, Jinlong Zhang, Hanwen Hao, Zhilong Cao, Xiaolong Wang, Xiao Guan, Zhenting Huang, Weifeng Jiang, Shuyu Guo, Zhentao Han, Qili Zhang, Siyuan Tao, Yujie Liu, Junnan Liu, Zhixing Tan, Jie Sun, Bo Li, Xudong Liu, Richong Zhang, Jianxin Li

Retrieval-augmented generation (RAG) synergizes the retrieval of pertinent
data with the generative capabilities of Large Language Models (LLMs), ensuring
that the generated output is not only contextually relevant but also accurate
and current.We introduce XRAG, an open-source, modular codebase that
facilitates exhaustive evaluation of the performance of foundational components
of advanced RAG modules. These components are systematically categorized into
four core phases: pre-retrieval, retrieval, post-retrieval, and generation. We
systematically analyse them across reconfigured datasets, providing a
comprehensive benchmark for their effectiveness. Given the escalating
complexity of RAG systems, we underscore the necessity of identifying potential
failure points of RAG modules. We formulate a suite of experimental
methodologies and diagnostic testing protocols to dissect the failure points
inherent in the engineering of RAG modules. Subsequently, we proffer bespoke
solutions that are designed to augment the validation processes and bolster the
overall performance of these modules. Our work thoroughly evaluates the
performance of core advanced components in RAG systems, providing insights into
optimizations for prevalent failure points.

摘要：檢索增強生成 (RAG) 協同運用大型語言模型 (LLM) 的檢索與生成能力，確保生成的輸出不僅與上下文相關，而且準確且最新。我們介紹了 XRAG，這是一個開源的模組化程式碼庫，可協助對進階 RAG 模組的基本元件效能進行詳盡的評估。這些元件被系統化地分類為四個核心階段：預檢索、檢索、檢索後和生成。我們系統化地分析它們在重新配置的資料集上，提供它們有效性的全面基準。鑑於 RAG 系統日益複雜，我們強調找出 RAG 模組潛在故障點的必要性。我們制定了一套實驗方法和診斷測試協定，以剖析 RAG 模組工程中固有的故障點。隨後，我們提供量身打造的解決方案，旨在擴充驗證流程並提升這些模組的整體效能。我們的研究徹底評估了 RAG 系統中核心進階元件的效能，提供了對常見故障點最佳化的見解。

##### **HREF: Human Response-Guided Evaluation of Instruction Following in Language Models**
2412.15524v1 by Xinxi Lyu, Yizhong Wang, Hannaneh Hajishirzi, Pradeep Dasigi

Evaluating the capability of Large Language Models (LLMs) in following
instructions has heavily relied on a powerful LLM as the judge, introducing
unresolved biases that deviate the judgments from human judges. In this work,
we reevaluate various choices for automatic evaluation on a wide range of
instruction-following tasks. We experiment with methods that leverage
human-written responses and observe that they enhance the reliability of
automatic evaluations across a wide range of tasks, resulting in up to a 3.2%
improvement in agreement with human judges. We also discovered that
human-written responses offer an orthogonal perspective to model-generated
responses in following instructions and should be used as an additional context
when comparing model responses. Based on these observations, we develop a new
evaluation benchmark, Human Response-Guided Evaluation of Instruction Following
(HREF), comprising 4,258 samples across 11 task categories with a composite
evaluation setup, employing a composite evaluation setup that selects the most
reliable method for each category. In addition to providing reliable
evaluation, HREF emphasizes individual task performance and is free from
contamination. Finally, we study the impact of key design choices in HREF,
including the size of the evaluation set, the judge model, the baseline model,
and the prompt template. We host a live leaderboard that evaluates LLMs on the
private evaluation set of HREF.

摘要：評估大型語言模型 (LLM) 在遵循說明方面的能力，一直高度依賴強大的 LLM 作為評審，引入了未解決的偏見，使判斷與人類評審產生偏差。在這項工作中，我們重新評估各種自動評估的選擇，針對廣泛的說明遵循任務進行評估。我們實驗利用人類撰寫的回應的方法，並觀察到它們提升了各種任務的自動評估的可靠性，與人類評審的吻合度提高了 3.2%。我們還發現，人類撰寫的回應提供了與模型產生的回應在遵循說明方面的正交觀點，在比較模型回應時應將其用作額外的背景。根據這些觀察，我們開發了一個新的評估基準，即人類回應引導的說明遵循評估 (HREF)，包含 11 個任務類別的 4,258 個範例，採用複合評估設定，為每個類別選出最可靠的方法。除了提供可靠的評估外，HREF 還強調了個別任務的表現，且不受汙染。最後，我們研究了 HREF 中關鍵設計選擇的影響，包括評估集的大小、評審模型、基準模型和提示範本。我們建立了一個動態排行榜，在 HREF 的私有評估集中評估 LLM。

##### **InstructOCR: Instruction Boosting Scene Text Spotting**
2412.15523v1 by Chen Duan, Qianyi Jiang, Pei Fu, Jiamin Chen, Shengxi Li, Zining Wang, Shan Guo, Junfeng Luo

In the field of scene text spotting, previous OCR methods primarily relied on
image encoders and pre-trained text information, but they often overlooked the
advantages of incorporating human language instructions. To address this gap,
we propose InstructOCR, an innovative instruction-based scene text spotting
model that leverages human language instructions to enhance the understanding
of text within images. Our framework employs both text and image encoders
during training and inference, along with instructions meticulously designed
based on text attributes. This approach enables the model to interpret text
more accurately and flexibly. Extensive experiments demonstrate the
effectiveness of our model and we achieve state-of-the-art results on widely
used benchmarks. Furthermore, the proposed framework can be seamlessly applied
to scene text VQA tasks. By leveraging instruction strategies during
pre-training, the performance on downstream VQA tasks can be significantly
improved, with a 2.6% increase on the TextVQA dataset and a 2.1% increase on
the ST-VQA dataset. These experimental results provide insights into the
benefits of incorporating human language instructions for OCR-related tasks.

摘要：在場景文字偵測領域，先前的 OCR 方法主要依賴影像編碼器和預先訓練的文字資訊，但它們常常忽略了結合人類語言指令的優勢。為了解決這個差距，我們提出 InstructOCR，一個創新的基於指令的場景文字偵測模型，利用人類語言指令來增強對影像中文字的理解。我們的架構在訓練和推論期間同時採用文字和影像編碼器，並根據文字屬性精心設計指令。這種方法使模型能夠更準確和靈活地解讀文字。廣泛的實驗證明了我們模型的有效性，我們在廣泛使用的基準上取得了最先進的結果。此外，所提出的架構可以無縫地應用於場景文字 VQA 任務。透過在預訓練期間利用指令策略，可以顯著提高下游 VQA 任務的效能，在 TextVQA 資料集上提升 2.6%，在 ST-VQA 資料集上提升 2.1%。這些實驗結果提供了將人類語言指令納入 OCR 相關任務的優點見解。

##### **RESQUE: Quantifying Estimator to Task and Distribution Shift for Sustainable Model Reusability**
2412.15511v1 by Vishwesh Sangarya, Jung-Eun Kim

As a strategy for sustainability of deep learning, reusing an existing model
by retraining it rather than training a new model from scratch is critical. In
this paper, we propose REpresentation Shift QUantifying Estimator (RESQUE), a
predictive quantifier to estimate the retraining cost of a model to
distributional shifts or change of tasks. It provides a single concise index
for an estimate of resources required for retraining the model. Through
extensive experiments, we show that RESQUE has a strong correlation with
various retraining measures. Our results validate that RESQUE is an effective
indicator in terms of epochs, gradient norms, changes of parameter magnitude,
energy, and carbon emissions. These measures align well with RESQUE for new
tasks, multiple noise types, and varying noise intensities. As a result, RESQUE
enables users to make informed decisions for retraining to different
tasks/distribution shifts and determine the most cost-effective and sustainable
option, allowing for the reuse of a model with a much smaller footprint in the
environment. The code for this work is available here:
https://github.com/JEKimLab/AAAI2025RESQUE

摘要：作為深度學習永續性的策略，重新訓練現有模型而非從頭訓練新模型以重複使用，至關重要。在本文中，我們提出表示位移量化估計器 (RESQUE)，一種預測量化器，用於估計模型重新訓練成本，以進行分配轉移或任務變更。它提供一個簡潔的單一指標，用於估計重新訓練模型所需的資源。透過廣泛的實驗，我們表明 RESQUE 與各種重新訓練措施有很強的相關性。我們的結果驗證了 RESQUE 在 epoch、梯度範數、參數大小變化、能量和碳排放方面是一個有效的指標。這些措施與 RESQUE 非常吻合，適用於新任務、多種雜訊類型和不同的雜訊強度。因此，RESQUE 使用戶能夠針對不同的任務/分配轉移做出明智的重新訓練決策，並確定最具成本效益和永續性的選項，允許重複使用在環境中佔用空間更小的模型。此項工作的程式碼在此處提供：
https://github.com/JEKimLab/AAAI2025RESQUE

##### **ADEQA: A Question Answer based approach for joint ADE-Suspect Extraction using Sequence-To-Sequence Transformers**
2412.15510v1 by Vinayak Arannil, Tomal Deb, Atanu Roy

Early identification of Adverse Drug Events (ADE) is critical for taking
prompt actions while introducing new drugs into the market. These ADEs
information are available through various unstructured data sources like
clinical study reports, patient health records, social media posts, etc.
Extracting ADEs and the related suspect drugs using machine learning is a
challenging task due to the complex linguistic relations between drug ADE pairs
in textual data and unavailability of large corpus of labelled datasets. This
paper introduces ADEQA, a question-answer(QA) based approach using quasi
supervised labelled data and sequence-to-sequence transformers to extract ADEs,
drug suspects and the relationships between them. Unlike traditional QA models,
natural language generation (NLG) based models don't require extensive token
level labelling and thereby reduces the adoption barrier significantly. On a
public ADE corpus, we were able to achieve state-of-the-art results with an F1
score of 94% on establishing the relationships between ADEs and the respective
suspects.

摘要：早期辨識不良藥物事件 (ADE) 對於在將新藥品推向市場時採取迅速行動至關重要。這些 ADE 資訊可透過各種非結構化資料來源取得，例如臨床研究報告、病人健康紀錄、社群媒體貼文等。由於文字資料中藥物 ADE 配對之間的語言關係複雜，且缺乏大量的標籤資料集，因此使用機器學習萃取 ADE 及相關可疑藥物是一項艱鉅的任務。本文介紹 ADEQA，一種基於問答 (QA) 的方法，使用擬監督標籤資料和序列對序列轉換器來萃取 ADE、可疑藥物及其之間的關係。與傳統的 QA 模型不同，基於自然語言生成 (NLG) 的模型不需要廣泛的代幣級標籤，從而大幅降低採用門檻。在一個公開的 ADE 語料庫上，我們在建立 ADE 和各自可疑藥物之間的關係方面達到了最先進的結果，F1 分數為 94%。

##### **Mitigating Social Bias in Large Language Models: A Multi-Objective Approach within a Multi-Agent Framework**
2412.15504v1 by Zhenjie Xu, Wenqing Chen, Yi Tang, Xuanying Li, Cheng Hu, Zhixuan Chu, Kui Ren, Zibin Zheng, Zhichao Lu

Natural language processing (NLP) has seen remarkable advancements with the
development of large language models (LLMs). Despite these advancements, LLMs
often produce socially biased outputs. Recent studies have mainly addressed
this problem by prompting LLMs to behave ethically, but this approach results
in unacceptable performance degradation. In this paper, we propose a
multi-objective approach within a multi-agent framework (MOMA) to mitigate
social bias in LLMs without significantly compromising their performance. The
key idea of MOMA involves deploying multiple agents to perform causal
interventions on bias-related contents of the input questions, breaking the
shortcut connection between these contents and the corresponding answers.
Unlike traditional debiasing techniques leading to performance degradation,
MOMA substantially reduces bias while maintaining accuracy in downstream tasks.
Our experiments conducted on two datasets and two models demonstrate that MOMA
reduces bias scores by up to 87.7%, with only a marginal performance
degradation of up to 6.8% in the BBQ dataset. Additionally, it significantly
enhances the multi-objective metric icat in the StereoSet dataset by up to
58.1%. Code will be made available at https://github.com/Cortantse/MOMA.

摘要：自然語言處理 (NLP) 隨著大型語言模型 (LLM) 的發展而有了顯著的進步。儘管有這些進步，LLM 經常產生社會偏見的輸出。最近的研究主要透過提示 LLM 以符合道德的方式來解決這個問題，但這種方法導致了無法接受的效能下降。在本文中，我們提出了一個多主體架構 (MOMA) 內的多目標方法，以減輕 LLM 中的社會偏見，而不會顯著損害其效能。MOMA 的關鍵思想涉及部署多個主體，對輸入問題中與偏見相關的內容執行因果干預，打破這些內容與對應答案之間的捷徑連接。與導致效能下降的傳統去偏見技術不同，MOMA 在維持下游任務準確性的同時，大幅減少了偏見。我們在兩個資料集和兩個模型上進行的實驗表明，MOMA 將偏見分數降低了 87.7%，在 BBQ 資料集中的效能下降幅度僅為 6.8%。此外，它在 StereoSet 資料集中將多目標指標 icat 大幅提升了 58.1%。程式碼將在 https://github.com/Cortantse/MOMA 上提供。

##### **Humanlike Cognitive Patterns as Emergent Phenomena in Large Language Models**
2412.15501v1 by Zhisheng Tang, Mayank Kejriwal

Research on emergent patterns in Large Language Models (LLMs) has gained
significant traction in both psychology and artificial intelligence, motivating
the need for a comprehensive review that offers a synthesis of this complex
landscape. In this article, we systematically review LLMs' capabilities across
three important cognitive domains: decision-making biases, reasoning, and
creativity. We use empirical studies drawing on established psychological tests
and compare LLMs' performance to human benchmarks. On decision-making, our
synthesis reveals that while LLMs demonstrate several human-like biases, some
biases observed in humans are absent, indicating cognitive patterns that only
partially align with human decision-making. On reasoning, advanced LLMs like
GPT-4 exhibit deliberative reasoning akin to human System-2 thinking, while
smaller models fall short of human-level performance. A distinct dichotomy
emerges in creativity: while LLMs excel in language-based creative tasks, such
as storytelling, they struggle with divergent thinking tasks that require
real-world context. Nonetheless, studies suggest that LLMs hold considerable
potential as collaborators, augmenting creativity in human-machine
problem-solving settings. Discussing key limitations, we also offer guidance
for future research in areas such as memory, attention, and open-source model
development.

摘要：大型語言模型 (LLM) 中出現模式的研究在心理學和人工智慧領域都獲得了顯著的關注，促使需要進行全面回顧，以綜合這個複雜的領域。在本文中，我們系統性地回顧了 LLM 在三個重要的認知領域中的能力：決策偏誤、推理和創造力。我們使用依據既定的心理測驗進行的實證研究，並將 LLM 的表現與人類基準進行比較。在決策制定方面，我們的綜合分析顯示，儘管 LLM 表現出幾種類似人類的偏誤，但在人類中觀察到的某些偏誤卻不存在，這表明認知模式僅部分與人類決策制定相符。在推理方面，GPT-4 等先進的 LLM 表現出類似人類系統 2 思考的審議推理，而較小的模型則未達到人類水準的表現。在創造力方面出現了明顯的二分法：雖然 LLM 在基於語言的創造性任務中表現出色，例如講故事，但它們在需要現實世界脈絡的發散性思考任務中卻表現不佳。儘管如此，研究表明 LLM 具有相當大的潛力作為協作者，在人機問題解決環境中增強創造力。在討論關鍵限制時，我們還為記憶、注意力和開源模型開發等領域的未來研究提供指導。

##### **A Robust Prototype-Based Network with Interpretable RBF Classifier Foundations**
2412.15499v1 by Sascha Saralajew, Ashish Rana, Thomas Villmann, Ammar Shaker

Prototype-based classification learning methods are known to be inherently
interpretable. However, this paradigm suffers from major limitations compared
to deep models, such as lower performance. This led to the development of the
so-called deep Prototype-Based Networks (PBNs), also known as prototypical
parts models. In this work, we analyze these models with respect to different
properties, including interpretability. In particular, we focus on the
Classification-by-Components (CBC) approach, which uses a probabilistic model
to ensure interpretability and can be used as a shallow or deep architecture.
We show that this model has several shortcomings, like creating contradicting
explanations. Based on these findings, we propose an extension of CBC that
solves these issues. Moreover, we prove that this extension has robustness
guarantees and derive a loss that optimizes robustness. Additionally, our
analysis shows that most (deep) PBNs are related to (deep) RBF classifiers,
which implies that our robustness guarantees generalize to shallow RBF
classifiers. The empirical evaluation demonstrates that our deep PBN yields
state-of-the-art classification accuracy on different benchmarks while
resolving the interpretability shortcomings of other approaches. Further, our
shallow PBN variant outperforms other shallow PBNs while being inherently
interpretable and exhibiting provable robustness guarantees.

摘要：<paragraph>原型為基礎的分類學習方法已知具有內在可解釋性。然而，與深度模型相比，此範例存在著重大的限制，例如較低的效能。這導致了所謂的深度原型為基礎網路 (PBN) 的發展，又稱為原型部分模型。在這項工作中，我們分析了這些模型對於不同屬性的關係，包括可解釋性。特別是，我們專注於元件分類 (CBC) 方法，它使用機率模型來確保可解釋性，並且可用作淺層或深層架構。我們證明了此模型有幾個缺點，例如產生矛盾的解釋。基於這些發現，我們提出了一個 CBC 延伸，來解決這些問題。此外，我們證明此延伸具有穩健性保證，並推導出最佳化穩健性的損失。此外，我們的分析顯示，大多數（深度）PBN 與（深度）RBF 分類器相關，這表示我們的穩健性保證概括到淺層 RBF 分類器。實證評估證明了我們的深度 PBN 在不同的基準上產生了最先進的分類準確度，同時解決了其他方法的可解釋性缺點。此外，我們的淺層 PBN 變體優於其他淺層 PBN，同時具有內在的可解釋性，並展現出可證明穩健性保證。</paragraph>

##### **The First Multilingual Model For The Detection of Suicide Texts**
2412.15498v1 by Rodolfo Zevallos, Annika Schoene, John E. Ortega

Suicidal ideation is a serious health problem affecting millions of people
worldwide. Social networks provide information about these mental health
problems through users' emotional expressions. We propose a multilingual model
leveraging transformer architectures like mBERT, XML-R, and mT5 to detect
suicidal text across posts in six languages - Spanish, English, German,
Catalan, Portuguese and Italian. A Spanish suicide ideation tweet dataset was
translated into five other languages using SeamlessM4T. Each model was
fine-tuned on this multilingual data and evaluated across classification
metrics. Results showed mT5 achieving the best performance overall with F1
scores above 85%, highlighting capabilities for cross-lingual transfer
learning. The English and Spanish translations also displayed high quality
based on perplexity. Our exploration underscores the importance of considering
linguistic diversity in developing automated multilingual tools to identify
suicidal risk. Limitations exist around semantic fidelity in translations and
ethical implications which provide guidance for future human-in-the-loop
evaluations.

摘要：自殺意念是一個嚴重的健康問題，影響全球數百萬人。社交網路透過使用者的情緒表達，提供這些心理健康問題的資訊。我們提出一個多語言模型，利用像 mBERT、XML-R 和 mT5 的轉換器架構，來偵測六種語言（西班牙文、英文、德文、加泰隆尼亞文、葡萄牙文和義大利文）貼文中具有自殺傾向的文字。一個西班牙文自殺意念推文資料集使用 SeamlessM4T 翻譯成其他五種語言。每個模型都針對這個多語言資料進行微調，並評估分類指標。結果顯示，mT5 在整體表現上達到最佳，F1 分數高於 85%，突顯跨語言轉移學習的能力。英文和西班牙文的翻譯也根據困惑度顯示出高品質。我們的探索強調在開發自動化多語言工具以識別自殺風險時，考慮語言多樣性的重要性。翻譯中的語義忠實度和倫理意涵存在限制，這些限制為未來的人類參與評估提供了指導。

##### **Lexicography Saves Lives (LSL): Automatically Translating Suicide-Related Language**
2412.15497v1 by Annika Marie Schoene, John E. Ortega, Rodolfo Joel Zevallos, Laura Haaber Ihle

Recent years have seen a marked increase in research that aims to identify or
predict risk, intention or ideation of suicide. The majority of new tasks,
datasets, language models and other resources focus on English and on suicide
in the context of Western culture. However, suicide is global issue and
reducing suicide rate by 2030 is one of the key goals of the UN's Sustainable
Development Goals. Previous work has used English dictionaries related to
suicide to translate into different target languages due to lack of other
available resources. Naturally, this leads to a variety of ethical tensions
(e.g.: linguistic misrepresentation), where discourse around suicide is not
present in a particular culture or country. In this work, we introduce the
'Lexicography Saves Lives Project' to address this issue and make three
distinct contributions. First, we outline ethical consideration and provide
overview guidelines to mitigate harm in developing suicide-related resources.
Next, we translate an existing dictionary related to suicidal ideation into 200
different languages and conduct human evaluations on a subset of translated
dictionaries. Finally, we introduce a public website to make our resources
available and enable community participation.

摘要：近年來，有許多研究旨在識別或預測自殺的風險、意圖或意念。大多數新任務、資料集、語言模型和其他資源都專注於英語和西方文化背景下的自殺。然而，自殺是一個全球性的問題，到 2030 年降低自殺率是聯合國永續發展目標的主要目標之一。由於缺乏其他可用資源，先前的研究使用與自殺相關的英語詞典翻譯成不同的目標語言。自然而然地，這會導致各種倫理緊張（例如：語言上的誤解），在特定文化或國家中沒有關於自殺的論述。在這項工作中，我們引入了「詞彙學拯救生命計畫」來解決這個問題，並做出三項不同的貢獻。首先，我們概述倫理考量，並提供概觀指南，以減輕開發與自殺相關資源的危害。接下來，我們將一本現有的與自殺意念相關的詞典翻譯成 200 種不同的語言，並對部分已翻譯的詞典進行人工評估。最後，我們建立一個公開網站，讓我們的資源可用，並讓社群參與。

##### **TL-Training: A Task-Feature-Based Framework for Training Large Language Models in Tool Use**
2412.15495v1 by Junjie Ye, Yilong Wu, Sixian Li, Yuming Yang, Tao Gui, Qi Zhang, Xuanjing Huang, Peng Wang, Zhongchao Shi, Jianping Fan, Zhengyin Du

Large language models (LLMs) achieve remarkable advancements by leveraging
tools to interact with external environments, a critical step toward
generalized AI. However, the standard supervised fine-tuning (SFT) approach,
which relies on large-scale datasets, often overlooks task-specific
characteristics in tool use, leading to performance bottlenecks. To address
this issue, we analyze three existing LLMs and uncover key insights: training
data can inadvertently impede tool-use behavior, token importance is
distributed unevenly, and errors in tool calls fall into a small set of
distinct categories. Building on these findings, we propose TL-Training, a
task-feature-based framework that mitigates the effects of suboptimal training
data, dynamically adjusts token weights to prioritize key tokens during SFT,
and incorporates a robust reward mechanism tailored to error categories,
optimized through proximal policy optimization. We validate TL-Training by
training CodeLLaMA-2-7B and evaluating it on four diverse open-source test
sets. Our results demonstrate that the LLM trained by our method matches or
surpasses both open- and closed-source LLMs in tool-use performance using only
1,217 training data points. Additionally, our method enhances robustness in
noisy environments and improves general task performance, offering a scalable
and efficient paradigm for tool-use training in LLMs. The code and data are
available at https://github.com/Junjie-Ye/TL-Training.

摘要：大型語言模型（LLM）透過利用與外部環境互動的工具取得顯著進展，這是邁向通用 AI 的關鍵一步。然而，標準的監督式微調（SFT）方法依賴於大規模的資料集，經常忽略工具使用中的特定任務特徵，導致效能瓶頸。為了解決這個問題，我們分析了三個現有的 LLM，並發現了關鍵見解：訓練資料可能會無意中阻礙工具使用行為、標記重要性分佈不均，以及工具呼叫中的錯誤屬於少數不同的類別。根據這些發現，我們提出了 TL-Training，一個基於任務特徵的架構，它可以減輕次佳訓練資料的影響，在 SFT 期間動態調整標記權重以優先考慮關鍵標記，並結合針對錯誤類別量身打造的強健獎勵機制，透過近端策略最佳化進行最佳化。我們透過訓練 CodeLLaMA-2-7B 並在四個不同的開源測試集中評估它來驗證 TL-Training。我們的結果證明，使用我們的方法訓練的 LLM 在工具使用效能上比開源和閉源 LLM 相同或更好，僅使用 1,217 個訓練資料點。此外，我們的方法增強了在有雜訊環境中的穩健性，並改進了整體任務效能，為 LLM 中的工具使用訓練提供了可擴充且有效率的範例。程式碼和資料可在 https://github.com/Junjie-Ye/TL-Training 取得。

##### **Multi-LLM Text Summarization**
2412.15487v1 by Jiangnan Fang, Cheng-Tse Liu, Jieun Kim, Yash Bhedaru, Ethan Liu, Nikhil Singh, Nedim Lipka, Puneet Mathur, Nesreen K. Ahmed, Franck Dernoncourt, Ryan A. Rossi, Hanieh Deilamsalehy

In this work, we propose a Multi-LLM summarization framework, and investigate
two different multi-LLM strategies including centralized and decentralized. Our
multi-LLM summarization framework has two fundamentally important steps at each
round of conversation: generation and evaluation. These steps are different
depending on whether our multi-LLM decentralized summarization is used or
centralized. In both our multi-LLM decentralized and centralized strategies, we
have k different LLMs that generate diverse summaries of the text. However,
during evaluation, our multi-LLM centralized summarization approach leverages a
single LLM to evaluate the summaries and select the best one whereas k LLMs are
used for decentralized multi-LLM summarization. Overall, we find that our
multi-LLM summarization approaches significantly outperform the baselines that
leverage only a single LLM by up to 3x. These results indicate the
effectiveness of multi-LLM approaches for summarization.

摘要：在這項工作中，我們提出了一個多 LLM 摘要架構，並探討了兩種不同的多 LLM 策略，包括集中式和分散式。我們的多 LLM 摘要架構在每個對話回合中都有兩個基本重要的步驟：生成和評估。這些步驟會根據我們使用的是多 LLM 分散式摘要還是集中式摘要而有所不同。在我們的多 LLM 分散式和集中式策略中，我們有 k 個不同的 LLM 來產生文本的多樣化摘要。然而，在評估期間，我們的多 LLM 集中式摘要方法利用單一的 LLM 來評估摘要並選出最佳摘要，而分散式多 LLM 摘要則使用 k 個 LLM。總體而言，我們發現我們的多 LLM 摘要方法顯著優於僅利用單一 LLM 的基準，最多可達 3 倍。這些結果表明多 LLM 方法對於摘要的有效性。

##### **Task-Specific Preconditioner for Cross-Domain Few-Shot Learning**
2412.15483v1 by Suhyun Kang, Jungwon Park, Wonseok Lee, Wonjong Rhee

Cross-Domain Few-Shot Learning~(CDFSL) methods typically parameterize models
with task-agnostic and task-specific parameters. To adapt task-specific
parameters, recent approaches have utilized fixed optimization strategies,
despite their potential sub-optimality across varying domains or target tasks.
To address this issue, we propose a novel adaptation mechanism called
Task-Specific Preconditioned gradient descent~(TSP). Our method first
meta-learns Domain-Specific Preconditioners~(DSPs) that capture the
characteristics of each meta-training domain, which are then linearly combined
using task-coefficients to form the Task-Specific Preconditioner. The
preconditioner is applied to gradient descent, making the optimization adaptive
to the target task. We constrain our preconditioners to be positive definite,
guiding the preconditioned gradient toward the direction of steepest descent.
Empirical evaluations on the Meta-Dataset show that TSP achieves
state-of-the-art performance across diverse experimental scenarios.

摘要：跨域小样本学习~(CDFSL) 方法通常使用与任务无关和特定于任务的参数对模型进行参数化。为了适应特定于任务的参数，最近的方法利用了固定的优化策略，尽管它们在不同域或目标任务中存在潜在的次优性。为了解决这个问题，我们提出了一种称为任务特定预处理梯度下降~(TSP) 的新颖自适应机制。我们的方法首先元学习领域特定预处理程序~(DSP)，它捕获每个元训练域的特征，然后使用任务系数线性组合它们以形成任务特定预处理程序。预处理程序应用于梯度下降，使优化适应目标任务。我们限制我们的预处理程序为正定，引导预处理梯度朝向最陡下降的方向。Meta-Dataset 上的经验评估表明，TSP 在各种实验场景中实现了最先进的性能。

##### **Continual Learning Using Only Large Language Model Prompting**
2412.15479v1 by Jiabao Qiu, Zixuan Ke, Bing Liu

We introduce CLOB, a novel continual learning (CL) paradigm wherein a large
language model (LLM) is regarded as a black box. Learning is done incrementally
via only verbal prompting. CLOB does not fine-tune any part of the LLM or add
any trainable parameters to it. It is particularly suitable for LLMs that are
accessible via APIs. We also propose a new CL technique, called CIS, based on
incremental summarization that also overcomes the LLM's input length limit.
Experiments show CIS outperforms baselines by a very large margin.

摘要：我們引進 CLOB，一種新穎的持續學習 (CL) 典範，其中將大型語言模型 (LLM) 視為黑盒子。學習是透過僅有的語言提示逐步進行的。CLOB 不會微調 LLM 的任何部分，也不會為其添加任何可訓練參數。它特別適合可透過 API 存取的 LLM。我們還提出了一種新的 CL 技術，稱為 CIS，它基於逐步摘要，也能克服 LLM 的輸入長度限制。實驗顯示 CIS 以非常大的幅度優於基線。

##### **A Review of the Marathi Natural Language Processing**
2412.15471v1 by Asang Dani, Shailesh R Sathe

Marathi is one of the most widely used languages in the world. One might
expect that the latest advances in NLP research in languages like Enlighs reach
such a large community. However, NLP advancements in English didn't immediately
reach Indian languages like Marathi. There were several reasons for this. They
included diversity of scripts used, lack of (publicly available) resources like
tokenization strategies, high quality datasets \& benchmarks, and evaluation
metrics. In addition to this, the morphologically rich nature of Marathi, made
NLP tasks challenging. Advances in Neural Network (NN) based models and tools
since the early 2000s helped improve this situation and make NLP research more
accessible. In the past 10 years, significant efforts were made to improve
language resources for all 22 scheduled languages of India. This paper presents
a broad overview of evolution of NLP research in Indic languages with a focus
on Marathi and state-of-the-art resources and tools available to the research
community. It also provides an overview of tools \& techniques associated with
Marathi NLP tasks.

摘要：馬拉地語是世界上使用最廣泛的語言之一。人們可能會預期，像英語這樣的語言在自然語言處理 (NLP) 研究中的最新進展會傳播到如此龐大的社群。然而，英語的 NLP 進展並未立即傳播到馬拉地語等印度語言。造成這種現象的原因有幾個，包括使用的腳本多樣化、缺乏（公開可用的）資源（例如，標記化策略、高品質的資料集和基準），以及評估指標。除此之外，馬拉地語在形態上豐富的特質，也讓 NLP 任務更具挑戰性。自 2000 年代初期以來，基於神經網路 (NN) 的模型和工具的進展，有助於改善這種情況，並讓 NLP 研究更易於取得。在過去 10 年中，人們做出了重大努力，以改善印度 22 種計畫語言的所有語言資源。本文簡要概述了印度語言中 NLP 研究的演變，重點在於馬拉地語以及研究社群可取得的最新資源和工具。本文也概述了與馬拉地語 NLP 任務相關的工具和技術。

##### **Non-Uniform Parameter-Wise Model Merging**
2412.15467v1 by Albert Manuel Orozco Camacho, Stefan Horoi, Guy Wolf, Eugene Belilovsky

Combining multiple machine learning models has long been a technique for
enhancing performance, particularly in distributed settings. Traditional
approaches, such as model ensembles, work well, but are expensive in terms of
memory and compute. Recently, methods based on averaging model parameters have
achieved good results in some settings and have gained popularity. However,
merging models initialized differently that do not share a part of their
training trajectories can yield worse results than simply using the base
models, even after aligning their neurons. In this paper, we introduce a novel
approach, Non-uniform Parameter-wise Model Merging, or NP Merge, which merges
models by learning the contribution of each parameter to the final model using
gradient-based optimization. We empirically demonstrate the effectiveness of
our method for merging models of various architectures in multiple settings,
outperforming past methods. We also extend NP Merge to handle the merging of
multiple models, showcasing its scalability and robustness.

摘要：將多個機器學習模型結合在一起，一直以來都是一種增強效能的技術，特別是在分散式設定中。傳統方法，例如模型組合，效果很好，但在記憶體和運算方面成本很高。最近，基於平均模型參數的方法在某些設定中取得了不錯的成果，並獲得了普及。然而，合併初始化不同的模型，這些模型沒有共用其訓練軌跡的一部分，可能會產生比僅使用基礎模型更差的結果，即使在調整其神經元之後也是如此。在本文中，我們介紹了一種新方法，非均勻參數模型合併，或 NP Merge，它通過使用基於梯度的最佳化來學習每個參數對最終模型的貢獻，從而合併模型。我們實證展示了我們的方法在多種設定中合併各種架構模型的有效性，其效能優於過去的方法。我們還擴充了 NP Merge 以處理多個模型的合併，展示了其可擴充性和穩健性。

##### **TalkWithMachines: Enhancing Human-Robot Interaction for Interpretable Industrial Robotics Through Large/Vision Language Models**
2412.15462v1 by Ammar N. Abbas, Csaba Beleznai

TalkWithMachines aims to enhance human-robot interaction by contributing to
interpretable industrial robotic systems, especially for safety-critical
applications. The presented paper investigates recent advancements in Large
Language Models (LLMs) and Vision Language Models (VLMs), in combination with
robotic perception and control. This integration allows robots to understand
and execute commands given in natural language and to perceive their
environment through visual and/or descriptive inputs. Moreover, translating the
LLM's internal states and reasoning into text that humans can easily understand
ensures that operators gain a clearer insight into the robot's current state
and intentions, which is essential for effective and safe operation. Our paper
outlines four LLM-assisted simulated robotic control workflows, which explore
(i) low-level control, (ii) the generation of language-based feedback that
describes the robot's internal states, (iii) the use of visual information as
additional input, and (iv) the use of robot structure information for
generating task plans and feedback, taking the robot's physical capabilities
and limitations into account. The proposed concepts are presented in a set of
experiments, along with a brief discussion. Project description, videos, and
supplementary materials will be available on the project website:
https://talk-machines.github.io.

摘要：TalkWithMachines 旨在透過貢獻可解釋的產業機器人系統，特別是對於安全關鍵應用，來提升人機互動。這篇論文探討了大型語言模型 (LLM) 和視覺語言模型 (VLM) 的最新進展，並結合機器人感知和控制。此整合讓機器人能夠理解並執行以自然語言給出的指令，並透過視覺和/或描述性輸入來感知其環境。此外，將 LLM 的內部狀態和推理轉換成人類可以輕鬆理解的文字，可確保操作員更清楚地了解機器人的當前狀態和意圖，這對於有效且安全的運作至關重要。我們的論文概述了四個 LLM 輔助的模擬機器人控制工作流程，探討 (i) 低階控制，(ii) 產生描述機器人內部狀態的基於語言的回饋，(iii) 使用視覺資訊作為額外的輸入，以及 (iv) 使用機器人結構資訊來產生任務計畫和回饋，考量機器人的物理能力和限制。所提出的概念在實驗中呈現，並附上簡短的討論。專案說明、影片和補充資料將在專案網站上提供：https://talk-machines.github.io。

##### **Northeastern Uni at Multilingual Counterspeech Generation: Enhancing Counter Speech Generation with LLM Alignment through Direct Preference Optimization**
2412.15453v1 by Sahil Wadhwa, Chengtian Xu, Haoming Chen, Aakash Mahalingam, Akankshya Kar, Divya Chaudhary

The automatic generation of counter-speech (CS) is a critical strategy for
addressing hate speech by providing constructive and informed responses.
However, existing methods often fail to generate high-quality, impactful, and
scalable CS, particularly across diverse linguistic contexts. In this paper, we
propose a novel methodology to enhance CS generation by aligning Large Language
Models (LLMs) using Supervised Fine-Tuning (SFT) and Direct Preference
Optimization (DPO). Our approach leverages DPO to align LLM outputs with human
preferences, ensuring contextually appropriate and linguistically adaptable
responses. Additionally, we incorporate knowledge grounding to enhance the
factual accuracy and relevance of generated CS. Experimental results
demonstrate that DPO-aligned models significantly outperform SFT baselines on
CS benchmarks while scaling effectively to multiple languages. These findings
highlight the potential of preference-based alignment techniques to advance CS
generation across varied linguistic settings. The model supervision and
alignment is done in English and the same model is used for reporting metrics
across other languages like Basque, Italian, and Spanish.

摘要：反論述 (CS) 的自動產生是透過提供具建設性且有根據的回應來解決仇恨言論的一項關鍵策略。
然而，現有方法通常無法產生高品質、有影響力且可擴充的 CS，特別是在不同的語言環境中。在本文中，我們提出了一種新的方法論，透過使用監督微調 (SFT) 和直接偏好最佳化 (DPO) 來調整大型語言模型 (LLM)，以增強 CS 的產生。我們的做法利用 DPO 將 LLM 輸出與人類偏好對齊，確保在語境上適當且在語言上適應性強的回應。此外，我們納入了知識基礎，以增強所產生 CS 的事實準確性和相關性。實驗結果表明，DPO 對齊模型在 CS 基準上顯著優於 SFT 基準，同時有效地擴充到多種語言。這些發現突顯了基於偏好的對齊技術在推進不同語言環境中的 CS 產生的潛力。模型監督和對齊是在英語中完成的，並且使用相同的模型來報告巴斯克語、義大利語和西班牙語等其他語言的指標。

##### **Fietje: An open, efficient LLM for Dutch**
2412.15450v1 by Bram Vanroy

This paper introduces Fietje, a family of small language models (SLMs)
specifically designed for the Dutch language. The model is based on Phi 2, an
English-centric model of 2.7 billion parameters. Fietje demonstrated
competitive results with larger language models upon its release. A core
emphasis of this work is transparency and reproducibility: Fietje is fully
open-source, with model weights, datasets, training, and evaluation code all
publicly accessible.
  The paper discusses the performance of Fietje and many other models on an
extensive evaluation suite of benchmarks on reasoning, sentiment analysis,
world knowledge, linguistic acceptability and word sense disambiguation.
Evaluation results illustrate the rapid progress in the field of LLMs, where
recent small models outperform older, larger models that were fine-tuned for
Dutch. This trend signals an exciting future for Dutch language processing,
suggesting that even compact LLMs are becoming increasingly capable.
Furthermore, ongoing and future efforts to adapt LLMs to Dutch are poised to
enhance these models even further, broadening their applicability and
accessibility. Fietje is only an intermediate step in improving accessibility
to language technology for users of the Dutch language.

摘要：本文介紹 Fietje，一種專門為荷蘭語設計的小型語言模型 (SLM) 家族。該模型基於 Phi 2，一種以英語為中心的 27 億個參數模型。Fietje 在發布時展示了與較大型語言模型競爭的結果。這項工作的核心重點是透明度和可複製性：Fietje 是完全開源的，模型權重、資料集、訓練和評估程式碼都公開可得。
本文討論了 Fietje 和許多其他模型在推理、情緒分析、世界知識、語言可接受性和詞義消歧的廣泛評估基準套件上的效能。評估結果說明了大型語言模型領域的快速進展，其中最近的小型模型優於針對荷蘭語微調的較舊、較大的模型。這種趨勢預示了荷蘭語處理的令人興奮的未來，表明即使是精簡的大型語言模型也正變得越來越有能力。此外，正在進行和未來的適應大型語言模型到荷蘭語的努力，準備進一步增強這些模型，擴大其適用性和可及性。Fietje 只是改善荷蘭語使用者語言技術可及性的一個中間步驟。

##### **AI-Enhanced Sensemaking: Exploring the Design of a Generative AI-Based Assistant to Support Genetic Professionals**
2412.15444v1 by Angela Mastrianni, Hope Twede, Aleksandra Sarcevic, Jeremiah Wander, Christina Austin-Tse, Scott Saponas, Heidi Rehm, Ashley Mae Conard, Amanda K. Hall

Generative AI has the potential to transform knowledge work, but further
research is needed to understand how knowledge workers envision using and
interacting with generative AI. We investigate the development of generative AI
tools to support domain experts in knowledge work, examining task delegation
and the design of human-AI interactions. Our research focused on designing a
generative AI assistant to aid genetic professionals in analyzing whole genome
sequences (WGS) and other clinical data for rare disease diagnosis. Through
interviews with 17 genetics professionals, we identified current challenges in
WGS analysis. We then conducted co-design sessions with six genetics
professionals to determine tasks that could be supported by an AI assistant and
considerations for designing interactions with the AI assistant. From our
findings, we identified sensemaking as both a current challenge in WGS analysis
and a process that could be supported by AI. We contribute an understanding of
how domain experts envision interacting with generative AI in their knowledge
work, a detailed empirical study of WGS analysis, and three design
considerations for using generative AI to support domain experts in sensemaking
during knowledge work.
  CCS CONCEPTS: Human-centered computing, Human-computer interaction, Empirical
studies in HCI
  Additional Keywords and Phrases: whole genome sequencing, generative AI,
large language models, knowledge work, sensemaking, co-design, rare disease
  Contact Author: Angela Mastrianni (This work was done during the author's
internship at Microsoft Research)
  Ashley Mae Conard and Amanda K. Hall contributed equally

摘要：<paragraph>生成式 AI 有可能轉換知識工作，但需要進一步的研究來了解知識工作者如何設想使用和與生成式 AI 互動。我們研究了生成式 AI 工具的開發，以支援領域專家進行知識工作，探討任務委派和人機互動的設計。我們的研究重點在於設計一個生成式 AI 助理，以協助遺傳學專業人士分析全基因體序列 (WGS) 和其他臨床資料，以診斷罕見疾病。透過訪談 17 位遺傳學專業人士，我們找出 WGS 分析中的現有挑戰。然後，我們與六位遺傳學專業人士進行共同設計會議，以確定 AI 助理可以支援的任務，以及設計與 AI 助理互動的考量因素。根據我們的研究結果，我們將意義建構認定為 WGS 分析中的現有挑戰，以及 AI 可以支援的流程。我們有助於了解領域專家如何設想在知識工作中與生成式 AI 互動，WGS 分析的詳細實證研究，以及在知識工作中使用生成式 AI 支援領域專家進行意義建構的三個設計考量因素。
CCS 概念：以人為本的運算、人機互動、HCI 中的實證研究
其他關鍵字和詞組：全基因體定序、生成式 AI、大型語言模型、知識工作、意義建構、共同設計、罕見疾病
聯絡作者：Angela Mastrianni（這項工作是在作者於 Microsoft Research 實習期間完成的）
Ashley Mae Conard 和 Amanda K. Hall 貢獻相同</paragraph>

##### **SKETCH: Structured Knowledge Enhanced Text Comprehension for Holistic Retrieval**
2412.15443v1 by Aakash Mahalingam, Vinesh Kumar Gande, Aman Chadha, Vinija Jain, Divya Chaudhary

Retrieval-Augmented Generation (RAG) systems have become pivotal in
leveraging vast corpora to generate informed and contextually relevant
responses, notably reducing hallucinations in Large Language Models. Despite
significant advancements, these systems struggle to efficiently process and
retrieve information from large datasets while maintaining a comprehensive
understanding of the context. This paper introduces SKETCH, a novel methodology
that enhances the RAG retrieval process by integrating semantic text retrieval
with knowledge graphs, thereby merging structured and unstructured data for a
more holistic comprehension. SKETCH, demonstrates substantial improvements in
retrieval performance and maintains superior context integrity compared to
traditional methods. Evaluated across four diverse datasets: QuALITY, QASPER,
NarrativeQA, and Italian Cuisine-SKETCH consistently outperforms baseline
approaches on key RAGAS metrics such as answer_relevancy, faithfulness,
context_precision and context_recall. Notably, on the Italian Cuisine dataset,
SKETCH achieved an answer relevancy of 0.94 and a context precision of 0.99,
representing the highest performance across all evaluated metrics. These
results highlight SKETCH's capability in delivering more accurate and
contextually relevant responses, setting new benchmarks for future retrieval
systems.

摘要：擷取增強生成 (RAG) 系統已成為利用龐大語料庫來產生明智且與情境相關回應的關鍵，特別是減少大型語言模型中的幻覺。儘管有顯著的進展，但這些系統在處理和擷取來自大型資料集的資訊時仍有困難，同時還要維持對情境的全面理解。本文介紹 SKETCH，一種透過將語意文字擷取與知識圖表整合，藉此合併結構化和非結構化資料以獲得更全面的理解，來增強 RAG 擷取程序的創新方法。SKETCH 在擷取效能方面展現出顯著的進步，並與傳統方法相比維持較佳的情境完整性。在四個不同的資料集：QuALITY、QASPER、NarrativeQA 和 Italian Cuisine 中進行評估，SKETCH 在關鍵的 RAGAS 指標（例如 answer_relevancy、faithfulness、context_precision 和 context_recall）上始終優於基準方法。值得注意的是，在 Italian Cuisine 資料集上，SKETCH 的 answer relevancy 達到 0.94，context precision 達到 0.99，代表在所有評估指標中表現最佳。這些結果突顯了 SKETCH 在提供更準確且與情境相關回應的能力，為未來的擷取系統樹立了新的基準。

##### **Energy consumption of code small language models serving with runtime engines and execution providers**
2412.15441v1 by Francisco Durán, Matias Martinez, Patricia Lago, Silverio Martínez-Fernández

Background. The rapid growth of Language Models (LMs), particularly in code
generation, requires substantial computational resources, raising concerns
about energy consumption and environmental impact. Optimizing LMs inference for
energy efficiency is crucial, and Small Language Models (SLMs) offer a
promising solution to reduce resource demands.
  Aim. Our goal is to analyze the impact of deep learning runtime engines and
execution providers on energy consumption, execution time, and
computing-resource utilization from the point of view of software engineers
conducting inference in the context of code SLMs.
  Method. We conducted a technology-oriented, multi-stage experimental pipeline
using twelve code generation SLMs to investigate energy consumption, execution
time, and computing-resource utilization across the configurations.
  Results. Significant differences emerged across configurations. CUDA
execution provider configurations outperformed CPU execution provider
configurations in both energy consumption and execution time. Among the
configurations, TORCH paired with CUDA demonstrated the greatest energy
efficiency, achieving energy savings from 37.99% up to 89.16% compared to other
serving configurations. Similarly, optimized runtime engines like ONNX with the
CPU execution provider achieved from 8.98% up to 72.04% energy savings within
CPU-based configurations. Also, TORCH paired with CUDA exhibited efficient
computing-resource utilization.
  Conclusions. Serving configuration choice significantly impacts energy
efficiency. While further research is needed, we recommend the above
configurations best suited to software engineers' requirements for enhancing
serving efficiency in energy and performance.

摘要：<paragraph>背景。語言模型（LM）的快速發展，特別是在程式碼生成方面，需要大量的計算資源，引發了對能源消耗和環境影響的擔憂。優化 LM 推論以提高能源效率至關重要，而小型語言模型（SLM）提供了一個有希望的解決方案來降低資源需求。
目標。我們的目標是分析深度學習執行引擎和執行提供者對能源消耗、執行時間和計算資源利用率的影響，從軟體工程師在程式碼 SLM 的背景下進行推論的角度來看。
方法。我們使用十二個程式碼生成 SLM 進行了一項以技術為導向的多階段實驗管道，以調查配置中的能源消耗、執行時間和計算資源利用率。
結果。配置之間出現了顯著差異。CUDA 執行提供者配置在能源消耗和執行時間上都優於 CPU 執行提供者配置。在這些配置中，與 CUDA 配對的 TORCH 表現出最高的能源效率，與其他服務配置相比，節能從 37.99% 達到 89.16%。同樣地，與 CPU 執行提供者配對的 ONNX 等優化的運行時引擎在基於 CPU 的配置中實現了 8.98% 到 72.04% 的節能。此外，與 CUDA 配對的 TORCH 表現出高效的計算資源利用率。
結論。服務配置的選擇顯著影響能源效率。雖然需要進一步的研究，但我們建議上述配置最適合軟體工程師對提高能源和效能服務效率的要求。</paragraph>

