{"2406.01238": {"publish_time": "2024-06-03", "title": "EffiQA: Efficient Question-Answering with Strategic Multi-Model Collaboration on Knowledge Graphs", "paper_summary": "While large language models (LLMs) have shown remarkable capabilities in\nnatural language processing, they struggle with complex, multi-step reasoning\ntasks involving knowledge graphs (KGs). Existing approaches that integrate LLMs\nand KGs either underutilize the reasoning abilities of LLMs or suffer from\nprohibitive computational costs due to tight coupling. To address these\nlimitations, we propose a novel collaborative framework named EffiQA that can\nstrike a balance between performance and efficiency via an iterative paradigm.\nEffiQA consists of three stages: global planning, efficient KG exploration, and\nself-reflection. Specifically, EffiQA leverages the commonsense capability of\nLLMs to explore potential reasoning pathways through global planning. Then, it\noffloads semantic pruning to a small plug-in model for efficient KG\nexploration. Finally, the exploration results are fed to LLMs for\nself-reflection to further improve the global planning and efficient KG\nexploration. Empirical evidence on multiple KBQA benchmarks shows EffiQA's\neffectiveness, achieving an optimal balance between reasoning accuracy and\ncomputational costs. We hope the proposed new framework will pave the way for\nefficient, knowledge-intensive querying by redefining the integration of LLMs\nand KGs, fostering future research on knowledge-based question answering.", "paper_summary_zh": "\u5118\u7ba1\u5927\u578b\u8a9e\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u81ea\u7136\u8a9e\u8a00\u8655\u7406\u4e2d\u5c55\u73fe\u51fa\u5353\u8d8a\u7684\u80fd\u529b\uff0c\u4f46\u5b83\u5011\u5728\u6d89\u53ca\u77e5\u8b58\u5716\u8b5c\uff08KG\uff09\u7684\u8907\u96dc\u591a\u6b65\u9a5f\u63a8\u7406\u4efb\u52d9\u4e2d\u4ecd\u6709\u56f0\u96e3\u3002\u73fe\u6709\u7684\u6574\u5408 LLM \u548c KG \u7684\u65b9\u6cd5\uff0c\u4e0d\u662f\u4f4e\u4f30 LLM \u7684\u63a8\u7406\u80fd\u529b\uff0c\u5c31\u662f\u56e0\u70ba\u7dca\u5bc6\u7d50\u5408\u800c\u5c0e\u81f4\u9ad8\u6602\u7684\u904b\u7b97\u6210\u672c\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u4e9b\u9650\u5236\uff0c\u6211\u5011\u63d0\u51fa\u4e00\u500b\u540d\u70ba EffiQA \u7684\u5275\u65b0\u5354\u4f5c\u67b6\u69cb\uff0c\u5b83\u53ef\u4ee5\u900f\u904e\u4e00\u500b\u53cd\u8986\u904b\u7b97\u7684\u6a21\u5f0f\uff0c\u5728\u6548\u80fd\u548c\u6548\u7387\u4e4b\u9593\u53d6\u5f97\u5e73\u8861\u3002EffiQA \u5305\u542b\u4e09\u500b\u968e\u6bb5\uff1a\u5168\u57df\u898f\u5283\u3001\u9ad8\u6548 KG \u63a2\u7d22\u548c\u81ea\u6211\u53cd\u7701\u3002\u5177\u9ad4\u4f86\u8aaa\uff0cEffiQA \u5229\u7528 LLM \u7684\u5e38\u8b58\u80fd\u529b\uff0c\u900f\u904e\u5168\u57df\u898f\u5283\u4f86\u63a2\u7d22\u6f5b\u5728\u7684\u63a8\u7406\u8def\u5f91\u3002\u7136\u5f8c\uff0c\u5b83\u5c07\u8a9e\u7fa9\u526a\u679d\u5378\u8f09\u7d66\u4e00\u500b\u5c0f\u578b\u5916\u639b\u7a0b\u5f0f\u6a21\u578b\uff0c\u4ee5\u9032\u884c\u9ad8\u6548\u7684 KG \u63a2\u7d22\u3002\u6700\u5f8c\uff0c\u5c07\u63a2\u7d22\u7d50\u679c\u56de\u994b\u7d66 LLM \u4ee5\u9032\u884c\u81ea\u6211\u53cd\u7701\uff0c\u4ee5\u9032\u4e00\u6b65\u6539\u5584\u5168\u57df\u898f\u5283\u548c\u9ad8\u6548 KG \u63a2\u7d22\u3002\u5728\u591a\u500b KBQA \u57fa\u6e96\u4e0a\u7684\u5be6\u8b49\u8b49\u64da\u986f\u793a\u4e86 EffiQA \u7684\u6709\u6548\u6027\uff0c\u5728\u63a8\u7406\u6e96\u78ba\u6027\u548c\u904b\u7b97\u6210\u672c\u4e4b\u9593\u53d6\u5f97\u4e86\u6700\u4f73\u5e73\u8861\u3002\u6211\u5011\u5e0c\u671b\u6240\u63d0\u51fa\u7684\u65b0\u67b6\u69cb\uff0c\u900f\u904e\u91cd\u65b0\u5b9a\u7fa9 LLM \u548c KG \u7684\u6574\u5408\uff0c\u70ba\u9ad8\u6548\u3001\u77e5\u8b58\u5bc6\u96c6\u7684\u67e5\u8a62\u92ea\u8def\uff0c\u4fc3\u9032\u672a\u4f86\u57fa\u65bc\u77e5\u8b58\u7684\u554f\u7b54\u7814\u7a76\u3002", "author": "Zixuan Dong et.al.", "authors": "Zixuan Dong, Baoyun Peng, Yufei Wang, Jia Fu, Xiaodong Wang, Yongxue Shan, Xin Zhou", "id": "2406.01238v1", "paper_url": "http://arxiv.org/abs/2406.01238v1", "repo": "null"}}