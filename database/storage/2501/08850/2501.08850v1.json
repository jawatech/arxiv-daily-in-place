{"2501.08850": {"publish_time": "2025-01-15", "title": "Graph Counterfactual Explainable AI via Latent Space Traversal", "paper_summary": "Explaining the predictions of a deep neural network is a nontrivial task, yet\nhigh-quality explanations for predictions are often a prerequisite for\npractitioners to trust these models. Counterfactual explanations aim to explain\npredictions by finding the ''nearest'' in-distribution alternative input whose\nprediction changes in a pre-specified way. However, it remains an open question\nhow to define this nearest alternative input, whose solution depends on both\nthe domain (e.g. images, graphs, tabular data, etc.) and the specific\napplication considered. For graphs, this problem is complicated i) by their\ndiscrete nature, as opposed to the continuous nature of state-of-the-art graph\nclassifiers; and ii) by the node permutation group acting on the graphs. We\npropose a method to generate counterfactual explanations for any differentiable\nblack-box graph classifier, utilizing a case-specific permutation equivariant\ngraph variational autoencoder. We generate counterfactual explanations in a\ncontinuous fashion by traversing the latent space of the autoencoder across the\nclassification boundary of the classifier, allowing for seamless integration of\ndiscrete graph structure and continuous graph attributes. We empirically\nvalidate the approach on three graph datasets, showing that our model is\nconsistently high-performing and more robust than the baselines.", "paper_summary_zh": "\u89e3\u91cb\u6df1\u5ea6\u795e\u7d93\u7db2\u8def\u7684\u9810\u6e2c\u4e26\u975e\u6613\u4e8b\uff0c\u4f46\u9ad8\u54c1\u8cea\u7684\u9810\u6e2c\u89e3\u91cb\u901a\u5e38\u662f\u5be6\u52d9\u4eba\u54e1\u4fe1\u8cf4\u9019\u4e9b\u6a21\u578b\u7684\u5148\u6c7a\u689d\u4ef6\u3002\u53cd\u4e8b\u5be6\u89e3\u91cb\u65e8\u5728\u900f\u904e\u5c0b\u627e\u9810\u6e2c\u4ee5\u9810\u5148\u6307\u5b9a\u65b9\u5f0f\u6539\u8b8a\u7684\u300c\u6700\u8fd1\u300d\u540c\u5206\u4f48\u66ff\u4ee3\u8f38\u5165\uff0c\u4f86\u89e3\u91cb\u9810\u6e2c\u3002\u7136\u800c\uff0c\u5982\u4f55\u5b9a\u7fa9\u9019\u500b\u6700\u8fd1\u7684\u66ff\u4ee3\u8f38\u5165\u4ecd\u7136\u662f\u4e00\u500b\u958b\u653e\u554f\u984c\uff0c\u5176\u89e3\u6c7a\u65b9\u6848\u53d6\u6c7a\u65bc\u9818\u57df\uff08\u4f8b\u5982\u5f71\u50cf\u3001\u5716\u8868\u3001\u8868\u683c\u8cc7\u6599\u7b49\uff09\u548c\u6240\u8003\u616e\u7684\u7279\u5b9a\u61c9\u7528\u7a0b\u5f0f\u3002\u5c0d\u65bc\u5716\u8868\u800c\u8a00\uff0c\u9019\u500b\u554f\u984c\u7684\u8907\u96dc\u6027\u5728\u65bc\uff1ai\uff09\u8207\u6700\u5148\u9032\u5716\u8868\u5206\u985e\u5668\u7684\u9023\u7e8c\u6027\u8cea\u76f8\u53cd\uff0c\u5716\u8868\u7684\u96e2\u6563\u6027\u8cea\uff1b\u4ee5\u53ca ii\uff09\u4f5c\u7528\u65bc\u5716\u8868\u7684\u7bc0\u9ede\u7f6e\u63db\u7fa4\u3002\u6211\u5011\u63d0\u51fa\u4e00\u500b\u65b9\u6cd5\uff0c\u5229\u7528\u7279\u5b9a\u6848\u4f8b\u7f6e\u63db\u7b49\u8b8a\u5716\u8868\u8b8a\u7570\u81ea\u52d5\u7de8\u78bc\u5668\uff0c\u70ba\u4efb\u4f55\u53ef\u5fae\u5206\u7684\u9ed1\u76d2\u5716\u8868\u5206\u985e\u5668\u7522\u751f\u53cd\u4e8b\u5be6\u89e3\u91cb\u3002\u6211\u5011\u900f\u904e\u5728\u5206\u985e\u5668\u5206\u985e\u908a\u754c\u4e0a\u7a7f\u8d8a\u81ea\u52d5\u7de8\u78bc\u5668\u7684\u6f5b\u5728\u7a7a\u9593\uff0c\u4ee5\u9023\u7e8c\u7684\u65b9\u5f0f\u7522\u751f\u53cd\u4e8b\u5be6\u89e3\u91cb\uff0c\u5141\u8a31\u96e2\u6563\u5716\u8868\u7d50\u69cb\u548c\u9023\u7e8c\u5716\u8868\u5c6c\u6027\u7684\u7121\u7e2b\u6574\u5408\u3002\u6211\u5011\u5728\u4e09\u500b\u5716\u8868\u8cc7\u6599\u96c6\u4e0a\u5be6\u8b49\u9a57\u8b49\u4e86\u6b64\u65b9\u6cd5\uff0c\u986f\u793a\u6211\u5011\u7684\u6a21\u578b\u6548\u80fd\u59cb\u7d42\u5f88\u9ad8\uff0c\u4e14\u6bd4\u57fa\u7dda\u66f4\u5f37\u5065\u3002", "author": "Andreas Abildtrup Hansen et.al.", "authors": "Andreas Abildtrup Hansen, Paraskevas Pegios, Anna Calissano, Aasa Feragen", "id": "2501.08850v1", "paper_url": "http://arxiv.org/abs/2501.08850v1", "repo": "null"}}