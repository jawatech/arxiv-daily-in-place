{"2502.21321": {"publish_time": "2025-02-28", "title": "LLM Post-Training: A Deep Dive into Reasoning Large Language Models", "paper_summary": "Large Language Models (LLMs) have transformed the natural language processing\nlandscape and brought to life diverse applications. Pretraining on vast\nweb-scale data has laid the foundation for these models, yet the research\ncommunity is now increasingly shifting focus toward post-training techniques to\nachieve further breakthroughs. While pretraining provides a broad linguistic\nfoundation, post-training methods enable LLMs to refine their knowledge,\nimprove reasoning, enhance factual accuracy, and align more effectively with\nuser intents and ethical considerations. Fine-tuning, reinforcement learning,\nand test-time scaling have emerged as critical strategies for optimizing LLMs\nperformance, ensuring robustness, and improving adaptability across various\nreal-world tasks. This survey provides a systematic exploration of\npost-training methodologies, analyzing their role in refining LLMs beyond\npretraining, addressing key challenges such as catastrophic forgetting, reward\nhacking, and inference-time trade-offs. We highlight emerging directions in\nmodel alignment, scalable adaptation, and inference-time reasoning, and outline\nfuture research directions. We also provide a public repository to continually\ntrack developments in this fast-evolving field:\nhttps://github.com/mbzuai-oryx/Awesome-LLM-Post-training.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5df2\u7d93\u6539\u8b8a\u4e86\u81ea\u7136\u8a9e\u8a00\u8655\u7406\u9818\u57df\uff0c\u4e26\u5e36\u4f86\u4e86\u5404\u7a2e\u61c9\u7528\u3002\u5728\u9f90\u5927\u7684\u7db2\u8def\u898f\u6a21\u6578\u64da\u4e0a\u9032\u884c\u9810\u8a13\u7df4\u70ba\u9019\u4e9b\u6a21\u578b\u5960\u5b9a\u4e86\u57fa\u790e\uff0c\u4f46\u7814\u7a76\u793e\u7fa4\u73fe\u5728\u6b63\u8d8a\u4f86\u8d8a\u591a\u5730\u5c07\u91cd\u9ede\u8f49\u5411\u5f8c\u8a13\u7df4\u6280\u8853\uff0c\u4ee5\u53d6\u5f97\u9032\u4e00\u6b65\u7684\u7a81\u7834\u3002\u96d6\u7136\u9810\u8a13\u7df4\u63d0\u4f9b\u4e86\u5ee3\u6cdb\u7684\u8a9e\u8a00\u57fa\u790e\uff0c\u4f46\u5f8c\u8a13\u7df4\u65b9\u6cd5\u4f7f LLM \u80fd\u5920\u5b8c\u5584\u5176\u77e5\u8b58\u3001\u6539\u9032\u63a8\u7406\u3001\u63d0\u9ad8\u4e8b\u5be6\u6e96\u78ba\u6027\uff0c\u4e26\u66f4\u6709\u6548\u5730\u8207\u7528\u6236\u610f\u5716\u548c\u9053\u5fb7\u8003\u91cf\u4fdd\u6301\u4e00\u81f4\u3002\u5fae\u8abf\u3001\u5f37\u5316\u5b78\u7fd2\u548c\u6e2c\u8a66\u6642\u8abf\u6574\u5df2\u6210\u70ba\u512a\u5316 LLM \u6027\u80fd\u3001\u78ba\u4fdd\u7a69\u5065\u6027\u548c\u63d0\u9ad8\u5404\u7a2e\u5be6\u969b\u4efb\u52d9\u7684\u9069\u61c9\u6027\u7684\u95dc\u9375\u7b56\u7565\u3002\u672c\u7d9c\u8ff0\u7cfb\u7d71\u5730\u63a2\u8a0e\u4e86\u5f8c\u8a13\u7df4\u65b9\u6cd5\uff0c\u5206\u6790\u4e86\u5b83\u5011\u5728\u9810\u8a13\u7df4\u4e4b\u5916\u5b8c\u5584 LLM \u7684\u4f5c\u7528\uff0c\u89e3\u6c7a\u4e86\u8af8\u5982\u707d\u96e3\u6027\u907a\u5fd8\u3001\u734e\u52f5\u9ed1\u5ba2\u548c\u63a8\u7406\u6642\u9593\u6b0a\u8861\u7b49\u95dc\u9375\u6311\u6230\u3002\u6211\u5011\u91cd\u9ede\u4ecb\u7d39\u4e86\u6a21\u578b\u5c0d\u9f4a\u3001\u53ef\u64f4\u5c55\u9069\u61c9\u6027\u548c\u63a8\u7406\u6642\u63a8\u7406\u65b9\u9762\u7684\u65b0\u8208\u65b9\u5411\uff0c\u4e26\u6982\u8ff0\u4e86\u672a\u4f86\u7684\u7814\u7a76\u65b9\u5411\u3002\u6211\u5011\u9084\u63d0\u4f9b\u4e86\u4e00\u500b\u516c\u5171\u5b58\u5132\u5eab\u4f86\u6301\u7e8c\u8ffd\u8e64\u9019\u500b\u5feb\u901f\u767c\u5c55\u9818\u57df\u7684\u767c\u5c55\uff1ahttps://github.com/mbzuai-oryx/Awesome-LLM-Post-training\u3002\n", "author": "Komal Kumar et.al.", "authors": "Komal Kumar, Tajamul Ashraf, Omkar Thawakar, Rao Muhammad Anwer, Hisham Cholakkal, Mubarak Shah, Ming-Hsuan Yang, Phillip H. S. Torr, Salman Khan, Fahad Shahbaz Khan", "id": "2502.21321v1", "paper_url": "http://arxiv.org/abs/2502.21321v1", "repo": "null"}}