
### LLM
|Publish Date|Title|Authors|PDF|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-05-02**|**Prometheus 2: An Open Source Language Model Specialized in Evaluating Other Language Models**|Seungone Kim et.al.|[2405.01535v1](http://arxiv.org/abs/2405.01535v1)|[link](https://github.com/prometheus-eval/prometheus-eval)|
|**2024-05-02**|**Plan-Seq-Learn: Language Model Guided RL for Solving Long Horizon Robotics Tasks**|Murtaza Dalal et.al.|[2405.01534v1](http://arxiv.org/abs/2405.01534v1)|null|
|**2024-05-02**|**Improving Intervention Efficacy via Concept Realignment in Concept Bottleneck Models**|Nishad Singhi et.al.|[2405.01531v1](http://arxiv.org/abs/2405.01531v1)|null|
|**2024-05-02**|**FLAME: Factuality-Aware Alignment for Large Language Models**|Sheng-Chieh Lin et.al.|[2405.01525v1](http://arxiv.org/abs/2405.01525v1)|null|
|**2024-05-02**|**A separability-based approach to quantifying generalization: which layer is best?**|Luciano Dyballa et.al.|[2405.01524v2](http://arxiv.org/abs/2405.01524v2)|null|
|**2024-05-02**|**D2PO: Discriminator-Guided DPO with Response Evaluation Models**|Prasann Singhal et.al.|[2405.01511v1](http://arxiv.org/abs/2405.01511v1)|[link](https://github.com/PrasannS/d2po)|
|**2024-05-02**|**Analyzing the Role of Semantic Representations in the Era of Large Language Models**|Zhijing Jin et.al.|[2405.01502v1](http://arxiv.org/abs/2405.01502v1)|[link](https://github.com/causalnlp/amr_llm)|
|**2024-05-02**|**Controllable Text Generation in the Instruction-Tuning Era**|Dhananjay Ashok et.al.|[2405.01490v1](http://arxiv.org/abs/2405.01490v1)|null|
|**2024-05-02**|**MANTIS: Interleaved Multi-Image Instruction Tuning**|Dongfu Jiang et.al.|[2405.01483v1](http://arxiv.org/abs/2405.01483v1)|null|
|**2024-05-02**|**NeMo-Aligner: Scalable Toolkit for Efficient Model Alignment**|Gerald Shen et.al.|[2405.01481v1](http://arxiv.org/abs/2405.01481v1)|[link](https://github.com/nvidia/nemo-aligner)|
|**2024-05-02**|**V-FLUTE: Visual Figurative Language Understanding with Textual Explanations**|Arkadiy Saakyan et.al.|[2405.01474v1](http://arxiv.org/abs/2405.01474v1)|null|
|**2024-05-02**|**WildChat: 1M ChatGPT Interaction Logs in the Wild**|Wenting Zhao et.al.|[2405.01470v1](http://arxiv.org/abs/2405.01470v1)|null|
|**2024-05-02**|**Advancing human-centric AI for robust X-ray analysis through holistic self-supervised learning**|Th√©o Moutakanni et.al.|[2405.01469v1](http://arxiv.org/abs/2405.01469v1)|null|
|**2024-05-02**|**Understanding Retrieval-Augmented Task Adaptation for Vision-Language Models**|Yifei Ming et.al.|[2405.01468v1](http://arxiv.org/abs/2405.01468v1)|null|
|**2024-05-02**|**UQA: Corpus for Urdu Question Answering**|Samee Arif et.al.|[2405.01458v1](http://arxiv.org/abs/2405.01458v1)|[link](https://github.com/sameearif/uqa)|
|**2024-05-02**|**Creative Problem Solving in Large Language and Vision Models -- What Would it Take?**|Lakshmi Nair et.al.|[2405.01453v1](http://arxiv.org/abs/2405.01453v1)|[link](https://github.com/lnairgt/creative-problem-solving-llms)|
|**2024-05-02**|**Natural Language to Verilog: Design of a Recurrent Spiking Neural Network using Large Language Models and ChatGPT**|Paola Vitolo et.al.|[2405.01419v1](http://arxiv.org/abs/2405.01419v1)|null|
|**2024-05-02**|**MiniGPT-3D: Efficiently Aligning 3D Point Clouds with Large Language Models using 2D Priors**|Yuan Tang et.al.|[2405.01413v1](http://arxiv.org/abs/2405.01413v1)|null|
|**2024-05-02**|**Goal-conditioned reinforcement learning for ultrasound navigation guidance**|Abdoul Aziz Amadou et.al.|[2405.01409v1](http://arxiv.org/abs/2405.01409v1)|null|
|**2024-05-02**|**Verification and Refinement of Natural Language Explanations through LLM-Symbolic Theorem Proving**|Xin Quan et.al.|[2405.01379v1](http://arxiv.org/abs/2405.01379v1)|null|
|**2024-05-02**|**Topics in the Study of the Pragmatic Functions of Phonetic Reduction in Dialog**|Nigel G. Ward et.al.|[2405.01376v1](http://arxiv.org/abs/2405.01376v1)|[link](https://github.com/Caortega4/reduction-detection)|
|**2024-05-02**|**GAIA: A General AI Assistant for Intelligent Accelerator Operations**|Frank Mayet et.al.|[2405.01359v1](http://arxiv.org/abs/2405.01359v1)|null|
|**2024-05-02**|**The Power of Question Translation Training in Multilingual Reasoning: Broadened Scope and Deepened Insights**|Wenhao Zhu et.al.|[2405.01345v1](http://arxiv.org/abs/2405.01345v1)|[link](https://github.com/njunlp/qalign)|
|**2024-05-02**|**Overcoming LLM Challenges using RAG-Driven Precision in Coffee Leaf Disease Remediation**|Dr. Selva Kumar S et.al.|[2405.01310v1](http://arxiv.org/abs/2405.01310v1)|null|
|**2024-05-02**|**Distributed Representations Enable Robust Multi-Timescale Computation in Neuromorphic Hardware**|Madison Cotteret et.al.|[2405.01305v1](http://arxiv.org/abs/2405.01305v1)|null|
|**2024-05-02**|**The Effectiveness of LLMs as Annotators: A Comparative Overview and Empirical Analysis of Direct Representation**|Maja Pavlovic et.al.|[2405.01299v1](http://arxiv.org/abs/2405.01299v1)|null|
|**2024-05-02**|**Low-resource speech recognition and dialect identification of Irish in a multi-task framework**|Liam Lonergan et.al.|[2405.01293v1](http://arxiv.org/abs/2405.01293v1)|null|
|**2024-05-02**|**Reinforcement Learning for Edit-Based Non-Autoregressive Neural Machine Translation**|Hao Wang et.al.|[2405.01280v1](http://arxiv.org/abs/2405.01280v1)|null|
|**2024-05-02**|**Towards Inclusive Face Recognition Through Synthetic Ethnicity Alteration**|Praveen Kumar Chandaliya et.al.|[2405.01273v1](http://arxiv.org/abs/2405.01273v1)|null|
|**2024-05-02**|**MFTraj: Map-Free, Behavior-Driven Trajectory Prediction for Autonomous Driving**|Haicheng Liao et.al.|[2405.01266v1](http://arxiv.org/abs/2405.01266v1)|null|
|**2024-05-02**|**Identification of Entailment and Contradiction Relations between Natural Language Sentences: A Neurosymbolic Approach**|Xuyao Feng et.al.|[2405.01259v1](http://arxiv.org/abs/2405.01259v1)|null|
|**2024-05-02**|**Prompt engineering paradigms for medical applications: scoping review and recommendations for better practices**|Jamil Zaghir et.al.|[2405.01249v1](http://arxiv.org/abs/2405.01249v1)|null|
|**2024-05-02**|**TRAMBA: A Hybrid Transformer and Mamba Architecture for Practical Audio and Bone Conduction Speech Super Resolution and Enhancement on Mobile and Wearable Platforms**|Yueyuan Sui et.al.|[2405.01242v1](http://arxiv.org/abs/2405.01242v1)|null|
|**2024-05-02**|**Boosting Jailbreak Attack with Momentum**|Yihao Zhang et.al.|[2405.01229v1](http://arxiv.org/abs/2405.01229v1)|[link](https://github.com/weizeming/momentum-attack-llm)|
|**2024-05-02**|**DMON: A Simple yet Effective Approach for Argument Structure Learning**|Wei Sun et.al.|[2405.01216v1](http://arxiv.org/abs/2405.01216v1)|[link](https://github.com/vrcmf/dmon)|
|**2024-05-02**|**Towards Interpretable Reinforcement Learning with Constrained Normalizing Flow Policies**|Finn Rietz et.al.|[2405.01198v1](http://arxiv.org/abs/2405.01198v1)|null|
|**2024-05-02**|**Gradient-Congruity Guided Federated Sparse Training**|Chris Xing Tian et.al.|[2405.01189v1](http://arxiv.org/abs/2405.01189v1)|null|
|**2024-05-02**|**Potential Energy based Mixture Model for Noisy Label Learning**|Zijia Wang et.al.|[2405.01186v1](http://arxiv.org/abs/2405.01186v1)|null|
|**2024-05-02**|**Uncertainty-aware self-training with expectation maximization basis transformation**|Zijia Wang et.al.|[2405.01175v1](http://arxiv.org/abs/2405.01175v1)|null|
|**2024-05-02**|**TartuNLP at EvaLatin 2024: Emotion Polarity Detection**|Aleksei Dorkin et.al.|[2405.01159v1](http://arxiv.org/abs/2405.01159v1)|null|
|**2024-05-02**|**Interpretable Data-driven Anomaly Detection in Industrial Processes with ExIFFI**|Davide Frizzo et.al.|[2405.01158v1](http://arxiv.org/abs/2405.01158v1)|null|
|**2024-05-02**|**Self-Supervised Learning for Interventional Image Analytics: Towards Robust Device Trackers**|Saahil Islam et.al.|[2405.01156v1](http://arxiv.org/abs/2405.01156v1)|null|
|**2024-05-02**|**Qualia and the Formal Structure of Meaning**|Xerxes D. Arsiwalla et.al.|[2405.01148v1](http://arxiv.org/abs/2405.01148v1)|null|
|**2024-05-02**|**It Couldn't Help But Overhear: On the Limits of Modelling Meta-Communicative Grounding Acts with Supervised Learning**|Brielen Madureira et.al.|[2405.01139v1](http://arxiv.org/abs/2405.01139v1)|null|
|**2024-05-02**|**Efficient Data Generation for Source-grounded Information-seeking Dialogs: A Use Case for Meeting Transcripts**|Lotem Golany et.al.|[2405.01121v1](http://arxiv.org/abs/2405.01121v1)|null|
|**2024-05-02**|**Domain-Transferred Synthetic Data Generation for Improving Monocular Depth Estimation**|Seungyeop Lee et.al.|[2405.01113v1](http://arxiv.org/abs/2405.01113v1)|null|
|**2024-05-02**|**Federated Learning with Heterogeneous Data Handling for Robust Vehicular Object Detection**|Ahmad Khalil et.al.|[2405.01108v1](http://arxiv.org/abs/2405.01108v1)|null|
|**2024-05-02**|**Less is More: on the Over-Globalizing Problem in Graph Transformers**|Yujie Xing et.al.|[2405.01102v1](http://arxiv.org/abs/2405.01102v1)|[link](https://github.com/null-xyj/CoBFormer)|
|**2024-05-02**|**Silencing the Risk, Not the Whistle: A Semi-automated Text Sanitization Tool for Mitigating the Risk of Whistleblower Re-Identification**|Dimitri Staufer et.al.|[2405.01097v1](http://arxiv.org/abs/2405.01097v1)|null|
|**2024-05-02**|**Poisoning Attacks on Federated Learning for Autonomous Driving**|Sonakshi Garg et.al.|[2405.01073v1](http://arxiv.org/abs/2405.01073v1)|null|
|**2024-05-02**|**AB-Training: A Communication-Efficient Approach for Distributed Low-Rank Learning**|Daniel Coquelin et.al.|[2405.01067v1](http://arxiv.org/abs/2405.01067v1)|null|
|**2024-05-02**|**HandSSCA: 3D Hand Mesh Reconstruction with State Space Channel Attention from RGB images**|Zixun Jiao et.al.|[2405.01066v1](http://arxiv.org/abs/2405.01066v1)|null|
|**2024-05-02**|**A text-based, generative deep learning model for soil reflectance spectrum simulation in the VIS-NIR (400-2499 nm) bands**|Tong Lei et.al.|[2405.01060v1](http://arxiv.org/abs/2405.01060v1)|[link](https://github.com/gemini-breeding/sogm_soil_spectra_simulation)|
|**2024-05-02**|**Leverage Multi-source Traffic Demand Data Fusion with Transformer Model for Urban Parking Prediction**|Yin Huang et.al.|[2405.01055v1](http://arxiv.org/abs/2405.01055v1)|null|
|**2024-05-02**|**Explicitly Modeling Generality into Self-Supervised Learning**|Jingyao Wang et.al.|[2405.01053v1](http://arxiv.org/abs/2405.01053v1)|null|
|**2024-05-02**|**Few Shot Class Incremental Learning using Vision-Language models**|Anurag Kumar et.al.|[2405.01040v1](http://arxiv.org/abs/2405.01040v1)|null|
|**2024-05-02**|**MVMoE: Multi-Task Vehicle Routing Solver with Mixture-of-Experts**|Jianan Zhou et.al.|[2405.01029v1](http://arxiv.org/abs/2405.01029v1)|[link](https://github.com/royalskye/routing-mvmoe)|
|**2024-05-02**|**UniGen: Universal Domain Generalization for Sentiment Classification via Zero-shot Dataset Generation**|Juhwan Choi et.al.|[2405.01022v2](http://arxiv.org/abs/2405.01022v2)|null|
|**2024-05-02**|**Deep Learning Models in Speech Recognition: Measuring GPU Energy Consumption, Impact of Noise and Model Quantization for Edge Deployment**|Aditya Chakravarty et.al.|[2405.01004v1](http://arxiv.org/abs/2405.01004v1)|[link](https://github.com/zzadiues3338/asr-energy-jetson)|
|**2024-05-02**|**The IgboAPI Dataset: Empowering Igbo Language Technologies through Multi-dialectal Enrichment**|Chris Chinenye Emezue et.al.|[2405.00997v1](http://arxiv.org/abs/2405.00997v1)|null|
|**2024-05-02**|**Context-Aware Clustering using Large Language Models**|Sindhu Tipirneni et.al.|[2405.00988v1](http://arxiv.org/abs/2405.00988v1)|null|
|**2024-05-02**|**Progressive Feedforward Collapse of ResNet Training**|Sicong Wang et.al.|[2405.00985v1](http://arxiv.org/abs/2405.00985v1)|null|
|**2024-05-02**|**On the Evaluation of Machine-Generated Reports**|James Mayfield et.al.|[2405.00982v1](http://arxiv.org/abs/2405.00982v1)|null|
|**2024-05-02**|**Bayesian Optimization with LLM-Based Acquisition Functions for Natural Language Preference Elicitation**|David Eric Austin et.al.|[2405.00981v1](http://arxiv.org/abs/2405.00981v1)|null|
|**2024-05-02**|**A Hong Kong Sign Language Corpus Collected from Sign-interpreted TV News**|Zhe Niu et.al.|[2405.00980v1](http://arxiv.org/abs/2405.00980v1)|null|
|**2024-05-02**|**Language Fairness in Multilingual Information Retrieval**|Eugene Yang et.al.|[2405.00978v1](http://arxiv.org/abs/2405.00978v1)|[link](https://github.com/hltcoe/peer_measure)|
|**2024-05-02**|**Distillation for Multilingual Information Retrieval**|Eugene Yang et.al.|[2405.00977v1](http://arxiv.org/abs/2405.00977v1)|[link](https://github.com/hltcoe/colbert-x)|
|**2024-05-02**|**PLAID SHIRTTT for Large-Scale Streaming Dense Retrieval**|Dawn Lawrie et.al.|[2405.00975v1](http://arxiv.org/abs/2405.00975v1)|[link](https://github.com/hltcoe/colbert-x)|
|**2024-05-02**|**CACTUS: Chemistry Agent Connecting Tool-Usage to Science**|Andrew D. McNaughton et.al.|[2405.00972v1](http://arxiv.org/abs/2405.00972v1)|null|
|**2024-05-02**|**How Can I Get It Right? Using GPT to Rephrase Incorrect Trainee Responses**|Jionghao Lin et.al.|[2405.00970v1](http://arxiv.org/abs/2405.00970v1)|null|
|**2024-05-02**|**Efficient Compression of Multitask Multilingual Speech Models**|Thomas Palmeira Ferraz et.al.|[2405.00966v1](http://arxiv.org/abs/2405.00966v1)|null|
|**2024-05-02**|**Generative manufacturing systems using diffusion models and ChatGPT**|Xingyu Li et.al.|[2405.00958v1](http://arxiv.org/abs/2405.00958v1)|null|
|**2024-05-02**|**Provably Efficient Reinforcement Learning for Adversarial Restless Multi-Armed Bandits with Unknown Transitions and Bandit Feedback**|Guojun Xiong et.al.|[2405.00950v1](http://arxiv.org/abs/2405.00950v1)|null|
|**2024-05-02**|**The Role of Model Architecture and Scale in Predicting Molecular Properties: Insights from Fine-Tuning RoBERTa, BART, and LLaMA**|Lee Youngmin et.al.|[2405.00949v1](http://arxiv.org/abs/2405.00949v1)|null|
|**2024-05-02**|**Modeling Empathetic Alignment in Conversation**|Jiamin Yang et.al.|[2405.00948v1](http://arxiv.org/abs/2405.00948v1)|null|
|**2024-05-02**|**LLaVA Finds Free Lunch: Teaching Human Behavior Improves Content Understanding Abilities Of LLMs**|Somesh Singh et.al.|[2405.00942v1](http://arxiv.org/abs/2405.00942v1)|null|
|**2024-05-02**|**EchoScene: Indoor Scene Generation via Information Echo over Scene Graph Diffusion**|Guangyao Zhai et.al.|[2405.00915v1](http://arxiv.org/abs/2405.00915v1)|null|
|**2024-05-01**|**Transformer-Based Self-Supervised Learning for Histopathological Classification of Ischemic Stroke Clot Origin**|K. Yeh et.al.|[2405.00908v1](http://arxiv.org/abs/2405.00908v1)|null|
|**2024-05-01**|**LOTUS: Improving Transformer Efficiency with Sparsity Pruning and Data Lottery Tickets**|Ojasw Upadhyay et.al.|[2405.00906v1](http://arxiv.org/abs/2405.00906v1)|null|
|**2024-05-01**|**A Named Entity Recognition and Topic Modeling-based Solution for Locating and Better Assessment of Natural Disasters in Social Media**|Ayaz Mehmood et.al.|[2405.00903v1](http://arxiv.org/abs/2405.00903v1)|null|
|**2024-05-01**|**Characterising the Creative Process in Humans and Large Language Models**|Surabhi S. Nath et.al.|[2405.00899v1](http://arxiv.org/abs/2405.00899v1)|[link](https://github.com/surabhisnath/creative_process)|
|**2024-05-01**|**Wake Vision: A Large-scale, Diverse Dataset and Benchmark Suite for TinyML Person Detection**|Colby Banbury et.al.|[2405.00892v1](http://arxiv.org/abs/2405.00892v1)|null|
|**2024-05-01**|**DynaMo: Accelerating Language Model Inference with Dynamic Multi-Token Sampling**|Shikhar Tuli et.al.|[2405.00888v1](http://arxiv.org/abs/2405.00888v1)|null|
|**2024-05-01**|**Beyond Human Vision: The Role of Large Vision Language Models in Microscope Image Analysis**|Prateek Verma et.al.|[2405.00876v1](http://arxiv.org/abs/2405.00876v1)|null|
|**2024-05-01**|**Artificial intelligence for context-aware visual change detection in software test automation**|Milad Moradi et.al.|[2405.00874v1](http://arxiv.org/abs/2405.00874v1)|null|
|**2024-05-01**|**Math Multiple Choice Question Generation via Human-Large Language Model Collaboration**|Jaewook Lee et.al.|[2405.00864v1](http://arxiv.org/abs/2405.00864v1)|null|
|**2024-05-01**|**Can a Hallucinating Model help in Reducing Human "Hallucination"?**|Sowmya S Sundaram et.al.|[2405.00843v1](http://arxiv.org/abs/2405.00843v1)|null|
|**2024-05-01**|**Sim-Grasp: Learning 6-DOF Grasp Policies for Cluttered Environments Using a Synthetic Benchmark**|Juncheng Li et.al.|[2405.00841v1](http://arxiv.org/abs/2405.00841v1)|[link](https://github.com/junchengli1/Sim-Grasp)|
|**2024-05-01**|**Communication-Efficient Training Workload Balancing for Decentralized Multi-Agent Learning**|Seyed Mahmoud Sajjadi Mohammadabadi et.al.|[2405.00839v1](http://arxiv.org/abs/2405.00839v1)|null|
|**2024-05-01**|**WIBA: What Is Being Argued? A Comprehensive Approach to Argument Mining**|Arman Irani et.al.|[2405.00828v1](http://arxiv.org/abs/2405.00828v1)|[link](https://github.com/Armaniii/WIBA)|
|**2024-05-01**|**"Ask Me Anything": How Comcast Uses LLMs to Assist Agents in Real Time**|Scott Rome et.al.|[2405.00801v1](http://arxiv.org/abs/2405.00801v1)|null|
|**2024-05-01**|**Obtaining Favorable Layouts for Multiple Object Generation**|Barak Battash et.al.|[2405.00791v1](http://arxiv.org/abs/2405.00791v1)|null|
|**2024-05-01**|**SCAR: Scheduling Multi-Model AI Workloads on Heterogeneous Multi-Chiplet Module Accelerators**|Mohanad Odema et.al.|[2405.00790v1](http://arxiv.org/abs/2405.00790v1)|null|
|**2024-05-01**|**Self-Play Preference Optimization for Language Model Alignment**|Yue Wu et.al.|[2405.00675v1](http://arxiv.org/abs/2405.00675v1)|null|
|**2024-05-01**|**Is Bigger Edit Batch Size Always Better? -- An Empirical Study on Model Editing with Llama-3**|Junsang Yoon et.al.|[2405.00664v1](http://arxiv.org/abs/2405.00664v1)|[link](https://github.com/scalable-model-editing/unified-model-editing)|
|**2024-05-01**|**NLU-STR at SemEval-2024 Task 1: Generative-based Augmentation and Encoder-based Scoring for Semantic Textual Relatedness**|Sanad Malaysha et.al.|[2405.00659v1](http://arxiv.org/abs/2405.00659v1)|null|
|**2024-05-01**|**RST-LoRA: A Discourse-Aware Low-Rank Adaptation for Long Document Abstractive Summarization**|Dongqi Pu et.al.|[2405.00657v1](http://arxiv.org/abs/2405.00657v1)|null|
|**2024-05-01**|**ConstrainedZero: Chance-Constrained POMDP Planning using Learned Probabilistic Failure Surrogates and Adaptive Safety Constraints**|Robert J. Moss et.al.|[2405.00644v1](http://arxiv.org/abs/2405.00644v1)|null|
|**2024-05-01**|**When Quantization Affects Confidence of Large Language Models?**|Irina Proskurina et.al.|[2405.00632v1](http://arxiv.org/abs/2405.00632v1)|[link](https://github.com/upunaprosk/quantized-lm-confidence)|
|**2024-05-01**|**"I'm Not Sure, But...": Examining the Impact of Large Language Models' Uncertainty Expression on User Reliance and Trust**|Sunnie S. Y. Kim et.al.|[2405.00623v1](http://arxiv.org/abs/2405.00623v1)|null|

#### Abstracts
##### **Prometheus 2: An Open Source Language Model Specialized in Evaluating Other Language Models**
2405.01535v1 by Seungone Kim,Juyoung Suk,Shayne Longpre,Bill Yuchen Lin,Jamin Shin,Sean Welleck,Graham Neubig,Moontae Lee,Kyungjae Lee,Minjoon Seo

Proprietary LMs such as GPT-4 are often employed to assess the quality of
responses from various LMs. However, concerns including transparency,
controllability, and affordability strongly motivate the development of
open-source LMs specialized in evaluations. On the other hand, existing open
evaluator LMs exhibit critical shortcomings: 1) they issue scores that
significantly diverge from those assigned by humans, and 2) they lack the
flexibility to perform both direct assessment and pairwise ranking, the two
most prevalent forms of assessment. Additionally, they do not possess the
ability to evaluate based on custom evaluation criteria, focusing instead on
general attributes like helpfulness and harmlessness. To address these issues,
we introduce Prometheus 2, a more powerful evaluator LM than its predecessor
that closely mirrors human and GPT-4 judgements. Moreover, it is capable of
processing both direct assessment and pair-wise ranking formats grouped with a
user-defined evaluation criteria. On four direct assessment benchmarks and four
pairwise ranking benchmarks, Prometheus 2 scores the highest correlation and
agreement with humans and proprietary LM judges among all tested open evaluator
LMs. Our models, code, and data are all publicly available at
https://github.com/prometheus-eval/prometheus-eval.

ÊëòË¶ÅÔºöÂ∞àÊúâÁöÑË™ûË®ÄÊ®°ÂûãÔºå‰æãÂ¶Ç GPT-4ÔºåÈÄöÂ∏∏Áî®ÊñºË©ï‰º∞ÂêÑÁ®ÆË™ûË®ÄÊ®°ÂûãÁöÑÂõûÊáâÂìÅË≥™„ÄÇÁÑ∂ËÄåÔºåÂåÖÊã¨ÈÄèÊòéÂ∫¶„ÄÅÂèØÊéßÊÄßÂíåÁ∂ìÊøüÂØ¶ÊÉ†ÊÄßÁöÑÂïèÈ°åÂº∑ÁÉàÂú∞‰øÉ‰ΩøÈñãÁôºÂ∞àÈñÄÁî®ÊñºË©ï‰º∞ÁöÑÈñãÊ∫êË™ûË®ÄÊ®°Âûã„ÄÇÂè¶‰∏ÄÊñπÈù¢ÔºåÁèæÊúâÁöÑÈñãÊîæÂºèË©ï‰º∞Âô®Ë™ûË®ÄÊ®°ÂûãË°®ÁèæÂá∫Âö¥ÈáçÁöÑÁº∫ÈªûÔºö1) ÂÆÉÂÄëÁôºÂá∫ÁöÑÂàÜÊï∏Ëàá‰∫∫È°ûÂàÜÈÖçÁöÑÂàÜÊï∏ÊúâÈ°ØËëóÂ∑ÆÁï∞Ôºå‰ª•Âèä 2) ÂÆÉÂÄëÁº∫‰πèÂü∑Ë°åÁõ¥Êé•Ë©ï‰º∞ÂíåÊàêÂ∞çÊéíÂêçÈÄôÂÖ©Á®ÆÊúÄÊôÆÈÅçÁöÑË©ï‰º∞ÂΩ¢ÂºèÁöÑÈùàÊ¥ªÊÄß„ÄÇÊ≠§Â§ñÔºåÂÆÉÂÄë‰∏çÂÖ∑ÂÇôÊ†πÊìöËá™Ë®ÇË©ï‰º∞Ê®ôÊ∫ñÈÄ≤Ë°åË©ï‰º∞ÁöÑËÉΩÂäõÔºåËÄåÊòØÂ∞àÊ≥®Êñº‰∏ÄËà¨Â±¨ÊÄßÔºå‰æãÂ¶ÇÊúâÂπ´Âä©ÊÄßÂíåÁÑ°ÂÆ≥ÊÄß„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÂïèÈ°åÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü Prometheus 2ÔºåÂÆÉÊØîÂÖ∂ÂâçË∫´Êõ¥Âº∑Â§ßÁöÑË©ï‰º∞Âô®Ë™ûË®ÄÊ®°ÂûãÔºåÂÆÉÂØÜÂàáÂèçÊò†‰∫Ü‰∫∫È°ûÂíå GPT-4 ÁöÑÂà§Êñ∑„ÄÇÊ≠§Â§ñÔºåÂÆÉËÉΩÂ§†ËôïÁêÜËàá‰ΩøÁî®ËÄÖÂÆöÁæ©ÁöÑË©ï‰º∞Ê®ôÊ∫ñÂàÜÁµÑÁöÑÁõ¥Êé•Ë©ï‰º∞ÂíåÊàêÂ∞çÊéíÂêçÊ†ºÂºè„ÄÇÂú®ÂõõÂÄãÁõ¥Êé•Ë©ï‰º∞Âü∫Ê∫ñÂíåÂõõÂÄãÊàêÂ∞çÊéíÂêçÂü∫Ê∫ñ‰∏äÔºåPrometheus 2 Âú®ÊâÄÊúâÊ∏¨Ë©¶ÁöÑÈñãÊîæÂºèË©ï‰º∞Âô®Ë™ûË®ÄÊ®°Âûã‰∏≠Ëàá‰∫∫È°ûÂíåÂ∞àÊúâË™ûË®ÄÊ®°ÂûãË©ïÂØ©ÁöÑÂàÜÊï∏Áõ∏ÈóúÊÄßÂíå‰∏ÄËá¥ÊÄßÊúÄÈ´ò„ÄÇÊàëÂÄëÁöÑÊ®°Âûã„ÄÅÁ®ãÂºèÁ¢ºÂíåË≥áÊñôÈÉΩÂÖ¨ÈñãÊñº https://github.com/prometheus-eval/prometheus-eval„ÄÇ

##### **Plan-Seq-Learn: Language Model Guided RL for Solving Long Horizon Robotics Tasks**
2405.01534v1 by Murtaza Dalal,Tarun Chiruvolu,Devendra Chaplot,Ruslan Salakhutdinov

Large Language Models (LLMs) have been shown to be capable of performing
high-level planning for long-horizon robotics tasks, yet existing methods
require access to a pre-defined skill library (e.g. picking, placing, pulling,
pushing, navigating). However, LLM planning does not address how to design or
learn those behaviors, which remains challenging particularly in long-horizon
settings. Furthermore, for many tasks of interest, the robot needs to be able
to adjust its behavior in a fine-grained manner, requiring the agent to be
capable of modifying low-level control actions. Can we instead use the
internet-scale knowledge from LLMs for high-level policies, guiding
reinforcement learning (RL) policies to efficiently solve robotic control tasks
online without requiring a pre-determined set of skills? In this paper, we
propose Plan-Seq-Learn (PSL): a modular approach that uses motion planning to
bridge the gap between abstract language and learned low-level control for
solving long-horizon robotics tasks from scratch. We demonstrate that PSL
achieves state-of-the-art results on over 25 challenging robotics tasks with up
to 10 stages. PSL solves long-horizon tasks from raw visual input spanning four
benchmarks at success rates of over 85%, out-performing language-based,
classical, and end-to-end approaches. Video results and code at
https://mihdalal.github.io/planseqlearn/

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤Ë¢´Ë≠âÊòéËÉΩÂ§†Âü∑Ë°åÈï∑ÊúüÊ©üÂô®‰∫∫‰ªªÂãôÁöÑÈ´òÈöéË¶èÂäÉÔºå‰ΩÜÁèæÊúâÊñπÊ≥ïÈúÄË¶ÅÂ≠òÂèñÈ†êÂÖàÂÆöÁæ©ÁöÑÊäÄËÉΩÂ∫´ (‰æãÂ¶ÇÔºåÊåëÈÅ∏„ÄÅÊîæÁΩÆ„ÄÅÊãâÂãï„ÄÅÊé®Âãï„ÄÅÂ∞éËà™)„ÄÇÁÑ∂ËÄåÔºåLLM Ë¶èÂäÉ‰∏¶Êú™Ë™™ÊòéÂ¶Ç‰ΩïË®≠Ë®àÊàñÂ≠∏ÁøíÈÄô‰∫õË°åÁÇ∫ÔºåÈÄôÂú®Èï∑ÊúüË®≠ÂÆö‰∏≠‰ªçÁÑ∂ÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÊ≠§Â§ñÔºåÂ∞çÊñºË®±Â§öÊÑüËààË∂£ÁöÑ‰ªªÂãôÔºåÊ©üÂô®‰∫∫ÈúÄË¶ÅËÉΩÂ§†‰ª•Á¥∞Á∑ªÁöÑÊñπÂºèË™øÊï¥ÂÖ∂Ë°åÁÇ∫ÔºåÈÄôÈúÄË¶Å‰ª£ÁêÜËÉΩÂ§†‰øÆÊîπ‰ΩéÈöéÊéßÂà∂Âãï‰Ωú„ÄÇÊàëÂÄëÊòØÂê¶ÂèØ‰ª•ÊîπÁî® LLM ÁöÑÁ∂≤Ë∑ØË¶èÊ®°Áü•Ë≠ò‰æÜÂà∂ÂÆöÈ´òÈöéÊîøÁ≠ñÔºåÂºïÂ∞éÂº∑ÂåñÂ≠∏Áøí (RL) ÊîøÁ≠ñÊúâÊïàÁéáÂú∞Ëß£Ê±∫Ê©üÂô®‰∫∫ÊéßÂà∂‰ªªÂãôÔºåËÄå‰∏çÈúÄË¶ÅÈ†êÂÖàË®≠ÂÆöÁöÑÊäÄËÉΩÁµÑÔºüÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫ Plan-Seq-Learn (PSL)Ôºö‰∏ÄÁ®ÆÊ®°ÁµÑÂåñÊñπÊ≥ïÔºå‰ΩøÁî®Âãï‰ΩúË¶èÂäÉ‰æÜÂΩåË£úÊäΩË±°Ë™ûË®ÄÂíåÂ≠∏Áøí‰ΩéÈöéÊéßÂà∂‰πãÈñìÁöÑÂ∑ÆË∑ùÔºåÂæûÈ†≠ÈñãÂßãËß£Ê±∫Èï∑ÊúüÊ©üÂô®‰∫∫‰ªªÂãô„ÄÇÊàëÂÄëË≠âÊòé PSL Âú®Ë∂ÖÈÅé 25 ÂÄãÂÖ∑ÊúâÊåëÊà∞ÊÄßÁöÑÊ©üÂô®‰∫∫‰ªªÂãô‰∏≠ÂèñÂæóÊúÄÂÖàÈÄ≤ÁöÑÁµêÊûúÔºåÊúÄÂ§öÊúâ 10 ÂÄãÈöéÊÆµ„ÄÇPSL ÂæûÂéüÂßãË¶ñË¶∫Ëº∏ÂÖ•‰∏≠Ëß£Ê±∫Èï∑Êúü‰ªªÂãôÔºåÊ©´Ë∑®ÂõõÂÄãÂü∫Ê∫ñÔºåÊàêÂäüÁéáË∂ÖÈÅé 85%ÔºåÂÑ™ÊñºÂü∫ÊñºË™ûË®Ä„ÄÅÂÇ≥Áµ±ÂíåÁ´ØÂà∞Á´ØÁöÑÊñπÊ≥ï„ÄÇÂΩ±ÁâáÁµêÊûúÂíåÁ®ãÂºèÁ¢ºË´ãÂèÉÈñ± https://mihdalal.github.io/planseqlearn/

##### **Improving Intervention Efficacy via Concept Realignment in Concept Bottleneck Models**
2405.01531v1 by Nishad Singhi,Jae Myung Kim,Karsten Roth,Zeynep Akata

Concept Bottleneck Models (CBMs) ground image classification on
human-understandable concepts to allow for interpretable model decisions.
Crucially, the CBM design inherently allows for human interventions, in which
expert users are given the ability to modify potentially misaligned concept
choices to influence the decision behavior of the model in an interpretable
fashion. However, existing approaches often require numerous human
interventions per image to achieve strong performances, posing practical
challenges in scenarios where obtaining human feedback is expensive. In this
paper, we find that this is noticeably driven by an independent treatment of
concepts during intervention, wherein a change of one concept does not
influence the use of other ones in the model's final decision. To address this
issue, we introduce a trainable concept intervention realignment module, which
leverages concept relations to realign concept assignments post-intervention.
Across standard, real-world benchmarks, we find that concept realignment can
significantly improve intervention efficacy; significantly reducing the number
of interventions needed to reach a target classification performance or concept
prediction accuracy. In addition, it easily integrates into existing
concept-based architectures without requiring changes to the models themselves.
This reduced cost of human-model collaboration is crucial to enhancing the
feasibility of CBMs in resource-constrained environments.

ÊëòË¶ÅÔºöÊ¶ÇÂøµÁì∂È†∏Ê®°Âûã (CBM) Â∞áÂΩ±ÂÉèÂàÜÈ°ûÂª∫Á´ãÂú®‰∫∫È°ûÂèØÁêÜËß£ÁöÑÊ¶ÇÂøµ‰∏äÔºå‰ª•ÂÖÅË®±ÂèØËß£ÈáãÁöÑÊ®°ÂûãÊ±∫Á≠ñ„ÄÇËá≥ÈóúÈáçË¶ÅÁöÑÊòØÔºåCBM Ë®≠Ë®àÊú¨Ë≥™‰∏äÂÖÅË®±‰∫∫È°û‰ªãÂÖ•ÔºåÂ∞àÂÆ∂‰ΩøÁî®ËÄÖÂèØ‰ª•‰øÆÊîπÊΩõÂú®ÈåØË™§Â∞çÈΩäÁöÑÊ¶ÇÂøµÈÅ∏ÊìáÔºå‰ª•ÂèØËß£ÈáãÁöÑÊñπÂºèÂΩ±ÈüøÊ®°ÂûãÁöÑÊ±∫Á≠ñË°åÁÇ∫„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÁöÑÊñπÊ≥ïÈÄöÂ∏∏ÈúÄË¶ÅÂ∞çÊØèÂºµÂΩ±ÂÉèÈÄ≤Ë°åÂ§ßÈáèÁöÑ‰∫∫Â∑•‰ªãÂÖ•ÊâçËÉΩÈÅîÂà∞Âº∑Â§ßÁöÑÊïàËÉΩÔºåÂú®ÂèñÂæó‰∫∫Â∑•ÂõûÈ•ãÊàêÊú¨È´òÊòÇÁöÑÊÉÖÊ≥Å‰∏ãÔºåÈÄôÊúÉÈÄ†ÊàêÂØ¶ÈöõÊåëÊà∞„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÁôºÁèæÈÄôÈ°ØËëóÂú∞ÂèóÂà∞‰ªãÂÖ•ÊúüÈñìÊ¶ÇÂøµÁç®Á´ãËôïÁêÜÁöÑÈ©ÖÂãïÔºåÂÖ∂‰∏≠‰∏ÄÂÄãÊ¶ÇÂøµÁöÑÊîπËÆä‰∏¶‰∏çÊúÉÂΩ±ÈüøÊ®°ÂûãÊúÄÁµÇÊ±∫Á≠ñ‰∏≠ÂÖ∂‰ªñÊ¶ÇÂøµÁöÑ‰ΩøÁî®„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜÂèØË®ìÁ∑¥ÁöÑÊ¶ÇÂøµ‰ªãÂÖ•ÈáçÊñ∞Â∞çÈΩäÊ®°ÁµÑÔºåÂÆÉÂà©Áî®Ê¶ÇÂøµÈóú‰øÇÂú®‰ªãÂÖ•ÂæåÈáçÊñ∞Â∞çÈΩäÊ¶ÇÂøµÊåáÊ¥æ„ÄÇÂú®Ê®ôÊ∫ñÁöÑÁúüÂØ¶‰∏ñÁïåÂü∫Ê∫ñ‰∏≠ÔºåÊàëÂÄëÁôºÁèæÊ¶ÇÂøµÈáçÊñ∞Â∞çÈΩäÂèØ‰ª•È°ØËëóÊîπÂñÑ‰ªãÂÖ•ÊïàËÉΩÔºõÈ°ØËëóÊ∏õÂ∞ëÈÅîÂà∞ÁõÆÊ®ôÂàÜÈ°ûÊïàËÉΩÊàñÊ¶ÇÂøµÈ†êÊ∏¨Ê∫ñÁ¢∫Â∫¶ÊâÄÈúÄÁöÑ‰ªãÂÖ•Ê¨°Êï∏„ÄÇÊ≠§Â§ñÔºåÂÆÉÂèØ‰ª•ËºïÈ¨ÜÊï¥ÂêàÂà∞ÁèæÊúâÁöÑÂü∫ÊñºÊ¶ÇÂøµÁöÑÊû∂Êßã‰∏≠ÔºåËÄå‰∏çÈúÄË¶ÅÊõ¥ÊîπÊ®°ÂûãÊú¨Ë∫´„ÄÇÈÄôÁ®ÆÈôç‰ΩéÁöÑ‰∫∫Ê©üÂçî‰ΩúÊàêÊú¨Â∞çÊñºÂú®Ë≥áÊ∫êÂèóÈôêÁöÑÁí∞Â¢É‰∏≠ÊèêÂçá CBM ÁöÑÂèØË°åÊÄßËá≥ÈóúÈáçË¶Å„ÄÇ

##### **FLAME: Factuality-Aware Alignment for Large Language Models**
2405.01525v1 by Sheng-Chieh Lin,Luyu Gao,Barlas Oguz,Wenhan Xiong,Jimmy Lin,Wen-tau Yih,Xilun Chen

Alignment is a standard procedure to fine-tune pre-trained large language
models (LLMs) to follow natural language instructions and serve as helpful AI
assistants. We have observed, however, that the conventional alignment process
fails to enhance the factual accuracy of LLMs, and often leads to the
generation of more false facts (i.e. hallucination). In this paper, we study
how to make the LLM alignment process more factual, by first identifying
factors that lead to hallucination in both alignment steps:\ supervised
fine-tuning (SFT) and reinforcement learning (RL). In particular, we find that
training the LLM on new knowledge or unfamiliar texts can encourage
hallucination. This makes SFT less factual as it trains on human labeled data
that may be novel to the LLM. Furthermore, reward functions used in standard RL
can also encourage hallucination, because it guides the LLM to provide more
helpful responses on a diverse set of instructions, often preferring longer and
more detailed responses. Based on these observations, we propose
factuality-aware alignment, comprised of factuality-aware SFT and
factuality-aware RL through direct preference optimization. Experiments show
that our proposed factuality-aware alignment guides LLMs to output more factual
responses while maintaining instruction-following capability.

ÊëòË¶ÅÔºöÂ∞çÈΩäÊòØ‰∏ÄÁ®ÆÊ®ôÊ∫ñÁ®ãÂ∫èÔºåÁî®ÊñºÂæÆË™øÈ†êÂÖàË®ìÁ∑¥ÁöÑÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM)Ôºå‰ª•ÈÅµÂæ™Ëá™ÁÑ∂Ë™ûË®ÄÊåá‰ª§‰∏¶‰ΩúÁÇ∫ÊúâÁî®ÁöÑ AI Âä©ÁêÜ„ÄÇÁÑ∂ËÄåÔºåÊàëÂÄëËßÄÂØüÂà∞ÔºåÂÇ≥Áµ±ÁöÑÂ∞çÈΩäÈÅéÁ®ãÁÑ°Ê≥ïÂ¢ûÂº∑ LLM ÁöÑ‰∫ãÂØ¶Ê∫ñÁ¢∫ÊÄßÔºå‰∏¶‰∏îÁ∂ìÂ∏∏Â∞éËá¥Áî¢ÁîüÊõ¥Â§öËôõÂÅá‰∫ãÂØ¶ÔºàÂç≥ÂπªË¶∫Ôºâ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÁ†îÁ©∂Â¶Ç‰ΩïËÆì LLM Â∞çÈΩäÈÅéÁ®ãÊõ¥ÂÖ∑‰∫ãÂØ¶ÊÄßÔºåÈ¶ñÂÖàÊâæÂá∫Â∞éËá¥Â∞çÈΩäÊ≠•È©ü‰∏≠Áî¢ÁîüÂπªË¶∫ÁöÑÂõ†Á¥†ÔºöÁõ£Áù£ÂæÆË™ø (SFT) ÂíåÂº∑ÂåñÂ≠∏Áøí (RL)„ÄÇÁâπÂà•ÊòØÔºåÊàëÂÄëÁôºÁèæË®ìÁ∑¥ LLM Â≠∏ÁøíÊñ∞Áü•Ë≠òÊàñ‰∏çÁÜüÊÇâÁöÑÊñáÊú¨ÊúÉÂä©Èï∑ÂπªË¶∫„ÄÇÈÄô‰ΩøÂæó SFT ÁöÑ‰∫ãÂØ¶ÊÄßÈôç‰ΩéÔºåÂõ†ÁÇ∫ÂÆÉË®ìÁ∑¥ÁöÑÊòØÂ∞ç LLM ‰æÜË™™ÂèØËÉΩÊòØÊñ∞Á©éÁöÑ‰∫∫È°ûÊ®ôË®òÊï∏Êìö„ÄÇÊ≠§Â§ñÔºåÊ®ôÊ∫ñ RL ‰∏≠‰ΩøÁî®ÁöÑÁçéÂãµÂáΩÊï∏‰πüÂèØËÉΩÂä©Èï∑ÂπªË¶∫ÔºåÂõ†ÁÇ∫ÂÆÉÂºïÂ∞é LLM Â∞çÂêÑÁ®ÆÊåá‰ª§Êèê‰æõÊõ¥Â§öÊúâÁî®ÁöÑÂõûÊáâÔºåÈÄöÂ∏∏ÂÅèÂ•ΩÊõ¥Èï∑‰∏îÊõ¥Ë©≥Á¥∞ÁöÑÂõûÊáâ„ÄÇÂü∫ÊñºÈÄô‰∫õËßÄÂØüÔºåÊàëÂÄëÊèêÂá∫‰∫ãÂØ¶ÊÑüÁü•Â∞çÈΩäÔºåÂÆÉÂåÖÂê´‰∫ãÂØ¶ÊÑüÁü• SFT ÂíåÈÄöÈÅéÁõ¥Êé•ÂÅèÂ•ΩÂÑ™ÂåñÁöÑ‰∫ãÂØ¶ÊÑüÁü• RL„ÄÇÂØ¶È©óË°®ÊòéÔºåÊàëÂÄëÊèêÂá∫ÁöÑ‰∫ãÂØ¶ÊÑüÁü•Â∞çÈΩäÂºïÂ∞é LLM Ëº∏Âá∫Êõ¥Â§öÁöÑ‰∫ãÂØ¶ÂõûÊáâÔºåÂêåÊôÇ‰øùÊåÅÈÅµÂæ™Êåá‰ª§ÁöÑËÉΩÂäõ„ÄÇ

##### **A separability-based approach to quantifying generalization: which layer is best?**
2405.01524v2 by Luciano Dyballa,Evan Gerritz,Steven W. Zucker

Generalization to unseen data remains poorly understood for deep learning
classification and foundation models. How can one assess the ability of
networks to adapt to new or extended versions of their input space in the
spirit of few-shot learning, out-of-distribution generalization, and domain
adaptation? Which layers of a network are likely to generalize best? We provide
a new method for evaluating the capacity of networks to represent a sampled
domain, regardless of whether the network has been trained on all classes in
the domain. Our approach is the following: after fine-tuning state-of-the-art
pre-trained models for visual classification on a particular domain, we assess
their performance on data from related but distinct variations in that domain.
Generalization power is quantified as a function of the latent embeddings of
unseen data from intermediate layers for both unsupervised and supervised
settings. Working throughout all stages of the network, we find that (i) high
classification accuracy does not imply high generalizability; and (ii) deeper
layers in a model do not always generalize the best, which has implications for
pruning. Since the trends observed across datasets are largely consistent, we
conclude that our approach reveals (a function of) the intrinsic capacity of
the different layers of a model to generalize.

ÊëòË¶ÅÔºöÊ∑±Â∫¶Â≠∏ÁøíÂàÜÈ°ûÂíåÂü∫Á§éÊ®°ÂûãÂ∞çÊú™Ë¶ãÊï∏ÊìöÁöÑÊ¶ÇÂåñ‰ªçÁÑ∂Áü•‰πãÁîöÂ∞ë„ÄÇÂ¶Ç‰ΩïË©ï‰º∞Á∂≤Ë∑ØÂú®Â∞èÊ®£Êú¨Â≠∏Áøí„ÄÅÂàÜÂ∏ÉÂ§ñÊ¶ÇÂåñÂíåÈ†òÂüüÈÅ©ÊáâÁ≤æÁ•û‰∏ãÈÅ©ÊáâÂÖ∂Ëº∏ÂÖ•Á©∫ÈñìÁöÑÊñ∞ÁâàÊú¨ÊàñÊì¥ÂÖÖÁâàÊú¨ÁöÑËÉΩÂäõÔºüÁ∂≤Ë∑ØÁöÑÂì™ÂπæÂ±§ÊúÄÊúâÂèØËÉΩÊ¶ÇÂåñÂæóÊúÄÂ•ΩÔºüÊàëÂÄëÊèê‰æõ‰∫Ü‰∏ÄÁ®ÆÊñ∞ÁöÑÊñπÊ≥ï‰æÜË©ï‰º∞Á∂≤Ë∑ØË°®Á§∫ÂèñÊ®£È†òÂüüÁöÑËÉΩÂäõÔºåÁÑ°Ë´ñÁ∂≤Ë∑ØÊòØÂê¶Â∑≤ÈáùÂ∞çÈ†òÂüü‰∏≠ÁöÑÊâÄÊúâÈ°ûÂà•ÈÄ≤Ë°åË®ìÁ∑¥„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÂ¶Ç‰∏ãÔºöÂú®ÁâπÂÆöÈ†òÂüüÂ∞çË¶ñË¶∫ÂàÜÈ°ûÁöÑÊúÄÊñ∞È†êË®ìÁ∑¥Ê®°ÂûãÈÄ≤Ë°åÂæÆË™øÂæåÔºåÊàëÂÄëË©ï‰º∞ÂÆÉÂÄëÂú®Ë©≤È†òÂüüÁõ∏Èóú‰ΩÜ‰∏çÂêåÁöÑËÆäÁï∞‰∏≠Ë≥áÊñô‰∏äÁöÑÊïàËÉΩ„ÄÇÊ¶ÇÂåñËÉΩÂäõË¢´ÈáèÂåñÁÇ∫‰æÜËá™‰∏≠ÈñìÂ±§Êú™Ë¶ãË≥áÊñôÁöÑÊΩõÂú®ÂµåÂÖ•ÂáΩÊï∏ÔºåÈÅ©Áî®ÊñºÁÑ°Áõ£Áù£ÂíåÁõ£Áù£Ë®≠ÂÆö„ÄÇÂú®Á∂≤Ë∑ØÁöÑÊâÄÊúâÈöéÊÆµÈÄ≤Ë°å‰ΩúÊ•≠ÔºåÊàëÂÄëÁôºÁèæ (i) È´òÂàÜÈ°ûÊ∫ñÁ¢∫Â∫¶‰∏¶‰∏çË°®Á§∫È´òÊ¶ÇÂåñËÉΩÂäõÔºõ‰ª•Âèä (ii) Ê®°Âûã‰∏≠ÁöÑËºÉÊ∑±Â±§‰∏¶ÈùûÁ∏ΩÊòØÊ¶ÇÂåñÂæóÊúÄÂ•ΩÔºåÈÄôÂ∞çÂâ™ÊûùÊúâÂΩ±Èüø„ÄÇÁî±ÊñºÂú®‰∏çÂêåË≥áÊñôÈõÜËßÄÂØüÂà∞ÁöÑË∂®Âã¢Âú®ÂæàÂ§ßÁ®ãÂ∫¶‰∏äÊòØ‰∏ÄËá¥ÁöÑÔºåÂõ†Ê≠§ÊàëÂÄëÂæóÂá∫ÁµêË´ñÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÊè≠Á§∫‰∫ÜÊ®°Âûã‰∏çÂêåÂ±§ÁöÑÂÖßÂú®Ê¶ÇÂåñËÉΩÂäõÔºàÂáΩÊï∏Ôºâ„ÄÇ

##### **D2PO: Discriminator-Guided DPO with Response Evaluation Models**
2405.01511v1 by Prasann Singhal,Nathan Lambert,Scott Niekum,Tanya Goyal,Greg Durrett

Varied approaches for aligning language models have been proposed, including
supervised fine-tuning, RLHF, and direct optimization methods such as DPO.
Although DPO has rapidly gained popularity due to its straightforward training
process and competitive results, there is an open question of whether there
remain practical advantages of using a discriminator, like a reward model, to
evaluate responses. We propose D2PO, discriminator-guided DPO, an approach for
the online setting where preferences are being collected throughout learning.
As we collect gold preferences, we use these not only to train our policy, but
to train a discriminative response evaluation model to silver-label even more
synthetic data for policy training. We explore this approach across a set of
diverse tasks, including a realistic chat setting, we find that our approach
leads to higher-quality outputs compared to DPO with the same data budget, and
greater efficiency in terms of preference data requirements. Furthermore, we
show conditions under which silver labeling is most helpful: it is most
effective when training the policy with DPO, outperforming traditional PPO, and
benefits from maintaining a separate discriminator from the policy model.

ÊëòË¶ÅÔºöÂ∑≤ÊèêÂá∫ÂêÑÁ®ÆÂ∞çÈΩäË™ûË®ÄÊ®°ÂûãÁöÑÊñπÊ≥ïÔºåÂåÖÊã¨Áõ£Áù£ÂæÆË™ø„ÄÅRLHF ÂíåÁõ¥Êé•ÊúÄ‰Ω≥ÂåñÊñπÊ≥ïÔºå‰æãÂ¶Ç DPO„ÄÇ
ÂÑòÁÆ° DPO Âõ†ÂÖ∂Áõ¥Êé•ÁöÑË®ìÁ∑¥ÈÅéÁ®ãÂíåÁ´∂Áà≠ÂäõÁöÑÁµêÊûúËÄåËøÖÈÄüÁç≤ÂæóÊôÆÂèäÔºå‰ΩÜ‰ªçÂ≠òÂú®‰∏ÄÂÄãÈñãÊîæÁöÑÂïèÈ°åÔºåÂç≥ÊòØÂê¶‰ªçÁÑ∂Êúâ‰ΩøÁî®Âà§Âà•Âô®Ôºà‰æãÂ¶ÇÁçéÂãµÊ®°ÂûãÔºâ‰æÜË©ï‰º∞ÂõûÊáâÁöÑÂØ¶ÈöõÂÑ™Âã¢„ÄÇÊàëÂÄëÊèêÂá∫ D2POÔºåÂà§Âà•Âô®ÂºïÂ∞éÁöÑ DPOÔºå‰∏ÄÁ®ÆÂú®Êï¥ÂÄãÂ≠∏ÁøíÈÅéÁ®ã‰∏≠Êî∂ÈõÜÂÅèÂ•ΩÁöÑÁ∑ö‰∏äË®≠ÂÆöÊñπÊ≥ï„ÄÇ
Áï∂ÊàëÂÄëÊî∂ÈõÜÈªÉÈáëÂÅèÂ•ΩÊôÇÔºåÊàëÂÄë‰∏çÂÉÖ‰ΩøÁî®ÂÆÉÂÄë‰æÜË®ìÁ∑¥ÊàëÂÄëÁöÑÊîøÁ≠ñÔºåÈÇÑ‰ΩøÁî®ÂÆÉÂÄë‰æÜË®ìÁ∑¥‰∏ÄÂÄãÂçÄÂà•ÊÄßÁöÑÂõûÊáâË©ï‰º∞Ê®°ÂûãÔºå‰ª•Â∞çÊõ¥Â§öÂêàÊàêÊï∏ÊìöÈÄ≤Ë°åÈäÄÊ®ôÁ±§ËôïÁêÜ‰ª•ÈÄ≤Ë°åÊîøÁ≠ñË®ìÁ∑¥„ÄÇÊàëÂÄëÂú®ÂêÑÁ®Æ‰ªªÂãô‰∏≠Êé¢Á¥¢ÈÄôÁ®ÆÊñπÊ≥ïÔºåÂåÖÊã¨ÁèæÂØ¶ÁöÑËÅäÂ§©Ë®≠ÂÆöÔºåÊàëÂÄëÁôºÁèæËàáÂÖ∑ÊúâÁõ∏ÂêåÊï∏ÊìöÈ†êÁÆóÁöÑ DPO Áõ∏ÊØîÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÊúÉÁî¢ÁîüÊõ¥È´òÂìÅË≥™ÁöÑËº∏Âá∫Ôºå‰∏¶‰∏îÂú®ÂÅèÂ•ΩÊï∏ÊìöÈúÄÊ±ÇÊñπÈù¢Êõ¥ÊúâÊïàÁéá„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜÈäÄÊ®ôÁ±§ÊúÄÊúâÂä©ÁõäÁöÑÊ¢ù‰ª∂ÔºöÂÆÉÂú®‰ΩøÁî® DPO Ë®ìÁ∑¥ÊîøÁ≠ñÊôÇÊúÄÊúâÊïàÔºåÂÑ™ÊñºÂÇ≥Áµ±ÁöÑ PPOÔºå‰∏¶‰∏îÂèóÁõäÊñº‰øùÊåÅÂà§Âà•Âô®ËàáÊîøÁ≠ñÊ®°ÂûãÂàÜÈñã„ÄÇ

##### **Analyzing the Role of Semantic Representations in the Era of Large Language Models**
2405.01502v1 by Zhijing Jin,Yuen Chen,Fernando Gonzalez,Jiarui Liu,Jiayi Zhang,Julian Michael,Bernhard Sch√∂lkopf,Mona Diab

Traditionally, natural language processing (NLP) models often use a rich set
of features created by linguistic expertise, such as semantic representations.
However, in the era of large language models (LLMs), more and more tasks are
turned into generic, end-to-end sequence generation problems. In this paper, we
investigate the question: what is the role of semantic representations in the
era of LLMs? Specifically, we investigate the effect of Abstract Meaning
Representation (AMR) across five diverse NLP tasks. We propose an AMR-driven
chain-of-thought prompting method, which we call AMRCoT, and find that it
generally hurts performance more than it helps. To investigate what AMR may
have to offer on these tasks, we conduct a series of analysis experiments. We
find that it is difficult to predict which input examples AMR may help or hurt
on, but errors tend to arise with multi-word expressions, named entities, and
in the final inference step where the LLM must connect its reasoning over the
AMR to its prediction. We recommend focusing on these areas for future work in
semantic representations for LLMs. Our code:
https://github.com/causalNLP/amr_llm.

ÊëòË¶ÅÔºöÂÇ≥Áµ±‰∏äÔºåËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ (NLP) Ê®°ÂûãÁ∂ìÂ∏∏‰ΩøÁî®Áî±Ë™ûË®ÄÂ∞àÂÆ∂Âª∫Á´ãÁöÑ‰∏ÄÁµÑË±êÂØåÁâπÂæµÔºå‰æãÂ¶ÇË™ûÁæ©Ë°®Á§∫„ÄÇÁÑ∂ËÄåÔºåÂú®Â§ßË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊôÇ‰ª£ÔºåË∂ä‰æÜË∂äÂ§öÁöÑ‰ªªÂãôËΩâËÆäÁÇ∫ÈÄöÁî®„ÄÅÁ´ØÂ∞çÁ´ØÁöÑÂ∫èÂàóÁîüÊàêÂïèÈ°å„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊé¢Ë®é‰ª•‰∏ãÂïèÈ°åÔºöÂú® LLM ÁöÑÊôÇ‰ª£ÔºåË™ûÁæ©Ë°®Á§∫ÊâÆÊºî‰ªÄÈ∫ºËßíËâ≤ÔºüÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÊé¢Ë®éÊäΩË±°ÊÑèÁæ©Ë°®Á§∫ (AMR) Âú®‰∫îÈ†Ö‰∏çÂêåÁöÑ NLP ‰ªªÂãô‰∏≠ÁöÑÊïàÊûú„ÄÇÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÁî± AMR È©ÖÂãïÁöÑÊÄùËÄÉÈèàÊèêÁ§∫ÊñπÊ≥ïÔºåÊàëÂÄëÁ®±‰πãÁÇ∫ AMRCoTÔºå‰∏¶ÁôºÁèæÂÆÉÈÄöÂ∏∏ÊØîÊúâÂπ´Âä©ÁöÑÊÉÖÊ≥Å‰∏ãÊõ¥ÊêçÂÆ≥ÊïàËÉΩ„ÄÇÁÇ∫‰∫ÜÊé¢Ë®é AMR Âú®ÈÄô‰∫õ‰ªªÂãô‰∏≠ÂèØËÉΩÊèê‰æõÁöÑÂÖßÂÆπÔºåÊàëÂÄëÈÄ≤Ë°å‰∫Ü‰∏ÄÁ≥ªÂàóÁöÑÂàÜÊûêÂØ¶È©ó„ÄÇÊàëÂÄëÁôºÁèæÂæàÈõ£È†êÊ∏¨ AMR ÂèØËÉΩÂú®Âì™‰∫õËº∏ÂÖ•ÁØÑ‰æã‰∏≠Êèê‰æõÂπ´Âä©ÊàñÈÄ†ÊàêÊêçÂÆ≥Ôºå‰ΩÜÈåØË™§ÂæÄÂæÄÂá∫ÁèæÂú®Â§öÂ≠óË©ûË°®ÈÅî„ÄÅÂëΩÂêçÂØ¶È´îÔºå‰ª•Âèä LLM ÂøÖÈ†àÂ∞áÂÖ∂Âú® AMR ‰∏äÁöÑÊé®ÁêÜËàáÂÖ∂È†êÊ∏¨ËÅØÁπ´Ëµ∑‰æÜÁöÑÊúÄÂæåÊé®Ë´ñÊ≠•È©ü„ÄÇÊàëÂÄëÂª∫Ë≠∞Âú® LLM ÁöÑË™ûÁæ©Ë°®Á§∫ÁöÑÊú™‰æÜÂ∑•‰Ωú‰∏≠Â∞àÊ≥®ÊñºÈÄô‰∫õÈ†òÂüü„ÄÇÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÔºöhttps://github.com/causalNLP/amr_llm„ÄÇ

##### **Controllable Text Generation in the Instruction-Tuning Era**
2405.01490v1 by Dhananjay Ashok,Barnabas Poczos

While most research on controllable text generation has focused on steering
base Language Models, the emerging instruction-tuning and prompting paradigm
offers an alternate approach to controllability. We compile and release
ConGenBench, a testbed of 17 different controllable generation tasks, using a
subset of it to benchmark the performance of 9 different baselines and methods
on Instruction-tuned Language Models. To our surprise, we find that
prompting-based approaches outperform controllable text generation methods on
most datasets and tasks, highlighting a need for research on controllable text
generation with Instruction-tuned Language Models in specific. Prompt-based
approaches match human performance on most stylistic tasks while lagging on
structural tasks, foregrounding a need to study more varied constraints and
more challenging stylistic tasks. To facilitate such research, we provide an
algorithm that uses only a task dataset and a Large Language Model with
in-context capabilities to automatically generate a constraint dataset. This
method eliminates the fields dependence on pre-curated constraint datasets,
hence vastly expanding the range of constraints that can be studied in the
future.

ÊëòË¶ÅÔºöÂÑòÁÆ°Â§ßÂ§öÊï∏ÈóúÊñºÂèØÊéßÊñáÊú¨ÁîüÊàêÁöÑÁõ∏ÈóúÁ†îÁ©∂ÈÉΩÂ∞àÊ≥®ÊñºÂºïÂ∞éÂü∫Á§éË™ûË®ÄÊ®°ÂûãÔºå‰ΩÜÊñ∞ËààÁöÑÊåá‰ª§ÂæÆË™øÂíåÊèêÁ§∫ÁØÑ‰æãÊèê‰æõ‰∫Ü‰∏ÄÂÄãÂèØÊéßÊÄßÁöÑÊõø‰ª£ÊñπÊ≥ï„ÄÇÊàëÂÄëÁ∑®Âà∂‰∏¶ÁôºÂ∏É ConGenBenchÔºå‰∏ÄÂÄãÁî± 17 ÂÄã‰∏çÂêåÁöÑÂèØÊéßÁîüÊàê‰ªªÂãôÁµÑÊàêÁöÑÊ∏¨Ë©¶Âπ≥Âè∞Ôºå‰ΩøÁî®ÂÖ∂Â≠êÈõÜ‰æÜË©ïÈáè 9 ÂÄã‰∏çÂêåÂü∫Á∑öÂíåÊñπÊ≥ïÂú®Êåá‰ª§ÂæÆË™øË™ûË®ÄÊ®°Âûã‰∏äÁöÑÊïàËÉΩ„ÄÇ‰ª§‰∫∫È©öË®ùÁöÑÊòØÔºåÊàëÂÄëÁôºÁèæÂü∫ÊñºÊèêÁ§∫ÁöÑÊñπÊ≥ïÂú®Â§öÊï∏Ë≥áÊñôÈõÜÂíå‰ªªÂãô‰∏≠ÂÑ™ÊñºÂèØÊéßÊñáÊú¨ÁîüÊàêÊñπÊ≥ïÔºåÁ™ÅÈ°Ø‰∫ÜÈáùÂ∞çÁâπÂÆöÊåá‰ª§ÂæÆË™øË™ûË®ÄÊ®°ÂûãÈÄ≤Ë°åÂèØÊéßÊñáÊú¨ÁîüÊàêÁ†îÁ©∂ÁöÑÂøÖË¶ÅÊÄß„ÄÇÂü∫ÊñºÊèêÁ§∫ÁöÑÊñπÊ≥ïÂú®Â§öÊï∏ÊñáÈ´î‰ªªÂãô‰∏≠Ëàá‰∫∫È°ûË°®ÁèæÁõ∏Á¨¶Ôºå‰ΩÜÂú®ÁµêÊßã‰ªªÂãô‰∏≠Ë°®ÁèæËêΩÂæåÔºåÁ™ÅÈ°Ø‰∫ÜÁ†îÁ©∂Êõ¥Â§öÂÖÉÁ¥ÑÊùüÂíåÊõ¥ÂÖ∑ÊåëÊà∞ÊÄßÁöÑÊñáÈ´î‰ªªÂãôÁöÑÂøÖË¶ÅÊÄß„ÄÇÁÇ∫‰∫Ü‰øÉÈÄ≤Ê≠§È°ûÁ†îÁ©∂ÔºåÊàëÂÄëÊèê‰æõ‰∫Ü‰∏ÄÂÄãÊºîÁÆóÊ≥ïÔºåÂÆÉÂÉÖ‰ΩøÁî®‰ªªÂãôË≥áÊñôÈõÜÂíåÂÖ∑ÂÇôÊÉÖÂ¢ÉÂÖßÂäüËÉΩÁöÑÂ§ßË™ûË®ÄÊ®°Âûã‰æÜËá™ÂãïÁîüÊàêÁ¥ÑÊùüË≥áÊñôÈõÜ„ÄÇÊ≠§ÊñπÊ≥ïÊ∂àÈô§‰∫ÜÈ†òÂüüÂ∞çÈ†êÂÖàÁ≠ñÂäÉÁöÑÁ¥ÑÊùüË≥áÊñôÈõÜÁöÑ‰æùË≥¥ÊÄßÔºåÂõ†Ê≠§Â§ßÂπÖÊì¥Â±ï‰∫ÜÊú™‰æÜÂèØ‰ª•Á†îÁ©∂ÁöÑÁ¥ÑÊùüÁØÑÂúç„ÄÇ

##### **MANTIS: Interleaved Multi-Image Instruction Tuning**
2405.01483v1 by Dongfu Jiang,Xuan He,Huaye Zeng,Cong Wei,Max Ku,Qian Liu,Wenhu Chen

The recent years have witnessed a great array of large multimodal models
(LMMs) to effectively solve single-image vision language tasks. However, their
abilities to solve multi-image visual language tasks is yet to be improved. The
existing multi-image LMMs (e.g. OpenFlamingo, Emu, Idefics, etc) mostly gain
their multi-image ability through pre-training on hundreds of millions of noisy
interleaved image-text data from web, which is neither efficient nor effective.
In this paper, we aim at building strong multi-image LMMs via instruction
tuning with academic-level resources. Therefore, we meticulously construct
Mantis-Instruct containing 721K instances from 14 multi-image datasets. We
design Mantis-Instruct to cover different multi-image skills like co-reference,
reasoning, comparing, temporal understanding. We combine Mantis-Instruct with
several single-image visual-language datasets to train our model Mantis to
handle any interleaved image-text inputs. We evaluate the trained Mantis on
five multi-image benchmarks and eight single-image benchmarks. Though only
requiring academic-level resources (i.e. 36 hours on 16xA100-40G), Mantis-8B
can achieve state-of-the-art performance on all the multi-image benchmarks and
beats the existing best multi-image LMM Idefics2-8B by an average of 9 absolute
points. We observe that Mantis performs equivalently well on the held-in and
held-out evaluation benchmarks. We further evaluate Mantis on single-image
benchmarks and demonstrate that Mantis can maintain a strong single-image
performance on par with CogVLM and Emu2. Our results are particularly
encouraging as it shows that low-cost instruction tuning is indeed much more
effective than intensive pre-training in terms of building multi-image LMMs.

ÊëòË¶ÅÔºöËøëÂπ¥‰æÜË¶ãË≠â‰∫ÜÂ§ßÈáèÂ§ßÂûãÂ§öÊ®°ÊÖãÊ®°Âûã (LMM) ÊúâÊïàËß£Ê±∫ÂñÆ‰∏ÄÂΩ±ÂÉèË¶ñË¶∫Ë™ûË®Ä‰ªªÂãô„ÄÇÁÑ∂ËÄåÔºåÂÆÉÂÄëËß£Ê±∫Â§öÂΩ±ÂÉèË¶ñË¶∫Ë™ûË®Ä‰ªªÂãôÁöÑËÉΩÂäõ‰ªçÊúâÂæÖÊîπÈÄ≤„ÄÇÁèæÊúâÁöÑÂ§öÂΩ±ÂÉè LMMÔºà‰æãÂ¶Ç OpenFlamingo„ÄÅEmu„ÄÅIdefics Á≠âÔºâÂ§ßÂ§öÈÄèÈÅéÈ†êÂÖàË®ìÁ∑¥Êï∏ÂÑÑÂÄã‰æÜËá™Á∂≤Ë∑ØÁöÑÈõúË®ä‰∫§ÈåØÂΩ±ÂÉèÊñáÂ≠óË≥áÊñô‰æÜÁç≤ÂæóÂ§öÂΩ±ÂÉèËÉΩÂäõÔºåÊó¢‰∏çÊúâÊïàÁéá‰πü‰∏çÊúâÊïà„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊó®Âú®ÈÄèÈÅé‰ΩøÁî®Â≠∏Ë°ìÁ¥öË≥áÊ∫êÈÄ≤Ë°åÊåá‰ª§Ë™øÊï¥‰æÜÂª∫ÊßãÂº∑Â§ßÁöÑÂ§öÂΩ±ÂÉè LMM„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëÁ≤æÂøÉÂª∫Êßã‰∫ÜÂåÖÂê´‰æÜËá™ 14 ÂÄãÂ§öÂΩ±ÂÉèË≥áÊñôÈõÜÁöÑ 721K ÂÄãÂØ¶‰æãÁöÑ Mantis-Instruct„ÄÇÊàëÂÄëË®≠Ë®à Mantis-Instruct ‰ª•Ê∂µËìã‰∏çÂêåÁöÑÂ§öÂΩ±ÂÉèÊäÄËÉΩÔºå‰æãÂ¶ÇÂÖ±ÂêåÂèÉËÄÉ„ÄÅÊé®ÁêÜ„ÄÅÊØîËºÉ„ÄÅÊôÇÈñìÁêÜËß£„ÄÇÊàëÂÄëÂ∞á Mantis-Instruct ËàáÂπæÂÄãÂñÆ‰∏ÄÂΩ±ÂÉèË¶ñË¶∫Ë™ûË®ÄË≥áÊñôÈõÜÁµêÂêàÔºå‰ª•Ë®ìÁ∑¥ÊàëÂÄëÁöÑÊ®°Âûã Mantis ËôïÁêÜ‰ªª‰Ωï‰∫§ÈåØÁöÑÂΩ±ÂÉèÊñáÂ≠óËº∏ÂÖ•„ÄÇÊàëÂÄëÂú®‰∫îÂÄãÂ§öÂΩ±ÂÉèÂü∫Ê∫ñÂíåÂÖ´ÂÄãÂñÆ‰∏ÄÂΩ±ÂÉèÂü∫Ê∫ñ‰∏äË©ï‰º∞Ë®ìÁ∑¥ÂæåÁöÑ Mantis„ÄÇÂÑòÁÆ°ÂÉÖÈúÄË¶ÅÂ≠∏Ë°ìÁ¥öË≥áÊ∫êÔºàÂç≥Âú® 16xA100-40G ‰∏ä‰ΩøÁî® 36 Â∞èÊôÇÔºâÔºåMantis-8B ‰ªçÂèØ‰ª•Âú®ÊâÄÊúâÂ§öÂΩ±ÂÉèÂü∫Ê∫ñ‰∏äÈÅîÂà∞ÊúÄÂÖàÈÄ≤ÁöÑÊïàËÉΩÔºå‰∏¶‰ª•Âπ≥Âùá 9 ÂÄãÁµïÂ∞çÈªûÊï∏ÊìäÊïóÁèæÊúâÁöÑÊúÄ‰Ω≥Â§öÂΩ±ÂÉè LMM Idefics2-8B„ÄÇÊàëÂÄëËßÄÂØüÂà∞ Mantis Âú®ÂÖßÈÉ®ÂíåÂ§ñÈÉ®Ë©ï‰º∞Âü∫Ê∫ñ‰∏äÁöÑË°®ÁèæÂêåÊ®£Âá∫Ëâ≤„ÄÇÊàëÂÄëÈÄ≤‰∏ÄÊ≠•Âú®ÂñÆ‰∏ÄÂΩ±ÂÉèÂü∫Ê∫ñ‰∏äË©ï‰º∞ MantisÔºå‰∏¶Ë≠âÊòé Mantis ÂèØ‰ª•Á∂≠ÊåÅËàá CogVLM Âíå Emu2 Áõ∏Áï∂ÁöÑÂº∑Â§ßÂñÆ‰∏ÄÂΩ±ÂÉèÊïàËÉΩ„ÄÇÊàëÂÄëÁöÑÁµêÊûúÁâπÂà•‰ª§‰∫∫ÈºìËàûÔºåÂõ†ÁÇ∫ÂÆÉË°®Êòé‰ΩéÊàêÊú¨Êåá‰ª§Ë™øÊï¥Âú®Âª∫ÊßãÂ§öÂΩ±ÂÉè LMM ÊñπÈù¢Á¢∫ÂØ¶ÊØîÂØÜÈõÜÈ†êÂÖàË®ìÁ∑¥ÊúâÊïàÂæóÂ§ö„ÄÇ

##### **NeMo-Aligner: Scalable Toolkit for Efficient Model Alignment**
2405.01481v1 by Gerald Shen,Zhilin Wang,Olivier Delalleau,Jiaqi Zeng,Yi Dong,Daniel Egert,Shengyang Sun,Jimmy Zhang,Sahil Jain,Ali Taghibakhshi,Markel Sanz Ausin,Ashwath Aithal,Oleksii Kuchaiev

Aligning Large Language Models (LLMs) with human values and preferences is
essential for making them helpful and safe. However, building efficient tools
to perform alignment can be challenging, especially for the largest and most
competent LLMs which often contain tens or hundreds of billions of parameters.
We create NeMo-Aligner, a toolkit for model alignment that can efficiently
scale to using hundreds of GPUs for training. NeMo-Aligner comes with highly
optimized and scalable implementations for major paradigms of model alignment
such as: Reinforcement Learning from Human Feedback (RLHF), Direct Preference
Optimization (DPO), SteerLM, and Self-Play Fine-Tuning (SPIN). Additionally,
our toolkit supports running most of the alignment techniques in a Parameter
Efficient Fine-Tuning (PEFT) setting. NeMo-Aligner is designed for
extensibility, allowing support for other alignment techniques with minimal
effort. It is open-sourced with Apache 2.0 License and we invite community
contributions at https://github.com/NVIDIA/NeMo-Aligner

ÊëòË¶ÅÔºöËàá‰∫∫È°ûÂÉπÂÄºËßÄÂíåÂÅèÂ•Ω‰∏ÄËá¥ÁöÑÂ§ßË™ûË®ÄÊ®°Âûã (LLM) Â∞çÊñºËÆìÂÆÉÂÄëËÆäÂæóÊúâÂπ´Âä©‰∏îÂÆâÂÖ®Ëá≥ÈóúÈáçË¶Å„ÄÇÁÑ∂ËÄåÔºåÂª∫Á´ãÁî®ÊñºÂü∑Ë°å‰∏ÄËá¥ÊÄßÁöÑÊúâÊïàÂ∑•ÂÖ∑ÂèØËÉΩÂÖ∑ÊúâÊåëÊà∞ÊÄßÔºåÁâπÂà•ÊòØÂ∞çÊñºÈÄöÂ∏∏ÂåÖÂê´Êï∏ÂçÅÂÑÑÊàñÊï∏ÁôæÂÑÑÂÄãÂèÉÊï∏ÁöÑË¶èÊ®°ÊúÄÂ§ß‰∏îÊúÄÂÖ∑ËÉΩÂäõÁöÑ LLM„ÄÇÊàëÂÄëÂª∫Á´ã‰∫Ü NeMo-AlignerÔºåÈÄôÊòØ‰∏ÄÂÄãÊ®°Âûã‰∏ÄËá¥ÊÄßÂ∑•ÂÖ∑ÂåÖÔºåÂèØ‰ª•ÊúâÊïàÊì¥Â±ïÂà∞‰ΩøÁî®Êï∏ÁôæÂÄã GPU ÈÄ≤Ë°åË®ìÁ∑¥„ÄÇNeMo-Aligner Èö®ÈôÑ‰∫ÜÈáùÂ∞ç‰∏ªË¶ÅÊ®°Âûã‰∏ÄËá¥ÊÄßÁØÑ‰æãÁöÑÈ´òÂ∫¶ÂÑ™Âåñ‰∏îÂèØÊì¥Â±ïÁöÑÂØ¶‰ΩúÔºå‰æãÂ¶ÇÔºö‰∫∫È°ûÂõûÈ•ãÂº∑ÂåñÂ≠∏Áøí (RLHF)„ÄÅÁõ¥Êé•ÂÅèÂ•ΩÊúÄ‰Ω≥Âåñ (DPO)„ÄÅSteerLM ÂíåËá™Áé©ÂæÆË™ø (SPIN)„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁöÑÂ∑•ÂÖ∑ÂåÖÊîØÊè¥Âú®ÂèÉÊï∏ÊúâÊïàÂæÆË™ø (PEFT) Ë®≠ÂÆö‰∏≠Âü∑Ë°åÂ§ßÈÉ®ÂàÜ‰∏ÄËá¥ÊÄßÊäÄË°ì„ÄÇNeMo-Aligner Ë¢´Ë®≠Ë®àÊàêÂèØÊì¥ÂÖÖÁöÑÔºåÂÖÅË®±‰ª•ÊúÄÂ∞èÁöÑÂ∑•‰ΩúÈáèÊîØÊè¥ÂÖ∂‰ªñ‰∏ÄËá¥ÊÄßÊäÄË°ì„ÄÇÂÆÉÊé°Áî® Apache 2.0 ÊéàÊ¨äÈñãÊîæÂéüÂßãÁ¢ºÔºåÊàëÂÄëÈÇÄË´ãÁ§æÁæ§Âú® https://github.com/NVIDIA/NeMo-Aligner ‰∏≠ÂÅöÂá∫Ë≤¢Áçª

##### **V-FLUTE: Visual Figurative Language Understanding with Textual Explanations**
2405.01474v1 by Arkadiy Saakyan,Shreyas Kulkarni,Tuhin Chakrabarty,Smaranda Muresan

Large Vision-Language models (VLMs) have demonstrated strong reasoning
capabilities in tasks requiring a fine-grained understanding of literal images
and text, such as visual question-answering or visual entailment. However,
there has been little exploration of these models' capabilities when presented
with images and captions containing figurative phenomena such as metaphors or
humor, the meaning of which is often implicit. To close this gap, we propose a
new task and a high-quality dataset: Visual Figurative Language Understanding
with Textual Explanations (V-FLUTE). We frame the visual figurative language
understanding problem as an explainable visual entailment task, where the model
has to predict whether the image (premise) entails a claim (hypothesis) and
justify the predicted label with a textual explanation. Using a human-AI
collaboration framework, we build a high-quality dataset, V-FLUTE, that
contains 6,027 <image, claim, label, explanation> instances spanning five
diverse multimodal figurative phenomena: metaphors, similes, idioms, sarcasm,
and humor. The figurative phenomena can be present either in the image, the
caption, or both. We further conduct both automatic and human evaluations to
assess current VLMs' capabilities in understanding figurative phenomena.

ÊëòË¶ÅÔºöÂ§ßÂûãËßÜËßâËØ≠Ë®ÄÊ®°Âûã (VLM) Â∑≤Âú®ÈúÄË¶ÅÂØπÊñáÂ≠óÂõæÂÉèÂíåÊñáÊú¨ËøõË°åÁªÜËá¥ÁêÜËß£ÁöÑ‰ªªÂä°‰∏≠Â±ïÁ§∫‰∫ÜÂº∫Â§ßÁöÑÊé®ÁêÜËÉΩÂäõÔºå‰æãÂ¶ÇËßÜËßâÈóÆÁ≠îÊàñËßÜËßâËï¥Ê∂µ„ÄÇÁÑ∂ËÄåÔºåÂΩìÊ®°ÂûãÈù¢ÂØπÂåÖÂê´ÈöêÂñªÊàñÂπΩÈªòÁ≠âÊØîÂñªÁé∞Ë±°ÁöÑÂõæÂÉèÂíåÊ†áÈ¢òÊó∂ÔºåÂØπËøô‰∫õÊ®°ÂûãÁöÑËÉΩÂäõÂá†‰πéÊ≤°ÊúâÊé¢Á¥¢ÔºåËÄåËøô‰∫õÁé∞Ë±°ÁöÑÂê´‰πâÈÄöÂ∏∏ÊòØÈöêÂê´ÁöÑ„ÄÇ‰∏∫‰∫ÜÂº•Ë°•Ëøô‰∏ÄÂ∑ÆË∑ùÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏Ä‰∏™Êñ∞‰ªªÂä°Âíå‰∏Ä‰∏™È´òË¥®ÈáèÊï∞ÊçÆÈõÜÔºöÂÖ∑ÊúâÊñáÊú¨Ëß£ÈáäÁöÑËßÜËßâÊØîÂñªËØ≠Ë®ÄÁêÜËß£ (V-FLUTE)„ÄÇÊàë‰ª¨Â∞ÜËßÜËßâÊØîÂñªËØ≠Ë®ÄÁêÜËß£ÈóÆÈ¢òÊûÑÂª∫‰∏∫‰∏Ä‰∏™ÂèØËß£ÈáäÁöÑËßÜËßâËï¥Ê∂µ‰ªªÂä°ÔºåÂÖ∂‰∏≠Ê®°ÂûãÂøÖÈ°ªÈ¢ÑÊµãÂõæÂÉèÔºàÂâçÊèêÔºâÊòØÂê¶Ëï¥Ê∂µ‰∏Ä‰∏™‰∏ªÂº†ÔºàÂÅáËÆæÔºâÔºåÂπ∂Áî®ÊñáÊú¨Ëß£ÈáäÊù•ËØÅÊòéÈ¢ÑÊµãÁöÑÊ†áÁ≠æ„ÄÇ‰ΩøÁî®‰∫∫Êú∫Âçè‰ΩúÊ°ÜÊû∂ÔºåÊàë‰ª¨ÊûÑÂª∫‰∫Ü‰∏Ä‰∏™È´òË¥®ÈáèÊï∞ÊçÆÈõÜ V-FLUTEÔºåÂÖ∂‰∏≠ÂåÖÂê´ 6,027 ‰∏™<ÂõæÂÉè„ÄÅ‰∏ªÂº†„ÄÅÊ†áÁ≠æ„ÄÅËß£Èáä>ÂÆû‰æãÔºåÊ∂µÁõñ‰∫îÁßç‰∏çÂêåÁöÑÂ§öÊ®°ÊÄÅÊØîÂñªÁé∞Ë±°ÔºöÈöêÂñª„ÄÅÊòéÂñª„ÄÅ‰π†ËØ≠„ÄÅËÆΩÂà∫ÂíåÂπΩÈªò„ÄÇÊØîÂñªÁé∞Ë±°ÂèØ‰ª•Âá∫Áé∞Âú®ÂõæÂÉè„ÄÅÊ†áÈ¢òÊàñ‰∏§ËÄÖ‰∏≠„ÄÇÊàë‰ª¨Ëøõ‰∏ÄÊ≠•ËøõË°åËá™Âä®Âíå‰∫∫Â∑•ËØÑ‰º∞Ôºå‰ª•ËØÑ‰º∞ÂΩìÂâç VLM Âú®ÁêÜËß£ÊØîÂñªÁé∞Ë±°ÊñπÈù¢ÁöÑËÉΩÂäõ„ÄÇ

##### **WildChat: 1M ChatGPT Interaction Logs in the Wild**
2405.01470v1 by Wenting Zhao,Xiang Ren,Jack Hessel,Claire Cardie,Yejin Choi,Yuntian Deng

Chatbots such as GPT-4 and ChatGPT are now serving millions of users. Despite
their widespread use, there remains a lack of public datasets showcasing how
these tools are used by a population of users in practice. To bridge this gap,
we offered free access to ChatGPT for online users in exchange for their
affirmative, consensual opt-in to anonymously collect their chat transcripts
and request headers. From this, we compiled WildChat, a corpus of 1 million
user-ChatGPT conversations, which consists of over 2.5 million interaction
turns. We compare WildChat with other popular user-chatbot interaction
datasets, and find that our dataset offers the most diverse user prompts,
contains the largest number of languages, and presents the richest variety of
potentially toxic use-cases for researchers to study. In addition to
timestamped chat transcripts, we enrich the dataset with demographic data,
including state, country, and hashed IP addresses, alongside request headers.
This augmentation allows for more detailed analysis of user behaviors across
different geographical regions and temporal dimensions. Finally, because it
captures a broad range of use cases, we demonstrate the dataset's potential
utility in fine-tuning instruction-following models. WildChat is released at
https://wildchat.allen.ai under AI2 ImpACT Licenses.

ÊëòË¶ÅÔºöËÅäÂ§©Ê©üÂô®‰∫∫Ôºå‰æãÂ¶Ç GPT-4 Âíå ChatGPTÔºåÁõÆÂâçÊúçÂãôÊñºÊï∏ÁôæËê¨Áî®Êà∂„ÄÇÂÑòÁÆ°ÂÆÉÂÄëË¢´Âª£Ê≥õ‰ΩøÁî®Ôºå‰ΩÜ‰ªçÁÑ∂Áº∫‰πèÂÖ¨ÈñãÁöÑË≥áÊñôÈõÜÔºåÂ±ïÁ§∫ÈÄô‰∫õÂ∑•ÂÖ∑Â¶Ç‰ΩïÂØ¶Èöõ‰∏äË¢´‰∏ÄÁæ§Áî®Êà∂‰ΩøÁî®„ÄÇÁÇ∫‰∫ÜÂΩåË£úÈÄôÂÄãÂ∑ÆË∑ùÔºåÊàëÂÄëÁÇ∫Á∑ö‰∏ä‰ΩøÁî®ËÄÖÂÖçË≤ªÊèê‰æõ ChatGPTÔºå‰ª•ÊèõÂèñ‰ªñÂÄëÁ©çÊ•µ„ÄÅËá™È°òÈÅ∏ÊìáÂåøÂêçÊî∂ÈõÜ‰ªñÂÄëÁöÑËÅäÂ§©Ë®òÈåÑÂíåË´ãÊ±ÇÊ®ôÈ†≠„ÄÇÁî±Ê≠§ÔºåÊàëÂÄëÁ∑®Âà∂‰∫Ü WildChatÔºå‰∏ÄÂÄãÂåÖÂê´ 100 Ëê¨‰ΩøÁî®ËÄÖ-ChatGPT Â∞çË©±ÁöÑË™ûÊñôÂ∫´ÔºåÂÖ∂‰∏≠ÂåÖÂê´Ë∂ÖÈÅé 250 Ëê¨ÂÄã‰∫íÂãïÂõûÂêà„ÄÇÊàëÂÄëÂ∞á WildChat ËàáÂÖ∂‰ªñÊµÅË°åÁöÑ‰ΩøÁî®ËÄÖ-ËÅäÂ§©Ê©üÂô®‰∫∫‰∫íÂãïË≥áÊñôÈõÜÈÄ≤Ë°åÊØîËºÉÔºåÁôºÁèæÊàëÂÄëÁöÑË≥áÊñôÈõÜÊèê‰æõ‰∫ÜÊúÄÂ§öÊ®£ÂåñÁöÑ‰ΩøÁî®ËÄÖÊèêÁ§∫ÔºåÂåÖÂê´ÊúÄÂ§öÁöÑË™ûË®ÄÔºå‰∏¶ÁÇ∫Á†îÁ©∂‰∫∫Âì°Êèê‰æõ‰∫ÜÊúÄË±êÂØåÁöÑÊΩõÂú®ÊúâÊØí‰ΩøÁî®Ê°à‰æã„ÄÇÈô§‰∫ÜÂ∏∂ÊúâÊôÇÈñìÊà≥Ë®òÁöÑËÅäÂ§©Ë®òÈåÑÂ§ñÔºåÊàëÂÄëÈÇÑ‰ΩøÁî®‰∫∫Âè£Áµ±Ë®àË≥áÊñôË±êÂØå‰∫ÜË≥áÊñôÈõÜÔºåÂåÖÊã¨Â∑û„ÄÅÂúãÂÆ∂ÂíåÈõúÊπä IP Âú∞ÂùÄÔºå‰ª•ÂèäË´ãÊ±ÇÊ®ôÈ†≠„ÄÇÈÄôÁ®ÆÊì¥ÂÖÖÂÖÅË®±Â∞ç‰∏çÂêåÂú∞ÁêÜÂçÄÂüüÂíåÊôÇÈñìÁ∂≠Â∫¶‰∏≠ÁöÑ‰ΩøÁî®ËÄÖË°åÁÇ∫ÈÄ≤Ë°åÊõ¥Ë©≥Á¥∞ÁöÑÂàÜÊûê„ÄÇÊúÄÂæåÔºåÁî±ÊñºÂÆÉÊ∂µËìã‰∫ÜÂª£Ê≥õÁöÑÁî®‰æãÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜË©≤Ë≥áÊñôÈõÜÂú®ÂæÆË™øÈÅµÂæ™Êåá‰ª§ÁöÑÊ®°Âûã‰∏≠ÁöÑÊΩõÂú®ÊïàÁî®„ÄÇWildChat Âú® https://wildchat.allen.ai ‰∏ãÊ†πÊìö AI2 ImpACT Ë®±ÂèØË≠âÁôºÂ∏É„ÄÇ

##### **Advancing human-centric AI for robust X-ray analysis through holistic self-supervised learning**
2405.01469v1 by Th√©o Moutakanni,Piotr Bojanowski,Guillaume Chassagnon,C√©line Hudelot,Armand Joulin,Yann LeCun,Matthew Muckley,Maxime Oquab,Marie-Pierre Revel,Maria Vakalopoulou

AI Foundation models are gaining traction in various applications, including
medical fields like radiology. However, medical foundation models are often
tested on limited tasks, leaving their generalisability and biases unexplored.
We present RayDINO, a large visual encoder trained by self-supervision on 873k
chest X-rays. We compare RayDINO to previous state-of-the-art models across
nine radiology tasks, from classification and dense segmentation to text
generation, and provide an in depth analysis of population, age and sex biases
of our model. Our findings suggest that self-supervision allows patient-centric
AI proving useful in clinical workflows and interpreting X-rays holistically.
With RayDINO and small task-specific adapters, we reach state-of-the-art
results and improve generalization to unseen populations while mitigating bias,
illustrating the true promise of foundation models: versatility and robustness.

ÊëòË¶ÅÔºöAI Âü∫Á§éÊ®°ÂûãÂú®ÂêÑÁ®ÆÊáâÁî®‰∏≠Áç≤ÂæóÈóúÊ≥®ÔºåÂåÖÊã¨ÊîæÂ∞ÑÂ≠∏Á≠âÈÜ´ÁôÇÈ†òÂüü„ÄÇÁÑ∂ËÄåÔºåÈÜ´ÁôÇÂü∫Á§éÊ®°ÂûãÈÄöÂ∏∏Âú®ÊúâÈôêÁöÑ‰ªªÂãô‰∏äÈÄ≤Ë°åÊ∏¨Ë©¶ÔºåÈÄôËÆìÂÆÉÂÄëÁöÑÊ≥õÂåñÊÄßÂíåÂÅèÂ∑ÆÊú™Ë¢´Êé¢Á¥¢„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫Ü RayDINOÔºåÈÄôÊòØ‰∏ÄÂÄãÂ§ßÂûãË¶ñË¶∫Á∑®Á¢ºÂô®ÔºåÈÄöÈÅé 873k ËÉ∏ÈÉ® X ÂÖâÁâáÁöÑËá™ÊàëÁõ£Áù£ÈÄ≤Ë°åË®ìÁ∑¥„ÄÇÊàëÂÄëÂ∞á RayDINO Ëàá‰πãÂâçÊúÄÂÖàÈÄ≤ÁöÑÊ®°ÂûãÈÄ≤Ë°åÊØîËºÉÔºåÊ∂µËìã‰∫ÜÂæûÂàÜÈ°ûÂíåÂØÜÈõÜÂàÜÂâ≤Âà∞ÊñáÊú¨ÁîüÊàêÁöÑ‰πùÈ†ÖÊîæÂ∞ÑÂ≠∏‰ªªÂãôÔºå‰∏¶Â∞çÊàëÂÄëÊ®°ÂûãÁöÑ‰∫∫Âè£„ÄÅÂπ¥ÈΩ°ÂíåÊÄßÂà•ÂÅèÂ∑ÆÈÄ≤Ë°å‰∫ÜÊ∑±ÂÖ•ÂàÜÊûê„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúË°®ÊòéÔºåËá™ÊàëÁõ£Áù£ÂÖÅË®±‰ª•ÊÇ£ËÄÖÁÇ∫‰∏≠ÂøÉÁöÑ AI Âú®Ëá®Â∫äÂ∑•‰ΩúÊµÅÁ®ã‰∏≠Ë≠âÊòéÂÖ∂ÊúâÁî®ÊÄßÔºå‰∏¶ÂÖ®Èù¢Ëß£Èáã X ÂÖâÁâá„ÄÇÈÄöÈÅé RayDINO ÂíåÁâπÂÆöÊñº‰ªªÂãôÁöÑÂ∞èÂûãÈÅ©ÈÖçÂô®ÔºåÊàëÂÄëÈÅîÂà∞‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÁµêÊûúÔºå‰∏¶ÊîπÈÄ≤‰∫ÜÂ∞çÊú™Ë¶ã‰∫∫Áæ§ÁöÑÊ≥õÂåñÔºåÂêåÊôÇÊ∏õËºï‰∫ÜÂÅèÂ∑ÆÔºåË™™Êòé‰∫ÜÂü∫Á§éÊ®°ÂûãÁöÑÁúüÊ≠£ÂâçÊôØÔºöÈÄöÁî®ÊÄßÂíåÈ≠ØÊ£íÊÄß„ÄÇ

##### **Understanding Retrieval-Augmented Task Adaptation for Vision-Language Models**
2405.01468v1 by Yifei Ming,Yixuan Li

Pre-trained contrastive vision-language models have demonstrated remarkable
performance across a wide range of tasks. However, they often struggle on
fine-trained datasets with categories not adequately represented during
pre-training, which makes adaptation necessary. Recent works have shown
promising results by utilizing samples from web-scale databases for
retrieval-augmented adaptation, especially in low-data regimes. Despite the
empirical success, understanding how retrieval impacts the adaptation of
vision-language models remains an open research question. In this work, we
adopt a reflective perspective by presenting a systematic study to understand
the roles of key components in retrieval-augmented adaptation. We unveil new
insights on uni-modal and cross-modal retrieval and highlight the critical role
of logit ensemble for effective adaptation. We further present theoretical
underpinnings that directly support our empirical observations.

ÊëòË¶ÅÔºöÈ†êÂÖàË®ìÁ∑¥Â•ΩÁöÑÂ∞çÊØîË¶ñË¶∫Ë™ûË®ÄÊ®°ÂûãÂ∑≤Â±ïÁèæÂá∫Âú®ÂêÑÁ®Æ‰ªªÂãô‰∏≠ÁöÑÈ°ØËëóÊïàËÉΩ„ÄÇÁÑ∂ËÄåÔºåÂÆÉÂÄëÈÄöÂ∏∏Âú®È†êÂÖàË®ìÁ∑¥ÊúüÈñìÊú™ÂÖÖÂàÜÂëàÁèæÈ°ûÂà•ÁöÑÁ≤æÁ¥∞Ë®ìÁ∑¥Ë≥áÊñôÈõÜ‰∏äÈÅáÂà∞Âõ∞Èõ£ÔºåÈÄô‰ΩøÂæóÈÅ©ÊáâËÆäÂæóÂøÖË¶Å„ÄÇÊúÄËøëÁöÑÁ†îÁ©∂È°ØÁ§∫ÔºåÂà©Áî®‰æÜËá™Á∂≤Ë∑ØË¶èÊ®°Ë≥áÊñôÂ∫´ÁöÑÊ®£Êú¨ÈÄ≤Ë°åÊ™¢Á¥¢Â¢ûÂº∑ÈÅ©ÊáâÔºåÁâπÂà•ÊòØÂú®‰ΩéË≥áÊñôÈáèÊ®°Âºè‰∏≠ÔºåÂ∑≤Â±ïÁèæÂá∫ÊúâÂâçÊôØÁöÑÁµêÊûú„ÄÇÂÑòÁÆ°ÊúâÁ∂ìÈ©ó‰∏äÁöÑÊàêÂäüÔºå‰ΩÜÁû≠Ëß£Ê™¢Á¥¢Â¶Ç‰ΩïÂΩ±ÈüøË¶ñË¶∫Ë™ûË®ÄÊ®°ÂûãÁöÑÈÅ©Êáâ‰ªçÁÑ∂ÊòØ‰∏ÄÂÄãÈñãÊîæÁöÑÁ†îÁ©∂ÂïèÈ°å„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊé°Áî®ÂèçÊÄùËßÄÈªûÔºåÈÄèÈÅéÊèêÂá∫Á≥ªÁµ±ÊÄßÁ†îÁ©∂‰æÜÁû≠Ëß£Ê™¢Á¥¢Â¢ûÂº∑ÈÅ©Êáâ‰∏≠ÈóúÈçµÁµÑÊàêÁöÑËßíËâ≤„ÄÇÊàëÂÄëÊè≠Á§∫‰∫ÜÂñÆÊ®°ÊÖãÂíåË∑®Ê®°ÊÖãÊ™¢Á¥¢ÁöÑÊñ∞Ë¶ãËß£Ôºå‰∏¶Âº∑Ë™ø‰∫ÜÈÇèËºØÈõÜÂêàÂ∞çÊúâÊïàÈÅ©ÊáâÁöÑÈóúÈçµ‰ΩúÁî®„ÄÇÊàëÂÄëÈÄ≤‰∏ÄÊ≠•ÊèêÂá∫‰∫ÜÁõ¥Êé•ÊîØÊè¥ÊàëÂÄëÁ∂ìÈ©óËßÄÂØüÁöÑÁêÜË´ñÂü∫Á§é„ÄÇ

##### **UQA: Corpus for Urdu Question Answering**
2405.01458v1 by Samee Arif,Sualeha Farid,Awais Athar,Agha Ali Raza

This paper introduces UQA, a novel dataset for question answering and text
comprehension in Urdu, a low-resource language with over 70 million native
speakers. UQA is generated by translating the Stanford Question Answering
Dataset (SQuAD2.0), a large-scale English QA dataset, using a technique called
EATS (Enclose to Anchor, Translate, Seek), which preserves the answer spans in
the translated context paragraphs. The paper describes the process of selecting
and evaluating the best translation model among two candidates: Google
Translator and Seamless M4T. The paper also benchmarks several state-of-the-art
multilingual QA models on UQA, including mBERT, XLM-RoBERTa, and mT5, and
reports promising results. For XLM-RoBERTa-XL, we have an F1 score of 85.99 and
74.56 EM. UQA is a valuable resource for developing and testing multilingual
NLP systems for Urdu and for enhancing the cross-lingual transferability of
existing models. Further, the paper demonstrates the effectiveness of EATS for
creating high-quality datasets for other languages and domains. The UQA dataset
and the code are publicly available at www.github.com/sameearif/UQA.

ÊëòË¶ÅÔºö<paragraph>Ê≠§Ë´ñÊñá‰ªãÁ¥π‰∫Ü UQAÔºåÈÄôÊòØ‰∏ÄÂÄãÈáùÂ∞çÂïèÈ°åËß£Á≠îÂíåÊñáÂ≠óÁêÜËß£ÁöÑÊñ∞ÂûãË≥áÊñôÈõÜÔºåÈÅ©Áî®ÊñºÁÉèÁàæÈÉΩË™ûÔºåÈÄôÊòØ‰∏ÄÁ®ÆÊìÅÊúâË∂ÖÈÅé 7000 Ëê¨ÂêçÊØçË™û‰∫∫Â£´ÁöÑ‰ΩéË≥áÊ∫êË™ûË®Ä„ÄÇUQA ÊòØÈÄèÈÅéÁøªË≠ØÂè≤‰∏π‰ΩõÂïèÈ°åËß£Á≠îË≥áÊñôÈõÜ (SQuAD2.0) ËÄåÁî¢ÁîüÁöÑÔºåÈÄôÊòØ‰∏ÄÂÄãÂ§ßÂûãÁöÑËã±Ë™û QA Ë≥áÊñôÈõÜÔºå‰ΩøÁî®‰∏ÄÁ®ÆÁ®±ÁÇ∫ EATSÔºàÂ∞ÅÈñâÂà∞Èå®Èªû„ÄÅÁøªË≠Ø„ÄÅÊêúÂ∞ãÔºâÁöÑÊäÄË°ìÔºåÂÆÉ‰øùÁïô‰∫ÜÁøªË≠ØË™ûÂ¢ÉÊÆµËêΩ‰∏≠ÁöÑÁ≠îÊ°àË∑®Â∫¶„ÄÇÊú¨ÊñáÊèèËø∞‰∫ÜÂú®ÂÖ©ÂÄãÂÄôÈÅ∏ËÄÖ‰∏≠ÈÅ∏ÊìáÂíåË©ï‰º∞ÊúÄ‰Ω≥ÁøªË≠ØÊ®°ÂûãÁöÑÈÅéÁ®ãÔºöGoogle ÁøªË≠ØÂíå Seamless M4T„ÄÇÊú¨ÊñáÈÇÑÂú® UQA ‰∏äÂ∞çÂπæÂÄãÊúÄÂÖàÈÄ≤ÁöÑÂ§öË™ûË®Ä QA Ê®°ÂûãÈÄ≤Ë°å‰∫ÜÂü∫Ê∫ñÊ∏¨Ë©¶ÔºåÂåÖÊã¨ mBERT„ÄÅXLM-RoBERTa Âíå mT5Ôºå‰∏¶Â†±Âëä‰∫ÜÊúâÂ∏åÊúõÁöÑÁµêÊûú„ÄÇÂ∞çÊñº XLM-RoBERTa-XLÔºåÊàëÂÄëÁöÑ F1 ÂàÜÊï∏ÁÇ∫ 85.99ÔºåEM ÁÇ∫ 74.56„ÄÇUQA ÊòØÁî®ÊñºÈñãÁôºÂíåÊ∏¨Ë©¶ÁÉèÁàæÈÉΩË™ûÂ§öË™ûË®Ä NLP Á≥ªÁµ±‰ª•ÂèäÂ¢ûÂº∑ÁèæÊúâÊ®°ÂûãÁöÑË∑®Ë™ûË®ÄÂèØÂÇ≥ÈÅûÊÄßÁöÑÂØ∂Ë≤¥Ë≥áÊ∫ê„ÄÇÊ≠§Â§ñÔºåÊú¨ÊñáÂ±ïÁ§∫‰∫Ü EATS Âú®ÁÇ∫ÂÖ∂‰ªñË™ûË®ÄÂíåÈ†òÂüüÂª∫Á´ãÈ´òÂìÅË≥™Ë≥áÊñôÈõÜÊñπÈù¢ÁöÑÊúâÊïàÊÄß„ÄÇUQA Ë≥áÊñôÈõÜÂíåÁ®ãÂºèÁ¢ºÂèØÂú® www.github.com/sameearif/UQA ÂÖ¨ÈñãÂèñÂæó„ÄÇ</paragraph>

##### **Creative Problem Solving in Large Language and Vision Models -- What Would it Take?**
2405.01453v1 by Lakshmi Nair,Evana Gizzi,Jivko Sinapov

In this paper, we discuss approaches for integrating Computational Creativity
(CC) with research in large language and vision models (LLVMs) to address a key
limitation of these models, i.e., creative problem solving. We present
preliminary experiments showing how CC principles can be applied to address
this limitation through augmented prompting. With this work, we hope to foster
discussions of Computational Creativity in the context of ML algorithms for
creative problem solving in LLVMs. Our code is at:
https://github.com/lnairGT/creative-problem-solving-LLMs

ÊëòË¶ÅÔºöÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëË®éË´ñ‰∫ÜÂ∞áË®àÁÆóÂâµÊÑè (CC) ËàáÂ§ßÂûãË™ûË®ÄÂíåË¶ñË¶∫Ê®°Âûã (LLVM) ÁöÑÁ†îÁ©∂Áõ∏ÁµêÂêàÁöÑÊñπÊ≥ïÔºå‰ª•Ëß£Ê±∫ÈÄô‰∫õÊ®°ÂûãÁöÑ‰∏ÄÂÄãÈóúÈçµÈôêÂà∂ÔºåÂç≥ÂâµÈÄ†ÊÄßÂïèÈ°åËß£Ê±∫„ÄÇÊàëÂÄëÊèêÂá∫ÂàùÊ≠•ÂØ¶È©óÔºåÂ±ïÁ§∫Â¶Ç‰ΩïÂ∞á CC ÂéüÂâáÊáâÁî®ÊñºÈÄöÈÅéÂ¢ûÂº∑ÊèêÁ§∫‰æÜËß£Ê±∫ÈÄôÂÄãÈôêÂà∂„ÄÇÈÄöÈÅéÈÄôÈ†ÖÂ∑•‰ΩúÔºåÊàëÂÄëÂ∏åÊúõ‰øÉÈÄ≤Âú®Ë®àÁÆóÂâµÊÑèËÉåÊôØ‰∏ãË®éË´ñ ML ÊºîÁÆóÊ≥ïÔºå‰ª•Ëß£Ê±∫ LLVMs ‰∏≠ÁöÑÂâµÈÄ†ÊÄßÂïèÈ°å„ÄÇÊàëÂÄëÁöÑÁ®ãÂºèÁ¢º‰ΩçÊñºÔºö
https://github.com/lnairGT/creative-problem-solving-LLMs

##### **Natural Language to Verilog: Design of a Recurrent Spiking Neural Network using Large Language Models and ChatGPT**
2405.01419v1 by Paola Vitolo,George Psaltakis,Michael Tomlinson,Gian Domenico Licciardo,Andreas G. Andreou

This paper investigates the use of Large Language Models (LLMs) for
automating the generation of hardware description code, aiming to explore their
potential in supporting and enhancing the development of efficient neuromorphic
computing architectures. Building on our prior work, we employ OpenAI's
ChatGPT4 and natural language prompts to synthesize a RTL Verilog module of a
programmable recurrent spiking neural network, while also generating test
benches to assess the system's correctness. The resultant design was validated
in three case studies, the exclusive OR,the IRIS flower classification and the
MNIST hand-written digit classification, achieving accuracies of up to 96.6%.
To verify its synthesizability and implementability, the design was prototyped
on a field-programmable gate array and implemented on SkyWater 130 nm
technology by using an open-source electronic design automation flow.
Additionally, we have submitted it to Tiny Tapeout 6 chip fabrication program
to further evaluate the system on-chip performance in the future.

ÊëòË¶ÅÔºöÊú¨ÊñáÊé¢Ë®é‰ΩøÁî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Ëá™ÂãïÂåñÁ°¨È´îÊèèËø∞Á¢ºÁöÑÁîüÊàêÔºåÊó®Âú®Êé¢Á¥¢ÂÖ∂Âú®ÊîØÊè¥ÂíåÂº∑ÂåñÈ´òÊïàËÉΩÁ•ûÁ∂ìÂûãÊÖãÈÅãÁÆóÊû∂ÊßãÈñãÁôºÁöÑÊΩõÂäõ„ÄÇÂª∫Á´ãÂú®ÊàëÂÄëÂÖàÂâçÁöÑÁ†îÁ©∂Âü∫Á§é‰∏äÔºåÊàëÂÄë‰ΩøÁî® OpenAI ÁöÑ ChatGPT4 ÂíåËá™ÁÑ∂Ë™ûË®ÄÊèêÁ§∫‰æÜÂêàÊàê‰∏ÄÂÄãÂèØÁ®ãÂºèÂåñÈÅûËø¥ËÑàË°ùÁ•ûÁ∂ìÁ∂≤Ë∑ØÁöÑ RTL Verilog Ê®°ÁµÑÔºåÂêåÊôÇ‰πüÁî¢ÁîüÊ∏¨Ë©¶Âπ≥Âè∞‰æÜË©ï‰º∞Á≥ªÁµ±ÁöÑÊ≠£Á¢∫ÊÄß„ÄÇÁµêÊûúË®≠Ë®àÂú®‰∏âÂÄãÊ°à‰æãÁ†îÁ©∂‰∏≠Áç≤ÂæóÈ©óË≠âÔºåÂåÖÊã¨Áç®‰ΩîÊàñ„ÄÅIRIS Ëä±ÊúµÂàÜÈ°ûÂíå MNIST ÊâãÂØ´Êï∏Â≠óÂàÜÈ°ûÔºåÊ∫ñÁ¢∫Â∫¶È´òÈÅî 96.6%„ÄÇÁÇ∫‰∫ÜÈ©óË≠âÂÖ∂ÂèØÂêàÊàêÊÄßÂíåÂèØÂØ¶‰ΩúÊÄßÔºåË©≤Ë®≠Ë®àÂú®ÁèæÂ†¥ÂèØÁ®ãÂºèÈñòÈô£Âàó‰∏äË£Ω‰ΩúÂéüÂûãÔºå‰∏¶‰ΩøÁî®ÈñãÊ∫êÈõªÂ≠êË®≠Ë®àËá™ÂãïÂåñÊµÅÁ®ãÂú® SkyWater 130 Â•àÁ±≥ÊäÄË°ì‰∏äÂØ¶‰Ωú„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂ∑≤Â∞áÂÖ∂Êèê‰∫§Áµ¶ Tiny Tapeout 6 Êô∂ÁâáË£ΩÈÄ†Ë®àÁï´Ôºå‰ª•ÈÄ≤‰∏ÄÊ≠•Ë©ï‰º∞Á≥ªÁµ±Êú™‰æÜÂú®Êô∂Áâá‰∏äÁöÑÊïàËÉΩ„ÄÇ

##### **MiniGPT-3D: Efficiently Aligning 3D Point Clouds with Large Language Models using 2D Priors**
2405.01413v1 by Yuan Tang,Xu Han,Xianzhi Li,Qiao Yu,Yixue Hao,Long Hu,Min Chen

Large 2D vision-language models (2D-LLMs) have gained significant attention
by bridging Large Language Models (LLMs) with images using a simple projector.
Inspired by their success, large 3D point cloud-language models (3D-LLMs) also
integrate point clouds into LLMs. However, directly aligning point clouds with
LLM requires expensive training costs, typically in hundreds of GPU-hours on
A100, which hinders the development of 3D-LLMs. In this paper, we introduce
MiniGPT-3D, an efficient and powerful 3D-LLM that achieves multiple SOTA
results while training for only 27 hours on one RTX 3090. Specifically, we
propose to align 3D point clouds with LLMs using 2D priors from 2D-LLMs, which
can leverage the similarity between 2D and 3D visual information. We introduce
a novel four-stage training strategy for modality alignment in a cascaded way,
and a mixture of query experts module to adaptively aggregate features with
high efficiency. Moreover, we utilize parameter-efficient fine-tuning methods
LoRA and Norm fine-tuning, resulting in only 47.8M learnable parameters, which
is up to 260x fewer than existing methods. Extensive experiments show that
MiniGPT-3D achieves SOTA on 3D object classification and captioning tasks, with
significantly cheaper training costs. Notably, MiniGPT-3D gains an 8.12
increase on GPT-4 evaluation score for the challenging object captioning task
compared to ShapeLLM-13B, while the latter costs 160 total GPU-hours on 8 A800.
We are the first to explore the efficient 3D-LLM, offering new insights to the
community. Code and weights are available at
https://github.com/TangYuan96/MiniGPT-3D.

ÊëòË¶ÅÔºöÂ§ßÂûã 2D Ë¶ñË¶∫Ë™ûË®ÄÊ®°Âûã (2D-LLM) ÈÄèÈÅé‰ΩøÁî®Á∞°ÂñÆÁöÑÊäïÂΩ±ÂÑÄÂ∞áÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ËàáÂΩ±ÂÉèÈÄ£ÁµêËµ∑‰æÜÔºåÂõ†ËÄåÁç≤Âæó‰∫ÜÈ°ØËëóÁöÑÈóúÊ≥®„ÄÇÂèóÂà∞ÂÖ∂ÊàêÂäüÁöÑÂïüÁôºÔºåÂ§ßÂûã 3D ÈªûÈõ≤Ë™ûË®ÄÊ®°Âûã (3D-LLM) ‰πüÂ∞áÈªûÈõ≤Êï¥ÂêàÂà∞ LLM ‰∏≠„ÄÇÁÑ∂ËÄåÔºåÂ∞áÈªûÈõ≤Áõ¥Êé•Ëàá LLM Â∞çÈΩäÈúÄË¶ÅÊòÇË≤¥ÁöÑË®ìÁ∑¥ÊàêÊú¨ÔºåÈÄöÂ∏∏Âú® A100 ‰∏äÈúÄË¶ÅÊï∏ÁôæÂÄã GPU Â∞èÊôÇÔºåÈÄôÈòªÁ§ô‰∫Ü 3D-LLM ÁöÑÁôºÂ±ï„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π MiniGPT-3DÔºåÈÄôÊòØ‰∏ÄÂÄãÈ´òÊïà‰∏îÂº∑Â§ßÁöÑ 3D-LLMÔºåÂú®‰∏ÄÂÄã RTX 3090 ‰∏äÂÉÖË®ìÁ∑¥ 27 Â∞èÊôÇÂ∞±ÈÅîÂà∞‰∫ÜÂ§öÂÄã SOTA ÁµêÊûú„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÂª∫Ë≠∞‰ΩøÁî® 2D-LLM ÁöÑ 2D ÂÖàÈ©óÂ∞á 3D ÈªûÈõ≤Ëàá LLM Â∞çÈΩäÔºåÈÄôÂèØ‰ª•Âà©Áî® 2D Âíå 3D Ë¶ñË¶∫Ë≥áË®ä‰πãÈñìÁöÑÁõ∏‰ººÊÄß„ÄÇÊàëÂÄë‰ªãÁ¥π‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÂõõÈöéÊÆµË®ìÁ∑¥Á≠ñÁï•Ôºå‰ª•‰∏≤ËÅØÁöÑÊñπÂºèÈÄ≤Ë°åÊ®°ÊÖãÂ∞çÈΩäÔºå‰ª•Âèä‰∏ÄÂÄãÊ∑∑ÂêàÊü•Ë©¢Â∞àÂÆ∂Ê®°ÁµÑÔºå‰ª•È´òÊïàÁéáËá™ÈÅ©ÊáâËÅöÂêàÁâπÂæµ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂà©Áî®ÂèÉÊï∏È´òÊïàÁöÑÂæÆË™øÊñπÊ≥ï LoRA Âíå Norm ÂæÆË™øÔºåÂÉÖÁî¢Áîü 47.8M ÂÄãÂèØÂ≠∏ÁøíÂèÉÊï∏ÔºåÈÄôÊØîÁèæÊúâÊñπÊ≥ïÂ∞ë‰∫Ü 260 ÂÄç„ÄÇÂ§ßÈáèÁöÑÂØ¶È©óË°®ÊòéÔºåMiniGPT-3D Âú® 3D Áâ©‰ª∂ÂàÜÈ°ûÂíåÂ≠óÂπï‰ªªÂãô‰∏äÈÅîÂà∞‰∫Ü SOTAÔºåË®ìÁ∑¥ÊàêÊú¨È°ØËëóÈôç‰Ωé„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåËàá ShapeLLM-13B Áõ∏ÊØîÔºåMiniGPT-3D Âú®ÂÖ∑ÊúâÊåëÊà∞ÊÄßÁöÑÁâ©‰ª∂Â≠óÂπï‰ªªÂãô‰∏äÁç≤Âæó‰∫Ü GPT-4 Ë©ïÂàÜ 8.12 ÁöÑÊèêÂçáÔºåËÄåÂæåËÄÖÂú® 8 ÂÄã A800 ‰∏äÂÖ±ËÄóË≤ª‰∫Ü 160 ÂÄã GPU Â∞èÊôÇ„ÄÇÊàëÂÄëÊòØÁ¨¨‰∏ÄÂÄãÊé¢Á¥¢È´òÊïàÁöÑ 3D-LLM ÁöÑ‰∫∫ÔºåÁÇ∫Á§æÁæ§Êèê‰æõ‰∫ÜÊñ∞ÁöÑË¶ãËß£„ÄÇÁ®ãÂºèÁ¢ºÂíåÊ¨äÈáçÂèØÂú® https://github.com/TangYuan96/MiniGPT-3D ÂèñÂæó„ÄÇ

##### **Goal-conditioned reinforcement learning for ultrasound navigation guidance**
2405.01409v1 by Abdoul Aziz Amadou,Vivek Singh,Florin C. Ghesu,Young-Ho Kim,Laura Stanciulescu,Harshitha P. Sai,Puneet Sharma,Alistair Young,Ronak Rajani,Kawal Rhode

Transesophageal echocardiography (TEE) plays a pivotal role in cardiology for
diagnostic and interventional procedures. However, using it effectively
requires extensive training due to the intricate nature of image acquisition
and interpretation. To enhance the efficiency of novice sonographers and reduce
variability in scan acquisitions, we propose a novel ultrasound (US) navigation
assistance method based on contrastive learning as goal-conditioned
reinforcement learning (GCRL). We augment the previous framework using a novel
contrastive patient batching method (CPB) and a data-augmented contrastive
loss, both of which we demonstrate are essential to ensure generalization to
anatomical variations across patients. The proposed framework enables
navigation to both standard diagnostic as well as intricate interventional
views with a single model. Our method was developed with a large dataset of 789
patients and obtained an average error of 6.56 mm in position and 9.36 degrees
in angle on a testing dataset of 140 patients, which is competitive or superior
to models trained on individual views. Furthermore, we quantitatively validate
our method's ability to navigate to interventional views such as the Left
Atrial Appendage (LAA) view used in LAA closure. Our approach holds promise in
providing valuable guidance during transesophageal ultrasound examinations,
contributing to the advancement of skill acquisition for cardiac ultrasound
practitioners.

ÊëòË¶ÅÔºöÁ∂ìÈ£üÈÅìÂøÉËáüË∂ÖÈü≥Ê≥¢ (TEE) Âú®ÂøÉËáüÁóÖÂ≠∏ÁöÑË®∫Êñ∑Âíå‰ªãÂÖ•ÊÄßÊ≤ªÁôÇ‰∏≠ÊâÆÊºîËëóÈóúÈçµÁöÑËßíËâ≤„ÄÇÁÑ∂ËÄåÔºåÁî±ÊñºÂΩ±ÂÉèÊì∑ÂèñÂíåËß£ËÆÄÁöÑË§áÈõúÊÄßÔºåË¶ÅÊúâÊïàÈÅãÁî®ÂÆÉÈúÄË¶ÅÂª£Ê≥õÁöÑË®ìÁ∑¥„ÄÇÁÇ∫‰∫ÜÊèêÂçáÊñ∞ÊâãË∂ÖÈü≥Ê≥¢Ê™¢Êü•Âì°ÁöÑÊïàÁéá‰∏¶Ê∏õÂ∞ëÊéÉÊèèÊì∑ÂèñÁöÑËÆäÁï∞ÊÄßÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞ÁöÑË∂ÖÈü≥Ê≥¢ (US) Â∞éËà™ËºîÂä©ÊñπÊ≥ïÔºåÂÆÉÂü∫ÊñºÂ∞çÊØîÂ≠∏Áøí‰ΩúÁÇ∫ÁõÆÊ®ôÊ¢ù‰ª∂Âº∑ÂåñÂ≠∏Áøí (GCRL)„ÄÇÊàëÂÄë‰ΩøÁî®‰∏ÄÁ®ÆÊñ∞ÁöÑÂ∞çÊØîÁóÖ‰∫∫ÊâπÊ¨°ËôïÁêÜÊñπÊ≥ï (CPB) ÂíåË≥áÊñôÊì¥ÂÖÖÂ∞çÊØîÊêçÂ§±‰æÜÊì¥ÂÖÖÂÖàÂâçÁöÑÊû∂ÊßãÔºåÊàëÂÄëË≠âÊòéÂÖ©ËÄÖÂ∞çÊñºÁ¢∫‰øùÂ∞ç‰∏çÂêåÁóÖ‰∫∫ÁöÑËß£ÂâñËÆäÁï∞ÈÄ≤Ë°åÊ¶ÇÂåñËá≥ÈóúÈáçË¶Å„ÄÇÊâÄÊèêÂá∫ÁöÑÊû∂ÊßãËÉΩÈÄèÈÅéÂñÆ‰∏ÄÊ®°ÂûãÂ∞éËà™Âà∞Ê®ôÊ∫ñË®∫Êñ∑ÂíåË§áÈõúÁöÑ‰ªãÂÖ•ÊÄßÂΩ±ÂÉè„ÄÇÊàëÂÄëÁöÑÊäÄË°ìÊòØ‰ΩøÁî® 789 ÂêçÁóÖ‰∫∫ÁöÑÂ§ßÂûãË≥áÊñôÈõÜÈñãÁôºÁöÑÔºåÂú® 140 ÂêçÁóÖ‰∫∫ÁöÑÊ∏¨Ë©¶Ë≥áÊñôÈõÜ‰∏äÔºå‰ΩçÁΩÆÁöÑÂπ≥ÂùáË™§Â∑ÆÁÇ∫ 6.56 ÊØ´Á±≥ÔºåËßíÂ∫¶ÁÇ∫ 9.36 Â∫¶ÔºåËàáÈáùÂ∞çÂÄãÂà•ÂΩ±ÂÉèË®ìÁ∑¥ÁöÑÊ®°ÂûãÁõ∏ÊØîÔºåÂÖ∑ÊúâÁ´∂Áà≠ÂäõÊàñÊõ¥ÂÑ™Áï∞„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂÆöÈáèÈ©óË≠â‰∫ÜÊàëÂÄëÁöÑÊñπÊ≥ïÂ∞éËà™Âà∞‰ªãÂÖ•ÊÄßÂΩ±ÂÉèÔºà‰æãÂ¶ÇÂ∑¶ÂøÉËÄ≥ (LAA) Â∞ÅÈñâ‰∏≠‰ΩøÁî®ÁöÑÂ∑¶ÂøÉËÄ≥ÈôÑÂ±¨Áâ© (LAA) ÂΩ±ÂÉèÔºâÁöÑËÉΩÂäõ„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÊúâÊúõÂú®Á∂ìÈ£üÈÅìË∂ÖÈü≥Ê≥¢Ê™¢Êü•‰∏≠Êèê‰æõÊúâÂÉπÂÄºÁöÑÊåáÂ∞éÔºåÊúâÂä©ÊñºÊèêÂçáÂøÉËáüË∂ÖÈü≥Ê≥¢ÂæûÊ•≠ËÄÖÁöÑÊäÄËÉΩÁøíÂæó„ÄÇ

##### **Verification and Refinement of Natural Language Explanations through LLM-Symbolic Theorem Proving**
2405.01379v1 by Xin Quan,Marco Valentino,Louise A. Dennis,Andr√© Freitas

Natural language explanations have become a proxy for evaluating explainable
and multi-step Natural Language Inference (NLI) models. However, assessing the
validity of explanations for NLI is challenging as it typically involves the
crowd-sourcing of apposite datasets, a process that is time-consuming and prone
to logical errors. To address existing limitations, this paper investigates the
verification and refinement of natural language explanations through the
integration of Large Language Models (LLMs) and Theorem Provers (TPs).
Specifically, we present a neuro-symbolic framework, named Explanation-Refiner,
that augments a TP with LLMs to generate and formalise explanatory sentences
and suggest potential inference strategies for NLI. In turn, the TP is employed
to provide formal guarantees on the logical validity of the explanations and to
generate feedback for subsequent improvements. We demonstrate how
Explanation-Refiner can be jointly used to evaluate explanatory reasoning,
autoformalisation, and error correction mechanisms of state-of-the-art LLMs as
well as to automatically enhance the quality of human-annotated explanations of
variable complexity in different domains.

ÊëòË¶ÅÔºöËá™ÁÑ∂Ë™ûË®ÄËß£ÈáãÂ∑≤ÊàêÁÇ∫Ë©ï‰º∞ÂèØËß£ÈáãÂíåÂ§öÊ≠•È©üËá™ÁÑ∂Ë™ûË®ÄÊé®ÁêÜ (NLI) Ê®°ÂûãÁöÑ‰ª£ÁêÜ„ÄÇÁÑ∂ËÄåÔºåË©ï‰º∞ NLI Ëß£ÈáãÁöÑÊúâÊïàÊÄßÂÖ∑ÊúâÊåëÊà∞ÊÄßÔºåÂõ†ÁÇ∫ÂÆÉÈÄöÂ∏∏Ê∂âÂèäÈÅ©Áï∂Êï∏ÊìöÈõÜÁöÑÁæ§ÁúæÂ§ñÂåÖÔºåÈÄôÊòØ‰∏ÄÂÄãËÄóÊôÇ‰∏îÂÆπÊòìÂá∫ÁèæÈÇèËºØÈåØË™§ÁöÑÈÅéÁ®ã„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÁèæÊúâÁöÑÈôêÂà∂ÔºåÊú¨ÊñáÊé¢Ë®é‰∫ÜÈÄöÈÅéÊï¥ÂêàÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂíåÂÆöÁêÜË≠âÊòéÂô® (TP) ‰æÜÈ©óË≠âÂíåÊîπÈÄ≤Ëá™ÁÑ∂Ë™ûË®ÄËß£Èáã„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂêçÁÇ∫ Explanation-Refiner ÁöÑÁ•ûÁ∂ìÁ¨¶ËôüÊ°ÜÊû∂ÔºåÂÆÉ‰ΩøÁî® LLM Êì¥ÂÖÖ‰∫Ü‰∏ÄÂÄã TPÔºå‰ª•ÁîüÊàêÂíåÂΩ¢ÂºèÂåñËß£ÈáãÊÄßÂè•Â≠êÔºå‰∏¶ÊèêÂá∫ NLI ÁöÑÊΩõÂú®Êé®ÁêÜÁ≠ñÁï•„ÄÇÂèçÈÅé‰æÜÔºåTP Ë¢´Áî®ÊñºÊèê‰æõÂ∞çËß£ÈáãÈÇèËºØÊúâÊïàÊÄßÁöÑÊ≠£Âºè‰øùË≠âÔºå‰∏¶ÁÇ∫ÂæåÁ∫åÊîπÈÄ≤Êèê‰æõÂèçÈ•ã„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫Ü Explanation-Refiner Â¶Ç‰ΩïË¢´ËÅØÂêàÁî®ÊñºË©ï‰º∞Ëß£ÈáãÊÄßÊé®ÁêÜ„ÄÅËá™ÂãïÂΩ¢ÂºèÂåñÂíåÊúÄÂÖàÈÄ≤ LLM ÁöÑÈåØË™§Ê†°Ê≠£Ê©üÂà∂Ôºå‰ª•ÂèäËá™ÂãïÊèêÈ´ò‰∏çÂêåÈ†òÂüü‰∏≠‰∫∫È°ûË®ªÈáãËß£ÈáãÁöÑË≥™Èáè„ÄÇ

##### **Topics in the Study of the Pragmatic Functions of Phonetic Reduction in Dialog**
2405.01376v1 by Nigel G. Ward,Carlos A. Ortega

Reduced articulatory precision is common in speech, but for dialog its
acoustic properties and pragmatic functions have been little studied. We here
try to remedy this gap. This technical report contains content that was omitted
from the journal article (Ward et al. 2024, submitted). Specifically, we here
report 1) lessons learned about annotating for perceived reduction, 2) the
finding that, unlike in read speech, the correlates of reduction in dialog
include high pitch, wide pitch range, and intensity, and 3) a baseline model
for predicting reduction in dialog, using simple acoustic/prosodic features,
that achieves correlations with human perceptions of 0.24 for English, and 0.17
for Spanish. We also provide examples of additional possible pragmatic
functions of reduction in English, and various discussion, observations and
speculations

ÊëòË¶ÅÔºöÂú®Âè£Ë™û‰∏≠ÔºåÁôºÈü≥Á≤æÊ∫ñÂ∫¶Èôç‰ΩéÁöÑÊÉÖÊ≥ÅÂæàÂ∏∏Ë¶ãÔºå‰ΩÜÂ∞çÊñºÂ∞çË©±‰æÜË™™ÔºåÂÖ∂Èü≥ÈüøÁâπÊÄßÂíåË™ûÁî®ÂäüËÉΩÁöÑÁ†îÁ©∂ÂçªÂæàÂ∞ë„ÄÇÊàëÂÄëÂú®Ê≠§ÂòóË©¶ÂΩåË£úÈÄôÂÄãÂ∑ÆË∑ù„ÄÇÈÄô‰ªΩÊäÄË°ìÂ†±ÂëäÂåÖÂê´ÂæûÊúüÂàäÊñáÁ´†ÔºàWard Á≠â‰∫∫Ôºå2024 Âπ¥ÔºåÂ∑≤Êèê‰∫§Ôºâ‰∏≠ÈÅ∫ÊºèÁöÑÂÖßÂÆπ„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÂú®Ê≠§Â†±Âëä 1) ÈóúÊñºÊ®ôË®ªÊÑüÁü•Âà∞ÁöÑÁ∞°ÂåñÁöÑÁ∂ìÈ©óÊïôË®ìÔºå2) ËàáÊúóËÆÄÁöÑË™ûÈü≥‰∏çÂêåÔºåÂ∞çË©±‰∏≠Á∞°ÂåñÁöÑÁõ∏ÈóúÊÄßÂåÖÊã¨È´òÈü≥È´ò„ÄÅÂØ¨Èü≥È´òÁØÑÂúçÂíåÂº∑Â∫¶Ôºå‰ª•Âèä 3) ‰∏ÄÂÄãÁî®ÊñºÈ†êÊ∏¨Â∞çË©±‰∏≠Á∞°ÂåñÁöÑÂü∫Ê∫ñÊ®°ÂûãÔºå‰ΩøÁî®Á∞°ÂñÆÁöÑÈü≥Èüø/ÈüªÂæãÁâπÂæµÔºåËàáËã±Ë™ûÁöÑ‰∫∫È°ûÊÑüÁü•Áõ∏ÈóúÊÄßÈÅîÂà∞ 0.24ÔºåËàáË•øÁè≠ÁâôË™ûÁõ∏ÈóúÊÄßÈÅîÂà∞ 0.17„ÄÇÊàëÂÄëÈÇÑÊèê‰æõ‰∫ÜËã±Ë™û‰∏≠Á∞°ÂåñÂÖ∂‰ªñÂèØËÉΩÁöÑË™ûÁî®ÂäüËÉΩÁöÑÁØÑ‰æãÔºå‰ª•ÂèäÂêÑÁ®ÆË®éË´ñ„ÄÅËßÄÂØüÂíåÊé®Ê∏¨

##### **GAIA: A General AI Assistant for Intelligent Accelerator Operations**
2405.01359v1 by Frank Mayet

Large-scale machines like particle accelerators are usually run by a team of
experienced operators. In case of a particle accelerator, these operators
possess suitable background knowledge on both accelerator physics and the
technology comprising the machine. Due to the complexity of the machine,
particular subsystems of the machine are taken care of by experts, who the
operators can turn to. In this work the reasoning and action (ReAct) prompting
paradigm is used to couple an open-weights large language model (LLM) with a
high-level machine control system framework and other tools, e.g. the
electronic logbook or machine design documentation. By doing so, a multi-expert
retrieval augmented generation (RAG) system is implemented, which assists
operators in knowledge retrieval tasks, interacts with the machine directly if
needed, or writes high level control system scripts. This consolidation of
expert knowledge and machine interaction can simplify and speed up machine
operation tasks for both new and experienced human operators.

ÊëòË¶ÅÔºöÂ§ßÂûãÊ©üÂô®Ôºà‰æãÂ¶ÇÁ≤íÂ≠êÂä†ÈÄüÂô®ÔºâÈÄöÂ∏∏Áî±Á∂ìÈ©óË±êÂØåÁöÑÊìç‰ΩúÂì°ÂúòÈöäÈÅãË°å„ÄÇÂ∞çÊñºÁ≤íÂ≠êÂä†ÈÄüÂô®ÔºåÈÄô‰∫õÊìç‰ΩúÂì°ÂÖ∑ÂÇôÂä†ÈÄüÂô®Áâ©ÁêÜÂíåÊßãÊàêÊ©üÂô®ÊäÄË°ìÁöÑÈÅ©Áï∂ËÉåÊôØÁü•Ë≠ò„ÄÇÁî±ÊñºÊ©üÂô®Ë§áÈõúÔºåÊ©üÂô®ÁöÑÁâπÂÆöÂ≠êÁ≥ªÁµ±Áî±Â∞àÂÆ∂Ë≤†Ë≤¨ÔºåÊìç‰ΩúÂì°ÂèØ‰ª•Âêë‰ªñÂÄëÊ±ÇÂä©„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊé®ÁêÜÂíåÂãï‰Ωú (ReAct) ÊèêÁ§∫ÁØÑ‰æãÁî®ÊñºÂ∞áÈñãÊîæÊ¨äÈáçÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ËàáÈ´òÁ¥öÊ©üÂô®ÊéßÂà∂Á≥ªÁµ±Ê°ÜÊû∂ÂíåÂÖ∂‰ªñÂ∑•ÂÖ∑Ôºà‰æãÂ¶ÇÈõªÂ≠êÊó•Ë™åÊàñÊ©üÂô®Ë®≠Ë®àÊñá‰ª∂ÔºâÁµêÂêàÂú®‰∏ÄËµ∑„ÄÇËóâÊ≠§ÂØ¶‰ΩúÂ§öÂ∞àÂÆ∂Ê™¢Á¥¢Â¢ûÂº∑ÁîüÊàê (RAG) Á≥ªÁµ±ÔºåÂçîÂä©Êìç‰ΩúÂì°Âü∑Ë°åÁü•Ë≠òÊ™¢Á¥¢‰ªªÂãôÔºåÂú®ÈúÄË¶ÅÊôÇÁõ¥Êé•ËàáÊ©üÂô®‰∫íÂãïÔºåÊàñÊí∞ÂØ´È´òÁ¥öÊéßÂà∂Á≥ªÁµ±ËÖ≥Êú¨„ÄÇÈÄôÁ®ÆÂ∞àÂÆ∂Áü•Ë≠òÂíåÊ©üÂô®‰∫íÂãïÁöÑÊï¥ÂêàÂèØ‰ª•Á∞°ÂåñÂíåÂä†ÈÄüÊñ∞Ëàä‰∫∫È°ûÊìç‰ΩúÂì°ÁöÑÊ©üÂô®Êìç‰Ωú‰ªªÂãô„ÄÇ

##### **The Power of Question Translation Training in Multilingual Reasoning: Broadened Scope and Deepened Insights**
2405.01345v1 by Wenhao Zhu,Shujian Huang,Fei Yuan,Cheng Chen,Jiajun Chen,Alexandra Birch

Bridging the significant gap between large language model's English and
non-English performance presents a great challenge. While some previous studies
attempt to mitigate this gap with translated training data, the recently
proposed question alignment approach leverages the model's English expertise to
improve multilingual performance with minimum usage of expensive, error-prone
translation. In this paper, we explore how broadly this method can be applied
by examining its effects in reasoning with executable code and reasoning with
common sense. We also explore how to apply this approach efficiently to
extremely large language models using proxy-tuning. Experiment results on
multilingual reasoning benchmarks mGSM, mSVAMP and xCSQA demonstrate that the
question alignment approach can be used to boost multilingual performance
across diverse reasoning scenarios, model families, and sizes. For instance,
when applied to the LLaMA2 models, our method brings an average accuracy
improvements of 12.2% on mGSM even with the 70B model. To understand the
mechanism of its success, we analyze representation space, chain-of-thought and
translation data scales, which reveals how question translation training
strengthens language alignment within LLMs and shapes their working patterns.

ÊëòË¶ÅÔºöÂΩåÂêàÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÁöÑËã±ÊñáÂíåÈùûËã±ÊñáË°®Áèæ‰πãÈñìÁöÑÈáçÂ§ßÂ∑ÆË∑ùÊòØ‰∏ÄÈ†ÖÂ∑®Â§ßÁöÑÊåëÊà∞„ÄÇÈõñÁÑ∂‰∏Ä‰∫õÂÖàÂâçÁöÑÁ†îÁ©∂ÂòóË©¶‰ΩøÁî®ÁøªË≠ØÁöÑË®ìÁ∑¥Ë≥áÊñô‰æÜÁ∏ÆÂ∞èÈÄôÂÄãÂ∑ÆË∑ùÔºå‰ΩÜÊúÄËøëÊèêÂá∫ÁöÑÂïèÈ°åÊØîÂ∞çÊñπÊ≥ïÂà©Áî®‰∫ÜÊ®°ÂûãÁöÑËã±ÊñáÂ∞àÊ•≠Áü•Ë≠òÔºå‰ª•ÊúÄÂ∞ë‰ΩøÁî®ÊòÇË≤¥‰∏îÂÆπÊòìÂá∫ÈåØÁöÑÁøªË≠Ø‰æÜÊîπÂñÑÂ§öË™ûË®ÄË°®Áèæ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊé¢Ë®é‰∫ÜÈÄôÁ®ÆÊñπÊ≥ïÂèØ‰ª•Âª£Ê≥õÊáâÁî®ÁöÑÁ®ãÂ∫¶ÔºåÊñπÊ≥ïÊòØÊ™¢Ë¶ñÂÆÉÂú®ÂèØÂü∑Ë°åÁ®ãÂºèÁ¢ºÊé®ÁêÜÂíåÂ∏∏Ë≠òÊé®ÁêÜ‰∏≠ÁöÑÂΩ±Èüø„ÄÇÊàëÂÄëÈÇÑÊé¢Ë®éÂ¶Ç‰Ωï‰ΩøÁî®‰ª£ÁêÜË™øÊï¥ÊúâÊïàÁéáÂú∞Â∞áÈÄôÁ®ÆÊñπÊ≥ïÊáâÁî®ÊñºÊ•µÂ§ßÂûãË™ûË®ÄÊ®°Âûã„ÄÇÂ§öË™ûË®ÄÊé®ÁêÜÂü∫Ê∫ñ mGSM„ÄÅmSVAMP Âíå xCSQA ÁöÑÂØ¶È©óÁµêÊûúË≠âÊòéÔºåÂïèÈ°åÊØîÂ∞çÊñπÊ≥ïÂèØÁî®ÊñºÊèêÂçáÂêÑÁ®ÆÊé®ÁêÜÊÉÖÂ¢É„ÄÅÊ®°ÂûãÁ≥ªÂàóÂíåË¶èÊ®°ÁöÑÂ§öË™ûË®ÄË°®Áèæ„ÄÇ‰æãÂ¶ÇÔºåÁï∂ÊáâÁî®Êñº LLaMA2 Ê®°ÂûãÊôÇÔºåÊàëÂÄëÁöÑÊ®°ÂûãÂç≥‰ΩøÂú® 70B Ê®°Âûã‰∏≠Ôºå‰πüËÉΩËÆì mGSM ÁöÑÂπ≥ÂùáÊ∫ñÁ¢∫Â∫¶ÊèêÂçá 12.2%„ÄÇÁÇ∫‰∫Ü‰∫ÜËß£ÂÖ∂ÊàêÂäüÁöÑÊ©üÂà∂ÔºåÊàëÂÄëÂàÜÊûê‰∫ÜË°®ÂæµÁ©∫Èñì„ÄÅÊÄùËÄÉÈèàÂíåÁøªË≠ØË≥áÊñôË¶èÊ®°ÔºåÊè≠Á§∫‰∫ÜÂïèÈ°åÁøªË≠ØË®ìÁ∑¥Â¶Ç‰ΩïÂº∑Âåñ LLM ÂÖßÈÉ®ÁöÑË™ûË®ÄÊØîÂ∞ç‰∏¶ÂΩ¢Â°ëÂÖ∂Â∑•‰ΩúÊ®°Âºè„ÄÇ

##### **Overcoming LLM Challenges using RAG-Driven Precision in Coffee Leaf Disease Remediation**
2405.01310v1 by Dr. Selva Kumar S,Afifah Khan Mohammed Ajmal Khan,Imadh Ajaz Banday,Manikantha Gada,Vibha Venkatesh Shanbhag

This research introduces an innovative AI-driven precision agriculture
system, leveraging YOLOv8 for disease identification and Retrieval Augmented
Generation (RAG) for context-aware diagnosis. Focused on addressing the
challenges of diseases affecting the coffee production sector in Karnataka, The
system integrates sophisticated object detection techniques with language
models to address the inherent constraints associated with Large Language
Models (LLMs). Our methodology not only tackles the issue of hallucinations in
LLMs, but also introduces dynamic disease identification and remediation
strategies. Real-time monitoring, collaborative dataset expansion, and
organizational involvement ensure the system's adaptability in diverse
agricultural settings. The effect of the suggested system extends beyond
automation, aiming to secure food supplies, protect livelihoods, and promote
eco-friendly farming practices. By facilitating precise disease identification,
the system contributes to sustainable and environmentally conscious
agriculture, reducing reliance on pesticides. Looking to the future, the
project envisions continuous development in RAG-integrated object detection
systems, emphasizing scalability, reliability, and usability. This research
strives to be a beacon for positive change in agriculture, aligning with global
efforts toward sustainable and technologically enhanced food production.

ÊëòË¶ÅÔºöÊú¨Á†îÁ©∂ÂºïÂÖ•‰∫Ü‰∏ÄÁ®ÆÂâµÊñ∞ÁöÑ AI È©ÖÂãïÁ≤æÊ∫ñËæ≤Ê•≠Á≥ªÁµ±ÔºåÂà©Áî® YOLOv8 ÈÄ≤Ë°åÁñæÁóÖË≠òÂà•Ôºå‰∏¶Âà©Áî®Ê™¢Á¥¢Â¢ûÂº∑ÁîüÊàê (RAG) ÈÄ≤Ë°åÊÉÖÂ¢ÉÊÑüÁü•Ë®∫Êñ∑„ÄÇÂ∞àÊ≥®ÊñºËß£Ê±∫ÂΩ±ÈüøÂç°Á¥çÂ°îÂÖãÈÇ¶ÂíñÂï°ÁîüÁî¢ÈÉ®ÈñÄÁöÑÁñæÁóÖÊåëÊà∞ÔºåË©≤Á≥ªÁµ±Â∞áÂÖàÈÄ≤ÁöÑÁâ©È´îÊ™¢Ê∏¨ÊäÄË°ìËàáË™ûË®ÄÊ®°ÂûãÁõ∏ÁµêÂêàÔºå‰ª•Ëß£Ê±∫ËàáÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Áõ∏ÈóúÁöÑÂõ∫ÊúâÁ¥ÑÊùü„ÄÇÊàëÂÄëÁöÑÊäÄË°ì‰∏çÂÉÖËß£Ê±∫‰∫Ü LLM ‰∏≠ÁöÑÂπªË¶∫ÂïèÈ°åÔºåÈÇÑÂºïÂÖ•‰∫ÜÂãïÊÖãÁñæÁóÖË≠òÂà•ÂíåË£úÊïëÁ≠ñÁï•„ÄÇÂØ¶ÊôÇÁõ£Êéß„ÄÅÂçî‰ΩúÂºèÊï∏ÊìöÈõÜÊì¥Â±ïÂíåÁµÑÁπîÂèÉËàáÁ¢∫‰øù‰∫ÜÁ≥ªÁµ±Âú®Â§öÊ®£ÂåñËæ≤Ê•≠Áí∞Â¢É‰∏≠ÁöÑÈÅ©ÊáâÊÄß„ÄÇÂª∫Ë≠∞Á≥ªÁµ±ÁöÑÊïàÊûúË∂ÖË∂ä‰∫ÜËá™ÂãïÂåñÔºåÊó®Âú®Á¢∫‰øùÁ≥ßÈ£ü‰æõÊáâ„ÄÅ‰øùË≠∑ÁîüË®à‰∏¶‰øÉÈÄ≤Áí∞‰øùËæ≤Ê•≠ÂØ¶Âãô„ÄÇÈÄöÈÅé‰øÉÈÄ≤Á≤æÁ¢∫ÁöÑÁñæÁóÖË≠òÂà•ÔºåË©≤Á≥ªÁµ±ÊúâÂä©ÊñºÂØ¶ÁèæÂèØÊåÅÁ∫åÂíåÊ≥®ÈáçÁí∞Â¢ÉÁöÑËæ≤Ê•≠ÔºåÊ∏õÂ∞ëÂ∞çËæ≤Ëó•ÁöÑ‰æùË≥¥„ÄÇÂ±ïÊúõÊú™‰æÜÔºåË©≤È†ÖÁõÆÈ†êË®à RAG ÈõÜÊàêÁöÑÁâ©È´îÊ™¢Ê∏¨Á≥ªÁµ±Â∞áÊåÅÁ∫åÁôºÂ±ïÔºåÂº∑Ë™øÂèØÊì¥Â±ïÊÄß„ÄÅÂèØÈù†ÊÄßÂíåÂèØÁî®ÊÄß„ÄÇÊú¨Á†îÁ©∂Ëá¥ÂäõÊñºÊàêÁÇ∫Ëæ≤Ê•≠Ê≠£Èù¢ËÆäÈù©ÁöÑÁáàÂ°îÔºåËàáÂÖ®ÁêÉÂú®ÂèØÊåÅÁ∫åÂíåÊäÄË°ìÂ¢ûÂº∑È£üÂìÅÁîüÁî¢ÊñπÈù¢ÁöÑÂä™Âäõ‰øùÊåÅ‰∏ÄËá¥„ÄÇ

##### **Distributed Representations Enable Robust Multi-Timescale Computation in Neuromorphic Hardware**
2405.01305v1 by Madison Cotteret,Hugh Greatorex,Alpha Renner,Junren Chen,Emre Neftci,Huaqiang Wu,Giacomo Indiveri,Martin Ziegler,Elisabetta Chicca

Programming recurrent spiking neural networks (RSNNs) to robustly perform
multi-timescale computation remains a difficult challenge. To address this, we
show how the distributed approach offered by vector symbolic architectures
(VSAs), which uses high-dimensional random vectors as the smallest units of
representation, can be leveraged to embed robust multi-timescale dynamics into
attractor-based RSNNs. We embed finite state machines into the RSNN dynamics by
superimposing a symmetric autoassociative weight matrix and asymmetric
transition terms. The transition terms are formed by the VSA binding of an
input and heteroassociative outer-products between states. Our approach is
validated through simulations with highly non-ideal weights; an experimental
closed-loop memristive hardware setup; and on Loihi 2, where it scales
seamlessly to large state machines. This work demonstrates the effectiveness of
VSA representations for embedding robust computation with recurrent dynamics
into neuromorphic hardware, without requiring parameter fine-tuning or
significant platform-specific optimisation. This advances VSAs as a high-level
representation-invariant abstract language for cognitive algorithms in
neuromorphic hardware.

ÊëòË¶ÅÔºöÂ∞çÈÅûËø¥Â∞ñÂ≥∞Á•ûÁ∂ìÁ∂≤Ë∑Ø (RSNN) ÈÄ≤Ë°åÁ∑®Á®ã‰ª•Á©©ÂÅ•Âú∞Âü∑Ë°åÂ§öÊôÇÈñìÂ∞∫Â∫¶ÈÅãÁÆó‰ªçÁÑ∂ÊòØ‰∏ÄÈ†ÖËâ±Èõ£ÁöÑÊåëÊà∞„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜÂêëÈáèÁ¨¶ËôüÊû∂Êßã (VSA) Êèê‰æõÁöÑÂàÜÂ∏ÉÂºèÊñπÊ≥ïÂ¶Ç‰Ωï‰ΩøÁî®È´òÁ∂≠Èö®Ê©üÂêëÈáè‰ΩúÁÇ∫Ë°®Á§∫ÁöÑÊúÄÂ∞èÂñÆ‰ΩçÔºåÂèØ‰ª•Âà©Áî®‰æÜÂ∞áÁ©©ÂÅ•ÁöÑÂ§öÊôÇÈñìÂ∞∫Â∫¶ÂãïÊÖãÂµåÂÖ•Âà∞Âü∫ÊñºÂê∏ÂºïÂ≠êÁöÑ RSNN ‰∏≠„ÄÇÊàëÂÄëÈÄöÈÅéÁñäÂä†Â∞çÁ®±Ëá™ËÅØÊÉ≥Ê¨äÈáçÁü©Èô£ÂíåÈùûÂ∞çÁ®±ËΩâÊèõÈ†ÖÂ∞áÊúâÈôêÁãÄÊÖãÊ©üÂµåÂÖ•Âà∞ RSNN ÂãïÊÖã‰∏≠„ÄÇËΩâÊèõÈ†ÖÁî±Ëº∏ÂÖ•ÁöÑ VSA ÁµêÂêàÂíåÁãÄÊÖã‰πãÈñìÁöÑÁï∞ËÅØÊÉ≥Â§ñÈÉ®‰πòÁ©çÂΩ¢Êàê„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÈÄöÈÅéÂÖ∑ÊúâÈ´òÂ∫¶ÈùûÁêÜÊÉ≥Ê¨äÈáçÁöÑÊ®°Êì¨ÈÄ≤Ë°åÈ©óË≠âÔºõÂØ¶È©óÊÄßÁöÑÈñâÁí∞ÊÜ∂ÈòªÂô®Á°¨È´îË®≠ÁΩÆÔºõ‰ª•ÂèäÂú® Loihi 2 ‰∏äÔºåÂÆÉÂèØ‰ª•ÁÑ°Á∏´Âú∞Êì¥Â±ïÂà∞Â§ßÂûãÁãÄÊÖãÊ©ü„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúË≠âÊòé‰∫Ü VSA Ë°®Á§∫Â∞çÊñºÂ∞áÁ©©ÂÅ•ÈÅãÁÆóËàáÈÅûËø¥ÂãïÊÖãÂµåÂÖ•Âà∞Á•ûÁ∂ìÂΩ¢ÊÖãÁ°¨È´î‰∏≠ÊòØÊúâÊïàÁöÑÔºåËÄå‰∏çÈúÄË¶ÅÂèÉÊï∏ÂæÆË™øÊàñÈáçË¶ÅÁöÑÁâπÂÆöÊñºÂπ≥Âè∞ÁöÑÊúÄ‰Ω≥Âåñ„ÄÇÈÄôÊé®Âãï‰∫Ü VSA ÊàêÁÇ∫Á•ûÁ∂ìÂΩ¢ÊÖãÁ°¨È´î‰∏≠Ë™çÁü•ÊºîÁÆóÊ≥ïÁöÑÈ´òÈöéË°®Á§∫‰∏çËÆäÊäΩË±°Ë™ûË®Ä„ÄÇ

##### **The Effectiveness of LLMs as Annotators: A Comparative Overview and Empirical Analysis of Direct Representation**
2405.01299v1 by Maja Pavlovic,Massimo Poesio

Large Language Models (LLMs) have emerged as powerful support tools across
various natural language tasks and a range of application domains. Recent
studies focus on exploring their capabilities for data annotation. This paper
provides a comparative overview of twelve studies investigating the potential
of LLMs in labelling data. While the models demonstrate promising cost and
time-saving benefits, there exist considerable limitations, such as
representativeness, bias, sensitivity to prompt variations and English language
preference. Leveraging insights from these studies, our empirical analysis
further examines the alignment between human and GPT-generated opinion
distributions across four subjective datasets. In contrast to the studies
examining representation, our methodology directly obtains the opinion
distribution from GPT. Our analysis thereby supports the minority of studies
that are considering diverse perspectives when evaluating data annotation tasks
and highlights the need for further research in this direction.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤ÊàêÁÇ∫ÂêÑÁ®ÆËá™ÁÑ∂Ë™ûË®Ä‰ªªÂãôÂíå‰∏ÄÁ≥ªÂàóÊáâÁî®È†òÂüü‰∏≠Âº∑Â§ßÁöÑÊîØÊè¥Â∑•ÂÖ∑„ÄÇÊúÄËøëÁöÑÁ†îÁ©∂Â∞àÊ≥®ÊñºÊé¢Á¥¢ÂÆÉÂÄëÂú®Ë≥áÊñôË®ªËß£ÊñπÈù¢ÁöÑËÉΩÂäõ„ÄÇÊú¨ÊñáÊèê‰æõ‰∫ÜÂ∞çÂçÅ‰∫åÈ†ÖÁ†îÁ©∂ÁöÑÊØîËºÉÊ¶ÇËø∞ÔºåÈÄô‰∫õÁ†îÁ©∂Êé¢Ë®é‰∫Ü LLM Âú®Ê®ôÁ±§Ë≥áÊñôÊñπÈù¢ÁöÑÊΩõÂäõ„ÄÇÂÑòÁÆ°ÈÄô‰∫õÊ®°ÂûãÂ±ïÁ§∫‰∫ÜÊúâÊúõÈôç‰ΩéÊàêÊú¨ÂíåÁØÄÁúÅÊôÇÈñìÁöÑÂÑ™ÈªûÔºå‰ΩÜ‰ªçÂ≠òÂú®Áõ∏Áï∂Â§ßÁöÑÈôêÂà∂Ôºå‰æãÂ¶Ç‰ª£Ë°®ÊÄß„ÄÅÂÅèË¶ã„ÄÅÂ∞çÊèêÁ§∫ËÆäÂåñÁöÑÊïèÊÑüÊÄß‰ª•ÂèäÂÅèÂ•ΩËã±Ë™ûË™ûË®Ä„ÄÇÂà©Áî®ÈÄô‰∫õÁ†îÁ©∂ÁöÑË¶ãËß£ÔºåÊàëÂÄëÁöÑÂØ¶Ë≠âÂàÜÊûêÈÄ≤‰∏ÄÊ≠•Êé¢Ë®é‰∫Ü‰∫∫È°ûÂíå GPT ÁîüÊàêÁöÑÊÑèË¶ãÂàÜ‰ΩàÂú®ÂõõÂÄã‰∏ªËßÄË≥áÊñôÈõÜ‰πãÈñìÁöÑ‰∏ÄËá¥ÊÄß„ÄÇËàáÊé¢Ë®é‰ª£Ë°®ÊÄßÁöÑÁ†îÁ©∂Áõ∏ÂèçÔºåÊàëÂÄëÁöÑÁ†îÁ©∂ÊñπÊ≥ïÁõ¥Êé•Âæû GPT Áç≤ÂæóÊÑèË¶ãÂàÜ‰Ωà„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëÁöÑÂàÜÊûêÊîØÊåÅÂ∞ëÊï∏Âú®Ë©ï‰º∞Ë≥áÊñôË®ªËß£‰ªªÂãôÊôÇËÄÉÊÖÆ‰∏çÂêåËßÄÈªûÁöÑÁ†îÁ©∂Ôºå‰∏¶Âº∑Ë™øÈúÄË¶ÅÊúùÈÄôÂÄãÊñπÂêëÈÄ≤Ë°åÈÄ≤‰∏ÄÊ≠•ÁöÑÁ†îÁ©∂„ÄÇ

##### **Low-resource speech recognition and dialect identification of Irish in a multi-task framework**
2405.01293v1 by Liam Lonergan,Mengjie Qian,Neasa N√≠ Chiar√°in,Christer Gobl,Ailbhe N√≠ Chasaide

This paper explores the use of Hybrid CTC/Attention encoder-decoder models
trained with Intermediate CTC (InterCTC) for Irish (Gaelic) low-resource speech
recognition (ASR) and dialect identification (DID). Results are compared to the
current best performing models trained for ASR (TDNN-HMM) and DID (ECAPA-TDNN).
An optimal InterCTC setting is initially established using a Conformer encoder.
This setting is then used to train a model with an E-branchformer encoder and
the performance of both architectures are compared. A multi-task fine-tuning
approach is adopted for language model (LM) shallow fusion. The experiments
yielded an improvement in DID accuracy of 10.8% relative to a baseline
ECAPA-TDNN, and WER performance approaching the TDNN-HMM model. This multi-task
approach emerges as a promising strategy for Irish low-resource ASR and DID.

ÊëòË¶ÅÔºöÊú¨ÊñáÊé¢Ë®é‰ΩøÁî®Ê∑∑Âêà CTC/Ê≥®ÊÑèÂäõÁ∑®Á¢ºÂô®-Ëß£Á¢ºÂô®Ê®°ÂûãÔºå‰∏¶‰ΩøÁî®‰∏≠Èñì CTC (InterCTC) Ë®ìÁ∑¥ÊÑõÁàæËò≠Ë™û (ËìãÁàæË™û) ‰ΩéË≥áÊ∫êË™ûÈü≥Ëæ®Ë≠ò (ASR) ÂíåÊñπË®ÄËæ®Ë≠ò (DID)„ÄÇÂ∞áÁµêÊûúËàáÁõÆÂâçË®ìÁ∑¥ ASR (TDNN-HMM) Âíå DID (ECAPA-TDNN) ÁöÑÊúÄ‰Ω≥Ë°®ÁèæÊ®°ÂûãÈÄ≤Ë°åÊØîËºÉ„ÄÇÊúÄÂàù‰ΩøÁî® Conformer Á∑®Á¢ºÂô®Âª∫Á´ãÊúÄ‰Ω≥ InterCTC Ë®≠ÂÆö„ÄÇÁÑ∂Âæå‰ΩøÁî®Ê≠§Ë®≠ÂÆöË®ìÁ∑¥ÂÖ∑Êúâ E-branchformer Á∑®Á¢ºÂô®ÁöÑÊ®°ÂûãÔºå‰∏¶ÊØîËºÉÂÖ©Á®ÆÊû∂ÊßãÁöÑÊïàËÉΩ„ÄÇÊé°Áî®Â§ö‰ªªÂãôÂæÆË™øÊñπÊ≥ïÈÄ≤Ë°åË™ûË®ÄÊ®°Âûã (LM) Ê∑∫Â±§ËûçÂêà„ÄÇÂØ¶È©óÈ°ØÁ§∫ÔºåËàáÂü∫Ê∫ñ ECAPA-TDNN Áõ∏ÊØîÔºåDID Ê∫ñÁ¢∫Â∫¶ÊèêÂçá‰∫Ü 10.8%ÔºåËÄå WER ÊïàËÉΩÊé•Ëøë TDNN-HMM Ê®°Âûã„ÄÇÈÄôÁ®ÆÂ§ö‰ªªÂãôÊñπÊ≥ïÊàêÁÇ∫ÊÑõÁàæËò≠Ë™û‰ΩéË≥áÊ∫ê ASR Âíå DID ÁöÑ‰∏ÄÂÄãÊúâÂâçÈÄîÁöÑÁ≠ñÁï•„ÄÇ

##### **Reinforcement Learning for Edit-Based Non-Autoregressive Neural Machine Translation**
2405.01280v1 by Hao Wang,Tetsuro Morimura,Ukyo Honda,Daisuke Kawahara

Non-autoregressive (NAR) language models are known for their low latency in
neural machine translation (NMT). However, a performance gap exists between NAR
and autoregressive models due to the large decoding space and difficulty in
capturing dependency between target words accurately. Compounding this,
preparing appropriate training data for NAR models is a non-trivial task, often
exacerbating exposure bias. To address these challenges, we apply reinforcement
learning (RL) to Levenshtein Transformer, a representative edit-based NAR
model, demonstrating that RL with self-generated data can enhance the
performance of edit-based NAR models. We explore two RL approaches: stepwise
reward maximization and episodic reward maximization. We discuss the respective
pros and cons of these two approaches and empirically verify them. Moreover, we
experimentally investigate the impact of temperature setting on performance,
confirming the importance of proper temperature setting for NAR models'
training.

ÊëòË¶ÅÔºöÈùûËá™Ëø¥Ê≠∏ (NAR) Ë™ûË®ÄÊ®°Âûã‰ª•ÂÖ∂Âú®Á•ûÁ∂ìÊ©üÂô®ÁøªË≠Ø (NMT) ‰∏≠ÁöÑ‰ΩéÂª∂ÈÅ≤ËÄåËÅûÂêç„ÄÇÁÑ∂ËÄåÔºåÁî±ÊñºËß£Á¢ºÁ©∫ÈñìÂ§ß‰∏îÈõ£‰ª•Ê∫ñÁ¢∫ÊçïÊçâÁõÆÊ®ôË©û‰πãÈñìÁöÑ‰æùË≥¥Èóú‰øÇÔºåÂõ†Ê≠§ NAR ÂíåËá™Ëø¥Ê≠∏Ê®°Âûã‰πãÈñìÂ≠òÂú®ÊïàËÉΩÂ∑ÆË∑ù„ÄÇÊõ¥Ë§áÈõúÁöÑÊòØÔºåÁÇ∫ NAR Ê®°ÂûãÊ∫ñÂÇôÈÅ©Áï∂ÁöÑË®ìÁ∑¥Ë≥áÊñôÊòØ‰∏ÄÈ†ÖÈùûÂπ≥Âá°ÁöÑ‰ªªÂãôÔºåÈÄöÂ∏∏ÊúÉÂä†ÂäáÊö¥Èú≤ÂÅèÂ∑Æ„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÂ∞áÂº∑ÂåñÂ≠∏Áøí (RL) ÊáâÁî®Êñº Levenshtein TransformerÔºåÈÄôÊòØ‰∏ÄÂÄãÂü∫ÊñºÁ∑®ËºØÁöÑ NAR ‰ª£Ë°®Ê®°ÂûãÔºåË≠âÊòé‰ΩøÁî®Ëá™ÁîüË≥áÊñôÁöÑ RL ÂèØ‰ª•Â¢ûÂº∑Âü∫ÊñºÁ∑®ËºØÁöÑ NAR Ê®°ÂûãÁöÑÊïàËÉΩ„ÄÇÊàëÂÄëÊé¢Ë®éÂÖ©Á®Æ RL ÊñπÊ≥ïÔºöÈÄêÊ≠•ÁçéÂãµÊúÄÂ§ßÂåñÂíåÊÉÖÁØÄÁçéÂãµÊúÄÂ§ßÂåñ„ÄÇÊàëÂÄëË®éË´ñÈÄôÂÖ©Á®ÆÊñπÊ≥ïÂêÑËá™ÁöÑÂÑ™Áº∫ÈªûÔºå‰∏¶‰ª•Á∂ìÈ©óÈ©óË≠âÂÆÉÂÄë„ÄÇÊ≠§Â§ñÔºåÊàëÂÄë‰ª•ÂØ¶È©óÊñπÂºèÊé¢Ë®éÊ∫´Â∫¶Ë®≠ÂÆöÂ∞çÊïàËÉΩÁöÑÂΩ±ÈüøÔºåÁ¢∫Ë™çÈÅ©Áï∂Ê∫´Â∫¶Ë®≠ÂÆöÂ∞ç NAR Ê®°ÂûãË®ìÁ∑¥ÁöÑÈáçË¶ÅÊÄß„ÄÇ

##### **Towards Inclusive Face Recognition Through Synthetic Ethnicity Alteration**
2405.01273v1 by Praveen Kumar Chandaliya,Kiran Raja,Raghavendra Ramachandra,Zahid Akhtar,Christoph Busch

Numerous studies have shown that existing Face Recognition Systems (FRS),
including commercial ones, often exhibit biases toward certain ethnicities due
to under-represented data. In this work, we explore ethnicity alteration and
skin tone modification using synthetic face image generation methods to
increase the diversity of datasets. We conduct a detailed analysis by first
constructing a balanced face image dataset representing three ethnicities:
Asian, Black, and Indian. We then make use of existing Generative Adversarial
Network-based (GAN) image-to-image translation and manifold learning models to
alter the ethnicity from one to another. A systematic analysis is further
conducted to assess the suitability of such datasets for FRS by studying the
realistic skin-tone representation using Individual Typology Angle (ITA).
Further, we also analyze the quality characteristics using existing Face image
quality assessment (FIQA) approaches. We then provide a holistic FRS
performance analysis using four different systems. Our findings pave the way
for future research works in (i) developing both specific ethnicity and general
(any to any) ethnicity alteration models, (ii) expanding such approaches to
create databases with diverse skin tones, (iii) creating datasets representing
various ethnicities which further can help in mitigating bias while addressing
privacy concerns.

ÊëòË¶ÅÔºöË®±Â§öÁ†îÁ©∂È°ØÁ§∫ÁèæÊúâÁöÑËáâÈÉ®Ëæ®Ë≠òÁ≥ªÁµ± (FRS)ÔºåÂåÖÊã¨ÂïÜÊ•≠Á≥ªÁµ±ÔºåÂ∏∏Â∏∏Âõ†ÁÇ∫Ë≥áÊñô‰ª£Ë°®ÊÄß‰∏çË∂≥ËÄåÂ∞çÊüê‰∫õÁ®ÆÊóèÂ±ïÁèæÂÅèË¶ã„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊé¢Ë®é‰ΩøÁî®ÂêàÊàêËáâÈÉ®ÂΩ±ÂÉèÁî¢ÁîüÊñπÊ≥ïÈÄ≤Ë°åÁ®ÆÊóèÊîπËÆäÂíåËÜöËâ≤‰øÆÊîπÔºå‰ª•Â¢ûÂä†Ë≥áÊñôÈõÜÁöÑÂ§öÊ®£ÊÄß„ÄÇÊàëÂÄëÈ¶ñÂÖàÂª∫Êßã‰∏ÄÂÄãÂπ≥Ë°°ÁöÑËáâÈÉ®ÂΩ±ÂÉèË≥áÊñôÈõÜÔºå‰ª£Ë°®‰∏âÁ®ÆÁ®ÆÊóèÔºö‰∫ûÊ¥≤‰∫∫„ÄÅÈªë‰∫∫ÂíåÂç∞Â∫¶‰∫∫ÔºåÂÜçÈÄ≤Ë°åË©≥Á¥∞ÂàÜÊûê„ÄÇÁÑ∂ÂæåÊàëÂÄëÂà©Áî®ÁèæÊúâÁöÑÁîüÊàêÂ∞çÊäóÁ∂≤Ë∑Ø (GAN) ÂΩ±ÂÉèÂà∞ÂΩ±ÂÉèËΩâË≠ØÂíåÊµÅÂΩ¢Â≠∏ÁøíÊ®°Âûã‰æÜÂ∞áÁ®ÆÊóèÂæû‰∏ÄÁ®ÆÊîπËÆäÁÇ∫Âè¶‰∏ÄÁ®Æ„ÄÇÈÄ≤‰∏ÄÊ≠•ÈÄ≤Ë°åÁ≥ªÁµ±ÂàÜÊûêÔºå‰ΩøÁî®ÂÄãÂà•È°ûÂûãËßí (ITA) Á†îÁ©∂ÈÄºÁúüÁöÑËÜöËâ≤Ë°®ÁèæÔºå‰ª•Ë©ï‰º∞Ê≠§È°ûË≥áÊñôÈõÜÊòØÂê¶ÈÅ©Âêà FRS„ÄÇÊ≠§Â§ñÔºåÊàëÂÄë‰πü‰ΩøÁî®ÁèæÊúâÁöÑËáâÈÉ®ÂΩ±ÂÉèÂìÅË≥™Ë©ï‰º∞ (FIQA) ÊñπÊ≥ïÂàÜÊûêÂìÅË≥™ÁâπÂæµ„ÄÇÁÑ∂ÂæåÊàëÂÄë‰ΩøÁî®ÂõõÂÄã‰∏çÂêåÁöÑÁ≥ªÁµ±Êèê‰æõ‰∏ÄÂÄãÊï¥È´îÁöÑ FRS ÊïàËÉΩÂàÜÊûê„ÄÇÊàëÂÄëÁöÑÁôºÁèæÁÇ∫Êú™‰æÜÁöÑÁ†îÁ©∂Â∑•‰ΩúÈã™Ë∑ØÔºåÂåÖÊã¨Ôºö(i) ÈñãÁôºÁâπÂÆöÁ®ÆÊóèÂíå‰∏ÄËà¨ (‰ªª‰ΩïÂà∞‰ªª‰Ωï) Á®ÆÊóèÊîπËÆäÊ®°ÂûãÔºå(ii) Êì¥ÂÖÖÊ≠§È°ûÊñπÊ≥ï‰ª•Âª∫Á´ãÂÖ∑ÊúâÂ§öÊ®£ÂåñËÜöËâ≤ÁöÑË≥áÊñôÂ∫´Ôºå(iii) Âª∫Á´ã‰ª£Ë°®ÂêÑÁ®ÆÁ®ÆÊóèÁöÑË≥áÊñôÈõÜÔºåËÄåÈÄôÈÄ≤‰∏ÄÊ≠•ÊúâÂä©ÊñºÂú®ËôïÁêÜÈö±ÁßÅÂïèÈ°åÁöÑÂêåÊôÇÊ∏õËºïÂÅèË¶ã„ÄÇ

##### **MFTraj: Map-Free, Behavior-Driven Trajectory Prediction for Autonomous Driving**
2405.01266v1 by Haicheng Liao,Zhenning Li,Chengyue Wang,Huanming Shen,Bonan Wang,Dongping Liao,Guofa Li,Chengzhong Xu

This paper introduces a trajectory prediction model tailored for autonomous
driving, focusing on capturing complex interactions in dynamic traffic
scenarios without reliance on high-definition maps. The model, termed MFTraj,
harnesses historical trajectory data combined with a novel dynamic geometric
graph-based behavior-aware module. At its core, an adaptive structure-aware
interactive graph convolutional network captures both positional and behavioral
features of road users, preserving spatial-temporal intricacies. Enhanced by a
linear attention mechanism, the model achieves computational efficiency and
reduced parameter overhead. Evaluations on the Argoverse, NGSIM, HighD, and
MoCAD datasets underscore MFTraj's robustness and adaptability, outperforming
numerous benchmarks even in data-challenged scenarios without the need for
additional information such as HD maps or vectorized maps. Importantly, it
maintains competitive performance even in scenarios with substantial missing
data, on par with most existing state-of-the-art models. The results and
methodology suggest a significant advancement in autonomous driving trajectory
prediction, paving the way for safer and more efficient autonomous systems.

ÊëòË¶ÅÔºöÊú¨Êñá‰ªãÁ¥π‰∫Ü‰∏ÄÁ®ÆÈáùÂ∞çËá™ÂãïÈßïÈßõÈáèË∫´ÊâìÈÄ†ÁöÑËªåË∑°È†êÊ∏¨Ê®°ÂûãÔºåËëóÈáçÊñºÂú®ÂãïÊÖã‰∫§ÈÄöÂ†¥ÊôØ‰∏≠ÊçïÊçâË§áÈõúÁöÑ‰∫§‰∫í‰ΩúÁî®ÔºåËÄå‰∏ç‰æùË≥¥ÊñºÈ´òËß£ÊûêÂ∫¶Âú∞Âúñ„ÄÇË©≤Ê®°ÂûãÁ®±ÁÇ∫ MFTrajÔºåÂà©Áî®Ê≠∑Âè≤ËªåË∑°Êï∏ÊìöËàá‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÂãïÊÖãÂπæ‰ΩïÂúñÂΩ¢Ë°åÁÇ∫ÊÑüÁü•Ê®°ÁµÑ„ÄÇÂú®Ê†∏ÂøÉÈÉ®ÂàÜÔºå‰∏ÄÂÄãÈÅ©ÊáâÊÄßÁµêÊßãÊÑüÁü•‰∫íÂãïÂúñÂΩ¢Âç∑Á©çÁ∂≤Ë∑ØÊçïÊçâÈÅìË∑Ø‰ΩøÁî®ËÄÖÁöÑ‰ΩçÁΩÆÂíåË°åÁÇ∫ÁâπÂæµÔºå‰øùÁïôÊôÇÁ©∫Ë§áÈõúÊÄß„ÄÇË©≤Ê®°ÂûãÈÄèÈÅéÁ∑öÊÄßÊ≥®ÊÑèÂäõÊ©üÂà∂Â¢ûÂº∑ÔºåÂØ¶Áèæ‰∫ÜÈÅãÁÆóÊïàÁéá‰∏¶Ê∏õÂ∞ë‰∫ÜÂèÉÊï∏ÈñãÈä∑„ÄÇÂú® Argoverse„ÄÅNGSIM„ÄÅHighD Âíå MoCAD Ë≥áÊñôÈõÜ‰∏äÁöÑË©ï‰º∞Á™ÅÈ°Ø‰∫Ü MFTraj ÁöÑÁ©©ÂÅ•ÊÄßÂíåÈÅ©ÊáâÊÄßÔºåÂç≥‰ΩøÂú®Ë≥áÊñô‰∏çË∂≥ÁöÑÂ†¥ÊôØ‰∏≠ÔºåÂú®‰∏çÈúÄË¶Å HD Âú∞ÂúñÊàñÂêëÈáèÂú∞ÂúñÁ≠âÈ°çÂ§ñË≥áË®äÁöÑÊÉÖÊ≥Å‰∏ãÔºå‰πüÂÑ™ÊñºË®±Â§öÂü∫Ê∫ñ„ÄÇÈáçË¶ÅÁöÑÊòØÔºåÂç≥‰ΩøÂú®Áº∫Â∞ëÂ§ßÈáèË≥áÊñôÁöÑÂ†¥ÊôØ‰∏≠ÔºåÂÆÉ‰ªçËÉΩÁ∂≠ÊåÅÁ´∂Áà≠ÂäõÁöÑÊïàËÉΩÔºåËàáÁèæÊúâÊúÄÂÖàÈÄ≤ÁöÑÊ®°Âûã‰∏çÁõ∏‰∏ä‰∏ã„ÄÇÁµêÊûúÂíåÊñπÊ≥ïË°®ÊòéËá™ÂãïÈßïÈßõËªåË∑°È†êÊ∏¨Êúâ‰∫ÜÈ°ØËëóÁöÑÈÄ≤Ê≠•ÔºåÁÇ∫Êõ¥ÂÆâÂÖ®„ÄÅÊõ¥ÊúâÊïàÁéáÁöÑËá™ÂãïÁ≥ªÁµ±Èã™Âπ≥‰∫ÜÈÅìË∑Ø„ÄÇ

##### **Identification of Entailment and Contradiction Relations between Natural Language Sentences: A Neurosymbolic Approach**
2405.01259v1 by Xuyao Feng,Anthony Hunter

Natural language inference (NLI), also known as Recognizing Textual
Entailment (RTE), is an important aspect of natural language understanding.
Most research now uses machine learning and deep learning to perform this task
on specific datasets, meaning their solution is not explainable nor explicit.
To address the need for an explainable approach to RTE, we propose a novel
pipeline that is based on translating text into an Abstract Meaning
Representation (AMR) graph. For this we use a pre-trained AMR parser. We then
translate the AMR graph into propositional logic and use a SAT solver for
automated reasoning. In text, often commonsense suggests that an entailment (or
contradiction) relationship holds between a premise and a claim, but because
different wordings are used, this is not identified from their logical
representations. To address this, we introduce relaxation methods to allow
replacement or forgetting of some propositions. Our experimental results show
this pipeline performs well on four RTE datasets.

ÊëòË¶ÅÔºöËá™ÁÑ∂Ë™ûË®ÄÊé®Ë´ñ (NLI)Ôºå‰πüÁ®±ÁÇ∫Ë≠òÂà•ÊñáÊú¨ËòäÊ∂µ (RTE)ÔºåÊòØËá™ÁÑ∂Ë™ûË®ÄÁêÜËß£ÁöÑÈáçË¶ÅÈù¢Âêë„ÄÇ
ÁèæÂú®Â§ßÂ§öÊï∏Á†îÁ©∂ÈÉΩ‰ΩøÁî®Ê©üÂô®Â≠∏ÁøíÂíåÊ∑±Â∫¶Â≠∏Áøí‰æÜÂü∑Ë°åÁâπÂÆöË≥áÊñôÈõÜ‰∏äÁöÑÈÄôÈ†Ö‰ªªÂãôÔºåË°®Á§∫‰ªñÂÄëÁöÑËß£Ê±∫ÊñπÊ°àÊó¢ÁÑ°Ê≥ïËß£ÈáãÔºå‰πü‰∏çÊòéÁ¢∫„ÄÇ
ÁÇ∫‰∫ÜÊªøË∂≥ RTE ÂèØËß£ÈáãÊñπÊ≥ïÁöÑÈúÄÊ±ÇÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÂâµÊñ∞ÁöÑÁÆ°ÈÅìÔºåÂÖ∂Âü∫Á§éÊòØÂ∞áÊñáÂ≠óÁøªË≠ØÊàêÊäΩË±°ÊÑèÁæ©Ë°®Á§∫ (AMR) ÂúñÂΩ¢„ÄÇÊàëÂÄë‰ΩøÁî®È†êÂÖàË®ìÁ∑¥Â•ΩÁöÑ AMR ÂàÜÊûêÂô®‰æÜÂü∑Ë°åÈÄôÈ†Ö‰ªªÂãô„ÄÇÊé•ËëóÔºåÊàëÂÄëÂ∞á AMR ÂúñÂΩ¢ÁøªË≠ØÊàêÂëΩÈ°åÈÇèËºØÔºå‰∏¶‰ΩøÁî® SAT Ê±ÇËß£Âô®ÈÄ≤Ë°åËá™ÂãïÊé®ÁêÜ„ÄÇÂú®ÊñáÂ≠ó‰∏≠ÔºåÂ∏∏Ë≠òÈÄöÂ∏∏ÊúÉÊöóÁ§∫ÂâçÊèêÂíå‰∏ªÂºµ‰πãÈñìÂ≠òÂú®ËòäÊ∂µÔºàÊàñÁüõÁõæÔºâÈóú‰øÇÔºå‰ΩÜÁî±Êñº‰ΩøÁî®‰∫Ü‰∏çÂêåÁöÑÊé™Ëæ≠ÔºåÂõ†Ê≠§ÁÑ°Ê≥ïÂæûÂÖ∂ÈÇèËºØË°®Á§∫‰∏≠Ëæ®Ë≠òÂá∫‰æÜ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÂºïÈÄ≤ÊîæÈ¨ÜÊñπÊ≥ï‰æÜÂÖÅË®±ÊõøÊèõÊàñÈÅ∫Âøò‰∏Ä‰∫õÂëΩÈ°å„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÁµêÊûúÈ°ØÁ§∫ÔºåÈÄôÂÄãÁÆ°ÈÅìÂú®ÂõõÂÄã RTE Ë≥áÊñôÈõÜ‰∏äË°®ÁèæËâØÂ•Ω„ÄÇ

##### **Prompt engineering paradigms for medical applications: scoping review and recommendations for better practices**
2405.01249v1 by Jamil Zaghir,Marco Naguib,Mina Bjelogrlic,Aur√©lie N√©v√©ol,Xavier Tannier,Christian Lovis

Prompt engineering is crucial for harnessing the potential of large language
models (LLMs), especially in the medical domain where specialized terminology
and phrasing is used. However, the efficacy of prompt engineering in the
medical domain remains to be explored. In this work, 114 recent studies
(2022-2024) applying prompt engineering in medicine, covering prompt learning
(PL), prompt tuning (PT), and prompt design (PD) are reviewed. PD is the most
prevalent (78 articles). In 12 papers, PD, PL, and PT terms were used
interchangeably. ChatGPT is the most commonly used LLM, with seven papers using
it for processing sensitive clinical data. Chain-of-Thought emerges as the most
common prompt engineering technique. While PL and PT articles typically provide
a baseline for evaluating prompt-based approaches, 64% of PD studies lack
non-prompt-related baselines. We provide tables and figures summarizing
existing work, and reporting recommendations to guide future research
contributions.

ÊëòË¶ÅÔºöÊèêÁ§∫Â∑•Á®ãÂ∞çÊñºÁôºÊèÆÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊΩõÂäõËá≥ÈóúÈáçË¶ÅÔºåÁâπÂà•ÊòØÂú®‰ΩøÁî®Â∞àÊ•≠Ë°ìË™ûÂíåÊé™Ëæ≠ÁöÑÈÜ´ÁôÇÈ†òÂüü„ÄÇÁÑ∂ËÄåÔºåÊèêÁ§∫Â∑•Á®ãÂú®ÈÜ´ÁôÇÈ†òÂüüÁöÑÂäüÊïà‰ªçÊúâÂæÖÊé¢Ë®é„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÂõûÈ°ß‰∫Ü 114 ÁØáÊúÄËøëÁöÑÁ†îÁ©∂Ôºà2022-2024 Âπ¥ÔºâÔºåÈÄô‰∫õÁ†îÁ©∂Â∞áÊèêÁ§∫Â∑•Á®ãÊáâÁî®ÊñºÈÜ´Â≠∏ÔºåÊ∂µËìãÊèêÁ§∫Â≠∏Áøí (PL)„ÄÅÊèêÁ§∫Ë™øÊï¥ (PT) ÂíåÊèêÁ§∫Ë®≠Ë®à (PD)„ÄÇPD ÊúÄÁÇ∫ÊôÆÈÅçÔºà78 ÁØáÊñáÁ´†Ôºâ„ÄÇÂú® 12 ÁØáË´ñÊñá‰∏≠ÔºåPD„ÄÅPL Âíå PT Ë°ìË™ûÂèØ‰ª•‰∫íÊèõ‰ΩøÁî®„ÄÇChatGPT ÊòØ‰ΩøÁî®ÊúÄÂª£Ê≥õÁöÑ LLMÔºåÊúâ‰∏ÉÁØáË´ñÊñá‰ΩøÁî®ÂÆÉ‰æÜËôïÁêÜÊïèÊÑüÁöÑËá®Â∫äÊï∏Êìö„ÄÇÊÄùÊÉ≥ÈèàÊàêÁÇ∫ÊúÄÂ∏∏Ë¶ãÁöÑÊèêÁ§∫Â∑•Á®ãÊäÄË°ì„ÄÇÈõñÁÑ∂ PL Âíå PT ÊñáÁ´†ÈÄöÂ∏∏Êèê‰æõ‰∫Ü‰∏ÄÂÄãË©ï‰º∞Âü∫ÊñºÊèêÁ§∫ÁöÑÊñπÊ≥ïÁöÑÂü∫Ê∫ñÔºå‰ΩÜ 64% ÁöÑ PD Á†îÁ©∂Áº∫‰πèËàáÊèêÁ§∫ÁÑ°ÈóúÁöÑÂü∫Ê∫ñ„ÄÇÊàëÂÄëÊèê‰æõ‰∫ÜË°®Ê†ºÂíåÂúñÂΩ¢ÔºåÁ∏ΩÁµê‰∫ÜÁèæÊúâÂ∑•‰ΩúÔºå‰∏¶Â†±Âëä‰∫ÜÊåáÂ∞éÊú™‰æÜÁ†îÁ©∂Ë≤¢ÁçªÁöÑÂª∫Ë≠∞„ÄÇ

##### **TRAMBA: A Hybrid Transformer and Mamba Architecture for Practical Audio and Bone Conduction Speech Super Resolution and Enhancement on Mobile and Wearable Platforms**
2405.01242v1 by Yueyuan Sui,Minghui Zhao,Junxi Xia,Xiaofan Jiang,Stephen Xia

We propose TRAMBA, a hybrid transformer and Mamba architecture for acoustic
and bone conduction speech enhancement, suitable for mobile and wearable
platforms. Bone conduction speech enhancement has been impractical to adopt in
mobile and wearable platforms for several reasons: (i) data collection is
labor-intensive, resulting in scarcity; (ii) there exists a performance gap
between state of-art models with memory footprints of hundreds of MBs and
methods better suited for resource-constrained systems. To adapt TRAMBA to
vibration-based sensing modalities, we pre-train TRAMBA with audio speech
datasets that are widely available. Then, users fine-tune with a small amount
of bone conduction data. TRAMBA outperforms state-of-art GANs by up to 7.3% in
PESQ and 1.8% in STOI, with an order of magnitude smaller memory footprint and
an inference speed up of up to 465 times. We integrate TRAMBA into real systems
and show that TRAMBA (i) improves battery life of wearables by up to 160% by
requiring less data sampling and transmission; (ii) generates higher quality
voice in noisy environments than over-the-air speech; (iii) requires a memory
footprint of less than 20.0 MB.

ÊëòË¶ÅÔºöÊàëÂÄëÊèêÂá∫ TRAMBAÔºå‰∏ÄÁ®ÆÊ∑∑ÂêàTransformerÂíå Mamba Êû∂ÊßãÔºåÈÅ©Áî®ÊñºË°åÂãïÂíåÁ©øÊà¥ÂºèÂπ≥Âè∞ÁöÑËÅ≤Â≠∏ÂíåÈ™®ÂÇ≥Â∞éË™ûÈü≥Â¢ûÂº∑„ÄÇÈ™®ÂÇ≥Â∞éË™ûÈü≥Â¢ûÂº∑Âú®Ë°åÂãïÂíåÁ©øÊà¥ÂºèÂπ≥Âè∞‰∏≠‰∏çÂàáÂØ¶ÈöõÁöÑÂéüÂõ†ÊúâÂπæÂÄãÔºö(i) Ë≥áÊñôÊî∂ÈõÜÈúÄË¶ÅÂ§ßÈáè‰∫∫ÂäõÔºåÂ∞éËá¥Á®ÄÁº∫Ôºõ(ii) Ë®òÊÜ∂È´î‰ΩîÁî®ÈáèÈÅîÊï∏Áôæ MB ÁöÑÊúÄÂÖàÈÄ≤Ê®°ÂûãËàáÊõ¥ÈÅ©ÂêàÊñºË≥áÊ∫êÂèóÈôêÁ≥ªÁµ±ÁöÑÊñπÊ≥ï‰πãÈñìÂ≠òÂú®ÊïàËÉΩÂ∑ÆË∑ù„ÄÇÁÇ∫‰∫ÜËÆì TRAMBA ÈÅ©ÊáâÂü∫ÊñºÊåØÂãïÁöÑÊÑüÊ∏¨Ê®°ÂºèÔºåÊàëÂÄë‰ΩøÁî®Âª£Ê≥õÂèØÁî®ÁöÑÈü≥Ë®äË™ûÈü≥Ë≥áÊñôÈõÜÂ∞ç TRAMBA ÈÄ≤Ë°åÈ†êË®ìÁ∑¥„ÄÇÁÑ∂ÂæåÔºå‰ΩøÁî®ËÄÖ‰ΩøÁî®Â∞ëÈáèÈ™®ÂÇ≥Â∞éË≥áÊñôÈÄ≤Ë°åÂæÆË™ø„ÄÇTRAMBA Âú® PESQ ‰∏≠ÊØîÊúÄÂÖàÈÄ≤ÁöÑ GAN È´òÂá∫ 7.3%ÔºåÂú® STOI ‰∏≠È´òÂá∫ 1.8%Ôºå‰∏îË®òÊÜ∂È´î‰ΩîÁî®ÈáèÂ∞è‰∏ÄÂÄãÊï∏ÈáèÁ¥öÔºåÊé®ÁêÜÈÄüÂ∫¶ÊèêÈ´òÂ§öÈÅî 465 ÂÄç„ÄÇÊàëÂÄëÂ∞á TRAMBA Êï¥ÂêàÂà∞ÂØ¶ÈöõÁ≥ªÁµ±‰∏≠Ôºå‰∏¶Ë°®Êòé TRAMBA (i) ÈÄèÈÅéÊ∏õÂ∞ëË≥áÊñôÂèñÊ®£ÂíåÂÇ≥Ëº∏ÔºåÂ∞áÁ©øÊà¥ÂºèË£ùÁΩÆÁöÑÈõªÊ±†Á∫åËà™ÂäõÊèêÈ´òÂ§öÈÅî 160%Ôºõ(ii) Âú®ÂòàÈõúÁí∞Â¢É‰∏≠Áî¢ÁîüÊØîÁÑ°Á∑öË™ûÈü≥Êõ¥È´òÁöÑÈü≥Ë≥™Ôºõ(iii) Ë®òÊÜ∂È´î‰ΩîÁî®ÈáèÂ∞èÊñº 20.0 MB„ÄÇ

##### **Boosting Jailbreak Attack with Momentum**
2405.01229v1 by Yihao Zhang,Zeming Wei

Large Language Models (LLMs) have achieved remarkable success across diverse
tasks, yet they remain vulnerable to adversarial attacks, notably the
well-documented \textit{jailbreak} attack. Recently, the Greedy Coordinate
Gradient (GCG) attack has demonstrated efficacy in exploiting this
vulnerability by optimizing adversarial prompts through a combination of
gradient heuristics and greedy search. However, the efficiency of this attack
has become a bottleneck in the attacking process. To mitigate this limitation,
in this paper we rethink the generation of adversarial prompts through an
optimization lens, aiming to stabilize the optimization process and harness
more heuristic insights from previous iterations. Specifically, we introduce
the \textbf{M}omentum \textbf{A}ccelerated G\textbf{C}G (\textbf{MAC}) attack,
which incorporates a momentum term into the gradient heuristic. Experimental
results showcase the notable enhancement achieved by MAP in gradient-based
attacks on aligned language models. Our code is available at
https://github.com/weizeming/momentum-attack-llm.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®ÂêÑÁ®Æ‰ªªÂãô‰∏≠ÈÉΩÂèñÂæó‰∫ÜÈ°ØËëóÁöÑÊàêÂäüÔºå‰ΩÜÂÆÉÂÄë‰ªçÁÑ∂ÂÆπÊòìÂèóÂà∞Â∞çÊäóÊÄßÊîªÊìäÔºåÁâπÂà•ÊòØË®òÈåÑËâØÂ•ΩÁöÑ„ÄåË∂äÁçÑ„ÄçÊîªÊìä„ÄÇÊúÄËøëÔºåË≤™Â©™ÂùêÊ®ôÊ¢ØÂ∫¶ (GCG) ÊîªÊìäÂ∑≤Ë≠âÊòé‰∫ÜÂà©Áî®Ê≠§ÊºèÊ¥ûÁöÑÂäüÊïàÔºåÊñπÊ≥ïÊòØÈÄèÈÅéÁµêÂêàÊ¢ØÂ∫¶ÂïüÁôºÊ≥ïÂíåË≤™Â©™ÊêúÂ∞ã‰æÜÊúÄ‰Ω≥ÂåñÂ∞çÊäóÊÄßÊèêÁ§∫„ÄÇÁÑ∂ËÄåÔºåÊ≠§ÊîªÊìäÁöÑÊïàÁéáÂ∑≤ÊàêÁÇ∫ÊîªÊìäÈÅéÁ®ã‰∏≠ÁöÑ‰∏ÄÂÄãÁì∂È†∏„ÄÇÁÇ∫‰∫ÜÊ∏õËºïÊ≠§ÈôêÂà∂ÔºåÊàëÂÄëÂú®Êú¨Êñá‰∏≠ÈÄèÈÅéÊúÄ‰Ω≥ÂåñÈè°È†≠ÈáçÊñ∞ÊÄùËÄÉÂ∞çÊäóÊÄßÊèêÁ§∫ÁöÑÁî¢ÁîüÔºåÁõÆÊ®ôÊòØÁ©©ÂÆöÊúÄ‰Ω≥ÂåñÈÅéÁ®ã‰∏¶Âà©Áî®ÂÖàÂâçÂèçË¶ÜÈÅãÁÆóÁöÑÊõ¥Â§öÂïüÁôºÂºèË¶ãËß£„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü\textbf{M}omentum \textbf{A}ccelerated G\textbf{C}G (\textbf{MAC}) ÊîªÊìäÔºåÂÖ∂‰∏≠Â∞áÂãïÈáèÈ†ÖÁ¥çÂÖ•Ê¢ØÂ∫¶ÂïüÁôºÊ≥ï‰∏≠„ÄÇÂØ¶È©óÁµêÊûúÂ±ïÁ§∫‰∫Ü MAP Âú®Â∞çÈΩäË™ûË®ÄÊ®°ÂûãÁöÑÂü∫ÊñºÊ¢ØÂ∫¶ÁöÑÊîªÊìä‰∏≠ÊâÄÂèñÂæóÁöÑÈ°ØËëóÂ¢ûÂº∑„ÄÇÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÂèØÂú® https://github.com/weizeming/momentum-attack-llm ÂèñÂæó„ÄÇ

##### **DMON: A Simple yet Effective Approach for Argument Structure Learning**
2405.01216v1 by Wei Sun,Mingxiao Li,Jingyuan Sun,Jesse Davis,Marie-Francine Moens

Argument structure learning~(ASL) entails predicting relations between
arguments. Because it can structure a document to facilitate its understanding,
it has been widely applied in many fields~(medical, commercial, and scientific
domains). Despite its broad utilization, ASL remains a challenging task because
it involves examining the complex relationships between the sentences in a
potentially unstructured discourse. To resolve this problem, we have developed
a simple yet effective approach called Dual-tower Multi-scale cOnvolution
neural Network~(DMON) for the ASL task. Specifically, we organize arguments
into a relationship matrix that together with the argument embeddings forms a
relationship tensor and design a mechanism to capture relations with contextual
arguments. Experimental results on three different-domain argument mining
datasets demonstrate that our framework outperforms state-of-the-art models.
The code is available at https://github.com/VRCMF/DMON.git .

ÊëòË¶ÅÔºöË´ñË≠âÁµêÊßãÂ≠∏Áøí (ASL) Ê∂âÂèäÈ†êÊ∏¨Ë´ñË≠â‰πãÈñìÁöÑÈóú‰øÇ„ÄÇÁî±ÊñºÂÆÉÂèØ‰ª•ÁÇ∫Êñá‰ª∂Âª∫ÊßãÁµêÊßã‰ª•Âà©ÊñºÁêÜËß£ÔºåÂõ†Ê≠§Â∑≤Âª£Ê≥õÊáâÁî®ÊñºË®±Â§öÈ†òÂüüÔºàÈÜ´ÁôÇ„ÄÅÂïÜÊ•≠ÂíåÁßëÂ≠∏È†òÂüüÔºâ„ÄÇÂÑòÁÆ° ASL Ë¢´Âª£Ê≥õ‰ΩøÁî®Ôºå‰ΩÜÂÆÉ‰ªçÁÑ∂ÊòØ‰∏ÄÈ†ÖÂÖ∑ÊúâÊåëÊà∞ÊÄßÁöÑ‰ªªÂãôÔºåÂõ†ÁÇ∫ÂÆÉÊ∂âÂèäÊ™¢Êü•ÊΩõÂú®ÈùûÁµêÊßãÂåñË©±Ë™û‰∏≠Âè•Â≠ê‰πãÈñìÁöÑË§áÈõúÈóú‰øÇ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÈñãÁôº‰∫Ü‰∏ÄÁ®ÆÁ∞°ÂñÆ‰ΩÜÊúâÊïàÁöÑÊñπÊ≥ïÔºåÁ®±ÁÇ∫ ASL ‰ªªÂãôÁöÑÈõôÂ°îÂ§öÂ∞∫Â∫¶Âç∑Á©çÁ•ûÁ∂ìÁ∂≤Ë∑Ø (DMON)„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÂ∞áË´ñË≠âÁµÑÁπîÊàê‰∏ÄÂÄãÈóú‰øÇÁü©Èô£ÔºåË©≤Áü©Èô£ËàáË´ñË≠âÂµåÂÖ•‰∏ÄËµ∑ÂΩ¢Êàê‰∏ÄÂÄãÈóú‰øÇÂºµÈáèÔºå‰∏¶Ë®≠Ë®à‰∏ÄÁ®ÆÊ©üÂà∂‰æÜÊçïÊçâËàá‰∏ä‰∏ãÊñáË´ñË≠âÁöÑÈóú‰øÇ„ÄÇÂú®‰∏âÂÄã‰∏çÂêåÈ†òÂüüÁöÑË´ñË≠âÊåñÊéòË≥áÊñôÈõÜ‰∏äÁöÑÂØ¶È©óÁµêÊûúË°®ÊòéÔºåÊàëÂÄëÁöÑÊ°ÜÊû∂ÂÑ™ÊñºÊúÄÂÖàÈÄ≤ÁöÑÊ®°Âûã„ÄÇÁ®ãÂºèÁ¢ºÂèØÂú® https://github.com/VRCMF/DMON.git ÂèñÂæó„ÄÇ

##### **Towards Interpretable Reinforcement Learning with Constrained Normalizing Flow Policies**
2405.01198v1 by Finn Rietz,Erik Schaffernicht,Stefan Heinrich,Johannes A. Stork

Reinforcement learning policies are typically represented by black-box neural
networks, which are non-interpretable and not well-suited for safety-critical
domains. To address both of these issues, we propose constrained normalizing
flow policies as interpretable and safe-by-construction policy models. We
achieve safety for reinforcement learning problems with instantaneous safety
constraints, for which we can exploit domain knowledge by analytically
constructing a normalizing flow that ensures constraint satisfaction. The
normalizing flow corresponds to an interpretable sequence of transformations on
action samples, each ensuring alignment with respect to a particular
constraint. Our experiments reveal benefits beyond interpretability in an
easier learning objective and maintained constraint satisfaction throughout the
entire learning process. Our approach leverages constraints over reward
engineering while offering enhanced interpretability, safety, and direct means
of providing domain knowledge to the agent without relying on complex reward
functions.

ÊëòË¶ÅÔºöÂº∑ÂåñÂ≠∏ÁøíÊîøÁ≠ñÈÄöÂ∏∏Áî±ÈªëÁõíÂ≠êÁ•ûÁ∂ìÁ∂≤Ë∑ØË°®Á§∫ÔºåÂÆÉÂÄë‰∏çÂèØËß£Èáã‰∏î‰∏çÈÅ©ÂêàÊñºÂÆâÂÖ®Ëá≥‰∏äÁöÑÈ†òÂüü„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÖ©ÂÄãÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫ÂèóÁ¥ÑÊùüÁöÑÊ≠£Ë¶èÂåñÊµÅÂãïÊîøÁ≠ñÔºå‰ΩúÁÇ∫ÂèØËß£Èáã‰∏îÂÆâÂÖ®‰∏îÂª∫ÊßãÊîøÁ≠ñÊ®°Âûã„ÄÇÊàëÂÄëÈáùÂ∞çÂÖ∑ÊúâÂç≥ÊôÇÂÆâÂÖ®Á¥ÑÊùüÁöÑÂº∑ÂåñÂ≠∏ÁøíÂïèÈ°åÂØ¶Áèæ‰∫ÜÂÆâÂÖ®ÊÄßÔºåÊàëÂÄëÂèØ‰ª•ÈÄèÈÅéÂàÜÊûêÂª∫Êßã‰∏ÄÂÄãÊ≠£Ë¶èÂåñÊµÅÂãï‰æÜÂà©Áî®È†òÂüüÁü•Ë≠òÔºå‰ª•Á¢∫‰øùÁ¥ÑÊùüÊªøË∂≥„ÄÇÊ≠£Ë¶èÂåñÊµÅÂãïÂ∞çÊáâÊñº‰ΩúÁî®Ê®£Êú¨‰∏äÁöÑ‰∏ÄÁ≥ªÂàóÂèØËß£ÈáãËΩâÊèõÔºåÊØèÂÄãËΩâÊèõÁ¢∫‰øùÁõ∏Â∞çÊñºÁâπÂÆöÁ¥ÑÊùüÁöÑ‰∏ÄËá¥ÊÄß„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÊè≠Á§∫‰∫ÜÂèØËß£ÈáãÊÄß‰ª•Â§ñÁöÑÂ•ΩËôïÔºåÂú®ÊñºÊõ¥ÂÆπÊòìÁöÑÂ≠∏ÁøíÁõÆÊ®ôÔºå‰∏¶Âú®Êï¥ÂÄãÂ≠∏ÁøíÈÅéÁ®ã‰∏≠Á∂≠ÊåÅÁ¥ÑÊùüÊªøË∂≥„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÂà©Áî®‰∫ÜÁçéÂãµÂ∑•Á®ã‰∏äÁöÑÁ¥ÑÊùüÔºåÂêåÊôÇÊèê‰æõ‰∫ÜÂ¢ûÂº∑ÁöÑÂèØËß£ÈáãÊÄß„ÄÅÂÆâÂÖ®ÊÄßÔºå‰ª•ÂèäÂú®‰∏ç‰æùË≥¥ÊñºË§áÈõúÁçéÂãµÂáΩÊï∏ÁöÑÊÉÖÊ≥Å‰∏ãÂêë‰ª£ÁêÜÊèê‰æõÈ†òÂüüÁü•Ë≠òÁöÑÁõ¥Êé•ÊñπÊ≥ï„ÄÇ

##### **Gradient-Congruity Guided Federated Sparse Training**
2405.01189v1 by Chris Xing Tian,Yibing Liu,Haoliang Li,Ray C. C. Cheung,Shiqi Wang

Edge computing allows artificial intelligence and machine learning models to
be deployed on edge devices, where they can learn from local data and
collaborate to form a global model. Federated learning (FL) is a distributed
machine learning technique that facilitates this process while preserving data
privacy. However, FL also faces challenges such as high computational and
communication costs regarding resource-constrained devices, and poor
generalization performance due to the heterogeneity of data across edge clients
and the presence of out-of-distribution data. In this paper, we propose the
Gradient-Congruity Guided Federated Sparse Training (FedSGC), a novel method
that integrates dynamic sparse training and gradient congruity inspection into
federated learning framework to address these issues. Our method leverages the
idea that the neurons, in which the associated gradients with conflicting
directions with respect to the global model contain irrelevant or less
generalized information for other clients, and could be pruned during the
sparse training process. Conversely, the neurons where the associated gradients
with consistent directions could be grown in a higher priority. In this way,
FedSGC can greatly reduce the local computation and communication overheads
while, at the same time, enhancing the generalization abilities of FL. We
evaluate our method on challenging non-i.i.d settings and show that it achieves
competitive accuracy with state-of-the-art FL methods across various scenarios
while minimizing computation and communication costs.

ÊëòË¶ÅÔºöÈÇäÁ∑£ÈÅãÁÆóËÆì‰∫∫Â∑•Êô∫ÊÖßÂíåÊ©üÂô®Â≠∏ÁøíÊ®°ÂûãËÉΩÂ§†ÈÉ®ÁΩ≤Âú®ÈÇäÁ∑£Ë£ùÁΩÆ‰∏äÔºåÂú®ÈÇäÁ∑£Ë£ùÁΩÆ‰∏äÔºåÂÆÉÂÄëÂèØ‰ª•ÂæûÂú®Âú∞Ë≥áÊñô‰∏≠Â≠∏ÁøíÔºå‰∏¶Âçî‰ΩúÂΩ¢Êàê‰∏ÄÂÄãÂÖ®ÁêÉÊ®°Âûã„ÄÇËÅØÈÇ¶Â≠∏Áøí (FL) ÊòØ‰∏ÄÁ®ÆÂàÜÊï£ÂºèÊ©üÂô®Â≠∏ÁøíÊäÄË°ìÔºåÂú®Á∂≠Ë≠∑Ë≥áÊñôÈö±ÁßÅÁöÑÂêåÊôÇ‰øÉÈÄ≤ÈÄôÂÄãÈÅéÁ®ã„ÄÇÁÑ∂ËÄåÔºåFL ‰πüÈù¢Ëá®ÊåëÊà∞Ôºå‰æãÂ¶ÇÂú®Ë≥áÊ∫êÂèóÈôêÁöÑË£ùÁΩÆ‰∏äÔºåÈ´òÈÅãÁÆóÂíåÈÄöË®äÊàêÊú¨Ôºå‰ª•ÂèäÁî±ÊñºÈÇäÁ∑£Áî®Êà∂Á´ØË≥áÊñôÁï∞Ë≥™ÊÄßÂíåÂ≠òÂú®ÂàÜÂ∏ÉÂ§ñË≥áÊñôÔºåËÄåÂ∞éËá¥ÁöÑÊ¶ÇÂåñÊïàËÉΩ‰∏ç‰Ω≥„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫Ê¢ØÂ∫¶ÂêåË≥™ÊÄßÂºïÂ∞éÁöÑËÅØÈÇ¶Á®ÄÁñèË®ìÁ∑¥ (FedSGC)ÔºåÈÄôÊòØ‰∏ÄÁ®ÆÊñ∞ÁöÑÊñπÊ≥ïÔºåÂ∞áÂãïÊÖãÁ®ÄÁñèË®ìÁ∑¥ÂíåÊ¢ØÂ∫¶ÂêåË≥™ÊÄßÊ™¢Êü•Êï¥ÂêàÂà∞ËÅØÈÇ¶Â≠∏ÁøíÊû∂Êßã‰∏≠Ôºå‰ª•Ëß£Ê±∫ÈÄô‰∫õÂïèÈ°å„ÄÇÊàëÂÄëÁöÑÊñπÊ≥ïÂà©Áî®‰∫ÜÈÄôÊ®£‰∏ÄÂÄãÊÉ≥Ê≥ïÔºöËàáÁõ∏Â∞çÊñºÂÖ®ÁêÉÊ®°ÂûãÂÖ∑ÊúâË°ùÁ™ÅÊñπÂêëÁöÑÊ¢ØÂ∫¶Áõ∏ÈóúÁöÑÁ•ûÁ∂ìÂÖÉÔºåÂåÖÂê´ËàáÂÖ∂‰ªñÁî®Êà∂Á´ØÁÑ°ÈóúÊàñÊ¶ÇÂåñÁ®ãÂ∫¶ËºÉ‰ΩéÁöÑ‰ø°ÊÅØÔºå‰∏¶‰∏îÂèØ‰ª•Âú®Á®ÄÁñèË®ìÁ∑¥ÈÅéÁ®ã‰∏≠Ë¢´Ââ™Êûù„ÄÇÁõ∏ÂèçÔºåËàá‰∏ÄËá¥ÊñπÂêëÁõ∏ÈóúÁöÑÁ•ûÁ∂ìÂÖÉÂèØ‰ª•ÂÑ™ÂÖàÂ¢ûÈï∑„ÄÇÈÄôÊ®£ÔºåFedSGC ÂèØ‰ª•Â§ßÂπÖÊ∏õÂ∞ëÂú®Âú∞ÈÅãÁÆóÂíåÈÄöË®äÈñãÈä∑ÔºåÂêåÊôÇÂ¢ûÂº∑ FL ÁöÑÊ¶ÇÂåñËÉΩÂäõ„ÄÇÊàëÂÄëÂú®ÂÖ∑ÊúâÊåëÊà∞ÊÄßÁöÑÈùûÁç®Á´ãÂêåÂàÜÂ∏ÉË®≠ÂÆö‰∏äË©ï‰º∞ÊàëÂÄëÁöÑÊñπÊ≥ïÔºå‰∏¶Â±ïÁ§∫ÂÆÉÂú®ÂêÑÁ®ÆÂ†¥ÊôØ‰∏≠‰ª•ÊúÄÂÖàÈÄ≤ÁöÑ FL ÊñπÊ≥ïÁç≤ÂæóÁ´∂Áà≠ÂÑ™Âã¢ÁöÑÊ∫ñÁ¢∫ÊÄßÔºåÂêåÊôÇÂ∞áÈÅãÁÆóÂíåÈÄöË®äÊàêÊú¨ÈôçËá≥ÊúÄ‰Ωé„ÄÇ

##### **Potential Energy based Mixture Model for Noisy Label Learning**
2405.01186v1 by Zijia Wang,Wenbin Yang,Zhisong Liu,Zhen Jia

Training deep neural networks (DNNs) from noisy labels is an important and
challenging task. However, most existing approaches focus on the corrupted
labels and ignore the importance of inherent data structure. To bridge the gap
between noisy labels and data, inspired by the concept of potential energy in
physics, we propose a novel Potential Energy based Mixture Model (PEMM) for
noise-labels learning. We innovate a distance-based classifier with the
potential energy regularization on its class centers. Embedding our proposed
classifier with existing deep learning backbones, we can have robust networks
with better feature representations. They can preserve intrinsic structures
from the data, resulting in a superior noisy tolerance. We conducted extensive
experiments to analyze the efficiency of our proposed model on several
real-world datasets. Quantitative results show that it can achieve
state-of-the-art performance.

ÊëòË¶ÅÔºöÂæûÊúâÈõúË®äÁöÑÊ®ôÁ±§Ë®ìÁ∑¥Ê∑±Â∫¶Á•ûÁ∂ìÁ∂≤Ë∑Ø (DNN) ÊòØ‰∏ÄÈ†ÖÈáçË¶Å‰∏îÂÖ∑ÊåëÊà∞ÊÄßÁöÑ‰ªªÂãô„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÁöÑÊñπÊ≥ïÂ§ßÂ§öËëóÈáçÊñºÊêçÂ£ûÁöÑÊ®ôÁ±§ÔºåËÄåÂøΩÁï•‰∫ÜÂÖßÂú®Ë≥áÊñôÁµêÊßãÁöÑÈáçË¶ÅÊÄß„ÄÇÁÇ∫‰∫ÜÂΩåË£úÊúâÈõúË®äÁöÑÊ®ôÁ±§ËàáË≥áÊñô‰πãÈñìÁöÑÂ∑ÆË∑ùÔºåÊàëÂÄëÂèóÂà∞Áâ©ÁêÜÂ≠∏‰∏≠‰ΩçËÉΩÊ¶ÇÂøµÁöÑÂïüÁôºÔºåÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂü∫Êñº‰ΩçËÉΩÁöÑÊ∑∑ÂêàÊ®°Âûã (PEMM)ÔºåÁî®ÊñºÈõúË®äÊ®ôÁ±§Â≠∏Áøí„ÄÇÊàëÂÄëÂâµÊñ∞‰∫Ü‰∏ÄÂÄãÂü∫ÊñºË∑ùÈõ¢ÁöÑÂàÜÈ°ûÂô®ÔºåÂÖ∂È°ûÂà•‰∏≠ÂøÉÂÖ∑Êúâ‰ΩçËÉΩÊ≠£ÂâáÂåñ„ÄÇÂ∞áÊàëÂÄëÊèêÂá∫ÁöÑÂàÜÈ°ûÂô®ÂµåÂÖ•ÁèæÊúâÁöÑÊ∑±Â∫¶Â≠∏Áøí‰∏ªÂππÔºåÊàëÂÄëÂèØ‰ª•Áç≤ÂæóÂÖ∑ÊúâÊõ¥Â•ΩÁâπÂæµË°®Á§∫ÁöÑÁ©©ÂÅ•Á∂≤Ë∑Ø„ÄÇÂÆÉÂÄëÂèØ‰ª•‰øùÁïôË≥áÊñô‰∏≠ÁöÑÂÖßÂú®ÁµêÊßãÔºåÂæûËÄåÁî¢ÁîüÂÑ™Áï∞ÁöÑÈõúË®äÂÆπÂøçÂ∫¶„ÄÇÊàëÂÄëÈÄ≤Ë°å‰∫ÜÂ§ßÈáèÁöÑÂØ¶È©óÔºå‰ª•ÂàÜÊûêÊàëÂÄëÊèêÂá∫ÁöÑÊ®°ÂûãÂú®Â§öÂÄãÁúüÂØ¶‰∏ñÁïåË≥áÊñôÈõÜ‰∏äÁöÑÊïàÁéá„ÄÇÂÆöÈáèÁµêÊûúË°®ÊòéÔºåÂÆÉÂèØ‰ª•ÈÅîÂà∞ÊúÄÂÖàÈÄ≤ÁöÑÊïàËÉΩ„ÄÇ

##### **Uncertainty-aware self-training with expectation maximization basis transformation**
2405.01175v1 by Zijia Wang,Wenbin Yang,Zhisong Liu,Zhen Jia

Self-training is a powerful approach to deep learning. The key process is to
find a pseudo-label for modeling. However, previous self-training algorithms
suffer from the over-confidence issue brought by the hard labels, even some
confidence-related regularizers cannot comprehensively catch the uncertainty.
Therefore, we propose a new self-training framework to combine uncertainty
information of both model and dataset. Specifically, we propose to use
Expectation-Maximization (EM) to smooth the labels and comprehensively estimate
the uncertainty information. We further design a basis extraction network to
estimate the initial basis from the dataset. The obtained basis with
uncertainty can be filtered based on uncertainty information. It can then be
transformed into the real hard label to iteratively update the model and basis
in the retraining process. Experiments on image classification and semantic
segmentation show the advantages of our methods among confidence-aware
self-training algorithms with 1-3 percentage improvement on different datasets.

ÊëòË¶ÅÔºöËá™Ë®ìÁ∑¥ÊòØÊ∑±Â∫¶Â≠∏ÁøíÁöÑ‰∏ÄÁ®ÆÂº∑Â§ßÊñπÊ≥ï„ÄÇÈóúÈçµÈÅéÁ®ãÊòØÊâæÂà∞‰∏ÄÂÄãÊì¨Ê®ôÁ±§ÈÄ≤Ë°åÂª∫Ê®°„ÄÇÁÑ∂ËÄåÔºåÂÖàÂâçÁöÑËá™Ë®ìÁ∑¥ÊºîÁÆóÊ≥ïÊúÉÂèóÂà∞Á°¨Ê®ôÁ±§Â∏∂‰æÜÁöÑÈÅéÂ∫¶Ëá™‰ø°ÂïèÈ°åÔºåÂç≥‰ΩøÊòØ‰∏Ä‰∫õËàá‰ø°ÂøÉÁõ∏ÈóúÁöÑÊ≠£ÂâáÂåñÈ†Ö‰πüÁÑ°Ê≥ïÂÖ®Èù¢ÊçïÊçâ‰∏çÁ¢∫ÂÆöÊÄß„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÊñ∞ÁöÑËá™Ë®ìÁ∑¥Êû∂Êßã‰æÜÁµêÂêàÊ®°ÂûãÂíåË≥áÊñôÈõÜÁöÑ‰∏çÁ¢∫ÂÆöÊÄßË≥áË®ä„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÂª∫Ë≠∞‰ΩøÁî®ÊúüÊúõÊúÄÂ§ßÂåñ (EM) ‰æÜÂπ≥ÊªëÊ®ôÁ±§‰∏¶ÂÖ®Èù¢‰º∞Ë®à‰∏çÁ¢∫ÂÆöÊÄßË≥áË®ä„ÄÇÊàëÂÄëÈÄ≤‰∏ÄÊ≠•Ë®≠Ë®à‰∏ÄÂÄãÂü∫Á§éÊèêÂèñÁ∂≤Ë∑ØÔºåÂæûË≥áÊñôÈõÜ‰º∞Ë®àÂàùÂßãÂü∫Á§é„ÄÇÁç≤ÂæóÁöÑ‰∏çÁ¢∫ÂÆöÊÄßÂü∫Á§éÂèØ‰ª•Ê†πÊìö‰∏çÁ¢∫ÂÆöÊÄßË≥áË®äÈÄ≤Ë°åÈÅéÊøæ„ÄÇÁÑ∂ÂæåÂèØ‰ª•Â∞áÂÖ∂ËΩâÊèõÁÇ∫ÁúüÊ≠£ÁöÑÁ°¨Ê®ôÁ±§Ôºå‰ª•Âú®ÈáçÊñ∞Ë®ìÁ∑¥ÈÅéÁ®ã‰∏≠ÂèçË¶ÜÊõ¥Êñ∞Ê®°ÂûãÂíåÂü∫Á§é„ÄÇÂú®ÂΩ±ÂÉèÂàÜÈ°ûÂíåË™ûÊÑèÂàÜÂâ≤‰∏äÁöÑÂØ¶È©óÈ°ØÁ§∫‰∫ÜÊàëÂÄëÁöÑÊºîÁÆóÊ≥ïÂú®‰∏çÂêåÁöÑË≥áÊñôÈõÜ‰∏äÊØîÊúâ‰ø°ÂøÉÊÑüÁü•ÁöÑËá™Ë®ìÁ∑¥ÊºîÁÆóÊ≥ïÊúâ 1-3 ÂÄãÁôæÂàÜÈªûÁöÑÂÑ™Âã¢„ÄÇ

##### **TartuNLP at EvaLatin 2024: Emotion Polarity Detection**
2405.01159v1 by Aleksei Dorkin,Kairit Sirts

This paper presents the TartuNLP team submission to EvaLatin 2024 shared task
of the emotion polarity detection for historical Latin texts. Our system relies
on two distinct approaches to annotating training data for supervised learning:
1) creating heuristics-based labels by adopting the polarity lexicon provided
by the organizers and 2) generating labels with GPT4. We employed parameter
efficient fine-tuning using the adapters framework and experimented with both
monolingual and cross-lingual knowledge transfer for training language and task
adapters. Our submission with the LLM-generated labels achieved the overall
first place in the emotion polarity detection task. Our results show that
LLM-based annotations show promising results on texts in Latin.

ÊëòË¶ÅÔºöÊú¨Êñá‰ªãÁ¥π‰∫Ü TartuNLP ÂúòÈöäÂú® 2024 Âπ¥ EvaLatin ÂÖ±‰∫´‰ªªÂãô‰∏≠Êèê‰∫§ÁöÑÊ≠∑Âè≤Êãâ‰∏ÅË™ûÊñáÊú¨ÁöÑÊÉÖÁ∑íÊ•µÊÄßÂÅµÊ∏¨„ÄÇÊàëÂÄëÁöÑÁ≥ªÁµ±‰æùË≥¥ÊñºÂÖ©Á®Æ‰∏çÂêåÁöÑÊñπÊ≥ï‰æÜË®ªÈáãÁõ£Áù£ÂºèÂ≠∏ÁøíÁöÑË®ìÁ∑¥Ë≥áÊñôÔºö1) Êé°Áî®ÁµÑÁπîËÄÖÊèê‰æõÁöÑÊ•µÊÄßË©ûÂΩôË°®‰æÜÂª∫Á´ãÂü∫ÊñºÂïüÁôºÊ≥ïÁöÑÊ®ôÁ±§Ôºå‰ª•Âèä 2) ‰ΩøÁî® GPT4 Áî¢ÁîüÊ®ôÁ±§„ÄÇÊàëÂÄë‰ΩøÁî®ÈÅ©ÈÖçÂô®Êû∂ÊßãÈÄ≤Ë°å‰∫ÜÂèÉÊï∏ÊúâÊïàÁöÑÂæÆË™øÔºå‰∏¶ÈáùÂ∞çË®ìÁ∑¥Ë™ûË®ÄÂíå‰ªªÂãôÈÅ©ÈÖçÂô®ÈÄ≤Ë°å‰∫ÜÂñÆË™ûÂíåË∑®Ë™ûË®ÄÁü•Ë≠òËΩâÁßªÁöÑÂØ¶È©ó„ÄÇÊàëÂÄë‰ΩøÁî® LLM ÁîüÊàêÁöÑÊ®ôÁ±§ÊâÄÊèê‰∫§ÁöÑÂÖßÂÆπÂú®ÊÉÖÁ∑íÊ•µÊÄßÂÅµÊ∏¨‰ªªÂãô‰∏≠Áç≤Âæó‰∫ÜÁ∏ΩÈ´îÁ¨¨‰∏ÄÂêç„ÄÇÊàëÂÄëÁöÑÁµêÊûúË°®ÊòéÔºåÂü∫Êñº LLM ÁöÑË®ªÈáãÂú®Êãâ‰∏ÅË™ûÊñáÊú¨‰∏≠È°ØÁ§∫Âá∫ÊúâÂ∏åÊúõÁöÑÁµêÊûú„ÄÇ

##### **Interpretable Data-driven Anomaly Detection in Industrial Processes with ExIFFI**
2405.01158v1 by Davide Frizzo,Francesco Borsatti,Alessio Arcudi,Antonio De Moliner,Roberto Oboe,Gian Antonio Susto

Anomaly detection (AD) is a crucial process often required in industrial
settings. Anomalies can signal underlying issues within a system, prompting
further investigation. Industrial processes aim to streamline operations as
much as possible, encompassing the production of the final product, making AD
an essential mean to reach this goal.Conventional anomaly detection
methodologies typically classify observations as either normal or anomalous
without providing insight into the reasons behind these
classifications.Consequently, in light of the emergence of Industry 5.0, a more
desirable approach involves providing interpretable outcomes, enabling users to
understand the rationale behind the results.This paper presents the first
industrial application of ExIFFI, a recently developed approach focused on the
production of fast and efficient explanations for the Extended Isolation Forest
(EIF) Anomaly detection method. ExIFFI is tested on two publicly available
industrial datasets demonstrating superior effectiveness in explanations and
computational efficiency with the respect to other state-of-the-art explainable
AD models.

ÊëòË¶ÅÔºöÁï∞Â∏∏ÂÅµÊ∏¨ (AD) ÊòØ‰∏ÄÂÄãÂú®Â∑•Ê•≠Áí∞Â¢É‰∏≠Á∂ìÂ∏∏ÈúÄË¶ÅÁöÑÈóúÈçµÁ®ãÂ∫è„ÄÇÁï∞Â∏∏ÂèØ‰ª•Ë°®Á§∫Á≥ªÁµ±ÂÖßÊΩõÂú®ÁöÑÂïèÈ°åÔºåÈÄ≤ËÄåÊèêÁ§∫ÈÄ≤‰∏ÄÊ≠•Ë™øÊü•„ÄÇÂ∑•Ê•≠Á®ãÂ∫èÊó®Âú®Áõ°ÂèØËÉΩÁ∞°Âåñ‰ΩúÊ•≠ÔºåÂåÖÂê´ÊúÄÁµÇÁî¢ÂìÅÁöÑÁîüÁî¢Ôºå‰ΩøÁï∞Â∏∏ÂÅµÊ∏¨ÊàêÁÇ∫ÈÅîÊàêÊ≠§ÁõÆÊ®ôÁöÑÂøÖË¶ÅÊâãÊÆµ„ÄÇÂÇ≥Áµ±ÁöÑÁï∞Â∏∏ÂÅµÊ∏¨ÊñπÊ≥ïÈÄöÂ∏∏Â∞áËßÄÊ∏¨ÂÄºÂàÜÈ°ûÁÇ∫Ê≠£Â∏∏ÊàñÁï∞Â∏∏ÔºåËÄå‰∏çÊúÉÊèê‰æõÈÄô‰∫õÂàÜÈ°ûËÉåÂæåÁöÑÂéüÂõ†„ÄÇÂõ†Ê≠§ÔºåÈëëÊñºÂ∑•Ê•≠ 5.0 ÁöÑÂá∫ÁèæÔºå‰∏ÄÂÄãÊõ¥ÁêÜÊÉ≥ÁöÑÊñπÊ≥ïÊòØÊèê‰æõÂèØËß£ÈáãÁöÑÁµêÊûúÔºåËÆì‰ΩøÁî®ËÄÖ‰∫ÜËß£ÁµêÊûúËÉåÂæåÁöÑÁêÜÁî±„ÄÇÊú¨ÊñáÊèêÂá∫ ExIFFI ÁöÑÁ¨¨‰∏ÄÂÄãÂ∑•Ê•≠ÊáâÁî®ÔºåExIFFI ÊòØ‰∏ÄÂÄãÊúÄËøëÈñãÁôºÁöÑÊñπÊ≥ïÔºåÂ∞àÊ≥®ÊñºÁÇ∫Âª∂‰º∏ÈöîÈõ¢Ê£ÆÊûó (EIF) Áï∞Â∏∏ÂÅµÊ∏¨ÊñπÊ≥ïÁî¢ÁîüÂø´ÈÄü‰∏îÊúâÊïàÁöÑËß£Èáã„ÄÇExIFFI Âú®ÂÖ©ÂÄãÂÖ¨ÈñãÂèØÁî®ÁöÑÂ∑•Ê•≠Ë≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÊ∏¨Ë©¶ÔºåË≠âÊòéÂÖ∂Âú®Ëß£ÈáãÂíåÈÅãÁÆóÊïàÁéáÊñπÈù¢ÂÑ™ÊñºÂÖ∂‰ªñÊúÄÂÖàÈÄ≤ÁöÑÂèØËß£ÈáãÁï∞Â∏∏ÂÅµÊ∏¨Ê®°Âûã„ÄÇ

##### **Self-Supervised Learning for Interventional Image Analytics: Towards Robust Device Trackers**
2405.01156v1 by Saahil Islam,Venkatesh N. Murthy,Dominik Neumann,Badhan Kumar Das,Puneet Sharma,Andreas Maier,Dorin Comaniciu,Florin C. Ghesu

An accurate detection and tracking of devices such as guiding catheters in
live X-ray image acquisitions is an essential prerequisite for endovascular
cardiac interventions. This information is leveraged for procedural guidance,
e.g., directing stent placements. To ensure procedural safety and efficacy,
there is a need for high robustness no failures during tracking. To achieve
that, one needs to efficiently tackle challenges, such as: device obscuration
by contrast agent or other external devices or wires, changes in field-of-view
or acquisition angle, as well as the continuous movement due to cardiac and
respiratory motion. To overcome the aforementioned challenges, we propose a
novel approach to learn spatio-temporal features from a very large data cohort
of over 16 million interventional X-ray frames using self-supervision for image
sequence data. Our approach is based on a masked image modeling technique that
leverages frame interpolation based reconstruction to learn fine inter-frame
temporal correspondences. The features encoded in the resulting model are
fine-tuned downstream. Our approach achieves state-of-the-art performance and
in particular robustness compared to ultra optimized reference solutions (that
use multi-stage feature fusion, multi-task and flow regularization). The
experiments show that our method achieves 66.31% reduction in maximum tracking
error against reference solutions (23.20% when flow regularization is used);
achieving a success score of 97.95% at a 3x faster inference speed of 42
frames-per-second (on GPU). The results encourage the use of our approach in
various other tasks within interventional image analytics that require
effective understanding of spatio-temporal semantics.

ÊëòË¶ÅÔºö<paragraph>Âú®ÂØ¶ÊôÇ X ÂÖâÂΩ±ÂÉèÊì∑Âèñ‰∏≠Á≤æÊ∫ñÂÅµÊ∏¨ÂíåËøΩËπ§Â∞éÁÆ°Á≠âË£ùÁΩÆÊòØÂøÉË°ÄÁÆ°ÂÖß‰ªãÂÖ•ÊÄßÊ≤ªÁôÇÁöÑÂü∫Êú¨ÂÖàÊ±∫Ê¢ù‰ª∂„ÄÇÈÄô‰∫õË≥áË®äÂèØÁî®ÊñºÁ®ãÂ∫èÊåáÂ∞éÔºå‰æãÂ¶ÇÂºïÂ∞éÊîØÊû∂ÊîæÁΩÆ„ÄÇÁÇ∫‰∫ÜÁ¢∫‰øùÁ®ãÂ∫èÂÆâÂÖ®ÊÄßÂíåÊúâÊïàÊÄßÔºåËøΩËπ§ÈÅéÁ®ã‰∏≠ÈúÄË¶ÅÊ•µÈ´òÁöÑÁ©©ÂÅ•ÊÄßÔºå‰∏çËÉΩÁôºÁîüÊïÖÈöú„ÄÇÁÇ∫Ê≠§ÔºåÈúÄË¶ÅÊúâÊïàÊáâÂ∞çÊåëÊà∞Ôºå‰æãÂ¶ÇÔºöÂ∞çÊØîÂäëÊàñÂÖ∂‰ªñÂ§ñÈÉ®Ë£ùÁΩÆÊàñÂ∞éÁ∑öÈÅÆËîΩË£ùÁΩÆ„ÄÅË¶ñÈáéÊàñÊì∑ÂèñËßíÂ∫¶ÊîπËÆäÔºå‰ª•ÂèäÁî±ÊñºÂøÉËáüÂíåÂëºÂê∏ÈÅãÂãïÂ∞éËá¥ÁöÑÊåÅÁ∫åÁßªÂãï„ÄÇÁÇ∫‰∫ÜÂÖãÊúç‰∏äËø∞ÊåëÊà∞ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞ÊñπÊ≥ïÔºåÂæûË∂ÖÈÅé 1600 Ëê¨ÂÄã‰ªãÂÖ•ÊÄß X ÂÖâÂΩ±ÂÉèÂ∫èÂàóË≥áÊñôÁöÑÊ•µÂ§ßË≥áÊñôÁæ§ÈõÜ‰∏≠Â≠∏ÁøíÊôÇÁ©∫ÁâπÂæµÔºå‰∏¶‰ΩøÁî®ÂΩ±ÂÉèÂ∫èÂàóË≥áÊñôÁöÑËá™Áõ£Áù£„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÂü∫ÊñºÈÅÆÁΩ©ÂΩ±ÂÉèÂª∫Ê®°ÊäÄË°ìÔºåË©≤ÊäÄË°ìÂà©Áî®Âü∫ÊñºÊèíÂÄºÁöÑÈáçÂª∫‰æÜÂ≠∏ÁøíÁ≤æÁ¥∞ÁöÑÂπÄÈñìÊôÇÊÖãÂ∞çÊáâ„ÄÇÁ∑®Á¢ºÂú®ÁµêÊûúÊ®°Âûã‰∏≠ÁöÑÁâπÂæµÊúÉÂú®ÂæåÁ∫åÈÄ≤Ë°åÂæÆË™ø„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÈÅîÂà∞‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÊïàËÉΩÔºåÁâπÂà•ÊòØËàáÁ∂ìÈÅéÈ´òÂ∫¶ÊúÄ‰Ω≥ÂåñÁöÑÂèÉËÄÉËß£Ê±∫ÊñπÊ°àÔºà‰ΩøÁî®Â§öÈöéÊÆµÁâπÂæµËûçÂêà„ÄÅÂ§ö‰ªªÂãôÂíåÊµÅÂãïÊ≠£Ë¶èÂåñÔºâÁõ∏ÊØîÔºåÂÖ∑ÊúâÊõ¥È´òÁöÑÁ©©ÂÅ•ÊÄß„ÄÇÂØ¶È©óË°®ÊòéÔºåÊàëÂÄëÁöÑÊñπÊ≥ïÂ∞áÊúÄÂ§ßËøΩËπ§Ë™§Â∑ÆÈôç‰Ωé‰∫Ü 66.31%ÔºåÁõ∏ËºÉÊñºÂèÉËÄÉËß£Ê±∫ÊñπÊ°àÔºà‰ΩøÁî®ÊµÅÂãïÊ≠£Ë¶èÂåñÊôÇÁÇ∫ 23.20%ÔºâÔºõÂú® 42 ÂπÄ/ÁßíÔºàÂú® GPU ‰∏äÔºâÁöÑ 3 ÂÄçÊé®ÁêÜÈÄüÂ∫¶‰∏ãÔºåÊàêÂäüÁéáÈÅîÂà∞ 97.95%„ÄÇÈÄô‰∫õÁµêÊûúÈºìÂãµÂú®‰ªãÂÖ•ÊÄßÂΩ±ÂÉèÂàÜÊûêÁöÑÂêÑÁ®ÆÂÖ∂‰ªñ‰ªªÂãô‰∏≠‰ΩøÁî®ÊàëÂÄëÁöÑÂÅöÊ≥ïÔºåÈÄô‰∫õ‰ªªÂãôÈúÄË¶ÅÊúâÊïàÁêÜËß£ÊôÇÁ©∫Ë™ûÁæ©„ÄÇ</paragraph>

##### **Qualia and the Formal Structure of Meaning**
2405.01148v1 by Xerxes D. Arsiwalla

This work explores the hypothesis that subjectively attributed meaning
constitutes the phenomenal content of conscious experience. That is, phenomenal
content is semantic. This form of subjective meaning manifests as an intrinsic
and non-representational character of qualia. Empirically, subjective meaning
is ubiquitous in conscious experiences. We point to phenomenological studies
that lend evidence to support this. Furthermore, this notion of meaning closely
relates to what Frege refers to as "sense", in metaphysics and philosophy of
language. It also aligns with Peirce's "interpretant", in semiotics. We discuss
how Frege's sense can also be extended to the raw feels of consciousness. Sense
and reference both play a role in phenomenal experience. Moreover, within the
context of the mind-matter relation, we provide a formalization of subjective
meaning associated to one's mental representations. Identifying the precise
maps between the physical and mental domains, we argue that syntactic and
semantic structures transcend language, and are realized within each of these
domains. Formally, meaning is a relational attribute, realized via a map that
interprets syntactic structures of a formal system within an appropriate
semantic space. The image of this map within the mental domain is what is
relevant for experience, and thus comprises the phenomenal content of qualia.
We conclude with possible implications this may have for experience-based
theories of consciousness.

ÊëòË¶ÅÔºöÊú¨Á†îÁ©∂Êé¢Ë®é‰∫Ü‰∏ªËßÄË≥¶‰∫àÊÑèÁæ©ÁöÑÂÅáË®≠ÊßãÊàêÊÑèË≠òÁ∂ìÈ©óÁöÑÁèæË±°ÂÖßÂÆπ„ÄÇ‰∫¶Âç≥ÔºåÁèæË±°ÂÖßÂÆπÂÖ∑ÊúâË™ûÊÑèÊÄß„ÄÇÈÄôÁ®ÆÂΩ¢ÂºèÁöÑ‰∏ªËßÄÊÑèÁæ©Ë°®ÁèæÁÇ∫ÊÑüË¶∫ÁöÑÂÖßÂú®‰∏îÈùûË°®ÂæµÊÄßÁöÑÁâπÂæµ„ÄÇÁ∂ìÈ©ó‰∏äÔºå‰∏ªËßÄÊÑèÁæ©ÊôÆÈÅçÂ≠òÂú®ÊñºÊÑèË≠òÁ∂ìÈ©ó‰∏≠„ÄÇÊàëÂÄëÊåáÂá∫ÁèæË±°Â≠∏Á†îÁ©∂Êèê‰æõ‰∫ÜÊîØÊåÅÊ≠§Ë´ñÈªûÁöÑË≠âÊìö„ÄÇÊ≠§Â§ñÔºåÊ≠§ÊÑèÁæ©Ê¶ÇÂøµËàáÂºóÈõ∑Ê†ºÂú®ÂΩ¢‰∏äÂ≠∏ÂíåË™ûË®ÄÂì≤Â≠∏‰∏≠ÊâÄÊåáÁöÑ„ÄåÊÑèÁæ©„ÄçÂØÜÂàáÁõ∏Èóú„ÄÇÂÆÉ‰πüËàáÁöÆÁàæÊñØÁöÑÁ¨¶ËôüÂ≠∏‰∏≠ÁöÑ„ÄåË©ÆÈáãÈ†Ö„ÄçÁõ∏Á¨¶„ÄÇÊàëÂÄëË®éË´ñ‰∫ÜÂºóÈõ∑Ê†ºÁöÑÊÑèÁæ©Â¶Ç‰Ωï‰πüËÉΩÂª∂‰º∏Ëá≥ÊÑèË≠òÁöÑÂéüÂßãÊÑüÂèó„ÄÇÊÑèÁæ©ÂíåÊåáÊ∂âÂú®ÁèæË±°Á∂ìÈ©ó‰∏≠ÈÉΩÊâÆÊºîËëóËßíËâ≤„ÄÇÊ≠§Â§ñÔºåÂú®ÂøÉÁâ©Èóú‰øÇÁöÑËÑàÁµ°‰∏≠ÔºåÊàëÂÄëÊèê‰æõ‰∫ÜËàáÂÄã‰∫∫ÂøÉÊô∫Ë°®ÂæµÁõ∏ÈóúÁöÑ‰∏ªËßÄÊÑèÁæ©ÁöÑÂΩ¢ÂºèÂåñ„ÄÇÈÄèÈÅéËæ®Ë≠òÁâ©ÁêÜÂíåÂøÉÊô∫È†òÂüü‰πãÈñìÁ≤æÁ¢∫ÁöÑÂ∞çÊáâÔºåÊàëÂÄë‰∏ªÂºµË™ûÊ≥ïÂíåË™ûÁæ©ÁµêÊßãË∂ÖË∂äË™ûË®ÄÔºå‰∏¶Âú®ÈÄô‰∫õÈ†òÂüü‰∏≠ÂØ¶Áèæ„ÄÇÂΩ¢Âºè‰∏äÔºåÊÑèÁæ©ÊòØ‰∏ÄÁ®ÆÈóú‰øÇÂ±¨ÊÄßÔºåÈÄèÈÅé‰∏ÄÂÄãÂ∞çÊáâÂØ¶ÁèæÔºåÊ≠§Â∞çÊáâÂú®ÈÅ©Áï∂ÁöÑË™ûÁæ©Á©∫Èñì‰∏≠Ë©ÆÈáãÂΩ¢ÂºèÁ≥ªÁµ±ÁöÑË™ûÊ≥ïÁµêÊßã„ÄÇÊ≠§Â∞çÊáâÂú®ÂøÉÊô∫È†òÂüü‰∏≠ÁöÑÂΩ±ÂÉèËàáÁ∂ìÈ©óÁõ∏ÈóúÔºåÂõ†Ê≠§ÊßãÊàêÊÑüË¶∫ÁöÑÁèæË±°ÂÖßÂÆπ„ÄÇÊàëÂÄë‰ª•ÈÄôÂèØËÉΩÂ∞çÂü∫ÊñºÁ∂ìÈ©óÁöÑÊÑèË≠òÁêÜË´ñÈÄ†ÊàêÁöÑÂΩ±Èüø‰ΩúÁÇ∫ÁµêË´ñ„ÄÇ

##### **It Couldn't Help But Overhear: On the Limits of Modelling Meta-Communicative Grounding Acts with Supervised Learning**
2405.01139v1 by Brielen Madureira,David Schlangen

Active participation in a conversation is key to building common ground,
since understanding is jointly tailored by producers and recipients.
Overhearers are deprived of the privilege of performing grounding acts and can
only conjecture about intended meanings. Still, data generation and annotation,
modelling, training and evaluation of NLP dialogue models place reliance on the
overhearing paradigm. How much of the underlying grounding processes are
thereby forfeited? As we show, there is evidence pointing to the impossibility
of properly modelling human meta-communicative acts with data-driven learning
models. In this paper, we discuss this issue and provide a preliminary analysis
on the variability of human decisions for requesting clarification. Most
importantly, we wish to bring this topic back to the community's table,
encouraging discussion on the consequences of having models designed to only
"listen in".

ÊëòË¶ÅÔºöÁ©çÊ•µÂèÉËàáÂ∞çË©±ÊòØÂª∫Á´ãÂÖ±Ë≠òÁöÑÈóúÈçµÔºå
Âõ†ÁÇ∫ÁêÜËß£ÊòØÁî±ÁîüÁî¢ËÄÖÂíåÊé•Êî∂ËÄÖÂÖ±ÂêåË™øÊï¥ÁöÑ„ÄÇ
ÊóÅËÅΩËÄÖË¢´ÂâùÂ•™‰∫ÜÂü∑Ë°åÂü∫Á§éË°åÁÇ∫ÁöÑÁâπÊ¨äÔºåÂè™ËÉΩÁåúÊ∏¨È†êÊúüÁöÑÂê´Áæ©„ÄÇÂÑòÁÆ°Â¶ÇÊ≠§ÔºåÊï∏ÊìöÁîüÊàêÂíåË®ªËß£„ÄÅ
NLP Â∞çË©±Ê®°ÂûãÁöÑÂª∫Ê®°„ÄÅË®ìÁ∑¥ÂíåË©ï‰º∞‰æùË≥¥ÊñºÊóÅËÅΩÁØÑÂºè„ÄÇÊúâÂ§öÂ∞ëÂü∫Á§éÈÅéÁ®ãË¢´
Âõ†Ê≠§Ê≤íÊî∂ÔºüÊ≠£Â¶ÇÊàëÂÄëÊâÄÂ±ïÁ§∫ÁöÑÔºåÊúâË≠âÊìöË°®Êòé‰∏çÂèØËÉΩ‰ΩøÁî®Êï∏ÊìöÈ©ÖÂãïÂ≠∏Áøí
Ê®°ÂûãÊ≠£Á¢∫Âú∞Âª∫Ê®°‰∫∫È°ûÂÖÉÊ∫ùÈÄöË°åÁÇ∫„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëË®éË´ñ‰∫ÜÈÄôÂÄãÂïèÈ°åÔºå‰∏¶Êèê‰æõ‰∫Ü‰∏ÄÂÄãÂàùÊ≠•ÂàÜÊûê
ÈóúÊñº‰∫∫È°ûË´ãÊ±ÇÊæÑÊ∏ÖÊ±∫Á≠ñÁöÑÂèØËÆäÊÄß„ÄÇÊúÄÈáçË¶ÅÁöÑÊòØÔºåÊàëÂÄëÂ∏åÊúõÂ∞áÈÄôÂÄãË©±È°åÂ∏∂ÂõûÁ§æÂçÄÁöÑÈ§êÊ°å‰∏äÔºå
ÈºìÂãµË®éË´ñÂÉÖ„ÄåËÅÜËÅΩ„ÄçÁöÑÊ®°ÂûãÁöÑÂæåÊûú„ÄÇ

##### **Efficient Data Generation for Source-grounded Information-seeking Dialogs: A Use Case for Meeting Transcripts**
2405.01121v1 by Lotem Golany,Filippo Galgani,Maya Mamo,Nimrod Parasol,Omer Vandsburger,Nadav Bar,Ido Dagan

Existing methods for creating source-grounded information-seeking dialog
datasets are often costly and hard to implement due to their sole reliance on
human annotators. We propose combining large language models (LLMs) prompting
with human expertise for more efficient and reliable data generation. Instead
of the labor-intensive Wizard-of-Oz (WOZ) method, where two annotators generate
a dialog from scratch, role-playing agent and user, we use LLM generation to
simulate the two roles. Annotators then verify the output and augment it with
attribution data. We demonstrate our method by constructing MISeD -- Meeting
Information Seeking Dialogs dataset -- the first information-seeking dialog
dataset focused on meeting transcripts. Models finetuned with MISeD demonstrate
superior performance on our test set, as well as on a novel fully-manual WOZ
test set and an existing query-based summarization benchmark, suggesting the
utility of our approach.

ÊëòË¶ÅÔºöÁèæÊúâÂª∫Á´ãÂü∫Êñº‰æÜÊ∫êË≥áË®äÂ∞ãÊ±ÇÂ∞çË©±Ë≥áÊñôÈõÜÁöÑÊñπÊ≥ïÔºåÈÄöÂ∏∏ÊàêÊú¨È´òÊòÇ‰∏îÈõ£‰ª•ÂØ¶‰ΩúÔºåÂõ†ÁÇ∫ÂÆÉÂÄëÂÆåÂÖ®‰æùË≥¥‰∫∫Â∑•Ë®ªËß£„ÄÇÊàëÂÄëÂª∫Ë≠∞ÁµêÂêàÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÊèêÁ§∫Âíå‰∫∫È°ûÂ∞àÊ•≠Áü•Ë≠òÔºå‰ª•Êõ¥ÊúâÊïàÁéá‰∏îÂèØÈù†Âú∞Áî¢ÁîüË≥áÊñô„ÄÇÊàëÂÄë‰ΩøÁî® LLM Áî¢Áîü‰æÜÊ®°Êì¨ÂÖ©ÂÄãËßíËâ≤ÔºåËÄå‰∏çÊòØÂãûÂäõÂØÜÈõÜÁöÑÁ∂†Èáé‰ªôËπ§ (WOZ) ÊñπÊ≥ïÔºåÂÖ∂‰∏≠ÂÖ©ÂÄãË®ªËß£ËÄÖÂæûÈ†≠ÈñãÂßãÁî¢ÁîüÂ∞çË©±ÔºåÊâÆÊºî‰ª£ÁêÜÂíå‰ΩøÁî®ËÄÖÁöÑËßíËâ≤„ÄÇÁÑ∂ÂæåÔºåË®ªËß£ËÄÖÈ©óË≠âËº∏Âá∫Ôºå‰∏¶‰ΩøÁî®Ê≠∏Âõ†Ë≥áÊñôÊì¥ÂÖÖÂÆÉ„ÄÇÊàëÂÄëÈÄèÈÅéÂª∫Êßã MISeDÔºàÊúÉË≠∞Ë≥áË®äÂ∞ãÊ±ÇÂ∞çË©±Ë≥áÊñôÈõÜÔºâ‰æÜÂ±ïÁ§∫ÊàëÂÄëÁöÑÈÄôÈ†ÖÊñπÊ≥ïÔºåÈÄôÊòØÁ¨¨‰∏ÄÂÄãÂ∞àÊ≥®ÊñºÊúÉË≠∞Á¥ÄÈåÑÁöÑË≥áË®äÂ∞ãÊ±ÇÂ∞çË©±Ë≥áÊñôÈõÜ„ÄÇ‰ΩøÁî® MISeD ÂæÆË™øÁöÑÊ®°ÂûãÂú®ÊàëÂÄëÁöÑÊ∏¨Ë©¶ÈõÜ‰∏äÂ±ïÁèæÂá∫ÂÑ™Áï∞ÊïàËÉΩÔºå‰ª•ÂèäÂú®Êñ∞ÁöÑÂÆåÂÖ®ÊâãÂãï WOZ Ê∏¨Ë©¶ÈõÜÂíåÁèæÊúâÁöÑÂü∫ÊñºÊü•Ë©¢ÁöÑÊëòË¶ÅÂü∫Ê∫ñ‰∏äÔºåÈÄôË°®Á§∫ÊàëÂÄëÊñπÊ≥ïÁöÑÊïàÁî®„ÄÇ

##### **Domain-Transferred Synthetic Data Generation for Improving Monocular Depth Estimation**
2405.01113v1 by Seungyeop Lee,Knut Peterson,Solmaz Arezoomandan,Bill Cai,Peihan Li,Lifeng Zhou,David Han

A major obstacle to the development of effective monocular depth estimation
algorithms is the difficulty in obtaining high-quality depth data that
corresponds to collected RGB images. Collecting this data is time-consuming and
costly, and even data collected by modern sensors has limited range or
resolution, and is subject to inconsistencies and noise. To combat this, we
propose a method of data generation in simulation using 3D synthetic
environments and CycleGAN domain transfer. We compare this method of data
generation to the popular NYUDepth V2 dataset by training a depth estimation
model based on the DenseDepth structure using different training sets of real
and simulated data. We evaluate the performance of the models on newly
collected images and LiDAR depth data from a Husky robot to verify the
generalizability of the approach and show that GAN-transformed data can serve
as an effective alternative to real-world data, particularly in depth
estimation.

ÊëòË¶ÅÔºöÂñÆÁõÆÊ∑±Â∫¶‰º∞Ë®àÊºîÁÆóÊ≥ïÁôºÂ±ïÁöÑ‰∏ªË¶ÅÈöúÁ§ôÂú®ÊñºÈõ£‰ª•ÂèñÂæóËàáÊî∂ÈõÜÂà∞ÁöÑ RGB ÂΩ±ÂÉèÁõ∏Á¨¶ÁöÑÈ´òÂìÅË≥™Ê∑±Â∫¶Ë≥áÊñô„ÄÇÊî∂ÈõÜÊ≠§Ë≥áÊñôËÄóÊôÇ‰∏îÊòÇË≤¥ÔºåËÄå‰∏îÂç≥‰ΩøÊòØÁèæ‰ª£ÊÑüÊ∏¨Âô®Êî∂ÈõÜÁöÑË≥áÊñô‰πüÊúâÁØÑÂúçÊàñËß£ÊûêÂ∫¶ÈôêÂà∂Ôºå‰∏îÂÆπÊòìÂá∫Áèæ‰∏ç‰∏ÄËá¥ÊÄßÂíåÈõúË®ä„ÄÇÁÇ∫‰∫ÜËß£Ê±∫Ê≠§ÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰ΩøÁî® 3D ÂêàÊàêÁí∞Â¢ÉÂíå CycleGAN È†òÂüüËΩâÁßªÈÄ≤Ë°åÊ®°Êì¨Ë≥áÊñôÁîüÊàêÁöÑÊñπÊ≥ï„ÄÇÊàëÂÄëÂ∞áÊ≠§Ë≥áÊñôÁîüÊàêÊñπÊ≥ïËàáÂª£Ê≥õ‰ΩøÁî®ÁöÑ NYUDepth V2 Ë≥áÊñôÈõÜÈÄ≤Ë°åÊØîËºÉÔºåÊñπÊ≥ïÊòØ‰ΩøÁî®‰∏çÂêåÁöÑÁúüÂØ¶ÂíåÊ®°Êì¨Ë≥áÊñôË®ìÁ∑¥ÁµÑ‰æÜË®ìÁ∑¥Âü∫Êñº DenseDepth ÁµêÊßãÁöÑÊ∑±Â∫¶‰º∞Ë®àÊ®°Âûã„ÄÇÊàëÂÄëÂú® Husky Ê©üÂô®‰∫∫Êñ∞Êî∂ÈõÜÁöÑÂΩ±ÂÉèÂíå LiDAR Ê∑±Â∫¶Ë≥áÊñô‰∏äË©ï‰º∞Ê®°ÂûãÁöÑÊïàËÉΩÔºå‰ª•È©óË≠âÊ≠§ÊñπÊ≥ïÁöÑÂèØÊ¶ÇÂåñÊÄßÔºå‰∏¶È°ØÁ§∫ GAN ËΩâÊèõË≥áÊñôÂèØ‰ª•Áî®‰ΩúÁúüÂØ¶‰∏ñÁïåË≥áÊñôÁöÑÊúâÊïàÊõø‰ª£ÊñπÊ°àÔºåÁâπÂà•ÊòØÂú®Ê∑±Â∫¶‰º∞Ë®àÊñπÈù¢„ÄÇ

##### **Federated Learning with Heterogeneous Data Handling for Robust Vehicular Object Detection**
2405.01108v1 by Ahmad Khalil,Tizian Dege,Pegah Golchin,Rostyslav Olshevskyi,Antonio Fernandez Anta,Tobias Meuser

In the pursuit of refining precise perception models for fully autonomous
driving, continual online model training becomes essential. Federated Learning
(FL) within vehicular networks offers an efficient mechanism for model training
while preserving raw sensory data integrity. Yet, FL struggles with
non-identically distributed data (e.g., quantity skew), leading to suboptimal
convergence rates during model training. In previous work, we introduced FedLA,
an innovative Label-Aware aggregation method addressing data heterogeneity in
FL for generic scenarios.
  In this paper, we introduce FedProx+LA, a novel FL method building upon the
state-of-the-art FedProx and FedLA to tackle data heterogeneity, which is
specifically tailored for vehicular networks. We evaluate the efficacy of
FedProx+LA in continuous online object detection model training. Through a
comparative analysis against conventional and state-of-the-art methods, our
findings reveal the superior convergence rate of FedProx+LA. Notably, if the
label distribution is very heterogeneous, our FedProx+LA approach shows
substantial improvements in detection performance compared to baseline methods,
also outperforming our previous FedLA approach. Moreover, both FedLA and
FedProx+LA increase convergence speed by 30% compared to baseline methods.

ÊëòË¶ÅÔºöÂú®ËøΩÊ±ÇÁ≤æÈÄ≤ÂÖ®Ëá™ÂãïÈßïÈßõÁöÑÁ≤æÁ¢∫ÊÑüÁü•Ê®°ÂûãÊôÇÔºåÊåÅÁ∫åÁöÑÁ∑ö‰∏äÊ®°ÂûãË®ìÁ∑¥ËÆäÂæóËá≥ÈóúÈáçË¶Å„ÄÇËªäËºõÁ∂≤Ë∑Ø‰∏≠ÁöÑËÅØÂêàÂ≠∏Áøí (FL) Êèê‰æõ‰∫Ü‰∏ÄÁ®ÆÊúâÊïàÁéáÁöÑÊ®°ÂûãË®ìÁ∑¥Ê©üÂà∂ÔºåÂêåÊôÇ‰øùÁïôÂéüÂßãÊÑüÊ∏¨Ë≥áÊñôÁöÑÂÆåÊï¥ÊÄß„ÄÇÁÑ∂ËÄåÔºåFL Âú®ÈùûÁõ∏ÂêåÂàÜ‰ΩàË≥áÊñôÔºà‰æãÂ¶ÇÔºåÊï∏ÈáèÂÅèÂ∑ÆÔºâ‰∏äÊúÉÈÅáÂà∞Âõ∞Èõ£ÔºåÂ∞éËá¥Ê®°ÂûãË®ìÁ∑¥ÊúüÈñìÊ¨°‰Ω≥ÁöÑÊî∂ÊñÇÁéá„ÄÇÂú®ÂÖàÂâçÁöÑÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü FedLAÔºåÈÄôÊòØ‰∏ÄÁ®ÆÂâµÊñ∞ÁöÑÊ®ôÁ±§ÊÑüÁü•ËÅöÂêàÊñπÊ≥ïÔºåÁî®ÊñºËß£Ê±∫ FL Âú®‰∏ÄËà¨Â†¥ÊôØ‰∏≠ÁöÑË≥áÊñôÁï∞Ë≥™ÊÄßÂïèÈ°å„ÄÇ
  Âú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü FedProx+LAÔºåÈÄôÊòØ‰∏ÄÁ®ÆÊñ∞Á©éÁöÑ FL ÊñπÊ≥ïÔºåÂª∫Á´ãÂú®ÁèæÊúâÊäÄË°ì FedProx Âíå FedLA ÁöÑÂü∫Á§é‰∏äÔºåÁî®ÊñºËß£Ê±∫Ë≥áÊñôÁï∞Ë≥™ÊÄßÂïèÈ°åÔºåÁâπÂà•ÈáùÂ∞çËªäËºõÁ∂≤Ë∑ØÈáèË∫´ÊâìÈÄ†„ÄÇÊàëÂÄëË©ï‰º∞‰∫Ü FedProx+LA Âú®ÈÄ£Á∫åÁ∑ö‰∏äÁâ©‰ª∂ÂÅµÊ∏¨Ê®°ÂûãË®ìÁ∑¥‰∏≠ÁöÑÊïàËÉΩ„ÄÇÈÄèÈÅéËàáÂÇ≥Áµ±ÊñπÊ≥ïÂíåÁèæÊúâÊäÄË°ìÈÄ≤Ë°åÊØîËºÉÂàÜÊûêÔºåÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÊè≠Á§∫‰∫Ü FedProx+LA ÂÖ∑ÊúâÂÑ™Áï∞ÁöÑÊî∂ÊñÇÁéá„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÂ¶ÇÊûúÊ®ôÁ±§ÂàÜ‰ΩàÈùûÂ∏∏Áï∞Ë≥™ÔºåËàáÂü∫Á∑öÊñπÊ≥ïÁõ∏ÊØîÔºåÊàëÂÄëÁöÑ FedProx+LA ÊñπÊ≥ïÈ°ØÁ§∫Âá∫ÂÅµÊ∏¨ÊïàËÉΩÁöÑÈ°ØËëóÊèêÂçáÔºå‰πüÂÑ™ÊñºÊàëÂÄëÂÖàÂâçÁöÑ FedLA ÊñπÊ≥ï„ÄÇÊ≠§Â§ñÔºåËàáÂü∫Á∑öÊñπÊ≥ïÁõ∏ÊØîÔºåFedLA Âíå FedProx+LA ÈÉΩÂ∞áÊî∂ÊñÇÈÄüÂ∫¶ÊèêÂçá‰∫Ü 30%„ÄÇ

##### **Less is More: on the Over-Globalizing Problem in Graph Transformers**
2405.01102v1 by Yujie Xing,Xiao Wang,Yibo Li,Hai Huang,Chuan Shi

Graph Transformer, due to its global attention mechanism, has emerged as a
new tool in dealing with graph-structured data. It is well recognized that the
global attention mechanism considers a wider receptive field in a fully
connected graph, leading many to believe that useful information can be
extracted from all the nodes. In this paper, we challenge this belief: does the
globalizing property always benefit Graph Transformers? We reveal the
over-globalizing problem in Graph Transformer by presenting both empirical
evidence and theoretical analysis, i.e., the current attention mechanism overly
focuses on those distant nodes, while the near nodes, which actually contain
most of the useful information, are relatively weakened. Then we propose a
novel Bi-Level Global Graph Transformer with Collaborative Training
(CoBFormer), including the inter-cluster and intra-cluster Transformers, to
prevent the over-globalizing problem while keeping the ability to extract
valuable information from distant nodes. Moreover, the collaborative training
is proposed to improve the model's generalization ability with a theoretical
guarantee. Extensive experiments on various graphs well validate the
effectiveness of our proposed CoBFormer.

ÊëòË¶ÅÔºöÂúñÂΩ¢TransformerÔºåÁî±ÊñºÂÖ∂ÂÖ®Â±ÄÊ≥®ÊÑèÂäõÊ©üÂà∂ÔºåÂ∑≤ÊàêÁÇ∫ËôïÁêÜÂúñÂΩ¢ÁµêÊßãÂåñÊï∏ÊìöÁöÑÊñ∞Â∑•ÂÖ∑„ÄÇÁúæÊâÄÂë®Áü•ÔºåÂÖ®Â±ÄÊ≥®ÊÑèÂäõÊ©üÂà∂Âú®ÂÆåÂÖ®ÈÄ£Êé•ÁöÑÂúñÂΩ¢‰∏≠ËÄÉÊÖÆ‰∫ÜÊõ¥Âª£Ê≥õÁöÑÊÑüÂèóÈáéÔºåÈÄôÂ∞éËá¥Ë®±Â§ö‰∫∫Áõ∏‰ø°ÂèØ‰ª•ÂæûÊâÄÊúâÁØÄÈªû‰∏≠ÊèêÂèñÊúâÁî®ÁöÑ‰ø°ÊÅØ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊåëÊà∞‰∫ÜÈÄô‰∏ÄËßÄÈªûÔºöÂÖ®Â±ÄÂåñÂ±¨ÊÄßÊòØÂê¶Á∏ΩËÉΩ‰ΩøÂúñÂΩ¢TransformerÂèóÁõäÔºüÊàëÂÄëÈÄöÈÅéÊèê‰æõÁ∂ìÈ©óË≠âÊìöÂíåÁêÜË´ñÂàÜÊûêÊè≠Á§∫‰∫ÜÂúñÂΩ¢Transformer‰∏≠ÁöÑÈÅéÂ∫¶ÂÖ®Â±ÄÂåñÂïèÈ°åÔºåÂç≥Áï∂ÂâçÁöÑÊ≥®ÊÑèÂäõÊ©üÂà∂ÈÅéÂ∫¶ÈóúÊ≥®ÈÇ£‰∫õÈÅ†Á®ãÁØÄÈªûÔºåËÄåÂØ¶Èöõ‰∏äÂåÖÂê´Â§ßÈÉ®ÂàÜÊúâÁî®‰ø°ÊÅØÁöÑËøëÁØÄÈªûÂâáÁõ∏Â∞çËºÉÂº±„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊñ∞ÁöÑÈõôÁ¥öÂÖ®Â±ÄÂúñÂΩ¢TransformerÔºå‰∏¶Êé°Áî®Âçî‰ΩúË®ìÁ∑¥ÔºàCoBFormerÔºâÔºåÂåÖÊã¨ÈõÜÁæ§ÈñìÂíåÈõÜÁæ§ÂÖßTransformerÔºå‰ª•Èò≤Ê≠¢ÈÅéÂ∫¶ÂÖ®Â±ÄÂåñÂïèÈ°åÔºåÂêåÊôÇ‰øùÊåÅÂæûÈÅ†Á®ãÁØÄÈªûÊèêÂèñÊúâÂÉπÂÄº‰ø°ÊÅØÁöÑÁöÑËÉΩÂäõ„ÄÇÊ≠§Â§ñÔºåÊèêÂá∫‰∫ÜÂçî‰ΩúË®ìÁ∑¥Ôºå‰ª•Âú®ÁêÜË´ñ‰øùË≠â‰∏ãÊèêÈ´òÊ®°ÂûãÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇÂú®ÂêÑÁ®ÆÂúñÂΩ¢‰∏äÁöÑÂ§ßÈáèÂØ¶È©óÂæàÂ•ΩÂú∞È©óË≠â‰∫ÜÊàëÂÄëÊèêÂá∫ÁöÑ CoBFormer ÁöÑÊúâÊïàÊÄß„ÄÇ

##### **Silencing the Risk, Not the Whistle: A Semi-automated Text Sanitization Tool for Mitigating the Risk of Whistleblower Re-Identification**
2405.01097v1 by Dimitri Staufer,Frank Pallas,Bettina Berendt

Whistleblowing is essential for ensuring transparency and accountability in
both public and private sectors. However, (potential) whistleblowers often fear
or face retaliation, even when reporting anonymously. The specific content of
their disclosures and their distinct writing style may re-identify them as the
source. Legal measures, such as the EU WBD, are limited in their scope and
effectiveness. Therefore, computational methods to prevent re-identification
are important complementary tools for encouraging whistleblowers to come
forward. However, current text sanitization tools follow a one-size-fits-all
approach and take an overly limited view of anonymity. They aim to mitigate
identification risk by replacing typical high-risk words (such as person names
and other NE labels) and combinations thereof with placeholders. Such an
approach, however, is inadequate for the whistleblowing scenario since it
neglects further re-identification potential in textual features, including
writing style. Therefore, we propose, implement, and evaluate a novel
classification and mitigation strategy for rewriting texts that involves the
whistleblower in the assessment of the risk and utility. Our prototypical tool
semi-automatically evaluates risk at the word/term level and applies
risk-adapted anonymization techniques to produce a grammatically disjointed yet
appropriately sanitized text. We then use a LLM that we fine-tuned for
paraphrasing to render this text coherent and style-neutral. We evaluate our
tool's effectiveness using court cases from the ECHR and excerpts from a
real-world whistleblower testimony and measure the protection against
authorship attribution (AA) attacks and utility loss statistically using the
popular IMDb62 movie reviews dataset. Our method can significantly reduce AA
accuracy from 98.81% to 31.22%, while preserving up to 73.1% of the original
content's semantics.

ÊëòË¶ÅÔºö<paragraph>ËàâÁôºÂ∞çÊñºÁ¢∫‰øùÂÖ¨ÂÖ±ÂíåÁßÅ‰∫∫ÈÉ®ÈñÄÁöÑÈÄèÊòéÂ∫¶ÂíåË≤¨‰ªªÂà∂Ëá≥ÈóúÈáçË¶Å„ÄÇÁÑ∂ËÄåÔºåÔºàÊΩõÂú®ÁöÑÔºâËàâÁôºËÄÖÂú®ÂåøÂêçËàâÂ†±ÊôÇÔºåÂ∏∏Â∏∏ÊúÉÂÆ≥ÊÄïÊàñÈù¢Ëá®Â†±Âæ©„ÄÇ‰ªñÂÄëÊè≠Èú≤ÁöÑÂÖ∑È´îÂÖßÂÆπÂíåÁç®ÁâπÁöÑÂØ´‰ΩúÈ¢®Ê†ºÂèØËÉΩÊúÉÂÜçÊ¨°Â∞á‰ªñÂÄëË≠òÂà•ÁÇ∫Ê∂àÊÅØ‰æÜÊ∫ê„ÄÇÊ≠êÁõüËàâÂ†±ËÄÖ‰øùË≠∑Êåá‰ª§Á≠âÊ≥ïÂæãÊé™ÊñΩÁöÑÁØÑÂúçÂíåÊïàÂäõÊúâÈôê„ÄÇÂõ†Ê≠§ÔºåË®àÁÆóÊ©üÊñπÊ≥ïÂ∞çÊñºÈò≤Ê≠¢ÂÜçÊ¨°Ë≠òÂà•ÊòØÈºìÂãµËàâÂ†±ËÄÖÁ´ôÂá∫‰æÜÁöÑÈáçË¶ÅÁöÑË£úÂÖÖÂ∑•ÂÖ∑„ÄÇÁÑ∂ËÄåÔºåÁõÆÂâçÁöÑÊñáÊú¨Ê∏ÖÁêÜÂ∑•ÂÖ∑Êé°Áî®‰∏ÄÂàÄÂàáÁöÑÊñπÊ≥ïÔºåÂ∞çÂåøÂêçÊÄßÁöÑÁúãÊ≥ïÈÅéÊñºÁãπÈöò„ÄÇÂÆÉÂÄëÊó®Âú®ÈÄöÈÅéÂ∞áÂÖ∏ÂûãÁöÑÈ¢®Èö™ËºÉÈ´òÁöÑË©ûÂΩôÔºà‰æãÂ¶Ç‰∫∫ÂêçÂíåÂÖ∂‰ªñ NE Ê®ôÁ±§ÔºâÂèäÂÖ∂ÁµÑÂêàÊõøÊèõÁÇ∫‰Ωî‰ΩçÁ¨¶‰æÜÈôç‰ΩéË≠òÂà•È¢®Èö™„ÄÇÁÑ∂ËÄåÔºåÈÄôÁ®ÆÊñπÊ≥ïÂ∞çÊñºËàâÂ†±Â†¥ÊôØ‰æÜË™™ÊòØ‰∏çÂ§†ÁöÑÔºåÂõ†ÁÇ∫ÂÆÉÂøΩË¶ñ‰∫ÜÊñáÊú¨ÁâπÂæµ‰∏≠ÈÄ≤‰∏ÄÊ≠•ÁöÑÈáçÊñ∞Ë≠òÂà•ÂèØËÉΩÊÄßÔºåÂåÖÊã¨ÂØ´‰ΩúÈ¢®Ê†º„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëÊèêÂá∫„ÄÅÂØ¶ÊñΩ‰∏¶Ë©ï‰º∞‰∫Ü‰∏ÄÁ®ÆÊñ∞ÁöÑÂàÜÈ°ûÂíåÁ∑©Ëß£Á≠ñÁï•ÔºåÁî®ÊñºÈáçÂØ´ÊñáÊú¨ÔºåÂÖ∂‰∏≠Ê∂âÂèäËàâÂ†±ËÄÖÂ∞çÈ¢®Èö™ÂíåÊïàÁî®ÁöÑË©ï‰º∞„ÄÇÊàëÂÄëÁöÑÂéüÂûãÂ∑•ÂÖ∑Âú®Ë©ûÂΩô/Ë°ìË™ûÂ±§Á¥öÂçäËá™ÂãïË©ï‰º∞È¢®Èö™Ôºå‰∏¶ÊáâÁî®È¢®Èö™ÈÅ©ÊáâÂåøÂêçÂåñÊäÄË°ì‰æÜÁî¢ÁîüË™ûÊ≥ï‰∏çÈÄ£Ë≤´‰ΩÜÈÅ©Áï∂Ê∏ÖÁêÜÁöÑÊñáÊú¨„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄë‰ΩøÁî®‰∏ÄÂÄãÁ∂ìÈÅéÂæÆË™øÁöÑ LLM ‰æÜÈÄ≤Ë°åÊîπÂØ´Ôºå‰ª•‰ΩøÊñáÊú¨ÈÄ£Ë≤´‰∏îÈ¢®Ê†º‰∏≠Á´ã„ÄÇÊàëÂÄë‰ΩøÁî®Ê≠êÊ¥≤‰∫∫Ê¨äÊ≥ïÈô¢ÁöÑÊ°à‰æãÂíåÁúüÂØ¶ËàâÂ†±ËÄÖË≠âË©ûÁöÑÊëòÈåÑ‰æÜË©ï‰º∞ÊàëÂÄëÂ∑•ÂÖ∑ÁöÑÊúâÊïàÊÄßÔºå‰∏¶‰ΩøÁî®ÊµÅË°åÁöÑ IMDb62 ÈõªÂΩ±Ë©ïË´ñÊï∏ÊìöÈõÜÁµ±Ë®àË°°ÈáèÂ∞ç‰ΩúËÄÖÊ≠∏Âõ† (AA) ÊîªÊìäÁöÑ‰øùË≠∑ÂíåÊïàÁî®ÊêçÂ§±„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÂèØ‰ª•Â∞á AA Ê∫ñÁ¢∫ÁéáÂæû 98.81% Â§ßÂπÖÈôç‰ΩéÂà∞ 31.22%ÔºåÂêåÊôÇ‰øùÁïôÈ´òÈÅî 73.1% ÁöÑÂéüÂßãÂÖßÂÆπË™ûÁæ©„ÄÇ</paragraph>

##### **Poisoning Attacks on Federated Learning for Autonomous Driving**
2405.01073v1 by Sonakshi Garg,Hugo J√∂nsson,Gustav Kalander,Axel Nilsson,Bhhaanu Pirange,Viktor Valadi,Johan √ñstman

Federated Learning (FL) is a decentralized learning paradigm, enabling
parties to collaboratively train models while keeping their data confidential.
Within autonomous driving, it brings the potential of reducing data storage
costs, reducing bandwidth requirements, and to accelerate the learning. FL is,
however, susceptible to poisoning attacks. In this paper, we introduce two
novel poisoning attacks on FL tailored to regression tasks within autonomous
driving: FLStealth and Off-Track Attack (OTA). FLStealth, an untargeted attack,
aims at providing model updates that deteriorate the global model performance
while appearing benign. OTA, on the other hand, is a targeted attack with the
objective to change the global model's behavior when exposed to a certain
trigger. We demonstrate the effectiveness of our attacks by conducting
comprehensive experiments pertaining to the task of vehicle trajectory
prediction. In particular, we show that, among five different untargeted
attacks, FLStealth is the most successful at bypassing the considered defenses
employed by the server. For OTA, we demonstrate the inability of common defense
strategies to mitigate the attack, highlighting the critical need for new
defensive mechanisms against targeted attacks within FL for autonomous driving.

ÊëòË¶ÅÔºöËÅØÂêàÂ≠∏Áøí (FL) ÊòØ‰∏ÄÁ®ÆÂàÜÊï£ÂºèÂ≠∏ÁøíÁØÑ‰æãÔºå‰ΩøÂêÑÊñπËÉΩÂ§†Âú®‰øùÊåÅÂÖ∂Ë≥áÊñôÊ©üÂØÜÊÄßÁöÑÂêåÊôÇÂçî‰ΩúË®ìÁ∑¥Ê®°Âûã„ÄÇÂú®Ëá™ÂãïÈßïÈßõ‰∏≠ÔºåÂÆÉÂÖ∑ÊúâÈôç‰ΩéË≥áÊñôÂÑ≤Â≠òÊàêÊú¨„ÄÅÊ∏õÂ∞ëÈ†ªÂØ¨ÈúÄÊ±ÇÂíåÂä†ÈÄüÂ≠∏ÁøíÁöÑÊΩõÂäõ„ÄÇÁÑ∂ËÄåÔºåFL ÂÆπÊòìÂèóÂà∞‰∏≠ÊØíÊîªÊìä„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫ÜÈáùÂ∞çËá™ÂãïÈßïÈßõ‰∏≠ÂõûÊ≠∏‰ªªÂãôÈáèË∫´ÂÆöÂà∂ÁöÑÂÖ©Á®ÆÊñ∞Âûã‰∏≠ÊØíÊîªÊìäÔºöFLStealth Âíå Off-Track Attack (OTA)„ÄÇFLStealth ÊòØ‰∏ÄÁ®ÆÈùûÁõÆÊ®ôÊîªÊìäÔºåÊó®Âú®Êèê‰æõÊúÉÊÉ°ÂåñÊï¥È´îÊ®°ÂûãÊïàËÉΩ‰ΩÜÁúãËµ∑‰æÜËâØÊÄßÁöÑÊ®°ÂûãÊõ¥Êñ∞„ÄÇÂè¶‰∏ÄÊñπÈù¢ÔºåOTA ÊòØ‰∏ÄÁ®ÆÁõÆÊ®ôÊîªÊìäÔºåÁõÆÊ®ôÊòØÊîπËÆäÊï¥È´îÊ®°ÂûãÂú®Êö¥Èú≤ÊñºÁâπÂÆöËß∏ÁôºÂô®ÊôÇÁöÑË°åÁÇ∫„ÄÇÊàëÂÄëÈÄèÈÅéÈáùÂ∞çËªäËºõËªåË∑°È†êÊ∏¨‰ªªÂãôÈÄ≤Ë°åÂÖ®Èù¢ÂØ¶È©ó‰æÜË≠âÊòéÊàëÂÄëÊîªÊìäÁöÑÊúâÊïàÊÄß„ÄÇÁâπÂà•ÊòØÔºåÊàëÂÄëË°®ÊòéÂú®‰∫îÁ®Æ‰∏çÂêåÁöÑÈùûÁõÆÊ®ôÊîªÊìä‰∏≠ÔºåFLStealth Âú®ÁπûÈÅé‰º∫ÊúçÂô®Êé°Áî®ÁöÑËÄÉÊÖÆÈò≤Á¶¶ÊñπÈù¢ÊúÄÁÇ∫ÊàêÂäü„ÄÇÂ∞çÊñº OTAÔºåÊàëÂÄëË≠âÊòé‰∫ÜÂ∏∏Ë¶ãÈò≤Á¶¶Á≠ñÁï•ÁÑ°Ê≥ïÊ∏õËºïÊîªÊìäÔºåÁ™ÅÈ°Ø‰∫ÜÂú® FL ‰∏≠ÈáùÂ∞çËá™ÂãïÈßïÈßõÁöÑÁõÆÊ®ôÊîªÊìäËø´ÂàáÈúÄË¶ÅÊñ∞ÁöÑÈò≤Á¶¶Ê©üÂà∂„ÄÇ

##### **AB-Training: A Communication-Efficient Approach for Distributed Low-Rank Learning**
2405.01067v1 by Daniel Coquelin,Katherina Fl√ºgel,Marie Weiel,Nicholas Kiefer,Muhammed √ñz,Charlotte Debus,Achim Streit,Markus G√∂tz

Communication bottlenecks hinder the scalability of distributed neural
network training, particularly on distributed-memory computing clusters. To
significantly reduce this communication overhead, we introduce AB-training, a
novel data-parallel training method that decomposes weight matrices into
low-rank representations and utilizes independent group-based training. This
approach consistently reduces network traffic by 50% across multiple scaling
scenarios, increasing the training potential on communication-constrained
systems. Our method exhibits regularization effects at smaller scales, leading
to improved generalization for models like VGG16, while achieving a remarkable
44.14 : 1 compression ratio during training on CIFAR-10 and maintaining
competitive accuracy. Albeit promising, our experiments reveal that large batch
effects remain a challenge even in low-rank training regimes.

ÊëòË¶ÅÔºöÈÄöË®äÁì∂È†∏ÊúÉÈòªÁ§ôÂàÜÊï£ÂºèÁ•ûÁ∂ìÁ∂≤Ë∑ØË®ìÁ∑¥ÁöÑÂèØÊì¥ÂÖÖÊÄßÔºåÁâπÂà•ÊòØÂú®ÂàÜÊï£ÂºèË®òÊÜ∂È´îÈÅãÁÆóÂè¢ÈõÜ‰∏ä„ÄÇÁÇ∫‰∫ÜÂ§ßÂπÖÊ∏õÂ∞ëÈÄôÁ®ÆÈÄöË®äÈñãÈä∑ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü AB Ë®ìÁ∑¥Ôºå‰∏ÄÁ®ÆÊñ∞Á©éÁöÑË≥áÊñôÂπ≥Ë°åË®ìÁ∑¥ÊñπÊ≥ïÔºåÂÆÉËÉΩÂ∞áÊ¨äÈáçÁü©Èô£ÂàÜËß£Êàê‰ΩéÈöéË°®Á§∫Ôºå‰∏¶Âà©Áî®Áç®Á´ãÁöÑÂü∫ÊñºÁæ§ÁµÑÁöÑË®ìÁ∑¥„ÄÇÈÄôÁ®ÆÊñπÊ≥ïÊåÅÁ∫åÂú®Â§öÁ®ÆÊì¥ÂÖÖÂ†¥ÊôØ‰∏≠Â∞áÁ∂≤Ë∑ØÊµÅÈáèÊ∏õÂ∞ë 50%ÔºåÂ¢ûÂä†‰∫ÜÂú®ÂèóÈÄöË®äÈôêÂà∂ÁöÑÁ≥ªÁµ±‰∏äÈÄ≤Ë°åË®ìÁ∑¥ÁöÑÊΩõÂäõ„ÄÇÊàëÂÄëÁöÑÈÄôÁ®ÆÊñπÊ≥ïÂú®ËºÉÂ∞èË¶èÊ®°‰∏ãÂ±ïÁèæ‰∫ÜÊ≠£ÂâáÂåñÁöÑÊïàÊûúÔºåÂ∞éËá¥ÂÉè VGG16 ÈÄôÊ®£ÁöÑÊ®°ÂûãÁöÑÊ≥õÂåñËÉΩÂäõÂæóÂà∞ÊîπÂñÑÔºåÂêåÊôÇÂú® CIFAR-10 ‰∏äÁöÑË®ìÁ∑¥‰∏≠ÈÅîÂà∞‰∫ÜÈ©ö‰∫∫ÁöÑ 44.14 : 1 Â£ìÁ∏ÆÁéáÔºå‰∏¶Á∂≠ÊåÅ‰∫ÜÊúâÁ´∂Áà≠ÂäõÁöÑÊ∫ñÁ¢∫Â∫¶„ÄÇÂÑòÁÆ°ÊúâÂ∏åÊúõÔºåÊàëÂÄëÁöÑÂØ¶È©óË°®ÊòéÔºåÂç≥‰ΩøÂú®‰ΩéÈöéË®ìÁ∑¥Ê®°Âºè‰∏≠ÔºåÂ§ßÊâπÊ¨°ÊïàÊáâ‰ªçÁÑ∂ÊòØ‰∏ÄÂÄãÊåëÊà∞„ÄÇ

##### **HandSSCA: 3D Hand Mesh Reconstruction with State Space Channel Attention from RGB images**
2405.01066v1 by Zixun Jiao,Xihan Wang,Quanli Gao

Reconstructing a hand mesh from a single RGB image is a challenging task
because hands are often occluded by objects. Most previous works attempted to
introduce more additional information and adopt attention mechanisms to improve
3D reconstruction results, but it would increased computational complexity.
This observation prompts us to propose a new and concise architecture while
improving computational efficiency. In this work, we propose a simple and
effective 3D hand mesh reconstruction network HandSSCA, which is the first to
incorporate state space modeling into the field of hand pose estimation. In the
network, we have designed a novel state space channel attention module that
extends the effective sensory field, extracts hand features in the spatial
dimension, and enhances hand regional features in the channel dimension. This
design helps to reconstruct a complete and detailed hand mesh. Extensive
experiments conducted on well-known datasets featuring challenging hand-object
occlusions (such as FREIHAND, DEXYCB, and HO3D) demonstrate that our proposed
HandSSCA achieves state-of-the-art performance while maintaining a minimal
parameter count.

ÊëòË¶ÅÔºöÂæûÂñÆ‰∏Ä RGB ÂΩ±ÂÉèÈáçÂª∫ÊâãÈÉ®Á∂≤Ê†ºÊòØ‰∏ÄÈ†ÖÂÖ∑ÊúâÊåëÊà∞ÊÄßÁöÑ‰ªªÂãôÔºåÂõ†ÁÇ∫ÊâãÈÉ®Á∂ìÂ∏∏Ë¢´Áâ©È´îÈÅÆÊìã„ÄÇÂ§ßÂ§öÊï∏ÂÖàÂâçÁöÑÁ†îÁ©∂ÂòóË©¶ÂºïÂÖ•Êõ¥Â§öÈ°çÂ§ñÁöÑË≥áË®äÔºå‰∏¶Êé°Áî®Ê≥®ÊÑèÂäõÊ©üÂà∂‰æÜÊîπÂñÑ 3D ÈáçÂª∫ÁµêÊûúÔºå‰ΩÜÈÄôÊúÉÂ¢ûÂä†Ë®àÁÆóË§áÈõúÊÄß„ÄÇÊ≠§ËßÄÂØü‰øÉ‰ΩøÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÊñ∞ÁöÑÁ∞°ÊΩîÊû∂ÊßãÔºåÂêåÊôÇÊèêÈ´òË®àÁÆóÊïàÁéá„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÁ∞°ÂñÆ‰∏îÊúâÊïàÁöÑ 3D ÊâãÈÉ®Á∂≤Ê†ºÈáçÂª∫Á∂≤Ë∑Ø HandSSCAÔºåÂÆÉÁéáÂÖàÂ∞áÁãÄÊÖãÁ©∫ÈñìÊ®°ÂûãÁ¥çÂÖ•ÊâãÈÉ®ÂßøÂã¢‰º∞Ë®àÈ†òÂüü„ÄÇÂú®Á∂≤Ë∑Ø‰∏≠ÔºåÊàëÂÄëË®≠Ë®à‰∫Ü‰∏ÄÂÄãÊñ∞Á©éÁöÑÁãÄÊÖãÁ©∫ÈñìÈÄöÈÅìÊ≥®ÊÑèÂäõÊ®°ÁµÑÔºåÂÆÉÊì¥Â±ï‰∫ÜÊúâÊïàÊÑüÊ∏¨Â†¥ÔºåÊèêÂèñÁ©∫ÈñìÁ∂≠Â∫¶‰∏≠ÁöÑÊâãÈÉ®ÁâπÂæµÔºå‰∏¶Â¢ûÂº∑ÈÄöÈÅìÁ∂≠Â∫¶‰∏≠ÁöÑÊâãÈÉ®ÂçÄÂüüÁâπÂæµ„ÄÇÊ≠§Ë®≠Ë®àÊúâÂä©ÊñºÈáçÂª∫ÂÆåÊï¥‰∏îË©≥Á¥∞ÁöÑÊâãÈÉ®Á∂≤Ê†º„ÄÇÂú®ÂÖ∑ÊúâÊåëÊà∞ÊÄßÁöÑÊâãÈÉ®Áâ©È´îÈÅÆÊìãÔºà‰æãÂ¶Ç FREIHAND„ÄÅDEXYCB Âíå HO3DÔºâ‰∏≠ÈÄ≤Ë°åÁöÑÂª£Ê≥õÂØ¶È©óË≠âÊòéÔºåÊàëÂÄëÊèêÂá∫ÁöÑ HandSSCA Âú®Á∂≠ÊåÅÊúÄÂ∞èÂèÉÊï∏Ë®àÊï∏ÁöÑÂêåÊôÇÔºåÈÅîÂà∞‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÊïàËÉΩ„ÄÇ

##### **A text-based, generative deep learning model for soil reflectance spectrum simulation in the VIS-NIR (400-2499 nm) bands**
2405.01060v1 by Tong Lei,Brian N. Bailey

Simulating soil reflectance spectra is invaluable for soil-plant radiative
modeling and training machine learning models, yet it is difficult as the
intricate relationships between soil structure and its constituents. To address
this, a fully data-driven soil optics generative model (SOGM) for simulation of
soil reflectance spectra based on soil property inputs was developed. The model
is trained on an extensive dataset comprising nearly 180,000 soil
spectra-property pairs from 17 datasets. It generates soil reflectance spectra
from text-based inputs describing soil properties and their values rather than
only numerical values and labels in binary vector format. The generative model
can simulate output spectra based on an incomplete set of input properties.
SOGM is based on the denoising diffusion probabilistic model (DDPM). Two
additional sub-models were also built to complement the SOGM: a spectral
padding model that can fill in the gaps for spectra shorter than the full
visible-near-infrared range (VIS-NIR; 400 to 2499 nm), and a wet soil spectra
model that can estimate the effects of water content on soil reflectance
spectra given the dry spectrum predicted by the SOGM. The SOGM was up-scaled by
coupling with the Helios 3D plant modeling software, which allowed for
generation of synthetic aerial images of simulated soil and plant scenes. It
can also be easily integrated with soil-plant radiation model used for remote
sensin research like PROSAIL. The testing results of the SOGM on new datasets
that not included in model training proved that the model can generate
reasonable soil reflectance spectra based on available property inputs. The
presented models are openly accessible on:
https://github.com/GEMINI-Breeding/SOGM_soil_spectra_simulation.

ÊëòË¶ÅÔºöÊ®°Êì¨ÂúüÂ£§ÂèçÂ∞ÑÂÖâË≠úÂ∞çÊñºÂúüÂ£§-Ê§çÁâ©ËºªÂ∞ÑÊ®°ÂûãÂíåË®ìÁ∑¥Ê©üÂô®Â≠∏ÁøíÊ®°ÂûãÈùûÂ∏∏ÊúâÂÉπÂÄºÔºå‰ΩÜÁî±ÊñºÂúüÂ£§ÁµêÊßãËàáÂÖ∂ÁµÑÊàêÊàêÂàÜ‰πãÈñìÁöÑË§áÈõúÈóú‰øÇÔºåÂõ†Ê≠§ÂæàÂõ∞Èõ£„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÈñãÁôº‰∫Ü‰∏ÄÂÄãÂü∫ÊñºÂúüÂ£§Â±¨ÊÄßËº∏ÂÖ•ÁöÑÂúüÂ£§ÂèçÂ∞ÑÂÖâË≠úÊ®°Êì¨ÁöÑÂÆåÂÖ®Êï∏ÊìöÈ©ÖÂãïÂúüÂ£§ÂÖâÂ≠∏ÁîüÊàêÊ®°Âûã (SOGM)„ÄÇË©≤Ê®°ÂûãÂú®‰∏ÄÂÄãÂåÖÂê´‰æÜËá™ 17 ÂÄãÊï∏ÊìöÈõÜÁöÑËøë 180,000 ÂÄãÂúüÂ£§ÂÖâË≠ú-Â±¨ÊÄßÂ∞çÁöÑÂª£Ê≥õÊï∏ÊìöÈõÜ‰∏äÈÄ≤Ë°åË®ìÁ∑¥„ÄÇÂÆÉÂæûÊèèËø∞ÂúüÂ£§Â±¨ÊÄßÂèäÂÖ∂ÂÄºÁöÑÂü∫ÊñºÊñáÊú¨ÁöÑËº∏ÂÖ•‰∏≠ÁîüÊàêÂúüÂ£§ÂèçÂ∞ÑÂÖâË≠úÔºåËÄå‰∏çÊòØÂÉÖ‰∫åÈÄ≤Âà∂ÂêëÈáèÊ†ºÂºè‰∏≠ÁöÑÊï∏ÂÄºÂíåÊ®ôÁ±§„ÄÇÁîüÊàêÊ®°ÂûãÂèØ‰ª•Ê†πÊìö‰∏çÂÆåÊï¥ÁöÑËº∏ÂÖ•Â±¨ÊÄßÈõÜÊ®°Êì¨Ëº∏Âá∫ÂÖâË≠ú„ÄÇSOGM Âü∫ÊñºÂéªÂô™Êì¥Êï£Ê¶ÇÁéáÊ®°Âûã (DDPM)„ÄÇÈÇÑÊßãÂª∫‰∫ÜÂÖ©ÂÄãÈ°çÂ§ñÁöÑÂ≠êÊ®°Âûã‰æÜË£úÂÖÖ SOGMÔºö‰∏ÄÂÄãÂÖâË≠úÂ°´ÂÖÖÊ®°ÂûãÔºåÂèØ‰ª•Â°´Ë£úÂ∞èÊñºÂÖ®ÂèØË¶ãËøëÁ¥ÖÂ§ñÁØÑÂúç (VIS-NIRÔºõ400 Ëá≥ 2499 nm) ÁöÑÂÖâË≠úÁöÑÁ©∫ÁôΩÔºå‰ª•Âèä‰∏ÄÂÄãÊøïÂúüÂÖâË≠úÊ®°ÂûãÔºåÂèØ‰ª•‰º∞Ë®àÊ∞¥Âê´ÈáèÂ∞ç‰πæÁá•ÂÖâË≠úÁöÑÂΩ±ÈüøÁî± SOGM È†êÊ∏¨ÁöÑÂÖâË≠ú„ÄÇSOGM ÈÄöÈÅéËàá Helios 3D Ê§çÁâ©Âª∫Ê®°ËªüÈ´îÁõ∏ÁµêÂêàÈÄ≤Ë°åÊì¥Â±ïÔºåÈÄôÂÖÅË®±ÁîüÊàêÊ®°Êì¨ÂúüÂ£§ÂíåÊ§çÁâ©Â†¥ÊôØÁöÑÂêàÊàêËà™ÊãçÂúñÂÉè„ÄÇÂÆÉÈÇÑÂèØ‰ª•ËºïÈ¨ÜÂú∞ËàáÁî®ÊñºÈÅôÊÑüÁ†îÁ©∂ÁöÑÂúüÂ£§Ê§çÁâ©ËºªÂ∞ÑÊ®°ÂûãÔºàÂ¶Ç PROSAILÔºâÈõÜÊàê„ÄÇSOGM Âú®Êú™ÂåÖÂê´Âú®Ê®°ÂûãË®ìÁ∑¥‰∏≠ÁöÑÊñ∞Êï∏ÊìöÈõÜ‰∏äÁöÑÊ∏¨Ë©¶ÁµêÊûúË≠âÊòéÔºåË©≤Ê®°ÂûãÂèØ‰ª•Ê†πÊìöÂèØÁî®ÁöÑÂ±¨ÊÄßËº∏ÂÖ•ÁîüÊàêÂêàÁêÜÁöÑÂúüÂ£§ÂèçÂ∞ÑÂÖâË≠ú„ÄÇÊâÄÊèêÂá∫ÁöÑÊ®°ÂûãÂèØÂú®‰ª•‰∏ã‰ΩçÁΩÆÂÖ¨ÈñãË®™ÂïèÔºö
https://github.com/GEMINI-Breeding/SOGM_soil_spectra_simulation„ÄÇ

##### **Leverage Multi-source Traffic Demand Data Fusion with Transformer Model for Urban Parking Prediction**
2405.01055v1 by Yin Huang,Yongqi Dong,Youhua Tang,Li Li

The escalation in urban private car ownership has worsened the urban parking
predicament, necessitating effective parking availability prediction for urban
planning and management. However, the existing prediction methods suffer from
low prediction accuracy with the lack of spatial-temporal correlation features
related to parking volume, and neglect of flow patterns and correlations
between similar parking lots within certain areas. To address these challenges,
this study proposes a parking availability prediction framework integrating
spatial-temporal deep learning with multi-source data fusion, encompassing
traffic demand data from multiple sources (e.g., metro, bus, taxi services),
and parking lot data. The framework is based on the Transformer as the
spatial-temporal deep learning model and leverages K-means clustering to
establish parking cluster zones, extracting and integrating traffic demand
characteristics from various transportation modes (i.e., metro, bus, online
ride-hailing, and taxi) connected to parking lots. Real-world empirical data
was used to verify the effectiveness of the proposed method compared with
different machine learning, deep learning, and traditional statistical models
for predicting parking availability. Experimental results reveal that, with the
proposed pipeline, the developed Transformer model outperforms other models in
terms of various metrics, e.g., Mean Squared Error (MSE), Mean Absolute Error
(MAE), and Mean Absolute Percentage Error (MAPE). By fusing multi-source
demanding data with spatial-temporal deep learning techniques, this approach
offers the potential to develop parking availability prediction systems that
furnish more accurate and timely information to both drivers and urban
planners, thereby fostering more efficient and sustainable urban mobility.

ÊëòË¶ÅÔºö<paragraph>Áî±ÊñºÂüéÂ∏ÇÁßÅ‰∫∫Ê±ΩËªäÊìÅÊúâÈáèÊøÄÂ¢ûÔºåÂ∞éËá¥ÂÅúËªäÈõ£ÂïèÈ°åÊó•ÁõäÂö¥ÈáçÔºåÈÄô‰ΩøÂæóÂú®ÂüéÂ∏ÇË¶èÂäÉÂíåÁÆ°ÁêÜ‰∏≠ÔºåÊúâÊïàÈ†êÊ∏¨ÂÅúËªä‰ΩçÂèØÁî®ÊÄßËÆäÂæóÂçÅÂàÜÂøÖË¶Å„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÁöÑÈ†êÊ∏¨ÊñπÊ≥ïÂ≠òÂú®È†êÊ∏¨Ê∫ñÁ¢∫Â∫¶‰ΩéÁöÑÂïèÈ°åÔºåÂõ†ÁÇ∫ÂÆÉÂÄëÁº∫‰πèËàáÂÅúËªäÈáèÁõ∏ÈóúÁöÑÊôÇÁ©∫ÈóúËÅØÊÄßÁâπÂæµÔºå‰∏¶‰∏îÂøΩÁï•‰∫ÜÁâπÂÆöÂçÄÂüüÂÖßÁõ∏‰ººÂÅúËªäÂ†¥‰πãÈñìÁöÑÊµÅÂãïÊ®°ÂºèÂíåÈóúËÅØÊÄß„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÔºåÊú¨Á†îÁ©∂ÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂÅúËªä‰ΩçÂèØÁî®ÊÄßÈ†êÊ∏¨Ê°ÜÊû∂ÔºåË©≤Ê°ÜÊû∂Â∞áÊôÇÁ©∫Ê∑±Â∫¶Â≠∏ÁøíËàáÂ§öÊ∫êÊï∏ÊìöËûçÂêàÁõ∏ÁµêÂêàÔºåÊ∂µËìã‰∫Ü‰æÜËá™Â§öÂÄã‰æÜÊ∫êÔºà‰æãÂ¶ÇÂú∞Èêµ„ÄÅÂÖ¨Ëªä„ÄÅË®àÁ®ãËªäÊúçÂãôÔºâÁöÑ‰∫§ÈÄöÈúÄÊ±ÇÊï∏ÊìöÂíåÂÅúËªäÂ†¥Êï∏Êìö„ÄÇË©≤Ê°ÜÊû∂Âü∫Êñº Transformer ‰ΩúÁÇ∫ÊôÇÁ©∫Ê∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÔºå‰∏¶Âà©Áî® K ÂùáÂÄºËÅöÈ°û‰æÜÂª∫Á´ãÂÅúËªäÂ†¥Áæ§ÈõÜÂçÄÂüüÔºåÂæûÈÄ£Êé•Âà∞ÂÅúËªäÂ†¥ÁöÑÂêÑÁ®Æ‰∫§ÈÄöÊ®°ÂºèÔºàÂç≥Âú∞Èêµ„ÄÅÂÖ¨Ëªä„ÄÅÁ∑ö‰∏äÂè´ËªäÊúçÂãôÂíåË®àÁ®ãËªäÔºâ‰∏≠ÊèêÂèñÂíåÊï¥Âêà‰∫§ÈÄöÈúÄÊ±ÇÁâπÂæµ„ÄÇ‰ΩøÁî®ÁúüÂØ¶‰∏ñÁïåÁöÑÁ∂ìÈ©óÊï∏ÊìöÈ©óË≠â‰∫ÜÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïËàáÁî®ÊñºÈ†êÊ∏¨ÂÅúËªä‰ΩçÂèØÁî®ÊÄßÁöÑ‰∏çÂêåÊ©üÂô®Â≠∏Áøí„ÄÅÊ∑±Â∫¶Â≠∏ÁøíÂíåÂÇ≥Áµ±Áµ±Ë®àÊ®°ÂûãÁõ∏ÊØîÁöÑÊúâÊïàÊÄß„ÄÇÂØ¶È©óÁµêÊûúË°®ÊòéÔºå‰ΩøÁî®ÊâÄÊèêÂá∫ÁöÑÁÆ°Á∑öÔºåÈñãÁôºÁöÑ Transformer Ê®°ÂûãÂú®ÂêÑÁ®ÆÊåáÊ®ôÊñπÈù¢ÂÑ™ÊñºÂÖ∂‰ªñÊ®°ÂûãÔºå‰æãÂ¶ÇÂùáÊñπË™§Â∑Æ (MSE)„ÄÅÂπ≥ÂùáÁµïÂ∞çË™§Â∑Æ (MAE) ÂíåÂπ≥ÂùáÁµïÂ∞çÁôæÂàÜÊØîË™§Â∑Æ (MAPE)„ÄÇÈÄöÈÅéÂ∞áÂ§öÊ∫êÈúÄÊ±ÇÊï∏ÊìöËàáÊôÇÁ©∫Ê∑±Â∫¶Â≠∏ÁøíÊäÄË°ìÁõ∏ËûçÂêàÔºåÈÄôÁ®ÆÊñπÊ≥ïÊèê‰æõ‰∫ÜÈñãÁôºÂÅúËªä‰ΩçÂèØÁî®ÊÄßÈ†êÊ∏¨Á≥ªÁµ±ÁöÑÊΩõÂäõÔºåË©≤Á≥ªÁµ±ÂèØÁÇ∫ÈßïÈßõËÄÖÂíåÂüéÂ∏ÇË¶èÂäÉËÄÖÊèê‰æõÊõ¥Ê∫ñÁ¢∫ÂíåÂèäÊôÇÁöÑË≥áË®äÔºåÂæûËÄå‰øÉÈÄ≤Êõ¥ÊúâÊïàÁéáÂíåÂèØÊåÅÁ∫åÁöÑÂüéÂ∏ÇÊµÅÂãïÊÄß„ÄÇ</paragraph>

##### **Explicitly Modeling Generality into Self-Supervised Learning**
2405.01053v1 by Jingyao Wang,Wenwen Qiang,Changwen Zheng

The goal of generality in machine learning is to achieve excellent
performance on various unseen tasks and domains. Recently, self-supervised
learning (SSL) has been regarded as an effective method to achieve this goal.
It can learn high-quality representations from unlabeled data and achieve
promising empirical performance on multiple downstream tasks. Existing SSL
methods mainly constrain generality from two aspects: (i) large-scale training
data, and (ii) learning task-level shared knowledge. However, these methods
lack explicit modeling of the SSL generality in the learning objective, and the
theoretical understanding of SSL's generality remains limited. This may cause
SSL models to overfit in data-scarce situations and generalize poorly in the
real world, making it difficult to achieve true generality. To address these
issues, we provide a theoretical definition of generality in SSL and define a
$\sigma$-measurement to help quantify it. Based on this insight, we explicitly
model generality into self-supervised learning and further propose a novel SSL
framework, called GeSSL. It introduces a self-motivated target based on
$\sigma$-measurement, which enables the model to find the optimal update
direction towards generality. Extensive theoretical and empirical evaluations
demonstrate the superior performance of the proposed GeSSL.

ÊëòË¶ÅÔºöÊ©üÂô®Â≠∏Áøí‰∏≠Ê≥õÂåñÁöÑÁõÆÊ®ôÊòØÂú®ÂêÑÁ®ÆÊú™Áü•‰ªªÂãôÂíåÈ†òÂüü‰∏≠Áç≤ÂæóÂÑ™Áï∞ÁöÑÊïàËÉΩ„ÄÇÊúÄËøëÔºåËá™ÊàëÁõ£Áù£ÂºèÂ≠∏Áøí (SSL) Ë¢´Ë¶ñÁÇ∫ÈÅîÊàêÊ≠§ÁõÆÊ®ôÁöÑÊúâÊïàÊñπÊ≥ï„ÄÇÂÆÉÂèØ‰ª•ÂæûÊú™Ê®ôË®òÁöÑË≥áÊñô‰∏≠Â≠∏ÁøíÈ´òÂìÅË≥™ÁöÑË°®ÂæµÔºå‰∏¶Âú®Â§öÂÄã‰∏ãÊ∏∏‰ªªÂãô‰∏≠Áç≤ÂæóÊúâÂâçÊôØÁöÑÁ∂ìÈ©óÊïàËÉΩ„ÄÇÁèæÊúâÁöÑ SSL ÊñπÊ≥ï‰∏ªË¶ÅÂæûÂÖ©ÂÄãÊñπÈù¢Á¥ÑÊùüÊ≥õÂåñÔºö(i) Â§ßË¶èÊ®°Ë®ìÁ∑¥Ë≥áÊñôÔºå‰ª•Âèä (ii) Â≠∏Áøí‰ªªÂãôÂ±§Á¥öÁöÑÂÖ±Áî®Áü•Ë≠ò„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÊñπÊ≥ïÁº∫‰πèÂú®Â≠∏ÁøíÁõÆÊ®ô‰∏≠Â∞ç SSL Ê≥õÂåñÁöÑÊòéÁ¢∫Âª∫Ê®°ÔºåËÄåÂ∞ç SSL Ê≥õÂåñÁöÑÁêÜË´ñÁêÜËß£‰ªçÁÑ∂ÊúâÈôê„ÄÇÈÄôÂèØËÉΩÊúÉÂ∞éËá¥ SSL Ê®°ÂûãÂú®Ë≥áÊñôÁ®ÄÂ∞ëÁöÑÊÉÖÊ≥Å‰∏ãÈÅéÂ∫¶Êì¨ÂêàÔºå‰∏¶Âú®ÁèæÂØ¶‰∏ñÁïå‰∏≠Ê≥õÂåñ‰∏çËâØÔºå‰ΩøÂæóÈõ£‰ª•ÈÅîÂà∞ÁúüÊ≠£ÁöÑÊ≥õÂåñ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÂïèÈ°åÔºåÊàëÂÄëÊèê‰æõ‰∫Ü SSL ‰∏≠Ê≥õÂåñÁöÑÁêÜË´ñÂÆöÁæ©Ôºå‰∏¶ÂÆöÁæ©‰∫Ü‰∏ÄÂÄã $\sigma$-Ê∏¨Èáè‰æÜÂπ´Âä©ÈáèÂåñÂÆÉ„ÄÇÂü∫ÊñºÊ≠§Ë¶ãËß£ÔºåÊàëÂÄëÂ∞áÊ≥õÂåñÊòéÁ¢∫Âª∫Ê®°Âà∞Ëá™ÊàëÁõ£Áù£ÂºèÂ≠∏Áøí‰∏≠Ôºå‰∏¶ÈÄ≤‰∏ÄÊ≠•ÊèêÂá∫‰∏ÄÂÄãÊñ∞Á©éÁöÑ SSL Êû∂ÊßãÔºåÁ®±ÁÇ∫ GeSSL„ÄÇÂÆÉÊ†πÊìö $\sigma$-Ê∏¨ÈáèÂºïÂÖ•‰∫ÜËá™ÊàëÊøÄÂãµÁöÑÁõÆÊ®ôÔºå‰ΩøÊ®°ÂûãËÉΩÂ§†ÊâæÂà∞ÊúùÂêëÊ≥õÂåñÁöÑÊúÄ‰Ω≥Êõ¥Êñ∞ÊñπÂêë„ÄÇÂª£Ê≥õÁöÑÁêÜË´ñÂíåÁ∂ìÈ©óË©ï‰º∞Ë≠âÊòé‰∫ÜÊâÄÊèêÂá∫ÁöÑ GeSSL ÁöÑÂÑ™Áï∞ÊïàËÉΩ„ÄÇ

##### **Few Shot Class Incremental Learning using Vision-Language models**
2405.01040v1 by Anurag Kumar,Chinmay Bharti,Saikat Dutta,Srikrishna Karanam,Biplab Banerjee

Recent advancements in deep learning have demonstrated remarkable performance
comparable to human capabilities across various supervised computer vision
tasks. However, the prevalent assumption of having an extensive pool of
training data encompassing all classes prior to model training often diverges
from real-world scenarios, where limited data availability for novel classes is
the norm. The challenge emerges in seamlessly integrating new classes with few
samples into the training data, demanding the model to adeptly accommodate
these additions without compromising its performance on base classes. To
address this exigency, the research community has introduced several solutions
under the realm of few-shot class incremental learning (FSCIL).
  In this study, we introduce an innovative FSCIL framework that utilizes
language regularizer and subspace regularizer. During base training, the
language regularizer helps incorporate semantic information extracted from a
Vision-Language model. The subspace regularizer helps in facilitating the
model's acquisition of nuanced connections between image and text semantics
inherent to base classes during incremental training. Our proposed framework
not only empowers the model to embrace novel classes with limited data, but
also ensures the preservation of performance on base classes. To substantiate
the efficacy of our approach, we conduct comprehensive experiments on three
distinct FSCIL benchmarks, where our framework attains state-of-the-art
performance.

ÊëòË¶ÅÔºö<paragraph>Ê∑±Â∫¶Â≠∏ÁøíÁöÑÊúÄÊñ∞ÈÄ≤Â±ïÂ∑≤Â±ïÁèæÂá∫ÂçìË∂äÁöÑÊïàËÉΩÔºåÂèØËàáÂêÑÁ®ÆÁõ£Áù£ÂºèÈõªËÖ¶Ë¶ñË¶∫‰ªªÂãôÁöÑ‰∫∫È°ûËÉΩÂäõÁõ∏Â™≤Áæé„ÄÇÁÑ∂ËÄåÔºåÂú®Ê®°ÂûãË®ìÁ∑¥‰πãÂâçÔºåÊôÆÈÅçÂÅáË®≠ÊìÅÊúâÊ∂µËìãÊâÄÊúâÈ°ûÂà•ÁöÑÂª£Ê≥õË®ìÁ∑¥Ë≥áÊñôÈõÜÈÄöÂ∏∏ËàáÂØ¶ÈöõÊÉÖÊ≥Å‰∏çÂêåÔºåËÄåÂØ¶ÈöõÊÉÖÊ≥Å‰∏≠ÔºåÊñ∞È°ûÂà•ÁöÑË≥áÊñôÂèØÁî®ÊÄßÊúâÈôêÊâçÊòØÂ∏∏ÊÖã„ÄÇÊåëÊà∞Âú®ÊñºÂ∞áÂ∞ëÊï∏Ê®£Êú¨ÁöÑÊñ∞È°ûÂà•ÁÑ°Á∏´Êï¥ÂêàÂà∞Ë®ìÁ∑¥Ë≥áÊñô‰∏≠ÔºåË¶ÅÊ±ÇÊ®°ÂûãÈùàÊ¥ªÂÆπÁ¥çÈÄô‰∫õÊñ∞Â¢ûË≥áÊñôÔºåÂêåÊôÇ‰∏çÂΩ±ÈüøÂÖ∂Âú®Âü∫Êú¨È°ûÂà•‰∏äÁöÑÊïàËÉΩ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÁ†îÁ©∂Á§æÁæ§Â∑≤Âú®Â∞ëÊ®£Êú¨È°ûÂà•Â¢ûÈáèÂ≠∏Áøí (FSCIL) ÁöÑÈ†òÂüü‰∏≠ÊèêÂá∫Â§öÁ®ÆËß£Ê±∫ÊñπÊ°à„ÄÇÂú®Êú¨Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÂâµÊñ∞ÁöÑ FSCIL Êû∂ÊßãÔºåÂÆÉÂà©Áî®Ë™ûË®ÄÊ≠£Ë¶èÂåñÂô®ÂíåÂ≠êÁ©∫ÈñìÊ≠£Ë¶èÂåñÂô®„ÄÇÂú®Âü∫Êú¨Ë®ìÁ∑¥ÊúüÈñìÔºåË™ûË®ÄÊ≠£Ë¶èÂåñÂô®ÊúâÂä©ÊñºÁ¥çÂÖ•ÂæûË¶ñË¶∫Ë™ûË®ÄÊ®°Âûã‰∏≠ËêÉÂèñÁöÑË™ûÁæ©Ë≥áË®ä„ÄÇÂ≠êÁ©∫ÈñìÊ≠£Ë¶èÂåñÂô®ÊúâÂä©Êñº‰øÉÈÄ≤Ê®°ÂûãÂú®Â¢ûÈáèË®ìÁ∑¥ÊúüÈñìÁç≤ÂèñÂü∫Êú¨È°ûÂà•‰∏≠ÂΩ±ÂÉèÂíåÊñáÂ≠óË™ûÁæ©‰πãÈñìÁöÑÁ¥∞ÂæÆÈóúËÅØ„ÄÇÊàëÂÄëÊèêÂá∫ÁöÑÊû∂Êßã‰∏çÂÉÖËÉΩËÆìÊ®°ÂûãÊé°Áî®Ë≥áÊñôÊúâÈôêÁöÑÊñ∞È°ûÂà•ÔºåÈÇÑËÉΩÁ¢∫‰øùÂü∫Êú¨È°ûÂà•ÁöÑÊïàËÉΩ„ÄÇÁÇ∫‰∫ÜË≠âÂØ¶ÊàëÂÄëÊñπÊ≥ïÁöÑÊïàÂäõÔºåÊàëÂÄëÂ∞ç‰∏âÂÄã‰∏çÂêåÁöÑ FSCIL Âü∫Ê∫ñÈÄ≤Ë°åÂÖ®Èù¢ÁöÑÂØ¶È©óÔºåÊàëÂÄëÁöÑÊû∂ÊßãÂú®ÂÖ∂‰∏≠Áç≤Âæó‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÊïàËÉΩ„ÄÇ</paragraph>

##### **MVMoE: Multi-Task Vehicle Routing Solver with Mixture-of-Experts**
2405.01029v1 by Jianan Zhou,Zhiguang Cao,Yaoxin Wu,Wen Song,Yining Ma,Jie Zhang,Chi Xu

Learning to solve vehicle routing problems (VRPs) has garnered much
attention. However, most neural solvers are only structured and trained
independently on a specific problem, making them less generic and practical. In
this paper, we aim to develop a unified neural solver that can cope with a
range of VRP variants simultaneously. Specifically, we propose a multi-task
vehicle routing solver with mixture-of-experts (MVMoE), which greatly enhances
the model capacity without a proportional increase in computation. We further
develop a hierarchical gating mechanism for the MVMoE, delivering a good
trade-off between empirical performance and computational complexity.
Experimentally, our method significantly promotes the zero-shot generalization
performance on 10 unseen VRP variants, and showcases decent results on the
few-shot setting and real-world benchmark instances. We further provide
extensive studies on the effect of MoE configurations in solving VRPs.
Surprisingly, the hierarchical gating can achieve much better
out-of-distribution generalization performance. The source code is available
at: https://github.com/RoyalSkye/Routing-MVMoE.

ÊëòË¶ÅÔºöÂ≠∏ÁøíËß£Ê±∫ËªäËºõË∑ØÁ∑öÂïèÈ°å (VRP) Â∑≤ÂÇôÂèóÈóúÊ≥®„ÄÇÁÑ∂ËÄåÔºåÂ§ßÂ§öÊï∏Á•ûÁ∂ìÊ±ÇËß£Âô®ÂÉÖÂú®ÁâπÂÆöÂïèÈ°å‰∏äÁç®Á´ãÂú∞Âª∫ÊßãÂíåË®ìÁ∑¥ÔºåÈÄô‰ΩøÂæóÂÆÉÂÄëËºÉ‰∏çÈÄöÁî®‰∏î‰∏çÂØ¶Áî®„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊó®Âú®ÈñãÁôº‰∏ÄÂÄãÁµ±‰∏ÄÁöÑÁ•ûÁ∂ìÊ±ÇËß£Âô®ÔºåÂèØ‰ª•ÂêåÊôÇÊáâÂ∞ç‰∏ÄÁ≥ªÂàó VRP ËÆäÈ´î„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂÖ∑ÊúâÂ∞àÂÆ∂Ê∑∑Âêà (MVMoE) ÁöÑÂ§ö‰ªªÂãôËªäËºõË∑ØÁ∑öÊ±ÇËß£Âô®ÔºåÂÆÉÊ•µÂ§ßÂú∞Â¢ûÂº∑‰∫ÜÊ®°ÂûãÂÆπÈáèÔºåËÄå‰∏çÊúÉÊàêÊØî‰æãÂú∞Â¢ûÂä†Ë®àÁÆó„ÄÇÊàëÂÄëÈÄ≤‰∏ÄÊ≠•ÁÇ∫ MVMoE ÈñãÁôº‰∫Ü‰∏ÄÂÄãÈöéÂ±§ÂºèÈñòÊéßÊ©üÂà∂ÔºåÂú®Á∂ìÈ©óÊïàËÉΩÂíåË®àÁÆóË§áÈõúÂ∫¶‰πãÈñìÂèñÂæó‰∫ÜËâØÂ•ΩÁöÑÂπ≥Ë°°„ÄÇÂú®ÂØ¶È©ó‰∏≠ÔºåÊàëÂÄëÁöÑÊ®°ÂûãÈ°ØËëóÊèêÂçá‰∫Ü 10 ÂÄãÊú™Ë¶ã VRP ËÆäÈ´îÁöÑÈõ∂Ê¨°Â≠∏ÁøíÊ≥õÂåñÊïàËÉΩÔºå‰∏¶Âú®Â∞ëÊ¨°Â≠∏ÁøíË®≠ÂÆöÂíåÁúüÂØ¶‰∏ñÁïåÂü∫Ê∫ñÂØ¶‰æã‰∏≠Â±ïÁ§∫‰∫ÜËâØÂ•ΩÁöÑÁµêÊûú„ÄÇÊàëÂÄëÈÄ≤‰∏ÄÊ≠•Êèê‰æõ‰∫ÜÈóúÊñº MoE ÈÖçÁΩÆÂú®Ëß£Ê±∫ VRP ‰∏≠ÁöÑÂΩ±ÈüøÁöÑÂª£Ê≥õÁ†îÁ©∂„ÄÇ‰ª§‰∫∫È©öË®ùÁöÑÊòØÔºåÈöéÂ±§ÂºèÈñòÊéßÂèØ‰ª•ÂØ¶ÁèæÊõ¥Â•ΩÁöÑÂàÜ‰ΩàÂ§ñÊ≥õÂåñÊïàËÉΩ„ÄÇÂéüÂßãÁ¢ºÂèØÂú®‰ª•‰∏ãÁ∂≤ÂùÄÂèñÂæóÔºöhttps://github.com/RoyalSkye/Routing-MVMoE„ÄÇ

##### **UniGen: Universal Domain Generalization for Sentiment Classification via Zero-shot Dataset Generation**
2405.01022v2 by Juhwan Choi,Yeonghwa Kim,Seunguk Yu,JungMin Yun,YoungBin Kim

Although pre-trained language models have exhibited great flexibility and
versatility with prompt-based few-shot learning, they suffer from the extensive
parameter size and limited applicability for inference. Recent studies have
suggested that PLMs be used as dataset generators and a tiny task-specific
model be trained to achieve efficient inference. However, their applicability
to various domains is limited because they tend to generate domain-specific
datasets. In this work, we propose a novel approach to universal domain
generalization that generates a dataset regardless of the target domain. This
allows for generalization of the tiny task model to any domain that shares the
label space, thus enhancing the real-world applicability of the dataset
generation paradigm. Our experiments indicate that the proposed method
accomplishes generalizability across various domains while using a parameter
set that is orders of magnitude smaller than PLMs.

ÊëòË¶ÅÔºöÂÑòÁÆ°È†êÂÖàË®ìÁ∑¥Â•ΩÁöÑË™ûË®ÄÊ®°ÂûãÂú®Âü∫ÊñºÊèêÁ§∫ÁöÑÂ∞ëÊ¨°Â≠∏Áøí‰∏≠Â±ïÁèæÂá∫Ê•µÂ§ßÁöÑÂΩàÊÄßÂíåÂ§öÂäüËÉΩÊÄßÔºå‰ΩÜÂÆÉÂÄëÂçªÊúâÂèÉÊï∏Ë¶èÊ®°ÈÅéÊñºÈæêÂ§ß‰∏îÊé®Ë´ñÈÅ©Áî®ÊÄßÊúâÈôêÁöÑÂïèÈ°å„ÄÇÊúÄËøëÁöÑÁ†îÁ©∂Âª∫Ë≠∞ÔºåÂ∞á PLM Áî®‰ΩúË≥áÊñôÈõÜÁî¢ÁîüÂô®Ôºå‰∏¶Ë®ìÁ∑¥‰∏ÄÂÄãÂæÆÂ∞èÁöÑÁâπÂÆöÊñº‰ªªÂãôÁöÑÊ®°Âûã‰ª•ÈÅîÊàêÊúâÊïàÁéáÁöÑÊé®Ë´ñ„ÄÇÁÑ∂ËÄåÔºåÂÆÉÂÄëÂú®ÂêÑÁ®ÆÈ†òÂüüÁöÑÈÅ©Áî®ÊÄßÊúâÈôêÔºåÂõ†ÁÇ∫ÂÆÉÂÄëÂÇæÂêëÊñºÁî¢ÁîüÁâπÂÆöÊñºÈ†òÂüüÁöÑË≥áÊñôÈõÜ„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞ÁöÑÊñπÊ≥ïÔºåÁî®ÊñºÊôÆÈÅçÈ†òÂüüÊ¶ÇÂåñÔºåÂÆÉÊúÉÁî¢Áîü‰∏ÄÂÄãËàáÁõÆÊ®ôÈ†òÂüüÁÑ°ÈóúÁöÑË≥áÊñôÈõÜ„ÄÇÈÄôÂÖÅË®±Â∞áÂæÆÂ∞è‰ªªÂãôÊ®°ÂûãÊ¶ÇÂåñÂà∞‰ªª‰ΩïËàáÊ®ôÁ±§Á©∫ÈñìÁõ∏ÂêåÁöÑÈ†òÂüüÔºåÈÄ≤ËÄåÊèêÂçáË≥áÊñôÈõÜÁî¢ÁîüÁØÑ‰æãÁöÑÁúüÂØ¶‰∏ñÁïåÈÅ©Áî®ÊÄß„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÊåáÂá∫ÔºåÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÂú®‰ΩøÁî®ÊØî PLM Â∞èÂ•ΩÂπæÂÄãÊï∏ÈáèÁ¥öÁöÑÂèÉÊï∏ÈõÜÊôÇÔºåÂ∞±ËÉΩÂú®ÂêÑÁ®ÆÈ†òÂüü‰∏≠ÈÅîÊàêÊ¶ÇÂåñËÉΩÂäõ„ÄÇ

##### **Deep Learning Models in Speech Recognition: Measuring GPU Energy Consumption, Impact of Noise and Model Quantization for Edge Deployment**
2405.01004v1 by Aditya Chakravarty

Recent transformer-based ASR models have achieved word-error rates (WER)
below 4%, surpassing human annotator accuracy, yet they demand extensive server
resources, contributing to significant carbon footprints. The traditional
server-based architecture of ASR also presents privacy concerns, alongside
reliability and latency issues due to network dependencies. In contrast,
on-device (edge) ASR enhances privacy, boosts performance, and promotes
sustainability by effectively balancing energy use and accuracy for specific
applications. This study examines the effects of quantization, memory demands,
and energy consumption on the performance of various ASR model inference on the
NVIDIA Jetson Orin Nano. By analyzing WER and transcription speed across models
using FP32, FP16, and INT8 quantization on clean and noisy datasets, we
highlight the crucial trade-offs between accuracy, speeds, quantization, energy
efficiency, and memory needs. We found that changing precision from fp32 to
fp16 halves the energy consumption for audio transcription across different
models, with minimal performance degradation. A larger model size and number of
parameters neither guarantees better resilience to noise, nor predicts the
energy consumption for a given transcription load. These, along with several
other findings offer novel insights for optimizing ASR systems within energy-
and memory-limited environments, crucial for the development of efficient
on-device ASR solutions. The code and input data needed to reproduce the
results in this article are open sourced are available on
[https://github.com/zzadiues3338/ASR-energy-jetson].

ÊëòË¶ÅÔºö<paragraph>ÊúÄËøëÁöÑÂü∫‰∫é Transformer ÁöÑ ASR Ê®°ÂûãÂ∑≤Â∞ÜËØçÈîôËØØÁéá (WER) ÈôçËá≥ 4% ‰ª•‰∏ãÔºåË∂ÖË∂ä‰∫Ü‰∫∫Á±ªÊ≥®ÈáäÂëòÁöÑÂáÜÁ°ÆÊÄßÔºå‰ΩÜÂÆÉ‰ª¨ÈúÄË¶ÅÂ§ßÈáèÁöÑÊúçÂä°Âô®ËµÑÊ∫êÔºå‰ªéËÄåÂØºËá¥Â∑®Â§ßÁöÑÁ¢≥Ë∂≥Ëøπ„ÄÇASR ÁöÑ‰º†ÁªüÂü∫‰∫éÊúçÂä°Âô®ÁöÑÊû∂ÊûÑËøòÂ≠òÂú®ÈöêÁßÅÈóÆÈ¢òÔºå‰ª•ÂèäÁî±‰∫éÁΩëÁªú‰æùËµñÊÄßÂØºËá¥ÁöÑÂèØÈù†ÊÄßÂíåÂª∂ËøüÈóÆÈ¢ò„ÄÇÁõ∏ÊØî‰πã‰∏ãÔºåËÆæÂ§áÁ´Ø (ËæπÁºò) ASR Â¢ûÂº∫‰∫ÜÈöêÁßÅÔºåÊèêÈ´ò‰∫ÜÊÄßËÉΩÔºåÂπ∂ÈÄöËøáÊúâÊïàÂπ≥Ë°°ÁâπÂÆöÂ∫îÁî®Á®ãÂ∫èÁöÑËÉΩËÄóÂíåÂáÜÁ°ÆÊÄßÊù•‰øÉËøõÂèØÊåÅÁª≠ÊÄß„ÄÇÊú¨Á†îÁ©∂Êé¢ËÆ®‰∫ÜÈáèÂåñ„ÄÅÂÜÖÂ≠òÈúÄÊ±ÇÂíåËÉΩËÄóÂØπ NVIDIA Jetson Orin Nano ‰∏äÂêÑÁßç ASR Ê®°ÂûãÊé®ÁêÜÊÄßËÉΩÁöÑÂΩ±Âìç„ÄÇÈÄöËøáÂàÜÊûê‰ΩøÁî® FP32„ÄÅFP16 Âíå INT8 ÈáèÂåñÂú®Âπ≤ÂáÄÂíåÂòàÊùÇÊï∞ÊçÆÈõÜ‰∏äÁöÑÊ®°ÂûãÁöÑ WER ÂíåËΩ¨ÂΩïÈÄüÂ∫¶ÔºåÊàë‰ª¨ÈáçÁÇπ‰ªãÁªç‰∫ÜÂáÜÁ°ÆÊÄß„ÄÅÈÄüÂ∫¶„ÄÅÈáèÂåñ„ÄÅËÉΩÊïàÂíåÂÜÖÂ≠òÈúÄÊ±Ç‰πãÈó¥ÁöÑÂÖ≥ÈîÆÊùÉË°°„ÄÇÊàë‰ª¨ÂèëÁé∞ÔºåÂØπ‰∫é‰∏çÂêåÁöÑÊ®°ÂûãÔºåÂ∞ÜÁ≤æÂ∫¶‰ªé fp32 ËΩ¨Êç¢‰∏∫ fp16 ÂèØÂ∞ÜÈü≥È¢ëËΩ¨ÂΩïÁöÑËÉΩËÄóÂáèÂçäÔºåÂêåÊó∂ÊÄßËÉΩ‰∏ãÈôçÂæàÂ∞è„ÄÇËæÉÂ§ßÁöÑÊ®°ÂûãÂ§ßÂ∞èÂíåÂèÇÊï∞Êï∞ÈáèÊó¢‰∏çËÉΩ‰øùËØÅÊõ¥Â•ΩÁöÑÊäóÂô™ÊÄßÔºå‰πü‰∏çËÉΩÈ¢ÑÊµãÁªôÂÆöËΩ¨ÂΩïË¥üËΩΩÁöÑËÉΩËÄó„ÄÇËøô‰∫õ‰ª•ÂèäÂÖ∂‰ªñ‰∏Ä‰∫õÂèëÁé∞‰∏∫Âú®ËÉΩËÄóÂíåÂÜÖÂ≠òÂèóÈôêÁöÑÁéØÂ¢É‰∏≠‰ºòÂåñ ASR Á≥ªÁªüÊèê‰æõ‰∫ÜÊñ∞ÁöÑËßÅËß£ÔºåËøôÂØπ‰∫éÂºÄÂèëÈ´òÊïàÁöÑËÆæÂ§áÁ´Ø ASR Ëß£ÂÜ≥ÊñπÊ°àËá≥ÂÖ≥ÈáçË¶Å„ÄÇÊú¨Êñá‰∏≠Â§çÂà∂ÁªìÊûúÊâÄÈúÄÁöÑ‰ª£Á†ÅÂíåËæìÂÖ•Êï∞ÊçÆÊòØÂºÄÊ∫êÁöÑÔºåÂèØÂú® [https://github.com/zzadiues3338/ASR-energy-jetson] ‰∏äËé∑Âæó„ÄÇ</paragraph>

##### **The IgboAPI Dataset: Empowering Igbo Language Technologies through Multi-dialectal Enrichment**
2405.00997v1 by Chris Chinenye Emezue,Ifeoma Okoh,Chinedu Mbonu,Chiamaka Chukwuneke,Daisy Lal,Ignatius Ezeani,Paul Rayson,Ijemma Onwuzulike,Chukwuma Okeke,Gerald Nweya,Bright Ogbonna,Chukwuebuka Oraegbunam,Esther Chidinma Awo-Ndubuisi,Akudo Amarachukwu Osuagwu,Obioha Nmezi

The Igbo language is facing a risk of becoming endangered, as indicated by a
2025 UNESCO study. This highlights the need to develop language technologies
for Igbo to foster communication, learning and preservation. To create robust,
impactful, and widely adopted language technologies for Igbo, it is essential
to incorporate the multi-dialectal nature of the language. The primary obstacle
in achieving dialectal-aware language technologies is the lack of comprehensive
dialectal datasets. In response, we present the IgboAPI dataset, a
multi-dialectal Igbo-English dictionary dataset, developed with the aim of
enhancing the representation of Igbo dialects. Furthermore, we illustrate the
practicality of the IgboAPI dataset through two distinct studies: one focusing
on Igbo semantic lexicon and the other on machine translation. In the semantic
lexicon project, we successfully establish an initial Igbo semantic lexicon for
the Igbo semantic tagger, while in the machine translation study, we
demonstrate that by finetuning existing machine translation systems using the
IgboAPI dataset, we significantly improve their ability to handle dialectal
variations in sentences.

ÊëòË¶ÅÔºöIgbo Ë™ûË®ÄÊ≠£Èù¢Ëá®ÁÄïËá®ÊªÖÁµïÁöÑÈ¢®Èö™ÔºåÊ≠£Â¶Ç 2025 Âπ¥ËÅØÂêàÂúãÊïôÁßëÊñáÁµÑÁπîÁöÑÁ†îÁ©∂ÊâÄÁ§∫„ÄÇÈÄôÁ™ÅÈ°Ø‰∫ÜÁÇ∫ Igbo Ë™ûË®ÄÈñãÁôºË™ûË®ÄÊäÄË°ì‰ª•‰øÉÈÄ≤Ê∫ùÈÄö„ÄÅÂ≠∏ÁøíÂíå‰øùÂ≠òÁöÑÂøÖË¶ÅÊÄß„ÄÇÁÇ∫ Igbo Ë™ûË®ÄÂâµÂª∫Âº∑Â§ß„ÄÅÊúâÂΩ±ÈüøÂäõÂíåÂª£Ê≥õÊé°Áî®ÁöÑË™ûË®ÄÊäÄË°ìÔºåÂøÖÈ†àÁ¥çÂÖ•Ë™ûË®ÄÁöÑÂ§öÊñπË®ÄÊÄßË≥™„ÄÇÂØ¶ÁèæÊñπË®ÄÊÑüÁü•Ë™ûË®ÄÊäÄË°ìÁöÑ‰∏ªË¶ÅÈöúÁ§ôÊòØÁº∫‰πèÂÖ®Èù¢ÁöÑÊñπË®ÄÊï∏ÊìöÈõÜ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∫Ü IgboAPI Êï∏ÊìöÈõÜÔºåÈÄôÊòØ‰∏ÄÂÄãÂ§öÊñπË®Ä Igbo-English Ë©ûÂÖ∏Êï∏ÊìöÈõÜÔºåÊó®Âú®Â¢ûÂº∑ Igbo ÊñπË®ÄÁöÑË°®Á§∫„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÈÄöÈÅéÂÖ©È†Ö‰∏çÂêåÁöÑÁ†îÁ©∂‰æÜË™™Êòé IgboAPI Êï∏ÊìöÈõÜÁöÑÂØ¶Áî®ÊÄßÔºö‰∏ÄÈ†ÖÂ∞àÊ≥®Êñº Igbo Ë™ûÁæ©Ë©ûÂΩôÔºåÂè¶‰∏ÄÈ†ÖÂ∞àÊ≥®ÊñºÊ©üÂô®ÁøªË≠Ø„ÄÇÂú®Ë™ûÁæ©Ë©ûÂΩôÈ†ÖÁõÆ‰∏≠ÔºåÊàëÂÄëÊàêÂäüÂú∞ÁÇ∫ Igbo Ë™ûÁæ©Ê®ôË®òÂô®Âª∫Á´ã‰∫Ü‰∏ÄÂÄãÂàùÂßãÁöÑ Igbo Ë™ûÁæ©Ë©ûÂΩôÔºåËÄåÂú®Ê©üÂô®ÁøªË≠ØÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄëË≠âÊòé‰∫ÜÈÄöÈÅé‰ΩøÁî® IgboAPI Êï∏ÊìöÈõÜÂæÆË™øÁèæÊúâÁöÑÊ©üÂô®ÁøªË≠ØÁ≥ªÁµ±ÔºåÊàëÂÄëÂèØ‰ª•È°ØËëóÊèêÈ´òÂÆÉÂÄëËôïÁêÜÂè•Â≠ê‰∏≠ÊñπË®ÄËÆäÂåñÁöÑËÉΩÂäõ„ÄÇ

##### **Context-Aware Clustering using Large Language Models**
2405.00988v1 by Sindhu Tipirneni,Ravinarayana Adkathimar,Nurendra Choudhary,Gaurush Hiranandani,Rana Ali Amjad,Vassilis N. Ioannidis,Changhe Yuan,Chandan K. Reddy

Despite the remarkable success of Large Language Models (LLMs) in text
understanding and generation, their potential for text clustering tasks remains
underexplored. We observed that powerful closed-source LLMs provide good
quality clusterings of entity sets but are not scalable due to the massive
compute power required and the associated costs. Thus, we propose CACTUS
(Context-Aware ClusTering with aUgmented triplet losS), a systematic approach
that leverages open-source LLMs for efficient and effective supervised
clustering of entity subsets, particularly focusing on text-based entities.
Existing text clustering methods fail to effectively capture the context
provided by the entity subset. Moreover, though there are several language
modeling based approaches for clustering, very few are designed for the task of
supervised clustering. This paper introduces a novel approach towards
clustering entity subsets using LLMs by capturing context via a scalable
inter-entity attention mechanism. We propose a novel augmented triplet loss
function tailored for supervised clustering, which addresses the inherent
challenges of directly applying the triplet loss to this problem. Furthermore,
we introduce a self-supervised clustering task based on text augmentation
techniques to improve the generalization of our model. For evaluation, we
collect ground truth clusterings from a closed-source LLM and transfer this
knowledge to an open-source LLM under the supervised clustering framework,
allowing a faster and cheaper open-source model to perform the same task.
Experiments on various e-commerce query and product clustering datasets
demonstrate that our proposed approach significantly outperforms existing
unsupervised and supervised baselines under various external clustering
evaluation metrics.

ÊëòË¶ÅÔºöÂÑòÁÆ°Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®ÊñáÂ≠óÁêÜËß£ÂíåÁîüÊàêÊñπÈù¢ÂèñÂæó‰∫ÜÈ°ØËëóÁöÑÊàêÂäüÔºå‰ΩÜÂÆÉÂÄëÂú®ÊñáÂ≠óÂàÜÁæ§‰ªªÂãô‰∏≠ÁöÑÊΩõÂäõ‰ªçÊú™Ë¢´ÂÖÖÂàÜÊé¢Á¥¢„ÄÇÊàëÂÄëËßÄÂØüÂà∞ÂäüËÉΩÂº∑Â§ßÁöÑÈñâÊ∫ê LLM ÂèØ‰ª•Êèê‰æõÂØ¶È´îÈõÜÂêàÁöÑÈ´òÂìÅË≥™ÂàÜÁæ§Ôºå‰ΩÜÁî±ÊñºÈúÄË¶ÅÂ§ßÈáèÁöÑÈÅãÁÆóËÉΩÂäõÂíåÁõ∏ÈóúÊàêÊú¨ÔºåÂõ†Ê≠§ÁÑ°Ê≥ïÊì¥Â±ï„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü CACTUSÔºà‰ΩøÁî®Êì¥Â¢û‰∏âÂÖÉÁµÑÊêçÂ§±ÁöÑ‰∏ä‰∏ãÊñáÊÑüÁü•ÂàÜÁæ§ÔºâÔºåÈÄôÊòØ‰∏ÄÁ®ÆÁ≥ªÁµ±ÂåñÊñπÊ≥ïÔºåÂÆÉÂà©Áî®ÈñãÊ∫ê LLM ‰æÜÊúâÊïàÁéá‰∏îÊúâÊïàÂú∞Áõ£Áù£ÂØ¶È´îÂ≠êÈõÜÁöÑÂàÜÁæ§ÔºåÁâπÂà•ÊòØÂ∞àÊ≥®ÊñºÂü∫ÊñºÊñáÂ≠óÁöÑÂØ¶È´î„ÄÇÁèæÊúâÁöÑÊñáÂ≠óÂàÜÁæ§ÊñπÊ≥ïÁÑ°Ê≥ïÊúâÊïàÊì∑ÂèñÂØ¶È´îÂ≠êÈõÜÊèê‰æõÁöÑ‰∏ä‰∏ãÊñá„ÄÇÊ≠§Â§ñÔºåÂÑòÁÆ°ÊúâÂπæÁ®ÆÂü∫ÊñºË™ûË®ÄÂª∫Ê®°ÁöÑÂàÜÁæ§ÊñπÊ≥ïÔºå‰ΩÜÂæàÂ∞ëÊúâÊñπÊ≥ïÊòØÈáùÂ∞çÁõ£Áù£ÂàÜÁæ§‰ªªÂãôËÄåË®≠Ë®àÁöÑ„ÄÇÊú¨Êñá‰ªãÁ¥π‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÊñπÊ≥ïÔºåÈÄèÈÅéÂèØÊì¥Â±ïÁöÑÂØ¶È´îÈñìÊ≥®ÊÑèÂäõÊ©üÂà∂Êì∑Âèñ‰∏ä‰∏ãÊñáÔºå‰æÜ‰ΩøÁî® LLM ÂàÜÁæ§ÂØ¶È´îÂ≠êÈõÜ„ÄÇÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊñ∞Á©éÁöÑÊì¥Â¢û‰∏âÂÖÉÁµÑÊêçÂ§±ÂáΩÊï∏ÔºåÂ∞àÈñÄÈáùÂ∞çÁõ£Áù£ÂàÜÁæ§ÔºåÂÆÉËß£Ê±∫‰∫ÜÂ∞á‰∏âÂÖÉÁµÑÊêçÂ§±Áõ¥Êé•ÊáâÁî®ÊñºÊ≠§ÂïèÈ°åÁöÑÂõ∫ÊúâÊåëÊà∞„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÂü∫ÊñºÊñáÂ≠óÊì¥ÂÖÖÊäÄË°ìÁöÑËá™ÊàëÁõ£Áù£ÂàÜÁæ§‰ªªÂãôÔºå‰ª•ÊîπÂñÑÊàëÂÄëÊ®°ÂûãÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇÁÇ∫‰∫ÜË©ï‰º∞ÔºåÊàëÂÄëÂæûÈñâÊ∫ê LLM Êî∂ÈõÜÂú∞Èù¢ÁúüÂØ¶ÂàÜÁæ§Ôºå‰∏¶Âú®Áõ£Áù£ÂàÜÁæ§Êû∂Êßã‰∏ãÂ∞áÊ≠§Áü•Ë≠òËΩâÁßªÂà∞ÈñãÊ∫ê LLMÔºåÂÖÅË®±Êõ¥Âø´ÈÄü‰∏îÊõ¥‰æøÂÆúÁöÑÈñãÊ∫êÊ®°ÂûãÂü∑Ë°åÁõ∏ÂêåÁöÑ‰ªªÂãô„ÄÇÂú®ÂêÑÁ®ÆÈõªÂ≠êÂïÜÂãôÊü•Ë©¢ÂíåÁî¢ÂìÅÂàÜÁæ§Ë≥áÊñôÈõÜ‰∏äÁöÑÂØ¶È©óË°®ÊòéÔºåÊàëÂÄëÊèêÂá∫ÁöÑÊñπÊ≥ïÂú®ÂêÑÁ®ÆÂ§ñÈÉ®ÂàÜÁæ§Ë©ï‰º∞ÊåáÊ®ô‰∏ãÔºåÊòéÈ°ØÂÑ™ÊñºÁèæÊúâÁöÑÁÑ°Áõ£Áù£ÂíåÁõ£Áù£Âü∫Ê∫ñ„ÄÇ

##### **Progressive Feedforward Collapse of ResNet Training**
2405.00985v1 by Sicong Wang,Kuo Gai,Shihua Zhang

Neural collapse (NC) is a simple and symmetric phenomenon for deep neural
networks (DNNs) at the terminal phase of training, where the last-layer
features collapse to their class means and form a simplex equiangular tight
frame aligning with the classifier vectors. However, the relationship of the
last-layer features to the data and intermediate layers during training remains
unexplored. To this end, we characterize the geometry of intermediate layers of
ResNet and propose a novel conjecture, progressive feedforward collapse (PFC),
claiming the degree of collapse increases during the forward propagation of
DNNs. We derive a transparent model for the well-trained ResNet according to
that ResNet with weight decay approximates the geodesic curve in Wasserstein
space at the terminal phase. The metrics of PFC indeed monotonically decrease
across depth on various datasets. We propose a new surrogate model, multilayer
unconstrained feature model (MUFM), connecting intermediate layers by an
optimal transport regularizer. The optimal solution of MUFM is inconsistent
with NC but is more concentrated relative to the input data. Overall, this
study extends NC to PFC to model the collapse phenomenon of intermediate layers
and its dependence on the input data, shedding light on the theoretical
understanding of ResNet in classification problems.

ÊëòË¶ÅÔºöÁ•ûÁ∂ìÂ¥©ÊΩ∞ (NC) ÊòØÊ∑±Â∫¶Á•ûÁ∂ìÁ∂≤Ë∑Ø (DNN) Âú®Ë®ìÁ∑¥ÁµÇÁ´ØÈöéÊÆµÁöÑ‰∏ÄÁ®ÆÁ∞°ÂñÆ‰∏îÂ∞çÁ®±ÁöÑÁèæË±°ÔºåÂÖ∂‰∏≠ÊúÄÂæå‰∏ÄÂ±§ÁöÑÁâπÂæµÊúÉÂ¥©ÊΩ∞ÊàêÂÆÉÂÄëÁöÑÈ°ûÂà•Âπ≥ÂùáÂÄºÔºå‰∏¶ÂΩ¢Êàê‰∏ÄÂÄãËàáÂàÜÈ°ûÂô®ÂêëÈáèÂ∞çÈΩäÁöÑÂñÆÁ¥îÁ≠âËßíÁ∑äÂØÜÊ°ÜÊû∂„ÄÇÁÑ∂ËÄåÔºåÊúÄÂæå‰∏ÄÂ±§ÁâπÂæµËàáË≥áÊñôÂíåË®ìÁ∑¥ÊúüÈñìÁöÑ‰∏≠ÈñìÂ±§ÁöÑÈóú‰øÇ‰ªçÊú™Êé¢Ë®é„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÊèèËø∞‰∫Ü ResNet ‰∏≠ÈñìÂ±§ÁöÑÂπæ‰ΩïÂΩ¢ÁãÄÔºå‰∏¶ÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊñ∞ÁöÑÁåúÊÉ≥ÔºåÂç≥Êº∏ÈÄ≤ÂâçÈ•ãÂ¥©ÊΩ∞ (PFC)ÔºåËÅ≤Á®±Â¥©ÊΩ∞ÁöÑÁ®ãÂ∫¶ÊúÉÂú® DNN ÁöÑÂâçÂêëÂÇ≥Êí≠ÈÅéÁ®ã‰∏≠Â¢ûÂä†„ÄÇÊ†πÊìöÊ¨äÈáçË°∞Ê∏õÁöÑ ResNet Ëøë‰ººÊñºÂú®ÁµÇÁ´ØÈöéÊÆµÁöÑ Wasserstein Á©∫Èñì‰∏≠ÁöÑÊ∏¨Âú∞Á∑öÊõ≤Á∑öÔºåÊàëÂÄëÁÇ∫Ë®ìÁ∑¥ËâØÂ•ΩÁöÑ ResNet Êé®Â∞é‰∫Ü‰∏ÄÂÄãÈÄèÊòéÊ®°Âûã„ÄÇPFC ÁöÑÊåáÊ®ôÁ¢∫ÂØ¶Âú®ÂêÑÁ®ÆË≥áÊñôÈõÜ‰∏äÈö®ËëóÊ∑±Â∫¶ÂñÆË™øÈÅûÊ∏õ„ÄÇÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊñ∞ÁöÑÊõø‰ª£Ê®°ÂûãÔºåÂ§öÂ±§ÁÑ°Á¥ÑÊùüÁâπÂæµÊ®°Âûã (MUFM)ÔºåÈÄöÈÅéÊúÄÂÑ™ÂÇ≥Ëº∏Ê≠£ÂâáÂåñÂô®ÈÄ£Êé•‰∏≠ÈñìÂ±§„ÄÇMUFM ÁöÑÊúÄÂÑ™Ëß£Ëàá NC ‰∏ç‰∏ÄËá¥Ôºå‰ΩÜÁõ∏Â∞çÊñºËº∏ÂÖ•Ë≥áÊñôÊõ¥ÈõÜ‰∏≠„ÄÇÁ∏ΩÁöÑ‰æÜË™™ÔºåÈÄôÈ†ÖÁ†îÁ©∂Â∞á NC Êì¥Â±ïÂà∞ PFC ‰ª•Ê®°Êì¨‰∏≠ÈñìÂ±§ÁöÑÂ¥©ÊΩ∞ÁèæË±°ÂèäÂÖ∂Â∞çËº∏ÂÖ•Ë≥áÊñôÁöÑ‰æùË≥¥ÊÄßÔºåÁÇ∫ÂàÜÈ°ûÂïèÈ°å‰∏≠ ResNet ÁöÑÁêÜË´ñÁêÜËß£Êèê‰æõ‰∫ÜÂïüÁ§∫„ÄÇ

##### **On the Evaluation of Machine-Generated Reports**
2405.00982v1 by James Mayfield,Eugene Yang,Dawn Lawrie,Sean MacAvaney,Paul McNamee,Douglas W. Oard,Luca Soldaini,Ian Soboroff,Orion Weller,Efsun Kayi,Kate Sanders,Marc Mason,Noah Hibbler

Large Language Models (LLMs) have enabled new ways to satisfy information
needs. Although great strides have been made in applying them to settings like
document ranking and short-form text generation, they still struggle to compose
complete, accurate, and verifiable long-form reports. Reports with these
qualities are necessary to satisfy the complex, nuanced, or multi-faceted
information needs of users. In this perspective paper, we draw together
opinions from industry and academia, and from a variety of related research
areas, to present our vision for automatic report generation, and -- critically
-- a flexible framework by which such reports can be evaluated. In contrast
with other summarization tasks, automatic report generation starts with a
detailed description of an information need, stating the necessary background,
requirements, and scope of the report. Further, the generated reports should be
complete, accurate, and verifiable. These qualities, which are desirable -- if
not required -- in many analytic report-writing settings, require rethinking
how to build and evaluate systems that exhibit these qualities. To foster new
efforts in building these systems, we present an evaluation framework that
draws on ideas found in various evaluations. To test completeness and accuracy,
the framework uses nuggets of information, expressed as questions and answers,
that need to be part of any high-quality generated report. Additionally,
evaluation of citations that map claims made in the report to their source
documents ensures verifiability.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ËÆìÊªøË∂≥Ë≥áË®äÈúÄÊ±ÇÊúâ‰∫ÜÊñ∞ÊñπÊ≥ï„ÄÇÂÑòÁÆ°Âú®Â∞áÂÖ∂ÊáâÁî®ÊñºÊñá‰ª∂ÊéíÂêçÂíåÁ∞°Áü≠ÊñáÂ≠óÁî¢ÁîüÁ≠âË®≠ÂÆöÊñπÈù¢Â∑≤ÂèñÂæóÈï∑Ë∂≥ÈÄ≤Â±ïÔºå‰ΩÜÂÆÉÂÄëÂú®Êí∞ÂØ´ÂÆåÊï¥„ÄÅÊ∫ñÁ¢∫‰∏îÂèØÈ©óË≠âÁöÑÈï∑ÁØáÂ†±ÂëäÊñπÈù¢‰ªçÈù¢Ëá®Èõ£È°å„ÄÇÂÖ∑ÂÇôÈÄô‰∫õÁâπË≥™ÁöÑÂ†±ÂëäÂ∞çÊñºÊªøË∂≥‰ΩøÁî®ËÄÖÁöÑË§áÈõú„ÄÅÁ¥∞Á∑ªÊàñÂ§öÈù¢ÂêëË≥áË®äÈúÄÊ±ÇÊòØÂøÖË¶ÅÁöÑ„ÄÇÂú®Êú¨ËßÄÈªûË´ñÊñá‰∏≠ÔºåÊàëÂÄëÂΩôÊï¥‰∫ÜÊ•≠ÁïåÂíåÂ≠∏Ë°ìÁïå‰ª•ÂèäÂêÑÁ®ÆÁõ∏ÈóúÁ†îÁ©∂È†òÂüüÁöÑÊÑèË¶ãÔºå‰ª•ÊèêÂá∫ÊàëÂÄëÂ∞çËá™ÂãïÂ†±ÂëäÁî¢ÁîüÁöÑÈ°òÊôØÔºå‰ª•ÂèäÊõ¥ÈáçË¶ÅÁöÑÊòØÔºå‰∏ÄÂÄãÂèØ‰ª•Ë©ï‰º∞Ê≠§È°ûÂ†±ÂëäÁöÑÂΩàÊÄßÊû∂Êßã„ÄÇËàáÂÖ∂‰ªñÊëòË¶Å‰ªªÂãô‰∏çÂêåÔºåËá™ÂãïÂ†±ÂëäÁî¢ÁîüÂßãÊñºÂ∞çË≥áË®äÈúÄÊ±ÇÁöÑË©≥Á¥∞Ë™™ÊòéÔºåË™™ÊòéÂ†±ÂëäÁöÑÂøÖË¶ÅËÉåÊôØ„ÄÅÈúÄÊ±ÇÂíåÁØÑÂúç„ÄÇÊ≠§Â§ñÔºåÁî¢ÁîüÁöÑÂ†±ÂëäÊáâÂÆåÊï¥„ÄÅÊ∫ñÁ¢∫‰∏îÂèØÈ©óË≠â„ÄÇÈÄô‰∫õÂú®Ë®±Â§öÂàÜÊûêÂ†±ÂëäÊí∞ÂØ´Ë®≠ÂÆö‰∏≠ÁêÜÊÉ≥ÔºàÂ¶ÇÊûú‰∏çÊòØÂøÖÈúÄÁöÑË©±ÔºâÁöÑÁâπË≥™ÔºåÈúÄË¶ÅÈáçÊñ∞ÊÄùËÄÉÂ¶Ç‰ΩïÂª∫ÊßãÂíåË©ï‰º∞Â±ïÁèæÈÄô‰∫õÁâπË≥™ÁöÑÁ≥ªÁµ±„ÄÇÁÇ∫‰∫Ü‰øÉÈÄ≤Âª∫ÊßãÈÄô‰∫õÁ≥ªÁµ±ÁöÑÊñ∞Âä™ÂäõÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãË©ï‰º∞Êû∂ÊßãÔºåË©≤Êû∂ÊßãÊ±≤Âèñ‰∫ÜÂêÑÁ®ÆË©ï‰º∞‰∏≠ÁöÑÊßãÊÉ≥„ÄÇÁÇ∫‰∫ÜÊ∏¨Ë©¶ÂÆåÊï¥ÊÄßÂíåÊ∫ñÁ¢∫ÊÄßÔºåË©≤Êû∂Êßã‰ΩøÁî®‰ª•ÂïèÁ≠îÂΩ¢ÂºèË°®ÈÅîÁöÑË≥áË®äÁâáÊÆµÔºåÈÄô‰∫õÁâáÊÆµÂøÖÈ†àÊòØ‰ªª‰ΩïÈ´òÂìÅË≥™Áî¢Âá∫Â†±ÂëäÁöÑ‰∏ÄÈÉ®ÂàÜ„ÄÇÊ≠§Â§ñÔºåË©ï‰º∞ÂºïÊñáÔºàÂ∞áÂ†±Âëä‰∏≠ÊèêÂá∫ÁöÑ‰∏ªÂºµÂ∞çÊáâÂà∞ÂÖ∂‰æÜÊ∫êÊñá‰ª∂ÔºâÂèØÁ¢∫‰øùÂèØÈ©óË≠âÊÄß„ÄÇ

##### **Bayesian Optimization with LLM-Based Acquisition Functions for Natural Language Preference Elicitation**
2405.00981v1 by David Eric Austin,Anton Korikov,Armin Toroghi,Scott Sanner

Designing preference elicitation (PE) methodologies that can quickly
ascertain a user's top item preferences in a cold-start setting is a key
challenge for building effective and personalized conversational recommendation
(ConvRec) systems. While large language models (LLMs) constitute a novel
technology that enables fully natural language (NL) PE dialogues, we
hypothesize that monolithic LLM NL-PE approaches lack the multi-turn,
decision-theoretic reasoning required to effectively balance the NL exploration
and exploitation of user preferences towards an arbitrary item set. In
contrast, traditional Bayesian optimization PE methods define theoretically
optimal PE strategies, but fail to use NL item descriptions or generate NL
queries, unrealistically assuming users can express preferences with direct
item ratings and comparisons. To overcome the limitations of both approaches,
we formulate NL-PE in a Bayesian Optimization (BO) framework that seeks to
generate NL queries which actively elicit natural language feedback to reduce
uncertainty over item utilities to identify the best recommendation. We
demonstrate our framework in a novel NL-PE algorithm, PEBOL, which uses Natural
Language Inference (NLI) between user preference utterances and NL item
descriptions to maintain preference beliefs and BO strategies such as Thompson
Sampling (TS) and Upper Confidence Bound (UCB) to guide LLM query generation.
We numerically evaluate our methods in controlled experiments, finding that
PEBOL achieves up to 131% improvement in MAP@10 after 10 turns of cold start
NL-PE dialogue compared to monolithic GPT-3.5, despite relying on a much
smaller 400M parameter NLI model for preference inference.

ÊëòË¶ÅÔºö<paragraph>Ë®≠Ë®àÂÅèÂ•ΩÂºïÂ∞éÔºàPEÔºâÊñπÊ≥ïÔºåÂèØ‰ª•Âú®ÂÜ∑ÂïüÂãïË®≠ÂÆö‰∏≠Âø´ÈÄüÁ¢∫ÂÆö‰ΩøÁî®ËÄÖÁöÑÈ¶ñË¶ÅÈ†ÖÁõÆÂÅèÂ•ΩÔºåÈÄôÂ∞çÊñºÂª∫Á´ãÊúâÊïà‰∏îÂÄã‰∫∫ÂåñÁöÑÂ∞çË©±ÂºèÊé®Ëñ¶ÔºàConvRecÔºâÁ≥ªÁµ±ÊòØ‰∏ÄÈ†ÖÈóúÈçµÊåëÊà∞„ÄÇÈõñÁÑ∂Â§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâÊßãÊàê‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÊäÄË°ìÔºåÂèØ‰ª•ÂØ¶ÁèæÂÆåÂÖ®Ëá™ÁÑ∂Ë™ûË®ÄÔºàNLÔºâPE Â∞çË©±ÔºåÊàëÂÄëÂÅáË®≠ÂñÆÈ´î LLM NL-PE ÊñπÊ≥ïÁº∫‰πèÂ§öËº™„ÄÅÊ±∫Á≠ñÁêÜË´ñÊé®ÁêÜÔºåËÄåÈÄôÂ∞çÊñºÊúâÊïàÂπ≥Ë°° NL Êé¢Á¥¢ÂíåÂà©Áî®‰ΩøÁî®ËÄÖÁöÑÂÅèÂ•Ω‰ª•ÈáùÂ∞ç‰ªªÊÑèÈ†ÖÁõÆÈõÜÊòØÂøÖË¶ÅÁöÑ„ÄÇÁõ∏ÊØî‰πã‰∏ãÔºåÂÇ≥Áµ±Ë≤ùÊ∞èÊúÄ‰Ω≥Âåñ PE ÊñπÊ≥ïÂÆöÁæ©‰∫ÜÁêÜË´ñ‰∏äÊúÄ‰Ω≥ÁöÑ PE Á≠ñÁï•Ôºå‰ΩÜÁÑ°Ê≥ï‰ΩøÁî® NL È†ÖÁõÆÊèèËø∞ÊàñÁî¢Áîü NL Êü•Ë©¢Ôºå‰∏çÂàáÂØ¶ÈöõÂú∞ÂÅáË®≠‰ΩøÁî®ËÄÖÂèØ‰ª•Áî®Áõ¥Êé•ÁöÑÈ†ÖÁõÆË©ïÂàÜÂíåÊØîËºÉ‰æÜË°®ÈÅîÂÅèÂ•Ω„ÄÇÁÇ∫‰∫ÜÂÖãÊúçÈÄôÂÖ©Á®ÆÊñπÊ≥ïÁöÑÈôêÂà∂ÔºåÊàëÂÄëÂú®Ë≤ùÊ∞èÊúÄ‰Ω≥ÂåñÔºàBOÔºâÊû∂Êßã‰∏≠Âà∂ÂÆö NL-PEÔºåË©≤Êû∂ÊßãÊó®Âú®Áî¢Áîü NL Êü•Ë©¢Ôºå‰∏ªÂãïÂºïÁôºËá™ÁÑ∂Ë™ûË®ÄÂõûÈ•ã‰ª•Ê∏õÂ∞ëÈ†ÖÁõÆÊïàÁî®ÁöÑ‰∏çÁ¢∫ÂÆöÊÄßÔºåÈÄ≤ËÄåÊâæÂá∫ÊúÄ‰Ω≥Êé®Ëñ¶„ÄÇÊàëÂÄëÂú®‰∏ÄÂÄãÊñ∞Á©éÁöÑ NL-PE ÊºîÁÆóÊ≥ï PEBOL ‰∏≠Â±ïÁ§∫ÊàëÂÄëÁöÑÊû∂ÊßãÔºåÂÆÉ‰ΩøÁî®‰ΩøÁî®ËÄÖÂÅèÂ•ΩË™ûÂè•Âíå NL È†ÖÁõÆÊèèËø∞‰πãÈñìÁöÑËá™ÁÑ∂Ë™ûË®ÄÊé®Ë´ñÔºàNLIÔºâÔºå‰ª•Á∂≠ÊåÅÂÅèÂ•Ω‰ø°ÂøµÂíå BO Á≠ñÁï•Ôºå‰æãÂ¶ÇÊπØÊôÆÊ£ÆÊäΩÊ®£ÔºàTSÔºâÂíå‰∏äÁΩÆ‰ø°ÁïåÔºàUCBÔºâÔºå‰ª•ÂºïÂ∞é LLM Êü•Ë©¢Áî¢Áîü„ÄÇÊàëÂÄëÂú®ÂèóÊéßÂØ¶È©ó‰∏≠Â∞çÊàëÂÄëÁöÑÈÄô‰∫õÊñπÊ≥ïÈÄ≤Ë°åÊï∏ÂÄºË©ï‰º∞ÔºåÁôºÁèæËàáÂñÆÈ´î GPT-3.5 Áõ∏ÊØîÔºåÂÑòÁÆ°‰æùË≥¥Êñº‰∏ÄÂÄãÂ∞èÂæóÂ§öÁöÑ 400M ÂèÉÊï∏ NLI Ê®°ÂûãÈÄ≤Ë°åÂÅèÂ•ΩÊé®Ë´ñÔºå‰ΩÜ PEBOL Âú® 10 Ëº™ÂÜ∑ÂïüÂãï NL-PE Â∞çË©±ÂæåÂú® MAP@10 ‰∏≠ÂØ¶Áèæ‰∫ÜÈ´òÈÅî 131% ÁöÑÊîπÈÄ≤„ÄÇ</paragraph>

##### **A Hong Kong Sign Language Corpus Collected from Sign-interpreted TV News**
2405.00980v1 by Zhe Niu,Ronglai Zuo,Brian Mak,Fangyun Wei

This paper introduces TVB-HKSL-News, a new Hong Kong sign language (HKSL)
dataset collected from a TV news program over a period of 7 months. The dataset
is collected to enrich resources for HKSL and support research in
large-vocabulary continuous sign language recognition (SLR) and translation
(SLT). It consists of 16.07 hours of sign videos of two signers with a
vocabulary of 6,515 glosses (for SLR) and 2,850 Chinese characters or 18K
Chinese words (for SLT). One signer has 11.66 hours of sign videos and the
other has 4.41 hours. One objective in building the dataset is to support the
investigation of how well large-vocabulary continuous sign language
recognition/translation can be done for a single signer given a (relatively)
large amount of his/her training data, which could potentially lead to the
development of new modeling methods. Besides, most parts of the data collection
pipeline are automated with little human intervention; we believe that our
collection method can be scaled up to collect more sign language data easily
for SLT in the future for any sign languages if such sign-interpreted videos
are available. We also run a SOTA SLR/SLT model on the dataset and get a
baseline SLR word error rate of 34.08% and a baseline SLT BLEU-4 score of 23.58
for benchmarking future research on the dataset.

ÊëòË¶ÅÔºö<paragraph>Êú¨Êñá‰ªãÁ¥π TVB-HKSL-NewsÔºåÈÄôÊòØ‰∏ÄÂÄãÂæûÈõªË¶ñÊñ∞ËÅûÁØÄÁõÆ‰∏≠Êî∂ÈõÜË∂ÖÈÅé 7 ÂÄãÊúàÁöÑÈ¶ôÊ∏ØÊâãË™û (HKSL) Êñ∞Ë≥áÊñôÈõÜ„ÄÇÊî∂ÈõÜÊ≠§Ë≥áÊñôÈõÜÊòØÁÇ∫‰∫ÜË±êÂØå HKSL ÁöÑË≥áÊ∫êÔºå‰∏¶ÊîØÊè¥Â§ßË©ûÂΩôÈáèÈÄ£Á∫åÊâãË™ûËæ®Ë≠ò (SLR) ÂíåÁøªË≠Ø (SLT) ÁöÑÁ†îÁ©∂„ÄÇÂÆÉÂåÖÂê´ÂÖ©‰ΩçÊâãË™ûËÄÖÁöÑ 16.07 Â∞èÊôÇÊâãË™ûÂΩ±ÁâáÔºåË©ûÂΩôÈáèÁÇ∫ 6,515 ÂÄãÊâãË™ûÁ¨¶Ëôü (Áî®Êñº SLR) Âíå 2,850 ÂÄã‰∏≠ÊñáÂ≠óÊàñ 18K ÂÄã‰∏≠ÊñáË©ûÂΩô (Áî®Êñº SLT)„ÄÇ‰∏Ä‰ΩçÊâãË™ûËÄÖÊúâ 11.66 Â∞èÊôÇÁöÑÊâãË™ûÂΩ±ÁâáÔºåÂè¶‰∏Ä‰ΩçÊúâ 4.41 Â∞èÊôÇ„ÄÇÂª∫Á´ãÊ≠§Ë≥áÊñôÈõÜÁöÑÂÖ∂‰∏≠‰∏ÄÂÄãÁõÆÊ®ôÊòØÊîØÊè¥Ë™øÊü•Â∞çÊñºÂñÆ‰∏Ä‰ΩçÊâãË™ûËÄÖÔºåÂ¶ÇÊûúÁµ¶‰∫à (Áõ∏Â∞ç) Â§ßÈáèË®ìÁ∑¥Ë≥áÊñôÔºåÈÄ£Á∫åÊâãË™ûËæ®Ë≠ò/ÁøªË≠ØÁöÑË°®ÁèæÊúâÂ§öÂ•ΩÔºåÈÄôÂèØËÉΩÊúÉÂ∞éËá¥Êñ∞ÁöÑÂª∫Ê®°ÊñπÊ≥ïÁöÑÁôºÂ±ï„ÄÇÊ≠§Â§ñÔºåÂ§ßÈÉ®ÂàÜË≥áÊñôÊî∂ÈõÜÁÆ°Á∑öÈÉΩÊòØËá™ÂãïÂåñÁöÑÔºåÂπæ‰πéÊ≤íÊúâ‰∫∫Â∑•‰ªãÂÖ•ÔºõÊàëÂÄëÁõ∏‰ø°ÊàëÂÄëÁöÑÊî∂ÈõÜÊñπÊ≥ïÂèØ‰ª•Êì¥Â±ïÔºå‰ª•‰æøÂú®Êú™‰æÜËºïÈ¨ÜÂú∞Êî∂ÈõÜÊõ¥Â§öÊâãË™ûË≥áÊñôÔºåÁî®Êñº‰ªª‰ΩïÊâãË™ûÁöÑ SLTÔºåÂè™Ë¶ÅÊúâÊ≠§È°ûÊâãË™ûÁøªË≠ØÂΩ±Áâá„ÄÇÊàëÂÄë‰πüÂú®Ë≥áÊñôÈõÜ‰∏äÂü∑Ë°å SOTA SLR/SLT Ê®°ÂûãÔºå‰∏¶ÂèñÂæó 34.08% ÁöÑÂü∫Ê∫ñ SLR Ë©ûÂΩôÈåØË™§ÁéáÂíå 23.58 ÁöÑÂü∫Ê∫ñ SLT BLEU-4 ÂàÜÊï∏Ôºå‰ΩúÁÇ∫Êú™‰æÜË≥áÊñôÈõÜÁ†îÁ©∂ÁöÑÂü∫Ê∫ñ„ÄÇ</paragraph>

##### **Language Fairness in Multilingual Information Retrieval**
2405.00978v1 by Eugene Yang,Thomas J√§nich,James Mayfield,Dawn Lawrie

Multilingual information retrieval (MLIR) considers the problem of ranking
documents in several languages for a query expressed in a language that may
differ from any of those languages. Recent work has observed that approaches
such as combining ranked lists representing a single document language each or
using multilingual pretrained language models demonstrate a preference for one
language over others. This results in systematic unfair treatment of documents
in different languages. This work proposes a language fairness metric to
evaluate whether documents across different languages are fairly ranked through
statistical equivalence testing using the Kruskal-Wallis test. In contrast to
most prior work in group fairness, we do not consider any language to be an
unprotected group. Thus our proposed measure, PEER (Probability of
EqualExpected Rank), is the first fairness metric specifically designed to
capture the language fairness of MLIR systems. We demonstrate the behavior of
PEER on artificial ranked lists. We also evaluate real MLIR systems on two
publicly available benchmarks and show that the PEER scores align with prior
analytical findings on MLIR fairness. Our implementation is compatible with
ir-measures and is available at http://github.com/hltcoe/peer_measure.

ÊëòË¶ÅÔºöÂ§öË™ûË®ÄË≥áË®äÊ™¢Á¥¢ (MLIR) ËÄÉÊÖÆ‰∫ÜÈáùÂ∞ç‰ª•ÂèØËÉΩËàáÈÄô‰∫õË™ûË®Ä‰∏çÂêåÁöÑË™ûË®ÄË°®ÈÅîÁöÑÊü•Ë©¢ÔºåÂ∞çÂ§öÁ®ÆË™ûË®ÄÁöÑÊñá‰ª∂ÈÄ≤Ë°åÊéíÂêçÁöÑÂïèÈ°å„ÄÇÊúÄËøëÁöÑÁ†îÁ©∂ÁôºÁèæÔºåË´∏Â¶ÇÁµÑÂêà‰ª£Ë°®ÂñÆ‰∏ÄÊñá‰ª∂Ë™ûË®ÄÁöÑÂ∑≤ÊéíÂ∫èÊ∏ÖÂñÆÊàñ‰ΩøÁî®Â§öË™ûË®ÄÈ†êË®ìÁ∑¥Ë™ûË®ÄÊ®°ÂûãÁ≠âÊñπÊ≥ïÈ°ØÁ§∫Âá∫ÂÅèÂ•Ω‰∏ÄÁ®ÆË™ûË®ÄÂãùÈÅéÂÖ∂‰ªñË™ûË®Ä„ÄÇÈÄôÂ∞éËá¥Â∞ç‰∏çÂêåË™ûË®ÄÁöÑÊñá‰ª∂ÈÄ≤Ë°åÁ≥ªÁµ±ÊÄßÁöÑ‰∏çÂÖ¨Âπ≥ËôïÁêÜ„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÊèêÂá∫‰∫Ü‰∏ÄÂÄãË™ûË®ÄÂÖ¨Âπ≥ÊÄßÊåáÊ®ôÔºå‰ª•‰ΩøÁî® Kruskal-Wallis Ê™¢ÂÆöÈÄèÈÅéÁµ±Ë®àÁ≠âÂÉπÊ∏¨Ë©¶‰æÜË©ï‰º∞‰∏çÂêåË™ûË®ÄÁöÑÊñá‰ª∂ÊòØÂê¶ÂæóÂà∞ÂÖ¨Âπ≥ÊéíÂêç„ÄÇËàáÁæ§È´îÂÖ¨Âπ≥ÊÄß‰∏≠ÁöÑÂ§ßÂ§öÊï∏ÂÖàÂâçÂ∑•‰ΩúÁõ∏ÂèçÔºåÊàëÂÄë‰∏çË™çÁÇ∫‰ªª‰ΩïË™ûË®ÄÈÉΩÊòØ‰∏çÂèó‰øùË≠∑ÁöÑÁæ§È´î„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëÊèêÂá∫ÁöÑÊåáÊ®ô PEERÔºàEqualExpected Rank ÁöÑÊ©üÁéáÔºâÊòØÁ¨¨‰∏ÄÂÄãÂÖ¨Âπ≥ÊÄßÊåáÊ®ôÔºåÂ∞àÈñÄÁî®ÊñºÊçïÊçâ MLIR Á≥ªÁµ±ÁöÑË™ûË®ÄÂÖ¨Âπ≥ÊÄß„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫Ü PEER Âú®‰∫∫Â∑•ÊéíÂ∫èÊ∏ÖÂñÆ‰∏äÁöÑË°åÁÇ∫„ÄÇÊàëÂÄëÈÇÑÂ∞çÂÖ©ÂÄãÂÖ¨ÈñãÂü∫Ê∫ñ‰∏äÁöÑÁúüÂØ¶ MLIR Á≥ªÁµ±ÈÄ≤Ë°åË©ï‰º∞Ôºå‰∏¶È°ØÁ§∫ PEER ÂàÜÊï∏Ëàá MLIR ÂÖ¨Âπ≥ÊÄßÁöÑÂÖàÂâçÂàÜÊûêÁµêÊûú‰∏ÄËá¥„ÄÇÊàëÂÄëÁöÑÂØ¶‰ΩúËàá ir-measures Áõ∏ÂÆπÔºå‰∏îÂèØ‰ª•Âú® http://github.com/hltcoe/peer_measure ÂèñÂæó„ÄÇ

##### **Distillation for Multilingual Information Retrieval**
2405.00977v1 by Eugene Yang,Dawn Lawrie,James Mayfield

Recent work in cross-language information retrieval (CLIR), where queries and
documents are in different languages, has shown the benefit of the
Translate-Distill framework that trains a cross-language neural dual-encoder
model using translation and distillation. However, Translate-Distill only
supports a single document language. Multilingual information retrieval (MLIR),
which ranks a multilingual document collection, is harder to train than CLIR
because the model must assign comparable relevance scores to documents in
different languages. This work extends Translate-Distill and propose
Multilingual Translate-Distill (MTD) for MLIR. We show that ColBERT-X models
trained with MTD outperform their counterparts trained ith Multilingual
Translate-Train, which is the previous state-of-the-art training approach, by
5% to 25% in nDCG@20 and 15% to 45% in MAP. We also show that the model is
robust to the way languages are mixed in training batches. Our implementation
is available on GitHub.

ÊëòË¶ÅÔºöÊúÄËøëË∑®Ë™ûË®ÄË≥áË®äÊ™¢Á¥¢ (CLIR) ÁöÑÂ∑•‰ΩúÔºàÂÖ∂‰∏≠Êü•Ë©¢ÂíåÊñá‰ª∂‰ΩøÁî®‰∏çÂêåÁöÑË™ûË®ÄÔºâÈ°ØÁ§∫‰∫Ü Translate-Distill Ê°ÜÊû∂ÁöÑÂ•ΩËôïÔºåË©≤Ê°ÜÊû∂‰ΩøÁî®ÁøªË≠ØÂíåÁ≤æÈ§æË®ìÁ∑¥Ë∑®Ë™ûË®ÄÁ•ûÁ∂ìÈõôÁ∑®Á¢ºÂô®Ê®°Âûã„ÄÇÁÑ∂ËÄåÔºåTranslate-Distill Âè™ÊîØÊè¥ÂñÆ‰∏ÄÊñá‰ª∂Ë™ûË®Ä„ÄÇÂ§öË™ûË®ÄË≥áË®äÊ™¢Á¥¢ (MLIR) Â∞çÂ§öË™ûË®ÄÊñá‰ª∂ÈõÜÂêàÈÄ≤Ë°åÊéíÂêçÔºåÂÖ∂Ë®ìÁ∑¥Èõ£Â∫¶È´òÊñº CLIRÔºåÂõ†ÁÇ∫Ê®°ÂûãÂøÖÈ†àÁÇ∫‰∏çÂêåË™ûË®ÄÁöÑÊñá‰ª∂ÊåáÂÆöÂèØÊØîËºÉÁöÑÁõ∏ÈóúÊÄßÂàÜÊï∏„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÊì¥ÂÖÖ‰∫Ü Translate-DistillÔºå‰∏¶ÁÇ∫ MLIR ÊèêÂá∫Â§öË™ûË®Ä Translate-Distill (MTD)„ÄÇÊàëÂÄëÈ°ØÁ§∫‰ΩøÁî® MTD Ë®ìÁ∑¥ÁöÑ ColBERT-X Ê®°ÂûãÂÑ™Êñº‰ΩøÁî®Â§öË™ûË®Ä Translate-TrainÔºàÈÄôÊòØ‰ª•ÂâçÊúÄÂÖàÈÄ≤ÁöÑË®ìÁ∑¥ÊñπÊ≥ïÔºâË®ìÁ∑¥ÁöÑÂ∞çÊáâÊ®°ÂûãÔºåÂú® nDCG@20 ‰∏≠È´òÂá∫ 5% Ëá≥ 25%ÔºåÂú® MAP ‰∏≠È´òÂá∫ 15% Ëá≥ 45%„ÄÇÊàëÂÄëÈÇÑÈ°ØÁ§∫Ë©≤Ê®°ÂûãÂ∞çÊñºË®ìÁ∑¥ÊâπÊ¨°‰∏≠Ë™ûË®ÄÁöÑÊ∑∑ÂêàÊñπÂºèÂÖ∑ÊúâÁ©©ÂÅ•ÊÄß„ÄÇÊàëÂÄëÁöÑÂØ¶‰ΩúÂèØÂú® GitHub ‰∏äÂèñÂæó„ÄÇ

##### **PLAID SHIRTTT for Large-Scale Streaming Dense Retrieval**
2405.00975v1 by Dawn Lawrie,Efsun Kayi,Eugene Yang,James Mayfield,Douglas W. Oard

PLAID, an efficient implementation of the ColBERT late interaction bi-encoder
using pretrained language models for ranking, consistently achieves
state-of-the-art performance in monolingual, cross-language, and multilingual
retrieval. PLAID differs from ColBERT by assigning terms to clusters and
representing those terms as cluster centroids plus compressed residual vectors.
While PLAID is effective in batch experiments, its performance degrades in
streaming settings where documents arrive over time because representations of
new tokens may be poorly modeled by the earlier tokens used to select cluster
centroids. PLAID Streaming Hierarchical Indexing that Runs on Terabytes of
Temporal Text (PLAID SHIRTTT) addresses this concern using multi-phase
incremental indexing based on hierarchical sharding. Experiments on ClueWeb09
and the multilingual NeuCLIR collection demonstrate the effectiveness of this
approach both for the largest collection indexed to date by the ColBERT
architecture and in the multilingual setting, respectively.

ÊëòË¶ÅÔºöPLAID ÊòØ‰∏ÄÁ®ÆÈ´òÊïàÁöÑ ColBERT ÂæåÊúü‰∫íÂãïÈõôÁ∑®Á¢ºÂô®ÂØ¶‰ΩúÔºåÂÆÉ‰ΩøÁî®È†êË®ìÁ∑¥Ë™ûË®ÄÊ®°ÂûãÈÄ≤Ë°åÊéíÂêçÔºåÂú®ÂñÆË™û„ÄÅË∑®Ë™ûË®ÄÂíåÂ§öË™ûË®ÄÊ™¢Á¥¢‰∏≠ÊåÅÁ∫åÈÅîÊàêÊúÄÂÖàÈÄ≤ÁöÑÊïàËÉΩ„ÄÇPLAID Ëàá ColBERT ÁöÑ‰∏çÂêå‰πãËôïÂú®ÊñºÂ∞áË©ûÂΩôÊåáÊ¥æÁµ¶Áæ§ÈõÜÔºå‰∏¶Â∞áÈÄô‰∫õË©ûÂΩôË°®Á§∫ÁÇ∫Áæ§ÈõÜË≥™ÂøÉÂä†‰∏äÂ£ìÁ∏ÆÁöÑÊÆòÂ∑ÆÂêëÈáè„ÄÇÈõñÁÑ∂ PLAID Âú®ÊâπÊ¨°ÂØ¶È©ó‰∏≠ÂæàÊúâÊïàÔºå‰ΩÜÂÆÉÁöÑÊïàËÉΩÊúÉÂú®‰∏≤ÊµÅË®≠ÂÆö‰∏≠‰∏ãÈôçÔºåÂõ†ÁÇ∫Êñá‰ª∂ÊúÉÈö®ËëóÊôÇÈñìËÄåÈô∏Á∫åÊäµÈÅîÔºåËÄåÊñ∞Ë©ûÂΩôÁöÑË°®Á§∫ÂèØËÉΩÊúÉÂõ†ÁÇ∫Áî®ÊñºÈÅ∏ÊìáÁæ§ÈõÜË≥™ÂøÉÁöÑÊó©ÊúüË©ûÂΩôËÄåÂª∫Ê®°‰∏ç‰Ω≥„ÄÇPLAID ‰∏≤ÊµÅÈöéÂ±§Á¥¢ÂºïÂú®Êï∏ TB ÁöÑÊôÇÈñìÊñáÂ≠ó‰∏äÂü∑Ë°åÔºàPLAID SHIRTTTÔºâ‰ΩøÁî®Âü∫ÊñºÈöéÂ±§ÂàÜÁâáÁöÑÂ§öÂàÜÊÆµÂ¢ûÈáèÁ¥¢Âºï‰æÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°å„ÄÇÂú® ClueWeb09 ÂíåÂ§öË™ûË®Ä NeuCLIR ÂΩôÁ∑®‰∏äÁöÑÂØ¶È©óÂ±ïÁ§∫‰∫ÜÈÄôÁ®ÆÊñπÊ≥ïÁöÑÊúâÊïàÊÄßÔºåÂàÜÂà•ÈÅ©Áî®Êñº ColBERT Êû∂ÊßãËøÑ‰ªäÁ¥¢ÂºïÁöÑÊúÄÂ§ßÂΩôÁ∑®ÂíåÂ§öË™ûË®ÄË®≠ÂÆö„ÄÇ

##### **CACTUS: Chemistry Agent Connecting Tool-Usage to Science**
2405.00972v1 by Andrew D. McNaughton,Gautham Ramalaxmi,Agustin Kruel,Carter R. Knutson,Rohith A. Varikoti,Neeraj Kumar

Large language models (LLMs) have shown remarkable potential in various
domains, but they often lack the ability to access and reason over
domain-specific knowledge and tools. In this paper, we introduced CACTUS
(Chemistry Agent Connecting Tool-Usage to Science), an LLM-based agent that
integrates cheminformatics tools to enable advanced reasoning and
problem-solving in chemistry and molecular discovery. We evaluate the
performance of CACTUS using a diverse set of open-source LLMs, including
Gemma-7b, Falcon-7b, MPT-7b, Llama2-7b, and Mistral-7b, on a benchmark of
thousands of chemistry questions. Our results demonstrate that CACTUS
significantly outperforms baseline LLMs, with the Gemma-7b and Mistral-7b
models achieving the highest accuracy regardless of the prompting strategy
used. Moreover, we explore the impact of domain-specific prompting and hardware
configurations on model performance, highlighting the importance of prompt
engineering and the potential for deploying smaller models on consumer-grade
hardware without significant loss in accuracy. By combining the cognitive
capabilities of open-source LLMs with domain-specific tools, CACTUS can assist
researchers in tasks such as molecular property prediction, similarity
searching, and drug-likeness assessment. Furthermore, CACTUS represents a
significant milestone in the field of cheminformatics, offering an adaptable
tool for researchers engaged in chemistry and molecular discovery. By
integrating the strengths of open-source LLMs with domain-specific tools,
CACTUS has the potential to accelerate scientific advancement and unlock new
frontiers in the exploration of novel, effective, and safe therapeutic
candidates, catalysts, and materials. Moreover, CACTUS's ability to integrate
with automated experimentation platforms and make data-driven decisions in real
time opens up new possibilities for autonomous discovery.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤Âú®ÂêÑÁ®ÆÈ†òÂüüÂ±ïÁèæÂá∫È©ö‰∫∫ÁöÑÊΩõÂäõÔºå‰ΩÜÂÆÉÂÄëÂ∏∏Â∏∏Áº∫‰πèÂ≠òÂèñÂíåÊé®ÁêÜÁâπÂÆöÈ†òÂüüÁü•Ë≠òÂíåÂ∑•ÂÖ∑ÁöÑËÉΩÂäõ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫Ü CACTUSÔºàÂåñÂ≠∏‰ª£ÁêÜÈÄ£Êé•Â∑•ÂÖ∑‰ΩøÁî®Âà∞ÁßëÂ≠∏ÔºâÔºå‰∏ÄÁ®ÆÂü∫Êñº LLM ÁöÑ‰ª£ÁêÜÔºåÂÆÉÊï¥Âêà‰∫ÜÂåñÂ≠∏Ë≥áË®äÂ≠∏Â∑•ÂÖ∑Ôºå‰ª•ÂØ¶ÁèæÂåñÂ≠∏ÂíåÂàÜÂ≠êÁôºÁèæ‰∏≠ÁöÑÂÖàÈÄ≤Êé®ÁêÜÂíåÂïèÈ°åËß£Ê±∫„ÄÇÊàëÂÄë‰ΩøÁî®‰∏ÄÁµÑÂ§öÊ®£ÂåñÁöÑÈñãÊ∫ê LLMÔºåÂåÖÊã¨ Gemma-7b„ÄÅFalcon-7b„ÄÅMPT-7b„ÄÅLlama2-7b Âíå Mistral-7bÔºåÂ∞ç CACTUS ÁöÑÊïàËÉΩÈÄ≤Ë°åË©ï‰º∞ÔºåÂü∫Ê∫ñÊòØÊï∏ÂçÉÂÄãÂåñÂ≠∏ÂïèÈ°å„ÄÇÊàëÂÄëÁöÑÁµêÊûúË°®ÊòéÔºåCACTUS ÊòéÈ°ØÂÑ™ÊñºÂü∫Ê∫ñ LLMÔºåÂÖ∂‰∏≠ Gemma-7b Âíå Mistral-7b Ê®°ÂûãÁÑ°Ë´ñ‰ΩøÁî®‰ΩïÁ®ÆÊèêÁ§∫Á≠ñÁï•ÔºåÈÉΩËÉΩÈÅîÂà∞ÊúÄÈ´òÁöÑÊ∫ñÁ¢∫Â∫¶„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊé¢Ë®é‰∫ÜÁâπÂÆöÈ†òÂüüÊèêÁ§∫ÂíåÁ°¨È´îÈÖçÁΩÆÂ∞çÊ®°ÂûãÊïàËÉΩÁöÑÂΩ±ÈüøÔºåÂº∑Ë™ø‰∫ÜÊèêÁ§∫Â∑•Á®ãÁöÑÈáçË¶ÅÊÄß‰ª•ÂèäÂú®Ê∂àË≤ªËÄÖÁ¥öÁ°¨È´î‰∏äÈÉ®ÁΩ≤ËºÉÂ∞èÊ®°ÂûãÁöÑÊΩõÂäõÔºåËÄåÊ∫ñÁ¢∫Â∫¶‰∏çÊúÉÈ°ØËëó‰∏ãÈôç„ÄÇÈÄèÈÅéÁµêÂêàÈñãÊ∫ê LLM ÁöÑË™çÁü•ËÉΩÂäõÂíåÁâπÂÆöÈ†òÂüüÂ∑•ÂÖ∑ÔºåCACTUS ËÉΩÂçîÂä©Á†îÁ©∂‰∫∫Âì°Âü∑Ë°åÂàÜÂ≠êÊÄßË≥™È†êÊ∏¨„ÄÅÁõ∏‰ººÊÄßÊêúÂ∞ãÂíåËó•Áâ©Áõ∏‰ººÊÄßË©ï‰º∞Á≠â‰ªªÂãô„ÄÇÊ≠§Â§ñÔºåCACTUS ‰ª£Ë°®‰∫ÜÂåñÂ≠∏Ë≥áË®äÂ≠∏È†òÂüüÁöÑ‰∏ÄÂÄãÈáçË¶ÅÈáåÁ®ãÁ¢ëÔºåÁÇ∫Âæû‰∫ãÂåñÂ≠∏ÂíåÂàÜÂ≠êÁôºÁèæÁöÑÁ†îÁ©∂‰∫∫Âì°Êèê‰æõ‰∫Ü‰∏ÄÂÄãÈÅ©ÊáâÊÄßÂ∑•ÂÖ∑„ÄÇÈÄèÈÅéÊï¥ÂêàÈñãÊ∫ê LLM ÁöÑÂÑ™Âã¢ÂíåÁâπÂÆöÈ†òÂüüÂ∑•ÂÖ∑ÔºåCACTUS ÊúâÂèØËÉΩÂä†ÈÄüÁßëÂ≠∏ÈÄ≤Ê≠•Ôºå‰∏¶ÈñãÂïüÊé¢Á¥¢Êñ∞Á©é„ÄÅÊúâÊïàÂíåÂÆâÂÖ®ÁöÑÊ≤ªÁôÇÂÄôÈÅ∏Áâ©„ÄÅÂÇ¨ÂåñÂäëÂíåÊùêÊñôÁöÑÊñ∞È†òÂüü„ÄÇÊ≠§Â§ñÔºåCACTUS ËÉΩËàáËá™ÂãïÂåñÂØ¶È©óÂπ≥Âè∞Êï¥ÂêàÔºå‰∏¶Âú®ÁúüÂØ¶ÊôÇÈñìÂÅöÂá∫Ë≥áÊñôÈ©ÖÂãïÊ±∫Á≠ñÔºåÁÇ∫Ëá™‰∏ªÁôºÁèæÈñãÂïü‰∫ÜÊñ∞ÁöÑÂèØËÉΩÊÄß„ÄÇ

##### **How Can I Get It Right? Using GPT to Rephrase Incorrect Trainee Responses**
2405.00970v1 by Jionghao Lin,Zifei Han,Danielle R. Thomas,Ashish Gurung,Shivang Gupta,Vincent Aleven,Kenneth R. Koedinger

One-on-one tutoring is widely acknowledged as an effective instructional
method, conditioned on qualified tutors. However, the high demand for qualified
tutors remains a challenge, often necessitating the training of novice tutors
(i.e., trainees) to ensure effective tutoring. Research suggests that providing
timely explanatory feedback can facilitate the training process for trainees.
However, it presents challenges due to the time-consuming nature of assessing
trainee performance by human experts. Inspired by the recent advancements of
large language models (LLMs), our study employed the GPT-4 model to build an
explanatory feedback system. This system identifies trainees' responses in
binary form (i.e., correct/incorrect) and automatically provides template-based
feedback with responses appropriately rephrased by the GPT-4 model. We
conducted our study on 410 responses from trainees across three training
lessons: Giving Effective Praise, Reacting to Errors, and Determining What
Students Know. Our findings indicate that: 1) using a few-shot approach, the
GPT-4 model effectively identifies correct/incorrect trainees' responses from
three training lessons with an average F1 score of 0.84 and an AUC score of
0.85; and 2) using the few-shot approach, the GPT-4 model adeptly rephrases
incorrect trainees' responses into desired responses, achieving performance
comparable to that of human experts.

ÊëòË¶ÅÔºö‰∏ÄÂ∞ç‰∏ÄËºîÂ∞éË¢´Âª£Ê≥õË™çÁÇ∫ÊòØ‰∏ÄÁ®ÆÊúâÊïàÁöÑÊïôÂ≠∏ÊñπÊ≥ïÔºåÊ¢ù‰ª∂ÊòØËºîÂ∞éÂì°ÊúâË≥áÊ†º„ÄÇÁÑ∂ËÄåÔºåÂ∞çÂêàÊ†ºËºîÂ∞éÂì°ÁöÑÈ´òÈúÄÊ±Ç‰ªçÁÑ∂ÊòØ‰∏ÄÂÄãÊåëÊà∞ÔºåÈÄôÈÄöÂ∏∏ÈúÄË¶ÅÂ∞çÊñ∞ÊâãËºîÂ∞éÂì°ÔºàÂç≥ÂèóË®ìËÄÖÔºâÈÄ≤Ë°åÂüπË®ì‰ª•Á¢∫‰øùËºîÂ∞éÊúâÊïà„ÄÇÁ†îÁ©∂Ë°®ÊòéÔºåÊèê‰æõÂèäÊôÇÁöÑËß£ÈáãÊÄßÂõûÈ•ãÂèØ‰ª•‰øÉÈÄ≤ÂèóË®ìËÄÖÁöÑÂüπË®ìÈÅéÁ®ã„ÄÇÁÑ∂ËÄåÔºåÁî±ÊñºÁî±‰∫∫È°ûÂ∞àÂÆ∂Ë©ï‰º∞ÂèóË®ìËÄÖË°®ÁèæÁöÑËÄóÊôÇÊÄßË≥™ÔºåÈÄôÊèêÂá∫‰∫ÜÊåëÊà∞„ÄÇÂèóÂà∞Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÊúÄËøëÈÄ≤Â±ïÁöÑÂïüÁôºÔºåÊàëÂÄëÁöÑÁ†îÁ©∂Êé°Áî® GPT-4 Ê®°Âûã‰æÜÂª∫Á´ã‰∏ÄÂÄãËß£ÈáãÊÄßÂõûÈ•ãÁ≥ªÁµ±„ÄÇÊ≠§Á≥ªÁµ±‰ª•‰∫åÈÄ≤‰ΩçÂΩ¢ÂºèÔºàÂç≥Ê≠£Á¢∫/‰∏çÊ≠£Á¢∫ÔºâË≠òÂà•ÂèóË®ìËÄÖÁöÑÂèçÊáâÔºå‰∏¶Ëá™ÂãïÊèê‰æõÂü∫ÊñºÁØÑÊú¨ÁöÑÂõûÈ•ãÔºåÂÖ∂‰∏≠ GPT-4 Ê®°ÂûãÈÅ©Áï∂Âú∞ÈáçÊñ∞Ë°®Ëø∞‰∫ÜÂèçÊáâ„ÄÇÊàëÂÄëÂ∞ç‰æÜËá™ÂèóË®ìËÄÖÁöÑ 410 ÂÄãÂèçÊáâÈÄ≤Ë°å‰∫ÜÁ†îÁ©∂ÔºåÊ∂µËìã‰∏âÂÄãÂüπË®ìË™≤Á®ãÔºöÁµ¶‰∫àÊúâÊïàÁöÑËÆöÁæé„ÄÅÂ∞çÈåØË™§ÁöÑÂèçÊáâ‰ª•ÂèäÁ¢∫ÂÆöÂ≠∏ÁîüÁöÑÁü•Ë≠ò„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúË°®ÊòéÔºö1) ‰ΩøÁî®Â∞ëÊ¨°ÂòóË©¶ÁöÑÊñπÊ≥ïÔºåGPT-4 Ê®°ÂûãÊúâÊïàÂú∞Âæû‰∏âÂÄãÂüπË®ìË™≤Á®ã‰∏≠Ë≠òÂà•Âá∫ÂèóË®ìËÄÖÁöÑÊ≠£Á¢∫/‰∏çÊ≠£Á¢∫ÂèçÊáâÔºåÂπ≥Âùá F1 ÂàÜÊï∏ÁÇ∫ 0.84ÔºåAUC ÂàÜÊï∏ÁÇ∫ 0.85Ôºõ2) ‰ΩøÁî®Â∞ëÊ¨°ÂòóË©¶ÁöÑÊñπÊ≥ïÔºåGPT-4 Ê®°ÂûãÂ∑ßÂ¶ôÂú∞Â∞áÂèóË®ìËÄÖ‰∏çÊ≠£Á¢∫ÁöÑÂèçÊáâÈáçÊñ∞Ë°®Ëø∞ÁÇ∫ÊâÄÈúÄÁöÑÂèçÊáâÔºåÈÅîÂà∞‰∫ÜËàá‰∫∫È°ûÂ∞àÂÆ∂Áõ∏Áï∂ÁöÑË°®Áèæ„ÄÇ

##### **Efficient Compression of Multitask Multilingual Speech Models**
2405.00966v1 by Thomas Palmeira Ferraz

Whisper is a multitask and multilingual speech model covering 99 languages.
It yields commendable automatic speech recognition (ASR) results in a subset of
its covered languages, but the model still underperforms on a non-negligible
number of under-represented languages, a problem exacerbated in smaller model
versions. In this work, we examine its limitations, demonstrating the presence
of speaker-related (gender, age) and model-related (resourcefulness and model
size) bias. Despite that, we show that only model-related bias are amplified by
quantization, impacting more low-resource languages and smaller models.
Searching for a better compression approach, we propose DistilWhisper, an
approach that is able to bridge the performance gap in ASR for these languages
while retaining the advantages of multitask and multilingual capabilities. Our
approach involves two key strategies: lightweight modular ASR fine-tuning of
whisper-small using language-specific experts, and knowledge distillation from
whisper-large-v2. This dual approach allows us to effectively boost ASR
performance while keeping the robustness inherited from the multitask and
multilingual pre-training. Results demonstrate that our approach is more
effective than standard fine-tuning or LoRA adapters, boosting performance in
the targeted languages for both in- and out-of-domain test sets, while
introducing only a negligible parameter overhead at inference.

ÊëòË¶ÅÔºöWhisper ÊòØ‰∏ÄÊ¨æÂ§ö‰ªªÂä°‰∏îÂ§öËØ≠Ë®ÄÁöÑËØ≠Èü≥Ê®°ÂûãÔºåÊ∂µÁõñ 99 ÁßçËØ≠Ë®Ä„ÄÇ
ÂÆÉÂú®ÊâÄÊ∂µÁõñËØ≠Ë®ÄÁöÑ‰∏Ä‰∏™Â≠êÈõÜ‰∏≠‰∫ßÁîü‰∫ÜÂÄºÂæóÁß∞ÈÅìÁöÑËá™Âä®ËØ≠Èü≥ËØÜÂà´ (ASR) ÁªìÊûúÔºå‰ΩÜËØ•Ê®°ÂûãÂú®Êï∞Èáè‰∏çÂ∞èÁöÑ‰ª£Ë°®ÊÄß‰∏çË∂≥ÁöÑËØ≠Ë®Ä‰∏ä‰ªçÁÑ∂Ë°®Áé∞‰∏ç‰Ω≥ÔºåËøô‰∏™ÈóÆÈ¢òÂú®ËæÉÂ∞èÁöÑÊ®°ÂûãÁâàÊú¨‰∏≠‰ºöÊõ¥Âä†‰∏•Èáç„ÄÇÂú®ËøôÈ°πÂ∑•‰Ωú‰∏≠ÔºåÊàë‰ª¨Ê£ÄÊü•‰∫ÜÂÆÉÁöÑÂ±ÄÈôêÊÄßÔºåÂ±ïÁ§∫‰∫ÜËØ¥ËØùËÄÖÁõ∏ÂÖ≥ÔºàÊÄßÂà´„ÄÅÂπ¥ÈæÑÔºâÂíåÊ®°ÂûãÁõ∏ÂÖ≥ÔºàËµÑÊ∫ê‰∏∞ÂØåÊÄßÂíåÊ®°ÂûãÂ§ßÂ∞èÔºâÂÅèÂ∑ÆÁöÑÂ≠òÂú®„ÄÇÂ∞ΩÁÆ°Â¶ÇÊ≠§ÔºåÊàë‰ª¨Ë°®ÊòéÂè™ÊúâÊ®°ÂûãÁõ∏ÂÖ≥ÁöÑÂÅèÂ∑ÆË¢´ÈáèÂåñÊîæÂ§ßÔºåÂΩ±Âìç‰∫ÜÊõ¥Â§öËµÑÊ∫êÂåÆ‰πèÁöÑËØ≠Ë®ÄÂíåËæÉÂ∞èÁöÑÊ®°Âûã„ÄÇÂú®ÂØªÊâæÊõ¥Â•ΩÁöÑÂéãÁº©ÊñπÊ≥ïÊó∂ÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü DistilWhisperÔºåËøôÊòØ‰∏ÄÁßçËÉΩÂ§üÂº•ÂêàËøô‰∫õËØ≠Ë®ÄÁöÑ ASR ‰∏≠ÁöÑÊÄßËÉΩÂ∑ÆË∑ùÁöÑÊñπÊ≥ïÔºåÂêåÊó∂‰øùÁïôÂ§ö‰ªªÂä°ÂíåÂ§öËØ≠Ë®ÄÂäüËÉΩÁöÑ‰ºòÂäø„ÄÇÊàë‰ª¨ÁöÑÊñπÊ≥ïÊ∂âÂèä‰∏§‰∏™ÂÖ≥ÈîÆÁ≠ñÁï•Ôºö‰ΩøÁî®ÁâπÂÆöËØ≠Ë®ÄÁöÑ‰∏ìÂÆ∂ÂØπ whisper-small ËøõË°åËΩªÈáèÁ∫ßÊ®°ÂùóÂåñ ASR ÂæÆË∞ÉÔºå‰ª•Âèä‰ªé whisper-large-v2 ‰∏≠ËøõË°åÁü•ËØÜËí∏È¶è„ÄÇËøôÁßçÂèåÈáçÊñπÊ≥ï‰ΩøÊàë‰ª¨ËÉΩÂ§üÊúâÊïàÊèêÂçá ASR ÊÄßËÉΩÔºåÂêåÊó∂‰øùÊåÅ‰ªéÂ§ö‰ªªÂä°ÂíåÂ§öËØ≠Ë®ÄÈ¢ÑËÆ≠ÁªÉ‰∏≠ÁªßÊâøÁöÑÈ≤ÅÊ£íÊÄß„ÄÇÁªìÊûúË°®ÊòéÔºå‰∏éÊ†áÂáÜÂæÆË∞ÉÊàñ LoRA ÈÄÇÈÖçÂô®Áõ∏ÊØîÔºåÊàë‰ª¨ÁöÑÊñπÊ≥ïÊõ¥ÊúâÊïàÔºåÊèêÂçá‰∫ÜÁõÆÊ†áËØ≠Ë®ÄÂú®ÂüüÂÜÖÂíåÂüüÂ§ñÊµãËØïÈõÜ‰∏≠ÁöÑÊÄßËÉΩÔºåÂêåÊó∂Âú®Êé®ÁêÜÊó∂‰ªÖÂºïÂÖ•‰∫ÜÂèØÂøΩÁï•ÁöÑÂèÇÊï∞ÂºÄÈîÄ„ÄÇ

##### **Generative manufacturing systems using diffusion models and ChatGPT**
2405.00958v1 by Xingyu Li,Fei Tao,Wei Ye,Aydin Nassehi,John W. Sutherland

In this study, we introduce Generative Manufacturing Systems (GMS) as a novel
approach to effectively manage and coordinate autonomous manufacturing assets,
thereby enhancing their responsiveness and flexibility to address a wide array
of production objectives and human preferences. Deviating from traditional
explicit modeling, GMS employs generative AI, including diffusion models and
ChatGPT, for implicit learning from envisioned futures, marking a shift from a
model-optimum to a training-sampling decision-making. Through the integration
of generative AI, GMS enables complex decision-making through interactive
dialogue with humans, allowing manufacturing assets to generate multiple
high-quality global decisions that can be iteratively refined based on human
feedback. Empirical findings showcase GMS's substantial improvement in system
resilience and responsiveness to uncertainties, with decision times reduced
from seconds to milliseconds. The study underscores the inherent creativity and
diversity in the generated solutions, facilitating human-centric
decision-making through seamless and continuous human-machine interactions.

ÊëòË¶ÅÔºöÂú®Êú¨Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëÂºïÂÖ•ÁîüÊàêÂºèË£ΩÈÄ†Á≥ªÁµ± (GMS) ‰ΩúÁÇ∫‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÊñπÊ≥ïÔºåÁî®ÊñºÊúâÊïàÁÆ°ÁêÜÂíåÂçîË™øËá™‰∏ªË£ΩÈÄ†Ë≥áÁî¢ÔºåÂæûËÄåÂ¢ûÂº∑ÂÖ∂ÊáâËÆäËÉΩÂäõÂíåÈùàÊ¥ªÊÄßÔºå‰ª•ÊªøË∂≥Âª£Ê≥õÁöÑÁîüÁî¢ÁõÆÊ®ôÂíå‰∫∫È°ûÂÅèÂ•Ω„ÄÇËàáÂÇ≥Áµ±ÁöÑÈ°ØÂºèÂª∫Ê®°‰∏çÂêåÔºåGMS Êé°Áî®ÁîüÊàêÂºè AIÔºåÂåÖÊã¨Êì¥Êï£Ê®°ÂûãÂíå ChatGPTÔºåÂæûË®≠ÊÉ≥ÁöÑÊú™‰æÜÈÄ≤Ë°åÈö±ÂºèÂ≠∏ÁøíÔºåÊ®ôË™åËëóÂæûÊ®°ÂûãÊúÄÂÑ™Ê±∫Á≠ñËΩâÂêëË®ìÁ∑¥ÂèñÊ®£Ê±∫Á≠ñÂà∂ÂÆö„ÄÇÈÄèÈÅéÊï¥ÂêàÁîüÊàêÂºè AIÔºåGMS ËÉΩÂ§†ÈÄèÈÅéËàá‰∫∫È°ûÁöÑ‰∫íÂãïÂºèÂ∞çË©±ÈÄ≤Ë°åË§áÈõúÁöÑÊ±∫Á≠ñÂà∂ÂÆöÔºåÂÖÅË®±Ë£ΩÈÄ†Ë≥áÁî¢ÁîüÊàêÂ§öÂÄãÈ´òÂìÅË≥™ÁöÑÊï¥È´îÊ±∫Á≠ñÔºå‰∏¶ËÉΩÊ†πÊìö‰∫∫È°ûÁöÑÂõûÈ•ãÈÄ≤Ë°åÂèçË¶ÜÊîπÈÄ≤„ÄÇÂØ¶Ë≠âÁ†îÁ©∂ÁµêÊûúÂ±ïÁ§∫‰∫Ü GMS Âú®Á≥ªÁµ±ÈüåÊÄßÂíåÂ∞ç‰∏çÁ¢∫ÂÆöÊÄßÁöÑÊáâËÆäËÉΩÂäõÊñπÈù¢ÊúâÈ°ØËëóÁöÑÊèêÂçáÔºåÊ±∫Á≠ñÊôÇÈñìÂæûÊï∏ÁßíÁ∏ÆÁü≠Ëá≥ÊØ´Áßí„ÄÇÈÄôÈ†ÖÁ†îÁ©∂Âº∑Ë™ø‰∫ÜÁîüÊàêÂºèËß£Ê±∫ÊñπÊ°à‰∏≠Âõ∫ÊúâÁöÑÂâµÈÄ†ÂäõÂíåÂ§öÊ®£ÊÄßÔºåÈÄèÈÅéÁÑ°Á∏´‰∏îÊåÅÁ∫åÁöÑ‰∫∫Ê©ü‰∫íÂãïÔºå‰øÉÈÄ≤‰ª•‰∫∫ÁÇ∫‰∏≠ÂøÉÁöÑÊ±∫Á≠ñÂà∂ÂÆö„ÄÇ

##### **Provably Efficient Reinforcement Learning for Adversarial Restless Multi-Armed Bandits with Unknown Transitions and Bandit Feedback**
2405.00950v1 by Guojun Xiong,Jian Li

Restless multi-armed bandits (RMAB) play a central role in modeling
sequential decision making problems under an instantaneous activation
constraint that at most B arms can be activated at any decision epoch. Each
restless arm is endowed with a state that evolves independently according to a
Markov decision process regardless of being activated or not. In this paper, we
consider the task of learning in episodic RMAB with unknown transition
functions and adversarial rewards, which can change arbitrarily across
episodes. Further, we consider a challenging but natural bandit feedback
setting that only adversarial rewards of activated arms are revealed to the
decision maker (DM). The goal of the DM is to maximize its total adversarial
rewards during the learning process while the instantaneous activation
constraint must be satisfied in each decision epoch. We develop a novel
reinforcement learning algorithm with two key contributors: a novel biased
adversarial reward estimator to deal with bandit feedback and unknown
transitions, and a low-complexity index policy to satisfy the instantaneous
activation constraint. We show $\tilde{\mathcal{O}}(H\sqrt{T})$ regret bound
for our algorithm, where $T$ is the number of episodes and $H$ is the episode
length. To our best knowledge, this is the first algorithm to ensure
$\tilde{\mathcal{O}}(\sqrt{T})$ regret for adversarial RMAB in our considered
challenging settings.

ÊëòË¶ÅÔºö‰∏çÂÆâÂàÜÁöÑ Multi-Armed Bandits (RMAB) Âú®Âª∫Ê®°ÂÖ∑ÊúâÂç≥Êó∂ÊøÄÊ¥ªÁ∫¶ÊùüÁöÑÈ°∫Â∫èÂÜ≥Á≠ñÈóÆÈ¢ò‰∏≠ÂèëÊå•ÁùÄÊ†∏ÂøÉ‰ΩúÁî®ÔºåËØ•Á∫¶ÊùüËßÑÂÆöÂú®‰ªª‰ΩïÂÜ≥Á≠ñÊó∂ÊúüÊúÄÂ§öÂèØ‰ª•ÊøÄÊ¥ª B ‰∏™ËáÇ„ÄÇÊØè‰∏™‰∏çÂÆâÂàÜÁöÑËáÇÈÉΩÂÖ∑Êúâ‰∏Ä‰∏™Áä∂ÊÄÅÔºåËØ•Áä∂ÊÄÅÊ†πÊçÆÈ©¨Â∞îÂèØÂ§´ÂÜ≥Á≠ñËøáÁ®ãÁã¨Á´ãÊºîÂèòÔºåÊó†ËÆ∫ÊòØÂê¶Ë¢´ÊøÄÊ¥ª„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨ËÄÉËôëÂú®ÂÖ∑ÊúâÊú™Áü•ËΩ¨ÁßªÂáΩÊï∞ÂíåÂØπÊäóÊÄßÂ•ñÂä±ÁöÑÊÉÖÊôØ RMAB ‰∏≠Â≠¶‰π†ÁöÑ‰ªªÂä°ÔºåËøô‰∫õÂ•ñÂä±ÂèØËÉΩ‰ºöÂú®‰∏çÂêåÊÉÖÊôØ‰∏≠‰ªªÊÑèÊîπÂèò„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨ËÄÉËôë‰∫Ü‰∏Ä‰∏™ÂÖ∑ÊúâÊåëÊàòÊÄß‰ΩÜËá™ÁÑ∂ÁöÑËµåÂæíÂèçÈ¶àËÆæÁΩÆÔºåÂÖ∂‰∏≠Âè™ÊúâÂ∑≤ÊøÄÊ¥ªËáÇÁöÑÂØπÊäóÊÄßÂ•ñÂä±Êâç‰ºöÂêëÂÜ≥Á≠ñËÄÖ (DM) ÈÄèÈú≤„ÄÇDM ÁöÑÁõÆÊ†áÊòØÂú®Â≠¶‰π†ËøáÁ®ã‰∏≠ÊúÄÂ§ßÂåñÂÖ∂ÂØπÊäóÊÄßÊÄªÂ•ñÂä±ÔºåÂêåÊó∂ÂøÖÈ°ªÂú®ÊØè‰∏™ÂÜ≥Á≠ñÊó∂ÊúüÊª°Ë∂≥Âç≥Êó∂ÊøÄÊ¥ªÁ∫¶Êùü„ÄÇÊàë‰ª¨ÂºÄÂèë‰∫Ü‰∏ÄÁßçÊñ∞È¢ñÁöÑÂº∫ÂåñÂ≠¶‰π†ÁÆóÊ≥ïÔºåËØ•ÁÆóÊ≥ïÊúâ‰∏§‰∏™ÂÖ≥ÈîÆË¥°ÁåÆËÄÖÔºö‰∏Ä‰∏™Êñ∞È¢ñÁöÑÂÅèÂ∑ÆÂØπÊäóÊÄßÂ•ñÂä±‰º∞ËÆ°Âô®ÔºåÁî®‰∫éÂ§ÑÁêÜËµåÂæíÂèçÈ¶àÂíåÊú™Áü•ËΩ¨ÁßªÔºå‰ª•Âèä‰∏Ä‰∏™‰ΩéÂ§çÊùÇÂ∫¶ÊåáÊï∞Á≠ñÁï•ÔºåÁî®‰∫éÊª°Ë∂≥Âç≥Êó∂ÊøÄÊ¥ªÁ∫¶Êùü„ÄÇÊàë‰ª¨Â±ïÁ§∫‰∫ÜÁÆóÊ≥ïÁöÑ $\tilde{\mathcal{O}}(H\sqrt{T})$ ÂêéÊÇîÁïåÈôêÔºåÂÖ∂‰∏≠ $T$ ÊòØÊÉÖÊôØÊï∞Ôºå$H$ ÊòØÊÉÖÊôØÈïøÂ∫¶„ÄÇÊçÆÊàë‰ª¨ÊâÄÁü•ÔºåËøôÊòØÁ¨¨‰∏Ä‰∏™ÁÆóÊ≥ïÔºåÂèØ‰ª•Á°Æ‰øùÂú®Êàë‰ª¨ÁöÑËÄÉËôëÁöÑÂÖ∑ÊúâÊåëÊàòÊÄßÁöÑËÆæÁΩÆ‰∏≠ÂØπÊäóÊÄß RMAB ÁöÑ $\tilde{\mathcal{O}}(\sqrt{T})$ ÂêéÊÇî„ÄÇ

##### **The Role of Model Architecture and Scale in Predicting Molecular Properties: Insights from Fine-Tuning RoBERTa, BART, and LLaMA**
2405.00949v1 by Lee Youngmin,Lang S. I. D. Andrew,Cai Duoduo,Wheat R. Stephen

This study introduces a systematic framework to compare the efficacy of Large
Language Models (LLMs) for fine-tuning across various cheminformatics tasks.
Employing a uniform training methodology, we assessed three well-known
models-RoBERTa, BART, and LLaMA-on their ability to predict molecular
properties using the Simplified Molecular Input Line Entry System (SMILES) as a
universal molecular representation format. Our comparative analysis involved
pre-training 18 configurations of these models, with varying parameter sizes
and dataset scales, followed by fine-tuning them on six benchmarking tasks from
DeepChem. We maintained consistent training environments across models to
ensure reliable comparisons. This approach allowed us to assess the influence
of model type, size, and training dataset size on model performance.
Specifically, we found that LLaMA-based models generally offered the lowest
validation loss, suggesting their superior adaptability across tasks and
scales. However, we observed that absolute validation loss is not a definitive
indicator of model performance - contradicts previous research - at least for
fine-tuning tasks: instead, model size plays a crucial role. Through rigorous
replication and validation, involving multiple training and fine-tuning cycles,
our study not only delineates the strengths and limitations of each model type
but also provides a robust methodology for selecting the most suitable LLM for
specific cheminformatics applications. This research underscores the importance
of considering model architecture and dataset characteristics in deploying AI
for molecular property prediction, paving the way for more informed and
effective utilization of AI in drug discovery and related fields.

ÊëòË¶ÅÔºöÊú¨Á†îÁ©∂ÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÁ≥ªÁµ±ÊÄßÁöÑÊû∂ÊßãÔºå‰ª•ÊØîËºÉÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®ÂêÑÁ®ÆÂåñÂ≠∏Ë≥áË®äÂ≠∏‰ªªÂãô‰∏≠ÂæÆË™øÁöÑÂäüÊïà„ÄÇÊé°Áî®Áµ±‰∏ÄÁöÑË®ìÁ∑¥ÊñπÊ≥ïÔºåÊàëÂÄëË©ï‰º∞‰∫Ü‰∏âÂÄãËëóÂêçÁöÑÊ®°Âûã (RoBERTa„ÄÅBART Âíå LLaMA) ‰ΩøÁî®Á∞°ÂåñÂàÜÂ≠êËº∏ÂÖ•Á∑öÊ¢ùËº∏ÂÖ•Á≥ªÁµ± (SMILES) ‰ΩúÁÇ∫ÈÄöÁî®ÂàÜÂ≠êË°®Á§∫Ê†ºÂºèÈ†êÊ∏¨ÂàÜÂ≠êÁâπÊÄßÁöÑËÉΩÂäõ„ÄÇÊàëÂÄëÁöÑÊØîËºÉÂàÜÊûêÊ∂âÂèäÈ†êË®ìÁ∑¥ÈÄô‰∫õÊ®°ÂûãÁöÑ 18 Á®ÆÈÖçÁΩÆÔºåÂÖ∑Êúâ‰∏çÂêåÁöÑÂèÉÊï∏Â§ßÂ∞èÂíåË≥áÊñôÈõÜË¶èÊ®°ÔºåÁÑ∂ÂæåÂú® DeepChem ÁöÑÂÖ≠ÂÄãÂü∫Ê∫ñ‰ªªÂãô‰∏äÂ∞çÂÆÉÂÄëÈÄ≤Ë°åÂæÆË™ø„ÄÇÊàëÂÄëÂú®ÊâÄÊúâÊ®°Âûã‰∏≠‰øùÊåÅ‰∏ÄËá¥ÁöÑË®ìÁ∑¥Áí∞Â¢ÉÔºå‰ª•Á¢∫‰øùÂèØÈù†ÁöÑÊØîËºÉ„ÄÇÈÄôÁ®ÆÊñπÊ≥ï‰ΩøÊàëÂÄëËÉΩÂ§†Ë©ï‰º∞Ê®°ÂûãÈ°ûÂûã„ÄÅÂ§ßÂ∞èÂíåË®ìÁ∑¥Ë≥áÊñôÈõÜÂ§ßÂ∞èÂ∞çÊ®°ÂûãÊïàËÉΩÁöÑÂΩ±Èüø„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÁôºÁèæÂü∫Êñº LLaMA ÁöÑÊ®°ÂûãÈÄöÂ∏∏Êèê‰æõÊúÄ‰ΩéÁöÑÈ©óË≠âÊêçÂ§±ÔºåË°®ÊòéÂÆÉÂÄëÂú®‰ªªÂãôÂíåË¶èÊ®°‰∏äÁöÑÈÅ©ÊáâÊÄßÊõ¥Âº∑„ÄÇÁÑ∂ËÄåÔºåÊàëÂÄëËßÄÂØüÂà∞ÔºåÁµïÂ∞çÈ©óË≠âÊêçÂ§±‰∏¶ÈùûÊ®°ÂûãÊïàËÉΩÁöÑÊ±∫ÂÆöÊÄßÊåáÊ®ô‚Äî‚ÄîËàáÂÖàÂâçÁöÑÁ†îÁ©∂Áõ∏ÁüõÁõæ‚Äî‚ÄîËá≥Â∞ëÂ∞çÊñºÂæÆË™ø‰ªªÂãôËÄåË®ÄÔºöÁõ∏ÂèçÔºåÊ®°ÂûãÂ§ßÂ∞èÁôºÊèÆËëóËá≥ÈóúÈáçË¶ÅÁöÑ‰ΩúÁî®„ÄÇÈÄöÈÅéÂö¥Ê†ºÁöÑË§áË£ΩÂíåÈ©óË≠âÔºåÂåÖÊã¨Â§öÂÄãË®ìÁ∑¥ÂíåÂæÆË™øÈÄ±ÊúüÔºåÊàëÂÄëÁöÑÁ†îÁ©∂‰∏çÂÉÖÊèèËø∞‰∫ÜÊØèÁ®ÆÈ°ûÂûãÊ®°ÂûãÁöÑÂÑ™ÈªûÂíåÁº∫ÈªûÔºåÈÇÑÊèê‰æõ‰∫Ü‰∏ÄÁ®ÆÁî®ÊñºÈÅ∏ÊìáÊúÄÈÅ©ÂêàÁâπÂÆöÂåñÂ≠∏Ë≥áË®äÂ≠∏ÊáâÁî®Á®ãÂºèÁöÑÂº∑ÂÅ•ÊñπÊ≥ïË´ñ„ÄÇÊú¨Á†îÁ©∂Âº∑Ë™ø‰∫ÜÂú®ÈÉ®ÁΩ≤ AI ÈÄ≤Ë°åÂàÜÂ≠êÊÄßË≥™È†êÊ∏¨ÊôÇËÄÉÊÖÆÊ®°ÂûãÊû∂ÊßãÂíåË≥áÊñôÈõÜÁâπÂæµÁöÑÈáçË¶ÅÊÄßÔºåÁÇ∫Âú®Ëó•Áâ©ÁôºÁèæÂíåÁõ∏ÈóúÈ†òÂüüÊõ¥ÊòéÊô∫ÂíåÊúâÊïàÂú∞Âà©Áî® AI Èã™Âπ≥‰∫ÜÈÅìË∑Ø„ÄÇ

##### **Modeling Empathetic Alignment in Conversation**
2405.00948v1 by Jiamin Yang,David Jurgens

Empathy requires perspective-taking: empathetic responses require a person to
reason about what another has experienced and communicate that understanding in
language. However, most NLP approaches to empathy do not explicitly model this
alignment process. Here, we introduce a new approach to recognizing alignment
in empathetic speech, grounded in Appraisal Theory. We introduce a new dataset
of over 9.2K span-level annotations of different types of appraisals of a
person's experience and over 3K empathetic alignments between a speaker's and
observer's speech. Through computational experiments, we show that these
appraisals and alignments can be accurately recognized. In experiments in over
9.2M Reddit conversations, we find that appraisals capture meaningful groupings
of behavior but that most responses have minimal alignment. However, we find
that mental health professionals engage with substantially more empathetic
alignment.

ÊëòË¶ÅÔºöÂêåÁêÜÂøÉÈúÄË¶ÅÊèõ‰ΩçÊÄùËÄÉÔºöÂêåÁêÜÂøÉÁöÑÂõûÊáâË¶ÅÊ±Ç‰∏ÄÂÄã‰∫∫Êé®ÁêÜ‰ªñ‰∫∫Á∂ìÊ≠∑ÈÅé‰ªÄÈ∫ºÔºå‰∏¶Áî®Ë™ûË®ÄÂÇ≥ÈÅîÈÄôÁ®ÆÁêÜËß£„ÄÇÁÑ∂ËÄåÔºåÂ§ßÂ§öÊï∏Â∞çÂêåÁêÜÂøÉÁöÑ NLP ÊñπÊ≥ï‰∏¶Ê≤íÊúâÊòéÁ¢∫Âú∞Âª∫Ê®°ÈÄôÂÄãÂ∞çÈΩäÈÅéÁ®ã„ÄÇÂú®Ê≠§ÔºåÊàëÂÄëÂºïÂÖ•‰∏ÄÁ®ÆÊñ∞ÁöÑÊñπÊ≥ï‰æÜË≠òÂà•ÂêåÁêÜÂøÉË®ÄË™û‰∏≠ÁöÑÂ∞çÈΩäÔºåÈÄôÁ®ÆÊñπÊ≥ï‰ª•Ë©ï‰º∞ÁêÜË´ñÁÇ∫Âü∫Á§é„ÄÇÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÊñ∞ÁöÑÊï∏ÊìöÈõÜÔºåÂÖ∂‰∏≠ÂåÖÂê´Â∞çÊüê‰∫∫Á∂ìÊ≠∑ÁöÑ‰∏çÂêåÈ°ûÂûãË©ï‰º∞ÁöÑ 9.2K ‰ª•‰∏äÁöÑË∑®Â∫¶Á¥öÂà•Ë®ªÈáãÔºå‰ª•ÂèäË™™Ë©±ËÄÖÂíåËßÄÂØüËÄÖË®ÄË™û‰πãÈñìÁöÑ 3K ‰ª•‰∏äÁöÑÂêåÁêÜÂøÉÂ∞çÈΩä„ÄÇÈÄöÈÅéË®àÁÆóÂØ¶È©óÔºåÊàëÂÄëË°®ÊòéÈÄô‰∫õË©ï‰º∞ÂíåÂ∞çÈΩäÂèØ‰ª•Ë¢´Ê∫ñÁ¢∫Âú∞Ë≠òÂà•Âá∫‰æÜ„ÄÇÂú®Ë∂ÖÈÅé 920 Ëê¨ Reddit Â∞çË©±ÁöÑÂØ¶È©ó‰∏≠ÔºåÊàëÂÄëÁôºÁèæË©ï‰º∞ÊçïÊçâÂà∞‰∫ÜÊúâÊÑèÁæ©ÁöÑË°åÁÇ∫Áæ§ÁµÑÔºå‰ΩÜÂ§ßÂ§öÊï∏ÂõûÊáâÁöÑÂ∞çÈΩäÁ®ãÂ∫¶Âæà‰Ωé„ÄÇÁÑ∂ËÄåÔºåÊàëÂÄëÁôºÁèæÂøÉÁêÜÂÅ•Â∫∑Â∞àÊ•≠‰∫∫Âì°ÂèÉËàá‰∫ÜÊõ¥Â§öÂÖ∑ÊúâÂêåÁêÜÂøÉÁöÑÂ∞çÈΩä„ÄÇ

##### **LLaVA Finds Free Lunch: Teaching Human Behavior Improves Content Understanding Abilities Of LLMs**
2405.00942v1 by Somesh Singh,Harini S I,Yaman K Singla,Veeky Baths,Rajiv Ratn Shah,Changyou Chen,Balaji Krishnamurthy

Communication is defined as ``Who says what to whom with what effect.'' A
message from a communicator generates downstream receiver effects, also known
as behavior. Receiver behavior, being a downstream effect of the message,
carries rich signals about it. Even after carrying signals about the message,
the behavior data is often ignored while training large language models. We
show that training LLMs on receiver behavior can actually help improve their
content-understanding abilities. Specifically, we show that training LLMs to
predict the receiver behavior of likes and comments improves the LLM's
performance on a wide variety of downstream content understanding tasks. We
show this performance increase over 40 video and image understanding tasks over
23 benchmark datasets across both 0-shot and fine-tuning settings,
outperforming many supervised baselines. Moreover, since receiver behavior,
such as likes and comments, is collected by default on the internet and does
not need any human annotations to be useful, the performance improvement we get
after training on this data is essentially free-lunch. We release the receiver
behavior cleaned comments and likes of 750k images and videos collected from
multiple platforms along with our instruction-tuning data.

ÊëòË¶ÅÔºöÊ≤üÈÄöË¢´ÂÆö‰πâ‰∏∫„ÄåË∞ÅÂØπË∞ÅËØ¥‰ªÄ‰πàÔºåÊúâ‰ªÄ‰πàÊïàÊûú„ÄÇ„ÄçÊ≤üÈÄöËÄÖÁöÑËÆØÊÅØ‰ºö‰∫ßÁîü‰∏ãÊ∏∏Êé•Êî∂ËÄÖÁöÑÊïàÊûúÔºå‰πüÂ∞±ÊòØË°å‰∏∫„ÄÇÊé•Êî∂ËÄÖÁöÑË°å‰∏∫Ôºå‰Ωú‰∏∫ËÆØÊÅØÁöÑ‰∏ãÊ∏∏ÊïàÊûúÔºå‰ºö‰º†ÈÄíÂá∫‰∏∞ÂØåÁöÑËÆØÂè∑„ÄÇÂç≥‰ΩøÂú®‰º†ÈÄí‰∫ÜÂÖ≥‰∫éËÆØÊÅØÁöÑËÆØÂè∑ÂêéÔºåË°å‰∏∫ËµÑÊñôÂú®ËÆ≠ÁªÉÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÊó∂‰ªçÂ∏∏Ë¢´ÂøΩÁï•„ÄÇÊàë‰ª¨ËØÅÊòéÂú®Êé•Êî∂ËÄÖÁöÑË°å‰∏∫‰∏äËÆ≠ÁªÉ LLM ÂÆûÈôÖ‰∏äÂèØ‰ª•Â∏ÆÂä©ÊîπÂñÑÂÖ∂ÂÜÖÂÆπÁêÜËß£ËÉΩÂäõ„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåÊàë‰ª¨ËØÅÊòéËÆ≠ÁªÉ LLM Êù•È¢ÑÊµãÊåâËµûÂíåÁïôË®ÄÁöÑÊé•Êî∂ËÄÖË°å‰∏∫ÔºåÂèØ‰ª•ÊîπÂñÑ LLM Âú®ÂêÑÁßç‰∏ãÊ∏∏ÂÜÖÂÆπÁêÜËß£‰ªªÂä°‰∏äÁöÑË°®Áé∞„ÄÇÊàë‰ª¨Âú® 23 ‰∏™Âü∫ÂáÜÊï∞ÊçÆÈõÜ‰∏äÂØπ 40 ‰∏™ËßÜÈ¢ëÂíåÂõæÂÉèÁêÜËß£‰ªªÂä°Â±ïÁ§∫‰∫ÜËøôÁßçÊÄßËÉΩÊèêÂçáÔºåÂú®Èõ∂Ê¨°Â≠¶‰π†ÂíåÂæÆË∞ÉËÆæÁΩÆ‰∏≠ÈÉΩ‰ºò‰∫éËÆ∏Â§öÁõëÁù£Âü∫ÂáÜ„ÄÇÊ≠§Â§ñÔºåÁî±‰∫éÊé•Êî∂ËÄÖÁöÑË°å‰∏∫Ôºà‰æãÂ¶ÇÊåâËµûÂíåÁïôË®ÄÔºâÂú®‰∫íËÅîÁΩë‰∏äÊòØÈªòËÆ§Êî∂ÈõÜÁöÑÔºåÂπ∂‰∏î‰∏çÈúÄË¶Å‰ªª‰Ωï‰∫∫Â∑•Ê≥®ÈáäÂç≥ÂèØÂèëÊå•‰ΩúÁî®ÔºåÂõ†Ê≠§Êàë‰ª¨Âú®ËÆ≠ÁªÉÊ≠§ËµÑÊñôÂêéËé∑ÂæóÁöÑÊÄßËÉΩÊèêÂçáÂü∫Êú¨‰∏äÊòØÂÖçË¥πÁöÑ„ÄÇÊàë‰ª¨ÂèëÂ∏É‰∫Ü‰ªéÂ§ö‰∏™Âπ≥Âè∞Êî∂ÈõÜÁöÑ 750,000 Âº†ÂõæÂÉèÂíåËßÜÈ¢ëÁöÑÁªèËøáÊï¥ÁêÜÁöÑÊé•Êî∂ËÄÖË°å‰∏∫ÁïôË®ÄÂíåÊåâËµûÔºå‰ª•ÂèäÊàë‰ª¨ÁöÑÊåá‰ª§ÂæÆË∞ÉËµÑÊñô„ÄÇ

##### **EchoScene: Indoor Scene Generation via Information Echo over Scene Graph Diffusion**
2405.00915v1 by Guangyao Zhai,Evin Pƒ±nar √ñrnek,Dave Zhenyu Chen,Ruotong Liao,Yan Di,Nassir Navab,Federico Tombari,Benjamin Busam

We present EchoScene, an interactive and controllable generative model that
generates 3D indoor scenes on scene graphs. EchoScene leverages a dual-branch
diffusion model that dynamically adapts to scene graphs. Existing methods
struggle to handle scene graphs due to varying numbers of nodes, multiple edge
combinations, and manipulator-induced node-edge operations. EchoScene overcomes
this by associating each node with a denoising process and enables
collaborative information exchange, enhancing controllable and consistent
generation aware of global constraints. This is achieved through an information
echo scheme in both shape and layout branches. At every denoising step, all
processes share their denoising data with an information exchange unit that
combines these updates using graph convolution. The scheme ensures that the
denoising processes are influenced by a holistic understanding of the scene
graph, facilitating the generation of globally coherent scenes. The resulting
scenes can be manipulated during inference by editing the input scene graph and
sampling the noise in the diffusion model. Extensive experiments validate our
approach, which maintains scene controllability and surpasses previous methods
in generation fidelity. Moreover, the generated scenes are of high quality and
thus directly compatible with off-the-shelf texture generation. Code and
trained models are open-sourced.

ÊëòË¶ÅÔºöÊàëÂÄëÊèêÂá∫ EchoSceneÔºå‰∏ÄÁ®Æ‰∫íÂãï‰∏îÂèØÊéßÁöÑÁîüÊàêÊ®°ÂûãÔºåÂèØÂú®Â†¥ÊôØÂúñ‰∏äÁîüÊàê 3D ÂÆ§ÂÖßÂ†¥ÊôØ„ÄÇEchoScene Âà©Áî®ÈõôÂàÜÊîØÊì¥Êï£Ê®°ÂûãÔºåÂèØÂãïÊÖãÈÅ©ÊáâÂ†¥ÊôØÂúñ„ÄÇÁèæÊúâÊñπÊ≥ïÁî±ÊñºÁØÄÈªûÊï∏Èáè‰∏çÂêå„ÄÅÈÇäÁ∑£ÁµÑÂêàÂ§öÊ®£‰ª•ÂèäÊìç‰ΩúÂô®ÂºïÁôºÁöÑÁØÄÈªûÈÇäÁ∑£Êìç‰ΩúÔºåÈõ£‰ª•ËôïÁêÜÂ†¥ÊôØÂúñ„ÄÇEchoScene ÈÄöÈÅéÂ∞áÊØèÂÄãÁØÄÈªûËàáÂéªÂô™Á®ãÂ∫èÈóúËÅØËµ∑‰æÜÔºå‰∏¶ÂïüÁî®Âçî‰ΩúË≥áË®ä‰∫§ÊèõÔºåÂ¢ûÂº∑ÂèØÊéß‰∏î‰∏ÄËá¥ÁöÑÁîüÊàêÔºå‰∏¶ÊÑèË≠òÂà∞ÂÖ®Â±ÄÁ¥ÑÊùü„ÄÇÈÄôÊòØÈÄèÈÅéÂΩ¢ÁãÄÂíå‰ΩàÂ±ÄÂàÜÊîØ‰∏≠ÁöÑË≥áË®äËø¥Èü≥ÊñπÊ°àÂØ¶ÁèæÁöÑ„ÄÇÂú®ÊØèÂÄãÂéªÂô™Ê≠•È©ü‰∏≠ÔºåÊâÄÊúâÁ®ãÂ∫èÈÉΩÊúÉËàáË≥áË®ä‰∫§ÊèõÂñÆÂÖÉÂÖ±‰∫´ÂÖ∂ÂéªÂô™Ë≥áÊñôÔºåË©≤ÂñÆÂÖÉ‰ΩøÁî®ÂúñÂΩ¢Âç∑Á©çÁµêÂêàÈÄô‰∫õÊõ¥Êñ∞„ÄÇË©≤ÊñπÊ°àÁ¢∫‰øùÂéªÂô™Á®ãÂ∫èÂèóÂà∞Â†¥ÊôØÂúñÊï¥È´îÁêÜËß£ÁöÑÂΩ±ÈüøÔºåÂæûËÄå‰øÉÈÄ≤ÁîüÊàêÂÖ®Â±Ä‰∏ÄËá¥ÁöÑÂ†¥ÊôØ„ÄÇÁî¢ÁîüÁöÑÂ†¥ÊôØÂèØ‰ª•Âú®Êé®ÁêÜÊúüÈñìÈÄèÈÅéÁ∑®ËºØËº∏ÂÖ•Â†¥ÊôØÂúñÂíåÂ∞çÊì¥Êï£Ê®°Âûã‰∏≠ÁöÑÈõúË®äÈÄ≤Ë°åÊé°Ê®£‰æÜÊìç‰Ωú„ÄÇÂª£Ê≥õÁöÑÂØ¶È©óÈ©óË≠â‰∫ÜÊàëÂÄëÁöÑÂÅöÊ≥ïÔºåÂÆÉ‰øùÊåÅ‰∫ÜÂ†¥ÊôØÁöÑÂèØÊéßÊÄßÔºå‰∏¶Âú®ÁîüÊàê‰øùÁúüÂ∫¶ÊñπÈù¢Ë∂ÖË∂ä‰∫Ü‰ª•ÂâçÁöÑÊñπÊ≥ï„ÄÇÊ≠§Â§ñÔºåÁîüÊàêÁöÑÂ†¥ÊôØÂìÅË≥™ÂæàÈ´òÔºåÂõ†Ê≠§ÂèØÁõ¥Êé•Áõ∏ÂÆπÊñºÁèæÊàêÁöÑÁ¥ãÁêÜÁîüÊàê„ÄÇÁ®ãÂºèÁ¢ºÂíåË®ìÁ∑¥Ê®°ÂûãÊòØÈñãÊ∫êÁöÑ„ÄÇ

##### **Transformer-Based Self-Supervised Learning for Histopathological Classification of Ischemic Stroke Clot Origin**
2405.00908v1 by K. Yeh,M. S. Jabal,V. Gupta,D. F. Kallmes,W. Brinjikji,B. S. Erdal

Background and Purpose: Identifying the thromboembolism source in ischemic
stroke is crucial for treatment and secondary prevention yet is often
undetermined. This study describes a self-supervised deep learning approach in
digital pathology of emboli for classifying ischemic stroke clot origin from
histopathological images. Methods: The dataset included whole slide images
(WSI) from the STRIP AI Kaggle challenge, consisting of retrieved clots from
ischemic stroke patients following mechanical thrombectomy. Transformer-based
deep learning models were developed using transfer learning and self-supervised
pretraining for classifying WSI. Customizations included an attention pooling
layer, weighted loss function, and threshold optimization. Various model
architectures were tested and compared, and model performances were primarily
evaluated using weighted logarithmic loss. Results: The model achieved a
logloss score of 0.662 in cross-validation and 0.659 on the test set. Different
model backbones were compared, with the swin_large_patch4_window12_384 showed
higher performance. Thresholding techniques for clot origin classification were
employed to balance false positives and negatives. Conclusion: The study
demonstrates the extent of efficacy of transformer-based deep learning models
in identifying ischemic stroke clot origins from histopathological images and
emphasizes the need for refined modeling techniques specifically adapted to
thrombi WSI. Further research is needed to improve model performance,
interpretability, validate its effectiveness. Future enhancement could include
integrating larger patient cohorts, advanced preprocessing strategies, and
exploring ensemble multimodal methods for enhanced diagnostic accuracy.

ÊëòË¶ÅÔºö<paragraph>ËÉåÊôØËàáÁõÆÁöÑÔºöÁ¢∫ÂÆöÁº∫Ë°ÄÊÄß‰∏≠È¢®ÁöÑË°ÄÊ†ìÊ†ìÂ°û‰æÜÊ∫êÂ∞çÊñºÊ≤ªÁôÇÂíå‰∫åÊ¨°È†êÈò≤Ëá≥ÈóúÈáçË¶ÅÔºå‰ΩÜÈÄöÂ∏∏ÁÑ°Ê≥ïÁ¢∫ÂÆö„ÄÇÊú¨Á†îÁ©∂ÊèèËø∞‰∫ÜÊï∏Â≠óÁóÖÁêÜÂ≠∏‰∏≠Ê†ìÂ°ûÁöÑËá™ÊàëÁõ£Áù£Ê∑±Â∫¶Â≠∏ÁøíÊñπÊ≥ïÔºåÁî®ÊñºÊ†πÊìöÁµÑÁπîÁóÖÁêÜÂ≠∏ÂúñÂÉèÂ∞çÁº∫Ë°ÄÊÄß‰∏≠È¢®Ë°ÄÂ°ä‰æÜÊ∫êÈÄ≤Ë°åÂàÜÈ°û„ÄÇÊñπÊ≥ïÔºöË©≤Êï∏ÊìöÈõÜÂåÖÊã¨‰æÜËá™ STRIP AI Kaggle ÊåëÊà∞Ë≥ΩÁöÑÂÖ®ÂπªÁáàÁâáÂúñÂÉè (WSI)ÔºåÁî±Ê©üÊ¢∞Ë°ÄÊ†ìÂàáÈô§Ë°ìÂæåÁº∫Ë°ÄÊÄß‰∏≠È¢®ÊÇ£ËÄÖÂèñÂá∫ÁöÑË°ÄÂ°äÁµÑÊàê„ÄÇ‰ΩøÁî®ÈÅ∑ÁßªÂ≠∏ÁøíÂíåËá™ÊàëÁõ£Áù£È†êË®ìÁ∑¥ÈñãÁôº‰∫ÜÂü∫Êñº Transformer ÁöÑÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÔºåÁî®ÊñºÂ∞ç WSI ÈÄ≤Ë°åÂàÜÈ°û„ÄÇËá™ÂÆöÁæ©ÂåÖÊã¨Ê≥®ÊÑèÊ±†ÂåñÂ±§„ÄÅÂä†Ê¨äÊêçÂ§±ÂáΩÊï∏ÂíåÈñæÂÄºÂÑ™Âåñ„ÄÇÊ∏¨Ë©¶‰∏¶ÊØîËºÉ‰∫ÜÂêÑÁ®ÆÊ®°ÂûãÊû∂ÊßãÔºå‰∏¶‰∏ªË¶Å‰ΩøÁî®Âä†Ê¨äÂ∞çÊï∏ÊêçÂ§±Â∞çÊ®°ÂûãÊÄßËÉΩÈÄ≤Ë°åË©ï‰º∞„ÄÇÁµêÊûúÔºöË©≤Ê®°ÂûãÂú®‰∫§ÂèâÈ©óË≠â‰∏≠ÂØ¶Áèæ‰∫Ü 0.662 ÁöÑÂ∞çÊï∏ÊêçÂ§±ÂàÜÊï∏ÔºåÂú®Ê∏¨Ë©¶ÈõÜ‰∏≠ÂØ¶Áèæ‰∫Ü 0.659„ÄÇÊØîËºÉ‰∫Ü‰∏çÂêåÁöÑÊ®°Âûã‰∏ªÂππÔºåÂÖ∂‰∏≠ swin_large_patch4_window12_384 Ë°®ÁèæÂá∫Êõ¥È´òÁöÑÊÄßËÉΩ„ÄÇÊé°Áî®‰∫ÜË°ÄÂ°ä‰æÜÊ∫êÂàÜÈ°ûÁöÑÈñæÂÄºÊäÄË°ì‰æÜÂπ≥Ë°°ÂÅáÈôΩÊÄßÂíåÂÅáÈô∞ÊÄß„ÄÇÁµêË´ñÔºöË©≤Á†îÁ©∂Â±ïÁ§∫‰∫ÜÂü∫Êñº Transformer ÁöÑÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÂú®ÂæûÁµÑÁπîÁóÖÁêÜÂ≠∏ÂúñÂÉè‰∏≠Ë≠òÂà•Áº∫Ë°ÄÊÄß‰∏≠È¢®Ë°ÄÂ°ä‰æÜÊ∫êÊñπÈù¢ÁöÑÂäüÊïàÁ®ãÂ∫¶Ôºå‰∏¶Âº∑Ë™ø‰∫ÜÂ∞àÈñÄÈáùÂ∞çË°ÄÊ†ì WSI Ë™øÊï¥Âª∫Ê®°ÊäÄË°ìÁöÑÂøÖË¶ÅÊÄß„ÄÇÈúÄË¶ÅÈÄ≤‰∏ÄÊ≠•Á†îÁ©∂‰ª•ÊèêÈ´òÊ®°ÂûãÊÄßËÉΩ„ÄÅÂèØËß£ÈáãÊÄß„ÄÅÈ©óË≠âÂÖ∂ÊúâÊïàÊÄß„ÄÇÊú™‰æÜÁöÑÊîπÈÄ≤ÂèØËÉΩÂåÖÊã¨Êï¥ÂêàÊõ¥Â§ßÁöÑÊÇ£ËÄÖÁæ§È´î„ÄÅÂÖàÈÄ≤ÁöÑÈ†êËôïÁêÜÁ≠ñÁï•Ôºå‰∏¶Êé¢Á¥¢ÈõÜÊàêÂ§öÊ®°ÊÖãÊñπÊ≥ï‰ª•ÊèêÈ´òË®∫Êñ∑Ê∫ñÁ¢∫ÊÄß„ÄÇ</paragraph>

##### **LOTUS: Improving Transformer Efficiency with Sparsity Pruning and Data Lottery Tickets**
2405.00906v1 by Ojasw Upadhyay

Vision transformers have revolutionized computer vision, but their
computational demands present challenges for training and deployment. This
paper introduces LOTUS (LOttery Transformers with Ultra Sparsity), a novel
method that leverages data lottery ticket selection and sparsity pruning to
accelerate vision transformer training while maintaining accuracy. Our approach
focuses on identifying and utilizing the most informative data subsets and
eliminating redundant model parameters to optimize the training process.
Through extensive experiments, we demonstrate the effectiveness of LOTUS in
achieving rapid convergence and high accuracy with significantly reduced
computational requirements. This work highlights the potential of combining
data selection and sparsity techniques for efficient vision transformer
training, opening doors for further research and development in this area.

ÊëòË¶ÅÔºöË¶ñË¶∫TransformerÂæπÂ∫ïÊîπËÆä‰∫ÜÈõªËÖ¶Ë¶ñË¶∫Ôºå‰ΩÜÂÆÉÂÄëÁöÑÈÅãÁÆóÈúÄÊ±ÇÂ∞çË®ìÁ∑¥ÂíåÈÉ®ÁΩ≤ÊèêÂá∫‰∫ÜÊåëÊà∞„ÄÇÊú¨Êñá‰ªãÁ¥π‰∫Ü LOTUSÔºàÂÖ∑ÊúâË∂ÖÁ®ÄÁñèÊÄßÁöÑÊ®ÇÈÄèTransformerÔºâÔºåÈÄôÊòØ‰∏ÄÁ®ÆÊñ∞ÊñπÊ≥ïÔºåÂà©Áî®Êï∏ÊìöÊ®ÇÈÄèÈÅ∏Á•®ÈÅ∏ÊìáÂíåÁ®ÄÁñèÊÄßÂâ™Êûù‰æÜÂä†ÈÄüË¶ñË¶∫TransformerË®ìÁ∑¥ÔºåÂêåÊôÇ‰øùÊåÅÊ∫ñÁ¢∫ÊÄß„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÂ∞àÊ≥®ÊñºË≠òÂà•ÂíåÂà©Áî®ÊúÄÊúâË≥áË®äÊÄßÁöÑÊï∏ÊìöÂ≠êÈõÜÔºå‰∏¶Ê∂àÈô§Â§öÈ§òÁöÑÊ®°ÂûãÂèÉÊï∏‰æÜÂÑ™ÂåñË®ìÁ∑¥ÈÅéÁ®ã„ÄÇÈÄèÈÅéÂª£Ê≥õÁöÑÂØ¶È©óÔºåÊàëÂÄëË≠âÊòé‰∫Ü LOTUS Âú®È°ØËëóÈôç‰ΩéÈÅãÁÆóÈúÄÊ±ÇÁöÑÊÉÖÊ≥Å‰∏ãÂØ¶ÁèæÂø´ÈÄüÊî∂ÊñÇÂíåÈ´òÊ∫ñÁ¢∫ÊÄßÁöÑÊúâÊïàÊÄß„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÁ™ÅÈ°Ø‰∫ÜÁµêÂêàÊï∏ÊìöÈÅ∏ÊìáÂíåÁ®ÄÁñèÊÄßÊäÄË°ì‰ª•ÈÄ≤Ë°åÊúâÊïàË¶ñË¶∫TransformerË®ìÁ∑¥ÁöÑÊΩõÂäõÔºåÁÇ∫Ë©≤È†òÂüüÁöÑÈÄ≤‰∏ÄÊ≠•Á†îÁ©∂ÂíåÈñãÁôºÊâìÈñã‰∫ÜÂ§ßÈñÄ„ÄÇ

##### **A Named Entity Recognition and Topic Modeling-based Solution for Locating and Better Assessment of Natural Disasters in Social Media**
2405.00903v1 by Ayaz Mehmood,Muhammad Tayyab Zamir,Muhammad Asif Ayub,Nasir Ahmad,Kashif Ahmad

Over the last decade, similar to other application domains, social media
content has been proven very effective in disaster informatics. However, due to
the unstructured nature of the data, several challenges are associated with
disaster analysis in social media content. To fully explore the potential of
social media content in disaster informatics, access to relevant content and
the correct geo-location information is very critical. In this paper, we
propose a three-step solution to tackling these challenges. Firstly, the
proposed solution aims to classify social media posts into relevant and
irrelevant posts followed by the automatic extraction of location information
from the posts' text through Named Entity Recognition (NER) analysis. Finally,
to quickly analyze the topics covered in large volumes of social media posts,
we perform topic modeling resulting in a list of top keywords, that highlight
the issues discussed in the tweet. For the Relevant Classification of Twitter
Posts (RCTP), we proposed a merit-based fusion framework combining the
capabilities of four different models namely BERT, RoBERTa, Distil BERT, and
ALBERT obtaining the highest F1-score of 0.933 on a benchmark dataset. For the
Location Extraction from Twitter Text (LETT), we evaluated four models namely
BERT, RoBERTa, Distil BERTA, and Electra in an NER framework obtaining the
highest F1-score of 0.960. For topic modeling, we used the BERTopic library to
discover the hidden topic patterns in the relevant tweets. The experimental
results of all the components of the proposed end-to-end solution are very
encouraging and hint at the potential of social media content and NLP in
disaster management.

ÊëòË¶ÅÔºö<paragraph>Âú®ÈÅéÂéªÂçÅÂπ¥‰∏≠ÔºåËàáÂÖ∂‰ªñÊáâÁî®È†òÂüüÈ°û‰ººÔºåÁ§æ‰∫§Â™íÈ´îÂÖßÂÆπÂ∑≤Ë¢´Ë≠âÊòéÂú®ÁÅΩÂÆ≥‰ø°ÊÅØÂ≠∏‰∏≠ÈùûÂ∏∏ÊúâÊïà„ÄÇÁÑ∂ËÄåÔºåÁî±ÊñºÊï∏ÊìöÁöÑÈùûÁµêÊßãÂåñÊÄßË≥™ÔºåÁ§æ‰∫§Â™íÈ´îÂÖßÂÆπ‰∏≠ÁöÑÁÅΩÂÆ≥ÂàÜÊûêÈù¢Ëá®ËëóË®±Â§öÊåëÊà∞„ÄÇÁÇ∫‰∫ÜÂÖÖÂàÜÊé¢Á¥¢Á§æ‰∫§Â™íÈ´îÂÖßÂÆπÂú®ÁÅΩÂÆ≥‰ø°ÊÅØÂ≠∏‰∏≠ÁöÑÊΩõÂäõÔºåË®™ÂïèÁõ∏ÈóúÂÖßÂÆπÂíåÊ≠£Á¢∫ÁöÑÂú∞ÁêÜ‰ΩçÁΩÆ‰ø°ÊÅØÈùûÂ∏∏ÈóúÈçµ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÁöÑ‰∏âÊ≠•È©üËß£Ê±∫ÊñπÊ°à„ÄÇÈ¶ñÂÖàÔºåÊâÄÊèêÂá∫ÁöÑËß£Ê±∫ÊñπÊ°àÊó®Âú®Â∞áÁ§æ‰∫§Â™íÈ´îË≤ºÊñáÂàÜÈ°ûÁÇ∫Áõ∏ÈóúÂíå‰∏çÁõ∏ÈóúÁöÑË≤ºÊñáÔºåÁÑ∂ÂæåÈÄöÈÅéÂëΩÂêçÂØ¶È´îË≠òÂà• (NER) ÂàÜÊûêÂæûË≤ºÊñáÁöÑÊñáÂ≠ó‰∏≠Ëá™ÂãïÊèêÂèñ‰ΩçÁΩÆ‰ø°ÊÅØ„ÄÇÊúÄÂæåÔºåÁÇ∫‰∫ÜÂø´ÈÄüÂàÜÊûêÂ§ßÈáèÁ§æ‰∫§Â™íÈ´îË≤ºÊñá‰∏≠Ê∂µËìãÁöÑ‰∏ªÈ°åÔºåÊàëÂÄëÂü∑Ë°å‰∏ªÈ°åÂª∫Ê®°ÔºåÁîüÊàê‰∏ÄÂÄãÈ†ÇÁ¥öÈóúÈçµÂ≠óÊ∏ÖÂñÆÔºåÈáçÈªûË™™ÊòéÊé®Êñá‰∏≠Ë®éË´ñÁöÑÂïèÈ°å„ÄÇÂ∞çÊñºÊé®ÊñáÁõ∏ÈóúÂàÜÈ°û (RCTP)ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂü∫ÊñºÂÑ™ÈªûÁöÑËûçÂêàÊ°ÜÊû∂ÔºåÁµêÂêà‰∫ÜÂõõÁ®Æ‰∏çÂêåÊ®°ÂûãÁöÑÂäüËÉΩÔºåÂç≥ BERT„ÄÅRoBERTa„ÄÅDistil BERT Âíå ALBERTÔºåÂú®Âü∫Ê∫ñÊï∏ÊìöÈõÜ‰∏äÁç≤Âæó‰∫Ü 0.933 ÁöÑÊúÄÈ´ò F1 ÂàÜÊï∏„ÄÇÂ∞çÊñºÂæûÊé®ÊñáÊñáÂ≠ó‰∏≠ÊèêÂèñ‰ΩçÁΩÆ (LETT)ÔºåÊàëÂÄëÂú® NER Ê°ÜÊû∂‰∏≠Ë©ï‰º∞‰∫ÜÂõõÂÄãÊ®°ÂûãÔºåÂç≥ BERT„ÄÅRoBERTa„ÄÅDistil BERTA Âíå ElectraÔºåÁç≤Âæó‰∫Ü 0.960 ÁöÑÊúÄÈ´ò F1 ÂàÜÊï∏„ÄÇÂ∞çÊñº‰∏ªÈ°åÂª∫Ê®°ÔºåÊàëÂÄë‰ΩøÁî®‰∫Ü BERTopic ÂáΩÂºèÂ∫´‰æÜÁôºÁèæÁõ∏ÈóúÊé®Êñá‰∏≠ÁöÑÈö±Ëóè‰∏ªÈ°åÊ®°Âºè„ÄÇÊâÄÊèêÂá∫ÁöÑÁ´ØÂà∞Á´ØËß£Ê±∫ÊñπÊ°àÁöÑÊâÄÊúâÁµÑÊàêÁöÑÂØ¶È©óÁµêÊûúÈùûÂ∏∏‰ª§‰∫∫ÈºìËàûÔºå‰∏¶ÊöóÁ§∫‰∫ÜÁ§æ‰∫§Â™íÈ´îÂÖßÂÆπÂíå NLP Âú®ÁÅΩÂÆ≥ÁÆ°ÁêÜ‰∏≠ÁöÑÊΩõÂäõ„ÄÇ</paragraph>

##### **Characterising the Creative Process in Humans and Large Language Models**
2405.00899v1 by Surabhi S. Nath,Peter Dayan,Claire Stevenson

Large language models appear quite creative, often performing on par with the
average human on creative tasks. However, research on LLM creativity has
focused solely on \textit{products}, with little attention on the creative
\textit{process}. Process analyses of human creativity often require hand-coded
categories or exploit response times, which do not apply to LLMs. We provide an
automated method to characterise how humans and LLMs explore semantic spaces on
the Alternate Uses Task, and contrast with behaviour in a Verbal Fluency Task.
We use sentence embeddings to identify response categories and compute semantic
similarities, which we use to generate jump profiles. Our results corroborate
earlier work in humans reporting both persistent (deep search in few semantic
spaces) and flexible (broad search across multiple semantic spaces) pathways to
creativity, where both pathways lead to similar creativity scores. LLMs were
found to be biased towards either persistent or flexible paths, that varied
across tasks. Though LLMs as a population match human profiles, their
relationship with creativity is different, where the more flexible models score
higher on creativity. Our dataset and scripts are available on
\href{https://github.com/surabhisnath/Creative_Process}{GitHub}.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÈ°ØÂæóÁõ∏Áï∂ÊúâÂâµÊÑèÔºåÂú®ÂâµÊÑè‰ªªÂãô‰∏≠Á∂ìÂ∏∏Ë°®ÁèæÂæóËàá‰∏ÄËà¨‰∫∫‰∏ÄÊ®£Âá∫Ëâ≤„ÄÇÁÑ∂ËÄåÔºåÂ∞çÊñº LLM ÂâµÊÑèÁöÑÁ†îÁ©∂ÂÉÖÂ∞àÊ≥®Êñº„ÄåÁî¢ÂìÅ„ÄçÔºåÂæàÂ∞ëÈóúÊ≥®ÂâµÊÑè„ÄåÈÅéÁ®ã„Äç„ÄÇ‰∫∫È°ûÂâµÊÑèÁöÑÈÅéÁ®ãÂàÜÊûêÈÄöÂ∏∏ÈúÄË¶ÅÊâãÂãïÁ∑®Á¢ºÁöÑÈ°ûÂà•ÊàñÂà©Áî®ÂèçÊáâÊôÇÈñìÔºåÈÄô‰∏çÈÅ©Áî®Êñº LLM„ÄÇÊàëÂÄëÊèê‰æõ‰∫Ü‰∏ÄÁ®ÆËá™ÂãïÂåñÊñπÊ≥ïÔºåÁî®ÊñºÊèèËø∞‰∫∫È°ûÂíå LLM Â¶Ç‰ΩïÂú®Êõø‰ª£Áî®ÈÄî‰ªªÂãô‰∏≠Êé¢Á¥¢Ë™ûÁæ©Á©∫ÈñìÔºå‰∏¶ËàáÊµÅÊö¢Âè£Ë™û‰ªªÂãô‰∏≠ÁöÑË°åÁÇ∫ÂΩ¢ÊàêÂ∞çÊØî„ÄÇÊàëÂÄë‰ΩøÁî®Âè•Â≠êÂµåÂÖ•‰æÜË≠òÂà•ÂõûÊáâÈ°ûÂà•‰∏¶Ë®àÁÆóË™ûÁæ©Áõ∏‰ººÊÄßÔºåÊàëÂÄë‰ΩøÁî®ÈÄô‰∫õÁõ∏‰ººÊÄß‰æÜÁîüÊàêË∑≥Ë∫çËº™Âªì„ÄÇÊàëÂÄëÁöÑÁµêÊûúË≠âÂØ¶‰∫Ü‰∫∫È°ûÊó©ÊúüÂ∑•‰ΩúÁöÑÂ†±ÂëäÔºåÂç≥ÊåÅ‰πÖÔºàÂú®Â∞ëÊï∏Ë™ûÁæ©Á©∫Èñì‰∏≠Ê∑±ÂÖ•ÊêúÂ∞ãÔºâÂíåÈùàÊ¥ªÔºàÂú®Â§öÂÄãË™ûÁæ©Á©∫Èñì‰∏≠Âª£Ê≥õÊêúÂ∞ãÔºâÁöÑÈÄîÂæëÈÉΩÂèØ‰ª•ÈÄöÂæÄÂâµÈÄ†ÂäõÔºåÈÄôÂÖ©Á®ÆÈÄîÂæëÈÉΩÂèØ‰ª•Â∏∂‰æÜÈ°û‰ººÁöÑÂâµÈÄ†ÂäõÂàÜÊï∏„ÄÇÁôºÁèæ LLM ÂÅèÂêëÊñºÊåÅ‰πÖÊàñÈùàÊ¥ªÁöÑÈÄîÂæëÔºåÈÄôÂú®‰∏çÂêåÁöÑ‰ªªÂãô‰∏≠ÊúâÊâÄ‰∏çÂêå„ÄÇÂÑòÁÆ° LLM ‰ΩúÁÇ∫‰∏ÄÂÄãÊóèÁæ§Á¨¶Âêà‰∫∫È°ûÁöÑËº™ÂªìÔºå‰ΩÜÂÆÉÂÄëËàáÂâµÈÄ†ÂäõÁöÑÈóú‰øÇÂçª‰∏çÂêåÔºåÂÖ∂‰∏≠ËºÉÈùàÊ¥ªÁöÑÊ®°ÂûãÂú®ÂâµÈÄ†ÂäõÊñπÈù¢ÂæóÂàÜÊõ¥È´ò„ÄÇÊàëÂÄëÁöÑË≥áÊñôÈõÜÂíåËÖ≥Êú¨ÂèØ‰ª•Âú® \href{https://github.com/surabhisnath/Creative_Process}{GitHub} ‰∏äÊâæÂà∞„ÄÇ

##### **Wake Vision: A Large-scale, Diverse Dataset and Benchmark Suite for TinyML Person Detection**
2405.00892v1 by Colby Banbury,Emil Njor,Matthew Stewart,Pete Warden,Manjunath Kudlur,Nat Jeffries,Xenofon Fafoutis,Vijay Janapa Reddi

Machine learning applications on extremely low-power devices, commonly
referred to as tiny machine learning (TinyML), promises a smarter and more
connected world. However, the advancement of current TinyML research is
hindered by the limited size and quality of pertinent datasets. To address this
challenge, we introduce Wake Vision, a large-scale, diverse dataset tailored
for person detection -- the canonical task for TinyML visual sensing. Wake
Vision comprises over 6 million images, which is a hundredfold increase
compared to the previous standard, and has undergone thorough quality
filtering. Using Wake Vision for training results in a 2.41\% increase in
accuracy compared to the established benchmark. Alongside the dataset, we
provide a collection of five detailed benchmark sets that assess model
performance on specific segments of the test data, such as varying lighting
conditions, distances from the camera, and demographic characteristics of
subjects. These novel fine-grained benchmarks facilitate the evaluation of
model quality in challenging real-world scenarios that are often ignored when
focusing solely on overall accuracy. Through an evaluation of a MobileNetV2
TinyML model on the benchmarks, we show that the input resolution plays a more
crucial role than the model width in detecting distant subjects and that the
impact of quantization on model robustness is minimal, thanks to the dataset
quality. These findings underscore the importance of a detailed evaluation to
identify essential factors for model development. The dataset, benchmark suite,
code, and models are publicly available under the CC-BY 4.0 license, enabling
their use for commercial use cases.

ÊëòË¶ÅÔºö<paragraph>Âú®Ê•µ‰ΩéÂäüËÄóË£ùÁΩÆ‰∏äÁöÑÊ©üÂô®Â≠∏ÁøíÊáâÁî®Á®ãÂºèÔºåÈÄöÂ∏∏Á®±ÁÇ∫ÂæÆÂûãÊ©üÂô®Â≠∏Áøí (TinyML)ÔºåÊâøË´æÊèê‰æõÊõ¥Êô∫ÊÖß‰∏îÊõ¥Á∑äÂØÜÁöÑÈÄ£Áµê‰∏ñÁïå„ÄÇÁÑ∂ËÄåÔºåÁõÆÂâçÁöÑ TinyML Á†îÁ©∂ÈÄ≤Â±ïÂèóÂà∞Áõ∏ÈóúË≥áÊñôÈõÜÂ§ßÂ∞èÂíåÂìÅË≥™ÁöÑÈôêÂà∂„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄôÈ†ÖÊåëÊà∞ÔºåÊàëÂÄëÊé®Âá∫ Wake VisionÔºå‰∏ÄÂÄãÈáùÂ∞ç‰∫∫Âì°ÂÅµÊ∏¨ÈáèË∫´ÊâìÈÄ†ÁöÑÂ§ßË¶èÊ®°„ÄÅÂ§öÊ®£ÂåñË≥áÊñôÈõÜÔºåÈÄôÈ†Ö‰ªªÂãôÊòØ TinyML Ë¶ñË¶∫ÊÑüÊ∏¨ÁöÑÊ≥ïË¶è‰ªªÂãô„ÄÇWake Vision ÂåÖÂê´Ë∂ÖÈÅé 600 Ëê¨ÂºµÂΩ±ÂÉèÔºåËàáÂÖàÂâçÁöÑÊ®ôÊ∫ñÁõ∏ÊØîÔºåÂ¢ûÂä†‰∫ÜÁôæÂÄçÔºåËÄå‰∏îÁ∂ìÈÅéÂæπÂ∫ïÁöÑÂìÅË≥™ÈÅéÊøæ„ÄÇ‰ΩøÁî® Wake Vision ÈÄ≤Ë°åË®ìÁ∑¥ÔºåÂèØÂ∞áÊ∫ñÁ¢∫Â∫¶ÊèêÈ´ò 2.41%ÔºåËàáÊó¢ÂÆöÁöÑÂü∫Ê∫ñÁõ∏ÊØî„ÄÇÈô§‰∫ÜË≥áÊñôÈõÜ‰πãÂ§ñÔºåÊàëÂÄëÈÇÑÊèê‰æõ‰∫îÂÄãË©≥Á¥∞ÁöÑÂü∫Ê∫ñÁµÑÔºåÁî®ÊñºË©ï‰º∞Ê®°ÂûãÂú®Ê∏¨Ë©¶Ë≥áÊñôÁöÑÁâπÂÆöÂçÄÊÆµ‰∏äÁöÑÊïàËÉΩÔºå‰æãÂ¶Ç‰∏çÂêåÁöÑÂÖâÁ∑öÊ¢ù‰ª∂„ÄÅËàáÁõ∏Ê©üÁöÑË∑ùÈõ¢Ôºå‰ª•ÂèäÂèóË©¶ËÄÖÁöÑÁâπÂæµ„ÄÇÈÄô‰∫õÊñ∞Á©éÁöÑÁ¥∞Á∑ªÂü∫Ê∫ñÊúâÂä©ÊñºË©ï‰º∞Ê®°ÂûãÂìÅË≥™ÔºåÂú®ÂÉÖÈóúÊ≥®Êï¥È´îÊ∫ñÁ¢∫Â∫¶ÊôÇÔºåÈÄô‰∫õÊåëÊà∞ÊÄßÁöÑÁúüÂØ¶‰∏ñÁïåÂ†¥ÊôØÈÄöÂ∏∏ÊúÉË¢´ÂøΩÁï•„ÄÇÈÄèÈÅéÂú®Âü∫Ê∫ñ‰∏äË©ï‰º∞ MobileNetV2 TinyML Ê®°ÂûãÔºåÊàëÂÄëÁôºÁèæËº∏ÂÖ•Ëß£ÊûêÂ∫¶Âú®ÂÅµÊ∏¨ÈÅ†Ë∑ùÈõ¢ÂèóË©¶ËÄÖÊôÇÊâÆÊºîÊØîÊ®°ÂûãÂØ¨Â∫¶Êõ¥ÈáçË¶ÅÁöÑËßíËâ≤ÔºåËÄå‰∏îÁî±ÊñºË≥áÊñôÈõÜÂìÅË≥™ÁöÑÈóú‰øÇÔºåÈáèÂåñÂ∞çÊ®°ÂûãÁ©©ÂÅ•ÊÄßÁöÑÂΩ±ÈüøÂæàÂ∞è„ÄÇÈÄô‰∫õÁôºÁèæÂº∑Ë™ø‰∫ÜË©≥Á¥∞Ë©ï‰º∞ÁöÑÈáçË¶ÅÊÄßÔºå‰ª•ÊâæÂá∫Ê®°ÂûãÈñãÁôºÁöÑÂøÖË¶ÅÂõ†Á¥†„ÄÇË≥áÊñôÈõÜ„ÄÅÂü∫Ê∫ñÁµÑ„ÄÅÁ®ãÂºèÁ¢ºÂíåÊ®°ÂûãÂú® CC-BY 4.0 ÊéàÊ¨ä‰∏ãÂÖ¨ÈñãÊèê‰æõÔºåÂèØ‰ª•‰ΩøÁî®ÊñºÂïÜÊ•≠Áî®‰æã„ÄÇ</paragraph>

##### **DynaMo: Accelerating Language Model Inference with Dynamic Multi-Token Sampling**
2405.00888v1 by Shikhar Tuli,Chi-Heng Lin,Yen-Chang Hsu,Niraj K. Jha,Yilin Shen,Hongxia Jin

Traditional language models operate autoregressively, i.e., they predict one
token at a time. Rapid explosion in model sizes has resulted in high inference
times. In this work, we propose DynaMo, a suite of multi-token prediction
language models that reduce net inference times. Our models
$\textit{dynamically}$ predict multiple tokens based on their confidence in the
predicted joint probability distribution. We propose a lightweight technique to
train these models, leveraging the weights of traditional autoregressive
counterparts. Moreover, we propose novel ways to enhance the estimated joint
probability to improve text generation quality, namely co-occurrence weighted
masking and adaptive thresholding. We also propose systematic qualitative and
quantitative methods to rigorously test the quality of generated text for
non-autoregressive generation. One of the models in our suite, DynaMo-7.3B-T3,
achieves same-quality generated text as the baseline (Pythia-6.9B) while
achieving 2.57$\times$ speed-up with only 5.87% and 2.67% parameter and
training time overheads, respectively.

ÊëòË¶ÅÔºöÂÇ≥Áµ±Ë™ûË®ÄÊ®°Âûã‰ª•Ëá™Ëø¥Ê≠∏ÁöÑÊñπÂºèÈÅã‰ΩúÔºå‰∫¶Âç≥‰∏ÄÊ¨°È†êÊ∏¨‰∏ÄÂÄãÁ¨¶Ëôü„ÄÇÊ®°ÂûãË¶èÊ®°ÁöÑÂø´ÈÄüÁàÜÁÇ∏Â∞éËá¥È´òÊé®Ë´ñÊôÇÈñì„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫ DynaMoÔºå‰∏ÄÁµÑÂ§öÁ¨¶ËôüÈ†êÊ∏¨Ë™ûË®ÄÊ®°ÂûãÔºåÂèØÊ∏õÂ∞ëÁ∂≤Ë∑ØÊé®Ë´ñÊôÇÈñì„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÂü∫ÊñºÂÖ∂Â∞çÈ†êÊ∏¨ËÅØÂêàÊ©üÁéáÂàÜ‰ΩàÁöÑ‰ø°ÂøÉÔºåÂãïÊÖãÈ†êÊ∏¨Â§öÂÄãÁ¨¶Ëôü„ÄÇÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãËºïÈáèÁ¥öÊäÄË°ì‰æÜË®ìÁ∑¥ÈÄô‰∫õÊ®°ÂûãÔºåÂà©Áî®ÂÇ≥Áµ±Ëá™Ëø¥Ê≠∏Â∞çÊáâÈ†ÖÁöÑÊ¨äÈáç„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèêÂá∫ÂâµÊñ∞ÁöÑÊñπÊ≥ï‰æÜÂ¢ûÂº∑‰º∞Ë®àÁöÑËÅØÂêàÊ©üÁéá‰ª•ÊèêÈ´òÊñáÂ≠óÁîüÊàêÂìÅË≥™ÔºåÂç≥ÂÖ±ÁèæÂä†Ê¨äÈÅÆÁΩ©ÂíåËá™ÈÅ©ÊáâÈñæÂÄº„ÄÇÊàëÂÄë‰πüÊèêÂá∫Á≥ªÁµ±ÊÄßÁöÑÂÆöÊÄßÂíåÂÆöÈáèÊñπÊ≥ï‰æÜÂö¥Ê†ºÊ∏¨Ë©¶ÈùûËá™Ëø¥Ê≠∏ÁîüÊàêÁöÑÁîüÊàêÊñáÂ≠óÂìÅË≥™„ÄÇÊàëÂÄëÂ•ó‰ª∂‰∏≠ÁöÑÂÖ∂‰∏≠‰∏ÄÂÄãÊ®°Âûã DynaMo-7.3B-T3ÔºåÂú®ËàáÂü∫Ê∫ñÁ∑ö (Pythia-6.9B) Áõ∏ÂêåÂìÅË≥™ÁöÑÁîüÊàêÊñáÂ≠ó‰∏≠ÔºåÂÉÖ‰ª• 5.87% Âíå 2.67% ÁöÑÂèÉÊï∏ÂíåË®ìÁ∑¥ÊôÇÈñìÈñãÈä∑ÔºåÈÅîÂà∞ 2.57 ÂÄçÁöÑÂä†ÈÄü„ÄÇ

##### **Beyond Human Vision: The Role of Large Vision Language Models in Microscope Image Analysis**
2405.00876v1 by Prateek Verma,Minh-Hao Van,Xintao Wu

Vision language models (VLMs) have recently emerged and gained the spotlight
for their ability to comprehend the dual modality of image and textual data.
VLMs such as LLaVA, ChatGPT-4, and Gemini have recently shown impressive
performance on tasks such as natural image captioning, visual question
answering (VQA), and spatial reasoning. Additionally, a universal segmentation
model by Meta AI, Segment Anything Model (SAM) shows unprecedented performance
at isolating objects from unforeseen images. Since medical experts, biologists,
and materials scientists routinely examine microscopy or medical images in
conjunction with textual information in the form of captions, literature, or
reports, and draw conclusions of great importance and merit, it is indubitably
essential to test the performance of VLMs and foundation models such as SAM, on
these images. In this study, we charge ChatGPT, LLaVA, Gemini, and SAM with
classification, segmentation, counting, and VQA tasks on a variety of
microscopy images. We observe that ChatGPT and Gemini are impressively able to
comprehend the visual features in microscopy images, while SAM is quite capable
at isolating artefacts in a general sense. However, the performance is not
close to that of a domain expert - the models are readily encumbered by the
introduction of impurities, defects, artefact overlaps and diversity present in
the images.

ÊëòË¶ÅÔºöË¶ñË¶∫Ë™ûË®ÄÊ®°Âûã (VLM) ËøëÊúüÊµÆÁèæ‰∏¶ÂèóÂà∞ÈóúÊ≥®ÔºåÂéüÂõ†Âú®ÊñºÂÆÉÂÄëËÉΩÁêÜËß£ÂΩ±ÂÉèÂíåÊñáÂ≠óË≥áÊñôÁöÑÈõôÈáçÊ®°Âºè„ÄÇLLaVA„ÄÅChatGPT-4 Âíå Gemini Á≠â VLM ËøëÊúüÂú®‰ªªÂãô‰∏äÂ±ïÁèæÈ©ö‰∫∫ÁöÑË°®ÁèæÔºå‰æãÂ¶ÇËá™ÁÑ∂ÂΩ±ÂÉèÊ®ôÈ°å„ÄÅË¶ñË¶∫ÂïèÁ≠î (VQA) ÂíåÁ©∫ÈñìÊé®ÁêÜ„ÄÇÊ≠§Â§ñÔºåMeta AI ÁöÑÈÄöÁî®ÂàÜÂâ≤Ê®°Âûã Segment Anything Model (SAM) Âú®ÂæûÊú™È†êË¶ãÁöÑÂΩ±ÂÉè‰∏≠ÂàÜÈõ¢Áâ©‰ª∂ÊñπÈù¢Â±ïÁèæÂâçÊâÄÊú™ÊúâÁöÑË°®Áèæ„ÄÇÁî±ÊñºÈÜ´Â≠∏Â∞àÂÆ∂„ÄÅÁîüÁâ©Â≠∏ÂÆ∂ÂíåÊùêÊñôÁßëÂ≠∏ÂÆ∂‰æãË°åÊ™¢Êü•È°ØÂæÆÈè°ÊàñÈÜ´Â≠∏ÂΩ±ÂÉèÔºå‰∏¶ÁµêÂêàÊ®ôÈ°å„ÄÅÊñáÁçªÊàñÂ†±ÂëäÂΩ¢ÂºèÁöÑÊñáÂ≠óË≥áË®äÔºå‰∏¶ÂæóÂá∫Ê•µÁÇ∫ÈáçË¶Å‰∏îÊúâÂÉπÂÄºÁöÑÁµêË´ñÔºåÂõ†Ê≠§ÁÑ°Â∫∏ÁΩÆÁñëÂú∞ÔºåÂú®ÈÄô‰∫õÂΩ±ÂÉè‰∏äÊ∏¨Ë©¶ VLM Âíå SAM Á≠âÂü∫Á§éÊ®°ÂûãÁöÑË°®ÁèæËá≥ÈóúÈáçË¶Å„ÄÇÂú®Ê≠§Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëË¶ÅÊ±Ç ChatGPT„ÄÅLLaVA„ÄÅGemini Âíå SAM Â∞çÂêÑÁ®ÆÈ°ØÂæÆÈè°ÂΩ±ÂÉèÈÄ≤Ë°åÂàÜÈ°û„ÄÅÂàÜÂâ≤„ÄÅË®àÊï∏Âíå VQA ‰ªªÂãô„ÄÇÊàëÂÄëËßÄÂØüÂà∞ÔºåChatGPT Âíå Gemini ËÉΩÂ§†‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÂú∞ÁêÜËß£È°ØÂæÆÈè°ÂΩ±ÂÉè‰∏≠ÁöÑË¶ñË¶∫ÁâπÂæµÔºåËÄå SAM ÂâáÁõ∏Áï∂ÊúâËÉΩÂäõÂæû‰∏ÄËà¨ÊÑèÁæ©‰∏äÂàÜÈõ¢‰∫∫Â∑•Ë£ΩÂìÅ„ÄÇÁÑ∂ËÄåÔºåË°®Áèæ‰∏¶Êú™Êé•ËøëÈ†òÂüüÂ∞àÂÆ∂ - Ê®°ÂûãÂæàÂÆπÊòìÂèóÂà∞ÂΩ±ÂÉè‰∏≠ÈõúË≥™„ÄÅÁº∫Èô∑„ÄÅ‰∫∫Â∑•Ë£ΩÂìÅÈáçÁñäÂíåÂ§öÊ®£ÊÄßÁöÑÂΩ±Èüø„ÄÇ

##### **Artificial intelligence for context-aware visual change detection in software test automation**
2405.00874v1 by Milad Moradi,Ke Yan,David Colwell,Rhona Asgari

Automated software testing is integral to the software development process,
streamlining workflows and ensuring product reliability. Visual testing within
this context, especially concerning user interface (UI) and user experience
(UX) validation, stands as one of crucial determinants of overall software
quality. Nevertheless, conventional methods like pixel-wise comparison and
region-based visual change detection fall short in capturing contextual
similarities, nuanced alterations, and understanding the spatial relationships
between UI elements. In this paper, we introduce a novel graph-based method for
visual change detection in software test automation. Leveraging a machine
learning model, our method accurately identifies UI controls from software
screenshots and constructs a graph representing contextual and spatial
relationships between the controls. This information is then used to find
correspondence between UI controls within screenshots of different versions of
a software. The resulting graph encapsulates the intricate layout of the UI and
underlying contextual relations, providing a holistic and context-aware model.
This model is finally used to detect and highlight visual regressions in the
UI. Comprehensive experiments on different datasets showed that our change
detector can accurately detect visual software changes in various simple and
complex test scenarios. Moreover, it outperformed pixel-wise comparison and
region-based baselines by a large margin in more complex testing scenarios.
This work not only contributes to the advancement of visual change detection
but also holds practical implications, offering a robust solution for
real-world software test automation challenges, enhancing reliability, and
ensuring the seamless evolution of software interfaces.

ÊëòË¶ÅÔºöËá™ÂãïÂåñËªüÈ´îÊ∏¨Ë©¶ÊòØËªüÈ´îÈñãÁôºÈÅéÁ®ã‰∏≠‰∏çÂèØÊàñÁº∫ÁöÑ‰∏ÄÁí∞ÔºåÂÆÉËÉΩÁ∞°ÂåñÂ∑•‰ΩúÊµÅÁ®ã‰∏¶Á¢∫‰øùÁî¢ÂìÅÂèØÈù†ÊÄß„ÄÇÂú®Ê≠§ËÉåÊôØ‰∏ãÔºåË¶ñË¶∫Ê∏¨Ë©¶ÔºàÁâπÂà•ÊòØÈóúÊñº‰ΩøÁî®ËÄÖ‰ªãÈù¢ (UI) Âíå‰ΩøÁî®ËÄÖÈ´îÈ©ó (UX) È©óË≠âÔºâÊòØÊ±∫ÂÆöÊï¥È´îËªüÈ´îÂìÅË≥™ÁöÑÈóúÈçµÂõ†Á¥†‰πã‰∏Ä„ÄÇÂÑòÁÆ°Â¶ÇÊ≠§ÔºåÂÇ≥Áµ±ÊñπÊ≥ïÔºà‰æãÂ¶ÇÈÄêÂÉèÁ¥†ÊØîËºÉÂíåÂü∫ÊñºÂçÄÂüüÁöÑË¶ñË¶∫ËÆäÊõ¥ÂÅµÊ∏¨ÔºâÂú®ÊçïÊçâËÉåÊôØÁõ∏‰ººÊÄß„ÄÅÁ¥∞ÂæÆËÆäÊõ¥Ôºå‰ª•ÂèäÁêÜËß£ UI ÂÖÉÁ¥†‰πãÈñìÁöÑÁ©∫ÈñìÈóú‰øÇÊñπÈù¢‰ªçÊúâ‰∏çË∂≥„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫Ü‰∏ÄÁ®ÆÁî®ÊñºËªüÈ´îÊ∏¨Ë©¶Ëá™ÂãïÂåñ‰∏≠ÁöÑË¶ñË¶∫ËÆäÊõ¥ÂÅµÊ∏¨ÁöÑÊñ∞Á©éÂúñÂΩ¢ÂåñÊñπÊ≥ï„ÄÇÈÄèÈÅéÂà©Áî®Ê©üÂô®Â≠∏ÁøíÊ®°ÂûãÔºåÊàëÂÄëÁöÑÈÄôÁ®ÆÊñπÊ≥ïÂèØ‰ª•ÂæûËªüÈ´îÊà™Âúñ‰∏≠Ê∫ñÁ¢∫Ë≠òÂà• UI ÊéßÂà∂È†ÖÔºå‰∏¶Âª∫Êßã‰∏ÄÂÄãÂúñÂΩ¢Ôºå‰ª•Ë°®Á§∫ÊéßÂà∂È†Ö‰πãÈñìÁöÑËÉåÊôØÂíåÁ©∫ÈñìÈóú‰øÇ„ÄÇÁÑ∂ÂæåÔºåÈÄô‰∫õË≥áË®äÊúÉÁî®ÊñºÂú®‰∏çÂêåÁâàÊú¨ÁöÑËªüÈ´îÊà™Âúñ‰∏≠ÊâæÂà∞ UI ÊéßÂà∂È†Ö‰πãÈñìÁöÑÂ∞çÊáâÈóú‰øÇ„ÄÇÁî¢ÁîüÁöÑÂúñÂΩ¢ÂõäÊã¨‰∫Ü UI ÁöÑË§áÈõú‰ΩàÂ±ÄÂíåÂ∫ïÂ±§ËÉåÊôØÈóú‰øÇÔºåÊèê‰æõ‰∫Ü‰∏ÄÂÄãÊï¥È´î‰∏îÂÖ∑ÂÇôËÉåÊôØÊÑüÁü•ËÉΩÂäõÁöÑÊ®°Âûã„ÄÇÊúÄÂæåÔºåÈÄôÂÄãÊ®°ÂûãÊúÉÁî®ÊñºÂÅµÊ∏¨ÂíåÁ™ÅÈ°Ø UI ‰∏≠ÁöÑË¶ñË¶∫ÂõûÊ≠∏„ÄÇÂú®‰∏çÂêåË≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÁöÑÂÖ®Èù¢ÂØ¶È©óÈ°ØÁ§∫ÔºåÊàëÂÄëÁöÑËÆäÊõ¥ÂÅµÊ∏¨Âô®ÂèØ‰ª•Âú®ÂêÑÁ®ÆÁ∞°ÂñÆÂíåË§áÈõúÁöÑÊ∏¨Ë©¶ÊÉÖÂ¢É‰∏≠Ê∫ñÁ¢∫ÂÅµÊ∏¨Ë¶ñË¶∫ËªüÈ´îËÆäÊõ¥„ÄÇÊ≠§Â§ñÔºåÂú®Êõ¥Ë§áÈõúÁöÑÊ∏¨Ë©¶ÊÉÖÂ¢É‰∏≠ÔºåÂÆÉÂú®ÈÄêÂÉèÁ¥†ÊØîËºÉÂíåÂü∫ÊñºÂçÄÂüüÁöÑÂü∫Ê∫ñÊ∏¨Ë©¶‰∏≠Ë°®ÁèæÂá∫Ëâ≤ÔºåÂ§ßÂπÖÂãùÂá∫„ÄÇÈÄôÈ†ÖÂ∑•‰Ωú‰∏çÂÉÖÊúâÂä©ÊñºÊé®ÈÄ≤Ë¶ñË¶∫ËÆäÊõ¥ÂÅµÊ∏¨ÁöÑÈÄ≤Â±ïÔºå‰πüÂÖ∑ÊúâÂØ¶ÈöõÊÑèÁæ©ÔºåÁÇ∫ÁúüÂØ¶‰∏ñÁïåÁöÑËªüÈ´îÊ∏¨Ë©¶Ëá™ÂãïÂåñÊåëÊà∞Êèê‰æõ‰∫Ü‰∏ÄÂÄãÁ©©ÂÅ•ÁöÑËß£Ê±∫ÊñπÊ°àÔºåÈÄ≤ËÄåÊèêÂçáÂèØÈù†ÊÄßÔºå‰∏¶Á¢∫‰øùËªüÈ´î‰ªãÈù¢ÁöÑÁÑ°Á∏´ÊºîÈÄ≤„ÄÇ

##### **Math Multiple Choice Question Generation via Human-Large Language Model Collaboration**
2405.00864v1 by Jaewook Lee,Digory Smith,Simon Woodhead,Andrew Lan

Multiple choice questions (MCQs) are a popular method for evaluating
students' knowledge due to their efficiency in administration and grading.
Crafting high-quality math MCQs is a labor-intensive process that requires
educators to formulate precise stems and plausible distractors. Recent advances
in large language models (LLMs) have sparked interest in automating MCQ
creation, but challenges persist in ensuring mathematical accuracy and
addressing student errors. This paper introduces a prototype tool designed to
facilitate collaboration between LLMs and educators for streamlining the math
MCQ generation process. We conduct a pilot study involving math educators to
investigate how the tool can help them simplify the process of crafting
high-quality math MCQs. We found that while LLMs can generate well-formulated
question stems, their ability to generate distractors that capture common
student errors and misconceptions is limited. Nevertheless, a human-AI
collaboration has the potential to enhance the efficiency and effectiveness of
MCQ generation.

ÊëòË¶ÅÔºöÂ§öÈÅ∏È°å (MCQ) Âõ†ÁÇ∫Âú®ÁÆ°ÁêÜÂíåË©ïÂàÜ‰∏äÁöÑÊïàÁéáÔºåÊòØ‰∏ÄÁ®ÆË©ïÈáèÂ≠∏ÁîüÁü•Ë≠òÁöÑÁÜ±ÈñÄÊñπÊ≥ï„ÄÇ
Êí∞ÂØ´È´òÂìÅË≥™ÁöÑÊï∏Â≠∏Â§öÈÅ∏È°åÊòØ‰∏ÄÂÄãÈúÄË¶ÅÂ§ßÈáè‰∫∫Âäõ‰∏îËÄóÊôÇÁöÑÂ∑•‰ΩúÔºåË¶ÅÊ±ÇÊïôËÇ≤ËÄÖÂà∂ÂÆöÁ≤æÁ¢∫ÁöÑÈ°åÂππÂíåÂêàÁêÜÁöÑÂπ≤ÊìæÈÅ∏È†Ö„ÄÇ
Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑËøëÊúüÈÄ≤Â±ïÊøÄÁôº‰∫ÜËá™ÂãïÂåñÂ§öÈÅ∏È°åË£Ω‰ΩúÁöÑËààË∂£Ôºå‰ΩÜ‰ªçÊúâÊåëÊà∞Â≠òÂú®ÊñºÁ¢∫‰øùÊï∏Â≠∏Ê≠£Á¢∫ÊÄßÂíåËß£Ê±∫Â≠∏ÁîüÁöÑÈåØË™§„ÄÇ
Êú¨Êñá‰ªãÁ¥π‰∫Ü‰∏ÄÂÄãÂéüÂûãÂ∑•ÂÖ∑ÔºåÊó®Âú®‰øÉÈÄ≤ LLM ËàáÊïôËÇ≤ËÄÖ‰πãÈñìÁöÑÂçî‰ΩúÔºå‰ª•Á∞°ÂåñÊï∏Â≠∏Â§öÈÅ∏È°åÁöÑÁî¢ÁîüÈÅéÁ®ã„ÄÇ
ÊàëÂÄëÈÄ≤Ë°å‰∫Ü‰∏ÄÈ†ÖÊ∂âÂèäÊï∏Â≠∏ÊïôËÇ≤ËÄÖÁöÑË©¶È©óÁ†îÁ©∂Ôºå‰ª•Êé¢Ë®éË©≤Â∑•ÂÖ∑Â¶Ç‰ΩïÂπ´Âä©‰ªñÂÄëÁ∞°ÂåñË£Ω‰ΩúÈ´òÂìÅË≥™Êï∏Â≠∏Â§öÈÅ∏È°åÁöÑÈÅéÁ®ã„ÄÇ
ÊàëÂÄëÁôºÁèæÔºåÈõñÁÑ∂ LLM ÂèØ‰ª•Áî¢ÁîüÁµêÊßãËâØÂ•ΩÁöÑÈ°åÂππÔºå‰ΩÜÂÆÉÂÄëÁî¢ÁîüÂπ≤ÊìæÈÅ∏È†ÖÁöÑËÉΩÂäõÔºå‰ª•ÊçïÊçâÂ∏∏Ë¶ãÁöÑÂ≠∏ÁîüÈåØË™§ÂíåË™§Ëß£ÊòØÊúâÈôêÁöÑ„ÄÇ
ÂÑòÁÆ°Â¶ÇÊ≠§Ôºå‰∫∫Ê©üÂçî‰ΩúÊúâÊΩõÂäõÊèêÈ´òÂ§öÈÅ∏È°åÁî¢ÁîüÁöÑÊïàÁéáÂíåÊïàËÉΩ„ÄÇ

##### **Can a Hallucinating Model help in Reducing Human "Hallucination"?**
2405.00843v1 by Sowmya S Sundaram,Balaji Alwar

The prevalence of unwarranted beliefs, spanning pseudoscience, logical
fallacies, and conspiracy theories, presents substantial societal hurdles and
the risk of disseminating misinformation. Utilizing established psychometric
assessments, this study explores the capabilities of large language models
(LLMs) vis-a-vis the average human in detecting prevalent logical pitfalls. We
undertake a philosophical inquiry, juxtaposing the rationality of humans
against that of LLMs. Furthermore, we propose methodologies for harnessing LLMs
to counter misconceptions, drawing upon psychological models of persuasion such
as cognitive dissonance theory and elaboration likelihood theory. Through this
endeavor, we highlight the potential of LLMs as personalized misinformation
debunking agents.

ÊëòË¶ÅÔºöÂÅΩÁßëÂ≠∏„ÄÅÈÇèËºØË¨¨Ë™§ÂíåÈô∞Ë¨ÄË´ñÁ≠â‰∏çÂêàÁêÜ‰ø°ÂøµÁöÑÁõõË°åÔºåÂ∞çÁ§æÊúÉÊßãÊàêÈáçÂ§ßÈöúÁ§ôÔºå‰∏¶ÊúâÊï£Â∏ÉÈåØË™§Ë≥áË®äÁöÑÈ¢®Èö™„ÄÇÊú¨Á†îÁ©∂Âà©Áî®Êó¢ÂÆöÁöÑÂøÉÁêÜÊ∏¨ÈáèË©ï‰º∞ÔºåÊé¢Ë®éÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Áõ∏Â∞çÊñº‰∏ÄËà¨‰∫∫Âú®ÂÅµÊ∏¨ÊôÆÈÅçÈÇèËºØÈô∑Èò±ÁöÑËÉΩÂäõ„ÄÇÊàëÂÄëÈÄ≤Ë°å‰∏ÄÈ†ÖÂì≤Â≠∏Êé¢Ë®éÔºåÂ∞á‰∫∫È°ûÁöÑÁêÜÊÄßËàá LLM ÁöÑÁêÜÊÄß‰∏¶ÁΩÆ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèêÂá∫Âà©Áî® LLM ‰æÜÂ∞çÊäóË™§Ëß£ÁöÑÊñπÊ≥ïÔºå‰∏¶ÂÄüÈëíË™çÁü•Â§±Ë™øÁêÜË´ñÂíåË®äÊÅØÁ≤æÁ∑ªÂèØËÉΩÊÄßÁêÜË´ñÁ≠âÂøÉÁêÜË™™ÊúçÊ®°Âûã„ÄÇÈÄèÈÅéÈÄôÈ†ÖÂä™ÂäõÔºåÊàëÂÄëÂº∑Ë™ø LLM ‰ΩúÁÇ∫ÂÄã‰∫∫ÂåñÈåØË™§Ë≥áË®äÁ†¥Ëß£‰ª£ÁêÜÁöÑÊΩõÂäõ„ÄÇ

##### **Sim-Grasp: Learning 6-DOF Grasp Policies for Cluttered Environments Using a Synthetic Benchmark**
2405.00841v1 by Juncheng Li,David J. Cappelleri

In this paper, we present Sim-Grasp, a robust 6-DOF two-finger grasping
system that integrates advanced language models for enhanced object
manipulation in cluttered environments. We introduce the Sim-Grasp-Dataset,
which includes 1,550 objects across 500 scenarios with 7.9 million annotated
labels, and develop Sim-GraspNet to generate grasp poses from point clouds. The
Sim-Grasp-Polices achieve grasping success rates of 97.14% for single objects
and 87.43% and 83.33% for mixed clutter scenarios of Levels 1-2 and Levels 3-4
objects, respectively. By incorporating language models for target
identification through text and box prompts, Sim-Grasp enables both
object-agnostic and target picking, pushing the boundaries of intelligent
robotic systems.

ÊëòË¶ÅÔºöÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü Sim-GraspÔºå‰∏ÄÂÄãÂº∑Â§ßÁöÑ 6-DOF ÈõôÊåáÊäìÂèñÁ≥ªÁµ±ÔºåÂÆÉÊï¥Âêà‰∫ÜÂÖàÈÄ≤ÁöÑË™ûË®ÄÊ®°ÂûãÔºå‰ª•Â¢ûÂº∑Âú®Ê∑∑‰∫ÇÁí∞Â¢É‰∏≠ÁöÑÁâ©È´îÊìç‰Ωú„ÄÇÊàëÂÄëÂºïÂÖ•‰∫Ü Sim-Grasp-DatasetÔºåÂÖ∂‰∏≠ÂåÖÂê´ 500 ÂÄãÂ†¥ÊôØ‰∏≠ÁöÑ 1,550 ÂÄãÁâ©È´îÔºå‰∏¶Êúâ 790 Ëê¨ÂÄãË®ªËß£Ê®ôÁ±§Ôºå‰∏¶ÈñãÁôº‰∫Ü Sim-GraspNet ÂæûÈªûÈõ≤ÁîüÊàêÊäìÂèñÂßøÂã¢„ÄÇSim-Grasp-Polices Â∞çÂñÆ‰∏ÄÁâ©È´îÁöÑÊäìÂèñÊàêÂäüÁéáÈÅîÂà∞ 97.14%ÔºåÂ∞çÁ≠âÁ¥ö 1-2 ÂíåÁ≠âÁ¥ö 3-4 Áâ©È´îÁöÑÊ∑∑ÂêàÊ∑∑‰∫ÇÂ†¥ÊôØÁöÑÊäìÂèñÊàêÂäüÁéáÂàÜÂà•ÈÅîÂà∞ 87.43% Âíå 83.33%„ÄÇÈÄöÈÅéÊï¥ÂêàË™ûË®ÄÊ®°Âûã‰æÜÈÄèÈÅéÊñáÂ≠óÂíåÊñπÊ°ÜÊèêÁ§∫ÈÄ≤Ë°åÁõÆÊ®ôË≠òÂà•ÔºåSim-Grasp ËÉΩÂ§†ÈÄ≤Ë°åÁâ©È´î‰∏çÂèØÁü•ÂíåÁõÆÊ®ôÊåëÈÅ∏ÔºåÊé®Âãï‰∫ÜÊô∫ÊÖßÂûãÊ©üÂô®‰∫∫Á≥ªÁµ±ÁöÑÁïåÈôê„ÄÇ

##### **Communication-Efficient Training Workload Balancing for Decentralized Multi-Agent Learning**
2405.00839v1 by Seyed Mahmoud Sajjadi Mohammadabadi,Lei Yang,Feng Yan,Junshan Zhang

Decentralized Multi-agent Learning (DML) enables collaborative model training
while preserving data privacy. However, inherent heterogeneity in agents'
resources (computation, communication, and task size) may lead to substantial
variations in training time. This heterogeneity creates a bottleneck,
lengthening the overall training time due to straggler effects and potentially
wasting spare resources of faster agents. To minimize training time in
heterogeneous environments, we present a Communication-Efficient Training
Workload Balancing for Decentralized Multi-Agent Learning (ComDML), which
balances the workload among agents through a decentralized approach. Leveraging
local-loss split training, ComDML enables parallel updates, where slower agents
offload part of their workload to faster agents. To minimize the overall
training time, ComDML optimizes the workload balancing by jointly considering
the communication and computation capacities of agents, which hinges upon
integer programming. A dynamic decentralized pairing scheduler is developed to
efficiently pair agents and determine optimal offloading amounts. We prove that
in ComDML, both slower and faster agents' models converge, for convex and
non-convex functions. Furthermore, extensive experimental results on popular
datasets (CIFAR-10, CIFAR-100, and CINIC-10) and their non-I.I.D. variants,
with large models such as ResNet-56 and ResNet-110, demonstrate that ComDML can
significantly reduce the overall training time while maintaining model
accuracy, compared to state-of-the-art methods. ComDML demonstrates robustness
in heterogeneous environments, and privacy measures can be seamlessly
integrated for enhanced data protection.

ÊëòË¶ÅÔºöÂàÜÊï£ÂºèÂ§öÊô∫ËÉΩÈ´îÂ≠∏Áøí (DML) ËÉΩÂú®‰øùÁïôË≥áÊñôÈö±ÁßÅÁöÑÂêåÊôÇÈÄ≤Ë°åÂçî‰ΩúÊ®°ÂûãË®ìÁ∑¥„ÄÇÁÑ∂ËÄåÔºåÊô∫ËÉΩÈ´îË≥áÊ∫êÔºàÈÅãÁÆó„ÄÅÈÄöË®äÂíå‰ªªÂãôÂ§ßÂ∞èÔºâÁöÑÂÖßÂú®Áï∞Ë≥™ÊÄßÂèØËÉΩÊúÉÂ∞éËá¥Ë®ìÁ∑¥ÊôÇÈñìÂ§ßÂπÖËÆäÁï∞„ÄÇÈÄôÁ®ÆÁï∞Ë≥™ÊÄßÊúÉÈÄ†ÊàêÁì∂È†∏ÔºåÁî±ÊñºËêΩÂæåÊïàÊáâËÄåÂª∂Èï∑Êï¥È´îË®ìÁ∑¥ÊôÇÈñìÔºå‰∏¶ÂèØËÉΩÊµ™Ë≤ªËºÉÂø´Êô∫ËÉΩÈ´îÁöÑÂÇôÁî®Ë≥áÊ∫ê„ÄÇÁÇ∫‰∫ÜÂú®Áï∞Ë≥™Áí∞Â¢É‰∏≠Â∞áË®ìÁ∑¥ÊôÇÈñìÊúÄÂ∞èÂåñÔºåÊàëÂÄëÊèêÂá∫ÂàÜÊï£ÂºèÂ§öÊô∫ËÉΩÈ´îÂ≠∏ÁøíÁöÑÈÄöË®äÊïàÁéáË®ìÁ∑¥Â∑•‰ΩúË≤†ËºâÂπ≥Ë°° (ComDML)ÔºåÂÆÉÈÄèÈÅéÂàÜÊï£ÂºèÊñπÊ≥ïÂπ≥Ë°°Êô∫ËÉΩÈ´î‰πãÈñìÁöÑÂ∑•‰ΩúË≤†Ëºâ„ÄÇComDML Êé°Áî®Â±ÄÈÉ®ÊêçÂ§±ÂàÜÂâ≤Ë®ìÁ∑¥ÔºåËÉΩÈÄ≤Ë°å‰∏¶Ë°åÊõ¥Êñ∞ÔºåÂÖ∂‰∏≠ËºÉÊÖ¢ÁöÑÊô∫ËÉΩÈ´îÊúÉÂ∞áÈÉ®ÂàÜÂ∑•‰ΩúË≤†ËºâÂç∏ËºâÁµ¶ËºÉÂø´ÁöÑÊô∫ËÉΩÈ´î„ÄÇÁÇ∫‰∫ÜÂ∞áÊï¥È´îË®ìÁ∑¥ÊôÇÈñìÊúÄÂ∞èÂåñÔºåComDML ÂÑ™ÂåñÂ∑•‰ΩúË≤†ËºâÂπ≥Ë°°ÔºåÂêåÊôÇËÄÉÈáèÊô∫ËÉΩÈ´îÁöÑÈÄöË®äÂíåÈÅãÁÆóËÉΩÂäõÔºåÈÄôÂèñÊ±∫ÊñºÊï¥Êï∏Ë¶èÂäÉ„ÄÇÈñãÁôº‰∫ÜÂãïÊÖãÂàÜÊï£ÂºèÈÖçÂ∞çÊéíÁ®ãÂô®‰æÜÊúâÊïàÈÖçÂ∞çÊô∫ËÉΩÈ´î‰∏¶Á¢∫ÂÆöÊúÄ‰Ω≥Âç∏ËºâÈáè„ÄÇÊàëÂÄëË≠âÊòéÂú® ComDML ‰∏≠ÔºåÂ∞çÊñºÂá∏ÂáΩÊï∏ÂíåÈùûÂá∏ÂáΩÊï∏ÔºåËºÉÊÖ¢ÂíåËºÉÂø´ÁöÑÊô∫ËÉΩÈ´îÊ®°ÂûãÈÉΩÊúÉÊî∂ÊñÇ„ÄÇÊ≠§Â§ñÔºåÂú®ÁÜ±ÈñÄË≥áÊñôÈõÜÔºàCIFAR-10„ÄÅCIFAR-100 Âíå CINIC-10ÔºâÂèäÂÖ∂Èùû I.I.D. ËÆäÈ´î‰∏äÈÄ≤Ë°åÁöÑÂª£Ê≥õÂØ¶È©óÁµêÊûúÔºå‰ª•Âèä ResNet-56 Âíå ResNet-110 Á≠âÂ§ßÂûãÊ®°ÂûãÔºåË≠âÊòéËàáÁèæÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåComDML ÂèØ‰ª•È°ØËëóÊ∏õÂ∞ëÊï¥È´îË®ìÁ∑¥ÊôÇÈñìÔºåÂêåÊôÇÁ∂≠ÊåÅÊ®°ÂûãÊ∫ñÁ¢∫Â∫¶„ÄÇComDML Âú®Áï∞Ë≥™Áí∞Â¢É‰∏≠Â±ïÁèæÂá∫Á©©ÂÅ•ÊÄßÔºå‰∏îÂèØ‰ª•ÁÑ°Á∏´Êï¥ÂêàÈö±ÁßÅÊé™ÊñΩ‰ª•Â¢ûÂº∑Ë≥áÊñô‰øùË≠∑„ÄÇ

##### **WIBA: What Is Being Argued? A Comprehensive Approach to Argument Mining**
2405.00828v1 by Arman Irani,Ju Yeon Park,Kevin Esterling,Michalis Faloutsos

We propose WIBA, a novel framework and suite of methods that enable the
comprehensive understanding of "What Is Being Argued" across contexts. Our
approach develops a comprehensive framework that detects: (a) the existence,
(b) the topic, and (c) the stance of an argument, correctly accounting for the
logical dependence among the three tasks. Our algorithm leverages the
fine-tuning and prompt-engineering of Large Language Models. We evaluate our
approach and show that it performs well in all the three capabilities. First,
we develop and release an Argument Detection model that can classify a piece of
text as an argument with an F1 score between 79% and 86% on three different
benchmark datasets. Second, we release a language model that can identify the
topic being argued in a sentence, be it implicit or explicit, with an average
similarity score of 71%, outperforming current naive methods by nearly 40%.
Finally, we develop a method for Argument Stance Classification, and evaluate
the capability of our approach, showing it achieves a classification F1 score
between 71% and 78% across three diverse benchmark datasets. Our evaluation
demonstrates that WIBA allows the comprehensive understanding of What Is Being
Argued in large corpora across diverse contexts, which is of core interest to
many applications in linguistics, communication, and social and computer
science. To facilitate accessibility to the advancements outlined in this work,
we release WIBA as a free open access platform (wiba.dev).

ÊëòË¶ÅÔºö<paragraph>ÊàëÂÄëÊèêÂá∫ WIBAÔºåÈÄôÊòØ‰∏ÄÂÄãÊñ∞Á©éÁöÑÊû∂ÊßãÂíåÊñπÊ≥ïÁµÑÔºåÂèØÂÖ®Èù¢‰∫ÜËß£‰∏çÂêåËÑàÁµ°‰∏≠ÁöÑ„ÄåË´ñÈªûÊòØ‰ªÄÈ∫º„Äç„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÈñãÁôº‰∫Ü‰∏ÄÂÄãÁ∂úÂêàÊû∂ÊßãÔºåÁî®ÊñºÂÅµÊ∏¨Ôºö(a) Ë´ñÈªûÊòØÂê¶Â≠òÂú®Ôºå(b) Ë´ñÈªûÁöÑ‰∏ªÈ°åÔºå‰ª•Âèä (c) Ë´ñÈªûÁöÑÁ´ãÂ†¥Ôºå‰∏¶Ê≠£Á¢∫ËÄÉÈáè‰∏âÈ†Ö‰ªªÂãô‰πãÈñìÁöÑÈÇèËºØ‰æùË≥¥ÊÄß„ÄÇÊàëÂÄëÁöÑÊºîÁÆóÊ≥ïÂà©Áî®Â§ßÂûãË™ûË®ÄÊ®°ÂûãÁöÑÂæÆË™øÂíåÊèêÁ§∫Â∑•Á®ã„ÄÇÊàëÂÄëË©ï‰º∞ÊàëÂÄëÁöÑÂÅöÊ≥ïÔºå‰∏¶È°ØÁ§∫ÂÆÉÂú®ÊâÄÊúâ‰∏âÈ†ÖËÉΩÂäõ‰∏≠ÈÉΩÊúâËâØÂ•ΩÁöÑË°®Áèæ„ÄÇÈ¶ñÂÖàÔºåÊàëÂÄëÈñãÁôº‰∏¶ÁôºÂ∏É‰∏ÄÂÄãË´ñÈªûÂÅµÊ∏¨Ê®°ÂûãÔºåÂÆÉÂèØ‰ª•Â∞á‰∏ÄÊÆµÊñáÂ≠óÂàÜÈ°ûÁÇ∫Ë´ñÈªûÔºåÂú®‰∏âÂÄã‰∏çÂêåÁöÑÂü∫Ê∫ñË≥áÊñôÈõÜ‰∏äÁöÑ F1 ÂàÜÊï∏‰ªãÊñº 79% Âà∞ 86% ‰πãÈñì„ÄÇÂÖ∂Ê¨°ÔºåÊàëÂÄëÁôºÂ∏É‰∏ÄÂÄãË™ûË®ÄÊ®°ÂûãÔºåÂÆÉÂèØ‰ª•Ë≠òÂà•Âè•Â≠ê‰∏≠Ë¢´Ë´ñË≠âÁöÑ‰∏ªÈ°åÔºåÁÑ°Ë´ñÊòØÈö±Âê´ÁöÑÈÇÑÊòØÊòéÁ¢∫ÁöÑÔºåÂπ≥ÂùáÁõ∏‰ººÂ∫¶ÂàÜÊï∏ÁÇ∫ 71%ÔºåÊØîÁõÆÂâçÁöÑÁ∞°ÂåñÊñπÊ≥ïÈ´òÂá∫Ëøë 40%„ÄÇÊúÄÂæåÔºåÊàëÂÄëÈñãÁôº‰∫Ü‰∏ÄÁ®ÆË´ñÈªûÁ´ãÂ†¥ÂàÜÈ°ûÁöÑÊñπÊ≥ïÔºå‰∏¶Ë©ï‰º∞ÊàëÂÄëÂÅöÊ≥ïÁöÑËÉΩÂäõÔºåÈ°ØÁ§∫ÂÆÉÂú®‰∏âÂÄã‰∏çÂêåÁöÑÂü∫Ê∫ñË≥áÊñôÈõÜ‰∏äÈÅîÂà∞‰∫Ü 71% Âà∞ 78% ‰πãÈñìÁöÑÂàÜÈ°û F1 ÂàÜÊï∏„ÄÇÊàëÂÄëÁöÑË©ï‰º∞È°ØÁ§∫ÔºåWIBA ÂÖÅË®±ÂÖ®Èù¢‰∫ÜËß£Âú®‰∏çÂêåËÑàÁµ°‰∏≠Â§ßÂûãË™ûÊñôÂ∫´‰∏≠ÁöÑ„ÄåË´ñÈªûÊòØ‰ªÄÈ∫º„ÄçÔºåÈÄôÂ∞çË™ûË®ÄÂ≠∏„ÄÅÊ∫ùÈÄö‰ª•ÂèäÁ§æÊúÉÂíåÈõªËÖ¶ÁßëÂ≠∏‰∏≠ÁöÑË®±Â§öÊáâÁî®Á®ãÂºè‰æÜË™™ÈÉΩÊòØÊ†∏ÂøÉËààË∂£„ÄÇÁÇ∫‰∫Ü‰øÉÈÄ≤ÂèñÂæóÊú¨Ëëó‰Ωú‰∏≠Ê¶ÇËø∞ÁöÑÈÄ≤Â±ïÔºåÊàëÂÄëÂ∞á WIBA ‰ΩúÁÇ∫‰∏ÄÂÄãÂÖçË≤ªÈñãÊîæÂ≠òÂèñÂπ≥Âè∞ (wiba.dev) ÁôºÂ∏É„ÄÇ</paragraph>

##### **"Ask Me Anything": How Comcast Uses LLMs to Assist Agents in Real Time**
2405.00801v1 by Scott Rome,Tianwen Chen,Raphael Tang,Luwei Zhou,Ferhan Ture

Customer service is how companies interface with their customers. It can
contribute heavily towards the overall customer satisfaction. However,
high-quality service can become expensive, creating an incentive to make it as
cost efficient as possible and prompting most companies to utilize AI-powered
assistants, or "chat bots". On the other hand, human-to-human interaction is
still desired by customers, especially when it comes to complex scenarios such
as disputes and sensitive topics like bill payment.
  This raises the bar for customer service agents. They need to accurately
understand the customer's question or concern, identify a solution that is
acceptable yet feasible (and within the company's policy), all while handling
multiple conversations at once.
  In this work, we introduce "Ask Me Anything" (AMA) as an add-on feature to an
agent-facing customer service interface. AMA allows agents to ask questions to
a large language model (LLM) on demand, as they are handling customer
conversations -- the LLM provides accurate responses in real-time, reducing the
amount of context switching the agent needs. In our internal experiments, we
find that agents using AMA versus a traditional search experience spend
approximately 10% fewer seconds per conversation containing a search,
translating to millions of dollars of savings annually. Agents that used the
AMA feature provided positive feedback nearly 80% of the time, demonstrating
its usefulness as an AI-assisted feature for customer care.

ÊëòË¶ÅÔºöÂÆ¢Êà∂ÊúçÂãôÊòØÂÖ¨Âè∏ËàáÂÆ¢Êà∂‰∫íÂãïÁöÑÊñπÂºè„ÄÇÂÆÉÂèØ‰ª•Ê•µÂ§ßÂú∞ÊèêÂçáÊï¥È´îÂÆ¢Êà∂ÊªøÊÑèÂ∫¶„ÄÇÁÑ∂ËÄåÔºåÈ´òÂìÅË≥™ÁöÑÊúçÂãôÂèØËÉΩÊúÉËÆäÂæóÊòÇË≤¥ÔºåÈÄôÊúÉÂ∏∂‰æÜ‰∏ÄÂÄãË™òÂõ†ÔºåËÆìÊúçÂãôÁõ°ÂèØËÉΩÂú∞ÂÖ∑ÊúâÊàêÊú¨ÊïàÁõäÔºå‰∏¶‰øÉ‰ΩøÂ§ßÂ§öÊï∏ÂÖ¨Âè∏Âà©Áî® AI È©ÖÂãïÁöÑÂä©ÁêÜÊàñ„ÄåËÅäÂ§©Ê©üÂô®‰∫∫„Äç„ÄÇÂè¶‰∏ÄÊñπÈù¢ÔºåÂÆ¢Êà∂‰ªçÁÑ∂Ê∏¥Êúõ‰∫∫Ëàá‰∫∫ÁöÑ‰∫íÂãïÔºåÁâπÂà•ÊòØÂú®ÈÅáÂà∞Á≥æÁ¥õÂíåÂ∏≥ÂñÆÊîØ‰ªòÁ≠âË§áÈõúÊÉÖÊ≥ÅÂíåÊïèÊÑüË©±È°åÊôÇ„ÄÇ
ÈÄôÊèêÈ´ò‰∫ÜÂÆ¢Êà∂ÊúçÂãô‰∫∫Âì°ÁöÑÊ®ôÊ∫ñ„ÄÇ‰ªñÂÄëÈúÄË¶ÅÊ∫ñÁ¢∫Âú∞‰∫ÜËß£ÂÆ¢Êà∂ÁöÑÂïèÈ°åÊàñÁñëÊÖÆÔºåÊâæÂá∫ÂèØÊé•Âèó‰∏îÂèØË°åÁöÑËß£Ê±∫ÊñπÊ°àÔºà‰∏¶Á¨¶ÂêàÂÖ¨Âè∏ÁöÑÊîøÁ≠ñÔºâÔºåÂêåÊôÇÈÇÑËÉΩ‰∏ÄÊ¨°ËôïÁêÜÂ§öÂÄãÂ∞çË©±„ÄÇ
Âú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÂ∞á„ÄåAsk Me Anything„ÄçÔºàAMAÔºâ‰ΩúÁÇ∫‰∏ÄÁ®ÆÈôÑÂä†ÂäüËÉΩÔºåÂºïÂÖ•Âà∞Èù¢ÂêëÂÆ¢Êúç‰∫∫Âì°ÁöÑÂÆ¢Êà∂ÊúçÂãô‰ªãÈù¢‰∏≠„ÄÇAMA ËÆìÂÆ¢Êúç‰∫∫Âì°ÂèØ‰ª•Âú®ËôïÁêÜÂÆ¢Êà∂Â∞çË©±ÊôÇÔºå‰æùÊìöÈúÄÊ±ÇÂêëÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâÊèêÂïè‚Äî‚ÄîLLM ÊúÉÂç≥ÊôÇÊèê‰æõÊ∫ñÁ¢∫ÁöÑÂõûÊáâÔºåÊ∏õÂ∞ëÂÆ¢Êúç‰∫∫Âì°Âú®‰∏çÂêåÊÉÖÂ¢ÉÈñìÂàáÊèõÁöÑÊ¨°Êï∏„ÄÇÂú®ÊàëÂÄëÁöÑÂÖßÈÉ®ÂØ¶È©ó‰∏≠ÔºåÊàëÂÄëÁôºÁèæ‰ΩøÁî® AMA ÁöÑÂÆ¢Êúç‰∫∫Âì°ÔºåËàá‰ΩøÁî®ÂÇ≥Áµ±ÊêúÂ∞ãÈ´îÈ©óÁöÑÂÆ¢Êúç‰∫∫Âì°Áõ∏ÊØîÔºåÂú®ÂåÖÂê´ÊêúÂ∞ãÁöÑÂ∞çË©±‰∏≠Âπ≥ÂùáÊ∏õÂ∞ë‰∫ÜÁ¥Ñ 10% ÁöÑÁßíÊï∏ÔºåÈÄôÁõ∏Áï∂ÊñºÊØèÂπ¥ÁØÄÁúÅÊï∏ÁôæËê¨ÁæéÂÖÉ„ÄÇ‰ΩøÁî® AMA ÂäüËÉΩÁöÑÂÆ¢Êúç‰∫∫Âì°ÊúâÂ∞áËøë 80% ÁöÑÊôÇÈñìÁµ¶‰∫àÊ≠£Èù¢ÁöÑÂõûÈ•ãÔºåÈÄôË≠âÊòé‰∫ÜÂÖ∂‰ΩúÁÇ∫ AI ËºîÂä©ÂäüËÉΩÂú®ÂÆ¢Êà∂ÊúçÂãô‰∏≠ÁöÑÂØ¶Áî®ÊÄß„ÄÇ

##### **Obtaining Favorable Layouts for Multiple Object Generation**
2405.00791v1 by Barak Battash,Amit Rozner,Lior Wolf,Ofir Lindenbaum

Large-scale text-to-image models that can generate high-quality and diverse
images based on textual prompts have shown remarkable success. These models aim
ultimately to create complex scenes, and addressing the challenge of
multi-subject generation is a critical step towards this goal. However, the
existing state-of-the-art diffusion models face difficulty when generating
images that involve multiple subjects. When presented with a prompt containing
more than one subject, these models may omit some subjects or merge them
together. To address this challenge, we propose a novel approach based on a
guiding principle. We allow the diffusion model to initially propose a layout,
and then we rearrange the layout grid. This is achieved by enforcing
cross-attention maps (XAMs) to adhere to proposed masks and by migrating pixels
from latent maps to new locations determined by us. We introduce new loss terms
aimed at reducing XAM entropy for clearer spatial definition of subjects,
reduce the overlap between XAMs, and ensure that XAMs align with their
respective masks. We contrast our approach with several alternative methods and
show that it more faithfully captures the desired concepts across a variety of
text prompts.

ÊëòË¶ÅÔºöÂ§ßÂûãÊñáÊú¨Âà∞ÂõæÂÉèÊ®°ÂûãÂèØ‰ª•Ê†πÊçÆÊñáÊú¨ÊèêÁ§∫ÁîüÊàêÈ´òË¥®Èáè‰∏îÂ§öÊ†∑ÁöÑÂõæÂÉèÔºåÂ∑≤Â±ïÁé∞Âá∫ÈùûÂá°ÁöÑÊàêÂäü„ÄÇËøô‰∫õÊ®°ÂûãÊúÄÁªàÁöÑÁõÆÊ†áÊòØÂàõÂª∫Â§çÊùÇÁöÑÂú∫ÊôØÔºåËÄåËß£ÂÜ≥Â§ö‰∏ªÈ¢òÁîüÊàêÊåëÊàòÊòØÂÆûÁé∞Ëøô‰∏ÄÁõÆÊ†áÁöÑÂÖ≥ÈîÆÊ≠•È™§„ÄÇÁÑ∂ËÄåÔºåÁé∞ÊúâÁöÑÊúÄÂÖàËøõÁöÑÊâ©Êï£Ê®°ÂûãÂú®ÁîüÊàêÊ∂âÂèäÂ§ö‰∏™‰∏ªÈ¢òÁöÑÂõæÂÉèÊó∂Èù¢‰∏¥Âõ∞Èöæ„ÄÇÂΩìÂá∫Áé∞ÂåÖÂê´Â§ö‰∏™‰∏ªÈ¢òÁöÑÊèêÁ§∫Êó∂ÔºåËøô‰∫õÊ®°ÂûãÂèØËÉΩ‰ºöÁúÅÁï•‰∏Ä‰∫õ‰∏ªÈ¢òÊàñÂ∞ÜÂÆÉ‰ª¨ÂêàÂπ∂Âú®‰∏ÄËµ∑„ÄÇ‰∏∫‰∫ÜÂ∫îÂØπËøô‰∏ÄÊåëÊàòÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçÂü∫‰∫éÊåáÂØºÂéüÂàôÁöÑÊñ∞ÊñπÊ≥ï„ÄÇÊàë‰ª¨ÂÖÅËÆ∏Êâ©Êï£Ê®°ÂûãÊúÄÂàùÊèêÂá∫‰∏Ä‰∏™Â∏ÉÂ±ÄÔºåÁÑ∂ÂêéÊàë‰ª¨ÈáçÊñ∞ÊéíÂàóÂ∏ÉÂ±ÄÁΩëÊ†º„ÄÇËøôÊòØÈÄöËøáÂº∫Âà∂‰∫§ÂèâÊ≥®ÊÑèÂäõÂõæ (XAM) ÈÅµÂÆàÂª∫ËÆÆÁöÑËíôÁâàÂπ∂ÈÄöËøáÂ∞ÜÂÉèÁ¥†‰ªéÊΩúÂú®Âú∞ÂõæËøÅÁßªÂà∞Êàë‰ª¨Á°ÆÂÆöÁöÑÊñ∞‰ΩçÁΩÆÊù•ÂÆûÁé∞ÁöÑ„ÄÇÊàë‰ª¨ÂºïÂÖ•‰∫ÜÊñ∞ÁöÑÊçüÂ§±È°πÔºåÊó®Âú®ÂáèÂ∞ë XAM ÁÜµ‰ª•Êõ¥Ê∏ÖÊô∞Âú∞ÂÆö‰πâ‰∏ªÈ¢òÁöÑÁ©∫Èó¥ÔºåÂáèÂ∞ë XAM ‰πãÈó¥ÁöÑÈáçÂè†ÔºåÂπ∂Á°Æ‰øù XAM ‰∏éÂÖ∂ÂêÑËá™ÁöÑËíôÁâàÂØπÈΩê„ÄÇÊàë‰ª¨Â∞ÜÊàë‰ª¨ÁöÑÊñπÊ≥ï‰∏éÂá†ÁßçÊõø‰ª£ÊñπÊ≥ïËøõË°åÂØπÊØîÔºåÂπ∂Ë°®ÊòéÂÆÉÂú®ÂêÑÁßçÊñáÊú¨ÊèêÁ§∫‰∏≠Êõ¥Âø†ÂÆûÂú∞ÊçïÊçâ‰∫ÜÊâÄÈúÄÁöÑÁêÜÂøµ„ÄÇ

##### **SCAR: Scheduling Multi-Model AI Workloads on Heterogeneous Multi-Chiplet Module Accelerators**
2405.00790v1 by Mohanad Odema,Luke Chen,Hyoukjun Kwon,Mohammad Abdullah Al Faruque

Emerging multi-model workloads with heavy models like recent large language
models significantly increased the compute and memory demands on hardware. To
address such increasing demands, designing a scalable hardware architecture
became a key problem. Among recent solutions, the 2.5D silicon interposer
multi-chip module (MCM)-based AI accelerator has been actively explored as a
promising scalable solution due to their significant benefits in the low
engineering cost and composability. However, previous MCM accelerators are
based on homogeneous architectures with fixed dataflow, which encounter major
challenges from highly heterogeneous multi-model workloads due to their limited
workload adaptivity. Therefore, in this work, we explore the opportunity in the
heterogeneous dataflow MCM AI accelerators. We identify the scheduling of
multi-model workload on heterogeneous dataflow MCM AI accelerator is an
important and challenging problem due to its significance and scale, which
reaches O(10^18) scale even for a single model case on 6x6 chiplets. We develop
a set of heuristics to navigate the huge scheduling space and codify them into
a scheduler with advanced techniques such as inter-chiplet pipelining. Our
evaluation on ten multi-model workload scenarios for datacenter multitenancy
and AR/VR use-cases has shown the efficacy of our approach, achieving on
average 35.3% and 31.4% less energy-delay product (EDP) for the respective
applications settings compared to homogeneous baselines.

ÊëòË¶ÅÔºöÈö®ËëóËøëÊúüÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÁ≠âÈáçÈáèÁ¥öÊ®°ÂûãÁöÑÊñ∞ËààÂ§öÊ®°ÂºèÂ∑•‰ΩúË≤†ËºâÔºåÂ∞çÁ°¨È´îÁöÑÈÅãÁÆóÂíåË®òÊÜ∂È´îÈúÄÊ±ÇÂ§ßÂπÖÂ¢ûÂä†„ÄÇÁÇ∫‰∫ÜÊªøË∂≥ÈÄô‰∫õÊó•ÁõäÂ¢ûÈï∑ÁöÑÈúÄÊ±ÇÔºåË®≠Ë®àÂèØÊì¥ÂÖÖÁöÑÁ°¨È´îÊû∂ÊßãÂ∑≤ÊàêÁÇ∫‰∏ÄÂÄãÈóúÈçµÂïèÈ°å„ÄÇÂú®ÊúÄËøëÁöÑËß£Ê±∫ÊñπÊ°à‰∏≠ÔºåÂü∫Êñº 2.5D ÁüΩ‰ªãÈù¢Â±§Â§öÊô∂ÁâáÊ®°ÁµÑ (MCM) ÁöÑ AI Âä†ÈÄüÂô®Áî±ÊñºÂÖ∂Âú®‰ΩéÂ∑•Á®ãÊàêÊú¨ÂíåÂèØÁµÑÂêàÊÄßÊñπÈù¢ÁöÑÈ°ØËëóÂÑ™Âã¢ÔºåÂ∑≤Ë¢´Á©çÊ•µÊé¢Á¥¢ÁÇ∫‰∏ÄÂÄãÊúâÂâçÈÄîÁöÑÂèØÊì¥ÂÖÖËß£Ê±∫ÊñπÊ°à„ÄÇÁÑ∂ËÄåÔºåÂÖàÂâçÁöÑ MCM Âä†ÈÄüÂô®Âü∫ÊñºÂÖ∑ÊúâÂõ∫ÂÆöË≥áÊñôÊµÅÁöÑÂêåË≥™Êû∂ÊßãÔºåÁî±ÊñºÂÖ∂ÊúâÈôêÁöÑÂ∑•‰ΩúË≤†ËºâÈÅ©ÊáâÊÄßÔºåÂú®È´òÂ∫¶Áï∞Ë≥™ÁöÑÂ§öÊ®°ÂºèÂ∑•‰ΩúË≤†Ëºâ‰∏≠ÈÅáÂà∞‰∫ÜÈáçÂ§ßÊåëÊà∞„ÄÇÂõ†Ê≠§ÔºåÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊé¢Ë®é‰∫ÜÁï∞Ë≥™Ë≥áÊñôÊµÅ MCM AI Âä†ÈÄüÂô®ÁöÑÊ©üÊúÉ„ÄÇÊàëÂÄëÁôºÁèæÔºåÂú®Áï∞Ë≥™Ë≥áÊñôÊµÅ MCM AI Âä†ÈÄüÂô®‰∏äÂÆâÊéíÂ§öÊ®°ÂºèÂ∑•‰ΩúË≤†ËºâÊòØ‰∏ÄÂÄãÈáçË¶Å‰∏îÂÖ∑ÊúâÊåëÊà∞ÊÄßÁöÑÂïèÈ°åÔºåÂõ†ÁÇ∫ÂÖ∂ÈáçË¶ÅÊÄßÂíåË¶èÊ®°ÔºåÂç≥‰ΩøÂ∞çÊñº 6x6 Êô∂ÁâáÁµÑ‰∏äÁöÑÂñÆ‰∏ÄÊ®°ÂûãÊ°à‰æãÔºå‰πüÈÅîÂà∞ O(10^18) ÁöÑË¶èÊ®°„ÄÇÊàëÂÄëÈñãÁôº‰∫Ü‰∏ÄÁµÑÂïüÁôºÊ≥ï‰æÜÂ∞éËà™ÈæêÂ§ßÁöÑÊéíÁ®ãÁ©∫ÈñìÔºå‰∏¶Â∞áÂÆÉÂÄëÁ∑®ÂÖ•‰∏ÄÂÄãÊéíÁ®ãÂô®ÔºåÂÖ∂‰∏≠ÂåÖÂê´ÂÖàÈÄ≤ÁöÑÊäÄË°ìÔºå‰æãÂ¶ÇÊô∂ÁâáÈñìÊµÅÊ∞¥Á∑ö„ÄÇÊàëÂÄëÂ∞çË≥áÊñô‰∏≠ÂøÉÂ§öÁßüÊà∂Âíå AR/VR ‰ΩøÁî®Ê°à‰æãÁöÑÂçÅÂÄãÂ§öÊ®°ÂºèÂ∑•‰ΩúË≤†ËºâÂ†¥ÊôØÁöÑË©ï‰º∞È°ØÁ§∫‰∫ÜÊàëÂÄëÊñπÊ≥ïÁöÑÊúâÊïàÊÄßÔºåËàáÂêåË≥™Âü∫Ê∫ñÁõ∏ÊØîÔºåÂ∞çÊñºÂêÑËá™ÁöÑÊáâÁî®Á®ãÂºèË®≠ÂÆöÔºåÂπ≥ÂùáÁØÄÁúÅ‰∫Ü 35.3% Âíå 31.4% ÁöÑËÉΩËÄóÂª∂ÈÅ≤‰πòÁ©ç (EDP)„ÄÇ

##### **Self-Play Preference Optimization for Language Model Alignment**
2405.00675v1 by Yue Wu,Zhiqing Sun,Huizhuo Yuan,Kaixuan Ji,Yiming Yang,Quanquan Gu

Traditional reinforcement learning from human feedback (RLHF) approaches
relying on parametric models like the Bradley-Terry model fall short in
capturing the intransitivity and irrationality in human preferences. Recent
advancements suggest that directly working with preference probabilities can
yield a more accurate reflection of human preferences, enabling more flexible
and accurate language model alignment. In this paper, we propose a
self-play-based method for language model alignment, which treats the problem
as a constant-sum two-player game aimed at identifying the Nash equilibrium
policy. Our approach, dubbed \textit{Self-Play Preference Optimization} (SPPO),
approximates the Nash equilibrium through iterative policy updates and enjoys
theoretical convergence guarantee. Our method can effectively increase the
log-likelihood of the chosen response and decrease that of the rejected
response, which cannot be trivially achieved by symmetric pairwise loss such as
Direct Preference Optimization (DPO) and Identity Preference Optimization
(IPO). In our experiments, using only 60k prompts (without responses) from the
UltraFeedback dataset and without any prompt augmentation, by leveraging a
pre-trained preference model PairRM with only 0.4B parameters, SPPO can obtain
a model from fine-tuning Mistral-7B-Instruct-v0.2 that achieves the
state-of-the-art length-controlled win-rate of 28.53% against GPT-4-Turbo on
AlpacaEval 2.0. It also outperforms the (iterative) DPO and IPO on MT-Bench and
the Open LLM Leaderboard. Notably, the strong performance of SPPO is achieved
without additional external supervision (e.g., responses, preferences, etc.)
from GPT-4 or other stronger language models.

ÊëòË¶ÅÔºö<paragraph>ÂÇ≥Áµ±ÁöÑ‰∫∫È°ûÂõûÈ•ãÂº∑ÂåñÂ≠∏Áøí (RLHF) ÊñπÊ≥ï‰æùË≥¥ÊñºÂèÉÊï∏Ê®°ÂûãÔºå‰æãÂ¶Ç Bradley-Terry Ê®°ÂûãÔºåÂú®ÊçïÊçâ‰∫∫È°ûÂÅèÂ•ΩÁöÑÈùûÂÇ≥ÈÅûÊÄßÂíåÈùûÁêÜÊÄßÊñπÈù¢Â≠òÂú®‰∏çË∂≥„ÄÇÊúÄËøëÁöÑÈÄ≤Â±ïË°®ÊòéÔºåÁõ¥Êé•‰ΩøÁî®ÂÅèÂ•ΩÊ©üÁéáÂèØ‰ª•Êõ¥Ê∫ñÁ¢∫Âú∞ÂèçÊò†‰∫∫È°ûÂÅèÂ•ΩÔºåÂØ¶ÁèæÊõ¥ÈùàÊ¥ª„ÄÅÊõ¥Ê∫ñÁ¢∫ÁöÑË™ûË®ÄÊ®°ÂûãÂ∞çÈΩä„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂü∫ÊñºËá™Áé©ÁöÑÊñπÊ≥ïÈÄ≤Ë°åË™ûË®ÄÊ®°ÂûãÂ∞çÈΩäÔºåÂ∞áÂïèÈ°åË¶ñÁÇ∫‰∏ÄÂÄãÊÅÜÂíåÈõô‰∫∫ÈÅäÊà≤ÔºåÊó®Âú®Ë≠òÂà•Á¥ç‰ªÄÂùáË°°Á≠ñÁï•„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÁ®±ÁÇ∫„ÄåËá™Áé©ÂÅèÂ•ΩÊúÄ‰Ω≥Âåñ„Äç(SPPO)ÔºåÈÄèÈÅéÂèçË¶ÜÁöÑÁ≠ñÁï•Êõ¥Êñ∞‰æÜÈÄºËøëÁ¥ç‰ªÄÂùáË°°Ôºå‰∏¶‰∫´ÊúâÁêÜË´ñ‰∏äÁöÑÊî∂ÊñÇ‰øùË≠â„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÂèØ‰ª•ÊúâÊïàÂú∞Â¢ûÂä†ÊâÄÈÅ∏ÂõûÊáâÁöÑÂ∞çÊï∏‰ººÁÑ∂Â∫¶Ôºå‰∏¶Ê∏õÂ∞ëË¢´ÊãíÁµïÂõûÊáâÁöÑÂ∞çÊï∏‰ººÁÑ∂Â∫¶ÔºåÈÄôÊòØÂ∞çÁ®±ÊàêÂ∞çÊêçÂ§±Ôºà‰æãÂ¶ÇÁõ¥Êé•ÂÅèÂ•ΩÊúÄ‰Ω≥Âåñ (DPO) ÂíåË∫´ÂàÜÂÅèÂ•ΩÊúÄ‰Ω≥Âåñ (IPO)ÔºâÁÑ°Ê≥ïËºïÊòìÂØ¶ÁèæÁöÑ„ÄÇÂú®ÊàëÂÄëÁöÑÂØ¶È©ó‰∏≠ÔºåÂÉÖ‰ΩøÁî® UltraFeedback Ë≥áÊñôÈõÜ‰∏≠ÁöÑ 60k ÂÄãÊèêÁ§∫ÔºàÊ≤íÊúâÂõûÊáâÔºâÔºå‰∏îÊ≤íÊúâ‰ªª‰ΩïÊèêÁ§∫Êì¥ÂÖÖÔºåÈÄèÈÅéÂà©Áî®ÂÉÖÊúâ 0.4B ÂèÉÊï∏ÁöÑÈ†êË®ìÁ∑¥ÂÅèÂ•ΩÊ®°Âûã PairRMÔºåSPPO ÂèØ‰ª•ÂæûÂæÆË™ø Mistral-7B-Instruct-v0.2 ‰∏≠Áç≤ÂæóÊ®°ÂûãÔºåÂú® AlpacaEval 2.0 ‰∏äÂ∞çÊäó GPT-4-Turbo ÊôÇÔºåÈÅîÂà∞ 28.53% ÁöÑÊúÄÂÖàÈÄ≤Èï∑Â∫¶ÊéßÂà∂ÂãùÁéá„ÄÇÂÆÉÈÇÑÂú® MT-Bench Âíå Open LLM Leaderboard ‰∏äÂÑ™ÊñºÔºàÂèçË¶ÜÔºâDPO Âíå IPO„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåSPPO ÁöÑÂº∑ÂãÅÊïàËÉΩÊòØÂú®Ê≤íÊúâ‰æÜËá™ GPT-4 ÊàñÂÖ∂‰ªñÊõ¥Âº∑Â§ßÁöÑË™ûË®ÄÊ®°ÂûãÁöÑÈ°çÂ§ñÂ§ñÈÉ®Áõ£Áù£Ôºà‰æãÂ¶ÇÂõûÊáâ„ÄÅÂÅèÂ•ΩÁ≠âÔºâÁöÑÊÉÖÊ≥Å‰∏ãÂØ¶ÁèæÁöÑ„ÄÇ</paragraph>

##### **Is Bigger Edit Batch Size Always Better? -- An Empirical Study on Model Editing with Llama-3**
2405.00664v1 by Junsang Yoon,Akshat Gupta,Gopala Anumanchipalli

This study presents a targeted model editing analysis focused on the latest
large language model, Llama-3. We explore the efficacy of popular model editing
techniques - ROME, MEMIT, and EMMET, which are designed for precise layer
interventions. We identify the most effective layers for targeted edits through
an evaluation that encompasses up to 4096 edits across three distinct
strategies: sequential editing, batch editing, and a hybrid approach we call as
sequential-batch editing. Our findings indicate that increasing edit
batch-sizes may degrade model performance more significantly than using smaller
edit batches sequentially for equal number of edits. With this, we argue that
sequential model editing is an important component for scaling model editing
methods and future research should focus on methods that combine both batched
and sequential editing. This observation suggests a potential limitation in
current model editing methods which push towards bigger edit batch sizes, and
we hope it paves way for future investigations into optimizing batch sizes and
model editing performance.

ÊëòË¶ÅÔºöÊú¨Á†îÁ©∂ÈáùÂ∞çÊúÄÊñ∞ÁöÑÂ§ßÂûãË™ûË®ÄÊ®°Âûã Llama-3 ÊèêÂá∫‰∏ÄÂÄãÁõÆÊ®ôÊ®°ÂûãÁ∑®ËºØÂàÜÊûê„ÄÇÊàëÂÄëÊé¢Ë®é‰∫ÜÁÜ±ÈñÄÊ®°ÂûãÁ∑®ËºØÊäÄË°ìÁöÑÂäüÊïàÔºåÂåÖÊã¨ ROME„ÄÅMEMIT Âíå EMMETÔºåÈÄô‰∫õÊäÄË°ìÊòØÁÇ∫Á≤æÁ¢∫ÁöÑÂ±§Á¥ö‰ªãÂÖ•ËÄåË®≠Ë®àÁöÑ„ÄÇÊàëÂÄëÈÄèÈÅéË©ï‰º∞‰æÜÊâæÂá∫ÈáùÂ∞çÁ∑®ËºØÊúÄÊúâÊïàÁöÑÂ±§Á¥öÔºåË©ï‰º∞Ê∂µËìã‰∫ÜÈÄèÈÅé‰∏âÁ®Æ‰∏çÂêåÁ≠ñÁï•Âü∑Ë°åÂ§öÈÅî 4096 Ê¨°Á∑®ËºØÔºöÂæ™Â∫èÁ∑®ËºØ„ÄÅÊâπÊ¨°Á∑®ËºØÔºå‰ª•ÂèäÊàëÂÄëÁ®±ÁÇ∫Âæ™Â∫èÊâπÊ¨°Á∑®ËºØÁöÑÊ∑∑ÂêàÊñπÊ≥ï„ÄÇÊàëÂÄëÁöÑÁôºÁèæÈ°ØÁ§∫ÔºåËàáÂæ™Â∫è‰ΩøÁî®ËºÉÂ∞èÁöÑÁ∑®ËºØÊâπÊ¨°‰æÜÂü∑Ë°åÁõ∏ÂêåÊ¨°Êï∏ÁöÑÁ∑®ËºØÁõ∏ÊØîÔºåÂ¢ûÂä†Á∑®ËºØÊâπÊ¨°Â§ßÂ∞èÂèØËÉΩÊúÉÊõ¥È°ØËëóÂú∞Èôç‰ΩéÊ®°ÂûãÊïàËÉΩ„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëË™çÁÇ∫Âæ™Â∫èÊ®°ÂûãÁ∑®ËºØÊòØÊì¥ÂÖÖÊ®°ÂûãÁ∑®ËºØÊñπÊ≥ïÁöÑÈáçË¶ÅÁµÑÊàêÈÉ®ÂàÜÔºåËÄåÊú™‰æÜÁöÑÁ†îÁ©∂ÊáâËëóÈáçÊñºÁµêÂêàÊâπÊ¨°ÂíåÂæ™Â∫èÁ∑®ËºØÁöÑÂÖ©Á®ÆÊñπÊ≥ï„ÄÇÊ≠§ËßÄÂØüÁµêÊûúÈ°ØÁ§∫ÔºåÁõÆÂâçÊé®Âãï‰ΩøÁî®ËºÉÂ§ßÁ∑®ËºØÊâπÊ¨°Â§ßÂ∞èÁöÑÊ®°ÂûãÁ∑®ËºØÊñπÊ≥ïÂ≠òÂú®ÊΩõÂú®ÈôêÂà∂ÔºåÊàëÂÄëÂ∏åÊúõÂÆÉËÉΩÁÇ∫Êú™‰æÜÂÑ™ÂåñÊâπÊ¨°Â§ßÂ∞èÂíåÊ®°ÂûãÁ∑®ËºØÊïàËÉΩÁöÑÁ†îÁ©∂Èã™Ë∑Ø„ÄÇ

##### **NLU-STR at SemEval-2024 Task 1: Generative-based Augmentation and Encoder-based Scoring for Semantic Textual Relatedness**
2405.00659v1 by Sanad Malaysha,Mustafa Jarrar,Mohammed Khalilia

Semantic textual relatedness is a broader concept of semantic similarity. It
measures the extent to which two chunks of text convey similar meaning or
topics, or share related concepts or contexts. This notion of relatedness can
be applied in various applications, such as document clustering and
summarizing. SemRel-2024, a shared task in SemEval-2024, aims at reducing the
gap in the semantic relatedness task by providing datasets for fourteen
languages and dialects including Arabic. This paper reports on our
participation in Track A (Algerian and Moroccan dialects) and Track B (Modern
Standard Arabic). A BERT-based model is augmented and fine-tuned for regression
scoring in supervised track (A), while BERT-based cosine similarity is employed
for unsupervised track (B). Our system ranked 1st in SemRel-2024 for MSA with a
Spearman correlation score of 0.49. We ranked 5th for Moroccan and 12th for
Algerian with scores of 0.83 and 0.53, respectively.

ÊëòË¶ÅÔºöË™ûÁæ©ÊñáÊú¨ÈóúËÅØÊÄßÊòØË™ûÁæ©Áõ∏‰ººÊÄßÁöÑÊõ¥Âª£Ê≥õÊ¶ÇÂøµ„ÄÇÂÆÉË°°ÈáèÂÖ©ÊÆµÊñáÊú¨ÂÇ≥ÈÅîÈ°û‰ººÊÑèÁæ©Êàñ‰∏ªÈ°åÁöÑÁ®ãÂ∫¶ÔºåÊàñÂÖ±‰∫´Áõ∏ÈóúÊ¶ÇÂøµÊàñ‰∏ä‰∏ãÊñá„ÄÇÈÄôÁ®ÆÁõ∏ÈóúÊÄßÁöÑÊ¶ÇÂøµÂèØ‰ª•ÊáâÁî®ÊñºÂêÑÁ®ÆÊáâÁî®Á®ãÂºèÔºå‰æãÂ¶ÇÊñá‰ª∂ÂàÜÁæ§ÂíåÊëòË¶Å„ÄÇSemEval-2024 ‰∏≠ÁöÑÂÖ±Áî®‰ªªÂãô SemRel-2024ÔºåÊó®Âú®ÈÄèÈÅéÊèê‰æõÂåÖÂê´ÈòøÊãâ‰ºØË™ûÂú®ÂÖßÁöÑÂçÅÂõõÁ®ÆË™ûË®ÄÂíåÊñπË®ÄÁöÑË≥áÊñôÈõÜÔºåÁ∏ÆÂ∞èË™ûÁæ©ÈóúËÅØÊÄß‰ªªÂãôÁöÑÂ∑ÆË∑ù„ÄÇÊú¨ÊñáÂ†±ÂëäÊàëÂÄëÂèÉËàá A ËªåÈÅìÔºàÈòøÁàæÂèäÂà©‰∫ûÂíåÊë©Ê¥õÂì•ÊñπË®ÄÔºâÂíå B ËªåÈÅìÔºàÁèæ‰ª£Ê®ôÊ∫ñÈòøÊãâ‰ºØË™ûÔºâÁöÑÁµêÊûú„ÄÇBERT Âü∫Á§éÊ®°ÂûãÁ∂ìÈÅéÊì¥ÂÖÖÂíåÂæÆË™øÔºå‰ª•ÈÄ≤Ë°åÁõ£Áù£ËªåÈÅì (A) ‰∏≠ÁöÑÂõûÊ≠∏Ë©ïÂàÜÔºåËÄå BERT Âü∫Á§éÈ§òÂº¶Áõ∏‰ººÂ∫¶ÂâáÁî®ÊñºÈùûÁõ£Áù£ËªåÈÅì (B)„ÄÇÊàëÂÄëÁöÑÁ≥ªÁµ±Âú® SemRel-2024 ‰∏≠ÁöÑ MSA ÊéíÂêçÁ¨¨ 1ÔºåSpearman Áõ∏Èóú‰øÇÊï∏ÂæóÂàÜÁÇ∫ 0.49„ÄÇÊàëÂÄëÂú®Êë©Ê¥õÂì•ÊéíÂêçÁ¨¨ 5ÔºåÂú®ÈòøÁàæÂèäÂà©‰∫ûÊéíÂêçÁ¨¨ 12ÔºåÂæóÂàÜÂàÜÂà•ÁÇ∫ 0.83 Âíå 0.53„ÄÇ

##### **RST-LoRA: A Discourse-Aware Low-Rank Adaptation for Long Document Abstractive Summarization**
2405.00657v1 by Dongqi Pu,Vera Demberg

For long document summarization, discourse structure is important to discern
the key content of the text and the differences in importance level between
sentences. Unfortunately, the integration of rhetorical structure theory (RST)
into parameter-efficient fine-tuning strategies for long document summarization
remains unexplored. Therefore, this paper introduces RST-LoRA and proposes four
RST-aware variants to explicitly incorporate RST into the LoRA model. Our
empirical evaluation demonstrates that incorporating the type and uncertainty
of rhetorical relations can complementarily enhance the performance of LoRA in
summarization tasks. Furthermore, the best-performing variant we introduced
outperforms the vanilla LoRA and full-parameter fine-tuning models, as
confirmed by multiple automatic and human evaluations, and even surpasses
previous state-of-the-art methods.

ÊëòË¶ÅÔºöÂ∞çÊñºÈï∑ÁØáÊñá‰ª∂ÊëòË¶ÅÔºåË™ûÁØáÁµêÊßãÂ∞çÊñºËæ®Âà•ÊñáÊú¨ÁöÑÈóúÈçµÂÖßÂÆπÂíåÂè•Â≠ê‰πãÈñìÈáçË¶ÅÊÄßÂ±§Á¥öÁöÑÂ∑ÆÁï∞ÈùûÂ∏∏ÈáçË¶Å„ÄÇ‰∏çÂπ∏ÁöÑÊòØÔºåÂ∞áË™ûÁØáÁµêÊßãÁêÜË´ñ (RST) Êï¥ÂêàÂà∞Èï∑ÁØáÊñá‰ª∂ÊëòË¶ÅÁöÑÂèÉÊï∏ÊúâÊïàÂæÆË™øÁ≠ñÁï•‰∏≠‰ªçÊú™Ë¢´Êé¢Ë®é„ÄÇÂõ†Ê≠§ÔºåÊú¨Êñá‰ªãÁ¥π RST-LoRAÔºå‰∏¶ÊèêÂá∫ÂõõÁ®Æ RST ÊÑüÁü•ËÆäÈ´îÔºå‰ª•Â∞á RST ÊòéÁ¢∫Á¥çÂÖ• LoRA Ê®°Âûã‰∏≠„ÄÇÊàëÂÄëÁöÑÂØ¶Ë≠âË©ï‰º∞Ë°®ÊòéÔºåÊï¥ÂêàË™ûÁØáÈóú‰øÇÁöÑÈ°ûÂûãÂíå‰∏çÁ¢∫ÂÆöÊÄßÂèØ‰ª•‰∫íË£úÂú∞Â¢ûÂº∑ LoRA Âú®ÊëòË¶Å‰ªªÂãô‰∏≠ÁöÑÊÄßËÉΩ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂºïÂÖ•ÁöÑÊïàËÉΩÊúÄ‰Ω≥ËÆäÈ´îÂÑ™ÊñºÈ¶ôËçâ LoRA ÂíåÂÖ®ÂèÉÊï∏ÂæÆË™øÊ®°ÂûãÔºåÊ≠£Â¶ÇÂ§öÈ†ÖËá™ÂãïÂíå‰∫∫Â∑•Ë©ï‰º∞ÊâÄË≠âÂØ¶ÁöÑÈÇ£Ê®£ÔºåÁîöËá≥Ë∂ÖË∂ä‰∫ÜÂÖàÂâçÁöÑÊúÄÂÖàÈÄ≤ÊñπÊ≥ï„ÄÇ

##### **ConstrainedZero: Chance-Constrained POMDP Planning using Learned Probabilistic Failure Surrogates and Adaptive Safety Constraints**
2405.00644v1 by Robert J. Moss,Arec Jamgochian,Johannes Fischer,Anthony Corso,Mykel J. Kochenderfer

To plan safely in uncertain environments, agents must balance utility with
safety constraints. Safe planning problems can be modeled as a
chance-constrained partially observable Markov decision process (CC-POMDP) and
solutions often use expensive rollouts or heuristics to estimate the optimal
value and action-selection policy. This work introduces the ConstrainedZero
policy iteration algorithm that solves CC-POMDPs in belief space by learning
neural network approximations of the optimal value and policy with an
additional network head that estimates the failure probability given a belief.
This failure probability guides safe action selection during online Monte Carlo
tree search (MCTS). To avoid overemphasizing search based on the failure
estimates, we introduce $\Delta$-MCTS, which uses adaptive conformal inference
to update the failure threshold during planning. The approach is tested on a
safety-critical POMDP benchmark, an aircraft collision avoidance system, and
the sustainability problem of safe CO$_2$ storage. Results show that by
separating safety constraints from the objective we can achieve a target level
of safety without optimizing the balance between rewards and costs.

ÊëòË¶ÅÔºöÂú®‰∏çÁ¢∫ÂÆöÁöÑÁí∞Â¢É‰∏≠ÂÆâÂÖ®Âú∞Ë¶èÂäÉÔºå‰ª£ÁêÜ‰∫∫ÂøÖÈ†àÂú®ÂØ¶Áî®ÊÄßËàáÂÆâÂÖ®ÈôêÂà∂‰πãÈñìÂèñÂæóÂπ≥Ë°°„ÄÇÂÆâÂÖ®ÁöÑË¶èÂäÉÂïèÈ°åÂèØ‰ª•Âª∫Ê®°ÁÇ∫ÂèóÊ©üÊúÉÁ¥ÑÊùüÁöÑÈÉ®ÂàÜÂèØËßÄÂØüÈ¶¨ÂèØÂ§´Ê±∫Á≠ñÈÅéÁ®ã (CC-POMDP)ÔºåËÄåËß£Ê±∫ÊñπÊ°àÈÄöÂ∏∏‰ΩøÁî®ÊòÇË≤¥ÁöÑÂ±ïÈñãÊàñÂïüÁôºÊ≥ï‰æÜ‰º∞Ë®àÊúÄ‰Ω≥ÂÄºÂíåÂãï‰ΩúÈÅ∏ÊìáÁ≠ñÁï•„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÂºïÂÖ•‰∫ÜÂèóÁ¥ÑÊùüÈõ∂Á≠ñÁï•ÂèçË¶ÜÈÅãÁÆóÊºîÁÆóÊ≥ïÔºåÂÆÉÈÄèÈÅéÂ≠∏ÁøíÊúÄ‰Ω≥ÂÄºÂíåÁ≠ñÁï•ÁöÑÁ•ûÁ∂ìÁ∂≤Ë∑ØËøë‰ººÂÄº‰æÜËß£Ê±∫‰ø°ÂøµÁ©∫Èñì‰∏≠ÁöÑ CC-POMDPÔºå‰∏¶‰ΩøÁî®È°çÂ§ñÁöÑÁ∂≤Ë∑ØÈ†≠‰æÜ‰º∞Ë®àÁµ¶ÂÆö‰ø°Âøµ‰∏ãÁöÑÂ§±ÊïóÊ©üÁéá„ÄÇÈÄôÂÄãÂ§±ÊïóÊ©üÁéáÊúÉÂú®Á∑ö‰∏äËíôÂú∞Âç°ÁæÖÊ®πÁãÄÊêúÂ∞ã (MCTS) ÊúüÈñìÂºïÂ∞éÂÆâÂÖ®ÁöÑÂãï‰ΩúÈÅ∏Êìá„ÄÇÁÇ∫‰∫ÜÈÅøÂÖçÈÅéÂ∫¶Âº∑Ë™øÂü∫ÊñºÂ§±Êïó‰º∞Ë®àÁöÑÊêúÂ∞ãÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü $\Delta$-MCTSÔºåÂÆÉ‰ΩøÁî®ÈÅ©ÊáâÊÄßÂÖ±ÂΩ¢Êé®Ë´ñÂú®Ë¶èÂäÉÊúüÈñìÊõ¥Êñ∞Â§±ÊïóÈñæÂÄº„ÄÇÈÄôÂÄãÊñπÊ≥ïÂú®‰∏ÄÂÄãÂÆâÂÖ®ÈóúÈçµÁöÑ POMDP Âü∫Ê∫ñ„ÄÅ‰∏ÄÂÄãÈ£õÊ©üÈò≤ÊíûÁ≥ªÁµ±ÂíåÂÆâÂÖ®ÁöÑ CO$_2$ ÂÑ≤Â≠òÊ∞∏Á∫åÊÄßÂïèÈ°å‰∏äÈÄ≤Ë°å‰∫ÜÊ∏¨Ë©¶„ÄÇÁµêÊûúÈ°ØÁ§∫ÔºåÈÄèÈÅéÂ∞áÂÆâÂÖ®ÈôêÂà∂ËàáÁõÆÊ®ôÂàÜÈñãÔºåÊàëÂÄëÂèØ‰ª•Âú®‰∏çÊúÄ‰Ω≥ÂåñÁçéÂãµËàáÊàêÊú¨‰πãÈñìÁöÑÂπ≥Ë°°‰∏ãÔºåÈÅîÊàêÁõÆÊ®ôÂÆâÂÖ®Á≠âÁ¥ö„ÄÇ

##### **When Quantization Affects Confidence of Large Language Models?**
2405.00632v1 by Irina Proskurina,Luc Brun,Guillaume Metzler,Julien Velcin

Recent studies introduced effective compression techniques for Large Language
Models (LLMs) via post-training quantization or low-bit weight representation.
Although quantized weights offer storage efficiency and allow for faster
inference, existing works have indicated that quantization might compromise
performance and exacerbate biases in LLMs. This study investigates the
confidence and calibration of quantized models, considering factors such as
language model type and scale as contributors to quantization loss. Firstly, we
reveal that quantization with GPTQ to 4-bit results in a decrease in confidence
regarding true labels, with varying impacts observed among different language
models. Secondly, we observe fluctuations in the impact on confidence across
different scales. Finally, we propose an explanation for quantization loss
based on confidence levels, indicating that quantization disproportionately
affects samples where the full model exhibited low confidence levels in the
first place.

ÊëòË¶ÅÔºöÊúÄËøëÁöÑÁ†îÁ©∂ÈÄèÈÅéË®ìÁ∑¥ÂæåÈáèÂåñÊàñ‰Ωé‰ΩçÂÖÉÊ¨äÈáçË°®Á§∫ÔºåÁÇ∫Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂºïÈÄ≤‰∫ÜÊúâÊïàÁöÑÂ£ìÁ∏ÆÊäÄË°ì„ÄÇÂÑòÁÆ°ÈáèÂåñÊ¨äÈáçÊèê‰æõ‰∫ÜÂÑ≤Â≠òÊïàÁéáÔºå‰∏¶ÂÖÅË®±Êõ¥Âø´ÁöÑÊé®Ë´ñÔºå‰ΩÜÁèæÊúâÁ†îÁ©∂Ë°®ÊòéÈáèÂåñÂèØËÉΩÊúÉÊêçÂÆ≥ LLM ÁöÑÊïàËÉΩ‰∏¶Âä†ÂäáÂÅèÂ∑Æ„ÄÇÊú¨Á†îÁ©∂Êé¢Ë®é‰∫ÜÈáèÂåñÊ®°ÂûãÁöÑ‰ø°ÂøÉÂíåÊ†°Ê∫ñÔºåËÄÉÊÖÆ‰∫ÜË™ûË®ÄÊ®°ÂûãÈ°ûÂûãÂíåË¶èÊ®°Á≠âÂõ†Á¥†‰ΩúÁÇ∫ÈáèÂåñÊêçÂ§±ÁöÑÂΩ±ÈüøÂõ†Á¥†„ÄÇÈ¶ñÂÖàÔºåÊàëÂÄëÊè≠Á§∫‰∫Ü‰ΩøÁî® GPTQ Â∞áÊ¨äÈáçÈáèÂåñÂà∞ 4 ‰ΩçÂÖÉÊúÉÂ∞éËá¥Â∞çÁúüÂØ¶Ê®ôÁ±§ÁöÑ‰ø°ÂøÉ‰∏ãÈôçÔºåÂú®‰∏çÂêåÁöÑË™ûË®ÄÊ®°Âûã‰∏≠ËßÄÂØüÂà∞ÁöÑÂΩ±ÈüøÂêÑ‰∏çÁõ∏Âêå„ÄÇÂÖ∂Ê¨°ÔºåÊàëÂÄëËßÄÂØüÂà∞‰∏çÂêåË¶èÊ®°Â∞ç‰ø°ÂøÉÂΩ±ÈüøÁöÑÊ≥¢Âãï„ÄÇÊúÄÂæåÔºåÊàëÂÄëÊ†πÊìö‰ø°ÂøÉÁ≠âÁ¥öÊèêÂá∫‰∫ÜÈáèÂåñÊêçÂ§±ÁöÑËß£ÈáãÔºåË°®ÊòéÈáèÂåñÂ∞çÂéüÊú¨ÂÆåÊï¥Ê®°ÂûãÂ±ïÁèæ‰Ωé‰ø°ÂøÉÁ≠âÁ¥öÁöÑÊ®£Êú¨Áî¢Áîü‰∫Ü‰∏çÊàêÊØî‰æãÁöÑÂΩ±Èüø„ÄÇ

##### **"I'm Not Sure, But...": Examining the Impact of Large Language Models' Uncertainty Expression on User Reliance and Trust**
2405.00623v1 by Sunnie S. Y. Kim,Q. Vera Liao,Mihaela Vorvoreanu,Stephanie Ballard,Jennifer Wortman Vaughan

Widely deployed large language models (LLMs) can produce convincing yet
incorrect outputs, potentially misleading users who may rely on them as if they
were correct. To reduce such overreliance, there have been calls for LLMs to
communicate their uncertainty to end users. However, there has been little
empirical work examining how users perceive and act upon LLMs' expressions of
uncertainty. We explore this question through a large-scale, pre-registered,
human-subject experiment (N=404) in which participants answer medical questions
with or without access to responses from a fictional LLM-infused search engine.
Using both behavioral and self-reported measures, we examine how different
natural language expressions of uncertainty impact participants' reliance,
trust, and overall task performance. We find that first-person expressions
(e.g., "I'm not sure, but...") decrease participants' confidence in the system
and tendency to agree with the system's answers, while increasing participants'
accuracy. An exploratory analysis suggests that this increase can be attributed
to reduced (but not fully eliminated) overreliance on incorrect answers. While
we observe similar effects for uncertainty expressed from a general perspective
(e.g., "It's not clear, but..."), these effects are weaker and not
statistically significant. Our findings suggest that using natural language
expressions of uncertainty may be an effective approach for reducing
overreliance on LLMs, but that the precise language used matters. This
highlights the importance of user testing before deploying LLMs at scale.

ÊëòË¶ÅÔºö<paragraph>Âª£Ê≥õÈÉ®ÁΩ≤ÁöÑÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂèØ‰ª•Áî¢Áîü‰ª§‰∫∫‰ø°Êúç‰ΩÜ
‰∏çÊ≠£Á¢∫ÁöÑËº∏Âá∫ÔºåÂèØËÉΩÊúÉË™§Â∞é‰æùË≥¥ÂÆÉÂÄëÁöÑ‰ΩøÁî®ËÄÖÔºåÂΩ∑ÂΩøÂÆÉÂÄëÊòØÊ≠£Á¢∫ÁöÑ„ÄÇÁÇ∫‰∫ÜÊ∏õÂ∞ëÈÄôÁ®ÆÈÅéÂ∫¶‰æùË≥¥ÔºåÊúâ‰∫∫ÂëºÁ±≤ LLM ÂêëÊúÄÁµÇ‰ΩøÁî®ËÄÖÂÇ≥ÈÅîÂÆÉÂÄëÁöÑ‰∏çÁ¢∫ÂÆöÊÄß„ÄÇÁÑ∂ËÄåÔºåÂæàÂ∞ëÊúâÂØ¶Ë≠âÁ†îÁ©∂Êé¢Ë®é‰ΩøÁî®ËÄÖÂ¶Ç‰ΩïÊÑüÁü•ÂíåÊ†πÊìö LLM ÁöÑ‰∏çÁ¢∫ÂÆöÊÄßË°®ÈÅîÊé°ÂèñË°åÂãï„ÄÇÊàëÂÄëÈÄèÈÅéÂ§ßË¶èÊ®°„ÄÅÈ†êÂÖàË®ªÂÜäÁöÑ‰∫∫È°ûÂèóË©¶ËÄÖÂØ¶È©ó (N=404) ‰æÜÊé¢Ë®éÈÄôÂÄãÂïèÈ°åÔºåÂÖ∂‰∏≠ÂèÉËàáËÄÖÂõûÁ≠îÈÜ´ÁôÇÂïèÈ°åÔºåËÄåÊúâÊàñÊ≤íÊúâÂ≠òÂèñËôõÊßãÁöÑ LLM Ê≥®ÂÖ•ÂºèÊêúÂ∞ãÂºïÊìéÁöÑÂõûÊáâ„ÄÇ
‰ΩøÁî®Ë°åÁÇ∫ÂíåËá™ÊàëÂ†±ÂëäÁöÑÊ∏¨ÈáèÔºåÊàëÂÄëÊé¢Ë®é‰∏çÂêåÁöÑËá™ÁÑ∂Ë™ûË®Ä‰∏çÁ¢∫ÂÆöÊÄßË°®ÈÅîÂ¶Ç‰ΩïÂΩ±ÈüøÂèÉËàáËÄÖÁöÑ‰æùË≥¥„ÄÅ
‰ø°‰ªªÂíåÊï¥È´î‰ªªÂãôË°®Áèæ„ÄÇÊàëÂÄëÁôºÁèæÁ¨¨‰∏Ä‰∫∫Á®±Ë°®ÈÅî
Ôºà‰æãÂ¶ÇÔºå„ÄåÊàë‰∏çÁ¢∫ÂÆöÔºå‰ΩÜ...„ÄçÔºâÈôç‰ΩéÂèÉËàáËÄÖÂ∞çÁ≥ªÁµ±ÁöÑ‰ø°ÂøÉÂíåÂêåÊÑèÁ≥ªÁµ±Á≠îÊ°àÁöÑÂÇæÂêëÔºåÂêåÊôÇÊèêÈ´òÂèÉËàáËÄÖÁöÑÊ∫ñÁ¢∫ÊÄß„ÄÇÊé¢Á¥¢ÊÄßÂàÜÊûêË°®ÊòéÔºåÈÄôÁ®ÆÂ¢ûÂä†ÂèØ‰ª•Ê≠∏Âõ†ÊñºÂ∞ç‰∏çÊ≠£Á¢∫Á≠îÊ°àÁöÑÈÅéÂ∫¶‰æùË≥¥Ê∏õÂ∞ëÔºà‰ΩÜ‰∏¶Êú™ÂÆåÂÖ®Ê∂àÈô§Ôºâ„ÄÇÈõñÁÑ∂ÊàëÂÄëËßÄÂØüÂà∞Âæû‰∏ÄËà¨ËßÄÈªûË°®ÈÅîÁöÑ‰∏çÁ¢∫ÂÆöÊÄßÔºà‰æãÂ¶ÇÔºå„ÄåÈÄô‰∏¶‰∏çÊ∏ÖÊ•öÔºå‰ΩÜ...„ÄçÔºâÊúâÈ°û‰ººÁöÑÂΩ±ÈüøÔºå‰ΩÜÈÄô‰∫õÂΩ±ÈüøËºÉÂº±‰∏îÊ≤íÊúâ
Áµ±Ë®àÈ°ØËëóÊÄß„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúË°®ÊòéÔºå‰ΩøÁî®Ëá™ÁÑ∂Ë™ûË®ÄÁöÑ‰∏çÁ¢∫ÂÆöÊÄßË°®ÈÅîÂèØËÉΩÊòØÊ∏õÂ∞ëÂ∞ç LLM ÈÅéÂ∫¶‰æùË≥¥ÁöÑÊúâÊïàÊñπÊ≥ïÔºå‰ΩÜ‰ΩøÁî®ÁöÑÁ≤æÁ¢∫Ë™ûË®ÄÂæàÈáçË¶Å„ÄÇÈÄôÁ™ÅÈ°Ø‰∫ÜÂú®Â§ßË¶èÊ®°ÈÉ®ÁΩ≤ LLM ‰πãÂâçÈÄ≤Ë°å‰ΩøÁî®ËÄÖÊ∏¨Ë©¶ÁöÑÈáçË¶ÅÊÄß„ÄÇ</paragraph>

