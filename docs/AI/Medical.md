
### Medical
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-12-20**|**Towards Interpretable Radiology Report Generation via Concept Bottlenecks using a Multi-Agentic RAG**|Hasan Md Tusfiqur Alam et.al.|[2412.16086v1](http://arxiv.org/abs/2412.16086v1)|[link](https://github.com/tifat58/irr-with-cbm-rag)|
|**2024-12-20**|**Applying Predictive Analytics to Occupational Health and Safety in India**|Ritwik Raj Saxena et.al.|[2412.16038v1](http://arxiv.org/abs/2412.16038v1)|null|
|**2024-12-20**|**Self-Supervised Radiograph Anatomical Region Classification -- How Clean Is Your Real-World Data?**|Simon Langer et.al.|[2412.15967v1](http://arxiv.org/abs/2412.15967v1)|null|
|**2024-12-20**|**From General to Specific: Tailoring Large Language Models for Personalized Healthcare**|Ruize Shi et.al.|[2412.15957v1](http://arxiv.org/abs/2412.15957v1)|null|
|**2024-12-20**|**Development of a Large-scale Dataset of Chest Computed Tomography Reports in Japanese and a High-performance Finding Classification Model**|Yosuke Yamagishi et.al.|[2412.15907v1](http://arxiv.org/abs/2412.15907v1)|null|
|**2024-12-20**|**Linguistic Features Extracted by GPT-4 Improve Alzheimer's Disease Detection based on Spontaneous Speech**|Jonathan Heitz et.al.|[2412.15772v1](http://arxiv.org/abs/2412.15772v1)|[link](https://github.com/jheitz/coling2025_gpt_paper)|
|**2024-12-20**|**Critique of Impure Reason: Unveiling the reasoning behaviour of medical Large Language Models**|Shamus Sim et.al.|[2412.15748v1](http://arxiv.org/abs/2412.15748v1)|null|
|**2024-12-20**|**NGQA: A Nutritional Graph Question Answering Benchmark for Personalized Health-aware Nutritional Reasoning**|Zheyuan Zhang et.al.|[2412.15547v1](http://arxiv.org/abs/2412.15547v1)|null|
|**2024-12-20**|**The First Multilingual Model For The Detection of Suicide Texts**|Rodolfo Zevallos et.al.|[2412.15498v1](http://arxiv.org/abs/2412.15498v1)|null|
|**2024-12-19**|**AI-Enhanced Sensemaking: Exploring the Design of a Generative AI-Based Assistant to Support Genetic Professionals**|Angela Mastrianni et.al.|[2412.15444v1](http://arxiv.org/abs/2412.15444v1)|null|
|**2024-12-19**|**GIRAFE: Glottal Imaging Dataset for Advanced Segmentation, Analysis, and Facilitative Playbacks Evaluation**|G. Andrade-Miranda et.al.|[2412.15054v1](http://arxiv.org/abs/2412.15054v1)|[link](https://github.com/andrade-miranda/girafe)|
|**2024-12-19**|**RobustFT: Robust Supervised Fine-tuning for Large Language Models under Noisy Response**|Junyu Luo et.al.|[2412.14922v1](http://arxiv.org/abs/2412.14922v1)|[link](https://github.com/luo-junyu/robustft)|
|**2024-12-19**|**Advances in Artificial Intelligence forDiabetes Prediction: Insights from a Systematic Literature Review**|Pir Bakhsh Khokhar et.al.|[2412.14736v1](http://arxiv.org/abs/2412.14736v1)|null|
|**2024-12-19**|**Pitfalls of topology-aware image segmentation**|Alexander H. Berger et.al.|[2412.14619v1](http://arxiv.org/abs/2412.14619v1)|[link](https://github.com/alexanderhberger/topo-pitfalls)|
|**2024-12-19**|**CAE-T: A Channelwise AutoEncoder with Transformer for EEG Abnormality Detection**|Youshen Zhao et.al.|[2412.14522v1](http://arxiv.org/abs/2412.14522v1)|[link](https://github.com/yossizhao/cae-t)|
|**2024-12-19**|**GenHMR: Generative Human Mesh Recovery**|Muhammad Usama Saleem et.al.|[2412.14444v1](http://arxiv.org/abs/2412.14444v1)|null|
|**2024-12-19**|**FedPIA -- Permuting and Integrating Adapters leveraging Wasserstein Barycenters for Finetuning Foundation Models in Multi-Modal Federated Learning**|Pramit Saha et.al.|[2412.14424v1](http://arxiv.org/abs/2412.14424v1)|null|
|**2024-12-18**|**Clinical Trials Ontology Engineering with Large Language Models**|Berkan Çakır et.al.|[2412.14387v1](http://arxiv.org/abs/2412.14387v1)|null|
|**2024-12-18**|**Multi-OphthaLingua: A Multilingual Benchmark for Assessing and Debiasing LLM Ophthalmological QA in LMICs**|David Restrepo et.al.|[2412.14304v1](http://arxiv.org/abs/2412.14304v1)|null|
|**2024-12-18**|**Discovering maximally consistent distribution of causal tournaments with Large Language Models**|Federico Baldo et.al.|[2412.14019v1](http://arxiv.org/abs/2412.14019v1)|null|
|**2024-12-18**|**SurgSora: Decoupled RGBD-Flow Diffusion Model for Controllable Surgical Video Generation**|Tong Chen et.al.|[2412.14018v1](http://arxiv.org/abs/2412.14018v1)|null|
|**2024-12-18**|**Cognition Chain for Explainable Psychological Stress Detection on Social Media**|Xin Wang et.al.|[2412.14009v1](http://arxiv.org/abs/2412.14009v1)|null|
|**2024-12-18**|**Federated Learning and RAG Integration: A Scalable Approach for Medical Large Language Models**|Jincheol Jung et.al.|[2412.13720v1](http://arxiv.org/abs/2412.13720v1)|null|
|**2024-12-18**|**Clio: Privacy-Preserving Insights into Real-World AI Use**|Alex Tamkin et.al.|[2412.13678v1](http://arxiv.org/abs/2412.13678v1)|null|
|**2024-12-18**|**Exploring Multi-Modal Integration with Tool-Augmented LLM Agents for Precise Causal Discovery**|ChengAo Shen et.al.|[2412.13667v1](http://arxiv.org/abs/2412.13667v1)|null|
|**2024-12-17**|**BadSAD: Clean-Label Backdoor Attacks against Deep Semi-Supervised Anomaly Detection**|He Cheng et.al.|[2412.13324v1](http://arxiv.org/abs/2412.13324v1)|null|
|**2024-12-17**|**In-context learning for medical image segmentation**|Eichi Takaya et.al.|[2412.13299v1](http://arxiv.org/abs/2412.13299v1)|null|
|**2024-12-17**|**Continuous Patient Monitoring with AI: Real-Time Analysis of Video in Hospital Care Settings**|Paolo Gabriel et.al.|[2412.13152v1](http://arxiv.org/abs/2412.13152v1)|[link](https://github.com/lookdeep/ai-norms-2024)|
|**2024-12-17**|**Boosting Fine-Grained Visual Anomaly Detection with Coarse-Knowledge-Aware Adversarial Learning**|Qingqing Fang et.al.|[2412.12850v1](http://arxiv.org/abs/2412.12850v1)|[link](https://github.com/Faustinaqq/CKAAD)|
|**2024-12-17**|**Rethinking Diffusion-Based Image Generators for Fundus Fluorescein Angiography Synthesis on Limited Data**|Chengzhou Yu et.al.|[2412.12778v1](http://arxiv.org/abs/2412.12778v1)|null|
|**2024-12-17**|**MedMax: Mixed-Modal Instruction Tuning for Training Biomedical Assistants**|Hritik Bansal et.al.|[2412.12661v1](http://arxiv.org/abs/2412.12661v1)|[link](https://github.com/Hritikbansal/medmax)|
|**2024-12-17**|**a2z-1 for Multi-Disease Detection in Abdomen-Pelvis CT: External Validation and Performance Analysis Across 21 Conditions**|Pranav Rajpurkar et.al.|[2412.12629v1](http://arxiv.org/abs/2412.12629v1)|null|
|**2024-12-17**|**A Scalable Approach to Benchmarking the In-Conversation Differential Diagnostic Accuracy of a Health AI**|Deep Bhatt et.al.|[2412.12538v1](http://arxiv.org/abs/2412.12538v1)|null|
|**2024-12-17**|**Addressing Small and Imbalanced Medical Image Datasets Using Generative Models: A Comparative Study of DDPM and PGGANs with Random and Greedy K Sampling**|Iman Khazrak et.al.|[2412.12532v1](http://arxiv.org/abs/2412.12532v1)|[link](https://github.com/imankhazrak/DDPM_X-Ray)|
|**2024-12-17**|**RareAgents: Autonomous Multi-disciplinary Team for Rare Disease Diagnosis and Treatment**|Xuanzhong Chen et.al.|[2412.12475v1](http://arxiv.org/abs/2412.12475v1)|null|
|**2024-12-17**|**ReXTrust: A Model for Fine-Grained Hallucination Detection in AI-Generated Radiology Reports**|Romain Hardy et.al.|[2412.15264v1](http://arxiv.org/abs/2412.15264v1)|null|
|**2024-12-16**|**Bridging the Gap: Enhancing LLM Performance for Low-Resource African Languages with New Benchmarks, Fine-Tuning, and Cultural Adjustments**|Tuka Alhanai et.al.|[2412.12417v1](http://arxiv.org/abs/2412.12417v1)|[link](https://github.com/InstituteforDiseaseModeling/Bridging-the-Gap-Low-Resource-African-Languages)|
|**2024-12-16**|**The Impact of AI Assistance on Radiology Reporting: A Pilot Study Using Simulated AI Draft Reports**|Julián N. Acosta et.al.|[2412.12042v1](http://arxiv.org/abs/2412.12042v1)|null|
|**2024-12-16**|**Combining Large Language Models with Tutoring System Intelligence: A Case Study in Caregiver Homework Support**|Devika Venugopalan et.al.|[2412.11995v1](http://arxiv.org/abs/2412.11995v1)|[link](https://github.com/devika-prog/caregiver-conversational-support-tool)|
|**2024-12-16**|**LLMs Can Simulate Standardized Patients via Agent Coevolution**|Zhuoyun Du et.al.|[2412.11716v1](http://arxiv.org/abs/2412.11716v1)|null|
|**2024-12-16**|**Fast-staged CNN Model for Accurate pulmonary diseases and Lung cancer detection**|Abdelbaki Souid et.al.|[2412.11681v1](http://arxiv.org/abs/2412.11681v1)|null|
|**2024-12-16**|**BioBridge: Unified Bio-Embedding with Bridging Modality in Code-Switched EMR**|Jangyeong Jeon et.al.|[2412.11671v1](http://arxiv.org/abs/2412.11671v1)|[link](https://github.com/jjy961228/biobridge)|
|**2024-12-16**|**Leveraging Foundation Language Models (FLMs) for Automated Cohort Extraction from Large EHR Databases**|Purity Mugambi et.al.|[2412.11472v1](http://arxiv.org/abs/2412.11472v1)|null|
|**2024-12-16**|**FedCAR: Cross-client Adaptive Re-weighting for Generative Models in Federated Learning**|Minjun Kim et.al.|[2412.11463v1](http://arxiv.org/abs/2412.11463v1)|[link](https://github.com/danny0628/fedcar)|
|**2024-12-16**|**ACE-$M^3$: Automatic Capability Evaluator for Multimodal Medical Models**|Xiechi Zhang et.al.|[2412.11453v1](http://arxiv.org/abs/2412.11453v1)|null|
|**2024-12-16**|**Structured Extraction of Real World Medical Knowledge using LLMs for Summarization and Search**|Edward Kim et.al.|[2412.15256v1](http://arxiv.org/abs/2412.15256v1)|null|
|**2024-12-15**|**Detecting Daily Living Gait Amid Huntington's Disease Chorea using a Foundation Deep Learning Model**|Dafna Schwartz et.al.|[2412.11286v1](http://arxiv.org/abs/2412.11286v1)|[link](https://github.com/dafnaschwartz/hd_gait_detection_with_ssl)|
|**2024-12-15**|**Wearable Accelerometer Foundation Models for Health via Knowledge Distillation**|Salar Abbaspourazad et.al.|[2412.11276v1](http://arxiv.org/abs/2412.11276v1)|null|
|**2024-12-15**|**TrimLLM: Progressive Layer Dropping for Domain-Specific LLMs**|Lanxiang Hu et.al.|[2412.11242v2](http://arxiv.org/abs/2412.11242v2)|null|
|**2024-12-15**|**Efficient Quantization-Aware Training on Segment Anything Model in Medical Images and Its Deployment**|Haisheng Lu et.al.|[2412.11186v1](http://arxiv.org/abs/2412.11186v1)|[link](https://github.com/avc2-uestc/qmedsam)|
|**2024-12-15**|**AD-LLM: Benchmarking Large Language Models for Anomaly Detection**|Tiankai Yang et.al.|[2412.11142v1](http://arxiv.org/abs/2412.11142v1)|[link](https://github.com/usc-fortis/ad-llm)|
|**2024-12-15**|**Decoding Drug Discovery: Exploring A-to-Z In silico Methods for Beginners**|Hezha O. Rasul et.al.|[2412.11137v1](http://arxiv.org/abs/2412.11137v1)|null|
|**2024-12-14**|**MedG-KRP: Medical Graph Knowledge Representation Probing**|Gabriel R. Rosenbaum et.al.|[2412.10982v2](http://arxiv.org/abs/2412.10982v2)|null|
|**2024-12-14**|**LLMs-in-the-Loop Part 2: Expert Small AI Models for Anonymization and De-identification of PHI Across Multiple Languages**|Murat Gunay et.al.|[2412.10918v1](http://arxiv.org/abs/2412.10918v1)|null|
|**2024-12-14**|**Superhuman performance of a large language model on the reasoning tasks of a physician**|Peter G. Brodeur et.al.|[2412.10849v1](http://arxiv.org/abs/2412.10849v1)|null|
|**2024-12-14**|**Large Language Models for Medical Forecasting -- Foresight 2**|Zeljko Kraljevic et.al.|[2412.10848v1](http://arxiv.org/abs/2412.10848v1)|null|
|**2024-12-14**|**Generative AI: A Pix2pix-GAN-Based Machine Learning Approach for Robust and Efficient Lung Segmentation**|Sharmin Akter et.al.|[2412.10826v1](http://arxiv.org/abs/2412.10826v1)|null|
|**2024-12-14**|**Medical Manifestation-Aware De-Identification**|Yuan Tian et.al.|[2412.10804v1](http://arxiv.org/abs/2412.10804v1)|[link](https://github.com/tianyuan168326/mema-pytorch)|
|**2024-12-14**|**Rapid Reconstruction of Extremely Accelerated Liver 4D MRI via Chained Iterative Refinement**|Di Xu et.al.|[2412.10629v1](http://arxiv.org/abs/2412.10629v1)|null|
|**2024-12-14**|**A recent evaluation on the performance of LLMs on radiation oncology physics using questions of randomly shuffled options**|Peilong Wang et.al.|[2412.10622v1](http://arxiv.org/abs/2412.10622v1)|null|
|**2024-12-13**|**Generative AI in Medicine**|Divya Shanmugam et.al.|[2412.10337v2](http://arxiv.org/abs/2412.10337v2)|null|
|**2024-12-13**|**A Cascaded Dilated Convolution Approach for Mpox Lesion Classification**|Ayush Deshmukh et.al.|[2412.10106v1](http://arxiv.org/abs/2412.10106v1)|null|
|**2024-12-13**|**Script-Based Dialog Policy Planning for LLM-Powered Conversational Agents: A Basic Architecture for an "AI Therapist"**|Robert Wasenmüller et.al.|[2412.15242v1](http://arxiv.org/abs/2412.15242v1)|null|
|**2024-12-13**|**Cycle-Consistent Bridge Diffusion Model for Accelerated MRI Reconstruction**|Tao Song et.al.|[2412.09998v1](http://arxiv.org/abs/2412.09998v1)|null|
|**2024-12-13**|**Enhancing Nursing and Elderly Care with Large Language Models: An AI-Driven Framework**|Qiao Sun et.al.|[2412.09946v1](http://arxiv.org/abs/2412.09946v1)|null|
|**2024-12-12**|**Detecting Cognitive Impairment and Psychological Well-being among Older Adults Using Facial, Acoustic, Linguistic, and Cardiovascular Patterns Derived from Remote Conversations**|Xiaofan Mu et.al.|[2412.14194v1](http://arxiv.org/abs/2412.14194v1)|null|
|**2024-12-12**|**Efficient and Comprehensive Feature Extraction in Large Vision-Language Model for Clinical Pathology Analysis**|Shengxuming Zhang et.al.|[2412.09521v1](http://arxiv.org/abs/2412.09521v1)|null|
|**2024-12-12**|**Towards a Multimodal Large Language Model with Pixel-Level Insight for Biomedicine**|Xiaoshuang Huang et.al.|[2412.09278v1](http://arxiv.org/abs/2412.09278v1)|[link](https://github.com/shawnhuang497/medplib)|
|**2024-12-12**|**CSSDH: An Ontology for Social Determinants of Health to Operational Continuity of Care Data Interoperability**|Subhashis Das et.al.|[2412.09223v1](http://arxiv.org/abs/2412.09223v1)|null|
|**2024-12-12**|**Understanding Opportunities and Risks of Synthetic Relationships: Leveraging the Power of Longitudinal Research with Customised AI Tools**|Alfio Ventura et.al.|[2412.09086v1](http://arxiv.org/abs/2412.09086v1)|null|
|**2024-12-12**|**An Interoperable Machine Learning Pipeline for Pediatric Obesity Risk Estimation**|Hamed Fayyaz et.al.|[2412.10454v1](http://arxiv.org/abs/2412.10454v1)|[link](https://github.com/healthylaife/fhir)|
|**2024-12-12**|**Structurally Consistent MRI Colorization using Cross-modal Fusion Learning**|Mayuri Mathur et.al.|[2412.10452v1](http://arxiv.org/abs/2412.10452v1)|null|
|**2024-12-12**|**CareBot: A Pioneering Full-Process Open-Source Medical Language Model**|Lulu Zhao et.al.|[2412.15236v1](http://arxiv.org/abs/2412.15236v1)|null|
|**2024-12-12**|**Radiology Report Generation via Multi-objective Preference Optimization**|Ting Xiao et.al.|[2412.08901v2](http://arxiv.org/abs/2412.08901v2)|null|
|**2024-12-12**|**AI-assisted Knowledge Discovery in Biomedical Literature to Support Decision-making in Precision Oncology**|Ting He et.al.|[2412.08900v1](http://arxiv.org/abs/2412.08900v1)|null|
|**2024-12-12**|**Towards modeling evolving longitudinal health trajectories with a transformer-based deep learning model**|Hans Moen et.al.|[2412.08873v1](http://arxiv.org/abs/2412.08873v1)|null|
|**2024-12-11**|**Performance of a large language model-Artificial Intelligence based chatbot for counseling patients with sexually transmitted infections and genital diseases**|Nikhil Mehta et.al.|[2412.12166v1](http://arxiv.org/abs/2412.12166v1)|null|
|**2024-12-11**|**Multimodal Approaches to Fair Image Classification: An Ethical Perspective**|Javon Hickmon et.al.|[2412.12165v1](http://arxiv.org/abs/2412.12165v1)|null|
|**2024-12-11**|**Euclid: Supercharging Multimodal LLMs with Synthetic High-Fidelity Visual Descriptions**|Jiarui Zhang et.al.|[2412.08737v1](http://arxiv.org/abs/2412.08737v1)|null|
|**2024-12-11**|**Assisted morbidity coding: the SISCO.web use case for identifying the main diagnosis in Hospital Discharge Records**|Elena Cardillo et.al.|[2412.09651v1](http://arxiv.org/abs/2412.09651v1)|null|
|**2024-12-11**|**IRL for Restless Multi-Armed Bandits with Applications in Maternal and Child Health**|Gauri Jain et.al.|[2412.08463v1](http://arxiv.org/abs/2412.08463v1)|[link](https://github.com/gjain234/whirl)|
|**2024-12-11**|**Personalized Sleep Staging Leveraging Source-free Unsupervised Domain Adaptation**|Yangxuan Zhou et.al.|[2412.12159v1](http://arxiv.org/abs/2412.12159v1)|null|
|**2024-12-11**|**SmolTulu: Higher Learning Rate to Batch Size Ratios Can Lead to Better Reasoning in SLMs**|Sultan Alrashed et.al.|[2412.08347v1](http://arxiv.org/abs/2412.08347v1)|null|
|**2024-12-11**|**Novel 3D Binary Indexed Tree for Volume Computation of 3D Reconstructed Models from Volumetric Data**|Quoc-Bao Nguyen-Le et.al.|[2412.10441v1](http://arxiv.org/abs/2412.10441v1)|null|
|**2024-12-11**|**Hierarchical Classification for Automated Image Annotation of Coral Reef Benthic Structures**|Célia Blondin et.al.|[2412.08228v1](http://arxiv.org/abs/2412.08228v1)|[link](https://github.com/celia-bl/hierarchical_classifying_corals_dataset)|
|**2024-12-11**|**How to select slices for annotation to train best-performing deep learning segmentation models for cross-sectional medical images?**|Yixin Zhang et.al.|[2412.08081v1](http://arxiv.org/abs/2412.08081v1)|null|
|**2024-12-11**|**Can a MISL Fly? Analysis and Ingredients for Mutual Information Skill Learning**|Chongyi Zheng et.al.|[2412.08021v1](http://arxiv.org/abs/2412.08021v1)|[link](https://github.com/Princeton-RL/contrastive-successor-features)|
|**2024-12-10**|**From Lived Experience to Insight: Unpacking the Psychological Risks of Using AI Conversational Agents**|Mohit Chandra et.al.|[2412.07951v2](http://arxiv.org/abs/2412.07951v2)|null|
|**2024-12-10**|**How Should We Represent History in Interpretable Models of Clinical Policies?**|Anton Matsson et.al.|[2412.07895v1](http://arxiv.org/abs/2412.07895v1)|[link](https://github.com/Healthy-AI/inpole)|
|**2024-12-10**|**Towards Foundation-model-based Multiagent System to Accelerate AI for Social Impact**|Yunfan Zhao et.al.|[2412.07880v2](http://arxiv.org/abs/2412.07880v2)|null|
|**2024-12-10**|**Comparative Analysis of Deep Learning Approaches for Harmful Brain Activity Detection Using EEG**|Shivraj Singh Bhatti et.al.|[2412.07878v1](http://arxiv.org/abs/2412.07878v1)|null|
|**2024-12-10**|**Combining knowledge graphs and LLMs for hazardous chemical information management and reuse**|Marcos Da Silveira et.al.|[2412.09644v1](http://arxiv.org/abs/2412.09644v1)|null|
|**2024-12-10**|**Adapting to Non-Stationary Environments: Multi-Armed Bandit Enhanced Retrieval-Augmented Generation on Knowledge Graphs**|Xiaqiang Tang et.al.|[2412.07618v2](http://arxiv.org/abs/2412.07618v2)|[link](https://github.com/futureeeeee/dynamic-rag)|
|**2024-12-10**|**Scaling Sequential Recommendation Models with Transformers**|Pablo Zivic et.al.|[2412.07585v1](http://arxiv.org/abs/2412.07585v1)|[link](https://github.com/mercadolibre/srt)|
|**2024-12-10**|**Knowledge Graph Guided Evaluation of Abstention Techniques**|Kinshuk Vasisht et.al.|[2412.07430v1](http://arxiv.org/abs/2412.07430v1)|null|
|**2024-12-10**|**AutoPrep: Natural Language Question-Aware Data Preparation with a Multi-Agent Framework**|Meihao Fan et.al.|[2412.10422v1](http://arxiv.org/abs/2412.10422v1)|null|
|**2024-12-10**|**A Review of Challenges in Speech-based Conversational AI for Elderly Care**|Willemijn Klaassen et.al.|[2412.07388v1](http://arxiv.org/abs/2412.07388v1)|null|
|**2024-12-10**|**Enhanced MRI Representation via Cross-series Masking**|Churan Wang et.al.|[2412.07387v1](http://arxiv.org/abs/2412.07387v1)|null|
|**2024-12-10**|**On Evaluating the Durability of Safeguards for Open-Weight LLMs**|Xiangyu Qi et.al.|[2412.07097v1](http://arxiv.org/abs/2412.07097v1)|[link](https://github.com/ai-law-society-lab/evaluating-durable-safeguards)|
|**2024-12-09**|**Toward AI-Driven Digital Organism: Multiscale Foundation Models for Predicting, Simulating and Programming Biology at All Levels**|Le Song et.al.|[2412.06993v1](http://arxiv.org/abs/2412.06993v1)|[link](https://github.com/genbio-ai/aido)|

#### Abstracts
##### **Towards Interpretable Radiology Report Generation via Concept Bottlenecks using a Multi-Agentic RAG**
2412.16086v1 by Hasan Md Tusfiqur Alam, Devansh Srivastav, Md Abdul Kadir, Daniel Sonntag

Deep learning has advanced medical image classification, but interpretability
challenges hinder its clinical adoption. This study enhances interpretability
in Chest X-ray (CXR) classification by using concept bottleneck models (CBMs)
and a multi-agent Retrieval-Augmented Generation (RAG) system for report
generation. By modeling relationships between visual features and clinical
concepts, we create interpretable concept vectors that guide a multi-agent RAG
system to generate radiology reports, enhancing clinical relevance,
explainability, and transparency. Evaluation of the generated reports using an
LLM-as-a-judge confirmed the interpretability and clinical utility of our
model's outputs. On the COVID-QU dataset, our model achieved 81% classification
accuracy and demonstrated robust report generation performance, with five key
metrics ranging between 84% and 90%. This interpretable multi-agent framework
bridges the gap between high-performance AI and the explainability required for
reliable AI-driven CXR analysis in clinical settings.

摘要：深度學習已進步了醫學影像分類，但可解釋性挑戰阻礙了其臨床採用。本研究透過使用概念瓶頸模型 (CBM) 和多重代理檢索增強生成 (RAG) 系統進行報告生成，增強了胸部 X 光 (CXR) 分類的可解釋性。透過對視覺特徵和臨床概念之間的關係進行建模，我們建立了可解釋的概念向量，用來引導多重代理 RAG 系統生成放射科報告，以增強臨床相關性、可解釋性和透明性。使用 LLM 作為判斷者對生成的報告進行評估，確認了我們模型輸出的可解釋性和臨床實用性。在 COVID-QU 資料集上，我們的模型達到了 81% 的分類準確度，並展示了強健的報告生成效能，五項關鍵指標介於 84% 到 90% 之間。這個可解釋的多重代理架構彌合了高性能 AI 與在臨床環境中進行可靠 AI 驅動 CXR 分析所需的可解釋性之間的差距。

##### **Applying Predictive Analytics to Occupational Health and Safety in India**
2412.16038v1 by Ritwik Raj Saxena

Predictive analytics is revolutionizing occupational health and safety (OHS).
It offers evidence-based insights. These insights enable proactive risk
management and informed, data-driven decision-making in organizational
settings. This paper explores the key components of predictive analytics in
OHS, beginning with data collection, management, and preparation, and moving
through to advanced predictive modelling techniques. We emphasize the
importance of data integrity through processes such as missing value
imputation, anomaly detection, and feature engineering to ensure accurate model
predictions. Risk prioritization identifies and ranks hazards across various
factors, including employee behaviours, organizational policies, environmental
conditions, and operational practices. We posit that insights derived from
predictive models must be effectively interpreted and implemented. These
insights guide organizations to focus on high-impact areas for accident
prevention and resource optimization. The integration of predictive analytics
in OHS brings notable benefits, including enhanced decision-making, greater
operational efficiency, cost savings, and improved compliance with safety
standards. We examine applications of predictive analytics in OHS in Indian
settings. India has the largest workforce in the world, and the predominance of
it is in the informal sector - a sector largely unprotected by the already
inadequate OHS laws. Ethical considerations, data privacy concerns, and the
risk of overdependence on predictive models are discussed. We conclude with a
discussion on the potential for predictive analytics to create a data-oriented,
adaptive approach to OHS in India. We posit that, using predictive analytics,
India can develop high safety standards while traversing the complexities of
its workforce setting.

摘要：預測分析正在革新職業健康與安全 (OHS)。
它提供基於證據的見解。這些見解能讓組織環境中的風險管理更具前瞻性，並能做出明智的、資料驅動的決策。本文探討了 OHS 中預測分析的關鍵組成部分，從資料收集、管理和準備開始，並進展到進階預測建模技術。我們強調資料完整性的重要性，透過遺失值插補、異常偵測和特徵工程等流程來確保準確的模型預測。風險優先順序會根據員工行為、組織政策、環境條件和作業慣例等各種因素來識別和排名危害。我們認為，從預測模型中得出的見解必須得到有效的詮釋和實施。這些見解引導組織專注於事故預防和資源最佳化的影響重大領域。預測分析在 OHS 中的整合帶來了顯著的優勢，包括增強決策制定、提高營運效率、節省成本和改善對安全標準的遵循。我們探討了預測分析在印度環境中 OHS 中的應用。印度擁有全球最大的勞動力，其中大部分屬於非正式部門，這個部門在很大程度上不受本已不足的 OHS 法律保護。本文討論了倫理考量、資料隱私問題和過度依賴預測模型的風險。我們最後討論了預測分析在印度創造以資料為導向、適應性強的 OHS 方法的潛力。我們認為，透過使用預測分析，印度可以在其勞動力環境的複雜性中發展出高安全標準。

##### **Self-Supervised Radiograph Anatomical Region Classification -- How Clean Is Your Real-World Data?**
2412.15967v1 by Simon Langer, Jessica Ritter, Rickmer Braren, Daniel Rueckert, Paul Hager

Modern deep learning-based clinical imaging workflows rely on accurate labels
of the examined anatomical region. Knowing the anatomical region is required to
select applicable downstream models and to effectively generate cohorts of high
quality data for future medical and machine learning research efforts. However,
this information may not be available in externally sourced data or generally
contain data entry errors. To address this problem, we show the effectiveness
of self-supervised methods such as SimCLR and BYOL as well as supervised
contrastive deep learning methods in assigning one of 14 anatomical region
classes in our in-house dataset of 48,434 skeletal radiographs. We achieve a
strong linear evaluation accuracy of 96.6% with a single model and 97.7% using
an ensemble approach. Furthermore, only a few labeled instances (1% of the
training set) suffice to achieve an accuracy of 92.2%, enabling usage in
low-label and thus low-resource scenarios. Our model can be used to correct
data entry mistakes: a follow-up analysis of the test set errors of our
best-performing single model by an expert radiologist identified 35% incorrect
labels and 11% out-of-domain images. When accounted for, the radiograph
anatomical region labelling performance increased -- without and with an
ensemble, respectively -- to a theoretical accuracy of 98.0% and 98.8%.

摘要：現代的深度學習臨床影像工作流程依賴於檢查解剖區域的準確標籤。了解解剖區域是必要的，用於選擇適用的下游模型，並有效地為未來的醫療和機器學習研究工作生成高品質資料群組。然而，此資訊可能無法在外部來源的資料中取得，或通常包含資料輸入錯誤。為了解決這個問題，我們展示了自監督方法（例如 SimCLR 和 BYOL）以及監督對比深度學習方法在我們內部 48,434 張骨骼 X 光片的資料集中分配 14 個解剖區域類別之一的有效性。我們使用單一模型達到了 96.6% 的強線性評估準確度，並使用整體方法達到了 97.7%。此外，僅有少數標記實例（訓練組的 1%）就足以達到 92.2% 的準確度，這使得在標籤少且資源少的情況下使用成為可能。我們的模型可用於更正資料輸入錯誤：由專業放射科醫師對我們效能最佳的單一模型的測試組錯誤進行後續分析，識別出 35% 的錯誤標籤和 11% 的領域外影像。在考慮到的情況下，X 光片解剖區域標籤效能提高了（分別在沒有和有整體的情況下）達到 98.0% 和 98.8% 的理論準確度。

##### **From General to Specific: Tailoring Large Language Models for Personalized Healthcare**
2412.15957v1 by Ruize Shi, Hong Huang, Wei Zhou, Kehan Yin, Kai Zhao, Yun Zhao

The rapid development of large language models (LLMs) has transformed many
industries, including healthcare. However, previous medical LLMs have largely
focused on leveraging general medical knowledge to provide responses, without
accounting for patient variability and lacking true personalization at the
individual level. To address this, we propose a novel method called
personalized medical language model (PMLM), which explores and optimizes
personalized LLMs through recommendation systems and reinforcement learning
(RL). Specifically, by utilizing self-informed and peer-informed
personalization, PMLM captures changes in behaviors and preferences to design
initial personalized prompts tailored to individual needs. We further refine
these initial personalized prompts through RL, ultimately enhancing the
precision of LLM guidance. Notably, the personalized prompt are hard prompt,
which grants PMLM high adaptability and reusability, allowing it to directly
leverage high-quality proprietary LLMs. We evaluate PMLM using real-world
obstetrics and gynecology data, and the experimental results demonstrate that
PMLM achieves personalized responses, and it provides more refined and
individualized services, offering a potential way for personalized medical
LLMs.

摘要：大型語言模型 (LLM) 的快速發展已轉變許多產業，包括醫療保健。然而，先前的醫療 LLM 主要專注於利用一般醫療知識提供回應，並未考量病患的變異性，且缺乏個人層級的真正個人化。為了解決此問題，我們提出了一種稱為個人化醫療語言模型 (PMLM) 的新方法，透過推薦系統和強化學習 (RL) 來探索和最佳化個人化的 LLM。具體來說，PMLM 透過利用自我知情和同儕知情的個人化，擷取行為和偏好的變化，以設計符合個人需求的初始個人化提示。我們進一步透過 RL 調整這些初始個人化提示，最終提升 LLM 指導的精確度。值得注意的是，個人化提示是硬提示，這賦予 PMLM 高度的適應性和可重複使用性，使其能夠直接利用高品質的專有 LLM。我們使用真實世界的產科和婦科資料評估 PMLM，實驗結果顯示 PMLM 達到了個人化的回應，並提供了更精緻和個人化的服務，為個人化的醫療 LLM 提供了一種潛在的方法。

##### **Development of a Large-scale Dataset of Chest Computed Tomography Reports in Japanese and a High-performance Finding Classification Model**
2412.15907v1 by Yosuke Yamagishi, Yuta Nakamura, Tomohiro Kikuchi, Yuki Sonoda, Hiroshi Hirakawa, Shintaro Kano, Satoshi Nakamura, Shouhei Hanaoka, Takeharu Yoshikawa, Osamu Abe

Background: Recent advances in large language models highlight the need for
high-quality multilingual medical datasets. While Japan leads globally in CT
scanner deployment and utilization, the lack of large-scale Japanese radiology
datasets has hindered the development of specialized language models for
medical imaging analysis. Objective: To develop a comprehensive Japanese CT
report dataset through machine translation and establish a specialized language
model for structured finding classification. Additionally, to create a
rigorously validated evaluation dataset through expert radiologist review.
Methods: We translated the CT-RATE dataset (24,283 CT reports from 21,304
patients) into Japanese using GPT-4o mini. The training dataset consisted of
22,778 machine-translated reports, while the validation dataset included 150
radiologist-revised reports. We developed CT-BERT-JPN based on
"tohoku-nlp/bert-base-japanese-v3" architecture for extracting 18 structured
findings from Japanese radiology reports. Results: Translation metrics showed
strong performance with BLEU scores of 0.731 and 0.690, and ROUGE scores
ranging from 0.770 to 0.876 for Findings and from 0.748 to 0.857 for Impression
sections. CT-BERT-JPN demonstrated superior performance compared to GPT-4o in
11 out of 18 conditions, including lymphadenopathy (+14.2%), interlobular
septal thickening (+10.9%), and atelectasis (+7.4%). The model maintained F1
scores exceeding 0.95 in 14 out of 18 conditions and achieved perfect scores in
four conditions. Conclusions: Our study establishes a robust Japanese CT report
dataset and demonstrates the effectiveness of a specialized language model for
structured finding classification. The hybrid approach of machine translation
and expert validation enables the creation of large-scale medical datasets
while maintaining high quality.

摘要：背景：大型語言模型的最新進展凸顯了對高品質多語言醫療資料集的需求。日本在 CT 掃描儀的部署和使用方面處於全球領先地位，但缺乏大規模的日語放射科資料集阻礙了針對醫學影像分析的專門語言模型的開發。目標：透過機器翻譯開發一個全面的日語 CT 報告資料集，並建立一個專門的語言模型，用於結構化結果分類。此外，透過專家放射科醫師的審查，建立一個嚴格驗證的評估資料集。方法：我們使用 GPT-4o mini 將 CT-RATE 資料集（來自 21,304 名患者的 24,283 份 CT 報告）翻譯成日語。訓練資料集包含 22,778 份機器翻譯報告，而驗證資料集包含 150 份放射科醫師修改過的報告。我們基於「tohoku-nlp/bert-base-japanese-v3」架構開發了 CT-BERT-JPN，用於從日語放射科報告中提取 18 項結構化結果。結果：翻譯指標顯示強勁的表現，BLEU 分數為 0.731 和 0.690，而 ROUGE 分數從結果的 0.770 到 0.876，從印象部分的 0.748 到 0.857 不等。與 GPT-4o 相比，CT-BERT-JPN 在 18 種情況中的 11 種情況下表現出優異的表現，包括淋巴腺病變（+14.2%）、小葉間隔增厚（+10.9%）和肺不張（+7.4%）。該模型在 18 種情況中的 14 種情況下維持 F1 分數超過 0.95，並在四種情況下達到完美分數。結論：我們的研究建立了一個強大的日語 CT 報告資料集，並展示了一個專門的語言模型在結構化結果分類方面的有效性。機器翻譯和專家驗證的混合方法能夠建立大規模的醫療資料集，同時保持高品質。

##### **Linguistic Features Extracted by GPT-4 Improve Alzheimer's Disease Detection based on Spontaneous Speech**
2412.15772v1 by Jonathan Heitz, Gerold Schneider, Nicolas Langer

Alzheimer's Disease (AD) is a significant and growing public health concern.
Investigating alterations in speech and language patterns offers a promising
path towards cost-effective and non-invasive early detection of AD on a large
scale. Large language models (LLMs), such as GPT, have enabled powerful new
possibilities for semantic text analysis. In this study, we leverage GPT-4 to
extract five semantic features from transcripts of spontaneous patient speech.
The features capture known symptoms of AD, but they are difficult to quantify
effectively using traditional methods of computational linguistics. We
demonstrate the clinical significance of these features and further validate
one of them ("Word-Finding Difficulties") against a proxy measure and human
raters. When combined with established linguistic features and a Random Forest
classifier, the GPT-derived features significantly improve the detection of AD.
Our approach proves effective for both manually transcribed and automatically
generated transcripts, representing a novel and impactful use of recent
advancements in LLMs for AD speech analysis.

摘要：阿茲海默症 (AD) 是個重大的且持續增加的公共衛生問題。
調查言語和語言模式的變化提供了一個有前景的途徑，可以大規模地對 AD 進行經濟有效且非侵入性的早期偵測。大型語言模型 (LLM)，例如 GPT，已經為語義文字分析開啟了強大的新可能性。在這項研究中，我們利用 GPT-4 從自發性患者言語的轉錄中提取五個語義特徵。這些特徵捕捉了 AD 的已知症狀，但使用傳統的計算語言學方法很難有效地量化它們。我們展示了這些特徵的臨床意義，並進一步驗證了其中一個特徵（「詞彙尋找困難」）與代理測量和人類評分員的結果。當與既定的語言特徵和隨機森林分類器結合時，GPT 衍生的特徵顯著改善了 AD 的偵測。我們的做法證明了手動轉錄和自動產生的轉錄都是有效的，這代表了 LLM 在 AD 語言分析中最新進展的一種新穎且有影響力的應用。

##### **Critique of Impure Reason: Unveiling the reasoning behaviour of medical Large Language Models**
2412.15748v1 by Shamus Sim, Tyrone Chen

Background: Despite the current ubiquity of Large Language Models (LLMs)
across the medical domain, there is a surprising lack of studies which address
their reasoning behaviour. We emphasise the importance of understanding
reasoning behaviour as opposed to high-level prediction accuracies, since it is
equivalent to explainable AI (XAI) in this context. In particular, achieving
XAI in medical LLMs used in the clinical domain will have a significant impact
across the healthcare sector. Results: Therefore, we define the concept of
reasoning behaviour in the specific context of medical LLMs. We then categorise
and discuss the current state of the art of methods which evaluate reasoning
behaviour in medical LLMs. Finally, we propose theoretical frameworks which can
empower medical professionals or machine learning engineers to gain insight
into the low-level reasoning operations of these previously obscure models.
Conclusion: The subsequent increased transparency and trust in medical machine
learning models by clinicians as well as patients will accelerate the
integration, application as well as further development of medical AI for the
healthcare system as a whole

摘要：背景：儘管大型語言模型 (LLM) 目前在醫療領域無所不在，但令人驚訝的是，探討其推理行為的研究卻相當缺乏。我們強調了解推理行為而非高層級的預測準確度非常重要，因為在這種情況下，這等同於可解釋 AI (XAI)。尤其是在臨床領域中使用的醫療 LLM 中實現 XAI，將對整個醫療保健產業產生重大影響。結果：因此，我們在醫療 LLM 的特定背景下定義了推理行為的概念。接著我們分類並探討當前評估醫療 LLM 中推理行為的方法的最新技術。最後，我們提出理論架構，讓醫療專業人員或機器學習工程師得以深入了解這些先前模糊模型的低層級推理運算。結論：臨床醫生和患者對醫療機器學習模型的透明度和信任度隨之提升，將加速醫療 AI 在整個醫療保健系統中的整合、應用和進一步發展。

##### **NGQA: A Nutritional Graph Question Answering Benchmark for Personalized Health-aware Nutritional Reasoning**
2412.15547v1 by Zheyuan Zhang, Yiyang Li, Nhi Ha Lan Le, Zehong Wang, Tianyi Ma, Vincent Galassi, Keerthiram Murugesan, Nuno Moniz, Werner Geyer, Nitesh V Chawla, Chuxu Zhang, Yanfang Ye

Diet plays a critical role in human health, yet tailoring dietary reasoning
to individual health conditions remains a major challenge. Nutrition Question
Answering (QA) has emerged as a popular method for addressing this problem.
However, current research faces two critical limitations. On one hand, the
absence of datasets involving user-specific medical information severely limits
\textit{personalization}. This challenge is further compounded by the wide
variability in individual health needs. On the other hand, while large language
models (LLMs), a popular solution for this task, demonstrate strong reasoning
abilities, they struggle with the domain-specific complexities of personalized
healthy dietary reasoning, and existing benchmarks fail to capture these
challenges. To address these gaps, we introduce the Nutritional Graph Question
Answering (NGQA) benchmark, the first graph question answering dataset designed
for personalized nutritional health reasoning. NGQA leverages data from the
National Health and Nutrition Examination Survey (NHANES) and the Food and
Nutrient Database for Dietary Studies (FNDDS) to evaluate whether a food is
healthy for a specific user, supported by explanations of the key contributing
nutrients. The benchmark incorporates three question complexity settings and
evaluates reasoning across three downstream tasks. Extensive experiments with
LLM backbones and baseline models demonstrate that the NGQA benchmark
effectively challenges existing models. In sum, NGQA addresses a critical
real-world problem while advancing GraphQA research with a novel
domain-specific benchmark.

摘要：飲食在人類健康中扮演著至關重要的角色，然而根據個人健康狀況調整飲食推理仍然是一項重大的挑戰。營養問題問答 (QA) 已成為解決此問題的流行方法。不過，目前的研究面臨兩項重大的限制。一方面，缺乏包含使用者特定醫療資訊的資料集嚴重限制了「個人化」。這個挑戰進一步受到個人健康需求廣泛變異的影響。另一方面，雖然大型語言模型 (LLM) 是此任務的熱門解決方案，展示出強大的推理能力，但它們在個人化健康飲食推理的特定領域複雜性上仍有困難，而現有的基準也無法捕捉這些挑戰。為了解決這些差距，我們引入了營養圖表問答 (NGQA) 基準，這是第一個專為個人化營養健康推理設計的圖表問答資料集。NGQA 利用國家健康與營養檢查調查 (NHANES) 和飲食研究食物與營養資料庫 (FNDDS) 的資料，評估食物是否對特定使用者健康，並說明主要貢獻營養素。此基準納入了三個問題複雜度設定，並評估三個下游任務的推理。使用 LLM 主幹和基線模型進行的廣泛實驗證明，NGQA 基準有效挑戰了現有模型。總之，NGQA 解決了一個重大的現實世界問題，同時透過新穎的特定領域基準推動了 GraphQA 研究。

##### **The First Multilingual Model For The Detection of Suicide Texts**
2412.15498v1 by Rodolfo Zevallos, Annika Schoene, John E. Ortega

Suicidal ideation is a serious health problem affecting millions of people
worldwide. Social networks provide information about these mental health
problems through users' emotional expressions. We propose a multilingual model
leveraging transformer architectures like mBERT, XML-R, and mT5 to detect
suicidal text across posts in six languages - Spanish, English, German,
Catalan, Portuguese and Italian. A Spanish suicide ideation tweet dataset was
translated into five other languages using SeamlessM4T. Each model was
fine-tuned on this multilingual data and evaluated across classification
metrics. Results showed mT5 achieving the best performance overall with F1
scores above 85%, highlighting capabilities for cross-lingual transfer
learning. The English and Spanish translations also displayed high quality
based on perplexity. Our exploration underscores the importance of considering
linguistic diversity in developing automated multilingual tools to identify
suicidal risk. Limitations exist around semantic fidelity in translations and
ethical implications which provide guidance for future human-in-the-loop
evaluations.

摘要：自殺意念是一個嚴重的健康問題，影響全球數百萬人。社交網路透過使用者的情緒表達，提供這些心理健康問題的資訊。我們提出一個多語言模型，利用像 mBERT、XML-R 和 mT5 的轉換器架構，來偵測六種語言（西班牙文、英文、德文、加泰隆尼亞文、葡萄牙文和義大利文）貼文中具有自殺傾向的文字。一個西班牙文自殺意念推文資料集使用 SeamlessM4T 翻譯成其他五種語言。每個模型都針對這個多語言資料進行微調，並評估分類指標。結果顯示，mT5 在整體表現上達到最佳，F1 分數高於 85%，突顯跨語言轉移學習的能力。英文和西班牙文的翻譯也根據困惑度顯示出高品質。我們的探索強調在開發自動化多語言工具以識別自殺風險時，考慮語言多樣性的重要性。翻譯中的語義忠實度和倫理意涵存在限制，這些限制為未來的人類參與評估提供了指導。

##### **AI-Enhanced Sensemaking: Exploring the Design of a Generative AI-Based Assistant to Support Genetic Professionals**
2412.15444v1 by Angela Mastrianni, Hope Twede, Aleksandra Sarcevic, Jeremiah Wander, Christina Austin-Tse, Scott Saponas, Heidi Rehm, Ashley Mae Conard, Amanda K. Hall

Generative AI has the potential to transform knowledge work, but further
research is needed to understand how knowledge workers envision using and
interacting with generative AI. We investigate the development of generative AI
tools to support domain experts in knowledge work, examining task delegation
and the design of human-AI interactions. Our research focused on designing a
generative AI assistant to aid genetic professionals in analyzing whole genome
sequences (WGS) and other clinical data for rare disease diagnosis. Through
interviews with 17 genetics professionals, we identified current challenges in
WGS analysis. We then conducted co-design sessions with six genetics
professionals to determine tasks that could be supported by an AI assistant and
considerations for designing interactions with the AI assistant. From our
findings, we identified sensemaking as both a current challenge in WGS analysis
and a process that could be supported by AI. We contribute an understanding of
how domain experts envision interacting with generative AI in their knowledge
work, a detailed empirical study of WGS analysis, and three design
considerations for using generative AI to support domain experts in sensemaking
during knowledge work.
  CCS CONCEPTS: Human-centered computing, Human-computer interaction, Empirical
studies in HCI
  Additional Keywords and Phrases: whole genome sequencing, generative AI,
large language models, knowledge work, sensemaking, co-design, rare disease
  Contact Author: Angela Mastrianni (This work was done during the author's
internship at Microsoft Research)
  Ashley Mae Conard and Amanda K. Hall contributed equally

摘要：<paragraph>生成式 AI 有可能轉換知識工作，但需要進一步的研究來了解知識工作者如何設想使用和與生成式 AI 互動。我們研究了生成式 AI 工具的開發，以支援領域專家進行知識工作，探討任務委派和人機互動的設計。我們的研究重點在於設計一個生成式 AI 助理，以協助遺傳學專業人士分析全基因體序列 (WGS) 和其他臨床資料，以診斷罕見疾病。透過訪談 17 位遺傳學專業人士，我們找出 WGS 分析中的現有挑戰。然後，我們與六位遺傳學專業人士進行共同設計會議，以確定 AI 助理可以支援的任務，以及設計與 AI 助理互動的考量因素。根據我們的研究結果，我們將意義建構認定為 WGS 分析中的現有挑戰，以及 AI 可以支援的流程。我們有助於了解領域專家如何設想在知識工作中與生成式 AI 互動，WGS 分析的詳細實證研究，以及在知識工作中使用生成式 AI 支援領域專家進行意義建構的三個設計考量因素。
CCS 概念：以人為本的運算、人機互動、HCI 中的實證研究
其他關鍵字和詞組：全基因體定序、生成式 AI、大型語言模型、知識工作、意義建構、共同設計、罕見疾病
聯絡作者：Angela Mastrianni（這項工作是在作者於 Microsoft Research 實習期間完成的）
Ashley Mae Conard 和 Amanda K. Hall 貢獻相同</paragraph>

##### **GIRAFE: Glottal Imaging Dataset for Advanced Segmentation, Analysis, and Facilitative Playbacks Evaluation**
2412.15054v1 by G. Andrade-Miranda, K. Chatzipapas, J. D. Arias-Londoño, J. I. Godino-Llorente

The advances in the development of Facilitative Playbacks extracted from
High-Speed videoendoscopic sequences of the vocal folds are hindered by a
notable lack of publicly available datasets annotated with the semantic
segmentations corresponding to the area of the glottal gap. This fact also
limits the reproducibility and further exploration of existing research in this
field.
  To address this gap, GIRAFE is a data repository designed to facilitate the
development of advanced techniques for the semantic segmentation, analysis, and
fast evaluation of High-Speed videoendoscopic sequences of the vocal folds. The
repository includes 65 high-speed videoendoscopic recordings from a cohort of
50 patients (30 female, 20 male). The dataset comprises 15 recordings from
healthy controls, 26 from patients with diagnosed voice disorders, and 24 with
an unknown health condition. All of them were manually annotated by an expert,
including the masks corresponding to the semantic segmentation of the glottal
gap. The repository is also complemented with the automatic segmentation of the
glottal area using different state-of-the-art approaches.
  This data set has already supported several studies, which demonstrates its
usefulness for the development of new glottal gap segmentation algorithms from
High-Speed-Videoendoscopic sequences to improve or create new Facilitative
Playbacks. Despite these advances and others in the field, the broader
challenge of performing an accurate and completely automatic semantic
segmentation method of the glottal area remains open.

摘要：<paragraph>從高速聲門內視鏡序列中提取的促進性回放的發展進展受到明顯缺乏公開可用資料集的阻礙，這些資料集帶有與聲門間隙區域相應的語義分割註解。這個事實也限制了現有研究在此領域的可重現性和進一步探索。
  為了解決這個差距，GIRAFE 是旨在促進語義分割、分析和高速聲門內視鏡序列快速評估的先進技術開發的資料庫。這個資料庫包含來自 50 位患者（30 位女性，20 位男性）的 65 份高速聲門內視鏡錄音。該資料集包含 15 份來自健康對照組的錄音、26 份來自被診斷出患有聲音障礙的患者的錄音，以及 24 份來自健康狀況不明的患者的錄音。所有這些錄音都由專家手動註解，包括與聲門間隙語義分割相應的遮罩。該資料庫還使用不同的最先進方法補充了聲門區域的自動分割。
  此資料集已經支援多項研究，這證明了它對於從高速視頻內視鏡序列開發新的聲門間隙分割演算法以改善或建立新的促進性回放很有用。儘管在該領域取得了這些進展和其他進展，但執行準確且完全自動化的聲門區域語義分割方法的更廣泛挑戰仍然存在。</paragraph>

##### **RobustFT: Robust Supervised Fine-tuning for Large Language Models under Noisy Response**
2412.14922v1 by Junyu Luo, Xiao Luo, Kaize Ding, Jingyang Yuan, Zhiping Xiao, Ming Zhang

Supervised fine-tuning (SFT) plays a crucial role in adapting large language
models (LLMs) to specific domains or tasks. However, as demonstrated by
empirical experiments, the collected data inevitably contains noise in
practical applications, which poses significant challenges to model performance
on downstream tasks. Therefore, there is an urgent need for a noise-robust SFT
framework to enhance model capabilities in downstream tasks. To address this
challenge, we introduce a robust SFT framework (RobustFT) that performs noise
detection and relabeling on downstream task data. For noise identification, our
approach employs a multi-expert collaborative system with inference-enhanced
models to achieve superior noise detection. In the denoising phase, we utilize
a context-enhanced strategy, which incorporates the most relevant and confident
knowledge followed by careful assessment to generate reliable annotations.
Additionally, we introduce an effective data selection mechanism based on
response entropy, ensuring only high-quality samples are retained for
fine-tuning. Extensive experiments conducted on multiple LLMs across five
datasets demonstrate RobustFT's exceptional performance in noisy scenarios.

摘要：監督式微調（SFT）在將大型語言模型（LLM）適應到特定領域或任務中扮演著至關重要的角色。然而，正如經驗實驗所證明，在實際應用中收集到的資料不可避免地包含雜訊，這對下游任務的模型效能構成了重大挑戰。因此，迫切需要一個抗雜訊的 SFT 框架，以增強模型在下游任務中的能力。為了應對這一挑戰，我們引入了穩健的 SFT 框架（RobustFT），它對下游任務資料執行雜訊偵測和重新標記。對於雜訊識別，我們的方法採用多專家協作系統，並使用增強推論的模型來實現優異的雜訊偵測。在去雜訊階段，我們利用一種情境增強策略，它結合了最相關和最確信的知識，然後進行仔細評估以產生可靠的註解。此外，我們還引入了一種基於回應熵的有效資料選取機制，確保僅保留高品質的樣本進行微調。在五個資料集上對多個 LLM 進行的廣泛實驗證明了 RobustFT 在雜訊情境中的出色效能。

##### **Advances in Artificial Intelligence forDiabetes Prediction: Insights from a Systematic Literature Review**
2412.14736v1 by Pir Bakhsh Khokhar, Carmine Gravino, Fabio Palomba

This systematic review explores the use of machine learning (ML) in
predicting diabetes, focusing on datasets, algorithms, training methods, and
evaluation metrics. It examines datasets like the Singapore National Diabetic
Retinopathy Screening program, REPLACE-BG, National Health and Nutrition
Examination Survey, and Pima Indians Diabetes Database. The review assesses the
performance of ML algorithms like CNN, SVM, Logistic Regression, and XGBoost in
predicting diabetes outcomes. The study emphasizes the importance of
interdisciplinary collaboration and ethical considerations in ML-based diabetes
prediction models.

摘要：這項系統性回顧探討了機器學習 (ML) 在糖尿病預測中的應用，重點在於資料集、演算法、訓練方法和評估指標。它檢驗了資料集，例如新加坡國家糖尿病視網膜病變篩檢計畫、REPLACE-BG、國家健康與營養檢查調查和皮馬印第安人糖尿病資料庫。該回顧評估了 ML 演算法（例如 CNN、SVM、邏輯迴歸和 XGBoost）在預測糖尿病結果方面的表現。這項研究強調了跨領域合作和在基於 ML 的糖尿病預測模型中進行道德考量的重要性。

##### **Pitfalls of topology-aware image segmentation**
2412.14619v1 by Alexander H. Berger, Laurin Lux, Alexander Weers, Martin Menten, Daniel Rueckert, Johannes C. Paetzold

Topological correctness, i.e., the preservation of structural integrity and
specific characteristics of shape, is a fundamental requirement for medical
imaging tasks, such as neuron or vessel segmentation. Despite the recent surge
in topology-aware methods addressing this challenge, their real-world
applicability is hindered by flawed benchmarking practices. In this paper, we
identify critical pitfalls in model evaluation that include inadequate
connectivity choices, overlooked topological artifacts in ground truth
annotations, and inappropriate use of evaluation metrics. Through detailed
empirical analysis, we uncover these issues' profound impact on the evaluation
and ranking of segmentation methods. Drawing from our findings, we propose a
set of actionable recommendations to establish fair and robust evaluation
standards for topology-aware medical image segmentation methods.

摘要：拓撲正確性，即形狀結構完整性和特定特徵的保留，是醫學影像任務（例如神經元或血管分割）的基本要求。儘管最近解決此挑戰的拓撲感知方法激增，但其真實世界的適用性受到有缺陷的基準測試實務的阻礙。在本文中，我們確定了模型評估中的關鍵缺陷，包括不適當的連接選擇、基本事實標註中被忽略的拓撲人工製品，以及評估指標的不適當使用。透過詳細的經驗分析，我們揭示了這些問題對分割方法的評估和排名產生的深遠影響。根據我們的研究結果，我們提出了一組可行的建議，以建立公平且穩健的評估標準，用於拓撲感知醫學影像分割方法。

##### **CAE-T: A Channelwise AutoEncoder with Transformer for EEG Abnormality Detection**
2412.14522v1 by Youshen Zhao, Keiji Iramina

Electroencephalogram (EEG) signals are critical for detecting abnormal brain
activity, but their high dimensionality and complexity pose significant
challenges for effective analysis. In this paper, we propose CAE-T, a novel
framework that combines a channelwise CNN-based autoencoder with a single-head
transformer classifier for efficient EEG abnormality detection. The channelwise
autoencoder compresses raw EEG signals while preserving channel independence,
reducing computational costs and retaining biologically meaningful features.
The compressed representations are then fed into the transformer-based
classifier, which efficiently models long-term dependencies to distinguish
between normal and abnormal signals. Evaluated on the TUH Abnormal EEG Corpus,
the proposed model achieves 85.0% accuracy, 76.2% sensitivity, and 91.2%
specificity at the per-case level, outperforming baseline models such as
EEGNet, Deep4Conv, and FusionCNN. Furthermore, CAE-T requires only 202M FLOPs
and 2.9M parameters, making it significantly more efficient than
transformer-based alternatives. The framework retains interpretability through
its channelwise design, demonstrating great potential for future applications
in neuroscience research and clinical practice. The source code is available at
https://github.com/YossiZhao/CAE-T.

摘要：腦電圖 (EEG) 訊號對於偵測異常腦部活動至關重要，但其高維度和複雜性對有效分析構成重大挑戰。在本文中，我們提出 CAE-T，一個結合基於通道的 CNN 自動編碼器和單頭Transformer分類器的全新架構，用於高效的 EEG 異常偵測。基於通道的自動編碼器壓縮原始 EEG 訊號，同時保留通道獨立性，降低計算成本並保留生物學上有意義的特徵。壓縮後的表示接著被輸入到基於Transformer的分類器中，該分類器有效地建模長期依賴關係以區分正常和異常訊號。在 TUH 異常 EEG 語料庫上進行評估，所提出的模型在個案層級達到 85.0% 的準確度、76.2% 的敏感度和 91.2% 的特異性，優於 EEGNet、Deep4Conv 和 FusionCNN 等基線模型。此外，CAE-T 僅需要 202M FLOP 和 2.9M 參數，使其比基於Transformer的替代方案顯著更有效率。該架構透過其基於通道的設計保留了解釋性，展現出在神經科學研究和臨床實務中未來應用極大的潛力。原始程式碼可在 https://github.com/YossiZhao/CAE-T 取得。

##### **GenHMR: Generative Human Mesh Recovery**
2412.14444v1 by Muhammad Usama Saleem, Ekkasit Pinyoanuntapong, Pu Wang, Hongfei Xue, Srijan Das, Chen Chen

Human mesh recovery (HMR) is crucial in many computer vision applications;
from health to arts and entertainment. HMR from monocular images has
predominantly been addressed by deterministic methods that output a single
prediction for a given 2D image. However, HMR from a single image is an
ill-posed problem due to depth ambiguity and occlusions. Probabilistic methods
have attempted to address this by generating and fusing multiple plausible 3D
reconstructions, but their performance has often lagged behind deterministic
approaches. In this paper, we introduce GenHMR, a novel generative framework
that reformulates monocular HMR as an image-conditioned generative task,
explicitly modeling and mitigating uncertainties in the 2D-to-3D mapping
process. GenHMR comprises two key components: (1) a pose tokenizer to convert
3D human poses into a sequence of discrete tokens in a latent space, and (2) an
image-conditional masked transformer to learn the probabilistic distributions
of the pose tokens, conditioned on the input image prompt along with randomly
masked token sequence. During inference, the model samples from the learned
conditional distribution to iteratively decode high-confidence pose tokens,
thereby reducing 3D reconstruction uncertainties. To further refine the
reconstruction, a 2D pose-guided refinement technique is proposed to directly
fine-tune the decoded pose tokens in the latent space, which forces the
projected 3D body mesh to align with the 2D pose clues. Experiments on
benchmark datasets demonstrate that GenHMR significantly outperforms
state-of-the-art methods. Project website can be found at
https://m-usamasaleem.github.io/publication/GenHMR/GenHMR.html

摘要：人體網格重建（HMR）在許多電腦視覺應用中至關重要；
從健康到藝術和娛樂。單目影像的 HMR 主要由確定性方法解決，
該方法針對給定的 2D 影像輸出單一預測。然而，由於深度模糊和遮擋，
單一影像的 HMR 是個病態問題。機率方法嘗試透過產生和融合多個合理的 3D
重建來解決此問題，但其效能通常落後於確定性方法。在本文中，我們介紹
GenHMR，這是一個新穎的生成式架構，將單目 HMR 重新表述為一個影像條件生成任務，
明確建模和減輕 2D 到 3D 對應過程中的不確定性。GenHMR 包含兩個關鍵組成部分：
（1）姿勢標記化器，將 3D 人體姿勢轉換為潛在空間中的離散標記序列，以及
（2）影像條件遮罩轉換器，以輸入影像提示以及隨機遮罩標記序列為條件，
學習姿勢標記的機率分佈。在推論期間，模型從學習到的條件分佈中取樣，
以反覆解碼高置信度姿勢標記，從而減少 3D 重建的不確定性。為了進一步優化
重建，提出了一種 2D 姿勢引導的優化技術，以直接微調潛在空間中解碼的姿勢標記，
這迫使投影的 3D 身體網格與 2D 姿勢線索對齊。基準資料集上的實驗證明，
GenHMR 明顯優於最先進的方法。專案網站可以在
https://m-usamasaleem.github.io/publication/GenHMR/GenHMR.html 找到

##### **FedPIA -- Permuting and Integrating Adapters leveraging Wasserstein Barycenters for Finetuning Foundation Models in Multi-Modal Federated Learning**
2412.14424v1 by Pramit Saha, Divyanshu Mishra, Felix Wagner, Konstantinos Kamnitsas, J. Alison Noble

Large Vision-Language Models typically require large text and image datasets
for effective fine-tuning. However, collecting data from various sites,
especially in healthcare, is challenging due to strict privacy regulations. An
alternative is to fine-tune these models on end-user devices, such as in
medical clinics, without sending data to a server. These local clients
typically have limited computing power and small datasets, which are not enough
for fully fine-tuning large VLMs on their own. A naive solution to these
scenarios is to leverage parameter-efficient fine-tuning (PEFT) strategies and
apply federated learning (FL) algorithms to combine the learned adapter
weights, thereby respecting the resource limitations and data privacy. However,
this approach does not fully leverage the knowledge from multiple adapters
trained on diverse data distributions and for diverse tasks. The adapters are
adversely impacted by data heterogeneity and task heterogeneity across clients
resulting in suboptimal convergence. To this end, we propose a novel framework
called FedPIA that improves upon the naive combinations of FL and PEFT by
introducing Permutation and Integration of the local Adapters in the server and
global Adapters in the clients exploiting Wasserstein barycenters for improved
blending of client-specific and client-agnostic knowledge. This layerwise
permutation helps to bridge the gap in the parameter space of local and global
adapters before integration. We conduct over 2000 client-level experiments
utilizing 48 medical image datasets across five different medical
vision-language FL task settings encompassing visual question answering as well
as image and report-based multi-label disease detection. Our experiments
involving diverse client settings, ten different modalities, and two VLM
backbones demonstrate that FedPIA consistently outperforms the state-of-the-art
PEFT-FL baselines.

摘要：大型視覺語言模型通常需要大型文字和影像資料集才能進行有效的微調。然而，由於嚴格的隱私法規，從各種網站收集資料，特別是在醫療保健方面，是一項挑戰。另一種方法是在終端使用者裝置上微調這些模型，例如在醫療診所，而不將資料傳送至伺服器。這些本機用戶端通常具有受限的運算能力和小型資料集，不足以自行對大型 VLM 進行完全微調。針對這些場景的一個天真解決方案是利用參數有效微調 (PEFT) 策略，並套用聯邦學習 (FL) 演算法來結合學習到的適配器權重，從而尊重資源限制和資料隱私。然而，此方法並未充分利用從訓練於不同資料分佈和不同任務的多個適配器中獲得的知識。適配器受到客戶端間資料異質性和任務異質性的不利影響，導致次佳收斂。為此，我們提出了一個名為 FedPIA 的新架構，透過在伺服器中引入局部適配器的排列和整合，以及在客戶端中引入全球適配器，並利用 Wasserstein 重心來改善客戶端特定和客戶端不可知知識的混合，從而改進 FL 和 PEFT 的天真組合。這種逐層排列有助於在整合之前彌合局部和全球適配器參數空間的差距。我們利用 48 個醫學影像資料集在五個不同的醫學視覺語言 FL 任務設定中進行了 2000 多個客戶端層級實驗，包括視覺問題解答以及基於影像和報告的多標籤疾病檢測。我們涉及不同客戶端設定、十種不同模式和兩個 VLM 主幹的實驗表明，FedPIA 持續優於最先進的 PEFT-FL 基準。

##### **Clinical Trials Ontology Engineering with Large Language Models**
2412.14387v1 by Berkan Çakır

Managing clinical trial information is currently a significant challenge for
the medical industry, as traditional methods are both time-consuming and
costly. This paper proposes a simple yet effective methodology to extract and
integrate clinical trial data in a cost-effective and time-efficient manner.
Allowing the medical industry to stay up-to-date with medical developments.
Comparing time, cost, and quality of the ontologies created by humans, GPT3.5,
GPT4, and Llama3 (8b & 70b). Findings suggest that large language models (LLM)
are a viable option to automate this process both from a cost and time
perspective. This study underscores significant implications for medical
research where real-time data integration from clinical trials could become the
norm.

摘要：管理臨床試驗資訊目前是醫療產業的一項重大挑戰，因為傳統方法既耗時又昂貴。本文提出一個簡單但有效的方法，以經濟有效且省時的方式提取和整合臨床試驗資料。讓醫療產業能隨時掌握醫療發展。比較人類、GPT3.5、GPT4 和 Llama3（8b 和 70b）建立的本体的時間、成本和品質。研究結果表明，大型語言模型 (LLM) 是從成本和時間角度自動化此流程的可行選項。這項研究強調了對醫療研究的重要影響，其中臨床試驗的即時資料整合可能會成為常態。

##### **Multi-OphthaLingua: A Multilingual Benchmark for Assessing and Debiasing LLM Ophthalmological QA in LMICs**
2412.14304v1 by David Restrepo, Chenwei Wu, Zhengxu Tang, Zitao Shuai, Thao Nguyen Minh Phan, Jun-En Ding, Cong-Tinh Dao, Jack Gallifant, Robyn Gayle Dychiao, Jose Carlo Artiaga, André Hiroshi Bando, Carolina Pelegrini Barbosa Gracitelli, Vincenz Ferrer, Leo Anthony Celi, Danielle Bitterman, Michael G Morley, Luis Filipe Nakayama

Current ophthalmology clinical workflows are plagued by over-referrals, long
waits, and complex and heterogeneous medical records. Large language models
(LLMs) present a promising solution to automate various procedures such as
triaging, preliminary tests like visual acuity assessment, and report
summaries. However, LLMs have demonstrated significantly varied performance
across different languages in natural language question-answering tasks,
potentially exacerbating healthcare disparities in Low and Middle-Income
Countries (LMICs). This study introduces the first multilingual
ophthalmological question-answering benchmark with manually curated questions
parallel across languages, allowing for direct cross-lingual comparisons. Our
evaluation of 6 popular LLMs across 7 different languages reveals substantial
bias across different languages, highlighting risks for clinical deployment of
LLMs in LMICs. Existing debiasing methods such as Translation Chain-of-Thought
or Retrieval-augmented generation (RAG) by themselves fall short of closing
this performance gap, often failing to improve performance across all languages
and lacking specificity for the medical domain. To address this issue, We
propose CLARA (Cross-Lingual Reflective Agentic system), a novel inference time
de-biasing method leveraging retrieval augmented generation and
self-verification. Our approach not only improves performance across all
languages but also significantly reduces the multilingual bias gap,
facilitating equitable LLM application across the globe.

摘要：<paragraph>當前眼科臨床工作流程飽受過度轉診、漫長等待時間以及複雜且異質的醫療記錄所苦。大型語言模型 (LLM) 提供了一個有前景的解決方案，可自動化各種程序，例如分流、視力評估等初步測試和報告摘要。然而，LLM 已在自然語言問答任務中展現出跨不同語言的顯著差異效能，這可能會加劇低收入和中等收入國家 (LMIC) 的醫療保健差異。本研究引入了首個多語言眼科問答基準，其中包含手動策劃且跨語言平行的問題，允許直接進行跨語言比較。我們對 7 種不同語言中的 6 個熱門 LLM 進行評估，結果顯示不同語言之間存在顯著偏差，突顯出在 LMIC 中部署 LLM 的臨床風險。現有的去偏方法，例如翻譯思維鏈或檢索增強生成 (RAG)，本身無法縮小此效能差距，通常無法改善所有語言的效能，且缺乏針對醫療領域的專一性。為了解決此問題，我們提出 CLARA (跨語言反射代理系統)，這是一種新穎的推理時間去偏方法，利用檢索增強生成和自我驗證。我們的做法不僅改善了所有語言的效能，還顯著縮小了多語言偏見差距，促進了 LLM 在全球範圍內的公平應用。</paragraph>

##### **Discovering maximally consistent distribution of causal tournaments with Large Language Models**
2412.14019v1 by Federico Baldo, Simon Ferreira, Charles K. Assaad

Causal discovery is essential for understanding complex systems, yet
traditional methods often depend on strong, untestable assumptions, making the
process challenging. Large Language Models (LLMs) present a promising
alternative for extracting causal insights from text-based metadata, which
consolidates domain expertise. However, LLMs are prone to unreliability and
hallucinations, necessitating strategies that account for their limitations.
One such strategy involves leveraging a consistency measure to evaluate
reliability. Additionally, most text metadata does not clearly distinguish
direct causal relationships from indirect ones, further complicating the
inference of causal graphs. As a result, focusing on causal orderings, rather
than causal graphs, emerges as a more practical and robust approach. We propose
a novel method to derive a distribution of acyclic tournaments (representing
plausible causal orders) that maximizes a consistency score. Our approach
begins by computing pairwise consistency scores between variables, yielding a
cyclic tournament that aggregates these scores. From this structure, we
identify optimal acyclic tournaments compatible with the original tournament,
prioritizing those that maximize consistency across all configurations. We
tested our method on both classical and well-established bechmarks, as well as
real-world datasets from epidemiology and public health. Our results
demonstrate the effectiveness of our approach in recovering distributions
causal orders with minimal error.

摘要：因果發現對於理解複雜系統至關重要，但傳統方法通常依賴於強而不可測試的假設，這使得這個過程充滿挑戰。大型語言模型 (LLM) 提供了一個從基於文本的元數據中提取因果見解的有希望的替代方案，它整合了領域專業知識。然而，LLM 容易出現不可靠性和幻覺，這需要考慮其限制的策略。一種這樣的策略涉及利用一致性度量來評估可靠性。此外，大多數文本元數據並未清楚地區分直接因果關係和間接因果關係，這進一步複雜化了因果圖的推論。因此，專注於因果順序，而不是因果圖，成為一種更實用、更穩健的方法。我們提出了一種新方法來推導無環錦標賽的分布（表示合理的因果順序），這最大化了一致性分數。我們的做法首先計算變量之間成對的一致性分數，產生一個彙總這些分數的循環錦標賽。從這個結構中，我們識別出與原始錦標賽相容的最佳無環錦標賽，優先考慮那些在所有配置中最大化一致性的錦標賽。我們在經典且完善的基準以及來自流行病學和公共衛生的真實世界數據集上測試了我們的模型。我們的結果證明了我們的方法在以最小誤差恢復因果順序分布方面的有效性。

##### **SurgSora: Decoupled RGBD-Flow Diffusion Model for Controllable Surgical Video Generation**
2412.14018v1 by Tong Chen, Shuya Yang, Junyi Wang, Long Bai, Hongliang Ren, Luping Zhou

Medical video generation has transformative potential for enhancing surgical
understanding and pathology insights through precise and controllable visual
representations. However, current models face limitations in controllability
and authenticity. To bridge this gap, we propose SurgSora, a
motion-controllable surgical video generation framework that uses a single
input frame and user-controllable motion cues. SurgSora consists of three key
modules: the Dual Semantic Injector (DSI), which extracts object-relevant RGB
and depth features from the input frame and integrates them with segmentation
cues to capture detailed spatial features of complex anatomical structures; the
Decoupled Flow Mapper (DFM), which fuses optical flow with semantic-RGB-D
features at multiple scales to enhance temporal understanding and object
spatial dynamics; and the Trajectory Controller (TC), which allows users to
specify motion directions and estimates sparse optical flow, guiding the video
generation process. The fused features are used as conditions for a frozen
Stable Diffusion model to produce realistic, temporally coherent surgical
videos. Extensive evaluations demonstrate that SurgSora outperforms
state-of-the-art methods in controllability and authenticity, showing its
potential to advance surgical video generation for medical education, training,
and research.

摘要：醫療影片生成具有變革性的潛力，可透過精確且可控的視覺表現來增強手術理解和病理見解。然而，目前的模型在可控性和真實性方面面臨限制。為了彌合這個差距，我們提出了 SurgSora，一個動作可控的手術影片生成框架，使用單一輸入幀和使用者可控的動作提示。SurgSora 包含三個關鍵模組：雙語意注入器 (DSI)，它從輸入幀中提取與物件相關的 RGB 和深度特徵，並將其與分割提示整合，以擷取複雜解剖結構的詳細空間特徵；解耦流對應器 (DFM)，它在多個尺度上將光流與語意 RGB-D 特徵融合，以增強時間理解和物件空間動態；以及軌跡控制器 (TC)，它允許使用者指定動作方向並估計稀疏光流，引導影片生成過程。融合的特徵用作凍結的 Stable Diffusion 模型的條件，以產生逼真、時間連貫的手術影片。廣泛的評估表明，SurgSora 在可控性和真實性方面優於最先進的方法，顯示其在推進手術影片生成以用於醫學教育、培訓和研究方面的潛力。

##### **Cognition Chain for Explainable Psychological Stress Detection on Social Media**
2412.14009v1 by Xin Wang, Boyan Gao, Yi Dai, Lei Cao, Liang Zhao, Yibo Yang, David Clifton

Stress is a pervasive global health issue that can lead to severe mental
health problems. Early detection offers timely intervention and prevention of
stress-related disorders. The current early detection models perform "black
box" inference suffering from limited explainability and trust which blocks the
real-world clinical application. Thanks to the generative properties introduced
by the Large Language Models (LLMs), the decision and the prediction from such
models are semi-interpretable through the corresponding description. However,
the existing LLMs are mostly trained for general purposes without the guidance
of psychological cognitive theory. To this end, we first highlight the
importance of prior theory with the observation of performance boosted by the
chain-of-thoughts tailored for stress detection. This method termed Cognition
Chain explicates the generation of stress through a step-by-step cognitive
perspective based on cognitive appraisal theory with a progress pipeline:
Stimulus $\rightarrow$ Evaluation $\rightarrow$ Reaction $\rightarrow$ Stress
State, guiding LLMs to provide comprehensive reasoning explanations. We further
study the benefits brought by the proposed Cognition Chain format by utilising
it as a synthetic dataset generation template for LLMs instruction-tuning and
introduce CogInstruct, an instruction-tuning dataset for stress detection. This
dataset is developed using a three-stage self-reflective annotation pipeline
that enables LLMs to autonomously generate and refine instructional data. By
instruction-tuning Llama3 with CogInstruct, we develop CogLLM, an explainable
stress detection model. Evaluations demonstrate that CogLLM achieves
outstanding performance while enhancing explainability. Our work contributes a
novel approach by integrating cognitive theories into LLM reasoning processes,
offering a promising direction for future explainable AI research.

摘要：壓力是一個普遍的全球性健康問題，可能會導致嚴重的精神
健康問題。早期發現提供及時的干預和預防
壓力相關疾病。目前的早期發現模型執行「黑
盒子」推論，存在可解釋性和信任度有限的問題，阻礙了
現實世界的臨床應用。多虧了大型語言模型 (LLM) 引入的生成屬性，此類
模型的決策和預測通過對應描述具有半可解釋性。然而，
現有的 LLM 主要針對一般用途進行訓練，沒有心理認知理論的指導。為此，我們首先強調
先驗理論的重要性，並觀察到針對壓力檢測量身定制的思想鏈提升了性能。這種方法稱為認知
鏈通過基於認知評估理論的循序漸進的認知視角闡明了壓力的產生，並具有進度管道：
刺激 $\rightarrow$ 評估 $\rightarrow$ 反應 $\rightarrow$ 壓力
狀態，指導 LLM 提供全面的推理解釋。我們進一步
通過將其用作 LLM 指令調整的合成數據集生成模板來研究所提出的認知鏈格式帶來的優點，並介紹 CogInstruct，這是一個針對壓力檢測的指令調整數據集。這個
數據集是使用一個三階段的自省標註管道開發的，使 LLM 能夠自主生成和優化指令數據。通過
使用 CogInstruct 對 Llama3 進行指令調整，我們開發了 CogLLM，這是一個可解釋的
壓力檢測模型。評估表明，CogLLM 在提高可解釋性的同時實現了出色的性能。我們的研究通過將認知理論整合到 LLM 推理過程中，提出了一種新穎的方法，
為未來的可解釋人工智能研究提供了一個有希望的方向。

##### **Federated Learning and RAG Integration: A Scalable Approach for Medical Large Language Models**
2412.13720v1 by Jincheol Jung, Hongju Jeong, Eui-Nam Huh

This study analyzes the performance of domain-specific Large Language Models
(LLMs) for the medical field by integrating Retrieval-Augmented Generation
(RAG) systems within a federated learning framework. Leveraging the inherent
advantages of federated learning, such as preserving data privacy and enabling
distributed computation, this research explores the integration of RAG systems
with models trained under varying client configurations to optimize
performance. Experimental results demonstrate that the federated learning-based
models integrated with RAG systems consistently outperform their non-integrated
counterparts across all evaluation metrics. This study highlights the potential
of combining federated learning and RAG systems for developing domain-specific
LLMs in the medical field, providing a scalable and privacy-preserving solution
for enhancing text generation capabilities.

摘要：本研究透過在聯邦學習架構中整合檢索擴增生成 (RAG) 系統，分析特定領域的大語言模型 (LLM) 在醫療領域的表現。利用聯邦學習的內在優勢，例如維護資料隱私和啟用分散式運算，本研究探討將 RAG 系統與在不同客戶端組態下訓練的模型整合，以最佳化效能。實驗結果顯示，與 RAG 系統整合的基於聯邦學習的模型在所有評估指標上都持續優於未整合的對應模型。本研究強調在醫療領域結合聯邦學習和 RAG 系統以開發特定領域 LLM 的潛力，提供可擴充且維護隱私的解決方案，以增強文字生成能力。

##### **Clio: Privacy-Preserving Insights into Real-World AI Use**
2412.13678v1 by Alex Tamkin, Miles McCain, Kunal Handa, Esin Durmus, Liane Lovitt, Ankur Rathi, Saffron Huang, Alfred Mountfield, Jerry Hong, Stuart Ritchie, Michael Stern, Brian Clarke, Landon Goldberg, Theodore R. Sumers, Jared Mueller, William McEachen, Wes Mitchell, Shan Carter, Jack Clark, Jared Kaplan, Deep Ganguli

How are AI assistants being used in the real world? While model providers in
theory have a window into this impact via their users' data, both privacy
concerns and practical challenges have made analyzing this data difficult. To
address these issues, we present Clio (Claude insights and observations), a
privacy-preserving platform that uses AI assistants themselves to analyze and
surface aggregated usage patterns across millions of conversations, without the
need for human reviewers to read raw conversations. We validate this can be
done with a high degree of accuracy and privacy by conducting extensive
evaluations. We demonstrate Clio's usefulness in two broad ways. First, we
share insights about how models are being used in the real world from one
million Claude.ai Free and Pro conversations, ranging from providing advice on
hairstyles to providing guidance on Git operations and concepts. We also
identify the most common high-level use cases on Claude.ai (coding, writing,
and research tasks) as well as patterns that differ across languages (e.g.,
conversations in Japanese discuss elder care and aging populations at
higher-than-typical rates). Second, we use Clio to make our systems safer by
identifying coordinated attempts to abuse our systems, monitoring for unknown
unknowns during critical periods like launches of new capabilities or major
world events, and improving our existing monitoring systems. We also discuss
the limitations of our approach, as well as risks and ethical concerns. By
enabling analysis of real-world AI usage, Clio provides a scalable platform for
empirically grounded AI safety and governance.

摘要：人工智能助理在現實世界中如何使用？雖然理論上模型供應商可以透過使用者的資料了解這種影響，但隱私問題和實際挑戰都讓分析這些資料變得困難。為了解決這些問題，我們提出了 Clio（Claude 見解與觀察），一個隱私保護平台，它使用人工智能助理本身來分析並浮出數百萬次對話中的彙整使用模式，而不需要人類審查員閱讀原始對話。我們透過進行廣泛的評估，驗證這可以用高度準確和隱私來完成。我們以兩種廣泛的方式展示 Clio 的用途。首先，我們分享關於模型在現實世界中如何使用的一百萬個 Claude.ai 免費和專業對話的見解，範圍從提供髮型建議到提供有關 Git 操作和概念的指導。我們還找出 Claude.ai 上最常見的高階使用案例（編碼、寫作和研究任務），以及不同語言之間的模式差異（例如，日語對話討論老年照護和老齡化人口的比率高於一般）。其次，我們使用 Clio 透過找出協調濫用我們系統的嘗試、在啟動新功能或重大世界事件等關鍵時期監控未知的未知數，以及改善我們現有的監控系統，讓我們的系統更安全。我們也討論我們方法的限制，以及風險和道德問題。透過啟用對現實世界人工智能使用的分析，Clio 提供了一個可擴充的平台，用於以經驗為基礎的人工智能安全和治理。

##### **Exploring Multi-Modal Integration with Tool-Augmented LLM Agents for Precise Causal Discovery**
2412.13667v1 by ChengAo Shen, Zhengzhang Chen, Dongsheng Luo, Dongkuan Xu, Haifeng Chen, Jingchao Ni

Causal inference is an imperative foundation for decision-making across
domains, such as smart health, AI for drug discovery and AIOps. Traditional
statistical causal discovery methods, while well-established, predominantly
rely on observational data and often overlook the semantic cues inherent in
cause-and-effect relationships. The advent of Large Language Models (LLMs) has
ushered in an affordable way of leveraging the semantic cues for
knowledge-driven causal discovery, but the development of LLMs for causal
discovery lags behind other areas, particularly in the exploration of
multi-modality data. To bridge the gap, we introduce MATMCD, a multi-agent
system powered by tool-augmented LLMs. MATMCD has two key agents: a Data
Augmentation agent that retrieves and processes modality-augmented data, and a
Causal Constraint agent that integrates multi-modal data for knowledge-driven
inference. Delicate design of the inner-workings ensures successful cooperation
of the agents. Our empirical study across seven datasets suggests the
significant potential of multi-modality enhanced causal discovery.

摘要：因果推論是跨領域決策制定中的必要基礎，例如智慧醫療、用於藥物發現的人工智慧和 AIOps。傳統的統計因果發現方法雖然已經確立，但主要依賴於觀察資料，且常常忽略因果關係中固有的語意線索。大型語言模型 (LLM) 的出現，開啟了一種利用語意線索進行知識驅動因果發現的方法，但用於因果發現的 LLM 發展落後於其他領域，特別是在多模態資料的探索方面。為了彌補差距，我們引入了 MATMCD，這是一個由工具增強的 LLM 驅動的多主體系統。MATMCD 有兩個關鍵主體：一個資料擴充主體，用於擷取和處理模態擴充資料，以及一個因果約束主體，用於整合多模態資料進行知識驅動推論。內部運作的精細設計確保了主體之間的成功合作。我們對七個資料集的實證研究表明，多模態增強因果發現具有顯著的潛力。

##### **BadSAD: Clean-Label Backdoor Attacks against Deep Semi-Supervised Anomaly Detection**
2412.13324v1 by He Cheng, Depeng Xu, Shuhan Yuan

Image anomaly detection (IAD) is essential in applications such as industrial
inspection, medical imaging, and security. Despite the progress achieved with
deep learning models like Deep Semi-Supervised Anomaly Detection (DeepSAD),
these models remain susceptible to backdoor attacks, presenting significant
security challenges. In this paper, we introduce BadSAD, a novel backdoor
attack framework specifically designed to target DeepSAD models. Our approach
involves two key phases: trigger injection, where subtle triggers are embedded
into normal images, and latent space manipulation, which positions and clusters
the poisoned images near normal images to make the triggers appear benign.
Extensive experiments on benchmark datasets validate the effectiveness of our
attack strategy, highlighting the severe risks that backdoor attacks pose to
deep learning-based anomaly detection systems.

摘要：影像異常偵測（IAD）在工業檢查、醫療影像和安全等應用中至關重要。儘管深度學習模型（如深度半監督異常偵測（DeepSAD））已取得進展，但這些模型仍然容易受到後門攻擊，造成重大的安全挑戰。在本文中，我們介紹 BadSAD，一個專門針對 DeepSAD 模型設計的新型後門攻擊架構。我們的做法包含兩個關鍵階段：觸發注入，其中將細微觸發嵌入到正常影像中，以及潛在空間操作，將中毒影像定位並群集在正常影像附近，以使觸發看起來是良性的。在基準資料集上進行的廣泛實驗驗證了我們攻擊策略的有效性，突顯了後門攻擊對基於深度學習的異常偵測系統造成的嚴重風險。

##### **In-context learning for medical image segmentation**
2412.13299v1 by Eichi Takaya, Shinnosuke Yamamoto

Annotation of medical images, such as MRI and CT scans, is crucial for
evaluating treatment efficacy and planning radiotherapy. However, the extensive
workload of medical professionals limits their ability to annotate large image
datasets, posing a bottleneck for AI applications in medical imaging. To
address this, we propose In-context Cascade Segmentation (ICS), a novel method
that minimizes annotation requirements while achieving high segmentation
accuracy for sequential medical images. ICS builds on the UniverSeg framework,
which performs few-shot segmentation using support images without additional
training. By iteratively adding the inference results of each slice to the
support set, ICS propagates information forward and backward through the
sequence, ensuring inter-slice consistency. We evaluate the proposed method on
the HVSMR dataset, which includes segmentation tasks for eight cardiac regions.
Experimental results demonstrate that ICS significantly improves segmentation
performance in complex anatomical regions, particularly in maintaining boundary
consistency across slices, compared to baseline methods. The study also
highlights the impact of the number and position of initial support slices on
segmentation accuracy. ICS offers a promising solution for reducing annotation
burdens while delivering robust segmentation results, paving the way for its
broader adoption in clinical and research applications.

摘要：醫學影像的註解，例如 MRI 和 CT 掃描，對於評估治療效果和規劃放射治療至關重要。然而，醫護人員龐大的工作量限制了他們註解大型影像資料集的能力，對醫學影像中的 AI 應用構成瓶頸。為了解決這個問題，我們提出情境串聯分割 (ICS)，這是一種新方法，可最大程度減少註解需求，同時為順序醫學影像實現高分割準確度。ICS 建立在 UniverSeg 架構之上，該架構使用支援影像執行少量分割，而無需額外訓練。透過反覆將每個切片的推論結果新增到支援集，ICS 透過序列向前和向後傳播資訊，確保切片間的一致性。我們在 HVSMR 資料集上評估所提出的方法，其中包括八個心臟區域的分割任務。實驗結果表明，與基準方法相比，ICS 在複雜的解剖區域顯著改善了分割效能，特別是在維護切片間的邊界一致性方面。該研究還強調了初始支援切片的數量和位置對分割準確度的影響。ICS 提供了一個有希望的解決方案，可以在提供穩健的分割結果的同時減少註解負擔，為其在臨床和研究應用中的更廣泛採用鋪平道路。

##### **Continuous Patient Monitoring with AI: Real-Time Analysis of Video in Hospital Care Settings**
2412.13152v1 by Paolo Gabriel, Peter Rehani, Tyler Troy, Tiffany Wyatt, Michael Choma, Narinder Singh

This study introduces an AI-driven platform for continuous and passive
patient monitoring in hospital settings, developed by LookDeep Health.
Leveraging advanced computer vision, the platform provides real-time insights
into patient behavior and interactions through video analysis, securely storing
inference results in the cloud for retrospective evaluation. The dataset,
compiled in collaboration with 11 hospital partners, encompasses over 300
high-risk fall patients and over 1,000 days of inference, enabling applications
such as fall detection and safety monitoring for vulnerable patient
populations. To foster innovation and reproducibility, an anonymized subset of
this dataset is publicly available. The AI system detects key components in
hospital rooms, including individual presence and role, furniture location,
motion magnitude, and boundary crossings. Performance evaluation demonstrates
strong accuracy in object detection (macro F1-score = 0.92) and patient-role
classification (F1-score = 0.98), as well as reliable trend analysis for the
"patient alone" metric (mean logistic regression accuracy = 0.82 \pm 0.15).
These capabilities enable automated detection of patient isolation, wandering,
or unsupervised movement-key indicators for fall risk and other adverse events.
This work establishes benchmarks for validating AI-driven patient monitoring
systems, highlighting the platform's potential to enhance patient safety and
care by providing continuous, data-driven insights into patient behavior and
interactions.

摘要：本研究介紹了一個由 LookDeep Health 開發的 AI 驅動平台，用於在醫院環境中持續且被動地監控患者。該平台利用先進的電腦視覺技術，透過影片分析提供患者行為和互動的即時見解，並將推論結果安全地儲存在雲端以供回顧性評估。該資料集與 11 家合作醫院共同編制，包含 300 多名高風險跌倒患者和 1,000 多天的推論，適用於跌倒偵測和脆弱患者族群的安全監控等應用。為了促進創新和可複製性，這份資料集的匿名子集已公開提供。AI 系統會偵測醫院房間中的關鍵組成部分，包括個人存在和角色、家具位置、動作幅度和邊界穿越。效能評估顯示物件偵測（巨觀 F1 分數 = 0.92）和患者角色分類（F1 分數 = 0.98）具有很高的準確性，以及「患者獨自一人」指標的可靠趨勢分析（平均邏輯迴歸準確性 = 0.82 ± 0.15）。這些功能可自動偵測患者隔離、遊走或無監督的移動，這些都是跌倒風險和其他不良事件的關鍵指標。這項工作為驗證 AI 驅動的患者監控系統建立了基準，突顯了該平台透過提供持續且資料驅動的患者行為和互動見解，增強患者安全和照護的潛力。

##### **Boosting Fine-Grained Visual Anomaly Detection with Coarse-Knowledge-Aware Adversarial Learning**
2412.12850v1 by Qingqing Fang, Qinliang Su, Wenxi Lv, Wenchao Xu, Jianxing Yu

Many unsupervised visual anomaly detection methods train an auto-encoder to
reconstruct normal samples and then leverage the reconstruction error map to
detect and localize the anomalies. However, due to the powerful modeling and
generalization ability of neural networks, some anomalies can also be well
reconstructed, resulting in unsatisfactory detection and localization accuracy.
In this paper, a small coarsely-labeled anomaly dataset is first collected.
Then, a coarse-knowledge-aware adversarial learning method is developed to
align the distribution of reconstructed features with that of normal features.
The alignment can effectively suppress the auto-encoder's reconstruction
ability on anomalies and thus improve the detection accuracy. Considering that
anomalies often only occupy very small areas in anomalous images, a patch-level
adversarial learning strategy is further developed. Although no patch-level
anomalous information is available, we rigorously prove that by simply viewing
any patch features from anomalous images as anomalies, the proposed
knowledge-aware method can also align the distribution of reconstructed patch
features with the normal ones. Experimental results on four medical datasets
and two industrial datasets demonstrate the effectiveness of our method in
improving the detection and localization performance.

摘要：許多無監督視覺異常偵測方法會訓練自動編碼器來重建正常樣本，然後利用重建誤差圖來偵測和定位異常。然而，由於神經網路強大的建模和概化能力，一些異常也可以被良好地重建，導致不令人滿意的偵測和定位準確度。在本文中，首先收集了一個小型粗略標記的異常資料集。然後，開發了一個粗略知識感知對抗學習方法，以將重建特徵的分布與正常特徵的分布對齊。對齊可以有效地抑制自動編碼器對異常的重建能力，從而提高偵測準確度。考慮到異常通常只佔異常影像中很小的區域，進一步開發了區塊級對抗學習策略。儘管沒有區塊級異常資訊可用，但我們嚴格證明，只需將異常影像中的任何區塊特徵視為異常，所提出的知識感知方法也可以將重建區塊特徵的分布與正常特徵對齊。在四個醫學資料集和兩個工業資料集上的實驗結果證明了我們的方法在改善偵測和定位效能方面的有效性。

##### **Rethinking Diffusion-Based Image Generators for Fundus Fluorescein Angiography Synthesis on Limited Data**
2412.12778v1 by Chengzhou Yu, Huihui Fang, Hongqiu Wang, Ting Deng, Qing Du, Yanwu Xu, Weihua Yang

Fundus imaging is a critical tool in ophthalmology, with different imaging
modalities offering unique advantages. For instance, fundus fluorescein
angiography (FFA) can accurately identify eye diseases. However, traditional
invasive FFA involves the injection of sodium fluorescein, which can cause
discomfort and risks. Generating corresponding FFA images from non-invasive
fundus images holds significant practical value but also presents challenges.
First, limited datasets constrain the performance and effectiveness of models.
Second, previous studies have primarily focused on generating FFA for single
diseases or single modalities, often resulting in poor performance for patients
with various ophthalmic conditions. To address these issues, we propose a novel
latent diffusion model-based framework, Diffusion, which introduces a
fine-tuning protocol to overcome the challenge of limited medical data and
unleash the generative capabilities of diffusion models. Furthermore, we
designed a new approach to tackle the challenges of generating across different
modalities and disease types. On limited datasets, our framework achieves
state-of-the-art results compared to existing methods, offering significant
potential to enhance ophthalmic diagnostics and patient care. Our code will be
released soon to support further research in this field.

摘要：眼底成像技術是眼科中的一項重要工具，不同的成像方式各有優勢。例如，眼底螢光素血管攝影 (FFA) 可精準辨識眼部疾病。然而，傳統侵入式的 FFA 會注射螢光素鈉，可能會造成不適和風險。從非侵入式眼底影像中產生相對應的 FFA 影像具有重要的實用價值，但也存在挑戰。首先，有限的資料集會限制模型的效能和效果。其次，先前的研究主要集中在為單一疾病或單一方式產生 FFA，對於患有多種眼科疾病的患者，效能通常不佳。為了解決這些問題，我們提出一個新穎的潛在擴散模型架構，稱為 Diffusion，它引入一個微調協定，以克服醫療資料有限的挑戰，並釋放擴散模型的生成能力。此外，我們設計了一種新方法來應對跨不同方式和疾病類型生成影像的挑戰。在有限的資料集上，與現有方法相比，我們的架構達到了最先進的結果，為增強眼科診斷和患者照護提供了顯著的潛力。我們的程式碼將很快釋出，以支持此領域的進一步研究。

##### **MedMax: Mixed-Modal Instruction Tuning for Training Biomedical Assistants**
2412.12661v1 by Hritik Bansal, Daniel Israel, Siyan Zhao, Shufan Li, Tung Nguyen, Aditya Grover

Recent advancements in mixed-modal generative models have enabled flexible
integration of information across image-text content. These models have opened
new avenues for developing unified biomedical assistants capable of analyzing
biomedical images, answering complex questions about them, and predicting the
impact of medical procedures on a patient's health. However, existing resources
face challenges such as limited data availability, narrow domain coverage, and
restricted sources (e.g., medical papers). To address these gaps, we present
MedMax, the first large-scale multimodal biomedical instruction-tuning dataset
for mixed-modal foundation models. With 1.47 million instances, MedMax
encompasses a diverse range of tasks, including multimodal content generation
(interleaved image-text data), biomedical image captioning and generation,
visual chatting, and report understanding. These tasks span diverse medical
domains such as radiology and histopathology. Subsequently, we fine-tune a
mixed-modal foundation model on the MedMax dataset, achieving significant
performance improvements: a 26% gain over the Chameleon model and an 18.3%
improvement over GPT-4o across 12 downstream biomedical visual
question-answering tasks. Additionally, we introduce a unified evaluation suite
for biomedical tasks, providing a robust framework to guide the development of
next-generation mixed-modal biomedical AI assistants.

摘要：混合模式生成模型的最新进展使得跨图像文本内容灵活整合信息成为可能。这些模型为开发统一的生物医学助手开辟了新途径，这些助手能够分析生物医学图像、回答有关图像的复杂问题，并预测医疗程序对患者健康的影响。然而，现有资源面临着数据可用性有限、领域覆盖范围狭窄和来源受限（例如医学论文）等挑战。为了解决这些差距，我们提出了 MedMax，这是第一个用于混合模式基础模型的大规模多模态生物医学指令微调数据集。MedMax 拥有 147 万个实例，涵盖了各种任务，包括多模态内容生成（交错图像文本数据）、生物医学图像标题和生成、可视化聊天和报告理解。这些任务跨越了放射学和组织病理学等不同的医学领域。随后，我们在 MedMax 数据集上对混合模式基础模型进行微调，取得了显著的性能提升：在 12 个下游生物医学视觉问答任务中，比 Chameleon 模型提升了 26%，比 GPT-4o 提升了 18.3%。此外，我们还引入了用于生物医学任务的统一评估套件，为指导下一代混合模式生物医学 AI 助手的发展提供了稳健的框架。

##### **a2z-1 for Multi-Disease Detection in Abdomen-Pelvis CT: External Validation and Performance Analysis Across 21 Conditions**
2412.12629v1 by Pranav Rajpurkar, Julian N. Acosta, Siddhant Dogra, Jaehwan Jeong, Deepanshu Jindal, Michael Moritz, Samir Rajpurkar

We present a comprehensive evaluation of a2z-1, an artificial intelligence
(AI) model designed to analyze abdomen-pelvis CT scans for 21 time-sensitive
and actionable findings. Our study focuses on rigorous assessment of the
model's performance and generalizability. Large-scale retrospective analysis
demonstrates an average AUC of 0.931 across 21 conditions. External validation
across two distinct health systems confirms consistent performance (AUC 0.923),
establishing generalizability to different evaluation scenarios, with notable
performance in critical findings such as small bowel obstruction (AUC 0.958)
and acute pancreatitis (AUC 0.961). Subgroup analysis shows consistent accuracy
across patient sex, age groups, and varied imaging protocols, including
different slice thicknesses and contrast administration types. Comparison of
high-confidence model outputs to radiologist reports reveals instances where
a2z-1 identified overlooked findings, suggesting potential for quality
assurance applications.

摘要：我們提出 a2z-1 的全面評估，這是一個人工智慧 (AI) 模型，旨在分析腹部骨盆電腦斷層掃描，以找出 21 項時間敏感且可採取行動的發現。我們的研究重點在於嚴格評估模型的效能和概括性。大規模回顧性分析顯示，21 種疾病的平均 AUC 為 0.931。兩個不同醫療系統的外部驗證確認效能一致（AUC 0.923），建立了對不同評估情境的概括性，在小腸阻塞（AUC 0.958）和急性胰臟炎（AUC 0.961）等關鍵發現中表現出色。次群體分析顯示，在患者性別、年齡組和不同的影像協議（包括不同的切片厚度和對比劑施用類型）中，準確度一致。將高信賴度模型輸出與放射科醫師報告進行比較，揭示了 a2z-1 找出被忽略發現的範例，表示有潛力用於品質保證應用。

##### **A Scalable Approach to Benchmarking the In-Conversation Differential Diagnostic Accuracy of a Health AI**
2412.12538v1 by Deep Bhatt, Surya Ayyagari, Anuruddh Mishra

Diagnostic errors in healthcare persist as a critical challenge, with
increasing numbers of patients turning to online resources for health
information. While AI-powered healthcare chatbots show promise, there exists no
standardized and scalable framework for evaluating their diagnostic
capabilities. This study introduces a scalable benchmarking methodology for
assessing health AI systems and demonstrates its application through August, an
AI-driven conversational chatbot. Our methodology employs 400 validated
clinical vignettes across 14 medical specialties, using AI-powered patient
actors to simulate realistic clinical interactions. In systematic testing,
August achieved a top-one diagnostic accuracy of 81.8% (327/400 cases) and a
top-two accuracy of 85.0% (340/400 cases), significantly outperforming
traditional symptom checkers. The system demonstrated 95.8% accuracy in
specialist referrals and required 47% fewer questions compared to conventional
symptom checkers (mean 16 vs 29 questions), while maintaining empathetic
dialogue throughout consultations. These findings demonstrate the potential of
AI chatbots to enhance healthcare delivery, though implementation challenges
remain regarding real-world validation and integration of objective clinical
data. This research provides a reproducible framework for evaluating healthcare
AI systems, contributing to the responsible development and deployment of AI in
clinical settings.

摘要：醫療保健中的診斷錯誤持續成為一項重大挑戰，越來越多的患者求助於線上資源來取得健康資訊。儘管由人工智慧驅動的醫療保健聊天機器人展現出前景，但目前還沒有標準化且可擴充的架構來評估其診斷能力。本研究介紹了一種可擴充的基準測試方法，用於評估健康人工智慧系統，並透過由人工智慧驅動的對話式聊天機器人 August，展示其應用。我們的做法採用了 14 個醫療專科的 400 個已驗證臨床小故事，並使用由人工智慧驅動的患者角色模擬實際的臨床互動。在系統性測試中，August 達到了 81.8% 的前一項診斷準確度（327/400 個案例）和 85.0% 的前兩項準確度（340/400 個案例），顯著優於傳統的症狀檢查器。該系統在專科轉診方面表現出 95.8% 的準確度，並且與傳統症狀檢查器相比，所需的提問數量減少了 47%（平均 16 個問題，相較於 29 個問題），同時在諮詢過程中維持同理的對話。這些發現證明了人工智慧聊天機器人增強醫療保健服務的潛力，儘管在實際驗證和整合客觀臨床數據方面仍存在實作挑戰。本研究提供了一個可複製的架構，用於評估醫療保健人工智慧系統，有助於在臨床環境中負責任地開發和部署人工智慧。

##### **Addressing Small and Imbalanced Medical Image Datasets Using Generative Models: A Comparative Study of DDPM and PGGANs with Random and Greedy K Sampling**
2412.12532v1 by Iman Khazrak, Shakhnoza Takhirova, Mostafa M. Rezaee, Mehrdad Yadollahi, Robert C. Green II, Shuteng Niu

The development of accurate medical image classification models is often
constrained by privacy concerns and data scarcity for certain conditions,
leading to small and imbalanced datasets. To address these limitations, this
study explores the use of generative models, such as Denoising Diffusion
Probabilistic Models (DDPM) and Progressive Growing Generative Adversarial
Networks (PGGANs), for dataset augmentation. The research introduces a
framework to assess the impact of synthetic images generated by DDPM and PGGANs
on the performance of four models: a custom CNN, Untrained VGG16, Pretrained
VGG16, and Pretrained ResNet50. Experiments were conducted using Random
Sampling and Greedy K Sampling to create small, imbalanced datasets. The
synthetic images were evaluated using Frechet Inception Distance (FID) and
compared to original datasets through classification metrics. The results show
that DDPM consistently generated more realistic images with lower FID scores
and significantly outperformed PGGANs in improving classification metrics
across all models and datasets. Incorporating DDPM-generated images into the
original datasets increased accuracy by up to 6%, enhancing model robustness
and stability, particularly in imbalanced scenarios. Random Sampling
demonstrated superior stability, while Greedy K Sampling offered diversity at
the cost of higher FID scores. This study highlights the efficacy of DDPM in
augmenting small, imbalanced medical image datasets, improving model
performance by balancing the dataset and expanding its size.

摘要：<paragraph>準確醫療影像分類模型的開發常受限於隱私疑慮和特定狀況資料的稀缺，這導致資料集規模小且不平衡。為了解決這些限制，本研究探討生成模型，例如去噪擴散機率模型 (DDPM) 和漸進式生成對抗網路 (PGGAN)，用於資料集擴充。本研究引進一個架構，評估由 DDPM 和 PGGAN 生成的合成影像對四個模型效能的影響：自訂 CNN、Untrained VGG16、Pretrained VGG16 和 Pretrained ResNet50。實驗使用隨機取樣和貪婪 K 取樣進行，以建立小規模的不平衡資料集。合成影像使用 Fréchet 起始距離 (FID) 進行評估，並透過分類指標與原始資料集進行比較。結果顯示，DDPM 持續產生較逼真的影像，FID 分數較低，且在改善所有模型和資料集的分類指標方面，表現明顯優於 PGGAN。將 DDPM 生成的影像納入原始資料集，可將準確度提升多達 6%，增強模型的穩健性和穩定性，特別是在不平衡的情況下。隨機取樣展現出優異的穩定性，而貪婪 K 取樣則以較高的 FID 分數為代價，提供了多樣性。本研究強調 DDPM 在擴充小規模、不平衡醫療影像資料集方面的效能，透過平衡資料集和擴充其規模，改善模型效能。</paragraph>

##### **RareAgents: Autonomous Multi-disciplinary Team for Rare Disease Diagnosis and Treatment**
2412.12475v1 by Xuanzhong Chen, Ye Jin, Xiaohao Mao, Lun Wang, Shuyang Zhang, Ting Chen

Rare diseases, despite their low individual incidence, collectively impact
around 300 million people worldwide due to the huge number of diseases. The
complexity of symptoms and the shortage of specialized doctors with relevant
experience make diagnosing and treating rare diseases more challenging than
common diseases. Recently, agents powered by large language models (LLMs) have
demonstrated notable improvements across various domains. In the medical field,
some agent methods have outperformed direct prompts in question-answering tasks
from medical exams. However, current agent frameworks lack adaptation for
real-world clinical scenarios, especially those involving the intricate demands
of rare diseases. To address these challenges, we present RareAgents, the first
multi-disciplinary team of LLM-based agents tailored to the complex clinical
context of rare diseases. RareAgents integrates advanced planning capabilities,
memory mechanisms, and medical tools utilization, leveraging Llama-3.1-8B/70B
as the base model. Experimental results show that RareAgents surpasses
state-of-the-art domain-specific models, GPT-4o, and existing agent frameworks
in both differential diagnosis and medication recommendation for rare diseases.
Furthermore, we contribute a novel dataset, MIMIC-IV-Ext-Rare, derived from
MIMIC-IV, to support further advancements in this field.

摘要：儘管罕見疾病的個別發生率很低，但由於疾病數量龐大，在全球影響了約 3 億人。症狀的複雜性和相關經驗的專科醫生短缺，使得診斷和治療罕見疾病比常見疾病更具挑戰性。最近，由大型語言模型 (LLM) 驅動的代理已在各個領域展示出顯著的改進。在醫學領域，一些代理方法在醫學考試的問答任務中優於直接提示。然而，當前的代理架構缺乏適應現實世界的臨床場景，特別是那些涉及罕見疾病複雜需求的場景。為了應對這些挑戰，我們提出了 RareAgents，這是第一個針對罕見疾病複雜臨床背景量身打造的 LLM 為基礎的多學科代理團隊。RareAgents 整合了先進的規劃能力、記憶機制和醫療工具利用，利用 Llama-3.1-8B/70B 作為基礎模型。實驗結果表明，RareAgents 在罕見疾病的鑑別診斷和藥物推薦方面都超越了最先進的特定領域模型 GPT-4o 和現有的代理架構。此外，我們貢獻了一個新的數據集 MIMIC-IV-Ext-Rare，它來自 MIMIC-IV，以支持該領域的進一步發展。

##### **ReXTrust: A Model for Fine-Grained Hallucination Detection in AI-Generated Radiology Reports**
2412.15264v1 by Romain Hardy, Sung Eun Kim, Pranav Rajpurkar

The increasing adoption of AI-generated radiology reports necessitates robust
methods for detecting hallucinations--false or unfounded statements that could
impact patient care. We present ReXTrust, a novel framework for fine-grained
hallucination detection in AI-generated radiology reports. Our approach
leverages sequences of hidden states from large vision-language models to
produce finding-level hallucination risk scores. We evaluate ReXTrust on a
subset of the MIMIC-CXR dataset and demonstrate superior performance compared
to existing approaches, achieving an AUROC of 0.8751 across all findings and
0.8963 on clinically significant findings. Our results show that white-box
approaches leveraging model hidden states can provide reliable hallucination
detection for medical AI systems, potentially improving the safety and
reliability of automated radiology reporting.

摘要：隨著 AI 生成的放射科報告採用率的提升，需要有穩健的方法來偵測幻覺，也就是可能會影響患者照護的虛假或不實的陳述。我們提出 ReXTrust，一個用於偵測 AI 生成的放射科報告中精細幻覺的新框架。我們的做法利用大型視覺語言模型中隱藏狀態的序列，以產生發現層級的幻覺風險評分。我們在 MIMIC-CXR 資料集的子集上評估 ReXTrust，並展示出比現有方法更好的效能，在所有發現中達到 0.8751 的 AUROC，在臨床上重要的發現中達到 0.8963。我們的結果顯示，利用模型隱藏狀態的白盒方法可以為醫療 AI 系統提供可靠的幻覺偵測，進而潛在地改善自動化放射科報告的安全性及可靠性。

##### **Bridging the Gap: Enhancing LLM Performance for Low-Resource African Languages with New Benchmarks, Fine-Tuning, and Cultural Adjustments**
2412.12417v1 by Tuka Alhanai, Adam Kasumovic, Mohammad Ghassemi, Aven Zitzelberger, Jessica Lundin, Guillaume Chabot-Couture

Large Language Models (LLMs) have shown remarkable performance across various
tasks, yet significant disparities remain for non-English languages, and
especially native African languages. This paper addresses these disparities by
creating approximately 1 million human-translated words of new benchmark data
in 8 low-resource African languages, covering a population of over 160 million
speakers of: Amharic, Bambara, Igbo, Sepedi (Northern Sotho), Shona, Sesotho
(Southern Sotho), Setswana, and Tsonga. Our benchmarks are translations of
Winogrande and three sections of MMLU: college medicine, clinical knowledge,
and virology. Using the translated benchmarks, we report previously unknown
performance gaps between state-of-the-art (SOTA) LLMs in English and African
languages. Finally, using results from over 400 fine-tuned models, we explore
several methods to reduce the LLM performance gap, including high-quality
dataset fine-tuning (using an LLM-as-an-Annotator), cross-lingual transfer, and
cultural appropriateness adjustments. Key findings include average mono-lingual
improvements of 5.6% with fine-tuning (with 5.4% average mono-lingual
improvements when using high-quality data over low-quality data), 2.9% average
gains from cross-lingual transfer, and a 3.0% out-of-the-box performance boost
on culturally appropriate questions. The publicly available benchmarks,
translations, and code from this study support further research and development
aimed at creating more inclusive and effective language technologies.

摘要：大型語言模型 (LLM) 在各種任務中展現出卓越的表現，但非英語語言，尤其是原生非洲語言，仍存在顯著的差異。本文透過在 8 種資源匱乏的非洲語言中建立約 100 萬個人類翻譯的單字作為新的基準資料，來解決這些差異，涵蓋超過 1.6 億人口的使用者：阿姆哈拉語、班巴拉語、伊博語、北索托語、紹納語、南索托語、茨瓦納語和聰加語。我們的基準是對 Winogrande 和 MMLU 的三個部分進行翻譯：大學醫學、臨床知識和病毒學。透過翻譯的基準，我們報告了先前未知的效能差距，在英語和非洲語言的最新 (SOTA) LLM 之間。最後，使用來自 400 多個微調模型的結果，我們探討了幾種方法來縮小 LLM 效能差距，包括高品質資料集微調（使用 LLM 作為註解者）、跨語言轉移和文化適宜性調整。主要發現包括微調後平均單語改善 5.6%（使用高品質資料比低品質資料時，平均單語改善 5.4%）、跨語言轉移平均提升 2.9%，以及在文化適宜問題上即時效能提升 3.0%。本研究中公開提供的基準、翻譯和程式碼支援進一步的研究和開發，旨在建立更具包容性和有效性的語言技術。

##### **The Impact of AI Assistance on Radiology Reporting: A Pilot Study Using Simulated AI Draft Reports**
2412.12042v1 by Julián N. Acosta, Siddhant Dogra, Subathra Adithan, Kay Wu, Michael Moritz, Stephen Kwak, Pranav Rajpurkar

Radiologists face increasing workload pressures amid growing imaging volumes,
creating risks of burnout and delayed reporting times. While artificial
intelligence (AI) based automated radiology report generation shows promise for
reporting workflow optimization, evidence of its real-world impact on clinical
accuracy and efficiency remains limited. This study evaluated the effect of
draft reports on radiology reporting workflows by conducting a three reader
multi-case study comparing standard versus AI-assisted reporting workflows. In
both workflows, radiologists reviewed the cases and modified either a standard
template (standard workflow) or an AI-generated draft report (AI-assisted
workflow) to create the final report. For controlled evaluation, we used GPT-4
to generate simulated AI drafts and deliberately introduced 1-3 errors in half
the cases to mimic real AI system performance. The AI-assisted workflow
significantly reduced average reporting time from 573 to 435 seconds (p=0.003),
without a statistically significant difference in clinically significant errors
between workflows. These findings suggest that AI-generated drafts can
meaningfully accelerate radiology reporting while maintaining diagnostic
accuracy, offering a practical solution to address mounting workload challenges
in clinical practice.

摘要：放射科醫師在影像量不斷增加的情況下，面臨工作量壓力增加，
造成倦怠和報告時間延誤的風險。雖然基於人工智慧 (AI) 的自動化放射科報告生成顯示出優化報告工作流程的希望，但其對臨床準確性和效率的實際影響證據仍然有限。本研究透過進行三名讀者多案例研究，比較標準與 AI 輔助報告工作流程，評估草稿報告對放射科報告工作流程的影響。在兩種工作流程中，放射科醫師檢閱病例並修改標準範本 (標準工作流程) 或 AI 生成的草稿報告 (AI 輔助工作流程) 以建立最終報告。為了進行受控評估，我們使用 GPT-4 產生模擬的 AI 草稿，並故意在半數病例中引入 1-3 個錯誤，以模擬真實的 AI 系統效能。AI 輔助工作流程將平均報告時間從 573 秒顯著減少到 435 秒 (p=0.003)，而工作流程之間在臨床顯著錯誤方面沒有統計上的顯著差異。這些發現表明，AI 生成的草稿可以在維持診斷準確性的同時，有意義地加速放射科報告，為解決臨床實務中不斷增加的工作量挑戰提供實際的解決方案。

##### **Combining Large Language Models with Tutoring System Intelligence: A Case Study in Caregiver Homework Support**
2412.11995v1 by Devika Venugopalan, Ziwen Yan, Conrad Borchers, Jionghao Lin, Vincent Aleven

Caregivers (i.e., parents and members of a child's caring community) are
underappreciated stakeholders in learning analytics. Although caregiver
involvement can enhance student academic outcomes, many obstacles hinder
involvement, most notably knowledge gaps with respect to modern school
curricula. An emerging topic of interest in learning analytics is hybrid
tutoring, which includes instructional and motivational support. Caregivers
assert similar roles in homework, yet it is unknown how learning analytics can
support them. Our past work with caregivers suggested that conversational
support is a promising method of providing caregivers with the guidance needed
to effectively support student learning. We developed a system that provides
instructional support to caregivers through conversational recommendations
generated by a Large Language Model (LLM). Addressing known instructional
limitations of LLMs, we use instructional intelligence from tutoring systems
while conducting prompt engineering experiments with the open-source Llama 3
LLM. This LLM generated message recommendations for caregivers supporting their
child's math practice via chat. Few-shot prompting and combining real-time
problem-solving context from tutoring systems with examples of tutoring
practices yielded desirable message recommendations. These recommendations were
evaluated with ten middle school caregivers, who valued recommendations
facilitating content-level support and student metacognition through
self-explanation. We contribute insights into how tutoring systems can best be
merged with LLMs to support hybrid tutoring settings through conversational
assistance, facilitating effective caregiver involvement in tutoring systems.

摘要：照顧者（即父母和兒童照顧社群的成員）是學習分析中未獲充分重視的利害關係人。儘管照顧者的參與可以提升學生的學業成績，但許多障礙阻礙了參與，最顯著的是關於現代學校課程的知識差距。學習分析中一個新興的關注主題是混合式輔導，其中包括教學和動機支持。照顧者在家庭作業中扮演類似的角色，但目前尚不清楚學習分析如何能支持他們。我們過去與照顧者的合作表明，對話式支持是提供照顧者有效支持學生學習所需的指導的一種有前途的方法。我們開發了一個系統，透過大型語言模型 (LLM) 產生的對話式建議，為照顧者提供教學支援。為了解決 LLM 已知的教學限制，我們在對開源 Llama 3 LLM 進行提示工程實驗時，使用了來自輔導系統的教學智慧。此 LLM 為照顧者透過聊天支援其子女的數學練習生成了訊息建議。少量提示並結合來自輔導系統的即時問題解決背景與輔導實務範例，產生了理想的訊息建議。這些建議經過十位國中照顧者的評估，他們重視促進內容層級支援和學生透過自我解釋進行元認知的建議。我們提供見解，說明輔導系統如何能透過對話式協助與 LLM 最佳整合，以支援混合式輔導設定，促進照顧者有效參與輔導系統。

##### **LLMs Can Simulate Standardized Patients via Agent Coevolution**
2412.11716v1 by Zhuoyun Du, Lujie Zheng, Renjun Hu, Yuyang Xu, Xiawei Li, Ying Sun, Wei Chen, Jian Wu, Haolei Cai, Haohao Ying

Training medical personnel using standardized patients (SPs) remains a
complex challenge, requiring extensive domain expertise and role-specific
practice. Most research on Large Language Model (LLM)-based simulated patients
focuses on improving data retrieval accuracy or adjusting prompts through human
feedback. However, this focus has overlooked the critical need for patient
agents to learn a standardized presentation pattern that transforms data into
human-like patient responses through unsupervised simulations. To address this
gap, we propose EvoPatient, a novel simulated patient framework in which a
patient agent and doctor agents simulate the diagnostic process through
multi-turn dialogues, simultaneously gathering experience to improve the
quality of both questions and answers, ultimately enabling human doctor
training. Extensive experiments on various cases demonstrate that, by providing
only overall SP requirements, our framework improves over existing reasoning
methods by more than 10% in requirement alignment and better human preference,
while achieving an optimal balance of resource consumption after evolving over
200 cases for 10 hours, with excellent generalizability. The code will be
available at https://github.com/ZJUMAI/EvoPatient.

摘要：使用标准化患者 (SP) 培训医疗人员仍然是一项复杂的挑战，需要广泛的领域专业知识和针对特定角色的实践。大多数关于基于大语言模型 (LLM) 的模拟患者的研究都集中在提高数据检索准确性或通过人工反馈调整提示上。然而，这种关注忽视了患者代理学习标准化陈述模式的关键需求，该模式通过无监督模拟将数据转换为类人的患者反应。为了解决这一差距，我们提出了 EvoPatient，这是一个新颖的模拟患者框架，其中患者代理和医生代理通过多轮对话模拟诊断过程，同时收集经验以提高问题和答案的质量，最终实现人类医生培训。对各种案例进行的广泛实验表明，通过仅提供整体 SP 要求，我们的框架在需求对齐和更好的人类偏好方面比现有的推理方法提高了 10% 以上，同时在经过 200 个案例演化 10 小时后实现了资源消耗的最佳平衡，具有出色的可概括性。代码可在 https://github.com/ZJUMAI/EvoPatient 获得。

##### **Fast-staged CNN Model for Accurate pulmonary diseases and Lung cancer detection**
2412.11681v1 by Abdelbaki Souid, Mohamed Hamroun, Soufiene Ben Othman, Hedi Sakli, Naceur Abdelkarim

Pulmonary pathologies are a significant global health concern, often leading
to fatal outcomes if not diagnosed and treated promptly. Chest radiography
serves as a primary diagnostic tool, but the availability of experienced
radiologists remains limited. Advances in Artificial Intelligence (AI) and
machine learning, particularly in computer vision, offer promising solutions to
address this challenge.
  This research evaluates a deep learning model designed to detect lung cancer,
specifically pulmonary nodules, along with eight other lung pathologies, using
chest radiographs. The study leverages diverse datasets comprising over 135,120
frontal chest radiographs to train a Convolutional Neural Network (CNN). A
two-stage classification system, utilizing ensemble methods and transfer
learning, is employed to first triage images into Normal or Abnormal categories
and then identify specific pathologies, including lung nodules.
  The deep learning model achieves notable results in nodule classification,
with a top-performing accuracy of 77%, a sensitivity of 0.713, a specificity of
0.776 during external validation, and an AUC score of 0.888. Despite these
successes, some misclassifications were observed, primarily false negatives.
  In conclusion, the model demonstrates robust potential for generalization
across diverse patient populations, attributed to the geographic diversity of
the training dataset. Future work could focus on integrating ETL data
distribution strategies and expanding the dataset with additional nodule-type
samples to further enhance diagnostic accuracy.

摘要：肺部病變是全球重要的健康問題，若未及時診斷和治療，常會導致致命後果。胸部 X 光攝影可用作主要的診斷工具，但經驗豐富的放射科醫師數量有限。人工智慧 (AI) 和機器學習的進展，特別是在電腦視覺方面，提供了有望解決此挑戰的方案。
本研究評估了一個深度學習模型，該模型旨在使用胸部 X 光片檢測肺癌，特別是肺結節，以及其他八種肺部病變。此研究利用包含超過 135,120 張正面胸部 X 光片的不同資料集來訓練卷積神經網路 (CNN)。採用兩階段分類系統，利用整體方法和遷移學習，首先將影像分類為正常或異常類別，然後識別特定病變，包括肺結節。
深度學習模型在結節分類方面取得顯著成果，在外部驗證期間，其準確率最高達到 77%，靈敏度為 0.713，特異度為 0.776，AUC 分數為 0.888。儘管有這些成功，但仍觀察到一些錯誤分類，主要是假陰性。
總之，該模型展示了在不同患者族群中概括的強大潛力，這歸功於訓練資料集的地理多樣性。未來的研究可以專注於整合 ETL 資料分佈策略，並使用額外的結節類型樣本擴充資料集，以進一步提高診斷準確性。

##### **BioBridge: Unified Bio-Embedding with Bridging Modality in Code-Switched EMR**
2412.11671v1 by Jangyeong Jeon, Sangyeon Cho, Dongjoon Lee, Changhee Lee, Junyeong Kim

Pediatric Emergency Department (PED) overcrowding presents a significant
global challenge, prompting the need for efficient solutions. This paper
introduces the BioBridge framework, a novel approach that applies Natural
Language Processing (NLP) to Electronic Medical Records (EMRs) in written
free-text form to enhance decision-making in PED. In non-English speaking
countries, such as South Korea, EMR data is often written in a Code-Switching
(CS) format that mixes the native language with English, with most
code-switched English words having clinical significance. The BioBridge
framework consists of two core modules: "bridging modality in context" and
"unified bio-embedding." The "bridging modality in context" module improves the
contextual understanding of bilingual and code-switched EMRs. In the "unified
bio-embedding" module, the knowledge of the model trained in the medical domain
is injected into the encoder-based model to bridge the gap between the medical
and general domains. Experimental results demonstrate that the proposed
BioBridge significantly performance traditional machine learning and
pre-trained encoder-based models on several metrics, including F1 score, area
under the receiver operating characteristic curve (AUROC), area under the
precision-recall curve (AUPRC), and Brier score. Specifically, BioBridge-XLM
achieved enhancements of 0.85% in F1 score, 0.75% in AUROC, and 0.76% in AUPRC,
along with a notable 3.04% decrease in the Brier score, demonstrating marked
improvements in accuracy, reliability, and prediction calibration over the
baseline XLM model. The source code will be made publicly available.

摘要：<paragraph>小兒急診部（PED）人滿為患是一個重大的全球性挑戰，促使我們需要找出有效率的解決方案。本文介紹 BioBridge 架構，這是一種創新的方法，將自然語言處理（NLP）應用於以自由文字形式撰寫的電子病歷（EMR），以增強在 PED 中的決策制定。在非英語系國家/地區（例如南韓），EMR 資料通常以代碼轉換（CS）格式撰寫，將母語與英語混合，而大多數代碼轉換的英語單字具有臨床意義。BioBridge 架構包含兩個核心模組：「語境中的橋接方式」和「統一生物嵌入」。「語境中的橋接方式」模組改善了雙語和代碼轉換 EMR 的語境理解。在「統一生物嵌入」模組中，將在醫療領域訓練的模型知識注入到基於編碼器的模型中，以彌合醫療和一般領域之間的差距。實驗結果證明，所提出的 BioBridge 在多項指標（包括 F1 分數、受試者操作特徵曲線下面積（AUROC）、精確度召回率曲線下面積（AUPRC）和布賴爾分數）上顯著優於傳統機器學習和預先訓練的基於編碼器的模型。具體來說，BioBridge-XLM 在 F1 分數上提升了 0.85%，在 AUROC 上提升了 0.75%，在 AUPRC 上提升了 0.76%，同時布賴爾分數顯著下降了 3.04%，證明在準確度、可靠性和預測校準方面，與基準 XLM 模型相比都有顯著的改善。原始碼將公開提供。</paragraph>

##### **Leveraging Foundation Language Models (FLMs) for Automated Cohort Extraction from Large EHR Databases**
2412.11472v1 by Purity Mugambi, Alexandra Meliou, Madalina Fiterau

A crucial step in cohort studies is to extract the required cohort from one
or more study datasets. This step is time-consuming, especially when a
researcher is presented with a dataset that they have not previously worked
with. When the cohort has to be extracted from multiple datasets, cohort
extraction can be extremely laborious. In this study, we present an approach
for partially automating cohort extraction from multiple electronic health
record (EHR) databases. We formulate the guided multi-dataset cohort extraction
problem in which selection criteria are first converted into queries,
translating them from natural language text to language that maps to database
entities. Then, using FLMs, columns of interest identified from the queries are
automatically matched between the study databases. Finally, the generated
queries are run across all databases to extract the study cohort. We propose
and evaluate an algorithm for automating column matching on two large, popular
and publicly-accessible EHR databases -- MIMIC-III and eICU. Our approach
achieves a high top-three accuracy of $92\%$, correctly matching $12$ out of
the $13$ columns of interest, when using a small, pre-trained general purpose
language model. Furthermore, this accuracy is maintained even as the search
space (i.e., size of the database) increases.

摘要：在队列研究中，从一个或多个研究数据集提取所需的队列是至关重要的一步。此步骤非常耗时，特别是当研究人员使用之前未处理过的数据集时。当必须从多个数据集提取队列时，队列提取可能会非常费力。在本研究中，我们提出了一种从多个电子健康记录 (EHR) 数据库中部分自动化队列提取的方法。我们制定了引导式多数据集队列提取问题，其中选择标准首先转换为查询，将它们从自然语言文本转换为映射到数据库实体的语言。然后，使用 FLM，从查询中识别出的目标列在研究数据库之间自动匹配。最后，在所有数据库中运行生成的查询以提取研究队列。我们提出并评估了一种算法，用于在两个大型、流行且可公开访问的 EHR 数据库（MIMIC-III 和 eICU）上自动执行列匹配。我们的方法实现了 92% 的高前三准确度，在使用小型、预先训练的通用语言模型时，正确匹配了 13 个目标列中的 12 个。此外，即使搜索空间（即数据库大小）增加，也能保持这种准确性。

##### **FedCAR: Cross-client Adaptive Re-weighting for Generative Models in Federated Learning**
2412.11463v1 by Minjun Kim, Minjee Kim, Jinhoon Jeong

Generative models trained on multi-institutional datasets can provide an
enriched understanding through diverse data distributions. However, training
the models on medical images is often challenging due to hospitals' reluctance
to share data for privacy reasons. Federated learning(FL) has emerged as a
privacy-preserving solution for training distributed datasets across data
centers by aggregating model weights from multiple clients instead of sharing
raw data. Previous research has explored the adaptation of FL to generative
models, yet effective aggregation algorithms specifically tailored for
generative models remain unexplored. We hereby propose a novel algorithm aimed
at improving the performance of generative models within FL. Our approach
adaptively re-weights the contribution of each client, resulting in
well-trained shared parameters. In each round, the server side measures the
distribution distance between fake images generated by clients instead of
directly comparing the Fr\'echet Inception Distance per client, thereby
enhancing efficiency of the learning. Experimental results on three public
chest X-ray datasets show superior performance in medical image generation,
outperforming both centralized learning and conventional FL algorithms. Our
code is available at https://github.com/danny0628/FedCAR.

摘要：在多機構資料集上訓練的生成模型能透過多樣化的資料分佈提供豐富的理解。然而，由於醫院基於隱私原因不願意分享資料，因此在醫學影像上訓練模型通常具有挑戰性。聯合學習 (FL) 已成為一種隱私保護解決方案，透過彙總多個用戶端的模型權重，而非分享原始資料，就能在資料中心間訓練分散式資料集。先前的研究已探討將 FL 改編到生成模型，但專門為生成模型量身打造的有效彙總演算法仍未被探討。我們在此提出一個新演算法，旨在改善 FL 內生成模型的效能。我們的做法是自適應地重新加權每個用戶端的貢獻，進而產生訓練良好的共用參數。在每一回合中，伺服器端測量用戶端產生的假影像之間的分配距離，而非直接比較每個用戶端的 Fr\'echet Inception Distance，從而提升學習效率。在三個公開胸部 X 光資料集上的實驗結果顯示，在醫學影像生成方面有優異的效能，優於集中式學習和傳統的 FL 演算法。我們的程式碼可以在 https://github.com/danny0628/FedCAR 取得。

##### **ACE-$M^3$: Automatic Capability Evaluator for Multimodal Medical Models**
2412.11453v1 by Xiechi Zhang, Shunfan Zheng, Linlin Wang, Gerard de Melo, Zhu Cao, Xiaoling Wang, Liang He

As multimodal large language models (MLLMs) gain prominence in the medical
field, the need for precise evaluation methods to assess their effectiveness
has become critical. While benchmarks provide a reliable means to evaluate the
capabilities of MLLMs, traditional metrics like ROUGE and BLEU employed for
open domain evaluation only focus on token overlap and may not align with human
judgment. Although human evaluation is more reliable, it is labor-intensive,
costly, and not scalable. LLM-based evaluation methods have proven promising,
but to date, there is still an urgent need for open-source multimodal LLM-based
evaluators in the medical field. To address this issue, we introduce ACE-$M^3$,
an open-sourced \textbf{A}utomatic \textbf{C}apability \textbf{E}valuator for
\textbf{M}ultimodal \textbf{M}edical \textbf{M}odels specifically designed to
assess the question answering abilities of medical MLLMs. It first utilizes a
branch-merge architecture to provide both detailed analysis and a concise final
score based on standard medical evaluation criteria. Subsequently, a reward
token-based direct preference optimization (RTDPO) strategy is incorporated to
save training time without compromising performance of our model. Extensive
experiments have demonstrated the effectiveness of our ACE-$M^3$
model\footnote{\url{https://huggingface.co/collections/AIUSRTMP/ace-m3-67593297ff391b93e3e5d068}}
in evaluating the capabilities of medical MLLMs.

摘要：<paragraph>隨著多模態大型語言模型 (MLLM) 在醫療領域的重要性日益提升，評估其效能的精準評量方法的需求也變得至關重要。雖然基準測試提供了評估 MLLM 能力的可靠方法，但用於開放領域評量的傳統指標，例如 ROUGE 和 BLEU，僅著重於權標重疊，可能與人類判斷不符。儘管人類評量較為可靠，但它卻勞力密集、成本高昂且無法擴充。基於 LLM 的評量方法已被證實具有前景，但迄今為止，醫療領域仍迫切需要開放原始碼的多模態基於 LLM 的評量器。為了解決這個問題，我們引入了 ACE-$M^3$，一個開放原始碼的**A**utomatic **C**apability **E**valuator for **M**ultimodal **M**edical **M**odels，專門設計用於評估醫療 MLLM 的問答能力。它首先利用分支合併架構提供詳細分析和基於標準醫療評量標準的簡潔最終評分。隨後，納入了基於獎勵權標的直接偏好最佳化 (RTDPO) 策略，以節省訓練時間，同時不影響我們模型的效能。廣泛的實驗證明了我們的 ACE-$M^3$ 模型\footnote{\url{https://huggingface.co/collections/AIUSRTMP/ace-m3-67593297ff391b93e3e5d068}} 在評估醫療 MLLM 能力方面的效能。</paragraph>

##### **Structured Extraction of Real World Medical Knowledge using LLMs for Summarization and Search**
2412.15256v1 by Edward Kim, Manil Shrestha, Richard Foty, Tom DeLay, Vicki Seyfert-Margolis

Creation and curation of knowledge graphs can accelerate disease discovery
and analysis in real-world data. While disease ontologies aid in biological
data annotation, codified categories (SNOMED-CT, ICD10, CPT) may not capture
patient condition nuances or rare diseases. Multiple disease definitions across
data sources complicate ontology mapping and disease clustering. We propose
creating patient knowledge graphs using large language model extraction
techniques, allowing data extraction via natural language rather than rigid
ontological hierarchies. Our method maps to existing ontologies (MeSH,
SNOMED-CT, RxNORM, HPO) to ground extracted entities.
  Using a large ambulatory care EHR database with 33.6M patients, we
demonstrate our method through the patient search for Dravet syndrome, which
received ICD10 recognition in October 2020. We describe our construction of
patient-specific knowledge graphs and symptom-based patient searches. Using
confirmed Dravet syndrome ICD10 codes as ground truth, we employ LLM-based
entity extraction to characterize patients in grounded ontologies. We then
apply this method to identify Beta-propeller protein-associated
neurodegeneration (BPAN) patients, demonstrating real-world discovery where no
ground truth exists.

摘要：知識圖譜的建立和策展可以加速疾病發現和分析真實世界中的資料。雖然疾病本體論有助於生物資料註釋，但編碼類別（SNOMED-CT、ICD10、CPT）可能無法捕捉患者狀況的細微差別或罕見疾病。跨資料來源的多重疾病定義使本體論對應和疾病群集複雜化。我們建議使用大型語言模型萃取技術建立患者知識圖譜，允許透過自然語言而不是僵化的本體論階層萃取資料。我們的模型對應到現有本體論（MeSH、SNOMED-CT、RxNORM、HPO）以建立萃取實體的基礎。使用一個擁有 3360 萬名患者的大型門診電子病歷資料庫，我們透過患者搜尋 Dravet 症候群來展示我們的模型，該症候群於 2020 年 10 月獲得 ICD10 認可。我們描述我們如何建構患者特定的知識圖譜和基於症狀的患者搜尋。使用已確認的 Dravet 症候群 ICD10 代碼作為基準，我們使用基於 LLM 的實體萃取來描述紮根於本體論中的患者。然後我們應用此模型來識別貝塔螺旋槳蛋白相關的神經退化（BPAN）患者，展示了在不存在基準的情況下進行真實世界發現。

##### **Detecting Daily Living Gait Amid Huntington's Disease Chorea using a Foundation Deep Learning Model**
2412.11286v1 by Dafna Schwartz, Lori Quinn, Nora E. Fritz, Lisa M. Muratori, Jeffery M. Hausdorff, Ran Gilad Bachrach

Wearable sensors offer a non-invasive way to collect physical activity (PA)
data, with walking as a key component. Existing models often struggle to detect
gait bouts in individuals with neurodegenerative diseases (NDDs) involving
involuntary movements. We developed J-Net, a deep learning model inspired by
U-Net, which uses a pre-trained self-supervised foundation model fine-tuned
with Huntington`s disease (HD) in-lab data and paired with a segmentation head
for gait detection. J-Net processes wrist-worn accelerometer data to detect
gait during daily living. We evaluated J-Net on in-lab and daily-living data
from HD, Parkinson`s disease (PD), and controls. J-Net achieved a 10-percentage
point improvement in ROC-AUC for HD over existing methods, reaching 0.97 for
in-lab data. In daily-living environments, J-Net estimates showed no
significant differences in median daily walking time between HD and controls (p
= 0.23), in contrast to other models, which indicated counterintuitive results
(p < 0.005). Walking time measured by J-Net correlated with the UHDRS-TMS
clinical severity score (r=-0.52; p=0.02), confirming its clinical relevance.
Fine-tuning J-Net on PD data also improved gait detection over current methods.
J-Net`s architecture effectively addresses the challenges of gait detection in
severe chorea and offers robust performance in daily living. The dataset and
J-Net model are publicly available, providing a resource for further research
into NDD-related gait impairments.

摘要：<paragraph>穿戴式感測器提供收集身體活動 (PA) 資料的非侵入式方法，其中步行為關鍵組成部分。現有模型通常難以偵測患有神經退化性疾病 (NDD) 並伴隨非自主運動的個體的步態發作。我們開發了 J-Net，一種受 U-Net 啟發的深度學習模型，它使用經過預先訓練的自監督基礎模型，並使用亨丁頓舞蹈症 (HD) 實驗室資料進行微調，並與用於步態偵測的分段頭部配對。J-Net 處理手腕配戴的加速度計資料，以偵測日常生活中的步態。我們在 HD、帕金森氏症 (PD) 和對照組的實驗室和日常生活資料上評估 J-Net。J-Net 在 HD 的 ROC-AUC 上比現有方法提高了 10 個百分點，對於實驗室資料達到 0.97。在日常生活環境中，J-Net 估計值顯示 HD 和對照組之間的每日平均步行時間沒有顯著差異 (p = 0.23)，這與其他模型形成對比，後者顯示出違背直覺的結果 (p < 0.005)。J-Net 測量的步行時間與 UHDRS-TMS 臨床嚴重程度評分相關 (r=-0.52；p=0.02)，證實其臨床相關性。在 PD 資料上微調 J-Net 也改善了對現有方法的步態偵測。J-Net 的架構有效解決了嚴重舞蹈症中步態偵測的挑戰，並在日常生活中提供穩健的效能。該資料集和 J-Net 模型公開提供，為進一步研究 NDD 相關步態障礙提供資源。</paragraph>

##### **Wearable Accelerometer Foundation Models for Health via Knowledge Distillation**
2412.11276v1 by Salar Abbaspourazad, Anshuman Mishra, Joseph Futoma, Andrew C. Miller, Ian Shapiro

Modern wearable devices can conveniently and continuously record various
biosignals in the many different environments of daily living, ultimately
enabling a rich view of individual health. However, not all biosignals are the
same: high-fidelity measurements, such as photoplethysmography (PPG), contain
more physiological information, but require optical sensors with a high power
footprint. In a resource-constrained setting, such biosignals may be
unavailable. Alternatively, a lower-fidelity biosignal, such as accelerometry
that captures minute cardiovascular information during low-motion periods, has
a significantly smaller power footprint and is available in almost any wearable
device. Here, we demonstrate that we can distill representational knowledge
across biosignals, i.e., from PPG to accelerometry, using 20 million minutes of
unlabeled data, collected from ~172K participants in the Apple Heart and
Movement Study under informed consent. We first pre-train PPG encoders via
self-supervised learning, and then distill their representational knowledge to
accelerometry encoders. We demonstrate strong cross-modal alignment on unseen
data, e.g., 99.2% top-1 accuracy for retrieving PPG embeddings from
accelerometry embeddings. We show that distilled accelerometry encoders have
significantly more informative representations compared to self-supervised or
supervised encoders trained directly on accelerometry data, observed by at
least 23%-49% improved performance for predicting heart rate and heart rate
variability. We also show that distilled accelerometry encoders are readily
predictive of a wide array of downstream health targets, i.e., they are
generalist foundation models. We believe accelerometry foundation models for
health may unlock new opportunities for developing digital biomarkers from any
wearable device, and help individuals track their health more frequently and
conveniently.

摘要：<paragraph>現代的可穿戴裝置可以在日常生活的許多不同環境中方便且持續地記錄各種生物訊號，最終能全面了解個人的健康狀況。然而，並非所有生物訊號都相同：高保真測量值（例如光電容積描記法 (PPG)）包含更多生理資訊，但需要具有高功率佔用的光學感測器。在資源受限的環境中，這些生物訊號可能無法取得。或者，低保真生物訊號（例如加速度計，可在低動作期間擷取細微的心血管資訊）具有明顯更小的功率佔用，且幾乎可以在任何可穿戴裝置中取得。在這裡，我們證明我們可以跨生物訊號（即從 PPG 到加速度計）萃取出表徵知識，使用從 Apple 心臟和運動研究中約 172K 名參與者收集的 2000 萬分鐘未標記資料，在知情同意下進行。我們先透過自我監督式學習預先訓練 PPG 編碼器，然後將其表徵知識萃取到加速度計編碼器。我們在未見過的資料上展示了強大的跨模態對齊，例如從加速度計嵌入中擷取 PPG 嵌入的 99.2% 最高 1 精確度。我們表明，與直接在加速度計資料上訓練的自我監督式或監督式編碼器相比，萃取的加速度計編碼器具有更多資訊豐富的表徵，從預測心率和心率變異性的表現改善至少 23%-49% 可見。我們還表明，萃取的加速度計編碼器很容易預測廣泛的下游健康目標，即它們是一般化的基礎模型。我們相信，用於健康的加速度計基礎模型可能會開啟從任何可穿戴裝置開發數位生物標記的新機會，並幫助個人更頻繁且更方便地追蹤他們的健康狀況。</paragraph>

##### **TrimLLM: Progressive Layer Dropping for Domain-Specific LLMs**
2412.11242v2 by Lanxiang Hu, Tajana Rosing, Hao Zhang

Specializing large language models (LLMs) for local deployment in
domain-specific use cases is necessary for strong performance while meeting
latency and privacy constraints. However, conventional task-specific adaptation
approaches do not show simultaneous memory saving and inference speedup at
deployment time. Practical compression techniques like quantization and pruning
require dedicated hardware or kernel support to achieve measured inference
speedup. We develop TrimLLM based on the layer-wise specialization phenomenon
we empirically observed and verified on contemporary LLMs. TrimLLM reduces the
depth of LLMs via progressive layer dropping. We show it retains LLMs' capacity
in specific domains and achieves inference speedup irrespective of hardware and
deep learning frameworks. We evaluated TrimLLM on LLMs of various sizes for
inference; models adapted on medical, legal, and financial datasets all
demonstrate $2.1-5.7\times$ inference speedup on consumer GPUs and up to
$3.1\times$ speedup on A100 when compared to state-of-the-art model compression
algorithms, with no loss in accuracy at 50$\sim$60\% model compression ratio.

摘要：針對特定領域的使用案例，將大型語言模型 (LLM) 專門化為本地部署對於在滿足延遲和隱私限制的同時，實現強大的效能十分必要。然而，傳統的特定任務適應方法並未在部署時同時展現記憶體節省和推論加速。量化和剪枝等實用的壓縮技術需要專用的硬體或核心支援，才能實現已測量的推論加速。我們根據在當代 LLM 上經驗觀察並驗證的分層專門化現象，開發了 TrimLLM。TrimLLM 透過漸進式層級捨棄來減少 LLM 的深度。我們展示它保留了 LLM 在特定領域中的容量，並在不考慮硬體和深度學習架構的情況下實現了推論加速。我們針對不同大小的 LLM 評估了 TrimLLM 的推論；在醫療、法律和財務資料集上適應的模型，與最先進的模型壓縮演算法相比，在消費級 GPU 上都展現了 $2.1-5.7\times$ 的推論加速，而 A100 上的加速則高達 $3.1\times$，且在 50$\sim$60% 的模型壓縮率下，準確度沒有損失。

##### **Efficient Quantization-Aware Training on Segment Anything Model in Medical Images and Its Deployment**
2412.11186v1 by Haisheng Lu, Yujie Fu, Fan Zhang, Le Zhang

Medical image segmentation is a critical component of clinical practice, and
the state-of-the-art MedSAM model has significantly advanced this field.
Nevertheless, critiques highlight that MedSAM demands substantial computational
resources during inference. To address this issue, the CVPR 2024 MedSAM on
Laptop Challenge was established to find an optimal balance between accuracy
and processing speed. In this paper, we introduce a quantization-aware training
pipeline designed to efficiently quantize the Segment Anything Model for
medical images and deploy it using the OpenVINO inference engine. This pipeline
optimizes both training time and disk storage. Our experimental results confirm
that this approach considerably enhances processing speed over the baseline,
while still achieving an acceptable accuracy level. The training script,
inference script, and quantized model are publicly accessible at
https://github.com/AVC2-UESTC/QMedSAM.

摘要：醫學影像分割是臨床實務中至關重要的組成部分，而最先進的 MedSAM 模型已大幅提升此領域。儘管如此，批評者強調 MedSAM 在推論期間需要大量的計算資源。為了解決這個問題，CVPR 2024 MedSAM on Laptop 挑戰賽因而成立，以期在準確度與處理速度之間取得最佳平衡。在本文中，我們介紹了一種量化感知訓練管道，用於有效量化 Segment Anything Model 以處理醫學影像，並使用 OpenVINO 推論引擎進行部署。此管道同時最佳化了訓練時間與磁碟儲存空間。我們的實驗結果證實，此方法大幅提升了處理速度，同時仍達到可接受的準確度等級。訓練腳本、推論腳本和量化模型已公開於 https://github.com/AVC2-UESTC/QMedSAM。

##### **AD-LLM: Benchmarking Large Language Models for Anomaly Detection**
2412.11142v1 by Tiankai Yang, Yi Nian, Shawn Li, Ruiyao Xu, Yuangang Li, Jiaqi Li, Zhuo Xiao, Xiyang Hu, Ryan Rossi, Kaize Ding, Xia Hu, Yue Zhao

Anomaly detection (AD) is an important machine learning task with many
real-world uses, including fraud detection, medical diagnosis, and industrial
monitoring. Within natural language processing (NLP), AD helps detect issues
like spam, misinformation, and unusual user activity. Although large language
models (LLMs) have had a strong impact on tasks such as text generation and
summarization, their potential in AD has not been studied enough. This paper
introduces AD-LLM, the first benchmark that evaluates how LLMs can help with
NLP anomaly detection. We examine three key tasks: (i) zero-shot detection,
using LLMs' pre-trained knowledge to perform AD without tasks-specific
training; (ii) data augmentation, generating synthetic data and category
descriptions to improve AD models; and (iii) model selection, using LLMs to
suggest unsupervised AD models. Through experiments with different datasets, we
find that LLMs can work well in zero-shot AD, that carefully designed
augmentation methods are useful, and that explaining model selection for
specific datasets remains challenging. Based on these results, we outline six
future research directions on LLMs for AD.

摘要：異常偵測 (AD) 是一項重要的機器學習任務，在現實世界中有許多用途，包括詐欺偵測、醫療診斷和工業監控。在自然語言處理 (NLP) 中，AD 有助於偵測垃圾郵件、錯誤訊息和異常使用者活動等問題。儘管大型語言模型 (LLM) 對文字生成和摘要等任務產生了重大影響，但它們在 AD 中的潛力尚未得到充分研究。本文介紹了 AD-LLM，這是第一個評估 LLM 如何協助 NLP 異常偵測的基準。我們探討了三個關鍵任務：(i) 零次學習偵測，使用 LLM 的預訓練知識在沒有特定任務訓練的情況下執行 AD；(ii) 資料擴充，生成合成資料和類別描述以改善 AD 模型；以及 (iii) 模型選擇，使用 LLM 來建議無監督 AD 模型。透過使用不同資料集進行的實驗，我們發現 LLM 可以很好地用於零次學習 AD，精心設計的擴充方法很有用，並且針對特定資料集解釋模型選擇仍然具有挑戰性。根據這些結果，我們概述了有關 AD 的 LLM 未來六個研究方向。

##### **Decoding Drug Discovery: Exploring A-to-Z In silico Methods for Beginners**
2412.11137v1 by Hezha O. Rasul, Dlzar D. Ghafour, Bakhtyar K. Aziz, Bryar A. Hassan, Tarik A. Rashid, Arif Kivrak

The drug development process is a critical challenge in the pharmaceutical
industry due to its time-consuming nature and the need to discover new drug
potentials to address various ailments. The initial step in drug development,
drug target identification, often consumes considerable time. While valid,
traditional methods such as in vivo and in vitro approaches are limited in
their ability to analyze vast amounts of data efficiently, leading to wasteful
outcomes. To expedite and streamline drug development, an increasing reliance
on computer-aided drug design (CADD) approaches has merged. These sophisticated
in silico methods offer a promising avenue for efficiently identifying viable
drug candidates, thus providing pharmaceutical firms with significant
opportunities to uncover new prospective drug targets. The main goal of this
work is to review in silico methods used in the drug development process with a
focus on identifying therapeutic targets linked to specific diseases at the
genetic or protein level. This article thoroughly discusses A-to-Z in silico
techniques, which are essential for identifying the targets of bioactive
compounds and their potential therapeutic effects. This review intends to
improve drug discovery processes by illuminating the state of these
cutting-edge approaches, thereby maximizing the effectiveness and duration of
clinical trials for novel drug target investigation.

摘要：藥物開發過程是製藥產業的一項關鍵挑戰，因為它耗時且需要找出新的藥物潛力來解決各種疾病。藥物開發的第一步，藥物目標識別，通常會花費大量時間。雖然有效，但傳統方法（例如體內和體外方法）在有效分析大量資料的能力上受到限制，導致浪費結果。為了加快和簡化藥物開發，越來越依賴電腦輔助藥物設計 (CADD) 方法。這些先進的 in silico 方法提供了一個有前途的途徑，可以有效地識別可行的候選藥物，從而為製藥公司提供顯著的機會來發現新的潛在藥物目標。這項工作的目標是回顧藥物開發過程中使用的 in silico 方法，重點是找出與特定疾病在基因或蛋白質層面相關的治療目標。本文徹底討論了 A-to-Z in silico 技術，這些技術對於識別生物活性化合物的目標及其潛在治療效果至關重要。這篇評論旨在透過闡明這些尖端方法的狀態來改進藥物發現過程，從而最大化新藥物目標研究的有效性和持續時間。

##### **MedG-KRP: Medical Graph Knowledge Representation Probing**
2412.10982v2 by Gabriel R. Rosenbaum, Lavender Yao Jiang, Ivaxi Sheth, Jaden Stryker, Anton Alyakin, Daniel Alexander Alber, Nicolas K. Goff, Young Joon Fred Kwon, John Markert, Mustafa Nasir-Moin, Jan Moritz Niehues, Karl L. Sangwon, Eunice Yang, Eric Karl Oermann

Large language models (LLMs) have recently emerged as powerful tools, finding
many medical applications. LLMs' ability to coalesce vast amounts of
information from many sources to generate a response-a process similar to that
of a human expert-has led many to see potential in deploying LLMs for clinical
use. However, medicine is a setting where accurate reasoning is paramount. Many
researchers are questioning the effectiveness of multiple choice question
answering (MCQA) benchmarks, frequently used to test LLMs. Researchers and
clinicians alike must have complete confidence in LLMs' abilities for them to
be deployed in a medical setting. To address this need for understanding, we
introduce a knowledge graph (KG)-based method to evaluate the biomedical
reasoning abilities of LLMs. Essentially, we map how LLMs link medical concepts
in order to better understand how they reason. We test GPT-4, Llama3-70b, and
PalmyraMed-70b, a specialized medical model. We enlist a panel of medical
students to review a total of 60 LLM-generated graphs and compare these graphs
to BIOS, a large biomedical KG. We observe GPT-4 to perform best in our human
review but worst in our ground truth comparison; vice-versa with PalmyraMed,
the medical model. Our work provides a means of visualizing the medical
reasoning pathways of LLMs so they can be implemented in clinical settings
safely and effectively.

摘要：大型語言模型 (LLM) 近期已成為強大的工具，在醫療領域中發現許多應用。LLM 從許多來源匯集大量資訊以產生回應的能力（此過程類似於人類專家的過程），已讓許多人看到將 LLM 部署於臨床用途的潛力。然而，醫學是一個準確推理至關重要的領域。許多研究人員質疑多選題回答 (MCQA) 基準的有效性，而這經常被用於測試 LLM。研究人員和臨床醫生都必須對 LLM 的能力有完全的信心，才能將其部署於醫療環境中。為了滿足這種理解需求，我們引入一個基於知識圖譜 (KG) 的方法來評估 LLM 的生物醫學推理能力。基本上，我們繪製 LLM 如何連結醫療概念，以更好地理解它們的推理方式。我們測試了 GPT-4、Llama3-70b 和 PalmyraMed-70b，這是一個專門的醫療模型。我們徵集了一組醫學生來檢閱總共 60 個 LLM 生成的圖表，並將這些圖表與 BIOS（一個大型生物醫學 KG）進行比較。我們觀察到 GPT-4 在我們的人工審查中表現最佳，但在我們的基本事實比較中表現最差；而專門的醫療模型 PalmyraMed 則相反。我們的研究提供了一種可視化 LLM 醫療推理路徑的方法，以便它們能夠安全有效地實作於臨床環境中。

##### **LLMs-in-the-Loop Part 2: Expert Small AI Models for Anonymization and De-identification of PHI Across Multiple Languages**
2412.10918v1 by Murat Gunay, Bunyamin Keles, Raife Hizlan

The rise of chronic diseases and pandemics like COVID-19 has emphasized the
need for effective patient data processing while ensuring privacy through
anonymization and de-identification of protected health information (PHI).
Anonymized data facilitates research without compromising patient
confidentiality. This paper introduces expert small AI models developed using
the LLM-in-the-loop methodology to meet the demand for domain-specific
de-identification NER models. These models overcome the privacy risks
associated with large language models (LLMs) used via APIs by eliminating the
need to transmit or store sensitive data. More importantly, they consistently
outperform LLMs in de-identification tasks, offering superior performance and
reliability. Our de-identification NER models, developed in eight languages
(English, German, Italian, French, Romanian, Turkish, Spanish, and Arabic)
achieved f1-micro score averages of 0.966, 0.975, 0.976, 0.970, 0.964, 0.974,
0.978, and 0.953 respectively. These results establish them as the most
accurate healthcare anonymization solutions, surpassing existing small models
and even general-purpose LLMs such as GPT-4o. While Part-1 of this series
introduced the LLM-in-the-loop methodology for bio-medical document
translation, this second paper showcases its success in developing
cost-effective expert small NER models in de-identification tasks. Our findings
lay the groundwork for future healthcare AI innovations, including biomedical
entity and relation extraction, demonstrating the value of specialized models
for domain-specific challenges.

摘要：慢性疾病和 COVID-19 等流行病的興起強調了有效處理患者資料的必要性，同時透過匿名化和移除受保護健康資訊 (PHI) 的識別資訊來確保隱私。匿名化資料有助於研究，而不會損害患者的機密性。本文介紹使用 LLM-in-the-loop 方法開發的專家小型 AI 模型，以滿足特定領域去識別化 NER 模型的需求。這些模型克服了透過 API 使用大型語言模型 (LLM) 所帶來的隱私風險，消除了傳輸或儲存敏感資料的需要。更重要的是，它們在去識別化任務中始終優於 LLM，提供卓越的效能和可靠性。我們以八種語言（英語、德語、義大利語、法語、羅馬尼亞語、土耳其語、西班牙語和阿拉伯語）開發的去識別化 NER 模型分別達到 f1-micro 分數平均值 0.966、0.975、0.976、0.970、0.964、0.974、0.978 和 0.953。這些結果確立了它們作為最準確的醫療保健匿名化解決方案，超越了現有的小模型，甚至超越了 GPT-4o 等通用 LLM。雖然本系列的第一部分介紹了用於生物醫學文件翻譯的 LLM-in-the-loop 方法，但第二篇論文展示了其在去識別化任務中開發具有成本效益的專家小型 NER 模型的成功。我們的研究結果為未來的醫療保健 AI 創新奠定了基礎，包括生物醫學實體和關係萃取，證明了專門化模型在特定領域挑戰中的價值。

##### **Superhuman performance of a large language model on the reasoning tasks of a physician**
2412.10849v1 by Peter G. Brodeur, Thomas A. Buckley, Zahir Kanjee, Ethan Goh, Evelyn Bin Ling, Priyank Jain, Stephanie Cabral, Raja-Elie Abdulnour, Adrian Haimovich, Jason A. Freed, Andrew Olson, Daniel J. Morgan, Jason Hom, Robert Gallo, Eric Horvitz, Jonathan Chen, Arjun K. Manrai, Adam Rodman

Performance of large language models (LLMs) on medical tasks has
traditionally been evaluated using multiple choice question benchmarks.
However, such benchmarks are highly constrained, saturated with repeated
impressive performance by LLMs, and have an unclear relationship to performance
in real clinical scenarios. Clinical reasoning, the process by which physicians
employ critical thinking to gather and synthesize clinical data to diagnose and
manage medical problems, remains an attractive benchmark for model performance.
Prior LLMs have shown promise in outperforming clinicians in routine and
complex diagnostic scenarios. We sought to evaluate OpenAI's o1-preview model,
a model developed to increase run-time via chain of thought processes prior to
generating a response. We characterize the performance of o1-preview with five
experiments including differential diagnosis generation, display of diagnostic
reasoning, triage differential diagnosis, probabilistic reasoning, and
management reasoning, adjudicated by physician experts with validated
psychometrics. Our primary outcome was comparison of the o1-preview output to
identical prior experiments that have historical human controls and benchmarks
of previous LLMs. Significant improvements were observed with differential
diagnosis generation and quality of diagnostic and management reasoning. No
improvements were observed with probabilistic reasoning or triage differential
diagnosis. This study highlights o1-preview's ability to perform strongly on
tasks that require complex critical thinking such as diagnosis and management
while its performance on probabilistic reasoning tasks was similar to past
models. New robust benchmarks and scalable evaluation of LLM capabilities
compared to human physicians are needed along with trials evaluating AI in real
clinical settings.

摘要：大型語言模型 (LLM) 在醫療任務中的表現通常使用多選題基準進行評估。然而，此類基準受到高度限制，充斥著 LLM 重複且令人印象深刻的表現，且與實際臨床場景中的表現關係不明確。臨床推理，即醫師運用批判性思考收集和綜合臨床資料以診斷和管理醫療問題的過程，仍然是模型表現的誘人基準。先前的 LLM 已展現出在常規和複雜診斷場景中優於臨床醫師的潛力。我們試圖評估 OpenAI 的 o1-preview 模型，這是一個在產生回應之前透過思考過程鏈來增加執行時間的模型。我們透過五項實驗來描述 o1-preview 的表現，包括鑑別診斷產生、診斷推理顯示、分流鑑別診斷、機率推理和管理推理，並由經過驗證的心理測量學的醫師專家進行判定。我們的主要結果是將 o1-preview 輸出與具有歷史人類控制和先前 LLM 基準的相同先前實驗進行比較。在鑑別診斷產生和診斷和管理推理品質方面觀察到顯著的進步。在機率推理或分流鑑別診斷方面沒有觀察到進步。這項研究突顯了 o1-preview 在執行需要複雜批判性思考的任務（例如診斷和管理）方面的強大能力，而它在機率推理任務中的表現則與過去的模型類似。需要新的穩健基準和 LLM 能力的可擴充評估，與人類醫師進行比較，以及評估 AI 在實際臨床環境中的試驗。

##### **Large Language Models for Medical Forecasting -- Foresight 2**
2412.10848v1 by Zeljko Kraljevic, Joshua Au Yeung, Daniel Bean, James Teo, Richard J. Dobson

Foresight 2 (FS2) is a large language model fine-tuned on hospital data for
modelling patient timelines (GitHub 'removed for anon'). It can understand
patients' clinical notes and predict SNOMED codes for a wide range of
biomedical use cases, including diagnosis suggestions, risk forecasting, and
procedure and medication recommendations. FS2 is trained on the free text
portion of the MIMIC-III dataset, firstly through extracting biomedical
concepts and then creating contextualised patient timelines, upon which the
model is then fine-tuned. The results show significant improvement over the
previous state-of-the-art for the next new biomedical concept prediction (P/R -
0.73/0.66 vs 0.52/0.32) and a similar improvement specifically for the next new
disorder prediction (P/R - 0.69/0.62 vs 0.46/0.25). Finally, on the task of
risk forecast, we compare our model to GPT-4-turbo (and a range of open-source
biomedical LLMs) and show that FS2 performs significantly better on such tasks
(P@5 - 0.90 vs 0.65). This highlights the need to incorporate hospital data
into LLMs and shows that small models outperform much larger ones when
fine-tuned on high-quality, specialised data.

摘要：Foresight 2 (FS2) 是一個大型語言模型，針對醫院數據進行微調，用於建模患者時間軸（GitHub「已移除匿名」）。它可以了解患者的臨床記錄，並預測各種生物醫學用例的 SNOMED 代碼，包括診斷建議、風險預測以及程序和藥物建議。FS2 在 MIMIC-III 數據集的自由文本部分上進行訓練，首先通過提取生物醫學概念，然後創建情境化的患者時間軸，然後對模型進行微調。結果表明，與先前最先進的下一新生物醫學概念預測（P/R - 0.73/0.66 對 0.52/0.32）相比，有顯著改進，並且特別是對於下一新疾病預測（P/R - 0.69/0.62 對 0.46/0.25）也有類似的改進。最後，在風險預測任務上，我們將我們的模型與 GPT-4-turbo（和一系列開源生物醫學 LLM）進行比較，並表明 FS2 在此類任務上表現顯著優於（P@5 - 0.90 對 0.65）。這突顯了將醫院數據納入 LLM 的必要性，並表明在針對高品質專門數據進行微調時，小型模型的表現優於大型模型。

##### **Generative AI: A Pix2pix-GAN-Based Machine Learning Approach for Robust and Efficient Lung Segmentation**
2412.10826v1 by Sharmin Akter

Chest radiography is climacteric in identifying different pulmonary diseases,
yet radiologist workload and inefficiency can lead to misdiagnoses. Automatic,
accurate, and efficient segmentation of lung from X-ray images of chest is
paramount for early disease detection. This study develops a deep learning
framework using a Pix2pix Generative Adversarial Network (GAN) to segment
pulmonary abnormalities from CXR images. This framework's image preprocessing
and augmentation techniques were properly incorporated with a U-Net-inspired
generator-discriminator architecture. Initially, it loaded the CXR images and
manual masks from the Montgomery and Shenzhen datasets, after which
preprocessing and resizing were performed. A U-Net generator is applied to the
processed CXR images that yield segmented masks; then, a Discriminator Network
differentiates between the generated and real masks. Montgomery dataset served
as the model's training set in the study, and the Shenzhen dataset was used to
test its robustness, which was used here for the first time. An adversarial
loss and an L1 distance were used to optimize the model in training. All
metrics, which assess precision, recall, F1 score, and Dice coefficient, prove
the effectiveness of this framework in pulmonary abnormality segmentation. It,
therefore, sets the basis for future studies to be performed shortly using
diverse datasets that could further confirm its clinical applicability in
medical imaging.

摘要：胸部 X 光攝影在辨識不同的肺部疾病中具有決定性，然而放射科醫師的工作負擔和效率不彰可能會導致誤診。自動、準確且有效率地從胸部 X 光影像中分割出肺部，對於早期疾病偵測至關重要。本研究開發一個深度學習架構，使用 Pix2pix 生成對抗網路 (GAN) 從 CXR 影像中分割出肺部異常。此架構的影像前處理和擴充技術與一個受 U-Net 啟發的生成器-判別器架構適當地整合。最初，它載入 CXR 影像和 Montgomery 及深圳資料集的手動遮罩，之後執行前處理和調整大小。將 U-Net 生成器應用於已處理的 CXR 影像，產生分割遮罩；然後，判別器網路區分生成的遮罩和真實遮罩。Montgomery 資料集作為本研究模型的訓練集，而深圳資料集用於測試其穩健性，這是首次使用於此。對抗損失和 L1 距離用於在訓練中最佳化模型。所有評估精準度、召回率、F1 分數和 Dice 係數的指標都證明此架構在肺部異常分割中的有效性。因此，它為不久後使用更多元資料集進行的未來研究奠定基礎，這些研究進一步確認其在醫學影像中的臨床適用性。

##### **Medical Manifestation-Aware De-Identification**
2412.10804v1 by Yuan Tian, Shuo Wang, Guangtao Zhai

Face de-identification (DeID) has been widely studied for common scenes, but
remains under-researched for medical scenes, mostly due to the lack of
large-scale patient face datasets. In this paper, we release MeMa, consisting
of over 40,000 photo-realistic patient faces. MeMa is re-generated from massive
real patient photos. By carefully modulating the generation and data-filtering
procedures, MeMa avoids breaching real patient privacy, while ensuring rich and
plausible medical manifestations. We recruit expert clinicians to annotate MeMa
with both coarse- and fine-grained labels, building the first medical-scene
DeID benchmark. Additionally, we propose a baseline approach for this new
medical-aware DeID task, by integrating data-driven medical semantic priors
into the DeID procedure. Despite its conciseness and simplicity, our approach
substantially outperforms previous ones. Dataset is available at
https://github.com/tianyuan168326/MeMa-Pytorch.

摘要：人脸去識別 (DeID) 已被廣泛研究用於常見場景，但
對於醫療場景的研究仍然不足，主要是由於缺乏
大規模的患者人臉數據集。在本文中，我們發布了 MeMa，其中
包含超過 40,000 張逼真的患者人臉。MeMa 是從大量的
真實患者照片中重新生成的。通過仔細調節生成和數據過濾
程序，MeMa 避免侵犯真實患者的隱私，同時確保豐富且
合理的醫療表現。我們招募專家臨床醫生為 MeMa 添加粗略和精細標籤，建立第一個醫療場景
DeID 基準。此外，我們提出了一種針對此新的
醫療感知 DeID 任務的基線方法，通過將數據驅動的醫療語義先驗
整合到 DeID 程序中。儘管簡潔且簡單，但我們的做法
大幅優於先前的做法。數據集可在
https://github.com/tianyuan168326/MeMa-Pytorch 中獲得。

##### **Rapid Reconstruction of Extremely Accelerated Liver 4D MRI via Chained Iterative Refinement**
2412.10629v1 by Di Xu, Xin Miao, Hengjie Liu, Jessica E. Scholey, Wensha Yang, Mary Feng, Michael Ohliger, Hui Lin, Yi Lao, Yang Yang, Ke Sheng

Abstract Purpose: High-quality 4D MRI requires an impractically long scanning
time for dense k-space signal acquisition covering all respiratory phases.
Accelerated sparse sampling followed by reconstruction enhancement is desired
but often results in degraded image quality and long reconstruction time. We
hereby propose the chained iterative reconstruction network (CIRNet) for
efficient sparse-sampling reconstruction while maintaining clinically
deployable quality. Methods: CIRNet adopts the denoising diffusion
probabilistic framework to condition the image reconstruction through a
stochastic iterative denoising process. During training, a forward Markovian
diffusion process is designed to gradually add Gaussian noise to the densely
sampled ground truth (GT), while CIRNet is optimized to iteratively reverse the
Markovian process from the forward outputs. At the inference stage, CIRNet
performs the reverse process solely to recover signals from noise, conditioned
upon the undersampled input. CIRNet processed the 4D data (3D+t) as temporal
slices (2D+t). The proposed framework is evaluated on a data cohort consisting
of 48 patients (12332 temporal slices) who underwent free-breathing liver 4D
MRI. 3-, 6-, 10-, 20- and 30-times acceleration were examined with a
retrospective random undersampling scheme. Compressed sensing (CS)
reconstruction with a spatiotemporal constraint and a recently proposed deep
network, Re-Con-GAN, are selected as baselines. Results: CIRNet consistently
achieved superior performance compared to CS and Re-Con-GAN. The inference time
of CIRNet, CS, and Re-Con-GAN are 11s, 120s, and 0.15s. Conclusion: A novel
framework, CIRNet, is presented. CIRNet maintains useable image quality for
acceleration up to 30 times, significantly reducing the burden of 4DMRI.

摘要：<paragraph>摘要目的：高品質 4D MRI 需要極不切實際的長時間掃描，才能獲得涵蓋所有呼吸階段的密集 k 空間訊號。加速稀疏取樣後再進行重建增強固然理想，但通常會導致影像品質下降，且重建時間過長。在此，我們提出鏈式反覆重建網路 (CIRNet)，以在維持臨床可部署品質的同時，進行有效率的稀疏取樣重建。方法：CIRNet 採用去噪擴散機率架構，透過隨機反覆去噪程序，對影像重建進行條件化。在訓練期間，正向馬可夫擴散程序會逐漸將高斯雜訊加入密集取樣的真實值 (GT) 中，而 CIRNet 則最佳化，以反覆逆轉正向輸出的馬可夫程序。在推論階段，CIRNet 僅執行逆向程序，以從雜訊中復原訊號，並以欠取樣輸入為條件。CIRNet 將 4D 資料 (3D+t) 處理為時間切片 (2D+t)。所提出的架構在一個資料群組中進行評估，該群組包含 48 位接受自由呼吸肝臟 4D MRI 的患者 (12332 個時間切片)。使用回溯隨機欠取樣方案，檢查 3、6、10、20 和 30 倍加速。選擇具有時空約束的壓縮感測 (CS) 重建和最近提出的深度網路 Re-Con-GAN 作為基準。結果：與 CS 和 Re-Con-GAN 相比，CIRNet 持續獲得較佳的效能。CIRNet、CS 和 Re-Con-GAN 的推論時間分別為 11 秒、120 秒和 0.15 秒。結論：提出了一個新穎的架構 CIRNet。CIRNet 可維持可用影像品質，加速率最高達 30 倍，大幅降低 4DMRI 的負擔。</paragraph>

##### **A recent evaluation on the performance of LLMs on radiation oncology physics using questions of randomly shuffled options**
2412.10622v1 by Peilong Wang, Jason Holmes, Zhengliang Liu, Dequan Chen, Tianming Liu, Jiajian Shen, Wei Liu

Purpose: We present an updated study evaluating the performance of large
language models (LLMs) in answering radiation oncology physics questions,
focusing on the latest released models.
  Methods: A set of 100 multiple-choice radiation oncology physics questions,
previously created by us, was used for this study. The answer options of the
questions were randomly shuffled to create "new" exam sets. Five LLMs -- OpenAI
o1-preview, GPT-4o, LLaMA 3.1 (405B), Gemini 1.5 Pro, and Claude 3.5 Sonnet --
with the versions released before September 30, 2024, were queried using these
new exams. To evaluate their deductive reasoning abilities, the correct answer
options in the questions were replaced with "None of the above." Then, the
explain-first and step-by-step instruction prompt was used to test if it
improved their reasoning abilities. The performance of the LLMs was compared to
medical physicists in majority-vote scenarios.
  Results: All models demonstrated expert-level performance on these questions,
with o1-preview even surpassing medical physicists in majority-vote scenarios.
When substituting the correct answer options with "None of the above," all
models exhibited a considerable decline in performance, suggesting room for
improvement. The explain-first and step-by-step instruction prompt helped
enhance the reasoning abilities of LLaMA 3.1 (405B), Gemini 1.5 Pro, and Claude
3.5 Sonnet models.
  Conclusion: These latest LLMs demonstrated expert-level performance in
answering radiation oncology physics questions, exhibiting great potential for
assisting in radiation oncology physics education.

摘要：<paragraph>目的：我们提出了一项更新的研究，评估大型语言模型 (LLM) 在回答放射肿瘤物理学问题方面的性能，重点关注最新发布的模型。
方法：我们之前创建的一组 100 道多项选择放射肿瘤物理学问题用于这项研究。问题的答案选项被随机打乱以创建“新”的考试集。五个 LLM——OpenAI o1-preview、GPT-4o、LLaMA 3.1 (405B)、Gemini 1.5 Pro 和 Claude 3.5 Sonnet——在 2024 年 9 月 30 日之前发布的版本中，使用这些新考试进行了查询。为了评估它们的演绎推理能力，问题中的正确答案选项被替换为“以上皆非”。然后，使用先解释和逐步说明的提示来测试它是否提高了它们的推理能力。LLM 的性能与大多数投票场景中的医学物理学家进行了比较。
结果：所有模型在这些问题上都表现出专家级性能，o1-preview 甚至在大多数投票场景中超过了医学物理学家。当用“以上皆非”替换正确的答案选项时，所有模型的性能都大幅下降，这表明有改进的空间。先解释和逐步说明的提示有助于增强 LLaMA 3.1 (405B)、Gemini 1.5 Pro 和 Claude 3.5 Sonnet 模型的推理能力。
结论：这些最新的 LLM 在回答放射肿瘤物理学问题方面表现出专家级性能，展示了在放射肿瘤物理学教育中提供帮助的巨大潜力。</paragraph>

##### **Generative AI in Medicine**
2412.10337v2 by Divya Shanmugam, Monica Agrawal, Rajiv Movva, Irene Y. Chen, Marzyeh Ghassemi, Maia Jacobs, Emma Pierson

The increased capabilities of generative AI have dramatically expanded its
possible use cases in medicine. We provide a comprehensive overview of
generative AI use cases for clinicians, patients, clinical trial organizers,
researchers, and trainees. We then discuss the many challenges -- including
maintaining privacy and security, improving transparency and interpretability,
upholding equity, and rigorously evaluating models -- which must be overcome to
realize this potential, and the open research directions they give rise to.

摘要：生成式 AI 功能的提升大幅擴展了其在醫學上的潛在用途。我們提供生成式 AI 使用案例的全面概述，適用於臨床醫生、患者、臨床試驗組織者、研究人員和受訓者。接著，我們討論許多挑戰，包括維護隱私和安全性、提升透明度和可解釋性、維護公平性，以及嚴格評估模型，這些挑戰必須克服才能實現此潛力，以及它們引發的開放式研究方向。

##### **A Cascaded Dilated Convolution Approach for Mpox Lesion Classification**
2412.10106v1 by Ayush Deshmukh

The global outbreak of Mpox virus, classified as a Public Health Emergency of
International Concern by WHO, presents significant diagnostic challenges due to
its visual similarity to other skin lesion diseases. Current clinical detection
techniques face limitations in accuracy and efficiency, necessitating improved
automated diagnostic solutions. This study introduces a novel Cascaded Atrous
Group Attention (CAGA) module, specifically designed to enhance multi-scale
feature representation while optimizing computational efficiency. By
integrating CAGA with EfficientViT-L1 as the backbone architecture, our
approach achieves state-of-the-art performance with a score of 0.98% on the
MCSI dataset, while reducing model parameters by 37.5% compared to the original
EfficientViT-L1. This reduction in computational complexity maintains
diagnostic accuracy while enabling broader deployment across
resource-constrained healthcare settings. Extensive validation across two other
benchmark datasets, including MSID and MSLD, demonstrate the model's
robustness, consistently outperforming existing approaches. Our findings
suggest that CAGA's efficient feature extraction mechanism could be adapted for
other medical imaging tasks requiring fine-grained visual discrimination.

摘要：由於世界衛生組織將猴痘病毒全球爆發定為國際關注的公共衛生緊急事件，因此猴痘病毒與其他皮膚病變疾病在視覺上的相似性，對診斷帶來重大挑戰。目前的臨床檢測技術在準確性和效率方面面臨限制，因此需要改進的自動化診斷解決方案。本研究引入了一個新穎的串聯空洞組注意力 (CAGA) 模組，專門設計用於增強多尺度特徵表示，同時最佳化運算效率。透過將 CAGA 與 EfficientViT-L1 整合作為主幹架構，我們的做法在 MCSI 資料集上以 0.98% 的分數達到了最先進的效能，同時與原始 EfficientViT-L1 相比，模型參數減少了 37.5%。這種運算複雜度的降低維持了診斷準確性，同時支援在資源受限的醫療保健環境中更廣泛地部署。在包括 MSID 和 MSLD 在內的另外兩個基準資料集上的廣泛驗證證明了模型的穩健性，始終優於現有方法。我們的研究結果表明，CAGA 的高效特徵提取機制可以調整為其他需要細緻視覺辨別的醫學影像任務。

##### **Script-Based Dialog Policy Planning for LLM-Powered Conversational Agents: A Basic Architecture for an "AI Therapist"**
2412.15242v1 by Robert Wasenmüller, Kevin Hilbert, Christoph Benzmüller

Large Language Model (LLM)-Powered Conversational Agents have the potential
to provide users with scaled behavioral healthcare support, and potentially
even deliver full-scale "AI therapy'" in the future. While such agents can
already conduct fluent and proactive emotional support conversations, they
inherently lack the ability to (a) consistently and reliably act by predefined
rules to align their conversation with an overarching therapeutic concept and
(b) make their decision paths inspectable for risk management and clinical
evaluation -- both essential requirements for an "AI Therapist".
  In this work, we introduce a novel paradigm for dialog policy planning in
conversational agents enabling them to (a) act according to an expert-written
"script" that outlines the therapeutic approach and (b) explicitly transition
through a finite set of states over the course of the conversation. The script
acts as a deterministic component, constraining the LLM's behavior in desirable
ways and establishing a basic architecture for an AI Therapist.
  We implement two variants of Script-Based Dialog Policy Planning using
different prompting techniques and synthesize a total of 100 conversations with
LLM-simulated patients. The results demonstrate the feasibility of this new
technology and provide insights into the efficiency and effectiveness of
different implementation variants.

摘要：大型語言模型 (LLM) 驅動的對話代理程式具有提供使用者規模化的行為保健支援的潛力，甚至有可能在未來提供全面的「AI 治療」。雖然此類代理程式已經可以進行流暢且主動的情緒支持對話，但它們本質上缺乏 (a) 根據預定義規則一致且可靠地採取行動，以使對話與整體治療概念保持一致，以及 (b) 使其決策路徑可供風險管理和臨床評估檢查，而這兩者都是「AI 治療師」的基本要求。
在這項工作中，我們引入了對話代理程式中的對話政策規劃的新範例，使它們能夠 (a) 根據專家撰寫的「腳本」採取行動，該腳本概述了治療方法，以及 (b) 在對話過程中明確地轉換有限的狀態集。腳本作為一個確定性組成部分，以合適的方式約束 LLM 的行為，並為 AI 治療師建立一個基本架構。
我們使用不同的提示技術實作了基於腳本的對話政策規劃的兩個變體，並與 LLM 模擬的患者合成了總共 100 場對話。結果證明了這項新技術的可行性，並提供了對不同實作變體的效率和有效性的見解。

##### **Cycle-Consistent Bridge Diffusion Model for Accelerated MRI Reconstruction**
2412.09998v1 by Tao Song, Yicheng Wu, Minhao Hu, Xiangde Luo, Guoting Luo, Guotai Wang, Yi Guo, Feng Xu, Shaoting Zhang

Accelerated MRI reconstruction techniques aim to reduce examination time
while maintaining high image fidelity, which is highly desirable in clinical
settings for improving patient comfort and hospital efficiency. Existing deep
learning methods typically reconstruct images from under-sampled data with
traditional reconstruction approaches, but they still struggle to provide
high-fidelity results. Diffusion models show great potential to improve
fidelity of generated images in recent years. However, their inference process
starting with a random Gaussian noise introduces instability into the results
and usually requires thousands of sampling steps, resulting in sub-optimal
reconstruction quality and low efficiency. To address these challenges, we
propose Cycle-Consistent Bridge Diffusion Model (CBDM). CBDM employs two bridge
diffusion models to construct a cycle-consistent diffusion process with a
consistency loss, enhancing the fine-grained details of reconstructed images
and reducing the number of diffusion steps. Moreover, CBDM incorporates a
Contourlet Decomposition Embedding Module (CDEM) which captures multi-scale
structural texture knowledge in images through frequency domain decomposition
pyramids and directional filter banks to improve structural fidelity. Extensive
experiments demonstrate the superiority of our model by higher reconstruction
quality and fewer training iterations, achieving a new state of the art for
accelerated MRI reconstruction in both fastMRI and IXI datasets.

摘要：加速式 MRI 重建技術旨在縮短檢查時間，同時維持高影像保真度，這在臨床環境中非常理想，可提升病患舒適度和醫院效率。現有的深度學習方法通常使用傳統重建方法從欠採樣數據重建影像，但仍難以提供高保真度結果。擴散模型在近年展現出提升生成影像保真度的絕佳潛力。然而，其從隨機高斯雜訊開始的推論過程會為結果帶來不穩定性，且通常需要數千個採樣步驟，導致次最佳重建品質和低效率。為了應對這些挑戰，我們提出循環一致橋接擴散模型 (CBDM)。CBDM 使用兩個橋接擴散模型，建構一個具有相容性損失的循環一致擴散過程，增強重建影像的精細細節並減少擴散步驟的數量。此外，CBDM 整合了一個輪廓分解嵌入模組 (CDEM)，透過頻域分解金字塔和方向濾波器組在影像中擷取多尺度結構紋理知識，以提升結構保真度。廣泛的實驗證明了我們模型的優異性，具有更高的重建品質和更少的訓練反覆運算，在 fastMRI 和 IXI 資料集的加速式 MRI 重建中達成新的技術水準。

##### **Enhancing Nursing and Elderly Care with Large Language Models: An AI-Driven Framework**
2412.09946v1 by Qiao Sun, Jiexin Xie, Nanyang Ye, Qinying Gu, Shijie Guo

This paper explores the application of large language models (LLMs) in
nursing and elderly care, focusing on AI-driven patient monitoring and
interaction. We introduce a novel Chinese nursing dataset and implement
incremental pre-training (IPT) and supervised fine-tuning (SFT) techniques to
enhance LLM performance in specialized tasks. Using LangChain, we develop a
dynamic nursing assistant capable of real-time care and personalized
interventions. Experimental results demonstrate significant improvements,
paving the way for AI-driven solutions to meet the growing demands of
healthcare in aging populations.

摘要：本文探討大型語言模型 (LLM) 在護理和老年照護中的應用，重點在於 AI 驅動的病人監控和互動。我們引入了一個新穎的中文護理資料集，並實施增量預訓練 (IPT) 和監督微調 (SFT) 技術，以增強 LLM 在專業任務中的表現。使用 LangChain，我們開發了一個動態護理助理，能夠提供即時照護和個人化干預措施。實驗結果證明了顯著的改進，為 AI 驅動的解決方案鋪平了道路，以滿足老齡化人口對醫療保健日益增長的需求。

##### **Detecting Cognitive Impairment and Psychological Well-being among Older Adults Using Facial, Acoustic, Linguistic, and Cardiovascular Patterns Derived from Remote Conversations**
2412.14194v1 by Xiaofan Mu, Salman Seyedi, Iris Zheng, Zifan Jiang, Liu Chen, Bolaji Omofojoye, Rachel Hershenberg, Allan I. Levey, Gari D. Clifford, Hiroko H. Dodge, Hyeokhyen Kwon

INTRODUCTION: The aging society urgently requires scalable methods to monitor
cognitive decline and identify social and psychological factors indicative of
dementia risk in older adults. METHODS: Our machine learning models captured
facial, acoustic, linguistic, and cardiovascular features from 39 individuals
with normal cognition or Mild Cognitive Impairment derived from remote video
conversations and classified cognitive status, social isolation, neuroticism,
and psychological well-being. RESULTS: Our model could distinguish Clinical
Dementia Rating Scale of 0.5 (vs. 0) with 0.78 area under the receiver
operating characteristic curve (AUC), social isolation with 0.75 AUC,
neuroticism with 0.71 AUC, and negative affect scales with 0.79 AUC.
DISCUSSION: Our findings demonstrate the feasibility of remotely monitoring
cognitive status, social isolation, neuroticism, and psychological well-being.
Speech and language patterns were more useful for quantifying cognitive
impairment, whereas facial expression and cardiovascular patterns using remote
photoplethysmography were more useful for quantifying personality and
psychological well-being.

摘要：引言：老齡化社會迫切需要可擴充的方法來監控認知能力下降，並找出年長者中顯示出失智症風險的社會和心理因素。方法：我們的機器學習模型從 39 位認知正常或輕度認知障礙的個人中擷取了面部、聲音、語言和心血管特徵，這些特徵來自遠端視訊對話，並分類了認知狀態、社交孤立、神經質和心理健康。結果：我們的模型可以區分臨床失智評分量表 0.5（相對於 0），接收者操作特徵曲線（AUC）下的面積為 0.78，社交孤立的 AUC 為 0.75，神經質的 AUC 為 0.71，負面影響量表的 AUC 為 0.79。討論：我們的研究結果證明了遠端監控認知狀態、社交孤立、神經質和心理健康的可行性。語言和語言模式對於量化認知障礙更有用，而使用遠端光電容積描記術的面部表情和心血管模式對於量化人格和心理健康更有用。

##### **Efficient and Comprehensive Feature Extraction in Large Vision-Language Model for Clinical Pathology Analysis**
2412.09521v1 by Shengxuming Zhang, Weihan Li, Tianhong Gao, Jiacong Hu, Haoming Luo, Mingli Song, Xiuming Zhang, Zunlei Feng

Pathological diagnosis is vital for determining disease characteristics,
guiding treatment, and assessing prognosis, relying heavily on detailed,
multi-scale analysis of high-resolution whole slide images (WSI). However,
traditional pure vision models face challenges of redundant feature extraction,
whereas existing large vision-language models (LVLMs) are limited by input
resolution constraints, hindering their efficiency and accuracy. To overcome
these issues, we propose two innovative strategies: the mixed task-guided
feature enhancement, which directs feature extraction toward lesion-related
details across scales, and the prompt-guided detail feature completion, which
integrates coarse- and fine-grained features from WSI based on specific prompts
without compromising inference speed. Leveraging a comprehensive dataset of
490,000 samples from diverse pathology tasks-including cancer detection,
grading, vascular and neural invasion identification, and so on-we trained the
pathology-specialized LVLM, OmniPath. Extensive experiments demonstrate that
this model significantly outperforms existing methods in diagnostic accuracy
and efficiency, offering an interactive, clinically aligned approach for
auxiliary diagnosis in a wide range of pathology applications.

摘要：病理诊断对于确定疾病特征、指导治疗和评估预后至关重要，它严重依赖于对高分辨率全玻片图像 (WSI) 的详细、多尺度分析。然而，传统的纯视觉模型面临冗余特征提取的挑战，而现有的大型视觉语言模型 (LVLMs) 受到输入分辨率约束的限制，阻碍了它们的效率和准确性。为了克服这些问题，我们提出了两种创新策略：混合任务引导的特征增强，它将特征提取引导到跨尺度的病变相关细节上；以及提示引导的细节特征完成，它基于特定提示将 WSI 中的粗粒度和细粒度特征集成在一起，而不会影响推理速度。利用来自不同病理任务的 490,000 个样本的综合数据集，包括癌症检测、分级、血管和神经侵袭识别等，我们训练了病理学专业 LVLM，即 OmniPath。大量的实验表明，该模型在诊断准确性和效率方面明显优于现有方法，为广泛的病理学应用中的辅助诊断提供了一种交互式、临床上一致的方法。

##### **Towards a Multimodal Large Language Model with Pixel-Level Insight for Biomedicine**
2412.09278v1 by Xiaoshuang Huang, Lingdong Shen, Jia Liu, Fangxin Shang, Hongxiang Li, Haifeng Huang, Yehui Yang

In recent years, Multimodal Large Language Models (MLLM) have achieved
notable advancements, demonstrating the feasibility of developing an
intelligent biomedical assistant. However, current biomedical MLLMs
predominantly focus on image-level understanding and restrict interactions to
textual commands, thus limiting their capability boundaries and the flexibility
of usage. In this paper, we introduce a novel end-to-end multimodal large
language model for the biomedical domain, named MedPLIB, which possesses
pixel-level understanding. Excitingly, it supports visual question answering
(VQA), arbitrary pixel-level prompts (points, bounding boxes, and free-form
shapes), and pixel-level grounding. We propose a novel Mixture-of-Experts (MoE)
multi-stage training strategy, which divides MoE into separate training phases
for a visual-language expert model and a pixel-grounding expert model, followed
by fine-tuning using MoE. This strategy effectively coordinates multitask
learning while maintaining the computational cost at inference equivalent to
that of a single expert model. To advance the research of biomedical MLLMs, we
introduce the Medical Complex Vision Question Answering Dataset (MeCoVQA),
which comprises an array of 8 modalities for complex medical imaging question
answering and image region understanding. Experimental results indicate that
MedPLIB has achieved state-of-the-art outcomes across multiple medical visual
language tasks. More importantly, in zero-shot evaluations for the pixel
grounding task, MedPLIB leads the best small and large models by margins of
19.7 and 15.6 respectively on the mDice metric. The codes, data, and model
checkpoints will be made publicly available at
https://github.com/ShawnHuang497/MedPLIB.

摘要：<paragraph>近年来，多模态大型语言模型 (MLLM) 已取得显著进展，证明了开发智能生物医学助理的可行性。然而，当前的生物医学 MLLM 主要专注于图像级理解，并将交互限制在文本命令中，从而限制了它们的能力边界和使用灵活性。在本文中，我们介绍了一个用于生物医学领域的全新端到端多模态大型语言模型，名为 MedPLIB，它具有像素级理解能力。令人兴奋的是，它支持视觉问答 (VQA)、任意像素级提示（点、边界框和自由形式形状）以及像素级接地。我们提出了一种新颖的专家混合 (MoE) 多阶段训练策略，该策略将 MoE 分为视觉语言专家模型和像素接地专家模型的单独训练阶段，然后使用 MoE 进行微调。该策略有效地协调了多任务学习，同时将推理时的计算成本保持在与单个专家模型相当的水平。为了推进生物医学 MLLM 的研究，我们引入了医学复杂视觉问答数据集 (MeCoVQA)，它包含一系列 8 种用于复杂医学影像问答和图像区域理解的模态。实验结果表明，MedPLIB 在多个医学视觉语言任务中取得了最先进的成果。更重要的是，在像素接地任务的零样本评估中，MedPLIB 在 mDice 指标上分别以 19.7 和 15.6 的优势领先于最好的小型和大型模型。代码、数据和模型检查点将在 https://github.com/ShawnHuang497/MedPLIB 上公开。
</paragraph>

##### **CSSDH: An Ontology for Social Determinants of Health to Operational Continuity of Care Data Interoperability**
2412.09223v1 by Subhashis Das, Debashis Naskar, Sara Rodriguez Gonzalez

The rise of digital platforms has led to an increasing reliance on
technology-driven, home-based healthcare solutions, enabling individuals to
monitor their health and share information with healthcare professionals as
needed. However, creating an efficient care plan management system requires
more than just analyzing hospital summaries and Electronic Health Records
(EHRs). Factors such as individual user needs and social determinants of
health, including living conditions and the flow of healthcare information
between different settings, must also be considered. Challenges in this complex
healthcare network involve schema diversity (in EHRs, personal health records,
etc.) and terminology diversity (e.g., ICD, SNOMED-CT) across ancillary
healthcare operations. Establishing interoperability among various systems and
applications is crucial, with the European Interoperability Framework (EIF)
emphasizing the need for patient-centric access and control of healthcare data.
In this paper, we propose an integrated ontological model, the Common Semantic
Data Model for Social Determinants of Health (CSSDH), by combining ISO/DIS
13940:2024 ContSys with WHO Social Determinants of Health. CSSDH aims to
achieve interoperability within the Continuity of Care Network.

摘要：數位平台的興起導致愈來愈依賴科技驅動、居家醫療保健解決方案，讓個人得以監測自己的健康，並視需要與醫療保健專業人員分享資訊。然而，建立一個有效的照護計畫管理系統，需要的可不僅僅是分析醫院摘要和電子健康紀錄 (EHR) 而已。還必須考量個人使用者需求和健康的社會決定因素，包括生活條件和不同環境之間的醫療保健資訊流動。這個複雜的醫療保健網路中的挑戰，包括架構多樣性 (在 EHR、個人健康紀錄等) 和術語多樣性 (例如 ICD、SNOMED-CT) 等輔助醫療保健作業。在各種系統和應用程式之間建立互通性至關重要，歐洲互通性架構 (EIF) 強調需要以病人為中心存取和控制醫療保健資料。在本文中，我們提出一個整合的本體論模型，即結合 ISO/DIS 13940:2024 ContSys 與 WHO 健康社會決定因素的社會決定因素健康共同語義資料模型 (CSSDH)。CSSDH 旨在在照護連續性網路中達成互通性。

##### **Understanding Opportunities and Risks of Synthetic Relationships: Leveraging the Power of Longitudinal Research with Customised AI Tools**
2412.09086v1 by Alfio Ventura, Nils Köbis

This position paper discusses the benefits of longitudinal behavioural
research with customised AI tools for exploring the opportunities and risks of
synthetic relationships. Synthetic relationships are defined as "continuing
associations between humans and AI tools that interact with one another wherein
the AI tool(s) influence(s) humans' thoughts, feelings, and/or actions."
(Starke et al., 2024). These relationships can potentially improve health,
education, and the workplace, but they also bring the risk of subtle
manipulation and privacy and autonomy concerns. To harness the opportunities of
synthetic relationships and mitigate their risks, we outline a methodological
approach that complements existing findings. We propose longitudinal research
designs with self-assembled AI agents that enable the integration of detailed
behavioural and self-reported data.

摘要：本立場文件探討縱向行為研究與客製化 AI 工具的優點，用於探討合成關係的機會與風險。合成關係定義為「人類與 AI 工具之間持續的關聯，彼此互動，其中 AI 工具會影響人類的想法、感受和/或行為。」（Starke 等人，2024 年）。這些關係有可能改善健康、教育和職場，但它們也帶來微妙的操縱以及隱私和自主權的隱憂。為了利用合成關係的機會並降低其風險，我們概述了一種方法論方法，補充現有的發現。我們提出使用自組裝 AI 代理的縱向研究設計，使我們能夠整合詳細的行為和自我報告資料。

##### **An Interoperable Machine Learning Pipeline for Pediatric Obesity Risk Estimation**
2412.10454v1 by Hamed Fayyaz, Mehak Gupta, Alejandra Perez Ramirez, Claudine Jurkovitz, H. Timothy Bunnell, Thao-Ly T. Phan, Rahmatollah Beheshti

Reliable prediction of pediatric obesity can offer a valuable resource to
providers, helping them engage in timely preventive interventions before the
disease is established. Many efforts have been made to develop ML-based
predictive models of obesity, and some studies have reported high predictive
performances. However, no commonly used clinical decision support tool based on
existing ML models currently exists. This study presents a novel end-to-end
pipeline specifically designed for pediatric obesity prediction, which supports
the entire process of data extraction, inference, and communication via an API
or a user interface. While focusing only on routinely recorded data in
pediatric electronic health records (EHRs), our pipeline uses a diverse
expert-curated list of medical concepts to predict the 1-3 years risk of
developing obesity. Furthermore, by using the Fast Healthcare Interoperability
Resources (FHIR) standard in our design procedure, we specifically target
facilitating low-effort integration of our pipeline with different EHR systems.
In our experiments, we report the effectiveness of the predictive model as well
as its alignment with the feedback from various stakeholders, including ML
scientists, providers, health IT personnel, health administration
representatives, and patient group representatives.

摘要：可靠的儿童肥胖预测可以为提供者提供宝贵的资源，帮助他们在疾病确立之前及时进行预防性干预。已经为开发基于 ML 的肥胖预测模型做出了许多努力，一些研究报告了较高的预测性能。然而，目前尚不存在基于现有 ML 模型的常用临床决策支持工具。本研究提出了一种专门设计用于儿童肥胖预测的新型端到端管道，它支持通过 API 或用户界面进行数据提取、推理和通信的整个过程。虽然仅关注儿科电子健康记录 (EHR) 中常规记录的数据，但我们的管道使用由专家策划的各种医学概念列表来预测 1-3 年内发生肥胖的风险。此外，通过在我们的设计程序中使用快速医疗互操作性资源 (FHIR) 标准，我们专门针对促进我们的管道与不同 EHR 系统的低成本集成。在我们的实验中，我们报告了预测模型的有效性以及它与包括 ML 科学家、提供者、健康 IT 人员、健康管理代表和患者群体代表在内的各种利益相关者的反馈的一致性。

##### **Structurally Consistent MRI Colorization using Cross-modal Fusion Learning**
2412.10452v1 by Mayuri Mathur, Anav Chaudhary, Saurabh Kumar Gupta, Ojaswa Sharma

Medical image colorization can greatly enhance the interpretability of the
underlying imaging modality and provide insights into human anatomy. The
objective of medical image colorization is to transfer a diverse spectrum of
colors distributed across human anatomy from Cryosection data to source MRI
data while retaining the structures of the MRI. To achieve this, we propose a
novel architecture for structurally consistent color transfer to the source MRI
data. Our architecture fuses segmentation semantics of Cryosection images for
stable contextual colorization of various organs in MRI images. For
colorization, we neither require precise registration between MRI and
Cryosection images, nor segmentation of MRI images. Additionally, our
architecture incorporates a feature compression-and-activation mechanism to
capture organ-level global information and suppress noise, enabling the
distinction of organ-specific data in MRI scans for more accurate and realistic
organ-specific colorization. Our experiments demonstrate that our architecture
surpasses the existing methods and yields better quantitative and qualitative
results.

摘要：醫學影像著色能大幅提升基礎影像模式的可解讀性，並提供人類解剖學的見解。醫學影像著色的目標是將分布在人類解剖學中、來自冷凍切片資料的各種色彩光譜轉移到原始 MRI 資料，同時保留 MRI 的結構。為達成此目標，我們提出一個結構一致色彩轉移到原始 MRI 資料的新穎架構。我們的架構融合冷凍切片影像的分割語義，以穩定著色 MRI 影像中各種器官的色彩。在著色時，我們既不需要 MRI 與冷凍切片影像之間精確的配準，也不需要 MRI 影像的分割。此外，我們的架構納入一個特徵壓縮和啟動機制，以擷取器官層級的整體資訊並抑制雜訊，讓 MRI 掃描中器官特定資料的區別更精確且逼真，進而進行器官特定著色。我們的實驗證明，我們的架構優於現有方法，並產生更好的量化和質化結果。

##### **CareBot: A Pioneering Full-Process Open-Source Medical Language Model**
2412.15236v1 by Lulu Zhao, Weihao Zeng, Xiaofeng Shi, Hua Zhou

Recently, both closed-source LLMs and open-source communities have made
significant strides, outperforming humans in various general domains. However,
their performance in specific professional domains such as medicine, especially
within the open-source community, remains suboptimal due to the complexity of
medical knowledge. In this paper, we propose CareBot, a bilingual medical LLM,
which leverages a comprehensive approach integrating continuous pre-training
(CPT), supervised fine-tuning (SFT), and reinforcement learning with human
feedback (RLHF). Our novel two-stage CPT method, comprising Stable CPT and
Boost CPT, effectively bridges the gap between general and domain-specific
data, facilitating a smooth transition from pre-training to fine-tuning and
enhancing domain knowledge progressively. We also introduce DataRater, a model
designed to assess data quality during CPT, ensuring that the training data is
both accurate and relevant. For SFT, we develope a large and diverse bilingual
dataset, along with ConFilter, a metric to enhance multi-turn dialogue quality,
which is crucial to improving the model's ability to handle more complex
dialogues. The combination of high-quality data sources and innovative
techniques significantly improves CareBot's performance across a range of
medical applications. Our rigorous evaluations on Chinese and English
benchmarks confirm CareBot's effectiveness in medical consultation and
education. These advancements not only address current limitations in medical
LLMs but also set a new standard for developing effective and reliable
open-source models in the medical domain. We will open-source the datasets and
models later, contributing valuable resources to the research community.

摘要：<paragraph>最近，閉源 LLM 和開源社群都取得顯著進展，在各種一般領域中表現優於人類。然而，由於醫學知識的複雜性，它們在特定專業領域（例如醫學）中的表現，特別是在開源社群中，仍然不理想。在本文中，我們提出 CareBot，一個雙語醫療 LLM，它利用一種綜合方法，整合了持續預訓練 (CPT)、監督微調 (SFT) 和帶有人類回饋的強化學習 (RLHF)。我們新穎的兩階段 CPT 方法，包括穩定 CPT 和提升 CPT，有效地彌合了通用資料和特定領域資料之間的差距，促成了從預訓練到微調的平穩過渡，並逐步增強領域知識。我們還引入了 DataRater，這是一個模型，旨在評估 CPT 期間的資料品質，確保訓練資料既準確又相關。對於 SFT，我們開發了一個大型且多樣化的雙語資料集，以及 ConFilter，這是一個用於增強多輪對話品質的指標，這對於提高模型處理更複雜對話的能力至關重要。高品質資料來源和創新技術的結合，顯著提升了 CareBot 在一系列醫療應用中的表現。我們對中文和英文基準的嚴格評估，證實了 CareBot 在醫療諮詢和教育方面的有效性。這些進展不僅解決了當前醫療 LLM 的限制，也為在醫療領域開發有效且可靠的開源模型設定了新的標準。我們稍後將開放資料集和模型的原始碼，為研究社群貢獻寶貴的資源。</paragraph>

##### **Radiology Report Generation via Multi-objective Preference Optimization**
2412.08901v2 by Ting Xiao, Lei Shi, Peng Liu, Zhe Wang, Chenjia Bai

Automatic Radiology Report Generation (RRG) is an important topic for
alleviating the substantial workload of radiologists. Existing RRG approaches
rely on supervised regression based on different architectures or additional
knowledge injection,while the generated report may not align optimally with
radiologists' preferences. Especially, since the preferences of radiologists
are inherently heterogeneous and multidimensional, e.g., some may prioritize
report fluency, while others emphasize clinical accuracy. To address this
problem,we propose a new RRG method via Multi-objective Preference Optimization
(MPO) to align the pre-trained RRG model with multiple human preferences, which
can be formulated by multi-dimensional reward functions and optimized by
multi-objective reinforcement learning (RL). Specifically, we use a preference
vector to represent the weight of preferences and use it as a condition for the
RRG model. Then, a linearly weighed reward is obtained via a dot product
between the preference vector and multi-dimensional reward. Next,the RRG model
is optimized to align with the preference vector by optimizing such a reward
via RL. In the training stage,we randomly sample diverse preference vectors
from the preference space and align the model by optimizing the weighted
multi-objective rewards, which leads to an optimal policy on the entire
preference space. When inference,our model can generate reports aligned with
specific preferences without further fine-tuning. Extensive experiments on two
public datasets show the proposed method can generate reports that cater to
different preferences in a single model and achieve state-of-the-art
performance.

摘要：自動放射報告生成 (RRG) 是減輕放射科醫師大量工作負擔的重要議題。現有的 RRG 方法仰賴基於不同架構或額外知識注入的監督式回歸，而產生的報告可能無法最佳地符合放射科醫師的偏好。特別是，由於放射科醫師的偏好本質上是異質且多面向的，例如，有些人可能優先考慮報告的流暢度，而另一些人則強調臨床準確性。為了解決這個問題，我們透過多目標偏好最佳化 (MPO) 提出一個新的 RRG 方法，以將預先訓練的 RRG 模型與多個人類偏好對齊，這可以用多維獎勵函數來制定，並透過多目標強化學習 (RL) 來最佳化。具體來說，我們使用偏好向量來表示偏好的權重，並將其用作 RRG 模型的條件。然後，透過偏好向量和多維獎勵之間的點積，獲得線性加權獎勵。接下來，透過 RL 最佳化此類獎勵，最佳化 RRG 模型以與偏好向量對齊。在訓練階段，我們從偏好空間中隨機取樣不同的偏好向量，並透過最佳化加權的多目標獎勵來對齊模型，這會產生整個偏好空間的最佳策略。在推論時，我們的模型可以生成與特定偏好對齊的報告，而無需進一步微調。在兩個公開資料集上的廣泛實驗顯示，所提出的方法可以在單一模型中生成迎合不同偏好的報告，並達到最先進的效能。

##### **AI-assisted Knowledge Discovery in Biomedical Literature to Support Decision-making in Precision Oncology**
2412.08900v1 by Ting He, Kory Kreimeyer, Mimi Najjar, Jonathan Spiker, Maria Fatteh, Valsamo Anagnostou, Taxiarchis Botsis

The delivery of appropriate targeted therapies to cancer patients requires
the complete analysis of the molecular profiling of tumors and the patient's
clinical characteristics in the context of existing knowledge and recent
findings described in biomedical literature and several other sources. We
evaluated the potential contributions of specific natural language processing
solutions to support knowledge discovery from biomedical literature. Two models
from the Bidirectional Encoder Representations from Transformers (BERT) family,
two Large Language Models, and PubTator 3.0 were tested for their ability to
support the named entity recognition (NER) and the relation extraction (RE)
tasks. PubTator 3.0 and the BioBERT model performed best in the NER task (best
F1-score equal to 0.93 and 0.89, respectively), while BioBERT outperformed all
other solutions in the RE task (best F1-score 0.79) and a specific use case it
was applied to by recognizing nearly all entity mentions and most of the
relations.

摘要：適當標靶療法在癌症病患的應用，需要在現有知識和生物醫學文獻中所描述的最新發現的脈絡下，完整分析腫瘤的分子特徵和病患的臨床特徵。我們評估了特定自然語言處理解決方案在支援從生物醫學文獻中發現知識的潛在貢獻。我們測試了來自 Transformer 雙向編碼器表示法 (BERT) 家族的兩個模型、兩個大型語言模型和 PubTator 3.0，以評估它們支援命名實體辨識 (NER) 和關係萃取 (RE) 任務的能力。PubTator 3.0 和 BioBERT 模型在 NER 任務中表現最佳（最佳 F1 分數分別為 0.93 和 0.89），而 BioBERT 在 RE 任務中優於所有其他解決方案（最佳 F1 分數為 0.79），並且在一個特定的應用案例中，它幾乎辨識出所有實體提及和大部分關係。

##### **Towards modeling evolving longitudinal health trajectories with a transformer-based deep learning model**
2412.08873v1 by Hans Moen, Vishnu Raj, Andrius Vabalas, Markus Perola, Samuel Kaski, Andrea Ganna, Pekka Marttinen

Health registers contain rich information about individuals' health
histories. Here our interest lies in understanding how individuals' health
trajectories evolve in a nationwide longitudinal dataset with coded features,
such as clinical codes, procedures, and drug purchases. We introduce a
straightforward approach for training a Transformer-based deep learning model
in a way that lets us analyze how individuals' trajectories change over time.
This is achieved by modifying the training objective and by applying a causal
attention mask. We focus here on a general task of predicting the onset of a
range of common diseases in a given future forecast interval. However, instead
of providing a single prediction about diagnoses that could occur in this
forecast interval, our approach enable the model to provide continuous
predictions at every time point up until, and conditioned on, the time of the
forecast period. We find that this model performs comparably to other models,
including a bi-directional transformer model, in terms of basic prediction
performance while at the same time offering promising trajectory modeling
properties. We explore a couple of ways to use this model for analyzing health
trajectories and aiding in early detection of events that forecast possible
later disease onsets. We hypothesize that this method may be helpful in
continuous monitoring of peoples' health trajectories and enabling
interventions in ongoing health trajectories, as well as being useful in
retrospective analyses.

摘要：健康登記包含個人健康史的豐富資訊。我們在此有興趣了解個人健康軌跡如何隨著編碼功能（例如臨床代碼、程序和藥物購買）在全國縱向資料集中演變。我們引入一種直接的方法，用於訓練 Transformer 為基礎的深度學習模型，讓我們分析個人軌跡如何隨著時間推移而改變。這是透過修改訓練目標並應用因果注意力遮罩來實現的。我們在此專注於預測在給定未來預測區間內一系列常見疾病發病的一般任務。然而，我們的做法並非提供關於可能在此預測區間內發生的診斷的單一預測，而是讓模型能夠在每個時間點提供連續預測，直到預測期間的時間，並以其為條件。我們發現此模型的表現與其他模型（包括雙向 Transformer 模型）相當，在基本預測效能方面如此，同時提供有希望的軌跡建模屬性。我們探索了幾種使用此模型分析健康軌跡並協助早期偵測預測可能後續發病事件的方法。我們假設此方法可能有助於持續監測個人健康軌跡，並讓干預措施得以在持續的健康軌跡中進行，且在回顧性分析中也很有用。

##### **Performance of a large language model-Artificial Intelligence based chatbot for counseling patients with sexually transmitted infections and genital diseases**
2412.12166v1 by Nikhil Mehta, Sithira Ambepitiya, Thanveer Ahamad, Dinuka Wijesundara, Yudara Kularathne

Introduction: Global burden of sexually transmitted infections (STIs) is
rising out of proportion to specialists. Current chatbots like ChatGPT are not
tailored for handling STI-related concerns out of the box. We developed Otiz,
an Artificial Intelligence-based (AI-based) chatbot platform designed
specifically for STI detection and counseling, and assessed its performance.
Methods: Otiz employs a multi-agent system architecture based on GPT4-0613,
leveraging large language model (LLM) and Deterministic Finite Automaton
principles to provide contextually relevant, medically accurate, and empathetic
responses. Its components include modules for general STI information,
emotional recognition, Acute Stress Disorder detection, and psychotherapy. A
question suggestion agent operates in parallel. Four STIs (anogenital warts,
herpes, syphilis, urethritis/cervicitis) and 2 non-STIs (candidiasis, penile
cancer) were evaluated using prompts mimicking patient language. Each prompt
was independently graded by two venereologists conversing with Otiz as patient
actors on 6 criteria using Numerical Rating Scale ranging from 0 (poor) to 5
(excellent). Results: Twenty-three venereologists did 60 evaluations of 30
prompts. Across STIs, Otiz scored highly on diagnostic accuracy (4.1-4.7),
overall accuracy (4.3-4.6), correctness of information (5.0), comprehensibility
(4.2-4.4), and empathy (4.5-4.8). However, relevance scores were lower
(2.9-3.6), suggesting some redundancy. Diagnostic scores for non-STIs were
lower (p=0.038). Inter-observer agreement was strong, with differences greater
than 1 point occurring in only 12.7% of paired evaluations. Conclusions: AI
conversational agents like Otiz can provide accurate, correct, discrete,
non-judgmental, readily accessible and easily understandable STI-related
information in an empathetic manner, and can alleviate the burden on healthcare
systems.

摘要：<paragraph>引言：全球性傳染感染（STI）的負擔與專家不成比例地增加。現有的聊天機器人，例如 ChatGPT，並非為了處理與 STI 相關的疑慮而量身打造。我們開發了 Otiz，一個基於人工智慧（AI）的聊天機器人平台，專門設計用於 STI 檢測和諮詢，並評估其效能。
方法：Otiz 採用基於 GPT4-0613 的多代理系統架構，利用大型語言模型（LLM）和確定有限自動機原則，提供與脈絡相關、醫學上準確且富有同理心的回應。其元件包括一般 STI 資訊、情緒辨識、急性壓力疾患檢測和心理治療模組。一個問題建議代理會並行運作。使用模擬患者語言的提示，評估了四種 STI（肛門生殖器疣、疱疹、梅毒、尿道炎/子宮頸炎）和兩種非 STI（念珠菌病、陰莖癌）。每個提示由兩位泌尿科醫師獨立評分，他們以患者角色與 Otiz 對話，根據 0（差）到 5（極佳）的數值評分量表，針對六項標準進行評分。結果：23 位泌尿科醫師對 30 個提示進行了 60 次評估。在 STI 中，Otiz 在診斷準確性（4.1-4.7）、整體準確性（4.3-4.6）、資訊正確性（5.0）、可理解性（4.2-4.4）和同理心（4.5-4.8）方面得分很高。然而，相關性得分較低（2.9-3.6），表示有些冗餘。非 STI 的診斷得分較低（p=0.038）。觀察者間的一致性很強，只有 12.7% 的配對評估中出現大於 1 分的差異。結論：像 Otiz 這樣的 AI 對話代理程式可以提供準確、正確、離散、不帶評判、易於取得且易於理解的 STI 相關資訊，並以同理心的方式，減輕醫療系統的負擔。</paragraph>

##### **Multimodal Approaches to Fair Image Classification: An Ethical Perspective**
2412.12165v1 by Javon Hickmon

In the rapidly advancing field of artificial intelligence, machine perception
is becoming paramount to achieving increased performance. Image classification
systems are becoming increasingly integral to various applications, ranging
from medical diagnostics to image generation; however, these systems often
exhibit harmful biases that can lead to unfair and discriminatory outcomes.
Machine Learning systems that depend on a single data modality, i.e. only
images or only text, can exaggerate hidden biases present in the training data,
if the data is not carefully balanced and filtered. Even so, these models can
still harm underrepresented populations when used in improper contexts, such as
when government agencies reinforce racial bias using predictive policing. This
thesis explores the intersection of technology and ethics in the development of
fair image classification models. Specifically, I focus on improving fairness
and methods of using multiple modalities to combat harmful demographic bias.
Integrating multimodal approaches, which combine visual data with additional
modalities such as text and metadata, allows this work to enhance the fairness
and accuracy of image classification systems. The study critically examines
existing biases in image datasets and classification algorithms, proposes
innovative methods for mitigating these biases, and evaluates the ethical
implications of deploying such systems in real-world scenarios. Through
comprehensive experimentation and analysis, the thesis demonstrates how
multimodal techniques can contribute to more equitable and ethical AI
solutions, ultimately advocating for responsible AI practices that prioritize
fairness.

摘要：在快速发展的 AI 領域中，機器感知正成為提升效能的關鍵。影像分類系統正逐漸成為各種應用程式中不可或缺的一部分，從醫療診斷到影像產生皆有涵蓋；然而，這些系統經常展現出有害的偏見，可能導致不公平且有歧視性的結果。機器學習系統依賴單一資料型態，例如僅有影像或僅有文字，可能會誇大訓練資料中隱藏的偏見，如果資料未經過仔細平衡及篩選的話。即使如此，當這些模型用於不適當的情境中時，例如政府機構使用預測警務來加強種族偏見，仍然可能傷害到少數族群。本論文探討技術與倫理在開發公平影像分類模型中的交集。具體來說，我專注於改善公平性，以及使用多種型態來對抗有害的人口統計偏見的方法。整合多模態方法，將視覺資料與其他型態（例如文字和元資料）結合，讓這項工作得以提升影像分類系統的公平性和準確性。本研究批判性地檢視影像資料集和分類演算法中現有的偏見，提出減輕這些偏見的創新方法，並評估在現實世界場景中部署此類系統的倫理意涵。透過全面的實驗和分析，本論文展示多模態技術如何能促成更公平且合乎倫理的 AI 解決方案，最終倡導以公平性為優先的負責任 AI 實務。

##### **Euclid: Supercharging Multimodal LLMs with Synthetic High-Fidelity Visual Descriptions**
2412.08737v1 by Jiarui Zhang, Ollie Liu, Tianyu Yu, Jinyi Hu, Willie Neiswanger

Multimodal large language models (MLLMs) have made rapid progress in recent
years, yet continue to struggle with low-level visual perception (LLVP) --
particularly the ability to accurately describe the geometric details of an
image. This capability is crucial for applications in areas such as robotics,
medical image analysis, and manufacturing. In this paper, we first introduce
Geoperception, a benchmark designed to evaluate an MLLM's ability to accurately
transcribe 2D geometric information from an image. Using this benchmark, we
demonstrate the limitations of leading MLLMs, and then conduct a comprehensive
empirical study to explore strategies for improving their performance on
geometric tasks. Our findings highlight the benefits of certain model
architectures, training techniques, and data strategies, including the use of
high-fidelity synthetic data and multi-stage training with a data curriculum.
Notably, we find that a data curriculum enables models to learn challenging
geometry understanding tasks which they fail to learn from scratch. Leveraging
these insights, we develop Euclid, a family of models specifically optimized
for strong low-level geometric perception. Although purely trained on synthetic
multimodal data, Euclid shows strong generalization ability to novel geometry
shapes. For instance, Euclid outperforms the best closed-source model,
Gemini-1.5-Pro, by up to 58.56% on certain Geoperception benchmark tasks and
10.65% on average across all tasks.

摘要：近幾年，多模態大型語言模型 (MLLM) 迅速進展，但仍持續與低階視覺感知 (LLVP) 奮戰，尤其是準確描述影像幾何細節的能力。此功能對於機器人、醫學影像分析和製造等領域的應用至關重要。在本文中，我們首先介紹 Geoperception，一個基準，旨在評估 MLLM 從影像準確轉錄 2D 幾何資訊的能力。使用此基準，我們展示了領先 MLLM 的限制，然後進行全面的實證研究，探討改善其在幾何任務上表現的策略。我們的研究結果突出了特定模型架構、訓練技術和資料策略的優點，包括使用高保真合成資料和具有資料課程的多階段訓練。值得注意的是，我們發現資料課程能讓模型學習他們無法從頭開始學習的具有挑戰性的幾何理解任務。利用這些見解，我們開發了 Euclid，一個專門針對強低階幾何感知而最佳化的模型家族。儘管純粹在合成多模態資料上訓練，但 Euclid 對新幾何形狀展現出強大的泛化能力。例如，Euclid 在某些 Geoperception 基準任務上比最佳閉源模型 Gemini-1.5-Pro 高出 58.56%，在所有任務上的平均表現高出 10.65%。

##### **Assisted morbidity coding: the SISCO.web use case for identifying the main diagnosis in Hospital Discharge Records**
2412.09651v1 by Elena Cardillo, Lucilla Frattura

Coding morbidity data using international standard diagnostic classifications
is increasingly important and still challenging. Clinical coders and physicians
assign codes to patient episodes based on their interpretation of case notes or
electronic patient records. Therefore, accurate coding relies on the legibility
of case notes and the coders' understanding of medical terminology. During the
last ten years, many studies have shown poor reproducibility of clinical
coding, even recently, with the application of Artificial Intelligence-based
models. Given this context, the paper aims to present the SISCO.web approach
designed to support physicians in filling in Hospital Discharge Records with
proper diagnoses and procedures codes using the International Classification of
Diseases (9th and 10th), and, above all, in identifying the main pathological
condition. The web service leverages NLP algorithms, specific coding rules, as
well as ad hoc decision trees to identify the main condition, showing promising
results in providing accurate ICD coding suggestions.

摘要：使用國際標準診斷分類對病態資料進行編碼越來越重要，但仍具有挑戰性。臨床編碼員和醫師根據他們對病例記錄或電子病歷的解讀，為患者就診情況分配代碼。因此，準確編碼依賴於病例記錄的可讀性和編碼員對醫學術語的理解。在過去十年中，許多研究表明臨床編碼的可再現性很差，即使在最近，人工智能模型的應用也是如此。鑑於這種情況，本文旨在介紹 SISCO.web 方法，該方法旨在支援醫師使用國際疾病分類 (第 9 版和第 10 版) 填寫出院記錄，並正確診斷和編碼程序，最重要的是，找出主要的病理狀況。網路服務利用 NLP 演算法、特定的編碼規則以及特別決策樹來找出主要狀況，在提供準確的 ICD 編碼建議方面顯示出有希望的結果。

##### **IRL for Restless Multi-Armed Bandits with Applications in Maternal and Child Health**
2412.08463v1 by Gauri Jain, Pradeep Varakantham, Haifeng Xu, Aparna Taneja, Prashant Doshi, Milind Tambe

Public health practitioners often have the goal of monitoring patients and
maximizing patients' time spent in "favorable" or healthy states while being
constrained to using limited resources. Restless multi-armed bandits (RMAB) are
an effective model to solve this problem as they are helpful to allocate
limited resources among many agents under resource constraints, where patients
behave differently depending on whether they are intervened on or not. However,
RMABs assume the reward function is known. This is unrealistic in many public
health settings because patients face unique challenges and it is impossible
for a human to know who is most deserving of any intervention at such a large
scale. To address this shortcoming, this paper is the first to present the use
of inverse reinforcement learning (IRL) to learn desired rewards for RMABs, and
we demonstrate improved outcomes in a maternal and child health telehealth
program. First we allow public health experts to specify their goals at an
aggregate or population level and propose an algorithm to design expert
trajectories at scale based on those goals. Second, our algorithm WHIRL uses
gradient updates to optimize the objective, allowing for efficient and accurate
learning of RMAB rewards. Third, we compare with existing baselines and
outperform those in terms of run-time and accuracy. Finally, we evaluate and
show the usefulness of WHIRL on thousands on beneficiaries from a real-world
maternal and child health setting in India. We publicly release our code here:
https://github.com/Gjain234/WHIRL.

摘要：<paragraph>公共衛生從業人員通常有監控患者和最大化患者處於「有利」或健康狀態的時間的目標，同時受到有限資源的限制。不安分的多臂強盜 (RMAB) 是解決此問題的有效模型，因為它們有助於在資源限制下，在許多代理之間分配有限的資源，其中患者的行為取決於是否對其進行干預。然而，RMAB 假設已知回報函數。這在許多公共衛生環境中是不切實際的，因為患者面臨獨特的挑戰，而且對於如此大規模的干預，人類不可能知道誰最需要干預。為了解決這個缺點，本文首次提出使用逆向強化學習 (IRL) 來學習 RMAB 的期望回報，並且我們在母嬰健康遠距醫療計畫中展示了改善的結果。首先，我們允許公共衛生專家在總體或人口層級指定他們的目標，並提出一個演算法來根據這些目標大規模設計專家軌跡。其次，我們的演算法 WHIRL 使用梯度更新來最佳化目標，允許有效且準確地學習 RMAB 回報。第三，我們與現有的基準進行比較，並在執行時間和準確性方面優於這些基準。最後，我們評估並展示了 WHIRL 在印度實際母嬰健康環境中對數千名受益者的有用性。我們在此公開發布我們的程式碼：https://github.com/Gjain234/WHIRL。</paragraph>

##### **Personalized Sleep Staging Leveraging Source-free Unsupervised Domain Adaptation**
2412.12159v1 by Yangxuan Zhou, Sha Zhao, Jiquan Wang, Haiteng Jiang, hijian Li, Benyan Luo, Tao Li, Gang Pan

Sleep staging is crucial for assessing sleep quality and diagnosing related
disorders. Recent deep learning models for automatic sleep staging using
polysomnography often suffer from poor generalization to new subjects because
they are trained and tested on the same labeled datasets, overlooking
individual differences. To tackle this issue, we propose a novel Source-Free
Unsupervised Individual Domain Adaptation (SF-UIDA) framework. This two-step
adaptation scheme allows the model to effectively adjust to new unlabeled
individuals without needing source data, facilitating personalized
customization in clinical settings. Our framework has been applied to three
established sleep staging models and tested on three public datasets, achieving
state-of-the-art performance.

摘要：睡眠分期對於評估睡眠品質和診斷相關疾病至關重要。最近使用多重生理睡眠檢查的自動睡眠分期深度學習模型，由於在同一個標籤資料集上訓練和測試，因此經常會出現無法廣泛運用到新受試者的問題，忽略了個體差異。為了解決這個問題，我們提出了一個新穎的無監督個體領域適應 (SF-UIDA) 框架，這種兩步驟適應機制允許模型有效地調整到新的未標籤個體，而不需要原始資料，有助於在臨床環境中進行個人化客製化。我們的框架已應用於三個既定的睡眠分期模型，並在三個公開資料集上進行測試，達到了最先進的效能。

##### **SmolTulu: Higher Learning Rate to Batch Size Ratios Can Lead to Better Reasoning in SLMs**
2412.08347v1 by Sultan Alrashed

We present SmolTulu-1.7b-Instruct, referenced in this report as
SmolTulu-DPO-1130, an instruction-tuned language model that adapts AllenAI's
Tulu 3 post-training pipeline to enhance Huggingface's SmolLM2-1.7B base model.
Through comprehensive empirical analysis using a 135M parameter model, we
demonstrate that the relationship between learning rate and batch size
significantly impacts model performance in a task-dependent manner. Our
findings reveal a clear split: reasoning tasks like ARC and GSM8K benefit from
higher learning rate to batch size ratios, while pattern recognition tasks such
as HellaSwag and IFEval show optimal performance with lower ratios. These
insights informed the development of SmolTulu, which achieves state-of-the-art
performance among sub-2B parameter models on instruction following, scoring
67.7% on IFEval ($\Delta$11%), and mathematical reasoning with 51.6% on GSM8K
($\Delta$3.4%), with an alternate version achieving scoring 57.1% on ARC
($\Delta5.4%$). We release our model, training recipes, and ablation studies to
facilitate further research in efficient model alignment, demonstrating that
careful adaptation of optimization dynamics can help bridge the capability gap
between small and large language models.

摘要：我們提出 SmolTulu-1.7b-Instruct，本報告中稱為 SmolTulu-DPO-1130，這是一種指令調整語言模型，採用 AllenAI 的 Tulu 3 後訓練管道來增強 Huggingface 的 SmolLM2-1.7B 基礎模型。透過使用 135M 參數模型的全面經驗分析，我們證明學習率與批次大小之間的關係會以任務相關的方式顯著影響模型效能。我們的發現揭示了一個明確的分歧：像 ARC 和 GSM8K 等推理任務受益於較高的學習率對批次大小的比率，而像 HellaSwag 和 IFEval 等模式辨識任務則顯示出較低比率的最佳效能。這些見解為 SmolTulu 的開發提供了資訊，在小於 2B 參數模型中，在指令遵循方面取得了最先進的表現，在 IFEval 上得分 67.7%（Δ11%），在 GSM8K 上的數學推理得分為 51.6%（Δ3.4%），而另一個版本在 ARC 上得分 57.1%（Δ5.4%）。我們發布我們的模型、訓練範例和消融研究，以促進高效模型對齊的進一步研究，證明仔細調整最佳化動態可以幫助縮小小型和大型語言模型之間的能力差距。

##### **Novel 3D Binary Indexed Tree for Volume Computation of 3D Reconstructed Models from Volumetric Data**
2412.10441v1 by Quoc-Bao Nguyen-Le, Tuan-Hy Le, Anh-Triet Do

In the burgeoning field of medical imaging, precise computation of 3D volume
holds a significant importance for subsequent qualitative analysis of 3D
reconstructed objects. Combining multivariate calculus, marching cube
algorithm, and binary indexed tree data structure, we developed an algorithm
for efficient computation of intrinsic volume of any volumetric data recovered
from computed tomography (CT) or magnetic resonance (MR). We proposed the 30
configurations of volume values based on the polygonal mesh generation method.
Our algorithm processes the data in scan-line order simultaneously with
reconstruction algorithm to create a Fenwick tree, ensuring query time much
faster and assisting users' edition of slicing or transforming model. We tested
the algorithm's accuracy on simple 3D objects (e.g., sphere, cylinder) to
complicated structures (e.g., lungs, cardiac chambers). The result deviated
within $\pm 0.004 \text{cm}^3$ and there is still room for further improvement.

摘要：在蓬勃發展的醫學影像領域中，3D 體積的精確計算對於後續 3D 重建物體的定性分析具有重要意義。結合多元微積分、行進立方體演算法和二元索引樹資料結構，我們開發了一種演算法，用於有效計算從電腦斷層掃描 (CT) 或磁振造影 (MR) 中恢復的任何體積資料的內在體積。我們根據多邊形網格生成方法提出了 30 種體積值的配置。我們的演算法與重建演算法同時以掃描線順序處理資料，以建立芬威克樹，確保查詢時間更快，並協助使用者編輯切片或轉換模型。我們在簡單的 3D 物體（例如球體、圓柱體）上測試了演算法的準確性，並對複雜的結構（例如肺、心腔）進行了測試。結果偏離在 $\pm 0.004 \text{cm}^3$ 內，並且仍有進一步改進的空間。

##### **Hierarchical Classification for Automated Image Annotation of Coral Reef Benthic Structures**
2412.08228v1 by Célia Blondin, Joris Guérin, Kelly Inagaki, Guilherme Longo, Laure Berti-Équille

Automated benthic image annotation is crucial to efficiently monitor and
protect coral reefs against climate change. Current machine learning approaches
fail to capture the hierarchical nature of benthic organisms covering reef
substrata, i.e., coral taxonomic levels and health condition. To address this
limitation, we propose to annotate benthic images using hierarchical
classification. Experiments on a custom dataset from a Northeast Brazilian
coral reef show that our approach outperforms flat classifiers, improving both
F1 and hierarchical F1 scores by approximately 2\% across varying amounts of
training data. In addition, this hierarchical method aligns more closely with
ecological objectives.

摘要：自動化底棲影像註解對於有效監測和保護珊瑚礁免受氣候變遷影響至關重要。目前的機器學習方法無法捕捉覆蓋礁石基質的底棲生物的階層性質，例如珊瑚分類等級和健康狀況。為了解決此限制，我們建議使用階層分類註解底棲影像。對來自巴西東北部珊瑚礁的自訂資料集進行的實驗顯示，我們的做法優於平面分類器，在不同數量的訓練資料中將 F1 和階層 F1 分數都提高了大約 2%。此外，這種階層式方法與生態目標更為一致。

##### **How to select slices for annotation to train best-performing deep learning segmentation models for cross-sectional medical images?**
2412.08081v1 by Yixin Zhang, Kevin Kramer, Maciej A. Mazurowski

Automated segmentation of medical images highly depends on the availability
of accurate manual image annotations. Such annotations are very time-consuming
and costly to generate, and often require specialized expertise, particularly
for cross-sectional images which contain many slices for each patient. It is
crucial to ensure the best use of annotation resources. In this paper, we
systematically answer the question of how to select slices of cross-sectional
medical images in order to maximize performance of the resulting deep learning
segmentation models. We conducted experiments on 4 medical imaging segmentation
tasks with varying annotation budgets, numbers of annotated cases, numbers of
annotated slices per volume, slice selection techniques, and mask
interpolations. We found that:
  1) It is almost always preferable to annotate fewer slices per volume and
more volumes given an annotation budget. 2) Selecting slices for annotation by
unsupervised active learning (UAL) is not superior to selecting slices randomly
or at fixed intervals, provided that each volume is allocated the same number
of annotated slices. 3) Interpolating masks between annotated slices rarely
enhances model performance, with exceptions of some specific configuration for
3D models.

摘要：醫學影像的自動化分割高度依賴於準確的手動影像標註。此類標註非常耗時且生成成本高昂，且通常需要專業知識，特別是對於每個患者包含許多切片的橫斷面影像。確保最佳利用標註資源至關重要。在本文中，我們系統性地回答了如何選擇橫斷面醫學影像切片以最大化深度學習分割模型效能的問題。我們針對 4 項醫學影像分割任務進行了實驗，這些任務具有不同的標註預算、標註案例數、每個體積的標註切片數、切片選擇技術和遮罩內插。我們發現：
1) 在給定標註預算的情況下，幾乎總是優先標註每個體積較少切片和更多體積。2) 透過非監督主動學習 (UAL) 選擇切片進行標註並不優於隨機或固定間隔選擇切片，前提是每個體積分配的標註切片數相同。3) 在標註切片之間內插遮罩很少能提升模型效能，但某些 3D 模型的特定組態除外。

##### **Can a MISL Fly? Analysis and Ingredients for Mutual Information Skill Learning**
2412.08021v1 by Chongyi Zheng, Jens Tuyls, Joanne Peng, Benjamin Eysenbach

Self-supervised learning has the potential of lifting several of the key
challenges in reinforcement learning today, such as exploration, representation
learning, and reward design. Recent work (METRA) has effectively argued that
moving away from mutual information and instead optimizing a certain
Wasserstein distance is important for good performance. In this paper, we argue
that the benefits seen in that paper can largely be explained within the
existing framework of mutual information skill learning (MISL). Our analysis
suggests a new MISL method (contrastive successor features) that retains the
excellent performance of METRA with fewer moving parts, and highlights
connections between skill learning, contrastive representation learning, and
successor features. Finally, through careful ablation studies, we provide
further insight into some of the key ingredients for both our method and METRA.

摘要：自我監督學習有潛力解決當今強化學習中的幾個關鍵挑戰，例如探索、表徵學習和獎勵設計。最近的研究（METRA）有效地論證了遠離互信息並改為優化某個 Wasserstein 距離對於良好的性能很重要。在本文中，我們論證該論文中看到的優點可以在互信息技能學習（MISL）的現有框架內得到很大程度的解釋。我們的分析提出了一種新的 MISL 方法（對比後繼特徵），它保留了 METRA 的出色性能，同時減少了活動部件，並突出了技能學習、對比表徵學習和後繼特徵之間的聯繫。最後，通過仔細的消融研究，我們進一步深入了解了我們的方法和 METRA 的一些關鍵要素。

##### **From Lived Experience to Insight: Unpacking the Psychological Risks of Using AI Conversational Agents**
2412.07951v2 by Mohit Chandra, Suchismita Naik, Denae Ford, Ebele Okoli, Munmun De Choudhury, Mahsa Ershadi, Gonzalo Ramos, Javier Hernandez, Ananya Bhattacharjee, Shahed Warreth, Jina Suh

Recent gain in popularity of AI conversational agents has led to their
increased use for improving productivity and supporting well-being. While
previous research has aimed to understand the risks associated with
interactions with AI conversational agents, these studies often fall short in
capturing the lived experiences. Additionally, psychological risks have often
been presented as a sub-category within broader AI-related risks in past
taxonomy works, leading to under-representation of the impact of psychological
risks of AI use. To address these challenges, our work presents a novel risk
taxonomy focusing on psychological risks of using AI gathered through lived
experience of individuals. We employed a mixed-method approach, involving a
comprehensive survey with 283 individuals with lived mental health experience
and workshops involving lived experience experts to develop a psychological
risk taxonomy. Our taxonomy features 19 AI behaviors, 21 negative psychological
impacts, and 15 contexts related to individuals. Additionally, we propose a
novel multi-path vignette based framework for understanding the complex
interplay between AI behaviors, psychological impacts, and individual user
contexts. Finally, based on the feedback obtained from the workshop sessions,
we present design recommendations for developing safer and more robust AI
agents. Our work offers an in-depth understanding of the psychological risks
associated with AI conversational agents and provides actionable
recommendations for policymakers, researchers, and developers.

摘要：近期 AI 對話代理的普及提升，導致其在提升生產力和支持幸福感方面的應用日益增加。雖然先前的研究旨在了解與 AI 對話代理互動相關的風險，但這些研究往往無法捕捉到生活體驗。此外，在過去的分類工作中，心理風險通常被視為更廣泛的 AI 相關風險中的子類別，導致 AI 使用心理風險的影響被低估。為了應對這些挑戰，我們的研究提出了新穎的風險分類法，重點關注透過個人生活經驗收集的 AI 使用心理風險。我們採用混合方法，包括對 283 位具有生活心理健康經驗的個人進行全面調查，以及與生活經驗專家合作的研討會，以制定心理風險分類法。我們的分類法包含 19 種 AI 行為、21 種負面心理影響和 15 種與個人相關的背景。此外，我們提出了一個新穎的多路徑小插圖框架，用於了解 AI 行為、心理影響和個人使用者背景之間的複雜交互作用。最後，根據從研討會中獲得的回饋，我們提出了設計建議，以開發更安全、更強大的 AI 代理。我們的研究深入了解了與 AI 對話代理相關的心理風險，並為政策制定者、研究人員和開發人員提供了可行的建議。

##### **How Should We Represent History in Interpretable Models of Clinical Policies?**
2412.07895v1 by Anton Matsson, Lena Stempfle, Yaochen Rao, Zachary R. Margolin, Heather J. Litman, Fredrik D. Johansson

Modeling policies for sequential clinical decision-making based on
observational data is useful for describing treatment practices, standardizing
frequent patterns in treatment, and evaluating alternative policies. For each
task, it is essential that the policy model is interpretable. Learning accurate
models requires effectively capturing the state of a patient, either through
sequence representation learning or carefully crafted summaries of their
medical history. While recent work has favored the former, it remains a
question as to how histories should best be represented for interpretable
policy modeling. Focused on model fit, we systematically compare diverse
approaches to summarizing patient history for interpretable modeling of
clinical policies across four sequential decision-making tasks. We illustrate
differences in the policies learned using various representations by breaking
down evaluations by patient subgroups, critical states, and stages of
treatment, highlighting challenges specific to common use cases. We find that
interpretable sequence models using learned representations perform on par with
black-box models across all tasks. Interpretable models using hand-crafted
representations perform substantially worse when ignoring history entirely, but
are made competitive by incorporating only a few aggregated and recent elements
of patient history. The added benefits of using a richer representation are
pronounced for subgroups and in specific use cases. This underscores the
importance of evaluating policy models in the context of their intended use.

摘要：基於觀察資料對序貫臨床決策制定建模政策，有助於描述治療實務、標準化治療中的常見模式，以及評估替代政策。對於每項任務，政策模型的可解釋性至關重要。學習精確的模型需要有效擷取患者的狀態，無論是透過序列表徵學習或精心製作的病史摘要。雖然近期研究偏好前者，但如何以最佳方式表徵病史以進行可解釋的政策建模，仍是一個問題。我們專注於模型擬合度，系統性地比較各種摘要患者病史的方法，以針對四項序貫決策制定任務進行可解釋的臨床政策建模。我們透過按患者子群、危急狀態和治療階段細分評估，來說明使用各種表徵所學習到的政策之間的差異，並強調特定於常見使用案例的挑戰。我們發現，使用學習表徵的可解釋序列模型在所有任務中表現與黑箱模型不相上下。使用手工製作表徵的可解釋模型在完全忽略病史時表現明顯較差，但透過僅納入少數患者病史的彙整和近期元素，便能使其具有競爭力。使用更豐富表徵的額外好處在子群和特定使用案例中顯著。這強調了在預期用途的脈絡中評估政策模型的重要性。

##### **Towards Foundation-model-based Multiagent System to Accelerate AI for Social Impact**
2412.07880v2 by Yunfan Zhao, Niclas Boehmer, Aparna Taneja, Milind Tambe

AI for social impact (AI4SI) offers significant potential for addressing
complex societal challenges in areas such as public health, agriculture,
education, conservation, and public safety. However, existing AI4SI research is
often labor-intensive and resource-demanding, limiting its accessibility and
scalability; the standard approach is to design a (base-level) system tailored
to a specific AI4SI problem. We propose the development of a novel meta-level
multi-agent system designed to accelerate the development of such base-level
systems, thereby reducing the computational cost and the burden on social
impact domain experts and AI researchers. Leveraging advancements in foundation
models and large language models, our proposed approach focuses on resource
allocation problems providing help across the full AI4SI pipeline from problem
formulation over solution design to impact evaluation. We highlight the ethical
considerations and challenges inherent in deploying such systems and emphasize
the importance of a human-in-the-loop approach to ensure the responsible and
effective application of AI systems.

摘要：人工智慧對社會影響（AI4SI）提供了巨大的潛力，用於解決複雜的社會挑戰，例如公共衛生、農業、教育、保育和公共安全。然而，現有的 AI4SI 研究通常需要大量人力和資源，這限制了其可及性和可擴展性；標準方法是設計一個針對特定 AI4SI 問題量身打造的（基礎層級）系統。我們建議開發一個新穎的元層級多代理系統，旨在加速此類基礎層級系統的開發，從而降低運算成本和社會影響領域專家與 AI 研究人員的負擔。透過運用基礎模型和大型語言模型的進展，我們建議的方法專注於資源配置問題，提供從問題建構、解決方案設計到影響評估的完整 AI4SI 管線的協助。我們強調部署此類系統時固有的道德考量和挑戰，並強調人機協作方法的重要性，以確保負責任且有效地應用 AI 系統。

##### **Comparative Analysis of Deep Learning Approaches for Harmful Brain Activity Detection Using EEG**
2412.07878v1 by Shivraj Singh Bhatti, Aryan Yadav, Mitali Monga, Neeraj Kumar

The classification of harmful brain activities, such as seizures and periodic
discharges, play a vital role in neurocritical care, enabling timely diagnosis
and intervention. Electroencephalography (EEG) provides a non-invasive method
for monitoring brain activity, but the manual interpretation of EEG signals are
time-consuming and rely heavily on expert judgment. This study presents a
comparative analysis of deep learning architectures, including Convolutional
Neural Networks (CNNs), Vision Transformers (ViTs), and EEGNet, applied to the
classification of harmful brain activities using both raw EEG data and
time-frequency representations generated through Continuous Wavelet Transform
(CWT). We evaluate the performance of these models use multimodal data
representations, including high-resolution spectrograms and waveform data, and
introduce a multi-stage training strategy to improve model robustness. Our
results show that training strategies, data preprocessing, and augmentation
techniques are as critical to model success as architecture choice, with
multi-stage TinyViT and EfficientNet demonstrating superior performance. The
findings underscore the importance of robust training regimes in achieving
accurate and efficient EEG classification, providing valuable insights for
deploying AI models in clinical practice.

摘要：有害腦部活動的分類，例如癲癇發作和週期性放電，在神經重症照護中扮演著至關重要的角色，能及時診斷和介入。腦電圖 (EEG) 提供了一種非侵入式的方法來監測腦部活動，但 EEG 訊號的手動判讀耗時且高度依賴專家的判斷。本研究針對深度學習架構進行比較分析，包括卷積神經網路 (CNN)、視覺Transformer (ViT) 和 EEGNet，運用於有害腦部活動的分類，同時使用原始 EEG 資料和透過連續小波轉換 (CWT) 生成的時頻表示。我們評估這些模型使用多模式資料表示的效能，包括高解析度頻譜圖和波形資料，並引入多階段訓練策略來改善模型的穩健性。我們的結果顯示，訓練策略、資料前處理和擴充技術對於模型的成功與架構選擇一樣重要，其中多階段 TinyViT 和 EfficientNet 表現出優異的效能。這些發現強調了穩健訓練機制對於達成準確且有效率的 EEG 分類的重要性，為在臨床實務中部署 AI 模型提供了寶貴的見解。

##### **Combining knowledge graphs and LLMs for hazardous chemical information management and reuse**
2412.09644v1 by Marcos Da Silveira, Louis Deladiennee, Kheira Acem, Oona Freudenthal

Human health is increasingly threatened by exposure to hazardous substances,
particularly persistent and toxic chemicals. The link between these substances,
often encountered in complex mixtures, and various diseases are demonstrated in
scientific studies. However, this information is scattered across several
sources and hardly accessible by humans and machines. This paper evaluates
current practices for publishing/accessing information on hazardous chemicals
and proposes a novel platform designed to facilitate retrieval of critical
chemical data in urgent situations. The platform aggregates information from
multiple sources and organizes it into a structured knowledge graph. Users can
access this information through a visual interface such as Neo4J Bloom and
dashboards, or via natural language queries using a Chatbot. Our findings
demonstrate a significant reduction in the time and effort required to access
vital chemical information when datasets follow FAIR principles. Furthermore,
we discuss the lessons learned from the development and implementation of this
platform and provide recommendations for data owners and publishers to enhance
data reuse and interoperability. This work aims to improve the accessibility
and usability of chemical information by healthcare professionals, thereby
supporting better health outcomes and informed decision-making in the face of
patients exposed to chemical intoxication risks.

摘要：人類健康越來越受到接觸有害物質的威脅，尤其是持久性和有毒的化學物質。科學研究已證明這些物質（通常存在於複雜的混合物中）與各種疾病之間的關聯。然而，這些資訊分散在多個來源中，人類和機器都很難取得。本文評估了當前發布/取得有關有害化學物質資訊的慣例，並提出一個新穎的平台，旨在促進在緊急情況下取得關鍵化學資料。此平台匯集來自多個來源的資訊，並將其組織成結構化的知識圖譜。使用者可以透過視覺化介面（例如 Neo4J Bloom 和儀表板）或使用聊天機器人的自然語言查詢來取得這些資訊。我們的研究結果表明，當資料集遵循 FAIR 原則時，取得重要化學資訊所需的時間和精力會大幅減少。此外，我們討論從此平台的開發和實作中學到的經驗教訓，並為資料擁有者和發布者提供建議，以增強資料再利用和互操作性。這項工作旨在改善醫療保健專業人員取得和使用化學資訊的方式，從而支持更好的健康結果，並在面對接觸化學中毒風險的患者時做出明智的決策。

##### **Adapting to Non-Stationary Environments: Multi-Armed Bandit Enhanced Retrieval-Augmented Generation on Knowledge Graphs**
2412.07618v2 by Xiaqiang Tang, Jian Li, Nan Du, Sihong Xie

Despite the superior performance of Large language models on many NLP tasks,
they still face significant limitations in memorizing extensive world
knowledge. Recent studies have demonstrated that leveraging the
Retrieval-Augmented Generation (RAG) framework, combined with Knowledge Graphs
that encapsulate extensive factual data in a structured format, robustly
enhances the reasoning capabilities of LLMs. However, deploying such systems in
real-world scenarios presents challenges: the continuous evolution of
non-stationary environments may lead to performance degradation and user
satisfaction requires a careful balance of performance and responsiveness. To
address these challenges, we introduce a Multi-objective Multi-Armed Bandit
enhanced RAG framework, supported by multiple retrieval methods with diverse
capabilities under rich and evolving retrieval contexts in practice. Within
this framework, each retrieval method is treated as a distinct ``arm''. The
system utilizes real-time user feedback to adapt to dynamic environments, by
selecting the appropriate retrieval method based on input queries and the
historical multi-objective performance of each arm. Extensive experiments
conducted on two benchmark KGQA datasets demonstrate that our method
significantly outperforms baseline methods in non-stationary settings while
achieving state-of-the-art performance in stationary environments. Code and
data are available at https://github.com/FUTUREEEEEE/Dynamic-RAG.git

摘要：儘管大型語言模型在許多自然語言處理任務中表現優異，
它們在記憶廣泛的世界知識方面仍面臨重大限制。最近的研究表明，利用擷取增強生成 (RAG) 框架，結合以結構化格式封裝廣泛事實資料的知識圖譜，可以穩健地增強 LLM 的推理能力。然而，在現實世界場景中部署此類系統會產生挑戰：非平穩環境的持續演變可能會導致效能下降，而使用者的滿意度需要在效能和回應性之間取得仔細的平衡。為了應對這些挑戰，我們引入了一個多目標多臂老虎機增強的 RAG 框架，由多種擷取方法支援，這些方法在實務中具有豐富且不斷演化的擷取背景下的不同功能。在此框架內，每種擷取方法都被視為一個不同的「臂」。該系統利用即時使用者回饋來適應動態環境，方法是根據輸入查詢和每個臂的歷史多目標效能來選擇適當的擷取方法。在兩個基準 KGQA 資料集上進行的廣泛實驗表明，我們的模型在非平穩環境中明顯優於基線模型，同時在平穩環境中實現了最先進的效能。程式碼和資料可在 https://github.com/FUTUREEEEEE/Dynamic-RAG.git 取得

##### **Scaling Sequential Recommendation Models with Transformers**
2412.07585v1 by Pablo Zivic, Hernan Vazquez, Jorge Sanchez

Modeling user preferences has been mainly addressed by looking at users'
interaction history with the different elements available in the system.
Tailoring content to individual preferences based on historical data is the
main goal of sequential recommendation.
  The nature of the problem, as well as the good performance observed across
various domains, has motivated the use of the transformer architecture, which
has proven effective in leveraging increasingly larger amounts of training data
when accompanied by an increase in the number of model parameters. This scaling
behavior has brought a great deal of attention, as it provides valuable
guidance in the design and training of even larger models.
  Taking inspiration from the scaling laws observed in training large language
models, we explore similar principles for sequential recommendation.
  We use the full Amazon Product Data dataset, which has only been partially
explored in other studies, and reveal scaling behaviors similar to those found
in language models. Compute-optimal training is possible but requires a careful
analysis of the compute-performance trade-offs specific to the application.
  We also show that performance scaling translates to downstream tasks by
fine-tuning larger pre-trained models on smaller task-specific domains. Our
approach and findings provide a strategic roadmap for model training and
deployment in real high-dimensional preference spaces, facilitating better
training and inference efficiency.
  We hope this paper bridges the gap between the potential of transformers and
the intrinsic complexities of high-dimensional sequential recommendation in
real-world recommender systems.
  Code and models can be found at https://github.com/mercadolibre/srt

摘要：<paragraph>建模使用者偏好主要透過觀察使用者與系統中不同元素的互動記錄。
根據歷史資料調整個人偏好的內容是連續推薦的主要目標。
問題的本質，以及在各個領域觀察到的良好效能，激勵了Transformer架構的使用，在增加模型參數數量時，已證明能有效利用越來越多訓練資料。這種規模行為引起了極大的關注，因為它在設計和訓練更大模型時提供了有價值的指導。
從訓練大型語言模型中觀察到的規模法則中汲取靈感，我們探討了連續推薦的類似原則。
我們使用了完整的 Amazon 產品資料集，其他研究僅部分探討過，並揭示了與在語言模型中發現的類似的規模行為。計算最佳訓練是可能的，但需要仔細分析特定於應用程式的計算效能折衷。
我們還展示了效能規模轉化為下游任務，透過對較小的特定任務領域微調較大的預訓練模型。我們的做法和發現為模型訓練和在實際高維度偏好空間中部署提供了策略性路線圖，促進更好的訓練和推理效率。
我們希望這篇論文能彌合Transformer潛力與實際推薦系統中高維度連續推薦的內在複雜性之間的差距。
程式碼和模型可以在 https://github.com/mercadolibre/srt 找到</paragraph>

##### **Knowledge Graph Guided Evaluation of Abstention Techniques**
2412.07430v1 by Kinshuk Vasisht, Navreet Kaur, Danish Pruthi

To deploy language models safely, it is crucial that they abstain from
responding to inappropriate requests. Several prior studies test the safety
promises of models based on their effectiveness in blocking malicious requests.
In this work, we focus on evaluating the underlying techniques that cause
models to abstain. We create SELECT, a benchmark derived from a set of benign
concepts (e.g., "rivers") from a knowledge graph. The nature of SELECT enables
us to isolate the effects of abstention techniques from other safety training
procedures, as well as evaluate their generalization and specificity. Using
SELECT, we benchmark different abstention techniques over six open-weight and
closed-source models. We find that the examined techniques indeed cause models
to abstain with over $80\%$ abstention rates. However, these techniques are not
as effective for descendants of the target concepts, with refusal rates
declining by $19\%$. We also characterize the generalization-vs-specificity
trade-offs for different techniques. Overall, no single technique is invariably
better than the others. Our findings call for a careful evaluation of different
aspects of abstention, and hopefully inform practitioners of various trade-offs
involved.

摘要：為了安全地部署語言模型，至關重要的是，它們必須避免回應不適當的請求。先前有數項研究測試模型的安全性，依據它們封鎖惡意請求的有效性為基礎。在這項工作中，我們專注於評估導致模型避免回應的底層技術。我們建立了 SELECT，一個從知識圖譜中一組良性概念（例如「河流」）衍生的基準。SELECT 的性質使我們能夠將避免回應技術的影響與其他安全訓練程序隔離，並評估它們的概括性和特異性。使用 SELECT，我們對六個開放權重和封閉原始碼模型進行了不同避免回應技術的基準測試。我們發現，所檢查的技術確實導致模型避免回應，避免回應率超過 80%。然而，這些技術對於目標概念的後代並不那麼有效，拒絕率下降了 19%。我們還描述了不同技術的概括性與特異性權衡。總體而言，沒有任何單一技術始終優於其他技術。我們的發現要求仔細評估避免回應的不同面向，並希望讓從業人員了解所涉及的各種權衡。

##### **AutoPrep: Natural Language Question-Aware Data Preparation with a Multi-Agent Framework**
2412.10422v1 by Meihao Fan, Ju Fan, Nan Tang, Lei Cao, Xiaoyong Du

Answering natural language (NL) questions about tables, which is referred to
as Tabular Question Answering (TQA), is important because it enables users to
extract meaningful insights quickly and efficiently from structured data,
bridging the gap between human language and machine-readable formats. Many of
these tables originate from web sources or real-world scenarios, necessitating
careful data preparation (or data prep for short) to ensure accurate answers.
However, unlike traditional data prep, question-aware data prep introduces new
requirements, which include tasks such as column augmentation and filtering for
given questions, and question-aware value normalization or conversion. Because
each of the above tasks is unique, a single model (or agent) may not perform
effectively across all scenarios. In this paper, we propose AUTOPREP, a large
language model (LLM)-based multi-agent framework that leverages the strengths
of multiple agents, each specialized in a certain type of data prep, ensuring
more accurate and contextually relevant responses. Given an NL question over a
table, AUTOPREP performs data prep through three key components. Planner:
Determines a logical plan, outlining a sequence of high-level operations.
Programmer: Translates this logical plan into a physical plan by generating the
corresponding low-level code. Executor: Iteratively executes and debugs the
generated code to ensure correct outcomes. To support this multi-agent
framework, we design a novel chain-of-thought reasoning mechanism for
high-level operation suggestion, and a tool-augmented method for low-level code
generation. Extensive experiments on real-world TQA datasets demonstrate that
AUTOPREP can significantly improve the SOTA TQA solutions through
question-aware data prep.

摘要：回答有关表格的自然语言 (NL) 问题，称为表格问题解答 (TQA)，非常重要，因为它使用户能够从结构化数据中快速有效地提取有意义的见解，从而弥合了人类语言和机器可读格式之间的差距。其中许多表格源自网络来源或现实世界场景，因此需要仔细准备数据（或简称为数据准备）以确保答案准确。然而，与传统数据准备不同，考虑问题的数据准备引入了新要求，其中包括针对给定问题进行列增强和过滤，以及考虑问题的价值规范化或转换等任务。由于上述每项任务都是唯一的，因此单个模型（或代理）可能无法在所有场景中有效执行。在本文中，我们提出了 AUTOPREP，这是一个基于大型语言模型 (LLM) 的多代理框架，它利用了多个代理的优势，每个代理都专门从事某种类型的数据准备，从而确保了更准确和与上下文相关的响应。给定一个关于表格的 NL 问题，AUTOPREP 通过三个关键组件执行数据准备。计划程序：确定一个逻辑计划，概述一系列高级操作。程序员：通过生成相应的低级代码将此逻辑计划转换为物理计划。执行器：迭代执行并调试生成的代码以确保正确的结果。为了支持此多代理框架，我们设计了一种新颖的思想链推理机制，用于高级操作建议，以及一种用于低级代码生成​​的工具增强方法。在真实世界 TQA 数据集上进行的广泛实验表明，AUTOPREP 可以通过考虑问题的​​数据准备显着改进 SOTA TQA 解决方案。

##### **A Review of Challenges in Speech-based Conversational AI for Elderly Care**
2412.07388v1 by Willemijn Klaassen, Bram van Dijk, Marco Spruit

Artificially intelligent systems optimized for speech conversation are
appearing at a fast pace. Such models are interesting from a healthcare
perspective, as these voice-controlled assistants may support the elderly and
enable remote health monitoring. The bottleneck for efficacy, however, is how
well these devices work in practice and how the elderly experience them, but
research on this topic is scant. We review elderly use of voice-controlled AI
and highlight various user- and technology-centered issues, that need to be
considered before effective speech-controlled AI for elderly care can be
realized.

摘要：以語音對話為最佳化的人工智慧系統正快速出現。此類模型在醫療保健方面很有趣，因為這些聲控助理可以支援長者並能進行遠距健康監控。然而，效能的瓶頸在於這些裝置在實際運作上的表現如何，以及長者如何體驗它們，但這方面的研究卻很稀少。我們回顧了長者使用聲控人工智慧的狀況，並重點說明各種以使用者和技術為中心的議題，在能實現有效的聲控人工智慧以進行長者照護之前，這些議題都需要加以考量。

##### **Enhanced MRI Representation via Cross-series Masking**
2412.07387v1 by Churan Wang, Fei Gao, Lijun Yan, Siwen Wang, Yizhou Yu, Yizhou Wang

Magnetic resonance imaging (MRI) is indispensable for diagnosing and planning
treatment in various medical conditions due to its ability to produce
multi-series images that reveal different tissue characteristics. However,
integrating these diverse series to form a coherent analysis presents
significant challenges, such as differing spatial resolutions and contrast
patterns meanwhile requiring extensive annotated data, which is scarce in
clinical practice. Due to these issues, we introduce a novel Cross-Series
Masking (CSM) Strategy for effectively learning MRI representation in a
self-supervised manner. Specifically, CSM commences by randomly sampling a
subset of regions and series, which are then strategically masked. In the
training process, the cross-series representation is learned by utilizing the
unmasked data to reconstruct the masked portions. This process not only
integrates information across different series but also facilitates the ability
to model both intra-series and inter-series correlations and complementarities.
With the learned representation, the downstream tasks like segmentation and
classification are also enhanced. Taking brain tissue segmentation, breast
tumor benign/malignant classification, and prostate cancer diagnosis as
examples, our method achieves state-of-the-art performance on both public and
in-house datasets.

摘要：磁振造影 (MRI) 對於診斷和規劃各種醫療狀況的治療至關重要，因為它能夠產生揭示不同組織特徵的多系列影像。然而，整合這些不同的系列以形成連貫的分析會帶來重大的挑戰，例如不同的空間解析度和對比模式，同時需要大量的註解資料，但在臨床實務中卻很稀少。由於這些問題，我們引入了一種新穎的跨系列遮罩 (CSM) 策略，以便以自我監督的方式有效地學習 MRI 表徵。具體來說，CSM 從隨機抽樣區域和系列的子集開始，然後對其進行策略性遮罩。在訓練過程中，跨系列表徵是透過利用未遮罩的資料來重建遮罩部分而學習的。這個過程不僅整合了不同系列的資訊，還促進了對系列內和系列間關聯性和互補性的建模能力。透過學習到的表徵，下游任務（例如分割和分類）也會得到增強。以腦組織分割、乳房腫瘤良性/惡性分類和前列腺癌診斷為例，我們的模型在公開資料集和內部資料集上都達到了最先進的效能。

##### **On Evaluating the Durability of Safeguards for Open-Weight LLMs**
2412.07097v1 by Xiangyu Qi, Boyi Wei, Nicholas Carlini, Yangsibo Huang, Tinghao Xie, Luxi He, Matthew Jagielski, Milad Nasr, Prateek Mittal, Peter Henderson

Stakeholders -- from model developers to policymakers -- seek to minimize the
dual-use risks of large language models (LLMs). An open challenge to this goal
is whether technical safeguards can impede the misuse of LLMs, even when models
are customizable via fine-tuning or when model weights are fully open. In
response, several recent studies have proposed methods to produce durable LLM
safeguards for open-weight LLMs that can withstand adversarial modifications of
the model's weights via fine-tuning. This holds the promise of raising
adversaries' costs even under strong threat models where adversaries can
directly fine-tune model weights. However, in this paper, we urge for more
careful characterization of the limits of these approaches. Through several
case studies, we demonstrate that even evaluating these defenses is exceedingly
difficult and can easily mislead audiences into thinking that safeguards are
more durable than they really are. We draw lessons from the evaluation pitfalls
that we identify and suggest future research carefully cabin claims to more
constrained, well-defined, and rigorously examined threat models, which can
provide more useful and candid assessments to stakeholders.

摘要：利害關係人（從模型開發人員到政策制定者）尋求將大型語言模型 (LLM) 的雙重使用風險降至最低。對此目標的公開挑戰在於，技術保障措施是否能阻止 LLM 的濫用，即使模型可通過微調進行自訂，或模型權重完全開放時亦然。為了解決此問題，最近有幾項研究提出方法，以產生適用於開放權重 LLM 的耐用 LLM 保障措施，這些保障措施能承受透過微調對模型權重進行的對抗性修改。這有望提高對手的成本，即使在對手可以直接微調模型權重的強威脅模型下亦然。然而，在本文中，我們敦促更仔細地描述這些方法的限制。透過多項案例研究，我們證明即使評估這些防禦措施也極其困難，並且很容易誤導受眾，讓他們認為保障措施比實際上更耐用。我們從我們辨識出的評估陷阱中汲取教訓，並建議未來的研究謹慎地將主張限制在更受限、定義明確且經過嚴格審查的威脅模型中，這可以為利害關係人提供更有用且坦率的評估。

##### **Toward AI-Driven Digital Organism: Multiscale Foundation Models for Predicting, Simulating and Programming Biology at All Levels**
2412.06993v1 by Le Song, Eran Segal, Eric Xing

We present an approach of using AI to model and simulate biology and life.
Why is it important? Because at the core of medicine, pharmacy, public health,
longevity, agriculture and food security, environmental protection, and clean
energy, it is biology at work. Biology in the physical world is too complex to
manipulate and always expensive and risky to tamper with. In this perspective,
we layout an engineering viable approach to address this challenge by
constructing an AI-Driven Digital Organism (AIDO), a system of integrated
multiscale foundation models, in a modular, connectable, and holistic fashion
to reflect biological scales, connectedness, and complexities. An AIDO opens up
a safe, affordable and high-throughput alternative platform for predicting,
simulating and programming biology at all levels from molecules to cells to
individuals. We envision that an AIDO is poised to trigger a new wave of
better-guided wet-lab experimentation and better-informed first-principle
reasoning, which can eventually help us better decode and improve life.

摘要：我們提出了一種使用 AI 來建模和模擬生物學和生命的方法。
為什麼這很重要？因為在醫學、藥學、公共衛生、
長壽、農業和食品安全、環境保護和清潔
能源的核心，都是生物學在運作。物理世界中的生物學太過複雜，
難以操作，而且總是昂貴且有風險。從這個角度來看，
我們制定了一種可行的工程方法來解決這個挑戰，方法是
構建一個 AI 驅動的數位生物體 (AIDO)，一個整合的
多尺度基礎模型系統，以模組化、可連接和整體的方式
來反映生物尺度、連通性和複雜性。AIDO 開啟了一個安全、
負擔得起且高通量的替代平台，用於預測、
模擬和編程從分子到細胞到個體的所有層級的生物學。我們預計 AIDO 將引發一波
由更佳指導的濕式實驗和更完善的第一原理
推理的新浪潮，最終可以幫助我們更好地解碼和改善生命。

