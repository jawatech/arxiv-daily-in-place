{"2408.04775": {"publish_time": "2024-08-08", "title": "Hybrid Student-Teacher Large Language Model Refinement for Cancer Toxicity Symptom Extraction", "paper_summary": "Large Language Models (LLMs) offer significant potential for clinical symptom\nextraction, but their deployment in healthcare settings is constrained by\nprivacy concerns, computational limitations, and operational costs. This study\ninvestigates the optimization of compact LLMs for cancer toxicity symptom\nextraction using a novel iterative refinement approach. We employ a\nstudent-teacher architecture, utilizing Zephyr-7b-beta and Phi3-mini-128 as\nstudent models and GPT-4o as the teacher, to dynamically select between prompt\nrefinement, Retrieval-Augmented Generation (RAG), and fine-tuning strategies.\nOur experiments on 294 clinical notes covering 12 post-radiotherapy toxicity\nsymptoms demonstrate the effectiveness of this approach. The RAG method proved\nmost efficient, improving average accuracy scores from 0.32 to 0.73 for\nZephyr-7b-beta and from 0.40 to 0.87 for Phi3-mini-128 during refinement. In\nthe test set, both models showed an approximate 0.20 increase in accuracy\nacross symptoms. Notably, this improvement was achieved at a cost 45 times\nlower than GPT-4o for Zephyr and 79 times lower for Phi-3. These results\nhighlight the potential of iterative refinement techniques in enhancing the\ncapabilities of compact LLMs for clinical applications, offering a balance\nbetween performance, cost-effectiveness, and privacy preservation in healthcare\nsettings.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5728\u81e8\u5e8a\u75c7\u72c0\u8403\u53d6\u4e2d\u5177\u6709\u986f\u8457\u7684\u6f5b\u529b\uff0c\u4f46\u5176\u5728\u91ab\u7642\u4fdd\u5065\u74b0\u5883\u4e2d\u7684\u61c9\u7528\u53d7\u5230\u96b1\u79c1\u554f\u984c\u3001\u904b\u7b97\u9650\u5236\u548c\u71df\u904b\u6210\u672c\u7684\u7d04\u675f\u3002\u672c\u7814\u7a76\u63a2\u8a0e\u4e86\u4f7f\u7528\u5275\u65b0\u7684\u53cd\u8986\u512a\u5316\u65b9\u6cd5\uff0c\u512a\u5316\u7528\u65bc\u764c\u75c7\u6bd2\u6027\u75c7\u72c0\u8403\u53d6\u7684\u7dca\u6e4a\u578b LLM\u3002\u6211\u5011\u63a1\u7528\u5b78\u751f-\u8001\u5e2b\u67b6\u69cb\uff0c\u5229\u7528 Zephyr-7b-beta \u548c Phi3-mini-128 \u4f5c\u70ba\u5b78\u751f\u6a21\u578b\uff0c\u4e26\u5c07 GPT-4o \u4f5c\u70ba\u8001\u5e2b\uff0c\u4ee5\u52d5\u614b\u9078\u64c7\u63d0\u793a\u512a\u5316\u3001\u6aa2\u7d22\u64f4\u5145\u751f\u6210 (RAG) \u548c\u5fae\u8abf\u7b56\u7565\u3002\u6211\u5011\u5728\u6db5\u84cb 12 \u7a2e\u653e\u5c04\u6cbb\u7642\u5f8c\u6bd2\u6027\u75c7\u72c0\u7684 294 \u4efd\u81e8\u5e8a\u7b46\u8a18\u4e0a\u9032\u884c\u7684\u5be6\u9a57\u8b49\u660e\u4e86\u6b64\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002RAG \u65b9\u6cd5\u88ab\u8b49\u660e\u6700\u6709\u6548\u7387\uff0c\u5728\u512a\u5316\u904e\u7a0b\u4e2d\u5c07 Zephyr-7b-beta \u7684\u5e73\u5747\u6e96\u78ba\u5ea6\u5206\u6578\u5f9e 0.32 \u63d0\u9ad8\u5230 0.73\uff0c\u5c07 Phi3-mini-128 \u7684\u5e73\u5747\u6e96\u78ba\u5ea6\u5206\u6578\u5f9e 0.40 \u63d0\u9ad8\u5230 0.87\u3002\u5728\u6e2c\u8a66\u96c6\u4e2d\uff0c\u9019\u5169\u500b\u6a21\u578b\u5728\u6240\u6709\u75c7\u72c0\u4e2d\u90fd\u986f\u793a\u51fa\u6e96\u78ba\u5ea6\u5927\u7d04\u589e\u52a0\u4e86 0.20\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u6b64\u6539\u9032\u662f\u4ee5\u6bd4 Zephyr \u4f4e 45 \u500d\u7684\u6210\u672c\u548c\u6bd4 Phi-3 \u4f4e 79 \u500d\u7684\u6210\u672c\u5be6\u73fe\u7684\u3002\u9019\u4e9b\u7d50\u679c\u7a81\u986f\u4e86\u53cd\u8986\u512a\u5316\u6280\u8853\u5728\u589e\u5f37\u7dca\u6e4a\u578b LLM \u5728\u81e8\u5e8a\u61c9\u7528\u4e2d\u7684\u80fd\u529b\u65b9\u9762\u7684\u6f5b\u529b\uff0c\u5728\u91ab\u7642\u4fdd\u5065\u74b0\u5883\u4e2d\u63d0\u4f9b\u4e86\u6548\u80fd\u3001\u6210\u672c\u6548\u76ca\u548c\u96b1\u79c1\u4fdd\u8b77\u4e4b\u9593\u7684\u5e73\u8861\u3002", "author": "Reza Khanmohammadi et.al.", "authors": "Reza Khanmohammadi, Ahmed I. Ghanem, Kyle Verdecchia, Ryan Hall, Mohamed Elshaikh, Benjamin Movsas, Hassan Bagher-Ebadian, Bing Luo, Indrin J. Chetty, Tuka Alhanai, Kundan Thind, Mohammad M. Ghassemi", "id": "2408.04775v1", "paper_url": "http://arxiv.org/abs/2408.04775v1", "repo": "null"}}