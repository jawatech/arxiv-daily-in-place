{"2311.10933": {"publish_time": "2023-11-18", "title": "Representing visual classification as a linear combination of words", "paper_summary": "Explainability is a longstanding challenge in deep learning, especially in\nhigh-stakes domains like healthcare. Common explainability methods highlight\nimage regions that drive an AI model's decision. Humans, however, heavily rely\non language to convey explanations of not only \"where\" but \"what\".\nAdditionally, most explainability approaches focus on explaining individual AI\npredictions, rather than describing the features used by an AI model in\ngeneral. The latter would be especially useful for model and dataset auditing,\nand potentially even knowledge generation as AI is increasingly being used in\nnovel tasks. Here, we present an explainability strategy that uses a\nvision-language model to identify language-based descriptors of a visual\nclassification task. By leveraging a pre-trained joint embedding space between\nimages and text, our approach estimates a new classification task as a linear\ncombination of words, resulting in a weight for each word that indicates its\nalignment with the vision-based classifier. We assess our approach using two\nmedical imaging classification tasks, where we find that the resulting\ndescriptors largely align with clinical knowledge despite a lack of\ndomain-specific language training. However, our approach also identifies the\npotential for 'shortcut connections' in the public datasets used. Towards a\nfunctional measure of explainability, we perform a pilot reader study where we\nfind that the AI-identified words can enable non-expert humans to perform a\nspecialized medical task at a non-trivial level. Altogether, our results\nemphasize the potential of using multimodal foundational models to deliver\nintuitive, language-based explanations of visual tasks.", "paper_summary_zh": "<paragraph>\u89e3\u91cb\u6027\u662f\u6df1\u5ea6\u5b78\u7fd2\u4e2d\u9577\u671f\u7684\u6311\u6230\uff0c\u7279\u5225\u662f\u5728\u91ab\u7642\u4fdd\u5065\u7b49\u9ad8\u98a8\u96aa\u9818\u57df\u3002\u5e38\u898b\u7684\u89e3\u91cb\u6027\u65b9\u6cd5\u6703\u5f37\u8abf\u9a45\u52d5 AI \u6a21\u578b\u6c7a\u7b56\u7684\u5f71\u50cf\u5340\u57df\u3002\u7136\u800c\uff0c\u4eba\u985e\u5f88\u5927\u7a0b\u5ea6\u4f9d\u8cf4\u8a9e\u8a00\u4f86\u50b3\u9054\u4e0d\u50c5\u662f\u300c\u5728\u54ea\u88e1\u300d\uff0c\u9084\u6709\u300c\u662f\u4ec0\u9ebc\u300d\u7684\u89e3\u91cb\u3002\u6b64\u5916\uff0c\u5927\u591a\u6578\u89e3\u91cb\u6027\u65b9\u6cd5\u90fd\u5c08\u6ce8\u65bc\u89e3\u91cb\u500b\u5225 AI \u9810\u6e2c\uff0c\u800c\u4e0d\u662f\u63cf\u8ff0 AI \u6a21\u578b\u4e00\u822c\u4f7f\u7528\u7684\u7279\u5fb5\u3002\u5f8c\u8005\u5c0d\u65bc\u6a21\u578b\u548c\u8cc7\u6599\u96c6\u7a3d\u6838\u7279\u5225\u6709\u7528\uff0c\u751a\u81f3\u53ef\u80fd\u5728 AI \u6108\u4f86\u6108\u7528\u65bc\u65b0\u7a4e\u4efb\u52d9\u6642\u7522\u751f\u77e5\u8b58\u3002\u5728\u6b64\uff0c\u6211\u5011\u63d0\u51fa\u4e00\u500b\u4f7f\u7528\u8996\u89ba\u8a9e\u8a00\u6a21\u578b\u4f86\u8fa8\u8b58\u8996\u89ba\u5206\u985e\u4efb\u52d9\u7684\u8a9e\u8a00\u63cf\u8ff0\u7b26\u7684\u89e3\u91cb\u6027\u7b56\u7565\u3002\u900f\u904e\u5229\u7528\u5f71\u50cf\u548c\u6587\u5b57\u4e4b\u9593\u9810\u5148\u8a13\u7df4\u7684\u806f\u5408\u5d4c\u5165\u7a7a\u9593\uff0c\u6211\u5011\u7684\u505a\u6cd5\u5c07\u65b0\u7684\u5206\u985e\u4efb\u52d9\u4f30\u8a08\u70ba\u4e00\u500b\u7dda\u6027\u6587\u5b57\u7d44\u5408\uff0c\u5c0e\u81f4\u6bcf\u500b\u6587\u5b57\u90fd\u6709\u6b0a\u91cd\uff0c\u8868\u793a\u5b83\u8207\u57fa\u65bc\u8996\u89ba\u7684\u5206\u985e\u5668\u5c0d\u9f4a\u3002\u6211\u5011\u4f7f\u7528\u5169\u500b\u91ab\u5b78\u5f71\u50cf\u5206\u985e\u4efb\u52d9\u4f86\u8a55\u4f30\u6211\u5011\u7684\u505a\u6cd5\uff0c\u6211\u5011\u767c\u73fe\u7522\u751f\u7684\u63cf\u8ff0\u7b26\u5728\u5f88\u5927\u7a0b\u5ea6\u4e0a\u8207\u81e8\u5e8a\u77e5\u8b58\u4e00\u81f4\uff0c\u5118\u7ba1\u7f3a\u4e4f\u7279\u5b9a\u9818\u57df\u7684\u8a9e\u8a00\u8a13\u7df4\u3002\u7136\u800c\uff0c\u6211\u5011\u7684\u505a\u6cd5\u4e5f\u767c\u73fe\u4e86\u6240\u7528\u516c\u958b\u8cc7\u6599\u96c6\u4e2d\u7684\u300c\u6377\u5f91\u9023\u7dda\u300d\u7684\u53ef\u80fd\u6027\u3002\u70ba\u4e86\u9054\u5230\u89e3\u91cb\u6027\u7684\u529f\u80fd\u6027\u8861\u91cf\uff0c\u6211\u5011\u9032\u884c\u4e86\u4e00\u9805\u8a66\u9a57\u8b80\u8005\u7814\u7a76\uff0c\u767c\u73fe AI \u8b58\u5225\u7684\u6587\u5b57\u80fd\u8b93\u975e\u5c08\u5bb6\u4eba\u985e\u5728\u975e\u5e73\u51e1\u7684\u5c64\u7d1a\u57f7\u884c\u5c08\u696d\u7684\u91ab\u7642\u4efb\u52d9\u3002\u7e3d\u4e4b\uff0c\u6211\u5011\u7684\u7d50\u679c\u5f37\u8abf\u4e86\u4f7f\u7528\u591a\u6a21\u5f0f\u57fa\u790e\u6a21\u578b\u4f86\u63d0\u4f9b\u76f4\u89c0\u7684\u3001\u57fa\u65bc\u8a9e\u8a00\u7684\u8996\u89ba\u4efb\u52d9\u89e3\u91cb\u7684\u6f5b\u529b\u3002</paragraph>", "author": "Shobhit Agarwal et.al.", "authors": "Shobhit Agarwal, Yevgeniy R. Semenov, William Lotter", "id": "2311.10933v1", "paper_url": "http://arxiv.org/abs/2311.10933v1", "repo": "https://github.com/lotterlab/task_word_explainability"}}