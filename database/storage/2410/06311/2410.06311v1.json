{"2410.06311": {"publish_time": "2024-10-08", "title": "A Comparative Study of Hybrid Models in Health Misinformation Text Classification", "paper_summary": "This study evaluates the effectiveness of machine learning (ML) and deep\nlearning (DL) models in detecting COVID-19-related misinformation on online\nsocial networks (OSNs), aiming to develop more effective tools for countering\nthe spread of health misinformation during the pan-demic. The study trained and\ntested various ML classifiers (Naive Bayes, SVM, Random Forest, etc.), DL\nmodels (CNN, LSTM, hybrid CNN+LSTM), and pretrained language models\n(DistilBERT, RoBERTa) on the \"COVID19-FNIR DATASET\". These models were\nevaluated for accuracy, F1 score, recall, precision, and ROC, and used\npreprocessing techniques like stemming and lemmatization. The results showed\nSVM performed well, achieving a 94.41% F1-score. DL models with Word2Vec\nembeddings exceeded 98% in all performance metrics (accuracy, F1 score, recall,\nprecision & ROC). The CNN+LSTM hybrid models also exceeded 98% across\nperformance metrics, outperforming pretrained models like DistilBERT and\nRoBERTa. Our study concludes that DL and hybrid DL models are more effective\nthan conventional ML algorithms for detecting COVID-19 misinformation on OSNs.\nThe findings highlight the importance of advanced neural network approaches and\nlarge-scale pretraining in misinformation detection. Future research should\noptimize these models for various misinformation types and adapt to changing\nOSNs, aiding in combating health misinformation.", "paper_summary_zh": "\u9019\u9805\u7814\u7a76\u8a55\u4f30\u6a5f\u5668\u5b78\u7fd2 (ML) \u548c\u6df1\u5ea6\u5b78\u7fd2 (DL) \u6a21\u578b\u5728\u5075\u6e2c\u7dda\u4e0a\u793e\u7fa4\u7db2\u8def (OSN) \u4e0a\u8207 COVID-19 \u76f8\u95dc\u7684\u932f\u8aa4\u8a0a\u606f\u7684\u6709\u6548\u6027\uff0c\u76ee\u6a19\u662f\u958b\u767c\u66f4\u6709\u6548\u7684\u5de5\u5177\u4f86\u5c0d\u6297\u5927\u6d41\u884c\u671f\u9593\u5065\u5eb7\u932f\u8aa4\u8a0a\u606f\u7684\u6563\u5e03\u3002\u9019\u9805\u7814\u7a76\u8a13\u7df4\u4e26\u6e2c\u8a66\u4e86\u5404\u7a2e ML \u5206\u985e\u5668\uff08\u6a38\u7d20\u8c9d\u6c0f\u3001SVM\u3001\u96a8\u6a5f\u68ee\u6797\u7b49\uff09\u3001DL \u6a21\u578b\uff08CNN\u3001LSTM\u3001\u6df7\u5408 CNN+LSTM\uff09\u548c\u9810\u8a13\u7df4\u8a9e\u8a00\u6a21\u578b\uff08DistilBERT\u3001RoBERTa\uff09\u5728\u300cCOVID19-FNIR \u8cc7\u6599\u96c6\u300d\u4e0a\u3002\u9019\u4e9b\u6a21\u578b\u7d93\u904e\u8a55\u4f30\uff0c\u6a19\u6e96\u70ba\u6e96\u78ba\u5ea6\u3001F1 \u5206\u6578\u3001\u53ec\u56de\u7387\u3001\u7cbe\u78ba\u5ea6\u548c ROC\uff0c\u4e26\u4f7f\u7528\u4e86\u8a5e\u5e79\u5316\u548c\u8a5e\u5f62\u9084\u539f\u7b49\u524d\u8655\u7406\u6280\u8853\u3002\u7d50\u679c\u986f\u793a SVM \u8868\u73fe\u826f\u597d\uff0c\u9054\u5230 94.41% \u7684 F1 \u5206\u6578\u3002\u4f7f\u7528 Word2Vec \u5d4c\u5165\u7684 DL \u6a21\u578b\u5728\u6240\u6709\u6548\u80fd\u6307\u6a19\uff08\u6e96\u78ba\u5ea6\u3001F1 \u5206\u6578\u3001\u53ec\u56de\u7387\u3001\u7cbe\u78ba\u5ea6\u548c ROC\uff09\u4e2d\u90fd\u8d85\u904e 98%\u3002CNN+LSTM \u6df7\u5408\u6a21\u578b\u5728\u6240\u6709\u6548\u80fd\u6307\u6a19\u4e2d\u4e5f\u8d85\u904e 98%\uff0c\u512a\u65bc DistilBERT \u548c RoBERTa \u7b49\u9810\u8a13\u7df4\u6a21\u578b\u3002\u6211\u5011\u7684\u7814\u7a76\u7d50\u8ad6\u662f\uff0cDL \u548c\u6df7\u5408 DL \u6a21\u578b\u6bd4\u50b3\u7d71 ML \u6f14\u7b97\u6cd5\u66f4\u80fd\u6709\u6548\u5075\u6e2c OSN \u4e0a\u7684 COVID-19 \u932f\u8aa4\u8a0a\u606f\u3002\u9019\u4e9b\u767c\u73fe\u7a81\u986f\u4e86\u9032\u968e\u795e\u7d93\u7db2\u8def\u65b9\u6cd5\u548c\u932f\u8aa4\u8a0a\u606f\u5075\u6e2c\u4e2d\u5927\u898f\u6a21\u9810\u8a13\u7df4\u7684\u91cd\u8981\u6027\u3002\u672a\u4f86\u7684\u7814\u7a76\u61c9\u91dd\u5c0d\u5404\u7a2e\u932f\u8aa4\u8a0a\u606f\u985e\u578b\u6700\u4f73\u5316\u9019\u4e9b\u6a21\u578b\uff0c\u4e26\u9069\u61c9\u4e0d\u65b7\u8b8a\u5316\u7684 OSN\uff0c\u5354\u52a9\u6253\u64ca\u5065\u5eb7\u932f\u8aa4\u8a0a\u606f\u3002", "author": "Mkululi Sikosana et.al.", "authors": "Mkululi Sikosana, Oluwaseun Ajao, Sean Maudsley-Barton", "id": "2410.06311v1", "paper_url": "http://arxiv.org/abs/2410.06311v1", "repo": "null"}}