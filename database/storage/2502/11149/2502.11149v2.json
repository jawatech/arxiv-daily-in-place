{"2502.11149": {"publish_time": "2025-02-16", "title": "Large Language-Geometry Model: When LLM meets Equivariance", "paper_summary": "Accurately predicting 3D structures and dynamics of physical systems is\ncrucial in scientific applications. Existing approaches that rely on geometric\nGraph Neural Networks (GNNs) effectively enforce $\\mathrm{E}(3)$-equivariance,\nbut they often fall in leveraging extensive broader information. While direct\napplication of Large Language Models (LLMs) can incorporate external knowledge,\nthey lack the capability for spatial reasoning with guaranteed equivariance. In\nthis paper, we propose EquiLLM, a novel framework for representing 3D physical\nsystems that seamlessly integrates E(3)-equivariance with LLM capabilities.\nSpecifically, EquiLLM comprises four key components: geometry-aware prompting,\nan equivariant encoder, an LLM, and an equivariant adaptor. Essentially, the\nLLM guided by the instructive prompt serves as a sophisticated invariant\nfeature processor, while 3D directional information is exclusively handled by\nthe equivariant encoder and adaptor modules. Experimental results demonstrate\nthat EquiLLM delivers significant improvements over previous methods across\nmolecular dynamics simulation, human motion simulation, and antibody design,\nhighlighting its promising generalizability.", "paper_summary_zh": "<paragraph>\u6e96\u78ba\u9810\u6e2c\u7269\u7406\u7cfb\u7d71\u7684 3D \u7d50\u69cb\u548c\u52d5\u529b\u5b78\u5728\u79d1\u5b78\u61c9\u7528\u4e2d\u81f3\u95dc\u91cd\u8981\u3002\u73fe\u6709\u4f9d\u8cf4\u65bc\u5e7e\u4f55\u5716\u795e\u7d93\u7db2\u8def (GNN) \u7684\u65b9\u6cd5\u6709\u6548\u5730\u5f37\u5236\u57f7\u884c\u4e86 $\\mathrm{E}(3)$-\u7b49\u8b8a\u6027\uff0c\u4f46\u5b83\u5011\u901a\u5e38\u7121\u6cd5\u5229\u7528\u5ee3\u6cdb\u7684\u66f4\u5ee3\u6cdb\u8cc7\u8a0a\u3002\u5118\u7ba1\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u76f4\u63a5\u61c9\u7528\u53ef\u4ee5\u7d0d\u5165\u5916\u90e8\u77e5\u8b58\uff0c\u4f46\u5b83\u5011\u7f3a\u4e4f\u4fdd\u8b49\u7b49\u8b8a\u6027\u7684\u7a7a\u9593\u63a8\u7406\u80fd\u529b\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e86 EquiLLM\uff0c\u4e00\u500b\u7528\u65bc\u8868\u793a 3D \u7269\u7406\u7cfb\u7d71\u7684\u65b0\u6846\u67b6\uff0c\u5b83\u5c07 E(3)-\u7b49\u8b8a\u6027\u8207 LLM \u80fd\u529b\u7121\u7e2b\u6574\u5408\u3002\u5177\u9ad4\u4f86\u8aaa\uff0cEquiLLM \u5305\u542b\u56db\u500b\u95dc\u9375\u7d44\u6210\u90e8\u5206\uff1a\u611f\u77e5\u5e7e\u4f55\u7684\u63d0\u793a\u3001\u7b49\u8b8a\u7de8\u78bc\u5668\u3001LLM \u548c\u7b49\u8b8a\u9069\u914d\u5668\u3002\u5f9e\u672c\u8cea\u4e0a\u8b1b\uff0c\u7531\u6307\u5c0e\u6027\u63d0\u793a\u5f15\u5c0e\u7684 LLM \u4f5c\u70ba\u4e00\u500b\u8907\u96dc\u7684\u4e0d\u8b8a\u7279\u5fb5\u8655\u7406\u5668\uff0c\u800c 3D \u65b9\u5411\u8cc7\u8a0a\u5247\u7531\u7b49\u8b8a\u7de8\u78bc\u5668\u548c\u9069\u914d\u5668\u6a21\u7d44\u7368\u5bb6\u8655\u7406\u3002\u5be6\u9a57\u7d50\u679c\u8868\u660e\uff0cEquiLLM \u5728\u5206\u5b50\u52d5\u529b\u5b78\u6a21\u64ec\u3001\u4eba\u985e\u904b\u52d5\u6a21\u64ec\u548c\u6297\u9ad4\u8a2d\u8a08\u65b9\u9762\u6bd4\u4ee5\u524d\u7684\u65b9\u6cd5\u6709\u4e86\u986f\u8457\u7684\u6539\u9032\uff0c\u7a81\u986f\u4e86\u5176\u6709\u5e0c\u671b\u7684\u6cdb\u5316\u80fd\u529b\u3002</paragraph>", "author": "Zongzhao Li et.al.", "authors": "Zongzhao Li, Jiacheng Cen, Bing Su, Wenbing Huang, Tingyang Xu, Yu Rong, Deli Zhao", "id": "2502.11149v2", "paper_url": "http://arxiv.org/abs/2502.11149v2", "repo": "null"}}