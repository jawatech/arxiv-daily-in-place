{"2502.13603": {"publish_time": "2025-02-19", "title": "Efficient Safety Retrofitting Against Jailbreaking for LLMs", "paper_summary": "Direct Preference Optimization (DPO) is an efficient alignment technique that\nsteers LLMs towards preferable outputs by training on preference data,\nbypassing the need for explicit reward models. Its simplicity enables easy\nadaptation to various domains and safety requirements. This paper examines\nDPO's effectiveness in model safety against jailbreaking attacks while\nminimizing data requirements and training costs. We introduce Egida, a dataset\nexpanded from multiple sources, which includes 27 different safety topics and\n18 different attack styles, complemented with synthetic and human labels. This\ndata is used to boost the safety of state-of-the-art LLMs\n(Llama-3.1-8B/70B-Instruct, Qwen-2.5-7B/72B-Instruct) across topics and attack\nstyles. In addition to safety evaluations, we assess their post-alignment\nperformance degradation in general purpose tasks, and their tendency to over\nrefusal. Following the proposed methodology, trained models reduce their Attack\nSuccess Rate by 10%-30%, using small training efforts (2,000 samples) with low\ncomputational cost (3\\$ for 8B models, 20\\$ for 72B models). Safety aligned\nmodels generalize to unseen topics and attack styles, with the most successful\nattack style reaching a success rate around 5%. Size and family are found to\nstrongly influence model malleability towards safety, pointing at the\nimportance of pre-training choices. To validate our findings, a large\nindependent assessment of human preference agreement with Llama-Guard-3-8B is\nconducted by the authors and the associated dataset Egida-HSafe is released.\nOverall, this study illustrates how affordable and accessible it is to enhance\nLLM safety using DPO while outlining its current limitations. All datasets and\nmodels are released to enable reproducibility and further research.", "paper_summary_zh": "\u76f4\u63a5\u504f\u597d\u6700\u4f73\u5316 (DPO) \u662f\u4e00\u7a2e\u6709\u6548\u5c0d\u9f4a\u6280\u8853\uff0c\u900f\u904e\u504f\u597d\u8cc7\u6599\u8a13\u7df4\uff0c\u5c07 LLM \u5f15\u5c0e\u81f3\u8f03\u4f73\u8f38\u51fa\uff0c\u7121\u9808\u660e\u78ba\u56de\u994b\u6a21\u578b\u3002\u5176\u7c21\u6f54\u6027\u8b93\u5b83\u6613\u65bc\u9069\u61c9\u5404\u7a2e\u9818\u57df\u548c\u5b89\u5168\u9700\u6c42\u3002\u672c\u6587\u63a2\u8a0e DPO \u5728\u6a21\u578b\u5b89\u5168\u65b9\u9762\u5c0d\u6297\u8d8a\u7344\u653b\u64ca\u7684\u6709\u6548\u6027\uff0c\u540c\u6642\u5c07\u8cc7\u6599\u9700\u6c42\u548c\u8a13\u7df4\u6210\u672c\u964d\u81f3\u6700\u4f4e\u3002\u6211\u5011\u5f15\u9032 Egida\uff0c\u4e00\u500b\u5f9e\u591a\u500b\u4f86\u6e90\u64f4\u5c55\u800c\u4f86\u7684\u8cc7\u6599\u96c6\uff0c\u5176\u4e2d\u5305\u542b 27 \u500b\u4e0d\u540c\u7684\u5b89\u5168\u4e3b\u984c\u548c 18 \u7a2e\u4e0d\u540c\u7684\u653b\u64ca\u6a23\u5f0f\uff0c\u4e26\u9644\u6709\u5408\u6210\u548c\u4eba\u5de5\u6a19\u7c64\u3002\u9019\u4e9b\u8cc7\u6599\u7528\u65bc\u63d0\u5347\u6700\u5148\u9032 LLM\uff08Llama-3.1-8B/70B-Instruct\u3001Qwen-2.5-7B/72B-Instruct\uff09\u5728\u5404\u7a2e\u4e3b\u984c\u548c\u653b\u64ca\u6a23\u5f0f\u4e2d\u7684\u5b89\u5168\u6027\u3002\u9664\u4e86\u5b89\u5168\u8a55\u4f30\u5916\uff0c\u6211\u5011\u8a55\u4f30\u5b83\u5011\u5728\u4e00\u822c\u4efb\u52d9\u4e2d\u5c0d\u9f4a\u5f8c\u6548\u80fd\u7684\u964d\u4f4e\uff0c\u4ee5\u53ca\u5b83\u5011\u904e\u5ea6\u62d2\u7d55\u7684\u50be\u5411\u3002\u9075\u5faa\u5efa\u8b70\u7684\u65b9\u6cd5\uff0c\u8a13\u7df4\u5f8c\u7684\u6a21\u578b\u5c07\u5b83\u5011\u7684\u653b\u64ca\u6210\u529f\u7387\u964d\u4f4e\u4e86 10%-30%\uff0c\u4e14\u8a13\u7df4\u5de5\u4f5c\u91cf\u5c0f\uff082,000 \u500b\u7bc4\u4f8b\uff09\uff0c\u904b\u7b97\u6210\u672c\u4f4e\uff088B \u6a21\u578b\u70ba 3 \u7f8e\u5143\uff0c72B \u6a21\u578b\u70ba 20 \u7f8e\u5143\uff09\u3002\u5b89\u5168\u5c0d\u9f4a\u6a21\u578b\u6982\u62ec\u81f3\u672a\u898b\u4e3b\u984c\u548c\u653b\u64ca\u6a23\u5f0f\uff0c\u5176\u4e2d\u6700\u6210\u529f\u7684\u653b\u64ca\u6a23\u5f0f\u6210\u529f\u7387\u7d04\u70ba 5%\u3002\u767c\u73fe\u6a21\u578b\u5927\u5c0f\u548c\u7cfb\u5217\u6703\u5f37\u70c8\u5f71\u97ff\u6a21\u578b\u5c0d\u5b89\u5168\u6027\u7684\u53ef\u5851\u6027\uff0c\u9019\u9ede\u51fa\u9810\u8a13\u7df4\u9078\u64c7\u7684\u91cd\u8981\u6027\u3002\u70ba\u4e86\u9a57\u8b49\u6211\u5011\u7684\u767c\u73fe\uff0c\u4f5c\u8005\u9032\u884c\u4e86 Llama-Guard-3-8B \u4eba\u985e\u504f\u597d\u4e00\u81f4\u6027\u7684\u5ee3\u6cdb\u7368\u7acb\u8a55\u4f30\uff0c\u4e26\u767c\u5e03\u4e86\u76f8\u95dc\u8cc7\u6599\u96c6 Egida-HSafe\u3002\u6574\u9ad4\u800c\u8a00\uff0c\u672c\u7814\u7a76\u8aaa\u660e\u4e86\u4f7f\u7528 DPO \u589e\u5f37 LLM \u5b89\u5168\u6027\u7684\u7d93\u6fdf\u6027\u548c\u53ef\u53ca\u6027\uff0c\u540c\u6642\u6982\u8ff0\u4e86\u5176\u7576\u524d\u7684\u9650\u5236\u3002\u6240\u6709\u8cc7\u6599\u96c6\u548c\u6a21\u578b\u7686\u5df2\u767c\u5e03\uff0c\u4ee5\u5229\u65bc\u91cd\u73fe\u6027\u548c\u9032\u4e00\u6b65\u7814\u7a76\u3002", "author": "Dario Garcia-Gasulla et.al.", "authors": "Dario Garcia-Gasulla, Anna Arias-Duart, Adrian Tormos, Daniel Hinjos, Oscar Molina-Sedano, Ashwin Kumar Gururajan, Maria Eugenia Cardello", "id": "2502.13603v1", "paper_url": "http://arxiv.org/abs/2502.13603v1", "repo": "null"}}