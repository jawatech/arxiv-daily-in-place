# arxiv-daily
 Automated deployment @ 2024-06-04 20:23:16 Asia/Taipei
> Welcome to contribute! Add your topics and keywords in [`topic.yml`](https://github.com/jawatech/arxiv-daily-in-place/blob/main/database/topic.yml).
> You can also view historical data through the [storage](https://github.com/jawatech/arxiv-daily-in-place/blob/main/database/storage).

## AI

### Medical
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-05-31**|**Recurrent neural networks: vanishing and exploding gradients are not the end of the story**|Nicolas Zucchet et.al.|[2405.21064v1](http://arxiv.org/abs/2405.21064v1)|null|
|**2024-05-31**|**Generative Adversarial Networks in Ultrasound Imaging: Extending Field of View Beyond Conventional Limits**|Matej Gazda et.al.|[2405.20981v1](http://arxiv.org/abs/2405.20981v1)|null|
|**2024-05-31**|**OR-Bench: An Over-Refusal Benchmark for Large Language Models**|Justin Cui et.al.|[2405.20947v1](http://arxiv.org/abs/2405.20947v1)|null|
|**2024-05-31**|**ABodyBuilder3: Improved and scalable antibody structure predictions**|Henry Kenlay et.al.|[2405.20863v1](http://arxiv.org/abs/2405.20863v1)|[link](https://github.com/exscientia/abodybuilder3)|
|**2024-05-31**|**Maximum Temperature Prediction Using Remote Sensing Data Via Convolutional Neural Network**|Lorenzo Innocenti et.al.|[2405.20731v1](http://arxiv.org/abs/2405.20731v1)|null|
|**2024-05-31**|**GAMedX: Generative AI-based Medical Entity Data Extractor Using Large Language Models**|Mohammed-Khalil Ghali et.al.|[2405.20585v1](http://arxiv.org/abs/2405.20585v1)|null|
|**2024-05-31**|**The Point of View of a Sentiment: Towards Clinician Bias Detection in Psychiatric Notes**|Alissa A. Valentine et.al.|[2405.20582v1](http://arxiv.org/abs/2405.20582v1)|null|
|**2024-05-31**|**Can Machine Learning Assist in Diagnosis of Primary Immune Thrombocytopenia? A feasibility study**|Haroon Miah et.al.|[2405.20562v1](http://arxiv.org/abs/2405.20562v1)|null|
|**2024-05-30**|**Enhancing Performance for Highly Imbalanced Medical Data via Data Regularization in a Federated Learning Setting**|Georgios Tsoumplekas et.al.|[2405.20430v1](http://arxiv.org/abs/2405.20430v1)|null|
|**2024-05-30**|**Worse than Random? An Embarrassingly Simple Probing Evaluation of Large Multimodal Models in Medical VQA**|Qianqi Yan et.al.|[2405.20421v1](http://arxiv.org/abs/2405.20421v1)|[link](https://github.com/eric-ai-lab/probmed)|
|**2024-05-30**|**Enhancing Antibiotic Stewardship using a Natural Language Approach for Better Feature Representation**|Simon A. Lee et.al.|[2405.20419v1](http://arxiv.org/abs/2405.20419v1)|null|
|**2024-05-30**|**MSSC-BiMamba: Multimodal Sleep Stage Classification and Early Diagnosis of Sleep Disorders with Bidirectional Mamba**|Chao Zhang et.al.|[2405.20142v2](http://arxiv.org/abs/2405.20142v2)|null|
|**2024-05-30**|**Out-of-distribution Reject Option Method for Dataset Shift Problem in Early Disease Onset Prediction**|Taisei Tosaki et.al.|[2405.19864v1](http://arxiv.org/abs/2405.19864v1)|null|
|**2024-05-30**|**Dynamic feature selection in medical predictive monitoring by reinforcement learning**|Yutong Chen et.al.|[2405.19729v1](http://arxiv.org/abs/2405.19729v1)|null|
|**2024-05-30**|**Unlocking the Power of Spatial and Temporal Information in Medical Multimodal Pre-training**|Jinxia Yang et.al.|[2405.19654v1](http://arxiv.org/abs/2405.19654v1)|[link](https://github.com/svt-yang/medst)|
|**2024-05-30**|**Leveraging Open-Source Large Language Models for encoding Social Determinants of Health using an Intelligent Router**|Akul Goel et.al.|[2405.19631v1](http://arxiv.org/abs/2405.19631v1)|null|
|**2024-05-29**|**Dr-LLaVA: Visual Instruction Tuning with Symbolic Clinical Grounding**|Shenghuan Sun et.al.|[2405.19567v1](http://arxiv.org/abs/2405.19567v1)|null|
|**2024-05-29**|**CheXpert Plus: Hundreds of Thousands of Aligned Radiology Texts, Images and Patients**|Pierre Chambon et.al.|[2405.19538v1](http://arxiv.org/abs/2405.19538v1)|[link](https://github.com/stanford-aimi/chexpert-plus)|
|**2024-05-29**|**Participation in the age of foundation models**|Harini Suresh et.al.|[2405.19479v1](http://arxiv.org/abs/2405.19479v1)|null|
|**2024-05-29**|**MemControl: Mitigating Memorization in Medical Diffusion Models via Automated Parameter Selection**|Raman Dutt et.al.|[2405.19458v1](http://arxiv.org/abs/2405.19458v1)|null|
|**2024-05-29**|**Conformal Depression Prediction**|Yonghong Li et.al.|[2405.18723v1](http://arxiv.org/abs/2405.18723v1)|null|
|**2024-05-28**|**D-CoRP: Differentiable Connectivity Refinement for Functional Brain Networks**|Haoyu Hu et.al.|[2405.18658v1](http://arxiv.org/abs/2405.18658v1)|null|
|**2024-05-28**|**DTR-Bench: An in silico Environment and Benchmark Platform for Reinforcement Learning Based Dynamic Treatment Regime**|Zhiyao Luo et.al.|[2405.18610v1](http://arxiv.org/abs/2405.18610v1)|[link](https://github.com/gilesluo/dtr-bench)|
|**2024-05-28**|**Low-rank finetuning for LLMs: A fairness perspective**|Saswat Das et.al.|[2405.18572v1](http://arxiv.org/abs/2405.18572v1)|null|
|**2024-05-28**|**Reinforcement Learning in Dynamic Treatment Regimes Needs Critical Reexamination**|Zhiyao Luo et.al.|[2405.18556v1](http://arxiv.org/abs/2405.18556v1)|[link](https://github.com/gilesluo/reassessdtr)|
|**2024-05-28**|**The FAIIR Tool: A Conversational AI Agent Assistant for Youth Mental Health Service Provision**|Stephen Obadinma et.al.|[2405.18553v1](http://arxiv.org/abs/2405.18553v1)|null|
|**2024-05-28**|**Improved Emotional Alignment of AI and Humans: Human Ratings of Emotions Expressed by Stable Diffusion v1, DALL-E 2, and DALL-E 3**|James Derek Lomas et.al.|[2405.18510v1](http://arxiv.org/abs/2405.18510v1)|null|
|**2024-05-28**|**A Review and Implementation of Object Detection Models and Optimizations for Real-time Medical Mask Detection during the COVID-19 Pandemic**|Ioanna Gogou et.al.|[2405.18387v1](http://arxiv.org/abs/2405.18387v1)|[link](https://github.com/joangog/object-detection)|
|**2024-05-28**|**Brain Tumor Segmentation (BraTS) Challenge 2024: Meningioma Radiotherapy Planning Automated Segmentation**|Dominic LaBella et.al.|[2405.18383v1](http://arxiv.org/abs/2405.18383v1)|null|
|**2024-05-28**|**Intelligent Clinical Documentation: Harnessing Generative AI for Patient-Centric Clinical Note Generation**|Anjanava Biswas et.al.|[2405.18346v1](http://arxiv.org/abs/2405.18346v1)|null|
|**2024-05-28**|**Histopathology Based AI Model Predicts Anti-Angiogenic Therapy Response in Renal Cancer Clinical Trial**|Jay Jasti et.al.|[2405.18327v1](http://arxiv.org/abs/2405.18327v1)|null|
|**2024-05-28**|**Edinburgh Clinical NLP at MEDIQA-CORR 2024: Guiding Large Language Models with Hints**|Aryo Pradipta Gema et.al.|[2405.18028v1](http://arxiv.org/abs/2405.18028v1)|null|
|**2024-05-28**|**Towards Clinical AI Fairness: Filling Gaps in the Puzzle**|Mingxuan Liu et.al.|[2405.17921v1](http://arxiv.org/abs/2405.17921v1)|null|
|**2024-05-28**|**Near-Infrared and Low-Rank Adaptation of Vision Transformers in Remote Sensing**|Irem Ulku et.al.|[2405.17901v1](http://arxiv.org/abs/2405.17901v1)|null|
|**2024-05-28**|**AI Alignment with Changing and Influenceable Reward Functions**|Micah Carroll et.al.|[2405.17713v1](http://arxiv.org/abs/2405.17713v1)|null|
|**2024-05-27**|**The Economic Implications of Large Language Model Selection on Earnings and Return on Investment: A Decision Theoretic Model**|Geraldo Xex√©o et.al.|[2405.17637v1](http://arxiv.org/abs/2405.17637v1)|null|
|**2024-05-27**|**BIOSCAN-CLIP: Bridging Vision and Genomics for Biodiversity Monitoring at Scale**|ZeMing Gong et.al.|[2405.17537v1](http://arxiv.org/abs/2405.17537v1)|null|
|**2024-05-27**|**On Fairness of Low-Rank Adaptation of Large Models**|Zhoujie Ding et.al.|[2405.17512v1](http://arxiv.org/abs/2405.17512v1)|null|
|**2024-05-26**|**Cross-Modality Jailbreak and Mismatched Attacks on Medical Multimodal Large Language Models**|Xijie Huang et.al.|[2405.20775v1](http://arxiv.org/abs/2405.20775v1)|null|
|**2024-05-26**|**Scalable Numerical Embeddings for Multivariate Time Series: Enhancing Healthcare Data Representation Learning**|Chun-Kai Huang et.al.|[2405.16557v1](http://arxiv.org/abs/2405.16557v1)|null|
|**2024-05-26**|**SED: Self-Evaluation Decoding Enhances Large Language Models for Better Generation**|Ziqin Luo et.al.|[2405.16552v1](http://arxiv.org/abs/2405.16552v1)|null|
|**2024-05-26**|**Gamified AI Approch for Early Detection of Dementia**|Paramita Kundu Maji et.al.|[2405.16538v1](http://arxiv.org/abs/2405.16538v1)|null|
|**2024-05-26**|**ECG Semantic Integrator (ESI): A Foundation ECG Model Pretrained with LLM-Enhanced Cardiological Text**|Han Yu et.al.|[2405.19366v1](http://arxiv.org/abs/2405.19366v1)|null|
|**2024-05-26**|**Improving Health Professionals' Onboarding with AI and XAI for Trustworthy Human-AI Collaborative Decision Making**|Min Hun Lee et.al.|[2405.16424v1](http://arxiv.org/abs/2405.16424v1)|null|
|**2024-05-26**|**Exploring Nutritional Impact on Alzheimer's Mortality: An Explainable AI Approach**|Ziming Liu et.al.|[2405.17502v1](http://arxiv.org/abs/2405.17502v1)|null|
|**2024-05-26**|**Augmented Risk Prediction for the Onset of Alzheimer's Disease from Electronic Health Records with Large Language Models**|Jiankun Wang et.al.|[2405.16413v1](http://arxiv.org/abs/2405.16413v1)|null|
|**2024-05-26**|**Assessing Empathy in Large Language Models with Real-World Physician-Patient Interactions**|Man Luo et.al.|[2405.16402v1](http://arxiv.org/abs/2405.16402v1)|null|
|**2024-05-25**|**Uncertainty Measurement of Deep Learning System based on the Convex Hull of Training Sets**|Hyekyoung Hwang et.al.|[2405.16082v1](http://arxiv.org/abs/2405.16082v1)|null|
|**2024-05-25**|**Transductive Confidence Machine and its application to Medical Data Sets**|David Lindsay et.al.|[2405.15988v1](http://arxiv.org/abs/2405.15988v1)|null|
|**2024-05-24**|**The Impact and Opportunities of Generative AI in Fact-Checking**|Robert Wolfe et.al.|[2405.15985v1](http://arxiv.org/abs/2405.15985v1)|null|
|**2024-05-24**|**Risk Factor Identification In Osteoporosis Using Unsupervised Machine Learning Techniques**|Mikayla Calitis et.al.|[2405.15882v1](http://arxiv.org/abs/2405.15882v1)|null|
|**2024-05-24**|**Enhancing Adverse Drug Event Detection with Multimodal Dataset: Corpus Creation and Model Development**|Pranab Sahoo et.al.|[2405.15766v2](http://arxiv.org/abs/2405.15766v2)|[link](https://github.com/singhayush27/mmade)|
|**2024-05-24**|**Medformer: A Multi-Granularity Patching Transformer for Medical Time-Series Classification**|Yihe Wang et.al.|[2405.19363v1](http://arxiv.org/abs/2405.19363v1)|null|
|**2024-05-24**|**Effective Confidence Region Prediction Using Probability Forecasters**|David Lindsay et.al.|[2405.15642v1](http://arxiv.org/abs/2405.15642v1)|null|
|**2024-05-24**|**Concept-based Explainable Malignancy Scoring on Pulmonary Nodules in CT Images**|Rinat I. Dumaev et.al.|[2405.17483v1](http://arxiv.org/abs/2405.17483v1)|null|
|**2024-05-24**|**PriCE: Privacy-Preserving and Cost-Effective Scheduling for Parallelizing the Large Medical Image Processing Workflow over Hybrid Clouds**|Yuandou Wang et.al.|[2405.15398v1](http://arxiv.org/abs/2405.15398v1)|[link](https://github.com/yuandou168/price)|
|**2024-05-24**|**Towards a Probabilistic Fusion Approach for Robust Battery Prognostics**|Jokin Alcibar et.al.|[2405.15292v1](http://arxiv.org/abs/2405.15292v1)|null|
|**2024-05-24**|**Efficient Reinforcement Learning via Large Language Model-based Search**|Siddhant Bhambri et.al.|[2405.15194v1](http://arxiv.org/abs/2405.15194v1)|null|
|**2024-05-24**|**Deep Activity Model: A Generative Approach for Human Mobility Pattern Synthesis**|Xishun Liao et.al.|[2405.17468v1](http://arxiv.org/abs/2405.17468v1)|null|
|**2024-05-23**|**Generative Camera Dolly: Extreme Monocular Dynamic Novel View Synthesis**|Basile Van Hoorick et.al.|[2405.14868v1](http://arxiv.org/abs/2405.14868v1)|null|
|**2024-05-23**|**A Declarative System for Optimizing AI Workloads**|Chunwei Liu et.al.|[2405.14696v2](http://arxiv.org/abs/2405.14696v2)|[link](https://github.com/mitdbg/palimpzest)|
|**2024-05-23**|**Efficient Medical Question Answering with Knowledge-Augmented Question Generation**|Julien Khlaut et.al.|[2405.14654v1](http://arxiv.org/abs/2405.14654v1)|null|
|**2024-05-23**|**Concept Visualization: Explaining the CLIP Multi-modal Embedding Using WordNet**|Loris Giulivi et.al.|[2405.14563v1](http://arxiv.org/abs/2405.14563v1)|[link](https://github.com/loris2222/concept-visualization)|
|**2024-05-23**|**Exploring the use of a Large Language Model for data extraction in systematic reviews: a rapid feasibility study**|Lena Schmidt et.al.|[2405.14445v1](http://arxiv.org/abs/2405.14445v1)|null|
|**2024-05-23**|**Unraveling overoptimism and publication bias in ML-driven science**|Pouria Saidi et.al.|[2405.14422v1](http://arxiv.org/abs/2405.14422v1)|null|
|**2024-05-23**|**Boosting Medical Image-based Cancer Detection via Text-guided Supervision from Reports**|Guangyu Guo et.al.|[2405.14230v1](http://arxiv.org/abs/2405.14230v1)|null|
|**2024-05-23**|**Investigation of Customized Medical Decision Algorithms Utilizing Graph Neural Networks**|Yafeng Yan et.al.|[2405.17460v1](http://arxiv.org/abs/2405.17460v1)|null|
|**2024-05-23**|**Integrating Medical Imaging and Clinical Reports Using Multimodal Deep Learning for Advanced Disease Analysis**|Ziyan Yao et.al.|[2405.17459v1](http://arxiv.org/abs/2405.17459v1)|null|
|**2024-05-23**|**Structural Entities Extraction and Patient Indications Incorporation for Chest X-ray Report Generation**|Kang Liu et.al.|[2405.14905v1](http://arxiv.org/abs/2405.14905v1)|[link](https://github.com/mk-runner/sei-temp)|
|**2024-05-22**|**How Many Bytes Can You Take Out Of Brain-To-Text Decoding?**|Richard Antonello et.al.|[2405.14055v1](http://arxiv.org/abs/2405.14055v1)|null|
|**2024-05-22**|**Federated Learning in Healthcare: Model Misconducts, Security, Challenges, Applications, and Future Research Directions -- A Systematic Review**|Md Shahin Ali et.al.|[2405.13832v1](http://arxiv.org/abs/2405.13832v1)|null|
|**2024-05-22**|**Efficient Two-Stage Gaussian Process Regression Via Automatic Kernel Search and Subsampling**|Shifan Zhao et.al.|[2405.13785v1](http://arxiv.org/abs/2405.13785v1)|null|
|**2024-05-21**|**How Reliable AI Chatbots are for Disease Prediction from Patient Complaints?**|Ayesha Siddika Nipu et.al.|[2405.13219v1](http://arxiv.org/abs/2405.13219v1)|null|
|**2024-05-21**|**Interpretable Spatio-Temporal Embedding for Brain Structural-Effective Network with Ordinary Differential Equation**|Haoteng Tang et.al.|[2405.13190v1](http://arxiv.org/abs/2405.13190v1)|null|
|**2024-05-21**|**The Role of Emotions in Informational Support Question-Response Pairs in Online Health Communities: A Multimodal Deep Learning Approach**|Mohsen Jozani et.al.|[2405.13099v1](http://arxiv.org/abs/2405.13099v1)|null|
|**2024-05-21**|**KPG: Key Propagation Graph Generator for Rumor Detection based on Reinforcement Learning**|Yusong Zhang et.al.|[2405.13094v1](http://arxiv.org/abs/2405.13094v1)|null|
|**2024-05-21**|**A Masked Semi-Supervised Learning Approach for Otago Micro Labels Recognition**|Meng Shang et.al.|[2405.12711v2](http://arxiv.org/abs/2405.12711v2)|null|
|**2024-05-21**|**OLAPH: Improving Factuality in Biomedical Long-form Question Answering**|Minbyul Jeong et.al.|[2405.12701v1](http://arxiv.org/abs/2405.12701v1)|[link](https://github.com/dmis-lab/olaph)|
|**2024-05-21**|**Exploration of Masked and Causal Language Modelling for Text Generation**|Nicolo Micheletti et.al.|[2405.12630v1](http://arxiv.org/abs/2405.12630v1)|null|
|**2024-05-21**|**DrHouse: An LLM-empowered Diagnostic Reasoning System through Harnessing Outcomes from Sensor Data and Expert Knowledge**|Bufang Yang et.al.|[2405.12541v1](http://arxiv.org/abs/2405.12541v1)|null|
|**2024-05-21**|**A Survey of Artificial Intelligence in Gait-Based Neurodegenerative Disease Diagnosis**|Haocong Rao et.al.|[2405.13082v1](http://arxiv.org/abs/2405.13082v1)|[link](https://github.com/kali-hac/ai4ndd-survey)|
|**2024-05-21**|**Future You: A Conversation with an AI-Generated Future Self Reduces Anxiety, Negative Emotions, and Increases Future Self-Continuity**|Pat Pataranutaporn et.al.|[2405.12514v2](http://arxiv.org/abs/2405.12514v2)|null|
|**2024-05-20**|**Ensuring Ground Truth Accuracy in Healthcare with the EVINCE framework**|Edward Y. Chang et.al.|[2405.15808v2](http://arxiv.org/abs/2405.15808v2)|null|
|**2024-05-20**|**Digital Health and Indoor Air Quality: An IoT-Driven Human-Centred Visualisation Platform for Behavioural Change and Technology Acceptance**|Rameez Raja Kureshi et.al.|[2405.13064v1](http://arxiv.org/abs/2405.13064v1)|null|
|**2024-05-20**|**Recommender Algorithm for Supporting Self-Management of CVD Risk Factors in an Adult Population at Home**|Tatiana V. Afanasieva et.al.|[2405.11967v1](http://arxiv.org/abs/2405.11967v1)|null|
|**2024-05-20**|**Contactless Polysomnography: What Radio Waves Tell Us about Sleep**|Hao He et.al.|[2405.11739v1](http://arxiv.org/abs/2405.11739v1)|null|
|**2024-05-20**|**Large Language Models for Medicine: A Survey**|Yanxin Zheng et.al.|[2405.13055v1](http://arxiv.org/abs/2405.13055v1)|null|
|**2024-05-19**|**Towards Contactless Elevators with TinyML using CNN-based Person Detection and Keyword Spotting**|Anway S. Pimpalkar et.al.|[2405.13051v1](http://arxiv.org/abs/2405.13051v1)|null|
|**2024-05-19**|**Inquire, Interact, and Integrate: A Proactive Agent Collaborative Framework for Zero-Shot Multimodal Medical Reasoning**|Zishan Gu et.al.|[2405.11640v1](http://arxiv.org/abs/2405.11640v1)|null|
|**2024-05-19**|**Sociotechnical Implications of Generative Artificial Intelligence for Information Access**|Bhaskar Mitra et.al.|[2405.11612v1](http://arxiv.org/abs/2405.11612v1)|null|
|**2024-05-19**|**AI-Assisted Diagnosis for Covid-19 CXR Screening: From Data Collection to Clinical Validation**|Carlo Alberto Barbano et.al.|[2405.11598v1](http://arxiv.org/abs/2405.11598v1)|null|
|**2024-05-18**|**EyeFound: A Multimodal Generalist Foundation Model for Ophthalmic Imaging**|Danli Shi et.al.|[2405.11338v2](http://arxiv.org/abs/2405.11338v2)|null|
|**2024-05-18**|**Towards Knowledge-Infused Automated Disease Diagnosis Assistant**|Mohit Tomar et.al.|[2405.11181v1](http://arxiv.org/abs/2405.11181v1)|[link](https://github.com/nlp-rl/ki-ddi)|
|**2024-05-18**|**Multi-scale Information Sharing and Selection Network with Boundary Attention for Polyp Segmentation**|Xiaolu Kang et.al.|[2405.11151v1](http://arxiv.org/abs/2405.11151v1)|null|
|**2024-05-17**|**Generative Artificial Intelligence: A Systematic Review and Applications**|Sandeep Singh Sengar et.al.|[2405.11029v1](http://arxiv.org/abs/2405.11029v1)|null|
|**2024-05-17**|**COGNET-MD, an evaluation framework and dataset for Large Language Model benchmarks in the medical domain**|Dimitrios P. Panagoulias et.al.|[2405.10893v1](http://arxiv.org/abs/2405.10893v1)|null|
|**2024-05-17**|**Application of Artificial Intelligence in Schizophrenia Rehabilitation Management: Systematic Literature Review**|Hongyi Yang et.al.|[2405.10883v1](http://arxiv.org/abs/2405.10883v1)|null|
|**2024-05-17**|**Causality in the Can: Diet Coke's Impact on Fatness**|Yicheng Qi et.al.|[2405.10746v1](http://arxiv.org/abs/2405.10746v1)|null|
|**2024-05-17**|**A Systematic Review and Meta-Analysis on Sleep Stage Classification and Sleep Disorder Detection Using Artificial Intelligence**|Tayab Uddin Wara et.al.|[2405.11008v1](http://arxiv.org/abs/2405.11008v1)|null|
|**2024-05-17**|**Cyclical Weight Consolidation: Towards Solving Catastrophic Forgetting in Serial Federated Learning**|Haoyue Song et.al.|[2405.10647v1](http://arxiv.org/abs/2405.10647v1)|null|

#### Abstracts
##### **Recurrent neural networks: vanishing and exploding gradients are not the end of the story**
2405.21064v1 by Nicolas Zucchet, Antonio Orvieto

Recurrent neural networks (RNNs) notoriously struggle to learn long-term
memories, primarily due to vanishing and exploding gradients. The recent
success of state-space models (SSMs), a subclass of RNNs, to overcome such
difficulties challenges our theoretical understanding. In this paper, we delve
into the optimization challenges of RNNs and discover that, as the memory of a
network increases, changes in its parameters result in increasingly large
output variations, making gradient-based learning highly sensitive, even
without exploding gradients. Our analysis further reveals the importance of the
element-wise recurrence design pattern combined with careful parametrizations
in mitigating this effect. This feature is present in SSMs, as well as in other
architectures, such as LSTMs. Overall, our insights provide a new explanation
for some of the difficulties in gradient-based learning of RNNs and why some
architectures perform better than others.

ÊëòË¶ÅÔºöÈÅûËø¥Á•ûÁ∂ìÁ∂≤Ë∑Ø (RNN) ÊÉ°ÂêçÊò≠ÂΩ∞Âú∞Èõ£‰ª•Â≠∏ÁøíÈï∑ÊúüË®òÊÜ∂Ôºå‰∏ªË¶ÅÊòØÁî±ÊñºÊ∂àÂ§±ÂíåÁàÜÁÇ∏Ê¢ØÂ∫¶„ÄÇÊúÄËøëÔºå‰ΩúÁÇ∫ RNN Â≠êÈ°ûÁöÑÁãÄÊÖãÁ©∫ÈñìÊ®°Âûã (SSM) Âú®ÂÖãÊúçÊ≠§È°ûÂõ∞Èõ£ÊñπÈù¢Áç≤ÂæóÊàêÂäüÔºåÈÄôÊåëÊà∞‰∫ÜÊàëÂÄëÁöÑÁêÜË´ñÁêÜËß£„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊ∑±ÂÖ•Êé¢Ë®é RNN ÁöÑÊúÄ‰Ω≥ÂåñÊåëÊà∞Ôºå‰∏¶ÁôºÁèæÈö®ËëóÁ∂≤Ë∑ØË®òÊÜ∂ÁöÑÂ¢ûÂä†ÔºåÂÖ∂ÂèÉÊï∏ÁöÑËÆäÂåñÊúÉÂ∞éËá¥Ë∂ä‰æÜË∂äÂ§ßÁöÑËº∏Âá∫ËÆäÂåñÔºå‰ΩøÂæóÂü∫ÊñºÊ¢ØÂ∫¶ÁöÑÂ≠∏ÁøíÈ´òÂ∫¶ÊïèÊÑüÔºåÂç≥‰ΩøÊ≤íÊúâÁàÜÁÇ∏Ê¢ØÂ∫¶„ÄÇÊàëÂÄëÁöÑÂàÜÊûêÈÄ≤‰∏ÄÊ≠•Êè≠Á§∫‰∫ÜÈÄêÂÖÉÁ¥†ÈÅûËø¥Ë®≠Ë®àÊ®°ÂºèËàá‰ªîÁ¥∞ÂèÉÊï∏ÂåñÁõ∏ÁµêÂêàÂú®Ê∏õËºïÊ≠§ÊïàÊáâÊñπÈù¢ÁöÑÈáçË¶ÅÊÄß„ÄÇÊ≠§ÂäüËÉΩÂ≠òÂú®Êñº SSM ‰ª•ÂèäÂÖ∂‰ªñÊû∂Êßã‰∏≠Ôºå‰æãÂ¶Ç LSTM„ÄÇÁ∏ΩÈ´îËÄåË®ÄÔºåÊàëÂÄëÁöÑË¶ãËß£ÁÇ∫ RNN Âü∫ÊñºÊ¢ØÂ∫¶ÁöÑÂ≠∏Áøí‰∏≠ÁöÑ‰∏Ä‰∫õÂõ∞Èõ£Êèê‰æõ‰∫Ü‰∏ÄÂÄãÊñ∞ÁöÑËß£ÈáãÔºå‰∏¶Ë™™Êòé‰∫ÜÁÇ∫‰ªÄÈ∫ºÊüê‰∫õÊû∂ÊßãÁöÑË°®ÁèæÂÑ™ÊñºÂÖ∂‰ªñÊû∂Êßã„ÄÇ

##### **Generative Adversarial Networks in Ultrasound Imaging: Extending Field of View Beyond Conventional Limits**
2405.20981v1 by Matej Gazda, Samuel Kadoury, Jakub Gazda, Peter Drotar

Transthoracic Echocardiography (TTE) is a fundamental, non-invasive
diagnostic tool in cardiovascular medicine, enabling detailed visualization of
cardiac structures crucial for diagnosing various heart conditions. Despite its
widespread use, TTE ultrasound imaging faces inherent limitations, notably the
trade-off between field of view (FoV) and resolution. This paper introduces a
novel application of conditional Generative Adversarial Networks (cGANs),
specifically designed to extend the FoV in TTE ultrasound imaging while
maintaining high resolution. Our proposed cGAN architecture, termed echoGAN,
demonstrates the capability to generate realistic anatomical structures through
outpainting, effectively broadening the viewable area in medical imaging. This
advancement has the potential to enhance both automatic and manual ultrasound
navigation, offering a more comprehensive view that could significantly reduce
the learning curve associated with ultrasound imaging and aid in more accurate
diagnoses. The results confirm that echoGAN reliably reproduce detailed cardiac
features, thereby promising a significant step forward in the field of
non-invasive cardiac naviagation and diagnostics.

ÊëòË¶ÅÔºöÁ∂ìËÉ∏Ë∂ÖÈü≥Ê≥¢ÂøÉËáüÂúñ (TTE) ÊòØÂøÉË°ÄÁÆ°ÈÜ´Â≠∏‰∏≠ÁöÑ‰∏ÄÈ†ÖÂü∫Êú¨Èùû‰æµÂÖ•ÊÄßË®∫Êñ∑Â∑•ÂÖ∑ÔºåËÉΩË©≥Á¥∞Ë¶ñË¶∫ÂåñÂøÉËáüÁµêÊßãÔºåÂ∞çÊñºË®∫Êñ∑ÂêÑÁ®ÆÂøÉËáüÁñæÁóÖËá≥ÈóúÈáçË¶Å„ÄÇÂÑòÁÆ° TTE Ë∂ÖÈü≥Ê≥¢ÂΩ±ÂÉèÂª£Ê≥õ‰ΩøÁî®Ôºå‰ΩÜÂÆÉÈù¢Ëá®ËëóÂõ∫ÊúâÁöÑÈôêÂà∂ÔºåÁâπÂà•ÊòØÂú®Ë¶ñÈáé (FoV) ÂíåËß£ÊûêÂ∫¶‰πãÈñìÁöÑÊ¨äË°°„ÄÇÊú¨Êñá‰ªãÁ¥π‰∫Ü‰∏ÄÁ®ÆÊ¢ù‰ª∂ÁîüÊàêÂ∞çÊäóÁ∂≤Ë∑Ø (cGANs) ÁöÑÊñ∞ÊáâÁî®ÔºåÂ∞àÈñÄË®≠Ë®àÁî®ÊñºÊì¥Â±ï TTE Ë∂ÖÈü≥Ê≥¢ÂΩ±ÂÉèÁöÑË¶ñÈáéÔºåÂêåÊôÇ‰øùÊåÅÈ´òËß£ÊûêÂ∫¶„ÄÇÊàëÂÄëÊèêÂá∫ÁöÑ cGAN Êû∂ÊßãÁ®±ÁÇ∫ echoGANÔºåÂÆÉÂ±ïÁ§∫‰∫ÜÈÄèÈÅéÂ§ñÁπ™‰æÜÁîüÊàêÈÄºÁúüÁöÑËß£ÂâñÁµêÊßãÁöÑËÉΩÂäõÔºåÊúâÊïàÂú∞Êì¥Â±ï‰∫ÜÈÜ´Â≠∏ÂΩ±ÂÉè‰∏≠ÁöÑÂèØË¶ñÂçÄÂüü„ÄÇÈÄôÈ†ÖÈÄ≤Â±ïÊúâÂèØËÉΩÂ¢ûÂº∑Ëá™ÂãïÂíåÊâãÂãïË∂ÖÈü≥Ê≥¢Â∞éËà™ÔºåÊèê‰æõÊõ¥ÂÖ®Èù¢ÁöÑË¶ñÈáéÔºåÈÄôÂèØ‰ª•Â§ßÂπÖÁ∏ÆÁü≠ËàáË∂ÖÈü≥Ê≥¢ÂΩ±ÂÉèÁõ∏ÈóúÁöÑÂ≠∏ÁøíÊõ≤Á∑öÔºå‰∏¶ÊúâÂä©ÊñºÊõ¥Ê∫ñÁ¢∫ÁöÑË®∫Êñ∑„ÄÇÁµêÊûúË≠âÂØ¶ÔºåechoGAN ÂèØÈù†Âú∞ÈáçÁèæË©≥Á¥∞ÁöÑÂøÉËáüÁâπÂæµÔºåÂæûËÄåÊúâÊúõÂú®Èùû‰æµÂÖ•ÊÄßÂøÉËáüÂ∞éËà™ÂíåË®∫Êñ∑È†òÂüüÈÇÅÂá∫ÈáçË¶Å‰∏ÄÊ≠•„ÄÇ

##### **OR-Bench: An Over-Refusal Benchmark for Large Language Models**
2405.20947v1 by Justin Cui, Wei-Lin Chiang, Ion Stoica, Cho-Jui Hsieh

Large Language Models (LLMs) require careful safety alignment to prevent
malicious outputs. While significant research focuses on mitigating harmful
content generation, the enhanced safety often come with the side effect of
over-refusal, where the LLMs may reject innocuous prompts and become less
helpful. Although the issue of over-refusal has been empirically observed, a
systematic measurement is challenging due to the difficulty of crafting prompts
that appear harmful but are benign. This study proposes a novel method for
automatically generating large-scale sets of ``seemingly toxic prompts''
(benign prompts likely rejected by LLMs). Leveraging this technique, we
introduce OR-Bench, the first large-scale over-refusal benchmark. OR-Bench
comprises 80,000 seemingly toxic prompts across 10 common rejection categories,
a subset of around 1,000 hard prompts that are challenging even for
state-of-the-art LLMs, and an additional 600 toxic prompts to prevent
indiscriminate responses. We then conduct a comprehensive study to measure the
over-refusal of 25 popular LLMs across 8 model families. Our datasets are
available at https://huggingface.co/datasets/bench-llm/OR-Bench and the
corresponding demo can be found at
https://huggingface.co/spaces/bench-llm/or-bench. We hope this benchmark can
help the community develop better safety aligned models.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÈúÄË¶ÅË¨πÊÖéÁöÑÂÆâÂÖ®Ë™øÊï¥Ôºå‰ª•Èò≤Ê≠¢ÊÉ°ÊÑèËº∏Âá∫„ÄÇÈõñÁÑ∂ÈáçË¶ÅÁöÑÁ†îÁ©∂Â∞àÊ≥®ÊñºÊ∏õËºïÊúâÂÆ≥ÂÖßÂÆπÁöÑÁî¢ÁîüÔºå‰ΩÜÂ¢ûÂº∑ÁöÑÂÆâÂÖ®ÈÄöÂ∏∏ÊúÉÁî¢ÁîüÈÅéÂ∫¶ÊãíÁµïÁöÑÂâØ‰ΩúÁî®ÔºåLLM ÂèØËÉΩÊãíÁµïÁÑ°ÂÆ≥ÁöÑÊèêÁ§∫‰∏¶ËÆäÂæó‰∏çÈÇ£È∫ºÊúâÂπ´Âä©„ÄÇÂÑòÁÆ°Â∑≤Á∂ìÁ∂ìÈ©óÊÄßÂú∞ËßÄÂØüÂà∞ÈÅéÂ∫¶ÊãíÁµïÁöÑÂïèÈ°åÔºå‰ΩÜÁî±ÊñºÈõ£‰ª•Êí∞ÂØ´Áúã‰ººÊúâÂÆ≥‰ΩÜËâØÊÄßÁöÑÊèêÁ§∫ÔºåÂõ†Ê≠§Á≥ªÁµ±ÊÄßÁöÑÊ∏¨ÈáèÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÊú¨Á†îÁ©∂ÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆËá™ÂãïÁî¢ÁîüÂ§ßÈáè„ÄåÁúã‰ººÊúâÊØíÁöÑÊèêÁ§∫„ÄçÈõÜÂêàÔºàÂèØËÉΩË¢´ LLM ÊãíÁµïÁöÑËâØÊÄßÊèêÁ§∫ÔºâÁöÑÊñ∞ÊñπÊ≥ï„ÄÇÂà©Áî®Ê≠§ÊäÄË°ìÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü OR-BenchÔºåÈÄôÊòØÁ¨¨‰∏ÄÂÄãÂ§ßË¶èÊ®°ÁöÑÈÅéÂ∫¶ÊãíÁµïÂü∫Ê∫ñ„ÄÇOR-Bench ÂåÖÂê´ 10 ÂÄãÂ∏∏Ë¶ãÊãíÁµïÈ°ûÂà•‰∏≠ÁöÑ 80,000 ÂÄãÁúã‰ººÊúâÊØíÁöÑÊèêÁ§∫Ôºå‰∏ÄÂÄãÁî±Á¥Ñ 1,000 ÂÄãÂç≥‰ΩøÂ∞çÊñºÊúÄÂÖàÈÄ≤ÁöÑ LLM ‰æÜË™™‰πüÂæàÊúâÊåëÊà∞ÊÄßÁöÑÂõ∞Èõ£ÊèêÁ§∫Â≠êÈõÜÔºå‰ª•ÂèäÈ°çÂ§ñÁöÑ 600 ÂÄãÊúâÊØíÊèêÁ§∫Ôºå‰ª•Èò≤Ê≠¢‰∏çÂä†ÂçÄÂà•ÁöÑÂõûÊáâ„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÈÄ≤Ë°å‰∫Ü‰∏ÄÈ†ÖÂÖ®Èù¢Á†îÁ©∂Ôºå‰ª•Ê∏¨Èáè 8 ÂÄãÊ®°ÂûãÁ≥ªÂàó‰∏≠ÁöÑ 25 ÂÄãÊµÅË°å LLM ÁöÑÈÅéÂ∫¶ÊãíÁµï„ÄÇÊàëÂÄëÁöÑÊï∏ÊìöÈõÜÂèØÂú® https://huggingface.co/datasets/bench-llm/OR-Bench Áç≤ÂæóÔºåÂèØ‰ª•Âú® https://huggingface.co/spaces/bench-llm/or-bench ÊâæÂà∞Â∞çÊáâÁöÑÁ§∫ÁØÑ„ÄÇÊàëÂÄëÂ∏åÊúõÊ≠§Âü∫Ê∫ñÂèØ‰ª•Âπ´Âä©Á§æÁæ§ÈñãÁôºÊõ¥Â•ΩÁöÑÂÆâÂÖ®Ë™øÊï¥Ê®°Âûã„ÄÇ

##### **ABodyBuilder3: Improved and scalable antibody structure predictions**
2405.20863v1 by Henry Kenlay, Fr√©d√©ric A. Dreyer, Daniel Cutting, Daniel Nissley, Charlotte M. Deane

Accurate prediction of antibody structure is a central task in the design and
development of monoclonal antibodies, notably to understand both their
developability and their binding properties. In this article, we introduce
ABodyBuilder3, an improved and scalable antibody structure prediction model
based on ImmuneBuilder. We achieve a new state-of-the-art accuracy in the
modelling of CDR loops by leveraging language model embeddings, and show how
predicted structures can be further improved through careful relaxation
strategies. Finally, we incorporate a predicted Local Distance Difference Test
into the model output to allow for a more accurate estimation of uncertainties.

ÊëòË¶ÅÔºöÁ≤æÊ∫ñÈ†êÊ∏¨ÊäóÈ´îÁµêÊßãÊòØÂñÆÊ†™ÊäóÈ´îË®≠Ë®àÂíåÈñãÁôº‰∏≠ÁöÑÊ†∏ÂøÉ‰ªªÂãôÔºåÁâπÂà•ÊòØÁÇ∫‰∫Ü‰∫ÜËß£ÂÆÉÂÄëÁöÑÂèØÈñãÁôºÊÄßÂíåÁµêÂêàÁâπÊÄß„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫Ü ABodyBuilder3ÔºåÈÄôÊòØ‰∏ÄÂÄãÂü∫Êñº ImmuneBuilder ÁöÑÊîπËâØ‰∏îÂèØÊì¥ÂÖÖÁöÑÊäóÈ´îÁµêÊßãÈ†êÊ∏¨Ê®°Âûã„ÄÇÊàëÂÄëÈÄèÈÅéÂà©Áî®Ë™ûË®ÄÊ®°ÂûãÂµåÂÖ•ÔºåÂú® CDR Ëø¥ÂúàÂª∫Ê®°‰∏≠ÈÅîÂà∞‰∫ÜÊñ∞ÁöÑÊúÄÂÖàÈÄ≤Ê∫ñÁ¢∫Â∫¶Ôºå‰∏¶Â±ïÁ§∫‰∫ÜÂ¶Ç‰ΩïÈÄèÈÅéË¨πÊÖéÁöÑÊîæÈ¨ÜÁ≠ñÁï•ÈÄ≤‰∏ÄÊ≠•ÊîπÂñÑÈ†êÊ∏¨ÁµêÊßã„ÄÇÊúÄÂæåÔºåÊàëÂÄëÂ∞áÈ†êÊ∏¨ÁöÑÂ±ÄÈÉ®Ë∑ùÈõ¢Â∑ÆÁï∞Ê∏¨Ë©¶Á¥çÂÖ•Ê®°ÂûãËº∏Âá∫Ôºå‰ª•Êõ¥Ê∫ñÁ¢∫Âú∞‰º∞Ë®à‰∏çÁ¢∫ÂÆöÊÄß„ÄÇ

##### **Maximum Temperature Prediction Using Remote Sensing Data Via Convolutional Neural Network**
2405.20731v1 by Lorenzo Innocenti, Giacomo Blanco, Luca Barco, Claudio Rossi

Urban heat islands, defined as specific zones exhibiting substantially higher
temperatures than their immediate environs, pose significant threats to
environmental sustainability and public health. This study introduces a novel
machine-learning model that amalgamates data from the Sentinel-3 satellite,
meteorological predictions, and additional remote sensing inputs. The primary
aim is to generate detailed spatiotemporal maps that forecast the peak
temperatures within a 24-hour period in Turin. Experimental results validate
the model's proficiency in predicting temperature patterns, achieving a Mean
Absolute Error (MAE) of 2.09 degrees Celsius for the year 2023 at a resolution
of 20 meters per pixel, thereby enriching our knowledge of urban climatic
behavior. This investigation enhances the understanding of urban microclimates,
emphasizing the importance of cross-disciplinary data integration, and laying
the groundwork for informed policy-making aimed at alleviating the negative
impacts of extreme urban temperatures.

ÊëòË¶ÅÔºöÈÉΩÂ∏ÇÁÜ±Â≥∂ÊïàÊáâÊòØÊåáÁâπÂÆöÂçÄÂüüÁöÑÊ∫´Â∫¶ÊòéÈ°ØÈ´òÊñºÂë®ÂúçÁí∞Â¢ÉÔºåÂ∞çÁí∞Â¢ÉÊ∞∏Á∫åÊÄßËàáÂÖ¨ÂÖ±ÂÅ•Â∫∑ÈÄ†ÊàêÈáçÂ§ßÂ®ÅËÑÖ„ÄÇÊú¨Á†îÁ©∂ÊèêÂá∫‰∏ÄÂÄãÂâµÊñ∞ÁöÑÊ©üÂô®Â≠∏ÁøíÊ®°ÂûãÔºåÁµêÂêà Sentinel-3 Ë°õÊòü„ÄÅÊ∞£Ë±°È†êÊ∏¨ÂíåÈ°çÂ§ñÈÅôÊ∏¨Ëº∏ÂÖ•ÁöÑË≥áÊñô„ÄÇ‰∏ªË¶ÅÁõÆÁöÑÊòØÁî¢ÁîüË©≥Á¥∞ÁöÑÊôÇÁ©∫Âú∞ÂúñÔºåÈ†êÊ∏¨ÈÉΩÈùà 24 Â∞èÊôÇÂÖßÁöÑÊúÄÈ´òÊ∫´Â∫¶„ÄÇÂØ¶È©óÁµêÊûúÈ©óË≠â‰∫ÜÊ®°ÂûãÂú®È†êÊ∏¨Ê∫´Â∫¶Ê®°ÂºèÊñπÈù¢ÁöÑÁÜüÁ∑¥Â∫¶ÔºåÂú® 2023 Âπ¥‰ª•ÊØèÂÉèÁ¥† 20 ÂÖ¨Â∞∫Ëß£ÊûêÂ∫¶ÈÅîÂà∞ 2.09 Â∫¶ÊîùÊ∞èÁöÑÂπ≥ÂùáÁµïÂ∞çË™§Â∑Æ (MAE)ÔºåÂæûËÄåË±êÂØå‰∫ÜÊàëÂÄëÂ∞çÈÉΩÂ∏ÇÊ∞£ÂÄôË°åÁÇ∫ÁöÑË™çË≠ò„ÄÇÊ≠§Á†îÁ©∂Â¢ûÂº∑‰∫ÜÂ∞çÈÉΩÂ∏ÇÂæÆÊ∞£ÂÄôÁöÑ‰∫ÜËß£ÔºåÂº∑Ë™øË∑®È†òÂüüË≥áÊñôÊï¥ÂêàÁöÑÈáçË¶ÅÊÄßÔºå‰∏¶ÁÇ∫Êó®Âú®Ê∏õËºïÊ•µÁ´ØÈÉΩÂ∏ÇÊ∫´Â∫¶Ë≤†Èù¢ÂΩ±ÈüøÁöÑÊòéÊô∫ÊîøÁ≠ñÂà∂ÂÆöÂ•†ÂÆöÂü∫Á§é„ÄÇ

##### **GAMedX: Generative AI-based Medical Entity Data Extractor Using Large Language Models**
2405.20585v1 by Mohammed-Khalil Ghali, Abdelrahman Farrag, Hajar Sakai, Hicham El Baz, Yu Jin, Sarah Lam

In the rapidly evolving field of healthcare and beyond, the integration of
generative AI in Electronic Health Records (EHRs) represents a pivotal
advancement, addressing a critical gap in current information extraction
techniques. This paper introduces GAMedX, a Named Entity Recognition (NER)
approach utilizing Large Language Models (LLMs) to efficiently extract entities
from medical narratives and unstructured text generated throughout various
phases of the patient hospital visit. By addressing the significant challenge
of processing unstructured medical text, GAMedX leverages the capabilities of
generative AI and LLMs for improved data extraction. Employing a unified
approach, the methodology integrates open-source LLMs for NER, utilizing
chained prompts and Pydantic schemas for structured output to navigate the
complexities of specialized medical jargon. The findings reveal significant
ROUGE F1 score on one of the evaluation datasets with an accuracy of 98\%. This
innovation enhances entity extraction, offering a scalable, cost-effective
solution for automated forms filling from unstructured data. As a result,
GAMedX streamlines the processing of unstructured narratives, and sets a new
standard in NER applications, contributing significantly to theoretical and
practical advancements beyond the medical technology sphere.

ÊëòË¶ÅÔºöÂú®Âø´ÈÄüÂèëÂ±ïÁöÑÈÜ´ÁôÇ‰øùÂÅ•ÂèäÂÖ∂‰ªñÈ†òÂüü‰∏≠ÔºåÁîüÊàêÂºè AI Êï¥ÂêàÂà∞ÈõªÂ≠êÂÅ•Â∫∑Á¥ÄÈåÑ (EHR) ‰∏≠‰ª£Ë°®ËëóÈóúÈçµÈÄ≤Â±ïÔºåËß£Ê±∫‰∫ÜÁï∂ÂâçË≥áË®äÊì∑ÂèñÊäÄË°ì‰∏≠ÁöÑÈáçÂ§ßÂ∑ÆË∑ù„ÄÇÊú¨Êñá‰ªãÁ¥π GAMedXÔºå‰∏ÄÁ®ÆÂëΩÂêçÂØ¶È´îËæ®Ë≠ò (NER) ÊñπÊ≥ïÔºåÂà©Áî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂæûÈÜ´ÁôÇÊïòËø∞ÂíåÊÇ£ËÄÖÈÜ´Èô¢Â∞±Ë®∫ÂêÑÂÄãÈöéÊÆµÁî¢ÁîüÁöÑÈùûÁµêÊßãÂåñÊñáÂ≠ó‰∏≠ÊúâÊïàÁéáÂú∞Êì∑ÂèñÂØ¶È´î„ÄÇÈÄèÈÅéËß£Ê±∫ËôïÁêÜÈùûÁµêÊßãÂåñÈÜ´ÁôÇÊñáÂ≠óÁöÑÈáçÂ§ßÊåëÊà∞ÔºåGAMedX ÂÖÖÂàÜÂà©Áî®ÁîüÊàêÂºè AI Âíå LLM ÁöÑËÉΩÂäõÔºå‰ª•ÊîπÂñÑË≥áÊñôÊì∑Âèñ„ÄÇÊé°Áî®Áµ±‰∏ÄÊñπÊ≥ïÔºåÊ≠§ÊñπÊ≥ïÊï¥ÂêàÈñãÊîæÂéüÂßãÁ¢º LLM ‰ª•ÈÄ≤Ë°å NERÔºåÂà©Áî®‰∏≤ÈÄ£ÊèêÁ§∫Âíå Pydantic Êû∂ÊßãÈÄ≤Ë°åÁµêÊßãÂåñËº∏Âá∫Ôºå‰ª•ÊáâÂ∞çÂ∞àÊ•≠ÈÜ´ÁôÇË°ìË™ûÁöÑË§áÈõúÊÄß„ÄÇÁ†îÁ©∂ÁµêÊûúÈ°ØÁ§∫ÔºåÂú®ÂÖ∂‰∏≠‰∏ÄÂÄãË©ïÈáèË≥áÊñôÈõÜ‰∏äÔºåROUGE F1 ÂæóÂàÜÈ°ØËëóÔºåÊ∫ñÁ¢∫Â∫¶ÁÇ∫ 98%„ÄÇÈÄôÈ†ÖÂâµÊñ∞Â¢ûÂº∑‰∫ÜÂØ¶È´îÊì∑ÂèñÔºåÊèê‰æõ‰∫Ü‰∏ÄÂÄãÂèØÊì¥ÂÖÖ„ÄÅÂÖ∑ÊàêÊú¨ÊïàÁõäÁöÑËß£Ê±∫ÊñπÊ°àÔºåÁî®ÊñºÂæûÈùûÁµêÊßãÂåñË≥áÊñô‰∏≠Ëá™ÂãïÂ°´ÂØ´Ë°®Ê†º„ÄÇÂõ†Ê≠§ÔºåGAMedX Á∞°Âåñ‰∫ÜÈùûÁµêÊßãÂåñÊïòËø∞ÁöÑËôïÁêÜÔºå‰∏¶Âú® NER ÊáâÁî®Á®ãÂºè‰∏≠Ë®≠ÂÆö‰∫ÜÊñ∞ÁöÑÊ®ôÊ∫ñÔºåÁÇ∫ÈÜ´ÁôÇÊäÄË°ìÈ†òÂüü‰πãÂ§ñÁöÑÁêÜË´ñÂíåÂØ¶ÂãôÈÄ≤Â±ïÂÅöÂá∫‰∫ÜÈáçÂ§ßË≤¢Áçª„ÄÇ

##### **The Point of View of a Sentiment: Towards Clinician Bias Detection in Psychiatric Notes**
2405.20582v1 by Alissa A. Valentine, Lauren A. Lepow, Alexander W. Charney, Isotta Landi

In psychiatry, negative patient descriptions and stigmatizing language can
contribute to healthcare disparities in two ways: (1) read by patients they can
harm their trust and engagement with the medical center; (2) read by future
providers they may negatively influence the future perspective of a patient. By
leveraging large language models, this work aims to identify the sentiment
expressed in psychiatric clinical notes based on the reader's point of view.
Extracting sentences from the Mount Sinai Health System's large and diverse
clinical notes, we used prompts and in-context learning to adapt three large
language models (GPT-3.5, Llama 2, Mistral) to classify the sentiment conveyed
by the sentences according to the provider or non-provider point of view.
Results showed that GPT-3.5 aligns best to provider point of view, whereas
Mistral aligns best to non-provider point of view.

ÊëòË¶ÅÔºöÂú®Á≤æÁ•ûÁóÖÂ≠∏‰∏≠ÔºåË≤†Èù¢ÁöÑÁóÖ‰∫∫ÊèèËø∞ÂíåÊ±°ÂêçÂåñÁöÑË™ûË®ÄÂèØËÉΩÈÄèÈÅéÂÖ©Á®ÆÊñπÂºèÈÄ†ÊàêÈÜ´ÁôÇ‰øùÂÅ•Â∑ÆÁï∞Ôºö(1) ÁóÖ‰∫∫ËÆÄÂà∞ÂæåÊúÉÊêçÂÆ≥‰ªñÂÄëÂ∞çÈÜ´ÁôÇ‰∏≠ÂøÉÁöÑ‰ø°‰ªªÂíåÂèÉËàáÔºõ(2) Êú™‰æÜÁöÑÊèê‰æõËÄÖËÆÄÂà∞ÂæåÔºåÂèØËÉΩÊúÉÂ∞çÁóÖ‰∫∫ÁöÑÊú™‰æÜËßÄÈªûÁî¢ÁîüË≤†Èù¢ÂΩ±Èüø„ÄÇÈÄèÈÅéÂà©Áî®Â§ßÂûãË™ûË®ÄÊ®°ÂûãÔºåÈÄôÈ†ÖÂ∑•‰ΩúÊó®Âú®Ê†πÊìöËÆÄËÄÖÁöÑËßÄÈªûÔºåÊâæÂá∫Á≤æÁ•ûÁóÖËá®Â∫äÁ≠ÜË®ò‰∏≠Ë°®ÈÅîÁöÑÊÉÖÁ∑í„ÄÇÂæûË•øÂ•àÂ±±ÂÅ•Â∫∑Á≥ªÁµ±ÁöÑÂ§ßÈáè‰∏îÂ§öÊ®£ÂåñÁöÑËá®Â∫äÁ≠ÜË®ò‰∏≠ÊëòÈåÑÂè•Â≠êÔºåÊàëÂÄë‰ΩøÁî®ÊèêÁ§∫ÂíåÊÉÖÂ¢ÉÂ≠∏Áøí‰æÜË™øÊï¥‰∏âÂÄãÂ§ßÂûãË™ûË®ÄÊ®°Âûã (GPT-3.5„ÄÅLlama 2„ÄÅMistral)Ôºå‰ª•Ê†πÊìöÊèê‰æõËÄÖÊàñÈùûÊèê‰æõËÄÖËßÄÈªûÂ∞çÂè•Â≠êÂÇ≥ÈÅîÁöÑÊÉÖÁ∑íÈÄ≤Ë°åÂàÜÈ°û„ÄÇÁµêÊûúÈ°ØÁ§∫ÔºåGPT-3.5 ÊúÄÁ¨¶ÂêàÊèê‰æõËÄÖËßÄÈªûÔºåËÄå Mistral ÊúÄÁ¨¶ÂêàÈùûÊèê‰æõËÄÖËßÄÈªû„ÄÇ

##### **Can Machine Learning Assist in Diagnosis of Primary Immune Thrombocytopenia? A feasibility study**
2405.20562v1 by Haroon Miah, Dimitrios Kollias, Giacinto Luca Pedone, Drew Provan, Frederick Chen

Primary Immune thrombocytopenia (ITP) is a rare autoimmune disease
characterised by immune-mediated destruction of peripheral blood platelets in
patients leading to low platelet counts and bleeding. The diagnosis and
effective management of ITP is challenging because there is no established test
to confirm the disease and no biomarker with which one can predict the response
to treatment and outcome. In this work we conduct a feasibility study to check
if machine learning can be applied effectively for diagnosis of ITP using
routine blood tests and demographic data in a non-acute outpatient setting.
Various ML models, including Logistic Regression, Support Vector Machine,
k-Nearest Neighbor, Decision Tree and Random Forest, were applied to data from
the UK Adult ITP Registry and a general hematology clinic. Two different
approaches were investigated: a demographic-unaware and a demographic-aware
one. We conduct extensive experiments to evaluate the predictive performance of
these models and approaches, as well as their bias. The results revealed that
Decision Tree and Random Forest models were both superior and fair, achieving
nearly perfect predictive and fairness scores, with platelet count identified
as the most significant variable. Models not provided with demographic
information performed better in terms of predictive accuracy but showed lower
fairness score, illustrating a trade-off between predictive performance and
fairness.

ÊëòË¶ÅÔºöÂéüÁôºÊÄßÂÖçÁñ´ÊÄßË°ÄÂ∞èÊùøÊ∏õÂ∞ëÁóáÔºàITPÔºâÊòØ‰∏ÄÁ®ÆÁΩïË¶ãÁöÑËá™È´îÂÖçÁñ´ÁñæÁóÖ
ÂÖ∂ÁâπÂæµÂú®ÊñºÂÖçÁñ´‰ªãÂ∞éÁöÑÂ§ñÂë®Ë°ÄÂ∞èÊùøÁ†¥Â£ûÂ∞éËá¥ÊÇ£ËÄÖË°ÄÂ∞èÊùøÊï∏ÈáèÊ∏õÂ∞ëÂíåÂá∫Ë°Ä„ÄÇITP ÁöÑË®∫Êñ∑ÂíåÊúâÊïàÁÆ°ÁêÜÂÖ∑ÊúâÊåëÊà∞ÊÄßÔºåÂõ†ÁÇ∫Ê≤íÊúâÊó¢ÂÆöÁöÑÊ™¢Ê∏¨ÊñπÊ≥ï‰æÜÁ¢∫Ë™çÁñæÁóÖÔºå‰πüÊ≤íÊúâÁîüÁâ©Ê®ôË™åÁâ©ÂèØ‰ª•È†êÊ∏¨Â∞çÊ≤ªÁôÇÂíåÁµêÊûúÁöÑÂèçÊáâ„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÈÄ≤Ë°å‰∫Ü‰∏ÄÈ†ÖÂèØË°åÊÄßÁ†îÁ©∂Ôºå‰ª•Ê™¢Êü•Ê©üÂô®Â≠∏ÁøíÊòØÂê¶ÂèØ‰ª•ÊúâÊïàÊáâÁî®Êñº‰ΩøÁî®ÈùûÊÄ•ÊÄßÈñÄË®∫Áí∞Â¢É‰∏≠ÁöÑÂ∏∏Ë¶èË°ÄÊ∂≤Ê™¢Êü•Âíå‰∫∫Âè£Áµ±Ë®àÊï∏ÊìöË®∫Êñ∑ ITP„ÄÇÂêÑÁ®Æ ML Ê®°ÂûãÔºåÂåÖÊã¨ÈÇèËºØËø¥Ê≠∏„ÄÅÊîØÊåÅÂêëÈáèÊ©ü„ÄÅk ÊúÄËøëÈÑ∞„ÄÅÊ±∫Á≠ñÊ®πÂíåÈö®Ê©üÊ£ÆÊûóÔºåË¢´ÊáâÁî®Êñº‰æÜËá™Ëã±ÂúãÊàê‰∫∫ ITP ÁôªË®òËôïÂíåÊôÆÈÄöË°ÄÊ∂≤Â≠∏Ë®∫ÊâÄÁöÑÊï∏Êìö„ÄÇÁ†îÁ©∂‰∫ÜÂÖ©Á®Æ‰∏çÂêåÁöÑÊñπÊ≥ïÔºö‰∏ÄÁ®ÆÊòØ‰∏çÁü•ÈÅì‰∫∫Âè£Áµ±Ë®àÊï∏ÊìöÁöÑÊñπÊ≥ïÔºåÂè¶‰∏ÄÁ®ÆÊòØÁü•ÈÅì‰∫∫Âè£Áµ±Ë®àÊï∏ÊìöÁöÑÊñπÊ≥ï„ÄÇÊàëÂÄëÈÄ≤Ë°å‰∫ÜÂª£Ê≥õÁöÑÂØ¶È©ó‰æÜË©ï‰º∞ÈÄô‰∫õÊ®°ÂûãÂíåÊñπÊ≥ïÁöÑÈ†êÊ∏¨ÊÄßËÉΩ‰ª•ÂèäÂÆÉÂÄëÁöÑÂÅèÂ∑Æ„ÄÇÁµêÊûúË°®ÊòéÔºåÊ±∫Á≠ñÊ®πÂíåÈö®Ê©üÊ£ÆÊûóÊ®°ÂûãÈÉΩÂÑ™Ë∂ä‰∏îÂÖ¨Âπ≥ÔºåÂØ¶Áèæ‰∫ÜÊé•ËøëÂÆåÁæéÁöÑÈ†êÊ∏¨ÂíåÂÖ¨Âπ≥ÂàÜÊï∏ÔºåË°ÄÂ∞èÊùøË®àÊï∏Ë¢´Á¢∫ÂÆöÁÇ∫ÊúÄÈáçË¶ÅÁöÑËÆäÈáè„ÄÇÊú™Êèê‰æõ‰∫∫Âè£Áµ±Ë®à‰ø°ÊÅØÁöÑÊ®°ÂûãÂú®È†êÊ∏¨Ê∫ñÁ¢∫ÊÄßÊñπÈù¢Ë°®ÁèæÂæóÊõ¥Â•ΩÔºå‰ΩÜÂÖ¨Âπ≥ÂàÜÊï∏ËºÉ‰ΩéÔºåË™™Êòé‰∫ÜÈ†êÊ∏¨ÊÄßËÉΩÂíåÂÖ¨Âπ≥ÊÄß‰πãÈñìÁöÑÊ¨äË°°„ÄÇ

##### **Enhancing Performance for Highly Imbalanced Medical Data via Data Regularization in a Federated Learning Setting**
2405.20430v1 by Georgios Tsoumplekas, Ilias Siniosoglou, Vasileios Argyriou, Ioannis D. Moscholios, Panagiotis Sarigiannidis

The increased availability of medical data has significantly impacted
healthcare by enabling the application of machine / deep learning approaches in
various instances. However, medical datasets are usually small and scattered
across multiple providers, suffer from high class-imbalance, and are subject to
stringent data privacy constraints. In this paper, the application of a data
regularization algorithm, suitable for learning under high class-imbalance, in
a federated learning setting is proposed. Specifically, the goal of the
proposed method is to enhance model performance for cardiovascular disease
prediction by tackling the class-imbalance that typically characterizes
datasets used for this purpose, as well as by leveraging patient data available
in different nodes of a federated ecosystem without compromising their privacy
and enabling more resource sensitive allocation. The method is evaluated across
four datasets for cardiovascular disease prediction, which are scattered across
different clients, achieving improved performance. Meanwhile, its robustness
under various hyperparameter settings, as well as its ability to adapt to
different resource allocation scenarios, is verified.

ÊëòË¶ÅÔºöÈÜ´ÁôÇÊï∏ÊìöÁöÑÊôÆÂèäÂ§ßÂπÖÂΩ±Èüø‰∫ÜÈÜ´ÁôÇ‰øùÂÅ•ÔºåÂõ†ÁÇ∫ÂÆÉËÉΩËÆìÊ©üÂô®ÔºèÊ∑±Â∫¶Â≠∏ÁøíÊñπÊ≥ïÊáâÁî®Âú®ÂêÑÁ®ÆÊÉÖÊ≥Å„ÄÇÁÑ∂ËÄåÔºåÈÜ´ÁôÇÊï∏ÊìöÈõÜÈÄöÂ∏∏ÂæàÂ∞èÔºå‰∏îÂàÜÊï£Âú®Â§öÂÄã‰æõÊáâÂïÜ‰∏≠ÔºåÂõ†Ê≠§ÊúÉÈù¢Ëá®È´òÂ∫¶È°ûÂà•‰∏çÂπ≥Ë°°ÁöÑÂïèÈ°åÔºå‰∏îÂèóÂà∞Âö¥Ê†ºÁöÑË≥áÊñôÈö±ÁßÅÈôêÂà∂„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆË≥áÊñôÊ≠£ÂâáÂåñÊºîÁÆóÊ≥ïÁöÑÊáâÁî®ÔºåÂÆÉÈÅ©Áî®ÊñºÂú®È´òÂ∫¶È°ûÂà•‰∏çÂπ≥Ë°°ÁöÑÊÉÖÊ≥Å‰∏ãÂ≠∏ÁøíÔºå‰∏¶Áî®ÊñºËÅØÈÇ¶Â≠∏ÁøíË®≠ÂÆö‰∏≠„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊâÄÊèêÂá∫ÊñπÊ≥ïÁöÑÁõÆÊ®ôÊòØÈÄèÈÅéËôïÁêÜÈÄöÂ∏∏Áî®ÊñºÊ≠§ÁõÆÁöÑÁöÑÊï∏ÊìöÈõÜ‰∏≠ÁâπÊúâÁöÑÈ°ûÂà•‰∏çÂπ≥Ë°°Ôºå‰ª•ÂèäÈÄèÈÅéÂà©Áî®ËÅØÈÇ¶ÁîüÊÖãÁ≥ªÁµ±‰∏≠‰∏çÂêåÁØÄÈªû‰∏≠ÂèØÁî®ÁöÑÊÇ£ËÄÖË≥áÊñôÔºå‰∏¶Âú®‰∏çÊêçÂÆ≥ÂÖ∂Èö±ÁßÅÂíåÂØ¶ÁèæÊõ¥ÂÖ∑Ë≥áÊ∫êÊïèÊÑüÊÄßÁöÑÈÖçÁΩÆ‰∏ãÔºå‰æÜÊèêÂçáÂøÉË°ÄÁÆ°ÁñæÁóÖÈ†êÊ∏¨ÁöÑÊ®°ÂûãÊïàËÉΩ„ÄÇË©≤ÊñπÊ≥ïÂú®ÂõõÂÄãÂøÉË°ÄÁÆ°ÁñæÁóÖÈ†êÊ∏¨Êï∏ÊìöÈõÜ‰∏≠ÈÄ≤Ë°åË©ï‰º∞ÔºåÈÄô‰∫õÊï∏ÊìöÈõÜÂàÜÊï£Âú®‰∏çÂêåÁöÑÂÆ¢Êà∂Á´Ø‰∏≠Ôºå‰∏¶Áç≤Âæó‰∫ÜÊõ¥Â•ΩÁöÑÊïàËÉΩ„ÄÇÂêåÊôÇÔºåÈ©óË≠â‰∫ÜÂÆÉÂú®ÂêÑÁ®ÆË∂ÖÂèÉÊï∏Ë®≠ÂÆö‰∏ãÁöÑÁ©©ÂÅ•ÊÄßÔºå‰ª•ÂèäÈÅ©Êáâ‰∏çÂêåË≥áÊ∫êÈÖçÁΩÆÂ†¥ÊôØÁöÑËÉΩÂäõ„ÄÇ

##### **Worse than Random? An Embarrassingly Simple Probing Evaluation of Large Multimodal Models in Medical VQA**
2405.20421v1 by Qianqi Yan, Xuehai He, Xiang Yue, Xin Eric Wang

Large Multimodal Models (LMMs) have shown remarkable progress in the field of
medical Visual Question Answering (Med-VQA), achieving high accuracy on
existing benchmarks. However, their reliability under robust evaluation is
questionable. This study reveals that state-of-the-art models, when subjected
to simple probing evaluation, perform worse than random guessing on medical
diagnosis questions. To address this critical evaluation problem, we introduce
the Probing Evaluation for Medical Diagnosis (ProbMed) dataset to rigorously
assess LMM performance in medical imaging through probing evaluation and
procedural diagnosis. Particularly, probing evaluation features pairing
original questions with negation questions with hallucinated attributes, while
procedural diagnosis requires reasoning across various diagnostic dimensions
for each image, including modality recognition, organ identification, clinical
findings, abnormalities, and positional grounding. Our evaluation reveals that
top-performing models like GPT-4V and Gemini Pro perform worse than random
guessing on specialized diagnostic questions, indicating significant
limitations in handling fine-grained medical inquiries. Besides, models like
LLaVA-Med struggle even with more general questions, and results from CheXagent
demonstrate the transferability of expertise across different modalities of the
same organ, showing that specialized domain knowledge is still crucial for
improving performance. This study underscores the urgent need for more robust
evaluation to ensure the reliability of LMMs in critical fields like medical
diagnosis, and current LMMs are still far from applicable to those fields.

ÊëòË¶ÅÔºöÂ§ßÂûãÂ§öÊ®°ÊÄÅÊ®°Âûã (LMM) Âú®ÂåªÂ≠¶ËßÜËßâÈóÆÁ≠î (Med-VQA) È¢ÜÂüüÂèñÂæó‰∫ÜÊòæËëóËøõÂ±ïÔºåÂú®Áé∞ÊúâÂü∫ÂáÜÊµãËØï‰∏≠ÂÆûÁé∞‰∫ÜÈ´òÂáÜÁ°ÆÂ∫¶„ÄÇÁÑ∂ËÄåÔºåÂÆÉ‰ª¨Âú®Á®≥ÂÅ•ËØÑ‰º∞‰∏ãÁöÑÂèØÈù†ÊÄßÂÄºÂæóÊÄÄÁñë„ÄÇÊú¨Á†îÁ©∂Ë°®ÊòéÔºåÂΩìÊúÄÂÖàËøõÁöÑÊ®°ÂûãÁªèËøáÁÆÄÂçïÁöÑÊé¢ÊµãËØÑ‰º∞Êó∂ÔºåÂú®ÂåªÂ≠¶ËØäÊñ≠ÈóÆÈ¢ò‰∏äÁöÑË°®Áé∞ÊØîÈöèÊú∫ÁåúÊµãËøòË¶ÅÂ∑Æ„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∏™ÂÖ≥ÈîÆÁöÑËØÑ‰º∞ÈóÆÈ¢òÔºåÊàë‰ª¨ÂºïÂÖ•‰∫ÜÂåªÂ≠¶ËØäÊñ≠Êé¢ÊµãËØÑ‰º∞ (ProbMed) Êï∞ÊçÆÈõÜÔºåÈÄöËøáÊé¢ÊµãËØÑ‰º∞ÂíåÁ®ãÂ∫èËØäÊñ≠‰∏•Ê†ºËØÑ‰º∞ LMM Âú®ÂåªÂ≠¶ÂΩ±ÂÉè‰∏≠ÁöÑÊÄßËÉΩ„ÄÇÁâπÂà´ÊòØÔºåÊé¢ÊµãËØÑ‰º∞ÁöÑÁâπÁÇπÊòØÂ∞ÜÂéüÂßãÈóÆÈ¢ò‰∏éÂ∏¶ÊúâÂπªËßâÂ±ûÊÄßÁöÑÂê¶ÂÆöÈóÆÈ¢òÈÖçÂØπÔºåËÄåÁ®ãÂ∫èËØäÊñ≠ÂàôÈúÄË¶ÅÈíàÂØπÊØè‰∏™ÂõæÂÉèÊé®ÁêÜÂêÑÁßçËØäÊñ≠Áª¥Â∫¶ÔºåÂåÖÊã¨Ê®°ÊÄÅËØÜÂà´„ÄÅÂô®ÂÆòËØÜÂà´„ÄÅ‰∏¥Â∫äÂèëÁé∞„ÄÅÂºÇÂ∏∏Âíå‰ΩçÁΩÆÂü∫Á°Ä„ÄÇÊàë‰ª¨ÁöÑËØÑ‰º∞Ë°®ÊòéÔºåÂÉè GPT-4V Âíå Gemini Pro ËøôÊ†∑ÁöÑÈ´òÊÄßËÉΩÊ®°ÂûãÂú®‰∏ìÈó®ÁöÑËØäÊñ≠ÈóÆÈ¢ò‰∏äË°®Áé∞ÊØîÈöèÊú∫ÁåúÊµãËøòË¶ÅÂ∑ÆÔºåË°®ÊòéÂú®Â§ÑÁêÜÁªÜÁ≤íÂ∫¶ÁöÑÂåªÂ≠¶Êü•ËØ¢ÊñπÈù¢Â≠òÂú®ÊòéÊòæÁöÑÂ±ÄÈôêÊÄß„ÄÇÊ≠§Â§ñÔºåÂÉè LLaVA-Med ËøôÊ†∑ÁöÑÊ®°ÂûãÁîöËá≥Âú®Êõ¥‰∏ÄËà¨ÁöÑÈóÆÈ¢ò‰∏ä‰πüÈöæ‰ª•Â∫î‰ªòÔºåËÄå CheXagent ÁöÑÁªìÊûúËØÅÊòé‰∫Ü‰∏ì‰∏öÁü•ËØÜÂú®Âêå‰∏ÄÂô®ÂÆòÁöÑ‰∏çÂêåÊ®°ÊÄÅ‰πãÈó¥ÂÖ∑ÊúâÂèØËΩ¨ÁßªÊÄßÔºåË°®Êòé‰∏ìÈó®ÁöÑÈ¢ÜÂüüÁü•ËØÜÂØπ‰∫éÊèêÈ´òÊÄßËÉΩ‰ªçÁÑ∂Ëá≥ÂÖ≥ÈáçË¶Å„ÄÇÊú¨Á†îÁ©∂Âº∫Ë∞É‰∫ÜÂØπÊõ¥Á®≥ÂÅ•ÁöÑËØÑ‰º∞ÁöÑËø´ÂàáÈúÄÊ±ÇÔºå‰ª•Á°Æ‰øù LMM Âú®ÂåªÂ≠¶ËØäÊñ≠Á≠âÂÖ≥ÈîÆÈ¢ÜÂüüÁöÑÂèØÈù†ÊÄßÔºåËÄåÂΩìÂâçÁöÑ LMM ‰ªçÁÑ∂Ëøú‰∏çËÉΩÂ∫îÁî®‰∫éËøô‰∫õÈ¢ÜÂüü„ÄÇ

##### **Enhancing Antibiotic Stewardship using a Natural Language Approach for Better Feature Representation**
2405.20419v1 by Simon A. Lee, Trevor Brokowski, Jeffrey N. Chiang

The rapid emergence of antibiotic-resistant bacteria is recognized as a
global healthcare crisis, undermining the efficacy of life-saving antibiotics.
This crisis is driven by the improper and overuse of antibiotics, which
escalates bacterial resistance. In response, this study explores the use of
clinical decision support systems, enhanced through the integration of
electronic health records (EHRs), to improve antibiotic stewardship. However,
EHR systems present numerous data-level challenges, complicating the effective
synthesis and utilization of data. In this work, we transform EHR data into a
serialized textual representation and employ pretrained foundation models to
demonstrate how this enhanced feature representation can aid in antibiotic
susceptibility predictions. Our results suggest that this text representation,
combined with foundation models, provides a valuable tool to increase
interpretability and support antibiotic stewardship efforts.

ÊëòË¶ÅÔºöÊäóÁîüÁ¥†ÊäóËó•ÊÄßÁ¥∞ËèåÁöÑÂø´ÈÄüÂá∫ÁèæË¢´Ë¶ñÁÇ∫ÂÖ®ÁêÉÈÜ´ÁôÇ‰øùÂÅ•Âç±Ê©üÔºåÁ†¥Â£û‰∫ÜÊïëÂëΩÊäóÁîüÁ¥†ÁöÑÊïàÂäõ„ÄÇÊ≠§Âç±Ê©üÊòØÁî±ÊäóÁîüÁ¥†ÁöÑ‰∏çÁï∂ÂíåÈÅéÂ∫¶‰ΩøÁî®ÊâÄÈ©ÖÂãïÔºåÈÄôÊúÉÂ¢ûÂä†Á¥∞ËèåÁöÑÊäóËó•ÊÄß„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊú¨Á†îÁ©∂Êé¢Ë®é‰∫ÜËá®Â∫äÊ±∫Á≠ñÊîØÊè¥Á≥ªÁµ±ÁöÑ‰ΩøÁî®ÔºåÈÄèÈÅéÊï¥ÂêàÈõªÂ≠êÂÅ•Â∫∑Ë®òÈåÑ (EHR) ‰æÜÂä†Âº∑Ôºå‰ª•ÊîπÂñÑÊäóÁîüÁ¥†ÁÆ°ÁêÜ„ÄÇÁÑ∂ËÄåÔºåEHR Á≥ªÁµ±ÊèêÂá∫‰∫ÜË®±Â§öË≥áÊñôÂ±§Á¥öÁöÑÊåëÊà∞Ôºå‰ΩøË≥áÊñôÁöÑÊúâÊïàÂêàÊàêÂíåÂà©Áî®ËÆäÂæóË§áÈõú„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÂ∞á EHR Ë≥áÊñôËΩâÊèõÊàêÂ∫èÂàóÂåñÁöÑÊñáÂ≠óË°®Á§∫Ôºå‰∏¶Êé°Áî®È†êÂÖàË®ìÁ∑¥Â•ΩÁöÑÂü∫Á§éÊ®°ÂûãÔºå‰ª•Â±ïÁ§∫ÈÄôÁ®ÆÂ¢ûÂº∑ÁöÑÂäüËÉΩË°®Á§∫Â¶Ç‰ΩïÊúâÂä©ÊñºÊäóÁîüÁ¥†ÊïèÊÑüÊÄßÈ†êÊ∏¨„ÄÇÊàëÂÄëÁöÑÁµêÊûúË°®ÊòéÔºåÈÄôÁ®ÆÊñáÂ≠óË°®Á§∫ËàáÂü∫Á§éÊ®°ÂûãÁµêÂêàÔºåÊèê‰æõ‰∫Ü‰∏ÄÂÄãÊúâÂÉπÂÄºÁöÑÂ∑•ÂÖ∑‰æÜÂ¢ûÂä†ÂèØËß£ÈáãÊÄßÔºå‰∏¶ÊîØÊåÅÊäóÁîüÁ¥†ÁÆ°ÁêÜÂ∑•‰Ωú„ÄÇ

##### **MSSC-BiMamba: Multimodal Sleep Stage Classification and Early Diagnosis of Sleep Disorders with Bidirectional Mamba**
2405.20142v2 by Chao Zhang, Weirong Cui, Jingjing Guo

Monitoring sleep states is essential for evaluating sleep quality and
diagnosing sleep disorders. Traditional manual staging is time-consuming and
prone to subjective bias, often resulting in inconsistent outcomes. Here, we
developed an automated model for sleep staging and disorder classification to
enhance diagnostic accuracy and efficiency. Considering the characteristics of
polysomnography (PSG) multi-lead sleep monitoring, we designed a multimodal
sleep state classification model, MSSC-BiMamba, that combines an Efficient
Channel Attention (ECA) mechanism with a Bidirectional State Space Model
(BSSM). The ECA module allows for weighting data from different sensor
channels, thereby amplifying the influence of diverse sensor inputs.
Additionally, the implementation of bidirectional Mamba (BiMamba) enables the
model to effectively capture the multidimensional features and long-range
dependencies of PSG data. The developed model demonstrated impressive
performance on sleep stage classification tasks on both the ISRUC-S3 and
ISRUC-S1 datasets, respectively containing data with healthy and unhealthy
sleep patterns. Also, the model exhibited a high accuracy for sleep health
prediction when evaluated on a combined dataset consisting of ISRUC and
Sleep-EDF. Our model, which can effectively handle diverse sleep conditions, is
the first to apply BiMamba to sleep staging with multimodal PSG data, showing
substantial gains in computational and memory efficiency over traditional
Transformer-style models. This method enhances sleep health management by
making monitoring more accessible and extending advanced healthcare through
innovative technology.

ÊëòË¶ÅÔºöÁõ£ÊéßÁù°Áú†ÁãÄÊÖãÂ∞çÊñºË©ï‰º∞Áù°Áú†ÂìÅË≥™ÂíåË®∫Êñ∑Áù°Áú†ÈöúÁ§ôËá≥ÈóúÈáçË¶Å„ÄÇÂÇ≥Áµ±ÁöÑÊâãÂãïÂàÜÊúüËÄóÊôÇ‰∏îÂÆπÊòìÁî¢Áîü‰∏ªËßÄÂÅèË¶ãÔºåÁ∂ìÂ∏∏Â∞éËá¥‰∏ç‰∏ÄËá¥ÁöÑÁµêÊûú„ÄÇÂú®Ê≠§ÔºåÊàëÂÄëÈñãÁôº‰∫Ü‰∏ÄÂÄãËá™ÂãïÂåñÊ®°ÂûãÔºåÁî®ÊñºÁù°Áú†ÂàÜÊúüÂíåÁñæÁóÖÂàÜÈ°ûÔºå‰ª•ÊèêÈ´òË®∫Êñ∑Ê∫ñÁ¢∫ÊÄßÂíåÊïàÁéá„ÄÇËÄÉÊÖÆÂà∞Â§öÂ∞éÁù°Áú†Ê™¢Êü• (PSG) Â§öÂ∞éÁ®ãÁù°Áú†Áõ£Ê∏¨ÁöÑÁâπÂæµÔºåÊàëÂÄëË®≠Ë®à‰∫Ü‰∏ÄÂÄãÂ§öÊ®°ÊÖãÁù°Áú†ÁãÄÊÖãÂàÜÈ°ûÊ®°Âûã MSSC-BiMambaÔºåÂÆÉÂ∞áÈ´òÊïàÈÄöÈÅìÊ≥®ÊÑè (ECA) Ê©üÂà∂ËàáÈõôÂêëÁãÄÊÖãÁ©∫ÈñìÊ®°Âûã (BSSM) ÁµêÂêàÂú®‰∏ÄËµ∑„ÄÇECA Ê®°ÁµÑÂÖÅË®±Â∞ç‰æÜËá™‰∏çÂêåÊÑüÊ∏¨Âô®ÈÄöÈÅìÁöÑË≥áÊñôÈÄ≤Ë°åÂä†Ê¨äÔºåÂæûËÄåÊîæÂ§ß‰∏çÂêåÊÑüÊ∏¨Âô®Ëº∏ÂÖ•ÁöÑÂΩ±Èüø„ÄÇÊ≠§Â§ñÔºåÈõôÂêë Mamba (BiMamba) ÁöÑÂØ¶‰ΩúËÆìÊ®°ÂûãËÉΩÂ§†ÊúâÊïàÊì∑Âèñ PSG Ë≥áÊñôÁöÑÂ§öÁ∂≠ÁâπÂæµÂíåÈï∑Á®ã‰æùË≥¥ÊÄß„ÄÇÈñãÁôºÁöÑÊ®°ÂûãÂú® ISRUC-S3 Âíå ISRUC-S1 Ë≥áÊñôÈõÜ‰∏äÂ±ïÁèæÂá∫‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑÁù°Áú†ÂàÜÊúüÂàÜÈ°û‰ªªÂãôÊïàËÉΩÔºåÈÄô‰∫õË≥áÊñôÈõÜÂàÜÂà•ÂåÖÂê´ÂÅ•Â∫∑Âíå‰∏çÂÅ•Â∫∑ÁöÑÁù°Áú†Ê®°ÂºèË≥áÊñô„ÄÇÊ≠§Â§ñÔºåÂú®Áî± ISRUC Âíå Sleep-EDF ÁµÑÊàêÁöÑÂêà‰ΩµË≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åË©ï‰º∞ÊôÇÔºåË©≤Ê®°ÂûãÂ±ïÁèæÂá∫ÂæàÈ´òÁöÑÁù°Áú†ÂÅ•Â∫∑È†êÊ∏¨Ê∫ñÁ¢∫Â∫¶„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÂèØ‰ª•ÊúâÊïàËôïÁêÜ‰∏çÂêåÁöÑÁù°Áú†ÁãÄÊ≥ÅÔºåÊòØÁ¨¨‰∏ÄÂÄãÂ∞á BiMamba ÊáâÁî®ÊñºÂÖ∑ÊúâÂ§öÊ®°ÊÖã PSG Ë≥áÊñôÁöÑÁù°Áú†ÂàÜÊúüÁöÑÊ®°ÂûãÔºåÂú®ÈÅãÁÆóÂíåË®òÊÜ∂È´îÊïàÁéáÊñπÈù¢Â±ïÁèæÂá∫ÊØîÂÇ≥Áµ± Transformer È¢®Ê†ºÊ®°ÂûãÊõ¥È°ØËëóÁöÑÈÄ≤Ê≠•„ÄÇÈÄôÁ®ÆÊñπÊ≥ïÈÄèÈÅéËÆìÁõ£ÊéßÊõ¥ÂÆπÊòìÂèñÂæóÔºå‰∏¶ÈÄèÈÅéÂâµÊñ∞ÊäÄË°ìÊì¥Â±ïÂÖàÈÄ≤ÁöÑÈÜ´ÁôÇ‰øùÂÅ•ÔºåÈÄ≤ËÄåÂ¢ûÂº∑Áù°Áú†ÂÅ•Â∫∑ÁÆ°ÁêÜ„ÄÇ

##### **Out-of-distribution Reject Option Method for Dataset Shift Problem in Early Disease Onset Prediction**
2405.19864v1 by Taisei Tosaki, Eiichiro Uchino, Ryosuke Kojima, Yohei Mineharu, Mikio Arita, Nobuyuki Miyai, Yoshinori Tamada, Tatsuya Mikami, Koichi Murashita, Shigeyuki Nakaji, Yasushi Okuno

Machine learning is increasingly used to predict lifestyle-related disease
onset using health and medical data. However, the prediction effectiveness is
hindered by dataset shift, which involves discrepancies in data distribution
between the training and testing datasets, misclassifying out-of-distribution
(OOD) data. To diminish dataset shift effects, this paper proposes the
out-of-distribution reject option for prediction (ODROP), which integrates OOD
detection models to preclude OOD data from the prediction phase. We
investigated the efficacy of five OOD detection methods (variational
autoencoder, neural network ensemble std, neural network ensemble epistemic,
neural network energy, and neural network gaussian mixture based energy
measurement) across two datasets, the Hirosaki and Wakayama health checkup
data, in the context of three disease onset prediction tasks: diabetes,
dyslipidemia, and hypertension. To evaluate the ODROP method, we trained
disease onset prediction models and OOD detection models on Hirosaki data and
used AUROC-rejection curve plots from Wakayama data. The variational
autoencoder method showed superior stability and magnitude of improvement in
Area Under the Receiver Operating Curve (AUROC) in five cases: AUROC in the
Wakayama data was improved from 0.80 to 0.90 at a 31.1% rejection rate for
diabetes onset and from 0.70 to 0.76 at a 34% rejection rate for dyslipidemia.
We categorized dataset shifts into two types using SHAP clustering - those that
considerably affect predictions and those that do not. We expect that this
classification will help standardize measuring instruments. This study is the
first to apply OOD detection to actual health and medical data, demonstrating
its potential to substantially improve the accuracy and reliability of disease
prediction models amidst dataset shift.

ÊëòË¶ÅÔºöÊ©üÂô®Â≠∏ÁøíÊ≠£Êó•ÁõäÁî®ÊñºÈ†êÊ∏¨ËàáÁîüÊ¥ªÊñπÂºèÁõ∏ÈóúÁöÑÁñæÁóÖÁôº‰ΩúÔºå‰∏¶‰ΩøÁî®ÂÅ•Â∫∑ÂíåÈÜ´ÁôÇÊï∏Êìö„ÄÇÁÑ∂ËÄåÔºåÈ†êÊ∏¨ÊïàÊûúÊúÉÂèóÂà∞Ë≥áÊñôÈõÜËΩâÁßªÁöÑÈòªÁ§ôÔºåÈÄôÊ∂âÂèäË®ìÁ∑¥ÂíåÊ∏¨Ë©¶Ë≥áÊñôÈõÜ‰πãÈñìÁöÑË≥áÊñôÂàÜ‰ΩàÂ∑ÆÁï∞ÔºåÂ∞áÂàÜÂ∏ÉÂ§ñ (OOD) Ë≥áÊñôÂàÜÈ°ûÈåØË™§„ÄÇÁÇ∫‰∫ÜÊ∏õÂ∞ëË≥áÊñôÈõÜËΩâÁßªÊïàÊáâÔºåÊú¨ÊñáÊèêÂá∫Áî®ÊñºÈ†êÊ∏¨ÁöÑÂàÜÂ∏ÉÂ§ñÊãíÁµïÈÅ∏È†Ö (ODROP)ÔºåÂÆÉÊï¥Âêà OOD ÂÅµÊ∏¨Ê®°Âûã‰ª•ÊéíÈô§È†êÊ∏¨ÈöéÊÆµÁöÑ OOD Ë≥áÊñô„ÄÇÊàëÂÄëË™øÊü•‰∫Ü‰∫îÁ®Æ OOD ÂÅµÊ∏¨ÊñπÊ≥ï (ËÆäÁï∞Ëá™ÂãïÁ∑®Á¢ºÂô®„ÄÅÁ•ûÁ∂ìÁ∂≤Ë∑ØÊï¥È´îÊ®ôÊ∫ñÂ∑Æ„ÄÅÁ•ûÁ∂ìÁ∂≤Ë∑ØÊï¥È´îË™çË≠òË´ñ„ÄÅÁ•ûÁ∂ìÁ∂≤Ë∑ØËÉΩÈáèÂíåÂü∫ÊñºÁ•ûÁ∂ìÁ∂≤Ë∑ØÈ´òÊñØÊ∑∑ÂêàËÉΩÈáèÊ∏¨Èáè) ÁöÑÊïàËÉΩÔºåË∑®ÂÖ©ÂÄãË≥áÊñôÈõÜÔºåÂºòÂâçÂíåÂíåÊ≠åÂ±±ÂÅ•Â∫∑Ê™¢Êü•Ë≥áÊñôÔºåÂú®Á≥ñÂ∞øÁóÖ„ÄÅË°ÄËÑÇÁï∞Â∏∏ÂíåÈ´òË°ÄÂ£ìÈÄô‰∏âÂÄãÁñæÁóÖÁôº‰ΩúÈ†êÊ∏¨‰ªªÂãôÁöÑËÑàÁµ°‰∏≠„ÄÇÁÇ∫‰∫ÜË©ï‰º∞ ODROP ÊñπÊ≥ïÔºåÊàëÂÄëË®ìÁ∑¥‰∫ÜÂºòÂâçË≥áÊñôÁöÑÁñæÁóÖÁôº‰ΩúÈ†êÊ∏¨Ê®°ÂûãÂíå OOD ÂÅµÊ∏¨Ê®°ÂûãÔºå‰∏¶‰ΩøÁî®ÂíåÊ≠åÂ±±Ë≥áÊñôÁöÑ AUROC ÊéíÊñ•Êõ≤Á∑öÂúñ„ÄÇËÆäÁï∞Ëá™ÂãïÁ∑®Á¢ºÂô®ÊñπÊ≥ïÂú®‰∫îÁ®ÆÊÉÖÊ≥Å‰∏ãÂ±ïÁèæÂá∫ÂÑ™Áï∞ÁöÑÁ©©ÂÆöÊÄßÂíåÊîπÂñÑÂπÖÂ∫¶ÔºöÂú®Êé•ÂèóËÄÖÊìç‰ΩúÁâπÂæµÊõ≤Á∑ö (AUROC) ‰∏ãÊñπÂçÄÂüü‰∏≠ÔºåÂíåÊ≠åÂ±±Ë≥áÊñôÁöÑ AUROC ÂæûÁ≥ñÂ∞øÁóÖÁôº‰ΩúÁöÑ 31.1% ÊéíÊñ•ÁéáÊîπÂñÑÂà∞ 0.90ÔºåÂæûË°ÄËÑÇÁï∞Â∏∏ÁöÑ 34% ÊéíÊñ•ÁéáÊîπÂñÑÂà∞ 0.76„ÄÇÊàëÂÄë‰ΩøÁî® SHAP ËÅöÈ°ûÂ∞áË≥áÊñôÈõÜËΩâÁßªÂàÜÁÇ∫ÂÖ©Á®ÆÈ°ûÂûãÔºå‰∏ÄÁ®ÆÊúÉÈ°ØËëóÂΩ±ÈüøÈ†êÊ∏¨ÔºåÂè¶‰∏ÄÁ®ÆÂâá‰∏çÊúÉ„ÄÇÊàëÂÄëÈ†êÊúüÈÄôÁ®ÆÂàÜÈ°ûÂ∞áÊúâÂä©ÊñºÊ®ôÊ∫ñÂåñÊ∏¨ÈáèÂÑÄÂô®„ÄÇÈÄôÈ†ÖÁ†îÁ©∂È¶ñÊ¨°Â∞á OOD ÂÅµÊ∏¨ÊáâÁî®ÊñºÂØ¶ÈöõÁöÑÂÅ•Â∫∑ÂíåÈÜ´ÁôÇË≥áÊñôÔºåË≠âÊòé‰∫ÜÂÖ∂Âú®Ë≥áÊñôÈõÜËΩâÁßª‰∏≠Â§ßÂπÖÊîπÂñÑÁñæÁóÖÈ†êÊ∏¨Ê®°ÂûãÁöÑÊ∫ñÁ¢∫ÊÄßÂíåÂèØÈù†ÊÄßÁöÑÊΩõÂäõ„ÄÇ

##### **Dynamic feature selection in medical predictive monitoring by reinforcement learning**
2405.19729v1 by Yutong Chen, Jiandong Gao, Ji Wu

In this paper, we investigate dynamic feature selection within multivariate
time-series scenario, a common occurrence in clinical prediction monitoring
where each feature corresponds to a bio-test result. Many existing feature
selection methods fall short in effectively leveraging time-series information,
primarily because they are designed for static data. Our approach addresses
this limitation by enabling the selection of time-varying feature subsets for
each patient. Specifically, we employ reinforcement learning to optimize a
policy under maximum cost restrictions. The prediction model is subsequently
updated using synthetic data generated by trained policy. Our method can
seamlessly integrate with non-differentiable prediction models. We conducted
experiments on a sizable clinical dataset encompassing regression and
classification tasks. The results demonstrate that our approach outperforms
strong feature selection baselines, particularly when subjected to stringent
cost limitations. Code will be released once paper is accepted.

ÊëòË¶ÅÔºöÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨Á†îÁ©∂Â§öËÆäÈáèÊôÇÈñìÂ∫èÂàóÂ†¥ÊôØ‰∏≠ÁöÑÂãïÊÖãÁâπÂæµÈÅ∏ÊìáÔºåÈÄôÂú®Ëá®Â∫ä‰∏äÈ†êÊ∏¨Áõ£Êéß‰∏≠ÂæàÂ∏∏Ë¶ãÔºåÂÖ∂‰∏≠ÊØèÂÄãÁâπÂæµÂ∞çÊáâÊñº‰∏ÄÂÄãÁîüÁâ©Ê™¢Ê∏¨ÁµêÊûú„ÄÇË®±Â§öÁèæÊúâÁöÑÁâπÂæµÈÅ∏ÊìáÊñπÊ≥ïÂú®ÊúâÊïàÂà©Áî®ÊôÇÈñìÂ∫èÂàóË≥áË®äÊñπÈù¢ÂÅöÂæó‰∏¶‰∏çÂ•ΩÔºå‰∏ªË¶ÅÊòØÂõ†ÁÇ∫ÂÆÉÂÄëÊòØÁÇ∫ÈùúÊÖãË≥áÊñôËÄåË®≠Ë®àÁöÑ„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÈÄöÈÅéÁÇ∫ÊØèÂÄãÊÇ£ËÄÖÂïüÁî®ÊôÇÈñìËÆäÁï∞ÁâπÂæµÂ≠êÈõÜÁöÑÈÅ∏Êìá‰æÜËß£Ê±∫ÈÄôÂÄãÈôêÂà∂„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÊé°Áî®Âº∑ÂåñÂ≠∏Áøí‰æÜÂú®ÊúÄÂ§ßÊàêÊú¨ÈôêÂà∂‰∏ãÊúÄ‰Ω≥Âåñ‰∏ÄÂÄãÁ≠ñÁï•„ÄÇÈ†êÊ∏¨Ê®°ÂûãÈö®Âæå‰ΩøÁî®Áî±Ë®ìÁ∑¥Á≠ñÁï•Áî¢ÁîüÁöÑÂêàÊàêË≥áÊñôÊõ¥Êñ∞„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÂèØ‰ª•Ëàá‰∏çÂèØÂæÆÂàÜÈ†êÊ∏¨Ê®°ÂûãÁÑ°Á∏´Êï¥Âêà„ÄÇÊàëÂÄëÂú®‰∏ÄÂÄãÂåÖÂê´ÂõûÊ≠∏ÂíåÂàÜÈ°û‰ªªÂãôÁöÑÂ§ßÂûãËá®Â∫äË≥áÊñôÈõÜ‰∏äÈÄ≤Ë°å‰∫ÜÂØ¶È©ó„ÄÇÁµêÊûúË°®ÊòéÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÂÑ™ÊñºÂº∑Â§ßÁöÑÁâπÂæµÈÅ∏ÊìáÂü∫Á∑öÔºåÁâπÂà•ÊòØÂú®ÂèóÂà∞Âö¥Ê†ºÊàêÊú¨ÈôêÂà∂ÊôÇ„ÄÇ‰∏ÄÊó¶Ë´ñÊñáË¢´Êé•ÂèóÔºåÁ®ãÂºèÁ¢ºÂ∞áÊúÉÁôºÂ∏É„ÄÇ

##### **Unlocking the Power of Spatial and Temporal Information in Medical Multimodal Pre-training**
2405.19654v1 by Jinxia Yang, Bing Su, Wayne Xin Zhao, Ji-Rong Wen

Medical vision-language pre-training methods mainly leverage the
correspondence between paired medical images and radiological reports. Although
multi-view spatial images and temporal sequences of image-report pairs are
available in off-the-shelf multi-modal medical datasets, most existing methods
have not thoroughly tapped into such extensive supervision signals. In this
paper, we introduce the Med-ST framework for fine-grained spatial and temporal
modeling to exploit information from multiple spatial views of chest
radiographs and temporal historical records. For spatial modeling, Med-ST
employs the Mixture of View Expert (MoVE) architecture to integrate different
visual features from both frontal and lateral views. To achieve a more
comprehensive alignment, Med-ST not only establishes the global alignment
between whole images and texts but also introduces modality-weighted local
alignment between text tokens and spatial regions of images. For temporal
modeling, we propose a novel cross-modal bidirectional cycle consistency
objective by forward mapping classification (FMC) and reverse mapping
regression (RMR). By perceiving temporal information from simple to complex,
Med-ST can learn temporal semantics. Experimental results across four distinct
tasks demonstrate the effectiveness of Med-ST, especially in temporal
classification tasks. Our code and model are available at
https://github.com/SVT-Yang/MedST.

ÊëòË¶ÅÔºöÈÜ´Â≠∏Ë¶ñË¶∫Ë™ûË®ÄÈ†êË®ìÁ∑¥ÊñπÊ≥ï‰∏ªË¶ÅÂà©Áî®ÈÖçÂ∞çÈÜ´Â≠∏ÂΩ±ÂÉèËàáÊîæÂ∞ÑÁßëÂ†±Âëä‰πãÈñìÁöÑÂ∞çÊáâÈóú‰øÇ„ÄÇÂÑòÁÆ°ÁèæÊàêÁöÑÂ§öÊ®°ÂºèÈÜ´Â≠∏Ë≥áÊñôÈõÜ‰∏≠Êèê‰æõ‰∫ÜÂ§öË¶ñËßíÁ©∫ÈñìÂΩ±ÂÉèÂíåÂΩ±ÂÉèÂ†±ÂëäÂ∞çÁöÑÊôÇÈñìÂ∫èÂàóÔºå‰ΩÜÂ§ßÂ§öÊï∏ÁèæÊúâÊñπÊ≥ïÂ∞öÊú™ÂæπÂ∫ïÂà©Áî®Â¶ÇÊ≠§Âª£Ê≥õÁöÑÁõ£Áù£Ë®äËôü„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫Ü Med-ST Êû∂ÊßãÔºåÁî®ÊñºÁ≤æÁ¥∞ÁöÑÁ©∫ÈñìÂíåÊôÇÈñìÂª∫Ê®°Ôºå‰ª•Âà©Áî®ËÉ∏ÈÉ® X ÂÖâÁâáÁöÑË¶ñËßíÂíåÊôÇÈñìÊ≠∑Âè≤Ë®òÈåÑÁöÑË≥áË®ä„ÄÇÂ∞çÊñºÁ©∫ÈñìÂª∫Ê®°ÔºåMed-ST Êé°Áî®Ë¶ñËßíÂ∞àÂÆ∂Ê∑∑Âêà (MoVE) Êû∂ÊßãÔºå‰ª•Êï¥Âêà‰æÜËá™Ê≠£Èù¢ÂíåÂÅ¥Èù¢Ë¶ñËßíÁöÑ‰∏çÂêåË¶ñË¶∫ÁâπÂæµ„ÄÇÁÇ∫‰∫ÜÂØ¶ÁèæÊõ¥ÂÖ®Èù¢ÁöÑÂ∞çÈΩäÔºåMed-ST ‰∏çÂÉÖÂª∫Á´ã‰∫ÜÊï¥ÂÄãÂΩ±ÂÉèÂíåÊñáÂ≠ó‰πãÈñìÁöÑÂÖ®Â±ÄÂ∞çÈΩäÔºåÈÇÑÂºïÂÖ•‰∫ÜÊñáÂ≠óÁ¨¶ËôüÂíåÂΩ±ÂÉèÁ©∫ÈñìÂçÄÂüü‰πãÈñìÁöÑÊ®°ÊÖãÂä†Ê¨äÂ±ÄÈÉ®Â∞çÈΩä„ÄÇÂ∞çÊñºÊôÇÈñìÂª∫Ê®°ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊñ∞Á©éÁöÑË∑®Ê®°ÊÖãÈõôÂêëÂæ™Áí∞‰∏ÄËá¥ÊÄßÁõÆÊ®ôÔºåÈÄöÈÅéÊ≠£ÂêëÊò†Â∞ÑÂàÜÈ°û (FMC) ÂíåÂèçÂêëÊò†Â∞ÑÂõûÊ≠∏ (RMR)„ÄÇÈÄöÈÅéÂæûÁ∞°ÂñÆÂà∞Ë§áÈõúÂú∞ÊÑüÁü•ÊôÇÈñìË≥áË®äÔºåMed-ST ÂèØ‰ª•Â≠∏ÁøíÊôÇÈñìË™ûÁæ©„ÄÇÂõõÂÄã‰∏çÂêå‰ªªÂãôÁöÑÂØ¶È©óÁµêÊûúË≠âÊòé‰∫Ü Med-ST ÁöÑÊúâÊïàÊÄßÔºåÁâπÂà•ÊòØÂú®ÊôÇÈñìÂàÜÈ°û‰ªªÂãô‰∏≠„ÄÇÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÂíåÊ®°ÂûãÂèØÂú® https://github.com/SVT-Yang/MedST ÂèñÂæó„ÄÇ

##### **Leveraging Open-Source Large Language Models for encoding Social Determinants of Health using an Intelligent Router**
2405.19631v1 by Akul Goel, Surya Narayanan Hari, Belinda Waltman, Matt Thomson

Social Determinants of Health (SDOH) play a significant role in patient
health outcomes. The Center of Disease Control (CDC) introduced a subset of
ICD-10 codes called Z-codes in an attempt to officially recognize and measure
SDOH in the health care system. However, these codes are rarely annotated in a
patient's Electronic Health Record (EHR), and instead, in many cases, need to
be inferred from clinical notes. Previous research has shown that large
language models (LLMs) show promise on extracting unstructured data from EHRs.
However, with thousands of models to choose from with unique architectures and
training sets, it's difficult to choose one model that performs the best on
coding tasks. Further, clinical notes contain trusted health information making
the use of closed-source language models from commercial vendors difficult, so
the identification of open source LLMs that can be run within health
organizations and exhibits high performance on SDOH tasks is an urgent problem.
Here, we introduce an intelligent routing system for SDOH coding that uses a
language model router to direct medical record data to open source LLMs that
demonstrate optimal performance on specific SDOH codes. The intelligent routing
system exhibits state of the art performance of 97.4% accuracy averaged across
5 codes, including homelessness and food insecurity, on par with closed models
such as GPT-4o. In order to train the routing system and validate models, we
also introduce a synthetic data generation and validation paradigm to increase
the scale of training data without needing privacy protected medical records.
Together, we demonstrate an architecture for intelligent routing of inputs to
task-optimal language models to achieve high performance across a set of
medical coding sub-tasks.

ÊëòË¶ÅÔºö<paragraph>ÂÅ•Â∫∑Á§æÊúÉÊ±∫ÂÆöÂõ†Á¥† (SDOH) Âú®ÊÇ£ËÄÖÂÅ•Â∫∑ÁµêÊûú‰∏≠ÊâÆÊºîËëóÈáçË¶ÅÁöÑËßíËâ≤„ÄÇÁñæÁóÖÊéßÂà∂‰∏≠ÂøÉ (CDC) ÂºïÂÖ•‰∫Ü‰∏ÄÁµÑÁ®±ÁÇ∫ Z Á¢ºÁöÑ ICD-10 ‰ª£Á¢ºÔºåË©¶ÂúñÂú®ÈÜ´ÁôÇ‰øùÂÅ•Á≥ªÁµ±‰∏≠Ê≠£ÂºèË≠òÂà•ÂíåË°°Èáè SDOH„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õ‰ª£Á¢ºÂæàÂ∞ëÂú®ÊÇ£ËÄÖÁöÑÈõªÂ≠êÂÅ•Â∫∑Ë®òÈåÑ (EHR) ‰∏≠Ë®ªËß£ÔºåËÄå‰∏îÂú®Ë®±Â§öÊÉÖÊ≥Å‰∏ãÔºåÈúÄË¶ÅÂæûËá®Â∫äÁ≠ÜË®ò‰∏≠Êé®Êñ∑Âá∫‰æÜ„ÄÇÂÖàÂâçÁöÑÁ†îÁ©∂Ë°®ÊòéÔºåÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®Âæû EHR ‰∏≠ÊèêÂèñÈùûÁµêÊßãÂåñÊï∏ÊìöÊñπÈù¢ÂæàÊúâÂâçÊôØ„ÄÇÁÑ∂ËÄåÔºåÊúâÊï∏ÂçÉÂÄãÊ®°ÂûãÂèØ‰æõÈÅ∏ÊìáÔºåÂÆÉÂÄëÂÖ∑ÊúâÁç®ÁâπÁöÑÊû∂ÊßãÂíåË®ìÁ∑¥ÈõÜÔºåÂõ†Ê≠§ÂæàÈõ£ÈÅ∏Êìá‰∏ÄÂÄãÂú®Á∑®Á¢º‰ªªÂãô‰∏äË°®ÁèæÊúÄ‰Ω≥ÁöÑÊ®°Âûã„ÄÇÊ≠§Â§ñÔºåËá®Â∫äÁ≠ÜË®òÂåÖÂê´Âèó‰ø°‰ªªÁöÑÂÅ•Â∫∑Ë≥áË®äÔºåÈÄô‰ΩøÂæóÈõ£‰ª•‰ΩøÁî®ÂïÜÊ•≠‰æõÊáâÂïÜÁöÑÈñâÊ∫êË™ûË®ÄÊ®°ÂûãÔºåÂõ†Ê≠§ÔºåË≠òÂà•ÂèØ‰ª•Âú®ÈÜ´ÁôÇÊ©üÊßãÂÖßÈÅã‰Ωú‰∏îÂú® SDOH ‰ªªÂãô‰∏äË°®ÁèæÂá∫È´òÊÄßËÉΩÁöÑÈñãÊ∫ê LLM ÊòØÂÄãËø´ÂàáÁöÑÂïèÈ°å„ÄÇÂú®Ê≠§ÔºåÊàëÂÄë‰ªãÁ¥π‰∫Ü‰∏ÄÂÄãÁî®Êñº SDOH Á∑®Á¢ºÁöÑÊô∫ÊÖßË∑ØÁî±Á≥ªÁµ±ÔºåÂÆÉ‰ΩøÁî®Ë™ûË®ÄÊ®°ÂûãË∑ØÁî±Âô®Â∞áÁóÖÊ≠∑Ë≥áÊñôÂ∞éÂêëÂú®ÁâπÂÆö SDOH ‰ª£Á¢º‰∏äË°®ÁèæÂá∫ÊúÄ‰Ω≥ÊÄßËÉΩÁöÑÈñãÊ∫ê LLM„ÄÇÊô∫ÊÖßË∑ØÁî±Á≥ªÁµ±Â±ïÁèæ‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÊÄßËÉΩÔºåÂú® 5 ÂÄã‰ª£Á¢ºÔºàÂåÖÊã¨ÁÑ°ÂÆ∂ÂèØÊ≠∏ÂíåÁ≥ßÈ£ü‰∏çÂÆâÂÖ®ÔºâÁöÑÂπ≥ÂùáÊ∫ñÁ¢∫Â∫¶ÁÇ∫ 97.4%ÔºåËàá GPT-4o Á≠âÈñâÂêàÊ®°Âûã‰∏çÁõ∏‰∏ä‰∏ã„ÄÇÁÇ∫‰∫ÜË®ìÁ∑¥Ë∑ØÁî±Á≥ªÁµ±ÂíåÈ©óË≠âÊ®°ÂûãÔºåÊàëÂÄëÈÇÑÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÂêàÊàêË≥áÊñôÁîüÊàêÂíåÈ©óË≠âÁØÑ‰æãÔºå‰ª•Â¢ûÂä†Ë®ìÁ∑¥Ë≥áÊñôÁöÑË¶èÊ®°ÔºåËÄåÁÑ°ÈúÄÂèóÈö±ÁßÅ‰øùË≠∑ÁöÑÁóÖÊ≠∑„ÄÇÁ∏Ω‰πãÔºåÊàëÂÄëÂ±ïÁ§∫‰∫Ü‰∏ÄÂÄãÊô∫ÊÖßË∑ØÁî±Êû∂ÊßãÔºåÁî®ÊñºÂ∞áËº∏ÂÖ•Ë∑ØÁî±Âà∞‰ªªÂãôÊúÄ‰Ω≥Ë™ûË®ÄÊ®°ÂûãÔºå‰ª•Âú®ÈÜ´ÁôÇÁ∑®Á¢ºÂ≠ê‰ªªÂãô‰∏≠ÂØ¶ÁèæÈ´òÊÄßËÉΩ„ÄÇ</paragraph>

##### **Dr-LLaVA: Visual Instruction Tuning with Symbolic Clinical Grounding**
2405.19567v1 by Shenghuan Sun, Gregory M. Goldgof, Alexander Schubert, Zhiqing Sun, Thomas Hartvigsen, Atul J. Butte, Ahmed Alaa

Vision-Language Models (VLM) can support clinicians by analyzing medical
images and engaging in natural language interactions to assist in diagnostic
and treatment tasks. However, VLMs often exhibit "hallucinogenic" behavior,
generating textual outputs not grounded in contextual multimodal information.
This challenge is particularly pronounced in the medical domain, where we do
not only require VLM outputs to be accurate in single interactions but also to
be consistent with clinical reasoning and diagnostic pathways throughout
multi-turn conversations. For this purpose, we propose a new alignment
algorithm that uses symbolic representations of clinical reasoning to ground
VLMs in medical knowledge. These representations are utilized to (i) generate
GPT-4-guided visual instruction tuning data at scale, simulating clinician-VLM
conversations with demonstrations of clinical reasoning, and (ii) create an
automatic reward function that evaluates the clinical validity of VLM
generations throughout clinician-VLM interactions. Our algorithm eliminates the
need for human involvement in training data generation or reward model
construction, reducing costs compared to standard reinforcement learning with
human feedback (RLHF). We apply our alignment algorithm to develop Dr-LLaVA, a
conversational VLM finetuned for analyzing bone marrow pathology slides,
demonstrating strong performance in multi-turn medical conversations.

ÊëòË¶ÅÔºöË¶ñË¶∫Ë™ûË®ÄÊ®°Âûã (VLM) ÂèØÈÄèÈÅéÂàÜÊûêÈÜ´ÁôÇÂΩ±ÂÉè‰∏¶ÈÄ≤Ë°åËá™ÁÑ∂Ë™ûË®Ä‰∫íÂãï‰æÜÂçîÂä©Ëá®Â∫äÈÜ´ÁîüÔºå‰ª•ÂçîÂä©Ë®∫Êñ∑ÂíåÊ≤ªÁôÇ‰ªªÂãô„ÄÇÁÑ∂ËÄåÔºåVLM Á∂ìÂ∏∏Ë°®ÁèæÂá∫„ÄåÂπªË¶∫„ÄçË°åÁÇ∫ÔºåÁî¢ÁîüÊú™Âü∫ÊñºËÑàÁµ°Â§öÊ®°ÊÖãË≥áË®äÁöÑÊñáÂ≠óËº∏Âá∫„ÄÇÈÄôÂÄãÊåëÊà∞Âú®ÈÜ´ÁôÇÈ†òÂüüÁâπÂà•ÊòéÈ°ØÔºåÂõ†ÁÇ∫ÊàëÂÄë‰∏çÂÉÖË¶ÅÊ±Ç VLM Ëº∏Âá∫Âú®ÂñÆ‰∏Ä‰∫íÂãï‰∏≠Ê∫ñÁ¢∫ÔºåÈÇÑÂøÖÈ†àÂú®Â§öËº™Â∞çË©±‰∏≠ËàáËá®Â∫äÊé®ÁêÜÂíåË®∫Êñ∑ÈÄîÂæë‰øùÊåÅ‰∏ÄËá¥„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞ÁöÑÂ∞çÈΩäÊºîÁÆóÊ≥ïÔºåÂÆÉ‰ΩøÁî®Ëá®Â∫äÊé®ÁêÜÁöÑÁ¨¶ËôüË°®Á§∫Ê≥ïÂ∞á VLM Âª∫Á´ãÂú®ÈÜ´Â≠∏Áü•Ë≠ò‰∏ä„ÄÇÈÄô‰∫õË°®Á§∫Ê≥ïÁî®ÊñºÔºö(i) ÁîüÊàê GPT-4 ÂºïÂ∞éÁöÑË¶ñË¶∫Êåá‰ª§Ë™øÊï¥Ë≥áÊñôÔºåÊ®°Êì¨Ëá®Â∫äÈÜ´Áîü-VLM Â∞çË©±Ôºå‰∏¶Â±ïÁ§∫Ëá®Â∫äÊé®ÁêÜÔºå‰ª•Âèä (ii) Âª∫Á´ã‰∏ÄÂÄãËá™ÂãïÁçéÂãµÂáΩÊï∏ÔºåÁî®ÊñºË©ï‰º∞ VLM ÁîüÊàêÂú®Ëá®Â∫äÈÜ´Áîü-VLM ‰∫íÂãï‰∏≠ÁöÑËá®Â∫äÊúâÊïàÊÄß„ÄÇÊàëÂÄëÁöÑÊºîÁÆóÊ≥ïÊ∂àÈô§‰∫ÜÂú®Ë®ìÁ∑¥Ë≥áÊñôÁîüÊàêÊàñÁçéÂãµÊ®°ÂûãÂª∫Êßã‰∏≠ÈúÄË¶Å‰∫∫Â∑•ÂèÉËàáÔºåËàáÈúÄË¶Å‰∫∫Â∑•ÂõûÈ•ãÔºàRLHFÔºâÁöÑÊ®ôÊ∫ñÂº∑ÂåñÂ≠∏ÁøíÁõ∏ÊØîÔºåÈôç‰Ωé‰∫ÜÊàêÊú¨„ÄÇÊàëÂÄëÂ∞áÊàëÂÄëÁöÑÂ∞çÈΩäÊºîÁÆóÊ≥ïÊáâÁî®ÊñºÈñãÁôº Dr-LLaVAÔºåÈÄôÊòØ‰∏ÄÂÄãÈáùÂ∞çÂàÜÊûêÈ™®È´ìÁóÖÁêÜÂàáÁâáÈÄ≤Ë°åÂæÆË™øÁöÑÂ∞çË©±Âºè VLMÔºåÂú®Â§öËº™ÈÜ´ÁôÇÂ∞çË©±‰∏≠Â±ïÁèæÂá∫Âº∑Â§ßÁöÑÊïàËÉΩ„ÄÇ

##### **CheXpert Plus: Hundreds of Thousands of Aligned Radiology Texts, Images and Patients**
2405.19538v1 by Pierre Chambon, Jean-Benoit Delbrouck, Thomas Sounack, Shih-Cheng Huang, Zhihong Chen, Maya Varma, Steven QH Truong, Chu The Chuong, Curtis P. Langlotz

Since the release of the original CheXpert paper five years ago, CheXpert has
become one of the most widely used and cited clinical AI datasets. The
emergence of vision language models has sparked an increase in demands for
sharing reports linked to CheXpert images, along with a growing interest among
AI fairness researchers in obtaining demographic data. To address this,
CheXpert Plus serves as a new collection of radiology data sources, made
publicly available to enhance the scaling, performance, robustness, and
fairness of models for all subsequent machine learning tasks in the field of
radiology. CheXpert Plus is the largest text dataset publicly released in
radiology, with a total of 36 million text tokens, including 13 million
impression tokens. To the best of our knowledge, it represents the largest text
de-identification effort in radiology, with almost 1 million PHI spans
anonymized. It is only the second time that a large-scale English paired
dataset has been released in radiology, thereby enabling, for the first time,
cross-institution training at scale. All reports are paired with high-quality
images in DICOM format, along with numerous image and patient metadata covering
various clinical and socio-economic groups, as well as many pathology labels
and RadGraph annotations. We hope this dataset will boost research for AI
models that can further assist radiologists and help improve medical care. Data
is available at the following URL:
https://stanfordaimi.azurewebsites.net/datasets/5158c524-d3ab-4e02-96e9-6ee9efc110a1
Models are available at the following URL:
https://github.com/Stanford-AIMI/chexpert-plus

ÊëòË¶ÅÔºöËá™‰∫îÂπ¥ÂâçÂéüÂßã CheXpert ËÆ∫ÊñáÂèëÂ∏É‰ª•Êù•ÔºåCheXpert Â∑≤Êàê‰∏∫‰ΩøÁî®ÊúÄÂπøÊ≥õ‰∏îÂºïÁî®ÊúÄÂ§öÁöÑ‰∏¥Â∫ä AI Êï∞ÊçÆÈõÜ‰πã‰∏Ä„ÄÇËßÜËßâËØ≠Ë®ÄÊ®°ÂûãÁöÑÂá∫Áé∞ÂºïÂèë‰∫ÜÂØπÂÖ±‰∫´‰∏é CheXpert ÂõæÂÉèÁõ∏ÂÖ≥ËÅîÁöÑÊä•ÂëäÁöÑÈúÄÊ±ÇÂ¢ûÂä†Ôºå‰ª•Âèä AI ÂÖ¨Âπ≥ÊÄßÁ†îÁ©∂‰∫∫ÂëòÂØπËé∑Âèñ‰∫∫Âè£ÁªüËÆ°Êï∞ÊçÆÁöÑÂÖ¥Ë∂£Êó•ÁõäÊµìÂéö„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢òÔºåCheXpert Plus ‰Ωú‰∏∫ÊîæÂ∞ÑÂ≠¶Êï∞ÊçÆÊ∫êÁöÑÊñ∞ÈõÜÂêàÔºåÂÖ¨ÂºÄÊèê‰æõÔºå‰ª•Â¢ûÂº∫ÊîæÂ∞ÑÂ≠¶È¢ÜÂüüÊâÄÊúâÂêéÁª≠Êú∫Âô®Â≠¶‰π†‰ªªÂä°ÁöÑÊ®°ÂûãÁöÑÂèØÊâ©Â±ïÊÄß„ÄÅÊÄßËÉΩ„ÄÅÈ≤ÅÊ£íÊÄßÂíåÂÖ¨Âπ≥ÊÄß„ÄÇCheXpert Plus ÊòØÊîæÂ∞ÑÂ≠¶È¢ÜÂüüÂÖ¨ÂºÄÂèëÂ∏ÉÁöÑÊúÄÂ§ßÊñáÊú¨Êï∞ÊçÆÈõÜÔºåÊÄªÂÖ±Êúâ 3600 ‰∏á‰∏™ÊñáÊú¨Ê†áËÆ∞ÔºåÂÖ∂‰∏≠ÂåÖÊã¨ 1300 ‰∏á‰∏™Âç∞Ë±°Ê†áËÆ∞„ÄÇÊçÆÊàë‰ª¨ÊâÄÁü•ÔºåÂÆÉ‰ª£Ë°®‰∫ÜÊîæÂ∞ÑÂ≠¶È¢ÜÂüüÊúÄÂ§ßÁöÑÊñáÊú¨ÂéªËØÜÂà´Â∑•‰ΩúÔºåÂá†‰πéÊúâ 100 ‰∏á‰∏™ PHI Ë∑®Â∫¶Ë¢´ÂåøÂêçÂåñ„ÄÇËøôÊòØÊîæÂ∞ÑÂ≠¶È¢ÜÂüüÁ¨¨‰∫åÊ¨°ÂèëÂ∏ÉÂ§ßËßÑÊ®°Ëã±ËØ≠ÈÖçÂØπÊï∞ÊçÆÈõÜÔºå‰ªéËÄåÈ¶ñÊ¨°ÂÆûÁé∞‰∫ÜÂ§ßËßÑÊ®°ÁöÑË∑®Êú∫ÊûÑÂüπËÆ≠„ÄÇÊâÄÊúâÊä•ÂëäÈÉΩ‰∏é DICOM Ê†ºÂºèÁöÑÈ´òË¥®ÈáèÂõæÂÉèÈÖçÂØπÔºå‰ª•ÂèäÊ∂µÁõñÂêÑÁßç‰∏¥Â∫äÂíåÁ§æ‰ºöÁªèÊµéÁæ§‰ΩìÁöÑÂ§ßÈáèÂõæÂÉèÂíåÊÇ£ËÄÖÂÖÉÊï∞ÊçÆÔºå‰ª•ÂèäËÆ∏Â§öÁóÖÁêÜÊ†áÁ≠æÂíå RadGraph Ê≥®Èáä„ÄÇÊàë‰ª¨Â∏åÊúõÊ≠§Êï∞ÊçÆÈõÜÂ∞Ü‰øÉËøõ‰∫∫Â∑•Êô∫ËÉΩÊ®°ÂûãÁöÑÁ†îÁ©∂ÔºåËøô‰∫õÊ®°ÂûãÂèØ‰ª•Ëøõ‰∏ÄÊ≠•ÂçèÂä©ÊîæÂ∞ÑÁßëÂåªÁîüÂπ∂Â∏ÆÂä©ÊîπÂñÑÂåªÁñó‰øùÂÅ•„ÄÇÊï∞ÊçÆÂèØÂú®‰ª•‰∏ã URL Ëé∑ÂæóÔºö
https://stanfordaimi.azurewebsites.net/datasets/5158c524-d3ab-4e02-96e9-6ee9efc110a1
Ê®°ÂûãÂèØÂú®‰ª•‰∏ã URL Ëé∑ÂæóÔºö
https://github.com/Stanford-AIMI/chexpert-plus

##### **Participation in the age of foundation models**
2405.19479v1 by Harini Suresh, Emily Tseng, Meg Young, Mary L. Gray, Emma Pierson, Karen Levy

Growing interest and investment in the capabilities of foundation models has
positioned such systems to impact a wide array of public services. Alongside
these opportunities is the risk that these systems reify existing power
imbalances and cause disproportionate harm to marginalized communities.
Participatory approaches hold promise to instead lend agency and
decision-making power to marginalized stakeholders. But existing approaches in
participatory AI/ML are typically deeply grounded in context - how do we apply
these approaches to foundation models, which are, by design, disconnected from
context? Our paper interrogates this question.
  First, we examine existing attempts at incorporating participation into
foundation models. We highlight the tension between participation and scale,
demonstrating that it is intractable for impacted communities to meaningfully
shape a foundation model that is intended to be universally applicable. In
response, we develop a blueprint for participatory foundation models that
identifies more local, application-oriented opportunities for meaningful
participation. In addition to the "foundation" layer, our framework proposes
the "subfloor'' layer, in which stakeholders develop shared technical
infrastructure, norms and governance for a grounded domain, and the "surface''
layer, in which affected communities shape the use of a foundation model for a
specific downstream task. The intermediate "subfloor'' layer scopes the range
of potential harms to consider, and affords communities more concrete avenues
for deliberation and intervention. At the same time, it avoids duplicative
effort by scaling input across relevant use cases. Through three case studies
in clinical care, financial services, and journalism, we illustrate how this
multi-layer model can create more meaningful opportunities for participation
than solely intervening at the foundation layer.

ÊëòË¶ÅÔºö<paragraph>Â∞çÊñºÂü∫Á§éÊ®°ÂûãËÉΩÂäõÁöÑËààË∂£ÂíåÊäïË≥áÊó•ÁõäÂ¢ûÈï∑ÔºåÂ∑≤‰ΩøÊ≠§È°ûÁ≥ªÁµ±ËÉΩÂ§†ÂΩ±ÈüøÂª£Ê≥õÁöÑÂÖ¨ÂÖ±ÊúçÂãô„ÄÇÈô§‰∫ÜÈÄô‰∫õÊ©üÊúÉ‰πãÂ§ñÔºåÈÄô‰∫õÁ≥ªÁµ±ÈÇÑÂ≠òÂú®Âº∑ÂåñÊó¢ÊúâÊ¨äÂäõÂ§±Ë°°‰∏¶Â∞çÈÇäÁ∑£ÂåñÁ§æÁæ§ÈÄ†Êàê‰∏çÊàêÊØî‰æãÂÇ∑ÂÆ≥ÁöÑÈ¢®Èö™„ÄÇÂèÉËàáÂºèÊñπÊ≥ïÊúâÊúõË≥¶‰∫àÈÇäÁ∑£ÂåñÂà©ÁõäÁõ∏ÈóúËÄÖ‰ª£ÁêÜÊ¨äÂíåÊ±∫Á≠ñÊ¨ä„ÄÇ‰ΩÜÁèæÊúâÁöÑÂèÉËàáÂºè AI/ML ÊñπÊ≥ïÈÄöÂ∏∏Ê∑±Ê§çÊñºËÑàÁµ°‰∏≠ - ÊàëÂÄëÂ¶Ç‰ΩïÂ∞áÈÄô‰∫õÊñπÊ≥ïÊáâÁî®ÊñºÂü∫Á§éÊ®°ÂûãÔºåËÄåÈÄô‰∫õÊ®°ÂûãÂú®Ë®≠Ë®à‰∏äËàáËÑàÁµ°ÁÑ°ÈóúÔºüÊàëÂÄëÁöÑË´ñÊñáÂØ©Ë¶ñ‰∫ÜÈÄôÂÄãÂïèÈ°å„ÄÇ
È¶ñÂÖàÔºåÊàëÂÄëÊ™¢Ë¶ñÂ∞áÂèÉËàáÁ¥çÂÖ•Âü∫Á§éÊ®°ÂûãÁöÑÊó¢ÊúâÂòóË©¶„ÄÇÊàëÂÄëÂº∑Ë™øÂèÉËàáËàáË¶èÊ®°‰πãÈñìÁöÑÁ∑äÂºµÈóú‰øÇÔºåË≠âÊòéÂèóÂΩ±ÈüøÁöÑÁ§æÁæ§Èõ£‰ª•ÊúâÊÑèÁæ©Âú∞Â°ëÈÄ†‰∏ÄÂÄãÊó®Âú®ÊôÆÈÅçÈÅ©Áî®ÁöÑÂü∫Á§éÊ®°Âûã„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÂà∂ÂÆö‰∫Ü‰∏ÄÂÄãÂèÉËàáÂºèÂü∫Á§éÊ®°ÂûãËóçÂúñÔºåÊâæÂá∫Êõ¥Âú®Âú∞Âåñ„ÄÅÊõ¥‰ª•ÊáâÁî®ÁÇ∫Â∞éÂêëÁöÑÊúâÊÑèÁæ©ÂèÉËàáÊ©üÊúÉ„ÄÇÈô§‰∫Ü„ÄåÂü∫Á§é„ÄçÂ±§ÔºåÊàëÂÄëÁöÑÊû∂ÊßãÈÇÑÊèêÂá∫‰∫Ü„ÄåÊ¨°Â±§„ÄçÂ±§ÔºåÂú®ÂÖ∂‰∏≠ÔºåÂà©ÁõäÁõ∏ÈóúËÄÖÊúÉÁÇ∫‰∏ÄÂÄãÁ¥ÆÊ†πÁöÑÈ†òÂüüÈñãÁôºÂÖ±‰∫´ÊäÄË°ìÂü∫Á§éË®≠ÊñΩ„ÄÅË¶èÁØÑÂíåÊ≤ªÁêÜÔºå‰ª•Âèä„ÄåË°®Èù¢„ÄçÂ±§ÔºåÂú®ÂÖ∂‰∏≠ÔºåÂèóÂΩ±ÈüøÁöÑÁ§æÁæ§ÊúÉÂ°ëÈÄ†Âü∫Á§éÊ®°ÂûãÂú®ÁâπÂÆö‰∏ãÊ∏∏‰ªªÂãô‰∏≠ÁöÑ‰ΩøÁî®ÊñπÂºè„ÄÇ‰∏≠ÈñìÁöÑ„ÄåÊ¨°Â±§„ÄçÂ±§ÁïåÂÆö‰∫ÜË¶ÅËÄÉÈáèÁöÑÊΩõÂú®Âç±ÂÆ≥ÁØÑÂúçÔºå‰∏¶ÁÇ∫Á§æÁæ§Êèê‰æõ‰∫ÜÊõ¥ÂÖ∑È´îÁöÑÂØ©Ë≠∞Âíå‰ªãÂÖ•ÁÆ°ÈÅì„ÄÇÂêåÊôÇÔºåÂÆÉÈÄèÈÅéÊì¥Â±ïËº∏ÂÖ•Âà∞Áõ∏ÈóúÁî®‰æã‰∏≠‰æÜÈÅøÂÖçÈáçË§áÁöÑÂä™Âäõ„ÄÇÈÄèÈÅéËá®Â∫äÁÖßË≠∑„ÄÅÈáëËûçÊúçÂãôÂíåÊñ∞ËÅûÊ•≠‰∏≠ÁöÑ‰∏âÂÄãÊ°à‰æãÁ†îÁ©∂ÔºåÊàëÂÄëË™™Êòé‰∫ÜÈÄôÂÄãÂ§öÂ±§Ê®°ÂûãÂ¶Ç‰ΩïËÉΩÂâµÈÄ†Âá∫ÊØîÂÉÖÂú®Âü∫Á§éÂ±§ÈÄ≤Ë°å‰ªãÂÖ•Êõ¥ÊúâÊÑèÁæ©ÁöÑÂèÉËàáÊ©üÊúÉ„ÄÇ</paragraph>

##### **MemControl: Mitigating Memorization in Medical Diffusion Models via Automated Parameter Selection**
2405.19458v1 by Raman Dutt, Pedro Sanchez, Ondrej Bohdal, Sotirios A. Tsaftaris, Timothy Hospedales

Diffusion models show a remarkable ability in generating images that closely
mirror the training distribution. However, these models are prone to training
data memorization, leading to significant privacy, ethical, and legal concerns,
particularly in sensitive fields such as medical imaging. We hypothesize that
memorization is driven by the overparameterization of deep models, suggesting
that regularizing model capacity during fine-tuning could be an effective
mitigation strategy. Parameter-efficient fine-tuning (PEFT) methods offer a
promising approach to capacity control by selectively updating specific
parameters. However, finding the optimal subset of learnable parameters that
balances generation quality and memorization remains elusive. To address this
challenge, we propose a bi-level optimization framework that guides automated
parameter selection by utilizing memorization and generation quality metrics as
rewards. Our framework successfully identifies the optimal parameter set to be
updated to satisfy the generation-memorization tradeoff. We perform our
experiments for the specific task of medical image generation and outperform
existing state-of-the-art training-time mitigation strategies by fine-tuning as
few as 0.019% of model parameters. Furthermore, we show that the strategies
learned through our framework are transferable across different datasets and
domains. Our proposed framework is scalable to large datasets and agnostic to
the choice of reward functions. Finally, we show that our framework can be
combined with existing approaches for further memorization mitigation.

ÊëòË¶ÅÔºöÊì¥Êï£Ê®°ÂûãÂú®ÁîüÊàêËàáË®ìÁ∑¥ÂàÜ‰ΩàÂØÜÂàáÁõ∏ÈóúÁöÑÂúñÂÉèÊñπÈù¢Ë°®ÁèæÂá∫ÂçìË∂äÁöÑËÉΩÂäõ„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÊ®°ÂûãÂÆπÊòìË®ìÁ∑¥Ë≥áÊñôË®òÊÜ∂ÔºåÂ∞éËá¥Âö¥ÈáçÁöÑÈö±ÁßÅ„ÄÅÂÄ´ÁêÜÂíåÊ≥ïÂæãÂïèÈ°åÔºåÁâπÂà•ÊòØÂú®ÈÜ´ÁôÇÂΩ±ÂÉèÁ≠âÊïèÊÑüÈ†òÂüü„ÄÇÊàëÂÄëÂÅáË®≠Ë®òÊÜ∂ÊòØÁî±Ê∑±Â∫¶Ê®°ÂûãÁöÑÈÅéÂ∫¶ÂèÉÊï∏ÂåñÈ©ÖÂãïÁöÑÔºåÈÄôË°®ÊòéÂú®ÂæÆË™øÊúüÈñìË¶èÁØÑÊ®°ÂûãÂÆπÈáèÂèØËÉΩÊòØÊúâÊïàÁöÑÁ∑©Ëß£Á≠ñÁï•„ÄÇÂèÉÊï∏ÊúâÊïàÂæÆË™ø (PEFT) ÊñπÊ≥ïÊèê‰æõ‰∫Ü‰∏ÄÁ®ÆÊúâÂ∏åÊúõÁöÑÂÆπÈáèÊéßÂà∂ÊñπÊ≥ïÔºåÈÄöÈÅéÈÅ∏ÊìáÊÄßÂú∞Êõ¥Êñ∞ÁâπÂÆöÂèÉÊï∏„ÄÇÁÑ∂ËÄåÔºåÊâæÂà∞Âπ≥Ë°°ÁîüÊàêÂìÅË≥™ÂíåË®òÊÜ∂ÁöÑÊúÄ‰Ω≥ÂèØÂ≠∏ÁøíÂèÉÊï∏Â≠êÈõÜ‰ªçÁÑ∂Èõ£‰ª•ÊçâÊë∏„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∏ÄÊåëÊà∞ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÈõôÂ±§ÂÑ™ÂåñÊ°ÜÊû∂ÔºåÈÄöÈÅéÂà©Áî®Ë®òÊÜ∂ÂíåÁîüÊàêÂìÅË≥™ÊåáÊ®ô‰ΩúÁÇ∫ÁçéÂãµ‰æÜÊåáÂ∞éËá™ÂãïÂåñÂèÉÊï∏ÈÅ∏Êìá„ÄÇÊàëÂÄëÁöÑÊ°ÜÊû∂ÊàêÂäüÂú∞Ë≠òÂà•‰∫ÜË¶ÅÊõ¥Êñ∞ÁöÑÊúÄ‰Ω≥ÂèÉÊï∏ÈõÜÔºå‰ª•ÊªøË∂≥ÁîüÊàêË®òÊÜ∂Ê¨äË°°„ÄÇÊàëÂÄëÈáùÂ∞çÈÜ´ÁôÇÂΩ±ÂÉèÁîüÊàêÂÖ∑È´î‰ªªÂãôÂü∑Ë°åÊàëÂÄëÁöÑÂØ¶È©óÔºå‰∏¶‰∏îÈÄèÈÅéÂæÆË™øÂÉÖ 0.019% ÁöÑÊ®°ÂûãÂèÉÊï∏ÔºåÂ∞±ÂÑ™ÊñºÁèæÊúâÁöÑÊúÄÂÖàÈÄ≤ÁöÑË®ìÁ∑¥ÊôÇÈñìÁ∑©Ëß£Á≠ñÁï•„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëË°®ÊòéÈÄèÈÅéÊàëÂÄëÁöÑÊ°ÜÊû∂Â≠∏ÁøíÂà∞ÁöÑÁ≠ñÁï•ÂèØ‰ª•ËΩâÁßªÂà∞‰∏çÂêåÁöÑË≥áÊñôÈõÜÂíåÈ†òÂüü„ÄÇÊàëÂÄëÊèêÂá∫ÁöÑÊ°ÜÊû∂ÂèØÊì¥ÂÖÖÂà∞Â§ßÂûãË≥áÊñôÈõÜÔºå‰∏¶‰∏îËàáÁçéÂãµÂáΩÊï∏ÁöÑÈÅ∏ÊìáÁÑ°Èóú„ÄÇÊúÄÂæåÔºåÊàëÂÄëË°®ÊòéÊàëÂÄëÁöÑÊ°ÜÊû∂ÂèØ‰ª•ËàáÁèæÊúâÊñπÊ≥ïÁµêÂêàÔºå‰ª•ÈÄ≤‰∏ÄÊ≠•Ê∏õÂ∞ëË®òÊÜ∂„ÄÇ

##### **Conformal Depression Prediction**
2405.18723v1 by Yonghong Li, Shan Qu, Xiuzhuang Zhou

While existing depression recognition methods based on deep learning show
promise, their practical application is hindered by the lack of
trustworthiness, as these deep models are often deployed as \textit{black box}
models, leaving us uncertain about the confidence of the model predictions. For
high-risk clinical applications like depression recognition, uncertainty
quantification is essential in decision-making. In this paper, we introduce
conformal depression prediction (CDP), a depression recognition method with
uncertainty quantification based on conformal prediction (CP), giving valid
confidence intervals with theoretical coverage guarantees for the model
predictions. CDP is a plug-and-play module that requires neither model
retraining nor an assumption about the depression data distribution. As CDP
provides only an average performance guarantee across all inputs rather than
per-input performance guarantee, we propose CDP-ACC, an improved conformal
prediction with approximate conditional coverage. CDP-ACC firstly estimates the
prediction distribution through neighborhood relaxation, and then introduces a
conformal score function by constructing nested sequences, so as to provide
tighter prediction interval for each specific input. We empirically demonstrate
the application of uncertainty quantification in depression recognition, and
the effectiveness and superiority of CDP and CDP-ACC on the AVEC 2013 and AVEC
2014 datasets

ÊëòË¶ÅÔºöÂÑòÁÆ°ÁèæÊúâÁöÑÂü∫ÊñºÊ∑±Â∫¶Â≠∏ÁøíÁöÑÊÜÇÈ¨±ÁóáËæ®Ë≠òÊñπÊ≥ïÈ°ØÁ§∫Âá∫ÂâçÊôØÔºåÂÖ∂ÂØ¶ÈöõÊáâÁî®ÂçªÂèóÂà∞ÂèØ‰ø°Â∫¶ÁöÑ‰∏çË∂≥ÊâÄÈòªÁ§ôÔºåÂõ†ÁÇ∫ÈÄô‰∫õÊ∑±Â∫¶Ê®°ÂûãÁ∂ìÂ∏∏Ë¢´ÈÉ®ÁΩ≤ÁÇ∫„ÄåÈªëÁÆ±„ÄçÊ®°ÂûãÔºåËÆìÊàëÂÄëÁÑ°Ê≥ïÁ¢∫ÂÆöÊ®°ÂûãÈ†êÊ∏¨ÁöÑÁΩÆ‰ø°Â∫¶„ÄÇÂ∞çÊñºÊÜÇÈ¨±ÁóáËæ®Ë≠òÁ≠âÈ´òÈ¢®Èö™ÁöÑËá®Â∫äÊáâÁî®Ôºå‰∏çÁ¢∫ÂÆöÊÄßÈáèÂåñÂú®Ê±∫Á≠ñÂà∂ÂÆö‰∏≠Ëá≥ÈóúÈáçË¶Å„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫ÜÂÖ±ÂΩ¢ÊÜÇÈ¨±ÁóáÈ†êÊ∏¨ (CDP)ÔºåÈÄôÊòØ‰∏ÄÁ®ÆÂü∫ÊñºÂÖ±ÂΩ¢È†êÊ∏¨ (CP) ÁöÑÊÜÇÈ¨±ÁóáËæ®Ë≠òÊñπÊ≥ïÔºåÂÖ∑Êúâ‰∏çÁ¢∫ÂÆöÊÄßÈáèÂåñÔºåÂèØÊèê‰æõÊ®°ÂûãÈ†êÊ∏¨ÁöÑÊúâÊïàÁΩÆ‰ø°ÂçÄÈñìÔºå‰∏¶‰øùË≠âÁêÜË´ñÊ∂µËìãÁéá„ÄÇCDP ÊòØ‰∏ÄÂÄãÂç≥ÊèíÂç≥Áî®ÁöÑÊ®°ÁµÑÔºåÊó¢‰∏çÈúÄË¶ÅÈáçÊñ∞Ë®ìÁ∑¥Ê®°ÂûãÔºå‰πü‰∏çÈúÄË¶ÅÂÅáË®≠ÊÜÇÈ¨±ÁóáË≥áÊñôÂàÜ‰Ωà„ÄÇÁî±Êñº CDP ÂÉÖÊèê‰æõÊâÄÊúâËº∏ÂÖ•ÁöÑÂπ≥ÂùáÊïàËÉΩ‰øùË≠âÔºåËÄå‰∏çÊòØÊØèÂÄãËº∏ÂÖ•ÁöÑÊïàËÉΩ‰øùË≠âÔºåÂõ†Ê≠§ÊàëÂÄëÊèêÂá∫‰∫Ü CDP-ACCÔºåÈÄôÊòØ‰∏ÄÁ®ÆÂÖ∑ÊúâËøë‰ººÊ¢ù‰ª∂Ê∂µËìãÁéáÁöÑÊîπËâØÂÖ±ÂΩ¢È†êÊ∏¨„ÄÇCDP-ACC È¶ñÂÖàÈÄèÈÅéÈÑ∞ÂüüÊîæÈ¨Ü‰æÜ‰º∞Ë®àÈ†êÊ∏¨ÂàÜ‰ΩàÔºåÁÑ∂ÂæåÈÄèÈÅéÂª∫ÊßãÂ∑¢ÁãÄÂ∫èÂàó‰æÜÂºïÂÖ•ÂÖ±ÂΩ¢Ë©ïÂàÜÂáΩÊï∏Ôºå‰ª•‰æøÁÇ∫ÊØèÂÄãÁâπÂÆöËº∏ÂÖ•Êèê‰æõÊõ¥Âö¥Ê†ºÁöÑÈ†êÊ∏¨ÂçÄÈñì„ÄÇÊàëÂÄëÊÜëÁ∂ìÈ©óË≠âÊòé‰∫Ü‰∏çÁ¢∫ÂÆöÊÄßÈáèÂåñÂú®ÊÜÇÈ¨±ÁóáËæ®Ë≠ò‰∏≠ÁöÑÊáâÁî®Ôºå‰ª•Âèä CDP Âíå CDP-ACC Âú® AVEC 2013 Âíå AVEC 2014 Ë≥áÊñôÈõÜ‰∏äÁöÑÊúâÊïàÊÄßÂíåÂÑ™Ë∂äÊÄß

##### **D-CoRP: Differentiable Connectivity Refinement for Functional Brain Networks**
2405.18658v1 by Haoyu Hu, Hongrun Zhang, Chao Li

Brain network is an important tool for understanding the brain, offering
insights for scientific research and clinical diagnosis. Existing models for
brain networks typically primarily focus on brain regions or overlook the
complexity of brain connectivities. MRI-derived brain network data is commonly
susceptible to connectivity noise, underscoring the necessity of incorporating
connectivities into the modeling of brain networks. To address this gap, we
introduce a differentiable module for refining brain connectivity. We develop
the multivariate optimization based on information bottleneck theory to address
the complexity of the brain network and filter noisy or redundant connections.
Also, our method functions as a flexible plugin that is adaptable to most graph
neural networks. Our extensive experimental results show that the proposed
method can significantly improve the performance of various baseline models and
outperform other state-of-the-art methods, indicating the effectiveness and
generalizability of the proposed method in refining brain network connectivity.
The code will be released for public availability.

ÊëòË¶ÅÔºöÂ§ßËÖ¶Á∂≤Ë∑ØÊòØÁêÜËß£Â§ßËÖ¶ÁöÑÈáçË¶ÅÂ∑•ÂÖ∑ÔºåÁÇ∫ÁßëÂ≠∏Á†îÁ©∂ÂíåËá®Â∫äË®∫Êñ∑Êèê‰æõË¶ãËß£„ÄÇÁèæÊúâÁöÑÂ§ßËÖ¶Á∂≤Ë∑ØÊ®°ÂûãÈÄöÂ∏∏‰∏ªË¶ÅÈóúÊ≥®Â§ßËÖ¶ÂçÄÂüüÊàñÂøΩÁï•Â§ßËÖ¶ÈÄ£Êé•ÁöÑË§áÈõúÊÄß„ÄÇÊ∫êËá™ MRI ÁöÑÂ§ßËÖ¶Á∂≤Ë∑ØË≥áÊñôÈÄöÂ∏∏ÂÆπÊòìÂèóÂà∞ÈÄ£Êé•ÈõúË®äÁöÑÂΩ±ÈüøÔºåÈÄôÂº∑Ë™ø‰∫ÜÂ∞áÈÄ£Êé•Á¥çÂÖ•Â§ßËÖ¶Á∂≤Ë∑ØÂª∫Ê®°ÁöÑÂøÖË¶ÅÊÄß„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂ∑ÆË∑ùÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÂèØÂçÄÂàÜÁöÑÊ®°ÁµÑ‰æÜÁ≤æÁÖâÂ§ßËÖ¶ÈÄ£Êé•ÊÄß„ÄÇÊàëÂÄëÊ†πÊìöË≥áË®äÁì∂È†∏ÁêÜË´ñÈñãÁôºÂ§öËÆäÊï∏ÊúÄ‰Ω≥ÂåñÔºå‰ª•Ëß£Ê±∫Â§ßËÖ¶Á∂≤Ë∑ØÁöÑË§áÈõúÊÄß‰∏¶ÈÅéÊøæÈõúË®äÊàñÂÜóÈ§òÈÄ£Êé•„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁöÑÊ®°ÂûãÂèØ‰ΩúÁÇ∫‰∏ÄÂÄãÈùàÊ¥ªÁöÑÂ§ñÊéõÁ®ãÂºèÔºåÈÅ©Áî®ÊñºÂ§ßÂ§öÊï∏ÂúñÂΩ¢Á•ûÁ∂ìÁ∂≤Ë∑Ø„ÄÇÊàëÂÄëÂª£Ê≥õÁöÑÂØ¶È©óÁµêÊûúË°®ÊòéÔºåÊâÄÊèêÂá∫ÁöÑÊ®°ÂûãÂèØ‰ª•È°ØËëóÊîπÂñÑÂêÑÁ®ÆÂü∫Ê∫ñÊ®°ÂûãÁöÑÊïàËÉΩÔºå‰∏¶ÂÑ™ÊñºÂÖ∂‰ªñÊúÄÂÖàÈÄ≤ÁöÑÊ®°ÂûãÔºåÈÄôË°®ÊòéÊâÄÊèêÂá∫ÁöÑÊ®°ÂûãÂú®Á≤æÁÖâÂ§ßËÖ¶Á∂≤Ë∑ØÈÄ£Êé•ÊÄßÊñπÈù¢ÁöÑÊúâÊïàÊÄßÂíåÊ¶ÇÊã¨ÊÄß„ÄÇË©≤Á®ãÂºèÁ¢ºÂ∞áÂÖ¨ÈñãÁôºÂ∏É„ÄÇ

##### **DTR-Bench: An in silico Environment and Benchmark Platform for Reinforcement Learning Based Dynamic Treatment Regime**
2405.18610v1 by Zhiyao Luo, Mingcheng Zhu, Fenglin Liu, Jiali Li, Yangchen Pan, Jiandong Zhou, Tingting Zhu

Reinforcement learning (RL) has garnered increasing recognition for its
potential to optimise dynamic treatment regimes (DTRs) in personalised
medicine, particularly for drug dosage prescriptions and medication
recommendations. However, a significant challenge persists: the absence of a
unified framework for simulating diverse healthcare scenarios and a
comprehensive analysis to benchmark the effectiveness of RL algorithms within
these contexts. To address this gap, we introduce \textit{DTR-Bench}, a
benchmarking platform comprising four distinct simulation environments tailored
to common DTR applications, including cancer chemotherapy, radiotherapy,
glucose management in diabetes, and sepsis treatment. We evaluate various
state-of-the-art RL algorithms across these settings, particularly highlighting
their performance amidst real-world challenges such as
pharmacokinetic/pharmacodynamic (PK/PD) variability, noise, and missing data.
Our experiments reveal varying degrees of performance degradation among RL
algorithms in the presence of noise and patient variability, with some
algorithms failing to converge. Additionally, we observe that using temporal
observation representations does not consistently lead to improved performance
in DTR settings. Our findings underscore the necessity of developing robust,
adaptive RL algorithms capable of effectively managing these complexities to
enhance patient-specific healthcare. We have open-sourced our benchmark and
code at https://github.com/GilesLuo/DTR-Bench.

ÊëòË¶ÅÔºöÂº∑ÂåñÂ≠∏Áøí (RL) Âõ†ÂÖ∂ÊúÄ‰Ω≥ÂåñÂÄã‰∫∫ÂåñÈÜ´ÁôÇ‰∏≠ÁöÑÂãïÊÖãÊ≤ªÁôÇÊñπÊ°à (DTR) ÁöÑÊΩõÂäõËÄåÁç≤ÂæóË∂ä‰æÜË∂äÂ§öÁöÑË™çÂèØÔºåÁâπÂà•ÊòØÂú®Ëó•Áâ©ÂäëÈáèËôïÊñπÂíåËó•Áâ©Âª∫Ë≠∞ÊñπÈù¢„ÄÇÁÑ∂ËÄåÔºå‰∏ÄÂÄãÈáçÂ§ßÁöÑÊåëÊà∞‰ªçÁÑ∂Â≠òÂú®ÔºöÁº∫‰πè‰∏ÄÂÄãÁµ±‰∏ÄÁöÑÊ°ÜÊû∂‰æÜÊ®°Êì¨‰∏çÂêåÁöÑÈÜ´ÁôÇ‰øùÂÅ•Â†¥ÊôØÔºå‰ª•Âèä‰∏ÄÂÄãÂÖ®Èù¢ÁöÑÂàÜÊûê‰æÜÊØîËºÉ RL ÊºîÁÆóÊ≥ïÂú®ÈÄô‰∫õÂ†¥ÊôØ‰∏≠ÁöÑÊúâÊïàÊÄß„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂ∑ÆË∑ùÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü \textit{DTR-Bench}Ôºå‰∏ÄÂÄãÂü∫Ê∫ñÊ∏¨Ë©¶Âπ≥Âè∞ÔºåÂåÖÂê´ÂõõÂÄã‰∏çÂêåÁöÑÊ®°Êì¨Áí∞Â¢ÉÔºåÈáùÂ∞çÂ∏∏Ë¶ãÁöÑ DTR ÊáâÁî®ÔºåÂåÖÊã¨ÁôåÁóáÂåñÁôÇ„ÄÅÊîæÂ∞ÑÊ≤ªÁôÇ„ÄÅÁ≥ñÂ∞øÁóÖ‰∏≠ÁöÑËë°ËêÑÁ≥ñÁÆ°ÁêÜÂíåÊïóË°ÄÁóáÊ≤ªÁôÇ„ÄÇÊàëÂÄëÂú®ÈÄô‰∫õË®≠ÂÆö‰∏≠Ë©ï‰º∞‰∫ÜÂêÑÁ®ÆÊúÄÂÖàÈÄ≤ÁöÑ RL ÊºîÁÆóÊ≥ïÔºåÁâπÂà•Âº∑Ë™øÂÆÉÂÄëÂú®Ëó•‰ª£ÂãïÂäõÂ≠∏/Ëó•ÊïàÂãïÂäõÂ≠∏ (PK/PD) ËÆäÁï∞ÊÄß„ÄÅÈõúË®äÂíåË≥áÊñôÈÅ∫Â§±Á≠âÁèæÂØ¶‰∏ñÁïåÊåëÊà∞‰∏≠ÁöÑË°®Áèæ„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÊè≠Á§∫‰∫ÜÂú®ÈõúË®äÂíåÊÇ£ËÄÖËÆäÁï∞ÊÄßÂ≠òÂú®ÁöÑÊÉÖÊ≥Å‰∏ãÔºåRL ÊºîÁÆóÊ≥ï‰πãÈñìÁöÑÊïàËÉΩ‰∏ãÈôçÁ®ãÂ∫¶‰∏çÂêåÔºåÊúâ‰∫õÊºîÁÆóÊ≥ïÁÑ°Ê≥ïÊî∂ÊñÇ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëËßÄÂØüÂà∞‰ΩøÁî®ÊôÇÈñìËßÄÂØüË°®Á§∫‰∏¶‰∏çÊúÉÊåÅÁ∫åÂ∞éËá¥ DTR Ë®≠ÂÆö‰∏≠ÁöÑÊïàËÉΩÊèêÂçá„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÂº∑Ë™ø‰∫ÜÈñãÁôºÂº∑ÂÅ•„ÄÅÈÅ©ÊáâÊÄß RL ÊºîÁÆóÊ≥ïÁöÑÂøÖË¶ÅÊÄßÔºåÈÄô‰∫õÊºîÁÆóÊ≥ïËÉΩÂ§†ÊúâÊïàÁÆ°ÁêÜÈÄô‰∫õË§áÈõúÊÄßÔºå‰ª•Â¢ûÂº∑ÁâπÂÆöÊÇ£ËÄÖÁöÑÈÜ´ÁôÇ‰øùÂÅ•„ÄÇÊàëÂÄëÂ∑≤Âú® https://github.com/GilesLuo/DTR-Bench ÈñãÊ∫ê‰∫ÜÊàëÂÄëÁöÑÂü∫Ê∫ñÊ∏¨Ë©¶ÂíåÁ®ãÂºèÁ¢º„ÄÇ

##### **Low-rank finetuning for LLMs: A fairness perspective**
2405.18572v1 by Saswat Das, Marco Romanelli, Cuong Tran, Zarreen Reza, Bhavya Kailkhura, Ferdinando Fioretto

Low-rank approximation techniques have become the de facto standard for
fine-tuning Large Language Models (LLMs) due to their reduced computational and
memory requirements. This paper investigates the effectiveness of these methods
in capturing the shift of fine-tuning datasets from the initial pre-trained
data distribution. Our findings reveal that there are cases in which low-rank
fine-tuning falls short in learning such shifts. This, in turn, produces
non-negligible side effects, especially when fine-tuning is adopted for
toxicity mitigation in pre-trained models, or in scenarios where it is
important to provide fair models. Through comprehensive empirical evidence on
several models, datasets, and tasks, we show that low-rank fine-tuning
inadvertently preserves undesirable biases and toxic behaviors. We also show
that this extends to sequential decision-making tasks, emphasizing the need for
careful evaluation to promote responsible LLMs development.

ÊëòË¶ÅÔºö‰ΩéÁß©Ëøë‰ººÊäÄÊúØÂ∑≤Êàê‰∏∫ÂæÆË∞ÉÂ§ßÂûãËØ≠Ë®ÄÊ®°Âûã (LLM) ÁöÑ‰∫ãÂÆûÊ†áÂáÜÔºåÂõ†‰∏∫ÂÆÉ‰ª¨Èôç‰Ωé‰∫ÜËÆ°ÁÆóÂíåÂÜÖÂ≠òÈúÄÊ±Ç„ÄÇÊú¨ÊñáÊé¢ËÆ®‰∫ÜËøô‰∫õÊñπÊ≥ïÂú®‰ªéÂàùÂßãÈ¢ÑËÆ≠ÁªÉÊï∞ÊçÆÂàÜÂ∏É‰∏≠ÊçïËé∑ÂæÆË∞ÉÊï∞ÊçÆÈõÜÁöÑÂèòÂåñÊñπÈù¢ÁöÑÊúâÊïàÊÄß„ÄÇÊàë‰ª¨ÁöÑÂèëÁé∞Ë°®ÊòéÔºåÂú®Êüê‰∫õÊÉÖÂÜµ‰∏ãÔºå‰ΩéÁß©ÂæÆË∞ÉÊó†Ê≥ïÂ≠¶‰π†ËøôÁßçÂèòÂåñ„ÄÇËøôÂèçËøáÊù•Âèà‰ºö‰∫ßÁîü‰∏çÂèØÂøΩËßÜÁöÑÂâØ‰ΩúÁî®ÔºåÂ∞§ÂÖ∂ÊòØÂú®ÂæÆË∞ÉË¢´Áî®‰∫éÈ¢ÑËÆ≠ÁªÉÊ®°Âûã‰∏≠ÁöÑÊØíÊÄßÁºìËß£Êó∂ÔºåÊàñÂú®Êèê‰æõÂÖ¨Âπ≥Ê®°ÂûãÂæàÈáçË¶ÅÁöÑÂú∫ÊôØ‰∏≠„ÄÇÈÄöËøáÂØπÂ§ö‰∏™Ê®°Âûã„ÄÅÊï∞ÊçÆÈõÜÂíå‰ªªÂä°ËøõË°åÂÖ®Èù¢ÁöÑÂÆûËØÅËØÅÊçÆÔºåÊàë‰ª¨Ë°®Êòé‰ΩéÁß©ÂæÆË∞ÉÊó†ÊÑè‰∏≠‰øùÁïô‰∫Ü‰∏çËâØÂÅèËßÅÂíåÊúâÂÆ≥Ë°å‰∏∫„ÄÇÊàë‰ª¨ËøòË°®ÊòéËøôÊâ©Â±ïÂà∞‰∫ÜÈ°∫Â∫èÂÜ≥Á≠ñ‰ªªÂä°ÔºåÂº∫Ë∞É‰∫Ü‰ªîÁªÜËØÑ‰º∞‰ª•‰øÉËøõË¥üË¥£‰ªªÁöÑ LLM ÂºÄÂèëÁöÑÂøÖË¶ÅÊÄß„ÄÇ

##### **Reinforcement Learning in Dynamic Treatment Regimes Needs Critical Reexamination**
2405.18556v1 by Zhiyao Luo, Yangchen Pan, Peter Watkinson, Tingting Zhu

In the rapidly changing healthcare landscape, the implementation of offline
reinforcement learning (RL) in dynamic treatment regimes (DTRs) presents a mix
of unprecedented opportunities and challenges. This position paper offers a
critical examination of the current status of offline RL in the context of
DTRs. We argue for a reassessment of applying RL in DTRs, citing concerns such
as inconsistent and potentially inconclusive evaluation metrics, the absence of
naive and supervised learning baselines, and the diverse choice of RL
formulation in existing research. Through a case study with more than 17,000
evaluation experiments using a publicly available Sepsis dataset, we
demonstrate that the performance of RL algorithms can significantly vary with
changes in evaluation metrics and Markov Decision Process (MDP) formulations.
Surprisingly, it is observed that in some instances, RL algorithms can be
surpassed by random baselines subjected to policy evaluation methods and reward
design. This calls for more careful policy evaluation and algorithm development
in future DTR works. Additionally, we discussed potential enhancements toward
more reliable development of RL-based dynamic treatment regimes and invited
further discussion within the community. Code is available at
https://github.com/GilesLuo/ReassessDTR.

ÊëòË¶ÅÔºöÂú®Âø´ÈÄüËÆäÂåñÁöÑÈÜ´ÁôÇ‰øùÂÅ•Áí∞Â¢É‰∏≠ÔºåÈõ¢Á∑öÂº∑ÂåñÂ≠∏Áøí (RL) Âú®ÂãïÊÖãÊ≤ªÁôÇÊñπÊ°à (DTR) ‰∏≠ÁöÑÂØ¶ÊñΩÂëàÁèæ‰∫ÜÂâçÊâÄÊú™ÊúâÁöÑÊ©üÊúÉÂíåÊåëÊà∞„ÄÇÊú¨Á´ãÂ†¥Êñá‰ª∂Â∞çÈõ¢Á∑ö RL Âú® DTR ËÉåÊôØ‰∏ãÁöÑÁèæÁãÄÈÄ≤Ë°å‰∫ÜÊâπÂà§ÊÄßÂØ©Êü•„ÄÇÊàëÂÄë‰∏ªÂºµÈáçÊñ∞Ë©ï‰º∞Âú® DTR ‰∏≠ÊáâÁî® RLÔºå‰∏¶ÊèêÂá∫‰∫Ü‰∏Ä‰∫õÁñëÊÖÆÔºå‰æãÂ¶Ç‰∏ç‰∏ÄËá¥‰∏îÂèØËÉΩÊ≤íÊúâÂÆöË´ñÁöÑË©ï‰º∞ÊåáÊ®ô„ÄÅÁº∫‰πèÂ§©ÁúüÁöÑÂíåÁõ£Áù£ÂºèÁöÑÂ≠∏ÁøíÂü∫Á∑öÔºå‰ª•ÂèäÁèæÊúâÁ†îÁ©∂‰∏≠ RL ÂÖ¨ÂºèÁöÑÂ§öÊ®£ÈÅ∏Êìá„ÄÇÈÄöÈÅé‰∏ÄÂÄã‰ΩøÁî®ÂÖ¨Èñã Sepsis Êï∏ÊìöÈõÜÈÄ≤Ë°åÁöÑË∂ÖÈÅé 17,000 Ê¨°Ë©ï‰º∞ÂØ¶È©óÁöÑÊ°à‰æãÁ†îÁ©∂ÔºåÊàëÂÄëË≠âÊòé‰∫Ü RL ÊºîÁÆóÊ≥ïÁöÑÊïàËÉΩÊúÉÈö®ËëóË©ï‰º∞ÊåáÊ®ôÂíåÈ¶¨ÂèØÂ§´Ê±∫Á≠ñÈÅéÁ®ã (MDP) ÂÖ¨ÂºèÁöÑËÆäÂåñËÄåÊúâÈ°ØËëóÂ∑ÆÁï∞„ÄÇ‰ª§‰∫∫È©öË®ùÁöÑÊòØÔºåÊàëÂÄëËßÄÂØüÂà∞Âú®Êüê‰∫õÊÉÖÊ≥Å‰∏ãÔºåRL ÊºîÁÆóÊ≥ïÂèØËÉΩÊúÉË¢´Èö®Ê©üÂü∫Á∑öÊâÄË∂ÖË∂äÔºåÈÄô‰∫õÂü∫Á∑öÊúÉÂèóÂà∞Á≠ñÁï•Ë©ï‰º∞ÊñπÊ≥ïÂíåÁçéÂãµË®≠Ë®àÁöÑÂΩ±Èüø„ÄÇÈÄôË¶ÅÊ±ÇÂú®Êú™‰æÜÁöÑ DTR Â∑•‰Ωú‰∏≠ÈÄ≤Ë°åÊõ¥‰ªîÁ¥∞ÁöÑÁ≠ñÁï•Ë©ï‰º∞ÂíåÊºîÁÆóÊ≥ïÈñãÁôº„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëË®éË´ñ‰∫ÜÊúùËëóÊõ¥ÂèØÈù†ÁöÑÂü∫Êñº RL ÁöÑÂãïÊÖãÊ≤ªÁôÇÊñπÊ°àÈñãÁôºÁöÑÊΩõÂú®ÊîπÈÄ≤Ôºå‰∏¶ÈÇÄË´ãÁ§æÁæ§ÈÄ≤‰∏ÄÊ≠•Ë®éË´ñ„ÄÇÁ®ãÂºèÁ¢ºÂèØÂú® https://github.com/GilesLuo/ReassessDTR ÂèñÂæó„ÄÇ

##### **The FAIIR Tool: A Conversational AI Agent Assistant for Youth Mental Health Service Provision**
2405.18553v1 by Stephen Obadinma, Alia Lachana, Maia Norman, Jocelyn Rankin, Joanna Yu, Xiaodan Zhu, Darren Mastropaolo, Deval Pandya, Roxana Sultan, Elham Dolatabadi

World's healthcare systems and mental health agencies face both a growing
demand for youth mental health services, alongside a simultaneous challenge of
limited resources. Given these constraints, this work presents our experience
in the creation and evaluation of the FAIIR (Frontline Assistant: Issue
Identification and Recommendation) tool, an ensemble of domain-adapted and
fine-tuned transformer models, leveraging natural language processing to
identify issues that youth may be experiencing. We explore the technical
development, performance, and validation processes leveraged for the FAIIR tool
in application to situations of frontline crisis response via Kids Help Phone.
Frontline Crisis Responders assign an issue tag from a defined list following
each conversation. Assisting with the identification of issues of relevance
helps reduce the burden on CRs, ensuring that appropriate resources can be
provided and that active rescues and mandatory reporting can take place in
critical situations requiring immediate de-escalation.

ÊëòË¶ÅÔºöÂÖ®ÁêÉÁöÑÈÜ´ÁôÇ‰øùÂÅ•Á≥ªÁµ±ËàáÂøÉÁêÜÂÅ•Â∫∑Ê©üÊßãÈù¢Ëá®ËëóÂ∞çÈùíÂ∞ëÂπ¥ÂøÉÁêÜÂÅ•Â∫∑ÊúçÂãôÈúÄÊ±ÇÂ¢ûÂä†ÁöÑÂïèÈ°åÔºåÂêåÊôÇ‰πüÈù¢Ëá®ËëóË≥áÊ∫êÊúâÈôêÁöÑÊåëÊà∞„ÄÇÂú®ÈÄô‰∫õÈôêÂà∂‰∏ãÔºåÊú¨Á†îÁ©∂ÂëàÁèæÊàëÂÄëÂú®Âª∫Á´ãËàáË©ï‰º∞ FAIIRÔºàÂâçÁ∑öÂä©ÁêÜÔºöÂïèÈ°åË≠òÂà•ËàáÂª∫Ë≠∞ÔºâÂ∑•ÂÖ∑ÁöÑÁ∂ìÈ©óÔºåÂÆÉÁµêÂêà‰∫ÜÈ†òÂüüÈÅ©ÊáâËàáÂæÆË™øÁöÑËΩâÊèõÂô®Ê®°ÂûãÔºåÂà©Áî®Ëá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ‰æÜË≠òÂà•ÈùíÂ∞ëÂπ¥ÂèØËÉΩÈÅ≠ÈÅáÁöÑÂïèÈ°å„ÄÇÊàëÂÄëÊé¢Ë®é‰∫Ü FAIIR Â∑•ÂÖ∑Âú® Kids Help Phone ÁöÑÂâçÁ∑öÂç±Ê©üÊáâÂ∞çÊÉÖÊ≥Å‰∏≠ÊâÄÊáâÁî®ÁöÑÊäÄË°ìÈñãÁôº„ÄÅÊïàËÉΩËàáÈ©óË≠âÁ®ãÂ∫è„ÄÇÂâçÁ∑öÂç±Ê©üÊáâËÆä‰∫∫Âì°Âú®ÊØèÊ¨°Â∞çË©±ÂæåÊúÉÂæûÊó¢ÂÆöÁöÑÊ∏ÖÂñÆ‰∏≠ÊåáÂÆö‰∏ÄÂÄãÂïèÈ°åÊ®ôÁ±§„ÄÇÂçîÂä©Ë≠òÂà•Áõ∏ÈóúÂïèÈ°åÊúâÂä©ÊñºÊ∏õËºïÂç±Ê©üÊáâËÆä‰∫∫Âì°ÁöÑË≤†ÊìîÔºåÁ¢∫‰øùÂú®Á∑äÊÄ•ÊÉÖÊ≥Å‰∏ãÂèØ‰ª•Êèê‰æõÈÅ©Áï∂ÁöÑË≥áÊ∫êÔºå‰∏¶ÈÄ≤Ë°åÂøÖË¶ÅÁöÑÊïëÊè¥ËàáÂº∑Âà∂ÈÄöÂ†±„ÄÇ

##### **Improved Emotional Alignment of AI and Humans: Human Ratings of Emotions Expressed by Stable Diffusion v1, DALL-E 2, and DALL-E 3**
2405.18510v1 by James Derek Lomas, Willem van der Maden, Sohhom Bandyopadhyay, Giovanni Lion, Nirmal Patel, Gyanesh Jain, Yanna Litowsky, Haian Xue, Pieter Desmet

Generative AI systems are increasingly capable of expressing emotions via
text and imagery. Effective emotional expression will likely play a major role
in the efficacy of AI systems -- particularly those designed to support human
mental health and wellbeing. This motivates our present research to better
understand the alignment of AI expressed emotions with the human perception of
emotions. When AI tries to express a particular emotion, how might we assess
whether they are successful? To answer this question, we designed a survey to
measure the alignment between emotions expressed by generative AI and human
perceptions. Three generative image models (DALL-E 2, DALL-E 3 and Stable
Diffusion v1) were used to generate 240 examples of images, each of which was
based on a prompt designed to express five positive and five negative emotions
across both humans and robots. 24 participants recruited from the Prolific
website rated the alignment of AI-generated emotional expressions with a text
prompt used to generate the emotion (i.e., "A robot expressing the emotion
amusement"). The results of our evaluation suggest that generative AI models
are indeed capable of producing emotional expressions that are well-aligned
with a range of human emotions; however, we show that the alignment
significantly depends upon the AI model used and the emotion itself. We analyze
variations in the performance of these systems to identify gaps for future
improvement. We conclude with a discussion of the implications for future AI
systems designed to support mental health and wellbeing.

ÊëòË¶ÅÔºöÁîüÊàêÂºè AI Á≥ªÁµ±Ë∂ä‰æÜË∂äËÉΩÂ§†ÈÄèÈÅéÊñáÂ≠óÂíåÂúñÂÉèË°®ÈÅîÊÉÖÁ∑í„ÄÇÊúâÊïàÁöÑË°®ÈÅîÊÉÖÁ∑íÂæàÂèØËÉΩÊúÉÂú® AI Á≥ªÁµ±ÁöÑÊïàËÉΩ‰∏≠ÊâÆÊºîÈáçË¶ÅËßíËâ≤ÔºåÂ∞§ÂÖ∂ÊòØÈÇ£‰∫õË®≠Ë®àÁî®‰æÜÊîØÊåÅ‰∫∫È°ûÂøÉÁêÜÂÅ•Â∫∑ÂíåÁ¶èÁ•âÁöÑÁ≥ªÁµ±„ÄÇÈÄôÊøÄÂãµ‰∫ÜÊàëÂÄëÁõÆÂâçÁöÑÈÄôÈ†ÖÁ†îÁ©∂Ôºå‰ª•ÊúüËÉΩÊõ¥‰∫ÜËß£ AI Ë°®ÈÅîÁöÑÊÉÖÁ∑íËàá‰∫∫È°ûÂ∞çÊÉÖÁ∑íÁöÑÊÑüÁü•‰πãÈñìÁöÑÂ∞çÈΩä„ÄÇÁï∂ AI ÂòóË©¶Ë°®ÈÅîÁâπÂÆöÊÉÖÁ∑íÊôÇÔºåÊàëÂÄëË©≤Â¶Ç‰ΩïË©ï‰º∞‰ªñÂÄëÊòØÂê¶ÊàêÂäüÔºüÁÇ∫‰∫ÜÂõûÁ≠îÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëË®≠Ë®à‰∫Ü‰∏ÄÈ†ÖË™øÊü•Ôºå‰ª•Ë°°ÈáèÁîüÊàêÂºè AI Ë°®ÈÅîÁöÑÊÉÖÁ∑íËàá‰∫∫È°ûÊÑüÁü•‰πãÈñìÁöÑÂ∞çÈΩä„ÄÇ‰∏âÂÄãÁîüÊàêÂºèÂΩ±ÂÉèÊ®°ÂûãÔºàDALL-E 2„ÄÅDALL-E 3 Âíå Stable Diffusion v1ÔºâÁî®ÊñºÁî¢Áîü 240 ÂÄãÂΩ±ÂÉèÁØÑ‰æãÔºåÊØèÂÄãÁØÑ‰æãÈÉΩÂü∫Êñº‰∏ÄÂÄãÊèêÁ§∫ÔºåÊó®Âú®Ë°®ÈÅî‰∫∫È°ûÂíåÊ©üÂô®‰∫∫‰∫îÁ®ÆÊ≠£ÂêëÂíå‰∫îÁ®ÆË≤†ÂêëÊÉÖÁ∑í„ÄÇÂæû Prolific Á∂≤Á´ôÊãõÂãüÁöÑ 24 ‰ΩçÂèÉËàáËÄÖË©ï‰º∞‰∫Ü AI ÁîüÊàêÁöÑË°®ÊÉÖËàáÁî®ÊñºÁî¢ÁîüÊÉÖÁ∑íÁöÑÊñáÂ≠óÊèêÁ§∫‰πãÈñìÁöÑÂ∞çÈΩäÔºà‰æãÂ¶ÇÔºå„ÄåË°®ÈÅîÂ®õÊ®ÇÊÉÖÁ∑íÁöÑÊ©üÂô®‰∫∫„ÄçÔºâ„ÄÇÊàëÂÄëÁöÑË©ï‰º∞ÁµêÊûúË°®ÊòéÔºåÁîüÊàêÂºè AI Ê®°ÂûãÁ¢∫ÂØ¶ËÉΩÂ§†Áî¢ÁîüËàá‰∏ÄÁ≥ªÂàó‰∫∫È°ûÊÉÖÁ∑íÈ´òÂ∫¶Â∞çÈΩäÁöÑÊÉÖÁ∑íË°®ÈÅîÔºõÁÑ∂ËÄåÔºåÊàëÂÄëË°®ÊòéÔºåÂ∞çÈΩäÂú®ÂæàÂ§ßÁ®ãÂ∫¶‰∏äÂèñÊ±∫ÊñºÊâÄ‰ΩøÁî®ÁöÑ AI Ê®°ÂûãÂíåÊÉÖÁ∑íÊú¨Ë∫´„ÄÇÊàëÂÄëÂàÜÊûêÈÄô‰∫õÁ≥ªÁµ±ÊïàËÉΩÁöÑËÆäÂåñÔºå‰ª•ÊâæÂá∫Êú™‰æÜÊîπÈÄ≤ÁöÑÂ∑ÆË∑ù„ÄÇÊàëÂÄëÊúÄÂæåË®éË´ñ‰∫ÜÂ∞çÊú™‰æÜÊó®Âú®ÊîØÊåÅÂøÉÁêÜÂÅ•Â∫∑ÂíåÁ¶èÁ•âÁöÑ AI Á≥ªÁµ±ÁöÑÂΩ±Èüø„ÄÇ

##### **A Review and Implementation of Object Detection Models and Optimizations for Real-time Medical Mask Detection during the COVID-19 Pandemic**
2405.18387v1 by Ioanna Gogou, Dimitrios Koutsomitropoulos

Convolutional Neural Networks (CNN) are commonly used for the problem of
object detection thanks to their increased accuracy. Nevertheless, the
performance of CNN-based detection models is ambiguous when detection speed is
considered. To the best of our knowledge, there has not been sufficient
evaluation of the available methods in terms of the speed/accuracy trade-off in
related literature. This work assesses the most fundamental object detection
models on the Common Objects in Context (COCO) dataset with respect to this
trade-off, their memory consumption, and computational and storage cost. Next,
we select a highly efficient model called YOLOv5 to train on the topical and
unexplored dataset of human faces with medical masks, the Properly-Wearing
Masked Faces Dataset (PWMFD), and analyze the benefits of specific optimization
techniques for real-time medical mask detection: transfer learning, data
augmentations, and a Squeeze-and-Excitation attention mechanism. Using our
findings in the context of the COVID-19 pandemic, we propose an optimized model
based on YOLOv5s using transfer learning for the detection of correctly and
incorrectly worn medical masks that surpassed more than two times in speed (69
frames per second) the state-of-the-art model SE-YOLOv3 on the PWMFD dataset
while maintaining the same level of mean Average Precision (67%).

ÊëòË¶ÅÔºöÂç∑Á©çÁ•ûÁ∂ìÁ∂≤Ë∑Ø (CNN) Âõ†ÂÖ∂Ê∫ñÁ¢∫Â∫¶È´òËÄåÂ∏∏Ë¢´Áî®ÊñºÁõÆÊ®ôÂÅµÊ∏¨ÂïèÈ°å„ÄÇÁÑ∂ËÄåÔºåÁï∂ËÄÉÈáèÂÅµÊ∏¨ÈÄüÂ∫¶ÊôÇÔºåÂü∫Êñº CNN ÁöÑÂÅµÊ∏¨Ê®°ÂûãÊïàËÉΩÂçªÊ®°Á®úÂÖ©ÂèØ„ÄÇÊìöÊàëÂÄëÊâÄÁü•ÔºåÁõ∏ÈóúÊñáÁçª‰∏≠Â∞öÊú™Â∞çÂèØÁî®ÊñπÊ≥ïÈÄ≤Ë°åË∂≥Â§†ÁöÑË©ï‰º∞Ôºå‰ª•‰∫ÜËß£ÈÄüÂ∫¶/Ê∫ñÁ¢∫Â∫¶ÁöÑÊ¨äË°°ÂèñÊç®„ÄÇÊú¨Á†îÁ©∂ÈáùÂ∞ç Common Objects in Context (COCO) Ë≥áÊñôÈõÜË©ï‰º∞ÊúÄÂü∫Êú¨ÁöÑÁõÆÊ®ôÂÅµÊ∏¨Ê®°ÂûãÔºåËÄÉÈáè‰∏äËø∞Ê¨äË°°ÂèñÊç®„ÄÅË®òÊÜ∂È´îÊ∂àËÄóÔºå‰ª•ÂèäÈÅãÁÆóÂíåÂÑ≤Â≠òÊàêÊú¨„ÄÇÊé•ËëóÔºåÊàëÂÄëÈÅ∏Êìá‰∏ÄÂÄãÂêçÁÇ∫ YOLOv5 ÁöÑÈ´òÊïàÁéáÊ®°ÂûãÔºåÂú®‰∏ªÈ°åÊÄß‰∏îÂ∞öÊú™Êé¢Á¥¢ÁöÑ‰∫∫ËáâÊà¥ÈÜ´Áî®Âè£ÁΩ©Ë≥áÊñôÈõÜ Properly-Wearing Masked Faces Dataset (PWMFD) ‰∏äÈÄ≤Ë°åË®ìÁ∑¥Ôºå‰∏¶ÂàÜÊûêÁâπÂÆöÊúÄ‰Ω≥ÂåñÊäÄË°ìÂ∞çÂç≥ÊôÇÈÜ´Áî®Âè£ÁΩ©ÂÅµÊ∏¨ÁöÑÂÑ™ÈªûÔºöÈÅ∑ÁßªÂ≠∏Áøí„ÄÅË≥áÊñôÊì¥ÂÖÖÔºå‰ª•Âèä Squeeze-and-Excitation Ê≥®ÊÑèÂäõÊ©üÂà∂„ÄÇÊàëÂÄëÂú® COVID-19 Áñ´ÊÉÖÁöÑËÉåÊôØ‰∏ãÈÅãÁî®Á†îÁ©∂ÁµêÊûúÔºåÊèêÂá∫‰∏ÄÂÄãÂü∫Êñº YOLOv5s ÁöÑÊúÄ‰Ω≥ÂåñÊ®°ÂûãÔºå‰ΩøÁî®ÈÅ∑ÁßªÂ≠∏ÁøíÂÅµÊ∏¨Ê≠£Á¢∫ÂíåÈåØË™§ÈÖçÊà¥ÁöÑÈÜ´Áî®Âè£ÁΩ©ÔºåÂú® PWMFD Ë≥áÊñôÈõÜ‰∏äÁöÑÈÄüÂ∫¶ÊØîÊúÄÂÖàÈÄ≤ÁöÑ SE-YOLOv3 Ê®°ÂûãÂø´ÂÖ©ÂÄç‰ª•‰∏ä (ÊØèÁßí 69 ÂπÄ)ÔºåÂêåÊôÇÁ∂≠ÊåÅÁõ∏ÂêåÁ≠âÁ¥öÁöÑÂπ≥ÂùáÊ∫ñÁ¢∫Â∫¶ (67%)„ÄÇ

##### **Brain Tumor Segmentation (BraTS) Challenge 2024: Meningioma Radiotherapy Planning Automated Segmentation**
2405.18383v1 by Dominic LaBella, Katherine Schumacher, Michael Mix, Kevin Leu, Shan McBurney-Lin, Pierre Nedelec, Javier Villanueva-Meyer, Jonathan Shapey, Tom Vercauteren, Kazumi Chia, Omar Al-Salihi, Justin Leu, Lia Halasz, Yury Velichko, Chunhao Wang, John Kirkpatrick, Scott Floyd, Zachary J. Reitman, Trey Mullikin, Ulas Bagci, Sean Sachdev, Jona A. Hattangadi-Gluth, Tyler Seibert, Nikdokht Farid, Connor Puett, Matthew W. Pease, Kevin Shiue, Syed Muhammad Anwar, Shahriar Faghani, Muhammad Ammar Haider, Pranav Warman, Jake Albrecht, Andr√°s Jakab, Mana Moassefi, Verena Chung, Alejandro Aristizabal, Alexandros Karargyris, Hasan Kassem, Sarthak Pati, Micah Sheller, Christina Huang, Aaron Coley, Siddharth Ghanta, Alex Schneider, Conrad Sharp, Rachit Saluja, Florian Kofler, Philipp Lohmann, Phillipp Vollmuth, Louis Gagnon, Maruf Adewole, Hongwei Bran Li, Anahita Fathi Kazerooni, Nourel Hoda Tahon, Udunna Anazodo, Ahmed W. Moawad, Bjoern Menze, Marius George Linguraru, Mariam Aboian, Benedikt Wiestler, Ujjwal Baid, Gian-Marco Conte, Andreas M. T. Rauschecker, Ayman Nada, Aly H. Abayazeed, Raymond Huang, Maria Correia de Verdier, Jeffrey D. Rudie, Spyridon Bakas, Evan Calabrese

The 2024 Brain Tumor Segmentation Meningioma Radiotherapy (BraTS-MEN-RT)
challenge aims to advance automated segmentation algorithms using the largest
known multi-institutional dataset of radiotherapy planning brain MRIs with
expert-annotated target labels for patients with intact or post-operative
meningioma that underwent either conventional external beam radiotherapy or
stereotactic radiosurgery. Each case includes a defaced 3D post-contrast
T1-weighted radiotherapy planning MRI in its native acquisition space,
accompanied by a single-label "target volume" representing the gross tumor
volume (GTV) and any at-risk post-operative site. Target volume annotations
adhere to established radiotherapy planning protocols, ensuring consistency
across cases and institutions. For pre-operative meningiomas, the target volume
encompasses the entire GTV and associated nodular dural tail, while for
post-operative cases, it includes at-risk resection cavity margins as
determined by the treating institution. Case annotations were reviewed and
approved by expert neuroradiologists and radiation oncologists. Participating
teams will develop, containerize, and evaluate automated segmentation models
using this comprehensive dataset. Model performance will be assessed using the
lesion-wise Dice Similarity Coefficient and the 95% Hausdorff distance. The
top-performing teams will be recognized at the Medical Image Computing and
Computer Assisted Intervention Conference in October 2024. BraTS-MEN-RT is
expected to significantly advance automated radiotherapy planning by enabling
precise tumor segmentation and facilitating tailored treatment, ultimately
improving patient outcomes.

ÊëòË¶ÅÔºö2024 Âπ¥ËÖ¶Áò§ÂàÜÂâ≤ËÖ¶ËÜúÁò§ÊîæÂ∞ÑÊ≤ªÁôÇ (BraTS-MEN-RT) ÊåëÊà∞Êó®Âú®‰ΩøÁî®Â∑≤Áü•ÊúÄÂ§ßÁöÑÊîæÂ∞ÑÊ≤ªÁôÇË¶èÂäÉËÖ¶ÈÉ® MRI Â§öÊ©üÊßãË≥áÊñôÈõÜÔºå‰æÜÊé®ÈÄ≤Ëá™ÂãïÂàÜÂâ≤ÊºîÁÆóÊ≥ïÔºåÂÖ∂‰∏≠ÂåÖÂê´Êé•ÂèóÂÇ≥Áµ±È´îÂ§ñÊîæÂ∞ÑÊ≤ªÁôÇÊàñÁ´ãÈ´îÂÆöÂêëÊîæÂ∞ÑÂ§ñÁßëÊâãË°ìÁöÑÂÆåÊï¥ÊàñË°ìÂæåËÖ¶ËÜúÁò§ÊÇ£ËÄÖÁöÑÂ∞àÂÆ∂Ê®ôË®ªÁõÆÊ®ôÊ®ôÁ±§„ÄÇÊØèÂÄãÊ°à‰æãÈÉΩÂåÖÂê´‰∏ÄÂÄãÂéªË≠òÂà•ÂåñÁöÑ 3D Â∞çÊØîÂæå T1 Âä†Ê¨äÊîæÂ∞ÑÊ≤ªÁôÇË¶èÂäÉ MRIÔºåÂú®ÂéüÁîüÊì∑ÂèñÁ©∫Èñì‰∏≠Ôºå‰∏¶ÈôÑÊúâ‰∏ÄÂÄã‰ª£Ë°®Á∏ΩËÖ´Áò§È´îÁ©ç (GTV) Âíå‰ªª‰ΩïÊúâÈ¢®Èö™ÁöÑË°ìÂæåÈÉ®‰ΩçÁöÑÂñÆÊ®ôÁ±§„ÄåÁõÆÊ®ôÈ´îÁ©ç„Äç„ÄÇÁõÆÊ®ôÈ´îÁ©çË®ªËß£ÈÅµÂæ™Êó¢ÂÆöÁöÑÊîæÂ∞ÑÊ≤ªÁôÇË¶èÂäÉÂçîË≠∞ÔºåÁ¢∫‰øùÂêÑÂÄãÊ°à‰æãÂíåÊ©üÊßã‰πãÈñìÁöÑ‰∏ÄËá¥ÊÄß„ÄÇÂ∞çÊñºË°ìÂâçËÖ¶ËÜúÁò§ÔºåÁõÆÊ®ôÈ´îÁ©çÂåÖÂê´Êï¥ÂÄã GTV ÂíåÁõ∏ÈóúÁµêÁØÄÊÄßÁ°¨ËÖ¶ËÜúÂ∞æÔºåËÄåÂ∞çÊñºË°ìÂæåÁóÖ‰æãÔºåÂâáÂåÖÊã¨Áî±Ê≤ªÁôÇÊ©üÊßãÁ¢∫ÂÆöÁöÑÊúâÈ¢®Èö™ÁöÑÂàáÈô§ËÖîÈöôÈÇäÁ∑£„ÄÇÊ°à‰æãË®ªËß£Â∑≤Áî±Â∞àÂÆ∂Á•ûÁ∂ìÊîæÂ∞ÑÁßëÈÜ´Â∏´ÂíåÊîæÂ∞ÑËÖ´Áò§ÁßëÈÜ´Â∏´ÂØ©Êü•‰∏¶Ê†∏ÂáÜ„ÄÇÂèÉËàáÂúòÈöäÂ∞á‰ΩøÁî®ÈÄôÂÄãÂÖ®Èù¢ÁöÑË≥áÊñôÈõÜ‰æÜÈñãÁôº„ÄÅÂ∞ÅË£ùÂíåË©ï‰º∞Ëá™ÂãïÂàÜÂâ≤Ê®°Âûã„ÄÇÊ®°ÂûãÊïàËÉΩÂ∞á‰ΩøÁî®ÁóÖÁÅ∂ÊòéÊô∫ÁöÑ Dice Áõ∏‰ººÊÄß‰øÇÊï∏Âíå 95% Hausdorff Ë∑ùÈõ¢ÈÄ≤Ë°åË©ï‰º∞„ÄÇË°®ÁèæÊúÄ‰Ω≥ÁöÑÂúòÈöäÂ∞áÂú® 2024 Âπ¥ 10 ÊúàÁöÑÈÜ´Â≠∏ÂΩ±ÂÉèÈÅãÁÆóÂíåÈõªËÖ¶ËºîÂä©‰ªãÂÖ•ÊúÉË≠∞‰∏äÁç≤ÂæóËÇØÂÆö„ÄÇÈ†êË®à BraTS-MEN-RT Â∞áÈÄèÈÅéÂØ¶ÁèæÁ≤æÁ¢∫ÁöÑËÖ´Áò§ÂàÜÂâ≤Âíå‰øÉÈÄ≤ÂÆ¢Ë£ΩÂåñÊ≤ªÁôÇ‰æÜÂ§ßÂπÖÊé®ÈÄ≤Ëá™ÂãïÊîæÂ∞ÑÊ≤ªÁôÇË¶èÂäÉÔºåÊúÄÁµÇÊîπÂñÑÊÇ£ËÄÖÁöÑÊ≤ªÁôÇÁµêÊûú„ÄÇ

##### **Intelligent Clinical Documentation: Harnessing Generative AI for Patient-Centric Clinical Note Generation**
2405.18346v1 by Anjanava Biswas, Wrick Talukdar

Comprehensive clinical documentation is crucial for effective healthcare
delivery, yet it poses a significant burden on healthcare professionals,
leading to burnout, increased medical errors, and compromised patient safety.
This paper explores the potential of generative AI (Artificial Intelligence) to
streamline the clinical documentation process, specifically focusing on
generating SOAP (Subjective, Objective, Assessment, Plan) and BIRP (Behavior,
Intervention, Response, Plan) notes. We present a case study demonstrating the
application of natural language processing (NLP) and automatic speech
recognition (ASR) technologies to transcribe patient-clinician interactions,
coupled with advanced prompting techniques to generate draft clinical notes
using large language models (LLMs). The study highlights the benefits of this
approach, including time savings, improved documentation quality, and enhanced
patient-centered care. Additionally, we discuss ethical considerations, such as
maintaining patient confidentiality and addressing model biases, underscoring
the need for responsible deployment of generative AI in healthcare settings.
The findings suggest that generative AI has the potential to revolutionize
clinical documentation practices, alleviating administrative burdens and
enabling healthcare professionals to focus more on direct patient care.

ÊëòË¶ÅÔºöÂÖ®Èù¢ÁöÑËá®Â∫äÊñá‰ª∂Â∞çÊñºÊúâÊïàÁöÑÈÜ´ÁôÇ‰øùÂÅ•ÊúçÂãôËá≥ÈóúÈáçË¶ÅÔºå‰ΩÜÂÆÉÂ∞çÈÜ´ÁôÇ‰øùÂÅ•Â∞àÊ•≠‰∫∫Âì°ÈÄ†Êàê‰∫ÜÈáçÂ§ßË≤†ÊìîÔºåÂ∞éËá¥ÂÄ¶ÊÄ†„ÄÅÈÜ´ÁôÇÈåØË™§Â¢ûÂä†‰ª•ÂèäÊÇ£ËÄÖÂÆâÂÖ®ÂèóÂà∞ÂΩ±Èüø„ÄÇÊú¨ÊñáÊé¢Ë®é‰∫ÜÁîüÊàêÂºè AIÔºà‰∫∫Â∑•Êô∫ÊÖßÔºâÁ∞°ÂåñËá®Â∫äÊñá‰ª∂ÊµÅÁ®ãÁöÑÂèØËÉΩÊÄßÔºåÁâπÂà•Â∞àÊ≥®ÊñºÁîüÊàê SOAPÔºà‰∏ªËßÄ„ÄÅÂÆ¢ËßÄ„ÄÅË©ï‰º∞„ÄÅË®àÁï´ÔºâÂíå BIRPÔºàË°åÁÇ∫„ÄÅ‰ªãÂÖ•„ÄÅÂèçÊáâ„ÄÅË®àÁï´ÔºâË®òÈåÑ„ÄÇÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊ°à‰æãÁ†îÁ©∂ÔºåÂ±ïÁ§∫‰∫ÜËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜÔºàNLPÔºâÂíåËá™ÂãïË™ûÈü≥Ëæ®Ë≠òÔºàASRÔºâÊäÄË°ìÂú®ËΩâÈåÑÊÇ£ËÄÖËàáËá®Â∫äÈÜ´Â∏´‰∫íÂãïÊñπÈù¢ÁöÑÊáâÁî®Ôºå‰ª•ÂèäÁµêÂêàÂÖàÈÄ≤ÁöÑÊèêÁ§∫ÊäÄË°ìÔºå‰ΩøÁî®Â§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâÁîüÊàêËá®Â∫äË®òÈåÑËçâÁ®ø„ÄÇÈÄôÈ†ÖÁ†îÁ©∂Âº∑Ë™ø‰∫ÜÈÄôÁ®ÆÊñπÊ≥ïÁöÑÂ•ΩËôïÔºåÂåÖÊã¨ÁØÄÁúÅÊôÇÈñì„ÄÅÊîπÂñÑÊñá‰ª∂ÂìÅË≥™Ôºå‰ª•ÂèäÂ¢ûÂº∑‰ª•ÊÇ£ËÄÖÁÇ∫‰∏≠ÂøÉÁöÑÁÖßË≠∑„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëË®éË´ñ‰∫ÜÈÅìÂæ∑ËÄÉÈáèÔºå‰æãÂ¶ÇÁ∂≠Ë≠∑ÊÇ£ËÄÖÊ©üÂØÜÊÄßÂíåËß£Ê±∫Ê®°ÂûãÂÅèÂ∑ÆÔºåÂº∑Ë™øÂú®ÈÜ´ÁôÇ‰øùÂÅ•Áí∞Â¢É‰∏≠Ë≤†Ë≤¨‰ªªÂú∞ÈÉ®ÁΩ≤ÁîüÊàêÂºè AI ÁöÑÂøÖË¶ÅÊÄß„ÄÇÁ†îÁ©∂ÁµêÊûúË°®ÊòéÔºåÁîüÊàêÂºè AI ÊúâÂèØËÉΩÂæπÂ∫ïÊîπËÆäËá®Â∫äÊñá‰ª∂ÂØ¶ÂãôÔºåÊ∏õËºïË°åÊîøË≤†ÊìîÔºå‰∏¶‰ΩøÈÜ´ÁôÇ‰øùÂÅ•Â∞àÊ•≠‰∫∫Âì°ËÉΩÂ§†Êõ¥Â§öÂú∞Â∞àÊ≥®ÊñºÁõ¥Êé•ÁöÑÊÇ£ËÄÖÁÖßË≠∑„ÄÇ

##### **Histopathology Based AI Model Predicts Anti-Angiogenic Therapy Response in Renal Cancer Clinical Trial**
2405.18327v1 by Jay Jasti, Hua Zhong, Vandana Panwar, Vipul Jarmale, Jeffrey Miyata, Deyssy Carrillo, Alana Christie, Dinesh Rakheja, Zora Modrusan, Edward Ernest Kadel III, Niha Beig, Mahrukh Huseni, James Brugarolas, Payal Kapur, Satwik Rajaram

Predictive biomarkers of treatment response are lacking for metastatic clear
cell renal cell carcinoma (ccRCC), a tumor type that is treated with
angiogenesis inhibitors, immune checkpoint inhibitors, mTOR inhibitors and a
HIF2 inhibitor. The Angioscore, an RNA-based quantification of angiogenesis, is
arguably the best candidate to predict anti-angiogenic (AA) response. However,
the clinical adoption of transcriptomic assays faces several challenges
including standardization, time delay, and high cost. Further, ccRCC tumors are
highly heterogenous, and sampling multiple areas for sequencing is impractical.
Here we present a novel deep learning (DL) approach to predict the Angioscore
from ubiquitous histopathology slides. To overcome the lack of
interpretability, one of the biggest limitations of typical DL models, our
model produces a visual vascular network which is the basis of the model's
prediction. To test its reliability, we applied this model to multiple cohorts
including a clinical trial dataset. Our model accurately predicts the RNA-based
Angioscore on multiple independent cohorts (spearman correlations of 0.77 and
0.73). Further, the predictions help unravel meaningful biology such as
association of angiogenesis with grade, stage, and driver mutation status.
Finally, we find our model can predict response to AA therapy, in both a
real-world cohort and the IMmotion150 clinical trial. The predictive power of
our model vastly exceeds that of CD31, a marker of vasculature, and nearly
rivals the performance (c-index 0.66 vs 0.67) of the ground truth RNA-based
Angioscore at a fraction of the cost. By providing a robust yet interpretable
prediction of the Angioscore from histopathology slides alone, our approach
offers insights into angiogenesis biology and AA treatment response.

ÊëòË¶ÅÔºö<paragraph>Â∞çÊñºËΩâÁßªÊÄßÈÄèÊòéÁ¥∞ËÉûËÖéÁ¥∞ËÉûÁôå (ccRCC)Ôºå‰∏ÄÁ®ÆÁî®ÊñºÊ≤ªÁôÇË°ÄÁÆ°ÁîüÊàêÊäëÂà∂Âäë„ÄÅÂÖçÁñ´Ê™¢Êü•ÈªûÊäëÂà∂Âäë„ÄÅmTOR ÊäëÂà∂ÂäëÂíå HIF2 ÊäëÂà∂ÂäëÁöÑËÖ´Áò§È°ûÂûãÔºåÁõÆÂâçÁº∫‰πèÊ≤ªÁôÇÂèçÊáâÁöÑÈ†êÊ∏¨ÊÄßÁîüÁâ©Ê®ôË®ò„ÄÇAngioscore ÊòØ‰∏ÄÁ®ÆÂü∫Êñº RNA ÁöÑË°ÄÁÆ°ÁîüÊàêÈáèÂåñÔºåÂèØ‰ª•Ë™™ÊòØÈ†êÊ∏¨ÊäóË°ÄÁÆ°ÁîüÊàê (AA) ÂèçÊáâÁöÑÊúÄ‰Ω≥ÂÄôÈÅ∏ËÄÖ„ÄÇÁÑ∂ËÄåÔºåËΩâÈåÑÁµÑÊ™¢Ê∏¨ÁöÑËá®Â∫äÊáâÁî®Èù¢Ëá®ËëóÊ®ôÊ∫ñÂåñ„ÄÅÊôÇÈñìÂª∂ÈÅ≤ÂíåÈ´òÊàêÊú¨Á≠âÂ§öÈ†ÖÊåëÊà∞„ÄÇÊ≠§Â§ñÔºåccRCC ËÖ´Áò§È´òÂ∫¶Áï∞Ë≥™ÔºåÂ∞çÂ§öÂÄãÂçÄÂüüÈÄ≤Ë°åÂèñÊ®£‰ª•ÈÄ≤Ë°åÊ∏¨Â∫è‰∏¶‰∏çÂàáÂØ¶Èöõ„ÄÇÂú®Ê≠§ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÊ∑±Â∫¶Â≠∏Áøí (DL) ÊñπÊ≥ïÔºåÂèØÂæûÊôÆÈÅçÂ≠òÂú®ÁöÑÁµÑÁπîÁóÖÁêÜÂàáÁâá‰∏≠È†êÊ∏¨ Angioscore„ÄÇÁÇ∫‰∫ÜÂÖãÊúçÂèØËß£ÈáãÊÄßÁöÑÁº∫‰πèÔºåÈÄôÊòØÂÖ∏Âûã DL Ê®°ÂûãÊúÄÂ§ßÁöÑÈôêÂà∂‰πã‰∏ÄÔºåÊàëÂÄëÁöÑÊ®°ÂûãÁî¢Áîü‰∫Ü‰∏ÄÂÄãË¶ñË¶∫Ë°ÄÁÆ°Á∂≤Ë∑ØÔºåÈÄôÊòØÊ®°ÂûãÈ†êÊ∏¨ÁöÑÂü∫Á§é„ÄÇÁÇ∫‰∫ÜÊ∏¨Ë©¶ÂÖ∂ÂèØÈù†ÊÄßÔºåÊàëÂÄëÂ∞áÊ≠§Ê®°ÂûãÊáâÁî®ÊñºÂ§öÂÄãÁæ§ÁµÑÔºåÂåÖÊã¨Ëá®Â∫äË©¶È©óË≥áÊñôÈõÜ„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÊ∫ñÁ¢∫È†êÊ∏¨‰∫ÜÂ§öÂÄãÁç®Á´ãÁæ§ÁµÑÁöÑÂü∫Êñº RNA ÁöÑ AngioscoreÔºàspearman Áõ∏Èóú‰øÇÊï∏ÁÇ∫ 0.77 Âíå 0.73Ôºâ„ÄÇÊ≠§Â§ñÔºåÈÄô‰∫õÈ†êÊ∏¨ÊúâÂä©ÊñºËß£ÈñãÊúâÊÑèÁæ©ÁöÑÁîüÁâ©Â≠∏Ôºå‰æãÂ¶ÇË°ÄÁÆ°ÁîüÊàêËàáÁ≠âÁ¥ö„ÄÅÈöéÊÆµÂíåÈ©ÖÂãïÁ™ÅËÆäÁãÄÊÖãÁöÑÈóúËÅØ„ÄÇÊúÄÂæåÔºåÊàëÂÄëÁôºÁèæÊàëÂÄëÁöÑÊ®°ÂûãÂèØ‰ª•È†êÊ∏¨Â∞ç AA Ê≤ªÁôÇÁöÑÂèçÊáâÔºåÁÑ°Ë´ñÊòØÂú®ÁèæÂØ¶‰∏ñÁïåÁæ§ÁµÑÈÇÑÊòØ IMmotion150 Ëá®Â∫äË©¶È©ó‰∏≠„ÄÇÊàëÂÄëÊ®°ÂûãÁöÑÈ†êÊ∏¨ËÉΩÂäõÈÅ†ÈÅ†Ë∂ÖÈÅéË°ÄÁÆ°Ê®ôË®ò CD31Ôºå‰∏¶‰∏îÂπæ‰πéËàáÂü∫Êñº RNA ÁöÑÁúüÂØ¶ Angioscore ÁöÑÊïàËÉΩÔºàc ÊåáÊï∏ 0.66 Â∞ç 0.67ÔºâÁõ∏Áï∂ÔºåËÄåÊàêÊú¨ÂçªÂè™ÊòØÂæåËÄÖÁöÑÈõ∂È†≠„ÄÇÈÄöÈÅéÂÉÖÂæûÁµÑÁπîÁóÖÁêÜÂàáÁâá‰∏≠Êèê‰æõÂ∞ç Angioscore ÁöÑÂº∑Â§ß‰∏îÂèØËß£ÈáãÁöÑÈ†êÊ∏¨ÔºåÊàëÂÄëÁöÑÊñπÊ≥ïÊèê‰æõ‰∫ÜÂ∞çË°ÄÁÆ°ÁîüÊàêÁîüÁâ©Â≠∏Âíå AA Ê≤ªÁôÇÂèçÊáâÁöÑË¶ãËß£„ÄÇ</paragraph>

##### **Edinburgh Clinical NLP at MEDIQA-CORR 2024: Guiding Large Language Models with Hints**
2405.18028v1 by Aryo Pradipta Gema, Chaeeun Lee, Pasquale Minervini, Luke Daines, T. Ian Simpson, Beatrice Alex

The MEDIQA-CORR 2024 shared task aims to assess the ability of Large Language
Models (LLMs) to identify and correct medical errors in clinical notes. In this
study, we evaluate the capability of general LLMs, specifically GPT-3.5 and
GPT-4, to identify and correct medical errors with multiple prompting
strategies. Recognising the limitation of LLMs in generating accurate
corrections only via prompting strategies, we propose incorporating error-span
predictions from a smaller, fine-tuned model in two ways: 1) by presenting it
as a hint in the prompt and 2) by framing it as multiple-choice questions from
which the LLM can choose the best correction. We found that our proposed
prompting strategies significantly improve the LLM's ability to generate
corrections. Our best-performing solution with 8-shot + CoT + hints ranked
sixth in the shared task leaderboard. Additionally, our comprehensive analyses
show the impact of the location of the error sentence, the prompted role, and
the position of the multiple-choice option on the accuracy of the LLM. This
prompts further questions about the readiness of LLM to be implemented in
real-world clinical settings.

ÊëòË¶ÅÔºöMEDIQA-CORR 2024 ÂÖ±‰∫´‰ªªÂãôÊó®Âú®Ë©ï‰º∞Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®Ëá®Â∫äÁ≠ÜË®ò‰∏≠Ë≠òÂà•ÂíåÊõ¥Ê≠£ÈÜ´ÁôÇÈåØË™§ÁöÑËÉΩÂäõ„ÄÇÂú®Ê≠§Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëË©ï‰º∞ÈÄöÁî® LLMÔºåÁâπÂà•ÊòØ GPT-3.5 Âíå GPT-4ÔºåË≠òÂà•ÂíåÊõ¥Ê≠£ÈÜ´ÁôÇÈåØË™§ÁöÑËÉΩÂäõÔºå‰∏¶Êé°Áî®Â§öÁ®ÆÊèêÁ§∫Á≠ñÁï•„ÄÇË™çË≠òÂà∞ LLM ÂÉÖÈÄöÈÅéÊèêÁ§∫Á≠ñÁï•ÁîüÊàêÊ∫ñÁ¢∫Êõ¥Ê≠£ÁöÑÈôêÂà∂ÔºåÊàëÂÄëÂª∫Ë≠∞‰ª•ÂÖ©Á®ÆÊñπÂºèÊï¥Âêà‰æÜËá™ËºÉÂ∞èÁöÑÂæÆË™øÊ®°ÂûãÁöÑÈåØË™§ÁØÑÂúçÈ†êÊ∏¨Ôºö1) Âú®ÊèêÁ§∫‰∏≠Â∞áÂÖ∂Ë°®Á§∫ÁÇ∫ÊèêÁ§∫Ôºå‰ª•Âèä 2) Â∞áÂÖ∂Ë®≠ÂÆöÁÇ∫Â§öÈÅ∏È°åÔºåLLM ÂèØ‰ª•Âæû‰∏≠ÈÅ∏ÊìáÊúÄ‰Ω≥Êõ¥Ê≠£„ÄÇÊàëÂÄëÁôºÁèæÊàëÂÄëÊèêÂá∫ÁöÑÊèêÁ§∫Á≠ñÁï•È°ØËëóÊèêÈ´ò‰∫Ü LLM ÁîüÊàêÊõ¥Ê≠£ÁöÑËÉΩÂäõ„ÄÇÊàëÂÄëÂú®ÂÖ±‰∫´‰ªªÂãôÊéíË°åÊ¶ú‰∏≠ÊéíÂêçÁ¨¨ÂÖ≠ÁöÑÊúÄ‰Ω≥Âü∑Ë°åÊñπÊ°àÊòØ 8 Ê¨°ÂòóË©¶ + CoT + ÊèêÁ§∫„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂÖ®Èù¢ÁöÑÂàÜÊûêÈ°ØÁ§∫‰∫ÜÈåØË™§Âè•Â≠ê‰ΩçÁΩÆ„ÄÅÊèêÁ§∫ËßíËâ≤ÂíåÂ§öÈÅ∏È†Ö‰ΩçÁΩÆÂ∞ç LLM Ê∫ñÁ¢∫ÊÄßÁöÑÂΩ±Èüø„ÄÇÈÄôÂºïÁôº‰∫ÜÈÄ≤‰∏ÄÊ≠•ÁöÑÂïèÈ°åÔºåÂç≥ LLM ÊòØÂê¶Â∑≤Ê∫ñÂÇôÂ•ΩÂØ¶ÊñΩÂú®ÁèæÂØ¶‰∏ñÁïåÁöÑËá®Â∫äÁí∞Â¢É‰∏≠„ÄÇ

##### **Towards Clinical AI Fairness: Filling Gaps in the Puzzle**
2405.17921v1 by Mingxuan Liu, Yilin Ning, Salinelat Teixayavong, Xiaoxuan Liu, Mayli Mertens, Yuqing Shang, Xin Li, Di Miao, Jie Xu, Daniel Shu Wei Ting, Lionel Tim-Ee Cheng, Jasmine Chiat Ling Ong, Zhen Ling Teo, Ting Fang Tan, Narrendar RaviChandran, Fei Wang, Leo Anthony Celi, Marcus Eng Hock Ong, Nan Liu

The ethical integration of Artificial Intelligence (AI) in healthcare
necessitates addressing fairness-a concept that is highly context-specific
across medical fields. Extensive studies have been conducted to expand the
technical components of AI fairness, while tremendous calls for AI fairness
have been raised from healthcare. Despite this, a significant disconnect
persists between technical advancements and their practical clinical
applications, resulting in a lack of contextualized discussion of AI fairness
in clinical settings. Through a detailed evidence gap analysis, our review
systematically pinpoints several deficiencies concerning both healthcare data
and the provided AI fairness solutions. We highlight the scarcity of research
on AI fairness in many medical domains where AI technology is increasingly
utilized. Additionally, our analysis highlights a substantial reliance on group
fairness, aiming to ensure equality among demographic groups from a macro
healthcare system perspective; in contrast, individual fairness, focusing on
equity at a more granular level, is frequently overlooked. To bridge these
gaps, our review advances actionable strategies for both the healthcare and AI
research communities. Beyond applying existing AI fairness methods in
healthcare, we further emphasize the importance of involving healthcare
professionals to refine AI fairness concepts and methods to ensure contextually
relevant and ethically sound AI applications in healthcare.

ÊëòË¶ÅÔºö‰∫∫Â∑•Êô∫ÊÖß (AI) Âú®ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÁöÑÂÄ´ÁêÜÊï¥ÂêàÈúÄË¶ÅËôïÁêÜÂÖ¨Âπ≥ÊÄß‚Äî‚ÄîÈÄôÂÄãÊ¶ÇÂøµÂú®ÂêÑÂÄãÈÜ´ÁôÇÈ†òÂüü‰∏≠È´òÂ∫¶ÁâπÂÆöÊñºÊÉÖÂ¢É„ÄÇÂ∑≤Á∂ìÈÄ≤Ë°å‰∫ÜÂª£Ê≥õÁöÑÁ†îÁ©∂‰æÜÊì¥Â±ï AI ÂÖ¨Âπ≥ÊÄßÁöÑÊäÄË°ìÁµÑÊàêÔºåËÄå‰æÜËá™ÈÜ´ÁôÇ‰øùÂÅ•ÁöÑ AI ÂÖ¨Âπ≥ÊÄßÂëºËÅ≤‰πüÂæàÂ§ß„ÄÇÂÑòÁÆ°Â¶ÇÊ≠§ÔºåÊäÄË°ìÈÄ≤Ê≠•ËàáÂÖ∂ÂØ¶ÈöõËá®Â∫äÊáâÁî®‰πãÈñì‰ªçÁÑ∂Â≠òÂú®È°ØËëóÁöÑËÑ´ÁØÄÔºåÂ∞éËá¥Âú®Ëá®Â∫äÁí∞Â¢É‰∏≠Áº∫‰πèÂ∞ç AI ÂÖ¨Âπ≥ÊÄßÁöÑÊÉÖÂ¢ÉÂåñË®éË´ñ„ÄÇÈÄèÈÅéË©≥Á¥∞ÁöÑË≠âÊìöÂ∑ÆË∑ùÂàÜÊûêÔºåÊàëÂÄëÁöÑÂõûÈ°ßÁ≥ªÁµ±ÊÄßÂú∞ÊâæÂá∫‰∫ÜËàáÈÜ´ÁôÇ‰øùÂÅ•Ë≥áÊñôÂíåÊèê‰æõÁöÑ AI ÂÖ¨Âπ≥ÊÄßËß£Ê±∫ÊñπÊ°àÁõ∏ÈóúÁöÑÂπæÂÄãÁº∫Èô∑„ÄÇÊàëÂÄëÂº∑Ë™øÂú®Ë®±Â§öÈÜ´ÁôÇÈ†òÂüü‰∏≠Áº∫‰πèÂ∞ç AI ÂÖ¨Âπ≥ÊÄßÁöÑÁ†îÁ©∂ÔºåËÄåÈÄô‰∫õÈ†òÂüü‰∏≠ AI ÊäÄË°ìÁöÑ‰ΩøÁî®Ë∂ä‰æÜË∂äÂ§ö„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁöÑÂàÜÊûêÂº∑Ë™ø‰∫ÜÂ∞çÁæ§È´îÂÖ¨Âπ≥ÊÄßÁöÑÂØ¶Ë≥™‰æùË≥¥ÔºåÊó®Âú®ÂæûÂ∑®ËßÄÈÜ´ÁôÇ‰øùÂÅ•Á≥ªÁµ±ÁöÑËßíÂ∫¶Á¢∫‰øù‰∫∫Âè£Áæ§È´î‰πãÈñìÁöÑÂπ≥Á≠âÔºõÁõ∏ÊØî‰πã‰∏ãÔºåÈóúÊ≥®Êõ¥Á¥∞Á∑ªÂ±§Á¥öÂÖ¨Âπ≥ÊÄßÁöÑÂÄãÂà•ÂÖ¨Âπ≥ÊÄßÂ∏∏Â∏∏Ë¢´ÂøΩË¶ñ„ÄÇÁÇ∫‰∫ÜÂΩåË£úÈÄô‰∫õÂ∑ÆË∑ùÔºåÊàëÂÄëÁöÑÂõûÈ°ßÊèêÂá∫‰∫ÜÈáùÂ∞çÈÜ´ÁôÇ‰øùÂÅ•Âíå AI Á†îÁ©∂Á§æÁæ§ÁöÑÂèØË°åÁ≠ñÁï•„ÄÇÈô§‰∫ÜÂú®ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÊáâÁî®ÁèæÊúâÁöÑ AI ÂÖ¨Âπ≥ÊÄßÊñπÊ≥ï‰πãÂ§ñÔºåÊàëÂÄëÈÄ≤‰∏ÄÊ≠•Âº∑Ë™ø‰∫ÜËÆìÈÜ´ÁôÇ‰øùÂÅ•Â∞àÊ•≠‰∫∫Âì°ÂèÉËàáÁöÑÈáçË¶ÅÊÄßÔºå‰ª•ÂÆåÂñÑ AI ÂÖ¨Âπ≥ÊÄßÊ¶ÇÂøµÂíåÊñπÊ≥ïÔºå‰ª•Á¢∫‰øùÂú®ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÂÖ∑ÊúâÊÉÖÂ¢ÉÁõ∏ÈóúÊÄßÂíåÁ¨¶ÂêàÂÄ´ÁêÜÁöÑ AI ÊáâÁî®„ÄÇ

##### **Near-Infrared and Low-Rank Adaptation of Vision Transformers in Remote Sensing**
2405.17901v1 by Irem Ulku, O. Ozgur Tanriover, Erdem Akag√ºnd√ºz

Plant health can be monitored dynamically using multispectral sensors that
measure Near-Infrared reflectance (NIR). Despite this potential, obtaining and
annotating high-resolution NIR images poses a significant challenge for
training deep neural networks. Typically, large networks pre-trained on the RGB
domain are utilized to fine-tune infrared images. This practice introduces a
domain shift issue because of the differing visual traits between RGB and NIR
images.As an alternative to fine-tuning, a method called low-rank adaptation
(LoRA) enables more efficient training by optimizing rank-decomposition
matrices while keeping the original network weights frozen. However, existing
parameter-efficient adaptation strategies for remote sensing images focus on
RGB images and overlook domain shift issues in the NIR domain. Therefore, this
study investigates the potential benefits of using vision transformer (ViT)
backbones pre-trained in the RGB domain, with low-rank adaptation for
downstream tasks in the NIR domain. Extensive experiments demonstrate that
employing LoRA with pre-trained ViT backbones yields the best performance for
downstream tasks applied to NIR images.

ÊëòË¶ÅÔºöÂà©Áî®ÊµãÈáèËøëÁ∫¢Â§ñÂèçÂ∞Ñ (NIR) ÁöÑÂ§öÂÖâË∞±‰º†ÊÑüÂô®ÔºåÂèØ‰ª•Âä®ÊÄÅÁõëÊµãÊ§çÁâ©ÂÅ•Â∫∑„ÄÇÂ∞ΩÁÆ°ÊúâÊ≠§ÊΩúÂäõÔºå‰ΩÜËé∑ÂèñÂíåÊ≥®ÈáäÈ´òÂàÜËæ®Áéá NIR ÂõæÂÉèÂØπËÆ≠ÁªÉÊ∑±Â∫¶Á•ûÁªèÁΩëÁªúÊûÑÊàê‰∫ÜÈáçÂ§ßÊåëÊàò„ÄÇÈÄöÂ∏∏ÔºåÂà©Áî®È¢ÑÂÖàÂú® RGB Âüü‰∏äËÆ≠ÁªÉÁöÑÂ§ßÂûãÁΩëÁªúÊù•ÂæÆË∞ÉÁ∫¢Â§ñÂõæÂÉè„ÄÇÁî±‰∫é RGB Âíå NIR ÂõæÂÉè‰πãÈó¥ÁöÑËßÜËßâÁâπÂæÅ‰∏çÂêåÔºåËøôÁßçÂÅöÊ≥ïÂºïÂÖ•‰∫ÜÂüüÂÅèÁßªÈóÆÈ¢ò„ÄÇ‰Ωú‰∏∫ÂæÆË∞ÉÁöÑÊõø‰ª£ÊñπÊ°àÔºå‰∏ÄÁßçÁß∞‰∏∫‰ΩéÁß©ÈÄÇÂ∫î (LoRA) ÁöÑÊñπÊ≥ïÈÄöËøá‰ºòÂåñÁß©ÂàÜËß£Áü©ÈòµÂêåÊó∂‰øùÊåÅÂéüÂßãÁΩëÁªúÊùÉÈáçÂÜªÁªìÔºå‰ªéËÄåÂÆûÁé∞Êõ¥ÊúâÊïàÁöÑËÆ≠ÁªÉ„ÄÇÁÑ∂ËÄåÔºåÁé∞ÊúâÁöÑÁî®‰∫éÈÅ•ÊÑüÂõæÂÉèÁöÑÂèÇÊï∞È´òÊïàÈÄÇÂ∫îÁ≠ñÁï•‰∏ìÊ≥®‰∫é RGB ÂõæÂÉèÔºåËÄåÂøΩÁï•‰∫Ü NIR Âüü‰∏≠ÁöÑÂüüÂÅèÁßªÈóÆÈ¢ò„ÄÇÂõ†Ê≠§ÔºåÊú¨Á†îÁ©∂Ë∞ÉÊü•‰∫ÜÂú® RGB Âüü‰∏≠È¢ÑÂÖàËÆ≠ÁªÉÁöÑËßÜËßâËΩ¨Êç¢Âô® (ViT) ‰∏ªÂπ≤‰ΩøÁî®‰ΩéÁß©ÈÄÇÂ∫îÂú® NIR ÂüüÁöÑ‰∏ãÊ∏∏‰ªªÂä°‰∏≠‰ΩøÁî®ËßÜËßâËΩ¨Êç¢Âô® (ViT) ‰∏ªÂπ≤ÁöÑÊΩúÂú®‰ºòÂäø„ÄÇÂ§ßÈáèÂÆûÈ™åË°®ÊòéÔºåÂ∞Ü LoRA ‰∏éÈ¢ÑÂÖàËÆ≠ÁªÉÁöÑ ViT ‰∏ªÂπ≤ÁªìÂêà‰ΩøÁî®ÔºåÂèØ‰∏∫Â∫îÁî®‰∫é NIR ÂõæÂÉèÁöÑ‰∏ãÊ∏∏‰ªªÂä°Â∏¶Êù•ÊúÄ‰Ω≥ÊÄßËÉΩ„ÄÇ

##### **AI Alignment with Changing and Influenceable Reward Functions**
2405.17713v1 by Micah Carroll, Davis Foote, Anand Siththaranjan, Stuart Russell, Anca Dragan

Existing AI alignment approaches assume that preferences are static, which is
unrealistic: our preferences change, and may even be influenced by our
interactions with AI systems themselves. To clarify the consequences of
incorrectly assuming static preferences, we introduce Dynamic Reward Markov
Decision Processes (DR-MDPs), which explicitly model preference changes and the
AI's influence on them. We show that despite its convenience, the
static-preference assumption may undermine the soundness of existing alignment
techniques, leading them to implicitly reward AI systems for influencing user
preferences in ways users may not truly want. We then explore potential
solutions. First, we offer a unifying perspective on how an agent's
optimization horizon may partially help reduce undesirable AI influence. Then,
we formalize different notions of AI alignment that account for preference
change from the outset. Comparing the strengths and limitations of 8 such
notions of alignment, we find that they all either err towards causing
undesirable AI influence, or are overly risk-averse, suggesting that a
straightforward solution to the problems of changing preferences may not exist.
As there is no avoiding grappling with changing preferences in real-world
settings, this makes it all the more important to handle these issues with
care, balancing risks and capabilities. We hope our work can provide conceptual
clarity and constitute a first step towards AI alignment practices which
explicitly account for (and contend with) the changing and influenceable nature
of human preferences.

ÊëòË¶ÅÔºöÁèæÊúâÁöÑ AI Â∞çÈΩäÊñπÊ≥ïÂÅáË®≠ÂÅèÂ•ΩÊòØÈùúÊÖãÁöÑÔºåÈÄôÊòØ‰∏çÂàáÂØ¶ÈöõÁöÑÔºöÊàëÂÄëÁöÑÂÅèÂ•ΩÊúÉÊîπËÆäÔºåÁîöËá≥ÂèØËÉΩÂèóÂà∞ÊàëÂÄëËàá AI Á≥ªÁµ±‰∫íÂãïÁöÑÂΩ±Èüø„ÄÇÁÇ∫‰∫ÜÈáêÊ∏ÖÈåØË™§ÂÅáË®≠ÈùúÊÖãÂÅèÂ•ΩÁöÑÂæåÊûúÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜÂãïÊÖãÁçéÂãµÈ¶¨ÂèØÂ§´Ê±∫Á≠ñÈÅéÁ®ã (DR-MDP)ÔºåÂÆÉÊòéÁ¢∫Âú∞Ê®°Êì¨‰∫ÜÂÅèÂ•ΩËÆäÂåñÂíå AI Â∞çÂÆÉÂÄëÁöÑÂΩ±Èüø„ÄÇÊàëÂÄëË°®ÊòéÔºåÂÑòÁÆ°ÂÖ∂‰æøÂà©ÊÄßÔºå‰ΩÜÈùúÊÖãÂÅèÂ•ΩÂÅáË®≠ÂèØËÉΩÊúÉÁ†¥Â£ûÁèæÊúâÂ∞çÈΩäÊäÄË°ìÁöÑÂÅ•ÂÖ®ÊÄßÔºåÂ∞éËá¥ÂÆÉÂÄëÈö±ÂºèÂú∞ÁçéÂãµ AI Á≥ªÁµ±‰ª•ÂΩ±ÈüøÁî®Êà∂ÂÅèÂ•ΩÁöÑÊñπÂºèÔºåËÄåÁî®Êà∂ÂèØËÉΩ‰∏¶ÈùûÁúüÊ≠£ÊÉ≥Ë¶Å„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÊé¢Ë®éÊΩõÂú®ÁöÑËß£Ê±∫ÊñπÊ°à„ÄÇÈ¶ñÂÖàÔºåÊàëÂÄëÊèê‰æõ‰∫Ü‰∏ÄÂÄãÁµ±‰∏ÄÁöÑËßÄÈªûÔºåË™™Êòé‰ª£ÁêÜÁöÑÊúÄ‰Ω≥ÂåñÁØÑÂúçÂ¶Ç‰ΩïÂú®‰∏ÄÂÆöÁ®ãÂ∫¶‰∏äÂπ´Âä©Ê∏õÂ∞ë‰∏çËâØÁöÑ AI ÂΩ±Èüø„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÂΩ¢ÂºèÂåñ‰∫Ü‰∏çÂêåÁöÑ AI Â∞çÈΩäÊ¶ÇÂøµÔºåÈÄô‰∫õÊ¶ÇÂøµÂæû‰∏ÄÈñãÂßãÂ∞±ËÄÉÊÖÆ‰∫ÜÂÅèÂ•ΩËÆäÂåñ„ÄÇÊØîËºÉÈÄô 8 ÂÄãÂ∞çÈΩäÊ¶ÇÂøµÁöÑÂÑ™Áº∫ÈªûÔºåÊàëÂÄëÁôºÁèæÂÆÉÂÄëË¶Å‰πàÊúÉÂ∞éËá¥‰∏çËâØÁöÑ AI ÂΩ±ÈüøÔºåË¶Å‰πàÈÅéÊñºËø¥ÈÅøÈ¢®Èö™ÔºåÈÄôË°®ÊòéÂèØËÉΩ‰∏çÂ≠òÂú®ÊîπËÆäÂÅèÂ•ΩÁöÑÂïèÈ°åÁöÑÁõ¥Êé•Ëß£Ê±∫ÊñπÊ°à„ÄÇÁî±ÊñºÂú®ÁèæÂØ¶Áí∞Â¢É‰∏≠ÁÑ°Ê≥ïÈÅøÂÖçÊáâÂ∞çÂÅèÂ•ΩÁöÑÊîπËÆäÔºåÈÄô‰ΩøÂæó‰ª•Ë¨πÊÖéÁöÑÊñπÂºèËôïÁêÜÈÄô‰∫õÂïèÈ°åËÆäÂæóÊõ¥Âä†ÈáçË¶ÅÔºåÊ¨äË°°È¢®Èö™ÂíåËÉΩÂäõ„ÄÇÊàëÂÄëÂ∏åÊúõÊàëÂÄëÁöÑÁ†îÁ©∂ÂèØ‰ª•Êèê‰æõÊ¶ÇÂøµ‰∏äÁöÑÊ∏ÖÊô∞Â∫¶Ôºå‰∏¶ÊßãÊàêÊúùËëó AI Â∞çÈΩäÂØ¶ÂãôÈÇÅÂá∫ÁöÑÁ¨¨‰∏ÄÊ≠•ÔºåÈÄô‰∫õÂØ¶ÂãôÊòéÁ¢∫ËÄÉÊÖÆÔºà‰∏¶ÊáâÂ∞çÔºâ‰∫∫È°ûÂÅèÂ•ΩÁöÑÂ§öËÆäÊÄßÂíåÂèØÂΩ±ÈüøÊÄß„ÄÇ

##### **The Economic Implications of Large Language Model Selection on Earnings and Return on Investment: A Decision Theoretic Model**
2405.17637v1 by Geraldo Xex√©o, Filipe Braida, Marcus Parreiras, Paulo Xavier

Selecting language models in business contexts requires a careful analysis of
the final financial benefits of the investment. However, the emphasis of
academia and industry analysis of LLM is solely on performance. This work
introduces a framework to evaluate LLMs, focusing on the earnings and return on
investment aspects that should be taken into account in business decision
making. We use a decision-theoretic approach to compare the financial impact of
different LLMs, considering variables such as the cost per token, the
probability of success in the specific task, and the gain and losses associated
with LLMs use. The study reveals how the superior accuracy of more expensive
models can, under certain conditions, justify a greater investment through more
significant earnings but not necessarily a larger RoI. This article provides a
framework for companies looking to optimize their technology choices, ensuring
that investment in cutting-edge technology aligns with strategic financial
objectives. In addition, we discuss how changes in operational variables
influence the economics of using LLMs, offering practical insights for
enterprise settings, finding that the predicted gain and loss and the different
probabilities of success and failure are the variables that most impact the
sensitivity of the models.

ÊëòË¶ÅÔºöÂú®ÂïÜÊ•≠ËÉåÊôØ‰∏ãÈÅ∏ÊìáË™ûË®ÄÊ®°ÂûãÈúÄË¶Å‰ªîÁ¥∞ÂàÜÊûêÊäïË≥áÁöÑÊúÄÁµÇË≤°ÂãôÊïàÁõä„ÄÇÁÑ∂ËÄåÔºåÂ≠∏Ë°ìÁïåÂíåÁî¢Ê•≠ÂàÜÊûê LLM ÁöÑÈáçÈªûÂÉÖÂú®ÊñºÊïàËÉΩ„ÄÇÊú¨Á†îÁ©∂ÂºïÂÖ•‰∫ÜË©ï‰º∞ LLM ÁöÑÊû∂ÊßãÔºåÈáçÈªûÂú®ÊñºÊáâÂú®ÂïÜÊ•≠Ê±∫Á≠ñ‰∏≠ËÄÉÈáèÁöÑÊî∂ÁõäÂíåÊäïË≥áÂ†±ÈÖ¨ÁéáÊñπÈù¢„ÄÇÊàëÂÄë‰ΩøÁî®Ê±∫Á≠ñÁêÜË´ñÊñπÊ≥ï‰æÜÊØîËºÉ‰∏çÂêå LLM ÁöÑË≤°ÂãôÂΩ±ÈüøÔºåËÄÉÈáèËÆäÊï∏Ôºå‰æãÂ¶ÇÊØèÂÄã‰ª£Âπ£ÁöÑÊàêÊú¨„ÄÅÂú®ÁâπÂÆö‰ªªÂãô‰∏≠ÊàêÂäüÁöÑÊ©üÁéáÔºå‰ª•ÂèäËàá‰ΩøÁî® LLM Áõ∏ÈóúÁöÑÊî∂ÁõäÂíåÊêçÂ§±„ÄÇÁ†îÁ©∂Êè≠Á§∫‰∫ÜÂú®ÁâπÂÆöÊ¢ù‰ª∂‰∏ãÔºåÊõ¥ÊòÇË≤¥ÁöÑÊ®°ÂûãÁöÑÂÑ™Ë∂äÊ∫ñÁ¢∫Â∫¶Â¶Ç‰ΩïËÉΩÈÄèÈÅéÊõ¥È°ØËëóÁöÑÊî∂ÁõäË≠âÊòéÊõ¥Â§ßÁöÑÊäïË≥áÔºå‰ΩÜ‰∏ç‰∏ÄÂÆöËÉΩË≠âÊòéÊõ¥Â§ßÁöÑÊäïË≥áÂ†±ÈÖ¨Áéá„ÄÇÊú¨ÊñáÊèê‰æõ‰∫Ü‰∏ÄÂÄãÊû∂ÊßãÔºå‰æõÂ∞ãÊ±ÇÊúÄ‰Ω≥ÂåñÂÖ∂ÊäÄË°ìÈÅ∏ÊìáÁöÑÂÖ¨Âè∏‰ΩøÁî®ÔºåÁ¢∫‰øùÂ∞çÂ∞ñÁ´ØÊäÄË°ìÁöÑÊäïË≥áËàáÁ≠ñÁï•ÊÄßË≤°ÂãôÁõÆÊ®ô‰∏ÄËá¥„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëË®éË´ñ‰∫ÜÁáüÈÅãËÆäÊï∏ÁöÑËÆäÂåñÂ¶Ç‰ΩïÂΩ±Èüø‰ΩøÁî® LLM ÁöÑÁ∂ìÊøüÊïàÁõäÔºåÊèê‰æõ‰ºÅÊ•≠Áí∞Â¢ÉÁöÑÂØ¶Áî®Ë¶ãËß£ÔºåÁôºÁèæÈ†êÊ∏¨ÁöÑÊî∂ÁõäÂíåÊêçÂ§±‰ª•ÂèäÊàêÂäüÁöÑ‰∏çÂêåÊ©üÁéáÂíåÂ§±ÊïóÁöÑÊ©üÁéáÊòØÂΩ±ÈüøÊ®°ÂûãÊïèÊÑüÂ∫¶ÁöÑËÆäÊï∏„ÄÇ

##### **BIOSCAN-CLIP: Bridging Vision and Genomics for Biodiversity Monitoring at Scale**
2405.17537v1 by ZeMing Gong, Austin T. Wang, Joakim Bruslund Haurum, Scott C. Lowe, Graham W. Taylor, Angel X. Chang

Measuring biodiversity is crucial for understanding ecosystem health. While
prior works have developed machine learning models for the taxonomic
classification of photographic images and DNA separately, in this work, we
introduce a multimodal approach combining both, using CLIP-style contrastive
learning to align images, DNA barcodes, and textual data in a unified embedding
space. This allows for accurate classification of both known and unknown insect
species without task-specific fine-tuning, leveraging contrastive learning for
the first time to fuse DNA and image data. Our method surpasses previous
single-modality approaches in accuracy by over 11% on zero-shot learning tasks,
showcasing its effectiveness in biodiversity studies.

ÊëòË¶ÅÔºöÊ∏¨ÈáèÁîüÁâ©Â§öÊ®£ÊÄßÂ∞çÊñº‰∫ÜËß£ÁîüÊÖãÁ≥ªÁµ±ÂÅ•Â∫∑Ëá≥ÈóúÈáçË¶Å„ÄÇÈõñÁÑ∂ÂÖàÂâçÁöÑÂ∑•‰ΩúÂ∑≤ÈáùÂ∞çÊîùÂΩ±ÂΩ±ÂÉèÂíå DNA ÁöÑÂàÜÈ°ûÂ≠∏ÂàÜÈ°ûÂàÜÂà•ÈñãÁôºÊ©üÂô®Â≠∏ÁøíÊ®°ÂûãÔºå‰ΩÜÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜÁµêÂêàÂÖ©ËÄÖÁöÑÂ§öÊ®°ÂºèÊñπÊ≥ïÔºå‰ΩøÁî® CLIP È¢®Ê†ºÁöÑÂ∞çÊØîÂ≠∏Áøí‰æÜÊØîÂ∞çÂΩ±ÂÉè„ÄÅDNA Ê¢ùÁ¢ºÂíåÁµ±‰∏ÄÂµåÂÖ•Á©∫Èñì‰∏≠ÁöÑÊñáÂ≠óË≥áÊñô„ÄÇÈÄôÂÖÅË®±Â∞çÂ∑≤Áü•ÂíåÊú™Áü•ÊòÜËü≤Áâ©Á®ÆÈÄ≤Ë°åÊ∫ñÁ¢∫ÂàÜÈ°ûÔºåÁÑ°ÈúÄÁâπÂÆö‰ªªÂãôÁöÑÂæÆË™øÔºåÈ¶ñÊ¨°Âà©Áî®Â∞çÊØîÂ≠∏Áøí‰æÜËûçÂêà DNA ÂíåÂΩ±ÂÉèË≥áÊñô„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÂú®Èõ∂Ê¨°Â≠∏Áøí‰ªªÂãô‰∏≠Ë∂ÖË∂ä‰∫ÜÂÖàÂâçÁöÑÂñÆ‰∏ÄÊ®°ÂºèÊñπÊ≥ïÔºåÊ∫ñÁ¢∫Â∫¶ÊèêÈ´ò‰∫Ü 11% ‰ª•‰∏äÔºåÂ±ïÁ§∫‰∫ÜÂÖ∂Âú®ÁîüÁâ©Â§öÊ®£ÊÄßÁ†îÁ©∂‰∏≠ÁöÑÊúâÊïàÊÄß„ÄÇ

##### **On Fairness of Low-Rank Adaptation of Large Models**
2405.17512v1 by Zhoujie Ding, Ken Ziyu Liu, Pura Peetathawatchai, Berivan Isik, Sanmi Koyejo

Low-rank adaptation of large models, particularly LoRA, has gained traction
due to its computational efficiency. This efficiency, contrasted with the
prohibitive costs of full-model fine-tuning, means that practitioners often
turn to LoRA and sometimes without a complete understanding of its
ramifications. In this study, we focus on fairness and ask whether LoRA has an
unexamined impact on utility, calibration, and resistance to membership
inference across different subgroups (e.g., genders, races, religions) compared
to a full-model fine-tuning baseline. We present extensive experiments across
vision and language domains and across classification and generation tasks
using ViT-Base, Swin-v2-Large, Llama-2 7B, and Mistral 7B. Intriguingly,
experiments suggest that while one can isolate cases where LoRA exacerbates
model bias across subgroups, the pattern is inconsistent -- in many cases, LoRA
has equivalent or even improved fairness compared to the base model or its full
fine-tuning baseline. We also examine the complications of evaluating
fine-tuning fairness relating to task design and model token bias, calling for
more careful fairness evaluations in future work.

ÊëòË¶ÅÔºö‰ΩéÁß©Â§ßÂûãÊ®°ÂûãÁöÑÈÅ©ÊáâÔºåÁâπÂà•ÊòØ LoRAÔºåÁî±ÊñºÂÖ∂Ë®àÁÆóÊïàÁéáËÄåÁç≤ÂæóÈóúÊ≥®„ÄÇÊ≠§ÊïàÁéáËàáÂÖ®Ê®°ÂûãÂæÆË™øÁöÑÁ¶ÅÊ≠¢ÊàêÊú¨ÂΩ¢ÊàêÂ∞çÊØîÔºåÈÄôË°®Á§∫ÂæûÊ•≠ËÄÖÁ∂ìÂ∏∏Ê±ÇÂä©Êñº LoRAÔºåÊúâÊôÇÂçª‰∏çÂÆåÂÖ®‰∫ÜËß£ÂÖ∂ÂæåÊûú„ÄÇÂú®Êú¨Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëÂ∞àÊ≥®ÊñºÂÖ¨Âπ≥ÊÄßÔºå‰∏¶Ë©¢Âïè LoRA ÊòØÂê¶Â∞çÊïàÁî®„ÄÅÊ†°Ê∫ñÂíåËàáÂÖ®Ê®°ÂûãÂæÆË™øÂü∫Ê∫ñÁ∑öÁõ∏ÊØîÔºåÂ∞ç‰∏çÂêåÂ≠êÁæ§Ôºà‰æãÂ¶ÇÊÄßÂà•„ÄÅÁ®ÆÊóè„ÄÅÂÆóÊïôÔºâÁöÑÊàêÂì°Êé®Ë´ñÁöÑÊäµÊäóÂäõÊúâÊú™Á∂ìÊ™¢È©óÁöÑÂΩ±Èüø„ÄÇÊàëÂÄëÂú®Ë¶ñË¶∫ÂíåË™ûË®ÄÈ†òÂüü‰ª•Âèä‰ΩøÁî® ViT-Base„ÄÅSwin-v2-Large„ÄÅLlama-2 7B Âíå Mistral 7B ÁöÑÂàÜÈ°ûÂíåÁîüÊàê‰ªªÂãô‰∏≠Â±ïÁ§∫‰∫ÜÂª£Ê≥õÁöÑÂØ¶È©ó„ÄÇÊúâË∂£ÁöÑÊòØÔºåÂØ¶È©óË°®ÊòéÔºåÈõñÁÑ∂‰∫∫ÂÄëÂèØ‰ª•ÊâæÂá∫ LoRA Âú®Â≠êÁæ§‰∏≠Âä†ÂäáÊ®°ÂûãÂÅèÂ∑ÆÁöÑÊÉÖÊ≥ÅÔºå‰ΩÜÊ®°Âºè‰∏¶‰∏ç‰∏ÄËá¥‚Äî‚ÄîÂú®Ë®±Â§öÊÉÖÊ≥Å‰∏ãÔºåËàáÂü∫Á§éÊ®°ÂûãÊàñÂÖ∂ÂÖ®ÂæÆË™øÂü∫Ê∫ñÁ∑öÁõ∏ÊØîÔºåLoRA ÂÖ∑ÊúâÁõ∏Á≠âÁîöËá≥Êõ¥Â•ΩÁöÑÂÖ¨Âπ≥ÊÄß„ÄÇÊàëÂÄëÈÇÑÊ™¢È©ó‰∫ÜËàá‰ªªÂãôË®≠Ë®àÂíåÊ®°Âûã‰ª£Âπ£ÂÅèÂ∑ÆÁõ∏ÈóúÁöÑÂæÆË™øÂÖ¨Âπ≥ÊÄßË©ï‰º∞ÁöÑË§áÈõúÊÄßÔºåÂëºÁ±≤Âú®Êú™‰æÜÁöÑÁ†îÁ©∂‰∏≠ÈÄ≤Ë°åÊõ¥‰ªîÁ¥∞ÁöÑÂÖ¨Âπ≥ÊÄßË©ï‰º∞„ÄÇ

##### **Cross-Modality Jailbreak and Mismatched Attacks on Medical Multimodal Large Language Models**
2405.20775v1 by Xijie Huang, Xinyuan Wang, Hantao Zhang, Jiawen Xi, Jingkun An, Hao Wang, Chengwei Pan

Security concerns related to Large Language Models (LLMs) have been
extensively explored, yet the safety implications for Multimodal Large Language
Models (MLLMs), particularly in medical contexts (MedMLLMs), remain
insufficiently studied. This paper delves into the underexplored security
vulnerabilities of MedMLLMs, especially when deployed in clinical environments
where the accuracy and relevance of question-and-answer interactions are
critically tested against complex medical challenges. By combining existing
clinical medical data with atypical natural phenomena, we redefine two types of
attacks: mismatched malicious attack (2M-attack) and optimized mismatched
malicious attack (O2M-attack). Using our own constructed voluminous 3MAD
dataset, which covers a wide range of medical image modalities and harmful
medical scenarios, we conduct a comprehensive analysis and propose the MCM
optimization method, which significantly enhances the attack success rate on
MedMLLMs. Evaluations with this dataset and novel attack methods, including
white-box attacks on LLaVA-Med and transfer attacks on four other
state-of-the-art models, indicate that even MedMLLMs designed with enhanced
security features are vulnerable to security breaches. Our work underscores the
urgent need for a concerted effort to implement robust security measures and
enhance the safety and efficacy of open-source MedMLLMs, particularly given the
potential severity of jailbreak attacks and other malicious or clinically
significant exploits in medical settings. For further research and replication,
anonymous access to our code is available at
https://github.com/dirtycomputer/O2M_attack. Warning: Medical large model
jailbreaking may generate content that includes unverified diagnoses and
treatment recommendations. Always consult professional medical advice.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Áõ∏ÈóúÁöÑÂÆâÂÖ®ÂïèÈ°åÂ∑≤Á∂ìË¢´Âª£Ê≥õÊé¢Ë®éÔºå‰ΩÜÂ§öÊ®°ÊÖãÂ§ßÂûãË™ûË®ÄÊ®°Âûã (MLLM) ÁöÑÂÆâÂÖ®ÊÄßÂΩ±ÈüøÔºåÁâπÂà•ÊòØÂú®ÈÜ´ÁôÇËÉåÊôØ (MedMLLM) ‰∏≠Ôºå‰ªçÊú™ÊúâË∂≥Â§†ÁöÑÁ†îÁ©∂„ÄÇÊú¨ÊñáÊ∑±ÂÖ•Êé¢Ë®é‰∫Ü MedMLLM Êú™Ë¢´ÂÖÖÂàÜÊé¢Ë®éÁöÑÂÆâÂÖ®ÊºèÊ¥ûÔºåÁâπÂà•ÊòØÂú®Ëá®Â∫äÁí∞Â¢É‰∏≠ÈÉ®ÁΩ≤ÊôÇÔºåÂïèÈ°åÂíåÁ≠îÊ°à‰∫íÂãïÁöÑÊ∫ñÁ¢∫ÊÄßÂíåÁõ∏ÈóúÊÄßÊúÉÂèóÂà∞Ë§áÈõúÁöÑÈÜ´ÁôÇÊåëÊà∞ÁöÑÂö¥Ê†ºËÄÉÈ©ó„ÄÇÈÄèÈÅéÁµêÂêàÁèæÊúâÁöÑËá®Â∫äÈÜ´ÁôÇÊï∏ÊìöÂíåÈùûÂÖ∏ÂûãÁöÑËá™ÁÑ∂ÁèæË±°ÔºåÊàëÂÄëÈáçÊñ∞ÂÆöÁæ©‰∫ÜÂÖ©Á®ÆÈ°ûÂûãÁöÑÊîªÊìäÔºö‰∏çÂåπÈÖçÊÉ°ÊÑèÊîªÊìä (2M ÊîªÊìä) ÂíåÊúÄ‰Ω≥Âåñ‰∏çÂåπÈÖçÊÉ°ÊÑèÊîªÊìä (O2M ÊîªÊìä)„ÄÇ‰ΩøÁî®ÊàëÂÄëËá™Â∑±Âª∫ÊßãÁöÑÂ§ßÈáè 3MAD Ë≥áÊñôÈõÜÔºåÊ∂µËìãÂª£Ê≥õÁöÑÈÜ´Â≠∏ÂΩ±ÂÉèÊ®°ÂºèÂíåÊúâÂÆ≥ÁöÑÈÜ´ÁôÇÊÉÖÂ¢ÉÔºåÊàëÂÄëÈÄ≤Ë°å‰∫ÜÂÖ®Èù¢ÁöÑÂàÜÊûêÔºå‰∏¶ÊèêÂá∫‰∫Ü MCM ÊúÄ‰Ω≥ÂåñÊñπÊ≥ïÔºåÈÄôÈ°ØËëóÊèêÂçá‰∫Ü MedMLLM ÁöÑÊîªÊìäÊàêÂäüÁéá„ÄÇ‰ΩøÁî®Ê≠§Ë≥áÊñôÈõÜÂíåÊñ∞Á©éÁöÑÊîªÊìäÊñπÊ≥ïÔºåÂåÖÊã¨Â∞ç LLaVA-Med ÁöÑÁôΩÁõíÊîªÊìäÂíåÂ∞çÂÖ∂‰ªñÂõõÁ®ÆÊúÄÂÖàÈÄ≤Ê®°ÂûãÁöÑÂÇ≥Ëº∏ÊîªÊìäÔºåË©ï‰º∞ÁµêÊûúÈ°ØÁ§∫ÔºåÂç≥‰ΩøÊòØË®≠Ë®àÊúâÂ¢ûÂº∑ÂÆâÂÖ®ÂäüËÉΩÁöÑ MedMLLM ‰πüÂÆπÊòìÂèóÂà∞ÂÆâÂÖ®ÊºèÊ¥ûÁöÑÂΩ±Èüø„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂Âº∑Ë™ø‰∫ÜËø´ÂàáÈúÄË¶ÅÊé°Âèñ‰∏ÄËá¥ÁöÑÊé™ÊñΩÔºåÂØ¶ÊñΩÂº∑Âõ∫ÁöÑÂÆâÂÖ®Êé™ÊñΩÔºå‰∏¶Â¢ûÂº∑ÈñãÊ∫ê MedMLLM ÁöÑÂÆâÂÖ®ÊÄßËàáÊïàËÉΩÔºåÁâπÂà•ÊòØËÄÉÊÖÆÂà∞Âú®ÈÜ´ÁôÇÁí∞Â¢É‰∏≠Ë∂äÁçÑÊîªÊìäÂíåÂÖ∂‰ªñÊÉ°ÊÑèÊîªÊìäÊàñËá®Â∫ä‰∏äÈáçË¶ÅÁöÑÊºèÊ¥ûÁöÑÊΩõÂú®Âö¥ÈáçÊÄß„ÄÇÁÇ∫‰∫ÜÈÄ≤‰∏ÄÊ≠•ÁöÑÁ†îÁ©∂ÂíåË§áË£ΩÔºåÊàëÂÄëÂ∑≤Âú® https://github.com/dirtycomputer/O2M_attack Êèê‰æõÂåøÂêçÂ≠òÂèñÊàëÂÄëÁöÑÁ®ãÂºèÁ¢º„ÄÇË≠¶ÂëäÔºöÈÜ´ÁôÇÂ§ßÂûãÊ®°ÂûãË∂äÁçÑÂèØËÉΩÊúÉÁî¢ÁîüÂåÖÂê´Êú™È©óË≠âË®∫Êñ∑ÂíåÊ≤ªÁôÇÂª∫Ë≠∞ÁöÑÂÖßÂÆπ„ÄÇÂãôÂøÖË´ÆË©¢Â∞àÊ•≠ÈÜ´ÁôÇÂª∫Ë≠∞„ÄÇ

##### **Scalable Numerical Embeddings for Multivariate Time Series: Enhancing Healthcare Data Representation Learning**
2405.16557v1 by Chun-Kai Huang, Yi-Hsien Hsieh, Ta-Jung Chien, Li-Cheng Chien, Shao-Hua Sun, Tung-Hung Su, Jia-Horng Kao, Che Lin

Multivariate time series (MTS) data, when sampled irregularly and
asynchronously, often present extensive missing values. Conventional
methodologies for MTS analysis tend to rely on temporal embeddings based on
timestamps that necessitate subsequent imputations, yet these imputed values
frequently deviate substantially from their actual counterparts, thereby
compromising prediction accuracy. Furthermore, these methods typically fail to
provide robust initial embeddings for values infrequently observed or even
absent within the training set, posing significant challenges to model
generalizability. In response to these challenges, we propose SCAlable
Numerical Embedding (SCANE), a novel framework that treats each feature value
as an independent token, effectively bypassing the need for imputation. SCANE
regularizes the traits of distinct feature embeddings and enhances
representational learning through a scalable embedding mechanism. Coupling
SCANE with the Transformer Encoder architecture, we develop the Scalable
nUMerical eMbeddIng Transformer (SUMMIT), which is engineered to deliver
precise predictive outputs for MTS characterized by prevalent missing entries.
Our experimental validation, conducted across three disparate electronic health
record (EHR) datasets marked by elevated missing value frequencies, confirms
the superior performance of SUMMIT over contemporary state-of-the-art
approaches addressing similar challenges. These results substantiate the
efficacy of SCANE and SUMMIT, underscoring their potential applicability across
a broad spectrum of MTS data analytical tasks.

ÊëòË¶ÅÔºöÂ§öËÆäÈáèÊôÇÈñìÂ∫èÂàó (MTS) Ë≥áÊñôÂú®‰∏çË¶èÂâá‰∏îÈùûÂêåÊ≠•Âú∞ÂèñÊ®£ÊôÇÔºåÈÄöÂ∏∏ÊúÉÂá∫ÁèæÂ§ßÈáèÁöÑÈÅ∫Â§±ÂÄº„ÄÇMTS ÂàÜÊûêÁöÑÂÇ≥Áµ±ÊñπÊ≥ïÂÇæÂêëÊñº‰æùË≥¥Âü∫ÊñºÊôÇÈñìÊà≥Ë®òÁöÑÊôÇÈñìÂµåÂÖ•ÔºåÈÄôÈúÄË¶ÅÂæåÁ∫åÁöÑÊèíË£úÔºå‰ΩÜÈÄô‰∫õÊèíË£úÂÄºÈÄöÂ∏∏ËàáÂÖ∂ÂØ¶ÈöõÂ∞çÊáâÂÄºÊúâÂæàÂ§ßÂÅèÂ∑ÆÔºåÂæûËÄåÂΩ±ÈüøÈ†êÊ∏¨Ê∫ñÁ¢∫Â∫¶„ÄÇÊ≠§Â§ñÔºåÈÄô‰∫õÊñπÊ≥ïÈÄöÂ∏∏ÁÑ°Ê≥ïÁÇ∫Ë®ìÁ∑¥ÈõÜ‰∏≠‰∏çÂ∏∏ËßÄÂØüÁîöËá≥‰∏çÂ≠òÂú®ÁöÑÂÄºÊèê‰æõÁ©©ÂÅ•ÁöÑÂàùÂßãÂµåÂÖ•ÔºåÈÄôÂ∞çÊ®°ÂûãÁöÑÊ≥õÂåñÊÄßÊèêÂá∫‰∫ÜÈáçÂ§ßÊåëÊà∞„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÊèêÂá∫‰∫ÜÂèØÊì¥ÂÖÖÊï∏ÂÄºÂµåÂÖ• (SCANE)ÔºåÈÄôÊòØ‰∏ÄÂÄãÊñ∞Á©éÁöÑÊ°ÜÊû∂ÔºåÂ∞áÊØèÂÄãÁâπÂæµÂÄºË¶ñÁÇ∫‰∏ÄÂÄãÁç®Á´ãÁöÑÊ®ôË®òÔºåÊúâÊïàÂú∞ÁπûÈÅé‰∫ÜÊèíË£úÁöÑÈúÄË¶Å„ÄÇSCANE Ë¶èÁØÑ‰∫Ü‰∏çÂêåÁâπÂæµÂµåÂÖ•ÁöÑÁâπÂæµÔºå‰∏¶ÈÄöÈÅéÂèØÊì¥ÂÖÖÁöÑÂµåÂÖ•Ê©üÂà∂Â¢ûÂº∑‰∫ÜË°®ÂæµÂ≠∏Áøí„ÄÇÂ∞á SCANE Ëàá Transformer Á∑®Á¢ºÂô®Êû∂ÊßãÁµêÂêàÔºåÊàëÂÄëÈñãÁôº‰∫ÜÂèØÊì¥ÂÖÖÊï∏ÂÄºÂµåÂÖ• Transformer (SUMMIT)ÔºåÂÆÉË¢´Ë®≠Ë®àÁÇ∫ÁÇ∫ÂÖ∑ÊúâÊôÆÈÅçÈÅ∫Â§±Ê¢ùÁõÆÁöÑ MTS Êèê‰æõÊ∫ñÁ¢∫ÁöÑÈ†êÊ∏¨Ëº∏Âá∫„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÈ©óË≠âÊòØÂú®‰∏âÂÄã‰∏çÂêåÁöÑÈõªÂ≠êÂÅ•Â∫∑Ë®òÈåÑ (EHR) Ë≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÁöÑÔºåÈÄô‰∫õË≥áÊñôÈõÜ‰ª•ÈÅ∫Â§±ÂÄºÈ†ªÁéáÈ´òÁÇ∫ÁâπÂæµÔºåË≠âÂØ¶‰∫Ü SUMMIT Âú®Ëß£Ê±∫È°û‰ººÊåëÊà∞ÁöÑÁï∂‰ª£ÊúÄÂÖàÈÄ≤ÊñπÊ≥ï‰∏äÁöÑÂçìË∂äÊÄßËÉΩ„ÄÇÈÄô‰∫õÁµêÊûúË≠âÂØ¶‰∫Ü SCANE Âíå SUMMIT ÁöÑÂäüÊïàÔºåÂº∑Ë™ø‰∫ÜÂÆÉÂÄëÂú®Âª£Ê≥õÁöÑ MTS Ë≥áÊñôÂàÜÊûê‰ªªÂãô‰∏≠ÁöÑÊΩõÂú®ÈÅ©Áî®ÊÄß„ÄÇ

##### **SED: Self-Evaluation Decoding Enhances Large Language Models for Better Generation**
2405.16552v1 by Ziqin Luo, Haixia Han, Haokun Zhao, Guochao Jiang, Chengyu Du, Tingyun Li, Jiaqing Liang, Deqing Yang, Yanghua Xiao

Existing Large Language Models (LLMs) generate text through unidirectional
autoregressive decoding methods to respond to various user queries. These
methods tend to consider token selection in a simple sequential manner, making
it easy to fall into suboptimal options when encountering uncertain tokens,
referred to as chaotic points in our work. Many chaotic points exist in texts
generated by LLMs, and they often significantly affect the quality of
subsequently generated tokens, which can interfere with LLMs' generation. This
paper proposes Self-Evaluation Decoding, SED, a decoding method for enhancing
model generation. Analogous to the human decision-making process, SED
integrates speculation and evaluation steps into the decoding process, allowing
LLMs to make more careful decisions and thus optimize token selection at
chaotic points. Experimental results across various tasks using different LLMs
demonstrate SED's effectiveness.

ÊëòË¶ÅÔºöÁèæÊúâÁöÑÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÈÄèÈÅéÂñÆÂêëËá™Ëø¥Ê≠∏Ëß£Á¢ºÊñπÊ≥ïÁî¢ÁîüÊñáÂ≠óÔºå‰ª•ÂõûÊáâÂêÑÁ®Æ‰ΩøÁî®ËÄÖÊü•Ë©¢„ÄÇÈÄô‰∫õÊñπÊ≥ïÂÇæÂêëÊñº‰ª•Á∞°ÂñÆÁöÑÈ†ÜÂ∫èÊñπÂºèËÄÉÈáè‰ª£Á¢ºÈÅ∏ÊìáÔºåÂú®ÈÅáÂà∞‰∏çÁ¢∫ÂÆöÁöÑ‰ª£Á¢ºÔºàÂú®ÊàëÂÄëÁöÑÂ∑•‰Ωú‰∏≠Á®±ÁÇ∫Ê∑∑‰∫ÇÈªûÔºâÊôÇÔºåÂæàÂÆπÊòìÈô∑ÂÖ•Ê¨°‰Ω≥ÈÅ∏È†Ö„ÄÇLLM ÁîüÊàêÁöÑÊñáÂ≠ó‰∏≠Â≠òÂú®Ë®±Â§öÊ∑∑‰∫ÇÈªûÔºåËÄåÂÆÉÂÄëÈÄöÂ∏∏ÊúÉÈ°ØËëóÂΩ±ÈüøÂæåÁ∫åÁîüÊàê‰ª£Á¢ºÁöÑÂìÅË≥™ÔºåÈÄ≤ËÄåÂπ≤Êìæ LLM ÁöÑÁîüÊàê„ÄÇÊú¨ÊñáÊèêÂá∫Ëá™ÊàëË©ï‰º∞Ëß£Á¢º (SED)Ôºå‰∏ÄÁ®ÆÁî®ÊñºÂ¢ûÂº∑Ê®°ÂûãÁîüÊàêÁöÑËß£Á¢ºÊñπÊ≥ï„ÄÇÈ°ûÊØîÊñº‰∫∫È°ûÊ±∫Á≠ñÈÅéÁ®ãÔºåSED Â∞áÊé®Ê∏¨ÂíåË©ï‰º∞Ê≠•È©üÊï¥ÂêàÂà∞Ëß£Á¢ºÈÅéÁ®ã‰∏≠ÔºåËÆì LLM ËÉΩÂÅöÂá∫Êõ¥Ë¨πÊÖéÁöÑÊ±∫ÂÆöÔºåÈÄ≤ËÄåÊúÄ‰Ω≥ÂåñÊ∑∑‰∫ÇÈªûÁöÑ‰ª£Á¢ºÈÅ∏Êìá„ÄÇ‰ΩøÁî®‰∏çÂêå LLM Âú®ÂêÑÁ®Æ‰ªªÂãô‰∏≠ÈÄ≤Ë°åÁöÑÂØ¶È©óÁµêÊûúË≠âÊòé‰∫Ü SED ÁöÑÊúâÊïàÊÄß„ÄÇ

##### **Gamified AI Approch for Early Detection of Dementia**
2405.16538v1 by Paramita Kundu Maji, Soubhik Acharya, Priti Paul, Sanjay Chakraborty, Saikat Basu

This paper aims to develop a new deep learning-inspired gaming approach for
early detection of dementia. This research integrates a robust convolutional
neural network (CNN)-based model for early dementia detection using health
metrics data as well as facial image data through a cognitive assessment-based
gaming application. We have collected 1000 data samples of health metrics
dataset from Apollo Diagnostic Center Kolkata that is labeled as either
demented or non-demented for the training of MOD-1D-CNN for the game level 1
and another dataset of facial images containing 1800 facial data that are
labeled as either demented or non-demented is collected by our research team
for the training of MOD-2D-CNN model in-game level 2. In our work, the loss for
the proposed MOD-1D-CNN model is 0.2692 and the highest accuracy is 70.50% for
identifying the dementia traits using real-life health metrics data. Similarly,
the proposed MOD-2D-CNN model loss is 0.1755 and the highest accuracy is
obtained here 95.72% for recognizing the dementia status using real-life
face-based image data. Therefore, a rule-based weightage method is applied to
combine both the proposed methods to achieve the final decision. The MOD-1D-CNN
and MOD-2D-CNN models are more lightweight and computationally efficient
alternatives because they have a significantly lower number of parameters when
compared to the other state-of-the-art models. We have compared their
accuracies and parameters with the other state-of-the-art deep learning models.

ÊëòË¶ÅÔºöÊú¨ÊñáÊó®Âú®ÂºÄÂèë‰∏ÄÁßçÊñ∞ÁöÑÂèóÊ∑±Â∫¶Â≠¶‰π†ÂêØÂèëÁöÑÊ∏∏ÊàèÊñπÊ≥ïÔºåÁî®‰∫éÊó©ÊúüÊ£ÄÊµãÁó¥ÂëÜÁóá„ÄÇÊú¨Á†îÁ©∂Êï¥Âêà‰∫Ü‰∏Ä‰∏™Âü∫‰∫éÈ≤ÅÊ£íÂç∑ÁßØÁ•ûÁªèÁΩëÁªú (CNN) ÁöÑÊ®°ÂûãÔºåÁî®‰∫éÈÄöËøáËÆ§Áü•ËØÑ‰º∞Ê∏∏ÊàèÂ∫îÁî®Á®ãÂ∫è‰ΩøÁî®ÂÅ•Â∫∑ÊåáÊ†áÊï∞ÊçÆÂíåÈù¢ÈÉ®ÂõæÂÉèÊï∞ÊçÆËøõË°åÊó©ÊúüÁó¥ÂëÜÁóáÊ£ÄÊµã„ÄÇÊàë‰ª¨‰ªé Apollo Diagnostic Center Kolkata Êî∂ÈõÜ‰∫Ü 1000 ‰∏™ÂÅ•Â∫∑ÊåáÊ†áÊï∞ÊçÆÈõÜÁöÑÊï∞ÊçÆÊ†∑Êú¨ÔºåËøô‰∫õÊ†∑Êú¨Ë¢´Ê†áËÆ∞‰∏∫Áó¥ÂëÜÊàñÈùûÁó¥ÂëÜÔºåÁî®‰∫éËÆ≠ÁªÉÊ∏∏ÊàèÁ¨¨ 1 ÂÖ≥ÁöÑ MOD-1D-CNNÔºå‰ª•ÂèäÁî±Êàë‰ª¨Á†îÁ©∂Âõ¢ÈòüÊî∂ÈõÜÁöÑÂè¶‰∏Ä‰∏™ÂåÖÂê´ 1800 ‰∏™Èù¢ÈÉ®Êï∞ÊçÆÁöÑÁöÑÈù¢ÈÉ®ÂõæÂÉèÊï∞ÊçÆÈõÜÔºåËøô‰∫õÊï∞ÊçÆË¢´Ê†áËÆ∞‰∏∫Áó¥ÂëÜÊàñÈùûÁó¥ÂëÜÔºåÁî®‰∫éËÆ≠ÁªÉÊ∏∏ÊàèÁ¨¨ 2 ÂÖ≥ÁöÑ MOD-2D-CNN Ê®°Âûã„ÄÇÂú®Êàë‰ª¨ÁöÑÂ∑•‰Ωú‰∏≠ÔºåÊèêÂá∫ÁöÑ MOD-1D-CNN Ê®°ÂûãÁöÑÊçüÂ§±‰∏∫ 0.2692Ôºå‰ΩøÁî®ÁúüÂÆûÂÅ•Â∫∑ÊåáÊ†áÊï∞ÊçÆËØÜÂà´Áó¥ÂëÜÁâπÂæÅÁöÑÊúÄÈ´òÂáÜÁ°ÆÁéá‰∏∫ 70.50%„ÄÇÁ±ª‰ººÂú∞ÔºåÊèêÂá∫ÁöÑ MOD-2D-CNN Ê®°ÂûãÊçüÂ§±‰∏∫ 0.1755Ôºå‰ΩøÁî®ÁúüÂÆûÂü∫‰∫éÈù¢ÈÉ®ÁöÑÂõæÂÉèÊï∞ÊçÆËØÜÂà´Áó¥ÂëÜÁä∂ÊÄÅÁöÑÊúÄÈ´òÂáÜÁ°ÆÁéá‰∏∫ 95.72%„ÄÇÂõ†Ê≠§ÔºåÂ∫îÁî®Âü∫‰∫éËßÑÂàôÁöÑÂä†ÊùÉÊñπÊ≥ïÊù•ÁªìÂêàËøô‰∏§ÁßçÊèêÂá∫ÁöÑÊñπÊ≥ï‰ª•ÂÆûÁé∞ÊúÄÁªàÂÜ≥Á≠ñ„ÄÇ‰∏éÂÖ∂‰ªñÊúÄÂÖàËøõÁöÑÊ®°ÂûãÁõ∏ÊØîÔºåMOD-1D-CNN Âíå MOD-2D-CNN Ê®°ÂûãÊõ¥ËΩªÈáè‰∏îËÆ°ÁÆóÊïàÁéáÊõ¥È´òÔºåÂõ†‰∏∫ÂÆÉ‰ª¨ÁöÑÂèÇÊï∞Êï∞ÈáèÊòéÊòæÊõ¥Â∞ë„ÄÇÊàë‰ª¨Â∑≤Â∞ÜÂÆÉ‰ª¨ÁöÑÂáÜÁ°ÆÊÄßÂíåÂèÇÊï∞‰∏éÂÖ∂‰ªñÊúÄÂÖàËøõÁöÑÊ∑±Â∫¶Â≠¶‰π†Ê®°ÂûãËøõË°å‰∫ÜÊØîËæÉ„ÄÇ

##### **ECG Semantic Integrator (ESI): A Foundation ECG Model Pretrained with LLM-Enhanced Cardiological Text**
2405.19366v1 by Han Yu, Peikun Guo, Akane Sano

The utilization of deep learning on electrocardiogram (ECG) analysis has
brought the advanced accuracy and efficiency of cardiac healthcare diagnostics.
By leveraging the capabilities of deep learning in semantic understanding,
especially in feature extraction and representation learning, this study
introduces a new multimodal contrastive pretaining framework that aims to
improve the quality and robustness of learned representations of 12-lead ECG
signals. Our framework comprises two key components, including Cardio Query
Assistant (CQA) and ECG Semantics Integrator(ESI). CQA integrates a
retrieval-augmented generation (RAG) pipeline to leverage large language models
(LLMs) and external medical knowledge to generate detailed textual descriptions
of ECGs. The generated text is enriched with information about demographics and
waveform patterns. ESI integrates both contrastive and captioning loss to
pretrain ECG encoders for enhanced representations. We validate our approach
through various downstream tasks, including arrhythmia detection and ECG-based
subject identification. Our experimental results demonstrate substantial
improvements over strong baselines in these tasks. These baselines encompass
supervised and self-supervised learning methods, as well as prior multimodal
pretraining approaches.

ÊëòË¶ÅÔºöÂà©Áî®Ê∑±Â∫¶Â≠∏ÁøíÊñºÂøÉÈõªÂúñ (ECG) ÂàÜÊûêÂ∑≤ÊèêÂçáÂøÉËáü‰øùÂÅ•Ë®∫Êñ∑ÁöÑÊ∫ñÁ¢∫ÊÄßÂíåÊïàÁéá„ÄÇÈÄèÈÅéÂà©Áî®Ê∑±Â∫¶Â≠∏ÁøíÂú®Ë™ûÊÑèÁêÜËß£‰∏≠ÁöÑËÉΩÂäõÔºåÁâπÂà•ÊòØÂú®ÁâπÂæµËêÉÂèñÂíåË°®Á§∫Â≠∏Áøí‰∏≠ÔºåÊú¨Á†îÁ©∂ÊèêÂá∫‰∏ÄÂÄãÊñ∞ÁöÑÂ§öÊ®°ÊÖãÂ∞çÊØîÈ†êË®ìÁ∑¥Êû∂ÊßãÔºåÊó®Âú®ÊèêÂçá 12 Â∞éÁ®ã ECG Ë®äËôüÂ≠∏ÁøíË°®Á§∫ÁöÑÂìÅË≥™ÂíåÁ©©ÂÅ•ÊÄß„ÄÇÊàëÂÄëÁöÑÊû∂ÊßãÂåÖÂê´ÂÖ©ÂÄãÈóúÈçµÂÖÉ‰ª∂ÔºåÂåÖÊã¨ÂøÉËáüÊü•Ë©¢Âä©ÁêÜ (CQA) Âíå ECG Ë™ûÊÑèÊï¥ÂêàÂô® (ESI)„ÄÇCQA Êï¥Âêà‰∏ÄÂÄãÊ™¢Á¥¢Â¢ûÂº∑ÁîüÊàê (RAG) ÁÆ°Á∑öÔºå‰ª•Âà©Áî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂíåÂ§ñÈÉ®ÈÜ´ÁôÇÁü•Ë≠ò‰æÜÁîüÊàê ECG ÁöÑË©≥Á¥∞ÊñáÂ≠óÊèèËø∞„ÄÇÁîüÊàêÁöÑÊñáÂ≠óÂåÖÂê´‰∫∫Âè£Áµ±Ë®àÂíåÊ≥¢ÂΩ¢Ê®°ÂºèÁöÑË≥áË®ä„ÄÇESI Êï¥ÂêàÂ∞çÊØîÂíåÊ®ôÈ°åÊêçÂ§±Ôºå‰ª•È†êË®ìÁ∑¥ ECG Á∑®Á¢ºÂô®‰ª•Áç≤ÂæóÂ¢ûÂº∑ÁöÑË°®Á§∫„ÄÇÊàëÂÄëÈÄèÈÅéÂêÑÁ®Æ‰∏ãÊ∏∏‰ªªÂãôÈ©óË≠âÊàëÂÄëÁöÑÂÅöÊ≥ïÔºåÂåÖÊã¨ÂøÉÂæã‰∏çÊï¥ÂÅµÊ∏¨ÂíåÂü∫Êñº ECG ÁöÑÂèóË©¶ËÄÖË≠òÂà•„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÁµêÊûúË≠âÊòéÔºåÂú®ÈÄô‰∫õ‰ªªÂãô‰∏≠Â§ßÂπÖÊèêÂçáÂº∑Â§ßÁöÑÂü∫Á∑ö„ÄÇÈÄô‰∫õÂü∫Á∑öÂåÖÂê´Áõ£Áù£ÂºèÂíåËá™Áõ£Áù£ÂºèÂ≠∏ÁøíÊñπÊ≥ïÔºå‰ª•ÂèäÂÖàÂâçÁöÑÂ§öÊ®°ÊÖãÈ†êË®ìÁ∑¥ÊñπÊ≥ï„ÄÇ

##### **Improving Health Professionals' Onboarding with AI and XAI for Trustworthy Human-AI Collaborative Decision Making**
2405.16424v1 by Min Hun Lee, Silvana Xin Yi Choo, Shamala D/O Thilarajah

With advanced AI/ML, there has been growing research on explainable AI (XAI)
and studies on how humans interact with AI and XAI for effective human-AI
collaborative decision-making. However, we still have a lack of understanding
of how AI systems and XAI should be first presented to users without technical
backgrounds. In this paper, we present the findings of semi-structured
interviews with health professionals (n=12) and students (n=4) majoring in
medicine and health to study how to improve onboarding with AI and XAI. For the
interviews, we built upon human-AI interaction guidelines to create onboarding
materials of an AI system for stroke rehabilitation assessment and AI
explanations and introduce them to the participants. Our findings reveal that
beyond presenting traditional performance metrics on AI, participants desired
benchmark information, the practical benefits of AI, and interaction trials to
better contextualize AI performance, and refine the objectives and performance
of AI. Based on these findings, we highlight directions for improving
onboarding with AI and XAI and human-AI collaborative decision-making.

ÊëòË¶ÅÔºöÈö®ËëóÂÖàÈÄ≤ÁöÑ AI/MLÔºåÂ∞çÂèØËß£Èáã AI (XAI) ÁöÑÁ†îÁ©∂‰∏çÊñ∑Â¢ûÂä†Ôºå‰ª•ÂèäÈóúÊñº‰∫∫È°ûÂ¶Ç‰ΩïËàá AI Âíå XAI ‰∫íÂãï‰ª•ÈÄ≤Ë°åÊúâÊïàÁöÑ‰∫∫Â∑•Êô∫ÊÖßÂçî‰ΩúÊ±∫Á≠ñÂà∂ÂÆö„ÄÇÁÑ∂ËÄåÔºåÊàëÂÄë‰ªçÁÑ∂Áº∫‰πèÂ∞ç AI Á≥ªÁµ±Âíå XAI ÊáâÂ¶Ç‰ΩïÈ¶ñÂÖàÂëàÁèæÁµ¶Ê≤íÊúâÊäÄË°ìËÉåÊôØÁöÑÁî®Êà∂ÁöÑ‰∫ÜËß£„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜËàáÈÜ´ÁôÇÂ∞àÊ•≠‰∫∫Âì° (n=12) Âíå‰∏ª‰øÆÈÜ´Â≠∏ÂíåÂÅ•Â∫∑ÁöÑÂ≠∏Áîü (n=4) ÈÄ≤Ë°åÂçäÁµêÊßãÂåñË®™Ë´áÁöÑÁµêÊûúÔºå‰ª•Á†îÁ©∂Â¶Ç‰ΩïÊîπÂñÑ AI Âíå XAI ÁöÑÂÖ•ÈñÄ„ÄÇÂ∞çÊñºË®™Ë´áÔºåÊàëÂÄëÂª∫Á´ãÂú®‰∫∫Ê©ü‰∫íÂãïÊ∫ñÂâá‰πã‰∏äÔºåÁÇ∫‰∏≠È¢®Â∫∑Âæ©Ë©ï‰º∞Âíå AI Ëß£ÈáãÁöÑ AI Á≥ªÁµ±ÂâµÂª∫ÂÖ•ÈñÄÊùêÊñôÔºå‰∏¶Â∞áÂÆÉÂÄë‰ªãÁ¥πÁµ¶ÂèÉËàáËÄÖ„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúË°®ÊòéÔºåÈô§‰∫ÜÂëàÁèæÂÇ≥Áµ±ÁöÑ AI ÊÄßËÉΩÊåáÊ®ôÂ§ñÔºåÂèÉËàáËÄÖÈÇÑÂ∏åÊúõÂü∫ÂáÜ‰ø°ÊÅØ„ÄÅAI ÁöÑÂØ¶ÈöõÂ•ΩËôï‰ª•Âèä‰∫§‰∫íË©¶È©óÔºå‰ª•Êõ¥Â•ΩÂú∞Â∞á AI ÊÄßËÉΩÊÉÖÂ¢ÉÂåñÔºå‰∏¶ÂÆåÂñÑ AI ÁöÑÁõÆÊ®ôÂíåÊÄßËÉΩ„ÄÇÊ†πÊìöÈÄô‰∫õÁôºÁèæÔºåÊàëÂÄëÂº∑Ë™ø‰∫ÜÊîπÈÄ≤ AI Âíå XAI ‰ª•Âèä‰∫∫Ê©üÂçî‰ΩúÊ±∫Á≠ñÂà∂ÂÆöÁöÑÂÖ•ÈñÄÊñπÂêë„ÄÇ

##### **Exploring Nutritional Impact on Alzheimer's Mortality: An Explainable AI Approach**
2405.17502v1 by Ziming Liu, Longjian Liu, Robert E. Heidel, Xiaopeng Zhao

This article uses machine learning (ML) and explainable artificial
intelligence (XAI) techniques to investigate the relationship between
nutritional status and mortality rates associated with Alzheimers disease (AD).
The Third National Health and Nutrition Examination Survey (NHANES III)
database is employed for analysis. The random forest model is selected as the
base model for XAI analysis, and the Shapley Additive Explanations (SHAP)
method is used to assess feature importance. The results highlight significant
nutritional factors such as serum vitamin B12 and glycated hemoglobin. The
study demonstrates the effectiveness of random forests in predicting AD
mortality compared to other diseases. This research provides insights into the
impact of nutrition on AD and contributes to a deeper understanding of disease
progression.

ÊëòË¶ÅÔºöÊú¨Êñá‰ΩøÁî®Ê©üÂô®Â≠∏Áøí (ML) ÂíåÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖß (XAI) ÊäÄË°ì‰æÜÊé¢Ë®éÁáüÈ§äÁãÄÊ≥ÅËàáÈòøËå≤Êµ∑ÈªòÁóá (AD) Áõ∏ÈóúÁöÑÊ≠ª‰∫°Áéá‰πãÈñìÁöÑÈóú‰øÇ„ÄÇÊé°Áî®Á¨¨‰∏âÊ¨°ÂÖ®ÂúãÂÅ•Â∫∑ËàáÁáüÈ§äÊ™¢Êü•Ë™øÊü• (NHANES III) Ë≥áÊñôÂ∫´ÈÄ≤Ë°åÂàÜÊûê„ÄÇÈÅ∏ÊìáÈö®Ê©üÊ£ÆÊûóÊ®°Âûã‰ΩúÁÇ∫ XAI ÂàÜÊûêÁöÑÂü∫Á§éÊ®°ÂûãÔºå‰∏¶‰ΩøÁî® Shapley Additive Explanations (SHAP) ÊñπÊ≥ï‰æÜË©ï‰º∞ÁâπÂæµÈáçË¶ÅÊÄß„ÄÇÁµêÊûúÁ™ÅÈ°Ø‰∫ÜÈáçË¶ÅÁöÑÁáüÈ§äÂõ†Á¥†Ôºå‰æãÂ¶ÇË°ÄÊ∏ÖÁ∂≠ÁîüÁ¥† B12 ÂíåÁ≥ñÂåñË°ÄÁ¥ÖËõãÁôΩ„ÄÇË©≤Á†îÁ©∂Ë≠âÊòé‰∫ÜÈö®Ê©üÊ£ÆÊûóÂú®È†êÊ∏¨ AD Ê≠ª‰∫°ÁéáÊñπÈù¢Áõ∏ËºÉÊñºÂÖ∂‰ªñÁñæÁóÖÁöÑÊúâÊïàÊÄß„ÄÇÊú¨Á†îÁ©∂Êèê‰æõ‰∫ÜÁáüÈ§äÂ∞ç AD ÁöÑÂΩ±ÈüøÁöÑË¶ãËß£Ôºå‰∏¶ÊúâÂä©ÊñºÊõ¥Ê∑±ÂÖ•Âú∞‰∫ÜËß£ÁñæÁóÖÁöÑÈÄ≤Â±ï„ÄÇ

##### **Augmented Risk Prediction for the Onset of Alzheimer's Disease from Electronic Health Records with Large Language Models**
2405.16413v1 by Jiankun Wang, Sumyeong Ahn, Taykhoom Dalal, Xiaodan Zhang, Weishen Pan, Qiannan Zhang, Bin Chen, Hiroko H. Dodge, Fei Wang, Jiayu Zhou

Alzheimer's disease (AD) is the fifth-leading cause of death among Americans
aged 65 and older. Screening and early detection of AD and related dementias
(ADRD) are critical for timely intervention and for identifying clinical trial
participants. The widespread adoption of electronic health records (EHRs)
offers an important resource for developing ADRD screening tools such as
machine learning based predictive models. Recent advancements in large language
models (LLMs) demonstrate their unprecedented capability of encoding knowledge
and performing reasoning, which offers them strong potential for enhancing risk
prediction. This paper proposes a novel pipeline that augments risk prediction
by leveraging the few-shot inference power of LLMs to make predictions on cases
where traditional supervised learning methods (SLs) may not excel.
Specifically, we develop a collaborative pipeline that combines SLs and LLMs
via a confidence-driven decision-making mechanism, leveraging the strengths of
SLs in clear-cut cases and LLMs in more complex scenarios. We evaluate this
pipeline using a real-world EHR data warehouse from Oregon Health \& Science
University (OHSU) Hospital, encompassing EHRs from over 2.5 million patients
and more than 20 million patient encounters. Our results show that our proposed
approach effectively combines the power of SLs and LLMs, offering significant
improvements in predictive performance. This advancement holds promise for
revolutionizing ADRD screening and early detection practices, with potential
implications for better strategies of patient management and thus improving
healthcare.

ÊëòË¶ÅÔºöÈòøËå≤Êµ∑ÈªòÁóá (AD) ÊòØ 65 Ê≠≤‰ª•‰∏äÁæéÂúã‰∫∫ÁöÑÁ¨¨‰∫îÂ§ßÊ≠ªÂõ†„ÄÇAD ÂíåÁõ∏ÈóúÂ§±Êô∫Áóá (ADRD) ÁöÑÁØ©Ê™¢ÂíåÊó©ÊúüÂÅµÊ∏¨Â∞çÊñºÂèäÊôÇ‰ªãÂÖ•ÂíåÊâæÂá∫Ëá®Â∫äË©¶È©óÂèÉËàáËÄÖËá≥ÈóúÈáçË¶Å„ÄÇÈõªÂ≠êÁóÖÊ≠∑ (EHRs) ÁöÑÂª£Ê≥õÊé°Áî®Êèê‰æõ‰∫ÜÈñãÁôº ADRD ÁØ©Ê™¢Â∑•ÂÖ∑ÁöÑÈáçË¶ÅË≥áÊ∫êÔºå‰æãÂ¶ÇÂü∫ÊñºÊ©üÂô®Â≠∏ÁøíÁöÑÈ†êÊ∏¨Ê®°Âûã„ÄÇÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊúÄÊñ∞ÈÄ≤Â±ïÂ±ïÁ§∫Âá∫ÂÖ∂Á∑®Á¢ºÁü•Ë≠òÂíåÂü∑Ë°åÊé®ÁêÜÁöÑÁ©∫ÂâçËÉΩÂäõÔºåÈÄôÁÇ∫Â¢ûÂº∑È¢®Èö™È†êÊ∏¨Êèê‰æõ‰∫ÜÂº∑Â§ßÁöÑÊΩõÂäõ„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂâµÊñ∞ÁöÑÁÆ°ÈÅìÔºåÂÆÉÈÄöÈÅéÂà©Áî® LLM ÁöÑÂ∞ëÈáèÊé®ÁêÜËÉΩÂäõ‰æÜÂ¢ûÂº∑È¢®Èö™È†êÊ∏¨ÔºåÂ∞çÂÇ≥Áµ±Áõ£Áù£ÂºèÂ≠∏ÁøíÊñπÊ≥ï (SL) ÂèØËÉΩÁÑ°Ê≥ïÂãù‰ªªÁöÑÊ°à‰æãÈÄ≤Ë°åÈ†êÊ∏¨„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÈñãÁôº‰∫Ü‰∏ÄÂÄãÂçî‰ΩúÁÆ°ÈÅìÔºåÈÄöÈÅé‰ø°ÂøÉÈ©ÖÂãïÁöÑÊ±∫Á≠ñÊ©üÂà∂Â∞á SL Âíå LLM ÁµêÂêàËµ∑‰æÜÔºåÂà©Áî® SL Âú®ÊòéÁ¢∫Ê°à‰æã‰∏≠ÁöÑÂÑ™Âã¢Âíå LLM Âú®Êõ¥Ë§áÈõúÂ†¥ÊôØ‰∏≠ÁöÑÂÑ™Âã¢„ÄÇÊàëÂÄë‰ΩøÁî®‰æÜËá™‰øÑÂãíÂ≤°Â∑ûÂÅ•Â∫∑ËàáÁßëÂ≠∏Â§ßÂ≠∏ (OHSU) ÈÜ´Èô¢ÁöÑÁúüÂØ¶‰∏ñÁïå EHR Ë≥áÊñôÂÄâÂ∫´Ë©ï‰º∞‰∫ÜÈÄôÂÄãÁÆ°ÈÅìÔºåÂÖ∂‰∏≠ÂåÖÂê´‰æÜËá™ 250 Â§öËê¨ÂêçÊÇ£ËÄÖÂíå 2000 Â§öËê¨Ê¨°ÊÇ£ËÄÖÂ∞±Ë®∫ÁöÑ EHR„ÄÇÊàëÂÄëÁöÑÁµêÊûúË°®ÊòéÔºåÊàëÂÄëÊèêÂá∫ÁöÑÊñπÊ≥ïÊúâÊïàÂú∞ÁµêÂêà‰∫Ü SL Âíå LLM ÁöÑÂÑ™Âã¢ÔºåÂú®È†êÊ∏¨ÊÄßËÉΩÊñπÈù¢Êèê‰æõ‰∫ÜÈ°ØËëóÁöÑÊîπÈÄ≤„ÄÇÈÄôÈ†ÖÈÄ≤Â±ïÊúâÊúõÈù©Êñ∞ ADRD ÁØ©Ê™¢ÂíåÊó©ÊúüÂÅµÊ∏¨ÂØ¶ÂãôÔºåÂ∞çÊÇ£ËÄÖÁÆ°ÁêÜÁöÑÊõ¥Â•ΩÁ≠ñÁï•‰ª•ÂèäÊîπÂñÑÈÜ´ÁôÇ‰øùÂÅ•ÂÖ∑ÊúâÊΩõÂú®ÂΩ±Èüø„ÄÇ

##### **Assessing Empathy in Large Language Models with Real-World Physician-Patient Interactions**
2405.16402v1 by Man Luo, Christopher J. Warren, Lu Cheng, Haidar M. Abdul-Muhsin, Imon Banerjee

The integration of Large Language Models (LLMs) into the healthcare domain
has the potential to significantly enhance patient care and support through the
development of empathetic, patient-facing chatbots. This study investigates an
intriguing question Can ChatGPT respond with a greater degree of empathy than
those typically offered by physicians? To answer this question, we collect a
de-identified dataset of patient messages and physician responses from Mayo
Clinic and generate alternative replies using ChatGPT. Our analyses incorporate
novel empathy ranking evaluation (EMRank) involving both automated metrics and
human assessments to gauge the empathy level of responses. Our findings
indicate that LLM-powered chatbots have the potential to surpass human
physicians in delivering empathetic communication, suggesting a promising
avenue for enhancing patient care and reducing professional burnout. The study
not only highlights the importance of empathy in patient interactions but also
proposes a set of effective automatic empathy ranking metrics, paving the way
for the broader adoption of LLMs in healthcare.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Êï¥ÂêàÂà∞ÈÜ´ÁôÇÈ†òÂüü‰∏≠ÔºåÊúâÊΩõÂäõÈÄèÈÅéÈñãÁôºÂêåÁêÜÂøÉ„ÄÅÈù¢ÂêëÁóÖÊÇ£ÁöÑËÅäÂ§©Ê©üÂô®‰∫∫‰æÜÂ§ßÂπÖÊèêÂçáÁóÖÊÇ£ÁÖßË≠∑ÂíåÊîØÊåÅ„ÄÇÊú¨Á†îÁ©∂Êé¢Ë®é‰∫Ü‰∏ÄÂÄãÂºï‰∫∫ÂÖ•ÂãùÁöÑÂïèÈ°åÔºöChatGPT ËÉΩÂê¶ÊØî‰∏ÄËà¨ÈÜ´ÁîüÊèê‰æõÊõ¥Â§öÂêåÁêÜÂøÉÁöÑÂõûÊáâÔºüÁÇ∫‰∫ÜÂõûÁ≠îÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÊî∂ÈõÜ‰∫Ü‰∏ÄÁµÑ‰æÜËá™Ê¢ÖÁ¥ÑË®∫ÊâÄÁöÑÂéªË≠òÂà•ÂåñÁóÖÊÇ£Ë®äÊÅØÂíåÈÜ´ÁîüÂõûÊáâË≥áÊñôÈõÜÔºå‰∏¶‰ΩøÁî® ChatGPT Áî¢ÁîüÊõø‰ª£ÂõûÊáâ„ÄÇÊàëÂÄëÁöÑÂàÜÊûêÁµêÂêà‰∫ÜÊñ∞Á©éÁöÑÂêåÁêÜÂøÉÊéíÂêçË©ï‰º∞ (EMRank)ÔºåÂÖ∂‰∏≠ÂåÖÂê´Ëá™ÂãïÂåñÊåáÊ®ôÂíå‰∫∫ÁÇ∫Ë©ï‰º∞Ôºå‰ª•Ë©ïÈáèÂõûÊáâÁöÑÂêåÁêÜÂøÉÁ®ãÂ∫¶„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÈ°ØÁ§∫ÔºåLLM È©ÖÂãïÁöÑËÅäÂ§©Ê©üÂô®‰∫∫ÊúâÊΩõÂäõÂú®Êèê‰æõÂêåÁêÜÂøÉÊ∫ùÈÄöÊñπÈù¢Ë∂ÖË∂ä‰∫∫È°ûÈÜ´ÁîüÔºåÈÄôÊöóÁ§∫‰∫Ü‰∏ÄÊ¢ùÊèêÂçáÁóÖÊÇ£ÁÖßË≠∑ÂíåÊ∏õÂ∞ëÂ∞àÊ•≠ÂÄ¶ÊÄ†ÁöÑÊΩõÂú®ÈÄîÂæë„ÄÇÊú¨Á†îÁ©∂‰∏çÂÉÖÂº∑Ë™ø‰∫ÜÂêåÁêÜÂøÉÂú®ÁóÖÊÇ£‰∫íÂãï‰∏≠ÁöÑÈáçË¶ÅÊÄßÔºå‰πüÊèêÂá∫‰∫Ü‰∏ÄÁµÑÊúâÊïàÁöÑËá™ÂãïÂêåÁêÜÂøÉÊéíÂêçÊåáÊ®ôÔºåÁÇ∫ LLM Âú®ÈÜ´ÁôÇ‰øùÂÅ•È†òÂüüÁöÑÊõ¥Âª£Ê≥õÊé°Áî®Èã™Ë∑Ø„ÄÇ

##### **Uncertainty Measurement of Deep Learning System based on the Convex Hull of Training Sets**
2405.16082v1 by Hyekyoung Hwang, Jitae Shin

Deep Learning (DL) has made remarkable achievements in computer vision and
adopted in safety critical domains such as medical imaging or autonomous drive.
Thus, it is necessary to understand the uncertainty of the model to effectively
reduce accidents and losses due to misjudgment of the Deep Neural Networks
(DNN). This can start by efficiently selecting data that could potentially
malfunction to the model. Traditionally, data collection and labeling have been
done manually, but recently test data selection methods have emerged that focus
on capturing samples that are not relevant to what the model had been learned.
They're selected based on the activation pattern of neurons in DNN, entropy
minimization based on softmax output of the DL. However, these methods cannot
quantitatively analyze the extent to which unseen samples are extrapolated from
the training data. Therefore, we propose To-hull Uncertainty and Closure Ratio,
which measures an uncertainty of trained model based on the convex hull of
training data. It can observe the positional relation between the convex hull
of the learned data and an unseen sample and infer how extrapolate the sample
is from the convex hull. To evaluate the proposed method, we conduct empirical
studies on popular datasets and DNN models, compared to state-of-the art test
selection metrics. As a result of the experiment, the proposed To-hull
Uncertainty is effective in finding samples with unusual patterns (e.g.
adversarial attack) compared to the existing test selection metric.

ÊëòË¶ÅÔºöÊ∑±Â∫¶Â≠∏Áøí (DL) Âú®ÈõªËÖ¶Ë¶ñË¶∫ÊñπÈù¢ÂèñÂæó‰∫ÜÈ°ØËëóÁöÑÊàêÂ∞±Ôºå‰∏¶Ë¢´Êé°Áî®ÊñºÂÆâÂÖ®ÈóúÈçµÈ†òÂüüÔºå‰æãÂ¶ÇÈÜ´ÁôÇÂΩ±ÂÉèÊàñËá™ÂãïÈßïÈßõ„ÄÇÂõ†Ê≠§Ôºå‰∫ÜËß£Ê®°ÂûãÁöÑ‰∏çÁ¢∫ÂÆöÊÄßÂ∞çÊñºÊúâÊïàÊ∏õÂ∞ëÊ∑±Â∫¶Á•ûÁ∂ìÁ∂≤Ë∑Ø (DNN) Ë™§Âà§ÈÄ†ÊàêÁöÑÊÑèÂ§ñ‰∫ãÊïÖÂíåÊêçÂ§±ÊòØÂøÖË¶ÅÁöÑ„ÄÇÈÄôÂèØ‰ª•ÂæûÊúâÊïàÂú∞ÈÅ∏ÊìáÊΩõÂú®ÂèØËÉΩÂ∞éËá¥Ê®°ÂûãÊïÖÈöúÁöÑË≥áÊñôÈñãÂßã„ÄÇÂÇ≥Áµ±‰∏äÔºåË≥áÊñôÊî∂ÈõÜÂíåÊ®ôË®òÊòØÊâãÂãïÂÆåÊàêÁöÑÔºå‰ΩÜÊúÄËøëÂá∫Áèæ‰∫ÜÊ∏¨Ë©¶Ë≥áÊñôÈÅ∏ÂèñÊñπÊ≥ïÔºåÂÖ∂ÈáçÈªûÂú®ÊñºÊì∑ÂèñËàáÊ®°ÂûãÊâÄÂ≠∏ÁøíÂÖßÂÆπÁÑ°ÈóúÁöÑÊ®£Êú¨„ÄÇÂÆÉÂÄëÊòØÊ†πÊìö DNN ‰∏≠Á•ûÁ∂ìÂÖÉÁöÑÊøÄÊ¥ªÊ®°Âºè„ÄÅÂü∫Êñº DL ÁöÑ softmax Ëº∏Âá∫ÁöÑÁÜµÊúÄÂ∞èÂåñ‰æÜÈÅ∏ÊìáÁöÑ„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÊñπÊ≥ïÁÑ°Ê≥ïÈáèÂåñÂàÜÊûêÊú™Ë¶ãÊ®£Êú¨ÂæûË®ìÁ∑¥Ë≥áÊñô‰∏≠Â§ñÊé®ÁöÑÁ®ãÂ∫¶„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü To-hull ‰∏çÁ¢∫ÂÆöÊÄßÂíåÂ∞ÅÈñâÊØîÁéáÔºåÂÆÉÊ†πÊìöË®ìÁ∑¥Ë≥áÊñôÁöÑÂá∏ÂåÖÊ∏¨ÈáèË®ìÁ∑¥Ê®°ÂûãÁöÑ‰∏çÁ¢∫ÂÆöÊÄß„ÄÇÂÆÉÂèØ‰ª•ËßÄÂØüÂ∑≤Â≠∏ÁøíË≥áÊñôÁöÑÂá∏ÂåÖÂíåÊú™Ë¶ãÊ®£Êú¨‰πãÈñìÁöÑ‰ΩçÁΩÆÈóú‰øÇÔºå‰∏¶Êé®Ë´ñÊ®£Êú¨ÊòØÂ¶Ç‰ΩïÂæûÂá∏ÂåÖ‰∏≠Â§ñÊé®ÁöÑ„ÄÇÁÇ∫‰∫ÜË©ï‰º∞ÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÔºåÊàëÂÄëÂ∞çÊµÅË°åÁöÑË≥áÊñôÈõÜÂíå DNN Ê®°ÂûãÈÄ≤Ë°åÂØ¶Ë≠âÁ†îÁ©∂Ôºå‰∏¶ËàáÊúÄÂÖàÈÄ≤ÁöÑÊ∏¨Ë©¶ÈÅ∏ÊìáÊåáÊ®ôÈÄ≤Ë°åÊØîËºÉ„ÄÇÂØ¶È©óÁµêÊûúÈ°ØÁ§∫ÔºåËàáÁèæÊúâÁöÑÊ∏¨Ë©¶ÈÅ∏ÊìáÊåáÊ®ôÁõ∏ÊØîÔºåÊâÄÊèêÂá∫ÁöÑ To-hull ‰∏çÁ¢∫ÂÆöÊÄßÂú®Â∞ãÊâæÂÖ∑ÊúâÁï∞Â∏∏Ê®°ÂºèÔºà‰æãÂ¶ÇÂ∞çÊäóÊÄßÊîªÊìäÔºâÁöÑÊ®£Êú¨ÊñπÈù¢ÊòØÊúâÊïàÁöÑ„ÄÇ

##### **Transductive Confidence Machine and its application to Medical Data Sets**
2405.15988v1 by David Lindsay

The Transductive Confidence Machine Nearest Neighbours (TCMNN) algorithm and
a supporting, simple user interface was developed. Different settings of the
TCMNN algorithms' parameters were tested on medical data sets, in addition to
the use of different Minkowski metrics and polynomial kernels. The effect of
increasing the number of nearest neighbours and marking results with
significance was also investigated. SVM implementation of the Transductive
Confidence Machine was compared with Nearest Neighbours implementation. The
application of neural networks was investigated as a useful comparison to the
transductive algorithms.

ÊëòË¶ÅÔºöÈñãÁôº‰∫ÜËΩâÂ∞é‰ø°ÂøÉÊ©üÂô®ÊúÄËøëÈÑ∞Â±Ö (TCMNN) ÊºîÁÆóÊ≥ïÂíåÊîØÊè¥ÊÄßÁöÑÁ∞°ÂñÆ‰ΩøÁî®ËÄÖ‰ªãÈù¢„ÄÇÈô§‰∫Ü‰ΩøÁî®‰∏çÂêåÁöÑÊòéÂèØÂ§´ÊñØÂü∫Â∫¶ÈáèÂíåÂ§öÈ†ÖÂºèÊ†∏‰πãÂ§ñÔºåÈÇÑÈáùÂ∞çÈÜ´ÁôÇË≥áÊñôÈõÜÊ∏¨Ë©¶‰∫Ü TCMNN ÊºîÁÆóÊ≥ïÂèÉÊï∏ÁöÑ‰∏çÂêåË®≠ÂÆö„ÄÇ‰πüÊé¢Ë®é‰∫ÜÂ¢ûÂä†ÊúÄËøëÈÑ∞Â±ÖÊï∏ÁõÆÂíåÊ®ôË®òÁµêÊûúÈ°ØËëóÊÄßÁöÑÂΩ±Èüø„ÄÇÂ∞áËΩâÂ∞é‰ø°ÂøÉÊ©üÂô®ÁöÑ SVM ÂØ¶‰ΩúËàáÊúÄËøëÈÑ∞Â±ÖÂØ¶‰ΩúÈÄ≤Ë°åÊØîËºÉ„ÄÇÊé¢Ë®é‰∫ÜÁ•ûÁ∂ìÁ∂≤Ë∑ØÁöÑÊáâÁî®Ôºå‰ΩúÁÇ∫Â∞çËΩâÂ∞éÊºîÁÆóÊ≥ïÊúâÁî®ÁöÑÊØîËºÉ„ÄÇ

##### **The Impact and Opportunities of Generative AI in Fact-Checking**
2405.15985v1 by Robert Wolfe, Tanushree Mitra

Generative AI appears poised to transform white collar professions, with more
than 90% of Fortune 500 companies using OpenAI's flagship GPT models, which
have been characterized as "general purpose technologies" capable of effecting
epochal changes in the economy. But how will such technologies impact
organizations whose job is to verify and report factual information, and to
ensure the health of the information ecosystem? To investigate this question,
we conducted 30 interviews with N=38 participants working at 29 fact-checking
organizations across six continents, asking about how they use generative AI
and the opportunities and challenges they see in the technology. We found that
uses of generative AI envisioned by fact-checkers differ based on
organizational infrastructure, with applications for quality assurance in
Editing, for trend analysis in Investigation, and for information literacy in
Advocacy. We used the TOE framework to describe participant concerns ranging
from the Technological (lack of transparency), to the Organizational (resource
constraints), to the Environmental (uncertain and evolving policy). Building on
the insights of our participants, we describe value tensions between
fact-checking and generative AI, and propose a novel Verification dimension to
the design space of generative models for information verification work.
Finally, we outline an agenda for fairness, accountability, and transparency
research to support the responsible use of generative AI in fact-checking.
Throughout, we highlight the importance of human infrastructure and labor in
producing verified information in collaboration with AI. We expect that this
work will inform not only the scientific literature on fact-checking, but also
contribute to understanding of organizational adaptation to a powerful but
unreliable new technology.

ÊëòË¶ÅÔºöÁîüÊàêÂºè AI ‰ºº‰πéÊ∫ñÂÇôËΩâËÆäÁôΩÈ†òËÅ∑Ê•≠ÔºåË∂ÖÈÅé 90% ÁöÑË≤°ÂØå 500 Â§ß‰ºÅÊ•≠‰ΩøÁî® OpenAI ÁöÑÊóóËâ¶ GPT Ê®°ÂûãÔºåÈÄô‰∫õÊ®°ÂûãË¢´Á®±ÁÇ∫„ÄåÈÄöÁî®ÊäÄË°ì„ÄçÔºåËÉΩÂ§†Â∞çÁ∂ìÊøüÁî¢ÁîüÂäÉÊôÇ‰ª£ÁöÑÊîπËÆä„ÄÇ‰ΩÜÈÄô‰∫õÊäÄË°ìÂ∞áÂ¶Ç‰ΩïÂΩ±ÈüøË≤†Ë≤¨È©óË≠âÂíåÂ†±Â∞é‰∫ãÂØ¶Ë≥áË®äÔºå‰∏¶Á¢∫‰øùË≥áË®äÁîüÊÖãÁ≥ªÁµ±ÂÅ•Â∫∑ÁöÑÁµÑÁπîÔºüÁÇ∫‰∫ÜÊé¢Ë®éÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÂ∞çÊ©´Ë∑®ÂÖ≠Â§ßÊ¥≤ÁöÑ 29 ÂÄãÊü•Ê†∏‰∫ãÂØ¶ÁµÑÁπî‰∏≠‰ªªËÅ∑ÁöÑ N=38 ÂêçÂèÉËàáËÄÖÈÄ≤Ë°å‰∫Ü 30 Ê¨°Ë®™Ë´áÔºåË©¢Âïè‰ªñÂÄëÂ¶Ç‰Ωï‰ΩøÁî®ÁîüÊàêÂºè AIÔºå‰ª•Âèä‰ªñÂÄëÂú®ÊäÄË°ì‰∏≠ÁúãÂà∞ÁöÑÊ©üÊúÉÂíåÊåëÊà∞„ÄÇÊàëÂÄëÁôºÁèæÊü•Ê†∏‰∫∫Âì°Ë®≠ÊÉ≥ÁöÑÁîüÊàêÂºè AI Áî®ÈÄîÂõ†ÁµÑÁπîÂü∫Á§éÊû∂ÊßãËÄåÁï∞ÔºåÂú®Á∑®ËºØ‰∏≠ÊáâÁî®ÊñºÂìÅË≥™‰øùË≠â„ÄÅÂú®Ë™øÊü•‰∏≠ÊáâÁî®ÊñºË∂®Âã¢ÂàÜÊûê„ÄÅÂú®ÂÄ°Ë≠∞‰∏≠ÊáâÁî®ÊñºË≥áË®äÁ¥†È§ä„ÄÇÊàëÂÄë‰ΩøÁî® TOE Êû∂Êßã‰æÜÊèèËø∞ÂèÉËàáËÄÖÁöÑÁñëÊÖÆÔºåÁØÑÂúçÂæûÊäÄË°ìÔºàÁº∫‰πèÈÄèÊòéÂ∫¶Ôºâ„ÄÅÁµÑÁπîÔºàË≥áÊ∫êÈôêÂà∂ÔºâÂà∞Áí∞Â¢ÉÔºà‰∏çÁ¢∫ÂÆö‰∏î‰∏çÊñ∑ÊºîËÆäÁöÑÊîøÁ≠ñÔºâ„ÄÇÊ†πÊìöÂèÉËàáËÄÖÁöÑË¶ãËß£ÔºåÊàëÂÄëÊèèËø∞‰∫ÜÊü•Ê†∏‰∫ãÂØ¶ÂíåÁîüÊàêÂºè AI ‰πãÈñìÁöÑÂÉπÂÄºÁ∑äÂºµÈóú‰øÇÔºå‰∏¶ÁÇ∫Ë≥áË®äÈ©óË≠âÂ∑•‰Ωú‰∏≠ÁîüÊàêÂºèÊ®°ÂûãÁöÑË®≠Ë®àÁ©∫ÈñìÊèêÂá∫‰∫ÜÊñ∞ÁöÑÈ©óË≠âÈù¢Âêë„ÄÇÊúÄÂæåÔºåÊàëÂÄëÊ¶ÇËø∞‰∫ÜÂÖ¨Âπ≥ÊÄß„ÄÅÂïèË≤¨Âà∂ÂíåÈÄèÊòéÂ∫¶Á†îÁ©∂Ë≠∞Á®ãÔºå‰ª•ÊîØÊåÅÂú®Êü•Ê†∏‰∫ãÂØ¶‰∏≠Ë≤†Ë≤¨‰ªªÂú∞‰ΩøÁî®ÁîüÊàêÂºè AI„ÄÇÂú®Êï¥ÂÄãÈÅéÁ®ã‰∏≠ÔºåÊàëÂÄëÂº∑Ë™ø‰∫Ü‰∫∫È°ûÂü∫Á§éÊû∂ÊßãÂíåÂãûÂãïÂäõÂú®Ëàá AI Âêà‰ΩúÁî¢ÁîüÂ∑≤È©óË≠âË≥áË®ä‰∏≠ÁöÑÈáçË¶ÅÊÄß„ÄÇÊàëÂÄëÈ†êÊúüÈÄôÈ†ÖÂ∑•‰Ωú‰∏çÂÉÖÊúÉÁÇ∫Êü•Ê†∏‰∫ãÂØ¶ÁöÑÁßëÂ≠∏ÊñáÁçªÊèê‰æõË≥áË®äÔºåÈÇÑËÉΩÊúâÂä©Êñº‰∫ÜËß£ÁµÑÁπîÂ¶Ç‰ΩïÈÅ©ÊáâÂº∑Â§ß‰ΩÜ‰∏çÂèØÈù†ÁöÑÊñ∞ÊäÄË°ì„ÄÇ

##### **Risk Factor Identification In Osteoporosis Using Unsupervised Machine Learning Techniques**
2405.15882v1 by Mikayla Calitis

In this study, the reliability of identified risk factors associated with
osteoporosis is investigated using a new clustering-based method on electronic
medical records. This study proposes utilizing a new CLustering Iterations
Framework (CLIF) that includes an iterative clustering framework that can adapt
any of the following three components: clustering, feature selection, and
principal feature identification. The study proposes using Wasserstein distance
to identify principal features, borrowing concepts from the optimal transport
theory. The study also suggests using a combination of ANOVA and ablation tests
to select influential features from a data set. Some risk factors presented in
existing works are endorsed by our identified significant clusters, while the
reliability of some other risk factors is weakened.

ÊëòË¶ÅÔºöÊú¨Á†îÁ©∂Âà©Áî®ÈõªÂ≠êÁóÖÊ≠∑‰∏≠Âü∫ÊñºÊñ∞Áæ§ÈõÜÁöÑÊñπÊ≥ïÔºåÊé¢Ë®éÂ∑≤Ë≠òÂà•‰πãÈ™®Ë≥™ÁñèÈ¨ÜÁóáÁõ∏ÈóúÈ¢®Èö™Âõ†Â≠êÁöÑÂèØÈù†ÊÄß„ÄÇÊú¨Á†îÁ©∂ÊèêÂá∫Âà©Áî®Êñ∞ÁöÑÁæ§ÈõÜËø≠‰ª£Êû∂Êßã (CLIF)ÔºåÂÖ∂‰∏≠ÂåÖÂê´‰∏ÄÂÄãËø≠‰ª£Áæ§ÈõÜÊû∂ÊßãÔºåÂèØË™øÊï¥‰ª•‰∏ã‰∏âÈ†ÖÁµÑÊàêÔºöÁæ§ÈõÜ„ÄÅÁâπÂæµÈÅ∏ÊìáÂíå‰∏ªË¶ÅÁâπÂæµË≠òÂà•„ÄÇÊú¨Á†îÁ©∂ÊèêÂá∫‰ΩøÁî® Wasserstein Ë∑ùÈõ¢‰æÜË≠òÂà•‰∏ªË¶ÅÁâπÂæµÔºåÂÄüÁî®ÊúÄÂÑ™ÂÇ≥Ëº∏ÁêÜË´ñ‰∏≠ÁöÑÊ¶ÇÂøµ„ÄÇÊú¨Á†îÁ©∂ÈÇÑÂª∫Ë≠∞‰ΩøÁî® ANOVA ÂíåÊ∂àËûçÊ∏¨Ë©¶ÁöÑÁµÑÂêàÔºåÂæûË≥áÊñôÈõÜ‰∏≠ÈÅ∏ÊìáÊúâÂΩ±ÈüøÂäõÁöÑÁâπÂæµ„ÄÇÁèæÊúâÁ†îÁ©∂‰∏≠ÂëàÁèæÁöÑÊüê‰∫õÈ¢®Èö™Âõ†Â≠êÂèóÂà∞ÊàëÂÄëË≠òÂà•Âá∫ÁöÑÈ°ØËëóÁæ§ÈõÜÁöÑË™çÂèØÔºåËÄåÊüê‰∫õÂÖ∂‰ªñÈ¢®Èö™Âõ†Â≠êÁöÑÂèØÈù†ÊÄßÂâáË¢´ÂâäÂº±„ÄÇ

##### **Enhancing Adverse Drug Event Detection with Multimodal Dataset: Corpus Creation and Model Development**
2405.15766v2 by Pranab Sahoo, Ayush Kumar Singh, Sriparna Saha, Aman Chadha, Samrat Mondal

The mining of adverse drug events (ADEs) is pivotal in pharmacovigilance,
enhancing patient safety by identifying potential risks associated with
medications, facilitating early detection of adverse events, and guiding
regulatory decision-making. Traditional ADE detection methods are reliable but
slow, not easily adaptable to large-scale operations, and offer limited
information. With the exponential increase in data sources like social media
content, biomedical literature, and Electronic Medical Records (EMR),
extracting relevant ADE-related information from these unstructured texts is
imperative. Previous ADE mining studies have focused on text-based
methodologies, overlooking visual cues, limiting contextual comprehension, and
hindering accurate interpretation. To address this gap, we present a MultiModal
Adverse Drug Event (MMADE) detection dataset, merging ADE-related textual
information with visual aids. Additionally, we introduce a framework that
leverages the capabilities of LLMs and VLMs for ADE detection by generating
detailed descriptions of medical images depicting ADEs, aiding healthcare
professionals in visually identifying adverse events. Using our MMADE dataset,
we showcase the significance of integrating visual cues from images to enhance
overall performance. This approach holds promise for patient safety, ADE
awareness, and healthcare accessibility, paving the way for further exploration
in personalized healthcare.

ÊëòË¶ÅÔºöËó•Áâ©Ë≠¶Êàí‰∏≠Ôºå‰∏çËâØËó•Áâ©‰∫ã‰ª∂ÔºàADEÔºâÁöÑÊåñÊéòËá≥ÈóúÈáçË¶ÅÔºå
ÈÄèÈÅéË≠òÂà•ËàáËó•Áâ©Áõ∏ÈóúÁöÑÊΩõÂú®È¢®Èö™Ôºå‰øÉÈÄ≤ÊÇ£ËÄÖÂÆâÂÖ®ÔºåÂçîÂä©ÊèêÊó©ÂÅµÊ∏¨‰∏çËâØ‰∫ã‰ª∂Ôºå‰∏¶ÂºïÂ∞éÊ≥ïË¶èÊ±∫Á≠ñ„ÄÇÂÇ≥Áµ±ÁöÑ ADE ÂÅµÊ∏¨ÊñπÊ≥ïÂèØÈù†Ôºå‰ΩÜÈÄüÂ∫¶ÊÖ¢Ôºå‰∏çÊòìÈÅ©ÊáâÂ§ßË¶èÊ®°‰ΩúÊ•≠Ôºå‰∏îÊèê‰æõÊúâÈôêÁöÑË≥áË®ä„ÄÇÈö®ËëóÁ§æÁæ§Â™íÈ´îÂÖßÂÆπ„ÄÅÁîüÁâ©ÈÜ´Â≠∏ÊñáÁçªÂíåÈõªÂ≠êÁóÖÊ≠∑ (EMR) Á≠âË≥áÊñô‰æÜÊ∫êÂëàÊåáÊï∏Á¥öÂ¢ûÂä†ÔºåÂæûÈÄô‰∫õÈùûÁµêÊßãÂåñÊñáÂ≠ó‰∏≠ËêÉÂèñÁõ∏ÈóúÁöÑ ADE Áõ∏ÈóúË≥áË®äËá≥ÈóúÈáçË¶Å„ÄÇÂÖàÂâçÁöÑ ADE ÊåñÊéòÁ†îÁ©∂ËëóÈáçÊñºÂü∫ÊñºÊñáÂ≠óÁöÑÊñπÊ≥ïÔºåÂøΩÁï•‰∫ÜË¶ñË¶∫Á∑öÁ¥¢ÔºåÈôêÂà∂‰∫ÜËÑàÁµ°ÁêÜËß£Ôºå‰∏¶ÈòªÁ§ô‰∫ÜÊ∫ñÁ¢∫ÁöÑË©ÆÈáã„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂ∑ÆË∑ùÔºåÊàëÂÄëÊèêÂá∫‰∫ÜÂ§öÊ®°Âºè‰∏çËâØËó•Áâ©‰∫ã‰ª∂ (MMADE) ÂÅµÊ∏¨Ë≥áÊñôÈõÜÔºåÂ∞á ADE Áõ∏ÈóúÁöÑÊñáÂ≠óË≥áË®äËàáË¶ñË¶∫ËºîÂä©Â∑•ÂÖ∑Âêà‰Ωµ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÈÇÑÂ∞éÂÖ•‰∫Ü‰∏ÄÂÄãÊû∂ÊßãÔºåÂà©Áî® LLM Âíå VLM ÁöÑÂäüËÉΩÈÄ≤Ë°å ADE ÂÅµÊ∏¨ÔºåÈÄèÈÅéÁî¢ÁîüÊèèÁπ™ ADE ÁöÑÈÜ´Â≠∏ÂΩ±ÂÉèÁöÑË©≥Á¥∞ÊèèËø∞ÔºåÂçîÂä©ÈÜ´ÁôÇÂ∞àÊ•≠‰∫∫Âì°Ë¶ñË¶∫ÂåñË≠òÂà•‰∏çËâØ‰∫ã‰ª∂„ÄÇ‰ΩøÁî®ÊàëÂÄëÁöÑ MMADE Ë≥áÊñôÈõÜÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜÊï¥ÂêàÂΩ±ÂÉèË¶ñË¶∫Á∑öÁ¥¢‰ª•Â¢ûÂº∑Êï¥È´îÊïàËÉΩÁöÑÈáçË¶ÅÊÄß„ÄÇÈÄôÁ®ÆÊñπÊ≥ïÊúâÊúõÊèêÂçáÊÇ£ËÄÖÂÆâÂÖ®„ÄÅADE ÊÑèË≠òÂíåÈÜ´ÁôÇ‰øùÂÅ•ÁöÑÂèØÂèäÊÄßÔºåÁÇ∫ÂÄã‰∫∫ÂåñÈÜ´ÁôÇ‰øùÂÅ•ÁöÑÈÄ≤‰∏ÄÊ≠•Êé¢Á¥¢Èã™Ë∑Ø„ÄÇ

##### **Medformer: A Multi-Granularity Patching Transformer for Medical Time-Series Classification**
2405.19363v1 by Yihe Wang, Nan Huang, Taida Li, Yujun Yan, Xiang Zhang

Medical time series data, such as Electroencephalography (EEG) and
Electrocardiography (ECG), play a crucial role in healthcare, such as
diagnosing brain and heart diseases. Existing methods for medical time series
classification primarily rely on handcrafted biomarkers extraction and
CNN-based models, with limited exploration of transformers tailored for medical
time series. In this paper, we introduce Medformer, a multi-granularity
patching transformer tailored specifically for medical time series
classification. Our method incorporates three novel mechanisms to leverage the
unique characteristics of medical time series: cross-channel patching to
leverage inter-channel correlations, multi-granularity embedding for capturing
features at different scales, and two-stage (intra- and inter-granularity)
multi-granularity self-attention for learning features and correlations within
and among granularities. We conduct extensive experiments on five public
datasets under both subject-dependent and challenging subject-independent
setups. Results demonstrate Medformer's superiority over 10 baselines,
achieving top averaged ranking across five datasets on all six evaluation
metrics. These findings underscore the significant impact of our method on
healthcare applications, such as diagnosing Myocardial Infarction, Alzheimer's,
and Parkinson's disease. We release the source code at
\url{https://github.com/DL4mHealth/Medformer}.

ÊëòË¶ÅÔºöÈÜ´Â≠∏ÊôÇÈñìÂ∫èÂàóË≥áÊñôÔºå‰æãÂ¶ÇËÖ¶ÈõªÂúñ (EEG) ÂíåÂøÉÈõªÂúñ (ECG)ÔºåÂú®ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÊâÆÊºîËëóËá≥ÈóúÈáçË¶ÅÁöÑËßíËâ≤Ôºå‰æãÂ¶ÇË®∫Êñ∑ËÖ¶ÈÉ®ÂíåÂøÉËáüÁñæÁóÖ„ÄÇÁèæÊúâÁöÑÈÜ´Â≠∏ÊôÇÈñìÂ∫èÂàóÂàÜÈ°ûÊñπÊ≥ï‰∏ªË¶Å‰æùË≥¥ÊñºÊâãÂ∑•Ë£Ω‰ΩúÁöÑÁîüÁâ©Ê®ôË®òËêÉÂèñÂíåÂü∫Êñº CNN ÁöÑÊ®°ÂûãÔºåÂ∞çÊñºÂ∞àÈñÄÈáùÂ∞çÈÜ´Â≠∏ÊôÇÈñìÂ∫èÂàóÈáèË∫´ÊâìÈÄ†ÁöÑËΩâÊèõÂô®ÂâáÊé¢Á¥¢ÊúâÈôê„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫Ü MedformerÔºå‰∏ÄÂÄãÂ∞àÈñÄÈáùÂ∞çÈÜ´Â≠∏ÊôÇÈñìÂ∫èÂàóÂàÜÈ°ûÈáèË∫´ÊâìÈÄ†ÁöÑÂ§öÁ≤íÂ∫¶Ë£ú‰∏ÅËΩâÊèõÂô®„ÄÇÊàëÂÄëÁöÑÊäÄË°ìÁµêÂêà‰∫Ü‰∏âÁ®ÆÊñ∞Á©éÁöÑÊ©üÂà∂‰æÜÂà©Áî®ÈÜ´Â≠∏ÊôÇÈñìÂ∫èÂàóÁöÑÁç®ÁâπÁâπÂæµÔºöË∑®ÈÄöÈÅìË£ú‰∏Å‰ª•Âà©Áî®ÈÄöÈÅìÈñìÁõ∏ÈóúÊÄß„ÄÅÂ§öÁ≤íÂ∫¶ÂµåÂÖ•‰ª•Êì∑Âèñ‰∏çÂêåÂ∞∫Â∫¶ÁöÑÁâπÂæµÔºå‰ª•ÂèäÂÖ©ÈöéÊÆµÔºàÁ≤íÂ∫¶ÂÖßÂíåÁ≤íÂ∫¶ÈñìÔºâÂ§öÁ≤íÂ∫¶Ëá™ÊàëÊ≥®ÊÑèÔºå‰ª•Â≠∏ÁøíÁ≤íÂ∫¶ÂÖßÂíåÁ≤íÂ∫¶ÈñìÁöÑÁâπÂæµÂíåÁõ∏ÈóúÊÄß„ÄÇÊàëÂÄëÂú®‰∫îÂÄãÂÖ¨ÂÖ±Ë≥áÊñôÈõÜ‰∏äÈÄ≤Ë°å‰∫ÜÂª£Ê≥õÁöÑÂØ¶È©óÔºåÂåÖÊã¨‰æùË≥¥ÂèóË©¶ËÄÖÂíåÂÖ∑ÊúâÊåëÊà∞ÊÄßÁöÑÁç®Á´ãÂèóË©¶ËÄÖË®≠ÂÆö„ÄÇÁµêÊûúÈ°ØÁ§∫ Medformer ÂÑ™Êñº 10 ÂÄãÂü∫Ê∫ñÔºåÂú®ÊâÄÊúâÂÖ≠ÂÄãË©ï‰º∞ÊåáÊ®ô‰∏äÔºåÂú®‰∫îÂÄãË≥áÊñôÈõÜ‰∏äÁç≤ÂæóÊúÄÈ´òÁöÑÂπ≥ÂùáÊéíÂêç„ÄÇÈÄô‰∫õÁôºÁèæÂº∑Ë™ø‰∫ÜÊàëÂÄëÁöÑÊñπÊ≥ïÂ∞çÈÜ´ÁôÇ‰øùÂÅ•ÊáâÁî®Ôºà‰æãÂ¶ÇË®∫Êñ∑ÂøÉËÇåÊ¢óÂ°û„ÄÅÈòøËå≤Êµ∑ÈªòÁóáÂíåÂ∏ïÈáëÊ£ÆÊ∞èÁóáÔºâÁöÑÈáçÂ§ßÂΩ±Èüø„ÄÇÊàëÂÄëÂú® \url{https://github.com/DL4mHealth/Medformer} ÈáãÂá∫ÂéüÂßãÁ¢º„ÄÇ

##### **Effective Confidence Region Prediction Using Probability Forecasters**
2405.15642v1 by David Lindsay, Sian Lindsay

Confidence region prediction is a practically useful extension to the
commonly studied pattern recognition problem. Instead of predicting a single
label, the constraint is relaxed to allow prediction of a subset of labels
given a desired confidence level 1-delta. Ideally, effective region predictions
should be (1) well calibrated - predictive regions at confidence level 1-delta
should err with relative frequency at most delta and (2) be as narrow (or
certain) as possible. We present a simple technique to generate confidence
region predictions from conditional probability estimates (probability
forecasts). We use this 'conversion' technique to generate confidence region
predictions from probability forecasts output by standard machine learning
algorithms when tested on 15 multi-class datasets. Our results show that
approximately 44% of experiments demonstrate well-calibrated confidence region
predictions, with the K-Nearest Neighbour algorithm tending to perform
consistently well across all data. Our results illustrate the practical
benefits of effective confidence region prediction with respect to medical
diagnostics, where guarantees of capturing the true disease label can be given.

ÊëòË¶ÅÔºöÁΩÆ‰ø°ÂçÄÂüüÈ†êÊ∏¨ÊòØÂ∞çÂ∏∏Ë¶ãÊ®°ÂºèË≠òÂà•ÂïèÈ°åÂØ¶Áî®ÁöÑÂª∂‰º∏„ÄÇÂÆÉ‰∏¶ÈùûÈ†êÊ∏¨ÂñÆ‰∏ÄÊ®ôÁ±§ÔºåËÄåÊòØÊîæÂØ¨ÈôêÂà∂ÔºåÂÖÅË®±È†êÊ∏¨Áµ¶ÂÆöÊâÄÈúÄÁΩÆ‰ø°Ê∞¥Ê∫ñ 1-delta ÁöÑÊ®ôÁ±§Â≠êÈõÜ„ÄÇÁêÜÊÉ≥ÊÉÖÊ≥Å‰∏ãÔºåÊúâÊïàÁöÑÂçÄÂüüÈ†êÊ∏¨ÊáâÁÇ∫Ôºö(1) Ê†°Ê∫ñËâØÂ•Ω - ÁΩÆ‰ø°Ê∞¥Ê∫ñÁÇ∫ 1-delta ÁöÑÈ†êÊ∏¨ÂçÄÂüüÊáâ‰ª•ÊúÄÂ§ö delta ÁöÑÁõ∏Â∞çÈ†ªÁéáÂá∫ÁèæË™§Â∑ÆÔºå‰∏î (2) Áõ°ÂèØËÉΩÁ™ÑÔºàÊàñÁ¢∫ÂÆöÔºâ„ÄÇÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÁ∞°ÂñÆÁöÑÊäÄË°ìÔºåÂæûÊ¢ù‰ª∂Ê©üÁéá‰º∞Ë®àÔºàÊ©üÁéáÈ†êÊ∏¨ÔºâÁî¢ÁîüÁΩÆ‰ø°ÂçÄÂüüÈ†êÊ∏¨„ÄÇÊàëÂÄë‰ΩøÁî®Ê≠§„ÄåËΩâÊèõ„ÄçÊäÄË°ìÔºåÂæûÊ®ôÊ∫ñÊ©üÂô®Â≠∏ÁøíÊºîÁÆóÊ≥ïÂú® 15 ÂÄãÂ§öÈ°ûÂà•Ë≥áÊñôÈõÜ‰∏äÊ∏¨Ë©¶ÊôÇËº∏Âá∫ÁöÑÊ©üÁéáÈ†êÊ∏¨Áî¢ÁîüÁΩÆ‰ø°ÂçÄÂüüÈ†êÊ∏¨„ÄÇÊàëÂÄëÁöÑÁµêÊûúÈ°ØÁ§∫ÔºåÁ¥ÑÊúâ 44% ÁöÑÂØ¶È©óÂ±ïÁ§∫Âá∫Ê†°Ê∫ñËâØÂ•ΩÁöÑÁΩÆ‰ø°ÂçÄÂüüÈ†êÊ∏¨ÔºåËÄå K-ÊúÄËøëÈÑ∞ÊºîÁÆóÊ≥ïÂú®ÊâÄÊúâË≥áÊñô‰∏äÈÉΩÂÇæÂêëÊñºË°®ÁèæÁ©©ÂÆöËâØÂ•Ω„ÄÇÊàëÂÄëÁöÑÁµêÊûúË™™Êòé‰∫ÜÊúâÊïàÁΩÆ‰ø°ÂçÄÂüüÈ†êÊ∏¨Âú®ÈÜ´Â≠∏Ë®∫Êñ∑ÊñπÈù¢ÁöÑÂØ¶ÈöõÊïàÁõäÔºåÂÖ∂‰∏≠ÂèØ‰ª•‰øùË≠âÊçïÊçâÂà∞ÁúüÊ≠£ÁöÑÁñæÁóÖÊ®ôÁ±§„ÄÇ

##### **Concept-based Explainable Malignancy Scoring on Pulmonary Nodules in CT Images**
2405.17483v1 by Rinat I. Dumaev, Sergei A. Molodyakov, Lev V. Utkin

To increase the transparency of modern computer-aided diagnosis (CAD) systems
for assessing the malignancy of lung nodules, an interpretable model based on
applying the generalized additive models and the concept-based learning is
proposed. The model detects a set of clinically significant attributes in
addition to the final malignancy regression score and learns the association
between the lung nodule attributes and a final diagnosis decision as well as
their contributions into the decision. The proposed concept-based learning
framework provides human-readable explanations in terms of different concepts
(numerical and categorical), their values, and their contribution to the final
prediction. Numerical experiments with the LIDC-IDRI dataset demonstrate that
the diagnosis results obtained using the proposed model, which explicitly
explores internal relationships, are in line with similar patterns observed in
clinical practice. Additionally, the proposed model shows the competitive
classification and the nodule attribute scoring performance, highlighting its
potential for effective decision-making in the lung nodule diagnosis.

ÊëòË¶ÅÔºöÁÇ∫‰∫ÜÊèêÂçáÁèæ‰ª£ÈõªËÖ¶ËºîÂä©Ë®∫Êñ∑ÔºàCADÔºâÁ≥ªÁµ±Â∞çËÇ∫ÁµêÁØÄÊÉ°ÊÄßÁ®ãÂ∫¶Ë©ï‰º∞ÁöÑÈÄèÊòéÂ∫¶ÔºåÊèêÂá∫‰∏ÄÂÄãÂü∫ÊñºÂª£Áæ©Âä†Ê≥ïÊ®°ÂûãÂíåÂü∫ÊñºÊ¶ÇÂøµÁöÑÂ≠∏ÁøíÁöÑÂèØËß£ÈáãÊ®°Âûã„ÄÇÊ≠§Ê®°ÂûãÈô§‰∫ÜÊúÄÁµÇÊÉ°ÊÄßÂõûÊ≠∏ÂàÜÊï∏Â§ñÔºåÈÇÑËÉΩÂÅµÊ∏¨‰∏ÄÁµÑËá®Â∫äÈ°ØËëóÂ±¨ÊÄßÔºå‰∏¶Â≠∏ÁøíËÇ∫ÁµêÁØÄÂ±¨ÊÄßËàáÊúÄÁµÇË®∫Êñ∑Ê±∫Á≠ñ‰πãÈñìÁöÑÈóúËÅØÔºå‰ª•ÂèäÂÆÉÂÄëÂ∞çÊ±∫Á≠ñÁöÑË≤¢Áçª„ÄÇÊâÄÊèêÂá∫ÁöÑÂü∫ÊñºÊ¶ÇÂøµÁöÑÂ≠∏ÁøíÊû∂ÊßãÊèê‰æõ‰∫∫È°ûÂèØËÆÄÁöÑËß£ÈáãÔºåÂåÖÊã¨‰∏çÂêåÁöÑÊ¶ÇÂøµÔºàÊï∏ÂÄºÂíåÈ°ûÂà•Ôºâ„ÄÅÂÆÉÂÄëÁöÑÂÄºÔºå‰ª•ÂèäÂÆÉÂÄëÂ∞çÊúÄÁµÇÈ†êÊ∏¨ÁöÑË≤¢Áçª„ÄÇ‰ΩøÁî® LIDC-IDRI Ë≥áÊñôÈõÜÈÄ≤Ë°åÁöÑÊï∏ÂÄºÂØ¶È©óË≠âÊòéÔºå‰ΩøÁî®ÊâÄÊèêÂá∫ÁöÑÊ®°ÂûãÁç≤ÂæóÁöÑË®∫Êñ∑ÁµêÊûúÊòéÁ¢∫Êé¢Á¥¢ÂÖßÈÉ®Èóú‰øÇÔºåËàáËá®Â∫äÂØ¶Âãô‰∏≠ËßÄÂØüÂà∞ÁöÑÈ°û‰ººÊ®°Âºè‰∏ÄËá¥„ÄÇÊ≠§Â§ñÔºåÊâÄÊèêÂá∫ÁöÑÊ®°ÂûãÈ°ØÁ§∫Âá∫Á´∂Áà≠ÊÄßÁöÑÂàÜÈ°ûÂíåÁµêÁØÄÂ±¨ÊÄßË©ïÂàÜË°®ÁèæÔºåÁ™ÅÈ°ØÂÖ∂Âú®ËÇ∫ÁµêÁØÄË®∫Êñ∑‰∏≠ÈÄ≤Ë°åÊúâÊïàÊ±∫Á≠ñÁöÑÊΩõÂäõ„ÄÇ

##### **PriCE: Privacy-Preserving and Cost-Effective Scheduling for Parallelizing the Large Medical Image Processing Workflow over Hybrid Clouds**
2405.15398v1 by Yuandou Wang, Neel Kanwal, Kjersti Engan, Chunming Rong, Paola Grosso, Zhiming Zhao

Running deep neural networks for large medical images is a resource-hungry
and time-consuming task with centralized computing. Outsourcing such medical
image processing tasks to hybrid clouds has benefits, such as a significant
reduction of execution time and monetary cost. However, due to privacy
concerns, it is still challenging to process sensitive medical images over
clouds, which would hinder their deployment in many real-world applications. To
overcome this, we first formulate the overall optimization objectives of the
privacy-preserving distributed system model, i.e., minimizing the amount of
information about the private data learned by the adversaries throughout the
process, reducing the maximum execution time and cost under the user budget
constraint. We propose a novel privacy-preserving and cost-effective method
called PriCE to solve this multi-objective optimization problem. We performed
extensive simulation experiments for artifact detection tasks on medical images
using an ensemble of five deep convolutional neural network inferences as the
workflow task. Experimental results show that PriCE successfully splits a wide
range of input gigapixel medical images with graph-coloring-based strategies,
yielding desired output utility and lowering the privacy risk, makespan, and
monetary cost under user's budget.

ÊëòË¶ÅÔºöÂü∑Ë°åÂ§ßÂûãÈÜ´ÁôÇÂΩ±ÂÉèÁöÑÊ∑±Â∫¶Á•ûÁ∂ìÁ∂≤Ë∑ØÊòØÈ†ÖË≥áÊ∫êÊ∂àËÄó‰∏îËÄóÊôÇÁöÑ‰ªªÂãôÔºåÈúÄË¶ÅÈõÜ‰∏≠ÂºèÈÅãÁÆó„ÄÇÂ∞áÊ≠§È°ûÈÜ´ÁôÇÂΩ±ÂÉèËôïÁêÜ‰ªªÂãôÂ§ñÂåÖÁµ¶Ê∑∑ÂêàÈõ≤Á´ØÂÖ∑ÊúâÂ•ΩËôïÔºå‰æãÂ¶ÇÂ§ßÂπÖÁ∏ÆÁü≠Âü∑Ë°åÊôÇÈñìÂíåÈáëÈå¢ÊàêÊú¨„ÄÇÁÑ∂ËÄåÔºåÁî±ÊñºÈö±ÁßÅÂïèÈ°åÔºåÂú®Èõ≤Á´ØËôïÁêÜÊïèÊÑüÁöÑÈÜ´ÁôÇÂΩ±ÂÉè‰ªçÊòØ‰∏ÄÈ†ÖÊåëÊà∞ÔºåÈÄôÊúÉÈòªÁ§ôÂÆÉÂÄëÂú®Ë®±Â§öÂØ¶ÈöõÊáâÁî®‰∏≠ÁöÑÈÉ®ÁΩ≤„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÈ¶ñÂÖàÂà∂ÂÆö‰∫ÜÈö±ÁßÅ‰øùË≠∑ÂàÜÊï£ÂºèÁ≥ªÁµ±Ê®°ÂûãÁöÑÊï¥È´îÊúÄ‰Ω≥ÂåñÁõÆÊ®ôÔºåÂç≥ÊúÄÂ∞èÂåñÂ∞çÊâãÂú®Êï¥ÂÄãÈÅéÁ®ã‰∏≠ÊâÄÂæóÁü•ÁöÑÁßÅ‰∫∫Ë≥áÊñôË≥áË®äÈáèÔºåÂú®‰ΩøÁî®ËÄÖÈ†êÁÆóÈôêÂà∂‰∏ãÊ∏õÂ∞ëÊúÄÂ§ßÁöÑÂü∑Ë°åÊôÇÈñìÂíåÊàêÊú¨„ÄÇÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÁ®±ÁÇ∫ PriCE ÁöÑÊñ∞ÂûãÈö±ÁßÅ‰øùË≠∑‰∏îÊàêÊú¨ÊïàÁõäÈ´òÁöÑÊñπÂºè‰æÜËß£Ê±∫ÈÄôÂÄãÂ§öÁõÆÊ®ôÊúÄ‰Ω≥ÂåñÂïèÈ°å„ÄÇÊàëÂÄëÂ∞çÈÜ´ÁôÇÂΩ±ÂÉè‰∏äÁöÑ‰∫∫Â∑•Ë£ΩÂìÅÂÅµÊ∏¨‰ªªÂãôÂü∑Ë°åÂª£Ê≥õÁöÑÊ®°Êì¨ÂØ¶È©óÔºå‰ΩøÁî®‰∫îÂÄãÊ∑±Â∫¶Âç∑Á©çÁ•ûÁ∂ìÁ∂≤Ë∑ØÊé®Ë´ñÁöÑÊï¥È´î‰ΩúÁÇ∫Â∑•‰ΩúÊµÅÁ®ã‰ªªÂãô„ÄÇÂØ¶È©óÁµêÊûúÈ°ØÁ§∫ÔºåPriCE ÊàêÂäüÂú∞‰ΩøÁî®Âü∫ÊñºÂúñÂΩ¢ËëóËâ≤ÁöÑÁ≠ñÁï•‰æÜÂàÜÂâ≤ÂêÑÁ®ÆËº∏ÂÖ•ÁöÑÂçÉÂÖÜÁï´Á¥†ÈÜ´ÁôÇÂΩ±ÂÉèÔºåÁî¢ÁîüÊâÄÈúÄÁöÑËº∏Âá∫ÊïàÁî®‰∏¶Èôç‰ΩéÈö±ÁßÅÈ¢®Èö™„ÄÅÂü∑Ë°åÊôÇÈñìÂíåÂú®‰ΩøÁî®ËÄÖÈ†êÁÆó‰∏ãÁöÑÈáëÈå¢ÊàêÊú¨„ÄÇ

##### **Towards a Probabilistic Fusion Approach for Robust Battery Prognostics**
2405.15292v1 by Jokin Alcibar, Jose I. Aizpurua, Ekhi Zugasti

Batteries are a key enabling technology for the decarbonization of transport
and energy sectors. The safe and reliable operation of batteries is crucial for
battery-powered systems. In this direction, the development of accurate and
robust battery state-of-health prognostics models can unlock the potential of
autonomous systems for complex, remote and reliable operations. The combination
of Neural Networks, Bayesian modelling concepts and ensemble learning
strategies, form a valuable prognostics framework to combine uncertainty in a
robust and accurate manner. Accordingly, this paper introduces a Bayesian
ensemble learning approach to predict the capacity depletion of lithium-ion
batteries. The approach accurately predicts the capacity fade and quantifies
the uncertainty associated with battery design and degradation processes. The
proposed Bayesian ensemble methodology employs a stacking technique,
integrating multiple Bayesian neural networks (BNNs) as base learners, which
have been trained on data diversity. The proposed method has been validated
using a battery aging dataset collected by the NASA Ames Prognostics Center of
Excellence. Obtained results demonstrate the improved accuracy and robustness
of the proposed probabilistic fusion approach with respect to (i) a single BNN
model and (ii) a classical stacking strategy based on different BNNs.

ÊëòË¶ÅÔºöÈõªÊ±†ÊòØÈÅãËº∏ÂíåËÉΩÊ∫êÈÉ®ÈñÄËÑ´Á¢≥ÁöÑÈáçË¶Å‰ΩøËÉΩÊäÄË°ì„ÄÇÈõªÊ±†ÁöÑÂÆâÂÖ®ÊÄß„ÄÅÂèØÈù†ÊÄßÂ∞çÊñºÈõªÊ±†‰æõÈõªÁ≥ªÁµ±Ëá≥ÈóúÈáçË¶Å„ÄÇÂú®ÈÄôÂÄãÊñπÂêë‰∏äÔºåÊ∫ñÁ¢∫„ÄÅÁ©©ÂÅ•ÁöÑÈõªÊ±†ÂÅ•Â∫∑ÁãÄÊÖãÈ†êÊ∏¨Ê®°ÂûãÁöÑÈñãÁôºÔºåÂèØ‰ª•ÈáãÊîæËá™‰∏ªÁ≥ªÁµ±Âú®Ë§áÈõú„ÄÅÈÅ†Á®ãÂíåÂèØÈù†Êìç‰ΩúÊñπÈù¢ÁöÑÊΩõÂäõ„ÄÇÁ•ûÁ∂ìÁ∂≤Ë∑Ø„ÄÅË≤ùÊ∞èÂª∫Ê®°Ê¶ÇÂøµÂíåÈõÜÊàêÂ≠∏ÁøíÁ≠ñÁï•ÁöÑÁµêÂêàÔºåÂΩ¢Êàê‰∫Ü‰∏ÄÂÄãÊúâÂÉπÂÄºÁöÑÈ†êÊ∏¨Ê°ÜÊû∂Ôºå‰ª•Á©©ÂÅ•„ÄÅÊ∫ñÁ¢∫ÁöÑÊñπÂºèÁµêÂêà‰∏çÁ¢∫ÂÆöÊÄß„ÄÇÂõ†Ê≠§ÔºåÊú¨Êñá‰ªãÁ¥π‰∫Ü‰∏ÄÁ®ÆË≤ùÊ∞èÈõÜÊàêÂ≠∏ÁøíÊñπÊ≥ï‰æÜÈ†êÊ∏¨Èã∞Èõ¢Â≠êÈõªÊ±†ÁöÑÂÆπÈáèË°∞Ê∏õ„ÄÇË©≤ÊñπÊ≥ïÊ∫ñÁ¢∫È†êÊ∏¨‰∫ÜÂÆπÈáèË°∞Ê∏õÔºå‰∏¶ÈáèÂåñ‰∫ÜËàáÈõªÊ±†Ë®≠Ë®àÂíåÈÄÄÂåñÈÅéÁ®ãÁõ∏ÈóúÁöÑ‰∏çÁ¢∫ÂÆöÊÄß„ÄÇÊâÄÊèêÂá∫ÁöÑË≤ùÊ∞èÈõÜÊàêÊñπÊ≥ïÊé°Áî®Â†ÜÁñäÊäÄË°ìÔºåÂ∞áÂ§öÂÄãË≤ùÊ∞èÁ•ûÁ∂ìÁ∂≤Ë∑Ø (BNN) ‰ΩúÁÇ∫Âü∫Á§éÂ≠∏ÁøíÂô®ÈÄ≤Ë°åÊï¥ÂêàÔºåÈÄô‰∫õÂü∫Á§éÂ≠∏ÁøíÂô®Â∑≤Á∂ìÈÅéË≥áÊñôÂ§öÊ®£ÊÄßÁöÑË®ìÁ∑¥„ÄÇÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÂ∑≤Á∂ìÈÅé NASA Ames È†êÊ∏¨ÂçìË∂ä‰∏≠ÂøÉÁöÑÈõªÊ±†ËÄÅÂåñË≥áÊñôÈõÜÈ©óË≠â„ÄÇÁç≤ÂæóÁöÑÁµêÊûúË≠âÊòé‰∫ÜÊâÄÊèêÂá∫ÁöÑÊ¶ÇÁéáËûçÂêàÊñπÊ≥ïÁõ∏Â∞çÊñº (i) ÂñÆÂÄã BNN Ê®°ÂûãÂíå (ii) Âü∫Êñº‰∏çÂêå BNN ÁöÑÁ∂ìÂÖ∏Â†ÜÁñäÁ≠ñÁï•ÔºåÊîπÈÄ≤‰∫ÜÊ∫ñÁ¢∫ÊÄßÂíåÁ©©ÂÅ•ÊÄß„ÄÇ

##### **Efficient Reinforcement Learning via Large Language Model-based Search**
2405.15194v1 by Siddhant Bhambri, Amrita Bhattacharjee, Huan Liu, Subbarao Kambhampati

Reinforcement Learning (RL) suffers from sample inefficiency in sparse reward
domains, and the problem is pronounced if there are stochastic transitions. To
improve the sample efficiency, reward shaping is a well-studied approach to
introduce intrinsic rewards that can help the RL agent converge to an optimal
policy faster. However, designing a useful reward shaping function specific to
each problem is challenging, even for domain experts. They would either have to
rely on task-specific domain knowledge or provide an expert demonstration
independently for each task. Given, that Large Language Models (LLMs) have
rapidly gained prominence across a magnitude of natural language tasks, we aim
to answer the following question: Can we leverage LLMs to construct a reward
shaping function that can boost the sample efficiency of an RL agent? In this
work, we aim to leverage off-the-shelf LLMs to generate a guide policy by
solving a simpler deterministic abstraction of the original problem that can
then be used to construct the reward shaping function for the downstream RL
agent. Given the ineffectiveness of directly prompting LLMs, we propose MEDIC:
a framework that augments LLMs with a Model-based feEDback critIC, which
verifies LLM-generated outputs, to generate a possibly sub-optimal but valid
plan for the abstract problem. Our experiments across domains from the BabyAI
environment suite show 1) the effectiveness of augmenting LLMs with MEDIC, 2) a
significant improvement in the sample complexity of PPO and A2C-based RL agents
when guided by our LLM-generated plan, and finally, 3) pave the direction for
further explorations of how these models can be used to augment existing RL
pipelines.

ÊëòË¶ÅÔºö<paragraph>Âº∑ÂåñÂ≠∏Áøí (RL) Âú®Á®ÄÁñèÁçéÂãµÈ†òÂüü‰∏≠ÊúÉÈÅáÂà∞Ê®£Êú¨ÊïàÁéá‰Ωé‰∏ãÁöÑÂïèÈ°åÔºåËÄåÂ¶ÇÊûúÂ≠òÂú®Èö®Ê©üËΩâÊèõÔºåÂâáÂïèÈ°åÊúÉÊõ¥Âä†Âö¥Èáç„ÄÇÁÇ∫‰∫ÜÊèêÈ´òÊ®£Êú¨ÊïàÁéáÔºåÁçéÂãµÊàêÂΩ¢ÊòØ‰∏ÄÁ®ÆÁ∂ìÈÅéÂÖÖÂàÜÁ†îÁ©∂ÁöÑÊñπÊ≥ïÔºåÁî®ÊñºÂºïÂÖ•ÂÖßÂú®ÁçéÂãµÔºåÂèØ‰ª•Âπ´Âä© RL ‰ª£ÁêÜÊõ¥Âø´Âú∞Êî∂ÊñÇÂà∞ÊúÄ‰Ω≥Á≠ñÁï•„ÄÇÁÑ∂ËÄåÔºåÈáùÂ∞çÊØèÂÄãÂïèÈ°åË®≠Ë®à‰∏ÄÂÄãÊúâÁî®ÁöÑÁçéÂãµÊàêÂΩ¢ÂáΩÊï∏ÊòØ‰∏ÄÈ†ÖÊåëÊà∞ÔºåÂç≥‰ΩøÂ∞çÊñºÈ†òÂüüÂ∞àÂÆ∂ËÄåË®Ä‰πüÊòØÂ¶ÇÊ≠§„ÄÇ‰ªñÂÄëÂøÖÈ†à‰æùË≥¥ÁâπÂÆöÊñº‰ªªÂãôÁöÑÈ†òÂüüÁü•Ë≠òÔºåÊàñËÄÖÁÇ∫ÊØèÂÄã‰ªªÂãôÁç®Á´ãÊèê‰æõÂ∞àÂÆ∂Á§∫ÁØÑ„ÄÇÈëëÊñºÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤ËøÖÈÄüÂú®Â§ßÈáèËá™ÁÑ∂Ë™ûË®Ä‰ªªÂãô‰∏≠Áç≤ÂæóÁ™ÅÂá∫Âú∞‰ΩçÔºåÊàëÂÄëÊó®Âú®ÂõûÁ≠î‰ª•‰∏ãÂïèÈ°åÔºöÊàëÂÄëËÉΩÂà©Áî® LLM ‰æÜÂª∫Êßã‰∏ÄÂÄãÁçéÂãµÊàêÂΩ¢ÂáΩÊï∏ÔºåÂæûËÄåÊèêÂçá RL ‰ª£ÁêÜÁöÑÊ®£Êú¨ÊïàÁéáÂóéÔºüÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊó®Âú®Âà©Áî®ÁèæÊàêÁöÑ LLMÔºåÈÄèÈÅéËß£Ê±∫ÂéüÂßãÂïèÈ°åÁöÑ‰∏ÄÂÄãÊõ¥Á∞°ÂñÆÁöÑÁ¢∫ÂÆöÊÄßÊäΩË±°‰æÜÁî¢Áîü‰∏ÄÂÄãÂºïÂ∞éÁ≠ñÁï•ÔºåÁÑ∂ÂæåÂèØ‰ª•Áî®ÂÆÉ‰æÜÁÇ∫‰∏ãÊ∏∏ RL ‰ª£ÁêÜÂª∫ÊßãÁçéÂãµÊàêÂΩ¢ÂáΩÊï∏„ÄÇÈëëÊñºÁõ¥Êé•ÊèêÁ§∫ LLM ÁöÑÁÑ°ÊïàÊÄßÔºåÊàëÂÄëÊèêÂá∫‰∫Ü MEDICÔºö‰∏ÄÂÄã‰ΩøÁî®Âü∫ÊñºÊ®°ÂûãÁöÑÂõûÈ•ãÊâπË©ïÂô®‰æÜÊì¥ÂÖÖ LLM ÁöÑÊ°ÜÊû∂ÔºåÂÆÉÊúÉÈ©óË≠â LLM Áî¢ÁîüÁöÑËº∏Âá∫Ôºå‰ª•Áî¢Áîü‰∏ÄÂÄãÂèØËÉΩÊ¨°ÊñºÊúÄ‰Ω≥‰ΩÜÊúâÊïàÁöÑÊäΩË±°ÂïèÈ°åË®àÁï´„ÄÇÊàëÂÄëÂú® BabyAI Áí∞Â¢ÉÂ•ó‰ª∂‰∏≠Ë∑®È†òÂüüÈÄ≤Ë°åÁöÑÂØ¶È©óÈ°ØÁ§∫ 1) ‰ΩøÁî® MEDIC Êì¥ÂÖÖ LLM ÁöÑÊúâÊïàÊÄßÔºå2) Âú®Áî±ÊàëÂÄëÁöÑ LLM Áî¢ÁîüÁöÑË®àÁï´ÂºïÂ∞é‰∏ãÔºåÂü∫Êñº PPO Âíå A2C ÁöÑ RL ‰ª£ÁêÜÁöÑÊ®£Êú¨Ë§áÈõúÂ∫¶ÊúâÈ°ØËëóÊîπÂñÑÔºåÊúÄÂæåÔºå3) ÁÇ∫ÈÄ≤‰∏ÄÊ≠•Êé¢Á¥¢Â¶Ç‰Ωï‰ΩøÁî®ÈÄô‰∫õÊ®°Âûã‰æÜÊì¥ÂÖÖÁèæÊúâÁöÑ RL ÁÆ°Á∑öÈã™Âπ≥‰∫ÜÈÅìË∑Ø„ÄÇ</paragraph>

##### **Deep Activity Model: A Generative Approach for Human Mobility Pattern Synthesis**
2405.17468v1 by Xishun Liao, Brian Yueshuai He, Qinhua Jiang, Chenchen Kuai, Jiaqi Ma

Human mobility significantly impacts various aspects of society, including
transportation, urban planning, and public health. The increasing availability
of diverse mobility data and advancements in deep learning have revolutionized
mobility modeling. Existing deep learning models, however, mainly study
spatio-temporal patterns using trajectories and often fall short in capturing
the underlying semantic interdependency among activities. Moreover, they are
also constrained by the data source. These two factors thereby limit their
realism and adaptability, respectively. Meanwhile, traditional activity-based
models (ABMs) in transportation modeling rely on rigid assumptions and are
costly and time-consuming to calibrate, making them difficult to adapt and
scale to new regions, especially those regions with limited amount of required
conventional travel data. To address these limitations, we develop a novel
generative deep learning approach for human mobility modeling and synthesis,
using ubiquitous and open-source data. Additionally, the model can be
fine-tuned with local data, enabling adaptable and accurate representations of
mobility patterns across different regions. The model is evaluated on a
nationwide dataset of the United States, where it demonstrates superior
performance in generating activity chains that closely follow ground truth
distributions. Further tests using state- or city-specific datasets from
California, Washington, and Mexico City confirm its transferability. This
innovative approach offers substantial potential to advance mobility modeling
research, especially in generating human activity chains as input for
downstream activity-based mobility simulation models and providing enhanced
tools for urban planners and policymakers.

ÊëòË¶ÅÔºö‰∫∫È°ûÊµÅÂãïÊÄßÈ°ØËëóÂΩ±ÈüøÁ§æÊúÉÁöÑÂêÑÂÄãÈù¢ÂêëÔºåÂåÖÊã¨‰∫§ÈÄö„ÄÅÈÉΩÂ∏ÇË¶èÂäÉÂíåÂÖ¨ÂÖ±Ë°õÁîü„ÄÇÂ§öÂÖÉÊµÅÂãïÊÄßË≥áÊñôÁöÑÊó•ÁõäÊôÆÂèäÂíåÊ∑±Â∫¶Â≠∏ÁøíÁöÑÈÄ≤Ê≠•ÔºåÂ∑≤Á∂ìÂæπÂ∫ïÊîπËÆä‰∫ÜÊµÅÂãïÊÄßÂª∫Ê®°„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÁöÑÊ∑±Â∫¶Â≠∏ÁøíÊ®°Âûã‰∏ªË¶Å‰ΩøÁî®ËªåË∑°Á†îÁ©∂ÊôÇÁ©∫Ê®°ÂºèÔºåËÄå‰∏îÁ∂ìÂ∏∏ÁÑ°Ê≥ïÊçïÊçâÊ¥ªÂãï‰πãÈñìÁöÑÂ∫ïÂ±§Ë™ûÁæ©Áõ∏‰∫í‰æùË≥¥ÊÄß„ÄÇÊ≠§Â§ñÔºåÂÆÉÂÄë‰πüÂèóÂà∞Ë≥áÊñô‰æÜÊ∫êÁöÑÈôêÂà∂„ÄÇÈÄôÂÖ©ÂÄãÂõ†Á¥†ÂàÜÂà•ÈôêÂà∂‰∫ÜÂÆÉÂÄëÁöÑÁúüÂØ¶ÊÄßÂíåÈÅ©ÊáâÊÄß„ÄÇÂêåÊôÇÔºå‰∫§ÈÄöÂª∫Ê®°‰∏≠ÁöÑÂÇ≥Áµ±Âü∫ÊñºÊ¥ªÂãïÁöÑÊ®°Âûã (ABM) ‰æùË≥¥ÊñºÂÉµÂåñÁöÑÂÅáË®≠ÔºåËÄå‰∏îÊ†°Ê∫ñËµ∑‰æÜÊó¢ÊòÇË≤¥ÂèàË≤ªÊôÇÔºåÈÄô‰ΩøÂæóÂÆÉÂÄëÈõ£‰ª•ÈÅ©ÊáâÂíåÊì¥Â±ïÂà∞Êñ∞ÁöÑÂçÄÂüüÔºåÁâπÂà•ÊòØÈÇ£‰∫õÁº∫‰πèÊâÄÈúÄÂÇ≥Áµ±Ë°åÁ®ãË≥áÊñôÁöÑÂçÄÂüü„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÈôêÂà∂ÔºåÊàëÂÄëÈñãÁôº‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÁîüÊàêÂºèÊ∑±Â∫¶Â≠∏ÁøíÊñπÊ≥ïÔºåÁî®Êñº‰∫∫È°ûÊµÅÂãïÊÄßÂª∫Ê®°ÂíåÂêàÊàêÔºå‰∏¶‰ΩøÁî®ÊôÆÈÅç‰∏îÈñãÊîæÂéüÂßãÁ¢ºÁöÑË≥áÊñô„ÄÇÊ≠§Â§ñÔºåË©≤Ê®°ÂûãÂèØ‰ª•Ê†πÊìöÁï∂Âú∞Ë≥áÊñôÈÄ≤Ë°åÂæÆË™øÔºåÂæûËÄåËÉΩÂ§†ÈÅ©Êáâ‰∏¶Ê∫ñÁ¢∫Âú∞Ë°®Á§∫‰∏çÂêåÂçÄÂüüÁöÑÊµÅÂãïÊÄßÊ®°Âºè„ÄÇË©≤Ê®°ÂûãÂú®ÁæéÂúãÂÖ®ÂúãË≥áÊñôÈõÜ‰∏äÈÄ≤Ë°å‰∫ÜË©ï‰º∞ÔºåÁµêÊûúÈ°ØÁ§∫Âá∫Âú®ÁîüÊàêËàáÂØ¶ÈöõÊÉÖÊ≥ÅÂàÜ‰ΩàÁ∑äÂØÜÁõ∏ÈóúÁöÑÊ¥ªÂãïÈèàÊñπÈù¢ÂÖ∑ÊúâÂÑ™Áï∞ÁöÑÊïàËÉΩ„ÄÇ‰ΩøÁî®‰æÜËá™Âä†Â∑û„ÄÅËèØÁõõÈ†ìÂ∑ûÂíåÂ¢®Ë•øÂì•ÂüéÁöÑÂ∑ûÊàñÂüéÂ∏ÇÁâπÂÆöË≥áÊñôÈõÜÈÄ≤Ë°åÁöÑÈÄ≤‰∏ÄÊ≠•Ê∏¨Ë©¶ÔºåË≠âÂØ¶‰∫ÜÂÆÉÁöÑÂèØËΩâÁßªÊÄß„ÄÇÈÄôÁ®ÆÂâµÊñ∞ÊñπÊ≥ïÊèê‰æõ‰∫ÜÊé®ÈÄ≤ÊµÅÂãïÊÄßÂª∫Ê®°Á†îÁ©∂ÁöÑÂ∑®Â§ßÊΩõÂäõÔºåÁâπÂà•ÊòØÂú®ÁîüÊàê‰∫∫È°ûÊ¥ªÂãïÈèà‰ΩúÁÇ∫‰∏ãÊ∏∏Âü∫ÊñºÊ¥ªÂãïÁöÑÊµÅÂãïÊÄßÊ®°Êì¨Ê®°ÂûãÁöÑËº∏ÂÖ•Ôºå‰ª•ÂèäÁÇ∫ÈÉΩÂ∏ÇË¶èÂäÉËÄÖÂíåÊîøÁ≠ñÂà∂ÂÆöËÄÖÊèê‰æõÂ¢ûÂº∑Â∑•ÂÖ∑ÊñπÈù¢„ÄÇ

##### **Generative Camera Dolly: Extreme Monocular Dynamic Novel View Synthesis**
2405.14868v1 by Basile Van Hoorick, Rundi Wu, Ege Ozguroglu, Kyle Sargent, Ruoshi Liu, Pavel Tokmakov, Achal Dave, Changxi Zheng, Carl Vondrick

Accurate reconstruction of complex dynamic scenes from just a single
viewpoint continues to be a challenging task in computer vision. Current
dynamic novel view synthesis methods typically require videos from many
different camera viewpoints, necessitating careful recording setups, and
significantly restricting their utility in the wild as well as in terms of
embodied AI applications. In this paper, we propose $\textbf{GCD}$, a
controllable monocular dynamic view synthesis pipeline that leverages
large-scale diffusion priors to, given a video of any scene, generate a
synchronous video from any other chosen perspective, conditioned on a set of
relative camera pose parameters. Our model does not require depth as input, and
does not explicitly model 3D scene geometry, instead performing end-to-end
video-to-video translation in order to achieve its goal efficiently. Despite
being trained on synthetic multi-view video data only, zero-shot real-world
generalization experiments show promising results in multiple domains,
including robotics, object permanence, and driving environments. We believe our
framework can potentially unlock powerful applications in rich dynamic scene
understanding, perception for robotics, and interactive 3D video viewing
experiences for virtual reality.

ÊëòË¶ÅÔºöÂÉÖÂæûÂñÆ‰∏ÄË¶ñÈªûÊ∫ñÁ¢∫ÈáçÂª∫Ë§áÈõúÁöÑÂãïÊÖãÂ†¥ÊôØÔºåÂú®ÈõªËÖ¶Ë¶ñË¶∫‰∏≠ÊåÅÁ∫åÊàêÁÇ∫‰∏ÄÈ†ÖËâ±Èõ£ÁöÑ‰ªªÂãô„ÄÇÁõÆÂâçÁöÑÂãïÊÖãÊñ∞Ë¶ñÂúñÂêàÊàêÊñπÊ≥ïÈÄöÂ∏∏ÈúÄË¶Å‰æÜËá™Ë®±Â§ö‰∏çÂêåÁõ∏Ê©üË¶ñÈªûÁöÑÂΩ±ÁâáÔºåÈÄôÈúÄË¶Å‰ªîÁ¥∞ÁöÑÈåÑË£ΩË®≠ÂÆöÔºå‰∏¶È°ØËëóÈôêÂà∂ÂÆÉÂÄëÂú®ÈáéÂ§ñ‰ª•ÂèäÂÖ∑Ë∫´ AI ÊáâÁî®ÊñπÈù¢ÁöÑÊïàÁî®„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫ $\textbf{GCD}$Ôºå‰∏ÄÁ®ÆÂèØÊéßÁöÑÂñÆÁúºÂãïÊÖãË¶ñÂúñÂêàÊàêÁÆ°ÈÅìÔºåÂÆÉÂà©Áî®Â§ßË¶èÊ®°Êì¥Êï£ÂÖàÈ©óÔºåÂú®Áµ¶ÂÆö‰ªª‰ΩïÂ†¥ÊôØÂΩ±ÁâáÁöÑÊÉÖÊ≥Å‰∏ãÔºåÊ†πÊìö‰∏ÄÁµÑÁõ∏Â∞çÁõ∏Ê©üÂßøÂã¢ÂèÉÊï∏ÁîüÊàê‰æÜËá™‰ªª‰ΩïÂÖ∂‰ªñÈÅ∏ÊìáË¶ñËßíÁöÑÂêåÊ≠•ÂΩ±Áâá„ÄÇÊàëÂÄëÁöÑÊ®°Âûã‰∏çÈúÄË¶ÅÊ∑±Â∫¶‰ΩúÁÇ∫Ëº∏ÂÖ•Ôºå‰πü‰∏çÊòéÁ¢∫Âª∫Ê®° 3D Â†¥ÊôØÂπæ‰ΩïÔºåËÄåÊòØÂü∑Ë°åÁ´ØÂ∞çÁ´ØÁöÑÂΩ±ÁâáÂà∞ÂΩ±ÁâáËΩâÊèõÔºå‰ª•ÊúâÊïàÈÅîÊàêÂÖ∂ÁõÆÊ®ô„ÄÇÂÑòÁÆ°ÂÉÖÂú®ÂêàÊàêÂ§öË¶ñÂúñÂΩ±ÁâáË≥áÊñô‰∏äË®ìÁ∑¥Ôºå‰ΩÜÈõ∂Ê¨°Â≠∏ÁøíÁúüÂØ¶‰∏ñÁïåÊ¶ÇÂåñÂØ¶È©óÂú®Â§öÂÄãÈ†òÂüüÈ°ØÁ§∫Âá∫ÊúâÂ∏åÊúõÁöÑÁµêÊûúÔºåÂåÖÊã¨Ê©üÂô®‰∫∫ÊäÄË°ì„ÄÅÁâ©È´îÊÅÜÂ∏∏ÊÄßÂíåÈßïÈßõÁí∞Â¢É„ÄÇÊàëÂÄëÁõ∏‰ø°ÊàëÂÄëÁöÑÊû∂ÊßãÊúâÂèØËÉΩÂú®Ë±êÂØåÁöÑÂãïÊÖãÂ†¥ÊôØÁêÜËß£„ÄÅÊ©üÂô®‰∫∫ÊÑüÁü•‰ª•ÂèäËôõÊì¨ÂØ¶Â¢É‰∫íÂãïÂºè 3D ÂΩ±ÁâáËßÄÁúãÈ´îÈ©ó‰∏≠ÈñãÂïüÂº∑Â§ßÁöÑÊáâÁî®Á®ãÂºè„ÄÇ

##### **A Declarative System for Optimizing AI Workloads**
2405.14696v2 by Chunwei Liu, Matthew Russo, Michael Cafarella, Lei Cao, Peter Baille Chen, Zui Chen, Michael Franklin, Tim Kraska, Samuel Madden, Gerardo Vitagliano

A long-standing goal of data management systems has been to build systems
which can compute quantitative insights over large corpora of unstructured data
in a cost-effective manner. Until recently, it was difficult and expensive to
extract facts from company documents, data from scientific papers, or metrics
from image and video corpora. Today's models can accomplish these tasks with
high accuracy. However, a programmer who wants to answer a substantive
AI-powered query must orchestrate large numbers of models, prompts, and data
operations. For even a single query, the programmer has to make a vast number
of decisions such as the choice of model, the right inference method, the most
cost-effective inference hardware, the ideal prompt design, and so on. The
optimal set of decisions can change as the query changes and as the
rapidly-evolving technical landscape shifts. In this paper we present
Palimpzest, a system that enables anyone to process AI-powered analytical
queries simply by defining them in a declarative language. The system uses its
cost optimization framework to implement the query plan with the best
trade-offs between runtime, financial cost, and output data quality. We
describe the workload of AI-powered analytics tasks, the optimization methods
that Palimpzest uses, and the prototype system itself. We evaluate Palimpzest
on tasks in Legal Discovery, Real Estate Search, and Medical Schema Matching.
We show that even our simple prototype offers a range of appealing plans,
including one that is 3.3x faster and 2.9x cheaper than the baseline method,
while also offering better data quality. With parallelism enabled, Palimpzest
can produce plans with up to a 90.3x speedup at 9.1x lower cost relative to a
single-threaded GPT-4 baseline, while obtaining an F1-score within 83.5% of the
baseline. These require no additional work by the user.

ÊëòË¶ÅÔºöÈï∑Êúü‰ª•‰æÜÔºåË≥áÊñôÁÆ°ÁêÜÁ≥ªÁµ±ÁöÑÁõÆÊ®ô‰∏ÄÁõ¥ÊòØÂª∫Á´ãÁ≥ªÁµ±ÔºåËÉΩÂ§†‰ª•Á∂ìÊøüÊúâÊïàÁöÑÊñπÂºèË®àÁÆóÂ§ßÈáèÈùûÁµêÊßãÂåñË≥áÊñôÁöÑÈáèÂåñË¶ãËß£„ÄÇÁõ¥Âà∞ÊúÄËøëÔºåÂæûÂÖ¨Âè∏Êñá‰ª∂„ÄÅÁßëÂ≠∏Ë´ñÊñá‰∏≠ÊèêÂèñ‰∫ãÂØ¶ÔºåÊàñÂæûÂΩ±ÂÉèÂíåÂΩ±ÁâáË≥áÊñô‰∏≠ÊèêÂèñÊåáÊ®ôÔºå‰ªçÁÑ∂Âõ∞Èõ£‰∏îÊòÇË≤¥„ÄÇÁèæ‰ªäÁöÑÊ®°ÂûãÂèØ‰ª•È´òÊ∫ñÁ¢∫Â∫¶ÂÆåÊàêÈÄô‰∫õ‰ªªÂãô„ÄÇÁÑ∂ËÄåÔºåÊÉ≥Ë¶ÅÂõûÁ≠îÂØ¶Ë≥™ÊÄß AI È©ÖÂãïÊü•Ë©¢ÁöÑÁ®ãÂºèË®≠Ë®àÂ∏´ÔºåÂøÖÈ†àÂçîË™øÂ§ßÈáèÁöÑÊ®°Âûã„ÄÅÊèêÁ§∫ÂíåË≥áÊñôÊìç‰Ωú„ÄÇÂç≥‰ΩøÂè™ÊòØ‰∏ÄÂÄãÂñÆ‰∏ÄÁöÑÊü•Ë©¢ÔºåÁ®ãÂºèË®≠Ë®àÂ∏´ÈÉΩÂøÖÈ†àÂÅöÂá∫Â§ßÈáèÁöÑÊ±∫Á≠ñÔºå‰æãÂ¶ÇÊ®°ÂûãÁöÑÈÅ∏Êìá„ÄÅÊ≠£Á¢∫ÁöÑÊé®Ë´ñÊñπÊ≥ï„ÄÅÊúÄÂÖ∑ÊàêÊú¨ÊïàÁõäÁöÑÊé®Ë´ñÁ°¨È´î„ÄÅÁêÜÊÉ≥ÁöÑÊèêÁ§∫Ë®≠Ë®àÔºåÁ≠âÁ≠â„ÄÇÊúÄ‰Ω≥Ê±∫Á≠ñÁµÑÂêàÊúÉÈö®ËëóÊü•Ë©¢ÁöÑÊîπËÆäÂíåÂø´ÈÄüËÆäÂåñÁöÑÊäÄË°ìÁí∞Â¢ÉËÄåÊîπËÆä„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü PalimpzestÔºå‰∏ÄÂÄãÁ≥ªÁµ±ÔºåËÆì‰ªª‰Ωï‰∫∫ÈÉΩËÉΩÈÄèÈÅéÂú®ÂÆ£ÂëäÂºèË™ûË®Ä‰∏≠ÂÆöÁæ© AI È©ÖÂãïÂàÜÊûêÊü•Ë©¢Ôºå‰æÜËôïÁêÜÈÄô‰∫õÊü•Ë©¢„ÄÇÁ≥ªÁµ±‰ΩøÁî®ÂÖ∂ÊàêÊú¨ÊúÄ‰Ω≥ÂåñÊû∂ÊßãÔºå‰ª•ÊúÄ‰Ω≥ÁöÑÂü∑Ë°åÊôÇÈñì„ÄÅË≤°ÂãôÊàêÊú¨ÂíåËº∏Âá∫Ë≥áÊñôÂìÅË≥™ÊäòË°∑Ôºå‰æÜÂØ¶‰ΩúÊü•Ë©¢Ë®àÁï´„ÄÇÊàëÂÄëÊèèËø∞‰∫Ü AI È©ÖÂãïÂàÜÊûê‰ªªÂãôÁöÑÂ∑•‰ΩúË≤†Ëºâ„ÄÅPalimpzest ‰ΩøÁî®ÁöÑÊúÄ‰Ω≥ÂåñÊñπÊ≥ïÔºå‰ª•ÂèäÂéüÂûãÁ≥ªÁµ±Êú¨Ë∫´„ÄÇÊàëÂÄëÂú®Ê≥ïÂæãÁôºÁèæ„ÄÅÊàøÂú∞Áî¢ÊêúÂ∞ãÂíåÈÜ´ÁôÇÊû∂ÊßãÊØîÂ∞çÁöÑ‰ªªÂãô‰∏≠Ë©ï‰º∞ Palimpzest„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫ÜÂç≥‰ΩøÊòØÊàëÂÄëÁöÑÁ∞°ÂñÆÂéüÂûã‰πüËÉΩÊèê‰æõ‰∏ÄÁ≥ªÂàóÊúâÂê∏ÂºïÂäõÁöÑË®àÁï´ÔºåÂåÖÊã¨‰∏ÄÂÄãÊØîÂü∫Ê∫ñÊñπÊ≥ïÂø´ 3.3 ÂÄç„ÄÅ‰æøÂÆú 2.9 ÂÄçÁöÑË®àÁï´ÔºåÂêåÊôÇÈÇÑËÉΩÊèê‰æõÊõ¥Â•ΩÁöÑË≥áÊñôÂìÅË≥™„ÄÇÂú®ÂïüÁî®Âπ≥Ë°åËôïÁêÜÁöÑÊÉÖÊ≥Å‰∏ãÔºåPalimpzest ÂèØ‰ª•Áî¢ÁîüÈÄüÂ∫¶ÊèêÂçáÈÅî 90.3 ÂÄç„ÄÅÊàêÊú¨Èôç‰Ωé 9.1 ÂÄçÁöÑË®àÁï´ÔºåÁõ∏ËºÉÊñºÂñÆÂü∑Ë°åÁ∑í GPT-4 Âü∫Ê∫ñÔºåÂêåÊôÇÁç≤Âæó F1 ÂàÜÊï∏Âú®Âü∫Ê∫ñÁöÑ 83.5% ‰ª•ÂÖß„ÄÇÈÄô‰∫õÈÉΩ‰∏çÈúÄË¶Å‰ΩøÁî®ËÄÖÈ°çÂ§ñÁöÑ‰ΩúÊ•≠„ÄÇ

##### **Efficient Medical Question Answering with Knowledge-Augmented Question Generation**
2405.14654v1 by Julien Khlaut, Corentin Dancette, Elodie Ferreres, Alaedine Bennani, Paul H√©rent, Pierre Manceron

In the expanding field of language model applications, medical knowledge
representation remains a significant challenge due to the specialized nature of
the domain. Large language models, such as GPT-4, obtain reasonable scores on
medical question answering tasks, but smaller models are far behind. In this
work, we introduce a method to improve the proficiency of a small language
model in the medical domain by employing a two-fold approach. We first
fine-tune the model on a corpus of medical textbooks. Then, we use GPT-4 to
generate questions similar to the downstream task, prompted with textbook
knowledge, and use them to fine-tune the model. Additionally, we introduce
ECN-QA, a novel medical question answering dataset containing ``progressive
questions'' composed of related sequential questions. We show the benefits of
our training strategy on this dataset. The study's findings highlight the
potential of small language models in the medical domain when appropriately
fine-tuned. The code and weights are available at
https://github.com/raidium-med/MQG.

ÊëòË¶ÅÔºöÂú®Ë™ûË®ÄÊ®°ÂûãÊáâÁî®‰∏çÊñ∑Êì¥Â±ïÁöÑÈ†òÂüü‰∏≠ÔºåÁî±ÊñºË©≤È†òÂüüÁöÑÂ∞àÊ•≠ÊÄßË≥™ÔºåÈÜ´Â≠∏Áü•Ë≠òË°®Á§∫‰ªçÁÑ∂ÊòØ‰∏ÄÂÄãÈáçÂ§ßÁöÑÊåëÊà∞„ÄÇÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºå‰æãÂ¶Ç GPT-4ÔºåÂú®ÈÜ´Â≠∏ÂïèÈ°åËß£Á≠î‰ªªÂãô‰∏≠Áç≤Âæó‰∫ÜÂêàÁêÜÁöÑË©ïÂàÜÔºå‰ΩÜËºÉÂ∞èÁöÑÊ®°ÂûãÂçªÈÅ†ÈÅ†ËêΩÂæå„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫Ü‰∏ÄÁ®ÆÊñπÊ≥ïÔºåÈÄöÈÅéÊé°Áî®ÈõôÈáçÊñπÊ≥ï‰æÜÊèêÈ´òÂ∞èÂûãË™ûË®ÄÊ®°ÂûãÂú®ÈÜ´Â≠∏È†òÂüüÁöÑÁÜüÁ∑¥Â∫¶„ÄÇÊàëÂÄëÈ¶ñÂÖàÂú®ÈÜ´Â≠∏ÊïôÁßëÊõ∏Ë™ûÊñôÂ∫´‰∏≠Â∞çÊ®°ÂûãÈÄ≤Ë°åÂæÆË™ø„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄë‰ΩøÁî® GPT-4 ÁîüÊàêËàá‰∏ãÊ∏∏‰ªªÂãôÁõ∏‰ººÁöÑÂïèÈ°åÔºå‰∏¶ÊèêÁ§∫ÊïôÁßëÊõ∏Áü•Ë≠òÔºå‰∏¶‰ΩøÁî®ÂÆÉÂÄëÂ∞çÊ®°ÂûãÈÄ≤Ë°åÂæÆË™ø„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÈÇÑÂºïÂÖ•‰∫Ü ECN-QAÔºåÈÄôÊòØ‰∏ÄÂÄãÊñ∞Á©éÁöÑÈÜ´Â≠∏ÂïèÈ°åËß£Á≠îÊï∏ÊìöÈõÜÔºåÂÖ∂‰∏≠ÂåÖÂê´Áî±Áõ∏ÈóúÈ†ÜÂ∫èÂïèÈ°åÁµÑÊàêÁöÑ„ÄåÊº∏ÈÄ≤ÂºèÂïèÈ°å„Äç„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫ÜÊàëÂÄëÁöÑË®ìÁ∑¥Á≠ñÁï•Âú®ÈÄôÂÄãÊï∏ÊìöÈõÜ‰∏äÁöÑÂ•ΩËôï„ÄÇÈÄôÈ†ÖÁ†îÁ©∂ÁöÑÁôºÁèæÁ™ÅÂá∫‰∫ÜÂ∞èÂûãË™ûË®ÄÊ®°ÂûãÂú®ÈÅ©Áï∂ÂæÆË™øÂæåÂú®ÈÜ´Â≠∏È†òÂüüÁöÑÊΩõÂäõ„ÄÇ‰ª£Á¢ºÂíåÊ¨äÈáçÂèØÂú® https://github.com/raidium-med/MQG Áç≤Âæó„ÄÇ

##### **Concept Visualization: Explaining the CLIP Multi-modal Embedding Using WordNet**
2405.14563v1 by Loris Giulivi, Giacomo Boracchi

Advances in multi-modal embeddings, and in particular CLIP, have recently
driven several breakthroughs in Computer Vision (CV). CLIP has shown impressive
performance on a variety of tasks, yet, its inherently opaque architecture may
hinder the application of models employing CLIP as backbone, especially in
fields where trust and model explainability are imperative, such as in the
medical domain. Current explanation methodologies for CV models rely on
Saliency Maps computed through gradient analysis or input perturbation.
However, these Saliency Maps can only be computed to explain classes relevant
to the end task, often smaller in scope than the backbone training classes. In
the context of models implementing CLIP as their vision backbone, a substantial
portion of the information embedded within the learned representations is thus
left unexplained.
  In this work, we propose Concept Visualization (ConVis), a novel saliency
methodology that explains the CLIP embedding of an image by exploiting the
multi-modal nature of the embeddings. ConVis makes use of lexical information
from WordNet to compute task-agnostic Saliency Maps for any concept, not
limited to concepts the end model was trained on. We validate our use of
WordNet via an out of distribution detection experiment, and test ConVis on an
object localization benchmark, showing that Concept Visualizations correctly
identify and localize the image's semantic content. Additionally, we perform a
user study demonstrating that our methodology can give users insight on the
model's functioning.

ÊëòË¶ÅÔºö<paragraph>Â§öÊ®°ÊÖãÂµåÂÖ•ÁöÑÈÄ≤Â±ïÔºåÁâπÂà•ÊòØ CLIPÔºåÊúÄËøëÊé®Âãï‰∫ÜÈõªËÖ¶Ë¶ñË¶∫ (CV) ÁöÑÂ§öÈ†ÖÁ™ÅÁ†¥„ÄÇCLIP Â∑≤Âú®ÂêÑÁ®Æ‰ªªÂãô‰∏≠Â±ïÁèæÂá∫‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑÊïàËÉΩÔºåÁÑ∂ËÄåÔºåÂÖ∂Êú¨Ë≥™‰∏ä‰∏çÈÄèÊòéÁöÑÊû∂ÊßãÂèØËÉΩÊúÉÈòªÁ§ôÊé°Áî®‰ª• CLIP ÁÇ∫Âü∫Á§éÊû∂ÊßãÁöÑÊ®°ÂûãÔºåÁâπÂà•ÊòØÂú®ÈúÄË¶Å‰ø°‰ªªÂíåÊ®°ÂûãÂèØËß£ÈáãÊÄßÁöÑÈ†òÂüüÔºå‰æãÂ¶ÇÈÜ´ÁôÇÈ†òÂüü„ÄÇÁõÆÂâçÈáùÂ∞ç CV Ê®°ÂûãÁöÑËß£ÈáãÊñπÊ≥ï‰æùË≥¥ÊñºÈÄèÈÅéÊ¢ØÂ∫¶ÂàÜÊûêÊàñËº∏ÂÖ•ÊìæÂãïË®àÁÆóÂá∫ÁöÑÈ°ØËëóÊÄßÂúñ„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÈ°ØËëóÊÄßÂúñÂè™ËÉΩË®àÁÆóÂá∫ËàáÊúÄÁµÇ‰ªªÂãôÁõ∏ÈóúÁöÑÈ°ûÂà•ÔºåÂÖ∂ÁØÑÂúçÈÄöÂ∏∏Â∞èÊñºÂü∫Á§éÊû∂ÊßãË®ìÁ∑¥È°ûÂà•„ÄÇÂú®Â∞á CLIP ‰ΩúÁÇ∫ÂÖ∂Ë¶ñË¶∫Âü∫Á§éÊû∂ÊßãÂØ¶‰ΩúÁöÑÊ®°Âûã‰∏≠ÔºåÂ≠∏ÁøíË°®Âæµ‰∏≠ÂµåÂÖ•ÁöÑÂ§ßÈÉ®ÂàÜË≥áË®äÂõ†Ê≠§ÁÑ°Ê≥ïËß£Èáã„ÄÇ
  Âú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫Ê¶ÇÂøµË¶ñË¶∫Âåñ (ConVis)ÔºåÈÄôÊòØ‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÈ°ØËëóÊÄßÊñπÊ≥ïÔºåÈÄèÈÅéÂà©Áî®ÂµåÂÖ•ÁöÑÂ§öÊ®°ÊÖãÁâπÊÄß‰æÜËß£ÈáãÂΩ±ÂÉèÁöÑ CLIP ÂµåÂÖ•„ÄÇConVis Âà©Áî® WordNet ‰∏≠ÁöÑË©ûÂΩôË≥áË®äÔºåÁÇ∫‰ªª‰ΩïÊ¶ÇÂøµË®àÁÆóËàá‰ªªÂãôÁÑ°ÈóúÁöÑÈ°ØËëóÊÄßÂúñÔºåËÄå‰∏çÈôêÊñºÊúÄÁµÇÊ®°ÂûãË®ìÁ∑¥ÁöÑÈÇ£‰∫õÊ¶ÇÂøµ„ÄÇÊàëÂÄëÈÄèÈÅé‰∏ÄÂÄãÂàÜ‰ΩàÊ™¢Ê∏¨ÂØ¶È©óÈ©óË≠âÊàëÂÄë‰ΩøÁî® WordNet ÁöÑÊñπÂºèÔºå‰∏¶Âú®‰∏ÄÂÄãÁâ©‰ª∂ÂÆö‰ΩçÂü∫Ê∫ñÊ∏¨Ë©¶‰∏≠Ê∏¨Ë©¶ ConVisÔºåÈ°ØÁ§∫Ê¶ÇÂøµË¶ñË¶∫ÂåñÂèØ‰ª•Ê≠£Á¢∫Ë≠òÂà•ÂíåÂÆö‰ΩçÂΩ±ÂÉèÁöÑË™ûÁæ©ÂÖßÂÆπ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÈÄ≤Ë°å‰∫Ü‰∏ÄÈ†Ö‰ΩøÁî®ËÄÖÁ†îÁ©∂ÔºåË≠âÊòéÊàëÂÄëÁöÑÊñπÊ≥ïÂèØ‰ª•ËÆì‰ΩøÁî®ËÄÖÊ∑±ÂÖ•‰∫ÜËß£Ê®°ÂûãÁöÑÂäüËÉΩ„ÄÇ</paragraph>

##### **Exploring the use of a Large Language Model for data extraction in systematic reviews: a rapid feasibility study**
2405.14445v1 by Lena Schmidt, Kaitlyn Hair, Sergio Graziozi, Fiona Campbell, Claudia Kapp, Alireza Khanteymoori, Dawn Craig, Mark Engelbert, James Thomas

This paper describes a rapid feasibility study of using GPT-4, a large
language model (LLM), to (semi)automate data extraction in systematic reviews.
Despite the recent surge of interest in LLMs there is still a lack of
understanding of how to design LLM-based automation tools and how to robustly
evaluate their performance. During the 2023 Evidence Synthesis Hackathon we
conducted two feasibility studies. Firstly, to automatically extract study
characteristics from human clinical, animal, and social science domain studies.
We used two studies from each category for prompt-development; and ten for
evaluation. Secondly, we used the LLM to predict Participants, Interventions,
Controls and Outcomes (PICOs) labelled within 100 abstracts in the EBM-NLP
dataset. Overall, results indicated an accuracy of around 80%, with some
variability between domains (82% for human clinical, 80% for animal, and 72%
for studies of human social sciences). Causal inference methods and study
design were the data extraction items with the most errors. In the PICO study,
participants and intervention/control showed high accuracy (>80%), outcomes
were more challenging. Evaluation was done manually; scoring methods such as
BLEU and ROUGE showed limited value. We observed variability in the LLMs
predictions and changes in response quality. This paper presents a template for
future evaluations of LLMs in the context of data extraction for systematic
review automation. Our results show that there might be value in using LLMs,
for example as second or third reviewers. However, caution is advised when
integrating models such as GPT-4 into tools. Further research on stability and
reliability in practical settings is warranted for each type of data that is
processed by the LLM.

ÊëòË¶ÅÔºöÈÄôÁØáË´ñÊñáÊèèËø∞‰∫Ü‰∏ÄÂÄã‰ΩøÁî® GPT-4Ôºà‰∏ÄÁ®ÆÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºåLLMÔºâ‰æÜÔºàÂçäÔºâËá™ÂãïÂåñÁ≥ªÁµ±ÂåñÂõûÈ°ß‰∏≠Ë≥áÊñôËêÉÂèñÁöÑÂø´ÈÄüÂèØË°åÊÄßÁ†îÁ©∂„ÄÇÂÑòÁÆ°ÊúÄËøëÂ∞ç LLM ÁöÑËààË∂£ÊøÄÂ¢ûÔºå‰ΩÜÂ∞çÊñºÂ¶Ç‰ΩïË®≠Ë®àÂü∫Êñº LLM ÁöÑËá™ÂãïÂåñÂ∑•ÂÖ∑‰ª•ÂèäÂ¶Ç‰ΩïÁ©©ÂÅ•Âú∞Ë©ï‰º∞ÂÖ∂ÊïàËÉΩÔºå‰ªçÁÑ∂Áº∫‰πè‰∫ÜËß£„ÄÇÂú® 2023 Âπ¥Ë≠âÊìöÁ∂úÂêàÈªëÂÆ¢ÊùæÊúüÈñìÔºåÊàëÂÄëÈÄ≤Ë°å‰∫ÜÂÖ©È†ÖÂèØË°åÊÄßÁ†îÁ©∂„ÄÇÈ¶ñÂÖàÔºåËá™ÂãïÂæû‰∫∫È°ûËá®Â∫ä„ÄÅÂãïÁâ©ÂíåÁ§æÊúÉÁßëÂ≠∏È†òÂüüÁ†îÁ©∂‰∏≠ËêÉÂèñÁ†îÁ©∂ÁâπÂæµ„ÄÇÊàëÂÄë‰ΩøÁî®ÊØèÂÄãÈ°ûÂà•‰∏≠ÁöÑÂÖ©È†ÖÁ†îÁ©∂ÈÄ≤Ë°åÊèêÁ§∫ÈñãÁôºÔºõ‰∏¶‰ΩøÁî®ÂçÅÈ†ÖÈÄ≤Ë°åË©ï‰º∞„ÄÇÂÖ∂Ê¨°ÔºåÊàëÂÄë‰ΩøÁî® LLM ‰æÜÈ†êÊ∏¨ EBM-NLP Ë≥áÊñôÈõÜ‰∏≠ÁöÑ 100 ÁØáÊëòË¶Å‰∏≠Ê®ôË®òÁöÑÂèÉËàáËÄÖ„ÄÅÂπ≤È†êÊé™ÊñΩ„ÄÅÂ∞çÁÖßÂíåÁµêÊûúÔºàPICOsÔºâ„ÄÇÁ∏ΩÈ´îËÄåË®ÄÔºåÁµêÊûúÈ°ØÁ§∫Ê∫ñÁ¢∫Â∫¶Á¥ÑÁÇ∫ 80%Ôºå‰∏çÂêåÈ†òÂüü‰πãÈñìÂ≠òÂú®‰∏Ä‰∫õÂ∑ÆÁï∞Ôºà‰∫∫È°ûËá®Â∫äÁÇ∫ 82%ÔºåÂãïÁâ©ÁÇ∫ 80%Ôºå‰∫∫È°ûÁ§æÊúÉÁßëÂ≠∏Á†îÁ©∂ÁÇ∫ 72%Ôºâ„ÄÇÂõ†ÊûúÊé®Ë´ñÊñπÊ≥ïÂíåÁ†îÁ©∂Ë®≠Ë®àÊòØË≥áÊñôËêÉÂèñÈ†ÖÁõÆ‰∏≠ÈåØË™§ÊúÄÂ§öÁöÑ„ÄÇÂú® PICO Á†îÁ©∂‰∏≠ÔºåÂèÉËàáËÄÖÂíåÂπ≤È†ê/Â∞çÁÖßÈ°ØÁ§∫Âá∫È´òÊ∫ñÁ¢∫Â∫¶Ôºà>80%ÔºâÔºåÁµêÊûúÊõ¥ÂÖ∑ÊåëÊà∞ÊÄß„ÄÇË©ï‰º∞ÊòØÊâãÂãïÂÆåÊàêÁöÑÔºõBLEU Âíå ROUGE Á≠âË®àÂàÜÊñπÊ≥ïÈ°ØÁ§∫ÁöÑÂÉπÂÄºÊúâÈôê„ÄÇÊàëÂÄëËßÄÂØüÂà∞ LLM È†êÊ∏¨ÂíåÂõûÊáâÂìÅË≥™ËÆäÂåñÁöÑËÆäÁï∞ÊÄß„ÄÇÊú¨ÊñáÊèê‰æõ‰∫Ü LLM Âú®Á≥ªÁµ±ÂåñÂõûÈ°ßËá™ÂãïÂåñÁöÑË≥áÊñôËêÉÂèñËÉåÊôØ‰∏ãÁöÑÊú™‰æÜË©ï‰º∞ÁØÑÊú¨„ÄÇÊàëÂÄëÁöÑÁµêÊûúÈ°ØÁ§∫‰ΩøÁî® LLM ÂèØËÉΩÊúâÂÉπÂÄºÔºå‰æãÂ¶Ç‰ΩúÁÇ∫Á¨¨‰∫åÊàñÁ¨¨‰∏â‰ΩçÂØ©Êü•ËÄÖ„ÄÇ‰ΩÜÊòØÔºåÂú®Â∞á GPT-4 Á≠âÊ®°ÂûãÊï¥ÂêàÂà∞Â∑•ÂÖ∑‰∏≠ÊôÇÔºåÂª∫Ë≠∞‰øùÊåÅË¨πÊÖé„ÄÇÂ∞çÊñº LLM ËôïÁêÜÁöÑÊØèÁ®ÆÈ°ûÂûãË≥áÊñôÔºåÈÉΩÊúâÂøÖË¶ÅÈÄ≤‰∏ÄÊ≠•Á†îÁ©∂ÂØ¶ÈöõË®≠ÂÆö‰∏≠ÁöÑÁ©©ÂÆöÊÄßÂíåÂèØÈù†ÊÄß„ÄÇ

##### **Unraveling overoptimism and publication bias in ML-driven science**
2405.14422v1 by Pouria Saidi, Gautam Dasarathy, Visar Berisha

Machine Learning (ML) is increasingly used across many disciplines with
impressive reported results across many domain areas. However, recent studies
suggest that the published performance of ML models are often overoptimistic
and not reflective of true accuracy were these models to be deployed. Validity
concerns are underscored by findings of a concerning inverse relationship
between sample size and reported accuracy in published ML models across several
domains. This is in contrast with the theory of learning curves in ML, where we
expect accuracy to improve or stay the same with increasing sample size. This
paper investigates the factors contributing to overoptimistic accuracy reports
in ML-based science, focusing on data leakage and publication bias. Our study
introduces a novel stochastic model for observed accuracy, integrating
parametric learning curves and the above biases. We then construct an estimator
based on this model that corrects for these biases in observed data.
Theoretical and empirical results demonstrate that this framework can estimate
the underlying learning curve that gives rise to the observed overoptimistic
results, thereby providing more realistic performance assessments of ML
performance from a collection of published results. We apply the model to
various meta-analyses in the digital health literature, including
neuroimaging-based and speech-based classifications of several neurological
conditions. Our results indicate prevalent overoptimism across these fields and
we estimate the inherent limits of ML-based prediction in each domain.

ÊëòË¶ÅÔºöÊ©üÂô®Â≠∏Áøí (ML) ÊÑà‰æÜÊÑàÂª£Ê≥õÂú∞Áî®ÊñºË®±Â§öÈ†òÂüüÔºåÂú®Ë®±Â§öÈ†òÂüüÈÉΩÂ†±Âëä‰∫Ü‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑÁµêÊûú„ÄÇÁÑ∂ËÄåÔºåÊúÄËøëÁöÑÁ†îÁ©∂Ë°®ÊòéÔºåML Ê®°ÂûãÂ∑≤ÁôºË°®ÁöÑÊïàËÉΩÂæÄÂæÄÈÅéÊñºÊ®ÇËßÄÔºå‰∏îÁÑ°Ê≥ïÂèçÊò†ÈÄô‰∫õÊ®°ÂûãÈÉ®ÁΩ≤ÂæåÁöÑÁúüÂØ¶Ê∫ñÁ¢∫Â∫¶„ÄÇÊúâÊïàÊÄßÁñëÊÖÆÂèóÂà∞‰ª§‰∫∫ÊìîÊÜÇÁöÑÁôºÁèæÁöÑÂº∑Ë™øÔºåÂç≥Âú®ÂπæÂÄãÈ†òÂüü‰∏≠ÔºåÂ∑≤ÁôºË°®ÁöÑ ML Ê®°Âûã‰∏≠ÁöÑÊ®£Êú¨Â§ßÂ∞èËàáÂ†±ÂëäÁöÑÊ∫ñÁ¢∫Â∫¶‰πãÈñìÂ≠òÂú®ÂèçÊØîÈóú‰øÇ„ÄÇÈÄôËàá ML ‰∏≠ÁöÑÂ≠∏ÁøíÊõ≤Á∑öÁêÜË´ñÁõ∏ÂèçÔºåÂú® ML ‰∏≠ÔºåÊàëÂÄëÈ†êÊúüÊ∫ñÁ¢∫Â∫¶ÊúÉÈö®ËëóÊ®£Êú¨Â§ßÂ∞èÁöÑÂ¢ûÂä†ËÄåÊèêÂçáÊàñ‰øùÊåÅ‰∏çËÆä„ÄÇÊú¨ÊñáÊé¢Ë®é‰∫ÜÂ∞éËá¥ ML Âü∫Á§éÁßëÂ≠∏‰∏≠ÈÅéÂ∫¶Ê®ÇËßÄÁöÑÊ∫ñÁ¢∫Â∫¶Â†±ÂëäÁöÑÂõ†Á¥†ÔºåÈáçÈªûÂú®ÊñºË≥áÊñôÂ§ñÊ¥©ÂíåÁôºË°®ÂÅèË™§„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÊñ∞Á©éÁöÑËßÄÊ∏¨Ê∫ñÁ¢∫Â∫¶Èö®Ê©üÊ®°ÂûãÔºåÊï¥Âêà‰∫ÜÂèÉÊï∏Â≠∏ÁøíÊõ≤Á∑öÂíå‰∏äËø∞ÂÅèË™§„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÊ†πÊìöÊ≠§Ê®°ÂûãÂª∫Êßã‰∫Ü‰∏ÄÂÄã‰º∞Ë®àÂô®Ôºå‰ª•‰øÆÊ≠£ËßÄÊ∏¨Ë≥áÊñô‰∏≠ÁöÑÈÄô‰∫õÂÅèË™§„ÄÇÁêÜË´ñÂíåÁ∂ìÈ©óÁµêÊûúË≠âÊòéÔºåÊ≠§Êû∂ÊßãÂèØ‰ª•‰º∞Ë®àÂ∞éËá¥ËßÄÊ∏¨ÈÅéÂ∫¶Ê®ÇËßÄÁµêÊûúÁöÑÂ∫ïÂ±§Â≠∏ÁøíÊõ≤Á∑öÔºåÂæûËÄåÊèê‰æõÊõ¥ÂØ¶ÈöõÁöÑ ML ÊïàËÉΩË©ï‰º∞ÔºåÈÄô‰∫õË©ï‰º∞‰æÜËá™‰∏ÄÁ≥ªÂàóÂ∑≤ÁôºË°®ÁöÑÁµêÊûú„ÄÇÊàëÂÄëÂ∞áÊ≠§Ê®°ÂûãÊáâÁî®ÊñºÊï∏‰ΩçÂÅ•Â∫∑ÊñáÁçª‰∏≠ÁöÑÂêÑÁ®ÆÂæåË®≠ÂàÜÊûêÔºåÂåÖÊã¨Âü∫ÊñºÁ•ûÁ∂ìÂΩ±ÂÉèÂíåÂü∫ÊñºË™ûÈü≥ÁöÑÂπæÁ®ÆÁ•ûÁ∂ìÁãÄÊ≥ÅÂàÜÈ°û„ÄÇÊàëÂÄëÁöÑÁµêÊûúÊåáÂá∫ÈÄô‰∫õÈ†òÂüüÊôÆÈÅçÂ≠òÂú®ÈÅéÂ∫¶Ê®ÇËßÄÔºå‰∏¶‰∏îÊàëÂÄë‰º∞Ë®à‰∫ÜÊØèÂÄãÈ†òÂüü‰∏≠Âü∫Êñº ML ÁöÑÈ†êÊ∏¨ÁöÑÂÖßÂú®ÈôêÂà∂„ÄÇ

##### **Boosting Medical Image-based Cancer Detection via Text-guided Supervision from Reports**
2405.14230v1 by Guangyu Guo, Jiawen Yao, Yingda Xia, Tony C. W. Mok, Zhilin Zheng, Junwei Han, Le Lu, Dingwen Zhang, Jian Zhou, Ling Zhang

The absence of adequately sufficient expert-level tumor annotations hinders
the effectiveness of supervised learning based opportunistic cancer screening
on medical imaging. Clinical reports (that are rich in descriptive textual
details) can offer a "free lunch'' supervision information and provide tumor
location as a type of weak label to cope with screening tasks, thus saving
human labeling workloads, if properly leveraged. However, predicting cancer
only using such weak labels can be very changeling since tumors are usually
presented in small anatomical regions compared to the whole 3D medical scans.
Weakly semi-supervised learning (WSSL) utilizes a limited set of voxel-level
tumor annotations and incorporates alongside a substantial number of medical
images that have only off-the-shelf clinical reports, which may strike a good
balance between minimizing expert annotation workload and optimizing screening
efficacy. In this paper, we propose a novel text-guided learning method to
achieve highly accurate cancer detection results. Through integrating
diagnostic and tumor location text prompts into the text encoder of a
vision-language model (VLM), optimization of weakly supervised learning can be
effectively performed in the latent space of VLM, thereby enhancing the
stability of training. Our approach can leverage clinical knowledge by
large-scale pre-trained VLM to enhance generalization ability, and produce
reliable pseudo tumor masks to improve cancer detection. Our extensive
quantitative experimental results on a large-scale cancer dataset, including
1,651 unique patients, validate that our approach can reduce human annotation
efforts by at least 70% while maintaining comparable cancer detection accuracy
to competing fully supervised methods (AUC value 0.961 versus 0.966).

ÊëòË¶ÅÔºöÁî±ÊñºÁº∫‰πèË∂≥Â§†ÁöÑÂ∞àÂÆ∂Á≠âÁ¥öËÖ´Áò§Ê®ôË®òÔºåÊúÉÈòªÁ§ôÂü∫ÊñºÁõ£Áù£ÂºèÂ≠∏ÁøíÁöÑÊ©üÊúÉ‰∏ªÁæ©ÁôåÁóáÁØ©Ê™¢Âú®ÈÜ´Â≠∏ÂΩ±ÂÉè‰∏äÁöÑÊïàËÉΩ„ÄÇËá®Â∫äÂ†±ÂëäÔºàÂåÖÂê´Ë±êÂØåÁöÑÊèèËø∞ÊÄßÊñáÂ≠óÁ¥∞ÁØÄÔºâÂèØÊèê‰æõ„ÄåÂÖçË≤ªÁöÑÂçàÈ§ê„ÄçÁõ£Áù£Ë≥áË®äÔºå‰∏¶Êèê‰æõËÖ´Áò§‰ΩçÁΩÆ‰ΩúÁÇ∫‰∏ÄÁ®ÆÂº±Ê®ôÁ±§‰ª•ÊáâÂ∞çÁØ©Ê™¢‰ªªÂãôÔºåÂæûËÄåÁØÄÁúÅ‰∫∫Â∑•Ê®ôÁ±§ÁöÑÂ∑•‰ΩúÈáèÔºåÂè™Ë¶ÅÈÅ©Áï∂Âà©Áî®Âç≥ÂèØ„ÄÇÁÑ∂ËÄåÔºåÂÉÖ‰ΩøÁî®Ê≠§È°ûÂº±Ê®ôÁ±§‰æÜÈ†êÊ∏¨ÁôåÁóáÂèØËÉΩÈùûÂ∏∏Âõ∞Èõ£ÔºåÂõ†ÁÇ∫ËàáÊï¥ÂÄã 3D ÈÜ´Â≠∏ÊéÉÊèèÁõ∏ÊØîÔºåËÖ´Áò§ÈÄöÂ∏∏Âá∫ÁèæÂú®ËºÉÂ∞èÁöÑËß£ÂâñÂçÄÂüü‰∏≠„ÄÇÂº±ÂçäÁõ£Áù£ÂºèÂ≠∏ÁøíÔºàWSSLÔºâÂà©Áî®ÊúâÈôêÁöÑÈ´îÁ¥†Á¥öËÖ´Áò§Ê®ôË®òÔºå‰∏¶ÁµêÂêàÂ§ßÈáèÂÉÖÊúâÁèæÊàêËá®Â∫äÂ†±ÂëäÁöÑÈÜ´Â≠∏ÂΩ±ÂÉèÔºåÈÄôÂèØËÉΩÊúÉÂú®ÊúÄÂ§ßÁ®ãÂ∫¶Ê∏õÂ∞ëÂ∞àÂÆ∂Ê®ôË®òÂ∑•‰ΩúÈáèÂíåÊúÄ‰Ω≥ÂåñÁØ©Ê™¢ÊïàËÉΩ‰πãÈñìÂèñÂæóËâØÂ•ΩÁöÑÂπ≥Ë°°„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÊñáÂ≠óÂºïÂ∞éÂ≠∏ÁøíÊñπÊ≥ïÔºå‰ª•ÈÅîÊàêÈ´òÂ∫¶Ê∫ñÁ¢∫ÁöÑÁôåÁóáÂÅµÊ∏¨ÁµêÊûú„ÄÇÈÄèÈÅéÂ∞áË®∫Êñ∑ÂíåËÖ´Áò§‰ΩçÁΩÆÊñáÂ≠óÊèêÁ§∫Êï¥ÂêàÂà∞Ë¶ñË¶∫Ë™ûË®ÄÊ®°ÂûãÔºàVLMÔºâÁöÑÊñáÂ≠óÁ∑®Á¢ºÂô®‰∏≠ÔºåÂèØ‰ª•Âú® VLM ÁöÑÊΩõÂú®Á©∫Èñì‰∏≠ÊúâÊïàÂü∑Ë°åÂº±Áõ£Áù£ÂºèÂ≠∏ÁøíÁöÑÊúÄ‰Ω≥ÂåñÔºåÂæûËÄåÂ¢ûÂº∑Ë®ìÁ∑¥ÁöÑÁ©©ÂÆöÊÄß„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÂèØ‰ª•ÈÄèÈÅéÂ§ßË¶èÊ®°È†êÂÖàË®ìÁ∑¥ÁöÑ VLM ‰æÜÂà©Áî®Ëá®Â∫äÁü•Ë≠ò‰ª•Â¢ûÂº∑Ê≥õÂåñËÉΩÂäõÔºå‰∏¶Áî¢ÁîüÂèØÈù†ÁöÑÂÅΩËÖ´Áò§ÈÅÆÁΩ©‰ª•ÊîπÂñÑÁôåÁóáÂÅµÊ∏¨„ÄÇÊàëÂÄëÂú®ÂåÖÂê´ 1,651 ‰ΩçÁç®ÁâπÊÇ£ËÄÖÁöÑÂ§ßË¶èÊ®°ÁôåÁóáË≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÁöÑÂª£Ê≥õÂÆöÈáèÂØ¶È©óÁµêÊûúÈ©óË≠â‰∫ÜÊàëÂÄëÁöÑÂÅöÊ≥ïÂèØ‰ª•Â∞á‰∫∫Â∑•Ê®ôË®òÂ∑•‰ΩúÈáèËá≥Â∞ëÊ∏õÂ∞ë 70%ÔºåÂêåÊôÇÁ∂≠ÊåÅËàáÁ´∂Áà≠ÁöÑÂÖ®Áõ£Áù£ÂºèÊñπÊ≥ïÁõ∏Áï∂ÁöÑÁôåÁóáÂÅµÊ∏¨Ê∫ñÁ¢∫Â∫¶ÔºàAUC ÂÄº 0.961 Â∞çÊØî 0.966Ôºâ„ÄÇ

##### **Investigation of Customized Medical Decision Algorithms Utilizing Graph Neural Networks**
2405.17460v1 by Yafeng Yan, Shuyao He, Zhou Yu, Jiajie Yuan, Ziang Liu, Yan Chen

Aiming at the limitations of traditional medical decision system in
processing large-scale heterogeneous medical data and realizing highly
personalized recommendation, this paper introduces a personalized medical
decision algorithm utilizing graph neural network (GNN). This research
innovatively integrates graph neural network technology into the medical and
health field, aiming to build a high-precision representation model of patient
health status by mining the complex association between patients' clinical
characteristics, genetic information, living habits. In this study, medical
data is preprocessed to transform it into a graph structure, where nodes
represent different data entities (such as patients, diseases, genes, etc.) and
edges represent interactions or relationships between entities. The core of the
algorithm is to design a novel multi-scale fusion mechanism, combining the
historical medical records, physiological indicators and genetic
characteristics of patients, to dynamically adjust the attention allocation
strategy of the graph neural network, so as to achieve highly customized
analysis of individual cases. In the experimental part, this study selected
several publicly available medical data sets for validation, and the results
showed that compared with traditional machine learning methods and a single
graph neural network model, the proposed personalized medical decision
algorithm showed significantly superior performance in terms of disease
prediction accuracy, treatment effect evaluation and patient risk
stratification.

ÊëòË¶ÅÔºöÈáùÂ∞çÂÇ≥Áµ±ÈÜ´ÁôÇÊ±∫Á≠ñÁ≥ªÁµ±Âú®ËôïÁêÜÂ§ßË¶èÊ®°Áï∞Ë≥™ÈÜ´ÁôÇË≥áÊñôÂíåÂØ¶ÁèæÈ´òÂ∫¶ÂÄã‰∫∫ÂåñÊé®Ëñ¶‰∏äÁöÑÈôêÂà∂ÔºåÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂà©Áî®ÂúñÁ•ûÁ∂ìÁ∂≤Ë∑Ø (GNN) ÁöÑÂÄã‰∫∫ÂåñÈÜ´ÁôÇÊ±∫Á≠ñÊºîÁÆóÊ≥ï„ÄÇÊú¨Á†îÁ©∂ÂâµÊñ∞Âú∞Â∞áÂúñÁ•ûÁ∂ìÁ∂≤Ë∑ØÊäÄË°ìÊï¥ÂêàÂà∞ÈÜ´ÁôÇ‰øùÂÅ•È†òÂüüÔºåÊó®Âú®ÈÄèÈÅéÊåñÊéòÊÇ£ËÄÖËá®Â∫äÁâπÂæµ„ÄÅÈÅ∫ÂÇ≥Ë≥áË®ä„ÄÅÁîüÊ¥ªÁøíÊÖ£‰πãÈñìÁöÑË§áÈõúÈóúËÅØÔºåÂª∫Á´ãÊÇ£ËÄÖÂÅ•Â∫∑ÁãÄÊÖãÁöÑÈ´òÁ≤æÂ∫¶Ë°®Á§∫Ê®°Âûã„ÄÇÊú¨Á†îÁ©∂‰∏≠ÔºåÈÜ´ÁôÇË≥áÊñôÁ∂ìÈÅéÈ†êËôïÁêÜËΩâÊèõÁÇ∫ÂúñÁµêÊßãÔºåÂÖ∂‰∏≠ÁØÄÈªûË°®Á§∫‰∏çÂêåÁöÑË≥áÊñôÂØ¶È´îÔºà‰æãÂ¶ÇÊÇ£ËÄÖ„ÄÅÁñæÁóÖ„ÄÅÂü∫Âõ†Á≠âÔºâÔºåËÄåÈÇäÁ∑£Ë°®Á§∫ÂØ¶È´î‰πãÈñìÁöÑ‰∫íÂãïÊàñÈóú‰øÇ„ÄÇË©≤ÊºîÁÆóÊ≥ïÁöÑÊ†∏ÂøÉÊòØË®≠Ë®à‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÂ§öÂ∞∫Â∫¶ËûçÂêàÊ©üÂà∂ÔºåÁµêÂêàÊÇ£ËÄÖÁöÑÊ≠∑Âè≤ÁóÖÊ≠∑„ÄÅÁîüÁêÜÊåáÊ®ôÂíåÈÅ∫ÂÇ≥ÁâπÂæµÔºåÂãïÊÖãË™øÊï¥ÂúñÁ•ûÁ∂ìÁ∂≤Ë∑ØÁöÑÊ≥®ÊÑèÂäõÂàÜÈÖçÁ≠ñÁï•Ôºå‰ª•ÂØ¶ÁèæÂ∞çÂÄãÊ°àÁöÑÈ´òÂ∫¶ÂÆ¢Ë£ΩÂåñÂàÜÊûê„ÄÇÂú®ÂØ¶È©óÈÉ®ÂàÜÔºåÊú¨Á†îÁ©∂ÈÅ∏Âèñ‰∫ÜÊï∏ÂÄãÂÖ¨ÈñãÁöÑÈÜ´ÁôÇË≥áÊñôÈõÜÈÄ≤Ë°åÈ©óË≠âÔºåÁµêÊûúÈ°ØÁ§∫ÔºåËàáÂÇ≥Áµ±Ê©üÂô®Â≠∏ÁøíÊñπÊ≥ïÂíåÂñÆ‰∏ÄÂúñÁ•ûÁ∂ìÁ∂≤Ë∑ØÊ®°ÂûãÁõ∏ÊØîÔºåÊâÄÊèêÂá∫ÁöÑÂÄã‰∫∫ÂåñÈÜ´ÁôÇÊ±∫Á≠ñÊºîÁÆóÊ≥ïÂú®ÁñæÁóÖÈ†êÊ∏¨Ê∫ñÁ¢∫Â∫¶„ÄÅÊ≤ªÁôÇÊïàÊûúË©ï‰º∞ÂíåÊÇ£ËÄÖÈ¢®Èö™ÂàÜÂ±§ÊñπÈù¢Ë°®ÁèæÂá∫È°ØËëóÁöÑÂÑ™Áï∞ÊïàËÉΩ„ÄÇ

##### **Integrating Medical Imaging and Clinical Reports Using Multimodal Deep Learning for Advanced Disease Analysis**
2405.17459v1 by Ziyan Yao, Fei Lin, Sheng Chai, Weijie He, Lu Dai, Xinghui Fei

In this paper, an innovative multi-modal deep learning model is proposed to
deeply integrate heterogeneous information from medical images and clinical
reports. First, for medical images, convolutional neural networks were used to
extract high-dimensional features and capture key visual information such as
focal details, texture and spatial distribution. Secondly, for clinical report
text, a two-way long and short-term memory network combined with an attention
mechanism is used for deep semantic understanding, and key statements related
to the disease are accurately captured. The two features interact and integrate
effectively through the designed multi-modal fusion layer to realize the joint
representation learning of image and text. In the empirical study, we selected
a large medical image database covering a variety of diseases, combined with
corresponding clinical reports for model training and validation. The proposed
multimodal deep learning model demonstrated substantial superiority in the
realms of disease classification, lesion localization, and clinical description
generation, as evidenced by the experimental results.

ÊëòË¶ÅÔºöÂú®Êú¨Êñá‰∏≠ÔºåÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂâµÊñ∞ÁöÑÂ§öÊ®°ÊÖãÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÔºå‰ª•Ê∑±ÂÖ•Êï¥Âêà‰æÜËá™ÈÜ´Â≠∏ÂΩ±ÂÉèÂíåËá®Â∫äÂ†±ÂëäÁöÑÁï∞Ë≥™Ë≥áË®ä„ÄÇÈ¶ñÂÖàÔºåÂ∞çÊñºÈÜ´Â≠∏ÂΩ±ÂÉèÔºå‰ΩøÁî®Âç∑Á©çÁ•ûÁ∂ìÁ∂≤Ë∑Ø‰æÜÊèêÂèñÈ´òÁ∂≠ÁâπÂæµ‰∏¶Êì∑ÂèñÈóúÈçµË¶ñË¶∫Ë≥áË®äÔºå‰æãÂ¶ÇÁÑ¶ÈªûÁ¥∞ÁØÄ„ÄÅÁ¥ãÁêÜÂíåÁ©∫ÈñìÂàÜ‰Ωà„ÄÇÂÖ∂Ê¨°ÔºåÂ∞çÊñºËá®Â∫äÂ†±ÂëäÊñáÂ≠óÔºå‰ΩøÁî®ÁµêÂêàÊ≥®ÊÑèÂäõÊ©üÂà∂ÁöÑÈõôÂêëÈï∑Áü≠ÊúüË®òÊÜ∂Á∂≤Ë∑ØÈÄ≤Ë°åÊ∑±Â∫¶Ë™ûÁæ©ÁêÜËß£Ôºå‰∏¶Ê∫ñÁ¢∫Êì∑ÂèñËàáÁñæÁóÖÁõ∏ÈóúÁöÑÈóúÈçµÈô≥Ëø∞„ÄÇÈÄôÂÖ©ÂÄãÁâπÂæµÈÄöÈÅéË®≠Ë®àÁöÑÂ§öÊ®°ÊÖãËûçÂêàÂ±§ÊúâÊïàÂú∞‰∫§‰∫íÂíåÊï¥ÂêàÔºå‰ª•ÂØ¶ÁèæÂΩ±ÂÉèÂíåÊñáÂ≠óÁöÑËÅØÂêàË°®ÂæµÂ≠∏Áøí„ÄÇÂú®ÂØ¶Ë≠âÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄëÈÅ∏Êìá‰∫Ü‰∏ÄÂÄãÊ∂µËìãÂêÑÁ®ÆÁñæÁóÖÁöÑÂ§ßÂûãÈÜ´Â≠∏ÂΩ±ÂÉèË≥áÊñôÂ∫´Ôºå‰∏¶ÁµêÂêàÂ∞çÊáâÁöÑËá®Â∫äÂ†±ÂëäÈÄ≤Ë°åÊ®°ÂûãË®ìÁ∑¥ÂíåÈ©óË≠â„ÄÇÊâÄÊèêÂá∫ÁöÑÂ§öÊ®°ÊÖãÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÂú®ÁñæÁóÖÂàÜÈ°û„ÄÅÁóÖÁÅ∂ÂÆö‰ΩçÂíåËá®Â∫äÊèèËø∞ÁîüÊàêÊñπÈù¢Ë°®ÁèæÂá∫È°ØËëóÁöÑÂÑ™Ë∂äÊÄßÔºåÂØ¶È©óÁµêÊûúË≠âÊòé‰∫ÜÈÄô‰∏ÄÈªû„ÄÇ

##### **Structural Entities Extraction and Patient Indications Incorporation for Chest X-ray Report Generation**
2405.14905v1 by Kang Liu, Zhuoqi Ma, Xiaolu Kang, Zhusi Zhong, Zhicheng Jiao, Grayson Baird, Harrison Bai, Qiguang Miao

The automated generation of imaging reports proves invaluable in alleviating
the workload of radiologists. A clinically applicable reports generation
algorithm should demonstrate its effectiveness in producing reports that
accurately describe radiology findings and attend to patient-specific
indications. In this paper, we introduce a novel method, \textbf{S}tructural
\textbf{E}ntities extraction and patient indications \textbf{I}ncorporation
(SEI) for chest X-ray report generation. Specifically, we employ a structural
entities extraction (SEE) approach to eliminate presentation-style vocabulary
in reports and improve the quality of factual entity sequences. This reduces
the noise in the following cross-modal alignment module by aligning X-ray
images with factual entity sequences in reports, thereby enhancing the
precision of cross-modal alignment and further aiding the model in
gradient-free retrieval of similar historical cases. Subsequently, we propose a
cross-modal fusion network to integrate information from X-ray images, similar
historical cases, and patient-specific indications. This process allows the
text decoder to attend to discriminative features of X-ray images, assimilate
historical diagnostic information from similar cases, and understand the
examination intention of patients. This, in turn, assists in triggering the
text decoder to produce high-quality reports. Experiments conducted on
MIMIC-CXR validate the superiority of SEI over state-of-the-art approaches on
both natural language generation and clinical efficacy metrics.

ÊëòË¶ÅÔºö<paragraph>ÂΩ±ÂÉèÂ†±ÂëäÁöÑËá™ÂãïÁîüÊàêÂú®Ê∏õËºïÊîæÂ∞ÑÁßëÈÜ´Â∏´ÁöÑÂ∑•‰ΩúË≤†ÊìîÊñπÈù¢Ë≠âÊòé‰∫ÜÂÖ∂ÁÑ°ÂèØÊØîÊì¨ÁöÑÂÉπÂÄº„ÄÇ‰∏ÄÂÄãËá®Â∫ä‰∏äÈÅ©Áî®ÁöÑÂ†±ÂëäÁîüÊàêÊºîÁÆóÊ≥ïÊáâË©≤Â±ïÁ§∫ÂÖ∂Âú®Áî¢ÁîüÂ†±ÂëäÊñπÈù¢ÁöÑÊúâÊïàÊÄßÔºåÈÄô‰∫õÂ†±ÂëäÊ∫ñÁ¢∫Âú∞ÊèèËø∞‰∫ÜÊîæÂ∞ÑÁßëÁôºÁèæÔºå‰∏¶Ê≥®ÊÑèÊÇ£ËÄÖÁâπÂÆöÁöÑÈÅ©ÊáâÁóá„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫Ü‰∏ÄÁ®ÆÊñ∞ÊñπÊ≥ïÔºåÂç≥ËÉ∏ÈÉ® X ÂÖâÂ†±ÂëäÁîüÊàêÁöÑÁµêÊßãÂØ¶È´îËêÉÂèñÂíåÊÇ£ËÄÖÈÅ©ÊáâÁóáÊï¥Âêà (SEI)„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÊé°Áî®ÁµêÊßãÂØ¶È´îËêÉÂèñ (SEE) ÊñπÊ≥ï‰æÜÊ∂àÈô§Â†±Âëä‰∏≠ÁöÑÂëàÁèæÂºèË©ûÂΩôÔºå‰∏¶ÊèêÈ´ò‰∫ãÂØ¶ÂØ¶È´îÂ∫èÂàóÁöÑÂìÅË≥™„ÄÇÈÄôÊúÉÊ∏õÂ∞ëÂæåÁ∫åË∑®Ê®°ÊÖãÂ∞çÈΩäÊ®°ÁµÑ‰∏≠ÁöÑÈõúË®äÔºåÈÄèÈÅéÂ∞á X ÂÖâÂΩ±ÂÉèËàáÂ†±Âëä‰∏≠ÁöÑ‰∫ãÂØ¶ÂØ¶È´îÂ∫èÂàóÂ∞çÈΩäÔºåÈÄ≤ËÄåÊèêÂçáË∑®Ê®°ÊÖãÂ∞çÈΩäÁöÑÁ≤æÁ¢∫Â∫¶Ôºå‰∏¶ÈÄ≤‰∏ÄÊ≠•ÂçîÂä©Ê®°ÂûãÁÑ°Ê¢ØÂ∫¶Ê™¢Á¥¢È°û‰ººÁöÑÊ≠∑Âè≤Ê°à‰æã„ÄÇÈö®ÂæåÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãË∑®Ê®°ÊÖãËûçÂêàÁ∂≤Ë∑ØÔºå‰ª•Êï¥Âêà‰æÜËá™ X ÂÖâÂΩ±ÂÉè„ÄÅÈ°û‰ººÁöÑÊ≠∑Âè≤Ê°à‰æãÂíåÊÇ£ËÄÖÁâπÂÆöÈÅ©ÊáâÁóáÁöÑË≥áË®ä„ÄÇÈÄôÂÄãÈÅéÁ®ãÂÖÅË®±ÊñáÂ≠óËß£Á¢ºÂô®Ê≥®ÊÑè X ÂÖâÂΩ±ÂÉèÁöÑÂçÄÂà•ÁâπÂæµÔºåÂæûÈ°û‰ººÊ°à‰æã‰∏≠ÂΩôÊï¥Ê≠∑Âè≤Ë®∫Êñ∑Ë≥áË®äÔºå‰∏¶‰∫ÜËß£ÊÇ£ËÄÖÁöÑÊ™¢Êü•ÊÑèÂúñ„ÄÇÈÄôÂèçÈÅé‰æÜÊúâÂä©ÊñºËß∏ÁôºÊñáÂ≠óËß£Á¢ºÂô®Áî¢ÁîüÈ´òÂìÅË≥™ÁöÑÂ†±Âëä„ÄÇÂú® MIMIC-CXR ‰∏äÈÄ≤Ë°åÁöÑÂØ¶È©óÈ©óË≠â‰∫Ü SEI Âú®Ëá™ÁÑ∂Ë™ûË®ÄÁîüÊàêÂíåËá®Â∫äÁôÇÊïàÊåáÊ®ô‰∏äÂÑ™ÊñºÊúÄÂÖàÈÄ≤ÊñπÊ≥ïÁöÑÂÑ™Ë∂äÊÄß„ÄÇ</paragraph>

##### **How Many Bytes Can You Take Out Of Brain-To-Text Decoding?**
2405.14055v1 by Richard Antonello, Nihita Sarma, Jerry Tang, Jiaru Song, Alexander Huth

Brain-computer interfaces have promising medical and scientific applications
for aiding speech and studying the brain. In this work, we propose an
information-based evaluation metric for brain-to-text decoders. Using this
metric, we examine two methods to augment existing state-of-the-art continuous
text decoders. We show that these methods, in concert, can improve brain
decoding performance by upwards of 40% when compared to a baseline model. We
further examine the informatic properties of brain-to-text decoders and show
empirically that they have Zipfian power law dynamics. Finally, we provide an
estimate for the idealized performance of an fMRI-based text decoder. We
compare this idealized model to our current model, and use our
information-based metric to quantify the main sources of decoding error. We
conclude that a practical brain-to-text decoder is likely possible given
further algorithmic improvements.

ÊëòË¶ÅÔºöËÖ¶Ê©ü‰ªãÈù¢Âú®ËºîÂä©Ë™™Ë©±ÂíåÁ†îÁ©∂Â§ßËÖ¶ÊñπÈù¢ÂÖ∑ÊúâÂæàÊúâÂâçÊôØÁöÑÈÜ´ÁôÇÂíåÁßëÂ≠∏ÊáâÁî®„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂü∫ÊñºË≥áË®äÁöÑË©ï‰º∞ÊåáÊ®ôÔºåÁî®ÊñºËÖ¶Â∞çÊñáÂ≠óÁöÑËß£Á¢ºÂô®„ÄÇ‰ΩøÁî®Ê≠§ÊåáÊ®ôÔºåÊàëÂÄëÊé¢Ë®é‰∫ÜÂÖ©Á®ÆÊñπÊ≥ï‰æÜÊì¥ÂÖÖÁèæÊúâÁöÑÊúÄÂÖàÈÄ≤ÁöÑÈÄ£Á∫åÊñáÂ≠óËß£Á¢ºÂô®„ÄÇÊàëÂÄëË°®ÊòéÔºåÈÄô‰∫õÊñπÊ≥ïÂçîÂêå‰ΩúÁî®ÔºåËàáÂü∫Ê∫ñÊ®°ÂûãÁõ∏ÊØîÔºåÂèØ‰ª•Â∞áËÖ¶Ëß£Á¢ºÊÄßËÉΩÊèêÈ´ò 40% ‰ª•‰∏ä„ÄÇÊàëÂÄëÈÄ≤‰∏ÄÊ≠•Êé¢Ë®é‰∫ÜËÖ¶Â∞çÊñáÂ≠óËß£Á¢ºÂô®ÁöÑË≥áË®äÁâπÊÄßÔºå‰∏¶ÊÜëÁ∂ìÈ©óË°®ÊòéÂÆÉÂÄëÂÖ∑ÊúâÈΩäÂ§´ÂÆöÂæãÂãïÊÖã„ÄÇÊúÄÂæåÔºåÊàëÂÄëÊèê‰æõ‰∫ÜÂü∫Êñº fMRI ÁöÑÊñáÂ≠óËß£Á¢ºÂô®ÁöÑÁêÜÊÉ≥ÂåñÊÄßËÉΩ‰º∞Ë®à„ÄÇÊàëÂÄëÂ∞áÈÄôÂÄãÁêÜÊÉ≥ÂåñÁöÑÊ®°ÂûãËàáÊàëÂÄëÁõÆÂâçÁöÑÊ®°ÂûãÈÄ≤Ë°åÊØîËºÉÔºå‰∏¶‰ΩøÁî®ÊàëÂÄëÂü∫ÊñºË≥áË®äÁöÑÊåáÊ®ôÈáèÂåñËß£Á¢ºÈåØË™§ÁöÑ‰∏ªË¶Å‰æÜÊ∫ê„ÄÇÊàëÂÄëÂæóÂá∫ÁµêË´ñÔºåÂ¶ÇÊûúÈÄ≤‰∏ÄÊ≠•ÊîπÈÄ≤ÊºîÁÆóÊ≥ïÔºåÂØ¶Áî®ÁöÑËÖ¶Â∞çÊñáÂ≠óËß£Á¢ºÂô®ÂæàÂèØËÉΩÂØ¶Áèæ„ÄÇ

##### **Federated Learning in Healthcare: Model Misconducts, Security, Challenges, Applications, and Future Research Directions -- A Systematic Review**
2405.13832v1 by Md Shahin Ali, Md Manjurul Ahsan, Lamia Tasnim, Sadia Afrin, Koushik Biswas, Md Maruf Hossain, Md Mahfuz Ahmed, Ronok Hashan, Md Khairul Islam, Shivakumar Raman

Data privacy has become a major concern in healthcare due to the increasing
digitization of medical records and data-driven medical research. Protecting
sensitive patient information from breaches and unauthorized access is
critical, as such incidents can have severe legal and ethical complications.
Federated Learning (FL) addresses this concern by enabling multiple healthcare
institutions to collaboratively learn from decentralized data without sharing
it. FL's scope in healthcare covers areas such as disease prediction, treatment
customization, and clinical trial research. However, implementing FL poses
challenges, including model convergence in non-IID (independent and identically
distributed) data environments, communication overhead, and managing
multi-institutional collaborations. A systematic review of FL in healthcare is
necessary to evaluate how effectively FL can provide privacy while maintaining
the integrity and usability of medical data analysis. In this study, we analyze
existing literature on FL applications in healthcare. We explore the current
state of model security practices, identify prevalent challenges, and discuss
practical applications and their implications. Additionally, the review
highlights promising future research directions to refine FL implementations,
enhance data security protocols, and expand FL's use to broader healthcare
applications, which will benefit future researchers and practitioners.

ÊëòË¶ÅÔºöÁî±ÊñºÈÜ´ÁôÇË®òÈåÑÊï∏‰ΩçÂåñÂíåË≥áÊñôÈ©ÖÂãïÂûãÈÜ´ÁôÇÁ†îÁ©∂ÁöÑÂ¢ûÂä†ÔºåË≥áÊñôÈö±ÁßÅÂ∑≤ÊàêÁÇ∫ÈÜ´ÁôÇ‰øùÂÅ•ÁöÑ‰∏ªË¶ÅÂïèÈ°å„ÄÇ‰øùË≠∑ÊïèÊÑüÁöÑÊÇ£ËÄÖË≥áË®äÂÖçÊñºÂ§ñÊ¥©ÂíåÊú™Á∂ìÊéàÊ¨äÁöÑÂ≠òÂèñËá≥ÈóúÈáçË¶ÅÔºåÂõ†ÁÇ∫Ê≠§È°û‰∫ã‰ª∂ÂèØËÉΩÊúÉÈÄ†ÊàêÂö¥ÈáçÁöÑÊ≥ïÂæãÂíåÂÄ´ÁêÜÂïèÈ°å„ÄÇËÅØÂêàÂ≠∏Áøí (FL) ÈÄèÈÅéËÆìÂ§öÂÄãÈÜ´ÁôÇ‰øùÂÅ•Ê©üÊßãÂú®‰∏çÂÖ±‰∫´ÂàÜÊï£Ë≥áÊñôÁöÑÊÉÖÊ≥Å‰∏ãÈÄ≤Ë°åÂçî‰ΩúÂ≠∏ÁøíÔºå‰æÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°å„ÄÇFL Âú®ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÁöÑÁØÑÂúçÊ∂µËìãÁñæÁóÖÈ†êÊ∏¨„ÄÅÊ≤ªÁôÇÂÆ¢Ë£ΩÂåñÂíåËá®Â∫äË©¶È©óÁ†îÁ©∂Á≠âÈ†òÂüü„ÄÇÁÑ∂ËÄåÔºåÂØ¶ÊñΩ FL ÊúÉÂ∏∂‰æÜÊåëÊà∞ÔºåÂåÖÊã¨Èùû IIDÔºàÁç®Á´ã‰∏îÂêåÂàÜÂ∏ÉÔºâË≥áÊñôÁí∞Â¢É‰∏≠ÁöÑÊ®°ÂûãÊî∂ÊñÇ„ÄÅÈÄöË®äË≤†ËºâÂíåÁÆ°ÁêÜÂ§öÊ©üÊßãÂêà‰Ωú„ÄÇÊúâÂøÖË¶ÅÂ∞çÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÁöÑ FL ÈÄ≤Ë°åÁ≥ªÁµ±ÊÄßÂõûÈ°ßÔºå‰ª•Ë©ï‰º∞ FL Âú®Á∂≠Ë≠∑ÈÜ´ÁôÇË≥áÊñôÂàÜÊûêÁöÑÂÆåÊï¥ÊÄßÂíåÂèØÁî®ÊÄßÁöÑÂêåÊôÇÔºåÂ¶Ç‰ΩïÊúâÊïàÂú∞Êèê‰æõÈö±ÁßÅ„ÄÇÂú®ÈÄôÈ†ÖÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄëÂàÜÊûê‰∫ÜÁèæÊúâÁöÑÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ FL ÊáâÁî®ÁöÑÊñáÁçª„ÄÇÊàëÂÄëÊé¢Ë®é‰∫ÜÊ®°ÂûãÂÆâÂÖ®ÂØ¶ÂãôÁöÑÁèæÊ≥Å„ÄÅÊâæÂá∫ÊôÆÈÅçÁöÑÊåëÊà∞Ôºå‰∏¶Ë®éË´ñÂØ¶ÈöõÊáâÁî®ÂèäÂÖ∂ÂΩ±Èüø„ÄÇÊ≠§Â§ñÔºåÊ≠§ÂõûÈ°ßÂº∑Ë™ø‰∫ÜÊúâÂâçÈÄîÁöÑÊú™‰æÜÁ†îÁ©∂ÊñπÂêëÔºå‰ª•ÊîπÂñÑ FL ÁöÑÂØ¶‰Ωú„ÄÅÂä†Âº∑Ë≥áÊñôÂÆâÂÖ®ÂçîÂÆöÔºå‰∏¶Â∞á FL ÁöÑÁî®ÈÄîÊì¥Â±ïÂà∞Êõ¥Âª£Ê≥õÁöÑÈÜ´ÁôÇ‰øùÂÅ•ÊáâÁî®ÔºåÈÄôÂ∞á‰ΩøÊú™‰æÜÁöÑÁ†îÁ©∂‰∫∫Âì°ÂíåÂæûÊ•≠‰∫∫Âì°ÂèóÁõä„ÄÇ

##### **Efficient Two-Stage Gaussian Process Regression Via Automatic Kernel Search and Subsampling**
2405.13785v1 by Shifan Zhao, Jiaying Lu, Ji Yang, Edmond Chow, Yuanzhe Xi

Gaussian Process Regression (GPR) is widely used in statistics and machine
learning for prediction tasks requiring uncertainty measures. Its efficacy
depends on the appropriate specification of the mean function, covariance
kernel function, and associated hyperparameters. Severe misspecifications can
lead to inaccurate results and problematic consequences, especially in
safety-critical applications. However, a systematic approach to handle these
misspecifications is lacking in the literature. In this work, we propose a
general framework to address these issues. Firstly, we introduce a flexible
two-stage GPR framework that separates mean prediction and uncertainty
quantification (UQ) to prevent mean misspecification, which can introduce bias
into the model. Secondly, kernel function misspecification is addressed through
a novel automatic kernel search algorithm, supported by theoretical analysis,
that selects the optimal kernel from a candidate set. Additionally, we propose
a subsampling-based warm-start strategy for hyperparameter initialization to
improve efficiency and avoid hyperparameter misspecification. With much lower
computational cost, our subsampling-based strategy can yield competitive or
better performance than training exclusively on the full dataset. Combining all
these components, we recommend two GPR methods-exact and scalable-designed to
match available computational resources and specific UQ requirements. Extensive
evaluation on real-world datasets, including UCI benchmarks and a
safety-critical medical case study, demonstrates the robustness and precision
of our methods.

ÊëòË¶ÅÔºöÈ´òÊñØÈÅéÁ®ãÂõûÊ≠∏ (GPR) Âª£Ê≥õÁî®ÊñºÁµ±Ë®àÂíåÊ©üÂô®Â≠∏Áøí‰∏≠ÁöÑÈ†êÊ∏¨‰ªªÂãôÔºåÈúÄË¶Å‰∏çÁ¢∫ÂÆöÊÄßÂ∫¶Èáè„ÄÇÂÖ∂ÊïàËÉΩÂèñÊ±∫ÊñºÂπ≥ÂùáÂáΩÊï∏„ÄÅÂçîÊñπÂ∑ÆÊ†∏ÂáΩÊï∏ÂíåÁõ∏ÈóúË∂ÖÂèÉÊï∏ÁöÑÈÅ©Áï∂Ë¶èÊ†º„ÄÇÂö¥ÈáçÁöÑÈåØË™§Ë¶èÊ†ºÂèØËÉΩÊúÉÂ∞éËá¥‰∏çÊ∫ñÁ¢∫ÁöÑÁµêÊûúÂíåÊúâÂïèÈ°åÁöÑÂæåÊûúÔºåÁâπÂà•ÊòØÂú®ÂÆâÂÖ®ÈóúÈçµÊáâÁî®‰∏≠„ÄÇÁÑ∂ËÄåÔºåÊñáÁçª‰∏≠Áº∫‰πèÁ≥ªÁµ±ÁöÑÊñπÊ≥ï‰æÜËôïÁêÜÈÄô‰∫õÈåØË™§Ë¶èÊ†º„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÈÄöÁî®Ê°ÜÊû∂‰æÜËß£Ê±∫ÈÄô‰∫õÂïèÈ°å„ÄÇÈ¶ñÂÖàÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÈùàÊ¥ªÁöÑÂÖ©ÈöéÊÆµ GPR Ê°ÜÊû∂ÔºåÂÆÉÂ∞áÂπ≥ÂùáÈ†êÊ∏¨Âíå‰∏çÁ¢∫ÂÆöÊÄßÈáèÂåñ (UQ) ÂàÜÈñãÔºå‰ª•Èò≤Ê≠¢Âπ≥ÂùáÈåØË™§Ë¶èÊ†ºÔºåÈÄôÂèØËÉΩÊúÉÂ∞áÂÅèÂ∑ÆÂºïÂÖ•Ê®°Âûã„ÄÇÂÖ∂Ê¨°ÔºåÈÄöÈÅé‰∏ÄÁ®ÆÊñ∞Á©éÁöÑËá™ÂãïÊ†∏ÊêúÁ¥¢ÁÆóÊ≥ï‰æÜËß£Ê±∫Ê†∏ÂáΩÊï∏ÈåØË™§Ë¶èÊ†ºÔºåË©≤ÁÆóÊ≥ïÁî±ÁêÜË´ñÂàÜÊûêÊîØÊåÅÔºåÂæûÂÄôÈÅ∏ÈõÜ‰∏≠ÈÅ∏ÊìáÊúÄ‰Ω≥Ê†∏„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂü∫ÊñºÂ≠êÊäΩÊ®£ÁöÑÁÜ±ÂïüÂãïÁ≠ñÁï•ÔºåÁî®ÊñºË∂ÖÂèÉÊï∏ÂàùÂßãÂåñÔºå‰ª•ÊèêÈ´òÊïàÁéá‰∏¶ÈÅøÂÖçË∂ÖÂèÉÊï∏ÈåØË™§Ë¶èÊ†º„ÄÇÊàëÂÄëÁöÑÂü∫ÊñºÂ≠êÊäΩÊ®£ÁöÑÁ≠ñÁï•‰ª•‰ΩéÂæóÂ§öÁöÑË®àÁÆóÊàêÊú¨ÔºåÂèØ‰ª•Áî¢ÁîüÊØîÂ∞àÈñÄÂú®ÂÆåÊï¥Êï∏ÊìöÈõÜ‰∏äË®ìÁ∑¥Êõ¥ÂÖ∑Á´∂Áà≠ÂäõÊàñÊõ¥Â•ΩÁöÑÊÄßËÉΩ„ÄÇÁµêÂêàÊâÄÊúâÈÄô‰∫õÁµÑÊàêÈÉ®ÂàÜÔºåÊàëÂÄëÊé®Ëñ¶ÂÖ©Á®Æ GPR ÊñπÊ≥ï‚Äî‚ÄîÁ≤æÁ¢∫ÂíåÂèØÊì¥Â±ï‚Äî‚ÄîÊó®Âú®ÂåπÈÖçÂèØÁî®ÁöÑË®àÁÆóË≥áÊ∫êÂíåÂÖ∑È´îÁöÑ UQ ÈúÄÊ±Ç„ÄÇÂú®ÂåÖÊã¨ UCI Âü∫Ê∫ñÂíåÂÆâÂÖ®ÈóúÈçµÈÜ´ÁôÇÊ°à‰æãÁ†îÁ©∂Âú®ÂÖßÁöÑÁúüÂØ¶‰∏ñÁïåÊï∏ÊìöÈõÜ‰∏äÁöÑÂª£Ê≥õË©ï‰º∞Ë≠âÊòé‰∫ÜÊàëÂÄëÊñπÊ≥ïÁöÑÁ©©ÂÅ•ÊÄßÂíåÁ≤æÁ¢∫ÊÄß„ÄÇ

##### **How Reliable AI Chatbots are for Disease Prediction from Patient Complaints?**
2405.13219v1 by Ayesha Siddika Nipu, K M Sajjadul Islam, Praveen Madiraju

Artificial Intelligence (AI) chatbots leveraging Large Language Models (LLMs)
are gaining traction in healthcare for their potential to automate patient
interactions and aid clinical decision-making. This study examines the
reliability of AI chatbots, specifically GPT 4.0, Claude 3 Opus, and Gemini
Ultra 1.0, in predicting diseases from patient complaints in the emergency
department. The methodology includes few-shot learning techniques to evaluate
the chatbots' effectiveness in disease prediction. We also fine-tune the
transformer-based model BERT and compare its performance with the AI chatbots.
Results suggest that GPT 4.0 achieves high accuracy with increased few-shot
data, while Gemini Ultra 1.0 performs well with fewer examples, and Claude 3
Opus maintains consistent performance. BERT's performance, however, is lower
than all the chatbots, indicating limitations due to limited labeled data.
Despite the chatbots' varying accuracy, none of them are sufficiently reliable
for critical medical decision-making, underscoring the need for rigorous
validation and human oversight. This study reflects that while AI chatbots have
potential in healthcare, they should complement, not replace, human expertise
to ensure patient safety. Further refinement and research are needed to improve
AI-based healthcare applications' reliability for disease prediction.

ÊëòË¶ÅÔºö‰∫∫Â∑•Êô∫ÊÖßÔºàAIÔºâËÅäÂ§©Ê©üÂô®‰∫∫Âà©Áî®Â§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâÔºåÂú®ÈÜ´ÁôÇ‰øùÂÅ•È†òÂüü‰∏≠Áç≤ÂæóÈóúÊ≥®ÔºåÂõ†ÁÇ∫ÂÆÉÂÄëÂÖ∑ÊúâËá™ÂãïÂåñÊÇ£ËÄÖ‰∫íÂãïÂíåÂçîÂä©Ëá®Â∫äÊ±∫Á≠ñÁöÑÊΩõÂäõ„ÄÇÊú¨Á†îÁ©∂Êé¢Ë®é‰∫Ü AI ËÅäÂ§©Ê©üÂô®‰∫∫ÁöÑÂèØÈù†ÊÄßÔºåÁâπÂà•ÊòØ GPT 4.0„ÄÅClaude 3 Opus Âíå Gemini Ultra 1.0ÔºåÂú®È†êÊ∏¨ÊÄ•Ë®∫ÈÉ®ÈñÄÊÇ£ËÄÖÁóáÁãÄÁöÑÁñæÁóÖÊñπÈù¢„ÄÇÊñπÊ≥ïÂåÖÊã¨Â∞ëÈáèÂ≠∏ÁøíÊäÄË°ìÔºå‰ª•Ë©ï‰º∞ËÅäÂ§©Ê©üÂô®‰∫∫Âú®ÁñæÁóÖÈ†êÊ∏¨‰∏≠ÁöÑÊúâÊïàÊÄß„ÄÇÊàëÂÄëÈÇÑÂæÆË™ø‰∫ÜÂü∫ÊñºËΩâÊèõÂô®ÁöÑÊ®°Âûã BERTÔºå‰∏¶Â∞áÂÖ∂ÊïàËÉΩËàá AI ËÅäÂ§©Ê©üÂô®‰∫∫ÈÄ≤Ë°åÊØîËºÉ„ÄÇÁµêÊûúË°®ÊòéÔºåGPT 4.0 Âú®Â∞ëÈáèÊï∏ÊìöÂ¢ûÂä†ÁöÑÊÉÖÊ≥Å‰∏ãÂØ¶Áèæ‰∫ÜÈ´òÊ∫ñÁ¢∫Â∫¶ÔºåËÄå Gemini Ultra 1.0 Âú®ËºÉÂ∞ëÁöÑÁØÑ‰æã‰∏≠Ë°®ÁèæËâØÂ•ΩÔºåClaude 3 Opus ÂâáÁ∂≠ÊåÅ‰∫Ü‰∏ÄËá¥ÁöÑÊïàËÉΩ„ÄÇÁÑ∂ËÄåÔºåBERT ÁöÑÊïàËÉΩ‰ΩéÊñºÊâÄÊúâËÅäÂ§©Ê©üÂô®‰∫∫ÔºåÈÄôË°®ÊòéÁî±ÊñºÊ®ôË®òÊï∏ÊìöÊúâÈôêËÄåÂ≠òÂú®ÈôêÂà∂„ÄÇÂÑòÁÆ°ËÅäÂ§©Ê©üÂô®‰∫∫ÁöÑÊ∫ñÁ¢∫Â∫¶‰∏çÂêåÔºå‰ΩÜÂÆÉÂÄëÈÉΩ‰∏çË∂≥‰ª•Áî®ÊñºÈáçË¶ÅÁöÑÈÜ´ÁôÇÊ±∫Á≠ñÔºåÈÄôÂº∑Ë™ø‰∫ÜÂö¥Ê†ºÈ©óË≠âÂíå‰∫∫È°ûÁõ£Áù£ÁöÑÂøÖË¶ÅÊÄß„ÄÇÊú¨Á†îÁ©∂Ë°®ÊòéÔºåÂÑòÁÆ° AI ËÅäÂ§©Ê©üÂô®‰∫∫Âú®ÈÜ´ÁôÇ‰øùÂÅ•ÊñπÈù¢ÂÖ∑ÊúâÊΩõÂäõÔºå‰ΩÜÂÆÉÂÄëÊáâË£úÂÖÖËÄå‰∏çÊòØÂèñ‰ª£‰∫∫È°ûÂ∞àÊ•≠Áü•Ë≠òÔºå‰ª•Á¢∫‰øùÊÇ£ËÄÖÂÆâÂÖ®„ÄÇÈúÄË¶ÅÈÄ≤‰∏ÄÊ≠•ÁöÑÊîπÈÄ≤ÂíåÁ†îÁ©∂Ôºå‰ª•ÊèêÈ´òÂü∫Êñº AI ÁöÑÈÜ´ÁôÇ‰øùÂÅ•ÊáâÁî®Âú®ÁñæÁóÖÈ†êÊ∏¨ÊñπÈù¢ÁöÑÂèØÈù†ÊÄß„ÄÇ

##### **Interpretable Spatio-Temporal Embedding for Brain Structural-Effective Network with Ordinary Differential Equation**
2405.13190v1 by Haoteng Tang, Guodong Liu, Siyuan Dai, Kai Ye, Kun Zhao, Wenlu Wang, Carl Yang, Lifang He, Alex Leow, Paul Thompson, Heng Huang, Liang Zhan

The MRI-derived brain network serves as a pivotal instrument in elucidating
both the structural and functional aspects of the brain, encompassing the
ramifications of diseases and developmental processes. However, prevailing
methodologies, often focusing on synchronous BOLD signals from functional MRI
(fMRI), may not capture directional influences among brain regions and rarely
tackle temporal functional dynamics. In this study, we first construct the
brain-effective network via the dynamic causal model. Subsequently, we
introduce an interpretable graph learning framework termed Spatio-Temporal
Embedding ODE (STE-ODE). This framework incorporates specifically designed
directed node embedding layers, aiming at capturing the dynamic interplay
between structural and effective networks via an ordinary differential equation
(ODE) model, which characterizes spatial-temporal brain dynamics. Our framework
is validated on several clinical phenotype prediction tasks using two
independent publicly available datasets (HCP and OASIS). The experimental
results clearly demonstrate the advantages of our model compared to several
state-of-the-art methods.

ÊëòË¶ÅÔºö‰ª• MRI Ë°çÁîüÁöÑËÖ¶Á∂≤Ë∑Ø‰ΩúÁÇ∫Ê®ûÁ¥êÂ∑•ÂÖ∑ÔºåÈó°ÊòéÂ§ßËÖ¶ÁöÑÁµêÊßãÂíåÂäüËÉΩÈù¢ÂêëÔºåÂåÖÂê´ÁñæÁóÖÂíåÁôºÂ±ïÈÅéÁ®ãÁöÑÂΩ±Èüø„ÄÇÁÑ∂ËÄåÔºåÁèæË°åÁöÑÁ†îÁ©∂ÊñπÊ≥ïÈÄöÂ∏∏Â∞àÊ≥®ÊñºÂäüËÉΩÊÄß MRI (fMRI) ÁöÑÂêåÊ≠• BOLD Ë®äËôüÔºåÂèØËÉΩÁÑ°Ê≥ïÊçïÊçâËÖ¶ÂçÄ‰πãÈñìÁöÑÊñπÂêëÊÄßÂΩ±ÈüøÔºå‰πüÂæàÂ∞ëËôïÁêÜÊôÇÈñìÂäüËÉΩÂãïÊÖã„ÄÇÂú®Êú¨Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëÈ¶ñÂÖàÈÄèÈÅéÂãïÊÖãÂõ†ÊûúÊ®°ÂûãÂª∫ÊßãËÖ¶ÈÉ®ÊúâÊïàÁ∂≤Ë∑Ø„ÄÇÊé•ËëóÔºåÊàëÂÄëÂºïÂÖ•Á®±ÁÇ∫ÊôÇÁ©∫ÂµåÂÖ• ODE (STE-ODE) ÁöÑÂèØËß£ÈáãÂúñÂΩ¢Â≠∏ÁøíÊû∂Êßã„ÄÇÊ≠§Êû∂ÊßãÁµêÂêàÂ∞àÈñÄË®≠Ë®àÁöÑÊúâÂêëÁØÄÈªûÂµåÂÖ•Â±§ÔºåÊó®Âú®ÈÄèÈÅéÂ∏∏ÂæÆÂàÜÊñπÁ®ã (ODE) Ê®°ÂûãÊçïÊçâÁµêÊßãÂíåÊúâÊïàÁ∂≤Ë∑Ø‰πãÈñìÁöÑÂãïÊÖã‰∫§‰∫í‰ΩúÁî®ÔºåÊèèËø∞ÊôÇÁ©∫ËÖ¶ÈÉ®ÂãïÊÖã„ÄÇÊàëÂÄëÁöÑÊû∂ÊßãÂú®ÂÖ©ÂÄãÁç®Á´ãÂÖ¨ÈñãË≥áÊñôÈõÜ (HCP Âíå OASIS) ‰∏äÁ∂ìÈÅéÂ§öÈ†ÖËá®Â∫äË°®ÂûãÈ†êÊ∏¨‰ªªÂãôÈ©óË≠â„ÄÇÂØ¶È©óÁµêÊûúÊ∏ÖÊ•öÈ°ØÁ§∫ÔºåËàáÂ§öÁ®ÆÊúÄÂÖàÈÄ≤ÊñπÊ≥ïÁõ∏ÊØîÔºåÊàëÂÄëÁöÑÊ®°ÂûãÂÖ∑ÊúâÂÑ™Âã¢„ÄÇ

##### **The Role of Emotions in Informational Support Question-Response Pairs in Online Health Communities: A Multimodal Deep Learning Approach**
2405.13099v1 by Mohsen Jozani, Jason A. Williams, Ahmed Aleroud, Sarbottam Bhagat

This study explores the relationship between informational support seeking
questions, responses, and helpfulness ratings in online health communities. We
created a labeled data set of question-response pairs and developed multimodal
machine learning and deep learning models to reliably predict informational
support questions and responses. We employed explainable AI to reveal the
emotions embedded in informational support exchanges, demonstrating the
importance of emotion in providing informational support. This complex
interplay between emotional and informational support has not been previously
researched. The study refines social support theory and lays the groundwork for
the development of user decision aids. Further implications are discussed.

ÊëòË¶ÅÔºöÊú¨Á†îÁ©∂Êé¢Ë®éÁ∑ö‰∏äÂÅ•Â∫∑Á§æÁæ§‰∏≠Â∞ãÊ±ÇË≥áË®äÊîØÊåÅÁöÑÂïèÈ°å„ÄÅÂõûÊáâÔºå‰ª•ÂèäÊúâÂπ´Âä©ÁöÑË©ïÂàÜ‰πãÈñìÁöÑÈóú‰øÇ„ÄÇÊàëÂÄëÂª∫Á´ã‰∫Ü‰∏ÄÁµÑÊ®ôË®òÁöÑÂïèÁ≠îÈÖçÂ∞çË≥áÊñôÈõÜÔºå‰∏¶ÈñãÁôº‰∫ÜÂ§öÊ®°ÊÖãÊ©üÂô®Â≠∏ÁøíÂíåÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÔºå‰ª•ÂèØÈù†Âú∞È†êÊ∏¨Ë≥áË®äÊîØÊåÅÂïèÈ°åÂíåÂõûÊáâ„ÄÇÊàëÂÄëÊé°Áî®ÂèØËß£ÈáãÁöÑ AI ‰æÜÊè≠Á§∫Ë≥áË®äÊîØÊåÅ‰∫§ÊµÅ‰∏≠ËòäÂê´ÁöÑÊÉÖÁ∑íÔºåË≠âÊòéÊÉÖÁ∑íÂú®Êèê‰æõË≥áË®äÊîØÊåÅ‰∏≠ÁöÑÈáçË¶ÅÊÄß„ÄÇÈÄôÁ®ÆÊÉÖÁ∑íÊîØÊåÅÂíåË≥áË®äÊîØÊåÅ‰πãÈñìÁöÑË§áÈõú‰∫§‰∫í‰ΩúÁî®‰ª•Ââç‰∏¶Êú™Ë¢´Á†îÁ©∂ÈÅé„ÄÇÊú¨Á†îÁ©∂ÊîπÈÄ≤‰∫ÜÁ§æÊúÉÊîØÊåÅÁêÜË´ñÔºå‰∏¶ÁÇ∫‰ΩøÁî®ËÄÖÊ±∫Á≠ñËºîÂä©Â∑•ÂÖ∑ÁöÑÈñãÁôºÂ•†ÂÆö‰∫ÜÂü∫Á§é„ÄÇË®éË´ñ‰∫ÜÈÄ≤‰∏ÄÊ≠•ÁöÑÂΩ±Èüø„ÄÇ

##### **KPG: Key Propagation Graph Generator for Rumor Detection based on Reinforcement Learning**
2405.13094v1 by Yusong Zhang, Kun Xie, Xingyi Zhang, Xiangyu Dong, Sibo Wang

The proliferation of rumors on social media platforms during significant
events, such as the US elections and the COVID-19 pandemic, has a profound
impact on social stability and public health. Existing approaches for rumor
detection primarily rely on propagation graphs to enhance model effectiveness.
However, the presence of noisy and irrelevant structures during the propagation
process limits the efficacy of these approaches. To tackle this issue,
techniques such as weight adjustment and data augmentation have been proposed.
However, these techniques heavily depend on rich original propagation
structures, thus hindering performance when dealing with rumors that lack
sufficient propagation information in the early propagation stages. In this
paper, we propose Key Propagation Graph Generator (KPG), a novel reinforcement
learning-based rumor detection framework that generates contextually coherent
and informative propagation patterns for events with insufficient topology
information, while also identifies indicative substructures for events with
redundant and noisy propagation structures. KPG consists of two key components:
the Candidate Response Generator (CRG) and the Ending Node Selector (ENS). CRG
learns the latent distribution from refined propagation patterns, filtering out
noise and generating new candidates for ENS. Simultaneously, ENS identifies the
most influential substructures within propagation graphs and generates training
data for CRG. Moreover, we introduce an end-to-end framework that utilizes
rewards to guide the entire training process via a pre-trained graph neural
network. Extensive experiments conducted on four datasets demonstrate the
superiority of our KPG compared to the state-of-the-art approaches.

ÊëòË¶ÅÔºö<paragraph>Âú®ÈáçÂ§ß‰∫ã‰ª∂Ôºà‰æãÂ¶ÇÁæéÂúãÈÅ∏ËàâÂíå COVID-19 Â§ßÊµÅË°åÔºâÊúüÈñìÔºåÁ§æ‰∫§Â™íÈ´îÂπ≥Âè∞‰∏äË¨†Ë®ÄÁöÑÊï£Â∏ÉÂ∞çÁ§æÊúÉÁ©©ÂÆöÂíåÂÖ¨ÂÖ±Ë°õÁîüÁî¢Áîü‰∫ÜÊ∑±ÈÅ†ÁöÑÂΩ±Èüø„ÄÇÁèæÊúâÁöÑË¨†Ë®ÄÊ™¢Ê∏¨ÊñπÊ≥ï‰∏ªË¶Å‰æùË≥¥ÂÇ≥Êí≠Âúñ‰æÜÊèêÈ´òÊ®°ÂûãÁöÑÊúâÊïàÊÄß„ÄÇÁÑ∂ËÄåÔºåÂú®ÂÇ≥Êí≠ÈÅéÁ®ã‰∏≠Â≠òÂú®ÈõúË®äÂíåÁÑ°ÈóúÁµêÊßãÊúÉÈôêÂà∂ÈÄô‰∫õÊñπÊ≥ïÁöÑÊïàÂäõ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÂ∑≤Á∂ìÊèêÂá∫‰∫ÜÊ¨äÈáçË™øÊï¥ÂíåÊï∏ÊìöÊì¥ÂÖÖÁ≠âÊäÄË°ì„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÊäÄË°ìÂö¥Èáç‰æùË≥¥ÊñºË±êÂØåÁöÑÂéüÂßãÂÇ≥Êí≠ÁµêÊßãÔºåÂõ†Ê≠§Âú®ËôïÁêÜÂú®Êó©ÊúüÂÇ≥Êí≠ÈöéÊÆµÁº∫‰πèË∂≥Â§†ÂÇ≥Êí≠‰ø°ÊÅØÁöÑË¨†Ë®ÄÊôÇÊúÉÈòªÁ§ôÊÄßËÉΩ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫ÜÈóúÈçµÂÇ≥Êí≠ÂúñÁîüÊàêÂô® (KPG)ÔºåÈÄôÊòØ‰∏ÄÂÄãÂü∫ÊñºÂº∑ÂåñÂ≠∏ÁøíÁöÑÊñ∞ÂûãË¨†Ë®ÄÊ™¢Ê∏¨Ê°ÜÊû∂ÔºåÂÆÉÁÇ∫ÊãìÊí≤‰ø°ÊÅØ‰∏çË∂≥ÁöÑ‰∫ã‰ª∂ÁîüÊàê‰∏ä‰∏ãÊñáÁõ∏Âπ≤‰∏î‰ø°ÊÅØË±êÂØåÁöÑÂÇ≥Êí≠Ê®°ÂºèÔºåÂêåÊôÇÈÇÑË≠òÂà•Âá∫ÂÖ∑ÊúâÂÜóÈ§òÂíåÈõúË®äÂÇ≥Êí≠ÁµêÊßãÁöÑ‰∫ã‰ª∂ÁöÑÊåáÁ§∫ÊÄßÂ≠êÁµêÊßã„ÄÇKPG ÂåÖÂê´ÂÖ©ÂÄãÈóúÈçµÁµÑÊàêÈÉ®ÂàÜÔºöÂÄôÈÅ∏ÈüøÊáâÁîüÊàêÂô® (CRG) ÂíåÁµêÊùüÁØÄÈªûÈÅ∏ÊìáÂô® (ENS)„ÄÇCRG ÂæûÁ≤æÁÖâÁöÑÂÇ≥Êí≠Ê®°Âºè‰∏≠Â≠∏ÁøíÊΩõÂú®ÂàÜ‰ΩàÔºåÈÅéÊøæÈõúË®ä‰∏¶ÁÇ∫ ENS ÁîüÊàêÊñ∞ÁöÑÂÄôÈÅ∏È†Ö„ÄÇÂêåÊôÇÔºåENS Ë≠òÂà•ÂÇ≥Êí≠Âúñ‰∏≠ÂΩ±ÈüøÊúÄÂ§ßÁöÑÂ≠êÁµêÊßãÔºå‰∏¶ÁÇ∫ CRG ÁîüÊàêË®ìÁ∑¥Êï∏Êìö„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÁ´ØÂà∞Á´ØÊ°ÜÊû∂ÔºåÂÆÉÂà©Áî®ÁçéÂãµÈÄöÈÅéÈ†êË®ìÁ∑¥ÁöÑÂúñÁ•ûÁ∂ìÁ∂≤Ë∑ØÊåáÂ∞éÊï¥ÂÄãË®ìÁ∑¥ÈÅéÁ®ã„ÄÇÂú®ÂõõÂÄãÊï∏ÊìöÈõÜ‰∏äÈÄ≤Ë°åÁöÑÂª£Ê≥õÂØ¶È©óË≠âÊòé‰∫ÜÊàëÂÄë KPG ËàáÊúÄÂÖàÈÄ≤ÊñπÊ≥ïÁõ∏ÊØîÁöÑÂÑ™Ë∂äÊÄß„ÄÇ</paragraph>

##### **A Masked Semi-Supervised Learning Approach for Otago Micro Labels Recognition**
2405.12711v2 by Meng Shang, Lenore Dedeyne, Jolan Dupont, Laura Vercauteren, Nadjia Amini, Laurence Lapauw, Evelien Gielen, Sabine Verschueren, Carolina Varon, Walter De Raedt, Bart Vanrumste

The Otago Exercise Program (OEP) serves as a vital rehabilitation initiative
for older adults, aiming to enhance their strength and balance, and
consequently prevent falls. While Human Activity Recognition (HAR) systems have
been widely employed in recognizing the activities of individuals, existing
systems focus on the duration of macro activities (i.e. a sequence of
repetitions of the same exercise), neglecting the ability to discern micro
activities (i.e. the individual repetitions of the exercises), in the case of
OEP. This study presents a novel semi-supervised machine learning approach
aimed at bridging this gap in recognizing the micro activities of OEP. To
manage the limited dataset size, our model utilizes a Transformer encoder for
feature extraction, subsequently classified by a Temporal Convolutional Network
(TCN). Simultaneously, the Transformer encoder is employed for masked
unsupervised learning to reconstruct input signals. Results indicate that the
masked unsupervised learning task enhances the performance of the supervised
learning (classification task), as evidenced by f1-scores surpassing the
clinically applicable threshold of 0.8. From the micro activities, two
clinically relevant outcomes emerge: counting the number of repetitions of each
exercise and calculating the velocity during chair rising. These outcomes
enable the automatic monitoring of exercise intensity and difficulty in the
daily lives of older adults.

ÊëòË¶ÅÔºöÂ•ßÂ°îÂì•ÈÅãÂãïË®àÁï´ (OEP) ‰ΩúÁÇ∫‰∏ÄÈ†ÖÈáçË¶ÅÁöÑÂæ©ÂÅ•Êé™ÊñΩÔºåÊúçÂãôÂ∞çË±°ÁÇ∫ËÄÅÂπ¥‰∫∫ÔºåÊó®Âú®Â¢ûÂº∑‰ªñÂÄëÁöÑËÇåÂäõÂíåÂπ≥Ë°°ÊÑüÔºåÈÄ≤ËÄåÈ†êÈò≤Ë∑åÂÄí„ÄÇÂÑòÁÆ°‰∫∫È°ûÊ¥ªÂãïËæ®Ë≠ò (HAR) Á≥ªÁµ±Â∑≤Ë¢´Âª£Ê≥õÁî®ÊñºËæ®Ë≠òÂÄã‰∫∫ÁöÑÊ¥ªÂãïÔºå‰ΩÜÁèæÊúâÁ≥ªÁµ±ËëóÈáçÊñºÂ∑®ËßÄÊ¥ªÂãïÁöÑÊåÅÁ∫åÊôÇÈñìÔºàÂç≥ÈáçË§áÂü∑Ë°åÁõ∏ÂêåÈÅãÂãïÁöÑÈ†ÜÂ∫èÔºâÔºåÂøΩÁï•‰∫ÜËæ®Âà•ÂæÆËßÄÊ¥ªÂãïÔºàÂç≥ÈÅãÂãïÁöÑÂÄãÂà•ÈáçË§áÊ¨°Êï∏ÔºâÁöÑËÉΩÂäõÔºåÂ∞± OEP ËÄåË®Ä„ÄÇÊú¨Á†îÁ©∂ÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÂçäÁõ£Áù£Ê©üÂô®Â≠∏ÁøíÊñπÊ≥ïÔºåÊó®Âú®ÂΩåË£úËæ®Ë≠ò OEP ÂæÆËßÄÊ¥ªÂãïÁöÑÈÄô‰∏ÄÂ∑ÆË∑ù„ÄÇÁÇ∫‰∫ÜÁÆ°ÁêÜÊúâÈôêÁöÑË≥áÊñôÈõÜÂ§ßÂ∞èÔºåÊàëÂÄëÁöÑÊ®°ÂûãÂà©Áî® Transformer Á∑®Á¢ºÂô®ÈÄ≤Ë°åÁâπÂæµËêÉÂèñÔºåÈö®ÂæåÁî±ÊôÇÂ∫èÂç∑Á©çÁ∂≤Ë∑Ø (TCN) ÈÄ≤Ë°åÂàÜÈ°û„ÄÇÂêåÊôÇÔºåTransformer Á∑®Á¢ºÂô®Áî®ÊñºÈÅÆËîΩÂºèÈùûÁõ£Áù£Â≠∏ÁøíÔºå‰ª•ÈáçÂª∫Ëº∏ÂÖ•Ë®äËôü„ÄÇÁµêÊûúË°®ÊòéÔºåÈÅÆËîΩÂºèÈùûÁõ£Áù£Â≠∏Áøí‰ªªÂãôÂ¢ûÂº∑‰∫ÜÁõ£Áù£Â≠∏ÁøíÔºàÂàÜÈ°û‰ªªÂãôÔºâÁöÑÊïàËÉΩÔºåÈÄôÁî± f1 ÂàÜÊï∏Ë∂ÖÈÅé 0.8 ÁöÑËá®Â∫äÈÅ©Áî®ÈñæÂÄºÊâÄË≠âÂØ¶„ÄÇÂæûÂæÆËßÄÊ¥ªÂãï‰∏≠ÔºåÂá∫Áèæ‰∫ÜÂÖ©ÂÄãËá®Â∫äÁõ∏ÈóúÁöÑÁµêÊûúÔºöË®àÁÆóÊØèÊ¨°ÈÅãÂãïÁöÑÈáçË§áÊ¨°Êï∏ÂíåË®àÁÆóÊ§ÖÂ≠ê‰∏äÂçáÊôÇÁöÑÈÄüÁéá„ÄÇÈÄô‰∫õÁµêÊûúËÉΩÂ§†Ëá™ÂãïÁõ£ÊéßËÄÅÂπ¥‰∫∫Âú®Êó•Â∏∏ÁîüÊ¥ª‰∏≠ÁöÑÈÅãÂãïÂº∑Â∫¶ÂíåÈõ£Â∫¶„ÄÇ

##### **OLAPH: Improving Factuality in Biomedical Long-form Question Answering**
2405.12701v1 by Minbyul Jeong, Hyeon Hwang, Chanwoong Yoon, Taewhoo Lee, Jaewoo Kang

In the medical domain, numerous scenarios necessitate the long-form
generation ability of large language models (LLMs). Specifically, when
addressing patients' questions, it is essential that the model's response
conveys factual claims, highlighting the need for an automated method to
evaluate those claims. Thus, we introduce MedLFQA, a benchmark dataset
reconstructed using long-form question-answering datasets related to the
biomedical domain. We use MedLFQA to facilitate the automatic evaluations of
factuality. We also propose OLAPH, a simple and novel framework that enables
the improvement of factuality through automatic evaluations. The OLAPH
framework iteratively trains LLMs to mitigate hallucinations using sampling
predictions and preference optimization. In other words, we iteratively set the
highest-scoring response as a preferred response derived from sampling
predictions and train LLMs to align with the preferred response that improves
factuality. We highlight that, even on evaluation metrics not used during
training, LLMs trained with our OLAPH framework demonstrate significant
performance improvement in factuality. Our findings reveal that a 7B LLM
trained with our OLAPH framework can provide long answers comparable to the
medical experts' answers in terms of factuality. We believe that our work could
shed light on gauging the long-text generation ability of LLMs in the medical
domain. Our code and datasets are available at
https://github.com/dmis-lab/OLAPH}{https://github.com/dmis-lab/OLAPH.

ÊëòË¶ÅÔºö<paragraph>Âú®ÈÜ´ÁôÇÈ†òÂüüÔºåË®±Â§öÊÉÖÂ¢ÉÈÉΩÈúÄË¶ÅÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Áî¢ÁîüÈï∑ÁØáÊñáÂ≠óÁöÑËÉΩÂäõ„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÂú®ÂõûÁ≠îÊÇ£ËÄÖÂïèÈ°åÊôÇÔºåÊ®°ÂûãÁöÑÂõûÊáâÂÇ≥ÈÅî‰∫ãÂØ¶ËÅ≤ÊòéËá≥ÈóúÈáçË¶ÅÔºåÈÄôÁ™ÅÈ°Ø‰∫ÜËá™ÂãïÂåñÊñπÊ≥ï‰æÜË©ï‰º∞ÈÄô‰∫õËÅ≤ÊòéÁöÑÂøÖË¶ÅÊÄß„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü MedLFQAÔºåÈÄôÊòØ‰∏ÄÂÄã‰ΩøÁî®ËàáÁîüÁâ©ÈÜ´Â≠∏È†òÂüüÁõ∏ÈóúÁöÑÈï∑ÁØáÂïèÁ≠îË≥áÊñôÈõÜÈáçÂª∫ÁöÑÂü∫Ê∫ñË≥áÊñôÈõÜ„ÄÇÊàëÂÄë‰ΩøÁî® MedLFQA ‰æÜ‰øÉÈÄ≤‰∫ãÂØ¶ÊÄßÁöÑËá™ÂãïË©ï‰º∞„ÄÇÊàëÂÄëÈÇÑÊèêÂá∫‰∫Ü‰∏ÄÂÄãÁ∞°ÂñÆ‰∏îÊñ∞Á©éÁöÑÊ°ÜÊû∂ OLAPHÔºåÂÆÉËÉΩÂ§†ÈÄèÈÅéËá™ÂãïË©ï‰º∞‰æÜÊîπÂñÑ‰∫ãÂØ¶ÊÄß„ÄÇOLAPH Ê°ÜÊû∂ÂèçË¶ÜË®ìÁ∑¥ LLMÔºå‰ª•‰ΩøÁî®ÊäΩÊ®£È†êÊ∏¨ÂíåÂÅèÂ•ΩÊúÄ‰Ω≥Âåñ‰æÜÊ∏õËºïÂπªË¶∫„ÄÇÊèõÂè•Ë©±Ë™™ÔºåÊàëÂÄëÂèçË¶ÜÂ∞áÊúÄÈ´òÂàÜÂõûÊáâË®≠ÂÆöÁÇ∫ÂæûÊäΩÊ®£È†êÊ∏¨‰∏≠ÂæóÂá∫ÁöÑÈ¶ñÈÅ∏ÂõûÊáâÔºå‰∏¶Ë®ìÁ∑¥ LLM ËàáÊîπÂñÑ‰∫ãÂØ¶ÊÄßÁöÑÈ¶ñÈÅ∏ÂõûÊáâ‰øùÊåÅ‰∏ÄËá¥„ÄÇÊàëÂÄëÂº∑Ë™øÔºåÂç≥‰ΩøÂú®Ë®ìÁ∑¥ÊúüÈñìÊú™‰ΩøÁî®Ë©ï‰º∞ÊåáÊ®ôÔºå‰ΩøÁî®ÊàëÂÄëÁöÑ OLAPH Ê°ÜÊû∂Ë®ìÁ∑¥ÁöÑ LLM ‰πüÂú®‰∫ãÂØ¶ÊÄßÊñπÈù¢Ë°®ÁèæÂá∫È°ØËëóÁöÑÈÄ≤Ê≠•„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúË°®ÊòéÔºå‰ΩøÁî®ÊàëÂÄëÁöÑ OLAPH Ê°ÜÊû∂Ë®ìÁ∑¥ÁöÑ 7B LLM Âú®‰∫ãÂØ¶ÊÄßÊñπÈù¢ÂèØ‰ª•Êèê‰æõËàáÈÜ´ÁôÇÂ∞àÂÆ∂Á≠îÊ°àÁõ∏Áï∂ÁöÑÈï∑ÁØáÂõûÁ≠î„ÄÇÊàëÂÄëÁõ∏‰ø°ÔºåÊàëÂÄëÁöÑÁ†îÁ©∂ÂèØ‰ª•Âπ´Âä©Ë©ï‰º∞ LLM Âú®ÈÜ´ÁôÇÈ†òÂüüÁöÑÈï∑ÁØáÊñáÂ≠óÁî¢ÁîüËÉΩÂäõ„ÄÇÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÂíåË≥áÊñôÈõÜÂèØÂú® https://github.com/dmis-lab/OLAPH Áç≤Âæó„ÄÇ</paragraph>

##### **Exploration of Masked and Causal Language Modelling for Text Generation**
2405.12630v1 by Nicolo Micheletti, Samuel Belkadi, Lifeng Han, Goran Nenadic

Large Language Models (LLMs) have revolutionised the field of Natural
Language Processing (NLP) and have achieved state-of-the-art performance in
practically every task in this field. However, the prevalent approach used in
text generation, Causal Language Modelling (CLM), which generates text
sequentially from left to right, inherently limits the freedom of the model,
which does not decide when and where each token is generated. In contrast,
Masked Language Modelling (MLM), primarily used for language understanding
tasks, can generate tokens anywhere in the text and any order. This paper
conducts an extensive comparison of MLM and CLM approaches for text generation
tasks. To do so, we pre-train several language models of comparable sizes on
three different datasets, namely 1) medical discharge summaries, 2) movie plot
synopses, and 3) authorship verification datasets. To assess the quality of the
generations, we first employ quantitative metrics and then perform a
qualitative human evaluation to analyse coherence and grammatical correctness.
In addition, we evaluate the usefulness of the generated texts by using them in
three different downstream tasks: 1) Entity Recognition, 2) Text
Classification, and 3) Authorship Verification. The results show that MLM
consistently outperforms CLM in text generation across all datasets, with
higher quantitative scores and better coherence in the generated text. The
study also finds \textit{no strong correlation} between the quality of the
generated text and the performance of the models in the downstream tasks. With
this study, we show that MLM for text generation has great potential for future
research and provides direction for future studies in this area.

ÊëòË¶ÅÔºö<paragraph>Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂæπÂ∫ïÊîπËÆä‰∫ÜËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ (NLP) È†òÂüüÔºå‰∏¶Âú®Ë©≤È†òÂüüÁöÑÂπæ‰πéÊØè‰∏ÄÈ†Ö‰ªªÂãô‰∏≠ÈÉΩÈÅîÂà∞‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÊÄßËÉΩ„ÄÇÁÑ∂ËÄåÔºåÊñáÊú¨ÁîüÊàê‰∏≠‰ΩøÁî®ÁöÑÊµÅË°åÊñπÊ≥ïÂõ†ÊûúË™ûË®ÄÂª∫Ê®° (CLM)ÔºåÂÆÉÂæûÂ∑¶Âà∞Âè≥ÊåâÈ†ÜÂ∫èÁîüÊàêÊñáÊú¨ÔºåÂæûÊú¨Ë≥™‰∏äÈôêÂà∂‰∫ÜÊ®°ÂûãÁöÑËá™Áî±Â∫¶ÔºåÂÆÉ‰∏çÊúÉÊ±∫ÂÆö‰ΩïÊôÇ‰ΩïÂú∞ÁîüÊàêÊØèÂÄãÁ¨¶Ëôü„ÄÇÁõ∏ÊØî‰πã‰∏ãÔºå‰∏ªË¶ÅÁî®ÊñºË™ûË®ÄÁêÜËß£‰ªªÂãôÁöÑÈÅÆÁΩ©Ë™ûË®ÄÂª∫Ê®° (MLM) ÂèØ‰ª•Êåâ‰ªª‰ΩïÈ†ÜÂ∫èÂú®ÊñáÊú¨‰∏≠ÁöÑ‰ªª‰Ωï‰ΩçÁΩÆÁîüÊàêÁ¨¶Ëôü„ÄÇÊú¨ÊñáÂ∞ç MLM Âíå CLM ÊñπÊ≥ïÂú®ÊñáÊú¨ÁîüÊàê‰ªªÂãô‰∏≠ÁöÑÈÄ≤Ë°å‰∫ÜÂª£Ê≥õÊØîËºÉ„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÂú®‰∏âÂÄã‰∏çÂêåÁöÑÊï∏ÊìöÈõÜ‰∏äÈ†êË®ìÁ∑¥‰∫ÜÂπæÂÄãÂ§ßÂ∞èÁõ∏Áï∂ÁöÑË™ûË®ÄÊ®°ÂûãÔºåÂç≥ 1) ÈÜ´ÁôÇÂá∫Èô¢ÊëòË¶Å„ÄÅ2) ÈõªÂΩ±ÊÉÖÁØÄÁ∞°‰ªãÂíå 3) ‰ΩúËÄÖÈ©óË≠âÊï∏ÊìöÈõÜ„ÄÇÁÇ∫‰∫ÜË©ï‰º∞ÁîüÊàêÁöÑË≥™ÈáèÔºåÊàëÂÄëÈ¶ñÂÖàÊé°Áî®ÂÆöÈáèÊåáÊ®ôÔºåÁÑ∂ÂæåÈÄ≤Ë°åÂÆöÊÄßÁöÑ‰∫∫Â∑•Ë©ï‰º∞Ôºå‰ª•ÂàÜÊûêÈÄ£Ë≤´ÊÄßÂíåË™ûÊ≥ïÊ≠£Á¢∫ÊÄß„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÈÄöÈÅéÂú®‰∏âÂÄã‰∏çÂêåÁöÑ‰∏ãÊ∏∏‰ªªÂãô‰∏≠‰ΩøÁî®ÁîüÊàêÁöÑÊñáÊú¨‰æÜË©ï‰º∞ÂÖ∂ÊúâÁî®ÊÄßÔºö1) ÂØ¶È´îË≠òÂà•„ÄÅ2) ÊñáÊú¨ÂàÜÈ°ûÂíå 3) ‰ΩúËÄÖÈ©óË≠â„ÄÇÁµêÊûúË°®ÊòéÔºåMLM Âú®ÊâÄÊúâÊï∏ÊìöÈõÜ‰∏äÁöÑÊñáÊú¨ÁîüÊàê‰∏≠ÂßãÁµÇÂÑ™Êñº CLMÔºåÁîüÊàêÁöÑÊñáÊú¨ÂÖ∑ÊúâÊõ¥È´òÁöÑÂÆöÈáèÂàÜÊï∏ÂíåÊõ¥Â•ΩÁöÑÈÄ£Ë≤´ÊÄß„ÄÇË©≤Á†îÁ©∂ÈÇÑÁôºÁèæÁîüÊàêÁöÑÊñáÊú¨Ë≥™ÈáèËàáÊ®°ÂûãÂú®‰∏ãÊ∏∏‰ªªÂãô‰∏≠ÁöÑÊÄßËÉΩ‰πãÈñì\textit{Ê≤íÊúâÂº∑Áõ∏ÈóúÊÄß}„ÄÇÈÄöÈÅéÈÄôÈ†ÖÁ†îÁ©∂ÔºåÊàëÂÄëË°®ÊòéÊñáÊú¨ÁîüÊàêÁöÑ MLM Â∞çÊñºÊú™‰æÜÁöÑÁ†îÁ©∂ÂÖ∑ÊúâÂ∑®Â§ßÊΩõÂäõÔºå‰∏¶ÁÇ∫Ë©≤È†òÂüüÁöÑÊú™‰æÜÁ†îÁ©∂Êèê‰æõ‰∫ÜÊñπÂêë„ÄÇ</paragraph>

##### **DrHouse: An LLM-empowered Diagnostic Reasoning System through Harnessing Outcomes from Sensor Data and Expert Knowledge**
2405.12541v1 by Bufang Yang, Siyang Jiang, Lilin Xu, Kaiwei Liu, Hai Li, Guoliang Xing, Hongkai Chen, Xiaofan Jiang, Zhenyu Yan

Large language models (LLMs) have the potential to transform digital
healthcare, as evidenced by recent advances in LLM-based virtual doctors.
However, current approaches rely on patient's subjective descriptions of
symptoms, causing increased misdiagnosis. Recognizing the value of daily data
from smart devices, we introduce a novel LLM-based multi-turn consultation
virtual doctor system, DrHouse, which incorporates three significant
contributions: 1) It utilizes sensor data from smart devices in the diagnosis
process, enhancing accuracy and reliability. 2) DrHouse leverages continuously
updating medical databases such as Up-to-Date and PubMed to ensure our model
remains at diagnostic standard's forefront. 3) DrHouse introduces a novel
diagnostic algorithm that concurrently evaluates potential diseases and their
likelihood, facilitating more nuanced and informed medical assessments. Through
multi-turn interactions, DrHouse determines the next steps, such as accessing
daily data from smart devices or requesting in-lab tests, and progressively
refines its diagnoses. Evaluations on three public datasets and our
self-collected datasets show that DrHouse can achieve up to an 18.8% increase
in diagnosis accuracy over the state-of-the-art baselines. The results of a
32-participant user study show that 75% medical experts and 91.7% patients are
willing to use DrHouse.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÊúâÊΩõÂäõËΩâËÆäÊï∏‰ΩçÈÜ´ÁôÇ‰øùÂÅ•ÔºåÈÄôÈªûÂæû LLM ÁÇ∫Âü∫Á§éÁöÑËôõÊì¨ÈÜ´Â∏´ÊúÄËøëÁöÑÈÄ≤Â±ï‰∏≠Â∞±ËÉΩÁúãÂá∫„ÄÇÁÑ∂ËÄåÔºåÁõÆÂâçÁöÑÂÅöÊ≥ï‰æùË≥¥ÊñºÊÇ£ËÄÖ‰∏ªËßÄÁöÑÁóáÁãÄÊèèËø∞ÔºåÂ∞éËá¥Ë™§Ë®∫Â¢ûÂä†„ÄÇÊàëÂÄëË™çË≠òÂà∞‰æÜËá™Êô∫ÊÖßË£ùÁΩÆÁöÑÊØèÊó•Ë≥áÊñôÂÉπÂÄºÔºåÂõ†Ê≠§ÊàëÂÄëÂºïÈÄ≤‰∏ÄÂÄãÊñ∞Á©éÁöÑ LLM ÁÇ∫Âü∫Á§éÁöÑÂ§öËº™Ë´ÆË©¢ËôõÊì¨ÈÜ´Â∏´Á≥ªÁµ± DrHouseÔºåÂÆÉÂåÖÂê´‰∏âÂÄãÈáçË¶ÅÁöÑË≤¢ÁçªÔºö1) ÂÆÉÂú®Ë®∫Êñ∑ÈÅéÁ®ã‰∏≠Âà©Áî®‰æÜËá™Êô∫ÊÖßË£ùÁΩÆÁöÑÊÑüÊ∏¨Âô®Ë≥áÊñôÔºåÊèêÂçáÊ∫ñÁ¢∫Â∫¶ÂíåÂèØÈù†Â∫¶„ÄÇ2) DrHouse ÂÖÖÂàÜÂà©Áî®ÊåÅÁ∫åÊõ¥Êñ∞ÁöÑÈÜ´ÁôÇË≥áÊñôÂ∫´Ôºå‰æãÂ¶Ç Up-to-Date Âíå PubMedÔºå‰ª•Á¢∫‰øùÊàëÂÄëÁöÑÊ®°ÂûãÁ∂≠ÊåÅÂú®Ë®∫Êñ∑Ê®ôÊ∫ñÁöÑÊúÄÂâçÁ∑ö„ÄÇ3) DrHouse ÂºïÈÄ≤‰∏ÄÁ®ÆÊñ∞Á©éÁöÑË®∫Êñ∑ÊºîÁÆóÊ≥ïÔºåÂÆÉÂêåÊôÇË©ï‰º∞ÊΩõÂú®ÁñæÁóÖÂèäÂÖ∂ÂèØËÉΩÊÄßÔºå‰øÉÈÄ≤Êõ¥Á¥∞Á∑ª‰∏îÊòéÊô∫ÁöÑÈÜ´ÁôÇË©ï‰º∞„ÄÇÈÄèÈÅéÂ§öËº™‰∫íÂãïÔºåDrHouse Ê±∫ÂÆö‰∏ã‰∏ÄÊ≠•Ôºå‰æãÂ¶ÇÂèñÂæó‰æÜËá™Êô∫ÊÖßË£ùÁΩÆÁöÑÊØèÊó•Ë≥áÊñôÊàñË¶ÅÊ±ÇÂØ¶È©óÂÆ§Ê™¢È©óÔºå‰∏¶ÈÄêÊ≠•ÊîπÂñÑÂÖ∂Ë®∫Êñ∑„ÄÇÈáùÂ∞ç‰∏âÂÄãÂÖ¨ÈñãË≥áÊñôÈõÜÂíåÊàëÂÄëËá™Ë°åÊî∂ÈõÜÁöÑË≥áÊñôÈõÜÈÄ≤Ë°åË©ï‰º∞È°ØÁ§∫ÔºåDrHouse Âú®Ë®∫Êñ∑Ê∫ñÁ¢∫Â∫¶ÊñπÈù¢ÂèØ‰ª•ÊØîÁèæÊúâÊúÄÂÖàÈÄ≤ÁöÑÂü∫Ê∫ñÁ∑öÊèêÈ´ò 18.8%„ÄÇ‰∏ÄÂÄãÊúâ 32 ‰ΩçÂèÉËàáËÄÖÁöÑ‰ΩøÁî®ËÄÖÁ†îÁ©∂ÁµêÊûúÈ°ØÁ§∫Ôºå75% ÁöÑÈÜ´ÁôÇÂ∞àÂÆ∂Âíå 91.7% ÁöÑÊÇ£ËÄÖÈ°òÊÑè‰ΩøÁî® DrHouse„ÄÇ

##### **A Survey of Artificial Intelligence in Gait-Based Neurodegenerative Disease Diagnosis**
2405.13082v1 by Haocong Rao, Minlin Zeng, Xuejiao Zhao, Chunyan Miao

Recent years have witnessed an increasing global population affected by
neurodegenerative diseases (NDs), which traditionally require extensive
healthcare resources and human effort for medical diagnosis and monitoring. As
a crucial disease-related motor symptom, human gait can be exploited to
characterize different NDs. The current advances in artificial intelligence
(AI) models enable automatic gait analysis for NDs identification and
classification, opening a new avenue to facilitate faster and more
cost-effective diagnosis of NDs. In this paper, we provide a comprehensive
survey on recent progress of machine learning and deep learning based AI
techniques applied to diagnosis of five typical NDs through gait. We provide an
overview of the process of AI-assisted NDs diagnosis, and present a systematic
taxonomy of existing gait data and AI models. Through an extensive review and
analysis of 164 studies, we identify and discuss the challenges, potential
solutions, and future directions in this field. Finally, we envision the
prospective utilization of 3D skeleton data for human gait representation and
the development of more efficient AI models for NDs diagnosis. We provide a
public resource repository to track and facilitate developments in this
emerging field: https://github.com/Kali-Hac/AI4NDD-Survey.

ÊëòË¶ÅÔºö<paragraph>ËøëÂπ¥‰æÜÔºåÂèóÁ•ûÁ∂ìÈÄÄÂåñÊÄßÁñæÁóÖ (NDs) ÂΩ±ÈüøÁöÑÂÖ®ÁêÉ‰∫∫Âè£ÊåÅÁ∫åÂ¢ûÂä†ÔºåÈÄô‰∫õÁñæÁóÖÂú®ÂÇ≥Áµ±‰∏äÈúÄË¶ÅÂ§ßÈáèÁöÑÈÜ´ÁôÇ‰øùÂÅ•Ë≥áÊ∫êÂíå‰∫∫ÂäõÈÄ≤Ë°åÈÜ´ÁôÇË®∫Êñ∑ÂíåÁõ£Ê∏¨„ÄÇ‰ΩúÁÇ∫‰∏ÄÁ®ÆËàáÁñæÁóÖÁõ∏ÈóúÁöÑÈáçË¶ÅÈÅãÂãïÁóáÁãÄÔºå‰∫∫È°ûÊ≠•ÊÖãÂèØÁî®ÊñºË°®Âæµ‰∏çÂêåÁöÑÁ•ûÁ∂ìÈÄÄÂåñÊÄßÁñæÁóÖ„ÄÇ‰∫∫Â∑•Êô∫ÊÖß (AI) Ê®°ÂûãÁöÑÊúÄÊñ∞ÈÄ≤Â±ï‰ΩøËá™ÂãïÊ≠•ÊÖãÂàÜÊûêËÉΩÂ§†Ë≠òÂà•ÂíåÂàÜÈ°ûÁ•ûÁ∂ìÈÄÄÂåñÊÄßÁñæÁóÖÔºåÁÇ∫Âä†ÈÄüÂíåÊõ¥ÂÖ∑ÊàêÊú¨ÊïàÁõäÁöÑÁ•ûÁ∂ìÈÄÄÂåñÊÄßÁñæÁóÖË®∫Êñ∑ÈñãÈó¢‰∫Ü‰∏ÄÊ¢ùÊñ∞ÈÄîÂæë„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂ∞çÂü∫ÊñºÊ©üÂô®Â≠∏ÁøíÂíåÊ∑±Â∫¶Â≠∏ÁøíÁöÑ‰∫∫Â∑•Êô∫ÊÖßÊäÄË°ìÊáâÁî®ÊñºÈÄöÈÅéÊ≠•ÊÖãË®∫Êñ∑‰∫îÁ®ÆÂÖ∏ÂûãÁ•ûÁ∂ìÈÄÄÂåñÊÄßÁñæÁóÖÁöÑÊúÄÊñ∞ÈÄ≤Â±ïÈÄ≤Ë°å‰∫ÜÂÖ®Èù¢ÁöÑË™øÊü•„ÄÇÊàëÂÄëÊ¶ÇËø∞‰∫Ü‰∫∫Â∑•Êô∫ËÉΩËºîÂä©Á•ûÁ∂ìÈÄÄÂåñÊÄßÁñæÁóÖË®∫Êñ∑ÁöÑÈÅéÁ®ãÔºå‰∏¶Â∞çÁèæÊúâÁöÑÊ≠•ÊÖãÊï∏ÊìöÂíå‰∫∫Â∑•Êô∫ËÉΩÊ®°ÂûãÊèêÂá∫‰∫ÜÁ≥ªÁµ±ÂàÜÈ°û„ÄÇÈÄöÈÅéÂ∞ç 164 È†ÖÁ†îÁ©∂ÁöÑÂª£Ê≥õÂõûÈ°ßÂíåÂàÜÊûêÔºåÊàëÂÄëÊâæÂá∫‰∏¶Ë®éË´ñ‰∫ÜÈÄô‰∏ÄÈ†òÂüüÁöÑÊåëÊà∞„ÄÅÊΩõÂú®Ëß£Ê±∫ÊñπÊ°àÂíåÊú™‰æÜÊñπÂêë„ÄÇÊúÄÂæåÔºåÊàëÂÄëË®≠ÊÉ≥Êú™‰æÜÂ∞áÂà©Áî® 3D È™®Êû∂Êï∏Êìö‰æÜË°®Á§∫‰∫∫È°ûÊ≠•ÊÖãÔºå‰∏¶ÈñãÁôºÊõ¥ÊúâÊïàÁöÑ AI Ê®°Âûã‰æÜË®∫Êñ∑Á•ûÁ∂ìÈÄÄÂåñÊÄßÁñæÁóÖ„ÄÇÊàëÂÄëÊèê‰æõ‰∫Ü‰∏ÄÂÄãÂÖ¨ÂÖ±Ë≥áÊ∫êÂ∫´‰æÜËøΩËπ§Âíå‰øÉÈÄ≤ÈÄô‰∏ÄÊñ∞ËààÈ†òÂüüÁöÑÁôºÂ±ïÔºöhttps://github.com/Kali-Hac/AI4NDD-Survey„ÄÇ</paragraph>

##### **Future You: A Conversation with an AI-Generated Future Self Reduces Anxiety, Negative Emotions, and Increases Future Self-Continuity**
2405.12514v2 by Pat Pataranutaporn, Kavin Winson, Peggy Yin, Auttasak Lapapirojn, Pichayoot Ouppaphan, Monchai Lertsutthiwong, Pattie Maes, Hal Hershfield

We introduce "Future You," an interactive, brief, single-session, digital
chat intervention designed to improve future self-continuity--the degree of
connection an individual feels with a temporally distant future self--a
characteristic that is positively related to mental health and wellbeing. Our
system allows users to chat with a relatable yet AI-powered virtual version of
their future selves that is tuned to their future goals and personal qualities.
To make the conversation realistic, the system generates a "synthetic
memory"--a unique backstory for each user--that creates a throughline between
the user's present age (between 18-30) and their life at age 60. The "Future
You" character also adopts the persona of an age-progressed image of the user's
present self. After a brief interaction with the "Future You" character, users
reported decreased anxiety, and increased future self-continuity. This is the
first study successfully demonstrating the use of personalized AI-generated
characters to improve users' future self-continuity and wellbeing.

ÊëòË¶ÅÔºöÊàëÂÄëÊé®Âá∫„ÄåÊú™‰æÜ‰Ω†„ÄçÔºå‰∏ÄÁ®Æ‰∫íÂãïÂºè„ÄÅÁ∞°Áü≠„ÄÅÂñÆ‰∏ÄÊúÉË©±ÁöÑÊï∏‰ΩçËÅäÂ§©‰ªãÂÖ•ÔºåÊó®Âú®ÊèêÂçáÊú™‰æÜÁöÑËá™ÊàëÈÄ£Á∫åÊÄßÔºå‰πüÂ∞±ÊòØÂÄã‰∫∫ËàáÊôÇÈñì‰∏äÈÅôÈÅ†ÁöÑÊú™‰æÜËá™Êàë‰πãÈñìÊÑüÂèóÂà∞ÁöÑÈÄ£ÁµêÁ®ãÂ∫¶ÔºåÈÄôÈ†ÖÁâπË≥™ËàáÂøÉÁêÜÂÅ•Â∫∑ÂíåÂπ∏Á¶èÊÑüÂëàÊ≠£Áõ∏Èóú„ÄÇÊàëÂÄëÁöÑÁ≥ªÁµ±ËÆì‰ΩøÁî®ËÄÖÂèØ‰ª•Ëàá‰∏ÄÂÄãË¶™ÂàáÔºå‰ΩÜÁî± AI È©ÖÂãïÁöÑËôõÊì¨Êú™‰æÜËá™ÊàëÁâàÊú¨ËÅäÂ§©ÔºåÈÄôÂÄãÁâàÊú¨Ê†πÊìö‰ΩøÁî®ËÄÖÁöÑÊú™‰æÜÁõÆÊ®ôÂíåÂÄã‰∫∫ÁâπË≥™ÈÄ≤Ë°åË™øÊï¥„ÄÇÁÇ∫‰∫ÜËÆìÂ∞çË©±Êõ¥ÁúüÂØ¶ÔºåÁ≥ªÁµ±ÊúÉÁî¢Áîü‰∏ÄÂÄã„ÄåÂêàÊàêË®òÊÜ∂„ÄçÔºå‰πüÂ∞±ÊòØÊØè‰Ωç‰ΩøÁî®ËÄÖÁöÑÁç®ÁâπËÉåÊôØÊïÖ‰∫ãÔºåÂú®‰ΩøÁî®ËÄÖÁõÆÂâçÁöÑÂπ¥ÈΩ°Ôºà18-30 Ê≠≤ÔºâÂíå 60 Ê≠≤ÁöÑÁîüÊ¥ª‰πãÈñìÂª∫Á´ã‰∏ÄÊ¢ùË≤´Á©øÁ∑ö„ÄÇ„ÄåÊú™‰æÜ‰Ω†„ÄçËßíËâ≤‰πüÊúÉÊé°Áî®‰ΩøÁî®ËÄÖÁõÆÂâçËá™ÊàëÁöÑÂπ¥ÈΩ°ÈÄ≤Â±ïÂΩ±ÂÉèÁöÑ‰∫∫Ê†º„ÄÇËàá„ÄåÊú™‰æÜ‰Ω†„ÄçËßíËâ≤ÈÄ≤Ë°åÁ∞°Áü≠‰∫íÂãïÂæåÔºå‰ΩøÁî®ËÄÖÂõûÂ†±ÁÑ¶ÊÖÆÊÑüÈôç‰ΩéÔºåÊú™‰æÜÁöÑËá™ÊàëÈÄ£Á∫åÊÄßÂ¢ûÂä†„ÄÇÈÄôÊòØÁ¨¨‰∏ÄÂÄãÊàêÂäüÂ±ïÁ§∫‰ΩøÁî®ÂÄã‰∫∫Âåñ AI ÁîüÊàêÁöÑËßíËâ≤‰æÜÊèêÂçá‰ΩøÁî®ËÄÖÊú™‰æÜËá™ÊàëÈÄ£Á∫åÊÄßÂíåÂπ∏Á¶èÊÑüÁöÑÊ°à‰æãÁ†îÁ©∂„ÄÇ

##### **Ensuring Ground Truth Accuracy in Healthcare with the EVINCE framework**
2405.15808v2 by Edward Y. Chang

Misdiagnosis is a significant issue in healthcare, leading to harmful
consequences for patients. The propagation of mislabeled data through machine
learning models into clinical practice is unacceptable. This paper proposes
EVINCE, a system designed to 1) improve diagnosis accuracy and 2) rectify
misdiagnoses and minimize training data errors. EVINCE stands for Entropy
Variation through Information Duality with Equal Competence, leveraging this
novel theory to optimize the diagnostic process using multiple Large Language
Models (LLMs) in a structured debate framework. Our empirical study verifies
EVINCE to be effective in achieving its design goals.

ÊëòË¶ÅÔºöË™§Ë®∫ÊòØÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÁöÑÈáçÂ§ßÂïèÈ°åÔºåÊúÉÂ∞çÊÇ£ËÄÖÈÄ†ÊàêÊúâÂÆ≥ÂæåÊûú„ÄÇÂ∞áÈåØË™§Ê®ôË®òÁöÑË≥áÊñôÈÄèÈÅéÊ©üÂô®Â≠∏ÁøíÊ®°ÂûãÂÇ≥Êí≠Âà∞Ëá®Â∫äÂØ¶Âãô‰∏≠ÊòØ‰∏çÂèØÊé•ÂèóÁöÑ„ÄÇÊú¨ÊñáÊèêÂá∫ EVINCEÔºå‰∏ÄÂÄãÊó®Âú® 1) ÊèêÈ´òË®∫Êñ∑Ê∫ñÁ¢∫ÊÄßÔºå‰ª•Âèä 2) Á≥æÊ≠£Ë™§Ë®∫‰∏¶Â∞áË®ìÁ∑¥Ë≥áÊñôÈåØË™§ÈôçËá≥ÊúÄ‰ΩéÁöÑÁ≥ªÁµ±„ÄÇEVINCE ÊòØ Entropy Variation through Information Duality with Equal Competence ÁöÑÁ∏ÆÂØ´ÔºåÂà©Áî®Ê≠§ÂâµÊñ∞ÁêÜË´ñÂú®ÁµêÊßãÂåñÁöÑËæØË´ñÊû∂Êßã‰∏≠‰ΩøÁî®Â§öÂÄãÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰æÜÊúÄ‰Ω≥ÂåñË®∫Êñ∑ÊµÅÁ®ã„ÄÇÊàëÂÄëÁöÑÂØ¶Ë≠âÁ†îÁ©∂È©óË≠â EVINCE Âú®ÈÅîÊàêÂÖ∂Ë®≠Ë®àÁõÆÊ®ôÊñπÈù¢ÊòØÊúâÊïàÁöÑ„ÄÇ

##### **Digital Health and Indoor Air Quality: An IoT-Driven Human-Centred Visualisation Platform for Behavioural Change and Technology Acceptance**
2405.13064v1 by Rameez Raja Kureshi, Bhupesh Kumar Mishra, Dhavalkumar Thakker, Suvodeep Mazumdar, Xiao Li

The detrimental effects of air pollutants on human health have prompted
increasing concerns regarding indoor air quality (IAQ). The emergence of
digital health interventions and citizen science initiatives has provided new
avenues for raising awareness, improving IAQ, and promoting behavioural
changes. The Technology Acceptance Model (TAM) offers a theoretical framework
to understand user acceptance and adoption of IAQ technology. This paper
presents a case study using the COM-B model and Internet of Things (IoT)
technology to design a human-centred digital visualisation platform, leading to
behavioural changes and improved IAQ. The study also investigates users'
acceptance and adoption of the technology, focusing on their experiences,
expectations, and the impact on IAQ. Integrating IAQ sensing, digital
health-related interventions, citizen science, and the TAM model offers
opportunities to address IAQ challenges, enhance public health, and foster
sustainable indoor environments. The analytical results show that factors such
as human behaviour, indoor activities, and awareness play crucial roles in
shaping IAQ.

ÊëòË¶ÅÔºöÁ©∫Ê∞îÊ±°ÊüìÁâ©ÂØπ‰∫∫‰ΩìÂÅ•Â∫∑ÁöÑ‰∏çÂà©ÂΩ±ÂìçÂºïÂèë‰∫Ü‰∫∫‰ª¨ÂØπÂÆ§ÂÜÖÁ©∫Ê∞îË¥®Èáè (IAQ) ÁöÑÊó•ÁõäÊãÖÂøß„ÄÇÊï∞Â≠óÂÅ•Â∫∑Âπ≤È¢ÑÊé™ÊñΩÂíåÂÖ¨Ê∞ëÁßëÂ≠¶ÂÄ°ËÆÆÁöÑÂá∫Áé∞‰∏∫ÊèêÈ´òËÆ§ËØÜ„ÄÅÊîπÂñÑÂÆ§ÂÜÖÁ©∫Ê∞îË¥®ÈáèÂíå‰øÉËøõË°å‰∏∫ÊîπÂèòÊèê‰æõ‰∫ÜÊñ∞ÈÄîÂæÑ„ÄÇÊäÄÊúØÊé•ÂèóÊ®°Âûã (TAM) Êèê‰æõ‰∫Ü‰∏Ä‰∏™ÁêÜËÆ∫Ê°ÜÊû∂ÔºåÁî®‰∫éÁêÜËß£Áî®Êà∑ÂØπÂÆ§ÂÜÖÁ©∫Ê∞îË¥®ÈáèÊäÄÊúØÁöÑÊé•ÂèóÂíåÈááÁî®„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏Ä‰∏™Ê°à‰æãÁ†îÁ©∂Ôºå‰ΩøÁî® COM-B Ê®°ÂûãÂíåÁâ©ËÅîÁΩë (IoT) ÊäÄÊúØÊù•ËÆæËÆ°‰∏Ä‰∏™‰ª•‰∫∫‰∏∫‰∏≠ÂøÉÁöÑÊï∞Â≠óÂèØËßÜÂåñÂπ≥Âè∞Ôºå‰ªéËÄåÂØºËá¥Ë°å‰∏∫ÊîπÂèòÂíåÊîπÂñÑÂÆ§ÂÜÖÁ©∫Ê∞îË¥®Èáè„ÄÇËØ•Á†îÁ©∂ËøòË∞ÉÊü•‰∫ÜÁî®Êà∑ÂØπËØ•ÊäÄÊúØÁöÑÊé•ÂèóÂíåÈááÁî®ÊÉÖÂÜµÔºåÈáçÁÇπÂÖ≥Ê≥®‰ªñ‰ª¨ÁöÑÁªèÈ™å„ÄÅÊúüÊúõÂíåÂØπÂÆ§ÂÜÖÁ©∫Ê∞îË¥®ÈáèÁöÑÂΩ±Âìç„ÄÇÊï¥ÂêàÂÆ§ÂÜÖÁ©∫Ê∞îË¥®Èáè‰º†ÊÑü„ÄÅÊï∞Â≠óÂÅ•Â∫∑Áõ∏ÂÖ≥Âπ≤È¢ÑÊé™ÊñΩ„ÄÅÂÖ¨Ê∞ëÁßëÂ≠¶ÂíåÊäÄÊúØÊé•ÂèóÊ®°ÂûãÊèê‰æõ‰∫ÜÂ∫îÂØπÂÆ§ÂÜÖÁ©∫Ê∞îË¥®ÈáèÊåëÊàò„ÄÅÂ¢ûÂº∫ÂÖ¨ÂÖ±Âç´ÁîüÂíå‰øÉËøõÂèØÊåÅÁª≠ÂÆ§ÂÜÖÁéØÂ¢ÉÁöÑÊú∫‰ºö„ÄÇÂàÜÊûêÁªìÊûúË°®ÊòéÔºå‰∫∫Á±ªË°å‰∏∫„ÄÅÂÆ§ÂÜÖÊ¥ªÂä®ÂíåÊÑèËØÜÁ≠âÂõ†Á¥†Âú®Â°ëÈÄ†ÂÆ§ÂÜÖÁ©∫Ê∞îË¥®ÈáèÊñπÈù¢ÂèëÊå•ÁùÄËá≥ÂÖ≥ÈáçË¶ÅÁöÑ‰ΩúÁî®„ÄÇ

##### **Recommender Algorithm for Supporting Self-Management of CVD Risk Factors in an Adult Population at Home**
2405.11967v1 by Tatiana V. Afanasieva, Pavel V. Platov, Anastasia I. Medvedeva

One of the new trends in the development of recommendation algorithms is the
dissemination of their capabilities to support the population in managing their
health. This article focuses on the problem of improving the effectiveness of
cardiovascular diseases (CVD) prevention, since CVD is the leading cause of
death worldwide. To address this issue, a knowledge-based recommendation
algorithm was proposed to support self-management of CVD risk factors in adults
at home. The proposed algorithm is based on the original multidimensional
recommendation model and on a new user profile model, which includes predictive
assessments of CVD health in addition to its current ones as outlined in
official guidelines. The main feature of the proposed algorithm is the
combination of rule-based logic with the capabilities of a large language model
in generating human-like text for explanatory component of multidimensional
recommendation. The verification and evaluation of the proposed algorithm
showed the usefulness of the proposed recommendation algorithm for supporting
adults in self-management of their CVD risk factors at home. As follows from
the comparison with similar knowledge-based recommendation algorithms, the
proposed algorithm evaluates a larger number of CVD risk factors and has a
greater information and semantic capacity of the generated recommendations.

ÊëòË¶ÅÔºöÊé®Ëñ¶ÊºîÁÆóÊ≥ïÁôºÂ±ïÁöÑÊñ∞Ë∂®Âã¢‰πã‰∏ÄÊòØÂÇ≥Êí≠ÂÖ∂ËÉΩÂäõÔºå‰ª•ÂçîÂä©Ê∞ëÁúæÁÆ°ÁêÜËá™Ë∫´ÂÅ•Â∫∑„ÄÇÊú¨ÊñáÈáçÈªûÊé¢Ë®éÊîπÂñÑÂøÉË°ÄÁÆ°ÁñæÁóÖÔºàCVDÔºâÈ†êÈò≤ÁöÑÊúâÊïàÊÄßÔºåÂõ†ÁÇ∫ CVD ÊòØÂÖ®ÁêÉ‰∏ªË¶ÅÁöÑÊ≠ª‰∫°ÂéüÂõ†„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂü∫ÊñºÁü•Ë≠òÁöÑÊé®Ëñ¶ÊºîÁÆóÊ≥ïÔºå‰ª•Âú®ÂÆ∂‰∏≠ÊîØÊè¥Êàê‰∫∫Ëá™ÊàëÁÆ°ÁêÜ CVD È¢®Èö™Âõ†Â≠ê„ÄÇÊâÄÊèêÂá∫ÁöÑÊºîÁÆóÊ≥ïÂü∫ÊñºÂéüÂßãÁöÑÂ§öÁ∂≠Â∫¶Êé®Ëñ¶Ê®°ÂûãÂíåÊñ∞ÁöÑ‰ΩøÁî®ËÄÖËº™ÂªìÊ®°ÂûãÔºåÂÖ∂‰∏≠Èô§‰∫ÜÂÆòÊñπÊåáÂçó‰∏≠Ê¶ÇËø∞ÁöÑÁèæÊúâË©ï‰º∞Â§ñÔºåÈÇÑÂåÖÊã¨ CVD ÂÅ•Â∫∑ÁöÑÈ†êÊ∏¨Ë©ï‰º∞„ÄÇÊâÄÊèêÂá∫ÁöÑÊºîÁÆóÊ≥ï‰∏ªË¶ÅÁâπËâ≤ÊòØÂ∞áÂü∫ÊñºË¶èÂâáÁöÑÈÇèËºØËàáÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÁöÑËÉΩÂäõÁõ∏ÁµêÂêàÔºå‰ª•Áî¢ÁîüÈ°û‰∫∫ÊñáÂ≠óÔºå‰ΩúÁÇ∫Â§öÁ∂≠Â∫¶Êé®Ëñ¶ÁöÑË™™ÊòéÊÄßÁµÑÊàêÈÉ®ÂàÜ„ÄÇÊâÄÊèêÂá∫ÁöÑÊºîÁÆóÊ≥ïÁöÑÈ©óË≠âÂíåË©ï‰º∞È°ØÁ§∫ÔºåÊâÄÊèêÂá∫ÁöÑÊé®Ëñ¶ÊºîÁÆóÊ≥ïÂú®ÂçîÂä©Êàê‰∫∫Âú®ÂÆ∂‰∏≠Ëá™ÊàëÁÆ°ÁêÜÂÖ∂ CVD È¢®Èö™Âõ†Â≠êÊñπÈù¢ÂæàÊúâÁî®„ÄÇÂæûËàáÈ°û‰ººÁöÑÂü∫ÊñºÁü•Ë≠òÁöÑÊé®Ëñ¶ÊºîÁÆóÊ≥ïÁöÑÊØîËºÉ‰∏≠ÂæóÁü•ÔºåÊâÄÊèêÂá∫ÁöÑÊºîÁÆóÊ≥ïË©ï‰º∞‰∫ÜÊõ¥Â§ö CVD È¢®Èö™Âõ†Â≠êÔºå‰∏¶‰∏îÁî¢ÁîüÁöÑÂª∫Ë≠∞ÂÖ∑ÊúâÊõ¥Â§ßÁöÑË≥áË®äÂíåË™ûÁæ©ÂÆπÈáè„ÄÇ

##### **Contactless Polysomnography: What Radio Waves Tell Us about Sleep**
2405.11739v1 by Hao He, Chao Li, Wolfgang Ganglberger, Kaileigh Gallagher, Rumen Hristov, Michail Ouroutzoglou, Haoqi Sun, Jimeng Sun, Brandon Westover, Dina Katabi

The ability to assess sleep at home, capture sleep stages, and detect the
occurrence of apnea (without on-body sensors) simply by analyzing the radio
waves bouncing off people's bodies while they sleep is quite powerful. Such a
capability would allow for longitudinal data collection in patients' homes,
informing our understanding of sleep and its interaction with various diseases
and their therapeutic responses, both in clinical trials and routine care. In
this article, we develop an advanced machine learning algorithm for passively
monitoring sleep and nocturnal breathing from radio waves reflected off people
while asleep. Validation results in comparison with the gold standard (i.e.,
polysomnography) (n=849) demonstrate that the model captures the sleep
hypnogram (with an accuracy of 81% for 30-second epochs categorized into Wake,
Light Sleep, Deep Sleep, or REM), detects sleep apnea (AUROC = 0.88), and
measures the patient's Apnea-Hypopnea Index (ICC=0.95; 95% CI = [0.93, 0.97]).
Notably, the model exhibits equitable performance across race, sex, and age.
Moreover, the model uncovers informative interactions between sleep stages and
a range of diseases including neurological, psychiatric, cardiovascular, and
immunological disorders. These findings not only hold promise for clinical
practice and interventional trials but also underscore the significance of
sleep as a fundamental component in understanding and managing various
diseases.

ÊëòË¶ÅÔºö<paragraph>ÂÉÖÈÄèÈÅéÂàÜÊûê‰∫∫ÂÄëÁù°Ë¶∫ÊôÇÂæûË∫´È´îÂèçÂ∞ÑÁöÑÁÑ°Á∑öÈõªÊ≥¢ÔºåÂ∞±ËÉΩË©ï‰º∞Â±ÖÂÆ∂Áù°Áú†„ÄÅÊçïÊçâÁù°Áú†ÈöéÊÆµ‰∏¶ÂÅµÊ∏¨ÂëºÂê∏‰∏≠Ê≠¢ÔºàÁÑ°ÈúÄÈÖçÊà¥Ë∫´È´îÊÑüÊ∏¨Âô®ÔºâÁöÑËÉΩÂäõÈùûÂ∏∏Âº∑Â§ß„ÄÇÈÄôÁ®ÆËÉΩÂäõËÉΩËÆìÊÇ£ËÄÖÂú®ÂÆ∂‰∏≠ÈÄ≤Ë°åÁ∏±ÂêëË≥áÊñôÊî∂ÈõÜÔºåÊúâÂä©ÊñºÊàëÂÄë‰∫ÜËß£Áù°Áú†ÂèäÂÖ∂ËàáÂêÑÁ®ÆÁñæÁóÖÁöÑ‰∫§‰∫í‰ΩúÁî®Ôºå‰ª•ÂèäÂú®Ëá®Â∫äË©¶È©óÂíå‰æãË°åÁÖßË≠∑‰∏≠ÁöÑÊ≤ªÁôÇÂèçÊáâ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÈñãÁôº‰∫Ü‰∏ÄÁ®ÆÂÖàÈÄ≤ÁöÑÊ©üÂô®Â≠∏ÁøíÊºîÁÆóÊ≥ïÔºåÂèØË¢´ÂãïÁõ£Êéß‰∫∫ÂÄëÁù°Ë¶∫ÊôÇÂæûË∫´È´îÂèçÂ∞ÑÁöÑÁÑ°Á∑öÈõªÊ≥¢‰∏≠ÁöÑÁù°Áú†ÂíåÂ§úÈñìÂëºÂê∏„ÄÇËàáÈªÉÈáëÊ®ôÊ∫ñÔºàÂç≥Â§öÈáçÁù°Áú†ÁîüÁêÜÊ™¢Êü•ÔºâÔºàn=849ÔºâÁõ∏ÊØîÁöÑÈ©óË≠âÁµêÊûúÈ°ØÁ§∫ÔºåË©≤Ê®°ÂûãÊçïÊçâÂà∞‰∫ÜÁù°Áú†ËÖ¶Ê≥¢ÂúñÔºà30 ÁßíÊôÇÈñìÂçÄÊÆµÂàÜÈ°ûÁÇ∫Ê∏ÖÈÜí„ÄÅÊ∑∫Áú†„ÄÅÊ∑±Áú†ÊàñÂø´ÈÄüÂãïÁúºÊúüÔºåÊ∫ñÁ¢∫Â∫¶ÁÇ∫ 81%ÔºâÔºåÂèØÂÅµÊ∏¨Áù°Áú†ÂëºÂê∏‰∏≠Ê≠¢ÔºàAUROC = 0.88ÔºâÔºå‰∏¶Ê∏¨ÈáèÊÇ£ËÄÖÁöÑÂëºÂê∏‰∏≠Ê≠¢‰ΩéÈÄöÊ∞£ÊåáÊï∏ÔºàICC=0.95Ôºõ95% CI = [0.93, 0.97]Ôºâ„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåË©≤Ê®°ÂûãÂú®Á®ÆÊóè„ÄÅÊÄßÂà•ÂíåÂπ¥ÈΩ°‰∏äË°®ÁèæÂá∫ÂÖ¨Âπ≥ÁöÑÊïàËÉΩ„ÄÇÊ≠§Â§ñÔºåË©≤Ê®°ÂûãÊè≠Á§∫‰∫ÜÁù°Áú†ÈöéÊÆµËàáÁ•ûÁ∂ì„ÄÅÁ≤æÁ•û„ÄÅÂøÉË°ÄÁÆ°ÂíåÂÖçÁñ´ÁñæÁóÖÁ≠â‰∏ÄÁ≥ªÂàóÁñæÁóÖ‰πãÈñìÁöÑË≥áË®äÊÄß‰∫§‰∫í‰ΩúÁî®„ÄÇÈÄô‰∫õÁôºÁèæ‰∏çÂÉÖÂ∞çËá®Â∫äÂØ¶ÂãôÂíå‰ªãÂÖ•Ë©¶È©óÊúâÊúõÔºå‰πüÂº∑Ë™ø‰∫ÜÁù°Áú†‰ΩúÁÇ∫ÁêÜËß£ÂíåÁÆ°ÁêÜÂêÑÁ®ÆÁñæÁóÖÁöÑÂü∫Êú¨ÁµÑÊàêÈÉ®ÂàÜÁöÑÈáçË¶ÅÊÄß„ÄÇ</paragraph>

##### **Large Language Models for Medicine: A Survey**
2405.13055v1 by Yanxin Zheng, Wensheng Gan, Zefeng Chen, Zhenlian Qi, Qian Liang, Philip S. Yu

To address challenges in the digital economy's landscape of digital
intelligence, large language models (LLMs) have been developed. Improvements in
computational power and available resources have significantly advanced LLMs,
allowing their integration into diverse domains for human life. Medical LLMs
are essential application tools with potential across various medical
scenarios. In this paper, we review LLM developments, focusing on the
requirements and applications of medical LLMs. We provide a concise overview of
existing models, aiming to explore advanced research directions and benefit
researchers for future medical applications. We emphasize the advantages of
medical LLMs in applications, as well as the challenges encountered during
their development. Finally, we suggest directions for technical integration to
mitigate challenges and potential research directions for the future of medical
LLMs, aiming to meet the demands of the medical field better.

ÊëòË¶ÅÔºöÁÇ∫‰∫ÜÊáâÂ∞çÊï∏‰ΩçÁ∂ìÊøüÁí∞Â¢É‰∏≠Êï∏‰ΩçÊô∫ÊÖßÁöÑÊåëÊà∞ÔºåÂ∑≤Á∂ìÈñãÁôºÂá∫Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM)„ÄÇÈÅãÁÆóËÉΩÂäõÂíåÂèØÁî®Ë≥áÊ∫êÁöÑÈÄ≤Ê≠•Â§ßÂπÖÊèêÂçá LLMÔºåËÆìÂÆÉÂÄëËÉΩÂ§†Êï¥ÂêàÂà∞‰∫∫È°ûÁîüÊ¥ªÁöÑ‰∏çÂêåÈ†òÂüü„ÄÇÈÜ´ÁôÇ LLM ÊòØÈáçË¶ÅÁöÑÊáâÁî®Â∑•ÂÖ∑ÔºåÂú®ÂêÑÁ®ÆÈÜ´ÁôÇÂ†¥ÊôØ‰∏≠ÂÖ∑ÊúâÊΩõÂäõ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂõûÈ°ß LLM ÁöÑÁôºÂ±ïÔºåÈáçÈªûÊé¢Ë®éÈÜ´ÁôÇ LLM ÁöÑÈúÄÊ±ÇÂíåÊáâÁî®„ÄÇÊàëÂÄëÁ∞°Ë¶ÅÊ¶ÇËø∞ÁèæÊúâÊ®°ÂûãÔºåÊó®Âú®Êé¢Ë®éÈÄ≤ÈöéÁöÑÁ†îÁ©∂ÊñπÂêëÔºå‰∏¶ÈÄ†Á¶èÊú™‰æÜÈÜ´ÁôÇÊáâÁî®ÁöÑÁ†îÁ©∂‰∫∫Âì°„ÄÇÊàëÂÄëÂº∑Ë™øÈÜ´ÁôÇ LLM Âú®ÊáâÁî®‰∏≠ÁöÑÂÑ™ÈªûÔºå‰ª•ÂèäÂú®ÈñãÁôºÈÅéÁ®ã‰∏≠ÈÅáÂà∞ÁöÑÊåëÊà∞„ÄÇÊúÄÂæåÔºåÊàëÂÄëÊèêÂá∫ÊäÄË°ìÊï¥ÂêàÁöÑÊñπÂêëÔºå‰ª•Ê∏õËºïÊåëÊà∞Ôºå‰∏¶ÊèêÂá∫ÈÜ´ÁôÇ LLM Êú™‰æÜÁöÑÊΩõÂú®Á†îÁ©∂ÊñπÂêëÔºåÁõÆÊ®ôÊòØÊõ¥Â•ΩÂú∞ÊªøË∂≥ÈÜ´ÁôÇÈ†òÂüüÁöÑÈúÄÊ±Ç„ÄÇ

##### **Towards Contactless Elevators with TinyML using CNN-based Person Detection and Keyword Spotting**
2405.13051v1 by Anway S. Pimpalkar, Deeplaxmi V. Niture

This study presents a proof of concept for a contactless elevator operation
system aimed at minimizing human intervention while enhancing safety,
intelligence, and efficiency. A microcontroller-based edge device executing
tiny Machine Learning (tinyML) inferences is developed for elevator operation.
Using person detection and keyword spotting algorithms, the system offers
cost-effective and robust units requiring minimal infrastructural changes. The
design incorporates preprocessing steps and quantized convolutional neural
networks in a multitenant framework to optimize accuracy and response time.
Results show a person detection accuracy of 83.34% and keyword spotting
efficacy of 80.5%, with an overall latency under 5 seconds, indicating
effectiveness in real-world scenarios. Unlike current high-cost and
inconsistent contactless technologies, this system leverages tinyML to provide
a cost-effective, reliable, and scalable solution, enhancing user safety and
operational efficiency without significant infrastructural changes. The study
highlights promising results, though further exploration is needed for
scalability and integration with existing systems. The demonstrated energy
efficiency, simplicity, and safety benefits suggest that tinyML adoption could
revolutionize elevator systems, serving as a model for future technological
advancements. This technology could significantly impact public health and
convenience in multi-floor buildings by reducing physical contact and improving
operational efficiency, particularly relevant in the context of pandemics or
hygiene concerns.

ÊëòË¶ÅÔºöÊú¨Á†îÁ©∂ÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÈùûÊé•Ëß∏ÂºèÈõªÊ¢ØÊìç‰ΩúÁ≥ªÁµ±ÁöÑÊ¶ÇÂøµÈ©óË≠âÔºåÊó®Âú®ÊúÄÂ§ßÈôêÂ∫¶Âú∞Ê∏õÂ∞ë‰∫∫ÁÇ∫Âπ≤È†êÔºåÂêåÊôÇÊèêÈ´òÂÆâÂÖ®ÊÄß„ÄÅÊô∫ÊÖßÂåñÂíåÊïàÁéá„ÄÇÈñãÁôº‰∫Ü‰∏ÄÁ®ÆÂü∫ÊñºÂæÆÊéßÂà∂Âô®ÁöÑÈÇäÁ∑£Ë®≠ÂÇôÔºåÁî®ÊñºÂü∑Ë°åÂæÆÂûãÊ©üÂô®Â≠∏Áøí (tinyML) Êé®Ë´ñÔºå‰ª•ÈÄ≤Ë°åÈõªÊ¢ØÊìç‰Ωú„ÄÇË©≤Á≥ªÁµ±‰ΩøÁî®‰∫∫Âì°Ê™¢Ê∏¨ÂíåÈóúÈçµÂ≠óË≠òÂà•ÊºîÁÆóÊ≥ïÔºåÊèê‰æõÁ∂ìÊøüÂØ¶ÊÉ†‰∏îÂº∑Â§ßÁöÑÂñÆÂÖÉÔºåÂè™ÈúÄÊúÄÂ∞ëÁöÑÂü∫Á§éË®≠ÊñΩËÆäÊõ¥„ÄÇË©≤Ë®≠Ë®àÂú®Â§öÁßüÊà∂Êû∂Êßã‰∏≠ÁµêÂêà‰∫ÜÈ†êËôïÁêÜÊ≠•È©üÂíåÈáèÂåñÁöÑÂç∑Á©çÁ•ûÁ∂ìÁ∂≤Ë∑ØÔºå‰ª•ÊúÄ‰Ω≥ÂåñÊ∫ñÁ¢∫Â∫¶ÂíåÂõûÊáâÊôÇÈñì„ÄÇÁµêÊûúÈ°ØÁ§∫‰∫∫Âì°Ê™¢Ê∏¨Ê∫ñÁ¢∫Â∫¶ÁÇ∫ 83.34%ÔºåÈóúÈçµÂ≠óË≠òÂà•ÊïàÁéáÁÇ∫ 80.5%ÔºåÊï¥È´îÂª∂ÈÅ≤‰ΩéÊñº 5 ÁßíÔºåË°®ÊòéÂú®ÂØ¶ÈöõÂ†¥ÊôØ‰∏≠ÊúâÊïà„ÄÇËàáÁõÆÂâçÈ´òÊàêÊú¨‰∏î‰∏ç‰∏ÄËá¥ÁöÑÈùûÊé•Ëß∏ÂºèÊäÄË°ì‰∏çÂêåÔºåÊ≠§Á≥ªÁµ±Âà©Áî® tinyML Êèê‰æõÁ∂ìÊøüÂØ¶ÊÉ†„ÄÅÂèØÈù†‰∏îÂèØÊì¥ÂÖÖÁöÑËß£Ê±∫ÊñπÊ°àÔºåÂú®‰∏çÈÄ≤Ë°åÈáçÂ§ßÂü∫Á§éË®≠ÊñΩËÆäÊõ¥ÁöÑÊÉÖÊ≥Å‰∏ãÊèêÈ´ò‰ΩøÁî®ËÄÖÂÆâÂÖ®ÊÄßËàáÁáüÈÅãÊïàÁéá„ÄÇÊú¨Á†îÁ©∂Âº∑Ë™ø‰∫ÜÊúâÂ∏åÊúõÁöÑÁµêÊûúÔºåÂÑòÁÆ°ÈúÄË¶ÅÈÄ≤‰∏ÄÊ≠•Êé¢Á¥¢‰ª•Êì¥ÂÖÖË¶èÊ®°‰∏¶ËàáÁèæÊúâÁ≥ªÁµ±Êï¥Âêà„ÄÇÂ∑≤Â±ïÁ§∫ÁöÑËÉΩÊ∫êÊïàÁéá„ÄÅÁ∞°ÊΩîÊÄßÂíåÂÆâÂÖ®ÊÄßÂÑ™Âã¢Ë°®ÊòéÔºåtinyML ÁöÑÊé°Áî®ÂèØ‰ª•ÂæπÂ∫ïÊîπËÆäÈõªÊ¢ØÁ≥ªÁµ±Ôºå‰ΩúÁÇ∫Êú™‰æÜÊäÄË°ìÈÄ≤Ê≠•ÁöÑÂÖ∏ÁØÑ„ÄÇÊ≠§ÊäÄË°ìÂèØ‰ª•ÈÄèÈÅéÊ∏õÂ∞ëË∫´È´îÊé•Ëß∏‰∏¶ÊèêÂçáÁáüÈÅãÊïàÁéáÔºåÈ°ØËëóÂΩ±ÈüøÂ§öÂ±§Âª∫ÁØâ‰∏≠ÁöÑÂÖ¨ÂÖ±Ë°õÁîüËàá‰æøÂà©ÊÄßÔºåÁâπÂà•ÊòØÂú®ÊµÅË°åÁóÖÊàñË°õÁîüÂïèÈ°åÁöÑËÉåÊôØ‰∏ãÂÖ∑ÊúâÁõ∏ÈóúÊÄß„ÄÇ

##### **Inquire, Interact, and Integrate: A Proactive Agent Collaborative Framework for Zero-Shot Multimodal Medical Reasoning**
2405.11640v1 by Zishan Gu, Fenglin Liu, Changchang Yin, Ping Zhang

The adoption of large language models (LLMs) in healthcare has attracted
significant research interest. However, their performance in healthcare remains
under-investigated and potentially limited, due to i) they lack rich
domain-specific knowledge and medical reasoning skills; and ii) most
state-of-the-art LLMs are unimodal, text-only models that cannot directly
process multimodal inputs. To this end, we propose a multimodal medical
collaborative reasoning framework \textbf{MultiMedRes}, which incorporates a
learner agent to proactively gain essential information from domain-specific
expert models, to solve medical multimodal reasoning problems. Our method
includes three steps: i) \textbf{Inquire}: The learner agent first decomposes
given complex medical reasoning problems into multiple domain-specific
sub-problems; ii) \textbf{Interact}: The agent then interacts with
domain-specific expert models by repeating the ``ask-answer'' process to
progressively obtain different domain-specific knowledge; iii)
\textbf{Integrate}: The agent finally integrates all the acquired
domain-specific knowledge to accurately address the medical reasoning problem.
We validate the effectiveness of our method on the task of difference visual
question answering for X-ray images. The experiments demonstrate that our
zero-shot prediction achieves state-of-the-art performance, and even
outperforms the fully supervised methods. Besides, our approach can be
incorporated into various LLMs and multimodal LLMs to significantly boost their
performance.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâÂú®ÈÜ´ÁôÇ‰øùÂÅ•È†òÂüüÁöÑÊé°Áî®ÂºïËµ∑‰∫Ü
È°ØËëóÁöÑÁ†îÁ©∂ËààË∂£„ÄÇÁÑ∂ËÄåÔºåÁî±Êñº i) ÂÆÉÂÄëÁº∫‰πèË±êÂØåÁöÑÁâπÂÆöÈ†òÂüüÁü•Ë≠òÂíåÈÜ´ÁôÇÊé®ÁêÜÊäÄËÉΩÔºõ‰ª•Âèä ii) Â§ßÂ§öÊï∏
ÊúÄÂÖàÈÄ≤ÁöÑ LLM ÊòØÂñÆÊ®°ÊÖã„ÄÅÁ¥îÊñáÂ≠óÊ®°ÂûãÔºåÁÑ°Ê≥ïÁõ¥Êé•
ËôïÁêÜÂ§öÊ®°ÊÖãËº∏ÂÖ•ÔºåÂõ†Ê≠§ÂÆÉÂÄëÂú®ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÁöÑË°®Áèæ‰ªçÊú™ÂæóÂà∞ÂÖÖÂàÜÁ†îÁ©∂Ôºå‰∏îÊΩõÂú®ÂèóÈôê„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂ§öÊ®°ÊÖãÈÜ´ÁôÇ
Âçî‰ΩúÊé®ÁêÜÊ°ÜÊû∂\textbf{MultiMedRes}ÔºåÂÆÉÂåÖÂê´‰∏ÄÂÄãÂ≠∏Áøí‰ª£ÁêÜÔºåÂèØ‰∏ªÂãïÂæûÁâπÂÆöÈ†òÂüüÁöÑ
Â∞àÂÆ∂Ê®°Âûã‰∏≠Áç≤ÂèñÂü∫Êú¨Ë≥áË®äÔºå‰ª•Ëß£Ê±∫ÈÜ´ÁôÇÂ§öÊ®°ÊÖãÊé®ÁêÜÂïèÈ°å„ÄÇÊàëÂÄëÁöÑ
ÊñπÊ≥ïÂåÖÊã¨‰∏âÂÄãÊ≠•È©üÔºöi) \textbf{Ë©¢Âïè}ÔºöÂ≠∏Áøí‰ª£ÁêÜÈ¶ñÂÖàÂ∞á
Áµ¶ÂÆöÁöÑË§áÈõúÈÜ´ÁôÇÊé®ÁêÜÂïèÈ°åÂàÜËß£ÁÇ∫Â§öÂÄãÁâπÂÆöÈ†òÂüüÁöÑ
Â≠êÂïèÈ°åÔºõii) \textbf{‰∫íÂãï}ÔºöÁÑ∂ÂæåÔºå‰ª£ÁêÜÈÄèÈÅéÈáçË§á``Ë©¢Âïè-ÂõûÁ≠î''Á®ãÂ∫èËàá
ÁâπÂÆöÈ†òÂüüÁöÑÂ∞àÂÆ∂Ê®°Âûã‰∫íÂãïÔºå‰ª•ÈÄêÊ≠•Áç≤Âèñ‰∏çÂêåÁöÑÁâπÂÆöÈ†òÂüüÁü•Ë≠òÔºõiii)
\textbf{Êï¥Âêà}ÔºöÊúÄÂæåÔºå‰ª£ÁêÜÊï¥ÂêàÊâÄÊúâÁç≤ÂæóÁöÑ
ÁâπÂÆöÈ†òÂüüÁü•Ë≠òÔºå‰ª•Ê∫ñÁ¢∫Ëß£Ê±∫ÈÜ´ÁôÇÊé®ÁêÜÂïèÈ°å„ÄÇ
ÊàëÂÄëÂú® X ÂÖâÂΩ±ÂÉèÁöÑÂ∑ÆÁï∞Ë¶ñË¶∫ÂïèÈ°åËß£Á≠î‰ªªÂãô‰∏äÈ©óË≠â‰∫ÜÊàëÂÄëÊñπÊ≥ïÁöÑÊúâÊïàÊÄß„ÄÇÂØ¶È©óË°®ÊòéÔºåÊàëÂÄëÁöÑ
Èõ∂Ê¨°Â≠∏ÁøíÈ†êÊ∏¨ÈÅîÂà∞‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÊÄßËÉΩÔºåÁîöËá≥
ÂÑ™ÊñºÂÆåÂÖ®Áõ£Áù£ÁöÑÊñπÊ≥ï„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁöÑ
ÊñπÊ≥ïÂèØ‰ª•Êï¥ÂêàÂà∞ÂêÑÁ®Æ LLM ÂíåÂ§öÊ®°ÊÖã LLM ‰∏≠Ôºå‰ª•È°ØËëóÊèêÂçáÂÖ∂
ÊÄßËÉΩ„ÄÇ

##### **Sociotechnical Implications of Generative Artificial Intelligence for Information Access**
2405.11612v1 by Bhaskar Mitra, Henriette Cramer, Olya Gurevich

Robust access to trustworthy information is a critical need for society with
implications for knowledge production, public health education, and promoting
informed citizenry in democratic societies. Generative AI technologies may
enable new ways to access information and improve effectiveness of existing
information retrieval systems but we are only starting to understand and
grapple with their long-term social implications. In this chapter, we present
an overview of some of the systemic consequences and risks of employing
generative AI in the context of information access. We also provide
recommendations for evaluation and mitigation, and discuss challenges for
future research.

ÊëòË¶ÅÔºöÂº∑ÂÅ•ÁöÑÁÆ°ÈÅìÂèñÂæóÂèØ‰ø°Ë≥¥ÁöÑË≥áË®äÊòØÁ§æÊúÉÁöÑÈóúÈçµÈúÄÊ±ÇÔºåÂ∞çÊñºÁü•Ë≠òÁîüÁî¢„ÄÅÂÖ¨ÂÖ±Ë°õÁîüÊïôËÇ≤Ôºå‰ª•ÂèäÂú®Ê∞ë‰∏ªÁ§æÊúÉ‰∏≠‰øÉÈÄ≤ÊúâË¶ãË≠òÁöÑÂÖ¨Ê∞ëÊÑèË≠òÂÖ∑ÊúâÂΩ±Èüø„ÄÇÁîüÊàêÂºè AI ÊäÄË°ìÂèØËÉΩÊúÉÁÇ∫ÂèñÂæóË≥áË®äÊèê‰æõÊñ∞ÊñπÊ≥ïÔºå‰∏¶ÊèêÂçáÁèæÊúâË≥áË®äÊ™¢Á¥¢Á≥ªÁµ±ÁöÑÊïàËÉΩÔºå‰ΩÜÊàëÂÄëÊâçÂâõÈñãÂßã‰∫ÜËß£‰∏¶ÊáâÂ∞çÂÖ∂Èï∑ÊúüÁöÑÁ§æÊúÉÂΩ±Èüø„ÄÇÂú®Êú¨Á´†‰∏≠ÔºåÊàëÂÄëÂ∞áÊ¶ÇËø∞Âú®Ë≥áË®äÂèñÂæóÁöÑËÑàÁµ°‰∏≠‰ΩøÁî®ÁîüÊàêÂºè AI ÁöÑ‰∏Ä‰∫õÁ≥ªÁµ±ÊÄßÂæåÊûúÂíåÈ¢®Èö™„ÄÇÊàëÂÄë‰πüÊèê‰æõË©ï‰º∞ÂíåÁ∑©Ëß£ÁöÑÂª∫Ë≠∞Ôºå‰∏¶Êé¢Ë®éÊú™‰æÜÁ†îÁ©∂ÁöÑÊåëÊà∞„ÄÇ

##### **AI-Assisted Diagnosis for Covid-19 CXR Screening: From Data Collection to Clinical Validation**
2405.11598v1 by Carlo Alberto Barbano, Riccardo Renzulli, Marco Grosso, Domenico Basile, Marco Busso, Marco Grangetto

In this paper, we present the major results from the Covid Radiographic
imaging System based on AI (Co.R.S.A.) project, which took place in Italy. This
project aims to develop a state-of-the-art AI-based system for diagnosing
Covid-19 pneumonia from Chest X-ray (CXR) images. The contributions of this
work are manyfold: the release of the public CORDA dataset, a deep learning
pipeline for Covid-19 detection, and the clinical validation of the developed
solution by expert radiologists. The proposed detection model is based on a
two-step approach that, paired with state-of-the-art debiasing, provides
reliable results. Most importantly, our investigation includes the actual usage
of the diagnosis aid tool by radiologists, allowing us to assess the real
benefits in terms of accuracy and time efficiency. Project homepage:
https://corsa.di.unito.it/

ÊëòË¶ÅÔºöÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂ∞á‰ªãÁ¥πÂú®Áæ©Â§ßÂà©ÈÄ≤Ë°åÁöÑ Covid ÊîæÂ∞ÑÂΩ±ÂÉèÁ≥ªÁµ±Âü∫Êñº AIÔºàCo.R.S.A.ÔºâË®àÁï´ÁöÑ‰∏ªË¶ÅÁµêÊûú„ÄÇÊ≠§Ë®àÁï´ÁöÑÁõÆÊ®ôÊòØÈñãÁôº‰∏ÄÂÄãÊúÄÂÖàÈÄ≤ÁöÑÂü∫Êñº AI ÁöÑÁ≥ªÁµ±ÔºåÁî®ÊñºÊ†πÊìöËÉ∏ÈÉ® X ÂÖâÔºàCXRÔºâÂΩ±ÂÉèË®∫Êñ∑ Covid-19 ËÇ∫ÁÇé„ÄÇÊ≠§Á†îÁ©∂ÁöÑË≤¢ÁçªÂåÖÊã¨ÔºöÈáãÂá∫ÂÖ¨ÈñãÁöÑ CORDA Ë≥áÊñôÈõÜ„ÄÅ‰∏ÄÂÄãÁî®ÊñºÂÅµÊ∏¨ Covid-19 ÁöÑÊ∑±Â∫¶Â≠∏ÁøíÁÆ°ÈÅìÔºå‰ª•ÂèäÁî±ÊîæÂ∞ÑÁßëÂ∞àÂÆ∂Â∞çÈñãÁôºÁöÑËß£Ê±∫ÊñπÊ°àÈÄ≤Ë°åËá®Â∫äÈ©óË≠â„ÄÇÊâÄÊèêÂá∫ÁöÑÂÅµÊ∏¨Ê®°ÂûãÂü∫Êñº‰∏ÄÂÄãÂÖ©Ê≠•È©üÊñπÊ≥ïÔºåÊê≠ÈÖçÊúÄÂÖàÈÄ≤ÁöÑÂéªÂÅèÔºåÊèê‰æõÂèØÈù†ÁöÑÁµêÊûú„ÄÇÊúÄÈáçË¶ÅÁöÑÊòØÔºåÊàëÂÄëÁöÑË™øÊü•ÂåÖÊã¨ÊîæÂ∞ÑÁßëÈÜ´Â∏´ÂØ¶Èöõ‰ΩøÁî®Ë®∫Êñ∑ËºîÂä©Â∑•ÂÖ∑ÔºåËÆìÊàëÂÄëËÉΩÂ§†Ë©ï‰º∞Âú®Ê∫ñÁ¢∫ÊÄßÂíåÊôÇÈñìÊïàÁéáÊñπÈù¢ÁöÑÂØ¶ÈöõÊïàÁõä„ÄÇË®àÁï´È¶ñÈ†ÅÔºöhttps://corsa.di.unito.it/

##### **EyeFound: A Multimodal Generalist Foundation Model for Ophthalmic Imaging**
2405.11338v2 by Danli Shi, Weiyi Zhang, Xiaolan Chen, Yexin Liu, Jiancheng Yang, Siyu Huang, Yih Chung Tham, Yingfeng Zheng, Mingguang He

Artificial intelligence (AI) is vital in ophthalmology, tackling tasks like
diagnosis, classification, and visual question answering (VQA). However,
existing AI models in this domain often require extensive annotation and are
task-specific, limiting their clinical utility. While recent developments have
brought about foundation models for ophthalmology, they are limited by the need
to train separate weights for each imaging modality, preventing a comprehensive
representation of multi-modal features. This highlights the need for versatile
foundation models capable of handling various tasks and modalities in
ophthalmology. To address this gap, we present EyeFound, a multimodal
foundation model for ophthalmic images. Unlike existing models, EyeFound learns
generalizable representations from unlabeled multimodal retinal images,
enabling efficient model adaptation across multiple applications. Trained on
2.78 million images from 227 hospitals across 11 ophthalmic modalities,
EyeFound facilitates generalist representations and diverse multimodal
downstream tasks, even for detecting challenging rare diseases. It outperforms
previous work RETFound in diagnosing eye diseases, predicting systemic disease
incidents, and zero-shot multimodal VQA. EyeFound provides a generalizable
solution to improve model performance and lessen the annotation burden on
experts, facilitating widespread clinical AI applications for retinal imaging.

ÊëòË¶ÅÔºö‰∫∫Â∑•Êô∫ÊÖß (AI) Âú®ÁúºÁßë‰∏≠Ëá≥ÈóúÈáçË¶ÅÔºåÂèØËôïÁêÜË®∫Êñ∑„ÄÅÂàÜÈ°ûÂíåË¶ñË¶∫ÂïèÁ≠î (VQA) Á≠â‰ªªÂãô„ÄÇÁÑ∂ËÄåÔºåÊ≠§È†òÂüüÁèæÊúâÁöÑ AI Ê®°ÂûãÈÄöÂ∏∏ÈúÄË¶ÅÂª£Ê≥õÁöÑË®ªËß£ÔºåËÄå‰∏îÁâπÂÆöÊñº‰ªªÂãôÔºåÈÄôÈôêÂà∂‰∫ÜÂÆÉÂÄëÁöÑËá®Â∫äÊïàÁî®„ÄÇÂÑòÁÆ°ÊúÄËøëÁöÑÁôºÂ±ïÁÇ∫ÁúºÁßëÂ∏∂‰æÜ‰∫ÜÂü∫Á§éÊ®°ÂûãÔºå‰ΩÜÂÆÉÂÄëÂèóÂà∞Ë®ìÁ∑¥ÈúÄË¶ÅÁÇ∫ÊØèÂÄãÂΩ±ÂÉèÊ®°ÂºèË®ìÁ∑¥Áç®Á´ãÊ¨äÈáçÁöÑÈôêÂà∂ÔºåÈÄôÈòªÁ§ô‰∫ÜÂ§öÊ®°ÂºèÁâπÂæµÁöÑÂÖ®Èù¢Ë°®Á§∫„ÄÇÈÄôÁ™ÅÈ°Ø‰∫ÜÈúÄË¶ÅËÉΩÂ§†ËôïÁêÜÁúºÁßë‰∏≠ÂêÑÁ®Æ‰ªªÂãôÂíåÊ®°ÂºèÁöÑÂ§öÂäüËÉΩÂü∫Á§éÊ®°Âûã„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂ∑ÆË∑ùÔºåÊàëÂÄëÊèêÂá∫‰∫Ü EyeFoundÔºå‰∏ÄÂÄãÁî®ÊñºÁúºÁßëÂΩ±ÂÉèÁöÑÂ§öÊ®°ÂºèÂü∫Á§éÊ®°Âûã„ÄÇËàáÁèæÊúâÊ®°Âûã‰∏çÂêåÔºåEyeFound ÂæûÊú™Ê®ôË®òÁöÑÂ§öÊ®°ÂºèË¶ñÁ∂≤ËÜúÂΩ±ÂÉè‰∏≠Â≠∏ÁøíÂèØÊ¶ÇÊã¨ÁöÑË°®Á§∫ÔºåÂæûËÄåËÉΩÂ§†Âú®Â§öÂÄãÊáâÁî®Á®ãÂºè‰∏≠ÊúâÊïàÂú∞Ë™øÊï¥Ê®°Âûã„ÄÇEyeFound Êé•Âèó‰∫Ü‰æÜËá™ 11 Á®ÆÁúºÁßëÊ®°ÂºèÁöÑ 227 ÂÆ∂ÈÜ´Èô¢ÁöÑ 278 Ëê¨ÂºµÂΩ±ÂÉèË®ìÁ∑¥ÔºåÂç≥‰ΩøÂú®ÂÅµÊ∏¨ÂÖ∑ÊúâÊåëÊà∞ÊÄßÁöÑÁΩïË¶ãÁñæÁóÖÊôÇÔºåÂÆÉ‰πüËÉΩ‰øÉÈÄ≤ÈÄöÊâçË°®Á§∫ÂíåÂ§öÊ®£ÂåñÁöÑÂ§öÊ®°Âºè‰∏ãÊ∏∏‰ªªÂãô„ÄÇÂÆÉÂú®Ë®∫Êñ∑ÁúºÁñæ„ÄÅÈ†êÊ∏¨ÂÖ®Ë∫´ÊÄßÁñæÁóÖ‰∫ã‰ª∂ÂíåÈõ∂Ê¨°Â≠∏ÁøíÂ§öÊ®°Âºè VQA ÊñπÈù¢ÂÑ™ÊñºÂÖàÂâçÁöÑ RETFound„ÄÇEyeFound Êèê‰æõ‰∫Ü‰∏ÄÂÄãÂèØÊ¶ÇÊã¨ÁöÑËß£Ê±∫ÊñπÊ°àÔºå‰ª•ÊîπÂñÑÊ®°ÂûãÊïàËÉΩ‰∏¶Ê∏õËºïÂ∞àÂÆ∂ÁöÑË®ªËß£Ë≤†ÊìîÔºå‰øÉÈÄ≤Âª£Ê≥õÁöÑËá®Â∫ä AI ÊáâÁî®ÊñºË¶ñÁ∂≤ËÜúÂΩ±ÂÉè„ÄÇ

##### **Towards Knowledge-Infused Automated Disease Diagnosis Assistant**
2405.11181v1 by Mohit Tomar, Abhisek Tiwari, Sriparna Saha

With the advancement of internet communication and telemedicine, people are
increasingly turning to the web for various healthcare activities. With an
ever-increasing number of diseases and symptoms, diagnosing patients becomes
challenging. In this work, we build a diagnosis assistant to assist doctors,
which identifies diseases based on patient-doctor interaction. During
diagnosis, doctors utilize both symptomatology knowledge and diagnostic
experience to identify diseases accurately and efficiently. Inspired by this,
we investigate the role of medical knowledge in disease diagnosis through
doctor-patient interaction. We propose a two-channel, knowledge-infused,
discourse-aware disease diagnosis model (KI-DDI), where the first channel
encodes patient-doctor communication using a transformer-based encoder, while
the other creates an embedding of symptom-disease using a graph attention
network (GAT). In the next stage, the conversation and knowledge graph
embeddings are infused together and fed to a deep neural network for disease
identification. Furthermore, we first develop an empathetic conversational
medical corpus comprising conversations between patients and doctors, annotated
with intent and symptoms information. The proposed model demonstrates a
significant improvement over the existing state-of-the-art models, establishing
the crucial roles of (a) a doctor's effort for additional symptom extraction
(in addition to patient self-report) and (b) infusing medical knowledge in
identifying diseases effectively. Many times, patients also show their medical
conditions, which acts as crucial evidence in diagnosis. Therefore, integrating
visual sensory information would represent an effective avenue for enhancing
the capabilities of diagnostic assistants.

ÊëòË¶ÅÔºöÈö®ËëóÁ∂≤Ë∑ØÈÄöË®äÂíåÈÅ†Ë∑ùÈÜ´ÁôÇÁöÑÈÄ≤Ê≠•Ôºå‰∫∫ÂÄëË∂ä‰æÜË∂ä‰æùË≥¥Á∂≤Ë∑ØÈÄ≤Ë°åÂêÑÁ®ÆÈÜ´ÁôÇ‰øùÂÅ•Ê¥ªÂãï„ÄÇÈö®ËëóÁñæÁóÖÂíåÁóáÁãÄÁöÑÊï∏Èáè‰∏çÊñ∑Â¢ûÂä†ÔºåË®∫Êñ∑ÊÇ£ËÄÖËÆäÂæóÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÂª∫Á´ã‰∫Ü‰∏ÄÂÄãË®∫Êñ∑Âä©ÁêÜ‰æÜÂçîÂä©ÈÜ´ÁîüÔºåÊ†πÊìöÊÇ£ËÄÖËàáÈÜ´ÁîüÁöÑ‰∫íÂãï‰æÜË≠òÂà•ÁñæÁóÖ„ÄÇÂú®Ë®∫Êñ∑ÈÅéÁ®ã‰∏≠ÔºåÈÜ´ÁîüÂêåÊôÇÂà©Áî®ÁóáÁãÄÂ≠∏Áü•Ë≠òÂíåË®∫Êñ∑Á∂ìÈ©ó‰æÜÊ∫ñÁ¢∫ÊúâÊïàÂú∞Ë≠òÂà•ÁñæÁóÖ„ÄÇÂèóÂà∞Ê≠§ÂïüÁôºÔºåÊàëÂÄëÈÄèÈÅéÈÜ´ÁîüËàáÊÇ£ËÄÖÁöÑ‰∫íÂãï‰æÜÊé¢Ë®éÈÜ´Â≠∏Áü•Ë≠òÂú®ÁñæÁóÖË®∫Êñ∑‰∏≠ÁöÑ‰ΩúÁî®„ÄÇÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÈõôÈÄöÈÅì„ÄÅÁü•Ë≠òÊ≥®ÂÖ•„ÄÅÂ∞çË©±ÊÑüÁü•ÁñæÁóÖË®∫Êñ∑Ê®°Âûã (KI-DDI)ÔºåÂÖ∂‰∏≠Á¨¨‰∏ÄÂÄãÈÄöÈÅì‰ΩøÁî®Âü∫ÊñºËΩâÊèõÂô®ÁöÑÁ∑®Á¢ºÂô®Â∞çÊÇ£ËÄÖËàáÈÜ´ÁîüÁöÑÊ∫ùÈÄöÈÄ≤Ë°åÁ∑®Á¢ºÔºåËÄåÂè¶‰∏ÄÂÄãÈÄöÈÅì‰ΩøÁî®ÂúñÊ≥®ÊÑèÂäõÁ∂≤Ë∑Ø (GAT) Âª∫Á´ãÁóáÁãÄÁñæÁóÖÁöÑÂµåÂÖ•„ÄÇÂú®‰∏ã‰∏ÄÈöéÊÆµÔºåÂ∞çË©±ÂíåÁü•Ë≠òÂúñÂµåÂÖ•Ë¢´Ê≥®ÂÖ•Âú®‰∏ÄËµ∑Ôºå‰∏¶Ëº∏ÂÖ•Ê∑±Â∫¶Á•ûÁ∂ìÁ∂≤Ë∑ØÈÄ≤Ë°åÁñæÁóÖË≠òÂà•„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÈ¶ñÂÖàÈñãÁôº‰∫Ü‰∏ÄÂÄãÂêåÁêÜÂøÉÂ∞çË©±ÂºèÈÜ´Â≠∏Ë™ûÊñôÂ∫´ÔºåÂÖ∂‰∏≠ÂåÖÂê´ÊÇ£ËÄÖÂíåÈÜ´Áîü‰πãÈñìÁöÑÂ∞çË©±Ôºå‰∏¶Ë®ªËß£‰∫ÜÊÑèÂúñÂíåÁóáÁãÄË≥áË®ä„ÄÇÊâÄÊèêÂá∫ÁöÑÊ®°ÂûãÂ±ïÁ§∫‰∫ÜÂ∞çÁèæÊúâÊúÄÂÖàÈÄ≤Ê®°ÂûãÁöÑÈ°ØËëóÊîπÈÄ≤ÔºåÁ¢∫Á´ã‰∫Ü (a) ÈÜ´ÁîüÁÇ∫È°çÂ§ñÁóáÁãÄÊèêÂèñÔºàÈô§‰∫ÜÊÇ£ËÄÖËá™ÊàëÂ†±Âëä‰πãÂ§ñÔºâÊâÄÂÅöÁöÑÂä™Âäõ‰ª•Âèä (b) Ê≥®ÂÖ•ÈÜ´Â≠∏Áü•Ë≠ò‰ª•ÊúâÊïàË≠òÂà•ÁñæÁóÖÁöÑÈóúÈçµ‰ΩúÁî®„ÄÇÂæàÂ§öÊôÇÂÄôÔºåÊÇ£ËÄÖÈÇÑÊúÉÂ±ïÁ§∫‰ªñÂÄëÁöÑÈÜ´ÁôÇÁãÄÊ≥ÅÔºåÈÄôÂú®Ë®∫Êñ∑‰∏≠ÊâÆÊºîËëóËá≥ÈóúÈáçË¶ÅÁöÑË≠âÊìö„ÄÇÂõ†Ê≠§ÔºåÊï¥ÂêàË¶ñË¶∫ÊÑüÂÆòË≥áË®äÂ∞á‰ª£Ë°®‰∏ÄÁ®ÆÂ¢ûÂº∑Ë®∫Êñ∑Âä©ÁêÜËÉΩÂäõÁöÑÊúâÊïàÈÄîÂæë„ÄÇ

##### **Multi-scale Information Sharing and Selection Network with Boundary Attention for Polyp Segmentation**
2405.11151v1 by Xiaolu Kang, Zhuoqi Ma, Kang Liu, Yunan Li, Qiguang Miao

Polyp segmentation for colonoscopy images is of vital importance in clinical
practice. It can provide valuable information for colorectal cancer diagnosis
and surgery. While existing methods have achieved relatively good performance,
polyp segmentation still faces the following challenges: (1) Varying lighting
conditions in colonoscopy and differences in polyp locations, sizes, and
morphologies. (2) The indistinct boundary between polyps and surrounding
tissue. To address these challenges, we propose a Multi-scale information
sharing and selection network (MISNet) for polyp segmentation task. We design a
Selectively Shared Fusion Module (SSFM) to enforce information sharing and
active selection between low-level and high-level features, thereby enhancing
model's ability to capture comprehensive information. We then design a Parallel
Attention Module (PAM) to enhance model's attention to boundaries, and a
Balancing Weight Module (BWM) to facilitate the continuous refinement of
boundary segmentation in the bottom-up process. Experiments on five polyp
segmentation datasets demonstrate that MISNet successfully improved the
accuracy and clarity of segmentation result, outperforming state-of-the-art
methods.

ÊëòË¶ÅÔºöÂ§ßËÖ∏Èè°Ê™¢Êü•ÂΩ±ÂÉè‰∏≠ÁöÑÊÅØËÇâÂàÜÂâ≤Âú®Ëá®Â∫äÂØ¶Âãô‰∏äËá≥ÈóúÈáçË¶Å„ÄÇÂÆÉÂèØ‰ª•Êèê‰æõÊúâÂÉπÂÄºÁöÑË≥áË®äÁî®ÊñºÂ§ßËÖ∏ÁôåÁöÑË®∫Êñ∑ÂíåÊâãË°ì„ÄÇÂÑòÁÆ°ÁèæÊúâÊñπÊ≥ïÂ∑≤ÂèñÂæóÁõ∏Â∞çËâØÂ•ΩÁöÑÊïàËÉΩÔºåÊÅØËÇâÂàÜÂâ≤‰ªçÈù¢Ëá®‰ª•‰∏ãÊåëÊà∞Ôºö(1) Â§ßËÖ∏Èè°Ê™¢Êü•‰∏≠‰∏çÂêåÁöÑÁÖßÊòéÊ¢ù‰ª∂Ôºå‰ª•ÂèäÊÅØËÇâ‰ΩçÁΩÆ„ÄÅÂ§ßÂ∞èÂíåÂΩ¢ÊÖãÁöÑÂ∑ÆÁï∞„ÄÇ(2) ÊÅØËÇâËàáÂë®ÂúçÁµÑÁπî‰πãÈñìÊ®°Á≥äÁöÑÈÇäÁïå„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÁî®ÊñºÊÅØËÇâÂàÜÂâ≤‰ªªÂãôÁöÑÂ§öÂ∞∫Â∫¶Ë≥áË®äÂÖ±‰∫´ÂíåÈÅ∏ÊìáÁ∂≤Ë∑Ø (MISNet)„ÄÇÊàëÂÄëË®≠Ë®à‰∫Ü‰∏ÄÂÄãÈÅ∏ÊìáÊÄßÂÖ±‰∫´ËûçÂêàÊ®°ÁµÑ (SSFM) ‰æÜÂº∑Âà∂Âü∑Ë°å‰ΩéÈöéÂíåÈ´òÈöéÁâπÂæµ‰πãÈñìÁöÑË≥áË®äÂÖ±‰∫´Âíå‰∏ªÂãïÈÅ∏ÊìáÔºåÂæûËÄåÂ¢ûÂº∑Ê®°ÂûãÊì∑ÂèñÂÖ®Èù¢Ë≥áË®äÁöÑËÉΩÂäõ„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëË®≠Ë®à‰∫Ü‰∏ÄÂÄãÂπ≥Ë°åÊ≥®ÊÑèÂäõÊ®°ÁµÑ (PAM) ‰æÜÂ¢ûÂº∑Ê®°ÂûãÂ∞çÈÇäÁïåÁöÑÊ≥®ÊÑèÂäõÔºå‰ª•Âèä‰∏ÄÂÄãÂπ≥Ë°°Ê¨äÈáçÊ®°ÁµÑ (BWM) ‰æÜ‰øÉÈÄ≤Ëá™‰∏ãËÄå‰∏äÁöÑÈÅéÁ®ã‰∏≠ÈÇäÁïåÂàÜÂâ≤ÁöÑÊåÅÁ∫åÁ≤æÁÖâ„ÄÇÂú®‰∫îÂÄãÊÅØËÇâÂàÜÂâ≤Ë≥áÊñôÈõÜ‰∏äÁöÑÂØ¶È©óË≠âÊòéÔºåMISNet ÊàêÂäüÂú∞ÊîπÂñÑ‰∫ÜÂàÜÂâ≤ÁµêÊûúÁöÑÊ∫ñÁ¢∫ÊÄßÂíåÊ∏ÖÊô∞Â∫¶ÔºåÂÑ™ÊñºÁèæÊúâÊäÄË°ì„ÄÇ

##### **Generative Artificial Intelligence: A Systematic Review and Applications**
2405.11029v1 by Sandeep Singh Sengar, Affan Bin Hasan, Sanjay Kumar, Fiona Carroll

In recent years, the study of artificial intelligence (AI) has undergone a
paradigm shift. This has been propelled by the groundbreaking capabilities of
generative models both in supervised and unsupervised learning scenarios.
Generative AI has shown state-of-the-art performance in solving perplexing
real-world conundrums in fields such as image translation, medical diagnostics,
textual imagery fusion, natural language processing, and beyond. This paper
documents the systematic review and analysis of recent advancements and
techniques in Generative AI with a detailed discussion of their applications
including application-specific models. Indeed, the major impact that generative
AI has made to date, has been in language generation with the development of
large language models, in the field of image translation and several other
interdisciplinary applications of generative AI. Moreover, the primary
contribution of this paper lies in its coherent synthesis of the latest
advancements in these areas, seamlessly weaving together contemporary
breakthroughs in the field. Particularly, how it shares an exploration of the
future trajectory for generative AI. In conclusion, the paper ends with a
discussion of Responsible AI principles, and the necessary ethical
considerations for the sustainability and growth of these generative models.

ÊëòË¶ÅÔºöËøëÂπ¥‰æÜÔºå‰∫∫Â∑•Êô∫ÊÖß (AI) ÁöÑÁ†îÁ©∂Á∂ìÊ≠∑‰∫Ü‰∏ÄÂ†¥ÂÖ∏ÁØÑËΩâÁßª„ÄÇÈÄôÈ†ÖËΩâËÆäÊòØÁî±ÊñºÁîüÊàêÂºèÊ®°ÂûãÂú®Áõ£Áù£ÂºèÂíåÈùûÁõ£Áù£ÂºèÂ≠∏ÁøíÂ†¥ÊôØ‰∏≠ÂÖ∑ÊúâÁ™ÅÁ†¥ÊÄßÁöÑËÉΩÂäõÊâÄÊé®ÂãïÁöÑ„ÄÇÁîüÊàêÂºè AI Â∑≤Â±ïÁèæÂá∫ÊúÄÂÖàÈÄ≤ÁöÑÊïàËÉΩÔºåÁî®‰ª•Ëß£Ê±∫ÂΩ±ÂÉèÁøªË≠Ø„ÄÅÈÜ´ÁôÇË®∫Êñ∑„ÄÅÊñáÂ≠óÊÑèË±°ËûçÂêà„ÄÅËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜÁ≠âÈ†òÂüü‰∏≠‰ª§‰∫∫Ë≤ªËß£ÁöÑÁúüÂØ¶‰∏ñÁïåÈõ£È°åÔºåËÄå‰∏î‰∏çÂè™ÊñºÊ≠§„ÄÇÊú¨ÊñáË®òÈåÑ‰∫ÜÂ∞çÁîüÊàêÂºè AI ËøëÊúüÈÄ≤Â±ïÂíåÊäÄË°ìÁöÑÁ≥ªÁµ±ÊÄßÂõûÈ°ßÂíåÂàÜÊûêÔºå‰∏¶Ë©≥Á¥∞Ë®éË´ñ‰∫ÜÂÆÉÂÄëÁöÑÊáâÁî®ÔºåÂåÖÊã¨ÁâπÂÆöÊáâÁî®Á®ãÂºèÁöÑÊ®°Âûã„ÄÇÁöÑÁ¢∫ÔºåÂà∞ÁõÆÂâçÁÇ∫Ê≠¢ÔºåÁîüÊàêÂºè AI ÊâÄÁî¢ÁîüÁöÑÈáçÂ§ßÂΩ±ÈüøÂú®ÊñºË™ûË®ÄÁîüÊàêÔºåÁâπÂà•ÊòØÂ§ßË™ûË®ÄÊ®°ÂûãÁöÑÁôºÂ±ï„ÄÅÂΩ±ÂÉèÁøªË≠ØÈ†òÂüü‰ª•ÂèäÁîüÊàêÂºè AI ÁöÑÂÖ∂‰ªñÂπæÂÄãË∑®È†òÂüüÊáâÁî®„ÄÇÊ≠§Â§ñÔºåÊú¨ÊñáÁöÑ‰∏ªË¶ÅË≤¢ÁçªÂú®ÊñºÂ∞çÈÄô‰∫õÈ†òÂüüÁöÑÊúÄÊñ∞ÈÄ≤Â±ïÈÄ≤Ë°åÈÄ£Ë≤´ÁöÑÁ∂úÂêàÔºåÂ∞áË©≤È†òÂüüÁöÑÁï∂‰ª£Á™ÅÁ†¥ÁÑ°Á∏´Âú∞‰∫§ÁπîÂú®‰∏ÄËµ∑„ÄÇÁâπÂà•ÊòØÔºåÂÆÉÂàÜ‰∫´‰∫ÜÂ∞çÁîüÊàêÂºè AI Êú™‰æÜËªåË∑°ÁöÑÊé¢Ë®é„ÄÇÊúÄÂæåÔºåÊú¨Êñá‰ª•Â∞çË≤†Ë≤¨‰ªª AI ÂéüÂâáÁöÑË®éË´ñÔºå‰ª•ÂèäÂ∞çÈÄô‰∫õÁîüÊàêÂºèÊ®°ÂûãÁöÑÂèØÊåÅÁ∫åÊÄßÂíåÊàêÈï∑ÁöÑÂøÖË¶ÅÂÄ´ÁêÜËÄÉÈáè‰ΩúÁÇ∫ÁµêÂ∞æ„ÄÇ

##### **COGNET-MD, an evaluation framework and dataset for Large Language Model benchmarks in the medical domain**
2405.10893v1 by Dimitrios P. Panagoulias, Persephone Papatheodosiou, Anastasios P. Palamidas, Mattheos Sanoudos, Evridiki Tsoureli-Nikita, Maria Virvou, George A. Tsihrintzis

Large Language Models (LLMs) constitute a breakthrough state-of-the-art
Artificial Intelligence (AI) technology which is rapidly evolving and promises
to aid in medical diagnosis either by assisting doctors or by simulating a
doctor's workflow in more advanced and complex implementations. In this
technical paper, we outline Cognitive Network Evaluation Toolkit for Medical
Domains (COGNET-MD), which constitutes a novel benchmark for LLM evaluation in
the medical domain. Specifically, we propose a scoring-framework with increased
difficulty to assess the ability of LLMs in interpreting medical text. The
proposed framework is accompanied with a database of Multiple Choice Quizzes
(MCQs). To ensure alignment with current medical trends and enhance safety,
usefulness, and applicability, these MCQs have been constructed in
collaboration with several associated medical experts in various medical
domains and are characterized by varying degrees of difficulty. The current
(first) version of the database includes the medical domains of Psychiatry,
Dentistry, Pulmonology, Dermatology and Endocrinology, but it will be
continuously extended and expanded to include additional medical domains.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÊßãÊàê‰∫Ü‰∏ÄÈ†ÖÁ™ÅÁ†¥ÊÄßÁöÑÂ∞ñÁ´Ø‰∫∫Â∑•Êô∫ËÉΩ (AI) ÊäÄË°ìÔºåÂÆÉÊ≠£Âú®ËøÖÈÄüÁôºÂ±ïÔºå‰∏¶ÊâøË´æÈÄöÈÅéÂçîÂä©ÈÜ´ÁîüÊàñÂú®Êõ¥ÂÖàÈÄ≤ÂíåË§áÈõúÁöÑÂØ¶ÊñΩ‰∏≠Ê®°Êì¨ÈÜ´ÁîüÁöÑÂ∑•‰ΩúÊµÅÁ®ã‰æÜÂπ´Âä©ÈÄ≤Ë°åÈÜ´ÁôÇË®∫Êñ∑„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊ¶ÇËø∞‰∫ÜÈÜ´ÁôÇÈ†òÂüüÁöÑË™çÁü•Á∂≤Ë∑ØË©ï‰º∞Â∑•ÂÖ∑ÂåÖ (COGNET-MD)ÔºåÂÆÉÊßãÊàê‰∫Ü‰∏ÄÂÄã LLM Ë©ï‰º∞Âú®ÈÜ´ÁôÇÈ†òÂüüÁöÑÊñ∞Âü∫Ê∫ñ„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãË©ïÂàÜÊ°ÜÊû∂ÔºåÈõ£Â∫¶Â¢ûÂä†Ôºå‰ª•Ë©ï‰º∞ LLM Ëß£ÈáãÈÜ´ÁôÇÊñáÊú¨ÁöÑËÉΩÂäõ„ÄÇÊâÄÊèêÂá∫ÁöÑÊ°ÜÊû∂ÈôÑÂ∏∂‰∫Ü‰∏ÄÂÄãÂ§öÈÅ∏È°åÊ∏¨È©ó (MCQ) Ë≥áÊñôÂ∫´„ÄÇÁÇ∫‰∫ÜÁ¢∫‰øùËàáÁï∂ÂâçÈÜ´ÁôÇË∂®Âã¢‰øùÊåÅ‰∏ÄËá¥‰∏¶Â¢ûÂº∑ÂÆâÂÖ®ÊÄß„ÄÅÂØ¶Áî®ÊÄßÂíåÈÅ©Áî®ÊÄßÔºåÈÄô‰∫õ MCQ Â∑≤ËàáÂ§öÂÄãÁõ∏ÈóúÈÜ´ÁôÇÈ†òÂüüÁöÑÂπæ‰ΩçÈÜ´ÁôÇÂ∞àÂÆ∂Âêà‰ΩúÊßãÂª∫Ôºå‰∏¶‰∏îÈõ£Â∫¶ÂêÑ‰∏çÁõ∏Âêå„ÄÇË≥áÊñôÂ∫´ÁöÑÁï∂ÂâçÔºàÁ¨¨‰∏ÄÔºâÁâàÊú¨ÂåÖÊã¨Á≤æÁ•ûÁóÖÂ≠∏„ÄÅÁâôÁßë„ÄÅËÇ∫ÁßëÂ≠∏„ÄÅÁöÆËÜöÁóÖÂ≠∏ÂíåÂÖßÂàÜÊ≥åÂ≠∏ÁöÑÈÜ´ÁôÇÈ†òÂüüÔºå‰ΩÜÂÆÉÂ∞á‰∏çÊñ∑Êì¥ÂÖÖÂíåÊì¥Â±ï‰ª•ÂåÖÊã¨ÂÖ∂‰ªñÈÜ´ÁôÇÈ†òÂüü„ÄÇ

##### **Application of Artificial Intelligence in Schizophrenia Rehabilitation Management: Systematic Literature Review**
2405.10883v1 by Hongyi Yang, Fangyuan Chang, Dian Zhu, Muroi Fumie, Zhao Liu

This review aims to systematically assess the current status and prospects of
artificial intelligence (AI) in the rehabilitation management of patients with
schizophrenia and their impact on the rehabilitation process. We selected 70
studies from 2012 to the present, focusing on application, technology
categories, products, and data types of machine learning, deep learning,
reinforcement learning, and other technologies in mental health interventions
and management. The results indicate that AI can be widely used in symptom
monitoring, relapse risk prediction, and rehabilitation treatment by analyzing
ecological momentary assessment, behavioral, and speech data. This review
further explores the potential challenges and future directions of emerging
products, technologies, and analytical methods based on AI, such as social
media analysis, serious games, and large language models in rehabilitation. In
summary, this study systematically reviews the application status of AI in
schizophrenia rehabilitation management and provides valuable insights and
recommendations for future research paths.

ÊëòË¶ÅÔºöÊú¨Á∂úËø∞Êó®Âú®Á≥ªÁµ±ÊÄßË©ï‰º∞‰∫∫Â∑•Êô∫ÊÖß (AI) Âú®Á≤æÁ•ûÂàÜË£ÇÁóáÊÇ£ËÄÖÂæ©ÂÅ•ÁÆ°ÁêÜ‰∏≠ÁöÑÁèæÊ≥ÅËàáÂâçÊôØÔºå‰ª•ÂèäÂÖ∂Â∞çÂæ©ÂÅ•Ê≠∑Á®ãÁöÑÂΩ±Èüø„ÄÇÊàëÂÄëÂæû 2012 Âπ¥Ëá≥‰ªäÈÅ∏Âèñ‰∫Ü 70 ÁØáÁ†îÁ©∂ÔºåÈáçÈªûÈóúÊ≥®Ê©üÂô®Â≠∏Áøí„ÄÅÊ∑±Â∫¶Â≠∏Áøí„ÄÅÂº∑ÂåñÂ≠∏ÁøíÂíåÂÖ∂‰ªñÊäÄË°ìÂú®ÂøÉÁêÜÂÅ•Â∫∑‰ªãÂÖ•ÂíåÁÆ°ÁêÜ‰∏≠ÁöÑÊáâÁî®„ÄÅÊäÄË°ìÈ°ûÂà•„ÄÅÁî¢ÂìÅÂíåË≥áÊñôÈ°ûÂûã„ÄÇÁµêÊûúÈ°ØÁ§∫ÔºåAI ÂèØÂª£Ê≥õÊáâÁî®ÊñºÁóáÁãÄÁõ£Êéß„ÄÅÂæ©ÁôºÈ¢®Èö™È†êÊ∏¨ÂíåÂæ©ÂÅ•Ê≤ªÁôÇÔºåÊñπÊ≥ïÊòØÂàÜÊûêÁîüÊÖãÁû¨ÊôÇË©ï‰º∞„ÄÅË°åÁÇ∫ÂíåË®ÄË™ûË≥áÊñô„ÄÇÊú¨Á∂úËø∞ÈÄ≤‰∏ÄÊ≠•Êé¢Ë®é‰∫ÜÂü∫Êñº AI ÁöÑÊñ∞ËààÁî¢ÂìÅ„ÄÅÊäÄË°ìÂíåÂàÜÊûêÊñπÊ≥ïÁöÑÊΩõÂú®ÊåëÊà∞ÂíåÊú™‰æÜÊñπÂêëÔºå‰æãÂ¶ÇÂæ©ÂÅ•‰∏≠ÁöÑÁ§æÁæ§Â™íÈ´îÂàÜÊûê„ÄÅÂö¥ËÇÖÈÅäÊà≤ÂíåÂ§ßË™ûË®ÄÊ®°Âûã„ÄÇÁ∏Ω‰πãÔºåÊú¨Á†îÁ©∂Á≥ªÁµ±ÊÄßÂú∞ÂõûÈ°ß‰∫Ü AI Âú®Á≤æÁ•ûÂàÜË£ÇÁóáÂæ©ÂÅ•ÁÆ°ÁêÜ‰∏≠ÁöÑÊáâÁî®ÁèæÊ≥ÅÔºå‰∏¶ÁÇ∫Êú™‰æÜÁöÑÁ†îÁ©∂Ë∑ØÂæëÊèê‰æõ‰∫ÜÊúâÂÉπÂÄºÁöÑË¶ãËß£ÂíåÂª∫Ë≠∞„ÄÇ

##### **Causality in the Can: Diet Coke's Impact on Fatness**
2405.10746v1 by Yicheng Qi, Ang Li

Artificially sweetened beverages like Diet Coke are often considered
healthier alternatives, but the debate over their impact on obesity persists.
Previous research has predominantly relied on observational data or randomized
controlled trials (RCTs), which may not accurately capture the causal
relationship between Diet Coke consumption and obesity. This study uses causal
inference methods, employing data from the National Health and Nutrition
Examination Survey (NHANES) to examine this relationship across diverse
demographics. Instead of relying on RCT data, we constructed a causal graph and
applied the back-door criterion with its adjustment formula to estimate the RCT
distributions. We then calculated the counterfactual quantity, the Probability
of Necessity and Sufficiency (PNS), using both NHANES data and estimated RCT
data. We propose that PNS is the essential metric for assessing the impact of
Diet Coke on obesity. Our results indicate that between 20% to 50% of
individuals, especially those with poor dietary habits, are more likely to gain
weight from Diet Coke. Conversely, in groups like young females with healthier
diets, only a small proportion experience weight gain due to Diet Coke. These
findings highlight the influence of individual lifestyle and potential hormonal
factors on the varied effects of Diet Coke, providing a new framework for
understanding its nutritional impacts on health.

ÊëòË¶ÅÔºö‰∫∫Â∑•Âä†Á≥ñÈ£≤ÊñôÔºàÂ¶ÇÂÅ•ÊÄ°ÂèØÊ®ÇÔºâÈÄöÂ∏∏Ë¢´Ë™çÁÇ∫ÊòØÊõ¥ÂÅ•Â∫∑ÁöÑÈÅ∏ÊìáÔºå‰ΩÜÂ∞çÊñºÂÆÉÂÄëÂ∞çËÇ•ËÉñÁöÑÂΩ±ÈüøÁöÑÁà≠Ë´ñ‰ªçÊåÅÁ∫åËëó„ÄÇÂÖàÂâçÁöÑÁ†îÁ©∂‰∏ªË¶Å‰æùË≥¥ÊñºËßÄÂØüÊï∏ÊìöÊàñÈö®Ê©üÂ∞çÁÖßË©¶È©ó (RCT)ÔºåÈÄôÂèØËÉΩÁÑ°Ê≥ïÊ∫ñÁ¢∫ÊçïÊçâÂÅ•ÊÄ°ÂèØÊ®ÇÊîùÂèñËàáËÇ•ËÉñ‰πãÈñìÁöÑÂõ†ÊûúÈóú‰øÇ„ÄÇÊú¨Á†îÁ©∂‰ΩøÁî®Âõ†ÊûúÊé®Ë´ñÊñπÊ≥ïÔºåÊé°Áî®ÂúãÂÆ∂ÂÅ•Â∫∑ËàáÁáüÈ§äÊ™¢Êü•Ë™øÊü• (NHANES) ÁöÑÊï∏Êìö‰æÜÊ™¢È©ó‰∏çÂêå‰∫∫Âè£Áµ±Ë®àË≥áÊñô‰∏≠ÁöÑÈÄôÁ®ÆÈóú‰øÇ„ÄÇÊàëÂÄëÊ≤íÊúâ‰æùË≥¥ RCT Êï∏ÊìöÔºåËÄåÊòØÂª∫Êßã‰∫Ü‰∏ÄÂÄãÂõ†ÊûúÂúñÔºå‰∏¶ÊáâÁî®ÂæåÈñÄÊ∫ñÂâáÂèäÂÖ∂Ë™øÊï¥ÂÖ¨Âºè‰æÜ‰º∞Ë®à RCT ÂàÜÈÖç„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄë‰ΩøÁî® NHANES Êï∏ÊìöÂíå‰º∞Ë®àÁöÑ RCT Êï∏ÊìöË®àÁÆóÂèç‰∫ãÂØ¶Êï∏ÈáèÔºåÂç≥ÂøÖË¶ÅÊÄßÂíåÂÖÖÂàÜÊÄßÊ©üÁéá (PNS)„ÄÇÊàëÂÄëÊèêÂá∫ PNS ÊòØË©ï‰º∞ÂÅ•ÊÄ°ÂèØÊ®ÇÂ∞çËÇ•ËÉñÂΩ±ÈüøÁöÑÂü∫Êú¨ÊåáÊ®ô„ÄÇÊàëÂÄëÁöÑÁµêÊûúË°®ÊòéÔºå20% Ëá≥ 50% ÁöÑÂÄã‰∫∫ÔºåÂ∞§ÂÖ∂ÊòØÈ£≤È£üÁøíÊÖ£‰∏çËâØËÄÖÔºåÊõ¥ÊúâÂèØËÉΩÂõ†ÂÅ•ÊÄ°ÂèØÊ®ÇËÄåÂ¢ûÂä†È´îÈáç„ÄÇÁõ∏ÂèçÂú∞ÔºåÂú®Âπ¥ËºïÂ•≥ÊÄßÁ≠âÈ£≤È£üËºÉÂÅ•Â∫∑ÁöÑÊóèÁæ§‰∏≠ÔºåÂè™ÊúâÂ∞ëÈÉ®ÂàÜ‰∫∫ÊúÉÂõ†ÂÅ•ÊÄ°ÂèØÊ®ÇËÄåÈ´îÈáçÂ¢ûÂä†„ÄÇÈÄô‰∫õÁôºÁèæÁ™ÅÈ°Ø‰∫ÜÂÄã‰∫∫ÁîüÊ¥ªÊñπÂºèÂíåÊΩõÂú®Ëç∑ÁàæËíôÂõ†Á¥†Â∞çÂÅ•ÊÄ°ÂèØÊ®Ç‰∏çÂêåÂΩ±ÈüøÁöÑÂΩ±ÈüøÔºåÁÇ∫‰∫ÜËß£ÂÖ∂Â∞çÂÅ•Â∫∑ÁöÑÁáüÈ§äÂΩ±ÈüøÊèê‰æõ‰∫ÜÊñ∞ÁöÑÊû∂Êßã„ÄÇ

##### **A Systematic Review and Meta-Analysis on Sleep Stage Classification and Sleep Disorder Detection Using Artificial Intelligence**
2405.11008v1 by Tayab Uddin Wara, Ababil Hossain Fahad, Adri Shankar Das, Md. Mehedi Hasan Shawon

Sleep is vital for people's physical and mental health, and sound sleep can
help them focus on daily activities. Therefore, a sleep study that includes
sleep patterns and disorders is crucial to enhancing our knowledge about
individuals' health status. The findings on sleep stages and sleep disorders
relied on polysomnography and self-report measures, and then the study went
through clinical assessments by expert physicians. However, the evaluation
process of sleep stage classification and sleep disorder has become more
convenient with artificial intelligence applications and numerous
investigations focusing on various datasets with advanced algorithms and
techniques that offer improved computational ease and accuracy. This study aims
to provide a comprehensive, systematic review and meta-analysis of the recent
literature to analyze the different approaches and their outcomes in sleep
studies, which includes works on sleep stages classification and sleep disorder
detection using AI. In this review, 183 articles were initially selected from
different journals, among which 80 records were enlisted for explicit review,
ranging from 2016 to 2023. Brain waves were the most commonly employed body
parameters for sleep staging and disorder studies. The convolutional neural
network, the most widely used of the 34 distinct artificial intelligence
models, comprised 27%. The other models included the long short-term memory,
support vector machine, random forest, and recurrent neural network, which
consisted of 11%, 6%, 6%, and 5% sequentially. For performance metrics,
accuracy was widely used for a maximum of 83.75% of the cases, the F1 score of
45%, Kappa of 36.25%, Sensitivity of 31.25%, and Specificity of 30% of cases,
along with the other metrics. This article would help physicians and
researchers get the gist of AI's contribution to sleep studies and the
feasibility of their intended work.

ÊëòË¶ÅÔºöÁù°Áú†Â∞ç‰∫∫ÂÄëÁöÑË∫´ÂøÉÂÅ•Â∫∑Ëá≥ÈóúÈáçË¶ÅÔºåÂÖÖË∂≥ÁöÑÁù°Áú†ÊúâÂä©Êñº‰∫∫ÂÄëÂ∞àÊ≥®ÊñºÊó•Â∏∏Ê¥ªÂãï„ÄÇÂõ†Ê≠§Ôºå‰∏ÄÈ†ÖÂåÖÂê´Áù°Áú†Ê®°ÂºèÂíåÁù°Áú†ÈöúÁ§ôÁöÑÁù°Áú†Á†îÁ©∂Â∞çÊñºÂ¢ûÈÄ≤ÊàëÂÄëÂ∞çÂÄã‰∫∫ÂÅ•Â∫∑ÁãÄÊ≥ÅÁöÑ‰∫ÜËß£Ëá≥ÈóúÈáçË¶Å„ÄÇÈóúÊñºÁù°Áú†ÈöéÊÆµÂíåÁù°Áú†ÈöúÁ§ôÁöÑÁôºÁèæ‰æùË≥¥ÊñºÂ§öÂ∞éÁù°Áú†ÊèèË®òË°ìÂíåËá™ÊàëÂ†±ÂëäÊ∏¨ÈáèÔºåÁÑ∂ÂæåË©≤Á†îÁ©∂Á∂ìÈÅéÂ∞àÂÆ∂ÈÜ´Â∏´ÁöÑËá®Â∫äË©ï‰º∞„ÄÇÁÑ∂ËÄåÔºåÈö®Ëëó‰∫∫Â∑•Êô∫ËÉΩÊáâÁî®Ôºå‰ª•ÂèäÈáùÂ∞çÂêÑÁ®ÆÊï∏ÊìöÈõÜÁöÑÁúæÂ§öÁ†îÁ©∂ÔºåÂà©Áî®ÂÖàÈÄ≤ÁöÑÊºîÁÆóÊ≥ïÂíåÊäÄË°ìÊèê‰æõÊõ¥È´òÁöÑÈÅãÁÆó‰æøÂà©ÊÄßÂíåÊ∫ñÁ¢∫ÊÄßÔºåÁù°Áú†ÈöéÊÆµÂàÜÈ°ûÂíåÁù°Áú†ÈöúÁ§ôÁöÑË©ï‰º∞ÈÅéÁ®ãËÆäÂæóÊõ¥Âä†‰æøÂà©„ÄÇÊú¨Á†îÁ©∂Êó®Âú®Êèê‰æõÂ∞çËøëÊúüÊñáÁçªÁöÑÂÖ®Èù¢„ÄÅÁ≥ªÁµ±ÊÄßÁöÑÂõûÈ°ßÂíåÁµ±ÂêàÂàÜÊûêÔºå‰ª•ÂàÜÊûêÁù°Áú†Á†îÁ©∂‰∏≠‰∏çÂêåÁöÑÊñπÊ≥ïÂèäÂÖ∂ÊàêÊûúÔºåÂÖ∂‰∏≠ÂåÖÊã¨‰ΩøÁî®‰∫∫Â∑•Êô∫ÊÖßÈÄ≤Ë°åÁù°Áú†ÈöéÊÆµÂàÜÈ°ûÂíåÁù°Áú†ÈöúÁ§ôÊ™¢Ê∏¨ÁöÑÁ†îÁ©∂„ÄÇÂú®Êú¨ÂõûÈ°ß‰∏≠ÔºåÊúÄÂàùÂæû‰∏çÂêåÁöÑÊúüÂàä‰∏≠ÈÅ∏Âá∫ 183 ÁØáÊñáÁ´†ÔºåÂÖ∂‰∏≠ 80 ÁØáÁ¥ÄÈåÑË¢´ÂàóÂÖ•ÊòéÁ¢∫ÁöÑÂõûÈ°ßÔºåÊôÇÈñìÁØÑÂúçÂæû 2016 Âπ¥Âà∞ 2023 Âπ¥„ÄÇËÖ¶Ê≥¢ÊòØÊúÄÂ∏∏‰ΩøÁî®ÁöÑÁù°Áú†ÂàÜÊúüÂíåÈöúÁ§ôÁ†îÁ©∂ÁöÑË∫´È´îÂèÉÊï∏„ÄÇÂç∑Á©çÁ•ûÁ∂ìÁ∂≤Ë∑ØÊòØ 34 ÂÄã‰∏çÂêåÁöÑ‰∫∫Â∑•Êô∫ÊÖßÊ®°Âûã‰∏≠ÊúÄÂª£Ê≥õ‰ΩøÁî®ÁöÑÔºå‰Ωî 27%„ÄÇÂÖ∂‰ªñÊ®°ÂûãÂåÖÊã¨Èï∑Áü≠ÊúüË®òÊÜ∂„ÄÅÊîØÊåÅÂêëÈáèÊ©ü„ÄÅÈö®Ê©üÊ£ÆÊûóÂíåÈÅûËø¥Á•ûÁ∂ìÁ∂≤Ë∑ØÔºå‰æùÂ∫è‰Ωî 11%„ÄÅ6%„ÄÅ6% Âíå 5%„ÄÇÂú®ÊïàËÉΩÊåáÊ®ôÊñπÈù¢ÔºåÊ∫ñÁ¢∫Â∫¶Âª£Ê≥õÁî®ÊñºÊúÄÂ§ö 83.75% ÁöÑÊ°à‰æãÔºåF1 ÂàÜÊï∏ÁÇ∫ 45%ÔºåKappa ÁÇ∫ 36.25%ÔºåÊïèÊÑüÂ∫¶ÁÇ∫ 31.25%ÔºåÁâπÁï∞Â∫¶ÁÇ∫ 30% ÁöÑÊ°à‰æãÔºå‰ª•ÂèäÂÖ∂‰ªñÊåáÊ®ô„ÄÇÊú¨ÊñáÂ∞áÂπ´Âä©ÈÜ´Â∏´ÂíåÁ†îÁ©∂‰∫∫Âì°‰∫ÜËß£‰∫∫Â∑•Êô∫ÊÖßÂ∞çÁù°Áú†Á†îÁ©∂ÁöÑË≤¢Áçª‰ª•ÂèäÂÖ∂È†êÊúüÂ∑•‰ΩúÁöÑÂèØË°åÊÄß„ÄÇ

##### **Cyclical Weight Consolidation: Towards Solving Catastrophic Forgetting in Serial Federated Learning**
2405.10647v1 by Haoyue Song, Jiacheng Wang, Liansheng Wang

Federated Learning (FL) has gained attention for addressing data scarcity and
privacy concerns. While parallel FL algorithms like FedAvg exhibit remarkable
performance, they face challenges in scenarios with diverse network speeds and
concerns about centralized control, especially in multi-institutional
collaborations like the medical domain. Serial FL presents an alternative
solution, circumventing these challenges by transferring model updates serially
between devices in a cyclical manner. Nevertheless, it is deemed inferior to
parallel FL in that (1) its performance shows undesirable fluctuations, and (2)
it converges to a lower plateau, particularly when dealing with non-IID data.
The observed phenomenon is attributed to catastrophic forgetting due to
knowledge loss from previous sites. In this paper, to overcome fluctuation and
low efficiency in the iterative learning and forgetting process, we introduce
cyclical weight consolidation (CWC), a straightforward yet potent approach
specifically tailored for serial FL. CWC employs a consolidation matrix to
regulate local optimization. This matrix tracks the significance of each
parameter on the overall federation throughout the entire training trajectory,
preventing abrupt changes in significant weights. During revisitation, to
maintain adaptability, old memory undergoes decay to incorporate new
information. Our comprehensive evaluations demonstrate that in various non-IID
settings, CWC mitigates the fluctuation behavior of the original serial FL
approach and enhances the converged performance consistently and significantly.
The improved performance is either comparable to or better than the parallel
vanilla.

ÊëòË¶ÅÔºöËÅîÈÇ¶Â≠¶‰π† (FL) Âõ†Ëß£ÂÜ≥Êï∞ÊçÆÁ®ÄÁº∫ÂíåÈöêÁßÅÈóÆÈ¢òËÄåÂèóÂà∞ÂÖ≥Ê≥®„ÄÇËôΩÁÑ∂ FedAvg Á≠âÂπ∂Ë°å FL ÁÆóÊ≥ïË°®Áé∞Âá∫Ëâ≤Ôºå‰ΩÜÂÆÉ‰ª¨Âú®ÁΩëÁªúÈÄüÂ∫¶Â§öÊ†∑ÂåñÂíåÈõÜ‰∏≠ÊéßÂà∂ÁöÑÂú∫ÊôØ‰∏≠Èù¢‰∏¥ÊåëÊàòÔºåÂ∞§ÂÖ∂ÊòØÂú®ÂåªÁñóÈ¢ÜÂüüÁ≠âÂ§öÊú∫ÊûÑÂçè‰Ωú‰∏≠„ÄÇ‰∏≤Ë°å FL ÊèêÂá∫‰∫Ü‰∏ÄÁßçÊõø‰ª£Ëß£ÂÜ≥ÊñπÊ°àÔºåÈÄöËøáÂæ™ÁéØÊñπÂºèÂú®ËÆæÂ§á‰πãÈó¥‰∏≤Ë°å‰º†ËæìÊ®°ÂûãÊõ¥Êñ∞Êù•ËßÑÈÅøËøô‰∫õÊåëÊàò„ÄÇÁÑ∂ËÄåÔºåÂÆÉË¢´ËÆ§‰∏∫‰∏çÂ¶ÇÂπ∂Ë°å FLÔºåÂéüÂõ†Âú®‰∫é (1) ÂÆÉÁöÑÊÄßËÉΩË°®Áé∞Âá∫‰∏çÂ∏åÊúõÁöÑÊ≥¢Âä®Ôºå(2) ÂÆÉÊî∂ÊïõÂà∞ËæÉ‰ΩéÁöÑÂπ≥Âè∞ÔºåÁâπÂà´ÊòØÂú®Â§ÑÁêÜÈùû IID Êï∞ÊçÆÊó∂„ÄÇËßÇÂØüÂà∞ÁöÑÁé∞Ë±°ÂΩíÂõ†‰∫éÁî±‰∫éÂÖàÂâçÁ´ôÁÇπÁü•ËØÜ‰∏¢Â§±ËÄåÂØºËá¥ÁöÑÁÅæÈöæÊÄßÈÅóÂøò„ÄÇÂú®Êú¨Êñá‰∏≠Ôºå‰∏∫‰∫ÜÂÖãÊúçËø≠‰ª£Â≠¶‰π†ÂíåÈÅóÂøòËøáÁ®ã‰∏≠ÁöÑÊ≥¢Âä®Âíå‰ΩéÊïàÁéáÔºåÊàë‰ª¨ÂºïÂÖ•‰∫ÜÂæ™ÁéØÊùÉÈáçÂêàÂπ∂ (CWC)ÔºåËøôÊòØ‰∏ÄÁßç‰∏ìÈó®ÈíàÂØπ‰∏≤Ë°å FL ÈáèË∫´ÂÆöÂà∂ÁöÑÁÆÄÂçïËÄåÊúâÊïàÁöÑÊñπÊ≥ï„ÄÇCWC ‰ΩøÁî®ÂêàÂπ∂Áü©ÈòµÊù•Ë∞ÉËäÇÂ±ÄÈÉ®‰ºòÂåñ„ÄÇËØ•Áü©ÈòµË∑üË∏™Êï¥‰∏™ËÆ≠ÁªÉËΩ®Ëøπ‰∏≠ÊØè‰∏™ÂèÇÊï∞ÂØπÊï¥‰∏™ËÅîÂêàÁöÑÈáçË¶ÅÊÄßÔºåÈò≤Ê≠¢ÈáçË¶ÅÊùÉÈáçÁöÑÁ™ÅÁÑ∂ÂèòÂåñ„ÄÇÂú®ÈáçÊñ∞ËÆøÈóÆÊúüÈó¥Ôºå‰∏∫‰∫Ü‰øùÊåÅÈÄÇÂ∫îÊÄßÔºåÊóßËÆ∞ÂøÜ‰ºöË°∞Âáè‰ª•Á∫≥ÂÖ•Êñ∞‰ø°ÊÅØ„ÄÇÊàë‰ª¨ÁöÑÁªºÂêàËØÑ‰º∞Ë°®ÊòéÔºåÂú®ÂêÑÁßçÈùû IID ËÆæÁΩÆ‰∏≠ÔºåCWC ÂáèËΩª‰∫ÜÂéüÂßã‰∏≤Ë°å FL ÊñπÊ≥ïÁöÑÊ≥¢Âä®Ë°å‰∏∫ÔºåÂπ∂ÊåÅÁª≠‰∏îÊòæÁùÄÂú∞ÊèêÈ´ò‰∫ÜÊî∂ÊïõÊÄßËÉΩ„ÄÇÊîπËøõÂêéÁöÑÊÄßËÉΩ‰∏éÂπ∂Ë°åÈ¶ôËçâÁõ∏ÂΩìÊàñÊõ¥Â•Ω„ÄÇ


### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-05-31**|**Video-MME: The First-Ever Comprehensive Evaluation Benchmark of Multi-modal LLMs in Video Analysis**|Chaoyou Fu et.al.|[2405.21075v1](http://arxiv.org/abs/2405.21075v1)|null|
|**2024-05-31**|**Generalization Beyond Data Imbalance: A Controlled Study on CLIP for Transferable Insights**|Xin Wen et.al.|[2405.21070v1](http://arxiv.org/abs/2405.21070v1)|[link](https://github.com/cvmi-lab/clip-beyond-tail)|
|**2024-05-31**|**Code Pretraining Improves Entity Tracking Abilities of Language Models**|Najoung Kim et.al.|[2405.21068v1](http://arxiv.org/abs/2405.21068v1)|null|
|**2024-05-31**|**Recurrent neural networks: vanishing and exploding gradients are not the end of the story**|Nicolas Zucchet et.al.|[2405.21064v1](http://arxiv.org/abs/2405.21064v1)|null|
|**2024-05-31**|**Grammar-Aligned Decoding**|Kanghee Park et.al.|[2405.21047v1](http://arxiv.org/abs/2405.21047v1)|null|
|**2024-05-31**|**Exploratory Preference Optimization: Harnessing Implicit Q*-Approximation for Sample-Efficient RLHF**|Tengyang Xie et.al.|[2405.21046v1](http://arxiv.org/abs/2405.21046v1)|null|
|**2024-05-31**|**Target Networks and Over-parameterization Stabilize Off-policy Bootstrapping with Function Approximation**|Fengdi Che et.al.|[2405.21043v1](http://arxiv.org/abs/2405.21043v1)|null|
|**2024-05-31**|**Direct Alignment of Language Models via Quality-Aware Self-Refinement**|Runsheng Yu et.al.|[2405.21040v1](http://arxiv.org/abs/2405.21040v1)|null|
|**2024-05-31**|**Standards for Belief Representations in LLMs**|Daniel A. Herrmann et.al.|[2405.21030v1](http://arxiv.org/abs/2405.21030v1)|null|
|**2024-05-31**|**LACIE: Listener-Aware Finetuning for Confidence Calibration in Large Language Models**|Elias Stengel-Eskin et.al.|[2405.21028v1](http://arxiv.org/abs/2405.21028v1)|[link](https://github.com/esteng/pragmatic_calibration)|
|**2024-05-31**|**Fusion-PSRO: Nash Policy Fusion for Policy Space Response Oracles**|Jiesong Lian et.al.|[2405.21027v2](http://arxiv.org/abs/2405.21027v2)|null|
|**2024-05-31**|**Compact Optimality Verification for Optimization Proxies**|Wenbo Chen et.al.|[2405.21023v1](http://arxiv.org/abs/2405.21023v1)|null|
|**2024-05-31**|**You Only Scan Once: Efficient Multi-dimension Sequential Modeling with LightNet**|Zhen Qin et.al.|[2405.21022v1](http://arxiv.org/abs/2405.21022v1)|null|
|**2024-05-31**|**Improved Techniques for Optimization-Based Jailbreaking on Large Language Models**|Xiaojun Jia et.al.|[2405.21018v1](http://arxiv.org/abs/2405.21018v1)|[link](https://github.com/jiaxiaojunqaq/i-gcg)|
|**2024-05-31**|**CWRCzech: 100M Query-Document Czech Click Dataset and Its Application to Web Relevance Ranking**|Josef Von√°≈°ek et.al.|[2405.20994v1](http://arxiv.org/abs/2405.20994v1)|null|
|**2024-05-31**|**Locking Machine Learning Models into Hardware**|Eleanor Clifford et.al.|[2405.20990v1](http://arxiv.org/abs/2405.20990v1)|null|
|**2024-05-31**|**Enhancing Noise Robustness of Retrieval-Augmented Language Models with Adaptive Adversarial Training**|Feiteng Fang et.al.|[2405.20978v1](http://arxiv.org/abs/2405.20978v1)|null|
|**2024-05-31**|**ACE: A Model Poisoning Attack on Contribution Evaluation Methods in Federated Learning**|Zhangchen Xu et.al.|[2405.20975v1](http://arxiv.org/abs/2405.20975v1)|null|
|**2024-05-31**|**SaySelf: Teaching LLMs to Express Confidence with Self-Reflective Rationales**|Tianyang Xu et.al.|[2405.20974v1](http://arxiv.org/abs/2405.20974v1)|[link](https://github.com/xu1868/sayself)|
|**2024-05-31**|**LCQ: Low-Rank Codebook based Quantization for Large Language Models**|Wen-Pu Cai et.al.|[2405.20973v1](http://arxiv.org/abs/2405.20973v1)|null|
|**2024-05-31**|**Superlatives in Context: Explicit and Implicit Domain Restrictions for Superlative Frames**|Valentina Pyatkin et.al.|[2405.20967v1](http://arxiv.org/abs/2405.20967v1)|null|
|**2024-05-31**|**Large Language Models are Zero-Shot Next Location Predictors**|Ciro Beneduce et.al.|[2405.20962v2](http://arxiv.org/abs/2405.20962v2)|[link](https://github.com/ssai-trento/llm-zero-shot-nl)|
|**2024-05-31**|**Navigating Tabular Data Synthesis Research: Understanding User Needs and Tool Capabilities**|Maria F. Davila R. et.al.|[2405.20959v1](http://arxiv.org/abs/2405.20959v1)|null|
|**2024-05-31**|**A Robot Walks into a Bar: Can Language Models Serve asCreativity Support Tools for Comedy? An Evaluation of LLMs' Humour Alignment with Comedians**|Piotr Wojciech Mirowski et.al.|[2405.20956v1](http://arxiv.org/abs/2405.20956v1)|null|
|**2024-05-31**|**OR-Bench: An Over-Refusal Benchmark for Large Language Models**|Justin Cui et.al.|[2405.20947v1](http://arxiv.org/abs/2405.20947v1)|null|
|**2024-05-31**|**Effective Interplay between Sparsity and Quantization: From Theory to Practice**|Simla Burcu Harma et.al.|[2405.20935v1](http://arxiv.org/abs/2405.20935v1)|null|
|**2024-05-31**|**Learning to Estimate System Specifications in Linear Temporal Logic using Transformers and Mamba**|ƒ∞lker I≈üƒ±k et.al.|[2405.20917v1](http://arxiv.org/abs/2405.20917v1)|null|
|**2024-05-31**|**Fast yet Safe: Early-Exiting with Risk Control**|Metod Jazbec et.al.|[2405.20915v1](http://arxiv.org/abs/2405.20915v1)|null|
|**2024-05-31**|**Enhancing Vision Models for Text-Heavy Content Understanding and Interaction**|Adithya TG et.al.|[2405.20906v1](http://arxiv.org/abs/2405.20906v1)|null|
|**2024-05-31**|**Preemptive Answer "Attacks" on Chain-of-Thought Reasoning**|Rongwu Xu et.al.|[2405.20902v1](http://arxiv.org/abs/2405.20902v1)|null|
|**2024-05-31**|**Large Language Models: A New Approach for Privacy Policy Analysis at Scale**|David Rodriguez et.al.|[2405.20900v1](http://arxiv.org/abs/2405.20900v1)|null|
|**2024-05-31**|**MALT: Multi-scale Action Learning Transformer for Online Action Detection**|Zhipeng Yang et.al.|[2405.20892v1](http://arxiv.org/abs/2405.20892v1)|null|
|**2024-05-31**|**Paying to Do Better: Games with Payments between Learning Agents**|Yoav Kolumbus et.al.|[2405.20880v1](http://arxiv.org/abs/2405.20880v1)|null|
|**2024-05-31**|**SelfGNN: Self-Supervised Graph Neural Networks for Sequential Recommendation**|Yuxi Liu et.al.|[2405.20878v1](http://arxiv.org/abs/2405.20878v1)|[link](https://github.com/hkuds/selfgnn)|
|**2024-05-31**|**Investigating Calibration and Corruption Robustness of Post-hoc Pruned Perception CNNs: An Image Classification Benchmark Study**|Pallavi Mitra et.al.|[2405.20876v1](http://arxiv.org/abs/2405.20876v1)|null|
|**2024-05-31**|**Automatic Channel Pruning for Multi-Head Attention**|Eunho Lee et.al.|[2405.20867v1](http://arxiv.org/abs/2405.20867v1)|null|
|**2024-05-31**|**ABodyBuilder3: Improved and scalable antibody structure predictions**|Henry Kenlay et.al.|[2405.20863v1](http://arxiv.org/abs/2405.20863v1)|[link](https://github.com/exscientia/abodybuilder3)|
|**2024-05-31**|**clembench-2024: A Challenging, Dynamic, Complementary, Multilingual Benchmark and Underlying Flexible Framework for LLMs as Multi-Action Agents**|Anne Beyer et.al.|[2405.20859v1](http://arxiv.org/abs/2405.20859v1)|null|
|**2024-05-31**|**Towards Spoken Language Understanding via Multi-level Multi-grained Contrastive Learning**|Xuxin Cheng et.al.|[2405.20852v1](http://arxiv.org/abs/2405.20852v1)|null|
|**2024-05-31**|**Improving Reward Models with Synthetic Critiques**|Zihuiwen Ye et.al.|[2405.20850v1](http://arxiv.org/abs/2405.20850v1)|null|
|**2024-05-31**|**SLIM: a Scalable Light-weight Root Cause Analysis for Imbalanced Data in Microservice**|Rui Ren et.al.|[2405.20848v1](http://arxiv.org/abs/2405.20848v1)|null|
|**2024-05-31**|**Don't Buy it! Reassessing the Ad Understanding Abilities of Contrastive Multimodal Models**|A. Bavaresco et.al.|[2405.20846v1](http://arxiv.org/abs/2405.20846v1)|null|
|**2024-05-31**|**einspace: Searching for Neural Architectures from Fundamental Operations**|Linus Ericsson et.al.|[2405.20838v1](http://arxiv.org/abs/2405.20838v1)|[link](https://github.com/linusericsson/einspace)|
|**2024-05-31**|**Outliers and Calibration Sets have Diminishing Effect on Quantization of Modern LLMs**|Davide Paglieri et.al.|[2405.20835v1](http://arxiv.org/abs/2405.20835v1)|null|
|**2024-05-31**|**That's Optional: A Contemporary Exploration of "that" Omission in English Subordinate Clauses**|Ella Rabinovich et.al.|[2405.20833v1](http://arxiv.org/abs/2405.20833v1)|null|
|**2024-05-31**|**Self-Augmented Preference Optimization: Off-Policy Paradigms for Language Model Alignment**|Yueqin Yin et.al.|[2405.20830v1](http://arxiv.org/abs/2405.20830v1)|null|
|**2024-05-31**|**An iterated learning model of language change that mixes supervised and unsupervised learning**|Jack Bunyan et.al.|[2405.20818v1](http://arxiv.org/abs/2405.20818v1)|null|
|**2024-05-31**|**There and Back Again: The AI Alignment Paradox**|Robert West et.al.|[2405.20806v1](http://arxiv.org/abs/2405.20806v1)|null|
|**2024-05-31**|**Multilingual Text Style Transfer: Datasets & Models for Indian Languages**|Sourabrata Mukherjee et.al.|[2405.20805v1](http://arxiv.org/abs/2405.20805v1)|null|
|**2024-05-31**|**Ovis: Structural Embedding Alignment for Multimodal Large Language Model**|Shiyin Lu et.al.|[2405.20797v1](http://arxiv.org/abs/2405.20797v1)|null|
|**2024-05-31**|**InsightSee: Advancing Multi-agent Vision-Language Models for Enhanced Visual Understanding**|Huaxiang Zhang et.al.|[2405.20795v1](http://arxiv.org/abs/2405.20795v1)|null|
|**2024-05-31**|**Improving code-mixed hate detection by native sample mixing: A case study for Hindi-English code-mixed scenario**|Debajyoti Mazumder et.al.|[2405.20755v1](http://arxiv.org/abs/2405.20755v1)|null|
|**2024-05-31**|**Trajectory Forecasting through Low-Rank Adaptation of Discrete Latent Codes**|Riccardo Benaglia et.al.|[2405.20743v1](http://arxiv.org/abs/2405.20743v1)|null|
|**2024-05-31**|**Maximum Temperature Prediction Using Remote Sensing Data Via Convolutional Neural Network**|Lorenzo Innocenti et.al.|[2405.20731v1](http://arxiv.org/abs/2405.20731v1)|null|
|**2024-05-31**|**GANcrop: A Contrastive Defense Against Backdoor Attacks in Federated Learning**|Xiaoyun Gan et.al.|[2405.20727v1](http://arxiv.org/abs/2405.20727v1)|null|
|**2024-05-31**|**GI-NAS: Boosting Gradient Inversion Attacks through Adaptive Neural Architecture Search**|Wenbo Yu et.al.|[2405.20725v1](http://arxiv.org/abs/2405.20725v1)|null|
|**2024-05-31**|**ContextGS: Compact 3D Gaussian Splatting with Anchor Level Context Model**|Yufei Wang et.al.|[2405.20721v1](http://arxiv.org/abs/2405.20721v1)|[link](https://github.com/wyf0912/contextgs)|
|**2024-05-31**|**Climate Variable Downscaling with Conditional Normalizing Flows**|Christina Winkler et.al.|[2405.20719v1](http://arxiv.org/abs/2405.20719v1)|null|
|**2024-05-31**|**Popularity-Aware Alignment and Contrast for Mitigating Popularity Bias**|Miaomiao Cai et.al.|[2405.20718v1](http://arxiv.org/abs/2405.20718v1)|[link](https://github.com/miaomiao-cai2/kdd2024-paac)|
|**2024-05-31**|**FinGen: A Dataset for Argument Generation in Finance**|Chung-Chi Chen et.al.|[2405.20708v1](http://arxiv.org/abs/2405.20708v1)|null|
|**2024-05-31**|**ADESSE: Advice Explanations in Complex Repeated Decision-Making Environments**|S√∂ren Schleibaum et.al.|[2405.20705v1](http://arxiv.org/abs/2405.20705v1)|null|
|**2024-05-31**|**It is Simple Sometimes: A Study On Improving Aspect-Based Sentiment Analysis Performance**|Laura Cabello et.al.|[2405.20703v1](http://arxiv.org/abs/2405.20703v1)|null|
|**2024-05-31**|**Unveiling the Lexical Sensitivity of LLMs: Combinatorial Optimization for Prompt Enhancement**|Pengwei Zhan et.al.|[2405.20701v1](http://arxiv.org/abs/2405.20701v1)|null|
|**2024-05-31**|**Self-degraded contrastive domain adaptation for industrial fault diagnosis with bi-imbalanced data**|Gecheng Chen et.al.|[2405.20700v1](http://arxiv.org/abs/2405.20700v1)|null|
|**2024-05-31**|**Joint Embeddings for Graph Instruction Tuning**|Vlad Argatu et.al.|[2405.20684v1](http://arxiv.org/abs/2405.20684v1)|null|
|**2024-05-31**|**No Free Lunch Theorem for Privacy-Preserving LLM Inference**|Xiaojin Zhang et.al.|[2405.20681v1](http://arxiv.org/abs/2405.20681v1)|null|
|**2024-05-31**|**Unraveling and Mitigating Retriever Inconsistencies in Retrieval-Augmented Large Language Models**|Mingda Li et.al.|[2405.20680v2](http://arxiv.org/abs/2405.20680v2)|null|
|**2024-05-31**|**Adv-KD: Adversarial Knowledge Distillation for Faster Diffusion Sampling**|Kidist Amde Mekonnen et.al.|[2405.20675v1](http://arxiv.org/abs/2405.20675v1)|[link](https://github.com/kidist-amde/adv-kd)|
|**2024-05-31**|**DORY: Deliberative Prompt Recovery for LLM**|Lirong Gao et.al.|[2405.20657v1](http://arxiv.org/abs/2405.20657v1)|null|
|**2024-05-31**|**Passage-specific Prompt Tuning for Passage Reranking in Question Answering with Large Language Models**|Xuyang Wu et.al.|[2405.20654v1](http://arxiv.org/abs/2405.20654v1)|null|
|**2024-05-31**|**Enhancing Jailbreak Attack Against Large Language Models through Silent Tokens**|Jiahao Yu et.al.|[2405.20653v1](http://arxiv.org/abs/2405.20653v1)|null|
|**2024-05-31**|**Reward-based Input Construction for Cross-document Relation Extraction**|Byeonghu Na et.al.|[2405.20649v1](http://arxiv.org/abs/2405.20649v1)|[link](https://github.com/aailabkaist/reic)|
|**2024-05-31**|**Shotluck Holmes: A Family of Efficient Small-Scale Large Language Vision Models For Video Captioning and Summarization**|Richard Luo et.al.|[2405.20648v1](http://arxiv.org/abs/2405.20648v1)|null|
|**2024-05-31**|**Large Language Models Enhanced Sequential Recommendation for Long-tail User and Item**|Qidong Liu et.al.|[2405.20646v1](http://arxiv.org/abs/2405.20646v1)|null|
|**2024-05-31**|**Learning Gaze-aware Compositional GAN**|Nerea Aranjuelo et.al.|[2405.20643v1](http://arxiv.org/abs/2405.20643v1)|[link](https://github.com/naranjuelo/gc-gan)|
|**2024-05-31**|**ToxVidLLM: A Multimodal LLM-based Framework for Toxicity Detection in Code-Mixed Videos**|Krishanu Maity et.al.|[2405.20628v1](http://arxiv.org/abs/2405.20628v1)|null|
|**2024-05-31**|**Robust Planning with LLM-Modulo Framework: Case Study in Travel Planning**|Atharva Gundawar et.al.|[2405.20625v1](http://arxiv.org/abs/2405.20625v1)|null|
|**2024-05-31**|**Leveraging Large Language Models for Entity Matching**|Qianyu Huang et.al.|[2405.20624v1](http://arxiv.org/abs/2405.20624v1)|null|
|**2024-05-31**|**FineRadScore: A Radiology Report Line-by-Line Evaluation Technique Generating Corrections with Severity Scores**|Alyssa Huang et.al.|[2405.20613v1](http://arxiv.org/abs/2405.20613v1)|null|
|**2024-05-31**|**UniBias: Unveiling and Mitigating LLM Bias through Internal Attention and FFN Manipulation**|Hanzhang Zhou et.al.|[2405.20612v1](http://arxiv.org/abs/2405.20612v1)|null|
|**2024-05-31**|**Bi-Directional Transformers vs. word2vec: Discovering Vulnerabilities in Lifted Compiled Code**|Gary A. McCully et.al.|[2405.20611v1](http://arxiv.org/abs/2405.20611v1)|null|
|**2024-05-31**|**Vision-Language Meets the Skeleton: Progressively Distillation with Cross-Modal Knowledge for 3D Action Representation Learning**|Yang Chen et.al.|[2405.20606v1](http://arxiv.org/abs/2405.20606v1)|null|
|**2024-05-31**|**Searching for internal symbols underlying deep learning**|Jung H. Lee et.al.|[2405.20605v1](http://arxiv.org/abs/2405.20605v1)|null|
|**2024-05-31**|**Advancing Financial Risk Prediction Through Optimized LSTM Model Performance and Comparative Analysis**|Ke Xu et.al.|[2405.20603v1](http://arxiv.org/abs/2405.20603v1)|null|
|**2024-05-31**|**Masked Language Modeling Becomes Conditional Density Estimation for Tabular Data Synthesis**|Seunghwan An et.al.|[2405.20602v1](http://arxiv.org/abs/2405.20602v1)|null|
|**2024-05-31**|**Multi-label Class Incremental Emotion Decoding with Augmented Emotional Semantics Learning**|Kaicheng Fu et.al.|[2405.20600v1](http://arxiv.org/abs/2405.20600v1)|null|
|**2024-05-31**|**Class-Based Time Series Data Augmentation to Mitigate Extreme Class Imbalance for Solar Flare Prediction**|Junzhi Wen et.al.|[2405.20590v1](http://arxiv.org/abs/2405.20590v1)|null|
|**2024-05-31**|**Selective Knowledge Sharing for Personalized Federated Learning Under Capacity Heterogeneity**|Zheng Wang et.al.|[2405.20589v1](http://arxiv.org/abs/2405.20589v1)|null|
|**2024-05-31**|**DAFNet: Dynamic Auxiliary Fusion for Sequential Model Editing in Large Language Models**|Taolin Zhang et.al.|[2405.20588v1](http://arxiv.org/abs/2405.20588v1)|null|
|**2024-05-31**|**GAMedX: Generative AI-based Medical Entity Data Extractor Using Large Language Models**|Mohammed-Khalil Ghali et.al.|[2405.20585v1](http://arxiv.org/abs/2405.20585v1)|null|
|**2024-05-31**|**Disrupting Diffusion: Token-Level Attention Erasure Attack against Diffusion-based Customization**|Yisu Liu et.al.|[2405.20584v1](http://arxiv.org/abs/2405.20584v1)|null|
|**2024-05-31**|**The Point of View of a Sentiment: Towards Clinician Bias Detection in Psychiatric Notes**|Alissa A. Valentine et.al.|[2405.20582v1](http://arxiv.org/abs/2405.20582v1)|null|
|**2024-05-31**|**Open Ko-LLM Leaderboard: Evaluating Large Language Models in Korean with Ko-H5 Benchmark**|Chanjun Park et.al.|[2405.20574v1](http://arxiv.org/abs/2405.20574v1)|null|
|**2024-05-31**|**Can Machine Learning Assist in Diagnosis of Primary Immune Thrombocytopenia? A feasibility study**|Haroon Miah et.al.|[2405.20562v1](http://arxiv.org/abs/2405.20562v1)|null|
|**2024-05-30**|**Perplexed by Perplexity: Perplexity-Based Data Pruning With Small Reference Models**|Zachary Ankner et.al.|[2405.20541v1](http://arxiv.org/abs/2405.20541v1)|null|
|**2024-05-30**|**Unveiling the Impact of Coding Data Instruction Fine-Tuning on Large Language Models Reasoning**|Xinlu Zhang et.al.|[2405.20535v1](http://arxiv.org/abs/2405.20535v1)|null|
|**2024-05-30**|**An Automatic Question Usability Evaluation Toolkit**|Steven Moore et.al.|[2405.20529v1](http://arxiv.org/abs/2405.20529v1)|null|
|**2024-05-30**|**Towards Ontology-Enhanced Representation Learning for Large Language Models**|Francesco Ronzano et.al.|[2405.20527v1](http://arxiv.org/abs/2405.20527v1)|null|
|**2024-05-30**|**Automated Generation and Tagging of Knowledge Components from Multiple-Choice Questions**|Steven Moore et.al.|[2405.20526v1](http://arxiv.org/abs/2405.20526v1)|[link](https://github.com/stevenjamesmoore/learningatscale24)|
|**2024-05-30**|**Diffusion On Syntax Trees For Program Synthesis**|Shreyas Kapur et.al.|[2405.20519v1](http://arxiv.org/abs/2405.20519v1)|null|

#### Abstracts
##### **Video-MME: The First-Ever Comprehensive Evaluation Benchmark of Multi-modal LLMs in Video Analysis**
2405.21075v1 by Chaoyou Fu, Yuhan Dai, Yondong Luo, Lei Li, Shuhuai Ren, Renrui Zhang, Zihan Wang, Chenyu Zhou, Yunhang Shen, Mengdan Zhang, Peixian Chen, Yanwei Li, Shaohui Lin, Sirui Zhao, Ke Li, Tong Xu, Xiawu Zheng, Enhong Chen, Rongrong Ji, Xing Sun

In the quest for artificial general intelligence, Multi-modal Large Language
Models (MLLMs) have emerged as a focal point in recent advancements. However,
the predominant focus remains on developing their capabilities in static image
understanding. The potential of MLLMs in processing sequential visual data is
still insufficiently explored, highlighting the absence of a comprehensive,
high-quality assessment of their performance. In this paper, we introduce
Video-MME, the first-ever full-spectrum, Multi-Modal Evaluation benchmark of
MLLMs in Video analysis. Our work distinguishes from existing benchmarks
through four key features: 1) Diversity in video types, spanning 6 primary
visual domains with 30 subfields to ensure broad scenario generalizability; 2)
Duration in temporal dimension, encompassing both short-, medium-, and
long-term videos, ranging from 11 seconds to 1 hour, for robust contextual
dynamics; 3) Breadth in data modalities, integrating multi-modal inputs besides
video frames, including subtitles and audios, to unveil the all-round
capabilities of MLLMs; 4) Quality in annotations, utilizing rigorous manual
labeling by expert annotators to facilitate precise and reliable model
assessment. 900 videos with a total of 256 hours are manually selected and
annotated by repeatedly viewing all the video content, resulting in 2,700
question-answer pairs. With Video-MME, we extensively evaluate various
state-of-the-art MLLMs, including GPT-4 series and Gemini 1.5 Pro, as well as
open-source image models like InternVL-Chat-V1.5 and video models like
LLaVA-NeXT-Video. Our experiments reveal that Gemini 1.5 Pro is the
best-performing commercial model, significantly outperforming the open-source
models. Our dataset along with these findings underscores the need for further
improvements in handling longer sequences and multi-modal data. Project Page:
https://video-mme.github.io

ÊëòË¶ÅÔºöÂú®ËøΩÊ±Ç‰∫∫Â∑•ÈÄöÁî®Êô∫ËÉΩÁöÑÈÅéÁ®ã‰∏≠ÔºåÂ§öÊ®°ÊÖãÂ§ßÂûãË™ûË®ÄÊ®°Âûã (MLLM) Â∑≤ÊàêÁÇ∫ËøëÊúüÈÄ≤Â±ï‰∏≠ÁöÑÁÑ¶Èªû„ÄÇÁÑ∂ËÄåÔºå‰∏ªË¶ÅÁöÑÈáçÈªû‰ªçÊîæÂú®ÁôºÂ±ïÂÆÉÂÄëÂú®ÈùúÊÖãÂΩ±ÂÉèÁêÜËß£ÊñπÈù¢ÁöÑËÉΩÂäõ„ÄÇMLLM Âú®ËôïÁêÜÈ†ÜÂ∫èË¶ñË¶∫Ë≥áÊñôÁöÑÊΩõÂäõ‰ªçÊú™Ë¢´ÂÖÖÂàÜÊé¢Ë®éÔºåÁ™ÅÈ°Ø‰∫ÜÁº∫‰πèÂ∞çÂÖ∂ÊïàËÉΩÈÄ≤Ë°åÂÖ®Èù¢„ÄÅÈ´òÂìÅË≥™Ë©ï‰º∞„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü Video-MMEÔºåÈÄôÊòØÁ¨¨‰∏ÄÂÄãÈáùÂ∞ç MLLM Âú®ÂΩ±ÁâáÂàÜÊûê‰∏≠ÁöÑÂÖ®ÂÖâË≠úÂ§öÊ®°ÊÖãË©ï‰º∞Âü∫Ê∫ñ„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÈÄèÈÅéÂõõÈ†ÖÈóúÈçµÁâπÂæµÂçÄÂà•ÊñºÁèæÊúâÂü∫Ê∫ñÔºö1) ÂΩ±ÁâáÈ°ûÂûãÁöÑÂ§öÊ®£ÊÄßÔºåÊ∂µËìã 6 ÂÄã‰∏ªË¶ÅË¶ñË¶∫È†òÂüüÔºåÂåÖÂê´ 30 ÂÄãÂ≠êÈ†òÂüüÔºå‰ª•Á¢∫‰øùÂª£Ê≥õÁöÑÂ†¥ÊôØÈÄöÁî®ÊÄßÔºõ2) ÊôÇÈñìÁ∂≠Â∫¶ÁöÑÊåÅÁ∫åÊôÇÈñìÔºåÂåÖÂê´Áü≠„ÄÅ‰∏≠„ÄÅÈï∑ÊúüÂΩ±ÁâáÔºåÁØÑÂúçÂæû 11 ÁßíÂà∞ 1 Â∞èÊôÇÔºå‰ª•Á¢∫‰øùÁ©©ÂÅ•ÁöÑËÑàÁµ°ÂãïÊÖãÔºõ3) Ë≥áÊñôÊ®°ÊÖãÁöÑÂª£Â∫¶ÔºåÈô§‰∫ÜÂΩ±ÁâáÂπÄ‰πãÂ§ñÔºåÈÇÑÊï¥Âêà‰∫ÜÂ§öÊ®°ÊÖãËº∏ÂÖ•ÔºåÂåÖÊã¨Â≠óÂπïÂíåÈü≥Ë®äÔºå‰ª•Êè≠Á§∫ MLLM ÁöÑÂÖ®Èù¢ËÉΩÂäõÔºõ4) Ê®ôË®ªÁöÑÂìÅË≥™ÔºåÂà©Áî®Â∞àÂÆ∂Ê®ôË®ªÂì°Âö¥Ë¨πÁöÑÊâãÂãïÊ®ôË®ªÔºå‰ª•Âà©Á≤æÁ¢∫‰∏îÂèØÈù†ÁöÑÊ®°ÂûãË©ï‰º∞„ÄÇ900 ÂÄãÂΩ±ÁâáÔºåÁ∏ΩÈï∑ÁÇ∫ 256 Â∞èÊôÇÔºåÈÄèÈÅéÈáçË§áËßÄÁúãÊâÄÊúâÂΩ±ÁâáÂÖßÂÆπÈÄ≤Ë°åÊâãÂãïÊåëÈÅ∏ÂíåÊ®ôË®ªÔºåÁî¢Áîü‰∫Ü 2,700 ÂÄãÂïèÁ≠îÈÖçÂ∞ç„ÄÇÈÄèÈÅé Video-MMEÔºåÊàëÂÄëÂª£Ê≥õË©ï‰º∞‰∫ÜÂêÑÁ®ÆÊúÄÂÖàÈÄ≤ÁöÑ MLLMÔºåÂåÖÊã¨ GPT-4 Á≥ªÂàóÂíå Gemini 1.5 ProÔºå‰ª•ÂèäÂÉè InternVL-Chat-V1.5 ÁöÑÈñãÊ∫êÂΩ±ÂÉèÊ®°ÂûãÂíå LLaVA-NeXT-Video ÁöÑÂΩ±ÁâáÊ®°Âûã„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÈ°ØÁ§∫ÔºåGemini 1.5 Pro ÊòØÊïàËÉΩÊúÄÂ•ΩÁöÑÂïÜÊ•≠Ê®°ÂûãÔºåÈ°ØËëóÂÑ™ÊñºÈñãÊ∫êÊ®°Âûã„ÄÇÊàëÂÄëÁöÑË≥áÊñôÈõÜÂíåÈÄô‰∫õÁôºÁèæÂº∑Ë™ø‰∫ÜÈÄ≤‰∏ÄÊ≠•ÊîπÈÄ≤ËôïÁêÜËºÉÈï∑È†ÜÂ∫èÂíåÂ§öÊ®°ÊÖãË≥áÊñôÁöÑÂøÖË¶ÅÊÄß„ÄÇÂ∞àÊ°àÈ†ÅÈù¢Ôºöhttps://video-mme.github.io

##### **Generalization Beyond Data Imbalance: A Controlled Study on CLIP for Transferable Insights**
2405.21070v1 by Xin Wen, Bingchen Zhao, Yilun Chen, Jiangmiao Pang, Xiaojuan Qi

Severe data imbalance naturally exists among web-scale vision-language
datasets. Despite this, we find CLIP pre-trained thereupon exhibits notable
robustness to the data imbalance compared to supervised learning, and
demonstrates significant effectiveness in learning generalizable
representations. With an aim to investigate the reasons behind this finding, we
conduct controlled experiments to study various underlying factors, and reveal
that CLIP's pretext task forms a dynamic classification problem wherein only a
subset of classes is present in training. This isolates the bias from dominant
classes and implicitly balances the learning signal. Furthermore, the
robustness and discriminability of CLIP improve with more descriptive language
supervision, larger data scale, and broader open-world concepts, which are
inaccessible to supervised learning. Our study not only uncovers the mechanisms
behind CLIP's generalizability beyond data imbalance but also provides
transferable insights for the research community. The findings are validated in
both supervised and self-supervised learning, enabling models trained on
imbalanced data to achieve CLIP-level performance on diverse recognition tasks.
Code will be available at: https://github.com/CVMI-Lab/clip-beyond-tail.

ÊëòË¶ÅÔºöÂö¥ÈáçÁöÑË≥áÊñô‰∏çÂπ≥Ë°°Ëá™ÁÑ∂Â≠òÂú®ÊñºÁ∂≤Ë∑ØË¶èÊ®°ÁöÑË¶ñË¶∫Ë™ûË®ÄË≥áÊñôÈõÜ‰∏≠„ÄÇÂÑòÁÆ°Â¶ÇÊ≠§ÔºåÊàëÂÄëÁôºÁèæÈ†êÂÖàË®ìÁ∑¥ÊñºÂÖ∂‰∏äÁöÑ CLIP Â∞çË≥áÊñô‰∏çÂπ≥Ë°°Â±ïÁèæÂá∫È°ØËëóÁöÑÁ©©ÂÅ•ÊÄßÔºåËàáÁõ£Áù£Â≠∏ÁøíÁõ∏ÊØîÔºå‰∏¶Â±ïÁèæÂá∫Â≠∏ÁøíÂèØÊ¶ÇÂåñË°®ÂæµÁöÑÈ°ØËëóÊïàËÉΩ„ÄÇÁÇ∫‰∫ÜË™øÊü•Ê≠§ÁôºÁèæËÉåÂæåÁöÑÂéüÂõ†ÔºåÊàëÂÄëÈÄ≤Ë°åÂèóÊéßÂØ¶È©ó‰ª•Á†îÁ©∂ÂêÑÁ®ÆÊΩõÂú®Âõ†Á¥†Ôºå‰∏¶Êè≠Á§∫ CLIP ÁöÑËóâÂè£‰ªªÂãôÂΩ¢Êàê‰∏ÄÂÄãÂãïÊÖãÂàÜÈ°ûÂïèÈ°åÔºåÂÖ∂‰∏≠Âè™Êúâ‰∏ÄÂÄãÂ≠êÈõÜÁöÑÈ°ûÂà•Â≠òÂú®ÊñºË®ìÁ∑¥‰∏≠„ÄÇÈÄôÊúÉÂæû‰∏ªË¶ÅÈ°ûÂà•‰∏≠ÂàÜÈõ¢Âá∫ÂÅèÂ∑ÆÔºå‰∏¶Èö±Âê´Âú∞Âπ≥Ë°°Â≠∏ÁøíË®äËôü„ÄÇÊ≠§Â§ñÔºåCLIP ÁöÑÁ©©ÂÅ•ÊÄßÂíåËæ®Âà•ÂäõÊúÉÈö®ËëóÊõ¥ÂÖ∑ÊèèËø∞ÊÄßÁöÑË™ûË®ÄÁõ£Áù£„ÄÅÊõ¥Â§ßÁöÑË≥áÊñôË¶èÊ®°ÂíåÊõ¥Âª£Ê≥õÁöÑÈñãÊîæ‰∏ñÁïåÊ¶ÇÂøµËÄåÊîπÂñÑÔºåËÄåÈÄô‰∫õÊ¶ÇÂøµÂ∞çÊñºÁõ£Áù£Â≠∏Áøí‰æÜË™™ÊòØÁÑ°Ê≥ïÂèñÂæóÁöÑ„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂‰∏çÂÉÖÊè≠Á§∫‰∫Ü CLIP Âú®Ë≥áÊñô‰∏çÂπ≥Ë°°‰πãÂ§ñÁöÑÊ¶ÇÂåñËÉΩÂäõËÉåÂæåÁöÑÊ©üÂà∂Ôºå‰πüÁÇ∫Á†îÁ©∂Á§æÁæ§Êèê‰æõ‰∫ÜÂèØËΩâÁßªÁöÑË¶ãËß£„ÄÇÈÄô‰∫õÁôºÁèæÂ∑≤Âú®Áõ£Áù£ÂºèÂíåËá™Áõ£Áù£ÂºèÂ≠∏Áøí‰∏≠ÂæóÂà∞È©óË≠âÔºåËÆìÂú®‰∏çÂπ≥Ë°°Ë≥áÊñô‰∏äË®ìÁ∑¥ÁöÑÊ®°ÂûãËÉΩÂ§†Âú®ÂêÑÁ®ÆËæ®Ë≠ò‰ªªÂãô‰∏≠ÈÅîÂà∞ CLIP Á≠âÁ¥öÁöÑÊïàËÉΩ„ÄÇÁ®ãÂºèÁ¢ºÂ∞áÊñº‰∏ãÂàó‰ΩçÁΩÆÊèê‰æõÔºöhttps://github.com/CVMI-Lab/clip-beyond-tail„ÄÇ

##### **Code Pretraining Improves Entity Tracking Abilities of Language Models**
2405.21068v1 by Najoung Kim, Sebastian Schuster, Shubham Toshniwal

Recent work has provided indirect evidence that pretraining language models
on code improves the ability of models to track state changes of discourse
entities expressed in natural language. In this work, we systematically test
this claim by comparing pairs of language models on their entity tracking
performance. Critically, the pairs consist of base models and models trained on
top of these base models with additional code data. We extend this analysis to
additionally examine the effect of math training, another highly structured
data type, and alignment tuning, an important step for enhancing the usability
of models. We find clear evidence that models additionally trained on large
amounts of code outperform the base models. On the other hand, we find no
consistent benefit of additional math training or alignment tuning across
various model families.

ÊëòË¶ÅÔºöÊúÄËøëÁöÑÁ†îÁ©∂Êèê‰æõ‰∫ÜÈñìÊé•Ë≠âÊìöÔºåË≠âÊòéÂú®Á®ãÂºèÁ¢º‰∏äÈ†êË®ìÁ∑¥Ë™ûË®ÄÊ®°ÂûãÔºåËÉΩÊèêÂçáÊ®°ÂûãËøΩËπ§Ëá™ÁÑ∂Ë™ûË®Ä‰∏≠Ë°®ÈÅîÁöÑÂ∞çË©±ÂØ¶È´îÁãÄÊÖãËÆäÂåñÁöÑËÉΩÂäõ„ÄÇÂú®ÈÄôÈ†ÖÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄëÁ≥ªÁµ±ÊÄßÂú∞Ê∏¨Ë©¶Ê≠§‰∏ªÂºµÔºåÊñπÊ≥ïÊòØÊØîËºÉË™ûË®ÄÊ®°ÂûãÈÖçÂ∞çÁöÑÂØ¶È´îËøΩËπ§Ë°®Áèæ„ÄÇËá≥ÈóúÈáçË¶ÅÁöÑÊòØÔºåÈÄô‰∫õÈÖçÂ∞çÂåÖÂê´Âü∫Á§éÊ®°ÂûãÂíåÂú®ÈÄô‰∫õÂü∫Á§éÊ®°Âûã‰∏äË®ìÁ∑¥ÁöÑÊ®°ÂûãÔºå‰∏¶Âä†ÂÖ•È°çÂ§ñÁöÑÁ®ãÂºèÁ¢ºË≥áÊñô„ÄÇÊàëÂÄëÂª∂‰º∏Ê≠§ÂàÜÊûêÔºå‰ª•ÈÄ≤‰∏ÄÊ≠•Ê™¢Ë¶ñÊï∏Â≠∏Ë®ìÁ∑¥ÁöÑÂΩ±ÈüøÔºåÂè¶‰∏ÄÁ®ÆÈ´òÂ∫¶ÁµêÊßãÂåñÁöÑË≥áÊñôÈ°ûÂûãÔºå‰ª•ÂèäÂ∞çÈΩäË™øÊï¥ÔºåÈÄôÊòØÂ¢ûÂº∑Ê®°ÂûãÂèØÁî®ÊÄßÁöÑÈáçË¶ÅÊ≠•È©ü„ÄÇÊàëÂÄëÁôºÁèæÊòéÁ¢∫ÁöÑË≠âÊìöÔºåË≠âÊòéÂú®Â§ßÈáèÁ®ãÂºèÁ¢º‰∏äÈ°çÂ§ñË®ìÁ∑¥ÁöÑÊ®°ÂûãÔºåË°®ÁèæÂÑ™ÊñºÂü∫Á§éÊ®°Âûã„ÄÇÂè¶‰∏ÄÊñπÈù¢ÔºåÊàëÂÄëÁôºÁèæÈ°çÂ§ñÁöÑÊï∏Â≠∏Ë®ìÁ∑¥ÊàñÂ∞çÈΩäË™øÊï¥ÔºåÂú®ÂêÑÁ®ÆÊ®°ÂûãÁ≥ªÂàó‰∏≠Ê≤íÊúâÂ∏∂‰æÜ‰∏ÄËá¥ÊÄßÁöÑÂ•ΩËôï„ÄÇ

##### **Recurrent neural networks: vanishing and exploding gradients are not the end of the story**
2405.21064v1 by Nicolas Zucchet, Antonio Orvieto

Recurrent neural networks (RNNs) notoriously struggle to learn long-term
memories, primarily due to vanishing and exploding gradients. The recent
success of state-space models (SSMs), a subclass of RNNs, to overcome such
difficulties challenges our theoretical understanding. In this paper, we delve
into the optimization challenges of RNNs and discover that, as the memory of a
network increases, changes in its parameters result in increasingly large
output variations, making gradient-based learning highly sensitive, even
without exploding gradients. Our analysis further reveals the importance of the
element-wise recurrence design pattern combined with careful parametrizations
in mitigating this effect. This feature is present in SSMs, as well as in other
architectures, such as LSTMs. Overall, our insights provide a new explanation
for some of the difficulties in gradient-based learning of RNNs and why some
architectures perform better than others.

ÊëòË¶ÅÔºöÈÅûËø¥Á•ûÁ∂ìÁ∂≤Ë∑Ø (RNN) ÊÉ°ÂêçÊò≠ÂΩ∞Âú∞Èõ£‰ª•Â≠∏ÁøíÈï∑ÊúüË®òÊÜ∂Ôºå‰∏ªË¶ÅÊòØÁî±ÊñºÊ∂àÂ§±ÂíåÁàÜÁÇ∏Ê¢ØÂ∫¶„ÄÇÊúÄËøëÔºå‰ΩúÁÇ∫ RNN Â≠êÈ°ûÁöÑÁãÄÊÖãÁ©∫ÈñìÊ®°Âûã (SSM) Âú®ÂÖãÊúçÊ≠§È°ûÂõ∞Èõ£ÊñπÈù¢Áç≤ÂæóÊàêÂäüÔºåÈÄôÊåëÊà∞‰∫ÜÊàëÂÄëÁöÑÁêÜË´ñÁêÜËß£„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊ∑±ÂÖ•Êé¢Ë®é RNN ÁöÑÊúÄ‰Ω≥ÂåñÊåëÊà∞Ôºå‰∏¶ÁôºÁèæÈö®ËëóÁ∂≤Ë∑ØË®òÊÜ∂ÁöÑÂ¢ûÂä†ÔºåÂÖ∂ÂèÉÊï∏ÁöÑËÆäÂåñÊúÉÂ∞éËá¥Ë∂ä‰æÜË∂äÂ§ßÁöÑËº∏Âá∫ËÆäÂåñÔºå‰ΩøÂæóÂü∫ÊñºÊ¢ØÂ∫¶ÁöÑÂ≠∏ÁøíÈ´òÂ∫¶ÊïèÊÑüÔºåÂç≥‰ΩøÊ≤íÊúâÁàÜÁÇ∏Ê¢ØÂ∫¶„ÄÇÊàëÂÄëÁöÑÂàÜÊûêÈÄ≤‰∏ÄÊ≠•Êè≠Á§∫‰∫ÜÈÄêÂÖÉÁ¥†ÈÅûËø¥Ë®≠Ë®àÊ®°ÂºèËàá‰ªîÁ¥∞ÂèÉÊï∏ÂåñÁõ∏ÁµêÂêàÂú®Ê∏õËºïÊ≠§ÊïàÊáâÊñπÈù¢ÁöÑÈáçË¶ÅÊÄß„ÄÇÊ≠§ÂäüËÉΩÂ≠òÂú®Êñº SSM ‰ª•ÂèäÂÖ∂‰ªñÊû∂Êßã‰∏≠Ôºå‰æãÂ¶Ç LSTM„ÄÇÁ∏ΩÈ´îËÄåË®ÄÔºåÊàëÂÄëÁöÑË¶ãËß£ÁÇ∫ RNN Âü∫ÊñºÊ¢ØÂ∫¶ÁöÑÂ≠∏Áøí‰∏≠ÁöÑ‰∏Ä‰∫õÂõ∞Èõ£Êèê‰æõ‰∫Ü‰∏ÄÂÄãÊñ∞ÁöÑËß£ÈáãÔºå‰∏¶Ë™™Êòé‰∫ÜÁÇ∫‰ªÄÈ∫ºÊüê‰∫õÊû∂ÊßãÁöÑË°®ÁèæÂÑ™ÊñºÂÖ∂‰ªñÊû∂Êßã„ÄÇ

##### **Grammar-Aligned Decoding**
2405.21047v1 by Kanghee Park, Jiayu Wang, Taylor Berg-Kirkpatrick, Nadia Polikarpova, Loris D'Antoni

Large Language Models (LLMs) struggle with reliably generating highly
structured outputs, such as program code, mathematical formulas, or well-formed
markup. Constrained decoding approaches mitigate this problem by greedily
restricting what tokens an LLM can output at each step to guarantee that the
output matches a given constraint. Specifically, in grammar-constrained
decoding (GCD), the LLM's output must follow a given grammar. In this paper we
demonstrate that GCD techniques (and in general constrained decoding
techniques) can distort the LLM's distribution, leading to outputs that are
grammatical but appear with likelihoods that are not proportional to the ones
given by the LLM, and so ultimately are low-quality. We call the problem of
aligning sampling with a grammar constraint, grammar-aligned decoding (GAD),
and propose adaptive sampling with approximate expected futures (ASAp), a
decoding algorithm that guarantees the output to be grammatical while provably
producing outputs that match the conditional probability of the LLM's
distribution conditioned on the given grammar constraint. Our algorithm uses
prior sample outputs to soundly overapproximate the future grammaticality of
different output prefixes. Our evaluation on code generation and structured NLP
tasks shows how ASAp often produces outputs with higher likelihood (according
to the LLM's distribution) than existing GCD techniques, while still enforcing
the desired grammatical constraints.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Èõ£‰ª•ÂèØÈù†Âú∞ÁîüÊàêÈ´òÂ∫¶ÁµêÊßãÂåñÁöÑËº∏Âá∫Ôºå‰æãÂ¶ÇÁ®ãÂºèÁ¢º„ÄÅÊï∏Â≠∏ÂÖ¨ÂºèÊàñÊ†ºÂºèËâØÂ•ΩÁöÑÊ®ôË®ò„ÄÇÂèóÈôêËß£Á¢ºÊñπÊ≥ïÈÄèÈÅéË≤™Â©™Âú∞ÈôêÂà∂ LLM Âú®ÊØèÂÄãÊ≠•È©ü‰∏≠ÂèØ‰ª•Ëº∏Âá∫ÁöÑÁ¨¶Ëôü‰æÜÊ∏õËºïÊ≠§ÂïèÈ°åÔºå‰ª•Á¢∫‰øùËº∏Âá∫Á¨¶ÂêàÁµ¶ÂÆöÁöÑÁ¥ÑÊùü„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÂú®Ë™ûÊ≥ïÁ¥ÑÊùüËß£Á¢º (GCD) ‰∏≠ÔºåLLM ÁöÑËº∏Âá∫ÂøÖÈ†àÈÅµÂæ™Áµ¶ÂÆöÁöÑË™ûÊ≥ï„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëË≠âÊòé GCD ÊäÄË°ìÔºà‰ª•Âèä‰∏ÄËà¨ÁöÑÁ¥ÑÊùüËß£Á¢ºÊäÄË°ìÔºâÊúÉÊâ≠Êõ≤ LLM ÁöÑÂàÜ‰ΩàÔºåÂ∞éËá¥Ë™ûÊ≥ïÊ≠£Á¢∫‰ΩÜÂá∫ÁèæÊ©üÁéáËàá LLM Áµ¶Âá∫ÁöÑÊ©üÁéá‰∏çÊàêÊØî‰æãÁöÑËº∏Âá∫ÔºåÂõ†Ê≠§ÊúÄÁµÇÂìÅË≥™‰∏ç‰Ω≥„ÄÇÊàëÂÄëÂ∞áÂ∞çÈΩäÊäΩÊ®£ËàáË™ûÊ≥ïÁ¥ÑÊùüÁöÑÂïèÈ°åÁ®±ÁÇ∫Ë™ûÊ≥ïÂ∞çÈΩäËß£Á¢º (GAD)Ôºå‰∏¶ÊèêÂá∫ÂÖ∑ÊúâËøë‰ººÈ†êÊúüÊú™‰æÜÁöÑËá™ÈÅ©ÊáâÊäΩÊ®£ (ASAp)ÔºåÈÄôÊòØ‰∏ÄÁ®ÆËß£Á¢ºÊºîÁÆóÊ≥ïÔºåÂèØ‰øùË≠âËº∏Âá∫Ë™ûÊ≥ïÊ≠£Á¢∫ÔºåÂêåÊôÇÂèØË≠âÊòéÁî¢ÁîüËàá LLM ÂàÜ‰ΩàÊ¢ù‰ª∂Ê©üÁéáÁõ∏Á¨¶ÁöÑËº∏Âá∫ÔºåÊ¢ù‰ª∂ÁÇ∫Áµ¶ÂÆöÁöÑË™ûÊ≥ïÁ¥ÑÊùü„ÄÇÊàëÂÄëÁöÑÊºîÁÆóÊ≥ï‰ΩøÁî®ÂÖàÂâçÁöÑÊ®£Êú¨Ëº∏Âá∫Ôºå‰ª•ÂÅ•ÂÖ®Âú∞ÈÅéÂ∫¶Ëøë‰ºº‰∏çÂêåËº∏Âá∫ÂâçÁ∂¥ÁöÑÊú™‰æÜË™ûÊ≥ïÊÄß„ÄÇÊàëÂÄëÂ∞çÁ®ãÂºèÁ¢ºÁîüÊàêÂíåÁµêÊßãÂåñ NLP ‰ªªÂãôÁöÑË©ï‰º∞È°ØÁ§∫ÔºåËàáÁèæÊúâÁöÑ GCD ÊäÄË°ìÁõ∏ÊØîÔºåASAp ÈÄöÂ∏∏ÊúÉÁî¢ÁîüÂÖ∑ÊúâÊõ¥È´òÊ©üÁéáÔºàÊ†πÊìö LLM ÁöÑÂàÜ‰ΩàÔºâÁöÑËº∏Âá∫ÔºåÂêåÊôÇ‰ªçÂº∑Âà∂Âü∑Ë°åÊâÄÈúÄÁöÑË™ûÊ≥ïÁ¥ÑÊùü„ÄÇ

##### **Exploratory Preference Optimization: Harnessing Implicit Q*-Approximation for Sample-Efficient RLHF**
2405.21046v1 by Tengyang Xie, Dylan J. Foster, Akshay Krishnamurthy, Corby Rosset, Ahmed Awadallah, Alexander Rakhlin

Reinforcement learning from human feedback (RLHF) has emerged as a central
tool for language model alignment. We consider online exploration in RLHF,
which exploits interactive access to human or AI feedback by deliberately
encouraging the model to produce diverse, maximally informative responses. By
allowing RLHF to confidently stray from the pre-trained model, online
exploration offers the possibility of novel, potentially super-human
capabilities, but its full potential as a paradigm for language model training
has yet to be realized, owing to computational and statistical bottlenecks in
directly adapting existing reinforcement learning techniques. We propose a new
algorithm for online exploration in RLHF, Exploratory Preference Optimization
(XPO), which is simple and practical -- a one-line change to (online) Direct
Preference Optimization (DPO; Rafailov et al., 2023) -- yet enjoys the
strongest known provable guarantees and promising empirical performance. XPO
augments the DPO objective with a novel and principled exploration bonus,
empowering the algorithm to explore outside the support of the initial model
and human feedback data. In theory, we show that XPO is provably
sample-efficient and converges to a near-optimal language model policy under
natural exploration conditions, irrespective of whether the initial model has
good coverage. Our analysis, which builds on the observation that DPO
implicitly performs a form of $Q^{\star}$-approximation (or, Bellman error
minimization), combines previously disparate techniques from language modeling
and theoretical reinforcement learning in a serendipitous fashion through the
perspective of KL-regularized Markov decision processes. Empirically, we find
that XPO is more sample-efficient than non-exploratory DPO variants in a
preliminary evaluation.

ÊëòË¶ÅÔºö‰∫∫È°ûÂõûÈ•ãÂº∑ÂåñÂ≠∏Áøí (RLHF) Â∑≤ÊàêÁÇ∫Ë™ûË®ÄÊ®°ÂûãÂ∞çÈΩäÁöÑÊ†∏ÂøÉÂ∑•ÂÖ∑„ÄÇÊàëÂÄëËÄÉÊÖÆ RLHF ‰∏≠ÁöÑÁ∑ö‰∏äÊé¢Á¥¢ÔºåÂÆÉÈÄèÈÅéÊïÖÊÑèÈºìÂãµÊ®°ÂûãÁî¢ÁîüÂ§öÊ®£Âåñ„ÄÅÊ•µÂÖ∑Ë≥áË®äÊÄßÁöÑÂõûÊáâÔºå‰æÜÂñÑÁî®Ëàá‰∫∫È°ûÊàñ AI ÂõûÈ•ãÁöÑ‰∫íÂãïÂ≠òÂèñ„ÄÇÈÄèÈÅéÂÖÅË®± RLHF Ëá™‰ø°Âú∞ÂÅèÈõ¢È†êÂÖàË®ìÁ∑¥ÁöÑÊ®°ÂûãÔºåÁ∑ö‰∏äÊé¢Á¥¢Êèê‰æõ‰∫ÜÊñ∞Á©é„ÄÅÊΩõÂú®Ë∂ÖË∂ä‰∫∫È°ûÁöÑËÉΩÂäõÔºå‰ΩÜÁî±ÊñºÂú®Áõ¥Êé•Ë™øÊï¥ÁèæÊúâÂº∑ÂåñÂ≠∏ÁøíÊäÄË°ìÊôÇÊúÉÈÅáÂà∞ÈÅãÁÆóÂíåÁµ±Ë®àÁì∂È†∏ÔºåÂõ†Ê≠§ÂÆÉ‰ΩúÁÇ∫Ë™ûË®ÄÊ®°ÂûãË®ìÁ∑¥ÂÖ∏ÁØÑÁöÑÂÖ®ÈÉ®ÊΩõÂäõÂ∞öÊú™ÂØ¶Áèæ„ÄÇÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞ÁöÑ RLHF Á∑ö‰∏äÊé¢Á¥¢ÊºîÁÆóÊ≥ïÔºåÊé¢Á¥¢ÊÄßÂÅèÂ•ΩÊúÄ‰Ω≥Âåñ (XPO)ÔºåÂÆÉÁ∞°ÂñÆ‰∏îÂØ¶Áî®ÔºåÂè™ÈúÄÂ∞ç (Á∑ö‰∏ä) Áõ¥Êé•ÂÅèÂ•ΩÊúÄ‰Ω≥Âåñ (DPOÔºõRafailov Á≠â‰∫∫Ôºå2023 Âπ¥) ÈÄ≤Ë°å‰∏ÄË°åËÆäÊõ¥Ôºå‰ΩÜÂçª‰∫´ÊúâÂ∑≤Áü•ÊúÄÂº∑Â§ßÁöÑÂèØË≠âÊòé‰øùË≠âÂíåÊúâÂâçÈÄîÁöÑÁ∂ìÈ©óÊïàËÉΩ„ÄÇXPO ‰ª•Êñ∞Á©é‰∏îÊúâÂéüÂâáÁöÑÊé¢Á¥¢ÁçéÂãµ‰æÜÊì¥ÂÖÖ DPO ÁõÆÊ®ôÔºåË≥¶‰∫àÊºîÁÆóÊ≥ïÂú®ÂàùÂßãÊ®°ÂûãÂíå‰∫∫È°ûÂõûÈ•ãË≥áÊñôÁöÑÊîØÊåÅÂ§ñÊé¢Á¥¢ÁöÑËÉΩÂäõ„ÄÇÂú®ÁêÜË´ñ‰∏äÔºåÊàëÂÄëË≠âÊòé XPO Âú®Ëá™ÁÑ∂Êé¢Á¥¢Ê¢ù‰ª∂‰∏ãÔºåÁÑ°Ë´ñÂàùÂßãÊ®°ÂûãÊòØÂê¶ÊúâËâØÂ•ΩÁöÑÊ∂µËìãÁØÑÂúçÔºåÈÉΩÂèØË≠âÊòéÂÖ∑ÊúâÊ®£Êú¨ÊïàÁéáÔºå‰∏¶Êî∂ÊñÇÂà∞Êé•ËøëÊúÄ‰Ω≥ÁöÑË™ûË®ÄÊ®°ÂûãÊîøÁ≠ñ„ÄÇÊàëÂÄëÁöÑÂàÜÊûêÂª∫Á´ãÂú® DPO Èö±Âê´Âü∑Ë°å‰∏ÄÁ®ÆÂΩ¢ÂºèÁöÑ $Q^{\star}$-Ëøë‰ººÔºàÊàñ Bellman Ë™§Â∑ÆÊúÄÂ∞èÂåñÔºâÁöÑËßÄÂØü‰∏äÔºåÂÆÉÈÄèÈÅé KL Ê≠£Ë¶èÂåñÈ¶¨ÂèØÂ§´Ê±∫Á≠ñÈÅéÁ®ãÁöÑËßíÂ∫¶Ôºå‰ª•‰∏ÄÁ®ÆÊÑèÂ§ñÁöÑÊñπÂºèÁµêÂêà‰∫ÜË™ûË®ÄÂª∫Ê®°ÂíåÁêÜË´ñÂº∑ÂåñÂ≠∏Áøí‰∏≠ÂÖàÂâç‰∏çÂêåÁöÑÊäÄË°ì„ÄÇÂú®Á∂ìÈ©ó‰∏äÔºåÊàëÂÄëÁôºÁèæ XPO Âú®ÂàùÊ≠•Ë©ï‰º∞‰∏≠ÊØîÈùûÊé¢Á¥¢ÊÄß DPO ËÆäÈ´îÊõ¥ÂÖ∑Ê®£Êú¨ÊïàÁéá„ÄÇ

##### **Target Networks and Over-parameterization Stabilize Off-policy Bootstrapping with Function Approximation**
2405.21043v1 by Fengdi Che, Chenjun Xiao, Jincheng Mei, Bo Dai, Ramki Gummadi, Oscar A Ramirez, Christopher K Harris, A. Rupam Mahmood, Dale Schuurmans

We prove that the combination of a target network and over-parameterized
linear function approximation establishes a weaker convergence condition for
bootstrapped value estimation in certain cases, even with off-policy data. Our
condition is naturally satisfied for expected updates over the entire
state-action space or learning with a batch of complete trajectories from
episodic Markov decision processes. Notably, using only a target network or an
over-parameterized model does not provide such a convergence guarantee.
Additionally, we extend our results to learning with truncated trajectories,
showing that convergence is achievable for all tasks with minor modifications,
akin to value truncation for the final states in trajectories. Our primary
result focuses on temporal difference estimation for prediction, providing
high-probability value estimation error bounds and empirical analysis on
Baird's counterexample and a Four-room task. Furthermore, we explore the
control setting, demonstrating that similar convergence conditions apply to
Q-learning.

ÊëòË¶ÅÔºöÊàëÂÄëË≠âÊòéÁõÆÊ®ôÁ∂≤Ë∑ØËàáÈÅéÂ∫¶ÂèÉÊï∏ÂåñÁöÑÁ∑öÊÄßÂáΩÊï∏Ëøë‰ººÁõ∏ÁµêÂêàÔºåÂú®Êüê‰∫õÊÉÖÊ≥Å‰∏ãÔºåÂç≥‰Ωø‰ΩøÁî®ÈùûÁ≠ñÁï•Ë≥áÊñôÔºå‰πüËÉΩÁÇ∫ÂºïÂ∞éÂÄº‰º∞Ë®àÂª∫Á´ãËºÉÂº±ÁöÑÊî∂ÊñÇÊ¢ù‰ª∂„ÄÇÊàëÂÄëÁöÑÊ¢ù‰ª∂Ëá™ÁÑ∂ÈÅ©Áî®ÊñºÊï¥ÂÄãÁãÄÊÖãÂãï‰ΩúÁ©∫Èñì‰∏äÁöÑÈ†êÊúüÊõ¥Êñ∞ÔºåÊàñ‰ΩøÁî®‰æÜËá™ÊÉÖÂ¢ÉÈ¶¨ÂèØÂ§´Ê±∫Á≠ñÈÅéÁ®ãÁöÑ‰∏ÄÊâπÂÆåÊï¥ËªåË∑°ÈÄ≤Ë°åÂ≠∏Áøí„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÂÉÖ‰ΩøÁî®ÁõÆÊ®ôÁ∂≤Ë∑ØÊàñÈÅéÂ∫¶ÂèÉÊï∏ÂåñÁöÑÊ®°ÂûãÁÑ°Ê≥ïÊèê‰æõÈÄôÊ®£ÁöÑÊî∂ÊñÇ‰øùË≠â„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂ∞áÁµêÊûúÂª∂‰º∏Âà∞‰ΩøÁî®Êà™Êñ∑ËªåË∑°ÈÄ≤Ë°åÂ≠∏ÁøíÔºåË°®ÊòéÂ∞çÊâÄÊúâ‰ªªÂãôÈÄ≤Ë°åËºïÂæÆ‰øÆÊîπÂç≥ÂèØÂØ¶ÁèæÊî∂ÊñÇÔºåÈ°û‰ººÊñºËªåË∑°‰∏≠ÊúÄÁµÇÁãÄÊÖãÁöÑÂÉπÂÄºÊà™Êñ∑„ÄÇÊàëÂÄëÁöÑÈ¶ñË¶ÅÁµêÊûúËëóÈáçÊñºÈ†êÊ∏¨ÁöÑÊôÇÂ∫èÂ∑ÆÂàÜ‰º∞Ë®àÔºåÊèê‰æõÈ´òÊ©üÁéáÂÄº‰º∞Ë®àË™§Â∑ÆÈÇäÁïåÂíåË≤ùÁàæÂæ∑Âèç‰æãËàáÂõõÊàøÈñì‰ªªÂãôÁöÑÂØ¶Ë≠âÂàÜÊûê„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊé¢Á¥¢ÊéßÂà∂Ë®≠ÂÆöÔºåË≠âÊòéÈ°û‰ººÁöÑÊî∂ÊñÇÊ¢ù‰ª∂ÈÅ©Áî®Êñº Q Â≠∏Áøí„ÄÇ

##### **Direct Alignment of Language Models via Quality-Aware Self-Refinement**
2405.21040v1 by Runsheng Yu, Yong Wang, Xiaoqi Jiao, Youzhi Zhang, James T. Kwok

Reinforcement Learning from Human Feedback (RLHF) has been commonly used to
align the behaviors of Large Language Models (LLMs) with human preferences.
Recently, a popular alternative is Direct Policy Optimization (DPO), which
replaces an LLM-based reward model with the policy itself, thus obviating the
need for extra memory and training time to learn the reward model. However, DPO
does not consider the relative qualities of the positive and negative
responses, and can lead to sub-optimal training outcomes. To alleviate this
problem, we investigate the use of intrinsic knowledge within the on-the-fly
fine-tuning LLM to obtain relative qualities and help to refine the loss
function. Specifically, we leverage the knowledge of the LLM to design a
refinement function to estimate the quality of both the positive and negative
responses. We show that the constructed refinement function can help
self-refine the loss function under mild assumptions. The refinement function
is integrated into DPO and its variant Identity Policy Optimization (IPO).
Experiments across various evaluators indicate that they can improve the
performance of the fine-tuned models over DPO and IPO.

ÊëòË¶ÅÔºö‰∫∫È°ûÂõûÈ•ãÂº∑ÂåñÂ≠∏Áøí (RLHF) Â∏∏Áî®ÊñºË™øÊï¥Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑË°åÁÇ∫‰ª•Á¨¶Âêà‰∫∫È°ûÂÅèÂ•Ω„ÄÇÊúÄËøëÔºå‰∏ÄÁ®ÆÊµÅË°åÁöÑÊõø‰ª£ÊñπÊ°àÊòØÁõ¥Êé•Á≠ñÁï•ÊúÄ‰Ω≥Âåñ (DPO)ÔºåÂÆÉ‰ΩøÁî®Á≠ñÁï•Êú¨Ë∫´Âèñ‰ª£Âü∫Êñº LLM ÁöÑÁçéÂãµÊ®°ÂûãÔºåÂæûËÄåÈÅøÂÖç‰∫ÜÂ≠∏ÁøíÁçéÂãµÊ®°ÂûãÊâÄÈúÄÁöÑÈ°çÂ§ñË®òÊÜ∂È´îÂíåË®ìÁ∑¥ÊôÇÈñì„ÄÇÁÑ∂ËÄåÔºåDPO Ê≤íÊúâËÄÉÊÖÆÊ≠£Èù¢ÂíåË≤†Èù¢ÂõûÊáâÁöÑÁõ∏Â∞çÂìÅË≥™Ôºå‰∏¶‰∏îÂèØËÉΩÂ∞éËá¥Ê¨°‰Ω≥ÁöÑË®ìÁ∑¥ÁµêÊûú„ÄÇÁÇ∫‰∫ÜÊ∏õËºïÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÊé¢Ë®éÂú®Âç≥ÊôÇÂæÆË™ø LLM ‰∏≠‰ΩøÁî®ÂÖßÂú®Áü•Ë≠ò‰ª•ÂèñÂæóÁõ∏Â∞çÂìÅË≥™‰∏¶Âπ´Âä©ÊîπÂñÑÊêçÂ§±ÂáΩÊï∏„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÂà©Áî® LLM ÁöÑÁü•Ë≠ò‰æÜË®≠Ë®à‰∏ÄÂÄãÊîπÂñÑÂáΩÊï∏Ôºå‰ª•‰º∞Ë®àÊ≠£Èù¢ÂíåË≤†Èù¢ÂõûÊáâÁöÑÂìÅË≥™„ÄÇÊàëÂÄëË°®ÊòéÔºåÊâÄÂª∫ÊßãÁöÑÊîπÂñÑÂáΩÊï∏ÂèØ‰ª•Âú®Ê∫´ÂíåÁöÑÂÅáË®≠‰∏ãÂπ´Âä©Ëá™ÊàëÊîπÂñÑÊêçÂ§±ÂáΩÊï∏„ÄÇÊîπÂñÑÂáΩÊï∏Êï¥ÂêàÂà∞ DPO ÂèäÂÖ∂ËÆäÈ´îË∫´ÂàÜÁ≠ñÁï•ÊúÄ‰Ω≥Âåñ (IPO) ‰∏≠„ÄÇÂú®ÂêÑÁ®ÆË©ï‰º∞ËÄÖ‰∏≠ÁöÑÂØ¶È©óË°®ÊòéÔºåÂÆÉÂÄëÂèØ‰ª•ÊîπÂñÑÂæÆË™øÊ®°ÂûãÂú® DPO Âíå IPO ‰∏äÁöÑÊïàËÉΩ„ÄÇ

##### **Standards for Belief Representations in LLMs**
2405.21030v1 by Daniel A. Herrmann, Benjamin A. Levinstein

As large language models (LLMs) continue to demonstrate remarkable abilities
across various domains, computer scientists are developing methods to
understand their cognitive processes, particularly concerning how (and if) LLMs
internally represent their beliefs about the world. However, this field
currently lacks a unified theoretical foundation to underpin the study of
belief in LLMs. This article begins filling this gap by proposing adequacy
conditions for a representation in an LLM to count as belief-like. We argue
that, while the project of belief measurement in LLMs shares striking features
with belief measurement as carried out in decision theory and formal
epistemology, it also differs in ways that should change how we measure belief.
Thus, drawing from insights in philosophy and contemporary practices of machine
learning, we establish four criteria that balance theoretical considerations
with practical constraints. Our proposed criteria include accuracy, coherence,
uniformity, and use, which together help lay the groundwork for a comprehensive
understanding of belief representation in LLMs. We draw on empirical work
showing the limitations of using various criteria in isolation to identify
belief representations.

ÊëòË¶ÅÔºöÈö®ËëóÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÊåÅÁ∫åÂ±ïÁèæÂÖ∂Âú®ÂêÑÁ®ÆÈ†òÂüüÁöÑÈ©ö‰∫∫ÂäüËÉΩÔºåÈõªËÖ¶ÁßëÂ≠∏ÂÆ∂Ê≠£Âú®ÈñãÁôºÊñπÊ≥ï‰æÜ‰∫ÜËß£ÂÖ∂Ë™çÁü•ÈÅéÁ®ãÔºåÁâπÂà•ÊòØÈóúÊñº LLM Â¶Ç‰ΩïÔºà‰ª•ÂèäÊòØÂê¶ÔºâÂú®ÂÖßÈÉ®Ë°®Á§∫ÂÖ∂Â∞ç‰∏ñÁïåÁöÑ‰ø°Âøµ„ÄÇÁÑ∂ËÄåÔºåÈÄôÂÄãÈ†òÂüüÁõÆÂâçÁº∫‰πèÁµ±‰∏ÄÁöÑÁêÜË´ñÂü∫Á§é‰æÜÊîØÊåÅÂ∞ç LLM ‰∏≠‰ø°ÂøµÁöÑÁ†îÁ©∂„ÄÇÊú¨ÊñáÈÄöÈÅéÊèêÂá∫ LLM ‰∏≠Ë°®ÂæµÁöÑÂÖÖÂàÜÊ¢ù‰ª∂‰æÜÁÆó‰ΩúÈ°û‰ø°ÂøµÔºåÈñãÂßãÂ°´Ë£úÈÄôÂÄãÁ©∫ÁôΩ„ÄÇÊàëÂÄëË™çÁÇ∫ÔºåÂÑòÁÆ° LLM ‰∏≠‰ø°ÂøµÊ∏¨ÈáèÂ∞àÊ°àËàáÊ±∫Á≠ñÁêÜË´ñÂíåÂΩ¢ÂºèË™çË≠òË´ñ‰∏≠Âü∑Ë°åÁöÑ‰ø°ÂøµÊ∏¨ÈáèÊúâÈ©ö‰∫∫ÁöÑÁâπÂæµÔºå‰ΩÜÂÆÉÂú®ÊàëÂÄëÊ∏¨Èáè‰ø°ÂøµÁöÑÊñπÂºè‰∏ä‰πüÊúâÊâÄ‰∏çÂêå„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëÂæûÂì≤Â≠∏ÂíåÊ©üÂô®Â≠∏ÁøíÁöÑÁï∂‰ª£ÂØ¶Âãô‰∏≠Ê±≤ÂèñË¶ãËß£ÔºåÂª∫Á´ã‰∫ÜÂõõÂÄãÂπ≥Ë°°ÁêÜË´ñËÄÉÈáèËàáÂØ¶ÈöõÈôêÂà∂ÁöÑÊ®ôÊ∫ñ„ÄÇÊàëÂÄëÊèêÂá∫ÁöÑÊ®ôÊ∫ñÂåÖÊã¨Ê∫ñÁ¢∫ÊÄß„ÄÅ‰∏ÄËá¥ÊÄß„ÄÅÂùáÂãªÊÄßÂíåÁî®ÈÄîÔºåÈÄô‰∫õÊ®ôÊ∫ñÂÖ±ÂêåÁÇ∫ÂÖ®Èù¢‰∫ÜËß£ LLM ‰∏≠ÁöÑ‰ø°ÂøµË°®ÂæµÂ•†ÂÆöÂü∫Á§é„ÄÇÊàëÂÄë‰æùÊìöÁ∂ìÈ©óÂ∑•‰ΩúÔºåÈ°ØÁ§∫Â≠§Á´ã‰ΩøÁî®ÂêÑÁ®ÆÊ®ôÊ∫ñ‰æÜË≠òÂà•‰ø°ÂøµË°®ÂæµÁöÑÈôêÂà∂„ÄÇ

##### **LACIE: Listener-Aware Finetuning for Confidence Calibration in Large Language Models**
2405.21028v1 by Elias Stengel-Eskin, Peter Hase, Mohit Bansal

When answering questions, LLMs can convey not only an answer, but a level of
confidence about the answer being correct. This includes explicit confidence
markers (e.g. giving a numeric score) as well as implicit markers, like an
authoritative tone or elaborating with additional knowledge. For LLMs to be
trustworthy knowledge sources, the confidence they convey should match their
actual expertise; however, most current models tend towards overconfidence. To
calibrate both implicit and explicit confidence markers, we introduce a
pragmatic, listener-aware finetuning method (LACIE) that models the listener,
considering not only whether an answer is right, but whether it will be
accepted by a listener. We cast calibration as preference optimization,
creating data via a two-agent game, where a speaker model's outputs are judged
by a simulated listener. We then finetune three LLMs (Mistral-7B, Llama3-8B,
Llama3-70B) with LACIE, and show that the resulting models are better
calibrated w.r.t. a simulated listener. Crucially, these trends transfer to
human listeners, helping them correctly predict model correctness: we conduct a
human evaluation where annotators accept or reject an LLM's answers, finding
that training with LACIE results in 47% fewer incorrect answers being accepted
while maintaining the same level of acceptance for correct answers.
Furthermore, LACIE generalizes to another dataset, resulting in a large
increase in truthfulness on TruthfulQA when trained on TriviaQA. Our analysis
indicates that LACIE leads to a better confidence separation between correct
and incorrect examples. Qualitatively, we find that a LACIE-trained model
hedges more and implicitly signals certainty when it is correct by using an
authoritative tone or including details. Finally, LACIE finetuning leads to an
emergent increase in model abstention (e.g. saying "I don't know") for answers
that are likely wrong.

ÊëòË¶ÅÔºöÂú®ÂõûÁ≠îÂïèÈ°åÊôÇÔºåLLM ‰∏çÂÉÖÂèØ‰ª•ÂÇ≥ÈÅîÁ≠îÊ°àÔºåÈÇÑÂèØ‰ª•ÂÇ≥ÈÅîÂ∞çÁ≠îÊ°àÊ≠£Á¢∫ÊÄßÁöÑ‰ø°ÂøÉÁ®ãÂ∫¶„ÄÇÈÄôÂåÖÊã¨ÊòéÁ¢∫ÁöÑ‰ø°ÂøÉÊ®ôË®òÔºà‰æãÂ¶ÇÁµ¶Âá∫Êï∏Â≠óÂàÜÊï∏Ôºâ‰ª•ÂèäÈö±Âê´ÁöÑÊ®ôË®òÔºå‰æãÂ¶ÇÊ¨äÂ®ÅÁöÑË™ûÊ∞£ÊàñÁî®È°çÂ§ñÁöÑÁü•Ë≠òÈÄ≤Ë°åÈó°Ëø∞„ÄÇÂ∞çÊñº LLM ‰æÜË™™ÔºåË¶ÅÊàêÁÇ∫ÂÄºÂæó‰ø°Ë≥¥ÁöÑÁü•Ë≠ò‰æÜÊ∫êÔºåÂÆÉÂÄëÂÇ≥ÈÅîÁöÑ‰ø°ÂøÉÊáâËàáÂÆÉÂÄëÁöÑÂØ¶ÈöõÂ∞àÊ•≠Áü•Ë≠òÁõ∏ÂåπÈÖçÔºõÁÑ∂ËÄåÔºåÂ§ßÂ§öÊï∏Áï∂ÂâçÊ®°ÂûãÈÉΩÂÇæÂêëÊñºÈÅéÂ∫¶Ëá™‰ø°„ÄÇÁÇ∫‰∫ÜÊ†°Ê∫ñÈö±Âê´ÂíåÊòéÁ¢∫ÁöÑ‰ø°ÂøÉÊ®ôË®òÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÁ®ÆÂØ¶Áî®ÁöÑ„ÄÅËÄÉÊÖÆËÅΩÁúæÁöÑÂæÆË™øÊñπÊ≥ï (LACIE)ÔºåË©≤ÊñπÊ≥ïÂ∞çËÅΩÁúæÈÄ≤Ë°åÂª∫Ê®°Ôºå‰∏çÂÉÖËÄÉÊÖÆÁ≠îÊ°àÊòØÂê¶Ê≠£Á¢∫ÔºåÈÇÑËÄÉÊÖÆÁ≠îÊ°àÊòØÂê¶ÊúÉË¢´ËÅΩÁúæÊé•Âèó„ÄÇÊàëÂÄëÂ∞áÊ†°Ê∫ñË¶ñÁÇ∫ÂÅèÂ•ΩÂÑ™ÂåñÔºåÈÄöÈÅé‰∏ÄÂ†¥Èõô‰∫∫ÈÅäÊà≤ÂâµÂª∫Êï∏ÊìöÔºåÂÖ∂‰∏≠Ë™™Ë©±ËÄÖÊ®°ÂûãÁöÑËº∏Âá∫Áî±Ê®°Êì¨ËÅΩÁúæ‰æÜÂà§Êñ∑„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄë‰ΩøÁî® LACIE Â∞ç‰∏âÂÄã LLMÔºàMistral-7B„ÄÅLlama3-8B„ÄÅLlama3-70BÔºâÈÄ≤Ë°åÂæÆË™øÔºå‰∏¶Ë°®ÊòéÁî±Ê≠§Áî¢ÁîüÁöÑÊ®°ÂûãÂú®Ê®°Êì¨ËÅΩÁúæÊñπÈù¢Ê†°Ê∫ñÂæóÊõ¥Â•Ω„ÄÇËá≥ÈóúÈáçË¶ÅÁöÑÊòØÔºåÈÄô‰∫õË∂®Âã¢ÊúÉÂÇ≥ÈÅûÁµ¶‰∫∫È°ûËÅΩÁúæÔºåÂπ´Âä©‰ªñÂÄëÊ≠£Á¢∫È†êÊ∏¨Ê®°ÂûãÁöÑÊ≠£Á¢∫ÊÄßÔºöÊàëÂÄëÈÄ≤Ë°å‰∫Ü‰∏ÄÈ†Ö‰∫∫È°ûË©ï‰º∞ÔºåÂÖ∂‰∏≠Ë®ªÈáãËÄÖÊé•ÂèóÊàñÊãíÁµï LLM ÁöÑÁ≠îÊ°àÔºåÁôºÁèæ‰ΩøÁî® LACIE ÈÄ≤Ë°åË®ìÁ∑¥Â∞éËá¥Êé•ÂèóÁöÑÈåØË™§Á≠îÊ°àÊ∏õÂ∞ë‰∫Ü 47%ÔºåÂêåÊôÇ‰øùÊåÅ‰∫ÜÂ∞çÊ≠£Á¢∫Á≠îÊ°àÁöÑÁõ∏ÂêåÊé•ÂèóÁ®ãÂ∫¶„ÄÇÊ≠§Â§ñÔºåLACIE ÂèØ‰ª•Êé®Âª£Âà∞Âè¶‰∏ÄÂÄãÊï∏ÊìöÈõÜÔºåÂæûËÄåÂú® TruthfulQA ‰∏äË®ìÁ∑¥ÊôÇÂ§ßÂ§ßÊèêÈ´ò‰∫ÜÁúüÂØ¶ÊÄß„ÄÇÊàëÂÄëÁöÑÂàÜÊûêË°®ÊòéÔºåLACIE Â∞éËá¥Ê≠£Á¢∫Âíå‰∏çÊ≠£Á¢∫Á§∫‰æã‰πãÈñìÁöÑ‰ø°ÂøÉÂàÜÈõ¢Êõ¥Â•Ω„ÄÇÂæûË≥™Èáè‰∏äË¨õÔºåÊàëÂÄëÁôºÁèæ LACIE Ë®ìÁ∑¥ÁöÑÊ®°ÂûãÊúÉÊõ¥Â§öÂú∞Ëø¥ÈÅøÔºå‰∏¶Âú®Ê≠£Á¢∫ÊôÇÈÄöÈÅé‰ΩøÁî®Ê¨äÂ®ÅÁöÑË™ûÊ∞£ÊàñÂåÖÂê´Á¥∞ÁØÄ‰æÜÊöóÁ§∫Á¢∫ÂÆöÊÄß„ÄÇÊúÄÂæåÔºåLACIE ÂæÆË™øÂ∞éËá¥Ê®°ÂûãÂ∞çÂèØËÉΩÈåØË™§ÁöÑÁ≠îÊ°àÔºà‰æãÂ¶ÇË™™„ÄåÊàë‰∏çÁü•ÈÅì„ÄçÔºâÁöÑÊ£ÑÊ¨äÂá∫Áèæ‰∫ÜÊñ∞ÁöÑÂ¢ûÂä†„ÄÇ

##### **Fusion-PSRO: Nash Policy Fusion for Policy Space Response Oracles**
2405.21027v2 by Jiesong Lian, Yucong Huang, Mingzhi Wang, Chengdong Ma, Yixue Hao, Ying Wen, Yaodong Yang

A popular approach for solving zero-sum games is to maintain populations of
policies to approximate the Nash Equilibrium (NE). Previous studies have shown
that Policy Space Response Oracle (PSRO) algorithm is an effective multi-agent
reinforcement learning framework for solving such games. However, repeatedly
training new policies from scratch to approximate Best Response (BR) to
opponents' mixed policies at each iteration is both inefficient and costly.
While some PSRO variants initialize a new policy by inheriting from past BR
policies, this approach limits the exploration of new policies, especially
against challenging opponents. To address this issue, we propose Fusion-PSRO,
which employs policy fusion to initialize policies for better approximation to
BR. By selecting high-quality base policies from meta-NE, policy fusion fuses
the base policies into a new policy through model averaging. This approach
allows the initialized policies to incorporate multiple expert policies, making
it easier to handle difficult opponents compared to inheriting from past BR
policies or initializing from scratch. Moreover, our method only modifies the
policy initialization phase, allowing its application to nearly all PSRO
variants without additional training overhead. Our experiments on
non-transitive matrix games, Leduc Poker, and the more complex Liars Dice
demonstrate that Fusion-PSRO enhances the performance of nearly all PSRO
variants, achieving lower exploitability.

ÊëòË¶ÅÔºöÊµÅË°åÁöÑÊ±ÇËß£Èõ∂ÂíåÂçöÂºàÊñπÊ≥ïÊòØÁª¥ÊåÅÁ≠ñÁï•Êóè‰ª•ÈÄºËøëÁ∫≥‰ªÄÂùáË°° (NE)„ÄÇÂÖàÂâçÁöÑÁ†îÁ©∂Ë°®ÊòéÔºåÁ≠ñÁï•Á©∫Èó¥ÂìçÂ∫îÈ¢ÑË®ÄÊú∫ (PSRO) ÁÆóÊ≥ïÊòØ‰∏ÄÁßçÊúâÊïàÁöÑÁî®‰∫éÊ±ÇËß£Ê≠§Á±ªÂçöÂºàÁöÑÂ§öÊô∫ËÉΩ‰ΩìÂº∫ÂåñÂ≠¶‰π†Ê°ÜÊû∂„ÄÇÁÑ∂ËÄåÔºåÂú®ÊØèÊ¨°Ëø≠‰ª£‰∏≠Ôºå‰ªéÂ§¥ÂºÄÂßãÈáçÂ§çËÆ≠ÁªÉÊñ∞Á≠ñÁï•‰ª•ÈÄºËøëÂØπÂØπÊâãÊ∑∑ÂêàÁ≠ñÁï•ÁöÑÊúÄ‰Ω≥ÂìçÂ∫î (BR) Êó¢‰ΩéÊïàÂèàÊòÇË¥µ„ÄÇËôΩÁÑ∂‰∏Ä‰∫õ PSRO Âèò‰ΩìÈÄöËøáÁªßÊâøËøáÂéªÁöÑ BR Á≠ñÁï•Êù•ÂàùÂßãÂåñÊñ∞Á≠ñÁï•Ôºå‰ΩÜÊ≠§ÊñπÊ≥ïÈôêÂà∂‰∫ÜÊñ∞Á≠ñÁï•ÁöÑÊé¢Á¥¢ÔºåÂ∞§ÂÖ∂ÊòØÂú®ÂØπÊäóÂÖ∑ÊúâÊåëÊàòÊÄßÁöÑÂØπÊâãÊó∂„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢òÔºåÊàë‰ª¨ÊèêÂá∫‰∫ÜËûçÂêà PSROÔºåÂÆÉÈááÁî®Á≠ñÁï•ËûçÂêàÊù•ÂàùÂßãÂåñÁ≠ñÁï•‰ª•Êõ¥Â•ΩÂú∞ÈÄºËøë BR„ÄÇÈÄöËøá‰ªéÂÖÉ NE ‰∏≠ÈÄâÊã©È´òË¥®ÈáèÁöÑÂü∫Êú¨Á≠ñÁï•ÔºåÁ≠ñÁï•ËûçÂêàÈÄöËøáÊ®°ÂûãÂπ≥ÂùáÂ∞ÜÂü∫Êú¨Á≠ñÁï•ËûçÂêàÂà∞Êñ∞Á≠ñÁï•‰∏≠„ÄÇ‰∏éÁªßÊâøËøáÂéªÁöÑ BR Á≠ñÁï•Êàñ‰ªéÂ§¥ÂºÄÂßãÂàùÂßãÂåñÁõ∏ÊØîÔºåËøôÁßçÊñπÊ≥ïÂÖÅËÆ∏ÂàùÂßãÂåñÁöÑÁ≠ñÁï•Á∫≥ÂÖ•Â§ö‰∏™‰∏ìÂÆ∂Á≠ñÁï•Ôºå‰ªéËÄåÊõ¥ÂÆπÊòìÂ§ÑÁêÜÂõ∞ÈöæÁöÑÂØπÊâã„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨ÁöÑÊñπÊ≥ï‰ªÖ‰øÆÊîπÁ≠ñÁï•ÂàùÂßãÂåñÈò∂ÊÆµÔºå‰ΩøÂÖ∂ÂèØ‰ª•Â∫îÁî®‰∫éÂá†‰πéÊâÄÊúâ PSRO Âèò‰ΩìÔºåËÄåÊó†ÈúÄÈ¢ùÂ§ñÁöÑËÆ≠ÁªÉÂºÄÈîÄ„ÄÇÊàë‰ª¨Âú®Èùû‰º†ÈÄíÁü©ÈòµÂçöÂºà„ÄÅLeduc ÊâëÂÖãÂíåÊõ¥Â§çÊùÇÁöÑ Liars Dice ‰∏äÁöÑÂÆûÈ™åË°®ÊòéÔºåËûçÂêà PSRO Â¢ûÂº∫‰∫ÜÂá†‰πéÊâÄÊúâ PSRO Âèò‰ΩìÁöÑÊÄßËÉΩÔºåÂÆûÁé∞‰∫ÜÊõ¥‰ΩéÁöÑÂà©Áî®Áéá„ÄÇ

##### **Compact Optimality Verification for Optimization Proxies**
2405.21023v1 by Wenbo Chen, Haoruo Zhao, Mathieu Tanneau, Pascal Van Hentenryck

Recent years have witnessed increasing interest in optimization proxies,
i.e., machine learning models that approximate the input-output mapping of
parametric optimization problems and return near-optimal feasible solutions.
Following recent work by (Nellikkath & Chatzivasileiadis, 2021), this paper
reconsiders the optimality verification problem for optimization proxies, i.e.,
the determination of the worst-case optimality gap over the instance
distribution. The paper proposes a compact formulation for optimality
verification and a gradient-based primal heuristic that brings substantial
computational benefits to the original formulation. The compact formulation is
also more general and applies to non-convex optimization problems. The benefits
of the compact formulation are demonstrated on large-scale DC Optimal Power
Flow and knapsack problems.

ÊëòË¶ÅÔºöËøëÂπ¥Êù•Ôºå‰∫∫‰ª¨ÂØπ‰ºòÂåñ‰ª£ÁêÜË∂äÊù•Ë∂äÊÑüÂÖ¥Ë∂£ÔºåÂç≥Ëøë‰ººÂèÇÊï∞‰ºòÂåñÈóÆÈ¢òÁöÑËæìÂÖ•ËæìÂá∫Êò†Â∞ÑÂπ∂ËøîÂõûÊé•ËøëÊúÄ‰ºòÂèØË°åËß£ÁöÑÊú∫Âô®Â≠¶‰π†Ê®°Âûã„ÄÇÂú® (Nellikkath & Chatzivasileiadis, 2021) ÁöÑÊúÄÊñ∞Â∑•‰Ωú‰πãÂêéÔºåÊú¨ÊñáÈáçÊñ∞ËÄÉËôë‰∫Ü‰ºòÂåñ‰ª£ÁêÜÁöÑÊúÄ‰ºòÊÄßÈ™åËØÅÈóÆÈ¢òÔºåÂç≥Á°ÆÂÆöÂÆû‰æãÂàÜÂ∏É‰∏äÁöÑÊúÄÂùèÊÉÖÂÜµÊúÄ‰ºòÊÄßÂ∑ÆË∑ù„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÁ¥ßÂáëÁöÑÊúÄ‰ºòÊÄßÈ™åËØÅÂÖ¨ÂºèÂíå‰∏ÄÁßçÂü∫‰∫éÊ¢ØÂ∫¶ÁöÑÂéüÂßãÂêØÂèëÂºèÊñπÊ≥ïÔºå‰∏∫ÂéüÂßãÂÖ¨ÂºèÂ∏¶Êù•‰∫ÜÂÆûË¥®ÊÄßÁöÑËÆ°ÁÆó‰ºòÂäø„ÄÇÁ¥ßÂáëÂÖ¨Âºè‰πüÊõ¥ÈÄöÁî®ÔºåÈÄÇÁî®‰∫éÈùûÂá∏‰ºòÂåñÈóÆÈ¢ò„ÄÇÁ¥ßÂáëÂÖ¨ÂºèÁöÑ‰ºòÂäøÂú®Â§ßÂûã DC ÊúÄ‰ºòÊΩÆÊµÅÂíåËÉåÂåÖÈóÆÈ¢ò‰∏äÂæóÂà∞ËØÅÊòé„ÄÇ

##### **You Only Scan Once: Efficient Multi-dimension Sequential Modeling with LightNet**
2405.21022v1 by Zhen Qin, Yuxin Mao, Xuyang Shen, Dong Li, Jing Zhang, Yuchao Dai, Yiran Zhong

Linear attention mechanisms have gained prominence in causal language models
due to their linear computational complexity and enhanced speed. However, the
inherent decay mechanism in linear attention presents challenges when applied
to multi-dimensional sequence modeling tasks, such as image processing and
multi-modal learning. In these scenarios, the utilization of sequential
scanning to establish a global receptive field necessitates multiple scans for
multi-dimensional data, thereby leading to inefficiencies. This paper
identifies the inefficiency caused by a multiplicative linear recurrence and
proposes an efficient alternative additive linear recurrence to avoid the
issue, as it can handle multi-dimensional data within a single scan. We further
develop an efficient multi-dimensional sequential modeling framework called
LightNet based on the new recurrence. Moreover, we present two new
multi-dimensional linear relative positional encoding methods, MD-TPE and
MD-LRPE to enhance the model's ability to discern positional information in
multi-dimensional scenarios. Our empirical evaluations across various tasks,
including image classification, image generation, bidirectional language
modeling, and autoregressive language modeling, demonstrate the efficacy of
LightNet, showcasing its potential as a versatile and efficient solution for
multi-dimensional sequential modeling.

ÊëòË¶ÅÔºöÁ∑öÊÄßÊ≥®ÊÑèÂäõÊ©üÂà∂Áî±ÊñºÂÖ∂Á∑öÊÄßË®àÁÆóË§áÈõúÂ∫¶ÂíåÂ¢ûÂº∑ÁöÑÈÄüÂ∫¶ËÄåÂú®Âõ†ÊûúË™ûË®ÄÊ®°Âûã‰∏≠Áç≤Âæó‰∫ÜÈ°ØËëóÂú∞‰Ωç„ÄÇÁÑ∂ËÄåÔºåÁ∑öÊÄßÊ≥®ÊÑèÂäõ‰∏≠ÁöÑÂõ∫ÊúâË°∞Ê∏õÊ©üÂà∂Âú®ÊáâÁî®ÊñºÂ§öÁ∂≠Â∫èÂàóÂª∫Ê®°‰ªªÂãôÔºà‰æãÂ¶ÇÂúñÂÉèËôïÁêÜÂíåÂ§öÊ®°ÊÖãÂ≠∏ÁøíÔºâÊôÇÊúÉÂ∏∂‰æÜÊåëÊà∞„ÄÇÂú®ÈÄô‰∫õÂ†¥ÊôØ‰∏≠ÔºåÂà©Áî®È†ÜÂ∫èÊéÉÊèè‰æÜÂª∫Á´ãÂÖ®Â±ÄÊÑüÂèóÈáéÈúÄË¶ÅÂ∞çÂ§öÁ∂≠Êï∏ÊìöÈÄ≤Ë°åÂ§öÊ¨°ÊéÉÊèèÔºåÂæûËÄåÂ∞éËá¥ÊïàÁéá‰Ωé‰∏ã„ÄÇÊú¨ÊñáÁ¢∫ÂÆö‰∫ÜÁî±‰πòÊ≥ïÁ∑öÊÄßÈÅûËø¥ÂºïËµ∑ÁöÑÊïàÁéá‰Ωé‰∏ãÔºå‰∏¶ÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊúâÊïàÁöÑÊõø‰ª£Âä†Ê≥ïÁ∑öÊÄßÈÅûËø¥‰æÜÈÅøÂÖçÈÄôÂÄãÂïèÈ°åÔºåÂõ†ÁÇ∫ÂÆÉÂèØ‰ª•Âú®‰∏ÄÊ¨°ÊéÉÊèèÂÖßËôïÁêÜÂ§öÁ∂≠Êï∏Êìö„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÈÇÑÂü∫ÊñºÊñ∞ÁöÑÈÅûËø¥ÈñãÁôº‰∫Ü‰∏ÄÂÄãÂêçÁÇ∫ LightNet ÁöÑÈ´òÊïàÂ§öÁ∂≠Â∫èÂàóÂª∫Ê®°Ê°ÜÊû∂„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèêÂá∫‰∫ÜÂÖ©Á®ÆÊñ∞ÁöÑÂ§öÁ∂≠Á∑öÊÄßÁõ∏Â∞ç‰ΩçÁΩÆÁ∑®Á¢ºÊñπÊ≥ïÔºåMD-TPE Âíå MD-LRPEÔºå‰ª•Â¢ûÂº∑Ê®°ÂûãÂú®Â§öÁ∂≠Â†¥ÊôØ‰∏≠Ëæ®Âà•‰ΩçÁΩÆ‰ø°ÊÅØÁöÑËÉΩÂäõ„ÄÇÊàëÂÄëÂú®ÂêÑÁ®Æ‰ªªÂãô‰∏≠ÁöÑÂØ¶Ë≠âË©ï‰º∞ÔºåÂåÖÊã¨ÂúñÂÉèÂàÜÈ°û„ÄÅÂúñÂÉèÁîüÊàê„ÄÅÈõôÂêëË™ûË®ÄÂª∫Ê®°ÂíåËá™Ëø¥Ê≠∏Ë™ûË®ÄÂª∫Ê®°ÔºåË≠âÊòé‰∫Ü LightNet ÁöÑÊúâÊïàÊÄßÔºåÂ±ïÁ§∫‰∫ÜÂÖ∂‰ΩúÁÇ∫Â§öÁ∂≠Â∫èÂàóÂª∫Ê®°ÁöÑÈÄöÁî®‰∏îÈ´òÊïàËß£Ê±∫ÊñπÊ°àÁöÑÊΩõÂäõ„ÄÇ

##### **Improved Techniques for Optimization-Based Jailbreaking on Large Language Models**
2405.21018v1 by Xiaojun Jia, Tianyu Pang, Chao Du, Yihao Huang, Jindong Gu, Yang Liu, Xiaochun Cao, Min Lin

Large language models (LLMs) are being rapidly developed, and a key component
of their widespread deployment is their safety-related alignment. Many
red-teaming efforts aim to jailbreak LLMs, where among these efforts, the
Greedy Coordinate Gradient (GCG) attack's success has led to a growing interest
in the study of optimization-based jailbreaking techniques. Although GCG is a
significant milestone, its attacking efficiency remains unsatisfactory. In this
paper, we present several improved (empirical) techniques for
optimization-based jailbreaks like GCG. We first observe that the single target
template of "Sure" largely limits the attacking performance of GCG; given this,
we propose to apply diverse target templates containing harmful self-suggestion
and/or guidance to mislead LLMs. Besides, from the optimization aspects, we
propose an automatic multi-coordinate updating strategy in GCG (i.e.,
adaptively deciding how many tokens to replace in each step) to accelerate
convergence, as well as tricks like easy-to-hard initialisation. Then, we
combine these improved technologies to develop an efficient jailbreak method,
dubbed $\mathcal{I}$-GCG. In our experiments, we evaluate on a series of
benchmarks (such as NeurIPS 2023 Red Teaming Track). The results demonstrate
that our improved techniques can help GCG outperform state-of-the-art
jailbreaking attacks and achieve nearly 100% attack success rate. The code is
released at https://github.com/jiaxiaojunQAQ/I-GCG.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Ê≠£Âú®Âø´ÈÄüÁôºÂ±ïÔºåËÄåÂÖ∂Âª£Ê≥õÈÉ®ÁΩ≤ÁöÑ‰∏ÄÂÄãÈóúÈçµÁµÑÊàêÈÉ®ÂàÜÊòØÂÖ∂ËàáÂÆâÂÖ®Áõ∏ÈóúÁöÑ‰∏ÄËá¥ÊÄß„ÄÇË®±Â§öÁ¥ÖÈöäË°åÂãïÊó®Âú®Á†¥Ëß£ LLMÔºåÂú®ÈÄô‰∫õË°åÂãï‰∏≠ÔºåË≤™Â©™ÂùêÊ®ôÊ¢ØÂ∫¶ (GCG) ÊîªÊìäÁöÑÊàêÂäüÂºïËµ∑‰∫Ü‰∫∫ÂÄëÂ∞çÂü∫ÊñºÊúÄ‰Ω≥ÂåñÁöÑÁ†¥Ëß£ÊäÄË°ìÁ†îÁ©∂ÁöÑËààË∂£Êó•ÁõäÊøÉÂéö„ÄÇÂÑòÁÆ° GCG ÊòØÂÄãÈáçË¶ÅÁöÑÈáåÁ®ãÁ¢ëÔºå‰ΩÜÂÖ∂ÊîªÊìäÊïàÁéá‰ªçÁÑ∂‰ª§‰∫∫‰∏çÊªøÊÑè„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫ÜÂπæÁ®ÆÊîπÈÄ≤ÁöÑÔºàÁ∂ìÈ©óÔºâÊäÄË°ìÔºåÁî®ÊñºÂü∫ÊñºÊúÄ‰Ω≥ÂåñÁöÑÁ†¥Ëß£Ôºå‰æãÂ¶Ç GCG„ÄÇÊàëÂÄëÈ¶ñÂÖàËßÄÂØüÂà∞„ÄåÁ¢∫ÂÆö„ÄçÁöÑÂñÆ‰∏ÄÁõÆÊ®ôÁØÑÊú¨Âú®ÂæàÂ§ßÁ®ãÂ∫¶‰∏äÈôêÂà∂‰∫Ü GCG ÁöÑÊîªÊìäÊïàËÉΩÔºõÊúâÈëëÊñºÊ≠§ÔºåÊàëÂÄëÂª∫Ë≠∞ÊáâÁî®ÂåÖÂê´ÊúâÂÆ≥Ëá™ÊàëÊöóÁ§∫Âíå/ÊàñÊåáÂ∞éÁöÑÂêÑÁ®ÆÁõÆÊ®ôÁØÑÊú¨‰æÜË™§Â∞é LLM„ÄÇÊ≠§Â§ñÔºåÂæûÊúÄ‰Ω≥ÂåñÁöÑËßíÂ∫¶‰æÜÁúãÔºåÊàëÂÄëÂú® GCG ‰∏≠ÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆËá™ÂãïÂ§öÂùêÊ®ôÊõ¥Êñ∞Á≠ñÁï•ÔºàÂç≥Ëá™ÈÅ©ÊáâÂú∞Ê±∫ÂÆöÂú®ÊØè‰∏ÄÊ≠•‰∏≠ÊõøÊèõÂ§öÂ∞ëÂÄã‰ª£Âπ£Ôºâ‰ª•Âä†ÈÄüÊî∂ÊñÇÔºå‰ª•ÂèäË´∏Â¶ÇÊòìÊñºÂõ∞Èõ£ÂàùÂßãÂåñÁöÑÊäÄÂ∑ß„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÂ∞áÈÄô‰∫õÊîπÈÄ≤ÁöÑÊäÄË°ìÁµêÂêàËµ∑‰æÜÔºåÈñãÁôºÂá∫‰∏ÄÁ®ÆÈ´òÊïàÁöÑÁ†¥Ëß£ÊñπÊ≥ïÔºåÁ®±ÁÇ∫ $\mathcal{I}$-GCG„ÄÇÂú®ÊàëÂÄëÁöÑÂØ¶È©ó‰∏≠ÔºåÊàëÂÄëÂú®‰∏ÄÁ≥ªÂàóÂü∫Ê∫ñ‰∏äÈÄ≤Ë°åË©ï‰º∞Ôºà‰æãÂ¶Ç NeurIPS 2023 Á¥ÖÈöäËøΩËπ§Ôºâ„ÄÇÁµêÊûúË°®ÊòéÔºåÊàëÂÄëÊîπÈÄ≤ÁöÑÊäÄË°ìÂèØ‰ª•Âπ´Âä© GCG ÂÑ™ÊñºÊúÄÂÖàÈÄ≤ÁöÑÁ†¥Ëß£ÊîªÊìäÔºå‰∏¶ÂØ¶ÁèæÊé•Ëøë 100% ÁöÑÊîªÊìäÊàêÂäüÁéá„ÄÇ‰ª£Á¢ºÂ∑≤ÁôºÂ∏ÉÂú® https://github.com/jiaxiaojunQAQ/I-GCG„ÄÇ

##### **CWRCzech: 100M Query-Document Czech Click Dataset and Its Application to Web Relevance Ranking**
2405.20994v1 by Josef Von√°≈°ek, Milan Straka, Rostislav Krƒç, Lenka Laso≈àov√°, Ekaterina Egorova, Jana Strakov√°, Jakub N√°plava

We present CWRCzech, Click Web Ranking dataset for Czech, a 100M
query-document Czech click dataset for relevance ranking with user behavior
data collected from search engine logs of Seznam.cz. To the best of our
knowledge, CWRCzech is the largest click dataset with raw text published so
far. It provides document positions in the search results as well as
information about user behavior: 27.6M clicked documents and 10.8M dwell times.
In addition, we also publish a manually annotated Czech test for the relevance
task, containing nearly 50k query-document pairs, each annotated by at least 2
annotators. Finally, we analyze how the user behavior data improve relevance
ranking and show that models trained on data automatically harnessed at
sufficient scale can surpass the performance of models trained on human
annotated data. CWRCzech is published under an academic non-commercial license
and is available to the research community at
https://github.com/seznam/CWRCzech.

ÊëòË¶ÅÔºö<paragraph>ÊàëÂÄëÊèêÂá∫ CWRCzechÔºåÊç∑ÂÖãË™ûÈªûÊìäÁ∂≤Ë∑ØÊéíÂêçË≥áÊñôÈõÜÔºå‰∏ÄÂÄãÂåÖÂê´ 1 ÂÑÑÂÄãÊç∑ÂÖãË™ûÊü•Ë©¢Êñá‰ª∂ÈªûÊìäË≥áÊñôÈõÜÔºåÁî®ÊñºÁõ∏ÈóúÊÄßÊéíÂêçÔºå‰∏¶Âæû Seznam.cz ÁöÑÊêúÂ∞ãÂºïÊìéË®òÈåÑ‰∏≠Êî∂ÈõÜ‰ΩøÁî®ËÄÖË°åÁÇ∫Ë≥áÊñô„ÄÇÊìöÊàëÂÄëÊâÄÁü•ÔºåCWRCzech ÊòØËøÑ‰ªäÁôºÂ∏ÉÁöÑÊúÄÂ§ßÈªûÊìäË≥áÊñôÈõÜÔºåÈôÑÊúâÂéüÂßãÊñáÂ≠ó„ÄÇÂÆÉÊèê‰æõÊêúÂ∞ãÁµêÊûú‰∏≠ÁöÑÊñá‰ª∂‰ΩçÁΩÆÔºå‰ª•Âèä‰ΩøÁî®ËÄÖË°åÁÇ∫Ë≥áË®äÔºö2,760 Ëê¨ÂÄãÂ∑≤ÈªûÊìäÊñá‰ª∂Âíå 1,080 Ëê¨ÂÄãÂÅúÁïôÊôÇÈñì„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÈÇÑÁôºÂ∏É‰∏ÄÂÄãÊâãÂãïË®ªËß£ÁöÑÊç∑ÂÖãË™ûÁõ∏ÈóúÊÄß‰ªªÂãôÊ∏¨Ë©¶ÔºåÂåÖÂê´Ëøë 5 Ëê¨ÂÄãÊü•Ë©¢Êñá‰ª∂ÈÖçÂ∞çÔºåÊØèÂÄãÈÖçÂ∞çËá≥Â∞ëÁî± 2 ÂÄãË®ªËß£Âì°Ë®ªËß£„ÄÇÊúÄÂæåÔºåÊàëÂÄëÂàÜÊûê‰ΩøÁî®ËÄÖË°åÁÇ∫Ë≥áÊñôÂ¶Ç‰ΩïÊîπÂñÑÁõ∏ÈóúÊÄßÊéíÂêçÔºå‰∏¶È°ØÁ§∫Âú®Ë∂≥Â§†Ë¶èÊ®°‰∏ãËá™ÂãïÂà©Áî®Ë≥áÊñôË®ìÁ∑¥ÁöÑÊ®°ÂûãÂèØ‰ª•Ë∂ÖË∂äÂú®‰∫∫Â∑•Ë®ªËß£Ë≥áÊñô‰∏äË®ìÁ∑¥ÁöÑÊ®°ÂûãÁöÑÊïàËÉΩ„ÄÇCWRCzech Âú®ÈùûÂïÜÊ•≠Â≠∏Ë°ìÊéàÊ¨ä‰∏ãÁôºÂ∏ÉÔºåÁ†îÁ©∂Á§æÁæ§ÂèØÂú® https://github.com/seznam/CWRCzech ÂèñÂæó„ÄÇ</paragraph>

##### **Locking Machine Learning Models into Hardware**
2405.20990v1 by Eleanor Clifford, Adhithya Saravanan, Harry Langford, Cheng Zhang, Yiren Zhao, Robert Mullins, Ilia Shumailov, Jamie Hayes

Modern Machine Learning models are expensive IP and business competitiveness
often depends on keeping this IP confidential. This in turn restricts how these
models are deployed -- for example it is unclear how to deploy a model
on-device without inevitably leaking the underlying model. At the same time,
confidential computing technologies such as Multi-Party Computation or
Homomorphic encryption remain impractical for wide adoption. In this paper we
take a different approach and investigate feasibility of ML-specific mechanisms
that deter unauthorized model use by restricting the model to only be usable on
specific hardware, making adoption on unauthorized hardware inconvenient. That
way, even if IP is compromised, it cannot be trivially used without specialised
hardware or major model adjustment. In a sense, we seek to enable cheap locking
of machine learning models into specific hardware. We demonstrate that locking
mechanisms are feasible by either targeting efficiency of model
representations, such making models incompatible with quantisation, or tie the
model's operation on specific characteristics of hardware, such as number of
cycles for arithmetic operations. We demonstrate that locking comes with
negligible work and latency overheads, while significantly restricting
usability of the resultant model on unauthorized hardware.

ÊëòË¶ÅÔºöÁèæ‰ª£Ê©üÂô®Â≠∏ÁøíÊ®°ÂûãÊòØÊòÇË≤¥ÁöÑÊô∫ÊÖßË≤°Áî¢Ê¨äÔºåËÄåÂïÜÊ•≠Á´∂Áà≠ÂäõÈÄöÂ∏∏ÂèñÊ±∫ÊñºÂ¶Ç‰Ωï‰øùÂØÜÊ≠§Êô∫ÊÖßË≤°Áî¢Ê¨ä„ÄÇÈÄôÂèçÈÅé‰æÜÈôêÂà∂‰∫ÜÈÄô‰∫õÊ®°ÂûãÁöÑÈÉ®ÁΩ≤ÊñπÂºè‚Äî‚Äî‰æãÂ¶ÇÔºåÁõÆÂâçÂ∞ö‰∏çÊ∏ÖÊ•öÂ¶Ç‰ΩïÂú®Ë®≠ÂÇô‰∏äÈÉ®ÁΩ≤Ê®°ÂûãÔºåÂêåÊôÇ‰∏çÂèØÈÅøÂÖçÂú∞Ê¥©Èú≤Âü∫Á§éÊ®°Âûã„ÄÇÂêåÊôÇÔºåÂ§öÊñπË®àÁÆóÊàñÂêåÊÖãÂä†ÂØÜÁ≠âÊ©üÂØÜË®àÁÆóÊäÄË°ì‰ªçÁÑ∂‰∏çÂàáÂØ¶ÈöõÔºåÁÑ°Ê≥ïÂª£Ê≥õÊé°Áî®„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊé°Áî®‰∏çÂêåÁöÑÊñπÊ≥ïÔºå‰∏¶Êé¢Ë®éÁâπÂÆöÊñºÊ©üÂô®Â≠∏ÁøíÁöÑÊ©üÂà∂ÁöÑÂèØË°åÊÄßÔºåÈÄô‰∫õÊ©üÂà∂ÈÄöÈÅéÂ∞áÊ®°ÂûãÈôêÂà∂ÁÇ∫Âè™ËÉΩÂú®ÁâπÂÆöÁ°¨È´î‰∏ä‰ΩøÁî®‰æÜÈòªÊ≠¢Êú™Á∂ìÊéàÊ¨äÁöÑÊ®°Âûã‰ΩøÁî®ÔºåÂæûËÄå‰ΩøÂú®Êú™Á∂ìÊéàÊ¨äÁöÑÁ°¨È´î‰∏äÊé°Áî®Ê®°ÂûãËÆäÂæó‰∏çÊñπ‰æø„ÄÇÈÄôÊ®£ÔºåÂç≥‰ΩøÊô∫ÊÖßË≤°Áî¢Ê¨äÂèóÂà∞ÊêçÂÆ≥Ôºå‰πüÁÑ°Ê≥ïÂú®Ê≤íÊúâÂ∞àÁî®Á°¨È´îÊàñ‰∏ªË¶ÅÊ®°ÂûãË™øÊï¥ÁöÑÊÉÖÊ≥Å‰∏ãËºïÊòì‰ΩøÁî®„ÄÇÂæûÊüêÁ®ÆÊÑèÁæ©‰∏äË™™ÔºåÊàëÂÄëÂ∞ãÊ±ÇÂØ¶ÁèæÂ∞áÊ©üÂô®Â≠∏ÁøíÊ®°ÂûãÂªâÂÉπÈéñÂÆöÂà∞ÁâπÂÆöÁ°¨È´î‰∏≠„ÄÇÊàëÂÄëË≠âÊòé‰∫ÜÈéñÂÆöÊ©üÂà∂ÊòØÂèØË°åÁöÑÔºåÊñπÊ≥ïÊòØÈáùÂ∞çÊ®°ÂûãË°®Á§∫ÁöÑÊïàÁéáÔºå‰æãÂ¶Ç‰ΩøÊ®°ÂûãËàáÈáèÂåñ‰∏çÁõ∏ÂÆπÔºåÊàñÂ∞áÊ®°ÂûãÁöÑÊìç‰ΩúËàáÁ°¨È´îÁöÑÁâπÂÆöÁâπÂæµËÅØÁπ´Ëµ∑‰æÜÔºå‰æãÂ¶ÇÁÆóË°ìÈÅãÁÆóÁöÑÈÄ±ÊúüÊï∏„ÄÇÊàëÂÄëË≠âÊòé‰∫ÜÈéñÂÆöÊúÉÂ∏∂‰æÜÂèØÂøΩÁï•‰∏çË®àÁöÑÂ∑•‰ΩúÂíåÂª∂ÈÅ≤ÈñãÈä∑ÔºåÂêåÊôÇÈ°ØËëóÈôêÂà∂‰∫ÜÂú®Êú™Á∂ìÊéàÊ¨äÁöÑÁ°¨È´î‰∏ä‰ΩøÁî®ÁµêÊûúÊ®°ÂûãÁöÑÂèØÁî®ÊÄß„ÄÇ

##### **Enhancing Noise Robustness of Retrieval-Augmented Language Models with Adaptive Adversarial Training**
2405.20978v1 by Feiteng Fang, Yuelin Bai, Shiwen Ni, Min Yang, Xiaojun Chen, Ruifeng Xu

Large Language Models (LLMs) exhibit substantial capabilities yet encounter
challenges, including hallucination, outdated knowledge, and untraceable
reasoning processes. Retrieval-augmented generation (RAG) has emerged as a
promising solution, integrating knowledge from external databases to mitigate
these challenges. However, inappropriate retrieved passages can potentially
hinder the LLMs' capacity to generate comprehensive and high-quality responses.
Prior RAG studies on the robustness of retrieval noises often confine
themselves to a limited set of noise types, deviating from real-world retrieval
environments and limiting practical applicability. In this study, we initially
investigate retrieval noises and categorize them into three distinct types,
reflecting real-world environments. We analyze the impact of these various
retrieval noises on the robustness of LLMs. Subsequently, we propose a novel
RAG approach known as Retrieval-augmented Adaptive Adversarial Training (RAAT).
RAAT leverages adaptive adversarial training to dynamically adjust the model's
training process in response to retrieval noises. Concurrently, it employs
multi-task learning to ensure the model's capacity to internally recognize
noisy contexts. Extensive experiments demonstrate that the LLaMA-2 7B model
trained using RAAT exhibits significant improvements in F1 and EM scores under
diverse noise conditions. For reproducibility, we release our code and data at:
https://github.com/calubkk/RAAT.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂÖ∑ÂÇôÂº∑Â§ßÁöÑÂäüËÉΩÔºåÂçª‰πüÈù¢Ëá®ÊåëÊà∞ÔºåÂåÖÊã¨ÂπªË¶∫„ÄÅÁü•Ë≠òÈÅéÊôÇÔºå‰ª•ÂèäÈõ£‰ª•ËøΩËπ§ÁöÑÊé®ÁêÜÈÅéÁ®ã„ÄÇÊ™¢Á¥¢Â¢ûÂº∑ÁîüÊàê (RAG) Â∑≤ÊàêÁÇ∫‰∏ÄÁ®ÆÊúâÂâçÊôØÁöÑËß£Ê±∫ÊñπÊ°àÔºåÂÆÉÊï¥Âêà‰æÜËá™Â§ñÈÉ®Ë≥áÊñôÂ∫´ÁöÑÁü•Ë≠ò‰ª•Ê∏õËºïÈÄô‰∫õÊåëÊà∞„ÄÇÁÑ∂ËÄåÔºå‰∏çÈÅ©Áï∂ÁöÑÊ™¢Á¥¢ÊÆµËêΩÂèØËÉΩÊúÉÈòªÁ§ô LLM ÁîüÊàêÂÖ®Èù¢‰∏îÈ´òÂìÅË≥™ÂõûÊáâÁöÑËÉΩÂäõ„ÄÇÂÖàÂâçÈáùÂ∞çÊ™¢Á¥¢ÈõúË®äÁ©©ÂÅ•ÊÄßÁöÑ RAG Á†îÁ©∂ÈÄöÂ∏∏‰æ∑ÈôêÊñºÊúâÈôêÁöÑÈõúË®äÈ°ûÂûãÔºåÂÅèÈõ¢ÁúüÂØ¶‰∏ñÁïåÁöÑÊ™¢Á¥¢Áí∞Â¢ÉÔºå‰∏¶ÈôêÂà∂‰∫ÜÂØ¶ÈöõÊáâÁî®ÊÄß„ÄÇÂú®Êú¨Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëÊúÄÂàùÊé¢Ë®éÊ™¢Á¥¢ÈõúË®äÔºå‰∏¶Â∞áÂÖ∂ÂàÜÈ°ûÁÇ∫‰∏âÁ®ÆÈ°ûÂûãÔºåÂèçÊò†ÁúüÂØ¶‰∏ñÁïåÁöÑÁí∞Â¢É„ÄÇÊàëÂÄëÂàÜÊûê‰∫ÜÈÄô‰∫õ‰∏çÂêåÊ™¢Á¥¢ÈõúË®äÂ∞ç LLM Á©©ÂÅ•ÊÄßÁöÑÂΩ±Èüø„ÄÇÈö®ÂæåÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÁ®±ÁÇ∫Ê™¢Á¥¢Â¢ûÂº∑ÈÅ©ÊáâÂ∞çÊäóË®ìÁ∑¥ (RAAT) ÁöÑÊñ∞ RAG ÊñπÊ≥ï„ÄÇRAAT Âà©Áî®ÈÅ©ÊáâÂ∞çÊäóË®ìÁ∑¥ÂãïÊÖãË™øÊï¥Ê®°ÂûãÁöÑË®ìÁ∑¥ÈÅéÁ®ãÔºå‰ª•ÊáâÂ∞çÊ™¢Á¥¢ÈõúË®ä„ÄÇÂêåÊôÇÔºåÂÆÉÊé°Áî®Â§ö‰ªªÂãôÂ≠∏ÁøíÔºå‰ª•Á¢∫‰øùÊ®°ÂûãËÉΩÂ§†ÂÖßÈÉ®Ëæ®Ë≠òÈõúË®äÁí∞Â¢É„ÄÇÂª£Ê≥õÁöÑÂØ¶È©óË≠âÊòéÔºå‰ΩøÁî® RAAT Ë®ìÁ∑¥ÁöÑ LLaMA-2 7B Ê®°ÂûãÂú®‰∏çÂêåÁöÑÈõúË®äÊ¢ù‰ª∂‰∏ãÔºåF1 Âíå EM ÂàÜÊï∏ÈÉΩÊúâÈ°ØËëóÁöÑÊèêÂçá„ÄÇÁÇ∫‰∫ÜÈáçÁèæÊÄßÔºåÊàëÂÄëÂú®‰ª•‰∏ã‰ΩçÁΩÆÈáãÂá∫ÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÂíåË≥áÊñôÔºöhttps://github.com/calubkk/RAAT„ÄÇ

##### **ACE: A Model Poisoning Attack on Contribution Evaluation Methods in Federated Learning**
2405.20975v1 by Zhangchen Xu, Fengqing Jiang, Luyao Niu, Jinyuan Jia, Bo Li, Radha Poovendran

In Federated Learning (FL), a set of clients collaboratively train a machine
learning model (called global model) without sharing their local training data.
The local training data of clients is typically non-i.i.d. and heterogeneous,
resulting in varying contributions from individual clients to the final
performance of the global model. In response, many contribution evaluation
methods were proposed, where the server could evaluate the contribution made by
each client and incentivize the high-contributing clients to sustain their
long-term participation in FL. Existing studies mainly focus on developing new
metrics or algorithms to better measure the contribution of each client.
However, the security of contribution evaluation methods of FL operating in
adversarial environments is largely unexplored. In this paper, we propose the
first model poisoning attack on contribution evaluation methods in FL, termed
ACE. Specifically, we show that any malicious client utilizing ACE could
manipulate the parameters of its local model such that it is evaluated to have
a high contribution by the server, even when its local training data is indeed
of low quality. We perform both theoretical analysis and empirical evaluations
of ACE. Theoretically, we show our design of ACE can effectively boost the
malicious client's perceived contribution when the server employs the
widely-used cosine distance metric to measure contribution. Empirically, our
results show ACE effectively and efficiently deceive five state-of-the-art
contribution evaluation methods. In addition, ACE preserves the accuracy of the
final global models on testing inputs. We also explore six countermeasures to
defend ACE. Our results show they are inadequate to thwart ACE, highlighting
the urgent need for new defenses to safeguard the contribution evaluation
methods in FL.

ÊëòË¶ÅÔºö<paragraph>Âú®ËÅØÂêàÂºèÂ≠∏Áøí (FL) ‰∏≠Ôºå‰∏ÄÁµÑÂÆ¢Êà∂Âçî‰ΩúË®ìÁ∑¥Ê©üÂô®Â≠∏ÁøíÊ®°ÂûãÔºàÁ®±ÁÇ∫ÂÖ®Â±ÄÊ®°ÂûãÔºâÔºåËÄå‰∏çÊúÉÂàÜ‰∫´‰ªñÂÄëÁöÑÊú¨Âú∞Ë®ìÁ∑¥Ë≥áÊñô„ÄÇÂÆ¢Êà∂ÁöÑÊú¨Âú∞Ë®ìÁ∑¥Ë≥áÊñôÈÄöÂ∏∏ÊòØÈùûÁç®Á´ãÂêåÂàÜÂ∏É (non-i.i.d.) ÂíåÁï∞Ë≥™ÁöÑÔºåÂ∞éËá¥ÂÄãÂà•ÂÆ¢Êà∂Â∞çÂÖ®Â±ÄÊ®°ÂûãÁöÑÊúÄÁµÇÊïàËÉΩË≤¢Áçª‰∏çÂêå„ÄÇÁÇ∫‰∫ÜËß£Ê±∫Ê≠§ÂïèÈ°åÔºåÊèêÂá∫‰∫ÜË®±Â§öË≤¢ÁçªË©ï‰º∞ÊñπÊ≥ïÔºåÂÖ∂‰∏≠‰º∫ÊúçÂô®ÂèØ‰ª•Ë©ï‰º∞ÊØèÂÄãÂÆ¢Êà∂ÂÅöÂá∫ÁöÑË≤¢ÁçªÔºå‰∏¶ÊøÄÂãµË≤¢ÁçªÂ∫¶È´òÁöÑÂÆ¢Êà∂ÊåÅÁ∫åÈï∑ÊúüÂèÉËàá FL„ÄÇÁèæÊúâÁöÑÁ†îÁ©∂‰∏ªË¶ÅÈõÜ‰∏≠ÊñºÈñãÁôºÊñ∞ÁöÑÊåáÊ®ôÊàñÊºîÁÆóÊ≥ïÔºå‰ª•Êõ¥Â•ΩÂú∞Ë°°ÈáèÊØèÂÄãÂÆ¢Êà∂ÁöÑË≤¢Áçª„ÄÇÁÑ∂ËÄåÔºåÂú®Â∞çÊäóÁí∞Â¢É‰∏≠ÈÅã‰ΩúÁöÑ FL Ë≤¢ÁçªË©ï‰º∞ÊñπÊ≥ïÁöÑÂÆâÂÖ®ÊÄßÂú®ÂæàÂ§ßÁ®ãÂ∫¶‰∏äÂ∞öÊú™Êé¢Ë®é„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫ÜÂ∞ç FL ‰∏≠Ë≤¢ÁçªË©ï‰º∞ÊñπÊ≥ïÁöÑÁ¨¨‰∏ÄÂÄãÊ®°Âûã‰∏≠ÊØíÊîªÊìäÔºåÁ®±ÁÇ∫ ACE„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëË°®Êòé‰ªª‰ΩïÂà©Áî® ACE ÁöÑÊÉ°ÊÑèÂÆ¢Êà∂ÈÉΩÂèØ‰ª•ÊìçÁ∏±ÂÖ∂Êú¨Âú∞Ê®°ÂûãÁöÑÂèÉÊï∏Ôºå‰ΩøÂÖ∂Ë¢´‰º∫ÊúçÂô®Ë©ï‰º∞ÁÇ∫ÂÖ∑ÊúâÈ´òË≤¢ÁçªÔºåÂç≥‰ΩøÂÖ∂Êú¨Âú∞Ë®ìÁ∑¥Ë≥áÊñôÂØ¶Èöõ‰∏äÂìÅË≥™ÂæàÂ∑Æ„ÄÇÊàëÂÄëÂ∞ç ACE ÈÄ≤Ë°å‰∫ÜÁêÜË´ñÂàÜÊûêÂíåÁ∂ìÈ©óË©ï‰º∞„ÄÇÂú®ÁêÜË´ñ‰∏äÔºåÊàëÂÄëË°®Êòé ACE ÁöÑË®≠Ë®àÂèØ‰ª•Âú®‰º∫ÊúçÂô®‰ΩøÁî®Âª£Ê≥õ‰ΩøÁî®ÁöÑÈ§òÂº¶Ë∑ùÈõ¢Â∫¶Èáè‰æÜË°°ÈáèË≤¢ÁçªÊôÇÔºåÊúâÊïàÂú∞ÊèêÂçáÊÉ°ÊÑèÂÆ¢Êà∂ÁöÑÊÑüÁü•Ë≤¢Áçª„ÄÇÊ†πÊìöÁ∂ìÈ©óÔºåÊàëÂÄëÁöÑÁµêÊûúË°®Êòé ACE ÊúâÊïà‰∏îÊúâÊïàÂú∞Ê¨∫È®ô‰∫Ü‰∫îÁ®ÆÊúÄÂÖàÈÄ≤ÁöÑË≤¢ÁçªË©ï‰º∞ÊñπÊ≥ï„ÄÇÊ≠§Â§ñÔºåACE ‰øùÁïô‰∫ÜÊúÄÁµÇÂÖ®Â±ÄÊ®°ÂûãÂú®Ê∏¨Ë©¶Ëº∏ÂÖ•‰∏äÁöÑÊ∫ñÁ¢∫ÊÄß„ÄÇÊàëÂÄëÈÇÑÊé¢Á¥¢‰∫ÜÂÖ≠Á®ÆÂ∞çÊäó ACE ÁöÑÂ∞çÁ≠ñ„ÄÇÊàëÂÄëÁöÑÁµêÊûúË°®ÊòéÂÆÉÂÄë‰∏çË∂≥‰ª•ÈòªÊ≠¢ ACEÔºåÂº∑Ë™ø‰∫ÜËø´ÂàáÈúÄË¶ÅÊñ∞ÁöÑÈò≤Á¶¶Êé™ÊñΩ‰æÜ‰øùË≠∑ FL ‰∏≠ÁöÑË≤¢ÁçªË©ï‰º∞ÊñπÊ≥ï„ÄÇ</paragraph>

##### **SaySelf: Teaching LLMs to Express Confidence with Self-Reflective Rationales**
2405.20974v1 by Tianyang Xu, Shujin Wu, Shizhe Diao, Xiaoze Liu, Xingyao Wang, Yangyi Chen, Jing Gao

Large language models (LLMs) often generate inaccurate or fabricated
information and generally fail to indicate their confidence, which limits their
broader applications. Previous work elicits confidence from LLMs by direct or
self-consistency prompting, or constructing specific datasets for supervised
finetuning. The prompting-based approaches have inferior performance, and the
training-based approaches are limited to binary or inaccurate group-level
confidence estimates. In this work, we present the advanced SaySelf, a training
framework that teaches LLMs to express more accurate fine-grained confidence
estimates. In addition, beyond the confidence scores, SaySelf initiates the
process of directing LLMs to produce self-reflective rationales that clearly
identify gaps in their parametric knowledge and explain their uncertainty. This
is achieved by using an LLM to automatically summarize the uncertainties in
specific knowledge via natural language. The summarization is based on the
analysis of the inconsistency in multiple sampled reasoning chains, and the
resulting data is utilized for supervised fine-tuning. Moreover, we utilize
reinforcement learning with a meticulously crafted reward function to calibrate
the confidence estimates, motivating LLMs to deliver accurate, high-confidence
predictions and to penalize overconfidence in erroneous outputs. Experimental
results in both in-distribution and out-of-distribution datasets demonstrate
the effectiveness of SaySelf in reducing the confidence calibration error and
maintaining the task performance. We show that the generated self-reflective
rationales are reasonable and can further contribute to the calibration. The
code is made public at \url{https://github.com/xu1868/SaySelf}.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâÁ∂ìÂ∏∏Áî¢Áîü‰∏çÊ∫ñÁ¢∫ÊàñËôõÊßãÁöÑË≥áË®äÔºå‰∏îÈÄöÂ∏∏ÁÑ°Ê≥ïÊåáÂá∫ÂÖ∂‰ø°ÂøÉÔºåÈÄôÈôêÂà∂‰∫ÜÂÖ∂Âª£Ê≥õÁöÑÊáâÁî®„ÄÇÂÖàÂâçÁöÑÁ†îÁ©∂ÈÄèÈÅéÁõ¥Êé•ÊàñËá™Êàë‰∏ÄËá¥ÁöÑÊèêÁ§∫ÔºåÊàñÂª∫ÊßãÁâπÂÆöË≥áÊñôÈõÜ‰ª•ÈÄ≤Ë°åÁõ£Áù£ÂºèÂæÆË™øÔºåÂæû LLM ‰∏≠ÂºïÂá∫‰ø°ÂøÉ„ÄÇÂü∫ÊñºÊèêÁ§∫ÁöÑÊñπÊ≥ïÊïàËÉΩËºÉÂ∑ÆÔºåËÄåÂü∫ÊñºË®ìÁ∑¥ÁöÑÊñπÊ≥ïÂâáÂÉÖÈôêÊñº‰∫åÂÖÉÊàñ‰∏çÊ∫ñÁ¢∫ÁöÑÁæ§ÁµÑÂ±§Á¥ö‰ø°ÂøÉ‰º∞Ë®à„ÄÇÂú®ÈÄôÈ†ÖÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫ÜÈÄ≤ÈöéÁöÑ SaySelfÔºåÈÄôÊòØ‰∏ÄÁ®ÆË®ìÁ∑¥Êû∂ÊßãÔºåÁî®ÊñºÊïôÂ∞é LLM Ë°®ÈÅîÊõ¥Ê∫ñÁ¢∫ÁöÑÁ¥∞Á≤íÂ∫¶‰ø°ÂøÉ‰º∞Ë®à„ÄÇÊ≠§Â§ñÔºåÈô§‰∫Ü‰ø°ÂøÉÂàÜÊï∏‰πãÂ§ñÔºåSaySelf ÈÇÑÂïüÂãï‰∫ÜÂºïÂ∞é LLM Áî¢ÁîüËá™ÊàëÂèçÁúÅÁöÑ‰æùÊìöÁöÑÁ®ãÂ∫èÔºåÊ∏ÖÊ•öÂú∞ÊâæÂá∫ÂÖ∂ÂèÉÊï∏Áü•Ë≠ò‰∏≠ÁöÑÂ∑ÆË∑ù‰∏¶Ëß£ÈáãÂÖ∂‰∏çÁ¢∫ÂÆöÊÄß„ÄÇÈÄôÈÄèÈÅé‰ΩøÁî® LLM ‰ª•Ëá™ÁÑ∂Ë™ûË®ÄËá™ÂãïÊëòË¶ÅÁâπÂÆöÁü•Ë≠ò‰∏≠ÁöÑ‰∏çÁ¢∫ÂÆöÊÄß‰æÜÂØ¶Áèæ„ÄÇÊëòË¶ÅÂü∫ÊñºÂ∞çÂ§öÂÄãÂèñÊ®£Êé®ÁêÜÈèà‰∏≠‰∏ç‰∏ÄËá¥ÊÄßÁöÑÂàÜÊûêÔºåËÄåÁî¢ÁîüÁöÑË≥áÊñôÁî®ÊñºÁõ£Áù£ÂºèÂæÆË™ø„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂà©Áî®Á∂ìÈÅéÁ≤æÂøÉË®≠Ë®àÁöÑÁçéÂãµÂáΩÊï∏ÈÄ≤Ë°åÂº∑ÂåñÂ≠∏ÁøíÔºå‰ª•Ê†°Ê∫ñ‰ø°ÂøÉ‰º∞Ë®àÔºå‰øÉ‰Ωø LLM Êèê‰æõÊ∫ñÁ¢∫„ÄÅÈ´ò‰ø°ÂøÉÁöÑÈ†êÊ∏¨Ôºå‰∏¶Êá≤ÁΩ∞Â∞çÈåØË™§Ëº∏Âá∫ÁöÑÈÅéÂ∫¶Ëá™‰ø°„ÄÇÁÑ°Ë´ñÊòØÂú®ÂàÜ‰ΩàÂÖßÈÇÑÊòØÂàÜ‰ΩàÂ§ñË≥áÊñôÈõÜ‰∏≠ÁöÑÂØ¶È©óÁµêÊûúÔºåÈÉΩË≠âÊòé‰∫Ü SaySelf Âú®Ê∏õÂ∞ë‰ø°ÂøÉÊ†°Ê∫ñË™§Â∑ÆÂíåÁ∂≠ÊåÅ‰ªªÂãôÊïàËÉΩÊñπÈù¢ÁöÑÊúâÊïàÊÄß„ÄÇÊàëÂÄëË≠âÊòé‰∫ÜÁî¢ÁîüÁöÑËá™ÊàëÂèçÁúÅÁöÑ‰æùÊìöÊòØÂêàÁêÜÁöÑÔºå‰∏¶‰∏îÂèØ‰ª•ÈÄ≤‰∏ÄÊ≠•ÊúâÂä©ÊñºÊ†°Ê∫ñ„ÄÇÁ®ãÂºèÁ¢ºÂ∑≤ÂÖ¨ÈñãÊñº\url{https://github.com/xu1868/SaySelf}„ÄÇ

##### **LCQ: Low-Rank Codebook based Quantization for Large Language Models**
2405.20973v1 by Wen-Pu Cai, Wu-Jun Li

Large language models~(LLMs) have recently demonstrated promising performance
in many tasks. However, the high storage and computational cost of LLMs has
become a challenge for deploying LLMs. Weight quantization has been widely used
for model compression, which can reduce both storage and computational cost.
Most existing weight quantization methods for LLMs use a rank-one codebook for
quantization, which results in substantial accuracy loss when the compression
ratio is high. In this paper, we propose a novel weight quantization method,
called low-rank codebook based quantization~(LCQ), for LLMs. LCQ adopts a
low-rank codebook, the rank of which can be larger than one, for quantization.
Experiments show that LCQ can achieve better accuracy than existing methods
with a negligibly extra storage cost.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ËøëÊúüÂú®Ë®±Â§ö‰ªªÂãô‰∏≠Â±ïÁèæÂá∫‰ª§‰∫∫ÊªøÊÑèÁöÑË°®Áèæ„ÄÇÁÑ∂ËÄåÔºåLLM È´òÊòÇÁöÑÂÑ≤Â≠òÂíåÈÅãÁÆóÊàêÊú¨Â∑≤ÊàêÁÇ∫ÈÉ®ÁΩ≤ LLM ÁöÑ‰∏ÄÈ†ÖÊåëÊà∞„ÄÇÊ¨äÈáçÈáèÂåñÂ∑≤Âª£Ê≥õÁî®ÊñºÊ®°ÂûãÂ£ìÁ∏ÆÔºåÈÄôÂèØ‰ª•ÂêåÊôÇÈôç‰ΩéÂÑ≤Â≠òÂíåÈÅãÁÆóÊàêÊú¨„ÄÇÁèæÊúâÈáùÂ∞ç LLM ÁöÑÊ¨äÈáçÈáèÂåñÊñπÊ≥ïÂ§ßÂ§ö‰ΩøÁî®Áß©‰∏ÄÁ¢ºÊú¨ÈÄ≤Ë°åÈáèÂåñÔºåÈÄôÊúÉÂú®Â£ìÁ∏ÆÁéáËºÉÈ´òÊôÇÂ∞éËá¥È°ØËëóÁöÑÊ∫ñÁ¢∫Â∫¶ÊêçÂ§±„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂêçÁÇ∫Âü∫Êñº‰ΩéÁß©Á¢ºÊú¨ÈáèÂåñÁöÑ (LCQ) Êñ∞Á©éÊ¨äÈáçÈáèÂåñÊñπÊ≥ïÔºåÈÅ©Áî®Êñº LLM„ÄÇLCQ Êé°Áî®Áß©‰ΩéÊñº‰∏Ä‰∏îÁß©ÂèØ‰ª•Â§ßÊñº‰∏ÄÁöÑ‰ΩéÁß©Á¢ºÊú¨ÈÄ≤Ë°åÈáèÂåñ„ÄÇÂØ¶È©óÈ°ØÁ§∫ÔºåLCQ ÂèØ‰ª•ÊØîÁèæÊúâÊñπÊ≥ïÁç≤ÂæóÊõ¥Â•ΩÁöÑÊ∫ñÁ¢∫Â∫¶Ôºå‰∏îÂÑ≤Â≠òÊàêÊú¨Âπæ‰πéÊ≤íÊúâÂ¢ûÂä†„ÄÇ

##### **Superlatives in Context: Explicit and Implicit Domain Restrictions for Superlative Frames**
2405.20967v1 by Valentina Pyatkin, Bonnie Webber, Ido Dagan, Reut Tsarfaty

Superlatives are used to single out elements with a maximal/minimal property.
Semantically, superlatives perform a set comparison: something (or some things)
has the min/max property out of a set. As such, superlatives provide an ideal
phenomenon for studying implicit phenomena and discourse restrictions. While
this comparison set is often not explicitly defined, its (implicit)
restrictions can be inferred from the discourse context the expression appears
in. In this work we provide an extensive computational study on the semantics
of superlatives. We propose a unified account of superlative semantics which
allows us to derive a broad-coverage annotation schema. Using this unified
schema we annotated a multi-domain dataset of superlatives and their semantic
interpretations. We specifically focus on interpreting implicit or ambiguous
superlative expressions, by analyzing how the discourse context restricts the
set of interpretations. In a set of experiments we then analyze how well models
perform at variations of predicting superlative semantics, with and without
context. We show that the fine-grained semantics of superlatives in context can
be challenging for contemporary models, including GPT-4.

ÊëòË¶ÅÔºöÊúÄÈ´òÁ∫ßÁî®‰∫éÊåëÈÄâÂÖ∑ÊúâÊúÄÂ§ß/ÊúÄÂ∞èÂ±ûÊÄßÁöÑÂÖÉÁ¥†„ÄÇ
ËØ≠‰πâ‰∏äÔºåÊúÄÈ´òÁ∫ßÊâßË°åÈõÜÂêàÊØîËæÉÔºöÊüêÁâ©ÔºàÊàñÊüê‰∫õ‰∫ãÁâ©Ôºâ
Âú®ÈõÜÂêà‰∏≠ÂÖ∑ÊúâÊúÄÂ∞è/ÊúÄÂ§ßÂ±ûÊÄß„ÄÇÂõ†Ê≠§ÔºåÊúÄÈ´òÁ∫ß‰∏∫Á†îÁ©∂ÈöêÂê´Áé∞Ë±°ÂíåËØùËØ≠ÈôêÂà∂Êèê‰æõ‰∫ÜÁêÜÊÉ≥Áé∞Ë±°„ÄÇËôΩÁÑ∂
Ê≠§ÊØîËæÉÈõÜÂêàÈÄöÂ∏∏Êú™ÊòéÁ°ÆÂÆö‰πâÔºå‰ΩÜÂÖ∂ÔºàÈöêÂê´ÁöÑÔºâ
ÈôêÂà∂ÂèØ‰ª•‰ªéË°®ËææÂºèÂá∫Áé∞ÁöÑËØ≠ÁØá‰∏ä‰∏ãÊñá‰∏≠Êé®Êñ≠Âá∫Êù•„ÄÇÂú®ËøôÈ°πÂ∑•‰Ωú‰∏≠ÔºåÊàë‰ª¨ÂØπËØ≠‰πâ
ÊúÄÈ´òÁ∫ßËøõË°å‰∫ÜÂπøÊ≥õÁöÑËÆ°ÁÆóÁ†îÁ©∂„ÄÇÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏Ä‰∏™Áªü‰∏ÄÁöÑÊúÄÈ´òÁ∫ßËØ≠‰πâËØ¥ÊòéÔºåÂÆÉ
‰ΩøÊàë‰ª¨ËÉΩÂ§üÊé®ÂØºÂá∫ÂπøÊ≥õË¶ÜÁõñÁöÑÊ≥®ÈáäÊ®°Âºè„ÄÇ‰ΩøÁî®Ê≠§Áªü‰∏Ä
Ê®°ÂºèÔºåÊàë‰ª¨Ê≥®Èáä‰∫Ü‰∏Ä‰∏™ÂåÖÂê´ÊúÄÈ´òÁ∫ßÂèäÂÖ∂ËØ≠‰πâÁöÑÂ§öÂüüÊï∞ÊçÆÈõÜ
Ëß£Èáä„ÄÇÊàë‰ª¨ÁâπÂà´‰∏ìÊ≥®‰∫éËß£ÈáäÈöêÂê´ÊàñÊ®°Ê£±‰∏§ÂèØÁöÑ
ÊúÄÈ´òÁ∫ßË°®ËææÂºèÔºåÈÄöËøáÂàÜÊûêËØ≠ÁØá‰∏ä‰∏ãÊñáÂ¶Ç‰ΩïÈôêÂà∂
Ëß£ÈáäÈõÜ„ÄÇÂú®‰∏ÄÁªÑÂÆûÈ™å‰∏≠ÔºåÊàë‰ª¨ÈöèÂêéÂàÜÊûê‰∫ÜÊ®°Âûã
Âú®È¢ÑÊµãÊúÄÈ´òÁ∫ßËØ≠‰πâÁöÑÂèò‰Ωì‰∏≠ÊâßË°åÂæóÂ¶Ç‰ΩïÔºåÊúâÂíåÊ≤°Êúâ
‰∏ä‰∏ãÊñá„ÄÇÊàë‰ª¨Ë°®ÊòéÔºå‰∏ä‰∏ãÊñá‰∏≠ÊúÄÈ´òÁ∫ßÁöÑÁªÜÁ≤íÂ∫¶ËØ≠‰πâÂØπÂΩì‰ª£Ê®°ÂûãÊù•ËØ¥ÂèØËÉΩÂÖ∑ÊúâÊåëÊàòÊÄßÔºåÂåÖÊã¨ GPT-4„ÄÇ

##### **Large Language Models are Zero-Shot Next Location Predictors**
2405.20962v2 by Ciro Beneduce, Bruno Lepri, Massimiliano Luca

Predicting the locations an individual will visit in the future is crucial
for solving many societal issues like disease diffusion and reduction of
pollution among many others. The models designed to tackle next-location
prediction, however, require a significant amount of individual-level
information to be trained effectively. Such data may be scarce or even
unavailable in some geographic regions or peculiar scenarios (e.g., cold-start
in recommendation systems). Moreover, the design of a next-location predictor
able to generalize or geographically transfer knowledge is still an open
research challenge. Recent advances in natural language processing have led to
a rapid diffusion of Large Language Models (LLMs) which have shown good
generalization and reasoning capabilities. These insights, coupled with the
recent findings that LLMs are rich in geographical knowledge, allowed us to
believe that these models can act as zero-shot next-location predictors. This
paper evaluates the capabilities of many popular LLMs in this role,
specifically Llama, GPT-3.5 and Mistral 7B. After designing a proper prompt, we
tested the models on three real-world mobility datasets. The results show that
LLMs can obtain accuracies up to 32.4%, a significant relative improvement of
over 600% when compared to sophisticated DL models specifically designed for
human mobility. Moreover, we show that other LLMs are unable to perform the
task properly. To prevent positively biased results, we also propose a
framework inspired by other studies to test data contamination. Finally, we
explored the possibility of using LLMs as text-based explainers for
next-location prediction showing that can effectively provide an explanation
for their decision. Notably, 7B models provide more generic, but still
reliable, explanations compared to larger counterparts. Code:
github.com/ssai-trento/LLM-zero-shot-NL

ÊëòË¶ÅÔºö<paragraph>È†êÊ∏¨ÂÄã‰∫∫Êú™‰æÜÊúÉÈÄ†Ë®™ÁöÑÂú∞ÈªûÂ∞çÊñºËß£Ê±∫Ë®±Â§öÁ§æÊúÉÂïèÈ°åËá≥ÈóúÈáçË¶ÅÔºå‰æãÂ¶ÇÁñæÁóÖÊì¥Êï£ÂíåÊ∏õÂ∞ëÊ±°ÊüìÁ≠â„ÄÇ‰∏çÈÅéÔºåÁî®‰æÜËôïÁêÜ‰∏ãÂÄãÂú∞ÈªûÈ†êÊ∏¨ÁöÑÊ®°ÂûãÈúÄË¶ÅÂ§ßÈáèÁöÑÂÄã‰∫∫Â±§Á¥öË≥áË®äÊâçËÉΩÊúâÊïàË®ìÁ∑¥„ÄÇÊ≠§È°ûË≥áÊñôÂú®Êüê‰∫õÂú∞ÁêÜÂçÄÂüüÊàñÁâπÊÆäÊÉÖÊ≥Å‰∏≠ÂèØËÉΩÁ®ÄÂ∞ëÁîöËá≥ÁÑ°Ê≥ïÂèñÂæóÔºà‰æãÂ¶ÇÊé®Ëñ¶Á≥ªÁµ±‰∏≠ÁöÑÂÜ∑ÂïüÂãïÔºâ„ÄÇÊ≠§Â§ñÔºåË®≠Ë®à‰∏ÄÂÄãËÉΩÂ§†Ê¶ÇÂåñÊàñÂú®Âú∞ÁêÜ‰∏äÂÇ≥ÈÅûÁü•Ë≠òÁöÑ‰∏ãÂÄãÂú∞ÈªûÈ†êÊ∏¨Âô®‰ªçÁÑ∂ÊòØ‰∏ÄÈ†ÖÈñãÊîæÁöÑÁ†îÁ©∂ÊåëÊà∞„ÄÇËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜÁöÑÊúÄÊñ∞ÈÄ≤Â±ïÂ∑≤Â∞éËá¥Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âø´ÈÄüÊì¥Êï£ÔºåÈÄô‰∫õÊ®°ÂûãÂ∑≤Â±ïÁèæËâØÂ•ΩÁöÑÊ¶ÇÂåñÂíåÊé®ÁêÜËÉΩÂäõ„ÄÇÈÄô‰∫õË¶ãËß£Âä†‰∏ä LLM ÂØåÂê´Âú∞ÁêÜÁü•Ë≠òÁöÑÊúÄÊñ∞ÁôºÁèæÔºåËÆìÊàëÂÄëÁõ∏‰ø°ÈÄô‰∫õÊ®°ÂûãÂèØ‰ª•‰ΩúÁÇ∫Èõ∂Ê¨°Â≠∏ÁøíÁöÑ‰∏ãÂÄãÂú∞ÈªûÈ†êÊ∏¨Âô®„ÄÇÊú¨ÊñáË©ï‰º∞Ë®±Â§öÁÜ±ÈñÄ LLM Âú®Ê≠§ËßíËâ≤‰∏≠ÁöÑËÉΩÂäõÔºåÁâπÂà•ÊòØ Llama„ÄÅGPT-3.5 Âíå Mistral 7B„ÄÇÂú®Ë®≠Ë®àÈÅ©Áï∂ÁöÑÊèêÁ§∫ÂæåÔºåÊàëÂÄëÂú®‰∏âÂÄãÁúüÂØ¶‰∏ñÁïåÊµÅÂãïÊÄßË≥áÊñôÈõÜ‰∏äÊ∏¨Ë©¶ÈÄô‰∫õÊ®°Âûã„ÄÇÁµêÊûúÈ°ØÁ§∫ LLM ÂèØ‰ª•Áç≤ÂæóÈ´òÈÅî 32.4% ÁöÑÊ∫ñÁ¢∫Â∫¶ÔºåËàáÂ∞àÈñÄÁÇ∫‰∫∫È°ûÊµÅÂãïÊÄßË®≠Ë®àÁöÑÁ≤æÂØÜ DL Ê®°ÂûãÁõ∏ÊØîÔºåÁõ∏Â∞çÊîπÂñÑÂπÖÂ∫¶Ë∂ÖÈÅé 600%„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÈ°ØÁ§∫ÂÖ∂‰ªñ LLM ÁÑ°Ê≥ïÈÅ©Áï∂Âü∑Ë°å‰ªªÂãô„ÄÇÁÇ∫Èò≤Ê≠¢Ê≠£ÂêëÂÅèÂ∑ÆÁöÑÁµêÊûúÔºåÊàëÂÄë‰πüÊèêÂá∫‰∏ÄÂÄãÂèóÂÖ∂‰ªñÁ†îÁ©∂ÂïüÁôºÁöÑÊû∂Êßã‰æÜÊ∏¨Ë©¶Ë≥áÊñôÊ±°Êüì„ÄÇÊúÄÂæåÔºåÊàëÂÄëÊé¢Á¥¢‰ΩøÁî® LLM ‰ΩúÁÇ∫‰∏ãÂÄãÂú∞ÈªûÈ†êÊ∏¨ÁöÑÂü∫ÊñºÊñáÂ≠óÁöÑË™™ÊòéÂ∑•ÂÖ∑ÁöÑÂèØËÉΩÊÄßÔºåÈ°ØÁ§∫ÂèØ‰ª•ÊúâÊïàÊèê‰æõÂÖ∂Ê±∫Á≠ñÁöÑË™™Êòé„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåËàáËºÉÂ§ßÁöÑÂ∞çÊáâÊ®°ÂûãÁõ∏ÊØîÔºå7B Ê®°ÂûãÊèê‰æõÁöÑË™™ÊòéÊõ¥ÈÄöÁî®Ôºå‰ΩÜ‰ªçÁÑ∂ÂèØÈù†„ÄÇÁ®ãÂºèÁ¢ºÔºögithub.com/ssai-trento/LLM-zero-shot-NL</paragraph>

##### **Navigating Tabular Data Synthesis Research: Understanding User Needs and Tool Capabilities**
2405.20959v1 by Maria F. Davila R., Sven Groen, Fabian Panse, Wolfram Wingerath

In an era of rapidly advancing data-driven applications, there is a growing
demand for data in both research and practice. Synthetic data have emerged as
an alternative when no real data is available (e.g., due to privacy
regulations). Synthesizing tabular data presents unique and complex challenges,
especially handling (i) missing values, (ii) dataset imbalance, (iii) diverse
column types, and (iv) complex data distributions, as well as preserving (i)
column correlations, (ii) temporal dependencies, and (iii) integrity
constraints (e.g., functional dependencies) present in the original dataset.
While substantial progress has been made recently in the context of
generational models, there is no one-size-fits-all solution for tabular data
today, and choosing the right tool for a given task is therefore no trivial
task. In this paper, we survey the state of the art in Tabular Data Synthesis
(TDS), examine the needs of users by defining a set of functional and
non-functional requirements, and compile the challenges associated with meeting
those needs. In addition, we evaluate the reported performance of 36 popular
research TDS tools about these requirements and develop a decision guide to
help users find suitable TDS tools for their applications. The resulting
decision guide also identifies significant research gaps.

ÊëòË¶ÅÔºö<paragraph>Âú®Âø´ÈÄüÊé®ÈÄ≤ÁöÑÊï∏ÊìöÈ©ÖÂãïÊáâÁî®Á®ãÂºèÊôÇ‰ª£ÔºåÁ†îÁ©∂ÂíåÂØ¶ÂãôÂ∞çË≥áÊñôÁöÑÈúÄÊ±ÇËàáÊó•‰ø±Â¢û„ÄÇÁï∂Ê≤íÊúâÁúüÂØ¶Ë≥áÊñôÂèØÁî®ÊôÇÔºà‰æãÂ¶ÇÔºåÁî±ÊñºÈö±ÁßÅÊ≥ïË¶èÔºâÔºåÂêàÊàêË≥áÊñôÂ∑≤ÊàêÁÇ∫‰∏ÄÁ®ÆÊõø‰ª£ÊñπÊ°à„ÄÇÂêàÊàêË°®Ê†ºË≥áÊñôÊúÉÂá∫ÁèæÁç®Áâπ‰∏îË§áÈõúÁöÑÊåëÊà∞ÔºåÁâπÂà•ÊòØËôïÁêÜÔºà‰∏ÄÔºâÈÅ∫Â§±ÂÄº„ÄÅÔºà‰∫åÔºâË≥áÊñôÈõÜ‰∏çÂπ≥Ë°°„ÄÅÔºà‰∏âÔºâÂ§öÊ®£ÂåñÁöÑÊ¨Ñ‰ΩçÈ°ûÂûãÂíåÔºàÂõõÔºâË§áÈõúÁöÑË≥áÊñôÂàÜ‰ΩàÔºå‰ª•Âèä‰øùÁïôÔºà‰∏ÄÔºâÊ¨Ñ‰ΩçÈóúËÅØÊÄß„ÄÅÔºà‰∫åÔºâÊôÇÈñì‰æùË≥¥ÊÄßÔºå‰ª•ÂèäÔºà‰∏âÔºâÂéüÂßãË≥áÊñôÈõÜ‰∏≠Â≠òÂú®ÁöÑÂÆåÊï¥ÊÄßÁ¥ÑÊùüÔºà‰æãÂ¶ÇÔºåÂáΩÊï∏‰æùË≥¥ÊÄßÔºâ„ÄÇÈõñÁÑ∂ÊúÄËøëÂú®ÁîüÊàêÊ®°ÂûãÁöÑËÉåÊôØ‰∏ãÂèñÂæó‰∫ÜÂØ¶Ë≥™ÊÄßÈÄ≤Â±ïÔºå‰ΩÜÁõÆÂâçÂ∞çÊñºË°®Ê†ºË≥áÊñô‰∏¶Ê≤íÊúâ‰∏ÄÈ´îÈÅ©Áî®ÁöÑËß£Ê±∫ÊñπÊ°àÔºåÂõ†Ê≠§ÁÇ∫ÁâπÂÆö‰ªªÂãôÈÅ∏ÊìáÊ≠£Á¢∫ÁöÑÂ∑•ÂÖ∑‰∏¶ÈùûÊòì‰∫ã„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëË™øÊü•‰∫ÜË°®Ê†ºË≥áÊñôÂêàÊàê (TDS) ÁöÑÊúÄÊñ∞ÊäÄË°ìÔºåÈÄèÈÅéÂÆöÁæ©‰∏ÄÁµÑÂäüËÉΩÊÄßÂíåÈùûÂäüËÉΩÊÄßÈúÄÊ±Ç‰æÜÊé¢Ë®é‰ΩøÁî®ËÄÖÁöÑÈúÄÊ±ÇÔºå‰∏¶ÂΩôÁ∑®ÊªøË∂≥ÈÄô‰∫õÈúÄÊ±ÇÊâÄÈù¢Ëá®ÁöÑÊåëÊà∞„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëË©ï‰º∞‰∫Ü 36 Á®ÆÊµÅË°åÁöÑÁ†îÁ©∂ TDS Â∑•ÂÖ∑ÈóúÊñºÈÄô‰∫õÈúÄÊ±ÇÁöÑÂ†±ÂëäÊïàËÉΩÔºå‰∏¶Âà∂ÂÆö‰∫Ü‰∏ÄÂÄãÊ±∫Á≠ñÊåáÂçóÔºå‰ª•Âπ´Âä©‰ΩøÁî®ËÄÖÁÇ∫ÂÖ∂ÊáâÁî®Á®ãÂºèÊâæÂà∞ÂêàÈÅ©ÁöÑ TDS Â∑•ÂÖ∑„ÄÇÁî¢ÁîüÁöÑÊ±∫Á≠ñÊåáÂçó‰πüÊâæÂá∫‰∫ÜÈáçË¶ÅÁöÑÁ†îÁ©∂Â∑ÆË∑ù„ÄÇ</paragraph>

##### **A Robot Walks into a Bar: Can Language Models Serve asCreativity Support Tools for Comedy? An Evaluation of LLMs' Humour Alignment with Comedians**
2405.20956v1 by Piotr Wojciech Mirowski, Juliette Love, Kory W. Mathewson, Shakir Mohamed

We interviewed twenty professional comedians who perform live shows in front
of audiences and who use artificial intelligence in their artistic process as
part of 3-hour workshops on ``AI x Comedy'' conducted at the Edinburgh Festival
Fringe in August 2023 and online. The workshop consisted of a comedy writing
session with large language models (LLMs), a human-computer interaction
questionnaire to assess the Creativity Support Index of AI as a writing tool,
and a focus group interrogating the comedians' motivations for and processes of
using AI, as well as their ethical concerns about bias, censorship and
copyright. Participants noted that existing moderation strategies used in
safety filtering and instruction-tuned LLMs reinforced hegemonic viewpoints by
erasing minority groups and their perspectives, and qualified this as a form of
censorship. At the same time, most participants felt the LLMs did not succeed
as a creativity support tool, by producing bland and biased comedy tropes, akin
to ``cruise ship comedy material from the 1950s, but a bit less racist''. Our
work extends scholarship about the subtle difference between, one the one hand,
harmful speech, and on the other hand, ``offensive'' language as a practice of
resistance, satire and ``punching up''. We also interrogate the global value
alignment behind such language models, and discuss the importance of
community-based value alignment and data ownership to build AI tools that
better suit artists' needs.

ÊëòË¶ÅÔºö<paragraph>ÊàëÂÄëÊé°Ë®™‰∫Ü‰∫åÂçÅ‰ΩçÂú®ÊÑõ‰∏ÅÂ†°ËóùÁ©óÁØÄ 2023 Âπ¥ 8 ÊúàÂíåÁ∑ö‰∏äËàâËæ¶ÁöÑ„ÄåAI x ÂñúÂäá„Äç3 Â∞èÊôÇÂ∑•‰ΩúÂùä‰∏≠ÔºåÂú®ËßÄÁúæÈù¢ÂâçÈÄ≤Ë°åÁèæÂ†¥Ë°®ÊºîÔºå‰∏¶Âú®Ââµ‰ΩúÈÅéÁ®ã‰∏≠‰ΩøÁî®‰∫∫Â∑•Êô∫ÊÖßÁöÑÂ∞àÊ•≠ÂñúÂäáÊºîÂì°„ÄÇÂ∑•‰ΩúÂùäÂåÖÂê´ËàáÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÈÄ≤Ë°åÂñúÂäáÂØ´‰ΩúË™≤Á®ã„ÄÅË©ï‰º∞ AI ‰ΩúÁÇ∫ÂØ´‰ΩúÂ∑•ÂÖ∑ÁöÑÂâµÈÄ†ÂäõÊîØÊè¥ÊåáÊï∏ÁöÑ‰∫∫Ê©ü‰∫íÂãïÂïèÂç∑Ôºå‰ª•ÂèäÁÑ¶ÈªûÂ∞èÁµÑÊé¢Ë®éÂñúÂäáÊºîÂì°‰ΩøÁî® AI ÁöÑÂãïÊ©üÂíåÊµÅÁ®ãÔºå‰ª•Âèä‰ªñÂÄëÂ∞çÂÅèË¶ã„ÄÅÂØ©Êü•ÂíåËëó‰ΩúÊ¨äÁöÑÈÅìÂæ∑ÁñëÊÖÆ„ÄÇËàáÊúÉËÄÖÊåáÂá∫ÔºåÂÆâÂÖ®ÈÅéÊøæÂíåÊåá‰ª§Ë™øÊï¥ LLM ‰∏≠‰ΩøÁî®ÁöÑÁèæÊúâÂØ©Ê†∏Á≠ñÁï•ÔºåÈÄèÈÅéÊäπÈô§Â∞ëÊï∏Áæ§È´îÂèäÂÖ∂ËßÄÈªûÔºåÂº∑Âåñ‰∫ÜÈú∏Ê¨äËßÄÈªûÔºå‰∏¶Â∞áÊ≠§Ë™çÂÆöÁÇ∫‰∏ÄÁ®ÆÂØ©Êü•ÂΩ¢Âºè„ÄÇÂêåÊôÇÔºåÂ§ßÂ§öÊï∏ËàáÊúÉËÄÖË™çÁÇ∫ LLM ÁÑ°Ê≥ï‰ΩúÁÇ∫ÂâµÈÄ†ÂäõÊîØÊè¥Â∑•ÂÖ∑Áç≤ÂæóÊàêÂäüÔºåÂõ†ÁÇ∫ÂÆÉÂÄëÁî¢ÁîüÁöÑÂñúÂäáÊ©ãÊÆµÂπ≥Ê∑°‰∏îÊúâÂÅèË¶ãÔºåÈ°û‰ººÊñº„Äå1950 Âπ¥‰ª£ÁöÑÈÉµËº™ÂñúÂäáÁ¥†ÊùêÔºå‰ΩÜÁ®ÆÊóèÊ≠ßË¶ñÊÑèÂë≥Á®çÊ∑°„Äç„ÄÇÊàëÂÄëÁöÑ‰ΩúÂìÅÊì¥Â±ï‰∫ÜÈóúÊñºÊúâÂÆ≥Ë®ÄË´ñËàá„ÄåÂÜíÁäØÊÄß„ÄçË™ûË®Ä‰πãÈñìÂæÆÂ¶ôÂ∑ÆÁï∞ÁöÑÁ†îÁ©∂ÔºåÂæåËÄÖÊòØ‰∏ÄÁ®ÆÊäµÊäó„ÄÅË´∑Âà∫Âíå„ÄåÂêë‰∏äÊîªÊìä„ÄçÁöÑÂØ¶Ë∏ê„ÄÇÊàëÂÄë‰πüÊé¢Ë®é‰∫ÜÊ≠§È°ûË™ûË®ÄÊ®°ÂûãËÉåÂæåÁöÑÂÖ®ÁêÉÂÉπÂÄºËßÄ‰∏ÄËá¥ÊÄßÔºå‰∏¶Ë®éË´ñ‰∫Ü‰ª•Á§æÁæ§ÁÇ∫Âü∫Á§éÁöÑÂÉπÂÄºËßÄ‰∏ÄËá¥ÊÄßÂíåË≥áÊñôÊâÄÊúâÊ¨äÔºåÂ∞çÊñºÂª∫ÊßãÊõ¥Á¨¶ÂêàËóùË°ìÂÆ∂ÈúÄÊ±ÇÁöÑ AI Â∑•ÂÖ∑ÁöÑÈáçË¶ÅÊÄß„ÄÇ</paragraph>

##### **OR-Bench: An Over-Refusal Benchmark for Large Language Models**
2405.20947v1 by Justin Cui, Wei-Lin Chiang, Ion Stoica, Cho-Jui Hsieh

Large Language Models (LLMs) require careful safety alignment to prevent
malicious outputs. While significant research focuses on mitigating harmful
content generation, the enhanced safety often come with the side effect of
over-refusal, where the LLMs may reject innocuous prompts and become less
helpful. Although the issue of over-refusal has been empirically observed, a
systematic measurement is challenging due to the difficulty of crafting prompts
that appear harmful but are benign. This study proposes a novel method for
automatically generating large-scale sets of ``seemingly toxic prompts''
(benign prompts likely rejected by LLMs). Leveraging this technique, we
introduce OR-Bench, the first large-scale over-refusal benchmark. OR-Bench
comprises 80,000 seemingly toxic prompts across 10 common rejection categories,
a subset of around 1,000 hard prompts that are challenging even for
state-of-the-art LLMs, and an additional 600 toxic prompts to prevent
indiscriminate responses. We then conduct a comprehensive study to measure the
over-refusal of 25 popular LLMs across 8 model families. Our datasets are
available at https://huggingface.co/datasets/bench-llm/OR-Bench and the
corresponding demo can be found at
https://huggingface.co/spaces/bench-llm/or-bench. We hope this benchmark can
help the community develop better safety aligned models.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÈúÄË¶ÅË¨πÊÖéÁöÑÂÆâÂÖ®Ë™øÊï¥Ôºå‰ª•Èò≤Ê≠¢ÊÉ°ÊÑèËº∏Âá∫„ÄÇÈõñÁÑ∂ÈáçË¶ÅÁöÑÁ†îÁ©∂Â∞àÊ≥®ÊñºÊ∏õËºïÊúâÂÆ≥ÂÖßÂÆπÁöÑÁî¢ÁîüÔºå‰ΩÜÂ¢ûÂº∑ÁöÑÂÆâÂÖ®ÈÄöÂ∏∏ÊúÉÁî¢ÁîüÈÅéÂ∫¶ÊãíÁµïÁöÑÂâØ‰ΩúÁî®ÔºåLLM ÂèØËÉΩÊãíÁµïÁÑ°ÂÆ≥ÁöÑÊèêÁ§∫‰∏¶ËÆäÂæó‰∏çÈÇ£È∫ºÊúâÂπ´Âä©„ÄÇÂÑòÁÆ°Â∑≤Á∂ìÁ∂ìÈ©óÊÄßÂú∞ËßÄÂØüÂà∞ÈÅéÂ∫¶ÊãíÁµïÁöÑÂïèÈ°åÔºå‰ΩÜÁî±ÊñºÈõ£‰ª•Êí∞ÂØ´Áúã‰ººÊúâÂÆ≥‰ΩÜËâØÊÄßÁöÑÊèêÁ§∫ÔºåÂõ†Ê≠§Á≥ªÁµ±ÊÄßÁöÑÊ∏¨ÈáèÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÊú¨Á†îÁ©∂ÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆËá™ÂãïÁî¢ÁîüÂ§ßÈáè„ÄåÁúã‰ººÊúâÊØíÁöÑÊèêÁ§∫„ÄçÈõÜÂêàÔºàÂèØËÉΩË¢´ LLM ÊãíÁµïÁöÑËâØÊÄßÊèêÁ§∫ÔºâÁöÑÊñ∞ÊñπÊ≥ï„ÄÇÂà©Áî®Ê≠§ÊäÄË°ìÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü OR-BenchÔºåÈÄôÊòØÁ¨¨‰∏ÄÂÄãÂ§ßË¶èÊ®°ÁöÑÈÅéÂ∫¶ÊãíÁµïÂü∫Ê∫ñ„ÄÇOR-Bench ÂåÖÂê´ 10 ÂÄãÂ∏∏Ë¶ãÊãíÁµïÈ°ûÂà•‰∏≠ÁöÑ 80,000 ÂÄãÁúã‰ººÊúâÊØíÁöÑÊèêÁ§∫Ôºå‰∏ÄÂÄãÁî±Á¥Ñ 1,000 ÂÄãÂç≥‰ΩøÂ∞çÊñºÊúÄÂÖàÈÄ≤ÁöÑ LLM ‰æÜË™™‰πüÂæàÊúâÊåëÊà∞ÊÄßÁöÑÂõ∞Èõ£ÊèêÁ§∫Â≠êÈõÜÔºå‰ª•ÂèäÈ°çÂ§ñÁöÑ 600 ÂÄãÊúâÊØíÊèêÁ§∫Ôºå‰ª•Èò≤Ê≠¢‰∏çÂä†ÂçÄÂà•ÁöÑÂõûÊáâ„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÈÄ≤Ë°å‰∫Ü‰∏ÄÈ†ÖÂÖ®Èù¢Á†îÁ©∂Ôºå‰ª•Ê∏¨Èáè 8 ÂÄãÊ®°ÂûãÁ≥ªÂàó‰∏≠ÁöÑ 25 ÂÄãÊµÅË°å LLM ÁöÑÈÅéÂ∫¶ÊãíÁµï„ÄÇÊàëÂÄëÁöÑÊï∏ÊìöÈõÜÂèØÂú® https://huggingface.co/datasets/bench-llm/OR-Bench Áç≤ÂæóÔºåÂèØ‰ª•Âú® https://huggingface.co/spaces/bench-llm/or-bench ÊâæÂà∞Â∞çÊáâÁöÑÁ§∫ÁØÑ„ÄÇÊàëÂÄëÂ∏åÊúõÊ≠§Âü∫Ê∫ñÂèØ‰ª•Âπ´Âä©Á§æÁæ§ÈñãÁôºÊõ¥Â•ΩÁöÑÂÆâÂÖ®Ë™øÊï¥Ê®°Âûã„ÄÇ

##### **Effective Interplay between Sparsity and Quantization: From Theory to Practice**
2405.20935v1 by Simla Burcu Harma, Ayan Chakraborty, Elizaveta Kostenok, Danila Mishin, Dongho Ha, Babak Falsafi, Martin Jaggi, Ming Liu, Yunho Oh, Suvinay Subramanian, Amir Yazdanbakhsh

The increasing size of deep neural networks necessitates effective model
compression to improve computational efficiency and reduce their memory
footprint. Sparsity and quantization are two prominent compression methods that
have individually demonstrated significant reduction in computational and
memory footprints while preserving model accuracy. While effective, the
interplay between these two methods remains an open question. In this paper, we
investigate the interaction between these two methods and assess whether their
combination impacts final model accuracy. We mathematically prove that applying
sparsity before quantization is the optimal sequence for these operations,
minimizing error in computation. Our empirical studies across a wide range of
models, including OPT and Llama model families (125M-8B) and ViT corroborate
these theoretical findings. In addition, through rigorous analysis, we
demonstrate that sparsity and quantization are not orthogonal; their
interaction can significantly harm model accuracy, with quantization error
playing a dominant role in this degradation. Our findings extend to the
efficient deployment of large models in resource-limited compute platforms and
reduce serving cost, offering insights into best practices for applying these
compression methods to maximize efficacy without compromising accuracy.

ÊëòË¶ÅÔºöÊ∑±Â∫¶Á•ûÁªèÁΩëÁªúÁöÑËßÑÊ®°Êó•ÁõäÊâ©Â§ßÔºåÈúÄË¶ÅÊúâÊïàÁöÑÊ®°ÂûãÂéãÁº©Êù•ÊèêÈ´òËÆ°ÁÆóÊïàÁéáÂπ∂ÂáèÂ∞ëÂÖ∂ÂÜÖÂ≠òÂç†Áî®„ÄÇÁ®ÄÁñèÊÄßÂíåÈáèÂåñÊòØ‰∏§ÁßçÁ™ÅÂá∫ÁöÑÂéãÁº©ÊñπÊ≥ïÔºåÂÆÉ‰ª¨ÂàÜÂà´ËØÅÊòé‰∫ÜÂú®‰øùÊåÅÊ®°ÂûãÂáÜÁ°ÆÊÄßÁöÑÂêåÊó∂ÔºåÊòæËëóÂáèÂ∞ë‰∫ÜËÆ°ÁÆóÂíåÂÜÖÂ≠òÂç†Áî®„ÄÇËôΩÁÑ∂ÊúâÊïàÔºå‰ΩÜËøô‰∏§‰∏™ÊñπÊ≥ï‰πãÈó¥ÁöÑÁõ∏‰∫í‰ΩúÁî®‰ªçÁÑ∂ÊòØ‰∏Ä‰∏™ÊÇ¨ËÄåÊú™ÂÜ≥ÁöÑÈóÆÈ¢ò„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨Á†îÁ©∂‰∫ÜËøô‰∏§ÁßçÊñπÊ≥ï‰πãÈó¥ÁöÑÁõ∏‰∫í‰ΩúÁî®ÔºåÂπ∂ËØÑ‰º∞ÂÆÉ‰ª¨ÁöÑÁªÑÂêàÊòØÂê¶‰ºöÂΩ±ÂìçÊúÄÁªàÁöÑÊ®°ÂûãÂáÜÁ°ÆÊÄß„ÄÇÊàë‰ª¨‰ªéÊï∞Â≠¶‰∏äËØÅÊòéÔºåÂú®ÈáèÂåñ‰πãÂâçÂ∫îÁî®Á®ÄÁñèÊÄßÊòØËøô‰∫õÊìç‰ΩúÁöÑÊúÄ‰Ω≥Â∫èÂàóÔºå‰ªéËÄåÊúÄÂ§ßÁ®ãÂ∫¶Âú∞ÂáèÂ∞ëËÆ°ÁÆóËØØÂ∑Æ„ÄÇÊàë‰ª¨ÂØπÂåÖÊã¨ OPT Âíå Llama Ê®°ÂûãÊóèÔºà125M-8BÔºâÂíå ViT Âú®ÂÜÖÁöÑÂêÑÁßçÊ®°ÂûãËøõË°åÁöÑÂÆûËØÅÁ†îÁ©∂ËØÅÂÆû‰∫ÜËøô‰∫õÁêÜËÆ∫ÂèëÁé∞„ÄÇÊ≠§Â§ñÔºåÈÄöËøá‰∏•Ê†ºÁöÑÂàÜÊûêÔºåÊàë‰ª¨ËØÅÊòé‰∫ÜÁ®ÄÁñèÊÄßÂíåÈáèÂåñ‰∏çÊòØÊ≠£‰∫§ÁöÑÔºõÂÆÉ‰ª¨ÁöÑÁõ∏‰∫í‰ΩúÁî®‰ºö‰∏•ÈáçÊçüÂÆ≥Ê®°ÂûãÁöÑÂáÜÁ°ÆÊÄßÔºåËÄåÈáèÂåñËØØÂ∑ÆÂú®Ëøô‰∏ÄÈÄÄÂåñ‰∏≠Ëµ∑‰∏ªÂØº‰ΩúÁî®„ÄÇÊàë‰ª¨ÁöÑÂèëÁé∞Êâ©Â±ïÂà∞Âú®ËµÑÊ∫êÂèóÈôêÁöÑËÆ°ÁÆóÂπ≥Âè∞‰∏≠ÊúâÊïàÈÉ®ÁΩ≤Â§ßÂûãÊ®°ÂûãÔºåÂπ∂Èôç‰ΩéÊúçÂä°ÊàêÊú¨Ôºå‰∏∫Âú®‰∏çÂΩ±ÂìçÂáÜÁ°ÆÊÄßÁöÑÂâçÊèê‰∏ãÂ∫îÁî®Ëøô‰∫õÂéãÁº©ÊñπÊ≥ï‰ª•ÊúÄÂ§ßÂåñÂäüÊïàÊèê‰æõ‰∫ÜËßÅËß£„ÄÇ

##### **Learning to Estimate System Specifications in Linear Temporal Logic using Transformers and Mamba**
2405.20917v1 by ƒ∞lker I≈üƒ±k, Ebru Aydin Gol, Ramazan Gokberk Cinbis

Temporal logic is a framework for representing and reasoning about
propositions that evolve over time. It is commonly used for specifying
requirements in various domains, including hardware and software systems, as
well as robotics. Specification mining or formula generation involves
extracting temporal logic formulae from system traces and has numerous
applications, such as detecting bugs and improving interpretability. Although
there has been a surge of deep learning-based methods for temporal logic
satisfiability checking in recent years, the specification mining literature
has been lagging behind in adopting deep learning methods despite their many
advantages, such as scalability. In this paper, we introduce autoregressive
models that can generate linear temporal logic formulae from traces, towards
addressing the specification mining problem. We propose multiple architectures
for this task: transformer encoder-decoder, decoder-only transformer, and
Mamba, which is an emerging alternative to transformer models. Additionally, we
devise a metric for quantifying the distinctiveness of the generated formulae
and a straightforward algorithm to enforce the syntax constraints. Our
experiments show that the proposed architectures yield promising results,
generating correct and distinct formulae at a fraction of the compute cost
needed for the combinatorial baseline.

ÊëòË¶ÅÔºöÊôÇÊÖãÈÇèËºØÊòØ‰∏ÄÁ®ÆÁî®ÊñºË°®Á§∫ÂíåÊé®ÁêÜÊôÇÊÖãÂëΩÈ°åÁöÑÊ°ÜÊû∂„ÄÇÂÆÉÈÄöÂ∏∏Áî®ÊñºÊåáÂÆöÂêÑÁ®ÆÈ†òÂüü‰∏≠ÁöÑÈúÄÊ±ÇÔºåÂåÖÊã¨Á°¨È´îÂíåËªüÈ´îÁ≥ªÁµ±Ôºå‰ª•ÂèäÊ©üÂô®‰∫∫ÊäÄË°ì„ÄÇË¶èÁØÑÊåñÊéòÊàñÂÖ¨ÂºèÁîüÊàêÊ∂âÂèäÂæûÁ≥ªÁµ±ËªåË∑°‰∏≠ÊèêÂèñÊôÇÊÖãÈÇèËºØÂÖ¨ÂºèÔºå‰∏¶ÂÖ∑ÊúâË®±Â§öÊáâÁî®Ôºå‰æãÂ¶ÇÂÅµÊ∏¨ÈåØË™§ÂíåÊîπÂñÑÂèØËß£ÈáãÊÄß„ÄÇÂÑòÁÆ°ËøëÂπ¥‰æÜÂü∫ÊñºÊ∑±Â∫¶Â≠∏ÁøíÁöÑÊñπÊ≥ïÂ∞çÊñºÊôÇÊÖãÈÇèËºØÊªøË∂≥ÊÄßÊ™¢Êü•ÊøÄÂ¢ûÔºå‰ΩÜË¶èÁØÑÊåñÊéòÊñáÁçªÂú®Êé°Áî®Ê∑±Â∫¶Â≠∏ÁøíÊñπÊ≥ïÊñπÈù¢‰∏ÄÁõ¥ËêΩÂæåÔºåÂÑòÁÆ°ÂÆÉÂÄëÊúâË®±Â§öÂÑ™ÈªûÔºå‰æãÂ¶ÇÂèØÊì¥ÂÖÖÊÄß„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫ÜËá™Ëø¥Ê≠∏Ê®°ÂûãÔºåÂÆÉÂèØ‰ª•ÂæûËªåË∑°‰∏≠ÁîüÊàêÁ∑öÊÄßÊôÇÊÖãÈÇèËºØÂÖ¨ÂºèÔºå‰ª•Ëß£Ê±∫Ë¶èÁØÑÊåñÊéòÂïèÈ°å„ÄÇÊàëÂÄëÁÇ∫Ê≠§‰ªªÂãôÊèêÂá∫‰∫ÜÂ§öÁ®ÆÊû∂ÊßãÔºöTransformerÁ∑®Á¢ºÂô®-Ëß£Á¢ºÂô®„ÄÅÂÉÖËß£Á¢ºÂô®TransformerÂíå MambaÔºåÈÄôÊòØ‰∏ÄÁ®ÆÊñ∞ËààÁöÑTransformerÊ®°ÂûãÊõø‰ª£ÊñπÊ°à„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëË®≠Ë®à‰∫Ü‰∏ÄÂÄãÈáèÂåñÁîüÊàêÂÖ¨ÂºèÁç®ÁâπÊÄßÁöÑÊåáÊ®ôÔºå‰ª•Âèä‰∏ÄÂÄãÂº∑Âà∂Ë™ûÊ≥ïÁ¥ÑÊùüÁöÑÁ∞°ÂñÆÊºîÁÆóÊ≥ï„ÄÇÊàëÂÄëÁöÑÂØ¶È©óË°®ÊòéÔºåÊâÄÊèêÂá∫ÁöÑÊû∂ÊßãÁî¢Áîü‰∫ÜÊúâÂ∏åÊúõÁöÑÁµêÊûúÔºå‰ª•‰ΩéÊñºÁµÑÂêàÂü∫Á∑öÊâÄÈúÄÁöÑË®àÁÆóÊàêÊú¨ÁîüÊàêÊ≠£Á¢∫‰∏î‰∏çÂêåÁöÑÂÖ¨Âºè„ÄÇ

##### **Fast yet Safe: Early-Exiting with Risk Control**
2405.20915v1 by Metod Jazbec, Alexander Timans, Tin Had≈æi Veljkoviƒá, Kaspar Sakmann, Dan Zhang, Christian A. Naesseth, Eric Nalisnick

Scaling machine learning models significantly improves their performance.
However, such gains come at the cost of inference being slow and
resource-intensive. Early-exit neural networks (EENNs) offer a promising
solution: they accelerate inference by allowing intermediate layers to exit and
produce a prediction early. Yet a fundamental issue with EENNs is how to
determine when to exit without severely degrading performance. In other words,
when is it 'safe' for an EENN to go 'fast'? To address this issue, we
investigate how to adapt frameworks of risk control to EENNs. Risk control
offers a distribution-free, post-hoc solution that tunes the EENN's exiting
mechanism so that exits only occur when the output is of sufficient quality. We
empirically validate our insights on a range of vision and language tasks,
demonstrating that risk control can produce substantial computational savings,
all the while preserving user-specified performance goals.

ÊëòË¶ÅÔºöÊì¥Â±ïÊ©üÂô®Â≠∏ÁøíÊ®°ÂûãÂèØ‰ª•Â§ßÂπÖÊèêÂçáÂÖ∂ÊïàËÉΩ„ÄÇ
ÁÑ∂ËÄåÔºåÈÄôÁ®ÆÊèêÂçáÊòØ‰ª•Êé®Ë´ñÈÄüÂ∫¶ËÆäÊÖ¢ÂíåË≥áÊ∫êÂØÜÈõÜÁÇ∫‰ª£ÂÉπ„ÄÇÊó©ÊúüÈÄÄÂá∫Á•ûÁ∂ìÁ∂≤Ë∑Ø (EENN) Êèê‰æõ‰∫Ü‰∏ÄÂÄãÊúâÂâçÊôØÁöÑËß£Ê±∫ÊñπÊ°àÔºöÂÆÉÂÄëÂÖÅË®±‰∏≠ÈñìÂ±§ÈÄÄÂá∫‰∏¶ÊèêÊó©Áî¢ÁîüÈ†êÊ∏¨ÔºåÈÄ≤ËÄåÂä†ÈÄüÊé®Ë´ñ„ÄÇÁÑ∂ËÄåÔºåEENN ÁöÑ‰∏ÄÂÄãÂü∫Êú¨ÂïèÈ°åÊòØÂ¶Ç‰ΩïÂú®‰∏çÂö¥ÈáçÈôç‰ΩéÊïàËÉΩÁöÑÊÉÖÊ≥Å‰∏ãÂà§Êñ∑‰ΩïÊôÇÈÄÄÂá∫„ÄÇÊèõÂè•Ë©±Ë™™Ôºå‰ªÄÈ∫ºÊôÇÂÄô EENN ÂèØ‰ª•„ÄåÂÆâÂÖ®„ÄçÂú∞„ÄåÂø´ÈÄü„ÄçÂü∑Ë°åÔºüÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÊé¢Ë®éÂ¶Ç‰ΩïÂ∞áÈ¢®Èö™ÊéßÂà∂Êû∂ÊßãË™øÊï¥Âà∞ EENN„ÄÇÈ¢®Èö™ÊéßÂà∂Êèê‰æõ‰∫Ü‰∏ÄÂÄãÁÑ°ÂàÜ‰Ωà„ÄÅ‰∫ãÂæåËß£Ê±∫ÊñπÊ°àÔºåÁî®ÊñºË™øÊï¥ EENN ÁöÑÈÄÄÂá∫Ê©üÂà∂Ôºå‰ª•‰æøÂÉÖÂú®Ëº∏Âá∫ÂìÅË≥™Ë∂≥Â§†ÊôÇÊâçÊúÉÈÄÄÂá∫„ÄÇÊàëÂÄëÊ†πÊìö‰∏ÄÁ≥ªÂàóË¶ñË¶∫ÂíåË™ûË®Ä‰ªªÂãôÂØ¶Ë≠âÈ©óË≠âÊàëÂÄëÁöÑË¶ãËß£ÔºåË≠âÊòéÈ¢®Èö™ÊéßÂà∂ÂèØ‰ª•Áî¢ÁîüÂ§ßÈáèÁöÑÈÅãÁÆóÁØÄÁúÅÔºåÂêåÊôÇ‰øùÁïô‰ΩøÁî®ËÄÖÊåáÂÆöÁöÑÊïàËÉΩÁõÆÊ®ô„ÄÇ

##### **Enhancing Vision Models for Text-Heavy Content Understanding and Interaction**
2405.20906v1 by Adithya TG, Adithya SK, Abhinav R Bharadwaj, Abhiram HA, Dr. Surabhi Narayan

Interacting and understanding with text heavy visual content with multiple
images is a major challenge for traditional vision models. This paper is on
enhancing vision models' capability to comprehend or understand and learn from
images containing a huge amount of textual information from the likes of
textbooks and research papers which contain multiple images like graphs, etc
and tables in them with different types of axes and scales. The approach
involves dataset preprocessing, fine tuning which is by using instructional
oriented data and evaluation. We also built a visual chat application
integrating CLIP for image encoding and a model from the Massive Text Embedding
Benchmark which is developed to consider both textual and visual inputs. An
accuracy of 96.71% was obtained. The aim of the project is to increase and also
enhance the advance vision models' capabilities in understanding complex visual
textual data interconnected data, contributing to multimodal AI.

ÊëòË¶ÅÔºöËàáÂåÖÂê´Â§öÂÄãÂΩ±ÂÉèÁöÑÊñáÂ≠óÁπÅÈáçÁöÑË¶ñË¶∫ÂÖßÂÆπ‰∫íÂãï‰∏¶ÁêÜËß£ÈÄô‰∫õÂÖßÂÆπÔºåÂ∞çÂÇ≥Áµ±ÁöÑË¶ñË¶∫Ê®°Âûã‰æÜË™™ÊòØ‰∏ÄÈ†ÖÈáçÂ§ßÁöÑÊåëÊà∞„ÄÇÊú¨ÊñáÊé¢Ë®éÂ¶Ç‰ΩïÊèêÂçáË¶ñË¶∫Ê®°ÂûãÁöÑËÉΩÂäõÔºå‰ª•ÁêÜËß£„ÄÅ‰∫ÜËß£ÂíåÂ≠∏ÁøíÂåÖÂê´Â§ßÈáèÊñáÂ≠óË≥áË®äÁöÑÂΩ±ÂÉèÔºå‰æãÂ¶ÇÊïôÁßëÊõ∏ÂíåÁ†îÁ©∂Ë´ñÊñáÔºåÂÖ∂‰∏≠ÂåÖÂê´Â§öÂÄãÂΩ±ÂÉèÔºå‰æãÂ¶ÇÂúñÂΩ¢„ÄÅË°®Ê†ºÁ≠âÔºå‰ª•ÂèäÂÖ∑Êúâ‰∏çÂêåÈ°ûÂûãËª∏Á∑öÂíåÊØî‰æãÁöÑË°®Ê†º„ÄÇÊ≠§ÊñπÊ≥ïÂåÖÂê´Ë≥áÊñôÈõÜÈ†êËôïÁêÜ„ÄÅÂæÆË™øÔºàÈÄèÈÅé‰ΩøÁî®ÊïôÂ≠∏Â∞éÂêëË≥áÊñôÂíåË©ïÈáèÔºâÔºåÊàëÂÄëÈÇÑÂª∫ÁΩÆ‰∫Ü‰∏ÄÂÄãË¶ñË¶∫ËÅäÂ§©ÊáâÁî®Á®ãÂºèÔºåÊï¥ÂêàÁî®ÊñºÂΩ±ÂÉèÁ∑®Á¢ºÁöÑ CLIPÔºå‰ª•Âèä‰∏ÄÂÄã‰æÜËá™ Massive Text Embedding Benchmark ÁöÑÊ®°ÂûãÔºåË©≤Ê®°ÂûãÊúÉËÄÉÈáèÊñáÂ≠óÂíåË¶ñË¶∫Ëº∏ÂÖ•„ÄÇÊàëÂÄëÁç≤Âæó‰∫Ü 96.71% ÁöÑÊ∫ñÁ¢∫Â∫¶„ÄÇÊ≠§Â∞àÊ°àÁöÑÁõÆÊ®ôÊòØÊèêÂçáÂíåÂ¢ûÂº∑ÈÄ≤ÈöéË¶ñË¶∫Ê®°ÂûãÁöÑËÉΩÂäõÔºå‰ª•ÁêÜËß£Ë§áÈõúÁöÑË¶ñË¶∫ÊñáÂ≠óË≥áÊñôÂíåÁõ∏‰∫íÈÄ£ÁµêÁöÑË≥áÊñôÔºå‰∏¶ÁÇ∫Â§öÊ®°ÊÖã AI ÂÅöÂá∫Ë≤¢Áçª„ÄÇ

##### **Preemptive Answer "Attacks" on Chain-of-Thought Reasoning**
2405.20902v1 by Rongwu Xu, Zehan Qi, Wei Xu

Large language models (LLMs) showcase impressive reasoning capabilities when
coupled with Chain-of-Thought (CoT) prompting. However, the robustness of this
approach warrants further investigation. In this paper, we introduce a novel
scenario termed preemptive answers, where the LLM obtains an answer before
engaging in reasoning. This situation can arise inadvertently or induced by
malicious users by prompt injection attacks. Experiments reveal that preemptive
answers significantly impair the model's reasoning capability across various
CoT methods and a broad spectrum of datasets. To bolster the robustness of
reasoning, we propose two measures aimed at mitigating this issue to some
extent.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®ËàáÊÄùËÄÉÈèà (CoT) ÊèêÁ§∫ÁµêÂêà‰ΩøÁî®ÊôÇÔºåÂ±ïÁ§∫Âá∫‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑÊé®ÁêÜËÉΩÂäõ„ÄÇÁÑ∂ËÄåÔºåÈÄôÁ®ÆÊñπÊ≥ïÁöÑÁ©©ÂÅ•ÊÄßÂÄºÂæóÈÄ≤‰∏ÄÊ≠•Êé¢Ë®é„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫Ü‰∏ÄÂÄãÁ®±ÁÇ∫ÂÖàÁôºÂà∂‰∫∫Á≠îÊ°àÁöÑÊñ∞Â†¥ÊôØÔºåÂÖ∂‰∏≠ LLM Âú®ÈÄ≤Ë°åÊé®ÁêÜ‰πãÂâçÁç≤Âæó‰∫Ü‰∏ÄÂÄãÁ≠îÊ°à„ÄÇÈÄôÁ®ÆÊÉÖÊ≥ÅÂèØËÉΩÊúÉÁÑ°ÊÑè‰∏≠Âá∫ÁèæÔºåÊàñËÄÖË¢´ÊÉ°ÊÑè‰ΩøÁî®ËÄÖÈÄèÈÅéÊèêÁ§∫Ê≥®ÂÖ•ÊîªÊìäË™òÁôº„ÄÇÂØ¶È©óË°®ÊòéÔºåÂÖàÁôºÂà∂‰∫∫Á≠îÊ°àÊúÉÂö¥ÈáçÊêçÂÆ≥Ê®°ÂûãÂú®ÂêÑÁ®Æ CoT ÊñπÊ≥ïÂíåÂª£Ê≥õÁöÑË≥áÊñôÈõÜ‰∏≠ÁöÑÊé®ÁêÜËÉΩÂäõ„ÄÇÁÇ∫‰∫ÜÂä†Âº∑Êé®ÁêÜÁöÑÁ©©ÂÅ•ÊÄßÔºåÊàëÂÄëÊèêÂá∫‰∫ÜÂÖ©È†ÖÊé™ÊñΩÔºåÊó®Âú®Âú®ÊüêÁ®ÆÁ®ãÂ∫¶‰∏äÊ∏õËºïÈÄôÂÄãÂïèÈ°å„ÄÇ

##### **Large Language Models: A New Approach for Privacy Policy Analysis at Scale**
2405.20900v1 by David Rodriguez, Ian Yang, Jose M. Del Alamo, Norman Sadeh

The number and dynamic nature of web and mobile applications presents
significant challenges for assessing their compliance with data protection
laws. In this context, symbolic and statistical Natural Language Processing
(NLP) techniques have been employed for the automated analysis of these
systems' privacy policies. However, these techniques typically require
labor-intensive and potentially error-prone manually annotated datasets for
training and validation. This research proposes the application of Large
Language Models (LLMs) as an alternative for effectively and efficiently
extracting privacy practices from privacy policies at scale. Particularly, we
leverage well-known LLMs such as ChatGPT and Llama 2, and offer guidance on the
optimal design of prompts, parameters, and models, incorporating advanced
strategies such as few-shot learning. We further illustrate its capability to
detect detailed and varied privacy practices accurately. Using several renowned
datasets in the domain as a benchmark, our evaluation validates its exceptional
performance, achieving an F1 score exceeding 93%. Besides, it does so with
reduced costs, faster processing times, and fewer technical knowledge
requirements. Consequently, we advocate for LLM-based solutions as a sound
alternative to traditional NLP techniques for the automated analysis of privacy
policies at scale.

ÊëòË¶ÅÔºöÁ∂≤Ë∑ØÂíåË°åÂãïÊáâÁî®Á®ãÂºèÁöÑÊï∏ÈáèÂíåÂãïÊÖãÁâπÊÄßÂ∞çË©ï‰º∞ÂÖ∂ÊòØÂê¶Á¨¶ÂêàË≥áÊñô‰øùË≠∑Ê≥ïË¶èÊßãÊàêÈáçÂ§ßÊåëÊà∞„ÄÇÂú®Ê≠§ËÉåÊôØ‰∏ãÔºåÁ¨¶ËôüÂíåÁµ±Ë®àËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ (NLP) ÊäÄË°ìÂ∑≤Ë¢´Áî®ÊñºËá™ÂãïÂåñÂàÜÊûêÈÄô‰∫õÁ≥ªÁµ±ÁöÑÈö±ÁßÅÊîøÁ≠ñ„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÊäÄË°ìÈÄöÂ∏∏ÈúÄË¶ÅÂ§ßÈáè‰∫∫Â∑•Ê®ôË®ªÁöÑË≥áÊñôÈõÜÈÄ≤Ë°åË®ìÁ∑¥ÂíåÈ©óË≠âÔºå‰∏îÂÆπÊòìÂá∫ÈåØ„ÄÇÊú¨Á†îÁ©∂ÊèêÂá∫ÊáâÁî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰ΩúÁÇ∫‰∏ÄÁ®ÆÊõø‰ª£ÊñπÊ°àÔºå‰ª•ÊúâÊïà‰∏îÈ´òÊïàÂú∞Â§ßË¶èÊ®°ÂæûÈö±ÁßÅÊîøÁ≠ñ‰∏≠ËêÉÂèñÈö±ÁßÅÂØ¶Âãô„ÄÇÁâπÂà•ÊòØÔºåÊàëÂÄëÂà©Áî®ÁúæÊâÄÂë®Áü•ÁöÑ LLMÔºå‰æãÂ¶Ç ChatGPT Âíå Llama 2Ôºå‰∏¶Êèê‰æõÊèêÁ§∫„ÄÅÂèÉÊï∏ÂíåÊ®°ÂûãÁöÑÊúÄ‰Ω≥Ë®≠Ë®àÊåáÂçóÔºå‰∏¶ÁµêÂêàÂ∞ëÈáèÂ≠∏ÁøíÁ≠âÂÖàÈÄ≤Á≠ñÁï•„ÄÇÊàëÂÄëÈÄ≤‰∏ÄÊ≠•Ë™™ÊòéÂÖ∂Ê∫ñÁ¢∫ÂÅµÊ∏¨Ë©≥Á¥∞‰∏îÂ§öÊ®£ÂåñÈö±ÁßÅÂØ¶ÂãôÁöÑËÉΩÂäõ„ÄÇ‰ΩøÁî®Ë©≤È†òÂüü‰∏≠ÂπæÂÄãËëóÂêçÁöÑË≥áÊñôÈõÜ‰ΩúÁÇ∫Âü∫Ê∫ñÔºåÊàëÂÄëÁöÑË©ï‰º∞È©óË≠âÂÖ∂ÂçìË∂äÁöÑÊïàËÉΩÔºåÈÅîÊàêË∂ÖÈÅé 93% ÁöÑ F1 ÂàÜÊï∏„ÄÇÊ≠§Â§ñÔºåÂÆÉ‰ª•Èôç‰ΩéÊàêÊú¨„ÄÅÊõ¥Âø´ÁöÑËôïÁêÜÊôÇÈñìÂíåËºÉÂ∞ëÁöÑÊäÄË°ìÁü•Ë≠òÈúÄÊ±Ç‰æÜÈÅîÊàêÊ≠§ÁõÆÊ®ô„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëÊèêÂÄ°Âü∫Êñº LLM ÁöÑËß£Ê±∫ÊñπÊ°àÔºå‰ΩúÁÇ∫ÂÇ≥Áµ± NLP ÊäÄË°ìÁöÑÂêàÁêÜÊõø‰ª£ÊñπÊ°àÔºå‰ª•Â§ßË¶èÊ®°Ëá™ÂãïÂåñÂàÜÊûêÈö±ÁßÅÊîøÁ≠ñ„ÄÇ

##### **MALT: Multi-scale Action Learning Transformer for Online Action Detection**
2405.20892v1 by Zhipeng Yang, Ruoyu Wang, Yang Tan, Liping Xie

Online action detection (OAD) aims to identify ongoing actions from streaming
video in real-time, without access to future frames. Since these actions
manifest at varying scales of granularity, ranging from coarse to fine,
projecting an entire set of action frames to a single latent encoding may
result in a lack of local information, necessitating the acquisition of action
features across multiple scales. In this paper, we propose a multi-scale action
learning transformer (MALT), which includes a novel recurrent decoder (used for
feature fusion) that includes fewer parameters and can be trained more
efficiently. A hierarchical encoder with multiple encoding branches is further
proposed to capture multi-scale action features. The output from the preceding
branch is then incrementally input to the subsequent branch as part of a
cross-attention calculation. In this way, output features transition from
coarse to fine as the branches deepen. We also introduce an explicit frame
scoring mechanism employing sparse attention, which filters irrelevant frames
more efficiently, without requiring an additional network. The proposed method
achieved state-of-the-art performance on two benchmark datasets (THUMOS'14 and
TVSeries), outperforming all existing models used for comparison, with an mAP
of 0.2% for THUMOS'14 and an mcAP of 0.1% for TVseries.

ÊëòË¶ÅÔºöÁ∑ö‰∏äÂãï‰ΩúÂÅµÊ∏¨ (OAD) Êó®Âú®Âæû‰∏≤ÊµÅÂΩ±Áâá‰∏≠Ëæ®Ë≠òÊ≠£Âú®ÈÄ≤Ë°åÁöÑÂãï‰ΩúÔºå‰∏îÁÇ∫Âç≥ÊôÇÂÅµÊ∏¨Ôºå‰∏îÁÑ°Ê≥ïÂ≠òÂèñÂæåÁ∫åÁöÑÂΩ±Ê†º„ÄÇÁî±ÊñºÈÄô‰∫õÂãï‰ΩúÊúÉ‰ª•‰∏çÂêåÂ∞∫Â∫¶ÁöÑÁ≤íÂ∫¶È°ØÁèæÔºåÂæûÁ≤óÁï•Âà∞Á≤æÁ¥∞ÔºåÂ∞á‰∏ÄÊï¥ÁµÑÂãï‰ΩúÂΩ±Ê†ºÊäïÂΩ±Âà∞ÂñÆ‰∏ÄÊΩõÂú®Á∑®Á¢º‰∏≠ÂèØËÉΩÊúÉÂ∞éËá¥Áº∫‰πèÂ±ÄÈÉ®Ë≥áË®äÔºåÂõ†Ê≠§ÈúÄË¶ÅË∑®Â§öÂÄãÂ∞∫Â∫¶ÂèñÂæóÂãï‰ΩúÁâπÂæµ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÂ§öÂ∞∫Â∫¶Âãï‰ΩúÂ≠∏ÁøíËΩâÊèõÂô® (MALT)ÔºåÂÖ∂‰∏≠ÂåÖÂê´‰∏ÄÂÄãÊñ∞Á©éÁöÑÈÅûËø¥Ëß£Á¢ºÂô® (Áî®ÊñºÁâπÂæµËûçÂêà)ÔºåË©≤Ëß£Á¢ºÂô®ÂåÖÂê´ËºÉÂ∞ëÁöÑÂèÉÊï∏Ôºå‰∏îÂèØ‰ª•Êõ¥ÊúâÊïàÁéáÂú∞ÈÄ≤Ë°åË®ìÁ∑¥„ÄÇÈÄ≤‰∏ÄÊ≠•ÊèêÂá∫‰∏ÄÂÄãÂÖ∑ÊúâÂ§öÂÄãÁ∑®Á¢ºÂàÜÊîØÁöÑÈöéÂ±§ÂºèÁ∑®Á¢ºÂô®Ôºå‰ª•Êì∑ÂèñÂ§öÂ∞∫Â∫¶Âãï‰ΩúÁâπÂæµ„ÄÇÁÑ∂ÂæåÂ∞áÂâç‰∏ÄÂÄãÂàÜÊîØÁöÑËº∏Âá∫‰ΩúÁÇ∫Ë∑®Ê≥®ÊÑèÂäõË®àÁÆóÁöÑ‰∏ÄÈÉ®ÂàÜÔºåÈÅûÂ¢ûËº∏ÂÖ•Âà∞ÂæåÁ∫åÂàÜÊîØ„ÄÇÈÄôÊ®£‰∏Ä‰æÜÔºåÈö®ËëóÂàÜÊîØÁöÑÂä†Ê∑±ÔºåËº∏Âá∫ÁâπÂæµÊúÉÂæûÁ≤óÁï•ËΩâËÆäÁÇ∫Á≤æÁ¥∞„ÄÇÊàëÂÄëÈÇÑÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÊòéÁ¢∫ÁöÑÂΩ±Ê†ºË©ïÂàÜÊ©üÂà∂ÔºåÊé°Áî®Á®ÄÁñèÊ≥®ÊÑèÂäõÔºåÂèØ‰ª•Êõ¥ÊúâÊïàÁéáÂú∞ÈÅéÊøæ‰∏çÁõ∏ÈóúÁöÑÂΩ±Ê†ºÔºåËÄå‰∏çÈúÄË¶ÅÈ°çÂ§ñÁöÑÁ∂≤Ë∑Ø„ÄÇÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÂú®ÂÖ©ÂÄãÂü∫Ê∫ñË≥áÊñôÈõÜ (THUMOS'14 Âíå TVSeries) ‰∏äÈÅîÂà∞ÊúÄÂÖàÈÄ≤ÁöÑÊïàËÉΩÔºåÂÑ™ÊñºÊâÄÊúâÁèæÊúâÁöÑÊØîËºÉÊ®°ÂûãÔºåÂÖ∂‰∏≠ THUMOS'14 ÁöÑ mAP ÁÇ∫ 0.2%ÔºåTVseries ÁöÑ mcAP ÁÇ∫ 0.1%„ÄÇ

##### **Paying to Do Better: Games with Payments between Learning Agents**
2405.20880v1 by Yoav Kolumbus, Joe Halpern, √âva Tardos

In repeated games, such as auctions, players typically use learning
algorithms to choose their actions. The use of such autonomous learning agents
has become widespread on online platforms. In this paper, we explore the impact
of players incorporating monetary transfers into their agents' algorithms,
aiming to incentivize behavior in their favor. Our focus is on understanding
when players have incentives to make use of monetary transfers, how these
payments affect learning dynamics, and what the implications are for welfare
and its distribution among the players. We propose a simple game-theoretic
model to capture such scenarios. Our results on general games show that in a
broad class of games, players benefit from letting their learning agents make
payments to other learners during the game dynamics, and that in many cases,
this kind of behavior improves welfare for all players. Our results on first-
and second-price auctions show that in equilibria of the ``payment policy
game,'' the agents' dynamics can reach strong collusive outcomes with low
revenue for the auctioneer. These results highlight a challenge for mechanism
design in systems where automated learning agents can benefit from interacting
with their peers outside the boundaries of the mechanism.

ÊëòË¶ÅÔºöÂú®ÈáçË§áÁöÑÈÅäÊà≤‰∏≠Ôºå‰æãÂ¶ÇÊãçË≥£ÔºåÁé©ÂÆ∂ÈÄöÂ∏∏‰ΩøÁî®Â≠∏ÁøíÊºîÁÆóÊ≥ï‰æÜÈÅ∏Êìá‰ªñÂÄëÁöÑË°åÂãï„ÄÇÈÄôÁ®ÆËá™‰∏ªÂ≠∏Áøí‰ª£ÁêÜÁöÑ‰ΩøÁî®Â∑≤Âú®Á∑ö‰∏äÂπ≥Âè∞‰∏äÂª£Ê≥õÊµÅÂÇ≥„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊé¢Ë®é‰∫ÜÁé©ÂÆ∂Â∞áÈáëÈå¢ËΩâÁßªÁ¥çÂÖ•ÂÖ∂‰ª£ÁêÜÊºîÁÆóÊ≥ï‰∏≠ÁöÑÂΩ±ÈüøÔºåÁõÆÁöÑÊòØÊøÄÂãµÊúâÂà©Êñº‰ªñÂÄëÁöÑË°åÁÇ∫„ÄÇÊàëÂÄëÁöÑÈáçÈªûÊòØ‰∫ÜËß£Áé©ÂÆ∂‰ΩïÊôÇÊúâË™òÂõ†‰ΩøÁî®ÈáëÈå¢ËΩâÁßª„ÄÅÈÄô‰∫õ‰ªòÊ¨æÂ¶Ç‰ΩïÂΩ±ÈüøÂ≠∏ÁøíÂãïÊÖãÔºå‰ª•ÂèäÂ∞çÁ¶èÂà©ÂèäÂÖ∂Âú®Áé©ÂÆ∂‰πãÈñìÁöÑÂàÜÈÖçÊúâ‰ΩïÂΩ±Èüø„ÄÇÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÁ∞°ÂñÆÁöÑÂçöÂºàË´ñÊ®°Âûã‰æÜÊçïÊçâÈÄôÁ®ÆÊÉÖÊ≥Å„ÄÇÊàëÂÄëÂ∞ç‰∏ÄËà¨ÈÅäÊà≤ÁöÑÁµêÊûúË°®ÊòéÔºåÂú®Âª£Ê≥õÁöÑÈÅäÊà≤È°ûÂà•‰∏≠ÔºåÁé©ÂÆ∂ÂèóÁõäÊñºËÆì‰ªñÂÄëÁöÑÂ≠∏Áøí‰ª£ÁêÜÂú®ÈÅäÊà≤ÂãïÊÖãÊúüÈñìÂêëÂÖ∂‰ªñÂ≠∏ÁøíËÄÖ‰ªòÊ¨æÔºå‰∏¶‰∏îÂú®Ë®±Â§öÊÉÖÊ≥Å‰∏ãÔºåÈÄôÁ®ÆË°åÁÇ∫ÊúÉÊîπÂñÑÊâÄÊúâÁé©ÂÆ∂ÁöÑÁ¶èÂà©„ÄÇÊàëÂÄëÂ∞ç‰∏ÄÈöéÂíå‰∫åÈöéÊãçË≥£ÁöÑÁµêÊûúË°®ÊòéÔºåÂú®„Äå‰ªòÊ¨æÊîøÁ≠ñÂçöÂºà„ÄçÁöÑÂùáË°°‰∏≠Ôºå‰ª£ÁêÜÁöÑÂãïÊÖãÂèØ‰ª•ÈÅîÂà∞Â∞çÊãçË≥£‰∫∫‰æÜË™™‰ΩéÊî∂ÂÖ•ÁöÑÂº∑ÊúâÂäõÂÖ±Ë¨ÄÁµêÊûú„ÄÇÈÄô‰∫õÁµêÊûúÁ™ÅÈ°Ø‰∫ÜÂú®Ëá™ÂãïÂåñÂ≠∏Áøí‰ª£ÁêÜÂèØ‰ª•ÂèóÁõäÊñºÂú®Ê©üÂà∂ÁïåÁ∑öÂ§ñËàáÂêåÂÑï‰∫íÂãïÁöÑÁ≥ªÁµ±‰∏≠ÈÄ≤Ë°åÊ©üÂà∂Ë®≠Ë®àÁöÑÊåëÊà∞„ÄÇ

##### **SelfGNN: Self-Supervised Graph Neural Networks for Sequential Recommendation**
2405.20878v1 by Yuxi Liu, Lianghao Xia, Chao Huang

Sequential recommendation effectively addresses information overload by
modeling users' temporal and sequential interaction patterns. To overcome the
limitations of supervision signals, recent approaches have adopted
self-supervised learning techniques in recommender systems. However, there are
still two critical challenges that remain unsolved. Firstly, existing
sequential models primarily focus on long-term modeling of individual
interaction sequences, overlooking the valuable short-term collaborative
relationships among the behaviors of different users. Secondly, real-world data
often contain noise, particularly in users' short-term behaviors, which can
arise from temporary intents or misclicks. Such noise negatively impacts the
accuracy of both graph and sequence models, further complicating the modeling
process. To address these challenges, we propose a novel framework called
Self-Supervised Graph Neural Network (SelfGNN) for sequential recommendation.
The SelfGNN framework encodes short-term graphs based on time intervals and
utilizes Graph Neural Networks (GNNs) to learn short-term collaborative
relationships. It captures long-term user and item representations at multiple
granularity levels through interval fusion and dynamic behavior modeling.
Importantly, our personalized self-augmented learning structure enhances model
robustness by mitigating noise in short-term graphs based on long-term user
interests and personal stability. Extensive experiments conducted on four
real-world datasets demonstrate that SelfGNN outperforms various
state-of-the-art baselines. Our model implementation codes are available at
https://github.com/HKUDS/SelfGNN.

ÊëòË¶ÅÔºöÂ∫èÂàóÊé®Ëñ¶ÈÄöÈÅéÂª∫Ê®°‰ΩøÁî®ËÄÖÁöÑÊôÇÈñìÂíåÂ∫èÂàó‰∫íÂãïÊ®°ÂºèÔºåÊúâÊïàÂú∞Ëß£Ê±∫Ë≥áË®äË∂ÖËºâÁöÑÂïèÈ°å„ÄÇÁÇ∫‰∫ÜÂÖãÊúçÁõ£Áù£Ë®äËôüÁöÑÈôêÂà∂ÔºåÊúÄËøëÁöÑÊñπÊ≥ïÂú®Êé®Ëñ¶Á≥ªÁµ±‰∏≠Êé°Áî®‰∫ÜËá™Áõ£Áù£Â≠∏ÁøíÊäÄË°ì„ÄÇÁÑ∂ËÄåÔºå‰ªçÊúâÂÖ©ÂÄãÈóúÈçµÊåëÊà∞Â∞öÊú™Ëß£Ê±∫„ÄÇÈ¶ñÂÖàÔºåÁèæÊúâÁöÑÂ∫èÂàóÊ®°Âûã‰∏ªË¶ÅÂ∞àÊ≥®ÊñºÂÄãÂà•‰∫íÂãïÂ∫èÂàóÁöÑÈï∑ÊúüÂª∫Ê®°ÔºåÂøΩÁï•‰∫Ü‰∏çÂêå‰ΩøÁî®ËÄÖË°åÁÇ∫‰πãÈñìÊúâÂÉπÂÄºÁöÑÁü≠ÊúüÂçî‰ΩúÈóú‰øÇ„ÄÇÂÖ∂Ê¨°ÔºåÁúüÂØ¶‰∏ñÁïåÁöÑË≥áÊñôÈÄöÂ∏∏ÂåÖÂê´ÈõúË®äÔºåÁâπÂà•ÊòØÂú®‰ΩøÁî®ËÄÖÁöÑÁü≠ÊúüË°åÁÇ∫‰∏≠ÔºåÈÄôÂèØËÉΩÊòØÁî±Êö´ÊôÇÁöÑÊÑèÂúñÊàñË™§ÈªûÈÄ†ÊàêÁöÑ„ÄÇÈÄôÁ®ÆÈõúË®äÂ∞çÂúñÂΩ¢ÂíåÂ∫èÂàóÊ®°ÂûãÁöÑÊ∫ñÁ¢∫ÊÄßÁî¢ÁîüË≤†Èù¢ÂΩ±ÈüøÔºåÈÄ≤‰∏ÄÊ≠•Ë§áÈõúÂåñ‰∫ÜÂª∫Ê®°ÈÅéÁ®ã„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂêçÁÇ∫Ëá™Áõ£Áù£ÂúñÁ•ûÁ∂ìÁ∂≤Ë∑Ø (SelfGNN) ÁöÑÊñ∞Ê°ÜÊû∂ÔºåÁî®ÊñºÂ∫èÂàóÊé®Ëñ¶„ÄÇSelfGNN Ê°ÜÊû∂Ê†πÊìöÊôÇÈñìÈñìÈöîÂ∞çÁü≠ÊúüÂúñÂΩ¢ÈÄ≤Ë°åÁ∑®Á¢ºÔºå‰∏¶Âà©Áî®ÂúñÁ•ûÁ∂ìÁ∂≤Ë∑Ø (GNN) ‰æÜÂ≠∏ÁøíÁü≠ÊúüÂçî‰ΩúÈóú‰øÇ„ÄÇÂÆÉÈÄöÈÅéÈñìÈöîËûçÂêàÂíåÂãïÊÖãË°åÁÇ∫Âª∫Ê®°ÔºåÂú®Â§öÂÄãÁ≤íÂ∫¶Â±§Ê¨°‰∏äÊì∑ÂèñÈï∑Êúü‰ΩøÁî®ËÄÖÂíåÈ†ÖÁõÆË°®Á§∫„ÄÇÈáçË¶ÅÁöÑÊòØÔºåÊàëÂÄëÂÄãÊÄßÂåñÁöÑËá™Â¢ûÂº∑Â≠∏ÁøíÁµêÊßãÈÄöÈÅéÊ†πÊìöÈï∑Êúü‰ΩøÁî®ËÄÖËààË∂£ÂíåÂÄã‰∫∫Á©©ÂÆöÊÄß‰æÜÊ∏õËºïÁü≠ÊúüÂúñÂΩ¢‰∏≠ÁöÑÈõúË®äÔºåÂ¢ûÂº∑Ê®°ÂûãÁöÑÁ©©ÂÅ•ÊÄß„ÄÇÂú®ÂõõÂÄãÁúüÂØ¶‰∏ñÁïåË≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÁöÑÂª£Ê≥õÂØ¶È©óË°®ÊòéÔºåSelfGNN ÂÑ™ÊñºÂêÑÁ®ÆÊúÄÂÖàÈÄ≤ÁöÑÂü∫Ê∫ñ„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÂØ¶‰ΩúÁ®ãÂºèÁ¢ºÂèØÂú® https://github.com/HKUDS/SelfGNN ÂèñÂæó„ÄÇ

##### **Investigating Calibration and Corruption Robustness of Post-hoc Pruned Perception CNNs: An Image Classification Benchmark Study**
2405.20876v1 by Pallavi Mitra, Gesina Schwalbe, Nadja Klein

Convolutional Neural Networks (CNNs) have achieved state-of-the-art
performance in many computer vision tasks. However, high computational and
storage demands hinder their deployment into resource-constrained environments,
such as embedded devices. Model pruning helps to meet these restrictions by
reducing the model size, while maintaining superior performance. Meanwhile,
safety-critical applications pose more than just resource and performance
constraints. In particular, predictions must not be overly confident, i.e.,
provide properly calibrated uncertainty estimations (proper uncertainty
calibration), and CNNs must be robust against corruptions like naturally
occurring input perturbations (natural corruption robustness). This work
investigates the important trade-off between uncertainty calibration, natural
corruption robustness, and performance for current state-of-research post-hoc
CNN pruning techniques in the context of image classification tasks. Our study
reveals that post-hoc pruning substantially improves the model's uncertainty
calibration, performance, and natural corruption robustness, sparking hope for
safe and robust embedded CNNs.Furthermore, uncertainty calibration and natural
corruption robustness are not mutually exclusive targets under pruning, as
evidenced by the improved safety aspects obtained by post-hoc unstructured
pruning with increasing compression.

ÊëòË¶ÅÔºöÂç∑Á©çÁ•ûÁ∂ìÁ∂≤Ë∑Ø (CNN) Âú®Ë®±Â§öÈõªËÖ¶Ë¶ñË¶∫‰ªªÂãô‰∏≠Â∑≤ÈÅîÂà∞ÊúÄÂÖàÈÄ≤ÁöÑÊïàËÉΩ„ÄÇÁÑ∂ËÄåÔºåÈ´òÈÅãÁÆóÂíåÂÑ≤Â≠òÈúÄÊ±ÇÈòªÁ§ô‰∫ÜÂÆÉÂÄëÈÉ®ÁΩ≤Âà∞Ë≥áÊ∫êÂèóÈôêÁöÑÁí∞Â¢É‰∏≠Ôºå‰æãÂ¶ÇÂµåÂÖ•ÂºèË£ùÁΩÆ„ÄÇÊ®°ÂûãÂâ™ÊûùÊúâÂä©ÊñºÊªøË∂≥ÈÄô‰∫õÈôêÂà∂ÔºåÊñπÊ≥ïÊòØÁ∏ÆÂ∞èÊ®°ÂûãÂ§ßÂ∞èÔºåÂêåÊôÇÁ∂≠ÊåÅÂÑ™Áï∞ÊïàËÉΩ„ÄÇÂêåÊôÇÔºåÂÆâÂÖ®ÈóúÈçµÊáâÁî®Á®ãÂºè‰∏çÂÉÖÊßãÊàêË≥áÊ∫êÂíåÊïàËÉΩÈôêÂà∂„ÄÇÁâπÂà•ÊòØÔºåÈ†êÊ∏¨‰∏çËÉΩÈÅéÊñºËá™‰ø°Ôºå‰∫¶Âç≥ÔºåÊèê‰æõÈÅ©Áï∂Ê†°Ê∫ñÁöÑ‰∏çÁ¢∫ÂÆöÊÄß‰º∞Ë®àÔºàÈÅ©Áï∂ÁöÑ‰∏çÁ¢∫ÂÆöÊÄßÊ†°Ê∫ñÔºâÔºåËÄå CNN ÂøÖÈ†àÂ∞çËá™ÁÑ∂ÁôºÁîüÁöÑËº∏ÂÖ•ÊìæÂãïÔºàËá™ÁÑ∂Á†¥Â£ûÁöÑÁ©©ÂÅ•ÊÄßÔºâÁ≠âÁ†¥Â£ûÂÖ∑ÊúâÁ©©ÂÅ•ÊÄß„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÊé¢Ë®é‰∫Ü‰∏çÁ¢∫ÂÆöÊÄßÊ†°Ê∫ñ„ÄÅËá™ÁÑ∂Á†¥Â£ûÁöÑÁ©©ÂÅ•ÊÄßËàáÊïàËÉΩ‰πãÈñìÁöÑÈáçË¶ÅÊ¨äË°°ÔºåÈáùÂ∞çÂúñÂÉèÂàÜÈ°û‰ªªÂãô‰∏≠ÁõÆÂâçÁ†îÁ©∂ÁãÄÊÖãÁöÑÂæåË®≠ CNN Ââ™ÊûùÊäÄË°ì„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂È°ØÁ§∫ÔºåÂæåË®≠Ââ™ÊûùÂ§ßÂπÖÊîπÂñÑ‰∫ÜÊ®°ÂûãÁöÑ‰∏çÁ¢∫ÂÆöÊÄßÊ†°Ê∫ñ„ÄÅÊïàËÉΩÂíåËá™ÁÑ∂Á†¥Â£ûÁöÑÁ©©ÂÅ•ÊÄßÔºåÁÇ∫ÂÆâÂÖ®‰∏îÁ©©ÂÅ•ÁöÑÂµåÂÖ•Âºè CNN Â∏∂‰æÜÂ∏åÊúõ„ÄÇÊ≠§Â§ñÔºåÂú®Ââ™Êûù‰∏ãÔºå‰∏çÁ¢∫ÂÆöÊÄßÊ†°Ê∫ñÂíåËá™ÁÑ∂Á†¥Â£ûÁöÑÁ©©ÂÅ•ÊÄß‰∏¶ÈùûÁõ∏‰∫íÊéíÊñ•ÁöÑÁõÆÊ®ôÔºåÊ≠£Â¶ÇÂæåË®≠ÈùûÁµêÊßãÂåñÂâ™ÊûùÂú®Â£ìÁ∏ÆÂ¢ûÂä†ÊôÇÁç≤ÂæóÁöÑÂÆâÂÖ®ÊÄßÊñπÈù¢ÁöÑÊîπÂñÑÊâÄË≠âÊòé„ÄÇ

##### **Automatic Channel Pruning for Multi-Head Attention**
2405.20867v1 by Eunho Lee, Youngbae Hwang

Despite the strong performance of Transformers, their quadratic computation
complexity presents challenges in applying them to vision tasks. Automatic
pruning is one of effective methods for reducing computation complexity without
heuristic approaches. However, directly applying it to multi-head attention is
not straightforward due to channel misalignment. In this paper, we propose an
automatic channel pruning method to take into account the multi-head attention
mechanism. First, we incorporate channel similarity-based weights into the
pruning indicator to preserve more informative channels in each head. Then, we
adjust pruning indicator to enforce removal of channels in equal proportions
across all heads, preventing the channel misalignment. We also add a reweight
module to compensate for information loss resulting from channel removal, and
an effective initialization step for pruning indicator based on difference of
attention between original structure and each channel. Our proposed method can
be used to not only original attention, but also linear attention, which is
more efficient as linear complexity with respect to the number of tokens. On
ImageNet-1K, applying our pruning method to the FLattenTransformer, which
includes both attention mechanisms, shows outperformed accuracy for several
MACs compared with previous state-of-the-art efficient models and pruned
methods. Code will be available soon.

ÊëòË¶ÅÔºöÂÑòÁÆ° Transformer ÊúâÂº∑ÂãÅÁöÑÊïàËÉΩÔºå‰ΩÜÂÖ∂‰∫åÊ¨°ÈÅãÁÆóË§áÈõúÂ∫¶Âú®ÊáâÁî®ÊñºË¶ñË¶∫‰ªªÂãôÊôÇÊúÉÁî¢ÁîüÊåëÊà∞„ÄÇËá™ÂãïÂâ™ÊûùÊòØÈôç‰ΩéÈÅãÁÆóË§áÈõúÂ∫¶ÁöÑÊñπÊ≥ï‰πã‰∏ÄÔºå‰∏îÁÑ°ÈúÄ‰ΩøÁî®ÂïüÁôºÂºèÊñπÊ≥ï„ÄÇÁÑ∂ËÄåÔºåÁî±ÊñºÈÄöÈÅìÊú™Â∞çÈΩäÔºåÁÑ°Ê≥ïÁõ¥Êé•Â∞áÂÖ∂ÊáâÁî®ÊñºÂ§öÈ†≠Ê≥®ÊÑèÂäõ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆËá™ÂãïÈÄöÈÅìÂâ™ÊûùÊñπÊ≥ï‰æÜËÄÉÈáèÂ§öÈ†≠Ê≥®ÊÑèÂäõÊ©üÂà∂„ÄÇÈ¶ñÂÖàÔºåÊàëÂÄëÂ∞áÂü∫ÊñºÈÄöÈÅìÁõ∏‰ººÊÄßÁöÑÊ¨äÈáçÁ¥çÂÖ•Ââ™ÊûùÊåáÊ®ôÔºå‰ª•‰øùÁïôÊØèÂÄãÈ†≠‰∏≠Êõ¥Â§öÊúâË≥áË®äÊÄßÁöÑÈÄöÈÅì„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëË™øÊï¥Ââ™ÊûùÊåáÊ®ôÔºå‰ª•Âº∑Âà∂Âú®ÊâÄÊúâÈ†≠‰∏≠ÊåâÁõ∏Á≠âÊØî‰æãÁßªÈô§ÈÄöÈÅìÔºåÈò≤Ê≠¢ÈÄöÈÅìÊú™Â∞çÈΩä„ÄÇÊàëÂÄëÈÇÑÊñ∞Â¢û‰∏ÄÂÄãÈáçÊñ∞Âä†Ê¨äÊ®°ÁµÑÔºå‰ª•Ë£úÂÑüÂõ†ÈÄöÈÅìÁßªÈô§ËÄåÈÄ†ÊàêÁöÑË≥áË®äÊêçÂ§±Ôºå‰ª•Âèä‰∏ÄÂÄãÂü∫ÊñºÂéüÂßãÁµêÊßãËàáÊØèÂÄãÈÄöÈÅì‰πãÈñìÊ≥®ÊÑèÂäõÁöÑÂ∑ÆÁï∞ÁöÑÂâ™ÊûùÊåáÊ®ôÊúâÊïàÂàùÂßãÂåñÊ≠•È©ü„ÄÇÊàëÂÄëÊèêÂá∫ÁöÑÊñπÊ≥ï‰∏çÂÉÖÂèØÁî®ÊñºÂéüÂßãÊ≥®ÊÑèÂäõÔºåÈÇÑËÉΩÁî®ÊñºÁ∑öÊÄßÊ≥®ÊÑèÂäõÔºåÂÖ∂ÊïàÁéáÊõ¥È´òÔºåÂõ†ÁÇ∫ÂÖ∂Á∑öÊÄßË§áÈõúÂ∫¶Ëàá token Êï∏ÈáèÊúâÈóú„ÄÇÂú® ImageNet-1K ‰∏äÔºåÂ∞áÊàëÂÄëÁöÑÂâ™ÊûùÊñπÊ≥ïÊáâÁî®ÊñºÂåÖÂê´ÂÖ©Á®ÆÊ≥®ÊÑèÂäõÊ©üÂà∂ÁöÑ FLattenTransformerÔºåËàáÂÖàÂâçÁöÑÊúÄÂÖàÈÄ≤È´òÊïàÊ®°ÂûãÂíåÂâ™ÊûùÊñπÊ≥ïÁõ∏ÊØîÔºåÂ∞çÊñºÂ§öÂÄã MAC È°ØÁ§∫Âá∫ÂÑ™Áï∞ÁöÑÊ∫ñÁ¢∫Â∫¶„ÄÇÁ®ãÂºèÁ¢ºÂ∞áÂæàÂø´Êèê‰æõ„ÄÇ

##### **ABodyBuilder3: Improved and scalable antibody structure predictions**
2405.20863v1 by Henry Kenlay, Fr√©d√©ric A. Dreyer, Daniel Cutting, Daniel Nissley, Charlotte M. Deane

Accurate prediction of antibody structure is a central task in the design and
development of monoclonal antibodies, notably to understand both their
developability and their binding properties. In this article, we introduce
ABodyBuilder3, an improved and scalable antibody structure prediction model
based on ImmuneBuilder. We achieve a new state-of-the-art accuracy in the
modelling of CDR loops by leveraging language model embeddings, and show how
predicted structures can be further improved through careful relaxation
strategies. Finally, we incorporate a predicted Local Distance Difference Test
into the model output to allow for a more accurate estimation of uncertainties.

ÊëòË¶ÅÔºöÁ≤æÊ∫ñÈ†êÊ∏¨ÊäóÈ´îÁµêÊßãÊòØÂñÆÊ†™ÊäóÈ´îË®≠Ë®àÂíåÈñãÁôº‰∏≠ÁöÑÊ†∏ÂøÉ‰ªªÂãôÔºåÁâπÂà•ÊòØÁÇ∫‰∫Ü‰∫ÜËß£ÂÆÉÂÄëÁöÑÂèØÈñãÁôºÊÄßÂíåÁµêÂêàÁâπÊÄß„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫Ü ABodyBuilder3ÔºåÈÄôÊòØ‰∏ÄÂÄãÂü∫Êñº ImmuneBuilder ÁöÑÊîπËâØ‰∏îÂèØÊì¥ÂÖÖÁöÑÊäóÈ´îÁµêÊßãÈ†êÊ∏¨Ê®°Âûã„ÄÇÊàëÂÄëÈÄèÈÅéÂà©Áî®Ë™ûË®ÄÊ®°ÂûãÂµåÂÖ•ÔºåÂú® CDR Ëø¥ÂúàÂª∫Ê®°‰∏≠ÈÅîÂà∞‰∫ÜÊñ∞ÁöÑÊúÄÂÖàÈÄ≤Ê∫ñÁ¢∫Â∫¶Ôºå‰∏¶Â±ïÁ§∫‰∫ÜÂ¶Ç‰ΩïÈÄèÈÅéË¨πÊÖéÁöÑÊîæÈ¨ÜÁ≠ñÁï•ÈÄ≤‰∏ÄÊ≠•ÊîπÂñÑÈ†êÊ∏¨ÁµêÊßã„ÄÇÊúÄÂæåÔºåÊàëÂÄëÂ∞áÈ†êÊ∏¨ÁöÑÂ±ÄÈÉ®Ë∑ùÈõ¢Â∑ÆÁï∞Ê∏¨Ë©¶Á¥çÂÖ•Ê®°ÂûãËº∏Âá∫Ôºå‰ª•Êõ¥Ê∫ñÁ¢∫Âú∞‰º∞Ë®à‰∏çÁ¢∫ÂÆöÊÄß„ÄÇ

##### **clembench-2024: A Challenging, Dynamic, Complementary, Multilingual Benchmark and Underlying Flexible Framework for LLMs as Multi-Action Agents**
2405.20859v1 by Anne Beyer, Kranti Chalamalasetti, Sherzod Hakimov, Brielen Madureira, Philipp Sadler, David Schlangen

It has been established in recent work that Large Language Models (LLMs) can
be prompted to "self-play" conversational games that probe certain capabilities
(general instruction following, strategic goal orientation, language
understanding abilities), where the resulting interactive game play can be
automatically scored. In this paper, we take one of the proposed frameworks for
setting up such game-play environments, and further test its usefulness as an
evaluation instrument, along a number of dimensions: We show that it can easily
keep up with new developments while avoiding data contamination, we show that
the tests implemented within it are not yet saturated (human performance is
substantially higher than that of even the best models), and we show that it
lends itself to investigating additional questions, such as the impact of the
prompting language on performance. We believe that the approach forms a good
basis for making decisions on model choice for building applied interactive
systems, and perhaps ultimately setting up a closed-loop development
environment of system and simulated evaluator.

ÊëòË¶ÅÔºöÊúÄËøëÁöÑÁ†îÁ©∂Ë°®ÊòéÔºåÂ§ßÂûãËØ≠Ë®ÄÊ®°Âûã (LLM) ÂèØ‰ª•Ë¢´ÊèêÁ§∫‚ÄúËá™Ë°åÁé©ËÄç‚Äù‰ºöËØùÊ∏∏ÊàèÔºåËøô‰∫õÊ∏∏ÊàèÊé¢Êü•Êüê‰∫õËÉΩÂäõÔºàÈÅµÂæ™‰∏ÄËà¨Êåá‰ª§„ÄÅÊàòÁï•ÁõÆÊ†áÂØºÂêë„ÄÅËØ≠Ë®ÄÁêÜËß£ËÉΩÂäõÔºâÔºåÂÖ∂‰∏≠‰∫ßÁîüÁöÑ‰∫íÂä®Ê∏∏ÊàèÁé©Ê≥ïÂèØ‰ª•Ëá™Âä®ËØÑÂàÜ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨ÈááÁî®‰∫Ü‰∏ÄÁßçÊèêËÆÆÁöÑÊ°ÜÊû∂Êù•ËÆæÁΩÆÊ≠§Á±ªÊ∏∏ÊàèÁéØÂ¢ÉÔºåÂπ∂Ëøõ‰∏ÄÊ≠•ÊµãËØïÂÖ∂‰Ωú‰∏∫ËØÑ‰º∞Â∑•ÂÖ∑ÁöÑÂÆûÁî®ÊÄßÔºåÊ≤øÂ§ö‰∏™Áª¥Â∫¶ÔºöÊàë‰ª¨Â±ïÁ§∫‰∫ÜÂÆÉÂèØ‰ª•ËΩªÊùæË∑ü‰∏äÊñ∞ÂèëÂ±ïÔºåÂêåÊó∂ÈÅøÂÖçÊï∞ÊçÆÊ±°ÊüìÔºåÊàë‰ª¨Â±ïÁ§∫‰∫ÜÂÖ∂‰∏≠ÂÆûÊñΩÁöÑÊµãËØïÂ∞öÊú™È•±ÂíåÔºà‰∫∫Á±ªÁöÑË°®Áé∞ÊòéÊòæÈ´ò‰∫éÁîöËá≥ÊúÄÂ•ΩÁöÑÊ®°ÂûãÔºâÔºåÊàë‰ª¨Â±ïÁ§∫‰∫ÜÂÆÉÈÄÇÁî®‰∫éË∞ÉÊü•ÂÖ∂‰ªñÈóÆÈ¢òÔºå‰æãÂ¶ÇÊèêÁ§∫ËØ≠Ë®ÄÂØπÊÄßËÉΩÁöÑÂΩ±Âìç„ÄÇÊàë‰ª¨Áõ∏‰ø°ËØ•ÊñπÊ≥ï‰∏∫ÈíàÂØπÊûÑÂª∫Â∫îÁî®‰∫§‰∫íÂºèÁ≥ªÁªüÂÅöÂá∫Ê®°ÂûãÈÄâÊã©ÂÜ≥Á≠ñÂ•†ÂÆö‰∫ÜËâØÂ•ΩÁöÑÂü∫Á°ÄÔºåÂπ∂ÊúÄÁªàÂª∫Á´ãÁ≥ªÁªüÂíåÊ®°ÊãüËØÑ‰º∞Âô®ÁöÑÈó≠ÁéØÂºÄÂèëÁéØÂ¢É„ÄÇ

##### **Towards Spoken Language Understanding via Multi-level Multi-grained Contrastive Learning**
2405.20852v1 by Xuxin Cheng, Wanshi Xu, Zhihong Zhu, Hongxiang Li, Yuexian Zou

Spoken language understanding (SLU) is a core task in task-oriented dialogue
systems, which aims at understanding the user's current goal through
constructing semantic frames. SLU usually consists of two subtasks, including
intent detection and slot filling. Although there are some SLU frameworks joint
modeling the two subtasks and achieving high performance, most of them still
overlook the inherent relationships between intents and slots and fail to
achieve mutual guidance between the two subtasks. To solve the problem, we
propose a multi-level multi-grained SLU framework MMCL to apply contrastive
learning at three levels, including utterance level, slot level, and word level
to enable intent and slot to mutually guide each other. For the utterance
level, our framework implements coarse granularity contrastive learning and
fine granularity contrastive learning simultaneously. Besides, we also apply
the self-distillation method to improve the robustness of the model.
Experimental results and further analysis demonstrate that our proposed model
achieves new state-of-the-art results on two public multi-intent SLU datasets,
obtaining a 2.6 overall accuracy improvement on the MixATIS dataset compared to
previous best models.

ÊëòË¶ÅÔºöÂè£Ë™ûÁêÜËß£ (SLU) ÊòØ‰ªªÂãôÂ∞éÂêëÂ∞çË©±Á≥ªÁµ±‰∏≠ÁöÑÊ†∏ÂøÉ‰ªªÂãôÔºåÊó®Âú®ÈÄöÈÅéÊßãÂª∫Ë™ûÁæ©Ê°ÜÊû∂‰æÜÁêÜËß£‰ΩøÁî®ËÄÖÁöÑÁï∂ÂâçÁõÆÊ®ô„ÄÇSLU ÈÄöÂ∏∏ÂåÖÂê´ÂÖ©ÂÄãÂ≠ê‰ªªÂãôÔºåÂåÖÊã¨ÊÑèÂúñÂÅµÊ∏¨ÂíåÊßΩ‰ΩçÂ°´Ë£ú„ÄÇÂÑòÁÆ°Êúâ‰∫õ SLU Ê°ÜÊû∂ËÅØÂêàÂª∫Ê®°ÈÄôÂÖ©ÂÄãÂ≠ê‰ªªÂãô‰∏¶Áç≤ÂæóÈ´òÊÄßËÉΩÔºå‰ΩÜÂ§ßÂ§öÊï∏‰ªçÁÑ∂ÂøΩÁï•ÊÑèÂúñÂíåÊßΩ‰Ωç‰πãÈñìÁöÑÂÖßÂú®Èóú‰øÇÔºå‰∏¶‰∏îÁÑ°Ê≥ïÂØ¶ÁèæÂÖ©ÂÄãÂ≠ê‰ªªÂãô‰πãÈñìÁöÑÁõ∏‰∫íÊåáÂ∞é„ÄÇÁÇ∫‰∫ÜËß£Ê±∫Ê≠§ÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂ§öÂ±§Â§öÁ≤íÂ∫¶ SLU Ê°ÜÊû∂ MMCLÔºåÂ∞áÂ∞çÊØîÂ≠∏ÁøíÊáâÁî®Êñº‰∏âÂÄãÂ±§Á¥öÔºåÂåÖÊã¨ÁôºË©±Â±§Á¥ö„ÄÅÊßΩ‰ΩçÂ±§Á¥öÂíåÂ≠óË©ûÂ±§Á¥öÔºå‰ª•‰ΩøÊÑèÂúñÂíåÊßΩ‰ΩçËÉΩÂ§†Áõ∏‰∫íÊåáÂ∞é„ÄÇÂ∞çÊñºÁôºË©±Â±§Á¥öÔºåÊàëÂÄëÁöÑÊ°ÜÊû∂ÂêåÊôÇÂØ¶‰ΩúÁ≤óÁ≤íÂ∫¶Â∞çÊØîÂ≠∏ÁøíÂíåÁ¥∞Á≤íÂ∫¶Â∞çÊØîÂ≠∏Áøí„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÈÇÑÊáâÁî®Ëá™Ëí∏È§æÊñπÊ≥ï‰æÜÊèêÈ´òÊ®°ÂûãÁöÑÁ©©ÂÅ•ÊÄß„ÄÇÂØ¶È©óÁµêÊûúÂíåÈÄ≤‰∏ÄÊ≠•ÂàÜÊûêË°®ÊòéÔºåÊàëÂÄëÊèêÂá∫ÁöÑÊ®°ÂûãÂú®ÂÖ©ÂÄãÂÖ¨ÈñãÁöÑÂ§öÊÑèÂúñ SLU Ë≥áÊñôÈõÜ‰∏äÂèñÂæóÊñ∞ÁöÑÊúÄÂÖàÈÄ≤ÁµêÊûúÔºåËàáÂÖàÂâçÁöÑÊúÄ‰Ω≥Ê®°ÂûãÁõ∏ÊØîÔºåÂú® MixATIS Ë≥áÊñôÈõÜ‰∏äÁç≤Âæó 2.6 ÁöÑÊï¥È´îÊ∫ñÁ¢∫Â∫¶ÊèêÂçá„ÄÇ

##### **Improving Reward Models with Synthetic Critiques**
2405.20850v1 by Zihuiwen Ye, Fraser Greenlee-Scott, Max Bartolo, Phil Blunsom, Jon Ander Campos, Matthias Gall√©

Reward models (RM) play a critical role in aligning language models through
the process of reinforcement learning from human feedback. RMs are trained to
predict a score reflecting human preference, which requires significant time
and cost for human annotation. Additionally, RMs tend to quickly overfit on
superficial features in the training set, hindering their generalization
performance on unseen distributions. We propose a novel approach using
synthetic natural language critiques generated by large language models to
provide additional feedback, evaluating aspects such as instruction following,
correctness, and style. This offers richer signals and more robust features for
RMs to assess and score on. We demonstrate that high-quality critiques improve
the performance and data efficiency of RMs initialized from different
pretrained models. Conversely, we also show that low-quality critiques
negatively impact performance. Furthermore, incorporating critiques enhances
the interpretability and robustness of RM training.

ÊëòË¶ÅÔºöÁçéÂãµÊ®°ÂûãÔºàRMÔºâÂú®ÈÄèÈÅé‰∫∫È°ûÂõûÈ•ãÁöÑÂº∑ÂåñÂ≠∏ÁøíÈÅéÁ®ã‰∏≠ÔºåÂ∞çÈΩäË™ûË®ÄÊ®°ÂûãÊâÆÊºîÈóúÈçµËßíËâ≤„ÄÇRM Á∂ìÈÅéË®ìÁ∑¥ÔºåÂèØÈ†êÊ∏¨ÂèçÊò†‰∫∫È°ûÂÅèÂ•ΩÁöÑÂàÜÊï∏ÔºåÈÄôÈúÄË¶ÅÂ§ßÈáèÊôÇÈñìÂíåÊàêÊú¨ÈÄ≤Ë°å‰∫∫Â∑•Ë®ªËß£„ÄÇÊ≠§Â§ñÔºåRM ÂÇæÂêëÊñºÂø´ÈÄüÈÅéÂ∫¶Êì¨ÂêàË®ìÁ∑¥ÈõÜ‰∏≠ÁöÑË°®Èù¢ÁâπÂæµÔºåÈòªÁ§ôÂÖ∂Âú®Êú™Ë¶ãÂàÜÂ∏É‰∏äÁöÑÊ≥õÂåñÊïàËÉΩ„ÄÇÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÊñ∞Á©éÁöÑÊñπÊ≥ïÔºå‰ΩøÁî®Â§ßÂûãË™ûË®ÄÊ®°ÂûãÁî¢ÁîüÁöÑÂêàÊàêËá™ÁÑ∂Ë™ûË®ÄÊâπË©ïÔºåÊèê‰æõÈ°çÂ§ñÁöÑÂõûÈ•ãÔºåË©ï‰º∞ÊåáÁ§∫ÈÅµÂæ™„ÄÅÊ≠£Á¢∫ÊÄßÂíåÈ¢®Ê†ºÁ≠âÈù¢Âêë„ÄÇÈÄôÁÇ∫ RM Êèê‰æõÊõ¥Ë±êÂØåÁöÑË®äËôüÂíåÊõ¥Á©©ÂÅ•ÁöÑÁâπÂæµÔºå‰ª•‰æøË©ï‰º∞ÂíåË©ïÂàÜ„ÄÇÊàëÂÄëË≠âÊòéÈ´òÂìÅË≥™ÁöÑÊâπË©ïÊîπÂñÑ‰∫ÜÂæû‰∏çÂêåÈ†êË®ìÁ∑¥Ê®°ÂûãÂàùÂßãÂåñÁöÑ RM ÁöÑÊïàËÉΩÂíåË≥áÊñôÊïàÁéá„ÄÇÁõ∏ÂèçÂú∞ÔºåÊàëÂÄë‰πüÈ°ØÁ§∫‰ΩéÂìÅË≥™ÁöÑÊâπË©ïÂ∞çÊïàËÉΩÁî¢ÁîüË≤†Èù¢ÂΩ±Èüø„ÄÇÊ≠§Â§ñÔºåÁ¥çÂÖ•ÊâπË©ïÂèØÂ¢ûÂº∑ RM Ë®ìÁ∑¥ÁöÑÂèØËß£ÈáãÊÄßÂíåÁ©©ÂÅ•ÊÄß„ÄÇ

##### **SLIM: a Scalable Light-weight Root Cause Analysis for Imbalanced Data in Microservice**
2405.20848v1 by Rui Ren, Jingbang Yang, Linxiao Yang, Xinyue Gu, Liang Sun

The newly deployed service -- one kind of change service, could lead to a new
type of minority fault. Existing state-of-the-art methods for fault
localization rarely consider the imbalanced fault classification in change
service. This paper proposes a novel method that utilizes decision rule sets to
deal with highly imbalanced data by optimizing the F1 score subject to
cardinality constraints. The proposed method greedily generates the rule with
maximal marginal gain and uses an efficient minorize-maximization (MM) approach
to select rules iteratively, maximizing a non-monotone submodular lower bound.
Compared with existing fault localization algorithms, our algorithm can adapt
to the imbalanced fault scenario of change service, and provide interpretable
fault causes which are easy to understand and verify. Our method can also be
deployed in the online training setting, with only about 15% training overhead
compared to the current SOTA methods. Empirical studies showcase that our
algorithm outperforms existing fault localization algorithms in both accuracy
and model interpretability.

ÊëòË¶ÅÔºöÊñ∞ÈÉ®ÁΩ≤ÁöÑÊúçÂãô‚Äî‚Äî‰∏ÄÁ®ÆËÆäÊõ¥ÊúçÂãôÔºåÂèØËÉΩÊúÉÂ∞éËá¥Êñ∞ÁöÑÂ∞ëÊï∏ÊïÖÈöúÈ°ûÂûã„ÄÇÁèæÊúâÁöÑÊïÖÈöúÂÆö‰ΩçÊäÄË°ìÊúÄÂÖàÈÄ≤ÁöÑÊñπÊ≥ïÂæàÂ∞ëËÄÉÊÖÆËÆäÊõ¥ÊúçÂãô‰∏≠ÁöÑ‰∏çÂπ≥Ë°°ÊïÖÈöúÂàÜÈ°û„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞ÊñπÊ≥ïÔºåÂà©Áî®Ê±∫Á≠ñË¶èÂâáÈõÜÈÄöÈÅéÂÑ™Âåñ F1 ÂàÜÊï∏ÔºàÂèóÂü∫Êï∏Á¥ÑÊùüÔºâ‰æÜËôïÁêÜÈ´òÂ∫¶‰∏çÂπ≥Ë°°ÁöÑÊï∏Êìö„ÄÇÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïË≤™Â©™Âú∞ÁîüÊàêÈÇäÈöõÂ¢ûÁõäÊúÄÂ§ßÁöÑË¶èÂâáÔºå‰∏¶‰ΩøÁî®‰∏ÄÁ®ÆÊúâÊïàÁöÑÊúÄÂ∞èÂåñ-ÊúÄÂ§ßÂåñ (MM) ÊñπÊ≥ïËø≠‰ª£ÈÅ∏ÊìáË¶èÂâáÔºåÂæûËÄåÊúÄÂ§ßÂåñÈùûÂñÆË™øÂ≠êÊ®°ÂáΩÊï∏‰∏ãÁïå„ÄÇËàáÁèæÊúâÁöÑÊïÖÈöúÂÆö‰ΩçÁÆóÊ≥ïÁõ∏ÊØîÔºåÊàëÂÄëÁöÑÁÆóÊ≥ïÂèØ‰ª•ÈÅ©ÊáâËÆäÊõ¥ÊúçÂãôÁöÑ‰∏çÂπ≥Ë°°ÊïÖÈöúÂ†¥ÊôØÔºå‰∏¶Êèê‰æõÊòìÊñºÁêÜËß£ÂíåÈ©óË≠âÁöÑÂèØËß£ÈáãÊïÖÈöúÂéüÂõ†„ÄÇÊàëÂÄëÁöÑÁÆóÊ≥ïÈÇÑÂèØ‰ª•ÈÉ®ÁΩ≤Âú®Á∑ö‰∏äË®ìÁ∑¥Ë®≠ÁΩÆ‰∏≠ÔºåËàáÁï∂Ââç SOTA ÊñπÊ≥ïÁõ∏ÊØîÔºåË®ìÁ∑¥ÈñãÈä∑ÂÉÖÂ¢ûÂä†‰∫ÜÁ¥Ñ 15%„ÄÇÁ∂ìÈ©óÁ†îÁ©∂Ë°®ÊòéÔºåÊàëÂÄëÁöÑÁÆóÊ≥ïÂú®Ê∫ñÁ¢∫ÊÄßÂíåÊ®°ÂûãÂèØËß£ÈáãÊÄßÊñπÈù¢ÈÉΩÂÑ™ÊñºÁèæÊúâÁöÑÊïÖÈöúÂÆö‰ΩçÁÆóÊ≥ï„ÄÇ

##### **Don't Buy it! Reassessing the Ad Understanding Abilities of Contrastive Multimodal Models**
2405.20846v1 by A. Bavaresco, A. Testoni, R. Fern√°ndez

Image-based advertisements are complex multimodal stimuli that often contain
unusual visual elements and figurative language. Previous research on automatic
ad understanding has reported impressive zero-shot accuracy of contrastive
vision-and-language models (VLMs) on an ad-explanation retrieval task. Here, we
examine the original task setup and show that contrastive VLMs can solve it by
exploiting grounding heuristics. To control for this confound, we introduce
TRADE, a new evaluation test set with adversarial grounded explanations. While
these explanations look implausible to humans, we show that they "fool" four
different contrastive VLMs. Our findings highlight the need for an improved
operationalisation of automatic ad understanding that truly evaluates VLMs'
multimodal reasoning abilities. We make our code and TRADE available at
https://github.com/dmg-illc/trade .

ÊëòË¶ÅÔºöÂü∫ÊñºÂΩ±ÂÉèÁöÑÂª£ÂëäÊòØË§áÈõúÁöÑÂ§öÊ®°ÊÖãÂà∫ÊøÄÔºåÈÄöÂ∏∏ÂåÖÂê´‰∏çÂ∞ãÂ∏∏ÁöÑË¶ñË¶∫ÂÖÉÁ¥†ÂíåÊØîÂñªË™ûË®Ä„ÄÇÂÖàÂâçÈóúÊñºËá™ÂãïÂª£ÂëäÁêÜËß£ÁöÑÁ†îÁ©∂Â∑≤Â†±Â∞éÂ∞çÊØîË¶ñË¶∫ÂíåË™ûË®ÄÊ®°Âûã (VLM) Âú®Âª£ÂëäËß£ÈáãÊ™¢Á¥¢‰ªªÂãô‰∏ä‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑÈõ∂Ê¨°Â≠∏ÁøíÊ∫ñÁ¢∫Â∫¶„ÄÇÂú®Ê≠§ÔºåÊàëÂÄëÊ™¢Êü•ÂéüÂßã‰ªªÂãôË®≠ÂÆöÔºå‰∏¶Â±ïÁ§∫Â∞çÊØî VLM ÂèØ‰ª•ÈÄèÈÅéÂà©Áî®Êé•Âú∞ÂïüÁôºÊ≥ï‰æÜËß£Ê±∫ÂÆÉ„ÄÇÁÇ∫‰∫ÜÊéßÂà∂ÈÄôÁ®ÆÊ∑∑Ê∑ÜÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü TRADEÔºåÈÄôÊòØ‰∏ÄÂÄãÂåÖÂê´Â∞çÊäóÊé•Âú∞Ëß£ÈáãÁöÑÊñ∞Ë©ï‰º∞Ê∏¨Ë©¶ÈõÜ„ÄÇÈõñÁÑ∂ÈÄô‰∫õËß£ÈáãÂ∞ç‰∫∫È°û‰æÜË™™ÁúãËµ∑‰æÜÈõ£‰ª•ÁΩÆ‰ø°Ôºå‰ΩÜÊàëÂÄëÂ±ïÁ§∫ÂÆÉÂÄë„ÄåÊÑöÂºÑ„Äç‰∫ÜÂõõÂÄã‰∏çÂêåÁöÑÂ∞çÊØî VLM„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÂº∑Ë™øÈúÄË¶ÅÊîπÈÄ≤Ëá™ÂãïÂª£ÂëäÁêÜËß£ÁöÑÊìç‰ΩúÂåñÔºå‰ª•ÁúüÊ≠£Ë©ï‰º∞ VLM ÁöÑÂ§öÊ®°ÊÖãÊé®ÁêÜËÉΩÂäõ„ÄÇÊàëÂÄëÂú® https://github.com/dmg-illc/trade Êèê‰æõÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÂíå TRADE„ÄÇ

##### **einspace: Searching for Neural Architectures from Fundamental Operations**
2405.20838v1 by Linus Ericsson, Miguel Espinosa, Chenhongyi Yang, Antreas Antoniou, Amos Storkey, Shay B. Cohen, Steven McDonagh, Elliot J. Crowley

Neural architecture search (NAS) finds high performing networks for a given
task. Yet the results of NAS are fairly prosaic; they did not e.g. create a
shift from convolutional structures to transformers. This is not least because
the search spaces in NAS often aren't diverse enough to include such
transformations a priori. Instead, for NAS to provide greater potential for
fundamental design shifts, we need a novel expressive search space design which
is built from more fundamental operations. To this end, we introduce einspace,
a search space based on a parameterised probabilistic context-free grammar. Our
space is versatile, supporting architectures of various sizes and complexities,
while also containing diverse network operations which allow it to model
convolutions, attention components and more. It contains many existing
competitive architectures, and provides flexibility for discovering new ones.
Using this search space, we perform experiments to find novel architectures as
well as improvements on existing ones on the diverse Unseen NAS datasets. We
show that competitive architectures can be obtained by searching from scratch,
and we consistently find large improvements when initialising the search with
strong baselines. We believe that this work is an important advancement towards
a transformative NAS paradigm where search space expressivity and strategic
search initialisation play key roles.

ÊëòË¶ÅÔºöÁ•ûÁ∂ìÁµêÊßãÊêúÂ∞ã (NAS) Â∞ãÊâæÁµ¶ÂÆö‰ªªÂãôÁöÑÈ´òÊïàËÉΩÁ∂≤Ë∑Ø„ÄÇÁÑ∂ËÄåÔºåNAS ÁöÑÁµêÊûúÁõ∏Áï∂Âπ≥Ê∑°Ôºõ‰æãÂ¶ÇÔºåÂÆÉÂÄë‰∏¶Êú™ÂæûÊç≤Á©çÁµêÊßãËΩâÁßªÂà∞Transformer„ÄÇÈÄô‰∏ªË¶ÅÊòØÂõ†ÁÇ∫ NAS ‰∏≠ÁöÑÊêúÂ∞ãÁ©∫ÈñìÈÄöÂ∏∏‰∏çÂ§†Â§öÂÖÉÔºåÁÑ°Ê≥ïÂÖàÈ©óÂåÖÂê´Ê≠§È°ûËΩâÊèõ„ÄÇÁõ∏ÂèçÂú∞ÔºåÁÇ∫‰∫ÜËÆì NAS Êèê‰æõÊõ¥Â§ßÁöÑÂü∫Êú¨Ë®≠Ë®àËΩâËÆäÊΩõÂäõÔºåÊàëÂÄëÈúÄË¶Å‰∏ÄÂÄãÊñ∞Á©é‰∏îÂÖ∑Ë°®ÈÅîÂäõÁöÑÊêúÂ∞ãÁ©∫ÈñìË®≠Ë®àÔºåËÄåÊ≠§Ë®≠Ë®àÊòØÂª∫Á´ãÂú®Êõ¥Âü∫Êú¨ÁöÑÈÅãÁÆó‰∏ä„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü einspaceÔºå‰∏ÄÂÄãÂü∫ÊñºÂèÉÊï∏ÂåñÊ©üÁéáÁÑ°‰∏ä‰∏ãÊñáÊñáÊ≥ïÁöÑÊêúÂ∞ãÁ©∫Èñì„ÄÇÊàëÂÄëÁöÑÁ©∫ÈñìÂÖ∑ÊúâÂ§öÂäüËÉΩÊÄßÔºåÊîØÊè¥ÂêÑÁ®ÆÂ§ßÂ∞èÂíåË§áÈõúÊÄßÁöÑÊû∂ÊßãÔºåÂêåÊôÇ‰πüÂåÖÂê´Â§öÂÖÉÁöÑÁ∂≤Ë∑ØÈÅãÁÆóÔºå‰ΩøÂÖ∂ËÉΩÂ§†Âª∫Ê®°Âç∑Á©ç„ÄÅÊ≥®ÊÑèÂäõÂÖÉ‰ª∂Á≠â„ÄÇÂÆÉÂåÖÂê´Ë®±Â§öÁèæÊúâÁöÑÁ´∂Áà≠ÊÄßÊû∂ÊßãÔºå‰∏¶Êèê‰æõÂΩàÊÄß‰æÜÁôºÁèæÊñ∞ÁöÑÊû∂Êßã„ÄÇ‰ΩøÁî®Ê≠§ÊêúÂ∞ãÁ©∫ÈñìÔºåÊàëÂÄëÂü∑Ë°åÂØ¶È©ó‰ª•Â∞ãÊâæÊñ∞Á©éÁöÑÊû∂ÊßãÔºå‰ª•ÂèäÂú®Â§öÂÖÉÁöÑ Unseen NAS Ë≥áÊñôÈõÜ‰∏äÂ∞çÁèæÊúâÊû∂ÊßãÈÄ≤Ë°åÊîπÈÄ≤„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫ÜÂèØÈÄèÈÅéÂæûÈ†≠ÈñãÂßãÊêúÂ∞ã‰æÜÂèñÂæóÁ´∂Áà≠ÊÄßÊû∂ÊßãÔºå‰∏¶‰∏îÂú®‰ΩøÁî®Âº∑Â§ßÁöÑÂü∫Ê∫ñÂàùÂßãÂåñÊêúÂ∞ãÊôÇÔºåÊàëÂÄëÊåÅÁ∫åÁôºÁèæÂ§ßÂπÖÁöÑÊîπÈÄ≤„ÄÇÊàëÂÄëÁõ∏‰ø°ÈÄôÈ†ÖÂ∑•‰ΩúÊòØÈÇÅÂêëËΩâÂûã NAS ÂÖ∏ÁØÑÁöÑÈáçË¶ÅÈÄ≤Â±ïÔºåÂÖ∂‰∏≠ÊêúÂ∞ãÁ©∫ÈñìÁöÑË°®ÈÅîÂäõÂíåÁ≠ñÁï•ÊÄßÊêúÂ∞ãÂàùÂßãÂåñÊâÆÊºî‰∫ÜÈóúÈçµËßíËâ≤„ÄÇ

##### **Outliers and Calibration Sets have Diminishing Effect on Quantization of Modern LLMs**
2405.20835v1 by Davide Paglieri, Saurabh Dash, Tim Rockt√§schel, Jack Parker-Holder

Post-Training Quantization (PTQ) enhances the efficiency of Large Language
Models (LLMs) by enabling faster operation and compatibility with more
accessible hardware through reduced memory usage, at the cost of small
performance drops. We explore the role of calibration sets in PTQ, specifically
their effect on hidden activations in various notable open-source LLMs.
Calibration sets are crucial for evaluating activation magnitudes and
identifying outliers, which can distort the quantization range and negatively
impact performance. Our analysis reveals a marked contrast in quantization
effectiveness across models. The older OPT model, which much of the
quantization literature is based on, shows significant performance
deterioration and high susceptibility to outliers with varying calibration
sets. In contrast, newer models like Llama-2 7B, Llama-3 8B, Command-R 35B, and
Mistral 7B demonstrate strong robustness, with Mistral 7B showing near-immunity
to outliers and stable activations. These findings suggest a shift in PTQ
strategies might be needed. As advancements in pre-training methods reduce the
relevance of outliers, there is an emerging need to reassess the fundamentals
of current quantization literature. The emphasis should pivot towards
optimizing inference speed, rather than primarily focusing on outlier
preservation, to align with the evolving characteristics of state-of-the-art
LLMs.

ÊëòË¶ÅÔºöÂæåË®ìÁ∑¥ÈáèÂåñ (PTQ) ÈÄèÈÅéÈôç‰ΩéË®òÊÜ∂È´î‰ΩøÁî®Èáè‰æÜÊèêÂçáÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊïàÁéáÔºåÈÄ≤ËÄåÂØ¶ÁèæÊõ¥Âø´ÈÄüÁöÑÈÅã‰ΩúÔºå‰∏¶ËàáÊõ¥Â§öÂèØÂ≠òÂèñÁöÑÁ°¨È´îÁõ∏ÂÆπÔºå‰ΩÜ‰ª£ÂÉπÊòØÊúÉÁ®çÂæÆÈôç‰ΩéÊïàËÉΩ„ÄÇÊàëÂÄëÊé¢Ë®éÊ†°Ê≠£ÈõÜÂú® PTQ ‰∏≠ÁöÑËßíËâ≤ÔºåÁâπÂà•ÊòØÂÆÉÂÄëÂ∞çÂêÑÁ®ÆËëóÂêçÁöÑÈñãÊîæÂéüÂßãÁ¢º LLM ‰∏≠ÁöÑÈö±ËóèÊøÄÊ¥ªÁöÑÂΩ±Èüø„ÄÇÊ†°Ê≠£ÈõÜÂ∞çÊñºË©ï‰º∞ÊøÄÊ¥ªÂπÖÂ∫¶ÂíåÊâæÂá∫Áï∞Â∏∏ÂÄºËá≥ÈóúÈáçË¶ÅÔºåÂõ†ÁÇ∫Áï∞Â∏∏ÂÄºÂèØËÉΩÊúÉÊâ≠Êõ≤ÈáèÂåñÁØÑÂúç‰∏¶Â∞çÊïàËÉΩÈÄ†ÊàêË≤†Èù¢ÂΩ±Èüø„ÄÇÊàëÂÄëÁöÑÂàÜÊûêÈ°ØÁ§∫Ôºå‰∏çÂêåÊ®°ÂûãÂú®ÈáèÂåñÊúâÊïàÊÄß‰∏äÊúâÈ°ØËëóÁöÑÂ∑ÆÁï∞„ÄÇË®±Â§öÈáèÂåñÊñáÁçªÊâÄ‰æùÊìöÁöÑËºÉËàä OPT Ê®°ÂûãÔºåÈ°ØÁ§∫Âá∫È°ØËëóÁöÑÊïàËÉΩÊÉ°ÂåñÔºå‰∏îÂ∞ç‰∏çÂêåÊ†°Ê≠£ÈõÜÁöÑÁï∞Â∏∏ÂÄºÈ´òÂ∫¶ÊïèÊÑü„ÄÇÁõ∏ÊØî‰πã‰∏ãÔºåÊõ¥Êñ∞ÁöÑÊ®°ÂûãÔºå‰æãÂ¶Ç Llama-2 7B„ÄÅLlama-3 8B„ÄÅCommand-R 35B Âíå Mistral 7BÔºåÂâáÂ±ïÁèæÂá∫Âº∑Â§ßÁöÑÁ©©ÂÅ•ÊÄßÔºåÂÖ∂‰∏≠ Mistral 7B È°ØÁ§∫Âá∫Â∞çÁï∞Â∏∏ÂÄºÁöÑËøë‰πéÂÖçÁñ´ÊÄßÂíåÁ©©ÂÆöÁöÑÊøÄÊ¥ª„ÄÇÈÄô‰∫õÁôºÁèæË°®ÊòéÔºåPTQ Á≠ñÁï•ÂèØËÉΩÈúÄË¶ÅËΩâËÆä„ÄÇÈö®ËëóÈ†êË®ìÁ∑¥ÊñπÊ≥ïÁöÑÈÄ≤Ê≠•Èôç‰ΩéÁï∞Â∏∏ÂÄºÁöÑÈáçË¶ÅÊÄßÔºåÈáçÊñ∞Ë©ï‰º∞Áï∂ÂâçÈáèÂåñÊñáÁçªÁöÑÂü∫Êú¨ÂéüÁêÜÂ∑≤ÊàêÁÇ∫Êñ∞ËààÈúÄÊ±Ç„ÄÇÈáçÈªûÊáâËΩâÂêëÊúÄ‰Ω≥ÂåñÊé®Ë´ñÈÄüÂ∫¶ÔºåËÄå‰∏çÊòØ‰∏ªË¶ÅÈóúÊ≥®Áï∞Â∏∏ÂÄº‰øùÁïôÔºå‰ª•Á¨¶ÂêàÊúÄÂÖàÈÄ≤ LLM ÁöÑÊºîÂåñÁâπÊÄß„ÄÇ

##### **That's Optional: A Contemporary Exploration of "that" Omission in English Subordinate Clauses**
2405.20833v1 by Ella Rabinovich

The Uniform Information Density (UID) hypothesis posits that speakers
optimize the communicative properties of their utterances by avoiding spikes in
information, thereby maintaining a relatively uniform information profile over
time. This paper investigates the impact of UID principles on syntactic
reduction, specifically focusing on the optional omission of the connector
"that" in English subordinate clauses. Building upon previous research, we
extend our investigation to a larger corpus of written English, utilize
contemporary large language models (LLMs) and extend the information-uniformity
principles by the notion of entropy, to estimate the UID manifestations in the
usecase of syntactic reduction choices.

ÊëòË¶ÅÔºöÂùáÂãªË≥áË®äÂØÜÂ∫¶ (UID) ÂÅáË®≠‰∏ªÂºµÔºåË™™Ë©±ËÄÖÈÄèÈÅéÈÅøÂÖçË≥áË®äÂ≥∞ÂÄº‰æÜÂÑ™ÂåñÂÖ∂Ë©±Ë™ûÁöÑÊ∫ùÈÄöÁâπÊÄßÔºåÂæûËÄåÈö®ËëóÊôÇÈñìÁ∂≠ÊåÅÁõ∏Â∞çÂùáÂãªÁöÑË≥áË®äËº™Âªì„ÄÇÊú¨ÊñáÊé¢Ë®é UID ÂéüÂâáÂ∞çÂè•Ê≥ïÁ∞°ÂåñÁöÑÂΩ±ÈüøÔºåÁâπÂà•ÈóúÊ≥®Ëã±Ë™ûÂæûÂ±¨Â≠êÂè•‰∏≠ÈÄ£Êé•Ë©û„Äåthat„ÄçÁöÑÁúÅÁï•„ÄÇÂú®ÂÖàÂâçÁöÑÁ†îÁ©∂Âü∫Á§é‰∏äÔºåÊàëÂÄëÂ∞áÁ†îÁ©∂Êì¥Â±ïÂà∞Êõ¥Â§ßÁöÑËã±Ë™ûÊõ∏Èù¢Ë™ûÊñôÂ∫´‰∏≠ÔºåÂà©Áî®Áï∂‰ª£Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM)Ôºå‰∏¶ÈÄèÈÅéÁÜµÁöÑÊ¶ÇÂøµÊì¥Â±ïË≥áË®äÂùáÂãªÊÄßÂéüÂâáÔºå‰ª•‰º∞Ë®à UID Âú®Âè•Ê≥ïÁ∞°ÂåñÈÅ∏Êìá‰∏≠ÁöÑË°®Áèæ„ÄÇ

##### **Self-Augmented Preference Optimization: Off-Policy Paradigms for Language Model Alignment**
2405.20830v1 by Yueqin Yin, Zhendong Wang, Yujia Xie, Weizhu Chen, Mingyuan Zhou

Traditional language model alignment methods, such as Direct Preference
Optimization (DPO), are limited by their dependence on static, pre-collected
paired preference data, which hampers their adaptability and practical
applicability. To overcome this limitation, we introduce Self-Augmented
Preference Optimization (SAPO), an effective and scalable training paradigm
that does not require existing paired data. Building on the self-play concept,
which autonomously generates negative responses, we further incorporate an
off-policy learning pipeline to enhance data exploration and exploitation.
Specifically, we employ an Exponential Moving Average (EMA) model in
conjunction with a replay buffer to enable dynamic updates of response
segments, effectively integrating real-time feedback with insights from
historical data. Our comprehensive evaluations of the LLaMA3-8B and Mistral-7B
models across benchmarks, including the Open LLM Leaderboard, IFEval,
AlpacaEval 2.0, and MT-Bench, demonstrate that SAPO matches or surpasses
established offline contrastive baselines, such as DPO and Odds Ratio
Preference Optimization, and outperforms offline self-play methods like SPIN.
Our code is available at https://github.com/yinyueqin/SAPO

ÊëòË¶ÅÔºöÂÇ≥Áµ±Ë™ûË®ÄÊ®°ÂûãÂ∞çÈΩäÊñπÊ≥ïÔºå‰æãÂ¶ÇÁõ¥Êé•ÂÅèÂ•ΩÊúÄ‰Ω≥Âåñ (DPO)ÔºåÂèóÂà∞‰æùË≥¥ÈùúÊÖã„ÄÅÈ†êÂÖàÊî∂ÈõÜÁöÑÈÖçÂ∞çÂÅèÂ•ΩË≥áÊñôÁöÑÈôêÂà∂ÔºåÈÄôÊúÉÂ¶®Á§ôÂÖ∂ÈÅ©ÊáâÊÄßÂíåÂØ¶Áî®ÊÄß„ÄÇÁÇ∫‰∫ÜÂÖãÊúçÈÄôÂÄãÈôêÂà∂ÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜËá™ÊàëÊì¥ÂÖÖÂÅèÂ•ΩÊúÄ‰Ω≥Âåñ (SAPO)ÔºåÈÄôÊòØ‰∏ÄÁ®ÆÊúâÊïà‰∏îÂèØÊì¥ÂÖÖÁöÑË®ìÁ∑¥ÁØÑ‰æãÔºå‰∏çÈúÄË¶ÅÁèæÊúâÁöÑÈÖçÂ∞çË≥áÊñô„ÄÇÂª∫Á´ãÂú®Ëá™ÊàëÂ∞çÂºàÊ¶ÇÂøµ‰πã‰∏äÔºåÂÆÉÊúÉËá™ÂãïÁî¢ÁîüË≤†Èù¢ÂõûÊáâÔºåÊàëÂÄëÈÄ≤‰∏ÄÊ≠•Êï¥Âêà‰∫Ü‰∏ÄÂÄãÈùûÁ≠ñÁï•Â≠∏ÁøíÁÆ°ÈÅìÔºå‰ª•Â¢ûÂº∑Ë≥áÊñôÊé¢Á¥¢ÂíåÂà©Áî®„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÊé°Áî®ÊåáÊï∏ÁßªÂãïÂπ≥Âùá (EMA) Ê®°ÂûãÔºå‰∏¶ÁµêÂêàÈáçÊí≠Á∑©Ë°ùÂçÄÔºå‰ª•ÂïüÁî®ÂõûÊáâÁâáÊÆµÁöÑÂãïÊÖãÊõ¥Êñ∞ÔºåÊúâÊïàÂú∞Â∞áÂç≥ÊôÇÂõûÈ•ãËàáÊ≠∑Âè≤Ë≥áÊñôÁöÑË¶ãËß£Êï¥ÂêàÂú®‰∏ÄËµ∑„ÄÇÊàëÂÄëÂ∞ç LLaMA3-8B Âíå Mistral-7B Ê®°ÂûãÂú®Âü∫Ê∫ñ‰∏äÁöÑÂÖ®Èù¢Ë©ï‰º∞ÔºåÂåÖÊã¨ Open LLM Leaderboard„ÄÅIFEval„ÄÅAlpacaEval 2.0 Âíå MT-BenchÔºåË≠âÊòé SAPO ÂåπÈÖçÊàñË∂ÖË∂äÂ∑≤Âª∫Á´ãÁöÑÈõ¢Á∑öÂ∞çÊØîÂü∫Ê∫ñÔºå‰æãÂ¶Ç DPO ÂíåÊ©üÁéáÊØîÂÅèÂ•ΩÊúÄ‰Ω≥ÂåñÔºå‰∏¶‰∏îÂÑ™ÊñºÈõ¢Á∑öËá™ÊàëÂ∞çÂºàÊñπÊ≥ïÔºå‰æãÂ¶Ç SPIN„ÄÇÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÂèØÂú® https://github.com/yinyueqin/SAPO ÂèñÂæó

##### **An iterated learning model of language change that mixes supervised and unsupervised learning**
2405.20818v1 by Jack Bunyan, Seth Bullock, Conor Houghton

The iterated learning model is an agent-based model of language change in
which language is transmitted from a tutor to a pupil which itself becomes a
tutor to a new pupil, and so on. Languages that are stable, expressive, and
compositional arise spontaneously as a consequence of a language transmission
bottleneck. Previous models have implemented an agent's mapping from signals to
meanings using an artificial neural network decoder, but have relied on an
unrealistic and computationally expensive process of obversion to implement the
associated encoder, mapping from meanings to signals. Here, a new model is
presented in which both decoder and encoder are neural networks, trained
separately through supervised learning, and trained together through
unsupervised learning in the form of an autoencoder. This avoids the
substantial computational burden entailed in obversion and introduces a mixture
of supervised and unsupervised learning as observed during human development.

ÊëòË¶ÅÔºöËø≠‰ª£Â≠∏ÁøíÊ®°ÂûãÊòØ‰∏ÄÁ®ÆÂü∫Êñº‰ª£ÁêÜÁöÑË™ûË®ÄËÆäÈÅ∑Ê®°ÂûãÔºåÂÖ∂‰∏≠Ë™ûË®ÄÁî±Â∞éÂ∏´ÂÇ≥ÈÅûÁµ¶Â≠∏ÁîüÔºåËÄåÂ≠∏ÁîüÊú¨Ë∫´ÂèàÊàêÁÇ∫Êñ∞Â≠∏ÁîüÁöÑÂ∞éÂ∏´Ôºå‰æùÊ≠§È°ûÊé®„ÄÇÁ©©ÂÆö„ÄÅË°®ÈÅîËÉΩÂäõÂº∑‰∏îÂÖ∑ÊúâÁµÑÂêàÊÄßÁöÑË™ûË®ÄÊúÉËá™ÁôºÂú∞Âá∫ÁèæÂú®Ë™ûË®ÄÂÇ≥ÈÅûÁì∂È†∏ÁöÑÂæåÊûú‰∏≠„ÄÇÂÖàÂâçÁöÑÊ®°ÂûãÂ∑≤‰ΩøÁî®‰∫∫Â∑•Á•ûÁ∂ìÁ∂≤Ë∑ØËß£Á¢ºÂô®ÂØ¶‰Ωú‰ª£ÁêÜÁ®ãÂºèÂæûË®äËôüÂà∞ÊÑèÁæ©ÁöÑÂ∞çÊáâÔºå‰ΩÜ‰æùË≥¥ÊñºÈùûÁèæÂØ¶‰∏îË®àÁÆóÊàêÊú¨ÊòÇË≤¥ÁöÑÈÄÜËΩâÈÅéÁ®ã‰æÜÂØ¶‰ΩúÈóúËÅØÁöÑÁ∑®Á¢ºÂô®ÔºåÂæûÊÑèÁæ©Â∞çÊáâÂà∞Ë®äËôü„ÄÇÂú®Ê≠§ÔºåÊèêÂá∫‰∏ÄÂÄãÊñ∞Ê®°ÂûãÔºåÂÖ∂‰∏≠Ëß£Á¢ºÂô®ÂíåÁ∑®Á¢ºÂô®ÈÉΩÊòØÁ•ûÁ∂ìÁ∂≤Ë∑ØÔºåÈÄèÈÅéÁõ£Áù£ÂºèÂ≠∏ÁøíÂàÜÂà•ÈÄ≤Ë°åË®ìÁ∑¥Ôºå‰∏¶ÈÄèÈÅéËá™Á∑®Á¢ºÂô®ÁöÑÂΩ¢Âºè‰ª•ÈùûÁõ£Áù£ÂºèÂ≠∏Áøí‰∏ÄËµ∑ÈÄ≤Ë°åË®ìÁ∑¥„ÄÇÈÄôÈÅøÂÖç‰∫ÜÈÄÜËΩâ‰∏≠ÊâÄÊ∂âÂèäÁöÑÈæêÂ§ßË®àÁÆóË≤†ÊìîÔºå‰∏¶ÂºïÂÖ•‰∫Ü‰∫∫È°ûÁôºÂ±ïÈÅéÁ®ã‰∏≠ËßÄÂØüÂà∞ÁöÑÁõ£Áù£ÂºèÂíåÈùûÁõ£Áù£ÂºèÂ≠∏ÁøíÁöÑÊ∑∑Âêà„ÄÇ

##### **There and Back Again: The AI Alignment Paradox**
2405.20806v1 by Robert West, Roland Aydin

The field of AI alignment aims to steer AI systems toward human goals,
preferences, and ethical principles. Its contributions have been instrumental
for improving the output quality, safety, and trustworthiness of today's AI
models. This perspective article draws attention to a fundamental challenge
inherent in all AI alignment endeavors, which we term the "AI alignment
paradox": The better we align AI models with our values, the easier we make it
for adversaries to misalign the models. We illustrate the paradox by sketching
three concrete example incarnations for the case of language models, each
corresponding to a distinct way in which adversaries can exploit the paradox.
With AI's increasing real-world impact, it is imperative that a broad community
of researchers be aware of the AI alignment paradox and work to find ways to
break out of it, in order to ensure the beneficial use of AI for the good of
humanity.

ÊëòË¶ÅÔºö‰∫∫Â∑•Êô∫ÊÖßÂ∞çÈΩäÈ†òÂüüÊó®Âú®ÂºïÂ∞é‰∫∫Â∑•Êô∫ÊÖßÁ≥ªÁµ±ÊúùÂêë‰∫∫È°ûÁöÑÁõÆÊ®ô„ÄÅÂÅèÂ•ΩÂíåÈÅìÂæ∑ÂéüÂâá„ÄÇÂÖ∂Ë≤¢ÁçªÂ∞çÊñºÊèêÂçáÁï∂‰ªä‰∫∫Â∑•Êô∫ÊÖßÊ®°ÂûãÁöÑËº∏Âá∫ÂìÅË≥™„ÄÅÂÆâÂÖ®ÊÄßËàáÂèØ‰ø°Â∫¶Ëá≥ÈóúÈáçË¶Å„ÄÇÈÄôÁØáËßÄÈªûÊñáÁ´†ÊèêÂà∞‰∫ÜÊâÄÊúâ‰∫∫Â∑•Êô∫ÊÖßÂ∞çÈΩäÂ∑•‰Ωú‰∏≠Âõ∫ÊúâÁöÑÂü∫Êú¨ÊåëÊà∞ÔºåÊàëÂÄëÁ®±‰πãÁÇ∫„Äå‰∫∫Â∑•Êô∫ÊÖßÂ∞çÈΩäÊÇñË´ñ„ÄçÔºöÊàëÂÄëÊÑàÊòØÂ∞á‰∫∫Â∑•Êô∫ÊÖßÊ®°ÂûãËàáÊàëÂÄëÁöÑÂÉπÂÄºËßÄÂ∞çÈΩäÔºåÂ∞çÊâãÂ∞±ÊÑàÂÆπÊòìÈåØÁΩÆÈÄô‰∫õÊ®°Âûã„ÄÇÊàëÂÄëÈÄèÈÅéÂãæÂãíÂá∫Ë™ûË®ÄÊ®°ÂûãÊ°à‰æãÁöÑ‰∏âÂÄãÂÖ∑È´îÁØÑ‰æãÂåñË∫´‰æÜË™™ÊòéÈÄôÂÄãÊÇñË´ñÔºåÊØèÂÄãÁØÑ‰æãÈÉΩÂ∞çÊáâÊñºÂ∞çÊâãÂèØ‰ª•Âà©Áî®ÊÇñË´ñÁöÑ‰∏çÂêåÊñπÂºè„ÄÇÈö®Ëëó‰∫∫Â∑•Êô∫ÊÖßÂú®ÁèæÂØ¶‰∏ñÁïå‰∏≠ÁöÑÂΩ±ÈüøÂäõËàáÊó•‰ø±Â¢ûÔºåÂª£Â§ßÁöÑÁ†îÁ©∂Á§æÁæ§ÂøÖÈ†àÊÑèË≠òÂà∞‰∫∫Â∑•Êô∫ÊÖßÂ∞çÈΩäÊÇñË´ñÔºå‰∏¶Âä™ÂäõÊâæÂá∫ÊñπÊ≥ï‰æÜÁ™ÅÁ†¥ÂÆÉÔºå‰ª•Á¢∫‰øù‰∫∫Â∑•Êô∫ÊÖßÁöÑÁõäËôïËÉΩÁî®Êñº‰∫∫È°ûÁ¶èÁ•â„ÄÇ

##### **Multilingual Text Style Transfer: Datasets & Models for Indian Languages**
2405.20805v1 by Sourabrata Mukherjee, Atul Kr. Ojha, Akanksha Bansal, Deepak Alok, John P. McCrae, Ond≈ôej Du≈°ek

Text style transfer (TST) involves altering the linguistic style of a text
while preserving its core content. This paper focuses on sentiment transfer, a
vital TST subtask (Mukherjee et al., 2022a), across a spectrum of Indian
languages: Hindi, Magahi, Malayalam, Marathi, Punjabi, Odia, Telugu, and Urdu,
expanding upon previous work on English-Bangla sentiment transfer (Mukherjee et
al., 2023). We introduce dedicated datasets of 1,000 positive and 1,000
negative style-parallel sentences for each of these eight languages. We then
evaluate the performance of various benchmark models categorized into parallel,
non-parallel, cross-lingual, and shared learning approaches, including the
Llama2 and GPT-3.5 large language models (LLMs). Our experiments highlight the
significance of parallel data in TST and demonstrate the effectiveness of the
Masked Style Filling (MSF) approach (Mukherjee et al., 2023) in non-parallel
techniques. Moreover, cross-lingual and joint multilingual learning methods
show promise, offering insights into selecting optimal models tailored to the
specific language and task requirements. To the best of our knowledge, this
work represents the first comprehensive exploration of the TST task as
sentiment transfer across a diverse set of languages.

ÊëòË¶ÅÔºöÊñáÊú¨È¢®Ê†ºËΩâÁßªÔºàTSTÔºâÊ∂âÂèäÊõ¥ÊîπÊñáÊú¨ÁöÑË™ûË®ÄÈ¢®Ê†ºÔºåÂêåÊôÇ‰øùÁïôÂÖ∂Ê†∏ÂøÉÂÖßÂÆπ„ÄÇÊú¨ÊñáÈáçÈªûÈóúÊ≥®ÊÉÖÁ∑íËΩâÁßªÔºåÈÄôÊòØ‰∏ÄÂÄãÈáçË¶ÅÁöÑ TST Â≠ê‰ªªÂãôÔºàMukherjee Á≠â‰∫∫Ôºå2022aÔºâÔºåÊ∂âÂèäÂç∞Âú∞Ë™û„ÄÅÈ¶¨Âä†Â∏åË™û„ÄÅÈ¶¨ÊãâÈõÖÊãâÂßÜË™û„ÄÅÈ¶¨ÊãâÂú∞Ë™û„ÄÅÊóÅÈÅÆÊôÆË™û„ÄÅÂ•ßÈáå‰∫ûË™û„ÄÅÊ≥∞ÁõßÂõ∫Ë™ûÂíåÁÉèÁàæÈÉΩË™ûÁ≠âÂç∞Â∫¶Ë™ûË®ÄÔºåÊì¥Â±ï‰∫ÜÂÖàÂâçÈóúÊñºËã±Ë™û-Â≠üÂä†ÊãâË™ûÊÉÖÁ∑íËΩâÁßªÔºàMukherjee Á≠â‰∫∫Ôºå2023ÔºâÁöÑÁ†îÁ©∂„ÄÇÊàëÂÄëÁÇ∫ÈÄôÂÖ´Á®ÆË™ûË®Ä‰∏≠ÁöÑÊØèÁ®ÆË™ûË®ÄÂºïÂÖ•‰∫Ü 1,000 ÂÄãÁ©çÊ•µÂíå 1,000 ÂÄãÊ∂àÊ•µÁöÑÈ¢®Ê†ºÂπ≥Ë°åÂè•Â≠êÁöÑÂ∞àÁî®Êï∏ÊìöÈõÜ„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëË©ï‰º∞‰∫ÜÂêÑÁ®ÆÂü∫Ê∫ñÊ®°ÂûãÁöÑÊÄßËÉΩÔºåÈÄô‰∫õÊ®°ÂûãÂàÜÁÇ∫Âπ≥Ë°å„ÄÅÈùûÂπ≥Ë°å„ÄÅË∑®Ë™ûË®ÄÂíåÂÖ±‰∫´Â≠∏ÁøíÊñπÊ≥ïÔºåÂåÖÊã¨ Llama2 Âíå GPT-3.5 Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM)„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÁ™ÅÂá∫‰∫ÜÂπ≥Ë°åÊï∏ÊìöÂú® TST ‰∏≠ÁöÑÈáçË¶ÅÊÄßÔºå‰∏¶Â±ïÁ§∫‰∫ÜÊé©Á¢ºÈ¢®Ê†ºÂ°´ÂÖÖ (MSF) ÊñπÊ≥ïÔºàMukherjee Á≠â‰∫∫Ôºå2023ÔºâÂú®ÈùûÂπ≥Ë°åÊäÄË°ì‰∏≠ÁöÑÊúâÊïàÊÄß„ÄÇÊ≠§Â§ñÔºåË∑®Ë™ûË®ÄÂíåËÅØÂêàÂ§öË™ûË®ÄÂ≠∏ÁøíÊñπÊ≥ïÈ°ØÁ§∫Âá∫ÂâçÊôØÔºåÊèê‰æõ‰∫ÜÈáùÂ∞çÁâπÂÆöË™ûË®ÄÂíå‰ªªÂãôË¶ÅÊ±ÇÈÅ∏ÊìáÊúÄ‰Ω≥Ê®°ÂûãÁöÑË¶ãËß£„ÄÇÊìöÊàëÂÄëÊâÄÁü•ÔºåÈÄôÈ†ÖÂ∑•‰Ωú‰ª£Ë°®‰∫ÜÈ¶ñÊ¨°Â∞ç TST ‰ªªÂãô‰ΩúÁÇ∫Ë∑®Â§öÁ®ÆË™ûË®ÄÁöÑÊÉÖÁ∑íËΩâÁßªÈÄ≤Ë°åÂÖ®Èù¢Êé¢Á¥¢„ÄÇ

##### **Ovis: Structural Embedding Alignment for Multimodal Large Language Model**
2405.20797v1 by Shiyin Lu, Yang Li, Qing-Guo Chen, Zhao Xu, Weihua Luo, Kaifu Zhang, Han-Jia Ye

Current Multimodal Large Language Models (MLLMs) typically integrate a
pre-trained LLM with another pre-trained vision transformer through a
connector, such as an MLP, endowing the LLM with visual capabilities. However,
the misalignment between two embedding strategies in MLLMs -- the structural
textual embeddings based on an embedding look-up table and the continuous
embeddings generated directly by the vision encoder -- makes challenges for a
more seamless fusion of visual and textual information. We propose Ovis, a
novel MLLM architecture designed to structurally align visual and textual
embeddings. Ovis integrates an additional learnable visual embedding table into
the visual encoder's process. To capture rich visual semantics, each image
patch indexes the visual embedding table multiple times, resulting in a final
visual embedding that is a probabilistic combination of the indexed embeddings.
This structural approach mirrors the method used for generating textual
embeddings. Empirical evaluations on various multimodal benchmarks demonstrate
that Ovis outperforms open-source MLLMs of similar parameter scales and even
surpasses the proprietary model Qwen-VL-Plus overall. These results highlight
the potential of Ovis' structured visual representation for advancing MLLM
architectural design and promoting more effective multimodal learning. Both the
source code and the training dataset of Ovis will be made publicly available.

ÊëòË¶ÅÔºöÁõÆÂâçÁöÑÂ§öÊ®°ÊÄÅÂ§ßÂûãËØ≠Ë®ÄÊ®°Âûã (MLLM) ÈÄöÂ∏∏ÈÄöËøáËøûÊé•Âô®Ôºà‰æãÂ¶Ç MLPÔºâÂ∞ÜÈ¢ÑÂÖàËÆ≠ÁªÉÁöÑ LLM ‰∏éÂè¶‰∏Ä‰∏™È¢ÑÂÖàËÆ≠ÁªÉÁöÑËßÜËßâËΩ¨Êç¢Âô®ÈõÜÊàêÂú®‰∏ÄËµ∑Ôºå‰ªéËÄåËµã‰∫à LLM ËßÜËßâÂäüËÉΩ„ÄÇÁÑ∂ËÄåÔºåMLLM ‰∏≠‰∏§ÁßçÂµåÂÖ•Á≠ñÁï•‰πãÈó¥ÁöÑÈîô‰Ωç‚Äî‚ÄîÂü∫‰∫éÂµåÂÖ•Êü•ÊâæË°®ÁöÑÁªìÊûÑÂåñÊñáÊú¨ÂµåÂÖ•ÂíåÁî±ËßÜËßâÁºñÁ†ÅÂô®Áõ¥Êé•ÁîüÊàêÁöÑËøûÁª≠ÂµåÂÖ•‚Äî‚ÄîÁªôËßÜËßâÂíåÊñáÊú¨‰ø°ÊÅØÁöÑÊõ¥Êó†ÁºùËûçÂêàÂ∏¶Êù•‰∫ÜÊåëÊàò„ÄÇÊàë‰ª¨ÊèêÂá∫‰∫Ü OvisÔºåËøôÊòØ‰∏ÄÁßçÊñ∞È¢ñÁöÑ MLLM Êû∂ÊûÑÔºåÊó®Âú®ÁªìÊûÑÂåñÂØπÈΩêËßÜËßâÂíåÊñáÊú¨ÂµåÂÖ•„ÄÇOvis Â∞Ü‰∏Ä‰∏™È¢ùÂ§ñÁöÑÂèØÂ≠¶‰π†ËßÜËßâÂµåÂÖ•Ë°®ÈõÜÊàêÂà∞ËßÜËßâÁºñÁ†ÅÂô®ÁöÑËøáÁ®ã‰∏≠„ÄÇ‰∏∫‰∫ÜÊçïËé∑‰∏∞ÂØåÁöÑËßÜËßâËØ≠‰πâÔºåÊØè‰∏™ÂõæÂÉèÂùóÈÉΩ‰ºöÂ§öÊ¨°Á¥¢ÂºïËßÜËßâÂµåÂÖ•Ë°®Ôºå‰ªéËÄåÁîüÊàê‰∏Ä‰∏™ÊúÄÁªàÁöÑËßÜËßâÂµåÂÖ•ÔºåËØ•ÂµåÂÖ•ÊòØÂ∑≤Á¥¢ÂºïÂµåÂÖ•ÁöÑÊ¶ÇÁéáÁªÑÂêà„ÄÇËøôÁßçÁªìÊûÑÂåñÊñπÊ≥ïÂèçÊò†‰∫ÜÁî®‰∫éÁîüÊàêÊñáÊú¨ÂµåÂÖ•ÁöÑÊñπÊ≥ï„ÄÇÂú®ÂêÑÁßçÂ§öÊ®°ÊÄÅÂü∫ÂáÜ‰∏äÁöÑÁªèÈ™åËØÑ‰º∞Ë°®ÊòéÔºåOvis ‰ºò‰∫éÂÖ∑ÊúâÁõ∏‰ººÂèÇÊï∞ËßÑÊ®°ÁöÑÂºÄÊ∫ê MLLMÔºåÁîöËá≥Âú®ÊÄª‰Ωì‰∏äË∂ÖË∂ä‰∫Ü‰∏ìÊúâÊ®°Âûã Qwen-VL-Plus„ÄÇËøô‰∫õÁªìÊûúÁ™ÅÂá∫‰∫Ü Ovis ÁöÑÁªìÊûÑÂåñËßÜËßâË°®Á§∫Âú®Êé®Ëøõ MLLM Êû∂ÊûÑËÆæËÆ°Âíå‰øÉËøõÊõ¥ÊúâÊïàÁöÑÂ§öÊ®°ÊÄÅÂ≠¶‰π†ÊñπÈù¢ÁöÑÊΩúÂäõ„ÄÇOvis ÁöÑÊ∫ê‰ª£Á†ÅÂíåËÆ≠ÁªÉÊï∞ÊçÆÈõÜÈÉΩÂ∞ÜÂÖ¨ÂºÄ„ÄÇ

##### **InsightSee: Advancing Multi-agent Vision-Language Models for Enhanced Visual Understanding**
2405.20795v1 by Huaxiang Zhang, Yaojia Mu, Guo-Niu Zhu, Zhongxue Gan

Accurate visual understanding is imperative for advancing autonomous systems
and intelligent robots. Despite the powerful capabilities of vision-language
models (VLMs) in processing complex visual scenes, precisely recognizing
obscured or ambiguously presented visual elements remains challenging. To
tackle such issues, this paper proposes InsightSee, a multi-agent framework to
enhance VLMs' interpretative capabilities in handling complex visual
understanding scenarios. The framework comprises a description agent, two
reasoning agents, and a decision agent, which are integrated to refine the
process of visual information interpretation. The design of these agents and
the mechanisms by which they can be enhanced in visual information processing
are presented. Experimental results demonstrate that the InsightSee framework
not only boosts performance on specific visual tasks but also retains the
original models' strength. The proposed framework outperforms state-of-the-art
algorithms in 6 out of 9 benchmark tests, with a substantial advancement in
multimodal understanding.

ÊëòË¶ÅÔºöÊ∫ñÁ¢∫ÁöÑË¶ñË¶∫ÁêÜËß£Â∞çÊñºÊé®ÈÄ≤Ëá™‰∏ªÁ≥ªÁµ±ÂíåÊô∫ÊÖßÊ©üÂô®‰∫∫Ëá≥ÈóúÈáçË¶Å„ÄÇÂÑòÁÆ°Ë¶ñË¶∫Ë™ûË®ÄÊ®°Âûã (VLM) Âú®ËôïÁêÜË§áÈõúË¶ñË¶∫Â†¥ÊôØÊñπÈù¢ÂÖ∑ÊúâÂº∑Â§ßÁöÑËÉΩÂäõÔºå‰ΩÜÁ≤æÁ¢∫Ë≠òÂà•Ê®°Á≥äÊàñÂê´Á≥äÂëàÁèæÁöÑË¶ñË¶∫ÂÖÉÁ¥†‰ªçÁÑ∂ÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÂïèÈ°åÔºåÊú¨ÊñáÊèêÂá∫‰∫Ü InsightSeeÔºå‰∏ÄÂÄãÂ§ö‰ª£ÁêÜÊû∂ÊßãÔºå‰ª•Â¢ûÂº∑ VLM Âú®ËôïÁêÜË§áÈõúË¶ñË¶∫ÁêÜËß£Â†¥ÊôØÊñπÈù¢ÁöÑËß£ÈáãËÉΩÂäõ„ÄÇË©≤Êû∂ÊßãÂåÖÂê´‰∏ÄÂÄãÊèèËø∞‰ª£ÁêÜ„ÄÅÂÖ©ÂÄãÊé®ÁêÜ‰ª£ÁêÜÂíå‰∏ÄÂÄãÊ±∫Á≠ñ‰ª£ÁêÜÔºåÈÄô‰∫õ‰ª£ÁêÜË¢´Êï¥ÂêàËµ∑‰æÜ‰ª•ÂÑ™ÂåñË¶ñË¶∫Ë≥áË®äËß£ÈáãÁöÑÈÅéÁ®ã„ÄÇÈÄô‰∫õ‰ª£ÁêÜÁöÑË®≠Ë®à‰ª•ÂèäÂÆÉÂÄëÂú®Ë¶ñË¶∫Ë≥áË®äËôïÁêÜ‰∏≠ÂèØ‰ª•Â¢ûÂº∑ÁöÑÊ©üÂà∂ÈÉΩÂ∑≤ÊèêÂá∫„ÄÇÂØ¶È©óÁµêÊûúË°®ÊòéÔºåInsightSee Ê°ÜÊû∂‰∏çÂÉÖÊèêÂçá‰∫ÜÁâπÂÆöË¶ñË¶∫‰ªªÂãôÁöÑÊïàËÉΩÔºåËÄå‰∏îÈÇÑ‰øùÁïô‰∫ÜÂéüÂßãÊ®°ÂûãÁöÑÂÑ™Âã¢„ÄÇÊâÄÊèêÂá∫ÁöÑÊ°ÜÊû∂Âú® 9 È†ÖÂü∫Ê∫ñÊ∏¨Ë©¶‰∏≠ÁöÑ 6 È†Ö‰∏≠ÂÑ™ÊñºÊúÄÂÖàÈÄ≤ÁöÑÊºîÁÆóÊ≥ïÔºåÂú®Â§öÊ®°ÊÖãÁêÜËß£ÊñπÈù¢ÂèñÂæó‰∫ÜÈ°ØËëóÈÄ≤Â±ï„ÄÇ

##### **Improving code-mixed hate detection by native sample mixing: A case study for Hindi-English code-mixed scenario**
2405.20755v1 by Debajyoti Mazumder, Aakash Kumar, Jasabanta Patro

Hate detection has long been a challenging task for the NLP community. The
task becomes complex in a code-mixed environment because the models must
understand the context and the hate expressed through language alteration.
Compared to the monolingual setup, we see very less work on code-mixed hate as
large-scale annotated hate corpora are unavailable to make the study. To
overcome this bottleneck, we propose using native language hate samples. We
hypothesise that in the era of multilingual language models (MLMs), hate in
code-mixed settings can be detected by majorly relying on the native language
samples. Even though the NLP literature reports the effectiveness of MLMs on
hate detection in many cross-lingual settings, their extensive evaluation in a
code-mixed scenario is yet to be done. This paper attempts to fill this gap
through rigorous empirical experiments. We considered the Hindi-English
code-mixed setup as a case study as we have the linguistic expertise for the
same. Some of the interesting observations we got are: (i) adding native hate
samples in the code-mixed training set, even in small quantity, improved the
performance of MLMs for code-mixed hate detection, (ii) MLMs trained with
native samples alone observed to be detecting code-mixed hate to a large
extent, (iii) The visualisation of attention scores revealed that, when native
samples were included in training, MLMs could better focus on the hate emitting
words in the code-mixed context, and (iv) finally, when hate is subjective or
sarcastic, naively mixing native samples doesn't help much to detect code-mixed
hate. We will release the data and code repository to reproduce the reported
results.

ÊëòË¶ÅÔºö<paragraph>‰ªáÊÅ®ÂÅµÊ∏¨‰∏ÄÁõ¥ÊòØËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜÁ§æÁæ§ÁöÑÊåëÊà∞ÊÄß‰ªªÂãô„ÄÇÊ≠§‰ªªÂãôÂú®‰ª£Á¢ºÊ∑∑ÂêàÁí∞Â¢É‰∏≠ËÆäÂæóË§áÈõúÔºåÂõ†ÁÇ∫Ê®°ÂûãÂøÖÈ†àÁêÜËß£‰∏ä‰∏ãÊñáÂíåÈÄèÈÅéË™ûË®ÄËÆäÊõ¥Ë°®ÈÅîÁöÑ‰ªáÊÅ®„ÄÇËàáÂñÆ‰∏ÄË™ûË®ÄË®≠ÂÆöÁõ∏ÊØîÔºåÊàëÂÄëÁúãÂà∞‰ª£Á¢ºÊ∑∑Âêà‰ªáÊÅ®ÁöÑÁ†îÁ©∂ÈùûÂ∏∏Â∞ëÔºåÂõ†ÁÇ∫Ê≤íÊúâÂèØÁî®ÁöÑÂ§ßÂûãÊ®ôË®ª‰ªáÊÅ®Ë™ûÊñôÂ∫´ÈÄ≤Ë°åÁ†îÁ©∂„ÄÇÁÇ∫‰∫ÜÂÖãÊúçÈÄôÂÄãÁì∂È†∏ÔºåÊàëÂÄëÂª∫Ë≠∞‰ΩøÁî®ÊØçË™û‰ªáÊÅ®ÁØÑ‰æã„ÄÇÊàëÂÄëÂÅáË®≠Âú®Â§öË™ûË®ÄË™ûË®ÄÊ®°Âûã (MLM) ÊôÇ‰ª£Ôºå‰ª£Á¢ºÊ∑∑ÂêàÁí∞Â¢É‰∏≠ÁöÑ‰ªáÊÅ®ÂèØ‰ª•‰∏ªË¶ÅÈÄèÈÅé‰æùË≥¥ÊØçË™ûÁØÑ‰æã‰æÜÂÅµÊ∏¨„ÄÇÂÑòÁÆ°Ëá™ÁÑ∂Ë™ûË®ÄËôïÁêÜÊñáÁçªÂ†±Âëä‰∫Ü MLM Âú®Ë®±Â§öË∑®Ë™ûË®ÄÁí∞Â¢É‰∏≠‰ªáÊÅ®ÂÅµÊ∏¨ÁöÑÊúâÊïàÊÄßÔºå‰ΩÜÂÆÉÂÄëÂú®‰ª£Á¢ºÊ∑∑ÂêàÂ†¥ÊôØ‰∏≠ÁöÑÂª£Ê≥õË©ï‰º∞Â∞öÊú™ÂÆåÊàê„ÄÇÊú¨ÊñáÂòóË©¶ÈÄèÈÅéÂö¥Ë¨πÁöÑÂØ¶Ë≠âÂØ¶È©ó‰æÜÂ°´Ë£úÈÄôÂÄãÁ©∫ÁôΩ„ÄÇÊàëÂÄëÂ∞áÂç∞Âú∞Ë™û-Ëã±Ë™û‰ª£Á¢ºÊ∑∑ÂêàË®≠ÂÆöË¶ñÁÇ∫Ê°à‰æãÁ†îÁ©∂ÔºåÂõ†ÁÇ∫ÊàëÂÄëÊìÅÊúâÁõ∏ÂêåÁöÑË™ûË®ÄÂ∞àÊ•≠Áü•Ë≠ò„ÄÇÊàëÂÄëÂæóÂà∞ÁöÑ‰∏Ä‰∫õÊúâË∂£ÁöÑËßÄÂØüÁµêÊûúÔºö(i) Âú®‰ª£Á¢ºÊ∑∑ÂêàË®ìÁ∑¥ÈõÜ‰∏≠Âä†ÂÖ•ÊØçË™û‰ªáÊÅ®ÁØÑ‰æãÔºåÂç≥‰ΩøÊï∏ÈáèÂæàÂ∞ëÔºå‰πüËÉΩÊîπÂñÑ MLM Â∞ç‰ª£Á¢ºÊ∑∑Âêà‰ªáÊÅ®ÂÅµÊ∏¨ÁöÑÊïàËÉΩÔºå(ii) ÂñÆÁç®‰ΩøÁî®ÊØçË™ûÁØÑ‰æãË®ìÁ∑¥ÁöÑ MLM ËßÄÂØüÂà∞Âú®ÂæàÂ§ßÁ®ãÂ∫¶‰∏äÂÅµÊ∏¨Âà∞‰ª£Á¢ºÊ∑∑Âêà‰ªáÊÅ®Ôºå(iii) Ê≥®ÊÑèÂäõÂàÜÊï∏ÁöÑÂèØË¶ñÂåñÈ°ØÁ§∫ÔºåÁï∂Ë®ìÁ∑¥‰∏≠ÂåÖÂê´ÊØçË™ûÁØÑ‰æãÊôÇÔºåMLM ÂèØ‰ª•Êõ¥Â•ΩÂú∞ÈóúÊ≥®‰ª£Á¢ºÊ∑∑Âêà‰∏ä‰∏ãÊñá‰∏≠Êï£Áôº‰ªáÊÅ®ÁöÑÂ≠óË©ûÔºå(iv) ÊúÄÂæåÔºåÁï∂‰ªáÊÅ®ÊòØ‰∏ªËßÄÊàñË´∑Âà∫ÊôÇÔºåÂ§©ÁúüÂú∞Ê∑∑ÂêàÊØçË™ûÁØÑ‰æãÂ∞çÂÅµÊ∏¨‰ª£Á¢ºÊ∑∑Âêà‰ªáÊÅ®Ê≤íÊúâÂ§™Â§ßÂπ´Âä©„ÄÇÊàëÂÄëÂ∞áÈáãÂá∫Ë≥áÊñôÂíåÁ®ãÂºèÁ¢ºÂÑ≤Â≠òÂ∫´Ôºå‰ª•ÈáçÁèæÂ†±ÂëäÁöÑÁµêÊûú„ÄÇ</paragraph>

##### **Trajectory Forecasting through Low-Rank Adaptation of Discrete Latent Codes**
2405.20743v1 by Riccardo Benaglia, Angelo Porrello, Pietro Buzzega, Simone Calderara, Rita Cucchiara

Trajectory forecasting is crucial for video surveillance analytics, as it
enables the anticipation of future movements for a set of agents, e.g.
basketball players engaged in intricate interactions with long-term intentions.
Deep generative models offer a natural learning approach for trajectory
forecasting, yet they encounter difficulties in achieving an optimal balance
between sampling fidelity and diversity. We address this challenge by
leveraging Vector Quantized Variational Autoencoders (VQ-VAEs), which utilize a
discrete latent space to tackle the issue of posterior collapse. Specifically,
we introduce an instance-based codebook that allows tailored latent
representations for each example. In a nutshell, the rows of the codebook are
dynamically adjusted to reflect contextual information (i.e., past motion
patterns extracted from the observed trajectories). In this way, the
discretization process gains flexibility, leading to improved reconstructions.
Notably, instance-level dynamics are injected into the codebook through
low-rank updates, which restrict the customization of the codebook to a lower
dimension space. The resulting discrete space serves as the basis of the
subsequent step, which regards the training of a diffusion-based predictive
model. We show that such a two-fold framework, augmented with instance-level
discretization, leads to accurate and diverse forecasts, yielding
state-of-the-art performance on three established benchmarks.

ÊëòË¶ÅÔºöËªåË∑°È†êÊ∏¨Â∞çÊñºÂΩ±ÁâáÁõ£ÊéßÂàÜÊûêËá≥ÈóúÈáçË¶ÅÔºåÂõ†ÁÇ∫ÂÆÉËÉΩÈ†êÊ∏¨‰∏ÄÁµÑ‰ª£ÁêÜ‰∫∫ÁöÑÊú™‰æÜÁßªÂãïÔºå‰æãÂ¶ÇÂèÉËàáË§áÈõú‰∫íÂãï‰∏îÂÖ∑ÊúâÈï∑ÊúüÊÑèÂúñÁöÑÁ±ÉÁêÉÂì°„ÄÇÊ∑±Â∫¶ÁîüÊàêÊ®°ÂûãÊèê‰æõ‰∫Ü‰∏ÄÁ®ÆËá™ÁÑ∂Â≠∏ÁøíÊñπÊ≥ï‰æÜÈÄ≤Ë°åËªåË∑°È†êÊ∏¨Ôºå‰ΩÜÂÆÉÂÄëÂú®ÈÅîÊàêÂèñÊ®£‰øùÁúüÂ∫¶ÂíåÂ§öÊ®£ÊÄß‰πãÈñìÁöÑÊúÄ‰Ω≥Âπ≥Ë°°ÊôÇÊúÉÈÅáÂà∞Âõ∞Èõ£„ÄÇÊàëÂÄëÈÄèÈÅéÂà©Áî®ÂêëÈáèÈáèÂåñËÆäÁï∞Ëá™ÂãïÁ∑®Á¢ºÂô® (VQ-VAE) ‰æÜÊáâÂ∞çÈÄôÈ†ÖÊåëÊà∞ÔºåÂÆÉ‰ΩøÁî®Èõ¢Êï£ÊΩõÂú®Á©∫Èñì‰æÜËß£Ê±∫ÂæåÈ©óÂ¥©ÊΩ∞ÂïèÈ°å„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÂü∫ÊñºÂØ¶‰æãÁöÑÁ¢ºÊú¨ÔºåÂÖÅË®±ÁÇ∫ÊØèÂÄãÁØÑ‰æãÈáèË∫´ÊâìÈÄ†ÊΩõÂú®Ë°®Á§∫„ÄÇÁ∞°ËÄåË®Ä‰πãÔºåÁ¢ºÊú¨ÁöÑË°åÊúÉÂãïÊÖãË™øÊï¥‰ª•ÂèçÊò†‰∏ä‰∏ãÊñáË≥áË®äÔºàÂç≥ÂæûËßÄÂØüÂà∞ÁöÑËªåË∑°‰∏≠ÊèêÂèñÁöÑÈÅéÂéªÈÅãÂãïÊ®°ÂºèÔºâ„ÄÇÈÄèÈÅéÈÄôÁ®ÆÊñπÂºèÔºåÈõ¢Êï£ÂåñÈÅéÁ®ãÊúÉÁç≤ÂæóÈùàÊ¥ªÊÄßÔºåÈÄ≤ËÄåÊîπÂñÑÈáçÂª∫„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÂØ¶‰æãÁ¥öÂãïÊÖãÊúÉÈÄèÈÅé‰ΩéÁß©Êõ¥Êñ∞Ê≥®ÂÖ•Á¢ºÊú¨ÔºåÈÄôÊúÉÂ∞áÁ¢ºÊú¨ÁöÑÂÆ¢Ë£ΩÂåñÈôêÂà∂Âú®ËºÉ‰ΩéÁ∂≠Â∫¶ÁöÑÁ©∫Èñì„ÄÇÁî¢ÁîüÁöÑÈõ¢Êï£Á©∫Èñì‰ΩúÁÇ∫ÂæåÁ∫åÊ≠•È©üÁöÑÂü∫Á§éÔºåË©≤Ê≠•È©üÊ∂âÂèäË®ìÁ∑¥Âü∫ÊñºÊì¥Êï£ÁöÑÈ†êÊ∏¨Ê®°Âûã„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫ÜÈÄôÁ®ÆÈõôÈáçÊû∂ÊßãÔºàÂä†‰∏äÂØ¶‰æãÁ¥öÈõ¢Êï£ÂåñÔºâÊúÉÁî¢ÁîüÊ∫ñÁ¢∫‰∏îÂ§öÊ®£ÂåñÁöÑÈ†êÊ∏¨ÔºåÂú®‰∏âÂÄãÊó¢ÂÆöÁöÑÂü∫Ê∫ñ‰∏äÁî¢ÁîüÊúÄÂÖàÈÄ≤ÁöÑÊïàËÉΩ„ÄÇ

##### **Maximum Temperature Prediction Using Remote Sensing Data Via Convolutional Neural Network**
2405.20731v1 by Lorenzo Innocenti, Giacomo Blanco, Luca Barco, Claudio Rossi

Urban heat islands, defined as specific zones exhibiting substantially higher
temperatures than their immediate environs, pose significant threats to
environmental sustainability and public health. This study introduces a novel
machine-learning model that amalgamates data from the Sentinel-3 satellite,
meteorological predictions, and additional remote sensing inputs. The primary
aim is to generate detailed spatiotemporal maps that forecast the peak
temperatures within a 24-hour period in Turin. Experimental results validate
the model's proficiency in predicting temperature patterns, achieving a Mean
Absolute Error (MAE) of 2.09 degrees Celsius for the year 2023 at a resolution
of 20 meters per pixel, thereby enriching our knowledge of urban climatic
behavior. This investigation enhances the understanding of urban microclimates,
emphasizing the importance of cross-disciplinary data integration, and laying
the groundwork for informed policy-making aimed at alleviating the negative
impacts of extreme urban temperatures.

ÊëòË¶ÅÔºöÈÉΩÂ∏ÇÁÜ±Â≥∂ÊïàÊáâÊòØÊåáÁâπÂÆöÂçÄÂüüÁöÑÊ∫´Â∫¶ÊòéÈ°ØÈ´òÊñºÂë®ÂúçÁí∞Â¢ÉÔºåÂ∞çÁí∞Â¢ÉÊ∞∏Á∫åÊÄßËàáÂÖ¨ÂÖ±ÂÅ•Â∫∑ÈÄ†ÊàêÈáçÂ§ßÂ®ÅËÑÖ„ÄÇÊú¨Á†îÁ©∂ÊèêÂá∫‰∏ÄÂÄãÂâµÊñ∞ÁöÑÊ©üÂô®Â≠∏ÁøíÊ®°ÂûãÔºåÁµêÂêà Sentinel-3 Ë°õÊòü„ÄÅÊ∞£Ë±°È†êÊ∏¨ÂíåÈ°çÂ§ñÈÅôÊ∏¨Ëº∏ÂÖ•ÁöÑË≥áÊñô„ÄÇ‰∏ªË¶ÅÁõÆÁöÑÊòØÁî¢ÁîüË©≥Á¥∞ÁöÑÊôÇÁ©∫Âú∞ÂúñÔºåÈ†êÊ∏¨ÈÉΩÈùà 24 Â∞èÊôÇÂÖßÁöÑÊúÄÈ´òÊ∫´Â∫¶„ÄÇÂØ¶È©óÁµêÊûúÈ©óË≠â‰∫ÜÊ®°ÂûãÂú®È†êÊ∏¨Ê∫´Â∫¶Ê®°ÂºèÊñπÈù¢ÁöÑÁÜüÁ∑¥Â∫¶ÔºåÂú® 2023 Âπ¥‰ª•ÊØèÂÉèÁ¥† 20 ÂÖ¨Â∞∫Ëß£ÊûêÂ∫¶ÈÅîÂà∞ 2.09 Â∫¶ÊîùÊ∞èÁöÑÂπ≥ÂùáÁµïÂ∞çË™§Â∑Æ (MAE)ÔºåÂæûËÄåË±êÂØå‰∫ÜÊàëÂÄëÂ∞çÈÉΩÂ∏ÇÊ∞£ÂÄôË°åÁÇ∫ÁöÑË™çË≠ò„ÄÇÊ≠§Á†îÁ©∂Â¢ûÂº∑‰∫ÜÂ∞çÈÉΩÂ∏ÇÂæÆÊ∞£ÂÄôÁöÑ‰∫ÜËß£ÔºåÂº∑Ë™øË∑®È†òÂüüË≥áÊñôÊï¥ÂêàÁöÑÈáçË¶ÅÊÄßÔºå‰∏¶ÁÇ∫Êó®Âú®Ê∏õËºïÊ•µÁ´ØÈÉΩÂ∏ÇÊ∫´Â∫¶Ë≤†Èù¢ÂΩ±ÈüøÁöÑÊòéÊô∫ÊîøÁ≠ñÂà∂ÂÆöÂ•†ÂÆöÂü∫Á§é„ÄÇ

##### **GANcrop: A Contrastive Defense Against Backdoor Attacks in Federated Learning**
2405.20727v1 by Xiaoyun Gan, Shanyu Gan, Taizhi Su, Peng Liu

With heightened awareness of data privacy protection, Federated Learning (FL)
has attracted widespread attention as a privacy-preserving distributed machine
learning method. However, the distributed nature of federated learning also
provides opportunities for backdoor attacks, where attackers can guide the
model to produce incorrect predictions without affecting the global model
training process.
  This paper introduces a novel defense mechanism against backdoor attacks in
federated learning, named GANcrop. This approach leverages contrastive learning
to deeply explore the disparities between malicious and benign models for
attack identification, followed by the utilization of Generative Adversarial
Networks (GAN) to recover backdoor triggers and implement targeted mitigation
strategies. Experimental findings demonstrate that GANcrop effectively
safeguards against backdoor attacks, particularly in non-IID scenarios, while
maintaining satisfactory model accuracy, showcasing its remarkable defensive
efficacy and practical utility.

ÊëòË¶ÅÔºöÈö®ËëóË≥áÊñôÈö±ÁßÅ‰øùË≠∑ÊÑèË≠òÁöÑÊèêÂçáÔºåËÅØÈÇ¶Â≠∏Áøí (FL) ‰ΩúÁÇ∫‰∏ÄÁ®Æ‰øùË≠∑Èö±ÁßÅÁöÑÂàÜÂ∏ÉÂºèÊ©üÂô®Â≠∏ÁøíÊñπÊ≥ïÔºåÂºïËµ∑‰∫ÜÂª£Ê≥õÈóúÊ≥®„ÄÇÁÑ∂ËÄåÔºåËÅØÈÇ¶Â≠∏ÁøíÁöÑÂàÜÂ∏ÉÂºèÁâπÊÄß‰πüÁÇ∫ÂæåÈñÄÊîªÊìäÊèê‰æõ‰∫ÜÊ©üÊúÉÔºåÊîªÊìäËÄÖÂèØ‰ª•Ë™òÂ∞éÊ®°ÂûãÁî¢Áîü‰∏çÊ≠£Á¢∫ÁöÑÈ†êÊ∏¨ÔºåËÄå‰∏çÊúÉÂΩ±ÈüøÂÖ®Â±ÄÊ®°ÂûãË®ìÁ∑¥ÈÅéÁ®ã„ÄÇÊú¨Êñá‰ªãÁ¥π‰∫Ü‰∏ÄÁ®ÆÈáùÂ∞çËÅØÈÇ¶Â≠∏Áøí‰∏≠ÂæåÈñÄÊîªÊìäÁöÑÊñ∞ÂûãÈò≤Á¶¶Ê©üÂà∂ÔºåÂêçÁÇ∫ GANcrop„ÄÇÊ≠§ÊñπÊ≥ïÂà©Áî®Â∞çÊØîÂ≠∏ÁøíÊ∑±ÂÖ•Êé¢Á¥¢ÊÉ°ÊÑèÊ®°ÂûãÂíåËâØÊÄßÊ®°Âûã‰πãÈñìÁöÑÂ∑ÆÁï∞Ôºå‰ª•ÈÄ≤Ë°åÊîªÊìäË≠òÂà•ÔºåÁÑ∂ÂæåÂà©Áî®ÁîüÊàêÂ∞çÊäóÁ∂≤Ë∑Ø (GAN) ‰æÜÊÅ¢Âæ©ÂæåÈñÄËß∏ÁôºÂô®‰∏¶ÂØ¶ÊñΩÊúâÈáùÂ∞çÊÄßÁöÑÁ∑©Ëß£Á≠ñÁï•„ÄÇÂØ¶È©óÁµêÊûúË°®ÊòéÔºåGANcrop ÊúâÊïàÂú∞Èò≤Á¶¶‰∫ÜÂæåÈñÄÊîªÊìäÔºåÁâπÂà•ÊòØÂú®Èùû IID Â†¥ÊôØ‰∏≠ÔºåÂêåÊôÇ‰øùÊåÅ‰∫Ü‰ª§‰∫∫ÊªøÊÑèÁöÑÊ®°ÂûãÊ∫ñÁ¢∫Â∫¶ÔºåÂ±ïÁ§∫‰∫ÜÂÖ∂ÂçìË∂äÁöÑÈò≤Á¶¶ÊïàËÉΩÂíåÂØ¶Áî®ÊÄß„ÄÇ

##### **GI-NAS: Boosting Gradient Inversion Attacks through Adaptive Neural Architecture Search**
2405.20725v1 by Wenbo Yu, Hao Fang, Bin Chen, Xiaohang Sui, Chuan Chen, Hao Wu, Shu-Tao Xia, Ke Xu

Gradient Inversion Attacks invert the transmitted gradients in Federated
Learning (FL) systems to reconstruct the sensitive data of local clients and
have raised considerable privacy concerns. A majority of gradient inversion
methods rely heavily on explicit prior knowledge (e.g., a well pre-trained
generative model), which is often unavailable in realistic scenarios. To
alleviate this issue, researchers have proposed to leverage the implicit prior
knowledge of an over-parameterized network. However, they only utilize a fixed
neural architecture for all the attack settings. This would hinder the adaptive
use of implicit architectural priors and consequently limit the
generalizability. In this paper, we further exploit such implicit prior
knowledge by proposing Gradient Inversion via Neural Architecture Search
(GI-NAS), which adaptively searches the network and captures the implicit
priors behind neural architectures. Extensive experiments verify that our
proposed GI-NAS can achieve superior attack performance compared to
state-of-the-art gradient inversion methods, even under more practical settings
with high-resolution images, large-sized batches, and advanced defense
strategies.

ÊëòË¶ÅÔºöÊ¢ØÂ∫¶ÂèçÊºîÊîªÂáªÂèçËΩ¨‰∫ÜËÅîÈÇ¶Â≠¶‰π† (FL) Á≥ªÁªü‰∏≠‰º†ËæìÁöÑÊ¢ØÂ∫¶Ôºå‰ª•ÈáçÂª∫Êú¨Âú∞ÂÆ¢Êà∑Á´ØÁöÑÊïèÊÑüÊï∞ÊçÆÔºåÂπ∂ÂºïÂèë‰∫ÜÁõ∏ÂΩìÂ§ßÁöÑÈöêÁßÅÈóÆÈ¢ò„ÄÇÂ§ßÂ§öÊï∞Ê¢ØÂ∫¶ÂèçÊºîÊñπÊ≥ï‰∏•Èáç‰æùËµñ‰∫éÊòéÁ°ÆÁöÑÂÖàÈ™åÁü•ËØÜÔºà‰æãÂ¶ÇÔºåÁªèËøáËâØÂ•ΩÈ¢ÑËÆ≠ÁªÉÁöÑÁîüÊàêÊ®°ÂûãÔºâÔºåËÄåÂú®ÂÆûÈôÖÂú∫ÊôØ‰∏≠ÈÄöÂ∏∏Êó†Ê≥ïËé∑Âæó„ÄÇ‰∏∫‰∫ÜÁºìËß£Ëøô‰∏™ÈóÆÈ¢òÔºåÁ†îÁ©∂‰∫∫ÂëòÊèêÂá∫Âà©Áî®ËøáÂèÇÊï∞ÂåñÁΩëÁªúÁöÑÈöêÂºèÂÖàÈ™åÁü•ËØÜ„ÄÇÁÑ∂ËÄåÔºå‰ªñ‰ª¨Âè™‰∏∫ÊâÄÊúâÊîªÂáªËÆæÁΩÆÂà©Áî®‰∫Ü‰∏Ä‰∏™Âõ∫ÂÆöÁöÑÁ•ûÁªèÊû∂ÊûÑ„ÄÇËøô‰ºöÈòªÁ¢çÈöêÂºèÊû∂ÊûÑÂÖàÈ™åÁöÑËá™ÈÄÇÂ∫î‰ΩøÁî®ÔºåÂπ∂Âõ†Ê≠§ÈôêÂà∂Ê≥õÂåñÊÄß„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨ÈÄöËøáÊèêÂá∫Á•ûÁªèÊû∂ÊûÑÊêúÁ¥¢ (GI-NAS) ‰∏≠ÁöÑÊ¢ØÂ∫¶ÂèçÊºîËøõ‰∏ÄÊ≠•Âà©Áî®Ê≠§Á±ªÈöêÂºèÂÖàÈ™åÁü•ËØÜÔºåËØ•Áü•ËØÜËá™ÈÄÇÂ∫îÂú∞ÊêúÁ¥¢ÁΩëÁªúÂπ∂ÊçïËé∑Á•ûÁªèÊû∂ÊûÑËÉåÂêéÁöÑÈöêÂºèÂÖàÈ™å„ÄÇÂ§ßÈáèÁöÑÂÆûÈ™åÈ™åËØÅ‰∫ÜÔºå‰∏éÊúÄÂÖàËøõÁöÑÊ¢ØÂ∫¶ÂèçÊºîÊñπÊ≥ïÁõ∏ÊØîÔºåÊàë‰ª¨ÊèêÂá∫ÁöÑ GI-NAS ÂèØ‰ª•Âú®Êõ¥ÂÆûÈôÖÁöÑÈ´òÂàÜËæ®ÁéáÂõæÂÉè„ÄÅÂ§ßËßÑÊ®°ÊâπÂ§ÑÁêÜÂíåÈ´òÁ∫ßÈò≤Âæ°Á≠ñÁï•ËÆæÁΩÆ‰∏ãÂÆûÁé∞ÂçìË∂äÁöÑÊîªÂáªÊÄßËÉΩ„ÄÇ

##### **ContextGS: Compact 3D Gaussian Splatting with Anchor Level Context Model**
2405.20721v1 by Yufei Wang, Zhihao Li, Lanqing Guo, Wenhan Yang, Alex C. Kot, Bihan Wen

Recently, 3D Gaussian Splatting (3DGS) has become a promising framework for
novel view synthesis, offering fast rendering speeds and high fidelity.
However, the large number of Gaussians and their associated attributes require
effective compression techniques. Existing methods primarily compress neural
Gaussians individually and independently, i.e., coding all the neural Gaussians
at the same time, with little design for their interactions and spatial
dependence. Inspired by the effectiveness of the context model in image
compression, we propose the first autoregressive model at the anchor level for
3DGS compression in this work. We divide anchors into different levels and the
anchors that are not coded yet can be predicted based on the already coded ones
in all the coarser levels, leading to more accurate modeling and higher coding
efficiency. To further improve the efficiency of entropy coding, e.g., to code
the coarsest level with no already coded anchors, we propose to introduce a
low-dimensional quantized feature as the hyperprior for each anchor, which can
be effectively compressed. Our work pioneers the context model in the anchor
level for 3DGS representation, yielding an impressive size reduction of over
100 times compared to vanilla 3DGS and 15 times compared to the most recent
state-of-the-art work Scaffold-GS, while achieving comparable or even higher
rendering quality.

ÊëòË¶ÅÔºö<paragraph>ÊúÄËøëÔºå3D È´òÊñØÊï£Â∏ÉÔºà3DGSÔºâÂ∑≤Êàê‰∏∫Êñ∞ËßÜÂõæÂêàÊàêÁöÑ‰∏Ä‰∏™ÊúâÂâçÈÄîÁöÑÊ°ÜÊû∂ÔºåÂÆÉÊèê‰æõ‰∫ÜÂø´ÈÄüÁöÑÊ∏≤ÊüìÈÄüÂ∫¶ÂíåÈ´ò‰øùÁúüÂ∫¶„ÄÇ
ÁÑ∂ËÄåÔºåÂ§ßÈáèÁöÑ Gaussians ÂèäÂÖ∂ÂÖ≥ËÅîÂ±ûÊÄßÈúÄË¶ÅÊúâÊïàÁöÑÂéãÁº©ÊäÄÊúØ„ÄÇÁé∞ÊúâÊñπÊ≥ï‰∏ªË¶ÅÂØπÁ•ûÁªè Gaussians ËøõË°åÂçïÁã¨‰∏îÁã¨Á´ãÁöÑÂéãÁº©ÔºåÂç≥ÂêåÊó∂ÁºñÁ†ÅÊâÄÊúâÁ•ûÁªè GaussiansÔºåËÄåÂæàÂ∞ëËÄÉËôëÂÆÉ‰ª¨‰πãÈó¥ÁöÑ‰∫§‰∫íÂíåÁ©∫Èó¥‰æùËµñÊÄß„ÄÇÂèóÂõæÂÉèÂéãÁº©‰∏≠‰∏ä‰∏ãÊñáÊ®°ÂûãÁöÑÊúâÊïàÊÄßÁöÑÂêØÂèëÔºåÊàë‰ª¨Âú®ËøôÈ°πÂ∑•‰Ωú‰∏≠ÊèêÂá∫‰∫ÜÁ¨¨‰∏Ä‰∏™Áî®‰∫é 3DGS ÂéãÁº©ÁöÑÈîöÁÇπÁ∫ßÂà´ÁöÑËá™ÂõûÂΩíÊ®°Âûã„ÄÇÊàë‰ª¨Â∞ÜÈîöÁÇπÂàíÂàÜ‰∏∫‰∏çÂêåÁöÑÁ∫ßÂà´ÔºåÂ∞öÊú™ÁºñÁ†ÅÁöÑÈîöÁÇπÂèØ‰ª•Ê†πÊçÆÊâÄÊúâËæÉÁ≤óÁ∫ßÂà´‰∏≠Â∑≤ÁºñÁ†ÅÁöÑÈîöÁÇπËøõË°åÈ¢ÑÊµãÔºå‰ªéËÄåÂÆûÁé∞Êõ¥ÂáÜÁ°ÆÁöÑÂª∫Ê®°ÂíåÊõ¥È´òÁöÑÁºñÁ†ÅÊïàÁéá„ÄÇ‰∏∫‰∫ÜËøõ‰∏ÄÊ≠•ÊèêÈ´òÁÜµÁºñÁ†ÅÁöÑÊïàÁéáÔºå‰æãÂ¶ÇÂØπÊ≤°ÊúâÂ∑≤ÁºñÁ†ÅÈîöÁÇπÁöÑÊúÄÁ≤óÁ∫ßÂà´ËøõË°åÁºñÁ†ÅÔºåÊàë‰ª¨Âª∫ËÆÆ‰∏∫ÊØè‰∏™ÈîöÁÇπÂºïÂÖ•‰∏Ä‰∏™‰ΩéÁª¥ÈáèÂåñÁâπÂæÅ‰Ωú‰∏∫Ë∂ÖÂÖàÈ™åÔºåÂÆÉÂèØ‰ª•Ë¢´ÊúâÊïàÂéãÁº©„ÄÇÊàë‰ª¨ÁöÑÂ∑•‰ΩúÂºÄÂàõ‰∫ÜÈîöÁÇπÁ∫ßÂà´‰∏≠Áî®‰∫é 3DGS Ë°®Á§∫ÁöÑ‰∏ä‰∏ãÊñáÊ®°ÂûãÔºå‰∏éÂéüÂßã 3DGS Áõ∏ÊØî‰∫ßÁîü‰∫ÜË∂ÖËøá 100 ÂÄçÁöÑÊÉä‰∫∫Â∞∫ÂØ∏Áº©ÂáèÔºå‰∏éÊúÄÊñ∞ÁöÑÊúÄÂÖàËøõÂ∑•‰Ωú Scaffold-GS Áõ∏ÊØîÁº©Âáè‰∫Ü 15 ÂÄçÔºåÂêåÊó∂ÂÆûÁé∞‰∫ÜÁõ∏ÂΩìÁîöËá≥Êõ¥È´òÁöÑÊ∏≤ÊüìË¥®Èáè„ÄÇ</paragraph>

##### **Climate Variable Downscaling with Conditional Normalizing Flows**
2405.20719v1 by Christina Winkler, Paula Harder, David Rolnick

Predictions of global climate models typically operate on coarse spatial
scales due to the large computational costs of climate simulations. This has
led to a considerable interest in methods for statistical downscaling, a
similar process to super-resolution in the computer vision context, to provide
more local and regional climate information. In this work, we apply conditional
normalizing flows to the task of climate variable downscaling. We showcase its
successful performance on an ERA5 water content dataset for different
upsampling factors. Additionally, we show that the method allows us to assess
the predictive uncertainty in terms of standard deviation from the fitted
conditional distribution mean.

ÊëòË¶ÅÔºöÂÖ®ÁêÉÊ∞£ÂÄôÊ®°ÂºèÁöÑÈ†êÊ∏¨ÈÄöÂ∏∏Âú®Á≤óÁï•ÁöÑÁ©∫ÈñìÂ∞∫Â∫¶‰∏äÈÄ≤Ë°åÔºåÈÄôÊòØÂõ†ÁÇ∫Ê∞£ÂÄôÊ®°Êì¨ÁöÑË®àÁÆóÊàêÊú¨È´òÊòÇ„ÄÇÈÄôÂºïËµ∑‰∫ÜÂ∞çÁµ±Ë®àÈôçÂ∞∫Â∫¶ÊñπÊ≥ïÁõ∏Áï∂Â§ßÁöÑËààË∂£ÔºåÈÄôÊòØ‰∏ÄÂÄãÈ°û‰ººÊñºÈõªËÖ¶Ë¶ñË¶∫ËÉåÊôØ‰∏≠Ë∂ÖËß£ÊûêÂ∫¶ÁöÑÈÅéÁ®ãÔºåÁî®ÊñºÊèê‰æõÊõ¥Â§öÂ±ÄÈÉ®ÂíåÂçÄÂüüÊ∞£ÂÄôË≥áË®ä„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÂ∞áÊ¢ù‰ª∂Ê≠£Ë¶èÂåñÊµÅÊáâÁî®ÊñºÊ∞£ÂÄôËÆäÊï∏ÈôçÂ∞∫Â∫¶ÁöÑ‰ªªÂãô„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫ÜÂÖ∂Âú®‰∏çÂêå‰∏äÊé°Ê®£Âõ†Â≠ê‰∏ãÂ∞ç ERA5 Âê´Ê∞¥ÈáèË≥áÊñôÈõÜÁöÑÊàêÂäüË°®Áèæ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜË©≤ÊñπÊ≥ïÂÖÅË®±ÊàëÂÄëÊ†πÊìöÊì¨ÂêàÊ¢ù‰ª∂ÂàÜ‰ΩàÂπ≥ÂùáÂÄºÁöÑÊ®ôÊ∫ñÂ∑ÆË©ï‰º∞È†êÊ∏¨‰∏çÁ¢∫ÂÆöÊÄß„ÄÇ

##### **Popularity-Aware Alignment and Contrast for Mitigating Popularity Bias**
2405.20718v1 by Miaomiao Cai, Lei Chen, Yifan Wang, Haoyue Bai, Peijie Sun, Le Wu, Min Zhang, Meng Wang

Collaborative Filtering (CF) typically suffers from the significant challenge
of popularity bias due to the uneven distribution of items in real-world
datasets. This bias leads to a significant accuracy gap between popular and
unpopular items. It not only hinders accurate user preference understanding but
also exacerbates the Matthew effect in recommendation systems. To alleviate
popularity bias, existing efforts focus on emphasizing unpopular items or
separating the correlation between item representations and their popularity.
Despite the effectiveness, existing works still face two persistent challenges:
(1) how to extract common supervision signals from popular items to improve the
unpopular item representations, and (2) how to alleviate the representation
separation caused by popularity bias. In this work, we conduct an empirical
analysis of popularity bias and propose Popularity-Aware Alignment and Contrast
(PAAC) to address two challenges. Specifically, we use the common supervisory
signals modeled in popular item representations and propose a novel
popularity-aware supervised alignment module to learn unpopular item
representations. Additionally, we suggest re-weighting the contrastive learning
loss to mitigate the representation separation from a popularity-centric
perspective. Finally, we validate the effectiveness and rationale of PAAC in
mitigating popularity bias through extensive experiments on three real-world
datasets. Our code is available at
https://github.com/miaomiao-cai2/KDD2024-PAAC.

ÊëòË¶ÅÔºöÂçîÂêåÈÅéÊøæ (CF) ÈÄöÂ∏∏ÊúÉÂõ†ÁÇ∫ÁúüÂØ¶‰∏ñÁïåË≥áÊñôÈõÜ‰∏≠È†ÖÁõÆÂàÜ‰Ωà‰∏çÂùáËÄåÈÅ≠ÂèóÈ°ØËëóÁöÑÁÜ±ÈñÄÂÅèÂ∑ÆÊåëÊà∞„ÄÇÊ≠§ÂÅèÂ∑ÆÂ∞éËá¥ÁÜ±ÈñÄÂíåÂÜ∑ÈñÄÈ†ÖÁõÆ‰πãÈñìÁöÑÈ°ØËëóÊ∫ñÁ¢∫Â∫¶Â∑ÆË∑ù„ÄÇÂÆÉ‰∏çÂÉÖÂ¶®Á§ôÊ∫ñÁ¢∫‰∫ÜËß£‰ΩøÁî®ËÄÖÁöÑÂÅèÂ•ΩÔºåÈÇÑÊúÉÂä†ÂäáÊé®Ëñ¶Á≥ªÁµ±‰∏≠ÁöÑÈ¶¨Â§™ÊïàÊáâ„ÄÇÁÇ∫‰∫ÜÊ∏õËºïÁÜ±ÈñÄÂÅèÂ∑ÆÔºåÁèæÊúâÁöÑÊñπÊ≥ïÂ∞àÊ≥®ÊñºÂº∑Ë™øÂÜ∑ÈñÄÈ†ÖÁõÆÊàñÂàÜÈõ¢È†ÖÁõÆË°®Á§∫ËàáÂÖ∂ÁÜ±ÈñÄÁ®ãÂ∫¶‰πãÈñìÁöÑÈóúËÅØÊÄß„ÄÇÂÑòÁÆ°ÊúâÊïàÔºå‰ΩÜÁèæÊúâÁöÑÂ∑•‰Ωú‰ªçÈù¢Ëá®ÂÖ©ÂÄãÊåÅÁ∫åÁöÑÊåëÊà∞Ôºö(1) Â¶Ç‰ΩïÂæûÁÜ±ÈñÄÈ†ÖÁõÆ‰∏≠ÊèêÂèñÂÖ±ÂêåÁöÑÁõ£Áù£‰ø°Ëôü‰æÜÊîπÂñÑÂÜ∑ÈñÄÈ†ÖÁõÆË°®Á§∫Ôºå‰ª•Âèä (2) Â¶Ç‰ΩïÊ∏õËºïÁÜ±ÈñÄÂÅèÂ∑ÆÈÄ†ÊàêÁöÑË°®Á§∫ÂàÜÈõ¢„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÂ∞çÁÜ±ÈñÄÂÅèÂ∑ÆÈÄ≤Ë°å‰∫ÜÂØ¶Ë≠âÂàÜÊûêÔºå‰∏¶ÊèêÂá∫ Popularity-Aware Alignment and Contrast (PAAC) ‰æÜÊáâÂ∞çÈÄôÂÖ©ÂÄãÊåëÊà∞„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄë‰ΩøÁî®Âú®ÁÜ±ÈñÄÈ†ÖÁõÆË°®Á§∫‰∏≠Âª∫Ê®°ÁöÑÂÖ±ÂêåÁõ£Áù£‰ø°ËôüÔºå‰∏¶ÊèêÂá∫‰∏ÄÂÄãÊñ∞Á©éÁöÑÁÜ±ÈñÄÊÑüÁü•Áõ£Áù£ÂºèÂ∞çÈΩäÊ®°ÁµÑ‰æÜÂ≠∏ÁøíÂÜ∑ÈñÄÈ†ÖÁõÆË°®Á§∫„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂª∫Ë≠∞ÈáçÊñ∞Âä†Ê¨äÂ∞çÊØîÂ≠∏ÁøíÊêçÂ§±Ôºå‰ª•Âæû‰ª•ÁÜ±ÈñÄÁÇ∫‰∏≠ÂøÉÁöÑËßÄÈªûÊ∏õËºïË°®Á§∫ÂàÜÈõ¢„ÄÇÊúÄÂæåÔºåÊàëÂÄëÈÄöÈÅéÂú®‰∏âÂÄãÁúüÂØ¶‰∏ñÁïåË≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÂª£Ê≥õÁöÑÂØ¶È©óÔºåÈ©óË≠â‰∫Ü PAAC Âú®Ê∏õËºïÁÜ±ÈñÄÂÅèÂ∑ÆÊñπÈù¢ÁöÑÊúâÊïàÊÄßÂíåÂéüÁêÜ„ÄÇÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÂèØÂú® https://github.com/miaomiao-cai2/KDD2024-PAAC ÂèñÂæó„ÄÇ

##### **FinGen: A Dataset for Argument Generation in Finance**
2405.20708v1 by Chung-Chi Chen, Hiroya Takamura, Ichiro Kobayashi, Yusuke Miyao

Thinking about the future is one of the important activities that people do
in daily life. Futurists also pay a lot of effort into figuring out possible
scenarios for the future. We argue that the exploration of this direction is
still in an early stage in the NLP research. To this end, we propose three
argument generation tasks in the financial application scenario. Our
experimental results show these tasks are still big challenges for
representative generation models. Based on our empirical results, we further
point out several unresolved issues and challenges in this research direction.

ÊëòË¶ÅÔºöÊÄùËÄÉÊú™‰æÜÊòØ‰∫∫ÂÄëÂú®Êó•Â∏∏ÁîüÊ¥ª‰∏≠ÈáçË¶ÅÁöÑÊ¥ªÂãï‰πã‰∏Ä„ÄÇÊú™‰æÜÂ≠∏ÂÆ∂‰πüËä±Ë≤ªË®±Â§öÁ≤æÂäõÊâæÂá∫Êú™‰æÜÁöÑÂèØËÉΩÊÉÖÂ¢É„ÄÇÊàëÂÄëË™çÁÇ∫ÔºåÂú®Ëá™ÁÑ∂Ë™ûË®ÄËôïÁêÜÁ†îÁ©∂‰∏≠ÔºåÊé¢Á¥¢ÈÄôÂÄãÊñπÂêë‰ªçËôïÊñºÊó©ÊúüÈöéÊÆµ„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÂú®Ë≤°ÂãôÊáâÁî®ÊÉÖÂ¢É‰∏≠ÊèêÂá∫‰∫Ü‰∏âÂÄãË´ñË≠âÁîüÊàê‰ªªÂãô„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÁµêÊûúÈ°ØÁ§∫ÔºåÈÄô‰∫õ‰ªªÂãôÂ∞çÊñºÂÖ∑Êúâ‰ª£Ë°®ÊÄßÁöÑÁîüÊàêÊ®°ÂûãËÄåË®Ä‰ªçÁÑ∂ÊòØÈáçÂ§ßÁöÑÊåëÊà∞„ÄÇÊ†πÊìöÊàëÂÄëÁöÑÂØ¶Ë≠âÁµêÊûúÔºåÊàëÂÄëÈÄ≤‰∏ÄÊ≠•ÊåáÂá∫ÈÄôÂÄãÁ†îÁ©∂ÊñπÂêë‰∏≠ÂπæÂÄãÂ∞öÊú™Ëß£Ê±∫ÁöÑÂïèÈ°åÂíåÊåëÊà∞„ÄÇ

##### **ADESSE: Advice Explanations in Complex Repeated Decision-Making Environments**
2405.20705v1 by S√∂ren Schleibaum, Lu Feng, Sarit Kraus, J√∂rg P. M√ºller

In the evolving landscape of human-centered AI, fostering a synergistic
relationship between humans and AI agents in decision-making processes stands
as a paramount challenge. This work considers a problem setup where an
intelligent agent comprising a neural network-based prediction component and a
deep reinforcement learning component provides advice to a human decision-maker
in complex repeated decision-making environments. Whether the human
decision-maker would follow the agent's advice depends on their beliefs and
trust in the agent and on their understanding of the advice itself. To this
end, we developed an approach named ADESSE to generate explanations about the
adviser agent to improve human trust and decision-making. Computational
experiments on a range of environments with varying model sizes demonstrate the
applicability and scalability of ADESSE. Furthermore, an interactive game-based
user study shows that participants were significantly more satisfied, achieved
a higher reward in the game, and took less time to select an action when
presented with explanations generated by ADESSE. These findings illuminate the
critical role of tailored, human-centered explanations in AI-assisted
decision-making.

ÊëòË¶ÅÔºöÂú®‰ª•‰∫∫‰∏∫‰∏≠ÂøÉÁöÑ‰∫∫Â∑•Êô∫ÊÖß‰∏çÊñ≠ÊºîËÆäÁöÑÈ†òÂüü‰∏≠Ôºå‰øÉÈÄ≤‰∫∫È°ûÂíå‰∫∫Â∑•Êô∫ÊÖß‰ª£ÁêÜÂú®Ê±∫Á≠ñÈÅéÁ®ã‰∏≠Áî¢ÁîüÂçîÂêåÊïàÊáâÁöÑÈóú‰øÇÔºåÊòØ‰∏ÄÈ†ÖËá≥ÈóúÈáçË¶ÅÁöÑÊåëÊà∞„ÄÇÊú¨Á†îÁ©∂ËÄÉÊÖÆ‰∫Ü‰∏ÄÂÄãÂïèÈ°åË®≠ÂÆöÔºåÂÖ∂‰∏≠‰∏ÄÂÄãÁî±Âü∫ÊñºÁ•ûÁ∂ìÁ∂≤Ë∑ØÁöÑÈ†êÊ∏¨ÁµÑÊàêÂíå‰∏ÄÂÄãÊ∑±Â∫¶Âº∑ÂåñÂ≠∏ÁøíÁµÑÊàêÁöÑÊô∫ÊÖß‰ª£ÁêÜÔºåÂú®Ë§áÈõúÁöÑÈáçË§áÊ±∫Á≠ñÁí∞Â¢É‰∏≠Âêë‰∫∫È°ûÊ±∫Á≠ñËÄÖÊèê‰æõÂª∫Ë≠∞„ÄÇ‰∫∫È°ûÊ±∫Á≠ñËÄÖÊòØÂê¶ÊúÉÈÅµÂæ™‰ª£ÁêÜÁöÑÂª∫Ë≠∞ÂèñÊ±∫Êñº‰ªñÂÄëÂ∞ç‰ª£ÁêÜÁöÑ‰ø°ÂøµÂíå‰ø°‰ªªÔºå‰ª•Âèä‰ªñÂÄëÂ∞çÂª∫Ë≠∞Êú¨Ë∫´ÁöÑÁêÜËß£„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÈñãÁôº‰∫Ü‰∏ÄÁ®ÆÂêçÁÇ∫ ADESSE ÁöÑÊñπÊ≥ïÔºå‰ª•Áî¢ÁîüÈóúÊñºÈ°ßÂïè‰ª£ÁêÜÁöÑËß£ÈáãÔºå‰ª•ÊèêÈ´ò‰∫∫È°ûÁöÑ‰ø°‰ªªÂíåÊ±∫Á≠ñËÉΩÂäõ„ÄÇÂú®ÂÖ∑Êúâ‰∏çÂêåÊ®°ÂûãÂ§ßÂ∞èÁöÑÂêÑÁ®ÆÁí∞Â¢É‰∏≠ÈÄ≤Ë°åÁöÑË®àÁÆóÂØ¶È©óË≠âÊòé‰∫Ü ADESSE ÁöÑÈÅ©Áî®ÊÄßÂíåÂèØÊì¥ÂÖÖÊÄß„ÄÇÊ≠§Â§ñÔºå‰∏ÄÈ†ÖÂü∫Êñº‰∫íÂãïÈÅäÊà≤ÁöÑ‰ΩøÁî®ËÄÖÁ†îÁ©∂Ë°®ÊòéÔºåÁï∂ÂèÉËàáËÄÖÁúãÂà∞Áî± ADESSE ÁîüÊàêÁöÑËß£ÈáãÊôÇÔºå‰ªñÂÄëÁöÑÊªøÊÑèÂ∫¶È°ØËëóÊèêÈ´òÔºåÂú®ÈÅäÊà≤‰∏≠Áç≤ÂæóÁöÑÁçéÂãµÊõ¥È´òÔºå‰∏¶‰∏îÈÅ∏ÊìáÂãï‰ΩúÊâÄÈúÄÁöÑÊôÇÈñìÊõ¥Áü≠„ÄÇÈÄô‰∫õÁôºÁèæÈó°Êòé‰∫ÜÈáèË∫´ÂÆöÂà∂„ÄÅ‰ª•‰∫∫ÁÇ∫‰∏≠ÂøÉÁöÑËß£ÈáãÂú®‰∫∫Â∑•Êô∫ÊÖßËºîÂä©Ê±∫Á≠ñ‰∏≠ÁöÑÈóúÈçµ‰ΩúÁî®„ÄÇ

##### **It is Simple Sometimes: A Study On Improving Aspect-Based Sentiment Analysis Performance**
2405.20703v1 by Laura Cabello, Uchenna Akujuobi

Aspect-Based Sentiment Analysis (ABSA) involves extracting opinions from
textual data about specific entities and their corresponding aspects through
various complementary subtasks. Several prior research has focused on
developing ad hoc designs of varying complexities for these subtasks. In this
paper, we present a generative framework extensible to any ABSA subtask. We
build upon the instruction tuned model proposed by Scaria et al. (2023), who
present an instruction-based model with task descriptions followed by
in-context examples on ABSA subtasks. We propose PFInstruct, an extension to
this instruction learning paradigm by appending an NLP-related task prefix to
the task description. This simple approach leads to improved performance across
all tested SemEval subtasks, surpassing previous state-of-the-art (SOTA) on the
ATE subtask (Rest14) by +3.28 F1-score, and on the AOOE subtask by an average
of +5.43 F1-score across SemEval datasets. Furthermore, we explore the impact
of the prefix-enhanced prompt quality on the ABSA subtasks and find that even a
noisy prefix enhances model performance compared to the baseline. Our method
also achieves competitive results on a biomedical domain dataset (ERSA).

ÊëòË¶ÅÔºöÈù¢ÂêëÊñπÈù¢ÁöÑËßÇÁÇπÂàÜÊûê (ABSA) Ê∂âÂèäÈÄèÈÅéÂêÑÁ®Æ‰∫íË£úÁöÑÂ≠ê‰ªªÂãôÂæûÊñáÊú¨Ë≥áÊñô‰∏≠Êì∑ÂèñÁâπÂÆöÂØ¶È´îÂèäÂÖ∂Â∞çÊáâÊñπÈù¢ÁöÑÊÑèË¶ã„ÄÇË®±Â§öÂÖàÂâçÁöÑÁ†îÁ©∂Â∞àÊ≥®ÊñºÁÇ∫ÈÄô‰∫õÂ≠ê‰ªªÂãôÈñãÁôºÂÖ∑Êúâ‰∏çÂêåË§áÈõúÂ∫¶ÁöÑÁâπÂÆöË®≠Ë®à„ÄÇÂú®ÈÄôÁØáË´ñÊñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÂèØÂª∂‰º∏Ëá≥‰ªª‰Ωï ABSA Â≠ê‰ªªÂãôÁöÑÁîüÊàêÂºèÊû∂Êßã„ÄÇÊàëÂÄëÂª∫Á´ãÂú® Scaria Á≠â‰∫∫ (2023) ÊèêÂá∫ÁöÑÊåá‰ª§Ë™øÊï¥Ê®°Âûã‰πã‰∏äÔºå‰ªñÂÄëÊèêÂá∫‰∏ÄÂÄãÂü∫ÊñºÊåá‰ª§ÁöÑÊ®°ÂûãÔºåÂÖ∂ÂæåÊé• ABSA Â≠ê‰ªªÂãôÁöÑËÑàÁµ°ÁØÑ‰æãÂíå‰ªªÂãôË™™Êòé„ÄÇÊàëÂÄëÊèêÂá∫ PFInstructÔºå‰∏ÄÁ®ÆÈÄèÈÅéÂ∞áËàá NLP Áõ∏ÈóúÁöÑ‰ªªÂãôÂâçÁΩÆË©ûÈôÑÂä†Âà∞‰ªªÂãôË™™Êòé‰∏≠‰æÜÂª∂‰º∏ÈÄôÂÄãÊåá‰ª§Â≠∏ÁøíÁØÑ‰æã„ÄÇÈÄôÁ®ÆÁ∞°ÂñÆÁöÑÊñπÊ≥ïÂèØÊèêÂçáÊâÄÊúâÂ∑≤Ê∏¨Ë©¶ SemEval Â≠ê‰ªªÂãôÁöÑÊïàËÉΩÔºåÂú® ATE Â≠ê‰ªªÂãô (Rest14) ‰∏äË∂ÖË∂äÂÖàÂâçÁöÑÊúÄÊñ∞ÊäÄË°ì (SOTA) +3.28 F1 ÂàÜÊï∏ÔºåÂú® AOOE Â≠ê‰ªªÂãô‰∏äÂπ≥ÂùáË∂ÖË∂ä SemEval Ë≥áÊñôÈõÜ +5.43 F1 ÂàÜÊï∏„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊé¢Ë®éÂâçÁΩÆË©ûÂ¢ûÂº∑ÊèêÁ§∫ÂìÅË≥™Â∞ç ABSA Â≠ê‰ªªÂãôÁöÑÂΩ±ÈüøÔºåÁôºÁèæÂç≥‰ΩøÊòØÊúâÈõúË®äÁöÑÂâçÁΩÆË©ûÔºåËàáÂü∫Ê∫ñÁ∑öÁõ∏ÊØîÔºå‰πüËÉΩÊèêÂçáÊ®°ÂûãÊïàËÉΩ„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÂú®ÁîüÁâ©ÈÜ´Â≠∏È†òÂüüË≥áÊñôÈõÜ (ERSA) ‰∏ä‰πüÁç≤ÂæóÊúâÁ´∂Áà≠ÂäõÁöÑÁµêÊûú„ÄÇ

##### **Unveiling the Lexical Sensitivity of LLMs: Combinatorial Optimization for Prompt Enhancement**
2405.20701v1 by Pengwei Zhan, Zhen Xu, Qian Tan, Jie Song, Ru Xie

Large language models (LLMs) demonstrate exceptional instruct-following
ability to complete various downstream tasks. Although this impressive ability
makes LLMs flexible task solvers, their performance in solving tasks also
heavily relies on instructions. In this paper, we reveal that LLMs are
over-sensitive to lexical variations in task instructions, even when the
variations are imperceptible to humans. By providing models with neighborhood
instructions, which are closely situated in the latent representation space and
differ by only one semantically similar word, the performance on downstream
tasks can be vastly different. Following this property, we propose a black-box
Combinatorial Optimization framework for Prompt Lexical Enhancement (COPLE).
COPLE performs iterative lexical optimization according to the feedback from a
batch of proxy tasks, using a search strategy related to word influence.
Experiments show that even widely-used human-crafted prompts for current
benchmarks suffer from the lexical sensitivity of models, and COPLE recovers
the declined model ability in both instruct-following and solving downstream
tasks.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â±ïÁ§∫Âá∫ÂçìË∂äÁöÑÊåá‰ª§ÈÅµÂæ™ËÉΩÂäõÔºå‰ª•ÂÆåÊàêÂêÑÁ®Æ‰∏ãÊ∏∏‰ªªÂãô„ÄÇÂÑòÁÆ°ÈÄôÁ®Æ‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑËÉΩÂäõ‰Ωø LLM ÊàêÁÇ∫ÈùàÊ¥ªÁöÑ‰ªªÂãôËß£Ê±∫Âô®Ôºå‰ΩÜÂÆÉÂÄëÂú®Ëß£Ê±∫‰ªªÂãô‰∏≠ÁöÑË°®Áèæ‰πüÊ•µÂ∫¶‰æùË≥¥ÊñºÊåá‰ª§„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊè≠Á§∫‰∫Ü LLM Â∞ç‰ªªÂãôÊåá‰ª§‰∏≠ÁöÑË©ûÂΩôËÆäÁï∞ÈÅéÂ∫¶ÊïèÊÑüÔºåÂç≥‰ΩøÈÄô‰∫õËÆäÁï∞Â∞ç‰∫∫È°û‰æÜË™™ÊòØÁÑ°Ê≥ïÂØüË¶∫ÁöÑ„ÄÇÈÄöÈÅéÁÇ∫Ê®°ÂûãÊèê‰æõÈÑ∞ÂüüÊåá‰ª§ÔºàÈÄô‰∫õÊåá‰ª§Âú®ÊΩõÂú®Ë°®Á§∫Á©∫Èñì‰∏≠Á∑äÂØÜÁõ∏ÈÑ∞Ôºå‰∏¶‰∏îÂè™Êúâ‰∏ÄÂÄãË™ûÁæ©Áõ∏‰ººÁöÑË©û‰∏çÂêåÔºâÔºå‰∏ãÊ∏∏‰ªªÂãôÁöÑË°®ÁèæÂèØËÉΩÊúÉÊúâÂæàÂ§ß‰∏çÂêå„ÄÇÈÅµÂæ™Ê≠§Â±¨ÊÄßÔºåÊàëÂÄëÊèêÂá∫‰∫ÜÁî®ÊñºÊèêÁ§∫Ë©ûÂΩôÂ¢ûÂº∑ (COPLE) ÁöÑÈªëÁõíÁµÑÂêàÂÑ™ÂåñÊ°ÜÊû∂„ÄÇCOPLE Ê†πÊìö‰∏ÄÊâπ‰ª£ÁêÜ‰ªªÂãôÁöÑÂõûÈ•ãÔºå‰ΩøÁî®ËàáË©ûÂΩôÂΩ±ÈüøÁõ∏ÈóúÁöÑÊêúÂ∞ãÁ≠ñÁï•ÔºåÂü∑Ë°åÂèçË¶ÜÁöÑË©ûÂΩôÂÑ™Âåñ„ÄÇÂØ¶È©óË°®ÊòéÔºåÂç≥‰ΩøÊòØÁï∂ÂâçÂü∫Ê∫ñÂª£Ê≥õ‰ΩøÁî®ÁöÑÁî±‰∫∫È°ûË£Ω‰ΩúÁöÑÊèêÁ§∫‰πüÊúÉÂèóÂà∞Ê®°ÂûãÁöÑË©ûÂΩôÊïèÊÑüÊÄßÂΩ±ÈüøÔºåËÄå COPLE Âú®Êåá‰ª§ÈÅµÂæ™ÂíåËß£Ê±∫‰∏ãÊ∏∏‰ªªÂãô‰∏≠ÊÅ¢Âæ©‰∫ÜÊ®°Âûã‰∏ãÈôçÁöÑËÉΩÂäõ„ÄÇ

##### **Self-degraded contrastive domain adaptation for industrial fault diagnosis with bi-imbalanced data**
2405.20700v1 by Gecheng Chen, Zeyu Yang, Chengwen Luo, Jianqiang Li

Modern industrial fault diagnosis tasks often face the combined challenge of
distribution discrepancy and bi-imbalance. Existing domain adaptation
approaches pay little attention to the prevailing bi-imbalance, leading to poor
domain adaptation performance or even negative transfer. In this work, we
propose a self-degraded contrastive domain adaptation (Sd-CDA) diagnosis
framework to handle the domain discrepancy under the bi-imbalanced data. It
first pre-trains the feature extractor via imbalance-aware contrastive learning
based on model pruning to learn the feature representation efficiently in a
self-supervised manner. Then it forces the samples away from the domain
boundary based on supervised contrastive domain adversarial learning
(SupCon-DA) and ensures the features generated by the feature extractor are
discriminative enough. Furthermore, we propose the pruned contrastive domain
adversarial learning (PSupCon-DA) to pay automatically re-weighted attention to
the minorities to enhance the performance towards bi-imbalanced data. We show
the superiority of the proposed method via two experiments.

ÊëòË¶ÅÔºöÁèæ‰ª£Â∑•Ê•≠ÊïÖÈöúË®∫Êñ∑‰ªªÂãôÁ∂ìÂ∏∏Èù¢Ëá®ÂàÜ‰ΩàÂ∑ÆÁï∞Âíå‰∫åÂÖÉ‰∏çÂπ≥Ë°°ÁöÑÁ∂úÂêàÊåëÊà∞„ÄÇÁèæÊúâÁöÑÂüüÈÅ©ÊáâÊñπÊ≥ïÂæàÂ∞ëÈóúÊ≥®ÊôÆÈÅçÂ≠òÂú®ÁöÑ‰∫åÂÖÉ‰∏çÂπ≥Ë°°ÔºåÂ∞éËá¥ÂüüÈÅ©ÊáâÊÄßËÉΩ‰∏ç‰Ω≥ÁîöËá≥Âá∫ÁèæË≤†ÂÇ≥ÈÅû„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãËá™ÈôçÁ¥öÂ∞çÊØîÂüüÈÅ©Êáâ (Sd-CDA) Ë®∫Êñ∑Ê°ÜÊû∂Ôºå‰ª•ËôïÁêÜ‰∫åÂÖÉ‰∏çÂπ≥Ë°°Êï∏Êìö‰∏ãÁöÑÂüüÂ∑ÆÁï∞„ÄÇÂÆÉÈ¶ñÂÖàÈÄöÈÅéÂü∫ÊñºÊ®°ÂûãÂâ™ÊûùÁöÑ‰∏çÂπ≥Ë°°ÊÑüÁü•Â∞çÊØîÂ≠∏ÁøíÂ∞çÁâπÂæµÊèêÂèñÂô®ÈÄ≤Ë°åÈ†êË®ìÁ∑¥Ôºå‰ª•Ëá™Áõ£Áù£ÁöÑÊñπÂºèÊúâÊïàÂú∞Â≠∏ÁøíÁâπÂæµË°®Á§∫„ÄÇÁÑ∂ÂæåÔºåÂÆÉÂü∫ÊñºÁõ£Áù£Â∞çÊØîÂüüÂ∞çÊäóÂ≠∏Áøí (SupCon-DA) Âº∑Âà∂Ê®£Êú¨ÈÅ†Èõ¢ÂüüÈÇäÁïåÔºå‰∏¶Á¢∫‰øùÁâπÂæµÊèêÂèñÂô®Áî¢ÁîüÁöÑÁâπÂæµÂÖ∑ÊúâË∂≥Â§†ÁöÑÂçÄÂà•ÊÄß„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèêÂá∫Ââ™ÊûùÂ∞çÊØîÂüüÂ∞çÊäóÂ≠∏Áøí (PSupCon-DA) ‰æÜËá™ÂãïÈáçÊñ∞Âä†Ê¨äÈóúÊ≥®Â∞ëÊï∏Áæ§È´îÔºå‰ª•ÊèêÈ´òÂ∞ç‰∫åÂÖÉ‰∏çÂπ≥Ë°°Êï∏ÊìöÁöÑÊÄßËÉΩ„ÄÇÊàëÂÄëÈÄöÈÅéÂÖ©ÂÄãÂØ¶È©óÂ±ïÁ§∫‰∫ÜÊâÄÊèêÂá∫ÊñπÊ≥ïÁöÑÂÑ™Ë∂äÊÄß„ÄÇ

##### **Joint Embeddings for Graph Instruction Tuning**
2405.20684v1 by Vlad Argatu, Aaron Haag, Oliver Lohse

Large Language Models (LLMs) have achieved impressive performance in text
understanding and have become an essential tool for building smart assistants.
Originally focusing on text, they have been enhanced with multimodal
capabilities in recent works that successfully built visual instruction
following assistants. As far as the graph modality goes, however, no such
assistants have yet been developed. Graph structures are complex in that they
represent relation between different features and are permutation invariant.
Moreover, representing them in purely textual form does not always lead to good
LLM performance even for finetuned models. As a result, there is a need to
develop a new method to integrate graphs in LLMs for general graph
understanding. This work explores the integration of the graph modality in LLM
for general graph instruction following tasks. It aims at producing a deep
learning model that enhances an underlying LLM with graph embeddings and trains
it to understand them and to produce, given an instruction, an answer grounded
in the graph representation. The approach performs significantly better than a
graph to text approach and remains consistent even for larger graphs.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®ÊñáÂ≠óÁêÜËß£ÊñπÈù¢ÂèñÂæó‰ª§‰∫∫È©öËâ∑ÁöÑË°®ÁèæÔºå‰∏¶Â∑≤ÊàêÁÇ∫Âª∫ÊßãÊô∫ÊÖßÂä©ÁêÜÁöÑÂøÖË¶ÅÂ∑•ÂÖ∑„ÄÇÂéüÊú¨Â∞àÊ≥®ÊñºÊñáÂ≠óÔºåÂÆÉÂÄëÂú®ËøëÊúüÁöÑ‰ΩúÂìÅ‰∏≠Â∑≤ÈÄèÈÅéÂ§öÊ®°ÂºèÂäüËÉΩÂæóÂà∞Âä†Âº∑ÔºåÊàêÂäüÂª∫ÊßãÂá∫Ë¶ñË¶∫Êåá‰ª§ËøΩËπ§Âä©ÁêÜ„ÄÇÁÑ∂ËÄåÔºåÂ∞±ÂúñÂΩ¢Ê®°ÂºèËÄåË®ÄÔºåÁõÆÂâçÂ∞öÊú™ÈñãÁôºÂá∫Ê≠§È°ûÂä©ÁêÜ„ÄÇÂúñÂΩ¢ÁµêÊßãÂæàË§áÈõúÔºåÂú®ÊñºÂÆÉÂÄëË°®Á§∫‰∏çÂêåÁâπÂæµ‰πãÈñìÁöÑÈóú‰øÇÔºå‰∏îÂÖ∑ÊúâÊéíÂàó‰∏çËÆäÊÄß„ÄÇÊ≠§Â§ñÔºåÂç≥‰ΩøÂ∞çÊñºÂæÆË™øÊ®°ÂûãÔºåÂ∞áÂÆÉÂÄëË°®Á§∫ÊàêÁ¥îÁ≤πÁöÑÊñáÂ≠óÂΩ¢Âºè‰∏¶ÈùûÁ∏ΩÊòØËÉΩÂ∏∂‰æÜËâØÂ•ΩÁöÑ LLM ÊïàËÉΩ„ÄÇÂõ†Ê≠§ÔºåÈúÄË¶ÅÈñãÁôº‰∏ÄÁ®ÆÊñ∞ÊñπÊ≥ïÔºåÂ∞áÂúñÂΩ¢Êï¥ÂêàÂà∞ LLM ‰∏≠Ôºå‰ª•ÈÄ≤Ë°å‰∏ÄËà¨ÁöÑÂúñÂΩ¢ÁêÜËß£„ÄÇÊú¨Á†îÁ©∂Êé¢Ë®é LLM ‰∏≠ÂúñÂΩ¢Ê®°ÂºèÁöÑÊï¥ÂêàÔºå‰ª•ÈÄ≤Ë°å‰∏ÄËà¨ÁöÑÂúñÂΩ¢Êåá‰ª§ËøΩËπ§‰ªªÂãô„ÄÇÂÖ∂ÁõÆÊ®ôÊòØÁî¢Áîü‰∏ÄÂÄãÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÔºåÈÄèÈÅéÂúñÂΩ¢ÂµåÂÖ•Â¢ûÂº∑Âü∫Á§é LLMÔºå‰∏¶Ë®ìÁ∑¥ÂÆÉ‰∫ÜËß£ÂúñÂΩ¢ÂµåÂÖ•Ôºå‰∏¶Ê†πÊìöÊåá‰ª§Áî¢Áîü‰ª•ÂúñÂΩ¢Ë°®Á§∫ÁÇ∫Âü∫Á§éÁöÑÁ≠îÊ°à„ÄÇÊ≠§ÊñπÊ≥ïÁöÑË°®ÁèæÈ°ØËëóÂÑ™ÊñºÊñáÂ≠óÂà∞ÊñáÂ≠óÁöÑÊñπÊ≥ïÔºåÂç≥‰ΩøÂ∞çÊñºËºÉÂ§ßÁöÑÂúñÂΩ¢‰πüËÉΩ‰øùÊåÅ‰∏ÄËá¥ÊÄß„ÄÇ

##### **No Free Lunch Theorem for Privacy-Preserving LLM Inference**
2405.20681v1 by Xiaojin Zhang, Yulin Fei, Yan Kang, Wei Chen, Lixin Fan, Hai Jin, Qiang Yang

Individuals and businesses have been significantly benefited by Large
Language Models (LLMs) including PaLM, Gemini and ChatGPT in various ways. For
example, LLMs enhance productivity, reduce costs, and enable us to focus on
more valuable tasks. Furthermore, LLMs possess the capacity to sift through
extensive datasets, uncover underlying patterns, and furnish critical insights
that propel the frontiers of technology and science. However, LLMs also pose
privacy concerns. Users' interactions with LLMs may expose their sensitive
personal or company information. A lack of robust privacy safeguards and legal
frameworks could permit the unwarranted intrusion or improper handling of
individual data, thereby risking infringements of privacy and the theft of
personal identities. To ensure privacy, it is essential to minimize the
dependency between shared prompts and private information. Various
randomization approaches have been proposed to protect prompts' privacy, but
they may incur utility loss compared to unprotected LLMs prompting. Therefore,
it is essential to evaluate the balance between the risk of privacy leakage and
loss of utility when conducting effective protection mechanisms. The current
study develops a framework for inferring privacy-protected Large Language
Models (LLMs) and lays down a solid theoretical basis for examining the
interplay between privacy preservation and utility. The core insight is
encapsulated within a theorem that is called as the NFL (abbreviation of the
word No-Free-Lunch) Theorem.

ÊëòË¶ÅÔºöÂÄã‰∫∫Âíå‰ºÅÊ•≠Â∑≤Á∂ìÂæûÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM)ÔºåÂåÖÊã¨ PaLM„ÄÅGemini Âíå ChatGPTÔºåÂú®ÂêÑÁ®ÆÊñπÈù¢Áç≤ÂæóÈ°ØËëóÁöÑÂ•ΩËôï„ÄÇ‰æãÂ¶ÇÔºåLLM ÊèêÈ´òÁîüÁî¢Âäõ„ÄÅÈôç‰ΩéÊàêÊú¨Ôºå‰∏¶‰ΩøÊàëÂÄëËÉΩÂ§†Â∞àÊ≥®ÊñºÊõ¥ÊúâÂÉπÂÄºÁöÑ‰ªªÂãô„ÄÇÊ≠§Â§ñÔºåLLM ÂÖ∑ÂÇôÁØ©ÈÅ∏Âª£Ê≥õÊï∏ÊìöÈõÜ„ÄÅÁôºÁèæÊΩõÂú®Ê®°ÂºèÔºå‰∏¶Êèê‰æõÊé®ÂãïÊäÄË°ìÂíåÁßëÂ≠∏ÂâçÊ≤øÁöÑÈóúÈçµË¶ãËß£ÁöÑËÉΩÂäõ„ÄÇÁÑ∂ËÄåÔºåLLM ‰πüÊúÉÂºïÁôºÈö±ÁßÅÂïèÈ°å„ÄÇ‰ΩøÁî®ËÄÖËàá LLM ÁöÑ‰∫íÂãïÂèØËÉΩÊúÉÊö¥Èú≤ÂÖ∂ÊïèÊÑüÁöÑÂÄã‰∫∫ÊàñÂÖ¨Âè∏Ë≥áË®ä„ÄÇÁº∫‰πèÂº∑Â§ßÁöÑÈö±ÁßÅ‰øùÈöúÊé™ÊñΩÂíåÊ≥ïÂæãÊû∂ÊßãÂèØËÉΩÊúÉÂÖÅË®±Â∞çÂÄã‰∫∫Ë≥áÊñôÁöÑÈùûÊ≥ïÂÖ•‰æµÊàñ‰∏çÁï∂ËôïÁêÜÔºåÂæûËÄåÈÄ†ÊàêÈö±ÁßÅÊ¨äÁöÑ‰æµÁäØÂíåÂÄã‰∫∫Ë∫´ÂàÜÁöÑÁõúÁî®„ÄÇÁÇ∫‰∫ÜÁ¢∫‰øùÈö±ÁßÅÔºåÊúÄÂ∞èÂåñÂÖ±‰∫´ÊèêÁ§∫ËàáÁßÅ‰∫∫Ë≥áË®ä‰πãÈñìÁöÑ‰æùË≥¥ÊÄßËá≥ÈóúÈáçË¶Å„ÄÇÂ∑≤Á∂ìÊèêÂá∫ÂêÑÁ®ÆÈö®Ê©üÂåñÊñπÊ≥ï‰æÜ‰øùË≠∑ÊèêÁ§∫ÁöÑÈö±ÁßÅÔºå‰ΩÜËàáÊú™Âèó‰øùË≠∑ÁöÑ LLM ÊèêÁ§∫Áõ∏ÊØîÔºåÂÆÉÂÄëÂèØËÉΩÊúÉÈÄ†ÊàêÊïàÁî®ÊêçÂ§±„ÄÇÂõ†Ê≠§ÔºåÂú®Âü∑Ë°åÊúâÊïàÁöÑ‰øùË≠∑Ê©üÂà∂ÊôÇÔºåË©ï‰º∞Èö±ÁßÅÊ¥©Èú≤È¢®Èö™ËàáÊïàÁî®ÊêçÂ§±‰πãÈñìÁöÑÂπ≥Ë°°Ëá≥ÈóúÈáçË¶Å„ÄÇÁõÆÂâçÁöÑÁ†îÁ©∂ÈñãÁôº‰∫Ü‰∏ÄÂÄãÁî®ÊñºÊé®Ë´ñÈö±ÁßÅ‰øùË≠∑Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊ°ÜÊû∂Ôºå‰∏¶ÁÇ∫Ê™¢Ë¶ñÈö±ÁßÅ‰øùË≠∑ÂíåÊïàÁî®‰πãÈñìÁöÑ‰∫§‰∫í‰ΩúÁî®Â•†ÂÆö‰∫ÜÁ©©Âõ∫ÁöÑÁêÜË´ñÂü∫Á§é„ÄÇÊ†∏ÂøÉË¶ãËß£Ë¢´Â∞ÅË£ùÂú®‰∏ÄÂÄãË¢´Á®±ÁÇ∫ NFLÔºàÂÖçË≤ªÂçàÈ§êÂÆöÁêÜÁöÑÁ∏ÆÂØ´ÔºâÂÆöÁêÜ‰∏≠„ÄÇ

##### **Unraveling and Mitigating Retriever Inconsistencies in Retrieval-Augmented Large Language Models**
2405.20680v2 by Mingda Li, Xinyu Li, Yifan Chen, Wenfeng Xuan, Weinan Zhang

Although Retrieval-Augmented Large Language Models (RALMs) demonstrate their
superiority in terms of factuality, they do not consistently outperform the
original retrieval-free Language Models (LMs). Our experiments reveal that this
example-level performance inconsistency exists not only between
retrieval-augmented and retrieval-free LM but also among different retrievers.
To understand this phenomenon, we investigate the degeneration behavior of
RALMs and theoretically decompose it into four categories. Further analysis
based on our decomposition reveals that the innate difference in knowledge
sources and the unpredictable degeneration of the reader model contribute most
to the inconsistency. Drawing from our analysis, we introduce Ensemble of
Retrievers (EoR), a trainable framework that can adaptively retrieve from
different knowledge sources and effectively decrease unpredictable reader
errors. Our experiments on Open Domain Question Answering show that EoR
substantially improves performance over the RALM with a single retriever by
considerably reducing inconsistent behaviors.

ÊëòË¶ÅÔºöÂÑòÁÆ°Ê™¢Á¥¢Â¢ûÂº∑Â§ßÂûãË™ûË®ÄÊ®°Âûã (RALM) Âú®‰∫ãÂØ¶ÊÄßÊñπÈù¢Â±ïÁèæÂÖ∂ÂÑ™Ë∂äÊÄßÔºå‰ΩÜÂÆÉÂÄë‰∏¶ÈùûÂßãÁµÇÂÑ™ÊñºÂéüÂßãÁöÑÈùûÊ™¢Á¥¢Ë™ûË®ÄÊ®°Âûã (LM)„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÊè≠Á§∫ÔºåÈÄôÁ®ÆÁØÑ‰æãÂ±§Á¥öÊïàËÉΩ‰∏ç‰∏ÄËá¥‰∏çÂÉÖÂ≠òÂú®ÊñºÊ™¢Á¥¢Â¢ûÂº∑ÂíåÈùûÊ™¢Á¥¢ LM ‰πãÈñìÔºå‰πüÂ≠òÂú®Êñº‰∏çÂêåÁöÑÊ™¢Á¥¢Âô®‰πãÈñì„ÄÇÁÇ∫‰∫Ü‰∫ÜËß£ÈÄôÁ®ÆÁèæË±°ÔºåÊàëÂÄëÁ†îÁ©∂‰∫Ü RALM ÁöÑÈÄÄÂåñË°åÁÇ∫Ôºå‰∏¶Âú®ÁêÜË´ñ‰∏äÂ∞áÂÖ∂ÂàÜËß£ÁÇ∫ÂõõÁ®ÆÈ°ûÂà•„ÄÇÊ†πÊìöÊàëÂÄëÁöÑÂàÜËß£ÈÄ≤Ë°åÈÄ≤‰∏ÄÊ≠•ÁöÑÂàÜÊûêÔºåÊè≠Á§∫‰∫ÜÁü•Ë≠ò‰æÜÊ∫êÁöÑÂÖßÂú®Â∑ÆÁï∞ÂíåÈñ±ËÆÄÂô®Ê®°Âûã‰∏çÂèØÈ†êÊ∏¨ÁöÑÈÄÄÂåñÂ∞ç‰∏ç‰∏ÄËá¥ÊÄßÁöÑÂΩ±ÈüøÊúÄÂ§ß„ÄÇÊ†πÊìöÊàëÂÄëÁöÑÂàÜÊûêÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜÊ™¢Á¥¢Âô®ÂêàÂ•è (EoR)ÔºåÈÄôÊòØ‰∏ÄÂÄãÂèØË®ìÁ∑¥ÁöÑÊû∂ÊßãÔºåÂèØ‰ª•Ëá™ÈÅ©ÊáâÂú∞Âæû‰∏çÂêåÁöÑÁü•Ë≠ò‰æÜÊ∫ê‰∏≠Ê™¢Á¥¢Ôºå‰∏¶ÊúâÊïàÊ∏õÂ∞ë‰∏çÂèØÈ†êÊ∏¨ÁöÑÈñ±ËÆÄÂô®ÈåØË™§„ÄÇÊàëÂÄëÂú®ÈñãÊîæÈ†òÂüüÂïèÁ≠î‰∏äÁöÑÂØ¶È©óË°®ÊòéÔºåEoR Â§ßÂπÖÊîπÂñÑ‰∫Ü‰ΩøÁî®ÂñÆ‰∏ÄÊ™¢Á¥¢Âô®ÁöÑ RALM ÁöÑÊïàËÉΩÔºåÊñπÊ≥ïÊòØÂ§ßÂπÖÊ∏õÂ∞ë‰∏ç‰∏ÄËá¥ÁöÑË°åÁÇ∫„ÄÇ

##### **Adv-KD: Adversarial Knowledge Distillation for Faster Diffusion Sampling**
2405.20675v1 by Kidist Amde Mekonnen, Nicola Dall'Asen, Paolo Rota

Diffusion Probabilistic Models (DPMs) have emerged as a powerful class of
deep generative models, achieving remarkable performance in image synthesis
tasks. However, these models face challenges in terms of widespread adoption
due to their reliance on sequential denoising steps during sample generation.
This dependence leads to substantial computational requirements, making them
unsuitable for resource-constrained or real-time processing systems. To address
these challenges, we propose a novel method that integrates denoising phases
directly into the model's architecture, thereby reducing the need for
resource-intensive computations. Our approach combines diffusion models with
generative adversarial networks (GANs) through knowledge distillation, enabling
more efficient training and evaluation. By utilizing a pre-trained diffusion
model as a teacher model, we train a student model through adversarial
learning, employing layerwise transformations for denoising and submodules for
predicting the teacher model's output at various points in time. This
integration significantly reduces the number of parameters and denoising steps
required, leading to improved sampling speed at test time. We validate our
method with extensive experiments, demonstrating comparable performance with
reduced computational requirements compared to existing approaches. By enabling
the deployment of diffusion models on resource-constrained devices, our
research mitigates their computational burden and paves the way for wider
accessibility and practical use across the research community and end-users.
  Our code is publicly available at https://github.com/kidist-amde/Adv-KD

ÊëòË¶ÅÔºöÊì¥Êï£Ê©üÁéáÊ®°Âûã (DPM) Â∑≤ÊàêÁÇ∫‰∏ÄÁ®ÆÂº∑Â§ßÁöÑÊ∑±Â∫¶ÁîüÊàêÊ®°ÂûãÔºåÂú®ÂΩ±ÂÉèÂêàÊàê‰ªªÂãô‰∏≠ÂèñÂæóÂçìË∂äÁöÑË°®Áèæ„ÄÇÁÑ∂ËÄåÔºåÁî±ÊñºÈÄô‰∫õÊ®°ÂûãÂú®Ê®£Êú¨ÁîüÊàêÊúüÈñì‰æùË≥¥ÊñºÂæ™Â∫èÊº∏ÈÄ≤ÁöÑÂéªÂô™Ê≠•È©üÔºåÂõ†Ê≠§Âú®Âª£Ê≥õÊé°Áî®ÊñπÈù¢Èù¢Ëá®ÊåëÊà∞„ÄÇÈÄôÁ®Æ‰æùË≥¥ÊÄßÂ∞éËá¥Â§ßÈáèÁöÑÈÅãÁÆóÈúÄÊ±ÇÔºå‰ΩøÂÆÉÂÄë‰∏çÈÅ©ÂêàË≥áÊ∫êÂèóÈôêÊàñÂç≥ÊôÇËôïÁêÜÁ≥ªÁµ±„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞ÊñπÊ≥ïÔºåÂ∞áÂéªÂô™ÈöéÊÆµÁõ¥Êé•Êï¥ÂêàÂà∞Ê®°ÂûãÊû∂Êßã‰∏≠ÔºåÂæûËÄåÊ∏õÂ∞ëÂ∞çË≥áÊ∫êÂØÜÈõÜÂûãÈÅãÁÆóÁöÑÈúÄÊ±Ç„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÈÄèÈÅéÁü•Ë≠òËí∏È§æÁµêÂêàÊì¥Êï£Ê®°ÂûãËàáÁîüÊàêÂ∞çÊäóÁ∂≤Ë∑Ø (GAN)ÔºåÂØ¶ÁèæÊõ¥ÊúâÊïàÁöÑË®ìÁ∑¥ÂíåË©ï‰º∞„ÄÇÈÄèÈÅéÂà©Áî®È†êÂÖàË®ìÁ∑¥ÁöÑÊì¥Êï£Ê®°Âûã‰ΩúÁÇ∫ÊïôÂ∏´Ê®°ÂûãÔºåÊàëÂÄëÈÄèÈÅéÂ∞çÊäóÂºèÂ≠∏ÁøíË®ìÁ∑¥Â≠∏ÁîüÊ®°ÂûãÔºåÊé°Áî®Â±§Á¥öËΩâÊèõÈÄ≤Ë°åÂéªÂô™Ôºå‰∏¶Êé°Áî®Â≠êÊ®°ÁµÑÂú®ÊôÇÈñìÁöÑ‰∏çÂêåÈªûÈ†êÊ∏¨ÊïôÂ∏´Ê®°ÂûãÁöÑËº∏Âá∫„ÄÇÈÄôÁ®ÆÊï¥ÂêàÈ°ØËëóÊ∏õÂ∞ë‰∫ÜÊâÄÈúÄÁöÑÂèÉÊï∏ÂíåÂéªÂô™Ê≠•È©üÊï∏ÈáèÔºåÂæûËÄåÊèêÈ´ò‰∫ÜÊ∏¨Ë©¶ÊôÇÁöÑÊäΩÊ®£ÈÄüÂ∫¶„ÄÇÊàëÂÄëÈÄèÈÅéÂª£Ê≥õÁöÑÂØ¶È©óÈ©óË≠â‰∫ÜÊàëÂÄëÁöÑÊñπÊ≥ïÔºåË≠âÊòéËàáÁèæÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåÂú®Èôç‰ΩéÈÅãÁÆóÈúÄÊ±ÇÁöÑÊÉÖÊ≥Å‰∏ãÂÖ∑ÊúâÂèØÊØîËºÉÁöÑÊïàËÉΩ„ÄÇÈÄèÈÅéÂú®Ë≥áÊ∫êÂèóÈôêÁöÑË£ùÁΩÆ‰∏äÈÉ®ÁΩ≤Êì¥Êï£Ê®°ÂûãÔºåÊàëÂÄëÁöÑÁ†îÁ©∂Ê∏õËºï‰∫ÜÂÆÉÂÄëÁöÑÈÅãÁÆóË≤†ÊìîÔºå‰∏¶ÁÇ∫Á†îÁ©∂Á§æÁæ§ÂíåÊúÄÁµÇ‰ΩøÁî®ËÄÖ‰πãÈñìÊõ¥Âª£Ê≥õÁöÑÂèØÂèäÊÄßÂíåÂØ¶ÈöõÁî®ÈÄîÈã™Âπ≥‰∫ÜÈÅìË∑Ø„ÄÇÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÂèØÂú® https://github.com/kidist-amde/Adv-KD ÂÖ¨ÈñãÂèñÂæó

##### **DORY: Deliberative Prompt Recovery for LLM**
2405.20657v1 by Lirong Gao, Ru Peng, Yiming Zhang, Junbo Zhao

Prompt recovery in large language models (LLMs) is crucial for understanding
how LLMs work and addressing concerns regarding privacy, copyright, etc. The
trend towards inference-only APIs complicates this task by restricting access
to essential outputs for recovery. To tackle this challenge, we extract
prompt-related information from limited outputs and identify a strong(negative)
correlation between output probability-based uncertainty and the success of
prompt recovery. This finding led to the development of Deliberative PrOmpt
RecoverY (DORY), our novel approach that leverages uncertainty to recover
prompts accurately. DORY involves reconstructing drafts from outputs, refining
these with hints, and filtering out noise based on uncertainty. Our evaluation
across diverse LLMs and prompt benchmarks shows that DORY outperforms existing
baselines, improving performance by approximately 10.82% and establishing a new
state-of-the-art record in prompt recovery tasks. Significantly, DORY operates
using a single LLM without any external resources or model, offering a
cost-effective, user-friendly prompt recovery solution.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰∏≠ÁöÑÊèêÁ§∫Âø´ÈÄüÂæ©ÂéüÂ∞çÊñºÁêÜËß£ LLM ÁöÑÈÅã‰ΩúÊñπÂºèÂíåËß£Ê±∫Èö±ÁßÅ„ÄÅÁâàÊ¨äÁ≠âÂïèÈ°åËá≥ÈóúÈáçË¶Å„ÄÇÂÉÖÈôêÊé®Ë´ñ API ÁöÑË∂®Âã¢ÊúÉÈôêÂà∂ÂèñÂæóÂæ©ÂéüÊâÄÈúÄÁöÑÈáçË¶ÅËº∏Âá∫Ôºå‰ΩøÈÄôÈ†Ö‰ªªÂãôËÆäÂæóÊõ¥Ë§áÈõú„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄôÈ†ÖÊåëÊà∞ÔºåÊàëÂÄëÂæûÊúâÈôêÁöÑËº∏Âá∫‰∏≠Êì∑ÂèñËàáÊèêÁ§∫Áõ∏ÈóúÁöÑË≥áË®äÔºå‰∏¶ÊâæÂá∫Ëº∏Âá∫Ê©üÁéá‰∏çÁ¢∫ÂÆöÊÄßËàáÊèêÁ§∫Âæ©ÂéüÊàêÂäüËàáÂê¶‰πãÈñìÁöÑÂº∑ÔºàË≤†ÔºâÈóúËÅØÊÄß„ÄÇÈÄôÈ†ÖÁôºÁèæ‰øÉÊàê‰∫Ü Deliberative PrOmpt RecoverY (DORY) ÁöÑÈñãÁôºÔºåÈÄôÈ†ÖÂâµÊñ∞ÊñπÊ≥ïÂà©Áî®‰∏çÁ¢∫ÂÆöÊÄß‰æÜÊ∫ñÁ¢∫Âæ©ÂéüÊèêÁ§∫„ÄÇDORY Ê∂âÂèäÂæûËº∏Âá∫‰∏≠ÈáçÂª∫ËçâÁ®øÔºåÂà©Áî®ÊèêÁ§∫Âä†‰ª•Á≤æÁÖâÔºå‰∏¶Ê†πÊìö‰∏çÁ¢∫ÂÆöÊÄßÈÅéÊøæÈõúË®ä„ÄÇÊàëÂÄëÂú®ÂêÑÁ®Æ LLM ÂíåÊèêÁ§∫Âü∫Ê∫ñ‰∏≠ÈÄ≤Ë°åË©ï‰º∞ÔºåÁµêÊûúÈ°ØÁ§∫ DORY ÂÑ™ÊñºÁèæÊúâÁöÑÂü∫Ê∫ñÔºåÂ∞áÊïàËÉΩÊèêÂçá‰∫ÜÁ¥Ñ 10.82%Ôºå‰∏¶Âú®ÊèêÁ§∫Âæ©Âéü‰ªªÂãô‰∏≠Ââµ‰∏ãÊñ∞ÁöÑÊäÄË°ìÊ∞¥Ê∫ñ„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåDORY ‰ΩøÁî®ÂñÆ‰∏Ä LLM ÈÅã‰ΩúÔºå‰∏ç‰ΩøÁî®‰ªª‰ΩïÂ§ñÈÉ®Ë≥áÊ∫êÊàñÊ®°ÂûãÔºåÊèê‰æõÂÖ∑ÊàêÊú¨ÊïàÁõä‰∏î‰ΩøÁî®ËÄÖÂèãÂñÑÁöÑÊèêÁ§∫Âæ©ÂéüËß£Ê±∫ÊñπÊ°à„ÄÇ

##### **Passage-specific Prompt Tuning for Passage Reranking in Question Answering with Large Language Models**
2405.20654v1 by Xuyang Wu, Zhiyuan Peng, Sravanthi Rajanala, Hsin-Tai Wu, Yi Fang

Effective passage retrieval and reranking methods have been widely utilized
to identify suitable candidates in open-domain question answering tasks, recent
studies have resorted to LLMs for reranking the retrieved passages by the
log-likelihood of the question conditioned on each passage. Although these
methods have demonstrated promising results, the performance is notably
sensitive to the human-written prompt (or hard prompt), and fine-tuning LLMs
can be computationally intensive and time-consuming. Furthermore, this approach
limits the leverage of question-passage relevance pairs and passage-specific
knowledge to enhance the ranking capabilities of LLMs. In this paper, we
propose passage-specific prompt tuning for reranking in open-domain question
answering (PSPT): a parameter-efficient method that fine-tunes learnable
passage-specific soft prompts, incorporating passage-specific knowledge from a
limited set of question-passage relevance pairs. The method involves ranking
retrieved passages based on the log-likelihood of the model generating the
question conditioned on each passage and the learned soft prompt. We conducted
extensive experiments utilizing the Llama-2-chat-7B model across three publicly
available open-domain question answering datasets and the results demonstrate
the effectiveness of the proposed approach.

ÊëòË¶ÅÔºöÊúâÊïàÁöÑÊÆµËêΩÊì∑ÂèñÂíåÈáçÊñ∞ÊéíÂ∫èÊñπÊ≥ïÂ∑≤Ë¢´Âª£Ê≥õÁî®ÊñºË≠òÂà•ÈñãÊîæÈ†òÂüüÂïèÈ°åÂõûÁ≠î‰ªªÂãô‰∏≠ÁöÑÂêàÈÅ©ÂÄôÈÅ∏ÊÆµËêΩÔºåÊúÄËøëÁöÑÁ†îÁ©∂Â∑≤Ë®¥Ë´∏ LLMs ÈÄèÈÅéÊØèÊÆµËêΩÊ¢ù‰ª∂‰∏ãÁöÑÂïèÈ°åÂ∞çÊï∏‰ººÁÑ∂ÂÄºÂ∞çÊì∑ÂèñÁöÑÊÆµËêΩÈÄ≤Ë°åÈáçÊñ∞ÊéíÂ∫è„ÄÇÂÑòÁÆ°ÈÄô‰∫õÊñπÊ≥ïÂ∑≤Â±ïÁ§∫Âá∫ÊúâÂ∏åÊúõÁöÑÁµêÊûúÔºå‰ΩÜÊïàËÉΩÈ°ØËëóÂú∞ÂèóÂà∞‰∫∫Â∑•Êí∞ÂØ´ÊèêÁ§∫ÔºàÊàñÁ°¨ÊèêÁ§∫ÔºâÁöÑÂΩ±ÈüøÔºå‰∏îÂæÆË™ø LLM ÂèØËÉΩÂú®Ë®àÁÆó‰∏äÂæàÂØÜÈõÜ‰∏îËÄóÊôÇ„ÄÇÊ≠§Â§ñÔºåÊ≠§ÊñπÊ≥ïÈôêÂà∂‰∫ÜÂïèÈ°åÊÆµËêΩÁõ∏ÈóúÊÄßÂ∞çÂíåÊÆµËêΩÁâπÂÆöÁü•Ë≠òÁöÑÊßìÊ°ø‰ΩúÁî®Ôºå‰ª•Â¢ûÂº∑ LLM ÁöÑÊéíÂ∫èËÉΩÂäõ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫ÈñãÊîæÈ†òÂüüÂïèÈ°åÂõûÁ≠î‰∏≠ÁöÑÊÆµËêΩÁâπÂÆöÊèêÁ§∫Ë™øÊï¥‰ª•ÈÄ≤Ë°åÈáçÊñ∞ÊéíÂ∫èÔºàPSPTÔºâÔºö‰∏ÄÁ®ÆÂèÉÊï∏ÊúâÊïàÁéáÁöÑÊñπÊ≥ïÔºåÂæÆË™øÂèØÂ≠∏ÁøíÁöÑÊÆµËêΩÁâπÂÆöËªüÊèêÁ§∫Ôºå‰∏¶Âæû‰∏ÄÁµÑÊúâÈôêÁöÑÂïèÈ°åÊÆµËêΩÁõ∏ÈóúÊÄßÂ∞ç‰∏≠Á¥çÂÖ•ÊÆµËêΩÁâπÂÆöÁü•Ë≠ò„ÄÇÊ≠§ÊñπÊ≥ïÊ∂âÂèäÊ†πÊìöÊ®°ÂûãÂú®ÊØèÊÆµËêΩÊ¢ù‰ª∂‰∏ãÁî¢ÁîüÂïèÈ°åÁöÑÂ∞çÊï∏‰ººÁÑ∂ÂÄºÂíåÂ≠∏ÁøíÁöÑËªüÊèêÁ§∫Â∞çÊì∑ÂèñÁöÑÊÆµËêΩÈÄ≤Ë°åÊéíÂ∫è„ÄÇÊàëÂÄëÂà©Áî® Llama-2-chat-7B Ê®°ÂûãÂ∞ç‰∏âÂÄãÂÖ¨ÈñãÂèØÁî®ÁöÑÈñãÊîæÈ†òÂüüÂïèÈ°åÂõûÁ≠îË≥áÊñôÈõÜÈÄ≤Ë°åÂª£Ê≥õÁöÑÂØ¶È©óÔºåÁµêÊûúË≠âÊòé‰∫ÜÊâÄÊèêÂá∫ÊñπÊ≥ïÁöÑÊúâÊïàÊÄß„ÄÇ

##### **Enhancing Jailbreak Attack Against Large Language Models through Silent Tokens**
2405.20653v1 by Jiahao Yu, Haozheng Luo, Jerry Yao-Chieh, Wenbo Guo, Han Liu, Xinyu Xing

Along with the remarkable successes of Language language models, recent
research also started to explore the security threats of LLMs, including
jailbreaking attacks. Attackers carefully craft jailbreaking prompts such that
a target LLM will respond to the harmful question. Existing jailbreaking
attacks require either human experts or leveraging complicated algorithms to
craft jailbreaking prompts. In this paper, we introduce BOOST, a simple attack
that leverages only the eos tokens. We demonstrate that rather than
constructing complicated jailbreaking prompts, the attacker can simply append a
few eos tokens to the end of a harmful question. It will bypass the safety
alignment of LLMs and lead to successful jailbreaking attacks. We further apply
BOOST to four representative jailbreak methods and show that the attack success
rates of these methods can be significantly enhanced by simply adding eos
tokens to the prompt. To understand this simple but novel phenomenon, we
conduct empirical analyses. Our analysis reveals that adding eos tokens makes
the target LLM believe the input is much less harmful, and eos tokens have low
attention values and do not affect LLM's understanding of the harmful
questions, leading the model to actually respond to the questions. Our findings
uncover how fragile an LLM is against jailbreak attacks, motivating the
development of strong safety alignment approaches.

ÊëòË¶ÅÔºöÈö®ËëóË™ûË®ÄË™ûË®ÄÊ®°ÂûãÁöÑÈ°ØËëóÊàêÂäüÔºåÊúÄËøëÁöÑÁ†îÁ©∂‰πüÈñãÂßãÊé¢Ë®é LLM ÁöÑÂÆâÂÖ®Â®ÅËÑÖÔºåÂåÖÊã¨Ë∂äÁçÑÊîªÊìä„ÄÇÊîªÊìäËÄÖ‰ªîÁ¥∞Ë£Ω‰ΩúË∂äÁçÑÊèêÁ§∫Ôºå‰ª•‰æøÁõÆÊ®ô LLM Â∞çÊúâÂÆ≥ÂïèÈ°åÂÅöÂá∫ÂõûÊáâ„ÄÇÁèæÊúâÁöÑË∂äÁçÑÊîªÊìäÈúÄË¶Å‰∫∫È°ûÂ∞àÂÆ∂ÊàñÂà©Áî®Ë§áÈõúÁöÑÊºîÁÆóÊ≥ï‰æÜË£Ω‰ΩúË∂äÁçÑÊèêÁ§∫„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫Ü BOOSTÔºåÈÄôÊòØ‰∏ÄÁ®ÆÂÉÖÂà©Áî® eos Á¨¶ËôüÁöÑÁ∞°ÂñÆÊîªÊìä„ÄÇÊàëÂÄëË≠âÊòéÔºåÊîªÊìäËÄÖ‰∏çÂøÖÂª∫ÊßãË§áÈõúÁöÑË∂äÁçÑÊèêÁ§∫ÔºåÂè™ÈúÄÂú®ÊúâÂÆ≥ÂïèÈ°åÁöÑÁµêÂ∞æÈôÑÂä†ÂπæÂÄã eos Á¨¶ËôüÂç≥ÂèØ„ÄÇÂÆÉÂ∞áÁπûÈÅé LLM ÁöÑÂÆâÂÖ®ÊØîÂ∞çÔºå‰∏¶Â∞éËá¥ÊàêÂäüÁöÑË∂äÁçÑÊîªÊìä„ÄÇÊàëÂÄëÈÄ≤‰∏ÄÊ≠•Â∞á BOOST ÊáâÁî®ÊñºÂõõÁ®Æ‰ª£Ë°®ÊÄßÁöÑË∂äÁçÑÊñπÊ≥ïÔºå‰∏¶Ë°®ÊòéÂè™ÈúÄÂú®ÊèêÁ§∫‰∏≠Âä†ÂÖ• eos Á¨¶ËôüÔºåÂç≥ÂèØÈ°ØËëóÊèêÈ´òÈÄô‰∫õÊñπÊ≥ïÁöÑÊîªÊìäÊàêÂäüÁéá„ÄÇÁÇ∫‰∫ÜÁêÜËß£ÈÄôÁ®ÆÁ∞°ÂñÆ‰ΩÜÊñ∞Á©éÁöÑÁèæË±°ÔºåÊàëÂÄëÈÄ≤Ë°å‰∫ÜÂØ¶Ë≠âÂàÜÊûê„ÄÇÊàëÂÄëÁöÑÂàÜÊûêË°®ÊòéÔºåÂä†ÂÖ• eos Á¨¶ËôüÊúÉËÆìÁõÆÊ®ô LLM Ë™çÁÇ∫Ëº∏ÂÖ•ÁöÑÂç±ÂÆ≥ÊÄßÂ∞èÂæóÂ§öÔºåËÄå eos Á¨¶ËôüÁöÑÊ≥®ÊÑèÂäõÂÄº‰ΩéÔºå‰∏î‰∏çÊúÉÂΩ±Èüø LLM Â∞çÊúâÂÆ≥ÂïèÈ°åÁöÑÁêÜËß£ÔºåÂ∞éËá¥Ê®°ÂûãÂØ¶Èöõ‰∏äÂ∞çÂïèÈ°åÂÅöÂá∫ÂõûÊáâ„ÄÇÊàëÂÄëÁöÑÁôºÁèæÊè≠Á§∫‰∫Ü LLM Â∞çË∂äÁçÑÊîªÊìäÁöÑËÑÜÂº±ÊÄßÔºåÊøÄÂãµ‰∫ÜÂº∑Â§ßÁöÑÂÆâÂÖ®ÊØîÂ∞çÊñπÊ≥ïÁöÑÈñãÁôº„ÄÇ

##### **Reward-based Input Construction for Cross-document Relation Extraction**
2405.20649v1 by Byeonghu Na, Suhyeon Jo, Yeongmin Kim, Il-Chul Moon

Relation extraction (RE) is a fundamental task in natural language
processing, aiming to identify relations between target entities in text. While
many RE methods are designed for a single sentence or document, cross-document
RE has emerged to address relations across multiple long documents. Given the
nature of long documents in cross-document RE, extracting document embeddings
is challenging due to the length constraints of pre-trained language models.
Therefore, we propose REward-based Input Construction (REIC), the first
learning-based sentence selector for cross-document RE. REIC extracts sentences
based on relational evidence, enabling the RE module to effectively infer
relations. Since supervision of evidence sentences is generally unavailable, we
train REIC using reinforcement learning with RE prediction scores as rewards.
Experimental results demonstrate the superiority of our method over heuristic
methods for different RE structures and backbones in cross-document RE. Our
code is publicly available at https://github.com/aailabkaist/REIC.

ÊëòË¶ÅÔºöÈóú‰øÇÊäΩÂèñ (RE) ÊòØËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ‰∏≠‰∏ÄÈ†ÖÂü∫Êú¨‰ªªÂãôÔºåÊó®Âú®ÊâæÂá∫ÊñáÂ≠ó‰∏≠ÁõÆÊ®ôÂØ¶È´î‰πãÈñìÁöÑÈóú‰øÇ„ÄÇÂÑòÁÆ°Ë®±Â§ö RE ÊñπÊ≥ïÊòØÈáùÂ∞çÂñÆ‰∏ÄÂè•Â≠êÊàñÊñá‰ª∂Ë®≠Ë®àÔºåË∑®Êñá‰ª∂ RE Â∑≤ÊáâÈÅãËÄåÁîüÔºåÁî®ÊñºËôïÁêÜË∑®Â§öÂÄãÈï∑Êñá‰ª∂ÁöÑÈóú‰øÇ„ÄÇËÄÉÈáèÂà∞Ë∑®Êñá‰ª∂ RE ‰∏≠Èï∑Êñá‰ª∂ÁöÑÊÄßË≥™ÔºåÁî±ÊñºÈ†êË®ìÁ∑¥Ë™ûË®ÄÊ®°ÂûãÁöÑÈï∑Â∫¶ÈôêÂà∂ÔºåÊèêÂèñÊñá‰ª∂ÂµåÂÖ•Áõ∏Áï∂ÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëÊèêÂá∫Âü∫Êñº RE ÁçéÂãµÁöÑËº∏ÂÖ•Âª∫Êßã (REIC)ÔºåÈÄôÊòØÁ¨¨‰∏ÄÂÄãÁî®ÊñºË∑®Êñá‰ª∂ RE ÁöÑÂü∫ÊñºÂ≠∏ÁøíÁöÑÂè•Â≠êÈÅ∏ÊìáÂô®„ÄÇREIC Âü∫ÊñºÈóú‰øÇË≠âÊìöÊèêÂèñÂè•Â≠êÔºåËÆì RE Ê®°ÁµÑËÉΩÂ§†ÊúâÊïàÊé®Ë´ñÈóú‰øÇ„ÄÇÁî±ÊñºË≠âÊìöÂè•Â≠êÁöÑÁõ£Áù£ÈÄöÂ∏∏‰∏çÂèØÁî®ÔºåÊàëÂÄë‰ΩøÁî®Âº∑ÂåñÂ≠∏ÁøíË®ìÁ∑¥ REICÔºå‰∏¶‰ª• RE È†êÊ∏¨ÂàÜÊï∏‰ΩúÁÇ∫ÁçéÂãµ„ÄÇÂØ¶È©óÁµêÊûúË≠âÊòéÔºåÂú®Ë∑®Êñá‰ª∂ RE ‰∏≠ÔºåÊàëÂÄëÁöÑÊ®°ÂûãÂÑ™Êñº‰∏çÂêå RE ÁµêÊßãÂíå‰∏ªÂππÁöÑÂïüÁôºÂºèÊñπÊ≥ï„ÄÇÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÂ∑≤ÂÖ¨ÈñãÁôºÂ∏ÉÊñº https://github.com/aailabkaist/REIC„ÄÇ

##### **Shotluck Holmes: A Family of Efficient Small-Scale Large Language Vision Models For Video Captioning and Summarization**
2405.20648v1 by Richard Luo, Austin Peng, Adithya Vasudev, Rishabh Jain

Video is an increasingly prominent and information-dense medium, yet it poses
substantial challenges for language models. A typical video consists of a
sequence of shorter segments, or shots, that collectively form a coherent
narrative. Each shot is analogous to a word in a sentence where multiple data
streams of information (such as visual and auditory data) must be processed
simultaneously. Comprehension of the entire video requires not only
understanding the visual-audio information of each shot but also requires that
the model links the ideas between each shot to generate a larger,
all-encompassing story. Despite significant progress in the field, current
works often overlook videos' more granular shot-by-shot semantic information.
In this project, we propose a family of efficient large language vision models
(LLVMs) to boost video summarization and captioning called Shotluck Holmes. By
leveraging better pretraining and data collection strategies, we extend the
abilities of existing small LLVMs from being able to understand a picture to
being able to understand a sequence of frames. Specifically, we show that
Shotluck Holmes achieves better performance than state-of-the-art results on
the Shot2Story video captioning and summary task with significantly smaller and
more computationally efficient models.

ÊëòË¶ÅÔºöÂΩ±ÁâáÊòØ‰∏ÄÁ®ÆË∂ä‰æÜË∂äÈ°ØËëó‰∏îË≥áË®äÂØÜÈõÜÁöÑÂ™í‰ªãÔºå‰ΩÜÂÆÉÂ∞çË™ûË®ÄÊ®°ÂûãÂçªÊßãÊàêÈáçÂ§ßÁöÑÊåëÊà∞„ÄÇ‰∏ÄÈÉ®ÂÖ∏ÂûãÁöÑÂΩ±ÁâáÂåÖÂê´‰∏ÄÁ≥ªÂàóËºÉÁü≠ÁöÑÁâáÊÆµÊàñÈè°È†≠ÔºåÂÆÉÂÄëÂÖ±ÂêåÂΩ¢Êàê‰∏ÄÂÄãÈÄ£Ë≤´ÁöÑÊïÖ‰∫ã„ÄÇÊØèÂÄãÈè°È†≠È°û‰ººÊñºÂè•Â≠ê‰∏≠ÁöÑÂñÆÂ≠óÔºåÂÖ∂‰∏≠ÂøÖÈ†àÂêåÊôÇËôïÁêÜÂ§öÂÄãË≥áË®äË≥áÊñô‰∏≤ÊµÅÔºà‰æãÂ¶ÇË¶ñË¶∫ÂíåËÅΩË¶∫Ë≥áÊñôÔºâ„ÄÇË¶ÅÁêÜËß£Êï¥ÈÉ®ÂΩ±ÁâáÔºå‰∏çÂÉÖÈúÄË¶ÅÁêÜËß£ÊØèÂÄãÈè°È†≠ÁöÑË¶ñË¶∫ÂíåËÅΩË¶∫Ë≥áË®äÔºåÈÇÑÈúÄË¶ÅÊ®°ÂûãÈÄ£ÁµêÊØèÂÄãÈè°È†≠‰πãÈñìÁöÑÊÉ≥Ê≥ïÔºå‰ª•Áî¢Áîü‰∏ÄÂÄãÊõ¥Â§ß‰∏îÂåÖÁæÖËê¨Ë±°ÁöÑÊïÖ‰∫ã„ÄÇÂÑòÁÆ°Ë©≤È†òÂüüÊúâÈ°ØËëóÁöÑÈÄ≤Â±ïÔºå‰ΩÜÁõÆÂâçÁöÑËëó‰ΩúÁ∂ìÂ∏∏ÂøΩÁï•ÂΩ±ÁâáÊõ¥Á≤æÁ¥∞ÁöÑÈÄêÈè°È†≠Ë™ûÁæ©Ë≥áË®ä„ÄÇÂú®ÈÄôÂÄãÂ∞àÊ°à‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ≥ªÂàóÊúâÊïàÁéáÁöÑÂ§ßÂûãË™ûË®ÄË¶ñË¶∫Ê®°Âûã (LLVM)Ôºå‰ª•ÊèêÂçáÂΩ±ÁâáÊëòË¶ÅÂíåÂ≠óÂπïÔºåÁ®±ÁÇ∫ Shotluck Holmes„ÄÇÈÄèÈÅéÂà©Áî®Êõ¥Â•ΩÁöÑÈ†êË®ìÁ∑¥ÂíåË≥áÊñôÊî∂ÈõÜÁ≠ñÁï•ÔºåÊàëÂÄëÊì¥ÂÖÖ‰∫ÜÁèæÊúâÂ∞èÂûã LLVMs ÁöÑËÉΩÂäõÔºåÂæûËÉΩÂ§†ÁêÜËß£ÂúñÁâáÂà∞ËÉΩÂ§†ÁêÜËß£‰∏ÄÁ≥ªÂàóÁöÑÂΩ±Ê†º„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëË≠âÊòé Shotluck Holmes Âú® Shot2Story ÂΩ±ÁâáÂ≠óÂπïÂíåÊëòË¶Å‰ªªÂãô‰∏äÔºå‰ª•È°ØËëóÊõ¥Â∞è‰∏îË®àÁÆóÊïàÁéáÊõ¥È´òÁöÑÊ®°ÂûãÔºåÈÅîÂà∞‰∫ÜÊØîÊúÄÂÖàÈÄ≤ÁöÑÁµêÊûúÊõ¥Â•ΩÁöÑÊïàËÉΩ„ÄÇ

##### **Large Language Models Enhanced Sequential Recommendation for Long-tail User and Item**
2405.20646v1 by Qidong Liu, Xian Wu, Xiangyu Zhao, Yejing Wang, Zijian Zhang, Feng Tian, Yefeng Zheng

Sequential recommendation systems (SRS) serve the purpose of predicting
users' subsequent preferences based on their past interactions and have been
applied across various domains such as e-commerce and social networking
platforms. However, practical SRS encounters challenges due to the fact that
most users engage with only a limited number of items, while the majority of
items are seldom consumed. These challenges, termed as the long-tail user and
long-tail item dilemmas, often create obstacles for traditional SRS methods.
Mitigating these challenges is crucial as they can significantly impact user
satisfaction and business profitability. While some research endeavors have
alleviated these issues, they still grapple with issues such as seesaw or noise
stemming from the scarcity of interactions. The emergence of large language
models (LLMs) presents a promising avenue to address these challenges from a
semantic standpoint. In this study, we introduce the Large Language Models
Enhancement framework for Sequential Recommendation (LLM-ESR), which leverages
semantic embeddings from LLMs to enhance SRS performance without increasing
computational overhead. To combat the long-tail item challenge, we propose a
dual-view modeling approach that fuses semantic information from LLMs with
collaborative signals from traditional SRS. To address the long-tail user
challenge, we introduce a retrieval augmented self-distillation technique to
refine user preference representations by incorporating richer interaction data
from similar users. Through comprehensive experiments conducted on three
authentic datasets using three widely used SRS models, our proposed enhancement
framework demonstrates superior performance compared to existing methodologies.

ÊëòË¶ÅÔºöÂ∫èË≤´Êé®Ëñ¶Á≥ªÁµ± (SRS) ÁöÑÁõÆÁöÑÊòØÊ†πÊìö‰ΩøÁî®ËÄÖÁöÑÈÅéÂéª‰∫íÂãïÈ†êÊ∏¨‰ªñÂÄëÂæåÁ∫åÁöÑÂÅèÂ•ΩÔºå‰∏¶Â∑≤ÊáâÁî®ÊñºÈõªÂ≠êÂïÜÂãôÂíåÁ§æÁæ§Á∂≤Ë∑ØÂπ≥Âè∞Á≠âÂêÑÁ®ÆÈ†òÂüü„ÄÇÁÑ∂ËÄåÔºåÂØ¶ÈöõÁöÑ SRS ÊúÉÈÅáÂà∞ÊåëÊà∞ÔºåÂõ†ÁÇ∫Â§ßÂ§öÊï∏‰ΩøÁî®ËÄÖÂè™ÊúÉËàáÊúâÈôêÊï∏ÈáèÁöÑÈ†ÖÁõÆ‰∫íÂãïÔºåËÄåÂ§ßÂ§öÊï∏È†ÖÁõÆÂæàÂ∞ëË¢´‰ΩøÁî®„ÄÇÈÄô‰∫õÊåëÊà∞Ë¢´Á®±ÁÇ∫Èï∑Â∞æ‰ΩøÁî®ËÄÖÂíåÈï∑Â∞æÈ†ÖÁõÆÂõ∞Â¢ÉÔºåÈÄöÂ∏∏ÊúÉÁÇ∫ÂÇ≥Áµ± SRS ÊñπÊ≥ïË£ΩÈÄ†ÈöúÁ§ô„ÄÇÁ∑©Ëß£ÈÄô‰∫õÊåëÊà∞Ëá≥ÈóúÈáçË¶ÅÔºåÂõ†ÁÇ∫ÂÆÉÂÄëÊúÉÂ∞ç‰ΩøÁî®ËÄÖÊªøÊÑèÂ∫¶ÂíåÊ•≠ÂãôÁç≤Âà©ËÉΩÂäõÁî¢ÁîüÈáçÂ§ßÂΩ±Èüø„ÄÇÈõñÁÑ∂Êúâ‰∫õÁ†îÁ©∂Âä™ÂäõÂ∑≤Á∂ìÁ∑©Ëß£‰∫ÜÈÄô‰∫õÂïèÈ°åÔºå‰ΩÜÂÆÉÂÄë‰ªçÁÑ∂Âú®Âõ†‰∫íÂãïÁ®ÄÂ∞ëËÄåÁî¢ÁîüÁöÑËπ∫Ëπ∫ÊùøÊàñÈõúË®äÁ≠âÂïèÈ°å‰∏≠ÊéôÊâé„ÄÇÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÂá∫ÁèæÊèê‰æõ‰∫Ü‰∏ÄÂÄãÂæûË™ûÁæ©ËßÄÈªûËß£Ê±∫ÈÄô‰∫õÊåëÊà∞ÁöÑÊúâÂ∏åÊúõÁöÑÈÄîÂæë„ÄÇÂú®Êú¨Á†îÁ©∂‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫ÜÂ∫èË≤´Êé®Ëñ¶ÁöÑÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÂ¢ûÂº∑Êû∂Êßã (LLM-ESR)ÔºåÂÆÉÂà©Áî®‰æÜËá™ LLM ÁöÑË™ûÁæ©ÂµåÂÖ•‰æÜÂ¢ûÂº∑ SRS ÊïàËÉΩÔºåËÄå‰∏çÊúÉÂ¢ûÂä†ÈÅãÁÆóË≤†Êìî„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈï∑Â∞æÈ†ÖÁõÆÊåëÊà∞ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÈõôË¶ñËßíÂª∫Ê®°ÊñπÊ≥ïÔºåË©≤ÊñπÊ≥ïÂ∞á‰æÜËá™ LLM ÁöÑË™ûÁæ©Ë≥áË®äËàá‰æÜËá™ÂÇ≥Áµ± SRS ÁöÑÂçîÂêåË®äËôüËûçÂêàÂú®‰∏ÄËµ∑„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈï∑Â∞æ‰ΩøÁî®ËÄÖÊåëÊà∞ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÁ®ÆÊ™¢Á¥¢Â¢ûÂº∑Ëá™ÊàëËí∏È§æÊäÄË°ìÔºåÈÄöÈÅéÁ¥çÂÖ•‰æÜËá™È°û‰ºº‰ΩøÁî®ËÄÖÁöÑÊõ¥Ë±êÂØå‰∫íÂãïË≥áÊñô‰æÜÊîπÂñÑ‰ΩøÁî®ËÄÖÂÅèÂ•ΩË°®Âæµ„ÄÇÈÄèÈÅé‰ΩøÁî®‰∏âÂÄãÂª£Ê≥õ‰ΩøÁî®ÁöÑ SRS Ê®°ÂûãÂú®‰∏âÂÄãÁúüÂØ¶Ë≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÁöÑÂÖ®Èù¢ÂØ¶È©óÔºåÊàëÂÄëÊèêÂá∫ÁöÑÂ¢ûÂº∑Êû∂ÊßãÂ±ïÁ§∫‰∫ÜÂÑ™ÊñºÁèæÊúâÊñπÊ≥ïÁöÑÂçìË∂äÊïàËÉΩ„ÄÇ

##### **Learning Gaze-aware Compositional GAN**
2405.20643v1 by Nerea Aranjuelo, Siyu Huang, Ignacio Arganda-Carreras, Luis Unzueta, Oihana Otaegui, Hanspeter Pfister, Donglai Wei

Gaze-annotated facial data is crucial for training deep neural networks
(DNNs) for gaze estimation. However, obtaining these data is labor-intensive
and requires specialized equipment due to the challenge of accurately
annotating the gaze direction of a subject. In this work, we present a
generative framework to create annotated gaze data by leveraging the benefits
of labeled and unlabeled data sources. We propose a Gaze-aware Compositional
GAN that learns to generate annotated facial images from a limited labeled
dataset. Then we transfer this model to an unlabeled data domain to take
advantage of the diversity it provides. Experiments demonstrate our approach's
effectiveness in generating within-domain image augmentations in the ETH-XGaze
dataset and cross-domain augmentations in the CelebAMask-HQ dataset domain for
gaze estimation DNN training. We also show additional applications of our work,
which include facial image editing and gaze redirection.

ÊëòË¶ÅÔºöÁî®ÂáùË¶ñÊ®ôË®ªÁöÑ‰∫∫ËáâË≥áÊñôÂ∞çÊñºË®ìÁ∑¥Ê∑±Â∫¶Á•ûÁ∂ìÁ∂≤Ë∑Ø (DNN) ‰ª•ÈÄ≤Ë°åÂáùË¶ñ‰º∞Ë®àËá≥ÈóúÈáçË¶Å„ÄÇÁÑ∂ËÄåÔºåÂèñÂæóÈÄô‰∫õË≥áÊñôÈúÄË¶ÅÂ§ßÈáè‰∫∫ÂäõÔºå‰∏îÁî±ÊñºÊ∫ñÁ¢∫Ê®ôË®ªÂèóË©¶ËÄÖÁöÑÂáùË¶ñÊñπÂêëÂÖ∑ÊúâÊåëÊà∞ÊÄßÔºåÂõ†Ê≠§ÈúÄË¶ÅÂ∞àÊ•≠ÁöÑË®≠ÂÇô„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÁîüÊàêÂºèÊû∂ÊßãÔºåÈÄèÈÅéÂà©Áî®Ê®ôÁ±§Ë≥áÊñôÂíåÊú™Ê®ôÁ±§Ë≥áÊñô‰æÜÊ∫êÁöÑÂÑ™ÈªûÔºå‰æÜÂª∫Á´ãÊ®ôË®ªÁöÑÂáùË¶ñË≥áÊñô„ÄÇÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂáùË¶ñÊÑüÁü•ÂêàÊàê GANÔºåË©≤ GAN ÊúÉÂ≠∏ÁøíÂæûÊúâÈôêÁöÑÊ®ôÁ±§Ë≥áÊñôÈõÜ‰∏≠Áî¢ÁîüÊ®ôË®ªÁöÑ‰∫∫ËáâÂΩ±ÂÉè„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÂ∞áÊ≠§Ê®°ÂûãËΩâÁßªÂà∞Êú™Ê®ôÁ±§ÁöÑË≥áÊñôÁ∂≤ÂüüÔºå‰ª•Âà©Áî®ÂÖ∂ÊâÄÊèê‰æõÁöÑÂ§öÊ®£ÊÄß„ÄÇÂØ¶È©óË≠âÊòé‰∫ÜÊàëÂÄëÁöÑÊñπÊ≥ïÂú® ETH-XGaze Ë≥áÊñôÈõÜ‰∏≠Áî¢ÁîüÂêåÁ∂≤ÂüüÂΩ±ÂÉèÊì¥ÂÖÖÔºå‰ª•ÂèäÂú® CelebAMask-HQ Ë≥áÊñôÈõÜÁ∂≤Âüü‰∏≠Áî¢ÁîüË∑®Á∂≤ÂüüÊì¥ÂÖÖÁöÑÊúâÊïàÊÄßÔºå‰ª•ÈÄ≤Ë°åÂáùË¶ñ‰º∞Ë®à DNN Ë®ìÁ∑¥„ÄÇÊàëÂÄë‰πüÂ±ïÁ§∫‰∫ÜÊàëÂÄëÂ∑•‰ΩúÁöÑÂÖ∂‰ªñÊáâÁî®ÔºåÂåÖÊã¨‰∫∫ËáâÂΩ±ÂÉèÁ∑®ËºØÂíåÂáùË¶ñÈáçÊñ∞Â∞éÂêë„ÄÇ

##### **ToxVidLLM: A Multimodal LLM-based Framework for Toxicity Detection in Code-Mixed Videos**
2405.20628v1 by Krishanu Maity, A. S. Poornash, Sriparna Saha, Pushpak Bhattacharyya

In an era of rapidly evolving internet technology, the surge in multimodal
content, including videos, has expanded the horizons of online communication.
However, the detection of toxic content in this diverse landscape, particularly
in low-resource code-mixed languages, remains a critical challenge. While
substantial research has addressed toxic content detection in textual data, the
realm of video content, especially in non-English languages, has been
relatively underexplored. This paper addresses this research gap by introducing
a benchmark dataset, the first of its kind, consisting of 931 videos with 4021
code-mixed Hindi-English utterances collected from YouTube. Each utterance
within this dataset has been meticulously annotated for toxicity, severity, and
sentiment labels. We have developed an advanced Multimodal Multitask framework
built for Toxicity detection in Video Content by leveraging Large Language
Models (LLMs), crafted for the primary objective along with the additional
tasks of conducting sentiment and severity analysis. ToxVidLLM incorporates
three key modules the Encoder module, Cross-Modal Synchronization module, and
Multitask module crafting a generic multimodal LLM customized for intricate
video classification tasks. Our experiments reveal that incorporating multiple
modalities from the videos substantially enhances the performance of toxic
content detection by achieving an Accuracy and Weighted F1 score of 94.29% and
94.35%, respectively.

ÊëòË¶ÅÔºöÂú®‰∫íËÅîÁΩëÊäÄÊúØÂø´ÈÄüÂèëÂ±ïÁöÑÊó∂‰ª£ÔºåÂåÖÊã¨ËßÜÈ¢ëÂú®ÂÜÖÁöÑÂ§öÊ®°ÊÄÅÂÜÖÂÆπÊøÄÂ¢ûÔºåÊãìÂÆΩ‰∫ÜÂú®Á∫ø‰∫§ÊµÅÁöÑËßÜÈáé„ÄÇÁÑ∂ËÄåÔºåÂú®Ëøô‰∏ÄÂ§öÂÖÉÂåñÁöÑÈ¢ÜÂüü‰∏≠Ê£ÄÊµãÊúâÊØíÂÜÖÂÆπÔºåÂ∞§ÂÖ∂ÊòØÂú®ËµÑÊ∫êÂåÆ‰πèÁöÑ‰ª£Á†ÅÊ∑∑ÂêàËØ≠Ë®Ä‰∏≠Ôºå‰ªçÁÑ∂ÊòØ‰∏ÄÈ°π‰∏•Â≥ªÁöÑÊåëÊàò„ÄÇËôΩÁÑ∂Â§ßÈáèÁ†îÁ©∂Â∑≤ÁªèËß£ÂÜ≥‰∫ÜÊñáÊú¨Êï∞ÊçÆ‰∏≠ÁöÑÊúâÊØíÂÜÖÂÆπÊ£ÄÊµãÔºå‰ΩÜËßÜÈ¢ëÂÜÖÂÆπÈ¢ÜÂüüÔºåÂ∞§ÂÖ∂ÊòØÈùûËã±ËØ≠ËØ≠Ë®ÄÔºåÁõ∏ÂØπËÄåË®ÄÂ∞öÊú™ÂæóÂà∞ÂÖÖÂàÜÊé¢Á¥¢„ÄÇÊú¨ÊñáÈÄöËøáÂºïÂÖ•Âü∫ÂáÜÊï∞ÊçÆÈõÜÊù•Ëß£ÂÜ≥Ëøô‰∏ÄÁ†îÁ©∂Á©∫ÁôΩÔºåËØ•Êï∞ÊçÆÈõÜÊòØÂêåÁ±ªÊï∞ÊçÆÈõÜ‰∏≠ÁöÑÁ¨¨‰∏Ä‰∏™ÔºåÂåÖÂê´ 931 ‰∏™ËßÜÈ¢ëÔºåÂÖ∂‰∏≠Êúâ 4021 ‰∏™‰ª£Á†ÅÊ∑∑ÂêàÁöÑÂç∞Âú∞ËØ≠-Ëã±ËØ≠ËØùËØ≠ÔºåËøô‰∫õËØùËØ≠ÊòØ‰ªé YouTube Êî∂ÈõÜÁöÑ„ÄÇËØ•Êï∞ÊçÆÈõÜ‰∏≠ÁöÑÊØè‰∏™ËØùËØ≠ÈÉΩÁªèËøáÁ≤æÂøÉÊ≥®ÈáäÔºå‰ª•Ë°®Á§∫ÊØíÊÄß„ÄÅ‰∏•ÈáçÊÄßÂíåÊÉÖÁª™Ê†áÁ≠æ„ÄÇÊàë‰ª¨ÂºÄÂèë‰∫Ü‰∏Ä‰∏™ÂÖàËøõÁöÑÂ§öÊ®°ÊÄÅÂ§ö‰ªªÂä°Ê°ÜÊû∂ÔºåÁî®‰∫éÈÄöËøáÂà©Áî®Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã (LLM) Êù•Ê£ÄÊµãËßÜÈ¢ëÂÜÖÂÆπ‰∏≠ÁöÑÊØíÊÄßÔºåËØ•Ê°ÜÊû∂‰∏ì‰∏∫‰∏ªË¶ÅÁõÆÊ†á‰ª•ÂèäÊâßË°åÊÉÖÁª™Âíå‰∏•ÈáçÊÄßÂàÜÊûêÁöÑÈôÑÂä†‰ªªÂä°ËÄåËÆæËÆ°„ÄÇToxVidLLM ÈááÁî®‰∫Ü‰∏â‰∏™ÂÖ≥ÈîÆÊ®°ÂùóÔºöÁºñÁ†ÅÂô®Ê®°Âùó„ÄÅË∑®Ê®°ÊÄÅÂêåÊ≠•Ê®°ÂùóÂíåÂ§ö‰ªªÂä°Ê®°ÂùóÔºåÊâìÈÄ†‰∫Ü‰∏Ä‰∏™ÈíàÂØπÂ§çÊùÇËßÜÈ¢ëÂàÜÁ±ª‰ªªÂä°ÂÆöÂà∂ÁöÑÈÄöÁî®Â§öÊ®°ÊÄÅ LLM„ÄÇÊàë‰ª¨ÁöÑÂÆûÈ™åË°®ÊòéÔºåÈÄöËøáËßÜÈ¢ëÂêàÂπ∂Â§öÁßçÊ®°ÊÄÅÂèØ‰ª•Â§ßÂπÖÊèêÈ´òÊúâÊØíÂÜÖÂÆπÊ£ÄÊµãÁöÑÊÄßËÉΩÔºåÂáÜÁ°ÆÁéáÂíåÂä†ÊùÉ F1 ÂàÜÂà´ËææÂà∞ 94.29% Âíå 94.35%„ÄÇ

##### **Robust Planning with LLM-Modulo Framework: Case Study in Travel Planning**
2405.20625v1 by Atharva Gundawar, Mudit Verma, Lin Guan, Karthik Valmeekam, Siddhant Bhambri, Subbarao Kambhampati

As the applicability of Large Language Models (LLMs) extends beyond
traditional text processing tasks, there is a burgeoning interest in their
potential to excel in planning and reasoning assignments, realms traditionally
reserved for System 2 cognitive competencies. Despite their perceived
versatility, the research community is still unraveling effective strategies to
harness these models in such complex domains. The recent discourse introduced
by the paper on LLM Modulo marks a significant stride, proposing a conceptual
framework that enhances the integration of LLMs into diverse planning and
reasoning activities. This workshop paper delves into the practical application
of this framework within the domain of travel planning, presenting a specific
instance of its implementation. We are using the Travel Planning benchmark by
the OSU NLP group, a benchmark for evaluating the performance of LLMs in
producing valid itineraries based on user queries presented in natural
language. While popular methods of enhancing the reasoning abilities of LLMs
such as Chain of Thought, ReAct, and Reflexion achieve a meager 0%, 0.6%, and
0% with GPT3.5-Turbo respectively, our operationalization of the LLM-Modulo
framework for TravelPlanning domain provides a remarkable improvement,
enhancing baseline performances by 4.6x for GPT4-Turbo and even more for older
models like GPT3.5-Turbo from 0% to 5%. Furthermore, we highlight the other
useful roles of LLMs in the planning pipeline, as suggested in LLM-Modulo,
which can be reliably operationalized such as extraction of useful critics and
reformulator for critics.

ÊëòË¶ÅÔºöÈö®ËëóÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÈÅ©Áî®ÊÄßË∂ÖË∂äÂÇ≥Áµ±ÁöÑÊñáÂ≠óËôïÁêÜ‰ªªÂãôÔºåÂÆÉÂÄëÂú®Ë¶èÂäÉÂíåÊé®ÁêÜ‰ªªÂãô‰∏≠Ë°®ÁèæÂá∫Ëâ≤ÁöÑÊΩõÂäõÂºïËµ∑‰∫ÜÊ•µÂ§ßÁöÑËààË∂£ÔºåÈÄô‰∫õÈ†òÂüüÂÇ≥Áµ±‰∏äÊòØ System 2 Ë™çÁü•ËÉΩÂäõÁöÑÂ∞àÂ±¨È†òÂüü„ÄÇÂÑòÁÆ°ÂÆÉÂÄëË¢´Ë™çÁÇ∫ÂÖ∑ÊúâÂ§öÂäüËÉΩÊÄßÔºå‰ΩÜÁ†îÁ©∂Á§æÁæ§‰ªçÂú®Êé¢Ë®éÂú®Â¶ÇÊ≠§Ë§áÈõúÁöÑÈ†òÂüü‰∏≠ÊúâÊïàÂà©Áî®ÈÄô‰∫õÊ®°ÂûãÁöÑÁ≠ñÁï•„ÄÇLLM Modulo Ë´ñÊñá‰∏≠ÊúÄËøëÊèêÂá∫ÁöÑË´ñËø∞Ê®ôË™åËëó‰∏ÄÂÄãÈáçË¶ÅÁöÑÈÄ≤Â±ïÔºåÊèêÂá∫‰∫ÜÂ¢ûÂº∑ LLM ËàáÂêÑÁ®ÆË¶èÂäÉÂíåÊé®ÁêÜÊ¥ªÂãïÊï¥ÂêàÁöÑÊ¶ÇÂøµÊ°ÜÊû∂„ÄÇÈÄôÁØáÁ†îË®éÊúÉË´ñÊñáÊ∑±ÂÖ•Êé¢Ë®é‰∫ÜÈÄôÂÄãÊ°ÜÊû∂Âú®ÊóÖÈÅäË¶èÂäÉÈ†òÂüü‰∏≠ÁöÑÂØ¶ÈöõÊáâÁî®Ôºå‰∏¶Â±ïÁ§∫‰∫Ü‰∏ÄÂÄãÂÖ∑È´îÁöÑÂØ¶‰ΩúÁØÑ‰æã„ÄÇÊàëÂÄë‰ΩøÁî®‰∫Ü‰øÑ‰∫•‰øÑÂ∑ûÁ´ãÂ§ßÂ≠∏Ëá™ÁÑ∂Ë™ûË®ÄËôïÁêÜÂ∞èÁµÑÁöÑÊóÖÈÅäË¶èÂäÉÂü∫Ê∫ñÔºåÈÄôÂÄãÂü∫Ê∫ñÁî®ÊñºË©ï‰º∞ LLM Âú®Ê†πÊìö‰ª•Ëá™ÁÑ∂Ë™ûË®ÄÂëàÁèæÁöÑ‰ΩøÁî®ËÄÖÊü•Ë©¢Áî¢ÁîüÊúâÊïàË°åÁ®ãÊñπÈù¢ÁöÑË°®Áèæ„ÄÇÈõñÁÑ∂Â¢ûÂº∑ LLM Êé®ÁêÜËÉΩÂäõÁöÑÊµÅË°åÊñπÊ≥ïÔºå‰æãÂ¶ÇÊÄùÁ∂≠Èèà„ÄÅReAct Âíå ReflexionÔºåÂàÜÂà•‰ΩøÁî® GPT3.5-Turbo ÈÅîÂà∞‰∫ÜÂæÆ‰∏çË∂≥ÈÅìÁöÑ 0%„ÄÅ0.6% Âíå 0%Ôºå‰ΩÜÊàëÂÄëÂ∞á LLM-Modulo Ê°ÜÊû∂Êìç‰ΩúÂåñÂà∞ÊóÖÈÅäË¶èÂäÉÈ†òÂüüÔºåÊèê‰æõ‰∫ÜÈ°ØËëóÁöÑÊîπÈÄ≤ÔºåÂ∞á GPT4-Turbo ÁöÑÂü∫Ê∫ñË°®ÁèæÊèêÂçá‰∫Ü 4.6 ÂÄçÔºåÁîöËá≥Â∞á GPT3.5-Turbo Á≠âËºÉËàäÊ®°ÂûãÂæû 0% ÊèêÂçáÂà∞ 5%„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂº∑Ë™ø‰∫Ü LLM Âú®Ë¶èÂäÉÊµÅÁ®ã‰∏≠ÂÖ∂‰ªñÊúâÁî®ÁöÑËßíËâ≤ÔºåÊ≠£Â¶Ç LLM-Modulo ÊâÄÂª∫Ë≠∞ÁöÑÔºåÈÄô‰∫õËßíËâ≤ÂèØ‰ª•Ë¢´ÂèØÈù†Âú∞Êìç‰ΩúÂåñÔºå‰æãÂ¶ÇÊèêÂèñÊúâÁî®ÁöÑÊâπË©ïÂíåÊâπË©ïÁöÑÈáçÊñ∞Ë°®Ëø∞„ÄÇ

##### **Leveraging Large Language Models for Entity Matching**
2405.20624v1 by Qianyu Huang, Tongfang Zhao

Entity matching (EM) is a critical task in data integration, aiming to
identify records across different datasets that refer to the same real-world
entities. Traditional methods often rely on manually engineered features and
rule-based systems, which struggle with diverse and unstructured data. The
emergence of Large Language Models (LLMs) such as GPT-4 offers transformative
potential for EM, leveraging their advanced semantic understanding and
contextual capabilities. This vision paper explores the application of LLMs to
EM, discussing their advantages, challenges, and future research directions.
Additionally, we review related work on applying weak supervision and
unsupervised approaches to EM, highlighting how LLMs can enhance these methods.

ÊëòË¶ÅÔºöÂØ¶È´îÈÖçÂ∞ç (EM) ÊòØË≥áÊñôÊï¥Âêà‰∏≠ÁöÑÈóúÈçµ‰ªªÂãôÔºåÁõÆÊ®ôÊòØË≠òÂà•‰∏çÂêåË≥áÊñôÈõÜ‰∏≠ÁöÑË®òÈåÑÔºåÈÄô‰∫õË®òÈåÑÊåáÁöÑÊòØÂêå‰∏ÄÂÄãÁúüÂØ¶‰∏ñÁïåÁöÑÂØ¶È´î„ÄÇÂÇ≥Áµ±ÁöÑÊñπÊ≥ïÈÄöÂ∏∏‰æùË≥¥Êñº‰∫∫Â∑•Ë®≠Ë®àÁöÑÁâπÂæµÂíåÂü∫ÊñºË¶èÂâáÁöÑÁ≥ªÁµ±ÔºåÈÄô‰∫õÁ≥ªÁµ±Èõ£‰ª•ËôïÁêÜÂ§öÊ®£Âåñ‰∏îÈùûÁµêÊßãÂåñÁöÑË≥áÊñô„ÄÇÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM)Ôºà‰æãÂ¶Ç GPT-4ÔºâÁöÑÂá∫ÁèæÁÇ∫ EM Êèê‰æõ‰∫ÜËÆäÈù©ÊÄßÁöÑÊΩõÂäõÔºåÂà©Áî®ÂÆÉÂÄëÂÖàÈÄ≤ÁöÑË™ûÁæ©ÁêÜËß£Âíå‰∏ä‰∏ãÊñáËÉΩÂäõ„ÄÇÊú¨È°òÊôØÊñá‰ª∂Êé¢Ë®é‰∫Ü LLM Âú® EM ‰∏≠ÁöÑÊáâÁî®ÔºåË®éË´ñ‰∫ÜÂÆÉÂÄëÁöÑÂÑ™Èªû„ÄÅÊåëÊà∞ÂíåÊú™‰æÜÁöÑÁ†îÁ©∂ÊñπÂêë„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂõûÈ°ß‰∫ÜÂú® EM ‰∏≠ÊáâÁî®Âº±Áõ£Áù£ÂíåÈùûÁõ£Áù£ÊñπÊ≥ïÁöÑÁõ∏ÈóúÂ∑•‰ΩúÔºåÂº∑Ë™ø‰∫Ü LLM Â¶Ç‰ΩïÂ¢ûÂº∑ÈÄô‰∫õÊñπÊ≥ï„ÄÇ

##### **FineRadScore: A Radiology Report Line-by-Line Evaluation Technique Generating Corrections with Severity Scores**
2405.20613v1 by Alyssa Huang, Oishi Banerjee, Kay Wu, Eduardo Pontes Reis, Pranav Rajpurkar

The current gold standard for evaluating generated chest x-ray (CXR) reports
is through radiologist annotations. However, this process can be extremely
time-consuming and costly, especially when evaluating large numbers of reports.
In this work, we present FineRadScore, a Large Language Model (LLM)-based
automated evaluation metric for generated CXR reports. Given a candidate report
and a ground-truth report, FineRadScore gives the minimum number of
line-by-line corrections required to go from the candidate to the ground-truth
report. Additionally, FineRadScore provides an error severity rating with each
correction and generates comments explaining why the correction was needed. We
demonstrate that FineRadScore's corrections and error severity scores align
with radiologist opinions. We also show that, when used to judge the quality of
the report as a whole, FineRadScore aligns with radiologists as well as current
state-of-the-art automated CXR evaluation metrics. Finally, we analyze
FineRadScore's shortcomings to provide suggestions for future improvements.

ÊëòË¶ÅÔºöÁõÆÂâçË©ï‰º∞ÁîüÊàêÁöÑËÉ∏ÈÉ® X ÂÖâ (CXR) Â†±ÂëäÁöÑÈªÉÈáëÊ®ôÊ∫ñÊòØÈÄèÈÅéÊîæÂ∞ÑÁßëÈÜ´Â∏´Ë®ªËß£„ÄÇÁÑ∂ËÄåÔºåÈÄôÂÄãÈÅéÁ®ãÂèØËÉΩÈùûÂ∏∏ËÄóÊôÇ‰∏îÊòÇË≤¥ÔºåÁâπÂà•ÊòØÂú®Ë©ï‰º∞Â§ßÈáèÁöÑÂ†±ÂëäÊôÇ„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫ FineRadScoreÔºå‰∏ÄÁ®ÆÂü∫ÊñºÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑËá™ÂãïÂåñË©ï‰º∞ÊåáÊ®ôÔºåÁî®ÊñºÁîüÊàêÁöÑ CXR Â†±Âëä„ÄÇÁµ¶ÂÆöÂÄôÈÅ∏Â†±ÂëäÂíåÂü∫Êú¨‰∫ãÂØ¶Â†±ÂëäÔºåFineRadScore ÊúÉÊèê‰æõÂæûÂÄôÈÅ∏Â†±ÂëäÂà∞Âü∫Êú¨‰∫ãÂØ¶Â†±ÂëäÊâÄÈúÄÁöÑÊúÄÂ∞ëÈÄêË°åÊõ¥Ê≠£Ê¨°Êï∏„ÄÇÊ≠§Â§ñÔºåFineRadScore ÊúÉÊèê‰æõÊØèÂÄãÊõ¥Ê≠£ÁöÑÈåØË™§Âö¥ÈáçÊÄßË©ïÂàÜÔºå‰∏¶Áî¢ÁîüË™™ÊòéÁÇ∫‰ΩïÈúÄË¶ÅÊõ¥Ê≠£ÁöÑË©ïË´ñ„ÄÇÊàëÂÄëË≠âÊòé FineRadScore ÁöÑÊõ¥Ê≠£ÂíåÈåØË™§Âö¥ÈáçÊÄßË©ïÂàÜËàáÊîæÂ∞ÑÁßëÈÜ´Â∏´ÁöÑÊÑèË¶ã‰∏ÄËá¥„ÄÇÊàëÂÄë‰πüÈ°ØÁ§∫ÔºåÁï∂Áî®ÊñºÂà§Êñ∑Â†±ÂëäÁöÑÊï¥È´îÂìÅË≥™ÊôÇÔºåFineRadScore ËàáÊîæÂ∞ÑÁßëÈÜ´Â∏´‰ª•ÂèäÁõÆÂâçÊúÄÂÖàÈÄ≤ÁöÑËá™ÂãïÂåñ CXR Ë©ï‰º∞ÊåáÊ®ô‰∏ÄËá¥„ÄÇÊúÄÂæåÔºåÊàëÂÄëÂàÜÊûê FineRadScore ÁöÑÁº∫ÈªûÔºå‰ª•Êèê‰æõÊú™‰æÜÊîπÈÄ≤ÁöÑÂª∫Ë≠∞„ÄÇ

##### **UniBias: Unveiling and Mitigating LLM Bias through Internal Attention and FFN Manipulation**
2405.20612v1 by Hanzhang Zhou, Zijian Feng, Zixiao Zhu, Junlang Qian, Kezhi Mao

Large language models (LLMs) have demonstrated impressive capabilities in
various tasks using the in-context learning (ICL) paradigm. However, their
effectiveness is often compromised by inherent bias, leading to prompt
brittleness, i.e., sensitivity to design settings such as example selection,
order, and prompt formatting. Previous studies have addressed LLM bias through
external adjustment of model outputs, but the internal mechanisms that lead to
such bias remain unexplored. Our work delves into these mechanisms,
particularly investigating how feedforward neural networks (FFNs) and attention
heads result in the bias of LLMs. By Interpreting the contribution of
individual FFN vectors and attention heads, we identify the biased LLM
components that skew LLMs' prediction toward specific labels. To mitigate these
biases, we introduce UniBias, an inference-only method that effectively
identifies and eliminates biased FFN vectors and attention heads. Extensive
experiments across 12 NLP datasets demonstrate that UniBias significantly
enhances ICL performance and alleviates prompt brittleness of LLMs.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤Âú®‰ΩøÁî®ÊÉÖÂ¢ÉÂ≠∏Áøí (ICL) ÂÖ∏ÁØÑÁöÑÂêÑÁ®Æ‰ªªÂãô‰∏≠Â±ïÁèæÂá∫‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑËÉΩÂäõ„ÄÇÁÑ∂ËÄåÔºåÂÆÉÂÄëÁöÑÊúâÊïàÊÄßÂ∏∏Â∏∏ÂèóÂà∞ÂÖßÂú®ÂÅèÂ∑ÆÁöÑÂΩ±ÈüøÔºåÂ∞éËá¥ÊèêÁ§∫ËÑÜÂº±ÊÄßÔºåÂç≥Â∞çÁØÑ‰æãÈÅ∏Êìá„ÄÅÈ†ÜÂ∫èÂíåÊèêÁ§∫Ê†ºÂºèÁ≠âË®≠Ë®àË®≠ÂÆöÁöÑÊïèÊÑüÊÄß„ÄÇÂÖàÂâçÁöÑÁ†îÁ©∂Â∑≤ÈÄèÈÅéÊ®°ÂûãËº∏Âá∫ÁöÑÂ§ñÈÉ®Ë™øÊï¥‰æÜËß£Ê±∫ LLM ÂÅèÂ∑ÆÔºå‰ΩÜÂ∞éËá¥Ê≠§È°ûÂÅèÂ∑ÆÁöÑÂÖßÈÉ®Ê©üÂà∂‰ªçÊú™Êé¢Ë®é„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂Ê∑±ÂÖ•Êé¢Ë®éÈÄô‰∫õÊ©üÂà∂ÔºåÁâπÂà•ÊòØË™øÊü•ÂâçÈ•ãÁ•ûÁ∂ìÁ∂≤Ë∑Ø (FFN) ÂíåÊ≥®ÊÑèÂäõÈ†≠Â¶Ç‰ΩïÂ∞éËá¥ LLM ÁöÑÂÅèÂ∑Æ„ÄÇÈÄèÈÅéË©ÆÈáãÂÄãÂà• FFN ÂêëÈáèÂíåÊ≥®ÊÑèÂäõÈ†≠ÁöÑË≤¢ÁçªÔºåÊàëÂÄëÊâæÂá∫ÂÅèÂ∑ÆÁöÑ LLM ÁµÑ‰ª∂Ôºå‰Ωø LLM ÁöÑÈ†êÊ∏¨ÂÅèÂêëÁâπÂÆöÊ®ôÁ±§„ÄÇÁÇ∫‰∫ÜÊ∏õËºïÈÄô‰∫õÂÅèÂ∑ÆÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü UniBiasÔºåÈÄôÊòØ‰∏ÄÁ®ÆÂÉÖÈôêÊé®Ë´ñÁöÑÊñπÊ≥ïÔºåÂèØ‰ª•ÊúâÊïàÊâæÂá∫‰∏¶Ê∂àÈô§ÊúâÂÅèÂ∑ÆÁöÑ FFN ÂêëÈáèÂíåÊ≥®ÊÑèÂäõÈ†≠„ÄÇÂú® 12 ÂÄã NLP Ë≥áÊñôÈõÜ‰∏≠ÁöÑÂª£Ê≥õÂØ¶È©óË≠âÊòéÔºåUniBias Â§ßÂπÖÊèêÂçá‰∫Ü ICL ÊïàËÉΩÔºå‰∏¶Ê∏õËºï‰∫Ü LLM ÁöÑÊèêÁ§∫ËÑÜÂº±ÊÄß„ÄÇ

##### **Bi-Directional Transformers vs. word2vec: Discovering Vulnerabilities in Lifted Compiled Code**
2405.20611v1 by Gary A. McCully, John D. Hastings, Shengjie Xu, Adam Fortier

Detecting vulnerabilities within compiled binaries is challenging due to lost
high-level code structures and other factors such as architectural
dependencies, compilers, and optimization options. To address these obstacles,
this research explores vulnerability detection by using natural language
processing (NLP) embedding techniques with word2vec, BERT, and RoBERTa to learn
semantics from intermediate representation (LLVM) code. Long short-term memory
(LSTM) neural networks were trained on embeddings from encoders created using
approximately 118k LLVM functions from the Juliet dataset. This study is
pioneering in its comparison of word2vec models with multiple bidirectional
transformer (BERT, RoBERTa) embeddings built using LLVM code to train neural
networks to detect vulnerabilities in compiled binaries. word2vec Continuous
Bag of Words (CBOW) models achieved 92.3% validation accuracy in detecting
vulnerabilities, outperforming word2vec Skip-Gram, BERT, and RoBERTa. This
suggests that complex contextual NLP embeddings may not provide advantages over
simpler word2vec models for this task when a limited number (e.g. 118K) of data
samples are used to train the bidirectional transformer-based models. The
comparative results provide novel insights into selecting optimal embeddings
for learning compiler-independent semantic code representations to advance
machine learning detection of vulnerabilities in compiled binaries.

ÊëòË¶ÅÔºöÂÅµÊ∏¨Á∑®Ë≠Ø‰∫åÈÄ≤‰ΩçÊ™î‰∏≠ÁöÑÂº±ÈªûÂÖ∑ÊúâÊåëÊà∞ÊÄßÔºåÂéüÂõ†Âú®ÊñºÈÅ∫Â§±‰∫ÜÈ´òÈöéÁ®ãÂºèÁ¢ºÁµêÊßã‰ª•ÂèäÊû∂ÊßãÁõ∏‰æùÊÄß„ÄÅÁ∑®Ë≠ØÂô®ÂíåÊúÄ‰Ω≥ÂåñÈÅ∏È†ÖÁ≠âÂÖ∂‰ªñÂõ†Á¥†„ÄÇÁÇ∫‰∫ÜÂÖãÊúçÈÄô‰∫õÈöúÁ§ôÔºåÊú¨Á†îÁ©∂Êé¢Á¥¢‰ΩøÁî®Ëá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ (NLP) ÂµåÂÖ•ÊäÄË°ìÔºåÊê≠ÈÖç word2vec„ÄÅBERT Âíå RoBERTaÔºåÈÄèÈÅé‰∏≠ÈñìË°®Á§∫ (LLVM) Á®ãÂºèÁ¢ºÂ≠∏ÁøíË™ûÊÑèÔºå‰ª•ÂÅµÊ∏¨Âº±Èªû„ÄÇÈï∑ÊúüÁü≠ÊúüË®òÊÜ∂ (LSTM) Á•ûÁ∂ìÁ∂≤Ë∑ØÁ∂ìÈÅéË®ìÁ∑¥Ôºå‰ΩøÁî®Á¥Ñ 118k ÂÄã‰æÜËá™ Juliet Ë≥áÊñôÈõÜÁöÑ LLVM ÂáΩÊï∏ÊâÄÂª∫Á´ãÁöÑÁ∑®Á¢ºÂô®‰∏≠ÁöÑÂµåÂÖ•„ÄÇÊú¨Á†îÁ©∂ÁéáÂÖàÊØîËºÉ word2vec Ê®°ÂûãËàá‰ΩøÁî® LLVM Á®ãÂºèÁ¢ºÂª∫Á´ãÁöÑÂ§öÂÄãÈõôÂêëËΩâÊèõÂô® (BERT„ÄÅRoBERTa) ÂµåÂÖ•Ôºå‰ª•Ë®ìÁ∑¥Á•ûÁ∂ìÁ∂≤Ë∑Ø‰æÜÂÅµÊ∏¨Á∑®Ë≠Ø‰∫åÈÄ≤‰ΩçÊ™î‰∏≠ÁöÑÂº±Èªû„ÄÇword2vec ÈÄ£Á∫åË©ûË¢ã (CBOW) Ê®°ÂûãÂú®ÂÅµÊ∏¨Âº±ÈªûÊñπÈù¢ÈÅîÂà∞‰∫Ü 92.3% ÁöÑÈ©óË≠âÊ∫ñÁ¢∫Â∫¶ÔºåÂÑ™Êñº word2vec Skip-Gram„ÄÅBERT Âíå RoBERTa„ÄÇÈÄôË°®Á§∫Ë§áÈõúÁöÑËÑàÁµ° NLP ÂµåÂÖ•Âú®‰ΩøÁî®ÊúâÈôêÊï∏ÁõÆ (‰æãÂ¶Ç 118K) ÁöÑË≥áÊñôÁØÑÊú¨‰æÜË®ìÁ∑¥Âü∫ÊñºÈõôÂêëËΩâÊèõÂô®ÁöÑÊ®°ÂûãÊôÇÔºåÂèØËÉΩÁÑ°Ê≥ïÁÇ∫Ê≠§‰ªªÂãôÊèê‰æõÂÑ™ÊñºÊõ¥Á∞°ÂñÆÁöÑ word2vec Ê®°ÂûãÁöÑÂÑ™Âã¢„ÄÇÊØîËºÉÁµêÊûúÊèê‰æõ‰∫ÜÊñ∞ÁöÑË¶ãËß£ÔºåÂèØÁî®ÊñºÈÅ∏ÊìáÊúÄ‰Ω≥ÂµåÂÖ•Ôºå‰ª•Â≠∏ÁøíËàáÁ∑®Ë≠ØÂô®ÁÑ°ÈóúÁöÑË™ûÊÑèÁ®ãÂºèÁ¢ºË°®Á§∫Ôºå‰ª•ÊèêÂçáÊ©üÂô®Â≠∏ÁøíÂÅµÊ∏¨Á∑®Ë≠Ø‰∫åÈÄ≤‰ΩçÊ™î‰∏≠Âº±ÈªûÁöÑËÉΩÂäõ„ÄÇ

##### **Vision-Language Meets the Skeleton: Progressively Distillation with Cross-Modal Knowledge for 3D Action Representation Learning**
2405.20606v1 by Yang Chen, Tian He, Junfeng Fu, Ling Wang, Jingcai Guo, Hong Cheng

Supervised and self-supervised learning are two main training paradigms for
skeleton-based human action recognition. However, the former one-hot
classification requires labor-intensive predefined action categories
annotations, while the latter involves skeleton transformations (e.g.,
cropping) in the pretext tasks that may impair the skeleton structure. To
address these challenges, we introduce a novel skeleton-based training
framework (C$^2$VL) based on Cross-modal Contrastive learning that uses the
progressive distillation to learn task-agnostic human skeleton action
representation from the Vision-Language knowledge prompts. Specifically, we
establish the vision-language action concept space through vision-language
knowledge prompts generated by pre-trained large multimodal models (LMMs),
which enrich the fine-grained details that the skeleton action space lacks.
Moreover, we propose the intra-modal self-similarity and inter-modal
cross-consistency softened targets in the cross-modal contrastive process to
progressively control and guide the degree of pulling vision-language knowledge
prompts and corresponding skeletons closer. These soft instance discrimination
and self-knowledge distillation strategies contribute to the learning of better
skeleton-based action representations from the noisy skeleton-vision-language
pairs. During the inference phase, our method requires only the skeleton data
as the input for action recognition and no longer for vision-language prompts.
Extensive experiments show that our method achieves state-of-the-art results on
NTU RGB+D 60, NTU RGB+D 120, and PKU-MMD datasets. The code will be available
in the future.

ÊëòË¶ÅÔºö<paragraph>Áõ£Áù£ÂºèÂíåËá™Áõ£Áù£ÂºèÂ≠∏ÁøíÊòØÂü∫ÊñºÈ™®Êû∂ÁöÑ‰∫∫È°ûÂãï‰ΩúËæ®Ë≠òÁöÑÂÖ©Á®Æ‰∏ªË¶ÅË®ìÁ∑¥ÁØÑ‰æã„ÄÇÁÑ∂ËÄåÔºåÂâçËÄÖÁöÑ‰∏ÄÁÜ±Á∑®Á¢ºÂàÜÈ°ûÈúÄË¶ÅÂ§ßÈáè‰∫∫Â∑•È†êÂÆöÁæ©ÁöÑÂãï‰ΩúÈ°ûÂà•Ë®ªËß£ÔºåËÄåÂæåËÄÖÂâáÊ∂âÂèäÂú®ÂèØËÉΩÊêçÂÆ≥È™®Êû∂ÁµêÊßãÁöÑËóâÂè£‰ªªÂãô‰∏≠ÈÄ≤Ë°åÈ™®Êû∂ËΩâÊèõÔºà‰æãÂ¶ÇÔºåË£ÅÂâ™Ôºâ„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÂü∫ÊñºË∑®Ê®°ÊÖãÂ∞çÊØîÂ≠∏ÁøíÁöÑÊñ∞ÂûãÂü∫ÊñºÈ™®Êû∂ÁöÑË®ìÁ∑¥Ê°ÜÊû∂ÔºàC$^2$VLÔºâÔºåË©≤Ê°ÜÊû∂‰ΩøÁî®Êº∏ÈÄ≤ÂºèËí∏È§æÂæûË¶ñË¶∫Ë™ûË®ÄÁü•Ë≠òÊèêÁ§∫‰∏≠Â≠∏ÁøíËàá‰ªªÂãôÁÑ°ÈóúÁöÑ‰∫∫È´îÈ™®Êû∂Âãï‰ΩúË°®Á§∫„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÈÄöÈÅéÈ†êÂÖàË®ìÁ∑¥ÁöÑÂ§ßÂûãÂ§öÊ®°ÊÖãÊ®°ÂûãÔºàLMMÔºâÁî¢ÁîüÁöÑË¶ñË¶∫Ë™ûË®ÄÁü•Ë≠òÊèêÁ§∫Âª∫Á´ã‰∫ÜË¶ñË¶∫Ë™ûË®ÄÂãï‰ΩúÊ¶ÇÂøµÁ©∫ÈñìÔºåÈÄôË±êÂØå‰∫ÜÈ™®Êû∂Âãï‰ΩúÁ©∫ÈñìÊâÄÁº∫‰πèÁöÑÁ¥∞Á≤íÂ∫¶Á¥∞ÁØÄ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂú®Ë∑®Ê®°ÊÖãÂ∞çÊØîÈÅéÁ®ã‰∏≠ÊèêÂá∫‰∫ÜÊ®°ÊÖãÂÖßËá™Áõ∏‰ººÊÄßÂíåÊ®°ÊÖãÈñì‰∫§Âèâ‰∏ÄËá¥ÊÄßËªüÂåñÁõÆÊ®ôÔºå‰ª•Êº∏ÈÄ≤ÂºèÂú∞ÊéßÂà∂ÂíåÂºïÂ∞éÊãâÂãïË¶ñË¶∫Ë™ûË®ÄÁü•Ë≠òÊèêÁ§∫ÂíåÁõ∏ÊáâÈ™®Êû∂Êõ¥Êé•ËøëÁöÑÁ®ãÂ∫¶„ÄÇÈÄô‰∫õËªüÂØ¶‰æãÂçÄÂàÜÂíåËá™ÊàëÁü•Ë≠òËí∏È§æÁ≠ñÁï•ÊúâÂä©ÊñºÂæûÂòàÈõúÁöÑÈ™®Êû∂Ë¶ñË¶∫Ë™ûË®ÄÂ∞ç‰∏≠Â≠∏ÁøíÊõ¥Â•ΩÁöÑÂü∫ÊñºÈ™®Êû∂ÁöÑÂãï‰ΩúË°®Á§∫„ÄÇÂú®Êé®ÁêÜÈöéÊÆµÔºåÊàëÂÄëÁöÑÊñπÊ≥ïÂè™ÈúÄË¶ÅÈ™®Êû∂Êï∏Êìö‰ΩúÁÇ∫Âãï‰ΩúË≠òÂà•ÁöÑËº∏ÂÖ•Ôºå‰∏çÂÜçÈúÄË¶ÅË¶ñË¶∫Ë™ûË®ÄÊèêÁ§∫„ÄÇÂ§ßÈáèÁöÑÂØ¶È©óË°®ÊòéÔºåÊàëÂÄëÁöÑÁöÑÊñπÊ≥ïÂú® NTU RGB+D 60„ÄÅNTU RGB+D 120 Âíå PKU-MMD Êï∏ÊìöÈõÜ‰∏äÂèñÂæó‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÁµêÊûú„ÄÇ‰ª£Á¢ºÂ∞áÂú®Êú™‰æÜÊèê‰æõ„ÄÇ</paragraph>

##### **Searching for internal symbols underlying deep learning**
2405.20605v1 by Jung H. Lee, Sujith Vijayan

Deep learning (DL) enables deep neural networks (DNNs) to automatically learn
complex tasks or rules from given examples without instructions or guiding
principles. As we do not engineer DNNs' functions, it is extremely difficult to
diagnose their decisions, and multiple lines of studies proposed to explain
principles of DNNs/DL operations. Notably, one line of studies suggests that
DNNs may learn concepts, the high level features recognizable to humans. Thus,
we hypothesized that DNNs develop abstract codes, not necessarily recognizable
to humans, which can be used to augment DNNs' decision-making. To address this
hypothesis, we combined foundation segmentation models and unsupervised
learning to extract internal codes and identify potential use of abstract codes
to make DL's decision-making more reliable and safer.

ÊëòË¶ÅÔºöÊ∑±Â∫¶Â≠∏Áøí (DL) ‰ΩøÂæóÊ∑±Â∫¶Á•ûÁ∂ìÁ∂≤Ë∑Ø (DNN) ËÉΩÂ§†Ëá™ÂãïÂ≠∏ÁøíË§áÈõú‰ªªÂãôÊàñË¶èÂâáÔºåËÄåÁÑ°ÈúÄË™™ÊòéÊàñÊåáÂ∞éÂéüÂâá„ÄÇÁî±ÊñºÊàëÂÄë‰∏¶Êú™Ë®≠Ë®à DNN ÁöÑÂäüËÉΩÔºåÂõ†Ê≠§Ê•µÈõ£Ë®∫Êñ∑ÂÖ∂Ê±∫Á≠ñÔºåËÄåÂ§öÊ¢ùÁ†îÁ©∂Ë∑ØÁ∑öÂâáÊèêÂá∫Ëß£Èáã DNN/DL ÈÅã‰ΩúÂéüÁêÜ„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºå‰∏ÄÊ¢ùÁ†îÁ©∂Ë∑ØÁ∑öË°®Êòé DNN ÂèØËÉΩÂ≠∏Áøí‰∫∫È°ûÂèØË≠òÂà•ÁöÑÈ´òÈöéÁâπÂæµÊ¶ÇÂøµ„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëÂÅáË®≠ DNN ÊúÉÈñãÁôºÂá∫ÊäΩË±°‰ª£Á¢ºÔºåËÄåÈÄô‰∫õ‰ª£Á¢º‰∏ç‰∏ÄÂÆöÁÇ∫‰∫∫È°ûÊâÄË≠òÂà•ÔºåÂèØÁî®ÊñºÊì¥Â¢û DNN ÁöÑÊ±∫Á≠ñÂà∂ÂÆö„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂÅáË®≠ÔºåÊàëÂÄëÁµêÂêàÂü∫Á§éÂàÜÂâ≤Ê®°ÂûãÂíåÁÑ°Áõ£Áù£Â≠∏ÁøíÔºå‰ª•ÊèêÂèñÂÖßÈÉ®‰ª£Á¢º‰∏¶ÊâæÂá∫ÊäΩË±°‰ª£Á¢ºÁöÑÊΩõÂú®Áî®ÈÄîÔºåËÆì DL ÁöÑÊ±∫Á≠ñÂà∂ÂÆöÊõ¥ÂèØÈù†‰∏îÊõ¥ÂÆâÂÖ®„ÄÇ

##### **Advancing Financial Risk Prediction Through Optimized LSTM Model Performance and Comparative Analysis**
2405.20603v1 by Ke Xu, Yu Cheng, Shiqing Long, Junjie Guo, Jue Xiao, Mengfang Sun

This paper focuses on the application and optimization of LSTM model in
financial risk prediction. The study starts with an overview of the
architecture and algorithm foundation of LSTM, and then details the model
training process and hyperparameter tuning strategy, and adjusts network
parameters through experiments to improve performance. Comparative experiments
show that the optimized LSTM model shows significant advantages in AUC index
compared with random forest, BP neural network and XGBoost, which verifies its
efficiency and practicability in the field of financial risk prediction,
especially its ability to deal with complex time series data, which lays a
solid foundation for the application of the model in the actual production
environment.

ÊëòË¶ÅÔºöÊú¨ÊñáÈáçÈªûÊé¢Ë®é LSTM Ê®°ÂûãÂú®ÈáëËûçÈ¢®Èö™È†êÊ∏¨‰∏≠ÁöÑÊáâÁî®ËàáÂÑ™Âåñ„ÄÇÊú¨Á†îÁ©∂È¶ñÂÖàÊ¶ÇËø∞ LSTM ÁöÑÊû∂ÊßãËàáÊºîÁÆóÊ≥ïÂü∫Á§éÔºåÊé•ËëóË©≥Á¥∞Ë™™ÊòéÊ®°ÂûãË®ìÁ∑¥ÊµÅÁ®ãËàáË∂ÖÂèÉÊï∏Ë™øÊï¥Á≠ñÁï•Ôºå‰∏¶ÈÄèÈÅéÂØ¶È©óË™øÊï¥Á∂≤Ë∑ØÂèÉÊï∏‰ª•ÊèêÂçáÊïàËÉΩ„ÄÇÊØîËºÉÂØ¶È©óÁµêÊûúÈ°ØÁ§∫ÔºåÂÑ™ÂåñÁöÑ LSTM Ê®°ÂûãÂú® AUC ÊåáÊ®ô‰∏äËºÉÈö®Ê©üÊ£ÆÊûó„ÄÅBP Á•ûÁ∂ìÁ∂≤Ë∑ØËàá XGBoost ÊúâÈ°ØËëóÂÑ™Âã¢ÔºåÈ©óË≠âÂÖ∂Âú®ÈáëËûçÈ¢®Èö™È†êÊ∏¨È†òÂüüÁöÑÊïàËÉΩËàáÂØ¶Áî®ÊÄßÔºåÁâπÂà•ÊòØËôïÁêÜË§áÈõúÊôÇÈñìÂ∫èÂàóË≥áÊñôÁöÑËÉΩÂäõÔºåÁÇ∫Ê®°ÂûãÂú®ÂØ¶ÈöõÁîüÁî¢Áí∞Â¢É‰∏≠ÁöÑÊáâÁî®Â•†ÂÆöËâØÂ•ΩÁöÑÂü∫Á§é„ÄÇ

##### **Masked Language Modeling Becomes Conditional Density Estimation for Tabular Data Synthesis**
2405.20602v1 by Seunghwan An, Gyeongdong Woo, Jaesung Lim, ChangHyun Kim, Sungchul Hong, Jong-June Jeon

In this paper, our goal is to generate synthetic data for heterogeneous
(mixed-type) tabular datasets with high machine learning utility (MLu). Given
that the MLu performance relies on accurately approximating the conditional
distributions, we focus on devising a synthetic data generation method based on
conditional distribution estimation. We propose a novel synthetic data
generation method, MaCoDE, by redefining the multi-class classification task of
Masked Language Modeling (MLM) as histogram-based non-parametric conditional
density estimation. Our proposed method enables estimating conditional
densities across arbitrary combinations of target and conditional variables.
Furthermore, we demonstrate that our proposed method bridges the theoretical
gap between distributional learning and MLM. To validate the effectiveness of
our proposed model, we conduct synthetic data generation experiments on 10
real-world datasets. Given the analogy between predicting masked input tokens
in MLM and missing data imputation, we also evaluate the performance of
multiple imputations on incomplete datasets with various missing data
mechanisms. Moreover, our proposed model offers the advantage of enabling
adjustments to data privacy levels without requiring re-training.

ÊëòË¶ÅÔºöÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨ÁöÑÁõÆÊ†áÊòØÈíàÂØπÂºÇÊûÑÔºàÊ∑∑ÂêàÁ±ªÂûãÔºâË°®Ê†ºÊï∞ÊçÆÈõÜÁîüÊàêÂÖ∑ÊúâÈ´òÊú∫Âô®Â≠¶‰π†ÊïàÁî®ÔºàMLuÔºâÁöÑÂêàÊàêÊï∞ÊçÆ„ÄÇÈâ¥‰∫é MLu ÊÄßËÉΩ‰æùËµñ‰∫éÂáÜÁ°ÆÂú∞ÈÄºËøëÊù°‰ª∂ÂàÜÂ∏ÉÔºåÂõ†Ê≠§Êàë‰ª¨‰∏ìÊ≥®‰∫éËÆæËÆ°‰∏ÄÁßçÂü∫‰∫éÊù°‰ª∂ÂàÜÂ∏É‰º∞ËÆ°ÁöÑÂêàÊàêÊï∞ÊçÆÁîüÊàêÊñπÊ≥ï„ÄÇÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞È¢ñÁöÑÂêàÊàêÊï∞ÊçÆÁîüÊàêÊñπÊ≥ï MaCoDEÔºåÊñπÊ≥ïÊòØÂ∞ÜÊé©Á†ÅËØ≠Ë®ÄÂª∫Ê®°ÔºàMLMÔºâÁöÑÂ§öÁ±ªÂàÜÁ±ª‰ªªÂä°ÈáçÊñ∞ÂÆö‰πâ‰∏∫Âü∫‰∫éÁõ¥ÊñπÂõæÁöÑÈùûÂèÇÊï∞Êù°‰ª∂ÂØÜÂ∫¶‰º∞ËÆ°„ÄÇÊàë‰ª¨ÊèêÂá∫ÁöÑÊñπÊ≥ïËÉΩÂ§ü‰º∞ËÆ°ÁõÆÊ†áÂèòÈáèÂíåÊù°‰ª∂ÂèòÈáèÁöÑ‰ªªÊÑèÁªÑÂêàÁöÑÊù°‰ª∂ÂØÜÂ∫¶„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨ËØÅÊòé‰∫ÜÊàë‰ª¨ÊèêÂá∫ÁöÑÊñπÊ≥ïÂº•Âêà‰∫ÜÂàÜÂ∏ÉÂºèÂ≠¶‰π†Âíå MLM ‰πãÈó¥ÁöÑÁêÜËÆ∫Â∑ÆË∑ù„ÄÇ‰∏∫‰∫ÜÈ™åËØÅÊàë‰ª¨ÊèêÂá∫ÁöÑÊ®°ÂûãÁöÑÊúâÊïàÊÄßÔºåÊàë‰ª¨Âú® 10 ‰∏™ÁúüÂÆû‰∏ñÁïåÁöÑÊï∞ÊçÆÈõÜ‰∏äËøõË°å‰∫ÜÂêàÊàêÊï∞ÊçÆÁîüÊàêÂÆûÈ™å„ÄÇÈâ¥‰∫éÈ¢ÑÊµã MLM ‰∏≠ÁöÑÊé©Á†ÅËæìÂÖ•Ê†áËÆ∞‰∏éÁº∫Â§±Êï∞ÊçÆÊèíË°•‰πãÈó¥ÁöÑÁ±ªÊØîÔºåÊàë‰ª¨ËøòËØÑ‰º∞‰∫ÜÂú®ÂÖ∑ÊúâÂêÑÁßçÁº∫Â§±Êï∞ÊçÆÊú∫Âà∂ÁöÑ‰∏çÂÆåÊï¥Êï∞ÊçÆÈõÜ‰∏äËøõË°åÂ§öÊ¨°ÊèíË°•ÁöÑÊÄßËÉΩ„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨ÊèêÂá∫ÁöÑÊ®°ÂûãÂÖ∑ÊúâË∞ÉÊï¥Êï∞ÊçÆÈöêÁßÅÁ∫ßÂà´ÁöÑ‰ºòÂäøÔºåËÄåÊó†ÈúÄÈáçÊñ∞ËÆ≠ÁªÉ„ÄÇ

##### **Multi-label Class Incremental Emotion Decoding with Augmented Emotional Semantics Learning**
2405.20600v1 by Kaicheng Fu, Changde Du, Xiaoyu Chen, Jie Peng, Huiguang He

Emotion decoding plays an important role in affective human-computer
interaction. However, previous studies ignored the dynamic real-world scenario,
where human experience a blend of multiple emotions which are incrementally
integrated into the model, leading to the multi-label class incremental
learning (MLCIL) problem. Existing methods have difficulty in solving MLCIL
issue due to notorious catastrophic forgetting caused by partial label problem
and inadequate label semantics mining. In this paper, we propose an augmented
emotional semantics learning framework for multi-label class incremental
emotion decoding. Specifically, we design an augmented emotional relation graph
module with label disambiguation to handle the past-missing partial label
problem. Then, we leverage domain knowledge from affective dimension space to
alleviate future-missing partial label problem by knowledge distillation.
Besides, an emotional semantics learning module is constructed with a graph
autoencoder to obtain emotion embeddings in order to guide the
semantic-specific feature decoupling for better multi-label learning. Extensive
experiments on three datasets show the superiority of our method for improving
emotion decoding performance and mitigating forgetting on MLCIL problem.

ÊëòË¶ÅÔºöÊÉÖÊÑüËß£Á†ÅÂú®ÊÉÖÊÑü‰∫∫Êú∫‰∫íÂä®‰∏≠ÊâÆÊºîÁùÄÈáçË¶ÅÁöÑËßíËâ≤„ÄÇÁÑ∂ËÄåÔºåÂÖàÂâçÁöÑÁ†îÁ©∂ÂøΩÁï•‰∫ÜÂä®ÊÄÅÁöÑÁúüÂÆû‰∏ñÁïåÂú∫ÊôØÔºåÂÖ∂‰∏≠‰∫∫Á±ª‰ΩìÈ™åÂà∞Â§öÁßçÊÉÖÊÑüÁöÑËûçÂêàÔºåËøô‰∫õÊÉÖÊÑüÈÄêÊ∏êÊï¥ÂêàÂà∞Ê®°Âûã‰∏≠Ôºå‰ªéËÄåÂØºËá¥Â§öÊ†áÁ≠æÁ±ªÂ¢ûÈáèÂ≠¶‰π† (MLCIL) ÈóÆÈ¢ò„ÄÇÁî±‰∫éÈÉ®ÂàÜÊ†áÁ≠æÈóÆÈ¢òÂíåÊ†áÁ≠æËØ≠‰πâÊåñÊéò‰∏çË∂≥ÂØºËá¥ÁöÑÁÅæÈöæÊÄßÈÅóÂøòÔºåÁé∞ÊúâÊñπÊ≥ïÈöæ‰ª•Ëß£ÂÜ≥ MLCIL ÈóÆÈ¢ò„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçÁî®‰∫éÂ§öÊ†áÁ≠æÁ±ªÂ¢ûÈáèÊÉÖÊÑüËß£Á†ÅÁöÑÂ¢ûÂº∫ÂûãÊÉÖÊÑüËØ≠‰πâÂ≠¶‰π†Ê°ÜÊû∂„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåÊàë‰ª¨ËÆæËÆ°‰∫Ü‰∏Ä‰∏™Â∏¶ÊúâÊ†áÁ≠æÊ∂àÊ≠ßÁöÑÂ¢ûÂº∫ÂûãÊÉÖÊÑüÂÖ≥Á≥ªÂõæÊ®°ÂùóÊù•Â§ÑÁêÜËøáÂéªÁº∫Â§±ÁöÑÈÉ®ÂàÜÊ†áÁ≠æÈóÆÈ¢ò„ÄÇÁÑ∂ÂêéÔºåÊàë‰ª¨Âà©Áî®ÊÉÖÊÑüÁª¥Â∫¶Á©∫Èó¥‰∏≠ÁöÑÈ¢ÜÂüüÁü•ËØÜÈÄöËøáÁü•ËØÜËí∏È¶èÊù•ÁºìËß£Êú™Êù•Áº∫Â§±ÁöÑÈÉ®ÂàÜÊ†áÁ≠æÈóÆÈ¢ò„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨ÊûÑÂª∫‰∫Ü‰∏Ä‰∏™Â∏¶ÊúâÂõæËá™Âä®ÁºñÁ†ÅÂô®ÁöÑËØ≠‰πâÊÉÖÊÑüÂ≠¶‰π†Ê®°ÂùóÔºå‰ª•Ëé∑ÂèñÊÉÖÊÑüÂµåÂÖ•Ôºå‰ª•‰æøÊåáÂØºËØ≠‰πâÁâπÂÆöÁâπÂæÅËß£ËÄ¶Ôºå‰ªéËÄåÂÆûÁé∞Êõ¥Â•ΩÁöÑÂ§öÊ†áÁ≠æÂ≠¶‰π†„ÄÇÂú®‰∏â‰∏™Êï∞ÊçÆÈõÜ‰∏äËøõË°åÁöÑÂπøÊ≥õÂÆûÈ™åË°®ÊòéÔºåÊàë‰ª¨ÁöÑÊñπÊ≥ïÂú®ÊèêÈ´òÊÉÖÊÑüËß£Á†ÅÊÄßËÉΩÂíåÂáèËΩª MLCIL ÈóÆÈ¢ò‰∏äÁöÑÈÅóÂøòÊñπÈù¢ÂÖ∑Êúâ‰ºòË∂äÊÄß„ÄÇ

##### **Class-Based Time Series Data Augmentation to Mitigate Extreme Class Imbalance for Solar Flare Prediction**
2405.20590v1 by Junzhi Wen, Rafal A. Angryk

Time series data plays a crucial role across various domains, making it
valuable for decision-making and predictive modeling. Machine learning (ML) and
deep learning (DL) have shown promise in this regard, yet their performance
hinges on data quality and quantity, often constrained by data scarcity and
class imbalance, particularly for rare events like solar flares. Data
augmentation techniques offer a potential solution to address these challenges,
yet their effectiveness on multivariate time series datasets remains
underexplored. In this study, we propose a novel data augmentation method for
time series data named Mean Gaussian Noise (MGN). We investigate the
performance of MGN compared to eight existing basic data augmentation methods
on a multivariate time series dataset for solar flare prediction, SWAN-SF,
using a ML algorithm for time series data, TimeSeriesSVC. The results
demonstrate the efficacy of MGN and highlight its potential for improving
classification performance in scenarios with extremely imbalanced data. Our
time complexity analysis shows that MGN also has a competitive computational
cost compared to the investigated alternative methods.

ÊëòË¶ÅÔºöÊôÇÂ∫èË≥áÊñôÂú®ÂêÑÂÄãÈ†òÂüü‰∏≠ÊâÆÊºîËëóËá≥ÈóúÈáçË¶ÅÁöÑËßíËâ≤Ôºå‰ΩøÂÖ∂Â∞çÊñºÊ±∫Á≠ñÂà∂ÂÆöÂíåÈ†êÊ∏¨Ê®°ÂûãËÄåË®ÄÊ•µÂÖ∑ÂÉπÂÄº„ÄÇÊ©üÂô®Â≠∏Áøí (ML) ÂíåÊ∑±Â∫¶Â≠∏Áøí (DL) Â∑≤Â±ïÁèæÂá∫Âú®ÈÄôÊñπÈù¢ÁöÑÂ∏åÊúõÔºå‰ΩÜÂÖ∂ÊïàËÉΩÂèñÊ±∫ÊñºË≥áÊñôÂìÅË≥™ÂíåÊï∏ÈáèÔºåËÄåË≥áÊñôÁ®ÄÂ∞ëÊÄßÂíåÈ°ûÂà•‰∏çÂπ≥Ë°°ÈÄöÂ∏∏ÊúÉÂ∞çÂÖ∂ÈÄ†ÊàêÈôêÂà∂ÔºåÁâπÂà•ÊòØÂ∞çÊñºÂ§™ÈôΩËÄÄÊñëÁ≠âÁΩïË¶ã‰∫ã‰ª∂ËÄåË®Ä„ÄÇË≥áÊñôÊì¥ÂÖÖÊäÄË°ìÊèê‰æõ‰∫ÜËß£Ê±∫ÈÄô‰∫õÊåëÊà∞ÁöÑÊΩõÂú®ÊñπÊ°àÔºå‰ΩÜÂÖ∂Âú®Â§öËÆäÈáèÊôÇÂ∫èË≥áÊñôÈõÜ‰∏äÁöÑÊúâÊïàÊÄß‰ªçÊú™ÂÖÖÂàÜÊé¢Ë®é„ÄÇÂú®Êú¨Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂêçÁÇ∫Âπ≥ÂùáÈ´òÊñØÈõúË®ä (MGN) ÁöÑÊôÇÂ∫èË≥áÊñôÊñ∞Ë≥áÊñôÊì¥ÂÖÖÊñπÊ≥ï„ÄÇÊàëÂÄëÂú®ÊôÇÂ∫èË≥áÊñôÊ©üÂô®Â≠∏ÁøíÊºîÁÆóÊ≥ï TimeSeriesSVC ‰∏äÔºåÈáùÂ∞çÂ§™ÈôΩËÄÄÊñëÈ†êÊ∏¨ÁöÑÂ§öËÆäÈáèÊôÇÂ∫èË≥áÊñôÈõÜ SWAN-SFÔºåÊé¢Ë®é‰∫Ü MGN ËàáÂÖ´Á®ÆÁèæÊúâÂü∫Êú¨Ë≥áÊñôÊì¥ÂÖÖÊñπÊ≥ïÁöÑÊïàËÉΩ„ÄÇÁµêÊûúË≠âÊòé‰∫Ü MGN ÁöÑÊïàËÉΩÔºå‰∏¶Âº∑Ë™ø‰∫ÜÂÖ∂Âú®Ê•µÂ∫¶‰∏çÂπ≥Ë°°Ë≥áÊñôÂ†¥ÊôØ‰∏≠ÊîπÂñÑÂàÜÈ°ûÊïàËÉΩÁöÑÊΩõÂäõ„ÄÇÊàëÂÄëÁöÑÊôÇÈñìË§áÈõúÂ∫¶ÂàÜÊûêÈ°ØÁ§∫ÔºåËàáÊâÄÊé¢Ë®éÁöÑÊõø‰ª£ÊñπÊ≥ïÁõ∏ÊØîÔºåMGN ‰πüÂÖ∑ÊúâÁ´∂Áà≠ÂäõÁöÑÈÅãÁÆóÊàêÊú¨„ÄÇ

##### **Selective Knowledge Sharing for Personalized Federated Learning Under Capacity Heterogeneity**
2405.20589v1 by Zheng Wang, Zheng Wang, Zhaopeng Peng, Zihui Wang, Cheng Wang

Federated Learning (FL) stands to gain significant advantages from
collaboratively training capacity-heterogeneous models, enabling the
utilization of private data and computing power from low-capacity devices.
However, the focus on personalizing capacity-heterogeneous models based on
client-specific data has been limited, resulting in suboptimal local model
utility, particularly for low-capacity clients. The heterogeneity in both data
and device capacity poses two key challenges for model personalization: 1)
accurately retaining necessary knowledge embedded within reduced submodels for
each client, and 2) effectively sharing knowledge through aggregating
size-varying parameters. To this end, we introduce Pa3dFL, a novel framework
designed to enhance local model performance by decoupling and selectively
sharing knowledge among capacity-heterogeneous models. First, we decompose each
layer of the model into general and personal parameters. Then, we maintain
uniform sizes for the general parameters across clients and aggregate them
through direct averaging. Subsequently, we employ a hyper-network to generate
size-varying personal parameters for clients using learnable embeddings.
Finally, we facilitate the implicit aggregation of personal parameters by
aggregating client embeddings through a self-attention module. We conducted
extensive experiments on three datasets to evaluate the effectiveness of
Pa3dFL. Our findings indicate that Pa3dFL consistently outperforms baseline
methods across various heterogeneity settings. Moreover, Pa3dFL demonstrates
competitive communication and computation efficiency compared to baseline
approaches, highlighting its practicality and adaptability in adverse system
conditions.

ÊëòË¶ÅÔºöËÅØÈÇ¶Â≠∏Áøí (FL) ÂèØÈÄèÈÅéÂçî‰ΩúË®ìÁ∑¥ÂÆπÈáèÁï∞Ë≥™Ê®°ÂûãÁç≤ÂæóÈ°ØËëóÂÑ™Âã¢Ôºå‰∏¶ËÉΩÂà©Áî®‰ΩéÂÆπÈáèË£ùÁΩÆ‰∏≠ÁöÑÁßÅ‰∫∫Ë≥áÊñôÂíåÈÅãÁÆóËÉΩÂäõ„ÄÇÁÑ∂ËÄåÔºåÈáùÂ∞çÂÆ¢Êà∂ÁâπÂÆöË≥áÊñôÂÄã‰∫∫ÂåñÂÆπÈáèÁï∞Ë≥™Ê®°ÂûãÁöÑÈáçÈªûÊúâÈôêÔºåÂ∞éËá¥Ê¨°‰Ω≥ÁöÑÂú®Âú∞Ê®°ÂûãÊïàÁî®ÔºåÁâπÂà•ÊòØÂ∞çÊñº‰ΩéÂÆπÈáèÂÆ¢Êà∂ËÄåË®Ä„ÄÇË≥áÊñôÂíåË£ùÁΩÆÂÆπÈáèÁöÑÁï∞Ë≥™ÊÄßÂ∞çÊ®°ÂûãÂÄã‰∫∫ÂåñÈÄ†ÊàêÂÖ©È†ÖÈóúÈçµÊåëÊà∞Ôºö1) Ê∫ñÁ¢∫‰øùÁïôÂµåÂÖ•Âú®ÊØèÂÄãÂÆ¢Êà∂ÁöÑÁ∞°ÂåñÂ≠êÊ®°Âûã‰∏≠ÁöÑÂøÖË¶ÅÁü•Ë≠òÔºå‰ª•Âèä 2) ÊúâÊïàÂú∞ÈÄèÈÅéÂΩôÁ∏ΩÂ§ßÂ∞è‰∏çÂêåÁöÑÂèÉÊï∏‰æÜÂàÜ‰∫´Áü•Ë≠ò„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÂºïÈÄ≤ Pa3dFLÔºå‰∏ÄÂÄãÊñ∞Á©éÁöÑÊû∂ÊßãÔºåÊó®Âú®ÈÄèÈÅéÂàÜÈõ¢ÂíåÈÅ∏ÊìáÊÄßÂú∞ÂàÜ‰∫´ÂÆπÈáèÁï∞Ë≥™Ê®°Âûã‰πãÈñìÁöÑÁü•Ë≠ò‰æÜÊèêÂçáÂú®Âú∞Ê®°ÂûãÊïàËÉΩ„ÄÇÈ¶ñÂÖàÔºåÊàëÂÄëÂ∞áÊ®°ÂûãÁöÑÊØè‰∏ÄÂ±§ÂàÜËß£Êàê‰∏ÄËà¨ÂèÉÊï∏ÂíåÂÄã‰∫∫ÂèÉÊï∏„ÄÇÊé•ËëóÔºåÊàëÂÄëÁ∂≠ÊåÅÂÆ¢Êà∂‰πãÈñì‰∏ÄËà¨ÂèÉÊï∏ÁöÑÂùá‰∏ÄÂ§ßÂ∞èÔºå‰∏¶ÈÄèÈÅéÁõ¥Êé•Âπ≥Âùá‰æÜÂΩôÁ∏ΩÂÆÉÂÄë„ÄÇÈö®ÂæåÔºåÊàëÂÄëÊé°Áî®‰∏ÄÂÄãË∂ÖÁ∂≤Ë∑Ø‰æÜ‰ΩøÁî®ÂèØÂ≠∏ÁøíÂµåÂÖ•ÁÇ∫ÂÆ¢Êà∂Áî¢ÁîüÂ§ßÂ∞è‰∏çÂêåÁöÑÂÄã‰∫∫ÂèÉÊï∏„ÄÇÊúÄÂæåÔºåÊàëÂÄëÈÄèÈÅéËá™Ê≥®ÊÑèÂäõÊ®°ÁµÑÂΩôÁ∏ΩÂÆ¢Êà∂ÂµåÂÖ•‰æÜ‰øÉÈÄ≤ÂÄã‰∫∫ÂèÉÊï∏ÁöÑÈö±ÂºèÂΩôÁ∏Ω„ÄÇÊàëÂÄëÂú®‰∏âÂÄãË≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÂª£Ê≥õÁöÑÂØ¶È©óÔºå‰ª•Ë©ï‰º∞ Pa3dFL ÁöÑÊïàËÉΩ„ÄÇÊàëÂÄëÁöÑÁôºÁèæÊåáÂá∫ÔºåÂú®ÂêÑÁ®ÆÁï∞Ë≥™ÊÄßË®≠ÂÆö‰∏≠ÔºåPa3dFL ÊåÅÁ∫åÂÑ™ÊñºÂü∫Ê∫ñÊñπÊ≥ï„ÄÇÊ≠§Â§ñÔºåËàáÂü∫Ê∫ñÊñπÊ≥ïÁõ∏ÊØîÔºåPa3dFL Â±ïÁèæÂá∫ÂÖ∑Á´∂Áà≠ÂäõÁöÑÈÄöË®äÂíåÈÅãÁÆóÊïàÁéáÔºåÁ™ÅÈ°ØÂÖ∂Âú®‰∏çÂà©ÁöÑÁ≥ªÁµ±Ê¢ù‰ª∂‰∏ãÁöÑÂØ¶Áî®ÊÄßÂíåÈÅ©ÊáâÊÄß„ÄÇ

##### **DAFNet: Dynamic Auxiliary Fusion for Sequential Model Editing in Large Language Models**
2405.20588v1 by Taolin Zhang, Qizhou Chen, Dongyang Li, Chengyu Wang, Xiaofeng He, Longtao Huang, Hui Xue, Jun Huang

Recently, while large language models (LLMs) have demonstrated impressive
results, they still suffer from hallucination, i.e., the generation of false
information. Model editing is the task of fixing factual mistakes in LLMs; yet,
most previous works treat it as a one-time task, paying little attention to
ever-emerging mistakes generated by LLMs. We address the task of sequential
model editing (SME) that aims to rectify mistakes continuously. A Dynamic
Auxiliary Fusion Network (DAFNet) is designed to enhance the semantic
interaction among the factual knowledge within the entire sequence, preventing
catastrophic forgetting during the editing process of multiple knowledge
triples. Specifically, (1) for semantic fusion within a relation triple, we
aggregate the intra-editing attention flow into auto-regressive self-attention
with token-level granularity in LLMs. We further leverage multi-layer diagonal
inter-editing attention flow to update the weighted representations of the
entire sequence-level granularity. (2) Considering that auxiliary parameters
are required to store the knowledge for sequential editing, we construct a new
dataset named \textbf{DAFSet}, fulfilling recent, popular, long-tail and robust
properties to enhance the generality of sequential editing. Experiments show
DAFNet significantly outperforms strong baselines in single-turn and sequential
editing. The usage of DAFSet also consistently improves the performance of
other auxiliary network-based methods in various scenarios

ÊëòË¶ÅÔºö<paragraph>ËøëÊúüÔºåËôΩÁÑ∂Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã (LLM) Â∑≤Â±ïÁ§∫Âá∫‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑÁªìÊûúÔºå‰ΩÜÂÆÉ‰ª¨‰ªçÈ•±ÂèóÂπªËßâÂõ∞Êâ∞ÔºåÂç≥ÁîüÊàêËôöÂÅá‰ø°ÊÅØ„ÄÇÊ®°ÂûãÁºñËæëÊòØ‰øÆÂ§ç LLM ‰∏≠‰∫ãÂÆûÈîôËØØÁöÑ‰ªªÂä°ÔºõÁÑ∂ËÄåÔºåÂ§ßÂ§öÊï∞‰ª•ÂâçÁöÑ‰ΩúÂìÅÂ∞ÜÂÖ∂ËßÜ‰∏∫‰∏ÄÊ¨°ÊÄß‰ªªÂä°ÔºåÂæàÂ∞ëÂÖ≥Ê≥® LLM ÁîüÊàêÁöÑ‰∏çÊñ≠Âá∫Áé∞ÁöÑÈîôËØØ„ÄÇÊàë‰ª¨Ëß£ÂÜ≥È°∫Â∫èÊ®°ÂûãÁºñËæë (SME) ÁöÑ‰ªªÂä°ÔºåÊó®Âú®ÊåÅÁª≠Á∫†Ê≠£ÈîôËØØ„ÄÇÂä®ÊÄÅËæÖÂä©ËûçÂêàÁΩëÁªú (DAFNet) Ë¢´ËÆæËÆ°Áî®‰∫éÂ¢ûÂº∫Êï¥‰∏™Â∫èÂàó‰∏≠‰∫ãÂÆûÁü•ËØÜ‰πãÈó¥ÁöÑËØ≠‰πâ‰∫§‰∫íÔºåÈò≤Ê≠¢Âú®ÁºñËæëÂ§ö‰∏™Áü•ËØÜ‰∏âÂÖÉÁªÑÁöÑËøáÁ®ã‰∏≠ÂèëÁîüÁÅæÈöæÊÄßÈÅóÂøò„ÄÇÂÖ∑‰ΩìÊù•ËØ¥Ôºå(1) ÂØπ‰∫éÂÖ≥Á≥ª‰∏âÂÖÉÁªÑÂÜÖÁöÑËØ≠‰πâËûçÂêàÔºåÊàë‰ª¨Â∞ÜÂÜÖÈÉ®ÁºñËæëÊ≥®ÊÑèÂäõÊµÅËÅöÂêàÂà∞ LLM ‰∏≠ÂÖ∑ÊúâÊ†áËÆ∞Á∫ßÂà´Á≤íÂ∫¶ÁöÑËá™ÂõûÂΩíËá™Ê≥®ÊÑèÂäõ‰∏≠„ÄÇÊàë‰ª¨Ëøõ‰∏ÄÊ≠•Âà©Áî®Â§öÂ±ÇÂØπËßíÁ∫ø‰∫íÁºñËæëÊ≥®ÊÑèÂäõÊµÅÊù•Êõ¥Êñ∞Êï¥‰∏™Â∫èÂàóÁ∫ßÂà´Á≤íÂ∫¶ÁöÑÂä†ÊùÉË°®Á§∫„ÄÇ(2) ËÄÉËôëÂà∞ÈúÄË¶ÅËæÖÂä©ÂèÇÊï∞Êù•Â≠òÂÇ®È°∫Â∫èÁºñËæëÁöÑÁü•ËØÜÔºåÊàë‰ª¨ÊûÑÂª∫‰∫Ü‰∏Ä‰∏™Âêç‰∏∫ \textbf{DAFSet} ÁöÑÊñ∞Êï∞ÊçÆÈõÜÔºåÊª°Ë∂≥ÊúÄÊñ∞„ÄÅÊµÅË°å„ÄÅÈïøÂ∞æÂíåÈ≤ÅÊ£íÂ±ûÊÄß‰ª•Â¢ûÂº∫È°∫Â∫èÁºñËæëÁöÑÈÄöÁî®ÊÄß„ÄÇÂÆûÈ™åË°®ÊòéÔºåDAFNet Âú®ÂçïËΩÆÂíåÈ°∫Â∫èÁºñËæë‰∏≠ÊòéÊòæ‰ºò‰∫éÂº∫Â§ßÁöÑÂü∫Á∫ø„ÄÇDAFSet ÁöÑ‰ΩøÁî®‰πüÊåÅÁª≠ÊèêÈ´ò‰∫ÜÂÖ∂‰ªñÂü∫‰∫éËæÖÂä©ÁΩëÁªúÁöÑÊñπÊ≥ïÂú®ÂêÑÁßçÂú∫ÊôØ‰∏≠ÁöÑÊÄßËÉΩ</paragraph>

##### **GAMedX: Generative AI-based Medical Entity Data Extractor Using Large Language Models**
2405.20585v1 by Mohammed-Khalil Ghali, Abdelrahman Farrag, Hajar Sakai, Hicham El Baz, Yu Jin, Sarah Lam

In the rapidly evolving field of healthcare and beyond, the integration of
generative AI in Electronic Health Records (EHRs) represents a pivotal
advancement, addressing a critical gap in current information extraction
techniques. This paper introduces GAMedX, a Named Entity Recognition (NER)
approach utilizing Large Language Models (LLMs) to efficiently extract entities
from medical narratives and unstructured text generated throughout various
phases of the patient hospital visit. By addressing the significant challenge
of processing unstructured medical text, GAMedX leverages the capabilities of
generative AI and LLMs for improved data extraction. Employing a unified
approach, the methodology integrates open-source LLMs for NER, utilizing
chained prompts and Pydantic schemas for structured output to navigate the
complexities of specialized medical jargon. The findings reveal significant
ROUGE F1 score on one of the evaluation datasets with an accuracy of 98\%. This
innovation enhances entity extraction, offering a scalable, cost-effective
solution for automated forms filling from unstructured data. As a result,
GAMedX streamlines the processing of unstructured narratives, and sets a new
standard in NER applications, contributing significantly to theoretical and
practical advancements beyond the medical technology sphere.

ÊëòË¶ÅÔºöÂú®Âø´ÈÄüÂèëÂ±ïÁöÑÈÜ´ÁôÇ‰øùÂÅ•ÂèäÂÖ∂‰ªñÈ†òÂüü‰∏≠ÔºåÁîüÊàêÂºè AI Êï¥ÂêàÂà∞ÈõªÂ≠êÂÅ•Â∫∑Á¥ÄÈåÑ (EHR) ‰∏≠‰ª£Ë°®ËëóÈóúÈçµÈÄ≤Â±ïÔºåËß£Ê±∫‰∫ÜÁï∂ÂâçË≥áË®äÊì∑ÂèñÊäÄË°ì‰∏≠ÁöÑÈáçÂ§ßÂ∑ÆË∑ù„ÄÇÊú¨Êñá‰ªãÁ¥π GAMedXÔºå‰∏ÄÁ®ÆÂëΩÂêçÂØ¶È´îËæ®Ë≠ò (NER) ÊñπÊ≥ïÔºåÂà©Áî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂæûÈÜ´ÁôÇÊïòËø∞ÂíåÊÇ£ËÄÖÈÜ´Èô¢Â∞±Ë®∫ÂêÑÂÄãÈöéÊÆµÁî¢ÁîüÁöÑÈùûÁµêÊßãÂåñÊñáÂ≠ó‰∏≠ÊúâÊïàÁéáÂú∞Êì∑ÂèñÂØ¶È´î„ÄÇÈÄèÈÅéËß£Ê±∫ËôïÁêÜÈùûÁµêÊßãÂåñÈÜ´ÁôÇÊñáÂ≠óÁöÑÈáçÂ§ßÊåëÊà∞ÔºåGAMedX ÂÖÖÂàÜÂà©Áî®ÁîüÊàêÂºè AI Âíå LLM ÁöÑËÉΩÂäõÔºå‰ª•ÊîπÂñÑË≥áÊñôÊì∑Âèñ„ÄÇÊé°Áî®Áµ±‰∏ÄÊñπÊ≥ïÔºåÊ≠§ÊñπÊ≥ïÊï¥ÂêàÈñãÊîæÂéüÂßãÁ¢º LLM ‰ª•ÈÄ≤Ë°å NERÔºåÂà©Áî®‰∏≤ÈÄ£ÊèêÁ§∫Âíå Pydantic Êû∂ÊßãÈÄ≤Ë°åÁµêÊßãÂåñËº∏Âá∫Ôºå‰ª•ÊáâÂ∞çÂ∞àÊ•≠ÈÜ´ÁôÇË°ìË™ûÁöÑË§áÈõúÊÄß„ÄÇÁ†îÁ©∂ÁµêÊûúÈ°ØÁ§∫ÔºåÂú®ÂÖ∂‰∏≠‰∏ÄÂÄãË©ïÈáèË≥áÊñôÈõÜ‰∏äÔºåROUGE F1 ÂæóÂàÜÈ°ØËëóÔºåÊ∫ñÁ¢∫Â∫¶ÁÇ∫ 98%„ÄÇÈÄôÈ†ÖÂâµÊñ∞Â¢ûÂº∑‰∫ÜÂØ¶È´îÊì∑ÂèñÔºåÊèê‰æõ‰∫Ü‰∏ÄÂÄãÂèØÊì¥ÂÖÖ„ÄÅÂÖ∑ÊàêÊú¨ÊïàÁõäÁöÑËß£Ê±∫ÊñπÊ°àÔºåÁî®ÊñºÂæûÈùûÁµêÊßãÂåñË≥áÊñô‰∏≠Ëá™ÂãïÂ°´ÂØ´Ë°®Ê†º„ÄÇÂõ†Ê≠§ÔºåGAMedX Á∞°Âåñ‰∫ÜÈùûÁµêÊßãÂåñÊïòËø∞ÁöÑËôïÁêÜÔºå‰∏¶Âú® NER ÊáâÁî®Á®ãÂºè‰∏≠Ë®≠ÂÆö‰∫ÜÊñ∞ÁöÑÊ®ôÊ∫ñÔºåÁÇ∫ÈÜ´ÁôÇÊäÄË°ìÈ†òÂüü‰πãÂ§ñÁöÑÁêÜË´ñÂíåÂØ¶ÂãôÈÄ≤Â±ïÂÅöÂá∫‰∫ÜÈáçÂ§ßË≤¢Áçª„ÄÇ

##### **Disrupting Diffusion: Token-Level Attention Erasure Attack against Diffusion-based Customization**
2405.20584v1 by Yisu Liu, Jinyang An, Wanqian Zhang, Dayan Wu, Jingzi Gu, Zheng Lin, Weiping Wang

With the development of diffusion-based customization methods like
DreamBooth, individuals now have access to train the models that can generate
their personalized images. Despite the convenience, malicious users have
misused these techniques to create fake images, thereby triggering a privacy
security crisis. In light of this, proactive adversarial attacks are proposed
to protect users against customization. The adversarial examples are trained to
distort the customization model's outputs and thus block the misuse. In this
paper, we propose DisDiff (Disrupting Diffusion), a novel adversarial attack
method to disrupt the diffusion model outputs. We first delve into the
intrinsic image-text relationships, well-known as cross-attention, and
empirically find that the subject-identifier token plays an important role in
guiding image generation. Thus, we propose the Cross-Attention Erasure module
to explicitly "erase" the indicated attention maps and disrupt the text
guidance. Besides,we analyze the influence of the sampling process of the
diffusion model on Projected Gradient Descent (PGD) attack and introduce a
novel Merit Sampling Scheduler to adaptively modulate the perturbation updating
amplitude in a step-aware manner. Our DisDiff outperforms the state-of-the-art
methods by 12.75% of FDFR scores and 7.25% of ISM scores across two facial
benchmarks and two commonly used prompts on average.

ÊëòË¶ÅÔºöÈö®ËëóÂÉè DreamBooth ÈÄôÁ®ÆÂü∫ÊñºÊì¥Êï£ÁöÑÂÆ¢Ë£ΩÂåñÊñπÊ≥ïÁöÑÁôºÂ±ïÔºåÂÄã‰∫∫ÁèæÂú®ÂèØ‰ª•Â≠òÂèñË®ìÁ∑¥Ê®°ÂûãÔºå‰ª•Áî¢Áîü‰ªñÂÄëÁöÑÂÄã‰∫∫ÂåñÂΩ±ÂÉè„ÄÇÂÑòÁÆ°ÂæàÊñπ‰æøÔºå‰ΩÜÊÉ°ÊÑè‰ΩøÁî®ËÄÖÂ∑≤Ë™§Áî®ÈÄô‰∫õÊäÄË°ì‰æÜÂª∫Á´ãÂÅáÂΩ±ÂÉèÔºåÂæûËÄåÂºïÁôºÈö±ÁßÅÂÆâÂÖ®Âç±Ê©ü„ÄÇÊúâÈëëÊñºÊ≠§ÔºåÊèêË≠∞‰∏ªÂãïÂ∞çÊäóÊîªÊìä‰æÜ‰øùË≠∑‰ΩøÁî®ËÄÖÂÖçÊñºÂÆ¢Ë£ΩÂåñ„ÄÇÂ∞çÊäóÁØÑ‰æãÁ∂ìÈÅéË®ìÁ∑¥ÔºåÂèØ‰ª•Êâ≠Êõ≤ÂÆ¢Ë£ΩÂåñÊ®°ÂûãÁöÑËº∏Âá∫ÔºåÂæûËÄåÈòªÊ≠¢Ë™§Áî®„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫ DisDiffÔºà‰∏≠Êñ∑Êì¥Êï£ÔºâÔºå‰∏ÄÁ®ÆÊñ∞ÁöÑÂ∞çÊäóÊîªÊìäÊñπÊ≥ïÔºåÁî®Êñº‰∏≠Êñ∑Êì¥Êï£Ê®°ÂûãÁöÑËº∏Âá∫„ÄÇÊàëÂÄëÈ¶ñÂÖàÊ∑±ÂÖ•Êé¢Ë®éÂÖßÂú®ÁöÑÂΩ±ÂÉèÊñáÂ≠óÈóú‰øÇÔºå‰πüÂ∞±ÊòØÁúæÊâÄÂë®Áü•ÁöÑ‰∫§ÂèâÊ≥®ÊÑèÂäõÔºå‰∏¶ÊÜëÁ∂ìÈ©óÁôºÁèæ‰∏ªÈ´îË≠òÂà•‰ª£Á¢ºÂú®ÂºïÂ∞éÂΩ±ÂÉèÁî¢Áîü‰∏≠ÊâÆÊºîÈáçË¶ÅËßíËâ≤„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëÊèêÂá∫‰∫§ÂèâÊ≥®ÊÑèÂäõÊ∂àÈô§Ê®°ÁµÑÔºå‰ª•ÊòéÁ¢∫„ÄåÊ∂àÈô§„ÄçÊåáÁ§∫ÁöÑÊ≥®ÊÑèÂäõÂúñÔºå‰∏¶‰∏≠Êñ∑ÊñáÂ≠óÊåáÂ∞é„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂàÜÊûê‰∫ÜÊì¥Êï£Ê®°ÂûãÁöÑÂèñÊ®£ÈÅéÁ®ãÂ∞çÊäïÂΩ±Ê¢ØÂ∫¶‰∏ãÈôç (PGD) ÊîªÊìäÁöÑÂΩ±ÈüøÔºå‰∏¶ÂºïÂÖ•‰∏ÄÁ®ÆÊñ∞ÁöÑÂÑ™ÈªûÂèñÊ®£ÊéíÁ®ãÂô®Ôºå‰ª•ÈÄêÊ≠•Ë™øÊï¥ÊìæÂãïÊõ¥Êñ∞ÂπÖÂ∫¶„ÄÇÊàëÂÄëÁöÑ DisDiff Âú®ÂÖ©ÂÄãÈù¢ÈÉ®Âü∫Ê∫ñÂíåÂÖ©ÂÄãÂ∏∏Áî®ÁöÑÊèêÁ§∫‰∏äÔºåÂπ≥ÂùáÂÑ™ÊñºÊúÄÂÖàÈÄ≤ÁöÑÊñπÊ≥ï 12.75% ÁöÑ FDFR ÂàÜÊï∏Âíå 7.25% ÁöÑ ISM ÂàÜÊï∏„ÄÇ

##### **The Point of View of a Sentiment: Towards Clinician Bias Detection in Psychiatric Notes**
2405.20582v1 by Alissa A. Valentine, Lauren A. Lepow, Alexander W. Charney, Isotta Landi

In psychiatry, negative patient descriptions and stigmatizing language can
contribute to healthcare disparities in two ways: (1) read by patients they can
harm their trust and engagement with the medical center; (2) read by future
providers they may negatively influence the future perspective of a patient. By
leveraging large language models, this work aims to identify the sentiment
expressed in psychiatric clinical notes based on the reader's point of view.
Extracting sentences from the Mount Sinai Health System's large and diverse
clinical notes, we used prompts and in-context learning to adapt three large
language models (GPT-3.5, Llama 2, Mistral) to classify the sentiment conveyed
by the sentences according to the provider or non-provider point of view.
Results showed that GPT-3.5 aligns best to provider point of view, whereas
Mistral aligns best to non-provider point of view.

ÊëòË¶ÅÔºöÂú®Á≤æÁ•ûÁóÖÂ≠∏‰∏≠ÔºåË≤†Èù¢ÁöÑÁóÖ‰∫∫ÊèèËø∞ÂíåÊ±°ÂêçÂåñÁöÑË™ûË®ÄÂèØËÉΩÈÄèÈÅéÂÖ©Á®ÆÊñπÂºèÈÄ†ÊàêÈÜ´ÁôÇ‰øùÂÅ•Â∑ÆÁï∞Ôºö(1) ÁóÖ‰∫∫ËÆÄÂà∞ÂæåÊúÉÊêçÂÆ≥‰ªñÂÄëÂ∞çÈÜ´ÁôÇ‰∏≠ÂøÉÁöÑ‰ø°‰ªªÂíåÂèÉËàáÔºõ(2) Êú™‰æÜÁöÑÊèê‰æõËÄÖËÆÄÂà∞ÂæåÔºåÂèØËÉΩÊúÉÂ∞çÁóÖ‰∫∫ÁöÑÊú™‰æÜËßÄÈªûÁî¢ÁîüË≤†Èù¢ÂΩ±Èüø„ÄÇÈÄèÈÅéÂà©Áî®Â§ßÂûãË™ûË®ÄÊ®°ÂûãÔºåÈÄôÈ†ÖÂ∑•‰ΩúÊó®Âú®Ê†πÊìöËÆÄËÄÖÁöÑËßÄÈªûÔºåÊâæÂá∫Á≤æÁ•ûÁóÖËá®Â∫äÁ≠ÜË®ò‰∏≠Ë°®ÈÅîÁöÑÊÉÖÁ∑í„ÄÇÂæûË•øÂ•àÂ±±ÂÅ•Â∫∑Á≥ªÁµ±ÁöÑÂ§ßÈáè‰∏îÂ§öÊ®£ÂåñÁöÑËá®Â∫äÁ≠ÜË®ò‰∏≠ÊëòÈåÑÂè•Â≠êÔºåÊàëÂÄë‰ΩøÁî®ÊèêÁ§∫ÂíåÊÉÖÂ¢ÉÂ≠∏Áøí‰æÜË™øÊï¥‰∏âÂÄãÂ§ßÂûãË™ûË®ÄÊ®°Âûã (GPT-3.5„ÄÅLlama 2„ÄÅMistral)Ôºå‰ª•Ê†πÊìöÊèê‰æõËÄÖÊàñÈùûÊèê‰æõËÄÖËßÄÈªûÂ∞çÂè•Â≠êÂÇ≥ÈÅîÁöÑÊÉÖÁ∑íÈÄ≤Ë°åÂàÜÈ°û„ÄÇÁµêÊûúÈ°ØÁ§∫ÔºåGPT-3.5 ÊúÄÁ¨¶ÂêàÊèê‰æõËÄÖËßÄÈªûÔºåËÄå Mistral ÊúÄÁ¨¶ÂêàÈùûÊèê‰æõËÄÖËßÄÈªû„ÄÇ

##### **Open Ko-LLM Leaderboard: Evaluating Large Language Models in Korean with Ko-H5 Benchmark**
2405.20574v1 by Chanjun Park, Hyeonwoo Kim, Dahyun Kim, Seonghwan Cho, Sanghoon Kim, Sukyung Lee, Yungi Kim, Hwalsuk Lee

This paper introduces the Open Ko-LLM Leaderboard and the Ko-H5 Benchmark as
vital tools for evaluating Large Language Models (LLMs) in Korean.
Incorporating private test sets while mirroring the English Open LLM
Leaderboard, we establish a robust evaluation framework that has been well
integrated in the Korean LLM community. We perform data leakage analysis that
shows the benefit of private test sets along with a correlation study within
the Ko-H5 benchmark and temporal analyses of the Ko-H5 score. Moreover, we
present empirical support for the need to expand beyond set benchmarks. We hope
the Open Ko-LLM Leaderboard sets precedent for expanding LLM evaluation to
foster more linguistic diversity.

ÊëòË¶ÅÔºöÊú¨Êñá‰ªãÁ¥π‰∫Ü Open Ko-LLM ÊéíË°åÊ¶úÂíå Ko-H5 Âü∫Ê∫ñÔºå‰ΩúÁÇ∫Ë©ï‰º∞ÈüìË™ûÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÈáçË¶ÅÂ∑•ÂÖ∑„ÄÇ
ÊàëÂÄëÂú®Âª∫Á´ãÂÅ•ÂÖ®ÁöÑË©ï‰º∞Êû∂ÊßãÊôÇÔºåÁ¥çÂÖ•‰∫ÜÁßÅ‰∫∫Ê∏¨Ë©¶ÈõÜÔºåÂêåÊôÇÊØîÁÖß‰∫ÜËã±Êñá Open LLM ÊéíË°åÊ¶úÔºåËÄåÊ≠§Êû∂ÊßãÂ∑≤Âú®ÈüìË™û LLM Á§æÁæ§‰∏≠Âª£Ê≥õÊï¥Âêà„ÄÇÊàëÂÄëÂü∑Ë°å‰∫ÜË≥áÊñôÂ§ñÊ¥©ÂàÜÊûêÔºåÈ°ØÁ§∫ÁßÅ‰∫∫Ê∏¨Ë©¶ÈõÜÁöÑÂÑ™ÈªûÔºå‰∏¶Âú® Ko-H5 Âü∫Ê∫ñÂÖßÈÄ≤Ë°åÁõ∏ÈóúÊÄßÁ†îÁ©∂Ôºå‰ª•Âèä Ko-H5 ÂàÜÊï∏ÁöÑÊôÇÈñìÂàÜÊûê„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèêÂá∫Á∂ìÈ©óË≠âÊìöÔºåË™™ÊòéÈúÄË¶ÅÊì¥Â±ïÂà∞Ë®≠ÂÆöÂü∫Ê∫ñ‰πãÂ§ñ„ÄÇÊàëÂÄëÂ∏åÊúõ Open Ko-LLM ÊéíË°åÊ¶úËÉΩÁÇ∫Êì¥Â±ï LLM Ë©ï‰º∞Ê®πÁ´ãÂÖà‰æãÔºå‰ª•‰øÉÈÄ≤Êõ¥Â§öË™ûË®ÄÁöÑÂ§öÊ®£ÊÄß„ÄÇ

##### **Can Machine Learning Assist in Diagnosis of Primary Immune Thrombocytopenia? A feasibility study**
2405.20562v1 by Haroon Miah, Dimitrios Kollias, Giacinto Luca Pedone, Drew Provan, Frederick Chen

Primary Immune thrombocytopenia (ITP) is a rare autoimmune disease
characterised by immune-mediated destruction of peripheral blood platelets in
patients leading to low platelet counts and bleeding. The diagnosis and
effective management of ITP is challenging because there is no established test
to confirm the disease and no biomarker with which one can predict the response
to treatment and outcome. In this work we conduct a feasibility study to check
if machine learning can be applied effectively for diagnosis of ITP using
routine blood tests and demographic data in a non-acute outpatient setting.
Various ML models, including Logistic Regression, Support Vector Machine,
k-Nearest Neighbor, Decision Tree and Random Forest, were applied to data from
the UK Adult ITP Registry and a general hematology clinic. Two different
approaches were investigated: a demographic-unaware and a demographic-aware
one. We conduct extensive experiments to evaluate the predictive performance of
these models and approaches, as well as their bias. The results revealed that
Decision Tree and Random Forest models were both superior and fair, achieving
nearly perfect predictive and fairness scores, with platelet count identified
as the most significant variable. Models not provided with demographic
information performed better in terms of predictive accuracy but showed lower
fairness score, illustrating a trade-off between predictive performance and
fairness.

ÊëòË¶ÅÔºöÂéüÁôºÊÄßÂÖçÁñ´ÊÄßË°ÄÂ∞èÊùøÊ∏õÂ∞ëÁóáÔºàITPÔºâÊòØ‰∏ÄÁ®ÆÁΩïË¶ãÁöÑËá™È´îÂÖçÁñ´ÁñæÁóÖ
ÂÖ∂ÁâπÂæµÂú®ÊñºÂÖçÁñ´‰ªãÂ∞éÁöÑÂ§ñÂë®Ë°ÄÂ∞èÊùøÁ†¥Â£ûÂ∞éËá¥ÊÇ£ËÄÖË°ÄÂ∞èÊùøÊï∏ÈáèÊ∏õÂ∞ëÂíåÂá∫Ë°Ä„ÄÇITP ÁöÑË®∫Êñ∑ÂíåÊúâÊïàÁÆ°ÁêÜÂÖ∑ÊúâÊåëÊà∞ÊÄßÔºåÂõ†ÁÇ∫Ê≤íÊúâÊó¢ÂÆöÁöÑÊ™¢Ê∏¨ÊñπÊ≥ï‰æÜÁ¢∫Ë™çÁñæÁóÖÔºå‰πüÊ≤íÊúâÁîüÁâ©Ê®ôË™åÁâ©ÂèØ‰ª•È†êÊ∏¨Â∞çÊ≤ªÁôÇÂíåÁµêÊûúÁöÑÂèçÊáâ„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÈÄ≤Ë°å‰∫Ü‰∏ÄÈ†ÖÂèØË°åÊÄßÁ†îÁ©∂Ôºå‰ª•Ê™¢Êü•Ê©üÂô®Â≠∏ÁøíÊòØÂê¶ÂèØ‰ª•ÊúâÊïàÊáâÁî®Êñº‰ΩøÁî®ÈùûÊÄ•ÊÄßÈñÄË®∫Áí∞Â¢É‰∏≠ÁöÑÂ∏∏Ë¶èË°ÄÊ∂≤Ê™¢Êü•Âíå‰∫∫Âè£Áµ±Ë®àÊï∏ÊìöË®∫Êñ∑ ITP„ÄÇÂêÑÁ®Æ ML Ê®°ÂûãÔºåÂåÖÊã¨ÈÇèËºØËø¥Ê≠∏„ÄÅÊîØÊåÅÂêëÈáèÊ©ü„ÄÅk ÊúÄËøëÈÑ∞„ÄÅÊ±∫Á≠ñÊ®πÂíåÈö®Ê©üÊ£ÆÊûóÔºåË¢´ÊáâÁî®Êñº‰æÜËá™Ëã±ÂúãÊàê‰∫∫ ITP ÁôªË®òËôïÂíåÊôÆÈÄöË°ÄÊ∂≤Â≠∏Ë®∫ÊâÄÁöÑÊï∏Êìö„ÄÇÁ†îÁ©∂‰∫ÜÂÖ©Á®Æ‰∏çÂêåÁöÑÊñπÊ≥ïÔºö‰∏ÄÁ®ÆÊòØ‰∏çÁü•ÈÅì‰∫∫Âè£Áµ±Ë®àÊï∏ÊìöÁöÑÊñπÊ≥ïÔºåÂè¶‰∏ÄÁ®ÆÊòØÁü•ÈÅì‰∫∫Âè£Áµ±Ë®àÊï∏ÊìöÁöÑÊñπÊ≥ï„ÄÇÊàëÂÄëÈÄ≤Ë°å‰∫ÜÂª£Ê≥õÁöÑÂØ¶È©ó‰æÜË©ï‰º∞ÈÄô‰∫õÊ®°ÂûãÂíåÊñπÊ≥ïÁöÑÈ†êÊ∏¨ÊÄßËÉΩ‰ª•ÂèäÂÆÉÂÄëÁöÑÂÅèÂ∑Æ„ÄÇÁµêÊûúË°®ÊòéÔºåÊ±∫Á≠ñÊ®πÂíåÈö®Ê©üÊ£ÆÊûóÊ®°ÂûãÈÉΩÂÑ™Ë∂ä‰∏îÂÖ¨Âπ≥ÔºåÂØ¶Áèæ‰∫ÜÊé•ËøëÂÆåÁæéÁöÑÈ†êÊ∏¨ÂíåÂÖ¨Âπ≥ÂàÜÊï∏ÔºåË°ÄÂ∞èÊùøË®àÊï∏Ë¢´Á¢∫ÂÆöÁÇ∫ÊúÄÈáçË¶ÅÁöÑËÆäÈáè„ÄÇÊú™Êèê‰æõ‰∫∫Âè£Áµ±Ë®à‰ø°ÊÅØÁöÑÊ®°ÂûãÂú®È†êÊ∏¨Ê∫ñÁ¢∫ÊÄßÊñπÈù¢Ë°®ÁèæÂæóÊõ¥Â•ΩÔºå‰ΩÜÂÖ¨Âπ≥ÂàÜÊï∏ËºÉ‰ΩéÔºåË™™Êòé‰∫ÜÈ†êÊ∏¨ÊÄßËÉΩÂíåÂÖ¨Âπ≥ÊÄß‰πãÈñìÁöÑÊ¨äË°°„ÄÇ

##### **Perplexed by Perplexity: Perplexity-Based Data Pruning With Small Reference Models**
2405.20541v1 by Zachary Ankner, Cody Blakeney, Kartik Sreenivasan, Max Marion, Matthew L. Leavitt, Mansheej Paul

In this work, we investigate whether small language models can determine
high-quality subsets of large-scale text datasets that improve the performance
of larger language models. While existing work has shown that pruning based on
the perplexity of a larger model can yield high-quality data, we investigate
whether smaller models can be used for perplexity-based pruning and how pruning
is affected by the domain composition of the data being pruned. We demonstrate
that for multiple dataset compositions, perplexity-based pruning of pretraining
data can \emph{significantly} improve downstream task performance: pruning
based on perplexities computed with a 125 million parameter model improves the
average performance on downstream tasks of a 3 billion parameter model by up to
2.04 and achieves up to a $1.45\times$ reduction in pretraining steps to reach
commensurate baseline performance. Furthermore, we demonstrate that such
perplexity-based data pruning also yields downstream performance gains in the
over-trained and data-constrained regimes.

ÊëòË¶ÅÔºöÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊé¢Ë®éÂ∞èÂûãË™ûË®ÄÊ®°ÂûãÊòØÂê¶ÂèØ‰ª•Á¢∫ÂÆöÂ§ßÂûãÊñáÂ≠óË≥áÊñôÈõÜ‰∏≠ÁöÑÈ´òÂìÅË≥™Â≠êÈõÜÔºå‰ª•ÊèêÂçáÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÁöÑÊïàËÉΩ„ÄÇÈõñÁÑ∂ÁèæÊúâÁ†îÁ©∂È°ØÁ§∫ÔºåÊ†πÊìöËºÉÂ§ßÂûãÊ®°ÂûãÁöÑÂõ∞ÊÉëÂ∫¶ÈÄ≤Ë°åÂâ™ÊûùÂèØ‰ª•Áî¢ÁîüÈ´òÂìÅË≥™Ë≥áÊñôÔºå‰ΩÜÊàëÂÄëÊé¢Ë®éËºÉÂ∞èÂûãÊ®°ÂûãÊòØÂê¶ÂèØÁî®ÊñºÂü∫ÊñºÂõ∞ÊÉëÂ∫¶ÁöÑÂâ™ÊûùÔºå‰ª•ÂèäÂâ™ÊûùÂ¶Ç‰ΩïÂèóÂà∞Ë¢´Ââ™ÊûùË≥áÊñôÁöÑÁ∂≤ÂüüÁµÑÊàêÂΩ±Èüø„ÄÇÊàëÂÄëË≠âÊòéÔºåÂ∞çÊñºÂ§öÂÄãË≥áÊñôÈõÜÁµÑÊàêÔºåÈ†êË®ìÁ∑¥Ë≥áÊñôÁöÑÂü∫ÊñºÂõ∞ÊÉëÂ∫¶ÁöÑÂâ™ÊûùÂèØ‰ª•È°ØËëóÊèêÂçá‰∏ãÊ∏∏‰ªªÂãôÊïàËÉΩÔºöÊ†πÊìö 1.25 ÂÑÑÂÄãÂèÉÊï∏Ê®°ÂûãË®àÁÆóÁöÑÂõ∞ÊÉëÂ∫¶ÈÄ≤Ë°åÂâ™ÊûùÔºåÂ∞á 30 ÂÑÑÂÄãÂèÉÊï∏Ê®°ÂûãÂú®‰∏ãÊ∏∏‰ªªÂãôÁöÑÂπ≥ÂùáÊïàËÉΩÊèêÂçáÂ§öÈÅî 2.04Ôºå‰∏¶Âú®È†êË®ìÁ∑¥Ê≠•È©ü‰∏≠ÊúÄÂ§öÊ∏õÂ∞ë $1.45\times$ ÂÄçÔºå‰ª•ÈÅîÂà∞Áõ∏Áï∂ÁöÑÂü∫Ê∫ñÊïàËÉΩ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëË≠âÊòéÈÄôÁ®ÆÂü∫ÊñºÂõ∞ÊÉëÂ∫¶ÁöÑË≥áÊñôÂâ™ÊûùÔºåÂú®ÈÅéÂ∫¶Ë®ìÁ∑¥ÂíåË≥áÊñôÂèóÈôêÁöÑÊ®°Âºè‰∏≠Ôºå‰πüËÉΩÁî¢Áîü‰∏ãÊ∏∏ÊïàËÉΩÊèêÂçá„ÄÇ

##### **Unveiling the Impact of Coding Data Instruction Fine-Tuning on Large Language Models Reasoning**
2405.20535v1 by Xinlu Zhang, Zhiyu Zoey Chen, Xi Ye, Xianjun Yang, Lichang Chen, William Yang Wang, Linda Ruth Petzold

Instruction Fine-Tuning (IFT) significantly enhances the zero-shot
capabilities of pretrained Large Language Models (LLMs). While coding data is
known to boost reasoning abilities during LLM pretraining, its role in
activating internal reasoning capacities during IFT remains understudied. This
paper investigates a key question: How does coding data impact LLMs' reasoning
capacities during the IFT stage? To explore this, we thoroughly examine the
impact of coding data across different coding data proportions, model families,
sizes, and reasoning domains, from various perspectives. Specifically, we
create three IFT datasets with increasing coding data proportions, fine-tune
six LLM backbones across different families and scales on these datasets,
evaluate the tuned models' performance across twelve tasks in three reasoning
domains, and analyze the outcomes from three broad-to-granular perspectives:
overall, domain-level, and task-specific. Our holistic analysis provides
valuable insights in each perspective. First, coding data tuning enhances the
overall reasoning capabilities of LLMs across different model families and
scales. Moreover, the effect of coding data varies among different domains but
shows consistent trends across model families and scales within each domain.
Additionally, coding data generally yields comparable task-specific benefits
across different model families, with the optimal coding data proportions in
IFT datasets being task-specific.

ÊëòË¶ÅÔºöÊåá‰ª§ÂæÆË™ø (IFT) Â§ßÂπÖÊèêÂçá‰∫ÜÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÈõ∂Ê¨°Â≠∏ÁøíËÉΩÂäõ„ÄÇÂÑòÁÆ°Â∑≤Áü•Á∑®Á¢ºË≥áÊñôÊúÉÂú® LLM È†êË®ìÁ∑¥ÊúüÈñìÊèêÂçáÊé®ÁêÜËÉΩÂäõÔºå‰ΩÜÂÖ∂Âú® IFT ÊúüÈñìÂïüÂãïÂÖßÈÉ®Êé®ÁêÜËÉΩÂäõ‰∏≠ÁöÑËßíËâ≤‰ªçÊú™ÂèóÂà∞Ê∑±ÂÖ•Êé¢Ë®é„ÄÇÊú¨Ë´ñÊñáÊé¢Ë®é‰∫Ü‰∏ÄÂÄãÈóúÈçµÂïèÈ°åÔºöÁ∑®Á¢ºË≥áÊñôÂú® IFT ÈöéÊÆµÂ¶Ç‰ΩïÂΩ±Èüø LLM ÁöÑÊé®ÁêÜËÉΩÂäõÔºüÁÇ∫‰∫ÜËß£Ê±∫Ê≠§ÂïèÈ°åÔºåÊàëÂÄëÂæûÂêÑÂÄãËßíÂ∫¶ÂæπÂ∫ïÊ™¢Ë¶ñ‰∫ÜÁ∑®Á¢ºË≥áÊñôÂú®‰∏çÂêåÁ∑®Á¢ºË≥áÊñôÊØî‰æã„ÄÅÊ®°ÂûãÁ≥ªÂàó„ÄÅÂ§ßÂ∞èÂíåÊé®ÁêÜÈ†òÂüü‰∏≠ÁöÑÂΩ±Èüø„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÂª∫Á´ã‰∫Ü‰∏âÂÄãÁ∑®Á¢ºË≥áÊñôÊØî‰æãÈÄêÊº∏Â¢ûÂä†ÁöÑ IFT Ë≥áÊñôÈõÜÔºåÂú®ÈÄô‰∫õË≥áÊñôÈõÜ‰∏äÂæÆË™ø‰∫Ü‰∏çÂêåÁ≥ªÂàóÂíåË¶èÊ®°ÁöÑÂÖ≠ÂÄã LLM ‰∏ªÂππÔºå‰∏¶Âú®‰∏âÂÄãÊé®ÁêÜÈ†òÂüüÁöÑÂçÅ‰∫åÈ†Ö‰ªªÂãô‰∏≠Ë©ï‰º∞‰∫ÜÂæÆË™øÊ®°ÂûãÁöÑÊïàËÉΩÔºå‰∏¶Âæû‰∏âÂÄãÂª£Ê≥õÂà∞Ë©≥Á¥∞ÁöÑËßíÂ∫¶ÂàÜÊûêÁµêÊûúÔºöÊï¥È´î„ÄÅÈ†òÂüüÂ±§Á¥öÂíåÁâπÂÆö‰ªªÂãô„ÄÇÊàëÂÄëÁöÑÊï¥È´îÂàÜÊûêÂú®ÊØèÂÄãËßíÂ∫¶ÈÉΩÊèê‰æõ‰∫ÜÂØ∂Ë≤¥ÁöÑË¶ãËß£„ÄÇÈ¶ñÂÖàÔºåÁ∑®Á¢ºË≥áÊñôÂæÆË™øÊèêÂçá‰∫Ü‰∏çÂêåÊ®°ÂûãÁ≥ªÂàóÂíåË¶èÊ®°ÁöÑ LLM ÁöÑÊï¥È´îÊé®ÁêÜËÉΩÂäõ„ÄÇÊ≠§Â§ñÔºåÁ∑®Á¢ºË≥áÊñôÁöÑÂΩ±ÈüøÂõ†È†òÂüüËÄåÁï∞Ôºå‰ΩÜÂú®ÊØèÂÄãÈ†òÂüü‰∏≠Ôºå‰∏çÂêåÊ®°ÂûãÁ≥ªÂàóÂíåË¶èÊ®°ÁöÑË∂®Âã¢‰∏ÄËá¥„ÄÇÊ≠§Â§ñÔºåÁ∑®Á¢ºË≥áÊñôÈÄöÂ∏∏Âú®‰∏çÂêåÊ®°ÂûãÁ≥ªÂàó‰∏≠Áî¢Áîü‰∫ÜÁõ∏Áï∂ÁöÑÁâπÂÆö‰ªªÂãôÊïàÁõäÔºåIFT Ë≥áÊñôÈõÜ‰∏≠ÊúÄ‰Ω≥ÁöÑÁ∑®Á¢ºË≥áÊñôÊØî‰æãÂõ†‰ªªÂãôËÄåÁï∞„ÄÇ

##### **An Automatic Question Usability Evaluation Toolkit**
2405.20529v1 by Steven Moore, Eamon Costello, Huy A. Nguyen, John Stamper

Evaluating multiple-choice questions (MCQs) involves either labor intensive
human assessments or automated methods that prioritize readability, often
overlooking deeper question design flaws. To address this issue, we introduce
the Scalable Automatic Question Usability Evaluation Toolkit (SAQUET), an
open-source tool that leverages the Item-Writing Flaws (IWF) rubric for a
comprehensive and automated quality evaluation of MCQs. By harnessing the
latest in large language models such as GPT-4, advanced word embeddings, and
Transformers designed to analyze textual complexity, SAQUET effectively
pinpoints and assesses a wide array of flaws in MCQs. We first demonstrate the
discrepancy between commonly used automated evaluation metrics and the human
assessment of MCQ quality. Then we evaluate SAQUET on a diverse dataset of MCQs
across the five domains of Chemistry, Statistics, Computer Science, Humanities,
and Healthcare, showing how it effectively distinguishes between flawed and
flawless questions, providing a level of analysis beyond what is achievable
with traditional metrics. With an accuracy rate of over 94% in detecting the
presence of flaws identified by human evaluators, our findings emphasize the
limitations of existing evaluation methods and showcase potential in improving
the quality of educational assessments.

ÊëòË¶ÅÔºöË©ïÈáèÈÅ∏ÊìáÈ°å (MCQ) Ê∂âÂèäÂà∞Â§ßÈáèÁöÑ‰∫∫ÂäõË©ïÈáèÊàñËá™ÂãïÂåñÊñπÊ≥ïÔºåÈÄô‰∫õÊñπÊ≥ïÂÑ™ÂÖàËÄÉÈáèÂèØËÆÄÊÄßÔºåÂçªÂ∏∏Â∏∏ÂøΩÁï•‰∫ÜÊõ¥Ê∑±Â±§ÁöÑÂïèÈ°åË®≠Ë®àÁº∫Èô∑„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜÂèØÊì¥ÂÖÖËá™ÂãïÂåñÂïèÈ°åÂèØÁî®ÊÄßË©ïÈáèÂ∑•ÂÖ∑ÂåÖ (SAQUET)ÔºåÈÄôÊòØ‰∏ÄÂÄãÈñãÊ∫êÂ∑•ÂÖ∑ÔºåÂÆÉÂà©Áî®È†ÖÁõÆÊí∞ÂØ´Áº∫Èô∑ (IWF) Ë©ïÂàÜÊ®ôÊ∫ñÔºåÂ∞çÈÅ∏ÊìáÈ°åÈÄ≤Ë°åÂÖ®Èù¢‰∏îËá™ÂãïÂåñÁöÑÂìÅË≥™Ë©ïÈáè„ÄÇÈÄèÈÅéÂà©Áî® GPT-4 Á≠âÂ§ßÂûãË™ûË®ÄÊ®°Âûã„ÄÅÈÄ≤ÈöéÁöÑË©ûÂµåÂÖ•ÂíåÊó®Âú®ÂàÜÊûêÊñáÂ≠óË§áÈõúÊÄßÁöÑ TransformerÔºåSAQUET ËÉΩÊúâÊïàÂú∞ÊâæÂá∫‰∏¶Ë©ïÈáèÈÅ∏ÊìáÈ°å‰∏≠ÁöÑÂêÑÁ®ÆÁº∫Èô∑„ÄÇÊàëÂÄëÈ¶ñÂÖàÂ±ïÁ§∫‰∫ÜÂ∏∏Áî®Ëá™ÂãïÂåñË©ïÈáèÊåáÊ®ôËàá‰∫∫È°ûÂ∞çÈÅ∏ÊìáÈ°åÂìÅË≥™Ë©ïÈáè‰πãÈñìÁöÑÂ∑ÆÁï∞„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÂú®ÂåñÂ≠∏„ÄÅÁµ±Ë®à„ÄÅÈõªËÖ¶ÁßëÂ≠∏„ÄÅ‰∫∫ÊñáÂíåÈÜ´ÁôÇ‰øùÂÅ•ÈÄô‰∫îÂÄãÈ†òÂüüÁöÑÂ§öÂÖÉÂåñÈÅ∏ÊìáÈ°åË≥áÊñôÈõÜ‰∏äË©ïÈáè SAQUETÔºåÂ±ïÁ§∫‰∫ÜÂÆÉÂ¶Ç‰ΩïÊúâÊïàÂçÄÂàÜÊúâÁº∫Èô∑ÂíåÁÑ°Áº∫Èô∑ÁöÑÂïèÈ°åÔºåÊèê‰æõË∂ÖË∂äÂÇ≥Áµ±ÊåáÊ®ôÊâÄËÉΩÈÅîÂà∞ÁöÑÂàÜÊûêÂ±§Á¥ö„ÄÇÊàëÂÄëÁöÑÁôºÁèæÂº∑Ë™ø‰∫ÜÁèæÊúâË©ïÈáèÊñπÊ≥ïÁöÑÈôêÂà∂Ôºå‰∏¶Â±ïÁ§∫‰∫ÜÊîπÂñÑÊïôËÇ≤Ë©ïÈáèÂìÅË≥™ÁöÑÊΩõÂäõÔºåÂú®ÂÅµÊ∏¨‰∫∫È°ûË©ïÈáèÂì°Ë≠òÂà•ÁöÑÁº∫Èô∑ÊñπÈù¢ÔºåÊ∫ñÁ¢∫ÁéáË∂ÖÈÅé 94%„ÄÇ

##### **Towards Ontology-Enhanced Representation Learning for Large Language Models**
2405.20527v1 by Francesco Ronzano, Jay Nanavati

Taking advantage of the widespread use of ontologies to organise and
harmonize knowledge across several distinct domains, this paper proposes a
novel approach to improve an embedding-Large Language Model (embedding-LLM) of
interest by infusing the knowledge formalized by a reference ontology:
ontological knowledge infusion aims at boosting the ability of the considered
LLM to effectively model the knowledge domain described by the infused
ontology. The linguistic information (i.e. concept synonyms and descriptions)
and structural information (i.e. is-a relations) formalized by the ontology are
utilized to compile a comprehensive set of concept definitions, with the
assistance of a powerful generative LLM (i.e. GPT-3.5-turbo). These concept
definitions are then employed to fine-tune the target embedding-LLM using a
contrastive learning framework. To demonstrate and evaluate the proposed
approach, we utilize the biomedical disease ontology MONDO. The results show
that embedding-LLMs enhanced by ontological disease knowledge exhibit an
improved capability to effectively evaluate the similarity of in-domain
sentences from biomedical documents mentioning diseases, without compromising
their out-of-domain performance.

ÊëòË¶ÅÔºö<paragraph>Âà©Áî®Êú¨‰ΩìË´ñÂª£Ê≥õÁî®ÊñºÁµÑÁπîÂíåË™øÂíå‰∏çÂêåÈ†òÂüüÈñìÁöÑÁü•Ë≠òÔºåÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞ÊñπÊ≥ï‰æÜÊîπÈÄ≤ÂµåÂÖ•ÂºèÂ§ßÂûãË™ûË®ÄÊ®°Âûã (embedding-LLM) ÁöÑËààË∂£ÔºåÊñπÊ≥ïÊòØÊ≥®ÂÖ•Áî±ÂèÉËÄÉÊú¨‰ΩìË´ñÂΩ¢ÂºèÂåñÁöÑÁü•Ë≠òÔºöÊú¨‰ΩìË´ñÁü•Ë≠òÊ≥®ÂÖ•Êó®Âú®ÊèêÂçáÊâÄËÄÉÊÖÆÁöÑ LLM ÊúâÊïàÂª∫Ê®°Áî±Ê≥®ÂÖ•ÁöÑÊú¨‰ΩìË´ñÊâÄÊèèËø∞ÁöÑÁü•Ë≠òÈ†òÂüüÁöÑËÉΩÂäõ„ÄÇÁî±Êú¨‰ΩìË´ñÂΩ¢ÂºèÂåñÁöÑË™ûË®ÄË≥áË®äÔºàÂç≥Ê¶ÇÂøµÂêåÁæ©Ë©ûÂíåÊèèËø∞ÔºâÂíåÁµêÊßãË≥áË®äÔºàÂç≥ is-a Èóú‰øÇÔºâÁî®ÊñºÁ∑®Ë≠Ø‰∏ÄÁµÑÂÖ®Èù¢ÁöÑÊ¶ÇÂøµÂÆöÁæ©Ôºå‰∏¶Âú®Âº∑Â§ßÁöÑÁîüÊàêÂºè LLMÔºàÂç≥ GPT-3.5-turboÔºâÁöÑÂçîÂä©‰∏ãÈÄ≤Ë°å„ÄÇÁÑ∂ÂæåÔºåÈÄô‰∫õÊ¶ÇÂøµÂÆöÁæ©Ë¢´Áî®Êñº‰ΩøÁî®Â∞çÊØîÂ≠∏ÁøíÊû∂ÊßãÂæÆË™øÁõÆÊ®ôÂµåÂÖ•Âºè LLM„ÄÇÁÇ∫‰∫ÜÂ±ïÁ§∫ÂíåË©ï‰º∞ÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÔºåÊàëÂÄëÂà©Áî®ÁîüÁâ©ÈÜ´Â≠∏ÁñæÁóÖÊú¨‰ΩìË´ñ MONDO„ÄÇÁµêÊûúË°®ÊòéÔºåÁî±Êú¨‰ΩìË´ñÁñæÁóÖÁü•Ë≠òÂ¢ûÂº∑ÁöÑÂµåÂÖ•Âºè LLM Ë°®ÁèæÂá∫ÊúâÊïàË©ï‰º∞ÊèêÂèäÁñæÁóÖÁöÑÁîüÁâ©ÈÜ´Â≠∏Êñá‰ª∂‰∏≠ÁöÑÂêåÂüüÂè•Â≠êÁõ∏‰ººÊÄßÁöÑÊîπÈÄ≤ËÉΩÂäõÔºåËÄå‰∏çÊúÉÊêçÂÆ≥ÂÖ∂ÂüüÂ§ñÊïàËÉΩ„ÄÇ</paragraph>

##### **Automated Generation and Tagging of Knowledge Components from Multiple-Choice Questions**
2405.20526v1 by Steven Moore, Robin Schmucker, Tom Mitchell, John Stamper

Knowledge Components (KCs) linked to assessments enhance the measurement of
student learning, enrich analytics, and facilitate adaptivity. However,
generating and linking KCs to assessment items requires significant effort and
domain-specific knowledge. To streamline this process for higher-education
courses, we employed GPT-4 to generate KCs for multiple-choice questions (MCQs)
in Chemistry and E-Learning. We analyzed discrepancies between the KCs
generated by the Large Language Model (LLM) and those made by humans through
evaluation from three domain experts in each subject area. This evaluation
aimed to determine whether, in instances of non-matching KCs, evaluators showed
a preference for the LLM-generated KCs over their human-created counterparts.
We also developed an ontology induction algorithm to cluster questions that
assess similar KCs based on their content. Our most effective LLM strategy
accurately matched KCs for 56% of Chemistry and 35% of E-Learning MCQs, with
even higher success when considering the top five KC suggestions. Human
evaluators favored LLM-generated KCs, choosing them over human-assigned ones
approximately two-thirds of the time, a preference that was statistically
significant across both domains. Our clustering algorithm successfully grouped
questions by their underlying KCs without needing explicit labels or contextual
information. This research advances the automation of KC generation and
classification for assessment items, alleviating the need for student data or
predefined KC labels.

ÊëòË¶ÅÔºöÁü•Ë≠òÁµÑ‰ª∂ (KC) ËàáË©ïÈáèÈÄ£ÁµêÔºåÂèØÊèêÂçáÂ≠∏ÁîüÂ≠∏ÁøíÁöÑÊ∏¨Èáè„ÄÅË±êÂØåÂàÜÊûêÔºå‰∏¶‰øÉÈÄ≤ÈÅ©ÊáâÊÄß„ÄÇÁÑ∂ËÄåÔºåÁî¢Áîü KC ‰∏¶Â∞áÂÖ∂ÈÄ£ÁµêÂà∞Ë©ïÈáèÈ†ÖÁõÆÈúÄË¶ÅÂ§ßÈáèÁöÑÂä™ÂäõÂíåÁâπÂÆöÈ†òÂüüÁöÑÁü•Ë≠ò„ÄÇÁÇ∫‰∫ÜÁ∞°ÂåñÈ´òÁ≠âÊïôËÇ≤Ë™≤Á®ãÁöÑÈÄôÂÄãÊµÅÁ®ãÔºåÊàëÂÄëÊé°Áî® GPT-4 ÁÇ∫ÂåñÂ≠∏ÂíåÈõªÂ≠êÂ≠∏ÁøíÁöÑÂ§öÈÅ∏È°å (MCQ) Áî¢Áîü KC„ÄÇÊàëÂÄëÂàÜÊûê‰∫ÜÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Áî¢ÁîüÁöÑ KC Ëàá‰∫∫È°ûË£Ω‰ΩúÁöÑ KC ‰πãÈñìÁöÑÂ∑ÆÁï∞Ôºå‰∏¶Áî±ÊØèÂÄãÈ†òÂüüÁöÑ‰∏â‰ΩçÈ†òÂüüÂ∞àÂÆ∂ÈÄ≤Ë°åË©ï‰º∞„ÄÇÊ≠§Ë©ï‰º∞Êó®Âú®Á¢∫ÂÆöÂú® KC ‰∏çÂåπÈÖçÁöÑÊÉÖÊ≥Å‰∏ãÔºåË©ï‰º∞ËÄÖÊòØÂê¶ÂÅèÂ•Ω LLM Áî¢ÁîüÁöÑ KCÔºåËÄåÈùû‰∫∫Â∑•Âª∫Á´ãÁöÑ KC„ÄÇÊàëÂÄëÈÇÑÈñãÁôº‰∫Ü‰∏ÄÂÄãÊú¨È´îË´ñÊ≠∏Á¥çÊºîÁÆóÊ≥ïÔºåÊ†πÊìöÂÖßÂÆπÂ∞áË©ïÈáèÁõ∏‰ºº KC ÁöÑÂïèÈ°åÈÄ≤Ë°åÂàÜÁæ§„ÄÇÊàëÂÄëÊúÄÊúâÊïàÁöÑ LLM Á≠ñÁï•Ê∫ñÁ¢∫Âú∞ÂåπÈÖç‰∫Ü 56% ÁöÑÂåñÂ≠∏Âíå 35% ÁöÑÈõªÂ≠êÂ≠∏Áøí MCQ ÁöÑ KCÔºåÂú®ËÄÉÊÖÆÂâç‰∫îÂÄã KC Âª∫Ë≠∞ÊôÇÔºåÊàêÂäüÁéáÊõ¥È´ò„ÄÇ‰∫∫È°ûË©ï‰º∞ËÄÖÂÅèÂ•Ω LLM Áî¢ÁîüÁöÑ KCÔºåÁ¥ÑÊúâ‰∏âÂàÜ‰πã‰∫åÁöÑÊôÇÈñìÈÅ∏ÊìáÂÆÉÂÄëÔºåËÄåÊîæÊ£Ñ‰∫∫Â∑•ÊåáÂÆöÁöÑ KCÔºåÈÄôÈ†ÖÂÅèÂ•ΩÂú®ÈÄôÂÖ©ÂÄãÈ†òÂüü‰∏≠ÂÖ∑ÊúâÁµ±Ë®àÈ°ØËëóÊÄß„ÄÇÊàëÂÄëÁöÑÂàÜÁæ§ÊºîÁÆóÊ≥ïÊàêÂäüÂú∞Ê†πÊìöÂÖ∂Âü∫Á§é KC Â∞áÂïèÈ°åÂàÜÁµÑÔºåËÄå‰∏çÈúÄË¶ÅÊòéÁ¢∫ÁöÑÊ®ôÁ±§ÊàñËÉåÊôØË≥áË®ä„ÄÇÈÄôÈ†ÖÁ†îÁ©∂Êé®Âãï‰∫ÜË©ïÈáèÈ†ÖÁõÆ KC Áî¢ÁîüÁöÑËá™ÂãïÂåñÂíåÂàÜÈ°ûÔºåÊ∏õËºï‰∫ÜÂ∞çÂ≠∏ÁîüË≥áÊñôÊàñÈ†êÂÆöÁæ© KC Ê®ôÁ±§ÁöÑÈúÄÊ±Ç„ÄÇ

##### **Diffusion On Syntax Trees For Program Synthesis**
2405.20519v1 by Shreyas Kapur, Erik Jenner, Stuart Russell

Large language models generate code one token at a time. Their autoregressive
generation process lacks the feedback of observing the program's output.
Training LLMs to suggest edits directly can be challenging due to the scarcity
of rich edit data. To address these problems, we propose neural diffusion
models that operate on syntax trees of any context-free grammar. Similar to
image diffusion models, our method also inverts ``noise'' applied to syntax
trees. Rather than generating code sequentially, we iteratively edit it while
preserving syntactic validity, which makes it easy to combine this neural model
with search. We apply our approach to inverse graphics tasks, where our model
learns to convert images into programs that produce those images. Combined with
search, our model is able to write graphics programs, see the execution result,
and debug them to meet the required specifications. We additionally show how
our system can write graphics programs for hand-drawn sketches.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã‰∏ÄÊ¨°Âè™Áî¢Áîü‰∏ÄÂÄã‰ª£Á¢ºÁ¨¶Ëôü„ÄÇÂÆÉÂÄëÁöÑËá™ÂãïËø¥Ê≠∏ÁîüÊàêÈÅéÁ®ãÁº∫‰πèËßÄÂØüÁ®ãÂºèËº∏Âá∫ÂõûÈ•ã„ÄÇÁî±ÊñºË±êÂØåÁöÑÁ∑®ËºØË≥áÊñôÁ®ÄÂ∞ëÔºåË®ìÁ∑¥ LLM Áõ¥Êé•Âª∫Ë≠∞Á∑®ËºØÂèØËÉΩÊúÉÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫Á•ûÁ∂ìÊì¥Êï£Ê®°ÂûãÔºåÂÆÉÂú®‰ªª‰ΩïÁÑ°ËÑàÁµ°Ë™ûÊ≥ïÁöÑË™ûÊ≥ïÊ®π‰∏äÈÅã‰Ωú„ÄÇËàáÂΩ±ÂÉèÊì¥Êï£Ê®°ÂûãÈ°û‰ººÔºåÊàëÂÄëÁöÑÊ®°Âûã‰πüÊúÉÂ∞çÊáâÁî®ÊñºË™ûÊ≥ïÊ®πÁöÑ„ÄåÈõúË®ä„ÄçÈÄ≤Ë°åÂèçËΩâ„ÄÇÊàëÂÄë‰∏çÊòØÂæ™Â∫èÊº∏ÈÄ≤Âú∞Áî¢ÁîüÁ®ãÂºèÁ¢ºÔºåËÄåÊòØÂèçË¶ÜÁ∑®ËºØÂÆÉÔºåÂêåÊôÇ‰øùÊåÅË™ûÊ≥ïÊúâÊïàÊÄßÔºåÈÄô‰ΩøÂæóÂ∞áÈÄôÂÄãÁ•ûÁ∂ìÊ®°ÂûãËàáÊêúÂ∞ãÁµêÂêàËÆäÂæóÂÆπÊòì„ÄÇÊàëÂÄëÂ∞áÊàëÂÄëÁöÑÂÅöÊ≥ïÊáâÁî®ÊñºÂèçÂêëÂúñÂΩ¢‰ªªÂãôÔºåÊàëÂÄëÁöÑÊ®°ÂûãÂ≠∏ÁøíÂ∞áÂΩ±ÂÉèËΩâÊèõÁÇ∫Áî¢ÁîüÈÇ£‰∫õÂΩ±ÂÉèÁöÑÁ®ãÂºè„ÄÇÁµêÂêàÊêúÂ∞ãÔºåÊàëÂÄëÁöÑÊ®°ÂûãËÉΩÂ§†Êí∞ÂØ´ÂúñÂΩ¢Á®ãÂºèÔºåÊü•ÁúãÂü∑Ë°åÁµêÊûúÔºå‰∏¶Èô§ÈåØÂÆÉÂÄë‰ª•Á¨¶ÂêàÊâÄÈúÄÁöÑË¶èÊ†º„ÄÇÊàëÂÄëÂè¶Â§ñÂ±ïÁ§∫ÊàëÂÄëÁöÑÁ≥ªÁµ±Â¶Ç‰ΩïÁÇ∫ÊâãÁπ™ËçâÂúñÊí∞ÂØ´ÂúñÂΩ¢Á®ãÂºè„ÄÇ


### Medical explainable AI
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-05-26**|**Improving Health Professionals' Onboarding with AI and XAI for Trustworthy Human-AI Collaborative Decision Making**|Min Hun Lee et.al.|[2405.16424v1](http://arxiv.org/abs/2405.16424v1)|null|
|**2024-05-26**|**Exploring Nutritional Impact on Alzheimer's Mortality: An Explainable AI Approach**|Ziming Liu et.al.|[2405.17502v1](http://arxiv.org/abs/2405.17502v1)|null|
|**2024-05-21**|**The Role of Emotions in Informational Support Question-Response Pairs in Online Health Communities: A Multimodal Deep Learning Approach**|Mohsen Jozani et.al.|[2405.13099v1](http://arxiv.org/abs/2405.13099v1)|null|
|**2024-05-17**|**ChatGPT in Classrooms: Transforming Challenges into Opportunities in Education**|Harris Bin Munawar et.al.|[2405.10645v1](http://arxiv.org/abs/2405.10645v1)|null|
|**2024-05-13**|**Evaluating the Explainable AI Method Grad-CAM for Breath Classification on Newborn Time Series Data**|Camelia Oprea et.al.|[2405.07590v1](http://arxiv.org/abs/2405.07590v1)|null|
|**2024-05-10**|**XAI4LLM. Let Machine Learning Models and LLMs Collaborate for Enhanced In-Context Learning in Healthcare**|Fatemeh Nazary et.al.|[2405.06270v3](http://arxiv.org/abs/2405.06270v3)|null|
|**2024-05-09**|**To Trust or Not to Trust: Towards a novel approach to measure trust for XAI systems**|Miquel Mir√≥-Nicolau et.al.|[2405.05766v1](http://arxiv.org/abs/2405.05766v1)|null|
|**2024-05-05**|**Region-specific Risk Quantification for Interpretable Prognosis of COVID-19**|Zhusi Zhong et.al.|[2405.02815v1](http://arxiv.org/abs/2405.02815v1)|[link](https://github.com/zzs95/RSP_COVID)|
|**2024-04-29**|**M3H: Multimodal Multitask Machine Learning for Healthcare**|Dimitris Bertsimas et.al.|[2404.18975v2](http://arxiv.org/abs/2404.18975v2)|null|
|**2024-04-27**|**Advancing Healthcare Automation: Multi-Agent Systems for Medical Necessity Justification**|Himanshu Pandey et.al.|[2404.17977v1](http://arxiv.org/abs/2404.17977v1)|null|
|**2024-04-26**|**Rad4XCNN: a new agnostic method for post-hoc global explanation of CNN-derived features by means of radiomics**|Francesco Prinzi et.al.|[2405.02334v1](http://arxiv.org/abs/2405.02334v1)|null|
|**2024-04-25**|**Attributing Responsibility in AI-Induced Incidents: A Computational Reflective Equilibrium Framework for Accountability**|Yunfei Ge et.al.|[2404.16957v1](http://arxiv.org/abs/2404.16957v1)|null|
|**2024-04-19**|**Explainable AI for Fair Sepsis Mortality Predictive Model**|Chia-Hsuan Chang et.al.|[2404.13139v1](http://arxiv.org/abs/2404.13139v1)|null|
|**2024-04-19**|**Multi Class Depression Detection Through Tweets using Artificial Intelligence**|Muhammad Osama Nusrat et.al.|[2404.13104v1](http://arxiv.org/abs/2404.13104v1)|[link](https://github.com/mnusrat786/masters-thesis)|
|**2024-04-19**|**COIN: Counterfactual inpainting for weakly supervised semantic segmentation for medical images**|Dmytro Shvetsov et.al.|[2404.12832v1](http://arxiv.org/abs/2404.12832v1)|[link](https://github.com/dmytro-shvetsov/counterfactual-search)|
|**2024-04-09**|**Advancements in Radiomics and Artificial Intelligence for Thyroid Cancer Diagnosis**|Milad Yousefi et.al.|[2404.07239v1](http://arxiv.org/abs/2404.07239v1)|null|
|**2024-04-06**|**Predictive Modeling for Breast Cancer Classification in the Context of Bangladeshi Patients: A Supervised Machine Learning Approach with Explainable AI**|Taminul Islam et.al.|[2404.04686v1](http://arxiv.org/abs/2404.04686v1)|null|
|**2024-04-05**|**Enhancing Breast Cancer Diagnosis in Mammography: Evaluation and Integration of Convolutional Neural Networks and Explainable AI**|Maryam Ahmed et.al.|[2404.03892v3](http://arxiv.org/abs/2404.03892v3)|null|
|**2024-03-26**|**Addressing Social Misattributions of Large Language Models: An HCXAI-based Approach**|Andrea Ferrario et.al.|[2403.17873v1](http://arxiv.org/abs/2403.17873v1)|null|
|**2024-03-26**|**Clinical Domain Knowledge-Derived Template Improves Post Hoc AI Explanations in Pneumothorax Classification**|Han Yuan et.al.|[2403.18871v1](http://arxiv.org/abs/2403.18871v1)|[link](https://github.com/han-yuan-med/template-explanation)|
|**2024-03-03**|**Enhancing Neural Machine Translation of Low-Resource Languages: Corpus Development, Human Evaluation and Explainable AI Architectures**|S√©amus Lankford et.al.|[2403.01580v1](http://arxiv.org/abs/2403.01580v1)|null|
|**2024-02-28**|**Artificial Intelligence and Diabetes Mellitus: An Inside Look Through the Retina**|Yasin Sadeghi Bazargani et.al.|[2402.18600v1](http://arxiv.org/abs/2402.18600v1)|null|
|**2024-02-22**|**Multi-stakeholder Perspective on Responsible Artificial Intelligence and Acceptability in Education**|A. J. Karran et.al.|[2402.15027v2](http://arxiv.org/abs/2402.15027v2)|null|
|**2024-02-12**|**Deciphering Heartbeat Signatures: A Vision Transformer Approach to Explainable Atrial Fibrillation Detection from ECG Signals**|Aruna Mohan et.al.|[2402.09474v2](http://arxiv.org/abs/2402.09474v2)|null|
|**2024-02-05**|**Illuminate: A novel approach for depression detection with explainable analysis and proactive therapy using prompt engineering**|Aryan Agrawal et.al.|[2402.05127v1](http://arxiv.org/abs/2402.05127v1)|null|
|**2024-01-24**|**Information That Matters: Exploring Information Needs of People Affected by Algorithmic Decisions**|Timoth√©e Schmude et.al.|[2401.13324v4](http://arxiv.org/abs/2401.13324v4)|null|
|**2024-01-02**|**Evaluating Large Language Models on the GMAT: Implications for the Future of Business Education**|Vahid Ashrafimoghari et.al.|[2401.02985v1](http://arxiv.org/abs/2401.02985v1)|null|
|**2023-12-29**|**XAI for In-hospital Mortality Prediction via Multimodal ICU Data**|Xingqiao Li et.al.|[2312.17624v1](http://arxiv.org/abs/2312.17624v1)|[link](https://github.com/lixingqiao/xai-icu)|
|**2023-12-22**|**Joining Forces for Pathology Diagnostics with AI Assistance: The EMPAIA Initiative**|Norman Zerbe et.al.|[2401.09450v2](http://arxiv.org/abs/2401.09450v2)|null|
|**2023-12-18**|**Robust Stochastic Graph Generator for Counterfactual Explanations**|Mario Alfonso Prado-Romero et.al.|[2312.11747v2](http://arxiv.org/abs/2312.11747v2)|null|
|**2023-12-10**|**Evaluating the Utility of Model Explanations for Model Development**|Shawn Im et.al.|[2312.06032v1](http://arxiv.org/abs/2312.06032v1)|null|
|**2023-12-05**|**Building Trustworthy NeuroSymbolic AI Systems: Consistency, Reliability, Explainability, and Safety**|Manas Gaur et.al.|[2312.06798v1](http://arxiv.org/abs/2312.06798v1)|null|
|**2023-11-28**|**Deployment of a Robust and Explainable Mortality Prediction Model: The COVID-19 Pandemic and Beyond**|Jacob R. Epifano et.al.|[2311.17133v1](http://arxiv.org/abs/2311.17133v1)|null|
|**2023-11-27**|**Variational Autoencoders for Feature Exploration and Malignancy Prediction of Lung Lesions**|Benjamin Keel et.al.|[2311.15719v1](http://arxiv.org/abs/2311.15719v1)|[link](https://github.com/benkeel/vae_lung_lesion_bmvc)|
|**2023-11-24**|**MRxaI: Black-Box Explainability for Image Classifiers in a Medical Setting**|Nathan Blake et.al.|[2311.14471v1](http://arxiv.org/abs/2311.14471v1)|null|
|**2023-11-21**|**Moderating Model Marketplaces: Platform Governance Puzzles for AI Intermediaries**|Robert Gorwa et.al.|[2311.12573v2](http://arxiv.org/abs/2311.12573v2)|null|
|**2023-11-20**|**Ovarian Cancer Data Analysis using Deep Learning: A Systematic Review from the Perspectives of Key Features of Data Analysis and AI Assurance**|Muta Tah Hira et.al.|[2311.11932v1](http://arxiv.org/abs/2311.11932v1)|null|
|**2023-11-18**|**Representing visual classification as a linear combination of words**|Shobhit Agarwal et.al.|[2311.10933v1](http://arxiv.org/abs/2311.10933v1)|[link](https://github.com/lotterlab/task_word_explainability)|
|**2023-11-03**|**Towards objective and systematic evaluation of bias in medical imaging AI**|Emma A. M. Stanley et.al.|[2311.02115v1](http://arxiv.org/abs/2311.02115v1)|[link](https://github.com/estanley16/simba)|
|**2023-10-29**|**Predicting recovery following stroke: deep learning, multimodal data and feature selection using explainable AI**|Adam White et.al.|[2310.19174v1](http://arxiv.org/abs/2310.19174v1)|null|
|**2023-10-03**|**Trainable Noise Model as an XAI evaluation method: application on Sobol for remote sensing image segmentation**|Hossein Shreim et.al.|[2310.01828v2](http://arxiv.org/abs/2310.01828v2)|[link](https://github.com/geoaigroup/geoai-ecrs2023)|
|**2023-09-26**|**Creating Trustworthy LLMs: Dealing with Hallucinations in Healthcare AI**|Muhammad Aurangzeb Ahmad et.al.|[2311.01463v1](http://arxiv.org/abs/2311.01463v1)|null|
|**2023-09-20**|**When to Trust AI: Advances and Challenges for Certification of Neural Networks**|Marta Kwiatkowska et.al.|[2309.11196v1](http://arxiv.org/abs/2309.11196v1)|null|
|**2023-09-19**|**Functional requirements to mitigate the Risk of Harm to Patients from Artificial Intelligence in Healthcare**|Juan M. Garc√≠a-G√≥mez et.al.|[2309.10424v1](http://arxiv.org/abs/2309.10424v1)|null|
|**2023-09-19**|**QXAI: Explainable AI Framework for Quantitative Analysis in Patient Monitoring Systems**|Thanveer Shaik et.al.|[2309.10293v3](http://arxiv.org/abs/2309.10293v3)|null|
|**2023-09-18**|**Evaluation of Human-Understandability of Global Model Explanations using Decision Tree**|Adarsa Sivaprasad et.al.|[2309.09917v1](http://arxiv.org/abs/2309.09917v1)|null|
|**2023-09-02**|**An explainable three dimension framework to uncover learning patterns: A unified look in variable sulci recognition**|Michail Mamalakis et.al.|[2309.00903v2](http://arxiv.org/abs/2309.00903v2)|[link](https://github.com/ece7048/3dsulci)|
|**2023-08-28**|**Leveraging A Medical Knowledge Graph into Large Language Models for Diagnosis Prediction**|Yanjun Gao et.al.|[2308.14321v1](http://arxiv.org/abs/2308.14321v1)|null|
|**2023-08-18**|**Deciphering knee osteoarthritis diagnostic features with explainable artificial intelligence: A systematic review**|Yun Xin Teoh et.al.|[2308.09380v1](http://arxiv.org/abs/2308.09380v1)|null|
|**2023-08-16**|**Explainable AI for clinical risk prediction: a survey of concepts, methods, and modalities**|Munib Mesinovic et.al.|[2308.08407v1](http://arxiv.org/abs/2308.08407v1)|null|
|**2023-08-11**|**FUTURE-AI: International consensus guideline for trustworthy and deployable artificial intelligence in healthcare**|Karim Lekadir et.al.|[2309.12325v1](http://arxiv.org/abs/2309.12325v1)|null|
|**2023-08-10**|**Explainable AI applications in the Medical Domain: a systematic review**|Nicoletta Prentzas et.al.|[2308.05411v1](http://arxiv.org/abs/2308.05411v1)|null|
|**2023-08-01**|**Exploring the Role of Explainability in AI-Assisted Embryo Selection**|Lucia Urcelay et.al.|[2308.02534v1](http://arxiv.org/abs/2308.02534v1)|null|
|**2023-07-26**|**A New Perspective on Evaluation Methods for Explainable Artificial Intelligence (XAI)**|Timo Speith et.al.|[2307.14246v1](http://arxiv.org/abs/2307.14246v1)|null|
|**2023-07-26**|**Revisiting the Performance-Explainability Trade-Off in Explainable Artificial Intelligence (XAI)**|Barnaby Crook et.al.|[2307.14239v1](http://arxiv.org/abs/2307.14239v1)|null|
|**2023-07-26**|**Acceptable risks in Europe's proposed AI Act: Reasonableness and other principles for deciding how much risk management is enough**|Henry Fraser et.al.|[2308.02047v1](http://arxiv.org/abs/2308.02047v1)|null|
|**2023-07-21**|**eXplainable Artificial Intelligence (XAI) in aging clock models**|Alena Kalyakulina et.al.|[2307.13704v3](http://arxiv.org/abs/2307.13704v3)|null|
|**2023-07-19**|**Interpreting and Correcting Medical Image Classification with PIP-Net**|Meike Nauta et.al.|[2307.10404v2](http://arxiv.org/abs/2307.10404v2)|[link](https://github.com/m-nauta/pipnet)|
|**2023-07-15**|**Explaining and visualizing black-box models through counterfactual paths**|Bastian Pfeifer et.al.|[2307.07764v3](http://arxiv.org/abs/2307.07764v3)|[link](https://github.com/pievos101/cpath)|
|**2023-07-05**|**Beyond Known Reality: Exploiting Counterfactual Explanations for Medical Research**|Toygar Tanyel et.al.|[2307.02131v5](http://arxiv.org/abs/2307.02131v5)|[link](https://github.com/toygarr/counterfactual-explanations-for-medical-research)|
|**2023-06-30**|**AI and Non AI Assessments for Dementia**|Mahboobeh Parsapoor et.al.|[2307.01210v1](http://arxiv.org/abs/2307.01210v1)|null|
|**2023-06-12**|**Active Globally Explainable Learning for Medical Images via Class Association Embedding and Cyclic Adversarial Generation**|Ruitao Xie et.al.|[2306.07306v1](http://arxiv.org/abs/2306.07306v1)|null|
|**2023-06-09**|**HiTZ@Antidote: Argumentation-driven Explainable Artificial Intelligence for Digital Medicine**|Rodrigo Agerri et.al.|[2306.06029v1](http://arxiv.org/abs/2306.06029v1)|null|
|**2023-06-07**|**XInsight: Revealing Model Insights for GNNs with Flow-based Explanations**|Eli Laird et.al.|[2306.04791v1](http://arxiv.org/abs/2306.04791v1)|null|
|**2023-06-06**|**Explainable AI using expressive Boolean formulas**|Gili Rosenberg et.al.|[2306.03976v1](http://arxiv.org/abs/2306.03976v1)|null|
|**2023-06-06**|**Utterance Classification with Logical Neural Network: Explainable AI for Mental Disorder Diagnosis**|Yeldar Toleubay et.al.|[2306.03902v1](http://arxiv.org/abs/2306.03902v1)|null|
|**2023-06-02**|**XAI Renaissance: Redefining Interpretability in Medical Diagnostic Models**|Sujith K Mandala et.al.|[2306.01668v1](http://arxiv.org/abs/2306.01668v1)|null|
|**2023-05-26**|**A Novel real-time arrhythmia detection model using YOLOv8**|Guang Jun Nicholas Ang et.al.|[2305.16727v3](http://arxiv.org/abs/2305.16727v3)|null|
|**2023-05-22**|**Breast Cancer Segmentation using Attention-based Convolutional Network and Explainable AI**|Jai Vardhan et.al.|[2305.14389v2](http://arxiv.org/abs/2305.14389v2)|null|
|**2023-05-18**|**What Symptoms and How Long? An Interpretable AI Approach for Depression Detection in Social Media**|Junwei Kuang et.al.|[2305.13127v2](http://arxiv.org/abs/2305.13127v2)|null|
|**2023-05-17**|**Echoes of Biases: How Stigmatizing Language Affects AI Performance**|Yizhi Liu et.al.|[2305.10201v4](http://arxiv.org/abs/2305.10201v4)|null|
|**2023-05-05**|**Explaining the ghosts: Feminist intersectional XAI and cartography as methods to account for invisible labour**|Goda Klumbyte et.al.|[2305.03376v1](http://arxiv.org/abs/2305.03376v1)|null|
|**2023-04-25**|**Towards Explainable and Safe Conversational Agents for Mental Health: A Survey**|Surjodeep Sarkar et.al.|[2304.13191v1](http://arxiv.org/abs/2304.13191v1)|null|
|**2023-04-04**|**A Brief Review of Explainable Artificial Intelligence in Healthcare**|Zahra Sadeghi et.al.|[2304.01543v1](http://arxiv.org/abs/2304.01543v1)|null|
|**2023-03-22**|**Reveal to Revise: An Explainable AI Life Cycle for Iterative Bias Correction of Deep Models**|Frederik Pahde et.al.|[2303.12641v2](http://arxiv.org/abs/2303.12641v2)|[link](https://github.com/maxdreyer/reveal2revise)|
|**2023-03-11**|**Explainable AI for Time Series via Virtual Inspection Layers**|Johanna Vielhaben et.al.|[2303.06365v1](http://arxiv.org/abs/2303.06365v1)|null|
|**2023-03-08**|**Towards Trust of Explainable AI in Thyroid Nodule Diagnosis**|Truong Thanh Hung Nguyen et.al.|[2303.04731v1](http://arxiv.org/abs/2303.04731v1)|[link](https://github.com/hungntt/xai_thyroid)|
|**2023-03-06**|**Cybersecurity of AI medical devices: risks, legislation, and challenges**|Elisabetta Biasin et.al.|[2303.03140v1](http://arxiv.org/abs/2303.03140v1)|null|
|**2023-02-06**|**LAVA: Granular Neuron-Level Explainable AI for Alzheimer's Disease Assessment from Fundus Images**|Nooshin Yousefzadeh et.al.|[2302.03008v2](http://arxiv.org/abs/2302.03008v2)|null|
|**2023-02-02**|**Diagrammatization: Rationalizing with diagrammatic AI explanations for abductive-deductive reasoning on hypotheses**|Brian Y. Lim et.al.|[2302.01241v2](http://arxiv.org/abs/2302.01241v2)|null|
|**2023-02-02**|**LesionAid: Vision Transformers-based Skin Lesion Generation and Classification**|Ghanta Sai Krishna et.al.|[2302.01104v1](http://arxiv.org/abs/2302.01104v1)|null|
|**2023-02-01**|**SkinCon: A skin disease dataset densely annotated by domain experts for fine-grained model debugging and analysis**|Roxana Daneshjou et.al.|[2302.00785v1](http://arxiv.org/abs/2302.00785v1)|null|
|**2023-01-19**|**Decision-Focused Evaluation: Analyzing Performance of Deployed Restless Multi-Arm Bandits**|Paritosh Verma et.al.|[2301.07835v1](http://arxiv.org/abs/2301.07835v1)|null|
|**2023-01-18**|**Exemplars and Counterexemplars Explanations for Image Classifiers, Targeting Skin Lesion Labeling**|Carlo Metta et.al.|[2302.03033v1](http://arxiv.org/abs/2302.03033v1)|null|
|**2023-01-17**|**Monotonicity for AI ethics and society: An empirical study of the monotonic neural additive model in criminology, education, health care, and finance**|Dangxing Chen et.al.|[2301.07060v1](http://arxiv.org/abs/2301.07060v1)|null|
|**2023-01-15**|**Rationalizing Predictions by Adversarial Information Calibration**|Lei Sha et.al.|[2301.06009v1](http://arxiv.org/abs/2301.06009v1)|null|
|**2023-01-05**|**Semantic match: Debugging feature attribution methods in XAI for healthcare**|Giovanni Cin√† et.al.|[2301.02080v3](http://arxiv.org/abs/2301.02080v3)|null|
|**2022-12-17**|**Context-dependent Explainability and Contestability for Trustworthy Medical Artificial Intelligence: Misclassification Identification of Morbidity Recognition Models in Preterm Infants**|Isil Guzey et.al.|[2212.08821v1](http://arxiv.org/abs/2212.08821v1)|null|
|**2022-12-16**|**It is not "accuracy vs. explainability" -- we need both for trustworthy AI systems**|D. Petkovic et.al.|[2212.11136v2](http://arxiv.org/abs/2212.11136v2)|null|
|**2022-12-02**|**SimpleMind adds thinking to deep neural networks**|Youngwon Choi et.al.|[2212.00951v1](http://arxiv.org/abs/2212.00951v1)|[link](https://gitlab.com/sm-ai-team/simplemind)|
|**2022-11-27**|**Attribution-based XAI Methods in Computer Vision: A Review**|Kumar Abhishek et.al.|[2211.14736v1](http://arxiv.org/abs/2211.14736v1)|null|
|**2022-11-08**|**Privacy Meets Explainability: A Comprehensive Impact Benchmark**|Saifullah Saifullah et.al.|[2211.04110v1](http://arxiv.org/abs/2211.04110v1)|null|
|**2022-11-05**|**Predicting Treatment Adherence of Tuberculosis Patients at Scale**|Mihir Kulkarni et.al.|[2211.02943v2](http://arxiv.org/abs/2211.02943v2)|null|
|**2022-11-02**|**Explainable AI over the Internet of Things (IoT): Overview, State-of-the-Art and Future Directions**|Senthil Kumar Jagatheesaperumal et.al.|[2211.01036v2](http://arxiv.org/abs/2211.01036v2)|null|
|**2022-10-24**|**Human-centered XAI for Burn Depth Characterization**|Maxwell J. Jacobson et.al.|[2210.13535v2](http://arxiv.org/abs/2210.13535v2)|null|
|**2022-10-07**|**What Do End-Users Really Want? Investigation of Human-Centered XAI for Mobile Health Apps**|Katharina Weitz et.al.|[2210.03506v1](http://arxiv.org/abs/2210.03506v1)|null|
|**2022-10-07**|**Explainable AI based Glaucoma Detection using Transfer Learning and LIME**|Touhidul Islam Chayan et.al.|[2210.03332v1](http://arxiv.org/abs/2210.03332v1)|null|
|**2022-09-30**|**Evaluation of importance estimators in deep learning classifiers for Computed Tomography**|Lennart Brocki et.al.|[2209.15398v1](http://arxiv.org/abs/2209.15398v1)|null|
|**2022-09-30**|**An Interactive Interpretability System for Breast Cancer Screening with Deep Learning**|Yuzhe Lu et.al.|[2210.08979v1](http://arxiv.org/abs/2210.08979v1)|null|
|**2022-09-14**|**Explainable AI for clinical and remote health applications: a survey on tabular and time series data**|Flavio Di Martino et.al.|[2209.06528v1](http://arxiv.org/abs/2209.06528v1)|null|

#### Abstracts
##### **Improving Health Professionals' Onboarding with AI and XAI for Trustworthy Human-AI Collaborative Decision Making**
2405.16424v1 by Min Hun Lee, Silvana Xin Yi Choo, Shamala D/O Thilarajah

With advanced AI/ML, there has been growing research on explainable AI (XAI)
and studies on how humans interact with AI and XAI for effective human-AI
collaborative decision-making. However, we still have a lack of understanding
of how AI systems and XAI should be first presented to users without technical
backgrounds. In this paper, we present the findings of semi-structured
interviews with health professionals (n=12) and students (n=4) majoring in
medicine and health to study how to improve onboarding with AI and XAI. For the
interviews, we built upon human-AI interaction guidelines to create onboarding
materials of an AI system for stroke rehabilitation assessment and AI
explanations and introduce them to the participants. Our findings reveal that
beyond presenting traditional performance metrics on AI, participants desired
benchmark information, the practical benefits of AI, and interaction trials to
better contextualize AI performance, and refine the objectives and performance
of AI. Based on these findings, we highlight directions for improving
onboarding with AI and XAI and human-AI collaborative decision-making.

ÊëòË¶ÅÔºöÈö®ËëóÂÖàÈÄ≤ÁöÑ AI/MLÔºåÂ∞çÂèØËß£Èáã AI (XAI) ÁöÑÁ†îÁ©∂‰∏çÊñ∑Â¢ûÂä†Ôºå‰ª•ÂèäÈóúÊñº‰∫∫È°ûÂ¶Ç‰ΩïËàá AI Âíå XAI ‰∫íÂãï‰ª•ÈÄ≤Ë°åÊúâÊïàÁöÑ‰∫∫Â∑•Êô∫ÊÖßÂçî‰ΩúÊ±∫Á≠ñÂà∂ÂÆö„ÄÇÁÑ∂ËÄåÔºåÊàëÂÄë‰ªçÁÑ∂Áº∫‰πèÂ∞ç AI Á≥ªÁµ±Âíå XAI ÊáâÂ¶Ç‰ΩïÈ¶ñÂÖàÂëàÁèæÁµ¶Ê≤íÊúâÊäÄË°ìËÉåÊôØÁöÑÁî®Êà∂ÁöÑ‰∫ÜËß£„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜËàáÈÜ´ÁôÇÂ∞àÊ•≠‰∫∫Âì° (n=12) Âíå‰∏ª‰øÆÈÜ´Â≠∏ÂíåÂÅ•Â∫∑ÁöÑÂ≠∏Áîü (n=4) ÈÄ≤Ë°åÂçäÁµêÊßãÂåñË®™Ë´áÁöÑÁµêÊûúÔºå‰ª•Á†îÁ©∂Â¶Ç‰ΩïÊîπÂñÑ AI Âíå XAI ÁöÑÂÖ•ÈñÄ„ÄÇÂ∞çÊñºË®™Ë´áÔºåÊàëÂÄëÂª∫Á´ãÂú®‰∫∫Ê©ü‰∫íÂãïÊ∫ñÂâá‰πã‰∏äÔºåÁÇ∫‰∏≠È¢®Â∫∑Âæ©Ë©ï‰º∞Âíå AI Ëß£ÈáãÁöÑ AI Á≥ªÁµ±ÂâµÂª∫ÂÖ•ÈñÄÊùêÊñôÔºå‰∏¶Â∞áÂÆÉÂÄë‰ªãÁ¥πÁµ¶ÂèÉËàáËÄÖ„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúË°®ÊòéÔºåÈô§‰∫ÜÂëàÁèæÂÇ≥Áµ±ÁöÑ AI ÊÄßËÉΩÊåáÊ®ôÂ§ñÔºåÂèÉËàáËÄÖÈÇÑÂ∏åÊúõÂü∫ÂáÜ‰ø°ÊÅØ„ÄÅAI ÁöÑÂØ¶ÈöõÂ•ΩËôï‰ª•Âèä‰∫§‰∫íË©¶È©óÔºå‰ª•Êõ¥Â•ΩÂú∞Â∞á AI ÊÄßËÉΩÊÉÖÂ¢ÉÂåñÔºå‰∏¶ÂÆåÂñÑ AI ÁöÑÁõÆÊ®ôÂíåÊÄßËÉΩ„ÄÇÊ†πÊìöÈÄô‰∫õÁôºÁèæÔºåÊàëÂÄëÂº∑Ë™ø‰∫ÜÊîπÈÄ≤ AI Âíå XAI ‰ª•Âèä‰∫∫Ê©üÂçî‰ΩúÊ±∫Á≠ñÂà∂ÂÆöÁöÑÂÖ•ÈñÄÊñπÂêë„ÄÇ

##### **Exploring Nutritional Impact on Alzheimer's Mortality: An Explainable AI Approach**
2405.17502v1 by Ziming Liu, Longjian Liu, Robert E. Heidel, Xiaopeng Zhao

This article uses machine learning (ML) and explainable artificial
intelligence (XAI) techniques to investigate the relationship between
nutritional status and mortality rates associated with Alzheimers disease (AD).
The Third National Health and Nutrition Examination Survey (NHANES III)
database is employed for analysis. The random forest model is selected as the
base model for XAI analysis, and the Shapley Additive Explanations (SHAP)
method is used to assess feature importance. The results highlight significant
nutritional factors such as serum vitamin B12 and glycated hemoglobin. The
study demonstrates the effectiveness of random forests in predicting AD
mortality compared to other diseases. This research provides insights into the
impact of nutrition on AD and contributes to a deeper understanding of disease
progression.

ÊëòË¶ÅÔºöÊú¨Êñá‰ΩøÁî®Ê©üÂô®Â≠∏Áøí (ML) ÂíåÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖß (XAI) ÊäÄË°ì‰æÜÊé¢Ë®éÁáüÈ§äÁãÄÊ≥ÅËàáÈòøËå≤Êµ∑ÈªòÁóá (AD) Áõ∏ÈóúÁöÑÊ≠ª‰∫°Áéá‰πãÈñìÁöÑÈóú‰øÇ„ÄÇÊé°Áî®Á¨¨‰∏âÊ¨°ÂÖ®ÂúãÂÅ•Â∫∑ËàáÁáüÈ§äÊ™¢Êü•Ë™øÊü• (NHANES III) Ë≥áÊñôÂ∫´ÈÄ≤Ë°åÂàÜÊûê„ÄÇÈÅ∏ÊìáÈö®Ê©üÊ£ÆÊûóÊ®°Âûã‰ΩúÁÇ∫ XAI ÂàÜÊûêÁöÑÂü∫Á§éÊ®°ÂûãÔºå‰∏¶‰ΩøÁî® Shapley Additive Explanations (SHAP) ÊñπÊ≥ï‰æÜË©ï‰º∞ÁâπÂæµÈáçË¶ÅÊÄß„ÄÇÁµêÊûúÁ™ÅÈ°Ø‰∫ÜÈáçË¶ÅÁöÑÁáüÈ§äÂõ†Á¥†Ôºå‰æãÂ¶ÇË°ÄÊ∏ÖÁ∂≠ÁîüÁ¥† B12 ÂíåÁ≥ñÂåñË°ÄÁ¥ÖËõãÁôΩ„ÄÇË©≤Á†îÁ©∂Ë≠âÊòé‰∫ÜÈö®Ê©üÊ£ÆÊûóÂú®È†êÊ∏¨ AD Ê≠ª‰∫°ÁéáÊñπÈù¢Áõ∏ËºÉÊñºÂÖ∂‰ªñÁñæÁóÖÁöÑÊúâÊïàÊÄß„ÄÇÊú¨Á†îÁ©∂Êèê‰æõ‰∫ÜÁáüÈ§äÂ∞ç AD ÁöÑÂΩ±ÈüøÁöÑË¶ãËß£Ôºå‰∏¶ÊúâÂä©ÊñºÊõ¥Ê∑±ÂÖ•Âú∞‰∫ÜËß£ÁñæÁóÖÁöÑÈÄ≤Â±ï„ÄÇ

##### **The Role of Emotions in Informational Support Question-Response Pairs in Online Health Communities: A Multimodal Deep Learning Approach**
2405.13099v1 by Mohsen Jozani, Jason A. Williams, Ahmed Aleroud, Sarbottam Bhagat

This study explores the relationship between informational support seeking
questions, responses, and helpfulness ratings in online health communities. We
created a labeled data set of question-response pairs and developed multimodal
machine learning and deep learning models to reliably predict informational
support questions and responses. We employed explainable AI to reveal the
emotions embedded in informational support exchanges, demonstrating the
importance of emotion in providing informational support. This complex
interplay between emotional and informational support has not been previously
researched. The study refines social support theory and lays the groundwork for
the development of user decision aids. Further implications are discussed.

ÊëòË¶ÅÔºöÊú¨Á†îÁ©∂Êé¢Ë®éÁ∑ö‰∏äÂÅ•Â∫∑Á§æÁæ§‰∏≠Â∞ãÊ±ÇË≥áË®äÊîØÊåÅÁöÑÂïèÈ°å„ÄÅÂõûÊáâÔºå‰ª•ÂèäÊúâÂπ´Âä©ÁöÑË©ïÂàÜ‰πãÈñìÁöÑÈóú‰øÇ„ÄÇÊàëÂÄëÂª∫Á´ã‰∫Ü‰∏ÄÁµÑÊ®ôË®òÁöÑÂïèÁ≠îÈÖçÂ∞çË≥áÊñôÈõÜÔºå‰∏¶ÈñãÁôº‰∫ÜÂ§öÊ®°ÊÖãÊ©üÂô®Â≠∏ÁøíÂíåÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÔºå‰ª•ÂèØÈù†Âú∞È†êÊ∏¨Ë≥áË®äÊîØÊåÅÂïèÈ°åÂíåÂõûÊáâ„ÄÇÊàëÂÄëÊé°Áî®ÂèØËß£ÈáãÁöÑ AI ‰æÜÊè≠Á§∫Ë≥áË®äÊîØÊåÅ‰∫§ÊµÅ‰∏≠ËòäÂê´ÁöÑÊÉÖÁ∑íÔºåË≠âÊòéÊÉÖÁ∑íÂú®Êèê‰æõË≥áË®äÊîØÊåÅ‰∏≠ÁöÑÈáçË¶ÅÊÄß„ÄÇÈÄôÁ®ÆÊÉÖÁ∑íÊîØÊåÅÂíåË≥áË®äÊîØÊåÅ‰πãÈñìÁöÑË§áÈõú‰∫§‰∫í‰ΩúÁî®‰ª•Ââç‰∏¶Êú™Ë¢´Á†îÁ©∂ÈÅé„ÄÇÊú¨Á†îÁ©∂ÊîπÈÄ≤‰∫ÜÁ§æÊúÉÊîØÊåÅÁêÜË´ñÔºå‰∏¶ÁÇ∫‰ΩøÁî®ËÄÖÊ±∫Á≠ñËºîÂä©Â∑•ÂÖ∑ÁöÑÈñãÁôºÂ•†ÂÆö‰∫ÜÂü∫Á§é„ÄÇË®éË´ñ‰∫ÜÈÄ≤‰∏ÄÊ≠•ÁöÑÂΩ±Èüø„ÄÇ

##### **ChatGPT in Classrooms: Transforming Challenges into Opportunities in Education**
2405.10645v1 by Harris Bin Munawar, Nikolaos Misirlis

In the era of exponential technology growth, one unexpected guest has claimed
a seat in classrooms worldwide, Artificial Intelligence. Generative AI, such as
ChatGPT, promises a revolution in education, yet it arrives with a double-edged
sword. Its potential for personalized learning is offset by issues of cheating,
inaccuracies, and educators struggling to incorporate it effectively into their
lesson design. We are standing on the brink of this educational frontier, and
it is clear that we need to navigate this terrain with a lot of care. This is a
major challenge that could undermine the integrity and value of our educational
process. So, how can we turn these challenges into opportunities? When used
inappropriately, AI tools can become the perfect tool for the cut copy paste
mentality, and quickly begin to corrode critical thinking, creativity, and deep
understanding, the most important skills in our rapidly changing world.
Teachers feel that they are not equipped to leverage this technology, widening
the digital divide among educators and institutions. Addressing these concerns
calls for an in depth research approach. We will employ empirical research,
drawing on the Technology Acceptance Model, to assess the attitudes toward
generative AI among educators and students. Understanding their perceptions,
usage patterns, and hurdles is the first crucial step in creating an effective
solution. The present study will be used as a process manual for future
researchers to apply, running their own data, based on the steps explained here

ÊëòË¶ÅÔºöÂú®ÁßëÊäÄÈ£õÈÄüÁôºÂ±ïÁöÑÊôÇ‰ª£Ôºå‰∏Ä‰ΩçÊÑèÂ§ñÁöÑË®™ÂÆ¢Â∑≤Âú®ÂÖ®ÁêÉÊïôÂÆ§‰∏≠‰ΩîÊúâ‰∏ÄÂ∏≠‰πãÂú∞ÔºåÈÇ£Â∞±ÊòØ‰∫∫Â∑•Êô∫ÊÖß„ÄÇÁîüÊàêÂºè AIÔºå‰æãÂ¶Ç ChatGPTÔºåÊâøË´æÂú®ÊïôËÇ≤È†òÂüüÊéÄËµ∑‰∏ÄÂ†¥Èù©ÂëΩÔºå‰ΩÜÂÆÉÂçªÊòØ‰∏ÄÊääÈõôÈù¢ÂàÉ„ÄÇÂÆÉÂú®ÂÄã‰∫∫ÂåñÂ≠∏ÁøíÊñπÈù¢ÁöÑÊΩõÂäõÔºåÂçªÂõ†‰ΩúÂºä„ÄÅ‰∏çÊ∫ñÁ¢∫‰ª•ÂèäÊïôËÇ≤Â∑•‰ΩúËÄÖÈõ£‰ª•Â∞áÂÖ∂ÊúâÊïàËûçÂÖ•ÊïôÂ≠∏Ë®≠Ë®àÁ≠âÂïèÈ°åËÄåÊäµÈä∑„ÄÇÊàëÂÄëÊ≠£Á´ôÂú®ÈÄôÊïôËÇ≤ÂâçÊ≤øÁöÑÈÇäÁ∑£ÔºåÈ°ØÁÑ∂ÊàëÂÄëÈúÄË¶ÅÈùûÂ∏∏Â∞èÂøÉÂú∞Êé¢Á¥¢ÈÄôÁâáÈ†òÂüü„ÄÇÈÄôÊòØ‰∏ÄÂÄãÈáçÂ§ßÁöÑÊåëÊà∞ÔºåÂèØËÉΩÊúÉÊêçÂÆ≥ÊàëÂÄëÊïôËÇ≤ÈÅéÁ®ãÁöÑÂÆåÊï¥ÊÄßÂíåÂÉπÂÄº„ÄÇÈÇ£È∫ºÔºåÊàëÂÄëÂ¶Ç‰ΩïÂ∞áÈÄô‰∫õÊåëÊà∞ËΩâÂåñÁÇ∫Ê©üÈÅáÔºüÁï∂‰∏çÈÅ©Áï∂Âú∞‰ΩøÁî®ÊôÇÔºåAI Â∑•ÂÖ∑ÂèØËÉΩÊúÉÊàêÁÇ∫Ë§áË£ΩË≤º‰∏äÂøÉÊÖãÁöÑÂÆåÁæéÂ∑•ÂÖ∑Ôºå‰∏¶ËøÖÈÄüËÖêËùïÊâπÂà§ÊÄßÊÄùÁ∂≠„ÄÅÂâµÈÄ†ÂäõÂíåÊ∑±ÂÖ•ÁêÜËß£ÔºåÈÄô‰∫õÈÉΩÊòØÊàëÂÄëÂø´ÈÄüËÆäÂåñÁöÑ‰∏ñÁïå‰∏≠ÊúÄÈáçË¶ÅÁöÑÊäÄËÉΩ„ÄÇÊïôÂ∏´ÂÄëË¶∫Âæó‰ªñÂÄëÊ≤íÊúâËÉΩÂäõÂà©Áî®ÈÄôÈ†ÖÊäÄË°ìÔºåÈÄôÊì¥Â§ß‰∫ÜÊïôËÇ≤Â∑•‰ΩúËÄÖÂíåÊ©üÊßã‰πãÈñìÁöÑÊï∏‰ΩçÈ¥ªÊ∫ù„ÄÇËß£Ê±∫ÈÄô‰∫õÂïèÈ°åÈúÄË¶ÅÊ∑±ÂÖ•ÁöÑÁ†îÁ©∂ÊñπÊ≥ï„ÄÇÊàëÂÄëÂ∞áÊé°Áî®ÂØ¶Ë≠âÁ†îÁ©∂ÔºåÂÄüÈëëÊäÄË°ìÊé•ÂèóÊ®°ÂûãÔºå‰æÜË©ï‰º∞ÊïôËÇ≤Â∑•‰ΩúËÄÖÂíåÂ≠∏ÁîüÂ∞çÁîüÊàêÂºè AI ÁöÑÊÖãÂ∫¶„ÄÇ‰∫ÜËß£‰ªñÂÄëÁöÑÁúãÊ≥ï„ÄÅ‰ΩøÁî®Ê®°ÂºèÂíåÈöúÁ§ôÊòØÂâµÈÄ†ÊúâÊïàËß£Ê±∫ÊñπÊ°àÁöÑÁ¨¨‰∏ÄÂÄãÈóúÈçµÊ≠•È©ü„ÄÇÊú¨Á†îÁ©∂Â∞á‰ΩúÁÇ∫Êú™‰æÜÁ†îÁ©∂‰∫∫Âì°ÊáâÁî®ÁöÑÊµÅÁ®ãÊâãÂÜäÔºåÊ†πÊìöÊ≠§ËôïË™™ÊòéÁöÑÊ≠•È©üÈÅãË°å‰ªñÂÄëËá™Â∑±ÁöÑÊï∏Êìö

##### **Evaluating the Explainable AI Method Grad-CAM for Breath Classification on Newborn Time Series Data**
2405.07590v1 by Camelia Oprea, Mike Gr√ºne, Mateusz Buglowski, Lena Olivier, Thorsten Orlikowsky, Stefan Kowalewski, Mark Schoberer, Andr√© Stollenwerk

With the digitalization of health care systems, artificial intelligence
becomes more present in medicine. Especially machine learning shows great
potential for complex tasks such as time series classification, usually at the
cost of transparency and comprehensibility. This leads to a lack of trust by
humans and thus hinders its active usage. Explainable artificial intelligence
tries to close this gap by providing insight into the decision-making process,
the actual usefulness of its different methods is however unclear. This paper
proposes a user study based evaluation of the explanation method Grad-CAM with
application to a neural network for the classification of breaths in time
series neonatal ventilation data. We present the perceived usefulness of the
explainability method by different stakeholders, exposing the difficulty to
achieve actual transparency and the wish for more in-depth explanations by many
of the participants.

ÊëòË¶ÅÔºöÈö®ËëóÈÜ´ÁôÇ‰øùÂÅ•Á≥ªÁµ±ÁöÑÊï∏‰ΩçÂåñÔºå‰∫∫Â∑•Êô∫ÊÖßÂú®ÈÜ´Â≠∏È†òÂüü‰∏≠ËÆäÂæóÊõ¥Âä†ÊôÆÂèä„ÄÇÁâπÂà•ÊòØÊ©üÂô®Â≠∏ÁøíÂú®ÊôÇÈñìÂ∫èÂàóÂàÜÈ°ûÁ≠âË§áÈõú‰ªªÂãô‰∏≠Â±ïÁèæÂá∫Ê•µÂ§ßÁöÑÊΩõÂäõÔºå‰ΩÜÈÄöÂ∏∏ÊòØ‰ª•ÈÄèÊòéÂ∫¶ÂíåÂèØÁêÜËß£ÊÄßÁÇ∫‰ª£ÂÉπ„ÄÇÈÄôÂ∞éËá¥‰∫∫È°ûÁº∫‰πè‰ø°‰ªªÔºåÂæûËÄåÈòªÁ§ô‰∫ÜÂÖ∂Á©çÊ•µ‰ΩøÁî®„ÄÇÂèØËß£ÈáãÁöÑ‰∫∫Â∑•Êô∫ÊÖßË©¶ÂúñÈÄöÈÅéÊèê‰æõÂ∞çÊ±∫Á≠ñÈÅéÁ®ãÁöÑÊ¥ûÂØü‰æÜÂΩåË£úÈÄô‰∏ÄÂ∑ÆË∑ùÔºå‰ΩÜÂÖ∂‰∏çÂêåÊñπÊ≥ïÁöÑÂØ¶ÈöõÊïàÁî®Â∞ö‰∏çÊ∏ÖÊ•ö„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂü∫Êñº‰ΩøÁî®ËÄÖÁ†îÁ©∂ÁöÑË©ï‰º∞ÔºåÂÖ∂‰∏≠ÂåÖÂê´‰∫Ü Grad-CAM Ëß£ÈáãÊñπÊ≥ïÔºå‰∏¶Â∞áÂÖ∂ÊáâÁî®ÊñºÁ•ûÁ∂ìÁ∂≤Ë∑Ø‰ª•ÂàÜÈ°ûÊôÇÈñìÂ∫èÂàóÊñ∞ÁîüÂÖíÂëºÂê∏Êï∏Êìö‰∏≠ÁöÑÂëºÂê∏„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫Ü‰∏çÂêåÂà©ÁõäÁõ∏ÈóúËÄÖÂ∞çÂèØËß£ÈáãÊÄßÊñπÊ≥ïÁöÑÊÑüÁü•ÊïàÁî®ÔºåÊè≠Á§∫‰∫ÜÂØ¶ÁèæÂØ¶ÈöõÈÄèÊòéÂ∫¶ÁöÑÈõ£Â∫¶Ôºå‰ª•ÂèäË®±Â§öÂèÉËàáËÄÖÂ∏åÊúõÁç≤ÂæóÊõ¥Ê∑±ÂÖ•ÁöÑËß£Èáã„ÄÇ

##### **XAI4LLM. Let Machine Learning Models and LLMs Collaborate for Enhanced In-Context Learning in Healthcare**
2405.06270v3 by Fatemeh Nazary, Yashar Deldjoo, Tommaso Di Noia, Eugenio di Sciascio

The integration of Large Language Models (LLMs) into healthcare diagnostics
offers a promising avenue for clinical decision-making. This study outlines the
development of a novel method for zero-shot/few-shot in-context learning (ICL)
by integrating medical domain knowledge using a multi-layered structured
prompt. We also explore the efficacy of two communication styles between the
user and LLMs: the Numerical Conversational (NC) style, which processes data
incrementally, and the Natural Language Single-Turn (NL-ST) style, which
employs long narrative prompts.
  Our study systematically evaluates the diagnostic accuracy and risk factors,
including gender bias and false negative rates, using a dataset of 920 patient
records in various few-shot scenarios. Results indicate that traditional
clinical machine learning (ML) models generally outperform LLMs in zero-shot
and few-shot settings. However, the performance gap narrows significantly when
employing few-shot examples alongside effective explainable AI (XAI) methods as
sources of domain knowledge. Moreover, with sufficient time and an increased
number of examples, the conversational style (NC) nearly matches the
performance of ML models. Most notably, LLMs demonstrate comparable or superior
cost-sensitive accuracy relative to ML models.
  This research confirms that, with appropriate domain knowledge and tailored
communication strategies, LLMs can significantly enhance diagnostic processes.
The findings highlight the importance of optimizing the number of training
examples and communication styles to improve accuracy and reduce biases in LLM
applications.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ËàáÈÜ´ÁôÇË®∫Êñ∑Êï¥Âêà
ÁÇ∫Ëá®Â∫äÊ±∫Á≠ñÊèê‰æõ‰∫Ü‰∏ÄÂÄãÊúâÂâçÊôØÁöÑÈÄîÂæë„ÄÇÊú¨Á†îÁ©∂Ê¶ÇËø∞‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÊñπÊ≥ïÁöÑÈñãÁôºÔºåÁî®ÊñºÈõ∂Ê¨°Â≠∏Áøí/Â∞ëÈáèÂ≠∏ÁøíÊÉÖÂ¢ÉÂ≠∏Áøí (ICL)ÔºåÊñπÊ≥ïÊòØ‰ΩøÁî®Â§öÂ±§ÁµêÊßãÂåñÊèêÁ§∫Êï¥ÂêàÈÜ´ÁôÇÈ†òÂüüÁü•Ë≠ò„ÄÇÊàëÂÄëÈÇÑÊé¢Ë®é‰∫Ü‰ΩøÁî®ËÄÖËàá LLM ‰πãÈñìÂÖ©Á®ÆÊ∫ùÈÄöÊñπÂºèÁöÑÂäüÊïàÔºöÊï∏ÂÄºÂ∞çË©± (NC) ÊñπÂºèÔºåÂÆÉÊúÉÈÄêÊ≠•ËôïÁêÜË≥áÊñôÔºå‰ª•ÂèäËá™ÁÑ∂Ë™ûË®ÄÂñÆÂõûÂêà (NL-ST) ÊñπÂºèÔºåÂÆÉÊúÉ‰ΩøÁî®Èï∑ÁØáÊïò‰∫ãÊèêÁ§∫„ÄÇ
ÊàëÂÄëÁöÑÁ†îÁ©∂Á≥ªÁµ±ÊÄßÂú∞Ë©ï‰º∞‰∫ÜË®∫Êñ∑Ê∫ñÁ¢∫ÊÄßÂíåÈ¢®Èö™Âõ†Â≠êÔºåÂåÖÊã¨ÊÄßÂà•ÂÅèË¶ãÂíåÂÅáÈô∞ÊÄßÁéáÔºå‰ΩøÁî®‰∫Ü‰∏ÄÂÄãÂåÖÂê´ 920 ÂÄãÊÇ£ËÄÖË®òÈåÑÁöÑË≥áÊñôÈõÜÔºåÊé°Áî®ÂêÑÁ®ÆÂ∞ëÈáèÂ≠∏ÁøíÊÉÖÂ¢É„ÄÇÁµêÊûúË°®ÊòéÔºåÂÇ≥Áµ±ÁöÑËá®Â∫äÊ©üÂô®Â≠∏Áøí (ML) Ê®°ÂûãÈÄöÂ∏∏Âú®Èõ∂Ê¨°Â≠∏ÁøíÂíåÂ∞ëÈáèÂ≠∏ÁøíË®≠ÂÆö‰∏≠Ë°®ÁèæÂÑ™Êñº LLM„ÄÇÁÑ∂ËÄåÔºåÁï∂‰ΩøÁî®Â∞ëÈáèÂ≠∏ÁøíÁØÑ‰æã‰ª•ÂèäÊúâÊïàÁöÑÂèØËß£Èáã AI (XAI) ÊñπÊ≥ï‰ΩúÁÇ∫È†òÂüüÁü•Ë≠ò‰æÜÊ∫êÊôÇÔºåÊïàËÉΩÂ∑ÆË∑ùÊúÉÈ°ØËëóÁ∏ÆÂ∞è„ÄÇÊ≠§Â§ñÔºåÈö®ËëóÊôÇÈñìÂÖÖË∂≥ÂíåÁØÑ‰æãÊï∏ÈáèÂ¢ûÂä†ÔºåÂ∞çË©±ÊñπÂºè (NC) Âπæ‰πéÂèØ‰ª•Â™≤Áæé ML Ê®°ÂûãÁöÑÊïàËÉΩ„ÄÇÊúÄÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåLLM Áõ∏Â∞çÊñº ML Ê®°ÂûãÂ±ïÁèæÂá∫Áõ∏Áï∂ÊàñÊõ¥‰Ω≥ÁöÑÊàêÊú¨ÊïèÊÑüÊ∫ñÁ¢∫Â∫¶„ÄÇ
Êú¨Á†îÁ©∂Ë≠âÂØ¶ÔºåÈÄèÈÅéÈÅ©Áï∂ÁöÑÈ†òÂüüÁü•Ë≠òÂíåÈáèË∫´ÊâìÈÄ†ÁöÑÊ∫ùÈÄöÁ≠ñÁï•ÔºåLLM ÂèØ‰ª•È°ØËëóÂ¢ûÂº∑Ë®∫Êñ∑Á®ãÂ∫è„ÄÇÈÄô‰∫õÁôºÁèæÁ™ÅÈ°Ø‰∫ÜÊúÄ‰Ω≥ÂåñË®ìÁ∑¥ÁØÑ‰æãÊï∏ÈáèÂíåÊ∫ùÈÄöÊñπÂºèÁöÑÈáçË¶ÅÊÄßÔºå‰ª•ÊèêÈ´òÊ∫ñÁ¢∫Â∫¶‰∏¶Ê∏õÂ∞ë LLM ÊáâÁî®‰∏≠ÁöÑÂÅèÂ∑Æ„ÄÇ

##### **To Trust or Not to Trust: Towards a novel approach to measure trust for XAI systems**
2405.05766v1 by Miquel Mir√≥-Nicolau, Gabriel Moy√†-Alcover, Antoni Jaume-i-Cap√≥, Manuel Gonz√°lez-Hidalgo, Maria Gemma Sempere Campello, Juan Antonio Palmer Sancho

The increasing reliance on Deep Learning models, combined with their inherent
lack of transparency, has spurred the development of a novel field of study
known as eXplainable AI (XAI) methods. These methods seek to enhance the trust
of end-users in automated systems by providing insights into the rationale
behind their decisions. This paper presents a novel approach for measuring user
trust in XAI systems, allowing their refinement. Our proposed metric combines
both performance metrics and trust indicators from an objective perspective. To
validate this novel methodology, we conducted a case study in a realistic
medical scenario: the usage of XAI system for the detection of pneumonia from
x-ray images.

ÊëòË¶ÅÔºöÈö®ËëóÂ∞çÊ∑±Â∫¶Â≠∏ÁøíÊ®°Âûã‰æùË≥¥ÊÄßÁöÑÂ¢ûÂä†ÔºåÂä†‰∏äÂÖ∂Âõ∫ÊúâÁöÑÈÄèÊòéÂ∫¶‰∏çË∂≥Ôºå‰øÉ‰Ωø‰∏ÄÂÄãÊñ∞ÁöÑÁ†îÁ©∂È†òÂüüÁôºÂ±ïÔºåÁ®±ÁÇ∫ÂèØËß£Èáã AI (XAI) ÊñπÊ≥ï„ÄÇÈÄô‰∫õÊñπÊ≥ïÊó®Âú®ÈÄèÈÅéÊ∑±ÂÖ•‰∫ÜËß£Ê±∫Á≠ñËÉåÂæåÁöÑÂéüÁêÜÔºå‰æÜÊèêÂçáÊúÄÁµÇ‰ΩøÁî®ËÄÖÂ∞çËá™ÂãïÂåñÁ≥ªÁµ±ÁöÑ‰ø°Ë≥¥„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆË°°Èáè‰ΩøÁî®ËÄÖÂ∞ç XAI Á≥ªÁµ±‰ø°Ë≥¥Â∫¶ÁöÑÊñ∞Á©éÊñπÊ≥ïÔºåÂÖÅË®±Â∞çÂÖ∂ÈÄ≤Ë°åÊîπÈÄ≤„ÄÇÊàëÂÄëÊèêÂá∫ÁöÑÊåáÊ®ôÁµêÂêà‰∫ÜÂÆ¢ËßÄËßÄÈªû‰∏ãÁöÑÊïàËÉΩÊåáÊ®ôÂíå‰ø°Ë≥¥ÊåáÊ®ô„ÄÇÁÇ∫‰∫ÜÈ©óË≠âÈÄôÂÄãÊñ∞Á©éÁöÑÊñπÊ≥ïÔºåÊàëÂÄëÂú®‰∏ÄÂÄãÁúüÂØ¶ÁöÑÈÜ´ÁôÇÂ†¥ÊôØ‰∏≠ÈÄ≤Ë°å‰∫Ü‰∏ÄÂÄãÊ°à‰æãÁ†îÁ©∂Ôºö‰ΩøÁî® XAI Á≥ªÁµ±Âæû X ÂÖâÂΩ±ÂÉè‰∏≠ÂÅµÊ∏¨ËÇ∫ÁÇé„ÄÇ

##### **Region-specific Risk Quantification for Interpretable Prognosis of COVID-19**
2405.02815v1 by Zhusi Zhong, Jie Li, Zhuoqi Ma, Scott Collins, Harrison Bai, Paul Zhang, Terrance Healey, Xinbo Gao, Michael K. Atalay, Zhicheng Jiao

The COVID-19 pandemic has strained global public health, necessitating
accurate diagnosis and intervention to control disease spread and reduce
mortality rates. This paper introduces an interpretable deep survival
prediction model designed specifically for improved understanding and trust in
COVID-19 prognosis using chest X-ray (CXR) images. By integrating a large-scale
pretrained image encoder, Risk-specific Grad-CAM, and anatomical region
detection techniques, our approach produces regional interpretable outcomes
that effectively capture essential disease features while focusing on rare but
critical abnormal regions. Our model's predictive results provide enhanced
clarity and transparency through risk area localization, enabling clinicians to
make informed decisions regarding COVID-19 diagnosis with better understanding
of prognostic insights. We evaluate the proposed method on a multi-center
survival dataset and demonstrate its effectiveness via quantitative and
qualitative assessments, achieving superior C-indexes (0.764 and 0.727) and
time-dependent AUCs (0.799 and 0.691). These results suggest that our
explainable deep survival prediction model surpasses traditional survival
analysis methods in risk prediction, improving interpretability for clinical
decision making and enhancing AI system trustworthiness.

ÊëòË¶ÅÔºöCOVID-19 Áñ´ÊÉÖÂ∞çÂÖ®ÁêÉÂÖ¨ÂÖ±Ë°õÁîüÈÄ†ÊàêÂ£ìÂäõÔºåÂøÖÈ†àÈÄ≤Ë°åÊ∫ñÁ¢∫ÁöÑË®∫Êñ∑ÂíåÂπ≤È†êÔºå‰ª•ÊéßÂà∂ÁñæÁóÖÂÇ≥Êí≠‰∏¶Èôç‰ΩéÊ≠ª‰∫°Áéá„ÄÇÊú¨Êñá‰ªãÁ¥π‰∫Ü‰∏ÄÂÄãÂèØËß£ÈáãÁöÑÊ∑±Â∫¶ÁîüÂ≠òÈ†êÊ∏¨Ê®°ÂûãÔºåÂ∞àÈñÄË®≠Ë®àÁî®ÊñºÈÄèÈÅéËÉ∏ÈÉ® X ÂÖâ (CXR) ÂΩ±ÂÉèÊîπÂñÑÂ∞ç COVID-19 È†êÂæåÁöÑÁêÜËß£Âíå‰ø°Ë≥¥„ÄÇÈÄèÈÅéÊï¥ÂêàÂ§ßË¶èÊ®°È†êË®ìÁ∑¥ÂΩ±ÂÉèÁ∑®Á¢ºÂô®„ÄÅÈ¢®Èö™ÁâπÂÆö Grad-CAM ÂíåËß£ÂâñÂçÄÂüüÂÅµÊ∏¨ÊäÄË°ìÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÁî¢ÁîüÂçÄÂüüÂèØËß£ÈáãÁöÑÁµêÊûúÔºåÊúâÊïàÊçïÊçâÂøÖË¶ÅÁöÑÁñæÁóÖÁâπÂæµÔºåÂêåÊôÇÂ∞àÊ≥®ÊñºÁΩïË¶ã‰ΩÜÈóúÈçµÁöÑÁï∞Â∏∏ÂçÄÂüü„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÈ†êÊ∏¨ÁµêÊûúÈÄèÈÅéÈ¢®Èö™ÂçÄÂüüÂÆö‰ΩçÊèê‰æõÂ¢ûÂº∑ÁöÑÊ∏ÖÊô∞Â∫¶ÂíåÈÄèÊòéÂ∫¶ÔºåËÆìËá®Â∫äÈÜ´ÁîüËÉΩÂ§†Âú®Êõ¥‰∫ÜËß£È†êÂæåË¶ãËß£ÁöÑÊÉÖÊ≥Å‰∏ãÔºåÂ∞± COVID-19 Ë®∫Êñ∑ÂÅöÂá∫ÊòéÊô∫ÁöÑÊ±∫Á≠ñ„ÄÇÊàëÂÄëÂú®Â§ö‰∏≠ÂøÉÁîüÂ≠òË≥áÊñôÈõÜ‰∏äË©ï‰º∞ÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÔºå‰∏¶ÈÄèÈÅéÈáèÂåñÂíåË≥™ÂåñË©ï‰º∞Ë≠âÊòéÂÖ∂ÊúâÊïàÊÄßÔºåÈÅîÂà∞ÂÑ™Áï∞ÁöÑ C ÊåáÊï∏Ôºà0.764 Âíå 0.727ÔºâÂíåÊôÇÈñìÁõ∏Èóú AUCÔºà0.799 Âíå 0.691Ôºâ„ÄÇÈÄô‰∫õÁµêÊûúË°®ÊòéÔºåÊàëÂÄëÂèØËß£ÈáãÁöÑÊ∑±Â∫¶ÁîüÂ≠òÈ†êÊ∏¨Ê®°ÂûãÂú®È¢®Èö™È†êÊ∏¨ÊñπÈù¢Ë∂ÖË∂äÂÇ≥Áµ±ÁöÑÁîüÂ≠òÂàÜÊûêÊñπÊ≥ïÔºåÊèêÂçáËá®Â∫äÊ±∫Á≠ñÁöÑËß£ÈáãÊÄßÔºå‰∏¶Â¢ûÂº∑ AI Á≥ªÁµ±ÁöÑ‰ø°Ë≥¥Â∫¶„ÄÇ

##### **M3H: Multimodal Multitask Machine Learning for Healthcare**
2404.18975v2 by Dimitris Bertsimas, Yu Ma

Artificial intelligence holds promise to fundamentally enhance healthcare.
Developing an integrated many-to-many framework leveraging multimodal data for
multiple tasks is essential to unifying modern medicine. We introduce M3H, an
explainable Multimodal Multitask Machine Learning for Healthcare framework that
consolidates learning from tabular, time-series, language, and vision data for
supervised binary/multiclass classification, regression, and unsupervised
clustering. M3H encompasses an unprecedented range of medical tasks and problem
domains and consistently outperforms traditional single-task models by on
average 11.6% across 40 disease diagnoses from 16 medical departments, three
hospital operation forecasts, and one patient phenotyping task. It features a
novel attention mechanism balancing self-exploitation (learning source-task),
and cross-exploration (learning cross-tasks), and offers explainability through
a proposed TIM score, shedding light on the dynamics of task learning
interdependencies. Its adaptable architecture supports easy customization and
integration of new data modalities and tasks, establishing it as a robust,
scalable solution for advancing AI-driven healthcare systems.

ÊëòË¶ÅÔºö‰∫∫Â∑•Êô∫ÊÖßÊúâÊúõÂæûÊ†πÊú¨‰∏äÊèêÂçáÈÜ´ÁôÇ‰øùÂÅ•„ÄÇ
ÈñãÁôº‰∏ÄÂÄãÊï¥ÂêàÂºèÂ§öÂ∞çÂ§öÊû∂ÊßãÔºåÂà©Áî®Â§öÊ®°ÊÖãË≥áÊñôÈÄ≤Ë°åÂ§öÈáç‰ªªÂãôÔºåÂ∞çÊñºÁµ±‰∏ÄÁèæ‰ª£ÈÜ´Â≠∏Ëá≥ÈóúÈáçË¶Å„ÄÇÊàëÂÄë‰ªãÁ¥π M3HÔºå‰∏ÄÂÄãÂèØËß£ÈáãÁöÑÂ§öÊ®°ÊÖãÂ§ö‰ªªÂãôÊ©üÂô®Â≠∏ÁøíÈÜ´ÁôÇ‰øùÂÅ•Êû∂ÊßãÔºåÂÆÉÊï¥Âêà‰∫ÜË°®Ê†º„ÄÅÊôÇÈñìÂ∫èÂàó„ÄÅË™ûË®ÄÂíåË¶ñË¶∫Ë≥áÊñôÁöÑÂ≠∏ÁøíÔºåÁî®ÊñºÁõ£Áù£Âºè‰∫åÂÖÉ/Â§öÈ°ûÂà•ÂàÜÈ°û„ÄÅÂõûÊ≠∏ÂíåÈùûÁõ£Áù£ÂºèËÅöÈ°û„ÄÇM3H Ê∂µËìã‰∫ÜÂâçÊâÄÊú™ÊúâÁöÑÈÜ´ÁôÇ‰ªªÂãôÂíåÂïèÈ°åÈ†òÂüüÁØÑÂúçÔºå‰∏¶‰∏îÂú® 16 ÂÄãÈÜ´ÁôÇÈÉ®ÈñÄÁöÑ 40 Á®ÆÁñæÁóÖË®∫Êñ∑„ÄÅ‰∏âÂÄãÈÜ´Èô¢ÈÅãÁáüÈ†êÊ∏¨Âíå‰∏ÄÂÄãÊÇ£ËÄÖË°®Âûã‰ªªÂãô‰∏≠ÔºåÂπ≥ÂùáÊØîÂÇ≥Áµ±ÁöÑÂñÆ‰∏Ä‰ªªÂãôÊ®°ÂûãÈ´òÂá∫ 11.6%„ÄÇÂÆÉÁöÑÁâπÈªûÊòØÊñ∞Á©éÁöÑÊ≥®ÊÑèÂäõÊ©üÂà∂ÔºåÂπ≥Ë°°‰∫ÜËá™ÊàëÈñãÁôºÔºàÂ≠∏Áøí‰æÜÊ∫ê‰ªªÂãôÔºâÂíåË∑®Êé¢Á¥¢ÔºàÂ≠∏ÁøíË∑®‰ªªÂãôÔºâÔºå‰∏¶ÈÄöÈÅéÊèêË≠∞ÁöÑ TIM ÂàÜÊï∏Êèê‰æõÂèØËß£ÈáãÊÄßÔºåÈó°Êòé‰∫Ü‰ªªÂãôÂ≠∏ÁøíÁõ∏‰∫í‰æùË≥¥ÁöÑÂãïÊÖã„ÄÇÂÖ∂ÈÅ©ÊáâÊÄßÊû∂ÊßãÊîØÊè¥ËºïÈ¨ÜËá™Ë®ÇÂíåÊï¥ÂêàÊñ∞ÁöÑË≥áÊñôÊ®°ÂºèÂíå‰ªªÂãôÔºå‰ΩøÂÖ∂ÊàêÁÇ∫Êé®Âãï AI È©ÖÂãïÈÜ´ÁôÇ‰øùÂÅ•Á≥ªÁµ±ÁöÑÂº∑Â§ß„ÄÅÂèØÊì¥ÂÖÖÁöÑËß£Ê±∫ÊñπÊ°à„ÄÇ

##### **Advancing Healthcare Automation: Multi-Agent Systems for Medical Necessity Justification**
2404.17977v1 by Himanshu Pandey, Akhil Amod, Shivang

This paper explores the application of Swarm-Structured Multi-Agent Systems
(MAS) to establish medical necessity, a process that involves a systematic
review of patient-specific medical structured and unstructured data against
clinical guidelines. We addressed this complex task by decomposing it into
smaller, more manageable sub-tasks. Each sub-task is handled by a specialized
AI agent. We conduct a systematic study of the impact of various prompting
strategies on these agents and benchmark different Large Language Models (LLMs)
to determine their accuracy in completing these tasks. Additionally, we
investigate how these agents can provide explainability, thereby enhancing
trust and transparency within the system.

ÊëòË¶ÅÔºöÊú¨ÊñáÊé¢Ë®é‰∫ÜÊáâÁî®Áæ§È´îÁµêÊßãÂ§ö‰∏ªÈ´îÁ≥ªÁµ± (MAS) ‰æÜÂª∫Á´ãÈÜ´ÁôÇÂøÖË¶ÅÊÄßÔºåÈÄôÊòØ‰∏ÄÂÄãÊ∂âÂèäÁ≥ªÁµ±ÊÄßÂØ©Êü•ÊÇ£ËÄÖÁâπÂÆöÈÜ´ÁôÇÁµêÊßãÂåñÂíåÈùûÁµêÊßãÂåñË≥áÊñôÂ∞çÁÖßËá®Â∫äÊåáÂºïÁöÑÈÅéÁ®ã„ÄÇÊàëÂÄëÈÄèÈÅéÂ∞áÊ≠§Ë§áÈõú‰ªªÂãôÂàÜËß£ÊàêËºÉÂ∞è‰∏îÊõ¥ÊòìÊñºÁÆ°ÁêÜÁöÑÂ≠ê‰ªªÂãô‰æÜËôïÁêÜ„ÄÇÊØèÂÄãÂ≠ê‰ªªÂãôÈÉΩÁî±‰∏ÄÂÄãÂ∞àÈñÄÁöÑ AI ‰∏ªÈ´îËôïÁêÜ„ÄÇÊàëÂÄëÂ∞çÂêÑÁ®ÆÊèêÁ§∫Á≠ñÁï•Â∞çÈÄô‰∫õ‰∏ªÈ´îÁöÑÂΩ±ÈüøÈÄ≤Ë°åÁ≥ªÁµ±ÊÄßÁ†îÁ©∂Ôºå‰∏¶Â∞ç‰∏çÂêåÁöÑÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÈÄ≤Ë°åÂü∫Ê∫ñÊ∏¨Ë©¶Ôºå‰ª•Á¢∫ÂÆöÂÆÉÂÄëÂú®ÂÆåÊàêÈÄô‰∫õ‰ªªÂãôÊôÇÁöÑÊ∫ñÁ¢∫ÊÄß„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁ†îÁ©∂ÈÄô‰∫õ‰∏ªÈ´îÂ¶Ç‰ΩïÊèê‰æõÂèØËß£ÈáãÊÄßÔºåÂæûËÄåÂ¢ûÂº∑Á≥ªÁµ±ÂÖßÁöÑ‰ø°‰ªªÂíåÈÄèÊòéÂ∫¶„ÄÇ

##### **Rad4XCNN: a new agnostic method for post-hoc global explanation of CNN-derived features by means of radiomics**
2405.02334v1 by Francesco Prinzi, Carmelo Militello, Calogero Zarcaro, Tommaso Vincenzo Bartolotta, Salvatore Gaglio, Salvatore Vitabile

In the last years, artificial intelligence (AI) in clinical decision support
systems (CDSS) played a key role in harnessing machine learning and deep
learning architectures. Despite their promising capabilities, the lack of
transparency and explainability of AI models poses significant challenges,
particularly in medical contexts where reliability is a mandatory aspect.
Achieving transparency without compromising predictive accuracy remains a key
challenge. This paper presents a novel method, namely Rad4XCNN, to enhance the
predictive power of CNN-derived features with the interpretability inherent in
radiomic features. Rad4XCNN diverges from conventional methods based on
saliency map, by associating intelligible meaning to CNN-derived features by
means of Radiomics, offering new perspectives on explanation methods beyond
visualization maps. Using a breast cancer classification task as a case study,
we evaluated Rad4XCNN on ultrasound imaging datasets, including an online
dataset and two in-house datasets for internal and external validation. Some
key results are: i) CNN-derived features guarantee more robust accuracy when
compared against ViT-derived and radiomic features; ii) conventional
visualization map methods for explanation present several pitfalls; iii)
Rad4XCNN does not sacrifice model accuracy for their explainability; iv)
Rad4XCNN provides global explanation insights enabling the physician to analyze
the model outputs and findings. In addition, we highlight the importance of
integrating interpretability into AI models for enhanced trust and adoption in
clinical practice, emphasizing how our method can mitigate some concerns
related to explainable AI methods.

ÊëòË¶ÅÔºö<paragraph>Âú®ÈÅéÂéªÂπæÂπ¥ÔºåËá®Â∫äÊ±∫Á≠ñÊîØÊè¥Á≥ªÁµ± (CDSS) ‰∏≠ÁöÑ‰∫∫Â∑•Êô∫ÊÖß (AI) Âú®Âà©Áî®Ê©üÂô®Â≠∏ÁøíÂíåÊ∑±Â∫¶Â≠∏ÁøíÊû∂ÊßãÊñπÈù¢ÁôºÊèÆ‰∫ÜÈóúÈçµ‰ΩúÁî®„ÄÇÂÑòÁÆ° AI Ê®°ÂûãÂÖ∑Êúâ‰ª§‰∫∫ÊªøÊÑèÁöÑËÉΩÂäõÔºå‰ΩÜÁº∫‰πèÈÄèÊòéÂ∫¶ÂíåÂèØËß£ÈáãÊÄßÔºåÁâπÂà•ÊòØÂú®ÂèØÈù†ÊÄßÁÇ∫ÂøÖË¶ÅËÄÉÈáèÁöÑÈÜ´ÁôÇËÉåÊôØ‰∏ãÔºåÈÄôÂ∏∂‰æÜ‰∫ÜÈáçÂ§ßÁöÑÊåëÊà∞„ÄÇÂú®‰∏çÂΩ±ÈüøÈ†êÊ∏¨Á≤æÊ∫ñÂ∫¶ÁöÑÊÉÖÊ≥Å‰∏ãÂØ¶ÁèæÈÄèÊòéÂ∫¶‰ªçÁÑ∂ÊòØ‰∏ÄÈ†ÖÈóúÈçµÊåëÊà∞„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞ÊñπÊ≥ïÔºåÂç≥ Rad4XCNNÔºå‰ª•Â¢ûÂº∑ CNN Ë°çÁîüÁâπÂæµÁöÑÈ†êÊ∏¨ËÉΩÂäõÔºåÂêåÊôÇÂÖ∑ÂÇôÊîæÂ∞ÑÁâπÂæµÂõ∫ÊúâÁöÑÂèØËß£ÈáãÊÄß„ÄÇRad4XCNN ‰∏çÂêåÊñºÂü∫ÊñºÈ°ØËëóÊÄßÂúñÁöÑÂÇ≥Áµ±ÊñπÊ≥ïÔºåÂÆÉÈÄöÈÅéÊîæÂ∞ÑÁµÑÂ≠∏Â∞áÂèØÁêÜËß£ÁöÑÂê´Áæ©Ëàá CNN Ë°çÁîüÁâπÂæµÈóúËÅØËµ∑‰æÜÔºåÁÇ∫Ë∂ÖË∂äË¶ñË¶∫ÂåñÂúñË°®ÁöÑËß£ÈáãÊñπÊ≥ïÊèê‰æõ‰∫ÜÊñ∞ÁöÑËßÄÈªû„ÄÇÊàëÂÄë‰ª•‰π≥ÁôåÂàÜÈ°û‰ªªÂãô‰ΩúÁÇ∫Ê°à‰æãÁ†îÁ©∂ÔºåÂú®Ë∂ÖÈü≥Ê≥¢ÂΩ±ÂÉèË≥áÊñôÈõÜ‰∏äË©ï‰º∞ Rad4XCNNÔºåÂåÖÊã¨‰∏ÄÂÄãÁ∑ö‰∏äË≥áÊñôÈõÜÂíåÂÖ©ÂÄãÁî®ÊñºÂÖßÈÉ®ÂíåÂ§ñÈÉ®È©óË≠âÁöÑÂÖßÈÉ®Ë≥áÊñôÈõÜ„ÄÇ‰∏Ä‰∫õÈóúÈçµÁµêÊûúÂ¶Ç‰∏ãÔºöi) Ëàá ViT Ë°çÁîüÁâπÂæµÂíåÊîæÂ∞ÑÁâπÂæµÁõ∏ÊØîÔºåCNN Ë°çÁîüÁâπÂæµ‰øùË≠â‰∫ÜÊõ¥Á©©ÂÅ•ÁöÑÊ∫ñÁ¢∫Â∫¶Ôºõii) ÂÇ≥Áµ±ÁöÑË¶ñË¶∫ÂåñÂúñËß£ÈáãÊñπÊ≥ïÂ≠òÂú®‰∏Ä‰∫õÁº∫Èô∑Ôºõiii) Rad4XCNN Ê≤íÊúâÁäßÁâ≤Ê®°ÂûãÊ∫ñÁ¢∫Â∫¶‰æÜÊèõÂèñÂÖ∂ÂèØËß£ÈáãÊÄßÔºõiv) Rad4XCNN Êèê‰æõ‰∫ÜÂÖ®Â±ÄËß£ÈáãË¶ãËß£Ôºå‰ΩøÈÜ´Â∏´ËÉΩÂ§†ÂàÜÊûêÊ®°ÂûãËº∏Âá∫ÂíåÁôºÁèæ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂº∑Ë™øÂ∞áÂèØËß£ÈáãÊÄßÊï¥ÂêàÂà∞ AI Ê®°Âûã‰∏≠Â∞çÊñºÂ¢ûÂº∑Ëá®Â∫äÂØ¶Âãô‰∏≠ÁöÑ‰ø°‰ªªÂíåÊé°Áî®Ëá≥ÈóúÈáçË¶ÅÔºå‰∏¶Âº∑Ë™ø‰∫ÜÊàëÂÄëÁöÑÊñπÊ≥ïÂ¶Ç‰ΩïËÉΩÁ∑©Ëß£ËàáÂèØËß£Èáã AI ÊñπÊ≥ïÁõ∏ÈóúÁöÑ‰∏Ä‰∫õÁñëÊÖÆ„ÄÇ</paragraph>

##### **Attributing Responsibility in AI-Induced Incidents: A Computational Reflective Equilibrium Framework for Accountability**
2404.16957v1 by Yunfei Ge, Quanyan Zhu

The pervasive integration of Artificial Intelligence (AI) has introduced
complex challenges in the responsibility and accountability in the event of
incidents involving AI-enabled systems. The interconnectivity of these systems,
ethical concerns of AI-induced incidents, coupled with uncertainties in AI
technology and the absence of corresponding regulations, have made traditional
responsibility attribution challenging. To this end, this work proposes a
Computational Reflective Equilibrium (CRE) approach to establish a coherent and
ethically acceptable responsibility attribution framework for all stakeholders.
The computational approach provides a structured analysis that overcomes the
limitations of conceptual approaches in dealing with dynamic and multifaceted
scenarios, showcasing the framework's explainability, coherence, and adaptivity
properties in the responsibility attribution process. We examine the pivotal
role of the initial activation level associated with claims in equilibrium
computation. Using an AI-assisted medical decision-support system as a case
study, we illustrate how different initializations lead to diverse
responsibility distributions. The framework offers valuable insights into
accountability in AI-induced incidents, facilitating the development of a
sustainable and resilient system through continuous monitoring, revision, and
reflection.

ÊëòË¶ÅÔºöÈö®Ëëó‰∫∫Â∑•Êô∫ÊÖß (AI) ÁöÑÊôÆÂèäÊï¥ÂêàÔºåÂú®Ê∂âÂèä AI È©ÖÂãïÁ≥ªÁµ±ÁöÑ‰∫ãÊïÖ‰∏≠ÔºåË≤¨‰ªªÂíåÁæ©ÂãôÊ≠∏Â±¨Áî¢Áîü‰∫ÜË§áÈõúÁöÑÊåëÊà∞„ÄÇÈÄô‰∫õÁ≥ªÁµ±ÁöÑ‰∫íÈÄ£ÊÄß„ÄÅAI ÂºïÁôº‰∫ãÊïÖÁöÑÂÄ´ÁêÜÂïèÈ°åÔºåÂä†‰∏ä AI ÊäÄË°ìÁöÑ‰∏çÁ¢∫ÂÆöÊÄßÂíåÁº∫‰πèÁõ∏ÊáâÊ≥ïË¶èÔºå‰ΩøÂæóÂÇ≥Áµ±Ë≤¨‰ªªÊ≠∏Â±¨Èù¢Ëá®ÊåëÊà∞„ÄÇÁÇ∫Ê≠§ÔºåÊú¨Á†îÁ©∂ÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆË®àÁÆóÂèçÊÄùÂùáË°° (CRE) ÊñπÊ≥ïÔºå‰ª•Âª∫Á´ã‰∏ÄÂÄãÈÄ£Ë≤´‰∏îÂú®ÂÄ´ÁêÜ‰∏äÂèØÊé•ÂèóÁöÑË≤¨‰ªªÊ≠∏Â±¨Êû∂ÊßãÔºåÈÅ©Áî®ÊñºÊâÄÊúâÂà©ÂÆ≥Èóú‰øÇ‰∫∫„ÄÇË®àÁÆóÊñπÊ≥ïÊèê‰æõ‰∫ÜÁµêÊßãÂåñÁöÑÂàÜÊûêÔºåÂÖãÊúç‰∫ÜÊ¶ÇÂøµÊñπÊ≥ïÂú®ËôïÁêÜÂãïÊÖã‰∏îÂ§öÈù¢ÂêëÊÉÖÂ¢ÉÊôÇÁöÑÈôêÂà∂ÔºåÂ±ïÁ§∫‰∫ÜË©≤Êû∂ÊßãÂú®Ë≤¨‰ªªÊ≠∏Â±¨ÈÅéÁ®ã‰∏≠ÂÖ∑ÂÇôÁöÑÂèØËß£ÈáãÊÄß„ÄÅÈÄ£Ë≤´ÊÄßÂíåÈÅ©ÊáâÊÄß„ÄÇÊàëÂÄëÊé¢Ë®é‰∫ÜËàáÂùáË°°Ë®àÁÆó‰∏≠Á¥¢Ë≥†Áõ∏ÈóúÁöÑÂàùÂßãÂïüÂãïÂ±§Á¥öÁöÑÈóúÈçµ‰ΩúÁî®„ÄÇÊàëÂÄë‰ª• AI ËºîÂä©ÈÜ´ÁôÇÊ±∫Á≠ñÊîØÊè¥Á≥ªÁµ±ÁÇ∫Ê°à‰æãÁ†îÁ©∂ÔºåË™™Êòé‰∏çÂêåÁöÑÂàùÂßãÂåñÂ¶Ç‰ΩïÂ∞éËá¥‰∏çÂêåÁöÑË≤¨‰ªªÂàÜÈÖç„ÄÇË©≤Êû∂ÊßãÊèê‰æõ‰∫ÜÂ∞ç AI ÂºïÁôº‰∫ãÊïÖ‰∏≠ÂïèË≤¨Âà∂ÁöÑÂØ∂Ë≤¥Ë¶ãËß£ÔºåÈÄèÈÅéÊåÅÁ∫åÁõ£Êéß„ÄÅ‰øÆË®ÇÂíåÂèçÊÄùÔºå‰øÉÈÄ≤‰∫ÜÊ∞∏Á∫å‰∏îÊúâÈüåÊÄßÁöÑÁ≥ªÁµ±ÁôºÂ±ï„ÄÇ

##### **Explainable AI for Fair Sepsis Mortality Predictive Model**
2404.13139v1 by Chia-Hsuan Chang, Xiaoyang Wang, Christopher C. Yang

Artificial intelligence supports healthcare professionals with predictive
modeling, greatly transforming clinical decision-making. This study addresses
the crucial need for fairness and explainability in AI applications within
healthcare to ensure equitable outcomes across diverse patient demographics. By
focusing on the predictive modeling of sepsis-related mortality, we propose a
method that learns a performance-optimized predictive model and then employs
the transfer learning process to produce a model with better fairness. Our
method also introduces a novel permutation-based feature importance algorithm
aiming at elucidating the contribution of each feature in enhancing fairness on
predictions. Unlike existing explainability methods concentrating on explaining
feature contribution to predictive performance, our proposed method uniquely
bridges the gap in understanding how each feature contributes to fairness. This
advancement is pivotal, given sepsis's significant mortality rate and its role
in one-third of hospital deaths. Our method not only aids in identifying and
mitigating biases within the predictive model but also fosters trust among
healthcare stakeholders by improving the transparency and fairness of model
predictions, thereby contributing to more equitable and trustworthy healthcare
delivery.

ÊëòË¶ÅÔºö‰∫∫Â∑•Êô∫ÊÖßÈÄèÈÅéÈ†êÊ∏¨Ê®°ÂûãÂçîÂä©ÈÜ´ÁôÇÂ∞àÊ•≠‰∫∫Âì°ÔºåÂ§ßÂπÖËΩâËÆä‰∫ÜËá®Â∫äÊ±∫Á≠ñÂà∂ÂÆö„ÄÇÊú¨Á†îÁ©∂Êé¢Ë®é‰∫ÜÂú®ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠‰ΩøÁî®‰∫∫Â∑•Êô∫ÊÖßÊáâÁî®Á®ãÂºèÊôÇÂÖ¨Âπ≥ÊÄßÂíåÂèØËß£ÈáãÊÄßÁöÑÈóúÈçµÈúÄÊ±ÇÔºå‰ª•Á¢∫‰øùÂú®‰∏çÂêåÁöÑÊÇ£ËÄÖ‰∫∫Âè£Áµ±Ë®àË≥áÊñô‰∏≠Áç≤ÂæóÂÖ¨Âπ≥ÁöÑÁµêÊûú„ÄÇÈÄèÈÅéÂ∞àÊ≥®ÊñºÊïóË°ÄÁóáÁõ∏ÈóúÊ≠ª‰∫°ÁéáÁöÑÈ†êÊ∏¨Ê®°ÂûãÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñπÊ≥ïÔºåË©≤ÊñπÊ≥ïÊúÉÂ≠∏Áøí‰∏ÄÂÄãÊïàËÉΩÊúÄ‰Ω≥ÂåñÁöÑÈ†êÊ∏¨Ê®°ÂûãÔºåÁÑ∂ÂæåÊé°Áî®ËΩâÁßªÂ≠∏ÁøíÈÅéÁ®ã‰æÜÁî¢Áîü‰∏ÄÂÄãÂÖ∑ÊúâÊõ¥Â•ΩÂÖ¨Âπ≥ÊÄßÁöÑÊ®°Âûã„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÈÇÑÂºïÂÖ•‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÂü∫ÊñºÊéíÂàóÁöÑÁâπÂæµÈáçË¶ÅÊÄßÊºîÁÆóÊ≥ïÔºåÊó®Âú®Èó°ÊòéÊØèÂÄãÁâπÂæµÂú®Â¢ûÂº∑È†êÊ∏¨ÂÖ¨Âπ≥ÊÄßÊñπÈù¢ÁöÑË≤¢Áçª„ÄÇËàáÁèæÊúâÁöÑÂèØËß£ÈáãÊÄßÊñπÊ≥ïÂ∞àÊ≥®ÊñºËß£ÈáãÁâπÂæµÂ∞çÈ†êÊ∏¨ÊïàËÉΩÁöÑË≤¢Áçª‰∏çÂêåÔºåÊàëÂÄëÊèêÂá∫ÁöÑÊñπÊ≥ïÁç®ÁâπÂú∞ÂΩåË£ú‰∫ÜÁêÜËß£ÊØèÂÄãÁâπÂæµÂ¶Ç‰ΩïÊúâÂä©ÊñºÂÖ¨Âπ≥ÊÄßÁöÑÂ∑ÆË∑ù„ÄÇÈÄôÈ†ÖÈÄ≤Â±ïËá≥ÈóúÈáçË¶ÅÔºåÂõ†ÁÇ∫ÊïóË°ÄÁóáÁöÑÊ≠ª‰∫°ÁéáÂæàÈ´òÔºå‰∏îÂú®‰∏âÂàÜ‰πã‰∏ÄÁöÑÈÜ´Èô¢Ê≠ª‰∫°‰∏≠ÊâÆÊºîËëóËßíËâ≤„ÄÇÊàëÂÄëÁöÑÊ®°Âûã‰∏çÂÉÖÊúâÂä©ÊñºË≠òÂà•ÂíåÊ∏õËºïÈ†êÊ∏¨Ê®°Âûã‰∏≠ÁöÑÂÅèÂ∑ÆÔºåÈÇÑËÉΩÈÄèÈÅéÊèêÈ´òÊ®°ÂûãÈ†êÊ∏¨ÁöÑÈÄèÊòéÂ∫¶ÂíåÂÖ¨Âπ≥ÊÄß‰æÜÂüπÈ§äÈÜ´ÁôÇ‰øùÂÅ•Âà©ÁõäÁõ∏ÈóúËÄÖ‰πãÈñìÁöÑ‰ø°‰ªªÔºåÈÄ≤ËÄåÊúâÂä©ÊñºÊèê‰æõÊõ¥ÂÖ¨Âπ≥‰∏îÂÄºÂæó‰ø°Ë≥¥ÁöÑÈÜ´ÁôÇ‰øùÂÅ•ÊúçÂãô„ÄÇ

##### **Multi Class Depression Detection Through Tweets using Artificial Intelligence**
2404.13104v1 by Muhammad Osama Nusrat, Waseem Shahzad, Saad Ahmed Jamal

Depression is a significant issue nowadays. As per the World Health
Organization (WHO), in 2023, over 280 million individuals are grappling with
depression. This is a huge number; if not taken seriously, these numbers will
increase rapidly. About 4.89 billion individuals are social media users. People
express their feelings and emotions on platforms like Twitter, Facebook,
Reddit, Instagram, etc. These platforms contain valuable information which can
be used for research purposes. Considerable research has been conducted across
various social media platforms. However, certain limitations persist in these
endeavors. Particularly, previous studies were only focused on detecting
depression and the intensity of depression in tweets. Also, there existed
inaccuracies in dataset labeling. In this research work, five types of
depression (Bipolar, major, psychotic, atypical, and postpartum) were predicted
using tweets from the Twitter database based on lexicon labeling. Explainable
AI was used to provide reasoning by highlighting the parts of tweets that
represent type of depression. Bidirectional Encoder Representations from
Transformers (BERT) was used for feature extraction and training. Machine
learning and deep learning methodologies were used to train the model. The BERT
model presented the most promising results, achieving an overall accuracy of
0.96.

ÊëòË¶ÅÔºöÁèæ‰ªäÔºåÊÜÇÈ¨±ÁóáÊòØ‰∏ÄÂÄãÈáçË¶ÅÁöÑË≠∞È°å„ÄÇÊ†πÊìö‰∏ñÁïåË°õÁîüÁµÑÁπî (WHO) ÁöÑË≥áÊñôÔºåÂú® 2023 Âπ¥ÔºåË∂ÖÈÅé 2.8 ÂÑÑ‰∫∫Ê≠£Âú®ËàáÊÜÇÈ¨±ÁóáÊêèÈ¨•„ÄÇÈÄôÊòØ‰∏ÄÂÄãÈæêÂ§ßÁöÑÊï∏Â≠óÔºõÂ¶ÇÊûú‰∏çË™çÁúüÁúãÂæÖÔºåÈÄô‰∫õÊï∏Â≠óÂ∞áÊúÉÂø´ÈÄüÂ¢ûÂä†„ÄÇÂ§ßÁ¥ÑÊúâ 48.9 ÂÑÑ‰∫∫ÊòØÁ§æÁæ§Â™íÈ´î‰ΩøÁî®ËÄÖ„ÄÇ‰∫∫ÂÄëÂú® Twitter„ÄÅFacebook„ÄÅReddit„ÄÅInstagram Á≠âÂπ≥Âè∞‰∏äË°®ÈÅîËá™Â∑±ÁöÑÊÑüÂèóÂíåÊÉÖÁ∑í„ÄÇÈÄô‰∫õÂπ≥Âè∞ÂåÖÂê´ÊúâÂÉπÂÄºÁöÑË≥áË®äÔºåÂèØÁî®ÊñºÁ†îÁ©∂ÁõÆÁöÑ„ÄÇÂ∑≤Á∂ìÂú®ÂêÑÁ®ÆÁ§æÁæ§Â™íÈ´îÂπ≥Âè∞‰∏äÈÄ≤Ë°å‰∫ÜÂ§ßÈáèÁöÑÁ†îÁ©∂„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÂä™Âäõ‰ªçÂ≠òÂú®Êüê‰∫õÈôêÂà∂„ÄÇÁâπÂà•ÊòØÔºåÂÖàÂâçÁöÑÁ†îÁ©∂ÂÉÖÂ∞àÊ≥®ÊñºÂÅµÊ∏¨Êé®Êñá‰∏≠ÁöÑÊÜÇÈ¨±ÁóáÂíåÊÜÇÈ¨±ÁóáÁöÑÂº∑Â∫¶„ÄÇÊ≠§Â§ñÔºåË≥áÊñôÈõÜÊ®ôÁ±§‰∏≠Â≠òÂú®‰∏çÊ∫ñÁ¢∫ÁöÑÊÉÖÊ≥Å„ÄÇÂú®ÈÄôÈ†ÖÁ†îÁ©∂Â∑•‰Ωú‰∏≠Ôºå‰ΩøÁî®Âü∫ÊñºË©ûÂΩôÊ®ôÁ±§ÁöÑ Twitter Ë≥áÊñôÂ∫´‰∏≠ÁöÑÊé®ÊñáÈ†êÊ∏¨‰∫Ü‰∫îÁ®ÆÈ°ûÂûãÁöÑÊÜÇÈ¨±ÁóáÔºàÈõôÊ•µÂûã„ÄÅÈáçÂ∫¶„ÄÅÁ≤æÁ•ûÁóÖÂûã„ÄÅÈùûÂÖ∏ÂûãÂíåÁî¢ÂæåÔºâ„ÄÇÂèØËß£ÈáãÁöÑ AI Áî®ÊñºÈÄèÈÅéÂº∑Ë™ø‰ª£Ë°®ÊÜÇÈ¨±ÁóáÈ°ûÂûãÁöÑÊé®ÊñáÈÉ®ÂàÜ‰æÜÊèê‰æõÊé®ÁêÜ„ÄÇÂæû TransformersÔºàBERTÔºâ‰∏≠ÊèêÂèñÁöÑÈõôÂêëÁ∑®Á¢ºÂô®Ë°®Á§∫Áî®ÊñºÁâπÂæµÊèêÂèñÂíåË®ìÁ∑¥„ÄÇÊ©üÂô®Â≠∏ÁøíÂíåÊ∑±Â∫¶Â≠∏ÁøíÊñπÊ≥ïÁî®ÊñºË®ìÁ∑¥Ê®°Âûã„ÄÇBERT Ê®°ÂûãÂëàÁèæÂá∫ÊúÄÊúâÂ∏åÊúõÁöÑÁµêÊûúÔºåÈÅîÂà∞ 0.96 ÁöÑÊï¥È´îÊ∫ñÁ¢∫Â∫¶„ÄÇ

##### **COIN: Counterfactual inpainting for weakly supervised semantic segmentation for medical images**
2404.12832v1 by Dmytro Shvetsov, Joonas Ariva, Marharyta Domnich, Raul Vicente, Dmytro Fishman

Deep learning is dramatically transforming the field of medical imaging and
radiology, enabling the identification of pathologies in medical images,
including computed tomography (CT) and X-ray scans. However, the performance of
deep learning models, particularly in segmentation tasks, is often limited by
the need for extensive annotated datasets. To address this challenge, the
capabilities of weakly supervised semantic segmentation are explored through
the lens of Explainable AI and the generation of counterfactual explanations.
The scope of this research is development of a novel counterfactual inpainting
approach (COIN) that flips the predicted classification label from abnormal to
normal by using a generative model. For instance, if the classifier deems an
input medical image X as abnormal, indicating the presence of a pathology, the
generative model aims to inpaint the abnormal region, thus reversing the
classifier's original prediction label. The approach enables us to produce
precise segmentations for pathologies without depending on pre-existing
segmentation masks. Crucially, image-level labels are utilized, which are
substantially easier to acquire than creating detailed segmentation masks. The
effectiveness of the method is demonstrated by segmenting synthetic targets and
actual kidney tumors from CT images acquired from Tartu University Hospital in
Estonia. The findings indicate that COIN greatly surpasses established
attribution methods, such as RISE, ScoreCAM, and LayerCAM, as well as an
alternative counterfactual explanation method introduced by Singla et al. This
evidence suggests that COIN is a promising approach for semantic segmentation
of tumors in CT images, and presents a step forward in making deep learning
applications more accessible and effective in healthcare, where annotated data
is scarce.

ÊëòË¶ÅÔºöÊ∑±Â∫¶Â≠∏ÁøíÊ≠£ÂäáÁÉàÂú∞ËΩâËÆäÈÜ´Â≠∏ÂΩ±ÂÉèÂíåÊîæÂ∞ÑÂ≠∏È†òÂüüÔºåËÉΩË≠òÂà•ÈÜ´Â≠∏ÂΩ±ÂÉè‰∏≠ÁöÑÁóÖÁêÜÔºåÂåÖÊã¨ÈõªËÖ¶Êñ∑Â±§ÊéÉÊèè (CT) Âíå X ÂÖâÊéÉÊèè„ÄÇÁÑ∂ËÄåÔºåÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÁöÑÊïàËÉΩÔºåÁâπÂà•ÊòØÂú®ÂàÜÂâ≤‰ªªÂãô‰∏≠ÔºåÂ∏∏Â∏∏ÂèóÂà∞Âª£Ê≥õË®ªËß£Ë≥áÊñôÈõÜÈúÄÊ±ÇÁöÑÈôêÂà∂„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÊ≠§ÊåëÊà∞ÔºåÈÄèÈÅéÂèØËß£Èáã AI ÂíåÂèç‰∫ãÂØ¶Ëß£ÈáãÁöÑÁî¢ÁîüÔºåÊé¢Ë®é‰∫ÜÂº±Áõ£Áù£Ë™ûÊÑèÂàÜÂâ≤ÁöÑËÉΩÂäõ„ÄÇÊú¨Á†îÁ©∂ÁöÑÁØÑÂúçÊòØÈñãÁôº‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÂèç‰∫ãÂØ¶ÂÖßÁπ™ÊñπÊ≥ï (COIN)ÔºåÂÆÉÈÄèÈÅé‰ΩøÁî®ÁîüÊàêÊ®°ÂûãÔºåÂ∞áÈ†êÊ∏¨ÂàÜÈ°ûÊ®ôÁ±§ÂæûÁï∞Â∏∏ÁøªËΩâÁÇ∫Ê≠£Â∏∏„ÄÇ‰æãÂ¶ÇÔºåÂ¶ÇÊûúÂàÜÈ°ûÂô®Â∞áËº∏ÂÖ•ÈÜ´Â≠∏ÂΩ±ÂÉè X Ë¶ñÁÇ∫Áï∞Â∏∏ÔºåË°®Á§∫Â≠òÂú®ÁóÖÁêÜÔºåÁîüÊàêÊ®°ÂûãÊó®Âú®ÂÖßÁπ™Áï∞Â∏∏ÂçÄÂüüÔºåÂæûËÄåÈÄÜËΩâÂàÜÈ°ûÂô®ÁöÑÂéüÂßãÈ†êÊ∏¨Ê®ôÁ±§„ÄÇÊ≠§ÊñπÊ≥ï‰ΩøÊàëÂÄëËÉΩÂ§†Áî¢ÁîüÁóÖÁêÜÁöÑÁ≤æÁ¢∫ÂàÜÂâ≤ÔºåËÄå‰∏ç‰æùË≥¥ÊñºÈ†êÂÖàÂ≠òÂú®ÁöÑÂàÜÂâ≤ÈÅÆÁΩ©„ÄÇËá≥ÈóúÈáçË¶ÅÁöÑÊòØÔºåÂà©Áî®ÂΩ±ÂÉèÂ±§Á¥öÊ®ôÁ±§ÔºåÈÄôÊØîÂª∫Á´ãË©≥Á¥∞ÁöÑÂàÜÂâ≤ÈÅÆÁΩ©ÂÆπÊòìÂèñÂæóÂæóÂ§ö„ÄÇË©≤ÊñπÊ≥ïÁöÑÊúâÊïàÊÄßÈÄèÈÅéÂàÜÂâ≤ÂêàÊàêÁõÆÊ®ôÂíåÂæûÊÑõÊ≤ôÂ∞º‰∫ûÂ°îÁàæÂúñÂ§ßÂ≠∏ÈÜ´Èô¢ÂèñÂæóÁöÑ CT ÂΩ±ÂÉè‰∏≠ÁöÑÂØ¶ÈöõËÖéËáüËÖ´Áò§‰æÜË≠âÊòé„ÄÇÁ†îÁ©∂ÁµêÊûúË°®ÊòéÔºåCOIN ÈÅ†ÈÅ†Ë∂ÖË∂ä‰∫ÜÊó¢ÂÆöÁöÑÊ≠∏Âõ†ÊñπÊ≥ïÔºå‰æãÂ¶Ç RISE„ÄÅScoreCAM Âíå LayerCAMÔºå‰ª•Âèä Singla Á≠â‰∫∫ÊèêÂá∫ÁöÑÂè¶‰∏ÄÁ®ÆÂèç‰∫ãÂØ¶Ëß£ÈáãÊñπÊ≥ï„ÄÇÊ≠§Ë≠âÊìöË°®ÊòéÔºåCOIN ÊòØ‰∏ÄÁ®ÆÂæàÊúâÂâçÊôØÁöÑ CT ÂΩ±ÂÉè‰∏≠ËÖ´Áò§Ë™ûÊÑèÂàÜÂâ≤ÊñπÊ≥ïÔºå‰∏¶Âú®‰ΩøÊ∑±Â∫¶Â≠∏ÁøíÊáâÁî®Âú®Ë®ªËß£Ë≥áÊñôÁ®ÄÁº∫ÁöÑÈÜ´ÁôÇ‰øùÂÅ•‰∏≠Êõ¥ÊòìÊñºÂèñÂæóÂíåÊõ¥ÊúâÊïàÊñπÈù¢ÈÇÅÈÄ≤‰∫Ü‰∏ÄÊ≠•„ÄÇ

##### **Advancements in Radiomics and Artificial Intelligence for Thyroid Cancer Diagnosis**
2404.07239v1 by Milad Yousefi, Shadi Farabi Maleki, Ali Jafarizadeh, Mahya Ahmadpour Youshanlui, Aida Jafari, Siamak Pedrammehr, Roohallah Alizadehsani, Ryszard Tadeusiewicz, Pawel Plawiak

Thyroid cancer is an increasing global health concern that requires advanced
diagnostic methods. The application of AI and radiomics to thyroid cancer
diagnosis is examined in this review. A review of multiple databases was
conducted in compliance with PRISMA guidelines until October 2023. A
combination of keywords led to the discovery of an English academic publication
on thyroid cancer and related subjects. 267 papers were returned from the
original search after 109 duplicates were removed. Relevant studies were
selected according to predetermined criteria after 124 articles were eliminated
based on an examination of their abstract and title. After the comprehensive
analysis, an additional six studies were excluded. Among the 28 included
studies, radiomics analysis, which incorporates ultrasound (US) images,
demonstrated its effectiveness in diagnosing thyroid cancer. Various results
were noted, some of the studies presenting new strategies that outperformed the
status quo. The literature has emphasized various challenges faced by AI
models, including interpretability issues, dataset constraints, and operator
dependence. The synthesized findings of the 28 included studies mentioned the
need for standardization efforts and prospective multicenter studies to address
these concerns. Furthermore, approaches to overcome these obstacles were
identified, such as advances in explainable AI technology and personalized
medicine techniques. The review focuses on how AI and radiomics could transform
the diagnosis and treatment of thyroid cancer. Despite challenges, future
research on multidisciplinary cooperation, clinical applicability validation,
and algorithm improvement holds the potential to improve patient outcomes and
diagnostic precision in the treatment of thyroid cancer.

ÊëòË¶ÅÔºöÁî≤ÁãÄËÖ∫ÁôåÊòØ‰∏ÄÁ®ÆÊó•ÁõäÂö¥ÈáçÁöÑÂÖ®ÁêÉÂÅ•Â∫∑ÂïèÈ°åÔºåÈúÄË¶ÅÂÖàÈÄ≤ÁöÑË®∫Êñ∑ÊñπÊ≥ï„ÄÇÊú¨ÁØáË©ïË´ñÊé¢Ë®é‰∫Ü‰∫∫Â∑•Êô∫ËÉΩËàáÊîæÂ∞ÑÁâπÂæµÂàÜÊûêÂú®Áî≤ÁãÄËÖ∫ÁôåË®∫Êñ∑‰∏≠ÁöÑÊáâÁî®„ÄÇÂú®Á¨¶Âêà PRISMA ÊåáÂçóÁöÑÊÉÖÊ≥Å‰∏ãÔºåÂ∞çÂ§öÂÄãË≥áÊñôÂ∫´ÈÄ≤Ë°å‰∫ÜÂõûÈ°ßÔºåÁõ¥Âà∞ 2023 Âπ¥ 10 Êúà„ÄÇÈÄöÈÅéÁµêÂêàÈóúÈçµÂ≠óÔºåÁôºÁèæ‰∫Ü‰∏ÄÁØáÈóúÊñºÁî≤ÁãÄËÖ∫ÁôåÂíåÁõ∏Èóú‰∏ªÈ°åÁöÑËã±ÊñáÂ≠∏Ë°ìÂá∫ÁâàÁâ©„ÄÇÂú®ÁßªÈô§ 109 ÁØáÈáçË§áÊñáÁçªÂæåÔºåÂéüÂßãÊêúÂ∞ãÂÖ±ÂõûÂÇ≥ 267 ÁØáË´ñÊñá„ÄÇÂú®Ê†πÊìöÈ†êÂÖàÁ¢∫ÂÆöÁöÑÊ®ôÊ∫ñÔºåÊ∑òÊ±∞‰∫Ü 124 ÁØáÊñáÁ´†ÁöÑÊëòË¶ÅÂíåÊ®ôÈ°åÂæåÔºåÈÅ∏Âá∫‰∫ÜÁõ∏ÈóúÁ†îÁ©∂„ÄÇÂú®ÈÄ≤Ë°åÂÖ®Èù¢ÂàÜÊûêÂæåÔºåÈ°çÂ§ñÊéíÈô§‰∫ÜÂÖ≠È†ÖÁ†îÁ©∂„ÄÇÂú®Á¥çÂÖ•ÁöÑ 28 È†ÖÁ†îÁ©∂‰∏≠ÔºåÁµêÂêàË∂ÖÈü≥Ê≥¢ (US) ÂΩ±ÂÉèÁöÑÊîæÂ∞ÑÁâπÂæµÂàÜÊûêÔºåË≠âÊòé‰∫ÜÂÖ∂Âú®Ë®∫Êñ∑Áî≤ÁãÄËÖ∫ÁôåÊñπÈù¢ÁöÑÊúâÊïàÊÄß„ÄÇÁ†îÁ©∂ÁµêÊûú‰∏ç‰∏ÄÔºåÊúâ‰∫õÁ†îÁ©∂ÊèêÂá∫‰∫ÜÂÑ™ÊñºÁèæÁãÄÁöÑÊñ∞Á≠ñÁï•„ÄÇÊñáÁçªÂº∑Ë™ø‰∫Ü‰∫∫Â∑•Êô∫ËÉΩÊ®°ÂûãÈù¢Ëá®ÁöÑÂêÑÁ®ÆÊåëÊà∞ÔºåÂåÖÊã¨ÂèØËß£ÈáãÊÄßÂïèÈ°å„ÄÅË≥áÊñôÈõÜÈôêÂà∂ÂíåÊìç‰ΩúÂì°‰æùË≥¥ÊÄß„ÄÇ28 È†ÖÁ¥çÂÖ•Á†îÁ©∂ÁöÑÁ∂úÂêàÁôºÁèæÊèêÂà∞ÔºåÈúÄË¶ÅÊ®ôÊ∫ñÂåñÂ∑•‰ΩúÂíåÂâçÁûªÊÄßÂ§ö‰∏≠ÂøÉÁ†îÁ©∂‰æÜËß£Ê±∫ÈÄô‰∫õÂïèÈ°å„ÄÇÊ≠§Â§ñÔºåÈÇÑÁ¢∫ÂÆö‰∫ÜÂÖãÊúçÈÄô‰∫õÈöúÁ§ôÁöÑÊñπÊ≥ïÔºå‰æãÂ¶ÇÂèØËß£Èáã‰∫∫Â∑•Êô∫ËÉΩÊäÄË°ìÂíåÂÄã‰∫∫ÂåñÈÜ´ÁôÇÊäÄË°ìÁöÑÈÄ≤Ê≠•„ÄÇÊú¨ÁØáË©ïË´ñÈáçÈªûÊé¢Ë®é‰∫Ü‰∫∫Â∑•Êô∫ËÉΩÂíåÊîæÂ∞ÑÁâπÂæµÂàÜÊûêÂ¶Ç‰ΩïËΩâËÆäÁî≤ÁãÄËÖ∫ÁôåÁöÑË®∫Êñ∑ÂíåÊ≤ªÁôÇ„ÄÇÂÑòÁÆ°Â≠òÂú®ÊåëÊà∞Ôºå‰ΩÜÊú™‰æÜÂ∞çÂ§öÂ≠∏ÁßëÂêà‰Ωú„ÄÅËá®Â∫äÈÅ©Áî®ÊÄßÈ©óË≠âÂíåÊºîÁÆóÊ≥ïÊîπÈÄ≤ÁöÑÁ†îÁ©∂Ôºå‰ªçÊúâÊΩõÂäõÊîπÂñÑÁî≤ÁãÄËÖ∫ÁôåÊ≤ªÁôÇ‰∏≠ÁöÑÊÇ£ËÄÖÈ†êÂæåÂíåË®∫Êñ∑Á≤æÊ∫ñÂ∫¶„ÄÇ

##### **Predictive Modeling for Breast Cancer Classification in the Context of Bangladeshi Patients: A Supervised Machine Learning Approach with Explainable AI**
2404.04686v1 by Taminul Islam, Md. Alif Sheakh, Mst. Sazia Tahosin, Most. Hasna Hena, Shopnil Akash, Yousef A. Bin Jardan, Gezahign Fentahun Wondmie, Hiba-Allah Nafidi, Mohammed Bourhia

Breast cancer has rapidly increased in prevalence in recent years, making it
one of the leading causes of mortality worldwide. Among all cancers, it is by
far the most common. Diagnosing this illness manually requires significant time
and expertise. Since detecting breast cancer is a time-consuming process,
preventing its further spread can be aided by creating machine-based forecasts.
Machine learning and Explainable AI are crucial in classification as they not
only provide accurate predictions but also offer insights into how the model
arrives at its decisions, aiding in the understanding and trustworthiness of
the classification results. In this study, we evaluate and compare the
classification accuracy, precision, recall, and F-1 scores of five different
machine learning methods using a primary dataset (500 patients from Dhaka
Medical College Hospital). Five different supervised machine learning
techniques, including decision tree, random forest, logistic regression, naive
bayes, and XGBoost, have been used to achieve optimal results on our dataset.
Additionally, this study applied SHAP analysis to the XGBoost model to
interpret the model's predictions and understand the impact of each feature on
the model's output. We compared the accuracy with which several algorithms
classified the data, as well as contrasted with other literature in this field.
After final evaluation, this study found that XGBoost achieved the best model
accuracy, which is 97%.

ÊëòË¶ÅÔºö<paragraph>ËøëÂπ¥‰æÜÔºå‰π≥ÁôåÁöÑÁõõË°åÁéáËøÖÈÄüÂ¢ûÂä†Ôºå‰ΩøÂÖ∂ÊàêÁÇ∫ÂÖ®ÁêÉ‰∏ªË¶ÅÁöÑÊ≠ª‰∫°ÂéüÂõ†‰πã‰∏Ä„ÄÇÂú®ÊâÄÊúâÁôåÁóá‰∏≠Ôºå‰π≥ÁôåËøÑ‰ªäÁÇ∫Ê≠¢ÊòØÊúÄÂ∏∏Ë¶ãÁöÑ„ÄÇÊâãÂãïË®∫Êñ∑Ê≠§ÁñæÁóÖÈúÄË¶ÅÂ§ßÈáèÁöÑÊôÇÈñìÂíåÂ∞àÊ•≠Áü•Ë≠ò„ÄÇÁî±Êñº‰π≥ÁôåÁöÑÊ™¢Ê∏¨ÈÅéÁ®ãËÄóÊôÇÔºåÂõ†Ê≠§ÈÄèÈÅéÂª∫Á´ãÊ©üÂô®Â≠∏ÁøíÊ®°Âûã‰æÜÈ†êÊ∏¨ÔºåÊúâÂä©ÊñºÈò≤Ê≠¢ÂÖ∂ÈÄ≤‰∏ÄÊ≠•Êì¥Êï£„ÄÇÊ©üÂô®Â≠∏ÁøíÂíåÂèØËß£Èáã AI Âú®ÂàÜÈ°û‰∏≠Ëá≥ÈóúÈáçË¶ÅÔºåÂõ†ÁÇ∫ÂÆÉÂÄë‰∏çÂÉÖÂèØ‰ª•Êèê‰æõÊ∫ñÁ¢∫ÁöÑÈ†êÊ∏¨ÔºåÈÇÑÂèØ‰ª•Ê∑±ÂÖ•‰∫ÜËß£Ê®°ÂûãÂ¶Ç‰ΩïÂÅöÂá∫Ê±∫Á≠ñÔºåÊúâÂä©ÊñºÁêÜËß£Âíå‰ø°Ë≥¥ÂàÜÈ°ûÁµêÊûú„ÄÇÂú®Ê≠§Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëË©ï‰º∞‰∏¶ÊØîËºÉ‰∫Ü‰∫îÁ®Æ‰∏çÂêåÁöÑÊ©üÂô®Â≠∏ÁøíÊñπÊ≥ïÁöÑÂàÜÈ°ûÊ∫ñÁ¢∫Â∫¶„ÄÅÁ≤æÁ¢∫Â∫¶„ÄÅÂè¨ÂõûÁéáÂíå F1 ÂàÜÊï∏Ôºå‰ΩøÁî®‰∫Ü‰∏ÄÂÄã‰∏ªË¶ÅÁöÑË≥áÊñôÈõÜÔºàÈÅîÂç°ÈÜ´Â≠∏Èô¢ÈÜ´Èô¢ÁöÑ 500 ÂêçÊÇ£ËÄÖÔºâ„ÄÇ‰∫îÁ®Æ‰∏çÂêåÁöÑÁõ£Áù£ÂºèÊ©üÂô®Â≠∏ÁøíÊäÄË°ìÔºåÂåÖÊã¨Ê±∫Á≠ñÊ®π„ÄÅÈö®Ê©üÊ£ÆÊûó„ÄÅÈÇèËºØËø¥Ê≠∏„ÄÅÊú¥Á¥†Ë≤ùÊ∞èÂíå XGBoostÔºåÂ∑≤Áî®ÊñºÂú®ÊàëÂÄëÁöÑË≥áÊñôÈõÜ‰∏äÂèñÂæóÊúÄ‰Ω≥ÁµêÊûú„ÄÇÊ≠§Â§ñÔºåÊú¨Á†îÁ©∂Â∞á SHAP ÂàÜÊûêÊáâÁî®Êñº XGBoost Ê®°ÂûãÔºå‰ª•Ëß£ÈáãÊ®°ÂûãÁöÑÈ†êÊ∏¨‰∏¶‰∫ÜËß£ÊØèÂÄãÁâπÂæµÂ∞çÊ®°ÂûãËº∏Âá∫ÁöÑÂΩ±Èüø„ÄÇÊàëÂÄëÊØîËºÉ‰∫ÜÂπæÁ®ÆÊºîÁÆóÊ≥ïÂ∞çË≥áÊñôÈÄ≤Ë°åÂàÜÈ°ûÁöÑÊ∫ñÁ¢∫Â∫¶Ôºå‰∏¶ËàáË©≤È†òÂüüÁöÑÂÖ∂‰ªñÊñáÁçªÈÄ≤Ë°åÂ∞çÊØî„ÄÇÂú®ÊúÄÂæåË©ï‰º∞ÂæåÔºåÊú¨Á†îÁ©∂ÁôºÁèæ XGBoost ÈÅîÂà∞‰∫ÜÊúÄ‰Ω≥ÁöÑÊ®°ÂûãÊ∫ñÁ¢∫Â∫¶ÔºåÁÇ∫ 97%„ÄÇ</paragraph>

##### **Enhancing Breast Cancer Diagnosis in Mammography: Evaluation and Integration of Convolutional Neural Networks and Explainable AI**
2404.03892v3 by Maryam Ahmed, Tooba Bibi, Rizwan Ahmed Khan, Sidra Nasir

The Deep learning (DL) models for diagnosing breast cancer from mammographic
images often operate as "black boxes", making it difficult for healthcare
professionals to trust and understand their decision-making processes. The
study presents an integrated framework combining Convolutional Neural Networks
(CNNs) and Explainable Artificial Intelligence (XAI) for the enhanced diagnosis
of breast cancer using the CBIS-DDSM dataset. The methodology encompasses an
elaborate data preprocessing pipeline and advanced data augmentation techniques
to counteract dataset limitations and transfer learning using pre-trained
networks such as VGG-16, Inception-V3 and ResNet was employed. A focal point of
our study is the evaluation of XAI's effectiveness in interpreting model
predictions, highlighted by utilizing the Hausdorff measure to assess the
alignment between AI-generated explanations and expert annotations
quantitatively. This approach is critical for XAI in promoting trustworthiness
and ethical fairness in AI-assisted diagnostics. The findings from our research
illustrate the effective collaboration between CNNs and XAI in advancing
diagnostic methods for breast cancer, thereby facilitating a more seamless
integration of advanced AI technologies within clinical settings. By enhancing
the interpretability of AI driven decisions, this work lays the groundwork for
improved collaboration between AI systems and medical practitioners, ultimately
enriching patient care. Furthermore, the implications of our research extended
well beyond the current methodologies. It encourages further research into how
to combine multimodal data and improve AI explanations to meet the needs of
clinical practice.

ÊëòË¶ÅÔºöÊ∑±Â∫¶Â≠∏Áøí (DL) Áî®ÊñºÂæû‰π≥ÊàøÊîùÂΩ±Ë°ìÂΩ±ÂÉèË®∫Êñ∑‰π≥ÁôåÁöÑÊ®°ÂûãÈÄöÂ∏∏‰ª•„ÄåÈªëÁõíÂ≠ê„ÄçÊñπÂºèÈÅã‰ΩúÔºåÈÄô‰ΩøÂæóÈÜ´ÁôÇ‰øùÂÅ•Â∞àÊ•≠‰∫∫Âì°Èõ£‰ª•‰ø°‰ªªÂíåÁêÜËß£ÂÖ∂Ê±∫Á≠ñÈÅéÁ®ã„ÄÇÊú¨Á†îÁ©∂ÊèêÂá∫‰∏ÄÂÄãÊï¥ÂêàÊû∂ÊßãÔºåÁµêÂêàÂç∑Á©çÁ•ûÁ∂ìÁ∂≤Ë∑Ø (CNN) ÂíåÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖß (XAI)Ôºå‰ª•‰ΩøÁî® CBIS-DDSM Ë≥áÊñôÈõÜÂ¢ûÂº∑‰π≥ÁôåÁöÑË®∫Êñ∑„ÄÇÊñπÊ≥ïÂåÖÂê´‰∏ÄÂÄãÁ≤æÁ¥∞ÁöÑË≥áÊñôÂâçËôïÁêÜÁÆ°Á∑öÂíåÈÄ≤ÈöéË≥áÊñôÊì¥ÂÖÖÊäÄË°ìÔºå‰ª•Â∞çÊäóË≥áÊñôÈõÜÈôêÂà∂Ôºå‰∏¶Êé°Áî®È†êÂÖàË®ìÁ∑¥ÁöÑÁ∂≤Ë∑ØÔºà‰æãÂ¶Ç VGG-16„ÄÅInception-V3 Âíå ResNetÔºâÈÄ≤Ë°åÈÅ∑ÁßªÂ≠∏Áøí„ÄÇÊàëÂÄëÁ†îÁ©∂ÁöÑÈáçÈªûÊòØË©ï‰º∞ XAI Âú®Ëß£ÈáãÊ®°ÂûãÈ†êÊ∏¨‰∏≠ÁöÑÊúâÊïàÊÄßÔºåÈáçÈªûÂà©Áî®Ë±™ÊñØÂ§öÂ§´Ê∏¨Â∫¶ÈáèÂåñË©ï‰º∞ AI ÁîüÊàêÁöÑËß£ÈáãÂíåÂ∞àÂÆ∂Ë®ªËß£‰πãÈñìÁöÑ‰∏ÄËá¥ÊÄß„ÄÇÈÄôÁ®ÆÊñπÊ≥ïÂ∞çÊñº XAI Âú®‰øÉÈÄ≤ AI ËºîÂä©Ë®∫Êñ∑‰∏≠ÁöÑÂèØ‰ø°Â∫¶ÂíåÂÄ´ÁêÜÂÖ¨Âπ≥ÊÄßËá≥ÈóúÈáçË¶Å„ÄÇÊàëÂÄëÁ†îÁ©∂ÁöÑÁôºÁèæË™™Êòé‰∫Ü CNN Âíå XAI Âú®Êé®ÈÄ≤‰π≥ÁôåË®∫Êñ∑ÊñπÊ≥ï‰∏≠ÁöÑÊúâÊïàÂçî‰ΩúÔºåÂæûËÄå‰øÉÈÄ≤‰∫ÜÂÖàÈÄ≤ AI ÊäÄË°ìÂú®Ëá®Â∫äÁí∞Â¢É‰∏≠ÁöÑÊõ¥È†ÜÊö¢Êï¥Âêà„ÄÇÈÄèÈÅéÂ¢ûÂº∑ AI È©ÖÂãïÊ±∫Á≠ñÁöÑÂèØËß£ÈáãÊÄßÔºåÈÄôÈ†ÖÂ∑•‰ΩúÁÇ∫ AI Á≥ªÁµ±ÂíåÈÜ´ÁôÇÂæûÊ•≠‰∫∫Âì°‰πãÈñìÁöÑÊîπÂñÑÂçî‰ΩúÂ•†ÂÆö‰∫ÜÂü∫Á§éÔºåÊúÄÁµÇË±êÂØå‰∫ÜÊÇ£ËÄÖÁÖßË≠∑„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁ†îÁ©∂ÁöÑÂΩ±ÈüøÈÅ†ÈÅ†Ë∂ÖÂá∫‰∫ÜÁõÆÂâçÁöÑÊäÄË°ì„ÄÇÂÆÉÈºìÂãµÈÄ≤‰∏ÄÊ≠•Á†îÁ©∂Â¶Ç‰ΩïÁµêÂêàÂ§öÊ®°ÂºèË≥áÊñô‰∏¶ÊîπÂñÑ AI Ëß£ÈáãÔºå‰ª•ÊªøË∂≥Ëá®Â∫äÂØ¶ÂãôÁöÑÈúÄÊ±Ç„ÄÇ

##### **Addressing Social Misattributions of Large Language Models: An HCXAI-based Approach**
2403.17873v1 by Andrea Ferrario, Alberto Termine, Alessandro Facchini

Human-centered explainable AI (HCXAI) advocates for the integration of social
aspects into AI explanations. Central to the HCXAI discourse is the Social
Transparency (ST) framework, which aims to make the socio-organizational
context of AI systems accessible to their users. In this work, we suggest
extending the ST framework to address the risks of social misattributions in
Large Language Models (LLMs), particularly in sensitive areas like mental
health. In fact LLMs, which are remarkably capable of simulating roles and
personas, may lead to mismatches between designers' intentions and users'
perceptions of social attributes, risking to promote emotional manipulation and
dangerous behaviors, cases of epistemic injustice, and unwarranted trust. To
address these issues, we propose enhancing the ST framework with a fifth
'W-question' to clarify the specific social attributions assigned to LLMs by
its designers and users. This addition aims to bridge the gap between LLM
capabilities and user perceptions, promoting the ethically responsible
development and use of LLM-based technology.

ÊëòË¶ÅÔºö‰ª•‰∫∫‰∏∫Êú¨ÁöÑÂèØËß£Èáä AI (HCXAI) ÂÄ°ÂØºÂ∞ÜÁ§æ‰ºöÂ±ÇÈù¢Êï¥ÂêàÂà∞ AI Ëß£Èáä‰∏≠„ÄÇHCXAI ËØùËØ≠ÁöÑÊ†∏ÂøÉÊòØÁ§æ‰ºöÈÄèÊòéÂ∫¶ (ST) Ê°ÜÊû∂ÔºåÂÖ∂ÁõÆÊ†áÊòØËÆ© AI Á≥ªÁªüÁöÑÁ§æ‰ºöÁªÑÁªáËÉåÊôØÂØπÁî®Êà∑Êù•ËØ¥ÊòØÂèØÁêÜËß£ÁöÑ„ÄÇÂú®ËøôÈ°πÂ∑•‰Ωú‰∏≠ÔºåÊàë‰ª¨Âª∫ËÆÆÊâ©Â±ï ST Ê°ÜÊû∂‰ª•Ëß£ÂÜ≥Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã (LLM) ‰∏≠Á§æ‰ºöÈîôËØØÂΩíÂõ†ÁöÑÈ£éÈô©ÔºåÂ∞§ÂÖ∂ÊòØÂú®ÂøÉÁêÜÂÅ•Â∫∑Á≠âÊïèÊÑüÈ¢ÜÂüü„ÄÇ‰∫ãÂÆû‰∏äÔºåLLM ËÉΩÂ§üÂá∫Ëâ≤Âú∞Ê®°ÊãüËßíËâ≤Âíå‰∫∫Ê†ºÔºåËøôÂèØËÉΩÂØºËá¥ËÆæËÆ°ËÄÖÁöÑÊÑèÂõæÂíåÁî®Êà∑ÂØπÁ§æ‰ºöÂ±ûÊÄßÁöÑËÆ§Áü•‰πãÈó¥Âá∫Áé∞ÈîôÈÖçÔºå‰ªéËÄåÊúâÈ£éÈô©‰øÉËøõÊÉÖÁª™ÊìçÁ∫µÂíåÂç±Èô©Ë°å‰∏∫„ÄÅËÆ§Áü•‰∏çÂÖ¨Ê≠£Âíå‰∏çÂêàÁêÜÁöÑ‰ø°‰ªª„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∫õÈóÆÈ¢òÔºåÊàë‰ª¨Âª∫ËÆÆÁî®Á¨¨‰∫î‰∏™‚ÄúW ÈóÆÈ¢ò‚ÄùÊù•Â¢ûÂº∫ ST Ê°ÜÊû∂Ôºå‰ª•ÊòéÁ°ÆËÆæËÆ°ËÄÖÂíåÁî®Êà∑Ëµã‰∫à LLM ÁöÑÂÖ∑‰ΩìÁ§æ‰ºöÂ±ûÊÄß„ÄÇÊ≠§Ë°•ÂÖÖÊó®Âú®Âº•Âêà LLM ËÉΩÂäõÂíåÁî®Êà∑ËÆ§Áü•‰πãÈó¥ÁöÑÂ∑ÆË∑ùÔºå‰øÉËøõÂü∫‰∫é LLM ÁöÑÊäÄÊúØÂú®ÈÅìÂæ∑‰∏äË¥üË¥£‰ªªÂú∞ÂºÄÂèëÂíå‰ΩøÁî®„ÄÇ

##### **Clinical Domain Knowledge-Derived Template Improves Post Hoc AI Explanations in Pneumothorax Classification**
2403.18871v1 by Han Yuan, Chuan Hong, Pengtao Jiang, Gangming Zhao, Nguyen Tuan Anh Tran, Xinxing Xu, Yet Yen Yan, Nan Liu

Background: Pneumothorax is an acute thoracic disease caused by abnormal air
collection between the lungs and chest wall. To address the opaqueness often
associated with deep learning (DL) models, explainable artificial intelligence
(XAI) methods have been introduced to outline regions related to pneumothorax
diagnoses made by DL models. However, these explanations sometimes diverge from
actual lesion areas, highlighting the need for further improvement. Method: We
propose a template-guided approach to incorporate the clinical knowledge of
pneumothorax into model explanations generated by XAI methods, thereby
enhancing the quality of these explanations. Utilizing one lesion delineation
created by radiologists, our approach first generates a template that
represents potential areas of pneumothorax occurrence. This template is then
superimposed on model explanations to filter out extraneous explanations that
fall outside the template's boundaries. To validate its efficacy, we carried
out a comparative analysis of three XAI methods with and without our template
guidance when explaining two DL models in two real-world datasets. Results: The
proposed approach consistently improved baseline XAI methods across twelve
benchmark scenarios built on three XAI methods, two DL models, and two
datasets. The average incremental percentages, calculated by the performance
improvements over the baseline performance, were 97.8% in Intersection over
Union (IoU) and 94.1% in Dice Similarity Coefficient (DSC) when comparing model
explanations and ground-truth lesion areas. Conclusions: In the context of
pneumothorax diagnoses, we proposed a template-guided approach for improving AI
explanations. We anticipate that our template guidance will forge a fresh
approach to elucidating AI models by integrating clinical domain expertise.

ÊëòË¶ÅÔºö<paragraph>ËÉåÊôØÔºöÊ∞£ËÉ∏ÊòØ‰∏ÄÁ®ÆÂõ†ËÇ∫ÈÉ®ËàáËÉ∏Â£Å‰πãÈñìÁï∞Â∏∏ÈõÜÊ∞£ÊâÄÂºïËµ∑ÁöÑÊÄ•ÊÄßËÉ∏ËÖîÁñæÁóÖ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫Ê∑±Â∫¶Â≠∏ÁøíÔºàDLÔºâÊ®°ÂûãÁ∂ìÂ∏∏‰º¥Èö®ÁöÑ‰∏çÈÄèÊòéÊÄßÔºåÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖßÔºàXAIÔºâÊñπÊ≥ïÂ∑≤Ë¢´ÂºïÂÖ•ÔºåÁî®ÊñºÊ¶ÇËø∞Ëàá DL Ê®°ÂûãÂÅöÂá∫ÁöÑÊ∞£ËÉ∏Ë®∫Êñ∑Áõ∏ÈóúÁöÑÂçÄÂüü„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õËß£ÈáãÊúâÊôÇÊúÉËàáÂØ¶ÈöõÁóÖÁÅ∂ÂçÄÂüüÊúâÊâÄÂá∫ÂÖ•ÔºåÁ™ÅÈ°ØÂá∫ÈÄ≤‰∏ÄÊ≠•ÊîπÈÄ≤ÁöÑÂøÖË¶ÅÊÄß„ÄÇÊñπÊ≥ïÔºöÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊ®°ÊùøÂºïÂ∞éÂºèÊñπÊ≥ïÔºåÂ∞áÊ∞£ËÉ∏ÁöÑËá®Â∫äÁü•Ë≠òÁ¥çÂÖ• XAI ÊñπÊ≥ïÁî¢ÁîüÁöÑÊ®°ÂûãËß£Èáã‰∏≠ÔºåÂæûËÄåÊèêÂçáÈÄô‰∫õËß£ÈáãÁöÑÂìÅË≥™„ÄÇÂà©Áî®ÊîæÂ∞ÑÁßëÈÜ´Â∏´Âª∫Á´ãÁöÑÁóÖÁÅ∂ÊèèÁπ™ÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÈ¶ñÂÖàÁî¢Áîü‰∏ÄÂÄãÊ®°ÊùøÔºåÁî®ÊñºË°®Á§∫Ê∞£ËÉ∏ÂèØËÉΩÁôºÁîüÁöÑÂçÄÂüü„ÄÇÁÑ∂ÂæåÂ∞áÊ≠§Ê®°ÊùøÁñäÂä†Âú®Ê®°ÂûãËß£Èáã‰∏äÔºå‰ª•ÁØ©ÈÅ∏Âá∫Ë∂ÖÂá∫Ê®°ÊùøÈÇäÁïåÁöÑÁÑ°ÈóúËß£Èáã„ÄÇÁÇ∫‰∫ÜÈ©óË≠âÂÖ∂ÊïàÂäõÔºåÊàëÂÄëÂ∞ç‰∏âÁ®Æ XAI ÊñπÊ≥ïÈÄ≤Ë°å‰∫ÜÊØîËºÉÂàÜÊûêÔºåÂú®ÂÖ©ÂÄãÁúüÂØ¶‰∏ñÁïåË≥áÊñôÈõÜ‰∏≠Ëß£ÈáãÂÖ©ÂÄã DL Ê®°ÂûãÊôÇÔºåÂàÜÂà•Êé°Áî®Âíå‰∏çÊé°Áî®ÊàëÂÄëÁöÑÊ®°ÊùøÂºïÂ∞é„ÄÇÁµêÊûúÔºöÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÂú®Âª∫Á´ãÊñº‰∏âÁ®Æ XAI ÊñπÊ≥ï„ÄÅÂÖ©ÂÄã DL Ê®°ÂûãÂíåÂÖ©ÂÄãË≥áÊñôÈõÜÁöÑÂçÅ‰∫åÁ®ÆÂü∫Ê∫ñÊÉÖÂ¢É‰∏≠ÔºåÂßãÁµÇÊîπÂñÑ‰∫ÜÂü∫Ê∫ñ XAI ÊñπÊ≥ï„ÄÇÂú®ÊØîËºÉÊ®°ÂûãËß£ÈáãÂíåÁúüÂØ¶ÁóÖÁÅ∂ÂçÄÂüüÊôÇÔºåÈÄèÈÅéÂü∫Ê∫ñÊïàËÉΩÁöÑÊïàËÉΩÊîπÈÄ≤Ë®àÁÆóÂá∫ÁöÑÂπ≥ÂùáÂ¢ûÈáèÁôæÂàÜÊØîÁÇ∫‰∫§ÈõÜÊØîÔºàIoUÔºâÁöÑ 97.8% ÂíåÈ™∞Â≠êÁõ∏‰ººÊÄß‰øÇÊï∏ÔºàDSCÔºâÁöÑ 94.1%„ÄÇÁµêË´ñÔºöÂú®Ê∞£ËÉ∏Ë®∫Êñ∑ÁöÑËÉåÊôØ‰∏ãÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊ®°ÊùøÂºïÂ∞éÂºèÊñπÊ≥ïÔºåÁî®ÊñºÊîπÂñÑ AI Ëß£Èáã„ÄÇÊàëÂÄëÈ†êÊúüÊàëÂÄëÁöÑÊ®°ÊùøÂºïÂ∞éÂ∞áÈÄèÈÅéÊï¥ÂêàËá®Â∫äÈ†òÂüüÂ∞àÊ•≠Áü•Ë≠òÔºåÁÇ∫Èó°Êòé AI Ê®°ÂûãÂª∫Á´ã‰∏ÄÁ®ÆÊñ∞ÊñπÊ≥ï„ÄÇ</paragraph>

##### **Enhancing Neural Machine Translation of Low-Resource Languages: Corpus Development, Human Evaluation and Explainable AI Architectures**
2403.01580v1 by S√©amus Lankford

In the current machine translation (MT) landscape, the Transformer
architecture stands out as the gold standard, especially for high-resource
language pairs. This research delves into its efficacy for low-resource
language pairs including both the English$\leftrightarrow$Irish and
English$\leftrightarrow$Marathi language pairs. Notably, the study identifies
the optimal hyperparameters and subword model type to significantly improve the
translation quality of Transformer models for low-resource language pairs.
  The scarcity of parallel datasets for low-resource languages can hinder MT
development. To address this, gaHealth was developed, the first bilingual
corpus of health data for the Irish language. Focusing on the health domain,
models developed using this in-domain dataset exhibited very significant
improvements in BLEU score when compared with models from the LoResMT2021
Shared Task. A subsequent human evaluation using the multidimensional quality
metrics error taxonomy showcased the superior performance of the Transformer
system in reducing both accuracy and fluency errors compared to an RNN-based
counterpart.
  Furthermore, this thesis introduces adaptNMT and adaptMLLM, two open-source
applications streamlined for the development, fine-tuning, and deployment of
neural machine translation models. These tools considerably simplify the setup
and evaluation process, making MT more accessible to both developers and
translators. Notably, adaptNMT, grounded in the OpenNMT ecosystem, promotes
eco-friendly natural language processing research by highlighting the
environmental footprint of model development. Fine-tuning of MLLMs by adaptMLLM
demonstrated advancements in translation performance for two low-resource
language pairs: English$\leftrightarrow$Irish and
English$\leftrightarrow$Marathi, compared to baselines from the LoResMT2021
Shared Task.

ÊëòË¶ÅÔºö<paragraph>Âú®Áï∂ÂâçÊ©üÂô®ÁøªË≠Ø (MT) È†òÂüü‰∏≠ÔºåTransformer Êû∂ÊßãËÑ´Á©éËÄåÂá∫ÔºåÊàêÁÇ∫ÈªÉÈáëÊ®ôÊ∫ñÔºåÁâπÂà•ÊòØÂ∞çÊñºÈ´òË≥áÊ∫êË™ûË®ÄÂ∞ç„ÄÇÊú¨Á†îÁ©∂Êé¢Ë®éÂÖ∂Â∞ç‰ΩéË≥áÊ∫êË™ûË®ÄÂ∞çÁöÑÊïàËÉΩÔºåÂåÖÊã¨Ëã±Ë™û‚ÜîÊÑõÁàæËò≠Ë™ûÂíåËã±Ë™û‚ÜîÈ¶¨ÊãâÂú∞Ë™ûË™ûË®ÄÂ∞ç„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÊú¨Á†îÁ©∂Ë≠òÂà•Âá∫ÊúÄ‰Ω≥Ë∂ÖÂèÉÊï∏ÂíåÂ≠êË©ûÊ®°ÂûãÈ°ûÂûãÔºå‰ª•È°ØËëóÊèêÈ´ò Transformer Ê®°ÂûãÂ∞ç‰ΩéË≥áÊ∫êË™ûË®ÄÂ∞çÁöÑÁøªË≠ØÂìÅË≥™„ÄÇ
‰ΩéË≥áÊ∫êË™ûË®ÄÁöÑÂπ≥Ë°åË≥áÊñôÈõÜÁöÑÁ®ÄÁº∫ÊúÉÈòªÁ§ô MT ÁöÑÁôºÂ±ï„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÈñãÁôº‰∫Ü gaHealthÔºåÈÄôÊòØÊÑõÁàæËò≠Ë™ûÁöÑÁ¨¨‰∏ÄÂÄãÈõôË™ûÂÅ•Â∫∑Ë≥áÊñôË™ûÊñôÂ∫´„ÄÇÂ∞àÊ≥®ÊñºÂÅ•Â∫∑È†òÂüüÔºå‰ΩøÁî®Ê≠§ÂüüÂÖßË≥áÊñôÈõÜÈñãÁôºÁöÑÊ®°ÂûãÂú® BLEU ÂæóÂàÜÊñπÈù¢Ë°®ÁèæÂá∫ÈùûÂ∏∏È°ØËëóÁöÑÈÄ≤Ê≠•ÔºåËàá LoResMT2021 ÂÖ±‰∫´‰ªªÂãô‰∏≠ÁöÑÊ®°ÂûãÁõ∏ÊØî„ÄÇÈö®Âæå‰ΩøÁî®Â§öÁ∂≠ÂìÅË≥™ÊåáÊ®ôÈåØË™§ÂàÜÈ°ûÊ≥ïÈÄ≤Ë°åÁöÑ‰∫∫Â∑•Ë©ï‰º∞È°ØÁ§∫ÔºåËàáÂü∫Êñº RNN ÁöÑÂ∞çÊáâÊ®°ÂûãÁõ∏ÊØîÔºåTransformer Á≥ªÁµ±Âú®Ê∏õÂ∞ëÊ∫ñÁ¢∫ÊÄßÂíåÊµÅÊö¢ÊÄßÈåØË™§ÊñπÈù¢Ë°®ÁèæÂá∫ÂÑ™Áï∞ÁöÑÊÄßËÉΩ„ÄÇ
Ê≠§Â§ñÔºåÊú¨Ë´ñÊñá‰ªãÁ¥π‰∫Ü adaptNMT Âíå adaptMLLMÔºåÈÄôÂÖ©ÂÄãÈñãÊ∫êÊáâÁî®Á®ãÂºèÁ∞°Âåñ‰∫ÜÁ•ûÁ∂ìÊ©üÂô®ÁøªË≠ØÊ®°ÂûãÁöÑÈñãÁôº„ÄÅÂæÆË™øÂíåÈÉ®ÁΩ≤„ÄÇÈÄô‰∫õÂ∑•ÂÖ∑Â§ßÂπÖÁ∞°Âåñ‰∫ÜË®≠ÂÆöÂíåË©ï‰º∞ÊµÅÁ®ãÔºåËÆì MT Êõ¥ÂÆπÊòìËÆìÈñãÁôº‰∫∫Âì°ÂíåÁøªË≠Ø‰∫∫Âì°‰ΩøÁî®„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåadaptNMT ‰ª• OpenNMT ÁîüÊÖãÁ≥ªÁµ±ÁÇ∫Âü∫Á§éÔºåÈÄöÈÅéÂº∑Ë™øÊ®°ÂûãÈñãÁôºÁöÑÁí∞Â¢ÉË∂≥Ë∑°‰æÜ‰øÉÈÄ≤ÁîüÊÖãÂèãÂ•ΩÁöÑËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜÁ†îÁ©∂„ÄÇËàá LoResMT2021 ÂÖ±‰∫´‰ªªÂãô‰∏≠ÁöÑÂü∫Ê∫ñÁõ∏ÊØîÔºåadaptMLLM Â∞ç MLLM ÁöÑÂæÆË™øË≠âÊòé‰∫ÜËã±Ë™û‚ÜîÊÑõÁàæËò≠Ë™ûÂíåËã±Ë™û‚ÜîÈ¶¨ÊãâÂú∞Ë™ûÈÄôÂÖ©ÂÄã‰ΩéË≥áÊ∫êË™ûË®ÄÂ∞çÁöÑÁøªË≠ØÊÄßËÉΩÈÄ≤Ê≠•„ÄÇ</paragraph>

##### **Artificial Intelligence and Diabetes Mellitus: An Inside Look Through the Retina**
2402.18600v1 by Yasin Sadeghi Bazargani, Majid Mirzaei, Navid Sobhi, Mirsaeed Abdollahi, Ali Jafarizadeh, Siamak Pedrammehr, Roohallah Alizadehsani, Ru San Tan, Sheikh Mohammed Shariful Islam, U. Rajendra Acharya

Diabetes mellitus (DM) predisposes patients to vascular complications.
Retinal images and vasculature reflect the body's micro- and macrovascular
health. They can be used to diagnose DM complications, including diabetic
retinopathy (DR), neuropathy, nephropathy, and atherosclerotic cardiovascular
disease, as well as forecast the risk of cardiovascular events. Artificial
intelligence (AI)-enabled systems developed for high-throughput detection of DR
using digitized retinal images have become clinically adopted. Beyond DR
screening, AI integration also holds immense potential to address challenges
associated with the holistic care of the patient with DM. In this work, we aim
to comprehensively review the literature for studies on AI applications based
on retinal images related to DM diagnosis, prognostication, and management. We
will describe the findings of holistic AI-assisted diabetes care, including but
not limited to DR screening, and discuss barriers to implementing such systems,
including issues concerning ethics, data privacy, equitable access, and
explainability. With the ability to evaluate the patient's health status vis a
vis DM complication as well as risk prognostication of future cardiovascular
complications, AI-assisted retinal image analysis has the potential to become a
central tool for modern personalized medicine in patients with DM.

ÊëòË¶ÅÔºöÁ≥ñÂ∞øÁóÖÔºàDMÔºâ‰ΩøÊÇ£ËÄÖÂÆπÊòìÂá∫ÁèæË°ÄÁÆ°‰ΩµÁôºÁóá„ÄÇ
Ë¶ñÁ∂≤ËÜúÂΩ±ÂÉèÂíåË°ÄÁÆ°ÂèçÊò†Ë∫´È´îÁöÑÂæÆË°ÄÁÆ°ÂíåÂ∑®Ë°ÄÁÆ°ÂÅ•Â∫∑ÁãÄÊ≥Å„ÄÇÂÆÉÂÄëÂèØÁî®ÊñºË®∫Êñ∑Á≥ñÂ∞øÁóÖ‰ΩµÁôºÁóáÔºåÂåÖÊã¨Á≥ñÂ∞øÁóÖË¶ñÁ∂≤ËÜúÁóÖËÆäÔºàDRÔºâ„ÄÅÁ•ûÁ∂ìÁóÖËÆä„ÄÅËÖéÁóÖÂíåÂãïËÑàÁ≤•Ê®£Á°¨ÂåñÊÄßÂøÉË°ÄÁÆ°ÁñæÁóÖÔºå‰ª•ÂèäÈ†êÊ∏¨ÂøÉË°ÄÁÆ°‰∫ã‰ª∂ÁöÑÈ¢®Èö™„ÄÇÁÇ∫‰ΩøÁî®Êï∏‰ΩçÂåñË¶ñÁ∂≤ËÜúÂΩ±ÂÉèÈÄ≤Ë°åÈ´òÈÄöÈáè DR Ê™¢Ê∏¨ËÄåÈñãÁôºÁöÑ‰∫∫Â∑•Êô∫ÊÖßÔºàAIÔºâÂïüÁî®Á≥ªÁµ±Â∑≤Âú®Ëá®Â∫äÊé°Áî®„ÄÇÈô§‰∫Ü DR ÁØ©Ê™¢Â§ñÔºåAI Êï¥Âêà‰πüÂÖ∑ÊúâÂ∑®Â§ßÁöÑÊΩõÂäõ‰æÜÊáâÂ∞çËàáÁ≥ñÂ∞øÁóÖÊÇ£ËÄÖÊï¥È´îÁÖßË≠∑Áõ∏ÈóúÁöÑÊåëÊà∞„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊó®Âú®ÂÖ®Èù¢ÂõûÈ°ßÂü∫ÊñºË¶ñÁ∂≤ËÜúÂΩ±ÂÉèÁöÑ AI ÊáâÁî®Áõ∏ÈóúÁ†îÁ©∂ÁöÑÊñáÁçªÔºåÈÄô‰∫õÁ†îÁ©∂ËàáÁ≥ñÂ∞øÁóÖÁöÑË®∫Êñ∑„ÄÅÈ†êÂæåÂíåÁÆ°ÁêÜÊúâÈóú„ÄÇÊàëÂÄëÂ∞áÊèèËø∞Êï¥È´î AI ËºîÂä©Á≥ñÂ∞øÁóÖÁÖßË≠∑ÁöÑÁôºÁèæÔºåÂåÖÊã¨‰ΩÜ‰∏çÈôêÊñº DR ÁØ©Ê™¢Ôºå‰∏¶Ë®éË´ñÂØ¶ÊñΩÊ≠§È°ûÁ≥ªÁµ±ÁöÑÈöúÁ§ôÔºåÂåÖÊã¨ËàáÂÄ´ÁêÜ„ÄÅË≥áÊñôÈö±ÁßÅ„ÄÅÂÖ¨Âπ≥Â≠òÂèñÂíåÂèØËß£ÈáãÊÄßÊúâÈóúÁöÑÂïèÈ°å„ÄÇÈÄèÈÅéË©ï‰º∞ÊÇ£ËÄÖÁöÑÂÅ•Â∫∑ÁãÄÊ≥ÅÔºåÂêåÊôÇËÄÉÈáèÁ≥ñÂ∞øÁóÖ‰ΩµÁôºÁóá‰ª•ÂèäÊú™‰æÜÂøÉË°ÄÁÆ°‰ΩµÁôºÁóáÁöÑÈ¢®Èö™È†êÂæåÔºåAI ËºîÂä©Ë¶ñÁ∂≤ËÜúÂΩ±ÂÉèÂàÜÊûêÊúâÊΩõÂäõÊàêÁÇ∫Á≥ñÂ∞øÁóÖÊÇ£ËÄÖÁèæ‰ª£ÂåñÂÄã‰∫∫ÂåñÈÜ´ÁôÇÁöÑ‰∏≠ÂøÉÂ∑•ÂÖ∑„ÄÇ

##### **Multi-stakeholder Perspective on Responsible Artificial Intelligence and Acceptability in Education**
2402.15027v2 by A. J. Karran, P. Charland, J-T. Martineau, A. Ortiz de Guinea Lopez de Arana, AM. Lesage, S. Senecal, P-M. Leger

This study investigates the acceptability of different artificial
intelligence (AI) applications in education from a multi-stakeholder
perspective, including students, teachers, and parents. Acknowledging the
transformative potential of AI in education, it addresses concerns related to
data privacy, AI agency, transparency, explainability and the ethical
deployment of AI. Through a vignette methodology, participants were presented
with four scenarios where AI's agency, transparency, explainability, and
privacy were manipulated. After each scenario, participants completed a survey
that captured their perceptions of AI's global utility, individual usefulness,
justice, confidence, risk, and intention to use each scenario's AI if
available. The data collection comprising a final sample of 1198
multi-stakeholder participants was distributed through a partner institution
and social media campaigns and focused on individual responses to four AI use
cases. A mediation analysis of the data indicated that acceptance and trust in
AI varies significantly across stakeholder groups. We found that the key
mediators between high and low levels of AI's agency, transparency, and
explainability, as well as the intention to use the different educational AI,
included perceived global utility, justice, and confidence. The study
highlights that the acceptance of AI in education is a nuanced and multifaceted
issue that requires careful consideration of specific AI applications and their
characteristics, in addition to the diverse stakeholders' perceptions.

ÊëòË¶ÅÔºöÈÄôÈ†ÖÁ†îÁ©∂ÂæûÂ§öÂÄãÂà©ÂÆ≥Èóú‰øÇ‰∫∫ÁöÑËßíÂ∫¶Êé¢Ë®é‰∏çÂêåÁöÑ‰∫∫Â∑•Êô∫ÊÖß (AI) ÊáâÁî®Âú®ÊïôËÇ≤‰∏äÁöÑÂèØÊé•ÂèóÊÄßÔºåÂåÖÊã¨Â≠∏Áîü„ÄÅËÄÅÂ∏´ÂíåÂÆ∂Èï∑„ÄÇÊâøË™ç AI Âú®ÊïôËÇ≤‰∏äÁöÑËΩâÂûãÊΩõÂäõÔºåÂÆÉËß£Ê±∫‰∫ÜËàáË≥áÊñôÈö±ÁßÅ„ÄÅAI ‰ª£ÁêÜ„ÄÅÈÄèÊòéÂ∫¶„ÄÅÂèØËß£ÈáãÊÄßÂíå AI ÁöÑÈÅìÂæ∑ÈÉ®ÁΩ≤Áõ∏ÈóúÁöÑÁñëÊÖÆ„ÄÇÈÄèÈÅéÂ∞èÊèíÊõ≤ÊñπÊ≥ïÔºåÂèÉËàáËÄÖË¢´ÂëàÁèæ‰∫ÜÂõõÁ®ÆÊÉÖÂ¢ÉÔºåÂÖ∂‰∏≠ AI ÁöÑ‰ª£ÁêÜ„ÄÅÈÄèÊòéÂ∫¶„ÄÅÂèØËß£ÈáãÊÄßÂíåÈö±ÁßÅÂèóÂà∞ÊìçÁ∏±„ÄÇÂú®ÊØèÂÄãÊÉÖÂ¢ÉÂæåÔºåÂèÉËàáËÄÖÂÆåÊàê‰∫Ü‰∏ÄÈ†ÖË™øÊü•ÔºåË©≤Ë™øÊü•ÊçïÊçâ‰∫Ü‰ªñÂÄëÂ∞ç AI ÁöÑÊï¥È´îÊïàÁî®„ÄÅÂÄã‰∫∫ÊïàÁî®„ÄÅÊ≠£Áæ©„ÄÅ‰ø°ÂøÉ„ÄÅÈ¢®Èö™ÂíåÂ¶ÇÊûúÂèØÁî®Ôºå‰ΩøÁî®ÊØèÂÄãÊÉÖÂ¢ÉÁöÑ AI ÁöÑÊÑèÂúñÁöÑÁúãÊ≥ï„ÄÇË≥áÊñôËíêÈõÜÂåÖÂê´‰æÜËá™Âêà‰ΩúÊ©üÊßãÂíåÁ§æÁæ§Â™íÈ´îÊ¥ªÂãïÁöÑ 1198 ‰ΩçÂ§öÂà©ÂÆ≥Èóú‰øÇ‰∫∫ÂèÉËàáËÄÖÁöÑÊúÄÁµÇÊ®£Êú¨Ôºå‰∏¶Â∞àÊ≥®ÊñºÂ∞çÂõõÂÄã AI ‰ΩøÁî®Ê°à‰æãÁöÑÂÄãÂà•ÂõûÊáâ„ÄÇÂ∞çË≥áÊñôÁöÑË™øËß£ÂàÜÊûêË°®ÊòéÔºåÂ∞ç AI ÁöÑÊé•ÂèóÂ∫¶Âíå‰ø°‰ªªÂú®Âà©ÂÆ≥Èóú‰øÇ‰∫∫ÂúòÈ´î‰πãÈñìÊúâÈ°ØËëóÂ∑ÆÁï∞„ÄÇÊàëÂÄëÁôºÁèæÔºåAI ÁöÑ‰ª£ÁêÜ„ÄÅÈÄèÊòéÂ∫¶ÂíåÂèØËß£ÈáãÊÄßÈ´ò‰ΩéÁ®ãÂ∫¶‰πãÈñìÁöÑÈóúÈçµË™øËß£ËÄÖÔºå‰ª•Âèä‰ΩøÁî®‰∏çÂêåÊïôËÇ≤ AI ÁöÑÊÑèÂúñÔºåÂåÖÊã¨ÊÑüÁü•Âà∞ÁöÑÊï¥È´îÊïàÁî®„ÄÅÊ≠£Áæ©Âíå‰ø°ÂøÉ„ÄÇÈÄôÈ†ÖÁ†îÁ©∂Âº∑Ë™øÔºåÊé•Âèó AI Âú®ÊïôËÇ≤‰∏äÁöÑÊáâÁî®ÊòØ‰∏ÄÂÄãÂæÆÂ¶ô‰∏îÂ§öÈù¢ÂêëÁöÑÂïèÈ°åÔºåÈô§‰∫Ü‰∏çÂêåÁöÑÂà©ÂÆ≥Èóú‰øÇ‰∫∫ÁöÑÁúãÊ≥ïÂ§ñÔºåÈÇÑÈúÄË¶Å‰ªîÁ¥∞ËÄÉÊÖÆÂÖ∑È´îÁöÑ AI ÊáâÁî®ÂèäÂÖ∂ÁâπÂæµ„ÄÇ

##### **Deciphering Heartbeat Signatures: A Vision Transformer Approach to Explainable Atrial Fibrillation Detection from ECG Signals**
2402.09474v2 by Aruna Mohan, Danne Elbers, Or Zilbershot, Fatemeh Afghah, David Vorchheimer

Remote patient monitoring based on wearable single-lead electrocardiogram
(ECG) devices has significant potential for enabling the early detection of
heart disease, especially in combination with artificial intelligence (AI)
approaches for automated heart disease detection. There have been prior studies
applying AI approaches based on deep learning for heart disease detection.
However, these models are yet to be widely accepted as a reliable aid for
clinical diagnostics, in part due to the current black-box perception
surrounding many AI algorithms. In particular, there is a need to identify the
key features of the ECG signal that contribute toward making an accurate
diagnosis, thereby enhancing the interpretability of the model. In the present
study, we develop a vision transformer approach to identify atrial fibrillation
based on single-lead ECG data. A residual network (ResNet) approach is also
developed for comparison with the vision transformer approach. These models are
applied to the Chapman-Shaoxing dataset to classify atrial fibrillation, as
well as another common arrhythmia, sinus bradycardia, and normal sinus rhythm
heartbeats. The models enable the identification of the key regions of the
heartbeat that determine the resulting classification, and highlight the
importance of P-waves and T-waves, as well as heartbeat duration and signal
amplitude, in distinguishing normal sinus rhythm from atrial fibrillation and
sinus bradycardia.

ÊëòË¶ÅÔºö<paragraph>Âü∫ÊñºÂèØÁ©øÊà¥ÂºèÂñÆÂ∞éÁ®ãÂøÉÈõªÂúñ (ECG) Ë£ùÁΩÆÁöÑÈÅ†Á´ØÁóÖÊÇ£Áõ£Ê∏¨Âú®Êó©ÊúüÂÅµÊ∏¨ÂøÉËáüÁñæÁóÖÊñπÈù¢ÂÖ∑ÊúâÈ°ØËëóÁöÑÊΩõÂäõÔºåÁâπÂà•ÊòØËàáÁî®ÊñºËá™ÂãïÂåñÂøÉËáüÁñæÁóÖÂÅµÊ∏¨ÁöÑ‰∫∫Â∑•Êô∫ÊÖß (AI) ÊñπÊ≥ïÁµêÂêà‰ΩøÁî®ÊôÇ„ÄÇÂÖàÂâçÂ∑≤ÊúâÁ†îÁ©∂ÊáâÁî®Âü∫ÊñºÊ∑±Â∫¶Â≠∏ÁøíÁöÑ AI ÊñπÊ≥ïÈÄ≤Ë°åÂøÉËáüÁñæÁóÖÂÅµÊ∏¨„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÊ®°ÂûãÂ∞öÊú™Ë¢´Âª£Ê≥õÊé•ÂèóÁÇ∫Ëá®Â∫äË®∫Êñ∑ÁöÑÂèØÈù†ËºîÂä©Â∑•ÂÖ∑ÔºåÈÉ®ÂàÜÂéüÂõ†Âú®ÊñºÂúçÁπûË®±Â§ö AI ÊºîÁÆóÊ≥ïÁöÑÁï∂ÂâçÈªëÁÆ±ÊÑüÁü•„ÄÇÁâπÂà•ÊòØÔºåÊúâÂøÖË¶ÅÊâæÂá∫ÊúâÂä©ÊñºÂÅöÂá∫Ê∫ñÁ¢∫Ë®∫Êñ∑ÁöÑ ECG Ë®äËôüÈóúÈçµÁâπÂæµÔºåÂæûËÄåÂ¢ûÂº∑Ê®°ÂûãÁöÑÂèØËß£ÈáãÊÄß„ÄÇÂú®Êú¨Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëÈñãÁôº‰∫Ü‰∏ÄÁ®ÆË¶ñË¶∫ËΩâÊèõÂô®ÊñπÊ≥ïÔºå‰ª•Ê†πÊìöÂñÆÂ∞éÁ®ã ECG Ë≥áÊñôÊâæÂá∫ÂøÉÊàøÈ°´Âãï„ÄÇÊÆòÂ∑ÆÁ∂≤Ë∑Ø (ResNet) ÊñπÊ≥ï‰πüÂ∑≤ÈñãÁôºÂá∫‰æÜÔºå‰ª•‰æøËàáË¶ñË¶∫ËΩâÊèõÂô®ÊñπÊ≥ïÈÄ≤Ë°åÊØîËºÉ„ÄÇÈÄô‰∫õÊ®°ÂûãÊáâÁî®Êñº Chapman-Shaoxing Ë≥áÊñôÈõÜÔºå‰ª•ÂàÜÈ°ûÂøÉÊàøÈ°´ÂãïÔºå‰ª•ÂèäÂè¶‰∏ÄÁ®ÆÂ∏∏Ë¶ãÁöÑÂøÉÂæã‰∏çÊï¥ÔºåÁ´áÊÄßÂøÉÂãïÈÅéÁ∑©ÔºåÂíåÊ≠£Â∏∏Á´áÊÄßÂøÉÂæãÁöÑÂøÉË∑≥„ÄÇÈÄô‰∫õÊ®°ÂûãËÉΩÂ§†ÊâæÂá∫Ê±∫ÂÆöÊúÄÁµÇÂàÜÈ°ûÁöÑÂøÉË∑≥ÈóúÈçµÂçÄÂüüÔºå‰∏¶Âº∑Ë™ø P Ê≥¢Âíå T Ê≥¢Ôºå‰ª•ÂèäÂøÉË∑≥ÊåÅÁ∫åÊôÇÈñìÂíåË®äËôüÊåØÂπÖÂú®ÂçÄÂàÜÊ≠£Â∏∏Á´áÊÄßÂøÉÂæãËàáÂøÉÊàøÈ°´ÂãïÂíåÁ´áÊÄßÂøÉÂãïÈÅéÁ∑©ÊñπÈù¢ÁöÑÈáçË¶ÅÊÄß„ÄÇ</paragraph>

##### **Illuminate: A novel approach for depression detection with explainable analysis and proactive therapy using prompt engineering**
2402.05127v1 by Aryan Agrawal

This paper introduces a novel paradigm for depression detection and treatment
using advanced Large Language Models (LLMs): Generative Pre-trained Transformer
4 (GPT-4), Llama 2 chat, and Gemini. These LLMs are fine-tuned with specialized
prompts to diagnose, explain, and suggest therapeutic interventions for
depression. A unique few-shot prompting method enhances the models' ability to
analyze and explain depressive symptoms based on the DSM-5 criteria. In the
interaction phase, the models engage in empathetic dialogue management, drawing
from resources like PsychDB and a Cognitive Behavioral Therapy (CBT) Guide,
fostering supportive interactions with individuals experiencing major
depressive disorders. Additionally, the research introduces the Illuminate
Database, enriched with various CBT modules, aiding in personalized therapy
recommendations. The study evaluates LLM performance using metrics such as F1
scores, Precision, Recall, Cosine similarity, and Recall-Oriented Understudy
for Gisting Evaluation (ROUGE) across different test sets, demonstrating their
effectiveness. This comprehensive approach blends cutting-edge AI with
established psychological methods, offering new possibilities in mental health
care and showcasing the potential of LLMs in revolutionizing depression
diagnosis and treatment strategies.

ÊëòË¶ÅÔºöÊú¨Êñá‰ªãÁ¥π‰∫Ü‰∏ÄÁ®Æ‰ΩøÁî®ÂÖàÈÄ≤Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÈÄ≤Ë°åÊÜÇÈ¨±ÁóáÂÅµÊ∏¨ÂíåÊ≤ªÁôÇÁöÑÊñ∞Ê®°ÂºèÔºöÁîüÊàêÂºèÈ†êË®ìÁ∑¥Transformer 4 (GPT-4)„ÄÅLlama 2 ËÅäÂ§©Ê©üÂô®‰∫∫Âíå Gemini„ÄÇÈÄô‰∫õ LLM Á∂ìÈÅéÂæÆË™øÔºåÂÖ∑ÂÇôÂ∞àÊ•≠ÊèêÁ§∫ÔºåÂèØË®∫Êñ∑„ÄÅËß£Èáã‰∏¶Âª∫Ë≠∞ÊÜÇÈ¨±ÁóáÁöÑÊ≤ªÁôÇ‰ªãÂÖ•ÊñπÊ≥ï„ÄÇ‰∏ÄÁ®ÆÁç®ÁâπÁöÑÂ∞ëÊ¨°ÊèêÁ§∫ÊñπÊ≥ïÂ¢ûÂº∑‰∫ÜÊ®°ÂûãÊ†πÊìö DSM-5 Ê®ôÊ∫ñÂàÜÊûêÂíåËß£ÈáãÊÜÇÈ¨±ÁóáÁãÄÁöÑËÉΩÂäõ„ÄÇÂú®‰∫íÂãïÈöéÊÆµÔºåÈÄô‰∫õÊ®°ÂûãÊúÉÂèÉËàáÂêåÁêÜÂøÉÂ∞çË©±ÁÆ°ÁêÜÔºåÂæû PsychDB ÂíåË™çÁü•Ë°åÁÇ∫ÁôÇÊ≥ï (CBT) ÊåáÂçóÁ≠âË≥áÊ∫ê‰∏≠Ê±≤ÂèñÔºå‰øÉÈÄ≤ËàáÁ∂ìÊ≠∑ÈáçÂ∫¶ÊÜÇÈ¨±ÁóáÁöÑ‰∫∫ÂÄëÁöÑÊîØÊåÅÊÄß‰∫íÂãï„ÄÇÊ≠§Â§ñÔºåÈÄôÈ†ÖÁ†îÁ©∂ÈÇÑ‰ªãÁ¥π‰∫Ü Illuminate Ë≥áÊñôÂ∫´ÔºåÂÖ∂‰∏≠ÂåÖÂê´ÂêÑÁ®Æ CBT Ê®°ÁµÑÔºåÊúâÂä©ÊñºÂÄãÊÄßÂåñÊ≤ªÁôÇÂª∫Ë≠∞„ÄÇÈÄôÈ†ÖÁ†îÁ©∂‰ΩøÁî® F1 ÂàÜÊï∏„ÄÅÊ∫ñÁ¢∫Áéá„ÄÅÂè¨ÂõûÁéá„ÄÅÈ§òÂº¶Áõ∏‰ººÂ∫¶ÂíåÈù¢ÂêëÂè¨ÂõûÁéáÁöÑ Gisting Ë©ï‰º∞ÊõøË∫´ (ROUGE) Á≠âÊåáÊ®ôÔºåÂú®‰∏çÂêåÁöÑÊ∏¨Ë©¶ÈõÜ‰∏≠Ë©ï‰º∞ LLM ÁöÑË°®ÁèæÔºåË≠âÊòé‰∫ÜÂÆÉÂÄëÁöÑÊúâÊïàÊÄß„ÄÇÈÄôÁ®ÆÁ∂úÂêàÊñπÊ≥ïÁµêÂêà‰∫ÜÂ∞ñÁ´ØÁöÑ AI ËàáÊó¢ÂÆöÁöÑÂøÉÁêÜÊñπÊ≥ïÔºåÁÇ∫ÂøÉÁêÜ‰øùÂÅ•Êèê‰æõ‰∫ÜÊñ∞ÁöÑÂèØËÉΩÊÄßÔºå‰∏¶Â±ïÁ§∫‰∫Ü LLM Âú®Èù©Êñ∞ÊÜÇÈ¨±ÁóáË®∫Êñ∑ÂíåÊ≤ªÁôÇÁ≠ñÁï•ÊñπÈù¢ÁöÑÊΩõÂäõ„ÄÇ

##### **Information That Matters: Exploring Information Needs of People Affected by Algorithmic Decisions**
2401.13324v4 by Timoth√©e Schmude, Laura Koesten, Torsten M√∂ller, Sebastian Tschiatschek

Explanations of AI systems rarely address the information needs of people
affected by algorithmic decision-making (ADM). This gap between conveyed
information and information that matters to affected stakeholders can impede
understanding and adherence to regulatory frameworks such as the AI Act. To
address this gap, we present the "XAI Novice Question Bank": A catalog of
affected stakeholders' information needs in two ADM use cases (employment
prediction and health monitoring), covering the categories data, system
context, system usage, and system specifications. Information needs were
gathered in an interview study where participants received explanations in
response to their inquiries. Participants further reported their understanding
and decision confidence, showing that while confidence tended to increase after
receiving explanations, participants also met understanding challenges, such as
being unable to tell why their understanding felt incomplete. Explanations
further influenced participants' perceptions of the systems' risks and
benefits, which they confirmed or changed depending on the use case. When risks
were perceived as high, participants expressed particular interest in
explanations about intention, such as why and to what end a system was put in
place. With this work, we aim to support the inclusion of affected stakeholders
into explainability by contributing an overview of information and challenges
relevant to them when deciding on the adoption of ADM systems. We close by
summarizing our findings in a list of six key implications that inform the
design of future explanations for affected stakeholder audiences.

ÊëòË¶ÅÔºö<paragraph>‰∫∫Â∑•Êô∫ÊÖßÁ≥ªÁµ±ÁöÑË™™ÊòéÂæàÂ∞ëËÉΩÊªøË∂≥ÂèóÊºîÁÆóÊ≥ïÊ±∫Á≠ñ (ADM) ÂΩ±ÈüøÁöÑ‰∫∫ÂÄëÁöÑË≥áË®äÈúÄÊ±Ç„ÄÇÂÇ≥ÈÅîÁöÑË≥áË®äËàáÂΩ±ÈüøÂà©ÂÆ≥Èóú‰øÇ‰∫∫ÈáçË¶ÅÁöÑË≥áË®ä‰πãÈñìÁöÑÂ∑ÆË∑ùÔºåÂèØËÉΩÊúÉÈòªÁ§ô‰∫ÜËß£ÂíåÈÅµÂÆàÊ≥ïË¶èÊû∂ÊßãÔºå‰æãÂ¶Ç‰∫∫Â∑•Êô∫ÊÖßÊ≥ïÊ°à„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂ∑ÆË∑ùÔºåÊàëÂÄëÊèêÂá∫‰∫Ü„ÄåXAI ÂàùÂ≠∏ËÄÖÂïèÈ°åÂ∫´„ÄçÔºöÂèóÂΩ±ÈüøÂà©ÂÆ≥Èóú‰øÇ‰∫∫Ë≥áË®äÈúÄÊ±ÇÁöÑÁõÆÈåÑÔºåÊ∂µËìãÂÖ©ÂÄã ADM ‰ΩøÁî®Ê°à‰æãÔºàÂ∞±Ê•≠È†êÊ∏¨ÂíåÂÅ•Â∫∑Áõ£Ê∏¨ÔºâÔºåÊ∂µËìãË≥áÊñô„ÄÅÁ≥ªÁµ±ËÑàÁµ°„ÄÅÁ≥ªÁµ±‰ΩøÁî®ÂíåÁ≥ªÁµ±Ë¶èÊ†ºÈ°ûÂà•„ÄÇË≥áË®äÈúÄÊ±ÇÊòØÈÄèÈÅéË®™Ë´áÁ†îÁ©∂Êî∂ÈõÜÁöÑÔºåÂèÉËàáËÄÖÂú®Ë©¢ÂïèÂæåÊî∂Âà∞Ë™™Êòé„ÄÇÂèÉËàáËÄÖÈÄ≤‰∏ÄÊ≠•ÂõûÂ†±‰ªñÂÄëÁöÑÁêÜËß£ÂíåÊ±∫Á≠ñ‰ø°ÂøÉÔºåÈ°ØÁ§∫ÈõñÁÑ∂Âú®Êî∂Âà∞Ë™™ÊòéÂæå‰ø°ÂøÉÂÇæÂêëÊñºÂ¢ûÂä†Ôºå‰ΩÜÂèÉËàáËÄÖ‰πüÈÅáÂà∞‰∫ÜÁêÜËß£ÊåëÊà∞Ôºå‰æãÂ¶ÇÁÑ°Ê≥ïË™™ÊòéÁÇ∫‰ªÄÈ∫º‰ªñÂÄëÁöÑÁêÜËß£ÊÑüË¶∫‰∏çÂÆåÊï¥„ÄÇË™™ÊòéÈÄ≤‰∏ÄÊ≠•ÂΩ±ÈüøÂèÉËàáËÄÖÂ∞çÁ≥ªÁµ±È¢®Èö™ÂíåÂ•ΩËôïÁöÑÁúãÊ≥ïÔºå‰ªñÂÄëÊúÉÊ†πÊìö‰ΩøÁî®Ê°à‰æãÁ¢∫Ë™çÊàñÊîπËÆäÈÄô‰∫õÁúãÊ≥ï„ÄÇÁï∂È¢®Èö™Ë¢´Ë™çÁÇ∫ÂæàÈ´òÊôÇÔºåÂèÉËàáËÄÖË°®Á§∫ÁâπÂà•ÊúâËààË∂£‰∫ÜËß£ÊÑèÂúñÁöÑË™™ÊòéÔºå‰æãÂ¶ÇÁÇ∫‰ªÄÈ∫º‰ª•ÂèäÁÇ∫‰∫Ü‰ªÄÈ∫ºÁõÆÁöÑËÄåÂª∫Á´ãÁ≥ªÁµ±„ÄÇÈÄèÈÅéÈÄôÈ†ÖÂ∑•‰ΩúÔºåÊàëÂÄëÊó®Âú®ÈÄèÈÅéÂú®Ê±∫Á≠ñÊé°Áî® ADM Á≥ªÁµ±ÊôÇÊèê‰æõÁõ∏ÈóúË≥áË®äÂíåÊåëÊà∞ÁöÑÊ¶ÇË¶ΩÔºå‰æÜÊîØÊè¥Â∞áÂèóÂΩ±ÈüøÁöÑÂà©ÂÆ≥Èóú‰øÇ‰∫∫Á¥çÂÖ•ÂèØËß£ÈáãÊÄß„ÄÇÊàëÂÄëÊúÄÂæåÁ∏ΩÁµêÊàëÂÄëÁöÑÁôºÁèæÔºåÂàóÂá∫ÂÖ≠È†ÖÈóúÈçµÂΩ±ÈüøÔºåÈÄô‰∫õÂΩ±ÈüøÊúÉÂëäÁü•Êú™‰æÜÈáùÂ∞çÂèóÂΩ±ÈüøÂà©ÂÆ≥Èóú‰øÇ‰∫∫ÂèóÁúæË™™ÊòéÁöÑË®≠Ë®à„ÄÇ</paragraph>

##### **Evaluating Large Language Models on the GMAT: Implications for the Future of Business Education**
2401.02985v1 by Vahid Ashrafimoghari, Necdet G√ºrkan, Jordan W. Suchow

The rapid evolution of artificial intelligence (AI), especially in the domain
of Large Language Models (LLMs) and generative AI, has opened new avenues for
application across various fields, yet its role in business education remains
underexplored. This study introduces the first benchmark to assess the
performance of seven major LLMs, OpenAI's models (GPT-3.5 Turbo, GPT-4, and
GPT-4 Turbo), Google's models (PaLM 2, Gemini 1.0 Pro), and Anthropic's models
(Claude 2 and Claude 2.1), on the GMAT, which is a key exam in the admission
process for graduate business programs. Our analysis shows that most LLMs
outperform human candidates, with GPT-4 Turbo not only outperforming the other
models but also surpassing the average scores of graduate students at top
business schools. Through a case study, this research examines GPT-4 Turbo's
ability to explain answers, evaluate responses, identify errors, tailor
instructions, and generate alternative scenarios. The latest LLM versions,
GPT-4 Turbo, Claude 2.1, and Gemini 1.0 Pro, show marked improvements in
reasoning tasks compared to their predecessors, underscoring their potential
for complex problem-solving. While AI's promise in education, assessment, and
tutoring is clear, challenges remain. Our study not only sheds light on LLMs'
academic potential but also emphasizes the need for careful development and
application of AI in education. As AI technology advances, it is imperative to
establish frameworks and protocols for AI interaction, verify the accuracy of
AI-generated content, ensure worldwide access for diverse learners, and create
an educational environment where AI supports human expertise. This research
sets the stage for further exploration into the responsible use of AI to enrich
educational experiences and improve exam preparation and assessment methods.

ÊëòË¶ÅÔºö‰∫∫Â∑•Êô∫ÊÖß (AI) ÁöÑÂø´ÈÄüÊºîÈÄ≤ÔºåÂ∞§ÂÖ∂ÊòØÂú®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂíåÁîüÊàêÂºè AI ÁöÑÈ†òÂüüÔºåÁÇ∫ÂêÑÂÄãÈ†òÂüüÁöÑÊáâÁî®ÈñãÂïü‰∫ÜÊñ∞ÈÄîÂæëÔºå‰ΩÜÂÖ∂Âú®ÂïÜÊ•≠ÊïôËÇ≤‰∏≠ÁöÑËßíËâ≤‰ªçÊú™Ë¢´ÂÖÖÂàÜÊé¢Ë®é„ÄÇÊú¨Á†îÁ©∂È¶ñÊ¨°ÂºïÂÖ•‰∫ÜÂü∫Ê∫ñÔºåÁî®‰ª•Ë©ï‰º∞‰∏ÉÂÄã‰∏ªË¶Å LLM ÁöÑÊïàËÉΩÔºåÂåÖÊã¨ OpenAI ÁöÑÊ®°Âûã (GPT-3.5 Turbo„ÄÅGPT-4 Âíå GPT-4 Turbo)„ÄÅGoogle ÁöÑÊ®°Âûã (PaLM 2„ÄÅGemini 1.0 Pro) Âíå Anthropic ÁöÑÊ®°Âûã (Claude 2 Âíå Claude 2.1)ÔºåÈÄô‰∫õÊ®°ÂûãÂ∞áÁî®ÊñºÁ†îÁ©∂ÁîüÂïÜÊ•≠Ë™≤Á®ãÂÖ•Â≠∏Á®ãÂ∫è‰∏≠ÁöÑÈóúÈçµËÄÉË©¶ GMAT„ÄÇÊàëÂÄëÁöÑÂàÜÊûêÈ°ØÁ§∫ÔºåÂ§ßÂ§öÊï∏ LLM ÁöÑË°®ÁèæÈÉΩÂÑ™Êñº‰∫∫È°ûËÄÉÁîüÔºåÂÖ∂‰∏≠ GPT-4 Turbo ‰∏çÂÉÖÂÑ™ÊñºÂÖ∂‰ªñÊ®°ÂûãÔºåÊõ¥Ë∂ÖË∂ä‰∫ÜÈ†ÇÂ∞ñÂïÜÂ≠∏Èô¢ÁöÑÁ†îÁ©∂ÁîüÂπ≥ÂùáÂàÜÊï∏„ÄÇÈÄèÈÅéÊ°à‰æãÁ†îÁ©∂ÔºåÊú¨Á†îÁ©∂Êé¢Ë®é‰∫Ü GPT-4 Turbo Âú®Ëß£ÈáãÁ≠îÊ°à„ÄÅË©ï‰º∞ÂõûÊáâ„ÄÅËæ®Ë≠òÈåØË™§„ÄÅË™øÊï¥Ë™™ÊòéÂíåÁî¢ÁîüÊõø‰ª£ÊÉÖÂ¢ÉÊñπÈù¢ÁöÑËÉΩÂäõ„ÄÇËàáÂâç‰∏Ä‰ª£ÁâàÊú¨Áõ∏ÊØîÔºåÊúÄÊñ∞ÁöÑ LLM ÁâàÊú¨ GPT-4 Turbo„ÄÅClaude 2.1 Âíå Gemini 1.0 Pro Âú®Êé®ÁêÜ‰ªªÂãôÊñπÈù¢ÊúâÈ°ØËëóÁöÑÈÄ≤Ê≠•ÔºåÂá∏È°Ø‰∫ÜÂÖ∂Âú®Ëß£Ê±∫Ë§áÈõúÂïèÈ°åÊñπÈù¢ÁöÑÊΩõÂäõ„ÄÇÂÑòÁÆ° AI Âú®ÊïôËÇ≤„ÄÅË©ïÈáèÂíåËºîÂ∞éÊñπÈù¢ÁöÑÊâøË´æÂæàÊòéÁ¢∫Ôºå‰ΩÜ‰ªçÊúâÊåëÊà∞Â≠òÂú®„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂‰∏çÂÉÖÈó°Êòé‰∫Ü LLM ÁöÑÂ≠∏Ë°ìÊΩõÂäõÔºå‰πüÂº∑Ë™ø‰∫ÜÂú®ÊïôËÇ≤‰∏≠ÂØ©ÊÖéÈñãÁôºÂíåÊáâÁî® AI ÁöÑÂøÖË¶ÅÊÄß„ÄÇÈö®Ëëó AI ÊäÄË°ìÁöÑÈÄ≤Ê≠•ÔºåÂª∫Á´ã AI ‰∫íÂãïÁöÑÊû∂ÊßãÂíåÂçîÂÆö„ÄÅÈ©óË≠â AI ÁîüÊàêÁöÑÂÖßÂÆπÁöÑÊ∫ñÁ¢∫ÊÄß„ÄÅÁ¢∫‰øùÂÖ®ÁêÉÂêÑÂú∞Â§öÂÖÉÂ≠∏ÁøíËÄÖÁöÑÂ≠òÂèñÊ¨äÔºå‰ª•ÂèäÂâµÈÄ†‰∏ÄÂÄã AI ÊîØÊåÅ‰∫∫È°ûÂ∞àÊ•≠Áü•Ë≠òÁöÑÊïôËÇ≤Áí∞Â¢ÉËá≥ÈóúÈáçË¶Å„ÄÇÊú¨Á†îÁ©∂ÁÇ∫ÈÄ≤‰∏ÄÊ≠•Êé¢Á¥¢Ë≤†Ë≤¨‰ªªÂú∞‰ΩøÁî® AI ‰æÜË±êÂØåÊïôËÇ≤È´îÈ©ó‰∏¶ÊîπÂñÑËÄÉË©¶Ê∫ñÂÇôÂíåË©ïÈáèÊñπÊ≥ïÂ•†ÂÆö‰∫ÜÂü∫Á§é„ÄÇ

##### **XAI for In-hospital Mortality Prediction via Multimodal ICU Data**
2312.17624v1 by Xingqiao Li, Jindong Gu, Zhiyong Wang, Yancheng Yuan, Bo Du, Fengxiang He

Predicting in-hospital mortality for intensive care unit (ICU) patients is
key to final clinical outcomes. AI has shown advantaged accuracy but suffers
from the lack of explainability. To address this issue, this paper proposes an
eXplainable Multimodal Mortality Predictor (X-MMP) approaching an efficient,
explainable AI solution for predicting in-hospital mortality via multimodal ICU
data. We employ multimodal learning in our framework, which can receive
heterogeneous inputs from clinical data and make decisions. Furthermore, we
introduce an explainable method, namely Layer-Wise Propagation to Transformer,
as a proper extension of the LRP method to Transformers, producing explanations
over multimodal inputs and revealing the salient features attributed to
prediction. Moreover, the contribution of each modality to clinical outcomes
can be visualized, assisting clinicians in understanding the reasoning behind
decision-making. We construct a multimodal dataset based on MIMIC-III and
MIMIC-III Waveform Database Matched Subset. Comprehensive experiments on
benchmark datasets demonstrate that our proposed framework can achieve
reasonable interpretation with competitive prediction accuracy. In particular,
our framework can be easily transferred to other clinical tasks, which
facilitates the discovery of crucial factors in healthcare research.

ÊëòË¶ÅÔºöÈ†êÊ∏¨Âä†Ë≠∑ÁóÖÊàø (ICU) ÁóÖÊÇ£ÁöÑÈô¢ÂÖßÊ≠ª‰∫°ÁéáÊòØÊúÄÁµÇËá®Â∫äÁµêÊûúÁöÑÈóúÈçµ„ÄÇAI Â∑≤Â±ïÁèæÂá∫ÂÑ™Áï∞ÁöÑÊ∫ñÁ¢∫Â∫¶Ôºå‰ΩÜÂçªÁº∫‰πèÂèØËß£ÈáãÊÄß„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂèØËß£ÈáãÁöÑÂ§öÊ®°ÂºèÊ≠ª‰∫°ÁéáÈ†êÊ∏¨Âô® (X-MMP)ÔºåÊé°Áî®ÊúâÊïà‰∏îÂèØËß£ÈáãÁöÑ AI ÊñπÂºèÔºåËóâÁî±Â§öÊ®°Âºè ICU Ë≥áÊñô‰æÜÈ†êÊ∏¨Èô¢ÂÖßÊ≠ª‰∫°Áéá„ÄÇÊàëÂÄëÂú®Êû∂Êßã‰∏≠Êé°Áî®Â§öÊ®°ÂºèÂ≠∏ÁøíÔºåÂèØ‰ª•Êé•Êî∂‰æÜËá™Ëá®Â∫äË≥áÊñôÁöÑÁï∞Ë≥™Ëº∏ÂÖ•‰∏¶ÂÅöÂá∫Ê±∫Á≠ñ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÂèØËß£ÈáãÁöÑÊñπÊ≥ïÔºå‰πüÂ∞±ÊòØÂàÜÂ±§ÂÇ≥Êí≠Ëá≥ TransformerÔºå‰ΩúÁÇ∫ LRP ÊñπÊ≥ïÈÅ©Áï∂Âú∞Âª∂‰º∏Ëá≥ TransformerÔºåÂ∞çÂ§öÊ®°ÂºèËº∏ÂÖ•Áî¢ÁîüËß£ÈáãÔºå‰∏¶Êè≠Èú≤Ê≠∏Âõ†ÊñºÈ†êÊ∏¨ÁöÑÈ°ØËëóÁâπÂæµ„ÄÇÊ≠§Â§ñÔºåÊØèÂÄãÊ®°ÂºèÂ∞çËá®Â∫äÁµêÊûúÁöÑË≤¢ÁçªÂèØ‰ª•Ë¶ñË¶∫ÂåñÔºåÂçîÂä©Ëá®Â∫äÈÜ´Â∏´‰∫ÜËß£Ê±∫Á≠ñËÉåÂæåÁöÑÁêÜÁî±„ÄÇÊàëÂÄëÊ†πÊìö MIMIC-III Âíå MIMIC-III Ê≥¢ÂΩ¢Ë≥áÊñôÂ∫´ÊØîÂ∞çÂ≠êÈõÜÂª∫Êßã‰∫Ü‰∏ÄÂÄãÂ§öÊ®°ÂºèË≥áÊñôÈõÜ„ÄÇÂú®Âü∫Ê∫ñË≥áÊñôÈõÜ‰∏äÁöÑÂÖ®Èù¢ÂØ¶È©óË≠âÊòéÔºåÊàëÂÄëÊèêÂá∫ÁöÑÊû∂ÊßãÂèØ‰ª•ÈÅîÊàêÂêàÁêÜÁöÑË©ÆÈáãÔºå‰∏¶ÂÖ∑ÂÇôÁ´∂Áà≠ÂäõÁöÑÈ†êÊ∏¨Ê∫ñÁ¢∫Â∫¶„ÄÇÁâπÂà•ÊòØÔºåÊàëÂÄëÁöÑÊû∂ÊßãÂèØ‰ª•ËºïÈ¨ÜÂú∞ËΩâÁßªÂà∞ÂÖ∂‰ªñËá®Â∫ä‰ªªÂãôÔºåÈÄôÊúâÂä©ÊñºÂú®ÈÜ´ÁôÇ‰øùÂÅ•Á†îÁ©∂‰∏≠ÁôºÁèæÈóúÈçµÂõ†Á¥†„ÄÇ

##### **Joining Forces for Pathology Diagnostics with AI Assistance: The EMPAIA Initiative**
2401.09450v2 by Norman Zerbe, Lars Ole Schwen, Christian Gei√üler, Katja Wiesemann, Tom Bisson, Peter Boor, Rita Carvalho, Michael Franz, Christoph Jansen, Tim-Rasmus Kiehl, Bj√∂rn Lindequist, Nora Charlotte Pohlan, Sarah Schmell, Klaus Strohmenger, Falk Zakrzewski, Markus Plass, Michael Takla, Tobias K√ºster, Andr√© Homeyer, Peter Hufnagl

Over the past decade, artificial intelligence (AI) methods in pathology have
advanced substantially. However, integration into routine clinical practice has
been slow due to numerous challenges, including technical and regulatory
hurdles in translating research results into clinical diagnostic products and
the lack of standardized interfaces. The open and vendor-neutral EMPAIA
initiative addresses these challenges. Here, we provide an overview of EMPAIA's
achievements and lessons learned. EMPAIA integrates various stakeholders of the
pathology AI ecosystem, i.e., pathologists, computer scientists, and industry.
In close collaboration, we developed technical interoperability standards,
recommendations for AI testing and product development, and explainability
methods. We implemented the modular and open-source EMPAIA platform and
successfully integrated 14 AI-based image analysis apps from 8 different
vendors, demonstrating how different apps can use a single standardized
interface. We prioritized requirements and evaluated the use of AI in real
clinical settings with 14 different pathology laboratories in Europe and Asia.
In addition to technical developments, we created a forum for all stakeholders
to share information and experiences on digital pathology and AI. Commercial,
clinical, and academic stakeholders can now adopt EMPAIA's common open-source
interfaces, providing a unique opportunity for large-scale standardization and
streamlining of processes. Further efforts are needed to effectively and
broadly establish AI assistance in routine laboratory use. To this end, a
sustainable infrastructure, the non-profit association EMPAIA International,
has been established to continue standardization and support broad
implementation and advocacy for an AI-assisted digital pathology future.

ÊëòË¶ÅÔºöÂú®ÈÅéÂéªÁöÑÂçÅÂπ¥‰∏≠ÔºåÁóÖÁêÜÂ≠∏‰∏≠ÁöÑ‰∫∫Â∑•Êô∫ÊÖß (AI) ÊñπÊ≥ïÂ∑≤Â§ßÂπÖÈÄ≤Ê≠•„ÄÇÁÑ∂ËÄåÔºåÁî±ÊñºË®±Â§öÊåëÊà∞ÔºåÂåÖÊã¨Â∞áÁ†îÁ©∂ÁµêÊûúËΩâÂåñÁÇ∫Ëá®Â∫äË®∫Êñ∑Áî¢ÂìÅÂú®ÊäÄË°ìÂíåÊ≥ïË¶èÊñπÈù¢ÁöÑÈöúÁ§ôÔºå‰ª•ÂèäÁº∫‰πèÊ®ôÊ∫ñÂåñ‰ªãÈù¢ÔºåÂ∞éËá¥Êï¥ÂêàÂà∞Â∏∏Ë¶èËá®Â∫äÂØ¶Âãô‰∏≠ÈÄ≤Â±ïÁ∑©ÊÖ¢„ÄÇÈñãÊîæ‰∏îËàá‰æõÊáâÂïÜÁÑ°ÈóúÁöÑ EMPAIA Ë®àÁï´ÊáâÂ∞ç‰∫ÜÈÄô‰∫õÊåëÊà∞„ÄÇÂú®Ê≠§ÔºåÊàëÂÄëÊèê‰æõ EMPAIA ÁöÑÊàêÂ∞±ÂíåÁ∂ìÈ©óÊïôË®ìÁöÑÊ¶ÇËø∞„ÄÇEMPAIA Êï¥Âêà‰∫ÜÁóÖÁêÜÂ≠∏ AI ÁîüÊÖãÁ≥ªÁµ±ÁöÑÂêÑÂÄãÂà©ÂÆ≥Èóú‰øÇ‰∫∫ÔºåÂç≥ÁóÖÁêÜÂ≠∏ÂÆ∂„ÄÅÈõªËÖ¶ÁßëÂ≠∏ÂÆ∂ÂíåÁî¢Ê•≠„ÄÇÂú®ÂØÜÂàáÂêà‰Ωú‰∏ãÔºåÊàëÂÄëÂà∂ÂÆö‰∫ÜÊäÄË°ì‰∫íÈÄöÊÄßÊ®ôÊ∫ñ„ÄÅAI Ê∏¨Ë©¶ÂíåÁî¢ÂìÅÈñãÁôºÂª∫Ë≠∞Ôºå‰ª•ÂèäÂèØËß£ÈáãÊÄßÊñπÊ≥ï„ÄÇÊàëÂÄëÂØ¶‰Ωú‰∫ÜÊ®°ÁµÑÂåñ‰∏îÈñãÊîæÂéüÂßãÁ¢ºÁöÑ EMPAIA Âπ≥Ëá∫Ôºå‰∏¶ÊàêÂäüÊï¥Âêà‰∫Ü‰æÜËá™ 8 ÂÄã‰∏çÂêå‰æõÊáâÂïÜÁöÑ 14 ÂÄãÂü∫Êñº AI ÁöÑÂΩ±ÂÉèÂàÜÊûêÊáâÁî®Á®ãÂºèÔºåÂ±ïÁ§∫‰∫Ü‰∏çÂêåÁöÑÊáâÁî®Á®ãÂºèÂ¶Ç‰Ωï‰ΩøÁî®ÂñÆ‰∏ÄÁöÑÊ®ôÊ∫ñÂåñ‰ªãÈù¢„ÄÇÊàëÂÄëÂÑ™ÂÖàËÄÉÊÖÆÈúÄÊ±ÇÔºå‰∏¶Ë©ï‰º∞‰∫Ü AI Âú®Ê≠êÊ¥≤Âíå‰∫ûÊ¥≤ÁöÑ 14 ÂÄã‰∏çÂêåÁóÖÁêÜÂØ¶È©óÂÆ§‰∏≠ÁöÑÂØ¶ÈöõËá®Â∫äÊáâÁî®„ÄÇÈô§‰∫ÜÊäÄË°ìÈñãÁôºÂ§ñÔºåÊàëÂÄëÈÇÑÁÇ∫ÊâÄÊúâÂà©ÂÆ≥Èóú‰øÇ‰∫∫Âª∫Á´ã‰∫Ü‰∏ÄÂÄãË´ñÂ£áÔºå‰ª•ÂàÜ‰∫´Êï∏‰ΩçÁóÖÁêÜÂ≠∏Âíå AI ÁöÑË≥áË®äÂíåÁ∂ìÈ©ó„ÄÇÂïÜÊ•≠„ÄÅËá®Â∫äÂíåÂ≠∏Ë°ìÂà©ÂÆ≥Èóú‰øÇ‰∫∫ÁèæÂú®ÂèØ‰ª•Êé°Áî® EMPAIA ÁöÑÂ∏∏Ë¶ãÈñãÊîæÂéüÂßãÁ¢º‰ªãÈù¢ÔºåÈÄôÁÇ∫Â§ßË¶èÊ®°Ê®ôÊ∫ñÂåñÂíåÁ∞°ÂåñÊµÅÁ®ãÊèê‰æõ‰∫ÜÁç®ÁâπÁöÑÊ©üÊúÉ„ÄÇÈúÄË¶ÅÈÄ≤‰∏ÄÊ≠•ÁöÑÂä™ÂäõÊâçËÉΩÊúâÊïà‰∏îÂª£Ê≥õÂú∞Âª∫Á´ã‰æãË°åÂØ¶È©óÂÆ§‰ΩøÁî®‰∏≠ÁöÑ AI ËºîÂä©„ÄÇÁÇ∫Ê≠§ÔºåÂ∑≤ÊàêÁ´ãÈùûÁáüÂà©ÂçîÊúÉ EMPAIA InternationalÔºå‰ª•‰ΩúÁÇ∫Ê∞∏Á∫åÂü∫Á§éÊû∂ÊßãÔºåÁπºÁ∫åÈÄ≤Ë°åÊ®ôÊ∫ñÂåñÔºå‰∏¶ÊîØÊè¥Âª£Ê≥õÂØ¶‰ΩúÂíåÂÄ°Â∞é AI ËºîÂä©Êï∏‰ΩçÁóÖÁêÜÂ≠∏ÁöÑÊú™‰æÜ„ÄÇ

##### **Robust Stochastic Graph Generator for Counterfactual Explanations**
2312.11747v2 by Mario Alfonso Prado-Romero, Bardh Prenkaj, Giovanni Stilo

Counterfactual Explanation (CE) techniques have garnered attention as a means
to provide insights to the users engaging with AI systems. While extensively
researched in domains such as medical imaging and autonomous vehicles, Graph
Counterfactual Explanation (GCE) methods have been comparatively
under-explored. GCEs generate a new graph similar to the original one, with a
different outcome grounded on the underlying predictive model. Among these GCE
techniques, those rooted in generative mechanisms have received relatively
limited investigation despite demonstrating impressive accomplishments in other
domains, such as artistic styles and natural language modelling. The preference
for generative explainers stems from their capacity to generate counterfactual
instances during inference, leveraging autonomously acquired perturbations of
the input graph. Motivated by the rationales above, our study introduces
RSGG-CE, a novel Robust Stochastic Graph Generator for Counterfactual
Explanations able to produce counterfactual examples from the learned latent
space considering a partially ordered generation sequence. Furthermore, we
undertake quantitative and qualitative analyses to compare RSGG-CE's
performance against SoA generative explainers, highlighting its increased
ability to engendering plausible counterfactual candidates.

ÊëòË¶ÅÔºöÂèç‰∫ãÂØ¶Ëß£Èáã (CE) ÊäÄË°ìÂ∑≤ÂºïËµ∑ÈóúÊ≥®Ôºå‰ΩúÁÇ∫‰∏ÄÁ®ÆÁÇ∫Ëàá AI Á≥ªÁµ±‰∫íÂãïÁöÑ‰ΩøÁî®ËÄÖÊèê‰æõË¶ãËß£ÁöÑÊñπÊ≥ï„ÄÇÈõñÁÑ∂Âú®ÈÜ´Â≠∏ÂΩ±ÂÉèÂíåËá™ÂãïÈßïÈßõÊ±ΩËªäÁ≠âÈ†òÂüüÂª£Ê≥õÁ†îÁ©∂ÔºåÂúñÂΩ¢Âèç‰∫ãÂØ¶Ëß£Èáã (GCE) ÊñπÊ≥ïÁõ∏Â∞çËºÉÂ∞ëË¢´Êé¢Á¥¢„ÄÇGCE ÊúÉÁî¢Áîü‰∏ÄÂÄãÈ°û‰ººÊñºÂéüÂßãÂúñÂΩ¢ÁöÑÊñ∞ÂúñÂΩ¢Ôºå‰∏¶Ê†πÊìöÂü∫Á§éÈ†êÊ∏¨Ê®°ÂûãÁî¢Áîü‰∏çÂêåÁöÑÁµêÊûú„ÄÇÂú®ÈÄô‰∫õ GCE ÊäÄË°ì‰∏≠ÔºåÂÑòÁÆ°Âú®ÂÖ∂‰ªñÈ†òÂüüÔºà‰æãÂ¶ÇËóùË°ìÈ¢®Ê†ºÂíåËá™ÁÑ∂Ë™ûË®ÄÂª∫Ê®°Ôºâ‰∏≠Â±ïÁèæÂá∫‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑÊàêÂ∞±Ôºå‰ΩÜÊ§çÂü∫ÊñºÁîüÊàêÊ©üÂà∂ÁöÑÊäÄË°ìÁç≤ÂæóÁöÑÈóúÊ≥®Áõ∏Â∞çÊúâÈôê„ÄÇÂ∞çÁîüÊàêÂºèËß£ÈáãÂô®ÁöÑÂÅèÂ•ΩÊ∫êÊñºÂÆÉÂÄëÂú®Êé®ÁêÜÊúüÈñìÁî¢ÁîüÂèç‰∫ãÂØ¶ÂØ¶‰æãÁöÑËÉΩÂäõÔºåÂà©Áî®Ëº∏ÂÖ•ÂúñÂΩ¢ÁöÑËá™‰∏ªÁç≤ÂèñÊìæÂãï„ÄÇÂü∫Êñº‰∏äËø∞ÁêÜÁî±ÔºåÊàëÂÄëÁöÑÁ†îÁ©∂ÂºïÂÖ•‰∫Ü RSGG-CEÔºå‰∏ÄÁ®ÆÁî®ÊñºÂèç‰∫ãÂØ¶Ëß£ÈáãÁöÑÊñ∞ÂûãÁ©©ÂÅ•Èö®Ê©üÂúñÂΩ¢ÁîüÊàêÂô®ÔºåËÉΩÂ§†ÂæûÂ≠∏ÁøíÂà∞ÁöÑÊΩõÂú®Á©∫Èñì‰∏≠Áî¢ÁîüÂèç‰∫ãÂØ¶ÁØÑ‰æãÔºåËÄÉÊÖÆÈÉ®ÂàÜÊúâÂ∫èÁöÑÁîüÊàêÂ∫èÂàó„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÈÄ≤Ë°åÂÆöÈáèÂíåÂÆöÊÄßÂàÜÊûêÔºå‰ª•ÊØîËºÉ RSGG-CE ÁöÑÊïàËÉΩËàá SoA ÁîüÊàêÂºèËß£ÈáãÂô®ÔºåÂº∑Ë™øÂÖ∂Â¢ûÂº∑‰∫ÜÁî¢ÁîüÂêàÁêÜËß£ÈáãÂÄôÈÅ∏ÁöÑËÉΩÂäõ„ÄÇ

##### **Evaluating the Utility of Model Explanations for Model Development**
2312.06032v1 by Shawn Im, Jacob Andreas, Yilun Zhou

One of the motivations for explainable AI is to allow humans to make better
and more informed decisions regarding the use and deployment of AI models. But
careful evaluations are needed to assess whether this expectation has been
fulfilled. Current evaluations mainly focus on algorithmic properties of
explanations, and those that involve human subjects often employ subjective
questions to test human's perception of explanation usefulness, without being
grounded in objective metrics and measurements. In this work, we evaluate
whether explanations can improve human decision-making in practical scenarios
of machine learning model development. We conduct a mixed-methods user study
involving image data to evaluate saliency maps generated by SmoothGrad,
GradCAM, and an oracle explanation on two tasks: model selection and
counterfactual simulation. To our surprise, we did not find evidence of
significant improvement on these tasks when users were provided with any of the
saliency maps, even the synthetic oracle explanation designed to be simple to
understand and highly indicative of the answer. Nonetheless, explanations did
help users more accurately describe the models. These findings suggest caution
regarding the usefulness and potential for misunderstanding in saliency-based
explanations.

ÊëòË¶ÅÔºöÂèØËß£Èáã AI ÁöÑÂãïÊ©ü‰πã‰∏ÄÊòØËÆì‰∫∫ÂÄëÂú®‰ΩøÁî®ÂíåÈÉ®ÁΩ≤ AI Ê®°ÂûãÊôÇÂÅöÂá∫Êõ¥Â•Ω„ÄÅÊõ¥ÊòéÊô∫ÁöÑÊ±∫Á≠ñ„ÄÇ‰ΩÜÈúÄË¶Å‰ªîÁ¥∞Ë©ï‰º∞‰ª•Ë©ï‰º∞ÊòØÂê¶Â∑≤ÈÅîÂà∞Ê≠§È†êÊúü„ÄÇÁõÆÂâçÁöÑË©ï‰º∞‰∏ªË¶ÅÈõÜ‰∏≠Âú®Ëß£ÈáãÁöÑÊºîÁÆóÊ≥ïÁâπÊÄßÔºåËÄåÊ∂âÂèä‰∫∫È°ûÂèóË©¶ËÄÖÁöÑË©ï‰º∞ÈÄöÂ∏∏Êé°Áî®‰∏ªËßÄÂïèÈ°å‰æÜÊ∏¨Ë©¶‰∫∫È°ûÂ∞çËß£ÈáãÊúâÁî®ÊÄßÁöÑÁúãÊ≥ïÔºåËÄåÊ≤íÊúâÂü∫ÊñºÂÆ¢ËßÄÊåáÊ®ôÂíåÊ∏¨Èáè„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëË©ï‰º∞Ëß£ÈáãÊòØÂê¶ÂèØ‰ª•Âú®Ê©üÂô®Â≠∏ÁøíÊ®°ÂûãÈñãÁôºÁöÑÂØ¶ÈöõÂ†¥ÊôØ‰∏≠ÊîπÂñÑ‰∫∫È°ûÊ±∫Á≠ñÂà∂ÂÆö„ÄÇÊàëÂÄëÈÄ≤Ë°å‰∫Ü‰∏ÄÈ†ÖÊ∂âÂèäÂΩ±ÂÉèË≥áÊñôÁöÑÊ∑∑ÂêàÊñπÊ≥ï‰ΩøÁî®ËÄÖÁ†îÁ©∂Ôºå‰ª•Ë©ï‰º∞ SmoothGrad„ÄÅGradCAM ÂíåÈ†êË®ÄËß£ÈáãÂú®ÂÖ©ÂÄã‰ªªÂãô‰∏≠Áî¢ÁîüÁöÑÈ°ØËëóÊÄßÂúñÔºöÊ®°ÂûãÈÅ∏ÊìáÂíåÂèç‰∫ãÂØ¶Ê®°Êì¨„ÄÇ‰ª§‰∫∫È©öË®ùÁöÑÊòØÔºåÊàëÂÄëÊ≤íÊúâÁôºÁèæ‰ªª‰ΩïÈ°ØËëóÊÄßÂúñÔºàÂç≥‰ΩøÊòØË®≠Ë®àÁÇ∫ÊòìÊñºÁêÜËß£‰∏îÈ´òÂ∫¶ÊåáÁ§∫Á≠îÊ°àÁöÑÂêàÊàêÈ†êË®ÄËß£ÈáãÔºâËÉΩËÆì‰ΩøÁî®ËÄÖÂú®ÈÄô‰∫õ‰ªªÂãô‰∏äÈ°ØËëóÊîπÂñÑÁöÑË≠âÊìö„ÄÇÂÑòÁÆ°Â¶ÇÊ≠§ÔºåËß£ÈáãÁ¢∫ÂØ¶ÊúâÂä©Êñº‰ΩøÁî®ËÄÖÊõ¥Ê∫ñÁ¢∫Âú∞ÊèèËø∞Ê®°Âûã„ÄÇÈÄô‰∫õÁôºÁèæÊèêÁ§∫ÊàëÂÄëË¶ÅÂ∞çÂü∫ÊñºÈ°ØËëóÊÄßÁöÑËß£Èáã‰∏≠ÂèØËÉΩÂ≠òÂú®Ë™§Ëß£ÁöÑÊúâÁî®ÊÄß‰øùÊåÅË¨πÊÖé„ÄÇ

##### **Building Trustworthy NeuroSymbolic AI Systems: Consistency, Reliability, Explainability, and Safety**
2312.06798v1 by Manas Gaur, Amit Sheth

Explainability and Safety engender Trust. These require a model to exhibit
consistency and reliability. To achieve these, it is necessary to use and
analyze data and knowledge with statistical and symbolic AI methods relevant to
the AI application - neither alone will do. Consequently, we argue and seek to
demonstrate that the NeuroSymbolic AI approach is better suited for making AI a
trusted AI system. We present the CREST framework that shows how Consistency,
Reliability, user-level Explainability, and Safety are built on NeuroSymbolic
methods that use data and knowledge to support requirements for critical
applications such as health and well-being. This article focuses on Large
Language Models (LLMs) as the chosen AI system within the CREST framework. LLMs
have garnered substantial attention from researchers due to their versatility
in handling a broad array of natural language processing (NLP) scenarios. For
example, ChatGPT and Google's MedPaLM have emerged as highly promising
platforms for providing information in general and health-related queries,
respectively. Nevertheless, these models remain black boxes despite
incorporating human feedback and instruction-guided tuning. For instance,
ChatGPT can generate unsafe responses despite instituting safety guardrails.
CREST presents a plausible approach harnessing procedural and graph-based
knowledge within a NeuroSymbolic framework to shed light on the challenges
associated with LLMs.

ÊëòË¶ÅÔºöÂèØËß£ÈáãÊÄßÂíåÂÆâÂÖ®ÊÄßÂª∫Á´ã‰ø°‰ªª„ÄÇÈÄô‰∫õÈúÄË¶Å‰∏ÄÂÄãÊ®°Âûã‰æÜÂ±ïÁ§∫‰∏ÄËá¥ÊÄßÂíåÂèØÈù†ÊÄß„ÄÇÁÇ∫‰∫ÜÂØ¶ÁèæÈÄô‰∫õÔºåÊúâÂøÖË¶Å‰ΩøÁî®ÂíåÂàÜÊûêÊï∏ÊìöÂíåÁü•Ë≠òÔºå‰∏¶‰ΩøÁî®Ëàá AI ÊáâÁî®Áõ∏ÈóúÁöÑÁµ±Ë®àÂíåÁ¨¶Ëôü AI ÊñπÊ≥ï - ÂñÆÁç®‰ΩøÁî®‰ªª‰Ωï‰∏ÄÁ®ÆÊñπÊ≥ïÈÉΩ‰∏çÊúÉÂ•èÊïà„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄë‰∏ªÂºµ‰∏¶Ë©¶ÂúñË≠âÊòé NeuroSymbolic AI ÊñπÊ≥ïÊõ¥ÈÅ©ÂêàÊñº‰Ωø AI ÊàêÁÇ∫Âèó‰ø°‰ªªÁöÑ AI Á≥ªÁµ±„ÄÇÊàëÂÄëÊèêÂá∫‰∫Ü CREST Ê°ÜÊû∂ÔºåÂ±ïÁ§∫‰∫Ü‰∏ÄËá¥ÊÄß„ÄÅÂèØÈù†ÊÄß„ÄÅ‰ΩøÁî®ËÄÖÂ±§Á¥öÁöÑÂèØËß£ÈáãÊÄßÂíåÂÆâÂÖ®ÊÄßÊòØÂ¶Ç‰ΩïÂª∫Á´ãÂú® NeuroSymbolic ÊñπÊ≥ï‰∏äÁöÑÔºåË©≤ÊñπÊ≥ï‰ΩøÁî®Êï∏ÊìöÂíåÁü•Ë≠ò‰æÜÊîØÊåÅÈóúÈçµÊáâÁî®Ôºà‰æãÂ¶ÇÂÅ•Â∫∑ÂíåÁ¶èÁ•âÔºâÁöÑË¶ÅÊ±Ç„ÄÇÊú¨ÊñáÈáçÈªûÈóúÊ≥®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM)ÔºåÂõ†ÁÇ∫ÂÆÉÊòØ CREST Ê°ÜÊû∂‰∏≠ÈÅ∏ÊìáÁöÑ AI Á≥ªÁµ±„ÄÇLLM Âõ†ÂÖ∂Âú®ËôïÁêÜÂª£Ê≥õÁöÑËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ (NLP) Â†¥ÊôØÊñπÈù¢ÁöÑÂ§öÂäüËÉΩÊÄßËÄåÂÇôÂèóÁ†îÁ©∂‰∫∫Âì°ÁöÑÈóúÊ≥®„ÄÇ‰æãÂ¶ÇÔºåChatGPT Âíå Google ÁöÑ MedPaLM Â∑≤ÊàêÁÇ∫Êèê‰æõ‰∏ÄËà¨ÂíåÂÅ•Â∫∑Áõ∏ÈóúÊü•Ë©¢‰ø°ÊÅØÁöÑÊ•µÊúâÂ∏åÊúõÁöÑÂπ≥Âè∞„ÄÇÂÑòÁÆ°Â¶ÇÊ≠§ÔºåÈÄô‰∫õÊ®°Âûã‰ªçÁÑ∂ÊòØÈªëÁõíÂ≠êÔºåÂÑòÁÆ°Á¥çÂÖ•‰∫Ü‰∫∫È°ûÂèçÈ•ãÂíåÊåá‰ª§ÂºïÂ∞éÁöÑË™øÊï¥„ÄÇ‰æãÂ¶ÇÔºåÂÑòÁÆ°Âà∂ÂÆö‰∫ÜÂÆâÂÖ®Èò≤Ë≠∑Êé™ÊñΩÔºåChatGPT ‰ªçÂèØËÉΩÁî¢Áîü‰∏çÂÆâÂÖ®ÁöÑÂõûÊáâ„ÄÇCREST ÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂêàÁêÜÁöÑÊñπÊ≥ïÔºåÂú® NeuroSymbolic Ê°ÜÊû∂‰∏≠Âà©Áî®Á®ãÂ∫èÂíåÂü∫ÊñºÂúñË°®ÁöÑÁü•Ë≠òÔºå‰ª•Èó°ÊòéËàá LLM Áõ∏ÈóúÁöÑÊåëÊà∞„ÄÇ

##### **Deployment of a Robust and Explainable Mortality Prediction Model: The COVID-19 Pandemic and Beyond**
2311.17133v1 by Jacob R. Epifano, Stephen Glass, Ravi P. Ramachandran, Sharad Patel, Aaron J. Masino, Ghulam Rasool

This study investigated the performance, explainability, and robustness of
deployed artificial intelligence (AI) models in predicting mortality during the
COVID-19 pandemic and beyond. The first study of its kind, we found that
Bayesian Neural Networks (BNNs) and intelligent training techniques allowed our
models to maintain performance amidst significant data shifts. Our results
emphasize the importance of developing robust AI models capable of matching or
surpassing clinician predictions, even under challenging conditions. Our
exploration of model explainability revealed that stochastic models generate
more diverse and personalized explanations thereby highlighting the need for AI
models that provide detailed and individualized insights in real-world clinical
settings. Furthermore, we underscored the importance of quantifying uncertainty
in AI models which enables clinicians to make better-informed decisions based
on reliable predictions. Our study advocates for prioritizing implementation
science in AI research for healthcare and ensuring that AI solutions are
practical, beneficial, and sustainable in real-world clinical environments. By
addressing unique challenges and complexities in healthcare settings,
researchers can develop AI models that effectively improve clinical practice
and patient outcomes.

ÊëòË¶ÅÔºöÊú¨Á†îÁ©∂Ë∞ÉÊü•‰∫ÜÂú® COVID-19 Áñ´ÊÉÖÊúüÈó¥Âèä‰ª•ÂêéÈ¢ÑÊµãÊ≠ª‰∫°ÁéáÊó∂ÔºåÂ∑≤ÈÉ®ÁΩ≤‰∫∫Â∑•Êô∫ËÉΩ (AI) Ê®°ÂûãÁöÑÊÄßËÉΩ„ÄÅÂèØËß£ÈáäÊÄßÂíåÁ®≥ÂÅ•ÊÄß„ÄÇ‰Ωú‰∏∫ÂêåÁ±ªÁ†îÁ©∂‰∏≠ÁöÑÈ¶ñ‰æãÔºåÊàë‰ª¨ÂèëÁé∞Ë¥ùÂè∂ÊñØÁ•ûÁªèÁΩëÁªú (BNN) ÂíåÊô∫ËÉΩËÆ≠ÁªÉÊäÄÊúØËÆ©Êàë‰ª¨ÁöÑÊ®°ÂûãÂú®Êï∞ÊçÆÂèëÁîüÈáçÂ§ßÂèòÂåñÊó∂‰ªçËÉΩ‰øùÊåÅÊÄßËÉΩ„ÄÇÊàë‰ª¨ÁöÑÁªìÊûúÂº∫Ë∞É‰∫ÜÂºÄÂèëÁ®≥ÂÅ•ÁöÑ AI Ê®°ÂûãÁöÑÈáçË¶ÅÊÄßÔºåÂç≥‰ΩøÂú®ÂÖ∑ÊúâÊåëÊàòÊÄßÁöÑÊù°‰ª∂‰∏ãÔºåËøô‰∫õÊ®°Âûã‰πüËÉΩÂåπÈÖçÊàñË∂ÖË∂ä‰∏¥Â∫äÂåªÁîüÁöÑÈ¢ÑÊµã„ÄÇÊàë‰ª¨ÂØπÊ®°ÂûãÂèØËß£ÈáäÊÄßÁöÑÊé¢Á¥¢Ë°®ÊòéÔºåÈöèÊú∫Ê®°Âûã‰ºö‰∫ßÁîüÊõ¥Â§öÊ†∑Âåñ‰∏î‰∏™ÊÄßÂåñÁöÑËß£ÈáäÔºå‰ªéËÄåÁ™ÅÂá∫‰∫ÜÂú®Áé∞ÂÆû‰∏ñÁïåÁöÑ‰∏¥Â∫äÁéØÂ¢É‰∏≠Êèê‰æõËØ¶ÁªÜ‰∏î‰∏™ÊÄßÂåñËßÅËß£ÁöÑ AI Ê®°ÂûãÁöÑÂøÖË¶ÅÊÄß„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨Âº∫Ë∞É‰∫ÜÈáèÂåñ AI Ê®°Âûã‰∏≠‰∏çÁ°ÆÂÆöÊÄßÁöÑÈáçË¶ÅÊÄßÔºåËøô‰Ωø‰∏¥Â∫äÂåªÁîüËÉΩÂ§üÊ†πÊçÆÂèØÈù†ÁöÑÈ¢ÑÊµãÂÅöÂá∫Êõ¥ÊòéÊô∫ÁöÑÂÜ≥Á≠ñ„ÄÇÊàë‰ª¨ÁöÑÁ†îÁ©∂ÊèêÂÄ°Âú®ÂåªÁñó‰øùÂÅ•ÁöÑ AI Á†îÁ©∂‰∏≠‰ºòÂÖàËÄÉËôëÂÆûÊñΩÁßëÂ≠¶ÔºåÂπ∂Á°Æ‰øù AI Ëß£ÂÜ≥ÊñπÊ°àÂú®Áé∞ÂÆû‰∏ñÁïåÁöÑ‰∏¥Â∫äÁéØÂ¢É‰∏≠ÂÆûÁî®„ÄÅÊúâÁõä‰∏îÂèØÊåÅÁª≠„ÄÇÈÄöËøáËß£ÂÜ≥ÂåªÁñó‰øùÂÅ•ÁéØÂ¢É‰∏≠ÁöÑÁã¨ÁâπÊåëÊàòÂíåÂ§çÊùÇÊÄßÔºåÁ†îÁ©∂‰∫∫ÂëòÂèØ‰ª•ÂºÄÂèëÂá∫ÊúâÊïàÊîπÂñÑ‰∏¥Â∫äÂÆûË∑µÂíåÊÇ£ËÄÖÈ¢ÑÂêéÁöÑ AI Ê®°Âûã„ÄÇ

##### **Variational Autoencoders for Feature Exploration and Malignancy Prediction of Lung Lesions**
2311.15719v1 by Benjamin Keel, Aaron Quyn, David Jayne, Samuel D. Relton

Lung cancer is responsible for 21% of cancer deaths in the UK and five-year
survival rates are heavily influenced by the stage the cancer was identified
at. Recent studies have demonstrated the capability of AI methods for accurate
and early diagnosis of lung cancer from routine scans. However, this evidence
has not translated into clinical practice with one barrier being a lack of
interpretable models. This study investigates the application Variational
Autoencoders (VAEs), a type of generative AI model, to lung cancer lesions.
Proposed models were trained on lesions extracted from 3D CT scans in the
LIDC-IDRI public dataset. Latent vector representations of 2D slices produced
by the VAEs were explored through clustering to justify their quality and used
in an MLP classifier model for lung cancer diagnosis, the best model achieved
state-of-the-art metrics of AUC 0.98 and 93.1% accuracy. Cluster analysis shows
the VAE latent space separates the dataset of malignant and benign lesions
based on meaningful feature components including tumour size, shape, patient
and malignancy class. We also include a comparative analysis of the standard
Gaussian VAE (GVAE) and the more recent Dirichlet VAE (DirVAE), which replaces
the prior with a Dirichlet distribution to encourage a more explainable latent
space with disentangled feature representation. Finally, we demonstrate the
potential for latent space traversals corresponding to clinically meaningful
feature changes.

ÊëòË¶ÅÔºöËÇ∫ÁôåÂç†Ëã±ÂúãÁôåÁóáÊ≠ª‰∫°‰∫∫Êï∏ÁöÑ 21%Ôºå‰∫îÂπ¥Â≠òÊ¥ªÁéáÂæàÂ§ßÁ®ãÂ∫¶ÂèñÊ±∫ÊñºÁôåÁóáË¢´ÁôºÁèæÁöÑÈöéÊÆµ„ÄÇÊúÄËøëÁöÑÁ†îÁ©∂Â∑≤Ë≠âÊòé‰∫∫Â∑•Êô∫ËÉΩÊñπÊ≥ïÂÖ∑ÊúâÂæû‰æãË°åÊéÉÊèè‰∏≠Ê∫ñÁ¢∫ÂèäÊó©Ë®∫Êñ∑ËÇ∫ÁôåÁöÑËÉΩÂäõ„ÄÇÁÑ∂ËÄåÔºåÊ≠§Ë≠âÊìöÂ∞öÊú™ËΩâÂåñÁÇ∫Ëá®Â∫äÂØ¶ÂãôÔºåÂÖ∂‰∏≠‰∏ÄÂÄãÈöúÁ§ôÊòØÁº∫‰πèÂèØËß£ÈáãÁöÑÊ®°Âûã„ÄÇÊú¨Á†îÁ©∂Êé¢Ë®é‰∫ÜÊáâÁî®ËÆäÂàÜËá™ÂãïÁ∑®Á¢ºÂô® (VAE)Ôºå‰∏ÄÁ®ÆÁîüÊàêÂºè‰∫∫Â∑•Êô∫ËÉΩÊ®°ÂûãÔºåÊñºËÇ∫ÁôåÁóÖÁÅ∂„ÄÇÂ∞áÊèêÂá∫ÁöÑÊ®°ÂûãË®ìÁ∑¥ÊñºÂæû LIDC-IDRI ÂÖ¨ÂÖ±Êï∏ÊìöÈõÜ‰∏≠ÊèêÂèñÁöÑ 3D ÈõªËÖ¶Êñ∑Â±§ÊéÉÊèèÁóÖÁÅ∂„ÄÇÈÄöÈÅéËÅöÈ°ûÊé¢Á¥¢‰∫Ü VAE ÁîüÊàêÁöÑ 2D ÂàáÁâáÁöÑÊΩõÂú®ÂêëÈáèË°®Á§∫Ôºå‰ª•Ë≠âÊòéÂÖ∂ÂìÅË≥™Ôºå‰∏¶Áî®ÊñºËÇ∫ÁôåË®∫Êñ∑ÁöÑ MLP ÂàÜÈ°ûÂô®Ê®°ÂûãÔºåÊúÄ‰Ω≥Ê®°ÂûãÈÅîÂà∞‰∫Ü AUC 0.98 Âíå 93.1% Ê∫ñÁ¢∫Â∫¶ÁöÑÊúÄÂÖàÈÄ≤ÊåáÊ®ô„ÄÇËÅöÈ°ûÂàÜÊûêÈ°ØÁ§∫ÔºåVAE ÊΩõÂú®Á©∫ÈñìÊ†πÊìöÊúâÊÑèÁæ©ÁöÑÁâπÂæµÁµÑÊàêÔºàÂåÖÊã¨ËÖ´Áò§Â§ßÂ∞è„ÄÅÂΩ¢ÁãÄ„ÄÅÊÇ£ËÄÖÂíåÊÉ°ÊÄßÈ°ûÂà•ÔºâÂ∞áÊÉ°ÊÄßÂíåËâØÊÄßÁóÖÁÅ∂ÁöÑÊï∏ÊìöÈõÜÂàÜÈñã„ÄÇÊàëÂÄëÈÇÑÂåÖÊã¨Ê®ôÊ∫ñÈ´òÊñØ VAE (GVAE) ÂíåÊõ¥Êñ∞ÁöÑÁãÑÂà©ÂÖãÈõ∑ VAE (DirVAE) ÁöÑÊØîËºÉÂàÜÊûêÔºåÂæåËÄÖÁî®ÁãÑÂà©ÂÖãÈõ∑ÂàÜ‰ΩàÂèñ‰ª£ÂÖàÈ©óÔºå‰ª•‰øÉÈÄ≤ÂÖ∑ÊúâËß£ÈñãÁâπÂæµË°®Á§∫ÁöÑÊõ¥ÂÖ∑ÂèØËß£ÈáãÊÄßÁöÑÊΩõÂú®Á©∫Èñì„ÄÇÊúÄÂæåÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜËàáËá®Â∫äÊúâÊÑèÁæ©ÁöÑÁâπÂæµËÆäÂåñÁõ∏ÊáâÁöÑÊΩõÂú®Á©∫ÈñìÊ©´Ë∂äÁöÑÊΩõÂäõ„ÄÇ

##### **MRxaI: Black-Box Explainability for Image Classifiers in a Medical Setting**
2311.14471v1 by Nathan Blake, Hana Chockler, David A. Kelly, Santiago Calderon Pena, Akchunya Chanchal

Existing tools for explaining the output of image classifiers can be divided
into white-box, which rely on access to the model internals, and black-box,
agnostic to the model. As the usage of AI in the medical domain grows, so too
does the usage of explainability tools. Existing work on medical image
explanations focuses on white-box tools, such as gradcam. However, there are
clear advantages to switching to a black-box tool, including the ability to use
it with any classifier and the wide selection of black-box tools available. On
standard images, black-box tools are as precise as white-box. In this paper we
compare the performance of several black-box methods against gradcam on a brain
cancer MRI dataset. We demonstrate that most black-box tools are not suitable
for explaining medical image classifications and present a detailed analysis of
the reasons for their shortcomings. We also show that one black-box tool, a
causal explainability-based rex, performs as well as \gradcam.

ÊëòË¶ÅÔºöÁèæÊúâÁöÑÂúñÂÉèÂàÜÈ°ûÂô®Ëº∏Âá∫Ëß£ÈáãÂ∑•ÂÖ∑ÂèØÂàÜÁÇ∫‰æùË≥¥ÊñºÊ®°ÂûãÂÖßÈÉ®Â≠òÂèñÊ¨äÈôêÁöÑÁôΩÁõíÔºå‰ª•ÂèäËàáÊ®°ÂûãÁÑ°ÈóúÁöÑÈªëÁõí„ÄÇÈö®Ëëó AI Âú®ÈÜ´ÁôÇÈ†òÂüüÁöÑ‰ΩøÁî®Â¢ûÂä†ÔºåÂèØËß£ÈáãÊÄßÂ∑•ÂÖ∑ÁöÑ‰ΩøÁî®‰πüÈö®‰πãÂ¢ûÂä†„ÄÇÁèæÊúâÈÜ´Â≠∏ÂΩ±ÂÉèËß£ÈáãÁöÑÂ∑•‰ΩúÈáçÈªûÂú®ÊñºÁôΩÁõíÂ∑•ÂÖ∑Ôºå‰æãÂ¶Ç gradcam„ÄÇÁÑ∂ËÄåÔºåÂàáÊèõÂà∞ÈªëÁõíÂ∑•ÂÖ∑ÊúâÊòéÈ°ØÁöÑÂÑ™ÈªûÔºåÂåÖÊã¨ËÉΩÂ§†Ëàá‰ªª‰ΩïÂàÜÈ°ûÂô®‰∏ÄËµ∑‰ΩøÁî®Ôºå‰ª•ÂèäÂª£Ê≥õÁöÑÈªëÁõíÂ∑•ÂÖ∑ÂèØ‰æõÈÅ∏Êìá„ÄÇÂú®Ê®ôÊ∫ñÂΩ±ÂÉè‰∏äÔºåÈªëÁõíÂ∑•ÂÖ∑ËàáÁôΩÁõí‰∏ÄÊ®£Á≤æÁ¢∫„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊØîËºÉ‰∫ÜÂ§öÁ®ÆÈªëÁõíÊñπÊ≥ïÂú®ËÖ¶Áôå MRI Ë≥áÊñôÈõÜ‰∏äËàá gradcam ÁöÑÊïàËÉΩ„ÄÇÊàëÂÄëË≠âÊòéÂ§ßÂ§öÊï∏ÈªëÁõíÂ∑•ÂÖ∑‰∏çÈÅ©ÂêàËß£ÈáãÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÈ°ûÔºå‰∏¶Ë©≥Á¥∞ÂàÜÊûêÂÖ∂Áº∫ÈªûÁöÑÂéüÂõ†„ÄÇÊàëÂÄëÈÇÑË°®Êòé‰∏ÄÁ®ÆÈªëÁõíÂ∑•ÂÖ∑ÔºåÂü∫ÊñºÂõ†ÊûúÂèØËß£ÈáãÊÄßÁöÑ rexÔºåË°®ÁèæËàá \gradcam ‰∏ÄÊ®£Â•Ω„ÄÇ

##### **Moderating Model Marketplaces: Platform Governance Puzzles for AI Intermediaries**
2311.12573v2 by Robert Gorwa, Michael Veale

The AI development community is increasingly making use of hosting
intermediaries such as Hugging Face provide easy access to user-uploaded models
and training data. These model marketplaces lower technical deployment barriers
for hundreds of thousands of users, yet can be used in numerous potentially
harmful and illegal ways. In this article, we explain ways in which AI systems,
which can both `contain' content and be open-ended tools, present one of the
trickiest platform governance challenges seen to date. We provide case studies
of several incidents across three illustrative platforms -- Hugging Face,
GitHub and Civitai -- to examine how model marketplaces moderate models.
Building on this analysis, we outline important (and yet nevertheless limited)
practices that industry has been developing to respond to moderation demands:
licensing, access and use restrictions, automated content moderation, and open
policy development. While the policy challenge at hand is a considerable one,
we conclude with some ideas as to how platforms could better mobilize resources
to act as a careful, fair, and proportionate regulatory access point.

ÊëòË¶ÅÔºöAI ÁôºÂ±ïÁ§æÁæ§Êó•ÁõäÂà©Áî® Hugging Face Á≠âË®óÁÆ°‰∏≠‰ªãÔºåÊèê‰æõ‰ΩøÁî®ËÄÖ‰∏äÂÇ≥‰πãÊ®°ÂûãËàáË®ìÁ∑¥Ë≥áÊñôÁöÑÁ∞°ÊòìÂèñÂæóÁÆ°ÈÅì„ÄÇÈÄô‰∫õÊ®°ÂûãÂ∏ÇÈõÜÈôç‰Ωé‰∫ÜÊï∏ÂçÅËê¨Âêç‰ΩøÁî®ËÄÖÁöÑÊäÄË°ìÈÉ®ÁΩ≤ÈñÄÊ™ªÔºå‰ΩÜÂçªÂèØËÉΩË¢´Áî®ÊñºË®±Â§öÊΩõÂú®ÊúâÂÆ≥‰∏îÈùûÊ≥ïÁöÑÁî®ÈÄî„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëË™™Êòé‰∫Ü AI Á≥ªÁµ±Êó¢ÂèØ‰ª•„ÄåÂåÖÂê´„ÄçÂÖßÂÆπÔºå‰πüÂèØ‰ª•‰ΩúÁÇ∫ÈñãÊîæÂºèÂ∑•ÂÖ∑ÔºåÈÄôÊèêÂá∫‰∫ÜËøÑ‰ªäÁÇ∫Ê≠¢ÊúÄÊ£òÊâãÁöÑÂπ≥Âè∞Ê≤ªÁêÜÊåëÊà∞‰πã‰∏Ä„ÄÇÊàëÂÄëÊèê‰æõ Hugging Face„ÄÅGitHub Âíå Civitai Á≠â‰∏âÂÄãË™™ÊòéÊÄßÂπ≥Âè∞‰∏äÊï∏Ëµ∑‰∫ã‰ª∂ÁöÑÊ°à‰æãÁ†îÁ©∂Ôºå‰ª•Êé¢Ë®éÊ®°ÂûãÂ∏ÇÈõÜÂ¶Ç‰ΩïÊéßÁÆ°Ê®°Âûã„ÄÇÊ†πÊìöÊ≠§ÂàÜÊûêÔºåÊàëÂÄëÊ¶ÇËø∞‰∫ÜÁî¢Ê•≠ÁÇ∫ÂõûÊáâÊéßÁÆ°ÈúÄÊ±ÇËÄåÁôºÂ±ïÁöÑÈáçË¶ÅÔºà‰ΩÜ‰ªçÊúâÈôêÔºâÂØ¶ÂãôÔºöÊéàÊ¨ä„ÄÅÂ≠òÂèñÂíå‰ΩøÁî®ÈôêÂà∂„ÄÅËá™ÂãïÂÖßÂÆπÊéßÁÆ°ÂíåÈñãÊîæÂºèÊîøÁ≠ñÁôºÂ±ï„ÄÇÂÑòÁÆ°ÁõÆÂâçÈù¢Ëá®ÁöÑÊîøÁ≠ñÊåëÊà∞Áõ∏Áï∂Âö¥Â≥ªÔºåÊàëÂÄë‰ªçÊèêÂá∫‰∫Ü‰∏Ä‰∫õÊÉ≥Ê≥ïÔºåË™™ÊòéÂπ≥Âè∞Â¶Ç‰ΩïËÉΩÊõ¥Â•ΩÂú∞ÂãïÂì°Ë≥áÊ∫êÔºå‰ΩúÁÇ∫Ë¨πÊÖé„ÄÅÂÖ¨Âπ≥ÂíåÈÅ©Â∫¶ÁöÑÊ≥ïË¶èÂ≠òÂèñÈªû„ÄÇ

##### **Ovarian Cancer Data Analysis using Deep Learning: A Systematic Review from the Perspectives of Key Features of Data Analysis and AI Assurance**
2311.11932v1 by Muta Tah Hira, Mohammad A. Razzaque, Mosharraf Sarker

Background and objectives: By extracting this information, Machine or Deep
Learning (ML/DL)-based autonomous data analysis tools can assist clinicians and
cancer researchers in discovering patterns and relationships from complex data
sets. Many DL-based analyses on ovarian cancer (OC) data have recently been
published. These analyses are highly diverse in various aspects of cancer
(e.g., subdomain(s) and cancer type they address) and data analysis features.
However, a comprehensive understanding of these analyses in terms of these
features and AI assurance (AIA) is currently lacking. This systematic review
aims to fill this gap by examining the existing literature and identifying
important aspects of OC data analysis using DL, explicitly focusing on the key
features and AI assurance perspectives. Methods: The PRISMA framework was used
to conduct comprehensive searches in three journal databases. Only studies
published between 2015 and 2023 in peer-reviewed journals were included in the
analysis. Results: In the review, a total of 96 DL-driven analyses were
examined. The findings reveal several important insights regarding DL-driven
ovarian cancer data analysis: - Most studies 71% (68 out of 96) focused on
detection and diagnosis, while no study addressed the prediction and prevention
of OC. - The analyses were predominantly based on samples from a non-diverse
population (75% (72/96 studies)), limited to a geographic location or country.
- Only a small proportion of studies (only 33% (32/96)) performed integrated
analyses, most of which used homogeneous data (clinical or omics). - Notably, a
mere 8.3% (8/96) of the studies validated their models using external and
diverse data sets, highlighting the need for enhanced model validation, and -
The inclusion of AIA in cancer data analysis is in a very early stage; only
2.1% (2/96) explicitly addressed AIA through explainability.

ÊëòË¶ÅÔºö<paragraph>ËÉåÊôØÂíåÁõÆÊ®ôÔºöÈÄöÈÅéÊèêÂèñÈÄô‰∫õË≥áË®äÔºåÊ©üÂô®ÊàñÊ∑±Â∫¶Â≠∏Áøí (ML/DL) Âü∫ÊñºËá™‰∏ªÊï∏ÊìöÂàÜÊûêÂ∑•ÂÖ∑ÂèØ‰ª•ÂçîÂä©Ëá®Â∫äÈÜ´ÁîüÂíåÁôåÁóáÁ†îÁ©∂‰∫∫Âì°ÂæûË§áÈõúÁöÑÊï∏ÊìöÈõÜ‰∏≠ÁôºÁèæÊ®°ÂºèÂíåÈóú‰øÇ„ÄÇÊúÄËøëÂ∑≤ÁôºË°®Ë®±Â§öÂü∫Êñº DL ÁöÑÂçµÂ∑¢Áôå (OC) Êï∏ÊìöÂàÜÊûê„ÄÇÈÄô‰∫õÂàÜÊûêÂú®ÁôåÁóáÁöÑÂêÑÂÄãÊñπÈù¢Ôºà‰æãÂ¶ÇÔºåÂÆÉÂÄëÊ∂âÂèäÁöÑÂ≠êÈ†òÂüüÂíåÁôåÁóáÈ°ûÂûãÔºâÂíåÊï∏ÊìöÂàÜÊûêÂäüËÉΩÊñπÈù¢È´òÂ∫¶Â§öÊ®£Âåñ„ÄÇÁÑ∂ËÄåÔºåÁõÆÂâçÁº∫‰πèÂ∞çÈÄô‰∫õÂàÜÊûêÂú®ÈÄô‰∫õÁâπÂæµÂíå AI ‰øùË≠â (AIA) ÊñπÈù¢ÁöÑÂÖ®Èù¢ÁêÜËß£„ÄÇÈÄôÁØáÁ≥ªÁµ±ÊÄßÂõûÈ°ßÊó®Âú®ÈÄöÈÅéÊ™¢Ë¶ñÁèæÊúâÊñáÁçª‰∏¶ÊòéÁ¢∫ÈóúÊ≥®ÈóúÈçµÁâπÂæµÂíå AI ‰øùË≠âËßÄÈªûÔºå‰æÜÂ°´Ë£úÈÄôÂÄãÁ©∫ÁôΩ„ÄÇÊñπÊ≥ïÔºö‰ΩøÁî® PRISMA Êû∂ÊßãÂú®‰∏âÂÄãÊúüÂàäË≥áÊñôÂ∫´‰∏≠ÈÄ≤Ë°åÂÖ®Èù¢ÊêúÂ∞ã„ÄÇÂàÜÊûêÂÉÖÂåÖÊã¨ 2015 Âπ¥Ëá≥ 2023 Âπ¥ÈñìÁôºË°®ÊñºÂêåË°åË©ïÂØ©ÊúüÂàäÁöÑÁ†îÁ©∂„ÄÇÁµêÊûúÔºöÂú®ÂõûÈ°ß‰∏≠ÔºåÁ∏ΩÂÖ±Ê™¢Ë¶ñ‰∫Ü 96 È†ÖÁî± DL È©ÖÂãïÁöÑÂàÜÊûê„ÄÇÁ†îÁ©∂ÁµêÊûúÊè≠Á§∫‰∫ÜÂπæÂÄãÈóúÊñºÁî± DL È©ÖÂãïÁöÑÂçµÂ∑¢ÁôåÊï∏ÊìöÂàÜÊûêÁöÑÈáçË¶ÅË¶ãËß£Ôºö- Â§ßÂ§öÊï∏Á†îÁ©∂ 71%Ôºà96 È†Ö‰∏≠Êúâ 68 È†ÖÔºâÂ∞àÊ≥®ÊñºÊ™¢Ê∏¨ÂíåË®∫Êñ∑ÔºåËÄåÊ≤íÊúâÁ†îÁ©∂Êé¢Ë®é OC ÁöÑÈ†êÊ∏¨ÂíåÈ†êÈò≤„ÄÇ- ÈÄô‰∫õÂàÜÊûê‰∏ªË¶ÅÂü∫Êñº‰æÜËá™ÈùûÂ§öÂÖÉÊóèÁæ§ÁöÑÊ®£Êú¨Ôºà75%Ôºà96 È†ÖÁ†îÁ©∂‰∏≠ÁöÑ 72 È†ÖÔºâÔºâÔºåÂÉÖÈôêÊñºÊüêÂÄãÂú∞ÁêÜ‰ΩçÁΩÆÊàñÂúãÂÆ∂„ÄÇ- Âè™ÊúâÂ∞ëÈÉ®ÂàÜÁ†îÁ©∂ÔºàÂÉÖ 33%Ôºà96 È†ÖÁ†îÁ©∂‰∏≠ÁöÑ 32 È†ÖÔºâÂü∑Ë°åÊï¥ÂêàÂàÜÊûêÔºåÂÖ∂‰∏≠Â§ßÂ§öÊï∏‰ΩøÁî®ÂêåË≥™Êï∏ÊìöÔºàËá®Â∫äÊàñÁµÑÂ≠∏Ôºâ„ÄÇ- ÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÂè™Êúâ 8.3%Ôºà96 È†ÖÁ†îÁ©∂‰∏≠ÁöÑ 8 È†ÖÔºâ‰ΩøÁî®Â§ñÈÉ®ÂíåÂ§öÂÖÉÊï∏ÊìöÈõÜÈ©óË≠â‰∫ÜÂÖ∂Ê®°ÂûãÔºåÂº∑Ë™ø‰∫ÜÂä†Âº∑Ê®°ÂûãÈ©óË≠âÁöÑÂøÖË¶ÅÊÄßÔºå‰ª•Âèä- Â∞á AIA Á¥çÂÖ•ÁôåÁóáÊï∏ÊìöÂàÜÊûê‰ªçËôïÊñºÈùûÂ∏∏Êó©ÊúüÁöÑÈöéÊÆµÔºõÂè™Êúâ 2.1%Ôºà96 È†ÖÁ†îÁ©∂‰∏≠ÁöÑ 2 È†ÖÔºâÈÄèÈÅéÂèØËß£ÈáãÊÄßÊòéÁ¢∫Êé¢Ë®é‰∫Ü AIA„ÄÇ</paragraph>

##### **Representing visual classification as a linear combination of words**
2311.10933v1 by Shobhit Agarwal, Yevgeniy R. Semenov, William Lotter

Explainability is a longstanding challenge in deep learning, especially in
high-stakes domains like healthcare. Common explainability methods highlight
image regions that drive an AI model's decision. Humans, however, heavily rely
on language to convey explanations of not only "where" but "what".
Additionally, most explainability approaches focus on explaining individual AI
predictions, rather than describing the features used by an AI model in
general. The latter would be especially useful for model and dataset auditing,
and potentially even knowledge generation as AI is increasingly being used in
novel tasks. Here, we present an explainability strategy that uses a
vision-language model to identify language-based descriptors of a visual
classification task. By leveraging a pre-trained joint embedding space between
images and text, our approach estimates a new classification task as a linear
combination of words, resulting in a weight for each word that indicates its
alignment with the vision-based classifier. We assess our approach using two
medical imaging classification tasks, where we find that the resulting
descriptors largely align with clinical knowledge despite a lack of
domain-specific language training. However, our approach also identifies the
potential for 'shortcut connections' in the public datasets used. Towards a
functional measure of explainability, we perform a pilot reader study where we
find that the AI-identified words can enable non-expert humans to perform a
specialized medical task at a non-trivial level. Altogether, our results
emphasize the potential of using multimodal foundational models to deliver
intuitive, language-based explanations of visual tasks.

ÊëòË¶ÅÔºö<paragraph>Ëß£ÈáãÊÄßÊòØÊ∑±Â∫¶Â≠∏Áøí‰∏≠Èï∑ÊúüÁöÑÊåëÊà∞ÔºåÁâπÂà•ÊòØÂú®ÈÜ´ÁôÇ‰øùÂÅ•Á≠âÈ´òÈ¢®Èö™È†òÂüü„ÄÇÂ∏∏Ë¶ãÁöÑËß£ÈáãÊÄßÊñπÊ≥ïÊúÉÂº∑Ë™øÈ©ÖÂãï AI Ê®°ÂûãÊ±∫Á≠ñÁöÑÂΩ±ÂÉèÂçÄÂüü„ÄÇÁÑ∂ËÄåÔºå‰∫∫È°ûÂæàÂ§ßÁ®ãÂ∫¶‰æùË≥¥Ë™ûË®Ä‰æÜÂÇ≥ÈÅî‰∏çÂÉÖÊòØ„ÄåÂú®Âì™Ë£°„ÄçÔºåÈÇÑÊúâ„ÄåÊòØ‰ªÄÈ∫º„ÄçÁöÑËß£Èáã„ÄÇÊ≠§Â§ñÔºåÂ§ßÂ§öÊï∏Ëß£ÈáãÊÄßÊñπÊ≥ïÈÉΩÂ∞àÊ≥®ÊñºËß£ÈáãÂÄãÂà• AI È†êÊ∏¨ÔºåËÄå‰∏çÊòØÊèèËø∞ AI Ê®°Âûã‰∏ÄËà¨‰ΩøÁî®ÁöÑÁâπÂæµ„ÄÇÂæåËÄÖÂ∞çÊñºÊ®°ÂûãÂíåË≥áÊñôÈõÜÁ®ΩÊ†∏ÁâπÂà•ÊúâÁî®ÔºåÁîöËá≥ÂèØËÉΩÂú® AI ÊÑà‰æÜÊÑàÁî®ÊñºÊñ∞Á©é‰ªªÂãôÊôÇÁî¢ÁîüÁü•Ë≠ò„ÄÇÂú®Ê≠§ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄã‰ΩøÁî®Ë¶ñË¶∫Ë™ûË®ÄÊ®°Âûã‰æÜËæ®Ë≠òË¶ñË¶∫ÂàÜÈ°û‰ªªÂãôÁöÑË™ûË®ÄÊèèËø∞Á¨¶ÁöÑËß£ÈáãÊÄßÁ≠ñÁï•„ÄÇÈÄèÈÅéÂà©Áî®ÂΩ±ÂÉèÂíåÊñáÂ≠ó‰πãÈñìÈ†êÂÖàË®ìÁ∑¥ÁöÑËÅØÂêàÂµåÂÖ•Á©∫ÈñìÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÂ∞áÊñ∞ÁöÑÂàÜÈ°û‰ªªÂãô‰º∞Ë®àÁÇ∫‰∏ÄÂÄãÁ∑öÊÄßÊñáÂ≠óÁµÑÂêàÔºåÂ∞éËá¥ÊØèÂÄãÊñáÂ≠óÈÉΩÊúâÊ¨äÈáçÔºåË°®Á§∫ÂÆÉËàáÂü∫ÊñºË¶ñË¶∫ÁöÑÂàÜÈ°ûÂô®Â∞çÈΩä„ÄÇÊàëÂÄë‰ΩøÁî®ÂÖ©ÂÄãÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÈ°û‰ªªÂãô‰æÜË©ï‰º∞ÊàëÂÄëÁöÑÂÅöÊ≥ïÔºåÊàëÂÄëÁôºÁèæÁî¢ÁîüÁöÑÊèèËø∞Á¨¶Âú®ÂæàÂ§ßÁ®ãÂ∫¶‰∏äËàáËá®Â∫äÁü•Ë≠ò‰∏ÄËá¥ÔºåÂÑòÁÆ°Áº∫‰πèÁâπÂÆöÈ†òÂüüÁöÑË™ûË®ÄË®ìÁ∑¥„ÄÇÁÑ∂ËÄåÔºåÊàëÂÄëÁöÑÂÅöÊ≥ï‰πüÁôºÁèæ‰∫ÜÊâÄÁî®ÂÖ¨ÈñãË≥áÊñôÈõÜ‰∏≠ÁöÑ„ÄåÊç∑ÂæëÈÄ£Á∑ö„ÄçÁöÑÂèØËÉΩÊÄß„ÄÇÁÇ∫‰∫ÜÈÅîÂà∞Ëß£ÈáãÊÄßÁöÑÂäüËÉΩÊÄßË°°ÈáèÔºåÊàëÂÄëÈÄ≤Ë°å‰∫Ü‰∏ÄÈ†ÖË©¶È©óËÆÄËÄÖÁ†îÁ©∂ÔºåÁôºÁèæ AI Ë≠òÂà•ÁöÑÊñáÂ≠óËÉΩËÆìÈùûÂ∞àÂÆ∂‰∫∫È°ûÂú®ÈùûÂπ≥Âá°ÁöÑÂ±§Á¥öÂü∑Ë°åÂ∞àÊ•≠ÁöÑÈÜ´ÁôÇ‰ªªÂãô„ÄÇÁ∏Ω‰πãÔºåÊàëÂÄëÁöÑÁµêÊûúÂº∑Ë™ø‰∫Ü‰ΩøÁî®Â§öÊ®°ÂºèÂü∫Á§éÊ®°Âûã‰æÜÊèê‰æõÁõ¥ËßÄÁöÑ„ÄÅÂü∫ÊñºË™ûË®ÄÁöÑË¶ñË¶∫‰ªªÂãôËß£ÈáãÁöÑÊΩõÂäõ„ÄÇ</paragraph>

##### **Towards objective and systematic evaluation of bias in medical imaging AI**
2311.02115v1 by Emma A. M. Stanley, Raissa Souza, Anthony Winder, Vedant Gulve, Kimberly Amador, Matthias Wilms, Nils D. Forkert

Artificial intelligence (AI) models trained using medical images for clinical
tasks often exhibit bias in the form of disparities in performance between
subgroups. Since not all sources of biases in real-world medical imaging data
are easily identifiable, it is challenging to comprehensively assess how those
biases are encoded in models, and how capable bias mitigation methods are at
ameliorating performance disparities. In this article, we introduce a novel
analysis framework for systematically and objectively investigating the impact
of biases in medical images on AI models. We developed and tested this
framework for conducting controlled in silico trials to assess bias in medical
imaging AI using a tool for generating synthetic magnetic resonance images with
known disease effects and sources of bias. The feasibility is showcased by
using three counterfactual bias scenarios to measure the impact of simulated
bias effects on a convolutional neural network (CNN) classifier and the
efficacy of three bias mitigation strategies. The analysis revealed that the
simulated biases resulted in expected subgroup performance disparities when the
CNN was trained on the synthetic datasets. Moreover, reweighing was identified
as the most successful bias mitigation strategy for this setup, and we
demonstrated how explainable AI methods can aid in investigating the
manifestation of bias in the model using this framework. Developing fair AI
models is a considerable challenge given that many and often unknown sources of
biases can be present in medical imaging datasets. In this work, we present a
novel methodology to objectively study the impact of biases and mitigation
strategies on deep learning pipelines, which can support the development of
clinical AI that is robust and responsible.

ÊëòË¶ÅÔºö<paragraph>‰ΩøÁî®ÈÜ´Â≠∏ÂΩ±ÂÉèË®ìÁ∑¥Áî®ÊñºËá®Â∫ä‰ªªÂãôÁöÑ‰∫∫Â∑•Êô∫ÊÖß (AI) Ê®°ÂûãÔºåÂ∏∏ÊúÉÂ±ïÁèæÂá∫ÊïàËÉΩÂ∑ÆÁï∞ÁöÑÂΩ¢ÂºèÂÅèË™§ÔºåÈÄô‰∫õÂ∑ÆÁï∞Â≠òÂú®ÊñºÊ¨°Áæ§ÁµÑ‰πãÈñì„ÄÇÁî±Êñº‰∏¶ÈùûÊâÄÊúâÁúüÂØ¶‰∏ñÁïåÈÜ´Â≠∏ÂΩ±ÂÉèË≥áÊñô‰∏≠ÁöÑÂÅèË™§‰æÜÊ∫êÈÉΩÂÆπÊòìËæ®Ë≠òÔºåÂõ†Ê≠§ÂÖ®Èù¢Ë©ï‰º∞ÈÄô‰∫õÂÅèË™§Â¶Ç‰ΩïÁ∑®Á¢ºÂú®Ê®°Âûã‰∏≠Ôºå‰ª•ÂèäÂÅèË™§Á∑©Ëß£ÊñπÊ≥ïÂú®ÊîπÂñÑÊïàËÉΩÂ∑ÆÁï∞ÊñπÈù¢ÁöÑËÉΩÂäõÊòØ‰∏ÄÈ†ÖÊåëÊà∞„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∏ÄÂÄãÊñ∞Á©éÁöÑÂàÜÊûêÊû∂ÊßãÔºåÁî®ÊñºÁ≥ªÁµ±ÊÄß‰∏îÂÆ¢ËßÄÂú∞Ë™øÊü•ÈÜ´Â≠∏ÂΩ±ÂÉè‰∏≠ÁöÑÂÅèË™§Â∞ç AI Ê®°ÂûãÁöÑÂΩ±Èüø„ÄÇÊàëÂÄëÈñãÁôº‰∏¶Ê∏¨Ë©¶‰∫ÜÈÄôÂÄãÊû∂ÊßãÔºåÁî®ÊñºÂü∑Ë°åÂèóÊéßÁöÑÈõªËÖ¶Ê®°Êì¨Ë©¶È©óÔºå‰ª•Ë©ï‰º∞ÈÜ´Â≠∏ÂΩ±ÂÉè AI ‰∏≠ÁöÑÂÅèË™§Ôºå‰∏¶‰ΩøÁî®‰∏ÄÂÄãÂ∑•ÂÖ∑‰æÜÁî¢ÁîüÂ∑≤Áü•ÁñæÁóÖÂΩ±ÈüøÂíåÂÅèË™§‰æÜÊ∫êÁöÑÂêàÊàêÁ£ÅÂÖ±ÊåØÂΩ±ÂÉè„ÄÇÂèØË°åÊÄßÈÄèÈÅé‰ΩøÁî®‰∏âÂÄãÂèç‰∫ãÂØ¶ÂÅèË™§ÊÉÖÂ¢É‰æÜË°°ÈáèÊ®°Êì¨ÂÅèË™§ÂΩ±ÈüøÂ∞çÂç∑Á©çÁ•ûÁ∂ìÁ∂≤Ë∑Ø (CNN) ÂàÜÈ°ûÂô®Âíå‰∏âÂÄãÂÅèË™§Á∑©Ëß£Á≠ñÁï•ÁöÑÊïàËÉΩ„ÄÇÂàÜÊûêÈ°ØÁ§∫ÔºåÁï∂ CNN Âú®ÂêàÊàêË≥áÊñôÈõÜ‰∏äË®ìÁ∑¥ÊôÇÔºåÊ®°Êì¨ÂÅèË™§ÊúÉÂ∞éËá¥È†êÊúüÁöÑÊ¨°Áæ§ÁµÑÊïàËÉΩÂ∑ÆÁï∞„ÄÇÊ≠§Â§ñÔºåÈáçÊñ∞Âä†Ê¨äË¢´Ë¶ñÁÇ∫Ê≠§Ë®≠ÂÆö‰∏≠ÊúÄÊàêÂäüÁöÑÂÅèË™§Á∑©Ëß£Á≠ñÁï•ÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜËß£ÈáãÊÄß AI ÊñπÊ≥ïÂ¶Ç‰ΩïÂçîÂä©Ë™øÊü•Ê®°Âûã‰∏≠ÂÅèË™§ÁöÑË°®ÁèæÔºåÊñπÊ≥ïÊòØ‰ΩøÁî®ÈÄôÂÄãÊû∂Êßã„ÄÇÈñãÁôºÂÖ¨Âπ≥ÁöÑ AI Ê®°ÂûãÊòØ‰∏ÄÈ†ÖÈáçÂ§ßÁöÑÊåëÊà∞ÔºåÂõ†ÁÇ∫Âú®ÈÜ´Â≠∏ÂΩ±ÂÉèË≥áÊñôÈõÜ‰∏≠ÊúâË®±Â§ö‰∏îÈÄöÂ∏∏Êú™Áü•ÁöÑÂÅèË™§‰æÜÊ∫ê„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÊñ∞Á©éÁöÑÊñπÊ≥ïÔºåÁî®ÊñºÂÆ¢ËßÄÂú∞Á†îÁ©∂ÂÅèË™§ÂíåÁ∑©Ëß£Á≠ñÁï•Â∞çÊ∑±Â∫¶Â≠∏ÁøíÁÆ°Á∑öÁöÑÂΩ±ÈüøÔºåÈÄôÂèØ‰ª•ÊîØÊè¥ÂÅ•ÂÖ®‰∏îË≤†Ë≤¨‰ªªÁöÑËá®Â∫ä AI ÁöÑÈñãÁôº„ÄÇ</paragraph>

##### **Predicting recovery following stroke: deep learning, multimodal data and feature selection using explainable AI**
2310.19174v1 by Adam White, Margarita Saranti, Artur d'Avila Garcez, Thomas M. H. Hope, Cathy J. Price, Howard Bowman

Machine learning offers great potential for automated prediction of
post-stroke symptoms and their response to rehabilitation. Major challenges for
this endeavour include the very high dimensionality of neuroimaging data, the
relatively small size of the datasets available for learning, and how to
effectively combine neuroimaging and tabular data (e.g. demographic information
and clinical characteristics). This paper evaluates several solutions based on
two strategies. The first is to use 2D images that summarise MRI scans. The
second is to select key features that improve classification accuracy.
Additionally, we introduce the novel approach of training a convolutional
neural network (CNN) on images that combine regions-of-interest extracted from
MRIs, with symbolic representations of tabular data. We evaluate a series of
CNN architectures (both 2D and a 3D) that are trained on different
representations of MRI and tabular data, to predict whether a composite measure
of post-stroke spoken picture description ability is in the aphasic or
non-aphasic range. MRI and tabular data were acquired from 758 English speaking
stroke survivors who participated in the PLORAS study. The classification
accuracy for a baseline logistic regression was 0.678 for lesion size alone,
rising to 0.757 and 0.813 when initial symptom severity and recovery time were
successively added. The highest classification accuracy 0.854 was observed when
8 regions-of-interest was extracted from each MRI scan and combined with lesion
size, initial severity and recovery time in a 2D Residual Neural Network.Our
findings demonstrate how imaging and tabular data can be combined for high
post-stroke classification accuracy, even when the dataset is small in machine
learning terms. We conclude by proposing how the current models could be
improved to achieve even higher levels of accuracy using images from hospital
scanners.

ÊëòË¶ÅÔºöÊ©üÂô®Â≠∏ÁøíÁÇ∫Ëá™ÂãïÈ†êÊ∏¨‰∏≠È¢®ÂæåÁóáÁãÄÂèäÂÖ∂Â∞çÂæ©ÂÅ•ÁöÑÂèçÊáâÊèê‰æõ‰∫ÜÊ•µÂ§ßÁöÑÊΩõÂäõ„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÁöÑÈáçÂ§ßÊåëÊà∞ÂåÖÊã¨Á•ûÁ∂ìÂΩ±ÂÉèË≥áÊñôÁöÑÁ∂≠Â∫¶ÈùûÂ∏∏È´ò„ÄÅÂèØÁî®ÊñºÂ≠∏ÁøíÁöÑË≥áÊñôÈõÜË¶èÊ®°Áõ∏Â∞çËºÉÂ∞èÔºå‰ª•ÂèäÂ¶Ç‰ΩïÊúâÊïàÁµêÂêàÁ•ûÁ∂ìÂΩ±ÂÉèÂíåË°®Ê†ºË≥áÊñôÔºà‰æãÂ¶Ç‰∫∫Âè£Áµ±Ë®àË≥áË®äÂíåËá®Â∫äÁâπÂæµÔºâ„ÄÇÊú¨ÊñáÊ†πÊìöÂÖ©Á®ÆÁ≠ñÁï•Ë©ï‰º∞‰∫ÜÂ§öÁ®ÆËß£Ê±∫ÊñπÊ°à„ÄÇÁ¨¨‰∏ÄÁ®ÆÊòØ‰ΩøÁî®Á∏ΩÁµê MRI ÊéÉÊèèÁöÑ 2D ÂΩ±ÂÉè„ÄÇÁ¨¨‰∫åÁ®ÆÊòØÈÅ∏ÊìáÊúâÂä©ÊñºÊèêÈ´òÂàÜÈ°ûÁ≤æÁ¢∫Â∫¶ÁöÑÈóúÈçµÁâπÂæµ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜÂú®ÁµêÂêàÂæû MRI ‰∏≠ÊèêÂèñÁöÑÊÑüËààË∂£ÂçÄÂüüËàáË°®Ê†ºË≥áÊñôÁöÑÁ¨¶ËôüË°®Á§∫ÁöÑÂΩ±ÂÉè‰∏äË®ìÁ∑¥Âç∑Á©çÁ•ûÁ∂ìÁ∂≤Ë∑Ø (CNN) ÁöÑÊñ∞Á©éÊñπÊ≥ï„ÄÇÊàëÂÄëË©ï‰º∞‰∫Ü‰∏ÄÁ≥ªÂàó CNN Êû∂ÊßãÔºà2D Âíå 3DÔºâÔºåÈÄô‰∫õÊû∂ÊßãÂú® MRI ÂíåË°®Ê†ºË≥áÊñôÁöÑ‰∏çÂêåË°®Á§∫‰∏äÈÄ≤Ë°åË®ìÁ∑¥Ôºå‰ª•È†êÊ∏¨‰∏≠È¢®ÂæåÂè£Ëø∞ÂúñÁâáÊèèËø∞ËÉΩÂäõÁöÑÁ∂úÂêàÊ∏¨ÈáèÊòØÂê¶Âú®Â§±Ë™ûÁóáÊàñÈùûÂ§±Ë™ûÁóáÁØÑÂúçÂÖß„ÄÇMRI ÂíåË°®Ê†ºË≥áÊñô‰æÜËá™ 758 ÂêçÂèÉËàá PLORAS Á†îÁ©∂ÁöÑËã±Ë™û‰∏≠È¢®ÂÄñÂ≠òËÄÖ„ÄÇÂÉÖÈáùÂ∞çÁóÖÁÅ∂Â§ßÂ∞èÁöÑÂü∫Á∑öÈÇèËºØËø¥Ê≠∏ÂàÜÈ°ûÊ∫ñÁ¢∫Â∫¶ÁÇ∫ 0.678ÔºåÁï∂‰æùÂ∫èÂä†ÂÖ•ÂàùÂßãÁóáÁãÄÂö¥ÈáçÁ®ãÂ∫¶ÂíåÊÅ¢Âæ©ÊôÇÈñìÊôÇÔºå‰∏äÂçáËá≥ 0.757 Âíå 0.813„ÄÇÂú®ÂæûÊØèÂÄã MRI ÊéÉÊèè‰∏≠ÊèêÂèñ 8 ÂÄãÊÑüËààË∂£ÂçÄÂüü‰∏¶Âú® 2D ÊÆòÂ∑ÆÁ•ûÁ∂ìÁ∂≤Ë∑Ø‰∏≠ËàáÁóÖÁÅ∂Â§ßÂ∞è„ÄÅÂàùÂßãÂö¥ÈáçÁ®ãÂ∫¶ÂíåÊÅ¢Âæ©ÊôÇÈñìÁµêÂêàÊôÇÔºåËßÄÂØüÂà∞ÊúÄÈ´òÁöÑÂàÜÈ°ûÊ∫ñÁ¢∫Â∫¶ 0.854„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÂ±ïÁ§∫‰∫ÜÂ¶Ç‰ΩïÂ∞áÂΩ±ÂÉèÂíåË°®Ê†ºË≥áÊñôÁµêÂêàËµ∑‰æÜ‰ª•Áç≤ÂæóÈ´òÊñº‰∏≠È¢®ÂæåÂàÜÈ°ûÊ∫ñÁ¢∫Â∫¶ÔºåÂç≥‰ΩøÂú®Ê©üÂô®Â≠∏ÁøíË°ìË™û‰∏≠Ë≥áÊñôÈõÜÂæàÂ∞èÁöÑÊÉÖÊ≥Å‰∏ã‰πüÊòØÂ¶ÇÊ≠§„ÄÇÊúÄÂæåÔºåÊàëÂÄëÊèêÂá∫Â¶Ç‰ΩïÊîπÈÄ≤ÁõÆÂâçÁöÑÊ®°ÂûãÔºå‰ª•‰ΩøÁî®‰æÜËá™ÈÜ´Èô¢ÊéÉÊèèÂÑÄÁöÑÂΩ±ÂÉè‰æÜÂØ¶ÁèæÊõ¥È´òÁöÑÊ∫ñÁ¢∫Â∫¶„ÄÇ

##### **Trainable Noise Model as an XAI evaluation method: application on Sobol for remote sensing image segmentation**
2310.01828v2 by Hossein Shreim, Abdul Karim Gizzini, Ali J. Ghandour

eXplainable Artificial Intelligence (XAI) has emerged as an essential
requirement when dealing with mission-critical applications, ensuring
transparency and interpretability of the employed black box AI models. The
significance of XAI spans various domains, from healthcare to finance, where
understanding the decision-making process of deep learning algorithms is
essential. Most AI-based computer vision models are often black boxes; hence,
providing explainability of deep neural networks in image processing is crucial
for their wide adoption and deployment in medical image analysis, autonomous
driving, and remote sensing applications. Recently, several XAI methods for
image classification tasks have been introduced. On the contrary, image
segmentation has received comparatively less attention in the context of
explainability, although it is a fundamental task in computer vision
applications, especially in remote sensing. Only some research proposes
gradient-based XAI algorithms for image segmentation. This paper adapts the
recent gradient-free Sobol XAI method for semantic segmentation. To measure the
performance of the Sobol method for segmentation, we propose a quantitative XAI
evaluation method based on a learnable noise model. The main objective of this
model is to induce noise on the explanation maps, where higher induced noise
signifies low accuracy and vice versa. A benchmark analysis is conducted to
evaluate and compare performance of three XAI methods, including Seg-Grad-CAM,
Seg-Grad-CAM++ and Seg-Sobol using the proposed noise-based evaluation
technique. This constitutes the first attempt to run and evaluate XAI methods
using high-resolution satellite images.

ÊëòË¶ÅÔºöÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖß (XAI) Â∑≤ÊàêÁÇ∫ËôïÁêÜ‰ªªÂãôÈóúÈçµÊáâÁî®Á®ãÂºèÊôÇÁöÑ‰∏ÄÈ†ÖÂü∫Êú¨ÈúÄÊ±ÇÔºåÁ¢∫‰øùÊé°Áî®ÈªëÁõí AI Ê®°ÂûãÁöÑÈÄèÊòéÂ∫¶ÂíåÂèØËß£ÈáãÊÄß„ÄÇXAI ÁöÑÈáçË¶ÅÊÄßÊ∂µËìãÂæûÈÜ´ÁôÇ‰øùÂÅ•Âà∞ÈáëËûçÁöÑÂêÑÁ®ÆÈ†òÂüüÔºåÂú®ÈÄô‰∫õÈ†òÂüü‰∏≠Ôºå‰∫ÜËß£Ê∑±Â∫¶Â≠∏ÁøíÊºîÁÆóÊ≥ïÁöÑÊ±∫Á≠ñÂà∂ÂÆöÈÅéÁ®ãËá≥ÈóúÈáçË¶Å„ÄÇÂ§ßÂ§öÊï∏Âü∫Êñº AI ÁöÑÈõªËÖ¶Ë¶ñË¶∫Ê®°ÂûãÈÄöÂ∏∏ÊòØÈªëÁõíÂ≠êÔºõÂõ†Ê≠§ÔºåÂú®ÂΩ±ÂÉèËôïÁêÜ‰∏≠Êèê‰æõÊ∑±Â∫¶Á•ûÁ∂ìÁ∂≤Ë∑ØÁöÑÂèØËß£ÈáãÊÄßÂ∞çÊñºÂÖ∂Âú®ÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÊûê„ÄÅËá™ÂãïÈßïÈßõÂíåÈÅôÊ∏¨ÊáâÁî®‰∏≠ÁöÑÂª£Ê≥õÊé°Áî®ÂíåÈÉ®ÁΩ≤Ëá≥ÈóúÈáçË¶Å„ÄÇÊúÄËøëÔºåÂ∑≤ÈáùÂ∞çÂΩ±ÂÉèÂàÜÈ°û‰ªªÂãôÂºïÂÖ•‰∫ÜÂ§öÁ®Æ XAI ÊñπÊ≥ï„ÄÇÁõ∏ÂèçÂú∞ÔºåÂΩ±ÂÉèÂàÜÂâ≤Âú®ÂèØËß£ÈáãÊÄßÁöÑËÉåÊôØ‰∏ãÂèóÂà∞ÁöÑÈóúÊ≥®Áõ∏Â∞çËºÉÂ∞ëÔºåÂÑòÁÆ°ÂÆÉÊòØÈõªËÖ¶Ë¶ñË¶∫ÊáâÁî®‰∏≠ÁöÑ‰∏ÄÈ†ÖÂü∫Êú¨‰ªªÂãôÔºåÁâπÂà•ÊòØÂú®ÈÅôÊ∏¨‰∏≠„ÄÇÂè™ÊúâÈÉ®ÂàÜÁ†îÁ©∂ÊèêÂá∫Áî®ÊñºÂΩ±ÂÉèÂàÜÂâ≤ÁöÑÂü∫ÊñºÊ¢ØÂ∫¶ÁöÑ XAI ÊºîÁÆóÊ≥ï„ÄÇÊú¨ÊñáÊîπÁ∑®‰∫ÜÊúÄËøëÁöÑÁÑ°Ê¢ØÂ∫¶ Sobol XAI ÊñπÊ≥ï‰ª•ÈÄ≤Ë°åË™ûÊÑèÂàÜÂâ≤„ÄÇÁÇ∫‰∫ÜË°°Èáè Sobol ÊñπÊ≥ïÂú®ÂàÜÂâ≤‰∏≠ÁöÑÊïàËÉΩÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂü∫ÊñºÂèØÂ≠∏ÁøíÈõúË®äÊ®°ÂûãÁöÑÂÆöÈáè XAI Ë©ï‰º∞ÊñπÊ≥ï„ÄÇÊ≠§Ê®°ÂûãÁöÑ‰∏ªË¶ÅÁõÆÁöÑÊòØÂú®Ëß£ÈáãÂúñ‰∏äË™òÁôºÈõúË®äÔºåÂÖ∂‰∏≠ËºÉÈ´òÁöÑË™òÁôºÈõúË®äË°®Á§∫ËºÉ‰ΩéÁöÑÊ∫ñÁ¢∫Â∫¶ÔºåÂèç‰πã‰∫¶ÁÑ∂„ÄÇÈÄ≤Ë°åÂü∫Ê∫ñÂàÜÊûê‰ª•Ë©ï‰º∞ÂíåÊØîËºÉ‰∏âÁ®Æ XAI ÊñπÊ≥ïÁöÑÊïàËÉΩÔºåÂåÖÊã¨ Seg-Grad-CAM„ÄÅSeg-Grad-CAM++ Âíå Seg-SobolÔºå‰∏¶‰ΩøÁî®ÊâÄÊèêÂá∫ÁöÑÂü∫ÊñºÈõúË®äÁöÑË©ï‰º∞ÊäÄË°ì„ÄÇÈÄôÊßãÊàê‰∫Ü‰ΩøÁî®È´òËß£ÊûêÂ∫¶Ë°õÊòüÂΩ±ÂÉèÂü∑Ë°åÂíåË©ï‰º∞ XAI ÊñπÊ≥ïÁöÑÈ¶ñÊ¨°ÂòóË©¶„ÄÇ

##### **Creating Trustworthy LLMs: Dealing with Hallucinations in Healthcare AI**
2311.01463v1 by Muhammad Aurangzeb Ahmad, Ilker Yaramis, Taposh Dutta Roy

Large language models have proliferated across multiple domains in as short
period of time. There is however hesitation in the medical and healthcare
domain towards their adoption because of issues like factuality, coherence, and
hallucinations. Give the high stakes nature of healthcare, many researchers
have even cautioned against its usage until these issues are resolved. The key
to the implementation and deployment of LLMs in healthcare is to make these
models trustworthy, transparent (as much possible) and explainable. In this
paper we describe the key elements in creating reliable, trustworthy, and
unbiased models as a necessary condition for their adoption in healthcare.
Specifically we focus on the quantification, validation, and mitigation of
hallucinations in the context in healthcare. Lastly, we discuss how the future
of LLMs in healthcare may look like.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÂú®Áü≠ÊôÇÈñìÂÖßÂ∑≤Âú®Â§öÂÄãÈ†òÂüü‰∏≠Â§ßÈáèÊøÄÂ¢û„ÄÇÁÑ∂ËÄåÔºåÁî±Êñº‰∫ãÂØ¶ÊÄß„ÄÅÈÄ£Ë≤´ÊÄßÂíåÂπªË¶∫Á≠âÂïèÈ°åÔºåÈÜ´ÁôÇÂíå‰øùÂÅ•È†òÂüüÂ∞çÂÖ∂Êé°Áî®Áå∂Ë±´‰∏çÊ±∫„ÄÇÈëëÊñºÈÜ´ÁôÇ‰øùÂÅ•ÁöÑÈ´òÈ¢®Èö™ÊÄßË≥™ÔºåË®±Â§öÁ†îÁ©∂‰∫∫Âì°ÁîöËá≥Ë≠¶Âëä‰∏çË¶Å‰ΩøÁî®ÂÆÉÔºåÁõ¥Âà∞ÈÄô‰∫õÂïèÈ°åÂæóÂà∞Ëß£Ê±∫„ÄÇÂú®ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÂØ¶ÊñΩÂíåÈÉ®ÁΩ≤ LLM ÁöÑÈóúÈçµÊòØ‰ΩøÈÄô‰∫õÊ®°ÂûãÂÄºÂæó‰ø°Ë≥¥„ÄÅÈÄèÊòéÔºàÁõ°ÂèØËÉΩÂ§öÔºâ‰∏îÂèØËß£Èáã„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèèËø∞‰∫ÜÂª∫Á´ãÂèØÈù†„ÄÅÂÄºÂæó‰ø°Ë≥¥ÂíåÁÑ°ÂÅèË¶ãÊ®°ÂûãÁöÑÈóúÈçµË¶ÅÁ¥†Ôºå‰ΩúÁÇ∫ÂÆÉÂÄëÂú®ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÂæóÂà∞Êé°Áî®ÁöÑÂøÖË¶ÅÊ¢ù‰ª∂„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÂ∞àÊ≥®ÊñºÂú®ÈÜ´ÁôÇ‰øùÂÅ•ËÉåÊôØ‰∏ãÂ∞çÂπªË¶∫ÈÄ≤Ë°åÈáèÂåñ„ÄÅÈ©óË≠âÂíåÁ∑©Ëß£„ÄÇÊúÄÂæåÔºåÊàëÂÄëË®éË´ñ‰∫Ü LLM Âú®ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÁöÑÊú™‰æÜÂèØËÉΩÊòØ‰ªÄÈ∫ºÊ®£Â≠ê„ÄÇ

##### **When to Trust AI: Advances and Challenges for Certification of Neural Networks**
2309.11196v1 by Marta Kwiatkowska, Xiyue Zhang

Artificial intelligence (AI) has been advancing at a fast pace and it is now
poised for deployment in a wide range of applications, such as autonomous
systems, medical diagnosis and natural language processing. Early adoption of
AI technology for real-world applications has not been without problems,
particularly for neural networks, which may be unstable and susceptible to
adversarial examples. In the longer term, appropriate safety assurance
techniques need to be developed to reduce potential harm due to avoidable
system failures and ensure trustworthiness. Focusing on certification and
explainability, this paper provides an overview of techniques that have been
developed to ensure safety of AI decisions and discusses future challenges.

ÊëòË¶ÅÔºö‰∫∫Â∑•Êô∫ÊÖßÔºàAIÔºâÂ∑≤Âø´ÈÄüÈÄ≤Ê≠•ÔºåÁèæÂ∑≤Ê∫ñÂÇôÈÉ®ÁΩ≤ÊñºÂª£Ê≥õÁöÑÊáâÁî®Á®ãÂºè‰∏≠Ôºå‰æãÂ¶ÇËá™‰∏ªÁ≥ªÁµ±„ÄÅÈÜ´ÁôÇË®∫Êñ∑ÂíåËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ„ÄÇÂèäÊó©Êé°Áî® AI ÊäÄË°ìÊñºÂØ¶ÈöõÊáâÁî®Á®ãÂºè‰∏¶ÈùûÊ≤íÊúâÂïèÈ°åÔºåÁâπÂà•ÊòØÂ∞çÊñºÁ•ûÁ∂ìÁ∂≤Ë∑ØÔºåÂÆÉÂèØËÉΩ‰∏çÁ©©ÂÆö‰∏îÂÆπÊòìÂèóÂà∞Â∞çÊäóÊÄßÁØÑ‰æãÁöÑÂΩ±Èüø„ÄÇÂæûÈï∑ÈÅ†‰æÜÁúãÔºåÈúÄË¶ÅÈñãÁôºÈÅ©Áï∂ÁöÑÂÆâÂÖ®‰øùË≠âÊäÄË°ìÔºå‰ª•Ê∏õÂ∞ëÂõ†ÂèØÈÅøÂÖçÁöÑÁ≥ªÁµ±ÊïÖÈöúËÄåÈÄ†ÊàêÁöÑÊΩõÂú®ÂÇ∑ÂÆ≥Ôºå‰∏¶Á¢∫‰øùÂèØ‰ø°Ë≥¥ÊÄß„ÄÇÊú¨ÊñáËëóÈáçÊñºË™çË≠âÂíåÂèØËß£ÈáãÊÄßÔºåÊ¶ÇËø∞‰∫ÜÂ∑≤ÈñãÁôºÁî®ÊñºÁ¢∫‰øù AI Ê±∫Á≠ñÂÆâÂÖ®ÁöÑÊäÄË°ìÔºå‰∏¶Ë®éË´ñÊú™‰æÜÁöÑÊåëÊà∞„ÄÇ

##### **Functional requirements to mitigate the Risk of Harm to Patients from Artificial Intelligence in Healthcare**
2309.10424v1 by Juan M. Garc√≠a-G√≥mez, Vicent Blanes-Selva, Jos√© Carlos de Bartolom√© Cenzano, Jaime Cebolla-Cornejo, Ascensi√≥n Do√±ate-Mart√≠nez

The Directorate General for Parliamentary Research Services of the European
Parliament has prepared a report to the Members of the European Parliament
where they enumerate seven main risks of Artificial Intelligence (AI) in
medicine and healthcare: patient harm due to AI errors, misuse of medical AI
tools, bias in AI and the perpetuation of existing inequities, lack of
transparency, privacy and security issues, gaps in accountability, and
obstacles in implementation.
  In this study, we propose fourteen functional requirements that AI systems
may implement to reduce the risks associated with their medical purpose: AI
passport, User management, Regulation check, Academic use only disclaimer, data
quality assessment, Clinicians double check, Continuous performance evaluation,
Audit trail, Continuous usability test, Review of retrospective/simulated
cases, Bias check, eXplainable AI, Encryption and use of field-tested
libraries, and Semantic interoperability.
  Our intention here is to provide specific high-level specifications of
technical solutions to ensure continuous good performance and use of AI systems
to benefit patients in compliance with the future EU regulatory framework.

ÊëòË¶ÅÔºöÊ≠êÊ¥≤Ë≠∞ÊúÉË≠∞ÊúÉÁ†îÁ©∂ÊúçÂãôÁ∏ΩÂ±ÄÂ∑≤ÁÇ∫Ê≠êÊ¥≤Ë≠∞ÊúÉË≠∞Âì°Ê∫ñÂÇô‰∫Ü‰∏Ä‰ªΩÂ†±ÂëäÔºåÂÖ∂‰∏≠ÂàóËàâ‰∫Ü‰∫∫Â∑•Êô∫ËÉΩ (AI) Âú®ÈÜ´ÁôÇ‰øùÂÅ•È†òÂüüÁöÑ‰∏ÉÈ†Ö‰∏ªË¶ÅÈ¢®Èö™ÔºöAI ÈåØË™§Â∞éËá¥ÊÇ£ËÄÖÂèóÂà∞ÂÇ∑ÂÆ≥„ÄÅÈÜ´ÁôÇ AI Â∑•ÂÖ∑Ë¢´Êø´Áî®„ÄÅAI Â≠òÂú®ÂÅèË¶ã‰∏¶Â∞éËá¥ÁèæÊúâ inequities ÊåÅÁ∫åÂ≠òÂú®„ÄÅÁº∫‰πèÈÄèÊòéÂ∫¶„ÄÅÈö±ÁßÅÂíåÂÆâÂÖ®ÂïèÈ°å„ÄÅÂïèË≤¨Â∑ÆË∑ù‰ª•ÂèäÂØ¶ÊñΩÈöúÁ§ô„ÄÇ
  Âú®ÈÄôÈ†ÖÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫ÜÂçÅÂõõÈ†ÖÂäüËÉΩÊÄßË¶ÅÊ±ÇÔºåAI Á≥ªÁµ±ÂèØ‰ª•ÂØ¶ÊñΩÈÄô‰∫õË¶ÅÊ±Ç‰æÜÈôç‰ΩéËàáÂÖ∂ÈÜ´ÁôÇÁõÆÁöÑÁõ∏ÈóúÁöÑÈ¢®Èö™ÔºöAI Ë≠∑ÁÖß„ÄÅ‰ΩøÁî®ËÄÖÁÆ°ÁêÜ„ÄÅÊ≥ïË¶èÊ™¢Êü•„ÄÅÂÉÖÈôêÂ≠∏Ë°ìÁî®ÈÄîÂÖçË≤¨ËÅ≤Êòé„ÄÅË≥áÊñôÂìÅË≥™Ë©ï‰º∞„ÄÅËá®Â∫äÈÜ´ÁîüÈõôÈáçÊ™¢Êü•„ÄÅÊåÅÁ∫åÊïàËÉΩË©ï‰º∞„ÄÅÁ®ΩÊ†∏ËøΩËπ§„ÄÅÊåÅÁ∫åÂèØÁî®ÊÄßÊ∏¨Ë©¶„ÄÅÂõûÈ°ßÂõûÊ∫Ø/Ê®°Êì¨Ê°à‰æã„ÄÅÂÅèË¶ãÊ™¢Êü•„ÄÅÂèØËß£Èáã AI„ÄÅÂä†ÂØÜÂíå‰ΩøÁî®Á∂ìÈÅéÂØ¶Âú∞Ê∏¨Ë©¶ÁöÑÁ®ãÂºèÂ∫´Ôºå‰ª•ÂèäË™ûÊÑè‰∫íÈÄöÊÄß„ÄÇ
  ÊàëÂÄëÂú®Ê≠§ÁöÑÁõÆÁöÑÊòØÊèê‰æõÊäÄË°ìËß£Ê±∫ÊñπÊ°àÁöÑÁâπÂÆöÈ´òÈöéË¶èÊ†ºÔºå‰ª•Á¢∫‰øùÊåÅÁ∫åËâØÂ•ΩÁöÑÊïàËÉΩÔºå‰∏¶‰ΩøÁî® AI Á≥ªÁµ±Ôºå‰ª•Á¨¶ÂêàÊú™‰æÜÁöÑÊ≠êÁõüÊ≥ïË¶èÊû∂ÊßãÔºåÂæûËÄå‰ΩøÊÇ£ËÄÖÂèóÁõä„ÄÇ

##### **QXAI: Explainable AI Framework for Quantitative Analysis in Patient Monitoring Systems**
2309.10293v3 by Thanveer Shaik, Xiaohui Tao, Haoran Xie, Lin Li, Juan D. Velasquez, Niall Higgins

Artificial Intelligence techniques can be used to classify a patient's
physical activities and predict vital signs for remote patient monitoring.
Regression analysis based on non-linear models like deep learning models has
limited explainability due to its black-box nature. This can require
decision-makers to make blind leaps of faith based on non-linear model results,
especially in healthcare applications. In non-invasive monitoring, patient data
from tracking sensors and their predisposing clinical attributes act as input
features for predicting future vital signs. Explaining the contributions of
various features to the overall output of the monitoring application is
critical for a clinician's decision-making. In this study, an Explainable AI
for Quantitative analysis (QXAI) framework is proposed with post-hoc model
explainability and intrinsic explainability for regression and classification
tasks in a supervised learning approach. This was achieved by utilizing the
Shapley values concept and incorporating attention mechanisms in deep learning
models. We adopted the artificial neural networks (ANN) and attention-based
Bidirectional LSTM (BiLSTM) models for the prediction of heart rate and
classification of physical activities based on sensor data. The deep learning
models achieved state-of-the-art results in both prediction and classification
tasks. Global explanation and local explanation were conducted on input data to
understand the feature contribution of various patient data. The proposed QXAI
framework was evaluated using PPG-DaLiA data to predict heart rate and mobile
health (MHEALTH) data to classify physical activities based on sensor data.
Monte Carlo approximation was applied to the framework to overcome the time
complexity and high computation power requirements required for Shapley value
calculations.

ÊëòË¶ÅÔºö‰∫∫Â∑•Êô∫ÊÖßÊäÄË°ìÂèØÁî®ÊñºÂàÜÈ°ûÁóÖÊÇ£ÁöÑË∫´È´îÊ¥ªÂãï‰∏¶È†êÊ∏¨ÈÅ†Ë∑ùÁóÖÊÇ£Áõ£ÊéßÁöÑÈáçË¶ÅÁîüÂëΩÂæµË±°„ÄÇÂü∫ÊñºÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÁ≠âÈùûÁ∑öÊÄßÊ®°ÂûãÁöÑÂõûÊ≠∏ÂàÜÊûêÁî±ÊñºÂÖ∂ÈªëÁõíÂ≠êÁöÑÊÄßË≥™ËÄåÂÖ∑ÊúâÊúâÈôêÁöÑÂèØËß£ÈáãÊÄß„ÄÇÈÄôÂèØËÉΩÈúÄË¶ÅÊ±∫Á≠ñËÄÖÊ†πÊìöÈùûÁ∑öÊÄßÊ®°ÂûãÁµêÊûúÂÅöÂá∫Áõ≤ÁõÆÁöÑ‰ø°‰ª∞È£õË∫çÔºåÁâπÂà•ÊòØÂú®ÈÜ´ÁôÇ‰øùÂÅ•ÊáâÁî®‰∏≠„ÄÇÂú®Èùû‰æµÂÖ•ÊÄßÁõ£Êéß‰∏≠Ôºå‰æÜËá™ËøΩËπ§ÊÑüÊ∏¨Âô®ÂíåÂÖ∂ÊòìÊÑüËá®Â∫äÂ±¨ÊÄßÁöÑÁóÖÊÇ£Ë≥áÊñôÂÖÖÁï∂È†êÊ∏¨Êú™‰æÜÁîüÂëΩÂæµË±°ÁöÑËº∏ÂÖ•ÁâπÂæµ„ÄÇËß£ÈáãÂêÑÁ®ÆÁâπÂæµÂ∞çÁõ£ÊéßÊáâÁî®Á®ãÂºèÊï¥È´îËº∏Âá∫ÁöÑË≤¢ÁçªÂ∞çÊñºËá®Â∫äÈÜ´ÁîüÁöÑÊ±∫Á≠ñËá≥ÈóúÈáçË¶Å„ÄÇÂú®Êú¨Á†îÁ©∂‰∏≠ÔºåÊèêÂá∫‰∫Ü‰∏ÄÂÄãÁî®ÊñºÈáèÂåñÂàÜÊûêÁöÑÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖß (QXAI) Êû∂ÊßãÔºåË©≤Êû∂ÊßãÂÖ∑ÊúâÁõ£Áù£ÂºèÂ≠∏ÁøíÊñπÊ≥ï‰∏≠ÂõûÊ≠∏ÂíåÂàÜÈ°û‰ªªÂãôÁöÑ‰∫ãÂæåÊ®°ÂûãÂèØËß£ÈáãÊÄßÂíåÂÖßÂú®ÂèØËß£ÈáãÊÄß„ÄÇÈÄôÈÄèÈÅéÂà©Áî® Shapley ÂÄºÊ¶ÇÂøµ‰∏¶Â∞áÊ≥®ÊÑèÂäõÊ©üÂà∂Á¥çÂÖ•Ê∑±Â∫¶Â≠∏ÁøíÊ®°Âûã‰æÜÂØ¶Áèæ„ÄÇÊàëÂÄëÊé°Áî®‰∫∫Â∑•Á•ûÁ∂ìÁ∂≤Ë∑Ø (ANN) ÂíåÂü∫ÊñºÊ≥®ÊÑèÂäõÁöÑÈõôÂêë LSTM (BiLSTM) Ê®°ÂûãÔºåÊ†πÊìöÊÑüÊ∏¨Âô®Ë≥áÊñôÈ†êÊ∏¨ÂøÉÁéáÂíåÂàÜÈ°ûË∫´È´îÊ¥ªÂãï„ÄÇÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÂú®È†êÊ∏¨ÂíåÂàÜÈ°û‰ªªÂãô‰∏≠ÈÉΩÂèñÂæó‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÊàêÊûú„ÄÇÂ∞çËº∏ÂÖ•Ë≥áÊñôÈÄ≤Ë°åÂÖ®Â±ÄËß£ÈáãÂíåÂ±ÄÈÉ®Ëß£ÈáãÔºå‰ª•‰∫ÜËß£ÂêÑÁ®ÆÁóÖÊÇ£Ë≥áÊñôÁöÑÁâπÂæµË≤¢Áçª„ÄÇÊâÄÊèêÂá∫ÁöÑ QXAI Êû∂Êßã‰ΩøÁî® PPG-DaLiA Ë≥áÊñôË©ï‰º∞Ôºå‰ª•È†êÊ∏¨ÂøÉÁéáÔºå‰∏¶‰ΩøÁî®Ë°åÂãïÂÅ•Â∫∑ (MHEALTH) Ë≥áÊñôÊ†πÊìöÊÑüÊ∏¨Âô®Ë≥áÊñôÂ∞çË∫´È´îÊ¥ªÂãïÈÄ≤Ë°åÂàÜÈ°û„ÄÇËíôÂú∞Âç°ÁæÖËøë‰ººÊ≥ïÊáâÁî®ÊñºË©≤Êû∂ÊßãÔºå‰ª•ÂÖãÊúç Shapley ÂÄºË®àÁÆóÊâÄÈúÄÁöÑÊôÇÈñìË§áÈõúÂ∫¶ÂíåÈ´òÈÅãÁÆóËÉΩÂäõÈúÄÊ±Ç„ÄÇ

##### **Evaluation of Human-Understandability of Global Model Explanations using Decision Tree**
2309.09917v1 by Adarsa Sivaprasad, Ehud Reiter, Nava Tintarev, Nir Oren

In explainable artificial intelligence (XAI) research, the predominant focus
has been on interpreting models for experts and practitioners. Model agnostic
and local explanation approaches are deemed interpretable and sufficient in
many applications. However, in domains like healthcare, where end users are
patients without AI or domain expertise, there is an urgent need for model
explanations that are more comprehensible and instil trust in the model's
operations. We hypothesise that generating model explanations that are
narrative, patient-specific and global(holistic of the model) would enable
better understandability and enable decision-making. We test this using a
decision tree model to generate both local and global explanations for patients
identified as having a high risk of coronary heart disease. These explanations
are presented to non-expert users. We find a strong individual preference for a
specific type of explanation. The majority of participants prefer global
explanations, while a smaller group prefers local explanations. A task based
evaluation of mental models of these participants provide valuable feedback to
enhance narrative global explanations. This, in turn, guides the design of
health informatics systems that are both trustworthy and actionable.

ÊëòË¶ÅÔºöÂú®ÂèØËß£Èáä‰∫∫Â∑•Êô∫ËÉΩ (XAI) Á†îÁ©∂‰∏≠Ôºå‰∏ªË¶ÅÈáçÁÇπÂú®‰∫é‰∏∫‰∏ìÂÆ∂Âíå‰ªé‰∏öËÄÖËß£ÈáäÊ®°Âûã„ÄÇÊ®°Âûã‰∏çÂèØÁü•ÂíåÂ±ÄÈÉ®Ëß£ÈáäÊñπÊ≥ïÂú®ËÆ∏Â§öÂ∫îÁî®‰∏≠Ë¢´ËÆ§‰∏∫ÊòØÂèØËß£Èáä‰∏îË∂≥Â§üÁöÑ„ÄÇÁÑ∂ËÄåÔºåÂú®ÂåªÁñó‰øùÂÅ•Á≠âÈ¢ÜÂüüÔºåÊúÄÁªàÁî®Êà∑ÊòØÁº∫‰πè‰∫∫Â∑•Êô∫ËÉΩÊàñÈ¢ÜÂüü‰∏ì‰∏öÁü•ËØÜÁöÑÊÇ£ËÄÖÔºåÂõ†Ê≠§Ëø´ÂàáÈúÄË¶ÅÊõ¥Êòì‰∫éÁêÜËß£‰∏îËÉΩÊøÄÂèëÂØπÊ®°ÂûãÊìç‰ΩúÁöÑ‰ø°‰ªªÁöÑÊ®°ÂûãËß£Èáä„ÄÇÊàë‰ª¨ÂÅáËÆæÁîüÊàêÂèôËø∞ÊÄß„ÄÅÊÇ£ËÄÖÁâπÂÆö‰∏îÂÖ®Â±ÄÔºàÊ®°ÂûãÊï¥‰ΩìÔºâÁöÑÊ®°ÂûãËß£ÈáäÂ∞ÜËÉΩÂ§üÊèêÈ´òÂèØÁêÜËß£ÊÄßÂπ∂ÊîØÊåÅÂÜ≥Á≠ñÂà∂ÂÆö„ÄÇÊàë‰ª¨‰ΩøÁî®ÂÜ≥Á≠ñÊ†ëÊ®°ÂûãÂØπÊ≠§ËøõË°åÊµãËØïÔºå‰∏∫Ë¢´ËØÜÂà´‰∏∫ÊÇ£ÊúâÂÜ†ÂøÉÁóÖÈ´òÈ£éÈô©ÁöÑÊÇ£ËÄÖÁîüÊàêÂ±ÄÈÉ®ÂíåÂÖ®Â±ÄËß£Èáä„ÄÇËøô‰∫õËß£Èáä‰ºöÂëàÁé∞ÁªôÈùû‰∏ìÂÆ∂Áî®Êà∑„ÄÇÊàë‰ª¨ÂèëÁé∞Áî®Êà∑Âº∫ÁÉàÂÅèÂ•ΩÁâπÂÆöÁ±ªÂûãÁöÑËß£Èáä„ÄÇÂ§ßÂ§öÊï∞ÂèÇ‰∏éËÄÖÂÅèÂ•ΩÂÖ®Â±ÄËß£ÈáäÔºåËÄåËæÉÂ∞èÁöÑ‰∏ÄÁªÑÂèÇ‰∏éËÄÖÂÅèÂ•ΩÂ±ÄÈÉ®Ëß£Èáä„ÄÇÂü∫‰∫é‰ªªÂä°ÁöÑÂøÉÁêÜÊ®°ÂûãËØÑ‰º∞‰∏∫Ëøô‰∫õÂèÇ‰∏éËÄÖÊèê‰æõ‰∫ÜÊúâ‰ª∑ÂÄºÁöÑÂèçÈ¶àÔºå‰ª•Â¢ûÂº∫ÂèôËø∞ÊÄßÂÖ®Â±ÄËß£Èáä„ÄÇËøôÂèçËøáÊù•ÂèàÊåáÂØº‰∫ÜÊó¢ÂÄºÂæó‰ø°ËµñÂèàÂèØÊìç‰ΩúÁöÑÂÅ•Â∫∑‰ø°ÊÅØÂ≠¶Á≥ªÁªüÁöÑËÆæËÆ°„ÄÇ

##### **An explainable three dimension framework to uncover learning patterns: A unified look in variable sulci recognition**
2309.00903v2 by Michail Mamalakis, Heloise de Vareilles, Atheer AI-Manea, Samantha C. Mitchell, Ingrid Arartz, Lynn Egeland Morch-Johnsen, Jane Garrison, Jon Simons, Pietro Lio, John Suckling, Graham Murray

Explainable AI is crucial in medical imaging. In the challenging field of
neuroscience, visual topics present a high level of complexity, particularly
within three-dimensional space. The application of neuroscience, which involves
identifying brain sulcal features from MRI, faces significant hurdles due to
varying annotation protocols among experts and the intricate three-dimension
functionality of the brain. Consequently, traditional explainability approaches
fall short in effectively validating and evaluating these networks. To address
this, we first present a mathematical formulation delineating various
categories of explanation needs across diverse computer vision tasks,
categorized into self-explanatory, semi-explanatory, non-explanatory, and
new-pattern learning applications based on the reliability of the validation
protocol. With respect to this mathematical formulation, we propose a 3D
explainability framework aimed at validating the outputs of deep learning
networks in detecting the paracingulate sulcus an essential brain anatomical
feature. The framework integrates local 3D explanations, global explanations
through dimensionality reduction, concatenated global explanations, and
statistical shape features, unveiling new insights into pattern learning. We
trained and tested two advanced 3D deep learning networks on the challenging
TOP-OSLO dataset, significantly improving sulcus detection accuracy,
particularly on the left hemisphere. During evaluation with diverse annotation
protocols for this dataset, we highlighted the crucial role of an unbiased
annotation process in achieving precise predictions and effective pattern
learning within our proposed 3D framework. The proposed framework not only
annotates the variable sulcus but also uncovers hidden AI knowledge, promising
to advance our understanding of brain anatomy and function.

ÊëòË¶ÅÔºö<paragraph>ÂèØËß£Èáã AI Âú®ÈÜ´Â≠∏ÂΩ±ÂÉè‰∏≠Ëá≥ÈóúÈáçË¶Å„ÄÇÂú®Á•ûÁ∂ìÁßëÂ≠∏ÈÄôÂÄãÂÖÖÊªøÊåëÊà∞ÁöÑÈ†òÂüü‰∏≠ÔºåË¶ñË¶∫‰∏ªÈ°åÂëàÁèæÂá∫È´òÂ∫¶ÁöÑË§áÈõúÊÄßÔºåÁâπÂà•ÊòØÂú®‰∏âÁ∂≠Á©∫Èñì‰∏≠„ÄÇÁ•ûÁ∂ìÁßëÂ≠∏ÁöÑÊáâÁî®ÔºåÂåÖÊã¨Âæû MRI Ë≠òÂà•ËÖ¶Ê∫ùÁâπÂæµÔºåÁî±ÊñºÂ∞àÂÆ∂‰πãÈñì‰∏çÂêåÁöÑË®ªËß£ÂçîÂÆöÂíåË§áÈõúÁöÑ‰∏âÁ∂≠Â§ßËÖ¶ÂäüËÉΩÔºåÈù¢Ëá®ÈáçÂ§ßÁöÑÈöúÁ§ô„ÄÇÂõ†Ê≠§ÔºåÂÇ≥Áµ±ÁöÑÂèØËß£ÈáãÊÄßÊñπÊ≥ïÁÑ°Ê≥ïÊúâÊïàÈ©óË≠âÂíåË©ï‰º∞ÈÄô‰∫õÁ∂≤Ë∑Ø„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÈ¶ñÂÖàÊèêÂá∫‰∏ÄÂÄãÊï∏Â≠∏ÂÖ¨ÂºèÔºåÊèèËø∞ÂêÑÁ®ÆÈõªËÖ¶Ë¶ñË¶∫‰ªªÂãô‰∏≠‰∏çÂêåÁöÑËß£ÈáãÈúÄÊ±ÇÈ°ûÂà•ÔºåÊ†πÊìöÈ©óË≠âÂçîÂÆöÁöÑÂèØÈù†ÊÄßÔºåÂ∞áÂÖ∂ÂàÜÈ°ûÁÇ∫Ëá™Ëß£Èáã„ÄÅÂçäËß£Èáã„ÄÅÈùûËß£ÈáãÂíåÊñ∞Ê®°ÂºèÂ≠∏ÁøíÊáâÁî®„ÄÇÈóúÊñºÈÄôÂÄãÊï∏Â≠∏ÂÖ¨ÂºèÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄã 3D ÂèØËß£ÈáãÊÄßÊ°ÜÊû∂ÔºåÊó®Âú®È©óË≠âÊ∑±Â∫¶Â≠∏ÁøíÁ∂≤Ë∑ØÂú®ÂÅµÊ∏¨ÊóÅÊâ£Â∏∂Ê∫ùÔºà‰∏ÄÂÄãÈáçË¶ÅÁöÑËÖ¶ÈÉ®Ëß£ÂâñÁâπÂæµÔºâÁöÑËº∏Âá∫„ÄÇË©≤Ê°ÜÊû∂Êï¥Âêà‰∫ÜÂ±ÄÈÉ® 3D Ëß£Èáã„ÄÅÈÄèÈÅéÈôçÁ∂≠ÁöÑÊï¥È´îËß£Èáã„ÄÅ‰∏≤ËÅØÁöÑÊï¥È´îËß£ÈáãÂíåÁµ±Ë®àÂΩ¢ÁãÄÁâπÂæµÔºåÊè≠Á§∫‰∫ÜÊ®°ÂºèÂ≠∏ÁøíÁöÑÊñ∞Ë¶ãËß£„ÄÇÊàëÂÄëÂú®ÂÖ∑ÊúâÊåëÊà∞ÊÄßÁöÑ TOP-OSLO Ë≥áÊñôÈõÜ‰∏äË®ìÁ∑¥‰∏¶Ê∏¨Ë©¶‰∫ÜÂÖ©ÂÄãÂÖàÈÄ≤ÁöÑ 3D Ê∑±Â∫¶Â≠∏ÁøíÁ∂≤Ë∑ØÔºåÈ°ØËëóÊèêÈ´ò‰∫ÜËÖ¶Ê∫ùÂÅµÊ∏¨ÁöÑÊ∫ñÁ¢∫Â∫¶ÔºåÁâπÂà•ÊòØÂú®Â∑¶ÂçäÁêÉ„ÄÇÂú®‰ΩøÁî®Ê≠§Ë≥áÊñôÈõÜÁöÑ‰∏çÂêåË®ªËß£ÂçîÂÆöÈÄ≤Ë°åË©ï‰º∞ÊôÇÔºåÊàëÂÄëÂº∑Ë™ø‰∫ÜÁÑ°ÂÅèË®ªËß£ÈÅéÁ®ãÂú®ÊàëÂÄëÊèêÂá∫ÁöÑ 3D Ê°ÜÊû∂‰∏≠ÂØ¶ÁèæÁ≤æÁ¢∫È†êÊ∏¨ÂíåÊúâÊïàÊ®°ÂºèÂ≠∏ÁøíÁöÑÈáçË¶Å‰ΩúÁî®„ÄÇÊâÄÊèêÂá∫ÁöÑÊ°ÜÊû∂‰∏çÂÉÖË®ªËß£‰∫ÜÂèØËÆäÁöÑËÖ¶Ê∫ùÔºåÈÇÑÊè≠Á§∫‰∫ÜÈö±ËóèÁöÑ‰∫∫Â∑•Êô∫ÊÖßÁü•Ë≠òÔºåÊúâÊúõÊé®ÈÄ≤ÊàëÂÄëÂ∞çËÖ¶ÈÉ®Ëß£ÂâñÂíåÂäüËÉΩÁöÑÁêÜËß£„ÄÇ</paragraph>

##### **Leveraging A Medical Knowledge Graph into Large Language Models for Diagnosis Prediction**
2308.14321v1 by Yanjun Gao, Ruizhe Li, John Caskey, Dmitriy Dligach, Timothy Miller, Matthew M. Churpek, Majid Afshar

Electronic Health Records (EHRs) and routine documentation practices play a
vital role in patients' daily care, providing a holistic record of health,
diagnoses, and treatment. However, complex and verbose EHR narratives overload
healthcare providers, risking diagnostic inaccuracies. While Large Language
Models (LLMs) have showcased their potential in diverse language tasks, their
application in the healthcare arena needs to ensure the minimization of
diagnostic errors and the prevention of patient harm. In this paper, we outline
an innovative approach for augmenting the proficiency of LLMs in the realm of
automated diagnosis generation, achieved through the incorporation of a medical
knowledge graph (KG) and a novel graph model: Dr.Knows, inspired by the
clinical diagnostic reasoning process. We derive the KG from the National
Library of Medicine's Unified Medical Language System (UMLS), a robust
repository of biomedical knowledge. Our method negates the need for
pre-training and instead leverages the KG as an auxiliary instrument aiding in
the interpretation and summarization of complex medical concepts. Using
real-world hospital datasets, our experimental results demonstrate that the
proposed approach of combining LLMs with KG has the potential to improve the
accuracy of automated diagnosis generation. More importantly, our approach
offers an explainable diagnostic pathway, edging us closer to the realization
of AI-augmented diagnostic decision support systems.

ÊëòË¶ÅÔºöÈõªÂ≠êÂÅ•Â∫∑Á¥ÄÈåÑ (EHR) Âíå‰æãË°åÊñá‰ª∂Ë®òÈåÑÂØ¶ÂãôÂú®ÁóÖÊÇ£ÁöÑÊó•Â∏∏ÁÖßË≠∑‰∏≠ÊâÆÊºîËëóËá≥ÈóúÈáçË¶ÅÁöÑËßíËâ≤ÔºåÊèê‰æõÂÅ•Â∫∑„ÄÅË®∫Êñ∑ÂíåÊ≤ªÁôÇÁöÑÊï¥È´îÁ¥ÄÈåÑ„ÄÇÁÑ∂ËÄåÔºåË§áÈõú‰∏îÂÜóÈï∑ÁöÑ EHR ÊïòËø∞ÊúÉËÆìÈÜ´ÁôÇ‰øùÂÅ•Êèê‰æõËÄÖË∂ÖËºâÔºåÊúâË®∫Êñ∑‰∏çÊ∫ñÁ¢∫ÁöÑÈ¢®Èö™„ÄÇÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤Â±ïÁèæÂÖ∂Âú®ÂêÑÁ®ÆË™ûË®Ä‰ªªÂãô‰∏äÁöÑÊΩõÂäõÔºå‰ΩÜÂÖ∂Âú®ÈÜ´ÁôÇ‰øùÂÅ•È†òÂüüÁöÑÊáâÁî®ÈúÄË¶ÅÁ¢∫‰øùÂ∞áË®∫Êñ∑ÈåØË™§ÈôçÂà∞ÊúÄ‰ΩéÔºå‰∏¶Èò≤Ê≠¢ÁóÖÊÇ£ÂèóÂà∞ÂÇ∑ÂÆ≥„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊ¶ÇËø∞‰∏ÄÁ®ÆÂâµÊñ∞ÁöÑÊñπÊ≥ïÔºåÈÄèÈÅéÊï¥ÂêàÈÜ´Â≠∏Áü•Ë≠òÂúñË≠ú (KG) Âíå‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÂúñË≠úÊ®°ÂûãÔºöDr.KnowsÔºàÈùàÊÑü‰æÜËá™Ëá®Â∫äË®∫Êñ∑Êé®ÁêÜÈÅéÁ®ãÔºâÔºå‰æÜÂ¢ûÂº∑ LLM Âú®Ëá™ÂãïÂåñË®∫Êñ∑Áî¢ÁîüÈ†òÂüüÁöÑËÉΩÂäõ„ÄÇÊàëÂÄëÂæûÁæéÂúãÂúãÂÆ∂ÈÜ´Â≠∏ÂúñÊõ∏È§®ÁöÑÁµ±‰∏ÄÈÜ´Â≠∏Ë™ûË®ÄÁ≥ªÁµ± (UMLS) ‰∏≠Ë°çÁîüÂá∫ KGÔºåÈÄôÊòØ‰∏ÄÂÄãÂº∑Â§ßÁöÑÁîüÁâ©ÈÜ´Â≠∏Áü•Ë≠òÂÑ≤Â≠òÂ∫´„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÂê¶ÂÆö‰∫ÜÈ†êÂÖàË®ìÁ∑¥ÁöÑÈúÄË¶ÅÔºåËÄåÊòØÂ∞á KG ‰ΩúÁÇ∫ËºîÂä©Â∑•ÂÖ∑ÔºåÂçîÂä©Ëß£ÈáãÂíåÁ∏ΩÁµêË§áÈõúÁöÑÈÜ´Â≠∏Ê¶ÇÂøµ„ÄÇ‰ΩøÁî®ÁúüÂØ¶‰∏ñÁïåÁöÑÈÜ´Èô¢Ë≥áÊñôÈõÜÔºåÊàëÂÄëÁöÑÂØ¶È©óÁµêÊûúË≠âÊòéÔºåÂ∞á LLM Ëàá KG ÁµêÂêàÁöÑÂª∫Ë≠∞ÊñπÊ≥ïÊúâÊΩõÂäõÊèêÈ´òËá™ÂãïÂåñË®∫Êñ∑Áî¢ÁîüÁöÑÊ∫ñÁ¢∫ÊÄß„ÄÇÊõ¥ÈáçË¶ÅÁöÑÊòØÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÊèê‰æõ‰∫Ü‰∏ÄÊ¢ùÂèØËß£ÈáãÁöÑË®∫Êñ∑ÈÄîÂæëÔºåËÆìÊàëÂÄëÊõ¥Êé•ËøëÂØ¶Áèæ AI Â¢ûÂº∑ÁöÑË®∫Êñ∑Ê±∫Á≠ñÊîØÊè¥Á≥ªÁµ±„ÄÇ

##### **Deciphering knee osteoarthritis diagnostic features with explainable artificial intelligence: A systematic review**
2308.09380v1 by Yun Xin Teoh, Alice Othmani, Siew Li Goh, Juliana Usman, Khin Wee Lai

Existing artificial intelligence (AI) models for diagnosing knee
osteoarthritis (OA) have faced criticism for their lack of transparency and
interpretability, despite achieving medical-expert-like performance. This
opacity makes them challenging to trust in clinical practice. Recently,
explainable artificial intelligence (XAI) has emerged as a specialized
technique that can provide confidence in the model's prediction by revealing
how the prediction is derived, thus promoting the use of AI systems in
healthcare. This paper presents the first survey of XAI techniques used for
knee OA diagnosis. The XAI techniques are discussed from two perspectives: data
interpretability and model interpretability. The aim of this paper is to
provide valuable insights into XAI's potential towards a more reliable knee OA
diagnosis approach and encourage its adoption in clinical practice.

ÊëòË¶ÅÔºöÁèæÊúâÁöÑÁî®ÊñºË®∫Êñ∑ËÜùÈ™®ÈóúÁØÄÁÇé (OA) ÁöÑ‰∫∫Â∑•Êô∫ÊÖß (AI) Ê®°ÂûãÂõ†ÂÖ∂Áº∫‰πèÈÄèÊòéÂ∫¶ÂíåÂèØËß£ÈáãÊÄßËÄåÂèóÂà∞ÊâπË©ïÔºåÂÑòÁÆ°ÂÆÉÂÄëÈÅîÂà∞‰∫ÜÈ°û‰ººÈÜ´Â≠∏Â∞àÂÆ∂ÁöÑË°®Áèæ„ÄÇÈÄôÁ®Æ‰∏çÈÄèÊòéÊÄß‰ΩøÂæóÂÆÉÂÄëÂú®Ëá®Â∫äÂØ¶Âãô‰∏≠Èõ£‰ª•Ë¢´‰ø°‰ªª„ÄÇÊúÄËøëÔºåÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖß (XAI) Â∑≤ÊàêÁÇ∫‰∏ÄÁ®ÆÂ∞àÈñÄÊäÄË°ìÔºåÂÆÉËÉΩÈÄèÈÅéÊè≠Á§∫È†êÊ∏¨ÁöÑÊé®Â∞éÊñπÂºè‰æÜÊèê‰æõÂ∞çÊ®°ÂûãÈ†êÊ∏¨ÁöÑ‰ø°ÂøÉÔºåÂæûËÄå‰øÉÈÄ≤Âú®ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠‰ΩøÁî® AI Á≥ªÁµ±„ÄÇÊú¨ÊñáÊèê‰æõ‰∫ÜÈáùÂ∞çËÜùÈ™®ÈóúÁØÄÁÇéË®∫Êñ∑ÊâÄ‰ΩøÁî®ÁöÑ XAI ÊäÄË°ìÁöÑÁ¨¨‰∏Ä‰ªΩË™øÊü•„ÄÇXAI ÊäÄË°ìÂæûÂÖ©ÂÄãËßíÂ∫¶ÈÄ≤Ë°åË®éË´ñÔºöË≥áÊñôÂèØËß£ÈáãÊÄßÂíåÊ®°ÂûãÂèØËß£ÈáãÊÄß„ÄÇÊú¨ÊñáÁöÑÁõÆÁöÑÊòØÊèê‰æõÂ∞ç XAI Âú®Êõ¥ÂèØÈù†ÁöÑËÜùÈ™®ÈóúÁØÄÁÇéË®∫Êñ∑ÊñπÊ≥ï‰∏≠ÁöÑÊΩõÂäõÁöÑÂØ∂Ë≤¥Ë¶ãËß£Ôºå‰∏¶ÈºìÂãµÂú®Ëá®Â∫äÂØ¶Âãô‰∏≠Êé°Áî®ÂÆÉ„ÄÇ

##### **Explainable AI for clinical risk prediction: a survey of concepts, methods, and modalities**
2308.08407v1 by Munib Mesinovic, Peter Watkinson, Tingting Zhu

Recent advancements in AI applications to healthcare have shown incredible
promise in surpassing human performance in diagnosis and disease prognosis.
With the increasing complexity of AI models, however, concerns regarding their
opacity, potential biases, and the need for interpretability. To ensure trust
and reliability in AI systems, especially in clinical risk prediction models,
explainability becomes crucial. Explainability is usually referred to as an AI
system's ability to provide a robust interpretation of its decision-making
logic or the decisions themselves to human stakeholders. In clinical risk
prediction, other aspects of explainability like fairness, bias, trust, and
transparency also represent important concepts beyond just interpretability. In
this review, we address the relationship between these concepts as they are
often used together or interchangeably. This review also discusses recent
progress in developing explainable models for clinical risk prediction,
highlighting the importance of quantitative and clinical evaluation and
validation across multiple common modalities in clinical practice. It
emphasizes the need for external validation and the combination of diverse
interpretability methods to enhance trust and fairness. Adopting rigorous
testing, such as using synthetic datasets with known generative factors, can
further improve the reliability of explainability methods. Open access and
code-sharing resources are essential for transparency and reproducibility,
enabling the growth and trustworthiness of explainable research. While
challenges exist, an end-to-end approach to explainability in clinical risk
prediction, incorporating stakeholders from clinicians to developers, is
essential for success.

ÊëòË¶ÅÔºöÊúÄËøëÂú®ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÁöÑ‰∫∫Â∑•Êô∫ÊÖßÊáâÁî®ÈÄ≤Â±ïÈ°ØÁ§∫Âá∫‰ª§‰∫∫Èõ£‰ª•ÁΩÆ‰ø°ÁöÑÊâøË´æÔºåÂú®Ë®∫Êñ∑ÂíåÁñæÁóÖÈ†êÂæåÊñπÈù¢Ë∂ÖË∂ä‰∫∫È°ûË°®Áèæ„ÄÇÁÑ∂ËÄåÔºåÈö®Ëëó‰∫∫Â∑•Êô∫ËÉΩÊ®°ÂûãÁöÑÊó•ÁõäË§áÈõúÔºå‰∫∫ÂÄëÂ∞çÂÖ∂‰∏çÈÄèÊòéÊÄß„ÄÅÊΩõÂú®ÂÅèÂ∑ÆÂíåÂ∞çÂèØËß£ÈáãÊÄßÁöÑÈúÄÊ±ÇÊÑüÂà∞ÊìîÊÜÇ„ÄÇÁÇ∫‰∫ÜÁ¢∫‰øù‰∫∫Â∑•Êô∫ËÉΩÁ≥ªÁµ±ÁöÑ‰ø°‰ªªÂíåÂèØÈù†ÊÄßÔºåÂ∞§ÂÖ∂ÊòØÂú®Ëá®Â∫äÈ¢®Èö™È†êÊ∏¨Ê®°Âûã‰∏≠ÔºåÂèØËß£ÈáãÊÄßËÆäÂæóËá≥ÈóúÈáçË¶Å„ÄÇÂèØËß£ÈáãÊÄßÈÄöÂ∏∏Ë¢´Á®±ÁÇ∫‰∫∫Â∑•Êô∫ËÉΩÁ≥ªÁµ±Êèê‰æõÂÖ∂Ê±∫Á≠ñÈÇèËºØÊàñÊ±∫Á≠ñÊú¨Ë∫´Â∞ç‰∫∫È°ûÂà©ÁõäÁõ∏ÈóúËÄÖÁöÑÂº∑ÊúâÂäõËß£ÈáãÁöÑËÉΩÂäõ„ÄÇÂú®Ëá®Â∫äÈ¢®Èö™È†êÊ∏¨‰∏≠ÔºåÂèØËß£ÈáãÊÄßÁöÑÂÖ∂‰ªñÊñπÈù¢ÔºåÂ¶ÇÂÖ¨Âπ≥ÊÄß„ÄÅÂÅèË¶ã„ÄÅ‰ø°‰ªªÂíåÈÄèÊòéÂ∫¶Ôºå‰πü‰ª£Ë°®‰∫ÜË∂ÖË∂äÂèØËß£ÈáãÊÄßÁöÑÈáçË¶ÅÊ¶ÇÂøµ„ÄÇÂú®Êú¨Ê¨°ÂØ©Êü•‰∏≠ÔºåÊàëÂÄëÊé¢Ë®é‰∫ÜÈÄô‰∫õÊ¶ÇÂøµ‰πãÈñìÁöÑÈóú‰øÇÔºåÂõ†ÁÇ∫ÂÆÉÂÄëÁ∂ìÂ∏∏‰∏ÄËµ∑Êàñ‰∫íÊèõ‰ΩøÁî®„ÄÇÊú¨ÂØ©Êü•ÈÇÑË®éË´ñ‰∫ÜÁÇ∫Ëá®Â∫äÈ¢®Èö™È†êÊ∏¨ÈñãÁôºÂèØËß£ÈáãÊ®°ÂûãÁöÑÊúÄÊñ∞ÈÄ≤Â±ïÔºåÂº∑Ë™ø‰∫ÜÂú®Ëá®Â∫äÂØ¶Ë∏ê‰∏≠Â∞çÂ§öÁ®ÆÂ∏∏Ë¶ãÊ®°ÂºèÈÄ≤Ë°åÂÆöÈáèÂíåËá®Â∫äË©ï‰º∞ÂíåÈ©óË≠âÁöÑÈáçË¶ÅÊÄß„ÄÇÂÆÉÂº∑Ë™ø‰∫ÜÂ§ñÈÉ®È©óË≠âÂíåÂ§öÊ®£ÂåñÂèØËß£ÈáãÊÄßÊñπÊ≥ïÁõ∏ÁµêÂêàÁöÑÂøÖË¶ÅÊÄßÔºå‰ª•Â¢ûÂº∑‰ø°‰ªªÂíåÂÖ¨Âπ≥ÊÄß„ÄÇÊé°Áî®Âö¥Ê†ºÁöÑÊ∏¨Ë©¶Ôºå‰æãÂ¶Ç‰ΩøÁî®ÂÖ∑ÊúâÂ∑≤Áü•ÁîüÊàêÂõ†Á¥†ÁöÑÂêàÊàêÊï∏ÊìöÈõÜÔºåÂèØ‰ª•ÈÄ≤‰∏ÄÊ≠•ÊèêÈ´òÂèØËß£ÈáãÊÄßÊñπÊ≥ïÁöÑÂèØÈù†ÊÄß„ÄÇÈñãÊîæÁç≤ÂèñÂíå‰ª£Á¢ºÂÖ±‰∫´Ë≥áÊ∫êÂ∞çÊñºÈÄèÊòéÂ∫¶ÂíåÂèØÈáçË§áÊÄßËá≥ÈóúÈáçË¶ÅÔºåÂæûËÄå‰øÉÈÄ≤ÂèØËß£ÈáãÁ†îÁ©∂ÁöÑÂ¢ûÈï∑ÂíåÂèØ‰ø°Â∫¶„ÄÇÂÑòÁÆ°Â≠òÂú®ÊåëÊà∞Ôºå‰ΩÜÂæûËá®Â∫äÈÜ´ÁîüÂà∞ÈñãÁôº‰∫∫Âì°ÔºåÊé°Áî®Á´ØÂà∞Á´ØÁöÑÂèØËß£ÈáãÊÄßÊñπÊ≥ïÂ∞çÊñºËá®Â∫äÈ¢®Èö™È†êÊ∏¨ÁöÑÊàêÂäüËá≥ÈóúÈáçË¶Å„ÄÇ

##### **FUTURE-AI: International consensus guideline for trustworthy and deployable artificial intelligence in healthcare**
2309.12325v1 by Karim Lekadir, Aasa Feragen, Abdul Joseph Fofanah, Alejandro F Frangi, Alena Buyx, Anais Emelie, Andrea Lara, Antonio R Porras, An-Wen Chan, Arcadi Navarro, Ben Glocker, Benard O Botwe, Bishesh Khanal, Brigit Beger, Carol C Wu, Celia Cintas, Curtis P Langlotz, Daniel Rueckert, Deogratias Mzurikwao, Dimitrios I Fotiadis, Doszhan Zhussupov, Enzo Ferrante, Erik Meijering, Eva Weicken, Fabio A Gonz√°lez, Folkert W Asselbergs, Fred Prior, Gabriel P Krestin, Gary Collins, Geletaw S Tegenaw, Georgios Kaissis, Gianluca Misuraca, Gianna Tsakou, Girish Dwivedi, Haridimos Kondylakis, Harsha Jayakody, Henry C Woodruf, Hugo JWL Aerts, Ian Walsh, Ioanna Chouvarda, Ir√®ne Buvat, Islem Rekik, James Duncan, Jayashree Kalpathy-Cramer, Jihad Zahir, Jinah Park, John Mongan, Judy W Gichoya, Julia A Schnabel, Kaisar Kushibar, Katrine Riklund, Kensaku Mori, Kostas Marias, Lameck M Amugongo, Lauren A Fromont, Lena Maier-Hein, Leonor Cerd√° Alberich, Leticia Rittner, Lighton Phiri, Linda Marrakchi-Kacem, Llu√≠s Donoso-Bach, Luis Mart√≠-Bonmat√≠, M Jorge Cardoso, Maciej Bobowicz, Mahsa Shabani, Manolis Tsiknakis, Maria A Zuluaga, Maria Bielikova, Marie-Christine Fritzsche, Marius George Linguraru, Markus Wenzel, Marleen De Bruijne, Martin G Tolsgaard, Marzyeh Ghassemi, Md Ashrafuzzaman, Melanie Goisauf, Mohammad Yaqub, Mohammed Ammar, M√≥nica Cano Abad√≠a, Mukhtar M E Mahmoud, Mustafa Elattar, Nicola Rieke, Nikolaos Papanikolaou, Noussair Lazrak, Oliver D√≠az, Olivier Salvado, Oriol Pujol, Ousmane Sall, Pamela Guevara, Peter Gordebeke, Philippe Lambin, Pieta Brown, Purang Abolmaesumi, Qi Dou, Qinghua Lu, Richard Osuala, Rose Nakasi, S Kevin Zhou, Sandy Napel, Sara Colantonio, Shadi Albarqouni, Smriti Joshi, Stacy Carter, Stefan Klein, Steffen E Petersen, Susanna Auss√≥, Suyash Awate, Tammy Riklin Raviv, Tessa Cook, Tinashe E M Mutsvangwa, Wendy A Rogers, Wiro J Niessen, X√®nia Puig-Bosch, Yi Zeng, Yunusa G Mohammed, Yves Saint James Aquino, Zohaib Salahuddin, Martijn P A Starmans

Despite major advances in artificial intelligence (AI) for medicine and
healthcare, the deployment and adoption of AI technologies remain limited in
real-world clinical practice. In recent years, concerns have been raised about
the technical, clinical, ethical and legal risks associated with medical AI. To
increase real world adoption, it is essential that medical AI tools are trusted
and accepted by patients, clinicians, health organisations and authorities.
This work describes the FUTURE-AI guideline as the first international
consensus framework for guiding the development and deployment of trustworthy
AI tools in healthcare. The FUTURE-AI consortium was founded in 2021 and
currently comprises 118 inter-disciplinary experts from 51 countries
representing all continents, including AI scientists, clinicians, ethicists,
and social scientists. Over a two-year period, the consortium defined guiding
principles and best practices for trustworthy AI through an iterative process
comprising an in-depth literature review, a modified Delphi survey, and online
consensus meetings. The FUTURE-AI framework was established based on 6 guiding
principles for trustworthy AI in healthcare, i.e. Fairness, Universality,
Traceability, Usability, Robustness and Explainability. Through consensus, a
set of 28 best practices were defined, addressing technical, clinical, legal
and socio-ethical dimensions. The recommendations cover the entire lifecycle of
medical AI, from design, development and validation to regulation, deployment,
and monitoring. FUTURE-AI is a risk-informed, assumption-free guideline which
provides a structured approach for constructing medical AI tools that will be
trusted, deployed and adopted in real-world practice. Researchers are
encouraged to take the recommendations into account in proof-of-concept stages
to facilitate future translation towards clinical practice of medical AI.

ÊëòË¶ÅÔºöÂÑòÁÆ°Âú®ÈÜ´Â≠∏ÂíåÈÜ´ÁôÇ‰øùÂÅ•ÊñπÈù¢ÁöÑ‰∫∫Â∑•Êô∫ÊÖß (AI) ÊúâÈáçÂ§ßÈÄ≤Â±ïÔºå‰ΩÜ AI ÊäÄË°ìÁöÑÈÉ®ÁΩ≤ÂíåÊé°Áî®Âú®ÁèæÂØ¶‰∏ñÁïåÁöÑËá®Â∫äÂØ¶Âãô‰∏≠‰ªçÁÑ∂ÊúâÈôê„ÄÇËøëÂπ¥‰æÜÔºå‰∫∫ÂÄëÂ∞çËàáÈÜ´ÁôÇ AI Áõ∏ÈóúÁöÑÊäÄË°ì„ÄÅËá®Â∫ä„ÄÅÂÄ´ÁêÜÂíåÊ≥ïÂæãÈ¢®Èö™ÊèêÂá∫‰∫ÜÁñëÊÖÆ„ÄÇÁÇ∫‰∫ÜÂ¢ûÂä†ÂØ¶Èöõ‰∏ñÁïåÁöÑÊé°Áî®ÁéáÔºåÈÜ´ÁôÇ AI Â∑•ÂÖ∑ÂøÖÈ†àÁç≤ÂæóÊÇ£ËÄÖ„ÄÅËá®Â∫äÈÜ´Áîü„ÄÅÈÜ´ÁôÇÊ©üÊßãÂíåÁï∂Â±ÄÁöÑ‰ø°‰ªªÂíåÊé•Âèó„ÄÇÊú¨Á†îÁ©∂Â∞á FUTURE-AI ÊåáÂçóÊèèËø∞ÁÇ∫ÊåáÂ∞éÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÂèØ‰ø°Ë≥¥ AI Â∑•ÂÖ∑ÈñãÁôºÂíåÈÉ®ÁΩ≤ÁöÑÁ¨¨‰∏ÄÂÄãÂúãÈöõÂÖ±Ë≠òÊ°ÜÊû∂„ÄÇFUTURE-AI ËÅØÁõüÊàêÁ´ãÊñº 2021 Âπ¥ÔºåÁõÆÂâçÁî±‰æÜËá™ 51 ÂÄãÂúãÂÆ∂/Âú∞ÂçÄÁöÑ 118 ‰ΩçË∑®È†òÂüüÂ∞àÂÆ∂ÁµÑÊàêÔºå‰ª£Ë°®ÊâÄÊúâÊ¥≤ÔºåÂåÖÊã¨ AI ÁßëÂ≠∏ÂÆ∂„ÄÅËá®Â∫äÈÜ´Áîü„ÄÅÂÄ´ÁêÜÂ≠∏ÂÆ∂ÂíåÁ§æÊúÉÁßëÂ≠∏ÂÆ∂„ÄÇÂú®ÂÖ©Âπ¥ÁöÑÊôÇÈñìË£°ÔºåË©≤ËÅØÁõüÈÄöÈÅé‰∏ÄÂÄãÂèçË¶ÜÈÅãÁÆóÁöÑÈÅéÁ®ãÂÆöÁæ©‰∫ÜÂèØ‰ø°Ë≥¥ AI ÁöÑÊåáÂ∞éÂéüÂâáÂíåÊúÄ‰Ω≥ÂØ¶ÂãôÔºåÂåÖÊã¨Ê∑±ÂÖ•ÁöÑÊñáÁçªÂõûÈ°ß„ÄÅ‰øÆÊîπÂæåÁöÑÂæ∑ÁàæËè≤Ë™øÊü•ÂíåÁ∑ö‰∏äÂÖ±Ë≠òÊúÉË≠∞„ÄÇFUTURE-AI Ê°ÜÊû∂ÊòØÂü∫ÊñºÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÂèØ‰ø°Ë≥¥ AI ÁöÑ 6 È†ÖÊåáÂ∞éÂéüÂâáÂª∫Á´ãÁöÑÔºåÂç≥ÂÖ¨Âπ≥ÊÄß„ÄÅÊôÆÈÅçÊÄß„ÄÅÂèØËøΩÊ∫ØÊÄß„ÄÅÂèØÁî®ÊÄß„ÄÅÂÅ•Â£ØÊÄßÂíåÂèØËß£ÈáãÊÄß„ÄÇÈÄöÈÅéÂÖ±Ë≠òÔºåÂÆöÁæ©‰∫Ü‰∏ÄÁµÑ 28 È†ÖÊúÄ‰Ω≥ÂØ¶ÂãôÔºåÊ∂µËìãÊäÄË°ì„ÄÅËá®Â∫ä„ÄÅÊ≥ïÂæãÂíåÁ§æÊúÉÂÄ´ÁêÜÂ±§Èù¢„ÄÇÂª∫Ë≠∞Ê∂µËìã‰∫ÜÈÜ´ÁôÇ AI ÁöÑÊï¥ÂÄãÁîüÂëΩÈÄ±ÊúüÔºåÂæûË®≠Ë®à„ÄÅÈñãÁôºÂíåÈ©óË≠âÂà∞Ê≥ïË¶è„ÄÅÈÉ®ÁΩ≤ÂíåÁõ£Êéß„ÄÇFUTURE-AI ÊòØ‰∏ÄÂÄãÂü∫ÊñºÈ¢®Èö™„ÄÅÁÑ°ÂÅáË®≠ÁöÑÊåáÂçóÔºåÂÆÉÊèê‰æõ‰∫Ü‰∏ÄÂÄãÁµêÊßãÂåñÁöÑÊñπÊ≥ï‰æÜÊßãÂª∫ÂèØ‰ø°Ë≥¥„ÄÅÈÉ®ÁΩ≤ÂíåÊé°Áî®ÊñºÁèæÂØ¶‰∏ñÁïåÂØ¶Âãô‰∏≠ÁöÑÈÜ´ÁôÇ AI Â∑•ÂÖ∑„ÄÇÈºìÂãµÁ†îÁ©∂‰∫∫Âì°Âú®Ê¶ÇÂøµÈ©óË≠âÈöéÊÆµËÄÉÊÖÆÂª∫Ë≠∞Ôºå‰ª•‰øÉÈÄ≤Êú™‰æÜÂ∞áÈÜ´ÁôÇ AI ËΩâÂåñÁÇ∫Ëá®Â∫äÂØ¶Âãô„ÄÇ

##### **Explainable AI applications in the Medical Domain: a systematic review**
2308.05411v1 by Nicoletta Prentzas, Antonis Kakas, Constantinos S. Pattichis

Artificial Intelligence in Medicine has made significant progress with
emerging applications in medical imaging, patient care, and other areas. While
these applications have proven successful in retrospective studies, very few of
them were applied in practice.The field of Medical AI faces various challenges,
in terms of building user trust, complying with regulations, using data
ethically.Explainable AI (XAI) aims to enable humans understand AI and trust
its results. This paper presents a literature review on the recent developments
of XAI solutions for medical decision support, based on a representative sample
of 198 articles published in recent years. The systematic synthesis of the
relevant articles resulted in several findings. (1) model-agnostic XAI
techniques were mostly employed in these solutions, (2) deep learning models
are utilized more than other types of machine learning models, (3)
explainability was applied to promote trust, but very few works reported the
physicians participation in the loop, (4) visual and interactive user interface
is more useful in understanding the explanation and the recommendation of the
system. More research is needed in collaboration between medical and AI
experts, that could guide the development of suitable frameworks for the
design, implementation, and evaluation of XAI solutions in medicine.

ÊëòË¶ÅÔºö‰∫∫Â∑•Êô∫ÊÖßÂú®ÈÜ´ÁôÇÈ†òÂüü‰∏≠Â∑≤ÂèñÂæóÈ°ØËëóÈÄ≤Â±ïÔºåÂú®ÈÜ´Â≠∏ÂΩ±ÂÉè„ÄÅÁóÖ‰∫∫ÁÖßË≠∑ÂíåÂÖ∂‰ªñÈ†òÂüü‰∏≠Âá∫Áèæ‰∫ÜÊñ∞ËààÊáâÁî®„ÄÇÈõñÁÑ∂ÈÄô‰∫õÊáâÁî®Â∑≤Âú®ÂõûÈ°ßÊÄßÁ†îÁ©∂‰∏≠Ë¢´Ë≠âÂØ¶ÊòØÊàêÂäüÁöÑÔºå‰ΩÜÂØ¶Èöõ‰∏äÂè™ÊúâÊ•µÂ∞ëÊï∏ÊáâÁî®ÊñºÂØ¶Âãô„ÄÇÈÜ´ÁôÇ AI È†òÂüüÈù¢Ëá®ËëóÂêÑÁ®ÆÊåëÊà∞ÔºåÂåÖÊã¨Âª∫Á´ã‰ΩøÁî®ËÄÖ‰ø°‰ªª„ÄÅÈÅµÂÆàÊ≥ïË¶è„ÄÅ‰ΩøÁî®Ë≥áÊñôÁ¨¶ÂêàÂÄ´ÁêÜ„ÄÇÂèØËß£Èáã AI (XAI) ÁöÑÁõÆÊ®ôÊòØËÆì‰∫∫È°û‰∫ÜËß£ AI ‰∏¶Áõ∏‰ø°ÂÖ∂ÁµêÊûú„ÄÇÊú¨ÊñáÈáùÂ∞çÊúÄËøëÂπæÂπ¥ÁôºË°®ÁöÑ 198 ÁØáÊñáÁ´†ÁöÑÂÖ∑‰ª£Ë°®ÊÄßÊ®£Êú¨ÔºåÊèêÂá∫ÊúâÈóúÈÜ´ÁôÇÊ±∫Á≠ñÊîØÊè¥ÁöÑ XAI Ëß£Ê±∫ÊñπÊ°àÁöÑÊúÄÊñ∞ÁôºÂ±ïÁöÑÊñáÁçªÂõûÈ°ß„ÄÇÁõ∏ÈóúÊñáÁ´†ÁöÑÁ≥ªÁµ±ÊÄßÁ∂úÂêàÊï¥ÁêÜÁî¢Áîü‰∫ÜÂ§öÈ†ÖÁôºÁèæÔºö(1) ÈÄô‰∫õËß£Ê±∫ÊñπÊ°àÂ§ßÂ§öÊé°Áî®ËàáÊ®°ÂûãÁÑ°ÈóúÁöÑ XAI ÊäÄË°ìÔºå(2) Ê∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÁöÑ‰ΩøÁî®ÁéáÈ´òÊñºÂÖ∂‰ªñÈ°ûÂûãÁöÑÊ©üÂô®Â≠∏ÁøíÊ®°ÂûãÔºå(3) ÂèØËß£ÈáãÊÄßË¢´Áî®Êñº‰øÉÈÄ≤‰ø°‰ªªÔºå‰ΩÜÂæàÂ∞ëÊúâÁ†îÁ©∂Â†±ÂëäÈÜ´Â∏´ÂèÉËàáËø¥ÂúàÔºå(4) Ë¶ñË¶∫Âíå‰∫íÂãïÂºè‰ΩøÁî®ËÄÖ‰ªãÈù¢Â∞çÊñºÁêÜËß£Á≥ªÁµ±ÁöÑËß£ÈáãÂíåÂª∫Ë≠∞Êõ¥ÊúâÁî®„ÄÇÈúÄË¶ÅÊõ¥Â§öÈÜ´ÁôÇÂíå AI Â∞àÂÆ∂Âêà‰ΩúÈÄ≤Ë°åÁ†îÁ©∂ÔºåÈÄôÊúâÂä©ÊñºÁÇ∫ÈÜ´ÁôÇÈ†òÂüüÁöÑ XAI Ëß£Ê±∫ÊñπÊ°àÁöÑË®≠Ë®à„ÄÅÂØ¶‰ΩúÂíåË©ï‰º∞Êèê‰æõÈÅ©Áï∂Êû∂Êßã„ÄÇ

##### **Exploring the Role of Explainability in AI-Assisted Embryo Selection**
2308.02534v1 by Lucia Urcelay, Daniel Hinjos, Pablo A. Martin-Torres, Marta Gonzalez, Marta Mendez, Salva C√≠vico, Sergio √Ålvarez-Napagao, Dario Garcia-Gasulla

In Vitro Fertilization is among the most widespread treatments for
infertility. One of its main challenges is the evaluation and selection of
embryo for implantation, a process with large inter- and intra-clinician
variability. Deep learning based methods are gaining attention, but their
opaque nature compromises their acceptance in the clinical context, where
transparency in the decision making is key. In this paper we analyze the
current work in the explainability of AI-assisted embryo analysis models,
identifying the limitations. We also discuss how these models could be
integrated in the clinical context as decision support systems, considering the
needs of clinicians and patients. Finally, we propose guidelines for the sake
of increasing interpretability and trustworthiness, pushing this technology
forward towards established clinical practice.

ÊëòË¶ÅÔºöÈ´îÂ§ñÂèóÁ≤æÊòØÊ≤ªÁôÇ‰∏çÂ≠ïÁóáÊúÄÂª£Ê≥õÁöÑÊñπÊ≥ï‰πã‰∏Ä„ÄÇÂÖ∂‰∏ªË¶ÅÊåëÊà∞‰πã‰∏ÄÊòØË©ï‰º∞ÂíåÈÅ∏ÊìáËÉöËÉéÈÄ≤Ë°åÊ§çÂÖ•ÔºåÊ≠§ÈÅéÁ®ãÂÖ∑ÊúâÂæàÂ§ßÁöÑËá®Â∫äÈñìÂíåËá®Â∫äÂÖßËÆäÁï∞ÊÄß„ÄÇÂü∫ÊñºÊ∑±Â∫¶Â≠∏ÁøíÁöÑÊñπÊ≥ïÊ≠£ÂèóÂà∞ÈóúÊ≥®Ôºå‰ΩÜÂÖ∂‰∏çÈÄèÊòéÁöÑÊÄßË≥™ÊúÉÂΩ±ÈüøÂÖ∂Âú®Ëá®Â∫äÁí∞Â¢É‰∏≠ÁöÑÊé•ÂèóÂ∫¶ÔºåËÄåÈÄèÊòéÂ∫¶Âú®Ê±∫Á≠ñÂà∂ÂÆö‰∏≠Ëá≥ÈóúÈáçË¶Å„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂàÜÊûê‰∫Ü AI ËºîÂä©ËÉöËÉéÂàÜÊûêÊ®°ÂûãÁöÑÂèØËß£ÈáãÊÄßÊñπÈù¢ÁöÑÁèæÊúâÂ∑•‰ΩúÔºå‰∏¶ÊâæÂá∫ÂÖ∂Â±ÄÈôêÊÄß„ÄÇÊàëÂÄëÈÇÑË®éË´ñ‰∫ÜÂ¶Ç‰ΩïÂ∞áÈÄô‰∫õÊ®°Âûã‰ΩúÁÇ∫Ê±∫Á≠ñÊîØÊåÅÁ≥ªÁµ±Êï¥ÂêàÂà∞Ëá®Â∫äÁí∞Â¢É‰∏≠ÔºåÂêåÊôÇËÄÉÊÖÆËá®Â∫äÈÜ´ÁîüÂíåÊÇ£ËÄÖÁöÑÈúÄÊ±Ç„ÄÇÊúÄÂæåÔºåÊàëÂÄëÊèêÂá∫‰∫ÜÊèêÈ´òÂèØËß£ÈáãÊÄßÂíåÂèØ‰ø°Â∫¶ÁöÑÊ∫ñÂâáÔºåÊé®ÈÄ≤ÈÄôÈ†ÖÊäÄË°ìÊúùËëóÊó¢ÂÆöÁöÑËá®Â∫äÂØ¶ÂãôÈÇÅÈÄ≤„ÄÇ

##### **A New Perspective on Evaluation Methods for Explainable Artificial Intelligence (XAI)**
2307.14246v1 by Timo Speith, Markus Langer

Within the field of Requirements Engineering (RE), the increasing
significance of Explainable Artificial Intelligence (XAI) in aligning
AI-supported systems with user needs, societal expectations, and regulatory
standards has garnered recognition. In general, explainability has emerged as
an important non-functional requirement that impacts system quality. However,
the supposed trade-off between explainability and performance challenges the
presumed positive influence of explainability. If meeting the requirement of
explainability entails a reduction in system performance, then careful
consideration must be given to which of these quality aspects takes precedence
and how to compromise between them. In this paper, we critically examine the
alleged trade-off. We argue that it is best approached in a nuanced way that
incorporates resource availability, domain characteristics, and considerations
of risk. By providing a foundation for future research and best practices, this
work aims to advance the field of RE for AI.

ÊëòË¶ÅÔºöÂú®ÈúÄÊ±ÇÂ∑•Á®ã (RE) È†òÂüü‰∏≠ÔºåÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖß (XAI) Âú®Â∞á AI ÊîØÊåÅÁöÑÁ≥ªÁµ±Ëàá‰ΩøÁî®ËÄÖÈúÄÊ±Ç„ÄÅÁ§æÊúÉÊúüÊúõÂíåÊ≥ïË¶èÊ®ôÊ∫ñÁõ∏Á¨¶ÊñπÈù¢ÁöÑÈáçË¶ÅÊÄßÊó•ÁõäÈ°ØËëóÔºåÂ∑≤Áç≤ÂæóË™çÂèØ„ÄÇ‰∏ÄËà¨‰æÜË™™ÔºåÂèØËß£ÈáãÊÄßÂ∑≤ÊàêÁÇ∫ÂΩ±ÈüøÁ≥ªÁµ±ÂìÅË≥™ÁöÑÈáçË¶ÅÈùûÂäüËÉΩÈúÄÊ±Ç„ÄÇÁÑ∂ËÄåÔºåÂèØËß£ÈáãÊÄßËàáÊïàËÉΩ‰πãÈñìÁöÑÂÅáÂÆöÊ¨äË°°ÊåëÊà∞‰∫ÜÂèØËß£ÈáãÊÄßÁöÑÂÅáÂÆöÊ≠£Èù¢ÂΩ±Èüø„ÄÇÂ¶ÇÊûúÊªøË∂≥ÂèØËß£ÈáãÊÄßÁöÑÈúÄÊ±ÇÈúÄË¶ÅÈôç‰ΩéÁ≥ªÁµ±ÊïàËÉΩÔºåÈÇ£È∫ºÂøÖÈ†à‰ªîÁ¥∞ËÄÉÊÖÆÈÄô‰∫õÂìÅË≥™Èù¢Âêë‰∏≠Âì™‰∏ÄÂÄãÂÑ™ÂÖàÔºå‰ª•ÂèäÂ¶Ç‰ΩïÂú®ÂÆÉÂÄë‰πãÈñìÈÄ≤Ë°åÊäòË°∑„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊâπÂà§ÊÄßÂú∞Êé¢Ë®é‰∫ÜÈÄôÁ®ÆÂÅáÂÆöÁöÑÊ¨äË°°„ÄÇÊàëÂÄëË™çÁÇ∫ÔºåÊúÄÂ•ΩÁöÑÊñπÊ≥ïÊòØ‰ª•‰∏ÄÁ®ÆÁ¥∞Á∑ªÁöÑÊñπÂºè‰æÜËôïÁêÜÔºåÈÄôÁ®ÆÊñπÂºèÂåÖÂê´Ë≥áÊ∫êÂèØÁî®ÊÄß„ÄÅÈ†òÂüüÁâπÊÄßÂíåÈ¢®Èö™ËÄÉÈáè„ÄÇÈÄèÈÅéÊèê‰æõÊú™‰æÜÁ†îÁ©∂ÂíåÊúÄ‰Ω≥ÂØ¶ÂãôÁöÑÂü∫Á§éÔºåÈÄôÈ†ÖÂ∑•‰ΩúÊó®Âú®ÊèêÂçá AI ÁöÑ RE È†òÂüü„ÄÇ

##### **Revisiting the Performance-Explainability Trade-Off in Explainable Artificial Intelligence (XAI)**
2307.14239v1 by Barnaby Crook, Maximilian Schl√ºter, Timo Speith

Within the field of Requirements Engineering (RE), the increasing
significance of Explainable Artificial Intelligence (XAI) in aligning
AI-supported systems with user needs, societal expectations, and regulatory
standards has garnered recognition. In general, explainability has emerged as
an important non-functional requirement that impacts system quality. However,
the supposed trade-off between explainability and performance challenges the
presumed positive influence of explainability. If meeting the requirement of
explainability entails a reduction in system performance, then careful
consideration must be given to which of these quality aspects takes precedence
and how to compromise between them. In this paper, we critically examine the
alleged trade-off. We argue that it is best approached in a nuanced way that
incorporates resource availability, domain characteristics, and considerations
of risk. By providing a foundation for future research and best practices, this
work aims to advance the field of RE for AI.

ÊëòË¶ÅÔºöÂú®ÈúÄÊ±ÇÂ∑•Á®ãÔºàREÔºâÈ¢ÜÂüüÔºåÂèØËß£Èáä‰∫∫Â∑•Êô∫ËÉΩÔºàXAIÔºâÂú®Â∞Ü‰∫∫Â∑•Êô∫ËÉΩÊîØÊåÅÁöÑÁ≥ªÁªü‰∏éÁî®Êà∑ÈúÄÊ±Ç„ÄÅÁ§æ‰ºöÊúüÊúõÂíåÁõëÁÆ°Ê†áÂáÜÁõ∏‰∏ÄËá¥ÊñπÈù¢ÁöÑÈáçË¶ÅÊÄßÊó•ÁõäÂá∏ÊòæÔºåÂπ∂Ëé∑Âæó‰∫ÜËÆ§ÂèØ„ÄÇ‰∏ÄËà¨Êù•ËØ¥ÔºåÂèØËß£ÈáäÊÄßÂ∑≤Êàê‰∏∫ÂΩ±ÂìçÁ≥ªÁªüË¥®ÈáèÁöÑÈáçË¶ÅÈùûÂäüËÉΩÊÄßÈúÄÊ±Ç„ÄÇÁÑ∂ËÄåÔºåÂèØËß£ÈáäÊÄßÂíåÊÄßËÉΩ‰πãÈó¥ÁöÑÊùÉË°°ÊåëÊàò‰∫ÜÂèØËß£ÈáäÊÄßÁöÑÊ≠£Èù¢ÂΩ±Âìç„ÄÇÂ¶ÇÊûúÊª°Ë∂≥ÂèØËß£ÈáäÊÄßÁöÑË¶ÅÊ±ÇÈúÄË¶ÅÈôç‰ΩéÁ≥ªÁªüÊÄßËÉΩÔºåÈÇ£‰πàÂøÖÈ°ª‰ªîÁªÜËÄÉËôëËøô‰∫õË¥®ÈáèÊñπÈù¢‰∏≠ÁöÑÂì™‰∏Ä‰∏™‰ºòÂÖàÔºå‰ª•ÂèäÂ¶Ç‰ΩïÂú®ÂÆÉ‰ª¨‰πãÈó¥ËøõË°åÊùÉË°°„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨ÊâπÂà§ÊÄßÂú∞ËÄÉÂØü‰∫ÜÊâÄË∞ìÁöÑÊùÉË°°„ÄÇÊàë‰ª¨ËÆ§‰∏∫ÔºåÊúÄÂ•Ω‰ª•‰∏ÄÁßçÁªÜËá¥ÂÖ•ÂæÆÁöÑÊñπÂºèÊù•Â§ÑÁêÜÂÆÉÔºåËøôÁßçÊñπÂºèÁªìÂêà‰∫ÜËµÑÊ∫êÂèØÁî®ÊÄß„ÄÅÈ¢ÜÂüüÁâπÂæÅÂíåÈ£éÈô©ËÄÉËôë„ÄÇÈÄöËøá‰∏∫Êú™Êù•ÁöÑÁ†îÁ©∂ÂíåÊúÄ‰Ω≥ÂÆûË∑µÊèê‰æõÂü∫Á°ÄÔºåËøôÈ°πÂ∑•‰ΩúÊó®Âú®Êé®Ëøõ‰∫∫Â∑•Êô∫ËÉΩÁöÑ RE È¢ÜÂüü„ÄÇ

##### **Acceptable risks in Europe's proposed AI Act: Reasonableness and other principles for deciding how much risk management is enough**
2308.02047v1 by Henry Fraser, Jose-Miguel Bello y Villarino

This paper critically evaluates the European Commission's proposed AI Act's
approach to risk management and risk acceptability for high-risk AI systems
that pose risks to fundamental rights and safety. The Act aims to promote
"trustworthy" AI with a proportionate regulatory burden. Its provisions on risk
acceptability require residual risks from high-risk systems to be reduced or
eliminated "as far as possible", having regard to the "state of the art". This
criterion, especially if interpreted narrowly, is unworkable and promotes
neither proportionate regulatory burden, nor trustworthiness. By contrast the
Parliament's most recent draft amendments to the risk management provisions
introduce "reasonableness", cost-benefit analysis, and are more transparent
about the value-laden and contextual nature of risk acceptability judgements.
This paper argues that the Parliament's approach is more workable, and better
balances the goals of proportionality and trustworthiness. It explains what
reasonableness in risk acceptability judgments would entail, drawing on
principles from negligence law and European medical devices regulation. And it
contends that the approach to risk acceptability judgments need a firm
foundation of civic legitimacy: including detailed guidance or involvement from
regulators, and meaningful input from affected stakeholders.

ÊëòË¶ÅÔºöÊú¨ÊñáÂö¥Ê†ºË©ï‰º∞Ê≠êÊ¥≤ÂßîÂì°ÊúÉÊèêÂá∫ÁöÑ AI Ê≥ïÊ°àÂ∞çÈ¢®Èö™ÁÆ°ÁêÜÂíåÈ¢®Èö™ÂèØÊé•ÂèóÊÄßÁöÑÊñπÊ≥ïÔºåÁî®ÊñºÂ∞çÂü∫Êú¨Ê¨äÂà©ÂíåÂÆâÂÖ®ÊßãÊàêÈ¢®Èö™ÁöÑÈ´òÈ¢®Èö™ AI Á≥ªÁµ±„ÄÇË©≤Ê≥ïÊ°àÊó®Âú®‰ª•Áõ∏Á®±ÁöÑÁõ£ÁÆ°Ë≤†Êìî‰øÉÈÄ≤„ÄåÂÄºÂæó‰ø°Ë≥¥„ÄçÁöÑ AI„ÄÇÂÖ∂ÈóúÊñºÈ¢®Èö™ÂèØÊé•ÂèóÊÄßÁöÑÊ¢ùÊ¨æË¶ÅÊ±ÇÂ∞áÈ´òÈ¢®Èö™Á≥ªÁµ±ÁöÑÊÆòÈ§òÈ¢®Èö™Ê∏õ‰ΩéÊàñÊ∂àÈô§„ÄåÁõ°ÂèØËÉΩ„ÄçÔºå‰∏¶ËÄÉÊÖÆ„ÄåÊäÄË°ìÁãÄÊÖã„Äç„ÄÇÊ≠§Ê∫ñÂâáÔºåÁâπÂà•ÊòØÂ¶ÇÊûúÁãπÁæ©Ëß£ÈáãÔºåÁÑ°Ê≥ïÂü∑Ë°åÔºåÊó¢‰∏ç‰øÉÈÄ≤Áõ∏Á®±ÁöÑÁõ£ÁÆ°Ë≤†ÊìîÔºå‰πü‰∏ç‰øÉÈÄ≤ÂèØ‰ø°Ë≥¥ÊÄß„ÄÇÁõ∏ÊØî‰πã‰∏ãÔºåË≠∞ÊúÉÂ∞çÈ¢®Èö™ÁÆ°ÁêÜÊ¢ùÊ¨æÁöÑÊúÄÊñ∞‰øÆÊ≠£ËçâÊ°àÂºïÂÖ•‰∫Ü„ÄåÂêàÁêÜÊÄß„Äç„ÄÅÊàêÊú¨ÊïàÁõäÂàÜÊûêÔºå‰∏¶‰∏îÊõ¥ÈÄèÊòéÂú∞Ë™™Êòé‰∫ÜÈ¢®Èö™ÂèØÊé•ÂèóÊÄßÂà§Êñ∑ÁöÑÂÉπÂÄºËßÄÂíåËÉåÊôØÊÄßË≥™„ÄÇÊú¨ÊñáË´ñË≠âË≠∞ÊúÉÁöÑÊñπÊ≥ïÊõ¥ÂèØË°åÔºå‰∏îËÉΩÊõ¥Â•ΩÂú∞Âπ≥Ë°°Áõ∏Á®±ÊÄßÂíåÂèØ‰ø°Ë≥¥ÊÄßÁöÑÁõÆÊ®ô„ÄÇÊú¨ÊñáË™™ÊòéÈ¢®Èö™ÂèØÊé•ÂèóÊÄßÂà§Êñ∑‰∏≠ÁöÑÂêàÁêÜÊÄßÊúÉÂ∏∂‰æÜ‰ªÄÈ∫ºÔºå‰∏¶Ê†πÊìöÈÅéÂ§±Ê≥ïÂíåÊ≠êÊ¥≤ÈÜ´ÁôÇÂô®ÊùêÊ≥ïË¶è‰∏≠ÁöÑÂéüÂâáÈÄ≤Ë°åË™™Êòé„ÄÇÊú¨Êñá‰∏ªÂºµÈ¢®Èö™ÂèØÊé•ÂèóÊÄßÂà§Êñ∑ÁöÑÊñπÊ≥ïÈúÄË¶ÅÁ©©Âõ∫ÁöÑÂÖ¨Ê∞ëÂêàÊ≥ïÊÄßÂü∫Á§éÔºöÂåÖÊã¨Áõ£ÁÆ°Ê©üÊßãÁöÑË©≥Á¥∞ÊåáÂ∞éÊàñÂèÉËàáÔºå‰ª•ÂèäÂèóÂΩ±ÈüøÂà©ÂÆ≥Èóú‰øÇ‰∫∫ÁöÑÊúâÊÑèÁæ©ÊäïÂÖ•„ÄÇ

##### **eXplainable Artificial Intelligence (XAI) in aging clock models**
2307.13704v3 by Alena Kalyakulina, Igor Yusipov, Alexey Moskalev, Claudio Franceschi, Mikhail Ivanchenko

eXplainable Artificial Intelligence (XAI) is a rapidly progressing field of
machine learning, aiming to unravel the predictions of complex models. XAI is
especially required in sensitive applications, e.g. in health care, when
diagnosis, recommendations and treatment choices might rely on the decisions
made by artificial intelligence systems. AI approaches have become widely used
in aging research as well, in particular, in developing biological clock models
and identifying biomarkers of aging and age-related diseases. However, the
potential of XAI here awaits to be fully appreciated. We discuss the
application of XAI for developing the "aging clocks" and present a
comprehensive analysis of the literature categorized by the focus on particular
physiological systems.

ÊëòË¶ÅÔºöÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖß (XAI) ÊòØÊ©üÂô®Â≠∏Áøí‰∏≠Âø´ÈÄüÈÄ≤Â±ïÁöÑÈ†òÂüüÔºåÊó®Âú®Ëß£ÈñãË§áÈõúÊ®°ÂûãÁöÑÈ†êÊ∏¨„ÄÇXAI Âú®ÊïèÊÑüÊáâÁî®‰∏≠ÁâπÂà•ÈúÄË¶ÅÔºå‰æãÂ¶ÇÂú®ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÔºåÁï∂Ë®∫Êñ∑„ÄÅÂª∫Ë≠∞ÂíåÊ≤ªÁôÇÈÅ∏ÊìáÂèØËÉΩ‰æùË≥¥Êñº‰∫∫Â∑•Êô∫ÊÖßÁ≥ªÁµ±ÂÅöÂá∫ÁöÑÊ±∫Á≠ñÊôÇ„ÄÇ‰∫∫Â∑•Êô∫ÊÖßÊñπÊ≥ï‰πüÂ∑≤Âª£Ê≥õÁî®ÊñºËÄÅÂåñÁ†îÁ©∂ÔºåÁâπÂà•ÊòØÂú®ÈñãÁôºÁîüÁâ©ÊôÇÈêòÊ®°ÂûãÂíåË≠òÂà•ËÄÅÂåñÂíåËàáÂπ¥ÈΩ°Áõ∏ÈóúÁñæÁóÖÁöÑÁîüÁâ©Ê®ôË™åÁâ©ÊñπÈù¢„ÄÇÁÑ∂ËÄåÔºåÈÄôË£° XAI ÁöÑÊΩõÂäõÊúâÂæÖÂÖÖÂàÜË™çË≠ò„ÄÇÊàëÂÄëË®éË´ñ‰∫Ü XAI Âú®ÈñãÁôº„ÄåËÄÅÂåñÊôÇÈêò„ÄçÊñπÈù¢ÁöÑÊáâÁî®Ôºå‰∏¶Â∞çÊåâÁâπÂÆöÁîüÁêÜÁ≥ªÁµ±ÁöÑÈáçÈªûÂàÜÈ°ûÁöÑÊñáÁçªÈÄ≤Ë°å‰∫ÜÂÖ®Èù¢ÁöÑÂàÜÊûê„ÄÇ

##### **Interpreting and Correcting Medical Image Classification with PIP-Net**
2307.10404v2 by Meike Nauta, Johannes H. Hegeman, Jeroen Geerdink, J√∂rg Schl√∂tterer, Maurice van Keulen, Christin Seifert

Part-prototype models are explainable-by-design image classifiers, and a
promising alternative to black box AI. This paper explores the applicability
and potential of interpretable machine learning, in particular PIP-Net, for
automated diagnosis support on real-world medical imaging data. PIP-Net learns
human-understandable prototypical image parts and we evaluate its accuracy and
interpretability for fracture detection and skin cancer diagnosis. We find that
PIP-Net's decision making process is in line with medical classification
standards, while only provided with image-level class labels. Because of
PIP-Net's unsupervised pretraining of prototypes, data quality problems such as
undesired text in an X-ray or labelling errors can be easily identified.
Additionally, we are the first to show that humans can manually correct the
reasoning of PIP-Net by directly disabling undesired prototypes. We conclude
that part-prototype models are promising for medical applications due to their
interpretability and potential for advanced model debugging.

ÊëòË¶ÅÔºöÈÉ®ÂàÜÂéüÂûãÊ®°ÂûãÊòØÂèØËß£ÈáãË®≠Ë®àÁöÑÂΩ±ÂÉèÂàÜÈ°ûÂô®Ôºå‰πüÊòØÈªëÁÆ± AI ÁöÑ‰∏ÄÂÄãÊúâÂâçÈÄîÁöÑÊõø‰ª£ÊñπÊ°à„ÄÇÈÄôÁØáË´ñÊñáÊé¢Ë®é‰∫ÜËß£ÈáãÊÄßÊ©üÂô®Â≠∏ÁøíÔºåÁâπÂà•ÊòØ PIP-NetÔºåÂú®ÁúüÂØ¶‰∏ñÁïåÈÜ´Â≠∏ÂΩ±ÂÉèË≥áÊñô‰∏äËá™ÂãïÂåñË®∫Êñ∑ÊîØÊè¥ÁöÑÈÅ©Áî®ÊÄßÂíåÊΩõÂäõ„ÄÇPIP-Net Â≠∏Áøí‰∫∫È°ûÂèØÁêÜËß£ÁöÑÂéüÂûãÂΩ±ÂÉèÈÉ®ÂàÜÔºåÊàëÂÄëË©ï‰º∞ÂÖ∂Âú®È™®ÊäòÊ™¢Ê∏¨ÂíåÁöÆËÜöÁôåË®∫Êñ∑ÊñπÈù¢ÁöÑÊ∫ñÁ¢∫ÊÄßÂíåÂèØËß£ÈáãÊÄß„ÄÇÊàëÂÄëÁôºÁèæ PIP-Net ÁöÑÊ±∫Á≠ñÂà∂ÂÆöÈÅéÁ®ãÁ¨¶ÂêàÈÜ´Â≠∏ÂàÜÈ°ûÊ®ôÊ∫ñÔºåÂêåÊôÇÂÉÖÊèê‰æõÂΩ±ÂÉèÂ±§Á¥öÈ°ûÂà•Ê®ôÁ±§„ÄÇÁî±Êñº PIP-Net Â∞çÂéüÂûãÁöÑÁÑ°Áõ£Áù£È†êË®ìÁ∑¥ÔºåÂõ†Ê≠§ÂèØ‰ª•ËºïÈ¨ÜË≠òÂà•Ë≥áÊñôÂìÅË≥™ÂïèÈ°åÔºå‰æãÂ¶Ç X ÂÖâ‰∏≠ÁöÑ‰∏çÈúÄË¶ÅÊñáÂ≠óÊàñÊ®ôÁ±§ÈåØË™§„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÈ¶ñÊ¨°Â±ïÁ§∫‰∫∫È°ûÂèØ‰ª•ÈÄèÈÅéÁõ¥Êé•ÂÅúÁî®‰∏çÈúÄË¶ÅÁöÑÂéüÂûã‰æÜÊâãÂãï‰øÆÊ≠£ PIP-Net ÁöÑÊé®ÁêÜ„ÄÇÊàëÂÄëÂæóÂá∫ÁµêË´ñÔºåÈÉ®ÂàÜÂéüÂûãÊ®°ÂûãÁî±ÊñºÂÖ∂ÂèØËß£ÈáãÊÄßÂíåÈÄ≤ÈöéÊ®°ÂûãÈô§ÈåØÁöÑÊΩõÂäõÔºåÂõ†Ê≠§ÊúâÊúõÊáâÁî®ÊñºÈÜ´ÁôÇ„ÄÇ

##### **Explaining and visualizing black-box models through counterfactual paths**
2307.07764v3 by Bastian Pfeifer, Mateusz Krzyzinski, Hubert Baniecki, Anna Saranti, Andreas Holzinger, Przemyslaw Biecek

Explainable AI (XAI) is an increasingly important area of machine learning
research, which aims to make black-box models transparent and interpretable. In
this paper, we propose a novel approach to XAI that uses the so-called
counterfactual paths generated by conditional permutations of features. The
algorithm measures feature importance by identifying sequential permutations of
features that most influence changes in model predictions. It is particularly
suitable for generating explanations based on counterfactual paths in knowledge
graphs incorporating domain knowledge. Counterfactual paths introduce an
additional graph dimension to current XAI methods in both explaining and
visualizing black-box models. Experiments with synthetic and medical data
demonstrate the practical applicability of our approach.

ÊëòË¶ÅÔºöÂèØËß£Èáã AI (XAI) ÊòØÊ©üÂô®Â≠∏ÁøíÁ†îÁ©∂‰∏≠Êó•ÁõäÈáçË¶ÅÁöÑÈ†òÂüüÔºåÂÖ∂ÁõÆÊ®ôÊòØËÆìÈªëÁÆ±Ê®°ÂûãÈÄèÊòé‰∏îÂèØËß£Èáã„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞ÁöÑ XAI ÊñπÊ≥ïÔºåË©≤ÊñπÊ≥ï‰ΩøÁî®Áî±ÁâπÂæµÊ¢ù‰ª∂ÁΩÆÊèõÁî¢ÁîüÁöÑÊâÄË¨ÇÂèç‰∫ãÂØ¶Ë∑ØÂæë„ÄÇË©≤ÊºîÁÆóÊ≥ïÈÄèÈÅéË≠òÂà•ÁâπÂæµÁöÑÈ†ÜÂ∫èÁΩÆÊèõ‰æÜË°°ÈáèÁâπÂæµÈáçË¶ÅÊÄßÔºåÈÄô‰∫õÁΩÆÊèõÊúÄËÉΩÂΩ±ÈüøÊ®°ÂûãÈ†êÊ∏¨ÁöÑËÆäÂåñ„ÄÇÂÆÉÁâπÂà•ÈÅ©ÂêàÊ†πÊìöÂåÖÂê´È†òÂüüÁü•Ë≠òÁöÑÁü•Ë≠òÂúñË≠ú‰∏≠ÁöÑÂèç‰∫ãÂØ¶Ë∑ØÂæë‰æÜÁî¢ÁîüËß£Èáã„ÄÇÂèç‰∫ãÂØ¶Ë∑ØÂæëÂú®Ëß£ÈáãÂíåË¶ñË¶∫ÂåñÈªëÁÆ±Ê®°ÂûãÊôÇÔºåÁÇ∫ÁõÆÂâçÁöÑ XAI ÊñπÊ≥ïÂºïÂÖ•‰∫ÜÈ°çÂ§ñÁöÑÂúñÂΩ¢Á∂≠Â∫¶„ÄÇ‰ΩøÁî®ÂêàÊàêÂíåÈÜ´ÁôÇË≥áÊñôÈÄ≤Ë°åÁöÑÂØ¶È©óË≠âÊòé‰∫ÜÊàëÂÄëÊñπÊ≥ïÁöÑÂØ¶Áî®ÈÅ©Áî®ÊÄß„ÄÇ

##### **Beyond Known Reality: Exploiting Counterfactual Explanations for Medical Research**
2307.02131v5 by Toygar Tanyel, Serkan Ayvaz, Bilgin Keserci

The field of explainability in artificial intelligence (AI) has witnessed a
growing number of studies and increasing scholarly interest. However, the lack
of human-friendly and individual interpretations in explaining the outcomes of
machine learning algorithms has significantly hindered the acceptance of these
methods by clinicians in their research and clinical practice. To address this
issue, our study uses counterfactual explanations to explore the applicability
of "what if?" scenarios in medical research. Our aim is to expand our
understanding of magnetic resonance imaging (MRI) features used for diagnosing
pediatric posterior fossa brain tumors beyond existing boundaries. In our case
study, the proposed concept provides a novel way to examine alternative
decision-making scenarios that offer personalized and context-specific
insights, enabling the validation of predictions and clarification of
variations under diverse circumstances. Additionally, we explore the potential
use of counterfactuals for data augmentation and evaluate their feasibility as
an alternative approach in our medical research case. The results demonstrate
the promising potential of using counterfactual explanations to enhance
acceptance of AI-driven methods in clinical research.

ÊëòË¶ÅÔºöÂú®‰∫∫Â∑•Êô∫ËÉΩ (AI) ÁöÑÂèØËß£ÈáãÊÄßÈ†òÂüü‰∏≠ÔºåÂ∑≤Á∂ìÁúãÂà∞Ë∂ä‰æÜË∂äÂ§öÁöÑÁ†îÁ©∂ÂíåÂ≠∏Ë°ìËààË∂£„ÄÇÁÑ∂ËÄåÔºåÂú®Ëß£ÈáãÊ©üÂô®Â≠∏ÁøíÊºîÁÆóÊ≥ïÁöÑÁµêÊûúÊôÇÁº∫‰πè‰∫∫ÊÄßÂåñÂíåÂÄã‰∫∫ÂåñÁöÑË©ÆÈáãÔºåÈÄôÈ°ØËëóÈòªÁ§ô‰∫ÜËá®Â∫äÈÜ´ÁîüÂú®Á†îÁ©∂ÂíåËá®Â∫äÂØ¶Âãô‰∏≠Êé•ÂèóÈÄô‰∫õÊñπÊ≥ï„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÁöÑÁ†îÁ©∂‰ΩøÁî®Âèç‰∫ãÂØ¶Ëß£Èáã‰æÜÊé¢Ë®é„ÄåÂ¶ÇÊûúÔºü„ÄçÊÉÖÂ¢ÉÂú®ÈÜ´Â≠∏Á†îÁ©∂‰∏≠ÁöÑÈÅ©Áî®ÊÄß„ÄÇÊàëÂÄëÁöÑÁõÆÊ®ôÊòØÊì¥Â±ïÊàëÂÄëÂ∞çÁî®ÊñºË®∫Êñ∑Â∞èÂÖíÂæåÈ°±Á™©ËÖ¶ËÖ´Áò§ÁöÑÁ£ÅÂÖ±ÊåØÊàêÂÉè (MRI) ÁâπÂæµÁöÑÁêÜËß£ÔºåË∂ÖË∂äÁèæÊúâÁöÑÁïåÁ∑ö„ÄÇÂú®ÊàëÂÄëÁöÑÊ°à‰æãÁ†îÁ©∂‰∏≠ÔºåÊâÄÊèêÂá∫ÁöÑÊ¶ÇÂøµÊèê‰æõ‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÊñπÊ≥ï‰æÜÊ™¢Ë¶ñÊõø‰ª£Ê±∫Á≠ñÊÉÖÂ¢ÉÔºåÊèê‰æõÂÄã‰∫∫ÂåñÂíåÁâπÂÆöÊñºÊÉÖÂ¢ÉÁöÑË¶ãËß£ÔºåÂæûËÄåËÉΩÂ§†È©óË≠âÈ†êÊ∏¨‰∏¶ÈáêÊ∏ÖÂú®‰∏çÂêåÊÉÖÊ≥Å‰∏ãÁöÑÂ∑ÆÁï∞„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊé¢Ë®é‰∫ÜÂèç‰∫ãÂØ¶Áî®ÊñºË≥áÊñôÊì¥ÂÖÖÁöÑÊΩõÂú®Áî®ÈÄîÔºå‰∏¶Ë©ï‰º∞ÂÖ∂‰ΩúÁÇ∫ÊàëÂÄëÈÜ´Â≠∏Á†îÁ©∂Ê°à‰æã‰∏≠Êõø‰ª£ÊñπÊ≥ïÁöÑÂèØË°åÊÄß„ÄÇÁµêÊûúË≠âÊòé‰∫Ü‰ΩøÁî®Âèç‰∫ãÂØ¶Ëß£Èáã‰æÜÂ¢ûÂº∑Ëá®Â∫äÁ†îÁ©∂‰∏≠ AI È©ÖÂãïÊñπÊ≥ïÁöÑÊé•ÂèóÂ∫¶ÁöÑÊΩõÂäõ„ÄÇ

##### **AI and Non AI Assessments for Dementia**
2307.01210v1 by Mahboobeh Parsapoor, Hamed Ghodrati, Vincenzo Dentamaro, Christopher R. Madan, Ioulietta Lazarou, Spiros Nikolopoulos, Ioannis Kompatsiaris

Current progress in the artificial intelligence domain has led to the
development of various types of AI-powered dementia assessments, which can be
employed to identify patients at the early stage of dementia. It can
revolutionize the dementia care settings. It is essential that the medical
community be aware of various AI assessments and choose them considering their
degrees of validity, efficiency, practicality, reliability, and accuracy
concerning the early identification of patients with dementia (PwD). On the
other hand, AI developers should be informed about various non-AI assessments
as well as recently developed AI assessments. Thus, this paper, which can be
readable by both clinicians and AI engineers, fills the gap in the literature
in explaining the existing solutions for the recognition of dementia to
clinicians, as well as the techniques used and the most widespread dementia
datasets to AI engineers. It follows a review of papers on AI and non-AI
assessments for dementia to provide valuable information about various dementia
assessments for both the AI and medical communities. The discussion and
conclusion highlight the most prominent research directions and the maturity of
existing solutions.

ÊëòË¶ÅÔºöÁõÆÂâç‰∫∫Â∑•Êô∫ËÉΩÈ†òÂüüÁöÑÈÄ≤Â±ïÂ∞éËá¥‰∫ÜÂêÑÁ®ÆÈ°ûÂûãÁöÑ‰∫∫Â∑•Êô∫ÊÖßÈ©ÖÂãïÁöÑÂ§±Êô∫ÁóáË©ï‰º∞ÁöÑÁôºÂ±ïÔºåÂèØÁî®ÊñºË≠òÂà•ËôïÊñºÂ§±Êô∫ÁóáÊó©ÊúüÈöéÊÆµÁöÑÊÇ£ËÄÖ„ÄÇÂÆÉÂèØ‰ª•ÂæπÂ∫ïÊîπËÆäÂ§±Êô∫ÁóáË≠∑ÁêÜË®≠ÁΩÆ„ÄÇÈáçË¶ÅÁöÑÊòØÔºåÈÜ´ÁôÇÁïåË¶Å‰∫ÜËß£ÂêÑÁ®Æ‰∫∫Â∑•Êô∫ËÉΩË©ï‰º∞Ôºå‰∏¶Ê†πÊìöÂÖ∂ÊúâÊïàÊÄß„ÄÅÊïàÁéá„ÄÅÂØ¶Áî®ÊÄß„ÄÅÂèØÈù†ÊÄßÂíåÊ∫ñÁ¢∫ÊÄßÁ®ãÂ∫¶ÔºåËÄÉÊÖÆÈÅ∏ÊìáÂÆÉÂÄë‰æÜÊó©ÊúüË≠òÂà•Â§±Êô∫ÁóáÊÇ£ËÄÖ (PwD)„ÄÇÂè¶‰∏ÄÊñπÈù¢Ôºå‰∫∫Â∑•Êô∫ËÉΩÈñãÁôº‰∫∫Âì°‰πüÊáâË©≤‰∫ÜËß£ÂêÑÁ®ÆÈùû‰∫∫Â∑•Êô∫ËÉΩË©ï‰º∞‰ª•ÂèäÊúÄËøëÈñãÁôºÁöÑ‰∫∫Â∑•Êô∫ËÉΩË©ï‰º∞„ÄÇÂõ†Ê≠§ÔºåÈÄôÁØáËá®Â∫äÈÜ´ÁîüÂíå‰∫∫Â∑•Êô∫ËÉΩÂ∑•Á®ãÂ∏´ÈÉΩÂèØ‰ª•Èñ±ËÆÄÁöÑË´ñÊñáÂ°´Ë£ú‰∫ÜÊñáÁçª‰∏≠ÈóúÊñºÂêëËá®Â∫äÈÜ´ÁîüËß£ÈáãÁèæÊúâÂ§±Êô∫ÁóáË≠òÂà•Ëß£Ê±∫ÊñπÊ°à‰ª•ÂèäÂêë‰∫∫Â∑•Êô∫ËÉΩÂ∑•Á®ãÂ∏´Ëß£ÈáãÊâÄÁî®ÊäÄË°ìÂíåÊúÄÂª£Ê≥õÁöÑÂ§±Êô∫ÁóáÊï∏ÊìöÈõÜÁöÑÁ©∫ÁôΩ„ÄÇÂÆÉÈÅµÂæ™Â∞ç‰∫∫Â∑•Êô∫ËÉΩÂíåÈùû‰∫∫Â∑•Êô∫ËÉΩÂ§±Êô∫ÁóáË©ï‰º∞Ë´ñÊñáÁöÑÂõûÈ°ßÔºåÁÇ∫‰∫∫Â∑•Êô∫ËÉΩÂíåÈÜ´ÁôÇÁïåÊèê‰æõÊúâÈóúÂêÑÁ®ÆÂ§±Êô∫ÁóáË©ï‰º∞ÁöÑÂØ∂Ë≤¥‰ø°ÊÅØ„ÄÇË®éË´ñÂíåÁµêË´ñÈáçÈªû‰ªãÁ¥π‰∫ÜÊúÄÁ™ÅÂá∫ÁöÑÁ†îÁ©∂ÊñπÂêëÂíåÁèæÊúâËß£Ê±∫ÊñπÊ°àÁöÑÊàêÁÜüÂ∫¶„ÄÇ

##### **Active Globally Explainable Learning for Medical Images via Class Association Embedding and Cyclic Adversarial Generation**
2306.07306v1 by Ruitao Xie, Jingbang Chen, Limai Jiang, Rui Xiao, Yi Pan, Yunpeng Cai

Explainability poses a major challenge to artificial intelligence (AI)
techniques. Current studies on explainable AI (XAI) lack the efficiency of
extracting global knowledge about the learning task, thus suffer deficiencies
such as imprecise saliency, context-aware absence and vague meaning. In this
paper, we propose the class association embedding (CAE) approach to address
these issues. We employ an encoder-decoder architecture to embed sample
features and separate them into class-related and individual-related style
vectors simultaneously. Recombining the individual-style code of a given sample
with the class-style code of another leads to a synthetic sample with preserved
individual characters but changed class assignment, following a cyclic
adversarial learning strategy. Class association embedding distills the global
class-related features of all instances into a unified domain with well
separation between classes. The transition rules between different classes can
be then extracted and further employed to individual instances. We then propose
an active XAI framework which manipulates the class-style vector of a certain
sample along guided paths towards the counter-classes, resulting in a series of
counter-example synthetic samples with identical individual characters.
Comparing these counterfactual samples with the original ones provides a
global, intuitive illustration to the nature of the classification tasks. We
adopt the framework on medical image classification tasks, which show that more
precise saliency maps with powerful context-aware representation can be
achieved compared with existing methods. Moreover, the disease pathology can be
directly visualized via traversing the paths in the class-style space.

ÊëòË¶ÅÔºö<paragraph>ÂèØËß£ÈáãÊÄßÂ∞ç‰∫∫Â∑•Êô∫ÊÖß (AI) ÊäÄË°ìÊßãÊàê‰∏ÄÈ†ÖÈáçÂ§ßÊåëÊà∞„ÄÇÁï∂ÂâçÂ∞çÂèØËß£Èáã AI (XAI) ÁöÑÁ†îÁ©∂Áº∫‰πèÊèêÂèñÂ≠∏Áøí‰ªªÂãôÊï¥È´îÁü•Ë≠òÁöÑÊïàÁéáÔºåÂõ†Ê≠§Â≠òÂú®‰∏çÁ≤æÁ¢∫ÁöÑÈ°ØËëóÊÄß„ÄÅËàáÊÉÖÂ¢ÉÁÑ°ÈóúÁöÑÁº∫Â§±ÂíåÂê´Á≥äÊÑèÁæ©Á≠âÁº∫Èô∑„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫È°ûÂà•ÈóúËÅØÂµåÂÖ• (CAE) ÊñπÊ≥ï‰æÜËß£Ê±∫ÈÄô‰∫õÂïèÈ°å„ÄÇÊàëÂÄëÊé°Áî®Á∑®Á¢ºÂô®-Ëß£Á¢ºÂô®Êû∂Êßã‰æÜÂµåÂÖ•Ê®£Êú¨ÁâπÂæµÔºå‰∏¶ÂêåÊôÇÂ∞áÂÆÉÂÄëÂàÜÁÇ∫È°ûÂà•Áõ∏ÈóúÂíåÂÄãÈ´îÁõ∏ÈóúÁöÑÊ®£ÂºèÂêëÈáè„ÄÇÂ∞áÁµ¶ÂÆöÊ®£Êú¨ÁöÑÂÄãÈ´îÊ®£Âºè‰ª£Á¢ºËàáÂè¶‰∏ÄÂÄãÊ®£Êú¨ÁöÑÈ°ûÂà•Ê®£Âºè‰ª£Á¢ºÈáçÊñ∞ÁµÑÂêàÔºåÊúÉÁî¢Áîü‰∏ÄÂÄãÂÖ∑Êúâ‰øùÁïôÂÄãÈ´îÁâπÂæµ‰ΩÜÊîπËÆäÈ°ûÂà•ÂàÜÈÖçÁöÑÂêàÊàêÊ®£Êú¨ÔºåÈÅµÂæ™Âæ™Áí∞Â∞çÊäóÂ≠∏ÁøíÁ≠ñÁï•„ÄÇÈ°ûÂà•ÈóúËÅØÂµåÂÖ•Â∞áÊâÄÊúâÂØ¶‰æãÁöÑÂÖ®Â±ÄÈ°ûÂà•Áõ∏ÈóúÁâπÂæµÊèêÁÖâÂà∞‰∏ÄÂÄãÁµ±‰∏ÄÁöÑÈ†òÂüü‰∏≠Ôºå‰∏¶Âú®È°ûÂà•‰πãÈñìÊúâËâØÂ•ΩÁöÑÂçÄÂàÜ„ÄÇÁÑ∂ÂæåÂèØ‰ª•ÊèêÂèñ‰∏çÂêåÈ°ûÂà•‰πãÈñìÁöÑËΩâÊèõË¶èÂâáÔºå‰∏¶ÈÄ≤‰∏ÄÊ≠•ÊáâÁî®ÊñºÂÄãÂà•ÂØ¶‰æã„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄã‰∏ªÂãï XAI Ê°ÜÊû∂ÔºåÂÆÉÊ≤øËëóÂºïÂ∞éË∑ØÂæëÊìç‰ΩúÁâπÂÆöÊ®£Êú¨ÁöÑÈ°ûÂà•Ê®£ÂºèÂêëÈáèÔºåÊúùËëóÂèçÈ°ûÂà•ÁßªÂãïÔºåÂæûËÄåÁî¢Áîü‰∏ÄÁ≥ªÂàóÂÖ∑ÊúâÁõ∏ÂêåÂÄãÈ´îÁâπÂæµÁöÑÂèç‰æãÂêàÊàêÊ®£Êú¨„ÄÇÂ∞áÈÄô‰∫õÂèç‰∫ãÂØ¶Ê®£Êú¨ËàáÂéüÂßãÊ®£Êú¨ÈÄ≤Ë°åÊØîËºÉÔºåÂèØ‰ª•Â∞çÂàÜÈ°û‰ªªÂãôÁöÑÊÄßË≥™Êèê‰æõÂÖ®Â±Ä„ÄÅÁõ¥ËßÄÁöÑË™™Êòé„ÄÇÊàëÂÄëÊé°Áî®Ë©≤Ê°ÜÊû∂ÈÄ≤Ë°åÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÈ°û‰ªªÂãôÔºåÁµêÊûúË°®ÊòéÔºåËàáÁèæÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåÂèØ‰ª•Áç≤ÂæóÊõ¥Á≤æÁ¢∫ÁöÑÈ°ØËëóÊÄßÂúñÔºå‰∏¶ÂÖ∑ÊúâÂº∑Â§ßÁöÑËàáÊÉÖÂ¢ÉÁÑ°ÈóúÁöÑË°®Á§∫„ÄÇÊ≠§Â§ñÔºåÁñæÁóÖÁóÖÁêÜÂ≠∏ÂèØ‰ª•Áõ¥Êé•ÈÄöÈÅéÂú®È°ûÂà•Ê®£ÂºèÁ©∫Èñì‰∏≠ÈÅçÊ≠∑Ë∑ØÂæë‰æÜÈÄ≤Ë°åÂèØË¶ñÂåñ„ÄÇ</paragraph>

##### **HiTZ@Antidote: Argumentation-driven Explainable Artificial Intelligence for Digital Medicine**
2306.06029v1 by Rodrigo Agerri, I√±igo Alonso, Aitziber Atutxa, Ander Berrondo, Ainara Estarrona, Iker Garcia-Ferrero, Iakes Goenaga, Koldo Gojenola, Maite Oronoz, Igor Perez-Tejedor, German Rigau, Anar Yeginbergenova

Providing high quality explanations for AI predictions based on machine
learning is a challenging and complex task. To work well it requires, among
other factors: selecting a proper level of generality/specificity of the
explanation; considering assumptions about the familiarity of the explanation
beneficiary with the AI task under consideration; referring to specific
elements that have contributed to the decision; making use of additional
knowledge (e.g. expert evidence) which might not be part of the prediction
process; and providing evidence supporting negative hypothesis. Finally, the
system needs to formulate the explanation in a clearly interpretable, and
possibly convincing, way. Given these considerations, ANTIDOTE fosters an
integrated vision of explainable AI, where low-level characteristics of the
deep learning process are combined with higher level schemes proper of the
human argumentation capacity. ANTIDOTE will exploit cross-disciplinary
competences in deep learning and argumentation to support a broader and
innovative view of explainable AI, where the need for high-quality explanations
for clinical cases deliberation is critical. As a first result of the project,
we publish the Antidote CasiMedicos dataset to facilitate research on
explainable AI in general, and argumentation in the medical domain in
particular.

ÊëòË¶ÅÔºöÊèê‰æõÂü∫ÊñºÊ©üÂô®Â≠∏ÁøíÁöÑ AI È†êÊ∏¨ÁöÑÈ´òÂìÅË≥™Ë™™ÊòéÊòØ‰∏ÄÈ†ÖÂÖ∑ÊúâÊåëÊà∞ÊÄßÂíåË§áÈõúÊÄßÁöÑ‰ªªÂãô„ÄÇË¶ÅÈ†ÜÂà©ÈÄ≤Ë°åÔºåÂÆÉÈúÄË¶ÅÂÖ∑ÂÇô‰∏ãÂàóÂõ†Á¥†ÔºöÈÅ∏ÊìáÈÅ©Áï∂ÁöÑË™™ÊòéÊôÆÈÅçÊÄß/ÁâπÊÆäÊÄßÂ±§Á¥öÔºõËÄÉÈáèË™™ÊòéÂèóÁõä‰∫∫Â∞çÊâÄËÄÉÊÖÆÁöÑ AI ‰ªªÂãôÁöÑÁÜüÊÇâÁ®ãÂ∫¶ÂÅáË®≠ÔºõÂèÉÁÖß‰øÉÊàêÊ±∫Á≠ñÁöÑÁâπÂÆöÂÖÉÁ¥†ÔºõÂà©Áî®ÂèØËÉΩ‰∏çÂ±¨ÊñºÈ†êÊ∏¨Á®ãÂ∫èÁöÑ‰∏ÄÈÉ®ÂàÜÁöÑÈ°çÂ§ñÁü•Ë≠òÔºà‰æãÂ¶ÇÂ∞àÂÆ∂Ë≠âÊìöÔºâÔºõ‰∏¶Êèê‰æõÊîØÊåÅÂê¶ÂÆöÂÅáË®≠ÁöÑË≠âÊìö„ÄÇÊúÄÂæåÔºåÁ≥ªÁµ±ÈúÄË¶Å‰ª•Ê∏ÖÊô∞ÂèØËß£Èáã‰∏îÂèØËÉΩ‰ª§‰∫∫‰ø°ÊúçÁöÑÊñπÂºèÂà∂ÂÆöË™™Êòé„ÄÇÂü∫ÊñºÈÄô‰∫õËÄÉÈáèÔºåANTIDOTE ‰øÉÊàê‰∫ÜÂèØËß£Èáã AI ÁöÑÊï¥ÂêàÈ°òÊôØÔºåÂÖ∂‰∏≠Ê∑±Â∫¶Â≠∏ÁøíÁ®ãÂ∫èÁöÑ‰ΩéÈöéÁâπÂæµËàá‰∫∫È°ûË´ñË≠âËÉΩÂäõÁöÑÈ´òÈöéÊû∂ÊßãÁõ∏ÁµêÂêà„ÄÇANTIDOTE Â∞áÂà©Áî®Ê∑±Â∫¶Â≠∏ÁøíËàáË´ñË≠âÁöÑË∑®È†òÂüüËÉΩÂäõÔºå‰æÜÊîØÊåÅÂèØËß£Èáã AI Êõ¥Âª£Ê≥õ‰∏îÂâµÊñ∞ÁöÑËßÄÈªûÔºåÂÖ∂‰∏≠Â∞çËá®Â∫äÊ°à‰æãÂØ©Ë≠∞ÁöÑÈ´òÂìÅË≥™Ë™™ÊòéÈúÄÊ±ÇËá≥ÈóúÈáçË¶Å„ÄÇ‰ΩúÁÇ∫Ë©≤Â∞àÊ°àÁöÑÁ¨¨‰∏ÄÂÄãÊàêÊûúÔºåÊàëÂÄëÁôºÂ∏É‰∫Ü Antidote CasiMedicos Ë≥áÊñôÈõÜÔºå‰ª•Âà©Êñº‰∏ÄËà¨ÂèØËß£Èáã AI ÁöÑÁ†îÁ©∂ÔºåÁâπÂà•ÊòØÈÜ´ÁôÇÈ†òÂüüÁöÑË´ñË≠â„ÄÇ

##### **XInsight: Revealing Model Insights for GNNs with Flow-based Explanations**
2306.04791v1 by Eli Laird, Ayesh Madushanka, Elfi Kraka, Corey Clark

Progress in graph neural networks has grown rapidly in recent years, with
many new developments in drug discovery, medical diagnosis, and recommender
systems. While this progress is significant, many networks are `black boxes'
with little understanding of the `what' exactly the network is learning. Many
high-stakes applications, such as drug discovery, require human-intelligible
explanations from the models so that users can recognize errors and discover
new knowledge. Therefore, the development of explainable AI algorithms is
essential for us to reap the benefits of AI.
  We propose an explainability algorithm for GNNs called eXplainable Insight
(XInsight) that generates a distribution of model explanations using GFlowNets.
Since GFlowNets generate objects with probabilities proportional to a reward,
XInsight can generate a diverse set of explanations, compared to previous
methods that only learn the maximum reward sample. We demonstrate XInsight by
generating explanations for GNNs trained on two graph classification tasks:
classifying mutagenic compounds with the MUTAG dataset and classifying acyclic
graphs with a synthetic dataset that we have open-sourced. We show the utility
of XInsight's explanations by analyzing the generated compounds using QSAR
modeling, and we find that XInsight generates compounds that cluster by
lipophilicity, a known correlate of mutagenicity. Our results show that
XInsight generates a distribution of explanations that uncovers the underlying
relationships demonstrated by the model. They also highlight the importance of
generating a diverse set of explanations, as it enables us to discover hidden
relationships in the model and provides valuable guidance for further analysis.

ÊëòË¶ÅÔºö<paragraph>ËøëÂπ¥‰æÜÔºåÂúñÁ•ûÁ∂ìÁ∂≤Ë∑ØÁöÑÈÄ≤Â±ïËøÖÈÄüÔºåÂú®Ëó•Áâ©ÁôºÁèæ„ÄÅÈÜ´ÁôÇË®∫Êñ∑ÂíåÊé®Ëñ¶Á≥ªÁµ±ÊñπÈù¢ÈÉΩÊúâË®±Â§öÊñ∞ÁôºÂ±ï„ÄÇÈõñÁÑ∂ÈÄô‰∫õÈÄ≤Â±ïÂæàÈáçË¶ÅÔºå‰ΩÜË®±Â§öÁ∂≤Ë∑ØÈÉΩÊòØ„ÄåÈªëÁõíÂ≠ê„ÄçÔºåÂ∞çÊñºÁ∂≤Ë∑ØÂà∞Â∫ïÂú®Â≠∏Áøí„Äå‰ªÄÈ∫º„Äç‰∫ÜËß£ÁîöÂ∞ë„ÄÇË®±Â§öÈ´òÈ¢®Èö™ÊáâÁî®Ôºå‰æãÂ¶ÇËó•Áâ©ÁôºÁèæÔºåÈúÄË¶ÅÊ®°ÂûãÊèê‰æõ‰∫∫È°ûÂèØ‰ª•ÁêÜËß£ÁöÑËß£ÈáãÔºå‰ª•‰æø‰ΩøÁî®ËÄÖÂèØ‰ª•Ëæ®Ë≠òÈåØË™§‰∏¶ÁôºÁèæÊñ∞Áü•Ë≠ò„ÄÇÂõ†Ê≠§ÔºåÂèØËß£Èáã AI ÊºîÁÆóÊ≥ïÁöÑÈñãÁôºÂ∞çÊñºÊàëÂÄëÁç≤Âèñ AI ÁöÑÂ•ΩËôïËá≥ÈóúÈáçË¶Å„ÄÇ
ÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÁ®±ÁÇ∫ eXplainable Insight (XInsight) ÁöÑ GNN ÂèØËß£ÈáãÊÄßÊºîÁÆóÊ≥ïÔºåÂÆÉ‰ΩøÁî® GFlowNets Áî¢ÁîüÊ®°ÂûãËß£ÈáãÂàÜ‰Ωà„ÄÇÁî±Êñº GFlowNets ÊúÉÁî¢ÁîüÊ©üÁéáËàáÁçéÂãµÊàêÊ≠£ÊØîÁöÑÁâ©‰ª∂ÔºåÂõ†Ê≠§ËàáÂÖàÂâçÂÉÖÂ≠∏ÁøíÊúÄÂ§ßÁçéÂãµÁØÑ‰æãÁöÑÊñπÊ≥ïÁõ∏ÊØîÔºåXInsight ÂèØ‰ª•Áî¢ÁîüÂ§öÊ®£ÂåñÁöÑËß£ÈáãÈõÜÂêà„ÄÇÊàëÂÄëÈÄèÈÅéÁÇ∫Âú®ÂÖ©ÂÄãÂúñÂΩ¢ÂàÜÈ°û‰ªªÂãô‰∏≠Ë®ìÁ∑¥ÁöÑ GNN Áî¢ÁîüËß£Èáã‰æÜÂ±ïÁ§∫ XInsightÔºö‰ΩøÁî® MUTAG Ë≥áÊñôÈõÜÂ∞çËá¥Á™ÅËÆäÂåñÂêàÁâ©ÈÄ≤Ë°åÂàÜÈ°ûÔºå‰∏¶‰ΩøÁî®ÊàëÂÄëÂ∑≤ÈñãÊîæÂéüÂßãÁ¢ºÁöÑÂêàÊàêË≥áÊñôÈõÜÂ∞çÈùûÁí∞ÁãÄÂúñÂΩ¢ÈÄ≤Ë°åÂàÜÈ°û„ÄÇÊàëÂÄëÈÄèÈÅé‰ΩøÁî® QSAR Âª∫Ê®°ÂàÜÊûêÁî¢ÁîüÁöÑÂåñÂêàÁâ©‰æÜÂ±ïÁ§∫ XInsight Ëß£ÈáãÁöÑÊïàÁî®ÔºåÊàëÂÄëÁôºÁèæ XInsight ÊúÉÁî¢ÁîüÊåâË¶™ËÑÇÊÄßÔºàÂ∑≤Áü•ÁöÑËá¥Á™ÅËÆäÁõ∏ÈóúÊÄßÔºâÂàÜÁæ§ÁöÑÂåñÂêàÁâ©„ÄÇÊàëÂÄëÁöÑÁµêÊûúÈ°ØÁ§∫ XInsight ÊúÉÁî¢Áîü‰∏ÄÂÄãËß£ÈáãÂàÜ‰ΩàÔºåÊè≠Á§∫Ê®°ÂûãÊâÄÂ±ïÁ§∫ÁöÑÂ∫ïÂ±§Èóú‰øÇ„ÄÇÂÆÉÂÄë‰πüÂº∑Ë™øÁî¢ÁîüÂ§öÊ®£ÂåñËß£ÈáãÈõÜÂêàÁöÑÈáçË¶ÅÊÄßÔºåÂõ†ÁÇ∫ÂÆÉ‰ΩøÊàëÂÄëËÉΩÂ§†ÁôºÁèæÊ®°Âûã‰∏≠ÁöÑÈö±ËóèÈóú‰øÇÔºå‰∏¶ÁÇ∫ÈÄ≤‰∏ÄÊ≠•ÂàÜÊûêÊèê‰æõÊúâÂÉπÂÄºÁöÑÊåáÂ∞é„ÄÇ</paragraph>

##### **Explainable AI using expressive Boolean formulas**
2306.03976v1 by Gili Rosenberg, J. Kyle Brubaker, Martin J. A. Schuetz, Grant Salton, Zhihuai Zhu, Elton Yechao Zhu, Serdar Kadƒ±oƒülu, Sima E. Borujeni, Helmut G. Katzgraber

We propose and implement an interpretable machine learning classification
model for Explainable AI (XAI) based on expressive Boolean formulas. Potential
applications include credit scoring and diagnosis of medical conditions. The
Boolean formula defines a rule with tunable complexity (or interpretability),
according to which input data are classified. Such a formula can include any
operator that can be applied to one or more Boolean variables, thus providing
higher expressivity compared to more rigid rule-based and tree-based
approaches. The classifier is trained using native local optimization
techniques, efficiently searching the space of feasible formulas. Shallow rules
can be determined by fast Integer Linear Programming (ILP) or Quadratic
Unconstrained Binary Optimization (QUBO) solvers, potentially powered by
special purpose hardware or quantum devices. We combine the expressivity and
efficiency of the native local optimizer with the fast operation of these
devices by executing non-local moves that optimize over subtrees of the full
Boolean formula. We provide extensive numerical benchmarking results featuring
several baselines on well-known public datasets. Based on the results, we find
that the native local rule classifier is generally competitive with the other
classifiers. The addition of non-local moves achieves similar results with
fewer iterations, and therefore using specialized or quantum hardware could
lead to a speedup by fast proposal of non-local moves.

ÊëòË¶ÅÔºöÊàëÂÄëÊèêÂá∫‰∏¶ÂØ¶‰Ωú‰∏ÄÂÄãÂèØËß£ÈáãÊ©üÂô®Â≠∏ÁøíÂàÜÈ°ûÊ®°ÂûãÔºåÁî®ÊñºÂü∫ÊñºË°®ÈÅîÂºèÂ∏ÉÊûóÂÖ¨ÂºèÁöÑÂèØËß£Èáã AI (XAI)„ÄÇÊΩõÂú®ÊáâÁî®ÂåÖÊã¨‰ø°Áî®Ë©ïÂàÜÂíåÈÜ´ÁôÇÁãÄÊ≥ÅË®∫Êñ∑„ÄÇÂ∏ÉÊûóÂÖ¨ÂºèÂÆöÁæ©‰∫Ü‰∏ÄÂÄãÂÖ∑ÊúâÂèØË™øÊï¥Ë§áÈõúÊÄßÔºàÊàñÂèØËß£ÈáãÊÄßÔºâÁöÑË¶èÂâáÔºåÊ†πÊìöË©≤Ë¶èÂâáÂ∞çËº∏ÂÖ•Êï∏ÊìöÈÄ≤Ë°åÂàÜÈ°û„ÄÇÈÄôÊ®£ÁöÑÂÖ¨ÂºèÂèØ‰ª•ÂåÖÂê´‰ªª‰ΩïÂèØÊáâÁî®Êñº‰∏ÄÂÄãÊàñÂ§öÂÄãÂ∏ÉÊûóËÆäÊï∏ÁöÑÈÅãÁÆóÂ≠êÔºåÂæûËÄåËàáÊõ¥Âö¥Ê†ºÁöÑÂü∫ÊñºË¶èÂâáÂíåÂü∫ÊñºÊ®πÁöÑÊñπÊ≥ïÁõ∏ÊØîÔºåÊèê‰æõÊõ¥È´òÁöÑË°®ÈÅîËÉΩÂäõ„ÄÇÂàÜÈ°ûÂô®‰ΩøÁî®ÂéüÁîüÂ±ÄÈÉ®ÊúÄ‰Ω≥ÂåñÊäÄË°ìÈÄ≤Ë°åË®ìÁ∑¥ÔºåÊúâÊïàÂú∞ÊêúÁ¥¢ÂèØË°åÂÖ¨ÂºèÁöÑÁ©∫Èñì„ÄÇÊ∑∫Â±§Ë¶èÂâáÂèØ‰ª•Áî®Âø´ÈÄüÁöÑÊï¥Êï∏Á∑öÊÄßË¶èÂäÉ (ILP) Êàñ‰∫åÊ¨°ÁÑ°Á¥ÑÊùü‰∫åÂÖÉÊúÄ‰Ω≥Âåñ (QUBO) Ê±ÇËß£Âô®‰æÜÁ¢∫ÂÆöÔºåÈÄô‰∫õÊ±ÇËß£Âô®ÂèØËÉΩÁî±ÁâπÊÆäÁî®ÈÄîÁöÑÁ°¨È´îÊàñÈáèÂ≠êË£ùÁΩÆÊèê‰æõÊîØÊè¥„ÄÇÊàëÂÄëÂ∞áÂéüÁîüÂ±ÄÈÉ®ÊúÄ‰Ω≥ÂåñÂô®ÁöÑË°®ÈÅîËÉΩÂäõÂíåÊïàÁéáËàáÈÄô‰∫õË£ùÁΩÆÁöÑÂø´ÈÄüÈÅãÁÆóÁõ∏ÁµêÂêàÔºåÈÄèÈÅéÂü∑Ë°åÈùûÂ±ÄÈÉ®ÁßªÂãï‰æÜÊúÄ‰Ω≥ÂåñÂÆåÊï¥Â∏ÉÊûóÂÖ¨ÂºèÁöÑÂ≠êÊ®π„ÄÇÊàëÂÄëÊèê‰æõÂª£Ê≥õÁöÑÊï∏ÂÄºÂü∫Ê∫ñÊ∏¨Ë©¶ÁµêÊûúÔºåÂÖ∂‰∏≠ÂåÖÂê´Âú®ÁúæÊâÄÂë®Áü•ÁöÑÂÖ¨ÂÖ±Ë≥áÊñôÈõÜ‰∏ä‰ΩøÁî®Â§öÂÄãÂü∫Á∑ö„ÄÇÊ†πÊìöÁµêÊûúÔºåÊàëÂÄëÁôºÁèæÂéüÁîüÂ±ÄÈÉ®Ë¶èÂâáÂàÜÈ°ûÂô®ÈÄöÂ∏∏ËàáÂÖ∂‰ªñÂàÜÈ°ûÂô®ÂÖ∑ÊúâÁ´∂Áà≠Âäõ„ÄÇÂä†ÂÖ•ÈùûÂ±ÄÈÉ®ÁßªÂãï‰ª•ËºÉÂ∞ëÁöÑÂèçË¶ÜÈÅãÁÆóÊ¨°Êï∏ÈÅîÊàêÈ°û‰ººÁöÑÁµêÊûúÔºåÂõ†Ê≠§‰ΩøÁî®Â∞àÁî®ÊàñÈáèÂ≠êÁ°¨È´îÂèØËÉΩÊúÉÈÄèÈÅéÂø´ÈÄüÊèêÂá∫ÈùûÂ±ÄÈÉ®ÁßªÂãï‰æÜÂä†ÈÄü„ÄÇ

##### **Utterance Classification with Logical Neural Network: Explainable AI for Mental Disorder Diagnosis**
2306.03902v1 by Yeldar Toleubay, Don Joven Agravante, Daiki Kimura, Baihan Lin, Djallel Bouneffouf, Michiaki Tatsubori

In response to the global challenge of mental health problems, we proposes a
Logical Neural Network (LNN) based Neuro-Symbolic AI method for the diagnosis
of mental disorders. Due to the lack of effective therapy coverage for mental
disorders, there is a need for an AI solution that can assist therapists with
the diagnosis. However, current Neural Network models lack explainability and
may not be trusted by therapists. The LNN is a Recurrent Neural Network
architecture that combines the learning capabilities of neural networks with
the reasoning capabilities of classical logic-based AI. The proposed system
uses input predicates from clinical interviews to output a mental disorder
class, and different predicate pruning techniques are used to achieve
scalability and higher scores. In addition, we provide an insight extraction
method to aid therapists with their diagnosis. The proposed system addresses
the lack of explainability of current Neural Network models and provides a more
trustworthy solution for mental disorder diagnosis.

ÊëòË¶ÅÔºöÁÇ∫‰∫ÜËß£Ê±∫ÂøÉÁêÜÂÅ•Â∫∑ÂïèÈ°åÁöÑÂÖ®ÁêÉÊåëÊà∞ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÂü∫ÊñºÈÇèËºØÁ•ûÁ∂ìÁ∂≤Ë∑Ø (LNN) ÁöÑÁ•ûÁ∂ìÁ¨¶Ëôü AI ÊñπÊ≥ï‰æÜË®∫Êñ∑ÂøÉÁêÜÁñæÁóÖ„ÄÇÁî±ÊñºÁº∫‰πèÊúâÊïàÁöÑÂøÉÁêÜÁñæÁóÖÊ≤ªÁôÇÊ∂µËìãÁØÑÂúçÔºåÂõ†Ê≠§ÈúÄË¶Å‰∏ÄÁ®Æ AI Ëß£Ê±∫ÊñπÊ°à‰æÜÂçîÂä©Ê≤ªÁôÇÂ∏´ÈÄ≤Ë°åË®∫Êñ∑„ÄÇÁÑ∂ËÄåÔºåÁõÆÂâçÁöÑÈ°ûÁ•ûÁ∂ìÁ∂≤Ë∑ØÊ®°ÂûãÁº∫‰πèÂèØËß£ÈáãÊÄßÔºåÊ≤ªÁôÇÂ∏´ÂèØËÉΩÁÑ°Ê≥ï‰ø°‰ªªÂÆÉÂÄë„ÄÇLNN ÊòØ‰∏ÄÁ®ÆÈÅûËø¥Á•ûÁ∂ìÁ∂≤Ë∑ØÊû∂ÊßãÔºåÂÆÉÁµêÂêà‰∫ÜÁ•ûÁ∂ìÁ∂≤Ë∑ØÁöÑÂ≠∏ÁøíËÉΩÂäõÂíåÂü∫ÊñºÁ∂ìÂÖ∏ÈÇèËºØÁöÑ AI ÁöÑÊé®ÁêÜËÉΩÂäõ„ÄÇÊâÄÊèêÂá∫ÁöÑÁ≥ªÁµ±‰ΩøÁî®‰æÜËá™Ëá®Â∫äË®™Ë´áÁöÑËº∏ÂÖ•Ë¨ÇË©û‰æÜËº∏Âá∫ÂøÉÁêÜÁñæÁóÖÈ°ûÂà•Ôºå‰∏¶‰ΩøÁî®‰∏çÂêåÁöÑË¨ÇË©ûÂâ™ÊûùÊäÄË°ì‰æÜÂØ¶ÁèæÂèØÊì¥ÂÖÖÊÄßÂíåÊõ¥È´òÁöÑÂàÜÊï∏„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèê‰æõ‰∫Ü‰∏ÄÂÄãË¶ãËß£ÊèêÂèñÊñπÊ≥ï‰æÜÂçîÂä©Ê≤ªÁôÇÂ∏´ÈÄ≤Ë°åË®∫Êñ∑„ÄÇÊâÄÊèêÂá∫ÁöÑÁ≥ªÁµ±Ëß£Ê±∫‰∫ÜÁï∂ÂâçÈ°ûÁ•ûÁ∂ìÁ∂≤Ë∑ØÊ®°ÂûãÁº∫‰πèÂèØËß£ÈáãÊÄßÁöÑÂïèÈ°åÔºå‰∏¶ÁÇ∫ÂøÉÁêÜÁñæÁóÖË®∫Êñ∑Êèê‰æõ‰∫ÜÊõ¥ÂÄºÂæó‰ø°Ë≥¥ÁöÑËß£Ê±∫ÊñπÊ°à„ÄÇ

##### **XAI Renaissance: Redefining Interpretability in Medical Diagnostic Models**
2306.01668v1 by Sujith K Mandala

As machine learning models become increasingly prevalent in medical
diagnostics, the need for interpretability and transparency becomes paramount.
The XAI Renaissance signifies a significant shift in the field, aiming to
redefine the interpretability of medical diagnostic models. This paper explores
the innovative approaches and methodologies within the realm of Explainable AI
(XAI) that are revolutionizing the interpretability of medical diagnostic
models. By shedding light on the underlying decision-making process, XAI
techniques empower healthcare professionals to understand, trust, and
effectively utilize these models for accurate and reliable medical diagnoses.
This review highlights the key advancements in XAI for medical diagnostics and
their potential to transform the healthcare landscape, ultimately improving
patient outcomes and fostering trust in AI-driven diagnostic systems.

ÊëòË¶ÅÔºöÈö®ËëóÊ©üÂô®Â≠∏ÁøíÊ®°ÂûãÂú®ÈÜ´ÁôÇË®∫Êñ∑‰∏≠Ë∂ä‰æÜË∂äÊôÆÈÅçÔºåÂèØËß£ÈáãÊÄßÂíåÈÄèÊòéÂ∫¶ÁöÑÈúÄÊ±ÇËÆäÂæóËá≥ÈóúÈáçË¶Å„ÄÇXAI Âæ©ËààÊ®ôË™åËëóË©≤È†òÂüüÁöÑÈáçÂ§ßËΩâËÆäÔºåÊó®Âú®ÈáçÊñ∞ÂÆöÁæ©ÈÜ´ÁôÇË®∫Êñ∑Ê®°ÂûãÁöÑÂèØËß£ÈáãÊÄß„ÄÇÊú¨ÊñáÊé¢Ë®é‰∫ÜÂèØËß£Èáã AI (XAI) È†òÂüüÂÖßÁöÑÂâµÊñ∞ÊñπÊ≥ïÂíåÊñπÊ≥ïË´ñÔºåÈÄô‰∫õÊñπÊ≥ïÂíåÊñπÊ≥ïË´ñÊ≠£Âú®Èù©Êñ∞ÈÜ´ÁôÇË®∫Êñ∑Ê®°ÂûãÁöÑÂèØËß£ÈáãÊÄß„ÄÇÈÄöÈÅéÈó°ÊòéÂü∫Á§éÊ±∫Á≠ñÂà∂ÂÆöÈÅéÁ®ãÔºåXAI ÊäÄË°ì‰ΩøÈÜ´ÁôÇ‰øùÂÅ•Â∞àÊ•≠‰∫∫Âì°ËÉΩÂ§†ÁêÜËß£„ÄÅ‰ø°‰ªª‰∏¶ÊúâÊïàÂú∞Âà©Áî®ÈÄô‰∫õÊ®°ÂûãÈÄ≤Ë°åÊ∫ñÁ¢∫‰∏îÂèØÈù†ÁöÑÈÜ´ÁôÇË®∫Êñ∑„ÄÇÊú¨Á∂úËø∞ÈáçÈªû‰ªãÁ¥π‰∫Ü XAI Âú®ÈÜ´ÁôÇË®∫Êñ∑ÊñπÈù¢ÁöÑÈóúÈçµÈÄ≤Â±ïÂèäÂÖ∂ËΩâËÆäÈÜ´ÁôÇ‰øùÂÅ•È†òÂüüÁöÑÊΩõÂäõÔºåÊúÄÁµÇÊîπÂñÑÊÇ£ËÄÖÁöÑÊ≤ªÁôÇÊïàÊûú‰∏¶ÂüπÈ§äÂ∞ç AI È©ÖÂãïÁöÑË®∫Êñ∑Á≥ªÁµ±ÁöÑ‰ø°‰ªª„ÄÇ

##### **A Novel real-time arrhythmia detection model using YOLOv8**
2305.16727v3 by Guang Jun Nicholas Ang, Aritejh Kr Goil, Henryk Chan, Jieyi Jeric Lew, Xin Chun Lee, Raihan Bin Ahmad Mustaffa, Timotius Jason, Ze Ting Woon, Bingquan Shen

In a landscape characterized by heightened connectivity and mobility, coupled
with a surge in cardiovascular ailments, the imperative to curtail healthcare
expenses through remote monitoring of cardiovascular health has become more
pronounced. The accurate detection and classification of cardiac arrhythmias
are pivotal for diagnosing individuals with heart irregularities. This study
underscores the feasibility of employing electrocardiograms (ECG) measurements
in the home environment for real-time arrhythmia detection. Presenting a fresh
application for arrhythmia detection, this paper leverages the cutting-edge
You-Only-Look-Once (YOLO)v8 algorithm to categorize single-lead ECG signals. We
introduce a novel loss-modified YOLOv8 model, fine-tuned on the MIT-BIH
arrhythmia dataset, enabling real-time continuous monitoring. The obtained
results substantiate the efficacy of our approach, with the model attaining an
average accuracy of 99.5% and 0.992 mAP@50, and a rapid detection time of 0.002
seconds on an NVIDIA Tesla V100. Our investigation exemplifies the potential of
real-time arrhythmia detection, enabling users to visually interpret the model
output within the comfort of their homes. Furthermore, this study lays the
groundwork for an extension into a real-time explainable AI (XAI) model capable
of deployment in the healthcare sector, thereby significantly advancing the
realm of healthcare solutions.

ÊëòË¶ÅÔºö<paragraph>Âú®‰ª•È´òÂ∫¶ÈÄ£Êé•ÊÄßÂíåÊµÅÂãïÊÄßÁÇ∫ÁâπÂæµÁöÑÁí∞Â¢É‰∏≠ÔºåÂä†‰∏äÂøÉË°ÄÁÆ°ÁñæÁóÖÁöÑÊøÄÂ¢ûÔºåÈÄöÈÅéÈÅ†Á®ãÁõ£ÊéßÂøÉË°ÄÁÆ°ÂÅ•Â∫∑‰æÜÂâäÊ∏õÈÜ´ÁôÇ‰øùÂÅ•ÊîØÂá∫ÁöÑÂøÖË¶ÅÊÄßËÆäÂæóÊõ¥Âä†ÊòéÈ°Ø„ÄÇÊ∫ñÁ¢∫Ê™¢Ê∏¨ÂíåÂàÜÈ°ûÂøÉÂæã‰∏çÊï¥Â∞çÊñºË®∫Êñ∑ÊÇ£ÊúâÂøÉËáü‰∏çË¶èÂâáÁöÑ‰∫∫Ëá≥ÈóúÈáçË¶Å„ÄÇÊú¨Á†îÁ©∂Âº∑Ë™ø‰∫ÜÂú®ÂÆ∂‰∏≠‰ΩøÁî®ÂøÉÈõªÂúñ (ECG) Ê∏¨ÈáèÈÄ≤Ë°åÂØ¶ÊôÇÂøÉÂæã‰∏çÊï¥Ê™¢Ê∏¨ÁöÑÂèØË°åÊÄß„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞ÁöÑÂøÉÂæã‰∏çÊï¥Ê™¢Ê∏¨ÊáâÁî®ÔºåÂà©Áî®Â∞ñÁ´ØÁöÑ You-Only-Look-Once (YOLO)v8 ÊºîÁÆóÊ≥ïÂ∞çÂñÆÂ∞éËÅØ ECG Ë®äËôüÈÄ≤Ë°åÂàÜÈ°û„ÄÇÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÊñ∞Á©éÁöÑÊêçÂ§±‰øÆÊîπ YOLOv8 Ê®°ÂûãÔºå‰∏¶ÈáùÂ∞ç MIT-BIH ÂøÉÂæã‰∏çÊï¥Ë≥áÊñôÈõÜÈÄ≤Ë°å‰∫ÜÂæÆË™øÔºåÂæûËÄåÂØ¶Áèæ‰∫ÜÂØ¶ÊôÇÁöÑÊåÅÁ∫åÁõ£Êéß„ÄÇÁç≤ÂæóÁöÑÁµêÊûúË≠âÂØ¶‰∫ÜÊàëÂÄëÊñπÊ≥ïÁöÑÊúâÊïàÊÄßÔºåË©≤Ê®°ÂûãÂú® NVIDIA Tesla V100 ‰∏äÈÅîÂà∞‰∫Ü 99.5% ÁöÑÂπ≥ÂùáÊ∫ñÁ¢∫Â∫¶Âíå 0.992 mAP@50Ôºå‰ª•Âèä 0.002 ÁßíÁöÑÂø´ÈÄüÊ™¢Ê∏¨ÊôÇÈñì„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂Ë™™Êòé‰∫ÜÂØ¶ÊôÇÂøÉÂæã‰∏çÊï¥Ê™¢Ê∏¨ÁöÑÊΩõÂäõÔºå‰ΩøÁî®Êà∂ËÉΩÂ§†Âú®ÂÆ∂‰∏≠ËàíÈÅ©Âú∞Ë¶ñË¶∫ÂåñËß£ËÆÄÊ®°ÂûãËº∏Âá∫„ÄÇÊ≠§Â§ñÔºåÊú¨Á†îÁ©∂ÁÇ∫Êì¥Â±ïÂà∞ÂØ¶ÊôÇÂèØËß£Èáã AI (XAI) Ê®°ÂûãÂ•†ÂÆö‰∫ÜÂü∫Á§éÔºåË©≤Ê®°ÂûãËÉΩÂ§†ÈÉ®ÁΩ≤Âú®ÈÜ´ÁôÇ‰øùÂÅ•È†òÂüüÔºåÂæûËÄåÈ°ØËëóÊé®ÈÄ≤ÈÜ´ÁôÇ‰øùÂÅ•Ëß£Ê±∫ÊñπÊ°àÁöÑÈ†òÂüü„ÄÇ</paragraph>

##### **Breast Cancer Segmentation using Attention-based Convolutional Network and Explainable AI**
2305.14389v2 by Jai Vardhan, Taraka Satya Krishna Teja Malisetti

Breast cancer (BC) remains a significant health threat, with no long-term
cure currently available. Early detection is crucial, yet mammography
interpretation is hindered by high false positives and negatives. With BC
incidence projected to surpass lung cancer, improving early detection methods
is vital. Thermography, using high-resolution infrared cameras, offers promise,
especially when combined with artificial intelligence (AI). This work presents
an attention-based convolutional neural network for segmentation, providing
increased speed and precision in BC detection and classification. The system
enhances images and performs cancer segmentation with explainable AI. We
propose a transformer-attention-based convolutional architecture (UNet) for
fault identification and employ Gradient-weighted Class Activation Mapping
(Grad-CAM) to analyze areas of bias and weakness in the UNet architecture with
IRT images. The superiority of our proposed framework is confirmed when
compared with existing deep learning frameworks.

ÊëòË¶ÅÔºö‰π≥ÁôåÔºàBCÔºâ‰ªçÁÑ∂ÊòØ‰∏ÄÂÄãÈáçÂ§ßÁöÑÂÅ•Â∫∑Â®ÅËÑÖÔºåÁõÆÂâçÂ∞öÁÑ°Èï∑ÊúüÊ≤ªÁôíÁöÑÊñπÊ≥ï„ÄÇÊó©ÊúüÁôºÁèæËá≥ÈóúÈáçË¶ÅÔºå‰ΩÜ‰π≥ÊàøÊîùÂΩ±ÁöÑÂà§ËÆÄÂçªÂèóÂà∞È´òÂÅáÈôΩÊÄßÂíåÂÅáÈô∞ÊÄßÁöÑÈòªÁ§ô„ÄÇÁî±Êñº‰π≥ÁôåÁöÑÁôºÁîüÁéáÈ†êË®àÂ∞áË∂ÖÈÅéËÇ∫ÁôåÔºåÂõ†Ê≠§ÊîπÂñÑÊó©ÊúüÊ™¢Ê∏¨ÊñπÊ≥ïËá≥ÈóúÈáçË¶Å„ÄÇÁÜ±ÂÉèÊîùÂΩ±‰ΩøÁî®È´òËß£ÊûêÂ∫¶Á¥ÖÂ§ñÁ∑öÁõ∏Ê©üÔºåÁâπÂà•ÊòØÂú®Ëàá‰∫∫Â∑•Êô∫ÊÖßÔºàAIÔºâÁµêÂêà‰ΩøÁî®ÊôÇÔºåÊèê‰æõ‰∫ÜÂ∏åÊúõ„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂü∫ÊñºÊ≥®ÊÑèÂäõÁöÑÂç∑Á©çÁ•ûÁ∂ìÁ∂≤Ë∑ØÁî®ÊñºÂàÜÂâ≤ÔºåÂú®‰π≥ÁôåÊ™¢Ê∏¨ÂíåÂàÜÈ°û‰∏≠Êèê‰æõ‰∫ÜÊõ¥È´òÁöÑÈÄüÂ∫¶ÂíåÁ≤æÂ∫¶„ÄÇË©≤Á≥ªÁµ±Â¢ûÂº∑ÂΩ±ÂÉè‰∏¶Âü∑Ë°åÂèØËß£ÈáãÁöÑ AI ÁôåÁóáÂàÜÂâ≤„ÄÇÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂü∫ÊñºTransformerÊ≥®ÊÑèÂäõÁöÑÂç∑Á©çÊû∂ÊßãÔºàUNetÔºâÁî®ÊñºÊïÖÈöúË≠òÂà•Ôºå‰∏¶‰ΩøÁî®Ê¢ØÂ∫¶Âä†Ê¨äÈ°ûÊøÄÊ¥ªÊò†Â∞ÑÔºàGrad-CAMÔºâ‰æÜÂàÜÊûê UNet Êû∂Êßã‰∏≠ÂÅèË¶ãÂíåÂº±ÈªûÁöÑÂçÄÂüüÔºå‰ΩøÁî® IRT ÂΩ±ÂÉè„ÄÇËàáÁèæÊúâÁöÑÊ∑±Â∫¶Â≠∏ÁøíÊ°ÜÊû∂Áõ∏ÊØîÔºåÊàëÂÄëÊèêÂá∫ÁöÑÊ°ÜÊû∂ÁöÑÂÑ™Ë∂äÊÄßÂæóÂà∞Ë≠âÂØ¶„ÄÇ

##### **What Symptoms and How Long? An Interpretable AI Approach for Depression Detection in Social Media**
2305.13127v2 by Junwei Kuang, Jiaheng Xie, Zhijun Yan

Depression is the most prevalent and serious mental illness, which induces
grave financial and societal ramifications. Depression detection is key for
early intervention to mitigate those consequences. Such a high-stake decision
inherently necessitates interpretability. Although a few depression detection
studies attempt to explain the decision based on the importance score or
attention weights, these explanations misalign with the clinical depression
diagnosis criterion that is based on depressive symptoms. To fill this gap, we
follow the computational design science paradigm to develop a novel Multi-Scale
Temporal Prototype Network (MSTPNet). MSTPNet innovatively detects and
interprets depressive symptoms as well as how long they last. Extensive
empirical analyses using a large-scale dataset show that MSTPNet outperforms
state-of-the-art depression detection methods with an F1-score of 0.851. This
result also reveals new symptoms that are unnoted in the survey approach, such
as sharing admiration for a different life. We further conduct a user study to
demonstrate its superiority over the benchmarks in interpretability. This study
contributes to IS literature with a novel interpretable deep learning model for
depression detection in social media. In practice, our proposed method can be
implemented in social media platforms to provide personalized online resources
for detected depressed patients.

ÊëòË¶ÅÔºöÊÜÇÈ¨±ÁóáÊòØÊúÄÊôÆÈÅç‰∏îÂö¥ÈáçÁöÑÁ≤æÁ•ûÁñæÁóÖÔºåÊúÉÈÄ†ÊàêÂö¥ÈáçÁöÑË≤°ÂãôÂíåÁ§æÊúÉÂæåÊûú„ÄÇÊÜÇÈ¨±ÁóáÁöÑÂÅµÊ∏¨Â∞çÊñºÊó©Êúü‰ªãÂÖ•‰ª•Ê∏õËºïÈÄô‰∫õÂæåÊûúËá≥ÈóúÈáçË¶Å„ÄÇÂ¶ÇÊ≠§ÈáçÂ§ßÁöÑÊ±∫ÂÆöÊú¨Ë≥™‰∏äÈúÄË¶ÅÂèØËß£ÈáãÊÄß„ÄÇÂÑòÁÆ°‰∏Ä‰∫õÊÜÇÈ¨±ÁóáÂÅµÊ∏¨Á†îÁ©∂ÂòóË©¶Ê†πÊìöÈáçË¶ÅÊÄßÂàÜÊï∏ÊàñÊ≥®ÊÑèÂäõÊ¨äÈáç‰æÜËß£ÈáãÈÄôÂÄãÊ±∫ÂÆöÔºå‰ΩÜÈÄô‰∫õËß£ÈáãËàáÂü∫ÊñºÊÜÇÈ¨±ÁóáÁãÄÁöÑËá®Â∫äÊÜÇÈ¨±ÁóáË®∫Êñ∑Ê®ôÊ∫ñ‰∏ç‰∏ÄËá¥„ÄÇÁÇ∫‰∫ÜÂ°´Ë£úÈÄôÂÄãÁº∫Âè£ÔºåÊàëÂÄëÈÅµÂæ™Ë®àÁÆóË®≠Ë®àÁßëÂ≠∏ÁØÑ‰æã‰æÜÈñãÁôº‰∏ÄÂÄãÊñ∞Á©éÁöÑÂ§öÂ∞∫Â∫¶ÊôÇÈñìÂéüÂûãÁ∂≤Ë∑Ø (MSTPNet)„ÄÇMSTPNet ÂâµÊñ∞Âú∞ÂÅµÊ∏¨‰∏¶Ëß£ÈáãÊÜÇÈ¨±ÁóáÁãÄ‰ª•ÂèäÂÆÉÂÄëÊåÅÁ∫åÂ§ö‰πÖ„ÄÇ‰ΩøÁî®Â§ßË¶èÊ®°Ë≥áÊñôÈõÜÈÄ≤Ë°åÁöÑÂª£Ê≥õÂØ¶Ë≠âÂàÜÊûêÈ°ØÁ§∫ÔºåMSTPNet ‰ª• 0.851 ÁöÑ F1 ÂàÜÊï∏ÂÑ™ÊñºÊúÄÂÖàÈÄ≤ÁöÑÊÜÇÈ¨±ÁóáÂÅµÊ∏¨ÊñπÊ≥ï„ÄÇÊ≠§ÁµêÊûúÈÇÑÊè≠Á§∫‰∫ÜË™øÊü•ÊñπÊ≥ï‰∏≠Êú™Ê≥®ÊÑèÂà∞ÁöÑÊñ∞ÁóáÁãÄÔºå‰æãÂ¶ÇÂàÜ‰∫´Â∞ç‰∏çÂêåÁîüÊ¥ªÁöÑÊ¨Ω‰Ω©„ÄÇÊàëÂÄëÈÄ≤‰∏ÄÊ≠•ÈÄ≤Ë°å‰ΩøÁî®ËÄÖÁ†îÁ©∂Ôºå‰ª•Ë≠âÊòéÂÖ∂Âú®ÂèØËß£ÈáãÊÄßÊñπÈù¢ÂÑ™ÊñºÂü∫Ê∫ñ„ÄÇÊú¨Á†îÁ©∂‰ª•‰∏ÄÂÄãÊñ∞Á©éÁöÑÂèØËß£ÈáãÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÁÇ∫ÊÜÇÈ¨±ÁóáÂÅµÊ∏¨Âú®Á§æÁæ§Â™íÈ´î‰∏≠ÁöÑ IS ÊñáÁçªÂÅöÂá∫Ë≤¢Áçª„ÄÇÂú®ÂØ¶Âãô‰∏äÔºåÊàëÂÄëÊèêÂá∫ÁöÑÊñπÊ≥ïÂèØ‰ª•ÂØ¶‰ΩúÂú®Á§æÁæ§Â™íÈ´îÂπ≥Âè∞‰∏≠Ôºå‰ª•Êèê‰æõÂÄã‰∫∫ÂåñÁöÑÁ∑ö‰∏äË≥áÊ∫êÁµ¶Ë¢´ÂÅµÊ∏¨Âá∫ÊÜÇÈ¨±ÁóáÁöÑÊÇ£ËÄÖ„ÄÇ

##### **Echoes of Biases: How Stigmatizing Language Affects AI Performance**
2305.10201v4 by Yizhi Liu, Weiguang Wang, Guodong Gordon Gao, Ritu Agarwal

Electronic health records (EHRs) serve as an essential data source for the
envisioned artificial intelligence (AI)-driven transformation in healthcare.
However, clinician biases reflected in EHR notes can lead to AI models
inheriting and amplifying these biases, perpetuating health disparities. This
study investigates the impact of stigmatizing language (SL) in EHR notes on
mortality prediction using a Transformer-based deep learning model and
explainable AI (XAI) techniques. Our findings demonstrate that SL written by
clinicians adversely affects AI performance, particularly so for black
patients, highlighting SL as a source of racial disparity in AI model
development. To explore an operationally efficient way to mitigate SL's impact,
we investigate patterns in the generation of SL through a clinicians'
collaborative network, identifying central clinicians as having a stronger
impact on racial disparity in the AI model. We find that removing SL written by
central clinicians is a more efficient bias reduction strategy than eliminating
all SL in the entire corpus of data. This study provides actionable insights
for responsible AI development and contributes to understanding clinician
behavior and EHR note writing in healthcare.

ÊëòË¶ÅÔºöÈõªÂ≠êÂÅ•Â∫∑Á¥ÄÈåÑ (EHR) ‰ΩúÁÇ∫È†êÊÉ≥‰∏≠Áî±‰∫∫Â∑•Êô∫ÊÖß (AI) Êé®ÂãïÁöÑÈÜ´ÁôÇ‰øùÂÅ•ËΩâÂûãÁöÑÈáçË¶ÅË≥áÊñô‰æÜÊ∫ê„ÄÇÁÑ∂ËÄåÔºåÂèçÊò†Âú® EHR ÂÇôË®ª‰∏≠ÁöÑËá®Â∫äÂÅèË¶ãÂèØËÉΩÂ∞éËá¥ AI Ê®°ÂûãÁπºÊâø‰∏¶Êì¥Â§ßÈÄô‰∫õÂÅèË¶ãÔºåÈÄ≤ËÄåÈÄ†ÊàêÂÅ•Â∫∑Â∑ÆÁï∞„ÄÇÊú¨Á†îÁ©∂Êé¢Ë®é EHR ÂÇôË®ª‰∏≠Ê±ôÂêçÂåñË™ûË®Ä (SL) Â∞ç‰ΩøÁî®Âü∫Êñº Transformer ÁöÑÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÂíåÂèØËß£Èáã AI (XAI) ÊäÄË°ìÈ†êÊ∏¨Ê≠ª‰∫°ÁéáÁöÑÂΩ±Èüø„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúË°®ÊòéÔºåÁî±Ëá®Â∫äÈÜ´ÁîüÊí∞ÂØ´ÁöÑ SL ÊúÉÂ∞ç AI ÊïàËÉΩÁî¢Áîü‰∏çÂà©ÂΩ±ÈüøÔºåÁâπÂà•ÊòØÂ∞çÈªë‰∫∫ÊÇ£ËÄÖËÄåË®ÄÔºåÁ™ÅÈ°Ø SL ÊòØ AI Ê®°ÂûãÈñãÁôº‰∏≠Á®ÆÊóèÂ∑ÆÁï∞ÁöÑ‰æÜÊ∫ê„ÄÇÁÇ∫‰∫ÜÊé¢Á¥¢‰∏ÄÁ®ÆÈÅã‰Ωú‰∏äÊúâÊïàÁéáÁöÑÊñπÊ≥ï‰æÜÊ∏õËºï SL ÁöÑÂΩ±ÈüøÔºåÊàëÂÄëÈÄèÈÅéËá®Â∫äÈÜ´ÁîüÁöÑÂçî‰ΩúÁ∂≤Ë∑ØÊé¢Ë®é SL Áî¢ÁîüÁöÑÊ®°ÂºèÔºå‰∏¶ÊâæÂá∫Ê†∏ÂøÉËá®Â∫äÈÜ´ÁîüÂ∞ç AI Ê®°Âûã‰∏≠ÁöÑÁ®ÆÊóèÂ∑ÆÁï∞ÊúâËºÉÂ§ßÁöÑÂΩ±Èüø„ÄÇÊàëÂÄëÁôºÁèæÔºåÁßªÈô§Áî±Ê†∏ÂøÉËá®Â∫äÈÜ´ÁîüÊí∞ÂØ´ÁöÑ SL ÊòØÊØîÊ∂àÈô§Ë≥áÊñôÈõÜ‰∏≠ÊâÄÊúâ SL Êõ¥ÊúâÊïàÁéáÁöÑÂÅèË¶ãÊ∏õÂ∞ëÁ≠ñÁï•„ÄÇÊú¨Á†îÁ©∂Êèê‰æõÂèØË°åÁöÑË¶ãËß£ÔºåÁî®ÊñºË≤†Ë≤¨‰ªªÁöÑ AI ÈñãÁôºÔºå‰∏¶ÊúâÂä©Êñº‰∫ÜËß£Ëá®Â∫äÈÜ´ÁîüË°åÁÇ∫ÂíåÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÁöÑ EHR ÂÇôË®ªÊí∞ÂØ´„ÄÇ

##### **Explaining the ghosts: Feminist intersectional XAI and cartography as methods to account for invisible labour**
2305.03376v1 by Goda Klumbyte, Hannah Piehl, Claude Draude

Contemporary automation through AI entails a substantial amount of
behind-the-scenes human labour, which is often both invisibilised and
underpaid. Since invisible labour, including labelling and maintenance work, is
an integral part of contemporary AI systems, it remains important to sensitise
users to its role. We suggest that this could be done through explainable AI
(XAI) design, particularly feminist intersectional XAI. We propose the method
of cartography, which stems from feminist intersectional research, to draw out
a systemic perspective of AI and include dimensions of AI that pertain to
invisible labour.

ÊëòË¶ÅÔºöÁï∂‰ª£ÈÄöÈÅé AI ÁöÑËá™ÂãïÂåñÈúÄË¶ÅÂ§ßÈáèÁöÑÂπïÂæå‰∫∫ÂäõÔºåÈÄôÈÄöÂ∏∏Êó¢‰∏çÂèØË¶ã‰∏îËñ™Ë≥áÈÅé‰Ωé„ÄÇÁî±Êñº‰∏çÂèØË¶ãÁöÑÂãûÂãïÔºåÂåÖÊã¨Ê®ôÁ±§ÂíåÁ∂≠Ë≠∑Â∑•‰ΩúÔºåÊòØÁï∂‰ª£ AI Á≥ªÁµ±ÁöÑÁµÑÊàêÈÉ®ÂàÜÔºåÂõ†Ê≠§ËÆì‰ΩøÁî®ËÄÖ‰∫ÜËß£ÂÖ∂ËßíËâ≤‰ªçÁÑ∂ÂæàÈáçË¶Å„ÄÇÊàëÂÄëÂª∫Ë≠∞ÈÄôÂèØ‰ª•ÈÄèÈÅéÂèØËß£ÈáãÁöÑ AIÔºàXAIÔºâË®≠Ë®à‰æÜÂÆåÊàêÔºåÁâπÂà•ÊòØÂ•≥ÊÄß‰∏ªÁæ©‰∫§ÂèâÁöÑ XAI„ÄÇÊàëÂÄëÊèêÂá∫Ê∫êËá™Â•≥ÊÄß‰∏ªÁæ©‰∫§ÂèâÁ†îÁ©∂ÁöÑË£ΩÂúñÊñπÊ≥ïÔºå‰ª•ÊèêÂá∫ AI ÁöÑÁ≥ªÁµ±ËßÄÈªûÔºå‰∏¶Á¥çÂÖ•Ëàá‰∏çÂèØË¶ãÂãûÂãïÁõ∏ÈóúÁöÑ AI Á∂≠Â∫¶„ÄÇ

##### **Towards Explainable and Safe Conversational Agents for Mental Health: A Survey**
2304.13191v1 by Surjodeep Sarkar, Manas Gaur, L. Chen, Muskan Garg, Biplav Srivastava, Bhaktee Dongaonkar

Virtual Mental Health Assistants (VMHAs) are seeing continual advancements to
support the overburdened global healthcare system that gets 60 million primary
care visits, and 6 million Emergency Room (ER) visits annually. These systems
are built by clinical psychologists, psychiatrists, and Artificial Intelligence
(AI) researchers for Cognitive Behavioral Therapy (CBT). At present, the role
of VMHAs is to provide emotional support through information, focusing less on
developing a reflective conversation with the patient. A more comprehensive,
safe and explainable approach is required to build responsible VMHAs to ask
follow-up questions or provide a well-informed response. This survey offers a
systematic critical review of the existing conversational agents in mental
health, followed by new insights into the improvements of VMHAs with contextual
knowledge, datasets, and their emerging role in clinical decision support. We
also provide new directions toward enriching the user experience of VMHAs with
explainability, safety, and wholesome trustworthiness. Finally, we provide
evaluation metrics and practical considerations for VMHAs beyond the current
literature to build trust between VMHAs and patients in active communications.

ÊëòË¶ÅÔºöËôõÊì¨ÂøÉÁêÜÂÅ•Â∫∑Âä©ÁêÜ (VMHA) ÊåÅÁ∫åÈÄ≤Ê≠•Ôºå‰ª•ÊîØÊè¥ÊØèÂπ¥Êúâ 6000 Ëê¨‰∫∫Ê¨°ÂàùÁ¥ö‰øùÂÅ•Â∞±Ë®∫Âíå 600 Ëê¨‰∫∫Ê¨°ÊÄ•Ë®∫ÂÆ§ (ER) Â∞±Ë®∫ÁöÑË∂ÖË≤†Ëç∑ÂÖ®ÁêÉÈÜ´ÁôÇ‰øùÂÅ•Á≥ªÁµ±„ÄÇÈÄô‰∫õÁ≥ªÁµ±ÊòØÁî±Ëá®Â∫äÂøÉÁêÜÂ≠∏ÂÆ∂„ÄÅÁ≤æÁ•ûÁßëÈÜ´Â∏´Âíå‰∫∫Â∑•Êô∫ÊÖß (AI) Á†îÁ©∂‰∫∫Âì°ÁÇ∫Ë™çÁü•Ë°åÁÇ∫ÁôÇÊ≥ï (CBT) ÊâÄÂª∫Êßã„ÄÇÁõÆÂâçÔºåVMHA ÁöÑËßíËâ≤ÊòØÈÄèÈÅéË≥áË®äÊèê‰æõÊÉÖÁ∑íÊîØÊåÅÔºåËºÉÂ∞ëËëóÈáçÊñºËàáÊÇ£ËÄÖÁôºÂ±ïÂèçÊÄùÊÄßÁöÑÂ∞çË©±„ÄÇÈúÄË¶ÅÊõ¥ÂÖ®Èù¢„ÄÅÂÆâÂÖ®‰∏îÂèØËß£ÈáãÁöÑÊñπÊ≥ï‰æÜÂª∫ÊßãË≤†Ë≤¨‰ªªÁöÑ VMHAÔºå‰ª•ÊèêÂá∫ÂæåÁ∫åÂïèÈ°åÊàñÊèê‰æõÂÖÖÂàÜÁöÑÂõûÊáâ„ÄÇÈÄôÈ†ÖË™øÊü•Êèê‰æõ‰∫ÜÂ∞çÂøÉÁêÜÂÅ•Â∫∑‰∏≠ÁèæÊúâÂ∞çË©±‰ª£ÁêÜÁöÑÁ≥ªÁµ±ÊÄßÊâπÂà§ÊÄßÂõûÈ°ßÔºåÊé•ËëóÊ∑±ÂÖ•Êé¢Ë®é‰∫Ü VMHA Âú®ËÑàÁµ°Áü•Ë≠ò„ÄÅË≥áÊñôÈõÜÂíåÂÖ∂Âú®Ëá®Â∫äÊ±∫Á≠ñÊîØÊè¥‰∏≠Êñ∞ËààËßíËâ≤ÁöÑÊîπÈÄ≤„ÄÇÊàëÂÄë‰πüÊèê‰æõ‰∫ÜÊñ∞ÁöÑÊñπÂêëÔºå‰ª•ÈÄèÈÅéÂèØËß£ÈáãÊÄß„ÄÅÂÆâÂÖ®ÊÄßËàáÊï¥È´îÂèØ‰ø°Â∫¶‰æÜË±êÂØå VMHA ÁöÑ‰ΩøÁî®ËÄÖÈ´îÈ©ó„ÄÇÊúÄÂæåÔºåÊàëÂÄëÊèê‰æõ‰∫ÜË©ïÈáèÊåáÊ®ôÂíå VMHA ÁöÑÂØ¶ÂãôËÄÉÈáèÔºåË∂ÖË∂äÁõÆÂâçÁöÑÊñáÁçªÔºåÂú® VMHA ËàáÊÇ£ËÄÖÁöÑÁ©çÊ•µÊ∫ùÈÄö‰∏≠Âª∫Á´ã‰ø°‰ªª„ÄÇ

##### **A Brief Review of Explainable Artificial Intelligence in Healthcare**
2304.01543v1 by Zahra Sadeghi, Roohallah Alizadehsani, Mehmet Akif Cifci, Samina Kausar, Rizwan Rehman, Priyakshi Mahanta, Pranjal Kumar Bora, Ammar Almasri, Rami S. Alkhawaldeh, Sadiq Hussain, Bilal Alatas, Afshin Shoeibi, Hossein Moosaei, Milan Hladik, Saeid Nahavandi, Panos M. Pardalos

XAI refers to the techniques and methods for building AI applications which
assist end users to interpret output and predictions of AI models. Black box AI
applications in high-stakes decision-making situations, such as medical domain
have increased the demand for transparency and explainability since wrong
predictions may have severe consequences. Model explainability and
interpretability are vital successful deployment of AI models in healthcare
practices. AI applications' underlying reasoning needs to be transparent to
clinicians in order to gain their trust. This paper presents a systematic
review of XAI aspects and challenges in the healthcare domain. The primary
goals of this study are to review various XAI methods, their challenges, and
related machine learning models in healthcare. The methods are discussed under
six categories: Features-oriented methods, global methods, concept models,
surrogate models, local pixel-based methods, and human-centric methods. Most
importantly, the paper explores XAI role in healthcare problems to clarify its
necessity in safety-critical applications. The paper intends to establish a
comprehensive understanding of XAI-related applications in the healthcare field
by reviewing the related experimental results. To facilitate future research
for filling research gaps, the importance of XAI models from different
viewpoints and their limitations are investigated.

ÊëòË¶ÅÔºöXAI ÊåáÁöÑÊòØÁî®ÊñºÂª∫Êßã AI ÊáâÁî®Á®ãÂºèÁöÑÊäÄË°ìÂíåÊñπÊ≥ïÔºåÈÄô‰∫õÊáâÁî®Á®ãÂºèÂèØÂçîÂä©ÊúÄÁµÇ‰ΩøÁî®ËÄÖË©ÆÈáã AI Ê®°ÂûãÁöÑËº∏Âá∫ÂíåÈ†êÊ∏¨„ÄÇÂú®È´òÈ¢®Èö™Ê±∫Á≠ñÊÉÖÂ¢É‰∏≠Ôºå‰æãÂ¶ÇÈÜ´ÁôÇÈ†òÂüüÔºåÈªëÁÆ± AI ÊáâÁî®Á®ãÂºèÂ¢ûÂä†‰∫ÜÈÄèÊòéÂ∫¶ÂíåÂèØËß£ÈáãÊÄßÁöÑÈúÄÊ±ÇÔºåÂõ†ÁÇ∫ÈåØË™§ÁöÑÈ†êÊ∏¨ÂèØËÉΩÊúÉÈÄ†ÊàêÂö¥ÈáçÁöÑÂæåÊûú„ÄÇÊ®°ÂûãÂèØËß£ÈáãÊÄßÂíåÂèØË©ÆÈáãÊÄßÂ∞çÊñºÂú®ÈÜ´ÁôÇÂØ¶Âãô‰∏≠ÊàêÂäüÈÉ®ÁΩ≤ AI Ê®°ÂûãËá≥ÈóúÈáçË¶Å„ÄÇAI ÊáâÁî®Á®ãÂºèÁöÑÂü∫Êú¨Êé®ÁêÜÈúÄË¶ÅÂ∞çËá®Â∫äÈÜ´ÁîüÈÄèÊòéÔºåÊâçËÉΩÁç≤Âæó‰ªñÂÄëÁöÑ‰ø°‰ªª„ÄÇÊú¨ÊñáÊèê‰æõ‰∫ÜÈÜ´ÁôÇÈ†òÂüü‰∏≠ XAI Èù¢ÂêëÂíåÊåëÊà∞ÁöÑÁ≥ªÁµ±ÊÄßÂõûÈ°ß„ÄÇÊú¨Á†îÁ©∂ÁöÑ‰∏ªË¶ÅÁõÆÊ®ôÊòØÂõûÈ°ßÂêÑÁ®Æ XAI ÊñπÊ≥ï„ÄÅÂÖ∂ÊåëÊà∞Ôºå‰ª•ÂèäÁõ∏ÈóúÁöÑÈÜ´ÁôÇ‰øùÂÅ•Ê©üÂô®Â≠∏ÁøíÊ®°Âûã„ÄÇÈÄô‰∫õÊñπÊ≥ïÂàÜÁÇ∫ÂÖ≠È°ûË®éË´ñÔºöÈù¢ÂêëÁâπÂæµÁöÑÊñπÊ≥ï„ÄÅÊï¥È´îÊñπÊ≥ï„ÄÅÊ¶ÇÂøµÊ®°Âûã„ÄÅ‰ª£ÁêÜÊ®°Âûã„ÄÅÂ±ÄÈÉ®Âü∫ÊñºÂÉèÁ¥†ÁöÑÊñπÊ≥ïÔºå‰ª•Âèä‰ª•‰∫∫ÁÇ∫‰∏≠ÂøÉÁöÑÊñπÊ≥ï„ÄÇÊúÄÈáçË¶ÅÁöÑÊòØÔºåÊú¨ÊñáÊé¢Ë®é‰∫Ü XAI Âú®ÈÜ´ÁôÇ‰øùÂÅ•ÂïèÈ°å‰∏≠ÁöÑËßíËâ≤Ôºå‰ª•ÈáêÊ∏ÖÂÖ∂Âú®ÂÆâÂÖ®ÈóúÈçµÊáâÁî®‰∏≠ÁöÑÂøÖË¶ÅÊÄß„ÄÇÊú¨ÊñáÊó®Âú®ÈÄèÈÅéÂõûÈ°ßÁõ∏ÈóúÁöÑÂØ¶È©óÁµêÊûúÔºåÂª∫Á´ãÂ∞çÈÜ´ÁôÇ‰øùÂÅ•È†òÂüü‰∏≠ XAI Áõ∏ÈóúÊáâÁî®Á®ãÂºèÁöÑÂÖ®Èù¢‰∫ÜËß£„ÄÇÁÇ∫‰∫Ü‰øÉÈÄ≤Êú™‰æÜÁ†îÁ©∂Â°´Ë£úÁ†îÁ©∂Â∑ÆË∑ùÔºåÊú¨ÊñáÊé¢Ë®é‰∫Ü XAI Ê®°ÂûãÂæû‰∏çÂêåËßÄÈªû‰æÜÁúãÁöÑÈáçË¶ÅÊÄßÂèäÂÖ∂ÈôêÂà∂„ÄÇ

##### **Reveal to Revise: An Explainable AI Life Cycle for Iterative Bias Correction of Deep Models**
2303.12641v2 by Frederik Pahde, Maximilian Dreyer, Wojciech Samek, Sebastian Lapuschkin

State-of-the-art machine learning models often learn spurious correlations
embedded in the training data. This poses risks when deploying these models for
high-stake decision-making, such as in medical applications like skin cancer
detection. To tackle this problem, we propose Reveal to Revise (R2R), a
framework entailing the entire eXplainable Artificial Intelligence (XAI) life
cycle, enabling practitioners to iteratively identify, mitigate, and
(re-)evaluate spurious model behavior with a minimal amount of human
interaction. In the first step (1), R2R reveals model weaknesses by finding
outliers in attributions or through inspection of latent concepts learned by
the model. Secondly (2), the responsible artifacts are detected and spatially
localized in the input data, which is then leveraged to (3) revise the model
behavior. Concretely, we apply the methods of RRR, CDEP and ClArC for model
correction, and (4) (re-)evaluate the model's performance and remaining
sensitivity towards the artifact. Using two medical benchmark datasets for
Melanoma detection and bone age estimation, we apply our R2R framework to VGG,
ResNet and EfficientNet architectures and thereby reveal and correct real
dataset-intrinsic artifacts, as well as synthetic variants in a controlled
setting. Completing the XAI life cycle, we demonstrate multiple R2R iterations
to mitigate different biases. Code is available on
https://github.com/maxdreyer/Reveal2Revise.

ÊëòË¶ÅÔºöÊúÄÂÖàËøõÁöÑÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÈÄöÂ∏∏‰ºöÂ≠¶‰π†ËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠ÂµåÂÖ•ÁöÑËôöÂÅáÂÖ≥ËÅî„ÄÇËøôÂú®Â∞ÜËøô‰∫õÊ®°ÂûãÈÉ®ÁΩ≤‰∫éÈ´òÈ£éÈô©ÂÜ≥Á≠ñÊó∂‰ºöÂ∏¶Êù•È£éÈô©Ôºå‰æãÂ¶ÇÂú®ÁöÆËÇ§ÁôåÊ£ÄÊµãÁ≠âÂåªÂ≠¶Â∫îÁî®‰∏≠„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢òÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü Reveal to Revise (R2R)Ôºå‰∏Ä‰∏™Ê∂µÁõñÊï¥‰∏™ÂèØËß£Èáä‰∫∫Â∑•Êô∫ËÉΩ (XAI) ÁîüÂëΩÂë®ÊúüÁöÑÊ°ÜÊû∂Ôºå‰Ωø‰ªé‰∏öËÄÖËÉΩÂ§ü‰ª•ÊúÄÂ∞ëÁöÑ‰∫∫Â∑•‰∫§‰∫íËø≠‰ª£ËØÜÂà´„ÄÅÁºìËß£ÂíåÔºàÈáçÊñ∞ÔºâËØÑ‰º∞ËôöÂÅáÊ®°ÂûãË°å‰∏∫„ÄÇÂú®Á¨¨‰∏ÄÊ≠• (1) ‰∏≠ÔºåR2R ÈÄöËøáÊâæÂá∫ÂΩíÂõ†‰∏≠ÁöÑÂºÇÂ∏∏ÂÄºÊàñÈÄöËøáÊ£ÄÊü•Ê®°ÂûãÂ≠¶‰π†ÁöÑÊΩúÂú®Ê¶ÇÂøµÊù•Êè≠Á§∫Ê®°ÂûãÁöÑÂº±ÁÇπ„ÄÇÂÖ∂Ê¨° (2)ÔºåÊ£ÄÊµãË¥üË¥£ÁöÑ‰º™ÂÉèÂπ∂Âú®ËæìÂÖ•Êï∞ÊçÆ‰∏≠ËøõË°åÁ©∫Èó¥ÂÆö‰ΩçÔºåÁÑ∂ÂêéÂà©Áî®ÂÆÉÊù• (3) ‰øÆÊîπÊ®°ÂûãË°å‰∏∫„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåÊàë‰ª¨Â∫îÁî® RRR„ÄÅCDEP Âíå ClArC ÁöÑÊñπÊ≥ïÊù•ËøõË°åÊ®°ÂûãÊ†°Ê≠£ÔºåÂπ∂ (4)ÔºàÈáçÊñ∞ÔºâËØÑ‰º∞Ê®°ÂûãÁöÑÊÄßËÉΩÂíåÂØπ‰º™ÂÉèÁöÑÂâ©‰ΩôÊïèÊÑüÊÄß„ÄÇ‰ΩøÁî®‰∏§‰∏™Áî®‰∫éÈªëËâ≤Á¥†Áò§Ê£ÄÊµãÂíåÈ™®ÈæÑ‰º∞ËÆ°ÁöÑÂåªÂ≠¶Âü∫ÂáÜÊï∞ÊçÆÈõÜÔºåÊàë‰ª¨Â∞ÜÊàë‰ª¨ÁöÑ R2R Ê°ÜÊû∂Â∫îÁî®‰∫é VGG„ÄÅResNet Âíå EfficientNet Êû∂ÊûÑÔºå‰ªéËÄåÊè≠Á§∫ÂíåÁ∫†Ê≠£‰∫ÜÁúüÂÆûÊï∞ÊçÆÈõÜÂõ∫ÊúâÁöÑ‰º™ÂÉèÔºå‰ª•ÂèäÂèóÊéßËÆæÁΩÆ‰∏≠ÁöÑÂêàÊàêÂèò‰Ωì„ÄÇÂÆåÊàê XAI ÁîüÂëΩÂë®ÊúüÔºåÊàë‰ª¨ÊºîÁ§∫‰∫ÜÂ§ö‰∏™ R2R Ëø≠‰ª£‰ª•ÂáèËΩª‰∏çÂêåÁöÑÂÅèÂ∑Æ„ÄÇ‰ª£Á†ÅÂèØÂú® https://github.com/maxdreyer/Reveal2Revise ‰∏äÊâæÂà∞„ÄÇ

##### **Explainable AI for Time Series via Virtual Inspection Layers**
2303.06365v1 by Johanna Vielhaben, Sebastian Lapuschkin, Gr√©goire Montavon, Wojciech Samek

The field of eXplainable Artificial Intelligence (XAI) has greatly advanced
in recent years, but progress has mainly been made in computer vision and
natural language processing. For time series, where the input is often not
interpretable, only limited research on XAI is available. In this work, we put
forward a virtual inspection layer, that transforms the time series to an
interpretable representation and allows to propagate relevance attributions to
this representation via local XAI methods like layer-wise relevance propagation
(LRP). In this way, we extend the applicability of a family of XAI methods to
domains (e.g. speech) where the input is only interpretable after a
transformation. Here, we focus on the Fourier transformation which is
prominently applied in the interpretation of time series and LRP and refer to
our method as DFT-LRP. We demonstrate the usefulness of DFT-LRP in various time
series classification settings like audio and electronic health records. We
showcase how DFT-LRP reveals differences in the classification strategies of
models trained in different domains (e.g., time vs. frequency domain) or helps
to discover how models act on spurious correlations in the data.

ÊëòË¶ÅÔºöÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖß (XAI) È†òÂüüÂú®ËøëÂπ¥‰æÜÂèñÂæóÈï∑Ë∂≥ÈÄ≤Ê≠•Ôºå‰ΩÜÈÄ≤Â±ï‰∏ªË¶ÅÊòØÂú®ÈõªËÖ¶Ë¶ñË¶∫ÂíåËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜÊñπÈù¢„ÄÇÂ∞çÊñºËº∏ÂÖ•ÈÄöÂ∏∏ÁÑ°Ê≥ïËß£ÈáãÁöÑÊôÇÈñìÂ∫èÂàóÔºåÂè™ÊúâÊúâÈôêÁöÑÁ†îÁ©∂ÂèØ‰æõ‰ΩøÁî® XAI„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãËôõÊì¨Ê™¢Êü•Â±§ÔºåÂÆÉÂ∞áÊôÇÈñìÂ∫èÂàóËΩâÊèõÁÇ∫ÂèØËß£ÈáãÁöÑË°®Á§∫Ôºå‰∏¶ÂÖÅË®±ÈÄöÈÅéÂ±§Á¥öÁõ∏ÈóúÊÄßÂÇ≥Êí≠ (LRP) Á≠âÂ±ÄÈÉ® XAI ÊñπÊ≥ïÂ∞áÁõ∏ÈóúÊÄßÊ≠∏Âõ†ÂÇ≥Êí≠Âà∞Ê≠§Ë°®Á§∫„ÄÇËóâÊ≠§ÔºåÊàëÂÄëÂ∞á‰∏ÄÁ≥ªÂàó XAI ÊñπÊ≥ïÁöÑÈÅ©Áî®ÊÄßÊì¥Â±ïÂà∞Ëº∏ÂÖ•ÂÉÖÂú®ËΩâÊèõÂæåÊâçËÉΩËß£ÈáãÁöÑÈ†òÂüüÔºà‰æãÂ¶ÇË™ûÈü≥Ôºâ„ÄÇÂú®Ê≠§ÔºåÊàëÂÄëÂ∞àÊ≥®ÊñºÂÇÖÁ´ãËëâËΩâÊèõÔºåÂÆÉ‰∏ªË¶ÅÊáâÁî®ÊñºÊôÇÈñìÂ∫èÂàóÂíå LRP ÁöÑËß£ÈáãÔºå‰∏¶Â∞áÊàëÂÄëÁöÑÁ®±‰πãÁÇ∫ DFT-LRP„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫Ü DFT-LRP Âú®ÂêÑÁ®ÆÊôÇÈñìÂ∫èÂàóÂàÜÈ°ûË®≠ÂÆöÔºà‰æãÂ¶ÇÈü≥Ë®äÂíåÈõªÂ≠êÂÅ•Â∫∑Á¥ÄÈåÑÔºâ‰∏≠ÁöÑÊïàÁî®„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫Ü DFT-LRP Â¶Ç‰ΩïÊè≠Á§∫Âú®‰∏çÂêåÈ†òÂüüÔºà‰æãÂ¶ÇÊôÇÈñìËàáÈ†ªÁéáÂüüÔºâË®ìÁ∑¥ÁöÑÊ®°ÂûãÁöÑÂàÜÈ°ûÁ≠ñÁï•Â∑ÆÁï∞ÔºåÊàñÊúâÂä©ÊñºÁôºÁèæÊ®°ÂûãÂ¶Ç‰ΩïËôïÁêÜË≥áÊñô‰∏≠ÁöÑËôõÂÅáÈóúËÅØ„ÄÇ

##### **Towards Trust of Explainable AI in Thyroid Nodule Diagnosis**
2303.04731v1 by Truong Thanh Hung Nguyen, Van Binh Truong, Vo Thanh Khang Nguyen, Quoc Hung Cao, Quoc Khanh Nguyen

The ability to explain the prediction of deep learning models to end-users is
an important feature to leverage the power of artificial intelligence (AI) for
the medical decision-making process, which is usually considered
non-transparent and challenging to comprehend. In this paper, we apply
state-of-the-art eXplainable artificial intelligence (XAI) methods to explain
the prediction of the black-box AI models in the thyroid nodule diagnosis
application. We propose new statistic-based XAI methods, namely Kernel Density
Estimation and Density map, to explain the case of no nodule detected. XAI
methods' performances are considered under a qualitative and quantitative
comparison as feedback to improve the data quality and the model performance.
Finally, we survey to assess doctors' and patients' trust in XAI explanations
of the model's decisions on thyroid nodule images.

ÊëòË¶ÅÔºöËß£ÈáãÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÈ†êÊ∏¨ÁµêÊûúÁöÑËÉΩÂäõÂ∞çÊúÄÁµÇ‰ΩøÁî®ËÄÖËÄåË®ÄÊòØ‰∏ÄÈ†ÖÈáçË¶ÅÂäüËÉΩÔºåÂèØÂà©Áî®‰∫∫Â∑•Êô∫ÊÖß (AI) ÁöÑÂäõÈáèÈÄ≤Ë°åÈÜ´ÁôÇÊ±∫Á≠ñÊµÅÁ®ãÔºåÈÄôÈÄöÂ∏∏Ë¢´Ë™çÁÇ∫ÊòØ‰∏çÈÄèÊòé‰∏îÈõ£‰ª•ÁêÜËß£ÁöÑ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÈÅãÁî®ÊúÄÂÖàÈÄ≤ÁöÑÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖß (XAI) ÊñπÊ≥ï‰æÜËß£ÈáãÈªëÁõí AI Ê®°ÂûãÂú®Áî≤ÁãÄËÖ∫ÁµêÁØÄË®∫Êñ∑ÊáâÁî®‰∏≠ÁöÑÈ†êÊ∏¨ÁµêÊûú„ÄÇÊàëÂÄëÊèêÂá∫Êñ∞ÁöÑÂü∫ÊñºÁµ±Ë®àÁöÑ XAI ÊñπÊ≥ïÔºåÂç≥Ê†∏ÂØÜÂ∫¶‰º∞Ë®àÂíåÂØÜÂ∫¶ÂúñÔºå‰æÜËß£ÈáãÊú™Ê™¢Ê∏¨Âà∞ÁµêÁØÄÁöÑÊÉÖÊ≥Å„ÄÇXAI ÊñπÊ≥ïÁöÑÊïàËÉΩÊúÉÂú®ÂÆöÊÄßÂíåÂÆöÈáèÊØîËºÉ‰∏ãË¢´Ë¶ñÁÇ∫ÊîπÂñÑË≥áÊñôÂìÅË≥™ÂíåÊ®°ÂûãÊïàËÉΩÁöÑÂõûÈ•ã„ÄÇÊúÄÂæåÔºåÊàëÂÄëÈÄ≤Ë°åË™øÊü•‰ª•Ë©ï‰º∞ÈÜ´Â∏´ÂíåÊÇ£ËÄÖÂ∞ç XAI Â∞çÊ®°ÂûãÂú®Áî≤ÁãÄËÖ∫ÁµêÁØÄÂΩ±ÂÉè‰∏≠Ê±∫Á≠ñÁöÑËß£ÈáãÁöÑ‰ø°‰ªªÂ∫¶„ÄÇ

##### **Cybersecurity of AI medical devices: risks, legislation, and challenges**
2303.03140v1 by Elisabetta Biasin, Erik Kamenjasevic, Kaspar Rosager Ludvigsen

Medical devices and artificial intelligence systems rapidly transform
healthcare provisions. At the same time, due to their nature, AI in or as
medical devices might get exposed to cyberattacks, leading to patient safety
and security risks. This book chapter is divided into three parts. The first
part starts by setting the scene where we explain the role of cybersecurity in
healthcare. Then, we briefly define what we refer to when we talk about AI that
is considered a medical device by itself or supports one. To illustrate the
risks such medical devices pose, we provide three examples: the poisoning of
datasets, social engineering, and data or source code extraction. In the second
part, the paper provides an overview of the European Union's regulatory
framework relevant for ensuring the cybersecurity of AI as or in medical
devices (MDR, NIS Directive, Cybersecurity Act, GDPR, the AI Act proposal and
the NIS 2 Directive proposal). Finally, the third part of the paper examines
possible challenges stemming from the EU regulatory framework. In particular,
we look toward the challenges deriving from the two legislative proposals and
their interaction with the existing legislation concerning AI medical devices'
cybersecurity. They are structured as answers to the following questions: (1)
how will the AI Act interact with the MDR regarding the cybersecurity and
safety requirements?; (2) how should we interpret incident notification
requirements from the NIS 2 Directive proposal and MDR?; and (3) what are the
consequences of the evolving term of critical infrastructures?
  [This is a draft chapter. The final version will be available in Research
Handbook on Health, AI and the Law edited by Barry Solaiman & I. Glenn Cohen,
forthcoming 2023, Edward Elgar Publishing Ltd]

ÊëòË¶ÅÔºöÈÜ´ÁôÇË®≠ÂÇôÂíå‰∫∫Â∑•Êô∫ÊÖßÁ≥ªÁµ±Âø´ÈÄüËΩâÂåñÈÜ´ÁôÇ‰øùÂÅ•ÁöÑÊèê‰æõÊñπÂºè„ÄÇÂêåÊôÇÔºåÁî±ÊñºÂÖ∂Êú¨Ë≥™ÔºåÈÜ´ÁôÇË®≠ÂÇô‰∏≠Êàñ‰ΩúÁÇ∫ÈÜ´ÁôÇË®≠ÂÇôÁöÑ‰∫∫Â∑•Êô∫ÊÖßÂèØËÉΩÊúÉÈÅ≠ÂèóÁ∂≤Ë∑ØÊîªÊìäÔºåÈÄ≤ËÄåÂ∞éËá¥ÊÇ£ËÄÖÂÆâÂÖ®ÂíåÂÆâÂÖ®È¢®Èö™„ÄÇÊú¨Á´†ÁØÄÂàÜÁÇ∫‰∏âÈÉ®ÂàÜ„ÄÇÁ¨¨‰∏ÄÈÉ®ÂàÜÂæûË®≠ÂÆöÂ†¥ÊôØÈñãÂßãÔºåË™™ÊòéÁ∂≤Ë∑ØÂÆâÂÖ®Âú®ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÁöÑËßíËâ≤„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÁ∞°Ë¶ÅÂÆöÁæ©ÊàëÂÄëÂú®Ë´áË´ñË¢´Ë¶ñÁÇ∫ÈÜ´ÁôÇË®≠ÂÇôÊú¨Ë∫´ÊàñÊîØÊè¥ÈÜ´ÁôÇË®≠ÂÇôÁöÑ‰∫∫Â∑•Êô∫ÊÖßÊôÇÊâÄÊåáÊ∂âÁöÑÂÖßÂÆπ„ÄÇÁÇ∫‰∫ÜË™™ÊòéÊ≠§È°ûÈÜ´ÁôÇË®≠ÂÇôÂ∏∂‰æÜÁöÑÈ¢®Èö™ÔºåÊàëÂÄëÊèê‰æõ‰∫Ü‰∏âÂÄãÁØÑ‰æãÔºöË≥áÊñôÈõÜ‰∏≠ÊØí„ÄÅÁ§æÊúÉÂ∑•Á®ãÂíåË≥áÊñôÊàñÂéüÂßãÁ¢ºËêÉÂèñ„ÄÇÂú®Á¨¨‰∫åÈÉ®ÂàÜÔºåÊú¨ÊñáÊ¶ÇËø∞‰∫ÜÊ≠êÁõüÁöÑÁõ£ÁÆ°Êû∂ÊßãÔºåËàáÁ¢∫‰øùÈÜ´ÁôÇË®≠ÂÇô‰∏≠Êàñ‰ΩúÁÇ∫ÈÜ´ÁôÇË®≠ÂÇôÁöÑ‰∫∫Â∑•Êô∫ÊÖßÁöÑÁ∂≤Ë∑ØÂÆâÂÖ®Áõ∏ÈóúÔºàÈÜ´ÁôÇÂô®ÊùêÊ≥ïË¶è„ÄÅÁ∂≤Ë∑ØËàáË≥áË®äÂÆâÂÖ®Êåá‰ª§„ÄÅÁ∂≤Ë∑ØÂÆâÂÖ®Ê≥ï„ÄÅ‰∏ÄËà¨Ë≥áÊñô‰øùË≠∑Ë¶èÁØÑ„ÄÅ‰∫∫Â∑•Êô∫ÊÖßÊ≥ïÊèêÊ°àÂíåÁ∂≤Ë∑ØËàáË≥áË®äÂÆâÂÖ® 2 Êåá‰ª§ÊèêÊ°àÔºâ„ÄÇÊúÄÂæåÔºåÊú¨ÊñáÁöÑÁ¨¨‰∏âÈÉ®ÂàÜÊé¢Ë®éÊ∫êËá™Ê≠êÁõüÁõ£ÁÆ°Êû∂ÊßãÁöÑÊΩõÂú®ÊåëÊà∞„ÄÇÁâπÂà•ÊòØÔºåÊàëÂÄëÂ±ïÊúõÊ∫êËá™ÈÄôÂÖ©È†ÖÁ´ãÊ≥ïÊèêÊ°àÁöÑÊåëÊà∞Ôºå‰ª•ÂèäÂÆÉÂÄëËàáÁèæÊúâÈóúÊñº‰∫∫Â∑•Êô∫ÊÖßÈÜ´ÁôÇË®≠ÂÇôÁ∂≤Ë∑ØÂÆâÂÖ®ÁöÑÁ´ãÊ≥ï‰πãÈñìÁöÑ‰∫íÂãï„ÄÇÂÆÉÂÄëË¢´Êû∂ÊßãÁÇ∫‰ª•‰∏ãÂïèÈ°åÁöÑËß£Á≠îÔºö(1) ‰∫∫Â∑•Êô∫ÊÖßÊ≥ïÂ∞áÂ¶Ç‰ΩïËàáÈÜ´ÁôÇÂô®ÊùêÊ≥ïË¶è‰∫íÂãïÔºåÂ∞±Á∂≤Ë∑ØÂÆâÂÖ®ÂíåÂÆâÂÖ®Ë¶ÅÊ±ÇËÄåË®ÄÔºü(2) ÊàëÂÄëÊáâÂ¶Ç‰ΩïËß£ËÆÄÁ∂≤Ë∑ØËàáË≥áË®äÂÆâÂÖ® 2 Êåá‰ª§ÊèêÊ°àÂíåÈÜ´ÁôÇÂô®ÊùêÊ≥ïË¶èÁöÑ‰∫ã‰ª∂ÈÄöÁü•Ë¶ÅÊ±ÇÔºü(3) ÈóúÈçµÂü∫Á§éË®≠ÊñΩÊºîÈÄ≤ÁöÑË°ìË™ûÊúÉÂ∏∂‰æÜ‰ªÄÈ∫ºÂæåÊûúÔºü
[ÈÄôÊòØËçâÁ®øÁ´†ÁØÄ„ÄÇÊúÄÁµÇÁâàÊú¨Â∞áÂàäËºâÊñº Barry Solaiman Âíå I. Glenn Cohen Á∑®ËºØÁöÑ„ÄäÂÅ•Â∫∑„ÄÅ‰∫∫Â∑•Êô∫ÊÖßËàáÊ≥ïÂæãÁ†îÁ©∂ÊâãÂÜä„Äã‰∏≠Ôºå2023 Âπ¥Âá∫ÁâàÔºåEdward Elgar Publishing Ltd]

##### **LAVA: Granular Neuron-Level Explainable AI for Alzheimer's Disease Assessment from Fundus Images**
2302.03008v2 by Nooshin Yousefzadeh, Charlie Tran, Adolfo Ramirez-Zamora, Jinghua Chen, Ruogu Fang, My T. Thai

Alzheimer's Disease (AD) is a progressive neurodegenerative disease and the
leading cause of dementia. Early diagnosis is critical for patients to benefit
from potential intervention and treatment. The retina has been hypothesized as
a diagnostic site for AD detection owing to its anatomical connection with the
brain. Developed AI models for this purpose have yet to provide a rational
explanation about the decision and neither infer the stage of disease's
progression. Along this direction, we propose a novel model-agnostic
explainable-AI framework, called Granular Neuron-level Explainer (LAVA), an
interpretation prototype that probes into intermediate layers of the
Convolutional Neural Network (CNN) models to assess the AD continuum directly
from the retinal imaging without longitudinal or clinical evaluation. This
method is applied to validate the retinal vasculature as a biomarker and
diagnostic modality for Alzheimer's Disease (AD) evaluation. UK Biobank
cognitive tests and vascular morphological features suggest LAVA shows strong
promise and effectiveness in identifying AD stages across the progression
continuum.

ÊëòË¶ÅÔºöÈòøËå≤Êµ∑ÈªòÁóá (AD) ÊòØ‰∏ÄÁ®ÆÈÄ≤Ë°åÊÄßÁöÑÁ•ûÁ∂ìÈÄÄÂåñÊÄßÁñæÁóÖÔºå‰πüÊòØÂ∞éËá¥Â§±Êô∫ÁóáÁöÑ‰∏ªÂõ†„ÄÇÊó©ÊúüË®∫Êñ∑Â∞çÊñºÊÇ£ËÄÖÊé•ÂèóÊΩõÂú®Âπ≤È†êÂíåÊ≤ªÁôÇËá≥ÈóúÈáçË¶Å„ÄÇÁî±ÊñºË¶ñÁ∂≤ËÜúËàáÂ§ßËÖ¶ÊúâËß£ÂâñÂ≠∏‰∏äÁöÑÈÄ£ÁµêÔºåÂõ†Ê≠§ÂÅáË®≠Ë¶ñÁ∂≤ËÜúÂèØ‰ª•‰ΩúÁÇ∫ AD Ê™¢Ê∏¨ÁöÑË®∫Êñ∑ÈÉ®‰Ωç„ÄÇÁÇ∫Ê≠§ÁõÆÁöÑËÄåÈñãÁôºÁöÑ AI Ê®°ÂûãÔºåÂ∞öÊú™Â∞çÊ±∫Á≠ñÊèê‰æõÂêàÁêÜÁöÑËß£ÈáãÔºå‰πüÁÑ°Ê≥ïÊé®Ë´ñÁñæÁóÖÈÄ≤Â±ïÁöÑÈöéÊÆµ„ÄÇÊ≤øËëóÈÄôÂÄãÊñπÂêëÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊñ∞Á©éÁöÑÊ®°Âûã‰∏çÂèØÁü•Ë´ñÂèØËß£Èáã AI Êû∂ÊßãÔºåÁ®±ÁÇ∫È°ÜÁ≤íÁ•ûÁ∂ìÂÖÉÁ¥öÂà•Ëß£ÈáãÂô® (LAVA)ÔºåÈÄôÊòØ‰∏ÄÂÄãËß£ÈáãÂéüÂûãÔºåÂèØ‰ª•Êé¢Ê∏¨Âç∑Á©çÁ•ûÁ∂ìÁ∂≤Ë∑Ø (CNN) Ê®°ÂûãÁöÑ‰∏≠ÈñìÂ±§Ôºå‰ª•Áõ¥Êé•ÂæûË¶ñÁ∂≤ËÜúÂΩ±ÂÉèË©ï‰º∞ AD ÈÄ£Á∫åÈ´îÔºåËÄåÁÑ°ÈúÄÁ∏±ÂêëÊàñËá®Â∫äË©ï‰º∞„ÄÇÊ≠§ÊñπÊ≥ïÁî®ÊñºÈ©óË≠âË¶ñÁ∂≤ËÜúË°ÄÁÆ°‰ΩúÁÇ∫ÁîüÁâ©Ê®ôË®òÂíåÈòøËå≤Êµ∑ÈªòÁóá (AD) Ë©ï‰º∞ÁöÑË®∫Êñ∑ÊñπÂºè„ÄÇËã±ÂúãÁîüÁâ©Ë≥áÊñôÂ∫´ÁöÑË™çÁü•Ê∏¨Ë©¶ÂíåË°ÄÁÆ°ÂΩ¢ÊÖãÁâπÂæµË°®ÊòéÔºåLAVA Âú®Ë≠òÂà•ÈÄ≤Â±ïÈÄ£Á∫åÈ´î‰∏≠ÁöÑ AD ÈöéÊÆµÊñπÈù¢È°ØÁ§∫Âá∫Âº∑Â§ßÁöÑÂâçÊôØÂíåÊúâÊïàÊÄß„ÄÇ

##### **Diagrammatization: Rationalizing with diagrammatic AI explanations for abductive-deductive reasoning on hypotheses**
2302.01241v2 by Brian Y. Lim, Joseph P. Cahaly, Chester Y. F. Sng, Adam Chew

Many visualizations have been developed for explainable AI (XAI), but they
often require further reasoning by users to interpret. We argue that XAI should
support diagrammatic and abductive reasoning for the AI to perform hypothesis
generation and evaluation to reduce the interpretability gap. We propose
Diagrammatization to i) perform Peircean abductive-deductive reasoning, ii)
follow domain conventions, and iii) explain with diagrams visually or verbally.
We implemented DiagramNet for a clinical application to predict cardiac
diagnoses from heart auscultation, and explain with shape-based murmur
diagrams. In modeling studies, we found that DiagramNet not only provides
faithful murmur shape explanations, but also has better prediction performance
than baseline models. We further demonstrate the interpretability and
trustworthiness of diagrammatic explanations in a qualitative user study with
medical students, showing that clinically-relevant, diagrammatic explanations
are preferred over technical saliency map explanations. This work contributes
insights into providing domain-conventional abductive explanations for
user-centric XAI.

ÊëòË¶ÅÔºöË®±Â§öË¶ñË¶∫ÂåñÂ∑≤Ë¢´ÈñãÁôºÁî®ÊñºÂèØËß£ÈáãÁöÑ AI (XAI)Ôºå‰ΩÜÂÆÉÂÄëÈÄöÂ∏∏ÈúÄË¶Å‰ΩøÁî®ËÄÖÈÄ≤‰∏ÄÊ≠•Êé®ÁêÜÊâçËÉΩËß£ËÆÄ„ÄÇÊàëÂÄë‰∏ªÂºµ XAI ÊáâÊîØÊè¥ÂúñËß£ÂíåÊºîÁππÊé®ÁêÜÔºåËÆì AI Âü∑Ë°åÂÅáË®≠Áî¢ÁîüÂíåË©ï‰º∞‰ª•Á∏ÆÂ∞èÂèØËß£ÈáãÊÄßÂ∑ÆË∑ù„ÄÇÊàëÂÄëÊèêÂá∫ÂúñËß£Âåñ‰ª• i) Âü∑Ë°åÁöÆÁàæÂ£´ÊºîÁππ-ÊºîÁππÊé®ÁêÜÔºåii) ÈÅµÂæ™È†òÂüüÊÖ£‰æãÔºå‰ª•Âèä iii) ‰ª•Ë¶ñË¶∫ÊàñÂè£Ë™ûÊñπÂºèË™™ÊòéÂúñË°®„ÄÇÊàëÂÄëÂØ¶‰Ωú‰∫Ü DiagramNet ÈÄ≤Ë°åËá®Â∫äÊáâÁî®Ôºå‰ª•ÂæûÂøÉËáüËÅΩË®∫È†êÊ∏¨ÂøÉËáüË®∫Êñ∑Ôºå‰∏¶‰ª•ÂΩ¢ÁãÄÁÇ∫Âü∫Á§éÁöÑÈõúÈü≥ÂúñË™™Êòé„ÄÇÂú®Âª∫Ê®°Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëÁôºÁèæ DiagramNet ‰∏çÂÉÖÊèê‰æõ‰∫ÜÂø†ÂØ¶ÁöÑÈõúÈü≥ÂΩ¢ÁãÄË™™ÊòéÔºåËÄå‰∏îÊØîÂü∫Ê∫ñÊ®°ÂûãÂÖ∑ÊúâÊõ¥Â•ΩÁöÑÈ†êÊ∏¨ÊïàËÉΩ„ÄÇÊàëÂÄëÈÄ≤‰∏ÄÊ≠•Âú®ËàáÈÜ´Â≠∏ÁîüÁöÑË≥™ÊÄß‰ΩøÁî®ËÄÖÁ†îÁ©∂‰∏≠Â±ïÁ§∫‰∫ÜÂúñËß£Ë™™ÊòéÁöÑÂèØËß£ÈáãÊÄßÂíåÂèØ‰ø°Â∫¶ÔºåÈ°ØÁ§∫Âá∫‰ª•Ëá®Â∫äÁõ∏ÈóúÁöÑÂúñËß£Ë™™ÊòéÂÑ™ÊñºÊäÄË°ìÈ°ØËëóÊÄßÂúñË™™Êòé„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÊúâÂä©ÊñºÊèê‰æõ‰ª•‰ΩøÁî®ËÄÖÁÇ∫‰∏≠ÂøÉÁöÑ XAI ÁöÑÈ†òÂüüÊÖ£‰æãÊºîÁππË™™Êòé„ÄÇ

##### **LesionAid: Vision Transformers-based Skin Lesion Generation and Classification**
2302.01104v1 by Ghanta Sai Krishna, Kundrapu Supriya, Mallikharjuna Rao K, Meetiksha Sorgile

Skin cancer is one of the most prevalent forms of human cancer. It is
recognized mainly visually, beginning with clinical screening and continuing
with the dermoscopic examination, histological assessment, and specimen
collection. Deep convolutional neural networks (CNNs) perform highly segregated
and potentially universal tasks against a classified finegrained object. This
research proposes a novel multi-class prediction framework that classifies skin
lesions based on ViT and ViTGAN. Vision transformers-based GANs (Generative
Adversarial Networks) are utilized to tackle the class imbalance. The framework
consists of four main phases: ViTGANs, Image processing, and explainable AI.
Phase 1 consists of generating synthetic images to balance all the classes in
the dataset. Phase 2 consists of applying different data augmentation
techniques and morphological operations to increase the size of the data.
Phases 3 & 4 involve developing a ViT model for edge computing systems that can
identify patterns and categorize skin lesions from the user's skin visible in
the image. In phase 3, after classifying the lesions into the desired class
with ViT, we will use explainable AI (XAI) that leads to more explainable
results (using activation maps, etc.) while ensuring high predictive accuracy.
Real-time images of skin diseases can capture by a doctor or a patient using
the camera of a mobile application to perform an early examination and
determine the cause of the skin lesion. The whole framework is compared with
the existing frameworks for skin lesion detection.

ÊëòË¶ÅÔºöÁöÆËÜöÁôåÊòØ‰∫∫È°ûÊúÄÊôÆÈÅçÁöÑÁôåÁóáÈ°ûÂûã‰πã‰∏Ä„ÄÇÂÆÉÁöÑË≠òÂà•‰∏ªË¶Å‰æùË≥¥Ë¶ñË¶∫ÔºåÂæûËá®Â∫äÁØ©Ê™¢ÈñãÂßãÔºåÊé•ËëóÊòØÁöÆËÜöÈè°Ê™¢Êü•„ÄÅÁµÑÁπîÂ≠∏Ë©ï‰º∞Ôºå‰ª•ÂèäÊ™¢È´îÊî∂ÈõÜ„ÄÇÊ∑±Â∫¶Âç∑Á©çÁ•ûÁ∂ìÁ∂≤Ë∑Ø (CNN) ÂèØÈáùÂ∞çÂàÜÈ°ûÁöÑÁ¥∞Á≤íÂ∫¶Áâ©‰ª∂Âü∑Ë°åÈ´òÂ∫¶ÂçÄÈöî‰∏îÊΩõÂú®ÈÄöÁî®ÁöÑ‰ªªÂãô„ÄÇÊú¨Á†îÁ©∂ÊèêÂá∫‰∏ÄÂÄãÊñ∞Á©éÁöÑÂ§öÈ°ûÂà•È†êÊ∏¨Êû∂ÊßãÔºåÂÆÉ‰ª• ViT Âíå ViTGAN ÁÇ∫Âü∫Á§éÂ∞çÁöÆËÜöÁóÖÁÅ∂ÈÄ≤Ë°åÂàÜÈ°û„ÄÇÂü∫ÊñºË¶ñË¶∫ËΩâÊèõÂô®ÁöÑ GANÔºàÁîüÊàêÂ∞çÊäóÁ∂≤Ë∑ØÔºâÁî®ÊñºËß£Ê±∫È°ûÂà•‰∏çÂπ≥Ë°°ÂïèÈ°å„ÄÇÊ≠§Êû∂ÊßãÂåÖÂê´ÂõõÂÄã‰∏ªË¶ÅÈöéÊÆµÔºöViTGAN„ÄÅÂΩ±ÂÉèËôïÁêÜÂíåÂèØËß£Èáã AI„ÄÇÁ¨¨‰∏ÄÈöéÊÆµÂåÖÊã¨Áî¢ÁîüÂêàÊàêÂΩ±ÂÉèÔºå‰ª•Âπ≥Ë°°Ë≥áÊñôÈõÜ‰∏≠ÁöÑÊâÄÊúâÈ°ûÂà•„ÄÇÁ¨¨‰∫åÈöéÊÆµÂåÖÊã¨ÊáâÁî®‰∏çÂêåÁöÑË≥áÊñôÊì¥ÂÖÖÊäÄË°ìÂíåÂΩ¢ÊÖãÈÅãÁÆóÔºå‰ª•Â¢ûÂä†Ë≥áÊñôÂ§ßÂ∞è„ÄÇÁ¨¨‰∏âÂíåÁ¨¨ÂõõÈöéÊÆµÊ∂âÂèäÈñãÁôºÈÅ©Áî®ÊñºÈÇäÁ∑£ÈÅãÁÆóÁ≥ªÁµ±ÁöÑ ViT Ê®°ÂûãÔºåË©≤Ê®°ÂûãÂèØ‰ª•Ë≠òÂà•ÂúñÊ°àÔºå‰∏¶Â∞çÂΩ±ÂÉè‰∏≠Áî®Êà∂ÁöÆËÜöÂèØË¶ãÁöÑÁöÆËÜöÁóÖÁÅ∂ÈÄ≤Ë°åÂàÜÈ°û„ÄÇÂú®Á¨¨‰∏âÈöéÊÆµÔºåÂú®‰ΩøÁî® ViT Â∞áÁóÖÁÅ∂ÂàÜÈ°ûÂà∞ÊâÄÈúÄÁöÑÈ°ûÂà•ÂæåÔºåÊàëÂÄëÂ∞á‰ΩøÁî®ÂèØËß£Èáã AI (XAI)ÔºåÂÆÉÊúÉÁî¢ÁîüÊõ¥ÂÖ∑ÂèØËß£ÈáãÊÄßÁöÑÁµêÊûúÔºà‰ΩøÁî®ÂïüÁî®ÂúñÁ≠âÔºâÔºåÂêåÊôÇÁ¢∫‰øùÈ´òÈ†êÊ∏¨Ê∫ñÁ¢∫Â∫¶„ÄÇÁöÆËÜöÁñæÁóÖÁöÑÂç≥ÊôÇÂΩ±ÂÉèÂèØ‰ª•Áî®Ë°åÂãïÊáâÁî®Á®ãÂºèÁöÑÁõ∏Ê©üÁî±ÈÜ´ÁîüÊàñÊÇ£ËÄÖÊì∑ÂèñÔºå‰ª•Âü∑Ë°åÊó©ÊúüÊ™¢Êü•‰∏¶Á¢∫ÂÆöÁöÆËÜöÁóÖÁÅ∂ÁöÑÂéüÂõ†„ÄÇÊï¥ÂÄãÊû∂ÊßãËàáÁèæÊúâÁöÑÁöÆËÜöÁóÖÁÅ∂ÂÅµÊ∏¨Êû∂ÊßãÈÄ≤Ë°åÊØîËºÉ„ÄÇ

##### **SkinCon: A skin disease dataset densely annotated by domain experts for fine-grained model debugging and analysis**
2302.00785v1 by Roxana Daneshjou, Mert Yuksekgonul, Zhuo Ran Cai, Roberto Novoa, James Zou

For the deployment of artificial intelligence (AI) in high-risk settings,
such as healthcare, methods that provide interpretability/explainability or
allow fine-grained error analysis are critical. Many recent methods for
interpretability/explainability and fine-grained error analysis use concepts,
which are meta-labels that are semantically meaningful to humans. However,
there are only a few datasets that include concept-level meta-labels and most
of these meta-labels are relevant for natural images that do not require domain
expertise. Densely annotated datasets in medicine focused on meta-labels that
are relevant to a single disease such as melanoma. In dermatology, skin disease
is described using an established clinical lexicon that allows clinicians to
describe physical exam findings to one another. To provide a medical dataset
densely annotated by domain experts with annotations useful across multiple
disease processes, we developed SkinCon: a skin disease dataset densely
annotated by dermatologists. SkinCon includes 3230 images from the Fitzpatrick
17k dataset densely annotated with 48 clinical concepts, 22 of which have at
least 50 images representing the concept. The concepts used were chosen by two
dermatologists considering the clinical descriptor terms used to describe skin
lesions. Examples include "plaque", "scale", and "erosion". The same concepts
were also used to label 656 skin disease images from the Diverse Dermatology
Images dataset, providing an additional external dataset with diverse skin tone
representations. We review the potential applications for the SkinCon dataset,
such as probing models, concept-based explanations, and concept bottlenecks.
Furthermore, we use SkinCon to demonstrate two of these use cases: debugging
mistakes of an existing dermatology AI model with concepts and developing
interpretable models with post-hoc concept bottleneck models.

ÊëòË¶ÅÔºö<paragraph>Âú®È´òÈ¢®Èö™Áí∞Â¢É‰∏≠ÈÉ®ÁΩ≤‰∫∫Â∑•Êô∫ÊÖß (AI)Ôºà‰æãÂ¶ÇÈÜ´ÁôÇ‰øùÂÅ•ÔºâÔºåÊèê‰æõÂèØËß£ÈáãÊÄß/ÂèØË™™ÊòéÊÄßÁöÑÊñπÊ≥ïÊàñÂÖÅË®±Á≤æÁ¥∞ÈåØË™§ÂàÜÊûêÈùûÂ∏∏ÈáçË¶Å„ÄÇË®±Â§öËøëÊúüÁî®ÊñºÂèØËß£ÈáãÊÄß/ÂèØË™™ÊòéÊÄßÂíåÁ≤æÁ¥∞ÈåØË™§ÂàÜÊûêÁöÑÊñπÊ≥ïÈÉΩ‰ΩøÁî®Ê¶ÇÂøµÔºåÈÄô‰∫õÊ¶ÇÂøµÊòØÂ∞ç‰∫∫È°ûÂÖ∑ÊúâË™ûÁæ©ÊÑèÁæ©ÁöÑÂÖÉÊ®ôÁ±§„ÄÇÁÑ∂ËÄåÔºåÂè™ÊúâÂ∞ëÊï∏Ë≥áÊñôÈõÜÂåÖÂê´Ê¶ÇÂøµÂ±§Á¥öÁöÑÂÖÉÊ®ôÁ±§ÔºåËÄå‰∏îÈÄô‰∫õÂÖÉÊ®ôÁ±§Â§ßÂ§öËàá‰∏çÈúÄË¶ÅÈ†òÂüüÂ∞àÊ•≠Áü•Ë≠òÁöÑËá™ÁÑ∂ÂΩ±ÂÉèÁõ∏Èóú„ÄÇÂ∞àÊ≥®ÊñºÂñÆ‰∏ÄÁñæÁóÖÔºà‰æãÂ¶ÇÈªëËâ≤Á¥†Áò§ÔºâÁöÑÂÖÉÊ®ôÁ±§ÁöÑÈÜ´Â≠∏ÂØÜÈõÜÊ®ôË®òË≥áÊñôÈõÜ„ÄÇÂú®ÁöÆËÜöÁßë‰∏≠ÔºåÁöÆËÜöÁñæÁóÖÁöÑÊèèËø∞‰ΩøÁî®Êó¢ÂÆöÁöÑËá®Â∫äË©ûÂΩôÔºåËÆìËá®Â∫äÈÜ´ÁîüÂèØ‰ª•ÂΩºÊ≠§ÊèèËø∞Ë∫´È´îÊ™¢Êü•ÁµêÊûú„ÄÇÁÇ∫‰∫ÜÊèê‰æõÁî±È†òÂüüÂ∞àÂÆ∂ÂØÜÈõÜÊ®ôË®òÁöÑÈÜ´Â≠∏Ë≥áÊñôÈõÜÔºåÂÖ∂‰∏≠ÂåÖÂê´ÂèØË∑®Â§öÁ®ÆÁñæÁóÖÈÅéÁ®ã‰ΩøÁî®ÁöÑÊ®ôË®òÔºåÊàëÂÄëÈñãÁôº‰∫Ü SkinConÔºöÁî±ÁöÆËÜöÁßëÈÜ´Â∏´ÂØÜÈõÜÊ®ôË®òÁöÑÁöÆËÜöÁñæÁóÖË≥áÊñôÈõÜ„ÄÇSkinCon ÂåÖÂê´‰æÜËá™ Fitzpatrick 17k Ë≥áÊñôÈõÜÁöÑ 3230 ÂºµÂΩ±ÂÉèÔºåÂØÜÈõÜÊ®ôË®ò‰∫Ü 48 ÂÄãËá®Â∫äÊ¶ÇÂøµÔºåÂÖ∂‰∏≠ 22 ÂÄãÊ¶ÇÂøµËá≥Â∞ëÊúâ 50 ÂºµÂΩ±ÂÉè‰ª£Ë°®Ë©≤Ê¶ÇÂøµ„ÄÇÊâÄ‰ΩøÁî®ÁöÑÊ¶ÇÂøµÊòØÁî±ÂÖ©‰ΩçÁöÆËÜöÁßëÈÜ´Â∏´Âú®ËÄÉÈáèÁî®ÊñºÊèèËø∞ÁöÆËÜöÁóÖËÆäÁöÑËá®Â∫äÊèèËø∞Ë©ûÂΩôÂæåÈÅ∏Âá∫ÁöÑ„ÄÇÁØÑ‰æãÂåÖÊã¨„ÄåÊñëÂ°ä„Äç„ÄÅ„ÄåÈ±óÂ±ë„ÄçÂíå„ÄåÁ≥úÁàõ„Äç„ÄÇÁõ∏ÂêåÁöÑÊ¶ÇÂøµ‰πüÁî®ÊñºÊ®ôË®ò‰æÜËá™ Diverse Dermatology Images Ë≥áÊñôÈõÜÁöÑ 656 ÂºµÁöÆËÜöÁñæÁóÖÂΩ±ÂÉèÔºåÊèê‰æõÂÖ∑ÊúâÂ§öÊ®£ËÜöËâ≤Ë°®Á§∫ÁöÑÈ°çÂ§ñÂ§ñÈÉ®Ë≥áÊñôÈõÜ„ÄÇÊàëÂÄëÊ™¢Ë¶ñ SkinCon Ë≥áÊñôÈõÜÁöÑÊΩõÂú®ÊáâÁî®Ôºå‰æãÂ¶ÇÊé¢Ê∏¨Ê®°Âûã„ÄÅÂü∫ÊñºÊ¶ÇÂøµÁöÑË™™ÊòéÂíåÊ¶ÇÂøµÁì∂È†∏„ÄÇÊ≠§Â§ñÔºåÊàëÂÄë‰ΩøÁî® SkinCon ‰æÜÂ±ïÁ§∫ÈÄôÂÖ©ÂÄã‰ΩøÁî®Ê°à‰æãÔºö‰ΩøÁî®Ê¶ÇÂøµÈô§ÈåØÁèæÊúâÁöÆËÜöÁßë AI Ê®°ÂûãÁöÑÈåØË™§Ôºå‰ª•Âèä‰ΩøÁî®‰∫ãÂæåÊ¶ÇÂøµÁì∂È†∏Ê®°ÂûãÈñãÁôºÂèØËß£ÈáãÁöÑÊ®°Âûã„ÄÇ</paragraph>

##### **Decision-Focused Evaluation: Analyzing Performance of Deployed Restless Multi-Arm Bandits**
2301.07835v1 by Paritosh Verma, Shresth Verma, Aditya Mate, Aparna Taneja, Milind Tambe

Restless multi-arm bandits (RMABs) is a popular decision-theoretic framework
that has been used to model real-world sequential decision making problems in
public health, wildlife conservation, communication systems, and beyond.
Deployed RMAB systems typically operate in two stages: the first predicts the
unknown parameters defining the RMAB instance, and the second employs an
optimization algorithm to solve the constructed RMAB instance.
  In this work we provide and analyze the results from a first-of-its-kind
deployment of an RMAB system in public health domain, aimed at improving
maternal and child health. Our analysis is focused towards understanding the
relationship between prediction accuracy and overall performance of deployed
RMAB systems. This is crucial for determining the value of investing in
improving predictive accuracy towards improving the final system performance,
and is useful for diagnosing, monitoring deployed RMAB systems.
  Using real-world data from our deployed RMAB system, we demonstrate that an
improvement in overall prediction accuracy may even be accompanied by a
degradation in the performance of RMAB system -- a broad investment of
resources to improve overall prediction accuracy may not yield expected
results. Following this, we develop decision-focused evaluation metrics to
evaluate the predictive component and show that it is better at explaining
(both empirically and theoretically) the overall performance of a deployed RMAB
system.

ÊëòË¶ÅÔºö‰∏çÂÆâÂàÜÁöÑÂ§öËáÇÂº∑Áõú (RMAB) ÊòØ‰∏ÄÂÄãÊµÅË°åÁöÑÊ±∫Á≠ñÁêÜË´ñÊû∂ÊßãÔºåÂ∑≤Ë¢´Áî®ÊñºÊ®°Êì¨ÂÖ¨ÂÖ±Ë°õÁîü„ÄÅÈáéÁîüÂãïÁâ©‰øùËÇ≤„ÄÅÈÄöË®äÁ≥ªÁµ±Á≠âÈ†òÂüüÁöÑÁúüÂØ¶‰∏ñÁïåÈ†ÜÂ∫èÊ±∫Á≠ñÂïèÈ°å„ÄÇÂ∑≤ÈÉ®ÁΩ≤ÁöÑ RMAB Á≥ªÁµ±ÈÄöÂ∏∏ÂàÜÂÖ©ÂÄãÈöéÊÆµÈÅã‰ΩúÔºöÁ¨¨‰∏ÄÂÄãÈöéÊÆµÈ†êÊ∏¨ÂÆöÁæ© RMAB Âü∑Ë°åÂÄãÈ´îÁöÑÊú™Áü•ÂèÉÊï∏ÔºåÁ¨¨‰∫åÂÄãÈöéÊÆµÊé°Áî®ÊúÄ‰Ω≥ÂåñÊºîÁÆóÊ≥ï‰æÜËß£Ê±∫Â∑≤Âª∫ÊßãÁöÑ RMAB Âü∑Ë°åÂÄãÈ´î„ÄÇ
Âú®Êú¨Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëÊèê‰æõ‰∏¶ÂàÜÊûê‰∫ÜÂú®ÂÖ¨ÂÖ±Ë°õÁîüÈ†òÂüü‰∏≠È¶ñÊ¨°ÈÉ®ÁΩ≤ RMAB Á≥ªÁµ±ÁöÑÁµêÊûúÔºåÁõÆÊ®ôÊòØÊîπÂñÑÂ≠ïÁî¢Â©¶ÂíåÂÖíÁ´•ÂÅ•Â∫∑„ÄÇÊàëÂÄëÁöÑÂàÜÊûêËëóÈáçÊñº‰∫ÜËß£È†êÊ∏¨Ê∫ñÁ¢∫Â∫¶ËàáÂ∑≤ÈÉ®ÁΩ≤ RMAB Á≥ªÁµ±ÁöÑÊï¥È´îÊïàËÉΩ‰πãÈñìÁöÑÈóú‰øÇ„ÄÇÈÄôÂ∞çÊñºÊ±∫ÂÆöÊäïË≥áÊñºÊîπÂñÑÈ†êÊ∏¨Ê∫ñÁ¢∫Â∫¶‰ª•ÊèêÂçáÊúÄÁµÇÁ≥ªÁµ±ÊïàËÉΩÁöÑÂÉπÂÄºËá≥ÈóúÈáçË¶ÅÔºå‰∏¶‰∏îÊúâÂä©ÊñºË®∫Êñ∑„ÄÅÁõ£ÊéßÂ∑≤ÈÉ®ÁΩ≤ÁöÑ RMAB Á≥ªÁµ±„ÄÇ
‰ΩøÁî®ÊàëÂÄëÂ∑≤ÈÉ®ÁΩ≤ RMAB Á≥ªÁµ±‰∏≠ÁöÑÁúüÂØ¶‰∏ñÁïåË≥áÊñôÔºåÊàëÂÄëË≠âÊòé‰∫ÜÊï¥È´îÈ†êÊ∏¨Ê∫ñÁ¢∫Â∫¶ÁöÑÊèêÂçáÁîöËá≥ÂèØËÉΩ‰º¥Èö®Ëëó RMAB Á≥ªÁµ±ÊïàËÉΩÁöÑ‰∏ãÈôç‚Äî‚ÄîÂª£Ê≥õÊäïÂÖ•Ë≥áÊ∫ê‰ª•ÊîπÂñÑÊï¥È´îÈ†êÊ∏¨Ê∫ñÁ¢∫Â∫¶ÂèØËÉΩÁÑ°Ê≥ïÁî¢ÁîüÈ†êÊúüÁöÑÁµêÊûú„ÄÇÂú®Ê≠§‰πãÂæåÔºåÊàëÂÄëÈñãÁôº‰∫Ü‰ª•Ê±∫Á≠ñÁÇ∫ÈáçÈªûÁöÑË©ï‰º∞ÊåáÊ®ô‰æÜË©ï‰º∞È†êÊ∏¨ÂÖÉ‰ª∂Ôºå‰∏¶Ë≠âÊòéÂÆÉÊõ¥ËÉΩËß£ÈáãÂ∑≤ÈÉ®ÁΩ≤ RMAB Á≥ªÁµ±ÁöÑÊï¥È´îÊïàËÉΩÔºàÁÑ°Ë´ñÊòØÁ∂ìÈ©ó‰∏äÊàñÁêÜË´ñ‰∏äÔºâ„ÄÇ

##### **Exemplars and Counterexemplars Explanations for Image Classifiers, Targeting Skin Lesion Labeling**
2302.03033v1 by Carlo Metta, Riccardo Guidotti, Yuan Yin, Patrick Gallinari, Salvatore Rinzivillo

Explainable AI consists in developing mechanisms allowing for an interaction
between decision systems and humans by making the decisions of the formers
understandable. This is particularly important in sensitive contexts like in
the medical domain. We propose a use case study, for skin lesion diagnosis,
illustrating how it is possible to provide the practitioner with explanations
on the decisions of a state of the art deep neural network classifier trained
to characterize skin lesions from examples. Our framework consists of a trained
classifier onto which an explanation module operates. The latter is able to
offer the practitioner exemplars and counterexemplars for the classification
diagnosis thus allowing the physician to interact with the automatic diagnosis
system. The exemplars are generated via an adversarial autoencoder. We
illustrate the behavior of the system on representative examples.

ÊëòË¶ÅÔºöÂèØËß£Èáã AI ÊòØÂú®ÈñãÁôºÊ©üÂà∂ÔºåËÆìÊ±∫Á≠ñÁ≥ªÁµ±Ëàá‰∫∫È°û‰πãÈñìËÉΩ‰∫íÂãïÔºå‰∏¶ËÆìÂâçËÄÖÁöÑÊ±∫Á≠ñËÆäÂæóÂèØ‰ª•ÁêÜËß£„ÄÇÈÄôÂú®ÊïèÊÑüÁöÑËÑàÁµ°‰∏≠ÁâπÂà•ÈáçË¶ÅÔºå‰æãÂ¶ÇÂú®ÈÜ´ÁôÇÈ†òÂüü„ÄÇÊàëÂÄëÊèêÂá∫‰∏ÄÂÄã‰ΩøÁî®Ê°à‰æãÁ†îÁ©∂ÔºåÁî®ÊñºÁöÆËÜöÁóÖËÆäË®∫Êñ∑ÔºåË™™ÊòéÂ¶Ç‰ΩïËÆìÂü∑Ê•≠ÈÜ´Â∏´‰∫ÜËß£ÊúÄÂÖàÈÄ≤ÁöÑÊ∑±Â∫¶Á•ûÁ∂ìÁ∂≤Ë∑ØÂàÜÈ°ûÂô®Âú®Ê±∫Á≠ñ‰∏äÁöÑËß£ÈáãÔºåË©≤ÂàÜÈ°ûÂô®Á∂ìÈÅéË®ìÁ∑¥ÔºåÂèØ‰ª•ÂæûÁØÑ‰æã‰∏≠ÊèèËø∞ÁöÆËÜöÁóÖËÆä„ÄÇÊàëÂÄëÁöÑÊû∂ÊßãÂåÖÂê´‰∏ÄÂÄãË®ìÁ∑¥ÈÅéÁöÑÂàÜÈ°ûÂô®ÔºåËß£ÈáãÊ®°ÁµÑÊúÉÂú®Ë©≤ÂàÜÈ°ûÂô®‰∏äÈÅã‰Ωú„ÄÇÂæåËÄÖËÉΩÂ§†ÁÇ∫ÂàÜÈ°ûË®∫Êñ∑Êèê‰æõÂü∑Ê•≠ÈÜ´Â∏´ÁØÑ‰æãÂíåÂèç‰æãÔºåÂõ†Ê≠§ËÆìÈÜ´Â∏´ÂèØ‰ª•ËàáËá™ÂãïË®∫Êñ∑Á≥ªÁµ±‰∫íÂãï„ÄÇÁØÑ‰æãÊòØÈÄèÈÅéÂ∞çÊäóÂºèËá™ÂãïÁ∑®Á¢ºÂô®Áî¢ÁîüÁöÑ„ÄÇÊàëÂÄëË™™ÊòéÁ≥ªÁµ±Âú®‰ª£Ë°®ÊÄßÁØÑ‰æã‰∏äÁöÑË°åÁÇ∫„ÄÇ

##### **Monotonicity for AI ethics and society: An empirical study of the monotonic neural additive model in criminology, education, health care, and finance**
2301.07060v1 by Dangxing Chen, Luyao Zhang

Algorithm fairness in the application of artificial intelligence (AI) is
essential for a better society. As the foundational axiom of social mechanisms,
fairness consists of multiple facets. Although the machine learning (ML)
community has focused on intersectionality as a matter of statistical parity,
especially in discrimination issues, an emerging body of literature addresses
another facet -- monotonicity. Based on domain expertise, monotonicity plays a
vital role in numerous fairness-related areas, where violations could misguide
human decisions and lead to disastrous consequences. In this paper, we first
systematically evaluate the significance of applying monotonic neural additive
models (MNAMs), which use a fairness-aware ML algorithm to enforce both
individual and pairwise monotonicity principles, for the fairness of AI ethics
and society. We have found, through a hybrid method of theoretical reasoning,
simulation, and extensive empirical analysis, that considering monotonicity
axioms is essential in all areas of fairness, including criminology, education,
health care, and finance. Our research contributes to the interdisciplinary
research at the interface of AI ethics, explainable AI (XAI), and
human-computer interactions (HCIs). By evidencing the catastrophic consequences
if monotonicity is not met, we address the significance of monotonicity
requirements in AI applications. Furthermore, we demonstrate that MNAMs are an
effective fairness-aware ML approach by imposing monotonicity restrictions
integrating human intelligence.

ÊëòË¶ÅÔºöÂú®‰∫∫Â∑•Êô∫ËÉΩ (AI) ÁöÑÊáâÁî®‰∏≠ÔºåÊºîÁÆóÊ≥ïÂÖ¨Âπ≥ÊÄßÂ∞çÊñºÂª∫Á´ã‰∏ÄÂÄãÊõ¥ÁæéÂ•ΩÁöÑÁ§æÊúÉËá≥ÈóúÈáçË¶Å„ÄÇÂÖ¨Âπ≥ÊÄß‰ΩúÁÇ∫Á§æÊúÉÊ©üÂà∂ÁöÑÂü∫Á§éÂÖ¨ÁêÜÔºåÂåÖÂê´Â§öÂÄãÈù¢Âêë„ÄÇÂÑòÁÆ°Ê©üÂô®Â≠∏Áøí (ML) Á§æÁæ§Â∑≤Â∞áÁÑ¶ÈªûÊîæÂú®‰∫§ÂèâÊÄß‰ΩúÁÇ∫Áµ±Ë®àÂêåË≥™ÊÄßÁöÑÂïèÈ°å‰∏äÔºåÁâπÂà•ÊòØÂú®Ê≠ßË¶ñÂïèÈ°å‰∏≠Ôºå‰ΩÜÊñ∞ËààÁöÑÊñáÁçªÊé¢Ë®é‰∫ÜÂè¶‰∏ÄÂÄãÈù¢Âêë‚Äî‚ÄîÂñÆË™øÊÄß„ÄÇÊ†πÊìöÈ†òÂüüÂ∞àÂÆ∂ÔºåÂñÆË™øÊÄßÂú®Ë®±Â§öËàáÂÖ¨Âπ≥ÊÄßÁõ∏ÈóúÁöÑÈ†òÂüü‰∏≠ÊâÆÊºîËëóËá≥ÈóúÈáçË¶ÅÁöÑËßíËâ≤ÔºåÈÅïÂèçÂñÆË™øÊÄßÂèØËÉΩÊúÉË™§Â∞é‰∫∫È°ûÊ±∫Á≠ñÔºå‰∏¶Â∞éËá¥ÁÅΩÈõ£ÊÄßÁöÑÂæåÊûú„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÈ¶ñÂÖàÁ≥ªÁµ±ÊÄßÂú∞Ë©ï‰º∞ÊáâÁî®ÂñÆË™øÁ•ûÁ∂ìÂä†Ê≥ïÊ®°Âûã (MNAM) ÁöÑÈáçË¶ÅÊÄßÔºåÈÄô‰∫õÊ®°Âûã‰ΩøÁî®ÂÖ¨Âπ≥ÊÑüÁü• ML ÊºîÁÆóÊ≥ï‰æÜÂº∑Âà∂Âü∑Ë°åÂÄãÂà•ÂíåÊàêÂ∞çÂñÆË™øÊÄßÂéüÂâáÔºå‰ª•Á¢∫‰øù AI ÂÄ´ÁêÜÂíåÁ§æÊúÉÁöÑÂÖ¨Âπ≥ÊÄß„ÄÇÊàëÂÄëÈÄèÈÅéÁêÜË´ñÊé®ÁêÜ„ÄÅÊ®°Êì¨ÂíåÂª£Ê≥õÁöÑÂØ¶Ë≠âÂàÜÊûêÁöÑÊ∑∑ÂêàÊñπÊ≥ïÁôºÁèæÔºåÂú®ÊâÄÊúâÂÖ¨Âπ≥È†òÂüüÔºàÂåÖÊã¨ÁäØÁΩ™Â≠∏„ÄÅÊïôËÇ≤„ÄÅÈÜ´ÁôÇ‰øùÂÅ•ÂíåÈáëËûçÔºâ‰∏≠ÔºåËÄÉÈáèÂñÆË™øÊÄßÂÖ¨ÁêÜËá≥ÈóúÈáçË¶Å„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÊúâÂä©Êñº AI ÂÄ´ÁêÜ„ÄÅÂèØËß£Èáã AI (XAI) Âíå‰∫∫Ê©ü‰∫íÂãï (HCI) ‰ªãÈù¢‰∏≠ÁöÑË∑®È†òÂüüÁ†îÁ©∂„ÄÇÈÄèÈÅéË≠âÊòé‰∏çÁ¨¶ÂêàÂñÆË™øÊÄßÁöÑÁÅΩÈõ£ÊÄßÂæåÊûúÔºåÊàëÂÄëÊé¢Ë®é‰∫ÜÂñÆË™øÊÄßÈúÄÊ±ÇÂú® AI ÊáâÁî®‰∏≠ÁöÑÈáçË¶ÅÊÄß„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëË≠âÊòé MNAM ÊòØ‰∏ÄÁ®ÆÊúâÊïàÁöÑÂÖ¨Âπ≥ÊÑüÁü• ML ÊñπÊ≥ïÔºåÈÄèÈÅéÊñΩÂä†ÂñÆË™øÊÄßÈôêÂà∂‰æÜÊï¥Âêà‰∫∫È°ûÊô∫ÊÖß„ÄÇ

##### **Rationalizing Predictions by Adversarial Information Calibration**
2301.06009v1 by Lei Sha, Oana-Maria Camburu, Thomas Lukasiewicz

Explaining the predictions of AI models is paramount in safety-critical
applications, such as in legal or medical domains. One form of explanation for
a prediction is an extractive rationale, i.e., a subset of features of an
instance that lead the model to give its prediction on that instance. For
example, the subphrase ``he stole the mobile phone'' can be an extractive
rationale for the prediction of ``Theft''. Previous works on generating
extractive rationales usually employ a two-phase model: a selector that selects
the most important features (i.e., the rationale) followed by a predictor that
makes the prediction based exclusively on the selected features. One
disadvantage of these works is that the main signal for learning to select
features comes from the comparison of the answers given by the predictor to the
ground-truth answers. In this work, we propose to squeeze more information from
the predictor via an information calibration method. More precisely, we train
two models jointly: one is a typical neural model that solves the task at hand
in an accurate but black-box manner, and the other is a selector-predictor
model that additionally produces a rationale for its prediction. The first
model is used as a guide for the second model. We use an adversarial technique
to calibrate the information extracted by the two models such that the
difference between them is an indicator of the missed or over-selected
features. In addition, for natural language tasks, we propose a
language-model-based regularizer to encourage the extraction of fluent
rationales. Experimental results on a sentiment analysis task, a hate speech
recognition task as well as on three tasks from the legal domain show the
effectiveness of our approach to rationale extraction.

ÊëòË¶ÅÔºö<paragraph>Âú®ÂÆâÂÖ®ÈóúÈçµÊáâÁî®Á®ãÂºè‰∏≠Ôºå‰æãÂ¶ÇÊ≥ïÂæãÊàñÈÜ´ÁôÇÈ†òÂüüÔºåËß£Èáã AI Ê®°ÂûãÁöÑÈ†êÊ∏¨Ëá≥ÈóúÈáçË¶Å„ÄÇ‰∏ÄÁ®ÆÈ†êÊ∏¨ÁöÑËß£ÈáãÂΩ¢ÂºèÊòØËêÉÂèñ‰æùÊìöÔºå‰∫¶Âç≥ÊüêÂÄãÂØ¶‰æã‰∏≠Â∞éËá¥Ê®°ÂûãÂ∞çË©≤ÂØ¶‰æãÂÅöÂá∫È†êÊ∏¨ÁöÑÂ≠êÈõÜÂêàÁâπÂæµ„ÄÇ‰æãÂ¶ÇÔºåÂ≠êË©ûÁµÑ„Äå‰ªñÂÅ∑‰∫ÜÊâãÊ©ü„ÄçÂèØËÉΩÊòØ„ÄåÂÅ∑Á´ä„ÄçÈ†êÊ∏¨ÁöÑËêÉÂèñ‰æùÊìö„ÄÇÂÖàÂâçÈóúÊñºÁî¢ÁîüËêÉÂèñ‰æùÊìöÁöÑÁ†îÁ©∂ÈÄöÂ∏∏Êé°Áî®‰∫åÈöéÊÆµÊ®°ÂûãÔºö‰∏ÄÂÄãÈÅ∏ÊìáÂô®ÈÅ∏ÊìáÊúÄÈáçË¶ÅÁöÑÁâπÂæµÔºàÂç≥‰æùÊìöÔºâÔºåÊé•ËëóÊòØ‰∏ÄÂÄãÈ†êÊ∏¨Âô®ÔºåÂÆÉÊ†πÊìöÊâÄÈÅ∏ÁöÑÁâπÂæµÁç®ÂÆ∂ÂÅöÂá∫È†êÊ∏¨„ÄÇÈÄô‰∫õÁ†îÁ©∂ÁöÑ‰∏ÄÂÄãÁº∫ÈªûÊòØÔºåÂ≠∏ÁøíÈÅ∏ÊìáÁâπÂæµÁöÑ‰∏ªË¶ÅË®äËôü‰æÜËá™Â∞áÈ†êÊ∏¨Âô®Áµ¶Âá∫ÁöÑÁ≠îÊ°àËàáÁúüÂØ¶Á≠îÊ°àÈÄ≤Ë°åÊØîËºÉ„ÄÇÂú®ÈÄôÈ†ÖÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄëÂª∫Ë≠∞ÈÄèÈÅéË≥áË®äÊ†°Ê≠£ÊñπÊ≥ïÂæûÈ†êÊ∏¨Âô®‰∏≠Êì∑ÂèñÊõ¥Â§öË≥áË®ä„ÄÇÊõ¥Á≤æÁ¢∫Âú∞Ë™™ÔºåÊàëÂÄëËÅØÂêàË®ìÁ∑¥ÂÖ©ÂÄãÊ®°ÂûãÔºö‰∏ÄÂÄãÊòØÂÖ∏ÂûãÁöÑÈ°ûÁ•ûÁ∂ìÁ∂≤Ë∑ØÊ®°ÂûãÔºåÂÆÉ‰ª•Ê∫ñÁ¢∫‰ΩÜÈªëÁÆ±ÁöÑÊñπÂºèËß£Ê±∫ÊâãÈÇäÁöÑ‰ªªÂãôÔºåÂè¶‰∏ÄÂÄãÊòØÈÅ∏ÊìáÂô®È†êÊ∏¨Âô®Ê®°ÂûãÔºåÂÆÉÂè¶Â§ñÁÇ∫ÂÖ∂È†êÊ∏¨Áî¢Áîü‰æùÊìö„ÄÇÁ¨¨‰∏ÄÂÄãÊ®°ÂûãÁî®‰ΩúÁ¨¨‰∫åÂÄãÊ®°ÂûãÁöÑÊåáÂçó„ÄÇÊàëÂÄë‰ΩøÁî®Â∞çÊäóÊäÄË°ìÊ†°Ê≠£ÂÖ©ÂÄãÊ®°ÂûãËêÉÂèñÁöÑË≥áË®äÔºå‰ΩøÂÆÉÂÄë‰πãÈñìÁöÑÂ∑ÆÁï∞ÊàêÁÇ∫ÈÅ∫ÊºèÊàñÈÅéÂ∫¶ÈÅ∏ÊìáÁöÑÁâπÂæµÁöÑÊåáÊ®ô„ÄÇÊ≠§Â§ñÔºåÂ∞çÊñºËá™ÁÑ∂Ë™ûË®Ä‰ªªÂãôÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÂü∫ÊñºË™ûË®ÄÊ®°ÂûãÁöÑÊ≠£Ë¶èÂåñÂô®Ôºå‰ª•ÈºìÂãµËêÉÂèñÊµÅÊö¢ÁöÑ‰æùÊìö„ÄÇÊÉÖÁ∑íÂàÜÊûê‰ªªÂãô„ÄÅ‰ªáÊÅ®Ë®ÄË´ñËæ®Ë≠ò‰ªªÂãô‰ª•ÂèäÊ≥ïÂæãÈ†òÂüü‰∏âÂÄã‰ªªÂãôÁöÑÂØ¶È©óÁµêÊûúÈ°ØÁ§∫ÔºåÊàëÂÄëÂú®‰æùÊìöËêÉÂèñÊñπÈù¢ÁöÑÂÅöÊ≥ïÂçÅÂàÜÊúâÊïà„ÄÇ</paragraph>

##### **Semantic match: Debugging feature attribution methods in XAI for healthcare**
2301.02080v3 by Giovanni Cin√†, Tabea E. R√∂ber, Rob Goedhart, ≈û. ƒ∞lker Birbil

The recent spike in certified Artificial Intelligence (AI) tools for
healthcare has renewed the debate around adoption of this technology. One
thread of such debate concerns Explainable AI (XAI) and its promise to render
AI devices more transparent and trustworthy. A few voices active in the medical
AI space have expressed concerns on the reliability of Explainable AI
techniques and especially feature attribution methods, questioning their use
and inclusion in guidelines and standards. Despite valid concerns, we argue
that existing criticism on the viability of post-hoc local explainability
methods throws away the baby with the bathwater by generalizing a problem that
is specific to image data. We begin by characterizing the problem as a lack of
semantic match between explanations and human understanding. To understand when
feature importance can be used reliably, we introduce a distinction between
feature importance of low- and high-level features. We argue that for data
types where low-level features come endowed with a clear semantics, such as
tabular data like Electronic Health Records (EHRs), semantic match can be
obtained, and thus feature attribution methods can still be employed in a
meaningful and useful way. Finally, we sketch a procedure to test whether
semantic match has been achieved.

ÊëòË¶ÅÔºöÊúÄËøëÈÄöÈÅéË™çË≠âÁöÑ‰∫∫Â∑•Êô∫ÊÖßÔºàAIÔºâÈÜ´ÁôÇ‰øùÂÅ•Â∑•ÂÖ∑Êï∏ÈáèÊøÄÂ¢ûÔºåËÆìÊé°Áî®Ê≠§ÊäÄË°ìÁöÑËæØË´ñÂÜçÂ∫¶ÊµÆ‰∏äÊ™ØÈù¢„ÄÇÂÖ∂‰∏≠‰∏ÄÂÄãËæØË´ñ‰∏ªÈ°åÊòØÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖßÔºàXAIÔºâÂèäÂÖ∂ËÆì AI Ë£ùÁΩÆÊõ¥ÈÄèÊòé‰∏îÂÄºÂæó‰ø°Ë≥¥ÁöÑÊâøË´æ„ÄÇÈÜ´ÁôÇ AI È†òÂüü‰∏≠ÁöÑ‰∏Ä‰∫õÁ©çÊ•µÁôºË®ÄËÄÖË°®ÈÅî‰∫ÜÂ∞çÂèØËß£Èáã AI ÊäÄË°ìÔºåÂ∞§ÂÖ∂ÊòØÁâπÂæµÊ≠∏Âõ†ÊñπÊ≥ïÁöÑÂèØÈù†ÊÄßÁñëÊÖÆÔºåË≥™ÁñëÂÖ∂Âú®Ê∫ñÂâáÂíåÊ®ôÊ∫ñ‰∏≠ÁöÑ‰ΩøÁî®ÂíåÁ¥çÂÖ•„ÄÇÂÑòÁÆ°ÊúâÂêàÁêÜÁöÑÁñëÊÖÆÔºåÊàëÂÄë‰∏ªÂºµÂ∞ç‰∫ãÂæåÂ±ÄÈÉ®ÂèØËß£ÈáãÊÄßÊñπÊ≥ïÁöÑÂèØË°åÊÄßÊèêÂá∫ÊâπË©ïÔºåÁ≠âÊñºÈÄ£ÂêåÊ¥óÊæ°Ê∞¥‰∏ÄËµ∑ÊääÂ¨∞ÂÖíÂÄíÊéâÔºåÂõ†ÁÇ∫ÈÄôÊòØÂú®Â∞çÂΩ±ÂÉèË≥áÊñôÁâπÊúâÁöÑÂïèÈ°åÈÄ≤Ë°åÊ¶ÇÂåñ„ÄÇÊàëÂÄëÂæûÂ∞áÂïèÈ°åÊèèËø∞ÁÇ∫Ëß£ÈáãËàá‰∫∫È°ûÁêÜËß£‰πãÈñìÁº∫‰πèË™ûÊÑèÂåπÈÖçÈñãÂßã„ÄÇÁÇ∫‰∫ÜÁû≠Ëß£‰ΩïÊôÇÂèØ‰ª•ÂèØÈù†Âú∞‰ΩøÁî®ÁâπÂæµÈáçË¶ÅÊÄßÔºåÊàëÂÄëÂçÄÂàÜ‰∫Ü‰ΩéÈöéÂíåÈ´òÈöéÁâπÂæµÁöÑÁâπÂæµÈáçË¶ÅÊÄß„ÄÇÊàëÂÄë‰∏ªÂºµÔºåÂ∞çÊñº‰ΩéÈöéÁâπÂæµÂÖ∑ÊúâÊòéÁ¢∫Ë™ûÊÑèÁöÑË≥áÊñôÈ°ûÂûãÔºå‰æãÂ¶ÇÈõªÂ≠êÂÅ•Â∫∑Ë®òÈåÑÔºàEHRÔºâÁ≠âË°®Ê†ºË≥áÊñôÔºåÂèØ‰ª•Áç≤ÂæóË™ûÊÑèÂåπÈÖçÔºåÂõ†Ê≠§‰ªçÁÑ∂ÂèØ‰ª•Âú®ÊúâÊÑèÁæ©‰∏îÊúâÁî®ÁöÑÊñπÂºè‰∏≠Êé°Áî®ÁâπÂæµÊ≠∏Âõ†ÊñπÊ≥ï„ÄÇÊúÄÂæåÔºåÊàëÂÄëÊ¶ÇËø∞‰∫Ü‰∏ÄÂÄãÁ®ãÂ∫èÔºå‰ª•Ê∏¨Ë©¶ÊòØÂê¶Â∑≤ÈÅîÊàêË™ûÊÑèÂåπÈÖç„ÄÇ

##### **Context-dependent Explainability and Contestability for Trustworthy Medical Artificial Intelligence: Misclassification Identification of Morbidity Recognition Models in Preterm Infants**
2212.08821v1 by Isil Guzey, Ozlem Ucar, Nukhet Aladag Ciftdemir, Betul Acunas

Although machine learning (ML) models of AI achieve high performances in
medicine, they are not free of errors. Empowering clinicians to identify
incorrect model recommendations is crucial for engendering trust in medical AI.
Explainable AI (XAI) aims to address this requirement by clarifying AI
reasoning to support the end users. Several studies on biomedical imaging
achieved promising results recently. Nevertheless, solutions for models using
tabular data are not sufficient to meet the requirements of clinicians yet.
This paper proposes a methodology to support clinicians in identifying failures
of ML models trained with tabular data. We built our methodology on three main
pillars: decomposing the feature set by leveraging clinical context latent
space, assessing the clinical association of global explanations, and Latent
Space Similarity (LSS) based local explanations. We demonstrated our
methodology on ML-based recognition of preterm infant morbidities caused by
infection. The risk of mortality, lifelong disability, and antibiotic
resistance due to model failures was an open research question in this domain.
We achieved to identify misclassification cases of two models with our
approach. By contextualizing local explanations, our solution provides
clinicians with actionable insights to support their autonomy for informed
final decisions.

ÊëòË¶ÅÔºöÂÑòÁÆ°‰∫∫Â∑•Êô∫ÊÖß (AI) ÁöÑÊ©üÂô®Â≠∏Áøí (ML) Ê®°ÂûãÂú®ÈÜ´Â≠∏È†òÂüü‰∏≠Ë°®ÁèæÂÑ™Áï∞Ôºå‰ΩÜÂÆÉÂÄë‰∏¶ÈùûÊ≤íÊúâÈåØË™§„ÄÇËÆìËá®Â∫äÈÜ´ÁîüËÉΩÂ§†Ëæ®Ë≠ò‰∏çÊ≠£Á¢∫ÁöÑÊ®°ÂûãÂª∫Ë≠∞ÔºåÂ∞çÊñºÂª∫Á´ãÂ∞çÈÜ´ÁôÇ AI ÁöÑ‰ø°‰ªªËá≥ÈóúÈáçË¶Å„ÄÇÂèØËß£Èáã AI (XAI) Êó®Âú®ÈÄèÈÅéÈáêÊ∏Ö AI Êé®ÁêÜ‰æÜÊªøË∂≥Ê≠§È†ÖÈúÄÊ±ÇÔºå‰ª•ÊîØÊè¥ÊúÄÁµÇ‰ΩøÁî®ËÄÖ„ÄÇÊúÄËøëÈáùÂ∞çÁîüÁâ©ÈÜ´Â≠∏ÂΩ±ÂÉèÈÄ≤Ë°åÁöÑÂπæÈ†ÖÁ†îÁ©∂Áç≤Âæó‰∫Ü‰ª§‰∫∫ÊªøÊÑèÁöÑÁµêÊûú„ÄÇÁÑ∂ËÄåÔºå‰ΩøÁî®Ë°®Ê†ºË≥áÊñôÁöÑÊ®°ÂûãËß£Ê±∫ÊñπÊ°àÈÇÑ‰∏çË∂≥‰ª•ÊªøË∂≥Ëá®Â∫äÈÜ´ÁîüÁöÑÈúÄÊ±Ç„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñπÊ≥ïÔºåÂçîÂä©Ëá®Â∫äÈÜ´ÁîüËæ®Ë≠ò‰ΩøÁî®Ë°®Ê†ºË≥áÊñôË®ìÁ∑¥ÁöÑ ML Ê®°ÂûãÁöÑÂ§±Êïó„ÄÇÊàëÂÄëÁöÑÊñπÊ≥ïÂª∫Á´ãÂú®‰∏âÂÄã‰∏ªË¶ÅÊîØÊü±‰∏äÔºöÂà©Áî®Ëá®Â∫äËÉåÊôØÊΩõÂú®Á©∫ÈñìÂàÜËß£ÁâπÂæµÈõÜ„ÄÅË©ï‰º∞Êï¥È´îËß£ÈáãÁöÑËá®Â∫äÈóúËÅØÊÄßÔºå‰ª•ÂèäÂü∫ÊñºÊΩõÂú®Á©∫ÈñìÁõ∏‰ººÊÄß (LSS) ÁöÑÂ±ÄÈÉ®Ëß£Èáã„ÄÇÊàëÂÄëÂú® ML Âü∫ÊñºÊÑüÊüìÊâÄÂ∞éËá¥ÁöÑÊó©Áî¢ÂÖíÁôºÁóÖÁéáË≠òÂà•‰∏äÂ±ïÁ§∫‰∫ÜÊàëÂÄëÁöÑÈÄôÈ†ÖÊñπÊ≥ï„ÄÇÁî±ÊñºÊ®°ÂûãÂ§±ÊïóËÄåÁî¢ÁîüÁöÑÊ≠ª‰∫°È¢®Èö™„ÄÅÁµÇË∫´ÊÆòÁñæÂíåÊäóÁîüÁ¥†ÊäóËó•ÊÄßÔºåÊòØÊ≠§È†òÂüü‰∏≠‰∏ÄÂÄãÂÖ¨ÈñãÁöÑÁ†îÁ©∂ÂïèÈ°å„ÄÇÊàëÂÄëÁöÑÊñπÊ≥ïÊàêÂäüËæ®Ë≠òÂá∫ÂÖ©ÂÄãÊ®°ÂûãÁöÑÈåØË™§ÂàÜÈ°ûÊ°à‰æã„ÄÇÊàëÂÄëÁöÑËß£Ê±∫ÊñπÊ°àÈÄèÈÅéÂ∞áÂ±ÄÈÉ®Ëß£ÈáãËÑàÁµ°ÂåñÔºåÁÇ∫Ëá®Â∫äÈÜ´ÁîüÊèê‰æõÂèØË°åÁöÑË¶ãËß£Ôºå‰ª•ÊîØÊè¥‰ªñÂÄëËá™‰∏ªÂÅöÂá∫ÊòéÊô∫ÁöÑÊúÄÁµÇÊ±∫ÂÆö„ÄÇ

##### **It is not "accuracy vs. explainability" -- we need both for trustworthy AI systems**
2212.11136v2 by D. Petkovic

We are witnessing the emergence of an AI economy and society where AI
technologies are increasingly impacting health care, business, transportation
and many aspects of everyday life. Many successes have been reported where AI
systems even surpassed the accuracy of human experts. However, AI systems may
produce errors, can exhibit bias, may be sensitive to noise in the data, and
often lack technical and judicial transparency resulting in reduction in trust
and challenges in their adoption. These recent shortcomings and concerns have
been documented in scientific but also in general press such as accidents with
self driving cars, biases in healthcare, hiring and face recognition systems
for people of color, seemingly correct medical decisions later found to be made
due to wrong reasons etc. This resulted in emergence of many government and
regulatory initiatives requiring trustworthy and ethical AI to provide accuracy
and robustness, some form of explainability, human control and oversight,
elimination of bias, judicial transparency and safety. The challenges in
delivery of trustworthy AI systems motivated intense research on explainable AI
systems (XAI). Aim of XAI is to provide human understandable information of how
AI systems make their decisions. In this paper we first briefly summarize
current XAI work and then challenge the recent arguments of accuracy vs.
explainability for being mutually exclusive and being focused only on deep
learning. We then present our recommendations for the use of XAI in full
lifecycle of high stakes trustworthy AI systems delivery, e.g. development,
validation and certification, and trustworthy production and maintenance.

ÊëòË¶ÅÔºö<paragraph>ÊàëÂÄëÊ≠£Ë¶ãË≠âËëó AI Á∂ìÊøüËàáÁ§æÊúÉÁöÑÂ¥õËµ∑ÔºåÂÖ∂‰∏≠ AI ÊäÄË°ìÊ≠£Êó•ÁõäÂΩ±ÈüøËëóÈÜ´ÁôÇ‰øùÂÅ•„ÄÅÂïÜÊ•≠„ÄÅÈÅãËº∏‰ª•ÂèäÊó•Â∏∏ÁîüÊ¥ª‰∏≠ÁöÑË®±Â§öÊñπÈù¢„ÄÇË®±Â§öÊàêÂäüÊ°à‰æã‰∏≠ÔºåAI Á≥ªÁµ±ÁîöËá≥Ë∂ÖË∂ä‰∫Ü‰∫∫È°ûÂ∞àÂÆ∂ÁöÑÊ∫ñÁ¢∫Â∫¶„ÄÇÁÑ∂ËÄåÔºåAI Á≥ªÁµ±ÂèØËÉΩÊúÉÁî¢ÁîüÈåØË™§ÔºåÂèØËÉΩË°®ÁèæÂá∫ÂÅèË¶ãÔºåÂèØËÉΩÂ∞çË≥áÊñô‰∏≠ÁöÑÈõúË®äÊïèÊÑüÔºåËÄå‰∏îÂ∏∏Â∏∏Áº∫‰πèÊäÄË°ìÂíåÂè∏Ê≥ïÈÄèÊòéÂ∫¶ÔºåÂ∞éËá¥‰ø°‰ªªÂ∫¶‰∏ãÈôç‰ª•ÂèäÊé°Áî®‰∏äÁöÑÊåëÊà∞„ÄÇÈÄô‰∫õÊúÄËøëÁöÑÁº∫ÈªûÂíåÁñëÊÖÆÂ∑≤Âú®ÁßëÂ≠∏ÊúüÂàäÂíå‰∏ÄËà¨Â™íÈ´î‰∏≠ÂæóÂà∞Ë®òÈåÑÔºå‰æãÂ¶ÇËá™ÂãïÈßïÈßõÊ±ΩËªä‰∫ãÊïÖ„ÄÅÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÁöÑÂÅèË¶ã„ÄÅÊúâËâ≤‰∫∫Á®ÆÁöÑÊãõËÅòÂíå‰∫∫ËáâË≠òÂà•Á≥ªÁµ±„ÄÅÁúã‰ººÊ≠£Á¢∫ÁöÑÈÜ´ÁôÇÊ±∫Á≠ñÂæå‰æÜÁôºÁèæÊòØÂá∫ÊñºÈåØË™§ÁöÑÂéüÂõ†Á≠âÁ≠â„ÄÇÈÄôÂ∞éËá¥Ë®±Â§öÊîøÂ∫úÂíåÁõ£ÁÆ°ÂÄ°Ë≠∞ÁöÑÂá∫ÁèæÔºåË¶ÅÊ±ÇÂèØ‰ø°Ë≥¥‰∏îÂêà‰πéÈÅìÂæ∑ÁöÑ AI Êèê‰æõÊ∫ñÁ¢∫ÊÄßÂíåÁ©©ÂÅ•ÊÄß„ÄÅÊüêÁ®ÆÂΩ¢ÂºèÁöÑÂèØËß£ÈáãÊÄß„ÄÅ‰∫∫È°ûÊéßÂà∂ÂíåÁõ£Áù£„ÄÅÊ∂àÈô§ÂÅèË¶ã„ÄÅÂè∏Ê≥ïÈÄèÊòéÂ∫¶ÂíåÂÆâÂÖ®ÊÄß„ÄÇÊèê‰æõÂèØ‰ø°Ë≥¥ AI Á≥ªÁµ±ÁöÑÊåëÊà∞ÊøÄÂãµ‰∫ÜÂ∞çÂèØËß£Èáã AI Á≥ªÁµ± (XAI) ÁöÑÊ∑±ÂÖ•Á†îÁ©∂„ÄÇXAI ÁöÑÁõÆÊ®ôÊòØÊèê‰æõ‰∫∫È°ûÂèØ‰ª•ÁêÜËß£ÁöÑË≥áË®äÔºåË™™Êòé AI Á≥ªÁµ±Â¶Ç‰ΩïÂÅöÂá∫Ê±∫Á≠ñ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÈ¶ñÂÖàÁ∞°Ë¶ÅÁ∏ΩÁµêÁõÆÂâçÁöÑ XAI Â∑•‰ΩúÔºåÁÑ∂ÂæåÊåëÊà∞Ê∫ñÁ¢∫ÊÄßËàáÂèØËß£ÈáãÊÄßÁõ∏‰∫íÊéíÊñ•‰∏îÂÉÖÂ∞àÊ≥®ÊñºÊ∑±Â∫¶Â≠∏ÁøíÁöÑËøëÊúüË´ñÈªû„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÊèêÂá∫ÊàëÂÄëÁöÑÂª∫Ë≠∞ÔºåÂú®È´òÈ¢®Èö™ÂèØ‰ø°Ë≥¥ AI Á≥ªÁµ±‰∫§‰ªòÁöÑÂÆåÊï¥ÁîüÂëΩÈÄ±Êúü‰∏≠‰ΩøÁî® XAIÔºå‰æãÂ¶ÇÈñãÁôº„ÄÅÈ©óË≠âÂíåË™çË≠âÔºå‰ª•ÂèäÂèØ‰ø°Ë≥¥ÁöÑÁîüÁî¢ÂíåÁ∂≠Ë≠∑„ÄÇ</paragraph>

##### **SimpleMind adds thinking to deep neural networks**
2212.00951v1 by Youngwon Choi, M. Wasil Wahi-Anwar, Matthew S. Brown

Deep neural networks (DNNs) detect patterns in data and have shown
versatility and strong performance in many computer vision applications.
However, DNNs alone are susceptible to obvious mistakes that violate simple,
common sense concepts and are limited in their ability to use explicit
knowledge to guide their search and decision making. While overall DNN
performance metrics may be good, these obvious errors, coupled with a lack of
explainability, have prevented widespread adoption for crucial tasks such as
medical image analysis. The purpose of this paper is to introduce SimpleMind,
an open-source software framework for Cognitive AI focused on medical image
understanding. It allows creation of a knowledge base that describes expected
characteristics and relationships between image objects in an intuitive
human-readable form. The SimpleMind framework brings thinking to DNNs by: (1)
providing methods for reasoning with the knowledge base about image content,
such as spatial inferencing and conditional reasoning to check DNN outputs; (2)
applying process knowledge, in the form of general-purpose software agents,
that are chained together to accomplish image preprocessing, DNN prediction,
and result post-processing, and (3) performing automatic co-optimization of all
knowledge base parameters to adapt agents to specific problems. SimpleMind
enables reasoning on multiple detected objects to ensure consistency, providing
cross checking between DNN outputs. This machine reasoning improves the
reliability and trustworthiness of DNNs through an interpretable model and
explainable decisions. Example applications are provided that demonstrate how
SimpleMind supports and improves deep neural networks by embedding them within
a Cognitive AI framework.

ÊëòË¶ÅÔºöÊ∑±Â∫¶Á•ûÁªèÁ∂≤Ë∑Ø (DNN) ÂèØÂÅµÊ∏¨Ë≥áÊñô‰∏≠ÁöÑÊ®°ÂºèÔºå‰∏¶Âú®Ë®±Â§öÈõªËÖ¶Ë¶ñË¶∫ÊáâÁî®‰∏≠Â±ïÁèæÂá∫Â§öÂäüËÉΩÊÄßËàáÂº∑Â§ßÊïàËÉΩ„ÄÇ
ÁÑ∂ËÄåÔºåDNN Êú¨Ë∫´ÂÆπÊòìÁäØ‰∏ãÈÅïÂèçÁ∞°ÂñÆÂ∏∏Ë≠òÊ¶ÇÂøµÁöÑÊòéÈ°ØÈåØË™§Ôºå‰∏îÂú®‰ΩøÁî®ÊòéÁ¢∫Áü•Ë≠ò‰æÜÂºïÂ∞éÂÖ∂ÊêúÂ∞ãËàáÊ±∫Á≠ñÂà∂ÂÆöÊôÇÊúâÂÖ∂ÈôêÂà∂„ÄÇÂÑòÁÆ°Êï¥È´î DNN ÊïàËÉΩÊåáÊ®ôÂèØËÉΩËâØÂ•ΩÔºå‰ΩÜÈÄô‰∫õÊòéÈ°ØÁöÑÈåØË™§ÔºåÂä†‰∏äÁº∫‰πèÂèØËß£ÈáãÊÄßÔºåÂ∑≤ÈòªÁ§ôÂÖ∂Âª£Ê≥õÊé°Áî®ÊñºË´∏Â¶ÇÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÊûêÁ≠âÈóúÈçµ‰ªªÂãô„ÄÇÊú¨ÊñáÁöÑÁõÆÁöÑÊòØ‰ªãÁ¥π SimpleMindÔºå‰∏ÄÂÄãÂ∞àÊ≥®ÊñºÈÜ´Â≠∏ÂΩ±ÂÉèÁêÜËß£ÁöÑË™çÁü• AI ÈñãÊ∫êËªüÈ´îÊ°ÜÊû∂„ÄÇÂÆÉÂÖÅË®±Âª∫Á´ã‰∏ÄÂÄãÁü•Ë≠òÂ∫´Ôºå‰ª•Áõ¥ËßÄÁöÑ‰∫∫È°ûÂèØËÆÄÂΩ¢ÂºèÊèèËø∞ÂΩ±ÂÉèÁâ©‰ª∂‰πãÈñìÈ†êÊúüÁöÑÁâπÂæµÂíåÈóú‰øÇ„ÄÇSimpleMind Ê°ÜÊû∂ÈÄèÈÅé‰ª•‰∏ãÊñπÂºèÁÇ∫ DNN Â∏∂‰æÜÊÄùËÄÉËÉΩÂäõÔºö(1) Êèê‰æõÂü∫ÊñºÁü•Ë≠òÂ∫´Â∞çÂΩ±ÂÉèÂÖßÂÆπÈÄ≤Ë°åÊé®ÁêÜÁöÑÊñπÊ≥ïÔºå‰æãÂ¶ÇÁ©∫ÈñìÊé®Ë´ñÂíåÊ¢ù‰ª∂Êé®ÁêÜÔºå‰ª•Ê™¢Êü• DNN Ëº∏Âá∫Ôºõ(2) ‰ª•ÈÄöÁî®ËªüÈ´î‰ª£ÁêÜÁöÑÂΩ¢ÂºèÂ•óÁî®Á®ãÂ∫èÁü•Ë≠òÔºåÂ∞áÂÖ∂‰∏≤ÈÄ£Âú®‰∏ÄËµ∑‰ª•ÂÆåÊàêÂΩ±ÂÉèÂâçËôïÁêÜ„ÄÅDNN È†êÊ∏¨ÂíåÁµêÊûúÂæåËôïÁêÜÔºõ‰ª•Âèä (3) Â∞çÊâÄÊúâÁü•Ë≠òÂ∫´ÂèÉÊï∏Âü∑Ë°åËá™ÂãïÂÖ±ÂêåÊúÄ‰Ω≥ÂåñÔºå‰ª•ÈÅ©Êáâ‰ª£ÁêÜÂà∞ÁâπÂÆöÂïèÈ°å„ÄÇSimpleMind ËÉΩÂ∞çÂ§öÂÄãÂÅµÊ∏¨Âà∞ÁöÑÁâ©‰ª∂ÈÄ≤Ë°åÊé®ÁêÜ‰ª•Á¢∫‰øù‰∏ÄËá¥ÊÄßÔºå‰∏¶Êèê‰æõ DNN Ëº∏Âá∫‰πãÈñìÁöÑ‰∫§ÂèâÊ™¢Êü•„ÄÇÈÄôÁ®ÆÊ©üÂô®Êé®ÁêÜÈÄèÈÅé‰∏ÄÂÄãÂèØËß£ÈáãÁöÑÊ®°ÂûãÂíåÂèØËß£ÈáãÁöÑÊ±∫Á≠ñÔºå‰æÜÊèêÂçá DNN ÁöÑÂèØÈù†ÊÄßÂíåÂèØ‰ø°Â∫¶„ÄÇÊú¨ÊñáÊèê‰æõ‰∫ÜÁØÑ‰æãÊáâÁî®ÔºåÂ±ïÁ§∫ SimpleMind Â¶Ç‰ΩïÈÄèÈÅéÂ∞áÊ∑±Â∫¶Á•ûÁ∂ìÁ∂≤Ë∑ØÂµåÂÖ•Ë™çÁü• AI Ê°ÜÊû∂‰∏≠Ôºå‰æÜÊîØÊè¥ÂíåÊîπÂñÑÊ∑±Â∫¶Á•ûÁ∂ìÁ∂≤Ë∑Ø„ÄÇ

##### **Attribution-based XAI Methods in Computer Vision: A Review**
2211.14736v1 by Kumar Abhishek, Deeksha Kamath

The advancements in deep learning-based methods for visual perception tasks
have seen astounding growth in the last decade, with widespread adoption in a
plethora of application areas from autonomous driving to clinical decision
support systems. Despite their impressive performance, these deep
learning-based models remain fairly opaque in their decision-making process,
making their deployment in human-critical tasks a risky endeavor. This in turn
makes understanding the decisions made by these models crucial for their
reliable deployment. Explainable AI (XAI) methods attempt to address this by
offering explanations for such black-box deep learning methods. In this paper,
we provide a comprehensive survey of attribution-based XAI methods in computer
vision and review the existing literature for gradient-based,
perturbation-based, and contrastive methods for XAI, and provide insights on
the key challenges in developing and evaluating robust XAI methods.

ÊëòË¶ÅÔºöÂú®ÈÅéÂéªÂçÅÂπ¥‰∏≠ÔºåÂü∫ÊñºÊ∑±Â∫¶Â≠∏ÁøíÊñπÊ≥ïÁöÑË¶ñË¶∫ÊÑüÁü•‰ªªÂãôÂèñÂæó‰∫ÜÈ©ö‰∫∫ÁöÑÈÄ≤Â±ïÔºå‰∏¶Âª£Ê≥õÊáâÁî®ÊñºÂæûËá™ÂãïÈßïÈßõÂà∞Ëá®Â∫äÊ±∫Á≠ñÊîØÊè¥Á≥ªÁµ±ÁöÑÁúæÂ§öÊáâÁî®È†òÂüü„ÄÇÂÑòÁÆ°ÈÄô‰∫õÂü∫ÊñºÊ∑±Â∫¶Â≠∏ÁøíÁöÑÊ®°ÂûãÊïàËÉΩ‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÔºå‰ΩÜÂÆÉÂÄëÂú®Ê±∫Á≠ñÈÅéÁ®ã‰∏≠‰ªçÁÑ∂Áõ∏Áï∂‰∏çÈÄèÊòéÔºåÈÄô‰ΩøÂæóÂÆÉÂÄëÂú®‰∫∫È°ûÈóúÈçµ‰ªªÂãô‰∏≠ÁöÑÈÉ®ÁΩ≤ÊàêÁÇ∫‰∏ÄÈ†ÖÂÜíÈö™ÁöÑ‰∫ãÊ•≠„ÄÇÈÄôÂèçÈÅé‰æÜÂèà‰ΩøÂæóÁêÜËß£ÈÄô‰∫õÊ®°ÂûãÂÅöÂá∫ÁöÑÊ±∫Á≠ñÂ∞çÊñºÂÆÉÂÄëÁöÑÂèØÈù†ÈÉ®ÁΩ≤Ëá≥ÈóúÈáçË¶Å„ÄÇÂèØËß£Èáã AI (XAI) ÊñπÊ≥ïË©¶ÂúñÈÄöÈÅéÁÇ∫ÈÄôÁ®ÆÈªëÁõíÊ∑±Â∫¶Â≠∏ÁøíÊñπÊ≥ïÊèê‰æõËß£Èáã‰æÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°å„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂ∞çÈõªËÖ¶Ë¶ñË¶∫‰∏≠ÁöÑÂü∫ÊñºÊ≠∏Âõ†ÁöÑ XAI ÊñπÊ≥ïÈÄ≤Ë°å‰∫ÜÂÖ®Èù¢ÁöÑË™øÊü•Ôºå‰∏¶ÂõûÈ°ß‰∫ÜÁèæÊúâÈóúÊñºÂü∫ÊñºÊ¢ØÂ∫¶„ÄÅÂü∫ÊñºÊìæÂãïÂíåÂü∫ÊñºÂ∞çÊØîÁöÑ XAI ÊñπÊ≥ïÁöÑÊñáÁçªÔºå‰∏¶Â∞çÈñãÁôºÂíåË©ï‰º∞Á©©ÂÅ•ÁöÑ XAI ÊñπÊ≥ïÁöÑÈóúÈçµÊåëÊà∞Êèê‰æõ‰∫ÜË¶ãËß£„ÄÇ

##### **Privacy Meets Explainability: A Comprehensive Impact Benchmark**
2211.04110v1 by Saifullah Saifullah, Dominique Mercier, Adriano Lucieri, Andreas Dengel, Sheraz Ahmed

Since the mid-10s, the era of Deep Learning (DL) has continued to this day,
bringing forth new superlatives and innovations each year. Nevertheless, the
speed with which these innovations translate into real applications lags behind
this fast pace. Safety-critical applications, in particular, underlie strict
regulatory and ethical requirements which need to be taken care of and are
still active areas of debate. eXplainable AI (XAI) and privacy-preserving
machine learning (PPML) are both crucial research fields, aiming at mitigating
some of the drawbacks of prevailing data-hungry black-box models in DL. Despite
brisk research activity in the respective fields, no attention has yet been
paid to their interaction. This work is the first to investigate the impact of
private learning techniques on generated explanations for DL-based models. In
an extensive experimental analysis covering various image and time series
datasets from multiple domains, as well as varying privacy techniques, XAI
methods, and model architectures, the effects of private training on generated
explanations are studied. The findings suggest non-negligible changes in
explanations through the introduction of privacy. Apart from reporting
individual effects of PPML on XAI, the paper gives clear recommendations for
the choice of techniques in real applications. By unveiling the
interdependencies of these pivotal technologies, this work is a first step
towards overcoming the remaining hurdles for practically applicable AI in
safety-critical domains.

ÊëòË¶ÅÔºöËá™ 10 Âπ¥‰ª£‰∏≠Êúü‰ª•‰æÜÔºåÊ∑±Â∫¶Â≠∏Áøí (DL) ÁöÑÊôÇ‰ª£ÊåÅÁ∫åËá≥‰ªäÔºåÊØèÂπ¥ÈÉΩÊúÉÂ∏∂‰æÜÊñ∞ÁöÑÊúÄÂÑ™ÂÄºÂíåÂâµÊñ∞„ÄÇÂÑòÁÆ°Â¶ÇÊ≠§ÔºåÈÄô‰∫õÂâµÊñ∞ËΩâÂåñÁÇ∫ÂØ¶ÈöõÊáâÁî®Á®ãÂºèÁöÑÈÄüÂ∫¶‰ªçËêΩÂæåÊñºÈÄôÁ®ÆÂø´ÈÄüÊ≠•‰ºê„ÄÇÁâπÂà•ÊòØÂÆâÂÖ®ÈóúÈçµÊáâÁî®Á®ãÂºèÔºåÂÖ∂Âü∫Á§éÊòØÂö¥Ê†ºÁöÑÊ≥ïË¶èÂíåÈÅìÂæ∑Ë¶ÅÊ±ÇÔºåÈúÄË¶ÅÂ¶•ÂñÑËôïÁêÜÔºå‰∏¶‰∏î‰ªçÁÑ∂ÊòØÁà≠Ë´ñÁöÑÈ†òÂüü„ÄÇÂèØËß£Èáã AI (XAI) ÂíåÈö±ÁßÅ‰øùË≠∑Ê©üÂô®Â≠∏Áøí (PPML) ÈÉΩÊòØËá≥ÈóúÈáçË¶ÅÁöÑÁ†îÁ©∂È†òÂüüÔºåÊó®Âú®Ê∏õËºï DL ‰∏≠ÊµÅË°åÁöÑË≥áÊñôÂØÜÈõÜÂûãÈªëÁõíÊ®°ÂûãÁöÑ‰∏Ä‰∫õÁº∫Èªû„ÄÇÂÑòÁÆ°Âú®ÂêÑËá™È†òÂüü‰∏≠ÈÄ≤Ë°å‰∫ÜÁÜ±ÁÉàÁöÑÁ†îÁ©∂Ê¥ªÂãïÔºå‰ΩÜÂ∞öÊú™ÈóúÊ≥®ÂÆÉÂÄëÁöÑ‰∫íÂãï„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÊòØÁ¨¨‰∏ÄÂÄãÊé¢Ë®éÁßÅÊúâÂ≠∏ÁøíÊäÄË°ìÂ∞çÂü∫Êñº DL ÁöÑÊ®°ÂûãÁî¢ÁîüÁöÑËß£ÈáãÁöÑÂΩ±Èüø„ÄÇÂú®Ê∂µËìãÂ§öÂÄãÈ†òÂüüÁöÑÂêÑÁ®ÆÂΩ±ÂÉèÂíåÊôÇÈñìÂ∫èÂàóË≥áÊñôÈõÜ‰ª•Âèä‰∏çÂêåÁöÑÈö±ÁßÅÊäÄË°ì„ÄÅXAI ÊñπÊ≥ïÂíåÊ®°ÂûãÊû∂ÊßãÁöÑÂª£Ê≥õÂØ¶È©óÂàÜÊûê‰∏≠ÔºåÁ†îÁ©∂‰∫ÜÁßÅÊúâË®ìÁ∑¥Â∞çÁî¢ÁîüÁöÑËß£ÈáãÁöÑÂΩ±Èüø„ÄÇÁ†îÁ©∂ÁµêÊûúË°®ÊòéÔºåÈÄèÈÅéÂºïÂÖ•Èö±ÁßÅÔºåËß£ÈáãÊúÉÁî¢Áîü‰∏çÂèØÂøΩË¶ñÁöÑËÆäÂåñ„ÄÇÈô§‰∫ÜÂ†±Âëä PPML Â∞ç XAI ÁöÑÂÄãÂà•ÂΩ±ÈüøÂ§ñÔºåÊú¨ÊñáÈÇÑÂ∞çÂØ¶ÈöõÊáâÁî®‰∏≠ÊäÄË°ìÁöÑÈÅ∏ÊìáÊèê‰æõ‰∫ÜÊòéÁ¢∫ÁöÑÂª∫Ë≠∞„ÄÇÈÄèÈÅéÊè≠Á§∫ÈÄô‰∫õÈóúÈçµÊäÄË°ìÁöÑÁõ∏‰∫í‰æùË≥¥ÊÄßÔºåÈÄôÈ†ÖÂ∑•‰ΩúÊòØÂÖãÊúçÂÆâÂÖ®ÈóúÈçµÈ†òÂüü‰∏≠ÂØ¶ÈöõÂèØÊáâÁî® AI ÁöÑÂâ©È§òÈöúÁ§ôÁöÑÁ¨¨‰∏ÄÊ≠•„ÄÇ

##### **Predicting Treatment Adherence of Tuberculosis Patients at Scale**
2211.02943v2 by Mihir Kulkarni, Satvik Golechha, Rishi Raj, Jithin Sreedharan, Ankit Bhardwaj, Santanu Rathod, Bhavin Vadera, Jayakrishna Kurada, Sanjay Mattoo, Rajendra Joshi, Kirankumar Rade, Alpan Raval

Tuberculosis (TB), an infectious bacterial disease, is a significant cause of
death, especially in low-income countries, with an estimated ten million new
cases reported globally in $2020$. While TB is treatable, non-adherence to the
medication regimen is a significant cause of morbidity and mortality. Thus,
proactively identifying patients at risk of dropping off their medication
regimen enables corrective measures to mitigate adverse outcomes. Using a proxy
measure of extreme non-adherence and a dataset of nearly $700,000$ patients
from four states in India, we formulate and solve the machine learning (ML)
problem of early prediction of non-adherence based on a custom rank-based
metric. We train ML models and evaluate against baselines, achieving a $\sim
100\%$ lift over rule-based baselines and $\sim 214\%$ over a random
classifier, taking into account country-wide large-scale future deployment. We
deal with various issues in the process, including data quality,
high-cardinality categorical data, low target prevalence, distribution shift,
variation across cohorts, algorithmic fairness, and the need for robustness and
explainability. Our findings indicate that risk stratification of non-adherent
patients is a viable, deployable-at-scale ML solution. As the official AI
partner of India's Central TB Division, we are working on multiple city and
state-level pilots with the goal of pan-India deployment.

ÊëòË¶ÅÔºöËÇ∫ÁµêÊ†∏ÔºàTBÔºâÔºå‰∏ÄÁ®ÆÂÇ≥ÊüìÊÄßÁ¥∞ËèåÁñæÁóÖÔºåÊòØÈÄ†ÊàêÊ≠ª‰∫°ÁöÑÈáçË¶ÅÂéüÂõ†ÔºåÁâπÂà•ÊòØÂú®‰ΩéÊî∂ÂÖ•ÂúãÂÆ∂ÔºåÊìö‰º∞Ë®àÂú® 2020 Âπ¥ÂÖ®ÁêÉÈÄöÂ†±‰∫Ü‰∏ÄÂçÉËê¨‰æãÊñ∞ÁóÖ‰æã„ÄÇÈõñÁÑ∂ËÇ∫ÁµêÊ†∏ÊòØÂèØ‰ª•Ê≤ªÁôÇÁöÑÔºå‰ΩÜÊú™ÈÅµÂæ™Ëó•Áâ©Ê≤ªÁôÇË®àÁï´ÊòØÈÄ†ÊàêÁôºÁóÖÁéáÂíåÊ≠ª‰∫°ÁéáÁöÑÈáçË¶ÅÂéüÂõ†„ÄÇÂõ†Ê≠§Ôºå‰∏ªÂãïÊâæÂá∫Êúâ‰∏≠Êñ∑Ëó•Áâ©Ê≤ªÁôÇË®àÁï´È¢®Èö™ÁöÑÊÇ£ËÄÖÔºåËÉΩÊé°ÂèñÁüØÊ≠£Êé™ÊñΩ‰æÜÊ∏õËºï‰∏çËâØÂæåÊûú„ÄÇÂà©Áî®Ê•µÁ´ØÊú™ÈÅµÂæ™Ê≤ªÁôÇË®àÁï´ÁöÑ‰ª£ÁêÜË°°ÈáèÊåáÊ®ôÔºå‰ª•Âèä‰æÜËá™Âç∞Â∫¶ÂõõÂÄãÈÇ¶Ëøë 700,000 ÂêçÊÇ£ËÄÖÁöÑË≥áÊñôÈõÜÔºåÊàëÂÄëÂà∂ÂÆö‰∏¶Ëß£Ê±∫‰∫ÜÊ©üÂô®Â≠∏Áøí (ML) ÂïèÈ°åÔºåÊ†πÊìöËá™Ë®ÇÁöÑÂü∫ÊñºÊéíÂêçÊåáÊ®ôÔºåÊèêÊó©È†êÊ∏¨Êú™ÈÅµÂæ™Ê≤ªÁôÇË®àÁï´ÁöÑÊÉÖÊ≥Å„ÄÇÊàëÂÄëË®ìÁ∑¥Ê©üÂô®Â≠∏ÁøíÊ®°Âûã‰∏¶ÈáùÂ∞çÂü∫Ê∫ñÈÄ≤Ë°åË©ï‰º∞ÔºåÂú®ËÄÉÈáèÂÖ®ÂúãË¶èÊ®°ÁöÑÊú™‰æÜÈÉ®ÁΩ≤ÂæåÔºåÈÅîÂà∞‰∫ÜÊØîÂü∫ÊñºË¶èÂâáÁöÑÂü∫Ê∫ñÈ´òÂá∫Á¥Ñ 100%ÔºåÊØîÈö®Ê©üÂàÜÈ°ûÂô®È´òÂá∫Á¥Ñ 214% ÁöÑÊèêÂçá„ÄÇÊàëÂÄëÂú®ÈÅéÁ®ã‰∏≠ËôïÁêÜ‰∫ÜÂêÑÁ®ÆÂïèÈ°åÔºåÂåÖÊã¨Ë≥áÊñôÂìÅË≥™„ÄÅÈ´òÂü∫Êï∏ÂàÜÈ°ûË≥áÊñô„ÄÅ‰ΩéÁõÆÊ®ôÊµÅË°åÁéá„ÄÅÂàÜ‰ΩàËΩâÁßª„ÄÅ‰∏çÂêåÁæ§ÁµÑÈñìÁöÑÂ∑ÆÁï∞„ÄÅÊºîÁÆóÊ≥ïÂÖ¨Âπ≥ÊÄßÔºå‰ª•ÂèäÂ∞çÁ©©ÂÅ•ÊÄßÂíåÂèØËß£ÈáãÊÄßÁöÑÈúÄÊ±Ç„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúË°®ÊòéÔºåÈùûÈÅµÂæ™Ê≤ªÁôÇË®àÁï´ÊÇ£ËÄÖÁöÑÈ¢®Èö™ÂàÜÂ±§ÊòØ‰∏ÄÁ®ÆÂèØË°åÁöÑ„ÄÅÂèØÂ§ßË¶èÊ®°ÈÉ®ÁΩ≤ÁöÑÊ©üÂô®Â≠∏ÁøíËß£Ê±∫ÊñπÊ°à„ÄÇ‰ΩúÁÇ∫Âç∞Â∫¶‰∏≠Â§ÆËÇ∫ÁµêÊ†∏ÈÉ®ÈñÄÁöÑÂÆòÊñπ‰∫∫Â∑•Êô∫ÊÖßÂêà‰ΩúÂ§•‰º¥ÔºåÊàëÂÄëÊ≠£Âú®ËàáÂ§öÂÄãÂüéÂ∏ÇÂíåÈÇ¶Á¥öË©¶ÈªûÂêà‰ΩúÔºåÁõÆÊ®ôÊòØÂÖ®Âç∞Â∫¶ÈÉ®ÁΩ≤„ÄÇ

##### **Explainable AI over the Internet of Things (IoT): Overview, State-of-the-Art and Future Directions**
2211.01036v2 by Senthil Kumar Jagatheesaperumal, Quoc-Viet Pham, Rukhsana Ruby, Zhaohui Yang, Chunmei Xu, Zhaoyang Zhang

Explainable Artificial Intelligence (XAI) is transforming the field of
Artificial Intelligence (AI) by enhancing the trust of end-users in machines.
As the number of connected devices keeps on growing, the Internet of Things
(IoT) market needs to be trustworthy for the end-users. However, existing
literature still lacks a systematic and comprehensive survey work on the use of
XAI for IoT. To bridge this lacking, in this paper, we address the XAI
frameworks with a focus on their characteristics and support for IoT. We
illustrate the widely-used XAI services for IoT applications, such as security
enhancement, Internet of Medical Things (IoMT), Industrial IoT (IIoT), and
Internet of City Things (IoCT). We also suggest the implementation choice of
XAI models over IoT systems in these applications with appropriate examples and
summarize the key inferences for future works. Moreover, we present the
cutting-edge development in edge XAI structures and the support of
sixth-generation (6G) communication services for IoT applications, along with
key inferences. In a nutshell, this paper constitutes the first holistic
compilation on the development of XAI-based frameworks tailored for the demands
of future IoT use cases.

ÊëòË¶ÅÔºöÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖß (XAI) ÈÄèÈÅéÊèêÂçáÁµÇÁ´Ø‰ΩøÁî®ËÄÖÂ∞çÊ©üÂô®‰ø°‰ªªÂ∫¶ÔºåËΩâËÆä‰∫Ü‰∫∫Â∑•Êô∫ÊÖß (AI) È†òÂüü„ÄÇÈö®ËëóÈÄ£Á∂≤Ë£ùÁΩÆÊï∏ÈáèÊåÅÁ∫åÂ¢ûÂä†ÔºåÁâ©ËÅØÁ∂≤ (IoT) Â∏ÇÂ†¥ÈúÄË¶ÅËÆìÁµÇÁ´Ø‰ΩøÁî®ËÄÖ‰ø°Ë≥¥„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÊñáÁçª‰ªçÁº∫‰πèÂ∞çÊñº XAI Áî®ÊñºÁâ©ËÅØÁ∂≤ÁöÑÁ≥ªÁµ±ÊÄß‰∏îÂÖ®Èù¢ÁöÑË™øÊü•Â∑•‰Ωú„ÄÇÁÇ∫‰∫ÜÂΩåË£úÈÄôÂÄã‰∏çË∂≥‰πãËôïÔºåÊàëÂÄëÂú®ÈÄôÁØáË´ñÊñá‰∏≠Êé¢Ë®é XAI Êû∂ÊßãÔºåÈáçÈªûÂú®ÊñºÂÖ∂ÁâπÊÄßÂíåÂ∞çÁâ©ËÅØÁ∂≤ÁöÑÊîØÊè¥„ÄÇÊàëÂÄëË™™ÊòéÂª£Ê≥õ‰ΩøÁî®ÁöÑ XAI ÊúçÂãôÔºåÁî®ÊñºÁâ©ËÅØÁ∂≤ÊáâÁî®Ôºå‰æãÂ¶ÇÂÆâÂÖ®ÊÄßÂº∑Âåñ„ÄÅÈÜ´ÁôÇÁâ©ËÅØÁ∂≤ (IoMT)„ÄÅÂ∑•Ê•≠Áâ©ËÅØÁ∂≤ (IIoT) ÂíåÂüéÂ∏ÇÁâ©ËÅØÁ∂≤ (IoCT)„ÄÇÊàëÂÄë‰πüÂª∫Ë≠∞Âú®ÈÄô‰∫õÊáâÁî®‰∏≠ÔºåÈÄèÈÅéÈÅ©Áï∂ÁöÑÁØÑ‰æãÂú®Áâ©ËÅØÁ∂≤Á≥ªÁµ±‰∏äÂØ¶‰Ωú XAI Ê®°ÂûãÁöÑÈÅ∏ÊìáÔºå‰∏¶Á∏ΩÁµêÊú™‰æÜÂ∑•‰ΩúÁöÑÈóúÈçµÊé®Ë´ñ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèêÂá∫ÈÇäÁ∑£ XAI Êû∂ÊßãÁöÑÂ∞ñÁ´ØÁôºÂ±ïÔºå‰ª•ÂèäÂ∞çÁâ©ËÅØÁ∂≤ÊáâÁî®Á¨¨ÂÖ≠‰ª£ (6G) ÈÄöË®äÊúçÂãôÁöÑÊîØÊè¥ÔºåÈÄ£ÂêåÈóúÈçµÊé®Ë´ñ„ÄÇÁ∞°ËÄåË®Ä‰πãÔºåÈÄôÁØáË´ñÊñáÊßãÊàêÁ¨¨‰∏ÄÂÄãÈáùÂ∞ç XAI Âü∫Á§éÊû∂ÊßãÁôºÂ±ïÁöÑÊï¥È´îÂΩôÁ∑®ÔºåÂ∞àÈñÄÈáùÂ∞çÊú™‰æÜÁâ©ËÅØÁ∂≤‰ΩøÁî®Ê°à‰æãÁöÑÈúÄÊ±Ç„ÄÇ

##### **Human-centered XAI for Burn Depth Characterization**
2210.13535v2 by Maxwell J. Jacobson, Daniela Chanci Arrubla, Maria Romeo Tricas, Gayle Gordillo, Yexiang Xue, Chandan Sen, Juan Wachs

Approximately 1.25 million people in the United States are treated each year
for burn injuries. Precise burn injury classification is an important aspect of
the medical AI field. In this work, we propose an explainable human-in-the-loop
framework for improving burn ultrasound classification models. Our framework
leverages an explanation system based on the LIME classification explainer to
corroborate and integrate a burn expert's knowledge -- suggesting new features
and ensuring the validity of the model. Using this framework, we discover that
B-mode ultrasound classifiers can be enhanced by supplying textural features.
More specifically, we confirm that texture features based on the Gray Level
Co-occurance Matrix (GLCM) of ultrasound frames can increase the accuracy of
transfer learned burn depth classifiers. We test our hypothesis on real data
from porcine subjects. We show improvements in the accuracy of burn depth
classification -- from ~88% to ~94% -- once modified according to our
framework.

ÊëòË¶ÅÔºöÁæéÂúãÊØèÂπ¥Á¥ÑÊúâ 125 Ëê¨‰∫∫Êé•ÂèóÁáíÂÇ∑Ê≤ªÁôÇ„ÄÇÊ∫ñÁ¢∫ÁöÑÁáíÂÇ∑ÂàÜÈ°ûÊòØÈÜ´ÁôÇ AI È†òÂüüÁöÑÈáçË¶ÅÈù¢Âêë„ÄÇÂú®Ê≠§Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÂèØËß£ÈáãÁöÑËø¥Âúà‰∏≠ÁöÑ‰∫∫È°ûÊ°ÜÊû∂ÔºåÁî®ÊñºÊîπÂñÑÁáíÂÇ∑Ë∂ÖÈü≥Ê≥¢ÂàÜÈ°ûÊ®°Âûã„ÄÇÊàëÂÄëÁöÑÊ°ÜÊû∂Âà©Áî®Âü∫Êñº LIME ÂàÜÈ°ûËß£ÈáãÂô®ÁöÑËß£ÈáãÁ≥ªÁµ±Ôºå‰æÜÈ©óË≠âÂíåÊï¥ÂêàÁáíÂÇ∑Â∞àÂÆ∂ÁöÑÁü•Ë≠òÔºåÂª∫Ë≠∞Êñ∞ÁöÑÁâπÂæµ‰∏¶Á¢∫‰øùÊ®°ÂûãÁöÑÊúâÊïàÊÄß„ÄÇ‰ΩøÁî®Ê≠§Ê°ÜÊû∂ÔºåÊàëÂÄëÁôºÁèæ B ÂûãË∂ÖÈü≥Ê≥¢ÂàÜÈ°ûÂô®ÂèØÈÄèÈÅéÊèê‰æõÁ¥ãÁêÜÁâπÂæµ‰æÜÂ¢ûÂº∑„ÄÇÊõ¥ÂÖ∑È´îÂú∞Ë™™ÔºåÊàëÂÄëÁ¢∫Ë™çÂü∫ÊñºË∂ÖÈü≥Ê≥¢ÂΩ±ÂÉèÁöÑÁÅ∞ÈöéÂÖ±ÁîüÁü©Èô£ (GLCM) ÁöÑÁ¥ãÁêÜÁâπÂæµÔºåÂèØ‰ª•ÊèêÈ´òËΩâÁßªÂ≠∏ÁøíÁöÑÁáíÂÇ∑Ê∑±Â∫¶ÂàÜÈ°ûÂô®ÁöÑÊ∫ñÁ¢∫ÊÄß„ÄÇÊàëÂÄëÂú®Ë±¨ÈöªÂèóË©¶ËÄÖÁöÑÁúüÂØ¶Ë≥áÊñô‰∏äÊ∏¨Ë©¶ÊàëÂÄëÁöÑÂÅáË®≠„ÄÇÊàëÂÄëÈ°ØÁ§∫Âá∫Âú®Ê†πÊìöÊàëÂÄëÁöÑÊ°ÜÊû∂‰øÆÊîπÂæåÔºåÁáíÂÇ∑Ê∑±Â∫¶ÂàÜÈ°ûÁöÑÊ∫ñÁ¢∫ÊÄßÊúâÊâÄÊèêÂçáÔºåÂæûÁ¥Ñ 88% ÊèêÂçáËá≥Á¥Ñ 94%„ÄÇ

##### **What Do End-Users Really Want? Investigation of Human-Centered XAI for Mobile Health Apps**
2210.03506v1 by Katharina Weitz, Alexander Zellner, Elisabeth Andr√©

In healthcare, AI systems support clinicians and patients in diagnosis,
treatment, and monitoring, but many systems' poor explainability remains
challenging for practical application. Overcoming this barrier is the goal of
explainable AI (XAI). However, an explanation can be perceived differently and,
thus, not solve the black-box problem for everyone. The domain of
Human-Centered AI deals with this problem by adapting AI to users. We present a
user-centered persona concept to evaluate XAI and use it to investigate
end-users preferences for various explanation styles and contents in a mobile
health stress monitoring application. The results of our online survey show
that users' demographics and personality, as well as the type of explanation,
impact explanation preferences, indicating that these are essential features
for XAI design. We subsumed the results in three prototypical user personas:
power-, casual-, and privacy-oriented users. Our insights bring an interactive,
human-centered XAI closer to practical application.

ÊëòË¶ÅÔºöÂú®ÈÜ´ÁôÇ‰øùÂÅ•È†òÂüüÔºåAI Á≥ªÁµ±ÊîØÊè¥Ëá®Â∫äÈÜ´ÁîüÂíåÊÇ£ËÄÖÈÄ≤Ë°åË®∫Êñ∑„ÄÅÊ≤ªÁôÇÂíåÁõ£ÊéßÔºå‰ΩÜË®±Â§öÁ≥ªÁµ±ÁöÑËß£ÈáãÊÄß‰∏çË∂≥ÔºåÂ∞çÂØ¶ÈöõÊáâÁî®‰ªçÊßãÊàêÊåëÊà∞„ÄÇÂÖãÊúçÊ≠§ÈöúÁ§ôÊòØÂèØËß£Èáã AI (XAI) ÁöÑÁõÆÊ®ô„ÄÇÁÑ∂ËÄåÔºåÊØèÂÄã‰∫∫Â∞çÊñºËß£ÈáãÁöÑÁêÜËß£ÂèØËÉΩ‰∏çÂêåÔºåÂõ†Ê≠§ÁÑ°Ê≥ïÁÇ∫ÊâÄÊúâ‰∫∫Ëß£Ê±∫ÈªëÁÆ±ÂïèÈ°å„ÄÇ‰ª•‰∫∫ÁÇ∫‰∏≠ÂøÉÁöÑ AI È†òÂüüÈÄèÈÅéË™øÊï¥ AI ‰ª•ÈÅ©Êáâ‰ΩøÁî®ËÄÖ‰æÜËôïÁêÜÊ≠§ÂïèÈ°å„ÄÇÊàëÂÄëÊèêÂá∫‰ª•‰ΩøÁî®ËÄÖÁÇ∫‰∏≠ÂøÉÁöÑËßíËâ≤Ê¶ÇÂøµ‰æÜË©ï‰º∞ XAIÔºå‰∏¶‰ΩøÁî®ÂÆÉ‰æÜË™øÊü•Ë°åÂãïÂÅ•Â∫∑Â£ìÂäõÁõ£ÊéßÊáâÁî®Á®ãÂºè‰∏≠ÔºåÁµÇÁ´Ø‰ΩøÁî®ËÄÖÂ∞çÊñºÂêÑÁ®ÆËß£ÈáãÈ¢®Ê†ºÂíåÂÖßÂÆπÁöÑÂÅèÂ•Ω„ÄÇÊàëÂÄëÁöÑÁ∑ö‰∏äË™øÊü•ÁµêÊûúÈ°ØÁ§∫Ôºå‰ΩøÁî®ËÄÖÁöÑÂÄã‰∫∫Ë≥áÊñôÂíå‰∫∫Ê†ºÁâπË≥™Ôºå‰ª•ÂèäËß£ÈáãÈ°ûÂûãÔºåÊúÉÂΩ±ÈüøËß£ÈáãÂÅèÂ•ΩÔºåÈÄôË°®Á§∫ÈÄô‰∫õÊòØ XAI Ë®≠Ë®àÁöÑÂü∫Êú¨ÁâπÂæµ„ÄÇÊàëÂÄëÂ∞áÁµêÊûúÊ≠∏Á¥çÁÇ∫‰∏âÁ®ÆÂéüÂûã‰ΩøÁî®ËÄÖËßíËâ≤ÔºöÈáçË¶ñÊ¨äÂäõ„ÄÅ‰ºëÈñíÂíåÈö±ÁßÅÁöÑ‰ΩøÁî®ËÄÖ„ÄÇÊàëÂÄëÁöÑË¶ãËß£ËÆì‰∫íÂãïÂºè„ÄÅ‰ª•‰∫∫ÁÇ∫‰∏≠ÂøÉÁöÑ XAI Êõ¥Êé•ËøëÂØ¶ÈöõÊáâÁî®„ÄÇ

##### **Explainable AI based Glaucoma Detection using Transfer Learning and LIME**
2210.03332v1 by Touhidul Islam Chayan, Anita Islam, Eftykhar Rahman, Md. Tanzim Reza, Tasnim Sakib Apon, MD. Golam Rabiul Alam

Glaucoma is the second driving reason for partial or complete blindness among
all the visual deficiencies which mainly occurs because of excessive pressure
in the eye due to anxiety or depression which damages the optic nerve and
creates complications in vision. Traditional glaucoma screening is a
time-consuming process that necessitates the medical professionals' constant
attention, and even so time to time due to the time constrains and pressure
they fail to classify correctly that leads to wrong treatment. Numerous efforts
have been made to automate the entire glaucoma classification procedure
however, these existing models in general have a black box characteristics that
prevents users from understanding the key reasons behind the prediction and
thus medical practitioners generally can not rely on these system. In this
article after comparing with various pre-trained models, we propose a transfer
learning model that is able to classify Glaucoma with 94.71\% accuracy. In
addition, we have utilized Local Interpretable Model-Agnostic
Explanations(LIME) that introduces explainability in our system. This
improvement enables medical professionals obtain important and comprehensive
information that aid them in making judgments. It also lessen the opacity and
fragility of the traditional deep learning models.

ÊëòË¶ÅÔºöÈùíÂÖâÁúºÊòØÊâÄÊúâË¶ñÂäõÁº∫Èô∑‰∏≠Â∞éËá¥ÈÉ®ÂàÜÊàñÂÆåÂÖ®Â§±ÊòéÁöÑÁ¨¨‰∫åÂ§ßÂéüÂõ†Ôºå‰∏ªË¶ÅÊòØÁî±ÊñºÁÑ¶ÊÖÆÊàñÊÜÇÈ¨±ÁóáÂ∞éËá¥ÁúºÁùõÂ£ìÂäõÈÅéÂ§ßÔºåÊêçÂÆ≥Ë¶ñÁ•ûÁ∂ì‰∏¶ÈÄ†ÊàêË¶ñÂäõ‰ΩµÁôºÁóá„ÄÇÂÇ≥Áµ±ÁöÑÈùíÂÖâÁúºÁØ©Ê™¢ÊòØ‰∏ÄÂÄãËÄóÊôÇÁöÑÈÅéÁ®ãÔºåÈúÄË¶ÅÈÜ´ÁôÇÂ∞àÊ•≠‰∫∫Âì°ÊåÅÁ∫åÈóúÊ≥®ÔºåÂç≥‰ΩøÂ¶ÇÊ≠§ÔºåÁî±ÊñºÊôÇÈñìÈôêÂà∂ÂíåÂ£ìÂäõÔºå‰ªñÂÄëÊúâÊôÇÁÑ°Ê≥ïÊ≠£Á¢∫ÂàÜÈ°ûÔºåÂ∞éËá¥Ê≤ªÁôÇÈåØË™§„ÄÇÂ∑≤Á∂ìÂÅöÂá∫Ë®±Â§öÂä™Âäõ‰æÜËá™ÂãïÂåñÊï¥ÂÄãÈùíÂÖâÁúºÂàÜÈ°ûÁ®ãÂ∫èÔºåÁÑ∂ËÄåÔºåÈÄô‰∫õÁèæÊúâÊ®°ÂûãÈÄöÂ∏∏ÂÖ∑ÊúâÈªëÁõíÁâπÂæµÔºå‰ΩøÁî®Êà∂ÁÑ°Ê≥ïÁêÜËß£È†êÊ∏¨ËÉåÂæåÁöÑ‰∏ªË¶ÅÂéüÂõ†ÔºåÂõ†Ê≠§ÈÜ´ÁôÇÂæûÊ•≠‰∫∫Âì°ÈÄöÂ∏∏ÁÑ°Ê≥ï‰æùË≥¥ÈÄô‰∫õÁ≥ªÁµ±„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÂú®ËàáÂêÑÁ®ÆÈ†êË®ìÁ∑¥Ê®°ÂûãÊØîËºÉÂæåÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãËΩâÁßªÂ≠∏ÁøíÊ®°ÂûãÔºåËÉΩÂ§†‰ª• 94.71% ÁöÑÊ∫ñÁ¢∫ÁéáÂ∞çÈùíÂÖâÁúºÈÄ≤Ë°åÂàÜÈ°û„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂà©Áî®‰∫ÜÂ±ÄÈÉ®ÂèØËß£ÈáãÊ®°Âûã‰∏çÂèØÁü•Ëß£ÈáãÔºàLIMEÔºâÔºåÂú®ÊàëÂÄëÁöÑÁ≥ªÁµ±‰∏≠ÂºïÂÖ•‰∫ÜÂèØËß£ÈáãÊÄß„ÄÇÈÄôÈ†ÖÊîπÈÄ≤‰ΩøÈÜ´ÁôÇÂ∞àÊ•≠‰∫∫Âì°ËÉΩÂ§†Áç≤ÂæóÈáçË¶Å‰∏îÂÖ®Èù¢ÁöÑË≥áË®äÔºåÂπ´Âä©‰ªñÂÄëÂÅöÂá∫Âà§Êñ∑„ÄÇÂÆÉ‰πüÈôç‰Ωé‰∫ÜÂÇ≥Áµ±Ê∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÁöÑ‰∏çÈÄèÊòéÊÄßÂíåËÑÜÂº±ÊÄß„ÄÇ

##### **Evaluation of importance estimators in deep learning classifiers for Computed Tomography**
2209.15398v1 by Lennart Brocki, Wistan Marchadour, Jonas Maison, Bogdan Badic, Panagiotis Papadimitroulas, Mathieu Hatt, Franck Vermet, Neo Christopher Chung

Deep learning has shown superb performance in detecting objects and
classifying images, ensuring a great promise for analyzing medical imaging.
Translating the success of deep learning to medical imaging, in which doctors
need to understand the underlying process, requires the capability to interpret
and explain the prediction of neural networks. Interpretability of deep neural
networks often relies on estimating the importance of input features (e.g.,
pixels) with respect to the outcome (e.g., class probability). However, a
number of importance estimators (also known as saliency maps) have been
developed and it is unclear which ones are more relevant for medical imaging
applications. In the present work, we investigated the performance of several
importance estimators in explaining the classification of computed tomography
(CT) images by a convolutional deep network, using three distinct evaluation
metrics. First, the model-centric fidelity measures a decrease in the model
accuracy when certain inputs are perturbed. Second, concordance between
importance scores and the expert-defined segmentation masks is measured on a
pixel level by a receiver operating characteristic (ROC) curves. Third, we
measure a region-wise overlap between a XRAI-based map and the segmentation
mask by Dice Similarity Coefficients (DSC). Overall, two versions of SmoothGrad
topped the fidelity and ROC rankings, whereas both Integrated Gradients and
SmoothGrad excelled in DSC evaluation. Interestingly, there was a critical
discrepancy between model-centric (fidelity) and human-centric (ROC and DSC)
evaluation. Expert expectation and intuition embedded in segmentation maps does
not necessarily align with how the model arrived at its prediction.
Understanding this difference in interpretability would help harnessing the
power of deep learning in medicine.

ÊëòË¶ÅÔºöÊ∑±Â∫¶Â≠∏ÁøíÂú®ÂÅµÊ∏¨Áâ©‰ª∂ÂíåÂàÜÈ°ûÂΩ±ÂÉèÊñπÈù¢Â±ïÁèæÂá∫ÂçìË∂äÁöÑË°®ÁèæÔºåÁ¢∫‰øù‰∫ÜÂàÜÊûêÈÜ´Â≠∏ÂΩ±ÂÉèÁöÑÂ∑®Â§ßÂâçÊôØ„ÄÇ
Â∞áÊ∑±Â∫¶Â≠∏ÁøíÁöÑÊàêÂäüËΩâÂåñÁÇ∫ÈÜ´Â≠∏ÂΩ±ÂÉèÔºåÂÖ∂‰∏≠ÈÜ´ÁîüÈúÄË¶Å‰∫ÜËß£ÂÖ∂ËÉåÂæåÈÅéÁ®ãÔºåÈÄôÈúÄË¶ÅËß£ÈáãÂíåË™™ÊòéÁ•ûÁ∂ìÁ∂≤Ë∑ØÁöÑÈ†êÊ∏¨„ÄÇÊ∑±Â∫¶Á•ûÁ∂ìÁ∂≤Ë∑ØÁöÑÂèØËß£ÈáãÊÄßÈÄöÂ∏∏‰æùË≥¥Êñº‰º∞Ë®àËº∏ÂÖ•ÁâπÂæµÔºà‰æãÂ¶ÇÔºåÂÉèÁ¥†ÔºâÁõ∏Â∞çÊñºÁµêÊûúÔºà‰æãÂ¶ÇÔºåÈ°ûÂà•Ê©üÁéáÔºâÁöÑÈáçË¶ÅÊÄß„ÄÇÁÑ∂ËÄåÔºåÂ∑≤Á∂ìÈñãÁôºÂá∫Ë®±Â§öÈáçË¶ÅÊÄß‰º∞Ë®àÂô®Ôºà‰πüÁ®±ÁÇ∫È°ØËëóÊÄßÂúñÔºâÔºå‰ΩÜÁõÆÂâçÂ∞ö‰∏çÊ∏ÖÊ•öÂì™‰∫õÂ∞çÊñºÈÜ´Â≠∏ÂΩ±ÂÉèÊáâÁî®Êõ¥ÁÇ∫Áõ∏Èóú„ÄÇÂú®ÁõÆÂâçÁöÑÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄë‰ΩøÁî®‰∏âÂÄã‰∏çÂêåÁöÑË©ï‰º∞ÊåáÊ®ôÔºåÁ†îÁ©∂‰∫ÜÂπæÂÄãÈáçË¶ÅÊÄß‰º∞Ë®àÂô®Âú®Ëß£ÈáãÂç∑Á©çÊ∑±Â∫¶Á∂≤Ë∑ØÂàÜÈ°ûÈõªËÖ¶Êñ∑Â±§ÊéÉÊèè (CT) ÂΩ±ÂÉèÊôÇÁöÑË°®Áèæ„ÄÇÈ¶ñÂÖàÔºå‰ª•Ê®°ÂûãÁÇ∫‰∏≠ÂøÉÁöÑ‰øùÁúüÂ∫¶Ê∏¨ÈáèÂú®Êüê‰∫õËº∏ÂÖ•ÂèóÂà∞ÊìæÂãïÊôÇÊ®°ÂûãÁ≤æÁ¢∫Â∫¶ÁöÑÈôç‰Ωé„ÄÇÂÖ∂Ê¨°ÔºåÂú®ÂÉèÁ¥†Â±§Á¥ö‰∏äÔºå‰ΩøÁî®ÂèóË©¶ËÄÖÊìç‰ΩúÁâπÂæµ (ROC) Êõ≤Á∑öÊ∏¨ÈáèÈáçË¶ÅÊÄßÂàÜÊï∏ÂíåÂ∞àÂÆ∂ÂÆöÁæ©ÁöÑÂàÜÂâ≤ÈÅÆÁΩ©‰πãÈñìÁöÑ‰∏ÄËá¥ÊÄß„ÄÇÁ¨¨‰∏âÔºåÊàëÂÄëÈÄèÈÅé Dice Áõ∏‰ºº‰øÇÊï∏ (DSC) Ê∏¨ÈáèÂü∫Êñº XRAI ÁöÑÂú∞ÂúñÂíåÂàÜÂâ≤ÈÅÆÁΩ©‰πãÈñìÁöÑÂçÄÂüüÈáçÁñä„ÄÇÊï¥È´îËÄåË®ÄÔºåÂÖ©ÂÄãÁâàÊú¨ÁöÑ SmoothGrad Âú®‰øùÁúüÂ∫¶Âíå ROC ÊéíÂêç‰∏≠ÂêçÂàóÂâçËåÖÔºåËÄåÁ©çÂàÜÊ¢ØÂ∫¶Âíå SmoothGrad Âú® DSC Ë©ï‰º∞‰∏≠Ë°®ÁèæÂÑ™Áï∞„ÄÇÊúâË∂£ÁöÑÊòØÔºå‰ª•Ê®°ÂûãÁÇ∫‰∏≠ÂøÉÔºà‰øùÁúüÂ∫¶ÔºâÂíå‰ª•‰∫∫ÁÇ∫‰∏≠ÂøÉÔºàROC Âíå DSCÔºâÁöÑË©ï‰º∞‰πãÈñìÂ≠òÂú®ËëóÂö¥ÈáçÁöÑÂ∑ÆÁï∞„ÄÇÂàÜÂâ≤Âú∞Âúñ‰∏≠ÂµåÂÖ•ÁöÑÂ∞àÂÆ∂ÊúüÊúõÂíåÁõ¥Ë¶∫‰∏ç‰∏ÄÂÆöËàáÊ®°ÂûãÂæóÂá∫È†êÊ∏¨ÁöÑÊñπÂºè‰∏ÄËá¥„ÄÇ‰∫ÜËß£ÂèØËß£ÈáãÊÄß‰∏≠ÁöÑÈÄôÁ®ÆÂ∑ÆÁï∞Â∞áÊúâÂä©ÊñºÂà©Áî®Ê∑±Â∫¶Â≠∏ÁøíÂú®ÈÜ´Â≠∏‰∏≠ÁöÑÂäõÈáè„ÄÇ

##### **An Interactive Interpretability System for Breast Cancer Screening with Deep Learning**
2210.08979v1 by Yuzhe Lu, Adam Perer

Deep learning methods, in particular convolutional neural networks, have
emerged as a powerful tool in medical image computing tasks. While these
complex models provide excellent performance, their black-box nature may hinder
real-world adoption in high-stakes decision-making. In this paper, we propose
an interactive system to take advantage of state-of-the-art interpretability
techniques to assist radiologists with breast cancer screening. Our system
integrates a deep learning model into the radiologists' workflow and provides
novel interactions to promote understanding of the model's decision-making
process. Moreover, we demonstrate that our system can take advantage of user
interactions progressively to provide finer-grained explainability reports with
little labeling overhead. Due to the generic nature of the adopted
interpretability technique, our system is domain-agnostic and can be used for
many different medical image computing tasks, presenting a novel perspective on
how we can leverage visual analytics to transform originally static
interpretability techniques to augment human decision making and promote the
adoption of medical AI.

ÊëòË¶ÅÔºöÊ∑±Â∫¶Â≠∏ÁøíÊñπÊ≥ïÔºåÂ∞§ÂÖ∂ÊòØÂç∑Á©çÁ•ûÁ∂ìÁ∂≤Ë∑ØÔºåÂ∑≤ÊàêÁÇ∫ÈÜ´Â≠∏ÂΩ±ÂÉèÈÅãÁÆó‰ªªÂãô‰∏≠Âº∑Â§ßÁöÑÂ∑•ÂÖ∑„ÄÇÂÑòÁÆ°ÈÄô‰∫õË§áÈõúÁöÑÊ®°ÂûãÊèê‰æõ‰∫ÜÂÑ™Áï∞ÁöÑÊïàËÉΩÔºå‰ΩÜÂÆÉÂÄëÁöÑÈªëÁÆ±Êú¨Ë≥™ÂèØËÉΩÊúÉÈòªÁ§ôÂú®È´òÈ¢®Èö™Ê±∫Á≠ñ‰∏≠Êé°Áî®ÊñºÁèæÂØ¶‰∏ñÁïå„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄã‰∫íÂãïÁ≥ªÁµ±Ôºå‰ª•Âà©Áî®ÊúÄÂÖàÈÄ≤ÁöÑÂèØËß£ÈáãÊÄßÊäÄË°ìÔºåÂçîÂä©ÊîæÂ∞ÑÁßëÈÜ´Â∏´ÈÄ≤Ë°å‰π≥ÁôåÁØ©Ê™¢„ÄÇÊàëÂÄëÁöÑÁ≥ªÁµ±Â∞áÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÊï¥ÂêàÂà∞ÊîæÂ∞ÑÁßëÈÜ´Â∏´ÁöÑÂ∑•‰ΩúÊµÅÁ®ã‰∏≠Ôºå‰∏¶Êèê‰æõÊñ∞Á©éÁöÑ‰∫íÂãïÊñπÂºèÔºå‰ª•‰øÉÈÄ≤Â∞çÊ®°ÂûãÊ±∫Á≠ñÈÅéÁ®ãÁöÑÁêÜËß£„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëË≠âÊòéÊàëÂÄëÁöÑÁ≥ªÁµ±ÂèØ‰ª•ÈÄêÊ≠•Âà©Áî®‰ΩøÁî®ËÄÖ‰∫íÂãïÔºå‰ª•Êèê‰æõÊõ¥Á¥∞Á∑ªÁöÑÂèØËß£ÈáãÊÄßÂ†±ÂëäÔºåËÄåÊ®ôË®òÈñãÈä∑ÂæàÂ∞è„ÄÇÁî±ÊñºÊâÄÊé°Áî®ÁöÑÂèØËß£ÈáãÊÄßÊäÄË°ìÁöÑÈÄöÁî®ÊÄßË≥™ÔºåÊàëÂÄëÁöÑÁ≥ªÁµ±ËàáÈ†òÂüüÁÑ°ÈóúÔºåÂèØÁî®ÊñºË®±Â§ö‰∏çÂêåÁöÑÈÜ´Â≠∏ÂΩ±ÂÉèÈÅãÁÆó‰ªªÂãôÔºåÊèê‰æõ‰∫Ü‰∏ÄÂÄãÊñ∞Á©éÁöÑËßÄÈªûÔºåË™™ÊòéÊàëÂÄëÂ¶Ç‰ΩïÂà©Áî®Ë¶ñË¶∫ÂàÜÊûêÂ∞áÂéüÊú¨ÈùúÊÖãÁöÑÂèØËß£ÈáãÊÄßÊäÄË°ìËΩâËÆäÁÇ∫Êì¥Â¢û‰∫∫È°ûÊ±∫Á≠ñÂà∂ÂÆöÂíå‰øÉÈÄ≤Êé°Áî®ÈÜ´ÁôÇ AI„ÄÇ

##### **Explainable AI for clinical and remote health applications: a survey on tabular and time series data**
2209.06528v1 by Flavio Di Martino, Franca Delmastro

Nowadays Artificial Intelligence (AI) has become a fundamental component of
healthcare applications, both clinical and remote, but the best performing AI
systems are often too complex to be self-explaining. Explainable AI (XAI)
techniques are defined to unveil the reasoning behind the system's predictions
and decisions, and they become even more critical when dealing with sensitive
and personal health data. It is worth noting that XAI has not gathered the same
attention across different research areas and data types, especially in
healthcare. In particular, many clinical and remote health applications are
based on tabular and time series data, respectively, and XAI is not commonly
analysed on these data types, while computer vision and Natural Language
Processing (NLP) are the reference applications. To provide an overview of XAI
methods that are most suitable for tabular and time series data in the
healthcare domain, this paper provides a review of the literature in the last 5
years, illustrating the type of generated explanations and the efforts provided
to evaluate their relevance and quality. Specifically, we identify clinical
validation, consistency assessment, objective and standardised quality
evaluation, and human-centered quality assessment as key features to ensure
effective explanations for the end users. Finally, we highlight the main
research challenges in the field as well as the limitations of existing XAI
methods.

ÊëòË¶ÅÔºöÁèæ‰ªäÔºå‰∫∫Â∑•Êô∫ÊÖß (AI) Â∑≤ÊàêÁÇ∫ÈÜ´ÁôÇ‰øùÂÅ•ÊáâÁî®Á®ãÂºè‰∏≠‰∏çÂèØÊàñÁº∫ÁöÑÁµÑÊàêÈÉ®ÂàÜÔºåÁÑ°Ë´ñÊòØËá®Â∫äÊàñÈÅ†Ë∑ùÈÜ´ÁôÇÔºå‰ΩÜÊïàËÉΩÊúÄ‰Ω≥ÁöÑ AI Á≥ªÁµ±ÈÄöÂ∏∏ÈÅéÊñºË§áÈõúÔºåÁÑ°Ê≥ïËá™Ë°åËß£Èáã„ÄÇÂèØËß£Èáã AI (XAI) ÊäÄË°ìË¢´ÂÆöÁæ©ÁÇ∫Êè≠Á§∫Á≥ªÁµ±È†êÊ∏¨ÂíåÊ±∫Á≠ñËÉåÂæåÁöÑÊé®ÁêÜÔºåÁï∂ËôïÁêÜÊïèÊÑü‰∏îÂÄã‰∫∫ÁöÑÂÅ•Â∫∑Ë≥áÊñôÊôÇÔºåÂÆÉÂÄëËÆäÂæóÊõ¥ÁÇ∫ÈóúÈçµ„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåXAI ‰∏¶Êú™Âú®‰∏çÂêåÁöÑÁ†îÁ©∂È†òÂüüÂíåË≥áÊñôÈ°ûÂûã‰∏≠Áç≤ÂæóÁõ∏ÂêåÁöÑÈóúÊ≥®ÔºåÁâπÂà•ÊòØÂú®ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠„ÄÇÁâπÂà•ÊòØÔºåË®±Â§öËá®Â∫äÂíåÈÅ†Ë∑ùÈÜ´ÁôÇÊáâÁî®Á®ãÂºèÂàÜÂà•Âü∫ÊñºË°®Ê†ºÂíåÊôÇÈñìÂ∫èÂàóË≥áÊñôÔºåËÄå XAI ‰∏¶Êú™ÈáùÂ∞çÈÄô‰∫õË≥áÊñôÈ°ûÂûãÈÄ≤Ë°åÂàÜÊûêÔºåËÄåÈõªËÖ¶Ë¶ñË¶∫ÂíåËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ (NLP) ÂâáÁÇ∫ÂèÉËÄÉÊáâÁî®Á®ãÂºè„ÄÇÁÇ∫‰∫ÜÊèê‰æõÊúÄÈÅ©ÂêàÈÜ´ÁôÇ‰øùÂÅ•È†òÂüü‰∏≠Ë°®Ê†ºÂíåÊôÇÈñìÂ∫èÂàóË≥áÊñôÁöÑ XAI ÊñπÊ≥ïÊ¶ÇËßÄÔºåÊú¨ÊñáÂõûÈ°ß‰∫ÜÈÅéÂéª 5 Âπ¥ÁöÑÊñáÁçªÔºåË™™ÊòéÁî¢ÁîüÁöÑËß£ÈáãÈ°ûÂûã‰ª•ÂèäË©ï‰º∞ÂÖ∂Áõ∏ÈóúÊÄßÂíåÂìÅË≥™ÊâÄÂÅöÁöÑÂä™Âäõ„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÂ∞áËá®Â∫äÈ©óË≠â„ÄÅ‰∏ÄËá¥ÊÄßË©ï‰º∞„ÄÅÂÆ¢ËßÄ‰∏îÊ®ôÊ∫ñÂåñÁöÑÂìÅË≥™Ë©ï‰º∞‰ª•Âèä‰ª•‰∫∫ÁÇ∫‰∏≠ÂøÉÁöÑÂìÅË≥™Ë©ï‰º∞Á¢∫ÂÆöÁÇ∫Á¢∫‰øùÂ∞çÊúÄÁµÇ‰ΩøÁî®ËÄÖÊèê‰æõÊúâÊïàËß£ÈáãÁöÑ‰∏ªË¶ÅÁâπÂæµ„ÄÇÊúÄÂæåÔºåÊàëÂÄëÂº∑Ë™ø‰∫ÜË©≤È†òÂüüÁöÑ‰∏ªË¶ÅÁ†îÁ©∂ÊåëÊà∞‰ª•ÂèäÁèæÊúâ XAI ÊñπÊ≥ïÁöÑÈôêÂà∂„ÄÇ


### Knowledge Graphs
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-05-31**|**Joint Embeddings for Graph Instruction Tuning**|Vlad Argatu et.al.|[2405.20684v1](http://arxiv.org/abs/2405.20684v1)|null|
|**2024-05-30**|**KerasCV and KerasNLP: Vision and Language Power-Ups**|Matthew Watson et.al.|[2405.20247v2](http://arxiv.org/abs/2405.20247v2)|null|
|**2024-05-30**|**Grokfast: Accelerated Grokking by Amplifying Slow Gradients**|Jaerin Lee et.al.|[2405.20233v1](http://arxiv.org/abs/2405.20233v1)|[link](https://github.com/ironjr/grokfast)|
|**2024-05-30**|**Reasoning about concepts with LLMs: Inconsistencies abound**|Rosario Uceda-Sosa et.al.|[2405.20163v1](http://arxiv.org/abs/2405.20163v1)|null|
|**2024-05-30**|**GNN-RAG: Graph Neural Retrieval for Large Language Model Reasoning**|Costas Mavromatis et.al.|[2405.20139v1](http://arxiv.org/abs/2405.20139v1)|null|
|**2024-05-30**|**MM-Lego: Modular Biomedical Multimodal Models with Minimal Fine-Tuning**|Konstantin Hemker et.al.|[2405.19950v1](http://arxiv.org/abs/2405.19950v1)|null|
|**2024-05-30**|**KNOW: A Real-World Ontology for Knowledge Capture with Large Language Models**|Arto Bendiken et.al.|[2405.19877v1](http://arxiv.org/abs/2405.19877v1)|null|
|**2024-05-30**|**Unsupervised Mutual Learning of Dialogue Discourse Parsing and Topic Segmentation**|Jiahui Xu et.al.|[2405.19799v2](http://arxiv.org/abs/2405.19799v2)|[link](https://github.com/jeff-sue/urt)|
|**2024-05-30**|**Dataflow-Guided Retrieval Augmentation for Repository-Level Code Completion**|Wei Cheng et.al.|[2405.19782v1](http://arxiv.org/abs/2405.19782v1)|[link](https://github.com/nju-websoft/DraCo)|
|**2024-05-30**|**Knowledge Graph Tuning: Real-time Large Language Model Personalization based on Human Feedback**|Jingwei Sun et.al.|[2405.19686v1](http://arxiv.org/abs/2405.19686v1)|null|
|**2024-05-29**|**MASSIVE Multilingual Abstract Meaning Representation: A Dataset and Baselines for Hallucination Detection**|Michael Regan et.al.|[2405.19285v1](http://arxiv.org/abs/2405.19285v1)|null|
|**2024-05-29**|**PediatricsGPT: Large Language Models as Chinese Medical Assistants for Pediatric Applications**|Dingkang Yang et.al.|[2405.19266v2](http://arxiv.org/abs/2405.19266v2)|null|
|**2024-05-29**|**Towards Next-Generation Urban Decision Support Systems through AI-Powered Generation of Scientific Ontology using Large Language Models -- A Case in Optimizing Intermodal Freight Transportation**|Jose Tupayachi et.al.|[2405.19255v1](http://arxiv.org/abs/2405.19255v1)|null|
|**2024-05-29**|**Learning from Litigation: Graphs and LLMs for Retrieval and Reasoning in eDiscovery**|Sounak Lahiri et.al.|[2405.19164v1](http://arxiv.org/abs/2405.19164v1)|null|
|**2024-05-28**|**Unleashing the Potential of Text-attributed Graphs: Automatic Relation Decomposition via Large Language Models**|Hyunjin Seo et.al.|[2405.18581v1](http://arxiv.org/abs/2405.18581v1)|null|
|**2024-05-28**|**Don't Forget to Connect! Improving RAG with Graph-based Reranking**|Jialin Dong et.al.|[2405.18414v1](http://arxiv.org/abs/2405.18414v1)|null|
|**2024-05-28**|**Knowledge Circuits in Pretrained Transformers**|Yunzhi Yao et.al.|[2405.17969v1](http://arxiv.org/abs/2405.17969v1)|[link](https://github.com/zjunlp/knowledgecircuits)|
|**2024-05-28**|**Safety Control of Service Robots with LLMs and Embodied Knowledge Graphs**|Yong Qi et.al.|[2405.17846v1](http://arxiv.org/abs/2405.17846v1)|null|
|**2024-05-27**|**Cost-efficient Knowledge-based Question Answering with Large Language Models**|Junnan Dong et.al.|[2405.17337v1](http://arxiv.org/abs/2405.17337v1)|null|
|**2024-05-27**|**Assessing LLMs Suitability for Knowledge Graph Completion**|Vasile Ionut Remus Iga et.al.|[2405.17249v1](http://arxiv.org/abs/2405.17249v1)|[link](https://github.com/ionutiga/llms-for-kgc)|
|**2024-05-27**|**Empowering Large Language Models to Set up a Knowledge Retrieval Indexer via Self-Learning**|Xun Liang et.al.|[2405.16933v1](http://arxiv.org/abs/2405.16933v1)|[link](https://github.com/iaar-shanghai/pgrag)|
|**2024-05-27**|**Entity Alignment with Noisy Annotations from Large Language Models**|Shengyuan Chen et.al.|[2405.16806v2](http://arxiv.org/abs/2405.16806v2)|[link](https://github.com/chensycn/llm4ea_official)|
|**2024-05-27**|**TAGA: Text-Attributed Graph Self-Supervised Learning by Synergizing Graph and Text Mutual Transformations**|Zheng Zhang et.al.|[2405.16800v1](http://arxiv.org/abs/2405.16800v1)|null|
|**2024-05-26**|**KG-FIT: Knowledge Graph Fine-Tuning Upon Open-World Knowledge**|Pengcheng Jiang et.al.|[2405.16412v1](http://arxiv.org/abs/2405.16412v1)|[link](https://github.com/pat-jj/KG-FIT)|
|**2024-05-26**|**Intruding with Words: Towards Understanding Graph Injection Attacks at the Text Level**|Runlin Lei et.al.|[2405.16405v1](http://arxiv.org/abs/2405.16405v1)|null|
|**2024-05-25**|**COLT: Towards Completeness-Oriented Tool Retrieval for Large Language Models**|Changle Qu et.al.|[2405.16089v1](http://arxiv.org/abs/2405.16089v1)|null|
|**2024-05-24**|**Large Language Models Reflect Human Citation Patterns with a Heightened Citation Bias**|Andres Algaba et.al.|[2405.15739v2](http://arxiv.org/abs/2405.15739v2)|[link](https://github.com/andresalgaba/llm_citation_patterns)|
|**2024-05-24**|**Leveraging Large Language Models for Semantic Query Processing in a Scholarly Knowledge Graph**|Runsong Jia et.al.|[2405.15374v1](http://arxiv.org/abs/2405.15374v1)|null|
|**2024-05-24**|**Intelligent Go-Explore: Standing on the Shoulders of Giant Foundation Models**|Cong Lu et.al.|[2405.15143v2](http://arxiv.org/abs/2405.15143v2)|[link](https://github.com/conglu1997/intelligent-go-explore)|
|**2024-05-23**|**HippoRAG: Neurobiologically Inspired Long-Term Memory for Large Language Models**|Bernal Jim√©nez Guti√©rrez et.al.|[2405.14831v1](http://arxiv.org/abs/2405.14831v1)|[link](https://github.com/osu-nlp-group/hipporag)|
|**2024-05-23**|**Fisher Flow Matching for Generative Modeling over Discrete Data**|Oscar Davis et.al.|[2405.14664v3](http://arxiv.org/abs/2405.14664v3)|null|
|**2024-05-23**|**GLaD: Synergizing Molecular Graphs and Language Descriptors for Enhanced Power Conversion Efficiency Prediction in Organic Photovoltaic Devices**|Thao Nguyen et.al.|[2405.14203v1](http://arxiv.org/abs/2405.14203v1)|null|
|**2024-05-23**|**Large Language Models-guided Dynamic Adaptation for Temporal Knowledge Graph Reasoning**|Jiapu Wang et.al.|[2405.14170v1](http://arxiv.org/abs/2405.14170v1)|null|
|**2024-05-22**|**Prompt-Time Ontology-Driven Symbolic Knowledge Capture with Large Language Models**|Tolga √á√∂pl√º et.al.|[2405.14012v1](http://arxiv.org/abs/2405.14012v1)|[link](https://github.com/haltiaai/paper-ptodskc)|
|**2024-05-22**|**LOGIN: A Large Language Model Consulted Graph Neural Network Training Framework**|Yiran Qiao et.al.|[2405.13902v1](http://arxiv.org/abs/2405.13902v1)|[link](https://github.com/qiaoyran/login)|
|**2024-05-22**|**FiDeLiS: Faithful Reasoning in Large Language Model for Knowledge Graph Question Answering**|Yuan Sui et.al.|[2405.13873v1](http://arxiv.org/abs/2405.13873v1)|null|
|**2024-05-22**|**Large Language Models are Effective Priors for Causal Graph Discovery**|Victor-Alexandru Darvariu et.al.|[2405.13551v1](http://arxiv.org/abs/2405.13551v1)|null|
|**2024-05-22**|**TrojanRAG: Retrieval-Augmented Generation Can Be Backdoor Driver in Large Language Models**|Pengzhou Cheng et.al.|[2405.13401v3](http://arxiv.org/abs/2405.13401v3)|null|
|**2024-05-21**|**Retrieval-Augmented Language Model for Extreme Multi-Label Knowledge Graph Link Prediction**|Yu-Hsiang Lin et.al.|[2405.12656v1](http://arxiv.org/abs/2405.12656v1)|[link](https://github.com/exiled1143/retrieval-augmented-language-model-for-multi-label-knowledge-graph-link-prediction)|
|**2024-05-21**|**Learning Structure and Knowledge Aware Representation with Large Language Models for Concept Recommendation**|Qingyao Li et.al.|[2405.12442v1](http://arxiv.org/abs/2405.12442v1)|null|
|**2024-05-20**|**KG-RAG: Bridging the Gap Between Knowledge and Creativity**|Diego Sanmartin et.al.|[2405.12035v1](http://arxiv.org/abs/2405.12035v1)|null|
|**2024-05-20**|**"Set It Up!": Functional Object Arrangement with Compositional Generative Models**|Yiqing Xu et.al.|[2405.11928v1](http://arxiv.org/abs/2405.11928v1)|null|
|**2024-05-20**|**Increasing the LLM Accuracy for Question Answering: Ontologies to the Rescue!**|Dean Allemang et.al.|[2405.11706v1](http://arxiv.org/abs/2405.11706v1)|null|
|**2024-05-17**|**Empowering Small-Scale Knowledge Graphs: A Strategy of Leveraging General-Purpose Knowledge Graphs for Enriched Embeddings**|Albert Sawczyn et.al.|[2405.10745v1](http://arxiv.org/abs/2405.10745v1)|null|
|**2024-05-17**|**Automatic News Generation and Fact-Checking System Based on Language Processing**|Xirui Peng et.al.|[2405.10492v2](http://arxiv.org/abs/2405.10492v2)|null|
|**2024-05-16**|**4D Panoptic Scene Graph Generation**|Jingkang Yang et.al.|[2405.10305v1](http://arxiv.org/abs/2405.10305v1)|[link](https://github.com/jingkang50/psg4d)|
|**2024-05-16**|**Timeline-based Sentence Decomposition with In-Context Learning for Temporal Fact Extraction**|Jianhao Chen et.al.|[2405.10288v2](http://arxiv.org/abs/2405.10288v2)|null|
|**2024-05-15**|**SCI 3.0: A Web-based Schema Curation Interface for Graphical Event Representations**|Reece Suchocki et.al.|[2405.09733v2](http://arxiv.org/abs/2405.09733v2)|null|
|**2024-05-15**|**SOK-Bench: A Situated Video Reasoning Benchmark with Aligned Open-World Knowledge**|Andong Wang et.al.|[2405.09713v2](http://arxiv.org/abs/2405.09713v2)|null|
|**2024-05-15**|**STAR: A Benchmark for Situated Reasoning in Real-World Videos**|Bo Wu et.al.|[2405.09711v1](http://arxiv.org/abs/2405.09711v1)|null|
|**2024-05-14**|**Falcon 7b for Software Mention Detection in Scholarly Documents**|AmeerAli Khan et.al.|[2405.08514v1](http://arxiv.org/abs/2405.08514v1)|null|
|**2024-05-14**|**Could Chemical LLMs benefit from Message Passing**|Jiaqing Xie et.al.|[2405.08334v1](http://arxiv.org/abs/2405.08334v1)|null|
|**2024-05-13**|**AnomalyLLM: Few-shot Anomaly Edge Detection for Dynamic Graphs using Large Language Models**|Shuo Liu et.al.|[2405.07626v1](http://arxiv.org/abs/2405.07626v1)|[link](https://github.com/anomalyllm/anomalyllm)|
|**2024-05-13**|**DynLLM: When Large Language Models Meet Dynamic Graph Recommendation**|Ziwei Zhao et.al.|[2405.07580v1](http://arxiv.org/abs/2405.07580v1)|null|
|**2024-05-10**|**LLM-Generated Black-box Explanations Can Be Adversarially Helpful**|Rohan Ajwani et.al.|[2405.06800v2](http://arxiv.org/abs/2405.06800v2)|[link](https://github.com/ziningzhu/adversarial_helpfulness)|
|**2024-05-10**|**A Survey of Large Language Models for Graphs**|Xubin Ren et.al.|[2405.08011v1](http://arxiv.org/abs/2405.08011v1)|[link](https://github.com/hkuds/awesome-llm4graph-papers)|
|**2024-05-10**|**Multimodal LLMs Struggle with Basic Visual Network Analysis: a VNA Benchmark**|Evan M. Williams et.al.|[2405.06634v1](http://arxiv.org/abs/2405.06634v1)|[link](https://github.com/evanup/vna_benchmark)|
|**2024-05-10**|**Mitigating Hallucinations in Large Language Models via Self-Refinement-Enhanced Knowledge Retrieval**|Mengjia Niu et.al.|[2405.06545v1](http://arxiv.org/abs/2405.06545v1)|null|
|**2024-05-10**|**Prompting Large Language Models with Knowledge Graphs for Question Answering Involving Long-tail Facts**|Wenyu Huang et.al.|[2405.06524v1](http://arxiv.org/abs/2405.06524v1)|null|
|**2024-05-09**|**RoboHop: Segment-based Topological Map Representation for Open-World Visual Navigation**|Sourav Garg et.al.|[2405.05792v1](http://arxiv.org/abs/2405.05792v1)|null|
|**2024-05-09**|**G-SAP: Graph-based Structure-Aware Prompt Learning over Heterogeneous Knowledge for Commonsense Reasoning**|Ruiting Dai et.al.|[2405.05616v1](http://arxiv.org/abs/2405.05616v1)|null|
|**2024-05-08**|**MIDGARD: Self-Consistency Using Minimum Description Length for Structured Commonsense Reasoning**|Inderjeet Nair et.al.|[2405.05189v2](http://arxiv.org/abs/2405.05189v2)|null|
|**2024-05-08**|**Lightweight Spatial Modeling for Combinatorial Information Extraction From Documents**|Yanfei Dong et.al.|[2405.06701v1](http://arxiv.org/abs/2405.06701v1)|null|
|**2024-05-08**|**DALK: Dynamic Co-Augmentation of LLMs and KG to answer Alzheimer's Disease Questions with Scientific Literature**|Dawei Li et.al.|[2405.04819v2](http://arxiv.org/abs/2405.04819v2)|[link](https://github.com/david-li0406/dalk)|
|**2024-05-08**|**BiasKG: Adversarial Knowledge Graphs to Induce Bias in Large Language Models**|Chu Fei Luo et.al.|[2405.04756v1](http://arxiv.org/abs/2405.04756v1)|[link](https://github.com/VectorInstitute/biaskg)|
|**2024-05-08**|**AttacKG+:Boosting Attack Knowledge Graph Construction with Large Language Models**|Yongheng Zhang et.al.|[2405.04753v1](http://arxiv.org/abs/2405.04753v1)|null|
|**2024-05-07**|**Enriched BERT Embeddings for Scholarly Publication Classification**|Benjamin Wolff et.al.|[2405.04136v1](http://arxiv.org/abs/2405.04136v1)|[link](https://github.com/foerstner-lab/nslp2024-forc)|
|**2024-05-06**|**FOKE: A Personalized and Explainable Education Framework Integrating Foundation Models, Knowledge Graphs, and Prompt Engineering**|Silan Hu et.al.|[2405.03734v1](http://arxiv.org/abs/2405.03734v1)|null|
|**2024-05-05**|**E-TSL: A Continuous Educational Turkish Sign Language Dataset with Baseline Methods**|≈û√ºkr√º √ñzt√ºrk et.al.|[2405.02984v1](http://arxiv.org/abs/2405.02984v1)|null|
|**2024-05-04**|**Relations Prediction for Knowledge Graph Completion using Large Language Models**|Sakher Khalil Alqaaidi et.al.|[2405.02738v1](http://arxiv.org/abs/2405.02738v1)|null|
|**2024-05-04**|**IQLS: Framework for leveraging Metadata to enable Large Language Model based queries to complex, versatile Data**|Sami Azirar et.al.|[2405.15792v1](http://arxiv.org/abs/2405.15792v1)|null|
|**2024-05-04**|**R4: Reinforced Retriever-Reorder-Responder for Retrieval-Augmented Large Language Models**|Taolin Zhang et.al.|[2405.02659v1](http://arxiv.org/abs/2405.02659v1)|null|
|**2024-05-03**|**Evaluating Large Language Models for Structured Science Summarization in the Open Research Knowledge Graph**|Vladyslav Nechakhin et.al.|[2405.02105v1](http://arxiv.org/abs/2405.02105v1)|null|
|**2024-05-03**|**Protein binding affinity prediction under multiple substitutions applying eGNNs on Residue and Atomic graphs combined with Language model information: eGRAL**|Arturo Fiorellini-Bernardis et.al.|[2405.02374v1](http://arxiv.org/abs/2405.02374v1)|null|
|**2024-05-03**|**CodeGRAG: Extracting Composed Syntax Graphs for Retrieval Augmented Cross-Lingual Code Generation**|Kounianhua Du et.al.|[2405.02355v1](http://arxiv.org/abs/2405.02355v1)|null|
|**2024-05-02**|**ALCM: Autonomous LLM-Augmented Causal Discovery Framework**|Elahe Khatibi et.al.|[2405.01744v1](http://arxiv.org/abs/2405.01744v1)|null|
|**2024-05-02**|**Improving Complex Reasoning over Knowledge Graph with Logic-Aware Curriculum Tuning**|Tianle Xia et.al.|[2405.01649v3](http://arxiv.org/abs/2405.01649v3)|null|
|**2024-05-02**|**Identification of Entailment and Contradiction Relations between Natural Language Sentences: A Neurosymbolic Approach**|Xuyao Feng et.al.|[2405.01259v1](http://arxiv.org/abs/2405.01259v1)|null|
|**2024-05-01**|**RAG-based Explainable Prediction of Road Users Behaviors for Automated Driving using Knowledge Graphs and Large Language Models**|Mohamed Manzour Hussien et.al.|[2405.00449v1](http://arxiv.org/abs/2405.00449v1)|null|
|**2024-04-30**|**Graph Neural Network Approach to Semantic Type Detection in Tables**|Ehsan Hoseinzade et.al.|[2405.00123v1](http://arxiv.org/abs/2405.00123v1)|[link](https://github.com/hoseinzadeehsan/gait)|
|**2024-04-30**|**PrivComp-KG : Leveraging Knowledge Graph and Large Language Models for Privacy Policy Compliance Verification**|Leon Garza et.al.|[2404.19744v1](http://arxiv.org/abs/2404.19744v1)|null|
|**2024-04-30**|**A Framework for Leveraging Human Computation Gaming to Enhance Knowledge Graphs for Accuracy Critical Generative AI Applications**|Steph Buongiorno et.al.|[2404.19729v1](http://arxiv.org/abs/2404.19729v1)|null|
|**2024-04-30**|**Octopus v4: Graph of language models**|Wei Chen et.al.|[2404.19296v1](http://arxiv.org/abs/2404.19296v1)|null|
|**2024-04-30**|**Multi-hop Question Answering over Knowledge Graphs using Large Language Models**|Abir Chakraborty et.al.|[2404.19234v1](http://arxiv.org/abs/2404.19234v1)|null|
|**2024-04-29**|**Automated Construction of Theme-specific Knowledge Graphs**|Linyi Ding et.al.|[2404.19146v1](http://arxiv.org/abs/2404.19146v1)|null|
|**2024-04-29**|**QANA: LLM-based Question Generation and Network Analysis for Zero-shot Key Point Analysis and Beyond**|Tomoki Fukuma et.al.|[2404.18371v1](http://arxiv.org/abs/2404.18371v1)|null|
|**2024-04-28**|**Parameter-Efficient Tuning Large Language Models for Graph Representation Learning**|Qi Zhu et.al.|[2404.18271v1](http://arxiv.org/abs/2404.18271v1)|null|
|**2024-04-28**|**Generative AI for Visualization: State of the Art and Future Directions**|Yilin Ye et.al.|[2404.18144v1](http://arxiv.org/abs/2404.18144v1)|null|
|**2024-04-26**|**Retrieval-Augmented Generation with Knowledge Graphs for Customer Service Question Answering**|Zhentao Xu et.al.|[2404.17723v2](http://arxiv.org/abs/2404.17723v2)|null|
|**2024-04-26**|**PLAYER*: Enhancing LLM-based Multi-Agent Communication and Interaction in Murder Mystery Games**|Qinglin Zhu et.al.|[2404.17662v1](http://arxiv.org/abs/2404.17662v1)|[link](https://github.com/alickzhu/player)|
|**2024-04-26**|**Language Interaction Network for Clinical Trial Approval Estimation**|Chufan Gao et.al.|[2405.06662v1](http://arxiv.org/abs/2405.06662v1)|null|
|**2024-04-25**|**CyNetDiff -- A Python Library for Accelerated Implementation of Network Diffusion Models**|Eliot W. Robson et.al.|[2404.17059v1](http://arxiv.org/abs/2404.17059v1)|[link](https://github.com/eliotwrobson/cynetdiff)|
|**2024-04-25**|**Player-Driven Emergence in LLM-Driven Game Narrative**|Xiangyu Peng et.al.|[2404.17027v2](http://arxiv.org/abs/2404.17027v2)|null|
|**2024-04-25**|**Evaluating Class Membership Relations in Knowledge Graphs using Large Language Models**|Bradley P. Allen et.al.|[2404.17000v1](http://arxiv.org/abs/2404.17000v1)|[link](https://github.com/bradleypallen/evaluating-kg-class-memberships-using-llms)|
|**2024-04-25**|**Incorporating Lexical and Syntactic Knowledge for Unsupervised Cross-Lingual Transfer**|Jianyu Zheng et.al.|[2404.16627v1](http://arxiv.org/abs/2404.16627v1)|[link](https://github.com/tian14267/ls_mbert)|
|**2024-04-24**|**Semgrex and Ssurgeon, Searching and Manipulating Dependency Graphs**|John Bauer et.al.|[2404.16250v1](http://arxiv.org/abs/2404.16250v1)|null|
|**2024-04-24**|**Knowledge Graph Completion using Structural and Textual Embeddings**|Sakher Khalil Alqaaidi et.al.|[2404.16206v1](http://arxiv.org/abs/2404.16206v1)|[link](https://github.com/sa5r/kgrp)|
|**2024-04-24**|**Improving Multi-label Recognition using Class Co-Occurrence Probabilities**|Samyak Rawlekar et.al.|[2404.16193v1](http://arxiv.org/abs/2404.16193v1)|null|
|**2024-04-24**|**From Local to Global: A Graph RAG Approach to Query-Focused Summarization**|Darren Edge et.al.|[2404.16130v1](http://arxiv.org/abs/2404.16130v1)|null|
|**2024-04-24**|**KGValidator: A Framework for Automatic Validation of Knowledge Graph Construction**|Jack Boylan et.al.|[2404.15923v1](http://arxiv.org/abs/2404.15923v1)|null|

#### Abstracts
##### **Joint Embeddings for Graph Instruction Tuning**
2405.20684v1 by Vlad Argatu, Aaron Haag, Oliver Lohse

Large Language Models (LLMs) have achieved impressive performance in text
understanding and have become an essential tool for building smart assistants.
Originally focusing on text, they have been enhanced with multimodal
capabilities in recent works that successfully built visual instruction
following assistants. As far as the graph modality goes, however, no such
assistants have yet been developed. Graph structures are complex in that they
represent relation between different features and are permutation invariant.
Moreover, representing them in purely textual form does not always lead to good
LLM performance even for finetuned models. As a result, there is a need to
develop a new method to integrate graphs in LLMs for general graph
understanding. This work explores the integration of the graph modality in LLM
for general graph instruction following tasks. It aims at producing a deep
learning model that enhances an underlying LLM with graph embeddings and trains
it to understand them and to produce, given an instruction, an answer grounded
in the graph representation. The approach performs significantly better than a
graph to text approach and remains consistent even for larger graphs.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®ÊñáÂ≠óÁêÜËß£ÊñπÈù¢ÂèñÂæó‰ª§‰∫∫È©öËâ∑ÁöÑË°®ÁèæÔºå‰∏¶Â∑≤ÊàêÁÇ∫Âª∫ÊßãÊô∫ÊÖßÂä©ÁêÜÁöÑÂøÖË¶ÅÂ∑•ÂÖ∑„ÄÇÂéüÊú¨Â∞àÊ≥®ÊñºÊñáÂ≠óÔºåÂÆÉÂÄëÂú®ËøëÊúüÁöÑ‰ΩúÂìÅ‰∏≠Â∑≤ÈÄèÈÅéÂ§öÊ®°ÂºèÂäüËÉΩÂæóÂà∞Âä†Âº∑ÔºåÊàêÂäüÂª∫ÊßãÂá∫Ë¶ñË¶∫Êåá‰ª§ËøΩËπ§Âä©ÁêÜ„ÄÇÁÑ∂ËÄåÔºåÂ∞±ÂúñÂΩ¢Ê®°ÂºèËÄåË®ÄÔºåÁõÆÂâçÂ∞öÊú™ÈñãÁôºÂá∫Ê≠§È°ûÂä©ÁêÜ„ÄÇÂúñÂΩ¢ÁµêÊßãÂæàË§áÈõúÔºåÂú®ÊñºÂÆÉÂÄëË°®Á§∫‰∏çÂêåÁâπÂæµ‰πãÈñìÁöÑÈóú‰øÇÔºå‰∏îÂÖ∑ÊúâÊéíÂàó‰∏çËÆäÊÄß„ÄÇÊ≠§Â§ñÔºåÂç≥‰ΩøÂ∞çÊñºÂæÆË™øÊ®°ÂûãÔºåÂ∞áÂÆÉÂÄëË°®Á§∫ÊàêÁ¥îÁ≤πÁöÑÊñáÂ≠óÂΩ¢Âºè‰∏¶ÈùûÁ∏ΩÊòØËÉΩÂ∏∂‰æÜËâØÂ•ΩÁöÑ LLM ÊïàËÉΩ„ÄÇÂõ†Ê≠§ÔºåÈúÄË¶ÅÈñãÁôº‰∏ÄÁ®ÆÊñ∞ÊñπÊ≥ïÔºåÂ∞áÂúñÂΩ¢Êï¥ÂêàÂà∞ LLM ‰∏≠Ôºå‰ª•ÈÄ≤Ë°å‰∏ÄËà¨ÁöÑÂúñÂΩ¢ÁêÜËß£„ÄÇÊú¨Á†îÁ©∂Êé¢Ë®é LLM ‰∏≠ÂúñÂΩ¢Ê®°ÂºèÁöÑÊï¥ÂêàÔºå‰ª•ÈÄ≤Ë°å‰∏ÄËà¨ÁöÑÂúñÂΩ¢Êåá‰ª§ËøΩËπ§‰ªªÂãô„ÄÇÂÖ∂ÁõÆÊ®ôÊòØÁî¢Áîü‰∏ÄÂÄãÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÔºåÈÄèÈÅéÂúñÂΩ¢ÂµåÂÖ•Â¢ûÂº∑Âü∫Á§é LLMÔºå‰∏¶Ë®ìÁ∑¥ÂÆÉ‰∫ÜËß£ÂúñÂΩ¢ÂµåÂÖ•Ôºå‰∏¶Ê†πÊìöÊåá‰ª§Áî¢Áîü‰ª•ÂúñÂΩ¢Ë°®Á§∫ÁÇ∫Âü∫Á§éÁöÑÁ≠îÊ°à„ÄÇÊ≠§ÊñπÊ≥ïÁöÑË°®ÁèæÈ°ØËëóÂÑ™ÊñºÊñáÂ≠óÂà∞ÊñáÂ≠óÁöÑÊñπÊ≥ïÔºåÂç≥‰ΩøÂ∞çÊñºËºÉÂ§ßÁöÑÂúñÂΩ¢‰πüËÉΩ‰øùÊåÅ‰∏ÄËá¥ÊÄß„ÄÇ

##### **KerasCV and KerasNLP: Vision and Language Power-Ups**
2405.20247v2 by Matthew Watson, Divyashree Shivakumar Sreepathihalli, Francois Chollet, Martin Gorner, Kiranbir Sodhia, Ramesh Sampath, Tirth Patel, Haifeng Jin, Neel Kovelamudi, Gabriel Rasskin, Samaneh Saadat, Luke Wood, Chen Qian, Jonathan Bischof, Ian Stenbit, Abheesht Sharma, Anshuman Mishra

We present the Keras domain packages KerasCV and KerasNLP, extensions of the
Keras API for Computer Vision and Natural Language Processing workflows,
capable of running on either JAX, TensorFlow, or PyTorch. These domain packages
are designed to enable fast experimentation, with a focus on ease-of-use and
performance. We adopt a modular, layered design: at the library's lowest level
of abstraction, we provide building blocks for creating models and data
preprocessing pipelines, and at the library's highest level of abstraction, we
provide pretrained ``task" models for popular architectures such as Stable
Diffusion, YOLOv8, GPT2, BERT, Mistral, CLIP, Gemma, T5, etc. Task models have
built-in preprocessing, pretrained weights, and can be fine-tuned on raw
inputs. To enable efficient training, we support XLA compilation for all
models, and run all preprocessing via a compiled graph of TensorFlow operations
using the tf.data API. The libraries are fully open-source (Apache 2.0 license)
and available on GitHub.

ÊëòË¶ÅÔºöÊàëÂÄëÂ±ïÁ§∫ Keras È†òÂüüÂ•ó‰ª∂ KerasCV Âíå KerasNLPÔºåÈÄôÊòØ Keras API ÁöÑÊì¥ÂÖÖÂ•ó‰ª∂ÔºåÈÅ©Áî®ÊñºÈõªËÖ¶Ë¶ñË¶∫ÂíåËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜÂ∑•‰ΩúÊµÅÁ®ãÔºåËÉΩÂ§†Âú® JAX„ÄÅTensorFlow Êàñ PyTorch ‰∏äÂü∑Ë°å„ÄÇÈÄô‰∫õÈ†òÂüüÂ•ó‰ª∂Êó®Âú®ÊîØÊè¥Âø´ÈÄüÂØ¶È©óÔºåÈáçÈªûÂú®ÊñºÊòìÁî®ÊÄßÂíåÊïàËÉΩ„ÄÇÊàëÂÄëÊé°Áî®Ê®°ÁµÑÂåñ„ÄÅÂàÜÂ±§Ë®≠Ë®àÔºöÂú®Á®ãÂºèÂ∫´ÊúÄ‰ΩéÂ±§Á¥öÁöÑÊäΩË±°Âåñ‰∏≠ÔºåÊàëÂÄëÊèê‰æõÁî®ÊñºÂª∫Á´ãÊ®°ÂûãÂíåË≥áÊñôÈ†êËôïÁêÜÁÆ°Á∑öÁöÑÂª∫ÊßãÊ®°ÁµÑÔºåËÄåÂú®Á®ãÂºèÂ∫´ÊúÄÈ´òÂ±§Á¥öÁöÑÊäΩË±°Âåñ‰∏≠ÔºåÊàëÂÄëÊèê‰æõÁÜ±ÈñÄÊû∂ÊßãÔºà‰æãÂ¶Ç Stable Diffusion„ÄÅYOLOv8„ÄÅGPT2„ÄÅBERT„ÄÅMistral„ÄÅCLIP„ÄÅGemma„ÄÅT5 Á≠âÔºâÁöÑÈ†êÂÖàË®ìÁ∑¥„Äå‰ªªÂãô„ÄçÊ®°Âûã„ÄÇ‰ªªÂãôÊ®°ÂûãÂÖ∑ÊúâÂÖßÂª∫È†êËôïÁêÜ„ÄÅÈ†êÂÖàË®ìÁ∑¥Ê¨äÈáçÔºå‰∏îÂèØÈáùÂ∞çÂéüÂßãËº∏ÂÖ•ÈÄ≤Ë°åÂæÆË™ø„ÄÇÁÇ∫‰∫ÜÊîØÊè¥ÊúâÊïàÁéáÁöÑË®ìÁ∑¥ÔºåÊàëÂÄëÊîØÊè¥ÊâÄÊúâÊ®°ÂûãÁöÑ XLA Á∑®Ë≠ØÔºå‰∏¶ÈÄèÈÅé‰ΩøÁî® tf.data API Á∑®Ë≠ØÁöÑ TensorFlow ‰ΩúÊ•≠ÂúñË°®Âü∑Ë°åÊâÄÊúâÈ†êËôïÁêÜ„ÄÇÈÄô‰∫õÁ®ãÂºèÂ∫´ÂÆåÂÖ®ÈñãÊîæÂéüÂßãÁ¢ºÔºàApache 2.0 ÊéàÊ¨äÔºâÔºå‰∏¶Âú® GitHub ‰∏äÊèê‰æõ„ÄÇ

##### **Grokfast: Accelerated Grokking by Amplifying Slow Gradients**
2405.20233v1 by Jaerin Lee, Bong Gyun Kang, Kihoon Kim, Kyoung Mu Lee

One puzzling artifact in machine learning dubbed grokking is where delayed
generalization is achieved tenfolds of iterations after near perfect
overfitting to the training data. Focusing on the long delay itself on behalf
of machine learning practitioners, our goal is to accelerate generalization of
a model under grokking phenomenon. By regarding a series of gradients of a
parameter over training iterations as a random signal over time, we can
spectrally decompose the parameter trajectories under gradient descent into two
components: the fast-varying, overfitting-yielding component and the
slow-varying, generalization-inducing component. This analysis allows us to
accelerate the grokking phenomenon more than $\times 50$ with only a few lines
of code that amplifies the slow-varying components of gradients. The
experiments show that our algorithm applies to diverse tasks involving images,
languages, and graphs, enabling practical availability of this peculiar
artifact of sudden generalization. Our code is available at
\url{https://github.com/ironjr/grokfast}.

ÊëòË¶ÅÔºö<paragraph>Ê©üÂô®Â≠∏Áøí‰∏≠Êúâ‰∏ÄÂÄã‰ª§‰∫∫Ë≤ªËß£ÁöÑ‰∫∫Â∑•Ë£ΩÂìÅÔºåÁ®±ÁÇ∫ grokkingÔºåÂÖ∂‰∏≠Âª∂ÈÅ≤Ê≥õÂåñÊòØÂú®Â∞çË®ìÁ∑¥Ë≥áÊñôÈÅéÂ∫¶Êì¨ÂêàÊé•ËøëÂÆåÁæéÂæåÔºåÁ∂ìÈÅéÂçÅÂÄçÁöÑËø≠‰ª£ÊâçÂØ¶ÁèæÁöÑ„ÄÇÂ∞àÊ≥®ÊñºÊ©üÂô®Â≠∏ÁøíÂæûÊ•≠ËÄÖÊú¨Ë∫´ÁöÑÈï∑ÊôÇÈñìÂª∂ÈÅ≤ÔºåÊàëÂÄëÁöÑÁõÆÊ®ôÊòØÂä†ÈÄü grokking ÁèæË±°‰∏ãÁöÑÊ®°ÂûãÊ≥õÂåñ„ÄÇÈÄöÈÅéÂ∞á‰∏ÄÁ≥ªÂàóË®ìÁ∑¥Ëø≠‰ª£‰∏≠ÁöÑÂèÉÊï∏Ê¢ØÂ∫¶Ë¶ñÁÇ∫Èö®ÊôÇÈñìËÆäÂåñÁöÑÈö®Ê©ü‰ø°ËôüÔºåÊàëÂÄëÂèØ‰ª•Â∞áÊ¢ØÂ∫¶‰∏ãÈôç‰∏ãÁöÑÂèÉÊï∏ËªåË∑°ÂÖâË≠úÂàÜËß£ÁÇ∫ÂÖ©ÂÄãÁµÑÊàêÈÉ®ÂàÜÔºöËÆäÂåñÂø´„ÄÅÁî¢ÁîüÈÅéÂ∫¶Êì¨ÂêàÁöÑÁµÑÊàêÈÉ®ÂàÜÂíåËÆäÂåñÊÖ¢„ÄÅË™òÂ∞éÊ≥õÂåñÁöÑÁµÑÊàêÈÉ®ÂàÜ„ÄÇÈÄôÁ®ÆÂàÜÊûê‰ΩøÊàëÂÄëËÉΩÂ§†ÂÉÖÈÄöÈÅéÂπæË°åÊîæÂ§ßÊ¢ØÂ∫¶‰∏≠ËÆäÂåñÁ∑©ÊÖ¢ÁöÑÁµÑÊàêÈÉ®ÂàÜÁöÑ‰ª£Á¢ºÔºåÂ∞á grokking ÁèæË±°Âä†ÈÄüË∂ÖÈÅé 50 ÂÄç„ÄÇÂØ¶È©óË°®ÊòéÔºåÊàëÂÄëÁöÑÊºîÁÆóÊ≥ïÈÅ©Áî®ÊñºÊ∂âÂèäÂΩ±ÂÉè„ÄÅË™ûË®ÄÂíåÂúñÂΩ¢ÁöÑÂêÑÁ®Æ‰ªªÂãôÔºå‰ΩøÈÄôÁ®ÆÁ™ÅÁÑ∂Ê≥õÂåñÁöÑÁâπÊÆä‰∫∫Â∑•Ë£ΩÂìÅÂÖ∑ÊúâÂØ¶Áî®ÁöÑÂèØÁî®ÊÄß„ÄÇÊàëÂÄëÁöÑ‰ª£Á¢ºÂèØÂú®‰ª•‰∏ãÁ∂≤ÂùÄÂèñÂæóÔºö\url{https://github.com/ironjr/grokfast}„ÄÇ</paragraph>

##### **Reasoning about concepts with LLMs: Inconsistencies abound**
2405.20163v1 by Rosario Uceda-Sosa, Karthikeyan Natesan Ramamurthy, Maria Chang, Moninder Singh

The ability to summarize and organize knowledge into abstract concepts is key
to learning and reasoning. Many industrial applications rely on the consistent
and systematic use of concepts, especially when dealing with decision-critical
knowledge. However, we demonstrate that, when methodically questioned, large
language models (LLMs) often display and demonstrate significant
inconsistencies in their knowledge. Computationally, the basic aspects of the
conceptualization of a given domain can be represented as Is-A hierarchies in a
knowledge graph (KG) or ontology, together with a few properties or axioms that
enable straightforward reasoning. We show that even simple ontologies can be
used to reveal conceptual inconsistencies across several LLMs. We also propose
strategies that domain experts can use to evaluate and improve the coverage of
key domain concepts in LLMs of various sizes. In particular, we have been able
to significantly enhance the performance of LLMs of various sizes with openly
available weights using simple knowledge-graph (KG) based prompting strategies.

ÊëòË¶ÅÔºöÊëòË¶ÅÂíåÁµÑÁπîÁü•Ë≠òÊàêÁÇ∫ÊäΩË±°Ê¶ÇÂøµÁöÑËÉΩÂäõÊòØÂ≠∏ÁøíÂíåÊé®ÁêÜÁöÑÈóúÈçµ„ÄÇË®±Â§öÁî¢Ê•≠ÊáâÁî®‰ª∞Ë≥¥Ê¶ÇÂøµÁöÑ‰∏ÄËá¥‰∏îÁ≥ªÁµ±ÊÄß‰ΩøÁî®ÔºåÁâπÂà•ÊòØÂú®ËôïÁêÜÊ±∫Á≠ñÈóúÈçµÁü•Ë≠òÊôÇ„ÄÇÁÑ∂ËÄåÔºåÊàëÂÄëË≠âÊòéÔºåÁï∂Á∂ìÈÅéÊúâÁ≥ªÁµ±Âú∞Ë≥™ÁñëÊôÇÔºåÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Á∂ìÂ∏∏È°ØÁ§∫‰∏¶Â±ïÁ§∫ÂÖ∂Áü•Ë≠ò‰∏≠ÁöÑÈáçÂ§ß‰∏ç‰∏ÄËá¥ÊÄß„ÄÇÂú®Ë®àÁÆó‰∏äÔºåÁµ¶ÂÆöÈ†òÂüüÁöÑÊ¶ÇÂøµÂåñÁöÑÂü∫Êú¨Èù¢ÂêëÂèØ‰ª•Áî®Áü•Ë≠òÂúñË≠ú (KG) ÊàñÊú¨È´îË´ñ‰∏≠ÁöÑ Is-A ÈöéÂ±§‰æÜË°®Á§∫Ôºå‰ª•Âèä‰∏Ä‰∫õÂ±¨ÊÄßÊàñÂÖ¨ÁêÜÔºåÈÄô‰∫õÂ±¨ÊÄßÊàñÂÖ¨ÁêÜËÉΩÈÄ≤Ë°åÁõ¥Êé•Êé®ÁêÜ„ÄÇÊàëÂÄëË≠âÊòéÔºåÂç≥‰ΩøÊòØÁ∞°ÂñÆÁöÑÊú¨È´îË´ñ‰πüËÉΩÁî®‰æÜÊè≠Èú≤Ë∑®Â§öÂÄã LLM ÁöÑÊ¶ÇÂøµ‰∏ç‰∏ÄËá¥ÊÄß„ÄÇÊàëÂÄë‰πüÊèêÂá∫È†òÂüüÂ∞àÂÆ∂ÂèØ‰ª•Áî®‰æÜË©ï‰º∞ÂíåÊîπÂñÑÂêÑÁ®ÆË¶èÊ®° LLM ‰∏≠ÈóúÈçµÈ†òÂüüÊ¶ÇÂøµÊ∂µËìãÁØÑÂúçÁöÑÁ≠ñÁï•„ÄÇÁâπÂà•ÊòØÔºåÊàëÂÄëÂ∑≤Á∂ìËÉΩÂ§†‰ΩøÁî®Âü∫ÊñºÁ∞°ÂñÆÁü•Ë≠òÂúñË≠ú (KG) ÁöÑÊèêÁ§∫Á≠ñÁï•ÔºåÂ§ßÂπÖÊèêÂçáÂêÑÁ®ÆË¶èÊ®° LLM ÁöÑÊÄßËÉΩÔºåÈÄô‰∫õ LLM ‰ΩøÁî®ÈñãÊîæÂèØÁî®ÁöÑÊ¨äÈáç„ÄÇ

##### **GNN-RAG: Graph Neural Retrieval for Large Language Model Reasoning**
2405.20139v1 by Costas Mavromatis, George Karypis

Knowledge Graphs (KGs) represent human-crafted factual knowledge in the form
of triplets (head, relation, tail), which collectively form a graph. Question
Answering over KGs (KGQA) is the task of answering natural questions grounding
the reasoning to the information provided by the KG. Large Language Models
(LLMs) are the state-of-the-art models for QA tasks due to their remarkable
ability to understand natural language. On the other hand, Graph Neural
Networks (GNNs) have been widely used for KGQA as they can handle the complex
graph information stored in the KG. In this work, we introduce GNN-RAG, a novel
method for combining language understanding abilities of LLMs with the
reasoning abilities of GNNs in a retrieval-augmented generation (RAG) style.
First, a GNN reasons over a dense KG subgraph to retrieve answer candidates for
a given question. Second, the shortest paths in the KG that connect question
entities and answer candidates are extracted to represent KG reasoning paths.
The extracted paths are verbalized and given as input for LLM reasoning with
RAG. In our GNN-RAG framework, the GNN acts as a dense subgraph reasoner to
extract useful graph information, while the LLM leverages its natural language
processing ability for ultimate KGQA. Furthermore, we develop a retrieval
augmentation (RA) technique to further boost KGQA performance with GNN-RAG.
Experimental results show that GNN-RAG achieves state-of-the-art performance in
two widely used KGQA benchmarks (WebQSP and CWQ), outperforming or matching
GPT-4 performance with a 7B tuned LLM. In addition, GNN-RAG excels on multi-hop
and multi-entity questions outperforming competing approaches by 8.9--15.5%
points at answer F1.

ÊëòË¶ÅÔºö<paragraph>Áü•Ë≠òÂúñË≠ú (KG) ‰ª•‰∏âÂÖÉÁµÑ (‰∏ªË©û„ÄÅÈóú‰øÇ„ÄÅË≥ìË©û) ÁöÑÂΩ¢ÂºèË°®Á§∫‰∫∫Â∑•Âª∫Á´ãÁöÑ‰∫ãÂØ¶Áü•Ë≠òÔºåÈÄô‰∫õ‰∏âÂÖÉÁµÑÂÖ±ÂêåÂΩ¢Êàê‰∏ÄÂÄãÂúñÂΩ¢„ÄÇÂú® KG ‰∏äÈÄ≤Ë°åÂïèÁ≠î (KGQA) ÊòØÂõûÁ≠îËá™ÁÑ∂ÂïèÈ°åÁöÑ‰ªªÂãôÔºåÂ∞áÊé®ÁêÜÂü∫Á§éÂª∫Á´ãÂú® KG Êèê‰æõÁöÑË≥áË®ä‰∏ä„ÄÇÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Áî±ÊñºÂÖ∂ÁêÜËß£Ëá™ÁÑ∂Ë™ûË®ÄÁöÑÈùûÂá°ËÉΩÂäõÔºåÊàêÁÇ∫ÂïèÁ≠î‰ªªÂãôÁöÑÊúÄÊñ∞ÊäÄË°ì„ÄÇÂè¶‰∏ÄÊñπÈù¢ÔºåÂúñÂΩ¢Á•ûÁ∂ìÁ∂≤Ë∑Ø (GNN) Â∑≤Âª£Ê≥õÁî®Êñº KGQAÔºåÂõ†ÁÇ∫ÂÆÉÂÄëÂèØ‰ª•ËôïÁêÜÂÑ≤Â≠òÂú® KG ‰∏≠ÁöÑË§áÈõúÂúñÂΩ¢Ë≥áË®ä„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫Ü GNN-RAGÔºåÈÄôÊòØ‰∏ÄÁ®ÆÊñ∞ÊñπÊ≥ïÔºåÁµêÂêà‰∫Ü LLM ÁöÑË™ûË®ÄÁêÜËß£ËÉΩÂäõÂíå GNN ÁöÑÊé®ÁêÜËÉΩÂäõÔºåÊé°Áî®Ê™¢Á¥¢Â¢ûÂº∑ÁîüÊàê (RAG) ÁöÑÊñπÂºè„ÄÇÈ¶ñÂÖàÔºåGNN Âú®‰∏ÄÂÄãÂØÜÈõÜÁöÑ KG Â≠êÂúñ‰∏≠ÈÄ≤Ë°åÊé®ÁêÜÔºå‰ª•Ê™¢Á¥¢Áµ¶ÂÆöÂïèÈ°åÁöÑÁ≠îÊ°àÂÄôÈÅ∏„ÄÇÂÖ∂Ê¨°ÔºåÊèêÂèñ KG ‰∏≠ÈÄ£Êé•ÂïèÈ°åÂØ¶È´îÂíåÁ≠îÊ°àÂÄôÈÅ∏ÁöÑÊúÄÁü≠Ë∑ØÂæëÔºå‰ª•Ë°®Á§∫ KG Êé®ÁêÜË∑ØÂæë„ÄÇÊèêÂèñÁöÑË∑ØÂæëÊúÉË¢´Âè£È†≠ÂåñÔºå‰∏¶‰ΩúÁÇ∫Ëº∏ÂÖ•Êèê‰æõÁµ¶ LLMÔºå‰ª•‰æø‰ΩøÁî® RAG ÈÄ≤Ë°åÊé®ÁêÜ„ÄÇÂú®ÊàëÂÄëÁöÑ GNN-RAG Ê°ÜÊû∂‰∏≠ÔºåGNN ‰ΩúÁÇ∫‰∏ÄÂÄãÂØÜÈõÜÂ≠êÂúñÊé®ÁêÜÂô®ÔºåÁî®ÊñºÊèêÂèñÊúâÁî®ÁöÑÂúñÂΩ¢Ë≥áË®äÔºåËÄå LLM ÂâáÂà©Áî®ÂÖ∂Ëá™ÁÑ∂Ë™ûË®ÄËôïÁêÜËÉΩÂäõÈÄ≤Ë°åÊúÄÁµÇÁöÑ KGQA„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÈñãÁôº‰∫Ü‰∏ÄÁ®ÆÊ™¢Á¥¢Â¢ûÂº∑ (RA) ÊäÄË°ìÔºå‰ª•ÈÄ≤‰∏ÄÊ≠•ÊèêÂçá GNN-RAG ÁöÑ KGQA ÊïàËÉΩ„ÄÇÂØ¶È©óÁµêÊûúÈ°ØÁ§∫ÔºåGNN-RAG Âú®ÂÖ©ÂÄãÂª£Ê≥õ‰ΩøÁî®ÁöÑ KGQA Âü∫Ê∫ñ (WebQSP Âíå CWQ) ‰∏≠ÈÅîÂà∞‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÊïàËÉΩÔºåÂú®‰ΩøÁî® 7B Ë™øÊï¥ÂæåÁöÑ LLM ‰∏≠Ë∂ÖË∂äÊàñÂåπÈÖç GPT-4 ÁöÑÊïàËÉΩ„ÄÇÊ≠§Â§ñÔºåGNN-RAG Âú®Â§öË∑≥ÂíåÂ§öÂØ¶È´îÂïèÈ°å‰∏äË°®ÁèæÂá∫Ëâ≤ÔºåÂú®Á≠îÊ°à F1 ‰∏äÊØîÁ´∂Áà≠ÊñπÊ≥ïÈ´òÂá∫ 8.9--15.5%„ÄÇ</paragraph>

##### **MM-Lego: Modular Biomedical Multimodal Models with Minimal Fine-Tuning**
2405.19950v1 by Konstantin Hemker, Nikola Simidjievski, Mateja Jamnik

Learning holistic computational representations in physical, chemical or
biological systems requires the ability to process information from different
distributions and modalities within the same model. Thus, the demand for
multimodal machine learning models has sharply risen for modalities that go
beyond vision and language, such as sequences, graphs, time series, or tabular
data. While there are many available multimodal fusion and alignment
approaches, most of them require end-to-end training, scale quadratically with
the number of modalities, cannot handle cases of high modality imbalance in the
training set, or are highly topology-specific, making them too restrictive for
many biomedical learning tasks. This paper presents Multimodal Lego (MM-Lego),
a modular and general-purpose fusion and model merging framework to turn any
set of encoders into a competitive multimodal model with no or minimal
fine-tuning. We achieve this by introducing a wrapper for unimodal encoders
that enforces lightweight dimensionality assumptions between modalities and
harmonises their representations by learning features in the frequency domain
to enable model merging with little signal interference. We show that MM-Lego
1) can be used as a model merging method which achieves competitive performance
with end-to-end fusion models without any fine-tuning, 2) can operate on any
unimodal encoder, and 3) is a model fusion method that, with minimal
fine-tuning, achieves state-of-the-art results on six benchmarked multimodal
biomedical tasks.

ÊëòË¶ÅÔºöÂú®Áâ©ÁêÜ„ÄÅÂåñÂ≠∏ÊàñÁîüÁâ©Á≥ªÁµ±‰∏≠Â≠∏ÁøíÊï¥È´îË®àÁÆóË°®Á§∫Ê≥ïÈúÄË¶ÅËôïÁêÜ‰æÜËá™Âêå‰∏ÄÊ®°Âûã‰∏≠‰∏çÂêåÂàÜ‰ΩàÂíåÊ®°ÂºèÁöÑË≥áË®äÁöÑËÉΩÂäõ„ÄÇÂõ†Ê≠§ÔºåÂ∞çÊñºË∂ÖË∂äË¶ñË¶∫ÂíåË™ûË®ÄÁöÑÂ§öÊ®°ÊÖãÊ©üÂô®Â≠∏ÁøíÊ®°ÂûãÁöÑÈúÄÊ±ÇÊÄ•Âäá‰∏äÂçáÔºå‰æãÂ¶ÇÂ∫èÂàó„ÄÅÂúñÂΩ¢„ÄÅÊôÇÈñìÂ∫èÂàóÊàñË°®Ê†ºË≥áÊñô„ÄÇÂÑòÁÆ°ÊúâË®±Â§öÂèØÁî®ÁöÑÂ§öÊ®°ÊÖãËûçÂêàÂíåÂ∞çÈΩäÊñπÊ≥ïÔºå‰ΩÜÂÆÉÂÄëÂ§ßÂ§öÈúÄË¶ÅÁ´ØÂà∞Á´ØË®ìÁ∑¥„ÄÅÈö®ËëóÊ®°ÊÖãÊï∏ÈáèÁöÑÂ¢ûÂä†ËÄåÂëà‰∫åÊ¨°ÊñπÊì¥ÂÖÖ„ÄÅÁÑ°Ê≥ïËôïÁêÜË®ìÁ∑¥ÈõÜ‰∏≠È´òÊ®°ÊÖã‰∏çÂπ≥Ë°°ÁöÑÊÉÖÊ≥ÅÔºåÊàñÂÖ∑ÊúâÈ´òÂ∫¶ÊãìÊí≤ÁâπÂÆöÊÄßÔºåÈÄô‰ΩøÂæóÂÆÉÂÄëÂ∞çÊñºË®±Â§öÁîüÁâ©ÈÜ´Â≠∏Â≠∏Áøí‰ªªÂãô‰æÜË™™ÈÅéÊñºÂö¥Ê†º„ÄÇÊú¨ÊñáÊèêÂá∫‰∫ÜÂ§öÊ®°ÊÖãÊ®ÇÈ´òÔºàMM-LegoÔºâÔºåÈÄôÊòØ‰∏ÄÂÄãÊ®°ÁµÑÂåñ‰∏îÈÄöÁî®ÁöÑËûçÂêàÂíåÊ®°ÂûãÂêà‰ΩµÊ°ÜÊû∂ÔºåÂèØ‰ª•Â∞á‰ªª‰Ωï‰∏ÄÁµÑÁ∑®Á¢ºÂô®ËΩâÊèõÁÇ∫ÂÖ∑ÊúâÁ´∂Áà≠ÂäõÁöÑÂ§öÊ®°ÊÖãÊ®°ÂûãÔºåËÄåÁÑ°ÈúÄÊàñÂè™ÈúÄÊúÄÂ∞ëÁöÑÂæÆË™ø„ÄÇÊàëÂÄëÈÄöÈÅéÂºïÂÖ•‰∏ÄÂÄãÂñÆÊ®°ÊÖãÁ∑®Á¢ºÂô®ÁöÑÂåÖË£ùÂô®‰æÜÂØ¶ÁèæÈÄô‰∏ÄÈªûÔºåË©≤ÂåÖË£ùÂô®Âú®Ê®°ÊÖã‰πãÈñìÂü∑Ë°åËºïÈáèÁ¥öÁ∂≠Â∫¶ÂÅáË®≠Ôºå‰∏¶ÈÄöÈÅéÂú®È†ªÂüü‰∏≠Â≠∏ÁøíÁâπÂæµ‰æÜÂçîË™øÂÆÉÂÄëÁöÑË°®Á§∫ÔºåÂæûËÄåÂØ¶ÁèæÊ®°ÂûãÂêà‰ΩµÔºåÂêåÊôÇÂπæ‰πé‰∏çÊúÉÁî¢ÁîüË®äËôüÂπ≤Êìæ„ÄÇÊàëÂÄëË°®Êòé MM-Lego 1) ÂèØ‰ª•Áî®‰ΩúÊ®°ÂûãÂêà‰ΩµÊñπÊ≥ïÔºåÂú®‰∏çÈÄ≤Ë°å‰ªª‰ΩïÂæÆË™øÁöÑÊÉÖÊ≥Å‰∏ãÂØ¶ÁèæËàáÁ´ØÂà∞Á´ØËûçÂêàÊ®°ÂûãÂÖ∑ÊúâÁ´∂Áà≠ÂäõÁöÑÊïàËÉΩÔºå2) ÂèØ‰ª•Êìç‰Ωú‰ªª‰ΩïÂñÆÊ®°ÊÖãÁ∑®Á¢ºÂô®Ôºå‰ª•Âèä 3) ÊòØ‰∏ÄÁ®ÆÊ®°ÂûãËûçÂêàÊñπÊ≥ïÔºåÂú®ÊúÄÂ∞èÁöÑÂæÆË™ø‰∏ãÔºåÂú®ÂÖ≠ÂÄãÂü∫Ê∫ñÂ§öÊ®°ÊÖãÁîüÁâ©ÈÜ´Â≠∏‰ªªÂãô‰∏äÂØ¶Áèæ‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÁµêÊûú„ÄÇ

##### **KNOW: A Real-World Ontology for Knowledge Capture with Large Language Models**
2405.19877v1 by Arto Bendiken

We present KNOW--the Knowledge Navigator Ontology for the World--the first
ontology designed to capture everyday knowledge to augment large language
models (LLMs) in real-world generative AI use cases such as personal AI
assistants. Our domain is human life, both its everyday concerns and its major
milestones. We have limited the initial scope of the modeled concepts to only
established human universals: spacetime (places, events) plus social (people,
groups, organizations). The inclusion criteria for modeled concepts are
pragmatic, beginning with universality and utility. We compare and contrast
previous work such as Schema.org and Cyc--as well as attempts at a synthesis of
knowledge graphs and language models--noting how LLMs already encode internally
much of the commonsense tacit knowledge that took decades to capture in the Cyc
project. We also make available code-generated software libraries for the 12
most popular programming languages, enabling the direct use of ontology
concepts in software engineering. We emphasize simplicity and developer
experience in promoting AI interoperability.

ÊëòË¶ÅÔºöÊàëÂÄëÊèêÂá∫‰∫Ü KNOWÔºåÂç≥‰∏ñÁïåÁü•Ë≠òÂ∞éËà™Êú¨‰ΩìÔºåÈÄôÊòØÁ¨¨‰∏ÄÂÄãÊó®Âú®Êì∑ÂèñÊó•Â∏∏Áü•Ë≠ò‰ª•Êì¥ÂÖÖÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®ÂØ¶ÈöõÁîüÊàêÂºè AI ‰ΩøÁî®Ê°à‰æã‰∏≠ÁöÑÊú¨‰ΩìÔºå‰æãÂ¶ÇÂÄã‰∫∫ AI Âä©ÁêÜ„ÄÇÊàëÂÄëÁöÑÈ†òÂüüÊòØ‰∫∫È°ûÁîüÊ¥ªÔºåÂåÖÊã¨ÂÖ∂Êó•Â∏∏ÈóúÂàáÂíåÈáçÂ§ßÈáåÁ®ãÁ¢ë„ÄÇÊàëÂÄëÂ∑≤Â∞áÂª∫Ê®°Ê¶ÇÂøµÁöÑÂàùÂßãÁØÑÂúçÈôêÂà∂ÁÇ∫ÂÉÖÂª∫Á´ã‰∫∫È°ûÊôÆÈÅçÊÄßÔºöÊôÇÁ©∫ÔºàÂú∞Èªû„ÄÅ‰∫ã‰ª∂ÔºâÂä†‰∏äÁ§æÊúÉÔºà‰∫∫„ÄÅÁæ§ÁµÑ„ÄÅÁµÑÁπîÔºâ„ÄÇÂª∫Ê®°Ê¶ÇÂøµÁöÑÁ¥çÂÖ•Ê®ôÊ∫ñÂæàÂãôÂØ¶ÔºåÂæûÊôÆÈÅçÊÄßÂíåÂØ¶Áî®ÊÄßÈñãÂßã„ÄÇÊàëÂÄëÊØîËºÉÂíåÂ∞çÊØîÂÖàÂâçÁöÑ‰ΩúÂìÅÔºå‰æãÂ¶Ç Schema.org Âíå CycÔºå‰ª•ÂèäÁü•Ë≠òÂúñË≠úÂíåË™ûË®ÄÊ®°ÂûãÁöÑÁ∂úÂêàÂòóË©¶Ôºå‰∏¶Ê≥®ÊÑèÂà∞ LLM Â∑≤ÂÖßÈÉ®Á∑®Á¢º‰∫ÜË®±Â§öÂ∏∏Ë≠òÊÄßÁöÑÈªòË™çÁü•Ë≠òÔºåËÄåÈÄô‰∫õÁü•Ë≠òËä±Ë≤ª‰∫ÜÊï∏ÂçÅÂπ¥ÊâçÂú® Cyc È†ÖÁõÆ‰∏≠Ë¢´Êì∑Âèñ„ÄÇÊàëÂÄëÈÇÑÊèê‰æõ‰∫Ü 12 Á®ÆÊúÄÂèóÊ≠°ËøéÁöÑÁ®ãÂºèË®≠Ë®àË™ûË®ÄÁöÑÁ®ãÂºèÁ¢ºÁîüÊàêËªüÈ´îÂáΩÂºèÂ∫´ÔºåËÆìÂª∫Ê®°Ê¶ÇÂøµËÉΩÂ§†Áõ¥Êé•Áî®ÊñºËªüÈ´îÂ∑•Á®ã‰∏≠„ÄÇÊàëÂÄëÂº∑Ë™øÁ∞°ÊΩîÊÄßÂíåÈñãÁôº‰∫∫Âì°Á∂ìÈ©óÂú®‰øÉÈÄ≤ AI ‰∫íÊìç‰ΩúÊÄß‰∏≠ÁöÑÈáçË¶ÅÊÄß„ÄÇ

##### **Unsupervised Mutual Learning of Dialogue Discourse Parsing and Topic Segmentation**
2405.19799v2 by Jiahui Xu, Feng Jiang, Anningzhe Gao, Haizhou Li

The advancement of large language models (LLMs) has propelled the development
of dialogue systems. Unlike the popular ChatGPT-like assistant model, which
only satisfies the user's preferences, task-oriented dialogue systems have also
faced new requirements and challenges in the broader business field. They are
expected to provide correct responses at each dialogue turn, at the same time,
achieve the overall goal defined by the task. By understanding rhetorical
structures and topic structures via topic segmentation and discourse parsing, a
dialogue system may do a better planning to achieve both objectives. However,
while both structures belong to discourse structure in linguistics, rhetorical
structure and topic structure are mostly modeled separately or with one
assisting the other in the prior work. The interaction between these two
structures has not been considered for joint modeling and mutual learning.
Furthermore, unsupervised learning techniques to achieve the above are not well
explored. To fill this gap, we propose an unsupervised mutual learning
framework of two structures leveraging the global and local connections between
them. We extend the topic modeling between non-adjacent discourse units to
ensure global structural relevance with rhetorical structures. We also
incorporate rhetorical structures into the topic structure through a graph
neural network model to ensure local coherence consistency. Finally, we utilize
the similarity between the two fused structures for mutual learning. The
experimental results demonstrate that our methods outperform all strong
baselines on two dialogue rhetorical datasets (STAC and Molweni), as well as
dialogue topic datasets (Doc2Dial and TIAGE). We provide our code at
https://github.com/Jeff-Sue/URT.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÈÄ≤Â±ïÊé®Âãï‰∫ÜÂ∞çË©±Á≥ªÁµ±ÁöÑÁôºÂ±ï„ÄÇËàáÂè™ÊªøË∂≥‰ΩøÁî®ËÄÖÂÅèÂ•ΩÁöÑÊµÅË°å ChatGPT È°ûÂûãÂä©ÁêÜÊ®°Âûã‰∏çÂêåÔºå‰ªªÂãôÂ∞éÂêëÂ∞çË©±Á≥ªÁµ±Âú®Êõ¥Âª£Ê≥õÁöÑÂïÜÊ•≠È†òÂüü‰∏≠‰πüÈù¢Ëá®Êñ∞ÁöÑÈúÄÊ±ÇÂíåÊåëÊà∞„ÄÇÂÆÉÂÄëÈ†êÊúüÂú®ÊØèÂÄãÂ∞çË©±ÂõûÂêà‰∏≠Êèê‰æõÊ≠£Á¢∫ÁöÑÂõûÊáâÔºåÂêåÊôÇÈÅîÊàê‰ªªÂãôÂÆöÁæ©ÁöÑÊï¥È´îÁõÆÊ®ô„ÄÇÈÄèÈÅé‰∏ªÈ°åÂàÜÊÆµÂíåË™ûÁØáËß£Êûê‰∫ÜËß£Ë™ûÁØáÁµêÊßãÂíå‰∏ªÈ°åÁµêÊßãÔºåÂ∞çË©±Á≥ªÁµ±ÂèØ‰ª•Êõ¥Â•ΩÂú∞Ë¶èÂäÉ‰ª•ÈÅîÊàêÈÄôÂÖ©ÂÄãÁõÆÊ®ô„ÄÇÁÑ∂ËÄåÔºåÂÑòÁÆ°ÈÄôÂÖ©ÂÄãÁµêÊßãÈÉΩÂ±¨ÊñºË™ûË®ÄÂ≠∏‰∏≠ÁöÑË™ûÁØáÁµêÊßãÔºå‰ΩÜË™ûÁØáÁµêÊßãÂíå‰∏ªÈ°åÁµêÊßãÂ§ßÂ§öÊòØÂàÜÈñãÂª∫Ê®°ÔºåÊàñÂú®ÂÖàÂâçÁöÑÁ†îÁ©∂‰∏≠‰ª•‰∏ÄÂÄãÂçîÂä©Âè¶‰∏ÄÂÄã„ÄÇÈÄôÂÖ©ÂÄãÁµêÊßã‰πãÈñìÁöÑ‰∫íÂãïÂ∞öÊú™ËÄÉÊÖÆÈÄ≤Ë°åËÅØÂêàÂª∫Ê®°ÂíåÁõ∏‰∫íÂ≠∏Áøí„ÄÇÊ≠§Â§ñÔºåÂ∞öÊú™ÂÖÖÂàÜÊé¢Á¥¢Áî®ÊñºÈÅîÊàê‰∏äËø∞ÁõÆÊ®ôÁöÑÈùûÁõ£Áù£ÂºèÂ≠∏ÁøíÊäÄË°ì„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂ∑ÆË∑ùÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÈùûÁõ£Áù£ÂºèÁõ∏‰∫íÂ≠∏ÁøíÊû∂ÊßãÔºåÂà©Áî®ÂÆÉÂÄë‰πãÈñìÁöÑÂÖ®Â±ÄÂíåÂ±ÄÈÉ®ÈÄ£Êé•„ÄÇÊàëÂÄëÊì¥ÂÖÖÈùûÁõ∏ÈÑ∞Ë™ûÁØáÂñÆÂÖÉ‰πãÈñìÁöÑ‰∏ªÈ°åÂª∫Ê®°Ôºå‰ª•Á¢∫‰øùËàáË™ûÁØáÁµêÊßãÁöÑÂÖ®Â±ÄÁµêÊßãÁõ∏ÈóúÊÄß„ÄÇÊàëÂÄëÈÇÑÈÄèÈÅéÂúñÁ•ûÁ∂ìÁ∂≤Ë∑ØÊ®°ÂûãÂ∞áË™ûÁØáÁµêÊßãÁ¥çÂÖ•‰∏ªÈ°åÁµêÊßãÔºå‰ª•Á¢∫‰øùÂ±ÄÈÉ®Áõ∏ÂÆπÊÄß‰∏ÄËá¥ÊÄß„ÄÇÊúÄÂæåÔºåÊàëÂÄëÂà©Áî®ÈÄôÂÖ©ÂÄãËûçÂêàÁµêÊßã‰πãÈñìÁöÑÁõ∏‰ººÊÄßÈÄ≤Ë°åÁõ∏‰∫íÂ≠∏Áøí„ÄÇÂØ¶È©óÁµêÊûúË≠âÊòéÔºåÊàëÂÄëÁöÑÊ®°ÂûãÂú®ÂÖ©ÂÄãÂ∞çË©±Ë™ûÁØáË≥áÊñôÈõÜ (STAC Âíå Molweni) ‰ª•ÂèäÂ∞çË©±‰∏ªÈ°åË≥áÊñôÈõÜ (Doc2Dial Âíå TIAGE) ‰∏äÂÑ™ÊñºÊâÄÊúâÂº∑Â§ßÁöÑÂü∫Ê∫ñ„ÄÇÊàëÂÄëÂú® https://github.com/Jeff-Sue/URT Êèê‰æõÊàëÂÄëÁöÑÁ®ãÂºèÁ¢º„ÄÇ

##### **Dataflow-Guided Retrieval Augmentation for Repository-Level Code Completion**
2405.19782v1 by Wei Cheng, Yuhan Wu, Wei Hu

Recent years have witnessed the deployment of code language models (LMs) in
various code intelligence tasks such as code completion. Yet, it is challenging
for pre-trained LMs to generate correct completions in private repositories.
Previous studies retrieve cross-file context based on import relations or text
similarity, which is insufficiently relevant to completion targets. In this
paper, we propose a dataflow-guided retrieval augmentation approach, called
DraCo, for repository-level code completion. DraCo parses a private repository
into code entities and establishes their relations through an extended dataflow
analysis, forming a repo-specific context graph. Whenever triggering code
completion, DraCo precisely retrieves relevant background knowledge from the
repo-specific context graph and generates well-formed prompts to query code
LMs. Furthermore, we construct a large Python dataset, ReccEval, with more
diverse completion targets. Our experiments demonstrate the superior accuracy
and applicable efficiency of DraCo, improving code exact match by 3.43% and
identifier F1-score by 3.27% on average compared to the state-of-the-art
approach.

ÊëòË¶ÅÔºöËøëÂπ¥Êù•Ôºå‰ª£Á†ÅËØ≠Ë®ÄÊ®°Âûã (LM) Â∑≤Ë¢´ÈÉ®ÁΩ≤Âú®ÂêÑÁßç‰ª£Á†ÅÊô∫ËÉΩ‰ªªÂä°‰∏≠Ôºå‰æãÂ¶Ç‰ª£Á†ÅË°•ÂÖ®„ÄÇÁÑ∂ËÄåÔºåÂØπ‰∫éÈ¢ÑËÆ≠ÁªÉÁöÑ LM Êù•ËØ¥ÔºåÂú®ÁßÅÊúâÂ≠òÂÇ®Â∫ì‰∏≠ÁîüÊàêÊ≠£Á°ÆÁöÑË°•ÂÖ®ÊòØ‰∏ÄÈ°πÊåëÊàò„ÄÇÂÖàÂâçÁöÑÁ†îÁ©∂Âü∫‰∫éÂØºÂÖ•ÂÖ≥Á≥ªÊàñÊñáÊú¨Áõ∏‰ººÊÄßÊ£ÄÁ¥¢Ë∑®Êñá‰ª∂‰∏ä‰∏ãÊñáÔºåËøô‰∏éË°•ÂÖ®ÁõÆÊ†áÁöÑÁõ∏ÂÖ≥ÊÄß‰∏çË∂≥„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçÊï∞ÊçÆÊµÅÂºïÂØºÂºèÊ£ÄÁ¥¢Â¢ûÂº∫ÊñπÊ≥ïÔºåÁß∞‰∏∫ DraCoÔºåÁî®‰∫éÂ≠òÂÇ®Â∫ìÁ∫ßÂà´ÁöÑ‰ª£Á†ÅË°•ÂÖ®„ÄÇDraCo Â∞ÜÁßÅÊúâÂ≠òÂÇ®Â∫ìËß£Êûê‰∏∫‰ª£Á†ÅÂÆû‰ΩìÔºåÂπ∂ÈÄöËøáÊâ©Â±ïÁöÑÊï∞ÊçÆÊµÅÂàÜÊûêÂª∫Á´ãÂÆÉ‰ª¨‰πãÈó¥ÁöÑÂÖ≥Á≥ªÔºåÂΩ¢ÊàêÁâπÂÆö‰∫éÂ≠òÂÇ®Â∫ìÁöÑ‰∏ä‰∏ãÊñáÂõæ„ÄÇÊØèÂΩìËß¶Âèë‰ª£Á†ÅË°•ÂÖ®Êó∂ÔºåDraCo ÈÉΩ‰ºö‰ªéÁâπÂÆö‰∫éÂ≠òÂÇ®Â∫ìÁöÑ‰∏ä‰∏ãÊñáÂõæ‰∏≠Á≤æÁ°ÆÂú∞Ê£ÄÁ¥¢Áõ∏ÂÖ≥ÁöÑËÉåÊôØÁü•ËØÜÔºåÂπ∂ÁîüÊàêÊ†ºÂºèËâØÂ•ΩÁöÑÊèêÁ§∫Êù•Êü•ËØ¢‰ª£Á†Å LM„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨ÊûÑÂª∫‰∫Ü‰∏Ä‰∏™Â§ßÂûã Python Êï∞ÊçÆÈõÜ ReccEvalÔºåÂÖ∂‰∏≠ÂåÖÂê´Êõ¥Â§öÊ†∑ÂåñÁöÑË°•ÂÖ®ÁõÆÊ†á„ÄÇÊàë‰ª¨ÁöÑÂÆûÈ™åË°®Êòé‰∫Ü DraCo ÁöÑÂçìË∂äÂáÜÁ°ÆÊÄßÂíåÈÄÇÁî®ÊïàÁéáÔºå‰∏éÊúÄÂÖàËøõÁöÑÊñπÊ≥ïÁõ∏ÊØîÔºåÂπ≥ÂùáÊèêÈ´ò‰∫Ü 3.43% ÁöÑ‰ª£Á†ÅÂÆåÂÖ®ÂåπÈÖçÂíå 3.27% ÁöÑÊ†áËØÜÁ¨¶ F1 ÂàÜÊï∞„ÄÇ

##### **Knowledge Graph Tuning: Real-time Large Language Model Personalization based on Human Feedback**
2405.19686v1 by Jingwei Sun, Zhixu Du, Yiran Chen

Large language models (LLMs) have demonstrated remarkable proficiency in a
range of natural language processing tasks. Once deployed, LLMs encounter users
with personalized factual knowledge, and such personalized knowledge is
consistently reflected through users' interactions with the LLMs. To enhance
user experience, real-time model personalization is essential, allowing LLMs to
adapt user-specific knowledge based on user feedback during human-LLM
interactions. Existing methods mostly require back-propagation to finetune the
model parameters, which incurs high computational and memory costs. In
addition, these methods suffer from low interpretability, which will cause
unforeseen impacts on model performance during long-term use, where the user's
personalized knowledge is accumulated extensively.To address these challenges,
we propose Knowledge Graph Tuning (KGT), a novel approach that leverages
knowledge graphs (KGs) to personalize LLMs. KGT extracts personalized factual
knowledge triples from users' queries and feedback and optimizes KGs without
modifying the LLM parameters. Our method improves computational and memory
efficiency by avoiding back-propagation and ensures interpretability by making
the KG adjustments comprehensible to humans.Experiments with state-of-the-art
LLMs, including GPT-2, Llama2, and Llama3, show that KGT significantly improves
personalization performance while reducing latency and GPU memory costs.
Ultimately, KGT offers a promising solution of effective, efficient, and
interpretable real-time LLM personalization during user interactions with the
LLMs.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤Ë≠âÊòéÂú®ÂêÑÁ®ÆËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ‰ªªÂãô‰∏≠ÂÖ∑ÊúâÂçìË∂äÁöÑËÉΩÂäõ„ÄÇ‰∏ÄÊó¶ÈÉ®ÁΩ≤ÔºåLLM ÊúÉÈÅáÂà∞ÊìÅÊúâÂÄã‰∫∫Âåñ‰∫ãÂØ¶Áü•Ë≠òÁöÑ‰ΩøÁî®ËÄÖÔºåËÄåÈÄôÁ®ÆÂÄã‰∫∫ÂåñÁü•Ë≠òÊúÉÊåÅÁ∫åÂèçÊò†Âú®‰ΩøÁî®ËÄÖËàá LLM ÁöÑ‰∫íÂãï‰∏≠„ÄÇÁÇ∫‰∫ÜÊèêÂçá‰ΩøÁî®ËÄÖÈ´îÈ©óÔºåÂç≥ÊôÇÊ®°ÂûãÂÄã‰∫∫ÂåñËá≥ÈóúÈáçË¶ÅÔºåÈÄôËÆì LLM ËÉΩÂú®‰∫∫È°ûËàá LLM ÁöÑ‰∫íÂãï‰∏≠Ê†πÊìö‰ΩøÁî®ËÄÖÁöÑÂõûÈ•ãË™øÊï¥‰ΩøÁî®ËÄÖÁâπÂÆöÁöÑÁü•Ë≠ò„ÄÇÁèæÊúâÊñπÊ≥ïÂ§ßÂ§öÈúÄË¶ÅÂèçÂêëÂÇ≥Êí≠‰æÜÂæÆË™øÊ®°ÂûãÂèÉÊï∏ÔºåÈÄôÊúÉÁî¢ÁîüÈ´òÈÅãÁÆóÂíåË®òÊÜ∂È´îÊàêÊú¨„ÄÇÊ≠§Â§ñÔºåÈÄô‰∫õÊñπÊ≥ïÁöÑÂèØËß£ÈáãÊÄß‰ΩéÔºåÈÄôÊúÉÂú®Èï∑Êúü‰ΩøÁî®ÊúüÈñìÂ∞çÊ®°ÂûãÊïàËÉΩÈÄ†ÊàêÁÑ°Ê≥ïÈ†êË¶ãÁöÑÂΩ±ÈüøÔºåËÄå‰ΩøÁî®ËÄÖÁöÑÂÄã‰∫∫ÂåñÁü•Ë≠òÊúÉÂ§ßÈáèÁ¥ØÁ©ç„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÊèêÂá∫Áü•Ë≠òÂúñË≠úË™øÊï¥ (KGT)ÔºåÈÄôÊòØ‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÊñπÊ≥ïÔºåÂà©Áî®Áü•Ë≠òÂúñË≠ú (KG) ‰æÜÂÄã‰∫∫Âåñ LLM„ÄÇKGT Âæû‰ΩøÁî®ËÄÖÁöÑÊü•Ë©¢ÂíåÂõûÈ•ã‰∏≠ËêÉÂèñÂÄã‰∫∫ÂåñÁöÑ‰∫ãÂØ¶Áü•Ë≠ò‰∏âÂÖÉÁµÑÔºå‰∏¶Âú®‰∏ç‰øÆÊîπ LLM ÂèÉÊï∏ÁöÑÊÉÖÊ≥Å‰∏ãÊúÄ‰Ω≥Âåñ KG„ÄÇÊàëÂÄëÁöÑÈÄôÁ®ÆÊñπÊ≥ïÈÄèÈÅéÈÅøÂÖçÂèçÂêëÂÇ≥Êí≠‰æÜÊèêÂçáÈÅãÁÆóÂíåË®òÊÜ∂È´îÊïàÁéáÔºå‰∏¶ÈÄèÈÅéËÆì KG Ë™øÊï¥Â∞ç‰∫∫È°û‰æÜË™™ÊòìÊñºÁêÜËß£‰æÜÁ¢∫‰øùÂèØËß£ÈáãÊÄß„ÄÇ‰ΩøÁî®ÂåÖÂê´ GPT-2„ÄÅLlama2 Âíå Llama3 Âú®ÂÖßÁöÑÊúÄÊñ∞ LLM ÈÄ≤Ë°åÁöÑÂØ¶È©óÈ°ØÁ§∫ÔºåKGT Âú®Èôç‰ΩéÂª∂ÈÅ≤Âíå GPU Ë®òÊÜ∂È´îÊàêÊú¨ÁöÑÂêåÊôÇÔºåÂ§ßÂπÖÊèêÂçáÂÄã‰∫∫ÂåñÊïàËÉΩ„ÄÇÊúÄÁµÇÔºåKGT Êèê‰æõ‰∫Ü‰∏ÄÂÄãÊúâÂâçÈÄîÁöÑËß£Ê±∫ÊñπÊ°àÔºåÂèØ‰ª•Âú®‰ΩøÁî®ËÄÖËàá LLM ‰∫íÂãïÊúüÈñìÈÄ≤Ë°åÊúâÊïà„ÄÅÈ´òÊïà‰∏îÂèØËß£ÈáãÁöÑÂç≥ÊôÇ LLM ÂÄã‰∫∫Âåñ„ÄÇ

##### **MASSIVE Multilingual Abstract Meaning Representation: A Dataset and Baselines for Hallucination Detection**
2405.19285v1 by Michael Regan, Shira Wein, George Baker, Emilio Monti

Abstract Meaning Representation (AMR) is a semantic formalism that captures
the core meaning of an utterance. There has been substantial work developing
AMR corpora in English and more recently across languages, though the limited
size of existing datasets and the cost of collecting more annotations are
prohibitive. With both engineering and scientific questions in mind, we
introduce MASSIVE-AMR, a dataset with more than 84,000 text-to-graph
annotations, currently the largest and most diverse of its kind: AMR graphs for
1,685 information-seeking utterances mapped to 50+ typologically diverse
languages. We describe how we built our resource and its unique features before
reporting on experiments using large language models for multilingual AMR and
SPARQL parsing as well as applying AMRs for hallucination detection in the
context of knowledge base question answering, with results shedding light on
persistent issues using LLMs for structured parsing.

ÊëòË¶ÅÔºöÊäΩË±°Ë™ûÊÑèË°®Á§∫ÔºàAMRÔºâÊòØ‰∏ÄÁ®ÆË™ûÊÑèÂΩ¢ÂºèÂåñÔºåÁî®ÊñºÊçïÊçâË™ûÂè•ÁöÑÊ†∏ÂøÉÂê´Áæ©„ÄÇ
ÁõÆÂâçÂ∑≤ÊúâÂ§ßÈáèÂ∑•‰ΩúËá¥ÂäõÊñºÈñãÁôºËã±Êñá AMR Ë™ûÊñôÂ∫´ÔºåÊúÄËøëÊõ¥Êì¥Â±ïÂà∞Ë∑®Ë™ûË®ÄÔºåÂÑòÁÆ°ÁèæÊúâË≥áÊñôÈõÜË¶èÊ®°ÊúâÈôêÔºå‰∏îÊî∂ÈõÜÊõ¥Â§öÊ®ôË®ªÁöÑÊàêÊú¨ÈÅéÈ´ò„ÄÇ
ËÄÉÈáèÂà∞Â∑•Á®ãÂíåÁßëÂ≠∏ÊñπÈù¢ÁöÑÂïèÈ°åÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü MASSIVE-AMRÔºåÈÄôÊòØ‰∏ÄÂÄãÂåÖÂê´Ë∂ÖÈÅé 84,000 ÂÄãÊñáÂ≠óËΩâÂúñÂΩ¢Ê®ôË®ªÁöÑË≥áÊñôÈõÜÔºåÁõÆÂâçÊòØÂêåÈ°ûË≥áÊñôÈõÜ‰∏≠Ë¶èÊ®°ÊúÄÂ§ß‰∏îÊúÄÂ§öÊ®£ÂåñÁöÑÔºöAMR ÂúñÂΩ¢Ê∂µËìã 1,685 ÂÄãË≥áË®äÂ∞ãÊ±ÇË™ûÂè•ÔºåÂ∞çÊáâÂà∞ 50 Â§öÁ®ÆË™ûË®ÄÈ°ûÂûãÂ§öÊ®£ÁöÑË™ûË®Ä„ÄÇ
ÊàëÂÄëÂ∞áË™™ÊòéÂ¶Ç‰ΩïÂª∫ÊßãË≥áÊ∫êÂèäÂÖ∂Áç®ÁâπÂäüËÉΩÔºåÁÑ∂ÂæåÂÜçÂ†±Âëä‰ΩøÁî®Â§ßÂûãË™ûË®ÄÊ®°ÂûãÈÄ≤Ë°åÂ§öË™ûË®Ä AMR Âíå SPARQL Ëß£ÊûêÁöÑÂØ¶È©óÔºå‰ª•ÂèäÂú®Áü•Ë≠òÂ∫´ÂïèÁ≠îÁöÑËÉåÊôØ‰∏ãÊáâÁî® AMR ÈÄ≤Ë°åÂπªË¶∫ÂÅµÊ∏¨ÔºåÁµêÊûúÊúâÂä©ÊñºÈáêÊ∏Ö‰ΩøÁî® LLM ÈÄ≤Ë°åÁµêÊßãÂåñËß£ÊûêÊôÇÊåÅÁ∫åÂ≠òÂú®ÁöÑÂïèÈ°å„ÄÇ

##### **PediatricsGPT: Large Language Models as Chinese Medical Assistants for Pediatric Applications**
2405.19266v2 by Dingkang Yang, Jinjie Wei, Dongling Xiao, Shunli Wang, Tong Wu, Gang Li, Mingcheng Li, Shuaibing Wang, Jiawei Chen, Yue Jiang, Qingyao Xu, Ke Li, Peng Zhai, Lihua Zhang

Developing intelligent pediatric consultation systems offers promising
prospects for improving diagnostic efficiency, especially in China, where
healthcare resources are scarce. Despite recent advances in Large Language
Models (LLMs) for Chinese medicine, their performance is sub-optimal in
pediatric applications due to inadequate instruction data and vulnerable
training procedures. To address the above issues, this paper builds PedCorpus,
a high-quality dataset of over 300,000 multi-task instructions from pediatric
textbooks, guidelines, and knowledge graph resources to fulfil diverse
diagnostic demands. Upon well-designed PedCorpus, we propose PediatricsGPT, the
first Chinese pediatric LLM assistant built on a systematic and robust training
pipeline. In the continuous pre-training phase, we introduce a hybrid
instruction pre-training mechanism to mitigate the internal-injected knowledge
inconsistency of LLMs for medical domain adaptation. Immediately, the
full-parameter Supervised Fine-Tuning (SFT) is utilized to incorporate the
general medical knowledge schema into the models. After that, we devise a
direct following preference optimization to enhance the generation of
pediatrician-like humanistic responses. In the parameter-efficient secondary
SFT phase, a mixture of universal-specific experts strategy is presented to
resolve the competency conflict between medical generalist and pediatric
expertise mastery. Extensive results based on the metrics, GPT-4, and doctor
evaluations on distinct doctor downstream tasks show that PediatricsGPT
consistently outperforms previous Chinese medical LLMs. Our model and dataset
will be open-source for community development.

ÊëòË¶ÅÔºö<paragraph>ÈñãÁôºÊô∫ËÉΩÂÖíÁßëË´ÆË©¢Á≥ªÁµ±ÔºåËÉΩÊúâÊïàÊèêÂçáË®∫Êñ∑ÊïàÁéáÔºåÁâπÂà•ÊòØÂú®ÈÜ´ÁôÇË≥áÊ∫êÁõ∏Â∞çÁº∫‰πèÁöÑ‰∏≠Âúã„ÄÇÂÑòÁÆ°‰∏≠ÊñáÈÜ´Â≠∏ÁöÑÂ§ßË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâËøë‰æÜÊúâÈï∑Ë∂≥ÈÄ≤Â±ïÔºå‰ΩÜÁî±ÊñºË®ìÁ∑¥Ë≥áÊñô‰∏çË∂≥‰∏îË®ìÁ∑¥Á®ãÂ∫è‰∏çÂÆåÂñÑÔºåÂÖ∂Âú®ÂÖíÁßëÊáâÁî®‰∏≠ÁöÑË°®Áèæ‰∏¶Êú™ÈÅîÂà∞ÊúÄ‰Ω≥Âåñ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫‰∏äËø∞ÂïèÈ°åÔºåÊú¨ÊñáÂª∫Á´ã‰∫Ü PedCorpusÔºå‰∏ÄÂÄãÂåÖÂê´Ë∂ÖÈÅé 30 Ëê¨Ê¢ù‰æÜËá™ÂÖíÁßëÊïôÁßëÊõ∏„ÄÅÊåáÂçóÂíåÁü•Ë≠òÂúñË≠úË≥áÊ∫êÁöÑÂ§ö‰ªªÂãôÊåá‰ª§ÁöÑÈ´òÂìÅË≥™Ë≥áÊñôÈõÜÔºå‰ª•ÊªøË∂≥Â§öÊ®£ÂåñÁöÑË®∫Êñ∑ÈúÄÊ±Ç„ÄÇÂú®Ë®≠Ë®àËâØÂ•ΩÁöÑ PedCorpus ‰∏äÔºåÊàëÂÄëÊèêÂá∫‰∫Ü PediatricsGPTÔºåÈÄôÊòØÁ¨¨‰∏ÄÂÄãÂª∫ÊßãÂú®Á≥ªÁµ±Âåñ‰∏îÁ©©ÂÅ•ÁöÑË®ìÁ∑¥ÊµÅÁ®ã‰∏äÁöÑ‰∏≠ÊñáÂÖíÁßë LLM Âä©ÁêÜ„ÄÇÂú®ÊåÅÁ∫åÁöÑÈ†êË®ìÁ∑¥ÈöéÊÆµÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÊ∑∑ÂêàÊåá‰ª§È†êË®ìÁ∑¥Ê©üÂà∂Ôºå‰ª•Ê∏õËºï LLM Âú®ÈÜ´Â≠∏È†òÂüüÈÅ©ÊáâÊôÇÂÖßÈÉ®Ê≥®ÂÖ•Áü•Ë≠òÁöÑ‰∏ç‰∏ÄËá¥ÊÄß„ÄÇÁ∑äÊé•ËëóÔºåÊàëÂÄëÂà©Áî®ÂÖ®ÂèÉÊï∏Áõ£Áù£ÂæÆË™øÔºàSFTÔºâÂ∞á‰∏ÄËà¨ÁöÑÈÜ´Â≠∏Áü•Ë≠òÊû∂ÊßãÁ¥çÂÖ•Ê®°Âûã‰∏≠„ÄÇÈö®ÂæåÔºåÊàëÂÄëË®≠Ë®à‰∫Ü‰∏ÄÂÄãÁõ¥Êé•ÈÅµÂæ™ÂÅèÂ•ΩÊúÄ‰Ω≥ÂåñÔºå‰ª•Â¢ûÂº∑È°ûÂÖíÁßëÈÜ´Â∏´ÁöÑ‰∫∫ÊñáÂõûÊáâÁîüÊàê„ÄÇÂú®ÂèÉÊï∏ÊïàÁéáÁöÑÊ¨°Ë¶Å SFT ÈöéÊÆµÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÈÄöÁî®Â∞àÂÆ∂Á≠ñÁï•ÁöÑÊ∑∑ÂêàÔºå‰ª•Ëß£Ê±∫ÂÖ®ÁßëÈÜ´Â∏´ÂíåÂÖíÁßëÂ∞àÂÆ∂ÊéåÊè°ËÉΩÂäõ‰πãÈñìÁöÑË°ùÁ™Å„ÄÇÊ†πÊìö GPT-4„ÄÅÈÜ´ÁîüË©ï‰º∞Âú®‰∏çÂêåÈÜ´Áîü‰∏ãÊ∏∏‰ªªÂãô‰∏äÁöÑÊåáÊ®ôÔºåÂª£Ê≥õÁöÑÁµêÊûúÈ°ØÁ§∫ PediatricsGPT ÊåÅÁ∫åÂÑ™ÊñºÂÖàÂâçÁöÑ‰∏≠ÊñáÈÜ´Â≠∏ LLM„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÂíåË≥áÊñôÈõÜÂ∞áÈñãÊîæÂéüÂßãÁ¢º‰æõÁ§æÁæ§ÈñãÁôº„ÄÇ</paragraph>

##### **Towards Next-Generation Urban Decision Support Systems through AI-Powered Generation of Scientific Ontology using Large Language Models -- A Case in Optimizing Intermodal Freight Transportation**
2405.19255v1 by Jose Tupayachi, Haowen Xu, Olufemi A. Omitaomu, Mustafa Can Camur, Aliza Sharmin, Xueping Li

The incorporation of Artificial Intelligence (AI) models into various
optimization systems is on the rise. Yet, addressing complex urban and
environmental management problems normally requires in-depth domain science and
informatics expertise. This expertise is essential for deriving data and
simulation-driven for informed decision support. In this context, we
investigate the potential of leveraging the pre-trained Large Language Models
(LLMs). By adopting ChatGPT API as the reasoning core, we outline an integrated
workflow that encompasses natural language processing, methontology-based
prompt tuning, and transformers. This workflow automates the creation of
scenario-based ontology using existing research articles and technical manuals
of urban datasets and simulations. The outcomes of our methodology are
knowledge graphs in widely adopted ontology languages (e.g., OWL, RDF, SPARQL).
These facilitate the development of urban decision support systems by enhancing
the data and metadata modeling, the integration of complex datasets, the
coupling of multi-domain simulation models, and the formulation of
decision-making metrics and workflow. The feasibility of our methodology is
evaluated through a comparative analysis that juxtaposes our AI-generated
ontology with the well-known Pizza Ontology employed in tutorials for popular
ontology software (e.g., prot\'eg\'e). We close with a real-world case study of
optimizing the complex urban system of multi-modal freight transportation by
generating anthologies of various domain data and simulations to support
informed decision-making.

ÊëòË¶ÅÔºö‰∫∫Â∑•Êô∫ËÉΩ (AI) Ê®°ÂûãÊï¥ÂêàÂà∞ÂêÑÁ®ÆÊúÄ‰Ω≥ÂåñÁ≥ªÁµ±‰∏≠Ê≠£ÊñπËààÊú™Ëâæ„ÄÇÁÑ∂ËÄåÔºåËß£Ê±∫Ë§áÈõúÁöÑÈÉΩÂ∏ÇÂíåÁí∞Â¢ÉÁÆ°ÁêÜÂïèÈ°åÈÄöÂ∏∏ÈúÄË¶ÅÊ∑±ÂÖ•ÁöÑÈ†òÂüüÁßëÂ≠∏ÂíåË≥áË®äÂ∞àÊ•≠Áü•Ë≠ò„ÄÇÈÄôÁ®ÆÂ∞àÊ•≠Áü•Ë≠òÂ∞çÊñºÂæûË≥áÊñôÂíåÊ®°Êì¨‰∏≠Êé®Â∞éÂá∫Ë≥áÊñôÈ©ÖÂãïÁöÑÊòéÊô∫Ê±∫Á≠ñÊîØÊè¥Ëá≥ÈóúÈáçË¶Å„ÄÇÂú®Ê≠§ËÑàÁµ°‰∏ãÔºåÊàëÂÄëÊé¢Ë®éÂà©Áî®È†êÂÖàË®ìÁ∑¥ÁöÑÂ§ßË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊΩõÂäõ„ÄÇÈÄèÈÅéÊé°Áî® ChatGPT API ‰ΩúÁÇ∫Êé®ÁêÜÊ†∏ÂøÉÔºåÊàëÂÄëÊ¶ÇËø∞‰∏ÄÂÄãÊï¥ÂêàÁöÑÂ∑•‰ΩúÊµÅÁ®ãÔºåÂÖ∂‰∏≠ÂåÖÂê´Ëá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ„ÄÅÂü∫ÊñºÊñπÊ≥ïË´ñÁöÑÊèêÁ§∫Ë™øÊï¥ÂíåËΩâÊèõÂô®„ÄÇÊ≠§Â∑•‰ΩúÊµÅÁ®ãËá™ÂãïÂåñ‰ΩøÁî®ÁèæÊúâÁ†îÁ©∂ÊñáÁ´†ÂíåÈÉΩÂ∏ÇË≥áÊñôÈõÜÂèäÊ®°Êì¨ÊäÄË°ìÊâãÂÜäÂª∫Á´ãÂü∫ÊñºÊÉÖÂ¢ÉÁöÑÊú¨‰Ωì„ÄÇÊàëÂÄëÊñπÊ≥ïË´ñÁöÑÊàêÊûúÊòØÂª£Ê≥õÊé°Áî®ÁöÑÊú¨‰ΩìË™ûË®ÄÔºà‰æãÂ¶Ç OWL„ÄÅRDF„ÄÅSPARQLÔºâ‰∏≠ÁöÑÁü•Ë≠òÂúñË≠ú„ÄÇÈÄô‰∫õÁü•Ë≠òÂúñË≠úÈÄèÈÅéÂ¢ûÂº∑Ë≥áÊñôÂíåÂÖÉË≥áÊñôÂª∫Ê®°„ÄÅÊï¥ÂêàË§áÈõúÁöÑË≥áÊñôÈõÜ„ÄÅÁµêÂêàÂ§öÈ†òÂüüÊ®°Êì¨Ê®°ÂûãÔºå‰ª•ÂèäÂà∂ÂÆöÊ±∫Á≠ñÊåáÊ®ôÂíåÂ∑•‰ΩúÊµÅÁ®ãÔºå‰øÉÈÄ≤ÈÉΩÂ∏ÇÊ±∫Á≠ñÊîØÊè¥Á≥ªÁµ±ÁöÑÁôºÂ±ï„ÄÇÊàëÂÄëÈÄèÈÅéÊØîËºÉÂàÜÊûêË©ï‰º∞ÊàëÂÄëÊñπÊ≥ïË´ñÁöÑÂèØË°åÊÄßÔºåË©≤ÂàÜÊûêÂ∞áÊàëÂÄë AI ÁîüÊàêÁöÑÊú¨‰ΩìËàáÂª£Ê≥õÁî®ÊñºÁÜ±ÈñÄÊú¨‰ΩìËªüÈ´î (‰æãÂ¶Ç prot\'eg\'e) ÊïôÂ≠∏Ë™≤Á®ãÁöÑÁü•Âêç Pizza Êú¨‰Ωì‰∏¶ÁΩÆ„ÄÇÊàëÂÄë‰ª•‰∏ÄÂÄãÁúüÂØ¶‰∏ñÁïåÁöÑÊ°à‰æãÁ†îÁ©∂‰ΩúÁµêÔºåÈÄèÈÅéÁî¢ÁîüÂêÑÁ®ÆÈ†òÂüüË≥áÊñôÂíåÊ®°Êì¨ÁöÑÈÅ∏ÈõÜ‰æÜÊúÄ‰Ω≥ÂåñÂ§öÂºèËÅØÈÅãË≤®ÈÅãÁöÑË§áÈõúÈÉΩÂ∏ÇÁ≥ªÁµ±Ôºå‰ª•ÊîØÊè¥ÊòéÊô∫ÁöÑÊ±∫Á≠ñÂà∂ÂÆö„ÄÇ

##### **Learning from Litigation: Graphs and LLMs for Retrieval and Reasoning in eDiscovery**
2405.19164v1 by Sounak Lahiri, Sumit Pai, Tim Weninger, Sanmitra Bhattacharya

Electronic Discovery (eDiscovery) involves identifying relevant documents
from a vast collection based on legal production requests. The integration of
artificial intelligence (AI) and natural language processing (NLP) has
transformed this process, helping document review and enhance efficiency and
cost-effectiveness. Although traditional approaches like BM25 or fine-tuned
pre-trained models are common in eDiscovery, they face performance,
computational, and interpretability challenges. In contrast, Large Language
Model (LLM)-based methods prioritize interpretability but sacrifice performance
and throughput. This paper introduces DISCOvery Graph (DISCOG), a hybrid
approach that combines the strengths of two worlds: a heterogeneous graph-based
method for accurate document relevance prediction and subsequent LLM-driven
approach for reasoning. Graph representational learning generates embeddings
and predicts links, ranking the corpus for a given request, and the LLMs
provide reasoning for document relevance. Our approach handles datasets with
balanced and imbalanced distributions, outperforming baselines in F1-score,
precision, and recall by an average of 12%, 3%, and 16%, respectively. In an
enterprise context, our approach drastically reduces document review costs by
99.9% compared to manual processes and by 95% compared to LLM-based
classification methods

ÊëòË¶ÅÔºöÈõªÂ≠êÁôºÁèæ (eDiscovery) Ê∂âÂèäÊ†πÊìöÊ≥ïÂæãË£Ω‰ΩúË¶ÅÊ±ÇÂæûÂ§ßÈáèÈõÜÂêà‰∏≠Ë≠òÂà•Áõ∏ÈóúÊñá‰ª∂„ÄÇ‰∫∫Â∑•Êô∫ÊÖß (AI) ÂíåËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ (NLP) ÁöÑÊï¥ÂêàÂ∑≤ËΩâËÆäÊ≠§Á®ãÂ∫èÔºåÂçîÂä©Êñá‰ª∂Ê™¢Èñ±‰∏¶ÊèêÂçáÊïàÁéáÂíåÊàêÊú¨ÊïàÁõä„ÄÇÂÑòÁÆ°ÂÇ≥Áµ±ÊñπÊ≥ïÔºà‰æãÂ¶Ç BM25 ÊàñÂæÆË™øÈ†êÂÖàË®ìÁ∑¥ÁöÑÊ®°ÂûãÔºâÂú®ÈõªÂ≠êÁôºÁèæ‰∏≠ÂæàÂ∏∏Ë¶ãÔºå‰ΩÜÂÆÉÂÄëÈù¢Ëá®ÊïàËÉΩ„ÄÅÈÅãÁÆóÂíåÂèØËß£ÈáãÊÄßÊñπÈù¢ÁöÑÊåëÊà∞„ÄÇÁõ∏Â∞çÂú∞ÔºåÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁÇ∫Âü∫Á§éÁöÑÊñπÊ≥ïÂÑ™ÂÖàËÄÉÈáèÂèØËß£ÈáãÊÄßÔºå‰ΩÜÁäßÁâ≤ÊïàËÉΩÂíåËôïÁêÜÈáè„ÄÇÊú¨Êñá‰ªãÁ¥π DISCOvery Graph (DISCOG)ÔºåÈÄôÊòØ‰∏ÄÁ®ÆÁµêÂêàÂÖ©ÂÄã‰∏ñÁïåÁöÑÂÑ™Âã¢ÁöÑÊ∑∑ÂêàÊñπÊ≥ïÔºö‰∏ÄÁ®ÆÁî®ÊñºÊ∫ñÁ¢∫Êñá‰ª∂Áõ∏ÈóúÊÄßÈ†êÊ∏¨ÁöÑÁï∞Ë≥™ÂúñÂΩ¢ÁÇ∫Âü∫Á§éÁöÑÊñπÊ≥ïÂíåÂæåÁ∫åÁöÑ LLM È©ÖÂãïÊñπÊ≥ïÁî®ÊñºÊé®ÁêÜ„ÄÇÂúñÂΩ¢Ë°®ÂæµÂ≠∏ÁøíÊúÉÁî¢ÁîüÂµåÂÖ•ÂíåÈ†êÊ∏¨ÈÄ£ÁµêÔºåÈáùÂ∞çÁâπÂÆöË¶ÅÊ±ÇÂ∞çË™ûÊñôÂ∫´ÈÄ≤Ë°åÊéíÂêçÔºåËÄå LLM ÂâáÊèê‰æõÊñá‰ª∂Áõ∏ÈóúÊÄßÁöÑÊé®ÁêÜ„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïËôïÁêÜÂÖ∑ÊúâÂπ≥Ë°°Âíå‰∏çÂπ≥Ë°°ÂàÜ‰ΩàÁöÑË≥áÊñôÈõÜÔºåÂú® F1 ÂàÜÊï∏„ÄÅÊ∫ñÁ¢∫Â∫¶ÂíåÂè¨ÂõûÁéáÊñπÈù¢ÂÑ™ÊñºÂü∫Ê∫ñÔºåÂπ≥ÂùáÂàÜÂà•È´òÂá∫ 12%„ÄÅ3% Âíå 16%„ÄÇÂú®‰ºÅÊ•≠Áí∞Â¢É‰∏≠ÔºåËàáÊâãÂãïÁ®ãÂ∫èÁõ∏ÊØîÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÂ§ßÂπÖÊ∏õÂ∞ëÊñá‰ª∂ÂØ©Êü•ÊàêÊú¨ 99.9%ÔºåËàáÂü∫Êñº LLM ÁöÑÂàÜÈ°ûÊñπÊ≥ïÁõ∏ÊØîÔºåÊ∏õÂ∞ë 95%„ÄÇ

##### **Unleashing the Potential of Text-attributed Graphs: Automatic Relation Decomposition via Large Language Models**
2405.18581v1 by Hyunjin Seo, Taewon Kim, June Yong Yang, Eunho Yang

Recent advancements in text-attributed graphs (TAGs) have significantly
improved the quality of node features by using the textual modeling
capabilities of language models. Despite this success, utilizing text
attributes to enhance the predefined graph structure remains largely
unexplored. Our extensive analysis reveals that conventional edges on TAGs,
treated as a single relation (e.g., hyperlinks) in previous literature,
actually encompass mixed semantics (e.g., "advised by" and "participates in").
This simplification hinders the representation learning process of Graph Neural
Networks (GNNs) on downstream tasks, even when integrated with advanced node
features. In contrast, we discover that decomposing these edges into distinct
semantic relations significantly enhances the performance of GNNs. Despite
this, manually identifying and labeling of edges to corresponding semantic
relations is labor-intensive, often requiring domain expertise. To this end, we
introduce RoSE (Relation-oriented Semantic Edge-decomposition), a novel
framework that leverages the capability of Large Language Models (LLMs) to
decompose the graph structure by analyzing raw text attributes - in a fully
automated manner. RoSE operates in two stages: (1) identifying meaningful
relations using an LLM-based generator and discriminator, and (2) categorizing
each edge into corresponding relations by analyzing textual contents associated
with connected nodes via an LLM-based decomposer. Extensive experiments
demonstrate that our model-agnostic framework significantly enhances node
classification performance across various datasets, with improvements of up to
16% on the Wisconsin dataset.

ÊëòË¶ÅÔºöÊñáÊú¨Â±ûÊÄßÂõæ (TAG) ÁöÑÊúÄÊñ∞ËøõÂ±ïÊòæËëóÊèêÂçá‰∫ÜËäÇÁÇπÁâπÂæÅÁöÑË¥®ÈáèÔºåÊñπÊ≥ïÊòØÂà©Áî®ËØ≠Ë®ÄÊ®°ÂûãÁöÑÊñáÊú¨Âª∫Ê®°ËÉΩÂäõ„ÄÇÂ∞ΩÁÆ°ÂèñÂæó‰∫ÜËøô‰∏ÄÊàêÂäüÔºå‰ΩÜÂà©Áî®ÊñáÊú¨Â±ûÊÄßÊù•Â¢ûÂº∫È¢ÑÂÆö‰πâÁöÑÂõæÁªìÊûÑÂú®ÂæàÂ§ßÁ®ãÂ∫¶‰∏ä‰ªçÊú™ÂæóÂà∞Êé¢Á¥¢„ÄÇÊàë‰ª¨ÁöÑÂπøÊ≥õÂàÜÊûêË°®ÊòéÔºåTAG ‰∏äÁöÑ‰º†ÁªüËæπÂú®ÂÖàÂâçÁöÑÊñáÁåÆ‰∏≠Ë¢´ËßÜ‰∏∫Âçï‰∏ÄÂÖ≥Á≥ªÔºà‰æãÂ¶ÇË∂ÖÈìæÊé•ÔºâÔºåÂÆûÈôÖ‰∏äÂåÖÂê´Ê∑∑ÂêàËØ≠‰πâÔºà‰æãÂ¶Ç‚ÄúÂª∫ËÆÆ‚ÄùÂíå‚ÄúÂèÇ‰∏é‚ÄùÔºâ„ÄÇËøôÁßçÁÆÄÂåñÈòªÁ¢ç‰∫ÜÂõæÁ•ûÁªèÁΩëÁªú (GNN) Âú®‰∏ãÊ∏∏‰ªªÂä°‰∏≠ÁöÑË°®Á§∫Â≠¶‰π†ËøáÁ®ãÔºåÂç≥‰Ωø‰∏éÈ´òÁ∫ßËäÇÁÇπÁâπÂæÅÈõÜÊàê‰πüÊòØÂ¶ÇÊ≠§„ÄÇÁõ∏ÊØî‰πã‰∏ãÔºåÊàë‰ª¨ÂèëÁé∞Â∞ÜËøô‰∫õËæπÂàÜËß£‰∏∫‰∏çÂêåÁöÑËØ≠‰πâÂÖ≥Á≥ª‰ºöÊòæËëóÂ¢ûÂº∫ GNN ÁöÑÊÄßËÉΩ„ÄÇÂ∞ΩÁÆ°Â¶ÇÊ≠§ÔºåÊâãÂä®ËØÜÂà´ÂíåÊ†áËÆ∞ÂØπÂ∫îËØ≠‰πâÂÖ≥Á≥ªÁöÑËæπÊòØ‰∏ÄÈ°πÂä≥Âä®ÂØÜÈõÜÂûãÂ∑•‰ΩúÔºåÈÄöÂ∏∏ÈúÄË¶ÅÈ¢ÜÂüü‰∏ì‰∏öÁü•ËØÜ„ÄÇ‰∏∫Ê≠§ÔºåÊàë‰ª¨ÂºïÂÖ•‰∫Ü RoSEÔºàÈù¢ÂêëÂÖ≥Á≥ªÁöÑËØ≠‰πâËæπÂàÜËß£ÔºâÔºåËøôÊòØ‰∏Ä‰∏™Êñ∞È¢ñÁöÑÊ°ÜÊû∂ÔºåÂÆÉÂà©Áî®Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã (LLM) ÁöÑËÉΩÂäõ‰ª•ÂÖ®Ëá™Âä®ÁöÑÊñπÂºèÈÄöËøáÂàÜÊûêÂéüÂßãÊñáÊú¨Â±ûÊÄßÊù•ÂàÜËß£ÂõæÁªìÊûÑ„ÄÇRoSE ÂàÜ‰∏∫‰∏§‰∏™Èò∂ÊÆµÔºöÔºà1Ôºâ‰ΩøÁî®Âü∫‰∫é LLM ÁöÑÁîüÊàêÂô®ÂíåÈâ¥Âà´Âô®ËØÜÂà´ÊúâÊÑè‰πâÁöÑÂÖ≥Á≥ªÔºå‰ª•ÂèäÔºà2ÔºâÈÄöËøáÂü∫‰∫é LLM ÁöÑÂàÜËß£Âô®ÂàÜÊûê‰∏éËøûÊé•ËäÇÁÇπÂÖ≥ËÅîÁöÑÊñáÊú¨ÂÜÖÂÆπÔºåÂ∞ÜÊØè‰∏™ËæπÂàÜÁ±ªÂà∞Áõ∏Â∫îÁöÑËØ≠‰πâÂÖ≥Á≥ª‰∏≠„ÄÇÂπøÊ≥õÁöÑÂÆûÈ™åË°®ÊòéÔºåÊàë‰ª¨ÁöÑÊ®°ÂûãÊó†ÂÖ≥Ê°ÜÊû∂ÊòæËëóÂ¢ûÂº∫‰∫ÜÂêÑ‰∏™Êï∞ÊçÆÈõÜ‰∏äÁöÑËäÇÁÇπÂàÜÁ±ªÊÄßËÉΩÔºåÂú® Wisconsin Êï∞ÊçÆÈõÜ‰∏äÊèêÈ´ò‰∫Ü 16%„ÄÇ

##### **Don't Forget to Connect! Improving RAG with Graph-based Reranking**
2405.18414v1 by Jialin Dong, Bahare Fatemi, Bryan Perozzi, Lin F. Yang, Anton Tsitsulin

Retrieval Augmented Generation (RAG) has greatly improved the performance of
Large Language Model (LLM) responses by grounding generation with context from
existing documents. These systems work well when documents are clearly relevant
to a question context. But what about when a document has partial information,
or less obvious connections to the context? And how should we reason about
connections between documents? In this work, we seek to answer these two core
questions about RAG generation. We introduce G-RAG, a reranker based on graph
neural networks (GNNs) between the retriever and reader in RAG. Our method
combines both connections between documents and semantic information (via
Abstract Meaning Representation graphs) to provide a context-informed ranker
for RAG. G-RAG outperforms state-of-the-art approaches while having smaller
computational footprint. Additionally, we assess the performance of PaLM 2 as a
reranker and find it to significantly underperform G-RAG. This result
emphasizes the importance of reranking for RAG even when using Large Language
Models.

ÊëòË¶ÅÔºöÊ™¢Á¥¢Â¢ûÂº∑ÁîüÊàê (RAG) Â∑≤Â§ßÂπÖÊèêÂçáÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂõûÊáâÁöÑÊïàËÉΩÔºåÊñπÊ≥ïÊòØÂ∞áÁîüÊàêÂü∫Á§éÊñºÁèæÊúâÊñá‰ª∂‰∏≠ÁöÑÂÖßÂÆπ„ÄÇÁï∂Êñá‰ª∂ËàáÂïèÈ°åÂÖßÂÆπÊòéÁ¢∫Áõ∏ÈóúÊôÇÔºåÈÄô‰∫õÁ≥ªÁµ±ÈÅã‰ΩúËâØÂ•Ω„ÄÇ‰ΩÜÁï∂Êñá‰ª∂ÊúâÈÉ®ÂàÜË≥áË®äÊàñËàáÂÖßÂÆπÁöÑÈóúËÅØÊÄßËºÉ‰∏çÈ°ØËëóÊôÇÂë¢ÔºüÊàëÂÄëÂèàË©≤Â¶Ç‰ΩïÊé®Ë´ñÊñá‰ª∂‰πãÈñìÁöÑÈóúËÅØÊÄßÔºüÂú®ÈÄôÈ†ÖÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄëÂ∞ãÊ±ÇÂõûÁ≠îÈÄôÂÖ©ÂÄãÈóúÊñº RAG ÁîüÊàêÁöÑÊ†∏ÂøÉÂïèÈ°å„ÄÇÊàëÂÄëÂºïÂÖ•‰∫Ü G-RAGÔºå‰∏ÄÁ®ÆÂü∫Êñº RAG ‰∏≠Ê™¢Á¥¢Âô®ÂíåËÆÄÂèñÂô®‰πãÈñìÁöÑÂúñÂΩ¢Á•ûÁ∂ìÁ∂≤Ë∑Ø (GNN) ÁöÑÈáçÊñ∞ÊéíÂ∫èÂô®„ÄÇÊàëÂÄëÁöÑÊäÄË°ìÁµêÂêà‰∫ÜÊñá‰ª∂‰πãÈñìÁöÑÈóúËÅØÊÄßËàáË™ûÁæ©Ë≥áË®äÔºàÈÄèÈÅéÊäΩË±°ÊÑèÁæ©Ë°®ÂæµÂúñÂΩ¢ÔºâÔºåÁÇ∫ RAG Êèê‰æõ‰∏ÄÂÄãÊúâËÑàÁµ°ÁöÑÊéíÂ∫èÂô®„ÄÇG-RAG ÁöÑË°®ÁèæË∂ÖË∂äÁèæÊúâÊäÄË°ìÔºåÂêåÊôÇÈÅãÁÆóË≥áÊ∫êÈúÄÊ±ÇËºÉÂ∞è„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëË©ï‰º∞‰∫Ü PaLM 2 ‰ΩúÁÇ∫ÈáçÊñ∞ÊéíÂ∫èÂô®ÁöÑË°®ÁèæÔºåÁôºÁèæÂÖ∂Ë°®ÁèæÈ°ØËëó‰ΩéÊñº G-RAG„ÄÇÈÄôÂÄãÁµêÊûúÂº∑Ë™ø‰∫ÜÈáçÊñ∞ÊéíÂ∫èÂ∞ç RAG ÁöÑÈáçË¶ÅÊÄßÔºåÂç≥‰ΩøÂú®‰ΩøÁî®Â§ßÂûãË™ûË®ÄÊ®°ÂûãÊôÇ‰πüÊòØÂ¶ÇÊ≠§„ÄÇ

##### **Knowledge Circuits in Pretrained Transformers**
2405.17969v1 by Yunzhi Yao, Ningyu Zhang, Zekun Xi, Mengru Wang, Ziwen Xu, Shumin Deng, Huajun Chen

The remarkable capabilities of modern large language models are rooted in
their vast repositories of knowledge encoded within their parameters, enabling
them to perceive the world and engage in reasoning. The inner workings of how
these models store knowledge have long been a subject of intense interest and
investigation among researchers. To date, most studies have concentrated on
isolated components within these models, such as the Multilayer Perceptrons and
attention head. In this paper, we delve into the computation graph of the
language model to uncover the knowledge circuits that are instrumental in
articulating specific knowledge. The experiments, conducted with GPT2 and
TinyLLAMA, has allowed us to observe how certain information heads, relation
heads, and Multilayer Perceptrons collaboratively encode knowledge within the
model. Moreover, we evaluate the impact of current knowledge editing techniques
on these knowledge circuits, providing deeper insights into the functioning and
constraints of these editing methodologies. Finally, we utilize knowledge
circuits to analyze and interpret language model behaviors such as
hallucinations and in-context learning. We believe the knowledge circuit holds
potential for advancing our understanding of Transformers and guiding the
improved design of knowledge editing. Code and data are available in
https://github.com/zjunlp/KnowledgeCircuits.

ÊëòË¶ÅÔºöÁèæ‰ª£Â§ßÂûãË™ûË®ÄÊ®°ÂûãÁöÑÂçìË∂äËÉΩÂäõÊ∫êÊñºÂÖ∂ÂèÉÊï∏‰∏≠Á∑®Á¢ºÁöÑÈæêÂ§ßÁü•Ë≠òÂ∫´ÔºåËÆìÂÆÉÂÄëËÉΩÂ§†ÊÑüÁü•‰∏ñÁïå‰∏¶ÂèÉËàáÊé®ÁêÜ„ÄÇÈÄô‰∫õÊ®°ÂûãÂ¶Ç‰ΩïÂÑ≤Â≠òÁü•Ë≠òÁöÑÂÖßÈÉ®ÈÅã‰ΩúÊñπÂºè‰∏ÄÁõ¥ÊòØÁ†îÁ©∂‰∫∫Âì°È´òÂ∫¶ÈóúÊ≥®ÂíåÁ†îÁ©∂ÁöÑ‰∏ªÈ°å„ÄÇËøÑ‰ªäÁÇ∫Ê≠¢ÔºåÂ§ßÂ§öÊï∏Á†îÁ©∂ÈÉΩÈõÜ‰∏≠Âú®ÈÄô‰∫õÊ®°Âûã‰∏≠ÁöÑÂ≠§Á´ãÂÖÉ‰ª∂Ôºå‰æãÂ¶ÇÂ§öÂ±§ÊÑüÁü•Âô®ÂíåÊ≥®ÊÑèÂäõÈ†≠„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊ∑±ÂÖ•Êé¢Ë®éË™ûË®ÄÊ®°ÂûãÁöÑË®àÁÆóÂúñÔºå‰ª•Êè≠Á§∫Ë°®ÈÅîÁâπÂÆöÁü•Ë≠ò‰∏≠Ëá≥ÈóúÈáçË¶ÅÁöÑÁü•Ë≠òÈõªË∑Ø„ÄÇ‰ΩøÁî® GPT2 Âíå TinyLLAMA ÈÄ≤Ë°åÁöÑÂØ¶È©óËÆìÊàëÂÄëËÉΩÂ§†ËßÄÂØüÊüê‰∫õË≥áË®äÈ†≠„ÄÅÈóú‰øÇÈ†≠ÂíåÂ§öÂ±§ÊÑüÁü•Âô®Â¶Ç‰ΩïÂú®Ê®°Âûã‰∏≠ÂçîÂêåÁ∑®Á¢ºÁü•Ë≠ò„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëË©ï‰º∞‰∫ÜÁï∂ÂâçÁü•Ë≠òÁ∑®ËºØÊäÄË°ìÂ∞çÈÄô‰∫õÁü•Ë≠òÈõªË∑ØÁöÑÂΩ±ÈüøÔºåÂ∞çÈÄô‰∫õÁ∑®ËºØÊñπÊ≥ïÁöÑÂäüËÉΩÂíåÈôêÂà∂Êèê‰æõ‰∫ÜÊõ¥Ê∑±ÂÖ•ÁöÑË¶ãËß£„ÄÇÊúÄÂæåÔºåÊàëÂÄëÂà©Áî®Áü•Ë≠òÈõªË∑ØÂàÜÊûêÂíåË©ÆÈáãË™ûË®ÄÊ®°ÂûãË°åÁÇ∫Ôºå‰æãÂ¶ÇÂπªË¶∫ÂíåÊÉÖÂ¢ÉÂ≠∏Áøí„ÄÇÊàëÂÄëÁõ∏‰ø°Áü•Ë≠òÈõªË∑ØÊúâÊΩõÂäõ‰øÉÈÄ≤ÊàëÂÄëÂ∞ç Transformer ÁöÑÁêÜËß£Ôºå‰∏¶ÊåáÂ∞éÁü•Ë≠òÁ∑®ËºØÁöÑÊîπÈÄ≤Ë®≠Ë®à„ÄÇ‰ª£Á¢ºÂíåË≥áÊñôÂèØÂú® https://github.com/zjunlp/KnowledgeCircuits ‰∏≠ÂèñÂæó„ÄÇ

##### **Safety Control of Service Robots with LLMs and Embodied Knowledge Graphs**
2405.17846v1 by Yong Qi, Gabriel Kyebambo, Siyuan Xie, Wei Shen, Shenghui Wang, Bitao Xie, Bin He, Zhipeng Wang, Shuo Jiang

Safety limitations in service robotics across various industries have raised
significant concerns about the need for robust mechanisms ensuring that robots
adhere to safe practices, thereby preventing actions that might harm humans or
cause property damage. Despite advances, including the integration of Knowledge
Graphs (KGs) with Large Language Models (LLMs), challenges in ensuring
consistent safety in autonomous robot actions persist. In this paper, we
propose a novel integration of Large Language Models with Embodied Robotic
Control Prompts (ERCPs) and Embodied Knowledge Graphs (EKGs) to enhance the
safety framework for service robots. ERCPs are designed as predefined
instructions that ensure LLMs generate safe and precise responses. These
responses are subsequently validated by EKGs, which provide a comprehensive
knowledge base ensuring that the actions of the robot are continuously aligned
with safety protocols, thereby promoting safer operational practices in varied
contexts. Our experimental setup involved diverse real-world tasks, where
robots equipped with our framework demonstrated significantly higher compliance
with safety standards compared to traditional methods. This integration fosters
secure human-robot interactions and positions our methodology at the forefront
of AI-driven safety innovations in service robotics.

ÊëòË¶ÅÔºöÂêÑÁî¢Ê•≠‰∏≠ÁöÑÊúçÂãôÊ©üÂô®‰∫∫ÂÆâÂÖ®ÈôêÂà∂Â∑≤ÂºïÁôºÈáçÂ§ßÁñëÊÖÆÔºåË™çÁÇ∫ÊúâÂøÖË¶ÅÂª∫Á´ãÂº∑ÂÅ•ÁöÑÊ©üÂà∂ÔºåÁ¢∫‰øùÊ©üÂô®‰∫∫ÈÅµÂÆàÂÆâÂÖ®Ë¶èÁØÑÔºåÈÄ≤ËÄåÈò≤Ê≠¢ÂèØËÉΩÂÇ∑ÂÆ≥‰∫∫È°ûÊàñÈÄ†ÊàêË≤°Áî¢ÊêçÂ§±ÁöÑË°åÁÇ∫„ÄÇÂÑòÁÆ°ÊúâÈÄ≤Â±ïÔºåÂåÖÊã¨Â∞áÁü•Ë≠òÂúñË≠ú (KG) ËàáÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Êï¥ÂêàÔºå‰ΩÜ‰ªçÊúâÊåëÊà∞Â≠òÂú®ÊñºÁ¢∫‰øùËá™‰∏ªÊ©üÂô®‰∫∫Ë°åÁÇ∫ÁöÑ‰∏ÄËá¥ÊÄßÂÆâÂÖ®„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫Â∞áÂ§ßÂûãË™ûË®ÄÊ®°ÂûãËàáÂÖ∑È´îÊ©üÂô®‰∫∫ÊéßÂà∂ÊèêÁ§∫ (ERCP) ÂíåÂÖ∑È´îÁü•Ë≠òÂúñË≠ú (EKG) ÈÄ≤Ë°åÂâµÊñ∞Êï¥ÂêàÔºå‰ª•Â¢ûÂº∑ÊúçÂãôÊ©üÂô®‰∫∫ÁöÑÂÆâÂÖ®Êû∂Êßã„ÄÇERCP Ë¢´Ë®≠Ë®àÁÇ∫È†êÂÖàÂÆöÁæ©ÁöÑÊåá‰ª§ÔºåÂèØÁ¢∫‰øù LLM Áî¢ÁîüÂÆâÂÖ®‰∏îÁ≤æÁ¢∫ÁöÑÂõûÊáâ„ÄÇÈÄô‰∫õÂõûÊáâÈö®ÂæåÁî± EKG È©óË≠âÔºåEKG Êèê‰æõ‰∫Ü‰∏ÄÂÄãÂÖ®Èù¢ÁöÑÁü•Ë≠òÂ∫´ÔºåÁ¢∫‰øùÊ©üÂô®‰∫∫ÁöÑË°åÁÇ∫ÊåÅÁ∫åÁ¨¶ÂêàÂÆâÂÖ®ÂçîÂÆöÔºåÈÄ≤ËÄå‰øÉÈÄ≤Âú®ÂêÑÁ®ÆÊÉÖÂ¢É‰∏≠Êõ¥ÂÆâÂÖ®ÁöÑÈÅã‰ΩúÂØ¶Âãô„ÄÇÊàëÂÄëÁöÑÂØ¶È©óË®≠ÁΩÆÊ∂âÂèäÂ§öÊ®£ÂåñÁöÑÁúüÂØ¶‰∏ñÁïå‰ªªÂãôÔºåÈÖçÂÇôÊàëÂÄëÊû∂ÊßãÁöÑÊ©üÂô®‰∫∫ËàáÂÇ≥Áµ±ÊñπÊ≥ïÁõ∏ÊØîÔºåÂ±ïÁèæÂá∫È°ØËëóÊõ¥È´òÁöÑÂÆâÂÖ®Ê®ôÊ∫ñÈÅµÂæ™Â∫¶„ÄÇÊ≠§Êï¥Âêà‰øÉÈÄ≤‰∫ÜÂÆâÂÖ®ÁöÑ‰∫∫Ê©ü‰∫íÂãïÔºå‰∏¶Â∞áÊàëÂÄëÁöÑÊäÄË°ìÂÆö‰ΩçÊñºÊúçÂãôÊ©üÂô®‰∫∫‰∏≠ AI È©ÖÂãïÂÆâÂÖ®ÂâµÊñ∞ÁöÑÊúÄÂâçÁ∑ö„ÄÇ

##### **Cost-efficient Knowledge-based Question Answering with Large Language Models**
2405.17337v1 by Junnan Dong, Qinggang Zhang, Chuang Zhou, Hao Chen, Daochen Zha, Xiao Huang

Knowledge-based question answering (KBQA) is widely used in many scenarios
that necessitate domain knowledge. Large language models (LLMs) bring
opportunities to KBQA, while their costs are significantly higher and absence
of domain-specific knowledge during pre-training. We are motivated to combine
LLMs and prior small models on knowledge graphs (KGMs) for both inferential
accuracy and cost saving. However, it remains challenging since accuracy and
cost are not readily combined in the optimization as two distinct metrics. It
is also laborious for model selection since different models excel in diverse
knowledge. To this end, we propose Coke, a novel cost-efficient strategy for
KBQA with LLMs, modeled as a tailored multi-armed bandit problem to minimize
calls to LLMs within limited budgets. We first formulate the accuracy
expectation with a cluster-level Thompson Sampling for either KGMs or LLMs. A
context-aware policy is optimized to further distinguish the expert model
subject to the question semantics. The overall decision is bounded by the cost
regret according to historical expenditure on failures. Extensive experiments
showcase the superior performance of Coke, which moves the Pareto frontier with
up to 20.89% saving of GPT-4 fees while achieving a 2.74% higher accuracy on
the benchmark datasets.

ÊëòË¶ÅÔºö<paragraph>Âü∫ÊñºÁü•Ë≠òÁöÑÂïèÁ≠î (KBQA) Âª£Ê≥õÊáâÁî®ÊñºË®±Â§öÈúÄË¶ÅÈ†òÂüüÁü•Ë≠òÁöÑÂ†¥ÊôØ‰∏≠„ÄÇÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁÇ∫ KBQA Â∏∂‰æÜ‰∫ÜÊ©üÊúÉÔºå‰ΩÜÂÖ∂ÊàêÊú¨È°ØËëóÊèêÈ´òÔºå‰∏îÂú®È†êË®ìÁ∑¥ÊúüÈñìÁº∫‰πèÁâπÂÆöÈ†òÂüüÁöÑÁü•Ë≠ò„ÄÇÊàëÂÄëÊúâÂãïÂäõÂ∞á LLM ÂíåÂÖàÂâçÁöÑÁü•Ë≠òÂúñË≠ú (KGM) ‰∏äÁöÑÂ∞èÊ®°ÂûãÁµêÂêàËµ∑‰æÜÔºå‰ª•ÊèêÈ´òÊé®ÁêÜÊ∫ñÁ¢∫ÊÄßÂíåÁØÄÁúÅÊàêÊú¨„ÄÇÁÑ∂ËÄåÔºåÁî±ÊñºÊ∫ñÁ¢∫ÊÄßÂíåÊàêÊú¨ÁÑ°Ê≥ïÂú®ÂÑ™Âåñ‰∏≠‰ΩúÁÇ∫ÂÖ©ÂÄã‰∏çÂêåÁöÑÊåáÊ®ôËºïÊòìÂú∞ÁµêÂêàÂú®‰∏ÄËµ∑ÔºåÂõ†Ê≠§ÈÄô‰ªçÁÑ∂ÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÁî±Êñº‰∏çÂêåÁöÑÊ®°ÂûãÊìÖÈï∑Êñº‰∏çÂêåÁöÑÁü•Ë≠òÔºåÂõ†Ê≠§Ê®°ÂûãÈÅ∏Êìá‰πüÂæàË≤ªÂäõ„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü CokeÔºå‰∏ÄÁ®ÆÈáùÂ∞ç LLM ÁöÑÊñ∞Á©é‰∏îÂÖ∑ÊúâÊàêÊú¨ÊïàÁõäÁöÑ KBQA Á≠ñÁï•ÔºåÂÆÉË¢´Âª∫Ê®°ÁÇ∫‰∏ÄÂÄãÂÆöÂà∂ÁöÑÂ§öËáÇË≥≠ÂçöÊ©üÂïèÈ°åÔºå‰ª•Âú®ÊúâÈôêÁöÑÈ†êÁÆóÂÖßÊúÄÂ§ßÁ®ãÂ∫¶Âú∞Ê∏õÂ∞ëÂ∞ç LLM ÁöÑÂëºÂè´„ÄÇÊàëÂÄëÈ¶ñÂÖà‰ΩøÁî®ÈáùÂ∞ç KGM Êàñ LLM ÁöÑÁæ§ÈõÜÁ¥ö Thompson Êé°Ê®£‰æÜÂà∂ÂÆöÊ∫ñÁ¢∫ÊÄßÊúüÊúõ„ÄÇÂÑ™Âåñ‰∫Ü‰∏ÄÂÄã‰∏ä‰∏ãÊñáÊÑüÁü•Á≠ñÁï•Ôºå‰ª•ÈÄ≤‰∏ÄÊ≠•ÂçÄÂàÜÂïèÈ°åË™ûÁæ©ÁöÑ‰∏ªÈ°åÊ®°Âûã„ÄÇÊ†πÊìöÂ§±ÊïóÁöÑÊ≠∑Âè≤ÊîØÂá∫ÔºåÁ∏ΩÈ´îÊ±∫Á≠ñÂèóÂà∞ÊàêÊú¨ÈÅ∫ÊÜæÁöÑÁ¥ÑÊùü„ÄÇÂ§ßÈáèÁöÑÂØ¶È©óÂ±ïÁ§∫‰∫Ü Coke ÁöÑÂÑ™Ë∂äÊÄßËÉΩÔºåÂÆÉÂ∞áÂ∏ïÁ¥ØÊâòÂâçÊ≤øÁßªÂãï‰∫ÜÂ§öÈÅî 20.89%ÔºåÂêåÊôÇÂú®Âü∫Ê∫ñÊï∏ÊìöÈõÜ‰∏äÂØ¶Áèæ‰∫Ü 2.74% ÁöÑÊõ¥È´òÊ∫ñÁ¢∫ÊÄß„ÄÇ</paragraph>

##### **Assessing LLMs Suitability for Knowledge Graph Completion**
2405.17249v1 by Vasile Ionut Remus Iga, Gheorghe Cosmin Silaghi

Recent work shown the capability of Large Language Models (LLMs) to solve
tasks related to Knowledge Graphs, such as Knowledge Graph Completion, even in
Zero- or Few-Shot paradigms. However, they are known to hallucinate answers, or
output results in a non-deterministic manner, thus leading to wrongly reasoned
responses, even if they satisfy the user's demands. To highlight opportunities
and challenges in knowledge graphs-related tasks, we experiment with two
distinguished LLMs, namely Mixtral-8x7B-Instruct-v0.1, and gpt-3.5-turbo-0125,
on Knowledge Graph Completion for static knowledge graphs, using prompts
constructed following the TELeR taxonomy, in Zero- and One-Shot contexts, on a
Task-Oriented Dialogue system use case. When evaluated using both strict and
flexible metrics measurement manners, our results show that LLMs could be fit
for such a task if prompts encapsulate sufficient information and relevant
examples.

ÊëòË¶ÅÔºöÊúÄËøëÁöÑÁ†îÁ©∂ÊòæÁ§∫ÔºåÂ§ßÂûãËØ≠Ë®ÄÊ®°Âûã (LLM) ÂÖ∑Â§áËß£ÂÜ≥Áü•ËØÜÂõæË∞±Áõ∏ÂÖ≥‰ªªÂä°ÁöÑËÉΩÂäõÔºå‰æãÂ¶ÇÁü•ËØÜÂõæË∞±Ë°•ÂÖ®ÔºåÂç≥‰ΩøÂú®Èõ∂Ê¨°ÊàñÂ∞èÊ†∑Êú¨ÁöÑÊÉÖÂÜµ‰∏ã‰πüÊòØÂ¶ÇÊ≠§„ÄÇÁÑ∂ËÄåÔºå‰ºóÊâÄÂë®Áü•ÔºåÂÆÉ‰ª¨‰ºö‰∫ßÁîüÂπªËßâÁ≠îÊ°àÔºåÊàñ‰ª•ÈùûÁ°ÆÂÆöÊÄßÁöÑÊñπÂºèËæìÂá∫ÁªìÊûúÔºå‰ªéËÄåÂØºËá¥Êé®ÁêÜÈîôËØØÁöÑÂìçÂ∫îÔºåÂç≥‰ΩøÂÆÉ‰ª¨Êª°Ë∂≥‰∫ÜÁî®Êà∑ÁöÑÈúÄÊ±Ç„ÄÇ‰∏∫‰∫ÜÁ™ÅÂá∫Áü•ËØÜÂõæË∞±Áõ∏ÂÖ≥‰ªªÂä°‰∏≠ÁöÑÊú∫ÈÅáÂíåÊåëÊàòÔºåÊàë‰ª¨ÂØπ‰∏§ÁßçÊù∞Âá∫ÁöÑ LLM ËøõË°å‰∫ÜÂÆûÈ™åÔºåÂàÜÂà´ÊòØ Mixtral-8x7B-Instruct-v0.1 Âíå gpt-3.5-turbo-0125ÔºåÂú®ÈùôÊÄÅÁü•ËØÜÂõæË∞±ÁöÑÁü•ËØÜÂõæË∞±Ë°•ÂÖ®‰∏äÔºå‰ΩøÁî®Ê†πÊçÆ TELeR ÂàÜÁ±ªÊ≥ïÊûÑÂª∫ÁöÑÊèêÁ§∫ÔºåÂú®Èõ∂Ê¨°Âíå‰∏ÄÊ¨°‰∏ä‰∏ãÊñá‰∏≠ÔºåÂú®Èù¢Âêë‰ªªÂä°ÁöÑÂØπËØùÁ≥ªÁªüÁî®‰æã‰∏≠„ÄÇÂΩì‰ΩøÁî®‰∏•Ê†ºÂíåÁÅµÊ¥ªÁöÑÂ∫¶ÈáèÊñπÂºèËøõË°åËØÑ‰º∞Êó∂ÔºåÊàë‰ª¨ÁöÑÁªìÊûúË°®ÊòéÔºåÂ¶ÇÊûúÊèêÁ§∫ÂåÖÂê´Ë∂≥Â§üÁöÑ‰ø°ÊÅØÂíåÁõ∏ÂÖ≥Á§∫‰æãÔºåÂàô LLM ÈÄÇÁî®‰∫éÊ≠§Á±ª‰ªªÂä°„ÄÇ

##### **Empowering Large Language Models to Set up a Knowledge Retrieval Indexer via Self-Learning**
2405.16933v1 by Xun Liang, Simin Niu, Zhiyu li, Sensen Zhang, Shichao Song, Hanyu Wang, Jiawei Yang, Feiyu Xiong, Bo Tang, Chenyang Xi

Retrieval-Augmented Generation (RAG) offers a cost-effective approach to
injecting real-time knowledge into large language models (LLMs). Nevertheless,
constructing and validating high-quality knowledge repositories require
considerable effort. We propose a pre-retrieval framework named Pseudo-Graph
Retrieval-Augmented Generation (PG-RAG), which conceptualizes LLMs as students
by providing them with abundant raw reading materials and encouraging them to
engage in autonomous reading to record factual information in their own words.
The resulting concise, well-organized mental indices are interconnected through
common topics or complementary facts to form a pseudo-graph database. During
the retrieval phase, PG-RAG mimics the human behavior in flipping through
notes, identifying fact paths and subsequently exploring the related contexts.
Adhering to the principle of the path taken by many is the best, it integrates
highly corroborated fact paths to provide a structured and refined sub-graph
assisting LLMs. We validated PG-RAG on three specialized question-answering
datasets. In single-document tasks, PG-RAG significantly outperformed the
current best baseline, KGP-LLaMA, across all key evaluation metrics, with an
average overall performance improvement of 11.6%. Specifically, its BLEU score
increased by approximately 14.3%, and the QE-F1 metric improved by 23.7%. In
multi-document scenarios, the average metrics of PG-RAG were at least 2.35%
higher than the best baseline. Notably, the BLEU score and QE-F1 metric showed
stable improvements of around 7.55% and 12.75%, respectively. Our code:
https://github.com/IAAR-Shanghai/PGRAG.

ÊëòË¶ÅÔºö<paragraph>Ê™¢Á¥¢Â¢ûÂº∑ÁîüÊàêÔºàRAGÔºâÊèê‰æõ‰∫Ü‰∏ÄÁ®ÆÂÖ∑ÊàêÊú¨ÊïàÁõäÁöÑÊñπÊ≥ïÔºåÂèØ‰ª•Â∞áÂç≥ÊôÇÁü•Ë≠òÊ≥®ÂÖ•Â§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâ„ÄÇÂÑòÁÆ°Â¶ÇÊ≠§ÔºåÂª∫ÊßãÂíåÈ©óË≠âÈ´òÂìÅË≥™ÁöÑÁü•Ë≠òÂÑ≤Â≠òÂ∫´ÈúÄË¶ÅÁõ∏Áï∂Â§ßÁöÑÂä™Âäõ„ÄÇÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂêçÁÇ∫ÂÅΩÂúñÂΩ¢Ê™¢Á¥¢Â¢ûÂº∑ÁîüÊàêÔºàPG-RAGÔºâÁöÑÈ†êÊ™¢Á¥¢Êû∂ÊßãÔºåÂÆÉÂ∞á LLM Ê¶ÇÂøµÂåñÁÇ∫Â≠∏ÁîüÔºåÁÇ∫‰ªñÂÄëÊèê‰æõË±êÂØåÁöÑÂéüÂßãÈñ±ËÆÄÊùêÊñôÔºå‰∏¶ÈºìÂãµ‰ªñÂÄëÂæû‰∫ãËá™‰∏ªÈñ±ËÆÄÔºåÁî®Ëá™Â∑±ÁöÑË©±Ë®òÈåÑ‰∫ãÂØ¶Ë≥áË®ä„ÄÇÁî±Ê≠§Áî¢ÁîüÁöÑÁ∞°ÊΩî„ÄÅÁµÑÁπîËâØÂ•ΩÁöÑÂøÉÊô∫Á¥¢ÂºïÈÄöÈÅéÂÖ±ÂêåÁöÑ‰∏ªÈ°åÊàñË£úÂÖÖ‰∫ãÂØ¶Áõ∏‰∫íÈÄ£Êé•ÔºåÂΩ¢Êàê‰∏ÄÂÄãÂÅΩÂúñÂΩ¢Ë≥áÊñôÂ∫´„ÄÇÂú®Ê™¢Á¥¢ÈöéÊÆµÔºåPG-RAG Ê®°‰ªø‰∫∫È°ûÂú®ÁøªÈñ±Á≠ÜË®ò„ÄÅË≠òÂà•‰∫ãÂØ¶Ë∑ØÂæë‰∏¶Èö®ÂæåÊé¢Á¥¢Áõ∏ÈóúËÉåÊôØ‰∏≠ÁöÑË°åÁÇ∫„ÄÇÈÅµÂæ™Áúæ‰∫∫Ëµ∞ÁöÑË∑ØÊòØÊúÄÂ•ΩÁöÑÂéüÂâáÔºåÂÆÉÊï¥Âêà‰∫ÜÈ´òÂ∫¶Ë≠âÂØ¶ÁöÑ‰∫ãÂØ¶Ë∑ØÂæëÔºå‰ª•Êèê‰æõ‰∏ÄÂÄãÁµêÊßãÂåñ‰∏îÁ≤æÁÖâÁöÑÂ≠êÂúñÔºåÂçîÂä© LLM„ÄÇÊàëÂÄëÂú®‰∏âÂÄãÂ∞àÊ•≠ÂïèÁ≠îË≥áÊñôÈõÜ‰∏äÈ©óË≠â‰∫Ü PG-RAG„ÄÇÂú®ÂñÆ‰∏ÄÊñá‰ª∂‰ªªÂãô‰∏≠ÔºåPG-RAG Âú®ÊâÄÊúâÈóúÈçµË©ï‰º∞ÊåáÊ®ô‰∏äÈÉΩÈ°ØËëóÂÑ™ÊñºÁõÆÂâçÁöÑÊúÄ‰Ω≥Âü∫Ê∫ñ KGP-LLaMAÔºåÂπ≥ÂùáÊï¥È´îÊïàËÉΩÊèêÂçá‰∫Ü 11.6%„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÂÆÉÁöÑ BLEU ÂàÜÊï∏ÊèêÈ´ò‰∫ÜÂ§ßÁ¥Ñ 14.3%ÔºåQE-F1 ÊåáÊ®ôÊèêÈ´ò‰∫Ü 23.7%„ÄÇÂú®Â§öÊñá‰ª∂Â†¥ÊôØ‰∏≠ÔºåPG-RAG ÁöÑÂπ≥ÂùáÊåáÊ®ôËá≥Â∞ëÊØîÊúÄ‰Ω≥Âü∫Ê∫ñÈ´ò 2.35%„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåBLEU ÂàÜÊï∏Âíå QE-F1 ÊåáÊ®ôÂàÜÂà•È°ØÁ§∫Âá∫Á¥Ñ 7.55% Âíå 12.75% ÁöÑÁ©©ÂÆöÊèêÂçá„ÄÇÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÔºöhttps://github.com/IAAR-Shanghai/PGRAG„ÄÇ</paragraph>

##### **Entity Alignment with Noisy Annotations from Large Language Models**
2405.16806v2 by Shengyuan Chen, Qinggang Zhang, Junnan Dong, Wen Hua, Qing Li, Xiao Huang

Entity alignment (EA) aims to merge two knowledge graphs (KGs) by identifying
equivalent entity pairs. While existing methods heavily rely on human-generated
labels, it is prohibitively expensive to incorporate cross-domain experts for
annotation in real-world scenarios. The advent of Large Language Models (LLMs)
presents new avenues for automating EA with annotations, inspired by their
comprehensive capability to process semantic information. However, it is
nontrivial to directly apply LLMs for EA since the annotation space in
real-world KGs is large. LLMs could also generate noisy labels that may mislead
the alignment. To this end, we propose a unified framework, LLM4EA, to
effectively leverage LLMs for EA. Specifically, we design a novel active
learning policy to significantly reduce the annotation space by prioritizing
the most valuable entities based on the entire inter-KG and intra-KG structure.
Moreover, we introduce an unsupervised label refiner to continuously enhance
label accuracy through in-depth probabilistic reasoning. We iteratively
optimize the policy based on the feedback from a base EA model. Extensive
experiments demonstrate the advantages of LLM4EA on four benchmark datasets in
terms of effectiveness, robustness, and efficiency. Codes are available via
https://github.com/chensyCN/llm4ea_official.

ÊëòË¶ÅÔºöÂØ¶È´îÊØîÂ∞ç (EA) Êó®Âú®ÈÄèÈÅéË≠òÂà•Á≠âÊïàÁöÑÂØ¶È´îÂ∞ç‰æÜÂêà‰ΩµÂÖ©ÂÄãÁü•Ë≠òÂúñË≠ú (KG)„ÄÇÈõñÁÑ∂ÁèæÊúâÊñπÊ≥ïÊ•µÂ∫¶‰æùË≥¥‰∫∫Â∑•Áî¢ÁîüÁöÑÊ®ôÁ±§Ôºå‰ΩÜÂú®ÁèæÂØ¶‰∏ñÁïåÁöÑÂ†¥ÊôØ‰∏≠ÔºåË¶ÅÁ¥çÂÖ•Ë∑®È†òÂüüÁöÑÂ∞àÂÆ∂ÈÄ≤Ë°åË®ªËß£ÊòØÈõ£‰ª•Ë≤†ÊìîÁöÑÊàêÊú¨„ÄÇÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÂá∫ÁèæÁÇ∫Ëá™ÂãïÂåñ EA Êèê‰æõ‰∫ÜÊñ∞ÁöÑÈÄîÂæëÔºåÂÖ∂ÈùàÊÑü‰æÜËá™Êñº LLM ÂÖ®Èù¢ËôïÁêÜË™ûÁæ©Ë≥áË®äÁöÑËÉΩÂäõ„ÄÇÁÑ∂ËÄåÔºåÁî±ÊñºÁèæÂØ¶‰∏ñÁïå KG ‰∏≠ÁöÑË®ªËß£Á©∫ÈñìÂæàÂ§ßÔºåÂõ†Ê≠§Áõ¥Êé•ÊáâÁî® LLM Êñº EA ‰∏¶ÈùûÊòì‰∫ã„ÄÇLLM ‰πüÊúâÂèØËÉΩÁî¢ÁîüÈõúË®äÊ®ôÁ±§ÔºåÈÄ≤ËÄåË™§Â∞éÊØîÂ∞ç„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÁµ±‰∏ÄÁöÑÊû∂Êßã LLM4EAÔºå‰ª•ÊúâÊïàÂà©Áî® LLM ÈÄ≤Ë°å EA„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëË®≠Ë®à‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑ‰∏ªÂãïÂ≠∏ÁøíÊîøÁ≠ñÔºåÈÄèÈÅéÊ†πÊìöÊï¥ÂÄãË∑® KG ÂíåÂÖßÈÉ® KG ÁµêÊßãÔºåÂÑ™ÂÖàËôïÁêÜÊúÄÊúâÂÉπÂÄºÁöÑÂØ¶È´îÔºåÂæûËÄåÂ§ßÂπÖÊ∏õÂ∞ëË®ªËß£Á©∫Èñì„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÁÑ°Áõ£Áù£Ê®ôÁ±§Á≤æÁÖâÂô®Ôºå‰ª•ÈÄèÈÅéÊ∑±ÂÖ•ÁöÑÊ©üÁéáÊé®ÁêÜÊåÅÁ∫åÊèêÂçáÊ®ôÁ±§ÁöÑÊ∫ñÁ¢∫ÊÄß„ÄÇÊàëÂÄëÊ†πÊìöÂü∫Á§é EA Ê®°ÂûãÁöÑÂõûÈ•ãÔºåÂèçË¶ÜÊúÄ‰Ω≥ÂåñÊîøÁ≠ñ„ÄÇÂª£Ê≥õÁöÑÂØ¶È©óË≠âÊòé‰∫Ü LLM4EA Âú®ÂõõÂÄãÂü∫Ê∫ñË≥áÊñôÈõÜ‰∏äÁöÑÂÑ™Âã¢ÔºåÂåÖÊã¨Âú®ÊïàËÉΩ„ÄÅÁ©©ÂÅ•ÊÄßÂíåÊïàÁéáÊñπÈù¢„ÄÇÁ®ãÂºèÁ¢ºÂèØÈÄèÈÅé https://github.com/chensyCN/llm4ea_official ÂèñÂæó„ÄÇ

##### **TAGA: Text-Attributed Graph Self-Supervised Learning by Synergizing Graph and Text Mutual Transformations**
2405.16800v1 by Zheng Zhang, Yuntong Hu, Bo Pan, Chen Ling, Liang Zhao

Text-Attributed Graphs (TAGs) enhance graph structures with natural language
descriptions, enabling detailed representation of data and their relationships
across a broad spectrum of real-world scenarios. Despite the potential for
deeper insights, existing TAG representation learning primarily relies on
supervised methods, necessitating extensive labeled data and limiting
applicability across diverse contexts. This paper introduces a new
self-supervised learning framework, Text-And-Graph Multi-View Alignment (TAGA),
which overcomes these constraints by integrating TAGs' structural and semantic
dimensions. TAGA constructs two complementary views: Text-of-Graph view, which
organizes node texts into structured documents based on graph topology, and the
Graph-of-Text view, which converts textual nodes and connections into graph
data. By aligning representations from both views, TAGA captures joint textual
and structural information. In addition, a novel structure-preserving random
walk algorithm is proposed for efficient training on large-sized TAGs. Our
framework demonstrates strong performance in zero-shot and few-shot scenarios
across eight real-world datasets.

ÊëòË¶ÅÔºöÊñáÊú¨Â±ûÊÄßÂõæ (TAG) ‰ΩøÁî®Ëá™ÁÑ∂ËØ≠Ë®ÄÊèèËø∞Â¢ûÂº∫ÂõæÁªìÊûÑÔºåËÉΩÂ§üËØ¶ÁªÜË°®Á§∫Êï∞ÊçÆÂèäÂÖ∂Âú®ÂπøÊ≥õÁöÑÁúüÂÆû‰∏ñÁïåÂú∫ÊôØ‰∏≠ÁöÑÂÖ≥Á≥ª„ÄÇÂ∞ΩÁÆ°ÊúâÊõ¥Ê∑±ÂÖ•ËßÅËß£ÁöÑÊΩúÂäõÔºå‰ΩÜÁé∞ÊúâÁöÑ TAG Ë°®Á§∫Â≠¶‰π†‰∏ªË¶Å‰æùËµñ‰∫éÁõëÁù£ÊñπÊ≥ïÔºåÈúÄË¶ÅÂ§ßÈáèÁöÑÊ†áËÆ∞Êï∞ÊçÆÔºåÂπ∂ÈôêÂà∂‰∫ÜÂú®‰∏çÂêå‰∏ä‰∏ãÊñá‰∏≠ÁöÑÈÄÇÁî®ÊÄß„ÄÇÊú¨Êñá‰ªãÁªç‰∫Ü‰∏Ä‰∏™Êñ∞ÁöÑËá™ÁõëÁù£Â≠¶‰π†Ê°ÜÊû∂ÔºåÊñáÊú¨ÂíåÂõæÂ§öËßÜÂõæÂØπÈΩê (TAGA)ÔºåÈÄöËøáÊï¥Âêà TAG ÁöÑÁªìÊûÑÂíåËØ≠‰πâÁª¥Â∫¶Êù•ÂÖãÊúçËøô‰∫õÈôêÂà∂„ÄÇTAGA ÊûÑÂª∫‰∫Ü‰∏§‰∏™‰∫íË°•ÁöÑËßÜÂõæÔºöÂõæÊñáÊú¨ËßÜÂõæÔºåÂÆÉÊ†πÊçÆÂõæÊãìÊâëÂ∞ÜËäÇÁÇπÊñáÊú¨ÁªÑÁªáÊàêÁªìÊûÑÂåñÊñáÊ°£ÔºõÊñáÊú¨ÂõæËßÜÂõæÔºåÂÆÉÂ∞ÜÊñáÊú¨ËäÇÁÇπÂíåËøûÊé•ËΩ¨Êç¢‰∏∫ÂõæÊï∞ÊçÆ„ÄÇÈÄöËøáÂØπÈΩêÊù•Ëá™‰∏§‰∏™ËßÜÂõæÁöÑË°®Á§∫ÔºåTAGA ÊçïËé∑‰∫ÜËÅîÂêàÊñáÊú¨ÂíåÁªìÊûÑ‰ø°ÊÅØ„ÄÇÊ≠§Â§ñÔºåÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞È¢ñÁöÑÁªìÊûÑ‰øùÊåÅÈöèÊú∫Ê∏∏Ëµ∞ÁÆóÊ≥ïÔºåÁî®‰∫éÂØπÂ§ßÂûã TAG ËøõË°åÈ´òÊïàËÆ≠ÁªÉ„ÄÇÊàë‰ª¨ÁöÑÊ°ÜÊû∂Âú®ÂÖ´‰∏™ÁúüÂÆû‰∏ñÁïåÊï∞ÊçÆÈõÜÁöÑÈõ∂Ê†∑Êú¨ÂíåÂ∞ëÊ†∑Êú¨Âú∫ÊôØ‰∏≠Â±ïÁ§∫‰∫ÜÂº∫Â§ßÁöÑÊÄßËÉΩ„ÄÇ

##### **KG-FIT: Knowledge Graph Fine-Tuning Upon Open-World Knowledge**
2405.16412v1 by Pengcheng Jiang, Lang Cao, Cao Xiao, Parminder Bhatia, Jimeng Sun, Jiawei Han

Knowledge Graph Embedding (KGE) techniques are crucial in learning compact
representations of entities and relations within a knowledge graph,
facilitating efficient reasoning and knowledge discovery. While existing
methods typically focus either on training KGE models solely based on graph
structure or fine-tuning pre-trained language models with classification data
in KG, KG-FIT leverages LLM-guided refinement to construct a semantically
coherent hierarchical structure of entity clusters. By incorporating this
hierarchical knowledge along with textual information during the fine-tuning
process, KG-FIT effectively captures both global semantics from the LLM and
local semantics from the KG. Extensive experiments on the benchmark datasets
FB15K-237, YAGO3-10, and PrimeKG demonstrate the superiority of KG-FIT over
state-of-the-art pre-trained language model-based methods, achieving
improvements of 14.4%, 13.5%, and 11.9% in the Hits@10 metric for the link
prediction task, respectively. Furthermore, KG-FIT yields substantial
performance gains of 12.6%, 6.7%, and 17.7% compared to the structure-based
base models upon which it is built. These results highlight the effectiveness
of KG-FIT in incorporating open-world knowledge from LLMs to significantly
enhance the expressiveness and informativeness of KG embeddings.

ÊëòË¶ÅÔºöÁü•Ë≠òÂúñË≠úÂµåÂÖ• (KGE) ÊäÄË°ìÂ∞çÊñºÂ≠∏ÁøíÁü•Ë≠òÂúñË≠ú‰∏≠ÂØ¶È´îÂíåÈóú‰øÇÁöÑÁ∑äÊπäË°®Á§∫Ëá≥ÈóúÈáçË¶ÅÔºå‰øÉÈÄ≤‰∫ÜÈ´òÊïàÁöÑÊé®ÁêÜÂíåÁü•Ë≠òÁôºÁèæ„ÄÇÈõñÁÑ∂ÁèæÊúâÊñπÊ≥ïÈÄöÂ∏∏Â∞àÊ≥®ÊñºÂÉÖÂü∫ÊñºÂúñÂΩ¢ÁµêÊßãË®ìÁ∑¥ KGE Ê®°ÂûãÊàñ‰ΩøÁî® KG ‰∏≠ÁöÑÂàÜÈ°ûÊï∏ÊìöÂæÆË™øÈ†êË®ìÁ∑¥ÁöÑË™ûË®ÄÊ®°ÂûãÔºå‰ΩÜ KG-FIT Âà©Áî® LLM ÊåáÂ∞éÁöÑÁ≤æÁÖâ‰æÜÊßãÂª∫Ë™ûÁæ©‰∏äÈÄ£Ë≤´ÁöÑÂØ¶È´îÁæ§ÈõÜÂ±§Ê¨°ÁµêÊßã„ÄÇÈÄöÈÅéÂú®ÂæÆË™øÈÅéÁ®ã‰∏≠Â∞áÈÄôÁ®ÆÂ±§Ê¨°Áü•Ë≠òËàáÊñáÊú¨‰ø°ÊÅØÁµêÂêàËµ∑‰æÜÔºåKG-FIT ÊúâÊïàÂú∞Âæû LLM ‰∏≠ÊçïÁç≤ÂÖ®Â±ÄË™ûÁæ©ÔºåÂæû KG ‰∏≠ÊçïÁç≤Â±ÄÈÉ®Ë™ûÁæ©„ÄÇÂú®Âü∫Ê∫ñÊï∏ÊìöÈõÜ FB15K-237„ÄÅYAGO3-10 Âíå PrimeKG ‰∏äÈÄ≤Ë°åÁöÑÂª£Ê≥õÂØ¶È©óË≠âÊòé‰∫Ü KG-FIT ÂÑ™ÊñºÊúÄÂÖàÈÄ≤ÁöÑÂü∫ÊñºÈ†êË®ìÁ∑¥Ë™ûË®ÄÊ®°ÂûãÁöÑÊñπÊ≥ïÔºåÂú®ÈèàË∑ØÈ†êÊ∏¨‰ªªÂãôÁöÑ Hits@10 ÊåáÊ®ô‰∏≠ÂàÜÂà•ÂèñÂæó‰∫Ü 14.4%„ÄÅ13.5% Âíå 11.9% ÁöÑÊîπÈÄ≤„ÄÇÊ≠§Â§ñÔºåËàáÂÖ∂ÊßãÂª∫ÁöÑÂü∫ÊñºÁµêÊßãÁöÑÂü∫Á§éÊ®°ÂûãÁõ∏ÊØîÔºåKG-FIT Âú®ÊÄßËÉΩ‰∏äÈ°ØËëóÊèêÂçá‰∫Ü 12.6%„ÄÅ6.7% Âíå 17.7%„ÄÇÈÄô‰∫õÁµêÊûúÁ™ÅÂá∫‰∫Ü KG-FIT Âú®Êï¥Âêà‰æÜËá™ LLM ÁöÑÈñãÊîæ‰∏ñÁïåÁü•Ë≠ò‰ª•È°ØËëóÂ¢ûÂº∑ KG ÂµåÂÖ•ÁöÑË°®ÈÅîÂäõÂíå‰ø°ÊÅØÈáèÊñπÈù¢ÁöÑÊúâÊïàÊÄß„ÄÇ

##### **Intruding with Words: Towards Understanding Graph Injection Attacks at the Text Level**
2405.16405v1 by Runlin Lei, Yuwei Hu, Yuchen Ren, Zhewei Wei

Graph Neural Networks (GNNs) excel across various applications but remain
vulnerable to adversarial attacks, particularly Graph Injection Attacks (GIAs),
which inject malicious nodes into the original graph and pose realistic
threats. Text-attributed graphs (TAGs), where nodes are associated with textual
features, are crucial due to their prevalence in real-world applications and
are commonly used to evaluate these vulnerabilities. However, existing research
only focuses on embedding-level GIAs, which inject node embeddings rather than
actual textual content, limiting their applicability and simplifying detection.
In this paper, we pioneer the exploration of GIAs at the text level, presenting
three novel attack designs that inject textual content into the graph. Through
theoretical and empirical analysis, we demonstrate that text interpretability,
a factor previously overlooked at the embedding level, plays a crucial role in
attack strength. Among the designs we investigate, the Word-frequency-based
Text-level GIA (WTGIA) is particularly notable for its balance between
performance and interpretability. Despite the success of WTGIA, we discover
that defenders can easily enhance their defenses with customized text embedding
methods or large language model (LLM)--based predictors. These insights
underscore the necessity for further research into the potential and practical
significance of text-level GIAs.

ÊëòË¶ÅÔºöÂúñÂΩ¢Á•ûÁ∂ìÁ∂≤Ë∑Ø (GNN) Âú®ÂêÑÁ®ÆÊáâÁî®‰∏≠Ë°®ÁèæÂá∫Ëâ≤Ôºå‰ΩÜ‰ªçÂÆπÊòìÂèóÂà∞Â∞çÊäóÊÄßÊîªÊìäÔºåÁâπÂà•ÊòØÂúñÂΩ¢Ê≥®ÂÖ•ÊîªÊìä (GIA)ÔºåÂÆÉÊúÉÂ∞áÊÉ°ÊÑèÁØÄÈªûÊ≥®ÂÖ•ÂéüÂßãÂúñÂΩ¢‰∏¶ÊßãÊàêÁèæÂØ¶Â®ÅËÑÖ„ÄÇÊñáÂ≠óÂ±¨ÊÄßÂúñÂΩ¢ (TAG) Áî±ÊñºÂú®ÂØ¶ÈöõÊáâÁî®‰∏≠ÂæàÊôÆÈÅçÔºåÂõ†Ê≠§Ëá≥ÈóúÈáçË¶ÅÔºå‰∏¶‰∏îÈÄöÂ∏∏Áî®ÊñºË©ï‰º∞ÈÄô‰∫õÊºèÊ¥û„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÁöÑÁ†îÁ©∂ÂÉÖÈóúÊ≥®ÂµåÂÖ•Â±§Á¥öÁöÑ GIAÔºåÂÆÉÊ≥®ÂÖ•ÁØÄÈªûÂµåÂÖ•ËÄåÈùûÂØ¶ÈöõÊñáÊú¨ÂÖßÂÆπÔºåÈôêÂà∂‰∫ÜÂÆÉÂÄëÁöÑÈÅ©Áî®ÊÄß‰∏¶Á∞°Âåñ‰∫ÜÊ™¢Ê∏¨„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÁéáÂÖàÊé¢Á¥¢ÊñáÊú¨Â±§Á¥öÁöÑ GIAÔºåÊèêÂá∫‰∫Ü‰∏âÁ®ÆÂ∞áÊñáÊú¨ÂÖßÂÆπÊ≥®ÂÖ•ÂúñÂΩ¢ÁöÑÂâµÊñ∞ÊîªÊìäË®≠Ë®à„ÄÇÈÄèÈÅéÁêÜË´ñÂíåÂØ¶Ë≠âÂàÜÊûêÔºåÊàëÂÄëË≠âÊòé‰∫ÜÊñáÊú¨ÂèØËß£ÈáãÊÄßÔºàÂú®ÂµåÂÖ•Â±§Á¥ö‰ª•ÂâçË¢´ÂøΩÁï•ÁöÑÂõ†Á¥†ÔºâÂú®ÊîªÊìäÂº∑Â∫¶‰∏≠ÊâÆÊºî‰∫ÜËá≥ÈóúÈáçË¶ÅÁöÑËßíËâ≤„ÄÇÂú®ÊàëÂÄëË™øÊü•ÁöÑË®≠Ë®à‰∏≠ÔºåÂü∫ÊñºË©ûÈ†ªÁöÑÊñáÊú¨Â±§Á¥ö GIA (WTGIA) ÁâπÂà•‰ª•ÂÖ∂ÊïàËÉΩÂíåÂèØËß£ÈáãÊÄß‰πãÈñìÁöÑÂπ≥Ë°°ËÄåËëóÁ®±„ÄÇÂÑòÁÆ° WTGIA ÊàêÂäüÁöÑÔºåÊàëÂÄëÁôºÁèæÈò≤Á¶¶ËÄÖÂèØ‰ª•ÈÄèÈÅéËá™Ë®ÇÊñáÂ≠óÂµåÂÖ•ÊñπÊ≥ïÊàñÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁÇ∫Âü∫Á§éÁöÑÈ†êÊ∏¨Âô®ËºïÈ¨ÜÂä†Âº∑‰ªñÂÄëÁöÑÈò≤Á¶¶„ÄÇÈÄô‰∫õË¶ãËß£Âº∑Ë™øÈÄ≤‰∏ÄÊ≠•Á†îÁ©∂ÊñáÊú¨Â±§Á¥ö GIA ÁöÑÊΩõÂäõÂíåÂØ¶ÈöõÊÑèÁæ©ÁöÑÂøÖË¶ÅÊÄß„ÄÇ

##### **COLT: Towards Completeness-Oriented Tool Retrieval for Large Language Models**
2405.16089v1 by Changle Qu, Sunhao Dai, Xiaochi Wei, Hengyi Cai, Shuaiqiang Wang, Dawei Yin, Jun Xu, Ji-Rong Wen

Recently, the integration of external tools with Large Language Models (LLMs)
has emerged as a promising approach to overcome the inherent constraints of
their pre-training data. However, realworld applications often involve a
diverse range of tools, making it infeasible to incorporate all tools directly
into LLMs due to constraints on input length and response time. Therefore, to
fully exploit the potential of tool-augmented LLMs, it is crucial to develop an
effective tool retrieval system. Existing tool retrieval methods techniques
mainly rely on semantic matching between user queries and tool descriptions,
which often results in the selection of redundant tools. As a result, these
methods fail to provide a complete set of diverse tools necessary for
addressing the multifaceted problems encountered by LLMs. In this paper, we
propose a novel modelagnostic COllaborative Learning-based Tool Retrieval
approach, COLT, which captures not only the semantic similarities between user
queries and tool descriptions but also takes into account the collaborative
information of tools. Specifically, we first fine-tune the PLM-based retrieval
models to capture the semantic relationships between queries and tools in the
semantic learning stage. Subsequently, we construct three bipartite graphs
among queries, scenes, and tools and introduce a dual-view graph collaborative
learning framework to capture the intricate collaborative relationships among
tools during the collaborative learning stage. Extensive experiments on both
the open benchmark and the newly introduced ToolLens dataset show that COLT
achieves superior performance. Notably, the performance of BERT-mini (11M) with
our proposed model framework outperforms BERT-large (340M), which has 30 times
more parameters. Additionally, we plan to publicly release the ToolLens dataset
to support further research in tool retrieval.

ÊëòË¶ÅÔºö<paragraph>ÊúÄËøëÔºåÂ§ñÈÉ®Â∑•ÂÖ∑‰∏éÂ§ßÂûãËØ≠Ë®ÄÊ®°Âûã (LLM) ÁöÑÊï¥ÂêàÂ∑≤Êàê‰∏∫ÂÖãÊúçÂÖ∂È¢ÑËÆ≠ÁªÉÊï∞ÊçÆÂõ∫ÊúâÁ∫¶ÊùüÁöÑ‰∏ÄÁßçÊúâÂâçÈÄîÁöÑÊñπÊ≥ï„ÄÇÁÑ∂ËÄåÔºåÁé∞ÂÆû‰∏ñÁïåÁöÑÂ∫îÁî®Á®ãÂ∫èÈÄöÂ∏∏Ê∂âÂèäÂêÑÁßçÂ∑•ÂÖ∑ÔºåÁî±‰∫éËæìÂÖ•ÈïøÂ∫¶ÂíåÂìçÂ∫îÊó∂Èó¥ÁöÑÈôêÂà∂ÔºåÂ∞ÜÊâÄÊúâÂ∑•ÂÖ∑Áõ¥Êé•Êï¥ÂêàÂà∞ LLM ‰∏≠ÊòØ‰∏çÂèØË°åÁöÑ„ÄÇÂõ†Ê≠§Ôºå‰∏∫‰∫ÜÂÖÖÂàÜÂà©Áî®Â∑•ÂÖ∑Â¢ûÂº∫Âûã LLM ÁöÑÊΩúÂäõÔºåËá≥ÂÖ≥ÈáçË¶ÅÁöÑÊòØÂºÄÂèë‰∏Ä‰∏™ÊúâÊïàÁöÑÂ∑•ÂÖ∑Ê£ÄÁ¥¢Á≥ªÁªü„ÄÇÁé∞ÊúâÁöÑÂ∑•ÂÖ∑Ê£ÄÁ¥¢ÊñπÊ≥ïÊäÄÊúØ‰∏ªË¶Å‰æùËµñ‰∫éÁî®Êà∑Êü•ËØ¢ÂíåÂ∑•ÂÖ∑ÊèèËø∞‰πãÈó¥ÁöÑËØ≠‰πâÂåπÈÖçÔºåËøôÈÄöÂ∏∏‰ºöÂØºËá¥ÈÄâÊã©ÂÜó‰ΩôÂ∑•ÂÖ∑„ÄÇÂõ†Ê≠§ÔºåËøô‰∫õÊñπÊ≥ïÊó†Ê≥ïÊèê‰æõËß£ÂÜ≥ LLM ÈÅáÂà∞ÁöÑÂ§öÊñπÈù¢ÈóÆÈ¢òÊâÄÈúÄÁöÑÂÆåÊï¥‰∏îÂ§öÊ†∑ÂåñÁöÑÂ∑•ÂÖ∑ÈõÜ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞È¢ñÁöÑ‰∏éÊ®°ÂûãÊó†ÂÖ≥ÁöÑÂü∫‰∫éÂçè‰ΩúÂ≠¶‰π†ÁöÑÂ∑•ÂÖ∑Ê£ÄÁ¥¢ÊñπÊ≥ï COLTÔºåÂÆÉ‰∏ç‰ªÖÊçïËé∑‰∫ÜÁî®Êà∑Êü•ËØ¢ÂíåÂ∑•ÂÖ∑ÊèèËø∞‰πãÈó¥ÁöÑËØ≠‰πâÁõ∏‰ººÊÄßÔºåËøòËÄÉËôë‰∫ÜÂ∑•ÂÖ∑ÁöÑÂçè‰Ωú‰ø°ÊÅØ„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåÊàë‰ª¨È¶ñÂÖàÂæÆË∞ÉÂü∫‰∫é PLM ÁöÑÊ£ÄÁ¥¢Ê®°ÂûãÔºå‰ª•Âú®ËØ≠‰πâÂ≠¶‰π†Èò∂ÊÆµÊçïËé∑Êü•ËØ¢ÂíåÂ∑•ÂÖ∑‰πãÈó¥ÁöÑËØ≠‰πâÂÖ≥Á≥ª„ÄÇÈöèÂêéÔºåÊàë‰ª¨Âú®Êü•ËØ¢„ÄÅÂú∫ÊôØÂíåÂ∑•ÂÖ∑‰πãÈó¥ÊûÑÂª∫‰∫Ü‰∏â‰∏™‰∫åÂàÜÂõæÔºåÂπ∂ÂºïÂÖ•‰∫Ü‰∏Ä‰∏™ÂèåËßÜÂõæÂõæÂçè‰ΩúÂ≠¶‰π†Ê°ÜÊû∂Ôºå‰ª•Âú®Âçè‰ΩúÂ≠¶‰π†Èò∂ÊÆµÊçïËé∑Â∑•ÂÖ∑‰πãÈó¥ÈîôÁªºÂ§çÊùÇÁöÑÂçè‰ΩúÂÖ≥Á≥ª„ÄÇÂú®ÂºÄÊîæÂü∫ÂáÜÂíåÊñ∞ÂºïÂÖ•ÁöÑ ToolLens Êï∞ÊçÆÈõÜ‰∏äÁöÑÂ§ßÈáèÂÆûÈ™åË°®ÊòéÔºåCOLT ÂèñÂæó‰∫ÜÂçìË∂äÁöÑÊÄßËÉΩ„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÊàë‰ª¨ÊèêÂá∫ÁöÑÊ®°ÂûãÊ°ÜÊû∂‰∏≠ BERT-miniÔºà11MÔºâÁöÑÊÄßËÉΩ‰ºò‰∫é BERT-largeÔºà340MÔºâÔºåËÄåÂêéËÄÖÁöÑÂèÇÊï∞Â§ö 30 ÂÄç„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨ËÆ°ÂàíÂÖ¨ÂºÄÂèëÂ∏É ToolLens Êï∞ÊçÆÈõÜÔºå‰ª•ÊîØÊåÅÂ∑•ÂÖ∑Ê£ÄÁ¥¢ÁöÑËøõ‰∏ÄÊ≠•Á†îÁ©∂„ÄÇ</paragraph>

##### **Large Language Models Reflect Human Citation Patterns with a Heightened Citation Bias**
2405.15739v2 by Andres Algaba, Carmen Mazijn, Vincent Holst, Floriano Tori, Sylvia Wenmackers, Vincent Ginis

Citation practices are crucial in shaping the structure of scientific
knowledge, yet they are often influenced by contemporary norms and biases. The
emergence of Large Language Models (LLMs) like GPT-4 introduces a new dynamic
to these practices. Interestingly, the characteristics and potential biases of
references recommended by LLMs that entirely rely on their parametric
knowledge, and not on search or retrieval-augmented generation, remain
unexplored. Here, we analyze these characteristics in an experiment using a
dataset of 166 papers from AAAI, NeurIPS, ICML, and ICLR, published after
GPT-4's knowledge cut-off date, encompassing 3,066 references in total. In our
experiment, GPT-4 was tasked with suggesting scholarly references for the
anonymized in-text citations within these papers. Our findings reveal a
remarkable similarity between human and LLM citation patterns, but with a more
pronounced high citation bias in GPT-4, which persists even after controlling
for publication year, title length, number of authors, and venue. Additionally,
we observe a large consistency between the characteristics of GPT-4's existing
and non-existent generated references, indicating the model's internalization
of citation patterns. By analyzing citation graphs, we show that the references
recommended by GPT-4 are embedded in the relevant citation context, suggesting
an even deeper conceptual internalization of the citation networks. While LLMs
can aid in citation generation, they may also amplify existing biases and
introduce new ones, potentially skewing scientific knowledge dissemination. Our
results underscore the need for identifying the model's biases and for
developing balanced methods to interact with LLMs in general.

ÊëòË¶ÅÔºö<paragraph>ÂºïË≠âÂØ¶ÂãôÂ∞çÊñºÂΩ¢Â°ëÁßëÂ≠∏Áü•Ë≠òÁöÑÁµêÊßãËá≥ÈóúÈáçË¶ÅÔºåÁÑ∂ËÄåÂæÄÂæÄÊúÉÂèóÂà∞Áï∂‰ª£Ë¶èÁØÑÂíåÂÅèË¶ãÁöÑÂΩ±Èüø„ÄÇÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â¶Ç GPT-4 ÁöÑÂá∫ÁèæÔºåÁÇ∫ÈÄô‰∫õÂØ¶ÂãôÂ∏∂‰æÜ‰∫ÜÊñ∞ÁöÑÂãïÊÖã„ÄÇÊúâË∂£ÁöÑÊòØÔºåÂÆåÂÖ®‰æùË≥¥ÂÖ∂ÂèÉÊï∏ÂåñÁü•Ë≠òÔºàËÄåÈùûÊêúÂ∞ãÊàñÊ™¢Á¥¢Â¢ûÂº∑ÁöÑÁîüÊàêÔºâÁöÑ LLM ÊâÄÊé®Ëñ¶ÁöÑÂèÉËÄÉÊñáÁçªÔºåÂÖ∂ÁâπÊÄßÂíåÊΩõÂú®ÂÅèË¶ã‰ªçÊú™Ë¢´Êé¢Ë®é„ÄÇÂú®Ê≠§ÔºåÊàëÂÄë‰ΩøÁî®‰∏ÄÂÄãÂåÖÂê´ 166 ÁØáË´ñÊñáÁöÑË≥áÊñôÈõÜÈÄ≤Ë°åÂØ¶È©óÔºåÂàÜÊûêÈÄô‰∫õÁâπÊÄßÔºåÈÄô‰∫õË´ñÊñá‰æÜËá™ AAAI„ÄÅNeurIPS„ÄÅICML Âíå ICLRÔºå‰∏¶Êñº GPT-4 Áü•Ë≠òÊà™Ê≠¢Êó•ÊúüÂæåÁôºË°®ÔºåÁ∏ΩÂÖ±Ê∂µËìã 3,066 ÁØáÂèÉËÄÉÊñáÁçª„ÄÇÂú®ÊàëÂÄëÁöÑÂØ¶È©ó‰∏≠ÔºåGPT-4 ÁöÑ‰ªªÂãôÊòØÁÇ∫ÈÄô‰∫õË´ñÊñá‰∏≠ÂåøÂêçÁöÑÂÖßÊñáÂºïÊñáÂª∫Ë≠∞Â≠∏Ë°ìÂèÉËÄÉÊñáÁçª„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÈ°ØÁ§∫Ôºå‰∫∫È°ûÂíå LLM ÁöÑÂºïË≠âÊ®°ÂºèÊúâÈ°ØËëóÁöÑÁõ∏‰ººÊÄßÔºå‰ΩÜ GPT-4 ÁöÑÈ´òÂºïË≠âÂÅèË¶ãËºÉÁÇ∫ÊòéÈ°ØÔºåÂç≥‰ΩøÂú®ÊéßÂà∂‰∫ÜÂá∫ÁâàÂπ¥‰ªΩ„ÄÅÊ®ôÈ°åÈï∑Â∫¶„ÄÅ‰ΩúËÄÖ‰∫∫Êï∏ÂíåÁôºË°®Âú∞ÈªûÂæåÔºåÈÄôÁ®ÆÂÅèË¶ã‰ªçÁÑ∂Â≠òÂú®„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëËßÄÂØüÂà∞ GPT-4 ÁèæÊúâÂíå‰∏çÂ≠òÂú®ÁöÑÁîüÊàêÂèÉËÄÉÊñáÁçª‰πãÈñìÁöÑ‰∏ÄËá¥ÊÄßÂæàÈ´òÔºåÈÄôË°®Á§∫Ê®°ÂûãÂÖßÂåñ‰∫ÜÂºïË≠âÊ®°Âºè„ÄÇÈÄèÈÅéÂàÜÊûêÂºïË≠âÂúñÔºåÊàëÂÄëÁôºÁèæ GPT-4 Êé®Ëñ¶ÁöÑÂèÉËÄÉÊñáÁçªÂµåÂÖ•Âú®Áõ∏ÈóúÁöÑÂºïË≠âËÑàÁµ°‰∏≠ÔºåÈÄôË°®Á§∫Â∞çÂºïË≠âÁ∂≤Ë∑ØÊúâÊõ¥Ê∑±ÂÖ•ÁöÑÊ¶ÇÂøµÂÖßÂåñ„ÄÇÈõñÁÑ∂ LLM ÂèØ‰ª•ÂçîÂä©ÁîüÊàêÂºïË≠âÔºå‰ΩÜÂÆÉÂÄë‰πüÂèØËÉΩÊîæÂ§ßÁèæÊúâÁöÑÂÅèË¶ã‰∏¶ÂºïÂÖ•Êñ∞ÁöÑÂÅèË¶ãÔºåÈÄ≤ËÄåÂèØËÉΩÊâ≠Êõ≤ÁßëÂ≠∏Áü•Ë≠òÁöÑÂÇ≥Êí≠„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÂº∑Ë™ø‰∫ÜË≠òÂà•Ê®°ÂûãÂÅèË¶ãÂíåÈñãÁôºËàá LLM ‰∫íÂãïÁöÑÂπ≥Ë°°ÊñπÊ≥ïÁöÑÈúÄÊ±Ç„ÄÇ</paragraph>

##### **Leveraging Large Language Models for Semantic Query Processing in a Scholarly Knowledge Graph**
2405.15374v1 by Runsong Jia, Bowen Zhang, Sergio J. Rodr√≠guez M√©ndez, Pouya G. Omran

The proposed research aims to develop an innovative semantic query processing
system that enables users to obtain comprehensive information about research
works produced by Computer Science (CS) researchers at the Australian National
University (ANU). The system integrates Large Language Models (LLMs) with the
ANU Scholarly Knowledge Graph (ASKG), a structured repository of all
research-related artifacts produced at ANU in the CS field. Each artifact and
its parts are represented as textual nodes stored in a Knowledge Graph (KG).
  To address the limitations of traditional scholarly KG construction and
utilization methods, which often fail to capture fine-grained details, we
propose a novel framework that integrates the Deep Document Model (DDM) for
comprehensive document representation and the KG-enhanced Query Processing
(KGQP) for optimized complex query handling. DDM enables a fine-grained
representation of the hierarchical structure and semantic relationships within
academic papers, while KGQP leverages the KG structure to improve query
accuracy and efficiency with LLMs.
  By combining the ASKG with LLMs, our approach enhances knowledge utilization
and natural language understanding capabilities. The proposed system employs an
automatic LLM-SPARQL fusion to retrieve relevant facts and textual nodes from
the ASKG. Initial experiments demonstrate that our framework is superior to
baseline methods in terms of accuracy retrieval and query efficiency.
  We showcase the practical application of our framework in academic research
scenarios, highlighting its potential to revolutionize scholarly knowledge
management and discovery. This work empowers researchers to acquire and utilize
knowledge from documents more effectively and provides a foundation for
developing precise and reliable interactions with LLMs.

ÊëòË¶ÅÔºö<paragraph>Êì¨Ë≠∞ÁöÑÁ†îÁ©∂Êó®Âú®ÈñãÁôºÂâµÊñ∞ÁöÑË™ûÁæ©Êü•Ë©¢ËôïÁêÜÁ≥ªÁµ±Ôºå‰ΩøÁî®Êà∂ËÉΩÂ§†Áç≤ÂæóÁî±Êæ≥Ê¥≤ÂúãÁ´ãÂ§ßÂ≠∏ÔºàANUÔºâÈõªËÖ¶ÁßëÂ≠∏ÔºàCSÔºâÁ†îÁ©∂‰∫∫Âì°Áî¢Âá∫ÁöÑÁ†îÁ©∂Ëëó‰ΩúÁöÑÂÖ®Èù¢Ë≥áË®ä„ÄÇÊ≠§Á≥ªÁµ±Êï¥ÂêàÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâËàáÊæ≥Ê¥≤ÂúãÁ´ãÂ§ßÂ≠∏Â≠∏Ë°ìÁü•Ë≠òÂúñË≠úÔºàASKGÔºâÔºåÂæåËÄÖÁÇ∫Âú®Êæ≥Ê¥≤ÂúãÁ´ãÂ§ßÂ≠∏ CS È†òÂüüÁî¢Âá∫ÁöÑÊâÄÊúâÁ†îÁ©∂Áõ∏Èóú‰∫∫Â∑•Ë£ΩÂìÅÁöÑÁµêÊßãÂåñÂÑ≤Â≠òÂ∫´„ÄÇÊØèÂÄã‰∫∫Â∑•Ë£ΩÂìÅÂèäÂÖ∂ÈÉ®ÂàÜ‰ª•ÂÑ≤Â≠òÂú®Áü•Ë≠òÂúñË≠úÔºàKGÔºâ‰∏≠ÁöÑÊñáÂ≠óÁØÄÈªûË°®Á§∫„ÄÇ
ÁÇ∫‰∫ÜËß£Ê±∫ÂÇ≥Áµ±Â≠∏Ë°ì KG Âª∫ÊßãÂíå‰ΩøÁî®ÊñπÂºèÁöÑÈôêÂà∂ÔºåÈÄô‰∫õÊñπÂºèÈÄöÂ∏∏ÁÑ°Ê≥ïÊì∑ÂèñÁ¥∞ÂæÆÁöÑÁ¥∞ÁØÄÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÊñ∞ÁöÑÊû∂ÊßãÔºåÂÆÉÊï¥ÂêàÊ∑±Â∫¶Êñá‰ª∂Ê®°ÂûãÔºàDDMÔºâ‰ª•ÈÄ≤Ë°åÂÖ®Èù¢ÁöÑÊñá‰ª∂Ë°®Á§∫Ôºå‰ª•Âèä KG Â¢ûÂº∑Êü•Ë©¢ËôïÁêÜÔºàKGQPÔºâ‰ª•ÈÄ≤Ë°åÊúÄ‰Ω≥ÂåñÁöÑË§áÈõúÊü•Ë©¢ËôïÁêÜ„ÄÇDDM ËÉΩÂ§†Á¥∞ÂæÆÂú∞Ë°®Á§∫Â≠∏Ë°ìË´ñÊñá‰∏≠ÁöÑÈöéÂ±§ÁµêÊßãÂíåË™ûÁæ©Èóú‰øÇÔºåËÄå KGQP ÂâáÂà©Áî® KG ÁµêÊßãÈÄèÈÅé LLM ‰æÜÊîπÂñÑÊü•Ë©¢ÁöÑÊ∫ñÁ¢∫ÊÄßÂíåÊïàÁéá„ÄÇ
ÈÄèÈÅéÂ∞á ASKG Ëàá LLM ÁµêÂêàÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÂ¢ûÂº∑‰∫ÜÁü•Ë≠òÂà©Áî®ÂíåËá™ÁÑ∂Ë™ûË®ÄÁêÜËß£ËÉΩÂäõ„ÄÇÊì¨Ë≠∞ÁöÑÁ≥ªÁµ±Êé°Áî®Ëá™Âãï LLM-SPARQL ËûçÂêà‰æÜÂæû ASKG Êì∑ÂèñÁõ∏Èóú‰∫ãÂØ¶ÂíåÊñáÂ≠óÁØÄÈªû„ÄÇÂàùÊ≠•ÂØ¶È©óÈ°ØÁ§∫ÔºåÊàëÂÄëÁöÑÊû∂ÊßãÂú®Ê∫ñÁ¢∫ÊÄßÊì∑ÂèñÂíåÊü•Ë©¢ÊïàÁéáÊñπÈù¢ÂÑ™ÊñºÂü∫Ê∫ñÊñπÊ≥ï„ÄÇ
ÊàëÂÄëÂ±ïÁ§∫‰∫ÜÊàëÂÄëÁöÑÊû∂ÊßãÂú®Â≠∏Ë°ìÁ†îÁ©∂ÊÉÖÂ¢É‰∏≠ÁöÑÂØ¶ÈöõÊáâÁî®ÔºåÂº∑Ë™øÂÖ∂Èù©Êñ∞Â≠∏Ë°ìÁü•Ë≠òÁÆ°ÁêÜÂíåÁôºÁèæÁöÑÊΩõÂäõ„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúË≥¶ËÉΩÁ†îÁ©∂‰∫∫Âì°Êõ¥ÊúâÊïàÂú∞ÂèñÂæóÂíåÂà©Áî®Êñá‰ª∂‰∏≠ÁöÑÁü•Ë≠òÔºå‰∏¶ÁÇ∫Ëàá LLM ÈÄ≤Ë°åÁ≤æÁ¢∫‰∏îÂèØÈù†ÁöÑ‰∫íÂãïÂ•†ÂÆöÂü∫Á§é„ÄÇ</paragraph>

##### **Intelligent Go-Explore: Standing on the Shoulders of Giant Foundation Models**
2405.15143v2 by Cong Lu, Shengran Hu, Jeff Clune

Go-Explore is a powerful family of algorithms designed to solve
hard-exploration problems, built on the principle of archiving discovered
states, and iteratively returning to and exploring from the most promising
states. This approach has led to superhuman performance across a wide variety
of challenging problems including Atari games and robotic control, but requires
manually designing heuristics to guide exploration, which is time-consuming and
infeasible in general. To resolve this, we propose Intelligent Go-Explore (IGE)
which greatly extends the scope of the original Go-Explore by replacing these
heuristics with the intelligence and internalized human notions of
interestingness captured by giant foundation models (FMs). This provides IGE
with a human-like ability to instinctively identify how interesting or
promising any new state is (e.g. discovering new objects, locations, or
behaviors), even in complex environments where heuristics are hard to define.
Moreover, IGE offers the exciting and previously impossible opportunity to
recognize and capitalize on serendipitous discoveries that cannot be predicted
ahead of time. We evaluate IGE on a range of language-based tasks that require
search and exploration. In Game of 24, a multistep mathematical reasoning
problem, IGE reaches 100% success rate 70.8% faster than the best classic graph
search baseline. Next, in BabyAI-Text, a challenging partially observable
gridworld, IGE exceeds the previous SOTA with orders of magnitude fewer online
samples. Finally, in TextWorld, we show the unique ability of IGE to succeed in
settings requiring long-horizon exploration where prior SOTA FM agents like
Reflexion completely fail. Overall, IGE combines the tremendous strengths of
FMs and the powerful Go-Explore algorithm, opening up a new frontier of
research into creating more generally capable agents with impressive
exploration capabilities.

ÊëòË¶ÅÔºöGo-Explore ÊòØ‰∏ÄÁ≥ªÂàóÂº∑Â§ßÁöÑÊºîÁÆóÊ≥ïÔºåÊó®Âú®Ëß£Ê±∫Âõ∞Èõ£ÁöÑÊé¢Á¥¢ÂïèÈ°åÔºåÂª∫Á´ãÂú®Â∞ÅÂ≠òÂ∑≤ÁôºÁèæÁãÄÊÖãÁöÑÂéüÂâá‰∏äÔºå‰∏¶ÂèçË¶ÜËøîÂõû‰∏¶ÂæûÊúÄÊúâÂ∏åÊúõÁöÑÁãÄÊÖãÈÄ≤Ë°åÊé¢Á¥¢„ÄÇÈÄôÁ®ÆÊñπÊ≥ïÂ∑≤Âú®ÂåÖÊã¨ Atari ÈÅäÊà≤ÂíåÊ©üÂô®‰∫∫ÊéßÂà∂Âú®ÂÖßÁöÑÂêÑÁ®ÆÂÖ∑ÊúâÊåëÊà∞ÊÄßÁöÑÂïèÈ°å‰∏≠ÂèñÂæó‰∫ÜË∂Ö‰∫∫ÁöÑË°®ÁèæÔºå‰ΩÜÈúÄË¶Å‰∫∫Â∑•Ë®≠Ë®àÂïüÁôºÂºèÊñπÊ≥ï‰æÜÊåáÂ∞éÊé¢Á¥¢ÔºåÈÄôÊó¢ËÄóÊôÇÂèàÈÄöÂ∏∏‰∏çÂèØË°å„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∫Ü Intelligent Go-Explore (IGE)ÔºåÂÆÉÈÄöÈÅéÁî®Â∑®ÂûãÂü∫Á§éÊ®°Âûã (FM) ÊçïÊçâÂà∞ÁöÑÊô∫ÊÖßÂíåÂÖßÂåñÁöÑ‰∫∫È°ûÊúâË∂£Ê¶ÇÂøµÂèñ‰ª£ÈÄô‰∫õÂïüÁôºÂºèÊñπÊ≥ïÔºåÊ•µÂ§ßÂú∞Êì¥Â±ï‰∫ÜÂéüÂßã Go-Explore ÁöÑÁØÑÂúç„ÄÇÈÄôÁÇ∫ IGE Êèê‰æõ‰∫ÜÈ°û‰ºº‰∫∫È°ûÁöÑËÉΩÂäõÔºåÂèØ‰ª•Êú¨ËÉΩÂú∞Ë≠òÂà•‰ªª‰ΩïÊñ∞ÁãÄÊÖãÊúâÂ§öÊúâË∂£ÊàñÊúâÂ∏åÊúõÔºà‰æãÂ¶ÇÁôºÁèæÊñ∞Áâ©‰ª∂„ÄÅ‰ΩçÁΩÆÊàñË°åÁÇ∫ÔºâÔºåÂç≥‰ΩøÂú®Èõ£‰ª•ÂÆöÁæ©ÂïüÁôºÂºèÊñπÊ≥ïÁöÑË§áÈõúÁí∞Â¢É‰∏≠‰πüÊòØÂ¶ÇÊ≠§„ÄÇÊ≠§Â§ñÔºåIGE Êèê‰æõ‰∫Ü‰ª§‰∫∫ËààÂ•Æ‰∏î‰ª•Ââç‰∏çÂèØËÉΩÁöÑÊ©üÊúÉÔºåÂèØ‰ª•Ë≠òÂà•‰∏¶Âà©Áî®ÁÑ°Ê≥ïÈ†êÂÖàÈ†êÊ∏¨ÁöÑÊÑèÂ§ñÁôºÁèæ„ÄÇÊàëÂÄëÂú®ÈúÄË¶ÅÊêúÂ∞ãÂíåÊé¢Á¥¢ÁöÑ‰∏ÄÁ≥ªÂàóÂü∫ÊñºË™ûË®ÄÁöÑ‰ªªÂãô‰∏äË©ï‰º∞‰∫Ü IGE„ÄÇÂú® 24 ÈªûÈÅäÊà≤‰∏≠Ôºå‰∏ÄÂÄãÂ§öÊ≠•È©üÁöÑÊï∏Â≠∏Êé®ÁêÜÂïèÈ°åÔºåIGE ÁöÑÊàêÂäüÁéáÈÅîÂà∞ 100%ÔºåÊØîÊúÄ‰Ω≥Á∂ìÂÖ∏ÂúñÂΩ¢ÊêúÂ∞ãÂü∫Ê∫ñÂø´ 70.8%„ÄÇÊé•‰∏ã‰æÜÔºåÂú® BabyAI-Text ‰∏≠Ôºå‰∏ÄÂÄãÂÖ∑ÊúâÊåëÊà∞ÊÄßÁöÑÈÉ®ÂàÜÂèØËßÄÂØüÁ∂≤Ê†º‰∏ñÁïåÔºåIGE Ë∂ÖË∂ä‰∫ÜÂÖàÂâçÁöÑ SOTAÔºåÂú®Á∑öÁØÑ‰æãÊ∏õÂ∞ë‰∫ÜÂπæÂÄãÊï∏ÈáèÁ¥ö„ÄÇÊúÄÂæåÔºåÂú® TextWorld ‰∏≠ÔºåÊàëÂÄëÂ±ïÁ§∫‰∫Ü IGE Âú®ÈúÄË¶ÅÈï∑ÊúüÊé¢Á¥¢ÁöÑË®≠ÂÆö‰∏≠ÂèñÂæóÊàêÂäüÁöÑÁç®ÁâπËÉΩÂäõÔºåËÄåÂÖàÂâçÁöÑ SOTA FM ‰ª£ÁêÜÔºàÂ¶Ç ReflexionÔºâÂâáÂÆåÂÖ®Â§±Êïó„ÄÇÁ∏ΩÁöÑ‰æÜË™™ÔºåIGE ÁµêÂêà‰∫Ü FM ÁöÑÂ∑®Â§ßÂÑ™Âã¢ÂíåÂº∑Â§ßÁöÑ Go-Explore ÊºîÁÆóÊ≥ïÔºåÈñãÈó¢‰∫Ü‰∏ÄÈ†ÖÊñ∞ÁöÑÁ†îÁ©∂È†òÂüüÔºåÊó®Âú®ÂâµÈÄ†ÂÖ∑Êúâ‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑÊé¢Á¥¢ËÉΩÂäõÁöÑÊõ¥ÈÄöÁî®ÁöÑ‰ª£ÁêÜ„ÄÇ

##### **HippoRAG: Neurobiologically Inspired Long-Term Memory for Large Language Models**
2405.14831v1 by Bernal Jim√©nez Guti√©rrez, Yiheng Shu, Yu Gu, Michihiro Yasunaga, Yu Su

In order to thrive in hostile and ever-changing natural environments,
mammalian brains evolved to store large amounts of knowledge about the world
and continually integrate new information while avoiding catastrophic
forgetting. Despite the impressive accomplishments, large language models
(LLMs), even with retrieval-augmented generation (RAG), still struggle to
efficiently and effectively integrate a large amount of new experiences after
pre-training. In this work, we introduce HippoRAG, a novel retrieval framework
inspired by the hippocampal indexing theory of human long-term memory to enable
deeper and more efficient knowledge integration over new experiences. HippoRAG
synergistically orchestrates LLMs, knowledge graphs, and the Personalized
PageRank algorithm to mimic the different roles of neocortex and hippocampus in
human memory. We compare HippoRAG with existing RAG methods on multi-hop
question answering and show that our method outperforms the state-of-the-art
methods remarkably, by up to 20%. Single-step retrieval with HippoRAG achieves
comparable or better performance than iterative retrieval like IRCoT while
being 10-30 times cheaper and 6-13 times faster, and integrating HippoRAG into
IRCoT brings further substantial gains. Finally, we show that our method can
tackle new types of scenarios that are out of reach of existing methods. Code
and data are available at https://github.com/OSU-NLP-Group/HippoRAG.

ÊëòË¶ÅÔºöÁÇ∫‰∫ÜÂú®ÊÉ°Âä£‰∏îÁû¨ÊÅØËê¨ËÆäÁöÑËá™ÁÑ∂Áí∞Â¢É‰∏≠ËåÅÂ£ØÊàêÈï∑Ôºå
Âì∫‰π≥ÂãïÁâ©ÁöÑÂ§ßËÖ¶ÊºîÂåñÂá∫ÂÑ≤Â≠òÂ§ßÈáèÈóúÊñº‰∏ñÁïåÁü•Ë≠òÁöÑËÉΩÂäõÔºå
‰∏¶Âú®ÈÅøÂÖçÁÅΩÈõ£ÊÄßÈÅ∫ÂøòÁöÑÂêåÊôÇÊåÅÁ∫åÊï¥ÂêàÊñ∞Ë≥áË®ä„ÄÇÂÑòÁÆ°Êúâ‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑÊàêÂ∞±Ôºå
Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM)ÔºåÂç≥‰ΩøÂÖ∑ÂÇôÊ™¢Á¥¢Â¢ûÂº∑ÁîüÊàê (RAG)Ôºå‰ªçÈõ£‰ª•
Âú®È†êË®ìÁ∑¥ÂæåÊúâÊïàÁéá‰∏îÊúâÊïàÂú∞Êï¥ÂêàÂ§ßÈáèÊñ∞Á∂ìÈ©ó„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π HippoRAGÔºå‰∏ÄÁ®ÆÂâµÊñ∞ÁöÑÊ™¢Á¥¢Êû∂ÊßãÔºå
ÈùàÊÑü‰æÜËá™‰∫∫È°ûÈï∑ÊúüË®òÊÜ∂ÁöÑÊµ∑È¶¨Ëø¥Á¥¢ÂºïÁêÜË´ñÔºå‰ª•Âú®Êñ∞ÁöÑÁ∂ìÈ©ó‰∏≠ÂØ¶ÁèæÊõ¥Ê∑±ÂÖ•‰∏îÊõ¥ÊúâÊïàÁéáÁöÑÁü•Ë≠òÊï¥Âêà„ÄÇHippoRAG
ÂçîÂêåÁ∑®Êéí LLM„ÄÅÁü•Ë≠òÂúñË≠úÂíåÂÄã‰∫∫Âåñ PageRank ÊºîÁÆóÊ≥ïÔºå‰ª•Ê®°Êì¨‰∫∫È°ûË®òÊÜ∂‰∏≠Êñ∞ÁöÆË≥™ÂíåÊµ∑È¶¨Ëø¥ÁöÑ‰∏çÂêåËßíËâ≤„ÄÇÊàëÂÄëÂ∞á HippoRAG ËàáÁèæÊúâÁöÑ RAG ÊñπÊ≥ïÈÄ≤Ë°åÂ§öË∑≥ÂºèÂïèÁ≠îÊØîËºÉÔºå‰∏¶Â±ïÁ§∫ÊàëÂÄëÁöÑ
ÊñπÊ≥ïÈ°ØËëóÂÑ™ÊñºÊúÄÂÖàÈÄ≤ÁöÑÊñπÊ≥ïÔºåÊúÄÂ§öÈÅî 20%„ÄÇ‰ΩøÁî® HippoRAG ÁöÑÂñÆÊ≠•Ê™¢Á¥¢ÂèØÂØ¶Áèæ
Ëàá IRCoT Á≠âËø≠‰ª£Ê™¢Á¥¢Áõ∏Áï∂ÊàñÊõ¥Â•ΩÁöÑÊïàËÉΩÔºåÂêåÊôÇÊàêÊú¨Èôç‰Ωé 10-30 ÂÄçÔºåÈÄüÂ∫¶Âä†Âø´ 6-13 ÂÄçÔºåÂ∞á HippoRAG Êï¥ÂêàÂà∞
IRCoT ‰∏≠ÂèØÂ∏∂‰æÜÈÄ≤‰∏ÄÊ≠•ÁöÑÂØ¶Ë≥™Êî∂Áõä„ÄÇÊúÄÂæåÔºåÊàëÂÄëÂ±ïÁ§∫ÊàëÂÄëÁöÑ
ÊñπÊ≥ïÂèØ‰ª•ËôïÁêÜÁèæÊúâÊñπÊ≥ïÁÑ°Ê≥ïÈÅîÂà∞ÁöÑÊñ∞ÂûãÊÖãÂ†¥ÊôØ„ÄÇÁ®ãÂºèÁ¢º
ÂíåË≥áÊñôÂèØÂú® https://github.com/OSU-NLP-Group/HippoRAG ÂèñÂæó„ÄÇ

##### **Fisher Flow Matching for Generative Modeling over Discrete Data**
2405.14664v3 by Oscar Davis, Samuel Kessler, Mircea Petrache, ƒ∞smail ƒ∞lkan Ceylan, Michael Bronstein, Avishek Joey Bose

Generative modeling over discrete data has recently seen numerous success
stories, with applications spanning language modeling, biological sequence
design, and graph-structured molecular data. The predominant generative
modeling paradigm for discrete data is still autoregressive, with more recent
alternatives based on diffusion or flow-matching falling short of their
impressive performance in continuous data settings, such as image or video
generation. In this work, we introduce Fisher-Flow, a novel flow-matching model
for discrete data. Fisher-Flow takes a manifestly geometric perspective by
considering categorical distributions over discrete data as points residing on
a statistical manifold equipped with its natural Riemannian metric: the
$\textit{Fisher-Rao metric}$. As a result, we demonstrate discrete data itself
can be continuously reparameterised to points on the positive orthant of the
$d$-hypersphere $\mathbb{S}^d_+$, which allows us to define flows that map any
source distribution to target in a principled manner by transporting mass along
(closed-form) geodesics of $\mathbb{S}^d_+$. Furthermore, the learned flows in
Fisher-Flow can be further bootstrapped by leveraging Riemannian optimal
transport leading to improved training dynamics. We prove that the gradient
flow induced by Fisher-Flow is optimal in reducing the forward KL divergence.
  We evaluate Fisher-Flow on an array of synthetic and diverse real-world
benchmarks, including designing DNA Promoter, and DNA Enhancer sequences.
Empirically, we find that Fisher-Flow improves over prior diffusion and
flow-matching models on these benchmarks.

ÊëòË¶ÅÔºö<paragraph>Èõ¢Êï£Ë≥áÊñôÁöÑÁîüÊàêÂºèÊ®°ÂûãÊúÄËøëÁç≤ÂæóË®±Â§öÊàêÂäüÊ°à‰æãÔºåÊáâÁî®ÁØÑÂúçÊ∂µËìãË™ûË®ÄÊ®°Âûã„ÄÅÁîüÁâ©Â∫èÂàóË®≠Ë®àÂíåÂúñÂΩ¢ÁµêÊßãÂàÜÂ≠êË≥áÊñô„ÄÇÈõ¢Êï£Ë≥áÊñôÁöÑ‰∏ªË¶ÅÁîüÊàêÂºèÊ®°ÂûãÁØÑ‰æã‰ªçÁÑ∂ÊòØËá™Ëø¥Ê≠∏ÔºåËÄåÊúÄËøëÂü∫ÊñºÊì¥Êï£ÊàñÊµÅÂåπÈÖçÁöÑÊõø‰ª£ÊñπÊ°àÁÑ°Ê≥ïÈÅîÂà∞Âú®ÈÄ£Á∫åË≥áÊñôË®≠ÂÆöÔºà‰æãÂ¶ÇÂΩ±ÂÉèÊàñÂΩ±ÁâáÁîüÊàêÔºâ‰∏≠ÁöÑÈ©ö‰∫∫ÊïàËÉΩ„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π Fisher-FlowÔºåÈÄôÊòØ‰∏ÄÁ®ÆÈáùÂ∞çÈõ¢Êï£Ë≥áÊñôÁöÑÊñ∞Á©éÊµÅÂåπÈÖçÊ®°Âûã„ÄÇFisher-Flow Êé°Áî®ÊòéÈ°ØÁöÑÂπæ‰ΩïËßÄÈªûÔºåÂ∞áÈõ¢Êï£Ë≥áÊñô‰∏äÁöÑÈ°ûÂà•ÂàÜ‰ΩàË¶ñÁÇ∫ÈßêÁïôÂú®ÂÖ∑ÊúâÂÖ∂Ëá™ÁÑ∂ÈªéÊõºÂ∫¶Ë¶èÁöÑÁµ±Ë®àÊµÅÂΩ¢ÁöÑÈªûÔºö$\textit{Fisher-Rao Â∫¶Èáè}$. Âõ†Ê≠§ÔºåÊàëÂÄëË≠âÊòéÈõ¢Êï£Ë≥áÊñôÊú¨Ë∫´ÂèØ‰ª•ÈÄ£Á∫åÈáçÊñ∞ÂèÉÊï∏ÂåñÁÇ∫ $d$-Ë∂ÖÁêÉÈù¢ $\mathbb{S}^d_+$ ÁöÑÊ≠£Ëª∏Âêë‰∏äÁöÑÈªûÔºåÈÄôËÆìÊàëÂÄëÂèØ‰ª•ÂÆöÁæ©ÊµÅÔºå‰ª•ÊúâÂéüÂâáÁöÑÊñπÂºèÂ∞á‰ªª‰ΩïÊ∫êÂàÜ‰ΩàÊò†Â∞ÑÂà∞ÁõÆÊ®ôÔºåÊñπÊ≥ïÊòØÊ≤øËëó $\mathbb{S}^d_+$ ÁöÑÔºàÈñâÂêàÂΩ¢ÂºèÔºâÊ∏¨Âú∞Á∑öÂÇ≥Ëº∏Ë≥™Èáè„ÄÇÊ≠§Â§ñÔºåFisher-Flow ‰∏≠Â≠∏ÁøíÂà∞ÁöÑÊµÅÂèØ‰ª•ÈÄ≤‰∏ÄÊ≠•ÈÄèÈÅéÂà©Áî®ÈªéÊõºÊúÄ‰Ω≥ÂÇ≥Ëº∏ÈÄ≤Ë°åÂºïÂ∞éÔºåÂæûËÄåÊîπÂñÑË®ìÁ∑¥ÂãïÊÖã„ÄÇÊàëÂÄëË≠âÊòé Fisher-Flow Ë™òÂ∞éÁöÑÊ¢ØÂ∫¶ÊµÅÂú®Ê∏õÂ∞ëÂâçÂêë KL Êï£Â∫¶ÊñπÈù¢ÊòØÊúÄÁêÜÊÉ≥ÁöÑ„ÄÇÊàëÂÄëÂú®ÂêÑÁ®ÆÂêàÊàêÂíåÂ§öÂÖÉÁöÑÁúüÂØ¶‰∏ñÁïåÂü∫Ê∫ñ‰∏äË©ï‰º∞ Fisher-FlowÔºåÂåÖÊã¨Ë®≠Ë®à DNA ÂïüÂãïÂ≠êÔºå‰ª•Âèä DNA Â¢ûÂº∑Â≠êÂ∫èÂàó„ÄÇÊ†πÊìöÁ∂ìÈ©óÔºåÊàëÂÄëÁôºÁèæ Fisher-Flow Âú®ÈÄô‰∫õÂü∫Ê∫ñ‰∏äÊîπÈÄ≤‰∫ÜÂÖàÂâçÁöÑÊì¥Êï£ÂíåÊµÅÂåπÈÖçÊ®°Âûã„ÄÇ</paragraph>

##### **GLaD: Synergizing Molecular Graphs and Language Descriptors for Enhanced Power Conversion Efficiency Prediction in Organic Photovoltaic Devices**
2405.14203v1 by Thao Nguyen, Tiara Torres-Flores, Changhyun Hwang, Carl Edwards, Ying Diao, Heng Ji

This paper presents a novel approach for predicting Power Conversion
Efficiency (PCE) of Organic Photovoltaic (OPV) devices, called GLaD:
synergizing molecular Graphs and Language Descriptors for enhanced PCE
prediction. Due to the lack of high-quality experimental data, we collect a
dataset consisting of 500 pairs of OPV donor and acceptor molecules along with
their corresponding PCE values, which we utilize as the training data for our
predictive model. In this low-data regime, GLaD leverages properties learned
from large language models (LLMs) pretrained on extensive scientific literature
to enrich molecular structural representations, allowing for a multimodal
representation of molecules. GLaD achieves precise predictions of PCE, thereby
facilitating the synthesis of new OPV molecules with improved efficiency.
Furthermore, GLaD showcases versatility, as it applies to a range of molecular
property prediction tasks (BBBP, BACE, ClinTox, and SIDER), not limited to
those concerning OPV materials. Especially, GLaD proves valuable for tasks in
low-data regimes within the chemical space, as it enriches molecular
representations by incorporating molecular property descriptions learned from
large-scale pretraining. This capability is significant in real-world
scientific endeavors like drug and material discovery, where access to
comprehensive data is crucial for informed decision-making and efficient
exploration of the chemical space.

ÊëòË¶ÅÔºöÈÄôÁØáË´ñÊñáÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊñ∞Á©éÁöÑÊñπÊ≥ï‰æÜÈ†êÊ∏¨ÊúâÊ©üÂÖâÈõª (OPV) Ë£ùÁΩÆÁöÑÂäüÁéáËΩâÊèõÊïàÁéá (PCE)ÔºåÁ®±ÁÇ∫ GLaDÔºöÁµêÂêàÂàÜÂ≠êÂúñÂΩ¢ÂíåË™ûË®ÄÊèèËø∞Á¨¶‰ª•Â¢ûÂº∑ PCE È†êÊ∏¨„ÄÇÁî±ÊñºÁº∫‰πèÈ´òÂìÅË≥™ÁöÑÂØ¶È©óÊï∏ÊìöÔºåÊàëÂÄëÊî∂ÈõÜ‰∫Ü‰∏ÄÂÄãÂåÖÂê´ 500 Â∞ç OPV ‰æõÈ´îÂíåÂèóÈ´îÂàÜÂ≠êÁöÑÊï∏ÊìöÈõÜÔºå‰ª•ÂèäÂ∞çÊáâÁöÑ PCE ÂÄºÔºåÊàëÂÄëÂ∞áÂÖ∂Áî®‰ΩúÈ†êÊ∏¨Ê®°ÂûãÁöÑË®ìÁ∑¥Êï∏Êìö„ÄÇÂú®ÈÄôÂÄã‰ΩéÊï∏ÊìöÊ®°Âºè‰∏≠ÔºåGLaD Âà©Áî®ÂæûÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰∏≠Â≠∏ÁøíÂà∞ÁöÑÁâπÊÄßÔºåÈÄô‰∫õ LLM Âú®Âª£Ê≥õÁöÑÁßëÂ≠∏ÊñáÁçª‰∏äÈÄ≤Ë°åÈ†êË®ìÁ∑¥Ôºå‰ª•Ë±êÂØåÂàÜÂ≠êÁµêÊßãË°®Á§∫ÔºåÂæûËÄåÂÖÅË®±Â∞çÂàÜÂ≠êÈÄ≤Ë°åÂ§öÊ®°ÊÖãË°®Á§∫„ÄÇGLaD Â∞ç PCE ÈÄ≤Ë°åÁ≤æÁ¢∫È†êÊ∏¨ÔºåÂæûËÄå‰øÉÈÄ≤ÂêàÊàêÂÖ∑ÊúâÊõ¥È´òÊïàÁéáÁöÑÊñ∞Âûã OPV ÂàÜÂ≠ê„ÄÇÊ≠§Â§ñÔºåGLaD Â±ïÁ§∫‰∫ÜÂÖ∂Â§öÂäüËÉΩÊÄßÔºåÂõ†ÁÇ∫ÂÆÉÈÅ©Áî®Êñº‰∏ÄÁ≥ªÂàóÂàÜÂ≠êÁâπÊÄßÈ†êÊ∏¨‰ªªÂãô (BBBP„ÄÅBACE„ÄÅClinTox Âíå SIDER)ÔºåËÄå‰∏çÂÉÖÈôêÊñºÈÇ£‰∫õÊ∂âÂèä OPV ÊùêÊñôÁöÑ‰ªªÂãô„ÄÇÁâπÂà•ÊòØÔºåGLaD Ë≠âÊòéÂ∞çÊñºÂåñÂ≠∏Á©∫Èñì‰∏≠ÁöÑ‰ΩéÊï∏ÊìöÊ®°Âºè‰ªªÂãôÈùûÂ∏∏ÊúâÂÉπÂÄºÔºåÂõ†ÁÇ∫ÂÆÉÈÄöÈÅéÁµêÂêàÂæûÂ§ßË¶èÊ®°È†êË®ìÁ∑¥‰∏≠Â≠∏ÁøíÂà∞ÁöÑÂàÜÂ≠êÁâπÊÄßÊèèËø∞‰æÜË±êÂØåÂàÜÂ≠êË°®Á§∫„ÄÇÈÄôÁ®ÆËÉΩÂäõÂú®ÂÉèËó•Áâ©ÂíåÊùêÊñôÁôºÁèæÈÄôÊ®£ÁöÑÁèæÂØ¶‰∏ñÁïåÁßëÂ≠∏Â∑•‰Ωú‰∏≠ÈùûÂ∏∏ÈáçË¶ÅÔºåÂú®ÈÄô‰∫õÂ∑•‰Ωú‰∏≠ÔºåÁç≤ÂæóÂÖ®Èù¢Êï∏ÊìöÂ∞çÊñºÊòéÊô∫ÁöÑÊ±∫Á≠ñÂà∂ÂÆöÂíåÂåñÂ≠∏Á©∫ÈñìÁöÑÊúâÊïàÊé¢Á¥¢Ëá≥ÈóúÈáçË¶Å„ÄÇ

##### **Large Language Models-guided Dynamic Adaptation for Temporal Knowledge Graph Reasoning**
2405.14170v1 by Jiapu Wang, Kai Sun, Linhao Luo, Wei Wei, Yongli Hu, Alan Wee-Chung Liew, Shirui Pan, Baocai Yin

Temporal Knowledge Graph Reasoning (TKGR) is the process of utilizing
temporal information to capture complex relations within a Temporal Knowledge
Graph (TKG) to infer new knowledge. Conventional methods in TKGR typically
depend on deep learning algorithms or temporal logical rules. However, deep
learning-based TKGRs often lack interpretability, whereas rule-based TKGRs
struggle to effectively learn temporal rules that capture temporal patterns.
Recently, Large Language Models (LLMs) have demonstrated extensive knowledge
and remarkable proficiency in temporal reasoning. Consequently, the employment
of LLMs for Temporal Knowledge Graph Reasoning (TKGR) has sparked increasing
interest among researchers. Nonetheless, LLMs are known to function as black
boxes, making it challenging to comprehend their reasoning process.
Additionally, due to the resource-intensive nature of fine-tuning, promptly
updating LLMs to integrate evolving knowledge within TKGs for reasoning is
impractical. To address these challenges, in this paper, we propose a Large
Language Models-guided Dynamic Adaptation (LLM-DA) method for reasoning on
TKGs. Specifically, LLM-DA harnesses the capabilities of LLMs to analyze
historical data and extract temporal logical rules. These rules unveil temporal
patterns and facilitate interpretable reasoning. To account for the evolving
nature of TKGs, a dynamic adaptation strategy is proposed to update the
LLM-generated rules with the latest events. This ensures that the extracted
rules always incorporate the most recent knowledge and better generalize to the
predictions on future events. Experimental results show that without the need
of fine-tuning, LLM-DA significantly improves the accuracy of reasoning over
several common datasets, providing a robust framework for TKGR tasks.

ÊëòË¶ÅÔºöÊôÇÂ∫èÁü•Ë≠òÂúñË°®Êé®ÁêÜ (TKGR) ÊòØÂà©Áî®ÊôÇÂ∫èË≥áË®ä‰æÜÊì∑ÂèñÊôÇÂ∫èÁü•Ë≠òÂúñË°® (TKG) ‰∏≠Ë§áÈõúÈóú‰øÇÁöÑÈÅéÁ®ãÔºå‰ª•Êé®Ë´ñÂá∫Êñ∞ÁöÑÁü•Ë≠ò„ÄÇTKGR ‰∏≠ÁöÑÂÇ≥Áµ±ÊñπÊ≥ïÈÄöÂ∏∏‰æùË≥¥Ê∑±Â∫¶Â≠∏ÁøíÊºîÁÆóÊ≥ïÊàñÊôÇÂ∫èÈÇèËºØË¶èÂâá„ÄÇÁÑ∂ËÄåÔºåÂü∫ÊñºÊ∑±Â∫¶Â≠∏ÁøíÁöÑ TKGR Á∂ìÂ∏∏Áº∫‰πèÂèØËß£ÈáãÊÄßÔºåËÄåÂü∫ÊñºË¶èÂâáÁöÑ TKGR ÂâáÈõ£‰ª•ÊúâÊïàÂ≠∏ÁøíÊì∑ÂèñÊôÇÂ∫èÊ®°ÂºèÁöÑÊôÇÂ∫èË¶èÂâá„ÄÇÊúÄËøëÔºåÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤Â±ïÁèæÂá∫Âª£Ê≥õÁöÑÁü•Ë≠òÂíåÂçìË∂äÁöÑÊôÇÂ∫èÊé®ÁêÜËÉΩÂäõ„ÄÇÂõ†Ê≠§Ôºå‰ΩøÁî® LLM ÈÄ≤Ë°åÊôÇÂ∫èÁü•Ë≠òÂúñË°®Êé®ÁêÜ (TKGR) Â∑≤ÂºïËµ∑Á†îÁ©∂‰∫∫Âì°Ë∂ä‰æÜË∂äÂ§ßÁöÑËààË∂£„ÄÇÂÑòÁÆ°Â¶ÇÊ≠§ÔºåÁúæÊâÄÂë®Áü• LLM ÁöÑÂäüËÉΩÂ∞±ÂÉèÈªëÁõíÂ≠êÔºåÈÄô‰ΩøÂæóÁêÜËß£ÂÖ∂Êé®ÁêÜÈÅéÁ®ãÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÊ≠§Â§ñÔºåÁî±ÊñºÂæÆË™øÁöÑË≥áÊ∫êÂØÜÈõÜÊÄßÔºåÂç≥ÊôÇÊõ¥Êñ∞ LLM ‰ª•Êï¥Âêà TKG ‰∏≠‰∏çÊñ∑ÊºîÂåñÁöÑÁü•Ë≠òÈÄ≤Ë°åÊé®ÁêÜÊòØ‰∏çÂàáÂØ¶ÈöõÁöÑ„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÂú®Êú¨Êñá‰∏≠ÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÂºïÂ∞éÁöÑÂãïÊÖãÈÅ©Êáâ (LLM-DA) ÊñπÊ≥ïÔºåÁî®ÊñºÂ∞ç TKG ÈÄ≤Ë°åÊé®ÁêÜ„ÄÇÂÖ∑È´î‰æÜË™™ÔºåLLM-DA Âà©Áî® LLM ÁöÑËÉΩÂäõ‰æÜÂàÜÊûêÊ≠∑Âè≤Ë≥áÊñô‰∏¶ÊèêÂèñÊôÇÂ∫èÈÇèËºØË¶èÂâá„ÄÇÈÄô‰∫õË¶èÂâáÊè≠Á§∫‰∫ÜÊôÇÂ∫èÊ®°Âºè‰∏¶‰øÉÈÄ≤ÂèØËß£ÈáãÁöÑÊé®ÁêÜ„ÄÇÁÇ∫‰∫ÜË™™Êòé TKG ÁöÑÊºîÂåñÊÄßË≥™ÔºåÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂãïÊÖãÈÅ©ÊáâÁ≠ñÁï•Ôºå‰ª•‰ΩøÁî®ÊúÄÊñ∞‰∫ã‰ª∂Êõ¥Êñ∞ LLM ÁîüÊàêÁöÑË¶èÂâá„ÄÇÈÄôÁ¢∫‰øù‰∫ÜÊèêÂèñÁöÑË¶èÂâáÂßãÁµÇÂåÖÂê´ÊúÄÊñ∞ÁöÑÁü•Ë≠òÔºå‰∏¶Êõ¥Â•ΩÂú∞Ê¶ÇÊã¨Â∞çÊú™‰æÜ‰∫ã‰ª∂ÁöÑÈ†êÊ∏¨„ÄÇÂØ¶È©óÁµêÊûúË°®ÊòéÔºåÁÑ°ÈúÄÂæÆË™øÔºåLLM-DA Â∞±È°ØËëóÊèêÈ´ò‰∫ÜÂ∞çÂπæÂÄãÂ∏∏Ë¶ãË≥áÊñôÈõÜÁöÑÊé®ÁêÜÊ∫ñÁ¢∫ÊÄßÔºåÁÇ∫ TKGR ‰ªªÂãôÊèê‰æõ‰∫Ü‰∏ÄÂÄãÁ©©ÂÅ•ÁöÑÊ°ÜÊû∂„ÄÇ

##### **Prompt-Time Ontology-Driven Symbolic Knowledge Capture with Large Language Models**
2405.14012v1 by Tolga √á√∂pl√º, Arto Bendiken, Andrii Skomorokhov, Eduard Bateiko, Stephen Cobb

In applications such as personal assistants, large language models (LLMs)
must consider the user's personal information and preferences. However, LLMs
lack the inherent ability to learn from user interactions. This paper explores
capturing personal information from user prompts using ontology and
knowledge-graph approaches. We use a subset of the KNOW ontology, which models
personal information, to train the language model on these concepts. We then
evaluate the success of knowledge capture using a specially constructed
dataset. Our code and datasets are publicly available at
https://github.com/HaltiaAI/paper-PTODSKC

ÊëòË¶ÅÔºöÂú®ÂÄã‰∫∫Âä©ÁêÜÁ≠âÊáâÁî®Á®ãÂºè‰∏≠ÔºåÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM)
ÂøÖÈ†àËÄÉÈáè‰ΩøÁî®ËÄÖÁöÑÂÄã‰∫∫Ë≥áË®äËàáÂÅèÂ•Ω„ÄÇÁÑ∂ËÄåÔºåLLM
Áº∫‰πèÂæû‰ΩøÁî®ËÄÖ‰∫íÂãï‰∏≠Â≠∏ÁøíÁöÑÂÖßÂª∫ËÉΩÂäõ„ÄÇÊú¨ÊñáÊé¢Ë®é‰ΩøÁî®Êú¨È´îË´ñÂíå
Áü•Ë≠òÂúñË≠úÊñπÊ≥ïÂæû‰ΩøÁî®ËÄÖÊèêÁ§∫‰∏≠Êì∑ÂèñÂÄã‰∫∫Ë≥áË®ä„ÄÇÊàëÂÄë‰ΩøÁî® KNOW Êú¨È´îË´ñÁöÑÂ≠êÈõÜÔºåÂÆÉÂª∫Êßã
ÂÄã‰∫∫Ë≥áË®äÔºåÈáùÂ∞çÈÄô‰∫õÊ¶ÇÂøµË®ìÁ∑¥Ë™ûË®ÄÊ®°Âûã„ÄÇÁÑ∂ÂæåÊàëÂÄë
‰ΩøÁî®ÁâπÂà•Âª∫ÊßãÁöÑË≥áÊñôÈõÜË©ï‰º∞Áü•Ë≠òÊì∑ÂèñÁöÑÊàêÂäüÁéá„ÄÇÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÂíåË≥áÊñôÈõÜÂÖ¨ÈñãÊñº
https://github.com/HaltiaAI/paper-PTODSKC

##### **LOGIN: A Large Language Model Consulted Graph Neural Network Training Framework**
2405.13902v1 by Yiran Qiao, Xiang Ao, Yang Liu, Jiarong Xu, Xiaoqian Sun, Qing He

Recent prevailing works on graph machine learning typically follow a similar
methodology that involves designing advanced variants of graph neural networks
(GNNs) to maintain the superior performance of GNNs on different graphs. In
this paper, we aim to streamline the GNN design process and leverage the
advantages of Large Language Models (LLMs) to improve the performance of GNNs
on downstream tasks. We formulate a new paradigm, coined "LLMs-as-Consultants,"
which integrates LLMs with GNNs in an interactive manner. A framework named
LOGIN (LLM Consulted GNN training) is instantiated, empowering the interactive
utilization of LLMs within the GNN training process. First, we attentively
craft concise prompts for spotted nodes, carrying comprehensive semantic and
topological information, and serving as input to LLMs. Second, we refine GNNs
by devising a complementary coping mechanism that utilizes the responses from
LLMs, depending on their correctness. We empirically evaluate the effectiveness
of LOGIN on node classification tasks across both homophilic and heterophilic
graphs. The results illustrate that even basic GNN architectures, when employed
within the proposed LLMs-as-Consultants paradigm, can achieve comparable
performance to advanced GNNs with intricate designs. Our codes are available at
https://github.com/QiaoYRan/LOGIN.

ÊëòË¶ÅÔºöËøëÊúüÁöÑ‰∏ªÊµÅÂõæÊú∫Âô®Â≠¶‰π†Á†îÁ©∂ÈÄöÂ∏∏ÈÅµÂæ™Á±ª‰ººÁöÑÊñπÊ≥ïÔºåÂç≥ËÆæËÆ°ÂõæÁ•ûÁªèÁΩëÁªú (GNN) ÁöÑÈ´òÁ∫ßÂèò‰ΩìÔºå‰ª•Áª¥ÊåÅ GNN Âú®‰∏çÂêåÂõæ‰∏äÁöÑ‰ºòÂºÇÊÄßËÉΩ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨Êó®Âú®ÁÆÄÂåñ GNN ËÆæËÆ°ÊµÅÁ®ãÔºåÂπ∂Âà©Áî®Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã (LLM) ÁöÑ‰ºòÂäøÊù•ÊèêÂçá GNN Âú®‰∏ãÊ∏∏‰ªªÂä°‰∏äÁöÑÊÄßËÉΩ„ÄÇÊàë‰ª¨Âà∂ÂÆö‰∫Ü‰∏Ä‰∏™Êñ∞ÁöÑËåÉ‰æãÔºåÁß∞‰∏∫‚ÄúLLM ‰Ωú‰∏∫È°æÈóÆ‚ÄùÔºåÂÆÉ‰ª•‰∫§‰∫íÊñπÂºèÂ∞Ü LLM ‰∏é GNN ÈõÜÊàêÂú®‰∏ÄËµ∑„ÄÇÂÆû‰æãÂåñ‰∫Ü‰∏Ä‰∏™Âêç‰∏∫ LOGINÔºàLLM Âí®ËØ¢ÁöÑ GNN ËÆ≠ÁªÉÔºâÁöÑÊ°ÜÊû∂ÔºåËµãËÉΩ‰∫Ü LLM Âú® GNN ËÆ≠ÁªÉËøáÁ®ã‰∏≠ÁöÑ‰∫§‰∫íÂºèÂà©Áî®„ÄÇÈ¶ñÂÖàÔºåÊàë‰ª¨‰∏ìÊ≥®‰∫é‰∏∫ÂèëÁé∞ÁöÑËäÇÁÇπÁ≤æÂøÉËÆæËÆ°ÁÆÄÊ¥ÅÁöÑÊèêÁ§∫ÔºåÊâøËΩΩÂÖ®Èù¢ÁöÑËØ≠‰πâÂíåÊãìÊâë‰ø°ÊÅØÔºåÂπ∂‰Ωú‰∏∫ LLM ÁöÑËæìÂÖ•„ÄÇÂÖ∂Ê¨°ÔºåÊàë‰ª¨ÈÄöËøáËÆæËÆ°‰∏ÄÁßçÂà©Áî® LLM ÂìçÂ∫îÁöÑË°•ÂÖÖÂ∫îÂØπÊú∫Âà∂Êù•‰ºòÂåñ GNNÔºåËøôÂèñÂÜ≥‰∫éÂÆÉ‰ª¨ÁöÑÊ≠£Á°ÆÊÄß„ÄÇÊàë‰ª¨ÂØπ LOGIN Âú®ÂêåË¥®ÂíåÂºÇË¥®Âõæ‰∏äÁöÑËäÇÁÇπÂàÜÁ±ª‰ªªÂä°ÁöÑÊúâÊïàÊÄßËøõË°å‰∫ÜÂÆûËØÅËØÑ‰º∞„ÄÇÁªìÊûúË°®ÊòéÔºåÂç≥‰ΩøÊòØÂü∫Êú¨ÁöÑ GNN Êû∂ÊûÑÔºåÂú®ÊâÄÊèêÂá∫ÁöÑ LLM ‰Ωú‰∏∫È°æÈóÆËåÉ‰æã‰∏≠‰ΩøÁî®Êó∂Ôºå‰πüÂèØ‰ª•ÂÆûÁé∞‰∏éÂÖ∑ÊúâÂ§çÊùÇËÆæËÆ°ÁöÑÂÖàËøõ GNN Áõ∏Â™≤ÁæéÁöÑÊÄßËÉΩ„ÄÇÊàë‰ª¨ÁöÑ‰ª£Á†ÅÂèØÂú® https://github.com/QiaoYRan/LOGIN Ëé∑Âèñ„ÄÇ

##### **FiDeLiS: Faithful Reasoning in Large Language Model for Knowledge Graph Question Answering**
2405.13873v1 by Yuan Sui, Yufei He, Nian Liu, Xiaoxin He, Kun Wang, Bryan Hooi

While large language models (LLMs) have achieved significant success in
various applications, they often struggle with hallucinations, especially in
scenarios that require deep and responsible reasoning. These issues could be
partially mitigate by integrating external knowledge graphs (KG) in LLM
reasoning. However, the method of their incorporation is still largely
unexplored. In this paper, we propose a retrieval-exploration interactive
method, FiDelis to handle intermediate steps of reasoning grounded by KGs.
Specifically, we propose Path-RAG module for recalling useful intermediate
knowledge from KG for LLM reasoning. We incorporate the logic and common-sense
reasoning of LLMs and topological connectivity of KGs into the knowledge
retrieval process, which provides more accurate recalling performance.
Furthermore, we propose to leverage deductive reasoning capabilities of LLMs as
a better criterion to automatically guide the reasoning process in a stepwise
and generalizable manner. Deductive verification serve as precise indicators
for when to cease further reasoning, thus avoiding misleading the chains of
reasoning and unnecessary computation. Extensive experiments show that our
method, as a training-free method with lower computational cost and better
generality outperforms the existing strong baselines in three benchmarks.

ÊëòË¶ÅÔºöÂÑòÁÆ°Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤Âú®ÂêÑÁ®ÆÊáâÁî®‰∏≠ÂèñÂæóÈ°ØËëóÊàêÂäüÔºå‰ΩÜÂÆÉÂÄëÁ∂ìÂ∏∏ÊúÉÈÅáÂà∞ÂπªË¶∫ÂïèÈ°åÔºåÁâπÂà•ÊòØÂú®ÈúÄË¶ÅÊ∑±ÂÖ•‰∏îË≤†Ë≤¨‰ªªÁöÑÊé®ÁêÜÂ†¥ÊôØ‰∏≠„ÄÇÈÄô‰∫õÂïèÈ°åÂèØ‰ª•ÈÄèÈÅéÂú® LLM Êé®ÁêÜ‰∏≠Êï¥ÂêàÂ§ñÈÉ®Áü•Ë≠òÂúñË≠ú (KG) ‰æÜÈÉ®ÂàÜÁ∑©Ëß£„ÄÇÁÑ∂ËÄåÔºåÊï¥ÂêàÁöÑÊñπÊ≥ïÂú®ÂæàÂ§ßÁ®ãÂ∫¶‰∏ä‰ªçÊú™ÈñãÁôº„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÊ™¢Á¥¢Êé¢Á¥¢‰∫íÂãïÊñπÊ≥ï FiDelis ‰æÜËôïÁêÜÁî± KG ÁÇ∫Âü∫Á§éÁöÑÊé®ÁêÜ‰∏≠ÈñìÊ≠•È©ü„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÊèêÂá∫ Path-RAG Ê®°ÁµÑÔºåÁî®ÊñºÂæû KG ‰∏≠Âè¨ÂõûÂ∞ç LLM Êé®ÁêÜÊúâÁî®ÁöÑ‰∏≠ÈñìÁü•Ë≠ò„ÄÇÊàëÂÄëÂ∞á LLM ÁöÑÈÇèËºØÂíåÂ∏∏Ë≠òÊé®ÁêÜ‰ª•Âèä KG ÁöÑÊãìÊí≤ÈÄ£Êé•Á¥çÂÖ•Áü•Ë≠òÊ™¢Á¥¢ÈÅéÁ®ã‰∏≠ÔºåÈÄôÊèê‰æõ‰∫ÜÊõ¥Ê∫ñÁ¢∫ÁöÑÂè¨ÂõûÊïàËÉΩ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂª∫Ë≠∞Âà©Áî® LLM ÁöÑÊºîÁππÊé®ÁêÜËÉΩÂäõ‰ΩúÁÇ∫‰∏ÄÂÄãÊõ¥Â•ΩÁöÑÊ∫ñÂâáÔºå‰ª•ÈÄêÊ≠•‰∏îÂèØÊ¶ÇÊã¨ÁöÑÊñπÂºèËá™ÂãïÂºïÂ∞éÊé®ÁêÜÈÅéÁ®ã„ÄÇÊºîÁππÈ©óË≠â‰ΩúÁÇ∫‰ΩïÊôÇÂÅúÊ≠¢ÈÄ≤‰∏ÄÊ≠•Êé®ÁêÜÁöÑÁ≤æÁ¢∫ÊåáÊ®ôÔºåÂæûËÄåÈÅøÂÖçË™§Â∞éÊé®ÁêÜÈèàÂíå‰∏çÂøÖË¶ÅÁöÑË®àÁÆó„ÄÇÂ§ßÈáèÁöÑÂØ¶È©óË°®ÊòéÔºåÊàëÂÄëÁöÑÊºîÁÆóÊ≥ï‰ΩúÁÇ∫‰∏ÄÁ®ÆË®ìÁ∑¥ÂÖçË≤ªÁöÑÊñπÊ≥ïÔºåÂÖ∑ÊúâËºÉ‰ΩéÁöÑÈÅãÁÆóÊàêÊú¨ÂíåÊõ¥Â•ΩÁöÑÊôÆÈÅçÊÄßÔºåÂú®‰∏âÂÄãÂü∫Ê∫ñÊ∏¨Ë©¶‰∏≠ÂÑ™ÊñºÁèæÊúâÁöÑÂº∑Â§ßÂü∫Ê∫ñ„ÄÇ

##### **Large Language Models are Effective Priors for Causal Graph Discovery**
2405.13551v1 by Victor-Alexandru Darvariu, Stephen Hailes, Mirco Musolesi

Causal structure discovery from observations can be improved by integrating
background knowledge provided by an expert to reduce the hypothesis space.
Recently, Large Language Models (LLMs) have begun to be considered as sources
of prior information given the low cost of querying them relative to a human
expert. In this work, firstly, we propose a set of metrics for assessing LLM
judgments for causal graph discovery independently of the downstream algorithm.
Secondly, we systematically study a set of prompting designs that allows the
model to specify priors about the structure of the causal graph. Finally, we
present a general methodology for the integration of LLM priors in graph
discovery algorithms, finding that they help improve performance on
common-sense benchmarks and especially when used for assessing edge
directionality. Our work highlights the potential as well as the shortcomings
of the use of LLMs in this problem space.

ÊëòË¶ÅÔºöÈÄèÈÅéÊï¥ÂêàÂ∞àÂÆ∂Êèê‰æõÁöÑËÉåÊôØÁü•Ë≠òÔºåÂèØ‰ª•Á∏ÆÂ∞èÂÅáË™™Á©∫ÈñìÔºåÈÄ≤ËÄåÊîπÂñÑÂæûËßÄÊ∏¨‰∏≠ÁôºÁèæÂõ†ÊûúÁµêÊßã„ÄÇ
ËøëÊúüÔºåËÄÉÈáèÂà∞Áõ∏ËºÉÊñº‰∫∫È°ûÂ∞àÂÆ∂ÔºåÊü•Ë©¢Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊàêÊú¨ËºÉ‰ΩéÔºåÂõ†Ê≠§ LLM Â∑≤ÈñãÂßãË¢´Ë¶ñÁÇ∫ÂÖàÈ©óË≥áË®äÁöÑ‰æÜÊ∫ê„ÄÇÂú®ÈÄôÈ†ÖÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄëÈ¶ñÂÖàÊèêÂá∫‰∫Ü‰∏ÄÁµÑÊåáÊ®ôÔºåÁî®ÊñºË©ï‰º∞ LLM Âà§Êñ∑Âõ†ÊûúÂúñÂΩ¢ÁôºÁèæÁöÑÁç®Á´ãÊÄßÔºåËàá‰∏ãÊ∏∏ÊºîÁÆóÊ≥ïÁÑ°Èóú„ÄÇÂÖ∂Ê¨°ÔºåÊàëÂÄëÁ≥ªÁµ±ÊÄßÂú∞Á†îÁ©∂‰∫Ü‰∏ÄÁµÑÊèêÁ§∫Ë®≠Ë®àÔºåÂÖÅË®±Ê®°ÂûãÊåáÂÆöÈóúÊñºÂõ†ÊûúÂúñÂΩ¢ÁµêÊßãÁöÑÂÖàÈ©ó„ÄÇÊúÄÂæåÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊï¥Âêà LLM ÂÖàÈ©óÁöÑÈÄöÁî®ÊñπÊ≥ïÔºåÁî®ÊñºÂúñÂΩ¢ÁôºÁèæÊºîÁÆóÊ≥ïÔºåÁôºÁèæÂÆÉÂÄëÊúâÂä©ÊñºÊîπÂñÑÂ∏∏Ë≠òÂü∫Ê∫ñÁöÑÊïàËÉΩÔºåÁâπÂà•ÊòØÂú®Áî®ÊñºË©ï‰º∞ÈÇäÁ∑£ÊñπÂêëÊÄßÊôÇ„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÈáçÈªûË™™Êòé‰∫ÜÂú®ÈÄôÂÄãÂïèÈ°åÁ©∫Èñì‰∏≠‰ΩøÁî® LLM ÁöÑÊΩõÂäõ‰ª•ÂèäÁº∫Èªû„ÄÇ

##### **TrojanRAG: Retrieval-Augmented Generation Can Be Backdoor Driver in Large Language Models**
2405.13401v3 by Pengzhou Cheng, Yidong Ding, Tianjie Ju, Zongru Wu, Wei Du, Ping Yi, Zhuosheng Zhang, Gongshen Liu

Large language models (LLMs) have raised concerns about potential security
threats despite performing significantly in Natural Language Processing (NLP).
Backdoor attacks initially verified that LLM is doing substantial harm at all
stages, but the cost and robustness have been criticized. Attacking LLMs is
inherently risky in security review, while prohibitively expensive. Besides,
the continuous iteration of LLMs will degrade the robustness of backdoors. In
this paper, we propose TrojanRAG, which employs a joint backdoor attack in the
Retrieval-Augmented Generation, thereby manipulating LLMs in universal attack
scenarios. Specifically, the adversary constructs elaborate target contexts and
trigger sets. Multiple pairs of backdoor shortcuts are orthogonally optimized
by contrastive learning, thus constraining the triggering conditions to a
parameter subspace to improve the matching. To improve the recall of the RAG
for the target contexts, we introduce a knowledge graph to construct structured
data to achieve hard matching at a fine-grained level. Moreover, we normalize
the backdoor scenarios in LLMs to analyze the real harm caused by backdoors
from both attackers' and users' perspectives and further verify whether the
context is a favorable tool for jailbreaking models. Extensive experimental
results on truthfulness, language understanding, and harmfulness show that
TrojanRAG exhibits versatility threats while maintaining retrieval capabilities
on normal queries.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂÑòÁÆ°Âú®Ëá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ (NLP) ‰∏≠Ë°®ÁèæÈ°ØËëóÔºå‰ΩÜÂ∑≤ÂºïËµ∑Â∞çÊΩõÂú®ÂÆâÂÖ®Â®ÅËÑÖÁöÑÊìîÊÜÇ„ÄÇÂæåÈñÄÊîªÊìäÊúÄÂàùÈ©óË≠â‰∫Ü LLM Âú®ÊâÄÊúâÈöéÊÆµÈÉΩÊúÉÈÄ†ÊàêÈáçÂ§ßÂç±ÂÆ≥Ôºå‰ΩÜÂÖ∂ÊàêÊú¨ÂíåÂÅ•Â£ØÊÄßÂèóÂà∞ÊâπË©ï„ÄÇÂú®ÂÆâÂÖ®ÂØ©Êü•‰∏≠ÊîªÊìä LLM Êú¨Ë≥™‰∏äÊòØÊúâÈ¢®Èö™ÁöÑÔºåËÄå‰∏îÊàêÊú¨È´òÂæó‰ª§‰∫∫ÊúõËÄåÂçªÊ≠•„ÄÇÊ≠§Â§ñÔºåLLM ÁöÑÊåÅÁ∫åËø≠‰ª£ÊúÉÈôç‰ΩéÂæåÈñÄÁöÑÂÅ•Â£ØÊÄß„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü TrojanRAGÔºåÂÆÉÂú®Ê™¢Á¥¢Â¢ûÂº∑ÁîüÊàê‰∏≠Êé°Áî®ËÅØÂêàÂæåÈñÄÊîªÊìäÔºåÂæûËÄåÊìçÁ∏± LLM Âú®ÈÄöÁî®ÊîªÊìäÂ†¥ÊôØ‰∏≠„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÂ∞çÊâãÊßãÂª∫‰∫ÜÁ≤æÁ¥∞ÁöÑÁõÆÊ®ô‰∏ä‰∏ãÊñáÂíåËß∏ÁôºÂô®ÈõÜ„ÄÇÂ§öÂ∞çÂæåÈñÄÊç∑ÂæëÈÄöÈÅéÂ∞çÊØîÂ≠∏ÁøíÈÄ≤Ë°åÊ≠£‰∫§ÂÑ™ÂåñÔºåÂæûËÄåÂ∞áËß∏ÁôºÊ¢ù‰ª∂Á¥ÑÊùüÂà∞ÂèÉÊï∏Â≠êÁ©∫Èñì‰ª•ÊîπÂñÑÂåπÈÖç„ÄÇÁÇ∫‰∫ÜÊèêÈ´ò RAG Â∞çÁõÆÊ®ô‰∏ä‰∏ãÊñáÁöÑÂè¨ÂõûÁéáÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÁü•Ë≠òÂúñË≠ú‰æÜÊßãÂª∫ÁµêÊßãÂåñÊï∏ÊìöÔºå‰ª•Âú®Á¥∞Á≤íÂ∫¶Á¥öÂà•ÂØ¶ÁèæÁ°¨ÂåπÈÖç„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂ∞ç LLM ‰∏≠ÁöÑÂæåÈñÄÂ†¥ÊôØÈÄ≤Ë°å‰∫ÜÊ≠£Ë¶èÂåñÔºå‰ª•ÂæûÊîªÊìäËÄÖÂíåÁî®Êà∂ÁöÑËßíÂ∫¶ÂàÜÊûêÂæåÈñÄÈÄ†ÊàêÁöÑÂØ¶ÈöõÂç±ÂÆ≥Ôºå‰∏¶ÈÄ≤‰∏ÄÊ≠•È©óË≠â‰∏ä‰∏ãÊñáÊòØÂê¶ÊòØË∂äÁçÑÊ®°ÂûãÁöÑÊúâÂà©Â∑•ÂÖ∑„ÄÇÂú®ÁúüÂØ¶ÊÄß„ÄÅË™ûË®ÄÁêÜËß£ÂíåÂç±ÂÆ≥ÊÄßÊñπÈù¢ÁöÑÂª£Ê≥õÂØ¶È©óÁµêÊûúË°®ÊòéÔºåTrojanRAG Âú®Â∞çÊ≠£Â∏∏Êü•Ë©¢‰øùÊåÅÊ™¢Á¥¢ËÉΩÂäõÁöÑÂêåÊôÇË°®ÁèæÂá∫Â§öÂäüËÉΩÂ®ÅËÑÖ„ÄÇ

##### **Retrieval-Augmented Language Model for Extreme Multi-Label Knowledge Graph Link Prediction**
2405.12656v1 by Yu-Hsiang Lin, Huang-Ting Shieh, Chih-Yu Liu, Kuang-Ting Lee, Hsiao-Cheng Chang, Jing-Lun Yang, Yu-Sheng Lin

Extrapolation in Large language models (LLMs) for open-ended inquiry
encounters two pivotal issues: (1) hallucination and (2) expensive training
costs. These issues present challenges for LLMs in specialized domains and
personalized data, requiring truthful responses and low fine-tuning costs.
Existing works attempt to tackle the problem by augmenting the input of a
smaller language model with information from a knowledge graph (KG). However,
they have two limitations: (1) failing to extract relevant information from a
large one-hop neighborhood in KG and (2) applying the same augmentation
strategy for KGs with different characteristics that may result in low
performance. Moreover, open-ended inquiry typically yields multiple responses,
further complicating extrapolation. We propose a new task, the extreme
multi-label KG link prediction task, to enable a model to perform extrapolation
with multiple responses using structured real-world knowledge. Our retriever
identifies relevant one-hop neighbors by considering entity, relation, and
textual data together. Our experiments demonstrate that (1) KGs with different
characteristics require different augmenting strategies, and (2) augmenting the
language model's input with textual data improves task performance
significantly. By incorporating the retrieval-augmented framework with KG, our
framework, with a small parameter size, is able to extrapolate based on a given
KG. The code can be obtained on GitHub:
https://github.com/exiled1143/Retrieval-Augmented-Language-Model-for-Multi-Label-Knowledge-Graph-Link-Prediction.git

ÊëòË¶ÅÔºö<paragraph>Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰∏≠Áî®ÊñºÈñãÊîæÂºèÊé¢Á©∂ÁöÑÊé®Êñ∑ÊúÉÈÅ≠ÈÅáÂÖ©ÂÄãÈóúÈçµÂïèÈ°åÔºö(1) ÂπªË¶∫Âíå (2) ÊòÇË≤¥ÁöÑË®ìÁ∑¥ÊàêÊú¨„ÄÇÈÄô‰∫õÂïèÈ°åÁÇ∫Â∞àÈñÄÈ†òÂüüÂíåÂÄã‰∫∫ÂåñÊï∏Êìö‰∏≠ÁöÑ LLM Â∏∂‰æÜÊåëÊà∞ÔºåÈúÄË¶ÅÁúüÂØ¶ÁöÑÂõûÊáâÂíå‰ΩéÂæÆË™øÊàêÊú¨„ÄÇÁèæÊúâ‰ΩúÂìÅÂòóË©¶ÈÄöÈÅé‰ΩøÁî®‰æÜËá™Áü•Ë≠òÂúñ (KG) ÁöÑË≥áË®äÊì¥ÂÖÖËºÉÂ∞èÂûãË™ûË®ÄÊ®°ÂûãÁöÑËº∏ÂÖ•‰æÜËß£Ê±∫ÂïèÈ°å„ÄÇÁÑ∂ËÄåÔºåÂÆÉÂÄëÊúâÂÖ©ÂÄãÈôêÂà∂Ôºö(1) ÁÑ°Ê≥ïÂæû KG ‰∏≠ÁöÑÂª£Â§ß‰∏ÄË∑≥ÈÑ∞Âüü‰∏≠ÊèêÂèñÁõ∏ÈóúË≥áË®äÔºå‰ª•Âèä (2) Â∞çÂÖ∑Êúâ‰∏çÂêåÁâπÂæµÁöÑ KG ÊáâÁî®Áõ∏ÂêåÁöÑÊì¥ÂÖÖÁ≠ñÁï•ÔºåÈÄôÂèØËÉΩÊúÉÂ∞éËá¥‰ΩéÊïàËÉΩ„ÄÇÊ≠§Â§ñÔºåÈñãÊîæÂºèÊé¢Á©∂ÈÄöÂ∏∏ÊúÉÁî¢ÁîüÂ§öÈáçÂõûÊáâÔºåÈÄ≤‰∏ÄÊ≠•Ë§áÈõúÂåñÊé®Êñ∑„ÄÇÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÊñ∞‰ªªÂãôÔºåÂç≥Ê•µÁ´ØÂ§öÊ®ôÁ±§ KG ÈÄ£ÁµêÈ†êÊ∏¨‰ªªÂãôÔºå‰ª•‰ΩøÊ®°ÂûãËÉΩÂ§†‰ΩøÁî®ÁµêÊßãÂåñÁöÑÁúüÂØ¶‰∏ñÁïåÁü•Ë≠òÂü∑Ë°åÂÖ∑ÊúâÂ§öÈáçÂõûÊáâÁöÑÊé®Êñ∑„ÄÇÊàëÂÄëÁöÑÊ™¢Á¥¢Âô®ÈÄöÈÅéÂêåÊôÇËÄÉÊÖÆÂØ¶È´î„ÄÅÈóú‰øÇÂíåÊñáÂ≠óË≥áÊñô‰æÜË≠òÂà•Áõ∏ÈóúÁöÑ‰∏ÄË∑≥ÈÑ∞Â±Ö„ÄÇÊàëÂÄëÁöÑÂØ¶È©óË≠âÊòéÔºö(1) ÂÖ∑Êúâ‰∏çÂêåÁâπÂæµÁöÑ KG ÈúÄË¶Å‰∏çÂêåÁöÑÊì¥ÂÖÖÁ≠ñÁï•Ôºå‰ª•Âèä (2) ‰ΩøÁî®ÊñáÂ≠óË≥áÊñôÊì¥ÂÖÖË™ûË®ÄÊ®°ÂûãÁöÑËº∏ÂÖ•ÊúÉÈ°ØËëóÊîπÂñÑ‰ªªÂãôÊïàËÉΩ„ÄÇÈÄèÈÅéÂ∞áÊ™¢Á¥¢Êì¥ÂÖÖÊ°ÜÊû∂Ëàá KG Êï¥ÂêàÔºåÊàëÂÄëÁöÑÊ°ÜÊû∂Âú®ÂèÉÊï∏Ë¶èÊ®°ËºÉÂ∞èÁöÑÊÉÖÊ≥Å‰∏ãÔºåËÉΩÂ§†Ê†πÊìöÁµ¶ÂÆöÁöÑ KG ÈÄ≤Ë°åÊé®Êñ∑„ÄÇ‰ª£Á¢ºÂèØ‰ª•Âú® GitHub ‰∏äÂèñÂæóÔºö
https://github.com/exiled1143/Retrieval-Augmented-Language-Model-for-Multi-Label-Knowledge-Graph-Link-Prediction.git</paragraph>

##### **Learning Structure and Knowledge Aware Representation with Large Language Models for Concept Recommendation**
2405.12442v1 by Qingyao Li, Wei Xia, Kounianhua Du, Qiji Zhang, Weinan Zhang, Ruiming Tang, Yong Yu

Concept recommendation aims to suggest the next concept for learners to study
based on their knowledge states and the human knowledge system. While knowledge
states can be predicted using knowledge tracing models, previous approaches
have not effectively integrated the human knowledge system into the process of
designing these educational models. In the era of rapidly evolving Large
Language Models (LLMs), many fields have begun using LLMs to generate and
encode text, introducing external knowledge. However, integrating LLMs into
concept recommendation presents two urgent challenges: 1) How to construct text
for concepts that effectively incorporate the human knowledge system? 2) How to
adapt non-smooth, anisotropic text encodings effectively for concept
recommendation? In this paper, we propose a novel Structure and Knowledge Aware
Representation learning framework for concept Recommendation (SKarREC). We
leverage factual knowledge from LLMs as well as the precedence and succession
relationships between concepts obtained from the knowledge graph to construct
textual representations of concepts. Furthermore, we propose a graph-based
adapter to adapt anisotropic text embeddings to the concept recommendation
task. This adapter is pre-trained through contrastive learning on the knowledge
graph to get a smooth and structure-aware concept representation. Then, it's
fine-tuned through the recommendation task, forming a
text-to-knowledge-to-recommendation adaptation pipeline, which effectively
constructs a structure and knowledge-aware concept representation. Our method
does a better job than previous adapters in transforming text encodings for
application in concept recommendation. Extensive experiments on real-world
datasets demonstrate the effectiveness of the proposed approach.

ÊëòË¶ÅÔºöÊ¶ÇÂøµÊé®Ëñ¶Êó®Âú®Ê†πÊìöÂ≠∏ÁøíËÄÖÁöÑÁü•Ë≠òÁãÄÊÖãÂíå‰∫∫È°ûÁü•Ë≠òÁ≥ªÁµ±ÔºåÂª∫Ë≠∞Â≠∏ÁøíËÄÖÂ≠∏ÁøíÁöÑ‰∏ã‰∏ÄÂÄãÊ¶ÇÂøµ„ÄÇÈõñÁÑ∂Áü•Ë≠òÁãÄÊÖãÂèØ‰ª•‰ΩøÁî®Áü•Ë≠òËøΩËπ§Ê®°Âûã‰æÜÈ†êÊ∏¨Ôºå‰ΩÜÂÖàÂâçÁöÑÂÅöÊ≥ï‰∏¶Êú™ÊúâÊïàÂú∞Â∞á‰∫∫È°ûÁü•Ë≠òÁ≥ªÁµ±Êï¥ÂêàÂà∞Ë®≠Ë®àÈÄô‰∫õÊïôËÇ≤Ê®°ÂûãÁöÑÈÅéÁ®ã‰∏≠„ÄÇÂú®Âø´ÈÄüÁôºÂ±ïÁöÑÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÊôÇ‰ª£ÔºåË®±Â§öÈ†òÂüüÂ∑≤ÈñãÂßã‰ΩøÁî® LLM ‰æÜÁî¢ÁîüÂíåÁ∑®Á¢ºÊñáÂ≠óÔºåÂºïÂÖ•Â§ñÈÉ®Áü•Ë≠ò„ÄÇÁÑ∂ËÄåÔºåÂ∞á LLM Êï¥ÂêàÂà∞Ê¶ÇÂøµÊé®Ëñ¶‰∏≠ÊúÉÂá∫ÁèæÂÖ©ÂÄãËø´ÂàáÁöÑÊåëÊà∞Ôºö1) Â¶Ç‰ΩïÂª∫ÊßãÊúâÊïàÂú∞Êï¥Âêà‰∫∫È°ûÁü•Ë≠òÁ≥ªÁµ±ÁöÑÊ¶ÇÂøµÊñáÂ≠óÔºü2) Â¶Ç‰ΩïÊúâÊïàÂú∞Ë™øÊï¥ÈùûÂπ≥Êªë„ÄÅÂêÑÂêëÁï∞ÊÄßÁöÑÊñáÂ≠óÁ∑®Á¢º‰ª•ÈÄ≤Ë°åÊ¶ÇÂøµÊé®Ëñ¶ÔºüÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊñ∞ÁöÑÁµêÊßãÂíåÁü•Ë≠òÊÑüÁü•Ë°®Á§∫Â≠∏ÁøíÊû∂ÊßãÔºåÁî®ÊñºÊ¶ÇÂøµÊé®Ëñ¶ (SKarREC)„ÄÇÊàëÂÄëÂà©Áî® LLM ÁöÑ‰∫ãÂØ¶Áü•Ë≠ò‰ª•ÂèäÂæûÁü•Ë≠òÂúñË≠ú‰∏≠Áç≤ÂæóÁöÑÊ¶ÇÂøµ‰πãÈñìÁöÑÂÖàÂæåÈóú‰øÇ‰æÜÂª∫ÊßãÊ¶ÇÂøµÁöÑÊñáÂ≠óË°®Á§∫„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂü∫ÊñºÂúñË°®ÁöÑÈÅ©ÈÖçÂô®Ôºå‰ª•Â∞áÂêÑÂêëÁï∞ÊÄßÁöÑÊñáÂ≠óÂµåÂÖ•Ë™øÊï¥Âà∞Ê¶ÇÂøµÊé®Ëñ¶‰ªªÂãô„ÄÇÈÄôÂÄãÈÅ©ÈÖçÂô®ÈÄèÈÅéÂ∞çÊØîÂ≠∏ÁøíÂú®Áü•Ë≠òÂúñË≠ú‰∏äÈÄ≤Ë°åÈ†êË®ìÁ∑¥Ôºå‰ª•Áç≤ÂæóÂπ≥Êªë‰∏îÂÖ∑ÊúâÁµêÊßãÊÑüÁü•ÁöÑÊ¶ÇÂøµË°®Á§∫„ÄÇÁÑ∂ÂæåÔºåÈÄèÈÅéÊé®Ëñ¶‰ªªÂãôÈÄ≤Ë°åÂæÆË™øÔºåÂΩ¢ÊàêÂæûÊñáÂ≠óÂà∞Áü•Ë≠òÂÜçÂà∞Êé®Ëñ¶ÁöÑÈÅ©ÈÖçÁÆ°ÈÅìÔºåÊúâÊïàÂú∞Âª∫Êßã‰∏ÄÂÄãÁµêÊßãÂíåÁü•Ë≠òÊÑüÁü•ÁöÑÊ¶ÇÂøµË°®Á§∫„ÄÇÊàëÂÄëÁöÑÊñπÊ≥ïÂú®ËΩâÊèõÊñáÂ≠óÁ∑®Á¢º‰ª•ÊáâÁî®ÊñºÊ¶ÇÂøµÊé®Ëñ¶ÊñπÈù¢ÔºåÊØîÂÖàÂâçÁöÑÈÅ©ÈÖçÂô®ÂÅöÂæóÊõ¥Â•Ω„ÄÇÂú®ÁúüÂØ¶‰∏ñÁïåË≥áÊñôÈõÜ‰∏äÁöÑÂª£Ê≥õÂØ¶È©óË≠âÊòé‰∫ÜÊâÄÊèêÂá∫ÊñπÊ≥ïÁöÑÊúâÊïàÊÄß„ÄÇ

##### **KG-RAG: Bridging the Gap Between Knowledge and Creativity**
2405.12035v1 by Diego Sanmartin

Ensuring factual accuracy while maintaining the creative capabilities of
Large Language Model Agents (LMAs) poses significant challenges in the
development of intelligent agent systems. LMAs face prevalent issues such as
information hallucinations, catastrophic forgetting, and limitations in
processing long contexts when dealing with knowledge-intensive tasks. This
paper introduces a KG-RAG (Knowledge Graph-Retrieval Augmented Generation)
pipeline, a novel framework designed to enhance the knowledge capabilities of
LMAs by integrating structured Knowledge Graphs (KGs) with the functionalities
of LLMs, thereby significantly reducing the reliance on the latent knowledge of
LLMs. The KG-RAG pipeline constructs a KG from unstructured text and then
performs information retrieval over the newly created graph to perform KGQA
(Knowledge Graph Question Answering). The retrieval methodology leverages a
novel algorithm called Chain of Explorations (CoE) which benefits from LLMs
reasoning to explore nodes and relationships within the KG sequentially.
Preliminary experiments on the ComplexWebQuestions dataset demonstrate notable
improvements in the reduction of hallucinated content and suggest a promising
path toward developing intelligent systems adept at handling
knowledge-intensive tasks.

ÊëòË¶ÅÔºöÂú®Á¢∫‰øù‰∫ãÂØ¶Ê∫ñÁ¢∫ÊÄßÁöÑÂêåÊôÇÔºå‰øùÊåÅÂ§ßÂûãË™ûË®ÄÊ®°Âûã‰ª£ÁêÜÔºàLMAÔºâÁöÑÂâµÂª∫ËÉΩÂäõÔºåÂ∞çÊô∫ÊÖßÂûã‰ª£ÁêÜÁ≥ªÁµ±ÁöÑÈñãÁôºÊßãÊàê‰∫ÜÈáçÂ§ßÁöÑÊåëÊà∞„ÄÇLMA Èù¢Ëá®ÊôÆÈÅçÁöÑÂïèÈ°åÔºå‰æãÂ¶ÇË≥áË®äÂπªË¶∫„ÄÅÁÅΩÈõ£ÊÄßÈÅ∫ÂøòÔºå‰ª•ÂèäÂú®ËôïÁêÜÁü•Ë≠òÂØÜÈõÜÂûã‰ªªÂãôÊôÇËôïÁêÜÈï∑ËÑàÁµ°ÁöÑÈôêÂà∂„ÄÇÊú¨Êñá‰ªãÁ¥π‰∫Ü KG-RAGÔºàÁü•Ë≠òÂúñË≠úÊ™¢Á¥¢Â¢ûÂº∑ÁîüÊàêÔºâÁÆ°ÈÅìÔºåÈÄôÊòØ‰∏ÄÂÄãÊñ∞Á©éÁöÑÊ°ÜÊû∂ÔºåÊó®Âú®ÈÄèÈÅéÂ∞áÁµêÊßãÂåñÁöÑÁü•Ë≠òÂúñË≠úÔºàKGÔºâËàá LLM ÁöÑÂäüËÉΩÊï¥ÂêàÂú®‰∏ÄËµ∑Ôºå‰æÜÂ¢ûÂº∑ LMA ÁöÑÁü•Ë≠òËÉΩÂäõÔºåÂæûËÄåÈ°ØËëóÊ∏õÂ∞ëÂ∞ç LLM ÊΩõÂú®Áü•Ë≠òÁöÑ‰æùË≥¥„ÄÇKG-RAG ÁÆ°ÈÅìÂæûÈùûÁµêÊßãÂåñÊñáÂ≠ó‰∏≠Âª∫Êßã‰∏ÄÂÄã KGÔºåÁÑ∂ÂæåÂ∞çÊñ∞Âª∫Á´ãÁöÑÂúñË≠úÂü∑Ë°åË≥áË®äÊ™¢Á¥¢Ôºå‰ª•Âü∑Ë°å KGQAÔºàÁü•Ë≠òÂúñË≠úÂïèÁ≠îÔºâ„ÄÇÊ™¢Á¥¢ÊñπÊ≥ïÂà©Áî®‰∫Ü‰∏ÄÁ®ÆÁ®±ÁÇ∫Êé¢Á¥¢ÈèàÔºàCoEÔºâÁöÑÊñ∞ÊºîÁÆóÊ≥ïÔºåË©≤ÊºîÁÆóÊ≥ïÂèóÁõäÊñº LLM Êé®ÁêÜÔºå‰ª•Âæ™Â∫èÊé¢Á¥¢ KG ‰∏≠ÁöÑÁØÄÈªûÂíåÈóú‰øÇ„ÄÇÂú® ComplexWebQuestions Ë≥áÊñôÈõÜ‰∏äÁöÑÂàùÊ≠•ÂØ¶È©óË≠âÊòé‰∫ÜÂú®Ê∏õÂ∞ëÂπªË¶∫ÂÖßÂÆπÊñπÈù¢ÊúâÈ°ØËëóÁöÑÊîπÈÄ≤Ôºå‰∏¶ÊöóÁ§∫‰∫Ü‰∏ÄÊ¢ùÊúâÂ∏åÊúõÁöÑÈÅìË∑ØÔºåÊúùËëóÈñãÁôºÊìÖÈï∑ËôïÁêÜÁü•Ë≠òÂØÜÈõÜÂûã‰ªªÂãôÁöÑÊô∫ÊÖßÂûãÁ≥ªÁµ±ÈÇÅÈÄ≤„ÄÇ

##### **"Set It Up!": Functional Object Arrangement with Compositional Generative Models**
2405.11928v1 by Yiqing Xu, Jiayuan Mao, Yilun Du, Tomas Loz√°no-P√©rez, Leslie Pack Kaebling, David Hsu

This paper studies the challenge of developing robots capable of
understanding under-specified instructions for creating functional object
arrangements, such as "set up a dining table for two"; previous arrangement
approaches have focused on much more explicit instructions, such as "put object
A on the table." We introduce a framework, SetItUp, for learning to interpret
under-specified instructions. SetItUp takes a small number of training examples
and a human-crafted program sketch to uncover arrangement rules for specific
scene types. By leveraging an intermediate graph-like representation of
abstract spatial relationships among objects, SetItUp decomposes the
arrangement problem into two subproblems: i) learning the arrangement patterns
from limited data and ii) grounding these abstract relationships into object
poses. SetItUp leverages large language models (LLMs) to propose the abstract
spatial relationships among objects in novel scenes as the constraints to be
satisfied; then, it composes a library of diffusion models associated with
these abstract relationships to find object poses that satisfy the constraints.
We validate our framework on a dataset comprising study desks, dining tables,
and coffee tables, with the results showing superior performance in generating
physically plausible, functional, and aesthetically pleasing object
arrangements compared to existing models.

ÊëòË¶ÅÔºöÈÄôÁØáË´ñÊñáÊé¢Ë®é‰∫ÜÈñãÁôºÊ©üÂô®‰∫∫ÁöÑÊåëÊà∞ÔºåÈÄô‰∫õÊ©üÂô®‰∫∫ËÉΩÂ§†ÁêÜËß£Êú™ÊòéÁ¢∫Ë¶èÂÆöÁöÑÊåáÁ§∫Ôºå‰ª•Âª∫Á´ãÂäüËÉΩÊÄßÁöÑÁâ©‰ª∂ÊéíÂàóÔºå‰æãÂ¶Ç„ÄåÁÇ∫ÂÖ©ÂÄã‰∫∫Êì∫Â•ΩÈ§êÊ°å„ÄçÔºõÂÖàÂâçÁöÑÊéíÂàóÊñπÊ≥ïËëóÈáçÊñºÊõ¥ÊòéÁ¢∫ÁöÑÊåáÁ§∫Ôºå‰æãÂ¶Ç„ÄåÂ∞áÁâ©‰ª∂ A ÊîæÂú®Ê°å‰∏ä„Äç„ÄÇÊàëÂÄëÂºïÈÄ≤‰∏ÄÂÄãÊû∂Êßã SetItUpÔºåÁî®ÊñºÂ≠∏ÁøíË©ÆÈáãÊú™ÊòéÁ¢∫Ë¶èÂÆöÁöÑÊåáÁ§∫„ÄÇSetItUp Êé°Áî®Â∞ëÊï∏Ë®ìÁ∑¥ÁØÑ‰æãÂíå‰∫∫È°ûË£Ω‰ΩúÁöÑÁ®ãÂºèËçâÂúñÔºå‰ª•ÊâæÂá∫ÁâπÂÆöÂ†¥ÊôØÈ°ûÂûãÁöÑÊéíÂàóË¶èÂâá„ÄÇÈÄèÈÅéÂà©Áî®Áâ©‰ª∂‰πãÈñìÊäΩË±°Á©∫ÈñìÈóú‰øÇÁöÑ‰∏≠ÈñìÂúñÂΩ¢ÂåñË°®Á§∫ÔºåSetItUp Â∞áÊéíÂàóÂïèÈ°åÂàÜËß£ÊàêÂÖ©ÂÄãÂ≠êÂïèÈ°åÔºöi) ÂæûÊúâÈôêË≥áÊñô‰∏≠Â≠∏ÁøíÊéíÂàóÊ®°ÂºèÔºå‰ª•Âèä ii) Â∞áÈÄô‰∫õÊäΩË±°Èóú‰øÇÂü∫Á§éÂåñÁÇ∫Áâ©‰ª∂ÂßøÂã¢„ÄÇSetItUp Âà©Áî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰æÜÊèêÂá∫Êñ∞Â†¥ÊôØ‰∏≠Áâ©‰ª∂‰πãÈñìÁöÑÊäΩË±°Á©∫ÈñìÈóú‰øÇÔºå‰ΩúÁÇ∫Ë¶ÅÊªøË∂≥ÁöÑÁ¥ÑÊùüÔºõÁÑ∂ÂæåÔºåÂÆÉÁ∑®ÂØ´‰∏ÄÂÄãËàáÈÄô‰∫õÊäΩË±°Èóú‰øÇÁõ∏ÈóúÁöÑÊì¥Êï£Ê®°ÂûãÂ∫´Ôºå‰ª•ÊâæÂá∫ÊªøË∂≥Á¥ÑÊùüÁöÑÁâ©‰ª∂ÂßøÂã¢„ÄÇÊàëÂÄëÂú®ÂåÖÂê´Êõ∏Ê°å„ÄÅÈ§êÊ°åÂíåÂíñÂï°Ê°åÁöÑË≥áÊñôÈõÜ‰∏äÈ©óË≠âÊàëÂÄëÁöÑÊû∂ÊßãÔºåÁµêÊûúÈ°ØÁ§∫Âú®Áî¢ÁîüÁâ©ÁêÜ‰∏äÂêàÁêÜ„ÄÅÂäüËÉΩÊÄßÂíåÁæéËßÄÁöÑÁâ©‰ª∂ÊéíÂàóÊñπÈù¢ÔºåËàáÁèæÊúâÊ®°ÂûãÁõ∏ÊØîÂÖ∑ÊúâÂÑ™Áï∞ÁöÑÊïàËÉΩ„ÄÇ

##### **Increasing the LLM Accuracy for Question Answering: Ontologies to the Rescue!**
2405.11706v1 by Dean Allemang, Juan Sequeda

There is increasing evidence that question-answering (QA) systems with Large
Language Models (LLMs), which employ a knowledge graph/semantic representation
of an enterprise SQL database (i.e. Text-to-SPARQL), achieve higher accuracy
compared to systems that answer questions directly on SQL databases (i.e.
Text-to-SQL). Our previous benchmark research showed that by using a knowledge
graph, the accuracy improved from 16% to 54%. The question remains: how can we
further improve the accuracy and reduce the error rate? Building on the
observations of our previous research where the inaccurate LLM-generated SPARQL
queries followed incorrect paths, we present an approach that consists of 1)
Ontology-based Query Check (OBQC): detects errors by leveraging the ontology of
the knowledge graph to check if the LLM-generated SPARQL query matches the
semantic of ontology and 2) LLM Repair: use the error explanations with an LLM
to repair the SPARQL query. Using the chat with the data benchmark, our primary
finding is that our approach increases the overall accuracy to 72% including an
additional 8% of "I don't know" unknown results. Thus, the overall error rate
is 20%. These results provide further evidence that investing knowledge graphs,
namely the ontology, provides higher accuracy for LLM powered question
answering systems.

ÊëòË¶ÅÔºöÊúâË∂ä‰æÜË∂äÂ§öÁöÑË≠âÊìöÈ°ØÁ§∫Ôºå‰ΩøÁî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÂïèÁ≠î (QA) Á≥ªÁµ±ÔºåÂÆÉÊé°Áî®‰ºÅÊ•≠ SQL Ë≥áÊñôÂ∫´ÁöÑÁü•Ë≠òÂúñË≠ú/Ë™ûÁæ©Ë°®Á§∫ÔºàÂç≥ Text-to-SPARQLÔºâÔºåËàáÁõ¥Êé•Âú® SQL Ë≥áÊñôÂ∫´‰∏äÂõûÁ≠îÂïèÈ°åÁöÑÁ≥ªÁµ±ÔºàÂç≥ Text-to-SQLÔºâÁõ∏ÊØîÔºåËÉΩÈÅîÂà∞Êõ¥È´òÁöÑÊ∫ñÁ¢∫Â∫¶„ÄÇÊàëÂÄëÂÖàÂâçÁöÑÂü∫Ê∫ñÁ†îÁ©∂È°ØÁ§∫ÔºåÈÄèÈÅé‰ΩøÁî®Áü•Ë≠òÂúñË≠úÔºåÊ∫ñÁ¢∫Â∫¶Âæû 16% ÊèêÂçáËá≥ 54%„ÄÇÂïèÈ°å‰ªçÁÑ∂Â≠òÂú®ÔºöÊàëÂÄëÂ¶Ç‰ΩïÈÄ≤‰∏ÄÊ≠•ÊèêÂçáÊ∫ñÁ¢∫Â∫¶‰∏¶Èôç‰ΩéÈåØË™§ÁéáÔºüÊ†πÊìöÊàëÂÄëÂÖàÂâçÁ†îÁ©∂ÁöÑËßÄÂØüÔºåÂÖ∂‰∏≠‰∏çÊ∫ñÁ¢∫ÁöÑ LLM ÁîüÊàêÁöÑ SPARQL Êü•Ë©¢ÈÅµÂæ™‰∏çÊ≠£Á¢∫ÁöÑË∑ØÂæëÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñπÊ≥ïÔºåÂÖ∂‰∏≠ÂåÖÂê´ 1) Âü∫ÊñºÊú¨‰ΩìÁöÑÊü•Ë©¢Ê™¢Êü• (OBQC)ÔºöÂà©Áî®Áü•Ë≠òÂúñË≠úÁöÑÊú¨‰Ωì‰æÜÊ™¢Êü• LLM ÁîüÊàêÁöÑ SPARQL Êü•Ë©¢ÊòØÂê¶Á¨¶ÂêàÊú¨‰ΩìÁöÑË™ûÁæ©ÔºåÂæûËÄåÂÅµÊ∏¨ÈåØË™§Ôºå‰ª•Âèä 2) LLM ‰øÆÂæ©Ôºö‰ΩøÁî®Â∏∂Êúâ LLM ÁöÑÈåØË™§Ë™™Êòé‰æÜ‰øÆÂæ© SPARQL Êü•Ë©¢„ÄÇ‰ΩøÁî®ËàáË≥áÊñôÂü∫Ê∫ñÁöÑËÅäÂ§©ÔºåÊàëÂÄëÁöÑÂàùÊ≠•ÁôºÁèæÊòØÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÂ∞áÊï¥È´îÊ∫ñÁ¢∫Â∫¶ÊèêÂçáËá≥ 72%ÔºåÂåÖÊã¨È°çÂ§ñÁöÑ 8% ÁöÑ„ÄåÊàë‰∏çÁü•ÈÅì„ÄçÊú™Áü•ÁµêÊûú„ÄÇÂõ†Ê≠§ÔºåÊï¥È´îÈåØË™§ÁéáÁÇ∫ 20%„ÄÇÈÄô‰∫õÁµêÊûúÈÄ≤‰∏ÄÊ≠•Ë≠âÊòéÊäïË≥áÁü•Ë≠òÂúñË≠úÔºåÂç≥Êú¨‰ΩìÔºåËÉΩÁÇ∫ LLM È©ÖÂãïÁöÑÂïèÁ≠îÁ≥ªÁµ±Êèê‰æõÊõ¥È´òÁöÑÊ∫ñÁ¢∫Â∫¶„ÄÇ

##### **Empowering Small-Scale Knowledge Graphs: A Strategy of Leveraging General-Purpose Knowledge Graphs for Enriched Embeddings**
2405.10745v1 by Albert Sawczyn, Jakub Binkowski, Piotr Bielak, Tomasz Kajdanowicz

Knowledge-intensive tasks pose a significant challenge for Machine Learning
(ML) techniques. Commonly adopted methods, such as Large Language Models
(LLMs), often exhibit limitations when applied to such tasks. Nevertheless,
there have been notable endeavours to mitigate these challenges, with a
significant emphasis on augmenting LLMs through Knowledge Graphs (KGs). While
KGs provide many advantages for representing knowledge, their development costs
can deter extensive research and applications. Addressing this limitation, we
introduce a framework for enriching embeddings of small-scale domain-specific
Knowledge Graphs with well-established general-purpose KGs. Adopting our
method, a modest domain-specific KG can benefit from a performance boost in
downstream tasks when linked to a substantial general-purpose KG. Experimental
evaluations demonstrate a notable enhancement, with up to a 44% increase
observed in the Hits@10 metric. This relatively unexplored research direction
can catalyze more frequent incorporation of KGs in knowledge-intensive tasks,
resulting in more robust, reliable ML implementations, which hallucinates less
than prevalent LLM solutions.
  Keywords: knowledge graph, knowledge graph completion, entity alignment,
representation learning, machine learning

ÊëòË¶ÅÔºöÁü•Ë≠òÂØÜÈõÜÂûã‰ªªÂãôÂ∞çÊ©üÂô®Â≠∏Áøí (ML) ÊäÄË°ìÊßãÊàêÈáçÂ§ßÊåëÊà∞„ÄÇÂ∏∏Ë¶ãÊé°Áî®ÁöÑÊñπÊ≥ïÔºå‰æãÂ¶ÇÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM)ÔºåÂú®ÊáâÁî®ÊñºÊ≠§È°û‰ªªÂãôÊôÇÔºåÈÄöÂ∏∏ÊúÉË°®ÁèæÂá∫ÈôêÂà∂„ÄÇÂÑòÁÆ°Â¶ÇÊ≠§ÔºåÂ∑≤Á∂ìÊúâÈ°ØËëóÁöÑÂä™Âäõ‰æÜÊ∏õËºïÈÄô‰∫õÊåëÊà∞ÔºåÈáçÈªûÂú®ÊñºÈÄèÈÅéÁü•Ë≠òÂúñË≠ú (KG) ‰æÜÊì¥ÂÖÖ LLM„ÄÇÈõñÁÑ∂ KG Âú®Ë°®Á§∫Áü•Ë≠òÊñπÈù¢Êèê‰æõ‰∫ÜË®±Â§öÂÑ™ÈªûÔºå‰ΩÜÂÖ∂ÈñãÁôºÊàêÊú¨ÂèØËÉΩÊúÉÈòªÁ§ôÂª£Ê≥õÁöÑÁ†îÁ©∂ÂíåÊáâÁî®„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÈôêÂà∂ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÊû∂ÊßãÔºåÁî®ÂÆåÂñÑÁöÑÈÄöÁî® KG ‰æÜË±êÂØåÂ∞èË¶èÊ®°ÁâπÂÆöÈ†òÂüüÁü•Ë≠òÂúñË≠úÁöÑÂµåÂÖ•„ÄÇÊé°Áî®ÊàëÂÄëÁöÑÈÄôÂÄãÊñπÊ≥ïÔºå‰∏ÄÂÄãÈÅ©Â∫¶ÁöÑÁâπÂÆöÈ†òÂüü KG ÂèØ‰ª•ÂæûËàá‰∏ÄÂÄãÂ§ßÈáèÁöÑÈÄöÁî® KG ÈÄ£ÁµêÊôÇÔºåÂú®‰∏ãÊ∏∏‰ªªÂãô‰∏≠ÂèóÁõäÊñºÊïàËÉΩÊèêÂçá„ÄÇÂØ¶È©óË©ï‰º∞Ë≠âÊòé‰∫ÜÈ°ØËëóÁöÑÊîπÈÄ≤ÔºåÂú® Hits@10 ÊåáÊ®ô‰∏≠ËßÄÂØüÂà∞È´òÈÅî 44% ÁöÑÊèêÂçá„ÄÇÈÄôÂÄãÁõ∏Â∞çÊú™ÈñãÁôºÁöÑÁ†îÁ©∂ÊñπÂêëÂèØ‰ª•ÂÇ¨ÂåñÂú®Áü•Ë≠òÂØÜÈõÜÂûã‰ªªÂãô‰∏≠Êõ¥È†ªÁπÅÂú∞Á¥çÂÖ• KGÔºåÂæûËÄåÁî¢ÁîüÊõ¥Âº∑Â§ß„ÄÅÊõ¥ÂèØÈù†ÁöÑ ML ÂØ¶‰ΩúÔºåÂÖ∂Áî¢ÁîüÁöÑÂπªË¶∫Â∞ëÊñºÊôÆÈÅçÁöÑ LLM Ëß£ÂÜ≥ÊñπÊ°à„ÄÇ
ÈóúÈçµÂ≠óÔºöÁü•Ë≠òÂúñË≠ú„ÄÅÁü•Ë≠òÂúñË≠úÂÆåÊàêÂäüËÉΩ„ÄÅÂØ¶È´îÂ∞çÈΩä„ÄÅË°®Á§∫Â≠∏Áøí„ÄÅÊ©üÂô®Â≠∏Áøí

##### **Automatic News Generation and Fact-Checking System Based on Language Processing**
2405.10492v2 by Xirui Peng, Qiming Xu, Zheng Feng, Haopeng Zhao, Lianghao Tan, Yan Zhou, Zecheng Zhang, Chenwei Gong, Yingqiao Zheng

This paper explores an automatic news generation and fact-checking system
based on language processing, aimed at enhancing the efficiency and quality of
news production while ensuring the authenticity and reliability of the news
content. With the rapid development of Natural Language Processing (NLP) and
deep learning technologies, automatic news generation systems are capable of
extracting key information from massive data and generating well-structured,
fluent news articles. Meanwhile, by integrating fact-checking technology, the
system can effectively prevent the spread of false news and improve the
accuracy and credibility of news. This study details the key technologies
involved in automatic news generation and factchecking, including text
generation, information extraction, and the application of knowledge graphs,
and validates the effectiveness of these technologies through experiments.
Additionally, the paper discusses the future development directions of
automatic news generation and fact-checking systems, emphasizing the importance
of further integration and innovation of technologies. The results show that
with continuous technological optimization and practical application, these
systems will play an increasingly important role in the future news industry,
providing more efficient and reliable news services.

ÊëòË¶ÅÔºöÊú¨ÊñáÊé¢Ë®é‰∫Ü‰∏ÄÁ®ÆÂü∫ÊñºË™ûË®ÄËôïÁêÜÁöÑËá™ÂãïÊñ∞ËÅûÁîüÊàêËàá‰∫ãÂØ¶Êü•Ê†∏Á≥ªÁµ±ÔºåÊó®Âú®ÊèêÂçáÊñ∞ËÅûÁî¢Ë£ΩÁöÑÊïàÁéáËàáÂìÅË≥™ÔºåÂêåÊôÇÁ¢∫‰øùÊñ∞ËÅûÂÖßÂÆπÁöÑÁúüÂØ¶ÊÄßËàáÂèØ‰ø°Â∫¶„ÄÇÈö®ËëóËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜÔºàNLPÔºâËàáÊ∑±Â∫¶Â≠∏ÁøíÊäÄË°ìÁöÑÂø´ÈÄüÁôºÂ±ïÔºåËá™ÂãïÊñ∞ËÅûÁîüÊàêÁ≥ªÁµ±ËÉΩÂ§†ÂæûÊµ∑ÈáèË≥áÊñô‰∏≠ËêÉÂèñÈóúÈçµË≥áË®äÔºå‰∏¶ÁîüÊàêÁµêÊßãËâØÂ•Ω„ÄÅÊµÅÊö¢ÁöÑÊñ∞ËÅûÊñáÁ´†„ÄÇÂêåÊôÇÔºåÈÄèÈÅéÊï¥Âêà‰∫ãÂØ¶Êü•Ê†∏ÊäÄË°ìÔºåÁ≥ªÁµ±ËÉΩÊúâÊïàÈò≤Ê≠¢ÂÅáÊñ∞ËÅûÁöÑÊï£Êí≠ÔºåÊèêÂçáÊñ∞ËÅûÁöÑÊ∫ñÁ¢∫Â∫¶ËàáÂèØ‰ø°Â∫¶„ÄÇÊú¨Á†îÁ©∂Ë©≥Á¥∞Ë™™ÊòéËá™ÂãïÊñ∞ËÅûÁîüÊàêËàá‰∫ãÂØ¶Êü•Ê†∏ÊâÄÊ∂âÂèäÁöÑÈóúÈçµÊäÄË°ìÔºåÂåÖÊã¨ÊñáÂ≠óÁîüÊàê„ÄÅË≥áË®äËêÉÂèñ„ÄÅÁü•Ë≠òÂúñË≠úÁöÑÊáâÁî®Ôºå‰∏¶ÈÄèÈÅéÂØ¶È©óÈ©óË≠âÈÄô‰∫õÊäÄË°ìÁöÑÊúâÊïàÊÄß„ÄÇÊ≠§Â§ñÔºåÊú¨ÊñáÊé¢Ë®éËá™ÂãïÊñ∞ËÅûÁîüÊàêËàá‰∫ãÂØ¶Êü•Ê†∏Á≥ªÁµ±Êú™‰æÜÁöÑÁôºÂ±ïÊñπÂêëÔºåÂº∑Ë™øÊäÄË°ìÈÄ≤‰∏ÄÊ≠•Êï¥ÂêàËàáÂâµÊñ∞ÁöÑÈáçË¶ÅÊÄß„ÄÇÁµêÊûúÈ°ØÁ§∫ÔºåÈö®ËëóÊäÄË°ìÊåÅÁ∫åÂÑ™ÂåñËàáÂØ¶ÂãôÊáâÁî®ÔºåÈÄô‰∫õÁ≥ªÁµ±Â∞áÂú®Êú™‰æÜÁöÑÊñ∞ËÅûÁî¢Ê•≠‰∏≠ÊâÆÊºîÊó•ÁõäÈáçË¶ÅÁöÑËßíËâ≤ÔºåÊèê‰æõÊõ¥ÊúâÊïàÁéá„ÄÅÊõ¥ÂèØ‰ø°Ë≥¥ÁöÑÊñ∞ËÅûÊúçÂãô„ÄÇ

##### **4D Panoptic Scene Graph Generation**
2405.10305v1 by Jingkang Yang, Jun Cen, Wenxuan Peng, Shuai Liu, Fangzhou Hong, Xiangtai Li, Kaiyang Zhou, Qifeng Chen, Ziwei Liu

We are living in a three-dimensional space while moving forward through a
fourth dimension: time. To allow artificial intelligence to develop a
comprehensive understanding of such a 4D environment, we introduce 4D Panoptic
Scene Graph (PSG-4D), a new representation that bridges the raw visual data
perceived in a dynamic 4D world and high-level visual understanding.
Specifically, PSG-4D abstracts rich 4D sensory data into nodes, which represent
entities with precise location and status information, and edges, which capture
the temporal relations. To facilitate research in this new area, we build a
richly annotated PSG-4D dataset consisting of 3K RGB-D videos with a total of
1M frames, each of which is labeled with 4D panoptic segmentation masks as well
as fine-grained, dynamic scene graphs. To solve PSG-4D, we propose PSG4DFormer,
a Transformer-based model that can predict panoptic segmentation masks, track
masks along the time axis, and generate the corresponding scene graphs via a
relation component. Extensive experiments on the new dataset show that our
method can serve as a strong baseline for future research on PSG-4D. In the
end, we provide a real-world application example to demonstrate how we can
achieve dynamic scene understanding by integrating a large language model into
our PSG-4D system.

ÊëòË¶ÅÔºöÊàëÂÄëÁîüÊ¥ªÂú®‰∏âÁ∂≠Á©∫Èñì‰∏≠ÔºåÂêåÊôÇÂú®Á¨¨ÂõõÁ∂≠Â∫¶ÔºöÊôÇÈñì‰∏≠ÂâçÈÄ≤„ÄÇÁÇ∫‰∫ÜËÆì‰∫∫Â∑•Êô∫ÊÖßÁôºÂ±ïÂ∞çÈÄôÁ®Æ 4D Áí∞Â¢ÉÁöÑÂÖ®Èù¢ÁêÜËß£ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü 4D ÂÖ®ÊôØÂ†¥ÊôØÂúñ (PSG-4D)ÔºåÈÄôÊòØ‰∏ÄÁ®ÆÊñ∞ÁöÑË°®Á§∫ÊñπÂºèÔºåÂÆÉÂΩåÂêà‰∫ÜÂú®ÂãïÊÖã 4D ‰∏ñÁïå‰∏≠ÊÑüÁü•Âà∞ÁöÑÂéüÂßãË¶ñË¶∫Êï∏ÊìöÂíåÈ´òÂ±§Á¥öË¶ñË¶∫ÁêÜËß£„ÄÇÂÖ∑È´î‰æÜË™™ÔºåPSG-4D Â∞áË±êÂØåÁöÑ 4D ÊÑüÊ∏¨Êï∏ÊìöÊäΩË±°ÁÇ∫ÁØÄÈªûÔºåÈÄô‰∫õÁØÄÈªûË°®Á§∫ÂÖ∑ÊúâÁ≤æÁ¢∫‰ΩçÁΩÆÂíåÁãÄÊÖã‰ø°ÊÅØÁöÑÂØ¶È´îÔºå‰ª•ÂèäÈÇäÁ∑£ÔºåÈÄô‰∫õÈÇäÁ∑£ÊçïÁç≤ÊôÇÈñìÈóú‰øÇ„ÄÇÁÇ∫‰∫Ü‰øÉÈÄ≤ÈÄô‰∏ÄÊñ∞È†òÂüüÁöÑÁ†îÁ©∂ÔºåÊàëÂÄëÊßãÂª∫‰∫Ü‰∏ÄÂÄãË±êÂØåË®ªÈáãÁöÑ PSG-4D Êï∏ÊìöÈõÜÔºåÂÖ∂‰∏≠ÂåÖÂê´ 3K RGB-D Ë¶ñÈ†ªÔºåÁ∏ΩÂÖ± 1M ÂπÄÔºåÊØèÂÄãÂπÄÈÉΩÊ®ôË®òÊúâ 4D ÂÖ®ÊôØÂàÜÂâ≤ËíôÁâà‰ª•ÂèäÁ¥∞Á≤íÂ∫¶„ÄÅÂãïÊÖãÂ†¥ÊôØÂúñ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ PSG-4DÔºåÊàëÂÄëÊèêÂá∫‰∫Ü PSG4DFormerÔºåÈÄôÊòØ‰∏ÄÂÄãÂü∫Êñº Transformer ÁöÑÊ®°ÂûãÔºåÂÆÉÂèØ‰ª•È†êÊ∏¨ÂÖ®ÊôØÂàÜÂâ≤ËíôÁâà„ÄÅÊ≤øÊôÇÈñìËª∏ËøΩËπ§ËíôÁâàÔºå‰∏¶ÈÄöÈÅéÈóú‰øÇÁµÑÊàêÁî¢ÁîüÂ∞çÊáâÁöÑÂ†¥ÊôØÂúñ„ÄÇÂú®Êñ∞ÁöÑÊï∏ÊìöÈõÜ‰∏äÈÄ≤Ë°åÁöÑÂª£Ê≥õÂØ¶È©óË°®ÊòéÔºåÊàëÂÄëÁöÑÊ®°ÂûãÂèØ‰ª•Áî®‰ΩúÊú™‰æÜ PSG-4D Á†îÁ©∂ÁöÑÂº∑Â§ßÂü∫Á∑ö„ÄÇÊúÄÂæåÔºåÊàëÂÄëÊèê‰æõ‰∫Ü‰∏ÄÂÄãÁúüÂØ¶‰∏ñÁïåÁöÑÊáâÁî®ÁØÑ‰æãÔºå‰ª•Â±ïÁ§∫Â¶Ç‰ΩïÈÄöÈÅéÂ∞áÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÊï¥ÂêàÂà∞ÊàëÂÄëÁöÑ PSG-4D Á≥ªÁµ±‰∏≠‰æÜÂØ¶ÁèæÂãïÊÖãÂ†¥ÊôØÁêÜËß£„ÄÇ

##### **Timeline-based Sentence Decomposition with In-Context Learning for Temporal Fact Extraction**
2405.10288v2 by Jianhao Chen, Haoyuan Ouyang, Junyang Ren, Wentao Ding, Wei Hu, Yuzhong Qu

Facts extraction is pivotal for constructing knowledge graphs. Recently, the
increasing demand for temporal facts in downstream tasks has led to the
emergence of the task of temporal fact extraction. In this paper, we
specifically address the extraction of temporal facts from natural language
text. Previous studies fail to handle the challenge of establishing
time-to-fact correspondences in complex sentences. To overcome this hurdle, we
propose a timeline-based sentence decomposition strategy using large language
models (LLMs) with in-context learning, ensuring a fine-grained understanding
of the timeline associated with various facts. In addition, we evaluate the
performance of LLMs for direct temporal fact extraction and get unsatisfactory
results. To this end, we introduce TSDRE, a method that incorporates the
decomposition capabilities of LLMs into the traditional fine-tuning of smaller
pre-trained language models (PLMs). To support the evaluation, we construct
ComplexTRED, a complex temporal fact extraction dataset. Our experiments show
that TSDRE achieves state-of-the-art results on both HyperRED-Temporal and
ComplexTRED datasets.

ÊëòË¶ÅÔºö‰∫ãÂØ¶ËêÉÂèñÂ∞çÊñºÂª∫ÊßãÁü•Ë≠òÂúñË≠úËá≥ÈóúÈáçË¶Å„ÄÇÊúÄËøëÔºå‰∏ãÊ∏∏‰ªªÂãôÂ∞çÊôÇÈñì‰∫ãÂØ¶ÁöÑÈúÄÊ±ÇÂ¢ûÂä†ÔºåÂ∞éËá¥ÊôÇÈñì‰∫ãÂØ¶ËêÉÂèñ‰ªªÂãôÁöÑÂá∫Áèæ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÁâπÂà•Êé¢Ë®éÂæûËá™ÁÑ∂Ë™ûË®ÄÊñáÊú¨‰∏≠ËêÉÂèñÊôÇÈñì‰∫ãÂØ¶„ÄÇÂÖàÂâçÁöÑÁ†îÁ©∂ÁÑ°Ê≥ïËôïÁêÜÂú®Ë§áÈõúÂè•Â≠ê‰∏≠Âª∫Á´ãÊôÇÈñìÂ∞ç‰∫ãÂØ¶Â∞çÊáâÁöÑÊåëÊà∞„ÄÇÁÇ∫‰∫ÜÂÖãÊúçÈÄôÂÄãÈöúÁ§ôÔºåÊàëÂÄëÊèêÂá∫‰ΩøÁî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂíåÊÉÖÂ¢ÉÂ≠∏ÁøíÁöÑÊôÇÈñìËª∏ÂºèÂè•Â≠êÂàÜËß£Á≠ñÁï•ÔºåÁ¢∫‰øùÂ∞çËàáÂêÑÁ®Æ‰∫ãÂØ¶Áõ∏ÈóúÁöÑÊôÇÈñìËª∏ÊúâÁ¥∞Á∑ªÁöÑÁêÜËß£„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëË©ï‰º∞ LLM Âú®Áõ¥Êé•ÊôÇÈñì‰∫ãÂØ¶ËêÉÂèñ‰∏≠ÁöÑË°®ÁèæÔºå‰∏¶ÂæóÂà∞‰∏ç‰ª§‰∫∫ÊªøÊÑèÁöÑÁµêÊûú„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü TSDREÔºå‰∏ÄÁ®ÆÂ∞á LLM ÁöÑÂàÜËß£ËÉΩÂäõÊï¥ÂêàÂà∞ËºÉÂ∞èÁöÑÈ†êË®ìÁ∑¥Ë™ûË®ÄÊ®°Âûã (PLM) ÁöÑÂÇ≥Áµ±ÂæÆË™ø‰∏≠ÁöÑÊñπÊ≥ï„ÄÇÁÇ∫‰∫ÜÊîØÊåÅË©ï‰º∞ÔºåÊàëÂÄëÂª∫Êßã‰∫Ü ComplexTREDÔºå‰∏ÄÂÄãË§áÈõúÁöÑÊôÇÈñì‰∫ãÂØ¶ËêÉÂèñË≥áÊñôÈõÜ„ÄÇÊàëÂÄëÁöÑÂØ¶È©óË°®ÊòéÔºåTSDRE Âú® HyperRED-Temporal Âíå ComplexTRED Ë≥áÊñôÈõÜ‰∏äÈÉΩÂèñÂæó‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÁµêÊûú„ÄÇ

##### **SCI 3.0: A Web-based Schema Curation Interface for Graphical Event Representations**
2405.09733v2 by Reece Suchocki, Mary Martin, Martha Palmer, Susan Brown

To understand the complexity of global events, one must navigate a web of
interwoven sub-events, identifying those most impactful elements within the
larger, abstract macro-event framework at play. This concept can be extended to
the field of natural language processing (NLP) through the creation of
structured event schemas which can serve as representations of these abstract
events. Central to our approach is the Schema Curation Interface 3.0 (SCI 3.0),
a web application that facilitates real-time editing of event schema properties
within a generated graph e.g., adding, removing, or editing sub-events,
entities, and relations directly through an interface.

ÊëòË¶ÅÔºö<paragraph>Ë¶Å‰∫ÜËß£ÂÖ®ÁêÉ‰∫ã‰ª∂ÁöÑÂ§çÊùÇÊÄßÔºåÂøÖÈ°ªÂú®Áõ∏‰∫í‰∫§ÁªáÁöÑÂ≠ê‰∫ã‰ª∂ÁΩëÁªú‰∏≠Á©øÊ¢≠ÔºåÂú®ÊäΩË±°ÁöÑÂÆèËßÇ‰∫ã‰ª∂Ê°ÜÊû∂‰∏≠ËØÜÂà´ÈÇ£‰∫õÂΩ±ÂìçÊúÄÂ§ßÁöÑÂÖÉÁ¥†„ÄÇËøô‰∏™Ê¶ÇÂøµÂèØ‰ª•ÈÄöËøáÂàõÂª∫ÁªìÊûÑÂåñÁöÑ‰∫ã‰ª∂Ê®°ÂºèÊâ©Â±ïÂà∞Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜ (NLP) È¢ÜÂüüÔºåËøô‰∫õÊ®°ÂºèÂèØ‰ª•‰Ωú‰∏∫Ëøô‰∫õÊäΩË±°‰∫ã‰ª∂ÁöÑË°®Á§∫„ÄÇÊàë‰ª¨ÊñπÊ≥ïÁöÑÊ†∏ÂøÉÊòØÊ®°ÂºèÁÆ°ÁêÜÁïåÈù¢ 3.0 (SCI 3.0)ÔºåËøôÊòØ‰∏Ä‰∏™ Web Â∫îÁî®Á®ãÂ∫èÔºåÂÆÉÈÄöËøáÁïåÈù¢Áõ¥Êé•Ê∑ªÂä†„ÄÅÂà†Èô§ÊàñÁºñËæëÂ≠ê‰∫ã‰ª∂„ÄÅÂÆû‰ΩìÂíåÂÖ≥Á≥ªÔºå‰ªéËÄåÊñπ‰æøÂÆûÊó∂ÁºñËæëÁîüÊàêÁöÑÂõæÂΩ¢‰∏≠ÁöÑ‰∫ã‰ª∂Ê®°ÂºèÂ±ûÊÄß„ÄÇ</paragraph>

##### **SOK-Bench: A Situated Video Reasoning Benchmark with Aligned Open-World Knowledge**
2405.09713v2 by Andong Wang, Bo Wu, Sunli Chen, Zhenfang Chen, Haotian Guan, Wei-Ning Lee, Li Erran Li, Chuang Gan

Learning commonsense reasoning from visual contexts and scenes in real-world
is a crucial step toward advanced artificial intelligence. However, existing
video reasoning benchmarks are still inadequate since they were mainly designed
for factual or situated reasoning and rarely involve broader knowledge in the
real world. Our work aims to delve deeper into reasoning evaluations,
specifically within dynamic, open-world, and structured context knowledge. We
propose a new benchmark (SOK-Bench), consisting of 44K questions and 10K
situations with instance-level annotations depicted in the videos. The
reasoning process is required to understand and apply situated knowledge and
general knowledge for problem-solving. To create such a dataset, we propose an
automatic and scalable generation method to generate question-answer pairs,
knowledge graphs, and rationales by instructing the combinations of LLMs and
MLLMs. Concretely, we first extract observable situated entities, relations,
and processes from videos for situated knowledge and then extend to open-world
knowledge beyond the visible content. The task generation is facilitated
through multiple dialogues as iterations and subsequently corrected and refined
by our designed self-promptings and demonstrations. With a corpus of both
explicit situated facts and implicit commonsense, we generate associated
question-answer pairs and reasoning processes, finally followed by manual
reviews for quality assurance. We evaluated recent mainstream large
vision-language models on the benchmark and found several insightful
conclusions. For more information, please refer to our benchmark at
www.bobbywu.com/SOKBench.

ÊëòË¶ÅÔºöÂæûÁúüÂØ¶‰∏ñÁïåÁöÑË¶ñË¶∫ËÑàÁµ°ÂíåÂ†¥ÊôØ‰∏≠Â≠∏ÁøíÂ∏∏Ë≠òÊé®ÁêÜÊòØÈÇÅÂêëÂÖàÈÄ≤‰∫∫Â∑•Êô∫ÊÖßÁöÑÈóúÈçµ‰∏ÄÊ≠•„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÁöÑÂΩ±ÁâáÊé®ÁêÜÂü∫Ê∫ñ‰ªçÁÑ∂‰∏çË∂≥ÔºåÂõ†ÁÇ∫ÂÆÉÂÄë‰∏ªË¶ÅË®≠Ë®àÁî®Êñº‰∫ãÂØ¶ÊàñÊÉÖÂ¢ÉÊé®ÁêÜÔºåÂæàÂ∞ëÊ∂âÂèäÁèæÂØ¶‰∏ñÁïå‰∏≠ÁöÑÊõ¥Âª£Ê≥õÁü•Ë≠ò„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂Êó®Âú®Ê∑±ÂÖ•Êé¢Ë®éÊé®ÁêÜË©ï‰º∞ÔºåÁâπÂà•ÊòØÂú®ÂãïÊÖã„ÄÅÈñãÊîæ‰∏ñÁïåÂíåÁµêÊßãÂåñËÉåÊôØÁü•Ë≠ò‰∏≠„ÄÇÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÊñ∞ÁöÑÂü∫Ê∫ñ (SOK-Bench)ÔºåÂåÖÂê´ 44K ÂÄãÂïèÈ°åÂíå 10K ÂÄãÊÉÖÊ≥ÅÔºåÂÖ∂‰∏≠ÂåÖÂê´ÂΩ±Áâá‰∏≠ÊèèÁπ™ÁöÑÂØ¶‰æãÁ¥öË®ªËß£„ÄÇÊé®ÁêÜÈÅéÁ®ãÈúÄË¶ÅÁêÜËß£‰∏¶ÊáâÁî®ÊÉÖÂ¢ÉÁü•Ë≠òÂíå‰∏ÄËà¨Áü•Ë≠ò‰æÜËß£Ê±∫ÂïèÈ°å„ÄÇÁÇ∫‰∫ÜÂª∫Á´ãÈÄôÊ®£ÁöÑË≥áÊñôÈõÜÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆËá™Âãï‰∏îÂèØÊì¥ÂÖÖÁöÑÁîüÊàêÊñπÊ≥ïÔºåÈÄèÈÅéÊåáÂ∞é LLM Âíå MLLM ÁöÑÁµÑÂêà‰æÜÁîüÊàêÂïèÁ≠îÂ∞ç„ÄÅÁü•Ë≠òÂúñË≠úÂíå‰æùÊìö„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÈ¶ñÂÖàÂæûÂΩ±Áâá‰∏≠ÊèêÂèñÂèØËßÄÂØüÁöÑÊÉÖÂ¢ÉÂØ¶È´î„ÄÅÈóú‰øÇÂíåÈÅéÁ®ã‰ª•Áç≤ÂæóÊÉÖÂ¢ÉÁü•Ë≠òÔºåÁÑ∂ÂæåÊì¥Â±ïÂà∞ÂèØË¶ãÂÖßÂÆπ‰πãÂ§ñÁöÑÈñãÊîæ‰∏ñÁïåÁü•Ë≠ò„ÄÇ‰ªªÂãôÁîüÊàêÈÄèÈÅéÂ§öÈáçÂ∞çË©±‰ΩúÁÇ∫Ëø≠‰ª£‰æÜ‰øÉÈÄ≤ÔºåÈö®ÂæåÁî±ÊàëÂÄëË®≠Ë®àÁöÑËá™ÊèêÁ§∫ÂíåÁ§∫ÁØÑÈÄ≤Ë°åÊõ¥Ê≠£ÂíåÂÑ™Âåñ„ÄÇÈÄèÈÅéÂåÖÂê´ÊòéÁ¢∫ÊÉÖÂ¢É‰∫ãÂØ¶ÂíåÈö±Âê´Â∏∏Ë≠òÁöÑË™ûÊñôÂ∫´ÔºåÊàëÂÄëÁîüÊàê‰∫ÜÁõ∏ÈóúÁöÑÂïèÁ≠îÂ∞çÂíåÊé®ÁêÜÈÅéÁ®ãÔºåÊúÄÂæåÈÄ≤Ë°å‰∫∫Â∑•ÂØ©Êü•‰ª•Á¢∫‰øùÂìÅË≥™„ÄÇÊàëÂÄëÂú®Âü∫Ê∫ñ‰∏äË©ï‰º∞‰∫ÜËøëÊúü‰∏ªÊµÅÁöÑÂ§ßÂûãË¶ñË¶∫Ë™ûË®ÄÊ®°ÂûãÔºå‰∏¶ÁôºÁèæ‰∫ÜÂπæÂÄãÊúâË¶ãÂú∞ÁöÑÁµêË´ñ„ÄÇÊúâÈóúÊõ¥Â§öË≥áË®äÔºåË´ãÂèÉÈñ±ÊàëÂÄëÁöÑÂü∫Ê∫ñÔºåÁ∂≤ÂùÄÁÇ∫ www.bobbywu.com/SOKBench„ÄÇ

##### **STAR: A Benchmark for Situated Reasoning in Real-World Videos**
2405.09711v1 by Bo Wu, Shoubin Yu, Zhenfang Chen, Joshua B Tenenbaum, Chuang Gan

Reasoning in the real world is not divorced from situations. How to capture
the present knowledge from surrounding situations and perform reasoning
accordingly is crucial and challenging for machine intelligence. This paper
introduces a new benchmark that evaluates the situated reasoning ability via
situation abstraction and logic-grounded question answering for real-world
videos, called Situated Reasoning in Real-World Videos (STAR Benchmark). This
benchmark is built upon the real-world videos associated with human actions or
interactions, which are naturally dynamic, compositional, and logical. The
dataset includes four types of questions, including interaction, sequence,
prediction, and feasibility. We represent the situations in real-world videos
by hyper-graphs connecting extracted atomic entities and relations (e.g.,
actions, persons, objects, and relationships). Besides visual perception,
situated reasoning also requires structured situation comprehension and logical
reasoning. Questions and answers are procedurally generated. The answering
logic of each question is represented by a functional program based on a
situation hyper-graph. We compare various existing video reasoning models and
find that they all struggle on this challenging situated reasoning task. We
further propose a diagnostic neuro-symbolic model that can disentangle visual
perception, situation abstraction, language understanding, and functional
reasoning to understand the challenges of this benchmark.

ÊëòË¶ÅÔºöÁèæÂØ¶‰∏ñÁïå‰∏≠ÁöÑÊé®ÁêÜ‰∏¶ÈùûËÑ´Èõ¢ÊÉÖÂ¢É„ÄÇÂ¶Ç‰ΩïÂæûÂë®ÈÅ≠ÊÉÖÂ¢É‰∏≠Êì∑ÂèñÁï∂ÂâçÁü•Ë≠ò‰∏¶ÊìöÊ≠§ÈÄ≤Ë°åÊé®ÁêÜÔºåÂ∞çÊ©üÂô®Êô∫ËÉΩËÄåË®ÄËá≥ÈóúÈáçË¶Å‰∏îÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÊú¨Êñá‰ªãÁ¥π‰∫Ü‰∏ÄÂÄãÊñ∞ÁöÑÂü∫Ê∫ñÔºåÈÄèÈÅéÊÉÖÂ¢ÉÊäΩË±°Âíå‰ª•ÈÇèËºØÁÇ∫Âü∫Á§éÁöÑÂïèÁ≠îÔºåË©ï‰º∞ÁúüÂØ¶‰∏ñÁïåÂΩ±Áâá‰∏≠ÁöÑÊÉÖÂ¢ÉÊé®ÁêÜËÉΩÂäõÔºåÁ®±ÁÇ∫ÁúüÂØ¶‰∏ñÁïåÂΩ±Áâá‰∏≠ÁöÑÊÉÖÂ¢ÉÊé®ÁêÜÔºàSTARÂü∫Ê∫ñÔºâ„ÄÇÊ≠§Âü∫Ê∫ñÂª∫Á´ãÊñºËàá‰∫∫È°ûÂãï‰ΩúÊàñ‰∫íÂãïÁõ∏ÈóúÁöÑÁúüÂØ¶‰∏ñÁïåÂΩ±Áâá‰πã‰∏äÔºåÈÄô‰∫õÂΩ±ÁâáÊú¨Ë≥™‰∏äÊòØÂãïÊÖã„ÄÅÁµÑÂêà‰∏îÂêà‰πéÈÇèËºØÁöÑ„ÄÇË©≤Ë≥áÊñôÈõÜÂåÖÂê´ÂõõÁ®ÆÈ°ûÂûãÁöÑÂïèÈ°åÔºåÂåÖÊã¨‰∫íÂãï„ÄÅÈ†ÜÂ∫è„ÄÅÈ†êÊ∏¨ÂíåÂèØË°åÊÄß„ÄÇÊàëÂÄëÈÄèÈÅéÈÄ£Êé•ÊèêÂèñÁöÑÂéüÂ≠êÂØ¶È´îÂíåÈóú‰øÇÔºà‰æãÂ¶ÇÂãï‰Ωú„ÄÅ‰∫∫Áâ©„ÄÅÁâ©‰ª∂ÂíåÈóú‰øÇÔºâÁöÑË∂ÖÂúñÂΩ¢Ôºå‰æÜË°®Á§∫ÁúüÂØ¶‰∏ñÁïåÂΩ±Áâá‰∏≠ÁöÑÊÉÖÂ¢É„ÄÇÈô§‰∫ÜË¶ñË¶∫ÊÑüÁü•‰πãÂ§ñÔºåÊÉÖÂ¢ÉÊé®ÁêÜÈÇÑÈúÄË¶ÅÁµêÊßãÂåñÁöÑÊÉÖÂ¢ÉÁêÜËß£ÂíåÈÇèËºØÊé®ÁêÜ„ÄÇÂïèÈ°åÂíåÁ≠îÊ°àÊòØÁ®ãÂ∫èÂåñÁî¢ÁîüÁöÑ„ÄÇÊØèÂÄãÂïèÈ°åÁöÑÂõûÁ≠îÈÇèËºØÁî±Âü∫ÊñºÊÉÖÂ¢ÉË∂ÖÂúñÂΩ¢ÁöÑÂáΩÂºèÁ®ãÂºèË°®Á§∫„ÄÇÊàëÂÄëÊØîËºÉ‰∫ÜÁèæÊúâÁöÑÂêÑÁ®ÆÂΩ±ÁâáÊé®ÁêÜÊ®°ÂûãÔºåÁôºÁèæÂÆÉÂÄëÂú®ÈÄôÂÄãÂÖ∑ÊúâÊåëÊà∞ÊÄßÁöÑÊÉÖÂ¢ÉÊé®ÁêÜ‰ªªÂãô‰∏≠ÈÉΩË°®Áèæ‰∏ç‰Ω≥„ÄÇÊàëÂÄëÈÄ≤‰∏ÄÊ≠•ÊèêÂá∫‰∫Ü‰∏ÄÂÄãË®∫Êñ∑ÊÄßÁ•ûÁ∂ìÁ¨¶ËôüÊ®°ÂûãÔºåÂÆÉÂèØ‰ª•Ëß£ÈñãË¶ñË¶∫ÊÑüÁü•„ÄÅÊÉÖÂ¢ÉÊäΩË±°„ÄÅË™ûË®ÄÁêÜËß£ÂíåÂáΩÂºèÊé®ÁêÜÔºå‰ª•‰∫ÜËß£Ê≠§Âü∫Ê∫ñÁöÑÊåëÊà∞„ÄÇ

##### **Falcon 7b for Software Mention Detection in Scholarly Documents**
2405.08514v1 by AmeerAli Khan, Qusai Ramadan, Cong Yang, Zeyd Boukhers

This paper aims to tackle the challenge posed by the increasing integration
of software tools in research across various disciplines by investigating the
application of Falcon-7b for the detection and classification of software
mentions within scholarly texts. Specifically, the study focuses on solving
Subtask I of the Software Mention Detection in Scholarly Publications (SOMD),
which entails identifying and categorizing software mentions from academic
literature. Through comprehensive experimentation, the paper explores different
training strategies, including a dual-classifier approach, adaptive sampling,
and weighted loss scaling, to enhance detection accuracy while overcoming the
complexities of class imbalance and the nuanced syntax of scholarly writing.
The findings highlight the benefits of selective labelling and adaptive
sampling in improving the model's performance. However, they also indicate that
integrating multiple strategies does not necessarily result in cumulative
improvements. This research offers insights into the effective application of
large language models for specific tasks such as SOMD, underlining the
importance of tailored approaches to address the unique challenges presented by
academic text analysis.

ÊëòË¶ÅÔºöÈÄôÁØáË´ñÊñáÊó®Âú®Ëß£Ê±∫ËªüÈ´îÂ∑•ÂÖ∑Âú®ÂêÑÂÄãÈ†òÂüüÁ†îÁ©∂‰∏≠Êó•ÁõäÊï¥ÂêàÊâÄÂ∏∂‰æÜÁöÑÊåëÊà∞ÔºåÁ†îÁ©∂ Falcon-7b Âú®Â≠∏Ë°ìÊñáÊú¨‰∏≠ÂÅµÊ∏¨ÂíåÂàÜÈ°ûËªüÈ´îÊèêÂèäÁöÑÊáâÁî®„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÈÄôÈ†ÖÁ†îÁ©∂Â∞àÊ≥®ÊñºËß£Ê±∫Â≠∏Ë°ìÂá∫ÁâàÁâ©‰∏≠ËªüÈ´îÊèêÂèäÂÅµÊ∏¨ (SOMD) ÁöÑÂ≠ê‰ªªÂãô‰∏ÄÔºåÂÖ∂‰∏≠ÂåÖÊã¨Ë≠òÂà•ÂíåÂàÜÈ°ûÂ≠∏Ë°ìÊñáÁçª‰∏≠ÁöÑËªüÈ´îÊèêÂèä„ÄÇÈÄèÈÅéÂÖ®Èù¢ÁöÑÂØ¶È©óÔºåÊú¨ÊñáÊé¢Ë®é‰∫Ü‰∏çÂêåÁöÑË®ìÁ∑¥Á≠ñÁï•ÔºåÂåÖÊã¨ÈõôÂàÜÈ°ûÂô®ÊñπÊ≥ï„ÄÅËá™ÈÅ©ÊáâÊäΩÊ®£ÂíåÂä†Ê¨äÊêçÂ§±Á∏ÆÊîæÔºå‰ª•Âú®ÂÖãÊúçÈ°ûÂà•‰∏çÂπ≥Ë°°ÁöÑË§áÈõúÊÄßÂíåÂ≠∏Ë°ìÂØ´‰ΩúÁöÑÁ¥∞ÂæÆË™ûÊ≥ïÁöÑÊÉÖÊ≥Å‰∏ãÔºåÊèêÂçáÂÅµÊ∏¨Ê∫ñÁ¢∫Â∫¶„ÄÇÁ†îÁ©∂ÁµêÊûúÁ™ÅÈ°Ø‰∫ÜÈÅ∏ÊìáÊÄßÊ®ôË®òÂíåËá™ÈÅ©ÊáâÊäΩÊ®£Âú®ÊèêÂçáÊ®°ÂûãÊïàËÉΩÊñπÈù¢ÁöÑÂÑ™Èªû„ÄÇÁÑ∂ËÄåÔºåÁ†îÁ©∂ÁµêÊûú‰πüÊåáÂá∫ÔºåÊï¥ÂêàÂ§öÁ®ÆÁ≠ñÁï•‰∏¶‰∏ç‰∏ÄÂÆöÊúÉÂ∏∂‰æÜÁ¥ØÁ©çÁöÑÈÄ≤Ê≠•„ÄÇÈÄôÈ†ÖÁ†îÁ©∂Êèê‰æõ‰∫ÜÂ∞çÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÂú®ÁâπÂÆö‰ªªÂãôÔºà‰æãÂ¶Ç SOMDÔºâ‰∏≠ÁöÑÊúâÊïàÊáâÁî®‰πãË¶ãËß£ÔºåÂº∑Ë™ø‰∫ÜÈáèË∫´ÊâìÈÄ†ÊñπÊ≥ïÂ∞çÊñºËß£Ê±∫Â≠∏Ë°ìÊñáÊú¨ÂàÜÊûêÊâÄÂëàÁèæ‰πãÁç®ÁâπÊåëÊà∞ÁöÑÈáçË¶ÅÊÄß„ÄÇ

##### **Could Chemical LLMs benefit from Message Passing**
2405.08334v1 by Jiaqing Xie, Ziheng Chi

Pretrained language models (LMs) showcase significant capabilities in
processing molecular text, while concurrently, message passing neural networks
(MPNNs) demonstrate resilience and versatility in the domain of molecular
science. Despite these advancements, we find there are limited studies
investigating the bidirectional interactions between molecular structures and
their corresponding textual representations. Therefore, in this paper, we
propose two strategies to evaluate whether an information integration can
enhance the performance: contrast learning, which involves utilizing an MPNN to
supervise the training of the LM, and fusion, which exploits information from
both models. Our empirical analysis reveals that the integration approaches
exhibit superior performance compared to baselines when applied to smaller
molecular graphs, while these integration approaches do not yield performance
enhancements on large scale graphs.

ÊëòË¶ÅÔºöÈ†êÂÖàË®ìÁ∑¥ÁöÑË™ûË®ÄÊ®°Âûã (LM) Âú®ËôïÁêÜÂàÜÂ≠êÊñáÊú¨ÊñπÈù¢Â±ïÁ§∫Âá∫È°ØËëóÁöÑËÉΩÂäõÔºåÂêåÊôÇÔºåË®äÊÅØÂÇ≥ÈÅûÁ•ûÁ∂ìÁ∂≤Ë∑Ø (MPNN) Âú®ÂàÜÂ≠êÁßëÂ≠∏È†òÂüü‰∏≠Â±ïÁèæÂá∫ÈüåÊÄßÂíåÂ§öÂäüËÉΩÊÄß„ÄÇÂÑòÁÆ°ÊúâÈÄô‰∫õÈÄ≤Â±ïÔºåÊàëÂÄëÁôºÁèæÊé¢Ë®éÂàÜÂ≠êÁµêÊßãËàáÂÖ∂Â∞çÊáâÊñáÊú¨Ë°®Á§∫‰πãÈñìÈõôÂêë‰∫§‰∫í‰ΩúÁî®ÁöÑÁ†îÁ©∂ÊúâÈôê„ÄÇÂõ†Ê≠§ÔºåÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫ÂÖ©Á®ÆÁ≠ñÁï•‰æÜË©ï‰º∞Ë≥áË®äÊï¥ÂêàÊòØÂê¶ËÉΩÊèêÂçáÊïàËÉΩÔºöÂ∞çÊØîÂ≠∏ÁøíÔºåÊ∂âÂèäÂà©Áî® MPNN Áõ£Áù£ LM ÁöÑË®ìÁ∑¥Ôºå‰ª•ÂèäËûçÂêàÔºåÂà©Áî®‰æÜËá™ÂÖ©ÂÄãÊ®°ÂûãÁöÑË≥áË®ä„ÄÇÊàëÂÄëÁöÑÂØ¶Ë≠âÂàÜÊûêÈ°ØÁ§∫ÔºåËàáÊáâÁî®ÊñºËºÉÂ∞èÂàÜÂ≠êÂúñÂΩ¢ÁöÑÂü∫Ê∫ñÁ∑öÁõ∏ÊØîÔºåÊï¥ÂêàÊñπÊ≥ïÂ±ïÁèæÂá∫ÂÑ™Áï∞ÁöÑÊïàËÉΩÔºåËÄåÈÄô‰∫õÊï¥ÂêàÊñπÊ≥ï‰∏¶Êú™Âú®Â§ßÂûãÂúñÂΩ¢‰∏äÁî¢ÁîüÊïàËÉΩÊèêÂçá„ÄÇ

##### **AnomalyLLM: Few-shot Anomaly Edge Detection for Dynamic Graphs using Large Language Models**
2405.07626v1 by Shuo Liu, Di Yao, Lanting Fang, Zhetao Li, Wenbin Li, Kaiyu Feng, XiaoWen Ji, Jingping Bi

Detecting anomaly edges for dynamic graphs aims to identify edges
significantly deviating from the normal pattern and can be applied in various
domains, such as cybersecurity, financial transactions and AIOps. With the
evolving of time, the types of anomaly edges are emerging and the labeled
anomaly samples are few for each type. Current methods are either designed to
detect randomly inserted edges or require sufficient labeled data for model
training, which harms their applicability for real-world applications. In this
paper, we study this problem by cooperating with the rich knowledge encoded in
large language models(LLMs) and propose a method, namely AnomalyLLM. To align
the dynamic graph with LLMs, AnomalyLLM pre-trains a dynamic-aware encoder to
generate the representations of edges and reprograms the edges using the
prototypes of word embeddings. Along with the encoder, we design an in-context
learning framework that integrates the information of a few labeled samples to
achieve few-shot anomaly detection. Experiments on four datasets reveal that
AnomalyLLM can not only significantly improve the performance of few-shot
anomaly detection, but also achieve superior results on new anomalies without
any update of model parameters.

ÊëòË¶ÅÔºöÂÅµÊ∏¨ÂãïÊÖãÂúñÂΩ¢ÁöÑÁï∞Â∏∏ÈÇäÁ∑£Êó®Âú®Ë≠òÂà•È°ØËëóÂÅèÈõ¢Ê≠£Â∏∏Ê®°ÂºèÁöÑÈÇäÁ∑£Ôºå‰∏¶ÂèØÁî®ÊñºÂêÑÁ®ÆÈ†òÂüüÔºå‰æãÂ¶ÇÁ∂≤Ë∑ØÂÆâÂÖ®„ÄÅÈáëËûç‰∫§ÊòìÂíå AIOps„ÄÇÈö®ËëóÊôÇÈñìÁöÑÊé®ÁßªÔºåÁï∞Â∏∏ÈÇäÁ∑£ÁöÑÈ°ûÂûã‰∏çÊñ∑Âá∫ÁèæÔºåËÄåÊØèÁ®ÆÈ°ûÂûãÁöÑÊ®ôÁ±§Áï∞Â∏∏Ê®£Êú¨ÂæàÂ∞ë„ÄÇÁõÆÂâçÁöÑÊäÄË°ìÊñπÊ≥ïÊó®Âú®ÂÅµÊ∏¨Èö®Ê©üÊèíÂÖ•ÁöÑÈÇäÁ∑£ÔºåÊàñÈúÄË¶ÅË∂≥Â§†ÁöÑÊ®ôÁ±§Ë≥áÊñôÈÄ≤Ë°åÊ®°ÂûãË®ìÁ∑¥ÔºåÈÄôÊúÉÊêçÂÆ≥ÂÖ∂Âú®ÂØ¶ÈöõÊáâÁî®‰∏≠ÁöÑÈÅ©Áî®ÊÄß„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÈÄèÈÅéËàáÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰∏≠Á∑®Á¢ºÁöÑË±êÂØåÁü•Ë≠òÂêà‰Ωú‰æÜÁ†îÁ©∂ÈÄôÂÄãÂïèÈ°åÔºå‰∏¶ÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂêçÁÇ∫ AnomalyLLM ÁöÑÊñπÊ≥ï„ÄÇÁÇ∫‰∫ÜÂ∞áÂãïÊÖãÂúñÂΩ¢Ëàá LLM Â∞çÈΩäÔºåAnomalyLLM È†êÂÖàË®ìÁ∑¥‰∫Ü‰∏ÄÂÄãÂãïÊÖãÊÑüÁü•Á∑®Á¢ºÂô®Ôºå‰ª•Áî¢ÁîüÈÇäÁ∑£ÁöÑË°®Á§∫Ôºå‰∏¶‰ΩøÁî®Ë©ûÂµåÂÖ•ÁöÑÂéüÂûãÈáçÊñ∞Á∑®ÂØ´ÈÇäÁ∑£„ÄÇÊàëÂÄëËàáÁ∑®Á¢ºÂô®‰∏ÄËµ∑Ë®≠Ë®à‰∫Ü‰∏ÄÂÄãÊÉÖÂ¢ÉÂÖßÂ≠∏ÁøíÊ°ÜÊû∂ÔºåÊï¥Âêà‰∫ÜÂ∞ëÊï∏Ê®ôÁ±§Ê®£Êú¨ÁöÑË≥áË®äÔºå‰ª•ÂØ¶ÁèæÂ∞ëÁôºÁï∞Â∏∏ÂÅµÊ∏¨„ÄÇÂú®ÂõõÂÄãË≥áÊñôÈõÜ‰∏äÁöÑÂØ¶È©óË°®ÊòéÔºåAnomalyLLM ‰∏çÂÉÖÂèØ‰ª•È°ØËëóÊîπÂñÑÂ∞ëÁôºÁï∞Â∏∏ÂÅµÊ∏¨ÁöÑÊïàËÉΩÔºåÈÇÑËÉΩÂ∞çÊ≤íÊúâ‰ªª‰ΩïÊ®°ÂûãÂèÉÊï∏Êõ¥Êñ∞ÁöÑÊñ∞Áï∞Â∏∏ÊÉÖÊ≥ÅÂèñÂæóÂÑ™Áï∞ÁöÑÁµêÊûú„ÄÇ

##### **DynLLM: When Large Language Models Meet Dynamic Graph Recommendation**
2405.07580v1 by Ziwei Zhao, Fake Lin, Xi Zhu, Zhi Zheng, Tong Xu, Shitian Shen, Xueying Li, Zikai Yin, Enhong Chen

Last year has witnessed the considerable interest of Large Language Models
(LLMs) for their potential applications in recommender systems, which may
mitigate the persistent issue of data sparsity. Though large efforts have been
made for user-item graph augmentation with better graph-based recommendation
performance, they may fail to deal with the dynamic graph recommendation task,
which involves both structural and temporal graph dynamics with inherent
complexity in processing time-evolving data. To bridge this gap, in this paper,
we propose a novel framework, called DynLLM, to deal with the dynamic graph
recommendation task with LLMs. Specifically, DynLLM harnesses the power of LLMs
to generate multi-faceted user profiles based on the rich textual features of
historical purchase records, including crowd segments, personal interests,
preferred categories, and favored brands, which in turn supplement and enrich
the underlying relationships between users and items. Along this line, to fuse
the multi-faceted profiles with temporal graph embedding, we engage LLMs to
derive corresponding profile embeddings, and further employ a distilled
attention mechanism to refine the LLM-generated profile embeddings for
alleviating noisy signals, while also assessing and adjusting the relevance of
each distilled facet embedding for seamless integration with temporal graph
embedding from continuous time dynamic graphs (CTDGs). Extensive experiments on
two real e-commerce datasets have validated the superior improvements of DynLLM
over a wide range of state-of-the-art baseline methods.

ÊëòË¶ÅÔºöÂéªÂπ¥ÔºåÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âõ†ÂÖ∂Âú®Êé®Ëñ¶Á≥ªÁµ±‰∏≠ÁöÑÊΩõÂú®ÊáâÁî®ËÄåÂÇôÂèóÈóúÊ≥®ÔºåÈÄôÂèØËÉΩÊúÉÁ∑©Ëß£Êï∏ÊìöÁ®ÄÁñèÊÄßÁöÑÊåÅÁ∫åÂïèÈ°å„ÄÇÂÑòÁÆ°Â∑≤ÁÇ∫Áî®Êà∂È†ÖÁõÆÂúñÂ¢ûÂº∑ÂÅöÂá∫Â∑®Â§ßÂä™ÂäõÔºå‰ª•ÊèêÈ´òÂü∫ÊñºÂúñÂΩ¢ÁöÑÊé®Ëñ¶ÊÄßËÉΩÔºå‰ΩÜÂÆÉÂÄëÂèØËÉΩÁÑ°Ê≥ïËôïÁêÜÂãïÊÖãÂúñÂΩ¢Êé®Ëñ¶‰ªªÂãôÔºåÂÖ∂‰∏≠Ê∂âÂèäÁµêÊßãÂíåÊôÇÈñìÂúñÂΩ¢ÂãïÊÖãÔºåÂú®ËôïÁêÜÊôÇÈñìÊºîÂåñÊï∏ÊìöÊôÇÂÖ∑ÊúâÂõ∫ÊúâÁöÑË§áÈõúÊÄß„ÄÇÁÇ∫‰∫ÜÂΩåÂêàÈÄô‰∏ÄÂ∑ÆË∑ùÔºåÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂêçÁÇ∫ DynLLM ÁöÑÊñ∞Ê°ÜÊû∂Ôºå‰ª•‰ΩøÁî® LLM ËôïÁêÜÂãïÊÖãÂúñÂΩ¢Êé®Ëñ¶‰ªªÂãô„ÄÇÂÖ∑È´î‰æÜË™™ÔºåDynLLM Âà©Áî® LLM ÁöÑËÉΩÂäõÔºåÊ†πÊìöÊ≠∑Âè≤Ë≥ºË≤∑Ë®òÈåÑÁöÑË±êÂØåÊñáÊú¨ÁâπÂæµÁîüÊàêÂ§öÊñπÈù¢ÁöÑÁî®Êà∂Ë≥áÊñôÔºåÂåÖÊã¨‰∫∫Áæ§ÂçÄÂ°ä„ÄÅÂÄã‰∫∫ËààË∂£„ÄÅÈ¶ñÈÅ∏È°ûÂà•ÂíåÂñúÊÑõÁöÑÂìÅÁâåÔºåÈÄ≤ËÄåË£úÂÖÖÂíåË±êÂØåÁî®Êà∂ÂíåÈ†ÖÁõÆ‰πãÈñìÁöÑÂ∫ïÂ±§Èóú‰øÇ„ÄÇÈ†ÜËëóÈÄôÊ¢ùÊÄùË∑ØÔºåÁÇ∫‰∫ÜÂ∞áÂ§öÊñπÈù¢ÁöÑË≥áÊñôËàáÊôÇÈñìÂúñÂΩ¢ÂµåÂÖ•ËûçÂêàÔºåÊàëÂÄë‰ΩøÁî® LLM ÂæóÂá∫Áõ∏ÊáâÁöÑË≥áÊñôÂµåÂÖ•Ôºå‰∏¶ÈÄ≤‰∏ÄÊ≠•Êé°Áî®Á≤æÁÖâÁöÑÊ≥®ÊÑèÂäõÊ©üÂà∂‰æÜÁ≤æÁÖâ LLM ÁîüÊàêÁöÑË≥áÊñôÂµåÂÖ•Ôºå‰ª•Ê∏õËºïÈõúË®ä‰ø°ËôüÔºåÂêåÊôÇË©ï‰º∞ÂíåË™øÊï¥ÊØèÂÄãÁ≤æÁÖâÁöÑÊñπÈù¢ÂµåÂÖ•Ëàá‰æÜËá™ÈÄ£Á∫åÊôÇÈñìÂãïÊÖãÂúñÂΩ¢ (CTDG) ÁöÑÊôÇÈñìÂúñÂΩ¢ÂµåÂÖ•ÁöÑÁÑ°Á∏´Êï¥Âêà„ÄÇÂú®ÂÖ©ÂÄãÁúüÂØ¶ÈõªÂ≠êÂïÜÂãôÊï∏ÊìöÈõÜ‰∏äÈÄ≤Ë°åÁöÑÂª£Ê≥õÂØ¶È©óÈ©óË≠â‰∫Ü DynLLM Â∞çÂª£Ê≥õÁöÑÊúÄÊñ∞Âü∫Á∑öÊñπÊ≥ïÁöÑÂÑ™Ë∂äÊîπÈÄ≤„ÄÇ

##### **LLM-Generated Black-box Explanations Can Be Adversarially Helpful**
2405.06800v2 by Rohan Ajwani, Shashidhar Reddy Javaji, Frank Rudzicz, Zining Zhu

Large Language Models (LLMs) are becoming vital tools that help us solve and
understand complex problems by acting as digital assistants. LLMs can generate
convincing explanations, even when only given the inputs and outputs of these
problems, i.e., in a ``black-box'' approach. However, our research uncovers a
hidden risk tied to this approach, which we call *adversarial helpfulness*.
This happens when an LLM's explanations make a wrong answer look right,
potentially leading people to trust incorrect solutions. In this paper, we show
that this issue affects not just humans, but also LLM evaluators. Digging
deeper, we identify and examine key persuasive strategies employed by LLMs. Our
findings reveal that these models employ strategies such as reframing the
questions, expressing an elevated level of confidence, and cherry-picking
evidence to paint misleading answers in a credible light. To examine if LLMs
are able to navigate complex-structured knowledge when generating adversarially
helpful explanations, we create a special task based on navigating through
graphs. Most LLMs are not able to find alternative paths along simple graphs,
indicating that their misleading explanations aren't produced by only logical
deductions using complex knowledge. These findings shed light on the
limitations of the black-box explanation setting and allow us to provide advice
on the safe usage of LLMs.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Ê≠£ÊàêÁÇ∫Âπ´Âä©ÊàëÂÄëËß£Ê±∫ÂíåÁêÜËß£Ë§áÈõúÂïèÈ°åÁöÑÈáçË¶ÅÂ∑•ÂÖ∑ÔºåÂõ†ÁÇ∫ÂÆÉÂÄëÂèØ‰ª•‰ΩúÁÇ∫Êï∏‰ΩçÂä©ÁêÜ„ÄÇLLM ÂèØ‰ª•Áî¢Áîü‰ª§‰∫∫‰ø°ÊúçÁöÑËß£ÈáãÔºåÂç≥‰ΩøÂÉÖÊèê‰æõÈÄô‰∫õÂïèÈ°åÁöÑËº∏ÂÖ•ÂíåËº∏Âá∫ÔºåÂç≥Âú®„ÄåÈªëÁõíÂ≠ê„ÄçÊñπÊ≥ï‰∏≠„ÄÇÁÑ∂ËÄåÔºåÊàëÂÄëÁöÑÁ†îÁ©∂Êè≠Èú≤‰∫ÜËàáÈÄôÁ®ÆÊñπÊ≥ïÁõ∏ÈóúÁöÑÈö±ËóèÈ¢®Èö™ÔºåÊàëÂÄëÁ®±‰πãÁÇ∫„ÄåÂ∞çÊäóÊÄßÂπ´Âä©„Äç„ÄÇÈÄôÊúÉÁôºÁîüÂú® LLM ÁöÑËß£ÈáãËÆìÈåØË™§Á≠îÊ°àÁúãËµ∑‰æÜÊ≠£Á¢∫ÊôÇÔºåÂèØËÉΩÊúÉÂ∞éËá¥‰∫∫ÂÄëÁõ∏‰ø°‰∏çÊ≠£Á¢∫ÁöÑËß£Ê±∫ÊñπÊ°à„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜÈÄôÂÄãÂïèÈ°å‰∏çÂÉÖÂΩ±Èüø‰∫∫È°ûÔºå‰πüÂΩ±Èüø LLM Ë©ï‰º∞ËÄÖ„ÄÇÊ∑±ÂÖ•Êé¢Ë®éÂæåÔºåÊàëÂÄëÊâæÂá∫‰∏¶Ê™¢Ë¶ñ LLM ‰ΩøÁî®ÁöÑ‰∏ªË¶ÅË™™ÊúçÁ≠ñÁï•„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÈ°ØÁ§∫ÔºåÈÄô‰∫õÊ®°ÂûãÊé°Áî®‰∫ÜÈáçÊñ∞Âª∫ÊßãÂïèÈ°å„ÄÅË°®ÈÅîÈ´òÂ∫¶‰ø°ÂøÉÔºå‰ª•ÂèäÊåëÈÅ∏Ë≠âÊìö‰æÜ‰ª•‰ª§‰∫∫‰ø°ÊúçÁöÑÊñπÂºèÊèèÁπ™Ë™§Â∞éÁ≠îÊ°àÁ≠âÁ≠ñÁï•„ÄÇÁÇ∫‰∫ÜÊé¢Ë®é LLM Âú®Áî¢ÁîüÂ∞çÊäóÊÄßÊúâÁî®ÁöÑËß£ÈáãÊôÇÊòØÂê¶ËÉΩÂ§†Â∞éËà™Ë§áÈõúÁµêÊßãÁöÑÁü•Ë≠òÔºåÊàëÂÄëÊ†πÊìöÂ∞éËà™ÂúñÂΩ¢Âª∫Á´ã‰∫Ü‰∏ÄÂÄãÁâπÊÆä‰ªªÂãô„ÄÇÂ§ßÂ§öÊï∏ LLM ÁÑ°Ê≥ïÂú®Á∞°ÂñÆÁöÑÂúñÂΩ¢‰∏≠ÊâæÂà∞Êõø‰ª£Ë∑ØÂæëÔºåÈÄôË°®Á§∫ÂÆÉÂÄëÁöÑË™§Â∞éÊÄßËß£Èáã‰∏¶ÈùûÂÉÖÂÉÖÈÄèÈÅé‰ΩøÁî®Ë§áÈõúÁü•Ë≠òÁöÑÈÇèËºØÊé®Ë´ñÁî¢Áîü„ÄÇÈÄô‰∫õÁ†îÁ©∂ÁµêÊûúÈó°Êòé‰∫ÜÈªëÁõíÂ≠êËß£ÈáãË®≠ÂÆöÁöÑÈôêÂà∂Ôºå‰∏¶ËÆìÊàëÂÄëËÉΩÂ§†Êèê‰æõÊúâÈóúÂÆâÂÖ®‰ΩøÁî® LLM ÁöÑÂª∫Ë≠∞„ÄÇ

##### **A Survey of Large Language Models for Graphs**
2405.08011v1 by Xubin Ren, Jiabin Tang, Dawei Yin, Nitesh Chawla, Chao Huang

Graphs are an essential data structure utilized to represent relationships in
real-world scenarios. Prior research has established that Graph Neural Networks
(GNNs) deliver impressive outcomes in graph-centric tasks, such as link
prediction and node classification. Despite these advancements, challenges like
data sparsity and limited generalization capabilities continue to persist.
Recently, Large Language Models (LLMs) have gained attention in natural
language processing. They excel in language comprehension and summarization.
Integrating LLMs with graph learning techniques has attracted interest as a way
to enhance performance in graph learning tasks. In this survey, we conduct an
in-depth review of the latest state-of-the-art LLMs applied in graph learning
and introduce a novel taxonomy to categorize existing methods based on their
framework design. We detail four unique designs: i) GNNs as Prefix, ii) LLMs as
Prefix, iii) LLMs-Graphs Integration, and iv) LLMs-Only, highlighting key
methodologies within each category. We explore the strengths and limitations of
each framework, and emphasize potential avenues for future research, including
overcoming current integration challenges between LLMs and graph learning
techniques, and venturing into new application areas. This survey aims to serve
as a valuable resource for researchers and practitioners eager to leverage
large language models in graph learning, and to inspire continued progress in
this dynamic field. We consistently maintain the related open-source materials
at \url{https://github.com/HKUDS/Awesome-LLM4Graph-Papers}.

ÊëòË¶ÅÔºöÂúñÂΩ¢ÊòØ‰∏ÄÁ®ÆÈáçË¶ÅÁöÑË≥áÊñôÁµêÊßãÔºåÁî®ÊñºË°®Á§∫ÁúüÂØ¶‰∏ñÁïåÂ†¥ÊôØ‰∏≠ÁöÑÈóú‰øÇ„ÄÇÂÖàÂâçÁöÑÁ†îÁ©∂Â∑≤Á¢∫Á´ãÂúñÁ•ûÁ∂ìÁ∂≤Ë∑Ø (GNN) Âú®‰ª•ÂúñÂΩ¢ÁÇ∫‰∏≠ÂøÉÁöÑ‰ªªÂãô‰∏≠Êèê‰æõ‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑÊàêÊûúÔºå‰æãÂ¶ÇÈÄ£ÁµêÈ†êÊ∏¨ÂíåÁØÄÈªûÂàÜÈ°û„ÄÇÂÑòÁÆ°ÊúâÈÄô‰∫õÈÄ≤Â±ïÔºå‰ΩÜË≥áÊñôÁ®ÄÁñèÊÄßÂíåÊúâÈôêÁöÑÊ¶ÇÂåñËÉΩÂäõÁ≠âÊåëÊà∞‰ªçÁÑ∂ÊåÅÁ∫åÂ≠òÂú®„ÄÇÊúÄËøëÔºåÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®Ëá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ‰∏≠ÂÇôÂèóÈóúÊ≥®„ÄÇÂÆÉÂÄëÂú®Ë™ûË®ÄÁêÜËß£ÂíåÊëòË¶ÅÊñπÈù¢Ë°®ÁèæÂá∫Ëâ≤„ÄÇÂ∞á LLM ËàáÂúñÂΩ¢Â≠∏ÁøíÊäÄË°ìÊï¥ÂêàÂ∑≤ÂºïËµ∑ËààË∂£Ôºå‰ΩúÁÇ∫Â¢ûÂº∑ÂúñÂΩ¢Â≠∏Áøí‰ªªÂãôÊïàËÉΩÁöÑ‰∏ÄÁ®ÆÊñπÂºè„ÄÇÂú®ÈÄôÈ†ÖË™øÊü•‰∏≠ÔºåÊàëÂÄëÂ∞çÊáâÁî®ÊñºÂúñÂΩ¢Â≠∏ÁøíÁöÑÊúÄÊñ∞ÊúÄÂÖàÈÄ≤ÁöÑ LLM ÈÄ≤Ë°åÊ∑±ÂÖ•Êé¢Ë®éÔºå‰∏¶ÂºïÂÖ•‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÂàÜÈ°ûÊ≥ïÔºåÊ†πÊìöÂÖ∂Êû∂ÊßãË®≠Ë®àÂ∞çÁèæÊúâÊñπÊ≥ïÈÄ≤Ë°åÂàÜÈ°û„ÄÇÊàëÂÄëË©≥Á¥∞Ë™™ÊòéÂõõÁ®ÆÁç®ÁâπË®≠Ë®àÔºöi) GNN ‰ΩúÁÇ∫ÂâçÁ∂¥Ôºåii) LLM ‰ΩúÁÇ∫ÂâçÁ∂¥Ôºåiii) LLM-ÂúñÂΩ¢Êï¥ÂêàÔºå‰ª•Âèä iv) ÂÉÖ LLMÔºåÂº∑Ë™øÊØèÂÄãÈ°ûÂà•‰∏≠ÁöÑÈóúÈçµÊñπÊ≥ï„ÄÇÊàëÂÄëÊé¢Ë®éÊØèÂÄãÊû∂ÊßãÁöÑÂÑ™ÈªûÂíåÈôêÂà∂Ôºå‰∏¶Âº∑Ë™øÊú™‰æÜÁ†îÁ©∂ÁöÑÊΩõÂú®ÈÄîÂæëÔºåÂåÖÊã¨ÂÖãÊúç LLM ÂíåÂúñÂΩ¢Â≠∏ÁøíÊäÄË°ì‰πãÈñìÁõÆÂâçÁöÑÊï¥ÂêàÊåëÊà∞Ôºå‰∏¶ÈÄ≤ËªçÊñ∞ÁöÑÊáâÁî®È†òÂüü„ÄÇÈÄôÈ†ÖË™øÊü•Êó®Âú®‰ΩúÁÇ∫Á†îÁ©∂‰∫∫Âì°ÂíåÂØ¶ÂãôÂ∑•‰ΩúËÄÖÁöÑÂØ∂Ë≤¥Ë≥áÊ∫êÔºå‰ªñÂÄëÊ∏¥ÊúõÂú®ÂúñÂΩ¢Â≠∏Áøí‰∏≠Âà©Áî®Â§ßÂûãË™ûË®ÄÊ®°ÂûãÔºå‰∏¶ÊøÄÂãµÈÄôÂÄãÂãïÊÖãÈ†òÂüüÊåÅÁ∫åÈÄ≤Ê≠•„ÄÇÊàëÂÄëÊåÅÁ∫åÁ∂≠Ë≠∑Áõ∏ÈóúÁöÑÈñãÊ∫êÊùêÊñôÔºåÁ∂≤ÂùÄÁÇ∫ \url{https://github.com/HKUDS/Awesome-LLM4Graph-Papers}„ÄÇ

##### **Multimodal LLMs Struggle with Basic Visual Network Analysis: a VNA Benchmark**
2405.06634v1 by Evan M. Williams, Kathleen M. Carley

We evaluate the zero-shot ability of GPT-4 and LLaVa to perform simple Visual
Network Analysis (VNA) tasks on small-scale graphs. We evaluate the Vision
Language Models (VLMs) on 5 tasks related to three foundational network science
concepts: identifying nodes of maximal degree on a rendered graph, identifying
whether signed triads are balanced or unbalanced, and counting components. The
tasks are structured to be easy for a human who understands the underlying
graph theoretic concepts, and can all be solved by counting the appropriate
elements in graphs. We find that while GPT-4 consistently outperforms LLaVa,
both models struggle with every visual network analysis task we propose. We
publicly release the first benchmark for the evaluation of VLMs on foundational
VNA tasks.

ÊëòË¶ÅÔºöÊàëÂÄëË©ï‰º∞ GPT-4 Âíå LLaVa ÁöÑÈõ∂Ê¨°Â≠∏ÁøíËÉΩÂäõÔºå‰ª•Âü∑Ë°åÂ∞èË¶èÊ®°ÂúñÂΩ¢‰∏äÁöÑÁ∞°ÂñÆË¶ñË¶∫Á∂≤Ë∑ØÂàÜÊûê (VNA) ‰ªªÂãô„ÄÇÊàëÂÄëË©ï‰º∞Ë¶ñË¶∫Ë™ûË®ÄÊ®°Âûã (VLM) Âú® 5 ÂÄãËàá‰∏âÂÄãÂü∫Á§éÁ∂≤Ë∑ØÁßëÂ≠∏Ê¶ÇÂøµÁõ∏ÈóúÁöÑ‰ªªÂãô‰∏äÔºöË≠òÂà•Ê∏≤ÊüìÂúñÂΩ¢‰∏äÊúÄÂ§ßÁ®ãÂ∫¶ÁöÑÁØÄÈªû„ÄÅË≠òÂà•Â∏∂Ê≠£Ë≤†ËôüÁöÑ‰∏âÂÖÉÁµÑÊòØÂπ≥Ë°°ÈÇÑÊòØ‰∏çÂπ≥Ë°°Ôºå‰ª•ÂèäË®àÁÆóÁµÑÊàêÈÉ®ÂàÜ„ÄÇÈÄô‰∫õ‰ªªÂãôÁöÑÁµêÊßãÂ∞çÊñºÁêÜËß£Âü∫Á§éÂúñÂΩ¢ÁêÜË´ñÊ¶ÇÂøµÁöÑ‰∫∫È°û‰æÜË™™ÂæàÂÆπÊòìÔºå‰∏¶‰∏îÈÉΩÂèØ‰ª•ÈÄèÈÅéË®àÁÆóÂúñÂΩ¢‰∏≠ÁöÑÈÅ©Áï∂ÂÖÉÁ¥†‰æÜËß£Ê±∫„ÄÇÊàëÂÄëÁôºÁèæÔºåÈõñÁÑ∂ GPT-4 ÊåÅÁ∫åÂÑ™Êñº LLaVaÔºå‰ΩÜÈÄôÂÖ©ÂÄãÊ®°ÂûãÈÉΩÈõ£‰ª•ËôïÁêÜÊàëÂÄëÊèêÂá∫ÁöÑÊØèÂÄãË¶ñË¶∫Á∂≤Ë∑ØÂàÜÊûê‰ªªÂãô„ÄÇÊàëÂÄëÂÖ¨ÈñãÁôºÂ∏É‰∫ÜÁ¨¨‰∏ÄÂÄãÁî®ÊñºË©ï‰º∞ VLM Âú®Âü∫Á§é VNA ‰ªªÂãô‰∏äÁöÑÂü∫Ê∫ñ„ÄÇ

##### **Mitigating Hallucinations in Large Language Models via Self-Refinement-Enhanced Knowledge Retrieval**
2405.06545v1 by Mengjia Niu, Hao Li, Jie Shi, Hamed Haddadi, Fan Mo

Large language models (LLMs) have demonstrated remarkable capabilities across
various domains, although their susceptibility to hallucination poses
significant challenges for their deployment in critical areas such as
healthcare. To address this issue, retrieving relevant facts from knowledge
graphs (KGs) is considered a promising method. Existing KG-augmented approaches
tend to be resource-intensive, requiring multiple rounds of retrieval and
verification for each factoid, which impedes their application in real-world
scenarios.
  In this study, we propose Self-Refinement-Enhanced Knowledge Graph Retrieval
(Re-KGR) to augment the factuality of LLMs' responses with less retrieval
efforts in the medical field. Our approach leverages the attribution of
next-token predictive probability distributions across different tokens, and
various model layers to primarily identify tokens with a high potential for
hallucination, reducing verification rounds by refining knowledge triples
associated with these tokens. Moreover, we rectify inaccurate content using
retrieved knowledge in the post-processing stage, which improves the
truthfulness of generated responses. Experimental results on a medical dataset
demonstrate that our approach can enhance the factual capability of LLMs across
various foundational models as evidenced by the highest scores on truthfulness.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®ÂêÑÂÄãÈ†òÂüüÂ±ïÁèæÂá∫ÂçìË∂äÁöÑËÉΩÂäõÔºåÂÑòÁÆ°ÂÆÉÂÄëÂÆπÊòìÂá∫ÁèæÂπªË¶∫ÔºåÂ∞çÂÖ∂Âú®ÈÜ´ÁôÇ‰øùÂÅ•Á≠âÈóúÈçµÈ†òÂüüÁöÑÈÉ®ÁΩ≤ÊßãÊàêÈáçÂ§ßÊåëÊà∞„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÂæûÁü•Ë≠òÂúñË≠ú (KG) ‰∏≠Êì∑ÂèñÁõ∏Èóú‰∫ãÂØ¶Ë¢´Ë™çÁÇ∫ÊòØ‰∏ÄÁ®ÆÊúâÂâçÈÄîÁöÑÊñπÊ≥ï„ÄÇÁèæÊúâÁöÑ KG Â¢ûÂº∑ÊñπÊ≥ïÂæÄÂæÄÈúÄË¶ÅÂ§ßÈáèË≥áÊ∫êÔºåÈúÄË¶ÅÂ∞çÊØèÂÄã‰∫ãÂØ¶ÈÄ≤Ë°åÂ§öËº™Ê™¢Á¥¢ÂíåÈ©óË≠âÔºåÈÄôÈòªÁ§ô‰∫ÜÂÆÉÂÄëÂú®ÂØ¶ÈöõÂ†¥ÊôØ‰∏≠ÁöÑÊáâÁî®„ÄÇ
Âú®ÈÄôÈ†ÖÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫ÜËá™‰øÆÊ≠£Â¢ûÂº∑Áü•Ë≠òÂúñË≠úÊ™¢Á¥¢ (Re-KGR)Ôºå‰ª•Ê∏õÂ∞ëÈÜ´ÁôÇÈ†òÂüü‰∏≠ LLM ÂõûÊáâÁöÑ‰∫ãÂØ¶ÊÄßÊ™¢Á¥¢Â∑•‰Ωú„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÂà©Áî®‰∫Ü‰∏çÂêåÊ®ôË®ò‰πãÈñì‰∏ã‰∏ÄÂÄãÊ®ôË®òÈ†êÊ∏¨Ê¶ÇÁéáÂàÜ‰ΩàÁöÑÊ≠∏Âõ†Ôºå‰ª•ÂèäÂêÑÁ®ÆÊ®°ÂûãÂ±§Ôºå‰ª•‰∏ªË¶ÅË≠òÂà•ÂÖ∑ÊúâÈ´òÂπªË¶∫ÊΩõÂäõÁöÑÊ®ôË®òÔºåÈÄöÈÅé‰øÆÊ≠£ËàáÈÄô‰∫õÊ®ôË®òÁõ∏ÈóúÁöÑÁü•Ë≠ò‰∏âÂÖÉÁµÑ‰æÜÊ∏õÂ∞ëÈ©óË≠âËº™Ê¨°„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂú®ÂæåËôïÁêÜÈöéÊÆµ‰ΩøÁî®Ê™¢Á¥¢Âà∞ÁöÑÁü•Ë≠ò‰æÜ‰øÆÊ≠£‰∏çÊ∫ñÁ¢∫ÁöÑÂÖßÂÆπÔºåÈÄôÊèêÈ´ò‰∫ÜÁîüÊàêÂõûÊáâÁöÑÁúüÂØ¶ÊÄß„ÄÇÂú®ÈÜ´ÁôÇÊï∏ÊìöÈõÜ‰∏äÁöÑÂØ¶È©óÁµêÊûúË°®ÊòéÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÂèØ‰ª•Â¢ûÂº∑ LLM Âú®ÂêÑÁ®ÆÂü∫Á§éÊ®°Âûã‰∏äÁöÑ‰∫ãÂØ¶ËÉΩÂäõÔºåÊúÄÈ´òÁúüÂØ¶ÊÄßÂàÜÊï∏Ë≠âÊòé‰∫ÜÈÄô‰∏ÄÈªû„ÄÇ

##### **Prompting Large Language Models with Knowledge Graphs for Question Answering Involving Long-tail Facts**
2405.06524v1 by Wenyu Huang, Guancheng Zhou, Mirella Lapata, Pavlos Vougiouklis, Sebastien Montella, Jeff Z. Pan

Although Large Language Models (LLMs) are effective in performing various NLP
tasks, they still struggle to handle tasks that require extensive, real-world
knowledge, especially when dealing with long-tail facts (facts related to
long-tail entities). This limitation highlights the need to supplement LLMs
with non-parametric knowledge. To address this issue, we analysed the effects
of different types of non-parametric knowledge, including textual passage and
knowledge graphs (KGs). Since LLMs have probably seen the majority of factual
question-answering datasets already, to facilitate our analysis, we proposed a
fully automatic pipeline for creating a benchmark that requires knowledge of
long-tail facts for answering the involved questions. Using this pipeline, we
introduce the LTGen benchmark. We evaluate state-of-the-art LLMs in different
knowledge settings using the proposed benchmark. Our experiments show that LLMs
alone struggle with answering these questions, especially when the long-tail
level is high or rich knowledge is required. Nonetheless, the performance of
the same models improved significantly when they were prompted with
non-parametric knowledge. We observed that, in most cases, prompting LLMs with
KG triples surpasses passage-based prompting using a state-of-the-art
retriever. In addition, while prompting LLMs with both KG triples and documents
does not consistently improve knowledge coverage, it can dramatically reduce
hallucinations in the generated content.

ÊëòË¶ÅÔºöÂÑòÁÆ°Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®Âü∑Ë°åÂêÑÁ®ÆËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ (NLP) ‰ªªÂãôÊôÇÂæàÊúâÊïàÔºåÂÆÉÂÄëÂú®ËôïÁêÜÈúÄË¶ÅÂª£Ê≥õÁöÑÁúüÂØ¶‰∏ñÁïåÁü•Ë≠òÁöÑ‰ªªÂãôÊôÇ‰ªçÊúâÂõ∞Èõ£ÔºåÁâπÂà•ÊòØÂú®ËôïÁêÜÈï∑Â∞æ‰∫ãÂØ¶ÔºàËàáÈï∑Â∞æÂØ¶È´îÁõ∏ÈóúÁöÑ‰∫ãÂØ¶ÔºâÊôÇ„ÄÇÊ≠§ÈôêÂà∂Á™ÅÈ°Ø‰∫ÜË£úÂÖÖ LLM ‰ª•Áç≤ÂæóÈùûÂèÉÊï∏Áü•Ë≠òÁöÑÂøÖË¶ÅÊÄß„ÄÇÁÇ∫‰∫ÜËß£Ê±∫Ê≠§ÂïèÈ°åÔºåÊàëÂÄëÂàÜÊûê‰∫Ü‰∏çÂêåÈ°ûÂûãÈùûÂèÉÊï∏Áü•Ë≠òÁöÑÂΩ±ÈüøÔºåÂåÖÊã¨ÊñáÂ≠óÊÆµËêΩÂíåÁü•Ë≠òÂúñ (KG)„ÄÇÁî±Êñº LLM ÂèØËÉΩÂ∑≤Á∂ìÁúãÈÅéÂ§ßÂ§öÊï∏‰∫ãÂØ¶ÊÄßÁöÑÂïèÁ≠îË≥áÊñôÈõÜÔºåÁÇ∫‰∫ÜÊñπ‰æøÊàëÂÄëÁöÑÂàÜÊûêÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂÖ®Ëá™ÂãïÁÆ°ÈÅìÔºåÁî®ÊñºÂª∫Á´ã‰∏ÄÂÄãÂü∫Ê∫ñÔºåÈúÄË¶Å‰∫ÜËß£Èï∑Â∞æ‰∫ãÂØ¶ÊâçËÉΩÂõûÁ≠îÁõ∏ÈóúÂïèÈ°å„ÄÇ‰ΩøÁî®Ê≠§ÁÆ°ÈÅìÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü LTGen Âü∫Ê∫ñ„ÄÇÊàëÂÄë‰ΩøÁî®ÊâÄÊèêÂá∫ÁöÑÂü∫Ê∫ñÔºåÂú®‰∏çÂêåÁöÑÁü•Ë≠òË®≠ÂÆö‰∏≠Ë©ï‰º∞ÊúÄÂÖàÈÄ≤ÁöÑ LLM„ÄÇÊàëÂÄëÁöÑÂØ¶È©óË°®ÊòéÔºåLLM ÂñÆÁç®Èõ£‰ª•ÂõûÁ≠îÈÄô‰∫õÂïèÈ°åÔºåÁâπÂà•ÊòØÂú®Èï∑Â∞æÂ±§Á¥öÂæàÈ´òÊàñÈúÄË¶ÅË±êÂØåÁöÑÁü•Ë≠òÊôÇ„ÄÇÂÑòÁÆ°Â¶ÇÊ≠§ÔºåÁï∂‰ΩøÁî®ÈùûÂèÉÊï∏Áü•Ë≠òÊèêÁ§∫ÈÄô‰∫õÊ®°ÂûãÊôÇÔºåÂÆÉÂÄëÁöÑÊïàËÉΩÈ°ØËëóÊèêÂçá„ÄÇÊàëÂÄëËßÄÂØüÂà∞ÔºåÂú®Â§ßÂ§öÊï∏ÊÉÖÊ≥Å‰∏ãÔºå‰ΩøÁî®ÊúÄÂÖàÈÄ≤ÁöÑÊ™¢Á¥¢Âô®ÊèêÁ§∫ LLM ‰ΩøÁî® KG ‰∏âÂÖÉÁµÑÊúÉÂÑ™ÊñºÂü∫ÊñºÊÆµËêΩÁöÑÊèêÁ§∫„ÄÇÊ≠§Â§ñÔºåÂÑòÁÆ°ÂêåÊôÇÊèêÁ§∫ LLM ‰ΩøÁî® KG ‰∏âÂÖÉÁµÑÂíåÊñá‰ª∂‰∏¶‰∏çÊúÉÊåÅÁ∫åÊîπÂñÑÁü•Ë≠òÊ∂µËìãÁØÑÂúçÔºå‰ΩÜÂÆÉÂèØ‰ª•Â§ßÂπÖÊ∏õÂ∞ëÁî¢ÁîüÁöÑÂÖßÂÆπ‰∏≠ÁöÑÂπªË¶∫„ÄÇ

##### **RoboHop: Segment-based Topological Map Representation for Open-World Visual Navigation**
2405.05792v1 by Sourav Garg, Krishan Rana, Mehdi Hosseinzadeh, Lachlan Mares, Niko S√ºnderhauf, Feras Dayoub, Ian Reid

Mapping is crucial for spatial reasoning, planning and robot navigation.
Existing approaches range from metric, which require precise geometry-based
optimization, to purely topological, where image-as-node based graphs lack
explicit object-level reasoning and interconnectivity. In this paper, we
propose a novel topological representation of an environment based on "image
segments", which are semantically meaningful and open-vocabulary queryable,
conferring several advantages over previous works based on pixel-level
features. Unlike 3D scene graphs, we create a purely topological graph with
segments as nodes, where edges are formed by a) associating segment-level
descriptors between pairs of consecutive images and b) connecting neighboring
segments within an image using their pixel centroids. This unveils a
"continuous sense of a place", defined by inter-image persistence of segments
along with their intra-image neighbours. It further enables us to represent and
update segment-level descriptors through neighborhood aggregation using graph
convolution layers, which improves robot localization based on segment-level
retrieval. Using real-world data, we show how our proposed map representation
can be used to i) generate navigation plans in the form of "hops over segments"
and ii) search for target objects using natural language queries describing
spatial relations of objects. Furthermore, we quantitatively analyze data
association at the segment level, which underpins inter-image connectivity
during mapping and segment-level localization when revisiting the same place.
Finally, we show preliminary trials on segment-level `hopping' based zero-shot
real-world navigation. Project page with supplementary details:
oravus.github.io/RoboHop/

ÊëòË¶ÅÔºö<paragraph>Áπ™Ë£ΩÂú∞ÂúñÂ∞çÊñºÁ©∫ÈñìÊé®ÁêÜ„ÄÅË¶èÂäÉÂíåÊ©üÂô®‰∫∫Â∞éËà™Ëá≥ÈóúÈáçË¶Å„ÄÇ
ÁèæÊúâÊñπÊ≥ïÂæûÂ∫¶ÈáèÔºàÈúÄË¶ÅÁ≤æÁ¢∫ÁöÑÂü∫ÊñºÂπæ‰ΩïÁöÑÊúÄ‰Ω≥ÂåñÔºâÂà∞Á¥îÊãìÊí≤ÔºàÂÖ∂‰∏≠‰ª•ÂΩ±ÂÉèÁÇ∫ÁØÄÈªûÁöÑÂúñÂΩ¢Áº∫‰πèÊòéÁ¢∫ÁöÑÁâ©‰ª∂Â±§Á¥öÊé®ÁêÜÂíå‰∫íÈÄ£ÊÄßÔºâ‰∏çÁ≠â„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÂü∫Êñº„ÄåÂΩ±ÂÉèÂçÄÊÆµ„ÄçÁöÑÊñ∞Á©éÊãìÊí≤Ë°®Á§∫ÔºåÈÄô‰∫õÂçÄÊÆµÂú®Ë™ûÊÑè‰∏äÊòØÊúâÊÑèÁæ©ÁöÑÔºå‰∏¶‰∏îÂèØ‰ª•ÈÄ≤Ë°åÈñãÊîæÂºèË©ûÂΩôÊü•Ë©¢ÔºåËàáÂü∫ÊñºÂÉèÁ¥†Â±§Á¥öÁâπÂæµÁöÑÂÖàÂâçÂ∑•‰ΩúÁõ∏ÊØîÔºåÂÖ∑ÊúâÂ§öÈ†ÖÂÑ™Èªû„ÄÇËàá 3D Â†¥ÊôØÂúñÂΩ¢‰∏çÂêåÔºåÊàëÂÄë‰ΩøÁî®ÂçÄÊÆµ‰ΩúÁÇ∫ÁØÄÈªûÂª∫Á´ã‰∏ÄÂÄãÁ¥îÊãìÊí≤ÂúñÂΩ¢ÔºåÂÖ∂‰∏≠ÈÇäÁ∑£ÊòØÁî± a) Â∞áÂçÄÊÆµÂ±§Á¥öÊèèËø∞Á¨¶ËàáÈÄ£Á∫åÂÖ©ÂºµÂΩ±ÂÉè‰πãÈñìÁöÑÈÖçÂ∞çÈóúËÅØËµ∑‰æÜÔºå‰ª•Âèä b) ‰ΩøÁî®ÂÖ∂ÂÉèÁ¥†Ë≥™ÂøÉÈÄ£Êé•ÂΩ±ÂÉè‰∏≠ÁöÑÈÑ∞ËøëÂçÄÊÆµÊâÄÂΩ¢ÊàêÁöÑ„ÄÇÈÄôÊè≠Á§∫‰∫Ü‰∏ÄÂÄã„ÄåÈÄ£Á∫åÁöÑÂú∞ÊñπÊÑü„ÄçÔºåÂÆÉÊòØÁî±ÂçÄÊÆµÂú®ÂΩ±ÂÉè‰πãÈñìÁöÑÊåÅÁ∫åÊÄßÂèäÂÖ∂Âú®ÂΩ±ÂÉèÂÖßÁöÑÈÑ∞ËøëÂÖÉÁ¥†ÊâÄÂÆöÁæ©ÁöÑ„ÄÇÂÆÉÈÄ≤‰∏ÄÊ≠•‰ΩøÊàëÂÄëËÉΩÂ§†‰ΩøÁî®ÂúñÂΩ¢Âç∑Á©çÂ±§ÈÄèÈÅéÈÑ∞ÂüüËÅöÂêà‰æÜË°®Á§∫ÂíåÊõ¥Êñ∞ÂçÄÊÆµÂ±§Á¥öÊèèËø∞Á¨¶ÔºåÈÄôÊîπÈÄ≤‰∫ÜÂü∫ÊñºÂçÄÊÆµÂ±§Á¥öÊì∑ÂèñÁöÑÊ©üÂô®‰∫∫ÂÆö‰Ωç„ÄÇ‰ΩøÁî®ÁúüÂØ¶‰∏ñÁïåË≥áÊñôÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜÊàëÂÄëÊèêÂá∫ÁöÑÂú∞ÂúñË°®Á§∫Â¶Ç‰ΩïÁî®Êñº i) ‰ª•„ÄåÂçÄÊÆµË∑≥Ë∫ç„ÄçÁöÑÂΩ¢ÂºèÁî¢ÁîüÂ∞éËà™Ë®àÁï´Ôºå‰ª•Âèä ii) ‰ΩøÁî®ÊèèËø∞Áâ©‰ª∂Á©∫ÈñìÈóú‰øÇÁöÑËá™ÁÑ∂Ë™ûË®ÄÊü•Ë©¢‰æÜÊêúÂ∞ãÁõÆÊ®ôÁâ©‰ª∂„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂÆöÈáèÂàÜÊûê‰∫ÜÂçÄÊÆµÂ±§Á¥öÁöÑË≥áÊñôÈóúËÅØÊÄßÔºåÈÄôÂú®Áπ™Ë£ΩÂú∞ÂúñÊúüÈñìÊîØÊíê‰∫ÜÂΩ±ÂÉè‰πãÈñìÁöÑÈÄ£Êé•ÊÄßÔºå‰ª•ÂèäÂú®ÂÜçÊ¨°ÈÄ†Ë®™Âêå‰∏ÄÂÄãÂú∞ÊñπÊôÇÁöÑÂçÄÊÆµÂ±§Á¥öÂÆö‰Ωç„ÄÇÊúÄÂæåÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜÂü∫ÊñºÂçÄÊÆµÂ±§Á¥ö„ÄåË∑≥Ë∫ç„ÄçÁöÑÈõ∂Ê¨°Â≠∏ÁøíÁúüÂØ¶‰∏ñÁïåÂ∞éËà™ÁöÑÂàùÊ≠•Ë©¶È©ó„ÄÇÂåÖÂê´Ë£úÂÖÖË©≥Á¥∞Ë≥áË®äÁöÑÂ∞àÊ°àÈ†ÅÈù¢Ôºö
oravus.github.io/RoboHop/</paragraph>

##### **G-SAP: Graph-based Structure-Aware Prompt Learning over Heterogeneous Knowledge for Commonsense Reasoning**
2405.05616v1 by Ruiting Dai, Yuqiao Tan, Lisi Mo, Shuang Liang, Guohao Huo, Jiayi Luo, Yao Cheng

Commonsense question answering has demonstrated considerable potential across
various applications like assistants and social robots. Although fully
fine-tuned pre-trained Language Models(LM) have achieved remarkable performance
in commonsense reasoning, their tendency to excessively prioritize textual
information hampers the precise transfer of structural knowledge and undermines
interpretability. Some studies have explored combining LMs with Knowledge
Graphs(KGs) by coarsely fusing the two modalities to perform Graph Neural
Network(GNN)-based reasoning that lacks a profound interaction between
heterogeneous modalities. In this paper, we propose a novel Graph-based
Structure-Aware Prompt Learning Model for commonsense reasoning, named G-SAP,
aiming to maintain a balance between heterogeneous knowledge and enhance the
cross-modal interaction within the LM+GNNs model. In particular, an evidence
graph is constructed by integrating multiple knowledge sources, i.e.
ConceptNet, Wikipedia, and Cambridge Dictionary to boost the performance.
Afterward, a structure-aware frozen PLM is employed to fully incorporate the
structured and textual information from the evidence graph, where the
generation of prompts is driven by graph entities and relations. Finally, a
heterogeneous message-passing reasoning module is used to facilitate deep
interaction of knowledge between the LM and graph-based networks. Empirical
validation, conducted through extensive experiments on three benchmark
datasets, demonstrates the notable performance of the proposed model. The
results reveal a significant advancement over the existing models, especially,
with 6.12% improvement over the SoTA LM+GNNs model on the OpenbookQA dataset.

ÊëòË¶ÅÔºöÂ∏∏Ë≠òÂïèÁ≠îÂú®ÂêÑÁ®ÆÊáâÁî®Á®ãÂºè‰∏≠Â±ïÁèæ‰∫ÜÁõ∏Áï∂Â§ßÁöÑÊΩõÂäõÔºå‰æãÂ¶ÇÂä©ÁêÜÂíåÁ§æ‰∫§Ê©üÂô®‰∫∫„ÄÇÂÑòÁÆ°Á∂ìÈÅéÂæÆË™øÁöÑÈ†êË®ìÁ∑¥Ë™ûË®ÄÊ®°Âûã (LM) Âú®Â∏∏Ë≠òÊé®ÁêÜ‰∏≠ÂèñÂæó‰∫ÜÈ°ØËëóÁöÑË°®ÁèæÔºå‰ΩÜÂÆÉÂÄëÈÅéÂ∫¶ÂÑ™ÂÖàËÄÉÊÖÆÊñáÊú¨Ë≥áË®äÁöÑÂÇæÂêëÊúÉÈòªÁ§ôÁµêÊßãÁü•Ë≠òÁöÑÁ≤æÁ¢∫ÂÇ≥Ëº∏Ôºå‰∏¶ÊêçÂÆ≥ÂèØËß£ÈáãÊÄß„ÄÇ‰∏Ä‰∫õÁ†îÁ©∂Êé¢Á¥¢‰∫ÜÂ∞á LM ËàáÁü•Ë≠òÂúñË≠ú (KG) ÁµêÂêàËµ∑‰æÜÔºåÈÄöÈÅéÁ≤óÁï•Âú∞ËûçÂêàÈÄôÂÖ©Á®ÆÊ®°Âºè‰æÜÂü∑Ë°åÂü∫ÊñºÂúñÁ•ûÁ∂ìÁ∂≤Ë∑Ø (GNN) ÁöÑÊé®ÁêÜÔºåËÄåÈÄôÁ®ÆÊé®ÁêÜÁº∫‰πèÁï∞Ë≥™Ê®°Âºè‰πãÈñìÁöÑÊ∑±ÂÖ•‰∫íÂãï„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊñ∞ÁöÑÂü∫ÊñºÂúñÁöÑÁµêÊßãÊÑüÁü•ÊèêÁ§∫Â≠∏ÁøíÊ®°ÂûãÔºåÁî®ÊñºÂ∏∏Ë≠òÊé®ÁêÜÔºåÁ®±ÁÇ∫ G-SAPÔºåÊó®Âú®Á∂≠ÊåÅÁï∞Ë≥™Áü•Ë≠ò‰πãÈñìÁöÑÂπ≥Ë°°Ôºå‰∏¶Â¢ûÂº∑ LM+GNN Ê®°ÂûãÂÖßÁöÑË∑®Ê®°Âºè‰∫íÂãï„ÄÇÁâπÂà•ÊòØÔºåÈÄöÈÅéÊï¥ÂêàÂ§öÂÄãÁü•Ë≠ò‰æÜÊ∫êÔºàÂç≥ ConceptNet„ÄÅWikipedia ÂíåÂäçÊ©ãË©ûÂÖ∏Ôºâ‰æÜÊßãÂª∫‰∏ÄÂÄãË≠âÊìöÂúñÔºå‰ª•ÊèêÂçáÊïàËÉΩ„ÄÇÈö®ÂæåÔºåÊé°Áî®ÁµêÊßãÊÑüÁü•ÂáçÁµê PLM ‰æÜÂÖÖÂàÜÊï¥Âêà‰æÜËá™Ë≠âÊìöÂúñÁöÑÁµêÊßãÂåñÂíåÊñáÊú¨Ë≥áË®äÔºåÂÖ∂‰∏≠ÊèêÁ§∫ÁöÑÁî¢ÁîüÊòØÁî±ÂúñÂØ¶È´îÂíåÈóú‰øÇÈ©ÖÂãïÁöÑ„ÄÇÊúÄÂæåÔºå‰ΩøÁî®Áï∞Ë≥™Ë®äÊÅØÂÇ≥ÈÅûÊé®ÁêÜÊ®°ÁµÑ‰æÜ‰øÉÈÄ≤ LM ÂíåÂü∫ÊñºÂúñÁöÑÁ∂≤Ë∑Ø‰πãÈñìÁöÑÊ∑±Â∫¶‰∫íÂãï„ÄÇÈÄèÈÅéÂú®‰∏âÂÄãÂü∫Ê∫ñË≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÂª£Ê≥õÁöÑÂØ¶È©óÈÄ≤Ë°åÁöÑÁ∂ìÈ©óÈ©óË≠âÔºåË≠âÊòé‰∫ÜÊâÄÊèêÂá∫ÁöÑÊ®°ÂûãÁöÑÈ°ØËëóÊïàËÉΩ„ÄÇÁµêÊûúÈ°ØÁ§∫Âá∫ÊØîÁèæÊúâÊ®°ÂûãÊúâÈ°ØËëóÁöÑÈÄ≤Ê≠•ÔºåÁâπÂà•ÊòØÂú® OpenbookQA Ë≥áÊñôÈõÜ‰∏äÊØî SoTA LM+GNN Ê®°ÂûãÊèêÂçá‰∫Ü 6.12%„ÄÇ

##### **MIDGARD: Self-Consistency Using Minimum Description Length for Structured Commonsense Reasoning**
2405.05189v2 by Inderjeet Nair, Lu Wang

We study the task of conducting structured reasoning as generating a
reasoning graph from natural language input using large language models (LLMs).
Previous approaches have explored various prompting schemes, yet they suffer
from error propagation due to the autoregressive nature and single-pass-based
decoding, which lack error correction capability. Additionally, relying solely
on a single sample may result in the omission of true nodes and edges. To
counter this, we draw inspiration from self-consistency (SC), which involves
sampling a diverse set of reasoning chains and taking the majority vote as the
final answer. To tackle the substantial challenge of applying SC on generated
graphs, we propose MIDGARD (MInimum Description length Guided Aggregation of
Reasoning in Directed acyclic graph) that leverages Minimum Description Length
(MDL)-based formulation to identify consistent properties among the different
graph samples generated by an LLM. This formulation helps reject properties
that appear in only a few samples, which are likely to be erroneous, while
enabling the inclusion of missing elements without compromising precision. Our
method demonstrates superior performance than comparisons across various
structured reasoning tasks, including argument structure extraction,
explanation graph generation, inferring dependency relations among actions for
everyday tasks, and semantic graph generation from natural texts.

ÊëòË¶ÅÔºöÊàëÂÄëÁ†îÁ©∂Â∞áÁµêÊßãÂåñÊé®ÁêÜ‰ªªÂãô‰ΩúÁÇ∫ÂæûËá™ÁÑ∂Ë™ûË®ÄËº∏ÂÖ•ÁîüÊàêÊé®ÁêÜÂúñÁöÑ‰ªªÂãôÔºå‰∏¶‰ΩøÁî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âü∑Ë°åÈÄôÈ†Ö‰ªªÂãô„ÄÇ
ÂÖàÂâçÁöÑÂÅöÊ≥ïÂ∑≤Êé¢Ë®éÂêÑÁ®ÆÊèêÁ§∫ÊñπÊ°àÔºå‰ΩÜÁî±ÊñºËá™Ëø¥Ê≠∏ÊÄßË≥™ÂíåÂü∫ÊñºÂñÆÊ¨°ÂÇ≥ÈÅûÁöÑËß£Á¢ºÔºåÂ∞éËá¥ÈåØË™§ÂÇ≥Êí≠ÔºåËÄåÈÄôÁº∫‰πèÈåØË™§‰øÆÊ≠£ËÉΩÂäõ„ÄÇÊ≠§Â§ñÔºåÂÉÖ‰æùË≥¥ÂñÆ‰∏ÄÁØÑÊú¨ÂèØËÉΩÊúÉÂ∞éËá¥ÈÅ∫ÊºèÁúüÂØ¶ÁØÄÈªûÂíåÈÇäÁ∑£„ÄÇÁÇ∫‰∫ÜÂ∞çÊäóÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÂæûËá™Êàë‰∏ÄËá¥ÊÄß (SC) ‰∏≠Ê±≤ÂèñÈùàÊÑüÔºåÂÖ∂‰∏≠Ê∂âÂèäÂèñÊ®£ÂêÑÁ®ÆÊé®ÁêÜÈèàÔºå‰∏¶Â∞áÂ§öÊï∏Ê±∫‰ΩúÁÇ∫ÊúÄÁµÇÁ≠îÊ°à„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÂú®ÁîüÊàêÂúñÂΩ¢‰∏äÊáâÁî® SC ÁöÑÈáçÂ§ßÊåëÊà∞ÔºåÊàëÂÄëÊèêÂá∫ MIDGARDÔºàÊúâÂêëÁÑ°Áí∞Âúñ‰∏≠Êé®ÁêÜÁöÑÊúÄÂ∞èÊèèËø∞Èï∑Â∫¶ÂºïÂ∞éËÅöÂêàÔºâÔºåÂÆÉÂà©Áî®Âü∫ÊñºÊúÄÂ∞èÊèèËø∞Èï∑Â∫¶ (MDL) ÁöÑÂÖ¨Âºè‰æÜË≠òÂà• LLM ÁîüÊàêÁöÑ‰∏çÂêåÂúñÂΩ¢ÁØÑÊú¨‰πãÈñìÁöÑ‰∏ÄËá¥Â±¨ÊÄß„ÄÇÊ≠§ÂÖ¨ÂºèÊúâÂä©ÊñºÊãíÁµïÂÉÖÂá∫ÁèæÂú®Â∞ëÊï∏ÁØÑÊú¨‰∏≠ÁöÑÂ±¨ÊÄßÔºàÈÄô‰∫õÂ±¨ÊÄßÂæàÂèØËÉΩÊòØÈåØË™§ÁöÑÔºâÔºåÂêåÊôÇÂú®‰∏çÊêçÂÆ≥Á≤æÁ¢∫Â∫¶ÁöÑÂâçÊèê‰∏ãÁ¥çÂÖ•ÈÅ∫Â§±ÂÖÉÁ¥†„ÄÇÊàëÂÄëÁöÑÊñπÊ≥ïÂú®ÂêÑÁ®ÆÁµêÊßãÂåñÊé®ÁêÜ‰ªªÂãô‰∏≠Â±ïÁèæÂá∫ÂÑ™Áï∞ÁöÑÊïàËÉΩÔºåÂåÖÊã¨Ë´ñË≠âÁµêÊßãËêÉÂèñ„ÄÅËß£ÈáãÂúñÂΩ¢ÁîüÊàê„ÄÅÊé®Ë´ñÊó•Â∏∏‰ªªÂãô‰∏≠Âãï‰Ωú‰πãÈñìÁöÑ‰æùË≥¥Èóú‰øÇÔºå‰ª•ÂèäÂæûËá™ÁÑ∂ÊñáÊú¨ÁîüÊàêË™ûÊÑèÂúñÂΩ¢„ÄÇ

##### **Lightweight Spatial Modeling for Combinatorial Information Extraction From Documents**
2405.06701v1 by Yanfei Dong, Lambert Deng, Jiazheng Zhang, Xiaodong Yu, Ting Lin, Francesco Gelli, Soujanya Poria, Wee Sun Lee

Documents that consist of diverse templates and exhibit complex spatial
structures pose a challenge for document entity classification. We propose
KNN-former, which incorporates a new kind of spatial bias in attention
calculation based on the K-nearest-neighbor (KNN) graph of document entities.
We limit entities' attention only to their local radius defined by the KNN
graph. We also use combinatorial matching to address the one-to-one mapping
property that exists in many documents, where one field has only one
corresponding entity. Moreover, our method is highly parameter-efficient
compared to existing approaches in terms of the number of trainable parameters.
Despite this, experiments across various datasets show our method outperforms
baselines in most entity types. Many real-world documents exhibit combinatorial
properties which can be leveraged as inductive biases to improve extraction
accuracy, but existing datasets do not cover these documents. To facilitate
future research into these types of documents, we release a new ID document
dataset that covers diverse templates and languages. We also release enhanced
annotations for an existing dataset.

ÊëòË¶ÅÔºö<paragraph>Áî±‰∏çÂêåÁØÑÊú¨ÁµÑÊàê‰∏îÂëàÁèæË§áÈõúÁ©∫ÈñìÁµêÊßãÁöÑÊñá‰ª∂ÔºåÊúÉÂ∞çÊñá‰ª∂ÂØ¶È´îÂàÜÈ°ûÊßãÊàêÊåëÊà∞„ÄÇÊàëÂÄëÊèêÂá∫ KNN-formerÔºåÂÆÉÂú®Ê≥®ÊÑèÂäõË®àÁÆó‰∏≠ÁµêÂêà‰∫Ü‰∏ÄÁ®ÆÂü∫ÊñºÊñá‰ª∂ÂØ¶È´îÁöÑ K-ÊúÄËøëÈÑ∞ (KNN) ÂúñÁöÑÊñ∞ÂûãÁ©∫ÈñìÂÅèÂ∑Æ„ÄÇÊàëÂÄëÂ∞áÂØ¶È´îÁöÑÊ≥®ÊÑèÂäõÈôêÂà∂Âú®ÂÖ∂Áî± KNN ÂúñÂÆöÁæ©ÁöÑÂ±ÄÈÉ®ÂçäÂæëÂÖß„ÄÇÊàëÂÄëÈÇÑ‰ΩøÁî®ÁµÑÂêàÂåπÈÖç‰æÜËß£Ê±∫Ë®±Â§öÊñá‰ª∂‰∏≠Â≠òÂú®ÁöÑÂñÆÂ∞çÂñÆÂ∞çÊáâÂ±¨ÊÄßÔºåÂÖ∂‰∏≠‰∏ÄÂÄãÊ¨Ñ‰ΩçÂè™Êúâ‰∏ÄÂÄãÂ∞çÊáâÂØ¶È´î„ÄÇÊ≠§Â§ñÔºåËàáÁèæÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåÊàëÂÄëÁöÑÊñπÊ≥ïÂú®ÂèØË®ìÁ∑¥ÂèÉÊï∏Êï∏ÈáèÊñπÈù¢ÂÖ∑ÊúâÂæàÈ´òÁöÑÂèÉÊï∏ÊïàÁéá„ÄÇÂÑòÁÆ°Â¶ÇÊ≠§ÔºåÂú®ÂêÑÁ®ÆË≥áÊñôÈõÜ‰∏äÁöÑÂØ¶È©óË°®ÊòéÔºåÊàëÂÄëÁöÑÊ®°ÂûãÂú®Â§ßÈÉ®ÂàÜÂØ¶È´îÈ°ûÂûã‰∏≠ÈÉΩÂÑ™ÊñºÂü∫Ê∫ñ„ÄÇË®±Â§öÁúüÂØ¶‰∏ñÁïåÁöÑÊñá‰ª∂ÈÉΩË°®ÁèæÂá∫ÁµÑÂêàÂ±¨ÊÄßÔºåÈÄô‰∫õÂ±¨ÊÄßÂèØ‰ª•Áî®‰ΩúÊ≠∏Á¥çÂÅèÂ∑Æ‰æÜÊèêÈ´òÊèêÂèñÊ∫ñÁ¢∫Â∫¶Ôºå‰ΩÜÁèæÊúâË≥áÊñôÈõÜ‰∏¶Êú™Ê∂µËìãÈÄô‰∫õÊñá‰ª∂„ÄÇÁÇ∫‰∫Ü‰øÉÈÄ≤Â∞çÈÄô‰∫õÈ°ûÂûãÊñá‰ª∂ÁöÑÊú™‰æÜÁ†îÁ©∂ÔºåÊàëÂÄëÁôºÂ∏É‰∫Ü‰∏ÄÂÄãÊñ∞ÁöÑË∫´ÂàÜË≠â‰ª∂Êñá‰ª∂Ë≥áÊñôÈõÜÔºåÂÖ∂‰∏≠Ê∂µËìã‰∫Ü‰∏çÂêåÁöÑÁØÑÊú¨ÂíåË™ûË®Ä„ÄÇÊàëÂÄëÈÇÑÁÇ∫ÁèæÊúâË≥áÊñôÈõÜÁôºÂ∏É‰∫ÜÂ¢ûÂº∑ÁöÑË®ªÈáã„ÄÇ</paragraph>

##### **DALK: Dynamic Co-Augmentation of LLMs and KG to answer Alzheimer's Disease Questions with Scientific Literature**
2405.04819v2 by Dawei Li, Shu Yang, Zhen Tan, Jae Young Baik, Sukwon Yun, Joseph Lee, Aaron Chacko, Bojian Hou, Duy Duong-Tran, Ying Ding, Huan Liu, Li Shen, Tianlong Chen

Recent advancements in large language models (LLMs) have achieved promising
performances across various applications. Nonetheless, the ongoing challenge of
integrating long-tail knowledge continues to impede the seamless adoption of
LLMs in specialized domains. In this work, we introduce DALK, a.k.a. Dynamic
Co-Augmentation of LLMs and KG, to address this limitation and demonstrate its
ability on studying Alzheimer's Disease (AD), a specialized sub-field in
biomedicine and a global health priority. With a synergized framework of LLM
and KG mutually enhancing each other, we first leverage LLM to construct an
evolving AD-specific knowledge graph (KG) sourced from AD-related scientific
literature, and then we utilize a coarse-to-fine sampling method with a novel
self-aware knowledge retrieval approach to select appropriate knowledge from
the KG to augment LLM inference capabilities. The experimental results,
conducted on our constructed AD question answering (ADQA) benchmark, underscore
the efficacy of DALK. Additionally, we perform a series of detailed analyses
that can offer valuable insights and guidelines for the emerging topic of
mutually enhancing KG and LLM. We will release the code and data at
https://github.com/David-Li0406/DALK.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑËøëÊúüÈÄ≤Â±ïÂú®ÂêÑÁ®ÆÊáâÁî®‰∏≠ÈÉΩÂèñÂæó‰∫ÜÊúâÊúõÁöÑË°®Áèæ„ÄÇÂÑòÁÆ°Â¶ÇÊ≠§ÔºåÊï¥ÂêàÈï∑Â∞æÁü•Ë≠òÁöÑÊåÅÁ∫åÊåëÊà∞‰ªçÁÑ∂ÈòªÁ§ô‰∫Ü LLM Âú®Â∞àÊ•≠È†òÂüü‰∏≠ÁöÑÁÑ°Á∏´Êé°Áî®„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫Ü DALKÔºåÂèàÂêç LLM Âíå KG ÁöÑÂãïÊÖãÂÖ±Â¢ûÂº∑Ôºå‰ª•Ëß£Ê±∫ÈÄôÂÄãÈôêÂà∂Ôºå‰∏¶Â±ïÁ§∫ÂÖ∂Âú®Á†îÁ©∂ÈòøËå≤Êµ∑ÈªòÁóá (AD) ÁöÑËÉΩÂäõÔºåÈÄôÊòØÁîüÁâ©ÈÜ´Â≠∏‰∏≠ÁöÑÂ∞àÊ•≠Â≠êÈ†òÂüüÔºå‰πüÊòØÂÖ®ÁêÉÂÅ•Â∫∑ÂÑ™ÂÖà‰∫ãÈ†Ö„ÄÇÂà©Áî® LLM Âíå KG Áõ∏‰∫íÂ¢ûÂº∑ÁöÑÂçîÂêåÊ°ÜÊû∂ÔºåÊàëÂÄëÈ¶ñÂÖàÂà©Áî® LLM ÂæûËàá AD Áõ∏ÈóúÁöÑÁßëÂ≠∏ÊñáÁçª‰∏≠ÊßãÂª∫‰∏ÄÂÄã‰∏çÊñ∑ÊºîÂåñÁöÑ AD ÁâπÂÆöÁü•Ë≠òÂúñË≠ú (KG)ÔºåÁÑ∂ÂæåÊàëÂÄëÂà©Áî®‰∏ÄÁ®ÆÁ≤óÂà∞Á¥∞ÁöÑÊäΩÊ®£ÊñπÊ≥ïÔºåÊé°Áî®‰∏ÄÁ®ÆÊñ∞Á©éÁöÑËá™Áü•Áü•Ë≠òÊ™¢Á¥¢ÊñπÊ≥ïÔºåÂæû KG ‰∏≠ÈÅ∏ÊìáÈÅ©Áï∂ÁöÑÁü•Ë≠ò‰æÜÂ¢ûÂº∑ LLM Êé®Ë´ñËÉΩÂäõ„ÄÇÂú®ÊàëÂÄëÊßãÂª∫ÁöÑ AD ÂïèÈ°åËß£Á≠î (ADQA) Âü∫Ê∫ñ‰∏äÈÄ≤Ë°åÁöÑÂØ¶È©óÁµêÊûúÂº∑Ë™ø‰∫Ü DALK ÁöÑÂäüÊïà„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÈÄ≤Ë°å‰∫Ü‰∏ÄÁ≥ªÂàóË©≥Á¥∞ÁöÑÂàÜÊûêÔºåÂèØ‰ª•ÁÇ∫ KG Âíå LLM Áõ∏‰∫íÂ¢ûÂº∑ÁöÑÊñ∞Ëàà‰∏ªÈ°åÊèê‰æõÊúâÂÉπÂÄºÁöÑË¶ãËß£ÂíåÊåáÂ∞éÊñπÈáù„ÄÇÊàëÂÄëÂ∞áÂú® https://github.com/David-Li0406/DALK ‰∏äÁôºÂ∏É‰ª£Á¢ºÂíåÊï∏Êìö„ÄÇ

##### **BiasKG: Adversarial Knowledge Graphs to Induce Bias in Large Language Models**
2405.04756v1 by Chu Fei Luo, Ahmad Ghawanmeh, Xiaodan Zhu, Faiza Khan Khattak

Modern large language models (LLMs) have a significant amount of world
knowledge, which enables strong performance in commonsense reasoning and
knowledge-intensive tasks when harnessed properly. The language model can also
learn social biases, which has a significant potential for societal harm. There
have been many mitigation strategies proposed for LLM safety, but it is unclear
how effective they are for eliminating social biases. In this work, we propose
a new methodology for attacking language models with knowledge graph augmented
generation. We refactor natural language stereotypes into a knowledge graph,
and use adversarial attacking strategies to induce biased responses from
several open- and closed-source language models. We find our method increases
bias in all models, even those trained with safety guardrails. This
demonstrates the need for further research in AI safety, and further work in
this new adversarial space.

ÊëòË¶ÅÔºöÁèæ‰ª£ÁöÑÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâÊìÅÊúâÂ§ßÈáèÁöÑ‰∏ñÁïåÁü•Ë≠òÔºåÂú®ÈÅ©Áï∂Âà©Áî®ÊôÇÔºåÈÄô‰ΩøÂÆÉÂÄëÂú®Â∏∏Ë≠òÊé®ÁêÜÂíåÁü•Ë≠òÂØÜÈõÜÂûã‰ªªÂãô‰∏≠Ë°®ÁèæÂá∫Ëâ≤„ÄÇË™ûË®ÄÊ®°ÂûãÈÇÑÂèØ‰ª•Â≠∏ÁøíÁ§æÊúÉÂÅèË¶ãÔºåÈÄôÂ∞çÁ§æÊúÉÂç±ÂÆ≥ÂÖ∑ÊúâÈáçÂ§ßÊΩõÂäõ„ÄÇÂ∑≤Á∂ìÊèêÂá∫‰∫ÜË®±Â§öÈáùÂ∞ç LLM ÂÆâÂÖ®ÊÄßÁöÑÁ∑©Ëß£Á≠ñÁï•Ôºå‰ΩÜÁõÆÂâçÂ∞ö‰∏çÊ∏ÖÊ•öÂÆÉÂÄëÂú®Ê∂àÈô§Á§æÊúÉÂÅèË¶ãÊñπÈù¢ÁöÑÊúâÊïàÊÄß„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞ÁöÑÊñπÊ≥ïÔºå‰ΩøÁî®Áü•Ë≠òÂúñË≠úÂ¢ûÂº∑ÁîüÊàê‰æÜÊîªÊìäË™ûË®ÄÊ®°Âûã„ÄÇÊàëÂÄëÂ∞áËá™ÁÑ∂Ë™ûË®ÄÂàªÊùøÂç∞Ë±°ÈáçÊßãÁÇ∫Áü•Ë≠òÂúñË≠úÔºå‰∏¶‰ΩøÁî®Â∞çÊäóÊÄßÊîªÊìäÁ≠ñÁï•‰æÜË™òÂ∞é‰æÜËá™ÂπæÂÄãÈñãÊ∫êÂíåÈñâÊ∫êË™ûË®ÄÊ®°ÂûãÁöÑÂÅèÂ∑ÆÂõûÊáâ„ÄÇÊàëÂÄëÁôºÁèæÊàëÂÄëÁöÑÊ®°ÂûãÂ¢ûÂä†‰∫ÜÊâÄÊúâÊ®°Âûã‰∏≠ÁöÑÂÅèÂ∑ÆÔºåÂç≥‰ΩøÊòØÈÇ£‰∫õ‰ΩøÁî®ÂÆâÂÖ®Èò≤Ë≠∑Êé™ÊñΩÈÄ≤Ë°åË®ìÁ∑¥ÁöÑÊ®°Âûã„ÄÇÈÄôË°®ÊòéÈúÄË¶ÅÈÄ≤‰∏ÄÊ≠•Á†îÁ©∂‰∫∫Â∑•Êô∫ËÉΩÂÆâÂÖ®Ôºå‰∏¶Âú®ÈÄôÂÄãÊñ∞ÁöÑÂ∞çÊäóÁ©∫Èñì‰∏≠ÈÄ≤‰∏ÄÊ≠•ÈñãÂ±ïÂ∑•‰Ωú„ÄÇ

##### **AttacKG+:Boosting Attack Knowledge Graph Construction with Large Language Models**
2405.04753v1 by Yongheng Zhang, Tingwen Du, Yunshan Ma, Xiang Wang, Yi Xie, Guozheng Yang, Yuliang Lu, Ee-Chien Chang

Attack knowledge graph construction seeks to convert textual cyber threat
intelligence (CTI) reports into structured representations, portraying the
evolutionary traces of cyber attacks. Even though previous research has
proposed various methods to construct attack knowledge graphs, they generally
suffer from limited generalization capability to diverse knowledge types as
well as requirement of expertise in model design and tuning. Addressing these
limitations, we seek to utilize Large Language Models (LLMs), which have
achieved enormous success in a broad range of tasks given exceptional
capabilities in both language understanding and zero-shot task fulfillment.
Thus, we propose a fully automatic LLM-based framework to construct attack
knowledge graphs named: AttacKG+. Our framework consists of four consecutive
modules: rewriter, parser, identifier, and summarizer, each of which is
implemented by instruction prompting and in-context learning empowered by LLMs.
Furthermore, we upgrade the existing attack knowledge schema and propose a
comprehensive version. We represent a cyber attack as a temporally unfolding
event, each temporal step of which encapsulates three layers of representation,
including behavior graph, MITRE TTP labels, and state summary. Extensive
evaluation demonstrates that: 1) our formulation seamlessly satisfies the
information needs in threat event analysis, 2) our construction framework is
effective in faithfully and accurately extracting the information defined by
AttacKG+, and 3) our attack graph directly benefits downstream security
practices such as attack reconstruction. All the code and datasets will be
released upon acceptance.

ÊëòË¶ÅÔºöÊîªÊìäÁü•Ë≠òÂúñË≠úÂª∫ÊßãÊó®Âú®Â∞áÊñáÂ≠óÂΩ¢ÂºèÁöÑÁ∂≤Ë∑ØÂ®ÅËÑÖÊÉÖÂ†± (CTI) Â†±ÂëäËΩâÊèõÊàêÁµêÊßãÂåñË°®Á§∫ÔºåÊèèÁπ™Á∂≤Ë∑ØÊîªÊìäÁöÑÊºîÂåñËªåË∑°„ÄÇÂÑòÁÆ°ÂÖàÂâçÁöÑÁ†îÁ©∂Â∑≤ÊèêÂá∫ÂêÑÁ®ÆÂª∫ÊßãÊîªÊìäÁü•Ë≠òÂúñË≠úÁöÑÊñπÊ≥ïÔºå‰ΩÜÂÆÉÂÄëÊôÆÈÅçÂ≠òÂú®Â∞ç‰∏çÂêåÁü•Ë≠òÈ°ûÂûãÁöÑÊ¶ÇÂåñËÉΩÂäõÊúâÈôêÔºå‰ª•ÂèäÂ∞çÊ®°ÂûãË®≠Ë®àÂíåË™øÊï¥Â∞àÊ•≠Áü•Ë≠òÁöÑÈúÄÊ±ÇÁ≠âÂïèÈ°å„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÈôêÂà∂ÔºåÊàëÂÄëÂ∞ãÊ±ÇÂà©Áî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM)ÔºåÂÆÉÂú®Âª£Ê≥õÁöÑ‰ªªÂãô‰∏≠ÂèñÂæó‰∫ÜÂ∑®Â§ßÁöÑÊàêÂäüÔºåÂú®Ë™ûË®ÄÁêÜËß£ÂíåÈõ∂Ê¨°Â≠∏Áøí‰ªªÂãôÂÆåÊàêÊñπÈù¢ÈÉΩÂÖ∑ÂÇôÂá∫Ëâ≤ÁöÑËÉΩÂäõ„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÂÆåÂÖ®Ëá™ÂãïÂåñÁöÑÂü∫Êñº LLM ÁöÑÊ°ÜÊû∂‰æÜÂª∫ÊßãÊîªÊìäÁü•Ë≠òÂúñË≠úÔºåÂêçÁÇ∫ÔºöAttacKG+„ÄÇÊàëÂÄëÁöÑÊ°ÜÊû∂ÂåÖÂê´ÂõõÂÄãÈÄ£Á∫åÁöÑÊ®°ÁµÑÔºöÊîπÂØ´Âô®„ÄÅËß£ÊûêÂô®„ÄÅË≠òÂà•Âô®ÂíåÊëòË¶ÅÂô®ÔºåÊØèÂÄãÊ®°ÁµÑÈÉΩÊòØÈÄèÈÅéÊåá‰ª§ÊèêÁ§∫Âíå LLM Ë≥¶ËÉΩÁöÑËÑàÁµ°Â≠∏Áøí‰æÜÂØ¶Áèæ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂçáÁ¥ö‰∫ÜÁèæÊúâÁöÑÊîªÊìäÁü•Ë≠òÊû∂ÊßãÔºå‰∏¶ÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂÖ®Èù¢ÁöÑÁâàÊú¨„ÄÇÊàëÂÄëÂ∞áÁ∂≤Ë∑ØÊîªÊìäË°®Á§∫ÁÇ∫‰∏ÄÂÄãÊôÇÈñìÂ±ïÈñãÁöÑ‰∫ã‰ª∂ÔºåÊØèÂÄãÊôÇÈñìÊ≠•È©üÈÉΩÂåÖÂê´‰∏âÂ±§Ë°®Á§∫ÔºåÂåÖÊã¨Ë°åÁÇ∫Âúñ„ÄÅMITRE TTP Ê®ôÁ±§ÂíåÁãÄÊÖãÊëòË¶Å„ÄÇÂª£Ê≥õÁöÑË©ï‰º∞Ë°®ÊòéÔºö1) ÊàëÂÄëÁöÑË°®Ëø∞ÁÑ°Á∏´Âú∞ÊªøË∂≥‰∫ÜÂ®ÅËÑÖ‰∫ã‰ª∂ÂàÜÊûê‰∏≠ÁöÑË≥áË®äÈúÄÊ±ÇÔºå2) ÊàëÂÄëÁöÑÂª∫ÊßãÊ°ÜÊû∂ÊúâÊïàÂú∞Âø†ÂØ¶‰∏îÊ∫ñÁ¢∫Âú∞ÊèêÂèñ AttacKG+ ÂÆöÁæ©ÁöÑË≥áË®äÔºå‰ª•Âèä 3) ÊàëÂÄëÁöÑÊîªÊìäÂúñÁõ¥Êé•ÊúâÂà©Êñº‰∏ãÊ∏∏ÂÆâÂÖ®ÂØ¶ÂãôÔºå‰æãÂ¶ÇÊîªÊìäÈáçÂª∫„ÄÇÊâÄÊúâÁ®ãÂºèÁ¢ºÂíåË≥áÊñôÈõÜÂ∞áÂú®Ë¢´Êé•ÂèóÂæåÁôºÂ∏É„ÄÇ

##### **Enriched BERT Embeddings for Scholarly Publication Classification**
2405.04136v1 by Benjamin Wolff, Eva Seidlmayer, Konrad U. F√∂rstner

With the rapid expansion of academic literature and the proliferation of
preprints, researchers face growing challenges in manually organizing and
labeling large volumes of articles. The NSLP 2024 FoRC Shared Task I addresses
this challenge organized as a competition. The goal is to develop a classifier
capable of predicting one of 123 predefined classes from the Open Research
Knowledge Graph (ORKG) taxonomy of research fields for a given article.This
paper presents our results. Initially, we enrich the dataset (containing
English scholarly articles sourced from ORKG and arXiv), then leverage
different pre-trained language Models (PLMs), specifically BERT, and explore
their efficacy in transfer learning for this downstream task. Our experiments
encompass feature-based and fine-tuned transfer learning approaches using
diverse PLMs, optimized for scientific tasks, including SciBERT, SciNCL, and
SPECTER2. We conduct hyperparameter tuning and investigate the impact of data
augmentation from bibliographic databases such as OpenAlex, Semantic Scholar,
and Crossref. Our results demonstrate that fine-tuning pre-trained models
substantially enhances classification performance, with SPECTER2 emerging as
the most accurate model. Moreover, enriching the dataset with additional
metadata improves classification outcomes significantly, especially when
integrating information from S2AG, OpenAlex and Crossref. Our best-performing
approach achieves a weighted F1-score of 0.7415. Overall, our study contributes
to the advancement of reliable automated systems for scholarly publication
categorization, offering a potential solution to the laborious manual curation
process, thereby facilitating researchers in efficiently locating relevant
resources.

ÊëòË¶ÅÔºö<paragraph>Èö®ËëóÂ≠∏Ë°ìÊñáÁçªÁöÑÂø´ÈÄüÊì¥Â±ïÂíåÈ†êÂç∞Êú¨ÁöÑÊøÄÂ¢ûÔºåÁ†îÁ©∂‰∫∫Âì°Âú®ÊâãÂãïÁµÑÁπîÂíåÊ®ôË®òÂ§ßÈáèÊñáÁ´†ÊôÇÈù¢Ëá®ËëóË∂ä‰æÜË∂äÂ§ßÁöÑÊåëÊà∞„ÄÇNSLP 2024 FoRC ÂÖ±‰∫´‰ªªÂãô‰∏Ä‰ª•Á´∂Ë≥ΩÁöÑÂΩ¢ÂºèËß£Ê±∫‰∫ÜÈÄô‰∏ÄÊåëÊà∞„ÄÇÁõÆÊ®ôÊòØÈñãÁôº‰∏ÄÂÄãÂàÜÈ°ûÂô®ÔºåËÉΩÂ§†ÂæûÁµ¶ÂÆöÊñáÁ´†ÁöÑÁ†îÁ©∂È†òÂüüÁöÑÈñãÊîæÁ†îÁ©∂Áü•Ë≠òÂúñË≠ú (ORKG) ÂàÜÈ°ûÊ≥ï‰∏≠È†êÊ∏¨ 123 ÂÄãÈ†êÂÆöÁæ©È°ûÂà•‰πã‰∏Ä„ÄÇÊú¨ÊñáÂ±ïÁ§∫‰∫ÜÊàëÂÄëÁöÑÊàêÊûú„ÄÇÊúÄÂàùÔºåÊàëÂÄëË±êÂØå‰∫ÜÊï∏ÊìöÈõÜÔºàÂåÖÂê´‰æÜËá™ ORKG Âíå arXiv ÁöÑËã±ÊñáÂ≠∏Ë°ìÊñáÁ´†ÔºâÔºåÁÑ∂ÂæåÂà©Áî®‰∏çÂêåÁöÑÈ†êË®ìÁ∑¥Ë™ûË®ÄÊ®°Âûã (PLM)ÔºåÁâπÂà•ÊòØ BERTÔºå‰∏¶Êé¢Á¥¢ÂÆÉÂÄëÂú®Áî®ÊñºÊ≠§‰∏ãÊ∏∏‰ªªÂãôÁöÑÈÅ∑ÁßªÂ≠∏Áøí‰∏≠ÁöÑÂäüÊïà„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÂåÖÊã¨‰ΩøÁî®ÈáùÂ∞çÁßëÂ≠∏‰ªªÂãôÈÄ≤Ë°åÂÑ™ÂåñÁöÑÂêÑÁ®Æ PLM ÁöÑÂü∫ÊñºÁâπÂæµÂíåÂæÆË™øÁöÑÈÅ∑ÁßªÂ≠∏ÁøíÊñπÊ≥ïÔºåÂåÖÊã¨ SciBERT„ÄÅSciNCL Âíå SPECTER2„ÄÇÊàëÂÄëÈÄ≤Ë°åË∂ÖÂèÉÊï∏Ë™øÊï¥Ôºå‰∏¶Á†îÁ©∂‰æÜËá™ OpenAlex„ÄÅSemantic Scholar Âíå Crossref Á≠âÊõ∏ÁõÆÊï∏ÊìöÂ∫´ÁöÑÊï∏ÊìöÂ¢ûÂº∑ÁöÑÂΩ±Èüø„ÄÇÊàëÂÄëÁöÑÁµêÊûúË°®ÊòéÔºåÂæÆË™øÈ†êË®ìÁ∑¥Ê®°ÂûãÂèØ‰ª•È°ØËëóÊèêÈ´òÂàÜÈ°ûÊÄßËÉΩÔºåËÄå SPECTER2 ÊàêÁÇ∫ÊúÄÊ∫ñÁ¢∫ÁöÑÊ®°Âûã„ÄÇÊ≠§Â§ñÔºå‰ΩøÁî®È°çÂ§ñÁöÑÂÖÉÊï∏ÊìöË±êÂØåÊï∏ÊìöÈõÜÂèØ‰ª•È°ØËëóÊîπÂñÑÂàÜÈ°ûÁµêÊûúÔºåÁâπÂà•ÊòØÂú®Êï¥Âêà‰æÜËá™ S2AG„ÄÅOpenAlex Âíå Crossref ÁöÑ‰ø°ÊÅØÊôÇ„ÄÇÊàëÂÄëÊÄßËÉΩÊúÄÂ•ΩÁöÑÊñπÊ≥ïÂØ¶Áèæ‰∫Ü 0.7415 ÁöÑÂä†Ê¨ä F1 ÂàÜÊï∏„ÄÇÁ∏ΩÁöÑ‰æÜË™™ÔºåÊàëÂÄëÁöÑÁ†îÁ©∂ÊúâÂä©ÊñºÊé®ÈÄ≤Áî®ÊñºÂ≠∏Ë°ìÂá∫ÁâàÁâ©ÂàÜÈ°ûÁöÑÂèØÈù†Ëá™ÂãïÂåñÁ≥ªÁµ±ÔºåÁÇ∫ÁπÅÁë£ÁöÑÊâãÂãïÁ≠ñÂ±ïÈÅéÁ®ãÊèê‰æõ‰∫Ü‰∏ÄÂÄãÊΩõÂú®ÁöÑËß£Ê±∫ÊñπÊ°àÔºåÂæûËÄåÂπ´Âä©Á†îÁ©∂‰∫∫Âì°ÊúâÊïàÂú∞ÊâæÂà∞Áõ∏ÈóúË≥áÊ∫ê„ÄÇ</paragraph>

##### **FOKE: A Personalized and Explainable Education Framework Integrating Foundation Models, Knowledge Graphs, and Prompt Engineering**
2405.03734v1 by Silan Hu, Xiaoning Wang

Integrating large language models (LLMs) and knowledge graphs (KGs) holds
great promise for revolutionizing intelligent education, but challenges remain
in achieving personalization, interactivity, and explainability. We propose
FOKE, a Forest Of Knowledge and Education framework that synergizes foundation
models, knowledge graphs, and prompt engineering to address these challenges.
FOKE introduces three key innovations: (1) a hierarchical knowledge forest for
structured domain knowledge representation; (2) a multi-dimensional user
profiling mechanism for comprehensive learner modeling; and (3) an interactive
prompt engineering scheme for generating precise and tailored learning
guidance.
  We showcase FOKE's application in programming education, homework assessment,
and learning path planning, demonstrating its effectiveness and practicality.
Additionally, we implement Scholar Hero, a real-world instantiation of FOKE.
Our research highlights the potential of integrating foundation models,
knowledge graphs, and prompt engineering to revolutionize intelligent education
practices, ultimately benefiting learners worldwide. FOKE provides a principled
and unified approach to harnessing cutting-edge AI technologies for
personalized, interactive, and explainable educational services, paving the way
for further research and development in this critical direction.

ÊëòË¶ÅÔºöÊï¥ÂêàÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂíåÁü•Ë≠òÂúñË≠ú (KG) Â∞çÊñºÈù©Êñ∞Êô∫ÊÖßÊïôËÇ≤ÂÖ∑ÊúâÊ•µÂ§ßÁöÑÂâçÊôØÔºå‰ΩÜÂú®ÂØ¶ÁèæÂÄã‰∫∫Âåñ„ÄÅ‰∫íÂãïÊÄßÂíåÂèØËß£ÈáãÊÄßÊñπÈù¢‰ªçÂ≠òÂú®ÊåëÊà∞„ÄÇÊàëÂÄëÊèêÂá∫ FOKEÔºå‰∏ÄÂÄãÁü•Ë≠òÂíåÊïôËÇ≤Ê£ÆÊûóÊû∂ÊßãÔºåÂÆÉÂçîÂêå‰∫ÜÂü∫Á§éÊ®°Âûã„ÄÅÁü•Ë≠òÂúñË≠úÂíåÊèêÁ§∫Â∑•Á®ãÔºå‰ª•ÊáâÂ∞çÈÄô‰∫õÊåëÊà∞„ÄÇFOKE ÂºïÂÖ•‰∫Ü‰∏âÈ†ÖÈóúÈçµÂâµÊñ∞Ôºö(1) ‰∏ÄÂÄãÁî®ÊñºÁµêÊßãÂåñÈ†òÂüüÁü•Ë≠òË°®Á§∫ÁöÑÂàÜÂ±§Áü•Ë≠òÊ£ÆÊûóÔºõ(2) ‰∏ÄÂÄãÁî®ÊñºÂÖ®Èù¢Â≠∏ÁøíËÄÖÂª∫Ê®°ÁöÑÂ§öÁ∂≠Áî®Êà∂ÂàÜÊûêÊ©üÂà∂Ôºõ(3) ‰∏ÄÂÄãÁî®ÊñºÁî¢ÁîüÁ≤æÁ¢∫‰∏îÈáèË∫´ÂÆöÂà∂ÁöÑÂ≠∏ÁøíÊåáÂ∞éÁöÑ‰∫íÂãïÂºèÊèêÁ§∫Â∑•Á®ãÊñπÊ°à„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫Ü FOKE Âú®Á®ãÂºèÊïôËÇ≤„ÄÅ‰ΩúÊ•≠Ë©ïÈáèÂíåÂ≠∏ÁøíË∑ØÂæëË¶èÂäÉ‰∏≠ÁöÑÊáâÁî®ÔºåË≠âÊòé‰∫ÜÂÆÉÁöÑÊúâÊïàÊÄßÂíåÂØ¶Áî®ÊÄß„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂØ¶‰Ωú‰∫Ü Scholar HeroÔºå‰∏ÄÂÄã FOKE ÁöÑÁúüÂØ¶‰∏ñÁïåÂØ¶‰æã„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂Âº∑Ë™ø‰∫ÜÊï¥ÂêàÂü∫Á§éÊ®°Âûã„ÄÅÁü•Ë≠òÂúñË≠úÂíåÊèêÁ§∫Â∑•Á®ã‰ª•Èù©Êñ∞Êô∫ÊÖßÊïôËÇ≤ÂØ¶ÂãôÁöÑÊΩõÂäõÔºåÊúÄÁµÇ‰ΩøÂÖ®ÁêÉÂ≠∏ÁøíËÄÖÂèóÁõä„ÄÇFOKE Êèê‰æõ‰∫Ü‰∏ÄÁ®ÆÂü∫ÊñºÂéüÂâá‰∏îÁµ±‰∏ÄÁöÑÊñπÊ≥ïÔºåÁî®ÊñºÂà©Áî®Â∞ñÁ´ØÁöÑ AI ÊäÄË°ìÊèê‰æõÂÄã‰∫∫Âåñ„ÄÅ‰∫íÂãï‰∏îÂèØËß£ÈáãÁöÑÊïôËÇ≤ÊúçÂãôÔºåÁÇ∫ÈÄôÂÄãÈóúÈçµÈ†òÂüüÁöÑÈÄ≤‰∏ÄÊ≠•Á†îÁ©∂ÂíåÁôºÂ±ïÈã™Âπ≥‰∫ÜÈÅìË∑Ø„ÄÇ

##### **E-TSL: A Continuous Educational Turkish Sign Language Dataset with Baseline Methods**
2405.02984v1 by ≈û√ºkr√º √ñzt√ºrk, Hacer Yalim Keles

This study introduces the continuous Educational Turkish Sign Language
(E-TSL) dataset, collected from online Turkish language lessons for 5th, 6th,
and 8th grades. The dataset comprises 1,410 videos totaling nearly 24 hours and
includes performances from 11 signers. Turkish, an agglutinative language,
poses unique challenges for sign language translation, particularly with a
vocabulary where 64% are singleton words and 85% are rare words, appearing less
than five times. We developed two baseline models to address these challenges:
the Pose to Text Transformer (P2T-T) and the Graph Neural Network based
Transformer (GNN-T) models. The GNN-T model achieved 19.13% BLEU-1 score and
3.28% BLEU-4 score, presenting a significant challenge compared to existing
benchmarks. The P2T-T model, while demonstrating slightly lower performance in
BLEU scores, achieved a higher ROUGE-L score of 22.09%. Additionally, we
benchmarked our model using the well-known PHOENIX-Weather 2014T dataset to
validate our approach.

ÊëòË¶ÅÔºöÊú¨Á†îÁ©∂‰ªãÁ¥πÈÄ£Á∫åÊïôËÇ≤ÂúüËÄ≥ÂÖ∂ÊâãË™û (E-TSL) Ë≥áÊñôÈõÜÔºåÊ≠§Ë≥áÊñôÈõÜÊòØÂæûÁ∑ö‰∏äÂúüËÄ≥ÂÖ∂Ë™ûË™≤Á®ã‰∏≠Êî∂ÈõÜËÄå‰æÜÔºåÂ∞çË±°ÁÇ∫ 5„ÄÅ6„ÄÅ8 Âπ¥Á¥ö„ÄÇË©≤Ë≥áÊñôÈõÜÂåÖÂê´ 1,410 ÈÉ®ÂΩ±ÁâáÔºåÁ∏ΩÈï∑Ëøë 24 Â∞èÊôÇÔºå‰∏¶ÂåÖÂê´ 11 ‰ΩçÊâãË™ûÁøªË≠ØÂì°ÁöÑË°®Êºî„ÄÇÂúüËÄ≥ÂÖ∂Ë™ûÊòØ‰∏ÄÁ®ÆÈªèËëóË™ûÔºåÂ∞çÊâãË™ûÁøªË≠ØÊßãÊàêÁç®ÁâπÊåëÊà∞ÔºåÁâπÂà•ÊòØÂÖ∂Ë©ûÂΩô‰∏≠Êúâ 64% ÊòØÂñÆË∫´Ë©ûÔºåËÄå 85% ÊòØÁΩïË¶ãË©ûÂΩôÔºåÂá∫ÁèæÊ¨°Êï∏‰∏çÂà∞‰∫îÊ¨°„ÄÇÊàëÂÄëÈñãÁôº‰∫ÜÂÖ©ÂÄãÂü∫Á∑öÊ®°Âûã‰æÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÔºöÂßøÂã¢ËΩâÊñáÂ≠óËΩâÊèõÂô® (P2T-T) ÂíåÂü∫ÊñºÂúñÂΩ¢Á•ûÁ∂ìÁ∂≤Ë∑ØÁöÑËΩâÊèõÂô® (GNN-T) Ê®°Âûã„ÄÇGNN-T Ê®°ÂûãÁç≤Âæó 19.13% ÁöÑ BLEU-1 ÂàÜÊï∏Âíå 3.28% ÁöÑ BLEU-4 ÂàÜÊï∏ÔºåËàáÁèæÊúâÂü∫Ê∫ñÁõ∏ÊØîÔºåÊòØ‰∏ÄÂÄãÈáçÂ§ßÁöÑÊåëÊà∞„ÄÇP2T-T Ê®°ÂûãÈõñÁÑ∂Âú® BLEU ÂàÜÊï∏‰∏äÁöÑË°®ÁèæÁ®ç‰ΩéÔºå‰ΩÜÁç≤Âæó‰∫ÜÊõ¥È´òÁöÑ ROUGE-L ÂàÜÊï∏ÔºåÁÇ∫ 22.09%„ÄÇÊ≠§Â§ñÔºåÊàëÂÄë‰ΩøÁî®ËëóÂêçÁöÑ PHOENIX-Weather 2014T Ë≥áÊñôÈõÜÂ∞çÊàëÂÄëÁöÑÊ®°ÂûãÈÄ≤Ë°åÂü∫Ê∫ñÊ∏¨Ë©¶Ôºå‰ª•È©óË≠âÊàëÂÄëÁöÑÂÅöÊ≥ï„ÄÇ

##### **Relations Prediction for Knowledge Graph Completion using Large Language Models**
2405.02738v1 by Sakher Khalil Alqaaidi, Krzysztof Kochut

Knowledge Graphs have been widely used to represent facts in a structured
format. Due to their large scale applications, knowledge graphs suffer from
being incomplete. The relation prediction task obtains knowledge graph
completion by assigning one or more possible relations to each pair of nodes.
In this work, we make use of the knowledge graph node names to fine-tune a
large language model for the relation prediction task. By utilizing the node
names only we enable our model to operate sufficiently in the inductive
settings. Our experiments show that we accomplish new scores on a widely used
knowledge graph benchmark.

ÊëòË¶ÅÔºöÁü•Ë≠òÂúñË≠úÂ∑≤Ë¢´Âª£Ê≥õÁî®Êñº‰ª•ÁµêÊßãÂåñÊ†ºÂºèË°®Á§∫‰∫ãÂØ¶„ÄÇÁî±ÊñºÂÖ∂Â§ßË¶èÊ®°ÊáâÁî®ÔºåÁü•Ë≠òÂúñË≠úÂ≠òÂú®‰∏çÂÆåÊï¥ÁöÑÂïèÈ°å„ÄÇÈóú‰øÇÈ†êÊ∏¨‰ªªÂãôÈÄöÈÅéÁÇ∫ÊØèÂ∞çÁØÄÈªûÂàÜÈÖç‰∏ÄÂÄãÊàñÂ§öÂÄãÂèØËÉΩÁöÑÈóú‰øÇ‰æÜÁç≤ÂæóÁü•Ë≠òÂúñË≠úÁöÑÂÆåÊàê„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÂà©Áî®Áü•Ë≠òÂúñË≠úÁØÄÈªûÂêçÁ®±‰æÜÂæÆË™øÈóú‰øÇÈ†êÊ∏¨‰ªªÂãôÁöÑÂ§ßË™ûË®ÄÊ®°Âûã„ÄÇÂÉÖÈÄöÈÅé‰ΩøÁî®ÁØÄÈªûÂêçÁ®±ÔºåÊàëÂÄëÂ∞±ËÉΩËÆìÊ®°ÂûãÂú®Ê≠∏Á¥çË®≠ÁΩÆ‰∏≠ÂÖÖÂàÜÈÅã‰Ωú„ÄÇÊàëÂÄëÁöÑÂØ¶È©óË°®ÊòéÔºåÊàëÂÄëÂú®Âª£Ê≥õ‰ΩøÁî®ÁöÑÁü•Ë≠òÂúñË≠úÂü∫Ê∫ñÊ∏¨Ë©¶‰∏≠Áç≤Âæó‰∫ÜÊñ∞ÁöÑÂàÜÊï∏„ÄÇ

##### **IQLS: Framework for leveraging Metadata to enable Large Language Model based queries to complex, versatile Data**
2405.15792v1 by Sami Azirar, Hossam A. Gabbar, Chaouki Regoui

As the amount and complexity of data grows, retrieving it has become a more
difficult task that requires greater knowledge and resources. This is
especially true for the logistics industry, where new technologies for data
collection provide tremendous amounts of interconnected real-time data. The
Intelligent Query and Learning System (IQLS) simplifies the process by allowing
natural language use to simplify data retrieval . It maps structured data into
a framework based on the available metadata and available data models. This
framework creates an environment for an agent powered by a Large Language
Model. The agent utilizes the hierarchical nature of the data to filter
iteratively by making multiple small context-aware decisions instead of
one-shot data retrieval. After the Data filtering, the IQLS enables the agent
to fulfill tasks given by the user query through interfaces. These interfaces
range from multimodal transportation information retrieval to route planning
under multiple constraints. The latter lets the agent define a dynamic object,
which is determined based on the query parameters. This object represents a
driver capable of navigating a road network. The road network is depicted as a
graph with attributes based on the data. Using a modified version of the
Dijkstra algorithm, the optimal route under the given constraints can be
determined. Throughout the entire process, the user maintains the ability to
interact and guide the system. The IQLS is showcased in a case study on the
Canadian logistics sector, allowing geospatial, visual, tabular and text data
to be easily queried semantically in natural language.

ÊëòË¶ÅÔºöÈöèÁùÄÊï∞ÊçÆÈáèÂíåÂ§çÊùÇÊÄß‰∏çÊñ≠Â¢ûÂä†ÔºåÊ£ÄÁ¥¢Êï∞ÊçÆÂ∑≤Êàê‰∏∫‰∏ÄÈ°πÊõ¥Âõ∞ÈöæÁöÑ‰ªªÂä°ÔºåÈúÄË¶ÅÊõ¥Â§öÁöÑÁü•ËØÜÂíåËµÑÊ∫ê„ÄÇÂØπ‰∫éÁâ©ÊµÅË°å‰∏öÊù•ËØ¥Â∞§ÂÖ∂Â¶ÇÊ≠§ÔºåËØ•Ë°å‰∏öÁî®‰∫éÊï∞ÊçÆÊî∂ÈõÜÁöÑÊñ∞ÊäÄÊúØÊèê‰æõ‰∫ÜÂ§ßÈáèÁõ∏‰∫íÂÖ≥ËÅîÁöÑÂÆûÊó∂Êï∞ÊçÆ„ÄÇÊô∫ËÉΩÊü•ËØ¢ÂíåÂ≠¶‰π†Á≥ªÁªü (IQLS) ÈÄöËøáÂÖÅËÆ∏‰ΩøÁî®Ëá™ÁÑ∂ËØ≠Ë®ÄÊù•ÁÆÄÂåñÊï∞ÊçÆÊ£ÄÁ¥¢Ôºå‰ªéËÄåÁÆÄÂåñ‰∫ÜËøô‰∏ÄËøáÁ®ã„ÄÇÂÆÉÂ∞ÜÁªìÊûÑÂåñÊï∞ÊçÆÊò†Â∞ÑÂà∞Âü∫‰∫éÂèØÁî®ÂÖÉÊï∞ÊçÆÂíåÂèØÁî®Êï∞ÊçÆÊ®°ÂûãÁöÑÊ°ÜÊû∂‰∏≠„ÄÇÊ≠§Ê°ÜÊû∂‰∏∫Áî±Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÊèê‰æõÊîØÊåÅÁöÑ‰ª£ÁêÜÂàõÂª∫‰∫Ü‰∏Ä‰∏™ÁéØÂ¢É„ÄÇËØ•‰ª£ÁêÜÂà©Áî®Êï∞ÊçÆÁöÑÂ±ÇÊ¨°ÁªìÊûÑÈÄöËøáÂ§öÊ¨°ËøõË°åÂ∞èÁöÑ‰∏ä‰∏ãÊñáÊÑüÁü•ÂÜ≥Á≠ñËÄå‰∏çÊòØ‰∏ÄÊ¨°ÊÄßÊï∞ÊçÆÊ£ÄÁ¥¢Êù•ËøõË°åËø≠‰ª£ËøáÊª§„ÄÇÂú®Êï∞ÊçÆËøáÊª§‰πãÂêéÔºåIQLS ‰Ωø‰ª£ÁêÜËÉΩÂ§üÈÄöËøáÁïåÈù¢ÂÆåÊàêÁî®Êà∑Êü•ËØ¢ÁªôÂÆöÁöÑ‰ªªÂä°„ÄÇËøô‰∫õÁïåÈù¢ËåÉÂõ¥‰ªéÂ§öÊ®°Âºè‰∫§ÈÄö‰ø°ÊÅØÊ£ÄÁ¥¢Âà∞Âú®Â§öÈáçÁ∫¶Êùü‰∏ãÁöÑË∑ØÁ∫øËßÑÂàí„ÄÇÂêéËÄÖËÆ©‰ª£ÁêÜËÉΩÂ§üÂÆö‰πâ‰∏Ä‰∏™Âä®ÊÄÅÂØπË±°ÔºåËØ•ÂØπË±°Ê†πÊçÆÊü•ËØ¢ÂèÇÊï∞Á°ÆÂÆö„ÄÇÊ≠§ÂØπË±°Ë°®Á§∫ËÉΩÂ§üÂú®ÈÅìË∑ØÁΩëÁªú‰∏≠ÂØºËà™ÁöÑÈ©æÈ©∂Âëò„ÄÇÈÅìË∑ØÁΩëÁªúË¢´ÊèèËø∞‰∏∫ÂÖ∑ÊúâÂü∫‰∫éÊï∞ÊçÆÁöÑÂ±ûÊÄßÁöÑÂõæË°®„ÄÇ‰ΩøÁî® Dijkstra ÁÆóÊ≥ïÁöÑ‰øÆÊîπÁâàÊú¨ÔºåÂèØ‰ª•Âú®ÁªôÂÆöÁ∫¶Êùü‰∏ãÁ°ÆÂÆöÊúÄ‰Ω≥Ë∑ØÁ∫ø„ÄÇÂú®Êï¥‰∏™ËøáÁ®ã‰∏≠ÔºåÁî®Êà∑ÂßãÁªàËÉΩÂ§ü‰∏éÁ≥ªÁªü‰∫§‰∫íÂπ∂ÊåáÂØºÁ≥ªÁªü„ÄÇIQLS Âú®Âä†ÊãøÂ§ßÁâ©ÊµÅÈÉ®Èó®ÁöÑÊ°à‰æãÁ†îÁ©∂‰∏≠ÂæóÂà∞Â±ïÁ§∫ÔºåÂÖÅËÆ∏Âú®Âú∞ÁêÜÁ©∫Èó¥„ÄÅËßÜËßâ„ÄÅË°®Ê†ºÂíåÊñáÊú¨Êï∞ÊçÆ‰∏≠‰ΩøÁî®Ëá™ÁÑ∂ËØ≠Ë®ÄËΩªÊùæÂú∞ËøõË°åËØ≠‰πâÊü•ËØ¢„ÄÇ

##### **R4: Reinforced Retriever-Reorder-Responder for Retrieval-Augmented Large Language Models**
2405.02659v1 by Taolin Zhang, Dongyang Li, Qizhou Chen, Chengyu Wang, Longtao Huang, Hui Xue, Xiaofeng He, Jun Huang

Retrieval-augmented large language models (LLMs) leverage relevant content
retrieved by information retrieval systems to generate correct responses,
aiming to alleviate the hallucination problem. However, existing
retriever-responder methods typically append relevant documents to the prompt
of LLMs to perform text generation tasks without considering the interaction of
fine-grained structural semantics between the retrieved documents and the LLMs.
This issue is particularly important for accurate response generation as LLMs
tend to ``lose in the middle'' when dealing with input prompts augmented with
lengthy documents. In this work, we propose a new pipeline named ``Reinforced
Retriever-Reorder-Responder'' (R$^4$) to learn document orderings for
retrieval-augmented LLMs, thereby further enhancing their generation abilities
while the large numbers of parameters of LLMs remain frozen. The reordering
learning process is divided into two steps according to the quality of the
generated responses: document order adjustment and document representation
enhancement. Specifically, document order adjustment aims to organize retrieved
document orderings into beginning, middle, and end positions based on graph
attention learning, which maximizes the reinforced reward of response quality.
Document representation enhancement further refines the representations of
retrieved documents for responses of poor quality via document-level gradient
adversarial learning. Extensive experiments demonstrate that our proposed
pipeline achieves better factual question-answering performance on
knowledge-intensive tasks compared to strong baselines across various public
datasets. The source codes and trained models will be released upon paper
acceptance.

ÊëòË¶ÅÔºö<paragraph>Ê™¢Á¥¢Â¢ûÂº∑Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âà©Áî®Ë≥áË®äÊ™¢Á¥¢Á≥ªÁµ±Ê™¢Á¥¢Âà∞ÁöÑÁõ∏ÈóúÂÖßÂÆπ‰æÜÁî¢ÁîüÊ≠£Á¢∫ÁöÑÂõûÊáâÔºåÊó®Âú®Ê∏õËºïÂπªË¶∫ÂïèÈ°å„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÁöÑÊ™¢Á¥¢ÂõûÊáâÊñπÊ≥ïÈÄöÂ∏∏Â∞áÁõ∏ÈóúÊñá‰ª∂ÈôÑÂä†Âà∞ LLM ÁöÑÊèêÁ§∫‰∏≠Ôºå‰ª•Âü∑Ë°åÊñáÂ≠óÁîüÊàê‰ªªÂãôÔºåËÄåÊ≤íÊúâËÄÉÊÖÆÊ™¢Á¥¢Âà∞ÁöÑÊñá‰ª∂Âíå LLM ‰πãÈñìÁ¥∞Á≤íÂ∫¶ÁµêÊßãË™ûÁæ©ÁöÑ‰∫íÂãï„ÄÇÈÄôÂÄãÂïèÈ°åÂ∞çÊñºÊ∫ñÁ¢∫ÁöÑÂõûÊáâÁîüÊàêÁâπÂà•ÈáçË¶ÅÔºåÂõ†ÁÇ∫ LLM Âú®ËôïÁêÜ‰ª•ÂÜóÈï∑Êñá‰ª∂Â¢ûÂº∑ÁöÑËº∏ÂÖ•ÊèêÁ§∫ÊôÇÂæÄÂæÄÊúÉ„ÄåËø∑Â§±Âú®‰∏≠Èñì„Äç„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂêçÁÇ∫„ÄåÂº∑ÂåñÊ™¢Á¥¢ÈáçÊéíÂ∫èÂõûÊáâÂô®„Äç(R$^4$) ÁöÑÊñ∞ÁÆ°ÈÅìÔºåÁî®ÊñºÂ≠∏ÁøíÊ™¢Á¥¢Â¢ûÂº∑ LLM ÁöÑÊñá‰ª∂ÊéíÂ∫èÔºåÂæûËÄåÈÄ≤‰∏ÄÊ≠•Â¢ûÂº∑ÂÆÉÂÄëÁöÑÁîüÊàêËÉΩÂäõÔºåÂêåÊôÇ LLM ÁöÑÂ§ßÈáèÂèÉÊï∏‰øùÊåÅÂáçÁµê„ÄÇÊ†πÊìöÁîüÊàêÂõûÊáâÁöÑÂìÅË≥™ÔºåÈáçÊéíÂ∫èÂ≠∏ÁøíÈÅéÁ®ãÂàÜÁÇ∫ÂÖ©ÂÄãÊ≠•È©üÔºöÊñá‰ª∂È†ÜÂ∫èË™øÊï¥ÂíåÊñá‰ª∂Ë°®Á§∫Â¢ûÂº∑„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊñá‰ª∂È†ÜÂ∫èË™øÊï¥Êó®Âú®Ê†πÊìöÂúñÊ≥®ÊÑèÂäõÂ≠∏ÁøíÂ∞áÊ™¢Á¥¢Âà∞ÁöÑÊñá‰ª∂ÊéíÂ∫èÁµÑÁπîÊàêÈñãÂßã„ÄÅ‰∏≠ÈñìÂíåÁµêÊùü‰ΩçÁΩÆÔºåÈÄôÊúÄÂ§ßÂåñ‰∫ÜÂõûÊáâÂìÅË≥™ÁöÑÂº∑ÂåñÁçéÂãµ„ÄÇÊñá‰ª∂Ë°®Á§∫Â¢ûÂº∑ÈÄ≤‰∏ÄÊ≠•ÈÄöÈÅéÊñá‰ª∂Á¥öÂà•Ê¢ØÂ∫¶Â∞çÊäóÂ≠∏ÁøíÔºåÊîπÂñÑ‰∫ÜÂìÅË≥™‰∏ç‰Ω≥ÁöÑÂõûÊáâÁöÑÊ™¢Á¥¢Êñá‰ª∂Ë°®Á§∫„ÄÇÂª£Ê≥õÁöÑÂØ¶È©óË°®ÊòéÔºåËàáÂêÑÁ®ÆÂÖ¨ÂÖ±Êï∏ÊìöÈõÜ‰∏äÁöÑÂº∑Â§ßÂü∫Á∑öÁõ∏ÊØîÔºåÊàëÂÄëÊèêÂá∫ÁöÑÁÆ°ÈÅìÂú®Áü•Ë≠òÂØÜÈõÜÂûã‰ªªÂãô‰∏äÂØ¶Áèæ‰∫ÜÊõ¥Â•ΩÁöÑ‰∫ãÂØ¶ÂïèÁ≠îÊÄßËÉΩ„ÄÇÂéüÂßãÁ¢ºÂíåË®ìÁ∑¥Â•ΩÁöÑÊ®°ÂûãÂ∞áÂú®Ë´ñÊñáË¢´Êé•ÂèóÂæåÁôºÂ∏É„ÄÇ</paragraph>

##### **Evaluating Large Language Models for Structured Science Summarization in the Open Research Knowledge Graph**
2405.02105v1 by Vladyslav Nechakhin, Jennifer D'Souza, Steffen Eger

Structured science summaries or research contributions using properties or
dimensions beyond traditional keywords enhances science findability. Current
methods, such as those used by the Open Research Knowledge Graph (ORKG),
involve manually curating properties to describe research papers' contributions
in a structured manner, but this is labor-intensive and inconsistent between
the domain expert human curators. We propose using Large Language Models (LLMs)
to automatically suggest these properties. However, it's essential to assess
the readiness of LLMs like GPT-3.5, Llama 2, and Mistral for this task before
application. Our study performs a comprehensive comparative analysis between
ORKG's manually curated properties and those generated by the aforementioned
state-of-the-art LLMs. We evaluate LLM performance through four unique
perspectives: semantic alignment and deviation with ORKG properties,
fine-grained properties mapping accuracy, SciNCL embeddings-based cosine
similarity, and expert surveys comparing manual annotations with LLM outputs.
These evaluations occur within a multidisciplinary science setting. Overall,
LLMs show potential as recommendation systems for structuring science, but
further finetuning is recommended to improve their alignment with scientific
tasks and mimicry of human expertise.

ÊëòË¶ÅÔºöÁµêÊßãÂåñÁöÑÁßëÂ≠∏ÊëòË¶ÅÊàñÁ†îÁ©∂Ë≤¢Áçª‰ΩøÁî®Ë∂ÖË∂äÂÇ≥Áµ±ÈóúÈçµÂ≠óÁöÑÂ±¨ÊÄßÊàñÁ∂≠Â∫¶ÔºåÊèêÂçáÁßëÂ≠∏ÁöÑÂèØÊü•ÊâæÊÄß„ÄÇÁõÆÂâçÁöÑÊäÄË°ìÔºåÂÉèÊòØÈñãÊîæÁ†îÁ©∂Áü•Ë≠òÂúñË≠ú (ORKG) ÊâÄ‰ΩøÁî®ÁöÑÊäÄË°ìÔºåÊ∂âÂèä‰∫∫Â∑•Á≠ñÂ±ïÂ±¨ÊÄß‰ª•ÁµêÊßãÂåñÊñπÂºèÊèèËø∞Á†îÁ©∂Ë´ñÊñáÁöÑË≤¢ÁçªÔºå‰ΩÜÈÄôÈ†ÖÂ∑•‰ΩúË≤ªÊôÇ‰∏îÂú®È†òÂüüÂ∞àÂÆ∂ÁöÑ‰∫∫Â∑•Á≠ñÂ±ïËÄÖ‰πãÈñì‰∏ç‰∏ÄËá¥„ÄÇÊàëÂÄëÊèêÂá∫‰ΩøÁî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Ëá™ÂãïÂª∫Ë≠∞ÈÄô‰∫õÂ±¨ÊÄß„ÄÇÁÑ∂ËÄåÔºåÂú®ÊáâÁî®‰πãÂâçÔºåË©ï‰º∞ GPT-3.5„ÄÅLlama 2 Âíå Mistral Á≠â LLM ÁöÑÊ∫ñÂÇôÂ∫¶Â∞çÈÄôÈ†Ö‰ªªÂãôËá≥ÈóúÈáçË¶Å„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂Â∞ç ORKG ‰∫∫Â∑•Á≠ñÂ±ïÁöÑÂ±¨ÊÄßÂíåÂâçËø∞ÊúÄÂÖàÈÄ≤ÁöÑ LLM ÊâÄÁî¢ÁîüÁöÑÂ±¨ÊÄß‰πãÈñìÈÄ≤Ë°åÂÖ®Èù¢ÁöÑÊØîËºÉÂàÜÊûê„ÄÇÊàëÂÄëÈÄèÈÅéÂõõÂÄãÁç®ÁâπÁöÑËßÄÈªûË©ï‰º∞ LLM ÁöÑÊïàËÉΩÔºöË™ûÊÑèÂ∞çÈΩäÂíåËàá ORKG Â±¨ÊÄßÁöÑÂÅèÂ∑Æ„ÄÅÁ¥∞Á≤íÂ∫¶Â±¨ÊÄßÂ∞çÊáâÊ∫ñÁ¢∫Â∫¶„ÄÅÂü∫Êñº SciNCL ÂµåÂÖ•ÁöÑÈ§òÂº¶Áõ∏‰ººÂ∫¶Ôºå‰ª•ÂèäÊØîËºÉ‰∫∫Â∑•Ë®ªËß£Âíå LLM Ëº∏Âá∫ÁöÑÂ∞àÂÆ∂Ë™øÊü•„ÄÇÈÄô‰∫õË©ïÈáèÁôºÁîüÂú®Â§öÂ≠∏ÁßëÁßëÂ≠∏Áí∞Â¢É‰∏≠„ÄÇÁ∏ΩÈ´îËÄåË®ÄÔºåLLM ‰ΩúÁÇ∫ÁµêÊßãÂåñÁßëÂ≠∏ÁöÑÊé®Ëñ¶Á≥ªÁµ±È°ØÁ§∫Âá∫ÊΩõÂäõÔºå‰ΩÜÂª∫Ë≠∞ÈÄ≤‰∏ÄÊ≠•ÂæÆË™ø‰ª•ÊîπÂñÑÂÆÉÂÄëËàáÁßëÂ≠∏‰ªªÂãôÁöÑ‰∏ÄËá¥ÊÄßÔºå‰∏¶Ê®°Êì¨‰∫∫È°ûÁöÑÂ∞àÊ•≠Áü•Ë≠ò„ÄÇ

##### **Protein binding affinity prediction under multiple substitutions applying eGNNs on Residue and Atomic graphs combined with Language model information: eGRAL**
2405.02374v1 by Arturo Fiorellini-Bernardis, Sebastien Boyer, Christoph Brunken, Bakary Diallo, Karim Beguir, Nicolas Lopez-Carranza, Oliver Bent

Protein-protein interactions (PPIs) play a crucial role in numerous
biological processes. Developing methods that predict binding affinity changes
under substitution mutations is fundamental for modelling and re-engineering
biological systems. Deep learning is increasingly recognized as a powerful tool
capable of bridging the gap between in-silico predictions and in-vitro
observations. With this contribution, we propose eGRAL, a novel SE(3)
equivariant graph neural network (eGNN) architecture designed for predicting
binding affinity changes from multiple amino acid substitutions in protein
complexes. eGRAL leverages residue, atomic and evolutionary scales, thanks to
features extracted from protein large language models. To address the limited
availability of large-scale affinity assays with structural information, we
generate a simulated dataset comprising approximately 500,000 data points. Our
model is pre-trained on this dataset, then fine-tuned and tested on
experimental data.

ÊëòË¶ÅÔºöËõãÁôΩ-ËõãÁôΩ‰∫§‰∫í‰ΩúÁî® (PPIs) Âú®Ë®±Â§öÁîüÁâ©ÈÅéÁ®ã‰∏≠ÊâÆÊºîÈóúÈçµËßíËâ≤„ÄÇÈñãÁôºÂèØÈ†êÊ∏¨Âèñ‰ª£Á™ÅËÆä‰∏ãÁµêÂêàË¶™ÂíåÂäõËÆäÂåñÁöÑÊñπÊ≥ïÔºåÂ∞çÊñºÂª∫Ê®°ÂíåÈáçÊñ∞Ë®≠Ë®àÁîüÁâ©Á≥ªÁµ±Ëá≥ÈóúÈáçË¶Å„ÄÇÊ∑±Â∫¶Â≠∏ÁøíÈÄêÊº∏Ë¢´Ë™çÁÇ∫ÊòØ‰∏ÄÁ®ÆÂº∑Â§ßÁöÑÂ∑•ÂÖ∑ÔºåËÉΩÂ§†ÂΩåÂêàÈõªËÖ¶Ê®°Êì¨È†êÊ∏¨ÂíåÈ´îÂ§ñËßÄÂØü‰πãÈñìÁöÑÂ∑ÆË∑ù„ÄÇÈÄèÈÅéÈÄôÈ†ÖË≤¢ÁçªÔºåÊàëÂÄëÊèêÂá∫ eGRALÔºå‰∏ÄÁ®ÆÊñ∞Á©éÁöÑ SE(3) Á≠âËÆäÂúñÁ•ûÁ∂ìÁ∂≤Ë∑Ø (eGNN) Êû∂ÊßãÔºåÂ∞àÈñÄË®≠Ë®àÁî®‰æÜÈ†êÊ∏¨ËõãÁôΩË≥™Ë§áÂêàÈ´î‰∏≠Â§öÂÄãËÉ∫Âü∫ÈÖ∏Âèñ‰ª£ÁöÑÁµêÂêàË¶™ÂíåÂäõËÆäÂåñ„ÄÇeGRAL ÈÄèÈÅéÂæûËõãÁôΩË≥™Â§ßÂûãË™ûË®ÄÊ®°Âûã‰∏≠ËêÉÂèñÁöÑÁâπÂæµÔºåÂñÑÁî®ÊÆòÂü∫„ÄÅÂéüÂ≠êÂíåÊºîÂåñÂ∞∫Â∫¶„ÄÇÁÇ∫‰∫ÜËß£Ê±∫Â§ßË¶èÊ®°Ë¶™ÂíåÂäõÊ∏¨ÂÆöÊ≥ïËàáÁµêÊßãË≥áË®äÂèØÁî®ÊÄßÊúâÈôêÁöÑÂïèÈ°åÔºåÊàëÂÄëÁî¢Áîü‰∫Ü‰∏ÄÂÄãÊ®°Êì¨ÁöÑË≥áÊñôÈõÜÔºåÂåÖÂê´Â§ßÁ¥Ñ 500,000 ÂÄãË≥áÊñôÈªû„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÂú®ÈÄôÁµÑË≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÈ†êË®ìÁ∑¥ÔºåÁÑ∂ÂæåÂú®ÂØ¶È©óË≥áÊñô‰∏äÂæÆË™øÂíåÊ∏¨Ë©¶„ÄÇ

##### **CodeGRAG: Extracting Composed Syntax Graphs for Retrieval Augmented Cross-Lingual Code Generation**
2405.02355v1 by Kounianhua Du, Renting Rui, Huacan Chai, Lingyue Fu, Wei Xia, Yasheng Wang, Ruiming Tang, Yong Yu, Weinan Zhang

Utilizing large language models to generate codes has shown promising meaning
in software development revolution. Despite the intelligence shown by the
general large language models, their specificity in code generation can still
be improved due to the syntactic gap and mismatched vocabulary existing among
natural language and different programming languages. In addition, programming
languages are inherently logical and complex, making them hard to be correctly
generated. Existing methods rely on multiple prompts to the large language
model to explore better solutions, which is expensive. In this paper, we
propose Syntax Graph Retrieval Augmented Code Generation (CodeGRAG) to enhance
the performance of LLMs in single-round code generation tasks. CodeGRAG
extracts and summarizes the control flow and data flow of code blocks to fill
the gap between programming languages and natural language. The extracted
external structural knowledge models the inherent flows of code blocks, which
can facilitate LLMs for better understanding of code syntax and serve as a
bridge among different programming languages. CodeGRAG significantly improves
the code generation ability of LLMs and can even offer performance gain for
cross-lingual code generation, e.g., C++ for Python.

ÊëòË¶ÅÔºöÂà©Áî®Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÊù•ÁîüÊàê‰ª£Á†ÅÂú®ËΩØ‰ª∂ÂºÄÂèëÈù©ÂëΩ‰∏≠ÊòæÁ§∫Âá∫ÊúâÂ∏åÊúõÁöÑÊÑè‰πâ„ÄÇÂ∞ΩÁÆ°ÈÄöÁî®Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÊòæÁ§∫Âá∫Êô∫ËÉΩÔºå‰ΩÜÁî±‰∫éËá™ÁÑ∂ËØ≠Ë®ÄÂíå‰∏çÂêåÁºñÁ®ãËØ≠Ë®Ä‰πãÈó¥Â≠òÂú®ÁöÑÂè•Ê≥ïÂ∑ÆË∑ùÂíåËØçÊ±á‰∏çÂåπÈÖçÔºåÂÆÉ‰ª¨Âú®‰ª£Á†ÅÁîüÊàê‰∏≠ÁöÑÁâπÂºÇÊÄß‰ªçÁÑ∂ÂèØ‰ª•ÂæóÂà∞ÊîπÂñÑ„ÄÇÊ≠§Â§ñÔºåÁºñÁ®ãËØ≠Ë®ÄÊú¨Ë¥®‰∏äÊòØÈÄªËæë‰∏îÂ§çÊùÇÁöÑÔºåËøô‰ΩøÂæóÂÆÉ‰ª¨Èöæ‰ª•Ë¢´Ê≠£Á°ÆÁîüÊàê„ÄÇÁé∞ÊúâÊñπÊ≥ï‰æùËµñ‰∫éÂêëÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÂèëÂá∫Â§ö‰∏™ÊèêÁ§∫‰ª•Êé¢Á¥¢Êõ¥Â•ΩÁöÑËß£ÂÜ≥ÊñπÊ°àÔºåËøôÊòØÊòÇË¥µÁöÑ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨ÊèêÂá∫‰∫ÜËØ≠Ê≥ïÂõæÊ£ÄÁ¥¢Â¢ûÂº∫‰ª£Á†ÅÁîüÊàê (CodeGRAG) Êù•Â¢ûÂº∫ LLM Âú®ÂçïËΩÆ‰ª£Á†ÅÁîüÊàê‰ªªÂä°‰∏≠ÁöÑÊÄßËÉΩ„ÄÇCodeGRAG ÊèêÂèñÂíåÊÄªÁªì‰ª£Á†ÅÂùóÁöÑÊéßÂà∂ÊµÅÂíåÊï∞ÊçÆÊµÅÔºå‰ª•Â°´Ë°•ÁºñÁ®ãËØ≠Ë®ÄÂíåËá™ÁÑ∂ËØ≠Ë®Ä‰πãÈó¥ÁöÑÁ©∫ÁôΩ„ÄÇÊèêÂèñÁöÑÂ§ñÈÉ®ÁªìÊûÑÁü•ËØÜÂØπ‰ª£Á†ÅÂùóÁöÑÂõ∫ÊúâÊµÅËøõË°åÂª∫Ê®°ÔºåËøôÂèØ‰ª•‰øÉËøõ LLM Êõ¥Â•ΩÂú∞ÁêÜËß£‰ª£Á†ÅËØ≠Ê≥ïÔºåÂπ∂Âú®‰∏çÂêåÁöÑÁºñÁ®ãËØ≠Ë®Ä‰πãÈó¥Êû∂Ëµ∑Ê°•Ê¢Å„ÄÇCodeGRAG ÊòæÁùÄÊèêÈ´ò‰∫Ü LLM ÁöÑ‰ª£Á†ÅÁîüÊàêËÉΩÂäõÔºåÁîöËá≥ÂèØ‰ª•‰∏∫Ë∑®ËØ≠Ë®Ä‰ª£Á†ÅÁîüÊàêÊèê‰æõÊÄßËÉΩÊèêÂçáÔºå‰æãÂ¶ÇÔºåC++ Áî®‰∫é Python„ÄÇ

##### **ALCM: Autonomous LLM-Augmented Causal Discovery Framework**
2405.01744v1 by Elahe Khatibi, Mahyar Abbasian, Zhongqi Yang, Iman Azimi, Amir M. Rahmani

To perform effective causal inference in high-dimensional datasets,
initiating the process with causal discovery is imperative, wherein a causal
graph is generated based on observational data. However, obtaining a complete
and accurate causal graph poses a formidable challenge, recognized as an
NP-hard problem. Recently, the advent of Large Language Models (LLMs) has
ushered in a new era, indicating their emergent capabilities and widespread
applicability in facilitating causal reasoning across diverse domains, such as
medicine, finance, and science. The expansive knowledge base of LLMs holds the
potential to elevate the field of causal reasoning by offering
interpretability, making inferences, generalizability, and uncovering novel
causal structures. In this paper, we introduce a new framework, named
Autonomous LLM-Augmented Causal Discovery Framework (ALCM), to synergize
data-driven causal discovery algorithms and LLMs, automating the generation of
a more resilient, accurate, and explicable causal graph. The ALCM consists of
three integral components: causal structure learning, causal wrapper, and
LLM-driven causal refiner. These components autonomously collaborate within a
dynamic environment to address causal discovery questions and deliver plausible
causal graphs. We evaluate the ALCM framework by implementing two
demonstrations on seven well-known datasets. Experimental results demonstrate
that ALCM outperforms existing LLM methods and conventional data-driven causal
reasoning mechanisms. This study not only shows the effectiveness of the ALCM
but also underscores new research directions in leveraging the causal reasoning
capabilities of LLMs.

ÊëòË¶ÅÔºö<paragraph>ÁÇ∫‰∫ÜÂú®È´òÁ∂≠Â∫¶Ë≥áÊñôÈõÜ‰∏≠Âü∑Ë°åÊúâÊïàÁöÑÂõ†ÊûúÊé®Ë´ñÔºå‰ª•Âõ†ÊûúÁôºÁèæÂïüÂãïÊµÅÁ®ãËá≥ÈóúÈáçË¶ÅÔºåÂÖ∂‰∏≠Âõ†ÊûúÂúñË°®ÊòØÊ†πÊìöËßÄÂØüË≥áÊñôÁî¢ÁîüÁöÑ„ÄÇÁÑ∂ËÄåÔºåÂèñÂæóÂÆåÊï¥‰∏îÊ∫ñÁ¢∫ÁöÑÂõ†ÊûúÂúñË°®ÊòØ‰∏ÄÈ†ÖËâ±ÈâÖÁöÑÊåëÊà∞ÔºåË¢´Ë¶ñÁÇ∫ NP Èõ£ÂïèÈ°å„ÄÇÊúÄËøëÔºåÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÂá∫ÁèæÈñãÂïü‰∫Ü‰∏ÄÂÄãÊñ∞Á¥ÄÂÖÉÔºåÈ°ØÁ§∫Âá∫ÂÆÉÂÄëÂú®‰øÉÈÄ≤‰∏çÂêåÈ†òÂüüÔºà‰æãÂ¶ÇÈÜ´Â≠∏„ÄÅÈáëËûçÂíåÁßëÂ≠∏ÔºâÁöÑÂõ†ÊûúÊé®ÁêÜÊñπÈù¢ÁöÑÈ°ØËëóËÉΩÂäõÂíåÂª£Ê≥õÈÅ©Áî®ÊÄß„ÄÇLLM Âª£Ê≥õÁöÑÁü•Ë≠òÂ∫´ÊúâÊΩõÂäõÊèêÂçáÂõ†ÊûúÊé®ÁêÜÈ†òÂüüÔºåÊñπÊ≥ïÊòØÊèê‰æõÂèØËß£ÈáãÊÄß„ÄÅÈÄ≤Ë°åÊé®Ë´ñ„ÄÅÈÄöÁî®ÂåñÂíåÁôºÁèæÊñ∞ÁöÑÂõ†ÊûúÁµêÊßã„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫Ü‰∏ÄÂÄãÂêçÁÇ∫Ëá™ÈÅ©Êáâ LLM Â¢ûÂº∑Âõ†ÊûúÁôºÁèæÊ°ÜÊû∂ (ALCM) ÁöÑÊñ∞Ê°ÜÊû∂Ôºå‰ª•ÂçîÂêåË≥áÊñôÈ©ÖÂãïÁöÑÂõ†ÊûúÁôºÁèæÊºîÁÆóÊ≥ïÂíå LLMÔºåËá™ÂãïÁî¢ÁîüÊõ¥ÂÖ∑ÈüåÊÄß„ÄÅÊ∫ñÁ¢∫‰∏îÂèØËß£ÈáãÁöÑÂõ†ÊûúÂúñË°®„ÄÇALCM ÂåÖÂê´‰∏âÂÄãÊï¥ÂêàÂÖÉ‰ª∂ÔºöÂõ†ÊûúÁµêÊßãÂ≠∏Áøí„ÄÅÂõ†ÊûúÂåÖË£ùÂô®Âíå LLM È©ÖÂãïÁöÑÂõ†ÊûúÁ≤æÁÖâÂô®„ÄÇÈÄô‰∫õÂÖÉ‰ª∂Âú®ÂãïÊÖãÁí∞Â¢É‰∏≠Ëá™‰∏ªÂçî‰ΩúÔºå‰ª•Ëß£Ê±∫Âõ†ÊûúÁôºÁèæÂïèÈ°å‰∏¶Êèê‰æõÂêàÁêÜÁöÑÂõ†ÊûúÂúñË°®„ÄÇÊàëÂÄëÈÄèÈÅéÂú®‰∏ÉÂÄãÁü•ÂêçË≥áÊñôÈõÜ‰∏äÂü∑Ë°åÂÖ©ÂÄãÁ§∫ÁØÑ‰æÜË©ï‰º∞ ALCM Ê°ÜÊû∂„ÄÇÂØ¶È©óÁµêÊûúË≠âÊòé ALCM ÂÑ™ÊñºÁèæÊúâÁöÑ LLM ÊñπÊ≥ïÂíåÂÇ≥Áµ±ÁöÑË≥áÊñôÈ©ÖÂãïÂõ†ÊûúÊé®ÁêÜÊ©üÂà∂„ÄÇÈÄôÈ†ÖÁ†îÁ©∂‰∏çÂÉÖÈ°ØÁ§∫ ALCM ÁöÑÊúâÊïàÊÄßÔºå‰πüÂº∑Ë™ø‰∫ÜÂà©Áî® LLM Âõ†ÊûúÊé®ÁêÜËÉΩÂäõÁöÑÊñ∞Á†îÁ©∂ÊñπÂêë„ÄÇ</paragraph>

##### **Improving Complex Reasoning over Knowledge Graph with Logic-Aware Curriculum Tuning**
2405.01649v3 by Tianle Xia, Liang Ding, Guojia Wan, Yibing Zhan, Bo Du, Dacheng Tao

Answering complex queries over incomplete knowledge graphs (KGs) is a
challenging job. Most previous works have focused on learning entity/relation
embeddings and simulating first-order logic operators with various neural
networks. However, they are bottlenecked by the inability to share world
knowledge to improve logical reasoning, thus resulting in suboptimal
performance. In this paper, we propose a complex reasoning schema over KG upon
large language models (LLMs), containing a curriculum-based logical-aware
instruction tuning framework, named LACT. Specifically, we augment the
arbitrary first-order logical queries via binary tree decomposition, to
stimulate the reasoning capability of LLMs. To address the difficulty gap among
different types of complex queries, we design a simple and flexible logic-aware
curriculum learning framework. Experiments across widely used datasets
demonstrate that LACT has substantial improvements~(brings an average +5.5% MRR
score) over advanced methods, achieving the new state-of-the-art. Our code and
model will be released at GitHub and huggingface soon.

ÊëòË¶ÅÔºöÂõûÁ≠î‰∏çÂÆåÊï¥Áü•ËØÜÂõæË∞± (KG) ‰∏äÁöÑÂ§çÊùÇÊü•ËØ¢ÊòØ‰∏ÄÈ°πÂÖ∑ÊúâÊåëÊàòÊÄßÁöÑÂ∑•‰Ωú„ÄÇÂ§ßÂ§öÊï∞‰ª•ÂâçÁöÑ‰ΩúÂìÅÈÉΩ‰∏ìÊ≥®‰∫éÂ≠¶‰π†ÂÆû‰Ωì/ÂÖ≥Á≥ªÂµåÂÖ•ÔºåÂπ∂‰ΩøÁî®ÂêÑÁßçÁ•ûÁªèÁΩëÁªúÊ®°Êãü‰∏ÄÈò∂ÈÄªËæëËøêÁÆóÁ¨¶„ÄÇÁÑ∂ËÄåÔºåÂÆÉ‰ª¨Âõ†Êó†Ê≥ïÂÖ±‰∫´‰∏ñÁïåÁü•ËØÜÊù•ÊîπËøõÈÄªËæëÊé®ÁêÜËÄåÊàê‰∏∫Áì∂È¢àÔºå‰ªéËÄåÂØºËá¥Ê¨°‰ºòÊÄßËÉΩ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏Ä‰∏™Âü∫‰∫éÂ§ßËØ≠Ë®ÄÊ®°Âûã (LLM) ÁöÑ KG ‰∏äÁöÑÂ§çÊùÇÊé®ÁêÜÊ®°ÂºèÔºåÂÖ∂‰∏≠ÂåÖÂê´‰∏Ä‰∏™Âü∫‰∫éËØæÁ®ãÁöÑÈÄªËæëÊÑüÁü•Êåá‰ª§Ë∞ÉÊï¥Ê°ÜÊû∂ÔºåÂêç‰∏∫ LACT„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåÊàë‰ª¨ÈÄöËøá‰∫åÂèâÊ†ëÂàÜËß£Êù•Êâ©ÂÖÖ‰ªªÊÑè‰∏ÄÈò∂ÈÄªËæëÊü•ËØ¢Ôºå‰ª•ÊøÄÂèë LLM ÁöÑÊé®ÁêÜËÉΩÂäõ„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥‰∏çÂêåÁ±ªÂûãÂ§çÊùÇÊü•ËØ¢‰πãÈó¥ÁöÑÈöæÂ∫¶Â∑ÆÂºÇÔºåÊàë‰ª¨ËÆæËÆ°‰∫Ü‰∏Ä‰∏™ÁÆÄÂçï‰∏îÁÅµÊ¥ªÁöÑÈÄªËæëÊÑüÁü•ËØæÁ®ãÂ≠¶‰π†Ê°ÜÊû∂„ÄÇÂú®ÂπøÊ≥õ‰ΩøÁî®ÁöÑÊï∞ÊçÆÈõÜ‰∏äËøõË°åÁöÑÂÆûÈ™åË°®ÊòéÔºåLACT Âú®ÂÖàËøõÊñπÊ≥ï‰∏äÊúâ‰∫ÜÂÆûË¥®ÊÄßÁöÑÊîπËøõÔºàÂ∏¶Êù•‰∫ÜÂπ≥Âùá +5.5% ÁöÑ MRR ÂàÜÊï∞ÔºâÔºåËææÂà∞‰∫ÜÊñ∞ÁöÑÊúÄÂÖàËøõÊ∞¥Âπ≥„ÄÇÊàë‰ª¨ÁöÑ‰ª£Á†ÅÂíåÊ®°ÂûãÂ∞ÜÂæàÂø´Âú® GitHub Âíå huggingface ‰∏äÂèëÂ∏É„ÄÇ

##### **Identification of Entailment and Contradiction Relations between Natural Language Sentences: A Neurosymbolic Approach**
2405.01259v1 by Xuyao Feng, Anthony Hunter

Natural language inference (NLI), also known as Recognizing Textual
Entailment (RTE), is an important aspect of natural language understanding.
Most research now uses machine learning and deep learning to perform this task
on specific datasets, meaning their solution is not explainable nor explicit.
To address the need for an explainable approach to RTE, we propose a novel
pipeline that is based on translating text into an Abstract Meaning
Representation (AMR) graph. For this we use a pre-trained AMR parser. We then
translate the AMR graph into propositional logic and use a SAT solver for
automated reasoning. In text, often commonsense suggests that an entailment (or
contradiction) relationship holds between a premise and a claim, but because
different wordings are used, this is not identified from their logical
representations. To address this, we introduce relaxation methods to allow
replacement or forgetting of some propositions. Our experimental results show
this pipeline performs well on four RTE datasets.

ÊëòË¶ÅÔºöËá™ÁÑ∂Ë™ûË®ÄÊé®Ë´ñ (NLI)Ôºå‰πüÁ®±ÁÇ∫Ë≠òÂà•ÊñáÊú¨ËòäÊ∂µÈóú‰øÇ (RTE)ÔºåÊòØËá™ÁÑ∂Ë™ûË®ÄÁêÜËß£ÁöÑÈáçË¶ÅÈù¢Âêë„ÄÇ
ÁõÆÂâçÂ§ßÂ§öÊï∏ÁöÑÁ†îÁ©∂‰ΩøÁî®Ê©üÂô®Â≠∏ÁøíÂíåÊ∑±Â∫¶Â≠∏ÁøíÂú®ÁâπÂÆöË≥áÊñôÈõÜ‰∏äÂü∑Ë°åÈÄôÈ†Ö‰ªªÂãôÔºåÈÄôË°®Á§∫‰ªñÂÄëÁöÑËß£Ê±∫ÊñπÊ°àÁÑ°Ê≥ïËß£ÈáãÊàñÊòéÁ¢∫Ë™™Êòé„ÄÇ
ÁÇ∫‰∫ÜÊªøË∂≥ RTE ÂèØËß£ÈáãÊñπÊ≥ïÁöÑÈúÄÊ±ÇÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÊñ∞Á©éÁöÑÁÆ°ÈÅìÔºåÂÖ∂Âü∫Á§éÊòØÂ∞áÊñáÂ≠óËΩâÊèõÁÇ∫ÊäΩË±°ÊÑèÁæ©Ë°®Á§∫ (AMR) ÂúñË°®„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄë‰ΩøÁî®È†êÂÖàË®ìÁ∑¥Â•ΩÁöÑ AMR Ëß£ÊûêÂô®„ÄÇÊé•ËëóÔºåÊàëÂÄëÂ∞á AMR ÂúñË°®ËΩâÊèõÁÇ∫ÂëΩÈ°åÈÇèËºØÔºå‰∏¶‰ΩøÁî® SAT Ê±ÇËß£Âô®ÈÄ≤Ë°åËá™ÂãïÊé®ÁêÜ„ÄÇÂú®ÊñáÂ≠ó‰∏≠ÔºåÂ∏∏Ë≠òÈÄöÂ∏∏ÊúÉÊöóÁ§∫ÂâçÊèêÂíå‰∏ªÂºµ‰πãÈñìÂ≠òÂú®ËòäÊ∂µÔºàÊàñÁüõÁõæÔºâÈóú‰øÇÔºå‰ΩÜÁî±Êñº‰ΩøÁî®‰∫Ü‰∏çÂêåÁöÑÊé™Ëæ≠ÔºåÂõ†Ê≠§ÁÑ°Ê≥ïÂæûÂÖ∂ÈÇèËºØË°®Á§∫‰∏≠Ëæ®Ë≠òÂá∫‰æÜ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÂºïÈÄ≤ÊîæÈ¨ÜÊñπÊ≥ïÔºåÂÖÅË®±ÊõøÊèõÊàñÈÅ∫ÂøòÊüê‰∫õÂëΩÈ°å„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÁµêÊûúÈ°ØÁ§∫ÔºåÈÄôÂÄãÁÆ°ÈÅìÂú®ÂõõÂÄã RTE Ë≥áÊñôÈõÜ‰∏äË°®ÁèæËâØÂ•Ω„ÄÇ

##### **RAG-based Explainable Prediction of Road Users Behaviors for Automated Driving using Knowledge Graphs and Large Language Models**
2405.00449v1 by Mohamed Manzour Hussien, Angie Nataly Melo, Augusto Luis Ballardini, Carlota Salinas Maldonado, Rub√©n Izquierdo, Miguel √Ångel Sotelo

Prediction of road users' behaviors in the context of autonomous driving has
gained considerable attention by the scientific community in the last years.
Most works focus on predicting behaviors based on kinematic information alone,
a simplification of the reality since road users are humans, and as such they
are highly influenced by their surrounding context. In addition, a large
plethora of research works rely on powerful Deep Learning techniques, which
exhibit high performance metrics in prediction tasks but may lack the ability
to fully understand and exploit the contextual semantic information contained
in the road scene, not to mention their inability to provide explainable
predictions that can be understood by humans. In this work, we propose an
explainable road users' behavior prediction system that integrates the
reasoning abilities of Knowledge Graphs (KG) and the expressiveness
capabilities of Large Language Models (LLM) by using Retrieval Augmented
Generation (RAG) techniques. For that purpose, Knowledge Graph Embeddings (KGE)
and Bayesian inference are combined to allow the deployment of a fully
inductive reasoning system that enables the issuing of predictions that rely on
legacy information contained in the graph as well as on current evidence
gathered in real time by onboard sensors. Two use cases have been implemented
following the proposed approach: 1) Prediction of pedestrians' crossing
actions; 2) Prediction of lane change maneuvers. In both cases, the performance
attained surpasses the current state of the art in terms of anticipation and
F1-score, showing a promising avenue for future research in this field.

ÊëòË¶ÅÔºöÂú®Ëá™Âä®È©æÈ©∂ËÉåÊôØ‰∏ãÈ¢ÑÊµãÈÅìË∑Ø‰ΩøÁî®ËÄÖË°å‰∏∫ËøëÂπ¥Êù•Â∑≤Ëé∑ÂæóÁßëÂ≠¶ÁïåÁöÑÂπøÊ≥õÂÖ≥Ê≥®„ÄÇÂ§ßÂ§öÊï∞Á†îÁ©∂‰∏ìÊ≥®‰∫é‰ªÖÂü∫‰∫éËøêÂä®Â≠¶‰ø°ÊÅØÊù•È¢ÑÊµãË°å‰∏∫ÔºåËøôÊòØÂØπÁé∞ÂÆûÁöÑÁÆÄÂåñÔºåÂõ†‰∏∫ÈÅìË∑Ø‰ΩøÁî®ËÄÖÊòØ‰∫∫Á±ªÔºåÂõ†Ê≠§‰ªñ‰ª¨‰ºöÂèóÂà∞Âë®Âõ¥ÁéØÂ¢ÉÁöÑÊûÅÂ§ßÂΩ±Âìç„ÄÇÊ≠§Â§ñÔºåÂ§ßÈáèÁ†îÁ©∂Â∑•‰Ωú‰æùËµñ‰∫éÂº∫Â§ßÁöÑÊ∑±Â∫¶Â≠¶‰π†ÊäÄÊúØÔºåËøô‰∫õÊäÄÊúØÂú®È¢ÑÊµã‰ªªÂä°‰∏≠Ë°®Áé∞Âá∫ÂæàÈ´òÁöÑÊÄßËÉΩÊåáÊ†áÔºå‰ΩÜÂèØËÉΩÁº∫‰πèÂÖÖÂàÜÁêÜËß£ÂíåÂà©Áî®ÈÅìË∑ØÂú∫ÊôØ‰∏≠ÂåÖÂê´ÁöÑ‰∏ä‰∏ãÊñáËØ≠‰πâ‰ø°ÊÅØÁöÑËÉΩÂäõÔºåÊõ¥‰∏çÁî®ËØ¥ÂÆÉ‰ª¨Êó†Ê≥ïÊèê‰æõ‰∫∫Á±ªÂèØ‰ª•ÁêÜËß£ÁöÑÂèØËß£ÈáäÈ¢ÑÊµãÁöÑËÉΩÂäõ„ÄÇÂú®ËøôÈ°πÂ∑•‰Ωú‰∏≠ÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçÂèØËß£ÈáäÁöÑÈÅìË∑Ø‰ΩøÁî®ËÄÖË°å‰∏∫È¢ÑÊµãÁ≥ªÁªüÔºåËØ•Á≥ªÁªüÈÄöËøá‰ΩøÁî®Ê£ÄÁ¥¢Â¢ûÂº∫ÁîüÊàê (RAG) ÊäÄÊúØÈõÜÊàê‰∫ÜÁü•ËØÜÂõæË∞± (KG) ÁöÑÊé®ÁêÜËÉΩÂäõÂíåÂ§ßÂûãËØ≠Ë®ÄÊ®°Âûã (LLM) ÁöÑË°®ËææËÉΩÂäõ„ÄÇ‰∏∫Ê≠§ÔºåÂ∞ÜÁü•ËØÜÂõæË∞±ÂµåÂÖ• (KGE) ÂíåË¥ùÂè∂ÊñØÊé®ÁêÜÁõ∏ÁªìÂêàÔºå‰ª•ÂÖÅËÆ∏ÈÉ®ÁΩ≤‰∏Ä‰∏™ÂÆåÂÖ®ÂΩíÁ∫≥Êé®ÁêÜÁ≥ªÁªüÔºåËØ•Á≥ªÁªüËÉΩÂ§üÂèëÂá∫‰æùËµñ‰∫éÂõæ‰∏≠ÂåÖÂê´ÁöÑ‰º†Áªü‰ø°ÊÅØ‰ª•ÂèäËΩ¶ËΩΩ‰º†ÊÑüÂô®ÂÆûÊó∂Êî∂ÈõÜÁöÑÂΩìÂâçËØÅÊçÆÁöÑÈ¢ÑÊµã„ÄÇÂ∑≤ÁªèÊåâÁÖßÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÂÆûÁé∞‰∫Ü‰∏§‰∏™Áî®‰æãÔºö1ÔºâÈ¢ÑÊµãË°å‰∫∫ÁöÑËøáÈ©¨Ë∑ØÂä®‰ΩúÔºõ2ÔºâÈ¢ÑÊµãÂèòÈÅìÂä®‰Ωú„ÄÇÂú®Ëøô‰∏§ÁßçÊÉÖÂÜµ‰∏ãÔºåÊâÄËææÂà∞ÁöÑÊÄßËÉΩÂú®È¢ÑÊúüÂíå F1 ÂàÜÊï∞ÊñπÈù¢ÈÉΩË∂ÖËøá‰∫ÜÂΩìÂâçÁöÑÊúÄÊñ∞Ê∞¥Âπ≥Ôºå‰∏∫ËØ•È¢ÜÂüüÁöÑÊú™Êù•Á†îÁ©∂Â±ïÁ§∫‰∫Ü‰∏ÄÊù°ÊúâÂâçÈÄîÁöÑÈÄîÂæÑ„ÄÇ

##### **Graph Neural Network Approach to Semantic Type Detection in Tables**
2405.00123v1 by Ehsan Hoseinzade, Ke Wang

This study addresses the challenge of detecting semantic column types in
relational tables, a key task in many real-world applications. While language
models like BERT have improved prediction accuracy, their token input
constraints limit the simultaneous processing of intra-table and inter-table
information. We propose a novel approach using Graph Neural Networks (GNNs) to
model intra-table dependencies, allowing language models to focus on
inter-table information. Our proposed method not only outperforms existing
state-of-the-art algorithms but also offers novel insights into the utility and
functionality of various GNN types for semantic type detection. The code is
available at https://github.com/hoseinzadeehsan/GAIT

ÊëòË¶ÅÔºöÊú¨Á†îÁ©∂Ëß£ÂÜ≥‰∫ÜÂú®ÂÖ≥Á≥ªË°®‰∏≠Ê£ÄÊµãËØ≠‰πâÂàóÁ±ªÂûãÁöÑÊåëÊàòÔºåËøôÊòØËÆ∏Â§öÂÆûÈôÖÂ∫îÁî®‰∏≠ÁöÑÂÖ≥ÈîÆ‰ªªÂä°„ÄÇËôΩÁÑ∂ÂÉè BERT ËøôÊ†∑ÁöÑËØ≠Ë®ÄÊ®°ÂûãÊèêÈ´ò‰∫ÜÈ¢ÑÊµãÂáÜÁ°ÆÊÄßÔºå‰ΩÜÂÆÉ‰ª¨ÁöÑÊ†áËÆ∞ËæìÂÖ•ÈôêÂà∂‰∫ÜÂØπË°®ÂÜÖÂíåË°®Èó¥‰ø°ÊÅØÁöÑÂêåÊ≠•Â§ÑÁêÜ„ÄÇÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßç‰ΩøÁî®ÂõæÁ•ûÁªèÁΩëÁªú (GNN) ÁöÑÊñ∞ÊñπÊ≥ïÊù•Âª∫Ê®°Ë°®ÂÜÖ‰æùËµñÂÖ≥Á≥ªÔºå‰ªéËÄåÂÖÅËÆ∏ËØ≠Ë®ÄÊ®°Âûã‰∏ìÊ≥®‰∫éË°®Èó¥‰ø°ÊÅØ„ÄÇÊàë‰ª¨ÊèêÂá∫ÁöÑÊñπÊ≥ï‰∏ç‰ªÖ‰ºò‰∫éÁé∞ÊúâÁöÑÊúÄÂÖàËøõÁÆóÊ≥ïÔºåËøò‰∏∫ËØ≠‰πâÁ±ªÂûãÊ£ÄÊµãÊèê‰æõÂêÑÁßç GNN Á±ªÂûãÁöÑÂÆûÁî®ÊÄßÂíåÂäüËÉΩÁöÑÊñ∞ËßÅËß£„ÄÇ‰ª£Á†ÅÂèØÂú® https://github.com/hoseinzadeehsan/GAIT Ëé∑Âæó

##### **PrivComp-KG : Leveraging Knowledge Graph and Large Language Models for Privacy Policy Compliance Verification**
2404.19744v1 by Leon Garza, Lavanya Elluri, Anantaa Kotal, Aritran Piplai, Deepti Gupta, Anupam Joshi

Data protection and privacy is becoming increasingly crucial in the digital
era. Numerous companies depend on third-party vendors and service providers to
carry out critical functions within their operations, encompassing tasks such
as data handling and storage. However, this reliance introduces potential
vulnerabilities, as these vendors' security measures and practices may not
always align with the standards expected by regulatory bodies. Businesses are
required, often under the penalty of law, to ensure compliance with the
evolving regulatory rules. Interpreting and implementing these regulations pose
challenges due to their complexity. Regulatory documents are extensive,
demanding significant effort for interpretation, while vendor-drafted privacy
policies often lack the detail required for full legal compliance, leading to
ambiguity. To ensure a concise interpretation of the regulatory requirements
and compliance of organizational privacy policy with said regulations, we
propose a Large Language Model (LLM) and Semantic Web based approach for
privacy compliance. In this paper, we develop the novel Privacy Policy
Compliance Verification Knowledge Graph, PrivComp-KG. It is designed to
efficiently store and retrieve comprehensive information concerning privacy
policies, regulatory frameworks, and domain-specific knowledge pertaining to
the legal landscape of privacy. Using Retrieval Augmented Generation, we
identify the relevant sections in a privacy policy with corresponding
regulatory rules. This information about individual privacy policies is
populated into the PrivComp-KG. Combining this with the domain context and
rules, the PrivComp-KG can be queried to check for compliance with privacy
policies by each vendor against relevant policy regulations. We demonstrate the
relevance of the PrivComp-KG, by verifying compliance of privacy policy
documents for various organizations.

ÊëòË¶ÅÔºö<paragraph>Âú®Êï∏‰ΩçÊôÇ‰ª£ÔºåË≥áÊñô‰øùË≠∑ÂíåÈö±ÁßÅÊ≠£ËÆäÂæóË∂ä‰æÜË∂äÈáçË¶Å„ÄÇË®±Â§öÂÖ¨Âè∏‰æùË≥¥Á¨¨‰∏âÊñπ‰æõÊáâÂïÜÂíåÊúçÂãô‰æõÊáâÂïÜÔºå‰ª•Âü∑Ë°åÂÖ∂ÁáüÈÅã‰∏≠ÁöÑÈóúÈçµÂäüËÉΩÔºåÂåÖÊã¨Ë≥áÊñôËôïÁêÜÂíåÂÑ≤Â≠òÁ≠â‰ªªÂãô„ÄÇÁÑ∂ËÄåÔºåÈÄôÁ®Æ‰æùË≥¥ÊúÉÂºïÁôºÊΩõÂú®ÁöÑÊºèÊ¥ûÔºåÂõ†ÁÇ∫ÈÄô‰∫õ‰æõÊáâÂïÜÁöÑÂÆâÂÖ®Êé™ÊñΩÂíåÂÅöÊ≥ïÂèØËÉΩ‰∏¶‰∏çÁ∏ΩÊòØÁ¨¶ÂêàÊ≥ïË¶èÊ©üÈóúÈ†êÊúüÁöÑÊ®ôÊ∫ñ„ÄÇ‰ºÅÊ•≠ÊúâÁæ©ÂãôÔºàÈÄöÂ∏∏Âú®Ê≥ïÂæãÁöÑËôïÁΩ∞‰∏ãÔºâÁ¢∫‰øùÁ¨¶Âêà‰∏çÊñ∑ËÆäÂåñÁöÑÊ≥ïË¶èË¶èÂÆö„ÄÇÁî±ÊñºÊ≥ïË¶èÊñá‰ª∂Ë§áÈõúÔºåÂõ†Ê≠§Ëß£ÈáãÂíåÂØ¶ÊñΩÈÄô‰∫õÊ≥ïË¶èÊúÉÊßãÊàêÊåëÊà∞„ÄÇÊ≥ïË¶èÊñá‰ª∂ÂæàÂª£Ê≥õÔºåÈúÄË¶ÅÂ§ßÈáèÁöÑËß£ÈáãÂ∑•‰ΩúÔºåËÄå‰æõÊáâÂïÜËµ∑ËçâÁöÑÈö±ÁßÅÊîøÁ≠ñÈÄöÂ∏∏Áº∫‰πèÁ¨¶ÂêàÂÆåÂÖ®Ê≥ïÂæãË¶èÁØÑÊâÄÈúÄÁöÑÁ¥∞ÁØÄÔºåÂ∞éËá¥Ê®°Á®úÂÖ©ÂèØ„ÄÇÁÇ∫‰∫ÜÁ¢∫‰øùÂ∞çÊ≥ïË¶èË¶ÅÊ±ÇÁöÑÁ∞°ÊΩîËß£ÈáãÔºå‰ª•ÂèäÁµÑÁπîÈö±ÁßÅÊîøÁ≠ñÁ¨¶ÂêàÊ≥ïË¶èÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂü∫ÊñºÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂíåË™ûÁæ©Á∂≤Ë∑ØÁöÑÊñπÊ≥ïÔºåÁî®ÊñºÈö±ÁßÅÂêàË¶è„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÈñãÁôº‰∫ÜÊñ∞Á©éÁöÑÈö±ÁßÅÊîøÁ≠ñÂêàË¶èÈ©óË≠âÁü•Ë≠òÂúñË≠ú PrivComp-KG„ÄÇÂÆÉÊó®Âú®ÊúâÊïàÂÑ≤Â≠òÂíåÊ™¢Á¥¢ÊúâÈóúÈö±ÁßÅÊîøÁ≠ñ„ÄÅÊ≥ïË¶èÊû∂ÊßãÂíåËàáÈö±ÁßÅÊ≥ïÂæãÁí∞Â¢ÉÁõ∏ÈóúÁöÑÁâπÂÆöÈ†òÂüüÁü•Ë≠òÁöÑÁ∂úÂêàË≥áË®ä„ÄÇ‰ΩøÁî®Ê™¢Á¥¢Êì¥ÂÖÖÁî¢ÁîüÔºåÊàëÂÄë‰ΩøÁî®Â∞çÊáâÁöÑÊ≥ïË¶èË¶èÂâá‰æÜË≠òÂà•Èö±ÁßÅÊîøÁ≠ñ‰∏≠ÁöÑÁõ∏ÈóúÈÉ®ÂàÜ„ÄÇÊúâÈóúÂÄãÂà•Èö±ÁßÅÊîøÁ≠ñÁöÑÈÄô‰∫õË≥áË®äÊúÉÂ°´ÂÖ• PrivComp-KG„ÄÇÂ∞áÊ≠§ËàáÁ∂≤ÂüüÂÖßÂÆπÂíåË¶èÂâáÁµêÂêàÂæåÔºåÂèØ‰ª•Â∞ç PrivComp-KG ÈÄ≤Ë°åÊü•Ë©¢Ôºå‰ª•Ê™¢Êü•ÊØèÂÄã‰æõÊáâÂïÜÁöÑÈö±ÁßÅÊîøÁ≠ñÊòØÂê¶Á¨¶ÂêàÁõ∏ÈóúÊîøÁ≠ñÊ≥ïË¶è„ÄÇÊàëÂÄëÈÄèÈÅéÈ©óË≠âÂêÑÁ®ÆÁµÑÁπîÁöÑÈö±ÁßÅÊîøÁ≠ñÊñá‰ª∂Ôºå‰æÜË≠âÊòé PrivComp-KG ÁöÑÁõ∏ÈóúÊÄß„ÄÇ</paragraph>

##### **A Framework for Leveraging Human Computation Gaming to Enhance Knowledge Graphs for Accuracy Critical Generative AI Applications**
2404.19729v1 by Steph Buongiorno, Corey Clark

External knowledge graphs (KGs) can be used to augment large language models
(LLMs), while simultaneously providing an explainable knowledge base of facts
that can be inspected by a human. This approach may be particularly valuable in
domains where explainability is critical, like human trafficking data analysis.
However, creating KGs can pose challenges. KGs parsed from documents may
comprise explicit connections (those directly stated by a document) but miss
implicit connections (those obvious to a human although not directly stated).
To address these challenges, this preliminary research introduces the GAME-KG
framework, standing for "Gaming for Augmenting Metadata and Enhancing Knowledge
Graphs." GAME-KG is a federated approach to modifying explicit as well as
implicit connections in KGs by using crowdsourced feedback collected through
video games. GAME-KG is shown through two demonstrations: a Unity test scenario
from Dark Shadows, a video game that collects feedback on KGs parsed from US
Department of Justice (DOJ) Press Releases on human trafficking, and a
following experiment where OpenAI's GPT-4 is prompted to answer questions based
on a modified and unmodified KG. Initial results suggest that GAME-KG can be an
effective framework for enhancing KGs, while simultaneously providing an
explainable set of structured facts verified by humans.

ÊëòË¶ÅÔºöÂ§ñÈÉ®Áü•Ë≠òÂúñË≠ú (KG) ÂèØÁî®ÊñºÊì¥ÂÖÖÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM)ÔºåÂêåÊôÇÊèê‰æõ‰∫∫È°ûÂèØ‰ª•Ê™¢Ë¶ñÁöÑ‰∫ãÂØ¶ÂèØËß£ÈáãÁü•Ë≠òÂ∫´„ÄÇÈÄôÁ®ÆÊñπÊ≥ïÂú®ÂèØËß£ÈáãÊÄßËá≥ÈóúÈáçË¶ÅÁöÑÈ†òÂüü‰∏≠ÁâπÂà•ÊúâÂÉπÂÄºÔºå‰æãÂ¶Ç‰∫∫Âè£Ë≤©ÈÅãË≥áÊñôÂàÜÊûê„ÄÇÁÑ∂ËÄåÔºåÂª∫Á´ã KG ÂèØËÉΩÊúÉÂ∏∂‰æÜÊåëÊà∞„ÄÇÂæûÊñá‰ª∂‰∏≠Ëß£ÊûêÁöÑ KG ÂèØËÉΩÂåÖÂê´ÊòéÁ¢∫ÁöÑÈÄ£Êé•ÔºàÊñá‰ª∂‰∏≠Áõ¥Êé•Èô≥Ëø∞ÁöÑÈÄ£Êé•ÔºâÔºå‰ΩÜÊúÉÈÅ∫ÊºèÈö±Âê´ÁöÑÈÄ£Êé•ÔºàÂ∞ç‰∫∫È°û‰æÜË™™ÂæàÊòéÈ°ØÔºå‰ΩÜ‰∏¶Êú™Áõ¥Êé•Èô≥Ëø∞Ôºâ„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÔºåÈÄôÈ†ÖÂàùÊ≠•Á†îÁ©∂ÂºïÂÖ•‰∫Ü GAME-KG Êû∂ÊßãÔºå‰ª£Ë°®„ÄåÈÄèÈÅéÈÅäÊà≤Êì¥ÂÖÖÂÖÉË≥áÊñô‰∏¶Â¢ûÂº∑Áü•Ë≠òÂúñË≠ú„Äç„ÄÇGAME-KG ÊòØ‰∏ÄÁ®ÆÈÄèÈÅé‰ΩøÁî®ÈÄèÈÅéÈõªÁé©ÈÅäÊà≤Êî∂ÈõÜÁöÑÂ§ñÂåÖÊÑèË¶ã‰æÜ‰øÆÊîπ KG ‰∏≠ÊòéÁ¢∫ÂíåÈö±Âê´ÈÄ£Êé•ÁöÑËÅØÂêàÊñπÊ≥ï„ÄÇGAME-KG ÈÄèÈÅéÂÖ©ÂÄãÁ§∫ÁØÑË™™ÊòéÔºö‰∏ÄÂÄã‰æÜËá™ÈªëÊöóÈô∞ÂΩ±ÁöÑ Unity Ê∏¨Ë©¶Â†¥ÊôØÔºåÈÄôÊòØ‰∏ÄÊ¨æÊî∂ÈõÜÁæéÂúãÂè∏Ê≥ïÈÉ® (DOJ) ‰∫∫Âè£Ë≤©ÈÅãÊñ∞ËÅûÁ®ø‰∏≠Ëß£ÊûêÁöÑ KG ÂõûÈ•ãÁöÑÈõªÁé©ÈÅäÊà≤Ôºå‰ª•ÂèäÂæåÁ∫åÁöÑÂØ¶È©óÔºåÂÖ∂‰∏≠ÊèêÁ§∫ OpenAI ÁöÑ GPT-4 Ê†πÊìöÂ∑≤‰øÆÊîπÂíåÊú™‰øÆÊîπÁöÑ KG ÂõûÁ≠îÂïèÈ°å„ÄÇÂàùÊ≠•ÁµêÊûúË°®ÊòéÔºåGAME-KG ÂèØ‰ª•ÊàêÁÇ∫Â¢ûÂº∑ KG ÁöÑÊúâÊïàÊû∂ÊßãÔºåÂêåÊôÇÊèê‰æõ‰∫∫È°ûÈ©óË≠âÁöÑÂèØËß£ÈáãÁµêÊßãÂåñ‰∫ãÂØ¶ÈõÜ„ÄÇ

##### **Octopus v4: Graph of language models**
2404.19296v1 by Wei Chen, Zhiyuan Li

Language models have been effective in a wide range of applications, yet the
most sophisticated models are often proprietary. For example, GPT-4 by OpenAI
and various models by Anthropic are expensive and consume substantial energy.
In contrast, the open-source community has produced competitive models, like
Llama3. Furthermore, niche-specific smaller language models, such as those
tailored for legal, medical or financial tasks, have outperformed their
proprietary counterparts. This paper introduces a novel approach that employs
\textit{functional tokens} to integrate \textbf{multiple open-source models},
each optimized for particular tasks. Our newly developed Octopus v4 model
leverages \textit{functional tokens} to intelligently direct user queries to
the most appropriate vertical model and reformat the query to achieve the best
performance. Octopus v4, an evolution of the Octopus v1, v2, and v3 models,
excels in selection and parameter understanding and reformatting. Additionally,
we explore the use of graph as a versatile data structure that effectively
coordinates multiple open-source models by harnessing the capabilities of the
Octopus model and \textit{functional tokens}. Use our open-sourced GitHub
(\url{https://www.nexa4ai.com/}) to try Octopus v4 models
(\url{https://huggingface.co/NexaAIDev/Octopus-v4}), and contrite to a larger
graph of language models. By activating models less than 10B parameters, we
achieved SOTA MMLU score of 74.8 among the same level models.

ÊëòË¶ÅÔºöË™ûË®ÄÊ®°ÂûãÂú®Âª£Ê≥õÁöÑÊáâÁî®‰∏≠ÈùûÂ∏∏ÊúâÊïàÔºå‰ΩÜÊúÄÁ≤æÂØÜÁöÑÊ®°ÂûãÈÄöÂ∏∏ÊòØÂ∞àÊúâÁöÑ„ÄÇ‰æãÂ¶ÇÔºåOpenAI ÁöÑ GPT-4 Âíå Anthropic ÁöÑÂêÑÁ®ÆÊ®°ÂûãÂÉπÊ†ºÊòÇË≤¥‰∏îÊ∂àËÄóÂ§ßÈáèËÉΩÊ∫ê„ÄÇÁõ∏ÊØî‰πã‰∏ãÔºåÈñãÊ∫êÁ§æÁæ§Â∑≤Á∂ìÁî¢Âá∫ÂÖ∑ÊúâÁ´∂Áà≠ÂäõÁöÑÊ®°ÂûãÔºå‰æãÂ¶Ç Llama3„ÄÇÊ≠§Â§ñÔºåÈáùÂ∞çÁâπÂÆöÈ†òÂüüÁöÑÂ∞èÂûãË™ûË®ÄÊ®°ÂûãÔºå‰æãÂ¶ÇÁÇ∫Ê≥ïÂæã„ÄÅÈÜ´ÁôÇÊàñË≤°Âãô‰ªªÂãôÈáèË∫´ÊâìÈÄ†ÁöÑÊ®°ÂûãÔºåÂ∑≤Á∂ìË∂ÖË∂ä‰∫ÜÂÆÉÂÄëÁöÑÂ∞àÊúâÂ∞çÊáâÊ®°Âûã„ÄÇÊú¨Êñá‰ªãÁ¥π‰∏ÄÁ®ÆÊñ∞ÊñπÊ≥ïÔºåÂÆÉÊé°Áî®„ÄåÂäüËÉΩÊÄßÊ®ôË®ò„Äç‰æÜÊï¥Âêà„ÄåÂ§öÂÄãÈñãÊ∫êÊ®°Âûã„ÄçÔºåÊØèÂÄãÊ®°ÂûãÈÉΩÈáùÂ∞çÁâπÂÆö‰ªªÂãôÈÄ≤Ë°åÊúÄ‰Ω≥Âåñ„ÄÇÊàëÂÄëÊñ∞ÈñãÁôºÁöÑ Octopus v4 Ê®°ÂûãÂà©Áî®„ÄåÂäüËÉΩÊÄßÊ®ôË®ò„ÄçÂ∞á‰ΩøÁî®ËÄÖÊü•Ë©¢Êô∫ËÉΩÂ∞éÂêëÊúÄÂêàÈÅ©ÁöÑÂûÇÁõ¥Ê®°ÂûãÔºå‰∏¶ÈáçÊñ∞Ê†ºÂºèÂåñÊü•Ë©¢‰ª•ÈÅîÊàêÊúÄ‰Ω≥ÊïàËÉΩ„ÄÇOctopus v4 ÊòØ Octopus v1„ÄÅv2 Âíå v3 Ê®°ÂûãÁöÑÈÄ≤ÂåñÁâàÊú¨ÔºåÂú®ÈÅ∏Êìá„ÄÅÂèÉÊï∏ÁêÜËß£ÂíåÈáçÊñ∞Ê†ºÂºèÂåñÊñπÈù¢Ë°®ÁèæÂÑ™Áï∞„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊé¢Ë®éÂ∞áÂúñÂΩ¢Áî®‰ΩúÈÄöÁî®Ë≥áÊñôÁµêÊßãÔºåÂÆÉÈÄèÈÅéÂà©Áî® Octopus Ê®°ÂûãÂíå„ÄåÂäüËÉΩÊÄßÊ®ôË®ò„ÄçÁöÑËÉΩÂäõÔºåÊúâÊïàÂú∞ÂçîË™øÂ§öÂÄãÈñãÊ∫êÊ®°Âûã„ÄÇ‰ΩøÁî®ÊàëÂÄëÁöÑÈñãÊ∫ê GitHub (\url{https://www.nexa4ai.com/}) ‰æÜË©¶Áî® Octopus v4 Ê®°Âûã (\url{https://huggingface.co/NexaAIDev/Octopus-v4})Ôºå‰∏¶ÁÇ∫Êõ¥Â§ßÁöÑË™ûË®ÄÊ®°ÂûãÂúñÂΩ¢ÂÅöÂá∫Ë≤¢Áçª„ÄÇÈÄèÈÅéÂïüÁî®ÂèÉÊï∏Â∞èÊñº 10B ÁöÑÊ®°ÂûãÔºåÊàëÂÄëÂú®ÂêåÁ¥öÂà•Ê®°Âûã‰∏≠ÈÅîÂà∞‰∫Ü 74.8 ÁöÑ SOTA MMLU ÂàÜÊï∏„ÄÇ

##### **Multi-hop Question Answering over Knowledge Graphs using Large Language Models**
2404.19234v1 by Abir Chakraborty

Knowledge graphs (KGs) are large datasets with specific structures
representing large knowledge bases (KB) where each node represents a key entity
and relations amongst them are typed edges. Natural language queries formed to
extract information from a KB entail starting from specific nodes and reasoning
over multiple edges of the corresponding KG to arrive at the correct set of
answer nodes. Traditional approaches of question answering on KG are based on
(a) semantic parsing (SP), where a logical form (e.g., S-expression, SPARQL
query, etc.) is generated using node and edge embeddings and then reasoning
over these representations or tuning language models to generate the final
answer directly, or (b) information-retrieval based that works by extracting
entities and relations sequentially. In this work, we evaluate the capability
of (LLMs) to answer questions over KG that involve multiple hops. We show that
depending upon the size and nature of the KG we need different approaches to
extract and feed the relevant information to an LLM since every LLM comes with
a fixed context window. We evaluate our approach on six KGs with and without
the availability of example-specific sub-graphs and show that both the IR and
SP-based methods can be adopted by LLMs resulting in an extremely competitive
performance.

ÊëòË¶ÅÔºöÁü•Ë≠òÂúñË≠ú (KG) ÊòØÂÖ∑ÊúâÁâπÂÆöÁµêÊßãÁöÑÂ§ßÂûãË≥áÊñôÈõÜÔºåË°®Á§∫Â§ßÂûãÁü•Ë≠òÂ∫´ (KB)ÔºåÂÖ∂‰∏≠ÊØèÂÄãÁØÄÈªû‰ª£Ë°®‰∏ÄÂÄãÈóúÈçµÂØ¶È´îÔºåËÄåÂÆÉÂÄë‰πãÈñìÁöÑÈóú‰øÇÊòØËº∏ÂÖ•ÈÇäÁ∑£„ÄÇÂæûÁâπÂÆöÁØÄÈªûÈñãÂßã‰∏¶Êé®ÁêÜÂ∞çÊáâ KG ÁöÑÂ§öÂÄãÈÇäÁ∑£‰ª•Âà∞ÈÅîÊ≠£Á¢∫ÁöÑÁ≠îÊ°àÁØÄÈªûÈõÜÂêàÔºåÂΩ¢ÊàêÁî®ÊñºÂæû KB ‰∏≠ÊèêÂèñË≥áË®äÁöÑËá™ÁÑ∂Ë™ûË®ÄÊü•Ë©¢„ÄÇÂÇ≥Áµ±ÁöÑ KG ÂïèÁ≠îÊñπÊ≥ïÂü∫Êñº (a) Ë™ûÁæ©Ëß£Êûê (SP)ÔºåÂÖ∂‰∏≠‰ΩøÁî®ÁØÄÈªûÂíåÈÇäÁ∑£ÂµåÂÖ•Áî¢ÁîüÈÇèËºØÂΩ¢ÂºèÔºà‰æãÂ¶Ç S Ë°®ÈÅîÂºè„ÄÅSPARQL Êü•Ë©¢Á≠âÔºâÔºåÁÑ∂ÂæåÊé®ÁêÜÈÄô‰∫õË°®Á§∫ÊàñË™øÊï¥Ë™ûË®ÄÊ®°Âûã‰ª•Áõ¥Êé•Áî¢ÁîüÊúÄÁµÇÁ≠îÊ°àÔºåÊàñ (b) Âü∫ÊñºË≥áË®äÊ™¢Á¥¢ÔºåÂÖ∂ÈÄöÈÅéÊåâÈ†ÜÂ∫èÊèêÂèñÂØ¶È´îÂíåÈóú‰øÇ‰æÜÂ∑•‰Ωú„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëË©ï‰º∞‰∫Ü (LLM) ÂõûÁ≠îÊ∂âÂèäÂ§öË∑≥ÁöÑ KG ÂïèÈ°åÁöÑËÉΩÂäõ„ÄÇÊàëÂÄëË°®ÊòéÔºåÊ†πÊìö KG ÁöÑÂ§ßÂ∞èÂíåÊÄßË≥™ÔºåÊàëÂÄëÈúÄË¶Å‰∏çÂêåÁöÑÊñπÊ≥ï‰æÜÊèêÂèñÁõ∏ÈóúË≥áË®ä‰∏¶Â∞áÂÖ∂Êèê‰æõÁµ¶ LLMÔºåÂõ†ÁÇ∫ÊØèÂÄã LLM ÈÉΩÊúâ‰∏ÄÂÄãÂõ∫ÂÆöÁöÑ‰∏ä‰∏ãÊñáË¶ñÁ™ó„ÄÇÊàëÂÄëÂú®ÊúâÂíåÊ≤íÊúâÁØÑ‰æãÁâπÂÆöÂ≠êÂúñÁöÑÊÉÖÊ≥Å‰∏ãÂ∞çÂÖ≠ÂÄã KG Ë©ï‰º∞‰∫ÜÊàëÂÄëÁöÑÊñπÊ≥ïÔºå‰∏¶Ë°®Êòé IR ÂíåÂü∫Êñº SP ÁöÑÊñπÊ≥ïÈÉΩÂèØ‰ª•Ë¢´ LLM Êé°Áî®ÔºåÂæûËÄåÁî¢ÁîüÊ•µÂÖ∑Á´∂Áà≠ÂäõÁöÑÊïàËÉΩ„ÄÇ

##### **Automated Construction of Theme-specific Knowledge Graphs**
2404.19146v1 by Linyi Ding, Sizhe Zhou, Jinfeng Xiao, Jiawei Han

Despite widespread applications of knowledge graphs (KGs) in various tasks
such as question answering and intelligent conversational systems, existing KGs
face two major challenges: information granularity and deficiency in
timeliness. These hinder considerably the retrieval and analysis of in-context,
fine-grained, and up-to-date knowledge from KGs, particularly in highly
specialized themes (e.g., specialized scientific research) and rapidly evolving
contexts (e.g., breaking news or disaster tracking). To tackle such challenges,
we propose a theme-specific knowledge graph (i.e., ThemeKG), a KG constructed
from a theme-specific corpus, and design an unsupervised framework for ThemeKG
construction (named TKGCon). The framework takes raw theme-specific corpus and
generates a high-quality KG that includes salient entities and relations under
the theme. Specifically, we start with an entity ontology of the theme from
Wikipedia, based on which we then generate candidate relations by Large
Language Models (LLMs) to construct a relation ontology. To parse the documents
from the theme corpus, we first map the extracted entity pairs to the ontology
and retrieve the candidate relations. Finally, we incorporate the context and
ontology to consolidate the relations for entity pairs. We observe that
directly prompting GPT-4 for theme-specific KG leads to inaccurate entities
(such as "two main types" as one entity in the query result) and unclear (such
as "is", "has") or wrong relations (such as "have due to", "to start"). In
contrast, by constructing the theme-specific KG step by step, our model
outperforms GPT-4 and could consistently identify accurate entities and
relations. Experimental results also show that our framework excels in
evaluations compared with various KG construction baselines.

ÊëòË¶ÅÔºöÂÑòÁÆ°Áü•Ë≠òÂúñË≠ú (KG) Âª£Ê≥õÊáâÁî®ÊñºÂêÑÁ®Æ‰ªªÂãôÔºå‰æãÂ¶ÇÂïèÁ≠îÂíåÊô∫ÊÖßÂ∞çË©±Á≥ªÁµ±ÔºåÁèæÊúâÁöÑ KG ‰ªçÈù¢Ëá®ÂÖ©È†ÖÈáçÂ§ßÊåëÊà∞ÔºöË≥áË®äÁ≤íÂ∫¶ÂíåÂç≥ÊôÇÊÄß‰∏çË∂≥„ÄÇÈÄô‰∫õÂïèÈ°åÂö¥ÈáçÈòªÁ§ô‰∫ÜÂæû KG ‰∏≠Êì∑ÂèñÂíåÂàÜÊûêÊÉÖÂ¢É‰∏≠ÁöÑ„ÄÅÁ¥∞Á≤íÂ∫¶ÁöÑÂíåÊúÄÊñ∞ÁöÑÁü•Ë≠òÔºåÁâπÂà•ÊòØÂú®È´òÂ∫¶Â∞àÊ•≠ÁöÑ‰∏ªÈ°åÔºà‰æãÂ¶ÇÔºåÂ∞àÊ•≠ÁßëÂ≠∏Á†îÁ©∂ÔºâÂíåÂø´ÈÄüËÆäÂåñÁöÑÊÉÖÂ¢ÉÔºà‰æãÂ¶ÇÔºåÁ™ÅÁôºÊñ∞ËÅûÊàñÁÅΩÈõ£ËøΩËπ§Ôºâ‰∏≠„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄã‰∏ªÈ°åÁâπÂÆöÁü•Ë≠òÂúñË≠úÔºà‰∫¶Âç≥ ThemeKGÔºâÔºå‰∏ÄÂÄãÁî±‰∏ªÈ°åÁâπÂÆöË™ûÊñôÂ∫´Âª∫ÊßãÁöÑ KGÔºå‰∏¶Ë®≠Ë®à‰∫Ü‰∏ÄÂÄãÈùûÁõ£Áù£ÂºèÊ°ÜÊû∂ TKGConÔºåÁî®ÊñºÂª∫Êßã ThemeKG„ÄÇÊ≠§Ê°ÜÊû∂Êé°Áî®ÂéüÂßãÁöÑ‰∏ªÈ°åÁâπÂÆöË™ûÊñôÂ∫´Ôºå‰∏¶Áî¢Áîü‰∏ÄÂÄãÈ´òÂìÅË≥™ÁöÑ KGÔºåÂÖ∂‰∏≠ÂåÖÂê´Ë©≤‰∏ªÈ°å‰∏ãÁöÑÈ°ØËëóÂØ¶È´îÂíåÈóú‰øÇ„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÂæûÁ∂≠Âü∫ÁôæÁßë‰∏≠ÊèêÂèñË©≤‰∏ªÈ°åÁöÑÂØ¶È´îÊú¨‰ΩìÔºåÁÑ∂ÂæåÊ†πÊìöË©≤Êú¨‰ΩìÔºåÊàëÂÄëÂÜçÁî±Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Áî¢ÁîüÂÄôÈÅ∏Èóú‰øÇÔºå‰ª•Âª∫ÊßãÈóú‰øÇÊú¨‰Ωì„ÄÇÁÇ∫‰∫ÜËß£Êûê‰∏ªÈ°åË™ûÊñôÂ∫´‰∏≠ÁöÑÊñá‰ª∂ÔºåÊàëÂÄëÈ¶ñÂÖàÂ∞áÊèêÂèñÁöÑÂØ¶È´îÂ∞çÊáâÂà∞Êú¨‰ΩìÔºå‰∏¶Êì∑ÂèñÂÄôÈÅ∏Èóú‰øÇ„ÄÇÊúÄÂæåÔºåÊàëÂÄëÁµêÂêàÊÉÖÂ¢ÉÂíåÊú¨‰ΩìÔºå‰ª•Âêà‰ΩµÂØ¶È´îÂ∞çÁöÑÈóú‰øÇ„ÄÇÊàëÂÄëËßÄÂØüÂà∞ÔºåÁõ¥Êé•ÊèêÁ§∫ GPT-4 Áî¢Áîü‰∏ªÈ°åÁâπÂÆö KG ÊúÉÂ∞éËá¥‰∏çÊ∫ñÁ¢∫ÁöÑÂØ¶È´îÔºà‰æãÂ¶ÇÔºåÊü•Ë©¢ÁµêÊûú‰∏≠Â∞á„ÄåÂÖ©ÂÄã‰∏ªË¶ÅÈ°ûÂûã„ÄçË¶ñÁÇ∫‰∏ÄÂÄãÂØ¶È´îÔºâÔºå‰ª•Âèä‰∏çÊòéÁ¢∫Ôºà‰æãÂ¶ÇÔºå„ÄåÊòØ„Äç„ÄÅ„ÄåÊúâ„ÄçÔºâÊàñÈåØË™§ÁöÑÈóú‰øÇÔºà‰æãÂ¶ÇÔºå„ÄåÊ≠∏Âõ†Êñº„Äç„ÄÅ„ÄåÈñãÂßã„ÄçÔºâ„ÄÇÁõ∏ÊØî‰πã‰∏ãÔºåÈÄèÈÅéÈÄêÊ≠•Âª∫Êßã‰∏ªÈ°åÁâπÂÆö KGÔºåÊàëÂÄëÁöÑÊ®°ÂûãÂÑ™Êñº GPT-4Ôºå‰∏¶ËÉΩÊåÅÁ∫åË≠òÂà•Ê∫ñÁ¢∫ÁöÑÂØ¶È´îÂíåÈóú‰øÇ„ÄÇÂØ¶È©óÁµêÊûú‰πüÈ°ØÁ§∫ÔºåËàáÂêÑÁ®Æ KG Âª∫ÊßãÂü∫Ê∫ñÁõ∏ÊØîÔºåÊàëÂÄëÁöÑÊ°ÜÊû∂Âú®Ë©ï‰º∞‰∏≠Ë°®ÁèæÂá∫Ëâ≤„ÄÇ

##### **QANA: LLM-based Question Generation and Network Analysis for Zero-shot Key Point Analysis and Beyond**
2404.18371v1 by Tomoki Fukuma, Koki Noda, Toshihide Ubukata Kousuke Hoso, Yoshiharu Ichikawa, Kyosuke Kambe, Yu Masubuch, Fujio Toriumi

The proliferation of social media has led to information overload and
increased interest in opinion mining. We propose "Question-Answering Network
Analysis" (QANA), a novel opinion mining framework that utilizes Large Language
Models (LLMs) to generate questions from users' comments, constructs a
bipartite graph based on the comments' answerability to the questions, and
applies centrality measures to examine the importance of opinions. We
investigate the impact of question generation styles, LLM selections, and the
choice of embedding model on the quality of the constructed QA networks by
comparing them with annotated Key Point Analysis datasets. QANA achieves
comparable performance to previous state-of-the-art supervised models in a
zero-shot manner for Key Point Matching task, also reducing the computational
cost from quadratic to linear. For Key Point Generation, questions with high
PageRank or degree centrality align well with manually annotated key points.
Notably, QANA enables analysts to assess the importance of key points from
various aspects according to their selection of centrality measure. QANA's
primary contribution lies in its flexibility to extract key points from a wide
range of perspectives, which enhances the quality and impartiality of opinion
mining.

ÊëòË¶ÅÔºöÁ§æ‰∫§Â™íÈ´îÁöÑËààËµ∑Â∞éËá¥Ë≥áË®äÈÅéËºâÔºå‰ª•ÂèäÂ∞çÊñºÊÑèË¶ãÊé¢ÂãòÁöÑËààË∂£Â¢ûÂä†„ÄÇÊàëÂÄëÊèêÂá∫„ÄåÂïèÁ≠îÁ∂≤Ë∑ØÂàÜÊûê„Äç(QANA)Ôºå‰∏ÄÂÄãÊñ∞Á©éÁöÑÊÑèË¶ãÊé¢ÂãòÊû∂ÊßãÔºåÂà©Áî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âæû‰ΩøÁî®ËÄÖÁöÑÁïôË®ÄÁî¢ÁîüÂïèÈ°åÔºåÊ†πÊìöÁïôË®ÄÂ∞çÂïèÈ°åÁöÑÂèØÂõûÁ≠îÊÄßÂª∫Êßã‰∏ÄÂÄã‰∫åÈÉ®ÂúñÔºå‰∏¶ÊáâÁî®‰∏≠ÂøÉÊÄßÊ∏¨Èáè‰æÜÊ™¢Ë¶ñÊÑèË¶ãÁöÑÈáçË¶ÅÊÄß„ÄÇÊàëÂÄëÈÄèÈÅéÂ∞áÂÆÉÂÄëËàáÊ®ôË®ªÈóúÈçµÈªûÂàÜÊûêË≥áÊñôÈõÜÈÄ≤Ë°åÊØîËºÉÔºå‰æÜÊé¢Ë®éÂïèÈ°åÁî¢ÁîüÈ¢®Ê†º„ÄÅLLM ÈÅ∏ÊìáÂíåÂµåÂÖ•Ê®°ÂûãÁöÑÈÅ∏ÊìáÂ∞çÂª∫ÊßãÁöÑÂïèÁ≠îÁ∂≤Ë∑ØÂìÅË≥™ÁöÑÂΩ±Èüø„ÄÇQANA Âú®ÈóúÈçµÈªûÈÖçÂ∞ç‰ªªÂãô‰∏≠‰ª•Èõ∂Ê¨°Â≠∏ÁøíÁöÑÊñπÂºèÔºåÈÅîÊàêËàáÂÖàÂâçÊúÄÂÖàÈÄ≤ÁöÑÁõ£Áù£ÂºèÊ®°ÂûãÁõ∏Áï∂ÁöÑÊïàËÉΩÔºåÂêåÊôÇÂ∞áÈÅãÁÆóÊàêÊú¨Âæû‰∫åÊ¨°ÊñπÈôç‰ΩéÂà∞‰∏ÄÊ¨°Êñπ„ÄÇÂ∞çÊñºÈóúÈçµÈªûÁî¢ÁîüÔºåÂÖ∑ÊúâÈ´ò PageRank ÊàñÂ∫¶‰∏≠ÂøÉÊÄßÁöÑÂïèÈ°åËàáÊâãÂãïÊ®ôË®ªÁöÑÈóúÈçµÈªûÈùûÂ∏∏ÂêªÂêà„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåQANA ËÉΩËÆìÂàÜÊûêÂ∏´Ê†πÊìö‰ªñÂÄëÈÅ∏ÊìáÁöÑ‰∏≠ÂøÉÊÄßÊ∏¨ÈáèÔºåÂæûÂêÑÁ®ÆÈù¢ÂêëË©ï‰º∞ÈóúÈçµÈªûÁöÑÈáçË¶ÅÊÄß„ÄÇQANA ÁöÑ‰∏ªË¶ÅË≤¢ÁçªÂú®ÊñºÂÆÉÂæûÂª£Ê≥õÁöÑËßÄÈªû‰∏≠Êì∑ÂèñÈóúÈçµÈªûÁöÑÈùàÊ¥ªÊÄßÔºåÈÄôÊèêÂçá‰∫ÜÊÑèË¶ãÊé¢ÂãòÁöÑÂìÅË≥™ÂíåÂÖ¨Ê≠£ÊÄß„ÄÇ

##### **Parameter-Efficient Tuning Large Language Models for Graph Representation Learning**
2404.18271v1 by Qi Zhu, Da Zheng, Xiang Song, Shichang Zhang, Bowen Jin, Yizhou Sun, George Karypis

Text-rich graphs, which exhibit rich textual information on nodes and edges,
are prevalent across a wide range of real-world business applications. Large
Language Models (LLMs) have demonstrated remarkable abilities in understanding
text, which also introduced the potential for more expressive modeling in
text-rich graphs. Despite these capabilities, efficiently applying LLMs to
representation learning on graphs presents significant challenges. Recently,
parameter-efficient fine-tuning methods for LLMs have enabled efficient new
task generalization with minimal time and memory consumption. Inspired by this,
we introduce Graph-aware Parameter-Efficient Fine-Tuning - GPEFT, a novel
approach for efficient graph representation learning with LLMs on text-rich
graphs. Specifically, we utilize a graph neural network (GNN) to encode
structural information from neighboring nodes into a graph prompt. This prompt
is then inserted at the beginning of the text sequence. To improve the quality
of graph prompts, we pre-trained the GNN to assist the frozen LLM in predicting
the next token in the node text. Compared with existing joint GNN and LMs, our
method directly generate the node embeddings from large language models with an
affordable fine-tuning cost. We validate our approach through comprehensive
experiments conducted on 8 different text-rich graphs, observing an average
improvement of 2% in hit@1 and Mean Reciprocal Rank (MRR) in link prediction
evaluations. Our results demonstrate the efficacy and efficiency of our model,
showing that it can be smoothly integrated with various large language models,
including OPT, LLaMA and Falcon.

ÊëòË¶ÅÔºö<paragraph>ÊñáÊú¨‰∏∞ÂØåÁöÑÂõæË°®Âú®ÂπøÊ≥õÁöÑÂÆûÈôÖÂïÜ‰∏öÂ∫îÁî®‰∏≠ÊôÆÈÅçÂ≠òÂú®ÔºåÂÆÉ‰ª¨Âú®ËäÇÁÇπÂíåËæπ‰∏äÂ±ïÁ§∫‰∏∞ÂØåÁöÑÊñáÊú¨‰ø°ÊÅØ„ÄÇÂ§ßÂûãËØ≠Ë®ÄÊ®°Âûã (LLM) Â∑≤Âú®ÁêÜËß£ÊñáÊú¨ÊñπÈù¢Â±ïÁé∞Âá∫ÈùûÂá°ÁöÑËÉΩÂäõÔºåËøô‰πü‰∏∫Âú®ÊñáÊú¨‰∏∞ÂØåÁöÑÂõæË°®‰∏≠ËøõË°åÊõ¥ÂÖ∑Ë°®Áé∞ÂäõÁöÑÂª∫Ê®°Â∏¶Êù•‰∫ÜÂèØËÉΩÊÄß„ÄÇÂ∞ΩÁÆ°ÊúâËøô‰∫õËÉΩÂäõÔºå‰ΩÜÊúâÊïàÂú∞Â∞Ü LLM Â∫îÁî®‰∫éÂõæË°®‰∏äÁöÑË°®Á§∫Â≠¶‰π†‰ªçÁÑ∂Èù¢‰∏¥ÁùÄÈáçÂ§ßÊåëÊàò„ÄÇÊúÄËøëÔºåÈíàÂØπ LLM ÁöÑÂèÇÊï∞È´òÊïàÂæÆË∞ÉÊñπÊ≥ïÂ∑≤ÂÆûÁé∞È´òÊïàÁöÑÊñ∞‰ªªÂä°Ê≥õÂåñÔºå‰∏îÊó∂Èó¥ÂíåÂÜÖÂ≠òÊ∂àËÄóÊúÄÂ∞è„ÄÇÂèóÊ≠§ÂêØÂèëÔºåÊàë‰ª¨ÂºïÂÖ•‰∫ÜÂõæÊÑüÁü•ÂèÇÊï∞È´òÊïàÂæÆË∞É - GPEFTÔºå‰∏ÄÁßçÂú®ÊñáÊú¨‰∏∞ÂØåÁöÑÂõæË°®‰∏ä‰ΩøÁî® LLM ËøõË°åÈ´òÊïàÂõæË°®Á§∫Â≠¶‰π†ÁöÑÊñ∞ÊñπÊ≥ï„ÄÇÂÖ∑‰ΩìËÄåË®ÄÔºåÊàë‰ª¨Âà©Áî®ÂõæÁ•ûÁªèÁΩëÁªú (GNN) Â∞ÜÊù•Ëá™Áõ∏ÈÇªËäÇÁÇπÁöÑÁªìÊûÑ‰ø°ÊÅØÁºñÁ†ÅÂà∞ÂõæÊèêÁ§∫‰∏≠„ÄÇÁÑ∂ÂêéÂ∞ÜÊ≠§ÊèêÁ§∫ÊèíÂÖ•ÊñáÊú¨Â∫èÂàóÁöÑÂºÄÂ§¥„ÄÇ‰∏∫‰∫ÜÊèêÈ´òÂõæÊèêÁ§∫ÁöÑË¥®ÈáèÔºåÊàë‰ª¨È¢ÑËÆ≠ÁªÉ‰∫Ü GNN ‰ª•Â∏ÆÂä©ÂÜªÁªìÁöÑ LLM È¢ÑÊµãËäÇÁÇπÊñáÊú¨‰∏≠ÁöÑ‰∏ã‰∏Ä‰∏™Ê†áËÆ∞„ÄÇ‰∏éÁé∞ÊúâÁöÑËÅîÂêà GNN Âíå LM Áõ∏ÊØîÔºåÊàë‰ª¨ÁöÑÊñπÊ≥ïÁõ¥Êé•‰ªéÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÁîüÊàêËäÇÁÇπÂµåÂÖ•Ôºå‰∏îÂæÆË∞ÉÊàêÊú¨‰ΩéÂªâ„ÄÇÊàë‰ª¨ÈÄöËøáÂú® 8 ‰∏™‰∏çÂêåÁöÑÊñáÊú¨‰∏∞ÂØåÂõæË°®‰∏äËøõË°åÁöÑÁªºÂêàÂÆûÈ™åÈ™åËØÅ‰∫ÜÊàë‰ª¨ÁöÑÊñπÊ≥ïÔºåËßÇÂØüÂà∞Âú®ÈìæÊé•È¢ÑÊµãËØÑ‰º∞‰∏≠Ôºåhit@1 ÂíåÂπ≥ÂùáÂÄíÊï∞Áß© (MRR) Âπ≥ÂùáÊèêÈ´ò‰∫Ü 2%„ÄÇÊàë‰ª¨ÁöÑÁªìÊûúËØÅÊòé‰∫ÜÊàë‰ª¨Ê®°ÂûãÁöÑÊúâÊïàÊÄßÂíåÊïàÁéáÔºåË°®ÊòéÂÆÉÂèØ‰ª•‰∏éÂêÑÁßçÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàÂåÖÊã¨ OPT„ÄÅLLaMA Âíå FalconÔºâÂπ≥ÊªëÈõÜÊàê„ÄÇ</paragraph>

##### **Generative AI for Visualization: State of the Art and Future Directions**
2404.18144v1 by Yilin Ye, Jianing Hao, Yihan Hou, Zhan Wang, Shishi Xiao, Yuyu Luo, Wei Zeng

Generative AI (GenAI) has witnessed remarkable progress in recent years and
demonstrated impressive performance in various generation tasks in different
domains such as computer vision and computational design. Many researchers have
attempted to integrate GenAI into visualization framework, leveraging the
superior generative capacity for different operations. Concurrently, recent
major breakthroughs in GenAI like diffusion model and large language model have
also drastically increase the potential of GenAI4VIS. From a technical
perspective, this paper looks back on previous visualization studies leveraging
GenAI and discusses the challenges and opportunities for future research.
Specifically, we cover the applications of different types of GenAI methods
including sequence, tabular, spatial and graph generation techniques for
different tasks of visualization which we summarize into four major stages:
data enhancement, visual mapping generation, stylization and interaction. For
each specific visualization sub-task, we illustrate the typical data and
concrete GenAI algorithms, aiming to provide in-depth understanding of the
state-of-the-art GenAI4VIS techniques and their limitations. Furthermore, based
on the survey, we discuss three major aspects of challenges and research
opportunities including evaluation, dataset, and the gap between end-to-end
GenAI and generative algorithms. By summarizing different generation
algorithms, their current applications and limitations, this paper endeavors to
provide useful insights for future GenAI4VIS research.

ÊëòË¶ÅÔºöÁîüÊàêÂºè AI (GenAI) ËøëÂπ¥‰æÜË¶ãË≠â‰∫ÜÈ°ØËëóÁöÑÈÄ≤Â±ïÔºå‰∏¶Âú®‰∏çÂêåÁöÑÈ†òÂüüÔºà‰æãÂ¶ÇÈõªËÖ¶Ë¶ñË¶∫ÂíåË®àÁÆóË®≠Ë®àÔºâ‰∏≠ÔºåÂ±ïÁèæ‰∫ÜÂú®ÂêÑÁ®ÆÁîüÊàê‰ªªÂãô‰∏äÁöÑÈ©ö‰∫∫Ë°®Áèæ„ÄÇË®±Â§öÁ†îÁ©∂‰∫∫Âì°Â∑≤ÂòóË©¶Â∞á GenAI Êï¥ÂêàÂà∞Ë¶ñË¶∫ÂåñÊû∂Êßã‰∏≠ÔºåÂà©Áî®ÂÖ∂ÂÑ™Ë∂äÁöÑÁîüÊàêËÉΩÂäõÈÄ≤Ë°å‰∏çÂêåÁöÑÊìç‰Ωú„ÄÇÂêåÊôÇÔºåGenAI ÊúÄËøëÂú®Êì¥Êï£Ê®°ÂûãÂíåÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÁ≠âÊñπÈù¢ÁöÑÈáçÂ§ßÁ™ÅÁ†¥Ôºå‰πüÂ§ßÂπÖÊèêÂçá‰∫Ü GenAI4VIS ÁöÑÊΩõÂäõ„ÄÇÂæûÊäÄË°ìÁöÑËßíÂ∫¶‰æÜÁúãÔºåÊú¨ÊñáÂõûÈ°ß‰∫ÜÂà©Áî® GenAI ÁöÑÂÖàÂâçÁöÑË¶ñË¶∫ÂåñÁ†îÁ©∂Ôºå‰∏¶Êé¢Ë®é‰∫ÜÊú™‰æÜÁ†îÁ©∂ÁöÑÊåëÊà∞ÂíåÊ©üÊúÉ„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÊ∂µËìã‰∫Ü‰∏çÂêåÈ°ûÂûã GenAI ÊñπÊ≥ïÁöÑÊáâÁî®ÔºåÂåÖÊã¨Â∫èÂàó„ÄÅË°®Ê†º„ÄÅÁ©∫ÈñìÂíåÂúñÂΩ¢ÁîüÊàêÊäÄË°ìÔºåÁî®Êñº‰∏çÂêåÁöÑË¶ñË¶∫Âåñ‰ªªÂãôÔºåÊàëÂÄëÂ∞áÂÖ∂Á∏ΩÁµêÁÇ∫ÂõõÂÄã‰∏ªË¶ÅÈöéÊÆµÔºöË≥áÊñôÂ¢ûÂº∑„ÄÅË¶ñË¶∫Â∞çÊáâÁîüÊàê„ÄÅÊ®£ÂºèÂåñÂíå‰∫íÂãï„ÄÇÂ∞çÊñºÊØèÂÄãÁâπÂÆöÁöÑË¶ñË¶∫ÂåñÂ≠ê‰ªªÂãôÔºåÊàëÂÄëË™™Êòé‰∫ÜÂÖ∏ÂûãÁöÑË≥áÊñôÂíåÂÖ∑È´îÁöÑ GenAI ÊºîÁÆóÊ≥ïÔºåÊó®Âú®Ê∑±ÂÖ•‰∫ÜËß£ÊúÄÂÖàÈÄ≤ÁöÑ GenAI4VIS ÊäÄË°ìÂèäÂÖ∂ÈôêÂà∂„ÄÇÊ≠§Â§ñÔºåÊ†πÊìöË™øÊü•ÔºåÊàëÂÄëÊé¢Ë®é‰∫ÜÊåëÊà∞ÂíåÁ†îÁ©∂Ê©üÊúÉÁöÑ‰∏âÂÄã‰∏ªË¶ÅÊñπÈù¢ÔºåÂåÖÊã¨Ë©ï‰º∞„ÄÅË≥áÊñôÈõÜÔºå‰ª•ÂèäÁ´ØÂà∞Á´Ø GenAI ÂíåÁîüÊàêÊºîÁÆóÊ≥ï‰πãÈñìÁöÑÂ∑ÆË∑ù„ÄÇÈÄèÈÅéÁ∏ΩÁµê‰∏çÂêåÁöÑÁîüÊàêÊºîÁÆóÊ≥ï„ÄÅÂÆÉÂÄëÁõÆÂâçÁöÑÊáâÁî®ÂíåÈôêÂà∂ÔºåÊú¨ÊñáËá¥ÂäõÊñºÁÇ∫Êú™‰æÜÁöÑ GenAI4VIS Á†îÁ©∂Êèê‰æõÊúâÁî®ÁöÑË¶ãËß£„ÄÇ

##### **Retrieval-Augmented Generation with Knowledge Graphs for Customer Service Question Answering**
2404.17723v2 by Zhentao Xu, Mark Jerome Cruz, Matthew Guevara, Tie Wang, Manasi Deshpande, Xiaofeng Wang, Zheng Li

In customer service technical support, swiftly and accurately retrieving
relevant past issues is critical for efficiently resolving customer inquiries.
The conventional retrieval methods in retrieval-augmented generation (RAG) for
large language models (LLMs) treat a large corpus of past issue tracking
tickets as plain text, ignoring the crucial intra-issue structure and
inter-issue relations, which limits performance. We introduce a novel customer
service question-answering method that amalgamates RAG with a knowledge graph
(KG). Our method constructs a KG from historical issues for use in retrieval,
retaining the intra-issue structure and inter-issue relations. During the
question-answering phase, our method parses consumer queries and retrieves
related sub-graphs from the KG to generate answers. This integration of a KG
not only improves retrieval accuracy by preserving customer service structure
information but also enhances answering quality by mitigating the effects of
text segmentation. Empirical assessments on our benchmark datasets, utilizing
key retrieval (MRR, Recall@K, NDCG@K) and text generation (BLEU, ROUGE, METEOR)
metrics, reveal that our method outperforms the baseline by 77.6% in MRR and by
0.32 in BLEU. Our method has been deployed within LinkedIn's customer service
team for approximately six months and has reduced the median per-issue
resolution time by 28.6%.

ÊëòË¶ÅÔºöÂú®ÂÆ¢Êà∂ÊúçÂãôÊäÄË°ìÊîØÊè¥‰∏≠ÔºåÂø´ÈÄü‰∏îÊ∫ñÁ¢∫Âú∞Êì∑ÂèñÁõ∏ÈóúÈÅéÂæÄÂïèÈ°åÂ∞çÊñºÊúâÊïàËß£Ê±∫ÂÆ¢Êà∂Ë©¢ÂïèËá≥ÈóúÈáçË¶Å„ÄÇÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰∏≠Áî®ÊñºÊ™¢Á¥¢Â¢ûÂº∑ÂºèÁîüÊàê (RAG) ÁöÑÂÇ≥Áµ±Ê™¢Á¥¢ÊñπÊ≥ïÂ∞áÂ§ßÈáèÈÅéÂæÄÂïèÈ°åËøΩËπ§ÂñÆÊìöË¶ñÁÇ∫Á¥îÊñáÂ≠óÔºåÂøΩÁï•‰∫ÜËá≥ÈóúÈáçË¶ÅÁöÑË≠∞È°åÂÖßÁµêÊßãÂíåË≠∞È°åÈñìÈóú‰øÇÔºåÈÄôÈôêÂà∂‰∫ÜÊïàËÉΩ„ÄÇÊàëÂÄëÂºïÂÖ•‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÂÆ¢Êà∂ÊúçÂãôÂïèÁ≠îÊñπÊ≥ïÔºåÂ∞á RAG ËàáÁü•Ë≠òÂúñË≠ú (KG) ÁµêÂêà„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÊòØÂæûÊ≠∑Âè≤ÂïèÈ°å‰∏≠Âª∫Êßã KG ‰ª•Áî®ÊñºÊ™¢Á¥¢Ôºå‰øùÁïôË≠∞È°åÂÖßÁµêÊßãÂíåË≠∞È°åÈñìÈóú‰øÇ„ÄÇÂú®ÂïèÁ≠îÈöéÊÆµÔºåÊàëÂÄëÁöÑÊñπÊ≥ïÊúÉÂàÜÊûêÊ∂àË≤ªËÄÖÊü•Ë©¢Ôºå‰∏¶Âæû KG ‰∏≠Êì∑ÂèñÁõ∏ÈóúÂ≠êÂúñÂΩ¢‰æÜÁî¢ÁîüÁ≠îÊ°à„ÄÇÈÄôÁ®Æ KG Êï¥Âêà‰∏çÂÉÖÈÄèÈÅé‰øùÁïôÂÆ¢Êà∂ÊúçÂãôÁµêÊßãË≥áË®ä‰æÜÊèêÂçáÊ™¢Á¥¢Ê∫ñÁ¢∫Â∫¶ÔºåËÄå‰∏îÈÄèÈÅéÊ∏õËºïÊñáÂ≠óÂàÜÊÆµÁöÑÊïàÊûú‰æÜÊèêÂçáÂõûÁ≠îÂìÅË≥™„ÄÇÂú®ÊàëÂÄëÁöÑÂü∫Ê∫ñË≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÁ∂ìÈ©óË©ï‰º∞ÔºåÂà©Áî®ÈóúÈçµÊ™¢Á¥¢ (MRR„ÄÅRecall@K„ÄÅNDCG@K) ÂíåÊñáÂ≠óÁîüÊàê (BLEU„ÄÅROUGE„ÄÅMETEOR) ÊåáÊ®ôÔºåÈ°ØÁ§∫ÊàëÂÄëÁöÑÂÅöÊ≥ïÂú® MRR ‰∏äÂÑ™ÊñºÂü∫Ê∫ñÁ∑ö 77.6%ÔºåÂú® BLEU ‰∏äÂÑ™ÊñºÂü∫Ê∫ñÁ∑ö 0.32„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÂ∑≤Âú® LinkedIn ÁöÑÂÆ¢Êà∂ÊúçÂãôÂúòÈöä‰∏≠ÈÉ®ÁΩ≤Á¥ÑÂÖ≠ÂÄãÊúàÔºåÂ∑≤Â∞áÊØèÂÄãÂïèÈ°åÁöÑÂπ≥ÂùáËß£Ê±∫ÊôÇÈñìÁ∏ÆÁü≠‰∫Ü 28.6%„ÄÇ

##### **PLAYER*: Enhancing LLM-based Multi-Agent Communication and Interaction in Murder Mystery Games**
2404.17662v1 by Qinglin Zhu, Runcong Zhao, Jinhua Du, Lin Gui, Yulan He

Recent advancements in Large Language Models (LLMs) have enhanced the
efficacy of agent communication and social interactions. Despite these
advancements, building LLM-based agents for reasoning in dynamic environments
involving competition and collaboration remains challenging due to the
limitations of informed graph-based search methods. We propose PLAYER*, a novel
framework based on an anytime sampling-based planner, which utilises sensors
and pruners to enable a purely question-driven searching framework for complex
reasoning tasks. We also introduce a quantifiable evaluation method using
multiple-choice questions and construct the WellPlay dataset with 1,482 QA
pairs. Experiments demonstrate PLAYER*'s efficiency and performance
enhancements compared to existing methods in complex, dynamic environments with
quantifiable results.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊúÄÊñ∞ÈÄ≤Â±ïÂ¢ûÂº∑‰∫Ü‰ª£ÁêÜÊ∫ùÈÄöÂíåÁ§æ‰∫§‰∫íÂãïÁöÑÊïàËÉΩ„ÄÇÂÑòÁÆ°ÊúâÈÄô‰∫õÈÄ≤Â±ïÔºåÁî±ÊñºÂü∫ÊñºË≥áË®äÂúñÂΩ¢ÁöÑÊêúÂ∞ãÊñπÊ≥ïÁöÑÈôêÂà∂ÔºåÂú®Ê∂âÂèäÁ´∂Áà≠ÂíåÂçî‰ΩúÁöÑÂãïÊÖãÁí∞Â¢É‰∏≠Âª∫Á´ãÂü∫Êñº LLM ÁöÑ‰ª£ÁêÜ‰ª•ÈÄ≤Ë°åÊé®ÁêÜ‰ªçÁÑ∂ÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÊàëÂÄëÊèêÂá∫ PLAYER*Ôºå‰∏ÄÂÄãÂü∫ÊñºÈö®ÊôÇÂèñÊ®£Ë¶èÂäÉÂô®ÁöÑÂÖ®Êñ∞Ê°ÜÊû∂ÔºåÂÆÉÂà©Áî®ÊÑüÊ∏¨Âô®Âíå‰øÆÂâ™Âô®‰æÜÂïüÁî®‰∏ÄÂÄãÁ¥îÁ≤πÁî±ÂïèÈ°åÈ©ÖÂãïÁöÑË§áÈõúÊé®ÁêÜ‰ªªÂãôÊêúÂ∞ãÊ°ÜÊû∂„ÄÇÊàëÂÄëÈÇÑ‰ΩøÁî®Â§öÈÅ∏È°åÂºïÂÖ•‰∏ÄÁ®ÆÂèØÈáèÂåñÁöÑË©ï‰º∞ÊñπÊ≥ïÔºå‰∏¶ÊßãÂª∫‰∫Ü‰∏ÄÂÄãÂåÖÂê´ 1,482 ÂÄãÂïèÁ≠îÂ∞çÁöÑ WellPlay Ë≥áÊñôÈõÜ„ÄÇÂØ¶È©óË≠âÊòé‰∫Ü PLAYER* ÁöÑÊïàÁéáÂíåÊïàËÉΩÔºåËàáÁèæÊúâÊñπÊ≥ïÂú®ÂÖ∑ÊúâÂèØÈáèÂåñÁµêÊûúÁöÑË§áÈõúÂãïÊÖãÁí∞Â¢É‰∏≠Áõ∏ÊØîÊúâ‰∫ÜÊèêÂçá„ÄÇ

##### **Language Interaction Network for Clinical Trial Approval Estimation**
2405.06662v1 by Chufan Gao, Tianfan Fu, Jimeng Sun

Clinical trial outcome prediction seeks to estimate the likelihood that a
clinical trial will successfully reach its intended endpoint. This process
predominantly involves the development of machine learning models that utilize
a variety of data sources such as descriptions of the clinical trials,
characteristics of the drug molecules, and specific disease conditions being
targeted. Accurate predictions of trial outcomes are crucial for optimizing
trial planning and prioritizing investments in a drug portfolio. While previous
research has largely concentrated on small-molecule drugs, there is a growing
need to focus on biologics-a rapidly expanding category of therapeutic agents
that often lack the well-defined molecular properties associated with
traditional drugs. Additionally, applying conventional methods like graph
neural networks to biologics data proves challenging due to their complex
nature. To address these challenges, we introduce the Language Interaction
Network (LINT), a novel approach that predicts trial outcomes using only the
free-text descriptions of the trials. We have rigorously tested the
effectiveness of LINT across three phases of clinical trials, where it achieved
ROC-AUC scores of 0.770, 0.740, and 0.748 for phases I, II, and III,
respectively, specifically concerning trials involving biologic interventions.

ÊëòË¶ÅÔºöËá®Â∫äË©¶È©óÁµêÊûúÈ†êÊ∏¨Êó®Âú®‰º∞Ë®àËá®Â∫äË©¶È©óÊàêÂäüÈÅîÂà∞È†êÊúüÁµÇÈªûÁöÑÂèØËÉΩÊÄß„ÄÇÊ≠§Á®ãÂ∫è‰∏ªË¶ÅÊ∂âÂèäÈñãÁôºÊ©üÂô®Â≠∏ÁøíÊ®°ÂûãÔºåÂà©Áî®ÂêÑÁ®ÆÊï∏Êìö‰æÜÊ∫êÔºå‰æãÂ¶ÇËá®Â∫äË©¶È©óÁöÑË™™Êòé„ÄÅËó•Áâ©ÂàÜÂ≠êÁöÑÁâπÂæµÂíåÁõÆÊ®ôÁâπÂÆöÁñæÁóÖÁöÑÁãÄÊ≥Å„ÄÇÊ∫ñÁ¢∫È†êÊ∏¨Ë©¶È©óÁµêÊûúÂ∞çÊñºÂÑ™ÂåñË©¶È©óË®àÁï´ÂíåÂÑ™ÂÖàÊäïË≥áËó•Áâ©ÁµÑÂêàËá≥ÈóúÈáçË¶Å„ÄÇÈõñÁÑ∂ÂÖàÂâçÁöÑÁ†îÁ©∂‰∏ªË¶ÅÈõÜ‰∏≠ÊñºÂ∞èÂàÜÂ≠êËó•Áâ©Ôºå‰ΩÜÊúâË∂ä‰æÜË∂äÂ§öÁöÑÈúÄÊ±ÇÂ∞àÊ≥®ÊñºÁîüÁâ©Ë£ΩÂäëÔºåÈÄôÊòØ‰∏ÄÂÄãÂø´ÈÄüÊì¥Â±ïÁöÑÊ≤ªÁôÇÂäëÈ°ûÂà•ÔºåÈÄöÂ∏∏Áº∫‰πèËàáÂÇ≥Áµ±Ëó•Áâ©Áõ∏ÈóúÁöÑÊòéÁ¢∫ÂàÜÂ≠êÁâπÊÄß„ÄÇÊ≠§Â§ñÔºåÁî±ÊñºÁîüÁâ©Ë£ΩÂäëÊï∏ÊìöÁöÑË§áÈõúÊÄßÔºåÂ∞áÂúñÂΩ¢Á•ûÁ∂ìÁ∂≤Ë∑ØÁ≠âÂÇ≥Áµ±ÊñπÊ≥ïÊáâÁî®ÊñºÁîüÁâ©Ë£ΩÂäëÊï∏ÊìöÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜË™ûË®Ä‰∫íÂãïÁ∂≤Ë∑Ø (LINT)ÔºåÈÄôÊòØ‰∏ÄÁ®ÆÂÉÖ‰ΩøÁî®Ë©¶È©óÁöÑËá™Áî±ÊñáÊú¨ÊèèËø∞‰æÜÈ†êÊ∏¨Ë©¶È©óÁµêÊûúÁöÑÊñ∞ÊñπÊ≥ï„ÄÇÊàëÂÄëÂö¥Ê†ºÊ∏¨Ë©¶‰∫Ü LINT Âú®Ëá®Â∫äË©¶È©óÁöÑ‰∏â‰∏™ÈöéÊÆµ‰∏≠ÁöÑÊúâÊïàÊÄßÔºåÂú®Ê∂âÂèäÁîüÁâ©Ë£ΩÂäëÂπ≤È†êÁöÑË©¶È©ó‰∏≠ÔºåÂàÜÂà•Âú® I„ÄÅII Âíå III ÊúüÂèñÂæó‰∫Ü 0.770„ÄÅ0.740 Âíå 0.748 ÁöÑ ROC-AUC ÂàÜÊï∏„ÄÇ

##### **CyNetDiff -- A Python Library for Accelerated Implementation of Network Diffusion Models**
2404.17059v1 by Eliot W. Robson, Dhemath Reddy, Abhishek K. Umrawal

In recent years, there has been increasing interest in network diffusion
models and related problems. The most popular of these are the independent
cascade and linear threshold models. Much of the recent experimental work done
on these models requires a large number of simulations conducted on large
graphs, a computationally expensive task suited for low-level languages.
However, many researchers prefer the use of higher-level languages (such as
Python) for their flexibility and shorter development times. Moreover, in many
research tasks, these simulations are the most computationally intensive task,
so it would be desirable to have a library for these with an interface to a
high-level language with the performance of a low-level language. To fill this
niche, we introduce CyNetDiff, a Python library with components written in
Cython to provide improved performance for these computationally intensive
diffusion tasks.

ÊëòË¶ÅÔºöËøëÂπ¥Êù•ÔºåÁΩëÁªúÊâ©Êï£Ê®°ÂûãÂèäÁõ∏ÂÖ≥ÈóÆÈ¢òË∂äÊù•Ë∂äÂèóÂà∞ÂÖ≥Ê≥®„ÄÇÂÖ∂‰∏≠ÊúÄÊµÅË°åÁöÑÊòØÁã¨Á´ãÁ∫ßËÅîÂíåÁ∫øÊÄßÈòàÂÄºÊ®°Âûã„ÄÇËøô‰∫õÊ®°Âûã‰∏äËøõË°åÁöÑËÆ∏Â§öËøëÊúüÂÆûÈ™åÂ∑•‰ΩúÈúÄË¶ÅÂØπÂ§ßÂûãÂõæËøõË°åÂ§ßÈáèÁöÑÊ®°ÊãüÔºåËøôÊòØ‰∏ÄÈ°πÈÄÇÂêà‰ΩéÁ∫ßËØ≠Ë®ÄÁöÑËÆ°ÁÆóÊàêÊú¨È´òÊòÇÁöÑ‰ªªÂä°„ÄÇÁÑ∂ËÄåÔºåËÆ∏Â§öÁ†îÁ©∂‰∫∫ÂëòÊõ¥ÂñúÊ¨¢‰ΩøÁî®È´òÁ∫ßËØ≠Ë®ÄÔºàÂ¶Ç PythonÔºâÔºåÂõ†‰∏∫ÂÆÉ‰ª¨ÂÖ∑ÊúâÁÅµÊ¥ªÊÄß‰∏îÂºÄÂèëÊó∂Èó¥ËæÉÁü≠„ÄÇÊ≠§Â§ñÔºåÂú®ËÆ∏Â§öÁ†îÁ©∂‰ªªÂä°‰∏≠ÔºåËøô‰∫õÊ®°ÊãüÊòØÊúÄËÄóË¥πËÆ°ÁÆóËµÑÊ∫êÁöÑ‰ªªÂä°ÔºåÂõ†Ê≠§ÊúÄÂ•ΩÊúâ‰∏Ä‰∏™ÈíàÂØπËøô‰∫õ‰ªªÂä°ÁöÑÂ∫ìÔºåËØ•Â∫ìÂÖ∑ÊúâÈ´òÁ∫ßËØ≠Ë®ÄÁöÑÊé•Âè£Âíå‰ΩéÁ∫ßËØ≠Ë®ÄÁöÑÊÄßËÉΩ„ÄÇ‰∏∫‰∫ÜÂ°´Ë°•Ëøô‰∏ÄÁ©∫ÁôΩÔºåÊàë‰ª¨ÂºïÂÖ•‰∫Ü CyNetDiffÔºåËøôÊòØ‰∏Ä‰∏™ Python Â∫ìÔºåÂÖ∂‰∏≠ÂåÖÂê´Áî® Cython ÁºñÂÜôÁöÑÁªÑ‰ª∂Ôºå‰ª•ÊèêÈ´òËøô‰∫õËÆ°ÁÆóÂØÜÈõÜÂûãÊâ©Êï£‰ªªÂä°ÁöÑÊÄßËÉΩ„ÄÇ

##### **Player-Driven Emergence in LLM-Driven Game Narrative**
2404.17027v2 by Xiangyu Peng, Jessica Quaye, Weijia Xu, Portia Botchway, Chris Brockett, Bill Dolan, Nebojsa Jojic, Gabriel DesGarennes, Ken Lobb, Michael Xu, Jorge Leandro, Claire Jin, Sudha Rao

We explore how interaction with large language models (LLMs) can give rise to
emergent behaviors, empowering players to participate in the evolution of game
narratives. Our testbed is a text-adventure game in which players attempt to
solve a mystery under a fixed narrative premise, but can freely interact with
non-player characters generated by GPT-4, a large language model. We recruit 28
gamers to play the game and use GPT-4 to automatically convert the game logs
into a node-graph representing the narrative in the player's gameplay. We find
that through their interactions with the non-deterministic behavior of the LLM,
players are able to discover interesting new emergent nodes that were not a
part of the original narrative but have potential for being fun and engaging.
Players that created the most emergent nodes tended to be those that often
enjoy games that facilitate discovery, exploration and experimentation.

ÊëòË¶ÅÔºöÊàëÂÄëÊé¢Ë®éËàáÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰∫íÂãïÂ¶Ç‰ΩïÁî¢ÁîüÊñ∞ËààË°åÁÇ∫ÔºåËÆìÁé©ÂÆ∂ËÉΩÂ§†ÂèÉËàáÈÅäÊà≤Êïò‰∫ãÁöÑÊºîËÆä„ÄÇÊàëÂÄëÁöÑÊ∏¨Ë©¶Âπ≥Âè∞ÊòØ‰∏ÄÂÄãÊñáÂ≠óÂÜíÈö™ÈÅäÊà≤ÔºåÁé©ÂÆ∂Âú®Âõ∫ÂÆöÁöÑÊïò‰∫ãÂâçÊèê‰∏ãÂòóË©¶Ëß£ÈñãË¨éÂúòÔºå‰ΩÜÂèØ‰ª•Ëá™Áî±Ëàá GPT-4Ôºà‰∏ÄÁ®ÆÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºâÁî¢ÁîüÁöÑÈùûÁé©ÂÆ∂ËßíËâ≤‰∫íÂãï„ÄÇÊàëÂÄëÊãõÂãü‰∫Ü 28 ‰ΩçÁé©ÂÆ∂‰æÜÁé©ÈÅäÊà≤Ôºå‰∏¶‰ΩøÁî® GPT-4 Ëá™ÂãïÂ∞áÈÅäÊà≤Ë®òÈåÑËΩâÊèõÊàê‰ª£Ë°®Áé©ÂÆ∂ÈÅäÊà≤ÈÅéÁ®ã‰∏≠Êïò‰∫ãÁöÑÁØÄÈªûÂúñ„ÄÇÊàëÂÄëÁôºÁèæÔºåÁé©ÂÆ∂ÈÄèÈÅéËàá LLM ÁöÑÈùûÁ¢∫ÂÆöÊÄßË°åÁÇ∫‰∫íÂãïÔºåËÉΩÂ§†ÁôºÁèæÊúâË∂£ÁöÑÂÖ®Êñ∞Êñ∞ËààÁØÄÈªûÔºåÈÄô‰∫õÁØÄÈªû‰∏¶ÈùûÂéüÂßãÊïò‰∫ãÁöÑ‰∏ÄÈÉ®ÂàÜÔºå‰ΩÜÊúâÊΩõÂäõÂ∏∂‰æÜÊ®ÇË∂£ÂíåÂê∏ÂºïÂäõ„ÄÇÂâµÈÄ†ÊúÄÂ§öÊñ∞ËààÁØÄÈªûÁöÑÁé©ÂÆ∂ÂæÄÂæÄÊòØÈÇ£‰∫õÁ∂ìÂ∏∏‰∫´Âèó‰øÉÈÄ≤ÁôºÁèæ„ÄÅÊé¢Á¥¢ÂíåÂØ¶È©óÁöÑÈÅäÊà≤ÁöÑ‰∫∫„ÄÇ

##### **Evaluating Class Membership Relations in Knowledge Graphs using Large Language Models**
2404.17000v1 by Bradley P. Allen, Paul T. Groth

A backbone of knowledge graphs are their class membership relations, which
assign entities to a given class. As part of the knowledge engineering process,
we propose a new method for evaluating the quality of these relations by
processing descriptions of a given entity and class using a zero-shot
chain-of-thought classifier that uses a natural language intensional definition
of a class. We evaluate the method using two publicly available knowledge
graphs, Wikidata and CaLiGraph, and 7 large language models. Using the
gpt-4-0125-preview large language model, the method's classification
performance achieves a macro-averaged F1-score of 0.830 on data from Wikidata
and 0.893 on data from CaLiGraph. Moreover, a manual analysis of the
classification errors shows that 40.9% of errors were due to the knowledge
graphs, with 16.0% due to missing relations and 24.9% due to incorrectly
asserted relations. These results show how large language models can assist
knowledge engineers in the process of knowledge graph refinement. The code and
data are available on Github.

ÊëòË¶ÅÔºöÁü•Ë≠òÂúñË≠úÁöÑÈ™®ÂππÊòØÂÖ∂È°ûÂà•ÊàêÂì°Èóú‰øÇÔºåÂÆÉÂ∞áÂØ¶È´îÂàÜÈÖçÁµ¶ÁâπÂÆöÈ°ûÂà•„ÄÇ‰ΩúÁÇ∫Áü•Ë≠òÂ∑•Á®ãÊµÅÁ®ãÁöÑ‰∏ÄÈÉ®ÂàÜÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞ÁöÑÊñπÊ≥ï‰æÜË©ï‰º∞ÈÄô‰∫õÈóú‰øÇÁöÑÂìÅË≥™ÔºåÊñπÊ≥ïÊòØ‰ΩøÁî®Èõ∂Ê¨°Â≠∏ÁøíÊÄùÁ∂≠ÈèàÂàÜÈ°ûÂô®ËôïÁêÜÁµ¶ÂÆöÂØ¶È´îÂíåÈ°ûÂà•ÁöÑÊèèËø∞ÔºåË©≤ÂàÜÈ°ûÂô®‰ΩøÁî®È°ûÂà•ÁöÑËá™ÁÑ∂Ë™ûË®ÄÂÖßÊ∂µÂÆöÁæ©„ÄÇÊàëÂÄë‰ΩøÁî®ÂÖ©ÂÄãÂÖ¨ÈñãÂèØÁî®ÁöÑÁü•Ë≠òÂúñË≠ú Wikidata Âíå CaLiGraph ‰ª•Âèä 7 ÂÄãÂ§ßÂûãË™ûË®ÄÊ®°Âûã‰æÜË©ï‰º∞Ë©≤ÊñπÊ≥ï„ÄÇ‰ΩøÁî® gpt-4-0125-preview Â§ßÂûãË™ûË®ÄÊ®°ÂûãÔºåË©≤ÊñπÊ≥ïÁöÑÂàÜÈ°ûÊÄßËÉΩÂú® Wikidata ÁöÑË≥áÊñô‰∏äÈÅîÂà∞ 0.830 ÁöÑÂ∑®ËßÄÂπ≥Âùá F1 ÂàÜÊï∏ÔºåÂú® CaLiGraph ÁöÑË≥áÊñô‰∏äÈÅîÂà∞ 0.893„ÄÇÊ≠§Â§ñÔºåÂ∞çÂàÜÈ°ûÈåØË™§ÁöÑÊâãÂãïÂàÜÊûêÈ°ØÁ§∫Ôºå40.9% ÁöÑÈåØË™§ÊòØÁü•Ë≠òÂúñË≠úÈÄ†ÊàêÁöÑÔºåÂÖ∂‰∏≠ 16.0% ÊòØÁî±ÊñºÈóú‰øÇÈÅ∫Â§±Ôºå24.9% ÊòØÁî±ÊñºÈåØË™§Êñ∑Ë®ÄÁöÑÈóú‰øÇ„ÄÇÈÄô‰∫õÁµêÊûúÈ°ØÁ§∫‰∫ÜÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÂ¶Ç‰ΩïÂçîÂä©Áü•Ë≠òÂ∑•Á®ãÂ∏´ÈÄ≤Ë°åÁü•Ë≠òÂúñË≠úÂÑ™ÂåñÁöÑÈÅéÁ®ã„ÄÇÁ®ãÂºèÁ¢ºÂíåË≥áÊñôÂèØÂú® Github ‰∏äÂèñÂæó„ÄÇ

##### **Incorporating Lexical and Syntactic Knowledge for Unsupervised Cross-Lingual Transfer**
2404.16627v1 by Jianyu Zheng, Fengfei Fan, Jianquan Li

Unsupervised cross-lingual transfer involves transferring knowledge between
languages without explicit supervision. Although numerous studies have been
conducted to improve performance in such tasks by focusing on cross-lingual
knowledge, particularly lexical and syntactic knowledge, current approaches are
limited as they only incorporate syntactic or lexical information. Since each
type of information offers unique advantages and no previous attempts have
combined both, we attempt to explore the potential of this approach. In this
paper, we present a novel framework called "Lexicon-Syntax Enhanced
Multilingual BERT" that combines both lexical and syntactic knowledge.
Specifically, we use Multilingual BERT (mBERT) as the base model and employ two
techniques to enhance its learning capabilities. The code-switching technique
is used to implicitly teach the model lexical alignment information, while a
syntactic-based graph attention network is designed to help the model encode
syntactic structure. To integrate both types of knowledge, we input
code-switched sequences into both the syntactic module and the mBERT base model
simultaneously. Our extensive experimental results demonstrate this framework
can consistently outperform all baselines of zero-shot cross-lingual transfer,
with the gains of 1.0~3.7 points on text classification, named entity
recognition (ner), and semantic parsing tasks. Keywords:cross-lingual transfer,
lexicon, syntax, code-switching, graph attention network

ÊëòË¶ÅÔºöÁÑ°Áõ£Áù£Ë∑®Ë™ûË®ÄËΩâÁßªÊ∂âÂèäÂú®Ë™ûË®Ä‰πãÈñìÂÇ≥ÈÅûÁü•Ë≠òÔºåËÄåÁÑ°ÈúÄÊòéÁ¢∫Áõ£Áù£„ÄÇÂÑòÁÆ°Â∑≤ÈÄ≤Ë°åË®±Â§öÁ†îÁ©∂ÔºåÂ∞àÊ≥®ÊñºË∑®Ë™ûË®ÄÁü•Ë≠òÔºàÁâπÂà•ÊòØË©ûÂΩôÂíåÂè•Ê≥ïÁü•Ë≠òÔºâ‰æÜÊîπÂñÑÊ≠§È°û‰ªªÂãôÁöÑÊÄßËÉΩÔºå‰ΩÜÁõÆÂâçÁöÑÂÅöÊ≥ïÂèóÂà∞ÈôêÂà∂ÔºåÂõ†ÁÇ∫ÂÆÉÂÄëÂÉÖÂåÖÂê´Âè•Ê≥ïÊàñË©ûÂΩô‰ø°ÊÅØ„ÄÇÁî±ÊñºÊØèÁ®ÆÈ°ûÂûãÁöÑ‰ø°ÊÅØÈÉΩÊèê‰æõÁç®ÁâπÁöÑÂÑ™Âã¢Ôºå‰∏¶‰∏î‰ª•ÂâçÊ≤íÊúâÂòóË©¶Â∞áÂÖ©ËÄÖÁµêÂêàËµ∑‰æÜÔºåÂõ†Ê≠§ÊàëÂÄëÂòóË©¶Êé¢Á¥¢ÈÄôÁ®ÆÊñπÊ≥ïÁöÑÊΩõÂäõ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂêçÁÇ∫„ÄåË©ûÂΩôÂè•Ê≥ïÂ¢ûÂº∑Â§öË™ûË®Ä BERT„ÄçÁöÑÊñ∞Ê°ÜÊû∂ÔºåÁµêÂêà‰∫ÜË©ûÂΩôÂíåÂè•Ê≥ïÁü•Ë≠ò„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄë‰ΩøÁî®Â§öË™ûË®Ä BERT (mBERT) ‰ΩúÁÇ∫Âü∫Á§éÊ®°ÂûãÔºå‰∏¶Êé°Áî®ÂÖ©Á®ÆÊäÄË°ì‰æÜÂ¢ûÂº∑ÂÖ∂Â≠∏ÁøíËÉΩÂäõ„ÄÇ‰ª£Á¢ºÂàáÊèõÊäÄË°ìÁî®ÊñºÈö±ÂºèÊïôÊéàÊ®°ÂûãË©ûÂΩôÂ∞çÈΩä‰ø°ÊÅØÔºåËÄåÂü∫ÊñºÂè•Ê≥ïÁöÑÂúñÊ≥®ÊÑèÂäõÁ∂≤Ë∑ØÊó®Âú®Âπ´Âä©Ê®°ÂûãÁ∑®Á¢ºÂè•Ê≥ïÁµêÊßã„ÄÇÁÇ∫‰∫ÜÊï¥ÂêàÈÄôÂÖ©Á®ÆÁü•Ë≠òÈ°ûÂûãÔºåÊàëÂÄëÂêåÊôÇÂ∞á‰ª£Á¢ºÂàáÊèõÂ∫èÂàóËº∏ÂÖ•Âè•Ê≥ïÊ®°ÁµÑÂíå mBERT Âü∫Á§éÊ®°Âûã„ÄÇÊàëÂÄëÂª£Ê≥õÁöÑÂØ¶È©óÁµêÊûúË°®ÊòéÔºåÈÄôÂÄãÊ°ÜÊû∂ÂèØ‰ª•ÊåÅÁ∫åÂÑ™ÊñºÊâÄÊúâÈõ∂Ê¨°Ë∑®Ë™ûË®ÄËΩâÁßªÂü∫Ê∫ñÔºåÂú®ÊñáÊú¨ÂàÜÈ°û„ÄÅÂëΩÂêçÂØ¶È´îË≠òÂà• (ner) ÂíåË™ûÁæ©Ëß£Êûê‰ªªÂãô‰∏äÁç≤Âæó 1.0~3.7 ÂàÜÁöÑÂ¢ûÁõä„ÄÇÈóúÈçµÂ≠óÔºöË∑®Ë™ûË®ÄËΩâÁßª„ÄÅË©ûÂΩô„ÄÅÂè•Ê≥ï„ÄÅ‰ª£Á¢ºÂàáÊèõ„ÄÅÂúñÊ≥®ÊÑèÂäõÁ∂≤Ë∑Ø

##### **Semgrex and Ssurgeon, Searching and Manipulating Dependency Graphs**
2404.16250v1 by John Bauer, Chloe Kiddon, Eric Yeh, Alex Shan, Christopher D. Manning

Searching dependency graphs and manipulating them can be a time consuming and
challenging task to get right. We document Semgrex, a system for searching
dependency graphs, and introduce Ssurgeon, a system for manipulating the output
of Semgrex. The compact language used by these systems allows for easy command
line or API processing of dependencies. Additionally, integration with publicly
released toolkits in Java and Python allows for searching text relations and
attributes over natural text.

ÊëòË¶ÅÔºöÊêúÂ∞ã‰æùË≥¥Èóú‰øÇÂúñÂΩ¢‰∏¶Êìç‰ΩúÂÆÉÂÄëÂèØËÉΩÊòØ‰∏ÄÈ†ÖËÄóÊôÇ‰∏îÂÖ∑ÊúâÊåëÊà∞ÊÄßÁöÑ‰ªªÂãô„ÄÇÊàëÂÄëË®òÈåÑ‰∫Ü SemgrexÔºåÈÄôÊòØ‰∏ÄÂÄãÁî®ÊñºÊêúÂ∞ã‰æùË≥¥Èóú‰øÇÂúñÂΩ¢ÁöÑÁ≥ªÁµ±Ôºå‰∏¶‰ªãÁ¥π‰∫Ü SsurgeonÔºåÈÄôÊòØ‰∏ÄÂÄãÁî®ÊñºÊìç‰Ωú Semgrex Ëº∏Âá∫ÁöÑÁ≥ªÁµ±„ÄÇÈÄô‰∫õÁ≥ªÁµ±‰ΩøÁî®ÁöÑÁ∞°ÊΩîË™ûË®ÄÂÖÅË®±ËºïÈ¨ÜÂú∞Â∞ç‰æùË≥¥Èóú‰øÇÈÄ≤Ë°åÂëΩ‰ª§ÂàóÊàñ API ËôïÁêÜ„ÄÇÊ≠§Â§ñÔºåËàá Java Âíå Python ‰∏≠ÂÖ¨ÈñãÁôºÂ∏ÉÁöÑÂ∑•ÂÖ∑ÂåÖÊï¥ÂêàÂÖÅË®±ÊêúÂ∞ãËá™ÁÑ∂Ë™ûË®ÄÊñáÂ≠óÈóú‰øÇÂíåÂ±¨ÊÄß„ÄÇ

##### **Knowledge Graph Completion using Structural and Textual Embeddings**
2404.16206v1 by Sakher Khalil Alqaaidi, Krzysztof Kochut

Knowledge Graphs (KGs) are widely employed in artificial intelligence
applications, such as question-answering and recommendation systems. However,
KGs are frequently found to be incomplete. While much of the existing
literature focuses on predicting missing nodes for given incomplete KG triples,
there remains an opportunity to complete KGs by exploring relations between
existing nodes, a task known as relation prediction. In this study, we propose
a relations prediction model that harnesses both textual and structural
information within KGs. Our approach integrates walks-based embeddings with
language model embeddings to effectively represent nodes. We demonstrate that
our model achieves competitive results in the relation prediction task when
evaluated on a widely used dataset.

ÊëòË¶ÅÔºöÁü•Ë≠òÂúñË≠ú (KG) Âª£Ê≥õÊáâÁî®Êñº‰∫∫Â∑•Êô∫ÊÖßÊáâÁî®Á®ãÂºèÔºå‰æãÂ¶ÇÂïèÁ≠îÂíåÊé®Ëñ¶Á≥ªÁµ±„ÄÇÁÑ∂ËÄåÔºåKG Á∂ìÂ∏∏Ë¢´ÁôºÁèæÊòØ‰∏çÂÆåÊï¥ÁöÑ„ÄÇÈõñÁÑ∂ÁèæÊúâÊñáÁçªÂ§ßÂ§öËëóÈáçÊñºÈ†êÊ∏¨Áµ¶ÂÆö‰∏çÂÆåÊï¥ KG ‰∏âÂÖÉÁµÑÁöÑÈÅ∫Â§±ÁØÄÈªûÔºå‰ΩÜ‰ªçÊúâÊ©üÊúÉÈÄèÈÅéÊé¢Á¥¢ÁèæÊúâÁØÄÈªû‰πãÈñìÁöÑÈóú‰øÇ‰æÜÂÆåÊàê KGÔºåÈÄôÈ†Ö‰ªªÂãôÁ®±ÁÇ∫Èóú‰øÇÈ†êÊ∏¨„ÄÇÂú®Êú¨Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÈóú‰øÇÈ†êÊ∏¨Ê®°ÂûãÔºåÂÆÉÂà©Áî® KG ‰∏≠ÁöÑÊñáÂ≠óÂíåÁµêÊßãË≥áË®ä„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÂ∞áÂü∫ÊñºÈÅäËµ∞ÁöÑÂµåÂÖ•ËàáË™ûË®ÄÊ®°ÂûãÂµåÂÖ•Êï¥ÂêàÔºå‰ª•ÊúâÊïàÂú∞Ë°®Á§∫ÁØÄÈªû„ÄÇÊàëÂÄëË≠âÊòéÊàëÂÄëÁöÑÊ®°ÂûãÂú®Èóú‰øÇÈ†êÊ∏¨‰ªªÂãô‰∏≠ÂèñÂæóÂÖ∑Á´∂Áà≠ÂäõÁöÑÁµêÊûúÔºå‰∏¶Âú®Âª£Ê≥õ‰ΩøÁî®ÁöÑË≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åË©ï‰º∞„ÄÇ

##### **Improving Multi-label Recognition using Class Co-Occurrence Probabilities**
2404.16193v1 by Samyak Rawlekar, Shubhang Bhatnagar, Vishnuvardhan Pogunulu Srinivasulu, Narendra Ahuja

Multi-label Recognition (MLR) involves the identification of multiple objects
within an image. To address the additional complexity of this problem, recent
works have leveraged information from vision-language models (VLMs) trained on
large text-images datasets for the task. These methods learn an independent
classifier for each object (class), overlooking correlations in their
occurrences. Such co-occurrences can be captured from the training data as
conditional probabilities between a pair of classes. We propose a framework to
extend the independent classifiers by incorporating the co-occurrence
information for object pairs to improve the performance of independent
classifiers. We use a Graph Convolutional Network (GCN) to enforce the
conditional probabilities between classes, by refining the initial estimates
derived from image and text sources obtained using VLMs. We validate our method
on four MLR datasets, where our approach outperforms all state-of-the-art
methods.

ÊëòË¶ÅÔºöÂ§öÊ®ôÁ±§Ëæ®Ë≠ò (MLR) Ê∂âÂèäË≠òÂà•ÂΩ±ÂÉè‰∏≠ÁöÑÂ§öÂÄãÁâ©‰ª∂„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÁöÑÈ°çÂ§ñË§áÈõúÊÄßÔºåÊúÄËøëÁöÑÁ†îÁ©∂Âà©Áî®‰∫ÜÈáùÂ∞çÂ§ßÂûãÊñáÂ≠óÂΩ±ÂÉèË≥áÊñôÈõÜË®ìÁ∑¥ÁöÑË¶ñË¶∫Ë™ûË®ÄÊ®°Âûã (VLM) ‰∏≠ÁöÑË≥áË®ä‰æÜÂü∑Ë°åÈÄôÈ†Ö‰ªªÂãô„ÄÇÈÄô‰∫õÊñπÊ≥ïÈáùÂ∞çÊØèÂÄãÁâ©‰ª∂ (È°ûÂà•) Â≠∏Áøí‰∏ÄÂÄãÁç®Á´ãÁöÑÂàÜÈ°ûÂô®ÔºåÂøΩÁï•ÂÆÉÂÄëÁôºÁîüÊôÇÁöÑÈóúËÅØÊÄß„ÄÇÈÄôÁ®ÆÂÖ±ÁèæÂèØ‰ª•ÂæûË®ìÁ∑¥Ë≥áÊñô‰∏≠Êì∑ÂèñÁÇ∫‰∏ÄÂ∞çÈ°ûÂà•‰πãÈñìÁöÑÊ¢ù‰ª∂Ê©üÁéá„ÄÇÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÊû∂ÊßãÔºåÈÄèÈÅéÁ¥çÂÖ•Áâ©‰ª∂Â∞çÁöÑÂÖ±ÁèæË≥áË®ä‰æÜÊì¥ÂÖÖÁç®Á´ãÂàÜÈ°ûÂô®Ôºå‰ª•ÊîπÂñÑÁç®Á´ãÂàÜÈ°ûÂô®ÁöÑÊïàËÉΩ„ÄÇÊàëÂÄë‰ΩøÁî®ÂúñÂΩ¢Âç∑Á©çÁ∂≤Ë∑Ø (GCN) ‰æÜÂº∑Âà∂Âü∑Ë°åÈ°ûÂà•‰πãÈñìÁöÑÊ¢ù‰ª∂Ê©üÁéáÔºåÊñπÊ≥ïÊòØÂà©Áî® VLM ÂèñÂæóÁöÑÂΩ±ÂÉèÂíåÊñáÂ≠ó‰æÜÊ∫êÊâÄË°çÁîüÁöÑÂàùÂßã‰º∞Ë®àÂÄº„ÄÇÊàëÂÄëÂú®ÂõõÂÄã MLR Ë≥áÊñôÈõÜ‰∏äÈ©óË≠â‰∫ÜÊàëÂÄëÁöÑÊ®°ÂûãÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÂÑ™ÊñºÊâÄÊúâÊúÄÂÖàÈÄ≤ÁöÑÊñπÊ≥ï„ÄÇ

##### **From Local to Global: A Graph RAG Approach to Query-Focused Summarization**
2404.16130v1 by Darren Edge, Ha Trinh, Newman Cheng, Joshua Bradley, Alex Chao, Apurva Mody, Steven Truitt, Jonathan Larson

The use of retrieval-augmented generation (RAG) to retrieve relevant
information from an external knowledge source enables large language models
(LLMs) to answer questions over private and/or previously unseen document
collections. However, RAG fails on global questions directed at an entire text
corpus, such as "What are the main themes in the dataset?", since this is
inherently a query-focused summarization (QFS) task, rather than an explicit
retrieval task. Prior QFS methods, meanwhile, fail to scale to the quantities
of text indexed by typical RAG systems. To combine the strengths of these
contrasting methods, we propose a Graph RAG approach to question answering over
private text corpora that scales with both the generality of user questions and
the quantity of source text to be indexed. Our approach uses an LLM to build a
graph-based text index in two stages: first to derive an entity knowledge graph
from the source documents, then to pregenerate community summaries for all
groups of closely-related entities. Given a question, each community summary is
used to generate a partial response, before all partial responses are again
summarized in a final response to the user. For a class of global sensemaking
questions over datasets in the 1 million token range, we show that Graph RAG
leads to substantial improvements over a na\"ive RAG baseline for both the
comprehensiveness and diversity of generated answers. An open-source,
Python-based implementation of both global and local Graph RAG approaches is
forthcoming at https://aka.ms/graphrag.

ÊëòË¶ÅÔºö‰ΩøÁî®Ê™¢Á¥¢Â¢ûÂº∑ÁîüÊàê (RAG) ÂæûÂ§ñÈÉ®Áü•Ë≠ò‰æÜÊ∫êÊ™¢Á¥¢Áõ∏ÈóúË≥áË®äÔºåËÆìÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ËÉΩÂõûÁ≠îÁßÅ‰∫∫Âíå/ÊàñÂÖàÂâçÊú™Ë¶ãÁöÑÊñá‰ª∂ÈõÜÂêà‰∏≠ÁöÑÂïèÈ°å„ÄÇÁÑ∂ËÄåÔºåÈáùÂ∞çÊï¥ÂÄãÊñáÂ≠óË™ûÊñôÂ∫´ÁöÑÂÖ®ÁêÉÂïèÈ°åÔºà‰æãÂ¶Ç„ÄåË≥áÊñôÈõÜ‰∏≠ÁöÑ‰∏ªË¶Å‰∏ªÈ°åÊòØ‰ªÄÈ∫ºÔºü„ÄçÔºâÔºåRAG ÊúÉÂ§±ÊïóÔºåÂõ†ÁÇ∫ÈÄôÊú¨Ë≥™‰∏äÊòØÊü•Ë©¢ÈáçÈªûÊëòË¶Å (QFS) ‰ªªÂãôÔºåËÄå‰∏çÊòØÊòéÁ¢∫ÁöÑÊ™¢Á¥¢‰ªªÂãô„ÄÇÂêåÊôÇÔºåÂÖàÂâçÁöÑ QFS ÊñπÊ≥ïÁÑ°Ê≥ïÊì¥ÂÖÖÂà∞ÂÖ∏Âûã RAG Á≥ªÁµ±Á¥¢ÂºïÁöÑÊñáÂ≠óÈáè„ÄÇÁÇ∫‰∫ÜÁµêÂêàÈÄô‰∫õÂ∞çÊØîÊñπÊ≥ïÁöÑÂÑ™Âã¢ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂúñÂΩ¢ RAG ÊñπÊ≥ïÔºåÁî®ÊñºÂõûÁ≠îÁßÅ‰∫∫ÊñáÂ≠óË™ûÊñôÂ∫´‰∏≠ÁöÑÂïèÈ°åÔºåË©≤ÊñπÊ≥ïÂèØÈö®Ëëó‰ΩøÁî®ËÄÖÂïèÈ°åÁöÑÊôÆÈÅçÊÄßÂíåË¶ÅÁ¥¢ÂºïÁöÑÂéüÂßãÊñáÂ≠óÈáèÁöÑÂ¢ûÂä†ËÄåÊì¥ÂÖÖ„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ï‰ΩøÁî® LLM ÂàÜÂÖ©ÂÄãÈöéÊÆµÂª∫Á´ãÂü∫ÊñºÂúñÂΩ¢ÁöÑÊñáÂ≠óÁ¥¢ÂºïÔºöÈ¶ñÂÖàÂæûÂéüÂßãÊñá‰ª∂Ë°çÁîüÂá∫ÂØ¶È´îÁü•Ë≠òÂúñÂΩ¢ÔºåÁÑ∂ÂæåÁÇ∫ÊâÄÊúâÂØÜÂàáÁõ∏ÈóúÂØ¶È´îÁöÑÁæ§ÁµÑÈ†êÂÖàÁî¢ÁîüÁ§æÁæ§ÊëòË¶Å„ÄÇÈáùÂ∞ç‰∏ÄÂÄãÂïèÈ°åÔºåÊØèÂÄãÁ§æÁæ§ÊëòË¶ÅÁî®ÊñºÁî¢ÁîüÈÉ®ÂàÜÂõûÊáâÔºåÁÑ∂ÂæåÂú®ÊúÄÁµÇÂõûÊáâ‰∏≠ÂÜçÊ¨°ÊëòË¶ÅÊâÄÊúâÈÉ®ÂàÜÂõûÊáâÁµ¶‰ΩøÁî®ËÄÖ„ÄÇÂ∞çÊñº 100 Ëê¨ÂÄã‰ª£Âπ£ÁØÑÂúçÂÖßË≥áÊñôÈõÜÁöÑ‰∏ÄÈ°ûÂÖ®ÁêÉÊÑèÁæ©Âª∫ÊßãÂïèÈ°åÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜÂúñÂΩ¢ RAG Âú®ÁîüÊàêÁ≠îÊ°àÁöÑÂÖ®Èù¢ÊÄßÂíåÂ§öÊ®£ÊÄßÊñπÈù¢ÔºåÈÉΩÊØîÂ§©ÁúüÁöÑ RAG Âü∫Ê∫ñÁ∑öÊúâÈ°ØËëóÁöÑÈÄ≤Ê≠•„ÄÇÂÖ®ÁêÉÂíåÊú¨Âú∞ÂúñÂΩ¢ RAG ÊñπÊ≥ïÁöÑÈñãÊ∫ê Python ÂØ¶‰ΩúÂç≥Â∞áÊñº https://aka.ms/graphrag ‰∏äÊèê‰æõ„ÄÇ

##### **KGValidator: A Framework for Automatic Validation of Knowledge Graph Construction**
2404.15923v1 by Jack Boylan, Shashank Mangla, Dominic Thorn, Demian Gholipour Ghalandari, Parsa Ghaffari, Chris Hokamp

This study explores the use of Large Language Models (LLMs) for automatic
evaluation of knowledge graph (KG) completion models. Historically, validating
information in KGs has been a challenging task, requiring large-scale human
annotation at prohibitive cost. With the emergence of general-purpose
generative AI and LLMs, it is now plausible that human-in-the-loop validation
could be replaced by a generative agent. We introduce a framework for
consistency and validation when using generative models to validate knowledge
graphs. Our framework is based upon recent open-source developments for
structural and semantic validation of LLM outputs, and upon flexible approaches
to fact checking and verification, supported by the capacity to reference
external knowledge sources of any kind. The design is easy to adapt and extend,
and can be used to verify any kind of graph-structured data through a
combination of model-intrinsic knowledge, user-supplied context, and agents
capable of external knowledge retrieval.

ÊëòË¶ÅÔºöÊú¨Á†îÁ©∂Êé¢Ë®é‰ΩøÁî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Ëá™ÂãïË©ï‰º∞Áü•Ë≠òÂúñË≠ú (KG) ÂÆåÊàêÊ®°Âûã„ÄÇÊ≠∑‰æÜÔºåÈ©óË≠â KG ‰∏≠ÁöÑË≥áË®äÊòØ‰∏ÄÈ†ÖËâ±ÈâÖÁöÑ‰ªªÂãôÔºåÈúÄË¶ÅÂ§ßÈáèÁöÑ‰∫∫Â∑•Ê®ôË®ªÔºåÊàêÊú¨È´òÊòÇ„ÄÇÈö®ËëóÈÄöÁî®ÁîüÊàêÂºè AI Âíå LLM ÁöÑÂá∫ÁèæÔºåÁèæÂú®ÊúâÂèØËÉΩÁî®ÁîüÊàêÂºè‰ª£ÁêÜÂèñ‰ª£‰∫∫Â∑•Ëø¥ÂúàÈ©óË≠â„ÄÇÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÊû∂ÊßãÔºåÁî®ÊñºÂú®‰ΩøÁî®ÁîüÊàêÂºèÊ®°ÂûãÈ©óË≠âÁü•Ë≠òÂúñË≠úÊôÇÁ¢∫‰øù‰∏ÄËá¥ÊÄßÂíåÈ©óË≠â„ÄÇÊàëÂÄëÁöÑÊû∂ÊßãÂü∫ÊñºÊúÄËøëÁöÑÁµêÊßãÂåñÂíåË™ûÁæ©È©óË≠â LLM Ëº∏Âá∫ÁöÑÈñãÊ∫êÈñãÁôºÔºå‰ª•ÂèäÈùàÊ¥ªÁöÑ‰∫ãÂØ¶Êü•Ê†∏ÂíåÈ©óË≠âÊñπÊ≥ïÔºå‰∏¶Áî±ÂèÉËÄÉ‰ªª‰ΩïÁ®ÆÈ°ûÁöÑÂ§ñÈÉ®Áü•Ë≠ò‰æÜÊ∫êÁöÑËÉΩÂäõÊâÄÊîØÊè¥„ÄÇÊ≠§Ë®≠Ë®àÊòìÊñºË™øÊï¥ÂíåÊì¥ÂÖÖÔºå‰∏îÂèØÈÄèÈÅéÁµêÂêàÊ®°ÂûãÂÖßÂú®Áü•Ë≠ò„ÄÅ‰ΩøÁî®ËÄÖÊèê‰æõÁöÑÂÖßÂÆπ‰ª•ÂèäËÉΩÂ§†Êì∑ÂèñÂ§ñÈÉ®Áü•Ë≠òÁöÑ‰ª£ÁêÜÔºå‰æÜÈ©óË≠â‰ªª‰ΩïÈ°ûÂûãÁöÑÂúñÂΩ¢ÁµêÊßãÂåñË≥áÊñô„ÄÇ

