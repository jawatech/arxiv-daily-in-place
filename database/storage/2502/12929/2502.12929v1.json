{"2502.12929": {"publish_time": "2025-02-18", "title": "Flow-of-Options: Diversified and Improved LLM Reasoning by Thinking Through Options", "paper_summary": "We present a novel reasoning approach called Flow-of-Options (FoO), designed\nto address intrinsic biases in Large Language Models (LLMs). FoO enables LLMs\nto systematically explore a diverse range of possibilities in their reasoning,\nas demonstrated by an FoO-based agentic system for autonomously solving Machine\nLearning tasks (AutoML). Our framework outperforms state-of-the-art baselines,\nachieving improvements of 38.2% - 69.2% on standard data science tasks, and\n37.4% - 47.9% on therapeutic chemistry tasks. With an overall operation cost\nunder $1 per task, our framework is well-suited for cost-sensitive\napplications. Beyond classification and regression, we illustrate the broader\napplicability of our FoO-based agentic system to tasks such as reinforcement\nlearning and image generation. Our framework presents significant advancements\ncompared to current state-of-the-art agentic systems for AutoML, due to the\nbenefits of FoO in enforcing diversity in LLM solutions through compressed,\nexplainable representations that also support long-term memory when combined\nwith case-based reasoning.", "paper_summary_zh": "\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u7a31\u70ba\u9078\u9805\u6d41 (FoO) \u7684\u65b0\u63a8\u7406\u65b9\u6cd5\uff0c\u65e8\u5728\u89e3\u6c7a\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u4e2d\u7684\u5167\u5728\u504f\u5dee\u3002FoO \u4f7f LLM \u80fd\u7cfb\u7d71\u6027\u5730\u63a2\u7d22\u5176\u63a8\u7406\u4e2d\u7684\u5404\u7a2e\u53ef\u80fd\u6027\uff0c\u9019\u7531\u4e00\u500b\u57fa\u65bc FoO \u7684\u4ee3\u7406\u7cfb\u7d71\u5c55\u793a\uff0c\u8a72\u7cfb\u7d71\u53ef\u81ea\u4e3b\u89e3\u6c7a\u6a5f\u5668\u5b78\u7fd2\u4efb\u52d9 (AutoML)\u3002\u6211\u5011\u7684\u6846\u67b6\u512a\u65bc\u6700\u5148\u9032\u7684\u57fa\u6e96\uff0c\u5728\u6a19\u6e96\u6578\u64da\u79d1\u5b78\u4efb\u52d9\u4e0a\u53d6\u5f97\u4e86 38.2% - 69.2% \u7684\u6539\u9032\uff0c\u5728\u6cbb\u7642\u5316\u5b78\u4efb\u52d9\u4e0a\u53d6\u5f97\u4e86 37.4% - 47.9% \u7684\u6539\u9032\u3002\u7531\u65bc\u6bcf\u500b\u4efb\u52d9\u7684\u6574\u9ad4\u904b\u71df\u6210\u672c\u4f4e\u65bc 1 \u7f8e\u5143\uff0c\u56e0\u6b64\u6211\u5011\u7684\u6846\u67b6\u975e\u5e38\u9069\u5408\u5c0d\u6210\u672c\u654f\u611f\u7684\u61c9\u7528\u3002\u9664\u4e86\u5206\u985e\u548c\u56de\u6b78\u4e4b\u5916\uff0c\u6211\u5011\u9084\u8aaa\u660e\u4e86\u57fa\u65bc FoO \u7684\u4ee3\u7406\u7cfb\u7d71\u5728\u5f37\u5316\u5b78\u7fd2\u548c\u5716\u50cf\u751f\u6210\u7b49\u4efb\u52d9\u4e2d\u7684\u66f4\u5ee3\u6cdb\u9069\u7528\u6027\u3002\u6211\u5011\u7684\u6846\u67b6\u8207\u7576\u524d\u6700\u5148\u9032\u7684 AutoML \u4ee3\u7406\u7cfb\u7d71\u76f8\u6bd4\u5177\u6709\u986f\u8457\u7684\u9032\u6b65\uff0c\u9019\u662f\u56e0\u70ba FoO \u5728\u901a\u904e\u58d3\u7e2e\u3001\u53ef\u89e3\u91cb\u7684\u8868\u793a\u5f37\u5236 LLM \u89e3\u6c7a\u65b9\u6848\u7684\u591a\u6a23\u6027\u65b9\u9762\u5177\u6709\u512a\u52e2\uff0c\u9019\u4e9b\u8868\u793a\u8207\u57fa\u65bc\u6848\u4f8b\u7684\u63a8\u7406\u7d50\u5408\u6642\u9084\u652f\u6301\u9577\u671f\u8a18\u61b6\u3002", "author": "Lakshmi Nair et.al.", "authors": "Lakshmi Nair, Ian Trase, Mark Kim", "id": "2502.12929v1", "paper_url": "http://arxiv.org/abs/2502.12929v1", "repo": "null"}}