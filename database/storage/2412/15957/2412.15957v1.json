{"2412.15957": {"publish_time": "2024-12-20", "title": "From General to Specific: Tailoring Large Language Models for Personalized Healthcare", "paper_summary": "The rapid development of large language models (LLMs) has transformed many\nindustries, including healthcare. However, previous medical LLMs have largely\nfocused on leveraging general medical knowledge to provide responses, without\naccounting for patient variability and lacking true personalization at the\nindividual level. To address this, we propose a novel method called\npersonalized medical language model (PMLM), which explores and optimizes\npersonalized LLMs through recommendation systems and reinforcement learning\n(RL). Specifically, by utilizing self-informed and peer-informed\npersonalization, PMLM captures changes in behaviors and preferences to design\ninitial personalized prompts tailored to individual needs. We further refine\nthese initial personalized prompts through RL, ultimately enhancing the\nprecision of LLM guidance. Notably, the personalized prompt are hard prompt,\nwhich grants PMLM high adaptability and reusability, allowing it to directly\nleverage high-quality proprietary LLMs. We evaluate PMLM using real-world\nobstetrics and gynecology data, and the experimental results demonstrate that\nPMLM achieves personalized responses, and it provides more refined and\nindividualized services, offering a potential way for personalized medical\nLLMs.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u5feb\u901f\u767c\u5c55\u5df2\u8f49\u8b8a\u8a31\u591a\u7522\u696d\uff0c\u5305\u62ec\u91ab\u7642\u4fdd\u5065\u3002\u7136\u800c\uff0c\u5148\u524d\u7684\u91ab\u7642 LLM \u4e3b\u8981\u5c08\u6ce8\u65bc\u5229\u7528\u4e00\u822c\u91ab\u7642\u77e5\u8b58\u63d0\u4f9b\u56de\u61c9\uff0c\u4e26\u672a\u8003\u91cf\u75c5\u60a3\u7684\u8b8a\u7570\u6027\uff0c\u4e14\u7f3a\u4e4f\u500b\u4eba\u5c64\u7d1a\u7684\u771f\u6b63\u500b\u4eba\u5316\u3002\u70ba\u4e86\u89e3\u6c7a\u6b64\u554f\u984c\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u7a31\u70ba\u500b\u4eba\u5316\u91ab\u7642\u8a9e\u8a00\u6a21\u578b (PMLM) \u7684\u65b0\u65b9\u6cd5\uff0c\u900f\u904e\u63a8\u85a6\u7cfb\u7d71\u548c\u5f37\u5316\u5b78\u7fd2 (RL) \u4f86\u63a2\u7d22\u548c\u6700\u4f73\u5316\u500b\u4eba\u5316\u7684 LLM\u3002\u5177\u9ad4\u4f86\u8aaa\uff0cPMLM \u900f\u904e\u5229\u7528\u81ea\u6211\u77e5\u60c5\u548c\u540c\u5115\u77e5\u60c5\u7684\u500b\u4eba\u5316\uff0c\u64f7\u53d6\u884c\u70ba\u548c\u504f\u597d\u7684\u8b8a\u5316\uff0c\u4ee5\u8a2d\u8a08\u7b26\u5408\u500b\u4eba\u9700\u6c42\u7684\u521d\u59cb\u500b\u4eba\u5316\u63d0\u793a\u3002\u6211\u5011\u9032\u4e00\u6b65\u900f\u904e RL \u8abf\u6574\u9019\u4e9b\u521d\u59cb\u500b\u4eba\u5316\u63d0\u793a\uff0c\u6700\u7d42\u63d0\u5347 LLM \u6307\u5c0e\u7684\u7cbe\u78ba\u5ea6\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u500b\u4eba\u5316\u63d0\u793a\u662f\u786c\u63d0\u793a\uff0c\u9019\u8ce6\u4e88 PMLM \u9ad8\u5ea6\u7684\u9069\u61c9\u6027\u548c\u53ef\u91cd\u8907\u4f7f\u7528\u6027\uff0c\u4f7f\u5176\u80fd\u5920\u76f4\u63a5\u5229\u7528\u9ad8\u54c1\u8cea\u7684\u5c08\u6709 LLM\u3002\u6211\u5011\u4f7f\u7528\u771f\u5be6\u4e16\u754c\u7684\u7522\u79d1\u548c\u5a66\u79d1\u8cc7\u6599\u8a55\u4f30 PMLM\uff0c\u5be6\u9a57\u7d50\u679c\u986f\u793a PMLM \u9054\u5230\u4e86\u500b\u4eba\u5316\u7684\u56de\u61c9\uff0c\u4e26\u63d0\u4f9b\u4e86\u66f4\u7cbe\u7dfb\u548c\u500b\u4eba\u5316\u7684\u670d\u52d9\uff0c\u70ba\u500b\u4eba\u5316\u7684\u91ab\u7642 LLM \u63d0\u4f9b\u4e86\u4e00\u7a2e\u6f5b\u5728\u7684\u65b9\u6cd5\u3002", "author": "Ruize Shi et.al.", "authors": "Ruize Shi, Hong Huang, Wei Zhou, Kehan Yin, Kai Zhao, Yun Zhao", "id": "2412.15957v1", "paper_url": "http://arxiv.org/abs/2412.15957v1", "repo": "null"}}