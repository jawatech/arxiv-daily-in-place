{"2411.13754": {"publish_time": "2024-11-20", "title": "Learning to Reason Iteratively and Parallelly for Complex Visual Reasoning Scenarios", "paper_summary": "Complex visual reasoning and question answering (VQA) is a challenging task\nthat requires compositional multi-step processing and higher-level reasoning\ncapabilities beyond the immediate recognition and localization of objects and\nevents. Here, we introduce a fully neural Iterative and Parallel Reasoning\nMechanism (IPRM) that combines two distinct forms of computation -- iterative\nand parallel -- to better address complex VQA scenarios. Specifically, IPRM's\n\"iterative\" computation facilitates compositional step-by-step reasoning for\nscenarios wherein individual operations need to be computed, stored, and\nrecalled dynamically (e.g. when computing the query \"determine the color of pen\nto the left of the child in red t-shirt sitting at the white table\").\nMeanwhile, its \"parallel\" computation allows for the simultaneous exploration\nof different reasoning paths and benefits more robust and efficient execution\nof operations that are mutually independent (e.g. when counting individual\ncolors for the query: \"determine the maximum occurring color amongst all\nt-shirts\"). We design IPRM as a lightweight and fully-differentiable neural\nmodule that can be conveniently applied to both transformer and non-transformer\nvision-language backbones. It notably outperforms prior task-specific methods\nand transformer-based attention modules across various image and video VQA\nbenchmarks testing distinct complex reasoning capabilities such as\ncompositional spatiotemporal reasoning (AGQA), situational reasoning (STAR),\nmulti-hop reasoning generalization (CLEVR-Humans) and causal event linking\n(CLEVRER-Humans). Further, IPRM's internal computations can be visualized\nacross reasoning steps, aiding interpretability and diagnosis of its errors.", "paper_summary_zh": "\u8907\u96dc\u8996\u89ba\u63a8\u7406\u548c\u554f\u984c\u89e3\u7b54 (VQA) \u662f\u4e00\u9805\u5177\u6709\u6311\u6230\u6027\u7684\u4efb\u52d9\uff0c\u9700\u8981\u7d44\u5408\u5f0f\u591a\u6b65\u9a5f\u8655\u7406\u548c\u8d85\u8d8a\u7acb\u5373\u8b58\u5225\u548c\u5b9a\u4f4d\u7269\u4ef6\u548c\u4e8b\u4ef6\u7684\u9ad8\u968e\u63a8\u7406\u80fd\u529b\u3002\u5728\u6b64\uff0c\u6211\u5011\u5f15\u5165\u4e86\u4e00\u7a2e\u5b8c\u5168\u795e\u7d93\u5143\u7684\u8fed\u4ee3\u4e26\u884c\u63a8\u7406\u6a5f\u5236 (IPRM)\uff0c\u5b83\u7d50\u5408\u4e86\u5169\u7a2e\u4e0d\u540c\u7684\u8a08\u7b97\u5f62\u5f0f\u2014\u2014\u8fed\u4ee3\u548c\u4e26\u884c\u2014\u2014\u4ee5\u66f4\u597d\u5730\u61c9\u5c0d\u8907\u96dc\u7684 VQA \u5834\u666f\u3002\u5177\u9ad4\u4f86\u8aaa\uff0cIPRM \u7684\u300c\u8fed\u4ee3\u300d\u8a08\u7b97\u4fc3\u9032\u4e86\u60c5\u5883\u4e2d\u9010\u6b65\u7d44\u5408\u5f0f\u63a8\u7406\uff0c\u5728\u8a72\u60c5\u5883\u4e2d\u9700\u8981\u52d5\u614b\u5730\u8a08\u7b97\u3001\u5132\u5b58\u548c\u8abf\u7528\u500b\u5225\u904b\u7b97\uff08\u4f8b\u5982\uff0c\u5728\u8a08\u7b97\u67e5\u8a62\u300c\u5224\u65b7\u5750\u5728\u767d\u8272\u684c\u5b50\u65c1\u7a7f\u7d05\u8272 T \u6064\u7684\u5c0f\u5b69\u5de6\u908a\u7684\u7b46\u7684\u984f\u8272\u300d\u6642\uff09\u3002\u540c\u6642\uff0c\u5176\u300c\u4e26\u884c\u300d\u8a08\u7b97\u5141\u8a31\u540c\u6642\u63a2\u7d22\u4e0d\u540c\u7684\u63a8\u7406\u8def\u5f91\uff0c\u4e26\u53d7\u76ca\u65bc\u5c0d\u76f8\u4e92\u7368\u7acb\u7684\u904b\u7b97\u9032\u884c\u66f4\u7a69\u5065\u4e14\u6709\u6548\u7387\u7684\u57f7\u884c\uff08\u4f8b\u5982\uff0c\u5728\u8a08\u7b97\u67e5\u8a62\u7684\u500b\u5225\u984f\u8272\u6642\uff1a\u300c\u5224\u65b7\u6240\u6709 T \u6064\u4e2d\u51fa\u73fe\u6b21\u6578\u6700\u591a\u7684\u984f\u8272\u300d\uff09\u3002\u6211\u5011\u5c07 IPRM \u8a2d\u8a08\u70ba\u4e00\u500b\u8f15\u91cf\u4e14\u5b8c\u5168\u53ef\u5fae\u5206\u7684\u985e\u795e\u7d93\u5143\u6a21\u7d44\uff0c\u53ef\u4ee5\u65b9\u4fbf\u5730\u61c9\u7528\u65bcTransformer\u548c\u975eTransformer\u8996\u89ba\u8a9e\u8a00\u4e3b\u5e79\u3002\u5b83\u660e\u986f\u512a\u65bc\u5404\u7a2e\u5f71\u50cf\u548c\u5f71\u7247 VQA \u57fa\u6e96\u6e2c\u8a66\u4e2d\u5148\u524d\u7684\u7279\u5b9a\u4efb\u52d9\u65b9\u6cd5\u548c\u57fa\u65bcTransformer\u7684\u6ce8\u610f\u529b\u6a21\u7d44\uff0c\u9019\u4e9b\u57fa\u51c6\u6e2c\u8a66\u4e86\u4e0d\u540c\u7684\u8907\u96dc\u63a8\u7406\u80fd\u529b\uff0c\u4f8b\u5982\u7d44\u5408\u5f0f\u6642\u7a7a\u63a8\u7406 (AGQA)\u3001\u60c5\u5883\u63a8\u7406 (STAR)\u3001\u591a\u8df3\u63a8\u7406\u6982\u5316 (CLEVR-Humans) \u548c\u56e0\u679c\u4e8b\u4ef6\u9023\u7d50 (CLEVRER-Humans)\u3002\u6b64\u5916\uff0cIPRM \u7684\u5167\u90e8\u8a08\u7b97\u53ef\u4ee5\u5728\u63a8\u7406\u6b65\u9a5f\u4e2d\u8996\u89ba\u5316\uff0c\u6709\u52a9\u65bc\u5176\u932f\u8aa4\u7684\u53ef\u89e3\u91cb\u6027\u548c\u8a3a\u65b7\u3002", "author": "Shantanu Jaiswal et.al.", "authors": "Shantanu Jaiswal, Debaditya Roy, Basura Fernando, Cheston Tan", "id": "2411.13754v1", "paper_url": "http://arxiv.org/abs/2411.13754v1", "repo": "null"}}