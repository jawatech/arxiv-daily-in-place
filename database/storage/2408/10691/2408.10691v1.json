{"2408.10691": {"publish_time": "2024-08-20", "title": "Fine-Tuning and Deploying Large Language Models Over Edges: Issues and Approaches", "paper_summary": "Since the invention of GPT2--1.5B in 2019, large language models (LLMs) have\ntransitioned from specialized models to versatile foundation models. The LLMs\nexhibit impressive zero-shot ability, however, require fine-tuning on local\ndatasets and significant resources for deployment. Traditional fine-tuning\ntechniques with the first-order optimizers require substantial GPU memory that\nexceeds mainstream hardware capability. Therefore, memory-efficient methods are\nmotivated to be investigated. Model compression techniques can reduce energy\nconsumption, operational costs, and environmental impact so that to support\nsustainable artificial intelligence advancements. Additionally, large-scale\nfoundation models have expanded to create images, audio, videos, and\nmulti-modal contents, further emphasizing the need for efficient deployment.\nTherefore, we are motivated to present a comprehensive overview of the\nprevalent memory-efficient fine-tuning methods over the network edge. We also\nreview the state-of-the-art literatures on model compression to provide a\nvision on deploying LLMs over the network edge.", "paper_summary_zh": "\u81ea 2019 \u5e74\u767c\u660e GPT2--1.5B \u4ee5\u4f86\uff0c\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5df2\u5f9e\u5c08\u696d\u6a21\u578b\u8f49\u8b8a\u70ba\u901a\u7528\u7684\u57fa\u790e\u6a21\u578b\u3002LLM \u8868\u73fe\u51fa\u4ee4\u4eba\u5370\u8c61\u6df1\u523b\u7684\u96f6\u6b21\u5b78\u7fd2\u80fd\u529b\uff0c\u7136\u800c\uff0c\u9700\u8981\u91dd\u5c0d\u672c\u5730\u8cc7\u6599\u96c6\u9032\u884c\u5fae\u8abf\uff0c\u4e26\u9700\u8981\u5927\u91cf\u7684\u8cc7\u6e90\u624d\u80fd\u90e8\u7f72\u3002\u4f7f\u7528\u4e00\u968e\u6700\u4f73\u5316\u5668\u7684\u50b3\u7d71\u5fae\u8abf\u6280\u8853\u9700\u8981\u5927\u91cf\u7684 GPU \u8a18\u61b6\u9ad4\uff0c\u9019\u8d85\u904e\u4e86\u4e3b\u6d41\u786c\u9ad4\u7684\u80fd\u529b\u3002\u56e0\u6b64\uff0c\u6709\u52d5\u6a5f\u7814\u7a76\u8a18\u61b6\u9ad4\u6548\u7387\u9ad8\u7684\u65b9\u6cd5\u3002\u6a21\u578b\u58d3\u7e2e\u6280\u8853\u53ef\u4ee5\u6e1b\u5c11\u80fd\u6e90\u6d88\u8017\u3001\u71df\u904b\u6210\u672c\u548c\u74b0\u5883\u5f71\u97ff\uff0c\u5f9e\u800c\u652f\u63f4\u6c38\u7e8c\u7684\u4eba\u5de5\u667a\u6167\u9032\u5c55\u3002\u6b64\u5916\uff0c\u5927\u898f\u6a21\u57fa\u790e\u6a21\u578b\u5df2\u64f4\u5c55\u5230\u5efa\u7acb\u5f71\u50cf\u3001\u97f3\u8a0a\u3001\u5f71\u7247\u548c\u591a\u6a21\u614b\u5167\u5bb9\uff0c\u9032\u4e00\u6b65\u5f37\u8abf\u4e86\u9ad8\u6548\u90e8\u7f72\u7684\u5fc5\u8981\u6027\u3002\u56e0\u6b64\uff0c\u6211\u5011\u6709\u52d5\u6a5f\u5c0d\u7db2\u8def\u908a\u7de3\u5e38\u898b\u7684\u8a18\u61b6\u9ad4\u6548\u7387\u9ad8\u5fae\u8abf\u65b9\u6cd5\u63d0\u51fa\u5168\u9762\u7684\u6982\u8ff0\u3002\u6211\u5011\u4e5f\u56de\u9867\u4e86\u6a21\u578b\u58d3\u7e2e\u7684\u6700\u65b0\u6587\u737b\uff0c\u4ee5\u63d0\u4f9b\u5728\u7db2\u8def\u908a\u7de3\u90e8\u7f72 LLM \u7684\u9858\u666f\u3002", "author": "Yanjie Dong et.al.", "authors": "Yanjie Dong, Xiaoyi Fan, Fangxin Wang, Chengming Li, Victor C. M. Leung, Xiping Hu", "id": "2408.10691v1", "paper_url": "http://arxiv.org/abs/2408.10691v1", "repo": "null"}}