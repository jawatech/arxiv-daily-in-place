{"2411.09945": {"publish_time": "2024-11-15", "title": "TEESlice: Protecting Sensitive Neural Network Models in Trusted Execution Environments When Attackers have Pre-Trained Models", "paper_summary": "Trusted Execution Environments (TEE) are used to safeguard on-device models.\nHowever, directly employing TEEs to secure the entire DNN model is challenging\ndue to the limited computational speed. Utilizing GPU can accelerate DNN's\ncomputation speed but commercial widely-available GPUs usually lack security\nprotection. To this end, scholars introduce TSDP, a method that protects\nprivacy-sensitive weights within TEEs and offloads insensitive weights to GPUs.\nNevertheless, current methods do not consider the presence of a knowledgeable\nadversary who can access abundant publicly available pre-trained models and\ndatasets. This paper investigates the security of existing methods against such\na knowledgeable adversary and reveals their inability to fulfill their security\npromises. Consequently, we introduce a novel partition before training\nstrategy, which effectively separates privacy-sensitive weights from other\ncomponents of the model. Our evaluation demonstrates that our approach can\noffer full model protection with a computational cost reduced by a factor of\n10. In addition to traditional CNN models, we also demonstrate the scalability\nto large language models. Our approach can compress the private functionalities\nof the large language model to lightweight slices and achieve the same level of\nprotection as the shielding-whole-model baseline.", "paper_summary_zh": "\u53d7\u4fe1\u4efb\u57f7\u884c\u74b0\u5883 (TEE) \u7528\u65bc\u4fdd\u8b77\u88dd\u7f6e\u4e0a\u7684\u6a21\u578b\u3002\n\u7136\u800c\uff0c\u7531\u65bc\u904b\u7b97\u901f\u5ea6\u6709\u9650\uff0c\u76f4\u63a5\u4f7f\u7528 TEE \u4fdd\u8b77\u6574\u500b DNN \u6a21\u578b\u5177\u6709\u6311\u6230\u6027\u3002\u5229\u7528 GPU \u53ef\u4ee5\u52a0\u901f DNN \u7684\u904b\u7b97\u901f\u5ea6\uff0c\u4f46\u5e02\u9762\u4e0a\u666e\u904d\u53ef\u7528\u7684 GPU \u901a\u5e38\u7f3a\u4e4f\u5b89\u5168\u6027\u4fdd\u8b77\u3002\u70ba\u6b64\uff0c\u5b78\u8005\u5011\u5f15\u5165\u4e86 TSDP\uff0c\u4e00\u7a2e\u5728 TEE \u5167\u4fdd\u8b77\u96b1\u79c1\u654f\u611f\u6b0a\u91cd\u4e26\u5c07\u4e0d\u654f\u611f\u6b0a\u91cd\u5378\u8f09\u5230 GPU \u7684\u65b9\u6cd5\u3002\n\u5118\u7ba1\u5982\u6b64\uff0c\u76ee\u524d\u7684\u65b9\u6cd5\u4e26\u672a\u8003\u616e\u77e5\u8b58\u6df5\u535a\u7684\u5c0d\u624b\uff0c\u4ed6\u5011\u53ef\u4ee5\u5b58\u53d6\u5927\u91cf\u516c\u958b\u53ef\u7528\u7684\u9810\u8a13\u7df4\u6a21\u578b\u548c\u8cc7\u6599\u96c6\u3002\u672c\u6587\u63a2\u8a0e\u4e86\u73fe\u6709\u65b9\u6cd5\u91dd\u5c0d\u6b64\u985e\u77e5\u8b58\u6df5\u535a\u5c0d\u624b\u7684\u5b89\u5168\u6027\uff0c\u4e26\u63ed\u793a\u4e86\u4ed6\u5011\u7121\u6cd5\u5c65\u884c\u5b89\u5168\u627f\u8afe\u3002\u56e0\u6b64\uff0c\u6211\u5011\u5728\u8a13\u7df4\u7b56\u7565\u4e4b\u524d\u5f15\u5165\u4e86\u5275\u65b0\u7684\u5206\u5272\uff0c\u6709\u6548\u5730\u5c07\u96b1\u79c1\u654f\u611f\u6b0a\u91cd\u8207\u6a21\u578b\u7684\u5176\u4ed6\u7d44\u6210\u90e8\u5206\u5206\u958b\u3002\u6211\u5011\u7684\u8a55\u4f30\u8868\u660e\uff0c\u6211\u5011\u7684\u505a\u6cd5\u53ef\u4ee5\u63d0\u4f9b\u5b8c\u6574\u7684\u6a21\u578b\u4fdd\u8b77\uff0c\u540c\u6642\u5c07\u904b\u7b97\u6210\u672c\u964d\u4f4e\u4e86 10 \u500d\u3002\u9664\u4e86\u50b3\u7d71\u7684 CNN \u6a21\u578b\u5916\uff0c\u6211\u5011\u9084\u5c55\u793a\u4e86\u53ef\u64f4\u5145\u6027\u81f3\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u3002\u6211\u5011\u7684\u505a\u6cd5\u53ef\u4ee5\u5c07\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u7684\u79c1\u6709\u529f\u80fd\u58d3\u7e2e\u6210\u8f15\u91cf\u7d1a\u5207\u7247\uff0c\u4e26\u5be6\u73fe\u8207\u4fdd\u8b77\u6574\u500b\u6a21\u578b\u7684\u57fa\u6e96\u7dda\u76f8\u540c\u7684\u4fdd\u8b77\u7d1a\u5225\u3002", "author": "Ding Li et.al.", "authors": "Ding Li, Ziqi Zhang, Mengyu Yao, Yifeng Cai, Yao Guo, Xiangqun Chen", "id": "2411.09945v1", "paper_url": "http://arxiv.org/abs/2411.09945v1", "repo": "null"}}