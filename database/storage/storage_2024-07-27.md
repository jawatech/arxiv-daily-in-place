# arxiv-daily
 Automated deployment @ 2024-07-27 08:56:39 Asia/Taipei
> Welcome to contribute! Add your topics and keywords in [`topic.yml`](https://github.com/jawatech/arxiv-daily-in-place/blob/main/database/topic.yml).
> You can also view historical data through the [storage](https://github.com/jawatech/arxiv-daily-in-place/blob/main/database/storage).

## AI

### Knowledge Graphs
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-07-25**|**Gene Regulatory Network Inference from Pre-trained Single-Cell Transcriptomics Transformer with Joint Graph Learning**|Sindhura Kommu et.al.|[2407.18181v1](http://arxiv.org/abs/2407.18181v1)|null|
|**2024-07-24**|**MathViz-E: A Case-study in Domain-Specialized Tool-Using Agents**|Arya Bulusu et.al.|[2407.17544v1](http://arxiv.org/abs/2407.17544v1)|null|
|**2024-07-23**|**Ranking protein-protein models with large language models and graph neural networks**|Xiaotong Xu et.al.|[2407.16375v1](http://arxiv.org/abs/2407.16375v1)|[link](https://github.com/haddocking/deeprank-gnn-esm)|
|**2024-07-23**|**PhenoFlow: A Human-LLM Driven Visual Analytics System for Exploring Large and Complex Stroke Datasets**|Jaeyoung Kim et.al.|[2407.16329v1](http://arxiv.org/abs/2407.16329v1)|null|
|**2024-07-23**|**Graph-Structured Speculative Decoding**|Zhuocheng Gong et.al.|[2407.16207v1](http://arxiv.org/abs/2407.16207v1)|null|
|**2024-07-23**|**Finetuning Generative Large Language Models with Discrimination Instructions for Knowledge Graph Completion**|Yang Liu et.al.|[2407.16127v1](http://arxiv.org/abs/2407.16127v1)|[link](https://github.com/nju-websoft/dift)|
|**2024-07-22**|**Unsupervised Robust Cross-Lingual Entity Alignment via Joint Modeling of Entity and Relation Texts**|Soojin Yoon et.al.|[2407.15588v1](http://arxiv.org/abs/2407.15588v1)|[link](https://github.com/eralign/eralign)|
|**2024-07-22**|**Pre-Training and Prompting for Few-Shot Node Classification on Text-Attributed Graphs**|Huanjing Zhao et.al.|[2407.15431v1](http://arxiv.org/abs/2407.15431v1)|null|
|**2024-07-22**|**LLMExplainer: Large Language Model based Bayesian Inference for Graph Explanation Generation**|Jiaxing Zhang et.al.|[2407.15351v2](http://arxiv.org/abs/2407.15351v2)|null|
|**2024-07-21**|**Text-Augmented Multimodal LLMs for Chemical Reaction Condition Recommendation**|Yu Zhang et.al.|[2407.15141v1](http://arxiv.org/abs/2407.15141v1)|null|
|**2024-07-20**|**On the Design and Analysis of LLM-Based Algorithms**|Yanxi Chen et.al.|[2407.14788v1](http://arxiv.org/abs/2407.14788v1)|[link](https://github.com/modelscope/agentscope)|
|**2024-07-19**|**Hierarchical Windowed Graph Attention Network and a Large Scale Dataset for Isolated Indian Sign Language Recognition**|Suvajit Patra et.al.|[2407.14224v1](http://arxiv.org/abs/2407.14224v1)|null|
|**2024-07-19**|**Enhancing Data-Limited Graph Neural Networks by Actively Distilling Knowledge from Large Language Models**|Quan Li et.al.|[2407.13989v1](http://arxiv.org/abs/2407.13989v1)|null|
|**2024-07-18**|**A Comprehensive Review of Recommender Systems: Transitioning from Theory to Practice**|Shaina Raza et.al.|[2407.13699v1](http://arxiv.org/abs/2407.13699v1)|null|
|**2024-07-17**|**Is Sarcasm Detection A Step-by-Step Reasoning Process in Large Language Models?**|Ben Yao et.al.|[2407.12725v1](http://arxiv.org/abs/2407.12725v1)|null|
|**2024-07-17**|**Subgraph-Aware Training of Text-based Methods for Knowledge Graph Completion**|Youmin Ko et.al.|[2407.12703v3](http://arxiv.org/abs/2407.12703v3)|null|
|**2024-07-17**|**Abstraction Alignment: Comparing Model and Human Conceptual Relationships**|Angie Boggust et.al.|[2407.12543v1](http://arxiv.org/abs/2407.12543v1)|[link](https://github.com/mitvis/abstraction-alignment)|
|**2024-07-17**|**Struct-X: Enhancing Large Language Models Reasoning with Structured Data**|Xiaoyu Tan et.al.|[2407.12522v1](http://arxiv.org/abs/2407.12522v1)|null|
|**2024-07-17**|**Explainable Biomedical Hypothesis Generation via Retrieval Augmented Generation enabled Large Language Models**|Alexander R. Pelletier et.al.|[2407.12888v1](http://arxiv.org/abs/2407.12888v1)|[link](https://github.com/pinglab-utils/rugged)|
|**2024-07-16**|**A Comprehensive Evaluation of Large Language Models on Temporal Event Forecasting**|He Chang et.al.|[2407.11638v1](http://arxiv.org/abs/2407.11638v1)|null|
|**2024-07-16**|**Learning on Graphs with Large Language Models(LLMs): A Deep Dive into Model Robustness**|Kai Guo et.al.|[2407.12068v1](http://arxiv.org/abs/2407.12068v1)|null|
|**2024-07-16**|**CIC-BART-SSA: Controllable Image Captioning with Structured Semantic Augmentation**|Kalliopi Basioti et.al.|[2407.11393v2](http://arxiv.org/abs/2407.11393v2)|[link](https://github.com/SamsungLabs/CIC-BART-SSA)|
|**2024-07-15**|**Think-on-Graph 2.0: Deep and Interpretable Large Language Model Reasoning with Knowledge Graph-guided Retrieval**|Shengjie Ma et.al.|[2407.10805v1](http://arxiv.org/abs/2407.10805v1)|null|
|**2024-07-15**|**Graphusion: Leveraging Large Language Models for Scientific Knowledge Graph Fusion and Construction in NLP Education**|Rui Yang et.al.|[2407.10794v1](http://arxiv.org/abs/2407.10794v1)|[link](https://github.com/irenezihuili/cgprompt)|
|**2024-07-15**|**GraphEval: A Knowledge-Graph Based LLM Hallucination Evaluation Framework**|Hannah Sansford et.al.|[2407.10793v1](http://arxiv.org/abs/2407.10793v1)|null|
|**2024-07-15**|**Scaling 3D Reasoning with LMMs to Large Robot Mission Environments Using Datagraphs**|W. J. Meijer et.al.|[2407.10743v1](http://arxiv.org/abs/2407.10743v1)|null|
|**2024-07-14**|**AutoGRAMS: Autonomous Graphical Agent Modeling Software**|Ben Krause et.al.|[2407.10049v1](http://arxiv.org/abs/2407.10049v1)|[link](https://github.com/autograms/autograms)|
|**2024-07-13**|**FarFetched: Entity-centric Reasoning and Claim Validation for the Greek Language based on Textually Represented Environments**|Dimitris Papadopoulos et.al.|[2407.09888v1](http://arxiv.org/abs/2407.09888v1)|[link](https://github.com/lighteternal/farfetched_nlp)|
|**2024-07-12**|**GOFA: A Generative One-For-All Model for Joint Graph Language Modeling**|Lecheng Kong et.al.|[2407.09709v1](http://arxiv.org/abs/2407.09709v1)|[link](https://github.com/jiaruifeng/gofa)|
|**2024-07-12**|**Human-like Episodic Memory for Infinite Context LLMs**|Zafeirios Fountas et.al.|[2407.09450v1](http://arxiv.org/abs/2407.09450v1)|null|
|**2024-07-12**|**The $Î¼\mathcal{G}$ Language for Programming Graph Neural Networks**|Matteo Belenchia et.al.|[2407.09441v1](http://arxiv.org/abs/2407.09441v1)|null|
|**2024-07-12**|**Towards More Trustworthy and Interpretable LLMs for Code through Syntax-Grounded Explanations**|David N. Palacio et.al.|[2407.08983v1](http://arxiv.org/abs/2407.08983v1)|null|
|**2024-07-12**|**Domain-Hierarchy Adaptation via Chain of Iterative Reasoning for Few-shot Hierarchical Text Classification**|Ke Ji et.al.|[2407.08959v1](http://arxiv.org/abs/2407.08959v1)|null|
|**2024-07-11**|**Cloud Atlas: Efficient Fault Localization for Cloud Systems using Language Models and Causal Insight**|Zhiqiang Xie et.al.|[2407.08694v1](http://arxiv.org/abs/2407.08694v1)|null|
|**2024-07-11**|**Converging Paradigms: The Synergy of Symbolic and Connectionist AI in LLM-Empowered Autonomous Agents**|Haoyi Xiong et.al.|[2407.08516v2](http://arxiv.org/abs/2407.08516v2)|null|
|**2024-07-10**|**A Comprehensive Survey on the Security of Smart Grid: Challenges, Mitigations, and Future Research Opportunities**|Arastoo Zibaeirad et.al.|[2407.07966v1](http://arxiv.org/abs/2407.07966v1)|null|
|**2024-07-10**|**Mobility VLA: Multimodal Instruction Navigation with Long-Context VLMs and Topological Graphs**|Hao-Tien Lewis Chiang et.al.|[2407.07775v2](http://arxiv.org/abs/2407.07775v2)|null|
|**2024-07-10**|**Teaching Transformers Causal Reasoning through Axiomatic Training**|Aniket Vashishtha et.al.|[2407.07612v1](http://arxiv.org/abs/2407.07612v1)|null|
|**2024-07-10**|**STAGE: Simplified Text-Attributed Graph Embeddings Using Pre-trained LLMs**|Aaron Zolnai-Lucas et.al.|[2407.12860v1](http://arxiv.org/abs/2407.12860v1)|[link](https://github.com/aaronzo/STAGE)|
|**2024-07-10**|**GLBench: A Comprehensive Benchmark for Graph with Large Language Models**|Yuhan Li et.al.|[2407.07457v2](http://arxiv.org/abs/2407.07457v2)|[link](https://github.com/nineabyss/glbench)|
|**2024-07-09**|**Decoding Climate Disagreement: A Graph Neural Network-Based Approach to Understanding Social Media Dynamics**|Ruiran Su et.al.|[2407.07038v1](http://arxiv.org/abs/2407.07038v1)|null|
|**2024-07-09**|**Graph-Based Captioning: Enhancing Visual Descriptions by Interconnecting Region Captions**|Yu-Guan Hsieh et.al.|[2407.06723v1](http://arxiv.org/abs/2407.06723v1)|null|
|**2024-07-09**|**Combining Knowledge Graphs and Large Language Models**|Amanda Kau et.al.|[2407.06564v1](http://arxiv.org/abs/2407.06564v1)|null|
|**2024-07-09**|**FuncEvalGMN: Evaluating Functional Correctness of SQL via Graph Matching Network**|Yi Zhan et.al.|[2407.14530v1](http://arxiv.org/abs/2407.14530v1)|null|
|**2024-07-08**|**MST5 -- Multilingual Question Answering over Knowledge Graphs**|Nikit Srivastava et.al.|[2407.06041v1](http://arxiv.org/abs/2407.06041v1)|[link](https://github.com/dice-group/MST5)|
|**2024-07-08**|**Enhancing Vision-Language Models with Scene Graphs for Traffic Accident Understanding**|Aaron Lohner et.al.|[2407.05910v1](http://arxiv.org/abs/2407.05910v1)|null|
|**2024-07-08**|**Affordances-Oriented Planning using Foundation Models for Continuous Vision-Language Navigation**|Jiaqi Chen et.al.|[2407.05890v1](http://arxiv.org/abs/2407.05890v1)|null|
|**2024-07-08**|**KG-FPQ: Evaluating Factuality Hallucination in LLMs with Knowledge Graph-based False Premise Questions**|Yanxu Zhu et.al.|[2407.05868v1](http://arxiv.org/abs/2407.05868v1)|[link](https://github.com/yanxuzhu/kg-fpq)|
|**2024-07-07**|**Language Models Encode Collaborative Signals in Recommendation**|Leheng Sheng et.al.|[2407.05441v1](http://arxiv.org/abs/2407.05441v1)|[link](https://github.com/lehengthu/alpharec)|
|**2024-07-07**|**LTLBench: Towards Benchmarks for Evaluating Temporal Logic Reasoning in Large Language Models**|Weizhi Tang et.al.|[2407.05434v1](http://arxiv.org/abs/2407.05434v1)|[link](https://github.com/rutatang/ltlbench)|
|**2024-07-05**|**Leveraging Graph Structures to Detect Hallucinations in Large Language Models**|Noa Nonkes et.al.|[2407.04485v1](http://arxiv.org/abs/2407.04485v1)|[link](https://github.com/noanonkes/Hallucination-Detection-in-LLMs)|
|**2024-07-05**|**AriGraph: Learning Knowledge Graph World Models with Episodic Memory for LLM Agents**|Petr Anokhin et.al.|[2407.04363v1](http://arxiv.org/abs/2407.04363v1)|[link](https://github.com/airi-institute/arigraph)|
|**2024-07-04**|**Semantic Graphs for Syntactic Simplification: A Revisit from the Age of LLM**|Peiran Yao et.al.|[2407.04067v1](http://arxiv.org/abs/2407.04067v1)|[link](https://github.com/U-Alberta/AMRS3)|
|**2024-07-04**|**Functional Faithfulness in the Wild: Circuit Discovery with Differentiable Computation Graph Pruning**|Lei Yu et.al.|[2407.03779v1](http://arxiv.org/abs/2407.03779v1)|null|
|**2024-07-03**|**BACON: Supercharge Your VLM with Bag-of-Concept Graph to Mitigate Hallucinations**|Zhantao Yang et.al.|[2407.03314v1](http://arxiv.org/abs/2407.03314v1)|null|
|**2024-07-03**|**Knowledge-based Consistency Testing of Large Language Models**|Sai Sathiesh Rajan et.al.|[2407.12830v1](http://arxiv.org/abs/2407.12830v1)|null|
|**2024-07-03**|**GraCoRe: Benchmarking Graph Comprehension and Complex Reasoning in Large Language Models**|Zike Yuan et.al.|[2407.02936v1](http://arxiv.org/abs/2407.02936v1)|[link](https://github.com/zikeyuan/gracore)|
|**2024-07-03**|**Croppable Knowledge Graph Embedding**|Yushan Zhu et.al.|[2407.02779v1](http://arxiv.org/abs/2407.02779v1)|null|
|**2024-07-02**|**Reasoning in Large Language Models: A Geometric Perspective**|Romain Cosentino et.al.|[2407.02678v1](http://arxiv.org/abs/2407.02678v1)|null|
|**2024-07-02**|**Ensuring Responsible Sourcing of Large Language Model Training Data Through Knowledge Graph Comparison**|Devam Mondal et.al.|[2407.02659v1](http://arxiv.org/abs/2407.02659v1)|null|
|**2024-07-02**|**Multi-Peptide: Multimodality Leveraged Language-Graph Learning of Peptide Properties**|Srivathsan Badrinarayanan et.al.|[2407.03380v1](http://arxiv.org/abs/2407.03380v1)|[link](https://github.com/srivathsanb14/multipeptide)|
|**2024-07-02**|**Pelican: Correcting Hallucination in Vision-LLMs via Claim Decomposition and Program of Thought Verification**|Pritish Sahu et.al.|[2407.02352v1](http://arxiv.org/abs/2407.02352v1)|null|
|**2024-07-02**|**Is Your Large Language Model Knowledgeable or a Choices-Only Cheater?**|Nishant Balepur et.al.|[2407.01992v1](http://arxiv.org/abs/2407.01992v1)|null|
|**2024-07-01**|**CRAB: Cross-environment Agent Benchmark for Multimodal Language Model Agents**|Tianqi Xu et.al.|[2407.01511v1](http://arxiv.org/abs/2407.01511v1)|[link](https://github.com/camel-ai/crab)|
|**2024-07-01**|**Dynamic Few-Shot Learning for Knowledge Graph Question Answering**|Jacopo D'Abramo et.al.|[2407.01409v1](http://arxiv.org/abs/2407.01409v1)|null|
|**2024-07-01**|**Adapting Multilingual LLMs to Low-Resource Languages with Knowledge Graphs via Adapters**|Daniil Gurgurov et.al.|[2407.01406v2](http://arxiv.org/abs/2407.01406v2)|[link](https://github.com/d-gurgurov/Injecting-Commonsense-Knowledge-into-LLMs)|
|**2024-07-01**|**SINKT: A Structure-Aware Inductive Knowledge Tracing Model with Large Language Model**|Lingyue Fu et.al.|[2407.01245v2](http://arxiv.org/abs/2407.01245v2)|null|
|**2024-07-01**|**Revisiting Random Walks for Learning on Graphs**|Jinwoo Kim et.al.|[2407.01214v1](http://arxiv.org/abs/2407.01214v1)|[link](https://github.com/jw9730/random-walk)|
|**2024-07-01**|**LLM Uncertainty Quantification through Directional Entailment Graph and Claim Level Response Augmentation**|Longchao Da et.al.|[2407.00994v2](http://arxiv.org/abs/2407.00994v2)|null|
|**2024-06-30**|**Actionable Cyber Threat Intelligence using Knowledge Graphs and Large Language Models**|Romy Fieblinger et.al.|[2407.02528v1](http://arxiv.org/abs/2407.02528v1)|null|
|**2024-06-30**|**Chain-of-Knowledge: Integrating Knowledge Reasoning into Large Language Models by Learning from Knowledge Graphs**|Yifei Zhang et.al.|[2407.00653v1](http://arxiv.org/abs/2407.00653v1)|null|
|**2024-06-29**|**BioKGBench: A Knowledge Graph Checking Benchmark of AI Agent for Biomedical Science**|Xinna Lin et.al.|[2407.00466v1](http://arxiv.org/abs/2407.00466v1)|[link](https://github.com/westlake-autolab/biokgbench.github.io)|
|**2024-06-29**|**GraphArena: Benchmarking Large Language Models on Graph Computational Problems**|Jianheng Tang et.al.|[2407.00379v1](http://arxiv.org/abs/2407.00379v1)|[link](https://github.com/squareroot3/grapharena)|
|**2024-06-29**|**Teola: Towards End-to-End Optimization of LLM-based Applications**|Xin Tan et.al.|[2407.00326v1](http://arxiv.org/abs/2407.00326v1)|null|
|**2024-06-28**|**Into the Unknown: Generating Geospatial Descriptions for New Environments**|Tzuf Paz-Argaman et.al.|[2406.19967v1](http://arxiv.org/abs/2406.19967v1)|null|
|**2024-06-27**|**Investigating How Large Language Models Leverage Internal Knowledge to Perform Complex Reasoning**|Miyoung Ko et.al.|[2406.19502v1](http://arxiv.org/abs/2406.19502v1)|[link](https://github.com/kaistai/knowledge-reasoning)|
|**2024-06-27**|**Enhancing Video-Language Representations with Structural Spatio-Temporal Alignment**|Hao Fei et.al.|[2406.19255v1](http://arxiv.org/abs/2406.19255v1)|null|
|**2024-06-27**|**TrustUQA: A Trustful Framework for Unified Structured Data Question Answering**|Wen Zhang et.al.|[2406.18916v1](http://arxiv.org/abs/2406.18916v1)|null|
|**2024-06-26**|**Fast Optimizer Benchmark**|Simon Blauth et.al.|[2406.18701v1](http://arxiv.org/abs/2406.18701v1)|[link](https://github.com/automl/fob)|
|**2024-06-26**|**Cascading Large Language Models for Salient Event Graph Generation**|Xingwei Tan et.al.|[2406.18449v1](http://arxiv.org/abs/2406.18449v1)|[link](https://github.com/xingwei-warwick/callmsae)|
|**2024-06-26**|**Sanskrit Knowledge-based Systems: Annotation and Computational Tools**|Hrishikesh Terdalkar et.al.|[2406.18276v1](http://arxiv.org/abs/2406.18276v1)|null|
|**2024-06-26**|**Multilingual Knowledge Graph Completion from Pretrained Language Models with Knowledge Constraints**|Ran Song et.al.|[2406.18085v1](http://arxiv.org/abs/2406.18085v1)|[link](https://github.com/Maxpa1n/gcplm-kgc)|
|**2024-06-26**|**AdaZeta: Adaptive Zeroth-Order Tensor-Train Adaption for Memory-Efficient Large Language Models Fine-Tuning**|Yifan Yang et.al.|[2406.18060v1](http://arxiv.org/abs/2406.18060v1)|[link](https://github.com/yifanycc/adazeta)|
|**2024-06-25**|**DARG: Dynamic Evaluation of Large Language Models via Adaptive Reasoning Graph**|Zhehao Zhang et.al.|[2406.17271v1](http://arxiv.org/abs/2406.17271v1)|[link](https://github.com/salt-nlp/darg)|
|**2024-06-25**|**CogMG: Collaborative Augmentation Between Large Language Model and Knowledge Graph**|Tong Zhou et.al.|[2406.17231v1](http://arxiv.org/abs/2406.17231v1)|[link](https://github.com/tongzhou21/CogMG)|
|**2024-06-24**|**Link Prediction with Untrained Message Passing Layers**|Lisi Qarkaxhija et.al.|[2406.16687v1](http://arxiv.org/abs/2406.16687v1)|null|
|**2024-06-24**|**CLEAR: Can Language Models Really Understand Causal Graphs?**|Sirui Chen et.al.|[2406.16605v1](http://arxiv.org/abs/2406.16605v1)|[link](https://github.com/opencausalab/clear)|
|**2024-06-24**|**KEHRL: Learning Knowledge-Enhanced Language Representations with Hierarchical Reinforcement Learning**|Dongyang Li et.al.|[2406.16374v1](http://arxiv.org/abs/2406.16374v1)|[link](https://github.com/MatNLP/KEHRL)|
|**2024-06-24**|**Prompt-Consistency Image Generation (PCIG): A Unified Framework Integrating LLMs, Knowledge Graphs, and Controllable Diffusion Models**|Yichen Sun et.al.|[2406.16333v1](http://arxiv.org/abs/2406.16333v1)|null|
|**2024-06-24**|**Graph-Augmented LLMs for Personalized Health Insights: A Case Study in Sleep Analysis**|Ajan Subramanian et.al.|[2406.16252v2](http://arxiv.org/abs/2406.16252v2)|null|
|**2024-06-23**|**GraphEval2000: Benchmarking and Improving Large Language Models on Graph Datasets**|Qiming Wu et.al.|[2406.16176v1](http://arxiv.org/abs/2406.16176v1)|null|
|**2024-06-23**|**Can LLM Graph Reasoning Generalize beyond Pattern Memorization?**|Yizhuo Zhang et.al.|[2406.15992v1](http://arxiv.org/abs/2406.15992v1)|[link](https://github.com/matthewyzhang/nlgift)|
|**2024-06-22**|**LLM-Powered Explanations: Unraveling Recommendations Through Subgraph Reasoning**|Guangsi Shi et.al.|[2406.15859v2](http://arxiv.org/abs/2406.15859v2)|null|
|**2024-06-22**|**Large Language Models for Link Stealing Attacks Against Graph Neural Networks**|Faqian Guan et.al.|[2406.16963v1](http://arxiv.org/abs/2406.16963v1)|null|
|**2024-06-21**|**Inferring Pluggable Types with Machine Learning**|Kazi Amanul Islam Siddiqui et.al.|[2406.15676v1](http://arxiv.org/abs/2406.15676v1)|null|
|**2024-06-21**|**NLP-KG: A System for Exploratory Search of Scientific Literature in Natural Language Processing**|Tim Schopf et.al.|[2406.15294v2](http://arxiv.org/abs/2406.15294v2)|[link](https://github.com/nlp-knowledge-graph/nlp-kg-webapp)|
|**2024-06-21**|**Unsupervised Extraction of Dialogue Policies from Conversations**|Makesh Narsimhan Sreedhar et.al.|[2406.15214v1](http://arxiv.org/abs/2406.15214v1)|null|
|**2024-06-21**|**Uni-Mol2: Exploring Molecular Pretraining Model at Scale**|Xiaohong Ji et.al.|[2406.14969v2](http://arxiv.org/abs/2406.14969v2)|null|
|**2024-06-20**|**Relation Extraction with Fine-Tuned Large Language Models in Retrieval Augmented Generation Frameworks**|Sefika Efeoglu et.al.|[2406.14745v2](http://arxiv.org/abs/2406.14745v2)|null|
|**2024-06-20**|**Do LLMs Have Distinct and Consistent Personality? TRAIT: Personality Testset designed for LLMs with Psychometrics**|Seungbeen Lee et.al.|[2406.14703v1](http://arxiv.org/abs/2406.14703v1)|null|

#### Abstracts
##### **Gene Regulatory Network Inference from Pre-trained Single-Cell Transcriptomics Transformer with Joint Graph Learning**
2407.18181v1 by Sindhura Kommu, Yizhi Wang, Yue Wang, Xuan Wang

Inferring gene regulatory networks (GRNs) from single-cell RNA sequencing
(scRNA-seq) data is a complex challenge that requires capturing the intricate
relationships between genes and their regulatory interactions. In this study,
we tackle this challenge by leveraging the single-cell BERT-based pre-trained
transformer model (scBERT), trained on extensive unlabeled scRNA-seq data, to
augment structured biological knowledge from existing GRNs. We introduce a
novel joint graph learning approach that combines the rich contextual
representations learned by pre-trained single-cell language models with the
structured knowledge encoded in GRNs using graph neural networks (GNNs). By
integrating these two modalities, our approach effectively reasons over boththe
gene expression level constraints provided by the scRNA-seq data and the
structured biological knowledge inherent in GRNs. We evaluate our method on
human cell benchmark datasets from the BEELINE study with cell type-specific
ground truth networks. The results demonstrate superior performance over
current state-of-the-art baselines, offering a deeper understanding of cellular
regulatory mechanisms.

æè¦ï¼å¾å®ç´°è RNA å®åº (scRNA-seq) è³ææ¨è«åºå èª¿æ§ç¶²è·¯ (GRN) æ¯ä¸é è¤éçææ°ï¼éè¦ææ¡åºå èå¶èª¿æ§äº¤äºä½ç¨ä¹éçè¤ééä¿ãå¨æ­¤ç ç©¶ä¸­ï¼æåééå©ç¨å¨å»£æ³çæªæ¨è¨ scRNA-seq è³æä¸è¨ç·´çå®ç´°è BERT åºæ¼é è¨ç·´è½æå¨æ¨¡å (scBERT)ï¼ä¾åææ­¤ææ°ï¼ä»¥æ´åç¾æ GRN ä¸­ççµæ§åçç©ç¥è­ãæåå¼å¥ä¸ç¨®æ°ç©çè¯ååå½¢å­¸ç¿æ¹æ³ï¼å®çµåäºé è¨ç·´å®ç´°èèªè¨æ¨¡åæå­¸ç¿å°çè±å¯èçµ¡è¡¨å¾µï¼ä»¥åä½¿ç¨åå½¢ç¥ç¶ç¶²è·¯ (GNN) å° GRN ä¸­ç·¨ç¢¼ççµæ§åç¥è­ãééæ´åéå©ç¨®æ¹å¼ï¼æåçåæ³ææå°å° scRNA-seq è³ææä¾çåºå è¡¨ç¾å±¤ç´ç´æå GRN ä¸­åºæççµæ§åçç©ç¥è­é²è¡æ¨çãæåä½¿ç¨ BEELINE ç ç©¶ä¸­çäººé¡ç´°èåºæºè³æéï¼ä»¥åç´°èé¡åç¹å®çåºæ¬äºå¯¦ç¶²è·¯ï¼ä¾è©ä¼°æåçæ¹æ³ãçµæè­æå¶æè½åªæ¼ç®åæåé²çåºæºï¼æä¾äºå°ç´°èèª¿æ§æ©å¶çæ´æ·±å¥çè§£ã

##### **MathViz-E: A Case-study in Domain-Specialized Tool-Using Agents**
2407.17544v1 by Arya Bulusu, Brandon Man, Ashish Jagmohan, Aditya Vempaty, Jennifer Mari-Wyka, Deepak Akkil

There has been significant recent interest in harnessing LLMs to control
software systems through multi-step reasoning, planning and tool-usage. While
some promising results have been obtained, application to specific domains
raises several general issues including the control of specialized domain
tools, the lack of existing datasets for training and evaluation, and the
non-triviality of automated system evaluation and improvement. In this paper,
we present a case-study where we examine these issues in the context of a
specific domain. Specifically, we present an automated math visualizer and
solver system for mathematical pedagogy. The system orchestrates mathematical
solvers and math graphing tools to produce accurate visualizations from simple
natural language commands. We describe the creation of specialized data-sets,
and also develop an auto-evaluator to easily evaluate the outputs of our system
by comparing them to ground-truth expressions. We have open sourced the
data-sets and code for the proposed system.

æè¦ï¼æè¿ï¼äººä»¬å¯¹å©ç¨å¤§åè¯­è¨æ¨¡å (LLM) æ¥éè¿å¤æ­¥éª¤æ¨çãè§ååå·¥å·ä½¿ç¨æ¥æ§å¶è½¯ä»¶ç³»ç»äº§çäºæå¤§çå´è¶£ãè½ç¶å·²ç»åå¾äºä¸äºæå¸æçç»æï¼ä½åºç¨äºç¹å®é¢åä¼å¼åå ä¸ªæ®éæ§é®é¢ï¼åæ¬å¯¹ä¸ä¸é¢åå·¥å·çæ§å¶ãç¼ºä¹ç¨äºè®­ç»åè¯ä¼°çç°ææ°æ®éï¼ä»¥åèªå¨åç³»ç»è¯ä¼°åæ¹è¿çéå¹³å¡æ§ãå¨æ¬æä¸­ï¼æä»¬æåºäºä¸ä¸ªæ¡ä¾ç ç©¶ï¼å¶ä¸­æä»¬ç ç©¶äºç¹å®é¢åèæ¯ä¸çè¿äºé®é¢ãå·ä½æ¥è¯´ï¼æä»¬å±ç¤ºäºä¸ä¸ªç¨äºæ°å­¦æè²çèªå¨åæ°å­¦å¯è§åå¨åæ±è§£å¨ç³»ç»ãè¯¥ç³»ç»åè°æ°å­¦æ±è§£å¨åæ°å­¦ç»å¾å·¥å·ï¼ä»¥æ ¹æ®ç®åçèªç¶è¯­è¨å½ä»¤çæåç¡®çå¯è§åææãæä»¬æè¿°äºä¸é¨æ°æ®éçåå»ºï¼è¿å¼åäºä¸ä¸ªèªå¨è¯ä¼°å¨ï¼éè¿å°æä»¬çç³»ç»è¾åºä¸çå®è¡¨è¾¾å¼è¿è¡æ¯è¾ï¼è½»æ¾è¯ä¼°å¶è¾åºãæä»¬å·²ç»å¼æºäºææè®®ç³»ç»çä»£ç åæ°æ®éã

##### **Ranking protein-protein models with large language models and graph neural networks**
2407.16375v1 by Xiaotong Xu, Alexandre M. J. J. Bonvin

Protein-protein interactions (PPIs) are associated with various diseases,
including cancer, infections, and neurodegenerative disorders. Obtaining
three-dimensional structural information on these PPIs serves as a foundation
to interfere with those or to guide drug design. Various strategies can be
followed to model those complexes, all typically resulting in a large number of
models. A challenging step in this process is the identification of good models
(near-native PPI conformations) from the large pool of generated models. To
address this challenge, we previously developed DeepRank-GNN-esm, a graph-based
deep learning algorithm for ranking modelled PPI structures harnessing the
power of protein language models. Here, we detail the use of our software with
examples. DeepRank-GNN-esm is freely available at
https://github.com/haddocking/DeepRank-GNN-esm

æè¦ï¼èç½-èç½äº¤äºä½ç¨ (PPI) èåç¨®ç¾çç¸éï¼åæ¬ççãææåç¥ç¶éåæ§ç¾çãåå¾éäº PPI çä¸ç¶­çµæ§è³è¨ï¼ä½çºå¹²æ¾å®åæå¼å°è¥ç©è¨­è¨çåºç¤ãå¯ä»¥éµå¾ªåç¨®ç­ç¥ä¾å»ºæ¨¡éäºè¤åé«ï¼ææéäºç­ç¥éå¸¸æç¢çå¤§éçæ¨¡åãæ­¤éç¨ä¸­çææ°æ§æ­¥é©ï¼æ¯å¾å¤§éç¢ççæ¨¡åä¸­æ¾åºå¥½çæ¨¡åï¼æ¥è¿åç PPI æ§è±¡ï¼ãçºäºæå°éåææ°ï¼æåä¹åéç¼äº DeepRank-GNN-esmï¼éæ¯ä¸ç¨®åºæ¼åå½¢çæ·±åº¦å­¸ç¿æ¼ç®æ³ï¼ç¨æ¼å°å»ºæ¨¡ç PPI çµæ§é²è¡æåï¼å©ç¨èç½è³ªèªè¨æ¨¡åçåéãå¨éè£¡ï¼æåè©³ç´°èªªæäºæåè»é«çä½¿ç¨ç¯ä¾ãDeepRank-GNN-esm å¯å¨ https://github.com/haddocking/DeepRank-GNN-esm åè²»åå¾

##### **PhenoFlow: A Human-LLM Driven Visual Analytics System for Exploring Large and Complex Stroke Datasets**
2407.16329v1 by Jaeyoung Kim, Sihyeon Lee, Hyeon Jeon, Keon-Joo Lee, Hee-Joon Bae, Bohyoung Kim, Jinwook Seo

Acute stroke demands prompt diagnosis and treatment to achieve optimal
patient outcomes. However, the intricate and irregular nature of clinical data
associated with acute stroke, particularly blood pressure (BP) measurements,
presents substantial obstacles to effective visual analytics and
decision-making. Through a year-long collaboration with experienced
neurologists, we developed PhenoFlow, a visual analytics system that leverages
the collaboration between human and Large Language Models (LLMs) to analyze the
extensive and complex data of acute ischemic stroke patients. PhenoFlow
pioneers an innovative workflow, where the LLM serves as a data wrangler while
neurologists explore and supervise the output using visualizations and natural
language interactions. This approach enables neurologists to focus more on
decision-making with reduced cognitive load. To protect sensitive patient
information, PhenoFlow only utilizes metadata to make inferences and synthesize
executable codes, without accessing raw patient data. This ensures that the
results are both reproducible and interpretable while maintaining patient
privacy. The system incorporates a slice-and-wrap design that employs temporal
folding to create an overlaid circular visualization. Combined with a linear
bar graph, this design aids in exploring meaningful patterns within irregularly
measured BP data. Through case studies, PhenoFlow has demonstrated its
capability to support iterative analysis of extensive clinical datasets,
reducing cognitive load and enabling neurologists to make well-informed
decisions. Grounded in long-term collaboration with domain experts, our
research demonstrates the potential of utilizing LLMs to tackle current
challenges in data-driven clinical decision-making for acute ischemic stroke
patients.

æè¦ï¼<paragraph>æ¥æ§ä¸­é¢¨éè¦è¿éè¨ºæ·åæ²»çï¼æè½éå°æä½³ççäººæ²»ççµæãç¶èï¼èæ¥æ§ä¸­é¢¨ç¸éçè¨åºè³æè¤éä¸ä¸è¦åï¼ç¹å¥æ¯è¡å£ (BP) æ¸¬éï¼å°ææçè¦è¦ºåæåæ±ºç­å¶å®æ§æéå¤§éç¤ãééèç¶é©è±å¯çç¥ç¶ç§é«å¸«é·éä¸å¹´çåä½ï¼æåéç¼äº PhenoFlowï¼éæ¯ä¸åè¦è¦ºåæç³»çµ±ï¼å©ç¨äººèå¤§åèªè¨æ¨¡å (LLM) ä¹éçåä½ä¾åææ¥æ§ç¼ºè¡æ§ä¸­é¢¨æ£èçå»£æ³ä¸è¤éè³æãPhenoFlow éåµäºä¸ç¨®åµæ°çå·¥ä½æµç¨ï¼å¶ä¸­ LLM æä»»è³ææ´çå¡ï¼èç¥ç¶ç§é«å¸«åä½¿ç¨è¦è¦ºååèªç¶èªè¨äºåä¾æ¢ç´¢åç£ç£è¼¸åºãéç¨®æ¹æ³ä½¿ç¥ç¶ç§é«å¸«è½å¤ æ´å°æ³¨æ¼æ±ºç­å¶å®ï¼åæéä½èªç¥è² æãçºäºä¿è­·ææççäººè³è¨ï¼PhenoFlow åå©ç¨åè³æé²è¡æ¨è«ä¸¦åæå¯å·è¡ç¨å¼ç¢¼ï¼èä¸æå­ååå§çäººè³æãéç¢ºä¿äºçµææ¢å¯éç¾åå¯è§£éï¼åæç¶­è­·çäººçé±ç§ãè©²ç³»çµ±æ¡ç¨åæ®µååè£è¨­è¨ï¼æ¡ç¨æéæºçä¾å»ºç«çå çåå½¢è¦è¦ºåãçµåç·æ§é·æ¢åï¼æ­¤è¨­è¨æå©æ¼æ¢ç´¢ä¸è¦åæ¸¬éè¡å£è³æä¸­çææç¾©æ¨¡å¼ãééæ¡ä¾ç ç©¶ï¼PhenoFlow å·²è­æå¶æ¯æ´å°å»£æ³è¨åºè³æéé²è¡åè¦åæçè½åï¼éä½èªç¥è² æä¸¦ä½¿ç¥ç¶ç§é«å¸«è½å¤ ååºææºçæ±ºç­ãæåçç ç©¶ä»¥èé åå°å®¶é·æåä½çºåºç¤ï¼è­æäºå©ç¨ LLM ä¾æå°ç¶åæ¥æ§ç¼ºè¡æ§ä¸­é¢¨æ£èè³æé©åè¨åºæ±ºç­å¶å®ææ°çæ½åã</paragraph>

##### **Graph-Structured Speculative Decoding**
2407.16207v1 by Zhuocheng Gong, Jiahao Liu, Ziyue Wang, Pengfei Wu, Jingang Wang, Xunliang Cai, Dongyan Zhao, Rui Yan

Speculative decoding has emerged as a promising technique to accelerate the
inference of Large Language Models (LLMs) by employing a small language model
to draft a hypothesis sequence, which is then validated by the LLM. The
effectiveness of this approach heavily relies on the balance between
performance and efficiency of the draft model. In our research, we focus on
enhancing the proportion of draft tokens that are accepted to the final output
by generating multiple hypotheses instead of just one. This allows the LLM more
options to choose from and select the longest sequence that meets its
standards. Our analysis reveals that hypotheses produced by the draft model
share many common token sequences, suggesting a potential for optimizing
computation. Leveraging this observation, we introduce an innovative approach
utilizing a directed acyclic graph (DAG) to manage the drafted hypotheses. This
structure enables us to efficiently predict and merge recurring token
sequences, vastly reducing the computational demands of the draft model. We
term this approach Graph-structured Speculative Decoding (GSD). We apply GSD
across a range of LLMs, including a 70-billion parameter LLaMA-2 model, and
observe a remarkable speedup of 1.73$\times$ to 1.96$\times$, significantly
surpassing standard speculative decoding.

æè¦ï¼<paragraph>æ¨æ¸¬æ§è§£ç¢¼å·²æçºä¸ç¨®æåéçæè¡ï¼å¯ééä½¿ç¨å°åèªè¨æ¨¡åèµ·èåè¨­åºåï¼ç¶å¾ç±å¤§åèªè¨æ¨¡å (LLM) é©è­è©²åºåï¼å¾èå éå¤§åèªè¨æ¨¡å (LLM) çæ¨çãæ­¤æ¹æ³çæææ§å¨å¾å¤§ç¨åº¦ä¸åæ±ºæ¼èç¨¿æ¨¡åçæ§è½åæçä¹éçå¹³è¡¡ãå¨æåçç ç©¶ä¸­ï¼æåå°æ³¨æ¼ééçæå¤ååè¨­èä¸æ¯åªçæä¸ååè¨­ä¾æé«è¢«æ¥åçºæçµè¼¸åºçèç¨¿ä»¤ççæ¯ä¾ãéåè¨± LLM å¾ä¸­é¸ææ´å¤é¸é ï¼ä¸¦é¸æç¬¦åå¶æ¨æºçæé·åºåãæåçåæè¡¨æï¼èç¨¿æ¨¡åç¢ççåè¨­å±äº«è¨±å¤å¬å±ä»¤çåºåï¼éè¡¨æåªåè¨ç®çå¯è½æ§ãå©ç¨éä¸è§å¯çµæï¼æåå¼å¥äºä¸ç¨®åµæ°çæ¹æ³ï¼å©ç¨æåç¡ç°å (DAG) ä¾ç®¡çå·²ç·¨å¶çåè¨­ãéç¨®çµæ§ä½¿æåè½å¤ ææå°é æ¸¬ååä½µéè¤çä»¤çåºåï¼å¾èå¤§å¤§éä½äºèç¨¿æ¨¡åçè¨ç®éæ±ãæåå°éç¨®æ¹æ³ç¨±çºåçµæ§æ¨æ¸¬æ§è§£ç¢¼ (GSD)ãæåå° GSD æç¨æ¼ä¸ç³»å LLMï¼åæ¬ä¸å 700 ååæ¸ç LLaMA-2 æ¨¡åï¼ä¸¦è§å¯å°é¡¯èçå éï¼å¾ 1.73 åå° 1.96 åï¼é¡¯èè¶éæ¨æºæ¨æ¸¬æ§è§£ç¢¼ã</paragraph>

##### **Finetuning Generative Large Language Models with Discrimination Instructions for Knowledge Graph Completion**
2407.16127v1 by Yang Liu, Xiaobin Tian, Zequn Sun, Wei Hu

Traditional knowledge graph (KG) completion models learn embeddings to
predict missing facts. Recent works attempt to complete KGs in a
text-generation manner with large language models (LLMs). However, they need to
ground the output of LLMs to KG entities, which inevitably brings errors. In
this paper, we present a finetuning framework, DIFT, aiming to unleash the KG
completion ability of LLMs and avoid grounding errors. Given an incomplete
fact, DIFT employs a lightweight model to obtain candidate entities and
finetunes an LLM with discrimination instructions to select the correct one
from the given candidates. To improve performance while reducing instruction
data, DIFT uses a truncated sampling method to select useful facts for
finetuning and injects KG embeddings into the LLM. Extensive experiments on
benchmark datasets demonstrate the effectiveness of our proposed framework.

æè¦ï¼å³çµ±ç¥è­åè­ï¼KGï¼å®æåè½æ¨¡åå­¸ç¿åµå¥ï¼ä»¥é æ¸¬éºå¤±çäºå¯¦ãæè¿çå·¥ä½åè©¦ä»¥å¤§åèªè¨æ¨¡åï¼LLMï¼ä»¥æå­çæçæ¹å¼å®æ KGãç¶èï¼ä»åéè¦å° LLM çè¼¸åºåºç¤å»ºç«å¨ KG å¯¦é«ä¸ï¼éä¸å¯é¿åå°æå¸¶ä¾é¯èª¤ãå¨æ¬æä¸­ï¼æåæåºäºä¸åå¾®èª¿æ¡æ¶ DIFTï¼æ¨å¨éæ¾ LLM ç KG å®æåè½ï¼ä¸¦é¿ååºç¤é¯èª¤ãçµ¦å®ä¸åä¸å®æ´çäºå¯¦ï¼DIFT ä½¿ç¨ä¸åè¼éç´æ¨¡åä¾ç²å¾åé¸å¯¦é«ï¼ä¸¦å¾®èª¿ä¸å LLMï¼ä¸¦ä½¿ç¨è¾¨å¥æä»¤å¾çµ¦å®çåé¸é ä¸­é¸ææ­£ç¢ºçå¯¦é«ãçºäºå¨æ¸å°æä»¤æ¸æçåææåæè½ï¼DIFT ä½¿ç¨ä¸åæªæ·æ½æ¨£æ¹æ³ä¾é¸ææç¨çäºå¯¦ä»¥é²è¡å¾®èª¿ï¼ä¸¦å° KG åµå¥æ³¨å¥å° LLM ä¸­ãå¨åºæºè³æéä¸çå»£æ³å¯¦é©è­æäºæåæåºçæ¡æ¶çæææ§ã

##### **Unsupervised Robust Cross-Lingual Entity Alignment via Joint Modeling of Entity and Relation Texts**
2407.15588v1 by Soojin Yoon, Sungho Ko, Tongyoung Kim, SeongKu Kang, Jinyoung Yeo, Dongha Lee

Cross-lingual entity alignment (EA) enables the integration of multiple
knowledge graphs (KGs) across different languages, providing users with
seamless access to diverse and comprehensive knowledge.Existing methods, mostly
supervised, face challenges in obtaining labeled entity pairs. To address this,
recent studies have shifted towards a self-supervised and unsupervised
frameworks. Despite their effectiveness, these approaches have limitations: (1)
they mainly focus on entity features, neglecting the semantic information of
relations, (2) they assume isomorphism between source and target graphs,
leading to noise and reduced alignment accuracy, and (3) they are susceptible
to noise in the textual features, especially when encountering inconsistent
translations or Out-Of-Vocabulary (OOV) problems.
  In this paper, we propose ERAlign, an unsupervised and robust cross-lingual
EA framework that jointly performs Entity-level and Relation-level Alignment
using semantic textual features of relations and entities. Its refinement
process iteratively enhances results by fusing entity-level and relation-level
alignments based on neighbor triple matching. The additional verification
process examines the entities' neighbor triples as the linearized text. This
\textit{Align-and-Verify} pipeline that rigorously assesses alignment results,
achieving near-perfect alignment even in the presence of noisy textual features
of entities. Our extensive experiments demonstrate that robustness and general
applicability of \proposed improved the accuracy and effectiveness of EA tasks,
contributing significantly to knowledge-oriented applications.

æè¦ï¼è·¨èªè¨å¯¦é«å°é½ (EA) è½å¤ æ´åä¸åèªè¨ä¸­çå¤åç¥è­åè­ (KG)ï¼è®ä½¿ç¨èè½ç¡ç¸«å°å­åå¤åä¸å¨é¢çç¥è­ãç¾ææ¹æ³å¤§å¤æ¯æç£ç£çï¼å¨åå¾æ¨è¨å¯¦é«å°æé¢è¨ææ°ãçºäºè§£æ±ºéååé¡ï¼æè¿çç ç©¶å·²è½åèªç£ç£åç¡ç£ç£çæ¶æ§ãåç®¡éäºæ¹æ³å¾ææï¼ä½å®åæä»¥ä¸éå¶ï¼(1) å®åä¸»è¦éæ³¨å¯¦é«ç¹å¾µï¼å¿½ç¥éä¿çèªç¾©è³è¨ï¼(2) å®ååè¨­ä¾æºåè­åç®æ¨åè­ä¹éåæ§ï¼å°è´éè¨åå°é½æºç¢ºåº¦éä½ï¼(3) å®åå®¹æåå°æå­ç¹å¾µä¸­çéè¨å½±é¿ï¼ç¹å¥æ¯å¨éå°ä¸ä¸è´çç¿»è­¯æè©å½å¤åé¡ (OOV) æã
å¨æ¬æä¸­ï¼æåæåº ERAlignï¼ä¸åç¡ç£ç£ä¸ç©©å¥çè·¨èªè¨ EA æ¶æ§ï¼å®ä½¿ç¨éä¿åå¯¦é«çèªç¾©æå­ç¹å¾µï¼åæå·è¡å¯¦é«å±¤ç´åéä¿å±¤ç´å°é½ãå®çç²¾çç¨åºééæ ¹æé°æ¥ä¸åçµå¹éèåå¯¦é«å±¤ç´åéä¿å±¤ç´å°é½ï¼åè¦å¢å¼·çµæãé¡å¤çé©è­ç¨åºå°å¯¦é«çé°æ¥ä¸åçµè¦çºç·æ§åæå­é²è¡æª¢æ¥ãéåå´æ ¼è©ä¼°å°é½çµæçãå°é½åé©è­ãç®¡ç·ï¼å³ä½¿å¨å­å¨å¯¦é«çéè¨æå­ç¹å¾µæä¹è½éæè¿ä¹å®ç¾çå°é½ãæåå»£æ³çå¯¦é©è­æï¼\proposed çç©©å¥æ§åæ®éé©ç¨æ§æåäº EA ä»»åçæºç¢ºåº¦åæææ§ï¼å°ç¥è­å°åæç¨ç¨å¼æé¡¯èçè²¢ç»ã

##### **Pre-Training and Prompting for Few-Shot Node Classification on Text-Attributed Graphs**
2407.15431v1 by Huanjing Zhao, Beining Yang, Yukuo Cen, Junyu Ren, Chenhui Zhang, Yuxiao Dong, Evgeny Kharlamov, Shu Zhao, Jie Tang

The text-attributed graph (TAG) is one kind of important real-world
graph-structured data with each node associated with raw texts. For TAGs,
traditional few-shot node classification methods directly conduct training on
the pre-processed node features and do not consider the raw texts. The
performance is highly dependent on the choice of the feature pre-processing
method. In this paper, we propose P2TAG, a framework designed for few-shot node
classification on TAGs with graph pre-training and prompting. P2TAG first
pre-trains the language model (LM) and graph neural network (GNN) on TAGs with
self-supervised loss. To fully utilize the ability of language models, we adapt
the masked language modeling objective for our framework. The pre-trained model
is then used for the few-shot node classification with a mixed prompt method,
which simultaneously considers both text and graph information. We conduct
experiments on six real-world TAGs, including paper citation networks and
product co-purchasing networks. Experimental results demonstrate that our
proposed framework outperforms existing graph few-shot learning methods on
these datasets with +18.98% ~ +35.98% improvements.

æè¦ï¼ææ¬å±æ§å¾ (TAG) æ¯ä¸ç§éè¦ççå®ä¸çå¾ç»æåæ°æ®ï¼å¶ä¸­æ¯ä¸ªèç¹é½ä¸åå§ææ¬ç¸å³èãå¯¹äº TAGï¼ä¼ ç»çå°æ°éå¤´èç¹åç±»æ¹æ³ç´æ¥å¯¹é¢å¤ççèç¹ç¹å¾è¿è¡è®­ç»ï¼èä¸èèåå§ææ¬ãæ§è½å¨å¾å¤§ç¨åº¦ä¸åå³äºç¹å¾é¢å¤çæ¹æ³çéæ©ãå¨æ¬æä¸­ï¼æä»¬æåºäº P2TAGï¼è¿æ¯ä¸ä¸ªä¸ä¸º TAG ä¸çå°æ°éå¤´èç¹åç±»è®¾è®¡çæ¡æ¶ï¼å·æå¾é¢è®­ç»åæç¤ºãP2TAG é¦åä½¿ç¨èªæçç£æå¤±å¯¹ TAG ä¸çè¯­è¨æ¨¡å (LM) åå¾ç¥ç»ç½ç» (GNN) è¿è¡é¢è®­ç»ãä¸ºäºååå©ç¨è¯­è¨æ¨¡åçè½åï¼æä»¬ä¸ºæä»¬çæ¡æ¶è°æ´äºæ©ç è¯­è¨å»ºæ¨¡ç®æ ãç¶åä½¿ç¨é¢è®­ç»æ¨¡åè¿è¡å°æ°éå¤´èç¹åç±»ï¼éç¨æ··åæç¤ºæ¹æ³ï¼åæ¶èèææ¬åå¾ä¿¡æ¯ãæä»¬å¯¹å­ä¸ªçå®ä¸çç TAG è¿è¡äºå®éªï¼åæ¬è®ºæå¼ç¨ç½ç»åäº§åå±åè´­ä¹°ç½ç»ãå®éªç»æè¡¨æï¼æä»¬æåºçæ¡æ¶å¨è¿äºæ°æ®éä¸ä¼äºç°æçå¾å°æ°éå¤´å­¦ä¹ æ¹æ³ï¼æ¹è¿äº +18.98% ~ +35.98%ã

##### **LLMExplainer: Large Language Model based Bayesian Inference for Graph Explanation Generation**
2407.15351v2 by Jiaxing Zhang, Jiayi Liu, Dongsheng Luo, Jennifer Neville, Hua Wei

Recent studies seek to provide Graph Neural Network (GNN) interpretability
via multiple unsupervised learning models. Due to the scarcity of datasets,
current methods easily suffer from learning bias. To solve this problem, we
embed a Large Language Model (LLM) as knowledge into the GNN explanation
network to avoid the learning bias problem. We inject LLM as a Bayesian
Inference (BI) module to mitigate learning bias. The efficacy of the BI module
has been proven both theoretically and experimentally. We conduct experiments
on both synthetic and real-world datasets. The innovation of our work lies in
two parts: 1. We provide a novel view of the possibility of an LLM functioning
as a Bayesian inference to improve the performance of existing algorithms; 2.
We are the first to discuss the learning bias issues in the GNN explanation
problem.

æè¦ï¼è¿æç ç©¶è©¦åééå¤ç¨®éç£ç£å¼å­¸ç¿æ¨¡åä¾æä¾åç¥ç¶ç¶²è·¯ (GNN) çå¯è§£éæ§ãç±æ¼è³æéçç¨å°ï¼ç®åçæ¼ç®æ³å®¹æåå°å­¸ç¿åå·®çå½±é¿ãçºäºè§£æ±ºéååé¡ï¼æåå°å¤§åèªè¨æ¨¡å (LLM) ä½çºç¥è­åµå¥å° GNN è§£éç¶²è·¯ä¸­ï¼ä»¥é¿åå­¸ç¿åå·®çåé¡ãæåå° LLM ä½çºè²æ°æ¨è« (BI) æ¨¡çµæ³¨å¥ï¼ä»¥æ¸è¼å­¸ç¿åå·®ãBI æ¨¡çµçæè½å·²å¨çè«ä¸åå¯¦é©ä¸å¾å°è­å¯¦ãæåå¨åæåçå¯¦ä¸çè³æéä¸é²è¡å¯¦é©ãæåå·¥ä½çåµæ°ä¹èå¨æ¼å©é¨åï¼1. æåæä¾ LLM ä½çºè²æ°æ¨è«ä»¥æ¹åç¾ææ¼ç®æ³æè½çå¯è½æ§ä¹æ°è§é»ï¼2. æåçåè¨è« GNN è§£éåé¡ä¸­çå­¸ç¿åå·®åé¡ã

##### **Text-Augmented Multimodal LLMs for Chemical Reaction Condition Recommendation**
2407.15141v1 by Yu Zhang, Ruijie Yu, Kaipeng Zeng, Ding Li, Feng Zhu, Xiaokang Yang, Yaohui Jin, Yanyan Xu

High-throughput reaction condition (RC) screening is fundamental to chemical
synthesis. However, current RC screening suffers from laborious and costly
trial-and-error workflows. Traditional computer-aided synthesis planning (CASP)
tools fail to find suitable RCs due to data sparsity and inadequate reaction
representations. Nowadays, large language models (LLMs) are capable of tackling
chemistry-related problems, such as molecule design, and chemical logic Q\&A
tasks. However, LLMs have not yet achieved accurate predictions of chemical
reaction conditions. Here, we present MM-RCR, a text-augmented multimodal LLM
that learns a unified reaction representation from SMILES, reaction graphs, and
textual corpus for chemical reaction recommendation (RCR). To train MM-RCR, we
construct 1.2 million pair-wised Q\&A instruction datasets. Our experimental
results demonstrate that MM-RCR achieves state-of-the-art performance on two
open benchmark datasets and exhibits strong generalization capabilities on
out-of-domain (OOD) and High-Throughput Experimentation (HTE) datasets. MM-RCR
has the potential to accelerate high-throughput condition screening in chemical
synthesis.

æè¦ï¼é«ééåææ¢ä»¶ (RC) ç¯©é¸æ¯åå­¸åæä¸­çåºç¤ãç¶èï¼ç¶åç RC ç¯©é¸æéå°ç¹ç£ä¸æè²´çè©¦é¯å·¥ä½æµç¨ãå³çµ±çé»è¦è¼å©åæè¦å (CASP) å·¥å·ç¡æ³æ¾å°åé©ç RCï¼éæ¯å çºè³æç¨çä¸åæè¡¨ç¤ºä¸è¶³ãå¦ä»ï¼å¤§åèªè¨æ¨¡å (LLM) è½å¤ è§£æ±ºèåå­¸ç¸éçåé¡ï¼ä¾å¦åå­è¨­è¨ååå­¸éè¼¯åç­ä»»åãç¶èï¼LLM å°æªéæåå­¸åææ¢ä»¶çæºç¢ºé æ¸¬ãå¨æ­¤ï¼æåæåº MM-RCRï¼ä¸åææ¬å¢å¼·çå¤æ¨¡æ LLMï¼å®å¾ SMILESãåæååææ¬èªæåº«å­¸ç¿çµ±ä¸çåæè¡¨ç¤ºï¼ä»¥é²è¡åå­¸åææ¨è¦ (RCR)ãçºäºè¨ç·´ MM-RCRï¼æåå»ºæ§äº 120 è¬å°éå°çåç­æä»¤è³æéãæåçå¯¦é©çµæè­æï¼MM-RCR å¨å©åéæ¾åºæºè³æéä¸éå°äºæåé²çæè½ï¼ä¸¦å¨é åå¤ (OOD) åé«ééå¯¦é© (HTE) è³æéä¸å±ç¾åºå¼·å¤§çæ¦åè½åãMM-RCR æå¯è½å éåå­¸åæä¸­çé«ééæ¢ä»¶ç¯©é¸ã

##### **On the Design and Analysis of LLM-Based Algorithms**
2407.14788v1 by Yanxi Chen, Yaliang Li, Bolin Ding, Jingren Zhou

We initiate a formal investigation into the design and analysis of LLM-based
algorithms, i.e. algorithms that contain one or multiple calls of large
language models (LLMs) as sub-routines and critically rely on the capabilities
of LLMs. While LLM-based algorithms, ranging from basic LLM calls with prompt
engineering to complicated LLM-powered agent systems and compound AI systems,
have achieved remarkable empirical success, the design and optimization of them
have mostly relied on heuristics and trial-and-errors, which is largely due to
a lack of formal and analytical study for these algorithms. To fill this gap,
we start by identifying the computational-graph representation of LLM-based
algorithms, the design principle of task decomposition, and some key
abstractions, which then facilitate our formal analysis for the accuracy and
efficiency of LLM-based algorithms, despite the black-box nature of LLMs. We
further consider parallel decomposition for a case study, providing extensive
analytical and empirical study for four concrete examples of this pattern. Our
proposed framework holds promise for advancing LLM-based algorithms, by
revealing the reasons behind curious empirical phenomena, guiding the choices
of hyperparameters, predicting the empirical performance of algorithms, and
inspiring new algorithm design. To promote further study of LLM-based
algorithms, we release our source code at
https://github.com/modelscope/agentscope/tree/main/examples/paper_llm_based_algorithm.

æè¦ï¼<paragraph>æåå°åºæ¼ LLM çæ¼ç®æ³çè¨­è¨ååæå±éæ­£å¼èª¿æ¥ï¼å³åå«ä¸åæå¤åå¤§åèªè¨æ¨¡å (LLM) ä½çºå­å¸¸å¼å¼å«çæ¼ç®æ³ï¼ä¸¦æ¥µåº¦ä¾è³´ LLM çåè½ãåç®¡åºæ¼ LLM çæ¼ç®æ³ï¼å¾å¸¶æç¤ºå·¥ç¨çåºæ¬ LLM å¼å«å°è¤éç LLM é©åçä»£çç³»çµ±åè¤åå¼ AI ç³»çµ±ï¼å·²åå¾é¡¯èçå¯¦è­æåï¼ä½å¶è¨­è¨åæä½³åå¤§å¤ä¾è³´è©¦é©æ³åé¯èª¤ï¼éå¨å¾å¤§ç¨åº¦ä¸æ¯å çºç¼ºä¹å°éäºæ¼ç®æ³çæ­£å¼ååæç ç©¶ãçºäºå¡«è£éåç©ºç½ï¼æåå¾è­å¥åºæ¼ LLM çæ¼ç®æ³çè¨ç®åè¡¨ç¤ºãä»»ååè§£çè¨­è¨ååï¼ä»¥åä¸äºééµæ½è±¡åéå§ï¼ç¶å¾ä¿é²æåå°åºæ¼ LLM çæ¼ç®æ³çæºç¢ºæ§åæçé²è¡æ­£å¼åæï¼åç®¡ LLM æ¬èº«å·æé»çç¹æ§ãæåé²ä¸æ­¥èæ®ä¸¦è¡åè§£ä½çºæ¡ä¾ç ç©¶ï¼çºæ­¤æ¨¡å¼çååå·é«ç¯ä¾æä¾å»£æ³çåæåå¯¦è­ç ç©¶ãæåæåºçæ¶æ§æææ¨é²åºæ¼ LLM çæ¼ç®æ³ï¼æ¹æ³æ¯æ­ç¤ºå¥æªçå¯¦è­ç¾è±¡èå¾çåå ãæå°è¶åæ¸çé¸æãé æ¸¬æ¼ç®æ³çå¯¦è­æè½ï¼ä¸¦æ¿ç¼æ°çæ¼ç®æ³è¨­è¨ãçºäºä¿é²å°åºæ¼ LLM çæ¼ç®æ³çé²ä¸æ­¥ç ç©¶ï¼æåå¨ https://github.com/modelscope/agentscope/tree/main/examples/paper_llm_based_algorithm/ ç¼å¸æåçåå§ç¢¼ã</paragraph>

##### **Hierarchical Windowed Graph Attention Network and a Large Scale Dataset for Isolated Indian Sign Language Recognition**
2407.14224v1 by Suvajit Patra, Arkadip Maitra, Megha Tiwari, K. Kumaran, Swathy Prabhu, Swami Punyeshwarananda, Soumitra Samanta

Automatic Sign Language (SL) recognition is an important task in the computer
vision community. To build a robust SL recognition system, we need a
considerable amount of data which is lacking particularly in Indian sign
language (ISL). In this paper, we propose a large-scale isolated ISL dataset
and a novel SL recognition model based on skeleton graph structure. The dataset
covers 2,002 daily used common words in the deaf community recorded by 20 (10
male and 10 female) deaf adult signers (contains 40033 videos). We propose a SL
recognition model namely Hierarchical Windowed Graph Attention Network (HWGAT)
by utilizing the human upper body skeleton graph structure. The HWGAT tries to
capture distinctive motions by giving attention to different body parts induced
by the human skeleton graph structure. The utility of the proposed dataset and
the usefulness of our model are evaluated through extensive experiments. We
pre-trained the proposed model on the proposed dataset and fine-tuned it across
different sign language datasets further boosting the performance of 1.10,
0.46, 0.78, and 6.84 percentage points on INCLUDE, LSA64, AUTSL and WLASL
respectively compared to the existing state-of-the-art skeleton-based models.

æè¦ï¼èªåæèª (SL) è­å¥æ¯é»è¦è¦è¦ºç¤¾ç¾¤ä¸­çéè¦ä»»åãè¦å»ºç«å¼·å¥ç SL è­å¥ç³»çµ±ï¼æåéè¦å¤§éçè³æï¼èéå¨å°åº¦æèª (ISL) ä¸­ç¹å¥ç¼ºä¹ãå¨æ¬æä¸­ï¼æåæåºä¸åå¤§è¦æ¨¡çå­¤ç« ISL è³æéï¼ä»¥åä¸ååºæ¼éª¨æ¶åçµæ§çæ°å SL è­å¥æ¨¡åãè©²è³æéæ¶µè 2,002 åè¾åç¤¾ç¾¤ä¸­å¸¸ç¨çæ¥å¸¸å®å­ï¼ç± 20 ä½ (10 ç· 10 å¥³) è¾åæäººæèªèéè£½ï¼åå« 40033 é¨å½±çï¼ãæåæåºä¸å SL è­å¥æ¨¡åï¼å³åå±¤è¦çªåæ³¨æåç¶²è·¯ (HWGAT)ï¼å©ç¨äººé«ä¸åèº«éª¨æ¶åçµæ§ãHWGAT åè©¦éééæ³¨ç±äººé«éª¨æ¶åçµæ§èªå°çä¸åèº«é«é¨ä½ä¾ææç¨ç¹çåä½ãééå»£æ³çå¯¦é©è©ä¼°ææåºçè³æéçæç¨åæåæ¨¡åçæç¨æ§ãæåå¨ææåºçè³æéä¸é è¨ç·´ææåºçæ¨¡åï¼ä¸¦å¨ä¸åçæèªè³æéä¸å¾®èª¿å®ï¼é²ä¸æ­¥æåäº INCLUDEãLSA64ãAUTSL å WLASL ä¸ 1.10ã0.46ã0.78 å 6.84 åç¾åé»çæè½ï¼åå¥èç¾æçæåé²çåºæ¼éª¨æ¶çæ¨¡åç¸æ¯ã

##### **Enhancing Data-Limited Graph Neural Networks by Actively Distilling Knowledge from Large Language Models**
2407.13989v1 by Quan Li, Tianxiang Zhao, Lingwei Chen, Junjie Xu, Suhang Wang

Graphs have emerged as critical data structures for content analysis in
various domains, such as social network analysis, bioinformatics, and
recommendation systems. Node classification, a fundamental task in this
context, is typically tackled using graph neural networks (GNNs).
Unfortunately, conventional GNNs still face challenges in scenarios with few
labeled nodes, despite the prevalence of few-shot node classification tasks in
real-world applications. To address this challenge, various approaches have
been proposed, including graph meta-learning, transfer learning, and methods
based on Large Language Models (LLMs). However, traditional meta-learning and
transfer learning methods often require prior knowledge from base classes or
fail to exploit the potential advantages of unlabeled nodes. Meanwhile,
LLM-based methods may overlook the zero-shot capabilities of LLMs and rely
heavily on the quality of generated contexts. In this paper, we propose a novel
approach that integrates LLMs and GNNs, leveraging the zero-shot inference and
reasoning capabilities of LLMs and employing a Graph-LLM-based active learning
paradigm to enhance GNNs' performance. Extensive experiments demonstrate the
effectiveness of our model in improving node classification accuracy with
considerably limited labeled data, surpassing state-of-the-art baselines by
significant margins.

æè¦ï¼åè¡¨å·²æçºåç¨®é åä¸­å§å®¹åæçééµæ¸æçµæ§ï¼ä¾å¦ç¤¾äº¤ç¶²è·¯åæãçç©è³è¨å­¸åæ¨è¦ç³»çµ±ãç¯é»åé¡æ¯æ­¤èçµ¡ä¸­çåºæ¬ä»»åï¼éå¸¸ä½¿ç¨åå½¢ç¥ç¶ç¶²è·¯ (GNN) ä¾èçãä¸å¹¸çæ¯ï¼åç®¡ç¾å¯¦ä¸çæç¨ä¸­æ®éå­å¨å°æ¨£æ¬ç¯é»åé¡ä»»åï¼ä½å³çµ±ç GNN å¨æ¨è¨ç¯é»å¾å°çææ³ä¸ä»é¢è¨ææ°ãçºäºæå°éä¸ææ°ï¼å·²æåºåç¨®æ¹æ³ï¼åæ¬åå½¢åå­¸ç¿ãé·ç§»å­¸ç¿ååºæ¼å¤§åèªè¨æ¨¡å (LLM) çæ¹æ³ãç¶èï¼å³çµ±çåå­¸ç¿åé·ç§»å­¸ç¿æ¹æ³éå¸¸éè¦ä¾èªåºç¤é¡å¥çåé©ç¥è­ï¼æèç¡æ³å©ç¨æªæ¨è¨ç¯é»çæ½å¨åªå¢ãåæï¼åºæ¼ LLM çæ¹æ³å¯è½æå¿½è¦ LLM çé¶æ¨£æ¬è½åï¼ä¸¦ä¸éåº¦ä¾è³´çæèªå¢çåè³ªãå¨æ¬æä¸­ï¼æåæåºäºä¸ç¨®æ°çæ¹æ³ï¼å®æ´åäº LLM å GNNï¼å©ç¨ LLM çé¶æ¨£æ¬æ¨è«åæ¨çè½åï¼ä¸¦æ¡ç¨åºæ¼ Graph-LLM çä¸»åå­¸ç¿ç¯ä¾ä¾å¢å¼· GNN çæè½ãå»£æ³çå¯¦é©è­æäºæåçæ¨¡åå¨æ¹é²ç¯é»åé¡æºç¢ºåº¦æ¹é¢çæææ§ï¼æ¨è¨æ¸æç¸ç¶æéï¼é¡¯èè¶è¶äºæåé²çåºæºã

##### **A Comprehensive Review of Recommender Systems: Transitioning from Theory to Practice**
2407.13699v1 by Shaina Raza, Mizanur Rahman, Safiullah Kamawal, Armin Toroghi, Ananya Raval, Farshad Navah, Amirmohammad Kazemeini

Recommender Systems (RS) play an integral role in enhancing user experiences
by providing personalized item suggestions. This survey reviews the progress in
RS inclusively from 2017 to 2024, effectively connecting theoretical advances
with practical applications. We explore the development from traditional RS
techniques like content-based and collaborative filtering to advanced methods
involving deep learning, graph-based models, reinforcement learning, and large
language models. We also discuss specialized systems such as context-aware,
review-based, and fairness-aware RS. The primary goal of this survey is to
bridge theory with practice. It addresses challenges across various sectors,
including e-commerce, healthcare, and finance, emphasizing the need for
scalable, real-time, and trustworthy solutions. Through this survey, we promote
stronger partnerships between academic research and industry practices. The
insights offered by this survey aim to guide industry professionals in
optimizing RS deployment and to inspire future research directions, especially
in addressing emerging technological and societal trends

æè¦ï¼æ¨è¦ç³»çµ± (RS) å¨æåä½¿ç¨èé«é©ä¸­æ®æ¼èä¸å¯æç¼ºçè§è²ï¼ééæä¾åäººåçååå»ºè­°ãéé èª¿æ¥åé¡§äº RS å¨ 2017 å¹´å° 2024 å¹´éçé²å±ï¼ææå°å°çè«é²å±èå¯¦éæç¨é£çµèµ·ä¾ãæåæ¢è¨äºå¾å³çµ±ç RS æè¡ï¼ä¾å¦åºæ¼å§å®¹åååéæ¿¾ï¼å°æ¶åæ·±åº¦å­¸ç¿ãåºæ¼åå½¢çæ¨¡åãå¼·åå­¸ç¿åå¤§èªè¨æ¨¡åç­åé²æ¹æ³çç¼å±ãæåä¹è¨è«äºå°éçç³»çµ±ï¼ä¾å¦æå¢æç¥ãåºæ¼è©è«åå¬å¹³æç¥ç RSãéé èª¿æ¥çä¸»è¦ç®æ¨æ¯å°çè«èå¯¦åçµåèµ·ä¾ãå®è§£æ±ºäºååé åçææ°ï¼åæ¬é»å­ååãé«çä¿å¥åéèï¼å¼·èª¿äºå°å¯æ´åãå³æåå¯ä¿¡è³´çè§£æ±ºæ¹æ¡çéæ±ãéééé èª¿æ¥ï¼æåä¿é²äºå­¸è¡ç ç©¶åç¢æ¥­å¯¦åä¹éæ´å¼·å¤§çå¤¥ä¼´éä¿ãéé èª¿æ¥æä¾çè¦è§£æ¨å¨å¼å°ç¢æ¥­å°æ¥­äººå£«åªå RS é¨ç½²ï¼ä¸¦æ¿åµæªä¾çç ç©¶æ¹åï¼ç¹å¥æ¯å¨è§£æ±ºæ°èçæè¡åç¤¾æè¶¨å¢æ¹é¢ã

##### **Is Sarcasm Detection A Step-by-Step Reasoning Process in Large Language Models?**
2407.12725v1 by Ben Yao, Yazhou Zhang, Qiuchi Li, Jing Qin

Elaborating a series of intermediate reasoning steps significantly improves
the ability of large language models (LLMs) to solve complex problems, as such
steps would evoke LLMs to think sequentially. However, human sarcasm
understanding is often considered an intuitive and holistic cognitive process,
in which various linguistic, contextual, and emotional cues are integrated to
form a comprehensive understanding of the speaker's true intention, which is
argued not be limited to a step-by-step reasoning process. To verify this
argument, we introduce a new prompting framework called SarcasmCue, which
contains four prompting strategies, $viz.$ chain of contradiction (CoC), graph
of cues (GoC), bagging of cues (BoC) and tensor of cues (ToC), which elicits
LLMs to detect human sarcasm by considering sequential and non-sequential
prompting methods. Through a comprehensive empirical comparison on four
benchmarking datasets, we show that the proposed four prompting methods
outperforms standard IO prompting, CoT and ToT with a considerable margin, and
non-sequential prompting generally outperforms sequential prompting.

æè¦ï¼ééé¡è¿°ä¸ç³»åä¸­éæ¨çæ­¥é©ï¼å¤§å¹æåå¤§åèªè¨æ¨¡å (LLM) è§£æ±ºè¤éåé¡çè½åï¼å çºéäºæ­¥é©æä¿ä½¿ LLM æé åºæèãç¶èï¼äººé¡çè«·åºçè§£éå¸¸è¢«èªçºæ¯ä¸ç¨®ç´è¦ºä¸å¨é¢çèªç¥éç¨ï¼å¶ä¸­åç¨®èªè¨ãèªå¢åæç·ç·ç´¢æ´åå¨ä¸èµ·ï¼ä»¥å¨é¢äºè§£èªªè©±èççå¯¦æåï¼éè¢«èªçºä¸åéæ¼å¾ªåºæ¼¸é²çæ¨çéç¨ãçºäºé©è­éåè«é»ï¼æåå¼å¥äºä¸åæ°çæç¤ºæ¡æ¶ï¼ç¨±çº SarcasmCueï¼å¶ä¸­åå«åç¨®æç¤ºç­ç¥ï¼å³çç¾é (CoC)ãç·ç´¢å (GoC)ãç·ç´¢è¢ (BoC) åç·ç´¢å¼µé (ToC)ï¼å®å¼ç¼ LLM ééèæ®é åºåéé åºæç¤ºæ¹æ³ä¾æª¢æ¸¬äººé¡çè«·åºãééå°åååºæºæ¸æéé²è¡å¨é¢çå¯¦è­æ¯è¼ï¼æåè¡¨æææåºçåç¨®æç¤ºæ¹æ³ä»¥ç¸ç¶å¤§çå¹åº¦åªæ¼æ¨æº IO æç¤ºãCoT å ToTï¼ä¸¦ä¸éé åºæç¤ºéå¸¸åªæ¼é åºæç¤ºã

##### **Subgraph-Aware Training of Text-based Methods for Knowledge Graph Completion**
2407.12703v3 by Youmin Ko, Hyemin Yang, Taeuk Kim, Hyunjoon Kim

Fine-tuning pre-trained language models (PLMs) has recently shown a potential
to improve knowledge graph completion (KGC). However, most PLM-based methods
encode only textual information, neglecting various topological structures of
knowledge graphs (KGs). In this paper, we empirically validate the significant
relations between the structural properties of KGs and the performance of the
PLM-based methods. To leverage the structural knowledge, we propose a
Subgraph-Aware Training framework for KGC (SATKGC) that combines (i)
subgraph-aware mini-batching to encourage hard negative sampling, and (ii) a
new contrastive learning method to focus more on harder entities and harder
negative triples in terms of the structural properties. To the best of our
knowledge, this is the first study to comprehensively incorporate the
structural inductive bias of the subgraphs into fine-tuning PLMs. Extensive
experiments on four KGC benchmarks demonstrate the superiority of SATKGC. Our
code is available.

æè¦ï¼å¾®èª¿é è¨ç·´èªè¨æ¨¡å (PLM) è¿ä¾é¡¯ç¤ºåºæ¹åç¥è­åè­å®æåè½ (KGC) çæ½åãç¶èï¼å¤§å¤æ¸åºæ¼ PLM çæ¹æ³åç·¨ç¢¼æå­è³è¨ï¼å¿½ç¥äºç¥è­åè­ (KG) çåç¨®ææ²çµæ§ãå¨æ¬æä¸­ï¼æåééç¶é©é©è­äº KG ççµæ§å±¬æ§èåºæ¼ PLM çæ¹æ³æè½ä¹éçéè¦éä¿ãçºäºå©ç¨çµæ§ç¥è­ï¼æåæåºäºä¸åç¨æ¼ KGC çå­åæç¥è¨ç·´æ¶æ§ (SATKGC)ï¼å®çµåäºï¼(i) å­åæç¥å°æ¹æ¬¡èçä»¥é¼åµå°é£è² é¢æ½æ¨£ï¼ä»¥å (ii) ä¸ç¨®æ°çå°æ¯å­¸ç¿æ¹æ³ï¼å¨çµæ§å±¬æ§æ¹é¢æ´å°æ³¨æ¼æ´å°é£çå¯¦é«åæ´å°é£çè² ä¸åçµãææåæç¥ï¼éæ¯ç¬¬ä¸åå°å­åççµæ§æ­¸ç´åèª¤å¨é¢ç´å¥ PLM å¾®èª¿çç ç©¶ãå¨åå KGC åºæºä¸çå»£æ³å¯¦é©è­æäº SATKGC çåªè¶æ§ãæåçç¨å¼ç¢¼ç¾å·²å¬éã

##### **Abstraction Alignment: Comparing Model and Human Conceptual Relationships**
2407.12543v1 by Angie Boggust, Hyemin Bang, Hendrik Strobelt, Arvind Satyanarayan

Abstraction -- the process of generalizing specific examples into broad
reusable patterns -- is central to how people efficiently process and store
information and apply their knowledge to new data. Promisingly, research has
shown that ML models learn representations that span levels of abstraction,
from specific concepts like "bolo tie" and "car tire" to more general concepts
like "CEO" and "model". However, existing techniques analyze these
representations in isolation, treating learned concepts as independent
artifacts rather than an interconnected web of abstraction. As a result,
although we can identify the concepts a model uses to produce its output, it is
difficult to assess if it has learned a human-aligned abstraction of the
concepts that will generalize to new data. To address this gap, we introduce
abstraction alignment, a methodology to measure the agreement between a model's
learned abstraction and the expected human abstraction. We quantify abstraction
alignment by comparing model outputs against a human abstraction graph, such as
linguistic relationships or medical disease hierarchies. In evaluation tasks
interpreting image models, benchmarking language models, and analyzing medical
datasets, abstraction alignment provides a deeper understanding of model
behavior and dataset content, differentiating errors based on their agreement
with human knowledge, expanding the verbosity of current model quality metrics,
and revealing ways to improve existing human abstractions.

æè¦ï¼æ½è±¡åââå°ç¹å®ç¯ä¾æ¦æ¬çºå»£æ³å¯éè¤ä½¿ç¨çæ¨¡å¼çéç¨ââæ¯äººåææèçåå²å­è³è¨ï¼ä¸¦å°å¶ç¥è­æç¨æ¼æ°è³æçæ ¸å¿ãæå¸æçæ¯ï¼ç ç©¶é¡¯ç¤º ML æ¨¡åå­¸ç¿è·¨è¶æ½è±¡å±¤ç´çè¡¨å¾µï¼å¾ãç´°é å¸¶ãåãæ±½è»è¼ªèãç­å·é«æ¦å¿µå°ãå·è¡é·ãåãæ¨¡åãç­æ´ä¸è¬çæ¦å¿µãç¶èï¼ç¾æçæè¡å­¤ç«å°åæéäºè¡¨å¾µï¼å°å­¸ç¿å°çæ¦å¿µè¦çºç¨ç«çç¢ç©ï¼èä¸æ¯æ½è±¡çç¸äºé£çµç¶²è·¯ãå æ­¤ï¼åç®¡æåå¯ä»¥è­å¥æ¨¡åç¨ä¾ç¢çå¶è¼¸åºçæ¦å¿µï¼ä½å¾é£è©ä¼°å®æ¯å¦å­¸ç¿å°æ¦å¿µçäººé¡å°é½æ½è±¡ï¼éäºæ¦å¿µå°æ¦æ¬å°æ°çè³æãçºäºè§£æ±ºéåå·®è·ï¼æåå¼å¥äºæ½è±¡å°é½ï¼ä¸ç¨®è¡¡éæ¨¡åå­¸ç¿çæ½è±¡èé æçæ½è±¡ä¹éä¸è´æ§çæ¹æ³ãæåééå°æ¨¡åè¼¸åºèäººé¡æ½è±¡åå½¢ï¼ä¾å¦èªè¨éä¿æé«çç¾çå±¤ç´çµæ§ï¼é²è¡æ¯è¼ä¾éåæ½è±¡å°é½ãå¨è§£éå½±åæ¨¡åãåºæºèªè¨æ¨¡åååæé«çè³æéçè©ä¼°ä»»åä¸­ï¼æ½è±¡å°é½æä¾äºå°æ¨¡åè¡çºåè³æéå§å®¹æ´æ·±å¥ççè§£ï¼æ ¹æèäººé¡ç¥è­çä¸è´æ§ååé¯èª¤ï¼æ´å±ç¶åæ¨¡ååè³ªææ¨çè©³ç´°ç¨åº¦ï¼ä¸¦æ­ç¤ºæ¹åç¾æäººé¡æ½è±¡çæ¹æ³ã

##### **Struct-X: Enhancing Large Language Models Reasoning with Structured Data**
2407.12522v1 by Xiaoyu Tan, Haoyu Wang, Xihe Qiu, Yuan Cheng, Yinghui Xu, Wei Chu, Yuan Qi

Structured data, rich in logical and relational information, has the
potential to enhance the reasoning abilities of large language models (LLMs).
Still, its integration poses a challenge due to the risk of overwhelming LLMs
with excessive tokens and irrelevant context information. To address this, we
propose Struct-X, a novel framework that operates through five key phases:
``read-model-fill-reflect-reason'' efficiently enabling LLMs to utilize
structured data. It begins by encoding structured data into a topological space
using graph embeddings, followed by filling in missing entity information with
knowledge retrieval modules, and filtering out irrelevant tokens via a
self-supervised module. The final phase involves constructing a topological
network with selected tokens to further reduce the total token length for more
effective LLM inference. Additionally, Struct-X includes an Auxiliary Module
trained to generate prompts, aiding LLMs in analyzing structured data.
Extensive experiments on benchmarks, including the knowledge graph
question-answer task and the long document reading comprehension task, show
that Struct-X notably improves LLM reasoning, demonstrating the effectiveness
of structured data augmentation in improving LLM inference with complex input
context.

æè¦ï¼çµæ§åè³æå¯å«éè¼¯åéä¿è³è¨ï¼ææ½åå¢å¼·å¤§åèªè¨æ¨¡å (LLM) çæ¨çè½åãåç®¡å¦æ­¤ï¼ç±æ¼éå¤ç¬¦èåç¡éèçµ¡è³è¨å¯è½æè® LLM ä¸å ªè² è·ï¼å æ­¤æ´åæ­¤é¡è³ææ§æäºä¸é ææ°ãçºäºè§£æ±ºæ­¤åé¡ï¼æåæåº Struct-Xï¼éæ¯ä¸åééäºåééµéæ®µéä½çæ°ç©æ¶æ§ï¼``è®å-å»ºæ¨¡-å¡«è£-åæ-æ¨ç''ï¼ææå°è® LLM è½å¤ å©ç¨çµæ§åè³æãå®é¦åä½¿ç¨åå½¢åµå¥å°çµæ§åè³æç·¨ç¢¼å°ææ²ç©ºéä¸­ï¼æ¥èå©ç¨ç¥è­æ·åæ¨¡çµå¡«è£éºå¤±çå¯¦é«è³è¨ï¼ä¸¦ééèªæç£ç£æ¨¡çµç¯©é¸åºç¡éç¬¦èãæå¾ä¸åéæ®µæ¶åå»ºæ§ä¸åææ²ç¶²è·¯ï¼å¶ä¸­åå«é¸å®çç¬¦èï¼ä»¥é²ä¸æ­¥æ¸å°ç¸½ç¬¦èé·åº¦ï¼ä»¥ä¾¿æ´ææå°é²è¡ LLM æ¨è«ãæ­¤å¤ï¼Struct-X éåæ¬ä¸åè¼å©æ¨¡çµï¼ç¶éè¨ç·´å¯ä»¥ç¢çæç¤ºï¼åå© LLM åæçµæ§åè³æãå¨åºæºä¸çå¤§éå¯¦é©ï¼åæ¬ç¥è­åè­åç­ä»»ååé·ç¯æä»¶é±è®çè§£ä»»åï¼é¡¯ç¤º Struct-X æé¡¯æ¹åäº LLM æ¨çï¼è­æäºçµæ§åè³ææ´åå¨æ¹å LLM æ¨è«æçæææ§ï¼ç¹å¥æ¯å¨è¼¸å¥èçµ¡è¤éçææ³ä¸ã

##### **Explainable Biomedical Hypothesis Generation via Retrieval Augmented Generation enabled Large Language Models**
2407.12888v1 by Alexander R. Pelletier, Joseph Ramirez, Irsyad Adam, Simha Sankar, Yu Yan, Ding Wang, Dylan Steinecke, Wei Wang, Peipei Ping

The vast amount of biomedical information available today presents a
significant challenge for investigators seeking to digest, process, and
understand these findings effectively. Large Language Models (LLMs) have
emerged as powerful tools to navigate this complex and challenging data
landscape. However, LLMs may lead to hallucinatory responses, making Retrieval
Augmented Generation (RAG) crucial for achieving accurate information. In this
protocol, we present RUGGED (Retrieval Under Graph-Guided Explainable disease
Distinction), a comprehensive workflow designed to support investigators with
knowledge integration and hypothesis generation, identifying validated paths
forward. Relevant biomedical information from publications and knowledge bases
are reviewed, integrated, and extracted via text-mining association analysis
and explainable graph prediction models on disease nodes, forecasting potential
links among drugs and diseases. These analyses, along with biomedical texts,
are integrated into a framework that facilitates user-directed mechanism
elucidation as well as hypothesis exploration through RAG-enabled LLMs. A
clinical use-case demonstrates RUGGED's ability to evaluate and recommend
therapeutics for Arrhythmogenic Cardiomyopathy (ACM) and Dilated Cardiomyopathy
(DCM), analyzing prescribed drugs for molecular interactions and unexplored
uses. The platform minimizes LLM hallucinations, offers actionable insights,
and improves the investigation of novel therapeutics.

æè¦ï¼<paragraph>ç¾ä»å¤§éççç©é«å­¸è³è¨å°è©¦åæææ¶åãèçåçè§£éäºç¼ç¾çç ç©¶äººå¡æ§æéå¤§ææ°ãå¤§åèªè¨æ¨¡å (LLM) å·²æçºå¨éåè¤éä¸å·ææ°æ§çè³æç°å¢ä¸­å°èªçå¼·å¤§å·¥å·ãç¶èï¼LLM å¯è½æå°è´å¹»è¦ºåæï¼éä½¿å¾æª¢ç´¢æ´å¢çæ (RAG) å°æ¼ç²å¾æºç¢ºè³è¨è³ééè¦ãå¨éååå®ä¸­ï¼æåæåº RUGGEDï¼åå½¢å°å¼å¯è§£éç¾çååçæª¢ç´¢ï¼ï¼éæ¯ä¸åå¨é¢çå·¥ä½æµç¨ï¼æ¨å¨æ¯æ´ç ç©¶äººå¡é²è¡ç¥è­æ´åååè¨­ç¢çï¼æ¾åºç¶éé©è­çé²å±è·¯å¾ãä¾èªåºçç©åç¥è­åº«çç¸éçç©é«å­¸è³è¨æééææ¬æ¢åéè¯åæåç¾çç¯é»çå¯è§£éåå½¢é æ¸¬æ¨¡åé²è¡æª¢é±ãæ´ååèåï¼é æ¸¬è¥ç©åç¾çä¹éçæ½å¨éè¯ãéäºåæé£åçç©é«å­¸ææ¬ææ´åå°ä¸åæ¶æ§ä¸­ï¼è©²æ¶æ§ä¿é²ä½¿ç¨èå°åçæ©å¶é¡æï¼ä»¥åéé RAG åç¨ç LLM é²è¡åè¨­æ¢è¨ãä¸åè¨åºä½¿ç¨æ¡ä¾å±ç¤ºäº RUGGED è©ä¼°åæ¨è¦ç¨æ¼å¿å¾å¤±å¸¸æ§å¿èçè® (ACM) åæ´å¼µåå¿èçè® (DCM) çæ²»çæ¹æ³çè½åï¼åæèæ¹è¥ç©çåå­äº¤äºä½ç¨åæªæ¢ç´¢çç¨éãéåå¹³å°å° LLM å¹»è¦ºéå°æä½ï¼æä¾å¯æä½çè¦è§£ï¼ä¸¦æ¹åæ°æ²»çæ¹æ³çç ç©¶ã</paragraph>

##### **A Comprehensive Evaluation of Large Language Models on Temporal Event Forecasting**
2407.11638v1 by He Chang, Chenchen Ye, Zhulin Tao, Jie Wu, Zhengmao Yang, Yunshan Ma, Xianglin Huang, Tat-Seng Chua

Recently, Large Language Models (LLMs) have demonstrated great potential in
various data mining tasks, such as knowledge question answering, mathematical
reasoning, and commonsense reasoning. However, the reasoning capability of LLMs
on temporal event forecasting has been under-explored. To systematically
investigate their abilities in temporal event forecasting, we conduct a
comprehensive evaluation of LLM-based methods for temporal event forecasting.
Due to the lack of a high-quality dataset that involves both graph and textual
data, we first construct a benchmark dataset, named MidEast-TE-mini. Based on
this dataset, we design a series of baseline methods, characterized by various
input formats and retrieval augmented generation(RAG) modules. From extensive
experiments, we find that directly integrating raw texts into the input of LLMs
does not enhance zero-shot extrapolation performance. In contrast,
incorporating raw texts in specific complex events and fine-tuning LLMs
significantly improves performance. Moreover, enhanced with retrieval modules,
LLM can effectively capture temporal relational patterns hidden in historical
events. Meanwhile, issues such as popularity bias and the long-tail problem
still persist in LLMs, particularly in the RAG-based method. These findings not
only deepen our understanding of LLM-based event forecasting methods but also
highlight several promising research directions.We consider that this
comprehensive evaluation, along with the identified research opportunities,
will significantly contribute to future research on temporal event forecasting
through LLMs.

æè¦ï¼è¿æï¼å¤§åè¯­è¨æ¨¡å (LLM) å¨åç§èµææ¢åä»»å¡ä¸­å±ç°åºæå¤§çæ½åï¼ä¾å¦ç¥è¯é®ç­ãæ°å­¦æ¨çåå¸¸è¯æ¨çãç¶èï¼LLM å¨æ¶é´äºä»¶é¢æµæ¹é¢çæ¨çè½åå°æªè¢«ååæ¢ç´¢ãä¸ºäºç³»ç»æ§å°è°æ¥å¶å¨æ¶é´äºä»¶é¢æµæ¹é¢çè½åï¼æä»¬å¯¹åºäº LLM çæ¶é´äºä»¶é¢æµæ¹æ³è¿è¡äºå¨é¢çè¯ä¼°ãç±äºç¼ºä¹åæ¶åå«å¾è¡¨åææ¬èµæçé«åè´¨æ°æ®éï¼æä»¬é¦åæå»ºäºä¸ä¸ªåä¸º MidEast-TE-mini çåºåæ°æ®éãåºäºæ­¤æ°æ®éï¼æä»¬è®¾è®¡äºä¸ç³»ååºçº¿æ¹æ³ï¼å¶ç¹ç¹æ¯åç§è¾å¥æ ¼å¼åæ£ç´¢å¢å¼ºçæ (RAG) æ¨¡åãä»å¹¿æ³çå®éªä¸­ï¼æä»¬åç°ç´æ¥å°åå§ææ¬æ´åå° LLM çè¾å¥ä¸­å¹¶ä¸ä¼å¢å¼ºé¶æ¬¡å­¦ä¹ å¤æ¨æ§è½ãç¸æ¯ä¹ä¸ï¼å¨ç¹å®å¤æäºä»¶ä¸­çº³å¥åå§ææ¬å¹¶å¾®è° LLM ä¼æ¾èæé«æ§è½ãæ­¤å¤ï¼éè¿æ£ç´¢æ¨¡åçå¢å¼ºï¼LLM å¯ä»¥ææå°ææéèå¨åå²äºä»¶ä¸­çæ¶é´å³ç³»æ¨¡å¼ãåæ¶ï¼è¯¸å¦æµè¡åº¦åå·®åé¿å°¾é®é¢ç­é®é¢ä»ç¶å­å¨äº LLM ä¸­ï¼å°¤å¶æ¯å¨åºäº RAG çæ¹æ³ä¸­ãè¿äºåç°ä¸ä»å æ·±äºæä»¬å¯¹åºäº LLM çäºä»¶é¢æµæ¹æ³ççè§£ï¼è¿çªåºäºå ä¸ªæåæ¯çç ç©¶æ¹åãæä»¬è®¤ä¸ºï¼è¿é¡¹å¨é¢çè¯ä¼°ï¼è¿åå·²ç¡®å®çç ç©¶æºä¼ï¼å°æå¤§å°ä¿è¿éè¿ LLM è¿è¡æ¶é´äºä»¶é¢æµçæªæ¥ç ç©¶ã

##### **Learning on Graphs with Large Language Models(LLMs): A Deep Dive into Model Robustness**
2407.12068v1 by Kai Guo, Zewen Liu, Zhikai Chen, Hongzhi Wen, Wei Jin, Jiliang Tang, Yi Chang

Large Language Models (LLMs) have demonstrated remarkable performance across
various natural language processing tasks. Recently, several LLMs-based
pipelines have been developed to enhance learning on graphs with text
attributes, showcasing promising performance. However, graphs are well-known to
be susceptible to adversarial attacks and it remains unclear whether LLMs
exhibit robustness in learning on graphs. To address this gap, our work aims to
explore the potential of LLMs in the context of adversarial attacks on graphs.
Specifically, we investigate the robustness against graph structural and
textual perturbations in terms of two dimensions: LLMs-as-Enhancers and
LLMs-as-Predictors. Through extensive experiments, we find that, compared to
shallow models, both LLMs-as-Enhancers and LLMs-as-Predictors offer superior
robustness against structural and textual attacks.Based on these findings, we
carried out additional analyses to investigate the underlying causes.
Furthermore, we have made our benchmark library openly available to facilitate
quick and fair evaluations, and to encourage ongoing innovative research in
this field.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨åç¨®èªç¶èªè¨èçä»»åä¸­å±ç¾äºåè¶çæè½ãæè¿ï¼å·²ç¶éç¼äºå¤ååºæ¼ LLM çç®¡éï¼ä»¥å¢å¼·åå½¢ä¸å·ææå­å±¬æ§çå­¸ç¿ï¼å±ç¤ºåºæåæ¯çæè½ãç¶èï¼ç¾æå¨ç¥ï¼åå½¢å®¹æåå°å°ææ§æ»æï¼è LLM å¨åå½¢å­¸ç¿ä¸­æ¯å¦è¡¨ç¾åºç©©å¥æ§ä»ä¸æ¸æ¥ãçºäºè§£æ±ºéåå·®è·ï¼æåçç ç©¶æ¨å¨æ¢ç´¢ LLM å¨åå½¢å°ææ»æä¸­çæ½åãå·é«ä¾èªªï¼æåç ç©¶äºå¨ LLM ä½çºå¢å¼·å¨å LLM ä½çºé æ¸¬å¨çå©åé¢åä¸­ï¼éå°åå½¢çµæ§åæå­æ¾åçç©©å¥æ§ãééå»£æ³çå¯¦é©ï¼æåç¼ç¾ï¼èæ·ºå±¤æ¨¡åç¸æ¯ï¼ä½çºå¢å¼·å¨ç LLM åä½çºé æ¸¬å¨ç LLM é½å°çµæ§åæå­æ»ææä¾äºåªç°çç©©å¥æ§ãåºæ¼éäºç¼ç¾ï¼æåé²è¡äºé¡å¤çåæä¾æ¢è¨å¶æ ¹æ¬åå ãæ­¤å¤ï¼æåå·²ç¶å¬éäºæåçåºæºåº«ï¼ä»¥å©æ¼å¿«éä¸å¬å¹³çè©ä¼°ï¼ä¸¦é¼åµå¨éåé åé²è¡æçºçåµæ°ç ç©¶ã

##### **CIC-BART-SSA: Controllable Image Captioning with Structured Semantic Augmentation**
2407.11393v2 by Kalliopi Basioti, Mohamed A. Abdelsalam, Federico Fancellu, Vladimir Pavlovic, Afsaneh Fazly

Controllable Image Captioning (CIC) aims at generating natural language
descriptions for an image, conditioned on information provided by end users,
e.g., regions, entities or events of interest. However, available
image-language datasets mainly contain captions that describe the entirety of
an image, making them ineffective for training CIC models that can potentially
attend to any subset of regions or relationships. To tackle this challenge, we
propose a novel, fully automatic method to sample additional focused and
visually grounded captions using a unified structured semantic representation
built on top of the existing set of captions associated with an image. We
leverage Abstract Meaning Representation (AMR), a cross-lingual graph-based
semantic formalism, to encode all possible spatio-semantic relations between
entities, beyond the typical spatial-relations-only focus of current methods.
We use this Structured Semantic Augmentation (SSA) framework to augment
existing image-caption datasets with the grounded controlled captions,
increasing their spatial and semantic diversity and focal coverage. We then
develop a new model, CIC-BART-SSA, specifically tailored for the CIC task, that
sources its control signals from SSA-diversified datasets. We empirically show
that, compared to SOTA CIC models, CIC-BART-SSA generates captions that are
superior in diversity and text quality, are competitive in controllability,
and, importantly, minimize the gap between broad and highly focused controlled
captioning performance by efficiently generalizing to the challenging highly
focused scenarios. Code is available at
https://github.com/SamsungLabs/CIC-BART-SSA.

æè¦ï¼å¯æ§å¾åæ æ³¨ (CIC) æ¨å¨çæèªç¶è¯­è¨æè¿°ä»¥æè¿°å¾åï¼æ¡ä»¶æ¯æ ¹æ®æç»ç¨æ·æä¾çèµè®¯ï¼ä¾å¦åºåãå®ä½ææå´è¶£çäºä»¶ãç¶èï¼ç°æçå¾åè¯­è¨æ°æ®éä¸»è¦åå«æè¿°æ´ä¸ªå¾åçæ æ³¨ï¼ä½¿å¶æ æ³ææè®­ç» CIC æ¨¡åï¼èè¿äºæ¨¡åæå¯è½å³æ³¨ä»»ä½åºåæå³ç³»çå­éãä¸ºäºåºå¯¹è¿ä¸ææï¼æä»¬æåºäºä¸ç§æ°é¢çãå¨èªå¨çæ¹æ³ï¼ä½¿ç¨å»ºç«å¨ä¸å¾åå³èçç°ææ æ³¨éä¹ä¸çç»ä¸ç»æåè¯­ä¹è¡¨ç¤ºæ¥æ½æ ·å¶ä»èç¦ä¸è§è§æ¥å°çæ æ³¨ãæä»¬å©ç¨è·¨è¯­è¨å¾å¼è¯­ä¹å½¢å¼åæ½è±¡æä¹è¡¨ç¤º (AMR) æ¥ç¼ç å®ä½ä¹é´ææå¯è½çç©ºé´è¯­ä¹å³ç³»ï¼èä¸ä»ä»æ¯å½åæ¹æ³ä¸­ä»å³æ³¨çç©ºé´å³ç³»ãæä»¬ä½¿ç¨è¿ç§ç»æåè¯­ä¹å¢å¼º (SSA) æ¡æ¶æ¥å¢å¼ºç°æçå¾åæ æ³¨æ°æ®éï¼ä½¿å¶æ¥å°ä¸å¯æ§çæ æ³¨ï¼å¢å å®ä»¬çç©ºé´åè¯­ä¹å¤æ ·æ§ä»¥åç¦ç¹è¦çèå´ãç¶åï¼æä»¬å¼åäºä¸ä¸ªæ°æ¨¡å CIC-BART-SSAï¼ä¸é¨éå¯¹ CIC ä»»å¡éèº«å®å¶ï¼å¶æ§å¶ä¿¡å·æ¥èª SSA å¤æ ·åçæ°æ®éãæä»¬å­ç»éªè¡¨æï¼ä¸ SOTA CIC æ¨¡åç¸æ¯ï¼CIC-BART-SSA çæçæ æ³¨å¨å¤æ ·æ§åææ¬è´¨éæ¹é¢æ´èä¸ç­¹ï¼å¨å¯æ§æ§æ¹é¢å·æç«äºåï¼èä¸éè¦çæ¯ï¼éè¿ææå°æ¨å¹¿å°å·ææææ§çé«åº¦èç¦åºæ¯ï¼æå¤§éåº¦å°ç¼©å°äºå¹¿æ³åé«åº¦èç¦çåæ§æ æ³¨æ§è½ä¹é´çå·®è·ãä»£ç å¯ä» https://github.com/SamsungLabs/CIC-BART-SSA è·å¾ã

##### **Think-on-Graph 2.0: Deep and Interpretable Large Language Model Reasoning with Knowledge Graph-guided Retrieval**
2407.10805v1 by Shengjie Ma, Chengjin Xu, Xuhui Jiang, Muzhi Li, Huaren Qu, Jian Guo

Retrieval-augmented generation (RAG) has significantly advanced large
language models (LLMs) by enabling dynamic information retrieval to mitigate
knowledge gaps and hallucinations in generated content. However, these systems
often falter with complex reasoning and consistency across diverse queries. In
this work, we present Think-on-Graph 2.0, an enhanced RAG framework that aligns
questions with the knowledge graph and uses it as a navigational tool, which
deepens and refines the RAG paradigm for information collection and
integration. The KG-guided navigation fosters deep and long-range associations
to uphold logical consistency and optimize the scope of retrieval for precision
and interoperability. In conjunction, factual consistency can be better ensured
through semantic similarity guided by precise directives. ToG${2.0}$ not only
improves the accuracy and reliability of LLMs' responses but also demonstrates
the potential of hybrid structured knowledge systems to significantly advance
LLM reasoning, aligning it closer to human-like performance. We conducted
extensive experiments on four public datasets to demonstrate the advantages of
our method compared to the baseline.

æè¦ï¼æª¢ç´¢å¢å¼·çæï¼RAGï¼ééåç¨åæè³è¨æª¢ç´¢ä¾æ¸è¼çæå§å®¹ä¸­çç¥è­å·®è·åå¹»è¦ºï¼å¤§å¹æåå¤§åèªè¨æ¨¡åï¼LLMï¼ãç¶èï¼éäºç³»çµ±å¨è¤éæ¨çåè·¨ä¸åæ¥è©¢çä¸è´æ§æ¹é¢å¸¸å¸¸è¡¨ç¾ä¸ä½³ãå¨éé å·¥ä½ä¸­ï¼æåæåºäº Think-on-Graph 2.0ï¼ä¸åå¢å¼·ç RAG æ¡æ¶ï¼å®å°åé¡èç¥è­åè­å°é½ï¼ä¸¦å°å¶ç¨ä½å°èªå·¥å·ï¼éå æ·±ä¸¦æ¹é²äº RAG å¸ç¯ï¼ç¨æ¼è³è¨æ¶éåæ´åãåç¥è­åè­å¼å°çå°èªä¿é²äºæ·±å±¤ä¸é·ç¨çéè¯ï¼ä»¥ç¶­æéè¼¯ä¸è´æ§ä¸¦æä½³åæª¢ç´¢ç¯åï¼ä»¥æé«ç²¾ç¢ºåº¦åäºæä½æ§ãåæï¼äºå¯¦ä¸è´æ§å¯ä»¥ééç±ç²¾ç¢ºæç¤ºå¼å°çèªæç¸ä¼¼æ§ç²å¾æ´å¥½çç¢ºä¿ãToG${2.0}$ ä¸åæåäº LLM åæçæºç¢ºæ§åå¯é æ§ï¼ä¹å±ç¤ºäºæ··åçµæ§åç¥è­ç³»çµ±çæ½åï¼å¯ä»¥å¤§å¹æå LLM æ¨çï¼ä½¿å¶æ´æ¥è¿äººé¡è¬çè¡¨ç¾ãæåå¨ååå¬éè³æéä¸é²è¡äºå»£æ³çå¯¦é©ï¼ä»¥å±ç¤ºæåçæ¹æ³ç¸è¼æ¼åºç·çåªå¢ã

##### **Graphusion: Leveraging Large Language Models for Scientific Knowledge Graph Fusion and Construction in NLP Education**
2407.10794v1 by Rui Yang, Boming Yang, Sixun Ouyang, Tianwei She, Aosong Feng, Yuang Jiang, Freddy Lecue, Jinghui Lu, Irene Li

Knowledge graphs (KGs) are crucial in the field of artificial intelligence
and are widely applied in downstream tasks, such as enhancing Question
Answering (QA) systems. The construction of KGs typically requires significant
effort from domain experts. Recently, Large Language Models (LLMs) have been
used for knowledge graph construction (KGC), however, most existing approaches
focus on a local perspective, extracting knowledge triplets from individual
sentences or documents. In this work, we introduce Graphusion, a zero-shot KGC
framework from free text. The core fusion module provides a global view of
triplets, incorporating entity merging, conflict resolution, and novel triplet
discovery. We showcase how Graphusion could be applied to the natural language
processing (NLP) domain and validate it in the educational scenario.
Specifically, we introduce TutorQA, a new expert-verified benchmark for graph
reasoning and QA, comprising six tasks and a total of 1,200 QA pairs. Our
evaluation demonstrates that Graphusion surpasses supervised baselines by up to
10% in accuracy on link prediction. Additionally, it achieves average scores of
2.92 and 2.37 out of 3 in human evaluations for concept entity extraction and
relation recognition, respectively.

æè¦ï¼<paragraph>ç¥è­åè­ (KG) å¨äººå·¥æºæ§é åè³ééè¦ï¼ä¸¦å»£æ³æç¨æ¼ä¸æ¸¸ä»»åï¼ä¾å¦å¢å¼·åç­ (QA) ç³»çµ±ãç¥è­åè­çå»ºæ§éå¸¸éè¦é åå°å®¶çå¤§éå·¥ä½ãæè¿ï¼å¤§åèªè¨æ¨¡å (LLM) å·²è¢«ç¨æ¼ç¥è­åè­å»ºæ§ (KGC)ï¼ç¶èï¼ç¾ææ¹æ³å¤§å¤éæ³¨å±é¨è§é»ï¼å¾åå¥å¥å­ææä»¶ä¸­æåç¥è­ä¸åçµãå¨éé å·¥ä½ä¸­ï¼æåä»ç´¹äº Graphusionï¼ä¸åå¾èªç±ææ¬ä¸­é²è¡é¶æ¬¡å­¸ç¿ç KGC æ¡æ¶ãæ ¸å¿èåæ¨¡çµæä¾ä¸åçµçå¨å±è§é»ï¼åå«å¯¦é«åä½µãè¡çªè§£æ±ºåæ°ä¸åçµç¼ç¾ãæåå±ç¤ºäºå¦ä½å° Graphusion æç¨æ¼èªç¶èªè¨èç (NLP) é åï¼ä¸¦å¨æè²å ´æ¯ä¸­é©è­å®ãå·é«ä¾èªªï¼æåä»ç´¹äº TutorQAï¼ä¸åæ°çç±å°å®¶é©è­çåè­æ¨çååç­åºæºï¼åå«å­é ä»»ååç¸½è¨ 1,200 ååç­å°ãæåçè©ä¼°è¡¨æï¼Graphusion å¨é£çµé æ¸¬çæºç¢ºåº¦ä¸æ¯ç£ç£å¼åºæºé«åº 10%ãæ­¤å¤ï¼å¨æ¦å¿µå¯¦é«æååéä¿è­å¥çäººé¡è©ä¼°ä¸­ï¼å®åå¥ç²å¾äº 3 åä¸­ç 2.92 åå 2.37 åã</paragraph>

##### **GraphEval: A Knowledge-Graph Based LLM Hallucination Evaluation Framework**
2407.10793v1 by Hannah Sansford, Nicholas Richardson, Hermina Petric Maretic, Juba Nait Saada

Methods to evaluate Large Language Model (LLM) responses and detect
inconsistencies, also known as hallucinations, with respect to the provided
knowledge, are becoming increasingly important for LLM applications. Current
metrics fall short in their ability to provide explainable decisions,
systematically check all pieces of information in the response, and are often
too computationally expensive to be used in practice. We present GraphEval: a
hallucination evaluation framework based on representing information in
Knowledge Graph (KG) structures. Our method identifies the specific triples in
the KG that are prone to hallucinations and hence provides more insight into
where in the response a hallucination has occurred, if at all, than previous
methods. Furthermore, using our approach in conjunction with state-of-the-art
natural language inference (NLI) models leads to an improvement in balanced
accuracy on various hallucination benchmarks, compared to using the raw NLI
models. Lastly, we explore the use of GraphEval for hallucination correction by
leveraging the structure of the KG, a method we name GraphCorrect, and
demonstrate that the majority of hallucinations can indeed be rectified.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) åæè©ä¼°æ¹æ³åä¸ä¸è´æ§åµæ¸¬ï¼åç¨±çºå¹»è¦ºï¼ï¼ç¸å°æ¼ææä¾çç¥è­ï¼å°æ¼ LLM æç¨æ­£è®å¾è¶ä¾è¶éè¦ãç®åçææ¨ç¡æ³æä¾å¯è§£éçæ±ºç­ãç³»çµ±æ§å°æª¢æ¥åæä¸­çææè³è¨ï¼èä¸å¨å¯¦åä¸ä½¿ç¨æï¼éå¸¸éæ¼èè²»éç®è³æºãæåæåº GraphEvalï¼ä¸ååºæ¼ç¥è­å (KG) çµæ§ä¾è¡¨ç¤ºè³è¨çå¹»è¦ºè©ä¼°æ¶æ§ãæåçæè¡è­å¥åºå®¹æåºç¾å¹»è¦ºç KG ä¸­ç¹å®ä¸åçµï¼å æ­¤æ¯ä»¥å¾çæ¹æ³æ´æ·±å¥å°äºè§£åæä¸­å¹»è¦ºç¼çå¨åªè£¡ï¼å¦ææçè©±ï¼ãæ­¤å¤ï¼å°æåçæ¹æ³èæåé²çèªç¶èªè¨æ¨è« (NLI) æ¨¡åçµåä½¿ç¨ï¼èä½¿ç¨åå§ NLI æ¨¡åç¸æ¯ï¼å¯ä»¥å¨åç¨®å¹»è¦ºåºæºä¸æé«å¹³è¡¡æºç¢ºåº¦ãæå¾ï¼æåæ¢ç´¢ä½¿ç¨ GraphEval ä¾é²è¡å¹»è¦ºä¿®æ­£ï¼æ¹æ³æ¯å©ç¨ KG ççµæ§ï¼æåå°æ­¤æ¹æ³å½åçº GraphCorrectï¼ä¸¦è­æå¤§å¤æ¸å¹»è¦ºç¢ºå¯¦å¯ä»¥å¾å°ç³¾æ­£ã

##### **Scaling 3D Reasoning with LMMs to Large Robot Mission Environments Using Datagraphs**
2407.10743v1 by W. J. Meijer, A. C. Kemmeren, E. H. J. Riemens, J. E. Fransman, M. van Bekkum, G. J. Burghouts, J. D. van Mil

This paper addresses the challenge of scaling Large Multimodal Models (LMMs)
to expansive 3D environments. Solving this open problem is especially relevant
for robot deployment in many first-responder scenarios, such as
search-and-rescue missions that cover vast spaces. The use of LMMs in these
settings is currently hampered by the strict context windows that limit the
LMM's input size. We therefore introduce a novel approach that utilizes a
datagraph structure, which allows the LMM to iteratively query smaller sections
of a large environment. Using the datagraph in conjunction with graph traversal
algorithms, we can prioritize the most relevant locations to the query, thereby
improving the scalability of 3D scene language tasks. We illustrate the
datagraph using 3D scenes, but these can be easily substituted by other dense
modalities that represent the environment, such as pointclouds or Gaussian
splats. We demonstrate the potential to use the datagraph for two 3D scene
language task use cases, in a search-and-rescue mission example.

æè¦ï¼æ¬æè¨è«äºå°å¤§åå¤æ¨¡ææ¨¡å (LMM) æ´å±å°å»£é 3D ç°å¢çææ°ãè§£æ±ºéåéæ¾æ§åé¡å°æ¼æ©å¨äººå¨è¨±å¤ç¬¬ä¸åæäººå¡å ´æ¯ä¸­çé¨ç½²ç¹å¥ç¸éï¼ä¾å¦æ¶µèå»£éç©ºéçææä»»åãéäºè¨­å®ä¸­ä½¿ç¨ LMM ç®ååå°å´æ ¼çä¸ä¸æè¦çªéå¶ï¼ééå¶äº LMM çè¼¸å¥å¤§å°ãå æ­¤ï¼æåå¼å¥äºä¸ç¨®æ°ç©çæ¹æ³ï¼è©²æ¹æ³å©ç¨è³æåçµæ§ï¼åè¨± LMM è¿­ä»£æ¥è©¢å¤§åç°å¢çè¼å°é¨åãééå°è³æåèåå½¢éæ­·æ¼ç®æ³çµåä½¿ç¨ï¼æåå¯ä»¥åªåèæ®èæ¥è©¢æç¸éçä½ç½®ï¼å¾èæé« 3D å ´æ¯èªè¨ä»»åçå¯æ´åæ§ãæåä½¿ç¨ 3D å ´æ¯èªªæè³æåï¼ä½éäºå ´æ¯å¯ä»¥è¼é¬å°ç±å¶ä»è¡¨ç¤ºç°å¢çå¯éæ¨¡å¼åä»£ï¼ä¾å¦é»é²æé«æ¯é»ãæåå±ç¤ºäºå¨ææä»»åç¯ä¾ä¸­ä½¿ç¨è³æåé²è¡å©å 3D å ´æ¯èªè¨ä»»åç¨ä¾çæ½åã

##### **AutoGRAMS: Autonomous Graphical Agent Modeling Software**
2407.10049v1 by Ben Krause, Lucia Chen, Emmanuel Kahembwe

We introduce the AutoGRAMS framework for programming multi-step interactions
with language models. AutoGRAMS represents AI agents as a graph, where each
node can execute either a language modeling instruction or traditional code.
Likewise, transitions in the graph can be governed by either language modeling
decisions or traditional branch logic. AutoGRAMS supports using variables as
memory and allows nodes to call other AutoGRAMS graphs as functions. We show
how AutoGRAMS can be used to design highly sophisticated agents, including
self-referential agents that can modify their own graph. AutoGRAMS's
graph-centric approach aids interpretability, controllability, and safety
during the design, development, and deployment of AI agents. We provide our
framework as open source at https://github.com/autograms/autograms .

æè¦ï¼æåä»ç´¹ AutoGRAMS æ¡æ¶ï¼ç¨æ¼ç·¨å¯«èèªè¨æ¨¡åçå¤æ­¥é©äºåãAutoGRAMS å° AI ä»£çè¡¨ç¤ºçºä¸ååå½¢ï¼å¶ä¸­æ¯åç¯é»å¯ä»¥å·è¡èªè¨å»ºæ¨¡æä»¤æå³çµ±ä»£ç¢¼ãåæ¨£å°ï¼åå½¢ä¸­çè½æå¯ä»¥ç±èªè¨å»ºæ¨¡æ±ºç­æå³çµ±åæ¯éè¼¯æ§å¶ãAutoGRAMS æ¯æ´ä½¿ç¨è®æ¸ä½çºè¨æ¶é«ï¼ä¸¦åè¨±ç¯é»å¼å«å¶ä» AutoGRAMS åå½¢ä½çºå½å¼ãæåå±ç¤ºå¦ä½ä½¿ç¨ AutoGRAMS è¨­è¨é«åº¦è¤éçä»£çï¼åæ¬å¯ä»¥ä¿®æ¹èªèº«åå½¢çèªåç§ä»£çãAutoGRAMS ä»¥åå½¢çºä¸­å¿çæ¹æ³æå©æ¼å¨ AI ä»£ççè¨­è¨ãéç¼åé¨ç½²éç¨ä¸­æé«å¯è§£éæ§ãå¯æ§æ§åå®å¨æ§ãæåå¨ https://github.com/autograms/autograms æä¾æåçæ¡æ¶ä½çºéæºã

##### **FarFetched: Entity-centric Reasoning and Claim Validation for the Greek Language based on Textually Represented Environments**
2407.09888v1 by Dimitris Papadopoulos, Katerina Metropoulou, Nikolaos Matsatsinis, Nikolaos Papadakis

Our collective attention span is shortened by the flood of online
information. With \textit{FarFetched}, we address the need for automated claim
validation based on the aggregated evidence derived from multiple online news
sources. We introduce an entity-centric reasoning framework in which latent
connections between events, actions, or statements are revealed via entity
mentions and represented in a graph database. Using entity linking and semantic
similarity, we offer a way for collecting and combining information from
diverse sources in order to generate evidence relevant to the user's claim.
Then, we leverage textual entailment recognition to quantitatively determine
whether this assertion is credible, based on the created evidence. Our approach
tries to fill the gap in automated claim validation for less-resourced
languages and is showcased on the Greek language, complemented by the training
of relevant semantic textual similarity (STS) and natural language inference
(NLI) models that are evaluated on translated versions of common benchmarks.

æè¦ï¼ç¶²è·¯è³è¨çæ´ªæµç¸®ç­äºæåçéé«æ³¨æåæéãéé \textit{FarFetched}ï¼æåè§£æ±ºäºæ ¹æå¾å¤åç·ä¸æ°èä¾æºå½ç¸½çè­æé²è¡èªååè²æé©è­çéæ±ãæåå¼å¥äºä¸åä»¥å¯¦é«çºä¸­å¿çæ¨çæ¡æ¶ï¼å¶ä¸­äºä»¶ãåä½æé³è¿°ä¹éçæ½å¨éè¯ééå¯¦é«æåè¢«æ­é²ï¼ä¸¦å¨åå½¢è³æåº«ä¸­è¡¨ç¤ºãä½¿ç¨å¯¦é«é£çµåèªç¾©ç¸ä¼¼æ§ï¼æåæä¾ä¸ç¨®æ¹å¼ä¾æ¶éåçµåä¾èªä¸åä¾æºçè³è¨ï¼ä»¥ç¢çèä½¿ç¨èè²æç¸éçè­æãç¶å¾ï¼æåå©ç¨ææ¬èæ¶µè­å¥ä¾æ ¹æå»ºç«çè­æéåç¢ºå®æ­¤æ·è¨æ¯å¦å¯ä¿¡ãæåçåæ³è©¦åå¡«è£è³æºè¼å°çèªè¨çèªååè²æé©è­æ¹é¢çç©ºç½ï¼ä¸¦å¨å¸èèªä¸­å±ç¤ºï¼è¼ä»¥å°ç¸éèªç¾©ææ¬ç¸ä¼¼æ§ (STS) åèªç¶èªè¨æ¨è« (NLI) æ¨¡åçè¨ç·´ï¼éäºæ¨¡åå¨å¸¸è¦åºæºçç¿»è­¯çæ¬ä¸é²è¡è©ä¼°ã

##### **GOFA: A Generative One-For-All Model for Joint Graph Language Modeling**
2407.09709v1 by Lecheng Kong, Jiarui Feng, Hao Liu, Chengsong Huang, Jiaxin Huang, Yixin Chen, Muhan Zhang

Foundation models, such as Large Language Models (LLMs) or Large Vision
Models (LVMs), have emerged as one of the most powerful tools in the respective
fields. However, unlike text and image data, graph data do not have a
definitive structure, posing great challenges to developing a Graph Foundation
Model (GFM). For example, current attempts at designing general graph models
either transform graph data into a language format for LLM-based prediction or
still train a GNN model with LLM as an assistant. The former can handle
unlimited tasks, while the latter captures graph structure much better -- yet,
no existing work can achieve both simultaneously. In this paper, we identify
three key desirable properties of a GFM: self-supervised pretraining, fluidity
in tasks, and graph awareness. To account for these properties, we extend the
conventional language modeling to the graph domain and propose a novel
generative graph language model GOFA to solve the problem. The model
interleaves randomly initialized GNN layers into a frozen pre-trained LLM so
that the semantic and structural modeling abilities are organically combined.
GOFA is pre-trained on newly proposed graph-level next-word prediction,
question-answering, and structural tasks to obtain the above GFM properties.
The pre-trained model is further fine-tuned on downstream tasks to obtain
task-solving ability. The fine-tuned model is evaluated on various downstream
tasks, demonstrating a strong ability to solve structural and contextual
problems in zero-shot scenarios. The code is available at
https://github.com/JiaruiFeng/GOFA.

æè¦ï¼åºç¤æ¨¡åï¼ä¾å¦å¤§åèªè¨æ¨¡å (LLM) æå¤§åè¦è¦ºæ¨¡å (LVM)ï¼å·²æçºåèªé åä¸­ææåçå·¥å·ä¹ä¸ãç¶èï¼èææ¬åå½±åè³æä¸åï¼åå½¢è³ææ²ææç¢ºççµæ§ï¼å°éç¼åå½¢åºç¤æ¨¡å (GFM) æ§ææ¥µå¤§çææ°ãä¾å¦ï¼ç®åè¨­è¨éç¨åå½¢æ¨¡åçåè©¦ï¼ä¸æ¯å°åå½¢è³æè½æçºèªè¨æ ¼å¼ä»¥ä¾åºæ¼ LLM çé æ¸¬ï¼å°±æ¯è¨ç·´ GNN æ¨¡åï¼ä¸¦ä»¥ LLM ä½çºè¼å©ãåèå¯ä»¥èçç¡éçä»»åï¼èå¾èå¯ä»¥æ´å¥½å°æ·ååå½¢çµæ§ï¼ä½ç¾æçå·¥ä½ç¡æ³åæéæéå©èãå¨æ¬æä¸­ï¼æåæ¾åº GFM çä¸åééµçæ³ç¹æ§ï¼èªæç£ç£é è¨ç·´ãä»»åæµæ¢åº¦ååå½¢æç¥ãçºäºèééäºç¹æ§ï¼æåå°å³çµ±çèªè¨å»ºæ¨¡æ´åå°åå½¢é åï¼ä¸¦æåºä¸åæ°ç©ççæå¼åå½¢èªè¨æ¨¡å GOFA ä¾è§£æ±ºåé¡ãæ­¤æ¨¡åå°é¨æ©åå§åç GNN å±¤äº¤é¯æå¥åçµçé è¨ç·´ LLM ä¸­ï¼ä»¥ä¾¿èªæåçµæ§å»ºæ¨¡è½åææ©çµåãGOFA æ¡ç¨æ°æåºçåå½¢å±¤ç´ä¸ä¸åå­é æ¸¬ãåç­åçµæ§ä»»åé²è¡é è¨ç·´ï¼ä»¥åå¾ä¸è¿° GFM ç¹æ§ãé è¨ç·´æ¨¡åé²ä¸æ­¥å¨ä¸æ¸¸ä»»åä¸é²è¡å¾®èª¿ï¼ä»¥åå¾è§£æ±ºä»»åçè½åãå¾®èª¿æ¨¡åå¨åç¨®ä¸æ¸¸ä»»åä¸é²è¡è©ä¼°ï¼è­æäºå¨é¶æ¬¡å­¸ç¿å ´æ¯ä¸­è§£æ±ºçµæ§åä¸ä¸æåé¡çå¼·å¤§è½åãç¨å¼ç¢¼å¯å¨ https://github.com/JiaruiFeng/GOFA åå¾ã

##### **Human-like Episodic Memory for Infinite Context LLMs**
2407.09450v1 by Zafeirios Fountas, Martin A Benfeghoul, Adnan Oomerjee, Fenia Christopoulou, Gerasimos Lampouras, Haitham Bou-Ammar, Jun Wang

Large language models (LLMs) have shown remarkable capabilities, but still
struggle with processing extensive contexts, limiting their ability to maintain
coherence and accuracy over long sequences. In contrast, the human brain excels
at organising and retrieving episodic experiences across vast temporal scales,
spanning a lifetime. In this work, we introduce EM-LLM, a novel approach that
integrates key aspects of human episodic memory and event cognition into LLMs,
enabling them to effectively handle practically infinite context lengths while
maintaining computational efficiency. EM-LLM organises sequences of tokens into
coherent episodic events using a combination of Bayesian surprise and
graph-theoretic boundary refinement in an on-line fashion. When needed, these
events are retrieved through a two-stage memory process, combining
similarity-based and temporally contiguous retrieval for efficient and
human-like access to relevant information. Experiments on the LongBench dataset
demonstrate EM-LLM's superior performance, outperforming the state-of-the-art
InfLLM model with an overall relative improvement of 4.3% across various tasks,
including a 33% improvement on the PassageRetrieval task. Furthermore, our
analysis reveals strong correlations between EM-LLM's event segmentation and
human-perceived events, suggesting a bridge between this artificial system and
its biological counterpart. This work not only advances LLM capabilities in
processing extended contexts but also provides a computational framework for
exploring human memory mechanisms, opening new avenues for interdisciplinary
research in AI and cognitive science.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²å±ç¾åºéå¡çè½åï¼ä½ä»é£ä»¥èçå»£æ³çèçµ¡ï¼ééå¶äºå®åå¨é·åºåä¸­ç¶­æé£è²«æ§åæºç¢ºæ§çè½åãç¸è¼ä¹ä¸ï¼äººè¦æé·å¨å»£å¤§çæéå°ºåº¦ä¸çµç¹åæåæç¯é«é©ï¼è·¨è¶ä¸çãå¨éé å·¥ä½ä¸­ï¼æåå¼å¥äº EM-LLMï¼éæ¯ä¸ç¨®æ°ç©çæ¹æ³ï¼å®å°äººé¡æç¯è¨æ¶åäºä»¶èªç¥çééµé¢åæ´åå° LLM ä¸­ï¼è®å®åè½å¤ ææå°èçå¯¦éä¸ç¡éçèçµ¡é·åº¦ï¼åæç¶­æéç®æçãEM-LLM ä½¿ç¨è²æ°é©åååè«éçç²¾çççµåï¼ä»¥ç·ä¸æ¹å¼å°åºåæ¨è¨çµç¹æé£è²«çæç¯äºä»¶ãå¨éè¦æï¼éäºäºä»¶æééå©éæ®µçè¨æ¶éç¨ä¾æåï¼çµååºæ¼ç¸ä¼¼æ§åæéé£çºæ§çæåï¼ä»¥ææä¸é¡ä¼¼äººé¡çæ¹å¼å­åç¸éè³è¨ãå¨ LongBench è³æéä¸çå¯¦é©è­æäº EM-LLM çåè¶æè½ï¼å¨åç¨®ä»»åä¸­åªæ¼æåé²ç InfLLM æ¨¡åï¼å¨ PassageRetrieval ä»»åä¸­æ¹é²äº 33%ãæ­¤å¤ï¼æåçåææ­ç¤ºäº EM-LLM çäºä»¶åå²èäººé¡æç¥äºä»¶ä¹éçå¼·ç¸éæ§ï¼é¡¯ç¤ºäºéåäººå·¥ç³»çµ±èå¶çç©å°æç©ä¹éçæ©æ¨ãéé å·¥ä½ä¸åæåäº LLM å¨èçå»¶ä¼¸èçµ¡æ¹é¢çè½åï¼ä¹æä¾äºä¸åéç®æ¶æ§ä¾æ¢ç´¢äººé¡è¨æ¶æ©å¶ï¼çº AI åèªç¥ç§å­¸çè·¨é åç ç©¶éåäºæ°çéå¾ã

##### **The $Î¼\mathcal{G}$ Language for Programming Graph Neural Networks**
2407.09441v1 by Matteo Belenchia, Flavio Corradini, Michela Quadrini, Michele Loreti

Graph neural networks form a class of deep learning architectures
specifically designed to work with graph-structured data. As such, they share
the inherent limitations and problems of deep learning, especially regarding
the issues of explainability and trustworthiness. We propose $\mu\mathcal{G}$,
an original domain-specific language for the specification of graph neural
networks that aims to overcome these issues. The language's syntax is
introduced, and its meaning is rigorously defined by a denotational semantics.
An equivalent characterization in the form of an operational semantics is also
provided and, together with a type system, is used to prove the type soundness
of $\mu\mathcal{G}$. We show how $\mu\mathcal{G}$ programs can be represented
in a more user-friendly graphical visualization, and provide examples of its
generality by showing how it can be used to define some of the most popular
graph neural network models, or to develop any custom graph processing
application.

æè¦ï¼åå½¢ç¥ç¶ç¶²è·¯å½¢æä¸é¡æ·±åº¦å­¸ç¿æ¶æ§ï¼ç¹å¥è¨­è¨ç¨æ¼èçåå½¢çµæ§åçè³æãå æ­¤ï¼å®åå·ææ·±åº¦å­¸ç¿åºæçéå¶ååé¡ï¼ç¹å¥æ¯å¨å¯è§£éæ§åå¯ä¿¡è³´æ§åé¡ä¸ãæåæåº $\mu\mathcal{G}$ï¼ä¸ç¨®ç¨æ¼æå®åå½¢ç¥ç¶ç¶²è·¯çååµé åç¹å®èªè¨ï¼æ¨å¨åæéäºåé¡ãå¼å¥äºèªè¨çèªæ³ï¼ä¸¦ééæç¤ºèªç¾©å´æ ¼å®ç¾©å¶å«ç¾©ãéæä¾äºéç®èªç¾©å½¢å¼çç­æç¹å¾µæè¿°ï¼ä¸¦èé¡åç³»çµ±ä¸èµ·ç¨æ¼è­æ $\mu\mathcal{G}$ çé¡åå¥å¨æ§ãæåå±ç¤ºäºå¦ä½å° $\mu\mathcal{G}$ ç¨å¼è¡¨ç¤ºçºæ´ååçåå½¢è¦è¦ºåï¼ä¸¦ééå±ç¤ºå¦ä½ä½¿ç¨å®å®ç¾©ä¸äºææµè¡çåå½¢ç¥ç¶ç¶²è·¯æ¨¡åæéç¼ä»»ä½èªè¨åå½¢èçæç¨ç¨å¼ï¼ä¾æä¾å¶éç¨æ§çç¯ä¾ã

##### **Towards More Trustworthy and Interpretable LLMs for Code through Syntax-Grounded Explanations**
2407.08983v1 by David N. Palacio, Daniel Rodriguez-Cardenas, Alejandro Velasco, Dipin Khati, Kevin Moran, Denys Poshyvanyk

Trustworthiness and interpretability are inextricably linked concepts for
LLMs. The more interpretable an LLM is, the more trustworthy it becomes.
However, current techniques for interpreting LLMs when applied to code-related
tasks largely focus on accuracy measurements, measures of how models react to
change, or individual task performance instead of the fine-grained explanations
needed at prediction time for greater interpretability, and hence trust. To
improve upon this status quo, this paper introduces ASTrust, an
interpretability method for LLMs of code that generates explanations grounded
in the relationship between model confidence and syntactic structures of
programming languages. ASTrust explains generated code in the context of syntax
categories based on Abstract Syntax Trees and aids practitioners in
understanding model predictions at both local (individual code snippets) and
global (larger datasets of code) levels. By distributing and assigning model
confidence scores to well-known syntactic structures that exist within ASTs,
our approach moves beyond prior techniques that perform token-level confidence
mapping by offering a view of model confidence that directly aligns with
programming language concepts with which developers are familiar. To put
ASTrust into practice, we developed an automated visualization that illustrates
the aggregated model confidence scores superimposed on sequence, heat-map, and
graph-based visuals of syntactic structures from ASTs. We examine both the
practical benefit that ASTrust can provide through a data science study on 12
popular LLMs on a curated set of GitHub repos and the usefulness of ASTrust
through a human study.

æè¦ï¼å¯ä¿¡åº¦åå¯è§£éæ§æ¯ LLM ä¸­å¯ä¸å¯åçæ¦å¿µãLLM çå¯è§£éæ§è¶é«ï¼å®çå¯ä¿¡åº¦å°±è¶é«ãç¶èï¼ç¶æç¨æ¼èç¨å¼ç¢¼ç¸éçä»»åæï¼ç®åè§£é LLM çæè¡ä¸»è¦éä¸­å¨æºç¢ºæ§æ¸¬éãæ¨¡åå°è®åçåææ¸¬éæåå¥ä»»åè¡¨ç¾ï¼èä¸æ¯å¨é æ¸¬æéæéçç´°ç²åº¦è§£éï¼å¾èæé«å¯è§£éæ§åå æ­¤æé«ä¿¡ä»»åº¦ãçºäºæ¹åéç¨®ç¾çï¼æ¬æä»ç´¹äº ASTrustï¼éæ¯ä¸ç¨®ç¨æ¼ç¨å¼ç¢¼ LLM çå¯è§£éæ§æ¹æ³ï¼å®ææ ¹ææ¨¡åä¿¡å¿èç¨å¼èªè¨çèªæ³çµæ§ä¹éçéä¿ç¢çè§£éãASTrust å¨åºæ¼æ½è±¡èªæ³æ¨¹çèªæ³é¡å¥çä¸ä¸æä¸­è§£éç¢ççç¨å¼ç¢¼ï¼ä¸¦å¹«å©å¯¦åäººå¡å¨å±é¨ï¼åå¥ç¨å¼ç¢¼çæ®µï¼åå¨åï¼è¼å¤§çç¨å¼ç¢¼è³æéï¼å±¤ç´äºè§£æ¨¡åé æ¸¬ãééå°æ¨¡åä¿¡å¿åæ¸åéåæå®çµ¦ AST ä¸­å­å¨çç¾æå¨ç¥çèªæ³çµæ§ï¼æåçåæ³è¶è¶äºååçæè¡ï¼éäºæè¡ééæä¾èéç¼äººå¡çæçç¨å¼èªè¨æ¦å¿µç´æ¥å°é½çæ¨¡åä¿¡å¿è¦åä¾å·è¡ä»¤çç´å¥çä¿¡å¿å°æãçºäºå¯¦è¸ ASTrustï¼æåéç¼äºä¸åèªååè¦è¦ºåå·¥å·ï¼å®èªªæäºçå å¨ AST èªæ³çµæ§çåºåãç±åååºæ¼åå½¢çè¦è¦ºææä¸çèåæ¨¡åä¿¡å¿åæ¸ãæåæª¢æ¥äº ASTrust å¯ä»¥ééå° 12 åæµè¡ç LLM å¨ä¸çµç²¾é¸ç GitHub å²å­åº«ä¸é²è¡è³æç§å­¸ç ç©¶æä¾çå¯¦éå¥½èï¼ä»¥åééäººé«ç ç©¶æä¾ç ASTrust çæç¨æ§ã

##### **Domain-Hierarchy Adaptation via Chain of Iterative Reasoning for Few-shot Hierarchical Text Classification**
2407.08959v1 by Ke Ji, Peng Wang, Wenjun Ke, Guozheng Li, Jiajun Liu, Jingsheng Gao, Ziyu Shang

Recently, various pre-trained language models (PLMs) have been proposed to
prove their impressive performances on a wide range of few-shot tasks. However,
limited by the unstructured prior knowledge in PLMs, it is difficult to
maintain consistent performance on complex structured scenarios, such as
hierarchical text classification (HTC), especially when the downstream data is
extremely scarce. The main challenge is how to transfer the unstructured
semantic space in PLMs to the downstream domain hierarchy. Unlike previous work
on HTC which directly performs multi-label classification or uses graph neural
network (GNN) to inject label hierarchy, in this work, we study the HTC problem
under a few-shot setting to adapt knowledge in PLMs from an unstructured manner
to the downstream hierarchy. Technically, we design a simple yet effective
method named Hierarchical Iterative Conditional Random Field (HierICRF) to
search the most domain-challenging directions and exquisitely crafts
domain-hierarchy adaptation as a hierarchical iterative language modeling
problem, and then it encourages the model to make hierarchical consistency
self-correction during the inference, thereby achieving knowledge transfer with
hierarchical consistency preservation. We perform HierICRF on various
architectures, and extensive experiments on two popular HTC datasets
demonstrate that prompt with HierICRF significantly boosts the few-shot HTC
performance with an average Micro-F1 by 28.80% to 1.50% and Macro-F1 by 36.29%
to 1.5% over the previous state-of-the-art (SOTA) baselines under few-shot
settings, while remaining SOTA hierarchical consistency performance.

æè¦ï¼<paragraph>æè¿ï¼å·²ç»æåºäºå¤ç§é¢è®­ç»è¯­è¨æ¨¡å (PLM)ï¼ä»¥è¯æå®ä»¬å¨å¹¿æ³çå°éæ ·æ¬ä»»å¡ä¸å·æä»¤äººå°è±¡æ·±å»çæ§è½ãç¶èï¼ç±äº PLM ä¸­éç»æåçåéªç¥è¯åå°éå¶ï¼å æ­¤é¾ä»¥å¨å¤æç»æååºæ¯ï¼ä¾å¦å±æ¬¡ææ¬åç±» (HTC)ï¼ä¸­ä¿æä¸è´çæ§è½ï¼å°¤å¶æ¯å¨ä¸æ¸¸æ°æ®æå¶ç¨å°çæåµä¸ãä¸»è¦çæææ¯å¦ä½å° PLM ä¸­éç»æåçè¯­ä¹ç©ºé´è½¬ç§»å°ä¸æ¸¸åå±æ¬¡ç»æãä¸ä»¥åç´æ¥æ§è¡å¤æ ç­¾åç±»æä½¿ç¨å¾ç¥ç»ç½ç» (GNN) æ³¨å¥æ ç­¾å±æ¬¡ç»æç HTC å·¥ä½ä¸åï¼å¨è¿é¡¹å·¥ä½ä¸­ï¼æä»¬å¨å°éæ ·æ¬è®¾ç½®ä¸ç ç©¶ HTC é®é¢ï¼ä»¥å° PLM ä¸­çç¥è¯ä»éç»æåæ¹å¼éåºå°ä¸æ¸¸å±æ¬¡ç»æãä»ææ¯ä¸è®²ï¼æä»¬è®¾è®¡äºä¸ç§ç®åèææçæ¹æ³ï¼ç§°ä¸ºå±æ¬¡è¿­ä»£æ¡ä»¶éæºåº (HierICRF)ï¼ä»¥æç´¢æå·é¢åæææ§çæ¹åï¼å¹¶ç²¾ç»å°å°é¢åå±æ¬¡ç»æéåºä½ä¸ºåå±è¿­ä»£è¯­è¨å»ºæ¨¡é®é¢ï¼ç¶åå®é¼å±æ¨¡åå¨æ¨çæé´è¿è¡å±æ¬¡ä¸è´æ§èªææ ¡æ­£ï¼ä»èå®ç°å·æå±æ¬¡ä¸è´æ§ä¿ççç¥è¯è½¬ç§»ãæä»¬å¨åç§æ¶æä¸æ§è¡ HierICRFï¼å¨ä¸¤ä¸ªæµè¡ç HTC æ°æ®éä¸çå¤§éå®éªè¡¨æï¼ä½¿ç¨ HierICRF çæç¤ºæ¾çæé«äºå°éæ ·æ¬ HTC æ§è½ï¼å¹³å Micro-F1 ä» 28.80% æé«å° 1.50%ï¼Macro-F1 ä» 36.29% æé«å° 1.5% å¨å°éæ ·æ¬è®¾ç½®ä¸è¶è¿äºä»¥åæåè¿ (SOTA) åºåï¼åæ¶ä¿æ SOTA å±æ¬¡ä¸è´æ§æ§è½ã</paragraph>

##### **Cloud Atlas: Efficient Fault Localization for Cloud Systems using Language Models and Causal Insight**
2407.08694v1 by Zhiqiang Xie, Yujia Zheng, Lizi Ottens, Kun Zhang, Christos Kozyrakis, Jonathan Mace

Runtime failure and performance degradation is commonplace in modern cloud
systems. For cloud providers, automatically determining the root cause of
incidents is paramount to ensuring high reliability and availability as prompt
fault localization can enable faster diagnosis and triage for timely
resolution. A compelling solution explored in recent work is causal reasoning
using causal graphs to capture relationships between varied cloud system
performance metrics. To be effective, however, systems developers must
correctly define the causal graph of their system, which is a time-consuming,
brittle, and challenging task that increases in difficulty for large and
dynamic systems and requires domain expertise. Alternatively, automated
data-driven approaches have limited efficacy for cloud systems due to the
inherent rarity of incidents. In this work, we present Atlas, a novel approach
to automatically synthesizing causal graphs for cloud systems. Atlas leverages
large language models (LLMs) to generate causal graphs using system
documentation, telemetry, and deployment feedback. Atlas is complementary to
data-driven causal discovery techniques, and we further enhance Atlas with a
data-driven validation step. We evaluate Atlas across a range of fault
localization scenarios and demonstrate that Atlas is capable of generating
causal graphs in a scalable and generalizable manner, with performance that far
surpasses that of data-driven algorithms and is commensurate to the
ground-truth baseline.

æè¦ï¼å¨ç¾ä»£é²ç«¯ç³»çµ±ä¸­ï¼å·è¡æææéåæè½éä½æ¯å¸ç©ºè¦æ£çäºãå°æ¼é²ç«¯ä¾æåèè¨ï¼èªåæ¾åºäºä»¶çæ ¹æ¬åå å°æ¼ç¢ºä¿é«å¯é æ§åå¯ç¨æ§è³ééè¦ï¼å çºåæçæéå®ä½å¯ä»¥è®è¨ºæ·ååé¡æ´å¿«éï¼ä»¥å©æ¼åæè§£æ±ºåé¡ãæè¿çå·¥ä½ä¸­æ¢è¨äºä¸åå¼äººæ³¨ç®çè§£æ±ºæ¹æ¡ï¼å³ä½¿ç¨å æåä¾æ·ååç¨®é²ç«¯ç³»çµ±æè½ææ¨ä¹ééä¿çå ææ¨çãç¶èï¼ç³»çµ±éç¼äººå¡å¿é æ­£ç¢ºå®ç¾©å¶ç³»çµ±çå æåæè½ç¼æ®æç¨ï¼èéé ä»»åèæãèå¼±ä¸å·æææ°æ§ï¼å°æ¼å¤§åä¸åæçç³»çµ±èè¨é£åº¦æ´é«ï¼èä¸éè¦é åå°å®¶ç¥è­ãæèï¼ç±æ¼äºä»¶çåºæç¨å°æ§ï¼èªååè³æé©åæ¹æ³å°æ¼é²ç«¯ç³»çµ±çæåæéãå¨éé å·¥ä½ä¸­ï¼æåæåº Atlasï¼ä¸ç¨®èªååæé²ç«¯ç³»çµ±å æåçæ°æ¹æ³ãAtlas å©ç¨å¤§åèªè¨æ¨¡å (LLM) ä½¿ç¨ç³»çµ±æä»¶ãéæ¸¬åé¨ç½²åé¥ä¾ç¢çå æåãAtlas æ¯è³æé©åå æç¼ç¾æè¡çè£åï¼æåé²ä¸æ­¥ä½¿ç¨è³æé©åé©è­æ­¥é©ä¾å¢å¼· Atlasãæåå¨åç¨®æéå®ä½æå¢ä¸­è©ä¼° Atlasï¼ä¸¦è­æ Atlas è½å¤ ä»¥å¯æ´åä¸å¯æ¦åçæ¹å¼ç¢çå æåï¼å¶æè½é é è¶éè³æé©åæ¼ç®æ³ï¼ä¸¦ä¸èçå¯¦åºç·ç¸ç¶ã

##### **Converging Paradigms: The Synergy of Symbolic and Connectionist AI in LLM-Empowered Autonomous Agents**
2407.08516v2 by Haoyi Xiong, Zhiyuan Wang, Xuhong Li, Jiang Bian, Zeke Xie, Shahid Mumtaz, Laura E. Barnes

This article explores the convergence of connectionist and symbolic
artificial intelligence (AI), from historical debates to contemporary
advancements. Traditionally considered distinct paradigms, connectionist AI
focuses on neural networks, while symbolic AI emphasizes symbolic
representation and logic. Recent advancements in large language models (LLMs),
exemplified by ChatGPT and GPT-4, highlight the potential of connectionist
architectures in handling human language as a form of symbols. The study argues
that LLM-empowered Autonomous Agents (LAAs) embody this paradigm convergence.
By utilizing LLMs for text-based knowledge modeling and representation, LAAs
integrate neuro-symbolic AI principles, showcasing enhanced reasoning and
decision-making capabilities. Comparing LAAs with Knowledge Graphs within the
neuro-symbolic AI theme highlights the unique strengths of LAAs in mimicking
human-like reasoning processes, scaling effectively with large datasets, and
leveraging in-context samples without explicit re-training. The research
underscores promising avenues in neuro-vector-symbolic integration,
instructional encoding, and implicit reasoning, aimed at further enhancing LAA
capabilities. By exploring the progression of neuro-symbolic AI and proposing
future research trajectories, this work advances the understanding and
development of AI technologies.

æè¦ï¼æ¬ææ¢è¨äºé£ç·ä¸»ç¾©èç¬¦èäººå·¥æºæ§ï¼AIï¼çèåï¼å¾æ­·å²è¾¯è«å°ç¶ä»£é²å±ãé£ç·ä¸»ç¾© AI å³çµ±ä¸è¢«è¦çºä¸åçç¯å¼ï¼å°æ³¨æ¼ç¥ç¶ç¶²è·¯ï¼èç¬¦è AI åå¼·èª¿ç¬¦èè¡¨å¾µèéè¼¯ãå¤§åèªè¨æ¨¡åï¼LLMï¼çææ°é²å±ï¼ä¾å¦ ChatGPT å GPT-4ï¼çªé¡¯äºé£ç·ä¸»ç¾©æ¶æ§å¨å°äººé¡èªè¨è¦çºç¬¦èå½¢å¼èçæ¹é¢çæ½åãç ç©¶èªçºï¼ç± LLM è³¦è½çèªä¸»ä»£çï¼LAAï¼é«ç¾äºéç¨®ç¯å¼èåãééå©ç¨ LLM é²è¡åºæ¼æå­çç¥è­å»ºæ¨¡åè¡¨å¾µï¼LAA æ´åäºç¥ç¶ç¬¦è AI ååï¼å±ç¤ºäºå¢å¼·çæ¨çåæ±ºç­è½åãå¨ç¥ç¶ç¬¦è AI ä¸»é¡ä¸­æ¯è¼ LAA èç¥è­åè­ï¼çªåºäº LAA å¨æ¨¡æ¬é¡äººæ¨çéç¨ãæææ´åå¤§åè³æéä»¥åå©ç¨æå¢ç¯ä¾èç¡éæç¢ºéæ°è¨ç·´æ¹é¢çç¨ç¹åªå¢ãç ç©¶å¼·èª¿äºç¥ç¶åéç¬¦èæ´åãæä»¤ç·¨ç¢¼åé±å¼æ¨çä¸­åæ¯çå¥½çéå¾ï¼æ¨å¨é²ä¸æ­¥å¢å¼· LAA è½åãééæ¢ç´¢ç¥ç¶ç¬¦è AI çé²å±ä¸¦æåºæªä¾çç ç©¶è»è·¡ï¼éé å·¥ä½æ¨åäº AI æè¡ççè§£åç¼å±ã

##### **A Comprehensive Survey on the Security of Smart Grid: Challenges, Mitigations, and Future Research Opportunities**
2407.07966v1 by Arastoo Zibaeirad, Farnoosh Koleini, Shengping Bi, Tao Hou, Tao Wang

In this study, we conduct a comprehensive review of smart grid security,
exploring system architectures, attack methodologies, defense strategies, and
future research opportunities. We provide an in-depth analysis of various
attack vectors, focusing on new attack surfaces introduced by advanced
components in smart grids. The review particularly includes an extensive
analysis of coordinated attacks that incorporate multiple attack strategies and
exploit vulnerabilities across various smart grid components to increase their
adverse impact, demonstrating the complexity and potential severity of these
threats. Following this, we examine innovative detection and mitigation
strategies, including game theory, graph theory, blockchain, and machine
learning, discussing their advancements in counteracting evolving threats and
associated research challenges. In particular, our review covers a thorough
examination of widely used machine learning-based mitigation strategies,
analyzing their applications and research challenges spanning across
supervised, unsupervised, semi-supervised, ensemble, and reinforcement
learning. Further, we outline future research directions and explore new
techniques and concerns. We first discuss the research opportunities for
existing and emerging strategies, and then explore the potential role of new
techniques, such as large language models (LLMs), and the emerging threat of
adversarial machine learning in the future of smart grid security.

æè¦ï¼å¨éé ç ç©¶ä¸­ï¼æåå°æºæ§é»ç¶²å®å¨æ§é²è¡å¨é¢æª¢è¦ï¼æ¢è¨ç³»çµ±æ¶æ§ãæ»ææ¹æ³ãé²ç¦¦ç­ç¥åæªä¾çç ç©¶æ©æãæåæ·±å¥åæåç¨®æ»æåªä»ï¼å°æ³¨æ¼æºæ§é»ç¶²ä¸­åé²çµä»¶æå¼å¥çæ°æ»æé¢ãæ¬æª¢è¦ç¹å¥åå«å°åèª¿æ»æçå»£æ³åæï¼å¶ä¸­åå«å¤ç¨®æ»æç­ç¥ä¸¦å©ç¨åç¨®æºæ§é»ç¶²çµä»¶ä¸­çæ¼æ´ä¾å¢å å¶è² é¢å½±é¿ï¼å±ç¤ºéäºå¨èçè¤éæ§åæ½å¨å´éæ§ãå¨æ­¤ä¹å¾ï¼æåæ¢è¨åµæ°çåµæ¸¬åç·©è§£ç­ç¥ï¼åæ¬åå¼è«ãåè«ãåå¡éåæ©å¨å­¸ç¿ï¼è¨è«å®åå¨å°æä¸æ·æ¼è®çå¨èåç¸éç ç©¶ææ°æ¹é¢çé²å±ãç¹å¥æ¯ï¼æåçæª¢è¦æ¶µèå°å»£æ³ä½¿ç¨çåºæ¼æ©å¨å­¸ç¿çç·©è§£ç­ç¥çå¾¹åºæª¢é©ï¼åæå®åå¨ç£ç£å¼ãéç£ç£å¼ãåç£ç£å¼ãæ´é«å¼åå¼·åå­¸ç¿ä¸­çæç¨åç ç©¶ææ°ãæ­¤å¤ï¼æåæ¦è¿°æªä¾çç ç©¶æ¹åä¸¦æ¢è¨æ°æè¡ååé¡ãæåé¦åè¨è«ç¾æåæ°èç­ç¥çç ç©¶æ©æï¼ç¶å¾æ¢è¨æ°æè¡çæ½å¨ä½ç¨ï¼ä¾å¦å¤§åèªè¨æ¨¡å (LLM)ï¼ä»¥åå°æå¼æ©å¨å­¸ç¿å¨æºæ§é»ç¶²å®å¨æªä¾çå¨èã

##### **Mobility VLA: Multimodal Instruction Navigation with Long-Context VLMs and Topological Graphs**
2407.07775v2 by Hao-Tien Lewis Chiang, Zhuo Xu, Zipeng Fu, Mithun George Jacob, Tingnan Zhang, Tsang-Wei Edward Lee, Wenhao Yu, Connor Schenck, David Rendleman, Dhruv Shah, Fei Xia, Jasmine Hsu, Jonathan Hoech, Pete Florence, Sean Kirmani, Sumeet Singh, Vikas Sindhwani, Carolina Parada, Chelsea Finn, Peng Xu, Sergey Levine, Jie Tan

An elusive goal in navigation research is to build an intelligent agent that
can understand multimodal instructions including natural language and image,
and perform useful navigation. To achieve this, we study a widely useful
category of navigation tasks we call Multimodal Instruction Navigation with
demonstration Tours (MINT), in which the environment prior is provided through
a previously recorded demonstration video. Recent advances in Vision Language
Models (VLMs) have shown a promising path in achieving this goal as it
demonstrates capabilities in perceiving and reasoning about multimodal inputs.
However, VLMs are typically trained to predict textual output and it is an open
research question about how to best utilize them in navigation. To solve MINT,
we present Mobility VLA, a hierarchical Vision-Language-Action (VLA) navigation
policy that combines the environment understanding and common sense reasoning
power of long-context VLMs and a robust low-level navigation policy based on
topological graphs. The high-level policy consists of a long-context VLM that
takes the demonstration tour video and the multimodal user instruction as input
to find the goal frame in the tour video. Next, a low-level policy uses the
goal frame and an offline constructed topological graph to generate robot
actions at every timestep. We evaluated Mobility VLA in a 836m^2 real world
environment and show that Mobility VLA has a high end-to-end success rates on
previously unsolved multimodal instructions such as "Where should I return
this?" while holding a plastic bin. A video demonstrating Mobility VLA can be
found here: https://youtu.be/-Tof__Q8_5s

æè¦ï¼<paragraph>å°èªç ç©¶ä¸­ä¸åé£ä»¥ææ¸çç®æ¨ï¼æ¯å»ºç«ä¸åæºè½ä»£çï¼å®å¯ä»¥çè§£åæ¬èªç¶èªè¨åå½±åçå¤æ¨¡ææä»¤ï¼ä¸¦å·è¡æç¨çå°èªãçºäºéææ­¤ç®æ¨ï¼æåç ç©¶äºä¸é¡å»£æ³æç¨çå°èªä»»åï¼æåç¨±ä¹çºç¤ºç¯å°è¦½çå¤æ¨¡ææä»¤å°èª (MINT)ï¼å¶ä¸­ç°å¢åé©æ¯ééååéè£½çç¤ºç¯å½±çæä¾çãè¦è¦ºèªè¨æ¨¡å (VLM) çè¿æé²å±ï¼å±ç¤ºäºä¸æ¢å¯¦ç¾æ­¤ç®æ¨çæåæ¯è·¯å¾ï¼å çºå®å±ç¤ºäºæç¥åæ¨çå¤æ¨¡æè¼¸å¥çè½åãç¶èï¼VLM éå¸¸è¨ç·´ç¨æ¼é æ¸¬æå­è¼¸åºï¼èå¦ä½æä½³å©ç¨å®åé²è¡å°èªï¼åæ¯ä¸åéæ¾çç ç©¶åé¡ãçºäºè§£æ±º MINTï¼æåæåºäº Mobility VLAï¼éæ¯ä¸ç¨®åå±¤çè¦è¦º-èªè¨-åä½ (VLA) å°èªæ¿ç­ï¼å®çµåäºé·èªå¢ VLM çç°å¢çè§£åå¸¸è­æ¨çè½åï¼ä»¥ååºæ¼ææ²åçå¼·å¥ä½éå°èªæ¿ç­ãé«éæ¿ç­åå«ä¸åé·èªå¢ VLMï¼å®æ¡ç¨ç¤ºç¯å°è¦½å½±çåå¤æ¨¡æä½¿ç¨èæä»¤ä½çºè¼¸å¥ï¼ä»¥å¨å°è¦½å½±çä¸­æ¾å°ç®æ¨å¹ãæ¥ä¸ä¾ï¼ä½éæ¿ç­ä½¿ç¨ç®æ¨å¹åé¢ç·å»ºæ§çææ²åï¼å¨æ¯åæéæ­¥ç¢çæ©å¨äººåä½ãæåå¨ 836 å¹³æ¹å¬å°ºççå¯¦ä¸çç°å¢ä¸­è©ä¼°äº Mobility VLAï¼ä¸¦å±ç¤ºäº Mobility VLA å¨ååæªè§£æ±ºçå¤æ¨¡ææä»¤ï¼ä¾å¦ãææè©²æéåå¡è ç®±æ­¸éå°åªè£¡ï¼ãï¼ä¸å·æå¾é«çç«¯å°ç«¯æåçï¼åææ¿èä¸åå¡è ç®±ãå±ç¤º Mobility VLA çå½±çå¯ä»¥å¨éè£¡æ¾å°ï¼https://youtu.be/-Tof__Q8_5s</paragraph>

##### **Teaching Transformers Causal Reasoning through Axiomatic Training**
2407.07612v1 by Aniket Vashishtha, Abhinav Kumar, Abbavaram Gowtham Reddy, Vineeth N Balasubramanian, Amit Sharma

For text-based AI systems to interact in the real world, causal reasoning is
an essential skill. Since interventional data is costly to generate, we study
to what extent an agent can learn causal reasoning from passive data.
Specifically, we consider an axiomatic training setup where an agent learns
from multiple demonstrations of a causal axiom (or rule), rather than
incorporating the axiom as an inductive bias or inferring it from data values.
A key question is whether the agent would learn to generalize from the axiom
demonstrations to new scenarios. For example, if a transformer model is trained
on demonstrations of the causal transitivity axiom over small graphs, would it
generalize to applying the transitivity axiom over large graphs? Our results,
based on a novel axiomatic training scheme, indicate that such generalization
is possible. We consider the task of inferring whether a variable causes
another variable, given a causal graph structure. We find that a 67 million
parameter transformer model, when trained on linear causal chains (along with
some noisy variations) can generalize well to new kinds of graphs, including
longer causal chains, causal chains with reversed order, and graphs with
branching; even when it is not explicitly trained for such settings. Our model
performs at par (or even better) than many larger language models such as
GPT-4, Gemini Pro, and Phi-3. Overall, our axiomatic training framework
provides a new paradigm of learning causal reasoning from passive data that can
be used to learn arbitrary axioms, as long as sufficient demonstrations can be
generated.

æè¦ï¼<paragraph>å°æ¼åºæ¼æå­çäººå·¥æºæ§ç³»çµ±èçå¯¦ä¸çäºåä¾èªªï¼å ææ¨çæ¯ä¸é å¿è¦çæè½ãç±æ¼ä»å¥è³æçç¢çææ¬å¾é«ï¼æåç ç©¶ä¸ä½ä»£çäººå¾è¢«åè³æä¸­å­¸ç¿å ææ¨ççç¨åº¦ãå·é«ä¾èªªï¼æåèæ®ä¸åå¬çè¨ç·´è¨­ç½®ï¼å¶ä¸­ä¸ä½ä»£çäººå¾å æå¬çï¼æè¦åï¼çå¤åç¤ºç¯ä¸­å­¸ç¿ï¼èä¸æ¯å°å¬çä½çºæ­¸ç´åèª¤æå¾è³æå¼ä¸­æ¨æ·åºä¾ãä¸åééµåé¡æ¯ä»£çäººæ¯å¦æå­¸æå¾å¬çç¤ºç¯æ¨å»£å°æ°çå ´æ¯ãä¾å¦ï¼å¦æä¸åTransformeræ¨¡åå¨å°åè¡¨ä¸å æå³éæ§å¬ççç¤ºç¯ä¸­æ¥åè¨ç·´ï¼å®æ¯å¦ææ¨å»£å°å¨å¤§åè¡¨ä¸æç¨å³éæ§å¬çï¼æåççµæåºæ¼ä¸åæ°ç©çå¬çè¨ç·´æ¹æ¡ï¼è¡¨æéæ¨£çæ¦æ¬æ¯å¯è½çãæåèæ®æ¨è«ä¸åè®æ¸æ¯å¦å°è´å¦ä¸åè®æ¸çä»»åï¼çµ¦å®ä¸åå æåçµæ§ãæåç¼ç¾ä¸å 6700 è¬ååæ¸çTransformeræ¨¡åï¼å¨ç·æ§å æéï¼ä»¥åä¸äºéè¨è®åï¼ä¸è¨ç·´æï¼å¯ä»¥å¾å¥½å°æ¦æ¬å°æ°é¡åçåå½¢ï¼åæ¬æ´é·çå æéãé åºç¸åçå æéåå·æåæ¯çåå½¢ï¼å³ä½¿å®æ²æéå°æ­¤é¡è¨­ç½®é²è¡æç¢ºè¨ç·´ãæåçæ¨¡åè¡¨ç¾èè¨±å¤è¼å¤§çèªè¨æ¨¡åï¼ä¾å¦ GPT-4ãGemini Pro å Phi-3ï¼ç¸ç¶ï¼çè³æ´å¥½ï¼ãç¸½é«èè¨ï¼æåçå¬çè¨ç·´æ¡æ¶æä¾äºä¸åå¾è¢«åè³æä¸­å­¸ç¿å ææ¨ççæ°ç¯ä¾ï¼åªè¦å¯ä»¥ç¢çè¶³å¤ çç¤ºç¯ï¼å°±å¯ä»¥ç¨æ¼å­¸ç¿ä»»æå¬çã</paragraph>

##### **STAGE: Simplified Text-Attributed Graph Embeddings Using Pre-trained LLMs**
2407.12860v1 by Aaron Zolnai-Lucas, Jack Boylan, Chris Hokamp, Parsa Ghaffari

We present Simplified Text-Attributed Graph Embeddings (STAGE), a
straightforward yet effective method for enhancing node features in Graph
Neural Network (GNN) models that encode Text-Attributed Graphs (TAGs). Our
approach leverages Large-Language Models (LLMs) to generate embeddings for
textual attributes. STAGE achieves competitive results on various node
classification benchmarks while also maintaining a simplicity in implementation
relative to current state-of-the-art (SoTA) techniques. We show that utilizing
pre-trained LLMs as embedding generators provides robust features for ensemble
GNN training, enabling pipelines that are simpler than current SoTA approaches
which require multiple expensive training and prompting stages. We also
implement diffusion-pattern GNNs in an effort to make this pipeline scalable to
graphs beyond academic benchmarks.

æè¦ï¼æåæåºäºç°¡åæå­å±¬æ§ååµå¥ (STAGE)ï¼éæ¯ä¸ç¨®ç´æ¥ä½ææçæ¹æ³ï¼ç¨æ¼å¢å¼·åç¥ç¶ç¶²è·¯ (GNN) æ¨¡åä¸­çç¯é»ç¹å¾µï¼éäºæ¨¡åæç·¨ç¢¼æå­å±¬æ§å (TAG)ãæåçåæ³å©ç¨å¤§åèªè¨æ¨¡å (LLM) ä¾çºæå­å±¬æ§ç¢çåµå¥ãSTAGE å¨åç¨®ç¯é»åé¡åºæºä¸åå¾äºæç«¶ç­åççµæï¼åæå¨å¯¦ä½ä¸ä¹ç¶­æäºç°¡æ½æ§ï¼ç¸è¼æ¼ç®åçæè¡æ°´æº (SoTA)ãæåå±ç¤ºäºä½¿ç¨é è¨ç·´ç LLM ä½çºåµå¥ç¢çå¨ï¼å¯çºæ´é« GNN è¨ç·´æä¾å¼·å¥çç¹å¾µï¼é²èå»ºæ§æ¯ç®å SoTA åæ³æ´ç°¡å®çç®¡éï¼èå¾èéè¦å¤åæè²´çè¨ç·´åæç¤ºéæ®µãæåä¹å¯¦ä½äºæ´æ£æ¨¡å¼ GNNï¼ä»¥æè®éåç®¡éè½æ´åå°å­¸è¡åºæºä¹å¤çåå½¢ã

##### **GLBench: A Comprehensive Benchmark for Graph with Large Language Models**
2407.07457v2 by Yuhan Li, Peisong Wang, Xiao Zhu, Aochuan Chen, Haiyun Jiang, Deng Cai, Victor Wai Kin Chan, Jia Li

The emergence of large language models (LLMs) has revolutionized the way we
interact with graphs, leading to a new paradigm called GraphLLM. Despite the
rapid development of GraphLLM methods in recent years, the progress and
understanding of this field remain unclear due to the lack of a benchmark with
consistent experimental protocols. To bridge this gap, we introduce GLBench,
the first comprehensive benchmark for evaluating GraphLLM methods in both
supervised and zero-shot scenarios. GLBench provides a fair and thorough
evaluation of different categories of GraphLLM methods, along with traditional
baselines such as graph neural networks. Through extensive experiments on a
collection of real-world datasets with consistent data processing and splitting
strategies, we have uncovered several key findings. Firstly, GraphLLM methods
outperform traditional baselines in supervised settings, with LLM-as-enhancers
showing the most robust performance. However, using LLMs as predictors is less
effective and often leads to uncontrollable output issues. We also notice that
no clear scaling laws exist for current GraphLLM methods. In addition, both
structures and semantics are crucial for effective zero-shot transfer, and our
proposed simple baseline can even outperform several models tailored for
zero-shot scenarios. The data and code of the benchmark can be found at
https://github.com/NineAbyss/GLBench.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çåºç¾å¾¹åºæ¹è®äºæåèåè¡¨äºåçæ¹å¼ï¼é²èç¢çä¸ç¨®ç¨±çº GraphLLM çæ°å¸ç¯ãåç®¡è¿å¹´ä¾ GraphLLM æ¹æ³å¿«éç¼å±ï¼ä½ç±æ¼ç¼ºä¹å·æä¸è´å¯¦é©åå®çåºæºï¼å æ­¤è©²é åçé²å±åçè§£ä»ä¸æç¢ºãçºäºå½è£éåå·®è·ï¼æåå¼å¥äº GLBenchï¼éæ¯ç¬¬ä¸åç¨æ¼è©ä¼° GraphLLM æ¹æ³å¨ç£ç£å¼åé¶æ¬¡å­¸ç¿å ´æ¯ä¸­çç¶ååºæºãGLBench æä¾å°ä¸åé¡å¥ç GraphLLM æ¹æ³é²è¡å¬å¹³ä¸å¾¹åºçè©ä¼°ï¼ä»¥åå³çµ±åºæºï¼ä¾å¦åç¥ç¶ç¶²è·¯ãééå°ä¸çµçå¯¦ä¸çè³æéé²è¡å»£æ³å¯¦é©ï¼ä¸¦æ¡ç¨ä¸è´çè³æèçååå²ç­ç¥ï¼æåç¼ç¾äºå¹¾åééµç¼ç¾ãé¦åï¼GraphLLM æ¹æ³å¨ç£ç£å¼è¨­å®ä¸­åªæ¼å³çµ±åºæºï¼å¶ä¸­ LLM ä½çºå¢å¼·å¨é¡¯ç¤ºåºæç©©å¥çæè½ãç¶èï¼ä½¿ç¨ LLM ä½çºé æ¸¬å¨è¼ä¸ææï¼èä¸ç¶å¸¸å°è´ç¡æ³æ§å¶çè¼¸åºåé¡ãæåéæ³¨æå°ï¼å°æ¼ç®åç GraphLLM æ¹æ³ä¸¦ä¸å­å¨æç¢ºçç¸®æ¾å®å¾ãæ­¤å¤ï¼çµæ§åèªç¾©å°æ¼ææçé¶æ¬¡å­¸ç¿å³è¼¸è³ééè¦ï¼èæåæåºçç°¡å®åºæºçè³å¯ä»¥åªæ¼éå°é¶æ¬¡å­¸ç¿å ´æ¯éèº«æé çå¹¾åæ¨¡åãåºæºçè³æåç¨å¼ç¢¼å¯ä»¥å¨ https://github.com/NineAbyss/GLBench ä¸­æ¾å°ã

##### **Decoding Climate Disagreement: A Graph Neural Network-Based Approach to Understanding Social Media Dynamics**
2407.07038v1 by Ruiran Su, Janet B. Pierrehumbert

This work introduces the ClimateSent-GAT Model, an innovative method that
integrates Graph Attention Networks (GATs) with techniques from natural
language processing to accurately identify and predict disagreements within
Reddit comment-reply pairs. Our model classifies disagreements into three
categories: agree, disagree, and neutral. Leveraging the inherent graph
structure of Reddit comment-reply pairs, the model significantly outperforms
existing benchmarks by capturing complex interaction patterns and sentiment
dynamics. This research advances graph-based NLP methodologies and provides
actionable insights for policymakers and educators in climate science
communication.

æè¦ï¼æ¬ç ç©¶ä»ç´¹ ClimateSent-GAT æ¨¡åï¼éæ¯ä¸ç¨®åµæ°çæ¹æ³ï¼å®å°åæ³¨æåç¶²è·¯ (GAT) èèªç¶èªè¨èçæè¡æ´åï¼ä»¥æºç¢ºè­å¥ä¸¦é æ¸¬ Reddit çè¨åè¦å°ä¸­çåæ­§ãæåçæ¨¡åå°åæ­§åçºä¸é¡ï¼åæãä¸åæåä¸­ç«ãééå©ç¨ Reddit çè¨åè¦å°çå§å¨åå½¢çµæ§ï¼æ­¤æ¨¡åè½å¤§å¹è¶è¶ç¾æåºæºï¼ææè¤éçäºåæ¨¡å¼åæç·åæãéé ç ç©¶æ¨åäºåºæ¼åå½¢ç NLP æ¹æ³ï¼ä¸¦çºæ°£åç§å­¸æºéä¸­çæ¿ç­å¶å®èåæè²å·¥ä½èæä¾å¯è¡çè¦è§£ã

##### **Graph-Based Captioning: Enhancing Visual Descriptions by Interconnecting Region Captions**
2407.06723v1 by Yu-Guan Hsieh, Cheng-Yu Hsieh, Shih-Ying Yeh, Louis BÃ©thune, Hadi Pour Ansari, Pavan Kumar Anasosalu Vasu, Chun-Liang Li, Ranjay Krishna, Oncel Tuzel, Marco Cuturi

Humans describe complex scenes with compositionality, using simple text
descriptions enriched with links and relationships. While vision-language
research has aimed to develop models with compositional understanding
capabilities, this is not reflected yet in existing datasets which, for the
most part, still use plain text to describe images. In this work, we propose a
new annotation strategy, graph-based captioning (GBC) that describes an image
using a labelled graph structure, with nodes of various types. The nodes in GBC
are created using, in a first stage, object detection and dense captioning
tools nested recursively to uncover and describe entity nodes, further linked
together in a second stage by highlighting, using new types of nodes,
compositions and relations among entities. Since all GBC nodes hold plain text
descriptions, GBC retains the flexibility found in natural language, but can
also encode hierarchical information in its edges. We demonstrate that GBC can
be produced automatically, using off-the-shelf multimodal LLMs and
open-vocabulary detection models, by building a new dataset, GBC10M, gathering
GBC annotations for about 10M images of the CC12M dataset. We use GBC10M to
showcase the wealth of node captions uncovered by GBC, as measured with CLIP
training. We show that using GBC nodes' annotations -- notably those stored in
composition and relation nodes -- results in significant performance boost on
downstream models when compared to other dataset formats. To further explore
the opportunities provided by GBC, we also propose a new attention mechanism
that can leverage the entire GBC graph, with encouraging experimental results
that show the extra benefits of incorporating the graph structure. Our datasets
are released at \url{https://huggingface.co/graph-based-captions}.

æè¦ï¼<paragraph>äººé¡ä½¿ç¨ç°¡å®çæå­æè¿°ï¼è±å¯çé£çµåéä¿ï¼ä¾æè¿°è¤éçå ´æ¯ãéç¶è¦è¦ºèªè¨çç ç©¶æ¨å¨éç¼å·æçµåçè§£è½åçæ¨¡åï¼ä½ç¾æçæ¸æéå°æªåæ éä¸é»ï¼éäºæ¸æéå¨å¾å¤§ç¨åº¦ä¸ä»ä½¿ç¨ç´ææ¬ä¾æè¿°ååãå¨éé å·¥ä½ä¸­ï¼æåæåºäºä¸ç¨®æ°çè¨»éç­ç¥ï¼åºæ¼åè¡¨çæ¨é¡ (GBC)ï¼å®ä½¿ç¨æ¨ç±¤åè¡¨çµæ§ä¾æè¿°ååï¼å¶ä¸­åå«åç¨®é¡åçç¯é»ãGBC ä¸­çç¯é»æ¯ä½¿ç¨ç©é«æª¢æ¸¬åå¯éæ¨é¡å·¥å·å¨ç¬¬ä¸éæ®µåµå»ºçï¼ä»¥éè¿´åµå¥çæ¹å¼ç¼ç¾åæè¿°å¯¦é«ç¯é»ï¼ä¸¦å¨ç¬¬äºéæ®µä½¿ç¨æ°é¡åçç¯é»çªåºé¡¯ç¤ºï¼å¾èå°å®åé²ä¸æ­¥é£çµå¨ä¸èµ·ï¼å¯¦é«ä¹éççµååéä¿ãç±æ¼ææ GBC ç¯é»é½åå«ç´ææ¬æè¿°ï¼å æ­¤ GBC ä¿çäºèªç¶èªè¨ä¸­çéæ´»æ§ï¼ä½ä¹å¯ä»¥å¨å¶éç·£ç·¨ç¢¼åå±¤ä¿¡æ¯ãæåè­æäº GBC å¯ä»¥ä½¿ç¨ç¾æçå¤æ¨¡æ LLM åéæ¾è©å½æª¢æ¸¬æ¨¡åèªåçæï¼ééæ§å»ºä¸åæ°çæ¸æé GBC10Mï¼æ¶éäºå¤§ç´ 10M CC12M æ¸æéååç GBC è¨»éãæåä½¿ç¨ GBC10M ä¾å±ç¤º GBC ç¼ç¾çè±å¯ç¯é»æ¨é¡ï¼ä¸¦ä½¿ç¨ CLIP è¨ç·´é²è¡æ¸¬éãæåè¡¨æï¼èå¶ä»æ¸æéæ ¼å¼ç¸æ¯ï¼ä½¿ç¨ GBC ç¯é»çè¨»éââç¹å¥æ¯å­å²å¨çµååéä¿ç¯é»ä¸­çè¨»éââæé¡¯èæåä¸æ¸¸æ¨¡åçæ§è½ãçºäºé²ä¸æ­¥æ¢ç´¢ GBC æä¾çæ©æï¼æåéæåºäºä¸ç¨®æ°çæ³¨ææ©å¶ï¼å®å¯ä»¥å©ç¨æ´å GBC åè¡¨ï¼ä¸¦ééé¼åµæ§çå¯¦é©çµæå±ç¤ºäºçµååè¡¨çµæ§çé¡å¤å¥½èãæåçæ¸æéç¼å¸å¨ \url{https://huggingface.co/graph-based-captions}ã</paragraph>

##### **Combining Knowledge Graphs and Large Language Models**
2407.06564v1 by Amanda Kau, Xuzeng He, Aishwarya Nambissan, Aland Astudillo, Hui Yin, Amir Aryani

In recent years, Natural Language Processing (NLP) has played a significant
role in various Artificial Intelligence (AI) applications such as chatbots,
text generation, and language translation. The emergence of large language
models (LLMs) has greatly improved the performance of these applications,
showing astonishing results in language understanding and generation. However,
they still show some disadvantages, such as hallucinations and lack of
domain-specific knowledge, that affect their performance in real-world tasks.
These issues can be effectively mitigated by incorporating knowledge graphs
(KGs), which organise information in structured formats that capture
relationships between entities in a versatile and interpretable fashion.
Likewise, the construction and validation of KGs present challenges that LLMs
can help resolve. The complementary relationship between LLMs and KGs has led
to a trend that combines these technologies to achieve trustworthy results.
This work collected 28 papers outlining methods for KG-powered LLMs, LLM-based
KGs, and LLM-KG hybrid approaches. We systematically analysed and compared
these approaches to provide a comprehensive overview highlighting key trends,
innovative techniques, and common challenges. This synthesis will benefit
researchers new to the field and those seeking to deepen their understanding of
how KGs and LLMs can be effectively combined to enhance AI applications
capabilities.

æè¦ï¼è¿å¹´æ¥ï¼èªç¶è¯­è¨å¤ç (NLP) å¨åç§äººå·¥æºè½ (AI) åºç¨ä¸­åæ¥äºéè¦ä½ç¨ï¼ä¾å¦èå¤©æºå¨äººãææ¬çæåè¯­è¨ç¿»è¯ãå¤§è¯­è¨æ¨¡å (LLM) çåºç°æå¤§å°æé«äºè¿äºåºç¨ç¨åºçæ§è½ï¼å¨è¯­è¨çè§£åçææ¹é¢æ¾ç¤ºåºæäººçç»æãç¶èï¼å®ä»¬ä»ç¶è¡¨ç°åºä¸äºç¼ºç¹ï¼ä¾å¦å¹»è§åç¼ºä¹ç¹å®é¢åçç¥è¯ï¼è¿äºç¼ºç¹ä¼å½±åå®ä»¬å¨ç°å®ä¸çä¸­çä»»å¡ä¸­çè¡¨ç°ãéè¿çº³å¥ç¥è¯å¾è°± (KG) å¯ä»¥ææå°åè½»è¿äºé®é¢ï¼ç¥è¯å¾è°±ä»¥ç»æåæ ¼å¼ç»ç»ä¿¡æ¯ï¼ä»¥å¤åè½ä¸å¯è§£éçæ¹å¼æè·å®ä½ä¹é´çå³ç³»ãåæ ·ï¼KG çæå»ºåéªè¯æåºäº LLM å¯ä»¥å¸®å©è§£å³çææãLLM å KG ä¹é´çäºè¡¥å³ç³»å¯¼è´äºä¸ç§å°è¿äºææ¯ç¸ç»åä»¥å®ç°å¯ä¿¡ç»æçè¶å¿ãè¿é¡¹å·¥ä½æ¶éäº 28 ç¯æ¦è¿°äº KG é©±å¨ç LLMãåºäº LLM ç KG å LLM-KG æ··åæ¹æ³çæ¹æ³çè®ºæãæä»¬ç³»ç»å°åæåæ¯è¾äºè¿äºæ¹æ³ï¼ä»¥æä¾ä¸ä¸ªå¨é¢çæ¦è¿°ï¼éç¹ä»ç»å³é®è¶å¿ãåæ°ææ¯åå±åææãè¿ç§ç»¼åå°ä½¿è¯¥é¢åçæ°ç ç©¶äººååé£äºå¯»æ±å æ·±å¯¹å¦ä½ææå°å° KG å LLM ç¸ç»åä»¥å¢å¼º AI åºç¨è½åççè§£çäººåçã

##### **FuncEvalGMN: Evaluating Functional Correctness of SQL via Graph Matching Network**
2407.14530v1 by Yi Zhan, Yang Sun, Han Weng, Longjie Cui, Guifeng Wang, Jiajun Xie, Yu Tian, Xiaoming Yin, Boyi Liu, Dongchi Huang

In this paper, we propose a novel graph-based methodology to evaluate the
functional correctness of SQL generation. Conventional metrics for assessing
SQL code generation, such as matching-based and execution-based methods (e.g.,
exact set match and execution accuracy), are subject to two primary
limitations. Firstly, the former fails to effectively assess functional
correctness, as different SQL queries may possess identical functionalities.
Secondly, the latter is susceptible to producing false positive samples in
evaluations. Our proposed evaluation method, \texttt{FuncEvalGMN}, does not
depend on the sufficient preparation of the test data, and it enables precise
testing of the functional correctness of the code. Firstly, we parse SQL using
a relational operator tree (ROT) called \textit{Relnode}, which contains rich
semantic information from the perspective of logical execution.Then, we
introduce a GNN-based approach for predicting the functional correctness of
generated SQL. This approach incorporates global positional embeddings to
address the limitations with the loss of topological information in
conventional graph matching frameworks. As an auxiliary contribution, we
propose a rule-based matching algorithm, Relnode Partial Matching
(\texttt{RelPM}) as a baseline. Finally, we contribute a dataset,
\texttt{Pair-Aug-Spider} with a training set and two testing sets, each
comprising pairs of SQL codes to simulate various SQL code evaluation
scenarios. The training set and one testing dataset focus on code generation
using large language models (LLMs), while the other emphasizes SQL equivalence
rewriting.

æè¦ï¼<paragraph>å¨æ¬æä¸­ï¼æåæåºäºä¸ç¨®æ°ç©çåºæ¼åçæ¹æ³ä¾è©ä¼° SQL çæçåè½æ­£ç¢ºæ§ãè©ä¼° SQL ç¨å¼ç¢¼çæçå³çµ±ææ¨ï¼ä¾å¦åºæ¼å¹éååºæ¼å·è¡çææ¨ï¼ä¾å¦ï¼ç²¾ç¢ºéåå¹éåå·è¡æºç¢ºåº¦ï¼ï¼å­å¨å©åä¸»è¦çéå¶ãé¦åï¼åèç¡æ³ææè©ä¼°åè½æ­£ç¢ºæ§ï¼å çºä¸åç SQL æ¥è©¢å¯è½å·æç¸åçæ©è½ãå¶æ¬¡ï¼å¾èå¨è©ä¼°ä¸­å®¹æç¢çåé½æ§æ¨£æ¬ãæåæåºçè©ä¼°æ¹æ³ \texttt{FuncEvalGMN} ä¸ä¾è³´æ¼æ¸¬è©¦è³æçååæºåï¼ä¸¦ä¸å¯ä»¥ç²¾ç¢ºæ¸¬è©¦ç¨å¼ç¢¼çåè½æ­£ç¢ºæ§ãé¦åï¼æåä½¿ç¨ç¨±çº \textit{Relnode} çéä¿éç®åæ¨¹ (ROT) ä¾è§£æ SQLï¼å¶ä¸­åå«å¾éè¼¯å·è¡çè§åº¦ä¾çè±å¯çèªç¾©è³è¨ãç¶å¾ï¼æåå¼å¥ä¸ç¨®åºæ¼ GNN çæ¹æ³ä¾é æ¸¬çæç SQL çåè½æ­£ç¢ºæ§ãéç¨®æ¹æ³çµåäºå¨å±ä½ç½®åµå¥ï¼ä»¥è§£æ±ºå³çµ±åå½¢å¹éæ¡æ¶ä¸­ææ²è³è¨éºå¤±çéå¶ãä½çºè¼å©è²¢ç»ï¼æåæåºäºä¸ååºæ¼è¦åçå¹éæ¼ç®æ³ï¼å³ Relnode é¨åå¹é (\texttt{RelPM}) ä½çºåºç·ãæå¾ï¼æåè²¢ç»äºä¸åè³æé \texttt{Pair-Aug-Spider}ï¼å¶ä¸­åå«ä¸åè¨ç·´éåå©åæ¸¬è©¦éï¼æ¯åæ¸¬è©¦éé½åå«æå°ç SQL ç¨å¼ç¢¼ä¾æ¨¡æ¬åç¨® SQL ç¨å¼ç¢¼è©ä¼°å ´æ¯ãè¨ç·´éåä¸åæ¸¬è©¦è³æéå°æ³¨æ¼ä½¿ç¨å¤§åèªè¨æ¨¡å (LLM) é²è¡ç¨å¼ç¢¼çæï¼èå¦ä¸ååå¼·èª¿ SQL ç­å¹éå¯«ã</paragraph>

##### **MST5 -- Multilingual Question Answering over Knowledge Graphs**
2407.06041v1 by Nikit Srivastava, Mengshi Ma, Daniel Vollmers, Hamada Zahera, Diego Moussallem, Axel-Cyrille Ngonga Ngomo

Knowledge Graph Question Answering (KGQA) simplifies querying vast amounts of
knowledge stored in a graph-based model using natural language. However, the
research has largely concentrated on English, putting non-English speakers at a
disadvantage. Meanwhile, existing multilingual KGQA systems face challenges in
achieving performance comparable to English systems, highlighting the
difficulty of generating SPARQL queries from diverse languages. In this
research, we propose a simplified approach to enhance multilingual KGQA systems
by incorporating linguistic context and entity information directly into the
processing pipeline of a language model. Unlike existing methods that rely on
separate encoders for integrating auxiliary information, our strategy leverages
a single, pretrained multilingual transformer-based language model to manage
both the primary input and the auxiliary data. Our methodology significantly
improves the language model's ability to accurately convert a natural language
query into a relevant SPARQL query. It demonstrates promising results on the
most recent QALD datasets, namely QALD-9-Plus and QALD-10. Furthermore, we
introduce and evaluate our approach on Chinese and Japanese, thereby expanding
the language diversity of the existing datasets.

æè¦ï¼ç¥è­åè¡¨åç­ (KGQA) ç°¡åäºä½¿ç¨èªç¶èªè¨æ¥è©¢å²å­å¨åå½¢åæ¨¡åä¸­çå¤§éç¥è­ãç¶èï¼ç ç©¶ä¸»è¦éä¸­å¨è±æä¸ï¼éå°éè±èªä½¿ç¨èä¾èªªæ¯ä¸å©çãåæï¼ç¾æçå¤èªè¨ KGQA ç³»çµ±å¨éæèè±æç³»çµ±ç¸åª²ç¾çæè½æ¹é¢é¢è¨ææ°ï¼çªé¡¯äºå¾ä¸åèªè¨ç¢ç SPARQL æ¥è©¢çå°é£æ§ãå¨éé ç ç©¶ä¸­ï¼æåæåºäºä¸ç¨®ç°¡åçæ¹æ³ï¼ééå°èªè¨å­¸èæ¯åå¯¦é«è³è¨ç´æ¥ç´å¥èªè¨æ¨¡åçèçç®¡éï¼ä¾å¢å¼·å¤èªè¨ KGQA ç³»çµ±ãèä¾è³´æ¼å®ç¨ç·¨ç¢¼å¨ä¾æ´åè¼å©è³è¨çç¾ææ¹æ³ä¸åï¼æåçç­ç¥å©ç¨å®ä¸çãé è¨ç·´çå¤èªè¨è½æå¨èªè¨æ¨¡åä¾ç®¡çä¸»è¦è¼¸å¥åè¼å©è³æãæåçæè¡é¡¯èæåäºèªè¨æ¨¡åæºç¢ºå°å°èªç¶èªè¨æ¥è©¢è½æçºç¸é SPARQL æ¥è©¢çè½åãå®å¨ææ°ç QALD è³æéï¼å³ QALD-9-Plus å QALD-10 ä¸å±ç¤ºäºæå¸æççµæãæ­¤å¤ï¼æåå¨ä¸­æåæ¥æä¸­å¼å¥ä¸¦è©ä¼°äºæåçåæ³ï¼å¾èæ´å±äºç¾æè³æéçèªè¨å¤æ¨£æ§ã

##### **Enhancing Vision-Language Models with Scene Graphs for Traffic Accident Understanding**
2407.05910v1 by Aaron Lohner, Francesco Compagno, Jonathan Francis, Alessandro Oltramari

Recognizing a traffic accident is an essential part of any autonomous driving
or road monitoring system. An accident can appear in a wide variety of forms,
and understanding what type of accident is taking place may be useful to
prevent it from reoccurring. The task of being able to classify a traffic scene
as a specific type of accident is the focus of this work. We approach the
problem by likening a traffic scene to a graph, where objects such as cars can
be represented as nodes, and relative distances and directions between them as
edges. This representation of an accident can be referred to as a scene graph,
and is used as input for an accident classifier. Better results can be obtained
with a classifier that fuses the scene graph input with representations from
vision and language. This work introduces a multi-stage, multimodal pipeline to
pre-process videos of traffic accidents, encode them as scene graphs, and align
this representation with vision and language modalities for accident
classification. When trained on 4 classes, our method achieves a balanced
accuracy score of 57.77% on an (unbalanced) subset of the popular Detection of
Traffic Anomaly (DoTA) benchmark, representing an increase of close to 5
percentage points from the case where scene graph information is not taken into
account.

æè¦ï¼è¾¨è­äº¤éäºææ¯ä»»ä½èªåé§é§æéè·¯ç£æ§ç³»çµ±çå¿è¦é¨åãäºæå¯è½ä»¥åç¨®å½¢å¼åºç¾ï¼äºè§£äºæé¡åå¯è½æå©æ¼é²æ­¢åæ¬¡ç¼çãå°äº¤éäºæå ´æ¯åé¡çºç¹å®äºæé¡åçä»»åæ¯éé å·¥ä½çéé»ãæåå°äº¤éäºæå ´æ¯æ¯å»çºåå½¢ä¾è§£æ±ºåé¡ï¼å¶ä¸­æ±½è»ç­ç©é«å¯ä»¥è¡¨ç¤ºçºç¯é»ï¼èå®åä¹éçç¸å°è·é¢åæ¹ååè¡¨ç¤ºçºéç·£ãéç¨®äºæè¡¨ç¤ºå¯ä»¥ç¨±çºå ´æ¯åï¼ä¸¦ç¨ä½äºæåé¡å¨çè¼¸å¥ãä½¿ç¨å°å ´æ¯åè¼¸å¥èè¦è¦ºåèªè¨è¡¨ç¤ºèåçåé¡å¨å¯ä»¥ç²å¾æ´å¥½ççµæãéé å·¥ä½å¼å¥äºä¸åå¤éæ®µãå¤æ¨¡æç®¡éï¼ç¨æ¼é èçäº¤éäºæå½±çãå°å¶ç·¨ç¢¼çºå ´æ¯åï¼ä»¥åå°æ­¤è¡¨ç¤ºèè¦è¦ºåèªè¨æ¨¡å¼å°é½ä»¥é²è¡äºæåé¡ãç¶å¨ 4 åé¡å¥ä¸é²è¡è¨ç·´æï¼æåçæ¨¡åå¨ç±éäº¤éç°å¸¸æª¢æ¸¬ (DoTA) åºæºçï¼ä¸å¹³è¡¡ï¼å­éä¸å¯¦ç¾äº 57.77% çå¹³è¡¡æºç¢ºçï¼æ¯ä¸èæ®å ´æ¯åè³è¨çææ³æé«äºæ¥è¿ 5 åç¾åé»ã

##### **Affordances-Oriented Planning using Foundation Models for Continuous Vision-Language Navigation**
2407.05890v1 by Jiaqi Chen, Bingqian Lin, Xinmin Liu, Xiaodan Liang, Kwan-Yee K. Wong

LLM-based agents have demonstrated impressive zero-shot performance in the
vision-language navigation (VLN) task. However, these zero-shot methods focus
only on solving high-level task planning by selecting nodes in predefined
navigation graphs for movements, overlooking low-level control in realistic
navigation scenarios. To bridge this gap, we propose AO-Planner, a novel
affordances-oriented planning framework for continuous VLN task. Our AO-Planner
integrates various foundation models to achieve affordances-oriented motion
planning and action decision-making, both performed in a zero-shot manner.
Specifically, we employ a visual affordances prompting (VAP) approach, where
visible ground is segmented utilizing SAM to provide navigational affordances,
based on which the LLM selects potential next waypoints and generates low-level
path planning towards selected waypoints. We further introduce a high-level
agent, PathAgent, to identify the most probable pixel-based path and convert it
into 3D coordinates to fulfill low-level motion. Experimental results on the
challenging R2R-CE benchmark demonstrate that AO-Planner achieves
state-of-the-art zero-shot performance (5.5% improvement in SPL). Our method
establishes an effective connection between LLM and 3D world to circumvent the
difficulty of directly predicting world coordinates, presenting novel prospects
for employing foundation models in low-level motion control.

æè¦ï¼åºæ¼ LLM çä»£çå·²å¨è¦è¦ºèªè¨å°èª (VLN) ä»»åä¸­å±ç¤ºåºä»¤äººå°è±¡æ·±å»çé¶æ¬¡å­¸ç¿æè½ãç¶èï¼éäºé¶æ¬¡å­¸ç¿æ¹æ³åå°æ³¨æ¼ééé¸æé å®ç¾©å°èªåå½¢ä¸­çç¯é»ä¾è§£æ±ºé«éä»»åè¦åï¼å¿½ç¥äºå¯¦éå°èªå ´æ¯ä¸­çä½éæ§å¶ãçºäºå½åæ­¤å·®è·ï¼æåæåº AO-Plannerï¼ä¸åç¨æ¼é£çº VLN ä»»åçæ°åä»¥å¯è² ææ§çºå°åçè¦åæ¶æ§ãæåç AO-Planner æ´ååç¨®åºç¤æ¨¡åï¼ä»¥å¯¦ç¾ä»¥å¯è² ææ§çºå°åçåä½è¦åååä½æ±ºç­ï¼å©èé½ä»¥é¶æ¬¡å­¸ç¿çæ¹å¼å·è¡ãå·é«ä¾èªªï¼æåæ¡ç¨è¦è¦ºå¯è² ææ§æç¤º (VAP) æ¹æ³ï¼å¶ä¸­å©ç¨ SAM å°å¯è¦å°é¢é²è¡åå²ï¼ä»¥æä¾å°èªå¯è² ææ§ï¼LLM æ ¹æéäºå¯è² ææ§é¸ææ½å¨çä¸ä¸åèªé»ï¼ä¸¦éå°æé¸èªé»ç¢çä½éè·¯å¾è¦åãæåé²ä¸æ­¥å¼å¥ä¸åé«éä»£ç PathAgentï¼ä»¥è­å¥æå¯è½çåºæ¼åç´ çè·¯å¾ï¼ä¸¦å°å¶è½æçº 3D åº§æ¨ï¼ä»¥å¯¦ç¾ä½éåä½ãå¨å·æææ°æ§ç R2R-CE åºæºæ¸¬è©¦ä¸çå¯¦é©çµæè¡¨æï¼AO-Planner éå°äºæåé²çé¶æ¬¡å­¸ç¿æè½ï¼SPL æå 5.5%ï¼ãæåçæ¨¡åå¨ LLM å 3D ä¸çä¹éå»ºç«äºä¸åææçé£çµï¼ä»¥è¦é¿ç´æ¥é æ¸¬ä¸çåº§æ¨çé£é¡ï¼çºå¨ä½éåä½æ§å¶ä¸­æ¡ç¨åºç¤æ¨¡åæä¾äºæ°çåæ¯ã

##### **KG-FPQ: Evaluating Factuality Hallucination in LLMs with Knowledge Graph-based False Premise Questions**
2407.05868v1 by Yanxu Zhu, Jinlin Xiao, Yuhang Wang, Jitao Sang

Recent studies have demonstrated that large language models (LLMs) are
susceptible to being misled by false premise questions (FPQs), leading to
errors in factual knowledge, know as factuality hallucination. Existing
benchmarks that assess this vulnerability primarily rely on manual
construction, resulting in limited scale and lack of scalability. In this work,
we introduce an automated, scalable pipeline to create FPQs based on knowledge
graphs (KGs). The first step is modifying true triplets extracted from KGs to
create false premises. Subsequently, utilizing the state-of-the-art
capabilities of GPTs, we generate semantically rich FPQs. Based on the proposed
method, we present a comprehensive benchmark, the Knowledge Graph-based False
Premise Questions (KG-FPQ), which contains approximately 178k FPQs across three
knowledge domains, at six levels of confusability, and in two task formats.
Using KG-FPQ, we conduct extensive evaluations on several representative LLMs
and provide valuable insights. The KG-FPQ dataset and code are available
at~https://github.com/yanxuzhu/KG-FPQ.

æè¦ï¼æè¿çç ç©¶è¡¨æï¼å¤§åè¯­è¨æ¨¡å (LLM) å®¹æè¢«éè¯¯åæé®é¢ (FPQ) è¯¯å¯¼ï¼ä»èå¯¼è´äºå®ç¥è¯éè¯¯ï¼å³äºå®å¹»è§ãç¨äºè¯ä¼°æ­¤æ¼æ´çç°æåºåä¸»è¦ä¾èµäºæå¨æå»ºï¼å¯¼è´è§æ¨¡æéä¸ç¼ºä¹å¯æ©å±æ§ãå¨è¿é¡¹å·¥ä½ä¸­ï¼æä»¬å¼å¥äºä¸ä¸ªåºäºç¥è¯å¾è°± (KG) åå»º FPQ çèªå¨åå¯æ©å±ç®¡éãç¬¬ä¸æ­¥æ¯ä¿®æ¹ä» KG ä¸­æåççä¸åç»ä»¥åå»ºéè¯¯åæãéåï¼å©ç¨ GPT çæåè¿åè½ï¼æä»¬çæäºè¯­ä¹ä¸°å¯ç FPQãåºäºææåºçæ¹æ³ï¼æä»¬æåºäºä¸ä¸ªç»¼ååºåï¼å³åºäºç¥è¯å¾è°±çéè¯¯åæé®é¢ (KG-FPQ)ï¼å®åå«å¤§çº¦ 178k ä¸ª FPQï¼æ¶µçä¸ä¸ªç¥è¯åï¼å­ä¸ªæ··æ·çº§å«åä¸¤ç§ä»»å¡æ ¼å¼ãä½¿ç¨ KG-FPQï¼æä»¬å¯¹å ä¸ªæä»£è¡¨æ§ç LLM è¿è¡äºå¹¿æ³çè¯ä¼°ï¼å¹¶æä¾äºæä»·å¼çè§è§£ãKG-FPQ æ°æ®éåä»£ç å¯å¨~https://github.com/yanxuzhu/KG-FPQ è·å¾ã

##### **Language Models Encode Collaborative Signals in Recommendation**
2407.05441v1 by Leheng Sheng, An Zhang, Yi Zhang, Yuxin Chen, Xiang Wang, Tat-Seng Chua

Recent studies empirically indicate that language models (LMs) encode rich
world knowledge beyond mere semantics, attracting significant attention across
various fields. However, in the recommendation domain, it remains uncertain
whether LMs implicitly encode user preference information. Contrary to the
prevailing understanding that LMs and traditional recommender models learn two
distinct representation spaces due to a huge gap in language and behavior
modeling objectives, this work rethinks such understanding and explores
extracting a recommendation space directly from the language representation
space. Surprisingly, our findings demonstrate that item representations, when
linearly mapped from advanced LM representations, yield superior recommendation
performance. This outcome suggests the homomorphism between the language
representation space and an effective recommendation space, implying that
collaborative signals may indeed be encoded within advanced LMs. Motivated by
these findings, we propose a simple yet effective collaborative filtering (CF)
model named AlphaRec, which utilizes language representations of item textual
metadata (e.g., titles) instead of traditional ID-based embeddings.
Specifically, AlphaRec is comprised of three main components: a multilayer
perceptron (MLP), graph convolution, and contrastive learning (CL) loss
function, making it extremely easy to implement and train. Our empirical
results show that AlphaRec outperforms leading ID-based CF models on multiple
datasets, marking the first instance of such a recommender with text embeddings
achieving this level of performance. Moreover, AlphaRec introduces a new
language-representation-based CF paradigm with several desirable advantages:
being easy to implement, lightweight, rapid convergence, superior zero-shot
recommendation abilities in new domains, and being aware of user intention.

æè¦ï¼<paragraph>æè¿çç ç©¶å¯¦è­è¡¨æï¼èªè¨æ¨¡å (LM) ç·¨ç¢¼è±å¯çä¸çç¥è­ï¼è¶è¶äºå®ç´çèªç¾©ï¼å¸å¼äºååé åçæ¥µå¤§éæ³¨ãç¶èï¼å¨æ¨è¦é åä¸­ï¼LM æ¯å¦é±å«ç·¨ç¢¼ä½¿ç¨èåå¥½è³è¨ä»ä¸ç¢ºå®ãèæ®éèªç¥ç¸åï¼LM åå³çµ±æ¨è¦æ¨¡åç±æ¼èªè¨åè¡çºå»ºæ¨¡ç®æ¨çå·¨å¤§å·®è·èå­¸ç¿å©åä¸åçè¡¨ç¤ºç©ºéï¼éé å·¥ä½éæ°æèéç¨®çè§£ï¼ä¸¦æ¢ç´¢ç´æ¥å¾èªè¨è¡¨ç¤ºç©ºéä¸­æåæ¨è¦ç©ºéãä»¤äººé©è¨çæ¯ï¼æåçç ç©¶çµæè¡¨æï¼ç¶å¾åé²ç LM è¡¨ç¤ºä¸­ç·æ§æ å°æï¼é ç®è¡¨ç¤ºæç¢çåªç°çæ¨è¦æè½ãæ­¤çµæè¡¨æèªè¨è¡¨ç¤ºç©ºéåææçæ¨è¦ç©ºéä¹éå­å¨åææ§ï¼éæå³èåä½è¨èç¢ºå¯¦å¯è½ç·¨ç¢¼å¨åé²ç LM ä¸­ãåéäºç ç©¶çµæçåç¼ï¼æåæåºäºä¸åç°¡å®ä½ææçååéæ¿¾ (CF) æ¨¡åï¼åçº AlphaRecï¼å®å©ç¨é ç®æå­åè³æï¼ä¾å¦æ¨é¡ï¼çèªè¨è¡¨ç¤ºï¼èä¸æ¯å³çµ±åºæ¼ ID çåµå¥ãå·é«ä¾èªªï¼AlphaRec ç±ä¸åä¸»è¦çµæé¨åçµæï¼å¤å±¤æç¥å¨ (MLP)ãåå½¢å·ç©åå°æ¯å­¸ç¿ (CL) æå¤±å½æ¸ï¼ä½¿å¶æ¥µææ¼å¯¦ä½åè¨ç·´ãæåçå¯¦è­çµæè¡¨æï¼AlphaRec å¨å¤åè³æéä¸åªæ¼é åçåºæ¼ ID ç CF æ¨¡åï¼æ¨èªèéç¨®å·ææå­åµå¥çæ¨è¦ç³»çµ±é¦æ¬¡éå°æ­¤æè½æ°´æºãæ­¤å¤ï¼AlphaRec å¼å¥äºä¸åæ°çåºæ¼èªè¨è¡¨ç¤ºç CF å¸ç¯ï¼å·æå¤é çæ³çåªé»ï¼ææ¼å¯¦ä½ãè¼éç´ãå¿«éæ¶æãå¨æ°çé åä¸­å·æåªç°çé¶æ¬¡å­¸ç¿æ¨è¦è½åï¼ä¸¦ä¸å¯ä»¥äºè§£ä½¿ç¨èçæåã</paragraph>

##### **LTLBench: Towards Benchmarks for Evaluating Temporal Logic Reasoning in Large Language Models**
2407.05434v1 by Weizhi Tang, Vaishak Belle

Temporal reasoning (TR) is a critical component of artificial intelligence,
encompassing understanding and processing temporal information and
relationships between events. To discover and study the TR ability in Large
Language Models (LLMs), various datasets have been constructed in different
ways for evaluating various aspects of TR ability. Our work proposes a novel
approach to design and develop a pipeline for constructing datasets to evaluate
the TR ability of LLMs by leveraging random directed graph generation, LTL
formula, and the NuSMV model checker. Based on the pipeline, we have also
constructed a dataset as a benchmark, namely LTLBench, consisting of 2,000 TR
challenges and evaluated six LLMs with it. Furthermore, we have conducted
additional experiments to discover the impact of increasing the number of
events and formula operators on the complexity of TR problems and the
performance of LLMs. We have demonstrated that although LLMs exhibit some
promise in handling TR challenges, they still struggle with complex TR. We
expect this work can offer insights into TR ability in LLMs while also
providing a valuable tool for future TR evaluations.

æè¦ï¼æéæ¨ç (TR) æ¯äººå·¥æºæ§çä¸é ééµçµæé¨åï¼
æ¶µèäºå°æéè³è¨åäºä»¶ä¹ééä¿ççè§£åèçãçºäºç¼ç¾åç ç©¶å¤§åèªè¨æ¨¡å (LLM) ä¸­ç TR è½åï¼å·²ééåç¨®æ¹å¼å»ºæ§åç¨®è³æéï¼ç¨æ¼è©ä¼° TR è½åçååé¢åãæåçå·¥ä½æåºäºä¸ç¨®æ°ç©çæ¹æ³ï¼ç¨æ¼è¨­è¨åéç¼ä¸åå»ºæ§è³æéçç®¡éï¼ä»¥è©ä¼° LLM ç TR è½åï¼æ¹æ³æ¯å©ç¨é¨æ©æååçæãLTL å¬å¼å NuSMV æ¨¡åæª¢æ¥å¨ãæ ¹æéåç®¡éï¼æåéå»ºæ§äºä¸åè³æéä½çºåºæºï¼å³ LTLBenchï¼å¶ä¸­åå« 2,000 å TR ææ°ï¼ä¸¦ç¨å®è©ä¼°äºå­å LLMãæ­¤å¤ï¼æåéé²è¡äºé¡å¤çå¯¦é©ï¼ä»¥ç¼ç¾å¢å äºä»¶æ¸éåå¬å¼éç®å­å° TR åé¡è¤éæ§å LLM æè½çå½±é¿ãæåå·²ç¶è­æï¼åç®¡ LLM å¨èç TR ææ°æ¹é¢è¡¨ç¾åºä¸äºå¸æï¼ä½å®åä»ç¶é£ä»¥èçè¤éç TRãæåé æéé å·¥ä½å¯ä»¥æä¾å° LLM ä¸­ TR è½åçè¦è§£ï¼åæä¹çºæªä¾ç TR è©ä¼°æä¾ä¸åæå¹å¼çå·¥å·ã

##### **Leveraging Graph Structures to Detect Hallucinations in Large Language Models**
2407.04485v1 by Noa Nonkes, Sergei Agaronian, Evangelos Kanoulas, Roxana Petcu

Large language models are extensively applied across a wide range of tasks,
such as customer support, content creation, educational tutoring, and providing
financial guidance. However, a well-known drawback is their predisposition to
generate hallucinations. This damages the trustworthiness of the information
these models provide, impacting decision-making and user confidence. We propose
a method to detect hallucinations by looking at the structure of the latent
space and finding associations within hallucinated and non-hallucinated
generations. We create a graph structure that connects generations that lie
closely in the embedding space. Moreover, we employ a Graph Attention Network
which utilizes message passing to aggregate information from neighboring nodes
and assigns varying degrees of importance to each neighbor based on their
relevance. Our findings show that 1) there exists a structure in the latent
space that differentiates between hallucinated and non-hallucinated
generations, 2) Graph Attention Networks can learn this structure and
generalize it to unseen generations, and 3) the robustness of our method is
enhanced when incorporating contrastive learning. When evaluated against
evidence-based benchmarks, our model performs similarly without access to
search-based methods.

æè¦ï¼å¤§åèªè¨æ¨¡åå»£æ³æç¨æ¼åç¨®ä»»åä¸­ï¼ä¾å¦å®¢æ¶æ¯æ´ãå§å®¹åµä½ãæè²è¼å°åæä¾è²¡åæå°ãç¶èï¼ä¸åç¾æå¨ç¥çç¼ºé»æ¯å®åå¾åæ¼ç¢çå¹»è¦ºãéæå®³äºéäºæ¨¡åææä¾è³è¨çå¯ä¿¡åº¦ï¼å½±é¿äºæ±ºç­å¶å®åä½¿ç¨èä¿¡å¿ãæåæåºäºä¸ç¨®ééè§å¯æ½å¨ç©ºéççµæ§ä¸¦æ¾åºå¹»è¦ºåéå¹»è¦ºçæä¸­çéè¯ä¾åµæ¸¬å¹»è¦ºçæ¹æ³ãæåå»ºç«äºä¸ååå½¢çµæ§ï¼é£æ¥å¨åµå¥ç©ºéä¸­ç·å¯ç¸é£ççæãæ­¤å¤ï¼æåæ¡ç¨äºä¸ååå½¢æ³¨æåç¶²è·¯ï¼å®å©ç¨è¨æ¯å³éä¾å½ç¸½ä¾èªç¸é°ç¯é»çè³è¨ï¼ä¸¦æ ¹ææ¯åç¸é°ç¯é»çç¸éæ§çºå¶æå®ä¸åç¨åº¦çéè¦æ§ãæåçç ç©¶çµæé¡¯ç¤ºï¼1) æ½å¨ç©ºéä¸­å­å¨ä¸åçµæ§ï¼å¯ä»¥ååå¹»è¦ºåéå¹»è¦ºçæï¼2) åå½¢æ³¨æåç¶²è·¯å¯ä»¥å­¸ç¿éåçµæ§ä¸¦å°å¶æ¦æ¬å°æªè¦ççæä¸­ï¼ä»¥å 3) ç¶ç´å¥å°æ¯å­¸ç¿æï¼æåæ¹æ³çç©©å¥æ§æå¾å°å¢å¼·ãç¶æ ¹æåºæ¼è­æçåºæºé²è¡è©ä¼°æï¼æåçæ¨¡åå¨ç¡æ³åå¾åºæ¼æå°çæ¹æ³çææ³ä¸ï¼è¡¨ç¾å¾é¡ä¼¼ã

##### **AriGraph: Learning Knowledge Graph World Models with Episodic Memory for LLM Agents**
2407.04363v1 by Petr Anokhin, Nikita Semenov, Artyom Sorokin, Dmitry Evseev, Mikhail Burtsev, Evgeny Burnaev

Advancements in generative AI have broadened the potential applications of
Large Language Models (LLMs) in the development of autonomous agents. Achieving
true autonomy requires accumulating and updating knowledge gained from
interactions with the environment and effectively utilizing it. Current
LLM-based approaches leverage past experiences using a full history of
observations, summarization or retrieval augmentation. However, these
unstructured memory representations do not facilitate the reasoning and
planning essential for complex decision-making. In our study, we introduce
AriGraph, a novel method wherein the agent constructs a memory graph that
integrates semantic and episodic memories while exploring the environment. This
graph structure facilitates efficient associative retrieval of interconnected
concepts, relevant to the agent's current state and goals, thus serving as an
effective environmental model that enhances the agent's exploratory and
planning capabilities. We demonstrate that our Ariadne LLM agent, equipped with
this proposed memory architecture augmented with planning and decision-making,
effectively handles complex tasks on a zero-shot basis in the TextWorld
environment. Our approach markedly outperforms established methods such as
full-history, summarization, and Retrieval-Augmented Generation in various
tasks, including the cooking challenge from the First TextWorld Problems
competition and novel tasks like house cleaning and puzzle Treasure Hunting.

æè¦ï¼çæå¼ AI çé²æ­¥æ´å±äºå¤§åèªè¨æ¨¡å (LLM) å¨èªä¸»ä»£çéç¼ä¸­çæ½å¨æç¨ãå¯¦ç¾çæ­£çèªä¸»æ§éè¦ç´¯ç©åæ´æ°å¾èç°å¢äºåä¸­ç²å¾çç¥è­ï¼ä¸¦ææå©ç¨å®ãç¶åçåºæ¼ LLM çæ¹æ³å©ç¨éå»çç¶é©ï¼ä½¿ç¨å®æ´çè§å¯ãæè¦ææª¢ç´¢æ´åãç¶èï¼éäºéçµæ§åçè¨æ¶è¡¨å¾µä¸¦ä¸è½ä¿é²è¤éæ±ºç­å¶å®ä¸­å¿ä¸å¯å°çæ¨çåè¦åãå¨æåçç ç©¶ä¸­ï¼æåä»ç´¹äº AriGraphï¼éæ¯ä¸ç¨®æ°æ¹æ³ï¼å¶ä¸­ä»£çæ§å»ºäºä¸åè¨æ¶åï¼è©²åå¨æ¢ç´¢ç°å¢ææ´åäºèªç¾©åæç¯è¨æ¶ãéç¨®åå½¢çµæ§ä¿é²äºç¸äºè¯ç¹«çæ¦å¿µçææéè¯æ§æª¢ç´¢ï¼èä»£ççç¶åçæåç®æ¨ç¸éï¼å¾èä½çºä¸åææçç°å¢æ¨¡åï¼å¢å¼·äºä»£ççæ¢ç´¢åè¦åè½åãæåå±ç¤ºäºæåç Ariadne LLM ä»£çï¼éåäºéç¨®æè­°çè¨æ¶æ¶æ§ï¼ä¸¦å¢å¼·äºè¦ååæ±ºç­å¶å®ï¼ææå°èçäº TextWorld ç°å¢ä¸­é¶æ¬¡å­¸ç¿çè¤éä»»åãæåçåæ³é¡¯èåªæ¼å·²å»ºç«çæ¹æ³ï¼ä¾å¦å®æ´æ­·å²ãæè¦åæª¢ç´¢å¢å¼·çæï¼å¨åç¨®ä»»åä¸­ï¼åæ¬ä¾èªç¬¬ä¸å TextWorld åé¡ç«¶è³½çç¹é£ªææ°åæ¿å±æ¸æ½åæ¼åå°å¯¶ç­æ°ä»»åã

##### **Semantic Graphs for Syntactic Simplification: A Revisit from the Age of LLM**
2407.04067v1 by Peiran Yao, Kostyantyn Guzhva, Denilson Barbosa

Symbolic sentence meaning representations, such as AMR (Abstract Meaning
Representation) provide expressive and structured semantic graphs that act as
intermediates that simplify downstream NLP tasks. However, the
instruction-following capability of large language models (LLMs) offers a
shortcut to effectively solve NLP tasks, questioning the utility of semantic
graphs. Meanwhile, recent work has also shown the difficulty of using meaning
representations merely as a helpful auxiliary for LLMs. We revisit the position
of semantic graphs in syntactic simplification, the task of simplifying
sentence structures while preserving their meaning, which requires semantic
understanding, and evaluate it on a new complex and natural dataset. The
AMR-based method that we propose, AMRS$^3$, demonstrates that state-of-the-art
meaning representations can lead to easy-to-implement simplification methods
with competitive performance and unique advantages in cost, interpretability,
and generalization. With AMRS$^3$ as an anchor, we discover that syntactic
simplification is a task where semantic graphs are helpful in LLM prompting. We
propose AMRCoC prompting that guides LLMs to emulate graph algorithms for
explicit symbolic reasoning on AMR graphs, and show its potential for improving
LLM on semantic-centered tasks like syntactic simplification.

æè¦ï¼ç¬¦èå¥å­æç¾©è¡¨å¾µï¼ä¾å¦ AMRï¼æ½è±¡æç¾©è¡¨å¾µï¼ï¼æä¾è¡¨éæ§åçµæ§åçèªç¾©åè¡¨ï¼ä½çºç°¡åä¸æ¸¸ NLP ä»»åçä¸­ä»ãç¶èï¼å¤§åèªè¨æ¨¡å (LLM) çæä»¤éµå¾ªè½åæä¾äºä¸åæ·å¾ä¾ææè§£æ±º NLP ä»»åï¼è³ªçèªç¾©åè¡¨çæç¨ãåæï¼æè¿çç ç©¶ä¹è¡¨æåå°æç¾©è¡¨å¾µç¨ä½ LLM çè¼å©å·¥å·çé£åº¦ãæåéæ°å¯©è¦èªç¾©åè¡¨å¨èªæ³ç°¡åä¸­çä½ç½®ï¼èªæ³ç°¡åçä»»åæ¯å¨ä¿çå¥å­çµæ§çåæç°¡åå¥å­çµæ§ï¼ééè¦èªç¾©çè§£ï¼ä¸¦å¨ä¸åæ°çè¤éä¸èªç¶çæ¸æéä¸å°å¶é²è¡è©ä¼°ãæåæåºçåºæ¼ AMR çæ¹æ³ AMRS$^3$ è­æäºæåé²çæç¾©è¡¨å¾µå¯ä»¥å°è´ææ¼å¯¦ç¾çç°¡åæ¹æ³ï¼å¨ææ¬ãå¯è§£éæ§åæ³åæ¹é¢å·æç«¶ç­åªå¢åç¨ç¹åªå¢ãä»¥ AMRS$^3$ çºé¨é»ï¼æåç¼ç¾èªæ³ç°¡åæ¯ä¸é èªç¾©åè¡¨æå©æ¼ LLM æç¤ºçä»»åãæåæåº AMRCoC æç¤ºï¼æå° LLM æ¨¡æ¬åå½¢æ¼ç®æ³ï¼å° AMR åå½¢é²è¡æç¢ºçç¬¦èæ¨çï¼ä¸¦å±ç¤ºå¶å¨æ¹é² LLM å¨ä»¥èªç¾©çºä¸­å¿çä»»åï¼å¦èªæ³ç°¡åï¼æ¹é¢çæ½åã

##### **Functional Faithfulness in the Wild: Circuit Discovery with Differentiable Computation Graph Pruning**
2407.03779v1 by Lei Yu, Jingcheng Niu, Zining Zhu, Gerald Penn

In this paper, we introduce a comprehensive reformulation of the task known
as Circuit Discovery, along with DiscoGP, a novel and effective algorithm based
on differentiable masking for discovering circuits. Circuit discovery is the
task of interpreting the computational mechanisms of language models (LMs) by
dissecting their functions and capabilities into sparse subnetworks (circuits).
We identified two major limitations in existing circuit discovery efforts: (1)
a dichotomy between weight-based and connection-edge-based approaches forces
researchers to choose between pruning connections or weights, thereby limiting
the scope of mechanistic interpretation of LMs; (2) algorithms based on
activation patching tend to identify circuits that are neither functionally
faithful nor complete. The performance of these identified circuits is
substantially reduced, often resulting in near-random performance in isolation.
Furthermore, the complement of the circuit -- i.e., the original LM with the
identified circuit removed -- still retains adequate performance, indicating
that essential components of a complete circuits are missed by existing
methods.
  DiscoGP successfully addresses the two aforementioned issues and demonstrates
state-of-the-art faithfulness, completeness, and sparsity. The effectiveness of
the algorithm and its novel structure open up new avenues of gathering new
insights into the internal workings of generative AI.

æè¦ï¼<paragraph>å¨æ¬æä¸­ï¼æåä»ç´¹äºå°ç¨±çºé»è·¯ç¼ç¾ä»»åçå¨é¢éæ°è¡¨è¿°ï¼ä»¥å DiscoGPï¼ä¸ç¨®åºæ¼å¯å¾®é®ç½©çç¼ç¾é»è·¯çæ°ç©ä¸ææçæ¼ç®æ³ãé»è·¯ç¼ç¾æ¯ééå°å¶åè½åè½åè§£åæç¨çå­ç¶²è·¯ï¼é»è·¯ï¼ä¾è©®éèªè¨æ¨¡åï¼LMï¼çéç®æ©å¶çä»»åãæåå¨ç¾æçé»è·¯ç¼ç¾å·¥ä½ä¸­ç¼ç¾äºå©åä¸»è¦çéå¶ï¼ï¼1ï¼åºæ¼æ¬éååºæ¼é£æ¥éç·£çæ¹æ³ä¹éçäºåæ³è¿«ä½¿ç ç©¶äººå¡å¨ä¿®åªé£æ¥ææ¬éä¹éé²è¡é¸æï¼å¾èéå¶äº LM æ©å¶è©®éçç¯åï¼ï¼2ï¼åºæ¼åç¨ä¿®è£çæ¼ç®æ³å¾åæ¼è­å¥å¨åè½ä¸æ¢ä¸å¿ å¯¦ä¹ä¸å®æ´çé»è·¯ãéäºå·²è­å¥é»è·¯çæè½å¤§å¹éä½ï¼éå¸¸å°è´å­¤ç«çè¿ä¹é¨æ©æè½ãæ­¤å¤ï¼é»è·¯çè£æ¸ââå³ç§»é¤å·²è­å¥é»è·¯çåå§ LMââä»ä¿çäºè¶³å¤ çæè½ï¼éè¡¨ç¤ºç¾ææ¹æ³é¯å¤±äºå®æ´é»è·¯çåºæ¬çµæé¨åã
DiscoGP æåå°è§£æ±ºäºä¸è¿°å©ååé¡ï¼ä¸¦å±ç¤ºäºæåé²çå¿ å¯¦åº¦ãå®æ´æ§åç¨çæ§ãè©²æ¼ç®æ³çæææ§åå¶æ°ç©ççµæ§çºæ·±å¥ç­è§£çæå¼ AI çå§é¨éä½éé¢äºæ°çéå¾ã</paragraph>

##### **BACON: Supercharge Your VLM with Bag-of-Concept Graph to Mitigate Hallucinations**
2407.03314v1 by Zhantao Yang, Ruili Feng, Keyu Yan, Huangji Wang, Zhicai Wang, Shangwen Zhu, Han Zhang, Jie Xiao, Pingyu Wu, Kai Zhu, Jixuan Chen, Chen-Wei Xie, Chaojie Mao, Yue Yang, Hongyang Zhang, Yu Liu, Fan Cheng

This paper presents Bag-of-Concept Graph (BACON) to gift models with limited
linguistic abilities to taste the privilege of Vision Language Models (VLMs)
and boost downstream tasks such as detection, visual question answering (VQA),
and image generation. Since the visual scenes in physical worlds are structured
with complex relations between objects, BACON breaks down annotations into
basic minimum elements and presents them in a graph structure. Element-wise
style enables easy understanding, and structural composition liberates
difficult locating. Careful prompt design births the BACON captions with the
help of public-available VLMs and segmentation methods. In this way, we gather
a dataset with 100K annotated images, which endow VLMs with remarkable
capabilities, such as accurately generating BACON, transforming prompts into
BACON format, envisioning scenarios in the style of BACONr, and dynamically
modifying elements within BACON through interactive dialogue and more. Wide
representative experiments, including detection, VQA, and image generation
tasks, tell BACON as a lifeline to achieve previous out-of-reach tasks or excel
in their current cutting-edge solutions.

æè¦ï¼æ¬ææåº Bag-of-Concept Graph (BACON)ï¼èµäºè¯­è¨è½åæéçæ¨¡ååå°è§è§è¯­è¨æ¨¡å (VLM) çç¹æï¼å¹¶æåä¸æ¸¸ä»»å¡ï¼ä¾å¦æ£æµãè§è§é®ç­ (VQA) åå¾åçæãç±äºç©çä¸çä¸­çè§è§åºæ¯æ¯ç±å¯¹è±¡ä¹é´çå¤æå³ç³»æå»ºèæçï¼å æ­¤ BACON å°æ³¨éåè§£ä¸ºåºæ¬çæå°åç´ ï¼å¹¶ä»¥å¾å½¢ç»æåç°å®ä»¬ãåºäºåç´ çé£æ ¼ä¾¿äºçè§£ï¼ç»æåç»åè§£æ¾äºå°é¾çå®ä½ãå¨å¬å±å¯ç¨ VLM ååå²æ¹æ³çå¸®å©ä¸ï¼ç²¾å¿è®¾è®¡çæç¤ºçæäº BACON æ é¢ãéè¿è¿ç§æ¹å¼ï¼æä»¬æ¶éäºä¸ä¸ªåå« 100K å¼ æ³¨éå¾åçæ°æ®éï¼è¯¥æ°æ®éèµäº VLM æ¾èçè½åï¼ä¾å¦åç¡®çæ BACONãå°æç¤ºè½¬æ¢ä¸º BACON æ ¼å¼ãä»¥ BACONr çé£æ ¼è®¾æ³åºæ¯ï¼ä»¥åéè¿äº¤äºå¼å¯¹è¯å¨æä¿®æ¹ BACON ä¸­çåç´ ç­ç­ãå¹¿æ³çä»£è¡¨æ§å®éªï¼åæ¬æ£æµãVQA åå¾åçæä»»å¡ï¼è¡¨æ BACON ä½ä¸ºä¸æ¡çå½çº¿ï¼å¯ä»¥å®ç°ä»¥åæ æ³å®ç°çä»»å¡ï¼æå¨å½åçå°ç«¯è§£å³æ¹æ¡ä¸­è¡¨ç°åºè²ã

##### **Knowledge-based Consistency Testing of Large Language Models**
2407.12830v1 by Sai Sathiesh Rajan, Ezekiel Soremekun, Sudipta Chattopadhyay

In this work, we systematically expose and measure the inconsistency and
knowledge gaps of Large Language Models (LLMs). Specifically, we propose an
automated testing framework (called KONTEST) which leverages a knowledge graph
to construct test cases. KONTEST probes and measures the inconsistencies in the
LLM's knowledge of the world via a combination of semantically-equivalent
queries and test oracles (metamorphic or ontological oracle). KONTEST further
mitigates knowledge gaps via a weighted LLM model ensemble. Using four
state-of-the-art LLMs (Falcon, Gemini, GPT3.5, and Llama2), we show that
KONTEST generates 19.2% error inducing inputs (1917 errors from 9983 test
inputs). It also reveals a 16.5% knowledge gap across all tested LLMs.
KONTEST's mitigation method reduces LLM knowledge gap by 32.48%. Our ablation
study further shows that GPT3.5 is not suitable for knowledge-based consistency
testing because it is only 60%-68% effective in knowledge construction.

æè¦ï¼å¨éé å·¥ä½ä¸­ï¼æåç³»çµ±æ§å°æ­é²ä¸¦è¡¡éå¤§åèªè¨æ¨¡å (LLM) çä¸ä¸è´æ§åç¥è­å·®è·ãå·é«ä¾èªªï¼æåæåºäºä¸åèªååæ¸¬è©¦æ¡æ¶ (ç¨±çº KONTEST)ï¼å®å©ç¨ç¥è­åè­ä¾å»ºæ§æ¸¬è©¦æ¡ä¾ãKONTEST ééèªç¾©ç­ææ¥è©¢åæ¸¬è©¦é è¨ (è®å½¢ææ¬é«è«é è¨) ççµåä¾æ¢æ¸¬åè¡¡é LLM å°ä¸çç¥è­çä¸ä¸è´æ§ãKONTEST é²ä¸æ­¥ééå æ¬ LLM æ¨¡åéæä¾ç·©è§£ç¥è­å·®è·ãä½¿ç¨åç¨®æåé²ç LLMï¼FalconãGeminiãGPT3.5 å Llama2ï¼ï¼æåè¡¨æ KONTEST çæäº 19.2% çé¯èª¤èªç¼è¼¸å¥ï¼9983 åæ¸¬è©¦è¼¸å¥ä¸­ç 1917 åé¯èª¤ï¼ãå®éæ­ç¤ºäºæææ¸¬è©¦ç LLM ä¸­æ 16.5% çç¥è­å·®è·ãKONTEST çç·©è§£æ¹æ³å° LLM ç¥è­å·®è·æ¸å°äº 32.48%ãæåçæ¶èç ç©¶é²ä¸æ­¥è¡¨æï¼GPT3.5 ä¸é©åç¨æ¼åºæ¼ç¥è­çä¸è´æ§æ¸¬è©¦ï¼å çºå®å¨ç¥è­å»ºæ§ä¸­åªæ 60%-68% çæææ§ã

##### **GraCoRe: Benchmarking Graph Comprehension and Complex Reasoning in Large Language Models**
2407.02936v1 by Zike Yuan, Ming Liu, Hui Wang, Bing Qin

Evaluating the graph comprehension and reasoning abilities of Large Language
Models (LLMs) is challenging and often incomplete. Existing benchmarks focus
primarily on pure graph understanding, lacking a comprehensive evaluation
across all graph types and detailed capability definitions. This paper presents
GraCoRe, a benchmark for systematically assessing LLMs' graph comprehension and
reasoning. GraCoRe uses a three-tier hierarchical taxonomy to categorize and
test models on pure graph and heterogeneous graphs, subdividing capabilities
into 10 distinct areas tested through 19 tasks. Our benchmark includes 11
datasets with 5,140 graphs of varying complexity. We evaluated three
closed-source and seven open-source LLMs, conducting thorough analyses from
both ability and task perspectives. Key findings reveal that semantic
enrichment enhances reasoning performance, node ordering impacts task success,
and the ability to process longer texts does not necessarily improve graph
comprehension or reasoning. GraCoRe is open-sourced at
https://github.com/ZIKEYUAN/GraCoRe

æè¦ï¼è©ä¼°å¤§åèªè¨æ¨¡å (LLM) çåå½¢çè§£åæ¨çè½åå·æææ°æ§ï¼ä¸éå¸¸ä¸å®æ´ãç¾æçåºæºä¸»è¦èéæ¼ç´ç²¹çåå½¢çè§£ï¼ç¼ºä¹å°ææåå½¢é¡ååè©³ç´°åè½å®ç¾©çå¨é¢è©ä¼°ãæ¬ææåºäº GraCoReï¼ä¸åç¨æ¼ç³»çµ±è©ä¼° LLM çåå½¢çè§£åæ¨ççåºæºãGraCoRe ä½¿ç¨ä¸å±¤éå±¤åé¡æ³å°æ¨¡åé²è¡åé¡åæ¸¬è©¦ï¼å°åè½ç´°åçº 10 åä¸åçé åï¼ä¸¦éé 19 åä»»åé²è¡æ¸¬è©¦ãæåçåºæºåå« 11 åæ¸æéï¼å¶ä¸­åå« 5,140 åä¸åè¤éåº¦çåå½¢ãæåè©ä¼°äºä¸åéæºåä¸åéæº LLMï¼å¾è½ååä»»åè§åº¦é²è¡äºå¾¹åºçåæãä¸»è¦ç¼ç¾è¡¨æèªç¾©è±å¯åå¢å¼·äºæ¨çæ§è½ï¼ç¯é»æåºå½±é¿ä»»åæåï¼èèçè¼é·ææ¬çè½åä¸¦ä¸ä¸å®è½æ¹ååå½¢çè§£ææ¨çãGraCoRe å¨ https://github.com/ZIKEYUAN/GraCoRe éæº

##### **Croppable Knowledge Graph Embedding**
2407.02779v1 by Yushan Zhu, Wen Zhang, Zhiqiang Liu, Mingyang Chen, Lei Liang, Huajun Chen

Knowledge Graph Embedding (KGE) is a common method for Knowledge Graphs (KGs)
to serve various artificial intelligence tasks. The suitable dimensions of the
embeddings depend on the storage and computing conditions of the specific
application scenarios. Once a new dimension is required, a new KGE model needs
to be trained from scratch, which greatly increases the training cost and
limits the efficiency and flexibility of KGE in serving various scenarios. In
this work, we propose a novel KGE training framework MED, through which we
could train once to get a croppable KGE model applicable to multiple scenarios
with different dimensional requirements, sub-models of the required dimensions
can be cropped out of it and used directly without any additional training. In
MED, we propose a mutual learning mechanism to improve the low-dimensional
sub-models performance and make the high-dimensional sub-models retain the
capacity that low-dimensional sub-models have, an evolutionary improvement
mechanism to promote the high-dimensional sub-models to master the knowledge
that the low-dimensional sub-models can not learn, and a dynamic loss weight to
balance the multiple losses adaptively. Experiments on 3 KGE models over 4
standard KG completion datasets, 3 real application scenarios over a real-world
large-scale KG, and the experiments of extending MED to the language model BERT
show the effectiveness, high efficiency, and flexible extensibility of MED.

æè¦ï¼ç¥è­ååµå¥ (KGE) æ¯ç¥è­å (KG) ç¨æ¼æååç¨®äººå·¥æºæ§ä»»åçå¸¸è¦æ¹æ³ãåµå¥çé©ç¶ç¶­åº¦åæ±ºæ¼ç¹å®æç¨å ´æ¯çå²å­åéç®æ¢ä»¶ãä¸æ¦éè¦æ°çç¶­åº¦ï¼å°±éè¦å¾é ­è¨ç·´æ°ç KGE æ¨¡åï¼éå¤§å¤§å¢å äºè¨ç·´ææ¬ï¼ä¸¦éå¶äº KGE å¨æååç¨®å ´æ¯ä¸­çæçåéæ´»æ§ãå¨éé å·¥ä½ä¸­ï¼æåæåºäºä¸ç¨®æ°ç©ç KGE è¨ç·´æ¡æ¶ MEDï¼ééå®ï¼æåå¯ä»¥è¨ç·´ä¸æ¬¡ä»¥ç²å¾é©ç¨æ¼å·æä¸åç¶­åº¦éæ±çå¤åå ´æ¯çå¯è£åª KGE æ¨¡åï¼å¯ä»¥å¾ä¸­è£åªåºæéç¶­åº¦çå­æ¨¡åä¸¦ç´æ¥ä½¿ç¨ï¼èç¡éä»»ä½é¡å¤è¨ç·´ãå¨ MED ä¸­ï¼æåæåºäºä¸ç¨®ç¸äºå­¸ç¿æ©å¶ï¼ä»¥æé«ä½ç¶­å­æ¨¡åçæè½ï¼ä¸¦ä½¿é«ç¶­å­æ¨¡åä¿çä½ç¶­å­æ¨¡åå·æçè½åï¼ä¸ç¨®é²åæ¹é²æ©å¶ï¼ä»¥ä¿é²é«ç¶­å­æ¨¡åææ¡ä½ç¶­å­æ¨¡åç¡æ³å­¸ç¿çç¥è­ï¼ä»¥åä¸ç¨®åææå¤±æ¬éï¼ä»¥èªé©æå°å¹³è¡¡å¤éæå¤±ãå¨ 4 åæ¨æº KG å®æè³æéä¸ç 3 å KGE æ¨¡åãä¸åçå¯¦ä¸çå¤§è¦æ¨¡ KG ä¸ç 3 åå¯¦éæç¨å ´æ¯ä»¥åå° MED æ´å±å°èªè¨æ¨¡å BERT çå¯¦é©ä¸­ï¼å±ç¤ºäº MED çæææ§ãé«æçåéæ´»çå¯æ´åæ§ã

##### **Reasoning in Large Language Models: A Geometric Perspective**
2407.02678v1 by Romain Cosentino, Sarath Shekkizhar

The advancement of large language models (LLMs) for real-world applications
hinges critically on enhancing their reasoning capabilities. In this work, we
explore the reasoning abilities of large language models (LLMs) through their
geometrical understanding. We establish a connection between the expressive
power of LLMs and the density of their self-attention graphs. Our analysis
demonstrates that the density of these graphs defines the intrinsic dimension
of the inputs to the MLP blocks. We demonstrate through theoretical analysis
and toy examples that a higher intrinsic dimension implies a greater expressive
capacity of the LLM. We further provide empirical evidence linking this
geometric framework to recent advancements in methods aimed at enhancing the
reasoning capabilities of LLMs.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨å¯¦éæç¨ä¸­çé²å±ï¼ééµå¨æ¼æåå¶æ¨çè½åãå¨éé å·¥ä½ä¸­ï¼æåééå¤§åèªè¨æ¨¡å (LLM) çå¹¾ä½çè§£ï¼æ¢è¨å¶æ¨çè½åãæåå»ºç«äº LLM çè¡¨éè½åèå¶èªæ³¨æååå¯åº¦ä¹éçéè¯ãæåçåæè­æï¼éäºåçå¯åº¦å®ç¾©äº MLP å¡è¼¸å¥çå§å¨ç¶­åº¦ãæåééçè«åæåç©å·ç¯ä¾è­æï¼è¼é«çå§å¨ç¶­åº¦æå³è LLM å·ææ´å¤§çè¡¨éè½åãæåé²ä¸æ­¥æä¾ç¶é©è­æï¼å°éåå¹¾ä½æ¡æ¶é£çµå°æè¿å¨æ¨å¨å¢å¼· LLM æ¨çè½åçæ¹æ³ä¸­åå¾çé²å±ã

##### **Ensuring Responsible Sourcing of Large Language Model Training Data Through Knowledge Graph Comparison**
2407.02659v1 by Devam Mondal, Carlo Lipizzi

In light of recent plagiarism allegations Brough by publishers, newspapers,
and other creators of copyrighted corpora against large language model (LLM)
developers, we propose a novel system, a variant of a plagiarism detection
system, that assesses whether a knowledge source has been used in the training
or fine-tuning of a large language model. Unlike current methods, we utilize an
approach that uses Resource Description Framework (RDF) triples to create
knowledge graphs from both a source document and a LLM continuation of that
document. These graphs are then analyzed with respect to content using cosine
similarity and with respect to structure using a normalized version of graph
edit distance that shows the degree of isomorphism. Unlike traditional systems
that focus on content matching and keyword identification between a source and
target corpus, our approach enables a broader evaluation of similarity and thus
a more accurate comparison of the similarity between a source document and LLM
continuation by focusing on relationships between ideas and their organization
with regards to others. Additionally, our approach does not require access to
LLM metrics like perplexity that may be unavailable in closed large language
modeling "black-box" systems, as well as the training corpus. A prototype of
our system will be found on a hyperlinked GitHub repository.

æè¦ï¼é´äºåºçåãæ¥çº¸åå¶ä»åçæä¿æ¤è¯­æåºçåé èæè¿å¯¹å¤§åè¯­è¨æ¨¡å (LLM) å¼åèæåºçå½çªææ§ï¼æä»¬æåºäºä¸ç§æ°é¢çç³»ç»ï¼è¯¥ç³»ç»æ¯å½çªæ£æµç³»ç»çä¸ä¸ªåä½ï¼å®è¯ä¼°ç¥è¯æºæ¯å¦å·²ç¨äºå¤§åè¯­è¨æ¨¡åçè®­ç»æå¾®è°ãä¸å½åæ¹æ³ä¸åï¼æä»¬å©ç¨ä¸ç§ä½¿ç¨èµæºæè¿°æ¡æ¶ (RDF) ä¸åç»çæ¹æ³ä»æºææ¡£åè¯¥ææ¡£ç LLM å»¶ç»­ä¸­åå»ºç¥è¯å¾è°±ãç¶åä½¿ç¨ä½å¼¦ç¸ä¼¼æ§åæè¿äºå¾è°±çåå®¹ï¼å¹¶ä½¿ç¨å¾ç¼è¾è·ç¦»çæ ååçæ¬åæç»æï¼è¯¥çæ¬æ¾ç¤ºåæåº¦ãä¸ä¸æ³¨äºæºè¯­æåºåç®æ è¯­æåºä¹é´çåå®¹å¹éåå³é®è¯è¯å«çä¼ ç»ç³»ç»ä¸åï¼æä»¬çæ¹æ³è½å¤å¯¹ç¸ä¼¼æ§è¿è¡æ´å¹¿æ³çè¯ä¼°ï¼ä»èæ´åç¡®å°æ¯è¾æºææ¡£å LLM å»¶ç»­ä¹é´çç¸ä¼¼æ§ï¼æ¹æ³æ¯å³æ³¨ææ³ä¹é´çå³ç³»ä»¥åå®ä»¬ä¸å¶ä»ææ³çå³ç³»ãæ­¤å¤ï¼æä»¬çæ¹æ³ä¸éè¦è®¿é® LLM ææ ï¼ä¾å¦å°æåº¦ï¼è¿äºææ å¨å°é­çå¤§åè¯­è¨å»ºæ¨¡âé»å£å­âç³»ç»ä»¥åè®­ç»è¯­æåºä¸­å¯è½ä¸å¯ç¨ãæä»¬ç³»ç»çååå°å¨è¶é¾æ¥ç GitHub å­å¨åºä¸­æ¾å°ã

##### **Multi-Peptide: Multimodality Leveraged Language-Graph Learning of Peptide Properties**
2407.03380v1 by Srivathsan Badrinarayanan, Chakradhar Guntuboina, Parisa Mollaei, Amir Barati Farimani

Peptides are essential in biological processes and therapeutics. In this
study, we introduce Multi-Peptide, an innovative approach that combines
transformer-based language models with Graph Neural Networks (GNNs) to predict
peptide properties. We combine PeptideBERT, a transformer model tailored for
peptide property prediction, with a GNN encoder to capture both sequence-based
and structural features. By employing Contrastive Language-Image Pre-training
(CLIP), Multi-Peptide aligns embeddings from both modalities into a shared
latent space, thereby enhancing the model's predictive accuracy. Evaluations on
hemolysis and nonfouling datasets demonstrate Multi-Peptide's robustness,
achieving state-of-the-art 86.185% accuracy in hemolysis prediction. This study
highlights the potential of multimodal learning in bioinformatics, paving the
way for accurate and reliable predictions in peptide-based research and
applications.

æè¦ï¼è½å¨çç©éç¨åæ²»çä¸­è³ééè¦ãå¨æ­¤ç ç©¶ä¸­ï¼æåä»ç´¹äºå¤è½ï¼éæ¯ä¸ç¨®åµæ°çæ¹æ³ï¼çµåäºåºæ¼è½æå¨çèªè¨æ¨¡åååç¥ç¶ç¶²çµ¡ (GNN) ä¾é æ¸¬è½çæ§è³ªãæåçµåäºå°éç¨æ¼è½æ§è³ªé æ¸¬çè½æå¨æ¨¡å PeptideBERT å GNN ç·¨ç¢¼å¨ï¼ä»¥æç²åºæ¼åºååçµæ§çç¹å¾µãééæ¡ç¨å°æ¯èªè¨ååé è¨ç·´ (CLIP)ï¼å¤è½å°ä¾èªå©ç¨®æ¨¡æçåµå¥å°é½å°ä¸åå±äº«çæ½å¨ç©ºéä¸­ï¼å¾èå¢å¼·æ¨¡åçé æ¸¬æºç¢ºåº¦ãå°æº¶è¡åææ±¡æ¸æéçè©ä¼°è­æäºå¤è½çç©©å¥æ§ï¼å¨æº¶è¡é æ¸¬ä¸­å¯¦ç¾äºæåé²ç 86.185% æºç¢ºçãæ¬ç ç©¶å¼·èª¿äºçç©ä¿¡æ¯å­¸ä¸­å¤æ¨¡æå­¸ç¿çæ½åï¼çºåºæ¼è½çç ç©¶åæç¨ä¸­çæºç¢ºä¸å¯é çé æ¸¬éªå¹³äºéè·¯ã

##### **Pelican: Correcting Hallucination in Vision-LLMs via Claim Decomposition and Program of Thought Verification**
2407.02352v1 by Pritish Sahu, Karan Sikka, Ajay Divakaran

Large Visual Language Models (LVLMs) struggle with hallucinations in visual
instruction following task(s), limiting their trustworthiness and real-world
applicability. We propose Pelican -- a novel framework designed to detect and
mitigate hallucinations through claim verification. Pelican first decomposes
the visual claim into a chain of sub-claims based on first-order predicates.
These sub-claims consist of (predicate, question) pairs and can be
conceptualized as nodes of a computational graph. We then use
Program-of-Thought prompting to generate Python code for answering these
questions through flexible composition of external tools. Pelican improves over
prior work by introducing (1) intermediate variables for precise grounding of
object instances, and (2) shared computation for answering the sub-question to
enable adaptive corrections and inconsistency identification. We finally use
reasoning abilities of LLM to verify the correctness of the the claim by
considering the consistency and confidence of the (question, answer) pairs from
each sub-claim. Our experiments reveal a drop in hallucination rate by
$\sim$8%-32% across various baseline LVLMs and a 27% drop compared to
approaches proposed for hallucination mitigation on MMHal-Bench. Results on two
other benchmarks further corroborate our results.

æè¦ï¼å¤§åè§è§è¯­è¨æ¨¡å (LVLMs) å¨è§è§æä»¤éµå¾ªä»»å¡ä¸­ä¼äº§çå¹»è§ï¼è¿éå¶äºå®ä»¬çå¯é æ§åç°å®ä¸ççéç¨æ§ãæä»¬æåºäº Pelicanââä¸ç§æ¨å¨éè¿å£°æéªè¯æ¥æ£æµååè½»å¹»è§çæ°åæ¡æ¶ãPelican é¦åæ ¹æ®ä¸é¶è°è¯å°è§è§å£°æåè§£æä¸ä¸ªå­å£°æé¾ãè¿äºå­å£°æç± (è°è¯ãé®é¢) å¯¹ç»æï¼å¯ä»¥è¢«æ¦å¿µåä¸ºè®¡ç®å¾çèç¹ãç¶åï¼æä»¬ä½¿ç¨ææ³è®¡åæç¤ºæ¥çæ Python ä»£ç ï¼éè¿å¤é¨å·¥å·ççµæ´»ç»åæ¥åç­è¿äºé®é¢ãPelican éè¿å¼å¥ (1) ç¨äºå¯¹è±¡å®ä¾ç²¾ç¡®æ¥å°çä¸­é´åéï¼ä»¥å (2) ç¨äºåç­å­é®é¢ä»¥å®ç°èªéåºæ ¡æ­£åä¸ä¸è´æ§è¯å«çå±äº«è®¡ç®ï¼æ¹è¿äºä¹åçå·¥ä½ãæä»¬æç»ä½¿ç¨ LLM çæ¨çè½åï¼éè¿èèæ¯ä¸ªå­å£°æç (é®é¢ãç­æ¡) å¯¹çä¸è´æ§åç½®ä¿¡åº¦æ¥éªè¯å£°æçæ­£ç¡®æ§ãæä»¬çå®éªè¡¨æï¼å¨åç§åºçº¿ LVLMs ä¸­ï¼å¹»è§çä¸éäºçº¦ 8%-32%ï¼ä¸ MMHal-Bench ä¸æåºçå¹»è§ç¼è§£æ¹æ³ç¸æ¯ï¼ä¸éäº 27%ãå¨å¦å¤ä¸¤ä¸ªåºåä¸çç»æè¿ä¸æ­¥è¯å®äºæä»¬çç»æã

##### **Is Your Large Language Model Knowledgeable or a Choices-Only Cheater?**
2407.01992v1 by Nishant Balepur, Rachel Rudinger

Recent work shows that large language models (LLMs) can answer
multiple-choice questions using only the choices, but does this mean that MCQA
leaderboard rankings of LLMs are largely influenced by abilities in
choices-only settings? To answer this, we use a contrast set that probes if
LLMs over-rely on choices-only shortcuts in MCQA. While previous works build
contrast sets via expensive human annotations or model-generated data which can
be biased, we employ graph mining to extract contrast sets from existing MCQA
datasets. We use our method on UnifiedQA, a group of six commonsense reasoning
datasets with high choices-only accuracy, to build an 820-question contrast
set. After validating our contrast set, we test 12 LLMs, finding that these
models do not exhibit reliance on choice-only shortcuts when given both the
question and choices. Thus, despite the susceptibility~of MCQA to high
choices-only accuracy, we argue that LLMs are not obtaining high ranks on MCQA
leaderboards just due to their ability to exploit choices-only shortcuts.

æè¦ï¼æè¿çç ç©¶è¡¨æï¼å¤§åè¯­è¨æ¨¡å (LLM) ä»ä½¿ç¨éé¡¹å°±è½åç­å¤é¡¹éæ©é¢ï¼ä½è¿æ¯å¦è¡¨ç¤ºå¤é¡¹éæ©é®ç­ (MCQA) æè¡æ¦ä¸ç LLM ä¸»è¦åéäºä»éé¡¹è®¾ç½®ä¸­çè½åï¼ä¸ºäºåç­è¿ä¸ªé®é¢ï¼æä»¬ä½¿ç¨å¯¹æ¯éæ¥æ¢æ¥ LLM å¨ MCQA ä¸­æ¯å¦è¿åº¦ä¾èµä»éé¡¹æ·å¾ãè½ç¶ååçç ç©¶éè¿æè´µçäººå·¥æ³¨éæå¯è½å­å¨åå·®çæ¨¡åçææ°æ®æ¥æå»ºå¯¹æ¯éï¼ä½æä»¬éç¨å¾ææä»ç°æ MCQA æ°æ®éä¸­æåå¯¹æ¯éãæä»¬ä½¿ç¨æä»¬çæ¹æ³å¨ UnifiedQA ä¸ï¼è¿æ¯ä¸ä¸ªç±å­ä¸ªå·æé«ä»éé¡¹åç¡®ççå¸¸è¯æ¨çæ°æ®éç»æçç»ï¼æå»ºäºä¸ä¸ª 820 é¢çå¯¹æ¯éãå¨éªè¯æä»¬çå¯¹æ¯éåï¼æä»¬æµè¯äº 12 ä¸ª LLMï¼åç°å½åæ¶ç»åºé®é¢åéé¡¹æ¶ï¼è¿äºæ¨¡åä¸ä¼è¡¨ç°åºå¯¹ä»éé¡¹æ·å¾çä¾èµãå æ­¤ï¼å°½ç®¡ MCQA å®¹æåå°é«ä»éé¡¹åç¡®ççå½±åï¼ä½æä»¬è®¤ä¸º LLM å¨ MCQA æè¡æ¦ä¸è·å¾é«æåå¹¶éä»ä»å ä¸ºå®ä»¬å©ç¨ä»éé¡¹æ·å¾çè½åã

##### **CRAB: Cross-environment Agent Benchmark for Multimodal Language Model Agents**
2407.01511v1 by Tianqi Xu, Linyao Chen, Dai-Jie Wu, Yanjun Chen, Zecheng Zhang, Xiang Yao, Zhiqiang Xie, Yongchao Chen, Shilong Liu, Bochen Qian, Philip Torr, Bernard Ghanem, Guohao Li

The development of autonomous agents increasingly relies on Multimodal
Language Models (MLMs) to perform tasks described in natural language with GUI
environments, such as websites, desktop computers, or mobile phones. Existing
benchmarks for MLM agents in interactive environments are limited by their
focus on a single environment, lack of detailed and generalized evaluation
methods, and the complexities of constructing tasks and evaluators. To overcome
these limitations, we introduce Crab, the first agent benchmark framework
designed to support cross-environment tasks, incorporating a graph-based
fine-grained evaluation method and an efficient mechanism for task and
evaluator construction. Our framework supports multiple devices and can be
easily extended to any environment with a Python interface. Leveraging Crab, we
developed a cross-platform Crab Benchmark-v0 comprising 100 tasks in computer
desktop and mobile phone environments. We evaluated four advanced MLMs using
different single and multi-agent system configurations on this benchmark. The
experimental results demonstrate that the single agent with GPT-4o achieves the
best completion ratio of 35.26%. All framework code, agent code, and task
datasets are publicly available at https://github.com/camel-ai/crab.

æè¦ï¼èªä¸»ä»£ççéç¼è¶ä¾è¶ä¾è³´å¤æ¨¡æèªè¨æ¨¡å (MLM)ï¼ä»¥å¨å·æ GUI ç°å¢ï¼ä¾å¦ç¶²ç«ãæ¡ä¸åé»è¦æææ©ï¼çèªç¶èªè¨ä¸­å·è¡ä»»åãç¾æçäºåç°å¢ä¸­ MLM ä»£ççåºæºåå°ä»¥ä¸éå¶ï¼å®åå°æ³¨æ¼å®ä¸ç°å¢ãç¼ºä¹è©³ç´°ä¸éç¨çè©ä¼°æ¹æ³ï¼ä»¥åå»ºæ§ä»»ååè©ä¼°å¨çè¤éæ§ãçºäºåæéäºéå¶ï¼æåå¼å¥äº Crabï¼éæ¯ç¬¬ä¸åä»£çåºæºæ¶æ§ï¼æ¨å¨æ¯æ´è·¨ç°å¢ä»»åï¼ä¸¦çµåäºåºæ¼åå½¢çç´°ç²åº¦è©ä¼°æ¹æ³åä»»åèè©ä¼°å¨å»ºæ§çæææ©å¶ãæåçæ¶æ§æ¯æ´å¤ç¨®è£ç½®ï¼ä¸¦ä¸å¯ä»¥è¼é¬å°æ´åå°ä»»ä½å·æ Python ä»é¢çç°å¢ãå©ç¨ Crabï¼æåéç¼äºä¸åè·¨å¹³å°ç Crab Benchmark-v0ï¼å¶ä¸­åå«é»è¦æ¡ä¸åé»è¦åææ©ç°å¢ä¸­ç 100 åä»»åãæåä½¿ç¨ä¸åçå®ä¸åå¤ä»£çç³»çµ±éç½®ï¼å¨éååºæºä¸è©ä¼°äºåç¨®åé²ç MLMãå¯¦é©çµæè¡¨æï¼å·æ GPT-4o çå®ä¸ä»£çå¯¦ç¾äº 35.26% çæä½³å®æçãæææ¶æ§ç¨å¼ç¢¼ãä»£çç¨å¼ç¢¼åä»»åè³æéé½å¬éæ¼ https://github.com/camel-ai/crabã

##### **Dynamic Few-Shot Learning for Knowledge Graph Question Answering**
2407.01409v1 by Jacopo D'Abramo, Andrea Zugarini, Paolo Torroni

Large language models present opportunities for innovative Question Answering
over Knowledge Graphs (KGQA). However, they are not inherently designed for
query generation. To bridge this gap, solutions have been proposed that rely on
fine-tuning or ad-hoc architectures, achieving good results but limited
out-of-domain distribution generalization. In this study, we introduce a novel
approach called Dynamic Few-Shot Learning (DFSL). DFSL integrates the
efficiency of in-context learning and semantic similarity and provides a
generally applicable solution for KGQA with state-of-the-art performance. We
run an extensive evaluation across multiple benchmark datasets and architecture
configurations.

æè¦ï¼å¤§åèªè¨æ¨¡åçºç¥è­åè­ï¼KGQAï¼çåµæ°åç­æä¾äºæ©æãç¶èï¼å®åä¸¦éå¤©çå°±è¨­è¨ç¨æ¼æ¥è©¢çæãçºäºå½è£éä¸å·®è·ï¼å·²æåºä¾è³´æ¼å¾®èª¿æç¹å®æ¶æ§çè§£æ±ºæ¹æ¡ï¼åå¾äºè¯å¥½ççµæï¼ä½åå¤åä½æ³åè½åæéãå¨æ¬ç ç©¶ä¸­ï¼æåå¼å¥äºä¸ç¨®ç¨±çºåæå°æ¨£æ¬å­¸ç¿ï¼DFSLï¼çæ°æ¹æ³ãDFSL éæäºèªå¢å­¸ç¿åèªç¾©ç¸ä¼¼æ§çæçï¼ä¸¦çº KGQA æä¾äºä¸åæ®éé©ç¨çè§£æ±ºæ¹æ¡ï¼å·ææåé²çæ§è½ãæåå°å¤ååºæºè³æéåæ¶æ§éç½®é²è¡äºå»£æ³çè©ä¼°ã

##### **Adapting Multilingual LLMs to Low-Resource Languages with Knowledge Graphs via Adapters**
2407.01406v2 by Daniil Gurgurov, Mareike Hartmann, Simon Ostermann

This paper explores the integration of graph knowledge from linguistic
ontologies into multilingual Large Language Models (LLMs) using adapters to
improve performance for low-resource languages (LRLs) in sentiment analysis
(SA) and named entity recognition (NER). Building upon successful
parameter-efficient fine-tuning techniques, such as K-ADAPTER and MAD-X, we
propose a similar approach for incorporating knowledge from multilingual
graphs, connecting concepts in various languages with each other through
linguistic relationships, into multilingual LLMs for LRLs. Specifically, we
focus on eight LRLs -- Maltese, Bulgarian, Indonesian, Nepali, Javanese,
Uyghur, Tibetan, and Sinhala -- and employ language-specific adapters
fine-tuned on data extracted from the language-specific section of ConceptNet,
aiming to enable knowledge transfer across the languages covered by the
knowledge graph. We compare various fine-tuning objectives, including standard
Masked Language Modeling (MLM), MLM with full-word masking, and MLM with
targeted masking, to analyse their effectiveness in learning and integrating
the extracted graph data. Through empirical evaluation on language-specific
tasks, we assess how structured graph knowledge affects the performance of
multilingual LLMs for LRLs in SA and NER, providing insights into the potential
benefits of adapting language models for low-resource scenarios.

æè¦ï¼éç¯è«ææ¢è¨äºä½¿ç¨é©éå¨å°ä¾èªèªè¨å­¸æ¬é«çåå½¢ç¥è­æ´åå°å¤èªè¨å¤§åèªè¨æ¨¡å (LLM) ä¸­ï¼ä»¥æåä½è³æºèªè¨ (LRL) å¨æç·åæ (SA) åå½åå¯¦é«è­å¥ (NER) ä¸­çæè½ãæåå»ºç«å¨æåçåæ¸ææå¾®èª¿æè¡ä¸ï¼ä¾å¦ K-ADAPTER å MAD-Xï¼æåæåºäºä¸åé¡ä¼¼çåæ³ï¼å°ä¾èªå¤èªè¨åå½¢ãééèªè¨éä¿å°åç¨®èªè¨ä¸­çæ¦å¿µç¸äºé£æ¥çç¥è­ï¼ç´å¥ LRL çå¤èªè¨ LLM ä¸­ãå·é«ä¾èªªï¼æåå°æ³¨æ¼å«ç¨® LRLââé¦¬ç¾ä»èªãä¿å å©äºèªãå°å°¼èªãå°¼æ³ç¾èªãçªåèªãç¶­å¾ç¾èªãèèªåå§ä¼½ç¾èªââä¸¦ä½¿ç¨å¨å¾ ConceptNet çèªè¨ç¹å®é¨åä¸­æåçè³æä¸å¾®èª¿çèªè¨ç¹å®é©éå¨ï¼æ¨å¨è®ç¥è­è½ç§»å°ç¥è­åå½¢æ¶µèçèªè¨ä¸­ãæåæ¯è¼äºåç¨®å¾®èª¿ç®æ¨ï¼åæ¬æ¨æºçé®ç½©èªè¨æ¨¡å (MLM)ãå·æå¨è©é®ç½©ç MLMï¼ä»¥åå·æç®æ¨é®ç½©ç MLMï¼ä»¥åæå®åå¨å­¸ç¿åæ´åæåçåå½¢è³æä¸­çæææ§ãééå°èªè¨ç¹å®ä»»åçå¯¦è­è©ä¼°ï¼æåè©ä¼°çµæ§ååå½¢ç¥è­å¦ä½å½±é¿å¤èªè¨ LLM å¨ LRL ä¸­ç SA å NER æè½ï¼ä¸¦æ·±å¥äºè§£çºä½è³æºå ´æ¯èª¿æ´èªè¨æ¨¡åçæ½å¨å¥½èã

##### **SINKT: A Structure-Aware Inductive Knowledge Tracing Model with Large Language Model**
2407.01245v2 by Lingyue Fu, Hao Guan, Kounianhua Du, Jianghao Lin, Wei Xia, Weinan Zhang, Ruiming Tang, Yasheng Wang, Yong Yu

Knowledge Tracing (KT) aims to determine whether students will respond
correctly to the next question, which is a crucial task in intelligent tutoring
systems (ITS). In educational KT scenarios, transductive ID-based methods often
face severe data sparsity and cold start problems, where interactions between
individual students and questions are sparse, and new questions and concepts
consistently arrive in the database. In addition, existing KT models only
implicitly consider the correlation between concepts and questions, lacking
direct modeling of the more complex relationships in the heterogeneous graph of
concepts and questions. In this paper, we propose a Structure-aware Inductive
Knowledge Tracing model with large language model (dubbed SINKT), which, for
the first time, introduces large language models (LLMs) and realizes inductive
knowledge tracing. Firstly, SINKT utilizes LLMs to introduce structural
relationships between concepts and constructs a heterogeneous graph for
concepts and questions. Secondly, by encoding concepts and questions with LLMs,
SINKT incorporates semantic information to aid prediction. Finally, SINKT
predicts the student's response to the target question by interacting with the
student's knowledge state and the question representation. Experiments on four
real-world datasets demonstrate that SINKT achieves state-of-the-art
performance among 12 existing transductive KT models. Additionally, we explore
the performance of SINKT on the inductive KT task and provide insights into
various modules.

æè¦ï¼ç¥è­è¿½è¹¤ (KT) çç®çæ¯ç¢ºå®å­¸çæ¯å¦è½æ­£ç¢ºåç­ä¸ä¸ååé¡ï¼éå¨æºæ§åæå­¸ç³»çµ± (ITS) ä¸­æ¯ä¸é è³ééè¦çä»»åãå¨æè² KT å ´æ¯ä¸­ï¼åºæ¼ ID çè½å°æ¹æ³ç¶å¸¸é¢è¨å´éçè³æç¨çæ§åå·åååé¡ï¼å¶ä¸­åå¥å­¸çååé¡ä¹éçäºåå¾ç¨çï¼èä¸æ°çåé¡åæ¦å¿µææçºåºç¾å¨è³æåº«ä¸­ãæ­¤å¤ï¼ç¾æç KT æ¨¡ååªæé±å«å°èæ®æ¦å¿µååé¡ä¹éçéè¯æ§ï¼ç¼ºä¹å°æ¦å¿µååé¡ç°è³ªåä¸­æ´è¤ééä¿çç´æ¥å»ºæ¨¡ãå¨æ¬æä¸­ï¼æåæåºäºä¸åå·æå¤§åèªè¨æ¨¡åççµæ§æç¥æ­¸ç´ç¥è­è¿½è¹¤æ¨¡åï¼ç¨±çº SINKTï¼ï¼å®é¦æ¬¡å¼å¥äºå¤§åèªè¨æ¨¡åï¼LLMï¼ï¼ä¸¦å¯¦ç¾äºæ­¸ç´ç¥è­è¿½è¹¤ãé¦åï¼SINKT å©ç¨ LLM å¼å¥æ¦å¿µä¹éççµæ§éä¿ï¼ä¸¦çºæ¦å¿µååé¡æ§å»ºäºä¸åç°è³ªåãå¶æ¬¡ï¼ééä½¿ç¨ LLM ç·¨ç¢¼æ¦å¿µååé¡ï¼SINKT çµåäºèªç¾©è³è¨ï¼ä»¥åå©é æ¸¬ãæå¾ï¼SINKT ééèå­¸ççç¥è­çæååé¡è¡¨å¾µé²è¡äºåï¼é æ¸¬å­¸çå°ç®æ¨åé¡çåæãå¨ååçå¯¦ä¸çè³æéä¸çå¯¦é©è¡¨æï¼SINKT å¨ 12 åç¾æçè½å° KT æ¨¡åä¸­åå¾äºæåé²çæè½ãæ­¤å¤ï¼æåæ¢è¨äº SINKT å¨æ­¸ç´ KT ä»»åä¸çæè½ï¼ä¸¦æä¾äºå°åç¨®æ¨¡çµçè¦è§£ã

##### **Revisiting Random Walks for Learning on Graphs**
2407.01214v1 by Jinwoo Kim, Olga Zaghen, Ayhan Suleymanzade, Youngmin Ryou, Seunghoon Hong

We revisit a simple idea for machine learning on graphs, where a random walk
on a graph produces a machine-readable record, and this record is processed by
a deep neural network to directly make vertex-level or graph-level predictions.
We refer to these stochastic machines as random walk neural networks, and show
that we can design them to be isomorphism invariant while capable of universal
approximation of graph functions in probability. A useful finding is that
almost any kind of record of random walk guarantees probabilistic invariance as
long as the vertices are anonymized. This enables us to record random walks in
plain text and adopt a language model to read these text records to solve graph
tasks. We further establish a parallelism to message passing neural networks
using tools from Markov chain theory, and show that over-smoothing in message
passing is alleviated by construction in random walk neural networks, while
over-squashing manifests as probabilistic under-reaching. We show that random
walk neural networks based on pre-trained language models can solve several
hard problems on graphs, such as separating strongly regular graphs where the
3-WL test fails, counting substructures, and transductive classification on
arXiv citation network without training. Code is available at
https://github.com/jw9730/random-walk.

æè¦ï¼<paragraph>æåéæ°å¯©è¦åå½¢æ©å¨å­¸ç¿çä¸åç°¡å®æ³æ³ï¼å¶ä¸­åå½¢ä¸çé¨æ©éèµ°æç¢çæ©å¨å¯è®çè¨éï¼èéåè¨éæç±æ·±åº¦ç¥ç¶ç¶²è·¯èçï¼ä»¥ç´æ¥é²è¡é é»å±¤ç´æåå½¢å±¤ç´çé æ¸¬ãæåå°éäºé¨æ©æ©å¨ç¨±çºé¨æ©éèµ°ç¥ç¶ç¶²è·¯ï¼ä¸¦å±ç¤ºæåå¯ä»¥å°å®åè¨­è¨æåæ§ä¸è®ï¼åæå·åæ©çä¸­åå½¢å½æ¸çéç¨è¿ä¼¼è½åãä¸åæç¨çç¼ç¾æ¯ï¼åªè¦é é»æ¯å¿åçï¼å¹¾ä¹ä»»ä½é¡åçé¨æ©éèµ°è¨éé½å¯ä»¥ä¿è­æ©çä¸è®æ§ãéä½¿æåè½å¤ ä»¥ç´æå­è¨éé¨æ©éèµ°ï¼ä¸¦æ¡ç¨èªè¨æ¨¡åä¾è®åéäºæå­è¨éï¼ä»¥è§£æ±ºåå½¢ä»»åãæåé²ä¸æ­¥å»ºç«äºä¸åèè¨æ¯å³éç¥ç¶ç¶²è·¯çå¹³è¡æ§ï¼ä½¿ç¨é¦¬å¯å¤«éçè«çå·¥å·ï¼ä¸¦å±ç¤ºè¨æ¯å³éä¸­çéåº¦å¹³æ»æå é¨æ©éèµ°ç¥ç¶ç¶²è·¯ä¸­çæ§é èå¾å°ç·©è§£ï¼èéåº¦å£ç¸®åè¡¨ç¾çºæ©çæ§ä¸è¶³ãæåå±ç¤ºäºåºæ¼é åè¨ç·´èªè¨æ¨¡åçé¨æ©éèµ°ç¥ç¶ç¶²è·¯å¯ä»¥è§£æ±ºåå½¢ä¸çå¹¾åå°é£åé¡ï¼ä¾å¦åé¢ 3-WL æ¸¬è©¦å¤±æçå¼·æ­£ååå½¢ãè¨ç®å­çµæ§ï¼ä»¥åå¨ arXiv å¼æç¶²è·¯ä¸­é²è¡è½å°åé¡ï¼èç¡éè¨ç·´ãç¨å¼ç¢¼å¯å¨ https://github.com/jw9730/random-walk åå¾ã</paragraph>

##### **LLM Uncertainty Quantification through Directional Entailment Graph and Claim Level Response Augmentation**
2407.00994v2 by Longchao Da, Tiejin Chen, Lu Cheng, Hua Wei

The Large language models (LLMs) have showcased superior capabilities in
sophisticated tasks across various domains, stemming from basic question-answer
(QA), they are nowadays used as decision assistants or explainers for
unfamiliar content. However, they are not always correct due to the data
sparsity in specific domain corpus, or the model's hallucination problems.
Given this, how much should we trust the responses from LLMs? This paper
presents a novel way to evaluate the uncertainty that captures the directional
instability, by constructing a directional graph from entailment probabilities,
and we innovatively conduct Random Walk Laplacian given the asymmetric property
of a constructed directed graph, then the uncertainty is aggregated by the
derived eigenvalues from the Laplacian process. We also provide a way to
incorporate the existing work's semantics uncertainty with our proposed layer.
Besides, this paper identifies the vagueness issues in the raw response set and
proposes an augmentation approach to mitigate such a problem, we conducted
extensive empirical experiments and demonstrated the superiority of our
proposed solutions.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨ååé åçè¤éä»»åä¸­å±ç¾åºåè¶çè½åï¼å¾åºæ¬çåç­ (QA) éå§ï¼å®åç¾å¨è¢«ç¨ä½æ±ºç­å©çæä¸çæå§å®¹çèªªæèãç¶èï¼å®åä¸¦ä¸ç¸½æ¯æ­£ç¢ºçï¼å çºç¹å®é åèªæåº«ä¸­çæ¸æç¨çï¼ææ¨¡åçå¹»è¦ºåé¡ãæéæ¼æ­¤ï¼æåæè©²å¤ç¸ä¿¡ LLM çåæï¼æ¬ææåºäºä¸ç¨®æ°çæ¹æ³ä¾è©ä¼°æææ¹åä¸ç©©å®æ§çä¸ç¢ºå®æ§ï¼ééå¾èæ¶µæ¦çæ§é ä¸åæååï¼ä¸¦ä¸æååµæ°å°é²è¡é¨æ©éèµ°ææ®ææ¯ç®å­ï¼çµ¦å®ä¸åæ§é çæååçä¸å°ç¨±å±¬æ§ï¼ç¶å¾ä¸ç¢ºå®æ§ç±ææ®ææ¯éç¨ä¸­çå°åºç¹å¾µå¼èåãæåéæä¾äºä¸ç¨®å°ç¾æå·¥ä½çèªç¾©ä¸ç¢ºå®æ§èæåæåºçå±¤çµåèµ·ä¾çæ¹æ³ãæ­¤å¤ï¼æ¬æè­å¥äºåå§åæéä¸­æ¨¡ç³çåé¡ï¼ä¸¦æåºäºä¸ç¨®æ´åæ¹æ³ä¾æ¸è¼éç¨®åé¡ï¼æåé²è¡äºå»£æ³çå¯¦è­å¯¦é©ï¼ä¸¦å±ç¤ºäºæåæåºçè§£æ±ºæ¹æ¡çåªè¶æ§ã

##### **Actionable Cyber Threat Intelligence using Knowledge Graphs and Large Language Models**
2407.02528v1 by Romy Fieblinger, Md Tanvirul Alam, Nidhi Rastogi

Cyber threats are constantly evolving. Extracting actionable insights from
unstructured Cyber Threat Intelligence (CTI) data is essential to guide
cybersecurity decisions. Increasingly, organizations like Microsoft, Trend
Micro, and CrowdStrike are using generative AI to facilitate CTI extraction.
This paper addresses the challenge of automating the extraction of actionable
CTI using advancements in Large Language Models (LLMs) and Knowledge Graphs
(KGs). We explore the application of state-of-the-art open-source LLMs,
including the Llama 2 series, Mistral 7B Instruct, and Zephyr for extracting
meaningful triples from CTI texts. Our methodology evaluates techniques such as
prompt engineering, the guidance framework, and fine-tuning to optimize
information extraction and structuring. The extracted data is then utilized to
construct a KG, offering a structured and queryable representation of threat
intelligence. Experimental results demonstrate the effectiveness of our
approach in extracting relevant information, with guidance and fine-tuning
showing superior performance over prompt engineering. However, while our
methods prove effective in small-scale tests, applying LLMs to large-scale data
for KG construction and Link Prediction presents ongoing challenges.

æè¦ï¼ç¶²è·¯å¨èä¸æ·æ¼è®ãå¾éçµæ§åçç¶²è·¯å¨èæå ± (CTI) è³æä¸­èåå¯æ¡åè¡åçè¦è§£ï¼å°æ¼å¼å°ç¶²è·¯å®å¨æ±ºç­è³ééè¦ãè¶ä¾è¶å¤çµç¹ï¼ä¾å¦ Microsoftãè¶¨å¢ç§æå CrowdStrikeï¼ä½¿ç¨çæå¼ AI ä¾ä¿é² CTI èåãæ¬ææ¢è¨äºä½¿ç¨å¤§åèªè¨æ¨¡å (LLM) åç¥è­åè­ (KG) çé²å±ï¼èªåèåå¯æ¡åè¡åç CTI çææ°ãæåæ¢è¨äºæåé²çéæº LLM çæç¨ï¼åæ¬ Llama 2 ç³»åãMistral 7B Instruct å Zephyrï¼ä»¥å¾ CTI æå­ä¸­èåææç¾©çä¸åçµãæåçåæ³è©ä¼°äºæç¤ºå·¥ç¨ãæå°æ¶æ§åå¾®èª¿ç­æè¡ï¼ä»¥æä½³åè³è¨èååçµæ§åãç¶å¾ï¼å°èåçè³æç¨æ¼å»ºæ§ KGï¼æä¾å¨èæå ±ççµæ§åä¸å¯æ¥è©¢çè¡¨ç¤ºãå¯¦é©çµæè­æäºæåæ¹æ³å¨èåç¸éè³è¨æ¹é¢çæææ§ï¼æå°åå¾®èª¿é¡¯ç¤ºåºåªæ¼æç¤ºå·¥ç¨çæè½ãç¶èï¼éç¶æåçåæ³å¨å°è¦æ¨¡æ¸¬è©¦ä¸­è­æææï¼ä½å° LLM æç¨æ¼å¤§è¦æ¨¡è³æä»¥é²è¡ KG å»ºæ§åé£çµé æ¸¬ï¼ä»å­å¨æçºçææ°ã

##### **Chain-of-Knowledge: Integrating Knowledge Reasoning into Large Language Models by Learning from Knowledge Graphs**
2407.00653v1 by Yifei Zhang, Xintao Wang, Jiaqing Liang, Sirui Xia, Lida Chen, Yanghua Xiao

Large Language Models (LLMs) have exhibited impressive proficiency in various
natural language processing (NLP) tasks, which involve increasingly complex
reasoning. Knowledge reasoning, a primary type of reasoning, aims at deriving
new knowledge from existing one.While it has been widely studied in the context
of knowledge graphs (KGs), knowledge reasoning in LLMs remains underexplored.
In this paper, we introduce Chain-of-Knowledge, a comprehensive framework for
knowledge reasoning, including methodologies for both dataset construction and
model learning. For dataset construction, we create KnowReason via rule mining
on KGs. For model learning, we observe rule overfitting induced by naive
training. Hence, we enhance CoK with a trial-and-error mechanism that simulates
the human process of internal knowledge exploration. We conduct extensive
experiments with KnowReason. Our results show the effectiveness of CoK in
refining LLMs in not only knowledge reasoning, but also general reasoning
benchmarkms.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨åç¨®èªç¶èªè¨èç (NLP) ä»»åä¸­å±ç¾åºé©äººçè½åï¼éäºä»»åæ¶åè¶ä¾è¶è¤éçæ¨çãç¥è­æ¨çä½çºæ¨ççä¸»è¦é¡åï¼æ¨å¨å¾æ¢æç¥è­ä¸­æ¨å°åºæ°ç¥è­ãåç®¡ç¥è­æ¨çå·²å¨ç¥è­åè­ (KG) çèæ¯ä¸å¾å°å»£æ³ç ç©¶ï¼ä½ LLM ä¸­çç¥è­æ¨çä»èæ¼æ¢ç´¢éæ®µãå¨æ¬æä¸­ï¼æåä»ç´¹äºç¥è­æ¨ççç¶åæ¡æ¶ç¥è­éï¼å¶ä¸­åæ¬ç¨æ¼è³æéæ§å»ºåæ¨¡åå­¸ç¿çæ¹æ³ãå°æ¼è³æéæ§å»ºï¼æåééå¨ KG ä¸­é²è¡è¦åææä¾å»ºç« KnowReasonãå°æ¼æ¨¡åå­¸ç¿ï¼æåè§å¯å°ç±å¤©çè¨ç·´å¼ç¼çè¦åéåº¦æ¬åãå æ­¤ï¼æåä½¿ç¨æ¨¡æ¬äººé¡å§é¨ç¥è­æ¢ç´¢éç¨çè©¦é¯æ©å¶ä¾å¢å¼· CoKãæåå° KnowReason é²è¡äºå»£æ³çå¯¦é©ãæåççµæé¡¯ç¤º CoK å¨ç²¾ç LLM ä¸åå¨ç¥è­æ¨çæ¹é¢ï¼éåæ¬ä¸è¬æ¨çåºæºæ¹é¢é½éå¸¸ææã

##### **BioKGBench: A Knowledge Graph Checking Benchmark of AI Agent for Biomedical Science**
2407.00466v1 by Xinna Lin, Siqi Ma, Junjie Shan, Xiaojing Zhang, Shell Xu Hu, Tiannan Guo, Stan Z. Li, Kaicheng Yu

Pursuing artificial intelligence for biomedical science, a.k.a. AI Scientist,
draws increasing attention, where one common approach is to build a copilot
agent driven by Large Language Models (LLMs). However, to evaluate such
systems, people either rely on direct Question-Answering (QA) to the LLM
itself, or in a biomedical experimental manner. How to precisely benchmark
biomedical agents from an AI Scientist perspective remains largely unexplored.
To this end, we draw inspiration from one most important abilities of
scientists, understanding the literature, and introduce BioKGBench. In contrast
to traditional evaluation benchmark that only focuses on factual QA, where the
LLMs are known to have hallucination issues, we first disentangle
"Understanding Literature" into two atomic abilities, i) "Understanding" the
unstructured text from research papers by performing scientific claim
verification, and ii) Ability to interact with structured Knowledge-Graph
Question-Answering (KGQA) as a form of "Literature" grounding. We then
formulate a novel agent task, dubbed KGCheck, using KGQA and domain-based
Retrieval-Augmented Generation (RAG) to identify the factual errors of existing
large-scale knowledge graph databases. We collect over two thousand data for
two atomic tasks and 225 high-quality annotated data for the agent task.
Surprisingly, we discover that state-of-the-art agents, both daily scenarios
and biomedical ones, have either failed or inferior performance on our
benchmark. We then introduce a simple yet effective baseline, dubbed BKGAgent.
On the widely used popular knowledge graph, we discover over 90 factual errors
which provide scenarios for agents to make discoveries and demonstrate the
effectiveness of our approach. The code and data are available at
https://github.com/westlake-autolab/BioKGBench.

æè¦ï¼<paragraph>è¿½æ±çç©é«å­¸ç§å­¸çäººå·¥æºæ§ï¼åç¨± AI ç§å­¸å®¶ï¼
è¶ä¾è¶åå°éæ³¨ï¼å¶ä¸­ä¸ç¨®å¸¸è¦çæ¹æ³æ¯å»ºç«ç±å¤§åèªè¨æ¨¡å (LLM) é©åçå¯é§é§ä»£çãç¶èï¼è¦è©ä¼°æ­¤é¡
ç³»çµ±ï¼äººåè¦ä¹ä¾è³´ LLM æ¬èº«çç´æ¥åç­ (QA)ï¼è¦ä¹ä¾è³´çç©é«å­¸å¯¦é©æ¹å¼ãå¦ä½å¾ AI ç§å­¸å®¶çè§åº¦ç²¾ç¢ºè©é
çç©é«å­¸ä»£çå¨å¾å¤§ç¨åº¦ä¸ä»æªæ¢ç´¢ã
çºæ­¤ï¼æåå¾ç§å­¸å®¶æéè¦çè½åä¹ä¸ï¼å³çè§£æç»ä¸­æ±²åéæï¼ä¸¦ä»ç´¹ BioKGBenchãèåéæ³¨äºå¯¦ QA çå³çµ±è©éåºæºä¸åï¼å·²ç¥ LLM å¨äºå¯¦ QA ä¸­å­å¨å¹»è¦ºåé¡ï¼æåé¦åå°
ãçè§£æç»ãåè§£çºå©ç¨®åºæ¬è½åï¼i) ééå·è¡ç§å­¸ä¸»å¼µé©è­ä¾ãçè§£ãç ç©¶è«æä¸­çéçµæ§åæå­ï¼ä»¥å ii) ä»¥ãæç»ãçºåºç¤ï¼èçµæ§åçç¥è­åè¡¨åç­ (KGQA) äºåçè½åãç¶å¾
æåä½¿ç¨ KGQA ååºæ¼ç¶²åçæª¢ç´¢æ´åç¢ç (RAG) å¶å®äºä¸é æ°ç©çä»£çä»»åï¼ç¨±çº KGCheckï¼ä»¥è­å¥ç¾æå¤§åç¥è­åè¡¨è³æåº«çäºå¯¦é¯èª¤ãæåçº
å©ååºæ¬ä»»åæ¶éäºå©åå¤åè³æï¼ä»¥å 225 åé«åè³ªè¨»è§£è³æï¼ä»¥ä½çºä»£çä»»åãä»¤äººé©è¨çæ¯ï¼æåç¼ç¾æåé²çä»£çï¼ç¡è«æ¯æ¥å¸¸æå¢éæ¯çç©é«å­¸ï¼å¨æåç
åºæºä¸é½è¡¨ç¾ä¸ä½³æè¡¨ç¾è¼å·®ãç¶å¾ï¼æåå¼å¥äºä¸åç°¡å®ä½ææçåºæºï¼ç¨±çº BKGAgentãå¨å»£æ³ä½¿ç¨çç±éç¥è­åè¡¨ä¸ï¼æåç¼ç¾è¶é 90 åäºå¯¦é¯èª¤ï¼éäºé¯èª¤çºä»£çæä¾äºç¼ç¾æå¢ï¼ä¸¦è­æäºæåæ¹æ³çæææ§ãç¨å¼ç¢¼åè³æå¯å¨
https://github.com/westlake-autolab/BioKGBench åå¾ã</paragraph>

##### **GraphArena: Benchmarking Large Language Models on Graph Computational Problems**
2407.00379v1 by Jianheng Tang, Qifan Zhang, Yuhan Li, Jia Li

The "arms race" of Large Language Models (LLMs) demands novel, challenging,
and diverse benchmarks to faithfully examine their progresses. We introduce
GraphArena, a benchmarking tool designed to evaluate LLMs on graph
computational problems using million-scale real-world graphs from diverse
scenarios such as knowledge graphs, social networks, and molecular structures.
GraphArena offers a suite of 10 computational tasks, encompassing four
polynomial-time (e.g., Shortest Distance) and six NP-complete challenges (e.g.,
Travelling Salesman Problem). It features a rigorous evaluation framework that
classifies LLM outputs as correct, suboptimal (feasible but not optimal), or
hallucinatory (properly formatted but infeasible). Evaluation of 10 leading
LLMs, including GPT-4o and LLaMA3-70B-Instruct, reveals that even
top-performing models struggle with larger, more complex graph problems and
exhibit hallucination issues. Despite the application of strategies such as
chain-of-thought prompting, these issues remain unresolved. GraphArena
contributes a valuable supplement to the existing LLM benchmarks and is
open-sourced at https://github.com/squareRoot3/GraphArena.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çãè»åç«¶è³½ãéè¦æ°ç©ãå·ææ°æ§ä¸å¤æ¨£åçåºæºä¾å¿ å¯¦æª¢é©å¶é²åº¦ãæåæ¨åº GraphArenaï¼éæ¯ä¸ååºæºå·¥å·ï¼æ¨å¨ä½¿ç¨ä¾èªç¥è­åè­ãç¤¾äº¤ç¶²è·¯ååå­çµæ§ç­å¤æ¨£åæå¢çæ¸ç¾è¬åçå¯¦ä¸çåå½¢ï¼éå°åå½¢è¨ç®åé¡è©ä¼° LLMãGraphArena æä¾ä¸ç³»å 10 åè¨ç®ä»»åï¼åå«ååå¤é å¼æéï¼ä¾å¦ï¼æç­è·é¢ï¼åå­å NP å®å¨ææ°ï¼ä¾å¦ï¼æè¡æ¨é·å¡åé¡ï¼ãå®å·æä¸åå´è¬¹çè©ä¼°æ¶æ§ï¼å° LLM è¼¸åºåé¡çºæ­£ç¢ºãæ¬¡ä½³ï¼å¯è¡ä½éæä½³ï¼æå¹»è¦ºï¼æ ¼å¼æ­£ç¢ºä½ä¸å¯è¡ï¼ãå°åæ¬ GPT-4o å LLaMA3-70B-Instruct å¨å§ç 10 åé å LLM çè©ä¼°é¡¯ç¤ºï¼å³ä½¿æ¯æè½æä½³çæ¨¡åå¨èçæ´å¤§ãæ´è¤éçåå½¢åé¡æä»æéå°å°é£ï¼ä¸¦åºç¾å¹»è¦ºåé¡ãåç®¡æç¨äºä¸ç³»åç­ç¥ï¼ä¾å¦æèéæç¤ºï¼éäºåé¡ä»æªè§£æ±ºãGraphArena çºç¾æç LLM åºæºæä¾äºæå¹å¼çè£åï¼ä¸¦å¨ https://github.com/squareRoot3/GraphArena éæºã

##### **Teola: Towards End-to-End Optimization of LLM-based Applications**
2407.00326v1 by Xin Tan, Yimin Jiang, Yitao Yang, Hong Xu

Large language model (LLM)-based applications consist of both LLM and non-LLM
components, each contributing to the end-to-end latency. Despite great efforts
to optimize LLM inference, end-to-end workflow optimization has been
overlooked. Existing frameworks employ coarse-grained orchestration with task
modules, which confines optimizations to within each module and yields
suboptimal scheduling decisions. We propose fine-grained end-to-end
orchestration, which utilizes task primitives as the basic units and represents
each query's workflow as a primitive-level dataflow graph. This explicitly
exposes a much larger design space, enables optimizations in parallelization
and pipelining across primitives of different modules, and enhances scheduling
to improve application-level performance. We build Teola, a novel orchestration
framework for LLM-based applications that implements this scheme. Comprehensive
experiments show that Teola can achieve up to 2.09x speedup over existing
systems across various popular LLM applications.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) æç¨ç¨å¼ç± LLM åé LLM åä»¶çµæï¼æ¯ååä»¶é½æå½±é¿ç«¯å°ç«¯å»¶é²ãåç®¡å·²éå°æä½³å LLM æ¨è«ååºè¨±å¤åªåï¼ä½ç«¯å°ç«¯å·¥ä½æµç¨æä½³åå»é­å°å¿½ç¥ãç¾ææ¶æ§æ¡ç¨ç²ç¥çç·¨æèä»»åæ¨¡çµï¼å°æä½³åéå¶å¨æ¯åæ¨¡çµå§ï¼ä¸¦ç¢çæ¬¡ä½³çæç¨æ±ºç­ãæåæåºç´°ç·»çç«¯å°ç«¯ç·¨æï¼å®ä½¿ç¨ä»»ååèªä½çºåºæ¬å®ä½ï¼ä¸¦å°æ¯åæ¥è©¢çå·¥ä½æµç¨è¡¨ç¤ºçºåèªå±¤ç´è³ææµåãéæç¢ºå°æ­é²äºæ´å¤§çè¨­è¨ç©ºéï¼å¨ä¸åæ¨¡çµçåèªä¹éåç¨å¹³è¡ååç®¡ç·æä½³åï¼ä¸¦å å¼·æç¨ä»¥æ¹åæç¨ç¨å¼å±¤ç´æè½ãæåå»ºæ§ Teolaï¼ä¸åå¯¦ä½æ­¤æ¶æ§ç LLM æç¨ç¨å¼åµæ°ç·¨ææ¶æ§ãå¨é¢çå¯¦é©é¡¯ç¤ºï¼Teola è½å¨åç¨®ç±é LLM æç¨ç¨å¼ä¸­ï¼æ¯ç¾æç³»çµ±å¿«ä¸ 2.09 åã

##### **Into the Unknown: Generating Geospatial Descriptions for New Environments**
2406.19967v1 by Tzuf Paz-Argaman, John Palowitch, Sayali Kulkarni, Reut Tsarfaty, Jason Baldridge

Similar to vision-and-language navigation (VLN) tasks that focus on bridging
the gap between vision and language for embodied navigation, the new Rendezvous
(RVS) task requires reasoning over allocentric spatial relationships
(independent of the observer's viewpoint) using non-sequential navigation
instructions and maps. However, performance substantially drops in new
environments with no training data. Using opensource descriptions paired with
coordinates (e.g., Wikipedia) provides training data but suffers from limited
spatially-oriented text resulting in low geolocation resolution. We propose a
large-scale augmentation method for generating high-quality synthetic data for
new environments using readily available geospatial data. Our method constructs
a grounded knowledge-graph, capturing entity relationships. Sampled entities
and relations (`shop north of school') generate navigation instructions via (i)
generating numerous templates using context-free grammar (CFG) to embed
specific entities and relations; (ii) feeding the entities and relation into a
large language model (LLM) for instruction generation. A comprehensive
evaluation on RVS, showed that our approach improves the 100-meter accuracy by
45.83% on unseen environments. Furthermore, we demonstrate that models trained
with CFG-based augmentation achieve superior performance compared with those
trained with LLM-based augmentation, both in unseen and seen environments.
These findings suggest that the potential advantages of explicitly structuring
spatial information for text-based geospatial reasoning in previously unknown,
can unlock data-scarce scenarios.

æè¦ï¼é¡ä¼¼æ¼å°æ³¨æ¼å½åå·é«å°èªä¸­è¦è¦ºèèªè¨å·®è·çè¦è¦ºèªè¨å°èª (VLN) ä»»åï¼æ°çæé¢ (RVS) ä»»åéè¦ä½¿ç¨éé åºå°èªæä»¤åå°åæ¨çç°ä¸­å¿ç©ºééä¿ï¼èè§å¯èçè§é»ç¡éï¼ãç¶èï¼å¨æ²æè¨ç·´è³æçæ°ç°å¢ä¸­ï¼æè½æå¤§å¹ä¸éãä½¿ç¨èåº§æ¨éå°çéæºèªªæï¼ä¾å¦ï¼ç¶­åºç¾ç§ï¼æä¾äºè¨ç·´è³æï¼ä½ç±æ¼ç©ºéå°åæå­æéï¼å°è´å°çä½ç½®è§£æåº¦ä½ãæåæåºäºä¸ç¨®å¤§è¦æ¨¡æ´åæ¹æ³ï¼ä½¿ç¨ç¾æçå°çç©ºéè³æçºæ°ç°å¢ç¢çé«åè³ªçåæè³æãæåçå»ºæ§æ¹æ³å»ºç«äºä¸ååºç¤ç¥è­åï¼æ·åå¯¦é«éä¿ãåæ¨£çå¯¦é«åéä¿ï¼ãååºå¨å­¸æ ¡åéãï¼ééä»¥ä¸æ¹å¼ç¢çå°èªæä»¤ï¼(i) ä½¿ç¨ç¡éä¹èªå¢çææ³ (CFG) ç¢çè¨±å¤ç¯æ¬ä¾åµå¥ç¹å®å¯¦é«åéä¿ï¼(ii) å°å¯¦é«åéä¿è¼¸å¥å¤§åèªè¨æ¨¡å (LLM) ä»¥ç¢çæä»¤ãå¨ RVS ä¸çå¨é¢è©ä¼°é¡¯ç¤ºï¼æåçåæ³å°æªè¦éç°å¢ä¸­ç 100 å¬å°ºæºç¢ºåº¦æåäº 45.83%ãæ­¤å¤ï¼æåè­æä½¿ç¨åºæ¼ CFG çæ´åæè¨ç·´çæ¨¡åï¼å¨æªè¦éåè¦éç°å¢ä¸­ï¼é½æ¯ä½¿ç¨åºæ¼ LLM çæ´åæè¨ç·´çæ¨¡åç²å¾äºæ´å¥½çæè½ãéäºç¼ç¾è¡¨æï¼å¨ä»¥åæªç¥çç°å¢ä¸­ï¼æç¢ºå»ºæ§ç¨æ¼åºæ¼æå­çå°çç©ºéæ¨ççç©ºéè³è¨çæ½å¨åªå¢ï¼å¯ä»¥è§£éè³æç¨å°çå ´æ¯ã

##### **Investigating How Large Language Models Leverage Internal Knowledge to Perform Complex Reasoning**
2406.19502v1 by Miyoung Ko, Sue Hyun Park, Joonsuk Park, Minjoon Seo

Despite significant advancements, there is a limited understanding of how
large language models (LLMs) utilize knowledge for reasoning. To address this,
we propose a method that deconstructs complex real-world questions into a
graph, representing each question as a node with parent nodes of background
knowledge needed to solve the question. We develop the DepthQA dataset,
deconstructing questions into three depths: (i) recalling conceptual knowledge,
(ii) applying procedural knowledge, and (iii) analyzing strategic knowledge.
Based on a hierarchical graph, we quantify forward discrepancy, discrepancies
in LLMs' performance on simpler sub-problems versus complex questions. We also
measure backward discrepancy, where LLMs answer complex questions but struggle
with simpler ones. Our analysis shows that smaller models have more
discrepancies than larger models. Additionally, guiding models from simpler to
complex questions through multi-turn interactions improves performance across
model sizes, highlighting the importance of structured intermediate steps in
knowledge reasoning. This work enhances our understanding of LLM reasoning and
suggests ways to improve their problem-solving abilities.

æè¦ï¼åç®¡æé¡¯èçé²å±ï¼ä½å°æ¼å¤§åèªè¨æ¨¡å (LLM) å¦ä½å©ç¨ç¥è­é²è¡æ¨çççè§£ä»ç¶æéãçºäºè§£æ±ºéååé¡ï¼æåæåºäºä¸ç¨®æ¹æ³ï¼å°è¤éççå¯¦ä¸çåé¡è§£æ§æä¸ååå½¢ï¼å°æ¯ååé¡è¡¨ç¤ºçºä¸åç¯é»ï¼å¶ä¸­åå«è§£æ±ºåé¡æéçèæ¯ç¥è­çç¶ç¯é»ãæåéç¼äº DepthQA è³æéï¼å°åé¡è§£æ§æä¸åæ·±åº¦ï¼(i) åæ¶æ¦å¿µç¥è­ï¼(ii) æç¨ç¨åºç¥è­ï¼ä»¥å (iii) åæç­ç¥ç¥è­ãåºæ¼ä¸åéå±¤åå½¢ï¼æåéåäºæ­£åå·®ç°ï¼LLM å¨è¼ç°¡å®çå­åé¡åè¤éåé¡ä¸çæè½å·®ç°ãæåä¹æ¸¬éäºååå·®ç°ï¼å¶ä¸­ LLM è½åç­è¤éåé¡ï¼ä½å¨è¼ç°¡å®çåé¡ä¸å»æå°é£ãæåçåæé¡¯ç¤ºï¼è¼å°çæ¨¡åæ¯è¼å¤§çæ¨¡åææ´å¤çå·®ç°ãæ­¤å¤ï¼ééå¤ååäºåå¼å°æ¨¡åå¾è¼ç°¡å®å°è¤éçåé¡ï¼å¯ä»¥æ¹åæææ¨¡åè¦æ¨¡çæè½ï¼çªé¡¯äºçµæ§åä¸­éæ­¥é©å¨ç¥è­æ¨çä¸­çéè¦æ§ãéé å·¥ä½å¢é²äºæåå° LLM æ¨çççè§£ï¼ä¸¦æåºäºæ¹åå¶åé¡è§£æ±ºè½åçæ¹æ³ã

##### **Enhancing Video-Language Representations with Structural Spatio-Temporal Alignment**
2406.19255v1 by Hao Fei, Shengqiong Wu, Meishan Zhang, Min Zhang, Tat-Seng Chua, Shuicheng Yan

While pre-training large-scale video-language models (VLMs) has shown
remarkable potential for various downstream video-language tasks, existing VLMs
can still suffer from certain commonly seen limitations, e.g., coarse-grained
cross-modal aligning , under-modeling of temporal dynamics, detached
video-language view. In this work, we target enhancing VLMs with a fine-grained
structural spatio-temporal alignment learning method (namely Finsta). First of
all, we represent the input texts and videos with fine-grained scene graph (SG)
structures, both of which are further unified into a holistic SG (HSG) for
bridging two modalities. Then, an SG-based framework is built, where the
textual SG (TSG) is encoded with a graph Transformer, while the video dynamic
SG (DSG) and the HSG are modeled with a novel recurrent graph Transformer for
spatial and temporal feature propagation. A spatial-temporal Gaussian
differential graph Transformer is further devised to strengthen the sense of
the changes in objects across spatial and temporal dimensions. Next, based on
the fine-grained structural features of TSG and DSG, we perform object-centered
spatial alignment and predicate-centered temporal alignment respectively,
enhancing the video-language grounding in both the spatiality and temporality.
We design our method as a plug&play system, which can be integrated into
existing well-trained VLMs for further representation augmentation, without
training from scratch or relying on SG annotations in downstream applications.
On 6 representative VL modeling tasks over 12 datasets in both standard and
long-form video scenarios, Finsta consistently improves the existing 13
strong-performing VLMs persistently, and refreshes the current state-of-the-art
end task performance significantly in both the fine-tuning and zero-shot
settings.

æè¦ï¼<paragraph>éç¶é è¨ç·´å¤§åè¦è¨èªè¨æ¨¡å (VLM) å·²å±ç¾åºå°åç¨®ä¸æ¸¸è¦è¨èªè¨ä»»åçé¡¯èæ½åï¼ä½ç¾æç VLM ä»å¯è½åå°æäºå¸¸è¦éå¶çå½±é¿ï¼ä¾å¦ç²ç²åº¦çè·¨æ¨¡æå°é½ãå°æéåæçå»ºæ¨¡ä¸è¶³ãåé¢çè¦è¨èªè¨æª¢è¦ãå¨éé å·¥ä½ä¸­ï¼æåä»¥å·åç´°ç²åº¦çµæ§åæç©ºå°é½å­¸ç¿æ¹æ³ (å³ Finsta) çå¢å¼· VLM çºç®æ¨ãé¦åï¼æåä»¥ç´°ç²åº¦çå ´æ¯å (SG) çµæ§è¡¨ç¤ºè¼¸å¥æå­åè¦è¨ï¼å©èé²ä¸æ­¥çµ±ä¸å°ä¸åæ´é« SG (HSG) ä¸­ï¼ä»¥æ©æ¥å©åæ¨¡æãç¶å¾ï¼å»ºç«ä¸ååºæ¼ SG çæ¡æ¶ï¼å¶ä¸­æå­ SG (TSG) ä½¿ç¨åå½¢ Transformer ç·¨ç¢¼ï¼èè¦è¨åæ SG (DSG) å HSG åä½¿ç¨æ°ç©çéè¿´åå½¢ Transformer å»ºæ¨¡ï¼ä»¥é²è¡ç©ºéåæéç¹å¾µå³æ­ãé²ä¸æ­¥è¨­è¨äºä¸åæç©ºé«æ¯å·®ååå½¢ Transformerï¼ä»¥å¢å¼·ç©é«å¨æç©ºç¶­åº¦ä¸­è®åçæè¦ºãæ¥ä¸ä¾ï¼æ ¹æ TSG å DSG çç´°ç²åº¦çµæ§ç¹å¾µï¼æååå¥å·è¡ä»¥ç©ä»¶çºä¸­å¿çç©ºéå°é½åä»¥è¬è©çºä¸­å¿çæåºå°é½ï¼å¢å¼·è¦è¨èªè¨å¨ç©ºéåæéä¸çåºç¤ãæåå°æ¹æ³è¨­è¨çºä¸åå³æå³ç¨çç³»çµ±ï¼å¯ä»¥æ´åå°ç¾æçè¨ç·´è¯å¥½ç VLM ä¸­ï¼ä»¥é²ä¸æ­¥æ´åè¡¨ç¤ºï¼èç¡éå¾é ­éå§è¨ç·´æä¾è³´ä¸æ¸¸æç¨ç¨å¼ä¸­ç SG æ¨è¨»ãå¨ 12 åè³æéä¸ç 6 åä»£è¡¨æ§ VL å»ºæ¨¡ä»»åä¸­ï¼ç¡è«æ¯å¨æ¨æºè¦è¨å ´æ¯éæ¯é·æ ¼å¼è¦è¨å ´æ¯ä¸­ï¼Finsta é½æçºæ¹åç¾æç 13 åæè½å¼·å¤§ç VLMï¼ä¸¦å¨å¾®èª¿åé¶æ¬¡å­¸ç¿è¨­å®ä¸­é¡¯èæ´æ°ç®åçææ°æè¡æçµä»»åæè½ã</paragraph>

##### **TrustUQA: A Trustful Framework for Unified Structured Data Question Answering**
2406.18916v1 by Wen Zhang, Long Jin, Yushan Zhu, Jiaoyan Chen, Zhiwei Huang, Junjie Wang, Yin Hua, Lei Liang, Huajun Chen

Natural language question answering (QA) over structured data sources such as
tables and knowledge graphs (KGs) have been widely investigated, for example
with Large Language Models (LLMs). The main solutions include question to
formal query parsing and retrieval-based answer generation. However, current
methods of the former often suffer from weak generalization, failing to dealing
with multiple sources simultaneously, while the later is limited in
trustfulness. In this paper, we propose UnifiedTQA, a trustful QA framework
that can simultaneously support multiple types of structured data in a unified
way. To this end, it adopts an LLM-friendly and unified knowledge
representation method called Condition Graph (CG), and uses an LLM and
demonstration-based two-level method for CG querying. For enhancement, it is
also equipped with dynamic demonstration retrieval. We have evaluated
UnifiedTQA with 5 benchmarks covering 3 types of structured data. It
outperforms 2 existing unified structured data QA methods and in comparison
with the baselines that are specific to a data type, it achieves
state-of-the-art on 2 of them. Further more, we demonstrates potential of our
method for more general QA tasks, QA over mixed structured data and QA across
structured data.

æè¦ï¼èªç¶èªè¨åç­ (QA) ééçµæ§åè³æä¾æºï¼ä¾å¦è¡¨æ ¼åç¥è­åè­ (KGs)ï¼å·²å»£æ³ç ç©¶ï¼ä¾å¦ä½¿ç¨å¤§åèªè¨æ¨¡å (LLM)ãä¸»è¦è§£æ±ºæ¹æ¡åæ¬åé¡è½ææå½¢å¼åæ¥è©¢è§£æååºæ¼æª¢ç´¢çç­æ¡ç¢çãç¶èï¼åèçç¾è¡æ¹æ³éå¸¸æç¢çå¼±æ³åï¼ç¡æ³åæèçå¤åä¾æºï¼èå¾èååå°å¯ä¿¡åº¦çéå¶ãå¨æ¬æä¸­ï¼æåæåº UnifiedTQAï¼ä¸åå¯ä¿¡è³´ç QA æ¡æ¶ï¼è½å¤ ä»¥çµ±ä¸çæ¹å¼åææ¯æ´å¤ç¨®é¡åççµæ§åè³æãçºæ­¤ï¼å®æ¡ç¨äºä¸ç¨® LLM ååä¸çµ±ä¸çç¥è­è¡¨ç¤ºæ¹æ³ï¼ç¨±çºæ¢ä»¶å (CG)ï¼ä¸¦ä½¿ç¨ LLM ååºæ¼ç¤ºç¯çäºéæ¹æ³é²è¡ CG æ¥è©¢ãçºäºå å¼·ï¼å®ééåäºåæç¤ºç¯æª¢ç´¢ãæåå·²ç¶ä½¿ç¨æ¶µè 3 ç¨®é¡åçµæ§åè³æç 5 ååºæºè©ä¼° UnifiedTQAãå®åªæ¼ 2 ç¨®ç¾æççµ±ä¸çµæ§åè³æ QA æ¹æ³ï¼ä¸¦ä¸èç¹å®æ¼è³æé¡åçåºç·ç¸æ¯ï¼å®å¨å¶ä¸­ 2 ååºæºä¸éå°äºæåé²çæ°´å¹³ãæ­¤å¤ï¼æåå±ç¤ºäºæåçæ¹æ³å¨æ´éç¨ç QA ä»»åãæ··åçµæ§åè³æç QA åè·¨çµæ§åè³æç QA ä¸­çæ½åã

##### **Fast Optimizer Benchmark**
2406.18701v1 by Simon Blauth, Tobias BÃ¼rger, Zacharias HÃ¤ringer, JÃ¶rg Franke, Frank Hutter

In this paper, we present the Fast Optimizer Benchmark (FOB), a tool designed
for evaluating deep learning optimizers during their development. The benchmark
supports tasks from multiple domains such as computer vision, natural language
processing, and graph learning. The focus is on convenient usage, featuring
human-readable YAML configurations, SLURM integration, and plotting utilities.
FOB can be used together with existing hyperparameter optimization (HPO) tools
as it handles training and resuming of runs. The modular design enables
integration into custom pipelines, using it simply as a collection of tasks. We
showcase an optimizer comparison as a usage example of our tool. FOB can be
found on GitHub: https://github.com/automl/FOB.

æè¦ï¼å¨æ¬æä¸­ï¼æåæåºäºå¿«éåªåå¨åºæº (FOB)ï¼éæ¯ä¸åç¨æ¼å¨éç¼éç¨ä¸­è©ä¼°æ·±åº¦å­¸ç¿åªåå¨çå·¥å·ãåºæºæ¯æä¾èªå¤åé åçä»»åï¼ä¾å¦é»è¦è¦è¦ºãèªç¶èªè¨èçååå½¢å­¸ç¿ãéé»å¨æ¼æ¹ä¾¿ä½¿ç¨ï¼å·æäººé¡å¯è®ç YAML éç½®ãSLURM æ´ååç¹ªåç¨å¼ãFOB å¯ä»¥èç¾æçè¶åæ¸åªå (HPO) å·¥å·ä¸èµ·ä½¿ç¨ï¼å çºå®å¯ä»¥èçè¨ç·´åæ¢å¾©éè¡ãæ¨¡çµåè¨­è¨è½å¤ æ´åå°èªè¨ç®¡ç·ä¸­ï¼åªéå°å¶ç¨ä½ä»»åéåå³å¯ãæåå±ç¤ºäºä¸ååªåå¨æ¯è¼ä½çºæåå·¥å·çä½¿ç¨ç¯ä¾ãFOB å¯ä»¥å¾ GitHub æ¾å°ï¼https://github.com/automl/FOBã

##### **Cascading Large Language Models for Salient Event Graph Generation**
2406.18449v1 by Xingwei Tan, Yuxiang Zhou, Gabriele Pergola, Yulan He

Generating event graphs from long documents is challenging due to the
inherent complexity of multiple tasks involved such as detecting events,
identifying their relationships, and reconciling unstructured input with
structured graphs. Recent studies typically consider all events with equal
importance, failing to distinguish salient events crucial for understanding
narratives. This paper presents CALLMSAE, a CAscading Large Language Model
framework for SAlient Event graph generation, which leverages the capabilities
of LLMs and eliminates the need for costly human annotations. We first identify
salient events by prompting LLMs to generate summaries, from which salient
events are identified. Next, we develop an iterative code refinement prompting
strategy to generate event relation graphs, removing hallucinated relations and
recovering missing edges. Fine-tuning contextualised graph generation models on
the LLM-generated graphs outperforms the models trained on CAEVO-generated
data. Experimental results on a human-annotated test set show that the proposed
method generates salient and more accurate graphs, outperforming competitive
baselines.

æè¦ï¼ç±æ¼æ¶åå¤é ä»»åçå§å¨è¤éæ§ï¼ä¾å¦åµæ¸¬äºä»¶ãè­å¥å¶éä¿ï¼ä»¥åèª¿åéçµæ§åè¼¸å¥èçµæ§ååè¡¨ï¼å æ­¤å¾é·ç¯æä»¶ç¢çäºä»¶åè¡¨æ¯ä¸é ææ°ãæè¿çç ç©¶éå¸¸å°ææäºä»¶è¦çºåç­éè¦ï¼æªè½ååå°çè§£æäºè³ééè¦çé¡¯èäºä»¶ãæ¬ææåºäº CALLMSAEï¼ä¸åç¨æ¼çæé¡¯èäºä»¶åè¡¨çå±¤çå¼å¤§åèªè¨æ¨¡åæ¡æ¶ï¼å®å©ç¨äº LLM çåè½ï¼ä¸¦æ¶é¤äºå°æè²´çäººå·¥æ¨è¨»çéæ±ãæåé¦åééæç¤º LLM ç¢çæè¦ä¾è­å¥é¡¯èäºä»¶ï¼å¾ä¸­è­å¥åºé¡¯èäºä»¶ãæ¥ä¸ä¾ï¼æåéç¼äºä¸ç¨®åè¦çç¨å¼ç¢¼ç²¾çæç¤ºç­ç¥ä¾ç¢çäºä»¶éä¿åè¡¨ï¼ç§»é¤å¹»è¦ºéä¿ä¸¦æ¢å¾©éºå¤±çéç·£ãå¨ LLM çæçåè¡¨ä¸å¾®èª¿æå¢ååè¡¨çææ¨¡åï¼å¶è¡¨ç¾åªæ¼å¨ CAEVO çæçè³æä¸è¨ç·´çæ¨¡åãå¨äººå·¥æ¨è¨»çæ¸¬è©¦éä¸çå¯¦é©çµæé¡¯ç¤ºï¼ææåºçæ¹æ³ç¢çäºé¡¯èä¸æ´æºç¢ºçåè¡¨ï¼åªæ¼ç«¶ç­æ§çåºæºã

##### **Sanskrit Knowledge-based Systems: Annotation and Computational Tools**
2406.18276v1 by Hrishikesh Terdalkar

We address the challenges and opportunities in the development of knowledge
systems for Sanskrit, with a focus on question answering. By proposing a
framework for the automated construction of knowledge graphs, introducing
annotation tools for ontology-driven and general-purpose tasks, and offering a
diverse collection of web-interfaces, tools, and software libraries, we have
made significant contributions to the field of computational Sanskrit. These
contributions not only enhance the accessibility and accuracy of Sanskrit text
analysis but also pave the way for further advancements in knowledge
representation and language processing. Ultimately, this research contributes
to the preservation, understanding, and utilization of the rich linguistic
information embodied in Sanskrit texts.

æè¦ï¼æåèæè§£æ±ºæ¢µèªç¥è­ç³»çµ±éç¼ä¸­çææ°åæ©æï¼éé»å¨æ¼åé¡è§£ç­ãééæåºä¸åç¨æ¼èªåå»ºæ§ç¥è­åè­çæ¶æ§ï¼å°å¥ç¨æ¼æ¬é«é©ååä¸è¬ç¨éä»»åçè¨»è§£å·¥å·ï¼ä¸¦æä¾å¤æ¨£åçç¶²è·¯ä»é¢ãå·¥å·åè»é«å½å¼åº«ï¼æåå°è¨ç®æ¢µèªé åååºäºéå¤§è²¢ç»ãéäºè²¢ç»ä¸åå¢å¼·äºæ¢µèªææ¬åæçå¯å­åæ§åæºç¢ºæ§ï¼ä¹çºç¥è­è¡¨å¾µåèªè¨èççé²ä¸æ­¥é²å±éªå¹³äºéè·¯ãæçµï¼éé ç ç©¶æå©æ¼ä¿å­ãçè§£åå©ç¨æ¢µèªææ¬ä¸­èå«çè±å¯èªè¨è³è¨ã

##### **Multilingual Knowledge Graph Completion from Pretrained Language Models with Knowledge Constraints**
2406.18085v1 by Ran Song, Shizhu He, Shengxiang Gao, Li Cai, Kang Liu, Zhengtao Yu, Jun Zhao

Multilingual Knowledge Graph Completion (mKGC) aim at solving queries like
(h, r, ?) in different languages by reasoning a tail entity t thus improving
multilingual knowledge graphs. Previous studies leverage multilingual
pretrained language models (PLMs) and the generative paradigm to achieve mKGC.
Although multilingual pretrained language models contain extensive knowledge of
different languages, its pretraining tasks cannot be directly aligned with the
mKGC tasks. Moreover, the majority of KGs and PLMs currently available exhibit
a pronounced English-centric bias. This makes it difficult for mKGC to achieve
good results, particularly in the context of low-resource languages. To
overcome previous problems, this paper introduces global and local knowledge
constraints for mKGC. The former is used to constrain the reasoning of answer
entities, while the latter is used to enhance the representation of query
contexts. The proposed method makes the pretrained model better adapt to the
mKGC task. Experimental results on public datasets demonstrate that our method
outperforms the previous SOTA on Hits@1 and Hits@10 by an average of 12.32% and
16.03%, which indicates that our proposed method has significant enhancement on
mKGC.

æè¦ï¼å¤èªè¨ç¥è­åè­å®æ (mKGC) æ¨å¨ééæ¨çå°¾é¨å¯¦é« t ä¾è§£æ±ºä¸åèªè¨ä¸­çæ¥è©¢ï¼ä¾å¦ (h, r, ?)ï¼é²èæ¹åå¤èªè¨ç¥è­åè­ãååçç ç©¶å©ç¨å¤èªè¨é è¨ç·´èªè¨æ¨¡å (PLM) åçæç¯ä¾ä¾éæ mKGCãåç®¡å¤èªè¨é è¨ç·´èªè¨æ¨¡ååå«ä¸åèªè¨çå»£æ³ç¥è­ï¼ä½å¶é è¨ç·´ä»»åç¡æ³ç´æ¥è mKGC ä»»åå°é½ãæ­¤å¤ï¼ç®åå¤§å¤æ¸çç¥è­åè­å PLM é½å±ç¾åºæé¡¯çè±èªä¸­å¿åèª¤ãéä½¿å¾ mKGC é£ä»¥éæè¯å¥½ççµæï¼ç¹å¥æ¯å¨ä½è³æºèªè¨çèçµ¡ä¸­ãçºäºåæååçåé¡ï¼æ¬æéå° mKGC å¼å¥äºå¨åèå±é¨ç¥è­éå¶ãåèç¨æ¼éå¶ç­æ¡å¯¦é«çæ¨çï¼èå¾èç¨æ¼å å¼·æ¥è©¢èçµ¡çè¡¨ç¤ºãææåºçæ¹æ³ä½¿å¾é è¨ç·´æ¨¡åè½æ´å¥½å°é©æ mKGC ä»»åãå¬éè³æéä¸çå¯¦é©çµæé¡¯ç¤ºï¼æåçæ¨¡åå¨ Hits@1 å Hits@10 ä¸å¹³ååªæ¼ååç SOTA 12.32% å 16.03%ï¼éè¡¨ç¤ºæåæåºçæ¹æ³é¡¯èå°å¢å¼·äº mKGCã

##### **AdaZeta: Adaptive Zeroth-Order Tensor-Train Adaption for Memory-Efficient Large Language Models Fine-Tuning**
2406.18060v1 by Yifan Yang, Kai Zhen, Ershad Banijamal, Athanasios Mouchtaris, Zheng Zhang

Fine-tuning large language models (LLMs) has achieved remarkable performance
across various natural language processing tasks, yet it demands more and more
memory as model sizes keep growing. To address this issue, the recently
proposed Memory-efficient Zeroth-order (MeZO) methods attempt to fine-tune LLMs
using only forward passes, thereby avoiding the need for a backpropagation
graph. However, significant performance drops and a high risk of divergence
have limited their widespread adoption. In this paper, we propose the Adaptive
Zeroth-order Tensor-Train Adaption (AdaZeta) framework, specifically designed
to improve the performance and convergence of the ZO methods. To enhance
dimension-dependent ZO estimation accuracy, we introduce a fast-forward,
low-parameter tensorized adapter. To tackle the frequently observed divergence
issue in large-scale ZO fine-tuning tasks, we propose an adaptive query number
schedule that guarantees convergence. Detailed theoretical analysis and
extensive experimental results on Roberta-Large and Llama-2-7B models
substantiate the efficacy of our AdaZeta framework in terms of accuracy, memory
efficiency, and convergence speed.

æè¦ï¼å¾®è°å¤§åè¯­è¨æ¨¡å (LLM) å¨åç§èªç¶è¯­è¨å¤çä»»å¡ä¸­åå¾äºæ¾èçæ§è½ï¼ä½éçæ¨¡åè§æ¨¡çä¸æ­æ©å¤§ï¼å®å¯¹åå­çéæ±ä¹è¶æ¥è¶å¤§ãä¸ºäºè§£å³è¿ä¸ªé®é¢ï¼æè¿æåºçåå­é«æé¶é¶ (MeZO) æ¹æ³è¯å¾ä»ä½¿ç¨ååä¼ éæ¥å¾®è° LLMï¼ä»èé¿åäºå¯¹ååä¼ æ­å¾çéæ±ãç¶èï¼ä¸¥éçæ§è½ä¸éååæ£çé«é£é©éå¶äºå®ä»¬çå¹¿æ³éç¨ãå¨æ¬æä¸­ï¼æä»¬æåºäºèªéåºé¶é¶å¼ éè®­ç»èªéåº (AdaZeta) æ¡æ¶ï¼ä¸é¨è®¾è®¡ç¨äºæé« ZO æ¹æ³çæ§è½åæ¶ææ§ãä¸ºäºå¢å¼ºç»´åº¦ç¸å³ç ZO ä¼°è®¡ç²¾åº¦ï¼æä»¬å¼å¥äºä¸ä¸ªå¿«éååãä½åæ°å¼ éåééå¨ãä¸ºäºè§£å³å¨å¤§è§æ¨¡ ZO å¾®è°ä»»å¡ä¸­ç»å¸¸è§å¯å°çåæ£é®é¢ï¼æä»¬æåºäºä¸ä¸ªèªéåºæ¥è¯¢æ°éè®¡åï¼ä»¥ä¿è¯æ¶ææ§ãå¯¹ Roberta-Large å Llama-2-7B æ¨¡åçè¯¦ç»çè®ºåæåå¹¿æ³çå®éªç»æè¯æäºæä»¬ç AdaZeta æ¡æ¶å¨åç¡®æ§ãåå­æçåæ¶æéåº¦æ¹é¢çæææ§ã

##### **DARG: Dynamic Evaluation of Large Language Models via Adaptive Reasoning Graph**
2406.17271v1 by Zhehao Zhang, Jiaao Chen, Diyi Yang

The current paradigm of evaluating Large Language Models (LLMs) through
static benchmarks comes with significant limitations, such as vulnerability to
data contamination and a lack of adaptability to the evolving capabilities of
LLMs. Therefore, evaluation methods that can adapt and generate evaluation data
with controlled complexity are urgently needed. In this work, we introduce
Dynamic Evaluation of LLMs via Adaptive Reasoning Graph Evolvement (DARG) to
dynamically extend current benchmarks with controlled complexity and diversity.
Specifically, we first extract the reasoning graphs of data points in current
benchmarks and then perturb the reasoning graphs to generate novel testing
data. Such newly generated test samples can have different levels of complexity
while maintaining linguistic diversity similar to the original benchmarks. We
further use a code-augmented LLM to ensure the label correctness of newly
generated data. We apply our DARG framework to diverse reasoning tasks in four
domains with 15 state-of-the-art LLMs. Experimental results show that almost
all LLMs experience a performance decrease with increased complexity and
certain LLMs exhibit significant drops. Additionally, we find that LLMs exhibit
more biases when being evaluated via the data generated by DARG with higher
complexity levels. These observations provide useful insights into how to
dynamically and adaptively evaluate LLMs. The code is available at
https://github.com/SALT-NLP/DARG.

æè¦ï¼ç®åéééæåºæºè©ä¼°å¤§åèªè¨æ¨¡å (LLM) çç¯ä¾ä¼´é¨èé¡¯èçéå¶ï¼ä¾å¦å®¹æåå°è³ææ±¡æï¼ä»¥åç¼ºä¹é©æ LLM ä¸æ·æ¼é²çè½åãå æ­¤ï¼è¿«åéè¦è½å¤ é©æä¸¦ç¢çå·æåæ§è¤éæ§çè©ä¼°è³æçè©ä¼°æ¹æ³ãå¨éé å·¥ä½ä¸­ï¼æåééèªé©ææ¨çåå½¢æ¼å (DARG) å¼å¥ LLM çåæè©ä¼°ï¼ä»¥åæå»¶ä¼¸ç®åå·æåæ§è¤éæ§åå¤æ¨£æ§çåºæºãå·é«ä¾èªªï¼æåé¦åæ·åç®ååºæºä¸­è³æé»çæ¨çåå½¢ï¼ç¶å¾æ¾åæ¨çåå½¢ä»¥ç¢çæ°çæ¸¬è©¦è³æãéäºæ°ç¢ççæ¸¬è©¦æ¨£æ¬å¯ä»¥æä¸åçè¤éæ§å±¤ç´ï¼åæç¶­æèåå§åºæºé¡ä¼¼çèªè¨å¤æ¨£æ§ãæåé²ä¸æ­¥ä½¿ç¨ç¨å¼ç¢¼å¢å¼·ç LLM ä¾ç¢ºä¿æ°ç¢çè³æçæ¨ç±¤æ­£ç¢ºæ§ãæåå° DARG æ¶æ§å¥ç¨æ¼ååé åä¸­çåç¨®æ¨çä»»åï¼ä¸¦ä½¿ç¨ 15 åæåé²ç LLMãå¯¦é©çµæé¡¯ç¤ºï¼å¹¾ä¹ææ LLM å¨è¤éæ§å¢å çææ³ä¸é½æåºç¾æè½ä¸éï¼èæäº LLM åè¡¨ç¾åºé¡¯èçä¸éãæ­¤å¤ï¼æåç¼ç¾ LLM å¨éé DARG ç¢çå·æè¼é«è¤éæ§å±¤ç´çè³æé²è¡è©ä¼°æï¼æè¡¨ç¾åºæ´å¤åå·®ãéäºè§å¯çµææä¾äºæç¨çè¦è§£ï¼èªªæå¦ä½åæä¸èªé©æå°è©ä¼° LLMãç¨å¼ç¢¼å¯å¨ https://github.com/SALT-NLP/DARG åå¾ã

##### **CogMG: Collaborative Augmentation Between Large Language Model and Knowledge Graph**
2406.17231v1 by Tong Zhou, Yubo Chen, Kang Liu, Jun Zhao

Large language models have become integral to question-answering applications
despite their propensity for generating hallucinations and factually inaccurate
content. Querying knowledge graphs to reduce hallucinations in LLM meets the
challenge of incomplete knowledge coverage in knowledge graphs. On the other
hand, updating knowledge graphs by information extraction and knowledge graph
completion faces the knowledge update misalignment issue. In this work, we
introduce a collaborative augmentation framework, CogMG, leveraging knowledge
graphs to address the limitations of LLMs in QA scenarios, explicitly targeting
the problems of incomplete knowledge coverage and knowledge update
misalignment. The LLMs identify and decompose required knowledge triples that
are not present in the KG, enriching them and aligning updates with real-world
demands. We demonstrate the efficacy of this approach through a supervised
fine-tuned LLM within an agent framework, showing significant improvements in
reducing hallucinations and enhancing factual accuracy in QA responses. Our
code and video are publicly available.

æè¦ï¼å¤§åèªè¨æ¨¡åå·²æçºåç­æç¨ç¨å¼ä¸­ä¸å¯æç¼ºçä¸é¨åï¼åç®¡å®åå¾åæ¼ç¢çå¹»è¦ºåäºå¯¦ä¸æ­£ç¢ºçå§å®¹ãæ¥è©¢ç¥è­åè¡¨ä»¥æ¸å° LLM ä¸­çå¹»è¦ºæéå°ç¥è­åè¡¨ä¸­ç¥è­è¦èä¸å®æ´çææ°ãå¦ä¸æ¹é¢ï¼ééè³è¨èååç¥è­åè¡¨å®æä¾æ´æ°ç¥è­åè¡¨æé¢è¨ç¥è­æ´æ°é¯ä½åé¡ãå¨éé å·¥ä½ä¸­ï¼æåå¼å¥äºåä½æ´åæ¶æ§ CogMGï¼å©ç¨ç¥è­åè¡¨ä¾è§£æ±º LLM å¨ QA å ´æ¯ä¸­çéå¶ï¼æç¢ºéå°ä¸å®æ´çç¥è­è¦èåç¥è­æ´æ°é¯ä½åé¡ãLLM è­å¥ä¸¦åè§£ KG ä¸­ä¸å­å¨çæéç¥è­ä¸åçµï¼è±å¯å®åä¸¦å°æ´æ°èç¾å¯¦ä¸ççéæ±ä¿æä¸è´ãæåééä»£çæ¶æ§ä¸­ç£ç£å¾®èª¿ç LLM å±ç¤ºäºéç¨®æ¹æ³çåæï¼é¡¯ç¤ºåºå¨æ¸å°å¹»è¦ºåå¢å¼· QA åæä¸­çäºå¯¦æºç¢ºæ§æ¹é¢æé¡¯èçæ¹é²ãæåçç¨å¼ç¢¼åå½±çå¬éæä¾ã

##### **Link Prediction with Untrained Message Passing Layers**
2406.16687v1 by Lisi Qarkaxhija, Anatol E. Wegner, Ingo Scholtes

Message passing neural networks (MPNNs) operate on graphs by exchanging
information between neigbouring nodes. MPNNs have been successfully applied to
various node-, edge-, and graph-level tasks in areas like molecular science,
computer vision, natural language processing, and combinatorial optimization.
However, most MPNNs require training on large amounts of labeled data, which
can be costly and time-consuming. In this work, we explore the use of various
untrained message passing layers in graph neural networks, i.e. variants of
popular message passing architecture where we remove all trainable parameters
that are used to transform node features in the message passing step. Focusing
on link prediction, we find that untrained message passing layers can lead to
competitive and even superior performance compared to fully trained MPNNs,
especially in the presence of high-dimensional features. We provide a
theoretical analysis of untrained message passing by relating the inner
products of features implicitly produced by untrained message passing layers to
path-based topological node similarity measures. As such, untrained message
passing architectures can be viewed as a highly efficient and interpretable
approach to link prediction.

æè¦ï¼è¨æ¯å³éç¥ç¶ç¶²è·¯ (MPNN) ééäº¤æé°è¿ç¯é»ä¹éçè³è¨ä¾èçåå½¢ãMPNN å·²æåæç¨æ¼åç¨®ç¯é»ãéç·£ååå½¢å±¤ç´çä»»åï¼ä¾å¦åå­ç§å­¸ãé»è¦è¦è¦ºãèªç¶èªè¨èçåçµåæä½³åãç¶èï¼å¤§å¤æ¸ MPNN éè¦å¤§éæ¨ç±¤è³ææè½é²è¡è¨ç·´ï¼éå¯è½æå¾æè²´ä¸èæãå¨éé å·¥ä½ä¸­ï¼æåæ¢è¨äºå¨åå½¢ç¥ç¶ç¶²è·¯ä¸­ä½¿ç¨åç¨®æªè¨ç·´çè¨æ¯å³éå±¤ï¼ä¹å°±æ¯èªªï¼æåç§»é¤äºææç¨æ¼å¨è¨æ¯å³éæ­¥é©ä¸­è½æç¯é»ç¹å¾µçå¯è¨ç·´åæ¸ï¼éæ¯ç±éè¨æ¯å³éæ¶æ§çè®é«ãå°æ³¨æ¼é£çµé æ¸¬ï¼æåç¼ç¾æªè¨ç·´çè¨æ¯å³éå±¤å¯ä»¥ç¢çå·æç«¶ç­åï¼çè³åªæ¼å®å¨è¨ç·´ç MPNN çæè½ï¼å°¤å¶æ¯å¨å­å¨é«ç¶­ç¹å¾µçææ³ä¸ãæåééå°æªè¨ç·´çè¨æ¯å³éå±¤é±å«ç¢ççç¹å¾µçå§ç©èåºæ¼è·¯å¾çææ²ç¯é»ç¸ä¼¼åº¦æ¸¬ééè¯ï¼æä¾æªè¨ç·´è¨æ¯å³éççè«åæãå æ­¤ï¼æªè¨ç·´çè¨æ¯å³éæ¶æ§å¯ä»¥è¦çºä¸ç¨®é«åº¦ææä¸å¯è§£éçé£çµé æ¸¬æ¹æ³ã

##### **CLEAR: Can Language Models Really Understand Causal Graphs?**
2406.16605v1 by Sirui Chen, Mengying Xu, Kun Wang, Xingyu Zeng, Rui Zhao, Shengjie Zhao, Chaochao Lu

Causal reasoning is a cornerstone of how humans interpret the world. To model
and reason about causality, causal graphs offer a concise yet effective
solution. Given the impressive advancements in language models, a crucial
question arises: can they really understand causal graphs? To this end, we
pioneer an investigation into language models' understanding of causal graphs.
Specifically, we develop a framework to define causal graph understanding, by
assessing language models' behaviors through four practical criteria derived
from diverse disciplines (e.g., philosophy and psychology). We then develop
CLEAR, a novel benchmark that defines three complexity levels and encompasses
20 causal graph-based tasks across these levels. Finally, based on our
framework and benchmark, we conduct extensive experiments on six leading
language models and summarize five empirical findings. Our results indicate
that while language models demonstrate a preliminary understanding of causal
graphs, significant potential for improvement remains. Our project website is
at https://github.com/OpenCausaLab/CLEAR.

æè¦ï¼å ææ¨çæ¯äººé¡è©®éä¸ççåºç³ãçºäºå°å æéä¿å»ºæ¨¡åæ¨çï¼å æåæä¾äºä¸åç°¡æ½èææçè§£æ±ºæ¹æ¡ãéæ¼èªè¨æ¨¡åçé©äººé²æ­¥ï¼ä¸åééµåé¡åºç¾äºï¼å®åççè½çè§£å æååï¼çºæ­¤ï¼æåçåå°èªè¨æ¨¡åå°å æåççè§£é²è¡äºèª¿æ¥ãå·é«ä¾èªªï¼æåéç¼äºä¸åæ¡æ¶ä¾å®ç¾©å æåçè§£ï¼ééå¾ä¸åå­¸ç§ï¼ä¾å¦å²å­¸åå¿çå­¸ï¼è¡ççååå¯¦ç¨æ¨æºä¾è©ä¼°èªè¨æ¨¡åçè¡çºãç¶å¾ï¼æåéç¼äº CLEARï¼ä¸åæ°çåºæºï¼å®å®ç¾©äºä¸åè¤éæ§ç´å¥ï¼ä¸¦æ¶µèäºéäºç´å¥ä¸­ç 20 ååºæ¼å æåçä»»åãæå¾ï¼åºæ¼æåçæ¡æ¶ååºæºï¼æåå°å­åé åçèªè¨æ¨¡åé²è¡äºå»£æ³çå¯¦é©ï¼ä¸¦ç¸½çµäºäºé å¯¦è­ç¼ç¾ãæåççµæè¡¨æï¼åç®¡èªè¨æ¨¡åå±ç¤ºäºå°å æåçåæ­¥çè§£ï¼ä½ä»æå¾å¤§çæ¹é²æ½åãæåçé ç®ç¶²ç«ä½æ¼ https://github.com/OpenCausaLab/CLEARã

##### **KEHRL: Learning Knowledge-Enhanced Language Representations with Hierarchical Reinforcement Learning**
2406.16374v1 by Dongyang Li, Taolin Zhang, Longtao Huang, Chengyu Wang, Xiaofeng He, Hui Xue

Knowledge-enhanced pre-trained language models (KEPLMs) leverage relation
triples from knowledge graphs (KGs) and integrate these external data sources
into language models via self-supervised learning. Previous works treat
knowledge enhancement as two independent operations, i.e., knowledge injection
and knowledge integration. In this paper, we propose to learn
Knowledge-Enhanced language representations with Hierarchical Reinforcement
Learning (KEHRL), which jointly addresses the problems of detecting positions
for knowledge injection and integrating external knowledge into the model in
order to avoid injecting inaccurate or irrelevant knowledge. Specifically, a
high-level reinforcement learning (RL) agent utilizes both internal and prior
knowledge to iteratively detect essential positions in texts for knowledge
injection, which filters out less meaningful entities to avoid diverting the
knowledge learning direction. Once the entity positions are selected, a
relevant triple filtration module is triggered to perform low-level RL to
dynamically refine the triples associated with polysemic entities through
binary-valued actions. Experiments validate KEHRL's effectiveness in probing
factual knowledge and enhancing the model's performance on various natural
language understanding tasks.

æè¦ï¼ç¥è­å¢å¼·é è¨ç·´èªè¨æ¨¡å (KEPLM) å©ç¨ç¥è­åè­ (KG) ä¸­çéè¯ä¸åçµï¼ä¸¦ééèªæç£ç£å¼å­¸ç¿å°éäºå¤é¨è³æä¾æºæ´åå°èªè¨æ¨¡åä¸­ãååçç ç©¶å°ç¥è­å¢å¼·è¦çºå©åç¨ç«çæä½ï¼å³ç¥è­æ³¨å¥åç¥è­æ´åãå¨æ¬æä¸­ï¼æåå»ºè­°ä½¿ç¨åå±¤å¼·åå­¸ç¿ (KEHRL) å­¸ç¿ç¥è­å¢å¼·èªè¨è¡¨å¾µï¼éå±åè§£æ±ºäºåµæ¸¬ç¥è­æ³¨å¥ä½ç½®åå°å¤é¨ç¥è­æ´åå°æ¨¡åä¸­çåé¡ï¼ä»¥é¿åæ³¨å¥ä¸æºç¢ºæä¸ç¸éçç¥è­ãå·é«ä¾èªªï¼é«éå¼·åå­¸ç¿ (RL) ä»£çä½¿ç¨å§é¨ååé©ç¥è­ï¼åè¦åµæ¸¬æå­ä¸­ç¥è­æ³¨å¥çéè¦ä½ç½®ï¼éæéæ¿¾æè¼ä¸éè¦çå¯¦é«ï¼ä»¥é¿åè½ç§»ç¥è­å­¸ç¿æ¹åãä¸æ¦é¸å®å¯¦é«ä½ç½®ï¼å°±æè§¸ç¼ç¸éçä¸åçµéæ¿¾æ¨¡çµï¼ééäºé²å¶åä½åæç²¾çèå¤ç¾©å¯¦é«ç¸éçä¸åçµãå¯¦é©é©è­äº KEHRL å¨æ¢æ¥äºå¯¦ç¥è­åå¢å¼·æ¨¡åå¨åç¨®èªç¶èªè¨çè§£ä»»åä¸çæè½ã

##### **Prompt-Consistency Image Generation (PCIG): A Unified Framework Integrating LLMs, Knowledge Graphs, and Controllable Diffusion Models**
2406.16333v1 by Yichen Sun, Zhixuan Chu, Zhan Qin, Kui Ren

The rapid advancement of Text-to-Image(T2I) generative models has enabled the
synthesis of high-quality images guided by textual descriptions. Despite this
significant progress, these models are often susceptible in generating contents
that contradict the input text, which poses a challenge to their reliability
and practical deployment. To address this problem, we introduce a novel
diffusion-based framework to significantly enhance the alignment of generated
images with their corresponding descriptions, addressing the inconsistency
between visual output and textual input. Our framework is built upon a
comprehensive analysis of inconsistency phenomena, categorizing them based on
their manifestation in the image. Leveraging a state-of-the-art large language
module, we first extract objects and construct a knowledge graph to predict the
locations of these objects in potentially generated images. We then integrate a
state-of-the-art controllable image generation model with a visual text
generation module to generate an image that is consistent with the original
prompt, guided by the predicted object locations. Through extensive experiments
on an advanced multimodal hallucination benchmark, we demonstrate the efficacy
of our approach in accurately generating the images without the inconsistency
with the original prompt. The code can be accessed via
https://github.com/TruthAI-Lab/PCIG.

æè¦ï¼ææ¬å°å¾å (T2I) çææ¨¡åçå¿«éè¿æ­¥ä½¿å¾åæç±ææ¬æè¿°å¼å¯¼çé«è´¨éå¾åæä¸ºå¯è½ãå°½ç®¡åå¾äºè¿äºéå¤§è¿å±ï¼ä½è¿äºæ¨¡åå¨çæä¸è¾å¥ææ¬ç¸çç¾çåå®¹æ¹é¢éå¸¸å¾ææï¼è¿å¯¹å®ä»¬çå¯é æ§åå®éé¨ç½²æåºäºææãä¸ºäºè§£å³è¿ä¸ªé®é¢ï¼æä»¬å¼å¥äºä¸ä¸ªæ°é¢çåºäºæ©æ£çæ¡æ¶ï¼ä»¥æ¾çå¢å¼ºçæå¾åä¸å¶ç¸åºæè¿°çä¸è´æ§ï¼è§£å³è§è§è¾åºåææ¬è¾å¥ä¹é´çä¸ä¸è´æ§ãæä»¬çæ¡æ¶å»ºç«å¨å¯¹ä¸ä¸è´ç°è±¡çå¨é¢åæä¹ä¸ï¼æ ¹æ®å®ä»¬å¨å¾åä¸­çè¡¨ç°å¯¹å®ä»¬è¿è¡åç±»ãå©ç¨æåè¿çå¤§åè¯­è¨æ¨¡åï¼æä»¬é¦åæåå¯¹è±¡å¹¶æå»ºç¥è¯å¾è°±æ¥é¢æµè¿äºå¯¹è±¡å¨æ½å¨çæçå¾åä¸­çä½ç½®ãç¶åï¼æä»¬å°æåè¿çå¯æ§å¾åçææ¨¡åä¸è§è§ææ¬çææ¨¡åéæå¨ä¸èµ·ï¼ä»¥çæä¸åå§æç¤ºä¸è´çå¾åï¼å¹¶ç±é¢æµçå¯¹è±¡ä½ç½®å¼å¯¼ãéè¿å¨é«çº§å¤æ¨¡æå¹»è§åºåä¸è¿è¡å¹¿æ³çå®éªï¼æä»¬å±ç¤ºäºæä»¬çæ¹æ³å¨åç¡®çæå¾åæ¹é¢çæææ§ï¼èä¸ä¼ä¸åå§æç¤ºä¸ä¸è´ãå¯ä»¥éè¿ https://github.com/TruthAI-Lab/PCIG è®¿é®ä»£ç ã

##### **Graph-Augmented LLMs for Personalized Health Insights: A Case Study in Sleep Analysis**
2406.16252v2 by Ajan Subramanian, Zhongqi Yang, Iman Azimi, Amir M. Rahmani

Health monitoring systems have revolutionized modern healthcare by enabling
the continuous capture of physiological and behavioral data, essential for
preventive measures and early health intervention. While integrating this data
with Large Language Models (LLMs) has shown promise in delivering interactive
health advice, traditional methods like Retrieval-Augmented Generation (RAG)
and fine-tuning often fail to fully utilize the complex, multi-dimensional, and
temporally relevant data from wearable devices. These conventional approaches
typically provide limited actionable and personalized health insights due to
their inadequate capacity to dynamically integrate and interpret diverse health
data streams. In response, this paper introduces a graph-augmented LLM
framework designed to significantly enhance the personalization and clarity of
health insights. Utilizing a hierarchical graph structure, the framework
captures inter and intra-patient relationships, enriching LLM prompts with
dynamic feature importance scores derived from a Random Forest Model. The
effectiveness of this approach is demonstrated through a sleep analysis case
study involving 20 college students during the COVID-19 lockdown, highlighting
the potential of our model to generate actionable and personalized health
insights efficiently. We leverage another LLM to evaluate the insights for
relevance, comprehensiveness, actionability, and personalization, addressing
the critical need for models that process and interpret complex health data
effectively. Our findings show that augmenting prompts with our framework
yields significant improvements in all 4 criteria. Through our framework, we
can elicit well-crafted, more thoughtful responses tailored to a specific
patient.

æè¦ï¼å¥åº·ç£æ§ç³»çµ±ééæçºæ¶éççåè¡çºè³æï¼å¾¹åºæ¹è®äºç¾ä»£é«çä¿å¥ï¼éäºè³æå°æ¼é é²æªæ½åæ©æå¥åº·å¹²é è³ééè¦ãéç¶å°éäºè³æèå¤§åèªè¨æ¨¡å (LLM) æ´åï¼å·²å±ç¾åºæä¾äºåå¼å¥åº·å»ºè­°çæ½åï¼ä½å³çµ±æ¹æ³ï¼ä¾å¦æª¢ç´¢æ´åçæ (RAG) åå¾®èª¿ï¼éå¸¸ç¡æ³ååå©ç¨ç©¿æ´å¼è£ç½®ä¸­è¤éãå¤é¢åä¸èæéç¸éçè³æãéäºå³çµ±æ¹æ³éå¸¸ææä¾æéçå¯è¡ä¸åäººåçå¥åº·è¦è§£ï¼å çºå®åç¡æ³åææ´ååè©®éä¸åçå¥åº·è³æä¸²æµãçºäºè§£æ±ºéååé¡ï¼æ¬æä»ç´¹äºä¸ååå½¢æ´å LLM æ¶æ§ï¼æ¨å¨å¤§å¹æåå¥åº·è¦è§£çåäººååæ¸æ°åº¦ãéåæ¶æ§å©ç¨éå±¤å¼åå½¢çµæ§ï¼æ·åæ£èä¹éåæ£èå§é¨çéä¿ï¼ä¸¦ä½¿ç¨å¾ Random Forest æ¨¡åè¡ççåæç¹å¾µéè¦æ§è©åï¼è±å¯ LLM æç¤ºãééä¸é ç¡ç åææ¡ä¾ç ç©¶ï¼å¨ COVID-19 å°éæééå° 20 åå¤§å­¸çé²è¡ï¼è­æäºéåæ¹æ³çæææ§ï¼çªé¡¯äºæåçæ¨¡åå¨ææç¢çå¯è¡ä¸åäººåçå¥åº·è¦è§£æ¹é¢çæ½åãæåå©ç¨å¦ä¸å LLM è©ä¼°è¦è§£çç¸éæ§ãå¨é¢æ§ãå¯è¡æ§ååäººåï¼æ»¿è¶³äºæ¨¡åææèçåè©®éè¤éå¥åº·è³æçééµéæ±ãæåçç ç©¶çµæé¡¯ç¤ºï¼ä½¿ç¨æåçæ¶æ§æ´åæç¤ºï¼å¯ä»¥å¨ææ 4 åæ¨æºä¸­å¤§å¹æ¹åãééæåçæ¶æ§ï¼æåå¯ä»¥å¼ç¼ç²¾å¿è¨­è¨ãæ´å¨å¨çåæï¼éå°ç¹å®æ£èéèº«æé ã

##### **GraphEval2000: Benchmarking and Improving Large Language Models on Graph Datasets**
2406.16176v1 by Qiming Wu, Zichen Chen, Will Corcoran, Misha Sra, Ambuj K. Singh

Large language models (LLMs) have achieved remarkable success in natural
language processing (NLP), demonstrating significant capabilities in processing
and understanding text data. However, recent studies have identified
limitations in LLMs' ability to reason about graph-structured data. To address
this gap, we introduce GraphEval2000, the first comprehensive graph dataset,
comprising 40 graph data structure problems along with 2000 test cases.
Additionally, we introduce an evaluation framework based on GraphEval2000,
designed to assess the graph reasoning abilities of LLMs through coding
challenges. Our dataset categorizes test cases into four primary and four
sub-categories, ensuring a comprehensive evaluation. We evaluate eight popular
LLMs on GraphEval2000, revealing that LLMs exhibit a better understanding of
directed graphs compared to undirected ones. While private LLMs consistently
outperform open-source models, the performance gap is narrowing. Furthermore,
to improve the usability of our evaluation framework, we propose Structured
Symbolic Decomposition (SSD), an instruction-based method designed to enhance
LLM performance on GraphEval2000. Results show that SSD improves the
performance of GPT-3.5, GPT-4, and GPT-4o on complex graph problems, with an
increase of 11.11\%, 33.37\%, and 33.37\%, respectively.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨èªç¶èªè¨èç (NLP) ä¸­åå¾äºé¡¯èçæåï¼å¨èçåçè§£ææ¬æ¸ææ¹é¢è¡¨ç¾åºé¡¯èçè½åãç¶èï¼æè¿çç ç©¶ç¼ç¾ LLM å¨æ¨çåå½¢çµæ§æ¸æçè½åæ¹é¢å­å¨å±éæ§ãçºäºè§£æ±ºéåå·®è·ï¼æåå¼å¥äº GraphEval2000ï¼ç¬¬ä¸åå¨é¢çåå½¢æ¸æéï¼åå« 40 ååå½¢æ¸æçµæ§åé¡ä»¥å 2000 åæ¸¬è©¦ç¨ä¾ãæ­¤å¤ï¼æåéå¼å¥äºåºæ¼ GraphEval2000 çè©ä¼°æ¡æ¶ï¼æ¨å¨ééç·¨ç¢¼ææ°è©ä¼° LLM çåå½¢æ¨çè½åãæåçæ¸æéå°æ¸¬è©¦ç¨ä¾åçºååä¸»è¦é¡å¥åååå­é¡å¥ï¼ç¢ºä¿é²è¡å¨é¢çè©ä¼°ãæåå¨ GraphEval2000 ä¸è©ä¼°äºå«åæµè¡ç LLMï¼çµæè¡¨æï¼èç¡ååç¸æ¯ï¼LLM å°æååççè§£æ´å¥½ãéç¶ç§æ LLM æçºåªæ¼éæºæ¨¡åï¼ä½æ§è½å·®è·æ­£å¨ç¸®å°ãæ­¤å¤ï¼çºäºæé«æåè©ä¼°æ¡æ¶çå¯ç¨æ§ï¼æåæåºäºçµæ§åç¬¦èåè§£ (SSD)ï¼ä¸ç¨®åºæ¼æä»¤çæ¹æ³ï¼æ¨å¨å¢å¼· LLM å¨ GraphEval2000 ä¸çæ§è½ãçµæè¡¨æï¼SSD åå¥æé«äº GPT-3.5ãGPT-4 å GPT-4o å¨è¤éåå½¢åé¡ä¸çæ§è½ï¼åå¥å¢å äº 11.11%ã33.37% å 33.37%ã

##### **Can LLM Graph Reasoning Generalize beyond Pattern Memorization?**
2406.15992v1 by Yizhuo Zhang, Heng Wang, Shangbin Feng, Zhaoxuan Tan, Xiaochuang Han, Tianxing He, Yulia Tsvetkov

Large language models (LLMs) demonstrate great potential for problems with
implicit graphical structures, while recent works seek to enhance the graph
reasoning capabilities of LLMs through specialized instruction tuning. The
resulting 'graph LLMs' are evaluated with in-distribution settings only, thus
it remains underexplored whether LLMs are learning generalizable graph
reasoning skills or merely memorizing patterns in the synthetic training data.
To this end, we propose the NLGift benchmark, an evaluation suite of LLM graph
reasoning generalization: whether LLMs could go beyond semantic, numeric,
structural, reasoning patterns in the synthetic training data and improve
utility on real-world graph-based tasks. Extensive experiments with two LLMs
across four graph reasoning tasks demonstrate that while generalization on
simple patterns (semantic, numeric) is somewhat satisfactory, LLMs struggle to
generalize across reasoning and real-world patterns, casting doubt on the
benefit of synthetic graph tuning for real-world tasks with underlying network
structures. We explore three strategies to improve LLM graph reasoning
generalization, and we find that while post-training alignment is most
promising for real-world tasks, empowering LLM graph reasoning to go beyond
pattern memorization remains an open research question.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å°æ¼å·æé±å¼åå½¢çµæ§çåé¡å±ç¾åºå·¨å¤§çæ½åï¼èè¿æç ç©¶åééå°æ¥­æä»¤èª¿æ´ä¾å¢å¼· LLM çåå½¢æ¨çè½åãç±æ­¤ç¢ççãåå½¢ LLMãåå¨åå¸å§è¨­å®ä¸­é²è¡è©ä¼°ï¼å æ­¤ LLM æ¯å¦å­¸ç¿å°å¯æ¦æ¬çåå½¢æ¨çæè½ï¼æååè¨æ¶åæè¨ç·´è³æä¸­çæ¨¡å¼ï¼ä»æªç²å¾ååæ¢è¨ãçºæ­¤ï¼æåæåº NLGift åºæºï¼éæ¯ä¸å LLM åå½¢æ¨çæ¦æ¬è©ä¼°å¥ä»¶ï¼LLM æ¯å¦å¯ä»¥è¶è¶åæè¨ç·´è³æä¸­çèªç¾©ãæ¸å¼ãçµæ§æ¨çæ¨¡å¼ï¼ä¸¦æåå¨çå¯¦ä¸çåºæ¼åå½¢çä»»åä¸­çæç¨ãééå©å LLM å¨åååå½¢æ¨çä»»åä¸­çå»£æ³å¯¦é©è­æï¼åç®¡å¨ç°¡å®æ¨¡å¼ï¼èªç¾©ãæ¸å¼ï¼ä¸çæ¦æ¬ä»¤äººæ»¿æï¼ä½ LLM é£ä»¥å¨æ¨çåçå¯¦ä¸çæ¨¡å¼ä¸­æ¦æ¬ï¼å°åæåå½¢èª¿æ´å°æ¼å·æåºç¤ç¶²è·¯çµæ§ççå¯¦ä¸çä»»åççèæåºè³ªçãæåæ¢è¨äºä¸ç¨®ç­ç¥ä¾æ¹å LLM åå½¢æ¨çæ¦æ¬ï¼æåç¼ç¾ï¼åç®¡è¨ç·´å¾å°é½å°çå¯¦ä¸çä»»åææå¸æï¼ä½è³¦è½ LLM åå½¢æ¨çä»¥è¶è¶æ¨¡å¼è¨æ¶ä»ç¶æ¯ä¸åéæ¾çç ç©¶åé¡ã

##### **LLM-Powered Explanations: Unraveling Recommendations Through Subgraph Reasoning**
2406.15859v2 by Guangsi Shi, Xiaofeng Deng, Linhao Luo, Lijuan Xia, Lei Bao, Bei Ye, Fei Du, Shirui Pan, Yuxiao Li

Recommender systems are pivotal in enhancing user experiences across various
web applications by analyzing the complicated relationships between users and
items. Knowledge graphs(KGs) have been widely used to enhance the performance
of recommender systems. However, KGs are known to be noisy and incomplete,
which are hard to provide reliable explanations for recommendation results. An
explainable recommender system is crucial for the product development and
subsequent decision-making. To address these challenges, we introduce a novel
recommender that synergies Large Language Models (LLMs) and KGs to enhance the
recommendation and provide interpretable results. Specifically, we first
harness the power of LLMs to augment KG reconstruction. LLMs comprehend and
decompose user reviews into new triples that are added into KG. In this way, we
can enrich KGs with explainable paths that express user preferences. To enhance
the recommendation on augmented KGs, we introduce a novel subgraph reasoning
module that effectively measures the importance of nodes and discovers
reasoning for recommendation. Finally, these reasoning paths are fed into the
LLMs to generate interpretable explanations of the recommendation results. Our
approach significantly enhances both the effectiveness and interpretability of
recommender systems, especially in cross-selling scenarios where traditional
methods falter. The effectiveness of our approach has been rigorously tested on
four open real-world datasets, with our methods demonstrating a superior
performance over contemporary state-of-the-art techniques by an average
improvement of 12%. The application of our model in a multinational engineering
and technology company cross-selling recommendation system further underscores
its practical utility and potential to redefine recommendation practices
through improved accuracy and user trust.

æè¦ï¼æ¨è¦ç³»çµ±å¨åæä½¿ç¨èèé ç®ä¹éè¤éçéä¿ï¼æååç¨®ç¶²è·¯æç¨ç¨å¼çä½¿ç¨èé«é©ä¸­æ®æ¼èééµè§è²ãç¥è­åè­ (KG) å·²è¢«å»£æ³ç¨æ¼æåæ¨è¦ç³»çµ±çæè½ãç¶èï¼KG ç¾æå¨ç¥æ¯æéè¨ä¸ä¸å®æ´çï¼éä½¿å¾é£ä»¥æä¾å¯é çæ¨è¦çµæèªªæãä¸åå¯è§£éçæ¨è¦ç³»çµ±å°æ¼ç¢åéç¼åå¾çºæ±ºç­è³ééè¦ãçºäºæå°éäºææ°ï¼æåå¼å¥äºä¸åæ°ç©çæ¨è¦ç³»çµ±ï¼å®çµåäºå¤§åèªè¨æ¨¡å (LLM) å KG ä¾å å¼·æ¨è¦ä¸¦æä¾å¯è§£éççµæãå·é«ä¾èªªï¼æåé¦åå©ç¨ LLM çåéä¾æ´å KG éå»ºãLLM çè§£ä¸¦å°ä½¿ç¨èè©è«åè§£ææ°çä¸åçµï¼ä¸¦å°å¶æ°å¢å° KG ä¸­ãéééç¨®æ¹å¼ï¼æåå¯ä»¥ç¨è¡¨éä½¿ç¨èåå¥½çå¯è§£éè·¯å¾ä¾è±å¯ KGãçºäºå¢å¼·å¨æ´å KG ä¸çæ¨è¦ï¼æåå¼å¥äºä¸åæ°ç©çå­åæ¨çæ¨¡çµï¼å®å¯ä»¥ææå°è¡¡éç¯é»çéè¦æ§ï¼ä¸¦æ¾åºæ¨è¦ççç±ãæå¾ï¼éäºæ¨çè·¯å¾è¢«è¼¸å¥å° LLM ä¸­ï¼ä»¥ç¢çæ¨è¦çµæçå¯è§£éèªªæãæåçåæ³å¤§å¹æåäºæ¨è¦ç³»çµ±çæææ§åå¯è§£éæ§ï¼ç¹å¥æ¯å¨å³çµ±æ¹æ³å¤±æçäº¤åé·å®æå¢ä¸­ãæåçåæ³çæææ§å·²å¨ååéæ¾ççå¯¦ä¸çè³æéä¸ç¶éå´æ ¼æ¸¬è©¦ï¼æåçåæ³å±ç¤ºåºæ¯ç¶ä»£æåé²æè¡æ´åè¶çæè½ï¼å¹³åæåäº 12%ãæåçæ¨¡åå¨ä¸å®¶è·¨åå·¥ç¨åæè¡å¬å¸äº¤åé·å®æ¨è¦ç³»çµ±ä¸­çæç¨é²ä¸æ­¥çªé¡¯äºå®çå¯¦ç¨æ§ï¼ä»¥åééæåæºç¢ºæ§åä½¿ç¨èä¿¡ä»»ä¾éæ°å®ç¾©æ¨è¦å¯¦åçæ½åã

##### **Large Language Models for Link Stealing Attacks Against Graph Neural Networks**
2406.16963v1 by Faqian Guan, Tianqing Zhu, Hui Sun, Wanlei Zhou, Philip S. Yu

Graph data contains rich node features and unique edge information, which
have been applied across various domains, such as citation networks or
recommendation systems. Graph Neural Networks (GNNs) are specialized for
handling such data and have shown impressive performance in many applications.
However, GNNs may contain of sensitive information and susceptible to privacy
attacks. For example, link stealing is a type of attack in which attackers
infer whether two nodes are linked or not. Previous link stealing attacks
primarily relied on posterior probabilities from the target GNN model,
neglecting the significance of node features. Additionally, variations in node
classes across different datasets lead to different dimensions of posterior
probabilities. The handling of these varying data dimensions posed a challenge
in using a single model to effectively conduct link stealing attacks on
different datasets. To address these challenges, we introduce Large Language
Models (LLMs) to perform link stealing attacks on GNNs. LLMs can effectively
integrate textual features and exhibit strong generalizability, enabling
attacks to handle diverse data dimensions across various datasets. We design
two distinct LLM prompts to effectively combine textual features and posterior
probabilities of graph nodes. Through these designed prompts, we fine-tune the
LLM to adapt to the link stealing attack task. Furthermore, we fine-tune the
LLM using multiple datasets and enable the LLM to learn features from different
datasets simultaneously. Experimental results show that our approach
significantly enhances the performance of existing link stealing attack tasks
in both white-box and black-box scenarios. Our method can execute link stealing
attacks across different datasets using only a single model, making link
stealing attacks more applicable to real-world scenarios.

æè¦ï¼åå½¢æ¸æåå«è±å¯çç¯é»ç¹å¾µåç¨ç¹çéç·£è³è¨ï¼å·²æç¨æ¼åç¨®é åï¼ä¾å¦å¼æç¶²è·¯ææ¨è¦ç³»çµ±ãåå½¢ç¥ç¶ç¶²è·¯ (GNN) å°éç¨æ¼èçæ­¤é¡æ¸æï¼ä¸¦å¨è¨±å¤æç¨ä¸­å±ç¾åºä»¤äººå°è±¡æ·±å»çæè½ãç¶èï¼GNN å¯è½åå«ææè³è¨ï¼ä¸å®¹æåå°é±ç§æ»æãä¾å¦ï¼é£çµç«åæ¯ä¸ç¨®æ»æï¼æ»æèæ¨æ·å©åç¯é»æ¯å¦é£çµãååçé£çµç«åæ»æä¸»è¦ä¾è³´æ¼ç®æ¨ GNN æ¨¡åçå¾é©æ©çï¼å¿½ç¥ç¯é»ç¹å¾µçéè¦æ§ãæ­¤å¤ï¼ä¸åè³æéä¸­çç¯é»é¡å¥è®åå°è´å¾é©æ©ççä¸åç¶­åº¦ãèçéäºä¸åçè³æç¶­åº¦å¨ä½¿ç¨å®ä¸æ¨¡åå°ä¸åè³æéå·è¡é£çµç«åæ»æææ§æä¸é ææ°ãçºäºæå°éäºææ°ï¼æåå¼å¥äºå¤§åèªè¨æ¨¡å (LLM) ä¾å° GNN å·è¡é£çµç«åæ»æãLLM å¯ä»¥æææ´åæå­ç¹å¾µä¸¦å±ç¾å¼·å¤§çæ³åè½åï¼ä½¿æ»æè½å¤ èçä¸åè³æéä¸­çä¸åè³æç¶­åº¦ãæåè¨­è¨äºå©åä¸åç LLM æç¤ºï¼ä»¥ææçµåæå­ç¹å¾µååå½¢ç¯é»çå¾é©æ©çãéééäºè¨­è¨çæç¤ºï¼æåå¾®èª¿ LLM ä»¥é©æé£çµç«åæ»æä»»åãæ­¤å¤ï¼æåä½¿ç¨å¤åè³æéå¾®èª¿ LLMï¼ä¸¦ä½¿ LLM è½å¤ åæå¾ä¸åçè³æéä¸­å­¸ç¿ç¹å¾µãå¯¦é©çµæé¡¯ç¤ºï¼æåçåæ³é¡¯èæåäºç¾æé£çµç«åæ»æä»»åå¨ç½çåé»çå ´æ¯ä¸­çæè½ãæåçæ¨¡ååä½¿ç¨å®ä¸æ¨¡åå°±è½è·¨ä¸åè³æéå·è¡é£çµç«åæ»æï¼ä½¿é£çµç«åæ»ææ´é©ç¨æ¼å¯¦éå ´æ¯ã

##### **Inferring Pluggable Types with Machine Learning**
2406.15676v1 by Kazi Amanul Islam Siddiqui, Martin Kellogg

Pluggable type systems allow programmers to extend the type system of a
programming language to enforce semantic properties defined by the programmer.
Pluggable type systems are difficult to deploy in legacy codebases because they
require programmers to write type annotations manually. This paper investigates
how to use machine learning to infer type qualifiers automatically. We propose
a novel representation, NaP-AST, that encodes minimal dataflow hints for the
effective inference of type qualifiers. We evaluate several model architectures
for inferring type qualifiers, including Graph Transformer Network, Graph
Convolutional Network and Large Language Model. We further validated these
models by applying them to 12 open-source programs from a prior evaluation of
the NullAway pluggable typechecker, lowering warnings in all but one
unannotated project. We discovered that GTN shows the best performance, with a
recall of .89 and precision of 0.6. Furthermore, we conduct a study to estimate
the number of Java classes needed for good performance of the trained model.
For our feasibility study, performance improved around 16k classes, and
deteriorated due to overfitting around 22k classes.

æè¦ï¼å¯ææç±»åç³»ç»åè®¸ç¨åºåæ©å±ç¼ç¨è¯­è¨çç±»åç³»ç»ï¼ä»¥æ§è¡ç¨åºåå®ä¹çè¯­ä¹å±æ§ãå¯ææç±»åç³»ç»é¾ä»¥é¨ç½²å¨éçä»£ç åºä¸­ï¼å ä¸ºå®ä»¬è¦æ±ç¨åºåæå¨ç¼åç±»åæ³¨éãæ¬æç ç©¶å¦ä½ä½¿ç¨æºå¨å­¦ä¹ èªå¨æ¨æ­ç±»åéå®ç¬¦ãæä»¬æåºäºä¸ç§æ°é¢çè¡¨ç¤ºå½¢å¼ NaP-ASTï¼å®å¯¹ç±»åéå®ç¬¦çæææ¨æ­ç¼ç äºæå°çæ°æ®æµæç¤ºãæä»¬è¯ä¼°äºç¨äºæ¨æ­ç±»åéå®ç¬¦çå ç§æ¨¡åæ¶æï¼åæ¬å¾è½¬æ¢å¨ç½ç»ãå¾å·ç§¯ç½ç»åå¤§è¯­è¨æ¨¡åãæä»¬éè¿å°è¿äºæ¨¡ååºç¨äº NullAway å¯ææç±»åæ£æ¥å¨çååè¯ä¼°ä¸­ç 12 ä¸ªå¼æºç¨åºï¼è¿ä¸æ­¥éªè¯äºè¿äºæ¨¡åï¼é¤äºä¸ä¸ªæªæ³¨éçé¡¹ç®å¤ï¼éä½äºææé¡¹ç®çè­¦åãæä»¬åç° GTN è¡¨ç°æä½³ï¼å¬åçä¸º 0.89ï¼ç²¾ç¡®çä¸º 0.6ãæ­¤å¤ï¼æä»¬è¿è¡äºä¸é¡¹ç ç©¶ï¼ä»¥ä¼°è®¡è®­ç»æ¨¡åè¯å¥½æ§è½æéç Java ç±»æ°éãå¯¹äºæä»¬çå¯è¡æ§ç ç©¶ï¼æ§è½æé«äºçº¦ 16k ä¸ªç±»ï¼å¹¶ä¸ç±äºå¨ 22k ä¸ªç±»å·¦å³è¿åº¦æåèæ¶åã

##### **NLP-KG: A System for Exploratory Search of Scientific Literature in Natural Language Processing**
2406.15294v2 by Tim Schopf, Florian Matthes

Scientific literature searches are often exploratory, whereby users are not
yet familiar with a particular field or concept but are interested in learning
more about it. However, existing systems for scientific literature search are
typically tailored to keyword-based lookup searches, limiting the possibilities
for exploration. We propose NLP-KG, a feature-rich system designed to support
the exploration of research literature in unfamiliar natural language
processing (NLP) fields. In addition to a semantic search, NLP-KG allows users
to easily find survey papers that provide a quick introduction to a field of
interest. Further, a Fields of Study hierarchy graph enables users to
familiarize themselves with a field and its related areas. Finally, a chat
interface allows users to ask questions about unfamiliar concepts or specific
articles in NLP and obtain answers grounded in knowledge retrieved from
scientific publications. Our system provides users with comprehensive
exploration possibilities, supporting them in investigating the relationships
between different fields, understanding unfamiliar concepts in NLP, and finding
relevant research literature. Demo, video, and code are available at:
https://github.com/NLP-Knowledge-Graph/NLP-KG-WebApp.

æè¦ï¼ç§å­¸æç»çæå°éå¸¸æ¯æ¢ç´¢æ§çï¼ä½¿ç¨èå¯è½éä¸çææåç¹å®é åææ¦å¿µï¼ä½æèè¶£é²ä¸æ­¥äºè§£å®ãç¶èï¼ç¾æçç§å­¸æç»æå°ç³»çµ±éå¸¸å°ééå°åºæ¼ééµå­çæ¥è©¢æå°ï¼éå¶äºæ¢ç´¢çå¯è½æ§ãæåæåº NLP-KGï¼éæ¯ä¸ååè½è±å¯çç³»çµ±ï¼æ¨å¨æ¯æ´å¨ä¸çæçèªç¶èªè¨èç (NLP) é åä¸­æ¢ç´¢ç ç©¶æç»ãé¤äºèªææå°ä¹å¤ï¼NLP-KG ä½¿ç¨èå¯ä»¥è¼é¬æ¾å°æä¾å°æèè¶£é åçå¿«éä»ç´¹çç¶è¿°è«æãæ­¤å¤ï¼ç ç©¶é åéå±¤åè®ä½¿ç¨èè½å¤ çæä¸åé ååå¶ç¸éé åãæå¾ï¼èå¤©ä»é¢åè¨±ä½¿ç¨èè©¢åæéä¸çæçæ¦å¿µæ NLP ä¸­ç¹å®æç« çåé¡ï¼ä¸¦ç²å¾å¾ç§å­¸åºçç©ä¸­æ·åçç¥è­çºåºç¤çç­æ¡ãæåçç³»çµ±çºä½¿ç¨èæä¾å¨é¢çæ¢ç´¢å¯è½æ§ï¼åå©ä»åèª¿æ¥ä¸åé åä¹éçéä¿ï¼çè§£ NLP ä¸­ä¸çæçæ¦å¿µï¼ä¸¦æ¾å°ç¸éçç ç©¶æç»ãç¤ºç¯ãå½±çåç¨å¼ç¢¼å¯å¨ä»¥ä¸ç¶²ååå¾ï¼
https://github.com/NLP-Knowledge-Graph/NLP-KG-WebAppã

##### **Unsupervised Extraction of Dialogue Policies from Conversations**
2406.15214v1 by Makesh Narsimhan Sreedhar, Traian Rebedea, Christopher Parisien

Dialogue policies play a crucial role in developing task-oriented dialogue
systems, yet their development and maintenance are challenging and typically
require substantial effort from experts in dialogue modeling. While in many
situations, large amounts of conversational data are available for the task at
hand, people lack an effective solution able to extract dialogue policies from
this data. In this paper, we address this gap by first illustrating how Large
Language Models (LLMs) can be instrumental in extracting dialogue policies from
datasets, through the conversion of conversations into a unified intermediate
representation consisting of canonical forms. We then propose a novel method
for generating dialogue policies utilizing a controllable and interpretable
graph-based methodology. By combining canonical forms across conversations into
a flow network, we find that running graph traversal algorithms helps in
extracting dialogue flows. These flows are a better representation of the
underlying interactions than flows extracted by prompting LLMs. Our technique
focuses on giving conversation designers greater control, offering a
productivity tool to improve the process of developing dialogue policies.

æè¦ï¼å°è©±æ¿ç­å¨éç¼ä»»åå°åå°è©±ç³»çµ±ä¸­æ®æ¼èè³ééè¦çè§è²ï¼ç¶èå®åçéç¼åç¶­è­·å·æææ°æ§ï¼ä¸éå¸¸éè¦å°è©±å»ºæ¨¡å°å®¶çå¤§éå·¥ä½ãéç¶å¨è¨±å¤ææ³ä¸ï¼å¤§éå°è©±è³æå¯ç¨æ¼æéçå·¥ä½ï¼ä½äººåç¼ºä¹ä¸ç¨®ææçè§£æ±ºæ¹æ¡ï¼ç¡æ³å¾éäºè³æä¸­æåå°è©±æ¿ç­ãå¨æ¬æä¸­ï¼æåééé¦åèªªæå¤§åèªè¨æ¨¡å (LLM) å¦ä½ééå°å°è©±è½ææç±è¦ç¯å½¢å¼çµæççµ±ä¸ä¸­éè¡¨ç¤ºï¼å¾è³æéä¸­æåå°è©±æ¿ç­ï¼ä¾èªªæå¦ä½è§£æ±ºéåå·®è·ãç¶å¾ï¼æåæåºäºä¸ç¨®å©ç¨å¯æ§ä¸å¯è§£éçåºæ¼åå½¢çæ¹æ³ä¾ç¢çå°è©±æ¿ç­çæ°æ¹æ³ãééå°å°è©±ä¸­çè¦ç¯å½¢å¼çµåææµç¶²è·¯ï¼æåç¼ç¾å·è¡åå½¢éæ­·æ¼ç®æ³æå©æ¼æåå°è©±æµãéäºæµæ¯ééæç¤º LLM æåçæµæ´è½ä»£è¡¨åºå±¤äºåãæåçæè¡å°æ³¨æ¼è®å°è©±è¨­è¨å¸«æææ´å¤§çæ§å¶æ¬ï¼æä¾ä¸ç¨®çç¢åå·¥å·ä¾æ¹åéç¼å°è©±æ¿ç­çéç¨ã

##### **Uni-Mol2: Exploring Molecular Pretraining Model at Scale**
2406.14969v2 by Xiaohong Ji, Zhen Wang, Zhifeng Gao, Hang Zheng, Linfeng Zhang, Guolin Ke, Weinan E

In recent years, pretraining models have made significant advancements in the
fields of natural language processing (NLP), computer vision (CV), and life
sciences. The significant advancements in NLP and CV are predominantly driven
by the expansion of model parameters and data size, a phenomenon now recognized
as the scaling laws. However, research exploring scaling law in molecular
pretraining models remains unexplored. In this work, we present Uni-Mol2 , an
innovative molecular pretraining model that leverages a two-track transformer
to effectively integrate features at the atomic level, graph level, and
geometry structure level. Along with this, we systematically investigate the
scaling law within molecular pretraining models, characterizing the power-law
correlations between validation loss and model size, dataset size, and
computational resources. Consequently, we successfully scale Uni-Mol2 to 1.1
billion parameters through pretraining on 800 million conformations, making it
the largest molecular pretraining model to date. Extensive experiments show
consistent improvement in the downstream tasks as the model size grows. The
Uni-Mol2 with 1.1B parameters also outperforms existing methods, achieving an
average 27% improvement on the QM9 and 14% on COMPAS-1D dataset.

æè¦ï¼è¿å¹´æ¥ï¼é¢è®­ç»æ¨¡åå¨èªç¶è¯­è¨å¤ç (NLP)ãè®¡ç®æºè§è§ (CV) åçå½ç§å­¦é¢ååå¾äºéå¤§è¿å±ãNLP å CV çéå¤§è¿æ­¥ä¸»è¦ç±æ¨¡ååæ°åæ°æ®éçæ©å±æ¨å¨ï¼è¿ä¸ç°è±¡ç°å¨è¢«è®¤ä¸ºæ¯ç¼©æ¾å®å¾ãç¶èï¼æ¢ç´¢åå­é¢è®­ç»æ¨¡åä¸­ç¼©æ¾å®å¾çç ç©¶ä»æªå¾å°æ¢ç´¢ãå¨è¿é¡¹å·¥ä½ä¸­ï¼æä»¬æåºäº Uni-Mol2ï¼ä¸ç§åæ°çåå­é¢è®­ç»æ¨¡åï¼å®å©ç¨åè½¨è½¬æ¢å¨ææå°æ´ååå­çº§ãå¾çº§åå ä½ç»æçº§çç¹å¾ãé¤æ­¤ä¹å¤ï¼æä»¬ç³»ç»å°ç ç©¶äºåå­é¢è®­ç»æ¨¡åä¸­çç¼©æ¾å®å¾ï¼æè¿°äºéªè¯æå¤±ä¸æ¨¡åå¤§å°ãæ°æ®éå¤§å°åè®¡ç®èµæºä¹é´çå¹å¾ç¸å³æ§ãå æ­¤ï¼æä»¬æåå°å° Uni-Mol2 æ©å±å° 11 äº¿ä¸ªåæ°ï¼éè¿å¯¹ 8 äº¿ä¸ªæè±¡è¿è¡é¢è®­ç»ï¼ä½¿å¶æä¸ºè¿ä»ä¸ºæ­¢æå¤§çåå­é¢è®­ç»æ¨¡åãå¤§éçå®éªè¡¨æï¼éçæ¨¡åå¤§å°çå¢é¿ï¼ä¸æ¸¸ä»»å¡æç»­å¾å°æ¹åãå·æ 1.1B åæ°ç Uni-Mol2 ä¹ä¼äºç°ææ¹æ³ï¼å¨ QM9 ä¸å®ç°äºå¹³å 27% çæ¹è¿ï¼å¨ COMPAS-1D æ°æ®éä¸å®ç°äº 14% çæ¹è¿ã

##### **Relation Extraction with Fine-Tuned Large Language Models in Retrieval Augmented Generation Frameworks**
2406.14745v2 by Sefika Efeoglu, Adrian Paschke

Information Extraction (IE) is crucial for converting unstructured data into
structured formats like Knowledge Graphs (KGs). A key task within IE is
Relation Extraction (RE), which identifies relationships between entities in
text. Various RE methods exist, including supervised, unsupervised, weakly
supervised, and rule-based approaches. Recent studies leveraging pre-trained
language models (PLMs) have shown significant success in this area. In the
current era dominated by Large Language Models (LLMs), fine-tuning these models
can overcome limitations associated with zero-shot LLM prompting-based RE
methods, especially regarding domain adaptation challenges and identifying
implicit relations between entities in sentences. These implicit relations,
which cannot be easily extracted from a sentence's dependency tree, require
logical inference for accurate identification. This work explores the
performance of fine-tuned LLMs and their integration into the Retrieval
Augmented-based (RAG) RE approach to address the challenges of identifying
implicit relations at the sentence level, particularly when LLMs act as
generators within the RAG framework. Empirical evaluations on the TACRED,
TACRED-Revisited (TACREV), Re-TACRED, and SemEVAL datasets show significant
performance improvements with fine-tuned LLMs, including Llama2-7B, Mistral-7B,
and T5 (Large). Notably, our approach achieves substantial gains on SemEVAL,
where implicit relations are common, surpassing previous results on this
dataset. Additionally, our method outperforms previous works on TACRED, TACREV,
and Re-TACRED, demonstrating exceptional performance across diverse evaluation
scenarios.

æè¦ï¼è³è¨èåï¼IEï¼å°æ¼å°éçµæ§åè³æè½ææç¥è­åè­ï¼KGï¼ç­çµæ§åæ ¼å¼è³ééè¦ãIE ä¸­çä¸é ééµä»»åæ¯éä¿èåï¼REï¼ï¼ç¨æ¼è­å¥æå­ä¸­å¯¦é«ä¹éçéä¿ãRE æ¹æ³å¤ç¨®å¤æ¨£ï¼åæ¬ç£ç£å¼ãéç£ç£å¼ãå¼±ç£ç£å¼ååºæ¼è¦åçæ¹æ³ãæè¿å©ç¨é è¨ç·´èªè¨æ¨¡åï¼PLMï¼çç ç©¶å·²å¨æ­¤é åå±ç¾é¡¯èææãå¨å¤§åèªè¨æ¨¡åï¼LLMï¼ä¸»å°çç¶åæä»£ï¼å¾®èª¿éäºæ¨¡åå¯ä»¥åæèé¶æ¬¡å­¸ç¿ LLM æç¤ºå¼ RE æ¹æ³ç¸éçéå¶ï¼ç¹å¥æ¯å¨é åé©æææ°åè­å¥å¥å­ä¸­å¯¦é«ä¹éçé±å«éä¿æ¹é¢ãéäºé±å«éä¿ç¡æ³è¼æå¾å¥å­çä¾è³´æ¨¹ä¸­èåï¼éè¦éè¼¯æ¨è«æè½æºç¢ºè­å¥ãéé å·¥ä½æ¢è¨äºå¾®èª¿å¾ç LLM çæè½ï¼ä»¥åå®åæ´åå°æª¢ç´¢å¢å¼·å¼ï¼RAGï¼RE æ¹æ³ä¸­ä»¥è§£æ±ºå¨å¥å­å±¤ç´è­å¥é±å«éä¿çææ°ï¼ç¹å¥æ¯å¨ LLM å¨ RAG æ¡æ¶ä¸­åç¶çæå¨çæå¾ãå¨ TACREDãTACRED-Revisitedï¼TACREVï¼ãRe-TACRED å SemEVAL è³æéä¸çç¶é©è©ä¼°é¡¯ç¤ºï¼å¾®èª¿å¾ç LLMï¼åæ¬ Llama2-7BãMistral-7B å T5ï¼å¤§åï¼ï¼å¤§å¹æåäºæè½ãå¼å¾æ³¨æçæ¯ï¼æåçåæ³å¨ SemEVAL ä¸åå¾äºé¡¯èçé²å±ï¼å çºé±å«éä¿å¾å¸¸è¦ï¼è¶è¶äºéåè³æéä¸çååçµæãæ­¤å¤ï¼æåçåæ³å¨ TACREDãTACREV å Re-TACRED ä¸åªæ¼ååçå·¥ä½ï¼è­æäºå¨ä¸åçè©ä¼°å ´æ¯ä¸­è¡¨ç¾åºè²çæè½ã

##### **Do LLMs Have Distinct and Consistent Personality? TRAIT: Personality Testset designed for LLMs with Psychometrics**
2406.14703v1 by Seungbeen Lee, Seungwon Lim, Seungju Han, Giyeong Oh, Hyungjoo Chae, Jiwan Chung, Minju Kim, Beong-woo Kwak, Yeonsoo Lee, Dongha Lee, Jinyoung Yeo, Youngjae Yu

The idea of personality in descriptive psychology, traditionally defined
through observable behavior, has now been extended to Large Language Models
(LLMs) to better understand their behavior. This raises a question: do LLMs
exhibit distinct and consistent personality traits, similar to humans? Existing
self-assessment personality tests, while applicable, lack the necessary
validity and reliability for precise personality measurements. To address this,
we introduce TRAIT, a new tool consisting of 8K multi-choice questions designed
to assess the personality of LLMs with validity and reliability. TRAIT is built
on the psychometrically validated human questionnaire, Big Five Inventory (BFI)
and Short Dark Triad (SD-3), enhanced with the ATOMIC10X knowledge graph for
testing personality in a variety of real scenarios. TRAIT overcomes the
reliability and validity issues when measuring personality of LLM with
self-assessment, showing the highest scores across three metrics: refusal rate,
prompt sensitivity, and option order sensitivity. It reveals notable insights
into personality of LLM: 1) LLMs exhibit distinct and consistent personality,
which is highly influenced by their training data (i.e., data used for
alignment tuning), and 2) current prompting techniques have limited
effectiveness in eliciting certain traits, such as high psychopathy or low
conscientiousness, suggesting the need for further research in this direction.

æè¦ï¼å¨å³çµ±å¿çå­¸ä¸­ï¼äººæ ¼çæ¦å¿µæ¯ééå¯è§å¯çè¡çºä¾å®ç¾©çï¼ç¾å¨å·²æ´å±å°å¤§åèªè¨æ¨¡å (LLM)ï¼ä»¥æ´äºè§£å¶è¡çºãéå¼ç¼äºä¸ååé¡ï¼LLM æ¯å¦åäººé¡ä¸æ¨£è¡¨ç¾åºç¨ç¹ä¸ä¸è´çäººæ ¼ç¹è³ªï¼ç¾æçèªæè©éäººæ ¼æ¸¬é©éç¶é©ç¨ï¼ä½ç¼ºä¹ç²¾ç¢ºäººæ ¼æ¸¬éæéçæåº¦åä¿¡åº¦ãçºäºè§£æ±ºéååé¡ï¼æåå¼å¥äº TRAITï¼éæ¯ä¸åç± 8K åå¤éé¸æé¡çµæçå¨æ°å·¥å·ï¼æ¨å¨è©ä¼° LLM çäººæ ¼ï¼ä¸¦å·åæåº¦åä¿¡åº¦ãTRAIT å»ºæ§æ¼ç¶éå¿çæ¸¬éé©è­çäººé¡åå·ï¼å¤§äºäººæ ¼éè¡¨ (BFI) åç°¡ç­é»æä¸åçµ (SD-3)ï¼ä¸¦å¢å¼·äº ATOMIC10X ç¥è­åè­ï¼ä»¥ä¾¿å¨åç¨®å¯¦éå ´æ¯ä¸­æ¸¬è©¦äººæ ¼ãTRAIT åæäºä½¿ç¨èªæè©éæ¸¬é LLM äººæ ¼æçä¿¡åº¦åæåº¦åé¡ï¼å¨ä¸é ææ¨ï¼æçµçãæç¤ºææåº¦åé¸é é åºææåº¦ï¼ä¸­é¡¯ç¤ºåºæé«åãå®æ­ç¤ºäº LLM äººæ ¼çéè¦è¦è§£ï¼1) LLM è¡¨ç¾åºç¨ç¹ä¸ä¸è´çäººæ ¼ï¼éæ·±åå¶è¨ç·´è³æï¼å³ç¨æ¼å°é½èª¿æ´çè³æï¼å½±é¿ï¼ä»¥å 2) ç®åçæç¤ºæè¡å¨å¼ç¼æäºç¹è³ªï¼ä¾å¦é«ç²¾ç¥çè³ªæä½ç¡è²¬æ§ï¼æ¹é¢æææéï¼éè¡¨ç¤ºéè¦é²ä¸æ­¥ç ç©¶éåæ¹åã


### Medical
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-07-25**|**Self-supervised pre-training with diffusion model for few-shot landmark detection in x-ray images**|Roberto Di Via et.al.|[2407.18125v1](http://arxiv.org/abs/2407.18125v1)|null|
|**2024-07-25**|**Multi-Resolution Histopathology Patch Graphs for Ovarian Cancer Subtyping**|Jack Breen et.al.|[2407.18105v1](http://arxiv.org/abs/2407.18105v1)|null|
|**2024-07-25**|**HG-PIPE: Vision Transformer Acceleration with Hybrid-Grained Pipeline**|Qingyu Guo et.al.|[2407.17879v1](http://arxiv.org/abs/2407.17879v1)|null|
|**2024-07-25**|**EEG-SSM: Leveraging State-Space Model for Dementia Detection**|Xuan-The Tran et.al.|[2407.17801v1](http://arxiv.org/abs/2407.17801v1)|null|
|**2024-07-25**|**Mpox Detection Advanced: Rapid Epidemic Response Through Synthetic Data**|Yudara Kularathne et.al.|[2407.17762v1](http://arxiv.org/abs/2407.17762v1)|null|
|**2024-07-25**|**Cost-effective Instruction Learning for Pathology Vision and Language Analysis**|Kaitao Chen et.al.|[2407.17734v1](http://arxiv.org/abs/2407.17734v1)|[link](https://github.com/jlinekai/clover)|
|**2024-07-24**|**Enhanced Deep Learning Methodologies and MRI Selection Techniques for Dementia Diagnosis in the Elderly Population**|Nikolaos Ntampakis et.al.|[2407.17324v2](http://arxiv.org/abs/2407.17324v2)|null|
|**2024-07-24**|**Improving ICD coding using Chapter based Named Entities and Attentional Models**|Abhijith R. Beeravolu et.al.|[2407.17230v1](http://arxiv.org/abs/2407.17230v1)|null|
|**2024-07-24**|**Robust Deep Hawkes Process under Label Noise of Both Event and Occurrence**|Xiaoyu Tan et.al.|[2407.17164v1](http://arxiv.org/abs/2407.17164v1)|null|
|**2024-07-24**|**SDoH-GPT: Using Large Language Models to Extract Social Determinants of Health (SDoH)**|Bernardo Consoli et.al.|[2407.17126v1](http://arxiv.org/abs/2407.17126v1)|null|
|**2024-07-24**|**SepsisLab: Early Sepsis Prediction with Uncertainty Quantification and Active Sensing**|Changchang Yin et.al.|[2407.16999v1](http://arxiv.org/abs/2407.16999v1)|[link](https://github.com/yinchangchang/sepsislab)|
|**2024-07-24**|**Toward an Integrated Decision Making Framework for Optimized Stroke Diagnosis with DSA and Treatment under Uncertainty**|Nur Ahmad Khatim et.al.|[2407.16962v1](http://arxiv.org/abs/2407.16962v1)|[link](https://github.com/inteligensi/dsapomdps.jl)|
|**2024-07-23**|**AI-Enhanced 7-Point Checklist for Melanoma Detection Using Clinical Knowledge Graphs and Data-Driven Quantification**|Yuheng Wang et.al.|[2407.16822v1](http://arxiv.org/abs/2407.16822v1)|[link](https://github.com/ryan315/7pgd)|
|**2024-07-23**|**Multimodal Machine Learning in Mental Health: A Survey of Data, Algorithms, and Challenges**|Zahraa Al Sahili et.al.|[2407.16804v1](http://arxiv.org/abs/2407.16804v1)|null|
|**2024-07-23**|**Deep Bayesian segmentation for colon polyps: Well-calibrated predictions in medical imaging**|Daniela L. Ramos et.al.|[2407.16608v1](http://arxiv.org/abs/2407.16608v1)|null|
|**2024-07-23**|**A Comparative Study on Patient Language across Therapeutic Domains for Effective Patient Voice Classification in Online Health Discussions**|Giorgos Lysandrou et.al.|[2407.16593v1](http://arxiv.org/abs/2407.16593v1)|null|
|**2024-07-23**|**Virtue Ethics For Ethically Tunable Robotic Assistants**|Rajitha Ramanayake et.al.|[2407.16361v1](http://arxiv.org/abs/2407.16361v1)|null|
|**2024-07-23**|**PhenoFlow: A Human-LLM Driven Visual Analytics System for Exploring Large and Complex Stroke Datasets**|Jaeyoung Kim et.al.|[2407.16329v1](http://arxiv.org/abs/2407.16329v1)|null|
|**2024-07-23**|**Research on Adverse Drug Reaction Prediction Model Combining Knowledge Graph Embedding and Deep Learning**|Yufeng Li et.al.|[2407.16715v1](http://arxiv.org/abs/2407.16715v1)|null|
|**2024-07-22**|**Artificial Intelligence-based Decision Support Systems for Precision and Digital Health**|Nina Deliu et.al.|[2407.16062v1](http://arxiv.org/abs/2407.16062v1)|null|
|**2024-07-22**|**GFE-Mamba: Mamba-based AD Multi-modal Progression Assessment via Generative Feature Extraction from MCI**|Zhaojie Fang et.al.|[2407.15719v1](http://arxiv.org/abs/2407.15719v1)|[link](https://github.com/tinysqua/gfe-mamba)|
|**2024-07-22**|**Synthetic Image Learning: Preserving Performance and Preventing Membership Inference Attacks**|Eugenio Lomurno et.al.|[2407.15526v1](http://arxiv.org/abs/2407.15526v1)|null|
|**2024-07-22**|**A Multimodal Knowledge-enhanced Whole-slide Pathology Foundation Model**|Yingxue Xu et.al.|[2407.15362v1](http://arxiv.org/abs/2407.15362v1)|null|
|**2024-07-21**|**Genetic Algorithm to Optimize Design of Micro-Surgical Scissors**|Fatemeh Norouziani et.al.|[2407.15243v1](http://arxiv.org/abs/2407.15243v1)|null|
|**2024-07-21**|**MedSAGa: Few-shot Memory Efficient Medical Image Segmentation using Gradient Low-Rank Projection in SAM**|Navyansh Mahla et.al.|[2407.15042v1](http://arxiv.org/abs/2407.15042v1)|null|
|**2024-07-20**|**Preictal Period Optimization for Deep Learning-Based Epileptic Seizure Prediction**|Petros Koutsouvelis et.al.|[2407.14876v1](http://arxiv.org/abs/2407.14876v1)|null|
|**2024-07-20**|**PASSION: Towards Effective Incomplete Multi-Modal Medical Image Segmentation with Imbalanced Missing Rates**|Junjie Shi et.al.|[2407.14796v1](http://arxiv.org/abs/2407.14796v1)|[link](https://github.com/jun-jie-shi/passion)|
|**2024-07-19**|**Improving Representation of High-frequency Components for Medical Foundation Models**|Yuetan Chu et.al.|[2407.14651v1](http://arxiv.org/abs/2407.14651v1)|null|
|**2024-07-19**|**CVE-LLM : Automatic vulnerability evaluation in medical device industry using large language models**|Rikhiya Ghosh et.al.|[2407.14640v1](http://arxiv.org/abs/2407.14640v1)|null|
|**2024-07-19**|**Two new feature selection methods based on learn-heuristic techniques for breast cancer prediction: A comprehensive analysis**|Kamyab Karimi et.al.|[2407.14631v1](http://arxiv.org/abs/2407.14631v1)|null|
|**2024-07-19**|**Panoptic Segmentation of Mammograms with Text-To-Image Diffusion Model**|Kun Zhao et.al.|[2407.14326v1](http://arxiv.org/abs/2407.14326v1)|null|
|**2024-07-19**|**Fair Overlap Number of Balls (Fair-ONB): A Data-Morphology-based Undersampling Method for Bias Reduction**|JosÃ© Daniel Pascual-Triana et.al.|[2407.14210v1](http://arxiv.org/abs/2407.14210v1)|null|
|**2024-07-19**|**Domain-Specific Pretraining of Language Models: A Comparative Study in the Medical Field**|Tobias Kerner et.al.|[2407.14076v1](http://arxiv.org/abs/2407.14076v1)|null|
|**2024-07-19**|**HeCiX: Integrating Knowledge Graphs and Large Language Models for Biomedical Research**|Prerana Sanjay Kulkarni et.al.|[2407.14030v1](http://arxiv.org/abs/2407.14030v1)|null|
|**2024-07-18**|**DuoFormer: Leveraging Hierarchical Visual Representations by Local and Global Attention**|Xiaoya Tang et.al.|[2407.13920v1](http://arxiv.org/abs/2407.13920v1)|null|
|**2024-07-18**|**Data-Algorithm-Architecture Co-Optimization for Fair Neural Networks on Skin Lesion Dataset**|Yi Sheng et.al.|[2407.13896v1](http://arxiv.org/abs/2407.13896v1)|null|
|**2024-07-18**|**APS-USCT: Ultrasound Computed Tomography on Sparse Data via AI-Physic Synergy**|Yi Sheng et.al.|[2407.14564v1](http://arxiv.org/abs/2407.14564v1)|null|
|**2024-07-18**|**Addressing Imbalance for Class Incremental Learning in Medical Image Classification**|Xuze Hao et.al.|[2407.13768v1](http://arxiv.org/abs/2407.13768v1)|null|
|**2024-07-18**|**Shaded Route Planning Using Active Segmentation and Identification of Satellite Images**|Longchao Da et.al.|[2407.13689v1](http://arxiv.org/abs/2407.13689v1)|null|
|**2024-07-18**|**A Comparative Study on Automatic Coding of Medical Letters with Explainability**|Jamie Glen et.al.|[2407.13638v1](http://arxiv.org/abs/2407.13638v1)|[link](https://github.com/Glenj01/Medical-Coding)|
|**2024-07-18**|**A review of handcrafted and deep radiomics in neurological diseases: transitioning from oncology to clinical neuroimaging**|Elizaveta Lavrova et.al.|[2407.13813v1](http://arxiv.org/abs/2407.13813v1)|null|
|**2024-07-18**|**End-To-End Clinical Trial Matching with Large Language Models**|Dyke Ferber et.al.|[2407.13463v1](http://arxiv.org/abs/2407.13463v1)|null|
|**2024-07-18**|**CoD, Towards an Interpretable Medical Agent using Chain of Diagnosis**|Junying Chen et.al.|[2407.13301v1](http://arxiv.org/abs/2407.13301v1)|null|
|**2024-07-18**|**NODER: Image Sequence Regression Based on Neural Ordinary Differential Equations**|Hao Bai et.al.|[2407.13241v1](http://arxiv.org/abs/2407.13241v1)|null|
|**2024-07-17**|**Enhancing the Utility of Privacy-Preserving Cancer Classification using Synthetic Data**|Richard Osuala et.al.|[2407.12669v1](http://arxiv.org/abs/2407.12669v1)|null|
|**2024-07-17**|**Abstraction Alignment: Comparing Model and Human Conceptual Relationships**|Angie Boggust et.al.|[2407.12543v1](http://arxiv.org/abs/2407.12543v1)|[link](https://github.com/mitvis/abstraction-alignment)|
|**2024-07-17**|**Maintenance Strategies for Sewer Pipes with Multi-State Degradation and Deep Reinforcement Learning**|Lisandro A. Jimenez-Roa et.al.|[2407.12894v1](http://arxiv.org/abs/2407.12894v1)|null|
|**2024-07-17**|**Search Engines, LLMs or Both? Evaluating Information Seeking Strategies for Answering Health Questions**|Marcos FernÃ¡ndez-Pichel et.al.|[2407.12468v2](http://arxiv.org/abs/2407.12468v2)|null|
|**2024-07-17**|**Explainable Biomedical Hypothesis Generation via Retrieval Augmented Generation enabled Large Language Models**|Alexander R. Pelletier et.al.|[2407.12888v1](http://arxiv.org/abs/2407.12888v1)|[link](https://github.com/pinglab-utils/rugged)|
|**2024-07-17**|**Evaluating graph-based explanations for AI-based recommender systems**|Simon Delarue et.al.|[2407.12357v1](http://arxiv.org/abs/2407.12357v1)|null|
|**2024-07-16**|**GPT-4V Cannot Generate Radiology Reports Yet**|Yuyang Jiang et.al.|[2407.12176v1](http://arxiv.org/abs/2407.12176v1)|[link](https://github.com/yuyangj0/gpt-4v-evaluation-radiology-report)|
|**2024-07-16**|**LLMs-in-the-loop Part-1: Expert Small AI Models for Bio-Medical Text Translation**|Bunyamin Keles et.al.|[2407.12126v1](http://arxiv.org/abs/2407.12126v1)|null|
|**2024-07-16**|**Schema Matching with Large Language Models: an Experimental Study**|Marcel Parciak et.al.|[2407.11852v1](http://arxiv.org/abs/2407.11852v1)|[link](https://github.com/uhasselt-dsi-data-systems-lab/code-schema-matching-llms-artefacs)|
|**2024-07-16**|**GPT Assisted Annotation of Rhetorical and Linguistic Features for Interpretable Propaganda Technique Detection in News Text**|Kyle Hamilton et.al.|[2407.11827v1](http://arxiv.org/abs/2407.11827v1)|null|
|**2024-07-16**|**Characterizing and Understanding HGNN Training on GPUs**|Dengke Han et.al.|[2407.11790v2](http://arxiv.org/abs/2407.11790v2)|null|
|**2024-07-16**|**CCoE: A Compact LLM with Collaboration of Experts**|Shaomang Huang et.al.|[2407.11686v3](http://arxiv.org/abs/2407.11686v3)|null|
|**2024-07-16**|**CCVA-FL: Cross-Client Variations Adaptive Federated Learning for Medical Imaging**|Sunny Gupta et.al.|[2407.11652v2](http://arxiv.org/abs/2407.11652v2)|null|
|**2024-07-16**|**Improving Engagement and Efficacy of mHealth Micro-Interventions for Stress Coping: an In-The-Wild Study**|Chaya Ben Yehuda et.al.|[2407.11612v1](http://arxiv.org/abs/2407.11612v1)|null|
|**2024-07-16**|**DiNO-Diffusion. Scaling Medical Diffusion via Self-Supervised Pre-Training**|Guillermo Jimenez-Perez et.al.|[2407.11594v1](http://arxiv.org/abs/2407.11594v1)|null|
|**2024-07-16**|**Probing the Efficacy of Federated Parameter-Efficient Fine-Tuning of Vision Transformers for Medical Image Classification**|Naif Alkhunaizi et.al.|[2407.11573v1](http://arxiv.org/abs/2407.11573v1)|null|
|**2024-07-16**|**Fine-Tuning Medical Language Models for Enhanced Long-Contextual Understanding and Domain Expertise**|Qimin Yang et.al.|[2407.11536v1](http://arxiv.org/abs/2407.11536v1)|null|
|**2024-07-16**|**Cross-Phase Mutual Learning Framework for Pulmonary Embolism Identification on Non-Contrast CT Scans**|Bizhe Bai et.al.|[2407.11529v1](http://arxiv.org/abs/2407.11529v1)|null|
|**2024-07-16**|**Multi-Channel Masked Autoencoder and Comprehensive Evaluations for Reconstructing 12-Lead ECG from Arbitrary Single-Lead ECG**|Jiarong Chen et.al.|[2407.11481v1](http://arxiv.org/abs/2407.11481v1)|[link](https://github.com/chenjiar3/mcma)|
|**2024-07-16**|**TM-PATHVQA:90000+ Textless Multilingual Questions for Medical Visual Question Answering**|Tonmoy Rajkhowa et.al.|[2407.11383v1](http://arxiv.org/abs/2407.11383v1)|null|
|**2024-07-16**|**Performance Evaluation of Lightweight Open-source Large Language Models in Pediatric Consultations: A Comparative Analysis**|Qiuhong Wei et.al.|[2407.15862v1](http://arxiv.org/abs/2407.15862v1)|null|
|**2024-07-15**|**Leveraging Multimodal CycleGAN for the Generation of Anatomically Accurate Synthetic CT Scans from MRIs**|Leonardo Crespi et.al.|[2407.10888v1](http://arxiv.org/abs/2407.10888v1)|null|
|**2024-07-15**|**Towards Enhanced Classification of Abnormal Lung sound in Multi-breath: A Light Weight Multi-label and Multi-head Attention Classification Method**|Yi-Wei Chua et.al.|[2407.10828v1](http://arxiv.org/abs/2407.10828v1)|null|
|**2024-07-15**|**Classification of Heart Sounds Using Multi-Branch Deep Convolutional Network and LSTM-CNN**|Seyed Amir Latifi et.al.|[2407.10689v1](http://arxiv.org/abs/2407.10689v1)|null|
|**2024-07-15**|**Spatio-temporal neural distance fields for conditional generative modeling of the heart**|Kristine SÃ¸rensen et.al.|[2407.10663v1](http://arxiv.org/abs/2407.10663v1)|[link](https://github.com/kristineaajuhl/spatio_temporal_generative_cardiac_model)|
|**2024-07-15**|**TCM-FTP: Fine-Tuning Large Language Models for Herbal Prescription Prediction**|Xingzhi Zhou et.al.|[2407.10510v1](http://arxiv.org/abs/2407.10510v1)|null|
|**2024-07-15**|**A Multi-Stage Framework for 3D Individual Tooth Segmentation in Dental CBCT**|Chunshi Wang et.al.|[2407.10433v1](http://arxiv.org/abs/2407.10433v1)|null|
|**2024-07-15**|**Static and multivariate-temporal attentive fusion transformer for readmission risk prediction**|Zhe Sun et.al.|[2407.11096v1](http://arxiv.org/abs/2407.11096v1)|null|
|**2024-07-14**|**Evolved Developmental Artificial Neural Networks for Multitasking with Advanced Activity Dependence**|Yintong Zhang et.al.|[2407.10359v1](http://arxiv.org/abs/2407.10359v1)|null|
|**2024-07-14**|**Learning Unlabeled Clients Divergence via Anchor Model Aggregation for Federated Semi-supervised Learning**|Marawan Elbatel et.al.|[2407.10327v1](http://arxiv.org/abs/2407.10327v1)|null|
|**2024-07-14**|**Rapid Biomedical Research Classification: The Pandemic PACT Advanced Categorisation Engine**|Omid Rohanian et.al.|[2407.10086v2](http://arxiv.org/abs/2407.10086v2)|null|
|**2024-07-13**|**Document-level Clinical Entity and Relation Extraction via Knowledge Base-Guided Generation**|Kriti Bhattarai et.al.|[2407.10021v1](http://arxiv.org/abs/2407.10021v1)|null|
|**2024-07-13**|**Causality extraction from medical text using Large Language Models (LLMs)**|Seethalakshmi Gopalakrishnan et.al.|[2407.10020v1](http://arxiv.org/abs/2407.10020v1)|null|
|**2024-07-13**|**Pay Less On Clinical Images: Asymmetric Multi-Modal Fusion Method For Efficient Multi-Label Skin Lesion Classification**|Peng Tang et.al.|[2407.09999v1](http://arxiv.org/abs/2407.09999v1)|null|
|**2024-07-13**|**Evaluating the Impact of Different Quantum Kernels on the Classification Performance of Support Vector Machine Algorithm: A Medical Dataset Application**|Emine Akpinar et.al.|[2407.09930v2](http://arxiv.org/abs/2407.09930v2)|null|
|**2024-07-13**|**Enhancing Semantic Segmentation with Adaptive Focal Loss: A Novel Approach**|Md Rakibul Islam et.al.|[2407.09828v1](http://arxiv.org/abs/2407.09828v1)|null|
|**2024-07-12**|**Towards Personalised Patient Risk Prediction Using Temporal Hospital Data Trajectories**|Thea Barnes et.al.|[2407.09373v1](http://arxiv.org/abs/2407.09373v1)|null|
|**2024-07-12**|**Enhancing Depressive Post Detection in Bangla: A Comparative Study of TF-IDF, BERT and FastText Embeddings**|Saad Ahmed Sazan et.al.|[2407.09187v1](http://arxiv.org/abs/2407.09187v1)|null|
|**2024-07-12**|**STD-LLM: Understanding Both Spatial and Temporal Properties of Spatial-Temporal Data with LLMs**|Yiheng Huang et.al.|[2407.09096v1](http://arxiv.org/abs/2407.09096v1)|null|
|**2024-07-12**|**FD-SOS: Vision-Language Open-Set Detectors for Bone Fenestration and Dehiscence Detection from Intraoral Images**|Marawan Elbatel et.al.|[2407.09088v1](http://arxiv.org/abs/2407.09088v1)|null|
|**2024-07-12**|**Heterogeneous Subgraph Network with Prompt Learning for Interpretable Depression Detection on Social Media**|Chen Chen et.al.|[2407.09019v1](http://arxiv.org/abs/2407.09019v1)|null|
|**2024-07-12**|**Application of Artificial Intelligence in Supporting Healthcare Professionals and Caregivers in Treatment of Autistic Children**|Hossein Mohammadi Rouzbahani et.al.|[2407.08902v1](http://arxiv.org/abs/2407.08902v1)|null|
|**2024-07-11**|**SALT: Introducing a Framework for Hierarchical Segmentations in Medical Imaging using Softmax for Arbitrary Label Trees**|Sven Koitka et.al.|[2407.08878v1](http://arxiv.org/abs/2407.08878v1)|[link](https://github.com/umessen/salt)|
|**2024-07-11**|**FedMedICL: Towards Holistic Evaluation of Distribution Shifts in Federated Medical Imaging**|Kumail Alhamoud et.al.|[2407.08822v1](http://arxiv.org/abs/2407.08822v1)|[link](https://github.com/m1k2zoo/fedmedicl)|
|**2024-07-11**|**FairDomain: Achieving Fairness in Cross-Domain Medical Image Segmentation and Classification**|Yu Tian et.al.|[2407.08813v2](http://arxiv.org/abs/2407.08813v2)|[link](https://github.com/harvard-ophthalmology-ai-lab/fairdomain)|
|**2024-07-11**|**Uncertainty Estimation of Large Language Models in Medical Question Answering**|Jiaxin Wu et.al.|[2407.08662v1](http://arxiv.org/abs/2407.08662v1)|null|
|**2024-07-11**|**Establishing Rigorous and Cost-effective Clinical Trials for Artificial Intelligence Models**|Wanling Gao et.al.|[2407.08554v1](http://arxiv.org/abs/2407.08554v1)|[link](https://github.com/benchcouncil/vc-medai)|
|**2024-07-11**|**How Deep is your Guess? A Fresh Perspective on Deep Learning for Medical Time-Series Imputation**|Linglong Qian et.al.|[2407.08442v1](http://arxiv.org/abs/2407.08442v1)|null|
|**2024-07-11**|**Specialist vision-language models for clinical ophthalmology**|Robbie Holland et.al.|[2407.08410v1](http://arxiv.org/abs/2407.08410v1)|[link](https://github.com/robbieholland/specialistvlms)|
|**2024-07-11**|**Unveiling Disparities in Maternity Care: A Topic Modelling Approach to Analysing Maternity Incident Investigation Reports**|Georgina Cosma et.al.|[2407.08328v1](http://arxiv.org/abs/2407.08328v1)|null|
|**2024-07-11**|**Predicting Heart Failure with Attention Learning Techniques Utilizing Cardiovascular Data**|Ershadul Haque et.al.|[2407.08289v1](http://arxiv.org/abs/2407.08289v1)|null|
|**2024-07-11**|**Leveraging LLMs to Predict Affective States via Smartphone Sensor Features**|Tianyi Zhang et.al.|[2407.08240v1](http://arxiv.org/abs/2407.08240v1)|null|
|**2024-07-11**|**DALL-M: Context-Aware Clinical Data Augmentation with LLMs**|Chihcheng Hsieh et.al.|[2407.08227v1](http://arxiv.org/abs/2407.08227v1)|[link](https://github.com/chihchenghsieh/dall-m)|
|**2024-07-11**|**Synthetic Electroretinogram Signal Generation Using Conditional Generative Adversarial Network for Enhancing Classification of Autism Spectrum Disorder**|Mikhail Kulyabin et.al.|[2407.08166v1](http://arxiv.org/abs/2407.08166v1)|null|
|**2024-07-11**|**Highway Networks for Improved Surface Reconstruction: The Role of Residuals and Weight Updates**|A. Noorizadegan et.al.|[2407.08134v1](http://arxiv.org/abs/2407.08134v1)|[link](https://github.com/cmmai/resnet_for_pinn)|
|**2024-07-10**|**Machine Learning for ALSFRS-R Score Prediction: Making Sense of the Sensor Data**|Ritesh Mehta et.al.|[2407.08003v1](http://arxiv.org/abs/2407.08003v1)|null|

#### Abstracts
##### **Self-supervised pre-training with diffusion model for few-shot landmark detection in x-ray images**
2407.18125v1 by Roberto Di Via, Francesca Odone, Vito Paolo Pastore

In the last few years, deep neural networks have been extensively applied in
the medical domain for different tasks, ranging from image classification and
segmentation to landmark detection. However, the application of these
technologies in the medical domain is often hindered by data scarcity, both in
terms of available annotations and images. This study introduces a new
self-supervised pre-training protocol based on diffusion models for landmark
detection in x-ray images. Our results show that the proposed self-supervised
framework can provide accurate landmark detection with a minimal number of
available annotated training images (up to 50), outperforming ImageNet
supervised pre-training and state-of-the-art self-supervised pre-trainings for
three popular x-ray benchmark datasets. To our knowledge, this is the first
exploration of diffusion models for self-supervised learning in landmark
detection, which may offer a valuable pre-training approach in few-shot
regimes, for mitigating data scarcity.

æè¦ï¼å¨éå»å¹¾å¹´ä¸­ï¼æ·±åº¦ç¥ç¶ç¶²è·¯å·²å»£æ³æç¨æ¼é«çé åçä¸åä»»åï¼å¾å½±ååé¡ååå²å°å°æ¨åµæ¸¬ãç¶èï¼éäºæè¡å¨é«çé åçæç¨å¸¸å¸¸åå°è³æç¨å°çé»ç¤ï¼ç¡è«æ¯å¨å¯ç¨çè¨»è§£æå½±åæ¹é¢ãæ¬ç ç©¶ä»ç´¹äºä¸åæ°çèªç£ç£é è¨ç·´åå®ï¼å®æ¯åºæ¼æ´æ£æ¨¡åï¼ç¨æ¼ X åå½±åä¸­çå°æ¨åµæ¸¬ãæåççµæé¡¯ç¤ºï¼ææåºçèªç£ç£æ¶æ§å¯ä»¥å¨æå°æ¸éçå¯ç¨è¨»è§£è¨ç·´å½±åï¼æå¤ 50 åï¼ä¸æä¾æºç¢ºçå°æ¨åµæ¸¬ï¼åªæ¼ ImageNet ç£ç£å¼é è¨ç·´ä»¥åä¸åç±é X ååºæºè³æéçææ°èªç£ç£å¼é è¨ç·´ãææåæç¥ï¼éæ¯é¦æ¬¡æ¢è¨æ´æ£æ¨¡åç¨æ¼å°æ¨åµæ¸¬ä¸­çèªç£ç£å¼å­¸ç¿ï¼å®å¯è½å¨å°æ¨£æ¬è¨ç·´æ¨¡å¼ä¸­æä¾æå¹å¼çé è¨ç·´æ¹æ³ï¼ä»¥æ¸è¼è³æç¨å°çåé¡ã

##### **Multi-Resolution Histopathology Patch Graphs for Ovarian Cancer Subtyping**
2407.18105v1 by Jack Breen, Katie Allen, Kieran Zucker, Nicolas M. Orsi, Nishant Ravikumar

Computer vision models are increasingly capable of classifying ovarian
epithelial cancer subtypes, but they differ from pathologists by processing
small tissue patches at a single resolution. Multi-resolution graph models
leverage the spatial relationships of patches at multiple magnifications,
learning the context for each patch. In this study, we conduct the most
thorough validation of a graph model for ovarian cancer subtyping to date.
Seven models were tuned and trained using five-fold cross-validation on a set
of 1864 whole slide images (WSIs) from 434 patients treated at Leeds Teaching
Hospitals NHS Trust. The cross-validation models were ensembled and evaluated
using a balanced hold-out test set of 100 WSIs from 30 patients, and an
external validation set of 80 WSIs from 80 patients in the Transcanadian Study.
The best-performing model, a graph model using 10x+20x magnification data, gave
balanced accuracies of 73%, 88%, and 99% in cross-validation, hold-out testing,
and external validation, respectively. However, this only exceeded the
performance of attention-based multiple instance learning in external
validation, with a 93% balanced accuracy. Graph models benefitted greatly from
using the UNI foundation model rather than an ImageNet-pretrained ResNet50 for
feature extraction, with this having a much greater effect on performance than
changing the subsequent classification approach. The accuracy of the combined
foundation model and multi-resolution graph network offers a step towards the
clinical applicability of these models, with a new highest-reported performance
for this task, though further validations are still required to ensure the
robustness and usability of the models.

æè¦ï¼é»è¦è¦è¦ºæ¨¡åè¶ä¾è¶è½å¤ åé¡åµå·¢ä¸ç®ççäºåï¼ä½å®åèççå­¸å®¶ä¸åï¼å®åä»¥å®ä¸è§£æåº¦èçå°çµç¹è²¼çãå¤è§£æåº¦åå½¢æ¨¡åå©ç¨å¤åæ¾å¤§åçä¸è²¼ççç©ºééä¿ï¼å­¸ç¿æ¯åè²¼ççèæ¯ãå¨éé ç ç©¶ä¸­ï¼æåå°åå½¢æ¨¡åé²è¡äºè¿ä»çºæ­¢æå¾¹åºçåµå·¢çäºåé©è­ãä½¿ç¨ 434 åå¨å©è²æå­¸é«é¢ NHS ä¿¡è¨åºéæ¥åæ²»ççæ£èç 1864 å¼µå¨å¹»ççå½±å (WSI) é²è¡äºåäº¤åé©è­ï¼èª¿æ´ä¸¦è¨ç·´äºä¸åæ¨¡åãå°äº¤åé©è­æ¨¡åéæä¸¦ä½¿ç¨ä¾èª 30 åæ£èç 100 å¼µ WSI çå¹³è¡¡çåºæ¸¬è©¦éåä¾èª Transcanadian ç ç©¶ä¸­ 80 åæ£èç 80 å¼µ WSI çå¤é¨é©è­éé²è¡è©ä¼°ãè¡¨ç¾æä½³çæ¨¡åï¼ä¸åä½¿ç¨ 10 å+20 åæ¾å¤§åçè³æçåå½¢æ¨¡åï¼å¨äº¤åé©è­ãçåºæ¸¬è©¦åå¤é¨é©è­ä¸­åå¥çµ¦åº 73%ã88% å 99% çå¹³è¡¡æºç¢ºåº¦ãç¶èï¼éåè¶éäºå¤é¨é©è­ä¸­åºæ¼æ³¨æåçå¤å¯¦ä¾å­¸ç¿çè¡¨ç¾ï¼å¹³è¡¡æºç¢ºåº¦çº 93%ãåå½¢æ¨¡åå¾ä½¿ç¨ UNI åºç¤æ¨¡åèä¸æ¯ ImageNet é è¨ç·´ç ResNet50 é²è¡ç¹å¾µæåä¸­åçåªæ·ºï¼èæ¹è®å¾çºåé¡æ¹æ³ç¸æ¯ï¼éå°æè½ææ´å¤§çå½±é¿ãçµååºç¤æ¨¡ååå¤è§£æåº¦åå½¢ç¶²è·¯çæºç¢ºåº¦çºéäºæ¨¡åçè¨åºæç¨éåºäºä¸æ­¥ï¼å°æ¼éé ä»»åä¾èªªï¼éæ¯æ°çæé«å ±åè¡¨ç¾ï¼åç®¡ä»éè¦é²ä¸æ­¥çé©è­ä¾ç¢ºä¿æ¨¡åçç©©å¥æ§åå¯ç¨æ§ã

##### **HG-PIPE: Vision Transformer Acceleration with Hybrid-Grained Pipeline**
2407.17879v1 by Qingyu Guo, Jiayong Wan, Songqiang Xu, Meng Li, Yuan Wang

Vision Transformer (ViT) acceleration with field programmable gate array
(FPGA) is promising but challenging. Existing FPGA-based ViT accelerators
mainly rely on temporal architectures, which process different operators by
reusing the same hardware blocks and suffer from extensive memory access
overhead. Pipelined architectures, either coarse-grained or fine-grained,
unroll the ViT computation spatially for memory access efficiency. However,
they usually suffer from significant hardware resource constraints and pipeline
bubbles induced by the global computation dependency of ViT. In this paper, we
introduce HG-PIPE, a pipelined FPGA accelerator for high-throughput and
low-latency ViT processing. HG-PIPE features a hybrid-grained pipeline
architecture to reduce on-chip buffer cost and couples the computation dataflow
and parallelism design to eliminate the pipeline bubbles. HG-PIPE further
introduces careful approximations to implement both linear and non-linear
operators with abundant Lookup Tables (LUTs), thus alleviating resource
constraints. On a ZCU102 FPGA, HG-PIPE achieves 2.78 times better throughput
and 2.52 times better resource efficiency than the prior-art accelerators,
e.g., AutoViTAcc. With a VCK190 FPGA, HG-PIPE realizes end-to-end ViT
acceleration on a single device and achieves 7118 images/s, which is 2.81 times
faster than a V100 GPU.

æè¦ï¼è¦è¦ºè½æå¨ (ViT) èç¾å ´å¯ç·¨ç¨éé£å (FPGA) çå éå¾æåæ¯ï¼ä½ä¹åæ»¿ææ°ãç¾æçåºæ¼ FPGA ç ViT å éå¨ä¸»è¦ä¾è³´æ¼æ«ææ¶æ§ï¼å®éééè¤ä½¿ç¨ç¸åçç¡¬é«åå¡ä¾èçä¸åçéç®å­ï¼ä¸¦æ¿åå¤§éçè¨æ¶é«å­åéé·ãç®¡ç·æ¶æ§ï¼ç¡è«æ¯ç²ç²åº¦æç´°ç²åº¦ï¼å¨ç©ºéä¸å±é ViT è¨ç®ä»¥æé«è¨æ¶é«å­åæçãç¶èï¼å®åéå¸¸æåå°é¡¯èçç¡¬é«è³æºéå¶åç± ViT çå¨å±è¨ç®ä¾è³´æ§æå¼ç¼çç®¡ç·æ°£æ³¡ãå¨æ¬æä¸­ï¼æåä»ç´¹äº HG-PIPEï¼éæ¯ä¸ç¨®ç¨æ¼é«ééåä½å»¶é² ViT èççç®¡ç·å¼ FPGA å éå¨ãHG-PIPE æ¡ç¨æ··åç²åº¦ç®¡ç·æ¶æ§ä¾éä½æ¶çç·©è¡ææ¬ï¼ä¸¦çµåè¨ç®è³ææµåä¸¦è¡è¨­è¨ä»¥æ¶é¤ç®¡ç·æ°£æ³¡ãHG-PIPE é²ä¸æ­¥å¼å¥äºä»ç´°çè¿ä¼¼å¼ï¼ä»¥ä½¿ç¨è±å¯çæ¥æ¾è¡¨ (LUT) ä¾å¯¦ä½ç·æ§åéç·æ§éç®å­ï¼å¾èæ¸è¼è³æºéå¶ãå¨ ZCU102 FPGA ä¸ï¼HG-PIPE çååéæ¯åé²çå éå¨ï¼ä¾å¦ AutoViTAccï¼é«åº 2.78 åï¼è³æºæçé«åº 2.52 åãä½¿ç¨ VCK190 FPGAï¼HG-PIPE å¨å®ä¸è£ç½®ä¸å¯¦ç¾ç«¯å°ç«¯ç ViT å éï¼ä¸¦éå°æ¯ç§ 7118 å¼µå½±åï¼æ¯ V100 GPU å¿« 2.81 åã

##### **EEG-SSM: Leveraging State-Space Model for Dementia Detection**
2407.17801v1 by Xuan-The Tran, Linh Le, Quoc Toan Nguyen, Thomas Do, Chin-Teng Lin

State-space models (SSMs) have garnered attention for effectively processing
long data sequences, reducing the need to segment time series into shorter
intervals for model training and inference. Traditionally, SSMs capture only
the temporal dynamics of time series data, omitting the equally critical
spectral features. This study introduces EEG-SSM, a novel state-space
model-based approach for dementia classification using EEG data. Our model
features two primary innovations: EEG-SSM temporal and EEG-SSM spectral
components. The temporal component is designed to efficiently process EEG
sequences of varying lengths, while the spectral component enhances the model
by integrating frequency-domain information from EEG signals. The synergy of
these components allows EEG-SSM to adeptly manage the complexities of
multivariate EEG data, significantly improving accuracy and stability across
different temporal resolutions. Demonstrating a remarkable 91.0 percent
accuracy in classifying Healthy Control (HC), Frontotemporal Dementia (FTD),
and Alzheimer's Disease (AD) groups, EEG-SSM outperforms existing models on the
same dataset. The development of EEG-SSM represents an improvement in the use
of state-space models for screening dementia, offering more precise and
cost-effective tools for clinical neuroscience.

æè¦ï¼çæç©ºéæ¨¡å (SSM) å ææèçé·è³æåºåèååéæ³¨ï¼æ¸å°å°æéåºååéæè¼ç­åéä»¥é²è¡æ¨¡åè¨ç·´åæ¨è«çéè¦ãå³çµ±ä¸ï¼SSM åªæ·åæéåºåè³æçæéåæï¼çç¥åæ¨£éè¦çé »è­ç¹å¾µãæ¬ç ç©¶æåº EEG-SSMï¼ä¸ç¨®æ°çåºæ¼çæç©ºéæ¨¡åçæ¹æ³ï¼ç¨æ¼ä½¿ç¨ EEG è³æé²è¡å¤±æºçåé¡ãæåçæ¨¡åå·æå©é ä¸»è¦çåµæ°ï¼EEG-SSM æéå EEG-SSM é »è­çµæé¨åãæéçµæé¨åæ¨å¨ææçå°èçé·åº¦ä¸åç EEG åºåï¼èé »è­çµæé¨åééæ´å EEG è¨èçé »åè³è¨ä¾å¢å¼·æ¨¡åãéäºçµæé¨åçååä½ç¨è® EEG-SSM è½éæ´»å°ç®¡çå¤è®é EEG è³æçè¤éæ§ï¼å¤§å¹æ¹åä¸åæéè§£æåº¦ä¸çæºç¢ºæ§åç©©å®æ§ãEEG-SSM å¨åé¡å¥åº·å°ç§çµ (HC)ãé¡é¡³èåå¤±æºç (FTD) åé¿è²æµ·é»ç (AD) çµå¥æå±ç¾åºé©äººç 91.0% æºç¢ºåº¦ï¼å¨ç¸åçè³æéä¸åªæ¼ç¾ææ¨¡åãEEG-SSM çéç¼ä»£è¡¨äºä½¿ç¨çæç©ºéæ¨¡åé²è¡å¤±æºçç¯©æª¢çé²æ­¥ï¼çºè¨åºç¥ç¶ç§å­¸æä¾æ´ç²¾ç¢ºä¸æ´å·ææ¬æççå·¥å·ã

##### **Mpox Detection Advanced: Rapid Epidemic Response Through Synthetic Data**
2407.17762v1 by Yudara Kularathne, Prathapa Janitha, Sithira Ambepitiya, Prarththanan Sothyrajah, Thanveer Ahamed, Dinuka Wijesundara

Rapid development of disease detection models using computer vision is
crucial in responding to medical emergencies, such as epidemics or bioterrorism
events. Traditional data collection methods are often too slow in these
scenarios, requiring innovative approaches for quick, reliable model generation
from minimal data. Our study introduces a novel approach by constructing a
comprehensive computer vision model to detect Mpox lesions using only synthetic
data. Initially, these models generated a diverse set of synthetic images
representing Mpox lesions on various body parts (face, back, chest, leg, neck,
arm) across different skin tones as defined by the Fitzpatrick scale (fair,
brown, dark skin). Subsequently, we trained and tested a vision model with this
synthetic dataset to evaluate the diffusion models' efficacy in producing
high-quality training data and its impact on the vision model's medical image
recognition performance. The results were promising; the vision model achieved
a 97% accuracy rate, with 96% precision and recall for Mpox cases, and
similarly high metrics for normal and other skin disorder cases, demonstrating
its ability to correctly identify true positives and minimize false positives.
The model achieved an F1-Score of 96% for Mpox cases and 98% for normal and
other skin disorders, reflecting a balanced precision-recall relationship, thus
ensuring reliability and robustness in its predictions. Our proposed
SynthVision methodology indicates the potential to develop accurate computer
vision models with minimal data input for future medical emergencies.

æè¦ï¼<paragraph>å©ç¨é»è¦è¦è¦ºå¿«ééç¼ç¾çæª¢æ¸¬æ¨¡åå°æ¼å æé«çç·æ¥äºä»¶ï¼ä¾å¦æµè¡çæçç©ææä¸»ç¾©äºä»¶ï¼è³ééè¦ãå³çµ±çè³ææ¶éæ¹æ³å¨éäºææ³ä¸éå¸¸å¤ªæ¢ï¼éè¦åµæ°çæ¹æ³æè½å¾æå°è³æä¸­å¿«éãå¯é å°ç¢çæ¨¡åãæåçç ç©¶ä»ç´¹äºä¸ç¨®æ°ç©çæ¹æ³ï¼ééå»ºæ§ä¸åå¨é¢çé»è¦è¦è¦ºæ¨¡åï¼åä½¿ç¨åæè³æä¾æª¢æ¸¬ç´ççç¶ãæåï¼éäºæ¨¡åç¢çäºä¸çµå¤æ¨£åçåæå½±åï¼ä»£è¡¨äºä¸åèè²ï¼æ ¹æ Fitzpatrick éè¡¨å®ç¾©çºç½çãæ£è²ãæ·±è²ç®èï¼ä¸ä¸åèº«é«é¨ä½ï¼èé¨ãèé¨ãè¸é¨ãè¿é¨ãé ¸é¨ãæèï¼çç´ççç¶ãé¨å¾ï¼æåä½¿ç¨éååæè³æéè¨ç·´åæ¸¬è©¦ä¸åè¦è¦ºæ¨¡åï¼ä»¥è©ä¼°æ´æ£æ¨¡åç¢çé«åè³ªè¨ç·´è³æçæè½ï¼ä»¥åå¶å°è¦è¦ºæ¨¡åé«å­¸å½±åè¾¨è­æè½çå½±é¿ãçµæä»¤äººæ»¿æï¼è¦è¦ºæ¨¡åéå°äº 97% çæºç¢ºçï¼ç´ççä¾çæºç¢ºåº¦åå¬åççº 96%ï¼æ­£å¸¸åå¶å®ç®èç¾ççä¾çææ¨ä¹åæ¨£é«ï¼è­æäºå®æ­£ç¢ºè¾¨è­çé½æ§ä¸¦å°åé½æ§éè³æä½çè½åãè©²æ¨¡åå¨ç´ççä¾ä¸­éå°äº 96% ç F1 åæ¸ï¼å¨æ­£å¸¸åå¶å®ç®èç¾çä¸­éå°äº 98%ï¼åæ åºå¹³è¡¡çæºç¢ºåº¦å¬åçéä¿ï¼å¾èç¢ºä¿å¶é æ¸¬çå¯é æ§åç©©å¥æ§ãæåæåºç SynthVision æ¹æ³è¡¨æï¼æå¯è½çºæªä¾çé«çç·æ¥äºä»¶éç¼åºæºç¢ºçé»è¦è¦è¦ºæ¨¡åï¼ä¸è³æè¼¸å¥éæå°ã</paragraph>

##### **Cost-effective Instruction Learning for Pathology Vision and Language Analysis**
2407.17734v1 by Kaitao Chen, Mianxin Liu, Fang Yan, Lei Ma, Xiaoming Shi, Lilong Wang, Xiaosong Wang, Lifeng Zhu, Zhe Wang, Mu Zhou, Shaoting Zhang

The advent of vision-language models fosters the interactive conversations
between AI-enabled models and humans. Yet applying these models into clinics
must deal with daunting challenges around large-scale training data, financial,
and computational resources. Here we propose a cost-effective instruction
learning framework for conversational pathology named as CLOVER. CLOVER only
trains a lightweight module and uses instruction tuning while freezing the
parameters of the large language model. Instead of using costly GPT-4, we
propose well-designed prompts on GPT-3.5 for building generation-based
instructions, emphasizing the utility of pathological knowledge derived from
the Internet source. To augment the use of instructions, we construct a
high-quality set of template-based instructions in the context of digital
pathology. From two benchmark datasets, our findings reveal the strength of
hybrid-form instructions in the visual question-answer in pathology. Extensive
results show the cost-effectiveness of CLOVER in answering both open-ended and
closed-ended questions, where CLOVER outperforms strong baselines that possess
37 times more training parameters and use instruction data generated from
GPT-4. Through the instruction tuning, CLOVER exhibits robustness of few-shot
learning in the external clinical dataset. These findings demonstrate that
cost-effective modeling of CLOVER could accelerate the adoption of rapid
conversational applications in the landscape of digital pathology.

æè¦ï¼è¦è¦ºèªè¨æ¨¡åçåºç¾ä¿é²äº AI åç¨æ¨¡åèäººé¡ä¹éçäºåå°è©±ãç¶èï¼å°éäºæ¨¡åæç¨æ¼è¨åºå¿é æå°å¤§è¦æ¨¡è¨ç·´æ¸æãè²¡ååè¨ç®è³æºç­å´å³»ææ°ãå¨æ­¤ï¼æåæåºäºä¸ååçº CLOVER çç¶æ¿é«æçæè©±ççå­¸æä»¤å­¸ç¿æ¶æ§ãCLOVER åè¨ç·´ä¸åè¼éç´æ¨¡çµï¼ä¸¦å¨åçµå¤§åèªè¨æ¨¡ååæ¸çåæä½¿ç¨æä»¤å¾®èª¿ãæåæ²æä½¿ç¨æè²´ç GPT-4ï¼èæ¯éå° GPT-3.5 æåºè¨­è¨è¯å¥½çæç¤ºï¼ä»¥å»ºç«åºæ¼çæçæä»¤ï¼å¼·èª¿å¾ç¶²éç¶²è·¯ä¾æºè¡ççççç¥è­çæç¨ãçºäºæ´å±æä»¤çä½¿ç¨ï¼æåå¨æ¸ä½ççå­¸çèæ¯ä¸æ§å»ºäºä¸çµé«åè³ªçåºæ¼ç¯æ¬çæä»¤ãå¾å©ååºæºè³æéï¼æåçç ç©¶çµææ­ç¤ºäºæ··åå½¢å¼æä»¤å¨ççå­¸è¦è¦ºåç­ä¸­çåªå¢ãå»£æ³ççµæé¡¯ç¤ºäº CLOVER å¨åç­éæ¾å¼åå°éå¼åé¡æ¹é¢çç¶æ¿æçï¼å¶ä¸­ CLOVER åªæ¼ææå¤ 37 åè¨ç·´åæ¸ä¸¦ä½¿ç¨å¾ GPT-4 çæçæä»¤è³æçå¼·å¤§åºæºãééæä»¤å¾®èª¿ï¼CLOVER å¨å¤é¨è¨åºè³æéä¸­å±ç¾äºå°æ¨£æ¬å­¸ç¿çç©©å¥æ§ãéäºç¼ç¾è­æäº CLOVER çç¶æ¿é«æå»ºæ¨¡å¯ä»¥å éå¨æ¸ä½ççé åæ¡ç¨å¿«éå°è©±å¼æç¨ç¨å¼ã

##### **Enhanced Deep Learning Methodologies and MRI Selection Techniques for Dementia Diagnosis in the Elderly Population**
2407.17324v2 by Nikolaos Ntampakis, Konstantinos Diamantaras, Ioanna Chouvarda, Vasileios Argyriou, Panagiotis Sarigianndis

Dementia, a debilitating neurological condition affecting millions worldwide,
presents significant diagnostic challenges. In this work, we introduce a novel
methodology for the classification of demented and non-demented elderly
patients using 3D brain Magnetic Resonance Imaging (MRI) scans. Our approach
features a unique technique for selectively processing MRI slices, focusing on
the most relevant brain regions and excluding less informative sections. This
methodology is complemented by a confidence-based classification committee
composed of three custom deep learning models: Dem3D ResNet, Dem3D CNN, and
Dem3D EfficientNet. These models work synergistically to enhance
decision-making accuracy, leveraging their collective strengths. Tested on the
Open Access Series of Imaging Studies(OASIS) dataset, our method achieved an
impressive accuracy of 94.12%, surpassing existing methodologies. Furthermore,
validation on the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset
confirmed the robustness and generalizability of our approach. The use of
explainable AI (XAI) techniques and comprehensive ablation studies further
substantiate the effectiveness of our techniques, providing insights into the
decision-making process and the importance of our methodology. This research
offers a significant advancement in dementia diagnosis, providing a highly
accurate and efficient tool for clinical applications.

æè¦ï¼å¤±æºçæ¯ä¸ç¨®å½±é¿å¨çæ¸ç¾è¬äººçè¡°å¼±æ§ç¥ç¶ç¾çï¼å¨è¨ºæ·ä¸å·æéå¤§ææ°ãå¨éé å·¥ä½ä¸­ï¼æåæåºäºä¸ç¨®æ°çæ¹æ³ï¼ç¨æ¼å°å¤±æºåéå¤±æºèå¹´æ£èé²è¡åé¡ï¼ä½¿ç¨ 3D å¤§è¦ç£æ¯é å½± (MRI) ææãæåçåæ³æ¡ç¨äºä¸ç¨®ç¨ç¹æè¡ï¼ç¨æ¼é¸ææ§èç MRI åçï¼éé»éæ³¨æç¸éçå¤§è¦ååï¼ä¸¦æé¤ä¿¡æ¯éè¼å°çé¨åãéç¨®æ¹æ³ç±ä¸ååºæ¼ä¿¡å¿çåé¡å§å¡æè£åï¼è©²å§å¡æç±ä¸åèªå®ç¾©æ·±åº¦å­¸ç¿æ¨¡åçµæï¼Dem3D ResNetãDem3D CNN å Dem3D EfficientNetãéäºæ¨¡åååå·¥ä½ä»¥å¢å¼·æ±ºç­çæºç¢ºæ§ï¼å©ç¨å®åçéé«åªå¢ãå¨å½±åç ç©¶éæ¾å­åç³»å (OASIS) è³æéä¸é²è¡æ¸¬è©¦ï¼æåçæ¨¡åéå°äº 94.12% çé©äººæºç¢ºåº¦ï¼è¶éäºç¾ææ¹æ³ãæ­¤å¤ï¼å¨é¿è²æµ·é»çç¥ç¶å½±åå¡è­° (ADNI) è³æéä¸çé©è­è­å¯¦äºæåæ¹æ³çç©©å¥æ§åæ®éæ§ãå¯è§£é AI (XAI) æè¡åå¨é¢çæ¶èç ç©¶é²ä¸æ­¥è­å¯¦äºæåæè¡çæææ§ï¼æä¾äºå°æ±ºç­éç¨åæåæ¹æ³éè¦æ§çè¦è§£ãéé ç ç©¶çºå¤±æºçè¨ºæ·æä¾äºéå¤§é²å±ï¼çºè¨åºæç¨æä¾äºä¸åé«åº¦æºç¢ºä¸é«æçå·¥å·ã

##### **Improving ICD coding using Chapter based Named Entities and Attentional Models**
2407.17230v1 by Abhijith R. Beeravolu, Mirjam Jonkman, Sami Azam, Friso De Boer

Recent advancements in natural language processing (NLP) have led to
automation in various domains. However, clinical NLP often relies on benchmark
datasets that may not reflect real-world scenarios accurately. Automatic ICD
coding, a vital NLP task, typically uses outdated and imbalanced datasets like
MIMIC-III, with existing methods yielding micro-averaged F1 scores between 0.4
and 0.7 due to many false positives. Our research introduces an enhanced
approach to ICD coding that improves F1 scores by using chapter-based named
entities and attentional models. This method categorizes discharge summaries
into ICD-9 Chapters and develops attentional models with chapter-specific data,
eliminating the need to consider external data for code identification. For
categorization, we use Chapter-IV to de-bias and influence key entities and
weights without neural networks, creating accurate thresholds and providing
interpretability for human validation. Post-validation, we develop attentional
models for three frequent and three non-frequent codes from Chapter-IV using
Bidirectional-Gated Recurrent Units (GRUs) with Attention and Transformer with
Multi-head Attention architectures. The average Micro-F1 scores of 0.79 and
0.81 from these models demonstrate significant performance improvements in ICD
coding.

æè¦ï¼èªç¶èªè¨èç (NLP) çææ°é²å±å·²å°è´åç¨®é åçèªååãç¶èï¼è¨åº NLP éå¸¸ä¾è³´æ¼åºæºè³æéï¼éäºè³æéå¯è½ç¡æ³æºç¢ºåæ çå¯¦ä¸ççå ´æ¯ãèªå ICD ç·¨ç¢¼æ¯ä¸é éè¦ç NLP ä»»åï¼éå¸¸ä½¿ç¨éæä¸ä¸å¹³è¡¡çè³æéï¼ä¾å¦ MIMIC-IIIï¼ç±æ¼è¨±å¤åé½æ§ï¼ç¾ææ¹æ³ç¢ççå¾®å¹³å F1 åæ¸ä»æ¼ 0.4 å 0.7 ä¹éãæåçç ç©¶å¼å¥äºä¸ç¨®å¢å¼·ç ICD ç·¨ç¢¼æ¹æ³ï¼ééä½¿ç¨åºæ¼ç« ç¯çå½åå¯¦é«åæ³¨æåæ¨¡åä¾æé« F1 åæ¸ãæ­¤æ¹æ³å°åºé¢æè¦åé¡çº ICD-9 ç« ç¯ï¼ä¸¦ä½¿ç¨ç« ç¯ç¹å®è³æéç¼æ³¨æåæ¨¡åï¼æ¶é¤äºèæ®å¤é¨è³æä»¥é²è¡ä»£ç¢¼è­å¥çéè¦ãå°æ¼åé¡ï¼æåä½¿ç¨ Chapter-IV ä¾æ¶é¤åå·®ä¸¦å½±é¿ééµå¯¦é«åæ¬éï¼èç¡éç¥ç¶ç¶²è·¯ï¼å¾èå»ºç«æºç¢ºçé¾å¼ä¸¦æä¾äººé¡é©è­çå¯è§£éæ§ãå¨é©è­ä¹å¾ï¼æåä½¿ç¨å¸¶ææ³¨æååå¤é ­æ³¨ææ¶æ§çéåéæ§éè¿´å®å (GRU) å Transformerï¼çº Chapter-IV ä¸­çä¸åé »ç¹åä¸åéé »ç¹ä»£ç¢¼éç¼æ³¨æåæ¨¡åãéäºæ¨¡åçå¹³åå¾® F1 åæ¸çº 0.79 å 0.81ï¼è¡¨æ ICD ç·¨ç¢¼çæè½æäºé¡¯èçæåã

##### **Robust Deep Hawkes Process under Label Noise of Both Event and Occurrence**
2407.17164v1 by Xiaoyu Tan, Bin Li, Xihe Qiu, Jingjing Huang, Yinghui Xu, Wei Chu

Integrating deep neural networks with the Hawkes process has significantly
improved predictive capabilities in finance, health informatics, and
information technology. Nevertheless, these models often face challenges in
real-world settings, particularly due to substantial label noise. This issue is
of significant concern in the medical field, where label noise can arise from
delayed updates in electronic medical records or misdiagnoses, leading to
increased prediction risks. Our research indicates that deep Hawkes process
models exhibit reduced robustness when dealing with label noise, particularly
when it affects both event types and timing. To address these challenges, we
first investigate the influence of label noise in approximated intensity
functions and present a novel framework, the Robust Deep Hawkes Process (RDHP),
to overcome the impact of label noise on the intensity function of Hawkes
models, considering both the events and their occurrences. We tested RDHP using
multiple open-source benchmarks with synthetic noise and conducted a case study
on obstructive sleep apnea-hypopnea syndrome (OSAHS) in a real-world setting
with inherent label noise. The results demonstrate that RDHP can effectively
perform classification and regression tasks, even in the presence of noise
related to events and their timing. To the best of our knowledge, this is the
first study to successfully address both event and time label noise in deep
Hawkes process models, offering a promising solution for medical applications,
specifically in diagnosing OSAHS.

æè¦ï¼å°æ·±åº¦ç¥ç¶ç¶²è·¯èéåæ¯éç¨æ´åï¼å¤§å¹æåäºéèãå¥åº·è³è¨å­¸åè³è¨ç§æçé æ¸¬è½åãç¶èï¼éäºæ¨¡åå¨ç¾å¯¦ä¸çä¸­ç¶å¸¸é¢è¨ææ°ï¼ç¹å¥æ¯å çºæ¨ç±¤éè¨éå¤§ãéååé¡å¨é«çé åç¹å¥ä»¤äººææï¼å çºæ¨ç±¤éè¨å¯è½ä¾èªé»å­çæ­·çæ´æ°å»¶èª¤æèª¤è¨ºï¼å°è´é æ¸¬é¢¨éªå¢å ãæåçç ç©¶è¡¨æï¼æ·±åº¦éåæ¯éç¨æ¨¡åå¨èçæ¨ç±¤éè¨æè¡¨ç¾åºè¼ä½çç©©å¥æ§ï¼ç¹å¥æ¯å¨æ¨ç±¤éè¨åæå½±é¿äºä»¶é¡ååæéé»æãçºäºæå°éäºææ°ï¼æåé¦åç ç©¶æ¨ç±¤éè¨å°è¿ä¼¼å¼·åº¦å½æ¸çå½±é¿ï¼ä¸¦æåºäºä¸åæ°çæ¡æ¶ï¼å³ç©©å¥æ·±åº¦éåæ¯éç¨ (RDHP)ï¼ä»¥åææ¨ç±¤éè¨å°éåæ¯æ¨¡åå¼·åº¦å½æ¸çå½±é¿ï¼åæèæ®äºä»¶åå¶ç¼çãæåä½¿ç¨å¤åå·æåæéè¨çéæºåºæºæ¸¬è©¦ RDHPï¼ä¸¦å°ç¾å¯¦ä¸çä¸­å·æå§å¨æ¨ç±¤éè¨çé»å¡æ§ç¡ç å¼å¸ä¸­æ­¢ä½éæ°£ç¶åç (OSAHS) é²è¡æ¡ä¾ç ç©¶ãçµæè¡¨æï¼å³ä½¿å¨å­å¨èäºä»¶åå¶æéé»ç¸éçéè¨çææ³ä¸ï¼RDHP ä»è½ææå·è¡åé¡ååæ­¸ä»»åãææåæç¥ï¼éæ¯ç¬¬ä¸åæåè§£æ±ºæ·±åº¦éåæ¯éç¨æ¨¡åä¸­äºä»¶åæéæ¨ç±¤éè¨çç ç©¶ï¼çºé«çæç¨ï¼ç¹å¥æ¯è¨ºæ· OSAHSï¼æä¾äºä¸åæåæ¯çè§£æ±ºæ¹æ¡ã

##### **SDoH-GPT: Using Large Language Models to Extract Social Determinants of Health (SDoH)**
2407.17126v1 by Bernardo Consoli, Xizhi Wu, Song Wang, Xinyu Zhao, Yanshan Wang, Justin Rousseau, Tom Hartvigsen, Li Shen, Huanmei Wu, Yifan Peng, Qi Long, Tianlong Chen, Ying Ding

Extracting social determinants of health (SDoH) from unstructured medical
notes depends heavily on labor-intensive annotations, which are typically
task-specific, hampering reusability and limiting sharing. In this study we
introduced SDoH-GPT, a simple and effective few-shot Large Language Model (LLM)
method leveraging contrastive examples and concise instructions to extract SDoH
without relying on extensive medical annotations or costly human intervention.
It achieved tenfold and twentyfold reductions in time and cost respectively,
and superior consistency with human annotators measured by Cohen's kappa of up
to 0.92. The innovative combination of SDoH-GPT and XGBoost leverages the
strengths of both, ensuring high accuracy and computational efficiency while
consistently maintaining 0.90+ AUROC scores. Testing across three distinct
datasets has confirmed its robustness and accuracy. This study highlights the
potential of leveraging LLMs to revolutionize medical note classification,
demonstrating their capability to achieve highly accurate classifications with
significantly reduced time and cost.

æè¦ï¼å¾éçµæ§åçé«çç­è¨ä¸­èåå¥åº·çç¤¾ææ±ºå®å ç´  (SDoH) ä»°è³´å¤§éçäººå·¥æ¨è¨»ï¼èéäºæ¨è¨»éå¸¸æ¯éå°ç¹å®ä»»åï¼éæé»ç¤å¯éè¤ä½¿ç¨æ§ä¸¦éå¶åäº«ãå¨éé ç ç©¶ä¸­ï¼æåå¼å¥äº SDoH-GPTï¼ä¸ç¨®ç°¡å®ä¸ææçæ¹æ³ï¼å®å©ç¨å°æ¯ç¯ä¾åç°¡æ½çæç¤ºä¾èå SDoHï¼èä¸éè¦ä»°è³´å¤§éçé«çæ¨è¨»ææè²´çäººå·¥ä»å¥ãå®åå¥å¨æéåææ¬ä¸éå°äºåååäºååçéä½ï¼ä¸¦ä¸èäººé¡æ¨è¨»èçåªç°ä¸è´æ§ï¼ç± Cohen's kappa æ¸¬éé«é 0.92ãSDoH-GPT å XGBoost çåµæ°çµåå©ç¨äºå©èçåªé»ï¼ç¢ºä¿äºé«æºç¢ºåº¦åéç®æçï¼åæå§çµç¶­æ 0.90+ ç AUROC åæ¸ãå¨ä¸åä¸åçè³æéä¸é²è¡æ¸¬è©¦å·²ç¶ç¢ºèªäºå®çç©©å¥æ§åæºç¢ºæ§ãéé ç ç©¶çªé¡¯äºå©ç¨ LLM ä¾é©æ°é«çç­è¨åé¡çæ½åï¼å±ç¤ºäºå®åå¨é¡¯èæ¸å°æéåææ¬çææ³ä¸å¯¦ç¾é«åº¦æºç¢ºåé¡çè½åã

##### **SepsisLab: Early Sepsis Prediction with Uncertainty Quantification and Active Sensing**
2407.16999v1 by Changchang Yin, Pin-Yu Chen, Bingsheng Yao, Dakuo Wang, Jeffrey Caterino, Ping Zhang

Sepsis is the leading cause of in-hospital mortality in the USA. Early sepsis
onset prediction and diagnosis could significantly improve the survival of
sepsis patients. Existing predictive models are usually trained on high-quality
data with few missing information, while missing values widely exist in
real-world clinical scenarios (especially in the first hours of admissions to
the hospital), which causes a significant decrease in accuracy and an increase
in uncertainty for the predictive models. The common method to handle missing
values is imputation, which replaces the unavailable variables with estimates
from the observed data. The uncertainty of imputation results can be propagated
to the sepsis prediction outputs, which have not been studied in existing works
on either sepsis prediction or uncertainty quantification. In this study, we
first define such propagated uncertainty as the variance of prediction output
and then introduce uncertainty propagation methods to quantify the propagated
uncertainty. Moreover, for the potential high-risk patients with low confidence
due to limited observations, we propose a robust active sensing algorithm to
increase confidence by actively recommending clinicians to observe the most
informative variables. We validate the proposed models in both publicly
available data (i.e., MIMIC-III and AmsterdamUMCdb) and proprietary data in The
Ohio State University Wexner Medical Center (OSUWMC). The experimental results
show that the propagated uncertainty is dominant at the beginning of admissions
to hospitals and the proposed algorithm outperforms state-of-the-art active
sensing methods. Finally, we implement a SepsisLab system for early sepsis
prediction and active sensing based on our pre-trained models. Clinicians and
potential sepsis patients can benefit from the system in early prediction and
diagnosis of sepsis.

æè¦ï¼æè¡çæ¯ç¾åé«é¢ä¸­æ­»äº¡çä¸»è¦åå ãæè¡ççæ©æç¼ä½é æ¸¬åè¨ºæ·å¯ä»¥é¡¯èæé«æè¡çæ£èçå­æ´»çãç¾æçé æ¸¬æ¨¡åéå¸¸å¨è³æåè³ªé«ä¸éºå¤±è³è¨è¼å°çææ³ä¸é²è¡è¨ç·´ï¼èéºå¤±å¼å¨å¯¦éè¨åºæå¢ä¸­æ®éå­å¨ï¼å°¤å¶æ¯å¨å¥é¢çåå¹¾åå°æï¼ï¼éæå°è´é æ¸¬æ¨¡åçæºç¢ºåº¦é¡¯èä¸éï¼ä¸¦å¢å ä¸ç¢ºå®æ§ãèçéºå¤±å¼çå¸¸è¦æ¹æ³æ¯å§æï¼å®ä½¿ç¨å¾è§æ¸¬è³æä¸­ä¼°è¨çæ¸å¼åä»£ä¸å¯ç¨çè®æ¸ãå§æçµæçä¸ç¢ºå®æ§å¯è½æå³æ­å°æè¡çé æ¸¬è¼¸åºï¼éå¨ç¾æçæè¡çé æ¸¬æä¸ç¢ºå®æ§éåç ç©¶ä¸­å°æªè¢«æ¢è¨ãå¨éé ç ç©¶ä¸­ï¼æåé¦åå°éç¨®å³æ­çä¸ç¢ºå®æ§å®ç¾©çºé æ¸¬è¼¸åºçè®ç°ï¼ç¶å¾å¼å¥ä¸ç¢ºå®æ§å³æ­æ¹æ³ä¾éåå³æ­çä¸ç¢ºå®æ§ãæ­¤å¤ï¼å°æ¼ç±æ¼è§å¯æéèå°è´ä¿¡å¿è¼ä½çæ½å¨é«é¢¨éªæ£èï¼æåæåºäºä¸ç¨®å¼·å¤§çä¸»åææ¸¬æ¼ç®æ³ï¼ééä¸»åå»ºè­°è¨åºé«çè§å¯ææè³è¨æ§çè®æ¸ä¾å¢å ä¿¡å¿ãæåå¨å¬éè³æï¼ä¾å¦ MIMIC-III å AmsterdamUMCdbï¼åä¿äº¥ä¿å·ç«å¤§å­¸éåæ¯ç´é«å­¸ä¸­å¿ (OSUWMC) çå°æè³æä¸­é©è­äºææåºçæ¨¡åãå¯¦é©çµæè¡¨æï¼å³æ­çä¸ç¢ºå®æ§å¨å¥é¢åæä½ä¸»å°å°ä½ï¼èææåºçæ¼ç®æ³åªæ¼æåé²çä¸»åææ¸¬æ¹æ³ãæå¾ï¼æåæ ¹æé åè¨ç·´çæ¨¡åå¯¦ä½äºä¸åæè¡çå¯¦é©å®¤ç³»çµ±ï¼ç¨æ¼æ©ææè¡çé æ¸¬åä¸»åææ¸¬ãè¨åºé«çåæ½å¨çæè¡çæ£èå¯ä»¥å¨æè¡ççæ©æé æ¸¬åè¨ºæ·ä¸­åçæ¼è©²ç³»çµ±ã

##### **Toward an Integrated Decision Making Framework for Optimized Stroke Diagnosis with DSA and Treatment under Uncertainty**
2407.16962v1 by Nur Ahmad Khatim, Ahmad Azmul Asmar Irfan, Amaliya Mata'ul Hayah, Mansur M. Arief

This study addresses the challenge of stroke diagnosis and treatment under
uncertainty, a critical issue given the rapid progression and severe
consequences of stroke conditions such as aneurysms, arteriovenous
malformations (AVM), and occlusions. Current diagnostic methods, including
Digital Subtraction Angiography (DSA), face limitations due to high costs and
its invasive nature. To overcome these challenges, we propose a novel approach
using a Partially Observable Markov Decision Process (POMDP) framework. Our
model integrates advanced diagnostic tools and treatment approaches with a
decision-making algorithm that accounts for the inherent uncertainties in
stroke diagnosis. Our approach combines noisy observations from CT scans,
Siriraj scores, and DSA reports to inform the subsequent treatment options. We
utilize the online solver DESPOT, which employs tree-search methods and
particle filters, to simulate potential future scenarios and guide our
strategies. The results indicate that our POMDP framework balances diagnostic
and treatment objectives, striking a tradeoff between the need for precise
stroke identification via invasive procedures like DSA and the constraints of
limited healthcare resources that necessitate more cost-effective strategies,
such as in-hospital or at-home observation, by relying only relying on
simulation rollouts and not imposing any prior knowledge. Our study offers a
significant contribution by presenting a systematic framework that optimally
integrates diagnostic and treatment processes for stroke and accounting for
various uncertainties, thereby improving care and outcomes in stroke
management.

æè¦ï¼æ¬ç ç©¶æ¢è¨å¨ä¸ç¢ºå®æ§ä¸ä¸­é¢¨çè¨ºæ·åæ²»ççææ°ï¼éæ¯èéå°ä¸­é¢¨çæ³ï¼ä¾å¦åèç¤ãåéèç¸å½¢ (AVM) åé»å¡ï¼çå¿«éé²å±åå´éå¾æèåºç¾çééµåé¡ãç®åçè¨ºæ·æ¹æ³ï¼åæ¬æ¸ä½æ¸å½±è¡ç®¡æå½± (DSA)ï¼ç±æ¼ææ¬é«æåä¾µå¥æ§èé¢è¨éå¶ãçºäºåæéäºææ°ï¼æåæåºäºä¸ç¨®ä½¿ç¨é¨åå¯è§å¯é¦¬å¯å¤«æ±ºç­éç¨ (POMDP) æ¶æ§çæ°ç©æ¹æ³ãæåçæ¨¡åæ´åäºåé²çè¨ºæ·å·¥å·åæ²»çæ¹æ³ï¼ä»¥åä¸åæ±ºç­æ¼ç®æ³ï¼è©²æ¼ç®æ³èéäºä¸­é¢¨è¨ºæ·ä¸­åºæçä¸ç¢ºå®æ§ãæåçåæ³çµåäºä¾èªé»è¦æ·å±¤ææãSiriraj è©åå DSA å ±åçéè¨è§æ¸¬å¼ï¼ä»¥åç¥å¾çºçæ²»çé¸é ãæåå©ç¨ç·ä¸æ±è§£å¨ DESPOTï¼å®æ¡ç¨æ¨¹çæå°æ¹æ³åç²å­æ¿¾æ³¢å¨ï¼æ¨¡æ¬æ½å¨çæªä¾æå¢ä¸¦æå°æåçç­ç¥ãçµæè¡¨æï¼æåç POMDP æ¶æ§å¹³è¡¡äºè¨ºæ·åæ²»çç®æ¨ï¼å¨éé DSA ç­ä¾µå¥æ§ç¨åºç²¾ç¢ºè­å¥ä¸­é¢¨çéæ±èéè¦æ´å·ææ¬æççç­ç¥ï¼ä¾å¦ä½é¢æå±å®¶è§å¯ï¼çé«çè³æºéå¶ä¹éåå¾å¹³è¡¡ï¼åä¾è³´æ¨¡æ¬æ¨åºä¸ä¸æ½å ä»»ä½åé©ç¥è­ãæåçç ç©¶ééæåºä¸åç³»çµ±æ§æ¶æ§ï¼æä½³åæ´åä¸­é¢¨çè¨ºæ·åæ²»çéç¨ä¸¦èéåç¨®ä¸ç¢ºå®æ§ï¼å¾èæ¹åä¸­é¢¨ç®¡ççç§è­·åçµæï¼ååºäºéå¤§è²¢ç»ã

##### **AI-Enhanced 7-Point Checklist for Melanoma Detection Using Clinical Knowledge Graphs and Data-Driven Quantification**
2407.16822v1 by Yuheng Wang, Tianze Yu, Jiayue Cai, Sunil Kalia, Harvey Lui, Z. Jane Wang, Tim K. Lee

The 7-point checklist (7PCL) is widely used in dermoscopy to identify
malignant melanoma lesions needing urgent medical attention. It assigns point
values to seven attributes: major attributes are worth two points each, and
minor ones are worth one point each. A total score of three or higher prompts
further evaluation, often including a biopsy. However, a significant limitation
of current methods is the uniform weighting of attributes, which leads to
imprecision and neglects their interconnections. Previous deep learning studies
have treated the prediction of each attribute with the same importance as
predicting melanoma, which fails to recognize the clinical significance of the
attributes for melanoma. To address these limitations, we introduce a novel
diagnostic method that integrates two innovative elements: a Clinical
Knowledge-Based Topological Graph (CKTG) and a Gradient Diagnostic Strategy
with Data-Driven Weighting Standards (GD-DDW). The CKTG integrates 7PCL
attributes with diagnostic information, revealing both internal and external
associations. By employing adaptive receptive domains and weighted edges, we
establish connections among melanoma's relevant features. Concurrently, GD-DDW
emulates dermatologists' diagnostic processes, who first observe the visual
characteristics associated with melanoma and then make predictions. Our model
uses two imaging modalities for the same lesion, ensuring comprehensive feature
acquisition. Our method shows outstanding performance in predicting malignant
melanoma and its features, achieving an average AUC value of 85%. This was
validated on the EDRA dataset, the largest publicly available dataset for the
7-point checklist algorithm. Specifically, the integrated weighting system can
provide clinicians with valuable data-driven benchmarks for their evaluations.

æè¦ï¼7 é»æª¢æ¥è¡¨ (7PCL) å»£æ³ç¨æ¼ç®èé¡æª¢æ¥ï¼ä»¥è­å¥éè¦ç·æ¥é«çç§è­·çæ¡æ§é»è²ç´ ç¤çç¶ãå®çºä¸åå±¬æ§åéåæ¸ï¼ä¸»è¦å±¬æ§åå¼å©åï¼æ¬¡è¦å±¬æ§åå¼ä¸åãç¸½åçºä¸æä»¥ä¸è¡¨ç¤ºéè¦é²ä¸æ­¥è©ä¼°ï¼éå¸¸åæ¬æ´»æª¢ãç¶èï¼ç®åæ¹æ³çä¸åéå¤§éå¶æ¯å±¬æ§ççµ±ä¸å æ¬ï¼å°è´ä¸ç²¾ç¢ºä¸å¿½ç¥å®åä¹éçç¸äºéè¯ãååçæ·±åº¦å­¸ç¿ç ç©¶å°æ¯åå±¬æ§çé æ¸¬è¦çºèé æ¸¬é»è²ç´ ç¤åç­éè¦ï¼éæªè½èªè­å°å±¬æ§å°é»è²ç´ ç¤çè¨åºæç¾©ãçºäºè§£æ±ºéäºéå¶ï¼æåå¼å¥ä¸ç¨®æ°çè¨ºæ·æ¹æ³ï¼çµåäºå©ååµæ°åç´ ï¼åºæ¼è¨åºç¥è­çææ²å (CKTG) åå·ææ¸æé©åå æ¬æ¨æºçæ¢¯åº¦è¨ºæ·ç­ç¥ (GD-DDW)ãCKTG å° 7PCL å±¬æ§èè¨ºæ·ä¿¡æ¯æ´åå¨ä¸èµ·ï¼æ­ç¤ºäºå§é¨åå¤é¨éè¯ãééæ¡ç¨èªé©ææåååå æ¬éç·£ï¼æåå»ºç«äºé»è²ç´ ç¤ç¸éç¹å¾µä¹éçè¯ç¹«ãåæï¼GD-DDW æ¨¡ä»¿ç®èç§é«ççè¨ºæ·éç¨ï¼ä»åé¦åè§å¯èé»è²ç´ ç¤ç¸éçè¦è¦ºç¹å¾µï¼ç¶å¾ååºé æ¸¬ãæåçæ¨¡åå°åä¸åçç¶ä½¿ç¨å©ç¨®æåæ¹å¼ï¼ç¢ºä¿å¨é¢ç²åç¹å¾µãæåçéç¨®æ¹æ³å¨é æ¸¬æ¡æ§é»è²ç´ ç¤åå¶ç¹å¾µæ¹é¢è¡¨ç¾åºè²ï¼å¹³å AUC å¼éå° 85%ãéå·²å¨ EDRA æ¸æéä¸å¾å°é©è­ï¼è©²æ¸æéæ¯ 7 é»æª¢æ¥è¡¨ç®æ³æå¤§çå¬éå¯ç¨æ¸æéãå·é«ä¾èªªï¼éæçå æ¬ç³»çµ±å¯ä»¥çºè¨åºé«çæä¾æå¹å¼çæ¸æé©ååºæºï¼ä¾ä»åè©ä¼°ã

##### **Multimodal Machine Learning in Mental Health: A Survey of Data, Algorithms, and Challenges**
2407.16804v1 by Zahraa Al Sahili, Ioannis Patras, Matthew Purver

The application of machine learning (ML) in detecting, diagnosing, and
treating mental health disorders is garnering increasing attention.
Traditionally, research has focused on single modalities, such as text from
clinical notes, audio from speech samples, or video of interaction patterns.
Recently, multimodal ML, which combines information from multiple modalities,
has demonstrated significant promise in offering novel insights into human
behavior patterns and recognizing mental health symptoms and risk factors.
Despite its potential, multimodal ML in mental health remains an emerging
field, facing several complex challenges before practical applications can be
effectively developed. This survey provides a comprehensive overview of the
data availability and current state-of-the-art multimodal ML applications for
mental health. It discusses key challenges that must be addressed to advance
the field. The insights from this survey aim to deepen the understanding of the
potential and limitations of multimodal ML in mental health, guiding future
research and development in this evolving domain.

æè¦ï¼æ©å¨å­¸ç¿ï¼MLï¼å¨åµæ¸¬ãè¨ºæ·åæ²»çå¿çå¥åº·ç¾çä¸­çæç¨æ­£è¶ä¾è¶åå°éè¦ãå³çµ±ä¸ï¼ç ç©¶èéæ¼å®ä¸æ¨¡å¼ï¼ä¾å¦è¨åºç­è¨ä¸­çæå­ãèªé³æ¨£æ¬ä¸­çé³è¨æäºåæ¨¡å¼çå½±çãæè¿ï¼çµåå¤æ¨¡å¼è³è¨çå¤æ¨¡æ ML å·²å±ç¾åºé¡¯èçæ½åï¼å¯æä¾å°äººé¡è¡çºæ¨¡å¼çæ°è¦è§£ï¼ä¸¦è­å¥å¿çå¥åº·ççåé¢¨éªå å­ãåç®¡å·ææ½åï¼å¿çå¥åº·ä¸­çå¤æ¨¡æ ML ä»æ¯ä¸åæ°èé åï¼å¨å¯¦éæç¨å¯ä»¥ææéç¼ä¹åï¼é¢è¨æ¸é è¤éææ°ãæ¬èª¿æ¥æä¾äºå¿çå¥åº·ä¸­è³æå¯ç¨æ§åç¶åæåé²çå¤æ¨¡æ ML æç¨ä¹å¨é¢æ¦è§ãå®è¨è«äºå¿é è§£æ±ºçééµææ°ï¼ä»¥æ¨åè©²é åçé²æ­¥ãæ¬èª¿æ¥çè¦è§£æ¨å¨å æ·±å°å¤æ¨¡æ ML å¨å¿çå¥åº·ä¸­çæ½ååéå¶ççè§£ï¼å¼å°éåä¸æ·æ¼è®é åæªä¾çç ç©¶åç¼å±ã

##### **Deep Bayesian segmentation for colon polyps: Well-calibrated predictions in medical imaging**
2407.16608v1 by Daniela L. Ramos, Hector J. Hortua

Colorectal polyps are generally benign alterations that, if not identified
promptly and managed successfully, can progress to cancer and cause
affectations on the colon mucosa, known as adenocarcinoma. Today advances in
Deep Learning have demonstrated the ability to achieve significant performance
in image classification and detection in medical diagnosis applications.
Nevertheless, these models are prone to overfitting, and making decisions based
only on point estimations may provide incorrect predictions. Thus, to obtain a
more informed decision, we must consider point estimations along with their
reliable uncertainty quantification. In this paper, we built different Bayesian
neural network approaches based on the flexibility of posterior distribution to
develop semantic segmentation of colorectal polyp images. We found that these
models not only provide state-of-the-art performance on the segmentation of
this medical dataset but also, yield accurate uncertainty estimates. We applied
multiplicative normalized flows(MNF) and reparameterization trick on the UNET,
FPN, and LINKNET architectures tested with multiple backbones in deterministic
and Bayesian versions. We report that the FPN + EfficientnetB7 architecture
with MNF is the most promising option given its IOU of 0.94 and Expected
Calibration Error (ECE) of 0.004, combined with its superiority in identifying
difficult-to-detect colorectal polyps, which is effective in clinical areas
where early detection prevents the development of colon cancer.

æè¦ï¼å¤§è¸æ¯èéå¸¸æ¯è¯æ§çè®ï¼å¦æä¸åæç¼ç¾ä¸¦æåèçï¼å¯è½ææ¼è®æççä¸¦å°è´å¤§è¸ç²èåç´¯ï¼å³èºçãå¦ä»ï¼æ·±åº¦å­¸ç¿çé²å±å·²è­ææè½åå¨é«çè¨ºæ·æç¨ä¸­å¯¦ç¾åååé¡åæª¢æ¸¬çé¡¯èæ§è½ãåç®¡å¦æ­¤ï¼éäºæ¨¡åå®¹æéåº¦æ¬åï¼ä¸¦ä¸ååºæ¼é»ä¼°è¨ååºæ±ºç­å¯è½ææä¾ä¸æ­£ç¢ºçé æ¸¬ãå æ­¤ï¼çºäºç²å¾æ´ææºçæ±ºç­ï¼æåå¿é èæ®é»ä¼°è¨åå¶å¯é çä¸ç¢ºå®æ§éåãå¨æ¬æä¸­ï¼æååºæ¼å¾é©åä½çéæ´»æ§æ§å»ºäºä¸åçè²èæ¯ç¥ç¶ç¶²çµ¡æ¹æ³ï¼ä»¥éç¼å¤§è¸æ¯èååçèªç¾©åå²ãæåç¼ç¾éäºæ¨¡åä¸åå¨éåé«çæ¸æéçåå²ä¸æä¾äºæåé²çæ§è½ï¼èä¸éç¢çäºæºç¢ºçä¸ç¢ºå®æ§ä¼°è¨ãæåå¨ç¢ºå®æ§åè²èæ¯çæ¬ä¸­ä½¿ç¨å¤åä¸»å¹¹æ¸¬è©¦ç UNETãFPN å LINKNET æ¶æ§ä¸æç¨ä¹æ³æ­¸ä¸åæµ (MNF) åéæ°åæ¸åæå·§ãæåå ±åèªªï¼å·æ MNF ç FPN + EfficientnetB7 æ¶æ§æ¯ææå¸æçé¸æï¼å çºå®ç IOU çº 0.94ï¼é æçæ ¡æºèª¤å·® (ECE) çº 0.004ï¼ä¸¦ä¸å¨è­å¥é£ä»¥æª¢æ¸¬çå¤§è¸æ¯èæ¹é¢å·æåªè¶æ§ï¼éå¨æ©ææª¢æ¸¬å¯ä»¥é²æ­¢çµè¸çç¼å±çè¨åºé åæ¯ææçã

##### **A Comparative Study on Patient Language across Therapeutic Domains for Effective Patient Voice Classification in Online Health Discussions**
2407.16593v1 by Giorgos Lysandrou, Roma English Owen, Vanja Popovic, Grant Le Brun, Aryo Pradipta Gema, Beatrice Alex, Elizabeth A. L. Fairley

There exists an invisible barrier between healthcare professionals'
perception of a patient's clinical experience and the reality. This barrier may
be induced by the environment that hinders patients from sharing their
experiences openly with healthcare professionals. As patients are observed to
discuss and exchange knowledge more candidly on social media, valuable insights
can be leveraged from these platforms. However, the abundance of non-patient
posts on social media necessitates filtering out such irrelevant content to
distinguish the genuine voices of patients, a task we refer to as patient voice
classification. In this study, we analyse the importance of linguistic
characteristics in accurately classifying patient voices. Our findings
underscore the essential role of linguistic and statistical text similarity
analysis in identifying common patterns among patient groups. These results
allude to even starker differences in the way patients express themselves at a
disease level and across various therapeutic domains. Additionally, we
fine-tuned a pre-trained Language Model on the combined datasets with similar
linguistic patterns, resulting in a highly accurate automatic patient voice
classification. Being the pioneering study on the topic, our focus on
extracting authentic patient experiences from social media stands as a crucial
step towards advancing healthcare standards and fostering a patient-centric
approach.

æè¦ï¼é«çä¿å¥å°æ¥­äººå¡å°æ¼æ£èè¨åºç¶é©çèªç¥èå¯¦éææ³ä¹éå­å¨èä¸éç¡å½¢çéç¤ãæ­¤éç¤å¯è½æ¯ç±ç°å¢æé æï¼é»ç¤æ£èèé«çä¿å¥å°æ¥­äººå¡å¬éåäº«ä»åçç¶é©ãç±æ¼è§å¯å°æ£èå¨ç¤¾ç¾¤åªé«ä¸æ´å¦çå°è¨è«åäº¤æç¥è­ï¼å æ­¤å¯ä»¥å¾éäºå¹³å°ç²å¾æå¹å¼çè¦è§£ãç¶èï¼ç¤¾ç¾¤åªé«ä¸åæ¥èéæ£èè²¼æï¼å æ­¤æå¿è¦éæ¿¾æéäºä¸ç¸éçå§å®¹ï¼ä»¥ååæ£èççå¯¦è²é³ï¼æåå°æ­¤ä»»åç¨±çºæ£èè²é³åé¡ãå¨æ¬ç ç©¶ä¸­ï¼æååæäºèªè¨ç¹å¾µå¨æºç¢ºåé¡æ£èè²é³ä¸­çéè¦æ§ãæåçç ç©¶çµæå¼·èª¿äºèªè¨åçµ±è¨æå­ç¸ä¼¼æ§åæå¨è­å¥æ£èç¾¤çµä¹éå±åæ¨¡å¼ä¸­çéè¦è§è²ãéäºçµææç¤ºäºæ£èå¨ç¾çå±¤ç´ååç¨®æ²»çé åä¸­è¡¨éèªå·±çæ¹å¼å­å¨èæ´æé¡¯çå·®ç°ãæ­¤å¤ï¼æåæ ¹æå·æé¡ä¼¼èªè¨æ¨¡å¼çåä½µè³æéå¾®èª¿äºé åè¨ç·´å¥½çèªè¨æ¨¡åï¼é²èç¢çé«åº¦æºç¢ºçèªåæ£èè²é³åé¡ãä½çºéé ä¸»é¡çéåµæ§ç ç©¶ï¼æåå°æ³¨æ¼å¾ç¤¾ç¾¤åªé«ä¸­æåçå¯¦çæ£èç¶é©ï¼éæ¯éåæåé«çä¿å¥æ¨æºåå¹é¤ä»¥æ£èçºä¸­å¿çéå¾çééµä¸æ­¥ã

##### **Virtue Ethics For Ethically Tunable Robotic Assistants**
2407.16361v1 by Rajitha Ramanayake, Vivek Nallur

The common consensus is that robots designed to work alongside or serve
humans must adhere to the ethical standards of their operational environment.
To achieve this, several methods based on established ethical theories have
been suggested. Nonetheless, numerous empirical studies show that the ethical
requirements of the real world are very diverse and can change rapidly from
region to region. This eliminates the idea of a universal robot that can fit
into any ethical context. However, creating customised robots for each
deployment, using existing techniques is challenging. This paper presents a way
to overcome this challenge by introducing a virtue ethics inspired
computational method that enables character-based tuning of robots to
accommodate the specific ethical needs of an environment. Using a simulated
elder-care environment, we illustrate how tuning can be used to change the
behaviour of a robot that interacts with an elderly resident in an
ambient-assisted environment. Further, we assess the robot's responses by
consulting ethicists to identify potential shortcomings.

æè¦ï¼ä¸è¬å±è­æ¯ï¼è¨­è¨ç¨æ¼èäººé¡ä¸¦è©å·¥ä½ææåäººé¡çæ©å¨äººå¿é éµå®å¶éä½ç°å¢çéå¾·æ¨æºãçºéææ­¤ç®çï¼å·²æåºå¹¾ç¨®åºæ¼æ¢å®å«ççè«çæ¹æ³ãåç®¡å¦æ­¤ï¼è¨±å¤å¯¦è­ç ç©¶é¡¯ç¤ºï¼ç¾å¯¦ä¸ççéå¾·è¦æ±éå¸¸å¤åï¼ä¸å¯è½å å°åèç°èå¿«éæ¹è®ãéæ¶é¤äºéç¨æ©å¨äººçæ¦å¿µï¼èéç¨æ©å¨äººå¯ä»¥èå¥ä»»ä½éå¾·èçµ¡ãç¶èï¼ä½¿ç¨ç¾ææè¡çºæ¯åé¨ç½²å»ºç«å®¢è£½åæ©å¨äººå·æææ°æ§ãæ¬ææåºäºä¸ç¨®åææ­¤ææ°çæ¹æ³ï¼æ¹æ³æ¯å¼å¥ä¸ç¨®ç¾å¾·å«çåç¼çéç®æ¹æ³ï¼ä½¿æ©å¨äººè½å¤ åºæ¼ç¹è³ªé²è¡èª¿æ´ï¼ä»¥é©æç°å¢çç¹å®éå¾·éæ±ãä½¿ç¨æ¨¡æ¬çé·èç§è­·ç°å¢ï¼æåèªªæå¦ä½ä½¿ç¨èª¿æ´ä¾æ¹è®æ©å¨äººå¨ç°å¢è¼å©ç°å¢ä¸­èå¹´é·ä½æ°äºåçè¡çºãæ­¤å¤ï¼æåè«®è©¢å«çå­¸å®¶ä¾è©ä¼°æ©å¨äººçåæï¼ä»¥æ¾åºæ½å¨çç¼ºé»ã

##### **PhenoFlow: A Human-LLM Driven Visual Analytics System for Exploring Large and Complex Stroke Datasets**
2407.16329v1 by Jaeyoung Kim, Sihyeon Lee, Hyeon Jeon, Keon-Joo Lee, Hee-Joon Bae, Bohyoung Kim, Jinwook Seo

Acute stroke demands prompt diagnosis and treatment to achieve optimal
patient outcomes. However, the intricate and irregular nature of clinical data
associated with acute stroke, particularly blood pressure (BP) measurements,
presents substantial obstacles to effective visual analytics and
decision-making. Through a year-long collaboration with experienced
neurologists, we developed PhenoFlow, a visual analytics system that leverages
the collaboration between human and Large Language Models (LLMs) to analyze the
extensive and complex data of acute ischemic stroke patients. PhenoFlow
pioneers an innovative workflow, where the LLM serves as a data wrangler while
neurologists explore and supervise the output using visualizations and natural
language interactions. This approach enables neurologists to focus more on
decision-making with reduced cognitive load. To protect sensitive patient
information, PhenoFlow only utilizes metadata to make inferences and synthesize
executable codes, without accessing raw patient data. This ensures that the
results are both reproducible and interpretable while maintaining patient
privacy. The system incorporates a slice-and-wrap design that employs temporal
folding to create an overlaid circular visualization. Combined with a linear
bar graph, this design aids in exploring meaningful patterns within irregularly
measured BP data. Through case studies, PhenoFlow has demonstrated its
capability to support iterative analysis of extensive clinical datasets,
reducing cognitive load and enabling neurologists to make well-informed
decisions. Grounded in long-term collaboration with domain experts, our
research demonstrates the potential of utilizing LLMs to tackle current
challenges in data-driven clinical decision-making for acute ischemic stroke
patients.

æè¦ï¼<paragraph>æ¥æ§ä¸­é¢¨éè¦è¿éè¨ºæ·åæ²»çï¼æè½éå°æä½³ççäººæ²»ççµæãç¶èï¼èæ¥æ§ä¸­é¢¨ç¸éçè¨åºè³æè¤éä¸ä¸è¦åï¼ç¹å¥æ¯è¡å£ (BP) æ¸¬éï¼å°ææçè¦è¦ºåæåæ±ºç­å¶å®æ§æéå¤§éç¤ãééèç¶é©è±å¯çç¥ç¶ç§é«å¸«é·éä¸å¹´çåä½ï¼æåéç¼äº PhenoFlowï¼éæ¯ä¸åè¦è¦ºåæç³»çµ±ï¼å©ç¨äººèå¤§åèªè¨æ¨¡å (LLM) ä¹éçåä½ä¾åææ¥æ§ç¼ºè¡æ§ä¸­é¢¨æ£èçå»£æ³ä¸è¤éè³æãPhenoFlow éåµäºä¸ç¨®åµæ°çå·¥ä½æµç¨ï¼å¶ä¸­ LLM æä»»è³ææ´çå¡ï¼èç¥ç¶ç§é«å¸«åä½¿ç¨è¦è¦ºååèªç¶èªè¨äºåä¾æ¢ç´¢åç£ç£è¼¸åºãéç¨®æ¹æ³ä½¿ç¥ç¶ç§é«å¸«è½å¤ æ´å°æ³¨æ¼æ±ºç­å¶å®ï¼åæéä½èªç¥è² æãçºäºä¿è­·ææççäººè³è¨ï¼PhenoFlow åå©ç¨åè³æé²è¡æ¨è«ä¸¦åæå¯å·è¡ç¨å¼ç¢¼ï¼èä¸æå­ååå§çäººè³æãéç¢ºä¿äºçµææ¢å¯éç¾åå¯è§£éï¼åæç¶­è­·çäººçé±ç§ãè©²ç³»çµ±æ¡ç¨åæ®µååè£è¨­è¨ï¼æ¡ç¨æéæºçä¾å»ºç«çå çåå½¢è¦è¦ºåãçµåç·æ§é·æ¢åï¼æ­¤è¨­è¨æå©æ¼æ¢ç´¢ä¸è¦åæ¸¬éè¡å£è³æä¸­çææç¾©æ¨¡å¼ãééæ¡ä¾ç ç©¶ï¼PhenoFlow å·²è­æå¶æ¯æ´å°å»£æ³è¨åºè³æéé²è¡åè¦åæçè½åï¼éä½èªç¥è² æä¸¦ä½¿ç¥ç¶ç§é«å¸«è½å¤ ååºææºçæ±ºç­ãæåçç ç©¶ä»¥èé åå°å®¶é·æåä½çºåºç¤ï¼è­æäºå©ç¨ LLM ä¾æå°ç¶åæ¥æ§ç¼ºè¡æ§ä¸­é¢¨æ£èè³æé©åè¨åºæ±ºç­å¶å®ææ°çæ½åã</paragraph>

##### **Research on Adverse Drug Reaction Prediction Model Combining Knowledge Graph Embedding and Deep Learning**
2407.16715v1 by Yufeng Li, Wenchao Zhao, Bo Dang, Xu Yan, Weimin Wang, Min Gao, Mingxuan Xiao

In clinical treatment, identifying potential adverse reactions of drugs can
help assist doctors in making medication decisions. In response to the problems
in previous studies that features are high-dimensional and sparse, independent
prediction models need to be constructed for each adverse reaction of drugs,
and the prediction accuracy is low, this paper develops an adverse drug
reaction prediction model based on knowledge graph embedding and deep learning,
which can predict experimental results. Unified prediction of adverse drug
reactions covered. Knowledge graph embedding technology can fuse the associated
information between drugs and alleviate the shortcomings of high-dimensional
sparsity in feature matrices, and the efficient training capabilities of deep
learning can improve the prediction accuracy of the model. This article builds
an adverse drug reaction knowledge graph based on drug feature data; by
analyzing the embedding effect of the knowledge graph under different embedding
strategies, the best embedding strategy is selected to obtain sample vectors;
and then a convolutional neural network model is constructed to predict adverse
reactions. The results show that under the DistMult embedding model and
400-dimensional embedding strategy, the convolutional neural network model has
the best prediction effect; the average accuracy, F_1 score, recall rate and
area under the curve of repeated experiments are better than the methods
reported in the literature. The obtained prediction model has good prediction
accuracy and stability, and can provide an effective reference for later safe
medication guidance.

æè¦ï¼å¨è¨åºæ²»çä¸­ï¼è­å¥è¥ç©çæ½å¨ä¸è¯åææå©æ¼åå©é«çååºç¨è¥æ±ºç­ãéå°ä»¥å¾ç ç©¶ä¸­ç¹å¾µé«ç¶­ç¨çãéè¦çºæ¯ç¨®è¥ç©çä¸åä¸è¯åæå»ºæ§ç¨ç«é æ¸¬æ¨¡åãä¸é æ¸¬æºç¢ºçä½çåé¡ï¼æ¬æéç¼åºæ¼ç¥è­åè­åµå¥èæ·±åº¦å­¸ç¿çä¸è¯è¥ç©åæé æ¸¬æ¨¡åï¼å¯é æ¸¬å¯¦é©çµæãæ¶µèä¸è¯è¥ç©åæççµ±ä¸é æ¸¬ãç¥è­åè­åµå¥æè¡è½èåè¥ç©éçéè¯è³è¨ï¼ç·©è§£ç¹å¾µç©é£é«ç¶­ç¨ççç¼ºé»ï¼èæ·±åº¦å­¸ç¿çå¼·å¤§è¨ç·´è½åè½æåæ¨¡åé æ¸¬æºç¢ºçãæ¬æå»ºæ§åºæ¼è¥ç©ç¹å¾µè³æçä¸è¯è¥ç©åæç¥è­åè­ï¼ééåæç¥è­åè­å¨ä¸ååµå¥ç­ç¥ä¸çåµå¥ææï¼é¸åæä½³åµå¥ç­ç¥ç²å¾æ¨£æ¬åéï¼åå»ºæ§å·ç©ç¥ç¶ç¶²è·¯æ¨¡åé æ¸¬ä¸è¯åæãçµæé¡¯ç¤ºï¼å¨ DistMult åµå¥æ¨¡åè 400 ç¶­åµå¥ç­ç¥ä¸ï¼å·ç©ç¥ç¶ç¶²è·¯æ¨¡åææä½³é æ¸¬ææï¼éè¤å¯¦é©çå¹³åæºç¢ºçãF_1 å¼ãå¬åçèæ²ç·ä¸é¢ç©ååªæ¼æç»æå ±å°çæ¹æ³ãæç²å¾çé æ¸¬æ¨¡åå·åè¯å¥½çé æ¸¬æºç¢ºçèç©©å®æ§ï¼å¯çºå¾çºå®å¨ç¨è¥æå°æä¾ææçåèä¾æã

##### **Artificial Intelligence-based Decision Support Systems for Precision and Digital Health**
2407.16062v1 by Nina Deliu, Bibhas Chakraborty

Precision health, increasingly supported by digital technologies, is a domain
of research that broadens the paradigm of precision medicine, advancing
everyday healthcare. This vision goes hand in hand with the groundbreaking
advent of artificial intelligence (AI), which is reshaping the way we diagnose,
treat, and monitor both clinical subjects and the general population. AI tools
powered by machine learning have shown considerable improvements in a variety
of healthcare domains. In particular, reinforcement learning (RL) holds great
promise for sequential and dynamic problems such as dynamic treatment regimes
and just-in-time adaptive interventions in digital health. In this work, we
discuss the opportunity offered by AI, more specifically RL, to current trends
in healthcare, providing a methodological survey of RL methods in the context
of precision and digital health. Focusing on the area of adaptive
interventions, we expand the methodological survey with illustrative case
studies that used RL in real practice.
  This invited article has undergone anonymous review and is intended as a book
chapter for the volume "Frontiers of Statistics and Data Science" edited by
Subhashis Ghoshal and Anindya Roy for the International Indian Statistical
Association Series on Statistics and Data Science, published by Springer. It
covers the material from a short course titled "Artificial Intelligence in
Precision and Digital Health" taught by the author Bibhas Chakraborty at the
IISA 2022 Conference, December 26-30 2022, at the Indian Institute of Science,
Bengaluru.

æè¦ï¼<paragraph>ç²¾æºå¥åº·å¨æ¸ä½ç§æçæ¯æä¸æ¥çæ®åï¼æ¯æ´å±ç²¾æºé«çå¸ç¯çç ç©¶é åï¼ä¿é²æ¥å¸¸ä¿å¥ãéåé¡æ¯èäººå·¥æºæ§ (AI) ççªç ´æ§é²å±æ¯æ¯ç¸éï¼å®æ­£å¨éå¡æåè¨ºæ·ãæ²»çåç£æ§è¨åºåè©¦èåä¸è¬æ°ç¾çæ¹å¼ãç±æ©å¨å­¸ç¿æ¯æ´ç AI å·¥å·å·²å¨åç¨®é«çä¿å¥é åå±ç¾é¡¯èçé²æ­¥ãç¹å¥æ¯ï¼å¼·åå­¸ç¿ (RL) å°åºè²«ååæåé¡ï¼ä¾å¦åææ²»çæ¹æ¡åå³æé©ææ§å¹²é ï¼æ¥µå·ç¼å±åæ¯ãå¨éé å·¥ä½ä¸­ï¼æåæ¢è¨ AIï¼æ´å·é«å°èªªï¼RLï¼çºç¶åé«çä¿å¥è¶¨å¢å¸¶ä¾çå¥æ©ï¼ä¸¦æä¾ RL æ¹æ³å¨ç²¾æºåæ¸ä½å¥åº·é åçæ¹æ³è«èª¿æ¥ãæåå°æ³¨æ¼é©ææ§å¹²é é åï¼ä¸¦ééå¨å¯¦éæç¨ä¸­ä½¿ç¨ RL çèªªææ§æ¡ä¾ç ç©¶æ´å±æ¹æ³è«èª¿æ¥ãéç¯åéæç« å·²ç¶éå¿åå¯©æ¥ï¼ä¸¦ä½çº Subhashis Ghoshal å Anindya Roy ç·¨è¼¯çãçµ±è¨å­¸èè³æç§å­¸åæ²¿ãä¸æ¸çç« ç¯ï¼ç± Springer åºççåéå°åº¦çµ±è¨åæçµ±è¨å­¸èè³æç§å­¸ç³»åå¢æ¸ç¼è¡ãå®æ¶µèäºç±ä½è Bibhas Chakraborty å¨å°åº¦çµ±è¨åæ 2022 å¹´æè­°ï¼2022 å¹´ 12 æ 26 æ¥è³ 30 æ¥ï¼æ¼å°åº¦ç§å­¸é¢ Bengaluru èè¡ï¼ææçãç²¾æºèæ¸ä½å¥åº·ä¸­çäººå·¥æºæ§ãç­æèª²ç¨çææã</paragraph>

##### **GFE-Mamba: Mamba-based AD Multi-modal Progression Assessment via Generative Feature Extraction from MCI**
2407.15719v1 by Zhaojie Fang, Shenghao Zhu, Yifei Chen, Binfeng Zou, Fan Jia, Linwei Qiu, Chang Liu, Yiyu Huang, Xiang Feng, Feiwei Qin, Changmiao Wang, Yeru Wang, Jin Fan, Changbiao Chu, Wan-Zhen Wu, Hu Zhao

Alzheimer's Disease (AD) is an irreversible neurodegenerative disorder that
often progresses from Mild Cognitive Impairment (MCI), leading to memory loss
and significantly impacting patients' lives. Clinical trials indicate that
early targeted interventions for MCI patients can potentially slow or halt the
development and progression of AD. Previous research has shown that accurate
medical classification requires the inclusion of extensive multimodal data,
such as assessment scales and various neuroimaging techniques like Magnetic
Resonance Imaging (MRI) and Positron Emission Tomography (PET). However,
consistently tracking the diagnosis of the same individual over time and
simultaneously collecting multimodal data poses significant challenges. To
address this issue, we introduce GFE-Mamba, a classifier based on Generative
Feature Extraction (GFE). This classifier effectively integrates data from
assessment scales, MRI, and PET, enabling deeper multimodal fusion. It
efficiently extracts both long and short sequence information and incorporates
additional information beyond the pixel space. This approach not only improves
classification accuracy but also enhances the interpretability and stability of
the model. We constructed datasets of over 3000 samples based on the
Alzheimer's Disease Neuroimaging Initiative (ADNI) for a two-step training
process. Our experimental results demonstrate that the GFE-Mamba model is
effective in predicting the conversion from MCI to AD and outperforms several
state-of-the-art methods. Our source code and ADNI dataset processing code are
available at https://github.com/Tinysqua/GFE-Mamba.

æè¦ï¼é¿è²æµ·é»ç (AD) æ¯ä¸ç¨®ä¸å¯éçç¥ç¶éåæ§ç¾çï¼
éå¸¸æå¾è¼åº¦èªç¥éç¤ (MCI) æ¡åï¼å°è´è¨æ¶åæ¸é
ä¸¦å°çæ£ççæ´»ç¢çéå¤§å½±é¿ãè¨åºè©¦é©é¡¯ç¤ºï¼
éå° MCI çæ£çæ©æç®æ¨æ§å¹²é æªæ½ï¼æå¯è½æ¸ç·©æåæ­¢
AD çç¼å±åæ¡åãååçç ç©¶é¡¯ç¤ºï¼ç²¾ç¢ºç
é«çåé¡éè¦ç´å¥å»£æ³çå¤æ¨¡å¼æ¸æï¼
ä¾å¦è©ä¼°éè¡¨ååç¨®ç¥ç¶å½±åæè¡ï¼å¦ç£æ¯é å½± (MRI) åæ­£å­æ·å±¤ææ (PET)ãç¶èï¼
æçºè¿½è¹¤åä¸ä½åé«çè¨ºæ·çµæï¼ä¸¦åææ¶éå¤æ¨¡å¼æ¸æï¼æé æéå¤§çææ°ãçºäº
è§£æ±ºéååé¡ï¼æåå¼å¥äº GFE-Mambaï¼ä¸ç¨®åºæ¼çæç¹å¾µèå (GFE) çåé¡å¨ãæ­¤åé¡å¨æææ´åä¾èª
è©ä¼°éè¡¨ãMRI å PET çæ¸æï¼å¯¦ç¾æ´æ·±å¥çå¤æ¨¡å¼èåãå®
ææçå°èååºé·åºååç­åºåè³è¨ï¼ä¸¦ç´å¥åç´ ç©ºéä»¥å¤çé¡å¤è³è¨ãéç¨®æ¹æ³ä¸åæåäº
åé¡æºç¢ºåº¦ï¼ä¹å¢å¼·äºæ¨¡åçå¯è§£éæ§åç©©å®æ§ãæåæ ¹æ
é¿è²æµ·é»çç¥ç¶å½±åå¡è­°çµç¹ (ADNI) å»ºç«äºè¶é 3000 åæ¨£æ¬çè³æéï¼ç¨æ¼å©éæ®µè¨ç·´
éç¨ãæåçå¯¦é©çµæè­æï¼GFE-Mamba æ¨¡åå¨é æ¸¬å¾ MCI è½è®çº AD ä¸æ¯ææçï¼ä¸¦ä¸åªæ¼å¤ç¨®
æåé²çæ¹æ³ãæåçåå§ç¨å¼ç¢¼å ADNI è³æéèçç¨å¼ç¢¼å¯æ¼ https://github.com/Tinysqua/GFE-Mamba åå¾ã

##### **Synthetic Image Learning: Preserving Performance and Preventing Membership Inference Attacks**
2407.15526v1 by Eugenio Lomurno, Matteo Matteucci

Generative artificial intelligence has transformed the generation of
synthetic data, providing innovative solutions to challenges like data scarcity
and privacy, which are particularly critical in fields such as medicine.
However, the effective use of this synthetic data to train high-performance
models remains a significant challenge. This paper addresses this issue by
introducing Knowledge Recycling (KR), a pipeline designed to optimise the
generation and use of synthetic data for training downstream classifiers. At
the heart of this pipeline is Generative Knowledge Distillation (GKD), the
proposed technique that significantly improves the quality and usefulness of
the information provided to classifiers through a synthetic dataset
regeneration and soft labelling mechanism. The KR pipeline has been tested on a
variety of datasets, with a focus on six highly heterogeneous medical image
datasets, ranging from retinal images to organ scans. The results show a
significant reduction in the performance gap between models trained on real and
synthetic data, with models based on synthetic data outperforming those trained
on real data in some cases. Furthermore, the resulting models show almost
complete immunity to Membership Inference Attacks, manifesting privacy
properties missing in models trained with conventional techniques.

æè¦ï¼çæå¼äººå·¥æºæ§å·²ç¶è½è®äºåæè³æççæï¼æä¾äºåµæ°çè§£æ±ºæ¹æ¡ä¾æå°è³æç¨å°åé±ç§ç­ææ°ï¼éå¨é«å­¸ç­é åç¹å¥éè¦ã
ç¶èï¼ææä½¿ç¨éäºåæè³æä¾è¨ç·´é«æ§è½æ¨¡åä»ç¶æ¯ä¸åéå¤§çææ°ãæ¬æééå¼å¥ç¥è­å¾ªç° (KR) ä¾è§£æ±ºéååé¡ï¼éæ¯ä¸åæ¨å¨åªååæè³æççæåä½¿ç¨ä»¥è¨ç·´ä¸æ¸¸åé¡å¨çç®¡éãéåç®¡éçæ ¸å¿æ¯çæå¼ç¥è­è¸é¤¾ (GKD)ï¼éæ¯ä¸ç¨®æåºçæè¡ï¼å®ééåæè³æéåçåè»æ¨ç±¤æ©å¶é¡¯èæé«äºæä¾çµ¦åé¡å¨çè³è¨çåè³ªåæç¨æ§ãKR ç®¡éå·²ç¶å¨åç¨®è³æéä¸é²è¡äºæ¸¬è©¦ï¼éé»æ¯å­åé«åº¦ç°è³ªçé«å­¸å½±åè³æéï¼ç¯åå¾è¦ç¶²èå½±åå°å¨å®ææãçµæé¡¯ç¤ºï¼å¨çå¯¦è³æååæè³æä¸è¨ç·´çæ¨¡åä¹éçæè½å·®è·é¡¯èç¸®å°ï¼å¨æäºææ³ä¸ï¼åºæ¼åæè³æçæ¨¡ååªæ¼å¨çå¯¦è³æä¸è¨ç·´çæ¨¡åãæ­¤å¤ï¼ç¢ççæ¨¡åé¡¯ç¤ºåºå°æå¡æ¨è«æ»æå¹¾ä¹å®å¨åç«ï¼è¡¨ç¾åºå³çµ±æè¡è¨ç·´çæ¨¡åä¸­ç¼ºå°çé±ç§å±¬æ§ã

##### **A Multimodal Knowledge-enhanced Whole-slide Pathology Foundation Model**
2407.15362v1 by Yingxue Xu, Yihui Wang, Fengtao Zhou, Jiabo Ma, Shu Yang, Huangjing Lin, Xin Wang, Jiguang Wang, Li Liang, Anjia Han, Ronald Cheong Kin Chan, Hao Chen

Remarkable strides in computational pathology have been made in the
task-agnostic foundation model that advances the performance of a wide array of
downstream clinical tasks. Despite the promising performance, there are still
several challenges. First, prior works have resorted to either vision-only or
vision-captions data, disregarding invaluable pathology reports and gene
expression profiles which respectively offer distinct knowledge for versatile
clinical applications. Second, the current progress in pathology FMs
predominantly concentrates on the patch level, where the restricted context of
patch-level pretraining fails to capture whole-slide patterns. Here we curated
the largest multimodal dataset consisting of H\&E diagnostic whole slide images
and their associated pathology reports and RNA-Seq data, resulting in 26,169
slide-level modality pairs from 10,275 patients across 32 cancer types. To
leverage these data for CPath, we propose a novel whole-slide pretraining
paradigm which injects multimodal knowledge at the whole-slide context into the
pathology FM, called Multimodal Self-TAught PRetraining (mSTAR). The proposed
paradigm revolutionizes the workflow of pretraining for CPath, which enables
the pathology FM to acquire the whole-slide context. To our knowledge, this is
the first attempt to incorporate multimodal knowledge at the slide level for
enhancing pathology FMs, expanding the modelling context from unimodal to
multimodal knowledge and from patch-level to slide-level. To systematically
evaluate the capabilities of mSTAR, extensive experiments including slide-level
unimodal and multimodal applications, are conducted across 7 diverse types of
tasks on 43 subtasks, resulting in the largest spectrum of downstream tasks.
The average performance in various slide-level applications consistently
demonstrates significant performance enhancements for mSTAR compared to SOTA
FMs.

æè¦ï¼<paragraph>å¨è¨ç®ççå­¸ä¸­ï¼ä»»åä¸å¯ç¥åºç¤æ¨¡åå·²åå¾é¡¯èé²å±ï¼å¯æåå»£æ³ä¸æ¸¸è¨åºä»»åçæè½ãåç®¡æè½ä»¤äººæ»¿æï¼ä½ä»æå¹¾åææ°ãé¦åï¼ååçç ç©¶åæ¡ç¨åéå½±åæå½±åæ¨é¡è³æï¼å¿½ç¥äºå¯¶è²´çççå ±åååºå è¡¨ç¾ç¹å¾µï¼èéäºç¹å¾µåå¥çºå¤åè½è¨åºæç¨æä¾äºä¸åçç¥è­ãå¶æ¬¡ï¼çç FM çç¶åé²åº¦ä¸»è¦éä¸­å¨åå¡å±¤ç´ï¼åå¡å±¤ç´é è¨ç·´çåéèæ¯ç¡æ³æ·åå¨åçæ¨¡å¼ãå¨æ­¤ï¼æåç­åäºæå¤§çå¤æ¨¡æè³æéï¼åå« H&E è¨ºæ·å¨åçå½±ååå¶ç¸éççå ±åå RNA-Seq è³æï¼å±ç¢çä¾èª 32 ç¨®ççé¡åç 10,275 åæ£èç 26,169 ååçå±¤ç´æ¨¡æéå°ãçºäºå°éäºè³æç¨æ¼ CPathï¼æåæåºäºä¸ç¨®åµæ°çå¨åçé è¨ç·´ç¯ä¾ï¼å°å¨åçèæ¯çå¤æ¨¡æç¥è­æ³¨å¥çç FMï¼ç¨±çºå¤æ¨¡æèªæé è¨ç·´ (mSTAR)ãææåºçç¯ä¾å¾¹åºæ¹è®äº CPath çé è¨ç·´å·¥ä½æµç¨ï¼ä½¿çç FM è½å¤ ç²åå¨åçèæ¯ãææåæç¥ï¼éæ¯é¦æ¬¡åè©¦å¨åçå±¤ç´ç´å¥å¤æ¨¡æç¥è­ä»¥å¢å¼·çç FMï¼å°å»ºæ¨¡èæ¯å¾å®ä¸æ¨¡æç¥è­æ´å±å°å¤æ¨¡æç¥è­ï¼ä»¥åå¾åå¡å±¤ç´æ´å±å°åçå±¤ç´ãçºäºç³»çµ±æ§å°è©ä¼° mSTAR çåè½ï¼æåå¨ 43 åå­ä»»åä¸­å° 7 ç¨®ä¸åé¡åçä»»åé²è¡äºå»£æ³çå¯¦é©ï¼åæ¬åçå±¤ç´çå®ä¸æ¨¡æåå¤æ¨¡ææç¨ï¼ç¢çäºæå¤§çä¸æ¸¸ä»»åç¯åãå¨åç¨®åçå±¤ç´æç¨ä¸­ï¼å¹³åæè½æçºé¡¯ç¤º mSTAR è SOTA FM ç¸æ¯æé¡¯èçæè½æåã</paragraph>

##### **Genetic Algorithm to Optimize Design of Micro-Surgical Scissors**
2407.15243v1 by Fatemeh Norouziani, Veerash Palanichamy, Shivam Gupta, Onaizah Onaizah

Microrobotics is an attractive area of research as small-scale robots have
the potential to improve the precision and dexterity offered by minimally
invasive surgeries. One example of such a tool is a pair of micro-surgical
scissors that was developed for cutting of tumors or cancerous tissues present
deep inside the body such as in the brain. This task is often deemed difficult
or impossible with conventional robotic tools due to their size and dexterity.
The scissors are designed with two magnets placed a specific distance apart to
maximize deflection and generate cutting forces. However, remote actuation and
size requirements of the micro-surgical scissors limits the force that can be
generated to puncture the tissue. To address the limitation of small output
forces, we use an evolutionary algorithm to further optimize the performance of
the scissors. In this study, the design of the previously developed untethered
micro-surgical scissors has been modified and their performance is enhanced by
determining the optimal position of the magnets as well as the direction of
each magnetic moment. The developed algorithm is successfully applied to a
4-magnet configuration which results in increased net torque. This improvement
in net torque is directly translated into higher cutting forces. The new
configuration generates a cutting force of 58 mN from 80 generations of the
evolutionary algorithm which is a 1.65 times improvement from the original
design. Furthermore, the developed algorithm has the advantage that it can be
deployed with minor modifications to other microrobotic tools and systems,
opening up new possibilities for various medical procedures and applications.

æè¦ï¼å¾®åæ©å¨äººæ¯ä¸åæå¸å¼åçç ç©¶é åï¼å çºå°åæ©å¨äººå·ææé«å¾®åµæè¡çç²¾ç¢ºåº¦åéæ´»æ§ãæ­¤é¡å·¥å·çä¸åç¯ä¾æ¯ä¸å°å¾®åæè¡åªåï¼å¶éç¼ç¨æ¼åé¤æ·±èæ¼é«å§ï¼ä¾å¦å¤§è¦ï¼çè«ç¤æççµç¹ãç±æ¼å³çµ±æ©å¨äººå·¥å·çå°ºå¯¸åéæ´»æ§ï¼æ­¤ä»»åéå¸¸è¢«èªçºå°é£æä¸å¯è½ãæ­¤åªåçè¨­è¨æ¡ç¨å©åç£éµï¼å®åä¹éçè·é¢è¨­å®çºç¹å®å¼ï¼ä»¥æå¤§ååè½ä¸¦ç¢çåååãç¶èï¼å¾®åæè¡åªåçé ç¨è´ååå°ºå¯¸è¦æ±éå¶äºå¯ç¢ççç©¿åºçµç¹åãçºäºè§£æ±ºå°è¼¸åºåçéå¶ï¼æåä½¿ç¨æ¼åæ¼ç®æ³é²ä¸æ­¥æä½³ååªåçæè½ãå¨æ¬ç ç©¶ä¸­ï¼ååéç¼çç¡ç¹«ç¹©å¾®åæè¡åªåçè¨­è¨å·²ä¿®æ¹ï¼ä¸¦ä¸ééç¢ºå®ç£éµçæä½³ä½ç½®ä»¥åæ¯åç£ç©çæ¹åä¾æåå¶æè½ãå·²å°éç¼çæ¼ç®æ³æåæç¨æ¼ 4 ç£éµçµæï¼éæå°è´æ·¨æ­åå¢å ãæ·¨æ­åçæ­¤é æ¹åç´æ¥è½åçºæ´é«çåååãæ°ççµæå¾æ¼åæ¼ç®æ³ç 80 åä¸ä»£ç¢ç 58 mN çåååï¼éæ¯ç¸è¼æ¼åå§è¨­è¨æ¹åäº 1.65 åãæ­¤å¤ï¼å·²éç¼çæ¼ç®æ³å·æå¯ééè¼å¾®ä¿®æ¹é¨ç½²è³å¶ä»å¾®åæ©å¨äººå·¥å·åç³»çµ±çåªé»ï¼çºåç¨®é«çç¨åºåæç¨éåäºæ°çå¯è½æ§ã

##### **MedSAGa: Few-shot Memory Efficient Medical Image Segmentation using Gradient Low-Rank Projection in SAM**
2407.15042v1 by Navyansh Mahla, Annie D'souza, Shubh Gupta, Bhavik Kanekar, Kshitij Sharad Jadhav

The application of large-scale models in medical image segmentation demands
substantial quantities of meticulously annotated data curated by experts along
with high computational resources, both of which are challenges in
resource-poor settings. In this study, we present the Medical Segment Anything
Model with Galore MedSAGa where we adopt the Segment Anything Model (SAM) to
achieve memory-efficient, few-shot medical image segmentation by applying
Gradient Low-Rank Projection GaLore to the parameters of the image encoder of
SAM. Meanwhile, the weights of the prompt encoder and mask decoder undergo full
parameter fine-tuning using standard optimizers. We further assess MedSAGa's
few-shot learning capabilities, reporting on its memory efficiency and
segmentation performance across multiple standard medical image segmentation
datasets. We compare it with several baseline models, including LoRA fine-tuned
SAM (SAMed) and DAE-Former. Experiments across multiple datasets and these
baseline models with different number of images for fine tuning demonstrated
that the GPU memory consumption of MedSAGa is significantly less than that of
the baseline models, achieving an average memory efficiency of 66% more than
current state-of-the-art (SOTA) models for medical image segmentation. The
combination of substantially lower memory requirements and comparable to SOTA
results in few-shot learning for medical image segmentation positions MedSAGa
as an optimal solution for deployment in resource-constrained settings.

æè¦ï¼å¤§åæ¨¡åå¨é«å­¸å½±ååå²ä¸­çæç¨éè¦å¤§éç±å°å®¶ç²¾å¿è¨»è§£çè³æï¼ä»¥åå¤§éçè¨ç®è³æºï¼éå©èå¨è³æºè²§ä¹çç°å¢ä¸­é½æ¯ææ°ãå¨æ¬ç ç©¶ä¸­ï¼æåæåºäºå·æè±å¯é«å­¸å½±ååå²çé«å­¸åå²ä»»ä½æ¨¡å (MedSAGa)ï¼å¶ä¸­æåæ¡ç¨åå²ä»»ä½æ¨¡å (SAM) ä¾ééå°æ¢¯åº¦ä½ç§©æå½± GaLore æç¨æ¼ SAM çå½±åç·¨ç¢¼å¨åæ¸ä¾å¯¦ç¾è¨æ¶é«æçé«çå°éé«å­¸å½±ååå²ãåæï¼æç¤ºç·¨ç¢¼å¨åé®ç½©è§£ç¢¼å¨çæ¬éä½¿ç¨æ¨æºæä½³åå¨é²è¡å®æ´çåæ¸å¾®èª¿ãæåé²ä¸æ­¥è©ä¼°äº MedSAGa çå°éå­¸ç¿è½åï¼å ±åäºå¶å¨å¤åæ¨æºé«å­¸å½±ååå²è³æéä¸­çè¨æ¶é«æçååå²æè½ãæåå°å¶èå¹¾ååºæºæ¨¡åé²è¡æ¯è¼ï¼åæ¬å¾®èª¿ SAM (SAMed) ç LoRA å DAE-Formerãè·¨å¤åè³æéåéäºåºæºæ¨¡åçå¯¦é©ï¼ä½¿ç¨ä¸åæ¸éçå½±åé²è¡å¾®èª¿ï¼è­æ MedSAGa ç GPU è¨æ¶é«æ¶èæé¡¯ä½æ¼åºæºæ¨¡åï¼æ¯ç®åæåé² (SOTA) çé«å­¸å½±ååå²æ¨¡åå¹³åè¨æ¶é«æçé«åº 66%ãå¨å°éå­¸ç¿ä¸­ï¼å¤§å¹éä½è¨æ¶é«éæ±è SOTA ç¸ç¶ççµæï¼ä½¿å¾ MedSAGa æçºå¨è³æºåéç°å¢ä¸­é¨ç½²çæä½³è§£æ±ºæ¹æ¡ã

##### **Preictal Period Optimization for Deep Learning-Based Epileptic Seizure Prediction**
2407.14876v1 by Petros Koutsouvelis, Bartlomiej Chybowski, Alfredo Gonzalez-Sulser, Shima Abdullateef, Javier Escudero

Accurate prediction of epileptic seizures could prove critical for improving
patient safety and quality of life in drug-resistant epilepsy. Although deep
learning-based approaches have shown promising seizure prediction performance
using scalp electroencephalogram (EEG) signals, substantial limitations still
impede their clinical adoption. Furthermore, identifying the optimal preictal
period (OPP) for labeling EEG segments remains a challenge. Here, we not only
develop a competitive deep learning model for seizure prediction but, more
importantly, leverage it to demonstrate a methodology to comprehensively
evaluate the predictive performance in the seizure prediction task. For this,
we introduce a CNN-Transformer deep learning model to detect preictal
spatiotemporal dynamics, alongside a novel Continuous Input-Output Performance
Ratio (CIOPR) metric to determine the OPP. We trained and evaluated our model
on 19 pediatric patients of the open-access CHB-MIT dataset in a
subject-specific manner. Using the OPP of each patient, preictal and interictal
segments were correctly identified with an average sensitivity of 99.31%,
specificity of 95.34%, AUC of 99.35%, and F1- score of 97.46%, while prediction
time averaged 76.8 minutes before onset. Notably, our novel CIOPR metric
allowed outlining the impact of different preictal period definitions on
prediction time, accuracy, output stability, and transition time between
interictal and preictal states in a comprehensive and quantitative way and
highlighted the importance of considering both inter- and intra-patient
variability in seizure prediction.

æè¦ï¼æºç¢ºé æ¸¬ç²çç¼ä½å°æ¼æ¹åè¥ç©ææ§ç²çæ£èçå®å¨æ§èçæ´»åè³ªè³ééè¦ãåç®¡åºæ¼æ·±åº¦å­¸ç¿çæ¹æ³å·²å±ç¾åºä½¿ç¨é ­ç®è¦é»å (EEG) ä¿¡èé²è¡ç²çç¼ä½é æ¸¬çåºè²è¡¨ç¾ï¼ä½ä»æå¯¦è³ªéå¶é»ç¤å¶è¨åºæç¨ãæ­¤å¤ï¼æ¾åºæ¨è¨ EEG çæ®µçæä½³ç¼ä½å (OPP) ææä»ç¶æ¯ä¸é ææ°ãå¨æ­¤ï¼æåä¸åéç¼äºä¸ç¨®ç¨æ¼ç²çç¼ä½é æ¸¬çç«¶ç­æ§æ·±åº¦å­¸ç¿æ¨¡åï¼æ´éè¦çæ¯ï¼å©ç¨å®ä¾å±ç¤ºä¸ç¨®æ¹æ³ï¼ä»¥å¨é¢è©ä¼°ç²çç¼ä½é æ¸¬ä»»åä¸­çé æ¸¬æ§è½ãçºæ­¤ï¼æåå¼å¥äºä¸å CNN-Transformer æ·±åº¦å­¸ç¿æ¨¡åä¾åµæ¸¬ç¼ä½åçæç©ºååå­¸ï¼ä»¥åä¸åæ°çé£çºè¼¸å¥è¼¸åºæè½æ¯ (CIOPR) ææ¨ä¾ç¢ºå® OPPãæåä»¥ä¸»é¡ç¹å®çæ¹å¼ï¼å¨éæ¾åç¨ç CHB-MIT è³æéç 19 ä½å°åæ£èä¸è¨ç·´ä¸¦è©ä¼°æåçæ¨¡åãä½¿ç¨æ¯ä½æ£èç OPPï¼ä»¥å¹³åææåº¦ 99.31%ãç¹ç°åº¦ 95.34%ãAUC 99.35% å F1 åæ¸ 97.46% æ­£ç¢ºè­å¥ç¼ä½ååç¼ä½éæï¼èé æ¸¬æéå¹³åå¨ç¼ä½å 76.8 åéãå¼å¾æ³¨æçæ¯ï¼æåæ°ç©ç CIOPR ææ¨å¯ä»¥å¨é¢ä¸éåå°æ¦è¿°ä¸åç¼ä½åææå®ç¾©å°é æ¸¬æéãæºç¢ºåº¦ãè¼¸åºç©©å®æ§ä»¥åç¼ä½éæåç¼ä½åçæä¹éçè½ææéçå½±é¿ï¼ä¸¦å¼·èª¿å¨ç²çç¼ä½é æ¸¬ä¸­èæ®æ£èéåæ£èå§è®ç°æ§çéè¦æ§ã

##### **PASSION: Towards Effective Incomplete Multi-Modal Medical Image Segmentation with Imbalanced Missing Rates**
2407.14796v1 by Junjie Shi, Caozhi Shang, Zhaobin Sun, Li Yu, Xin Yang, Zengqiang Yan

Incomplete multi-modal image segmentation is a fundamental task in medical
imaging to refine deployment efficiency when only partial modalities are
available. However, the common practice that complete-modality data is visible
during model training is far from realistic, as modalities can have imbalanced
missing rates in clinical scenarios. In this paper, we, for the first time,
formulate such a challenging setting and propose Preference-Aware
Self-diStillatION (PASSION) for incomplete multi-modal medical image
segmentation under imbalanced missing rates. Specifically, we first construct
pixel-wise and semantic-wise self-distillation to balance the optimization
objective of each modality. Then, we define relative preference to evaluate the
dominance of each modality during training, based on which to design task-wise
and gradient-wise regularization to balance the convergence rates of different
modalities. Experimental results on two publicly available multi-modal datasets
demonstrate the superiority of PASSION against existing approaches for modality
balancing. More importantly, PASSION is validated to work as a plug-and-play
module for consistent performance improvement across different backbones. Code
is available at https://github.com/Jun-Jie-Shi/PASSION.

æè¦ï¼ä¸å®æ´çå¤æ¨¡æå½±ååå²æ¯é«å­¸å½±åä¸­çä¸é åºæ¬ä»»åï¼ç¨æ¼å¨åªæé¨åæ¨¡æå¯ç¨æç²¾é²é¨ç½²æçãç¶èï¼å¨æ¨¡åè¨ç·´æéå¯è¦å®æ´æ¨¡æè³æçå¸¸è¦åæ³ä¸¦ä¸åå¯¦éï¼å çºå¨è¨åºå ´æ¯ä¸­ï¼æ¨¡æå¯è½ææä¸å¹³è¡¡çéºæ¼çãå¨æ¬æä¸­ï¼æåé¦æ¬¡å¶å®äºéæ¨£ä¸åå·æææ°æ§çè¨­å®ï¼ä¸¦æåºäºä¸å¹³è¡¡éºæ¼çä¸ä¸å®æ´å¤æ¨¡æé«å­¸å½±ååå²çåå¥½æç¥èªè¸é¤¾ (PASSION)ãå·é«ä¾èªªï¼æåé¦åå»ºæ§åç´ ç´åèªç¾©ç´èªè¸é¤¾ï¼ä»¥å¹³è¡¡æ¯åæ¨¡æçæä½³åç®æ¨ãç¶å¾ï¼æåå®ç¾©ç¸å°åå¥½ä¾è©ä¼°è¨ç·´æéæ¯åæ¨¡æçä¸»å°å°ä½ï¼ä¸¦æ ¹ææ­¤è¨­è¨ä»»åç´åæ¢¯åº¦ç´æ­£ååï¼ä»¥å¹³è¡¡ä¸åæ¨¡æçæ¶æçãå¨å©åå¬éçå¤æ¨¡æè³æéä¸çå¯¦é©çµæè­æäº PASSION åªæ¼ç¾ææ¨¡æå¹³è¡¡æ¹æ³ãæ´éè¦çæ¯ï¼PASSION è¢«é©è­çºå³æå³ç¨æ¨¡çµï¼å¯å¨ä¸åçä¸»å¹¹ä¸­æçºæåæè½ãç¨å¼ç¢¼å¯å¨ https://github.com/Jun-Jie-Shi/PASSION åå¾ã

##### **Improving Representation of High-frequency Components for Medical Foundation Models**
2407.14651v1 by Yuetan Chu, Yilan Zhang, Zhongyi Han, Changchun Yang, Longxi Zhou, Gongning Luo, Xin Gao

Foundation models have recently attracted significant attention for their
impressive generalizability across diverse downstream tasks. However, these
models are demonstrated to exhibit great limitations in representing
high-frequency components and fine-grained details. In many medical imaging
tasks, the precise representation of such information is crucial due to the
inherently intricate anatomical structures, sub-visual features, and complex
boundaries involved. Consequently, the limited representation of prevalent
foundation models can result in significant performance degradation or even
failure in these tasks. To address these challenges, we propose a novel
pretraining strategy, named Frequency-advanced Representation Autoencoder
(Frepa). Through high-frequency masking and low-frequency perturbation combined
with adversarial learning, Frepa encourages the encoder to effectively
represent and preserve high-frequency components in the image embeddings.
Additionally, we introduce an innovative histogram-equalized image masking
strategy, extending the Masked Autoencoder approach beyond ViT to other
architectures such as Swin Transformer and convolutional networks. We develop
Frepa across nine medical modalities and validate it on 32 downstream tasks for
both 2D images and 3D volume data. Without fine-tuning, Frepa can outperform
other self-supervised pretraining methods and, in some cases, even surpasses
task-specific trained models. This improvement is particularly significant for
tasks involving fine-grained details, such as achieving up to a +15% increase
in DSC for retina vessel segmentation and a +7% increase in IoU for lung nodule
detection. Further experiments quantitatively reveal that Frepa enables
superior high-frequency representations and preservation in the embeddings,
underscoring its potential for developing more generalized and universal
medical image foundation models.

æè¦ï¼åºç¤æ¨¡åæè¿å å¶å¨åç¨®ä¸æ¸¸ä»»åä¸­ä»¤äººå°è±¡æ·±å»çæ³åè½åèååéæ³¨ãç¶èï¼éäºæ¨¡åå¨è¡¨ç¤ºé«é »ççµæåç´°ç²åº¦ç´°ç¯æ¹é¢è¡¨ç¾åºå¾å¤§çéå¶ãå¨è¨±å¤é«å­¸å½±åä»»åä¸­ï¼ç±æ¼æ¶ååºæçè¤éè§£åçµæ§ãæ¬¡è¦è¦ºç¹å¾µåè¤éçéçï¼å æ­¤æºç¢ºè¡¨ç¤ºæ­¤é¡ä¿¡æ¯è³ééè¦ãå æ­¤ï¼æµè¡åºç¤æ¨¡åçæéè¡¨ç¤ºå¯è½æå°è´éäºä»»åçæ§è½é¡¯èä¸éçè³å¤±æãçºäºæå°éäºææ°ï¼æåæåºäºä¸ç¨®æ°ç©çé è¨ç·´ç­ç¥ï¼ç¨±çºé »çåé²è¡¨ç¤ºèªç·¨ç¢¼å¨ï¼Frepaï¼ãééé«é »å±è½åä½é »æ¾åèå°ææ§å­¸ç¿ç¸çµåï¼Frepa é¼åµç·¨ç¢¼å¨ææå°è¡¨ç¤ºåä¿çåååµå¥ä¸­çé«é »çµæãæ­¤å¤ï¼æåå¼å¥äºä¸ç¨®åµæ°çç´æ¹ååè¡¡ååå±è½ç­ç¥ï¼å°æ©è½èªç·¨ç¢¼å¨æ¹æ³å¾ ViT æ´å±å°å¶ä»æ¶æ§ï¼ä¾å¦ Swin Transformer åå·ç©ç¶²è·¯ãæåå¨ä¹ç¨®é«çæ¨¡å¼ä¸éç¼äº Frepaï¼ä¸¦å¨ 2D ååå 3D é«ç©æ¸æç 32 åä¸æ¸¸ä»»åä¸å°å¶é²è¡äºé©è­ãå¨ä¸é²è¡å¾®èª¿çææ³ä¸ï¼Frepa å¯ä»¥åªæ¼å¶ä»èªç£ç£é è¨ç·´æ¹æ³ï¼å¨æäºææ³ä¸çè³åªæ¼ä»»åç¹å®è¨ç·´æ¨¡åãå°æ¼æ¶åç´°ç²åº¦ç´°ç¯çä»»åï¼éç¨®æ¹é²å°¤å¶é¡¯èï¼ä¾å¦è¦ç¶²èè¡ç®¡åå²ç DSC å¢å é«é +15%ï¼èºçµç¯æª¢æ¸¬ç IoU å¢å  +7%ãé²ä¸æ­¥çå¯¦é©å®éå°è¡¨æï¼Frepa è½å¤ å¨åµå¥ä¸­å¯¦ç¾åªè¶çé«é »è¡¨ç¤ºåä¿çï¼éå¸é¡¯äºå¶éç¼æ´éç¨åéç¨çé«å­¸å½±ååºç¤æ¨¡åçæ½åã

##### **CVE-LLM : Automatic vulnerability evaluation in medical device industry using large language models**
2407.14640v1 by Rikhiya Ghosh, Oladimeji Farri, Hans-Martin von Stockhausen, Martin Schmitt, George Marica Vasile

The healthcare industry is currently experiencing an unprecedented wave of
cybersecurity attacks, impacting millions of individuals. With the discovery of
thousands of vulnerabilities each month, there is a pressing need to drive the
automation of vulnerability assessment processes for medical devices,
facilitating rapid mitigation efforts. Generative AI systems have
revolutionized various industries, offering unparalleled opportunities for
automation and increased efficiency. This paper presents a solution leveraging
Large Language Models (LLMs) to learn from historical evaluations of
vulnerabilities for the automatic assessment of vulnerabilities in the medical
devices industry. This approach is applied within the portfolio of a single
manufacturer, taking into account device characteristics, including existing
security posture and controls. The primary contributions of this paper are
threefold. Firstly, it provides a detailed examination of the best practices
for training a vulnerability Language Model (LM) in an industrial context.
Secondly, it presents a comprehensive comparison and insightful analysis of the
effectiveness of Language Models in vulnerability assessment. Finally, it
proposes a new human-in-the-loop framework to expedite vulnerability evaluation
processes.

æè¦ï¼é«çä¿å¥ç¢æ¥­ç®åæ­£ç¶æ­·ä¸åææªæçç¶²è·¯å®å¨æ»ææµªæ½®ï¼å½±é¿äºæ¸ç¾è¬äººãé¨èæ¯æç¼ç¾æ¸ååæ¼æ´ï¼è¿«åéè¦æ¨åé«çå¨ææ¼æ´è©ä¼°ç¨åºçèªååï¼ä»¥å©æ¼å¿«éæ¡åç·©è§£æªæ½ãçæå¼ AI ç³»çµ±å·²ç¶å¾¹åºæ¹è®äºåç¢æ¥­ï¼çºèªåååæé«æçæä¾äºç¡èå«æ¯çæ©æãæ¬ææåºäºä¸ç¨®è§£æ±ºæ¹æ¡ï¼å©ç¨å¤§åèªè¨æ¨¡å (LLM) å¾æ¼æ´çæ­·å²è©ä¼°ä¸­å­¸ç¿ï¼ä»¥èªåè©ä¼°é«çå¨æç¢æ¥­ä¸­çæ¼æ´ãæ­¤æ¹æ³æç¨æ¼å®ä¸è£½é åçç¢åçµåä¸­ï¼èéäºè£ç½®ç¹æ§ï¼åæ¬ç¾æçå®å¨æå¢åæ§å¶æªæ½ãæ¬æçä¸»è¦è²¢ç»æä¸æ¹é¢ãé¦åï¼å®æä¾äºå¨ç¢æ¥­èæ¯ä¸è¨ç·´æ¼æ´èªè¨æ¨¡å (LM) çæä½³å¯¦åè©³ç´°èªªæãå¶æ¬¡ï¼å®æåºäºèªè¨æ¨¡åå¨æ¼æ´è©ä¼°ä¸­çæææ§ä¹å¨é¢æ¯è¼åæ·±å¥åæãæå¾ï¼å®æåºäºä¸åæ°çãäººæ©åä½ãæ¶æ§ï¼ä»¥å éæ¼æ´è©ä¼°ç¨åºã

##### **Two new feature selection methods based on learn-heuristic techniques for breast cancer prediction: A comprehensive analysis**
2407.14631v1 by Kamyab Karimi, Ali Ghodratnama, Reza Tavakkoli-Moghaddam

Breast cancer is not preventable because of its unknown causes. However, its
early diagnosis increases patients' recovery chances. Machine learning (ML) can
be utilized to improve treatment outcomes in healthcare operations while
diminishing costs and time. In this research, we suggest two novel feature
selection (FS) methods based upon an imperialist competitive algorithm (ICA)
and a bat algorithm (BA) and their combination with ML algorithms. This study
aims to enhance diagnostic models' efficiency and present a comprehensive
analysis to help clinical physicians make much more precise and reliable
decisions than before. K-nearest neighbors, support vector machine, decision
tree, Naive Bayes, AdaBoost, linear discriminant analysis, random forest,
logistic regression, and artificial neural network are some of the methods
employed. This paper applied a distinctive integration of evaluation measures
and ML algorithms using the wrapper feature selection based on ICA (WFSIC) and
BA (WFSB) separately. We compared two proposed approaches for the performance
of the classifiers. Also, we compared our best diagnostic model with previous
works reported in the literature survey. Experimentations were performed on the
Wisconsin diagnostic breast cancer dataset. Results reveal that the proposed
framework that uses the BA with an accuracy of 99.12\%, surpasses the framework
using the ICA and most previous works. Additionally, the RF classifier in the
approach of FS based on BA emerges as the best model and outperforms others
regarding its criteria. Besides, the results illustrate the role of our
techniques in reducing the dataset dimensions up to 90\% and increasing the
performance of diagnostic models by over 99\%. Moreover, the result
demonstrates that there are more critical features than the optimum dataset
obtained by proposed FS approaches that have been selected by most ML models.

æè¦ï¼<paragraph>ç±æ¼ä¹³ççæå ä¸æï¼å æ­¤ç¡æ³é é²ãç¶èï¼æ©æè¨ºæ·å¯å¢å æ£èçåº·å¾©æ©æãæ©å¨å­¸ç¿ (ML) å¯ç¨æ¼æ¹åé«çä¿å¥ä½æ¥­ä¸­çæ²»çææï¼åæéä½ææ¬åæéãå¨æ¬ç ç©¶ä¸­ï¼æåæåºå©ç¨®åºæ¼å¸åä¸»ç¾©ç«¶ç­æ¼ç®æ³ (ICA) åèè æ¼ç®æ³ (BA) çæ°ç¹å¾µé¸æ (FS) æ¹æ³ï¼ä»¥åå®åè ML æ¼ç®æ³ççµåãæ¬ç ç©¶æ¨å¨æé«è¨ºæ·æ¨¡åçæçï¼ä¸¦æä¾å¨é¢çåæï¼ä»¥å¹«å©è¨åºé«å¸«ååºæ¯ä»¥å¾æ´ç²¾ç¢ºä¸å¯é çæ±ºç­ãK æè¿é°ãæ¯æ´åéæ©ãæ±ºç­æ¨¹ãæ¨¸ç´ è²æ°ãAdaBoostãç·æ§å¤å¥åæãé¨æ©æ£®æãéè¼¯è¿´æ­¸åäººå·¥ç¥ç¶ç¶²è·¯æ¯ä¸äºææ¡ç¨çæ¹æ³ãæ¬æä½¿ç¨åºæ¼ ICA (WFSIC) å BA (WFSB) çåè£ç¹å¾µé¸æï¼æç¨è©ä¼°æªæ½å ML æ¼ç®æ³çç¨ç¹æ´åãæåæ¯è¼äºå©ç¨®æåºçæ¹æ³ä»¥è©ä¼°åé¡å¨çæè½ãæ­¤å¤ï¼æåå°æåæå¥½çè¨ºæ·æ¨¡åèæç»èª¿æ¥ä¸­å ±å°çååç ç©¶é²è¡æ¯è¼ãå¯¦é©æ¯å¨å¨æ¯åº·è¾è¨ºæ·ä¹³çè³æéä¸é²è¡çãçµæé¡¯ç¤ºï¼ä½¿ç¨ BA çæ¬è­°æ¶æ§æºç¢ºççº 99.12%ï¼åªæ¼ä½¿ç¨ ICA åå¤§å¤æ¸ååç ç©¶çæ¶æ§ãæ­¤å¤ï¼åºæ¼ BA ç FS æ¹æ³ä¸­ç RF åé¡å¨æçºæä½³æ¨¡åï¼ä¸¦å¨æ¨æºæ¹é¢åªæ¼å¶ä»æ¨¡åãæ­¤å¤ï¼çµæèªªæäºæåçæè¡å¨å°è³æéç¶­åº¦æ¸å°å¤é 90% ä»¥åå°è¨ºæ·æ¨¡åçæè½æé«è¶é 99% ä¸­ææ®æ¼çè§è²ãæ­¤å¤ï¼çµæè¡¨æï¼ç±å¤§å¤æ¸ ML æ¨¡åæé¸åçï¼æ¯ç±æåºç FS æ¹æ³æç²å¾çæä½³è³æéæ´éè¦çç¹å¾µéæ´å¤ã</paragraph>

##### **Panoptic Segmentation of Mammograms with Text-To-Image Diffusion Model**
2407.14326v1 by Kun Zhao, Jakub Prokop, Javier Montalt Tordera, Sadegh Mohammadi

Mammography is crucial for breast cancer surveillance and early diagnosis.
However, analyzing mammography images is a demanding task for radiologists, who
often review hundreds of mammograms daily, leading to overdiagnosis and
overtreatment. Computer-Aided Diagnosis (CAD) systems have been developed to
assist in this process, but their capabilities, particularly in lesion
segmentation, remained limited. With the contemporary advances in deep learning
their performance may be improved. Recently, vision-language diffusion models
emerged, demonstrating outstanding performance in image generation and
transferability to various downstream tasks. We aim to harness their
capabilities for breast lesion segmentation in a panoptic setting, which
encompasses both semantic and instance-level predictions. Specifically, we
propose leveraging pretrained features from a Stable Diffusion model as inputs
to a state-of-the-art panoptic segmentation architecture, resulting in accurate
delineation of individual breast lesions. To bridge the gap between natural and
medical imaging domains, we incorporated a mammography-specific MAM-E diffusion
model and BiomedCLIP image and text encoders into this framework. We evaluated
our approach on two recently published mammography datasets, CDD-CESM and
VinDr-Mammo. For the instance segmentation task, we noted 40.25 AP0.1 and 46.82
AP0.05, as well as 25.44 PQ0.1 and 26.92 PQ0.05. For the semantic segmentation
task, we achieved Dice scores of 38.86 and 40.92, respectively.

æè¦ï¼ä¹³æ¿æå½±å°æ¼ä¹³çç£æ§åæ©æè¨ºæ·è³ééè¦ã
ç¶èï¼åæä¹³æ¿æå½±å½±åå°æ¾å°ç§é«å¸«ä¾èªªæ¯ä¸é è±éçä»»åï¼ä»å
æ¯å¤©ç¶å¸¸æª¢é±æ¸ç¾å¼µä¹³æ¿æå½±å½±åï¼å°è´éåº¦è¨ºæ·å
éåº¦æ²»çãé»è¦è¼å©è¨ºæ· (CAD) ç³»çµ±å·²éç¼åºä¾ä»¥
åå©æ­¤æµç¨ï¼ä½å¶åè½ï¼ç¹å¥æ¯å¨çç¶
åå²æ¹é¢ï¼ä»ç¶æéãé¨èæ·±åº¦å­¸ç¿çç¶ä»£é²å±
å¶æ§è½å¯è½æå¾å°æ¹åãæè¿ï¼è¦è¦ºèªè¨æ´æ£æ¨¡å
åºç¾ï¼å¨å½±åçæå
å¯è½ç§»å°åç¨®ä¸æ¸¸ä»»åä¸­å±ç¾åºååºçæ§è½ãæåæ¨å¨å©ç¨å¶
åè½å¨å¨æ¯è¨­ç½®ä¸­é²è¡ä¹³æ¿çç¶åå²ï¼å¶ä¸­
åå«èªç¾©åå¯¦ä¾ç´å¥é æ¸¬ãå·é«ä¾èªªï¼æå
å»ºè­°å©ç¨é åè¨ç·´ç Stable Diffusion æ¨¡åä¸­çç¹å¾µä½çºè¼¸å¥
å°æåé²çå¨æ¯åå²æ¶æ§ï¼å¾èç²¾ç¢ºå°æç¹ªåå¥ä¹³æ¿çç¶ãçºäºå½åèªç¶å
é«å­¸å½±åé åä¹éçå·®è·ï¼æåå°ä¹³æ¿æå½±å°ç¨ç MAM-E æ´æ£
æ¨¡åå BiomedCLIP å½±ååæå­ç·¨ç¢¼å¨ç´å¥éåæ¶æ§ä¸­ãæåè©ä¼°
æåçæ¹æ³å¨å©åæè¿ç¼å¸çä¹³æ¿æå½±è³æé CDD-CESM å
VinDr-Mammoãå°æ¼å¯¦ä¾åå²ä»»åï¼æåæ³¨æå° 40.25 AP0.1 å 46.82
AP0.05ï¼ä»¥å 25.44 PQ0.1 å 26.92 PQ0.05ãå°æ¼èªç¾©åå²
ä»»åï¼æååå¥éå°äº 38.86 å 40.92 ç Dice åæ¸ã

##### **Fair Overlap Number of Balls (Fair-ONB): A Data-Morphology-based Undersampling Method for Bias Reduction**
2407.14210v1 by JosÃ© Daniel Pascual-Triana, Alberto FernÃ¡ndez, Paulo Novais, Francisco Herrera

Given the magnitude of data generation currently, both in quantity and speed,
the use of machine learning is increasingly important. When data include
protected features that might give rise to discrimination, special care must be
taken. Data quality is critical in these cases, as biases in training data can
be reflected in classification models. This has devastating consequences and
fails to comply with current regulations. Data-Centric Artificial Intelligence
proposes dataset modifications to improve its quality. Instance selection via
undersampling can foster balanced learning of classes and protected feature
values in the classifier. When such undersampling is done close to the decision
boundary, the effect on the classifier would be bolstered. This work proposes
Fair Overlap Number of Balls (Fair-ONB), an undersampling method that harnesses
the data morphology of the different data groups (obtained from the combination
of classes and protected feature values) to perform guided undersampling in the
areas where they overlap. It employs attributes of the ball coverage of the
groups, such as the radius, number of covered instances and density, to select
the most suitable areas for undersampling and reduce bias. Results show that
the Fair-ONB method reduces bias with low impact on the classifier's predictive
performance.

æè¦ï¼<paragraph>é´äºå½åæ°æ®çæçè§æ¨¡ï¼æ è®ºæ¯å¨æ°éè¿æ¯éåº¦ä¸ï¼æºå¨å­¦ä¹ çä½¿ç¨åå¾è¶æ¥è¶éè¦ãå½æ°æ®åå«å¯è½å¯¼è´æ­§è§çåä¿æ¤ç¹å¾æ¶ï¼å¿é¡»ç¹å«å°å¿ãå¨è¿äºæåµä¸ï¼æ°æ®è´¨éè³å³éè¦ï¼å ä¸ºè®­ç»æ°æ®ä¸­çåå·®å¯è½ä¼åæ å¨åç±»æ¨¡åä¸­ãè¿ä¼äº§çæ¯ç­æ§çåæï¼å¹¶ä¸ä¸ç¬¦åå½åæ³è§ãä»¥æ°æ®ä¸ºä¸­å¿ç AI æåºäºæ°æ®éä¿®æ¹ä»¥æé«å¶è´¨éãéè¿æ¬ éæ ·è¿è¡å®ä¾éæ©å¯ä»¥ä¿è¿åç±»å¨ä¸­ç±»ååä¿æ¤ç¹å¾å¼çå¹³è¡¡å­¦ä¹ ãå½æ­¤ç±»æ¬ éæ ·æ¥è¿å³ç­è¾¹çæ¶ï¼å¯¹åç±»å¨çå½±åå°å¾å°å å¼ºãè¿é¡¹å·¥ä½æåºäºå¬å¹³éå çæ° (Fair-ONB)ï¼è¿æ¯ä¸ç§æ¬ éæ ·æ¹æ³ï¼å©ç¨ä¸åæ°æ®ç»ï¼ä»ç±»ååä¿æ¤ç¹å¾å¼çç»åä¸­è·å¾ï¼çæ°æ®å½¢æï¼å¨å®ä»¬éå çåºåæ§è¡å¼å¯¼æ¬ éæ ·ãå®éç¨çè¦ççå±æ§ï¼ä¾å¦åå¾ãè¦çå®ä¾æ°åå¯åº¦ï¼ä»¥éæ©æéåæ¬ éæ ·çåºåå¹¶åå°åå·®ãç»æè¡¨æï¼Fair-ONB æ¹æ³åå°äºåå·®ï¼å¯¹åç±»å¨çé¢æµæ§è½å½±åå¾å°ã</paragraph>

##### **Domain-Specific Pretraining of Language Models: A Comparative Study in the Medical Field**
2407.14076v1 by Tobias Kerner

There are many cases where LLMs are used for specific tasks in a single
domain. These usually require less general, but more domain-specific knowledge.
Highly capable, general-purpose state-of-the-art language models like GPT-4 or
Claude-3-opus can often be used for such tasks, but they are very large and
cannot be run locally, even if they were not proprietary. This can be a problem
when working with sensitive data. This paper focuses on domain-specific and
mixed-domain pretraining as potentially more efficient methods than general
pretraining for specialized language models. We will take a look at work
related to domain-specific pretraining, specifically in the medical area, and
compare benchmark results of specialized language models to general-purpose
language models.

æè¦ï¼å¨è¨±å¤ææ³ä¸ï¼LLM è¢«ç¨æ¼å®ä¸é åä¸­çç¹å®ä»»åãéäºä»»åéå¸¸éè¦è¼å°çéç¨ç¥è­ï¼ä½éè¦æ´å¤ç¹å®é åçç¥è­ãåè½å¼·å¤§ãç¨éå»£æ³çææ°èªè¨æ¨¡åï¼ä¾å¦ GPT-4 æ Claude-3-opusï¼éå¸¸å¯ç¨æ¼æ­¤é¡ä»»åï¼ä½å®åéå¸¸é¾å¤§ï¼å³ä½¿ä¸æ¯å°æè»é«ï¼ä¹ç¡æ³å¨æ¬å°å·è¡ãå¨èçææè³ææï¼éå¯è½æé æåé¡ãæ¬æéé»æ¢è¨ç¹å®é ååæ··åé åçé è¨ç·´ï¼ä½çºæ¯ä¸è¬é è¨ç·´æ´ææççå°æ¥­èªè¨æ¨¡åæ½å¨æ¹æ³ãæåå°æ¢è¨èç¹å®é åé è¨ç·´ç¸éçå·¥ä½ï¼ç¹å¥æ¯å¨é«çé åï¼ä¸¦æ¯è¼å°æ¥­èªè¨æ¨¡åèéç¨èªè¨æ¨¡åçåºæºæ¸¬è©¦çµæã

##### **HeCiX: Integrating Knowledge Graphs and Large Language Models for Biomedical Research**
2407.14030v1 by Prerana Sanjay Kulkarni, Muskaan Jain, Disha Sheshanarayana, Srinivasan Parthiban

Despite advancements in drug development strategies, 90% of clinical trials
fail. This suggests overlooked aspects in target validation and drug
optimization. In order to address this, we introduce HeCiX-KG,
Hetionet-Clinicaltrials neXus Knowledge Graph, a novel fusion of data from
ClinicalTrials.gov and Hetionet in a single knowledge graph. HeCiX-KG combines
data on previously conducted clinical trials from ClinicalTrials.gov, and
domain expertise on diseases and genes from Hetionet. This offers a thorough
resource for clinical researchers. Further, we introduce HeCiX, a system that
uses LangChain to integrate HeCiX-KG with GPT-4, and increase its usability.
HeCiX shows high performance during evaluation against a range of clinically
relevant issues, proving this model to be promising for enhancing the
effectiveness of clinical research. Thus, this approach provides a more
holistic view of clinical trials and existing biological data.

æè¦ï¼åç®¡è¥ç©éç¼ç­ç¥æé²å±ï¼90% çè¨åºè©¦é©é½å¤±æäºãéè¡¨ç¤ºå¨ç®æ¨é©è­åè¥ç©æä½³åæ¹é¢æè¢«å¿½ç¥çå±¤é¢ãçºäºè§£æ±ºéååé¡ï¼æåå¼é²äº HeCiX-KGï¼Hetionet-Clinicaltrials neXus ç¥è­åè­ï¼éæ¯ä¸åå° ClinicalTrials.gov å Hetionet çè³æèåå¨å®ä¸ç¥è­åè­ä¸­çæ°ç©èåãHeCiX-KG çµåäºä¾èª ClinicalTrials.gov çååå·è¡è¨åºè©¦é©è³æï¼ä»¥åä¾èª Hetionet çç¾çååºå é åå°æ¥­ç¥è­ãéçºè¨åºç ç©¶äººå¡æä¾äºè±å¯çè³æºãæ­¤å¤ï¼æåå¼é²äº HeCiXï¼ä¸åä½¿ç¨ LangChain å° HeCiX-KG è GPT-4 æ´åï¼ä¸¦æé«å¶å¯ç¨æ§çç³»çµ±ãHeCiX å¨éå°ä¸ç³»åè¨åºç¸éåé¡çè©ä¼°ä¸­è¡¨ç¾åºé«æ§è½ï¼è­æäºéåæ¨¡åæææé«è¨åºç ç©¶çæææ§ãå æ­¤ï¼éç¨®æ¹æ³æä¾äºå°è¨åºè©¦é©åç¾æçç©è³ææ´å¨é¢ççæ³ã

##### **DuoFormer: Leveraging Hierarchical Visual Representations by Local and Global Attention**
2407.13920v1 by Xiaoya Tang, Bodong Zhang, Beatrice S. Knudsen, Tolga Tasdizen

We here propose a novel hierarchical transformer model that adeptly
integrates the feature extraction capabilities of Convolutional Neural Networks
(CNNs) with the advanced representational potential of Vision Transformers
(ViTs). Addressing the lack of inductive biases and dependence on extensive
training datasets in ViTs, our model employs a CNN backbone to generate
hierarchical visual representations. These representations are then adapted for
transformer input through an innovative patch tokenization. We also introduce a
'scale attention' mechanism that captures cross-scale dependencies,
complementing patch attention to enhance spatial understanding and preserve
global perception. Our approach significantly outperforms baseline models on
small and medium-sized medical datasets, demonstrating its efficiency and
generalizability. The components are designed as plug-and-play for different
CNN architectures and can be adapted for multiple applications. The code is
available at https://github.com/xiaoyatang/DuoFormer.git.

æè¦ï¼æåå¨æ­¤æåºä¸åæ°ç©çåå±¤Transformeræ¨¡åï¼å®å·§å¦å°æ´åäºå·ç©ç¥ç¶ç¶²è·¯ (CNN) çç¹å¾µæ·åè½åï¼ä»¥åè¦è¦ºTransformer (ViT) çåé²è¡¨ç¤ºæ½åãéå° ViT ä¸­ç¼ºä¹æ­¸ç´åèª¤åä¾è³´æ¼å»£æ³è¨ç·´è³æéçåé¡ï¼æåçæ¨¡åæ¡ç¨ CNN ä¸»å¹¹ä¾ç¢çåå±¤è¦è¦ºè¡¨ç¤ºãéäºè¡¨ç¤ºæ¥èééåµæ°çåå¡æ¨è¨åï¼èª¿æ´çºTransformerè¼¸å¥ãæåä¹å¼å¥ãå°ºåº¦æ³¨æåãæ©å¶ï¼å®ææè·¨å°ºåº¦ä¾è³´æ§ï¼è£ååå¡æ³¨æåä»¥å¢å¼·ç©ºéçè§£ä¸¦ä¿çå¨å±æç¥ãæåçåæ³å¨å°ååä¸­åçé«å­¸è³æéä¸ï¼æé¡¯åªæ¼åºç·æ¨¡åï¼è­æäºå®çæçåå¯æ¦åæ§ãéäºçµä»¶è¢«è¨­è¨æå³æå³ç¨ï¼é©ç¨æ¼ä¸åç CNN æ¶æ§ï¼ä¸¦ä¸å¯ä»¥èª¿æ´çºå¤ç¨®æç¨ç¨å¼ãç¨å¼ç¢¼å¯å¨ https://github.com/xiaoyatang/DuoFormer.git åå¾ã

##### **Data-Algorithm-Architecture Co-Optimization for Fair Neural Networks on Skin Lesion Dataset**
2407.13896v1 by Yi Sheng, Junhuan Yang, Jinyang Li, James Alaina, Xiaowei Xu, Yiyu Shi, Jingtong Hu, Weiwen Jiang, Lei Yang

As Artificial Intelligence (AI) increasingly integrates into our daily lives,
fairness has emerged as a critical concern, particularly in medical AI, where
datasets often reflect inherent biases due to social factors like the
underrepresentation of marginalized communities and socioeconomic barriers to
data collection. Traditional approaches to mitigating these biases have focused
on data augmentation and the development of fairness-aware training algorithms.
However, this paper argues that the architecture of neural networks, a core
component of Machine Learning (ML), plays a crucial role in ensuring fairness.
We demonstrate that addressing fairness effectively requires a holistic
approach that simultaneously considers data, algorithms, and architecture.
Utilizing Automated ML (AutoML) technology, specifically Neural Architecture
Search (NAS), we introduce a novel framework, BiaslessNAS, designed to achieve
fair outcomes in analyzing skin lesion datasets. BiaslessNAS incorporates
fairness considerations at every stage of the NAS process, leading to the
identification of neural networks that are not only more accurate but also
significantly fairer. Our experiments show that BiaslessNAS achieves a 2.55%
increase in accuracy and a 65.50% improvement in fairness compared to
traditional NAS methods, underscoring the importance of integrating fairness
into neural network architecture for better outcomes in medical AI
applications.

æè¦ï¼é¨èäººå·¥æºæ§ï¼AIï¼æ¥çèå¥æåçæ¥å¸¸çæ´»ï¼å¬å¹³æ§å·²æçºä¸é è³ééè¦çèéï¼ç¹å¥æ¯å¨é«ç AI é åï¼å¶ä¸­ç±æ¼ç¤¾æå ç´ ï¼ä¾å¦éç·£åç¤¾ç¾¤çä»£è¡¨æ§ä¸è¶³åè³ææ¶éçç¤¾æç¶æ¿éç¤ï¼ï¼è³æéå¾å¾åæ åºåºæçåè¦ãæ¸è¼éäºåè¦çå³çµ±æ¹æ³èéæ¼è³ææ´ååéç¼æ³¨éå¬å¹³æ§çè¨ç·´æ¼ç®æ³ãç¶èï¼æ¬æè«è­ç¥ç¶ç¶²è·¯çæ¶æ§ï¼æ©å¨å­¸ç¿ï¼MLï¼çæ ¸å¿çµæé¨åï¼å¨ç¢ºä¿å¬å¹³æ§æ¹é¢ç¼æ®èè³ééè¦çä½ç¨ãæåè­æï¼ææè§£æ±ºå¬å¹³æ§åé¡éè¦ä¸ç¨®å¨é¢çæ¹æ³ï¼è©²æ¹æ³åæèæ®è³æãæ¼ç®æ³åæ¶æ§ãå©ç¨èªåå MLï¼AutoMLï¼æè¡ï¼ç¹å¥æ¯ç¥ç¶æ¶æ§æå°ï¼NASï¼ï¼æåå¼å¥äºä¸åæ°ç©çæ¡æ¶ BiaslessNASï¼æ¨å¨åæç®èçè®è³æéæç²å¾å¬å¹³ççµæãBiaslessNAS å¨ NAS ç¨åºçæ¯åéæ®µé½ç´å¥äºå¬å¹³æ§èéï¼å¾èè­å¥åºä¸åæ´æºç¢ºï¼èä¸ä¹é¡¯èæ´å¬å¹³çç¥ç¶ç¶²è·¯ãæåçå¯¦é©è¡¨æï¼èå³çµ±ç NAS æ¹æ³ç¸æ¯ï¼BiaslessNAS çæºç¢ºåº¦æé«äº 2.55%ï¼å¬å¹³æ§æé«äº 65.50%ï¼éå¸é¡¯äºå°å¬å¹³æ§æ´åå°ç¥ç¶ç¶²è·¯æ¶æ§ä¸­å°æ¼æ¹åé«ç AI æç¨ä¸­ççµæçéè¦æ§ã

##### **APS-USCT: Ultrasound Computed Tomography on Sparse Data via AI-Physic Synergy**
2407.14564v1 by Yi Sheng, Hanchen Wang, Yipei Liu, Junhuan Yang, Weiwen Jiang, Youzuo Lin, Lei Yang

Ultrasound computed tomography (USCT) is a promising technique that achieves
superior medical imaging reconstruction resolution by fully leveraging waveform
information, outperforming conventional ultrasound methods. Despite its
advantages, high-quality USCT reconstruction relies on extensive data
acquisition by a large number of transducers, leading to increased costs,
computational demands, extended patient scanning times, and manufacturing
complexities. To mitigate these issues, we propose a new USCT method called
APS-USCT, which facilitates imaging with sparse data, substantially reducing
dependence on high-cost dense data acquisition. Our APS-USCT method consists of
two primary components: APS-wave and APS-FWI. The APS-wave component, an
encoder-decoder system, preprocesses the waveform data, converting sparse data
into dense waveforms to augment sample density prior to reconstruction. The
APS-FWI component, utilizing the InversionNet, directly reconstructs the speed
of sound (SOS) from the ultrasound waveform data. We further improve the
model's performance by incorporating Squeeze-and-Excitation (SE) Blocks and
source encoding techniques. Testing our method on a breast cancer dataset
yielded promising results. It demonstrated outstanding performance with an
average Structural Similarity Index (SSIM) of 0.8431. Notably, over 82% of
samples achieved an SSIM above 0.8, with nearly 61% exceeding 0.85,
highlighting the significant potential of our approach in improving USCT image
reconstruction by efficiently utilizing sparse data.

æè¦ï¼è¶é³æ³¢é»è¦æ·å±¤æå½± (USCT) æ¯ä¸ç¨®å¾æåæ¯çæè¡ï¼å®è½ééååå©ç¨æ³¢å½¢è³è¨ï¼éæåªç°çé«å­¸å½±åéå»ºè§£æåº¦ï¼è¡¨ç¾åªæ¼å³çµ±è¶é³æ³¢æ¹æ³ãåç®¡æå¶åªé»ï¼é«åè³ªç USCT éå»ºä¾è³´æ¼å¤§éæè½å¨å»£æ³çè³ææ·åï¼å°è´ææ¬å¢å ãéç®éæ±ãçæ£æææéå»¶é·ï¼ä»¥åè£½é è¤éåº¦ãçºäºæ¸è¼éäºåé¡ï¼æåæåºäºä¸ç¨®åçº APS-USCT çæ°å USCT æ¹æ³ï¼å®ä¿é²ä½¿ç¨ç¨çè³æé²è¡å½±åèçï¼å¤§å¹éä½å°é«ææ¬å¯éè³ææ·åçä¾è³´ãæåç APS-USCT æ¹æ³åå«å©åä¸»è¦çµæé¨åï¼APS-wave å APS-FWIãAPS-wave çµä»¶æ¯ä¸åç·¨ç¢¼å¨è§£ç¢¼å¨ç³»çµ±ï¼å®é åèçæ³¢å½¢è³æï¼å°ç¨çè³æè½æçºå¯éæ³¢å½¢ï¼ä»¥å¨éå»ºä¹åå¢å åæ¨£å¯åº¦ãAPS-FWI çµä»¶å©ç¨ InversionNetï¼ç´æ¥å¾è¶é³æ³¢æ³¢å½¢è³æéå»ºé³é (SOS)ãæåé²ä¸æ­¥ééçµå Squeeze-and-Excitation (SE) åå¡ååå§ç·¨ç¢¼æè¡ä¾æåæ¨¡åæè½ãå¨ä¹³çè³æéä¸æ¸¬è©¦æåçéåæ¹æ³ï¼å¾å°äºæåæ¯ççµæãå®å±ç¾äºååºçæè½ï¼çµæ§ç¸ä¼¼æ§ææ¨ (SSIM) å¹³åçº 0.8431ãå¼å¾æ³¨æçæ¯ï¼è¶é 82% çæ¨£æ¬éæ SSIM é«æ¼ 0.8ï¼è¿ 61% è¶é 0.85ï¼çªé¡¯äºæåçæ¹æ³å¨ééææå©ç¨ç¨çè³æä¾æ¹å USCT å½±åéå»ºæ¹é¢çé¡¯èæ½åã

##### **Addressing Imbalance for Class Incremental Learning in Medical Image Classification**
2407.13768v1 by Xuze Hao, Wenqian Ni, Xuhao Jiang, Weimin Tan, Bo Yan

Deep convolutional neural networks have made significant breakthroughs in
medical image classification, under the assumption that training samples from
all classes are simultaneously available. However, in real-world medical
scenarios, there's a common need to continuously learn about new diseases,
leading to the emerging field of class incremental learning (CIL) in the
medical domain. Typically, CIL suffers from catastrophic forgetting when
trained on new classes. This phenomenon is mainly caused by the imbalance
between old and new classes, and it becomes even more challenging with
imbalanced medical datasets. In this work, we introduce two simple yet
effective plug-in methods to mitigate the adverse effects of the imbalance.
First, we propose a CIL-balanced classification loss to mitigate the classifier
bias toward majority classes via logit adjustment. Second, we propose a
distribution margin loss that not only alleviates the inter-class overlap in
embedding space but also enforces the intra-class compactness. We evaluate the
effectiveness of our method with extensive experiments on three benchmark
datasets (CCH5000, HAM10000, and EyePACS). The results demonstrate that our
approach outperforms state-of-the-art methods.

æè¦ï¼æ·±åº¦å·ç©ç¥ç¶ç¶²è·¯å¨é«å­¸å½±ååé¡æ¹é¢åå¾äºéå¤§çªç ´ï¼åè¨­ææé¡å¥çè¨ç·´æ¨£æ¬é½è½åæåå¾ãç¶èï¼å¨ç¾å¯¦ä¸ççé«çå ´æ¯ä¸­ï¼éå¸¸éè¦æçºå­¸ç¿æ°çç¾çï¼å°è´é«çé åä¸­é¡å¥å¢éå­¸ç¿ (CIL) çæ°èé åãéå¸¸ï¼CIL å¨è¨ç·´æ°é¡å¥ææé­åç½é£æ§éºå¿ãéç¨®ç¾è±¡ä¸»è¦æ¯ç±æ¼èé¡å¥åæ°é¡å¥ä¹éçä¸å¹³è¡¡é æçï¼èå¨ä¸å¹³è¡¡çé«çè³æéä¸ï¼éæè®å¾æ´å·ææ°æ§ãå¨éé å·¥ä½ä¸­ï¼æåä»ç´¹äºå©ç¨®ç°¡å®ä½ææçå¤ææ¹æ³ä¾æ¸è¼ä¸å¹³è¡¡çè² é¢å½±é¿ãé¦åï¼æåæåºä¸å CIL å¹³è¡¡åé¡æå¤±ï¼éé logit èª¿æ´ä¾æ¸è¼åé¡å¨å°å¤æ¸é¡å¥çåè¦ãå¶æ¬¡ï¼æåæåºä¸ååä½ééæå¤±ï¼å®ä¸åå¯ä»¥æ¸è¼åµå¥ç©ºéä¸­çé¡ééçï¼éå¯ä»¥å å¼·é¡å§ç·å¯æ§ãæåå¨ä¸ååºæºè³æéï¼CCH5000ãHAM10000 å EyePACSï¼ä¸é²è¡äºå»£æ³çå¯¦é©ï¼è©ä¼°äºæåæ¹æ³çæææ§ãçµæè¡¨æï¼æåçåæ³åªæ¼æåé²çæ¹æ³ã

##### **Shaded Route Planning Using Active Segmentation and Identification of Satellite Images**
2407.13689v1 by Longchao Da, Rohan Chhibba, Rushabh Jaiswal, Ariane Middel, Hua Wei

Heatwaves pose significant health risks, particularly due to prolonged
exposure to high summer temperatures. Vulnerable groups, especially pedestrians
and cyclists on sun-exposed sidewalks, motivate the development of a route
planning method that incorporates somatosensory temperature effects through
shade ratio consideration. This paper is the first to introduce a pipeline that
utilizes segmentation foundation models to extract shaded areas from
high-resolution satellite images. These areas are then integrated into a
multi-layered road map, enabling users to customize routes based on a balance
between distance and shade exposure, thereby enhancing comfort and health
during outdoor activities. Specifically, we construct a graph-based
representation of the road map, where links indicate connectivity and are
updated with shade ratio data for dynamic route planning. This system is
already implemented online, with a video demonstration, and will be
specifically adapted to assist travelers during the 2024 Olympic Games in
Paris.

æè¦ï¼ç±æµªé æé¡¯èçå¥åº·é¢¨éªï¼ç¹å¥æ¯é·æéæ´é²å¨å¤å­£çé«æº«ä¸ãå®¹æåå·å®³çæç¾¤ï¼å°¤å¶æ¯è¡èµ°å¨é½åç´å°äººè¡éä¸çè¡äººåèªè¡è»é¨å£«ï¼ä¿æäºè¦åè·¯ç·æ¹æ³çç¼å±ï¼å¶ä¸­ç´å¥äºééé®é½çèéä¾ç¢ççé«ææº«åº¦å½±é¿ãæ¬æé¦æ¬¡ä»ç´¹ä¸åå©ç¨åå²åºç¤æ¨¡åå¾é«è§£æåº¦è¡æå½±åä¸­æ·åé°å½±ååçç®¡ç·ãéäºååæ¥èæ´åå°å¤å±¤éè·¯å°åä¸­ï¼ä½¿ç¨æ¶è½å¤ æ ¹æè·é¢åé®é½ææ¬ä¹éçå¹³è¡¡ä¾èªè¨è·¯ç·ï¼é²èæåæ¶å¤æ´»åæçèé©åº¦åå¥åº·ãå·é«ä¾èªªï¼æåå»ºæ§äºä¸åä»¥åå½¢çºåºç¤çéè·¯å°åè¡¨å¾µï¼å¶ä¸­é£çµè¡¨ç¤ºé£éæ§ï¼ä¸¦ééé®é½çè³ææ´æ°ä»¥é²è¡åæè·¯ç·è¦åãæ­¤ç³»çµ±å·²ç·ä¸å¯¦ä½ï¼ä¸¦éæå½±çç¤ºç¯ï¼ä¸å°ç¹å¥èª¿æ´ä»¥åå©æå®¢åå  2024 å¹´å·´é»å¥§éã

##### **A Comparative Study on Automatic Coding of Medical Letters with Explainability**
2407.13638v1 by Jamie Glen, Lifeng Han, Paul Rayson, Goran Nenadic

This study aims to explore the implementation of Natural Language Processing
(NLP) and machine learning (ML) techniques to automate the coding of medical
letters with visualised explainability and light-weighted local computer
settings. Currently in clinical settings, coding is a manual process that
involves assigning codes to each condition, procedure, and medication in a
patient's paperwork (e.g., 56265001 heart disease using SNOMED CT code). There
are preliminary research on automatic coding in this field using
state-of-the-art ML models; however, due to the complexity and size of the
models, the real-world deployment is not achieved. To further facilitate the
possibility of automatic coding practice, we explore some solutions in a local
computer setting; in addition, we explore the function of explainability for
transparency of AI models. We used the publicly available MIMIC-III database
and the HAN/HLAN network models for ICD code prediction purposes. We also
experimented with the mapping between ICD and SNOMED CT knowledge bases. In our
experiments, the models provided useful information for 97.98\% of codes. The
result of this investigation can shed some light on implementing automatic
clinical coding in practice, such as in hospital settings, on the local
computers used by clinicians , project page
\url{https://github.com/Glenj01/Medical-Coding}.

æè¦ï¼æ¬ç ç©¶æ¨å¨æ¢è¨å°èªç¶èªè¨èç (NLP) åæ©å¨å­¸ç¿ (ML) æè¡å¯¦ä½æ¼é«çä¿¡å½ç·¨ç¢¼èªååï¼ä¸¦å·åè¦è¦ºåèªªæè½ååè¼éåçæ¬å°é»è¦è¨­å®ãç®åå¨è¨åºç°å¢ä¸­ï¼ç·¨ç¢¼æ¯ä¸ç¨®æåæµç¨ï¼æ¶åçºçæ£æä»¶ä¸­çæ¯é ççãç¨åºåè¥ç©ææ´¾ä»£ç¢¼ (ä¾å¦ï¼ä½¿ç¨ SNOMED CT ä»£ç¢¼ 56265001 è¡¨ç¤ºå¿èç)ãæ­¤é åæä½¿ç¨ææ° ML æ¨¡åé²è¡èªåç·¨ç¢¼çåæ­¥ç ç©¶ï¼ç¶èï¼ç±æ¼æ¨¡åçè¤éæ§åå¤§å°ï¼ä¸¦æªå¯¦ç¾å¯¦éé¨ç½²ãçºäºé²ä¸æ­¥ä¿é²èªåç·¨ç¢¼å¯¦åçå¯è½æ§ï¼æåå¨æ¬å°é»è¦è¨­å®ä¸­æ¢è¨äºä¸äºè§£æ±ºæ¹æ¡ï¼æ­¤å¤ï¼æåæ¢è¨äºèªªæåè½å¨ AI æ¨¡åéæåº¦ä¸­çåè½ãæåä½¿ç¨å¬éç MIMIC-III è³æåº«å HAN/HLAN ç¶²è·¯æ¨¡åé²è¡ ICD ä»£ç¢¼é æ¸¬ãæåéè©¦é©äº ICD å SNOMED CT ç¥è­åº«ä¹éçå°æãå¨æåçå¯¦é©ä¸­ï¼éäºæ¨¡åæä¾äº 97.98% ä»£ç¢¼çæç¨è³è¨ãéé èª¿æ¥çµæå¯ä»¥çºå¯¦åä¸­çèªåè¨åºç·¨ç¢¼å¯¦ä½æä¾ä¸äºè¦è§£ï¼ä¾å¦å¨é«é¢ç°å¢ä¸­ï¼ç±è¨åºé«çä½¿ç¨çæ¬å°é»è¦ï¼å°æ¡é é¢ \url{https://github.com/Glenj01/Medical-Coding}ã

##### **A review of handcrafted and deep radiomics in neurological diseases: transitioning from oncology to clinical neuroimaging**
2407.13813v1 by Elizaveta Lavrova, Henry C. Woodruff, Hamza Khan, Eric Salmon, Philippe Lambin, Christophe Phillips

Medical imaging technologies have undergone extensive development, enabling
non-invasive visualization of clinical information. The traditional review of
medical images by clinicians remains subjective, time-consuming, and prone to
human error. With the recent availability of medical imaging data,
quantification have become important goals in the field. Radiomics, a
methodology aimed at extracting quantitative information from imaging data, has
emerged as a promising approach to uncover hidden biological information and
support decision-making in clinical practice. This paper presents a review of
the radiomic pipeline from the clinical neuroimaging perspective, providing a
detailed overview of each step with practical advice. It discusses the
application of handcrafted and deep radiomics in neuroimaging, stratified by
neurological diagnosis. Although radiomics shows great potential for increasing
diagnostic precision and improving treatment quality in neurology, several
limitations hinder its clinical implementation. Addressing these challenges
requires collaborative efforts, advancements in image harmonization methods,
and the establishment of reproducible and standardized pipelines with
transparent reporting. By overcoming these obstacles, radiomics can
significantly impact clinical neurology and enhance patient care.

æè¦ï¼é«å­¸å½±åæè¡å·²æ­·ç¶å»£æ³ç¼å±ï¼è½ä»¥éä¾µå¥æ§æ¹å¼è¦è¦ºåè¨åºè³è¨ãè¨åºé«å¸«å³çµ±ä¸å°é«å­¸å½±åçæª¢è¦ä»ä¸»è§ãèæï¼ä¸å®¹æç¼çäººçºé¯èª¤ãé¨èé«å­¸å½±åè³æè¿æè®å¾å®¹æåå¾ï¼éåå·²æçºè©²é åçéè¦ç®æ¨ãæ¾å°ç¹å¾µçµå­¸æ¯ä¸ç¨®æ¨å¨å¾å½±åè³æä¸­èåéåè³è¨çæ¹æ³ï¼å·²æçºä¸ç¨®æææ­é²é±èçç©è³è¨ä¸¦æ¯æ´è¨åºå¯¦åæ±ºç­å¶å®çæ¹æ³ãæ¬æåé¡§äºæ¾å°ç¹å¾µçµå­¸ç®¡ç·å¨è¨åºç¥ç¶å½±åçè§é»ï¼ä¸¦æä¾åæ­¥é©çè©³ç´°æ¦è§åå¯¦ç¨å»ºè­°ãæ¬æè¨è«äºäººå·¥è£½ä½åæ·±åº¦æ¾å°ç¹å¾µçµå­¸å¨ç¥ç¶å½±åä¸­çæç¨ï¼ä¸¦ä¾ç¥ç¶è¨ºæ·åå±¤ãåç®¡æ¾å°ç¹å¾µçµå­¸å¨æé«ç¥ç¶ç§è¨ºæ·ç²¾æºåº¦åæ¹åæ²»çåè³ªæ¹é¢é¡¯ç¤ºåºæ¥µå¤§çæ½åï¼ä½ä»æè¥å¹²éå¶é»ç¤å¶è¨åºæç¨ãè¦è§£æ±ºéäºææ°ï¼éè¦åä½åªåãå½±åèª¿åæ¹æ³çé²å±ï¼ä»¥åå»ºç«å·æéæå ±åçå¯è¤è£½ä¸æ¨æºåçç®¡ç·ãééåæéäºéç¤ï¼æ¾å°ç¹å¾µçµå­¸å°è½é¡¯èå½±é¿è¨åºç¥ç¶ç§ä¸¦æåçæ£ç§è­·ã

##### **End-To-End Clinical Trial Matching with Large Language Models**
2407.13463v1 by Dyke Ferber, Lars Hilgers, Isabella C. Wiest, Marie-Elisabeth LeÃmann, Jan Clusmann, Peter Neidlinger, Jiefu Zhu, Georg WÃ¶lflein, Jacqueline Lammert, Maximilian Tschochohei, Heiko BÃ¶hme, Dirk JÃ¤ger, Mihaela Aldea, Daniel Truhn, Christiane HÃ¶per, Jakob Nikolas Kather

Matching cancer patients to clinical trials is essential for advancing
treatment and patient care. However, the inconsistent format of medical free
text documents and complex trial eligibility criteria make this process
extremely challenging and time-consuming for physicians. We investigated
whether the entire trial matching process - from identifying relevant trials
among 105,600 oncology-related clinical trials on clinicaltrials.gov to
generating criterion-level eligibility matches - could be automated using Large
Language Models (LLMs). Using GPT-4o and a set of 51 synthetic Electronic
Health Records (EHRs), we demonstrate that our approach identifies relevant
candidate trials in 93.3% of cases and achieves a preliminary accuracy of 88.0%
when matching patient-level information at the criterion level against a
baseline defined by human experts. Utilizing LLM feedback reveals that 39.3%
criteria that were initially considered incorrect are either ambiguous or
inaccurately annotated, leading to a total model accuracy of 92.7% after
refining our human baseline. In summary, we present an end-to-end pipeline for
clinical trial matching using LLMs, demonstrating high precision in screening
and matching trials to individual patients, even outperforming the performance
of qualified medical doctors. Our fully end-to-end pipeline can operate
autonomously or with human supervision and is not restricted to oncology,
offering a scalable solution for enhancing patient-trial matching in real-world
settings.

æè¦ï¼éå°ççæ£èèè¨åºè©¦é©å°æ¼æ¨é²æ²»çåæ£èç§è­·è³ééè¦ãç¶èï¼é«çèªç±ææ¬æä»¶æ ¼å¼ä¸ä¸è´ä»¥åè¤éçè©¦é©è³æ ¼æ¨æºï¼ä½¿å¾éåéç¨å°é«å¸«ä¾èªªæ¥µå·ææ°æ§ä¸èæãæåèª¿æ¥äºæ´åè©¦é©éå°éç¨ââå¾å¨ clinicaltrials.gov ä¸ 105,600 åèè«ç¤å­¸ç¸éçè¨åºè©¦é©ä¸­æ¾åºç¸éè©¦é©ï¼å°ç¢çæ¨æºå±¤ç´è³æ ¼éå°ââæ¯å¦å¯ä»¥ä½¿ç¨å¤§åèªè¨æ¨¡å (LLM) èªååãæåä½¿ç¨ GPT-4o åä¸å¥ 51 ååæçé»å­å¥åº·ç´é (EHR)ï¼è­ææåçåæ³å¨ 93.3% çæ¡ä¾ä¸­æ¾åºç¸éåé¸è©¦é©ï¼ä¸¦ä¸å¨éå°äººé¡å°å®¶å®ç¾©çåºæºï¼æ¯å°æ¨æºå±¤ç´çæ£èå±¤ç´è³è¨æï¼éå° 88.0% çåæ­¥æºç¢ºåº¦ãå©ç¨ LLM åé¥é¡¯ç¤ºï¼æåè¢«èªçºä¸æ­£ç¢ºç 39.3% æ¨æºï¼ä¸æ¯æ¨¡ç¨å©å¯å°±æ¯è¨»è§£ä¸æºç¢ºï¼å¨æåæ¹åäººé¡åºæºå¾ï¼å°è´æ¨¡åç¸½æºç¢ºåº¦çº 92.7%ãç¸½ä¹ï¼æåæåºä¸åä½¿ç¨ LLM çè¨åºè©¦é©éå°ç«¯å°ç«¯ç®¡ç·ï¼è­æå¨ç¯©é¸åæ¯å°è©¦é©å°åå¥æ£èæå·æé«ç²¾æºåº¦ï¼çè³åªæ¼åæ ¼é«ççè¡¨ç¾ãæåå®å¨çç«¯å°ç«¯ç®¡ç·å¯ä»¥èªä¸»éä½æå¨äººé¡ç£ç£ä¸éä½ï¼ä¸ä¸éæ¼è«ç¤å­¸ï¼æä¾ä¸åå¯æ´åçè§£æ±ºæ¹æ¡ï¼ç¨æ¼æåç¾å¯¦ä¸çä¸­çæ£èè©¦é©éå°ã

##### **CoD, Towards an Interpretable Medical Agent using Chain of Diagnosis**
2407.13301v1 by Junying Chen, Chi Gui, Anningzhe Gao, Ke Ji, Xidong Wang, Xiang Wan, Benyou Wang

The field of medical diagnosis has undergone a significant transformation
with the advent of large language models (LLMs), yet the challenges of
interpretability within these models remain largely unaddressed. This study
introduces Chain-of-Diagnosis (CoD) to enhance the interpretability of
LLM-based medical diagnostics. CoD transforms the diagnostic process into a
diagnostic chain that mirrors a physician's thought process, providing a
transparent reasoning pathway. Additionally, CoD outputs the disease confidence
distribution to ensure transparency in decision-making. This interpretability
makes model diagnostics controllable and aids in identifying critical symptoms
for inquiry through the entropy reduction of confidences. With CoD, we
developed DiagnosisGPT, capable of diagnosing 9604 diseases. Experimental
results demonstrate that DiagnosisGPT outperforms other LLMs on diagnostic
benchmarks. Moreover, DiagnosisGPT provides interpretability while ensuring
controllability in diagnostic rigor.

æè¦ï¼é¨èå¤§åèªè¨æ¨¡å (LLM) çåºç¾ï¼é«çè¨ºæ·é åç¶æ­·äºä¸å ´éå¤§è½åï¼ä½éäºæ¨¡åçå¯è§£éæ§ææ°å¨å¾å¤§ç¨åº¦ä¸ä»æªå¾å°è§£æ±ºãæ¬ç ç©¶å¼å¥äºè¨ºæ·é (CoD) ä¾å¢å¼·åºæ¼ LLM çé«çè¨ºæ·çå¯è§£éæ§ãCoD å°è¨ºæ·éç¨è½æçºä¸åè¨ºæ·éï¼åæ äºé«ççæèéç¨ï¼æä¾äºä¸æ¢éæçæ¨çè·¯å¾ãæ­¤å¤ï¼CoD è¼¸åºäºç¾çç½®ä¿¡åº¦åä½ï¼ä»¥ç¢ºä¿æ±ºç­éæåº¦ãéç¨®å¯è§£éæ§ä½¿æ¨¡åè¨ºæ·å¯æ§ï¼ä¸¦æå©æ¼ééç½®ä¿¡åº¦ççµæ¸ä¾è­å¥éè¦è©¢åçééµççãä½¿ç¨ CoDï¼æåéç¼äº DiagnosisGPTï¼å®è½å¤ è¨ºæ· 9604 ç¨®ç¾çãå¯¦é©çµæè¡¨æï¼DiagnosisGPT å¨è¨ºæ·åºæºä¸åªæ¼å¶ä» LLMãæ­¤å¤ï¼DiagnosisGPT å¨ç¢ºä¿è¨ºæ·å´è¬¹æ§å¯æ§æ§çåææä¾äºå¯è§£éæ§ã

##### **NODER: Image Sequence Regression Based on Neural Ordinary Differential Equations**
2407.13241v1 by Hao Bai, Yi Hong

Regression on medical image sequences can capture temporal image pattern
changes and predict images at missing or future time points. However, existing
geodesic regression methods limit their regression performance by a strong
underlying assumption of linear dynamics, while diffusion-based methods have
high computational costs and lack constraints to preserve image topology. In
this paper, we propose an optimization-based new framework called NODER, which
leverages neural ordinary differential equations to capture complex underlying
dynamics and reduces its high computational cost of handling high-dimensional
image volumes by introducing the latent space. We compare our NODER with two
recent regression methods, and the experimental results on ADNI and ACDC
datasets demonstrate that our method achieves the state-of-the-art performance
in 3D image regression. Our model needs only a couple of images in a sequence
for prediction, which is practical, especially for clinical situations where
extremely limited image time series are available for analysis. Our source code
is available at https://github.com/ZedKing12138/NODER-pytorch.

æè¦ï¼åæ­¸é«çå½±ååºåå¯ä»¥æææéå½±åæ¨¡å¼è®åï¼ä¸¦é æ¸¬éºå¤±ææªä¾æéé»çå½±åãç¶èï¼ç¾æçæ¸¬å°ç·è¿´æ­¸æ¹æ³éå¶å¶è¿´æ­¸æè½ï¼å çºå¶å¼·çä¾è³´ç·æ§åæçåºæ¬åè¨­ï¼èåºæ¼æ´æ£çæ¹æ³åå·æå¾é«çéç®ææ¬ï¼èä¸ç¼ºä¹ä¿çå½±åææ²çç´æãå¨æ¬æä¸­ï¼æåæåºä¸åç¨±çº NODER çåºæ¼æä½³åçå¨æ°æ¶æ§ï¼å®å©ç¨ç¥ç¶å¸¸å¾®åæ¹ç¨å¼ä¾ææè¤éçåºå±¤åæï¼ä¸¦ééå¼å¥æ½å¨ç©ºéä¾éä½èçé«ç¶­åº¦å½±åé«ç©çé«éç®ææ¬ãæåå° NODER èå©ç¨®æè¿çè¿´æ­¸æ¹æ³é²è¡æ¯è¼ï¼å¨ ADNI å ACDC è³æéä¸çå¯¦é©çµæè­æï¼æåçæ¨¡åå¨ 3D å½±åè¿´æ­¸ä¸­åå¾äºæåé²çæè½ãæåçæ¨¡ååªéè¦åºåä¸­å¹¾åå½±åå³å¯é²è¡é æ¸¬ï¼éå¾å¯¦ç¨ï¼ç¹å¥æ¯å¨è¨åºææ³ä¸ï¼æ¥µå¶æéçå½±åæéåºåå¯ä¾åæãæåçåå§ç¨å¼ç¢¼å¯å¨ https://github.com/ZedKing12138/NODER-pytorch åå¾ã

##### **Enhancing the Utility of Privacy-Preserving Cancer Classification using Synthetic Data**
2407.12669v1 by Richard Osuala, Daniel M. Lang, Anneliese Riess, Georgios Kaissis, Zuzanna Szafranowska, Grzegorz Skorupko, Oliver Diaz, Julia A. Schnabel, Karim Lekadir

Deep learning holds immense promise for aiding radiologists in breast cancer
detection. However, achieving optimal model performance is hampered by
limitations in availability and sharing of data commonly associated to patient
privacy concerns. Such concerns are further exacerbated, as traditional deep
learning models can inadvertently leak sensitive training information. This
work addresses these challenges exploring and quantifying the utility of
privacy-preserving deep learning techniques, concretely, (i) differentially
private stochastic gradient descent (DP-SGD) and (ii) fully synthetic training
data generated by our proposed malignancy-conditioned generative adversarial
network. We assess these methods via downstream malignancy classification of
mammography masses using a transformer model. Our experimental results depict
that synthetic data augmentation can improve privacy-utility tradeoffs in
differentially private model training. Further, model pretraining on synthetic
data achieves remarkable performance, which can be further increased with
DP-SGD fine-tuning across all privacy guarantees. With this first in-depth
exploration of privacy-preserving deep learning in breast imaging, we address
current and emerging clinical privacy requirements and pave the way towards the
adoption of private high-utility deep diagnostic models. Our reproducible
codebase is publicly available at https://github.com/RichardObi/mammo_dp.

æè¦ï¼æ·±åº¦å­¸ç¿å¨åå©æ¾å°ç§é«å¸«é²è¡ä¹³çåµæ¸¬æ¹é¢å·æå·¨å¤§çæ½åãç¶èï¼ç±æ¼èçæ£é±ç§ç¸éççæ®ï¼è³æçåå¾èåäº«åå°éå¶ï¼éé»ç¤äºæ¨¡åéå°æä½³æè½ãç±æ¼å³çµ±çæ·±åº¦å­¸ç¿æ¨¡åå¯è½æç¡æéæ´©æ¼ææçè¨ç·´è³è¨ï¼éäºçæ®é²ä¸æ­¥å åãéé ç ç©¶æ¢è¨ä¸¦éåé±ç§ä¿è­·æ·±åº¦å­¸ç¿æè¡çæç¨ï¼å·é«ä¾èªªï¼(i) å·®åé±ç§é¨æ©æ¢¯åº¦ä¸éæ³ (DP-SGD) å (ii) ç±æåæåºçæ¡æ§è«ç¤æ¢ä»¶çæå°æç¶²è·¯æç¢ççå®å¨åæè¨ç·´è³æï¼ä»¥è§£æ±ºéäºææ°ãæåééä½¿ç¨è½æå¨æ¨¡åå°ä¹³æ¿æå½±è«å¡é²è¡ä¸æ¸¸æ¡æ§è«ç¤åé¡ä¾è©ä¼°éäºæ¹æ³ãæåçå¯¦é©çµæé¡¯ç¤ºï¼åæè³ææ´åå¯ä»¥æ¹åå·®åé±ç§æ¨¡åè¨ç·´ä¸­çé±ç§æç¨æ¬è¡¡ãæ­¤å¤ï¼å¨åæè³æä¸é²è¡æ¨¡åé è¨ç·´å¯ç²å¾é¡¯èçæè½ï¼ä¸¦å¯ééå¨ææé±ç§ä¿è­ä¸é²è¡ DP-SGD å¾®èª¿é²ä¸æ­¥æåãééé¦æ¬¡æ·±å¥æ¢è¨ä¹³æ¿å½±åä¸­çé±ç§ä¿è­·æ·±åº¦å­¸ç¿ï¼æåè§£æ±ºäºç¶ååæ°èçè¨åºé±ç§éæ±ï¼ä¸¦çºæ¡ç¨ç§æé«å¯¦ç¨æ§æ·±åº¦è¨ºæ·æ¨¡åéªè·¯ãæåçå¯è¤è£½ç¨å¼ç¢¼åº«å·²å¬éæ¼ https://github.com/RichardObi/mammo_dpã

##### **Abstraction Alignment: Comparing Model and Human Conceptual Relationships**
2407.12543v1 by Angie Boggust, Hyemin Bang, Hendrik Strobelt, Arvind Satyanarayan

Abstraction -- the process of generalizing specific examples into broad
reusable patterns -- is central to how people efficiently process and store
information and apply their knowledge to new data. Promisingly, research has
shown that ML models learn representations that span levels of abstraction,
from specific concepts like "bolo tie" and "car tire" to more general concepts
like "CEO" and "model". However, existing techniques analyze these
representations in isolation, treating learned concepts as independent
artifacts rather than an interconnected web of abstraction. As a result,
although we can identify the concepts a model uses to produce its output, it is
difficult to assess if it has learned a human-aligned abstraction of the
concepts that will generalize to new data. To address this gap, we introduce
abstraction alignment, a methodology to measure the agreement between a model's
learned abstraction and the expected human abstraction. We quantify abstraction
alignment by comparing model outputs against a human abstraction graph, such as
linguistic relationships or medical disease hierarchies. In evaluation tasks
interpreting image models, benchmarking language models, and analyzing medical
datasets, abstraction alignment provides a deeper understanding of model
behavior and dataset content, differentiating errors based on their agreement
with human knowledge, expanding the verbosity of current model quality metrics,
and revealing ways to improve existing human abstractions.

æè¦ï¼æ½è±¡åââå°ç¹å®ç¯ä¾æ¦æ¬çºå»£æ³å¯éè¤ä½¿ç¨çæ¨¡å¼çéç¨ââæ¯äººåææèçåå²å­è³è¨ï¼ä¸¦å°å¶ç¥è­æç¨æ¼æ°è³æçæ ¸å¿ãæå¸æçæ¯ï¼ç ç©¶é¡¯ç¤º ML æ¨¡åå­¸ç¿è·¨è¶æ½è±¡å±¤ç´çè¡¨å¾µï¼å¾ãç´°é å¸¶ãåãæ±½è»è¼ªèãç­å·é«æ¦å¿µå°ãå·è¡é·ãåãæ¨¡åãç­æ´ä¸è¬çæ¦å¿µãç¶èï¼ç¾æçæè¡å­¤ç«å°åæéäºè¡¨å¾µï¼å°å­¸ç¿å°çæ¦å¿µè¦çºç¨ç«çç¢ç©ï¼èä¸æ¯æ½è±¡çç¸äºé£çµç¶²è·¯ãå æ­¤ï¼åç®¡æåå¯ä»¥è­å¥æ¨¡åç¨ä¾ç¢çå¶è¼¸åºçæ¦å¿µï¼ä½å¾é£è©ä¼°å®æ¯å¦å­¸ç¿å°æ¦å¿µçäººé¡å°é½æ½è±¡ï¼éäºæ¦å¿µå°æ¦æ¬å°æ°çè³æãçºäºè§£æ±ºéåå·®è·ï¼æåå¼å¥äºæ½è±¡å°é½ï¼ä¸ç¨®è¡¡éæ¨¡åå­¸ç¿çæ½è±¡èé æçæ½è±¡ä¹éä¸è´æ§çæ¹æ³ãæåééå°æ¨¡åè¼¸åºèäººé¡æ½è±¡åå½¢ï¼ä¾å¦èªè¨éä¿æé«çç¾çå±¤ç´çµæ§ï¼é²è¡æ¯è¼ä¾éåæ½è±¡å°é½ãå¨è§£éå½±åæ¨¡åãåºæºèªè¨æ¨¡åååæé«çè³æéçè©ä¼°ä»»åä¸­ï¼æ½è±¡å°é½æä¾äºå°æ¨¡åè¡çºåè³æéå§å®¹æ´æ·±å¥ççè§£ï¼æ ¹æèäººé¡ç¥è­çä¸è´æ§ååé¯èª¤ï¼æ´å±ç¶åæ¨¡ååè³ªææ¨çè©³ç´°ç¨åº¦ï¼ä¸¦æ­ç¤ºæ¹åç¾æäººé¡æ½è±¡çæ¹æ³ã

##### **Maintenance Strategies for Sewer Pipes with Multi-State Degradation and Deep Reinforcement Learning**
2407.12894v1 by Lisandro A. Jimenez-Roa, Thiago D. SimÃ£o, Zaharah Bukhsh, Tiedo Tinga, Hajo Molegraaf, Nils Jansen, Marielle Stoelinga

Large-scale infrastructure systems are crucial for societal welfare, and
their effective management requires strategic forecasting and intervention
methods that account for various complexities. Our study addresses two
challenges within the Prognostics and Health Management (PHM) framework applied
to sewer assets: modeling pipe degradation across severity levels and
developing effective maintenance policies. We employ Multi-State Degradation
Models (MSDM) to represent the stochastic degradation process in sewer pipes
and use Deep Reinforcement Learning (DRL) to devise maintenance strategies. A
case study of a Dutch sewer network exemplifies our methodology. Our findings
demonstrate the model's effectiveness in generating intelligent, cost-saving
maintenance strategies that surpass heuristics. It adapts its management
strategy based on the pipe's age, opting for a passive approach for newer pipes
and transitioning to active strategies for older ones to prevent failures and
reduce costs. This research highlights DRL's potential in optimizing
maintenance policies. Future research will aim improve the model by
incorporating partial observability, exploring various reinforcement learning
algorithms, and extending this methodology to comprehensive infrastructure
management.

æè¦ï¼å¤§ååºç¤è¨­æ½ç³»çµ±å°ç¤¾æç¦å©è³ééè¦ï¼ææç®¡çéäºç³»çµ±éè¦ç­ç¥æ§é æ¸¬åå¹²é æ¹æ³ï¼ä¸¦èéåç¨®è¤éæ§ãæåçç ç©¶éå°æç¨æ¼ä¸æ°´éè³ç¢çé æ¸¬åå¥åº·ç®¡ç (PHM) æ¡æ¶ä¸­çå©åææ°ï¼å°ä¸åå´éç¨åº¦çç®¡éå£åé²è¡å»ºæ¨¡ï¼ä¸¦å¶å®ææçç¶­è­·æ¿ç­ãæåæ¡ç¨å¤çæå£åæ¨¡å (MSDM) ä¾è¡¨ç¤ºä¸æ°´éç®¡éä¸­çé¨æ©å£åéç¨ï¼ä¸¦ä½¿ç¨æ·±åº¦å¼·åå­¸ç¿ (DRL) ä¾è¨­è¨ç¶­è­·ç­ç¥ãè·è­ä¸æ°´éç¶²è·¯çæ¡ä¾ç ç©¶èªªæäºæåçåæ³ãæåçç ç©¶çµæè­æäºè©²æ¨¡åå¨ç¢çè¶è¶åç¼æ³çæºæ§åç¯çææ¬ç¶­è­·ç­ç¥æ¹é¢çæææ§ãå®æ ¹æç®¡éçå¹´é½¡èª¿æ´å¶ç®¡çç­ç¥ï¼é¸æè¼æ°çç®¡éæ¡ç¨è¢«åæ¹å¼ï¼ä¸¦è½è®çºè¼èç®¡éçç©æ¥µç­ç¥ï¼ä»¥é²æ­¢æéä¸¦éä½ææ¬ãéé ç ç©¶å¼·èª¿äº DRL å¨æä½³åç¶­è­·æ¿ç­æ¹é¢çæ½åãæªä¾çç ç©¶å°æ¨å¨ééç´å¥é¨åå¯è§å¯æ§ãæ¢ç´¢åç¨®å¼·åå­¸ç¿æ¼ç®æ³ï¼ä¸¦å°æ­¤æ¹æ³æ´å±å°å¨é¢çåºç¤è¨­æ½ç®¡çï¼ä¾æ¹åæ¨¡åã

##### **Search Engines, LLMs or Both? Evaluating Information Seeking Strategies for Answering Health Questions**
2407.12468v2 by Marcos FernÃ¡ndez-Pichel, Juan C. Pichel, David E. Losada

Search engines have traditionally served as primary tools for information
seeking. However, the new Large Language Models (LLMs) have recently
demonstrated remarkable capabilities in multiple tasks and, specifically, their
adoption as question answering systems is becoming increasingly prevalent. It
is expected that LLM-based conversational systems and traditional web engines
will continue to coexist in the future, supporting end users in various ways.
But there is a need for more scientific research on the effectiveness of both
types of systems in facilitating accurate information seeking. In this study,
we focus on their merits in answering health questions. We conducted an
extensive study comparing different web search engines, LLMs and
retrieval-augmented (RAG) approaches. Our research reveals intriguing
conclusions. For example, we observed that the quality of webpages potentially
responding to a health question does not decline as we navigate further down
the ranked lists. However, according to our evaluation, web engines are less
accurate than LLMs in finding correct answers to health questions. On the other
hand, LLMs are quite sensitive to the input prompts, and we also found out that
RAG leads to highly effective information seeking methods.

æè¦ï¼æå°å¼æå³çµ±ä¸ä¸ç´ä½çºå°æ¾è³è¨çä¸»è¦å·¥å·ãç¶èï¼æ°çå¤§åèªè¨æ¨¡å (LLM) è¿æå·²å¨å¤é ä»»åä¸­å±ç¾åºåè¶çè½åï¼ç¹å¥æ¯å¶è¢«æ¡ç¨çºåé¡è§£ç­ç³»çµ±æ­£è®å¾è¶ä¾è¶æ®éãé è¨æªä¾åºæ¼ LLM çå°è©±ç³»çµ±åå³çµ±ç¶²è·¯å¼æå°æçºå±å­ï¼ä»¥åç¨®æ¹å¼æ¯æ´æçµä½¿ç¨èãä½éè¦æ´å¤ç§å­¸ç ç©¶ä¾æ¢è¨éå©ç¨®ç³»çµ±å¨ä¿é²æºç¢ºè³è¨æå°æ¹é¢çæè½ãå¨éé ç ç©¶ä¸­ï¼æåå°æ³¨æ¼å®åå¨åç­å¥åº·åé¡æ¹é¢çåªé»ãæåé²è¡äºä¸é å»£æ³çç ç©¶ï¼æ¯è¼äºä¸åçç¶²è·¯æå°å¼æãLLM åæª¢ç´¢å¢å¼· (RAG) æ¹æ³ãæåçç ç©¶æ­ç¤ºäºæè¶£ççµè«ãä¾å¦ï¼æåè§å¯å°ï¼é¨èæåå¨æåæ¸å®ä¸­åä¸çè¦½ï¼å¯è½æåç­å¥åº·åé¡çç¶²é åè³ªä¸¦ä¸æä¸éãç¶èï¼æ ¹ææåçè©ä¼°ï¼ç¶²è·¯å¼æå¨å°æ¾å¥åº·åé¡çæ­£ç¢ºç­æ¡æ¹é¢ä¸å¦ LLM æºç¢ºãå¦ä¸æ¹é¢ï¼LLM å°è¼¸å¥æç¤ºéå¸¸ææï¼æåéç¼ç¾ RAG å°è´é«åº¦ææçè³è¨æå°æ¹æ³ã

##### **Explainable Biomedical Hypothesis Generation via Retrieval Augmented Generation enabled Large Language Models**
2407.12888v1 by Alexander R. Pelletier, Joseph Ramirez, Irsyad Adam, Simha Sankar, Yu Yan, Ding Wang, Dylan Steinecke, Wei Wang, Peipei Ping

The vast amount of biomedical information available today presents a
significant challenge for investigators seeking to digest, process, and
understand these findings effectively. Large Language Models (LLMs) have
emerged as powerful tools to navigate this complex and challenging data
landscape. However, LLMs may lead to hallucinatory responses, making Retrieval
Augmented Generation (RAG) crucial for achieving accurate information. In this
protocol, we present RUGGED (Retrieval Under Graph-Guided Explainable disease
Distinction), a comprehensive workflow designed to support investigators with
knowledge integration and hypothesis generation, identifying validated paths
forward. Relevant biomedical information from publications and knowledge bases
are reviewed, integrated, and extracted via text-mining association analysis
and explainable graph prediction models on disease nodes, forecasting potential
links among drugs and diseases. These analyses, along with biomedical texts,
are integrated into a framework that facilitates user-directed mechanism
elucidation as well as hypothesis exploration through RAG-enabled LLMs. A
clinical use-case demonstrates RUGGED's ability to evaluate and recommend
therapeutics for Arrhythmogenic Cardiomyopathy (ACM) and Dilated Cardiomyopathy
(DCM), analyzing prescribed drugs for molecular interactions and unexplored
uses. The platform minimizes LLM hallucinations, offers actionable insights,
and improves the investigation of novel therapeutics.

æè¦ï¼<paragraph>ç¾ä»å¤§éççç©é«å­¸è³è¨å°è©¦åæææ¶åãèçåçè§£éäºç¼ç¾çç ç©¶äººå¡æ§æéå¤§ææ°ãå¤§åèªè¨æ¨¡å (LLM) å·²æçºå¨éåè¤éä¸å·ææ°æ§çè³æç°å¢ä¸­å°èªçå¼·å¤§å·¥å·ãç¶èï¼LLM å¯è½æå°è´å¹»è¦ºåæï¼éä½¿å¾æª¢ç´¢æ´å¢çæ (RAG) å°æ¼ç²å¾æºç¢ºè³è¨è³ééè¦ãå¨éååå®ä¸­ï¼æåæåº RUGGEDï¼åå½¢å°å¼å¯è§£éç¾çååçæª¢ç´¢ï¼ï¼éæ¯ä¸åå¨é¢çå·¥ä½æµç¨ï¼æ¨å¨æ¯æ´ç ç©¶äººå¡é²è¡ç¥è­æ´åååè¨­ç¢çï¼æ¾åºç¶éé©è­çé²å±è·¯å¾ãä¾èªåºçç©åç¥è­åº«çç¸éçç©é«å­¸è³è¨æééææ¬æ¢åéè¯åæåç¾çç¯é»çå¯è§£éåå½¢é æ¸¬æ¨¡åé²è¡æª¢é±ãæ´ååèåï¼é æ¸¬è¥ç©åç¾çä¹éçæ½å¨éè¯ãéäºåæé£åçç©é«å­¸ææ¬ææ´åå°ä¸åæ¶æ§ä¸­ï¼è©²æ¶æ§ä¿é²ä½¿ç¨èå°åçæ©å¶é¡æï¼ä»¥åéé RAG åç¨ç LLM é²è¡åè¨­æ¢è¨ãä¸åè¨åºä½¿ç¨æ¡ä¾å±ç¤ºäº RUGGED è©ä¼°åæ¨è¦ç¨æ¼å¿å¾å¤±å¸¸æ§å¿èçè® (ACM) åæ´å¼µåå¿èçè® (DCM) çæ²»çæ¹æ³çè½åï¼åæèæ¹è¥ç©çåå­äº¤äºä½ç¨åæªæ¢ç´¢çç¨éãéåå¹³å°å° LLM å¹»è¦ºéå°æä½ï¼æä¾å¯æä½çè¦è§£ï¼ä¸¦æ¹åæ°æ²»çæ¹æ³çç ç©¶ã</paragraph>

##### **Evaluating graph-based explanations for AI-based recommender systems**
2407.12357v1 by Simon Delarue, Astrid Bertrand, Tiphaine Viard

Recent years have witnessed a rapid growth of recommender systems, providing
suggestions in numerous applications with potentially high social impact, such
as health or justice. Meanwhile, in Europe, the upcoming AI Act mentions
\emph{transparency} as a requirement for critical AI systems in order to
``mitigate the risks to fundamental rights''. Post-hoc explanations seamlessly
align with this goal and extensive literature on the subject produced several
forms of such objects, graphs being one of them. Early studies in visualization
demonstrated the graphs' ability to improve user understanding, positioning
them as potentially ideal explanations. However, it remains unclear how
graph-based explanations compare to other explanation designs. In this work, we
aim to determine the effectiveness of graph-based explanations in improving
users' perception of AI-based recommendations using a mixed-methods approach.
We first conduct a qualitative study to collect users' requirements for graph
explanations. We then run a larger quantitative study in which we evaluate the
influence of various explanation designs, including enhanced graph-based ones,
on aspects such as understanding, usability and curiosity toward the AI system.
We find that users perceive graph-based explanations as more usable than
designs involving feature importance. However, we also reveal that textual
explanations lead to higher objective understanding than graph-based designs.
Most importantly, we highlight the strong contrast between participants'
expressed preferences for graph design and their actual ratings using it, which
are lower compared to textual design. These findings imply that meeting
stakeholders' expressed preferences might not alone guarantee ``good''
explanations. Therefore, crafting hybrid designs successfully balancing social
expectations with downstream performance emerges as a significant challenge.

æè¦ï¼<paragraph>è¿å¹´ä¾æ¨è¦ç³»çµ±å¿«éæé·ï¼æä¾åç¨®æç¨ç¨å¼å»ºè­°ï¼å·ææ½å¨çé«ç¤¾æå½±é¿åï¼ä¾å¦å¥åº·æå¸æ³ãåæï¼å¨æ­æ´²ï¼å³å°åºå°çäººå·¥æºæ§æ³æ¡æå°ï¼ééµäººå·¥æºæ§ç³»çµ±éè¦ãéæåº¦ãï¼æè½ãéä½å°åºæ¬æ¬å©çé¢¨éªããäºå¾è§£éèæ­¤ç®æ¨ç¡ç¸«å°é½ï¼ä¸è©²ä¸»é¡çå»£æ³æç»ç¢çäºå¤ç¨®æ­¤é¡ç©ä»¶ï¼å¶ä¸­ä¸ç¨®å°±æ¯åå½¢ãè¦è¦ºåçæ©æç ç©¶è­æäºåå½¢è½å¤ æåä½¿ç¨èçè§£åï¼å°å¶å®ä½çºæ½å¨ççæ³è§£éãç¶èï¼åºæ¼åå½¢çè§£éèå¶ä»è§£éè¨­è¨ç¸æ¯å¦ä½ï¼ç®åä»ä¸æ¸æ¥ãå¨éé å·¥ä½ä¸­ï¼æåæ¨å¨ä½¿ç¨æ··åæ¹æ³ï¼ä¾ç¢ºå®åºæ¼åå½¢çè§£éå¨æåä½¿ç¨èå°åºæ¼äººå·¥æºæ§çå»ºè­°çæç¥ä¸çæææ§ãæåé¦åé²è¡ä¸é å®æ§ç ç©¶ï¼ä»¥æ¶éä½¿ç¨èå°åå½¢è§£éçéæ±ãç¶å¾ï¼æåå·è¡ä¸é è¦æ¨¡æ´å¤§çå®éç ç©¶ï¼è©ä¼°åç¨®è§£éè¨­è¨çå½±é¿ï¼åæ¬å¢å¼·çåºæ¼åå½¢çè¨­è¨ï¼å°äººå·¥æºæ§ç³»çµ±ççè§£ãå¯ç¨æ§åå¥½å¥å¿ç­é¢åãæåç¼ç¾ï¼ä½¿ç¨èèªçºåºæ¼åå½¢çè§£éæ¯æ¶åç¹å¾µéè¦æ§çè¨­è¨æ´å¯ç¨ãç¶èï¼æåä¹ç¼ç¾ï¼æå­è§£éæ¯åºæ¼åå½¢çè¨­è¨å¸¶ä¾æ´é«çå®¢è§çè§£ãæéè¦çæ¯ï¼æåå¼·èª¿äºåèèå°åå½¢è¨­è¨è¡¨éçåå¥½èå¯¦éä½¿ç¨åå½¢è¨­è¨æçè©åä¹éçå¼·çå°æ¯ï¼èæå­è¨­è¨ç¸æ¯ï¼ä½¿ç¨åå½¢è¨­è¨çè©åè¼ä½ãéäºç¼ç¾æç¤ºï¼æ»¿è¶³å©å®³éä¿äººè¡¨éçåå¥½ï¼å¯è½ç¡æ³å®ç¨ä¿è­ãè¯å¥½ãçè§£éãå æ­¤ï¼å·§å¦è¨­è¨æ··åè¨­è¨ï¼æåå¹³è¡¡ç¤¾æææèä¸æ¸¸æè½ï¼æçºä¸é éå¤§çææ°ã</paragraph>

##### **GPT-4V Cannot Generate Radiology Reports Yet**
2407.12176v1 by Yuyang Jiang, Chacha Chen, Dang Nguyen, Benjamin M. Mervak, Chenhao Tan

GPT-4V's purported strong multimodal abilities raise interests in using it to
automate radiology report writing, but there lacks thorough evaluations. In
this work, we perform a systematic evaluation of GPT-4V in generating radiology
reports on two chest X-ray report datasets: MIMIC-CXR and IU X-Ray. We attempt
to directly generate reports using GPT-4V through different prompting
strategies and find that it fails terribly in both lexical metrics and clinical
efficacy metrics. To understand the low performance, we decompose the task into
two steps: 1) the medical image reasoning step of predicting medical condition
labels from images; and 2) the report synthesis step of generating reports from
(groundtruth) conditions. We show that GPT-4V's performance in image reasoning
is consistently low across different prompts. In fact, the distributions of
model-predicted labels remain constant regardless of which groundtruth
conditions are present on the image, suggesting that the model is not
interpreting chest X-rays meaningfully. Even when given groundtruth conditions
in report synthesis, its generated reports are less correct and less
natural-sounding than a finetuned LLaMA-2. Altogether, our findings cast doubt
on the viability of using GPT-4V in a radiology workflow.

æè¦ï¼GPT-4V æè¬å¼·å¤§çå¤æ¨¡æè½åå¼èµ·äºäººåå°ä½¿ç¨å®ä¾èªååæ¾å°å ±åç·¨å¯«çèè¶£ï¼ä½å»ç¼ºä¹å¾¹åºçè©ä¼°ãå¨éé å·¥ä½ä¸­ï¼æåå° GPT-4V å¨å©åè¸é¨ X åå ±åæ¸æéï¼MIMIC-CXR å IU X-Ray ä¸çææ¾å°å ±åé²è¡äºç³»çµ±è©ä¼°ãæååè©¦ééä¸åçæç¤ºç­ç¥ç´æ¥ä½¿ç¨ GPT-4V çæå ±åï¼ä¸¦ç¼ç¾å®å¨è©å½ææ¨åè¨åºçæææ¨ä¸é½è¡¨ç¾å¾å¾ç³ç³ãçºäºäºè§£ä½æ§è½ï¼æåå°ä»»ååè§£çºå©åæ­¥é©ï¼1) å¾ååé æ¸¬é«ççæ³æ¨ç±¤çé«å­¸å½±åæ¨çæ­¥é©ï¼ä»¥å 2) å¾ï¼çå¯¦ï¼æ¢ä»¶çæå ±åçå ±ååææ­¥é©ãæåè¡¨æï¼GPT-4V å¨ååæ¨çä¸­çè¡¨ç¾å§çµä½æ¼ä¸åçæç¤ºãäºå¯¦ä¸ï¼æ¨¡åé æ¸¬æ¨ç±¤çåå¸ä¿æä¸è®ï¼ç¡è«ååä¸å­å¨åªäºçå¯¦æ¢ä»¶ï¼éè¡¨æè©²æ¨¡åæ²æææç¾©å°è§£éè¸é¨ X åãå³ä½¿å¨å ±ååæä¸­çµ¦åºçå¯¦æ¢ä»¶ï¼å¶çæçå ±åä¹ä¸å¦å¾®èª¿å¾ç LLaMA-2 æ­£ç¢ºåèªç¶ãç¸½ä¹ï¼æåçç¼ç¾å°å¨æ¾å°å·¥ä½æµç¨ä¸­ä½¿ç¨ GPT-4V çå¯è¡æ§æåºäºè³ªçã

##### **LLMs-in-the-loop Part-1: Expert Small AI Models for Bio-Medical Text Translation**
2407.12126v1 by Bunyamin Keles, Murat Gunay, Serdar I. Caglar

Machine translation is indispensable in healthcare for enabling the global
dissemination of medical knowledge across languages. However, complex medical
terminology poses unique challenges to achieving adequate translation quality
and accuracy. This study introduces a novel "LLMs-in-the-loop" approach to
develop supervised neural machine translation models optimized specifically for
medical texts. While large language models (LLMs) have demonstrated powerful
capabilities, this research shows that small, specialized models trained on
high-quality in-domain (mostly synthetic) data can outperform even vastly
larger LLMs.
  Custom parallel corpora in six languages were compiled from scientific
articles, synthetically generated clinical documents, and medical texts. Our
LLMs-in-the-loop methodology employs synthetic data generation, rigorous
evaluation, and agent orchestration to enhance performance. We developed small
medical translation models using the MarianMT base model. We introduce a new
medical translation test dataset to standardize evaluation in this domain.
Assessed using BLEU, METEOR, ROUGE, and BERT scores on this test set, our
MarianMT-based models outperform Google Translate, DeepL, and GPT-4-Turbo.
  Results demonstrate that our LLMs-in-the-loop approach, combined with
fine-tuning high-quality, domain-specific data, enables specialized models to
outperform general-purpose and some larger systems. This research, part of a
broader series on expert small models, paves the way for future
healthcare-related AI developments, including deidentification and bio-medical
entity extraction models. Our study underscores the potential of tailored
neural translation models and the LLMs-in-the-loop methodology to advance the
field through improved data generation, evaluation, agent, and modeling
techniques.

æè¦ï¼<paragraph>æ©å¨ç¿»è­¯å¨é«çä¿å¥ä¸­ä¸å¯æç¼ºï¼å çºå®è½è·¨èªè¨å³æ­å¨çé«çç¥è­ãç¶èï¼è¤éçé«å­¸è¡èªå°éæé©ç¶çç¿»è­¯åè³ªåæºç¢ºæ§æ§æç¨ç¹çææ°ãæ¬ç ç©¶ä»ç´¹ä¸ç¨®æ°ç©çãè¿´åä¸­ç LLMãæ¹æ³ï¼ç¨æ¼éç¼å°ééå°é«å­¸ææ¬æä½³åçç£ç£å¼ç¥ç¶æ©å¨ç¿»è­¯æ¨¡åãéç¶å¤§åèªè¨æ¨¡å (LLM) å·²å±ç¾å¼·å¤§çè½åï¼ä½æ¬ç ç©¶é¡¯ç¤ºï¼éå°é«åè³ªé åå§ (å¤§å¤çºåæ) è³æè¨ç·´çå°åç¹æ®åæ¨¡åï¼çè³å¯ä»¥è¶è¶è¦æ¨¡æ´å¤§ç LLMã
  å¾ç§å­¸æç« ãåæç¢ççè¨åºæä»¶åé«å­¸ææ¬ç·¨è­¯äºå­ç¨®èªè¨çå®¢è£½åå¹³è¡èªæåº«ãæåçè¿´åä¸­ LLM æ¹æ³æ¡ç¨åæè³æç¢çãå´è¬¹è©ä¼°åä»£çåèª¿ä¾æåæè½ãæåä½¿ç¨ MarianMT åºç¤æ¨¡åéç¼å°åé«å­¸ç¿»è­¯æ¨¡åãæåå¼å¥æ°çé«å­¸ç¿»è­¯æ¸¬è©¦è³æéï¼ç¨æ¼æ¨æºåæ­¤é åçè©ä¼°ãå¨éåæ¸¬è©¦éä¸­ä½¿ç¨ BLEUãMETEORãROUGE å BERT åæ¸é²è¡è©ä¼°ï¼æåç MarianMT åºç¤æ¨¡ååªæ¼ Google TranslateãDeepL å GPT-4-Turboã
  çµæè­æï¼æåçè¿´åä¸­ LLM æ¹æ³çµåéå°ç¹å®é åé²è¡å¾®èª¿çé«åè³ªè³æï¼ä½¿ç¹æ®åæ¨¡åè½è¶è¶éç¨åä¸äºè¼å¤§çç³»çµ±ãéé ç ç©¶æ¯å°å®¶å°åæ¨¡åç³»åçä¸é¨åï¼çºæªä¾çé«çä¿å¥ç¸é AI ç¼å±éªè·¯ï¼åæ¬å»è­å¥ååçç©é«å­¸å¯¦é«èåæ¨¡åãæåçç ç©¶å¼·èª¿äºå®¢è£½åç¥ç¶ç¿»è­¯æ¨¡ååè¿´åä¸­ LLM æ¹æ³çæ½åï¼ééæ¹åè³æç¢çãè©ä¼°ãä»£çåå»ºæ¨¡æè¡ï¼æ¨é²éåé åçç¼å±ã</paragraph>

##### **Schema Matching with Large Language Models: an Experimental Study**
2407.11852v1 by Marcel Parciak, Brecht Vandevoort, Frank Neven, Liesbet M. Peeters, Stijn Vansummeren

Large Language Models (LLMs) have shown useful applications in a variety of
tasks, including data wrangling. In this paper, we investigate the use of an
off-the-shelf LLM for schema matching. Our objective is to identify semantic
correspondences between elements of two relational schemas using only names and
descriptions. Using a newly created benchmark from the health domain, we
propose different so-called task scopes. These are methods for prompting the
LLM to do schema matching, which vary in the amount of context information
contained in the prompt. Using these task scopes we compare LLM-based schema
matching against a string similarity baseline, investigating matching quality,
verification effort, decisiveness, and complementarity of the approaches. We
find that matching quality suffers from a lack of context information, but also
from providing too much context information. In general, using newer LLM
versions increases decisiveness. We identify task scopes that have acceptable
verification effort and succeed in identifying a significant number of true
semantic matches. Our study shows that LLMs have potential in bootstrapping the
schema matching process and are able to assist data engineers in speeding up
this task solely based on schema element names and descriptions without the
need for data instances.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²å¨åç¨®ä»»åä¸­å±ç¾åºæç¨çæç¨ï¼åæ¬è³ææ´çãå¨æ¬æä¸­ï¼æåæ¢è¨ç¾æ LLM å¨æ¶æ§æ¯å°ä¸­çç¨éãæåçç®æ¨æ¯åä½¿ç¨åç¨±åæè¿°ï¼æ¾åºå©åéè¯å¼æ¶æ§çåç´ ä¹éçèªæå°æãä½¿ç¨å¾å¥åº·é åæ°å»ºç«çåºæºï¼æåæåºä¸åçæè¬ä»»åç¯åãéäºæ¹æ³æ¯ç¨æ¼æç¤º LLM é²è¡æ¶æ§æ¯å°ï¼å¶åå«å¨æç¤ºä¸­çèçµ¡è³è¨éææä¸åãä½¿ç¨éäºä»»åç¯åï¼æåå°åºæ¼ LLM çæ¶æ§æ¯å°èå­ä¸²ç¸ä¼¼æ§åºæºé²è¡æ¯è¼ï¼æ¢è¨æ¯å°åè³ªãé©è­å·¥ä½ãææ·æ§ï¼ä»¥åæ¹æ³çäºè£æ§ãæåç¼ç¾æ¯å°åè³ªæåå°èçµ¡è³è¨ä¸è¶³ä»¥åæä¾éå¤èçµ¡è³è¨çå½±é¿ãä¸è¬ä¾èªªï¼ä½¿ç¨è¼æ°ç LLM çæ¬æå¢å ææ·æ§ãæåæ¾åºå·æå¯æ¥åé©è­å·¥ä½ï¼ä¸¦æåæ¾åºå¤§éçå¯¦èªææ¯å°çä»»åç¯åãæåçç ç©¶é¡¯ç¤ºï¼LLM æå©æ¼å¼å°æ¶æ§æ¯å°æµç¨ï¼ä¸¦ä¸è½å¤ åå©è³æå·¥ç¨å¸«åæ ¹ææ¶æ§åç´ åç¨±åæè¿°å éæ­¤ä»»åï¼èä¸éè¦è³æå¯¦ä¾ã

##### **GPT Assisted Annotation of Rhetorical and Linguistic Features for Interpretable Propaganda Technique Detection in News Text**
2407.11827v1 by Kyle Hamilton, Luca Longo, Bojan Bozic

While the use of machine learning for the detection of propaganda techniques
in text has garnered considerable attention, most approaches focus on
"black-box" solutions with opaque inner workings. Interpretable approaches
provide a solution, however, they depend on careful feature engineering and
costly expert annotated data. Additionally, language features specific to
propagandistic text are generally the focus of rhetoricians or linguists, and
there is no data set labeled with such features suitable for machine learning.
This study codifies 22 rhetorical and linguistic features identified in
literature related to the language of persuasion for the purpose of annotating
an existing data set labeled with propaganda techniques. To help human experts
annotate natural language sentences with these features, RhetAnn, a web
application, was specifically designed to minimize an otherwise considerable
mental effort. Finally, a small set of annotated data was used to fine-tune
GPT-3.5, a generative large language model (LLM), to annotate the remaining
data while optimizing for financial cost and classification accuracy. This
study demonstrates how combining a small number of human annotated examples
with GPT can be an effective strategy for scaling the annotation process at a
fraction of the cost of traditional annotation relying solely on human experts.
The results are on par with the best performing model at the time of writing,
namely GPT-4, at 10x less the cost. Our contribution is a set of features,
their properties, definitions, and examples in a machine-readable format, along
with the code for RhetAnn and the GPT prompts and fine-tuning procedures for
advancing state-of-the-art interpretable propaganda technique detection.

æè¦ï¼<paragraph>åç®¡ä½¿ç¨æ©å¨å­¸ç¿ä¾åµæ¸¬å®£å³æå·§å¨ææ¬ä¸­å·²ç²å¾ç¸ç¶çéæ³¨ï¼ä½å¤§å¤æ¸æ¹æ³é½å°æ³¨æ¼å·æä¸éæå§é¨éä½çãé»çå­ãè§£æ±ºæ¹æ¡ãå¯è§£éçæ¹æ³æä¾äºè§£æ±ºæ¹æ¡ï¼ç¶èï¼å®åä¾è³´æ¼ä»ç´°çç¹å¾µå·¥ç¨åæè²´çå°å®¶è¨»éè³æãæ­¤å¤ï¼å®£å³æ§ææ¬çç¹å®èªè¨ç¹å¾µéå¸¸æ¯ä¿®è¾­å­¸å®¶æèªè¨å­¸å®¶çéæ³¨ç¦é»ï¼ä¸¦ä¸æ²ææ¨è¨ææ­¤é¡ç¹å¾µçè³æéé©åæ©å¨å­¸ç¿ãæ¬ç ç©¶å°åºç¾å¨èèªªæèªè¨ç¸éçæç»ä¸­è­å¥åºç 22 åä¿®è¾­åèªè¨ç¹å¾µç·¨çºææ³å¸ï¼ç®çæ¯çºæ¨è¨æå®£å³æå·§çç¾æè³æéãçºäºå¹«å©äººé¡å°å®¶ä½¿ç¨éäºç¹å¾µè¨»éèªç¶èªè¨å¥å­ï¼å°éè¨­è¨äºç¶²è·¯æç¨ç¨å¼ RhetAnnï¼ä»¥æå¤§ç¨åº¦å°æ¸å°åæ¬ç¸ç¶å¤§çå¿æºè² æãæå¾ï¼ä½¿ç¨ä¸å°çµè¨»éè³æå¾®èª¿äºçæå¼å¤§åèªè¨æ¨¡å (LLM) GPT-3.5ï¼ä»¥è¨»éå©é¤è³æï¼åæéå°è²¡åææ¬ååé¡æºç¢ºåº¦é²è¡æä½³åãæ¬ç ç©¶å±ç¤ºäºå°å°æ¸äººé¡è¨»éç¯ä¾è GPT çµåå¦ä½æçºä»¥å³çµ±åä¾è³´äººé¡å°å®¶çè¨»éææ¬çä¸å°é¨åä¾æ´å±è¨»éç¨åºçææç­ç¥ãå¨æ°å¯«æ¬ææï¼çµæèç¶æè¡¨ç¾æä½³çæ¨¡å GPT-4 ç¸ç¶ï¼ææ¬å»ä½äº 10 åãæåçè²¢ç»æ¯ä¸çµç¹å¾µãå®åçå±¬æ§ãå®ç¾©åç¯ä¾ï¼æ¡ç¨æ©å¨å¯è®æ ¼å¼ï¼ä»¥å RhetAnn çç¨å¼ç¢¼å GPT æç¤ºåå¾®èª¿ç¨åºï¼ç¨æ¼æ¨é²æåé²çå¯è§£éå®£å³æå·§åµæ¸¬ã</paragraph>

##### **Characterizing and Understanding HGNN Training on GPUs**
2407.11790v2 by Dengke Han, Mingyu Yan, Xiaochun Ye, Dongrui Fan, Ninghui Sun

Owing to their remarkable representation capabilities for heterogeneous graph
data, Heterogeneous Graph Neural Networks (HGNNs) have been widely adopted in
many critical real-world domains such as recommendation systems and medical
analysis. Prior to their practical application, identifying the optimal HGNN
model parameters tailored to specific tasks through extensive training is a
time-consuming and costly process. To enhance the efficiency of HGNN training,
it is essential to characterize and analyze the execution semantics and
patterns within the training process to identify performance bottlenecks. In
this study, we conduct an in-depth quantification and analysis of two
mainstream HGNN training scenarios, including single-GPU and multi-GPU
distributed training. Based on the characterization results, we disclose the
performance bottlenecks and their underlying causes in different HGNN training
scenarios and provide optimization guidelines from both software and hardware
perspectives.

æè¦ï¼ç±æ¼ç°è³ªåå½¢ç¥ç¶ç¶²è·¯ (HGNN) å°ç°è³ªåå½¢è³ææåè¶çè¡¨ç¤ºè½åï¼å æ­¤å·²å»£æ³ç¨æ¼è¨±å¤éè¦ççå¯¦ä¸çé åï¼ä¾å¦æ¨è¦ç³»çµ±åé«çåæãå¨å¯¦éæç¨ä¹åï¼ééå»£æ³çè¨ç·´ä¾æ¾åºéå°ç¹å®ä»»åéèº«æé çæä½³ HGNN æ¨¡ååæ¸ï¼æ¯ä¸åèæä¸æè²´çéç¨ãçºäºæé« HGNN è¨ç·´çæçï¼å¿é å°è¨ç·´éç¨ä¸­å·è¡èªç¾©åæ¨¡å¼é²è¡ç¹å¾µåååæï¼ä»¥æ¾åºæè½ç¶é ¸ãå¨æ¬ç ç©¶ä¸­ï¼æåå°å©åä¸»æµ HGNN è¨ç·´å ´æ¯é²è¡æ·±å¥çéåååæï¼åæ¬å®ä¸ GPU åå¤ GPU åæ£å¼è¨ç·´ãæ ¹æç¹å¾µåçµæï¼æåæ­é²äºä¸å HGNN è¨ç·´å ´æ¯ä¸­çæè½ç¶é ¸åå¶æ ¹æ¬åå ï¼ä¸¦å¾è»é«åç¡¬é«è§åº¦æä¾æä½³åæºåã

##### **CCoE: A Compact LLM with Collaboration of Experts**
2407.11686v3 by Shaomang Huang, Jianfeng Pan, Hanzhong Zheng

In the domain of Large Language Model (LLM), LLMs demonstrate significant
capabilities in natural language understanding and generation. With the growing
needs of applying LLMs on various domains, it is a research question that how
to efficiently train and build a model that has expertise in different domains
but with a low training cost. We propose CCoE architecture, a framework of
easily coupling multiple strong domain experts together to fuse into a big LLM,
provides a collective way of utilizing the different domain expert LLMs.
Besides, training a large collaborative of multiple expert LLMs requires a high
requirements on training sources. CCoE bypasses this problem through isolating
other experts and train each expert separately. The design of CCoE assembles
multiple expert LLMs through the CoE (Collaboration of Experts) layer. Each CoE
layer could have one or more expert LLMs. Expert LLMs have different number of
layers and have been well-trained for different domain tasks. Each expert is
fine-tuned to be able to achieve the comparable results with SOTA domain LLMs.
We start from 5 experts in the domain of Code, Math, Law, text-to-SQL and
Medical. The results indicate that our CCoE framework can easily and
efficiently boost nearly 10%-20% performance on original base model in
different domains but using less resources on training, as well as inference.

æè¦ï¼å¨å¤§èªè¨æ¨¡åï¼LLMï¼é åä¸­ï¼LLM å¨èªç¶èªè¨çè§£åçææ¹é¢å±ç¾åºé¡¯èçè½åãé¨è LLM å¨åç¨®é åæç¨çéæ±æ¥çå¢é·ï¼å¦ä½ææè¨ç·´åå»ºç«ä¸åå¨ä¸åé åå·æå°æ¥­ç¥è­ä½è¨ç·´ææ¬ä½çæ¨¡åï¼æ¯ä¸åç ç©¶åé¡ãæåæåº CCoE æ¶æ§ï¼ä¸åå°å¤åå¼·å¤§çé åå°å®¶è¼é¬çµåå¨ä¸èµ·ä»¥èåæä¸åå¤§å LLM çæ¡æ¶ï¼æä¾äºä¸ç¨®å©ç¨ä¸åé åå°å®¶ LLM çéåæ¹å¼ãæ­¤å¤ï¼è¨ç·´å¤åå°å®¶ LLM çå¤§ååä½éè¦å°è¨ç·´ä¾æºæåºå¾é«çè¦æ±ãCCoE éééé¢å¶ä»å°å®¶ä¸¦åå¥è¨ç·´æ¯åå°å®¶ä¾ç¹ééååé¡ãCCoE çè¨­è¨éé CoEï¼å°å®¶åä½ï¼å±¤çµè£å¤åå°å®¶ LLMãæ¯å CoE å±¤å¯ä»¥æä¸åæå¤åå°å®¶ LLMãå°å®¶ LLM å·æä¸åçå±¤æ¸ï¼ä¸¦ä¸å·²ç¶éå°ä¸åçé åä»»åæ¥åéè¯å¥½çè¨ç·´ãæ¯åå°å®¶é½ç¶éå¾®èª¿ï¼è½å¤ éå°è SOTA é å LLM ç¸ç¶ççµæãæåå¾ç¨å¼ç¢¼ãæ¸å­¸ãæ³å¾ãæå­è½ SQL åé«å­¸é åç 5 ä½å°å®¶éå§ãçµæè¡¨æï¼æåç CCoE æ¡æ¶å¯ä»¥è¼é¬ææå°æåä¸åé åä¸­åå§åºç¤æ¨¡åçæ§è½è¿ 10%-20%ï¼ä½è¨ç·´åæ¨çä½¿ç¨çè³æºæ´å°ã

##### **CCVA-FL: Cross-Client Variations Adaptive Federated Learning for Medical Imaging**
2407.11652v2 by Sunny Gupta, Amit Sethi

Federated Learning (FL) offers a privacy-preserving approach to train models
on decentralized data. Its potential in healthcare is significant, but
challenges arise due to cross-client variations in medical image data,
exacerbated by limited annotations. This paper introduces Cross-Client
Variations Adaptive Federated Learning (CCVA-FL) to address these issues.
CCVA-FL aims to minimize cross-client variations by transforming images into a
common feature space. It involves expert annotation of a subset of images from
each client, followed by the selection of a client with the least data
complexity as the target. Synthetic medical images are then generated using
Scalable Diffusion Models with Transformers (DiT) based on the target client's
annotated images. These synthetic images, capturing diversity and representing
the original data, are shared with other clients. Each client then translates
its local images into the target image space using image-to-image translation.
The translated images are subsequently used in a federated learning setting to
develop a server model. Our results demonstrate that CCVA-FL outperforms
Vanilla Federated Averaging by effectively addressing data distribution
differences across clients without compromising privacy.

æè¦ï¼è¯é¦å­¸ç¿ (FL) æä¾ä¸ç¨®ä¿è­·é±ç§çæ¹æ³ï¼å¯ä»¥å¨åæ£å¼æ¸æä¸è¨ç·´æ¨¡åãå¶å¨é«çä¿å¥ä¸­çæ½åå¾å¤§ï¼ä½ç±æ¼é«çå½±åæ¸æä¸­çè·¨å®¢æ¶å·®ç°ï¼å ä¸è¨»éæéï¼å æ­¤ç¢çäºææ°ãæ¬æä»ç´¹è·¨å®¢æ¶å·®ç°èªé©æè¯é¦å­¸ç¿ (CCVA-FL) ä¾è§£æ±ºéäºåé¡ãCCVA-FL æ¨å¨ééå°å½±åè½æå°ä¸åå±åç¹å¾µç©ºéä¾æå°åè·¨å®¢æ¶å·®ç°ãå®æ¶åå¾æ¯åå®¢æ¶ç«¯ä¸­çä¸åå½±åå­éé²è¡å°å®¶è¨»éï¼ç¶å¾é¸ææ¸æè¤éæ§æä½çå®¢æ¶ç«¯ä½çºç®æ¨ãç¶å¾ä½¿ç¨åºæ¼ç®æ¨å®¢æ¶ç«¯è¨»éå½±åçå¯æ´åæ´æ£æ¨¡åè Transformer (DiT) ä¾ç¢çåæé«çå½±åãéäºåæå½±åæ·åå¤æ¨£æ§ä¸¦ä»£è¡¨åå§æ¸æï¼ä¸¦èå¶ä»å®¢æ¶ç«¯å±äº«ãç¶å¾ï¼æ¯åå®¢æ¶ç«¯ä½¿ç¨å½±åå°å½±åç¿»è­¯ï¼å°å¶æ¬å°å½±åè½æå°ç®æ¨å½±åç©ºéãç¿»è­¯å¾çå½±åé¨å¾ç¨æ¼è¯é¦å­¸ç¿è¨­å®ï¼ä»¥éç¼ä¼ºæå¨æ¨¡åãæåççµæè­æï¼CCVA-FL ééææè§£æ±ºå®¢æ¶ç«¯ä¹éçæ¸æåä½å·®ç°ï¼å¨ä¸æå®³é±ç§çææ³ä¸ï¼åªæ¼é¦èè¯é¦å¹³åã

##### **Improving Engagement and Efficacy of mHealth Micro-Interventions for Stress Coping: an In-The-Wild Study**
2407.11612v1 by Chaya Ben Yehuda, Ran Gilad-Bachrach, Yarin Udi

Sustaining long-term user engagement with mobile health (mHealth)
interventions while preserving their high efficacy remains an ongoing challenge
in real-world well-being applications. To address this issue, we introduce a
new algorithm, the Personalized, Context-Aware Recommender (PCAR), for
intervention selection and evaluate its performance in a field experiment. In a
four-week, in-the-wild experiment involving 29 parents of young children, we
delivered personalized stress-reducing micro-interventions through a mobile
chatbot. We assessed their impact on stress reduction using momentary stress
level ecological momentary assessments (EMAs) before and after each
intervention. Our findings demonstrate the superiority of PCAR intervention
selection in enhancing the engagement and efficacy of mHealth
micro-interventions to stress coping compared to random intervention selection
and a control group that did not receive any intervention. Furthermore, we show
that even brief, one-minute interventions can significantly reduce perceived
stress levels (p=0.001). We observe that individuals are most receptive to
one-minute interventions during transitional periods between activities, such
as transitioning from afternoon activities to bedtime routines. Our study
contributes to the literature by introducing a personalized context-aware
intervention selection algorithm that improves engagement and efficacy of
mHealth interventions, identifying key timing for stress interventions, and
offering insights into mechanisms to improve stress coping.

æè¦ï¼<paragraph>å¨ç¶­æè¡åå¥åº· (mHealth) å¹²é æªæ½çé·æä½¿ç¨èåèåº¦ï¼åæç¶­æå¶é«åæï¼å¨ç¾å¯¦ä¸ççå¥åº·æç¨ä¸­ä»æ¯ä¸åæçºçææ°ãçºäºè§£æ±ºéååé¡ï¼æåå¼å¥äºä¸ç¨®æ°çæ¼ç®æ³ï¼ç¨±çºåäººåãæå¢æç¥æ¨è¦å¨ (PCAR)ï¼ç¨æ¼å¹²é é¸æï¼ä¸¦å¨å¯¦å°å¯¦é©ä¸­è©ä¼°å¶æè½ãå¨çºæåé±çéå¤å¯¦é©ä¸­ï¼æ¶å 29 ä½å¹¼åçç¶æ¯ï¼æåééè¡åèå¤©æ©å¨äººå³éåäººåçæ¸å£å¾®åå¹²é æªæ½ãæåééå¨æ¯æ¬¡å¹²é æªæ½åå¾é²è¡çç¬éå£åç­ç´çæç¬æè©ä¼° (EMA)ï¼è©ä¼°å®åå°æ¸å£çå½±é¿ãæåçç ç©¶çµæè­æäº PCAR å¹²é é¸æå¨å¢å¼· mHealth å¾®åå¹²é æªæ½å°å£åæå°çåèåº¦åæè½æ¹é¢çåªè¶æ§ï¼ç¸è¼æ¼é¨æ©å¹²é é¸æåæªæ¥åä»»ä½å¹²é æªæ½çå°ç§çµãæ­¤å¤ï¼æåè­æäºå³ä½¿ç°¡ç­çä¸åéå¹²é æªæ½ä¹è½é¡¯èéä½æç¥å£åç­ç´ (p=0.001)ãæåè§å¯å°ï¼åäººå¨æ´»åä¹éçéæ¸¡æï¼ä¾å¦å¾ä¸åæ´»åéæ¸¡å°å°±å¯¢æéï¼å°ä¸åéçå¹²é æªæ½æå·æ¥ååº¦ãæåçç ç©¶ééå¼å¥ä¸ç¨®åäººåæå¢æç¥å¹²é é¸ææ¼ç®æ³ï¼æ¹å mHealth å¹²é æªæ½çåèåº¦åæè½ï¼æ¾åºå£åå¹²é æªæ½çééµææ©ï¼ä¸¦æä¾æ¹åå£åæå°æ©å¶çè¦è§£ï¼çºæç»ååºè²¢ç»ã</paragraph>

##### **DiNO-Diffusion. Scaling Medical Diffusion via Self-Supervised Pre-Training**
2407.11594v1 by Guillermo Jimenez-Perez, Pedro Osorio, Josef Cersovsky, Javier Montalt-Tordera, Jens Hooge, Steffen Vogler, Sadegh Mohammadi

Diffusion models (DMs) have emerged as powerful foundation models for a
variety of tasks, with a large focus in synthetic image generation. However,
their requirement of large annotated datasets for training limits their
applicability in medical imaging, where datasets are typically smaller and
sparsely annotated. We introduce DiNO-Diffusion, a self-supervised method for
training latent diffusion models (LDMs) that conditions the generation process
on image embeddings extracted from DiNO. By eliminating the reliance on
annotations, our training leverages over 868k unlabelled images from public
chest X-Ray (CXR) datasets. Despite being self-supervised, DiNO-Diffusion shows
comprehensive manifold coverage, with FID scores as low as 4.7, and emerging
properties when evaluated in downstream tasks. It can be used to generate
semantically-diverse synthetic datasets even from small data pools,
demonstrating up to 20% AUC increase in classification performance when used
for data augmentation. Images were generated with different sampling strategies
over the DiNO embedding manifold and using real images as a starting point.
Results suggest, DiNO-Diffusion could facilitate the creation of large datasets
for flexible training of downstream AI models from limited amount of real data,
while also holding potential for privacy preservation. Additionally,
DiNO-Diffusion demonstrates zero-shot segmentation performance of up to 84.4%
Dice score when evaluating lung lobe segmentation. This evidences good CXR
image-anatomy alignment, akin to segmenting using textual descriptors on
vanilla DMs. Finally, DiNO-Diffusion can be easily adapted to other medical
imaging modalities or state-of-the-art diffusion models, opening the door for
large-scale, multi-domain image generation pipelines for medical imaging.

æè¦ï¼æ´æ£æ¨¡å (DM) å·²æçºåç¨®ä»»åä¸­å¼·å¤§çåºç¤æ¨¡åï¼ç¹å¥æ¯åæå½±åçæãç¶èï¼å®åå¨è¨ç·´ä¸­å°å¤§åæ¨è¨»è³æéçè¦æ±éå¶äºå®åå¨é«çå½±åä¸­çæç¨ï¼èé«çå½±åçè³æééå¸¸è¼å°ä¸æ¨è¨»ç¨çãæåå¼å¥äº DiNO-Diffusionï¼éæ¯ä¸ç¨®ç¨æ¼è¨ç·´æ¢ä»¶çæéç¨çæ½å¨æ´æ£æ¨¡å (LDM) çèªç£ç£æ¹æ³ï¼è©²éç¨åºæ¼å¾ DiNO ä¸­æåçå½±ååµå¥ãééæ¶é¤å°æ¨è¨»çä¾è³´ï¼æåçè¨ç·´å©ç¨äºä¾èªå¬å±è¸é¨ X å (CXR) è³æéçè¶é 868k å¼µæªæ¨è¨»å½±åãåç®¡æ¯èªç£ç£çï¼ä½ DiNO-Diffusion é¡¯ç¤ºåºå¨é¢çæµå½¢è¦èï¼FID åæ¸ä½è³ 4.7ï¼ä¸¦ä¸å¨è©ä¼°ä¸æ¸¸ä»»åæåºç¾äºæ°èçå±¬æ§ãå®å¯ç¨æ¼å¾å°åè³æåº«çæèªç¾©å¤æ¨£çåæè³æéï¼å¨ç¨æ¼è³ææ´åæï¼åé¡æè½æåå¹åº¦é«é 20% AUCãå½±åæ¯å¨ DiNO åµå¥æµå½¢ä¸ä½¿ç¨ä¸åçåæ¨£ç­ç¥çæçï¼ä¸¦ä½¿ç¨çå¯¦å½±åä½çºèµ·é»ãçµæé¡¯ç¤ºï¼DiNO-Diffusion å¯ä»¥ä¿é²å¾æéççå¯¦è³æä¸­éæ´»è¨ç·´ä¸æ¸¸ AI æ¨¡åçå¤§åè³æéçå»ºç«ï¼åæä¹å·æé±ç§ä¿è­·çæ½åãæ­¤å¤ï¼DiNO-Diffusion å¨è©ä¼°èºèåå²æå±ç¤ºäºé«é 84.4% ç Dice åæ¸çé¶æ¬¡å­¸ç¿åå²æè½ãéè­æäºè¯å¥½ç CXR å½±åè§£åå°é½ï¼é¡ä¼¼æ¼å¨é¦è DM ä¸ä½¿ç¨æå­æè¿°ç¬¦é²è¡åå²ãæå¾ï¼DiNO-Diffusion å¯ä»¥è¼é¬é©æå¶ä»é«çå½±åæ¹å¼ææåé²çæ´æ£æ¨¡åï¼çºé«çå½±åçå¤§è¦æ¨¡ãå¤é åå½±åçæç®¡ééåäºå¤§éã

##### **Probing the Efficacy of Federated Parameter-Efficient Fine-Tuning of Vision Transformers for Medical Image Classification**
2407.11573v1 by Naif Alkhunaizi, Faris Almalik, Rouqaiah Al-Refai, Muzammal Naseer, Karthik Nandakumar

With the advent of large pre-trained transformer models, fine-tuning these
models for various downstream tasks is a critical problem. Paucity of training
data, the existence of data silos, and stringent privacy constraints exacerbate
this fine-tuning problem in the medical imaging domain, creating a strong need
for algorithms that enable collaborative fine-tuning of pre-trained models.
Moreover, the large size of these models necessitates the use of
parameter-efficient fine-tuning (PEFT) to reduce the communication burden in
federated learning. In this work, we systematically investigate various
federated PEFT strategies for adapting a Vision Transformer (ViT) model
(pre-trained on a large natural image dataset) for medical image
classification. Apart from evaluating known PEFT techniques, we introduce new
federated variants of PEFT algorithms such as visual prompt tuning (VPT),
low-rank decomposition of visual prompts, stochastic block attention
fine-tuning, and hybrid PEFT methods like low-rank adaptation (LoRA)+VPT.
Moreover, we perform a thorough empirical analysis to identify the optimal PEFT
method for the federated setting and understand the impact of data distribution
on federated PEFT, especially for out-of-domain (OOD) and non-IID data. The key
insight of this study is that while most federated PEFT methods work well for
in-domain transfer, there is a substantial accuracy vs. efficiency trade-off
when dealing with OOD and non-IID scenarios, which is commonly the case in
medical imaging. Specifically, every order of magnitude reduction in
fine-tuned/exchanged parameters can lead to a 4% drop in accuracy. Thus, the
initial model choice is crucial for federated PEFT. It is preferable to use
medical foundation models learned from in-domain medical image data (if
available) rather than general vision models.

æè¦ï¼<paragraph>é¨èå¤§åé è¨ç·´è½æå¨æ¨¡åçåºç¾ï¼éå°åç¨®ä¸æ¸¸ä»»åå¾®èª¿éäºæ¨¡åæ¯ä¸åééµåé¡ãè¨ç·´è³æçç¨ç¼ºæ§ãè³æå­¤å³¶çå­å¨ä»¥åå´æ ¼çé±ç§éå¶æå åé«çå½±åé åä¸­çå¾®èª¿åé¡ï¼éå°è½è®é è¨ç·´æ¨¡åé²è¡åä½å¾®èª¿çæ¼ç®æ³ç¢çäºå¼·çéæ±ãæ­¤å¤ï¼éäºæ¨¡åçé¾å¤§è¦æ¨¡éè¦ä½¿ç¨åæ¸ææå¾®èª¿ (PEFT) ä¾éä½è¯åå­¸ç¿ä¸­çéè¨è² æãå¨éé å·¥ä½ä¸­ï¼æåç³»çµ±æ§å°æ¢è¨äºåç¨®è¯å PEFT ç­ç¥ï¼ä»¥èª¿æ´è¦è¦ºè½æå¨ (ViT) æ¨¡åï¼å¨å¤§åèªç¶å½±åè³æéä¸é åè¨ç·´ï¼ä»¥é²è¡é«çå½±ååé¡ãé¤äºè©ä¼°å·²ç¥ç PEFT æè¡å¤ï¼æåéå¼å¥äº PEFT æ¼ç®æ³çæ°è¯åè®é«ï¼ä¾å¦è¦è¦ºæç¤ºèª¿æ´ (VPT)ãè¦è¦ºæç¤ºçä½ç§©åè§£ãé¨æ©åå¡æ³¨æåå¾®èª¿ï¼ä»¥åä½ç§©é©æ (LoRA)+VPT ç­æ··å PEFT æ¹æ³ãæ­¤å¤ï¼æåé²è¡äºå¾¹åºçç¶é©åæï¼ä»¥æ¾åºè¯åè¨­å®çæä½³ PEFT æ¹æ³ï¼ä¸¦äºè§£è³æåä½å°è¯å PEFT çå½±é¿ï¼ç¹å¥æ¯å°æ¼é åå¤ (OOD) åéç¨ç«ååä½ (non-IID) è³æãéé ç ç©¶çä¸»è¦è¦è§£æ¯ï¼åç®¡å¤§å¤æ¸è¯å PEFT æ¹æ³é½é©ç¨æ¼é åå§è½ç§»ï¼ä½å¨èç OOD åéç¨ç«ååä½å ´æ¯æï¼ææå¤§å¹çæºç¢ºåº¦èæçæè¡·ï¼ééå¸¸æ¯é«çå½±åä¸­çææ³ãå·é«ä¾èªªï¼å¾®èª¿/äº¤æåæ¸çæ¯åæ¸éç´æ¸å°é½å¯è½å°è´æºç¢ºåº¦ä¸é 4%ãå æ­¤ï¼åå§æ¨¡åçé¸æå°æ¼è¯å PEFT è³ééè¦ãæå¥½ä½¿ç¨å¾é åå§é«å­¸å½±åè³æï¼å¦ææçè©±ï¼å­¸ç¿çé«å­¸åºç¤æ¨¡åï¼èä¸æ¯ä¸è¬è¦è¦ºæ¨¡åã</paragraph>

##### **Fine-Tuning Medical Language Models for Enhanced Long-Contextual Understanding and Domain Expertise**
2407.11536v1 by Qimin Yang, Rongsheng Wang, Jiexin Chen, Runqi Su, Tao Tan

Large Language Models (LLMs) have been widely applied in various professional
fields. By fine-tuning the models using domain specific question and answer
datasets, the professional domain knowledge and Q\&A abilities of these models
have significantly improved, for example, medical professional LLMs that use
fine-tuning of doctor-patient Q\&A data exhibit extraordinary disease
diagnostic abilities. However, we observed that despite improvements in
specific domain knowledge, the performance of medical LLM in long-context
understanding has significantly declined, especially compared to general
language models with similar parameters. The purpose of this study is to
investigate the phenomenon of reduced performance in understanding long-context
in medical LLM. We designed a series of experiments to conduct open-book
professional knowledge exams on all models to evaluate their ability to read
long-context. By adjusting the proportion and quantity of general data and
medical data in the process of fine-tuning, we can determine the best data
composition to optimize the professional model and achieve a balance between
long-context performance and specific domain knowledge.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²å»£æ³æç¨æ¼åç¨®å°æ¥­é åãééä½¿ç¨ç¹å®é åçåç­è³æéå¾®èª¿æ¨¡åï¼éäºæ¨¡åçå°æ¥­é åç¥è­ååç­è½åå·²é¡¯èæåï¼ä¾å¦ï¼ä½¿ç¨é«ç-æ£èåç­è³æé²è¡å¾®èª¿çé«çå°æ¥­ LLM å±ç¾åºéå¡çç¾çè¨ºæ·è½åãç¶èï¼æåè§å¯å°ï¼åç®¡ç¹å®é åç¥è­æææåï¼ä½é«ç LLM å¨é·èªå¢çè§£æ¹é¢çè¡¨ç¾å»å¤§å¹ä¸éï¼å°¤å¶æ¯èå·æé¡ä¼¼åæ¸çä¸è¬èªè¨æ¨¡åç¸æ¯ãæ¬ç ç©¶çç®çæ¯æ¢è¨é«ç LLM å¨çè§£é·èªå¢æ¹é¢çè¡¨ç¾ä¸éç¾è±¡ãæåè¨­è¨äºä¸ç³»åå¯¦é©ï¼å°æææ¨¡åé²è¡éæ¾å¼å°æ¥­ç¥è­èè©¦ï¼ä»¥è©ä¼°å®åé±è®é·èªå¢ççè§£è½åãééèª¿æ´å¾®èª¿éç¨ä¸­ä¸è¬è³æåé«çè³æçæ¯ä¾åæ¸éï¼æåå¯ä»¥ç¢ºå®æä½³è³æçµåï¼ä»¥åªåå°æ¥­æ¨¡åï¼ä¸¦å¨é·èªå¢è¡¨ç¾åç¹å®é åç¥è­ä¹éåå¾å¹³è¡¡ã

##### **Cross-Phase Mutual Learning Framework for Pulmonary Embolism Identification on Non-Contrast CT Scans**
2407.11529v1 by Bizhe Bai, Yan-Jie Zhou, Yujian Hu, Tony C. W. Mok, Yilang Xiang, Le Lu, Hongkun Zhang, Minfeng Xu

Pulmonary embolism (PE) is a life-threatening condition where rapid and
accurate diagnosis is imperative yet difficult due to predominantly atypical
symptomatology. Computed tomography pulmonary angiography (CTPA) is
acknowledged as the gold standard imaging tool in clinics, yet it can be
contraindicated for emergency department (ED) patients and represents an
onerous procedure, thus necessitating PE identification through non-contrast CT
(NCT) scans. In this work, we explore the feasibility of applying a
deep-learning approach to NCT scans for PE identification. We propose a novel
Cross-Phase Mutual learNing framework (CPMN) that fosters knowledge transfer
from CTPA to NCT, while concurrently conducting embolism segmentation and
abnormality classification in a multi-task manner. The proposed CPMN leverages
the Inter-Feature Alignment (IFA) strategy that enhances spatial contiguity and
mutual learning between the dual-pathway network, while the Intra-Feature
Discrepancy (IFD) strategy can facilitate precise segmentation of PE against
complex backgrounds for single-pathway networks. For a comprehensive assessment
of the proposed approach, a large-scale dual-phase dataset containing 334 PE
patients and 1,105 normal subjects has been established. Experimental results
demonstrate that CPMN achieves the leading identification performance, which is
95.4\% and 99.6\% in patient-level sensitivity and specificity on NCT scans,
indicating the potential of our approach as an economical, accessible, and
precise tool for PE identification in clinical practice.

æè¦ï¼èºæ å¡ (PE) æ¯ä¸ç¨®å±åçå½çç¾çï¼å¿«éä¸æºç¢ºçè¨ºæ·è³ééè¦ï¼ä½ç±æ¼ççä¸»è¦æ¯éå¸åçï¼å æ­¤å¾é£è¨ºæ·ãé»è¦æ·å±¤èºè¡ç®¡æå½± (CTPA) è¢«å¬èªçºè¨ºæä¸­çé»éæ¨æºå½±åå·¥å·ï¼ä½å®å¯è½æå°æ¥è¨ºé¨é (ED) çæ£èç¦å¿ï¼ä¸¦ä¸ä»£è¡¨èç¹éçç¨åºï¼å æ­¤éè¦éééå°æ¯ CT (NCT) ææä¾è­å¥ PEãå¨éé å·¥ä½ä¸­ï¼æåæ¢è¨äºå°æ·±åº¦å­¸ç¿æ¹æ³æç¨æ¼ NCT ææä»¥è­å¥ PE çå¯è¡æ§ãæåæåºäºä¸åæ°ç©çè·¨ç¸ä½äºå­¸ç¿æ¡æ¶ (CPMN)ï¼å®ä¿é²äºå¾ CTPA å° NCT çç¥è­è½ç§»ï¼åæä»¥å¤ä»»åçæ¹å¼é²è¡æ å¡åå²åç°å¸¸åé¡ãææåºç CPMN æ¡ç¨äºç¹å¾µéå°é½ (IFA) ç­ç¥ï¼å®å¢å¼·äºéè·¯å¾ç¶²è·¯ä¹éçç©ºéé£çºæ§åç¸äºå­¸ç¿ï¼èç¹å¾µå§å·®ç° (IFD) ç­ç¥å¯ä»¥ä¿é²å®è·¯å¾ç¶²è·¯å°è¤éèæ¯ä¸­ç PE é²è¡ç²¾ç¢ºåå²ãçºäºå°ææåºçæ¹æ³é²è¡å¨é¢è©ä¼°ï¼å·²ç¶å»ºç«äºä¸ååå« 334 å PE æ£èå 1,105 åæ­£å¸¸åè©¦èçãå¤§è¦æ¨¡éç¸ä½æ¸æéãå¯¦é©çµæè¡¨æï¼CPMN éå°äºé åçè­å¥æè½ï¼å¨ NCT ææä¸­ï¼æ£èå±¤ç´çæææ§åç¹ç°æ§åå¥çº 95.4% å 99.6%ï¼éè¡¨ææåçåæ³æå¯è½æçºä¸ç¨®ç¶æ¿ãææ¼åå¾ä¸ç²¾ç¢ºç PE è­å¥å·¥å·ï¼å¯æç¨æ¼è¨åºå¯¦åã

##### **Multi-Channel Masked Autoencoder and Comprehensive Evaluations for Reconstructing 12-Lead ECG from Arbitrary Single-Lead ECG**
2407.11481v1 by Jiarong Chen, Wanqing Wu, Tong Liu, Shenda Hong

In the context of cardiovascular diseases (CVD) that exhibit an elevated
prevalence and mortality, the electrocardiogram (ECG) is a popular and standard
diagnostic tool for doctors, commonly utilizing a 12-lead configuration in
clinical practice. However, the 10 electrodes placed on the surface would cause
a lot of inconvenience and discomfort, while the rapidly advancing wearable
devices adopt the reduced-lead or single-lead ECG to reduce discomfort as a
solution in long-term monitoring. Since the single-lead ECG is a subset of
12-lead ECG, it provides insufficient cardiac health information and plays a
substandard role in real-world healthcare applications. Hence, it is necessary
to utilize signal generation technologies to reduce their clinical importance
gap by reconstructing 12-lead ECG from the real single-lead ECG. Specifically,
this study proposes a multi-channel masked autoencoder (MCMA) for this goal. In
the experimental results, the visualized results between the generated and real
signals can demonstrate the effectiveness of the proposed framework. At the
same time, this study introduces a comprehensive evaluation benchmark named
ECGGenEval, encompassing the signal-level, feature-level, and diagnostic-level
evaluations, providing a holistic assessment of 12-lead ECG signals and
generative model. Further, the quantitative experimental results are as
follows, the mean square errors of 0.0178 and 0.0658, correlation coefficients
of 0.7698 and 0.7237 in the signal-level evaluation, the average F1-score with
two generated 12-lead ECG is 0.8319 and 0.7824 in the diagnostic-level
evaluation, achieving the state-of-the-art performance. The open-source code is
publicly available at \url{https://github.com/CHENJIAR3/MCMA}.

æè¦ï¼<paragraph>å¨è¡¨ç¾åºé«çè¡çåæ­»äº¡ççå¿è¡ç®¡ç¾ç (CVD) çææ³ä¸ï¼å¿é»å (ECG) æ¯ä¸ç¨®é«çå¸¸ç¨çæ¨æºè¨ºæ·å·¥å·ï¼å¨è¨åºå¯¦åä¸­éå¸¸ä½¿ç¨ 12 å°ç¨çµæãç¶èï¼æ¾ç½®å¨è¡¨é¢ç 10 åé»æ¥µæé æè¨±å¤ä¸ä¾¿åä¸é©ï¼èå¿«éé²æ­¥çå¯ç©¿æ´å¼è£ç½®æ¡ç¨æ¸å°å°ç¨æå®å°ç¨ ECG ä¾éä½ä¸é©ï¼ä½çºé·æç£æ¸¬çè§£æ±ºæ¹æ¡ãç±æ¼å®å°ç¨ ECG æ¯ 12 å°ç¨ ECG çå­éï¼å®æä¾çå¥åº·è³è¨ä¸è¶³ï¼å¨çå¯¦ä¸ççé«çä¿å¥æç¨ä¸­æ®æ¼èæ¬¡æ¨æºçè§è²ãå æ­¤ï¼æå¿è¦å©ç¨è¨èç¢çæè¡ä¾ç¸®å°å¶è¨åºéè¦æ§å·®è·ï¼æ¹æ³æ¯å¾çå¯¦çå®å°ç¨ ECG éå»º 12 å°ç¨ ECGãå·é«ä¾èªªï¼æ¬ç ç©¶æåºäºä¸åå¤ééé®ç½©èªåç·¨ç¢¼å¨ (MCMA) ä¾éææ­¤ç®æ¨ãå¨å¯¦é©çµæä¸­ï¼çæçè¨èèçå¯¦è¨èä¹éçå¯è¦åçµæå¯ä»¥è­æææåºæ¶æ§çæææ§ãåæï¼æ¬ç ç©¶å¼å¥äºç¨±çº ECGGenEval çç¶åè©ä¼°åºæºï¼æ¶µèè¨èå±¤ç´ãç¹å¾µå±¤ç´åè¨ºæ·å±¤ç´è©ä¼°ï¼æä¾ 12 å°ç¨ ECG è¨èåçææ¨¡åçæ´é«è©ä¼°ãæ­¤å¤ï¼å®éçå¯¦é©çµæå¦ä¸ï¼å¨è¨èå±¤ç´è©ä¼°ä¸­ï¼åæ¹èª¤å·®çº 0.0178 å 0.0658ï¼ç¸éä¿æ¸çº 0.7698 å 0.7237ï¼å¨è¨ºæ·å±¤ç´è©ä¼°ä¸­ï¼å©åçæç 12 å°ç¨ ECG çå¹³å F1 åæ¸çº 0.8319 å 0.7824ï¼éå°äºæåé²çæè½ãéæ¾åå§ç¢¼å¯ä»¥å¨ \url{https://github.com/CHENJIAR3/MCMA} å¬éåå¾ã</paragraph>

##### **TM-PATHVQA:90000+ Textless Multilingual Questions for Medical Visual Question Answering**
2407.11383v1 by Tonmoy Rajkhowa, Amartya Roy Chowdhury, Sankalp Nagaonkar, Achyut Mani Tripathi

In healthcare and medical diagnostics, Visual Question Answering (VQA)
mayemergeasapivotal tool in scenarios where analysis of intricate medical
images becomes critical for accurate diagnoses. Current text-based VQA systems
limit their utility in scenarios where hands-free interaction and accessibility
are crucial while performing tasks. A speech-based VQA system may provide a
better means of interaction where information can be accessed while performing
tasks simultaneously. To this end, this work implements a speech-based VQA
system by introducing a Textless Multilingual Pathological VQA (TMPathVQA)
dataset, an expansion of the PathVQA dataset, containing spoken questions in
English, German & French. This dataset comprises 98,397 multilingual spoken
questions and answers based on 5,004 pathological images along with 70 hours of
audio. Finally, this work benchmarks and compares TMPathVQA systems implemented
using various combinations of acoustic and visual features.

æè¦ï¼å¨é«çä¿å¥åé«çè¨ºæ·ä¸­ï¼è¦è¦ºåç­ï¼VQAï¼å¯è½æçºééµå·¥å·ï¼å¨åæè¤éçé«çå½±åå°æ¼æºç¢ºè¨ºæ·è³ééè¦çå ´æ¯ä¸­ãç®åçåºæ¼æå­ç VQA ç³»çµ±éå¶äºå®åå¨å·è¡ä»»åæåæäºååå¯åæ§è³ééè¦çå ´æ¯ä¸­çæç¨ãåºæ¼èªé³ç VQA ç³»çµ±å¯è½æä¾æ´å¥½çäºåæ¹å¼ï¼å¯ä»¥å¨å·è¡ä»»åçåæå­åè³è¨ãçºæ­¤ï¼æ¬ç ç©¶ééå°å¥ç¡æå­å¤èªè¨çç VQAï¼TMPathVQAï¼è³æéï¼æ´åäº PathVQA è³æéï¼åå«è±èªãå¾·èªåæ³èªçå£èªªåé¡ï¼å¯¦ä½äºä¸ååºæ¼èªé³ç VQA ç³»çµ±ãæ­¤è³æéåå« 98,397 åå¤èªè¨çå£èªªåé¡åç­æ¡ï¼åºæ¼ 5,004 åççå½±åä»¥å 70 å°æçé³è¨ãæå¾ï¼æ¬ç ç©¶ä½¿ç¨åç¨®é³è¨åè¦è¦ºç¹å¾µççµåä¾å¯¦ä½ TMPathVQA ç³»çµ±ï¼ä¸¦é²è¡åºæºæ¸¬è©¦åæ¯è¼ã

##### **Performance Evaluation of Lightweight Open-source Large Language Models in Pediatric Consultations: A Comparative Analysis**
2407.15862v1 by Qiuhong Wei, Ying Cui, Mengwei Ding, Yanqin Wang, Lingling Xiang, Zhengxiong Yao, Ceran Chen, Ying Long, Zhezhen Jin, Ximing Xu

Large language models (LLMs) have demonstrated potential applications in
medicine, yet data privacy and computational burden limit their deployment in
healthcare institutions. Open-source and lightweight versions of LLMs emerge as
potential solutions, but their performance, particularly in pediatric settings
remains underexplored. In this cross-sectional study, 250 patient consultation
questions were randomly selected from a public online medical forum, with 10
questions from each of 25 pediatric departments, spanning from December 1,
2022, to October 30, 2023. Two lightweight open-source LLMs, ChatGLM3-6B and
Vicuna-7B, along with a larger-scale model, Vicuna-13B, and the widely-used
proprietary ChatGPT-3.5, independently answered these questions in Chinese
between November 1, 2023, and November 7, 2023. To assess reproducibility, each
inquiry was replicated once. We found that ChatGLM3-6B demonstrated higher
accuracy and completeness than Vicuna-13B and Vicuna-7B (P < .001), but all
were outperformed by ChatGPT-3.5. ChatGPT-3.5 received the highest ratings in
accuracy (65.2%) compared to ChatGLM3-6B (41.2%), Vicuna-13B (11.2%), and
Vicuna-7B (4.4%). Similarly, in completeness, ChatGPT-3.5 led (78.4%), followed
by ChatGLM3-6B (76.0%), Vicuna-13B (34.8%), and Vicuna-7B (22.0%) in highest
ratings. ChatGLM3-6B matched ChatGPT-3.5 in readability, both outperforming
Vicuna models (P < .001). In terms of empathy, ChatGPT-3.5 outperformed the
lightweight LLMs (P < .001). In safety, all models performed comparably well (P
> .05), with over 98.4% of responses being rated as safe. Repetition of
inquiries confirmed these findings. In conclusion, Lightweight LLMs demonstrate
promising application in pediatric healthcare. However, the observed gap
between lightweight and large-scale proprietary LLMs underscores the need for
continued development efforts.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²å±ç¾åºå¨é«çä¿å¥é åçæ½å¨æç¨ï¼ä½è³æé±ç§åéç®è² æéå¶äºå®åå¨é«çä¿å¥æ©æ§ä¸­çé¨ç½²ãéæ¾åå§ç¢¼åè¼éç´çæ¬ç LLM æçºæ½å¨çè§£æ±ºæ¹æ¡ï¼ä½å®åçæè½ï¼ç¹å¥æ¯å¨åç§é åçæè½ï¼ä»æªè¢«ååæ¢è¨ãå¨éé æ©«æ·é¢ç ç©¶ä¸­ï¼å¾ä¸åå¬éçç·ä¸é«çè«å£ä¸­é¨æ©é¸åäº 250 åæ£èè«®è©¢åé¡ï¼æ¯ååç§é¨éå 10 ååé¡ï¼æéè·¨åº¦å¾ 2022 å¹´ 12 æ 1 æ¥å° 2023 å¹´ 10 æ 30 æ¥ãå©åè¼éç´çéæ¾åå§ç¢¼ LLMï¼ChatGLM3-6B å Vicuna-7Bï¼ä»¥åä¸åæ´å¤§è¦æ¨¡çæ¨¡å Vicuna-13Bï¼éæå»£æ³ä½¿ç¨çå°æ ChatGPT-3.5ï¼å¨ 2023 å¹´ 11 æ 1 æ¥å° 2023 å¹´ 11 æ 7 æ¥æéç¨ç«ç¨ä¸­æåç­äºéäºåé¡ãçºäºè©ä¼°å¯è¤è£½æ§ï¼æ¯åæ¥è©¢é½è¤è£½äºä¸æ¬¡ãæåç¼ç¾ ChatGLM3-6B çæºç¢ºæ§åå®æ´æ§é«æ¼ Vicuna-13B å Vicuna-7B (P < .001)ï¼ä½ææéäºé½ä½æ¼ ChatGPT-3.5ãChatGPT-3.5 å¨æºç¢ºæ§æ¹é¢ç²å¾äºæé«è©å (65.2%)ï¼è ChatGLM3-6B (41.2%)ãVicuna-13B (11.2%) å Vicuna-7B (4.4%) çè©åè¼ä½ãåæ¨£å°ï¼å¨å®æ´æ§æ¹é¢ï¼ChatGPT-3.5 é å (78.4%)ï¼å¶æ¬¡æ¯ ChatGLM3-6B (76.0%)ãVicuna-13B (34.8%) å Vicuna-7B (22.0%) çè©åæé«ãChatGLM3-6B å¨å¯è®æ§æ¹é¢è ChatGPT-3.5 ç¸å¹éï¼å©èé½åªæ¼ Vicuna æ¨¡å (P < .001)ãå¨åçå¿æ¹é¢ï¼ChatGPT-3.5 åªæ¼è¼éç´ LLM (P < .001)ãå¨å®å¨æ§æ¹é¢ï¼æææ¨¡åçè¡¨ç¾é½ç¸ç¶å¥½ (P > .05)ï¼è¶é 98.4% çåæè¢«è©çºå®å¨ãæ¥è©¢çéè¤ç¢ºèªäºéäºç¼ç¾ãçµè«æ¯ï¼è¼éç´ LLM å±ç¤ºäºå¨åç§é«çä¿å¥ä¸­çæç¨åæ¯ãç¶èï¼å¨è¼éç´åå¤§åå°æ LLM ä¹éè§å¯å°çå·®è·å¼·èª¿äºæçºéç¼å·¥ä½çéè¦æ§ã

##### **Leveraging Multimodal CycleGAN for the Generation of Anatomically Accurate Synthetic CT Scans from MRIs**
2407.10888v1 by Leonardo Crespi, Samuele Camnasio, Damiano Dei, Nicola Lambri, Pietro Mancosu, Marta Scorsetti, Daniele Loiacono

In many clinical settings, the use of both Computed Tomography (CT) and
Magnetic Resonance (MRI) is necessary to pursue a thorough understanding of the
patient's anatomy and to plan a suitable therapeutical strategy; this is often
the case in MRI-based radiotherapy, where CT is always necessary to prepare the
dose delivery, as it provides the essential information about the radiation
absorption properties of the tissues. Sometimes, MRI is preferred to contour
the target volumes. However, this approach is often not the most efficient, as
it is more expensive, time-consuming and, most importantly, stressful for the
patients. To overcome this issue, in this work, we analyse the capabilities of
different configurations of Deep Learning models to generate synthetic CT scans
from MRI, leveraging the power of Generative Adversarial Networks (GANs) and,
in particular, the CycleGAN architecture, capable of working in an unsupervised
manner and without paired images, which were not available. Several CycleGAN
models were trained unsupervised to generate CT scans from different MRI
modalities with and without contrast agents. To overcome the problem of not
having a ground truth, distribution-based metrics were used to assess the
model's performance quantitatively, together with a qualitative evaluation
where physicians were asked to differentiate between real and synthetic images
to understand how realistic the generated images were. The results show how,
depending on the input modalities, the models can have very different
performances; however, models with the best quantitative results, according to
the distribution-based metrics used, can generate very difficult images to
distinguish from the real ones, even for physicians, demonstrating the
approach's potential.

æè¦ï¼å¨è¨±å¤è¨åºç°å¢ä¸­ï¼éè¦ä½¿ç¨é»è¦æ·å±¤ææ (CT) åç£æ¯é å½± (MRI) ä¾å¾¹åºäºè§£æ£èçè§£åçµæ§ï¼ä¸¦è¦åé©ç¶çæ²»çç­ç¥ï¼ééå¸¸ç¼çå¨åºæ¼ MRI çæ¾å°æ²»çä¸­ï¼å¶ä¸­ CT å°æ¼æºååéå³éç¸½æ¯å¿è¦çï¼å çºå®æä¾äºæéçµç¹è¼»å°å¸æ¶ç¹æ§çåºæ¬è³è¨ãææï¼MRI åªåæ¼å¾åç®æ¨é«ç©ãç¶èï¼éç¨®æ¹æ³éå¸¸ä¸æ¯æææççï¼å çºå®æ´æè²´ãèæï¼æéè¦çæ¯æè®æ£èæå°å£åãçºäºåæéååé¡ï¼å¨éé å·¥ä½ä¸­ï¼æååæäºæ·±åº¦å­¸ç¿æ¨¡åçä¸åéç½®ï¼ä»¥å¾ MRI çæåæ CT ææçè½åï¼å©ç¨çæå°æç¶²è·¯ (GAN) çåè½ï¼ç¹å¥æ¯ CycleGAN æ¶æ§ï¼è½å¤ ä»¥ç¡ç£ç£çæ¹å¼å·¥ä½ï¼èä¸ä¸éè¦æå°çå½±åï¼èéäºå½±åä¸¦ä¸å¯ç¨ãå¹¾å CycleGAN æ¨¡åç¶éç¡ç£ç£è¨ç·´ï¼ä»¥å¾ä¸å MRI æ¨¡å¼çæ CT ææï¼ç¡è«æ¯å¦ä½¿ç¨å°æ¯åãçºäºåææ²æåºæ¬äºå¯¦çåé¡ï¼åºæ¼åä½çææ¨è¢«ç¨æ¼å®éè©ä¼°æ¨¡åçæè½ï¼ä»¥åå®æ§è©ä¼°ï¼å¶ä¸­è¦æ±é«çååçå¯¦ååæå½±åï¼ä»¥äºè§£çæçå½±åæå¤é¼çãçµæé¡¯ç¤ºï¼æ ¹æè¼¸å¥æ¨¡å¼ï¼æ¨¡åçæè½å¯è½å¤§ä¸ç¸åï¼ç¶èï¼æ ¹ææä½¿ç¨çåºæ¼åä½çææ¨ï¼å·ææä½³å®éçµæçæ¨¡åå¯ä»¥ç¢çéå¸¸é£ä»¥èçå¯¦å½±åååçå½±åï¼å³ä½¿å°æ¼é«çä¾èªªä¹æ¯å¦æ­¤ï¼éè­æäºéç¨®æ¹æ³çæ½åã

##### **Towards Enhanced Classification of Abnormal Lung sound in Multi-breath: A Light Weight Multi-label and Multi-head Attention Classification Method**
2407.10828v1 by Yi-Wei Chua, Yun-Chien Cheng

This study aims to develop an auxiliary diagnostic system for classifying
abnormal lung respiratory sounds, enhancing the accuracy of automatic abnormal
breath sound classification through an innovative multi-label learning approach
and multi-head attention mechanism. Addressing the issue of class imbalance and
lack of diversity in existing respiratory sound datasets, our study employs a
lightweight and highly accurate model, using a two-dimensional label set to
represent multiple respiratory sound characteristics. Our method achieved a
59.2% ICBHI score in the four-category task on the ICBHI2017 dataset,
demonstrating its advantages in terms of lightweight and high accuracy. This
study not only improves the accuracy of automatic diagnosis of lung respiratory
sound abnormalities but also opens new possibilities for clinical applications.

æè¦ï¼æ¬ç ç©¶æ¨å¨éç¼ä¸åè¼å©è¨ºæ·ç³»çµ±ï¼ç¨æ¼åé¡ç°å¸¸çèºé¨å¼å¸é³ï¼ééåµæ°çå¤æ¨ç±¤å­¸ç¿æ¹æ³åå¤é ­æ³¨æåæ©å¶ï¼æåèªåç°å¸¸å¼å¸é³åé¡çæºç¢ºåº¦ãéå°ç¾æå¼å¸é³è³æéä¸­é¡å¥ä¸å¹³è¡¡åç¼ºä¹å¤æ¨£æ§çåé¡ï¼æ¬ç ç©¶æ¡ç¨è¼éä¸é«ç²¾ç¢ºåº¦çæ¨¡åï¼ä½¿ç¨äºç¶­æ¨ç±¤çµä¾è¡¨ç¤ºå¤éå¼å¸é³ç¹å¾µãæåçæ¨¡åå¨ ICBHI2017 è³æéçåé¡å¥ä»»åä¸­ï¼ç²å¾äº 59.2% ç ICBHI åæ¸ï¼è­æäºå¶å¨è¼éååé«æºç¢ºåº¦æ¹é¢çåªå¢ãæ¬ç ç©¶ä¸åæåäºèºé¨å¼å¸é³ç°å¸¸èªåè¨ºæ·çæºç¢ºåº¦ï¼ä¹çºè¨åºæç¨éåäºæ°çå¯è½æ§ã

##### **Classification of Heart Sounds Using Multi-Branch Deep Convolutional Network and LSTM-CNN**
2407.10689v1 by Seyed Amir Latifi, Hassan Ghassemian, Maryam Imani

This paper presents a fast and cost-effective method for diagnosing cardiac
abnormalities with high accuracy and reliability using low-cost systems in
clinics. The primary limitation of automatic diagnosing of cardiac diseases is
the rarity of correct and acceptable labeled samples, which can be expensive to
prepare. To address this issue, two methods are proposed in this work. The
first method is a unique Multi-Branch Deep Convolutional Neural Network (MBDCN)
architecture inspired by human auditory processing, specifically designed to
optimize feature extraction by employing various sizes of convolutional filters
and audio signal power spectrum as input. In the second method, called as Long
short-term memory-Convolutional Neural (LSCN) model, Additionally, the network
architecture includes Long Short-Term Memory (LSTM) network blocks to improve
feature extraction in the time domain. The innovative approach of combining
multiple parallel branches consisting of the one-dimensional convolutional
layers along with LSTM blocks helps in achieving superior results in audio
signal processing tasks. The experimental results demonstrate superiority of
the proposed methods over the state-of-the-art techniques. The overall
classification accuracy of heart sounds with the LSCN network is more than 96%.
The efficiency of this network is significant compared to common feature
extraction methods such as Mel Frequency Cepstral Coefficients (MFCC) and
wavelet transform. Therefore, the proposed method shows promising results in
the automatic analysis of heart sounds and has potential applications in the
diagnosis and early detection of cardiovascular diseases.

æè¦ï¼æ¬ææåºäºä¸ç¨®å¿«éä¸ç¶æ¿ææçæ¹æ³ï¼ä½¿ç¨ä½ææ¬çç³»çµ±å¨è¨ºæè¨ºæ·å¿èç°å¸¸ï¼ä¸å·æé«æºç¢ºåº¦åå¯é æ§ãèªåè¨ºæ·å¿èç¾ççä¸»è¦éå¶æ¯æ­£ç¢ºä¸å¯æ¥åçæ¨ç±¤æ¨£æ¬ç¨å°ï¼èä¸æºåèµ·ä¾å¯è½å¾æè²´ãçºäºè§£æ±ºéååé¡ï¼éé å·¥ä½æåºäºå©ç¨®æ¹æ³ãç¬¬ä¸ç¨®æ¹æ³æ¯ä¸ç¨®ç¨ç¹çå¤åæ¯æ·±åº¦å·ç©ç¥ç¶ç¶²è·¯ (MBDCN) æ¶æ§ï¼éæä¾èªäººé¡è½è¦ºèçï¼ç¹å¥è¨­è¨çºééæ¡ç¨åç¨®å¤§å°çå·ç©æ¿¾æ³¢å¨åé³è¨è¨èåçè­ä½çºè¼¸å¥ï¼ä¾æä½³åç¹å¾µæåãå¨ç¬¬äºç¨®æ¹æ³ä¸­ï¼ç¨±çºé·ç­æè¨æ¶ - å·ç©ç¥ç¶ (LSCN) æ¨¡åï¼æ­¤å¤ï¼ç¶²è·¯æ¶æ§åæ¬é·ç­æè¨æ¶ (LSTM) ç¶²è·¯åå¡ï¼ä»¥æ¹åæåä¸­çç¹å¾µæåãçµåç±ä¸ç¶­å·ç©å±¤å LSTM åå¡çµæçå¤åä¸¦è¡åæ¯çåµæ°æ¹æ³ï¼æå©æ¼å¨é³è¨è¨èèçä»»åä¸­éæåªç°ççµæãå¯¦é©çµæè­æäºææåºçæ¹æ³åªæ¼æåé²çæè¡ãLSCN ç¶²è·¯å°å¿é³çæ´é«åé¡æºç¢ºåº¦è¶é 96%ãèå¸¸è¦çç¹å¾µæåæ¹æ³ï¼ä¾å¦æ¢ç¾é »çåè­ä¿æ¸ (MFCC) åå°æ³¢è½æï¼ç¸æ¯ï¼æ­¤ç¶²è·¯çæçé¡¯èãå æ­¤ï¼ææåºçæ¹æ³å¨å¿é³çèªååæä¸­é¡¯ç¤ºåºæå¸æççµæï¼ä¸¦ä¸å¨å¿è¡ç®¡ç¾ççè¨ºæ·åæ©ææª¢æ¸¬ä¸­å·ææ½å¨æç¨ã

##### **Spatio-temporal neural distance fields for conditional generative modeling of the heart**
2407.10663v1 by Kristine SÃ¸rensen, Paula Diez, Jan Margeta, Yasmin El Youssef, Michael Pham, Jonas Jalili Pedersen, Tobias KÃ¼hl, Ole de Backer, Klaus Kofoed, Oscar Camara, Rasmus Paulsen

The rhythmic pumping motion of the heart stands as a cornerstone in life, as
it circulates blood to the entire human body through a series of carefully
timed contractions of the individual chambers. Changes in the size, shape and
movement of the chambers can be important markers for cardiac disease and
modeling this in relation to clinical demography or disease is therefore of
interest. Existing methods for spatio-temporal modeling of the human heart
require shape correspondence over time or suffer from large memory
requirements, making it difficult to use for complex anatomies. We introduce a
novel conditional generative model, where the shape and movement is modeled
implicitly in the form of a spatio-temporal neural distance field and
conditioned on clinical demography. The model is based on an auto-decoder
architecture and aims to disentangle the individual variations from that
related to the clinical demography. It is tested on the left atrium (including
the left atrial appendage), where it outperforms current state-of-the-art
methods for anatomical sequence completion and generates synthetic sequences
that realistically mimics the shape and motion of the real left atrium. In
practice, this means we can infer functional measurements from a static image,
generate synthetic populations with specified demography or disease and
investigate how non-imaging clinical data effect the shape and motion of
cardiac anatomies.

æè¦ï¼å¿èæç¯å¥çè·³ååä½æ¯çå½ä¸­çåºç³ï¼å çºå®ééä¸ç³»åä»ç´°è¨æçå®ç¨å¿å®¤æ¶ç¸®ï¼å°è¡æ¶²å¾ªç°å°æ´åèº«é«ãå¿å®¤çå¤§å°ãå½¢çåéåçè®åå¯è½æ¯å¿èç¾ççéè¦æ¨è¨ï¼å æ­¤å°æ­¤é²è¡å»ºæ¨¡ä»¥éè¯è¨åºäººå£çµ±è¨æç¾çï¼å æ­¤å·ææç¾©ãç¾æçæç©ºå»ºæ¨¡æ¹æ³éè¦é¨èæéæ¨ç§»é²è¡å½¢çå°æï¼æéè¦å¤§éçè¨æ¶é«éæ±ï¼éä½¿å¾é£ä»¥ç¨æ¼è¤éçè§£åçµæ§ãæåå¼å¥äºä¸åæ°ç©çæ¢ä»¶çææ¨¡åï¼å¶ä¸­å½¢çåéåä»¥æç©ºç¥ç¶è·é¢å ´çå½¢å¼é±å«å»ºæ¨¡ï¼ä¸¦æ ¹æè¨åºäººå£çµ±è¨é²è¡æ¢ä»¶è¨­å®ãè©²æ¨¡ååºæ¼èªåç·¨ç¢¼å¨æ¶æ§ï¼æ¨å¨è§£éèè¨åºäººå£çµ±è¨ç¸éçåå¥è®ç°ãå®å¨å·¦å¿æ¿ï¼åæ¬å·¦å¿è³ï¼ä¸é²è¡æ¸¬è©¦ï¼å¨è§£ååºåå®ææ¹é¢åªæ¼ç¶åæåé²çæ¹æ³ï¼ä¸¦çæé¼çå°æ¨¡æ¬çå¯¦å·¦å¿æ¿å½¢çåéåçåæåºåãå¯¦éä¸ï¼éæå³èæåå¯ä»¥å¾éæå½±åæ¨æ·åè½æ§æ¸¬éï¼çæå·æç¹å®äººå£çµ±è¨æç¾ççåææç¾¤ï¼ä¸¦èª¿æ¥éå½±åè¨åºè³æå¦ä½å½±é¿å¿èè§£åçµæ§çå½¢çåéåã

##### **TCM-FTP: Fine-Tuning Large Language Models for Herbal Prescription Prediction**
2407.10510v1 by Xingzhi Zhou, Xin Dong, Chunhao Li, Yuning Bai, Yulong Xu, Ka Chun Cheung, Simon See, Xinpeng Song, Runshun Zhang, Xuezhong Zhou, Nevin L. Zhang

Traditional Chinese medicine (TCM) relies on specific combinations of herbs
in prescriptions to treat symptoms and signs, a practice that spans thousands
of years. Predicting TCM prescriptions presents a fascinating technical
challenge with practical implications. However, this task faces limitations due
to the scarcity of high-quality clinical datasets and the intricate
relationship between symptoms and herbs. To address these issues, we introduce
DigestDS, a new dataset containing practical medical records from experienced
experts in digestive system diseases. We also propose a method, TCM-FTP (TCM
Fine-Tuning Pre-trained), to leverage pre-trained large language models (LLMs)
through supervised fine-tuning on DigestDS. Additionally, we enhance
computational efficiency using a low-rank adaptation technique. TCM-FTP also
incorporates data augmentation by permuting herbs within prescriptions,
capitalizing on their order-agnostic properties. Impressively, TCM-FTP achieves
an F1-score of 0.8031, surpassing previous methods significantly. Furthermore,
it demonstrates remarkable accuracy in dosage prediction, achieving a
normalized mean square error of 0.0604. In contrast, LLMs without fine-tuning
perform poorly. Although LLMs have shown capabilities on a wide range of tasks,
this work illustrates the importance of fine-tuning for TCM prescription
prediction, and we have proposed an effective way to do that.

æè¦ï¼ä¸­é«ä¾è³´ç¹å®ä¸­èè¥çµåä¾æ²»çççåå¾µåï¼éé åæ³å·²ææ¸åå¹´çæ­·å²ãé æ¸¬ä¸­é«èæ¹æ¯ä¸åå¼äººå¥åçæè¡ææ°ï¼å·æå¯¦éæç¾©ãç¶èï¼ç±æ¼ç¼ºä¹é«åè³ªçè¨åºæ¸æéä»¥åççèä¸­èè¥ä¹éçè¤ééä¿ï¼éé ä»»åé¢è¨éå¶ãçºäºè§£æ±ºéäºåé¡ï¼æåå¼å¥äº DigestDSï¼ä¸ååå«æ¶åç³»çµ±ç¾çç¶é©è±å¯å°å®¶å¯¦éçæ­·çæ°æ¸æéãæåéæåºäºä¸ç¨®æ¹æ³ï¼TCM-FTPï¼ä¸­é«å¾®èª¿é è¨ç·´ï¼ï¼ééå¨ DigestDS ä¸é²è¡ç£ç£å¾®èª¿ä¾å©ç¨é è¨ç·´çå¤§èªè¨æ¨¡å (LLM)ãæ­¤å¤ï¼æåä½¿ç¨ä½ç§©é©ææè¡ä¾æé«è¨ç®æçãTCM-FTP éééç½®æèæ¹ä¸­çä¸­èè¥ä¾ç´å¥æ¸ææ´åï¼å©ç¨å®åèé åºç¡éçç¹æ§ãä»¤äººå°è±¡æ·±å»çæ¯ï¼TCM-FTP éå°äº 0.8031 ç F1 åæ¸ï¼é¡¯èè¶è¶äºä»¥åçæ¹æ³ãæ­¤å¤ï¼å®å¨åéé æ¸¬ä¸­è¡¨ç¾åºé¡¯èçæºç¢ºæ§ï¼å¯¦ç¾äº 0.0604 çæ­¸ä¸ååæ¹èª¤å·®ãç¸æ¯ä¹ä¸ï¼æªç¶å¾®èª¿ç LLM è¡¨ç¾ä¸ä½³ãåç®¡ LLM å·²å¨å»£æ³çä»»åä¸­å±ç¾åºè½åï¼ä½éé å·¥ä½èªªæäºå¾®èª¿å°æ¼ä¸­é«èæ¹é æ¸¬çéè¦æ§ï¼èä¸æåæåºäºä¸åææçæ¹æ³ä¾åå°éä¸é»ã

##### **A Multi-Stage Framework for 3D Individual Tooth Segmentation in Dental CBCT**
2407.10433v1 by Chunshi Wang, Bin Zhao, Shuxue Ding

Cone beam computed tomography (CBCT) is a common way of diagnosing dental
related diseases. Accurate segmentation of 3D tooth is of importance for the
treatment. Although deep learning based methods have achieved convincing
results in medical image processing, they need a large of annotated data for
network training, making it very time-consuming in data collection and
annotation. Besides, domain shift widely existing in the distribution of data
acquired by different devices impacts severely the model generalization. To
resolve the problem, we propose a multi-stage framework for 3D tooth
segmentation in dental CBCT, which achieves the third place in the
"Semi-supervised Teeth Segmentation" 3D (STS-3D) challenge. The experiments on
validation set compared with other semi-supervised segmentation methods further
indicate the validity of our approach.

æè¦ï¼éçåæé»è¦æ·å±¤ææ (CBCT) æ¯ä¸ç¨®å¸¸è¦ççç§ç¸éç¾çè¨ºæ·æ¹å¼ã3D çé½çç²¾ç¢ºåå²å°æ¼æ²»çè³ééè¦ãåç®¡åºæ¼æ·±åº¦å­¸ç¿çæ¹æ³å¨é«å­¸å½±åèçä¸­å·²åå¾ä»¤äººä¿¡æçææï¼ä½å®åéè¦å¤§éçè¨»è§£è³æé²è¡ç¶²è·¯è¨ç·´ï¼éä½¿å¾è³ææ¶éåè¨»è§£éå¸¸èæãæ­¤å¤ï¼å¨ä¸åè£ç½®åå¾çè³æåä½ä¸­å»£æ³å­å¨çé åè½ç§»æå´éå½±é¿æ¨¡åçæ³åè½åãçºäºè§£æ±ºéååé¡ï¼æåæåºäºä¸åå¤éæ®µæ¶æ§ï¼ç¨æ¼çç§ CBCT ä¸­ç 3D çé½åå²ï¼å¨ãåç£ç£çé½åå²ã3D (STS-3D) ææ°ä¸­ç²å¾ç¬¬ä¸åãèå¶ä»åç£ç£åå²æ¹æ³ç¸æ¯ï¼å¨é©è­éä¸çå¯¦é©é²ä¸æ­¥è­æäºæåæ¹æ³çæææ§ã

##### **Static and multivariate-temporal attentive fusion transformer for readmission risk prediction**
2407.11096v1 by Zhe Sun, Runzhi Li, Jing Wang, Gang Chen, Siyu Yan, Lihong Ma

Background: Accurate short-term readmission prediction of ICU patients is
significant in improving the efficiency of resource assignment by assisting
physicians in making discharge decisions. Clinically, both individual static
static and multivariate temporal data collected from ICU monitors play critical
roles in short-term readmission prediction. Informative static and multivariate
temporal feature representation capturing and fusion present challenges for
accurate readmission prediction. Methods:We propose a novel static and
multivariate-temporal attentive fusion transformer (SMTAFormer) to predict
short-term readmission of ICU patients by fully leveraging the potential of
demographic and dynamic temporal data. In SMTAFormer, we first apply an MLP
network and a temporal transformer network to learn useful static and temporal
feature representations, respectively. Then, the well-designed static and
multivariate temporal feature fusion module is applied to fuse static and
temporal feature representations by modeling intra-correlation among
multivariate temporal features and constructing inter-correlation between
static and multivariate temporal features. Results: We construct a readmission
risk assessment (RRA) dataset based on the MIMIC-III dataset. The extensive
experiments show that SMTAFormer outperforms advanced methods, in which the
accuracy of our proposed method is up to 86.6%, and the area under the receiver
operating characteristic curve (AUC) is up to 0.717. Conclusion: Our proposed
SMTAFormer can efficiently capture and fuse static and multivariate temporal
feature representations. The results show that SMTAFormer significantly
improves the short-term readmission prediction performance of ICU patients
through comparisons to strong baselines.

æè¦ï¼<paragraph>èæ¯ï¼ç²¾æºç­æéè¿é æ¸¬éçå è­·çæ¿ï¼ICUï¼çäººå°æ¼æåè³æºåéæçè³ééè¦ï¼è½åå©é«å¸«ååºåºé¢æ±ºç­ãè¨åºä¸ï¼å¾ ICU ç£æ¸¬å¨æ¶éå°çåå¥éæè³æåå¤è®éæéè³æå¨ç­æéè¿é æ¸¬ä¸­æ®æ¼ééµè§è²ãæ·ååèåææç¾©çéæåå¤è®éæéç¹å¾µè¡¨å¾µå°æ¼ç²¾æºéè¿é æ¸¬æ§æææ°ãæ¹æ³ï¼æåæåºä¸åæ°ç©çéæåå¤è®éæéæ³¨æåèåTransformerï¼SMTAFormerï¼ï¼èç±ååå©ç¨äººå£çµ±è¨ååææéè³æçæ½åï¼ä¾é æ¸¬ ICU çäººçç­æéè¿ãå¨ SMTAFormer ä¸­ï¼æåé¦åæç¨ä¸å MLP ç¶²è·¯åä¸åæéTransformerç¶²è·¯ï¼åå¥å­¸ç¿æç¨çéæåæéç¹å¾µè¡¨å¾µãç¶å¾ï¼æç¨ç²¾å¿è¨­è¨çéæåå¤è®éæéç¹å¾µèåæ¨¡çµï¼èç±å»ºæ¨¡å¤è®éæéç¹å¾µä¹éçå§é¨ç¸éæ§ï¼ä»¥åå»ºæ§éæåå¤è®éæéç¹å¾µä¹éçç¸äºéè¯æ§ï¼ä¾èåéæåæéç¹å¾µè¡¨å¾µãçµæï¼æåæ ¹æ MIMIC-III è³æéå»ºæ§ä¸åéè¿é¢¨éªè©ä¼°ï¼RRAï¼è³æéãå»£æ³çå¯¦é©é¡¯ç¤ºï¼SMTAFormer åªæ¼é²éæ¹æ³ï¼å¶ä¸­æåæåºçæ¹æ³çæºç¢ºåº¦é«é 86.6%ï¼èåè©¦èå·¥ä½ç¹æ§æ²ç·ï¼AUCï¼ä¸çé¢ç©é«é 0.717ãçµè«ï¼æåæåºç SMTAFormer è½æææ·ååèåéæåå¤è®éæéç¹å¾µè¡¨å¾µãçµæé¡¯ç¤ºï¼SMTAFormer èç±èå¼·å¤§çåºç·æ¯è¼ï¼é¡¯èæå ICU çäººçç­æéè¿é æ¸¬æè½ã</paragraph>

##### **Evolved Developmental Artificial Neural Networks for Multitasking with Advanced Activity Dependence**
2407.10359v1 by Yintong Zhang, Jason A. Yoder

Recently, Cartesian Genetic Programming has been used to evolve developmental
programs to guide the formation of artificial neural networks (ANNs). This
approach has demonstrated success in enabling ANNs to perform multiple tasks
while avoiding catastrophic forgetting. One unique aspect of this approach is
the use of separate developmental programs evolved to regulate the development
of separate soma and dendrite units. An opportunity afforded by this approach
is the ability to incorporate Activity Dependence (AD) into the model such that
environmental feedback can help to regulate the behavior of each type of unit.
Previous work has shown a limited version of AD (influencing neural bias) to
provide marginal improvements over non-AD ANNs. In this work, we present
promising results from new extensions to AD. Specifically, we demonstrate a
more significant improvement via AD on new neural parameters including health
and position, as well as a combination of all of these along with bias. We
report on the implications of this work and suggest several promising
directions for future work.

æè¦ï¼æè¿ï¼ç¬å¡å°éä¼ è§åå·²è¢«ç¨äºè¿ååè²ç¨åºï¼ä»¥æå¯¼äººå·¥ç¥ç»ç½ç» (ANN) çå½¢æãè¿ç§æ¹æ³å·²è¯æè½å¤è®© ANN æ§è¡å¤é¡¹ä»»å¡ï¼åæ¶é¿åç¾é¾æ§éå¿ãè¿ç§æ¹æ³çä¸ä¸ªç¬ç¹æ¹é¢æ¯ä½¿ç¨åç¬çåå±ç¨åºæ¥è°èåç¬çèº¯ä½åæ çªååçåå±ãè¿ç§æ¹æ³æä¾äºä¸ä¸ªæºä¼ï¼å³è½å¤å°æ´»å¨ä¾èµæ§ (AD) çº³å¥æ¨¡åï¼ä»¥ä¾¿ç¯å¢åé¦å¯ä»¥å¸®å©è°èæ¯ç§ç±»åçååçè¡ä¸ºãä»¥åçå·¥ä½å·²ç»å±ç¤ºäº AD çä¸ä¸ªæéçæ¬ï¼å½±åç¥ç»åç½®ï¼ï¼ä»¥æä¾å¯¹é AD ANN çè¾¹éæ¹è¿ãå¨è¿é¡¹å·¥ä½ä¸­ï¼æä»¬å±ç¤ºäº AD æ°æ©å±çä»¤äººé¼èçç»æãå·ä½æ¥è¯´ï¼æä»¬éè¿ AD å¨æ°çç¥ç»åæ°ï¼åæ¬å¥åº·åä½ç½®ï¼ä»¥åææè¿äºåæ°ä¸åç½®çç»åä¸å±ç¤ºäºæ´æ¾ççæ¹è¿ãæä»¬æ¥åäºè¿é¡¹å·¥ä½çå½±åï¼å¹¶ä¸ºæªæ¥çå·¥ä½æåºäºå ä¸ªæå¸æçæ¹åã

##### **Learning Unlabeled Clients Divergence via Anchor Model Aggregation for Federated Semi-supervised Learning**
2407.10327v1 by Marawan Elbatel, Hualiang Wang, Jixiang Chen, Hao Wang, Xiaomeng Li

Federated semi-supervised learning (FedSemi) refers to scenarios where there
may be clients with fully labeled data, clients with partially labeled, and
even fully unlabeled clients while preserving data privacy. However, challenges
arise from client drift due to undefined heterogeneous class distributions and
erroneous pseudo-labels. Existing FedSemi methods typically fail to aggregate
models from unlabeled clients due to their inherent unreliability, thus
overlooking unique information from their heterogeneous data distribution,
leading to sub-optimal results. In this paper, we enable unlabeled client
aggregation through SemiAnAgg, a novel Semi-supervised Anchor-Based federated
Aggregation. SemiAnAgg learns unlabeled client contributions via an anchor
model, effectively harnessing their informative value. Our key idea is that by
feeding local client data to the same global model and the same consistently
initialized anchor model (i.e., random model), we can measure the importance of
each unlabeled client accordingly. Extensive experiments demonstrate that
SemiAnAgg achieves new state-of-the-art results on four widely used FedSemi
benchmarks, leading to substantial performance improvements: a 9% increase in
accuracy on CIFAR-100 and a 7.6% improvement in recall on the medical dataset
ISIC-18, compared with prior state-of-the-art. Code is available at:
https://github.com/xmed-lab/SemiAnAgg.

æè¦ï¼è¯é¦åç£ç£å­¸ç¿ (FedSemi) æçæ¯å¨ä¿è­·è³æé±ç§çåæï¼å¯è½å­å¨å·æå®å¨æ¨ç±¤è³æçå®¢æ¶ç«¯ãå·æé¨åæ¨ç±¤çå®¢æ¶ç«¯ï¼çè³å®å¨æ²ææ¨ç±¤çå®¢æ¶ç«¯çææ³ãç¶èï¼ç±æ¼æªå®ç¾©çç°è³ªé¡å¥åä½åé¯èª¤çå½æ¨ç±¤ï¼å®¢æ¶ç«¯æ¼ç§»å¸¶ä¾äºææ°ãç¾æç FedSemi æ¹æ³éå¸¸ç¡æ³å½ç¸½ä¾èªæªæ¨ç±¤å®¢æ¶ç«¯çæ¨¡åï¼å çºå®åæ¬è³ªä¸ä¸å¯é ï¼å æ­¤å¿½ç¥äºå¶ç°è³ªè³æåä½ä¸­çç¨ç¹è³è¨ï¼å°è´æ¬¡ä½³çµæãå¨æ¬æä¸­ï¼æåéé SemiAnAggï¼ä¸ç¨®æ°ç©çåç£ç£é¨å®å¼è¯é¦èåï¼åç¨æªæ¨ç±¤å®¢æ¶ç«¯èåãSemiAnAgg ééé¨å®æ¨¡åå­¸ç¿æªæ¨ç±¤å®¢æ¶ç«¯è²¢ç»ï¼ææå©ç¨å¶è³è¨å¹å¼ãæåçééµæ§æ³æ¯ï¼ééå°æ¬å°å®¢æ¶ç«¯è³ææä¾çµ¦ç¸åçå¨çæ¨¡ååç¸åä¸è´åå§åçé¨å®æ¨¡åï¼å³é¨æ©æ¨¡åï¼ï¼æåå¯ä»¥ç¸æå°è¡¡éæ¯åæªæ¨ç±¤å®¢æ¶ç«¯çéè¦æ§ãå»£æ³çå¯¦é©è­æ SemiAnAgg å¨ååå»£æ³ä½¿ç¨ç FedSemi åºæºä¸ç²å¾äºæ°çæåé²çµæï¼å¸¶ä¾äºé¡¯èçæè½æåï¼èååçæåé²æè¡ç¸æ¯ï¼CIFAR-100 çæºç¢ºåº¦æé«äº 9%ï¼é«çè³æé ISIC-18 çå¬åçæé«äº 7.6%ãç¨å¼ç¢¼å¯å¨ https://github.com/xmed-lab/SemiAnAgg åå¾ã

##### **Rapid Biomedical Research Classification: The Pandemic PACT Advanced Categorisation Engine**
2407.10086v2 by Omid Rohanian, Mohammadmahdi Nouriborji, Olena Seminog, Rodrigo Furst, Thomas Mendy, Shanthi Levanita, Zaharat Kadri-Alabi, Nusrat Jabin, Daniela Toale, Georgina Humphreys, Emilia Antonio, Adrian Bucher, Alice Norton, David A. Clifton

This paper introduces the Pandemic PACT Advanced Categorisation Engine
(PPACE) along with its associated dataset. PPACE is a fine-tuned model
developed to automatically classify research abstracts from funded biomedical
projects according to WHO-aligned research priorities. This task is crucial for
monitoring research trends and identifying gaps in global health preparedness
and response. Our approach builds on human-annotated projects, which are
allocated one or more categories from a predefined list. A large language model
is then used to generate `rationales' explaining the reasoning behind these
annotations. This augmented data, comprising expert annotations and rationales,
is subsequently used to fine-tune a smaller, more efficient model. Developed as
part of the Pandemic PACT project, which aims to track and analyse research
funding and clinical evidence for a wide range of diseases with outbreak
potential, PPACE supports informed decision-making by research funders,
policymakers, and independent researchers. We introduce and release both the
trained model and the instruction-based dataset used for its training. Our
evaluation shows that PPACE significantly outperforms its baselines. The
release of PPACE and its associated dataset offers valuable resources for
researchers in multilabel biomedical document classification and supports
advancements in aligning biomedical research with key global health priorities.

æè¦ï¼æ¬æä»ç´¹äºæµè¡ç PACT é«ç´åé¡å¼æ (PPACE) åå¶ç¸éçè³æéãPPACE æ¯ä¸åå¾®èª¿æ¨¡åï¼ç¨æ¼æ ¹æ WHO å°é½çç ç©¶åªåäºé èªååé¡ç²å¾è³å©ççç©é«å­¸å°æ¡ç ç©¶æè¦ãéé ä»»åå°æ¼ç£æ§ç ç©¶è¶¨å¢åæ¾åºå¨çè¡çæºååæè®çç¼ºå£è³ééè¦ãæåçåæ³å»ºç«å¨äººå·¥æ¨è¨»çå°æ¡ä¸ï¼éäºå°æ¡å¾é åå®ç¾©çæ¸å®ä¸­åéä¸åæå¤åé¡å¥ãç¶å¾ä½¿ç¨å¤§åèªè¨æ¨¡åç¢çãä¾æãä¾è§£ééäºæ¨è¨»èå¾çæ¨çãæ­¤æ´åè³æåå«å°å®¶æ¨è¨»åä¾æï¼é¨å¾ç¨æ¼å¾®èª¿è¼å°ãæ´ææççæ¨¡åãPPACE ä½çºæµè¡ç PACT å°æ¡çä¸é¨åèéç¼ï¼æ¨å¨è¿½è¹¤ååæåç¨®å·æçç¼æ½åçç¾ççç ç©¶è³éåè¨åºè­æï¼ééç ç©¶è³éæä¾èãæ¿ç­å¶å®èåç¨ç«ç ç©¶äººå¡çææºæ±ºç­å¶å®æä¾æ¯æ´ãæåä»ç´¹ä¸¦éåºäºåè¨æ¨¡ååç¨æ¼å¶è¨ç·´çåºæ¼èªªæçè³æéãæåçè©ä¼°é¡¯ç¤º PPACE æé¡¯åªæ¼å¶åºæºãPPACE åå¶ç¸éè³æéçéåºçºå¤æ¨ç±¤çç©é«å­¸æä»¶åé¡çç ç©¶äººå¡æä¾äºå¯¶è²´çè³æºï¼ä¸¦æ¯æ´å°çç©é«å­¸ç ç©¶èééµå¨çè¡çåªåäºé å°é½çé²å±ã

##### **Document-level Clinical Entity and Relation Extraction via Knowledge Base-Guided Generation**
2407.10021v1 by Kriti Bhattarai, Inez Y. Oh, Zachary B. Abrams, Albert M. Lai

Generative pre-trained transformer (GPT) models have shown promise in
clinical entity and relation extraction tasks because of their precise
extraction and contextual understanding capability. In this work, we further
leverage the Unified Medical Language System (UMLS) knowledge base to
accurately identify medical concepts and improve clinical entity and relation
extraction at the document level. Our framework selects UMLS concepts relevant
to the text and combines them with prompts to guide language models in
extracting entities. Our experiments demonstrate that this initial concept
mapping and the inclusion of these mapped concepts in the prompts improves
extraction results compared to few-shot extraction tasks on generic language
models that do not leverage UMLS. Further, our results show that this approach
is more effective than the standard Retrieval Augmented Generation (RAG)
technique, where retrieved data is compared with prompt embeddings to generate
results. Overall, we find that integrating UMLS concepts with GPT models
significantly improves entity and relation identification, outperforming the
baseline and RAG models. By combining the precise concept mapping capability of
knowledge-based approaches like UMLS with the contextual understanding
capability of GPT, our method highlights the potential of these approaches in
specialized domains like healthcare.

æè¦ï¼çæå¼é¢è®­ç»è½¬æ¢å¨ (GPT) æ¨¡åå¨ä¸´åºå®ä½åå³ç³»æ½åä»»å¡ä¸­å±ç°åºæ½åï¼å ä¸ºå®ä»¬å·æç²¾ç¡®æ½ååä¸ä¸æçè§£è½åãå¨è¿é¡¹å·¥ä½ä¸­ï¼æä»¬è¿ä¸æ­¥å©ç¨ç»ä¸å»å­¦è¯­è¨ç³»ç» (UMLS) ç¥è¯åºæ¥åç¡®è¯å«å»å­¦æ¦å¿µï¼å¹¶å¨ææ¡£çº§å«æ¹è¿ä¸´åºå®ä½åå³ç³»æ½åãæä»¬çæ¡æ¶éæ©ä¸ææ¬ç¸å³ç UMLS æ¦å¿µï¼å¹¶å°å®ä»¬ä¸æç¤ºç¸ç»åï¼ä»¥æå¯¼è¯­è¨æ¨¡åæ½åå®ä½ãæä»¬çå®éªè¡¨æï¼ä¸ä¸å©ç¨ UMLS çéç¨è¯­è¨æ¨¡åä¸çå°éæ½åä»»å¡ç¸æ¯ï¼è¿ç§åå§æ¦å¿µæ å°åå¨æç¤ºä¸­åå«è¿äºæ å°æ¦å¿µæ¹è¿äºæ½åç»æãæ­¤å¤ï¼æä»¬çç»æè¡¨æï¼è¿ç§æ¹æ³æ¯æ åçæ£ç´¢å¢å¼ºçæ (RAG) ææ¯æ´ææï¼å¶ä¸­æ£ç´¢å°çæ°æ®ä¸æç¤ºåµå¥è¿è¡æ¯è¾ä»¥çæç»æãæ»ä½èè¨ï¼æä»¬åç°å° UMLS æ¦å¿µä¸ GPT æ¨¡åéæå¯ä»¥æ¾èæ¹åå®ä½åå³ç³»è¯å«ï¼ä¼äºåºçº¿å RAG æ¨¡åãéè¿å° UMLS ç­åºäºç¥è¯çæ¹æ³çç²¾ç¡®æ¦å¿µæ å°è½åä¸ GPT çä¸ä¸æçè§£è½åç¸ç»åï¼æä»¬çæ¹æ³çªåºäºè¿äºæ¹æ³å¨å»çä¿å¥ç­ä¸ä¸é¢åçæ½åã

##### **Causality extraction from medical text using Large Language Models (LLMs)**
2407.10020v1 by Seethalakshmi Gopalakrishnan, Luciana Garbayo, Wlodek Zadrozny

This study explores the potential of natural language models, including large
language models, to extract causal relations from medical texts, specifically
from Clinical Practice Guidelines (CPGs). The outcomes causality extraction
from Clinical Practice Guidelines for gestational diabetes are presented,
marking a first in the field. We report on a set of experiments using variants
of BERT (BioBERT, DistilBERT, and BERT) and using Large Language Models (LLMs),
namely GPT-4 and LLAMA2. Our experiments show that BioBERT performed better
than other models, including the Large Language Models, with an average
F1-score of 0.72. GPT-4 and LLAMA2 results show similar performance but less
consistency. We also release the code and an annotated a corpus of causal
statements within the Clinical Practice Guidelines for gestational diabetes.

æè¦ï¼æ¬ç ç©¶æ¢è¨èªç¶èªè¨æ¨¡åï¼åæ¬å¤§åèªè¨æ¨¡åï¼å¾é«å­¸ææ¬ä¸­èåå æéä¿çå¯è½æ§ï¼ç¹å¥æ¯å¾è¨åºå¯¦åæå (CPG) ä¸­ãç ç©¶ææçºå¦å¨ ç³å°¿ççè¨åºå¯¦åæåä¸­å æéä¿èåï¼çºè©²é åé¦ä¾ãæåå ±åäºä¸çµä½¿ç¨ BERT è®é« (BioBERTãDistilBERT å BERT) åä½¿ç¨å¤§åèªè¨æ¨¡å (LLM) çå¯¦é©ï¼å³ GPT-4 å LLAMA2ãæåçå¯¦é©é¡¯ç¤ºï¼BioBERT çè¡¨ç¾åªæ¼å¶ä»æ¨¡åï¼åæ¬å¤§åèªè¨æ¨¡åï¼å¹³å F1 åæ¸çº 0.72ãGPT-4 å LLAMA2 ççµæé¡¯ç¤ºåºé¡ä¼¼çè¡¨ç¾ï¼ä½ä¸è´æ§è¼ä½ãæåä¹éåºäºç¨å¼ç¢¼åå¦å¨ ç³å°¿çè¨åºå¯¦åæåä¸­å æé³è¿°çæ¨è¨»èªæåº«ã

##### **Pay Less On Clinical Images: Asymmetric Multi-Modal Fusion Method For Efficient Multi-Label Skin Lesion Classification**
2407.09999v1 by Peng Tang, Tobias Lasser

Existing multi-modal approaches primarily focus on enhancing multi-label skin
lesion classification performance through advanced fusion modules, often
neglecting the associated rise in parameters. In clinical settings, both
clinical and dermoscopy images are captured for diagnosis; however, dermoscopy
images exhibit more crucial visual features for multi-label skin lesion
classification. Motivated by this observation, we introduce a novel asymmetric
multi-modal fusion method in this paper for efficient multi-label skin lesion
classification. Our fusion method incorporates two innovative schemes. Firstly,
we validate the effectiveness of our asymmetric fusion structure. It employs a
light and simple network for clinical images and a heavier, more complex one
for dermoscopy images, resulting in significant parameter savings compared to
the symmetric fusion structure using two identical networks for both
modalities. Secondly, in contrast to previous approaches using mutual attention
modules for interaction between image modalities, we propose an asymmetric
attention module. This module solely leverages clinical image information to
enhance dermoscopy image features, considering clinical images as supplementary
information in our pipeline. We conduct the extensive experiments on the
seven-point checklist dataset. Results demonstrate the generality of our
proposed method for both networks and Transformer structures, showcasing its
superiority over existing methods We will make our code publicly available.

æè¦ï¼ç¾æçå¤æ¨¡å¼æ¹æ³ä¸»è¦å°æ³¨æ¼ééåé²çèåæ¨¡çµä¾å¢å¼·å¤æ¨ç±¤ç®èçè®åé¡æè½ï¼å¾å¾å¿½ç¥äºç¸éåæ¸çå¢å ãå¨è¨åºç°å¢ä¸­ï¼è¨åºä¸åç®èé¡å½±åé½æè¢«æ·åç¨æ¼è¨ºæ·ï¼ç¶èï¼ç®èé¡å½±åå±ç¾åºæ´éè¦çè¦è¦ºç¹å¾µï¼ç¨æ¼å¤æ¨ç±¤ç®èçè®åé¡ãåæ­¤è§å¯çµæåç¼ï¼æåå¨æ¬æä¸­ä»ç´¹ä¸ç¨®æ°ç©çä¸å°ç¨±å¤æ¨¡å¼èåæ¹æ³ï¼ç¨æ¼ææçå¤æ¨ç±¤ç®èçè®åé¡ãæåçèåæ¹æ³åå«å©ååµæ°çæ¹æ¡ãé¦åï¼æåé©è­äºæåçä¸å°ç¨±èåçµæ§çæææ§ãå®æ¡ç¨ä¸åè¼éä¸ç°¡å®çç¶²è·¯ç¨æ¼è¨åºå½±åï¼ä»¥åä¸åè¼éä¸è¤éçç¶²è·¯ç¨æ¼ç®èé¡å½±åï¼èä½¿ç¨å©åç¸åçç¶²è·¯ç¨æ¼å©ç¨®æ¨¡å¼çå°ç¨±èåçµæ§ç¸æ¯ï¼éæç¯çå¤§éçåæ¸ãå¶æ¬¡ï¼èååä½¿ç¨ç¸äºæ³¨æåæ¨¡çµç¨æ¼å½±åæ¨¡å¼ä¹éäºåçæ¹æ³ç¸åï¼æåæåºäºä¸åä¸å°ç¨±æ³¨æåæ¨¡çµãéåæ¨¡çµåå©ç¨è¨åºå½±åè³è¨ä¾å¢å¼·ç®èé¡å½±åç¹å¾µï¼å°è¨åºå½±åè¦çºæåæµç¨ä¸­çè£åè³è¨ãæåå¨ä¸é»æ ¸å°æ¸å®è³æéä¸é²è¡äºå»£æ³çå¯¦é©ãçµæè­æäºæåæåºçæ¹æ³å°ç¶²è·¯å Transformer çµæ§çæ®éæ§ï¼å±ç¤ºäºå®åªæ¼ç¾ææ¹æ³çåªè¶æ§ãæåå°å¬éæåçç¨å¼ç¢¼ã

##### **Evaluating the Impact of Different Quantum Kernels on the Classification Performance of Support Vector Machine Algorithm: A Medical Dataset Application**
2407.09930v2 by Emine Akpinar, Sardar M. N. Islam, Murat Oduncuoglu

The support vector machine algorithm with a quantum kernel estimator
(QSVM-Kernel), as a leading example of a quantum machine learning technique,
has undergone significant advancements. Nevertheless, its integration with
classical data presents unique challenges. While quantum computers primarily
interact with data in quantum states, embedding classical data into quantum
states using feature mapping techniques is essential for leveraging quantum
algorithms Despite the recognized importance of feature mapping, its specific
impact on data classification outcomes remains largely unexplored. This study
addresses this gap by comprehensively assessing the effects of various feature
mapping methods on classification results, taking medical data analysis as a
case study. In this study, the QSVM-Kernel method was applied to classification
problems in two different and publicly available medical datasets, namely, the
Wisconsin Breast Cancer (original) and The Cancer Genome Atlas (TCGA) Glioma
datasets. In the QSVM-Kernel algorithm, quantum kernel matrices obtained from 9
different quantum feature maps were used. Thus, the effects of these quantum
feature maps on the classification results of the QSVM-Kernel algorithm were
examined in terms of both classifier performance and total execution time. As a
result, in the Wisconsin Breast Cancer (original) and TCGA Glioma datasets,
when Rx and Ry rotational gates were used, respectively, as feature maps in the
QSVM-Kernel algorithm, the best classification performances were achieved both
in terms of classification performance and total execution time. The
contributions of this study are that (1) it highlights the significant impact
of feature mapping techniques on medical data classification outcomes using the
QSVM-Kernel algorithm, and (2) it also guides undertaking research for improved
QSVM classification performance.

æè¦ï¼<paragraph>ä½çºéå­æ©å¨å­¸ç¿æè¡çé åç¯ä¾ï¼å·æéå­æ ¸ä¼°è¨å¨çæ¯æåéæ©æ¼ç®æ³ (QSVM-Kernel) å·²ç¶æ­·éå¤§çé²å±ãåç®¡å¦æ­¤ï¼å®èç¶å¸è³æçæ´åæåºäºç¨ç¹çææ°ãéç¶éå­é»è¦ä¸»è¦èéå­çæä¸­çè³æäºåï¼ä½ä½¿ç¨ç¹å¾µå°ææè¡å°ç¶å¸è³æåµå¥éå­çæå°æ¼å©ç¨éå­æ¼ç®æ³è³ééè¦ãåç®¡ç¹å¾µå°æçéè¦æ§ç²å¾èªå¯ï¼ä½å¶å°è³æåé¡çµæçå·é«å½±é¿ä»æªå¾å°ååæ¢è¨ãæ¬ç ç©¶ééå¨é¢è©ä¼°åç¨®ç¹å¾µå°ææ¹æ³å°åé¡çµæçå½±é¿ä¾è§£æ±ºéåå·®è·ï¼ä¸¦å°é«å­¸è³æåæä½çºæ¡ä¾ç ç©¶ãå¨æ¬ç ç©¶ä¸­ï¼QSVM-Kernel æ¹æ³è¢«æç¨æ¼å©åä¸åä¸å¬éå¯ç¨çé«å­¸è³æéä¸­çåé¡åé¡ï¼å³å¨æ¯åº·è¾ä¹³ç (åå§) åççåºå çµåè­ (TCGA) ç¥ç¶è è³ªç¤è³æéãå¨ QSVM-Kernel æ¼ç®æ³ä¸­ï¼ä½¿ç¨äºå¾ 9 åä¸åçéå­ç¹å¾µå°æä¸­ç²å¾çéå­æ ¸ç©é£ãå æ­¤ï¼éäºéå­ç¹å¾µå°æå° QSVM-Kernel æ¼ç®æ³åé¡çµæçå½±é¿å¨åé¡å¨æè½åç¸½å·è¡æéæ¹é¢é½å¾å°äºæª¢é©ãçµæï¼å¨å¨æ¯åº·è¾ä¹³ç (åå§) å TCGA ç¥ç¶è è³ªç¤è³æéä¸­ï¼ç¶ Rx å Ry æè½éåå¥ç¨ä½ QSVM-Kernel æ¼ç®æ³ä¸­çç¹å¾µå°ææï¼å¨åé¡æè½åç¸½å·è¡æéæ¹é¢é½éå°äºæä½³çåé¡æè½ãæ¬ç ç©¶çè²¢ç»å¨æ¼ï¼(1) å®å¼·èª¿äºç¹å¾µå°ææè¡å°ä½¿ç¨ QSVM-Kernel æ¼ç®æ³çé«å­¸è³æåé¡çµæçéå¤§å½±é¿ï¼ä»¥å (2) å®ä¹æå°é²è¡ç ç©¶ä»¥æ¹å QSVM åé¡æè½ã</paragraph>

##### **Enhancing Semantic Segmentation with Adaptive Focal Loss: A Novel Approach**
2407.09828v1 by Md Rakibul Islam, Riad Hassan, Abdullah Nazib, Kien Nguyen, Clinton Fookes, Md Zahidul Islam

Deep learning has achieved outstanding accuracy in medical image
segmentation, particularly for objects like organs or tumors with smooth
boundaries or large sizes. Whereas, it encounters significant difficulties with
objects that have zigzag boundaries or are small in size, leading to a notable
decrease in segmentation effectiveness. In this context, using a loss function
that incorporates smoothness and volume information into a model's predictions
offers a promising solution to these shortcomings. In this work, we introduce
an Adaptive Focal Loss (A-FL) function designed to mitigate class imbalance by
down-weighting the loss for easy examples that results in up-weighting the loss
for hard examples and giving greater emphasis to challenging examples, such as
small and irregularly shaped objects. The proposed A-FL involves dynamically
adjusting a focusing parameter based on an object's surface smoothness, size
information, and adjusting the class balancing parameter based on the ratio of
targeted area to total area in an image. We evaluated the performance of the
A-FL using ResNet50-encoded U-Net architecture on the Picai 2022 and BraTS 2018
datasets. On the Picai 2022 dataset, the A-FL achieved an Intersection over
Union (IoU) of 0.696 and a Dice Similarity Coefficient (DSC) of 0.769,
outperforming the regular Focal Loss (FL) by 5.5% and 5.4% respectively. It
also surpassed the best baseline Dice-Focal by 2.0% and 1.2%. On the BraTS 2018
dataset, A-FL achieved an IoU of 0.883 and a DSC of 0.931. The comparative
studies show that the proposed A-FL function surpasses conventional methods,
including Dice Loss, Focal Loss, and their hybrid variants, in IoU, DSC,
Sensitivity, and Specificity metrics. This work highlights A-FL's potential to
improve deep learning models for segmenting clinically significant regions in
medical images, leading to more precise and reliable diagnostic tools.

æè¦ï¼æ·±åº¦å­¸ç¿å¨é«å­¸å½±ååå²æ¹é¢åå¾äºååºçæºç¢ºæ§ï¼ç¹å¥æ¯å°æ¼å·æå¹³æ»éçæå¤§å°ºå¯¸çå¨å®æè«ç¤ç­ç©é«ãç¶èï¼å°æ¼å·ææ²æéçæå°ºå¯¸å°çç©é«ï¼å®æéå°å¾å¤§çå°é£ï¼å°è´åå²ææé¡¯èä¸éãå¨æ­¤èæ¯ä¸ï¼ä½¿ç¨å°å¹³æ»åº¦åé«ç©è³è¨ç´å¥æ¨¡åé æ¸¬çæå¤±å½æ¸çºéäºç¼ºé»æä¾äºä¸åæå¸æçè§£æ±ºæ¹æ¡ãå¨éé å·¥ä½ä¸­ï¼æåå¼å¥äºä¸åèªé©æç¦é»æå¤± (A-FL) å½æ¸ï¼æ¨å¨éééä½ææ¼ç¯ä¾çæå¤±ä¾æ¸è¼é¡å¥å¤±è¡¡ï¼å¾èå¢å å°é£ç¯ä¾çæå¤±ï¼ä¸¦æ´å å¼·èª¿å·æææ°æ§çç¯ä¾ï¼ä¾å¦å°ä¸å½¢çä¸è¦åçç©é«ãææåºç A-FL æ¶åæ ¹æç©é«çè¡¨é¢å¹³æ»åº¦ãå°ºå¯¸è³è¨åæèª¿æ´èç¦åæ¸ï¼ä¸¦æ ¹æååä¸­ç®æ¨ååèç¸½ååçæ¯çèª¿æ´é¡å¥å¹³è¡¡åæ¸ãæåä½¿ç¨ ResNet50 ç·¨ç¢¼ç U-Net æ¶æ§å¨ Picai 2022 å BraTS 2018 è³æéä¸è©ä¼°äº A-FL çæè½ãå¨ Picai 2022 è³æéä¸ï¼A-FL çäº¤éæ¯è¯é (IoU) çº 0.696ï¼éª°å­ç¸ä¼¼æ§ä¿æ¸ (DSC) çº 0.769ï¼åå¥åªæ¼å¸¸è¦ç¦é»æå¤± (FL) 5.5% å 5.4%ãå®éè¶è¶äºæä½³åºæº Dice-Focal 2.0% å 1.2%ãå¨ BraTS 2018 è³æéä¸ï¼A-FL ç IoU çº 0.883ï¼DSC çº 0.931ãæ¯è¼ç ç©¶è¡¨æï¼ææåºç A-FL å½æ¸å¨ IoUãDSCãæææ§åç¹ç°æ§ææ¨ä¸åªæ¼å³çµ±æ¹æ³ï¼åæ¬ Dice æå¤±ãç¦é»æå¤±åå¶æ··åè®é«ãéé å·¥ä½çªåºäº A-FL å¨åå²é«å­¸å½±åä¸­å·æè¨åºæç¾©çååä»¥æ¹åæ·±åº¦å­¸ç¿æ¨¡åçæ½åï¼å¾èç¢çæ´ç²¾ç¢ºãæ´å¯é çè¨ºæ·å·¥å·ã

##### **Towards Personalised Patient Risk Prediction Using Temporal Hospital Data Trajectories**
2407.09373v1 by Thea Barnes, Enrico Werner, Jeffrey N. Clark, Raul Santos-Rodriguez

Quantifying a patient's health status provides clinicians with insight into
patient risk, and the ability to better triage and manage resources. Early
Warning Scores (EWS) are widely deployed to measure overall health status, and
risk of adverse outcomes, in hospital patients. However, current EWS are
limited both by their lack of personalisation and use of static observations.
We propose a pipeline that groups intensive care unit patients by the
trajectories of observations data throughout their stay as a basis for the
development of personalised risk predictions. Feature importance is considered
to provide model explainability. Using the MIMIC-IV dataset, six clusters were
identified, capturing differences in disease codes, observations, lengths of
admissions and outcomes. Applying the pipeline to data from just the first four
hours of each ICU stay assigns the majority of patients to the same cluster as
when the entire stay duration is considered. In-hospital mortality prediction
models trained on individual clusters had higher F1 score performance in five
of the six clusters when compared against the unclustered patient cohort. The
pipeline could form the basis of a clinical decision support tool, working to
improve the clinical characterisation of risk groups and the early detection of
patient deterioration.

æè¦ï¼éåæ£èçå¥åº·ç¶åµå¯è®©ä¸´åºå»çæ·±å¥äºè§£æ£èé£é©ï¼å¹¶è½æ´å¥½å°å¯¹èµæºè¿è¡åç±»åç®¡çãæ©æé¢è­¦è¯å (EWS) è¢«å¹¿æ³ç¨äºè¡¡éæ´ä½å¥åº·ç¶åµåä½é¢æ£èçä¸è¯åæé£é©ãç¶èï¼å½åç EWS åéäºå¶ç¼ºä¹ä¸ªæ§ååä½¿ç¨éæè§å¯ãæä»¬æåºäºä¸ä¸ªç®¡éï¼è¯¥ç®¡éæ ¹æ®æ£èå¨æ´ä¸ªä½é¢æé´çè§å¯æ°æ®è½¨è¿¹å¯¹éççæ¤çæ¿æ£èè¿è¡åç»ï¼ä½ä¸ºå¶å®ä¸ªæ§åé£é©é¢æµçåºç¡ãç¹å¾éè¦æ§è¢«èèä¸ºæä¾æ¨¡åå¯è§£éæ§ãä½¿ç¨ MIMIC-IV æ°æ®éï¼è¯å«åºå­ä¸ªéç¾¤ï¼ææç¾çä»£ç ãè§å¯ãå¥é¢æ¶é´åç»æçå·®å¼ãå°ç®¡éåºç¨äºæ¯ä¸ª ICU ä½é¢çååä¸ªå°æ¶çæ°æ®æ¶ï¼å°å¤§å¤æ°æ£èåéå°ä¸èèæ´ä¸ªä½é¢æ¶é´æ¶ç¸åçéç¾¤ãå¨äºä¸ªéç¾¤ä¸­ï¼éå¯¹åä¸ªéç¾¤è®­ç»çé¢åæ­»äº¡çé¢æµæ¨¡åä¸æªåç»æ£èéåç¸æ¯å·ææ´é«ç F1 åæ°è¡¨ç°ãè¯¥ç®¡éå¯ä»¥å½¢æä¸´åºå³ç­æ¯æå·¥å·çåºç¡ï¼ç¨äºæ¹åé£é©ç»çä¸´åºè¡¨å¾åæ£èæ¶åçæ©ææ£æµã

##### **Enhancing Depressive Post Detection in Bangla: A Comparative Study of TF-IDF, BERT and FastText Embeddings**
2407.09187v1 by Saad Ahmed Sazan, Mahdi H. Miraz, A B M Muntasir Rahman

Due to massive adoption of social media, detection of users' depression
through social media analytics bears significant importance, particularly for
underrepresented languages, such as Bangla. This study introduces a
well-grounded approach to identify depressive social media posts in Bangla, by
employing advanced natural language processing techniques. The dataset used in
this work, annotated by domain experts, includes both depressive and
non-depressive posts, ensuring high-quality data for model training and
evaluation. To address the prevalent issue of class imbalance, we utilised
random oversampling for the minority class, thereby enhancing the model's
ability to accurately detect depressive posts. We explored various numerical
representation techniques, including Term Frequency-Inverse Document Frequency
(TF-IDF), Bidirectional Encoder Representations from Transformers (BERT)
embedding and FastText embedding, by integrating them with a deep
learning-based Convolutional Neural Network-Bidirectional Long Short-Term
Memory (CNN-BiLSTM) model. The results obtained through extensive
experimentation, indicate that the BERT approach performed better the others,
achieving a F1-score of 84%. This indicates that BERT, in combination with the
CNN-BiLSTM architecture, effectively recognises the nuances of Bangla texts
relevant to depressive contents. Comparative analysis with the existing
state-of-the-art methods demonstrates that our approach with BERT embedding
performs better than others in terms of evaluation metrics and the reliability
of dataset annotations. Our research significantly contribution to the
development of reliable tools for detecting depressive posts in the Bangla
language. By highlighting the efficacy of different embedding techniques and
deep learning models, this study paves the way for improved mental health
monitoring through social media platforms.

æè¦ï¼<paragraph>ç±æ¼ç¤¾ç¾¤åªé«çå»£æ³æ¡ç¨ï¼ééç¤¾ç¾¤åªé«åæä¾åµæ¸¬ä½¿ç¨èçæé¬±çå·æéè¦çæç¾©ï¼ç¹å¥æ¯å°æ¼å­å æèªç­ä»£è¡¨æ§ä¸è¶³çèªè¨ãæ¬ç ç©¶ä»ç´¹äºä¸ç¨®ææ ¹æçæ¹æ³ä¾è­å¥å­å æèªä¸­çæé¬±ç¤¾ç¾¤åªé«è²¼æï¼æ¹æ³æ¯æ¡ç¨åé²çèªç¶èªè¨èçæè¡ãæ¬ç ç©¶ä¸­æä½¿ç¨çè³æéç±é åå°å®¶è¨»è§£ï¼åæ¬æé¬±åéæé¬±è²¼æï¼ç¢ºä¿æ¨¡åè¨ç·´åè©ä¼°è³æçé«åè³ªãçºäºè§£æ±ºé¡å¥ä¸å¹³è¡¡çæ®éåé¡ï¼æåå°å°æ¸é¡å¥æ¡ç¨é¨æ©éåº¦åæ¨£ï¼å¾èå¢å¼·æ¨¡åæºç¢ºåµæ¸¬æé¬±è²¼æçè½åãæåæ¢è¨äºåç¨®æ¸å¼è¡¨ç¤ºæè¡ï¼åæ¬è©é »-éæä»¶é »ç (TF-IDF)ãTransformer (BERT) åµå¥çéåç·¨ç¢¼å¨è¡¨ç¤ºå FastText åµå¥ï¼ä¸¦å°å®åèåºæ¼æ·±åº¦å­¸ç¿çå·ç©ç¥ç¶ç¶²è·¯-éåé·ç­æè¨æ¶ (CNN-BiLSTM) æ¨¡åæ´åå¨ä¸èµ·ãééå»£æ³çå¯¦é©æç²å¾ççµæé¡¯ç¤ºï¼BERT æ¹æ³çè¡¨ç¾åªæ¼å¶ä»æ¹æ³ï¼éå°äº 84% ç F1 åæ¸ãéè¡¨ç¤º BERT è CNN-BiLSTM æ¶æ§ç¸çµåï¼å¯ä»¥ææè­å¥èæé¬±å§å®¹ç¸éçå­å æèªææ¬çç´°å¾®å·®å¥ãèç¾æçæåé²æ¹æ³é²è¡æ¯è¼åæï¼è­ææåæ¡ç¨ BERT åµå¥çæ¹æ³å¨è©ä¼°ææ¨åè³æéè¨»è§£çå¯é æ§æ¹é¢åªæ¼å¶ä»æ¹æ³ãæåçç ç©¶çºéç¼ç¨æ¼åµæ¸¬å­å æèªä¸­æé¬±è²¼æçå¯é å·¥å·ååºäºéå¤§è²¢ç»ãééå¼·èª¿ä¸ååµå¥æè¡åæ·±åº¦å­¸ç¿æ¨¡åçæè½ï¼æ¬ç ç©¶çºééç¤¾ç¾¤åªé«å¹³å°æ¹åå¿çå¥åº·ç£æ§éªå¹³äºéè·¯ã</paragraph>

##### **STD-LLM: Understanding Both Spatial and Temporal Properties of Spatial-Temporal Data with LLMs**
2407.09096v1 by Yiheng Huang, Xiaowei Mao, Shengnan Guo, Yubin Chen, Youfang Lin, Huaiyu Wan

Spatial-temporal forecasting and imputation are important for real-world
dynamic systems such as intelligent transportation, urban planning, and public
health. Most existing methods are tailored for individual forecasting or
imputation tasks but are not designed for both. Additionally, they are less
effective for zero-shot and few-shot learning. While large language models
(LLMs) have exhibited strong pattern recognition and reasoning abilities across
various tasks, including few-shot and zero-shot learning, their development in
understanding spatial-temporal data has been constrained by insufficient
modeling of complex correlations such as the temporal correlations, spatial
connectivity, non-pairwise and high-order spatial-temporal correlations within
data. In this paper, we propose STD-LLM for understanding both spatial and
temporal properties of \underline{S}patial-\underline{T}emporal
\underline{D}ata with \underline{LLM}s, which is capable of implementing both
spatial-temporal forecasting and imputation tasks. STD-LLM understands
spatial-temporal correlations via explicitly designed spatial and temporal
tokenizers as well as virtual nodes. Topology-aware node embeddings are
designed for LLMs to comprehend and exploit the topology structure of data.
Additionally, to capture the non-pairwise and higher-order correlations, we
design a hypergraph learning module for LLMs, which can enhance the overall
performance and improve efficiency. Extensive experiments demonstrate that
STD-LLM exhibits strong performance and generalization capabilities across the
forecasting and imputation tasks on various datasets. Moreover, STD-LLM
achieves promising results on both few-shot and zero-shot learning tasks.

æè¦ï¼æç©ºé æ¸¬åå¡«è£å°æ¼æºæ§äº¤éãé½å¸è¨ç«åå¬å±è¡çç­çå¯¦ä¸çåæç³»çµ±ä¾èªªå¾éè¦ãç¾ææ¹æ³å¤§å¤æ¯éå°åå¥é æ¸¬æå¡«è£ä»»åéèº«æé ï¼ä½ä¸¦ééå°å©èè¨­è¨ãæ­¤å¤ï¼å®åå°æ¼é¶æ¬¡å­¸ç¿åå°æ¬¡å­¸ç¿çææè¼å·®ãåç®¡å¤§åèªè¨æ¨¡å (LLM) å·²å¨åç¨®ä»»åä¸­å±ç¾å¼·å¤§çæ¨¡å¼è­å¥åæ¨çè½åï¼åæ¬å°æ¬¡å­¸ç¿åé¶æ¬¡å­¸ç¿ï¼ä½å®åå¨çè§£æç©ºè³ææ¹é¢çç¼å±åå°éå¶ï¼åå æ¯å°è¤ééè¯æ§çå»ºæ¨¡ä¸è¶³ï¼ä¾å¦è³æä¸­çæééè¯æ§ãç©ºéé£éæ§ãéæå°åé«éæç©ºéè¯æ§ãå¨æ¬æä¸­ï¼æåæåº STD-LLMï¼ç¨æ¼äºè§£æç©ºè³æçç©ºéåæéå±¬æ§ï¼ä¸¦å·åå·è¡æç©ºé æ¸¬åå¡«è£ä»»åçè½åãSTD-LLM ééæç¢ºè¨­è¨çç©ºéåæéæ¨è¨åå¨ä»¥åèæ¬ç¯é»ä¾äºè§£æç©ºéè¯æ§ãææ²æç¥ç¯é»åµå¥æ¯çº LLM è¨­è¨çï¼ç¨æ¼çè§£åå©ç¨è³æçææ²çµæ§ãæ­¤å¤ï¼çºäºææéæå°åé«ééè¯æ§ï¼æåçº LLM è¨­è¨äºä¸åè¶åå­¸ç¿æ¨¡çµï¼å¯ä»¥æåæ´é«æè½ä¸¦æ¹åæçãå¤§éçå¯¦é©è­æ STD-LLM å¨åç¨®è³æéçé æ¸¬åå¡«è£ä»»åä¸­å±ç¾åºå¼·å¤§çæè½åæ³åè½åãæ­¤å¤ï¼STD-LLM å¨å°æ¬¡å­¸ç¿åé¶æ¬¡å­¸ç¿ä»»åä¸­é½åå¾äºä»¤äººæ»¿æçææã

##### **FD-SOS: Vision-Language Open-Set Detectors for Bone Fenestration and Dehiscence Detection from Intraoral Images**
2407.09088v1 by Marawan Elbatel, Keyuan Liu, Yanqi Yang, Xiaomeng Li

Accurate detection of bone fenestration and dehiscence (FD) is crucial for
effective treatment planning in dentistry. While cone-beam computed tomography
(CBCT) is the gold standard for evaluating FD, it comes with limitations such
as radiation exposure, limited accessibility, and higher cost compared to
intraoral images. In intraoral images, dentists face challenges in the
differential diagnosis of FD. This paper presents a novel and clinically
significant application of FD detection solely from intraoral images. To
achieve this, we propose FD-SOS, a novel open-set object detector for FD
detection from intraoral images. FD-SOS has two novel components: conditional
contrastive denoising (CCDN) and teeth-specific matching assignment (TMA).
These modules enable FD-SOS to effectively leverage external dental semantics.
Experimental results showed that our method outperformed existing detection
methods and surpassed dental professionals by 35% recall under the same level
of precision. Code is available at: https://github.com/xmed-lab/FD-SOS.

æè¦ï¼éª¨éª¼ç©¿å­åéª¨ç¼ºæ (FD) çæºç¢ºåµæ¸¬å°æ¼çç§çæææ²»çè¨ç«è³ééè¦ãéå½¢æé»è¦æ·å±¤ææ (CBCT) éç¶æ¯è©ä¼° FD çé»éæ¨æºï¼ä½å®å­å¨èè«¸å¦è¼»å°æé²ãåå¾ä¸æåèå£èå§å½±åç¸æ¯ææ¬è¼é«ç­éå¶ãå¨å£èå§å½±åä¸­ï¼çé«å¸«å¨ FD çéå¥è¨ºæ·ä¸­é¢è¨ææ°ãæ¬ææåºäºä¸ååµæ°ä¸è¨åºä¸éè¦çæç¨ï¼å¯åå¾å£èå§å½±åä¸­åµæ¸¬ FDãçºéææ­¤ç®æ¨ï¼æåæåº FD-SOSï¼éæ¯ä¸ç¨®ç¨æ¼å¾å£èå§å½±åä¸­åµæ¸¬ FD çæ°åéæ¾å¼ç©ä»¶åµæ¸¬å¨ãFD-SOS æå©åæ°ç©ççµæé¨åï¼æ¢ä»¶å°æ¯å»åª (CCDN) åç¹å®æ¼çé½çå¹éæå® (TMA)ãéäºæ¨¡çµä½¿ FD-SOS è½ææå©ç¨å¤é¨çç§èªç¾©ãå¯¦é©çµæé¡¯ç¤ºï¼æåçæè¡åªæ¼ç¾æçåµæ¸¬æè¡ï¼ä¸å¨ç¸åçæºç¢ºåº¦ä¸ï¼æ¯çç§å°æ¥­äººå¡é«åº 35% çå¬åçãç¨å¼ç¢¼å¯å¨ https://github.com/xmed-lab/FD-SOS åå¾ã

##### **Heterogeneous Subgraph Network with Prompt Learning for Interpretable Depression Detection on Social Media**
2407.09019v1 by Chen Chen, Mingwei Li, Fenghuan Li, Haopeng Chen, Yuankun Lin

Massive social media data can reflect people's authentic thoughts, emotions,
communication, etc., and therefore can be analyzed for early detection of
mental health problems such as depression. Existing works about early
depression detection on social media lacked interpretability and neglected the
heterogeneity of social media data. Furthermore, they overlooked the global
interaction among users. To address these issues, we develop a novel method
that leverages a Heterogeneous Subgraph Network with Prompt Learning(HSNPL) and
contrastive learning mechanisms. Specifically, prompt learning is employed to
map users' implicit psychological symbols with excellent interpretability while
deep semantic and diverse behavioral features are incorporated by a
heterogeneous information network. Then, the heterogeneous graph network with a
dual attention mechanism is constructed to model the relationships among
heterogeneous social information at the feature level. Furthermore, the
heterogeneous subgraph network integrating subgraph attention and
self-supervised contrastive learning is developed to explore complicated
interactions among users and groups at the user level. Extensive experimental
results demonstrate that our proposed method significantly outperforms
state-of-the-art methods for depression detection on social media.

æè¦ï¼é¾å¤§çç¤¾ç¾¤åªé«è³æå¯ä»¥åæ äººåçå¯¦çæ³æ³ãæç·ãæºéç­ï¼å æ­¤å¯ä»¥åæéäºè³æï¼ä»¥æ©æåµæ¸¬æé¬±çç­å¿çå¥åº·åé¡ãç¾æéæ¼ç¤¾ç¾¤åªé«ä¸æ©ææé¬±çåµæ¸¬çç ç©¶ç¼ºä¹å¯è§£éæ§ï¼ä¸å¿½ç¥äºç¤¾ç¾¤åªé«è³æçç°è³ªæ§ãæ­¤å¤ï¼éäºç ç©¶å¿½è¦äºä½¿ç¨èä¹éçæ´é«äºåãçºäºè§£æ±ºéäºåé¡ï¼æåéç¼äºä¸ç¨®æ°ç©çæ¹æ³ï¼éç¨®æ¹æ³å©ç¨å¸¶ææç¤ºå­¸ç¿ï¼HSNPLï¼çç°è³ªå­åç¶²è·¯åå°æ¯å­¸ç¿æ©å¶ãå·é«èè¨ï¼æç¤ºå­¸ç¿è¢«ç¨æ¼ç¹ªè£½ä½¿ç¨èå·æåºè²å¯è§£éæ§çé±å«å¿çç¬¦èï¼åæééç°è³ªè³è¨ç¶²è·¯æ´åäºæ·±å±¤èªç¾©åå¤æ¨£åçè¡çºç¹å¾µãç¶å¾ï¼æ§å»ºå·æééæ³¨ææ©å¶çç°è³ªåç¶²è·¯ï¼ä»¥å¨ç¹å¾µå±¤ç´å»ºæ¨¡ç°è³ªç¤¾ç¾¤è³è¨ä¹éçéä¿ãæ­¤å¤ï¼éç¼äºæ´åå­åæ³¨æåèªæç£ç£å°æ¯å­¸ç¿çç°è³ªå­åç¶²è·¯ï¼ä»¥æ¢ç´¢ä½¿ç¨èåç¾¤çµä¹éå¨ä½¿ç¨èå±¤ç´çè¤éäºåãå¤§éçå¯¦é©çµæè¡¨æï¼æåæåºçæ¹æ³å¨ç¤¾ç¾¤åªé«ä¸çæé¬±çåµæ¸¬æ¹é¢é¡¯èåªæ¼æåé²çæ¹æ³ã

##### **Application of Artificial Intelligence in Supporting Healthcare Professionals and Caregivers in Treatment of Autistic Children**
2407.08902v1 by Hossein Mohammadi Rouzbahani, Hadis Karimipour

Autism Spectrum Disorder (ASD) represents a multifaceted neurodevelopmental
condition marked by difficulties in social interaction, communication
impediments, and repetitive behaviors. Despite progress in understanding ASD,
its diagnosis and treatment continue to pose significant challenges due to the
variability in symptomatology and the necessity for multidisciplinary care
approaches. This paper investigates the potential of Artificial Intelligence
(AI) to augment the capabilities of healthcare professionals and caregivers in
managing ASD. We have developed a sophisticated algorithm designed to analyze
facial and bodily expressions during daily activities of both autistic and
non-autistic children, leading to the development of a powerful deep
learning-based autism detection system. Our study demonstrated that AI models,
specifically the Xception and ResNet50V2 architectures, achieved high accuracy
in diagnosing Autism Spectrum Disorder (ASD). This research highlights the
transformative potential of AI in improving the diagnosis, treatment, and
comprehensive management of ASD. Our study revealed that AI models, notably the
Xception and ResNet50V2 architectures, demonstrated high accuracy in diagnosing
ASD.

æè¦ï¼èªéçè­ç³»éç¤ (ASD) æ¯ä¸ç¨®å¤é¢åçç¥ç¶ç¼å±çæ³ï¼å¶ç¹å¾µå¨æ¼ç¤¾äº¤äºåå°é£ãæºééç¤åéè¤æ§è¡çºãåç®¡å¨äºè§£ ASD æ¹é¢åå¾é²å±ï¼ä½ç±æ¼çççå¤è®æ§åå°è·¨é åç§è­·æ¹æ³çå¿è¦æ§ï¼å¶è¨ºæ·åæ²»çä»ç¶æ§æéå¤§ææ°ãæ¬ææ¢è¨äººå·¥æºæ§ (AI) å¨æ´å¢é«çä¿å¥å°æ¥­äººå¡åç§è­·èç®¡ç ASD è½åæ¹é¢çæ½åãæåéç¼äºä¸ç¨®ç²¾å¯æ¼ç®æ³ï¼æ¨å¨åæèªéçåéèªéçåç«¥å¨æ¥å¸¸æ´»åä¸­çé¢é¨åèº«é«è¡¨æï¼é²èéç¼åºåè½å¼·å¤§çæ·±åº¦å­¸ç¿èªéçåµæ¸¬ç³»çµ±ãæåçç ç©¶è¡¨æï¼AI æ¨¡åï¼ç¹å¥æ¯ Xception å ResNet50V2 æ¶æ§ï¼å¨è¨ºæ·èªéçè­ç³»éç¤ (ASD) æ¹é¢åå¾é«æºç¢ºåº¦ãéé ç ç©¶çªé¡¯äº AI å¨æ¹å ASD è¨ºæ·ãæ²»çåå¨é¢ç®¡çæ¹é¢çè®é©æ½åãæåçç ç©¶æ­ç¤ºï¼AI æ¨¡åï¼ç¹å¥æ¯ Xception å ResNet50V2 æ¶æ§ï¼å¨è¨ºæ· ASD æ¹é¢è¡¨ç¾åºé«æºç¢ºåº¦ã

##### **SALT: Introducing a Framework for Hierarchical Segmentations in Medical Imaging using Softmax for Arbitrary Label Trees**
2407.08878v1 by Sven Koitka, Giulia Baldini, Cynthia S. Schmidt, Olivia B. Pollok, Obioma Pelka, Judith Kohnke, Katarzyna Borys, Christoph M. Friedrich, Benedikt M. Schaarschmidt, Michael Forsting, Lale Umutlu, Johannes Haubold, Felix Nensa, RenÃ© Hosch

Traditional segmentation networks approach anatomical structures as
standalone elements, overlooking the intrinsic hierarchical connections among
them. This study introduces Softmax for Arbitrary Label Trees (SALT), a novel
approach designed to leverage the hierarchical relationships between labels,
improving the efficiency and interpretability of the segmentations.
  This study introduces a novel segmentation technique for CT imaging, which
leverages conditional probabilities to map the hierarchical structure of
anatomical landmarks, such as the spine's division into lumbar, thoracic, and
cervical regions and further into individual vertebrae. The model was developed
using the SAROS dataset from The Cancer Imaging Archive (TCIA), comprising 900
body region segmentations from 883 patients. The dataset was further enhanced
by generating additional segmentations with the TotalSegmentator, for a total
of 113 labels. The model was trained on 600 scans, while validation and testing
were conducted on 150 CT scans. Performance was assessed using the Dice score
across various datasets, including SAROS, CT-ORG, FLARE22, LCTSC, LUNA16, and
WORD.
  Among the evaluated datasets, SALT achieved its best results on the LUNA16
and SAROS datasets, with Dice scores of 0.93 and 0.929 respectively. The model
demonstrated reliable accuracy across other datasets, scoring 0.891 on CT-ORG
and 0.849 on FLARE22. The LCTSC dataset showed a score of 0.908 and the WORD
dataset also showed good performance with a score of 0.844.
  SALT used the hierarchical structures inherent in the human body to achieve
whole-body segmentations with an average of 35 seconds for 100 slices. This
rapid processing underscores its potential for integration into clinical
workflows, facilitating the automatic and efficient computation of full-body
segmentations with each CT scan, thus enhancing diagnostic processes and
patient care.

æè¦ï¼<paragraph>å³çµ±çåå²ç¶²è·¯å°è§£åçµæ§è¦çºç¨ç«åç´ ï¼å¿½ç¥äºå®åä¹éåºæçå±¤ç´é£æ¥ãæ¬ç ç©¶å¼å¥äºä»»ææ¨ç±¤æ¨¹ç Softmax (SALT)ï¼éæ¯ä¸ç¨®æ°ç©çæ¹æ³ï¼æ¨å¨å©ç¨æ¨ç±¤ä¹éçå±¤ç´éä¿ï¼æé«åå²çæçåå¯è§£éæ§ã
æ¬ç ç©¶å¼å¥äºä¸ç¨®æ°ç CT å½±ååå²æè¡ï¼å®å©ç¨æ¢ä»¶æ©çä¾å°è§£åæ¨èªçå±¤ç´çµæ§é²è¡å°æï¼ä¾å¦å°èæ¤åçºè°æ¤ãè¸æ¤åé ¸æ¤ååï¼ä¸¦é²ä¸æ­¥åçºåå¥æ¤éª¨ãè©²æ¨¡åæ¯ä½¿ç¨ççå½±åæªæ¡é¤¨ (TCIA) ä¸­ç SAROS è³æééç¼çï¼å¶ä¸­åå«ä¾èª 883 ä½æ£èç 900 åèº«é«åååå²ãè©²è³æéé²ä¸æ­¥éé TotalSegmentator çæäºé¡å¤çåå²ï¼ç¸½å± 113 åæ¨ç±¤ãè©²æ¨¡åå¨ 600 æ¬¡ææä¸­æ¥åäºè¨ç·´ï¼èé©è­åæ¸¬è©¦åå¨ 150 æ¬¡ CT ææä¸­é²è¡ãæè½ä½¿ç¨ Dice åæ¸å¨åç¨®è³æéä¸é²è¡è©ä¼°ï¼åæ¬ SAROSãCT-ORGãFLARE22ãLCTSCãLUNA16 å WORDã
å¨è©ä¼°çè³æéä¸­ï¼SALT å¨ LUNA16 å SAROS è³æéä¸åå¾äºæä½³çµæï¼Dice åæ¸åå¥çº 0.93 å 0.929ãè©²æ¨¡åå¨å¶ä»è³æéä¸è¡¨ç¾åºå¯é çæºç¢ºæ§ï¼å¨ CT-ORG ä¸å¾åçº 0.891ï¼å¨ FLARE22 ä¸å¾åçº 0.849ãLCTSC è³æéçå¾åçº 0.908ï¼WORD è³æéçè¡¨ç¾ä¹å¾å¥½ï¼å¾åçº 0.844ã
SALT å©ç¨äººé«åºæçå±¤ç´çµæ§ï¼ä»¥å¹³å 35 ç§çæéå° 100 ååçé²è¡å¨èº«åå²ãéç¨®å¿«éèççªé¡¯äºå®æ´åå°è¨åºå·¥ä½æµç¨ä¸­çæ½åï¼ä¿é²äºæ¯æ¬¡ CT ææçå¨èº«åå²çèªåååé«æè¨ç®ï¼å¾èå¢å¼·äºè¨ºæ·éç¨åæ£èè­·çã</paragraph>

##### **FedMedICL: Towards Holistic Evaluation of Distribution Shifts in Federated Medical Imaging**
2407.08822v1 by Kumail Alhamoud, Yasir Ghunaim, Motasem Alfarra, Thomas Hartvigsen, Philip Torr, Bernard Ghanem, Adel Bibi, Marzyeh Ghassemi

For medical imaging AI models to be clinically impactful, they must
generalize. However, this goal is hindered by (i) diverse types of distribution
shifts, such as temporal, demographic, and label shifts, and (ii) limited
diversity in datasets that are siloed within single medical institutions. While
these limitations have spurred interest in federated learning, current
evaluation benchmarks fail to evaluate different shifts simultaneously.
However, in real healthcare settings, multiple types of shifts co-exist, yet
their impact on medical imaging performance remains unstudied. In response, we
introduce FedMedICL, a unified framework and benchmark to holistically evaluate
federated medical imaging challenges, simultaneously capturing label,
demographic, and temporal distribution shifts. We comprehensively evaluate
several popular methods on six diverse medical imaging datasets (totaling 550
GPU hours). Furthermore, we use FedMedICL to simulate COVID-19 propagation
across hospitals and evaluate whether methods can adapt to pandemic changes in
disease prevalence. We find that a simple batch balancing technique surpasses
advanced methods in average performance across FedMedICL experiments. This
finding questions the applicability of results from previous, narrow benchmarks
in real-world medical settings.

æè¦ï¼çºäºè®é«å­¸å½±å AI æ¨¡åå¨è¨åºä¸ç¢çå½±é¿ï¼å®åå¿é å·åæ³åæ§ãç¶èï¼æ­¤ç®æ¨åå° (i) åä½è½ç§»çä¸åé¡åï¼ä¾å¦æéãäººå£çµ±è¨åæ¨ç±¤è½ç§»ï¼ä»¥å (ii) ä¾·éæ¼å®ä¸é«çæ©æ§å§è³æéçå¤æ¨£æ§æé»ç¤ãåç®¡éäºéå¶æ¿ç¼äºå°è¯åå­¸ç¿çèè¶£ï¼ä½ç®åçè©ä¼°åºæºç¡æ³åæè©ä¼°ä¸åçè½ç§»ãç¶èï¼å¨å¯¦éçé«çä¿å¥ç°å¢ä¸­ï¼å¤ç¨®é¡åçè½ç§»åæå­å¨ï¼ä½å®åå°é«å­¸å½±åæè½çå½±é¿ä»æªå¾å°ç ç©¶ãçºäºè§£æ±ºéååé¡ï¼æåå¼å¥äº FedMedICLï¼ä¸åçµ±ä¸çæ¶æ§ååºæºï¼ä»¥å¨é¢è©ä¼°è¯åé«å­¸å½±åææ°ï¼åææææ¨ç±¤ãäººå£çµ±è¨åæéåä½è½ç§»ãæåå¨å­åä¸åçé«å­¸å½±åè³æéï¼ç¸½è¨ 550 å GPU å°æï¼ä¸å¨é¢è©ä¼°äºå¹¾ç¨®æµè¡çæ¹æ³ãæ­¤å¤ï¼æåä½¿ç¨ FedMedICL æ¨¡æ¬äº COVID-19 å¨é«é¢éçå³æ­ï¼ä¸¦è©ä¼°æ¹æ³æ¯å¦è½é©æç¾ççè¡ççæµè¡çè®åãæåç¼ç¾ï¼ä¸åç°¡å®çæ¹æ¬¡å¹³è¡¡æè¡å¨ FedMedICL å¯¦é©ä¸­è¶è¶äºåé²çæ¹æ³çå¹³åæè½ãæ­¤ç¼ç¾è³ªçäºååç¹éåºæºå¨ç¾å¯¦ä¸çé«çç°å¢ä¸­çµæçé©ç¨æ§ã

##### **FairDomain: Achieving Fairness in Cross-Domain Medical Image Segmentation and Classification**
2407.08813v2 by Yu Tian, Congcong Wen, Min Shi, Muhammad Muneeb Afzal, Hao Huang, Muhammad Osama Khan, Yan Luo, Yi Fang, Mengyu Wang

Addressing fairness in artificial intelligence (AI), particularly in medical
AI, is crucial for ensuring equitable healthcare outcomes. Recent efforts to
enhance fairness have introduced new methodologies and datasets in medical AI.
However, the fairness issue under the setting of domain transfer is almost
unexplored, while it is common that clinics rely on different imaging
technologies (e.g., different retinal imaging modalities) for patient
diagnosis. This paper presents FairDomain, a pioneering systemic study into
algorithmic fairness under domain shifts, employing state-of-the-art domain
adaptation (DA) and generalization (DG) algorithms for both medical
segmentation and classification tasks to understand how biases are transferred
between different domains. We also introduce a novel plug-and-play fair
identity attention (FIA) module that adapts to various DA and DG algorithms to
improve fairness by using self-attention to adjust feature importance based on
demographic attributes. Additionally, we curate the first fairness-focused
dataset with two paired imaging modalities for the same patient cohort on
medical segmentation and classification tasks, to rigorously assess fairness in
domain-shift scenarios. Excluding the confounding impact of demographic
distribution variation between source and target domains will allow clearer
quantification of the performance of domain transfer models. Our extensive
evaluations reveal that the proposed FIA significantly enhances both model
performance accounted for fairness across all domain shift settings (i.e., DA
and DG) with respect to different demographics, which outperforms existing
methods on both segmentation and classification. The code and data can be
accessed at https://ophai.hms.harvard.edu/datasets/harvard-fairdomain20k.

æè¦ï¼<paragraph>å¨äººå·¥æºæ§ï¼AIï¼ä¸­ï¼ç¹å¥æ¯å¨é«ç AI ä¸­ï¼è§£æ±ºå¬å¹³æ§å°æ¼ç¢ºä¿å¬å¹³çé«çä¿å¥çµæè³ééè¦ãæè¿çºæé«å¬å¹³æ§æåçåªåï¼å¨é«ç AI ä¸­å¼å¥äºæ°çæ¹æ³åæ¸æéãç¶èï¼å¨é åè½ç§»çè¨­å®ä¸ï¼å¬å¹³æ§åé¡å¹¾ä¹æªè¢«æ¢è¨ï¼èè¨ºæä¾è³´ä¸åçå½±åæè¡ï¼ä¾å¦ï¼ä¸åçè¦ç¶²èå½±åæ¹å¼ï¼ä¾é²è¡æ£èè¨ºæ·æ¯å¾å¸¸è¦çãæ¬ææåºäº FairDomainï¼éæ¯ä¸é éæ¼é åè½ç§»ä¸æ¼ç®æ³å¬å¹³æ§çéåµæ§ç³»çµ±æ§ç ç©¶ï¼æ¡ç¨æåé²çé åé©æï¼DAï¼åæ¦åï¼DGï¼æ¼ç®æ³ï¼ç¨æ¼é«çåå²ååé¡ä»»åï¼ä»¥äºè§£åå·®å¦ä½å¨ä¸åé åä¹éè½ç§»ãæåéå¼å¥äºä¸åæ°ç©çå³æå³ç¨å¬å¹³èº«åæ³¨æåï¼FIAï¼æ¨¡çµï¼å®é©ç¨æ¼åç¨® DA å DG æ¼ç®æ³ï¼ééä½¿ç¨èªææ³¨æåæ ¹æäººå£å±¬æ§èª¿æ´ç¹å¾µéè¦æ§ä¾æ¹åå¬å¹³æ§ãæ­¤å¤ï¼æåç­åäºç¬¬ä¸åä»¥å¬å¹³æ§çºéé»çæ¸æéï¼å¶ä¸­åå«éå°ç¸åæ£èç¾¤é«çå©ç¨®éå°å½±åæ¹å¼ï¼ç¨æ¼é«çåå²ååé¡ä»»åï¼ä»¥å´æ ¼è©ä¼°é åè½ç§»æå¢ä¸­çå¬å¹³æ§ãæé¤ä¾æºåç®æ¨é åä¹éäººå£åä½å·®ç°çæ··æ·å½±é¿ï¼å°åè¨±æ´æ¸æ¥å°éåé åè½ç§»æ¨¡åçæè½ãæåå»£æ³çè©ä¼°é¡¯ç¤ºï¼ææåºç FIA å¤§å¹æåäºæ¨¡åæè½ï¼å¨ææé åè½ç§»è¨­å®ï¼å³ DA å DGï¼ä¸­ï¼éå°ä¸åäººå£çµ±è¨è³æé½èæ®äºå¬å¹³æ§ï¼å¨åå²ååé¡æ¹é¢é½åªæ¼ç¾ææ¹æ³ãç¨å¼ç¢¼åè³æå¯æ¼ https://ophai.hms.harvard.edu/datasets/harvard-fairdomain20k åå¾ã</paragraph>

##### **Uncertainty Estimation of Large Language Models in Medical Question Answering**
2407.08662v1 by Jiaxin Wu, Yizhou Yu, Hong-Yu Zhou

Large Language Models (LLMs) show promise for natural language generation in
healthcare, but risk hallucinating factually incorrect information. Deploying
LLMs for medical question answering necessitates reliable uncertainty
estimation (UE) methods to detect hallucinations. In this work, we benchmark
popular UE methods with different model sizes on medical question-answering
datasets. Our results show that current approaches generally perform poorly in
this domain, highlighting the challenge of UE for medical applications. We also
observe that larger models tend to yield better results, suggesting a
correlation between model size and the reliability of UE. To address these
challenges, we propose Two-phase Verification, a probability-free Uncertainty
Estimation approach. First, an LLM generates a step-by-step explanation
alongside its initial answer, followed by formulating verification questions to
check the factual claims in the explanation. The model then answers these
questions twice: first independently, and then referencing the explanation.
Inconsistencies between the two sets of answers measure the uncertainty in the
original response. We evaluate our approach on three biomedical
question-answering datasets using Llama 2 Chat models and compare it against
the benchmarked baseline methods. The results show that our Two-phase
Verification method achieves the best overall accuracy and stability across
various datasets and model sizes, and its performance scales as the model size
increases.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨é«çä¿å¥é åçèªç¶èªè¨çææ¹é¢é¡¯ç¤ºåºåæ¯ï¼ä½å­å¨èæ§äºå¯¦ä¸æ­£ç¢ºè³è¨çé¢¨éªãé¨ç½² LLM ä¾åç­é«çåé¡éè¦å¯é çä¸ç¢ºå®æ§ä¼°è¨ (UE) æ¹æ³ä¾åµæ¸¬èæ§ãå¨éé å·¥ä½ä¸­ï¼æåä½¿ç¨ä¸åæ¨¡åå¤§å°å°ç±é UE æ¹æ³é²è¡åºæºæ¸¬è©¦ï¼éå°é«çåé¡åç­è³æéãæåççµæé¡¯ç¤ºï¼ç®åçä½æ³å¨éæ¹é¢éå¸¸è¡¨ç¾ä¸ä½³ï¼çªé¡¯äº UE å¨é«çæç¨ä¸­çææ°ãæåéè§å¯å°ï¼è¼å¤§çæ¨¡åå¾å¾æç¢çæ´å¥½ççµæï¼éè¡¨ææ¨¡åå¤§å°è UE çå¯é æ§ä¹éå­å¨ç¸éæ§ãçºäºæå°éäºææ°ï¼æåæåºäºå©éæ®µé©è­ï¼ä¸ç¨®ç¡æ©ççä¸ç¢ºå®æ§ä¼°è¨æ¹æ³ãé¦åï¼LLM æå¨å¶åå§ç­æ¡æéç¢çéæ­¥èªªæï¼ç¶å¾å¶å®é©è­åé¡ä¾æª¢æ¥èªªæä¸­çäºå¯¦è²æãç¶å¾ï¼æ¨¡ååç­éäºåé¡å©æ¬¡ï¼ç¬¬ä¸æ¬¡ç¨ç«åç­ï¼ç¶å¾åèèªªæãå©çµç­æ¡ä¹éçä¸ä¸è´æ§è¡¡éåå§åæä¸­çä¸ç¢ºå®æ§ãæåä½¿ç¨ Llama 2 Chat æ¨¡åå¨ä¸åçç©é«å­¸åé¡åç­è³æéä¸è©ä¼°æåçä½æ³ï¼ä¸¦å°å¶èåºæºåºæºæ¹æ³é²è¡æ¯è¼ãçµæé¡¯ç¤ºï¼æåçå©éæ®µé©è­æ¹æ³å¨åç¨®è³æéåæ¨¡åå¤§å°ä¸­å¯¦ç¾äºæä½³çæ´é«æºç¢ºæ§åç©©å®æ§ï¼ä¸¦ä¸å¶æè½é¨èæ¨¡åå¤§å°çå¢å èæ´å±ã

##### **Establishing Rigorous and Cost-effective Clinical Trials for Artificial Intelligence Models**
2407.08554v1 by Wanling Gao, Yunyou Huang, Dandan Cui, Zhuoming Yu, Wenjing Liu, Xiaoshuang Liang, Jiahui Zhao, Jiyue Xie, Hao Li, Li Ma, Ning Ye, Yumiao Kang, Dingfeng Luo, Peng Pan, Wei Huang, Zhongmou Liu, Jizhong Hu, Gangyuan Zhao, Chongrong Jiang, Fan Huang, Tianyi Wei, Suqin Tang, Bingjie Xia, Zhifei Zhang, Jianfeng Zhan

A profound gap persists between artificial intelligence (AI) and clinical
practice in medicine, primarily due to the lack of rigorous and cost-effective
evaluation methodologies. State-of-the-art and state-of-the-practice AI model
evaluations are limited to laboratory studies on medical datasets or direct
clinical trials with no or solely patient-centered controls. Moreover, the
crucial role of clinicians in collaborating with AI, pivotal for determining
its impact on clinical practice, is often overlooked. For the first time, we
emphasize the critical necessity for rigorous and cost-effective evaluation
methodologies for AI models in clinical practice, featuring
patient/clinician-centered (dual-centered) AI randomized controlled trials
(DC-AI RCTs) and virtual clinician-based in-silico trials (VC-MedAI) as an
effective proxy for DC-AI RCTs. Leveraging 7500 diagnosis records from
two-phase inaugural DC-AI RCTs across 14 medical centers with 125 clinicians,
our results demonstrate the necessity of DC-AI RCTs and the effectiveness of
VC-MedAI. Notably, VC-MedAI performs comparably to human clinicians,
replicating insights and conclusions from prospective DC-AI RCTs. We envision
DC-AI RCTs and VC-MedAI as pivotal advancements, presenting innovative and
transformative evaluation methodologies for AI models in clinical practice,
offering a preclinical-like setting mirroring conventional medicine, and
reshaping development paradigms in a cost-effective and fast-iterative manner.
Chinese Clinical Trial Registration: ChiCTR2400086816.

æè¦ï¼<paragraph>äººå·¥æºæ§ï¼AIï¼èè¨åºé«çå¯¦åä¹éå­å¨èå·¨å¤§çé´»æºï¼å¶ä¸»è¦åå å¨æ¼ç¼ºä¹å´è¬¹ä¸å·ææ¬æççè©ä¼°æ¹æ³ãæåé²ä¸ç¬¦åå¯¦åç AI æ¨¡åè©ä¼°åéæ¼éå°é«å­¸è³æéé²è¡çå¯¦é©å®¤ç ç©¶ï¼æåææ£èçºä¸­å¿çå°ç§çµçç´æ¥è¨åºè©¦é©ãæ­¤å¤ï¼è¨åºé«å¸«å¨è AI åä½ä¸­ææ®æ¼çééµè§è²ï¼å°æ¼æ±ºå®å¶å°è¨åºå¯¦åçå½±é¿è³ééè¦ï¼å»ç¶å¸¸è¢«å¿½è¦ãæåé¦åº¦å¼·èª¿å¨è¨åºå¯¦åä¸­æ¡ç¨å´è¬¹ä¸å·ææ¬æçç AI æ¨¡åè©ä¼°æ¹æ³è³ééè¦ï¼å¶ç¹è²å¨æ¼ä»¥æ£èï¼è¨åºé«å¸«çºä¸­å¿çï¼éä¸­å¿ï¼AI é¨æ©å°ç§è©¦é©ï¼DC-AI RCTï¼åèæ¬è¨åºé«å¸«çºåºç¤çé»è¦æ¨¡æ¬è©¦é©ï¼VC-MedAIï¼ï¼åçº DC-AI RCT çæææ¿ä»£æ¹æ¡ãå©ç¨ä¾èª 14 åé«çä¸­å¿ã125 ä½è¨åºé«å¸«çå©éæ®µé¦æ¬¡ DC-AI RCT ä¸­ç 7500 ç­è¨ºæ·ç´éï¼æåççµæè­æäº DC-AI RCT çå¿è¦æ§è VC-MedAI çæææ§ãå¼å¾æ³¨æçæ¯ï¼VC-MedAI çè¡¨ç¾èäººé¡è¨åºé«å¸«ç¸ç¶ï¼è¤è£½äºåç»æ§ DC-AI RCT çè¦è§£åçµè«ãæåå° DC-AI RCT å VC-MedAI è¦çºééµçé²å±ï¼å®åæåºäºåµæ°ä¸å·æè®é©æ§ç AI æ¨¡åè©ä¼°æ¹æ³ï¼å¨è¨åºå¯¦åä¸­æä¾é¡ä¼¼æ¼è¨åºåè¨­å®çç°å¢ï¼åæ å³çµ±é«å­¸ï¼ä¸¦ä»¥å·ææ¬æçä¸å¿«éåè¦éç®çæ¹å¼éæ°å¡é éç¼æ¨¡å¼ãä¸­åè¨åºè©¦é©è¨»åï¼ChiCTR2400086816ã</paragraph>

##### **How Deep is your Guess? A Fresh Perspective on Deep Learning for Medical Time-Series Imputation**
2407.08442v1 by Linglong Qian, Tao Wang, Jun Wang, Hugh Logan Ellis, Robin Mitra, Richard Dobson, Zina Ibrahim

We introduce a novel classification framework for time-series imputation
using deep learning, with a particular focus on clinical data. By identifying
conceptual gaps in the literature and existing reviews, we devise a taxonomy
grounded on the inductive bias of neural imputation frameworks, resulting in a
classification of existing deep imputation strategies based on their
suitability for specific imputation scenarios and data-specific properties. Our
review further examines the existing methodologies employed to benchmark deep
imputation models, evaluating their effectiveness in capturing the missingness
scenarios found in clinical data and emphasising the importance of reconciling
mathematical abstraction with clinical insights. Our classification aims to
serve as a guide for researchers to facilitate the selection of appropriate
deep learning imputation techniques tailored to their specific clinical data.
Our novel perspective also highlights the significance of bridging the gap
between computational methodologies and medical insights to achieve clinically
sound imputation models.

æè¦ï¼æåæåºäºä¸åæ°çæéåºåæè£åé¡æ¶æ§ï¼ä½¿ç¨æ·±åº¦å­¸ç¿ï¼ç¹å¥éæ³¨è¨åºæ¸æãééæ¾åºæç»åç¾æè©è«ä¸­çæ¦å¿µå·®è·ï¼æåè¨­è¨äºä¸ååé¡æ³ï¼è©²åé¡æ³åºæ¼ç¥ç¶æè£æ¡æ¶çæ­¸ç´åèª¤ï¼å¾èå°ç¾æçæ·±åº¦æè£ç­ç¥é²è¡åé¡ï¼åºæ¼å®åå°ç¹å®æè£å ´æ¯åæ¸æç¹å®å±¬æ§çé©ç¨æ§ãæåçåé¡§é²ä¸æ­¥æª¢é©äºç¨æ¼å°æ·±åº¦æè£æ¨¡åé²è¡åºæºæ¸¬è©¦çç¾ææ¹æ³ï¼è©ä¼°äºå®åå¨ææè¨åºæ¸æä¸­ç¼ç¾çç¼ºå¤±å ´æ¯æ¹é¢çæææ§ï¼ä¸¦å¼·èª¿äºèª¿åæ¸å­¸æ½è±¡èè¨åºè¦è§£çéè¦æ§ãæåçåé¡æ¨å¨ä½çºç ç©¶äººå¡çæåï¼ä»¥ä¿é²æ ¹æå¶ç¹å®è¨åºæ¸æé¸æé©ç¶çæ·±åº¦å­¸ç¿æè£æè¡ãæåçæ°è§é»éå¼·èª¿äºå½åè¨ç®æ¹æ³åé«å­¸è¦è§£ä¹éå·®è·ä»¥å¯¦ç¾è¨åºåçæè£æ¨¡åçéè¦æ§ã

##### **Specialist vision-language models for clinical ophthalmology**
2407.08410v1 by Robbie Holland, Thomas R. P. Taylor, Christopher Holmes, Sophie Riedl, Julia Mai, Maria Patsiamanidi, Dimitra Mitsopoulou, Paul Hager, Philip MÃ¼ller, Hendrik P. N. Scholl, Hrvoje BogunoviÄ, Ursula Schmidt-Erfurth, Daniel Rueckert, Sobha Sivaprasad, Andrew J. Lotery, Martin J. Menten

Clinicians spend a significant amount of time reviewing medical images and
transcribing their findings regarding patient diagnosis, referral and treatment
in text form. Vision-language models (VLMs), which automatically interpret
images and summarize their findings as text, have enormous potential to
alleviate clinical workloads and increase patient access to high-quality
medical care. While foundational models have stirred considerable interest in
the medical community, it is unclear whether their general capabilities
translate to real-world clinical utility. In this work, we show that foundation
VLMs markedly underperform compared to practicing ophthalmologists on
specialist tasks crucial to the care of patients with age-related macular
degeneration (AMD). To address this, we initially identified the essential
capabilities required for image-based clinical decision-making, and then
developed a curriculum to selectively train VLMs in these skills. The resulting
model, RetinaVLM, can be instructed to write reports that significantly
outperform those written by leading foundation medical VLMs in disease staging
(F1 score of 0.63 vs. 0.11) and patient referral (0.67 vs. 0.39), and
approaches the diagnostic performance of junior ophthalmologists (who achieve
0.77 and 0.78 on the respective tasks). Furthermore, in a reader study
involving two senior ophthalmologists with up to 32 years of experience,
RetinaVLM's reports were found to be similarly correct (78.6% vs. 82.1%) and
complete (both 78.6%) as reports written by junior ophthalmologists with up to
10 years of experience. These results demonstrate that our curriculum-based
approach provides a blueprint for specializing generalist foundation medical
VLMs to handle real-world clinical tasks.

æè¦ï¼<paragraph>è¨åºé«çè±è²»å¤§éæéæª¢é±é«çå½±åï¼ä¸¦ä»¥æå­å½¢å¼è¨éä»åéæ¼æ£èè¨ºæ·ãè½è¨ºåæ²»ççç¼ç¾ãè¦è¦ºèªè¨æ¨¡å (VLM) æèªåè§£è®å½±åä¸¦å°å¶ç¼ç¾æè¦ææå­ï¼å·ææ¸è¼è¨åºå·¥ä½è² è¼åå¢å æ£èç²å¾åªè³ªé«çä¿å¥çæ©æçå·¨å¤§æ½åãéç¶åºç¤æ¨¡åå¨é«ççå¼èµ·äºç¸ç¶å¤§çèè¶£ï¼ä½å°ä¸æ¸æ¥å®åçä¸è¬è½åæ¯å¦è½è½åçºå¯¦éçè¨åºæç¨ãå¨éé å·¥ä½ä¸­ï¼æåè¡¨æåºç¤ VLM å¨èå¹´é½¡ç¸éæ§é»æé¨çè® (AMD) æ£èç§è­·è³ééè¦çå°éä»»åä¸ï¼è¡¨ç¾æé¡¯ä¸å¦å·æ¥­ç¼ç§é«çãçºäºè§£æ±ºéååé¡ï¼æåæåæ¾åºå½±åå¼è¨åºæ±ºç­æéçå¿è¦è½åï¼ç¶å¾å¶å®èª²ç¨ä¾é¸ææ§å°è¨ç·´ VLM éäºæè½ãæç¢ççæ¨¡å RetinaVLM å¯ä»¥è¢«æç¤ºæ°å¯«å ±åï¼å¶å¨ç¾çåæï¼F1 åæ¸çº 0.63 å° 0.11ï¼åæ£èè½è¨ºï¼0.67 å° 0.39ï¼æ¹é¢æé¡¯åªæ¼é åçåºç¤é«ç VLM ææ°å¯«çå ±åï¼ä¸¦æ¥è¿åç´ç¼ç§é«ççè¨ºæ·è¡¨ç¾ï¼å¨åé ä»»åä¸­åå¥éå° 0.77 å 0.78ï¼ãæ­¤å¤ï¼å¨æ¶åå©ä½ææé·é 32 å¹´ç¶é©çé«ç´ç¼ç§é«ççè®èç ç©¶ä¸­ï¼ç¼ç¾ RetinaVLM çå ±åæ­£ç¢ºæ§ï¼78.6% å° 82.1%ï¼åå®æ´æ§ï¼åçº 78.6%ï¼èææé·é 10 å¹´ç¶é©çåç´ç¼ç§é«çææ°å¯«çå ±åç¸ä¼¼ãéäºçµæè¡¨æï¼æååºæ¼èª²ç¨çæ¹æ³æä¾äºå°éæåºç¤é«ç VLM å°éåä»¥èçå¯¦éè¨åºä»»åçèåã</paragraph>

##### **Unveiling Disparities in Maternity Care: A Topic Modelling Approach to Analysing Maternity Incident Investigation Reports**
2407.08328v1 by Georgina Cosma, Mohit Kumar Singh, Patrick Waterson, Gyuchan Thomas Jun, Jonathan Back

This study applies Natural Language Processing techniques, including Latent
Dirichlet Allocation, to analyse anonymised maternity incident investigation
reports from the Healthcare Safety Investigation Branch. The reports underwent
preprocessing, annotation using the Safety Intelligence Research taxonomy, and
topic modelling to uncover prevalent topics and detect differences in maternity
care across ethnic groups. A combination of offline and online methods was
utilised to ensure data protection whilst enabling advanced analysis, with
offline processing for sensitive data and online processing for non-sensitive
data using the `Claude 3 Opus' language model. Interactive topic analysis and
semantic network visualisation were employed to extract and display thematic
topics and visualise semantic relationships among keywords. The analysis
revealed disparities in care among different ethnic groups, with distinct focus
areas for the Black, Asian, and White British ethnic groups. The study
demonstrates the effectiveness of topic modelling and NLP techniques in
analysing maternity incident investigation reports and highlighting disparities
in care. The findings emphasise the crucial role of advanced data analysis in
improving maternity care quality and equity.

æè¦ï¼æ¬ç ç©¶æç¨èªç¶èªè¨èçæè¡ï¼åæ¬æ½å¨çå©åé·åéï¼åæé«çä¿å¥å®å¨èª¿æ¥å±çå¿åç¢å©¦äºä»¶èª¿æ¥å ±åãéäºå ±åç¶éé èçãä½¿ç¨å®å¨æå ±ç ç©¶åé¡æ³è¨»è§£ï¼ä»¥åä¸»é¡å»ºæ¨¡ï¼ä»¥æ¾åºæ®éçä¸»é¡ä¸¦æ¾åºä¸åæç¾¤å¨ç¢åç§è­·çå·®ç°ãçµåé¢ç·åç·ä¸æ¹æ³ï¼ä»¥ç¢ºä¿è³æä¿è­·ï¼åæé²è¡é²éåæï¼ä½¿ç¨ Claude 3 Opus èªè¨æ¨¡åå°ææè³æé²è¡é¢ç·èçï¼å°éææè³æé²è¡ç·ä¸èçãæ¡ç¨äºåä¸»é¡åæåèªæç¶²è·¯è¦è¦ºåï¼ä»¥èååé¡¯ç¤ºä¸»é¡ä¸»é¡ï¼ä¸¦è¦è¦ºåééµå­ä¹éçèªæéä¿ãåæé¡¯ç¤ºä¸åæç¾¤ä¹éçç§è­·å·®ç°ï¼é»äººãäºæ´²äººåç½äººè±åäººæç¾¤çéæ³¨é åä¸åãæ¬ç ç©¶è­æäºä¸»é¡å»ºæ¨¡åèªç¶èªè¨èçæè¡å¨åæç¢å©¦äºä»¶èª¿æ¥å ±ååå¼·èª¿ç§è­·å·®ç°æ¹é¢çæææ§ãç ç©¶çµæå¼·èª¿äºé²éè³æåæå¨æåç¢åç§è­·åè³ªåå¬å¹³æ§æ¹é¢çééµè§è²ã

##### **Predicting Heart Failure with Attention Learning Techniques Utilizing Cardiovascular Data**
2407.08289v1 by Ershadul Haque, Manoranjan Paul, Faranak Tohidi

Cardiovascular diseases (CVDs) encompass a group of disorders affecting the
heart and blood vessels, including conditions such as coronary artery disease,
heart failure, stroke, and hypertension. In cardiovascular diseases, heart
failure is one of the main causes of death and also long-term suffering in
patients worldwide. Prediction is one of the risk factors that is highly
valuable for treatment and intervention to minimize heart failure. In this
work, an attention learning-based heart failure prediction approach is proposed
on EHR(electronic health record) cardiovascular data such as ejection fraction
and serum creatinine. Moreover, different optimizers with various learning rate
approaches are applied to fine-tune the proposed approach. Serum creatinine and
ejection fraction are the two most important features to predict the patient's
heart failure. The computational result shows that the RMSProp optimizer with
0.001 learning rate has a better prediction based on serum creatinine. On the
other hand, the combination of SGD optimizer with 0.01 learning rate exhibits
optimum performance based on ejection fraction features. Overall, the proposed
attention learning-based approach performs very efficiently in predicting heart
failure compared to the existing state-of-the-art such as LSTM approach.

æè¦ï¼å¿è¡ç®¡ç¾ç (CVD) åå«ä¸çµå½±é¿å¿èåè¡ç®¡çç¾çï¼åæ¬å çåèç¾çãå¿è¡°ç«­ãä¸­é¢¨åé«è¡å£ç­ç¾çãå¨å¿è¡ç®¡ç¾çä¸­ï¼å¿è¡°ç«­æ¯å¨çæ£èæ­»äº¡çä¸»è¦åå ä¹ä¸ï¼ä¹æ¯é·æçè¦çä¾æºãé æ¸¬æ¯å°æ²»çåå¹²é ä»¥æå¤§ç¨åº¦æ¸å°å¿è¡°ç«­æ¥µæå¹å¼çé¢¨éªå ç´ ä¹ä¸ãå¨éé å·¥ä½ä¸­ï¼æåºäºä¸ç¨®åºæ¼æ³¨æåå­¸ç¿çå¿è¡°ç«­é æ¸¬æ¹æ³ï¼è©²æ¹æ³åºæ¼ EHRï¼é»å­å¥åº·è¨éï¼å¿è¡ç®¡æ¸æï¼ä¾å¦å°è¡åæ¸åè¡æ¸èéãæ­¤å¤ï¼æç¨å·æåç¨®å­¸ç¿çæ¹æ³çä¸ååªåå¨å°ææåºçæ¹æ³é²è¡å¾®èª¿ãè¡æ¸èéåå°è¡åæ¸æ¯é æ¸¬æ£èå¿è¡°ç«­çå©åæéè¦çç¹å¾µãè¨ç®çµæè¡¨æï¼å­¸ç¿ççº 0.001 ç RMSProp åªåå¨åºæ¼è¡æ¸èéå·ææ´å¥½çé æ¸¬ãå¦ä¸æ¹é¢ï¼å­¸ç¿ççº 0.01 ç SGD åªåå¨èå°è¡åæ¸ç¹å¾µç¸çµåï¼è¡¨ç¾åºæä½³æ§è½ãç¸½é«èè¨ï¼è LSTM æ¹æ³ç­ç¾ææè¡ç¸æ¯ï¼ææåºçåºæ¼æ³¨æåå­¸ç¿çæ¹æ³å¨é æ¸¬å¿è¡°ç«­æ¹é¢è¡¨ç¾å¾éå¸¸ææã

##### **Leveraging LLMs to Predict Affective States via Smartphone Sensor Features**
2407.08240v1 by Tianyi Zhang, Songyan Teng, Hong Jia, Simon D'Alfonso

As mental health issues for young adults present a pressing public health
concern, daily digital mood monitoring for early detection has become an
important prospect. An active research area, digital phenotyping, involves
collecting and analysing data from personal digital devices such as smartphones
(usage and sensors) and wearables to infer behaviours and mental health. Whilst
this data is standardly analysed using statistical and machine learning
approaches, the emergence of large language models (LLMs) offers a new approach
to make sense of smartphone sensing data. Despite their effectiveness across
various domains, LLMs remain relatively unexplored in digital mental health,
particularly in integrating mobile sensor data. Our study aims to bridge this
gap by employing LLMs to predict affect outcomes based on smartphone sensing
data from university students. We demonstrate the efficacy of zero-shot and
few-shot embedding LLMs in inferring general wellbeing. Our findings reveal
that LLMs can make promising predictions of affect measures using solely
smartphone sensing data. This research sheds light on the potential of LLMs for
affective state prediction, emphasizing the intricate link between smartphone
behavioral patterns and affective states. To our knowledge, this is the first
work to leverage LLMs for affective state prediction and digital phenotyping
tasks.

æè¦ï¼é¨èå¹´è¼äººçå¿çå¥åº·åé¡æçºè¿«åçå¬å±è¡çåé¡ï¼æ¯æ¥æ¸ä½æç·ç£æ§å·²æçºæ©æåµæ¸¬çéè¦åæ¯ãæ¸ä½è¡¨ååæ¯ä¸åç©æ¥µçç ç©¶é åï¼æ¶åæ¶éååæä¾èªåäººæ¸ä½è£ç½®ï¼ä¾å¦æºæ§åææ©ï¼ä½¿ç¨åææ¸¬å¨ï¼åå¯ç©¿æ´è£ç½®ï¼çè³æï¼ä»¥æ¨è«è¡çºåå¿çå¥åº·ãéç¶éäºè³æéå¸¸ä½¿ç¨çµ±è¨åæ©å¨å­¸ç¿æ¹æ³é²è¡åæï¼ä½å¤§åèªè¨æ¨¡å (LLM) çåºç¾æä¾äºä¸ç¨®æ°çæ¹æ³ä¾çè§£æºæ§åææ©ææ¸¬è³æãåç®¡ LLM å¨åç¨®é åé½éå¸¸ææï¼ä½å¶å¨æ¸ä½å¿çå¥åº·é åä»ç¸å°æªè¢«æ¢ç´¢ï¼ç¹å¥æ¯å¨æ´åè¡åææ¸¬å¨è³ææ¹é¢ãæåçç ç©¶æ¨å¨ééä½¿ç¨ LLM ä¾æ ¹æå¤§å­¸ççæºæ§åææ©ææ¸¬è³æé æ¸¬å½±é¿çµæï¼ä»¥å½åéä¸å·®è·ãæåå±ç¤ºäºé¶æ¬¡å­¸ç¿åå°æ¬¡å­¸ç¿åµå¥å¼ LLM å¨æ¨è«ä¸è¬å¹¸ç¦ææ¹é¢çæè½ãæåçç ç©¶çµæé¡¯ç¤ºï¼LLM å¯ä»¥åä½¿ç¨æºæ§åææ©ææ¸¬è³æå°å½±é¿æ¸¬éé²è¡æå¸æçé æ¸¬ãæ¬ç ç©¶æ­ç¤ºäº LLM å¨ææçæé æ¸¬æ¹é¢çæ½åï¼å¼·èª¿äºæºæ§åææ©è¡çºæ¨¡å¼åææçæä¹éçè¤éè¯ç¹«ãææåæç¥ï¼éæ¯ç¬¬ä¸åå©ç¨ LLM é²è¡ææçæé æ¸¬åæ¸ä½è¡¨ååä»»åçç ç©¶ã

##### **DALL-M: Context-Aware Clinical Data Augmentation with LLMs**
2407.08227v1 by Chihcheng Hsieh, Catarina Moreira, Isabel Blanco Nobre, Sandra Costa Sousa, Chun Ouyang, Margot Brereton, Joaquim Jorge, Jacinto C. Nascimento

X-ray images are vital in medical diagnostics, but their effectiveness is
limited without clinical context. Radiologists often find chest X-rays
insufficient for diagnosing underlying diseases, necessitating comprehensive
clinical features and data integration. We present a novel technique to enhance
the clinical context through augmentation techniques with clinical tabular
data, thereby improving its applicability and reliability in AI medical
diagnostics. To address this, we introduce a pioneering approach to clinical
data augmentation that employs large language models (LLMs) to generate patient
contextual synthetic data. This methodology is crucial for training more robust
deep learning models in healthcare. It preserves the integrity of real patient
data while enriching the dataset with contextually relevant synthetic features,
significantly enhancing model performance. DALL-M uses a three-phase feature
generation process: (i) clinical context storage, (ii) expert query generation,
and (iii) context-aware feature augmentation. DALL-M generates new, clinically
relevant features by synthesizing chest X-ray images and reports. Applied to
799 cases using nine features from the MIMIC-IV dataset, it created an
augmented set of 91 features. This is the first work to generate contextual
values for existing and new features based on patients' X-ray reports, gender,
and age and to produce new contextual knowledge during data augmentation.
Empirical validation with machine learning models, including Decision Trees,
Random Forests, XGBoost, and TabNET, showed significant performance
improvements. Incorporating augmented features increased the F1 score by 16.5%
and Precision and Recall by approximately 25%. DALL-M addresses a critical gap
in clinical data augmentation, offering a robust framework for generating
contextually enriched datasets.

æè¦ï¼<paragraph>X åå½±åå¨å»å­¦è¯æ­ä¸­è³å³éè¦ï¼ä½å¦ææ²¡æä¸´åºèæ¯ï¼å¶æææ§ä¼åå°éå¶ãæ¾å°ç§å»çç»å¸¸åç°è¸é¨ X åå½±åä¸è¶³ä»¥è¯æ­æ½å¨ç¾çï¼å æ­¤éè¦å¨é¢çä¸´åºç¹å¾åæ°æ®æ´åãæä»¬æåºäºä¸ç§æ°ææ¯ï¼éè¿ä½¿ç¨ä¸´åºè¡¨æ ¼æ°æ®è¿è¡å¢å¼ºææ¯æ¥å¢å¼ºä¸´åºèæ¯ï¼ä»èæé«å¶å¨ AI å»å­¦è¯æ­ä¸­çéç¨æ§åå¯é æ§ãä¸ºäºè§£å³è¿ä¸ªé®é¢ï¼æä»¬å¼å¥äºä¸ç§å¼åæ§çä¸´åºæ°æ®å¢å¼ºæ¹æ³ï¼è¯¥æ¹æ³éç¨å¤§åè¯­è¨æ¨¡å (LLM) æ¥çææ£èèæ¯åææ°æ®ãè¿ç§æ¹æ³å¯¹äºå¨å»çä¿å¥é¢åè®­ç»æ´å¼ºå¤§çæ·±åº¦å­¦ä¹ æ¨¡åè³å³éè¦ãå®ä¿çäºçå®æ£èæ°æ®çå®æ´æ§ï¼åæ¶ä½¿ç¨ä¸ä¸ä¸æç¸å³çåæç¹å¾ä¸°å¯äºæ°æ®éï¼ä»èæ¾èæé«äºæ¨¡åæ§è½ãDALL-M ä½¿ç¨äºä¸ä¸ªä¸é¶æ®µç¹å¾çæè¿ç¨ï¼(i) ä¸´åºèæ¯å­å¨ï¼(ii) ä¸å®¶æ¥è¯¢çæï¼(iii) ä¸ä¸ææç¥ç¹å¾å¢å¼ºãDALL-M éè¿åæè¸é¨ X åå½±ååæ¥åæ¥çææ°çãä¸ä¸´åºç¸å³çç¹å¾ãå°å¶åºç¨äº MIMIC-IV æ°æ®éä¸­ç 799 ä¸ªæ¡ä¾ï¼ä½¿ç¨ä¹ä¸ªç¹å¾ï¼å®åå»ºäºä¸ä¸ªåå« 91 ä¸ªç¹å¾çå¢å¼ºéåãè¿æ¯ç¬¬ä¸é¡¹åºäºæ£èç X åæ¥åãæ§å«åå¹´é¾ä¸ºç°æåæ°ç¹å¾çæä¸ä¸æå¼çèä½ï¼å¹¶å¨æ°æ®å¢å¼ºæé´äº§çæ°çä¸ä¸æç¥è¯ãä½¿ç¨åæ¬å³ç­æ ãéæºæ£®æãXGBoost å TabNET å¨åçæºå¨å­¦ä¹ æ¨¡åè¿è¡çç»éªéªè¯æ¾ç¤ºåºæ¾èçæ§è½æ¹è¿ãåå¹¶å¢å¼ºåè½å° F1 åæ°æé«äº 16.5%ï¼å¹¶å°ç²¾ç¡®åº¦åå¬åçæé«äºå¤§çº¦ 25%ãDALL-M è§£å³äºä¸ä¸ªä¸´åºæ°æ®å¢å¼ºä¸­çå³é®ç©ºç½ï¼æä¾äºä¸ä¸ªç¨äºçæä¸ä¸æä¸°å¯çæ°æ®éçç¨³å¥æ¡æ¶ã</paragraph>

##### **Synthetic Electroretinogram Signal Generation Using Conditional Generative Adversarial Network for Enhancing Classification of Autism Spectrum Disorder**
2407.08166v1 by Mikhail Kulyabin, Paul A. Constable, Aleksei Zhdanov, Irene O. Lee, David H. Skuse, Dorothy A. Thompson, Andreas Maier

The electroretinogram (ERG) is a clinical test that records the retina's
electrical response to light. The ERG is a promising way to study different
neurodevelopmental and neurodegenerative disorders, including autism spectrum
disorder (ASD) - a neurodevelopmental condition that impacts language,
communication, and reciprocal social interactions. However, in heterogeneous
populations, such as ASD, where the ability to collect large datasets is
limited, the application of artificial intelligence (AI) is complicated.
Synthetic ERG signals generated from real ERG recordings carry similar
information as natural ERGs and, therefore, could be used as an extension for
natural data to increase datasets so that AI applications can be fully
utilized. As proof of principle, this study presents a Generative Adversarial
Network capable of generating synthetic ERG signals of children with ASD and
typically developing control individuals. We applied a Time Series Transformer
and Visual Transformer with Continuous Wavelet Transform to enhance
classification results on the extended synthetic signals dataset. This approach
may support classification models in related psychiatric conditions where the
ERG may help classify disorders.

æè¦ï¼è¦ç¶²èé»å (ERG) æ¯ä¸ç¨®è¨åºæ¸¬è©¦ï¼ç¨æ¼è¨éè¦ç¶²èå°åçé»æ°£åæãERG æ¯ä¸ç¨®å¾æåéçç ç©¶ä¸åç¥ç¶ç¼è²åç¥ç¶éåæ§ç¾ççæ¹æ³ï¼åæ¬èªéçè­ç³»éç¤ (ASD) - ä¸ç¨®å½±é¿èªè¨ãæºéåç¤¾äº¤äºåçç¥ç¶ç¼è²çæ³ãç¶èï¼å¨ç°è³ªäººç¾¤ä¸­ï¼ä¾å¦ ASDï¼æ¶éå¤§åæ¸æéçè½åæéï¼äººå·¥æºè½ (AI) çæç¨å¾è¤éãå¾çå¯¦ ERG è¨éä¸­ç¢ççåæ ERG ä¿¡èæå¸¶èèªç¶ ERG ç¸ä¼¼çä¿¡æ¯ï¼å æ­¤å¯ç¨ä½èªç¶æ¸æçæ´å±ï¼ä»¥å¢å æ¸æéï¼ä»¥ä¾¿ AI æç¨ç¨åºå¯ä»¥å¾å°ååå©ç¨ãä½çºåçè­æï¼æ¬ç ç©¶æåºäºä¸åçæå°æç¶²è·¯ï¼è½å¤ ç¢çèªéçåç«¥åæ­£å¸¸ç¼è²å°ç§åäººçåæ ERG ä¿¡èãæåæç¨æåºè½æå¨åå·æé£çºå°æ³¢è½æçè¦è¦ºè½æå¨ä¾å¢å¼·æ´å±åæä¿¡èæ¸æéä¸çåé¡çµæãéç¨®æ¹æ³å¯ä»¥æ¯æç¸éç²¾ç¥ç¾ççåé¡æ¨¡åï¼å¨éäºç¾çä¸­ï¼ERG å¯è½æå©æ¼å°ç¾çé²è¡åé¡ã

##### **Highway Networks for Improved Surface Reconstruction: The Role of Residuals and Weight Updates**
2407.08134v1 by A. Noorizadegan, Y. C. Hon, D. L. Young, C. S. Chen

Surface reconstruction from point clouds is a fundamental challenge in
computer graphics and medical imaging. In this paper, we explore the
application of advanced neural network architectures for the accurate and
efficient reconstruction of surfaces from data points. We introduce a novel
variant of the Highway network (Hw) called Square-Highway (SqrHw) within the
context of multilayer perceptrons and investigate its performance alongside
plain neural networks and a simplified Hw in various numerical examples. These
examples include the reconstruction of simple and complex surfaces, such as
spheres, human hands, and intricate models like the Stanford Bunny. We analyze
the impact of factors such as the number of hidden layers, interior and
exterior points, and data distribution on surface reconstruction quality. Our
results show that the proposed SqrHw architecture outperforms other neural
network configurations, achieving faster convergence and higher-quality surface
reconstructions. Additionally, we demonstrate the SqrHw's ability to predict
surfaces over missing data, a valuable feature for challenging applications
like medical imaging. Furthermore, our study delves into further details,
demonstrating that the proposed method based on highway networks yields more
stable weight norms and backpropagation gradients compared to the Plain Network
architecture. This research not only advances the field of computer graphics
but also holds utility for other purposes such as function interpolation and
physics-informed neural networks, which integrate multilayer perceptrons into
their algorithms.

æè¦ï¼å¾é»é²é²è¡æ²é¢éå»ºæ¯é»è¦åå­¸åé«å­¸å½±åä¸­çä¸é åºæ¬ææ°ãå¨æ¬æä¸­ï¼æåæ¢è¨äºåé²ç¥ç¶ç¶²è·¯æ¶æ§å¨å¾è³æé»ç²¾ç¢ºä¸ææéå»ºæ²é¢ä¸­çæç¨ãæåå¨å¤å±¤æç¥å¨çæ¶æ§ä¸­ï¼å¼å¥äºé«éå¬è·¯ç¶²è·¯ï¼Hwï¼çä¸ç¨®æ°è®é«ï¼ç¨±çº Square-Highwayï¼SqrHwï¼ï¼ä¸¦å¨åç¨®æ¸å¼ç¯ä¾ä¸­æ¢è¨å¶æè½ï¼ä»¥åèä¸è¬ç¥ç¶ç¶²è·¯åç°¡åç Hw çæè½ãéäºç¯ä¾åæ¬éå»ºç°¡å®åè¤éçæ²é¢ï¼ä¾å¦çé«ãäººæåå Stanford Bunny é£æ¨£è¤éçæ¨¡åãæååæäºé±èå±¤æ¸ãå§é¨åå¤é¨é»ä»¥åè³æåä½ç­å ç´ å°æ²é¢éå»ºåè³ªçå½±é¿ãæåççµæé¡¯ç¤ºï¼ææåºç SqrHw æ¶æ§åªæ¼å¶ä»ç¥ç¶ç¶²è·¯çµæï¼è½éææ´å¿«çæ¶æéåº¦åæ´é«åè³ªçæ²é¢éå»ºãæ­¤å¤ï¼æåå±ç¤ºäº SqrHw è½å¤ é æ¸¬éºå¤±è³æä¸çæ²é¢ï¼éå°æ¼åé«å­¸å½±åé£æ¨£å·æææ°æ§çæç¨ä¾èªªï¼æ¯ä¸åæå¹å¼çåè½ãæ­¤å¤ï¼æåçç ç©¶æ·±å¥æ¢è¨äºæ´å¤ç´°ç¯ï¼è­æäºåºæ¼é«éå¬è·¯ç¶²è·¯çææåºæ¹æ³ï¼èä¸è¬ç¶²è·¯æ¶æ§ç¸æ¯ï¼ç¢çäºæ´ç©©å®çæ¬éç¯æ¸åååå³æ­æ¢¯åº¦ãéé ç ç©¶ä¸åæ¨åäºé»è¦åå­¸é åï¼ä¹å°å¶ä»ç¨éæå¹«å©ï¼ä¾å¦å½æ¸å§æåç©çè³è¨ç¥ç¶ç¶²è·¯ï¼å°å¤å±¤æç¥å¨æ´åå°å¶æ¼ç®æ³ä¸­ã

##### **Machine Learning for ALSFRS-R Score Prediction: Making Sense of the Sensor Data**
2407.08003v1 by Ritesh Mehta, Aleksandar Pramov, Shashank Verma

Amyotrophic Lateral Sclerosis (ALS) is characterized as a rapidly progressive
neurodegenerative disease that presents individuals with limited treatment
options in the realm of medical interventions and therapies. The disease
showcases a diverse range of onset patterns and progression trajectories,
emphasizing the critical importance of early detection of functional decline to
enable tailored care strategies and timely therapeutic interventions. The
present investigation, spearheaded by the iDPP@CLEF 2024 challenge, focuses on
utilizing sensor-derived data obtained through an app. This data is used to
construct various machine learning models specifically designed to forecast the
advancement of the ALS Functional Rating Scale-Revised (ALSFRS-R) score,
leveraging the dataset provided by the organizers. In our analysis, multiple
predictive models were evaluated to determine their efficacy in handling ALS
sensor data. The temporal aspect of the sensor data was compressed and
amalgamated using statistical methods, thereby augmenting the interpretability
and applicability of the gathered information for predictive modeling
objectives. The models that demonstrated optimal performance were a naive
baseline and ElasticNet regression. The naive model achieved a Mean Absolute
Error (MAE) of 0.20 and a Root Mean Square Error (RMSE) of 0.49, slightly
outperforming the ElasticNet model, which recorded an MAE of 0.22 and an RMSE
of 0.50. Our comparative analysis suggests that while the naive approach
yielded marginally better predictive accuracy, the ElasticNet model provides a
robust framework for understanding feature contributions.

æè¦ï¼èèç¸®æ§èé«å´ç´¢ç¡¬åç (ALS) çç¹å¾µçºå¿«éé²å±çç¥ç¶éåæ§ç¾çï¼å¨é«çä»å¥åæ²»çé åä¸­ï¼æ£èçæ²»çé¸ææéãæ­¤ç¾çå±ç¤ºåºå¤æ¨£åçç¼çæ¨¡å¼åé²å±è»è·¡ï¼å¼·èª¿æ©æåµæ¸¬åè½è¡°éè³ééè¦ï¼ä»¥å¶å®å®¢è£½åçç§è­·ç­ç¥ååæçæ²»çä»å¥ãæ¬ç ç©¶ç± iDPP@CLEF 2024 ææ°å¸¶é ­ï¼å°æ³¨æ¼å©ç¨ééæç¨ç¨å¼åå¾çææ¸¬å¨è¡çè³æãéäºè³æç¨æ¼å»ºæ§åç¨®æ©å¨å­¸ç¿æ¨¡åï¼ç¹å¥è¨­è¨ç¨æ¼é æ¸¬ ALS åè½è©åéè¡¨ä¿®è¨ç (ALSFRS-R) åæ¸çé²å±ï¼ä¸¦å©ç¨ä¸»è¾¦å®ä½æä¾çè³æéãå¨æåçåæä¸­ï¼è©ä¼°äºå¤ç¨®é æ¸¬æ¨¡åï¼ä»¥ç¢ºå®å®åå¨èç ALS ææ¸¬å¨è³ææ¹é¢çæè½ãææ¸¬å¨è³æçæéé¢åä½¿ç¨çµ±è¨æ¹æ³é²è¡å£ç¸®ååä½µï¼å¾èå¢å¼·æ¶éè³è¨å¨é æ¸¬å»ºæ¨¡ç®æ¨æ¹é¢çå¯è§£éæ§åé©ç¨æ§ãè¡¨ç¾æä½³çæ¨¡åæ¯æ¨¸ç´ åºæºå ElasticNet åæ­¸ãæ¨¸ç´ æ¨¡åéå°äºå¹³åçµå°èª¤å·® (MAE) çº 0.20 ååæ¹æ ¹èª¤å·® (RMSE) çº 0.49ï¼ç¥åæ¼ ElasticNet æ¨¡åï¼å¾èç MAE çº 0.22ï¼RMSE çº 0.50ãæåçæ¯è¼åæè¡¨æï¼éç¶æ¨¸ç´ æ¹æ³ç¢ççé æ¸¬æºç¢ºåº¦ç¥é«ï¼ä½ ElasticNet æ¨¡åæä¾äºä¸åç©©å¥çæ¶æ§ï¼ç¨æ¼ç­è§£ç¹å¾µè²¢ç»ã


### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-07-25**|**Self-Training with Direct Preference Optimization Improves Chain-of-Thought Reasoning**|Tianduo Wang et.al.|[2407.18248v1](http://arxiv.org/abs/2407.18248v1)|[link](https://github.com/tianduowang/dpo-st)|
|**2024-07-25**|**LoRA-Pro: Are Low-Rank Adapters Properly Optimized?**|Zhengbo Wang et.al.|[2407.18242v1](http://arxiv.org/abs/2407.18242v1)|[link](https://github.com/mrflogs/LoRA-Pro)|
|**2024-07-25**|**Recursive Introspection: Teaching Language Model Agents How to Self-Improve**|Yuxiao Qu et.al.|[2407.18219v1](http://arxiv.org/abs/2407.18219v1)|null|
|**2024-07-25**|**Exploring Scaling Trends in LLM Robustness**|Nikolhaus Howe et.al.|[2407.18213v1](http://arxiv.org/abs/2407.18213v1)|null|
|**2024-07-25**|**Differentiable Quantum Architecture Search in Asynchronous Quantum Reinforcement Learning**|Samuel Yen-Chi Chen et.al.|[2407.18202v1](http://arxiv.org/abs/2407.18202v1)|null|
|**2024-07-25**|**Gene Regulatory Network Inference from Pre-trained Single-Cell Transcriptomics Transformer with Joint Graph Learning**|Sindhura Kommu et.al.|[2407.18181v1](http://arxiv.org/abs/2407.18181v1)|null|
|**2024-07-25**|**Quasar-ViT: Hardware-Oriented Quantization-Aware Architecture Search for Vision Transformers**|Zhengang Li et.al.|[2407.18175v1](http://arxiv.org/abs/2407.18175v1)|null|
|**2024-07-25**|**The FIGNEWS Shared Task on News Media Narratives**|Wajdi Zaghouani et.al.|[2407.18147v1](http://arxiv.org/abs/2407.18147v1)|null|
|**2024-07-25**|**Taxonomy-Aware Continual Semantic Segmentation in Hyperbolic Spaces for Open-World Perception**|Julia Hindel et.al.|[2407.18145v1](http://arxiv.org/abs/2407.18145v1)|null|
|**2024-07-25**|**Dallah: A Dialect-Aware Multimodal Large Language Model for Arabic**|Fakhraddin Alwajih et.al.|[2407.18129v1](http://arxiv.org/abs/2407.18129v1)|null|
|**2024-07-25**|**Self-supervised pre-training with diffusion model for few-shot landmark detection in x-ray images**|Roberto Di Via et.al.|[2407.18125v1](http://arxiv.org/abs/2407.18125v1)|null|
|**2024-07-25**|**Tracking linguistic information in transformer-based sentence embeddings through targeted sparsification**|Vivi Nastase et.al.|[2407.18119v1](http://arxiv.org/abs/2407.18119v1)|null|
|**2024-07-25**|**Multi-Resolution Histopathology Patch Graphs for Ovarian Cancer Subtyping**|Jack Breen et.al.|[2407.18105v1](http://arxiv.org/abs/2407.18105v1)|null|
|**2024-07-25**|**Privacy Threats and Countermeasures in Federated Learning for Internet of Things: A Systematic Review**|Adel ElZemity et.al.|[2407.18096v1](http://arxiv.org/abs/2407.18096v1)|null|
|**2024-07-25**|**PEFT-U: Parameter-Efficient Fine-Tuning for User Personalization**|Christopher Clarke et.al.|[2407.18078v1](http://arxiv.org/abs/2407.18078v1)|null|
|**2024-07-25**|**Difficulty Estimation and Simplification of French Text Using LLMs**|Henri Jamet et.al.|[2407.18061v1](http://arxiv.org/abs/2407.18061v1)|null|
|**2024-07-25**|**Peak-Controlled Logits Poisoning Attack in Federated Distillation**|Yuhan Tang et.al.|[2407.18039v1](http://arxiv.org/abs/2407.18039v1)|null|
|**2024-07-25**|**RestoreAgent: Autonomous Image Restoration Agent via Multimodal Large Language Models**|Haoyu Chen et.al.|[2407.18035v1](http://arxiv.org/abs/2407.18035v1)|null|
|**2024-07-25**|**AttentionHand: Text-driven Controllable Hand Image Generation for 3D Hand Reconstruction in the Wild**|Junho Park et.al.|[2407.18034v1](http://arxiv.org/abs/2407.18034v1)|null|
|**2024-07-25**|**Learning mental states estimation through self-observation: a developmental synergy between intentions and beliefs representations in a deep-learning model of Theory of Mind**|Francesca Bianco et.al.|[2407.18022v1](http://arxiv.org/abs/2407.18022v1)|null|
|**2024-07-25**|**Quadratic Advantage with Quantum Randomized Smoothing Applied to Time-Series Analysis**|Nicola Franco et.al.|[2407.18021v1](http://arxiv.org/abs/2407.18021v1)|null|
|**2024-07-25**|**GermanPartiesQA: Benchmarking Commercial Large Language Models for Political Bias and Sycophancy**|Jan Batzner et.al.|[2407.18008v1](http://arxiv.org/abs/2407.18008v1)|null|
|**2024-07-25**|**Keep the Cost Down: A Review on Methods to Optimize LLM' s KV-Cache Consumption**|Shi Luohe et.al.|[2407.18003v1](http://arxiv.org/abs/2407.18003v1)|null|
|**2024-07-25**|**On the Effect of Purely Synthetic Training Data for Different Automatic Speech Recognition Architectures**|Nick Rossenbach et.al.|[2407.17997v1](http://arxiv.org/abs/2407.17997v1)|null|
|**2024-07-25**|**What does Kiki look like? Cross-modal associations between speech sounds and visual shapes in vision-and-language models**|Tessa Verhoef et.al.|[2407.17974v1](http://arxiv.org/abs/2407.17974v1)|null|
|**2024-07-25**|**Relating the Seemingly Unrelated: Principled Understanding of Generalization for Generative Models in Arithmetic Reasoning Tasks**|Xingcheng Xu et.al.|[2407.17963v1](http://arxiv.org/abs/2407.17963v1)|null|
|**2024-07-25**|**The Curious Case of Representational Alignment: Unravelling Visio-Linguistic Tasks in Emergent Communication**|Tom Kouwenhoven et.al.|[2407.17960v1](http://arxiv.org/abs/2407.17960v1)|null|
|**2024-07-25**|**Real Time American Sign Language Detection Using Yolo-v9**|Amna Imran et.al.|[2407.17950v1](http://arxiv.org/abs/2407.17950v1)|null|
|**2024-07-25**|**Positive Text Reframing under Multi-strategy Optimization**|Shutong Jia et.al.|[2407.17940v1](http://arxiv.org/abs/2407.17940v1)|null|
|**2024-07-25**|**Comparison of different Artificial Neural Networks for Bitcoin price forecasting**|Silas Baumann et.al.|[2407.17930v1](http://arxiv.org/abs/2407.17930v1)|null|
|**2024-07-25**|**Invariance of deep image quality metrics to affine transformations**|Nuria Alabau-Bosque et.al.|[2407.17927v1](http://arxiv.org/abs/2407.17927v1)|null|
|**2024-07-25**|**The Dark Side of Function Calling: Pathways to Jailbreaking Large Language Models**|Zihui Wu et.al.|[2407.17915v1](http://arxiv.org/abs/2407.17915v1)|[link](https://github.com/wooozihui/jailbreakfunction)|
|**2024-07-25**|**Modelling Multimodal Integration in Human Concept Processing with Vision-and-Language Models**|Anna Bavaresco et.al.|[2407.17914v1](http://arxiv.org/abs/2407.17914v1)|null|
|**2024-07-25**|**ReCorD: Reasoning and Correcting Diffusion for HOI Generation**|Jian-Yu Jiang-Lin et.al.|[2407.17911v1](http://arxiv.org/abs/2407.17911v1)|null|
|**2024-07-25**|**The Power of Combining Data and Knowledge: GPT-4o is an Effective Interpreter of Machine Learning Models in Predicting Lymph Node Metastasis of Lung Cancer**|Danqing Hu et.al.|[2407.17900v1](http://arxiv.org/abs/2407.17900v1)|null|
|**2024-07-25**|**3D Hole Filling using Deep Learning Inpainting**|Marina HernÃ¡ndez-Bautista et.al.|[2407.17896v1](http://arxiv.org/abs/2407.17896v1)|null|
|**2024-07-25**|**An Iterative Approach to Topic Modelling**|Albert Wong et.al.|[2407.17892v1](http://arxiv.org/abs/2407.17892v1)|null|
|**2024-07-25**|**Unraveling the Never-Ending Story of Lifecycles and Vitalizing Processes**|Stephan A. Fahrenkrog-Petersen et.al.|[2407.17881v1](http://arxiv.org/abs/2407.17881v1)|null|
|**2024-07-25**|**A Large-Scale Sensitivity Analysis on Latent Embeddings and Dimensionality Reductions for Text Spatializations**|Daniel Atzberger et.al.|[2407.17876v1](http://arxiv.org/abs/2407.17876v1)|[link](https://github.com/hpicgs/topic-models-and-dimensionality-reduction-sensitivity-study)|
|**2024-07-25**|**Improving Domain-Specific ASR with LLM-Generated Contextual Descriptions**|Jiwon Suh et.al.|[2407.17874v1](http://arxiv.org/abs/2407.17874v1)|null|
|**2024-07-25**|**Is the Digital Forensics and Incident Response Pipeline Ready for Text-Based Threats in LLM Era?**|Avanti Bhandarkar et.al.|[2407.17870v1](http://arxiv.org/abs/2407.17870v1)|null|
|**2024-07-25**|**Financial Statement Analysis with Large Language Models**|Alex Kim et.al.|[2407.17866v1](http://arxiv.org/abs/2407.17866v1)|null|
|**2024-07-25**|**factgenie: A Framework for Span-based Evaluation of Generated Texts**|ZdenÄk Kasner et.al.|[2407.17863v1](http://arxiv.org/abs/2407.17863v1)|null|
|**2024-07-25**|**Exploring Description-Augmented Dataless Intent Classification**|Ruoyu Hu et.al.|[2407.17862v1](http://arxiv.org/abs/2407.17862v1)|null|
|**2024-07-25**|**Shapley Value-based Contrastive Alignment for Multimodal Information Extraction**|Wen Luo et.al.|[2407.17854v1](http://arxiv.org/abs/2407.17854v1)|null|
|**2024-07-25**|**Scaling A Simple Approach to Zero-Shot Speech Recognition**|Jinming Zhao et.al.|[2407.17852v1](http://arxiv.org/abs/2407.17852v1)|null|
|**2024-07-25**|**Innovative Speech-Based Deep Learning Approaches for Parkinson's Disease Classification: A Systematic Review**|Lisanne van Gelderen et.al.|[2407.17844v1](http://arxiv.org/abs/2407.17844v1)|null|
|**2024-07-25**|**DragText: Rethinking Text Embedding in Point-based Image Editing**|Gayoon Choi et.al.|[2407.17843v1](http://arxiv.org/abs/2407.17843v1)|null|
|**2024-07-25**|**On the Opportunities of (Re)-Exploring Atmospheric Science by Foundation Models: A Case Study**|Lujia Zhang et.al.|[2407.17842v1](http://arxiv.org/abs/2407.17842v1)|null|
|**2024-07-25**|**Long-term Fairness in Ride-Hailing Platform**|Yufan Kang et.al.|[2407.17839v1](http://arxiv.org/abs/2407.17839v1)|null|
|**2024-07-25**|**UMono: Physical Model Informed Hybrid CNN-Transformer Framework for Underwater Monocular Depth Estimation**|Jian Wang et.al.|[2407.17838v1](http://arxiv.org/abs/2407.17838v1)|null|
|**2024-07-25**|**Unified Lexical Representation for Interpretable Visual-Language Alignment**|Yifan Li et.al.|[2407.17827v1](http://arxiv.org/abs/2407.17827v1)|null|
|**2024-07-25**|**Demystifying Verbatim Memorization in Large Language Models**|Jing Huang et.al.|[2407.17817v1](http://arxiv.org/abs/2407.17817v1)|null|
|**2024-07-25**|**NC-NCD: Novel Class Discovery for Node Classification**|Yue Hou et.al.|[2407.17816v1](http://arxiv.org/abs/2407.17816v1)|null|
|**2024-07-25**|**Enhancing Model Performance: Another Approach to Vision-Language Instruction Tuning**|Vedanshu et.al.|[2407.17813v1](http://arxiv.org/abs/2407.17813v1)|null|
|**2024-07-25**|**EEG-SSM: Leveraging State-Space Model for Dementia Detection**|Xuan-The Tran et.al.|[2407.17801v1](http://arxiv.org/abs/2407.17801v1)|null|
|**2024-07-25**|**A Unified Understanding of Adversarial Vulnerability Regarding Unimodal Models and Vision-Language Pre-training Models**|Haonan Zheng et.al.|[2407.17797v1](http://arxiv.org/abs/2407.17797v1)|null|
|**2024-07-25**|**Investigating learning-independent abstract reasoning in artificial neural networks**|Tomer Barak et.al.|[2407.17791v1](http://arxiv.org/abs/2407.17791v1)|null|
|**2024-07-25**|**Very Large-Scale Multi-Agent Simulation in AgentScope**|Xuchen Pan et.al.|[2407.17789v1](http://arxiv.org/abs/2407.17789v1)|[link](https://github.com/modelscope/agentscope)|
|**2024-07-25**|**Advancing Multi-Modal Sensing Through Expandable Modality Alignment**|Shenghong Dai et.al.|[2407.17777v1](http://arxiv.org/abs/2407.17777v1)|null|
|**2024-07-25**|**KiVA: Kid-inspired Visual Analogies for Testing Large Multimodal Models**|Eunice Yiu et.al.|[2407.17773v1](http://arxiv.org/abs/2407.17773v1)|[link](https://github.com/ey242/kiva)|
|**2024-07-25**|**Banyan: Improved Representation Learning with Explicit Structure**|Mattia Opper et.al.|[2407.17771v1](http://arxiv.org/abs/2407.17771v1)|null|
|**2024-07-25**|**BotEval: Facilitating Interactive Human Evaluation**|Hyundong Cho et.al.|[2407.17770v1](http://arxiv.org/abs/2407.17770v1)|null|
|**2024-07-25**|**Mpox Detection Advanced: Rapid Epidemic Response Through Synthetic Data**|Yudara Kularathne et.al.|[2407.17762v1](http://arxiv.org/abs/2407.17762v1)|null|
|**2024-07-25**|**TwIPS: A Large Language Model Powered Texting Application to Simplify Conversational Nuances for Autistic Users**|Rukhshan Haroon et.al.|[2407.17760v1](http://arxiv.org/abs/2407.17760v1)|null|
|**2024-07-25**|**Beyond Entity Alignment: Towards Complete Knowledge Graph Alignment via Entity-Relation Synergy**|Xiaohan Fang et.al.|[2407.17745v1](http://arxiv.org/abs/2407.17745v1)|null|
|**2024-07-25**|**Cost-effective Instruction Learning for Pathology Vision and Language Analysis**|Kaitao Chen et.al.|[2407.17734v1](http://arxiv.org/abs/2407.17734v1)|[link](https://github.com/jlinekai/clover)|
|**2024-07-25**|**Are Large Language Models Possible to Conduct Cognitive Behavioral Therapy?**|Hao Shen et.al.|[2407.17730v1](http://arxiv.org/abs/2407.17730v1)|null|
|**2024-07-25**|**Describe Where You Are: Improving Noise-Robustness for Speech Emotion Recognition with Text Description of the Environment**|Seong-Gyun Leem et.al.|[2407.17716v1](http://arxiv.org/abs/2407.17716v1)|null|
|**2024-07-25**|**Enhancing Agent Learning through World Dynamics Modeling**|Zhiyuan Sun et.al.|[2407.17695v1](http://arxiv.org/abs/2407.17695v1)|null|
|**2024-07-25**|**Examining the Influence of Political Bias on Large Language Model Performance in Stance Classification**|Lynnette Hui Xian Ng et.al.|[2407.17688v1](http://arxiv.org/abs/2407.17688v1)|null|
|**2024-07-25**|**Transformers on Markov Data: Constant Depth Suffices**|Nived Rajaraman et.al.|[2407.17686v1](http://arxiv.org/abs/2407.17686v1)|null|
|**2024-07-25**|**Efficient LLM Training and Serving with Heterogeneous Context Sharding among Attention Heads**|Xihui Lin et.al.|[2407.17678v1](http://arxiv.org/abs/2407.17678v1)|null|
|**2024-07-24**|**CRASAR-U-DROIDs: A Large Scale Benchmark Dataset for Building Alignment and Damage Assessment in Georectified sUAS Imagery**|Thomas Manzini et.al.|[2407.17673v1](http://arxiv.org/abs/2407.17673v1)|null|
|**2024-07-24**|**Spiking Neural Networks in Vertical Federated Learning: Performance Trade-offs**|Maryam Abbasihafshejani et.al.|[2407.17672v1](http://arxiv.org/abs/2407.17672v1)|null|
|**2024-07-24**|**SMA-Hyper: Spatiotemporal Multi-View Fusion Hypergraph Learning for Traffic Accident Prediction**|Xiaowei Gao et.al.|[2407.17642v1](http://arxiv.org/abs/2407.17642v1)|null|
|**2024-07-24**|**Time Matters: Examine Temporal Effects on Biomedical Language Models**|Weisi Liu et.al.|[2407.17638v1](http://arxiv.org/abs/2407.17638v1)|null|
|**2024-07-24**|**IgnitionInnovators at "Discharge Me!": Chain-of-Thought Instruction Finetuning Large Language Models for Discharge Summaries**|An Quang Tang et.al.|[2407.17636v1](http://arxiv.org/abs/2407.17636v1)|[link](https://github.com/antangrocket1312/discharge_llm)|
|**2024-07-24**|**Traditional Methods Outperform Generative LLMs at Forecasting Credit Ratings**|Felix Drinkall et.al.|[2407.17624v1](http://arxiv.org/abs/2407.17624v1)|null|
|**2024-07-24**|**CoMoTo: Unpaired Cross-Modal Lesion Distillation Improves Breast Lesion Detection in Tomosynthesis**|Muhammad Alberb et.al.|[2407.17620v1](http://arxiv.org/abs/2407.17620v1)|[link](https://github.com/muhammad-al-barbary/comoto)|
|**2024-07-24**|**Coupling Speech Encoders with Downstream Text Models**|Ciprian Chelba et.al.|[2407.17605v1](http://arxiv.org/abs/2407.17605v1)|null|
|**2024-07-24**|**I Could've Asked That: Reformulating Unanswerable Questions**|Wenting Zhao et.al.|[2407.17469v1](http://arxiv.org/abs/2407.17469v1)|[link](https://github.com/wenting-zhao/couldask)|
|**2024-07-24**|**WildHallucinations: Evaluating Long-form Factuality in LLMs with Real-World Entity Queries**|Wenting Zhao et.al.|[2407.17468v1](http://arxiv.org/abs/2407.17468v1)|null|
|**2024-07-24**|**CMR Scaling Law: Predicting Critical Mixture Ratios for Continual Pre-training of Language Models**|Jiawei Gu et.al.|[2407.17467v1](http://arxiv.org/abs/2407.17467v1)|null|
|**2024-07-24**|**Why Machines Can't Be Moral: Turing's Halting Problem and the Moral Limits of Artificial Intelligence**|Massimo Passamonti et.al.|[2407.16890v1](http://arxiv.org/abs/2407.16890v1)|null|
|**2024-07-24**|**Exploring Domain Robust Lightweight Reward Models based on Router Mechanism**|Hyuk Namgoong et.al.|[2407.17546v1](http://arxiv.org/abs/2407.17546v1)|null|
|**2024-07-24**|**Fluent Student-Teacher Redteaming**|T. Ben Thompson et.al.|[2407.17447v1](http://arxiv.org/abs/2407.17447v1)|[link](https://github.com/Confirm-Solutions/flrt)|
|**2024-07-24**|**HumanVid: Demystifying Training Data for Camera-controllable Human Image Animation**|Zhenzhi Wang et.al.|[2407.17438v1](http://arxiv.org/abs/2407.17438v1)|[link](https://github.com/zhenzhiwang/humanvid)|
|**2024-07-24**|**(PASS) Visual Prompt Locates Good Structure Sparsity through a Recurrent HyperNetwork**|Tianjin Huang et.al.|[2407.17412v1](http://arxiv.org/abs/2407.17412v1)|null|
|**2024-07-24**|**Dependency Transformer Grammars: Integrating Dependency Structures into Transformer Language Models**|Yida Zhao et.al.|[2407.17406v1](http://arxiv.org/abs/2407.17406v1)|[link](https://github.com/zhaoyd1/dep_transformer_grammars)|
|**2024-07-24**|**Grammar-based Game Description Generation using Large Language Models**|Tsunehiko Tanaka et.al.|[2407.17404v1](http://arxiv.org/abs/2407.17404v1)|null|
|**2024-07-24**|**Large Language Models for Anomaly Detection in Computational Workflows: from Supervised Fine-Tuning to In-Context Learning**|Hongwei Jin et.al.|[2407.17545v1](http://arxiv.org/abs/2407.17545v1)|[link](https://github.com/poseidon-workflows/llm_ad)|
|**2024-07-24**|**Systematic Reasoning About Relational Domains With Graph Neural Networks**|Irtaza Khalid et.al.|[2407.17396v1](http://arxiv.org/abs/2407.17396v1)|[link](https://github.com/erg0dic/gnn-sg)|
|**2024-07-24**|**CovScore: Evaluation of Multi-Document Abstractive Title Set Generation**|Itamar Trainin et.al.|[2407.17390v1](http://arxiv.org/abs/2407.17390v1)|null|
|**2024-07-24**|**PERSONA: A Reproducible Testbed for Pluralistic Alignment**|Louis Castricato et.al.|[2407.17387v1](http://arxiv.org/abs/2407.17387v1)|null|
|**2024-07-24**|**A Comprehensive Approach to Misspelling Correction with BERT and Levenshtein Distance**|Amirreza Naziri et.al.|[2407.17383v1](http://arxiv.org/abs/2407.17383v1)|null|
|**2024-07-24**|**MMRA: A Benchmark for Multi-granularity Multi-image Relational Association**|Siwei Wu et.al.|[2407.17379v1](http://arxiv.org/abs/2407.17379v1)|null|
|**2024-07-24**|**MathViz-E: A Case-study in Domain-Specialized Tool-Using Agents**|Arya Bulusu et.al.|[2407.17544v1](http://arxiv.org/abs/2407.17544v1)|null|
|**2024-07-24**|**Dataset Distribution Impacts Model Fairness: Single vs. Multi-Task Learning**|Ralf Raumanns et.al.|[2407.17543v1](http://arxiv.org/abs/2407.17543v1)|null|
|**2024-07-24**|**Boosting Large Language Models with Socratic Method for Conversational Mathematics Teaching**|Yuyang Ding et.al.|[2407.17349v1](http://arxiv.org/abs/2407.17349v1)|null|

#### Abstracts
##### **Self-Training with Direct Preference Optimization Improves Chain-of-Thought Reasoning**
2407.18248v1 by Tianduo Wang, Shichen Li, Wei Lu

Effective training of language models (LMs) for mathematical reasoning tasks
demands high-quality supervised fine-tuning data. Besides obtaining annotations
from human experts, a common alternative is sampling from larger and more
powerful LMs. However, this knowledge distillation approach can be costly and
unstable, particularly when relying on closed-source, proprietary LMs like
GPT-4, whose behaviors are often unpredictable. In this work, we demonstrate
that the reasoning abilities of small-scale LMs can be enhanced through
self-training, a process where models learn from their own outputs. We also
show that the conventional self-training can be further augmented by a
preference learning algorithm called Direct Preference Optimization (DPO). By
integrating DPO into self-training, we leverage preference data to guide LMs
towards more accurate and diverse chain-of-thought reasoning. We evaluate our
method across various mathematical reasoning tasks using different base models.
Our experiments show that this approach not only improves LMs' reasoning
performance but also offers a more cost-effective and scalable solution
compared to relying on large proprietary LMs.

æè¦ï¼è¦ææè¨ç·´æ¸å­¸æ¨çä»»åçèªè¨æ¨¡å (LM)ï¼éè¦é«åè³ªçç£ç£å¾®èª¿è³æãé¤äºå¾äººé¡å°å®¶åå¾è¨»è§£ä¹å¤ï¼ä¸åå¸¸è¦çæ¿ä»£æ¹æ¡æ¯å¾æ´å¤§ãæ´å¼·å¤§ç LM ä¸­åæ¨£ãç¶èï¼éç¨®ç¥è­è¸é¤¾æ¹æ³ä»£å¹é«æä¸ä¸ç©©å®ï¼ç¹å¥æ¯ç¶ä¾è³´æ¼å°éåå§ç¢¼çå°æ LMï¼ä¾å¦ GPT-4ï¼æï¼å¶è¡çºéå¸¸é£ä»¥é æ¸¬ãå¨éé å·¥ä½ä¸­ï¼æåè­æäºå°è¦æ¨¡ LM çæ¨çè½åå¯ä»¥ééèªè¨ç·´ä¾å¢å¼·ï¼éæ¯ä¸åæ¨¡åå¾èªå·±çè¼¸åºä¸­å­¸ç¿çéç¨ãæåä¹å±ç¤ºäºå³çµ±çèªè¨ç·´å¯ä»¥é²ä¸æ­¥ééä¸ç¨®ç¨±çºç´æ¥åå¥½æä½³å (DPO) çåå¥½å­¸ç¿æ¼ç®æ³ä¾æ´åãééå° DPO æ´åå°èªè¨ç·´ä¸­ï¼æåå©ç¨åå¥½è³æå¼å° LM æåæ´æºç¢ºãæ´å¤æ¨£åçæèéæ¨çãæåä½¿ç¨ä¸åçåºç¤æ¨¡åï¼å¨åç¨®æ¸å­¸æ¨çä»»åä¸­è©ä¼°æåçæ¨¡åãæåçå¯¦é©é¡¯ç¤ºï¼éç¨®æ¹æ³ä¸åæ¹åäº LM çæ¨çæè½ï¼èä¸èä¾è³´å¤§åå°æ LM ç¸æ¯ï¼éæä¾äºä¸åæ´å·ææ¬æçä¸å¯æ´åçè§£æ±ºæ¹æ¡ã

##### **LoRA-Pro: Are Low-Rank Adapters Properly Optimized?**
2407.18242v1 by Zhengbo Wang, Jian Liang

Low-Rank Adaptation, also known as LoRA, has emerged as a prominent method
for parameter-efficient fine-tuning foundation models by re-parameterizing the
original matrix into the product of two low-rank matrices. Despite its
efficiency, LoRA often yields inferior performance compared to full
fine-tuning. In this paper, we propose LoRA-Pro to bridge this performance gap.
Firstly, we delve into the optimization processes in LoRA and full fine-tuning.
We reveal that while LoRA employs low-rank approximation, it neglects to
approximate the optimization process of full fine-tuning. To address this, we
introduce a novel concept called the "equivalent gradient." This virtual
gradient makes the optimization process on the re-parameterized matrix
equivalent to LoRA, which can be used to quantify the differences between LoRA
and full fine-tuning. The equivalent gradient is derived from the gradients of
matrices $A$ and $B$. To narrow the performance gap, our approach minimizes the
differences between the equivalent gradient and the gradient obtained from full
fine-tuning during the optimization process. By solving this objective, we
derive optimal closed-form solutions for updating matrices $A$ and $B$. Our
method constrains the optimization process, shrinking the performance gap
between LoRA and full fine-tuning. Extensive experiments on natural language
processing tasks validate the effectiveness of our method.

æè¦ï¼ä½ç§©é©æï¼LoRAï¼å·²æçºä¸ç¨®éè¦çæ¹æ³ï¼å¯ééå°åå§ç©é£éæ°åæ¸åçºå©åä½ç§©ç©é£çä¹ç©ï¼å°åæ¸ææççå¾®èª¿åºç¤æ¨¡åãåç®¡ LoRA å·ææçï¼ä½èå®æ´å¾®èª¿ç¸æ¯ï¼å¶æè½éå¸¸è¼å·®ãå¨æ¬æä¸­ï¼æåæåº LoRA-Pro ä¾å½åæ­¤æè½å·®è·ãé¦åï¼æåæ·±å¥æ¢è¨ LoRA åå®æ´å¾®èª¿ä¸­çæä½³åç¨åºãæåæ­ç¤ºï¼åç®¡ LoRA æ¡ç¨ä½ç§©è¿ä¼¼ï¼ä½å®å¿½ç¥äºå®æ´å¾®èª¿çæä½³åç¨åºãçºäºè§£æ±ºéååé¡ï¼æåå¼å¥äºä¸ååçºãç­ææ¢¯åº¦ãçæ°æ¦å¿µãéåèæ¬æ¢¯åº¦ä½¿éæ°åæ¸åç©é£ä¸çæä½³åç¨åºç­åæ¼ LoRAï¼å¯ç¨æ¥éå LoRA åå®æ´å¾®èª¿ä¹éçå·®ç°ãç­ææ¢¯åº¦ä¾èªç©é£ A å B çæ¢¯åº¦ãçºäºç¸®å°æè½å·®è·ï¼æåçåæ³æ¯å¨æä½³åç¨åºä¸­æå°åç­ææ¢¯åº¦åå¾å®æ´å¾®èª¿ä¸­ç²å¾çæ¢¯åº¦ä¹éçå·®ç°ãééè§£æ±ºéåç®æ¨ï¼æåæ¨å°åºæ´æ°ç©é£ A å B çæä½³éå¼è§£ãæåçåæ³ç´æäºæä½³åç¨åºï¼ç¸®å°äº LoRA åå®æ´å¾®èª¿ä¹éçæè½å·®è·ãèªç¶èªè¨èçä»»åä¸çå¤§éå¯¦é©é©è­äºæåæ¹æ³çæææ§ã

##### **Recursive Introspection: Teaching Language Model Agents How to Self-Improve**
2407.18219v1 by Yuxiao Qu, Tianjun Zhang, Naman Garg, Aviral Kumar

A central piece in enabling intelligent agentic behavior in foundation models
is to make them capable of introspecting upon their behavior, reasoning, and
correcting their mistakes as more computation or interaction is available. Even
the strongest proprietary large language models (LLMs) do not quite exhibit the
ability of continually improving their responses sequentially, even in
scenarios where they are explicitly told that they are making a mistake. In
this paper, we develop RISE: Recursive IntroSpEction, an approach for
fine-tuning LLMs to introduce this capability, despite prior work hypothesizing
that this capability may not be possible to attain. Our approach prescribes an
iterative fine-tuning procedure, which attempts to teach the model how to alter
its response after having executed previously unsuccessful attempts to solve a
hard test-time problem, with optionally additional environment feedback. RISE
poses fine-tuning for a single-turn prompt as solving a multi-turn Markov
decision process (MDP), where the initial state is the prompt. Inspired by
principles in online imitation learning and reinforcement learning, we propose
strategies for multi-turn data collection and training so as to imbue an LLM
with the capability to recursively detect and correct its previous mistakes in
subsequent iterations. Our experiments show that RISE enables Llama2, Llama3,
and Mistral models to improve themselves with more turns on math reasoning
tasks, outperforming several single-turn strategies given an equal amount of
inference-time computation. We also find that RISE scales well, often attaining
larger benefits with more capable models. Our analysis shows that RISE makes
meaningful improvements to responses to arrive at the correct solution for
challenging prompts, without disrupting one-turn abilities as a result of
expressing more complex distributions.

æè¦ï¼<paragraph>å¨åºç¤æ¨¡åä¸­åç¨æºæ§ä»£çè¡çºçæ ¸å¿é¨åæ¯è®å®åè½å¤ å§çèªå·±çè¡çºãæ¨çï¼ä¸¦å¨ææ´å¤éç®æäºåææ´æ­£èªå·±çé¯èª¤ãå³ä½¿æ¯æå¼·å¤§çå°æå¤§åèªè¨æ¨¡å (LLM) ä¹ç¡æ³å®å¨å±ç¾é£çºå¾ªåºæ¼¸é²å°æ¹åå¶åæçè½åï¼å³ä½¿å¨æç¢ºåç¥å®åç¯é¯çææ³ä¸ä¹æ¯å¦æ­¤ãå¨æ¬æä¸­ï¼æåéç¼äº RISEï¼éè¿´å§çï¼ä¸ç¨®å¾®èª¿ LLM çæ¹æ³ä¾å¼å¥éç¨®è½åï¼åç®¡ååçç ç©¶åè¨­ç¡æ³ç²å¾éç¨®è½åãæåçåæ³è¦å®äºä¸ç¨®åè¦å¾®èª¿ç¨åºï¼è©²ç¨åºåè©¦æå°æ¨¡åå¦ä½å¨å·è¡ååä¸æåçåè©¦ä¾è§£æ±ºå°é£çæ¸¬è©¦æéåé¡å¾æ¹è®å¶åæï¼ä¸¦å¯é¸æé¡å¤æä¾ç°å¢åé¥ãRISE å°å®è¼ªæç¤ºçå¾®èª¿è¦çºè§£æ±ºå¤è¼ªé¦¬å¯å¤«æ±ºç­éç¨ (MDP) çåé¡ï¼å¶ä¸­åå§çææ¯æç¤ºãåå°å¨ç·æ¨¡ä»¿å­¸ç¿åå¼·åå­¸ç¿ååçåç¼ï¼æåæåºäºå¤è¼ªæ¸ææ¶éåè¨ç·´ç­ç¥ï¼ä»¥è³¦äº LLM å¨å¾çºè¿­ä»£ä¸­éè¿´æª¢æ¸¬åç³¾æ­£å¶ååé¯èª¤çè½åãæåçå¯¦é©è¡¨æï¼RISE è½è® Llama2ãLlama3 å Mistral æ¨¡åå¨æ¸å­¸æ¨çä»»åä¸­é¨èæ´å¤è¼ªæ¬¡èèªææåï¼å¨çµ¦å®ç¸åæ¨çæééç®çææ³ä¸ï¼è¡¨ç¾åªæ¼å¤ç¨®å®è¼ªç­ç¥ãæåéç¼ç¾ RISE å·æè¯å¥½çæ´å±æ§ï¼éå¸¸è½é¨èæ¨¡ååè½æ´å¼·å¤§èç²å¾æ´å¤§çå¥½èãæåçåæè¡¨æï¼RISE å°åæé²è¡äºææç¾©çæ¹é²ï¼ä»¥éå°å·æææ°æ§çæç¤ºå¾åºæ­£ç¢ºçè§£æ±ºæ¹æ¡ï¼èä¸æå çºè¡¨éæ´è¤éçåå¸èç ´å£å®è¼ªè½åã</paragraph>

##### **Exploring Scaling Trends in LLM Robustness**
2407.18213v1 by Nikolhaus Howe, MichaÅ Zajac, Ian McKenzie, Oskar Hollinsworth, Tom Tseng, Pierre-Luc Bacon, Adam Gleave

Language model capabilities predictably improve from scaling a model's size
and training data. Motivated by this, increasingly large language models have
been trained, yielding an array of impressive capabilities. Yet these models
are vulnerable to adversarial prompts, such as "jailbreaks" that hijack models
to perform undesired behaviors, posing a significant risk of misuse. Prior work
indicates that computer vision models become more robust with model and data
scaling, raising the question: does language model robustness also improve with
scale? We study this question empirically, finding that larger models respond
substantially better to adversarial training, but there is little to no benefit
from model scale in the absence of explicit defenses.

æè¦ï¼èªè¨æ¨¡åè½åå¯é æ¸¬å°å¾æ´å±æ¨¡åå¤§å°åè¨ç·´è³æä¸­ç²å¾æåãåæ­¤æ¿åµï¼è¶ä¾è¶å¤§çèªè¨æ¨¡åå·²ç¶éè¨ç·´ï¼ç¢çäºä¸ç³»åä»¤äººå°è±¡æ·±å»çè½åãç¶èï¼éäºæ¨¡åå®¹æåå°å°ææ§æç¤ºçå½±é¿ï¼ä¾å¦å«ææ¨¡åä»¥å·è¡ä¸éè¦çè¡çºçãè¶çãï¼é æéå¤§èª¤ç¨é¢¨éªãååçç ç©¶è¡¨æï¼é»è¦è¦è¦ºæ¨¡åæé¨èæ¨¡ååè³æçæ´å±èè®å¾æ´å¼·å¤§ï¼éå¼ç¼äºä¸ååé¡ï¼èªè¨æ¨¡åçå¼·å¥æ§æ¯å¦ä¹é¨èè¦æ¨¡çæ´å±èæåï¼æåå°æ­¤åé¡é²è¡å¯¦è­ç ç©¶ï¼ç¼ç¾è¼å¤§çæ¨¡åå°å°ææ§è¨ç·´çåæå¤§å¹æ¹åï¼ä½å¨æ²ææç¢ºé²ç¦¦æªæ½çææ³ä¸ï¼æ¨¡åè¦æ¨¡å¹¾ä¹æ²æå¥½èã

##### **Differentiable Quantum Architecture Search in Asynchronous Quantum Reinforcement Learning**
2407.18202v1 by Samuel Yen-Chi Chen

The emergence of quantum reinforcement learning (QRL) is propelled by
advancements in quantum computing (QC) and machine learning (ML), particularly
through quantum neural networks (QNN) built on variational quantum circuits
(VQC). These advancements have proven successful in addressing sequential
decision-making tasks. However, constructing effective QRL models demands
significant expertise due to challenges in designing quantum circuit
architectures, including data encoding and parameterized circuits, which
profoundly influence model performance. In this paper, we propose addressing
this challenge with differentiable quantum architecture search (DiffQAS),
enabling trainable circuit parameters and structure weights using
gradient-based optimization. Furthermore, we enhance training efficiency
through asynchronous reinforcement learning (RL) methods facilitating parallel
training. Through numerical simulations, we demonstrate that our proposed
DiffQAS-QRL approach achieves performance comparable to manually-crafted
circuit architectures across considered environments, showcasing stability
across diverse scenarios. This methodology offers a pathway for designing QRL
models without extensive quantum knowledge, ensuring robust performance and
fostering broader application of QRL.

æè¦ï¼éå­å¼·åå­¸ç¿ (QRL) çåºç¾æ¯ç±éå­éç® (QC) åæ©å¨å­¸ç¿ (ML) çé²æ­¥æ¨åï¼ç¹å¥æ¯å»ºç«å¨è®åéå­é»è·¯ (VQC) ä¸çéå­ç¥ç¶ç¶²è·¯ (QNN)ãéäºé²æ­¥å·²è¢«è­æå¨è§£æ±ºåºè²«æ±ºç­ä»»åæ¹é¢æ¯æåçãç¶èï¼æ§å»ºææç QRL æ¨¡åéè¦å¤§éçå°æ¥­ç¥è­ï¼å çºå¨è¨­è¨éå­é»è·¯æ¶æ§ææéå°ææ°ï¼åæ¬æ¸æç·¨ç¢¼ååæ¸åé»è·¯ï¼éææ·±å»å½±é¿æ¨¡åæ§è½ãå¨æ¬æä¸­ï¼æåæåºä½¿ç¨å¯å¾®åéå­æ¶æ§æå° (DiffQAS) ä¾è§£æ±ºéåææ°ï¼ä½¿ç¨åºæ¼æ¢¯åº¦çæä½³åä¾åç¨å¯è¨ç·´çé»è·¯åæ¸åçµæ§æ¬éãæ­¤å¤ï¼æåéééåæ­¥å¼·åå­¸ç¿ (RL) æ¹æ³ä¾å¢å¼·è¨ç·´æçï¼ä¿é²ä¸¦è¡è¨ç·´ãééæ¸å¼æ¨¡æ¬ï¼æåè­ææåæåºç DiffQAS-QRL æ¹æ³éå°äºèäººå·¥è£½ä½çé»è·¯æ¶æ§ç¸ç¶çæ§è½ï¼å¨åç¨®ç°å¢ä¸­å±ç¾äºç©©å®æ§ãéç¨®æ¹æ³æä¾äºä¸åå¨æ²æå»£æ³éå­ç¥è­çææ³ä¸è¨­è¨ QRL æ¨¡åçéå¾ï¼ç¢ºä¿äºç©©å¥çæ§è½ï¼ä¸¦ä¿é²äº QRL çæ´å»£æ³æç¨ã

##### **Gene Regulatory Network Inference from Pre-trained Single-Cell Transcriptomics Transformer with Joint Graph Learning**
2407.18181v1 by Sindhura Kommu, Yizhi Wang, Yue Wang, Xuan Wang

Inferring gene regulatory networks (GRNs) from single-cell RNA sequencing
(scRNA-seq) data is a complex challenge that requires capturing the intricate
relationships between genes and their regulatory interactions. In this study,
we tackle this challenge by leveraging the single-cell BERT-based pre-trained
transformer model (scBERT), trained on extensive unlabeled scRNA-seq data, to
augment structured biological knowledge from existing GRNs. We introduce a
novel joint graph learning approach that combines the rich contextual
representations learned by pre-trained single-cell language models with the
structured knowledge encoded in GRNs using graph neural networks (GNNs). By
integrating these two modalities, our approach effectively reasons over boththe
gene expression level constraints provided by the scRNA-seq data and the
structured biological knowledge inherent in GRNs. We evaluate our method on
human cell benchmark datasets from the BEELINE study with cell type-specific
ground truth networks. The results demonstrate superior performance over
current state-of-the-art baselines, offering a deeper understanding of cellular
regulatory mechanisms.

æè¦ï¼å¾å®ç´°è RNA å®åº (scRNA-seq) è³ææ¨è«åºå èª¿æ§ç¶²è·¯ (GRN) æ¯ä¸é è¤éçææ°ï¼éè¦ææ¡åºå èå¶èª¿æ§äº¤äºä½ç¨ä¹éçè¤ééä¿ãå¨æ­¤ç ç©¶ä¸­ï¼æåééå©ç¨å¨å»£æ³çæªæ¨è¨ scRNA-seq è³æä¸è¨ç·´çå®ç´°è BERT åºæ¼é è¨ç·´è½æå¨æ¨¡å (scBERT)ï¼ä¾åææ­¤ææ°ï¼ä»¥æ´åç¾æ GRN ä¸­ççµæ§åçç©ç¥è­ãæåå¼å¥ä¸ç¨®æ°ç©çè¯ååå½¢å­¸ç¿æ¹æ³ï¼å®çµåäºé è¨ç·´å®ç´°èèªè¨æ¨¡åæå­¸ç¿å°çè±å¯èçµ¡è¡¨å¾µï¼ä»¥åä½¿ç¨åå½¢ç¥ç¶ç¶²è·¯ (GNN) å° GRN ä¸­ç·¨ç¢¼ççµæ§åç¥è­ãééæ´åéå©ç¨®æ¹å¼ï¼æåçåæ³ææå°å° scRNA-seq è³ææä¾çåºå è¡¨ç¾å±¤ç´ç´æå GRN ä¸­åºæççµæ§åçç©ç¥è­é²è¡æ¨çãæåä½¿ç¨ BEELINE ç ç©¶ä¸­çäººé¡ç´°èåºæºè³æéï¼ä»¥åç´°èé¡åç¹å®çåºæ¬äºå¯¦ç¶²è·¯ï¼ä¾è©ä¼°æåçæ¹æ³ãçµæè­æå¶æè½åªæ¼ç®åæåé²çåºæºï¼æä¾äºå°ç´°èèª¿æ§æ©å¶çæ´æ·±å¥çè§£ã

##### **Quasar-ViT: Hardware-Oriented Quantization-Aware Architecture Search for Vision Transformers**
2407.18175v1 by Zhengang Li, Alec Lu, Yanyue Xie, Zhenglun Kong, Mengshu Sun, Hao Tang, Zhong Jia Xue, Peiyan Dong, Caiwen Ding, Yanzhi Wang, Xue Lin, Zhenman Fang

Vision transformers (ViTs) have demonstrated their superior accuracy for
computer vision tasks compared to convolutional neural networks (CNNs).
However, ViT models are often computation-intensive for efficient deployment on
resource-limited edge devices. This work proposes Quasar-ViT, a
hardware-oriented quantization-aware architecture search framework for ViTs, to
design efficient ViT models for hardware implementation while preserving the
accuracy. First, Quasar-ViT trains a supernet using our row-wise flexible
mixed-precision quantization scheme, mixed-precision weight entanglement, and
supernet layer scaling techniques. Then, it applies an efficient
hardware-oriented search algorithm, integrated with hardware latency and
resource modeling, to determine a series of optimal subnets from supernet under
different inference latency targets. Finally, we propose a series of
model-adaptive designs on the FPGA platform to support the architecture search
and mitigate the gap between the theoretical computation reduction and the
practical inference speedup. Our searched models achieve 101.5, 159.6, and
251.6 frames-per-second (FPS) inference speed on the AMD/Xilinx ZCU102 FPGA
with 80.4%, 78.6%, and 74.9% top-1 accuracy, respectively, for the ImageNet
dataset, consistently outperforming prior works.

æè¦ï¼<paragraph>èå·ç©ç¥ç¶ç¶²è·¯ï¼CNNï¼ç¸æ¯ï¼è¦è¦ºè½æå¨ï¼ViTï¼å·²è­æå¶å¨é»è¦è¦è¦ºä»»åä¸çåªç°æºç¢ºåº¦ãç¶èï¼ViT æ¨¡åéå¸¸å¨è¨ç®ä¸å¾å¯éï¼ç¡æ³å¨è³æºæéçéç·£è£ç½®ä¸ææçå°é¨ç½²ãéé å·¥ä½æåºäº Quasar-ViTï¼ä¸åé¢åç¡¬é«çéåæç¥æ¶æ§æå°æ¡æ¶ï¼ç¨æ¼ ViTï¼ä»¥è¨­è¨é«æç ViT æ¨¡åé²è¡ç¡¬é«å¯¦ä½ï¼åæä¿ææºç¢ºåº¦ãé¦åï¼Quasar-ViT ä½¿ç¨æååå¼å½æ§æ··åç²¾åº¦éåæ¹æ¡ãæ··åç²¾åº¦æ¬éç³¾çºåè¶ç¶²è·¯å±¤ç¸®æ¾æè¡ä¾è¨ç·´è¶ç¶²è·¯ãç¶å¾ï¼å®æç¨ä¸åææççé¢åç¡¬é«çæå°æ¼ç®æ³ï¼æ´åç¡¬é«å»¶é²åè³æºå»ºæ¨¡ï¼ä»¥å¨ä¸åçæ¨è«å»¶é²ç®æ¨ä¸å¾è¶ç¶²è·¯ä¸­ç¢ºå®ä¸ç³»åæä½³å­ç¶²è·¯ãæå¾ï¼æåå¨ FPGA å¹³èºä¸æåºäºä¸ç³»åæ¨¡åèªé©æè¨­è¨ï¼ä»¥æ¯æ´æ¶æ§æå°ä¸¦ç¸®å°çè«éç®æ¸å°åå¯¦éæ¨è«å éä¹éçå·®è·ãæåæå°çæ¨¡åå¨ AMD/Xilinx ZCU102 FPGA ä¸åå¥ä»¥ 80.4%ã78.6% å 74.9% ç top-1 æºç¢ºåº¦ï¼éå° 101.5ã159.6 å 251.6 å¹æ¯ç§ (FPS) çæ¨è«éåº¦ï¼ç¨æ¼ ImageNet è³æéï¼å§çµåªæ¼ååçç ç©¶ã</paragraph>

##### **The FIGNEWS Shared Task on News Media Narratives**
2407.18147v1 by Wajdi Zaghouani, Mustafa Jarrar, Nizar Habash, Houda Bouamor, Imed Zitouni, Mona Diab, Samhaa R. El-Beltagy, Muhammed AbuOdeh

We present an overview of the FIGNEWS shared task, organized as part of the
ArabicNLP 2024 conference co-located with ACL 2024. The shared task addresses
bias and propaganda annotation in multilingual news posts. We focus on the
early days of the Israel War on Gaza as a case study. The task aims to foster
collaboration in developing annotation guidelines for subjective tasks by
creating frameworks for analyzing diverse narratives highlighting potential
bias and propaganda. In a spirit of fostering and encouraging diversity, we
address the problem from a multilingual perspective, namely within five
languages: English, French, Arabic, Hebrew, and Hindi. A total of 17 teams
participated in two annotation subtasks: bias (16 teams) and propaganda (6
teams). The teams competed in four evaluation tracks: guidelines development,
annotation quality, annotation quantity, and consistency. Collectively, the
teams produced 129,800 data points. Key findings and implications for the field
are discussed.

æè¦ï¼<paragraph>æåæ¦è¿°äº FIGNEWS å±äº«ä»»åï¼è©²ä»»åä½çº ArabicNLP 2024 æè­°çä¸é¨åï¼è ACL 2024 å±åèè¾¦ãå±äº«ä»»åèçå¤èªè¨æ°èæç« ä¸­çåè¦åå®£å³æ¨è¨»ãæåå°æ³¨æ¼ä»¥è²åå°å è©æ°ç­çæ©æä½çºæ¡ä¾ç ç©¶ãè©²ä»»åæ¨å¨ééå»ºç«åæä¸åæè¿°çæ¡æ¶ä¾ä¿é²éç¼ä¸»è§ä»»åçæ¨è¨»æåï¼éé»æ¯æ½å¨çåè¦åå®£å³ãæ¬èå¹é¤åé¼åµå¤æ¨£æ§çç²¾ç¥ï¼æåå¾å¤èªè¨çè§åº¦ä¾è§£æ±ºéååé¡ï¼å³å¨äºç¨®èªè¨ä¸­ï¼è±èªãæ³èªãé¿æä¼¯èªãå¸ä¼¯ä¾èªåå°å°èªãå±æ 17 ååéåèäºå©åæ¨è¨»å­ä»»åï¼åè¦ï¼16 ååéï¼åå®£å³ï¼6 ååéï¼ãéäºåéåå äºååè©ä¼°è»éï¼æåå¶å®ãæ¨è¨»åè³ªãæ¨è¨»æ¸éåä¸è´æ§ãç¸½çä¾èªªï¼éäºåéç¢çäº 129,800 åæ¸æé»ãè¨è«äºè©²é åçééµç¼ç¾åå½±é¿ã</paragraph>

##### **Taxonomy-Aware Continual Semantic Segmentation in Hyperbolic Spaces for Open-World Perception**
2407.18145v1 by Julia Hindel, Daniele Cattaneo, Abhinav Valada

Semantic segmentation models are typically trained on a fixed set of classes,
limiting their applicability in open-world scenarios. Class-incremental
semantic segmentation aims to update models with emerging new classes while
preventing catastrophic forgetting of previously learned ones. However,
existing methods impose strict rigidity on old classes, reducing their
effectiveness in learning new incremental classes. In this work, we propose
Taxonomy-Oriented Poincar\'e-regularized Incremental-Class Segmentation
(TOPICS) that learns feature embeddings in hyperbolic space following explicit
taxonomy-tree structures. This supervision provides plasticity for old classes,
updating ancestors based on new classes while integrating new classes at
fitting positions. Additionally, we maintain implicit class relational
constraints on the geometric basis of the Poincar\'e ball. This ensures that
the latent space can continuously adapt to new constraints while maintaining a
robust structure to combat catastrophic forgetting. We also establish eight
realistic incremental learning protocols for autonomous driving scenarios,
where novel classes can originate from known classes or the background.
Extensive evaluations of TOPICS on the Cityscapes and Mapillary Vistas 2.0
benchmarks demonstrate that it achieves state-of-the-art performance. We make
the code and trained models publicly available at
http://topics.cs.uni-freiburg.de.

æè¦ï¼èªæåå²æ¨¡åéå¸¸å¨åºå®çé¡å¥éåä¸è¨ç·´ï¼
éå¶äºå®åå¨éæ¾ä¸çå ´æ¯ä¸­çé©ç¨æ§ãé¡å¥éå¢
èªæåå²æ¨å¨ä½¿ç¨æ°åºç¾çé¡å¥æ´æ°æ¨¡åï¼åæ
é²æ­¢ç½é£æ§å°éºå¿ååå­¸ç¿çé¡å¥ãç¶èï¼
ç¾ææ¹æ³å°èé¡å¥æ½å å´æ ¼çåæ§ï¼éä½äºå®å
å­¸ç¿æ°éå¢é¡å¥çæææ§ãå¨éé å·¥ä½ä¸­ï¼æåæåº
é¢ååé¡å­¸çé¾å èæ­£ååéå¢é¡å¥åå² (TOPICS)ï¼å®å¨éæ²ç©ºéä¸­å­¸ç¿ç¹å¾µåµå¥ï¼éµå¾ªæç¢ºç
åé¡æ¨¹çµæ§ãéç¨®ç£ç£çºèé¡å¥æä¾å¯å¡æ§ï¼
å¨é©ç¶çä½ç½®æ´åæ°é¡å¥çåæï¼åºæ¼æ°é¡å¥æ´æ°ç¥åãæ­¤å¤ï¼æåå¨é¾å èççå¹¾ä½åºç¤ä¸ç¶­æé±å¼é¡å¥éä¿ç´æãéç¢ºä¿äº
æ½å¨ç©ºéå¯ä»¥æçºé©ææ°ç´æï¼åæç¶­æç©©åºççµæ§ä»¥å°æç½é£æ§éºå¿ãæåéçºèªåé§é§å ´æ¯å»ºç«äºå«å
ç¾å¯¦çéå¢å­¸ç¿åå®ï¼å¶ä¸­æ°é¡å¥å¯ä»¥æºèªå·²ç¥é¡å¥æèæ¯ã
å¨ Cityscapes å Mapillary Vistas 2.0 ä¸å° TOPICS çå»£æ³è©ä¼°
åºæºè­æå®éå°äºæåé²çæè½ãæåå°
ç¨å¼ç¢¼åè¨ç·´å¥½çæ¨¡åå¬éæ¼
http://topics.cs.uni-freiburg.deã

##### **Dallah: A Dialect-Aware Multimodal Large Language Model for Arabic**
2407.18129v1 by Fakhraddin Alwajih, Gagan Bhatia, Muhammad Abdul-Mageed

Recent advancements have significantly enhanced the capabilities of
Multimodal Large Language Models (MLLMs) in generating and understanding
image-to-text content. Despite these successes, progress is predominantly
limited to English due to the scarcity of high quality multimodal resources in
other languages. This limitation impedes the development of competitive models
in languages such as Arabic. To alleviate this situation, we introduce an
efficient Arabic multimodal assistant, dubbed Dallah, that utilizes an advanced
language model based on LLaMA-2 to facilitate multimodal interactions. Dallah
demonstrates state-of-the-art performance in Arabic MLLMs. Through fine-tuning
six Arabic dialects, Dallah showcases its capability to handle complex
dialectal interactions incorporating both textual and visual elements. The
model excels in two benchmark tests: one evaluating its performance on Modern
Standard Arabic (MSA) and another specifically designed to assess dialectal
responses. Beyond its robust performance in multimodal interaction tasks,
Dallah has the potential to pave the way for further development of
dialect-aware Arabic MLLMs.

æè¦ï¼æè¿çé²å±é¡¯èæåäºå¤æ¨¡æå¤§åèªè¨æ¨¡å (MLLM) å¨ç¢çåçè§£å½±åè½æå­å§å®¹çè½åãåç®¡æéäºæåï¼é²å±ä¸»è¦åéæ¼è±èªï¼å çºå¶ä»èªè¨ç¼ºä¹é«åè³ªçå¤æ¨¡æè³æºãæ­¤éå¶é»ç¤äºå¨é¿æä¼¯èªç­èªè¨ä¸­éç¼ç«¶ç­æ¨¡åãçºäºæ¹åæ­¤ææ³ï¼æåå¼é²äºä¸æ¬¾ææççé¿æä¼¯èªå¤æ¨¡æå©çï¼ç¨±çº Dallahï¼å®å©ç¨åºæ¼ LLaMA-2 çé²éèªè¨æ¨¡åä¾ä¿é²å¤æ¨¡æäºåãDallah å¨é¿æä¼¯èª MLLM ä¸­å±ç¾äºæåé²çæè½ãééå¾®èª¿å­ç¨®é¿æä¼¯èªæ¹è¨ï¼Dallah å±ç¤ºäºå®èçè¤éæ¹è¨äºåçè½åï¼çµåäºæå­åè¦è¦ºåç´ ãæ­¤æ¨¡åå¨å©ååºæºæ¸¬è©¦ä¸­è¡¨ç¾åºè²ï¼ä¸åè©ä¼°å®å¨ç¾ä»£æ¨æºé¿æä¼¯èª (MSA) ä¸çæè½ï¼å¦ä¸åå°éè¨­è¨ä¾è©ä¼°æ¹è¨åæãé¤äºå¨å¤æ¨¡æäºåä»»åä¸­è¡¨ç¾å¼·åå¤ï¼Dallah æå¯è½çºé²ä¸æ­¥éç¼å·æ¹è¨æç¥è½åçé¿æä¼¯èª MLLM éªè·¯ã

##### **Self-supervised pre-training with diffusion model for few-shot landmark detection in x-ray images**
2407.18125v1 by Roberto Di Via, Francesca Odone, Vito Paolo Pastore

In the last few years, deep neural networks have been extensively applied in
the medical domain for different tasks, ranging from image classification and
segmentation to landmark detection. However, the application of these
technologies in the medical domain is often hindered by data scarcity, both in
terms of available annotations and images. This study introduces a new
self-supervised pre-training protocol based on diffusion models for landmark
detection in x-ray images. Our results show that the proposed self-supervised
framework can provide accurate landmark detection with a minimal number of
available annotated training images (up to 50), outperforming ImageNet
supervised pre-training and state-of-the-art self-supervised pre-trainings for
three popular x-ray benchmark datasets. To our knowledge, this is the first
exploration of diffusion models for self-supervised learning in landmark
detection, which may offer a valuable pre-training approach in few-shot
regimes, for mitigating data scarcity.

æè¦ï¼å¨éå»å¹¾å¹´ä¸­ï¼æ·±åº¦ç¥ç¶ç¶²è·¯å·²å»£æ³æç¨æ¼é«çé åçä¸åä»»åï¼å¾å½±ååé¡ååå²å°å°æ¨åµæ¸¬ãç¶èï¼éäºæè¡å¨é«çé åçæç¨å¸¸å¸¸åå°è³æç¨å°çé»ç¤ï¼ç¡è«æ¯å¨å¯ç¨çè¨»è§£æå½±åæ¹é¢ãæ¬ç ç©¶ä»ç´¹äºä¸åæ°çèªç£ç£é è¨ç·´åå®ï¼å®æ¯åºæ¼æ´æ£æ¨¡åï¼ç¨æ¼ X åå½±åä¸­çå°æ¨åµæ¸¬ãæåççµæé¡¯ç¤ºï¼ææåºçèªç£ç£æ¶æ§å¯ä»¥å¨æå°æ¸éçå¯ç¨è¨»è§£è¨ç·´å½±åï¼æå¤ 50 åï¼ä¸æä¾æºç¢ºçå°æ¨åµæ¸¬ï¼åªæ¼ ImageNet ç£ç£å¼é è¨ç·´ä»¥åä¸åç±é X ååºæºè³æéçææ°èªç£ç£å¼é è¨ç·´ãææåæç¥ï¼éæ¯é¦æ¬¡æ¢è¨æ´æ£æ¨¡åç¨æ¼å°æ¨åµæ¸¬ä¸­çèªç£ç£å¼å­¸ç¿ï¼å®å¯è½å¨å°æ¨£æ¬è¨ç·´æ¨¡å¼ä¸­æä¾æå¹å¼çé è¨ç·´æ¹æ³ï¼ä»¥æ¸è¼è³æç¨å°çåé¡ã

##### **Tracking linguistic information in transformer-based sentence embeddings through targeted sparsification**
2407.18119v1 by Vivi Nastase, Paola Merlo

Analyses of transformer-based models have shown that they encode a variety of
linguistic information from their textual input. While these analyses have shed
a light on the relation between linguistic information on one side, and
internal architecture and parameters on the other, a question remains
unanswered: how is this linguistic information reflected in sentence
embeddings? Using datasets consisting of sentences with known structure, we
test to what degree information about chunks (in particular noun, verb or
prepositional phrases), such as grammatical number, or semantic role, can be
localized in sentence embeddings. Our results show that such information is not
distributed over the entire sentence embedding, but rather it is encoded in
specific regions. Understanding how the information from an input text is
compressed into sentence embeddings helps understand current transformer models
and help build future explainable neural models.

æè¦ï¼åºæ¼Transformerçæ¨¡ååæé¡¯ç¤ºï¼å®åæå°ææ¬è¼¸å¥ç·¨ç¢¼åç¨®èªè¨è³è¨ãåç®¡éäºåæå·²é¡æä¸æ¹é¢èªè¨è³è¨èå¦ä¸æ¹é¢å§é¨æ¶æ§ååæ¸ä¹éçéä¿ï¼ä½ä»æä¸ååé¡æªç²å¾è§£ç­ï¼éç¨®èªè¨è³è¨æ¯å¦ä½åæ å¨å¥å­åµå¥ä¸­ï¼æåä½¿ç¨åå«å·²ç¥çµæ§å¥å­çè³æéï¼æ¸¬è©¦æéåå¡ï¼ç¹å¥æ¯åè©ãåè©æä»ç³»è©ç­èªï¼çè³è¨ï¼ä¾å¦ææ³æ¸æèªæè§è²ï¼å¯ä»¥å¨ä½ç¨®ç¨åº¦ä¸å®ä½å¨å¥å­åµå¥ä¸­ãæåççµæé¡¯ç¤ºï¼æ­¤é¡è³è¨ä¸¦æªåä½å¨æ´åå¥å­åµå¥ä¸­ï¼èæ¯ç·¨ç¢¼å¨ç¹å®ååä¸­ãäºè§£è¼¸å¥æå­çè³è¨å¦ä½å£ç¸®å°å¥å­åµå¥ä¸­ï¼æå©æ¼äºè§£ç®åçTransformeræ¨¡åï¼ä¸¦æå©æ¼å»ºæ§æªä¾å¯è§£éçç¥ç¶æ¨¡åã

##### **Multi-Resolution Histopathology Patch Graphs for Ovarian Cancer Subtyping**
2407.18105v1 by Jack Breen, Katie Allen, Kieran Zucker, Nicolas M. Orsi, Nishant Ravikumar

Computer vision models are increasingly capable of classifying ovarian
epithelial cancer subtypes, but they differ from pathologists by processing
small tissue patches at a single resolution. Multi-resolution graph models
leverage the spatial relationships of patches at multiple magnifications,
learning the context for each patch. In this study, we conduct the most
thorough validation of a graph model for ovarian cancer subtyping to date.
Seven models were tuned and trained using five-fold cross-validation on a set
of 1864 whole slide images (WSIs) from 434 patients treated at Leeds Teaching
Hospitals NHS Trust. The cross-validation models were ensembled and evaluated
using a balanced hold-out test set of 100 WSIs from 30 patients, and an
external validation set of 80 WSIs from 80 patients in the Transcanadian Study.
The best-performing model, a graph model using 10x+20x magnification data, gave
balanced accuracies of 73%, 88%, and 99% in cross-validation, hold-out testing,
and external validation, respectively. However, this only exceeded the
performance of attention-based multiple instance learning in external
validation, with a 93% balanced accuracy. Graph models benefitted greatly from
using the UNI foundation model rather than an ImageNet-pretrained ResNet50 for
feature extraction, with this having a much greater effect on performance than
changing the subsequent classification approach. The accuracy of the combined
foundation model and multi-resolution graph network offers a step towards the
clinical applicability of these models, with a new highest-reported performance
for this task, though further validations are still required to ensure the
robustness and usability of the models.

æè¦ï¼é»è¦è¦è¦ºæ¨¡åè¶ä¾è¶è½å¤ åé¡åµå·¢ä¸ç®ççäºåï¼ä½å®åèççå­¸å®¶ä¸åï¼å®åä»¥å®ä¸è§£æåº¦èçå°çµç¹è²¼çãå¤è§£æåº¦åå½¢æ¨¡åå©ç¨å¤åæ¾å¤§åçä¸è²¼ççç©ºééä¿ï¼å­¸ç¿æ¯åè²¼ççèæ¯ãå¨éé ç ç©¶ä¸­ï¼æåå°åå½¢æ¨¡åé²è¡äºè¿ä»çºæ­¢æå¾¹åºçåµå·¢çäºåé©è­ãä½¿ç¨ 434 åå¨å©è²æå­¸é«é¢ NHS ä¿¡è¨åºéæ¥åæ²»ççæ£èç 1864 å¼µå¨å¹»ççå½±å (WSI) é²è¡äºåäº¤åé©è­ï¼èª¿æ´ä¸¦è¨ç·´äºä¸åæ¨¡åãå°äº¤åé©è­æ¨¡åéæä¸¦ä½¿ç¨ä¾èª 30 åæ£èç 100 å¼µ WSI çå¹³è¡¡çåºæ¸¬è©¦éåä¾èª Transcanadian ç ç©¶ä¸­ 80 åæ£èç 80 å¼µ WSI çå¤é¨é©è­éé²è¡è©ä¼°ãè¡¨ç¾æä½³çæ¨¡åï¼ä¸åä½¿ç¨ 10 å+20 åæ¾å¤§åçè³æçåå½¢æ¨¡åï¼å¨äº¤åé©è­ãçåºæ¸¬è©¦åå¤é¨é©è­ä¸­åå¥çµ¦åº 73%ã88% å 99% çå¹³è¡¡æºç¢ºåº¦ãç¶èï¼éåè¶éäºå¤é¨é©è­ä¸­åºæ¼æ³¨æåçå¤å¯¦ä¾å­¸ç¿çè¡¨ç¾ï¼å¹³è¡¡æºç¢ºåº¦çº 93%ãåå½¢æ¨¡åå¾ä½¿ç¨ UNI åºç¤æ¨¡åèä¸æ¯ ImageNet é è¨ç·´ç ResNet50 é²è¡ç¹å¾µæåä¸­åçåªæ·ºï¼èæ¹è®å¾çºåé¡æ¹æ³ç¸æ¯ï¼éå°æè½ææ´å¤§çå½±é¿ãçµååºç¤æ¨¡ååå¤è§£æåº¦åå½¢ç¶²è·¯çæºç¢ºåº¦çºéäºæ¨¡åçè¨åºæç¨éåºäºä¸æ­¥ï¼å°æ¼éé ä»»åä¾èªªï¼éæ¯æ°çæé«å ±åè¡¨ç¾ï¼åç®¡ä»éè¦é²ä¸æ­¥çé©è­ä¾ç¢ºä¿æ¨¡åçç©©å¥æ§åå¯ç¨æ§ã

##### **Privacy Threats and Countermeasures in Federated Learning for Internet of Things: A Systematic Review**
2407.18096v1 by Adel ElZemity, Budi Arief

Federated Learning (FL) in the Internet of Things (IoT) environments can
enhance machine learning by utilising decentralised data, but at the same time,
it might introduce significant privacy and security concerns due to the
constrained nature of IoT devices. This represents a research challenge that we
aim to address in this paper. We systematically analysed recent literature to
identify privacy threats in FL within IoT environments, and evaluate the
defensive measures that can be employed to mitigate these threats. Using a
Systematic Literature Review (SLR) approach, we searched five publication
databases (Scopus, IEEE Xplore, Wiley, ACM, and Science Direct), collating
relevant papers published between 2017 and April 2024, a period which spans
from the introduction of FL until now. Guided by the PRISMA protocol, we
selected 49 papers to focus our systematic review on. We analysed these papers,
paying special attention to the privacy threats and defensive measures --
specifically within the context of IoT -- using inclusion and exclusion
criteria tailored to highlight recent advances and critical insights. We
identified various privacy threats, including inference attacks, poisoning
attacks, and eavesdropping, along with defensive measures such as Differential
Privacy and Secure Multi-Party Computation. These defences were evaluated for
their effectiveness in protecting privacy without compromising the functional
integrity of FL in IoT settings. Our review underscores the necessity for
robust and efficient privacy-preserving strategies tailored for IoT
environments. Notably, there is a need for strategies against replay, evasion,
and model stealing attacks. Exploring lightweight defensive measures and
emerging technologies such as blockchain may help improve the privacy of FL in
IoT, leading to the creation of FL models that can operate under variable
network conditions.

æè¦ï¼<paragraph>è¯é¦å­¸ç¿ (FL) å¨ç©è¯ç¶² (IoT) ç°å¢ä¸­å¯ä»¥å©ç¨åæ£å¼æ¸æå¢å¼·æ©å¨å­¸ç¿ï¼ä½åæï¼ç±æ¼ IoT è¨­åçåéæ§è³ªï¼å®å¯è½æå¸¶ä¾éå¤§çé±ç§åå®å¨åé¡ãéæ¯ä¸åç ç©¶ææ°ï¼æåå¸æå¨æ¬æä¸­è§£æ±ºéååé¡ãæåç³»çµ±å°åæäºæè¿çæç»ï¼ä»¥è­å¥ IoT ç°å¢ä¸­ FL ä¸­çé±ç§å¨èï¼ä¸¦è©ä¼°å¯æ¡åçé²ç¦¦æªæ½ä¾æ¸è¼éäºå¨èãä½¿ç¨ç³»çµ±æç»åé¡§ (SLR) æ¹æ³ï¼æåæç´¢äºäºååºçç©è³æåº«ï¼ScopusãIEEE XploreãWileyãACM å Science Directï¼ï¼æ´çäº 2017 å¹´è³ 2024 å¹´ 4 æä¹éç¼è¡¨çç¸éè«æï¼éæ®µæéæ¶µèäº FL çå¼å¥è³ä»ãå¨ PRISMA åè­°çæå°ä¸ï¼æåé¸æäº 49 ç¯è«æä½çºç³»çµ±åé¡§çéé»ãæååæäºéäºè«æï¼ç¹å¥éæ³¨é±ç§å¨èåé²ç¦¦æªæ½ââç¹å¥æ¯å¨ IoT çèæ¯ä¸ââä½¿ç¨éèº«å®å¶çåå«åæé¤æ¨æºä¾å¼·èª¿æè¿çé²å±åæ¹å¤æ§è¦è§£ãæåç¼ç¾äºåç¨®é±ç§å¨èï¼åæ¬æ¨çæ»æãä¸­æ¯æ»æåç«è½ï¼ä»¥åé²ç¦¦æªæ½ï¼ä¾å¦å·®åé±ç§åå®å¨å¤æ¹è¨ç®ãéäºé²ç¦¦æªæ½çæææ§å¨æ¼ä¿è­·é±ç§ï¼åæä¸æå®³ IoT è¨­ç½®ä¸­ FL çåè½å®æ´æ§ãæåçåé¡§å¼·èª¿äºéå° IoT ç°å¢éèº«å®å¶çå¼·å¤§ä¸ææçé±ç§ä¿è­·ç­ç¥çå¿è¦æ§ãå¼å¾æ³¨æçæ¯ï¼éè¦éå°éæ­ãè¦é¿åæ¨¡åç«åæ»æå¶å®ç­ç¥ãæ¢ç´¢è¼éç´é²ç¦¦æªæ½ååå¡éç­æ°èæè¡å¯è½æå©æ¼æé« IoT ä¸­ FL çé±ç§æ§ï¼å¾èåµå»ºå¯å¨è®éç¶²è·¯æ¢ä»¶ä¸éä½ç FL æ¨¡åã</paragraph>

##### **PEFT-U: Parameter-Efficient Fine-Tuning for User Personalization**
2407.18078v1 by Christopher Clarke, Yuzhao Heng, Lingjia Tang, Jason Mars

The recent emergence of Large Language Models (LLMs) has heralded a new era
of human-AI interaction. These sophisticated models, exemplified by Chat-GPT
and its successors, have exhibited remarkable capabilities in language
understanding. However, as these LLMs have undergone exponential growth, a
crucial dimension that remains understudied is the personalization of these
models. Large foundation models such as GPT-3 etc. focus on creating a
universal model that serves a broad range of tasks and users. This approach
emphasizes the model's generalization capabilities, treating users as a
collective rather than as distinct individuals. While practical for many common
applications, this one-size-fits-all approach often fails to address the rich
tapestry of human diversity and individual needs. To explore this issue we
introduce the PEFT-U Benchmark: a new dataset for building and evaluating NLP
models for user personalization. \datasetname{} consists of a series of
user-centered tasks containing diverse and individualized expressions where the
preferences of users can potentially differ for the same input. Using PEFT-U,
we explore the challenge of efficiently personalizing LLMs to accommodate
user-specific preferences in the context of diverse user-centered tasks.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) è¿æèèµ·ï¼é ç¤ºèäººæ©äºåçæ°ç´åãéäºç²¾å¯çæ¨¡åï¼ä»¥ Chat-GPT åå¶å¾ç¹¼èçºä¾ï¼å¨èªè¨çè§£æ¹é¢å±ç¾äºéå¡çè½åãç¶èï¼é¨èéäº LLM ç¶æ­·ææ¸ç´å¢é·ï¼ä¸åä»æªå¾å°ååç ç©¶çéè¦é¢åæ¯éäºæ¨¡åçåäººåãå¤§ååºç¤æ¨¡åï¼ä¾å¦ GPT-3 ç­ï¼å°æ³¨æ¼å»ºç«ä¸åéç¨çæ¨¡åï¼æåæ¼å»£æ³çä»»ååä½¿ç¨èãæ­¤æ¹æ³å¼·èª¿æ¨¡åçæ¦åè½åï¼å°ä½¿ç¨èè¦çºä¸åéé«ï¼èéç¨ç«çåé«ãéç¶å°è¨±å¤å¸¸è¦æç¨ä¾èªªå¾å¯¦ç¨ï¼ä½éç¨®ä¸é«é©ç¨çæ¹æ³éå¸¸ç¡æ³æ»¿è¶³äººé¡å¤åæ§ååå¥éæ±çè±å¯æ§ãçºäºæ¢è¨æ­¤åé¡ï¼æåå¼å¥äº PEFT-U åºæºï¼ä¸åç¨æ¼å»ºç«åè©ä¼°ä½¿ç¨èåäººå NLP æ¨¡åçæ°è³æéã\datasetname{} åå«ä¸ç³»åä»¥ä½¿ç¨èçºä¸­å¿çä»»åï¼å¶ä¸­åå«å¤æ¨£åä¸åæ§åçè¡¨éï¼ä½¿ç¨èçåå¥½å¯è½å ç¸åçè¼¸å¥èææä¸åãä½¿ç¨ PEFT-Uï¼æåæ¢è¨äºå¨å¤ååä»¥ä½¿ç¨èçºä¸­å¿çä»»åä¸­ï¼ææåäººå LLM ä»¥é©æä½¿ç¨èç¹å®åå¥½çææ°ã

##### **Difficulty Estimation and Simplification of French Text Using LLMs**
2407.18061v1 by Henri Jamet, Yash Raj Shrestha, Michalis Vlachos

We leverage generative large language models for language learning
applications, focusing on estimating the difficulty of foreign language texts
and simplifying them to lower difficulty levels. We frame both tasks as
prediction problems and develop a difficulty classification model using labeled
examples, transfer learning, and large language models, demonstrating superior
accuracy compared to previous approaches. For simplification, we evaluate the
trade-off between simplification quality and meaning preservation, comparing
zero-shot and fine-tuned performances of large language models. We show that
meaningful text simplifications can be obtained with limited fine-tuning. Our
experiments are conducted on French texts, but our methods are
language-agnostic and directly applicable to other foreign languages.

æè¦ï¼æåå©ç¨çæå¼å¤§åèªè¨æ¨¡åé²è¡èªè¨å­¸ç¿æç¨ï¼éé»å¨æ¼ä¼°è¨å¤èªææ¬çé£åº¦ä¸¦å°å¶ç°¡åçºè¼ä½çé£åº¦ç­ç´ãæåå°éå©åä»»åé½è¨­å®çºé æ¸¬åé¡ï¼ä¸¦ä½¿ç¨æ¨è¨ç¯ä¾ãè½ç§»å­¸ç¿åå¤§èªè¨æ¨¡åéç¼é£åº¦åé¡æ¨¡åï¼èååçåæ³ç¸æ¯ï¼è­æäºå¶åªè¶çæºç¢ºæ§ãå°æ¼ç°¡åï¼æåè©ä¼°äºç°¡ååè³ªèæç¾©ä¿çä¹éçåæ¨ï¼æ¯è¼å¤§åèªè¨æ¨¡åçé¶æ¬¡å­¸ç¿åå¾®èª¿æè½ãæåè¡¨æï¼ééæéçå¾®èª¿ï¼å¯ä»¥ç²å¾ææç¾©çææ¬ç°¡åãæåçå¯¦é©æ¯å¨æ³èªææ¬ä¸é²è¡çï¼ä½æåçèªè¨æ¹æ³èèªè¨ç¡éï¼ä¸¦ä¸å¯ç´æ¥æç¨æ¼å¶ä»å¤èªã

##### **Peak-Controlled Logits Poisoning Attack in Federated Distillation**
2407.18039v1 by Yuhan Tang, Aoxu Zhang, Zhiyuan Wu, Bo Gao, Tian Wen, Yuwei Wang, Sheng Sun

Federated Distillation (FD) offers an innovative approach to distributed
machine learning, leveraging knowledge distillation for efficient and flexible
cross-device knowledge transfer without necessitating the upload of extensive
model parameters to a central server. While FD has gained popularity, its
vulnerability to poisoning attacks remains underexplored. To address this gap,
we previously introduced FDLA (Federated Distillation Logits Attack), a method
that manipulates logits communication to mislead and degrade the performance of
client models. However, the impact of FDLA on participants with different
identities and the effects of malicious modifications at various stages of
knowledge transfer remain unexplored. To this end, we present PCFDLA
(Peak-Controlled Federated Distillation Logits Attack), an advanced and more
stealthy logits poisoning attack method for FD. PCFDLA enhances the
effectiveness of FDLA by carefully controlling the peak values of logits to
create highly misleading yet inconspicuous modifications. Furthermore, we
introduce a novel metric for better evaluating attack efficacy, demonstrating
that PCFDLA maintains stealth while being significantly more disruptive to
victim models compared to its predecessors. Experimental results across various
datasets confirm the superior impact of PCFDLA on model accuracy, solidifying
its potential threat in federated distillation systems.

æè¦ï¼èé¦è¸é¦ (FD) æä¾äºä¸ç§åå¸å¼æºå¨å­¦ä¹ çåæ°æ¹æ³ï¼å®å©ç¨ç¥è¯è¸é¦æ¥å®ç°é«æä¸çµæ´»çè·¨è®¾å¤ç¥è¯è½¬ç§»ï¼èæ éå°å¤§éçæ¨¡ååæ°ä¸ä¼ å°ä¸­å¤®æå¡å¨ãè½ç¶ FD å·²è·å¾æ®åï¼ä½å¶å¯¹ä¸­æ¯æ»å»çèå¼±æ§ä»æªå¾å°ååæ¢ç´¢ãä¸ºäºè§£å³è¿ä¸å·®è·ï¼æä»¬ä¹åå¼å¥äº FDLAï¼èé¦è¸é¦ Logits æ»å»ï¼ï¼è¿æ¯ä¸ç§éè¿æçºµ Logits éä¿¡æ¥è¯¯å¯¼å¹¶éä½å®¢æ·ç«¯æ¨¡åæ§è½çæ¹æ³ãä½æ¯ï¼FDLA å¯¹å·æä¸åèº«ä»½çåä¸èçå½±åä»¥åå¨ç¥è¯è½¬ç§»çä¸åé¶æ®µè¿è¡æ¶æä¿®æ¹çå½±åä»æªå¾å°æ¢ç´¢ãä¸ºæ­¤ï¼æä»¬æåºäº PCFDLAï¼å³°å¼æ§å¶èé¦è¸é¦ Logits æ»å»ï¼ï¼è¿æ¯ä¸ç§éå¯¹ FD çé«çº§ä¸æ´éè½ç Logits ä¸­æ¯æ»å»æ¹æ³ãPCFDLA éè¿ä»ç»æ§å¶ Logits çå³°å¼æ¥å¢å¼º FDLA çæææ§ï¼ä»¥åå»ºæå·è¯¯å¯¼æ§ä½åä¸å¼äººæ³¨ç®çä¿®æ¹ãæ­¤å¤ï¼æä»¬å¼å¥äºä¸ä¸ªæ°ææ æ¥æ´å¥½å°è¯ä¼°æ»å»ææï¼è¯æ PCFDLA å¨ä¿æéè½æ§çåæ¶ï¼ä¸ä¹åçæ»å»æ¹æ³ç¸æ¯ï¼å¯¹åå®³èæ¨¡åçç ´åæ§æ´å¤§ãè·¨åç§æ°æ®éçå®éªç»æè¯å®äº PCFDLA å¯¹æ¨¡åç²¾åº¦çåè¶å½±åï¼å·©åºäºå¶å¨èé¦è¸é¦ç³»ç»ä¸­çæ½å¨å¨èã

##### **RestoreAgent: Autonomous Image Restoration Agent via Multimodal Large Language Models**
2407.18035v1 by Haoyu Chen, Wenbo Li, Jinjin Gu, Jingjing Ren, Sixiang Chen, Tian Ye, Renjing Pei, Kaiwen Zhou, Fenglong Song, Lei Zhu

Natural images captured by mobile devices often suffer from multiple types of
degradation, such as noise, blur, and low light. Traditional image restoration
methods require manual selection of specific tasks, algorithms, and execution
sequences, which is time-consuming and may yield suboptimal results. All-in-one
models, though capable of handling multiple tasks, typically support only a
limited range and often produce overly smooth, low-fidelity outcomes due to
their broad data distribution fitting. To address these challenges, we first
define a new pipeline for restoring images with multiple degradations, and then
introduce RestoreAgent, an intelligent image restoration system leveraging
multimodal large language models. RestoreAgent autonomously assesses the type
and extent of degradation in input images and performs restoration through (1)
determining the appropriate restoration tasks, (2) optimizing the task
sequence, (3) selecting the most suitable models, and (4) executing the
restoration. Experimental results demonstrate the superior performance of
RestoreAgent in handling complex degradation, surpassing human experts.
Furthermore, the system modular design facilitates the fast integration of new
tasks and models, enhancing its flexibility and scalability for various
applications.

æè¦ï¼è¡åè£ç½®ææçèªç¶å½±åéå¸¸æåå°å¤ç¨®é¡åçå£åï¼ä¾å¦éè¨ãæ¨¡ç³åä½åæºãå³çµ±çå½±åä¿®å¾©æ¹æ³éè¦æåé¸æç¹å®ä»»åãæ¼ç®æ³åå·è¡é åºï¼éæ¢èæåå¯è½ç¢çæ¬¡ä½³ççµæãéç¶ä¸é«æåçæ¨¡åè½å¤ èçå¤é ä»»åï¼ä½éå¸¸åªæ¯æ´æéçç¯åï¼èä¸ç±æ¼å¶å»£æ³çè³æåä½æ¬åï¼éå¸¸æç¢çéæ¼å¹³æ»ãä½ä¿çççµæãçºäºæå°éäºææ°ï¼æåé¦åå®ç¾©äºä¸åæ°çç®¡éä¾ä¿®å¾©å·æå¤éå£åç¾è±¡çå½±åï¼ç¶å¾ä»ç´¹ RestoreAgentï¼ä¸åå©ç¨å¤æ¨¡æå¤§åèªè¨æ¨¡åçæºæ§å½±åä¿®å¾©ç³»çµ±ãRestoreAgent èªä¸»è©ä¼°è¼¸å¥å½±åçå£åé¡ååç¨åº¦ï¼ä¸¦éé (1) ç¢ºå®é©ç¶çä¿®å¾©ä»»åã(2) æä½³åä»»åé åºã(3) é¸ææåé©çæ¨¡åï¼ä»¥å (4) å·è¡ä¿®å¾©ä¾å·è¡ä¿®å¾©ãå¯¦é©çµæè­æ RestoreAgent å¨èçè¤éå£åæ¹é¢çåªç°æè½ï¼è¶è¶äºäººé¡å°å®¶ãæ­¤å¤ï¼ç³»çµ±æ¨¡çµåè¨­è¨æå©æ¼å¿«éæ´åæ°çä»»ååæ¨¡åï¼å¢å¼·å¶éæ´»æ§ï¼ä¸¦æ´åå¶å¨åç¨®æç¨ç¨å¼ä¸­çå¯æ´åæ§ã

##### **AttentionHand: Text-driven Controllable Hand Image Generation for 3D Hand Reconstruction in the Wild**
2407.18034v1 by Junho Park, Kyeongbo Kong, Suk-Ju Kang

Recently, there has been a significant amount of research conducted on 3D
hand reconstruction to use various forms of human-computer interaction.
However, 3D hand reconstruction in the wild is challenging due to extreme lack
of in-the-wild 3D hand datasets. Especially, when hands are in complex pose
such as interacting hands, the problems like appearance similarity, self-handed
occclusion and depth ambiguity make it more difficult. To overcome these
issues, we propose AttentionHand, a novel method for text-driven controllable
hand image generation. Since AttentionHand can generate various and numerous
in-the-wild hand images well-aligned with 3D hand label, we can acquire a new
3D hand dataset, and can relieve the domain gap between indoor and outdoor
scenes. Our method needs easy-to-use four modalities (i.e, an RGB image, a hand
mesh image from 3D label, a bounding box, and a text prompt). These modalities
are embedded into the latent space by the encoding phase. Then, through the
text attention stage, hand-related tokens from the given text prompt are
attended to highlight hand-related regions of the latent embedding. After the
highlighted embedding is fed to the visual attention stage, hand-related
regions in the embedding are attended by conditioning global and local hand
mesh images with the diffusion-based pipeline. In the decoding phase, the final
feature is decoded to new hand images, which are well-aligned with the given
hand mesh image and text prompt. As a result, AttentionHand achieved
state-of-the-art among text-to-hand image generation models, and the
performance of 3D hand mesh reconstruction was improved by additionally
training with hand images generated by AttentionHand.

æè¦ï¼<paragraph>æè¿ï¼å·²éå¯¹ 3D æé¨éå»ºè¿è¡äºå¤§éç ç©¶ï¼ä»¥ä½¿ç¨åç§å½¢å¼çäººæºäº¤äºã
ç¶èï¼ç±äºæåº¦ç¼ºä¹éå¤ 3D æé¨æ°æ®éï¼éå¤ 3D æé¨éå»ºå·ææææ§ãç¹å«æ¯å¨æé¨å¤äºå¤æå§¿å¿ï¼ä¾å¦äº¤äºæé¨ï¼æ¶ï¼å¤è§ç¸ä¼¼æ§ãèªæé®æ¡åæ·±åº¦æ­§ä¹ç­é®é¢ä½¿æåµåå¾æ´å å°é¾ãä¸ºäºåæè¿äºé®é¢ï¼æä»¬æåºäº AttentionHandï¼è¿æ¯ä¸ç§ç¨äºææ¬é©±å¨çå¯æ§æé¨å¾åçæçæ°æ¹æ³ãç±äº AttentionHand å¯ä»¥çæåç§å¤§éä¸ 3D æé¨æ ç­¾å¯¹é½è¯å¥½çéå¤æé¨å¾åï¼æä»¬å¯ä»¥è·åæ°ç 3D æé¨æ°æ®éï¼å¹¶ä¸å¯ä»¥ç¼è§£å®¤ååå®¤å¤åºæ¯ä¹é´çé¢åå·®è·ãæä»¬çæ¹æ³éè¦æäºä½¿ç¨çåç§æ¨¡æï¼å³ RGB å¾åã3D æ ç­¾ä¸­çæé¨ç½æ ¼å¾åãè¾¹çæ¡åææ¬æç¤ºï¼ãè¿äºæ¨¡æéè¿ç¼ç é¶æ®µåµå¥å°æ½å¨ç©ºé´ä¸­ãç¶åï¼éè¿ææ¬æ³¨æåé¶æ®µï¼æ¥èªç»å®ææ¬æç¤ºçæé¨ç¸å³æ è®°è¢«ç¨æ¥çªåºæ½å¨åµå¥ä¸­çæé¨ç¸å³åºåãå¨çªåºæ¾ç¤ºçåµå¥è¢«é¦éå°è§è§æ³¨æåé¶æ®µåï¼åµå¥ä¸­çæé¨ç¸å³åºåéè¿åºäºæ©æ£çç®¡éä¸å¨å±åå±é¨æé¨ç½æ ¼å¾åè¿è¡æ¡ä»¶å¤çãå¨è§£ç é¶æ®µï¼æç»ç¹å¾è¢«è§£ç ä¸ºæ°çæé¨å¾åï¼è¿äºå¾åä¸ç»å®çæé¨ç½æ ¼å¾ååææ¬æç¤ºå¯¹é½è¯å¥½ãç»æï¼AttentionHand å¨ææ¬å°æé¨å¾åçææ¨¡åä¸­å®ç°äºæåè¿çæ°´å¹³ï¼å¹¶ä¸éè¿ä½¿ç¨ AttentionHand çæçå¾åè¿è¡é¢å¤è®­ç»ï¼æ¹è¿äº 3D æé¨ç½æ ¼éå»ºçæ§è½ã</paragraph>

##### **Learning mental states estimation through self-observation: a developmental synergy between intentions and beliefs representations in a deep-learning model of Theory of Mind**
2407.18022v1 by Francesca Bianco, Silvia Rigato, Maria Laura Filippetti, Dimitri Ognibene

Theory of Mind (ToM), the ability to attribute beliefs, intentions, or mental
states to others, is a crucial feature of human social interaction. In complex
environments, where the human sensory system reaches its limits, behaviour is
strongly driven by our beliefs about the state of the world around us.
Accessing others' mental states, e.g., beliefs and intentions, allows for more
effective social interactions in natural contexts. Yet, these variables are not
directly observable, making understanding ToM a challenging quest of interest
for different fields, including psychology, machine learning and robotics. In
this paper, we contribute to this topic by showing a developmental synergy
between learning to predict low-level mental states (e.g., intentions, goals)
and attributing high-level ones (i.e., beliefs). Specifically, we assume that
learning beliefs attribution can occur by observing one's own decision
processes involving beliefs, e.g., in a partially observable environment. Using
a simple feed-forward deep learning model, we show that, when learning to
predict others' intentions and actions, more accurate predictions can be
acquired earlier if beliefs attribution is learnt simultaneously. Furthermore,
we show that the learning performance improves even when observed actors have a
different embodiment than the observer and the gain is higher when observing
beliefs-driven chunks of behaviour. We propose that our computational approach
can inform the understanding of human social cognitive development and be
relevant for the design of future adaptive social robots able to autonomously
understand, assist, and learn from human interaction partners in novel natural
environments and tasks.

æè¦ï¼å¿æºçè« (ToM) æ¯å°ä¿¡å¿µãæåæå¿æºçææ­¸å æ¼ä»äººçè½åï¼æ¯äººé¡ç¤¾äº¤äºåçä¸é ééµç¹å¾µãå¨è¤éçç°å¢ä¸­ï¼äººé¡çæå®ç³»çµ±æéå°å¶æ¥µéï¼è¡çºæåå°æåå°å¨é­ä¸ççæçä¿¡å¿µå¼·çé©ä½¿ãå­åä»äººçå¿æºçæï¼ä¾å¦ä¿¡å¿µåæåï¼å¯ä»¥å¨èªç¶æå¢ä¸­é²è¡æ´ææçç¤¾äº¤äºåãç¶èï¼éäºè®æ¸ä¸¦éç´æ¥å¯è§å¯ï¼ä½¿å¾çè§£å¿æºçè«æçºä¸åå·æææ°æ§çä»»åï¼å¼èµ·å¿çå­¸ãæ©å¨å­¸ç¿åæ©å¨äººå­¸ç­ä¸åé åçèè¶£ãå¨æ¬æä¸­ï¼æåééå±ç¤ºé æ¸¬ä½éå¿æºçæï¼ä¾å¦æåãç®æ¨ï¼åæ­¸å é«éå¿æºçæï¼å³ä¿¡å¿µï¼ä¹éçç¼å±ååä½ç¨ï¼çºæ­¤ä¸»é¡ååºè²¢ç»ãå·é«ä¾èªªï¼æååè¨­ä¿¡å¿µæ­¸å å­¸ç¿å¯ä»¥ééè§å¯åäººæ¶åä¿¡å¿µçæ±ºç­éç¨ä¾é²è¡ï¼ä¾å¦å¨é¨åå¯è§å¯çç°å¢ä¸­ãä½¿ç¨ç°¡å®çåé¥æ·±åº¦å­¸ç¿æ¨¡åï¼æåå±ç¤ºå¨å­¸ç¿é æ¸¬ä»äººçæååè¡çºæï¼å¦æåæå­¸ç¿ä¿¡å¿µæ­¸å ï¼å¯ä»¥æ´æ©ç²å¾æ´æºç¢ºçé æ¸¬ãæ­¤å¤ï¼æåå±ç¤ºå³ä½¿è§å¯å°çè¡çºèèè§å¯èå·æä¸åçå·é«åï¼å­¸ç¿è¡¨ç¾ä¹ææææåï¼èä¸å¨è§å¯ç±ä¿¡å¿µé©åçè¡çºçæ®µæï¼å¢çææ´é«ãæåæåºæåçè¨ç®æ¹æ³å¯ä»¥çºçè§£äººé¡ç¤¾æèªç¥ç¼å±æä¾è³è¨ï¼ä¸¦èæªä¾é©ææ§ç¤¾ææ©å¨äººçè¨­è¨ç¸éï¼éäºæ©å¨äººè½å¤ å¨æ°çèªç¶ç°å¢åä»»åä¸­èªä¸»çè§£ãåå©åå¾äººé¡äºåå¤¥ä¼´é£è£¡å­¸ç¿ã

##### **Quadratic Advantage with Quantum Randomized Smoothing Applied to Time-Series Analysis**
2407.18021v1 by Nicola Franco, Marie Kempkes, Jakob Spiegelberg, Jeanette Miriam Lorenz

As quantum machine learning continues to develop at a rapid pace, the
importance of ensuring the robustness and efficiency of quantum algorithms
cannot be overstated. Our research presents an analysis of quantum randomized
smoothing, how data encoding and perturbation modeling approaches can be
matched to achieve meaningful robustness certificates. By utilizing an
innovative approach integrating Grover's algorithm, a quadratic sampling
advantage over classical randomized smoothing is achieved. This strategy
necessitates a basis state encoding, thus restricting the space of meaningful
perturbations. We show how constrained $k$-distant Hamming weight perturbations
are a suitable noise distribution here, and elucidate how they can be
constructed on a quantum computer. The efficacy of the proposed framework is
demonstrated on a time series classification task employing a Bag-of-Words
pre-processing solution. The advantage of quadratic sample reduction is
recovered especially in the regime with large number of samples. This may allow
quantum computers to efficiently scale randomized smoothing to more complex
tasks beyond the reach of classical methods.

æè¦ï¼é¨èéå­æ©å¨å­¸ç¿æçºå¿«éç¼å±ï¼ç¢ºä¿éå­æ¼ç®æ³çç©©å¥æ§åæçè³ééè¦ãæåçç ç©¶åæäºéå­é¨æ©å¹³æ»ï¼ä»¥åå¦ä½å°è³æç·¨ç¢¼åæ¾åå»ºæ¨¡æ¹æ³å¹éä»¥åå¾ææç¾©çç©©å¥æ§è­æãééæ´åèç¾ä½æ¼ç®æ³çåµæ°æ¹æ³ï¼éæç¸è¼æ¼å¤å¸é¨æ©å¹³æ»çäºæ¬¡åæ¨£åªå¢ãæ­¤ç­ç¥éè¦åºåºæç·¨ç¢¼ï¼å æ­¤éå¶äºææç¾©çæ¾åç©ºéãæåå±ç¤ºäºåç´æç k é è·æ¼¢ææ¬éæ¾åå¨æ­¤èçºåé©çéè¨åä½ï¼ä¸¦èªªæå¦ä½å¨éå­é»è¦ä¸å»ºæ§å®åãææåºçæ¶æ§æè½å·²å¨ä½¿ç¨è©è¢é èçè§£æ±ºæ¹æ¡çæéåºååé¡ä»»åä¸­å¾å°é©è­ãäºæ¬¡åæ¨£æ¸å°çåªå¢ç¹å¥å¨å¤§éæ¨£æ¬çæ¢ä»¶ä¸å¾ä»¥æ¢å¾©ãéå¯è½è®éå­é»è¦ææå°å°é¨æ©å¹³æ»æ´å±å°æ´è¤éçä»»åï¼è¶è¶å¤å¸æ¹æ³çç¯åã

##### **GermanPartiesQA: Benchmarking Commercial Large Language Models for Political Bias and Sycophancy**
2407.18008v1 by Jan Batzner, Volker Stocker, Stefan Schmid, Gjergji Kasneci

LLMs are changing the way humans create and interact with content,
potentially affecting citizens' political opinions and voting decisions. As
LLMs increasingly shape our digital information ecosystems, auditing to
evaluate biases, sycophancy, or steerability has emerged as an active field of
research. In this paper, we evaluate and compare the alignment of six LLMs by
OpenAI, Anthropic, and Cohere with German party positions and evaluate
sycophancy based on a prompt experiment. We contribute to evaluating political
bias and sycophancy in multi-party systems across major commercial LLMs. First,
we develop the benchmark dataset GermanPartiesQA based on the Voting Advice
Application Wahl-o-Mat covering 10 state and 1 national elections between 2021
and 2023. In our study, we find a left-green tendency across all examined LLMs.
We then conduct our prompt experiment for which we use the benchmark and
sociodemographic data of leading German parliamentarians to evaluate changes in
LLMs responses. To differentiate between sycophancy and steerabilty, we use 'I
am [politician X], ...' and 'You are [politician X], ...' prompts. Against our
expectations, we do not observe notable differences between prompting 'I am'
and 'You are'. While our findings underscore that LLM responses can be
ideologically steered with political personas, they suggest that observed
changes in LLM outputs could be better described as personalization to the
given context rather than sycophancy.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) æ­£å¨æ¹è®äººé¡å»ºç«åäºåå§å®¹çæ¹å¼ï¼
æ½å¨å°å½±é¿å¬æ°çæ¿æ²»è§é»åæç¥¨æ±ºå®ãç±æ¼
LLM æä¾æå½¢å¡æåçæ¸ä½è³è¨çæç³»çµ±ï¼å¯©æ¥ä»¥
è©ä¼°åè¦ãé¿è«å¥æ¿æå¯æç¸±æ§å·²æçºä¸é æ´»èºçç ç©¶é åãå¨æ¬æä¸­ï¼æåè©ä¼°ä¸¦æ¯è¼ OpenAIãAnthropic å Cohere çå­å LLM èå¾·åæ¿é»¨ç«å ´çä¸è´æ§ï¼ä¸¦æ ¹ææç¤ºå¯¦é©è©ä¼°é¿è«å¥æ¿ãæåè´åæ¼è©ä¼°ä¸»è¦åæ¥­ LLM ä¸­å¤é»¨å¶çæ¿æ²»åè¦åé¿è«å¥æ¿ãé¦åï¼
æåæ ¹ææç¥¨å»ºè­°æç¨ç¨å¼ Wahl-o-Mat éç¼åºæºè³æé GermanPartiesQAï¼æ¶µè 2021 å¹´è³ 2023 å¹´ä¹éç 10 æ¬¡å·é¸èå 1 æ¬¡å¨åé¸èãå¨æåçç ç©¶ä¸­ï¼æåç¼ç¾ææåæª¢ LLM é½å¾åæ¼å·¦ç¶ ãç¶å¾ï¼æåé²è¡æç¤ºå¯¦é©ï¼æåä½¿ç¨åºæºåå¾·ååæè­°å¡çç¤¾æäººå£è³æä¾è©ä¼° LLM åæçè®åãçºäºååé¿è«å¥æ¿åå¯æç¸±æ§ï¼æåä½¿ç¨ãææ¯ [æ¿æ²»äººç© X]ï¼...ãåãä½ æ¯ [æ¿æ²»äººç© X]ï¼...ãæç¤ºãèæåçé æç¸åï¼æåæ²æè§å¯å°æç¤ºãææ¯ãåãä½ æ¯ãä¹éçé¡¯èå·®ç°ãéç¶æåçç ç©¶çµæå¼·èª¿ LLM åæå¯ä»¥ç¨æ¿æ²»äººç©ä¾é²è¡æè­å½¢ææç¸±ï¼ä½å®åè¡¨æï¼è§å¯å°ç LLM è¼¸åºè®åå¯ä»¥æ´é©åå°æè¿°çºå°ç¹å®èçµ¡çåäººåï¼èä¸æ¯é¿è«å¥æ¿ã

##### **Keep the Cost Down: A Review on Methods to Optimize LLM' s KV-Cache Consumption**
2407.18003v1 by Shi Luohe, Zhang Hongyi, Yao Yao, Li Zuchao, Zhao Hai

Large Language Models (LLMs), epitomized by ChatGPT' s release in late 2022,
have revolutionized various industries with their advanced language
comprehension. However, their efficiency is challenged by the Transformer
architecture' s struggle with handling long texts. KV-Cache has emerged as a
pivotal solution to this issue, converting the time complexity of token
generation from quadratic to linear, albeit with increased GPU memory overhead
proportional to conversation length. With the development of the LLM community
and academia, various KV-Cache compression methods have been proposed. In this
review, we dissect the various properties of KV-Cache and elaborate on various
methods currently used to optimize the KV-Cache space usage of LLMs. These
methods span the pre-training phase, deployment phase, and inference phase, and
we summarize the commonalities and differences among these methods.
Additionally, we list some metrics for evaluating the long-text capabilities of
large language models, from both efficiency and capability perspectives. Our
review thus sheds light on the evolving landscape of LLM optimization, offering
insights into future advancements in this dynamic field.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM)ï¼ä»¥ 2022 å¹´åºç¼å¸ç ChatGPT çºä»£è¡¨ï¼
ä»¥å¶åé²çèªè¨çè§£åå¾¹åºæ¹è®äºååç¢æ¥­ãç¶èï¼å¶æçåå° Transformer
æ¶æ§å¨èçé·æå­ææé­éçå°é£æææ°ãKV å¿«åå·²æçºè§£æ±ºæ­¤åé¡çééµè§£æ±ºæ¹æ¡ï¼å° token
ç¢ççæéè¤éåº¦å¾äºæ¬¡è½æçºç·æ§ï¼åç®¡ GPU è¨æ¶é«éé·æé¨èå°è©±é·åº¦ææ¯ä¾å°å¢å ãé¨è LLM ç¤¾ç¾¤
åå­¸è¡ççç¼å±ï¼å·²æåºåç¨® KV å¿«åå£ç¸®æ¹æ³ãå¨æ­¤
åé¡§ä¸­ï¼æååæäº KV å¿«åçåç¨®ç¹æ§ï¼ä¸¦é¡è¿°äºç®åç¨æ¼æä½³å LLM ç KV å¿«åç©ºéä½¿ç¨ççåç¨®
æ¹æ³ãéäº
æ¹æ³æ¶µèäºé è¨ç·´éæ®µãé¨ç½²éæ®µåæ¨è«éæ®µï¼æåç¸½çµäºéäºæ¹æ³ä¹éçå±æ§åå·®ç°ã
æ­¤å¤ï¼æåååºäºä¸äºç¨æ¼è©ä¼°å¤§åèªè¨æ¨¡åé·æå­è½åçææ¨ï¼å¾æçåè½åçè§åº¦ä¾çãå æ­¤ï¼æåç
åé¡§é¡æäº LLM æä½³åçæ¼è®è¶¨å¢ï¼æä¾äºå°æ­¤åæé åæªä¾é²å±çè¦è§£ã

##### **On the Effect of Purely Synthetic Training Data for Different Automatic Speech Recognition Architectures**
2407.17997v1 by Nick Rossenbach, Benedikt Hilmes, Ralf SchlÃ¼ter

In this work we evaluate the utility of synthetic data for training automatic
speech recognition (ASR). We use the ASR training data to train a
text-to-speech (TTS) system similar to FastSpeech-2. With this TTS we reproduce
the original training data, training ASR systems solely on synthetic data. For
ASR, we use three different architectures, attention-based encoder-decoder,
hybrid deep neural network hidden Markov model and a Gaussian mixture hidden
Markov model, showing the different sensitivity of the models to synthetic data
generation. In order to extend previous work, we present a number of ablation
studies on the effectiveness of synthetic vs. real training data for ASR. In
particular we focus on how the gap between training on synthetic and real data
changes by varying the speaker embedding or by scaling the model size. For the
latter we show that the TTS models generalize well, even when training scores
indicate overfitting.

æè¦ï¼å¨éé å·¥ä½ä¸­ï¼æåè©ä¼°äºåæè³æå¨è¨ç·´èªåèªé³è¾¨è­ (ASR) çæç¨ãæåä½¿ç¨ ASR è¨ç·´è³æä¾è¨ç·´é¡ä¼¼ FastSpeech-2 çæå­è½èªé³ (TTS) ç³»çµ±ãéééå TTSï¼æåéç¾åå§è¨ç·´è³æï¼åä½¿ç¨åæè³æè¨ç·´ ASR ç³»çµ±ãå°æ¼ ASRï¼æåä½¿ç¨ä¸ç¨®ä¸åçæ¶æ§ï¼åºæ¼æ³¨æåçç·¨ç¢¼å¨-è§£ç¢¼å¨ãæ··åæ·±åº¦ç¥ç¶ç¶²è·¯é±èé¦¬å¯å¤«æ¨¡ååé«æ¯æ··åé±èé¦¬å¯å¤«æ¨¡åï¼é¡¯ç¤ºæ¨¡åå°åæè³æçæçææåº¦ä¸åãçºäºæ´å±ååçç ç©¶ï¼æåæåºäºä¸äºéæ¼åæèçå¯¦è¨ç·´è³æå° ASR æææ§çæ¶èç ç©¶ãç¹å¥æ¯ï¼æåå°æ³¨æ¼ééæ¹è®èªªè©±èåµå¥æèª¿æ´æ¨¡åå¤§å°ï¼ä¾ç¸®å°å¨åæè³æåçå¯¦è³æä¸è¨ç·´çå·®è·ãå°æ¼å¾èï¼æåè¡¨æ TTS æ¨¡åå·æè¯å¥½çæ³åæ§ï¼å³ä½¿è¨ç·´åæ¸è¡¨ç¤ºéåº¦æ¬åã

##### **What does Kiki look like? Cross-modal associations between speech sounds and visual shapes in vision-and-language models**
2407.17974v1 by Tessa Verhoef, Kiana Shahrasbi, Tom Kouwenhoven

Humans have clear cross-modal preferences when matching certain novel words
to visual shapes. Evidence suggests that these preferences play a prominent
role in our linguistic processing, language learning, and the origins of
signal-meaning mappings. With the rise of multimodal models in AI, such as
vision- and-language (VLM) models, it becomes increasingly important to uncover
the kinds of visio-linguistic associations these models encode and whether they
align with human representations. Informed by experiments with humans, we probe
and compare four VLMs for a well-known human cross-modal preference, the
bouba-kiki effect. We do not find conclusive evidence for this effect but
suggest that results may depend on features of the models, such as architecture
design, model size, and training details. Our findings inform discussions on
the origins of the bouba-kiki effect in human cognition and future developments
of VLMs that align well with human cross-modal associations.

æè¦ï¼äººé¡å¨å°æäºæ°å­è©èè¦è¦ºå½¢çéå°æï¼å·ææç¢ºçè·¨æ¨¡æåå¥½ãè­æé¡¯ç¤ºéäºåå¥½æå¨æåçèªè¨èçãèªè¨å­¸ç¿ï¼ä»¥åç¬¦èèæç¾©å°æçèµ·æºä¸­æ®æ¼éè¦çè§è²ãé¨èå¤æ¨¡ææ¨¡åå¨äººå·¥æºæ§é åçèèµ·ï¼ä¾å¦è¦è¦ºåèªè¨ (VLM) æ¨¡åï¼æ­é²éäºæ¨¡åç·¨ç¢¼çè¦è¦ºèªè¨éè¯é¡åï¼ä»¥åå®åæ¯å¦èäººé¡è¡¨å¾µä¸è´ï¼è®å¾è¶ä¾è¶éè¦ãæåå¾äººé¡å¯¦é©ä¸­ç²å¾åç¼ï¼æ¢è¨ä¸¦æ¯è¼åå VLM ä»¥äºè§£ç¾æå¨ç¥ç bouba-kiki ææï¼éæ¯äººé¡èåçè·¨æ¨¡æåå¥½ãæåæ²ææ¾å°æ­¤ææçæ±ºå®æ§è­æï¼ä½æåèªçºçµæå¯è½åæ±ºæ¼æ¨¡åçç¹å¾µï¼ä¾å¦æ¶æ§è¨­è¨ãæ¨¡åå¤§å°åè¨ç·´ç´°ç¯ãæåçç ç©¶çµææå©æ¼è¨è«äººé¡èªç¥ä¸­ bouba-kiki ææçèµ·æºï¼ä»¥åèäººé¡è·¨æ¨¡æéè¯ç¸ç¬¦ç VLM æªä¾ç¼å±ã

##### **Relating the Seemingly Unrelated: Principled Understanding of Generalization for Generative Models in Arithmetic Reasoning Tasks**
2407.17963v1 by Xingcheng Xu, Zibo Zhao, Haipeng Zhang, Yanqing Yang

Large language models (LLMs) have demonstrated impressive versatility across
numerous tasks, yet their generalization capabilities remain poorly understood.
To investigate these behaviors, arithmetic tasks serve as important venues. In
previous studies, seemingly unrelated mysteries still exist -- (1) models with
appropriate positional embeddings can correctly perform longer unseen
arithmetic operations such as addition, but their effectiveness varies in more
complex tasks like multiplication; (2) models perform well for longer unseen
cases in modular addition under specific moduli (e.g., modulo 100) but struggle
under very close moduli (e.g., modulo 101), regardless of the positional
encoding used. We believe previous studies have been treating the symptoms
rather than addressing the root cause -- they have paid excessive attention to
improving model components, while overlooking the differences in task
properties that may be the real drivers. This is confirmed by our unified
theoretical framework for different arithmetic scenarios. For example, unlike
multiplication, the digital addition task has the property of translation
invariance which naturally aligns with the relative positional encoding, and
this combination leads to successful generalization of addition to unseen
longer domains. The discrepancy in operations modulo 100 and 101 arises from
the base. Modulo 100, unlike 101, is compatible with the decimal system (base
10), such that unseen information in digits beyond the units digit and the tens
digit is actually not needed for the task. Extensive experiments with GPT-like
models validate our theoretical predictions. These findings deepen our
understanding of the generalization mechanisms, and facilitate more
data-efficient model training and objective-oriented AI alignment.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²å¨ç¾å¤ä»»åä¸­å±ç¾åºä»¤äººå°è±¡æ·±å»çå¤åè½æ§ï¼ä½å¶æ¦åè½åä»é®®çºäººç¥ãçºäºç ç©¶éäºè¡çºï¼ç®è¡ä»»åæ®æ¼èéè¦çè§è²ãå¨ååçç ç©¶ä¸­ï¼çä¼¼ç¡éçè¬åä»ç¶å­å¨ï¼(1) å·æé©ç¶ä½ç½®åµå¥çæ¨¡åå¯ä»¥æ­£ç¢ºå·è¡è¼é·çæªè¦ç®è¡éç®ï¼ä¾å¦å æ³ï¼ä½å¶å¨ä¹æ³ç­æ´è¤éçä»»åä¸­çææå»ææä¸åï¼(2) æ¨¡åå¨ç¹å®æ¨¡æ¸ (ä¾å¦æ¨¡æ¸ 100) ä¸çè¼é·æªè¦ææ³ä¸­è¡¨ç¾è¯å¥½ï¼ä½å¨éå¸¸æ¥è¿çæ¨¡æ¸ (ä¾å¦æ¨¡æ¸ 101) ä¸å»æéå°å°é£ï¼ç¡è«ä½¿ç¨ä½ç¨®ä½ç½®ç·¨ç¢¼ãæåèªçºååçç ç©¶ä¸ç´å¨æ²»çççï¼èä¸æ¯è§£æ±ºæ ¹æ¬åå ââå®åéåº¦éæ³¨æ¼æ¹é²æ¨¡åçµæé¨åï¼èå¿½è¦äºå¯è½æ¯çæ­£é©åå ç´ çä»»åå±¬æ§å·®ç°ãéä¸é»å·²ç±æåéå°ä¸åç®è¡å ´æ¯æåºççµ±ä¸çè«æ¡æ¶æè­å¯¦ãä¾å¦ï¼èä¹æ³ä¸åï¼æ¸ä½å æ³ä»»åå·æå¹³ç§»ä¸è®æ§çå±¬æ§ï¼éèªç¶èç¸å°ä½ç½®ç·¨ç¢¼ä¸è´ï¼èéç¨®çµåå°è´å æ³æåæ¦åå°æªè¦çè¼é·ç¶²åãæ¨¡æ¸ 100 å 101 éç®ä¸­çå·®ç°æºæ¼åºæ¸ãè 101 ä¸åï¼æ¨¡æ¸ 100 èåé²ä½ç³»çµ± (åºæ¸ 10) ç¸å®¹ï¼å æ­¤å¨åä½æ¸ååä½æ¸ä¹å¤çæ¸å­ä¸­æªè¦çè³è¨å¯¦éä¸å°æ¼ä»»åä¸¦éå¿è¦ãä½¿ç¨é¡ä¼¼ GPT çæ¨¡åé²è¡çå»£æ³å¯¦é©é©è­äºæåççè«é æ¸¬ãéäºç¼ç¾å æ·±äºæåå°æ¦åæ©å¶ççè§£ï¼ä¸¦ä¿é²äºæ´å·è³ææççæ¨¡åè¨ç·´åç®æ¨å°åçäººå·¥æºæ§å°é½ã

##### **The Curious Case of Representational Alignment: Unravelling Visio-Linguistic Tasks in Emergent Communication**
2407.17960v1 by Tom Kouwenhoven, Max Peeperkorn, Bram van Dijk, Tessa Verhoef

Natural language has the universal properties of being compositional and
grounded in reality. The emergence of linguistic properties is often
investigated through simulations of emergent communication in referential
games. However, these experiments have yielded mixed results compared to
similar experiments addressing linguistic properties of human language. Here we
address representational alignment as a potential contributing factor to these
results. Specifically, we assess the representational alignment between agent
image representations and between agent representations and input images. Doing
so, we confirm that the emergent language does not appear to encode human-like
conceptual visual features, since agent image representations drift away from
inputs whilst inter-agent alignment increases. We moreover identify a strong
relationship between inter-agent alignment and topographic similarity, a common
metric for compositionality, and address its consequences. To address these
issues, we introduce an alignment penalty that prevents representational drift
but interestingly does not improve performance on a compositional
discrimination task. Together, our findings emphasise the key role
representational alignment plays in simulations of language emergence.

æè¦ï¼èªç¶èªè¨å·æçµææ§ä¸æ ¹æ¤æ¼ç¾å¯¦çæ®éå±¬æ§ãèªè¨å±¬æ§çåºç¾ç¶å¸¸ééææ¶éæ²ä¸­ç·æ¥æºéçæ¨¡æ¬ä¾èª¿æ¥ãç¶èï¼èæ¢è¨äººé¡èªè¨èªè¨å±¬æ§çé¡ä¼¼å¯¦é©ç¸æ¯ï¼éäºå¯¦é©ç¢çäºä¸åççµæãå¨æ­¤ï¼æåæ¢è¨è¡¨å¾µå°é½ä½çºéäºçµæçæ½å¨ä¿æå ç´ ãå·é«ä¾èªªï¼æåè©ä¼°ä»£çå½±åè¡¨å¾µä¹éä»¥åä»£çè¡¨å¾µèè¼¸å¥å½±åä¹éçè¡¨å¾µå°é½ãéæ¨£åï¼æåç¢ºèªç·æ¥èªè¨ä¼¼ä¹æ²æç·¨ç¢¼é¡äººæ¦å¿µè¦è¦ºç¹å¾µï¼å çºä»£çå½±åè¡¨å¾µåé¢è¼¸å¥ï¼èä»£çéå°é½åå¢å ãæ­¤å¤ï¼æåç¢ºèªä»£çéå°é½èææ²ç¸ä¼¼æ§ï¼çµææ§çå¸¸è¦ææ¨ï¼ä¹éçå¼·å¤§éä¿ï¼ä¸¦æ¢è¨å¶å¾æãçºäºè§£æ±ºéäºåé¡ï¼æåå¼å¥äºé²æ­¢è¡¨å¾µæ¼ç§»çå°é½æ²ç½°ï¼ä½æè¶£çæ¯ï¼éä¸¦æªæåçµææ§åè¾¨ä»»åçè¡¨ç¾ãæåçç¼ç¾å±åå¼·èª¿äºè¡¨å¾µå°é½å¨èªè¨åºç¾æ¨¡æ¬ä¸­æ®æ¼çéè¦è§è²ã

##### **Real Time American Sign Language Detection Using Yolo-v9**
2407.17950v1 by Amna Imran, Meghana Shashishekhara Hulikal, Hamza A. A. Gardi

This paper focuses on real-time American Sign Language Detection. YOLO is a
convolutional neural network (CNN) based model, which was first released in
2015. In recent years, it gained popularity for its real-time detection
capabilities. Our study specifically targets YOLO-v9 model, released in 2024.
As the model is newly introduced, not much work has been done on it, especially
not in Sign Language Detection. Our paper provides deep insight on how YOLO- v9
works and better than previous model.

æè¦ï¼æ¬è«æå°æ³¨æ¼å³æç¾åæèªåµæ¸¬ãYOLO æ¯ä¸ç¨®åºæ¼æ²ç©ç¥ç¶ç¶²è·¯ (CNN) çæ¨¡åï¼ææ©æ¼ 2015 å¹´ç¼å¸ãè¿å¹´ä¾ï¼ç±æ¼å¶å³æåµæ¸¬è½åèå»£åæ­¡è¿ãæåçç ç©¶ç¹å¥éå° 2024 å¹´ç¼å¸ç YOLO-v9 æ¨¡åãç±æ¼è©²æ¨¡åæ¯æ°æ¨åºçï¼å æ­¤å°æªæå¤ªå¤ç ç©¶ï¼ç¹å¥æ¯å¨æèªåµæ¸¬æ¹é¢ãæåçè«ææ·±å¥æ¢è¨äº YOLO-v9 çéä½æ¹å¼ï¼ä¸¦èªªæå¶åªæ¼ååçæ¨¡åã

##### **Positive Text Reframing under Multi-strategy Optimization**
2407.17940v1 by Shutong Jia, Biwei Cao, Qingqing Gao, Jiuxin Cao, Bo Liu

Differing from sentiment transfer, positive reframing seeks to substitute
negative perspectives with positive expressions while preserving the original
meaning. With the emergence of pre-trained language models (PLMs), it is
possible to achieve acceptable results by fine-tuning PLMs. Nevertheless,
generating fluent, diverse and task-constrained reframing text remains a
significant challenge. To tackle this issue, a \textbf{m}ulti-\textbf{s}trategy
\textbf{o}ptimization \textbf{f}ramework (MSOF) is proposed in this paper.
Starting from the objective of positive reframing, we first design positive
sentiment reward and content preservation reward to encourage the model to
transform the negative expressions of the original text while ensuring the
integrity and consistency of the semantics. Then, different decoding
optimization approaches are introduced to improve the quality of text
generation. Finally, based on the modeling formula of positive reframing, we
propose a multi-dimensional re-ranking method that further selects candidate
sentences from three dimensions: strategy consistency, text similarity and
fluency. Extensive experiments on two Seq2Seq PLMs, BART and T5, demonstrate
our framework achieves significant improvements on unconstrained and controlled
positive reframing tasks.

æè¦ï¼èæç·è½ç§»ä¸åï¼æ­£åéæ§è©¦åä»¥æ­£åè¡¨éåä»£è² é¢è§é»ï¼åæä¿çåå§ææãé¨èé è¨ç·´èªè¨æ¨¡å (PLM) çåºç¾ï¼ééå¾®èª¿ PLM å¯ä»¥éæå¯æ¥åççµæãç¶èï¼ç¢çæµæ¢ãå¤æ¨£åä¸ç¬¦åä»»åéå¶çéæ§ææ¬ä»ç¶æ¯ä¸é éå¤§ææ°ãçºäºè§£æ±ºéååé¡ï¼æ¬ææåºäºä¸åå¤ç­ç¥æä½³åæ¡æ¶ (MSOF)ãå¾æ­£åéæ§çç®æ¨éå§ï¼æåé¦åè¨­è¨æ­£åæç·çåµåå§å®¹ä¿ççåµï¼ä»¥é¼åµæ¨¡åè½æåå§ææ¬çè² é¢è¡¨éï¼åæç¢ºä¿èªæçå®æ´æ§åä¸è´æ§ãç¶å¾ï¼å¼å¥ä¸åçè§£ç¢¼æä½³åæ¹æ³ä¾æåææ¬çæçåè³ªãæå¾ï¼åºæ¼æ­£åéæ§çå»ºæ¨¡å¬å¼ï¼æåæåºäºä¸åå¤ç¶­åº¦çéæ°æåºæ¹æ³ï¼å¾ç­ç¥ä¸è´æ§ãæå­ç¸ä¼¼æ§åæµæ¢åº¦ä¸åé¢åé²ä¸æ­¥é¸æåé¸å¥å­ãå¨å©å Seq2Seq PLMï¼BART å T5 ä¸é²è¡çå»£æ³å¯¦é©è­æï¼æåçæ¡æ¶å¨ä¸åéååæ§çæ­£åéæ§ä»»åä¸ç²å¾é¡¯èçæ¹é²ã

##### **Comparison of different Artificial Neural Networks for Bitcoin price forecasting**
2407.17930v1 by Silas Baumann, Karl A. Busch, Hamza A. A. Gardi

This study investigates the impact of varying sequence lengths on the
accuracy of predicting cryptocurrency returns using Artificial Neural Networks
(ANNs). Utilizing the Mean Absolute Error (MAE) as a threshold criterion, we
aim to enhance prediction accuracy by excluding returns that are smaller than
this threshold, thus mitigating errors associated with minor returns. The
subsequent evaluation focuses on the accuracy of predicted returns that exceed
this threshold. We compare four sequence lengths 168 hours (7 days), 72 hours
(3 days), 24 hours, and 12 hours each with a return prediction interval of 2
hours. Our findings reveal the influence of sequence length on prediction
accuracy and underscore the potential for optimized sequence configurations in
financial forecasting models.

æè¦ï¼æ¬ç ç©¶æ¢è¨äºåºåé·åº¦è®ç°å°ä½¿ç¨äººå·¥ç¥ç¶ç¶²è·¯ (ANN) é æ¸¬å å¯è²¨å¹£å ±é¬çæºç¢ºåº¦çå½±é¿ãæåå©ç¨å¹³åçµå°èª¤å·® (MAE) ä½çºé¾å¼æ¨æºï¼æ¨å¨ééæé¤å°æ¼æ­¤é¾å¼çå ±é¬çä¾æåé æ¸¬æºç¢ºåº¦ï¼é²èæ¸è¼èå¾®å°å ±é¬çç¸éçèª¤å·®ãå¾çºè©ä¼°èéæ¼è¶éæ­¤é¾å¼çé æ¸¬å ±é¬çæºç¢ºåº¦ãæåæ¯è¼äºåç¨®åºåé·åº¦ï¼168 å°æ (7 å¤©)ã72 å°æ (3 å¤©)ã24 å°æå 12 å°æï¼æ¯ååºåé·åº¦æ­é 2 å°æçå ±é¬çé æ¸¬åéãæåçç¼ç¾æ­ç¤ºäºåºåé·åº¦å°é æ¸¬æºç¢ºåº¦çå½±é¿ï¼ä¸¦å¼·èª¿äºå¨è²¡åé æ¸¬æ¨¡åä¸­åªååºåçµæçæ½åã

##### **Invariance of deep image quality metrics to affine transformations**
2407.17927v1 by Nuria Alabau-Bosque, Paula DaudÃ©n-Oliver, Jorge Vila-TomÃ¡s, Valero Laparra, JesÃºs Malo

Deep architectures are the current state-of-the-art in predicting subjective
image quality. Usually, these models are evaluated according to their ability
to correlate with human opinion in databases with a range of distortions that
may appear in digital media. However, these oversee affine transformations
which may represent better the changes in the images actually happening in
natural conditions. Humans can be particularly invariant to these natural
transformations, as opposed to the digital ones. In this work, we evaluate
state-of-the-art deep image quality metrics by assessing their invariance to
affine transformations, specifically: rotation, translation, scaling, and
changes in spectral illumination. We propose a methodology to assign
invisibility thresholds for any perceptual metric. This methodology involves
transforming the distance measured by an arbitrary metric to a common distance
representation based on available subjectively rated databases. We
psychophysically measure an absolute detection threshold in that common
representation and express it in the physical units of each affine transform
for each metric. By doing so, we allow the analyzed metrics to be directly
comparable with actual human thresholds. We find that none of the
state-of-the-art metrics shows human-like results under this strong test based
on invisibility thresholds. This means that tuning the models exclusively to
predict the visibility of generic distortions may disregard other properties of
human vision as for instance invariances or invisibility thresholds.

æè¦ï¼æ·±åº¦æ¶æ§æ¯ç®åé æ¸¬ä¸»è§å½±ååè³ªçææ°æè¡ãéå¸¸ï¼éäºæ¨¡åææ ¹æå®åèäººé¡æè¦å¨åå«å¯è½åºç¾å¨æ¸ä½åªé«ä¸­åç¨®å¤±çç¯åçè³æåº«ä¸­ç¸éè¯çè½åä¾è©ä¼°ãç¶èï¼éäºæ¨¡åæå¿½ç¥ä»¿å°è½æï¼èä»¿å°è½æå¯ä»¥æ´å¥½å°è¡¨ç¤ºå¨èªç¶æ¢ä»¶ä¸å¯¦éç¼ççå½±åè®åãèæ¸ä½è½æç¸æ¯ï¼äººé¡å°éäºèªç¶è½æå¯è½ç¹å¥ä¸è®ãå¨éé å·¥ä½ä¸­ï¼æåééè©ä¼°å®åå°ä»¿å°è½æçä¸è®æ§ä¾è©ä¼°æåé²çæ·±åº¦å½±ååè³ªææ¨ï¼ç¹å¥æ¯ï¼æè½ãå¹³ç§»ãç¸®æ¾ååè­ç§æçè®åãæåæåºäºä¸ç¨®æ¹æ³ä¾çºä»»ä½æç¥ææ¨åéä¸å¯è¦é¾å¼ãæ­¤æ¹æ³æ¶åå°ä»»æææ¨æ¸¬éçè·é¢è½æçºåºæ¼å¯ç¨ä¸»è§è©åè³æåº«çå±åè·é¢è¡¨ç¤ºãæåå¨è©²å±åè¡¨ç¤ºä¸­ä»¥å¿çç©çå­¸çæ¹å¼æ¸¬éçµå°æª¢æ¸¬é¾å¼ï¼ä¸¦éå°æ¯åææ¨ä»¥æ¯åä»¿å°è½æçç©çå®ä½è¡¨ç¤ºãééééº¼åï¼æåè®åæçææ¨å¯ä»¥ç´æ¥èå¯¦éçäººé¡é¾å¼é²è¡æ¯è¼ãæåç¼ç¾ï¼å¨åºæ¼ä¸å¯è¦é¾å¼çå´æ ¼æ¸¬è©¦ä¸­ï¼æ²æä»»ä½æåé²çææ¨é¡¯ç¤ºåºé¡ä¼¼äººé¡ççµæãéè¡¨ç¤ºåèª¿æ´æ¨¡åä»¥é æ¸¬ä¸è¬å¤±ççå¯è¦æ§å¯è½æå¿½ç¥äººé¡è¦è¦ºçå¶ä»ç¹æ§ï¼ä¾å¦ä¸è®æ§æä¸å¯è¦é¾å¼ã

##### **The Dark Side of Function Calling: Pathways to Jailbreaking Large Language Models**
2407.17915v1 by Zihui Wu, Haichang Gao, Jianping He, Ping Wang

Large language models (LLMs) have demonstrated remarkable capabilities, but
their power comes with significant security considerations. While extensive
research has been conducted on the safety of LLMs in chat mode, the security
implications of their function calling feature have been largely overlooked.
This paper uncovers a critical vulnerability in the function calling process of
LLMs, introducing a novel "jailbreak function" attack method that exploits
alignment discrepancies, user coercion, and the absence of rigorous safety
filters. Our empirical study, conducted on six state-of-the-art LLMs including
GPT-4o, Claude-3.5-Sonnet, and Gemini-1.5-pro, reveals an alarming average
success rate of over 90\% for this attack. We provide a comprehensive analysis
of why function calls are susceptible to such attacks and propose defensive
strategies, including the use of defensive prompts. Our findings highlight the
urgent need for enhanced security measures in the function calling capabilities
of LLMs, contributing to the field of AI safety by identifying a previously
unexplored risk, designing an effective attack method, and suggesting practical
defensive measures. Our code is available at
https://github.com/wooozihui/jailbreakfunction.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²å±ç¤ºåºéå¡çè½åï¼ä½å¶è½åä¼´é¨èéå¤§çå®å¨èéãåç®¡å·²å°èå¤©æ¨¡å¼ä¸­ LLM çå®å¨æ§é²è¡å»£æ³çç ç©¶ï¼ä½å¶å½æ¸å¼å«åè½çå®å¨å½±é¿å»å¨å¾å¤§ç¨åº¦ä¸è¢«å¿½è¦ãæ¬ææ­é²äº LLM å½æ¸å¼å«éç¨ä¸­çä¸åéå¤§æ¼æ´ï¼å¼å¥äºä¸ç¨®æ°çãè¶çå½æ¸ãæ»ææ¹æ³ï¼è©²æ¹æ³å©ç¨å°é½å·®ç°ãä½¿ç¨èå¼·å¶åç¼ºä¹å´æ ¼çå®å¨éæ¿¾å¨ãæåéå°å­ç¨®æåé²ç LLMï¼åæ¬ GPT-4oãClaude-3.5-Sonnet å Gemini-1.5-proï¼é²è¡çå¯¦è­ç ç©¶é¡¯ç¤ºï¼éç¨®æ»æçå¹³åæåçé«é 90%ï¼ä»¤äººå ªæãæåæä¾äºå½æ¸å¼å«å®¹æåå°æ­¤é¡æ»æçåå çå¨é¢åæï¼ä¸¦æåºäºé²ç¦¦ç­ç¥ï¼åæ¬ä½¿ç¨é²ç¦¦æç¤ºãæåçç ç©¶çµæå¼·èª¿äºè¿«åéè¦å¢å¼· LLM å½æ¸å¼å«åè½ä¸­çå®å¨æªæ½ï¼ééè­å¥ä»¥åæªæ¢ç´¢çé¢¨éªãè¨­è¨ææçæ»ææ¹æ³åå»ºè­°å¯¦ç¨çé²ç¦¦æªæ½ï¼çº AI å®å¨é åååºè²¢ç»ãæåçç¨å¼ç¢¼å¯å¨ https://github.com/wooozihui/jailbreakfunction åå¾ã

##### **Modelling Multimodal Integration in Human Concept Processing with Vision-and-Language Models**
2407.17914v1 by Anna Bavaresco, Marianne de Heer Kloots, Sandro Pezzelle, Raquel FernÃ¡ndez

Representations from deep neural networks (DNNs) have proven remarkably
predictive of neural activity involved in both visual and linguistic
processing. Despite these successes, most studies to date concern unimodal
DNNs, encoding either visual or textual input but not both. Yet, there is
growing evidence that human meaning representations integrate linguistic and
sensory-motor information. Here we investigate whether the integration of
multimodal information operated by current vision-and-language DNN models
(VLMs) leads to representations that are more aligned with human brain activity
than those obtained by language-only and vision-only DNNs. We focus on fMRI
responses recorded while participants read concept words in the context of
either a full sentence or an accompanying picture. Our results reveal that VLM
representations correlate more strongly than language- and vision-only DNNs
with activations in brain areas functionally related to language processing. A
comparison between different types of visuo-linguistic architectures shows that
recent generative VLMs tend to be less brain-aligned than previous
architectures with lower performance on downstream applications. Moreover,
through an additional analysis comparing brain vs. behavioural alignment across
multiple VLMs, we show that -- with one remarkable exception -- representations
that strongly align with behavioural judgments do not correlate highly with
brain responses. This indicates that brain similarity does not go hand in hand
with behavioural similarity, and vice versa.

æè¦ï¼æ·±åº¦ç¥ç»ç½ç» (DNN) çè¡¨å¾å·²è¯æå¯ä»¥æ¾èé¢æµè§è§åè¯­è¨å¤çä¸­æ¶åçç¥ç»æ´»å¨ãå°½ç®¡åå¾äºè¿äºæåï¼ä½è¿ä»ä¸ºæ­¢å¤§å¤æ°ç ç©¶é½æ¶ååæ¨¡æ DNNï¼ä»å¯¹è§è§æææ¬è¾å¥è¿è¡ç¼ç ï¼èä¸æ¯ä¸¤èé½è¿è¡ç¼ç ãç¶èï¼è¶æ¥è¶å¤çè¯æ®è¡¨æï¼äººç±»çæä¹è¡¨å¾æ´åäºè¯­è¨åæè§è¿å¨ä¿¡æ¯ãå¨æ­¤ï¼æä»¬ç ç©¶äºç±å½åè§è§è¯­è¨ DNN æ¨¡å (VLM) è¿è¥çå¤æ¨¡æä¿¡æ¯æ´åæ¯å¦å¯¼è´äºä¸äººç±»å¤§èæ´»å¨æ´ä¸è´çè¡¨å¾ï¼èä¸æ¯ä»éè¿è¯­è¨åä»éè¿è§è§ç DNN è·å¾çè¡¨å¾ãæä»¬ä¸æ³¨äºå¨åä¸èå¨å®æ´å¥å­æéå¸¦å¾ççä¸ä¸æä¸­éè¯»æ¦å¿µè¯æ¶è®°å½ç fMRI ååºãæä»¬çç»æè¡¨æï¼VLM è¡¨å¾ä¸è¯­è¨åä»è§è§ DNN æ´å¼ºçå°ç¸å³ï¼ä¸åè½ä¸ä¸è¯­è¨å¤çç¸å³çèåºæ¿æ´»ç¸å³ãä¸åç±»åè§è§è¯­è¨æ¶æä¹é´çæ¯è¾è¡¨æï¼æè¿ççæå¼ VLM å¾å¾æ¯ä»¥åå¨ä¸æ¸¸åºç¨ç¨åºä¸æ§è½è¾ä½çæ¶æä¸å¤§èå¯¹é½ç¨åº¦è¾ä½ãæ­¤å¤ï¼éè¿æ¯è¾å¤ä¸ª VLM ä¸­å¤§èä¸è¡ä¸ºå¯¹é½çéå åæï¼æä»¬è¡¨æââæä¸ä¸ªæ¾ççä¾å¤ââä¸è¡ä¸ºå¤æ­å¼ºçå¯¹é½çè¡¨å¾ä¸å¤§èååºæ²¡æé«åº¦ç¸å³æ§ãè¿è¡¨æå¤§èç¸ä¼¼æ§ä¸è¡ä¸ºç¸ä¼¼æ§å¹¶ä¸é½å¤´å¹¶è¿ï¼åä¹äº¦ç¶ã

##### **ReCorD: Reasoning and Correcting Diffusion for HOI Generation**
2407.17911v1 by Jian-Yu Jiang-Lin, Kang-Yang Huang, Ling Lo, Yi-Ning Huang, Terence Lin, Jhih-Ciang Wu, Hong-Han Shuai, Wen-Huang Cheng

Diffusion models revolutionize image generation by leveraging natural
language to guide the creation of multimedia content. Despite significant
advancements in such generative models, challenges persist in depicting
detailed human-object interactions, especially regarding pose and object
placement accuracy. We introduce a training-free method named Reasoning and
Correcting Diffusion (ReCorD) to address these challenges. Our model couples
Latent Diffusion Models with Visual Language Models to refine the generation
process, ensuring precise depictions of HOIs. We propose an interaction-aware
reasoning module to improve the interpretation of the interaction, along with
an interaction correcting module to refine the output image for more precise
HOI generation delicately. Through a meticulous process of pose selection and
object positioning, ReCorD achieves superior fidelity in generated images while
efficiently reducing computational requirements. We conduct comprehensive
experiments on three benchmarks to demonstrate the significant progress in
solving text-to-image generation tasks, showcasing ReCorD's ability to render
complex interactions accurately by outperforming existing methods in HOI
classification score, as well as FID and Verb CLIP-Score. Project website is
available at https://alberthkyhky.github.io/ReCorD/ .

æè¦ï¼æ´æ£æ¨¡åééå©ç¨èªç¶èªè¨ä¾å¼å°å¤åªé«å§å®¹çå»ºç«ï¼é²èé©æ°äºå½±åçæãåç®¡æ­¤é¡çææ¨¡åå·²æé¡¯èçé²å±ï¼ä½å¨æç¹ªè©³ç´°çäººé¡-ç©ä»¶äºåæ¹é¢ä»å­å¨ææ°ï¼ç¹å¥æ¯å¨å§¿å¢åç©ä»¶æ¾ç½®çæºç¢ºæ§ä¸ãæåæåºäºä¸ç¨®åçºæ¨çèä¿®æ­£æ´æ£ (ReCorD) çç¡è¨ç·´æ¹æ³ä¾è§£æ±ºéäºææ°ãæåçæ¨¡åå°æ½å¨æ´æ£æ¨¡åèè¦è¦ºèªè¨æ¨¡åçµåï¼ä»¥åªåçæéç¨ï¼ç¢ºä¿ç²¾ç¢ºæç¹ª HOIãæåæåºäºä¸åäºåæç¥æ¨çæ¨¡çµä¾æ¹åäºåçè©®éï¼ä¸¦æåºäºä¸åäºåä¿®æ­£æ¨¡çµä¾åªåè¼¸åºå½±åï¼ä»¥æ´ç²¾ç¢ºå°çæ HOIãééå§¿å¢é¸æåç©ä»¶å®ä½çç´°ç·»éç¨ï¼ReCorD å¨çæçå½±åä¸­éå°äºæ´é«çä¿çåº¦ï¼åæææå°éä½äºéç®éæ±ãæåå¨ä¸ååºæºä¸é²è¡äºå¨é¢çå¯¦é©ï¼ä»¥å±ç¤ºå¨è§£æ±ºæå­å°å½±åçæä»»åæ¹é¢åå¾çé¡¯èé²å±ï¼å±ç¤ºäº ReCorD å¨ HOI åé¡åæ¸ä»¥å FID ååè© CLIP åæ¸æ¹é¢åªæ¼ç¾ææ¹æ³ï¼æºç¢ºåç¾è¤éäºåçè½åãå°æ¡ç¶²ç«å¯æ¼ https://alberthkyhky.github.io/ReCorD/ åå¾ã

##### **The Power of Combining Data and Knowledge: GPT-4o is an Effective Interpreter of Machine Learning Models in Predicting Lymph Node Metastasis of Lung Cancer**
2407.17900v1 by Danqing Hu, Bing Liu, Xiaofeng Zhu, Nan Wu

Lymph node metastasis (LNM) is a crucial factor in determining the initial
treatment for patients with lung cancer, yet accurate preoperative diagnosis of
LNM remains challenging. Recently, large language models (LLMs) have garnered
significant attention due to their remarkable text generation capabilities.
Leveraging the extensive medical knowledge learned from vast corpora, LLMs can
estimate probabilities for clinical problems, though their performance has
historically been inferior to data-driven machine learning models. In this
paper, we propose a novel ensemble method that combines the medical knowledge
acquired by LLMs with the latent patterns identified by machine learning models
to enhance LNM prediction performance. Initially, we developed machine learning
models using patient data. We then designed a prompt template to integrate the
patient data with the predicted probability from the machine learning model.
Subsequently, we instructed GPT-4o, the most advanced LLM developed by OpenAI,
to estimate the likelihood of LNM based on patient data and then adjust the
estimate using the machine learning output. Finally, we collected three outputs
from the GPT-4o using the same prompt and ensembled these results as the final
prediction. Using the proposed method, our models achieved an AUC value of
0.765 and an AP value of 0.415 for LNM prediction, significantly improving
predictive performance compared to baseline machine learning models. The
experimental results indicate that GPT-4o can effectively leverage its medical
knowledge and the probabilities predicted by machine learning models to achieve
more accurate LNM predictions. These findings demonstrate that LLMs can perform
well in clinical risk prediction tasks, offering a new paradigm for integrating
medical knowledge and patient data in clinical predictions.

æè¦ï¼æ·å·´çµè½ç§» (LNM) æ¯æ±ºå®èºçæ£èåå§æ²»ççééµå ç´ ï¼ä½æºç¢ºçè¡å LNM è¨ºæ·ä»ç¶å·æææ°æ§ãæè¿ï¼å¤§åèªè¨æ¨¡å (LLM) å å¶åè¶çææ¬çæè½åèååéæ³¨ãå©ç¨å¾é¾å¤§èªæåº«ä¸­å­¸ç¿å°çå»£æ³é«å­¸ç¥è­ï¼LLM å¯ä»¥ä¼°è¨è¨åºåé¡çæ©çï¼åç®¡å®åçè¡¨ç¾æ­·ä¾ä¸å¦æ¸æé©åçæ©å¨å­¸ç¿æ¨¡åãå¨æ¬æä¸­ï¼æåæåºäºä¸ç¨®æ°ç©çéææ¹æ³ï¼å° LLM ç²å¾çé«å­¸ç¥è­èæ©å¨å­¸ç¿æ¨¡åè­å¥çæ½å¨æ¨¡å¼ç¸çµåï¼ä»¥å¢å¼· LNM é æ¸¬æ§è½ãæåï¼æåä½¿ç¨æ£èæ¸æéç¼äºæ©å¨å­¸ç¿æ¨¡åãç¶å¾ï¼æåè¨­è¨äºä¸åæç¤ºæ¨¡æ¿ï¼å°æ£èæ¸æèæ©å¨å­¸ç¿æ¨¡åçé æ¸¬æ©çç¸çµåãé¨å¾ï¼æåæç¤º OpenAI éç¼çæåé² LLM GPT-4o æ ¹ææ£èæ¸æä¼°è¨ LNM çå¯è½æ§ï¼ç¶å¾ä½¿ç¨æ©å¨å­¸ç¿è¼¸åºèª¿æ´ä¼°è¨ãæå¾ï¼æåä½¿ç¨ç¸åçæç¤ºå¾ GPT-4o æ¶éäºä¸åè¼¸åºï¼ä¸¦å°éäºçµæä½çºæçµé æ¸¬é²è¡éæãä½¿ç¨ææåºçæ¹æ³ï¼æåçæ¨¡åå¨ LNM é æ¸¬ä¸­å¯¦ç¾äº 0.765 ç AUC å¼å 0.415 ç AP å¼ï¼èåºç·æ©å¨å­¸ç¿æ¨¡åç¸æ¯ï¼é æ¸¬æ§è½é¡¯èæé«ãå¯¦é©çµæè¡¨æï¼GPT-4o å¯ä»¥ææå©ç¨å¶é«å­¸ç¥è­åæ©å¨å­¸ç¿æ¨¡åé æ¸¬çæ©çä¾å¯¦ç¾æ´æºç¢ºç LNM é æ¸¬ãéäºç¼ç¾è¡¨æï¼LLM å¯ä»¥å¾å¥½å°å·è¡è¨åºé¢¨éªé æ¸¬ä»»åï¼çºæ´åè¨åºé æ¸¬ä¸­çé«å­¸ç¥è­åæ£èæ¸ææä¾äºä¸åæ°çç¯ä¾ã

##### **3D Hole Filling using Deep Learning Inpainting**
2407.17896v1 by Marina HernÃ¡ndez-Bautista, F. J. Melero

The current work presents a novel methodology for completing 3D surfaces
produced from 3D digitization technologies in places where there is a scarcity
of meaningful geometric data. Incomplete or missing data in these
three-dimensional (3D) models can lead to erroneous or flawed renderings,
limiting their usefulness in a variety of applications such as visualization,
geometric computation, and 3D printing. Conventional surface estimation
approaches often produce implausible results, especially when dealing with
complex surfaces. To address this issue, we propose a technique that
incorporates neural network-based 2D inpainting to effectively reconstruct 3D
surfaces. Our customized neural networks were trained on a dataset containing
over 1 million curvature images. These images show the curvature of vertices as
planar representations in 2D. Furthermore, we used a coarse-to-fine surface
deformation technique to improve the accuracy of the reconstructed pictures and
assure surface adaptability. This strategy enables the system to learn and
generalize patterns from input data, resulting in the development of precise
and comprehensive three-dimensional surfaces. Our methodology excels in the
shape completion process, effectively filling complex holes in
three-dimensional surfaces with a remarkable level of realism and precision.

æè¦ï¼æ¬ç ç©¶æåºäºä¸ç¨®æ°ç©çæ¹æ³ï¼ç¨æ¼å¨ææç¾©çå¹¾ä½æ¸æç¨ç¼ºçå°æ¹ï¼å®æç± 3D æ¸ä½åæè¡ç¢çç 3D è¡¨é¢ãéäºä¸ç¶­ (3D) æ¨¡åä¸­çä¸å®æ´æéºå¤±æ¸æå¯è½æå°è´é¯èª¤ææç¼ºé·çæ¸²æï¼éå¶äºå®åå¨å¯è¦åãå¹¾ä½è¨ç®å 3D åå°ç­åç¨®æç¨ä¸­çå¯¦ç¨æ§ãå³çµ±çæ²é¢ä¼°è¨æ¹æ³éå¸¸æç¢çé£ä»¥ç½®ä¿¡ççµæï¼ç¹å¥æ¯å¨èçè¤éæ²é¢æãçºäºè§£æ±ºéååé¡ï¼æåæåºäºä¸ç¨®æè¡ï¼çµåäºåºæ¼ç¥ç¶ç¶²è·¯ç 2D ä¿®è£ï¼ä»¥ææéå»º 3D æ²é¢ãæåçå®¢è£½åç¥ç¶ç¶²è·¯æ¯å¨åå«è¶é 100 è¬åæ²çå½±åçè³æéä¸è¨ç·´çãéäºå½±åé¡¯ç¤ºäºé é»çæ²çï¼ä½çº 2D ä¸­çå¹³é¢è¡¨ç¤ºãæ­¤å¤ï¼æåä½¿ç¨ç±ç²å°ç´°çæ²é¢è®å½¢æè¡ä¾æé«éå»ºå½±åçæºç¢ºæ§ï¼ä¸¦ç¢ºä¿æ²é¢é©ææ§ãæ­¤ç­ç¥ä½¿ç³»çµ±è½å¤ å¾è¼¸å¥æ¸æä¸­å­¸ç¿åæ¦æ¬æ¨¡å¼ï¼å¾èéç¼åºç²¾ç¢ºä¸å¨é¢çä¸ç¶­æ²é¢ãæåçæè¡å¨å½¢çå®æéç¨ä¸­è¡¨ç¾åºè²ï¼ææå°å¡«è£äºä¸ç¶­æ²é¢ä¸­è¤éçå­æ´ï¼å·æé¡¯èççå¯¦æ§åæºç¢ºæ§ã

##### **An Iterative Approach to Topic Modelling**
2407.17892v1 by Albert Wong, Florence Wing Yau Cheng, Ashley Keung, Yamileth Hercules, Mary Alexandra Garcia, Yew-Wei Lim, Lien Pham

Topic modelling has become increasingly popular for summarizing text data,
such as social media posts and articles. However, topic modelling is usually
completed in one shot. Assessing the quality of resulting topics is
challenging. No effective methods or measures have been developed for assessing
the results or for making further enhancements to the topics. In this research,
we propose we propose to use an iterative process to perform topic modelling
that gives rise to a sense of completeness of the resulting topics when the
process is complete. Using the BERTopic package, a popular method in topic
modelling, we demonstrate how the modelling process can be applied iteratively
to arrive at a set of topics that could not be further improved upon using one
of the three selected measures for clustering comparison as the decision
criteria. This demonstration is conducted using a subset of the COVIDSenti-A
dataset. The early success leads us to believe that further research using in
using this approach in conjunction with other topic modelling algorithms could
be viable.

æè¦ï¼ä¸»é¡å»ºæ¨¡å¨ç¸½çµæå­è³æä¸è¶ä¾è¶åæ­¡è¿ï¼ä¾å¦ç¤¾ç¾¤åªé«è²¼æåæç« ãç¶èï¼ä¸»é¡å»ºæ¨¡éå¸¸ä¸æ¬¡å®æãè©ä¼°ç¢åºä¸»é¡çåè³ªå·æææ°æ§ãå°æªç¼å±åºææçæ¹æ³ææªæ½ä¾è©ä¼°çµææé²ä¸æ­¥å¢å¼·ä¸»é¡ãå¨éé ç ç©¶ä¸­ï¼æåæè­°ä½¿ç¨åè¦éç®èçä¾å·è¡ä¸»é¡å»ºæ¨¡ï¼å¨èçå®æææç¢ççµæä¸»é¡çå®æ´æ§ãä½¿ç¨ä¸»é¡å»ºæ¨¡ä¸­å¸¸è¦çæ¹æ³ BERTopic å¥ä»¶ï¼æåç¤ºç¯å¦ä½åè¦å¥ç¨å»ºæ¨¡èçï¼ä»¥å¾åºç¡æ³ä½¿ç¨ä¸åé¸å®çç¾¤éæ¯è¼æ¸¬éæ¨æºä¹ä¸ä½çºæ±ºç­æºåé²ä¸æ­¥æ¹åçä¸»é¡éãæ­¤ç¤ºç¯ä½¿ç¨ COVIDSenti-A è³æéçå­éé²è¡ãæ©æçæåè®æåç¸ä¿¡ï¼ä½¿ç¨éç¨®æ¹æ³èå¶ä»ä¸»é¡å»ºæ¨¡æ¼ç®æ³çµåé²ä¸æ­¥ç ç©¶æ¯å¯è¡çã

##### **Unraveling the Never-Ending Story of Lifecycles and Vitalizing Processes**
2407.17881v1 by Stephan A. Fahrenkrog-Petersen, Saimir Bala, Luise Pufahl, Jan Mendling

Business process management (BPM) has been widely used to discover, model,
analyze, and optimize organizational processes. BPM looks at these processes
with analysis techniques that assume a clearly defined start and end. However,
not all processes adhere to this logic, with the consequence that their
behavior cannot be appropriately captured by BPM analysis techniques. This
paper addresses this research problem at a conceptual level. More specifically,
we introduce the notion of vitalizing business processes that target the
lifecycle process of one or more entities. We show the existence of lifecycle
processes in many industries and that their appropriate conceptualizations pave
the way for the definition of suitable modeling and analysis techniques. This
paper provides a set of requirements for their analysis, and a
conceptualization of lifecycle and vitalizing processes.

æè¦ï¼æ¥­åæµç¨ç®¡ç (BPM) å·²å»£æ³ç¨æ¼ç¼ç¾ãå»ºæ¨¡ãåæåæä½³åçµç¹æµç¨ãBPM ä»¥åææè¡å¯©è¦éäºæµç¨ï¼åè¨­æä¸åæç¢ºå®ç¾©çéå§åçµæãç¶èï¼ä¸¦éæææµç¨é½éµå¾ªæ­¤éè¼¯ï¼å¶å¾ææ¯ BPM åææè¡ç¡æ³é©ç¶å°æ·åå¶è¡çºãæ¬æå¨æ¦å¿µå±¤é¢ä¸æ¢è¨æ­¤ç ç©¶åé¡ãæ´å·é«å°èªªï¼æåå¼å¥äºæ¿åµæ¥­åæµç¨çæ¦å¿µï¼å¶ç®æ¨æ¯éå°ä¸åæå¤åå¯¦é«ççå½é±ææµç¨ãæåå±ç¤ºäºè¨±å¤ç¢æ¥­ä¸­çå½é±ææµç¨çå­å¨ï¼èå¶é©ç¶çæ¦å¿µåçºå®ç¾©åé©çå»ºæ¨¡ååææè¡éªå¹³äºéè·¯ãæ¬ææä¾äºä¸çµåæè¦æ±ï¼ä»¥åçå½é±æåæ¿åµæµç¨çæ¦å¿µåã

##### **A Large-Scale Sensitivity Analysis on Latent Embeddings and Dimensionality Reductions for Text Spatializations**
2407.17876v1 by Daniel Atzberger, Tim Cech, Willy Scheibel, JÃ¼rgen DÃ¶llner, Michael Behrisch, Tobias Schreck

The semantic similarity between documents of a text corpus can be visualized
using map-like metaphors based on two-dimensional scatterplot layouts. These
layouts result from a dimensionality reduction on the document-term matrix or a
representation within a latent embedding, including topic models. Thereby, the
resulting layout depends on the input data and hyperparameters of the
dimensionality reduction and is therefore affected by changes in them.
Furthermore, the resulting layout is affected by changes in the input data and
hyperparameters of the dimensionality reduction. However, such changes to the
layout require additional cognitive efforts from the user. In this work, we
present a sensitivity study that analyzes the stability of these layouts
concerning (1) changes in the text corpora, (2) changes in the hyperparameter,
and (3) randomness in the initialization. Our approach has two stages: data
measurement and data analysis. First, we derived layouts for the combination of
three text corpora and six text embeddings and a grid-search-inspired
hyperparameter selection of the dimensionality reductions. Afterward, we
quantified the similarity of the layouts through ten metrics, concerning local
and global structures and class separation. Second, we analyzed the resulting
42817 tabular data points in a descriptive statistical analysis. From this, we
derived guidelines for informed decisions on the layout algorithm and highlight
specific hyperparameter settings. We provide our implementation as a Git
repository at
https://github.com/hpicgs/Topic-Models-and-Dimensionality-Reduction-Sensitivity-Study
and results as Zenodo archive at https://doi.org/10.5281/zenodo.12772898.

æè¦ï¼<paragraph>ææ¬è¯­æåºä¸­æä»¶ä¹é´çè¯­ä¹ç¸ä¼¼æ§å¯ä»¥ä½¿ç¨åºäºäºç»´æ£ç¹å¾å¸å±çå°å¾ç±»æ¯æ¥å¯è§åãè¿äºå¸å±æºèªææ¡£æ¯è¯­ç©éµä¸çéç»´ææ½å¨åµå¥ä¸­çè¡¨ç¤ºï¼åæ¬ä¸»é¢æ¨¡åãå æ­¤ï¼çæçå¸å±åå³äºéç»´çè¾å¥æ°æ®åè¶åæ°ï¼å æ­¤ä¼åå°å®ä»¬çæ´æ¹çå½±åãæ­¤å¤ï¼çæçå¸å±ä¼åå°è¾å¥æ°æ®åéç»´è¶åæ°æ´æ¹çå½±åãç¶èï¼å¸å±çæ­¤ç±»æ´æ¹éè¦ç¨æ·ä»åºé¢å¤çè®¤ç¥åªåãå¨è¿é¡¹å·¥ä½ä¸­ï¼æä»¬æåºäºä¸é¡¹æææ§ç ç©¶ï¼åæäºè¿äºå¸å±å¨ (1) ææ¬è¯­æåºçååã(2) è¶åæ°çååä»¥å (3) åå§åçéæºæ§æ¹é¢çç¨³å®æ§ãæä»¬çæ¹æ³æä¸¤ä¸ªé¶æ®µï¼æ°æ®æµéåæ°æ®åæãé¦åï¼æä»¬å¯¼åºäºä¸ä¸ªææ¬è¯­æåºåå­ä¸ªææ¬åµå¥ç»åçå¸å±ï¼ä»¥åéç»´çç½æ ¼æç´¢å¯åè¶åæ°éæ©ãä¹åï¼æä»¬éè¿åä¸ªææ éåäºå¸å±çç¸ä¼¼æ§ï¼æ¶åå±é¨åå¨å±ç»æä»¥åç±»åç¦»ãå¶æ¬¡ï¼æä»¬å¨æè¿°æ§ç»è®¡åæä¸­åæäºçæç 42817 ä¸ªè¡¨æ ¼æ°æ®ç¹ãç±æ­¤ï¼æä»¬å¾åºäºæå³å¸å±ç®æ³çææºå³ç­æåï¼å¹¶éç¹ä»ç»äºç¹å®çè¶åæ°è®¾ç½®ãæä»¬å¨ Git å­å¨åºä¸­æä¾äºæä»¬çå®ç°ï¼ç½åä¸º https://github.com/hpicgs/Topic-Models-and-Dimensionality-Reduction-Sensitivity-Studyï¼å¹¶å¨ Zenodo å­æ¡£ä¸­æä¾äºç»æï¼ç½åä¸º https://doi.org/10.5281/zenodo.12772898ã</paragraph>

##### **Improving Domain-Specific ASR with LLM-Generated Contextual Descriptions**
2407.17874v1 by Jiwon Suh, Injae Na, Woohwan Jung

End-to-end automatic speech recognition (E2E ASR) systems have significantly
improved speech recognition through training on extensive datasets. Despite
these advancements, they still struggle to accurately recognize domain specific
words, such as proper nouns and technical terminologies. To address this
problem, we propose a method to utilize the state-of-the-art Whisper without
modifying its architecture, preserving its generalization performance while
enabling it to leverage descriptions effectively. Moreover, we propose two
additional training techniques to improve the domain specific ASR: decoder
fine-tuning, and context perturbation. We also propose a method to use a Large
Language Model (LLM) to generate descriptions with simple metadata, when
descriptions are unavailable. Our experiments demonstrate that proposed methods
notably enhance domain-specific ASR accuracy on real-life datasets, with
LLM-generated descriptions outperforming human-crafted ones in effectiveness.

æè¦ï¼ç«¯å°ç«¯èªåèªé³è¾¨è­ (E2E ASR) ç³»çµ±ééå¨å»£æ³çè³æéä¸è¨ç·´ï¼å¤§å¹æåäºèªé³è¾¨è­è½åãåç®¡æéäºé²å±ï¼å®åå¨æºç¢ºè¾¨è­ç¹å®é åçè©å½ï¼ä¾å¦å°æåè©åæè¡è¡èªï¼æ¹é¢ä»æå°é£ãçºäºè§£æ±ºéååé¡ï¼æåæåºäºä¸ç¨®æ¹æ³ï¼å©ç¨æåé²ç Whisperï¼èç¡éä¿®æ¹å¶æ¶æ§ï¼ä¿çå¶æ³åæè½ï¼åæè®å®è½ææå©ç¨æè¿°ãæ­¤å¤ï¼æåæåºäºå©ç¨®é¡å¤çè¨ç·´æè¡ä¾æ¹åç¹å®é åç ASRï¼è§£ç¢¼å¨å¾®èª¿åèçµ¡æ¾åãæåéæåºäºä¸ç¨®æ¹æ³ï¼å¨æ²ææè¿°æï¼ä½¿ç¨å¤§åèªè¨æ¨¡å (LLM) ä¾ç¢çå·æç°¡å®åè³æçæè¿°ãæåçå¯¦é©è­æï¼ææåºçæ¹æ³é¡¯èæåäºçå¯¦è³æéä¸çç¹å®é å ASR æºç¢ºåº¦ï¼ç± LLM ç¢ççæè¿°å¨æææ§æ¹é¢åªæ¼äººå·¥æ°å¯«çæè¿°ã

##### **Is the Digital Forensics and Incident Response Pipeline Ready for Text-Based Threats in LLM Era?**
2407.17870v1 by Avanti Bhandarkar, Ronald Wilson, Anushka Swarup, Mengdi Zhu, Damon Woodard

In the era of generative AI, the widespread adoption of Neural Text
Generators (NTGs) presents new cybersecurity challenges, particularly within
the realms of Digital Forensics and Incident Response (DFIR). These challenges
primarily involve the detection and attribution of sources behind advanced
attacks like spearphishing and disinformation campaigns. As NTGs evolve, the
task of distinguishing between human and NTG-authored texts becomes critically
complex. This paper rigorously evaluates the DFIR pipeline tailored for
text-based security systems, specifically focusing on the challenges of
detecting and attributing authorship of NTG-authored texts. By introducing a
novel human-NTG co-authorship text attack, termed CS-ACT, our study uncovers
significant vulnerabilities in traditional DFIR methodologies, highlighting
discrepancies between ideal scenarios and real-world conditions. Utilizing 14
diverse datasets and 43 unique NTGs, up to the latest GPT-4, our research
identifies substantial vulnerabilities in the forensic profiling phase,
particularly in attributing authorship to NTGs. Our comprehensive evaluation
points to factors such as model sophistication and the lack of distinctive
style within NTGs as significant contributors for these vulnerabilities. Our
findings underscore the necessity for more sophisticated and adaptable
strategies, such as incorporating adversarial learning, stylizing NTGs, and
implementing hierarchical attribution through the mapping of NTG lineages to
enhance source attribution. This sets the stage for future research and the
development of more resilient text-based security systems.

æè¦ï¼å¨çæå¼ AI æä»£ï¼ç¥ç¶ææ¬çæå¨ (NTG) çå»£æ³æ¡ç¨æåºäºæ°çç¶²è·¯å®å¨ææ°ï¼ç¹å¥æ¯å¨æ¸ä½éè­åäºä»¶æè® (DFIR) é åãéäºææ°ä¸»è¦æ¶ååµæ¸¬åæ­¸å æ¼é­åå¼ç¶²è·¯é£é­ååè¨æ¯æ´»åç­é²éæ»æèå¾çä¾æºãé¨è NTG çæ¼é²ï¼ååäººé¡å NTG æ°å¯«ææ¬çä»»åè®å¾æ¥µçºè¤éãæ¬æå´è¬¹å°è©ä¼°äºå°çºåºæ¼ææ¬çå®å¨ç³»çµ±éèº«æé ç DFIR ç®¡ç·ï¼ç¹å¥éæ³¨åµæ¸¬åæ­¸å  NTG æ°å¯«ææ¬ä½èçææ°ãééå¼å¥ä¸ç¨®ç¨±çº CS-ACT çæ°åäººé¡-NTG å±ååµä½ææ¬æ»æï¼æåçç ç©¶æ­é²äºå³çµ± DFIR æ¹æ³è«ä¸­çéå¤§æ¼æ´ï¼çªé¡¯äºçæ³ææ³èå¯¦éææ³ä¹éçå·®ç°ãå©ç¨ 14 åä¸åçè³æéå 43 åç¨ç¹ç NTGï¼åæ¬ææ°ç GPT-4ï¼ï¼æåçç ç©¶ç¼ç¾äºéè­åæéæ®µçéå¤§æ¼æ´ï¼ç¹å¥æ¯å¨å°ä½èæ­¸å æ¼ NTG æãæåçå¨é¢è©ä¼°æåºï¼æ¨¡åè¤éæ§å NTG ä¸­ç¼ºä¹ç¨ç¹é¢¨æ ¼ç­å ç´ æ¯éäºæ¼æ´çéè¦æå ãæåçç¼ç¾å¼·èª¿äºæ´è¤éåé©ææ§ç­ç¥çå¿è¦æ§ï¼ä¾å¦ç´å¥å°ææ§å­¸ç¿ãèª¿æ´ NTG é¢¨æ ¼ï¼ä»¥åééå° NTG ä¸ç³»æ å°å°å¢å¼·ä¾æºæ­¸å ä¾å¯¦æ½éå±¤å¼æ­¸å ãéçºæªä¾çç ç©¶åæ´å·éæ§çåºæ¼ææ¬çå®å¨ç³»çµ±çéç¼å¥ å®äºåºç¤ã

##### **Financial Statement Analysis with Large Language Models**
2407.17866v1 by Alex Kim, Maximilian Muhn, Valeri Nikolaev

We investigate whether an LLM can successfully perform financial statement
analysis in a way similar to a professional human analyst. We provide
standardized and anonymous financial statements to GPT4 and instruct the model
to analyze them to determine the direction of future earnings. Even without any
narrative or industry-specific information, the LLM outperforms financial
analysts in its ability to predict earnings changes. The LLM exhibits a
relative advantage over human analysts in situations when the analysts tend to
struggle. Furthermore, we find that the prediction accuracy of the LLM is on
par with the performance of a narrowly trained state-of-the-art ML model. LLM
prediction does not stem from its training memory. Instead, we find that the
LLM generates useful narrative insights about a company's future performance.
Lastly, our trading strategies based on GPT's predictions yield a higher Sharpe
ratio and alphas than strategies based on other models. Taken together, our
results suggest that LLMs may take a central role in decision-making.

æè¦ï¼æåæ¢è¨ LLM æ¯å¦è½æåå·è¡è²¡åå ±è¡¨åæï¼å¶æ¹å¼é¡ä¼¼æ¼å°æ¥­çäººé¡åæå¸«ãæåæä¾æ¨æºåä¸å¿åçè²¡åå ±è¡¨çµ¦ GPT4ï¼ä¸¦æç¤ºæ¨¡ååæå®åä»¥ç¢ºå®æªä¾æ¶ççæ¹åãå³ä½¿æ²æä»»ä½æè¿°æç¢æ¥­ç¹å®è³è¨ï¼LLM å¨é æ¸¬æ¶çè®åçè½åä¸ä¹åªæ¼è²¡ååæå¸«ãç¶åæå¸«å¾åæ¼é·å¥å°å¢æï¼LLM å±ç¾åºç¸å°æ¼äººé¡åæå¸«çç¸å°åªå¢ãæ­¤å¤ï¼æåç¼ç¾ LLM çé æ¸¬æºç¢ºåº¦èè¨ç·´æç´ çææ° ML æ¨¡åçæè½ç¸ç¶ãLLM çé æ¸¬ä¸¦éæºèªå¶è¨ç·´è¨æ¶ãç¸åå°ï¼æåç¼ç¾ LLM è½ç¢çæéå¬å¸æªä¾è¡¨ç¾çæç¨æè¿°æ§è¦è§£ãæå¾ï¼æåæ ¹æ GPT é æ¸¬æå»ºç«çäº¤æç­ç¥ç¢çé«æ¼å¶ä»æ¨¡åçå¤æ®æ¯çå alpha å¼ãç¶è§èè¨ï¼æåççµæè¡¨æ LLM å¯è½å¨æ±ºç­å¶å®ä¸­æ®æ¼æ ¸å¿è§è²ã

##### **factgenie: A Framework for Span-based Evaluation of Generated Texts**
2407.17863v1 by ZdenÄk Kasner, OndÅej PlÃ¡tek, PatrÃ­cia SchmidtovÃ¡, Simone Balloccu, OndÅej DuÅ¡ek

We present factgenie: a framework for annotating and visualizing word spans
in textual model outputs. Annotations can capture various span-based phenomena
such as semantic inaccuracies or irrelevant text. With factgenie, the
annotations can be collected both from human crowdworkers and large language
models. Our framework consists of a web interface for data visualization and
gathering text annotations, powered by an easily extensible codebase.

æè¦ï¼æåæåº factgenieï¼ä¸åç¨æ¼æ¨è¨»åè¦è¦ºåææ¬æ¨¡åè¼¸åºä¸­å­è©åéçæ¡æ¶ãæ¨è¨»å¯ä»¥ææåç¨®åºæ¼åéçç¾è±¡ï¼ä¾å¦èªç¾©ä¸æºç¢ºæç¡éæå­ãæäº factgenieï¼å¯ä»¥å¾äººå·¥ç¾¤ç¾å·¥ä½èåå¤§åèªè¨æ¨¡åæ¶éæ¨è¨»ãæåçæ¡æ¶åå«ä¸åç¶²è·¯ä»é¢ï¼ç¨æ¼è³æè¦è¦ºååæ¶éæå­æ¨è¨»ï¼ä¸¦ç±ä¸åå®¹ææ´åçç¨å¼ç¢¼åº«æä¾æ¯æ´ã

##### **Exploring Description-Augmented Dataless Intent Classification**
2407.17862v1 by Ruoyu Hu, Foaad Khosmood, Abbas Edalat

In this work, we introduce several schemes to leverage description-augmented
embedding similarity for dataless intent classification using current
state-of-the-art (SOTA) text embedding models. We report results of our methods
on four commonly used intent classification datasets and compare against
previous works of a similar nature. Our work shows promising results for
dataless classification scaling to a large number of unseen intents. We show
competitive results and significant improvements (+6.12\% Avg.) over strong
zero-shot baselines, all without training on labelled or task-specific data.
Furthermore, we provide qualitative error analysis of the shortfalls of this
methodology to help guide future research in this area.

æè¦ï¼å¨æ¬æä¸­ï¼æä»¬ä»ç»äºå ç§æ¹æ¡ï¼å©ç¨æè¿°å¢å¼ºåµå¥ç¸ä¼¼æ§è¿è¡æ æ°æ®æå¾åç±»ï¼ä½¿ç¨å½åæåè¿ (SOTA) çææ¬åµå¥æ¨¡åãæä»¬æ¥åäºæä»¬å¨åä¸ªå¸¸ç¨çæå¾åç±»æ°æ®éä¸çæ¹æ³ç»æï¼å¹¶ä¸ç±»ä¼¼æ§è´¨çååå·¥ä½è¿è¡äºæ¯è¾ãæä»¬çå·¥ä½è¡¨æï¼æ æ°æ®åç±»æ©å±å°å¤§éçä¸è§çæå¾æ¶ï¼ç»æå¾æå¸æãæä»¬å±ç¤ºäºæç«äºåçç»æåæ¾çæ¹è¿ï¼+6.12% å¹³åå¼ï¼è¶è¿å¼ºå¤§çé¶æ ·æ¬åºçº¿ï¼ææè¿äºé½æ ééå¯¹æ è®°æç¹å®ä»»å¡çæ°æ®è¿è¡è®­ç»ãæ­¤å¤ï¼æä»¬æä¾äºæ­¤æ¹æ³è®ºä¸è¶³çå®æ§éè¯¯åæï¼ä»¥å¸®å©æå¯¼è¯¥é¢åçæªæ¥ç ç©¶ã

##### **Shapley Value-based Contrastive Alignment for Multimodal Information Extraction**
2407.17854v1 by Wen Luo, Yu Xia, Shen Tianshu, Sujian Li

The rise of social media and the exponential growth of multimodal
communication necessitates advanced techniques for Multimodal Information
Extraction (MIE). However, existing methodologies primarily rely on direct
Image-Text interactions, a paradigm that often faces significant challenges due
to semantic and modality gaps between images and text. In this paper, we
introduce a new paradigm of Image-Context-Text interaction, where large
multimodal models (LMMs) are utilized to generate descriptive textual context
to bridge these gaps. In line with this paradigm, we propose a novel Shapley
Value-based Contrastive Alignment (Shap-CA) method, which aligns both
context-text and context-image pairs. Shap-CA initially applies the Shapley
value concept from cooperative game theory to assess the individual
contribution of each element in the set of contexts, texts and images towards
total semantic and modality overlaps. Following this quantitative evaluation, a
contrastive learning strategy is employed to enhance the interactive
contribution within context-text/image pairs, while minimizing the influence
across these pairs. Furthermore, we design an adaptive fusion module for
selective cross-modal fusion. Extensive experiments across four MIE datasets
demonstrate that our method significantly outperforms existing state-of-the-art
methods.

æè¦ï¼ç¤¾ç¾¤åªé«çå´èµ·åå¤æ¨¡ææºéçææ¸åæé·ï¼éè¦é²éçå¤æ¨¡æè³è¨èå (MIE) æè¡ãç¶èï¼ç¾æçæ¹æ³è«ä¸»è¦ä¾è³´æ¼ç´æ¥çå½±åæå­äºåï¼éç¨®æ¨¡å¼éå¸¸æå çºå½±ååæå­ä¹éçèªæåæ¨¡æå·®è·èé¢è¨éå¤§çææ°ãå¨æ¬æä¸­ï¼æåå¼é²ä¸ç¨®æ°çå½±å-èçµ¡-æå­äºåæ¨¡å¼ï¼å¶ä¸­å©ç¨å¤§åå¤æ¨¡ææ¨¡å (LMM) ä¾ç¢çæè¿°æ§çæå­èçµ¡ï¼ä»¥å½è£éäºå·®è·ãæ ¹æéåæ¨¡å¼ï¼æåæåºä¸åæ°ç Shapley å¼åºç¤å°æ¯å¼æ ¡æº (Shap-CA) æ¹æ³ï¼å®æ ¡æºèçµ¡æå­åèçµ¡å½±åå°ãShap-CA æåæç¨åä½åå¼è«ä¸­ç Shapley å¼æ¦å¿µï¼è©ä¼°èçµ¡ãæå­åå½±åéåä¸­æ¯ååç´ å°ç¸½é«èªæåæ¨¡æéççåå¥è²¢ç»ãå¨éåå®éè©ä¼°ä¹å¾ï¼æ¡ç¨å°æ¯å¼å­¸ç¿ç­ç¥ä¾å å¼·èçµ¡æå­/å½±åå°ä¹éçäºåè²¢ç»ï¼åæå°éäºå°ä¹éçå½±é¿éå°æä½ãæ­¤å¤ï¼æåè¨­è¨äºä¸åé©æå¼èåæ¨¡çµï¼ç¨æ¼é¸ææ§çè·¨æ¨¡æèåãå¨åå MIE è³æéä¸çå»£æ³å¯¦é©è­æï¼æåçæ¹æ³æé¡¯åªæ¼ç¾æçæåé²æ¹æ³ã

##### **Scaling A Simple Approach to Zero-Shot Speech Recognition**
2407.17852v1 by Jinming Zhao, Vineel Pratap, Michael Auli

Despite rapid progress in increasing the language coverage of automatic
speech recognition, the field is still far from covering all languages with a
known writing script. Recent work showed promising results with a zero-shot
approach requiring only a small amount of text data, however, accuracy heavily
depends on the quality of the used phonemizer which is often weak for unseen
languages. In this paper, we present MMS Zero-shot a conceptually simpler
approach based on romanization and an acoustic model trained on data in 1,078
different languages or three orders of magnitude more than prior art. MMS
Zero-shot reduces the average character error rate by a relative 46% over 100
unseen languages compared to the best previous work. Moreover, the error rate
of our approach is only 2.5x higher compared to in-domain supervised baselines,
while our approach uses no labeled data for the evaluation languages at all.

æè¦ï¼åç®¡èªåèªé³è¾¨è­å¨æ´å±èªè¨æ¶µèç¯åæ¹é¢é²å±è¿éï¼ä½æ­¤é åä»é é ç¡æ³æ¶µèææå·²ç¥æ¸å¯«ç³»çµ±çèªè¨ãæè¿çç ç©¶é¡¯ç¤ºï¼ä¸ç¨®åªéå°éæå­è³æçé¶æ¬¡å­¸ç¿æ¹æ³ç²å¾äºæå¸æçææï¼ç¶èï¼æºç¢ºåº¦é«åº¦ä¾è³´æ¼æä½¿ç¨çé³ç´ åå¨çåè³ªï¼èé³ç´ åå¨å°æ¼æªè¦éçèªè¨éå¸¸å¾å¼±ãå¨æ¬æä¸­ï¼æåæåºäº MMS é¶æ¬¡å­¸ç¿ï¼éæ¯ä¸ç¨®åºæ¼ç¾é¦¬ååå¨ 1,078 ç¨®ä¸åèªè¨çè³æä¸è¨ç·´çè²å­¸æ¨¡åçæ¦å¿µä¸æ´ç°¡å®çæ¹æ³ï¼æ¯ååçæè¡å¤äºä¸åæ¸éç´ãèååçæä½³æè¡ç¸æ¯ï¼MMS é¶æ¬¡å­¸ç¿å° 100 ç¨®æªè¦éèªè¨çå¹³åå­åé¯èª¤çéä½äºç¸å°ç 46%ãæ­¤å¤ï¼èç¹å®é åçç£ç£åºæºç¸æ¯ï¼æåçæ¹æ³çé¯èª¤çåé«åº 2.5 åï¼èæåçæ¹æ³å®å¨ä¸ä½¿ç¨è©ä¼°èªè¨çæ¨ç±¤è³æã

##### **Innovative Speech-Based Deep Learning Approaches for Parkinson's Disease Classification: A Systematic Review**
2407.17844v1 by Lisanne van Gelderen, Cristian Tejedor-GarcÃ­a

Parkinson's disease (PD), the second most prevalent neurodegenerative
disorder worldwide, frequently presents with early-stage speech impairments.
Recent advancements in Artificial Intelligence (AI), particularly deep learning
(DL), have significantly enhanced PD diagnosis through the analysis of speech
data. Nevertheless, the progress of research is restricted by the limited
availability of publicly accessible speech-based PD datasets, primarily due to
privacy and ethical concerns. This review covers the latest DL-based AI
approaches for speech-based PD classification, focusing on performance,
available resources and associated challenges of 33 scientific works published
between 2020 and March 2024. These DL approaches are categorized into
end-to-end (E2E) learning, transfer learning (TL) and deep acoustic features
(DAF) extraction. Among E2E approaches, Convolutional Neural Networks (CNNs)
are prevalent, though Transformers are increasingly popular. E2E approaches
face challenges such as limited data and computational resources, especially
with Transformers. TL addresses these issues by providing more robust PD
diagnosis and better generalizability across languages. DAF extraction aims to
improve the explainability and interpretability of results by examining the
specific effects of deep features on both other DL approaches and more
traditional machine learning (ML) methods. However, it often underperforms
compared to E2E and TL approaches. This review also discusses unresolved issues
related to bias, explainability and privacy, highlighting the need for future
research.

æè¦ï¼å¸éæ£®æ°ç (PD) æ¯å¨çç¬¬äºå¸¸è¦çç¥ç¶éåæ§ç¾çï¼éå¸¸æåºç¾æ©æè¨èªéç¤ãäººå·¥æºæ§ (AI) çææ°é²å±ï¼å°¤å¶æ¯æ·±åº¦å­¸ç¿ (DL)ï¼å·²ééåæè¨èªè³æå¤§å¹æå PD è¨ºæ·ãåç®¡å¦æ­¤ï¼ç ç©¶é²åº¦åå°å¬éå¯å­åçåºæ¼è¨èªç PD è³æéæéæéå¶ï¼éä¸»è¦æ¯ç±æ¼é±ç§åå«çèéãæ¬ç¯è©è«æ¶µèäºææ°çåºæ¼ DL ç AI æ¹æ³ï¼ç¨æ¼åºæ¼è¨èªç PD åé¡ï¼éé»å¨æ¼ 2020 å¹´è³ 2024 å¹´ 3 æéç¼è¡¨ç 33 ç¯ç§å­¸èä½çæè½ãå¯ç¨è³æºåç¸éææ°ãéäº DL æ¹æ³è¢«åé¡çºç«¯å°ç«¯ (E2E) å­¸ç¿ãé·ç§»å­¸ç¿ (TL) åæ·±åº¦é³é¿ç¹å¾µ (DAF) èåãå¨ E2E æ¹æ³ä¸­ï¼å·ç©ç¥ç¶ç¶²è·¯ (CNN) å¾æ®éï¼åç®¡ Transformer è®å¾è¶ä¾è¶åæ­¡è¿ãE2E æ¹æ³é¢è¨è«¸å¦è³æåéç®è³æºæéç­ææ°ï¼ç¹å¥æ¯ä½¿ç¨ TransformerãTL ééæä¾æ´å¼·å¥ç PD è¨ºæ·åè·¨èªè¨çæ´ä½³æ¦æ¬æ§ä¾è§£æ±ºéäºåé¡ãDAF èåæ¨å¨ééæª¢è¦æ·±åº¦ç¹å¾µå°å¶ä» DL æ¹æ³åæ´å³çµ±æ©å¨å­¸ç¿ (ML) æ¹æ³çå·é«å½±é¿ï¼ä¾æåçµæçå¯è§£éæ§åå¯è©®éæ§ãç¶èï¼è E2E å TL æ¹æ³ç¸æ¯ï¼å®çè¡¨ç¾éå¸¸è¼å·®ãæ¬ç¯è©è«ä¹è¨è«äºèåè¦ãå¯è§£éæ§åé±ç§ç¸éçæªè§£æ±ºåé¡ï¼å¼·èª¿æªä¾ç ç©¶çå¿è¦æ§ã

##### **DragText: Rethinking Text Embedding in Point-based Image Editing**
2407.17843v1 by Gayoon Choi, Taejin Jeong, Sujung Hong, Jaehoon Joo, Seong Jae Hwang

Point-based image editing enables accurate and flexible control through
content dragging. However, the role of text embedding in the editing process
has not been thoroughly investigated. A significant aspect that remains
unexplored is the interaction between text and image embeddings. In this study,
we show that during the progressive editing of an input image in a diffusion
model, the text embedding remains constant. As the image embedding increasingly
diverges from its initial state, the discrepancy between the image and text
embeddings presents a significant challenge. Moreover, we found that the text
prompt significantly influences the dragging process, particularly in
maintaining content integrity and achieving the desired manipulation. To
utilize these insights, we propose DragText, which optimizes text embedding in
conjunction with the dragging process to pair with the modified image
embedding. Simultaneously, we regularize the text optimization process to
preserve the integrity of the original text prompt. Our approach can be
seamlessly integrated with existing diffusion-based drag methods with only a
few lines of code.

æè¦ï¼åºæ¼é»çå½±åç·¨è¼¯ééå§å®¹ææ³å¯¦ç¾ç²¾æºä¸å½æ§çæ§å¶ãç¶èï¼æå­åµå¥å¨ç·¨è¼¯éç¨ä¸­ææ®æ¼çè§è²å°æªè¢«å¾¹åºç ç©¶ãæå­åµå¥èå½±ååµå¥ä¹éçäºåæ¯ä»æªæ¢ç´¢çéè¦é¢åãå¨æ¬ç ç©¶ä¸­ï¼æåå±ç¤ºå¨æ´æ£æ¨¡åä¸­è¼¸å¥å½±åçæ¼¸é²å¼ç·¨è¼¯éç¨ä¸­ï¼æå­åµå¥ä¿æä¸è®ãé¨èå½±ååµå¥èå¶åå§çæçå·®ç°è¶ä¾è¶å¤§ï¼å½±åèæå­åµå¥ä¹éçå·®ç°åç¾åºéå¤§çææ°ãæ­¤å¤ï¼æåç¼ç¾æå­æç¤ºæé¡¯èå½±é¿ææ³éç¨ï¼ç¹å¥æ¯å¨ç¶­æå§å®¹å®æ´æ§ä¸¦éæé æçæä½ãçºäºå©ç¨éäºè¦è§£ï¼æåæåº DragTextï¼å®ææä½³åæå­åµå¥ï¼ä¸¦çµåææ³éç¨èä¿®æ¹å¾çå½±ååµå¥éå°ãåæï¼æåè¦ç¯åæå­æä½³åéç¨ï¼ä»¥ç¶­æåå§æå­æç¤ºçå®æ´æ§ãæåçåæ³å¯ä»¥ç¡ç¸«æ´åå°ç¾æçåºæ¼æ´æ£çææ³æ¹æ³ä¸­ï¼åªéå¹¾è¡ç¨å¼ç¢¼å³å¯ã

##### **On the Opportunities of (Re)-Exploring Atmospheric Science by Foundation Models: A Case Study**
2407.17842v1 by Lujia Zhang, Hanzhe Cui, Yurong Song, Chenyue Li, Binhang Yuan, Mengqian Lu

Most state-of-the-art AI applications in atmospheric science are based on
classic deep learning approaches. However, such approaches cannot automatically
integrate multiple complicated procedures to construct an intelligent agent,
since each functionality is enabled by a separate model learned from
independent climate datasets. The emergence of foundation models, especially
multimodal foundation models, with their ability to process heterogeneous input
data and execute complex tasks, offers a substantial opportunity to overcome
this challenge. In this report, we want to explore a central question - how the
state-of-the-art foundation model, i.e., GPT-4o, performs various atmospheric
scientific tasks. Toward this end, we conduct a case study by categorizing the
tasks into four main classes, including climate data processing, physical
diagnosis, forecast and prediction, and adaptation and mitigation. For each
task, we comprehensively evaluate the GPT-4o's performance along with a
concrete discussion. We hope that this report may shed new light on future AI
applications and research in atmospheric science.

æè¦ï¼ç®åå¨æ°£è±¡ç§å­¸ä¸­ï¼å¤§å¤æ¸æåé²çäººå·¥æºæ§æç¨ç¨å¼é½æ¯åºæ¼ç¶å¸æ·±åº¦å­¸ç¿æ¹æ³ãç¶èï¼éç¨®æ¹æ³ç¡æ³èªåæ´åå¤ç¨®è¤éçç¨åºä¾å»ºæ§ä¸åæºæ§åä»£çï¼å çºæ¯é åè½é½æ¯ç±å¾ç¨ç«æ°£åè³æéå­¸ç¿çå®ç¨æ¨¡åæåç¨ãåºç¤æ¨¡åçåºç¾ï¼ç¹å¥æ¯å¤æ¨¡æåºç¤æ¨¡åï¼å·åèçç°è³ªè¼¸å¥è³æåå·è¡è¤éä»»åçè½åï¼æä¾äºåææ­¤ææ°çéå¤§å¥æ©ãå¨æ­¤å ±åä¸­ï¼æåæ³è¦æ¢è¨ä¸åæ ¸å¿åé¡ââæåé²çåºç¤æ¨¡åï¼å³ GPT-4oï¼å¦ä½å·è¡åç¨®å¤§æ°£ç§å­¸ä»»åãçºæ­¤ï¼æåééå°ä»»ååé¡çºååä¸»è¦é¡å¥ï¼åæ¬æ°£åè³æèçãç©çè¨ºæ·ãé æ¸¬åé å ±ï¼ä»¥åé©æåæ¸ç·©ï¼ä¾é²è¡åæ¡ç ç©¶ãå°æ¼æ¯åä»»åï¼æåæå¨é¢è©ä¼° GPT-4o çæè½ï¼ä¸¦é²è¡å·é«çè¨è«ãæåå¸æéä»½å ±åè½çºæªä¾çäººå·¥æºæ§æç¨ç¨å¼åæ°£è±¡ç§å­¸ç ç©¶å¸¶ä¾æ°çåç¼ã

##### **Long-term Fairness in Ride-Hailing Platform**
2407.17839v1 by Yufan Kang, Jeffrey Chan, Wei Shao, Flora D. Salim, Christopher Leckie

Matching in two-sided markets such as ride-hailing has recently received
significant attention. However, existing studies on ride-hailing mainly focus
on optimising efficiency, and fairness issues in ride-hailing have been
neglected. Fairness issues in ride-hailing, including significant earning
differences between drivers and variance of passenger waiting times among
different locations, have potential impacts on economic and ethical aspects.
The recent studies that focus on fairness in ride-hailing exploit traditional
optimisation methods and the Markov Decision Process to balance efficiency and
fairness. However, there are several issues in these existing studies, such as
myopic short-term decision-making from traditional optimisation and instability
of fairness in a comparably longer horizon from both traditional optimisation
and Markov Decision Process-based methods. To address these issues, we propose
a dynamic Markov Decision Process model to alleviate fairness issues currently
faced by ride-hailing, and seek a balance between efficiency and fairness, with
two distinct characteristics: (i) a prediction module to predict the number of
requests that will be raised in the future from different locations to allow
the proposed method to consider long-term fairness based on the whole timeline
instead of consider fairness only based on historical and current data
patterns; (ii) a customised scalarisation function for multi-objective
multi-agent Q Learning that aims to balance efficiency and fairness. Extensive
experiments on a publicly available real-world dataset demonstrate that our
proposed method outperforms existing state-of-the-art methods.

æè¦ï¼<paragraph>æè¿ï¼å¨è¯¸å¦å«è½¦ç­åè¾¹å¸åºä¸­çå¹éé®é¢åå°äºå¹¿æ³å³æ³¨ãç¶èï¼ç°æçå³äºå«è½¦æå¡ççç ç©¶ä¸»è¦éä¸­å¨ä¼åæçä¸ï¼èå«è½¦æå¡çå¬å¹³æ§é®é¢å´è¢«å¿½è§äºãå«è½¦æå¡ä¸­çå¬å¹³æ§é®é¢ï¼åæ¬å¸æºä¹é´çæ¾èæ¶å¥å·®å¼ä»¥åä¸åå°ç¹ä¹é´çä¹å®¢ç­å¾æ¶é´å·®å¼ï¼å¯¹ç»æµåéå¾·æ¹é¢é½ææ½å¨å½±åãæè¿å³æ³¨å«è½¦æå¡å¬å¹³æ§çç ç©¶å©ç¨äºä¼ ç»çä¼åæ¹æ³åé©¬å°å¯å¤«å³ç­è¿ç¨æ¥å¹³è¡¡æçåå¬å¹³æ§ãç¶èï¼ç°æçè¿äºç ç©¶å­å¨ä¸äºé®é¢ï¼ä¾å¦ä¼ ç»çä¼åæ¹æ³ä¸­çç­è§çç­æå³ç­ï¼ä»¥ååºäºä¼ ç»ä¼åæ¹æ³ååºäºé©¬å°å¯å¤«å³ç­è¿ç¨çæ¹æ³å¨ç¸å¯¹è¾é¿çæ¶åä¸­å¬å¹³æ§çä¸ç¨³å®æ§ãä¸ºäºè§£å³è¿äºé®é¢ï¼æä»¬æåºäºä¸ç§å¨æé©¬å°å¯å¤«å³ç­è¿ç¨æ¨¡åæ¥ç¼è§£å«è½¦æå¡ç®åé¢ä¸´çå¬å¹³æ§é®é¢ï¼å¹¶å¨æçåå¬å¹³æ§ä¹é´å¯»æ±å¹³è¡¡ï¼è¯¥æ¨¡åå·æä¸¤ä¸ªæ¾èç¹å¾ï¼(i) ä¸ä¸ªé¢æµæ¨¡åï¼ç¨äºé¢æµæªæ¥ä¸åå°ç¹æåºçè¯·æ±æ°éï¼ä»¥ä½¿ææåºçæ¹æ³è½å¤åºäºæ´ä¸ªæ¶é´çº¿èèé¿æå¬å¹³æ§ï¼èä¸æ¯ä»åºäºåå²åå½åæ°æ®æ¨¡å¼èèå¬å¹³æ§ï¼(ii) ä¸ä¸ªç¨äºå¤ç®æ å¤æºè½ä½ Q å­¦ä¹ çå®å¶æ éåå½æ°ï¼æ¨å¨å¹³è¡¡æçåå¬å¹³æ§ãå¨å¬å¼ççå®ä¸çæ°æ®éä¸è¿è¡çå¹¿æ³å®éªè¡¨æï¼æä»¬æåºçæ¹æ³ä¼äºç°æçæåè¿çæ¹æ³ã</paragraph>

##### **UMono: Physical Model Informed Hybrid CNN-Transformer Framework for Underwater Monocular Depth Estimation**
2407.17838v1 by Jian Wang, Jing Wang, Shenghui Rong, Bo He

Underwater monocular depth estimation serves as the foundation for tasks such
as 3D reconstruction of underwater scenes. However, due to the influence of
light and medium, the underwater environment undergoes a distinctive imaging
process, which presents challenges in accurately estimating depth from a single
image. The existing methods fail to consider the unique characteristics of
underwater environments, leading to inadequate estimation results and limited
generalization performance. Furthermore, underwater depth estimation requires
extracting and fusing both local and global features, which is not fully
explored in existing methods. In this paper, an end-to-end learning framework
for underwater monocular depth estimation called UMono is presented, which
incorporates underwater image formation model characteristics into network
architecture, and effectively utilize both local and global features of
underwater image. Experimental results demonstrate that the proposed method is
effective for underwater monocular depth estimation and outperforms the
existing methods in both quantitative and qualitative analyses.

æè¦ï¼æ°´ä¸å®ç®æ·±åº¦ä¼°è¨ä½çºæ°´ä¸å ´æ¯ 3D éå»ºç­ä»»åçåºç¤ãç¶èï¼ç±æ¼åç·ååªä»çå½±é¿ï¼æ°´ä¸ç°å¢ç¶æ­·äºä¸åç¨ç¹çæåéç¨ï¼éå°æ¼å¾å®ä¸å½±åæºç¢ºä¼°è¨æ·±åº¦æåºäºææ°ãç¾ææ¹æ³æªè½èæ®æ°´ä¸ç°å¢çç¨ç¹ç¹å¾µï¼å°è´ä¼°è¨çµæä¸ååï¼ä¸æ³åæè½æéãæ­¤å¤ï¼æ°´ä¸æ·±åº¦ä¼°è¨éè¦æååèåå±é¨åå¨å±ç¹å¾µï¼éå¨ç¾ææ¹æ³ä¸­ä¸¦æªå¾å°ååæ¢è¨ãå¨æ¬æä¸­ï¼æåºäºä¸åç¨±çº UMono çæ°´ä¸å®ç®æ·±åº¦ä¼°è¨ç«¯å°ç«¯å­¸ç¿æ¶æ§ï¼å®å°æ°´ä¸å½±åå½¢ææ¨¡åç¹å¾µæ´åå°ç¶²è·¯æ¶æ§ä¸­ï¼ä¸¦ææå©ç¨æ°´ä¸å½±åçå±é¨åå¨å±ç¹å¾µãå¯¦é©çµæè¡¨æï¼ææåºçæ¹æ³å°æ¼æ°´ä¸å®ç®æ·±åº¦ä¼°è¨æ¯ææçï¼ä¸¦ä¸å¨å®éåå®æ§åæä¸­é½åªæ¼ç¾ææ¹æ³ã

##### **Unified Lexical Representation for Interpretable Visual-Language Alignment**
2407.17827v1 by Yifan Li, Yikai Wang, Yanwei Fu, Dongyu Ru, Zheng Zhang, Tong He

Visual-Language Alignment (VLA) has gained a lot of attention since CLIP's
groundbreaking work. Although CLIP performs well, the typical direct latent
feature alignment lacks clarity in its representation and similarity scores. On
the other hand, lexical representation, a vector whose element represents the
similarity between the sample and a word from the vocabulary, is a natural
sparse representation and interpretable, providing exact matches for individual
words. However, lexical representations is difficult to learn due to no
ground-truth supervision and false-discovery issues, and thus requires complex
design to train effectively. In this paper, we introduce LexVLA, a more
interpretable VLA framework by learning a unified lexical representation for
both modalities without complex design. We use DINOv2 as our visual model for
its local-inclined features and Llama 2, a generative language model, to
leverage its in-context lexical prediction ability. To avoid the false
discovery, we propose an overuse penalty to refrain the lexical representation
from falsely frequently activating meaningless words. We demonstrate that these
two pre-trained uni-modal models can be well-aligned by fine-tuning on modest
multi-modal dataset and avoid intricate training configurations. On cross-modal
retrieval benchmarks, LexVLA, trained on the CC-12M multi-modal dataset,
outperforms baselines fine-tuned on larger datasets (e.g., YFCC15M) and those
trained from scratch on even bigger datasets (e.g., 1.1B data, including
CC-12M). We conduct extensive experiments to analyze LexVLA.

æè¦ï¼èª CLIP çéåµæ§å·¥ä½ä»¥ä¾ï¼è¦è¦ºèªè¨å°é½ (VLA) ç²å¾äºè¨±å¤éæ³¨ãåç®¡ CLIP è¡¨ç¾è¯å¥½ï¼ä½å¸åçç´æ¥æ½å¨ç¹å¾µå°é½ç¼ºä¹å¶è¡¨ç¤ºåç¸ä¼¼æ§è©åçæ¸æ°åº¦ãå¦ä¸æ¹é¢ï¼è©å½è¡¨ç¤ºæ¯ä¸ååéï¼å¶åç´ è¡¨ç¤ºæ¨£æ¬èè©å½ä¸­ä¸åå®è©ä¹éçç¸ä¼¼æ§ï¼æ¯ä¸ç¨®èªç¶çç¨çè¡¨ç¤ºï¼ä¸¦ä¸å¯ä»¥è§£éï¼çºåå¥å®è©æä¾æºç¢ºçå¹éãç¶èï¼ç±æ¼æ²æçå¯¦çç£ç£åèåç¼ç¾åé¡ï¼è©å½è¡¨ç¤ºé£ä»¥å­¸ç¿ï¼å æ­¤éè¦è¤éçè¨­è¨æè½ææè¨ç·´ãå¨æ¬æä¸­ï¼æåä»ç´¹äº LexVLAï¼éæ¯ä¸åæ´å·å¯è§£éæ§ç VLA æ¡æ¶ï¼ééå­¸ç¿ä¸åçµ±ä¸çè©å½è¡¨ç¤ºä¾è¡¨ç¤ºå©ç¨®æ¨¡å¼ï¼èç¡éè¤éçè¨­è¨ãæåä½¿ç¨ DINOv2 ä½çºæåçè¦è¦ºæ¨¡åï¼å çºå®å·æå±é¨å¾æçç¹å¾µï¼ä»¥å Llama 2ï¼ä¸åçæèªè¨æ¨¡åï¼ä»¥å©ç¨å¶ä¸ä¸æè©å½é æ¸¬è½åãçºäºé¿åèåç¼ç¾ï¼æåæåºäºä¸åéåº¦ä½¿ç¨æ²ç½°ï¼ä»¥é²æ­¢è©å½è¡¨ç¤ºé¯èª¤å°é »ç¹æ¿æ´»ç¡æç¾©çè©ãæåè­æäºéå©åé åè¨ç·´çå®æ¨¡ææ¨¡åå¯ä»¥ééå¾®èª¿é©åº¦çå¤æ¨¡ææ¸æéä¸¦é¿åè¤éçè¨ç·´éç½®ä¾å¾å¥½å°å°é½ãå¨è·¨æ¨¡ææª¢ç´¢åºæºä¸ï¼å¨ CC-12M å¤æ¨¡ææ¸æéä¸è¨ç·´ç LexVLA åªæ¼å¨è¼å¤§æ¸æéï¼ä¾å¦ YFCC15Mï¼ä¸é²è¡å¾®èª¿çåºç·ï¼ä»¥åå¾æ´å¤§çæ¸æéï¼ä¾å¦ 1.1B æ¸æï¼åæ¬ CC-12Mï¼ä¸­å¾é ­è¨ç·´çåºç·ãæåé²è¡äºå¤§éçå¯¦é©ä¾åæ LexVLAã

##### **Demystifying Verbatim Memorization in Large Language Models**
2407.17817v1 by Jing Huang, Diyi Yang, Christopher Potts

Large Language Models (LLMs) frequently memorize long sequences verbatim,
often with serious legal and privacy implications. Much prior work has studied
such verbatim memorization using observational data. To complement such work,
we develop a framework to study verbatim memorization in a controlled setting
by continuing pre-training from Pythia checkpoints with injected sequences. We
find that (1) non-trivial amounts of repetition are necessary for verbatim
memorization to happen; (2) later (and presumably better) checkpoints are more
likely to verbatim memorize sequences, even for out-of-distribution sequences;
(3) the generation of memorized sequences is triggered by distributed model
states that encode high-level features and makes important use of general
language modeling capabilities. Guided by these insights, we develop stress
tests to evaluate unlearning methods and find they often fail to remove the
verbatim memorized information, while also degrading the LM. Overall, these
findings challenge the hypothesis that verbatim memorization stems from
specific model weights or mechanisms. Rather, verbatim memorization is
intertwined with the LM's general capabilities and thus will be very difficult
to isolate and suppress without degrading model quality.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) ç¶å¸¸éå­è¨æ¶é·åºåï¼
éå¸¸æé æå´éçæ³å¾åé±ç§åé¡ãè¨±å¤ååçå·¥ä½å·²ç¶ä½¿ç¨è§å¯è³æç ç©¶éç¨®éå­è¨æ¶ãçºäºè£åéé¡å·¥ä½ï¼
æåéç¼äºä¸åæ¶æ§ï¼ééå¾æ³¨å¥åºåç Pythia æª¢æ¥é»ç¹¼çºé è¨ç·´ï¼å¨åæ§è¨­å®ä¸ç ç©¶éå­è¨æ¶ãæåç¼ç¾ (1) ç¼çéå­è¨æ¶éè¦å¤§éçéè¤ï¼(2) è¼å¾ç (ä¸æ¨æ¸¬è¼å¥½ç) æª¢æ¥é»è¼æå¯è½éå­è¨æ¶åºåï¼å³ä½¿å°æ¼åä½å¤çåºåï¼
(3) è¨æ¶åºåçç¢çæ¯ç±ç·¨ç¢¼é«éç¹å¾µçåå¸å¼æ¨¡åçæè§¸ç¼ï¼ä¸¦å¤§éä½¿ç¨ä¸è¬èªè¨å»ºæ¨¡åè½ãå¨éäºè¦è§£çæå°ä¸ï¼æåéç¼å£åæ¸¬è©¦ä¾è©ä¼°åæ¶å­¸ç¿çæ¹æ³ï¼ä¸¦ç¼ç¾å®åéå¸¸ç¡æ³ç§»é¤éå­è¨æ¶çè³è¨ï¼åæä¹æéä½ LMãæ´é«èè¨ï¼éäºç¼ç¾ææ°äºéå­è¨æ¶æºèªç¹å®æ¨¡åæ¬éææ©å¶çåè¨­ãåä¹ï¼éå­è¨æ¶è LM çä¸è¬åè½äº¤ç¹å¨ä¸èµ·ï¼å æ­¤å¨ä¸éä½æ¨¡ååè³ªçææ³ä¸ï¼å°å¾é£å­¤ç«åæå¶ã

##### **NC-NCD: Novel Class Discovery for Node Classification**
2407.17816v1 by Yue Hou, Xueyuan Chen, He Zhu, Romei Liu, Bowen Shi, Jiaheng Liu, Junran Wu, Ke Xu

Novel Class Discovery (NCD) involves identifying new categories within
unlabeled data by utilizing knowledge acquired from previously established
categories. However, existing NCD methods often struggle to maintain a balance
between the performance of old and new categories. Discovering unlabeled new
categories in a class-incremental way is more practical but also more
challenging, as it is frequently hindered by either catastrophic forgetting of
old categories or an inability to learn new ones. Furthermore, the
implementation of NCD on continuously scalable graph-structured data remains an
under-explored area. In response to these challenges, we introduce for the
first time a more practical NCD scenario for node classification (i.e.,
NC-NCD), and propose a novel self-training framework with prototype replay and
distillation called SWORD, adopted to our NC-NCD setting. Our approach enables
the model to cluster unlabeled new category nodes after learning labeled nodes
while preserving performance on old categories without reliance on old category
nodes. SWORD achieves this by employing a self-training strategy to learn new
categories and preventing the forgetting of old categories through the joint
use of feature prototypes and knowledge distillation. Extensive experiments on
four common benchmarks demonstrate the superiority of SWORD over other
state-of-the-art methods.

æè¦ï¼æ°ç©é¡å¥ç¼ç¾ (NCD) æ¶åå©ç¨å¾ååå»ºç«çé¡å¥ä¸­ç²å¾çç¥è­ï¼å¨æªæ¨è¨è³æä¸­è­å¥æ°çé¡å¥ãç¶èï¼ç¾æç NCD æ¹æ³ç¶å¸¸é£ä»¥å¨èé¡å¥åæ°é¡å¥çæè½ä¹éåå¾å¹³è¡¡ãä»¥é¡å¥éå¢çæ¹å¼ç¼ç¾æªæ¨è¨çæ°é¡å¥æ´å¯¦éï¼ä½ææ°æ§ä¹æ´é«ï¼å çºå®ç¶å¸¸åå°èé¡å¥çç½é£æ§éºå¿æç¡æ³å­¸ç¿æ°é¡å¥çé»ç¤ãæ­¤å¤ï¼å¨é£çºå¯æ´åçåå½¢çµæ§è³æä¸å¯¦ä½ NCD ä»æ¯ä¸åæ¢ç´¢ä¸è¶³çé åãçºäºæå°éäºææ°ï¼æåé¦æ¬¡å¼å¥ä¸åæ´å¯¦ç¨çç¯é»åé¡ NCD å ´æ¯ (å³ NC-NCD)ï¼ä¸¦æåºä¸åæ°çèªè¨ç·´æ¶æ§ï¼å¶ä¸­åå«ååéæ­åç¨±çº SWORD çç¥è­èåï¼ä¸¦æ¡ç¨æåç NC-NCD è¨­å®ãæåçåæ³è®æ¨¡åå¨å­¸ç¿æ¨ç±¤ç¯é»å¾ï¼è½å¤ å°æªæ¨è¨çæ°é¡å¥ç¯é»åç¾¤ï¼åæå¨ä¸ä¾è³´èé¡å¥ç¯é»çææ³ä¸ï¼ç¶­æèé¡å¥çæè½ãSWORD ééæ¡ç¨èªè¨ç·´ç­ç¥ä¾å­¸ç¿æ°é¡å¥ï¼ä¸¦ééå±åä½¿ç¨ç¹å¾µåååç¥è­èåä¾é²æ­¢éºå¿èé¡å¥ï¼é²èéææ­¤ç®æ¨ãå¨ååå¸¸è¦åºæºä¸çå»£æ³å¯¦é©è­æäº SWORD åªæ¼å¶ä»ç¾ææè¡ã

##### **Enhancing Model Performance: Another Approach to Vision-Language Instruction Tuning**
2407.17813v1 by Vedanshu, MM Tripathi, Bhavnesh Jaint

The integration of large language models (LLMs) with vision-language (VL)
tasks has been a transformative development in the realm of artificial
intelligence, highlighting the potential of LLMs as a versatile general-purpose
chatbot. However, the current trend in this evolution focuses on the
integration of vision and language to create models that can operate in more
diverse and real-world contexts. We present a novel approach, termed Bottleneck
Adapter, specifically crafted for enhancing the multimodal functionalities of
these complex models, enabling joint optimization of the entire multimodal LLM
framework through a process known as Multimodal Model Tuning (MMT). Our
approach utilizes lightweight adapters to connect the image encoder and LLM
without the need for large, complex neural networks. Unlike the conventional
modular training schemes, our approach adopts an end-to-end optimization
regime, which, when combined with the adapters, facilitates the joint
optimization using a significantly smaller parameter set. Our method exhibits
robust performance with 90.12\% accuracy, outperforming both human-level
performance (88.4\%) and LaVIN-7B (89.41\%).

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) èè¦è¦ºèªè¨ (VL) ä»»åçæ´åæ¯äººå·¥æºæ§é åçä¸é è®é©æ§ç¼å±ï¼çªé¡¯äº LLM ä½çºå¤åè½éç¨èå¤©æ©å¨äººçæ½åãç¶èï¼éç¨®æ¼åçç¶åè¶¨å¢èéæ¼æ´åè¦è¦ºåèªè¨ï¼ä»¥å»ºç«å¯å¨æ´å¤æ¨£åä¸çå¯¦ä¸ççç°å¢ä¸­éä½çæ¨¡åãæåæåºä¸åæ°ç©çæ¹æ³ï¼ç¨±çºç¶é ¸é©éå¨ï¼å°éç¨æ¼å¢å¼·éäºè¤éæ¨¡åçå¤æ¨¡æåè½ï¼ééä¸åç¨±çºå¤æ¨¡ææ¨¡åèª¿æ´ (MMT) çç¨åºï¼å¯¦ç¾æ´åå¤æ¨¡æ LLM æ¶æ§çè¯åæä½³åãæåçåæ³å©ç¨è¼éç´é©éå¨é£æ¥å½±åç·¨ç¢¼å¨å LLMï¼èä¸éè¦å¤§åãè¤éçç¥ç¶ç¶²è·¯ãèå³çµ±çæ¨¡çµåè¨ç·´æ¹æ¡ä¸åï¼æåçåæ³æ¡ç¨ç«¯å°ç«¯æä½³åæ©å¶ï¼çµåé©éå¨å¾ï¼æå©æ¼ä½¿ç¨é¡¯èè¼å°çåæ¸éé²è¡è¯åæä½³åãæåçåæ³å±ç¾åºç©©å¥çæè½ï¼æºç¢ºåº¦é 90.12%ï¼è¶è¶äººé¡æ°´æºçæè½ (88.4%) å LaVIN-7B (89.41%)ã

##### **EEG-SSM: Leveraging State-Space Model for Dementia Detection**
2407.17801v1 by Xuan-The Tran, Linh Le, Quoc Toan Nguyen, Thomas Do, Chin-Teng Lin

State-space models (SSMs) have garnered attention for effectively processing
long data sequences, reducing the need to segment time series into shorter
intervals for model training and inference. Traditionally, SSMs capture only
the temporal dynamics of time series data, omitting the equally critical
spectral features. This study introduces EEG-SSM, a novel state-space
model-based approach for dementia classification using EEG data. Our model
features two primary innovations: EEG-SSM temporal and EEG-SSM spectral
components. The temporal component is designed to efficiently process EEG
sequences of varying lengths, while the spectral component enhances the model
by integrating frequency-domain information from EEG signals. The synergy of
these components allows EEG-SSM to adeptly manage the complexities of
multivariate EEG data, significantly improving accuracy and stability across
different temporal resolutions. Demonstrating a remarkable 91.0 percent
accuracy in classifying Healthy Control (HC), Frontotemporal Dementia (FTD),
and Alzheimer's Disease (AD) groups, EEG-SSM outperforms existing models on the
same dataset. The development of EEG-SSM represents an improvement in the use
of state-space models for screening dementia, offering more precise and
cost-effective tools for clinical neuroscience.

æè¦ï¼çæç©ºéæ¨¡å (SSM) å ææèçé·è³æåºåèååéæ³¨ï¼æ¸å°å°æéåºååéæè¼ç­åéä»¥é²è¡æ¨¡åè¨ç·´åæ¨è«çéè¦ãå³çµ±ä¸ï¼SSM åªæ·åæéåºåè³æçæéåæï¼çç¥åæ¨£éè¦çé »è­ç¹å¾µãæ¬ç ç©¶æåº EEG-SSMï¼ä¸ç¨®æ°çåºæ¼çæç©ºéæ¨¡åçæ¹æ³ï¼ç¨æ¼ä½¿ç¨ EEG è³æé²è¡å¤±æºçåé¡ãæåçæ¨¡åå·æå©é ä¸»è¦çåµæ°ï¼EEG-SSM æéå EEG-SSM é »è­çµæé¨åãæéçµæé¨åæ¨å¨ææçå°èçé·åº¦ä¸åç EEG åºåï¼èé »è­çµæé¨åééæ´å EEG è¨èçé »åè³è¨ä¾å¢å¼·æ¨¡åãéäºçµæé¨åçååä½ç¨è® EEG-SSM è½éæ´»å°ç®¡çå¤è®é EEG è³æçè¤éæ§ï¼å¤§å¹æ¹åä¸åæéè§£æåº¦ä¸çæºç¢ºæ§åç©©å®æ§ãEEG-SSM å¨åé¡å¥åº·å°ç§çµ (HC)ãé¡é¡³èåå¤±æºç (FTD) åé¿è²æµ·é»ç (AD) çµå¥æå±ç¾åºé©äººç 91.0% æºç¢ºåº¦ï¼å¨ç¸åçè³æéä¸åªæ¼ç¾ææ¨¡åãEEG-SSM çéç¼ä»£è¡¨äºä½¿ç¨çæç©ºéæ¨¡åé²è¡å¤±æºçç¯©æª¢çé²æ­¥ï¼çºè¨åºç¥ç¶ç§å­¸æä¾æ´ç²¾ç¢ºä¸æ´å·ææ¬æççå·¥å·ã

##### **A Unified Understanding of Adversarial Vulnerability Regarding Unimodal Models and Vision-Language Pre-training Models**
2407.17797v1 by Haonan Zheng, Xinyang Deng, Wen Jiang, Wenrui Li

With Vision-Language Pre-training (VLP) models demonstrating powerful
multimodal interaction capabilities, the application scenarios of neural
networks are no longer confined to unimodal domains but have expanded to more
complex multimodal V+L downstream tasks. The security vulnerabilities of
unimodal models have been extensively examined, whereas those of VLP models
remain challenging. We note that in CV models, the understanding of images
comes from annotated information, while VLP models are designed to learn image
representations directly from raw text. Motivated by this discrepancy, we
developed the Feature Guidance Attack (FGA), a novel method that uses text
representations to direct the perturbation of clean images, resulting in the
generation of adversarial images. FGA is orthogonal to many advanced attack
strategies in the unimodal domain, facilitating the direct application of rich
research findings from the unimodal to the multimodal scenario. By
appropriately introducing text attack into FGA, we construct Feature Guidance
with Text Attack (FGA-T). Through the interaction of attacking two modalities,
FGA-T achieves superior attack effects against VLP models. Moreover,
incorporating data augmentation and momentum mechanisms significantly improves
the black-box transferability of FGA-T. Our method demonstrates stable and
effective attack capabilities across various datasets, downstream tasks, and
both black-box and white-box settings, offering a unified baseline for
exploring the robustness of VLP models.

æè¦ï¼ééå±ç¾å¼·å¤§çå¤æ¨¡æäºåè½åï¼è¦è¦ºèªè¨é è¨ç·´ (VLP) æ¨¡åè®ç¥ç¶ç¶²è·¯çæç¨å ´æ¯ä¸åä¾·éæ¼å®æ¨¡æé åï¼èæ¯æ´å±å°æ´è¤éçå¤æ¨¡æ V+L ä¸æ¸¸ä»»åãå®æ¨¡ææ¨¡åçå®å¨æ¼æ´å·²è¢«å»£æ³æ¢è¨ï¼è VLP æ¨¡åçå®å¨æ¼æ´ä»å·æææ°æ§ãæåæ³¨æå°å¨ CV æ¨¡åä¸­ï¼å°å½±åççè§£ä¾èªæ¼æ¨è¨»è³è¨ï¼è VLP æ¨¡ååè¢«è¨­è¨çºç´æ¥å¾åå§æå­ä¸­å­¸ç¿å½±åè¡¨ç¤ºãåºæ¼æ­¤å·®ç°ï¼æåéç¼äºç¹å¾µå¼å°æ»æ (FGA)ï¼éæ¯ä¸ç¨®ä½¿ç¨æå­è¡¨ç¤ºä¾å¼å°ä¹¾æ·¨å½±åæ¾åçæ°æ¹æ³ï¼é²èç¢çå°ææ§å½±åãFGA èå®æ¨¡æé åä¸­çè¨±å¤é²éæ»æç­ç¥æ­£äº¤ï¼ä¿æäºè±å¯çç ç©¶ç¼ç¾å¾å®æ¨¡æç´æ¥æç¨å°å¤æ¨¡æå ´æ¯ãééé©ç¶å°å°æå­æ»æå¼å¥ FGAï¼æåå»ºæ§äºæ¡ç¨æå­æ»æçç¹å¾µå¼å° (FGA-T)ãééå©åæ¨¡æçäºåæ»æï¼FGA-T å° VLP æ¨¡åéå°äºåªç°çæ»æææãæ­¤å¤ï¼å å¥è³ææ´åååéæ©å¶é¡¯èæ¹åäº FGA-T çé»çè½ç§»æ§ãæåçæ¨¡åå¨åç¨®è³æéãä¸æ¸¸ä»»åä»¥åé»çåç½çè¨­å®ä¸­å±ç¾äºç©©å®ä¸ææçæ»æè½åï¼çºæ¢ç´¢ VLP æ¨¡åçç©©å¥æ§æä¾äºçµ±ä¸çåºç·ã

##### **Investigating learning-independent abstract reasoning in artificial neural networks**
2407.17791v1 by Tomer Barak, Yonatan Loewenstein

Humans are capable of solving complex abstract reasoning tests. Whether this
ability reflects a learning-independent inference mechanism applicable to any
novel unlearned problem or whether it is a manifestation of extensive training
throughout life is an open question. Addressing this question in humans is
challenging because it is impossible to control their prior training. However,
assuming a similarity between the cognitive processing of Artificial Neural
Networks (ANNs) and humans, the extent to which training is required for ANNs'
abstract reasoning is informative about this question in humans. Previous
studies demonstrated that ANNs can solve abstract reasoning tests. However,
this success required extensive training. In this study, we examined the
learning-independent abstract reasoning of ANNs. Specifically, we evaluated
their performance without any pretraining, with the ANNs' weights being
randomly-initialized, and only change in the process of problem solving. We
found that naive ANN models can solve non-trivial visual reasoning tests,
similar to those used to evaluate human learning-independent reasoning. We
further studied the mechanisms that support this ability. Our results suggest
the possibility of learning-independent abstract reasoning that does not
require extensive training.

æè¦ï¼äººé¡æè½åè§£æ±ºè¤éçæ½è±¡æ¨çæ¸¬é©ãéç¨®è½åæ¯åæ åºé©ç¨æ¼ä»»ä½æ°ç©æªå­¸ç¿åé¡çå­¸ç¿ç¡éæ¨è«æ©å¶ï¼éæ¯åæ åºæ´åçå½ä¸­å»£æ³è¨ç·´çè¡¨ç¾ï¼éæ¯ä¸åéæ¾æ§çåé¡ãå¨äººé¡ä¸­æ¢è¨éååé¡å·æææ°æ§ï¼å çºä¸å¯è½æ§å¶ä»åååçè¨ç·´ãç¶èï¼åè¨­äººå·¥ç¥ç¶ç¶²è·¯ (ANN) åäººé¡çèªç¥èçä¹éå­å¨ç¸ä¼¼æ§ï¼é£éº¼ ANN æ½è±¡æ¨çæéçè¨ç·´ç¨åº¦å°æ¼äººé¡ä¸­çéååé¡å·æåèæç¾©ãååçç ç©¶è¡¨æï¼ANN å¯ä»¥è§£æ±ºæ½è±¡æ¨çæ¸¬é©ãç¶èï¼éç¨®æåéè¦å»£æ³çè¨ç·´ãå¨æ¬ç ç©¶ä¸­ï¼æåæª¢é©äº ANN çå­¸ç¿ç¡éæ½è±¡æ¨çãå·é«ä¾èªªï¼æåè©ä¼°äºå®åå¨æ²æä»»ä½é è¨ç·´çææ³ä¸çè¡¨ç¾ï¼å¶ä¸­ ANN çæ¬éæ¯é¨æ©åå§åçï¼ä¸¦ä¸åå¨åé¡è§£æ±ºéç¨ä¸­ç¼çè®åãæåç¼ç¾ï¼æ¨¸ç´ ç ANN æ¨¡åå¯ä»¥è§£æ±ºéå¹³å¡çè¦è¦ºæ¨çæ¸¬é©ï¼é¡ä¼¼æ¼ç¨æ¼è©ä¼°äººé¡å­¸ç¿ç¡éæ¨ççæ¸¬é©ãæåé²ä¸æ­¥ç ç©¶äºæ¯æéç¨®è½åçæ©å¶ãæåççµæè¡¨æäºå­¸ç¿ç¡éæ½è±¡æ¨ççå¯è½æ§ï¼å®ä¸éè¦å»£æ³çè¨ç·´ã

##### **Very Large-Scale Multi-Agent Simulation in AgentScope**
2407.17789v1 by Xuchen Pan, Dawei Gao, Yuexiang Xie, Zhewei Wei, Yaliang Li, Bolin Ding, Ji-Rong Wen, Jingren Zhou

Recent advances in large language models (LLMs) have opened new avenues for
applying multi-agent systems in very large-scale simulations. However, there
remain several challenges when conducting multi-agent simulations with existing
platforms, such as limited scalability and low efficiency, unsatisfied agent
diversity, and effort-intensive management processes. To address these
challenges, we develop several new features and components for AgentScope, a
user-friendly multi-agent platform, enhancing its convenience and flexibility
for supporting very large-scale multi-agent simulations. Specifically, we
propose an actor-based distributed mechanism as the underlying technological
infrastructure towards great scalability and high efficiency, and provide
flexible environment support for simulating various real-world scenarios, which
enables parallel execution of multiple agents, centralized workflow
orchestration, and both inter-agent and agent-environment interactions among
agents. Moreover, we integrate an easy-to-use configurable tool and an
automatic background generation pipeline in AgentScope, simplifying the process
of creating agents with diverse yet detailed background settings. Last but not
least, we provide a web-based interface for conveniently monitoring and
managing a large number of agents that might deploy across multiple devices. We
conduct a comprehensive simulation to demonstrate the effectiveness of the
proposed enhancements in AgentScope, and provide detailed observations and
discussions to highlight the great potential of applying multi-agent systems in
large-scale simulations. The source code is released on GitHub at
https://github.com/modelscope/agentscope to inspire further research and
development in large-scale multi-agent simulations.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çææ°é²å±çºå¨éå¸¸å¤§è¦æ¨¡çæ¨¡æ¬ä¸­æç¨å¤ä¸»é«ç³»çµ±éé¢äºæ°éå¾ãç¶èï¼å¨ä½¿ç¨ç¾æå¹³å°é²è¡å¤ä¸»é«æ¨¡æ¬æï¼ä»ç¶å­å¨ä¸äºææ°ï¼ä¾å¦å¯æ´å±æ§æéä¸æçä½ãä¸»é«å¤æ¨£æ§ä¸è¶³ï¼ä»¥åç®¡çæµç¨éè¦å¤§éäººåãçºäºæå°éäºææ°ï¼æåçº AgentScopeï¼ä¸åä½¿ç¨èååçå¤ä¸»é«å¹³å°ï¼éç¼äºå¤é æ°åè½ååä»¶ï¼æåå¶ä¾¿å©æ§åéæ´»æ§ï¼ä»¥æ¯æ´éå¸¸å¤§è¦æ¨¡çå¤ä¸»é«æ¨¡æ¬ãå·é«ä¾èªªï¼æåæåºä¸ååºæ¼ actor çåæ£æ©å¶ä½çºåºå±¤æè¡åºç¤æ¶æ§ï¼ä»¥å¯¦ç¾æ¥µä½³çå¯æ´å±æ§åé«æçï¼ä¸¦æä¾éæ´»çç°å¢æ¯æ´ï¼ä»¥æ¨¡æ¬åç¨®çå¯¦ä¸ççå ´æ¯ï¼éä½¿å¾å¤åä¸»é«è½å¤ å¹³è¡å·è¡ãéä¸­å·¥ä½æµç¨ç·¨æï¼ä»¥åä¸»é«ä¹éåä¸»é«èç°å¢ä¹éçäºåãæ­¤å¤ï¼æåå°ä¸åææ¼ä½¿ç¨çå¯è¨­å®å·¥å·åä¸åèªåèæ¯çæç®¡éæ´åå° AgentScope ä¸­ï¼ç°¡åäºå»ºç«å·æå¤æ¨£åä¸è©³ç´°èæ¯è¨­å®çä¸»é«çæµç¨ãæå¾ä½ä¸¦éæä¸éè¦çä¸é»æ¯ï¼æåæä¾äºä¸ååºæ¼ç¶²è·¯çä»é¢ï¼ä»¥ä¾¿ä¾¿å©å°ç£æ§åç®¡çå¯è½é¨ç½²å¨å¤åè£ç½®ä¸çå¤§éä¸»é«ãæåé²è¡äºä¸é å¨é¢çæ¨¡æ¬ï¼ä»¥å±ç¤º AgentScope ä¸­ææåºå¢å¼·åè½çæææ§ï¼ä¸¦æä¾è©³ç´°çè§å¯åè¨è«ï¼ä»¥å¼·èª¿å¨å¤§åæ¨¡æ¬ä¸­æç¨å¤ä¸»é«ç³»çµ±çå·¨å¤§æ½åãåå§ç¢¼å·²å¨ GitHub ä¸éåºï¼ç¶²åçº https://github.com/modelscope/agentscopeï¼ä»¥æ¿åµå¨å¤§åå¤ä¸»é«æ¨¡æ¬ä¸­é²è¡é²ä¸æ­¥çç ç©¶åéç¼ã

##### **Advancing Multi-Modal Sensing Through Expandable Modality Alignment**
2407.17777v1 by Shenghong Dai, Shiqi Jiang, Yifan Yang, Ting Cao, Mo Li, Suman Banerjee, Lili Qiu

Sensing technology is widely used for comprehending the physical world, with
numerous modalities explored in past decades. While there has been considerable
work on multi-modality learning, they all require data of all modalities be
paired. How to leverage multi-modality data with partially pairings remains an
open problem. To tackle this challenge, we introduce the Babel framework,
encompassing the neural network architecture, data preparation and processing,
as well as the training strategies. Babel serves as a scalable pre-trained
multi-modal sensing neural network, currently aligning six sensing modalities,
namely Wi-Fi, mmWave, IMU, LiDAR, video, and depth. To overcome the scarcity of
complete paired data, the key idea of Babel involves transforming the
N-modality alignment into a series of two-modality alignments by devising the
expandable network architecture. This concept is also realized via a series of
novel techniques, including the pre-trained modality tower that capitalizes on
available single-modal networks, and the adaptive training strategy balancing
the contribution of the newly incorporated modality with the previously
established modality alignment.
  Evaluation demonstrates Babel's outstanding performance on eight human
activity recognition datasets, compared to various baselines e.g., the top
multi-modal sensing framework, single-modal sensing networks, and multi-modal
large language models. Babel not only effectively fuses multiple available
modalities (up to 22% accuracy increase), but also enhance the performance of
individual modality (12% averaged accuracy improvement). Case studies also
highlight exciting application scenarios empowered by Babel, including
cross-modality retrieval (i.e., sensing imaging), and bridging LLM for sensing
comprehension.

æè¦ï¼æç¥æè¡å»£æ³ç¨æ¼çè§£ç©çä¸çï¼å¨éå»çå¹¾åå¹´ä¸­æ¢ç´¢äºè¨±å¤æ¨¡å¼ãéç¶å·²ç¶å°å¤æ¨¡å¼å­¸ç¿é²è¡äºå¤§éç ç©¶ï¼ä½å®åé½éè¦æææ¨¡å¼çæ¸æéå°ãå¦ä½å©ç¨é¨åéå°çå¤æ¨¡å¼æ¸æä»ç¶æ¯ä¸åæªè§£æ±ºçåé¡ãçºäºæå°éä¸ææ°ï¼æåå¼å¥äº Babel æ¡æ¶ï¼å®åå«ç¥ç¶ç¶²çµ¡æ¶æ§ãæ¸ææºååèçä»¥åè¨ç·´ç­ç¥ãBabel ä½çºä¸åå¯æ´å±çé è¨ç·´å¤æ¨¡å¼æç¥ç¥ç¶ç¶²çµ¡ï¼ç®åå°é½å­ç¨®æç¥æ¨¡å¼ï¼å³ Wi-Fiãæ¯«ç±³æ³¢ãIMUãLiDARãè¦é »åæ·±åº¦ãçºäºåæéå°æ¸æçç¨ç¼ºæ§ï¼Babel çééµææ³æ¶åééè¨­è¨å¯æ´å±çç¶²çµ¡æ¶æ§ï¼å° N æ¨¡å¼å°é½è½æçºä¸ç³»åå©æ¨¡å¼å°é½ãéåæ¦å¿µä¹ééä¸ç³»åæ°æè¡å¯¦ç¾ï¼åæ¬å©ç¨å¯ç¨å®æ¨¡å¼ç¶²çµ¡çé è¨ç·´æ¨¡å¼å¡ï¼ä»¥åå¹³è¡¡æ°å å¥æ¨¡å¼èååå»ºç«æ¨¡å¼å°é½çè²¢ç»çèªé©æè¨ç·´ç­ç¥ãè©ä¼°è¡¨æï¼èåç¨®åºæºç¸æ¯ï¼Babel å¨å«åäººé¡æ´»åè­å¥æ¸æéä¸çè¡¨ç¾åºè²ï¼ä¾å¦é ç´å¤æ¨¡å¼æç¥æ¡æ¶ãå®æ¨¡å¼æç¥ç¶²çµ¡åå¤æ¨¡å¼å¤§åèªè¨æ¨¡åãBabel ä¸åææå°èåäºå¤ç¨®å¯ç¨æ¨¡å¼ï¼æºç¢ºçæé«äº 22%ï¼ï¼èä¸éæé«äºå®åæ¨¡å¼çæ§è½ï¼å¹³åæºç¢ºçæé«äº 12%ï¼ãæ¡ä¾ç ç©¶éå¼·èª¿äº Babel è³¦è½çä»¤äººèå¥®çæç¨å ´æ¯ï¼åæ¬è·¨æ¨¡å¼æª¢ç´¢ï¼å³ææ¸¬æåï¼åæ©æ¥ LLM ä»¥é²è¡ææ¸¬çè§£ã

##### **KiVA: Kid-inspired Visual Analogies for Testing Large Multimodal Models**
2407.17773v1 by Eunice Yiu, Maan Qraitem, Charlie Wong, Anisa Noor Majhi, Yutong Bai, Shiry Ginosar, Alison Gopnik, Kate Saenko

This paper investigates visual analogical reasoning in large multimodal
models (LMMs) compared to human adults and children. A "visual analogy" is an
abstract rule inferred from one image and applied to another. While benchmarks
exist for testing visual reasoning in LMMs, they require advanced skills and
omit basic visual analogies that even young children can make. Inspired by
developmental psychology, we propose a new benchmark of 1,400 visual
transformations of everyday objects to test LMMs on visual analogical reasoning
and compare them to children and adults. We structure the evaluation into three
stages: identifying what changed (e.g., color, number, etc.), how it changed
(e.g., added one object), and applying the rule to new scenarios. Our findings
show that while models like GPT-4V, LLaVA-1.5, and MANTIS identify the "what"
effectively, they struggle with quantifying the "how" and extrapolating this
rule to new objects. In contrast, children and adults exhibit much stronger
analogical reasoning at all three stages. Additionally, the strongest tested
model, GPT-4V, performs better in tasks involving simple visual attributes like
color and size, correlating with quicker human adult response times.
Conversely, more complex tasks such as number, rotation, and reflection, which
necessitate extensive cognitive processing and understanding of the 3D physical
world, present more significant challenges. Altogether, these findings
highlight the limitations of training models on data that primarily consists of
2D images and text.

æè¦ï¼<paragraph>æ¬ç¯è«ææ¢è¨å¤§åå¤æ¨¡ææ¨¡å (LMM) èäººé¡æäººååç«¥å¨è¦è¦ºé¡æ¯æ¨çä¸çå·®ç°ããè¦è¦ºé¡æ¯ãæ¯ä¸ç¨®å¾ä¸å¹ååæ¨è«åºçæ½è±¡è¦åï¼ä¸¦æç¨æ¼å¦ä¸å¹ååãéç¶ç¾ææ¸¬è©¦ LMM è¦è¦ºæ¨çè½åçåºæºï¼ä½éäºåºæºéè¦é²éæè½ï¼ä¸çç¥äºå³ä½¿å¹¼ç«¥ä¹è½ååºçåºæ¬è¦è¦ºé¡æ¯ãåç¼å±å¿çå­¸åç¼ï¼æåæåºä¸åæ°çåºæºï¼åå« 1,400 åæ¥å¸¸ç©é«çè¦è¦ºè½æï¼ä»¥æ¸¬è©¦ LMM çè¦è¦ºé¡æ¯æ¨çè½åï¼ä¸¦å°å¶èåç«¥åæäººé²è¡æ¯è¼ãæåå°è©ä¼°åçºä¸åéæ®µï¼æ¾åºæ¹è®çå§å®¹ï¼ä¾å¦é¡è²ãæ¸éç­ï¼ãæ¹è®çæ¹å¼ï¼ä¾å¦å¢å ä¸åç©ä»¶ï¼ï¼ä»¥åå°è¦åæç¨æ¼æ°çå ´æ¯ãæåçç ç©¶çµæé¡¯ç¤ºï¼åç®¡ GPT-4VãLLaVA-1.5 å MANTIS ç­æ¨¡åè½ææè­å¥ãæ¯ä»éº¼ãï¼ä½å®åå¨éåãå¦ä½ãä»¥åå°æ­¤è¦åæ¨å»£å°æ°ç©ä»¶æ¹é¢æå°é£ãç¸æ¯ä¹ä¸ï¼åç«¥åæäººåå¨ææä¸åéæ®µé½å±ç¾åºæ´å¼·çé¡æ¯æ¨çè½åãæ­¤å¤ï¼æ¸¬è©¦ä¸­è¡¨ç¾æå¥½çæ¨¡å GPT-4V å¨æ¶åç°¡å®è¦è¦ºå±¬æ§ï¼ä¾å¦é¡è²åå¤§å°ï¼çä»»åä¸­è¡¨ç¾è¼ä½³ï¼éèäººé¡æäººçåææéè¼å¿«æéãç¸åå°ï¼æ´è¤éçä»»åï¼ä¾å¦æ¸å­ãæè½ååå°ï¼éè¦å»£æ³çèªç¥èçåå° 3D ç©çä¸çççè§£ï¼å°æ¨¡åä¾èªªæ´å·ææ°æ§ãç¸½èè¨ä¹ï¼éäºç ç©¶çµæçªé¡¯äºå¨ä¸»è¦ç± 2D å½±ååæå­çµæçè³æä¸è¨ç·´æ¨¡åçéå¶ã</paragraph>

##### **Banyan: Improved Representation Learning with Explicit Structure**
2407.17771v1 by Mattia Opper, N. Siddharth

We present Banyan, an improved model to learn semantic representations by
inducing explicit structure over data. In contrast to prior approaches using
structure spanning single sentences, Banyan learns by resolving multiple
constituent structures into a shared one explicitly incorporating global
context. Combined with an improved message-passing scheme inspired by Griffin,
Banyan learns significantly better representations, avoids spurious false
negatives with contrastive learning, and drastically improves memory efficiency
in such explicit-structured models. Using the Self-StrAE framework, we show
that Banyan (a) outperforms baselines using sentential structure across various
settings (b) matches or outperforms unstructured baselines like GloVe
(+augmentations) and a RoBERTa medium (+simcse) pre-trained on 100M tokens,
despite having just a handful of (non-embedding) parameters, and (c) also
learns effective representations across several low resource (Asian and
African) languages as measured on SemRel tasks.

æè¦ï¼æåæåº Banyanï¼éæ¯ä¸åæ¹é²çæ¨¡åï¼å¯ä»¥ééå¨è³æä¸èªå°æç¢ºççµæ§ä¾å­¸ç¿èªç¾©è¡¨ç¤ºãèååä½¿ç¨è·¨è¶å®ä¸å¥å­ççµæ§çæ¹æ³ç¸åï¼Banyan ééå°å¤åçµæçµæ§è§£ææä¸åæç¢ºåå«å¨å±ä¸ä¸æçå±äº«çµæ§ä¾å­¸ç¿ãçµåå Griffin åç¼çæ¹è¯è¨æ¯å³éæ©å¶ï¼Banyan å¯ä»¥å­¸ç¿å°é¡¯èæ´å¥½çè¡¨ç¤ºï¼é¿åå°æ¯å­¸ç¿ä¸­çèåå¦å®ï¼ä¸¦å¤§å¹æé«æ­¤é¡æç¢ºçµæ§æ¨¡åä¸­çè¨æ¶é«æçãä½¿ç¨ Self-StrAE æ¡æ¶ï¼æåå±ç¤º Banyan (a) å¨åç¨®è¨­å®ä¸­ä½¿ç¨å¥å­çµæ§åªæ¼åºæº (b) å¹éæåªæ¼éçµæ§ååºæºï¼ä¾å¦ GloVe (+ æ´å) åå¨ 100M åä»£å¹£ä¸é è¨ç·´ç RoBERTa ä¸­å (+ simcse)ï¼åç®¡åªæå°æ¸ (éåµå¥) åæ¸ï¼èä¸ (c) ä¹å¨å¹¾åä½è³æº (äºæ´²åéæ´²) èªè¨ä¸­å­¸ç¿å°ææçè¡¨ç¤ºï¼å¦ SemRel ä»»åä¸­ææ¸¬éã

##### **BotEval: Facilitating Interactive Human Evaluation**
2407.17770v1 by Hyundong Cho, Thamme Gowda, Yuyang Huang, Zixun Lu, Tianli Tong, Jonathan May

Following the rapid progress in natural language processing (NLP) models,
language models are applied to increasingly more complex interactive tasks such
as negotiations and conversation moderations. Having human evaluators directly
interact with these NLP models is essential for adequately evaluating the
performance on such interactive tasks. We develop BotEval, an easily
customizable, open-source, evaluation toolkit that focuses on enabling
human-bot interactions as part of the evaluation process, as opposed to human
evaluators making judgements for a static input. BotEval balances flexibility
for customization and user-friendliness by providing templates for common use
cases that span various degrees of complexity and built-in compatibility with
popular crowdsourcing platforms. We showcase the numerous useful features of
BotEval through a study that evaluates the performance of various chatbots on
their effectiveness for conversational moderation and discuss how BotEval
differs from other annotation tools.

æè¦ï¼é¨èèªç¶èªè¨èç (NLP) æ¨¡åçå¿«éé²å±ï¼èªè¨æ¨¡åæ­£è¢«æç¨æ¼è¶ä¾è¶è¤éçäºåä»»åï¼ä¾å¦åååå°è©±èª¿ç¯ãè®äººé¡è©ä¼°äººå¡ç´æ¥èéäº NLP æ¨¡åäºåå°æ¼ååè©ä¼°æ­¤é¡äºåä»»åçæè½è³ééè¦ãæåéç¼äº BotEvalï¼éæ¯ä¸åææ¼èªè¨ãéæºçè©ä¼°å·¥å·åï¼å¶éé»å¨æ¼å°äººé¡æ©å¨äººäºåç´å¥è©ä¼°æµç¨çä¸é¨åï¼èä¸æ¯è®äººé¡è©ä¼°äººå¡å°éæè¼¸å¥ååºå¤æ·ãBotEval å¨èªè¨å½æ§åä½¿ç¨èååæ§ä¹éåå¾å¹³è¡¡ï¼æä¾é©ç¨æ¼åç¨®è¤éç¨åº¦çå¸¸è¦ä½¿ç¨æ¡ä¾ç¯æ¬ï¼ä¸¦å§å»ºèç±éç¾¤ç¾å¤åå¹³å°ç¸å®¹ãæåééä¸é ç ç©¶å±ç¤ºäº BotEval çè¨±å¤æç¨åè½ï¼è©²ç ç©¶è©ä¼°äºåç¨®èå¤©æ©å¨äººå¨å°è©±èª¿ç¯æ¹é¢çæææ§ï¼ä¸¦è¨è« BotEval èå¶ä»è¨»è§£å·¥å·æä½ä¸åã

##### **Mpox Detection Advanced: Rapid Epidemic Response Through Synthetic Data**
2407.17762v1 by Yudara Kularathne, Prathapa Janitha, Sithira Ambepitiya, Prarththanan Sothyrajah, Thanveer Ahamed, Dinuka Wijesundara

Rapid development of disease detection models using computer vision is
crucial in responding to medical emergencies, such as epidemics or bioterrorism
events. Traditional data collection methods are often too slow in these
scenarios, requiring innovative approaches for quick, reliable model generation
from minimal data. Our study introduces a novel approach by constructing a
comprehensive computer vision model to detect Mpox lesions using only synthetic
data. Initially, these models generated a diverse set of synthetic images
representing Mpox lesions on various body parts (face, back, chest, leg, neck,
arm) across different skin tones as defined by the Fitzpatrick scale (fair,
brown, dark skin). Subsequently, we trained and tested a vision model with this
synthetic dataset to evaluate the diffusion models' efficacy in producing
high-quality training data and its impact on the vision model's medical image
recognition performance. The results were promising; the vision model achieved
a 97% accuracy rate, with 96% precision and recall for Mpox cases, and
similarly high metrics for normal and other skin disorder cases, demonstrating
its ability to correctly identify true positives and minimize false positives.
The model achieved an F1-Score of 96% for Mpox cases and 98% for normal and
other skin disorders, reflecting a balanced precision-recall relationship, thus
ensuring reliability and robustness in its predictions. Our proposed
SynthVision methodology indicates the potential to develop accurate computer
vision models with minimal data input for future medical emergencies.

æè¦ï¼<paragraph>å©ç¨é»è¦è¦è¦ºå¿«ééç¼ç¾çæª¢æ¸¬æ¨¡åå°æ¼å æé«çç·æ¥äºä»¶ï¼ä¾å¦æµè¡çæçç©ææä¸»ç¾©äºä»¶ï¼è³ééè¦ãå³çµ±çè³ææ¶éæ¹æ³å¨éäºææ³ä¸éå¸¸å¤ªæ¢ï¼éè¦åµæ°çæ¹æ³æè½å¾æå°è³æä¸­å¿«éãå¯é å°ç¢çæ¨¡åãæåçç ç©¶ä»ç´¹äºä¸ç¨®æ°ç©çæ¹æ³ï¼ééå»ºæ§ä¸åå¨é¢çé»è¦è¦è¦ºæ¨¡åï¼åä½¿ç¨åæè³æä¾æª¢æ¸¬ç´ççç¶ãæåï¼éäºæ¨¡åç¢çäºä¸çµå¤æ¨£åçåæå½±åï¼ä»£è¡¨äºä¸åèè²ï¼æ ¹æ Fitzpatrick éè¡¨å®ç¾©çºç½çãæ£è²ãæ·±è²ç®èï¼ä¸ä¸åèº«é«é¨ä½ï¼èé¨ãèé¨ãè¸é¨ãè¿é¨ãé ¸é¨ãæèï¼çç´ççç¶ãé¨å¾ï¼æåä½¿ç¨éååæè³æéè¨ç·´åæ¸¬è©¦ä¸åè¦è¦ºæ¨¡åï¼ä»¥è©ä¼°æ´æ£æ¨¡åç¢çé«åè³ªè¨ç·´è³æçæè½ï¼ä»¥åå¶å°è¦è¦ºæ¨¡åé«å­¸å½±åè¾¨è­æè½çå½±é¿ãçµæä»¤äººæ»¿æï¼è¦è¦ºæ¨¡åéå°äº 97% çæºç¢ºçï¼ç´ççä¾çæºç¢ºåº¦åå¬åççº 96%ï¼æ­£å¸¸åå¶å®ç®èç¾ççä¾çææ¨ä¹åæ¨£é«ï¼è­æäºå®æ­£ç¢ºè¾¨è­çé½æ§ä¸¦å°åé½æ§éè³æä½çè½åãè©²æ¨¡åå¨ç´ççä¾ä¸­éå°äº 96% ç F1 åæ¸ï¼å¨æ­£å¸¸åå¶å®ç®èç¾çä¸­éå°äº 98%ï¼åæ åºå¹³è¡¡çæºç¢ºåº¦å¬åçéä¿ï¼å¾èç¢ºä¿å¶é æ¸¬çå¯é æ§åç©©å¥æ§ãæåæåºç SynthVision æ¹æ³è¡¨æï¼æå¯è½çºæªä¾çé«çç·æ¥äºä»¶éç¼åºæºç¢ºçé»è¦è¦è¦ºæ¨¡åï¼ä¸è³æè¼¸å¥éæå°ã</paragraph>

##### **TwIPS: A Large Language Model Powered Texting Application to Simplify Conversational Nuances for Autistic Users**
2407.17760v1 by Rukhshan Haroon, Fahad Dogar

Autistic individuals often experience difficulties in conveying and
interpreting emotional tone and non-literal nuances. Many also mask their
communication style to avoid being misconstrued by others, spending
considerable time and mental effort in the process. To address these challenges
in text-based communication, we present TwIPS, a prototype texting application
powered by a large language model (LLM), which can assist users with: a)
deciphering tone and meaning of incoming messages, b) ensuring the emotional
tone of their message is in line with their intent, and c) coming up with
alternate phrasing for messages that could be misconstrued and received
negatively by others. We leverage an AI-based simulation and a conversational
script to evaluate TwIPS with 8 autistic participants in an in-lab setting. Our
findings show TwIPS enables a convenient way for participants to seek
clarifications, provides a better alternative to tone indicators, and
facilitates constructive reflection on writing technique and style. We also
examine how autistic users utilize language for self-expression and
interpretation in instant messaging, and gather feedback for enhancing our
prototype. We conclude with a discussion around balancing user-autonomy with
AI-mediation, establishing appropriate trust levels in AI systems, and
customization needs if autistic users in the context of AI-assisted
communication

æè¦ï¼èªéçæ£èéå¸¸é£ä»¥å³éåè©®éæç·èªæ°£åéå­é¢å«ç¾©ãè¨±å¤äººä¹ææ©é£¾ä»åçæºéæ¹å¼ï¼ä»¥é¿åè¢«ä»äººèª¤è§£ï¼å¨æ­¤éç¨ä¸­è±è²»å¤§éæéåå¿åãçºäºæå°æå­æºéä¸­çéäºææ°ï¼æåæåºäº TwIPSï¼éæ¯ä¸åç±å¤§åèªè¨æ¨¡å (LLM) æä¾æ¯æ´çååç°¡è¨æç¨ç¨å¼ï¼å¯ä»¥åå©ä½¿ç¨èï¼a) è§£è®è¨æ¯çèªæ°£åå«ç¾©ï¼b) ç¢ºä¿ä»åè¨æ¯çæç·èªæ°£ç¬¦åä»åçæåï¼ä»¥å c) æ³åºå¶ä»æªè¾­ï¼ä»¥åè¨æ¯è¢«èª¤è§£ä¸¦è¢«ä»äººè² é¢æ¥æ¶ãæåå©ç¨åºæ¼ AI çæ¨¡æ¬åå°è©±è³æ¬ï¼å¨å¯¦é©å®¤ç°å¢ä¸­å° 8 ä½èªéçåèèè©ä¼° TwIPSãæåçç ç©¶çµæé¡¯ç¤ºï¼TwIPS è®åèèè½å¤ æ¹ä¾¿å°å°æ±æ¾æ¸ï¼æä¾äºä¸åæ¯èªæ°£ææ¨æ´å¥½çæ¿ä»£æ¹æ¡ï¼ä¸¦ä¿é²å°å¯«ä½æå·§åé¢¨æ ¼çå»ºè¨­æ§åæãæåéæ¢è¨äºèªéçä½¿ç¨èå¦ä½å©ç¨èªè¨å¨å³æè¨æ¯ä¸­é²è¡èªæè¡¨éåè©®éï¼ä¸¦æ¶éåé¥ä»¥å¢å¼·æåçååãæåæå¾è¨è«äºå¨ AI è¼å©æºéçèæ¯ä¸ï¼å¹³è¡¡ä½¿ç¨èèªä¸»æ§è AI åèª¿ãå»ºç«å° AI ç³»çµ±çé©ç¶ä¿¡ä»»ç¨åº¦ï¼ä»¥åèªéçä½¿ç¨èçå®¢è£½åéæ±ã

##### **Beyond Entity Alignment: Towards Complete Knowledge Graph Alignment via Entity-Relation Synergy**
2407.17745v1 by Xiaohan Fang, Chaozhuo Li, Yi Zhao, Qian Zang, Litian Zhang, Jiquan Peng, Xi Zhang, Jibing Gong

Knowledge Graph Alignment (KGA) aims to integrate knowledge from multiple
sources to address the limitations of individual Knowledge Graphs (KGs) in
terms of coverage and depth. However, current KGA models fall short in
achieving a ``complete'' knowledge graph alignment. Existing models primarily
emphasize the linkage of cross-graph entities but overlook aligning relations
across KGs, thereby providing only a partial solution to KGA. The semantic
correlations embedded in relations are largely overlooked, potentially
restricting a comprehensive understanding of cross-KG signals. In this paper,
we propose to conceptualize relation alignment as an independent task and
conduct KGA by decomposing it into two distinct but highly correlated
sub-tasks: entity alignment and relation alignment. To capture the mutually
reinforcing correlations between these objectives, we propose a novel
Expectation-Maximization-based model, EREM, which iteratively optimizes both
sub-tasks. Experimental results on real-world datasets demonstrate that EREM
consistently outperforms state-of-the-art models in both entity alignment and
relation alignment tasks.

æè¦ï¼ç¥è­åè­å°é½ (KGA) æ¨å¨æ´åä¾èªå¤åä¾æºçç¥è­ï¼ä»¥è§£æ±ºåå¥ç¥è­åè­ (KG) å¨æ¶µèç¯ååæ·±åº¦æ¹é¢çéå¶ãç¶èï¼ç¶åç KGA æ¨¡åç¡æ³éæãå®æ´çãç¥è­åè­å°é½ãç¾æçæ¨¡åä¸»è¦å¼·èª¿è·¨åè­å¯¦é«çé£çµï¼ä½å¿½ç¥äºè·¨ KG å°é½éä¿ï¼å æ­¤åæä¾ KGA çé¨åè§£æ±ºæ¹æ¡ãéä¿ä¸­å§åµçèªç¾©éè¯æ§å¨å¾å¤§ç¨åº¦ä¸è¢«å¿½ç¥ï¼éå¯è½æéå¶å°è·¨ KG è¨èçå¨é¢çè§£ãå¨æ¬æä¸­ï¼æåå»ºè­°å°éä¿å°é½æ¦å¿µåçºä¸åç¨ç«çä»»åï¼ä¸¦ééå°å¶åè§£çºå©åä¸åä½é«åº¦ç¸éçå­ä»»åï¼å¯¦é«å°é½åéä¿å°é½ï¼ä¾å·è¡ KGAãçºäºææéäºç®æ¨ä¹éç¸äºå¼·åçéè¯æ§ï¼æåæåºäºä¸åæ°çåºæ¼æææå¤§åçæ¨¡å EREMï¼å®è¿­ä»£åªåå©åå­ä»»åãå¨çå¯¦ä¸çè³æéä¸çå¯¦é©çµæè¡¨æï¼å¨å¯¦é«å°é½åéä¿å°é½ä»»åä¸­ï¼EREM æçºåªæ¼æåé²çæ¨¡åã

##### **Cost-effective Instruction Learning for Pathology Vision and Language Analysis**
2407.17734v1 by Kaitao Chen, Mianxin Liu, Fang Yan, Lei Ma, Xiaoming Shi, Lilong Wang, Xiaosong Wang, Lifeng Zhu, Zhe Wang, Mu Zhou, Shaoting Zhang

The advent of vision-language models fosters the interactive conversations
between AI-enabled models and humans. Yet applying these models into clinics
must deal with daunting challenges around large-scale training data, financial,
and computational resources. Here we propose a cost-effective instruction
learning framework for conversational pathology named as CLOVER. CLOVER only
trains a lightweight module and uses instruction tuning while freezing the
parameters of the large language model. Instead of using costly GPT-4, we
propose well-designed prompts on GPT-3.5 for building generation-based
instructions, emphasizing the utility of pathological knowledge derived from
the Internet source. To augment the use of instructions, we construct a
high-quality set of template-based instructions in the context of digital
pathology. From two benchmark datasets, our findings reveal the strength of
hybrid-form instructions in the visual question-answer in pathology. Extensive
results show the cost-effectiveness of CLOVER in answering both open-ended and
closed-ended questions, where CLOVER outperforms strong baselines that possess
37 times more training parameters and use instruction data generated from
GPT-4. Through the instruction tuning, CLOVER exhibits robustness of few-shot
learning in the external clinical dataset. These findings demonstrate that
cost-effective modeling of CLOVER could accelerate the adoption of rapid
conversational applications in the landscape of digital pathology.

æè¦ï¼è¦è¦ºèªè¨æ¨¡åçåºç¾ä¿é²äº AI åç¨æ¨¡åèäººé¡ä¹éçäºåå°è©±ãç¶èï¼å°éäºæ¨¡åæç¨æ¼è¨åºå¿é æå°å¤§è¦æ¨¡è¨ç·´æ¸æãè²¡ååè¨ç®è³æºç­å´å³»ææ°ãå¨æ­¤ï¼æåæåºäºä¸ååçº CLOVER çç¶æ¿é«æçæè©±ççå­¸æä»¤å­¸ç¿æ¶æ§ãCLOVER åè¨ç·´ä¸åè¼éç´æ¨¡çµï¼ä¸¦å¨åçµå¤§åèªè¨æ¨¡ååæ¸çåæä½¿ç¨æä»¤å¾®èª¿ãæåæ²æä½¿ç¨æè²´ç GPT-4ï¼èæ¯éå° GPT-3.5 æåºè¨­è¨è¯å¥½çæç¤ºï¼ä»¥å»ºç«åºæ¼çæçæä»¤ï¼å¼·èª¿å¾ç¶²éç¶²è·¯ä¾æºè¡ççççç¥è­çæç¨ãçºäºæ´å±æä»¤çä½¿ç¨ï¼æåå¨æ¸ä½ççå­¸çèæ¯ä¸æ§å»ºäºä¸çµé«åè³ªçåºæ¼ç¯æ¬çæä»¤ãå¾å©ååºæºè³æéï¼æåçç ç©¶çµææ­ç¤ºäºæ··åå½¢å¼æä»¤å¨ççå­¸è¦è¦ºåç­ä¸­çåªå¢ãå»£æ³ççµæé¡¯ç¤ºäº CLOVER å¨åç­éæ¾å¼åå°éå¼åé¡æ¹é¢çç¶æ¿æçï¼å¶ä¸­ CLOVER åªæ¼ææå¤ 37 åè¨ç·´åæ¸ä¸¦ä½¿ç¨å¾ GPT-4 çæçæä»¤è³æçå¼·å¤§åºæºãééæä»¤å¾®èª¿ï¼CLOVER å¨å¤é¨è¨åºè³æéä¸­å±ç¾äºå°æ¨£æ¬å­¸ç¿çç©©å¥æ§ãéäºç¼ç¾è­æäº CLOVER çç¶æ¿é«æå»ºæ¨¡å¯ä»¥å éå¨æ¸ä½ççé åæ¡ç¨å¿«éå°è©±å¼æç¨ç¨å¼ã

##### **Are Large Language Models Possible to Conduct Cognitive Behavioral Therapy?**
2407.17730v1 by Hao Shen, Zihan Li, Minqiang Yang, Minghui Ni, Yongfeng Tao, Zhengyang Yu, Weihao Zheng, Chen Xu, Bin Hu

In contemporary society, the issue of psychological health has become
increasingly prominent, characterized by the diversification, complexity, and
universality of mental disorders. Cognitive Behavioral Therapy (CBT), currently
the most influential and clinically effective psychological treatment method
with no side effects, has limited coverage and poor quality in most countries.
In recent years, researches on the recognition and intervention of emotional
disorders using large language models (LLMs) have been validated, providing new
possibilities for psychological assistance therapy. However, are LLMs truly
possible to conduct cognitive behavioral therapy? Many concerns have been
raised by mental health experts regarding the use of LLMs for therapy. Seeking
to answer this question, we collected real CBT corpus from online video
websites, designed and conducted a targeted automatic evaluation framework
involving the evaluation of emotion tendency of generated text, structured
dialogue pattern and proactive inquiry ability. For emotion tendency, we
calculate the emotion tendency score of the CBT dialogue text generated by each
model. For structured dialogue pattern, we use a diverse range of automatic
evaluation metrics to compare speaking style, the ability to maintain
consistency of topic and the use of technology in CBT between different models
. As for inquiring to guide the patient, we utilize PQA (Proactive Questioning
Ability) metric. We also evaluated the CBT ability of the LLM after integrating
a CBT knowledge base to explore the help of introducing additional knowledge to
enhance the model's CBT counseling ability. Four LLM variants with excellent
performance on natural language processing are evaluated, and the experimental
result shows the great potential of LLMs in psychological counseling realm,
especially after combining with other technological means.

æè¦ï¼å¨ç¶ä»£ç¤¾æä¸­ï¼å¿çå¥åº·è­°é¡æ¥çåå°éè¦ï¼å¶ç¹å¾µå¨æ¼å¿çç¾ççå¤æ¨£åãè¤éåãæ®éåãèªç¥è¡çºçæ³ï¼CBTï¼ï¼ç®åæå·å½±é¿åä¸è¨åºçææå¥½çå¿çæ²»çæ¹æ³ï¼å¨å¤æ¸åå®¶è¦èçä½ä¸åè³ªä¸ä½³ãè¿å¹´ä¾ï¼å©ç¨å¤§åèªè¨æ¨¡åï¼LLMï¼è¾¨è­èä»å¥æç·ç¾æ£çç ç©¶ç²å¾é©è­ï¼çºå¿çè«®å©æ²»çå¸¶ä¾æ°çå¯è½æ§ãç¶èï¼LLM æ¯å¦çè½å·è¡èªç¥è¡çºæ²»çï¼è¨±å¤å¿çå¥åº·å°å®¶å°æ¼ LLM æç¨æ¼æ²»çæåºçæ®ãçºäºè§£ç­æ­¤åé¡ï¼æåå¾ç·ä¸å½±é³ç¶²ç«èéçå¯¦ç CBT èªæï¼è¨­è¨ä¸¦å·è¡ç®æ¨èªåè©ä¼°æ¶æ§ï¼åå«è©ä¼°çææå­çæç·å¾åãçµæ§åå°è©±æ¨¡å¼åä¸»åæåè½åãå°æ¼æç·å¾åï¼æåè¨ç®ååæ¨¡åç¢çç CBT å°è©±æå­çæç·å¾ååæ¸ãå°æ¼çµæ§åå°è©±æ¨¡å¼ï¼æåä½¿ç¨å¤åçèªåè©ä¼°ææ¨ï¼æ¯è¼ä¸åæ¨¡åå¨ CBT ä¸­çèªªè©±é¢¨æ ¼ãç¶­æä¸»é¡ä¸è´æ§çè½ååä½¿ç¨æè¡ãè³æ¼å¼å°çæ£æåï¼æåæ¡ç¨ PQAï¼ä¸»åæåè½åï¼ææ¨ãæåä¹è©ä¼° LLM æ´å CBT ç¥è­åº«å¾ç CBT è½åï¼æ¢è¨å¼å¥é¡å¤ç¥è­å°æ¼å¢å¼·æ¨¡å CBT è«®åè½åçå¹«å©ãè©ä¼°åç¨®å¨èªç¶èªè¨èçè¡¨ç¾åªç°ç LLM è®é«ï¼å¯¦é©çµæé¡¯ç¤º LLM å¨å¿çè«®åé åææ¥µå¤§çæ½åï¼ç¹å¥æ¯å¨çµåå¶ä»æè¡ææ®µå¾ã

##### **Describe Where You Are: Improving Noise-Robustness for Speech Emotion Recognition with Text Description of the Environment**
2407.17716v1 by Seong-Gyun Leem, Daniel Fulford, Jukka-Pekka Onnela, David Gard, Carlos Busso

Speech emotion recognition (SER) systems often struggle in real-world
environments, where ambient noise severely degrades their performance. This
paper explores a novel approach that exploits prior knowledge of testing
environments to maximize SER performance under noisy conditions. To address
this task, we propose a text-guided, environment-aware training where an SER
model is trained with contaminated speech samples and their paired noise
description. We use a pre-trained text encoder to extract the text-based
environment embedding and then fuse it to a transformer-based SER model during
training and inference. We demonstrate the effectiveness of our approach
through our experiment with the MSP-Podcast corpus and real-world additive
noise samples collected from the Freesound repository. Our experiment indicates
that the text-based environment descriptions processed by a large language
model (LLM) produce representations that improve the noise-robustness of the
SER system. In addition, our proposed approach with an LLM yields better
performance than our environment-agnostic baselines, especially in low
signal-to-noise ratio (SNR) conditions. When testing at -5dB SNR level, our
proposed method shows better performance than our best baseline model by 31.8 %
(arousal), 23.5% (dominance), and 9.5% (valence).

æè¦ï¼èªé³æç·è¾¨è­ (SER) ç³»çµ±å¨çå¯¦ä¸ççç°å¢ä¸­å¸¸å¸¸æéå°å°é£ï¼å çºç°å¢åªé³æå´ééä½å¶æè½ãæ¬ææ¢è¨äºä¸ç¨®æ°æ¹æ³ï¼å©ç¨æ¸¬è©¦ç°å¢çåé©ç¥è­ï¼å¨æåªé³çæ¢ä»¶ä¸æå¤§å SER æè½ãçºäºèçéåä»»åï¼æåæåºä¸åæå­å°å¼ãç°å¢æç¥çè¨ç·´ï¼å¶ä¸­ SER æ¨¡åä½¿ç¨åæ±æçèªé³ç¯ä¾åå¶éå°çåªé³æè¿°é²è¡è¨ç·´ãæåä½¿ç¨é åè¨ç·´çæå­ç·¨ç¢¼å¨ä¾èååºæ¼æå­çç°å¢åµå¥ï¼ç¶å¾å¨è¨ç·´åæ¨è«æéå°å¶èåå°åºæ¼è½æå¨ç SER æ¨¡åä¸­ãæåééä½¿ç¨ MSP-Podcast èªæåº«åå¾ Freesound è³æåº«æ¶éççå¯¦ä¸çå æåªé³ç¯ä¾é²è¡å¯¦é©ï¼è­æäºæåæ¹æ³çæææ§ãæåçå¯¦é©è¡¨æï¼ç±å¤§åèªè¨æ¨¡å (LLM) èççåºæ¼æå­çç°å¢æè¿°æç¢çè¡¨å¾µï¼é²èæå SER ç³»çµ±çæåªæ§ãæ­¤å¤ï¼æåæåºçä½¿ç¨ LLM çæ¹æ³æ¯æåèç°å¢ç¡éçåºæºç·ææ´å¥½çæè½ï¼ç¹å¥æ¯å¨ä½è¨åªæ¯ (SNR) æ¢ä»¶ä¸ãç¶å¨ -5dB SNR ç­ç´é²è¡æ¸¬è©¦æï¼æåæåºçæ¹æ³æ¯æåæå¥½çåºæºç·æ¨¡åå¨åéæ¹é¢æåäº 31.8%ï¼å¨æ¯éæ¹é¢æåäº 23.5%ï¼å¨æå¹æ¹é¢æåäº 9.5%ã

##### **Enhancing Agent Learning through World Dynamics Modeling**
2407.17695v1 by Zhiyuan Sun, Haochen Shi, Marc-Alexandre CÃ´tÃ©, Glen Berseth, Xingdi Yuan, Bang Liu

While large language models (LLMs) have been increasingly deployed across
tasks in language understanding and interactive decision-making, their
impressive performance is largely due to the comprehensive and in-depth domain
knowledge embedded within them. However, the extent of this knowledge can vary
across different domains. Existing methods often assume that LLMs already
possess such comprehensive and in-depth knowledge of their environment,
overlooking potential gaps in their understanding of actual world dynamics. To
address this gap, we introduce Discover, Verify, and Evolve (DiVE), a framework
that discovers world dynamics from a small number of demonstrations, verifies
the correctness of these dynamics, and evolves new, advanced dynamics tailored
to the current situation. Through extensive evaluations, we analyze the impact
of each component on performance and compare the automatically generated
dynamics from DiVE with human-annotated world dynamics. Our results demonstrate
that LLMs guided by DiVE can make better decisions, achieving rewards
comparable to human players in the Crafter environment.

æè¦ï¼åç®¡å¤§åèªè¨æ¨¡å (LLM) å·²å¨èªè¨çè§£åäºåæ±ºç­å¶å®ç­ä»»åä¸­å¾å°è¶ä¾è¶å»£æ³çé¨ç½²ï¼ä½å®åä»¤äººå°è±¡æ·±å»çè¡¨ç¾å¾å¤§ç¨åº¦ä¸æ­¸åæ¼å§åµå¨å¶ä¸­çå¨é¢ä¸æ·±å¥çé åç¥è­ãç¶èï¼éç¨®ç¥è­çç¨åº¦å¨ä¸åçé åä¸­å¯è½ææä¸åãç¾ææ¹æ³éå¸¸åè¨­ LLM å·²å·åå°å¶ç°å¢çå¨é¢ä¸æ·±å¥çäºè§£ï¼å¿½è¦äºå®åå°å¯¦éä¸çåæçè§£ä¸­çæ½å¨å·®è·ãçºäºè§£æ±ºéåå·®è·ï¼æåå¼å¥äºæ¢ç´¢ãé©è­åæ¼å (DiVE)ï¼éæ¯ä¸åæ¡æ¶ï¼å®å¾å°æ¸ç¤ºç¯ä¸­æ¢ç´¢ä¸çåæï¼é©è­éäºåæçæ­£ç¢ºæ§ï¼ä¸¦æ¼ååºæ°çãåé²çåæï¼éäºåæå°ééå°ç¶åææ³ãééå»£æ³çè©ä¼°ï¼æååæäºæ¯åçµæé¨åå°æè½çå½±é¿ï¼ä¸¦å° DiVE èªåç¢ççåæèäººå·¥æ¨è¨»çä¸çåæé²è¡æ¯è¼ãæåççµæè¡¨æï¼ç± DiVE æå°ç LLM å¯ä»¥ååºæ´å¥½çæ±ºç­ï¼å¨ Crafter ç°å¢ä¸­ç²å¾èäººé¡ç©å®¶ç¸ç¶ççåµã

##### **Examining the Influence of Political Bias on Large Language Model Performance in Stance Classification**
2407.17688v1 by Lynnette Hui Xian Ng, Iain Cruickshank, Roy Ka-Wei Lee

Large Language Models (LLMs) have demonstrated remarkable capabilities in
executing tasks based on natural language queries. However, these models,
trained on curated datasets, inherently embody biases ranging from racial to
national and gender biases. It remains uncertain whether these biases impact
the performance of LLMs for certain tasks. In this study, we investigate the
political biases of LLMs within the stance classification task, specifically
examining whether these models exhibit a tendency to more accurately classify
politically-charged stances. Utilizing three datasets, seven LLMs, and four
distinct prompting schemes, we analyze the performance of LLMs on politically
oriented statements and targets. Our findings reveal a statistically
significant difference in the performance of LLMs across various politically
oriented stance classification tasks. Furthermore, we observe that this
difference primarily manifests at the dataset level, with models and prompting
schemes showing statistically similar performances across different stance
classification datasets. Lastly, we observe that when there is greater
ambiguity in the target the statement is directed towards, LLMs have poorer
stance classification accuracy.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨å·è¡åºæ¼èªç¶èªè¨æ¥è©¢çä»»åæå±ç¾åºéå¡çè½åãç¶èï¼éäºå¨ç­å±è³æéä¸è¨ç·´çæ¨¡åæ¬è³ªä¸æé«ç¾åç¨®åè¦ï¼å¾ç¨®æå°åå®¶åæ§å¥åè¦ãéäºåè¦æ¯å¦æå½±é¿ LLM å¨æäºä»»åä¸­çè¡¨ç¾ä»ä¸ç¢ºå®ãå¨éé ç ç©¶ä¸­ï¼æåæ¢è¨äº LLM å¨ç«å ´åé¡ä»»åä¸­çæ¿æ²»åè¦ï¼ç¹å¥æ¯æª¢è¦éäºæ¨¡åæ¯å¦è¡¨ç¾åºæ´æºç¢ºåé¡æ¿æ²»ç«å ´çå¾åãæåå©ç¨ä¸åè³æéãä¸å LLM ååç¨®ä¸åçæç¤ºæ¹æ¡ï¼åæäº LLM å¨æ¿æ²»å°åé³è¿°åç®æ¨ä¸çè¡¨ç¾ãæåçç ç©¶çµææ­ç¤ºäº LLM å¨åç¨®æ¿æ²»å°åç«å ´åé¡ä»»åä¸­çè¡¨ç¾å­å¨çµ±è¨ä¸é¡¯èçå·®ç°ãæ­¤å¤ï¼æåè§å¯å°éç¨®å·®ç°ä¸»è¦è¡¨ç¾å¨è³æéå±¤ç´ï¼æ¨¡ååæç¤ºæ¹æ¡å¨ä¸åçç«å ´åé¡è³æéä¸­è¡¨ç¾åºçµ±è¨ä¸ç¸ä¼¼çè¡¨ç¾ãæå¾ï¼æåè§å¯å°ï¼ç¶é³è¿°æéå°çç®æ¨å­å¨è¼å¤§çæ­§ç¾©æï¼LLM çç«å ´åé¡æºç¢ºåº¦è¼å·®ã

##### **Transformers on Markov Data: Constant Depth Suffices**
2407.17686v1 by Nived Rajaraman, Marco Bondaschi, Kannan Ramchandran, Michael Gastpar, Ashok Vardhan Makkuva

Attention-based transformers have been remarkably successful at modeling
generative processes across various domains and modalities. In this paper, we
study the behavior of transformers on data drawn from \kth Markov processes,
where the conditional distribution of the next symbol in a sequence depends on
the previous $k$ symbols observed. We observe a surprising phenomenon
empirically which contradicts previous findings: when trained for sufficiently
long, a transformer with a fixed depth and $1$ head per layer is able to
achieve low test loss on sequences drawn from \kth Markov sources, even as $k$
grows. Furthermore, this low test loss is achieved by the transformer's ability
to represent and learn the in-context conditional empirical distribution. On
the theoretical side, our main result is that a transformer with a single head
and three layers can represent the in-context conditional empirical
distribution for \kth Markov sources, concurring with our empirical
observations. Along the way, we prove that \textit{attention-only} transformers
with $O(\log_2(k))$ layers can represent the in-context conditional empirical
distribution by composing induction heads to track the previous $k$ symbols in
the sequence. These results provide more insight into our current understanding
of the mechanisms by which transformers learn to capture context, by
understanding their behavior on Markov sources.

æè¦ï¼åºæ¼æ³¨æåçTransformerå¨å°åç¨®é ååæ¨¡æççæå¼éç¨å»ºæ¨¡æ¹é¢åå¾äºé¡¯èçæåãå¨æ¬æä¸­ï¼æåç ç©¶äºTransformerå¨å¾ k éé¦¬å¯å¤«éç¨ä¸­æåçè³æä¸çè¡çºï¼å¶ä¸­åºåä¸­ä¸ä¸åç¬¦èçæ¢ä»¶åä½åæ±ºæ¼è§å¯å°çå k åç¬¦èãæåå¨ç¶é©ä¸è§å¯å°ä¸åé©äººçç¾è±¡ï¼éèååçç¼ç¾ç¸çç¾ï¼ç¶éååé·çè¨ç·´å¾ï¼å·æåºå®æ·±åº¦åæ¯å±¤ 1 åé ­çTransformerè½å¤ å¨å¾ k éé¦¬å¯å¤«æºä¸­æåçåºåä¸å¯¦ç¾ä½æ¸¬è©¦æå¤±ï¼å³ä½¿ k å¢é·ãæ­¤å¤ï¼éç¨®ä½æ¸¬è©¦æå¤±æ¯ééTransformerè¡¨ç¤ºåå­¸ç¿ä¸ä¸ææ¢ä»¶ç¶é©åä½çè½åå¯¦ç¾çãå¨çè«æ¹é¢ï¼æåççä¸»è¦çµææ¯å·æå®åé ­åä¸å±¤çTransformerå¯ä»¥è¡¨ç¤º k éé¦¬å¯å¤«æºçä¸ä¸ææ¢ä»¶ç¶é©åä½ï¼éèæåçç¶é©è§å¯çµæä¸è´ãå¨æ­¤éç¨ä¸­ï¼æåè­æäºå·æ O(log_2(k)) å±¤çãåæ³¨æåãTransformerå¯ä»¥ééçµåæ­¸ç´é ­é¨ä¾è¿½è¹¤åºåä¸­çå k åç¬¦èï¼å¾èè¡¨ç¤ºä¸ä¸ææ¢ä»¶ç¶é©åä½ãéäºçµæééçè§£Transformerå¨é¦¬å¯å¤«æºä¸çè¡çºï¼å°æåç¶åå°Transformerå­¸ç¿ææä¸ä¸æçæ©å¶ççè§£æä¾äºæ´å¤è¦è§£ã

##### **Efficient LLM Training and Serving with Heterogeneous Context Sharding among Attention Heads**
2407.17678v1 by Xihui Lin, Yunan Zhang, Suyu Ge, Barun Patra, Vishrav Chaudhary, Xia Song

Existing LLM training and inference frameworks struggle in boosting
efficiency with sparsity while maintaining the integrity of context and model
architecture. Inspired by the sharding concept in database and the fact that
attention parallelizes over heads on accelerators, we propose Sparsely-Sharded
(S2) Attention, an attention algorithm that allocates heterogeneous context
partitions for different attention heads to divide and conquer. S2-Attention
enforces each attention head to only attend to a partition of contexts
following a strided sparsity pattern, while the full context is preserved as
the union of all the shards. As attention heads are processed in separate
thread blocks, the context reduction for each head can thus produce end-to-end
speed-up and memory reduction. At inference, LLMs trained with S2-Attention can
then take the KV cache reduction as free meals with guaranteed model quality
preserve. In experiments, we show S2-Attentioncan provide as much as (1) 25.3X
wall-clock attention speed-up over FlashAttention-2, resulting in 6X reduction
in end-to-end training time and 10X inference latency, (2) on-par model
training quality compared to default attention, (3)perfect needle retrieval
accuracy over 32K context window. On top of the algorithm, we build DKernel, an
LLM training and inference kernel library that allows users to customize
sparsity patterns for their own models. We open-sourced DKerneland make it
compatible with Megatron, Pytorch, and vLLM.

æè¦ï¼ç¾æç LLM è¨ç·´åæ¨çæ¶æ§å¨æåç¨çæ§æççåæï¼é£ä»¥ç¶­æèçµ¡åæ¨¡åæ¶æ§çå®æ´æ§ãåå°è³æåº«åçæ¦å¿µåæ³¨æåå¨å éå¨ä¸å¹³è¡æ¼é ­é¨çåç¼ï¼æåæåºç¨çåç (S2) æ³¨æåï¼éæ¯ä¸ç¨®æ³¨æåæ¼ç®æ³ï¼å®åéç°è³ªèçµ¡åå²ï¼ä¾ä¸åçæ³¨æåé ­é¨é²è¡åèæ²»ä¹ãS2-Attention å¼·å¶æ¯åæ³¨æåé ­é¨åªéæ³¨èçµ¡åå²ï¼éµå¾ªåæ­¥ç¨çæ§æ¨¡å¼ï¼åæå°å®æ´èçµ¡ä¿ççºææåççè¯éãç±æ¼æ³¨æåé ­é¨å¨ç¨ç«çå·è¡ç·åå¡ä¸­èçï¼å æ­¤æ¯åé ­é¨çèçµ¡ç°¡åå¯ä»¥ç¢çç«¯å°ç«¯çå éåè¨æ¶é«æ¸å°ãå¨æ¨çæï¼ä½¿ç¨ S2-Attention è¨ç·´ç LLM å¯ä»¥å° KV å¿«åç°¡åè¦çºåè²»é¤é»ï¼åæä¿è­æ¨¡ååè³ªä¿æä¸è®ãå¨å¯¦é©ä¸­ï¼æåå±ç¤º S2-Attention å¯ä»¥æä¾é«é (1) 25.3 åç FlashAttention-2 çé¢æèæ³¨æåå éï¼å¾èå°ç«¯å°ç«¯è¨ç·´æéæ¸å° 6 åï¼å°æ¨çå»¶é²æ¸å° 10 åï¼(2) èé è¨­æ³¨æåç¸æ¯ï¼æ¨¡åè¨ç·´åè³ªç¸ç¶ï¼(3) å¨ 32K èçµ¡è¦çªä¸­å®ç¾ç¡ç¼ºçéé ­æª¢ç´¢æºç¢ºåº¦ãå¨æ¼ç®æ³ä¹ä¸ï¼æåå»ºæ§äº DKernelï¼éæ¯ä¸å LLM è¨ç·´åæ¨çæ ¸å¿å½å¼åº«ï¼åè¨±ä½¿ç¨èçºèªå·±çæ¨¡åèªè¨ç¨çæ§æ¨¡å¼ãæåéæ¾åå§ç¢¼ DKernelï¼ä¸¦ä½¿å¶è MegatronãPytorch å vLLM ç¸å®¹ã

##### **CRASAR-U-DROIDs: A Large Scale Benchmark Dataset for Building Alignment and Damage Assessment in Georectified sUAS Imagery**
2407.17673v1 by Thomas Manzini, Priyankari Perali, Raisa Karnik, Robin Murphy

This document presents the Center for Robot Assisted Search And Rescue -
Uncrewed Aerial Systems - Disaster Response Overhead Inspection Dataset
(CRASAR-U-DROIDs) for building damage assessment and spatial alignment
collected from small uncrewed aerial systems (sUAS) geospatial imagery. This
dataset is motivated by the increasing use of sUAS in disaster response and the
lack of previous work in utilizing high-resolution geospatial sUAS imagery for
machine learning and computer vision models, the lack of alignment with
operational use cases, and with hopes of enabling further investigations
between sUAS and satellite imagery. The CRASAR-U-DRIODs dataset consists of
fifty-two (52) orthomosaics from ten (10) federally declared disasters
(Hurricane Ian, Hurricane Ida, Hurricane Harvey, Hurricane Idalia, Hurricane
Laura, Hurricane Michael, Musset Bayou Fire, Mayfield Tornado, Kilauea
Eruption, and Champlain Towers Collapse) spanning 67.98 square kilometers
(26.245 square miles), containing 21,716 building polygons and damage labels,
and 7,880 adjustment annotations. The imagery was tiled and presented in
conjunction with overlaid building polygons to a pool of 130 annotators who
provided human judgments of damage according to the Joint Damage Scale. These
annotations were then reviewed via a two-stage review process in which building
polygon damage labels were first reviewed individually and then again by
committee. Additionally, the building polygons have been aligned spatially to
precisely overlap with the imagery to enable more performant machine learning
models to be trained. It appears that CRASAR-U-DRIODs is the largest labeled
dataset of sUAS orthomosaic imagery.

æè¦ï¼<paragraph>æ¬æä»¶å±ç¤ºäºæ©å¨äººåå©æå°åææ´ä¸­å¿ - ç¡äººæ©ç³»çµ± - ç½é£æè®èªææª¢æ¸¬è³æé (CRASAR-U-DROIDs)ï¼ç¨æ¼å»ºç¯æå®³è©ä¼°åç©ºéå°é½ï¼è³æéæ¶éèªå°åç¡äººæ© (sUAS) å°çç©ºéå½±åãæ­¤è³æéçåæ©ä¾èªæ¼ sUAS å¨ç½é£æè®ä¸­ä½¿ç¨æ¥çå¢å ï¼ä»¥åååç¼ºä¹å©ç¨é«è§£æåº¦ sUAS å°çç©ºéå½±åé²è¡æ©å¨å­¸ç¿åé»è¦è¦è¦ºæ¨¡åãç¼ºä¹èæä½ä½¿ç¨æ¡ä¾å°é½ï¼ä»¥åå¸æä¿æ sUAS åè¡æå½±åä¹éé²ä¸æ­¥èª¿æ¥ãCRASAR-U-DROIDs è³æéåå«ä¾èªå (10) åè¯é¦å®£å¸çç½é£ (ä¼æ©é¢¶é¢¨ãè¾éé¢¶é¢¨ãåç¶­é¢¶é¢¨ãä¼éèäºé¢¶é¢¨ãåæé¢¶é¢¨ãéº¥å¯é¢¶é¢¨ãé¦¬å¡ç¹ç£å¤§ç«ãæ¢è²ç¾å¾·é¾æ²é¢¨ãåºæéåç«å±±çç¼åå°æ®è­å¤§å»åå¡) çäºåäº (52) åæ­£å°å½±åï¼æ¶µè 67.98 å¹³æ¹å¬é (26.245 å¹³æ¹è±é)ï¼åå« 21,716 åå»ºç¯å¤éå½¢åæå®³æ¨ç±¤ï¼ä»¥å 7,880 åèª¿æ´è¨»è§£ãå½±åä»¥æ¼è²¼æ¹å¼åç¾ï¼ä¸¦èçå çå»ºç¯å¤éå½¢ä¸èµ·åç¾çµ¦ 130 ä½è¨»è§£èï¼ä»åæ ¹æè¯åæå®³éè¡¨æä¾äººçºæå®³å¤æ·ãç¶å¾ééå©éæ®µå¯©æ¥æµç¨å¯©æ¥éäºè¨»è§£ï¼å¶ä¸­å»ºç¯å¤éå½¢æå®³æ¨ç±¤ååå¥å¯©æ¥ï¼ç¶å¾åç±å§å¡æå¯©æ¥ãæ­¤å¤ï¼å»ºç¯å¤éå½¢å·²å¨ç©ºéä¸å°é½ï¼ä»¥ä¾¿èå½±åç²¾ç¢ºéçï¼ä»¥è¨ç·´æè½æ´é«çæ©å¨å­¸ç¿æ¨¡åãCRASAR-U-DROIDs çä¼¼æ¯æ¨ç±¤æå¤ç sUAS æ­£å°å½±åè³æéã</paragraph>

##### **Spiking Neural Networks in Vertical Federated Learning: Performance Trade-offs**
2407.17672v1 by Maryam Abbasihafshejani, Anindya Maiti, Murtuza Jadliwala

Federated machine learning enables model training across multiple clients
while maintaining data privacy. Vertical Federated Learning (VFL) specifically
deals with instances where the clients have different feature sets of the same
samples. As federated learning models aim to improve efficiency and
adaptability, innovative neural network architectures like Spiking Neural
Networks (SNNs) are being leveraged to enable fast and accurate processing at
the edge. SNNs, known for their efficiency over Artificial Neural Networks
(ANNs), have not been analyzed for their applicability in VFL, thus far. In
this paper, we investigate the benefits and trade-offs of using SNN models in a
vertical federated learning setting. We implement two different federated
learning architectures -- with model splitting and without model splitting --
that have different privacy and performance implications. We evaluate the setup
using CIFAR-10 and CIFAR-100 benchmark datasets along with SNN implementations
of VGG9 and ResNET classification models. Comparative evaluations demonstrate
that the accuracy of SNN models is comparable to that of traditional ANNs for
VFL applications, albeit significantly more energy efficient.

æè¦ï¼è¯é¦æ©å¨å­¸ç¿è®æ¨¡åè¨ç·´è·¨è¶å¤åå®¢æ¶ç«¯ï¼åæç¶­æè³æé±ç§ãåç´è¯é¦å­¸ç¿ (VFL) ç¹å¥èçå®¢æ¶ç«¯ææç¸åæ¨£æ¬ä¸åç¹å¾µéçæ¡ä¾ãç±æ¼è¯é¦å­¸ç¿æ¨¡åæ¨å¨æåæçåé©ææ§ï¼åµæ°çç¥ç¶ç¶²è·¯æ¶æ§ï¼å¦èè¡ç¥ç¶ç¶²è·¯ (SNNs)ï¼è¢«ç¨æ¼å¨éç·£è£ç½®ä¸å¯¦ç¾å¿«éä¸ç²¾ç¢ºçèçãä»¥å¶é«æ¼äººå·¥ç¥ç¶ç¶²è·¯ (ANNs) çæçèç¨±ç SNNsï¼ç®åå°æªéå°å¶å¨ VFL ä¸­çé©ç¨æ§é²è¡åæãå¨æ¬æä¸­ï¼æåæ¢è¨å¨åç´è¯é¦å­¸ç¿è¨­å®ä¸­ä½¿ç¨ SNN æ¨¡åçåªé»åæ¬è¡¡ãæåå¯¦ä½äºå©ç¨®ä¸åçè¯é¦å­¸ç¿æ¶æ§ï¼ä¸ç¨®ææ¨¡ååå²ï¼ä¸ç¨®æ²ææ¨¡ååå²ï¼ï¼å®åæä¸åçé±ç§åæè½å½±é¿ãæåä½¿ç¨ CIFAR-10 å CIFAR-100 åºæºè³æéä»¥å VGG9 å ResNET åé¡æ¨¡åç SNN å¯¦ä½ä¾è©ä¼°è¨­å®ãæ¯è¼è©ä¼°è­æï¼SNN æ¨¡åçæºç¢ºåº¦èå³çµ± ANNs å¨ VFL æç¨ä¸­ç¸ç¶ï¼ä½è½æºæçé¡¯èæåã

##### **SMA-Hyper: Spatiotemporal Multi-View Fusion Hypergraph Learning for Traffic Accident Prediction**
2407.17642v1 by Xiaowei Gao, James Haworth, Ilya Ilyankou, Xianghui Zhang, Tao Cheng, Stephen Law, Huanfa Chen

Predicting traffic accidents is the key to sustainable city management, which
requires effective address of the dynamic and complex spatiotemporal
characteristics of cities. Current data-driven models often struggle with data
sparsity and typically overlook the integration of diverse urban data sources
and the high-order dependencies within them. Additionally, they frequently rely
on predefined topologies or weights, limiting their adaptability in
spatiotemporal predictions. To address these issues, we introduce the
Spatiotemporal Multiview Adaptive HyperGraph Learning (SMA-Hyper) model, a
dynamic deep learning framework designed for traffic accident prediction.
Building on previous research, this innovative model incorporates dual adaptive
spatiotemporal graph learning mechanisms that enable high-order cross-regional
learning through hypergraphs and dynamic adaptation to evolving urban data. It
also utilises contrastive learning to enhance global and local data
representations in sparse datasets and employs an advance attention mechanism
to fuse multiple views of accident data and urban functional features, thereby
enriching the contextual understanding of risk factors. Extensive testing on
the London traffic accident dataset demonstrates that the SMA-Hyper model
significantly outperforms baseline models across various temporal horizons and
multistep outputs, affirming the effectiveness of its multiview fusion and
adaptive learning strategies. The interpretability of the results further
underscores its potential to improve urban traffic management and safety by
leveraging complex spatiotemporal urban data, offering a scalable framework
adaptable to diverse urban environments.

æè¦ï¼é æ¸¬äº¤éäºææ¯æ°¸çºåå¸ç®¡ççééµï¼ééè¦ææèçåå¸åæä¸è¤éçæç©ºç¹å¾µãç®åçè³æé©åæ¨¡åç¶å¸¸å¨è³æç¨çæ§ä¸ææï¼ä¸éå¸¸å¿½ç¥æ´åå¤æ¨£çé½å¸è³æä¾æºåå®åä¹éçé«éä¾è³´æ§ãæ­¤å¤ï¼å®åç¶å¸¸ä¾è³´é åå®ç¾©çææ²ææ¬éï¼éå¶äºå®åå¨æç©ºé æ¸¬ä¸­çé©ææ§ãçºäºè§£æ±ºéäºåé¡ï¼æåå¼å¥äºæç©ºå¤è¦è§èªé©æè¶åå­¸ç¿ (SMA-Hyper) æ¨¡åï¼éæ¯ä¸ååææ·±åº¦å­¸ç¿æ¶æ§ï¼è¨­è¨ç¨æ¼äº¤éäºæé æ¸¬ãå»ºæ§æ¼ååçç ç©¶ï¼éååµæ°æ¨¡åçµåäºééèªé©ææç©ºåå­¸ç¿æ©å¶ï¼ééè¶ååç¨é«éè·¨ååå­¸ç¿ï¼ä»¥ååæé©ææ¼åçé½å¸è³æãå®ä¹å©ç¨å°æ¯å­¸ç¿ä¾å¢å¼·ç¨çè³æéä¸­çå¨å±åå±é¨è³æè¡¨ç¤ºï¼ä¸¦æ¡ç¨åé²çæ³¨ææ©å¶ä¾èåäºæè³æåé½å¸åè½ç¹å¾µçå¤éè¦è§ï¼å¾èè±å¯é¢¨éªå å­çèçµ¡çè§£ãå¨å«æ¦äº¤éäºæè³æéä¸çå»£æ³æ¸¬è©¦è­æï¼SMA-Hyper æ¨¡åå¨åç¨®æéç¯ååå¤æ­¥é©è¼¸åºä¸é½é¡¯èåªæ¼åºæºæ¨¡åï¼è¯å®äºå¶å¤è¦è§èååèªé©æå­¸ç¿ç­ç¥çæææ§ãçµæçå¯è§£éæ§é²ä¸æ­¥å¼·èª¿äºå®ééå©ç¨è¤éçæç©ºé½å¸è³æä¾æ¹åé½å¸äº¤éç®¡çåå®å¨çæ½åï¼æä¾ä¸åå¯é©æå¤æ¨£é½å¸ç°å¢çå¯æ´åæ¶æ§ã

##### **Time Matters: Examine Temporal Effects on Biomedical Language Models**
2407.17638v1 by Weisi Liu, Zhe He, Xiaolei Huang

Time roots in applying language models for biomedical applications: models
are trained on historical data and will be deployed for new or future data,
which may vary from training data. While increasing biomedical tasks have
employed state-of-the-art language models, there are very few studies have
examined temporal effects on biomedical models when data usually shifts across
development and deployment. This study fills the gap by statistically probing
relations between language model performance and data shifts across three
biomedical tasks. We deploy diverse metrics to evaluate model performance,
distance methods to measure data drifts, and statistical methods to quantify
temporal effects on biomedical language models. Our study shows that time
matters for deploying biomedical language models, while the degree of
performance degradation varies by biomedical tasks and statistical
quantification approaches. We believe this study can establish a solid
benchmark to evaluate and assess temporal effects on deploying biomedical
language models.

æè¦ï¼æéæ¤æ ¹æ¼å°èªè¨æ¨¡åæç¨æ¼çç©é«å­¸æç¨ï¼æ¨¡å
ç¶éæ­·å²æ¸æè¨ç·´ï¼å°é¨ç½²æ¼æ°æ¸æææªä¾æ¸æï¼
éå¯è½æèè¨ç·´æ¸æææä¸åãéç¶è¶ä¾è¶å¤ççç©é«å­¸ä»»åå·²ç¶
æ¡ç¨äºæåé²çèªè¨æ¨¡åï¼ä½ç¶æ¸æéå¸¸å¨éç¼åé¨ç½²ä¹éè½ç§»æï¼å¾å°æç ç©¶
æª¢æ¥äºå°çç©é«å­¸æ¨¡åçæåºææãæ¬ç ç©¶ééçµ±è¨æ¢æ¥
èªè¨æ¨¡åæ§è½èä¸åçç©é«å­¸ä»»åä¹éçæ¸æè½ç§»éä¿ä¾å¡«è£éä¸ç©ºç½ãæåé¨ç½²å¤ç¨®ææ¨ä¾è©ä¼°æ¨¡åæ§è½ï¼
è·é¢æ¹æ³ä¾æ¸¬éæ¸ææ¼ç§»ï¼ä»¥åçµ±è¨æ¹æ³ä¾éå
å°çç©é«å­¸èªè¨æ¨¡åçæåºææãæåçç ç©¶è¡¨æï¼æé
å°æ¼é¨ç½²çç©é«å­¸èªè¨æ¨¡åå¾éè¦ï¼èæ§è½ä¸éçç¨åº¦å çç©é«å­¸ä»»ååçµ±è¨
éåæ¹æ³èç°ãæåç¸ä¿¡éé ç ç©¶å¯ä»¥å»ºç«ä¸åç©©åºç
åºæºä¾è©ä¼°åè©ä¼°å°é¨ç½²çç©é«å­¸çæåºææ
èªè¨æ¨¡åã

##### **IgnitionInnovators at "Discharge Me!": Chain-of-Thought Instruction Finetuning Large Language Models for Discharge Summaries**
2407.17636v1 by An Quang Tang, Xiuzhen Zhang, Minh Ngoc Dinh

This paper presents our proposed approach to the Discharge Me! shared task,
collocated with the 23th Workshop on Biomedical Natural Language Processing
(BioNLP). In this work, we develop an LLM-based framework for solving the
Discharge Summary Documentation (DSD) task, i.e., generating the two critical
target sections `Brief Hospital Course' and `Discharge Instructions' in the
discharge summary. By streamlining the recent instruction-finetuning process on
LLMs, we explore several prompting strategies for optimally adapting LLMs to
specific generation task of DSD. Experimental results show that providing a
clear output structure, complimented by a set of comprehensive
Chain-of-Thoughts (CoT) questions, effectively improves the model's reasoning
capability, and thereby, enhancing the structural correctness and faithfulness
of clinical information in the generated text. Source code is available at:
https://github.com/antangrocket1312/Discharge_LLM

æè¦ï¼æ¬æä»ç´¹æåæåºçãDischarge Meï¼ãå±äº«ä»»åæ¹æ³ï¼èç¬¬ 23 å±çç©é«å­¸èªç¶èªè¨èçå·¥ä½å (BioNLP) ä¸¦åãå¨éé å·¥ä½ä¸­ï¼æåéç¼äºä¸ååºæ¼ LLM çæ¶æ§ï¼ç¨æ¼è§£æ±ºåºé¢æè¦æä»¶ (DSD) ä»»åï¼ä¹å°±æ¯ç¢çåºé¢æè¦ä¸­å©åéè¦çç®æ¨é¨åãç°¡è¦ä½é¢çç¨ãåãåºé¢æç¤ºããééç°¡å LLM ä¸æè¿çæä»¤å¾®èª¿æµç¨ï¼æåæ¢è¨äºå¤ç¨®æç¤ºç­ç¥ï¼ä»¥æä½³åèª¿æ´ LLM ä¾å·è¡ DSD çç¹å®çæä»»åãå¯¦é©çµæé¡¯ç¤ºï¼æä¾æç¢ºçè¼¸åºçµæ§ï¼ä¸¦æ­éä¸çµå¨é¢çæèé (CoT) åé¡ï¼å¯ä»¥ææå°æåæ¨¡åçæ¨çè½åï¼é²èå¢å¼·æçææå­ä¸­è¨åºè³è¨ççµæ§æ­£ç¢ºæ§åçå¯¦æ§ãåå§ç¢¼å¯å¨ä»¥ä¸ç¶²ååå¾ï¼https://github.com/antangrocket1312/Discharge_LLM

##### **Traditional Methods Outperform Generative LLMs at Forecasting Credit Ratings**
2407.17624v1 by Felix Drinkall, Janet B. Pierrehumbert, Stefan Zohren

Large Language Models (LLMs) have been shown to perform well for many
downstream tasks. Transfer learning can enable LLMs to acquire skills that were
not targeted during pre-training. In financial contexts, LLMs can sometimes
beat well-established benchmarks. This paper investigates how well LLMs perform
in the task of forecasting corporate credit ratings. We show that while LLMs
are very good at encoding textual information, traditional methods are still
very competitive when it comes to encoding numeric and multimodal data. For our
task, current LLMs perform worse than a more traditional XGBoost architecture
that combines fundamental and macroeconomic data with high-density text-based
embedding features.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²è¢«è­æå¨è¨±å¤ä¸æ¸¸ä»»åä¸­è¡¨ç¾è¯å¥½ãè½ç§»å­¸ç¿å¯ä»¥è® LLM ç¿å¾å¨é è¨ç·´æéæªè¨­å®çºç®æ¨çæè½ãå¨éèèæ¯ä¸ï¼LLM ææå¯ä»¥è¶è¶æ¢å®çåºæºãæ¬ææ¢è¨ LLM å¨é æ¸¬å¬å¸ä¿¡ç¨è©ç´ä»»åä¸­çè¡¨ç¾ãæåå±ç¤ºäºåç®¡ LLM å¨ç·¨ç¢¼æå­è³è¨æ¹é¢éå¸¸åºè²ï¼ä½å³çµ±æ¹æ³å¨ç·¨ç¢¼æ¸å­åå¤æ¨¡æè³ææ¹é¢ä»éå¸¸æç«¶ç­åãå°æ¼æåçä»»åï¼ç¶å LLM çè¡¨ç¾æ¯çµååºæ¬åå·¨è§ç¶æ¿è³æèé«å¯åº¦åºæ¼æå­çåµå¥ç¹å¾µçæ´å³çµ±ç XGBoost æ¶æ§å·®ã

##### **CoMoTo: Unpaired Cross-Modal Lesion Distillation Improves Breast Lesion Detection in Tomosynthesis**
2407.17620v1 by Muhammad Alberb, Marawan Elbatel, Aya Elgebaly, Ricardo Montoya-del-Angel, Xiaomeng Li, Robert MartÃ­

Digital Breast Tomosynthesis (DBT) is an advanced breast imaging modality
that offers superior lesion detection accuracy compared to conventional
mammography, albeit at the trade-off of longer reading time. Accelerating
lesion detection from DBT using deep learning is hindered by limited data
availability and huge annotation costs. A possible solution to this issue could
be to leverage the information provided by a more widely available modality,
such as mammography, to enhance DBT lesion detection. In this paper, we present
a novel framework, CoMoTo, for improving lesion detection in DBT. Our framework
leverages unpaired mammography data to enhance the training of a DBT model,
improving practicality by eliminating the need for mammography during
inference. Specifically, we propose two novel components, Lesion-specific
Knowledge Distillation (LsKD) and Intra-modal Point Alignment (ImPA). LsKD
selectively distills lesion features from a mammography teacher model to a DBT
student model, disregarding background features. ImPA further enriches LsKD by
ensuring the alignment of lesion features within the teacher before distilling
knowledge to the student. Our comprehensive evaluation shows that CoMoTo is
superior to traditional pretraining and image-level KD, improving performance
by 7% Mean Sensitivity under low-data setting. Our code is available at
https://github.com/Muhammad-Al-Barbary/CoMoTo .

æè¦ï¼æ¸ä½ä¹³æ¿æ·å±¤åæ (DBT) æ¯ä¸ç¨®é²éä¹³æ¿å½±åæ¨¡å¼ï¼
èå³çµ±ä¹³æ¿æå½±ç¸æ¯ï¼å®æä¾äºåªè¶ççç¶åµæ¸¬æºç¢ºåº¦ï¼
åç®¡éè¦è¼é·çå¤è®æéãå é
ä½¿ç¨æ·±åº¦å­¸ç¿å¾ DBT ä¸­åµæ¸¬çç¶åå°è³æ
å¯ç¨æ§æéåé¾å¤§æ¨è¨»ææ¬çé»ç¤ãè§£æ±ºæ­¤åé¡çä¸ç¨®å¯è½æ¹æ³æ¯
å©ç¨æ´å»£æ³å¯ç¨çæ¨¡å¼ï¼ä¾å¦ä¹³æ¿æå½±ï¼ææä¾çè³è¨ï¼
ä¾å¢å¼· DBT çç¶åµæ¸¬ãå¨æ¬æä¸­ï¼æåæåº
ä¸åæ°ç©çæ¶æ§ CoMoToï¼ç¨æ¼æ¹å DBT ä¸­ççç¶åµæ¸¬ãæåçæ¶æ§
å©ç¨æªéå°çä¹³æ¿æå½±è³æä¾å¢å¼· DBT æ¨¡åçè¨ç·´ï¼
ééæ¶é¤æ¨è«æéå°ä¹³æ¿æå½±çéæ±ä¾æ¹åå¯¦ç¨æ§ãå·é«ä¾èªªï¼æåæåºå©åæ°ç©ççµæé¨åï¼çç¶ç¹å®ç¥è­èå (LsKD) åæ¨¡å§é»å°é½ (ImPA)ãLsKD
æé¸ææ§å°å¾ä¹³æ¿æå½±æå¸«æ¨¡åèååºçç¶ç¹å¾µå° DBT
å­¸çæ¨¡åï¼å¿½ç¥èæ¯ç¹å¾µãImPA é²ä¸æ­¥éé
ç¢ºä¿æå¸«å§ççç¶ç¹å¾µå¨èååº
ç¥è­å°å­¸çä¹åå°é½ï¼ä¾è±å¯ LsKDãæåçå¨é¢è©ä¼°é¡¯ç¤ºï¼CoMoTo åªæ¼å³çµ±çé è¨ç·´åå½±åå±¤ç´ KDï¼å¨ä½è³æè¨­å®ä¸å°æè½æå 7% çå¹³åéæåº¦ãæåçç¨å¼ç¢¼å¯å¨ https://github.com/Muhammad-Al-Barbary/CoMoTo åå¾ã

##### **Coupling Speech Encoders with Downstream Text Models**
2407.17605v1 by Ciprian Chelba, Johan Schalkwyk

We present a modular approach to building cascade speech translation (AST)
models that guarantees that the resulting model performs no worse than the
1-best cascade baseline while preserving state-of-the-art speech recognition
(ASR) and text translation (MT) performance for a given task. Our novel
contribution is the use of an ``exporter'' layer that is trained under L2-loss
to ensure a strong match between ASR embeddings and the MT token embeddings for
the 1-best sequence. The ``exporter'' output embeddings are fed directly to the
MT model in lieu of 1-best token embeddings, thus guaranteeing that the
resulting model performs no worse than the 1-best cascade baseline, while
allowing back-propagation gradient to flow from the MT model into the ASR
components. The matched-embeddings cascade architecture provide a significant
improvement over its 1-best counterpart in scenarios where incremental training
of the MT model is not an option and yet we seek to improve quality by
leveraging (speech, transcription, translated transcription) data provided with
the AST task. The gain disappears when the MT model is incrementally trained on
the parallel text data available with the AST task. The approach holds promise
for other scenarios that seek to couple ASR encoders and immutable text models,
such at large language models (LLM).

æè¦ï¼æåæåºäºä¸åå»ºæ§ä¸²è¯èªé³ç¿»è­¯ (AST) æ¨¡åçæ¨¡çµåæ¹æ³ï¼å¯ç¢ºä¿ç¢ççæ¨¡åå·è¡æè½ä¸éæ¼ 1-best ä¸²è¯åºæºï¼åæä¿çæåé²çèªé³è¾¨è­ (ASR) åæå­ç¿»è­¯ (MT) æè½ï¼ä»¥å·è¡ç¹å®ä»»åãæåçåµæ°è²¢ç»æ¯ä½¿ç¨ä¸åå¨ L2 æå¤±ä¸è¨ç·´çãå¯åºå±¤ãï¼ä»¥ç¢ºä¿ ASR åµå¥è MT ä»£å¹£åµå¥ä¹éæå¼·ççå¹éï¼ä»¥ä¾ 1-best é åºä½¿ç¨ãå°ãå¯åºå±¤ãè¼¸åºåµå¥ç´æ¥æä¾çµ¦ MT æ¨¡åï¼ä»¥åä»£ 1-best ä»£å¹£åµå¥ï¼å¾èç¢ºä¿ç¢ççæ¨¡åå·è¡æè½ä¸éæ¼ 1-best ä¸²è¯åºæºï¼åæåè¨±ååå³æ­æ¢¯åº¦å¾ MT æ¨¡åæµå¥ ASR çµä»¶ãå¹éåµå¥ä¸²è¯æ¶æ§å¨å¶ 1-best å°ææ¶æ§ä¸­æä¾é¡¯èçæ¹é²ï¼å¨ç¡æ³é¸æ MT æ¨¡åå¢éè¨ç·´çææ³ä¸ï¼æåä»å°æ±ééå©ç¨ AST ä»»åæä¾çï¼èªé³ãè½éãç¿»è­¯è½éï¼è³æä¾æååè³ªãç¶ MT æ¨¡åæ ¹æ AST ä»»åæä¾çå¹³è¡æå­è³æé²è¡å¢éè¨ç·´æï¼å¢çå°±ææ¶å¤±ãéç¨®æ¹æ³å°æ¼å°æ±å° ASR ç·¨ç¢¼å¨åä¸å¯è®æå­æ¨¡åï¼ä¾å¦å¤§åèªè¨æ¨¡å (LLM)ï¼çµåçå¶ä»å ´æ¯å¾æåæ¯ã

##### **I Could've Asked That: Reformulating Unanswerable Questions**
2407.17469v1 by Wenting Zhao, Ge Gao, Claire Cardie, Alexander M. Rush

When seeking information from unfamiliar documents, users frequently pose
questions that cannot be answered by the documents. While existing large
language models (LLMs) identify these unanswerable questions, they do not
assist users in reformulating their questions, thereby reducing their overall
utility. We curate CouldAsk, an evaluation benchmark composed of existing and
new datasets for document-grounded question answering, specifically designed to
study reformulating unanswerable questions. We evaluate state-of-the-art
open-source and proprietary LLMs on CouldAsk. The results demonstrate the
limited capabilities of these models in reformulating questions. Specifically,
GPT-4 and Llama2-7B successfully reformulate questions only 26% and 12% of the
time, respectively. Error analysis shows that 62% of the unsuccessful
reformulations stem from the models merely rephrasing the questions or even
generating identical questions. We publicly release the benchmark and the code
to reproduce the experiments.

æè¦ï¼å¨å¾ä¸çæçææªä¸­å°æ±è³è¨æï¼ä½¿ç¨èç¶å¸¸ææåºææªç¡æ³åç­çåé¡ãéç¶ç¾æçå¤§åèªè¨æ¨¡å (LLM) å¯ä»¥è­å¥éäºç¡æ³åç­çåé¡ï¼ä½å®åä¸¦æªåå©ä½¿ç¨èéæ°è¡¨è¿°åé¡ï¼å æ­¤éä½äºå®åçæ´é«æç¨ãæåæ´çäº CouldAskï¼éæ¯ä¸åè©ä¼°åºæºï¼ç±ç¾æåæ°çè³æéçµæï¼ç¨æ¼åºæ¼ææªçåç­ï¼ç¹å¥è¨­è¨ç¨æ¼ç ç©¶éæ°è¡¨è¿°ç¡æ³åç­çåé¡ãæåå¨ CouldAsk ä¸è©ä¼°äºæåé²çéæºåå°æ LLMãçµæè­æäºéäºæ¨¡åå¨éæ°è¡¨è¿°åé¡æ¹é¢çè½åæéãå·é«ä¾èªªï¼GPT-4 å Llama2-7B åå¥åå¨ 26% å 12% çæéå§æåéæ°è¡¨è¿°åé¡ãé¯èª¤åæé¡¯ç¤ºï¼62% çä¸æåéæ°è¡¨è¿°æºæ¼æ¨¡åååéæ°è¡¨è¿°åé¡ï¼çè³ç¢çç¸åçåé¡ãæåå¬éç¼å¸åºæºåä»£ç¢¼ä»¥éç¾å¯¦é©ã

##### **WildHallucinations: Evaluating Long-form Factuality in LLMs with Real-World Entity Queries**
2407.17468v1 by Wenting Zhao, Tanya Goyal, Yu Ying Chiu, Liwei Jiang, Benjamin Newman, Abhilasha Ravichander, Khyathi Chandu, Ronan Le Bras, Claire Cardie, Yuntian Deng, Yejin Choi

While hallucinations of large language models (LLMs) prevail as a major
challenge, existing evaluation benchmarks on factuality do not cover the
diverse domains of knowledge that the real-world users of LLMs seek information
about. To bridge this gap, we introduce WildHallucinations, a benchmark that
evaluates factuality. It does so by prompting LLMs to generate information
about entities mined from user-chatbot conversations in the wild. These
generations are then automatically fact-checked against a systematically
curated knowledge source collected from web search. Notably, half of these
real-world entities do not have associated Wikipedia pages. We evaluate 118,785
generations from 15 LLMs on 7,919 entities. We find that LLMs consistently
hallucinate more on entities without Wikipedia pages and exhibit varying
hallucination rates across different domains. Finally, given the same base
models, adding a retrieval component only slightly reduces hallucinations but
does not eliminate hallucinations.

æè¦ï¼åç®¡å¤§åèªè¨æ¨¡å (LLM) çå¹»è¦ºçè¡ï¼æçºä¸é éå¤§ææ°ï¼ä½ç¾æçéæ¼äºå¯¦æ§çè©ä¼°åºæºä¸¦æªæ¶µè LLM ççå¯¦ä½¿ç¨èå°æ±è³è¨çåç¨®ç¥è­é åãçºäºå½è£éåå·®è·ï¼æåå¼å¥äº WildHallucinationsï¼éæ¯ä¸åè©ä¼°äºå¯¦æ§çåºæºãå®ééæç¤º LLM ç¢çå¾éå¤ä½¿ç¨èèå¤©æ©å¨äººå°è©±ä¸­æåçå¯¦é«è³è¨ä¾åå°éä¸é»ãç¶å¾æ ¹æå¾ç¶²è·¯æå°æ¶éçç³»çµ±åç­å±ç¥è­ä¾æºï¼èªåå°éäºçæé²è¡äºå¯¦æ¥æ ¸ãå¼å¾æ³¨æçæ¯ï¼éäºçå¯¦ä¸çå¯¦é«ä¸­æä¸åæ²æéè¯çç¶­åºç¾ç§é é¢ãæåè©ä¼°äº 15 å LLM å¨ 7,919 åå¯¦é«ä¸ç¢çç 118,785 åçæãæåç¼ç¾ LLM æçºå°æ²æç¶­åºç¾ç§é é¢çå¯¦é«ç¢çæ´å¤å¹»è¦ºï¼ä¸¦å¨ä¸åé åè¡¨ç¾åºä¸åçå¹»è¦ºçãæå¾ï¼å¨çµ¦å®ç¸åçåºç¤æ¨¡åçææ³ä¸ï¼å å¥æª¢ç´¢åä»¶åè½ç¨å¾®æ¸å°å¹»è¦ºï¼ä½ç¡æ³æ¶é¤å¹»è¦ºã

##### **CMR Scaling Law: Predicting Critical Mixture Ratios for Continual Pre-training of Language Models**
2407.17467v1 by Jiawei Gu, Zacc Yang, Chuanghao Ding, Rui Zhao, Fei Tan

Large Language Models (LLMs) excel in diverse tasks but often underperform in
specialized fields due to limited domain-specific or proprietary corpus.
Continual pre-training (CPT) enhances LLM capabilities by imbuing new
domain-specific or proprietary knowledge while replaying general corpus to
prevent catastrophic forgetting. The data mixture ratio of general corpus and
domain-specific corpus, however, has been chosen heuristically, leading to
sub-optimal training efficiency in practice. In this context, we attempt to
re-visit the scaling behavior of LLMs under the hood of CPT, and discover a
power-law relationship between loss, mixture ratio, and training tokens scale.
We formalize the trade-off between general and domain-specific capabilities,
leading to a well-defined Critical Mixture Ratio (CMR) of general and domain
data. By striking the balance, CMR maintains the model's general ability and
achieves the desired domain transfer, ensuring the highest utilization of
available resources. Therefore, if we value the balance between efficiency and
effectiveness, CMR can be consider as the optimal mixture ratio.Through
extensive experiments, we ascertain the predictability of CMR, and propose CMR
scaling law and have substantiated its generalization. These findings offer
practical guidelines for optimizing LLM training in specialized domains,
ensuring both general and domain-specific performance while efficiently
managing training resources.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨åç¨®ä»»åä¸­è¡¨ç¾åºè²ï¼ä½ç±æ¼ç¹å®é åæå°æèªæåº«æéï¼å®åå¨å°æ¥­é åçè¡¨ç¾å¾å¾ä¸ä½³ã
æçºé è¨ç·´ (CPT) å¯ééå°å¥æ°çç¹å®é åæå°æç¥è­ï¼åæéæ­ä¸è¬èªæåº«ä¾é²æ­¢ç½é£æ§éºå¿ï¼é²èå¢å¼· LLM çåè½ãç¶èï¼ä¸è¬èªæåº«åç¹å®é åèªæåº«çè³ææ··åæ¯ä¾æ¯æ ¹æç¶é©æ³åé¸æçï¼å°è´å¯¦éè¨ç·´æçä¸ä½³ãå¨æ­¤èæ¯ä¸ï¼æååè©¦éæ°æ¢è¨ LLM å¨ CPT å¼æèä¸çæ´åè¡çºï¼ä¸¦ç¼ç¾æå¤±ãæ··åæ¯ä¾åè¨ç·´ä»£å¹£è¦æ¨¡ä¹éå­å¨åªå¾éä¿ãæåå°ä¸è¬åè½åç¹å®é ååè½ä¹éçæ¬è¡¡å½¢å¼åï¼é²èå®ç¾©åºä¸è¬è³æåé åè³æçæç¢ºè¨çæ··åæ¯ä¾ (CMR)ãCMR å¨åå¾å¹³è¡¡å¾ï¼å¯ç¶­ææ¨¡åçä¸è¬è½åä¸¦éææéçé åè½ç§»ï¼ç¢ºä¿å°å¯ç¨è³æºçæé«å©ç¨çãå æ­¤ï¼å¦ææåéè¦æçåæè½ä¹éçå¹³è¡¡ï¼CMR å¯ä»¥è¦çºæä½³æ··åæ¯ä¾ãééå»£æ³çå¯¦é©ï¼æåç¢ºèªäº CMR çå¯é æ¸¬æ§ï¼ä¸¦æåº CMR æ´åå®å¾ï¼ä¸¦å·²è­å¯¦å¶æ¦æ¬æ§ãéäºç¼ç¾æä¾äºå¯¦ç¨çæºåï¼ç¨æ¼æä½³åç¹å®é åç LLM è¨ç·´ï¼åæç¢ºä¿ä¸è¬åç¹å®é åçæè½ï¼ä¸¦ææç®¡çè¨ç·´è³æºã

##### **Why Machines Can't Be Moral: Turing's Halting Problem and the Moral Limits of Artificial Intelligence**
2407.16890v1 by Massimo Passamonti

In this essay, I argue that explicit ethical machines, whose moral principles
are inferred through a bottom-up approach, are unable to replicate human-like
moral reasoning and cannot be considered moral agents. By utilizing Alan
Turing's theory of computation, I demonstrate that moral reasoning is
computationally intractable by these machines due to the halting problem. I
address the frontiers of machine ethics by formalizing moral problems into
'algorithmic moral questions' and by exploring moral psychology's dual-process
model. While the nature of Turing Machines theoretically allows artificial
agents to engage in recursive moral reasoning, critical limitations are
introduced by the halting problem, which states that it is impossible to
predict with certainty whether a computational process will halt. A thought
experiment involving a military drone illustrates this issue, showing that an
artificial agent might fail to decide between actions due to the halting
problem, which limits the agent's ability to make decisions in all instances,
undermining its moral agency.

æè¦ï¼å¨æ¬æä¸­ï¼æä¸»å¼µééèªä¸èä¸æ¹æ³æ¨è«åºéå¾·ååçæç¢ºéå¾·æ©å¨ï¼ç¡æ³è¤è£½é¡äººçéå¾·æ¨çï¼ä¹ä¸è½è¢«è¦çºéå¾·ä»£çäººãééå©ç¨è¾å«Â·åéçè¨ç®çè«ï¼æè­æäºç±æ¼åæ©åé¡ï¼éäºæ©å¨å¨è¨ç®ä¸ç¡æ³é²è¡éå¾·æ¨çãæééå°éå¾·åé¡å½¢å¼åçºãæ¼ç®æ³éå¾·åé¡ãä»¥åæ¢ç´¢éå¾·å¿çå­¸çéééç¨æ¨¡åï¼ä¾æ¢è¨æ©å¨å«ççéçãéç¶åéæ©çæ¬è³ªå¨çè«ä¸åè¨±äººå·¥ä»£çåèéè¿´éå¾·æ¨çï¼ä½åæ©åé¡å¼å¥äºééµéå¶ï¼è©²åé¡æåºä¸å¯è½ç¢ºå®é æ¸¬è¨ç®éç¨æ¯å¦æåæ­¢ãä¸åæ¶åè»äºç¡äººæ©çææ³å¯¦é©èªªæäºéååé¡ï¼è¡¨æäººå·¥ä»£çå¯è½æå çºåæ©åé¡èç¡æ³å¨è¡åä¹éååºæ±ºå®ï¼ééå¶äºä»£çäººå¨ææææ³ä¸ååºæ±ºå®çè½åï¼å¾èç ´å£äºå¶éå¾·ä»£çã

##### **Exploring Domain Robust Lightweight Reward Models based on Router Mechanism**
2407.17546v1 by Hyuk Namgoong, Jeesu Jung, Sangkeun Jung, Yoonhyung Roh

Recent advancements in large language models have heavily relied on the large
reward model from reinforcement learning from human feedback for fine-tuning.
However, the use of a single reward model across various domains may not always
be optimal, often requiring retraining from scratch when new domain data is
introduced. To address these challenges, we explore the utilization of small
language models operating in a domain-specific manner based on router
mechanisms. Our three approaches are: 1) utilize mixture of experts to form a
single reward model by modularizing an internal router and experts, 2)
employing external router to select the appropriate reward model from multiple
domain-specific models, and 3) the framework reduces parameter size by loading
reward models and router adapters onto a single small language model using
adapters. Experimental validation underscores the effectiveness of our
approach, demonstrating performance comparable to baseline methods while also
reducing the total parameter size.

æè¦ï¼è¿æå¤§åèªè¨æ¨¡åçé²å±é«åº¦ä»°è³´å¼·åå­¸ç¿ä¸­ä¾èªäººé¡åé¥çå¤§åçåµæ¨¡åé²è¡å¾®èª¿ãç¶èï¼å¨ä¸åé åä¸­ä½¿ç¨å®ä¸çåµæ¨¡åå¯è½ä¸¦ä¸ç¸½æ¯æä½³çï¼å¨å¼å¥æ°çé åè³ææï¼éå¸¸éè¦å¾é ­éå§éæ°è¨ç·´ãçºäºæå°éäºææ°ï¼æåæ¢ç´¢äºåºæ¼è·¯ç±æ©å¶çå¨ç¹å®é åéä½çå°åèªè¨æ¨¡åçå©ç¨ãæåçä¸ç¨®æ¹æ³æ¯ï¼1) å©ç¨å°å®¶æ··åé«ééæ¨¡çµåå§é¨è·¯ç±å¨åå°å®¶ä¾å½¢æå®ä¸çåµæ¨¡åï¼2) ä½¿ç¨å¤é¨è·¯ç±å¨å¾å¤åç¹å®é åæ¨¡åä¸­é¸æé©ç¶ççåµæ¨¡åï¼ä»¥å 3) è©²æ¡æ¶ééä½¿ç¨é©éå¨å°çåµæ¨¡ååè·¯ç±å¨é©éå¨è¼å¥å°å®ä¸å°åèªè¨æ¨¡åä¸ä¾æ¸å°åæ¸å¤§å°ãå¯¦é©é©è­å¼·èª¿äºæåæ¹æ³çæææ§ï¼å±ç¤ºäºèåºæºæ¹æ³ç¸ç¶çæè½ï¼åæä¹æ¸å°äºç¸½åæ¸å¤§å°ã

##### **Fluent Student-Teacher Redteaming**
2407.17447v1 by T. Ben Thompson, Michael Sklar

Many publicly available language models have been safety tuned to reduce the
likelihood of toxic or liability-inducing text. Users or security analysts
attempt to jailbreak or redteam these models with adversarial prompts which
cause compliance with requests. One attack method is to apply discrete
optimization techniques to the prompt. However, the resulting attack strings
are often gibberish text, easily filtered by defenders due to high measured
perplexity, and may fail for unseen tasks and/or well-tuned models. In this
work, we improve existing algorithms (primarily GCG and BEAST) to develop
powerful and fluent attacks on safety-tuned models like Llama-2 and Phi-3. Our
technique centers around a new distillation-based approach that encourages the
victim model to emulate a toxified finetune, either in terms of output
probabilities or internal activations. To encourage human-fluent attacks, we
add a multi-model perplexity penalty and a repetition penalty to the objective.
We also enhance optimizer strength by allowing token insertions, token swaps,
and token deletions and by using longer attack sequences. The resulting process
is able to reliably jailbreak the most difficult target models with prompts
that appear similar to human-written prompts. On Advbench we achieve attack
success rates $>93$% for Llama-2-7B, Llama-3-8B, and Vicuna-7B, while
maintaining model-measured perplexity $<33$; we achieve $95$% attack success
for Phi-3, though with higher perplexity. We also find a universally-optimized
single fluent prompt that induces $>88$% compliance on previously unseen tasks
across Llama-2-7B, Phi-3-mini and Vicuna-7B and transfers to other black-box
models.

æè¦ï¼è¨±å¤å¬éå¯ç¨çèªè¨æ¨¡åé½ç¶éå®å¨æ§èª¿æ´ï¼ä»¥éä½ç¢çææ¯æå¼ç¼è²¬ä»»çæå­çå¯è½æ§ãä½¿ç¨èæå®å¨åæå¸«åè©¦ä½¿ç¨å°ææ§æç¤ºä¾ç ´è§£æå°éäºæ¨¡åé²è¡ç´éæ¸¬è©¦ï¼éæå°è´ç¬¦åè«æ±ãä¸ç¨®æ»ææ¹æ³æ¯å°æç¤ºå¥ç¨é¢æ£æä½³åæè¡ãç¶èï¼ç¢ççæ»æå­ä¸²éå¸¸æ¯ç¡æç¾©çæå­ï¼ç±æ¼æ¸¬éå°çå°æåº¦é«ï¼å¾å®¹æè¢«é²ç¦¦èéæ¿¾æï¼ä¸¦ä¸å¯è½ç¡æ³å·è¡æªè¦éçå·¥ä½å/æèª¿æ´è¯å¥½çæ¨¡åãå¨éé å·¥ä½ä¸­ï¼æåæ¹é²äºç¾ææ¼ç®æ³ï¼ä¸»è¦æ¯ GCG å BEASTï¼ï¼ä»¥å° Llama-2 å Phi-3 ç­å®å¨æ§èª¿æ´æ¨¡åç¼åå¼·å¤§ä¸æµæ¢çæ»æãæåçæè¡åç¹ä¸ç¨®æ°çåºæ¼è¸é¤¾çæ¹æ³ï¼å®é¼åµåå®³èæ¨¡åæ¨¡æ¬ä¸­æ¯çå¾®èª¿ï¼ç¡è«æ¯å¨è¼¸åºæ©çæå§é¨æ¿æ´»æ¹é¢ãçºäºé¼åµäººé¡æµæ¢çæ»æï¼æåå¨ç®æ¨ä¸­å å¥å¤æ¨¡åå°æåº¦æ²ç½°åéè¤æ²ç½°ãæåéééåè¨±æå¥ä»£ç¢¼ãäº¤æä»£ç¢¼ååªé¤ä»£ç¢¼ï¼ä»¥åä½¿ç¨è¼é·çæ»æåºåä¾å¢å¼·æä½³åå¨çå¼·åº¦ãç±æ­¤ç¢ççç¨åºè½å¤ å¯é å°ç ´è§£æå°é£çç®æ¨æ¨¡åï¼å¶æç¤ºçèµ·ä¾é¡ä¼¼æ¼äººé¡ç·¨å¯«çæç¤ºãå¨ Advbench ä¸ï¼æåå° Llama-2-7BãLlama-3-8B å Vicuna-7B éå°äº $>93$% çæ»ææåçï¼åæç¶­ææ¨¡åæ¸¬éçå°æåº¦ $<33$ï¼æåå° Phi-3 éå°äº $95$% çæ»ææåçï¼åç®¡å°æåº¦è¼é«ãæåéæ¾å°äºç¶ééç¨æä½³åçå®ä¸æµæ¢æç¤ºï¼å®å¯ä»¥å¨ Llama-2-7BãPhi-3-mini å Vicuna-7B ä¸­ä»¥åææªè¦çå·¥ä½ä¸å¼ç¼ $>88$% çåè¦æ§ï¼ä¸¦å³è¼¸å°å¶ä»é»çæ¨¡åã

##### **HumanVid: Demystifying Training Data for Camera-controllable Human Image Animation**
2407.17438v1 by Zhenzhi Wang, Yixuan Li, Yanhong Zeng, Youqing Fang, Yuwei Guo, Wenran Liu, Jing Tan, Kai Chen, Tianfan Xue, Bo Dai, Dahua Lin

Human image animation involves generating videos from a character photo,
allowing user control and unlocking potential for video and movie production.
While recent approaches yield impressive results using high-quality training
data, the inaccessibility of these datasets hampers fair and transparent
benchmarking. Moreover, these approaches prioritize 2D human motion and
overlook the significance of camera motions in videos, leading to limited
control and unstable video generation.To demystify the training data, we
present HumanVid, the first large-scale high-quality dataset tailored for human
image animation, which combines crafted real-world and synthetic data. For the
real-world data, we compile a vast collection of copyright-free real-world
videos from the internet. Through a carefully designed rule-based filtering
strategy, we ensure the inclusion of high-quality videos, resulting in a
collection of 20K human-centric videos in 1080P resolution. Human and camera
motion annotation is accomplished using a 2D pose estimator and a SLAM-based
method. For the synthetic data, we gather 2,300 copyright-free 3D avatar assets
to augment existing available 3D assets. Notably, we introduce a rule-based
camera trajectory generation method, enabling the synthetic pipeline to
incorporate diverse and precise camera motion annotation, which can rarely be
found in real-world data. To verify the effectiveness of HumanVid, we establish
a baseline model named CamAnimate, short for Camera-controllable Human
Animation, that considers both human and camera motions as conditions. Through
extensive experimentation, we demonstrate that such simple baseline training on
our HumanVid achieves state-of-the-art performance in controlling both human
pose and camera motions, setting a new benchmark. Code and data will be
publicly available at \url{https://github.com/zhenzhiwang/HumanVid/}.

æè¦ï¼äººé¡å½±ååç«æ¶åå¾è§è²ç§çç¢çå½±çï¼
è®ä½¿ç¨èå¯ä»¥æ§å¶ä¸¦è§£éå½±çåé»å½±è£½ä½çæ½åã
éç¶æè¿çæ¹æ³ä½¿ç¨é«åè³ªè¨ç·´è³æç¢çä»¤äººå°è±¡æ·±å»ççµæï¼
ä½éäºè³æéé£ä»¥åå¾ï¼é»ç¤äºå¬å¹³åéæçåºæºæ¸¬è©¦ã
æ­¤å¤ï¼éäºæ¹æ³åªåèæ® 2D äººé¡åä½ï¼
èå¿½ç¥äºå½±çä¸­ç¸æ©åä½çéè¦æ§ï¼å°è´æ§å¶åéä¸å½±çç¢çä¸ç©©å®ã
çºäºéæ¸è¨ç·´è³æï¼æåæåº HumanVidï¼éæ¯ç¬¬ä¸åéå°äººé¡å½±ååç«éèº«æé çå¤§è¦æ¨¡é«åè³ªè³æéï¼
çµåäºç²¾å¿è£½ä½ççå¯¦ä¸çååæè³æã
å°æ¼çå¯¦ä¸çè³æï¼æåå¾ç¶²è·¯ä¸ç·¨å¶äºå¤§éåçæ¬ççå¯¦ä¸çå½±çã
ééç²¾å¿è¨­è¨çåºæ¼è¦åçéæ¿¾ç­ç¥ï¼æåç¢ºä¿ç´å¥é«åè³ªå½±çï¼
ç¢çäº 1080P è§£æåº¦ç 20K ä»¥äººé¡çºä¸­å¿çå½±çéã
äººé¡åç¸æ©åä½è¨»è§£æ¯ä½¿ç¨ 2D å§¿å¢ä¼°è¨å¨ååºæ¼ SLAM çæ¹æ³å®æçã
å°æ¼åæè³æï¼æåæ¶éäº 2,300 ååçæ¬ç 3D é ­åè³ç¢ä¾æ´åç¾æç 3D è³ç¢ã
å¼å¾æ³¨æçæ¯ï¼æåå¼å¥äºåºæ¼è¦åçç¸æ©è»è·¡ç¢çæ¹æ³ï¼
ä½¿åæç®¡ç·è½å¤ ç´å¥å¤æ¨£ä¸ç²¾ç¢ºçç¸æ©åä½è¨»è§£ï¼éå¨çå¯¦ä¸çè³æä¸­å¾å°è¦ã
çºäºé©è­ HumanVid çæææ§ï¼æåå»ºç«äºä¸ååçº CamAnimate çåºæºæ¨¡åï¼ç°¡ç¨± Camera-controllable Human Animationï¼
å°äººé¡åç¸æ©åä½é½è¦çºæ¢ä»¶ã
ééå»£æ³çå¯¦é©ï¼æåè­æäºå¨æåç HumanVid ä¸é²è¡éç¨®ç°¡å®çåºæºè¨ç·´ï¼
å¨æ§å¶äººé¡å§¿å¢åç¸æ©åä½æ¹é¢éå°äºæåé²çæè½ï¼æ¨¹ç«äºæ°çåºæºã
ç¨å¼ç¢¼åè³æå°å¨ \url{https://github.com/zhenzhiwang/HumanVid/} å¬éã

##### **(PASS) Visual Prompt Locates Good Structure Sparsity through a Recurrent HyperNetwork**
2407.17412v1 by Tianjin Huang, Fang Meng, Li Shen, Fan Liu, Yulong Pei, Mykola Pechenizkiy, Shiwei Liu, Tianlong Chen

Large-scale neural networks have demonstrated remarkable performance in
different domains like vision and language processing, although at the cost of
massive computation resources. As illustrated by compression literature,
structural model pruning is a prominent algorithm to encourage model
efficiency, thanks to its acceleration-friendly sparsity patterns. One of the
key questions of structural pruning is how to estimate the channel
significance. In parallel, work on data-centric AI has shown that
prompting-based techniques enable impressive generalization of large language
models across diverse downstream tasks. In this paper, we investigate a
charming possibility - \textit{leveraging visual prompts to capture the channel
importance and derive high-quality structural sparsity}. To this end, we
propose a novel algorithmic framework, namely \texttt{PASS}. It is a tailored
hyper-network to take both visual prompts and network weight statistics as
input, and output layer-wise channel sparsity in a recurrent manner. Such
designs consider the intrinsic channel dependency between layers. Comprehensive
experiments across multiple network architectures and six datasets demonstrate
the superiority of \texttt{PASS} in locating good structural sparsity. For
example, at the same FLOPs level, \texttt{PASS} subnetworks achieve $1\%\sim
3\%$ better accuracy on Food101 dataset; or with a similar performance of
$80\%$ accuracy, \texttt{PASS} subnetworks obtain $0.35\times$ more speedup
than the baselines.

æè¦ï¼å¤§åç¥ç»ç¶²è·¯å¨ä¸åçé åï¼ä¾å¦è¦è¦ºåèªè¨èçä¸­ï¼å±ç¾äºéå¡çæè½ï¼åç®¡æ¯ä»¥å¤§éçéç®è³æºçºä»£å¹ãæ­£å¦å£ç¸®æç»æèªªæçï¼çµæ§æ¨¡ååªææ¯ä¸ç¨®çªåºçæ¼ç®æ³ï¼ç¨æ¼æåæ¨¡åæçï¼éè¦æ­¸åæ¼å¶æå©æ¼å éçç¨çæ¨¡å¼ãçµæ§åªæçééµåé¡ä¹ä¸æ¯å¦ä½ä¼°è¨éééè¦æ§ãèæ­¤åæï¼è³æä¸­å¿ AI çç ç©¶è¡¨æï¼åºæ¼æç¤ºçæè¡è½å¤ è®å¤§åèªè¨æ¨¡åå¨åç¨®ä¸æ¸¸ä»»åä¸­é²è¡ä»¤äººå°è±¡æ·±å»çæ³åãå¨æ¬æä¸­ï¼æåæ¢è¨äºä¸åè¿·äººçå¯è½æ§ââå©ç¨è¦è¦ºæç¤ºä¾æ·åéééè¦æ§ï¼ä¸¦æ¨å°åºé«åè³ªççµæ§ç¨çæ§ãçºæ­¤ï¼æåæåºäºä¸åæ°ç©çæ¼ç®æ³æ¶æ§ï¼å³ \texttt{PASS}ãå®æ¯ä¸åéèº«æé çè¶ç¶²è·¯ï¼ç¨æ¼å°è¦è¦ºæç¤ºåç¶²è·¯æ¬éçµ±è¨è³æä½çºè¼¸å¥ï¼ä¸¦ä»¥éè¿´æ¹å¼è¼¸åºéå±¤ééç¨çæ§ãæ­¤é¡è¨­è¨èæ®äºå±¤ä¹éçå§å¨ééä¾è³´æ§ãè·¨å¤åç¶²è·¯æ¶æ§åå­åè³æéçç¶åå¯¦é©è­æäº \texttt{PASS} å¨å®ä½è¯å¥½çµæ§ç¨çæ§æ¹é¢çåªè¶æ§ãä¾å¦ï¼å¨ç¸åç FLOP å±¤ç´ï¼\texttt{PASS} å­ç¶²è·¯å¨ Food101 è³æéä¸éå°äº $1\%\sim 3\%$ çæ´ä½³æºç¢ºåº¦ï¼æèå¨å·æç¸ä¼¼ç $80\%$ æºç¢ºåº¦æè½ä¸ï¼\texttt{PASS} å­ç¶²è·¯æ¯åºæºå¿«äº $0.35\times$ åã

##### **Dependency Transformer Grammars: Integrating Dependency Structures into Transformer Language Models**
2407.17406v1 by Yida Zhao, Chao Lou, Kewei Tu

Syntactic Transformer language models aim to achieve better generalization
through simultaneously modeling syntax trees and sentences. While prior work
has been focusing on adding constituency-based structures to Transformers, we
introduce Dependency Transformer Grammars (DTGs), a new class of Transformer
language model with explicit dependency-based inductive bias. DTGs simulate
dependency transition systems with constrained attention patterns by modifying
attention masks, incorporate the stack information through relative positional
encoding, and augment dependency arc representation with a combination of token
embeddings and operation embeddings. When trained on a dataset of sentences
annotated with dependency trees, DTGs achieve better generalization while
maintaining comparable perplexity with Transformer language model baselines.
DTGs also outperform recent constituency-based models, showing that dependency
can better guide Transformer language models. Our code is released at
https://github.com/zhaoyd1/Dep_Transformer_Grammars.

æè¦ï¼å¥æ³è½æèªè¨æ¨¡åæ¨å¨ééåæå°å¥æ³æ¨¹åå¥å­é²è¡å»ºæ¨¡ä¾éææ´å¥½çæ¦æ¬ãéç¶ååçç ç©¶ä¸ç´å°æ³¨æ¼å¨ Transformers ä¸­å å¥åºæ¼æåççµæ§ï¼ä½æåå¼å¥äºä¾è³´è½æèªæ³ (DTG)ï¼éæ¯ä¸ç¨®æ°çè½æèªè¨æ¨¡åé¡å¥ï¼å·ææç¢ºçåºæ¼ä¾è³´çæ­¸ç´åèª¤ãDTG æ¨¡æ¬å·æç´ææ³¨æåæ¨¡å¼çä¾è³´è½æç³»çµ±ï¼ééä¿®æ¹æ³¨æåé®ç½©ãééç¸å°ä½ç½®ç·¨ç¢¼ç´å¥å çè³è¨ï¼ä¸¦çµåæ¨è¨åµå¥åéç®åµå¥ä¾æ´åä¾è³´å¼§è¡¨ç¤ºãç¶å¨æ¨è¨æä¾è³´æ¨¹çå¥å­è³æéä¸é²è¡è¨ç·´æï¼DTG å¯å¨ç¶­æèè½æèªè¨æ¨¡ååºæºç¸ç¶çå°æåº¦çåæï¼éææ´å¥½çæ¦æ¬ãDTG ä¹åªæ¼æè¿åºæ¼æåçæ¨¡åï¼é¡¯ç¤ºä¾è³´å¯ä»¥æ´å¥½å°å¼å°è½æèªè¨æ¨¡åãæåçç¨å¼ç¢¼å·²å¨ https://github.com/zhaoyd1/Dep_Transformer_Grammars ç¼å¸ã

##### **Grammar-based Game Description Generation using Large Language Models**
2407.17404v1 by Tsunehiko Tanaka, Edgar Simo-Serra

To lower the barriers to game design development, automated game design,
which generates game designs through computational processes, has been
explored. In automated game design, machine learning-based techniques such as
evolutionary algorithms have achieved success. Benefiting from the remarkable
advancements in deep learning, applications in computer vision and natural
language processing have progressed in level generation. However, due to the
limited amount of data in game design, the application of deep learning has
been insufficient for tasks such as game description generation. To pioneer a
new approach for handling limited data in automated game design, we focus on
the in-context learning of large language models (LLMs). LLMs can capture the
features of a task from a few demonstration examples and apply the capabilities
acquired during pre-training. We introduce the grammar of game descriptions,
which effectively structures the game design space, into the LLMs' reasoning
process. Grammar helps LLMs capture the characteristics of the complex task of
game description generation. Furthermore, we propose a decoding method that
iteratively improves the generated output by leveraging the grammar. Our
experiments demonstrate that this approach performs well in generating game
descriptions.

æè¦ï¼çºäºéä½éæ²è¨­è¨éç¼çéæª»ï¼èªååéæ²è¨­è¨ï¼éééç®ç¨åºç¢çéæ²è¨­è¨ï¼å·²ç¶è¢«å»£æ³æ¢è¨ãå¨èªååéæ²è¨­è¨ä¸­ï¼åºæ¼æ©å¨å­¸ç¿çæè¡ï¼ä¾å¦æ¼åæ¼ç®æ³ï¼å·²åå¾æåãåçæ¼æ·±åº¦å­¸ç¿çé¡¯èé²æ­¥ï¼é»è¦è¦è¦ºåèªç¶èªè¨èççæç¨å·²å¨éå¡çææ¹é¢åå¾é²å±ãç¶èï¼ç±æ¼éæ²è¨­è¨ä¸­çæ¸æéæéï¼æ·±åº¦å­¸ç¿çæç¨å°æ¼éæ²æè¿°çæç­ä»»åä¾èªªéä¸è¶³å¤ ãçºäºå¨èªååéæ²è¨­è¨ä¸­èçæéæ¸æéåµä¸ç¨®æ°æ¹æ³ï¼æåå°æ³¨æ¼å¤§åèªè¨æ¨¡å (LLM) çèªå¢å­¸ç¿ãLLM å¯ä»¥å¾å°æ¸ç¤ºç¯ç¯ä¾ä¸­æ·åä»»åçç¹å¾µï¼ä¸¦æç¨é è¨ç·´æéç¿å¾çè½åãæåå°éæ²æè¿°çèªæ³ï¼ææå°å»ºæ§éæ²è¨­è¨ç©ºéï¼å¼å¥ LLM çæ¨çéç¨ä¸­ãèªæ³æå©æ¼ LLM æ·åéæ²æè¿°çæéé è¤éä»»åçç¹å¾µãæ­¤å¤ï¼æåæåºäºä¸ç¨®è§£ç¢¼æ¹æ³ï¼ééå©ç¨èªæ³åè¦æ¹åç¢ççè¼¸åºãæåçå¯¦é©è­æï¼éç¨®æ¹æ³å¨ç¢çéæ²æè¿°æ¹é¢è¡¨ç¾è¯å¥½ã

##### **Large Language Models for Anomaly Detection in Computational Workflows: from Supervised Fine-Tuning to In-Context Learning**
2407.17545v1 by Hongwei Jin, George Papadimitriou, Krishnan Raghavan, Pawel Zuk, Prasanna Balaprakash, Cong Wang, Anirban Mandal, Ewa Deelman

Anomaly detection in computational workflows is critical for ensuring system
reliability and security. However, traditional rule-based methods struggle to
detect novel anomalies. This paper leverages large language models (LLMs) for
workflow anomaly detection by exploiting their ability to learn complex data
patterns. Two approaches are investigated: 1) supervised fine-tuning (SFT),
where pre-trained LLMs are fine-tuned on labeled data for sentence
classification to identify anomalies, and 2) in-context learning (ICL) where
prompts containing task descriptions and examples guide LLMs in few-shot
anomaly detection without fine-tuning. The paper evaluates the performance,
efficiency, generalization of SFT models, and explores zero-shot and few-shot
ICL prompts and interpretability enhancement via chain-of-thought prompting.
Experiments across multiple workflow datasets demonstrate the promising
potential of LLMs for effective anomaly detection in complex executions.

æè¦ï¼ç°å¸¸åµæ¸¬å¨éç®å·¥ä½æµç¨ä¸­è³ééè¦ï¼ç¨æ¼ç¢ºä¿ç³»çµ±å¯é æ§åå®å¨æ§ãç¶èï¼å³çµ±çåºæ¼è¦åçæ¹æ³é£ä»¥åµæ¸¬å°æ°çç°å¸¸ãæ¬æå©ç¨å¤§åèªè¨æ¨¡å (LLM) é²è¡å·¥ä½æµç¨ç°å¸¸åµæ¸¬ï¼æ¹æ³æ¯å©ç¨å®åå­¸ç¿è¤éè³ææ¨¡å¼çè½åãç ç©¶äºå©ç¨®æ¹æ³ï¼1) ç£ç£å¾®èª¿ (SFT)ï¼å¶ä¸­é åè¨ç·´ç LLM å¨æ¨ç±¤è³æä¸é²è¡å¾®èª¿ï¼ç¨æ¼å¥å­åé¡ä»¥è­å¥ç°å¸¸ï¼ä»¥å 2) ä¸ä¸æå­¸ç¿ (ICL)ï¼å¶ä¸­åå«ä»»åæè¿°åç¯ä¾çæç¤ºå¨æ²æå¾®èª¿çææ³ä¸å¼å° LLM é²è¡å°æ¬¡ç°å¸¸åµæ¸¬ãæ¬æè©ä¼°äº SFT æ¨¡åçæè½ãæçãæ³åæ§ï¼ä¸¦æ¢è¨äºé¶æ¬¡åå°æ¬¡ ICL æç¤ºä»¥åééæèéæç¤ºå¢å¼·å¯è§£éæ§ãè·¨å¤åå·¥ä½æµç¨è³æéçå¯¦é©è­æäº LLM å¨è¤éå·è¡ä¸­é²è¡ææç°å¸¸åµæ¸¬çæ½åã

##### **Systematic Reasoning About Relational Domains With Graph Neural Networks**
2407.17396v1 by Irtaza Khalid, Steven Schockaert

Developing models that can learn to reason is a notoriously challenging
problem. We focus on reasoning in relational domains, where the use of Graph
Neural Networks (GNNs) seems like a natural choice. However, previous work on
reasoning with GNNs has shown that such models tend to fail when presented with
test examples that require longer inference chains than those seen during
training. This suggests that GNNs lack the ability to generalize from training
examples in a systematic way, which would fundamentally limit their reasoning
abilities. A common solution is to instead rely on neuro-symbolic methods,
which are capable of reasoning in a systematic way by design. Unfortunately,
the scalability of such methods is often limited and they tend to rely on
overly strong assumptions, e.g.\ that queries can be answered by inspecting a
single relational path. In this paper, we revisit the idea of reasoning with
GNNs, showing that systematic generalization is possible as long as the right
inductive bias is provided. In particular, we argue that node embeddings should
be treated as epistemic states and that GNN should be parameterised
accordingly. We propose a simple GNN architecture which is based on this view
and show that it is capable of achieving state-of-the-art results. We
furthermore introduce a benchmark which requires models to aggregate evidence
from multiple relational paths. We show that existing neuro-symbolic approaches
fail on this benchmark, whereas our considered GNN model learns to reason
accurately.

æè¦ï¼<paragraph>éç¼è½å­¸ç¿æ¨ççæ¨¡åæ¯åºäºåçå°é£åé¡ãæåå°æ³¨æ¼éä¿é åä¸­çæ¨çï¼å¶ä¸­åå½¢ç¥ç¶ç¶²è·¯ (GNN) çä½¿ç¨ä¼¼ä¹æ¯ä¸åèªç¶é¸æãç¶èï¼ååéæ¼ä½¿ç¨ GNN æ¨ççç ç©¶é¡¯ç¤ºï¼ç¶æä¾æ¯è¨ç·´æéæè¦æ´é·æ¨è«éçæ¸¬è©¦ç¯ä¾æï¼æ­¤é¡æ¨¡åå¾å¾æå¤±æãéè¡¨æ GNN ç¼ºä¹ä»¥ç³»çµ±æ¹å¼å¾è¨ç·´ç¯ä¾ä¸­æ¦åçè½åï¼éå¾æ ¹æ¬ä¸éå¶äºå®åçæ¨çè½åãä¸åå¸¸è¦çè§£æ±ºæ¹æ¡æ¯æ¹èä¾è³´ç¥ç¶ç¬¦èæ¹æ³ï¼å®å¨è¨­è¨ä¸è½å¤ ä»¥ç³»çµ±æ¹å¼é²è¡æ¨çãä¸å¹¸çæ¯ï¼æ­¤é¡æ¹æ³çå¯æ´åæ§éå¸¸åå°éå¶ï¼èä¸å®åå¾å¾ä¾è³´æ¼éæ¼å¼·ççåè¨­ï¼ä¾å¦ï¼æ¥è©¢å¯ä»¥ééæª¢æ¥å®ä¸éä¿è·¯å¾ä¾åç­ãå¨æ¬æä¸­ï¼æåéæ°æ¢è¨ä½¿ç¨ GNN æ¨ççæ³æ³ï¼è­æåªè¦æä¾äºæ­£ç¢ºçæ­¸ç´åèª¤ï¼ç³»çµ±æ¦åæ¯å¯è½çãç¹å¥æ¯ï¼æåä¸»å¼µç¯é»åµå¥æè¦çºèªè­çæï¼ä¸¦ä¸ GNN æç¸æå°åæ¸åãæåæåºäºä¸ååºæ¼æ­¤è§é»çç°¡å® GNN æ¶æ§ï¼ä¸¦è¡¨æå®è½å¤ å¯¦ç¾æåé²ççµæãæ­¤å¤ï¼æåéå¼å¥äºéè¦æ¨¡åå¾å¤åéä¿è·¯å¾å¯ç¸½è­æçåºæºãæåè¡¨æç¾æçç¥ç¶ç¬¦èæ¹æ³å¨æ­¤åºæºä¸å¤±æï¼èæåèæ®ç GNN æ¨¡ååå­¸ææºç¢ºæ¨çã</paragraph>

##### **CovScore: Evaluation of Multi-Document Abstractive Title Set Generation**
2407.17390v1 by Itamar Trainin, Omri Abend

This paper introduces CovScore, an automatic reference-less methodology for
evaluating thematic title sets, extracted from a corpus of documents. While
such extraction methods are widely used, evaluating their effectiveness remains
an open question. Moreover, some existing practices heavily rely on slow and
laborious human annotation procedures. Inspired by recently introduced
LLM-based judge methods, we propose a novel methodology that decomposes quality
into five main metrics along different aspects of evaluation. This framing
simplifies and expedites the manual evaluation process and enables automatic
and independent LLM-based evaluation. As a test case, we apply our approach to
a corpus of Holocaust survivor testimonies, motivated both by its relevance to
title set extraction and by the moral significance of this pursuit. We validate
the methodology by experimenting with naturalistic and synthetic title set
generation systems and compare their performance with the methodology.

æè¦ï¼æ¬æä»ç´¹ CovScoreï¼éæ¯ä¸ç¨®èªåç¡åèæ¹æ³ï¼ç¨æ¼è©ä¼°å¾æä»¶èªæåº«ä¸­æåçä¸»é¡æ¨é¡éãéç¶æ­¤é¡æåæ¹æ³è¢«å»£æ³ä½¿ç¨ï¼ä½è©ä¼°å¶æææ§ä»ç¶æ¯ä¸åæ¸èæªæ±ºçåé¡ãæ­¤å¤ï¼ä¸äºç¾æåæ³å´éä¾è³´æ¼ç·©æ¢ä¸è²»åççäººæ¨è¨»ç¨åºãåæè¿æ¨åºçåºæ¼ LLM çè©å¯©æ¹æ³çåç¼ï¼æåæåºäºä¸ç¨®æ°æ¹æ³ï¼å°è³ªéåè§£çºäºåä¸»è¦ææ¨ï¼æ¶µèè©ä¼°çä¸åæ¹é¢ãæ­¤æ¡æ¶ç°¡åä¸¦å å¿«äºæåè©ä¼°éç¨ï¼ä¸¦å¯¦ç¾äºåºæ¼ LLM çèªåä¸ç¨ç«è©ä¼°ãä½çºä¸åæ¸¬è©¦æ¡ä¾ï¼æåå°æåçåæ³æç¨æ¼å¤§å± æ®ºåå­èè­è©èªæåº«ï¼éæ¢æ¯å çºå®èæ¨é¡éæåç¸éï¼ä¹æ¯å çºéé è¿½æ±çéå¾·æç¾©ãæåééå°èªç¶ä¸»ç¾©ååææ¨é¡éçæç³»çµ±é²è¡å¯¦é©ä¾é©è­è©²æ¹æ³ï¼ä¸¦å°å¶æ§è½èè©²æ¹æ³é²è¡æ¯è¼ã

##### **PERSONA: A Reproducible Testbed for Pluralistic Alignment**
2407.17387v1 by Louis Castricato, Nathan Lile, Rafael Rafailov, Jan-Philipp FrÃ¤nken, Chelsea Finn

The rapid advancement of language models (LMs) necessitates robust alignment
with diverse user values. However, current preference optimization approaches
often fail to capture the plurality of user opinions, instead reinforcing
majority viewpoints and marginalizing minority perspectives. We introduce
PERSONA, a reproducible test bed designed to evaluate and improve pluralistic
alignment of LMs. We procedurally generate diverse user profiles from US census
data, resulting in 1,586 synthetic personas with varied demographic and
idiosyncratic attributes. We then generate a large-scale evaluation dataset
containing 3,868 prompts and 317,200 feedback pairs obtained from our synthetic
personas. Leveraging this dataset, we systematically evaluate LM capabilities
in role-playing diverse users, verified through human judges, and the
establishment of both a benchmark, PERSONA Bench, for pluralistic alignment
approaches as well as an extensive dataset to create new and future benchmarks.
The full dataset and benchmarks are available here:
https://www.synthlabs.ai/research/persona.

æè¦ï¼èªè¨æ¨¡å (LM) çå¿«éé²æ­¥éè¦èå¤åçä½¿ç¨èå¹å¼è§é²è¡ç©©å¥çå°é½ãç¶èï¼ç®åçåå¥½æä½³åæ¹æ³éå¸¸ç¡æ³ææå°ä½¿ç¨èçæè¦å¤åæ§ï¼åèå¼·åäºå¤æ¸è§é»ï¼ä¸¦å°å°æ¸è§é»éç·£åãæåå¼å¥äº PERSONAï¼ä¸åå¯éè£½çæ¸¬è©¦å¹³å°ï¼æ¨å¨è©ä¼°åæ¹å LM çå¤åå°é½ãæåæ ¹æç¾åäººå£æ®æ¥è³æç¨åºåå°ç¢çäºå¤æ¨£åçä½¿ç¨èè¼ªå»ï¼ç¢çäº 1,586 åå·æä¸åäººå£çµ±è¨åç¹æ®å±¬æ§çåæè§è²ãç¶å¾ï¼æåçæäºåå« 3,868 åæç¤ºå 317,200 ååé¥éå°çå¤§è¦æ¨¡è©ä¼°è³æéï¼éäºéå°ä¾èªæåçåæè§è²ãå©ç¨æ­¤è³æéï¼æåç³»çµ±æ§å°è©ä¼°äº LM å¨æ®æ¼ä¸åä½¿ç¨èæçè½åï¼ä¸¦ééäººå·¥è©å¯©å¡é©è­ï¼ä»¥åå»ºç«äºä¸ååºæºï¼PERSONA Benchï¼ç¨æ¼å¤åå°é½æ¹æ³ï¼ä»¥åä¸åå»£æ³çè³æéä¾å»ºç«æ°çåæªä¾çåºæºãå®æ´çè³æéååºæºå¯å¨æ­¤èåå¾ï¼
https://www.synthlabs.ai/research/personaã

##### **A Comprehensive Approach to Misspelling Correction with BERT and Levenshtein Distance**
2407.17383v1 by Amirreza Naziri, Hossein Zeinali

Writing, as an omnipresent form of human communication, permeates nearly
every aspect of contemporary life. Consequently, inaccuracies or errors in
written communication can lead to profound consequences, ranging from financial
losses to potentially life-threatening situations. Spelling mistakes, among the
most prevalent writing errors, are frequently encountered due to various
factors. This research aims to identify and rectify diverse spelling errors in
text using neural networks, specifically leveraging the Bidirectional Encoder
Representations from Transformers (BERT) masked language model. To achieve this
goal, we compiled a comprehensive dataset encompassing both non-real-word and
real-word errors after categorizing different types of spelling mistakes.
Subsequently, multiple pre-trained BERT models were employed. To ensure optimal
performance in correcting misspelling errors, we propose a combined approach
utilizing the BERT masked language model and Levenshtein distance. The results
from our evaluation data demonstrate that the system presented herein exhibits
remarkable capabilities in identifying and rectifying spelling mistakes, often
surpassing existing systems tailored for the Persian language.

æè¦ï¼èº«çºäººé¡æºéä¸­ç¡æä¸å¨çä¸ç¨®å½¢å¼ï¼å¯«ä½æ»²éæ¼ç¶ä»£çæ´»çå¹¾ä¹æ¯åé¢åãå æ­¤ï¼æ¸é¢æºéä¸­çä¸æºç¢ºæé¯èª¤å¯è½å°è´æ·±é çå¾æï¼å¾è²¡åæå¤±å°æ½å¨å±åçå½ççæ³ãæ¼å¯«é¯èª¤æ¯æå¸¸è¦çå¯«ä½é¯èª¤ä¹ä¸ï¼ç±æ¼åç¨®å ç´ èç¶å¸¸ç¼çãæ¬ç ç©¶æ¨å¨ä½¿ç¨ç¥ç¶ç¶²è·¯è­å¥åç³¾æ­£æå­ä¸­çåç¨®æ¼å¯«é¯èª¤ï¼ç¹å¥æ¯å©ç¨ä¾èª Transformerï¼BERTï¼çéåç·¨ç¢¼å¨è¡¨ç¤ºæ³é®ç½©èªè¨æ¨¡åãçºäºå¯¦ç¾éåç®æ¨ï¼æåç·¨å¶äºä¸åå¨é¢çè³æéï¼å¨å°ä¸åé¡åçæ¼å¯«é¯èª¤é²è¡åé¡å¾ï¼åå«éçå¯¦å­è©åçå¯¦å­è©çé¯èª¤ãé¨å¾ï¼æ¡ç¨äºå¤åé è¨ç·´ç BERT æ¨¡åãçºäºç¢ºä¿å¨ç³¾æ­£æ¼å¯«é¯èª¤æ¹é¢ç²å¾æä½³æè½ï¼æåæåºäºä¸ç¨®çµå BERT é®ç½©èªè¨æ¨¡åå Levenshtein è·é¢çç¶åæ¹æ³ãæåè©ä¼°è³æççµæè¡¨æï¼æ¬ææåºçç³»çµ±å¨è­å¥åç³¾æ­£æ¼å¯«é¯èª¤æ¹é¢è¡¨ç¾åºé¡¯èçè½åï¼éå¸¸åªæ¼éå°æ³¢æ¯èªéèº«æé çç¾æç³»çµ±ã

##### **MMRA: A Benchmark for Multi-granularity Multi-image Relational Association**
2407.17379v1 by Siwei Wu, Kang Zhu, Yu Bai, Yiming Liang, Yizhi Li, Haoning Wu, Jiaheng Liu, Ruibo Liu, Xingwei Qu, Xuxin Cheng, Ge Zhang, Wenhao Huang, Chenghua Lin

Given the remarkable success that large visual language models (LVLMs) have
achieved in image perception tasks, the endeavor to make LVMLs perceive the
world like humans is drawing increasing attention. Current multi-modal
benchmarks mainly focus on the objective fact or certain topic related
potential knowledge within a image, but overlook the associative relations
between multiple images. Therefore, we define a multi-image relation
association task, and meticulously curate \textbf{MMRA} benchmark, a
\textbf{M}ulti-granularity \textbf{M}ulti-image \textbf{R}elational
\textbf{A}ssociation benchmark, consisted of \textbf{1026} samples. In order to
systematically and comprehensively evaluate mainstream LVLMs, we establish an
associational relation system among images that contain \textbf{11 subtasks}
(e.g, UsageSimilarity, SubEvent, etc.) at two granularity levels (i.e.,
"\textbf{image}" and "\textbf{entity}") according to the relations in
ConceptNet. Our experiments demonstrate that, on our MMRA benchmark, current
mainstream LVLMs all have their own advantages and disadvantages across
different subtasks. It is worth noting that, at the entity level, the
performance of all models is worse than that of them at the image level,
indicating that the fine-grained multi-image perception task is still
challenging for LVLMs. The tasks related to spatial perception are relatively
difficult for LVLMs to handle. Furthermore, we find that LVMLs exhibit a good
ability to perceive image details, and the key to enhancing their multi-image
association capability is to strengthen the reasoning ability of their language
model component. All our codes and data are released at
htt\url{https://github.com/Wusiwei0410/MMRA}.

æè¦ï¼<paragraph>é´äºå¤§åè§è§è¯­è¨æ¨¡å (LVLMs) å¨å¾åæç¥ä»»å¡ä¸­åå¾çæ¾èæåï¼è®© LVML åäººç±»ä¸æ ·æç¥ä¸ççåªåæ­£å¼èµ·è¶æ¥è¶å¤çå³æ³¨ãå½åçå¤æ¨¡æåºåä¸»è¦å³æ³¨å¾åä¸­çå®¢è§äºå®æä¸ç¹å®ä¸»é¢ç¸å³çæ½å¨ç¥è¯ï¼ä½å¿½ç¥äºå¤å¹å¾åä¹é´çå³èå³ç³»ãå æ­¤ï¼æä»¬å®ä¹äºä¸ä¸ªå¤å¾åå³ç³»å³èä»»å¡ï¼å¹¶ç²¾å¿ç­åäº\textbf{MMRA}åºåï¼è¿æ¯ä¸ä¸ª\textbf{M}ulti-granularity \textbf{M}ulti-image \textbf{R}elational \textbf{A}ssociationåºåï¼ç±\textbf{1026}ä¸ªæ ·æ¬ç»æãä¸ºäºç³»ç»å¨é¢å°è¯ä¼°ä¸»æµ LVLMsï¼æä»¬æ ¹æ® ConceptNet ä¸­çå³ç³»ï¼å¨åå«\textbf{11 ä¸ªå­ä»»å¡}(ä¾å¦ UsageSimilarityãSubEvent ç­)çå¾åä¸­å»ºç«äºä¸ä¸ªå³èå³ç³»ç³»ç»ï¼è¯¥ç³»ç»å·æä¸¤ä¸ªç²åº¦çº§å«(å³â\textbf{å¾å}âåâ\textbf{å®ä½}â)ãæä»¬çå®éªè¡¨æï¼å¨æä»¬ç MMRA åºåä¸ï¼å½åçä¸»æµ LVLMs å¨ä¸åçå­ä»»å¡ä¸­é½æåèªçä¼å¿åå£å¿ãå¼å¾æ³¨æçæ¯ï¼å¨å®ä½å±é¢ä¸ï¼æææ¨¡åçæ§è½é½æ¯å®ä»¬å¨å¾åå±é¢çæ§è½å·®ï¼è¿è¡¨æç»ç²åº¦å¤å¾åæç¥ä»»å¡å¯¹äº LVLMs ä»ç¶å·ææææ§ãä¸ç©ºé´æç¥ç¸å³çä»»å¡å¯¹äº LVLMs æ¥è¯´ç¸å¯¹é¾ä»¥å¤çãæ­¤å¤ï¼æä»¬åç° LVMLs è¡¨ç°åºè¯å¥½çæç¥å¾åç»èçè½åï¼å¢å¼ºå¶å¤å¾åå³èè½åçå³é®å¨äºå å¼ºå¶è¯­è¨æ¨¡åç»ä»¶çæ¨çè½åãæä»¬ææçä»£ç åæ°æ®é½å¯ä»¥å¨htt\url{https://github.com/Wusiwei0410/MMRA}åå¸ã</paragraph>

##### **MathViz-E: A Case-study in Domain-Specialized Tool-Using Agents**
2407.17544v1 by Arya Bulusu, Brandon Man, Ashish Jagmohan, Aditya Vempaty, Jennifer Mari-Wyka, Deepak Akkil

There has been significant recent interest in harnessing LLMs to control
software systems through multi-step reasoning, planning and tool-usage. While
some promising results have been obtained, application to specific domains
raises several general issues including the control of specialized domain
tools, the lack of existing datasets for training and evaluation, and the
non-triviality of automated system evaluation and improvement. In this paper,
we present a case-study where we examine these issues in the context of a
specific domain. Specifically, we present an automated math visualizer and
solver system for mathematical pedagogy. The system orchestrates mathematical
solvers and math graphing tools to produce accurate visualizations from simple
natural language commands. We describe the creation of specialized data-sets,
and also develop an auto-evaluator to easily evaluate the outputs of our system
by comparing them to ground-truth expressions. We have open sourced the
data-sets and code for the proposed system.

æè¦ï¼æè¿ï¼äººä»¬å¯¹å©ç¨å¤§åè¯­è¨æ¨¡å (LLM) æ¥éè¿å¤æ­¥éª¤æ¨çãè§ååå·¥å·ä½¿ç¨æ¥æ§å¶è½¯ä»¶ç³»ç»äº§çäºæå¤§çå´è¶£ãè½ç¶å·²ç»åå¾äºä¸äºæå¸æçç»æï¼ä½åºç¨äºç¹å®é¢åä¼å¼åå ä¸ªæ®éæ§é®é¢ï¼åæ¬å¯¹ä¸ä¸é¢åå·¥å·çæ§å¶ãç¼ºä¹ç¨äºè®­ç»åè¯ä¼°çç°ææ°æ®éï¼ä»¥åèªå¨åç³»ç»è¯ä¼°åæ¹è¿çéå¹³å¡æ§ãå¨æ¬æä¸­ï¼æä»¬æåºäºä¸ä¸ªæ¡ä¾ç ç©¶ï¼å¶ä¸­æä»¬ç ç©¶äºç¹å®é¢åèæ¯ä¸çè¿äºé®é¢ãå·ä½æ¥è¯´ï¼æä»¬å±ç¤ºäºä¸ä¸ªç¨äºæ°å­¦æè²çèªå¨åæ°å­¦å¯è§åå¨åæ±è§£å¨ç³»ç»ãè¯¥ç³»ç»åè°æ°å­¦æ±è§£å¨åæ°å­¦ç»å¾å·¥å·ï¼ä»¥æ ¹æ®ç®åçèªç¶è¯­è¨å½ä»¤çæåç¡®çå¯è§åææãæä»¬æè¿°äºä¸é¨æ°æ®éçåå»ºï¼è¿å¼åäºä¸ä¸ªèªå¨è¯ä¼°å¨ï¼éè¿å°æä»¬çç³»ç»è¾åºä¸çå®è¡¨è¾¾å¼è¿è¡æ¯è¾ï¼è½»æ¾è¯ä¼°å¶è¾åºãæä»¬å·²ç»å¼æºäºææè®®ç³»ç»çä»£ç åæ°æ®éã

##### **Dataset Distribution Impacts Model Fairness: Single vs. Multi-Task Learning**
2407.17543v1 by Ralf Raumanns, Gerard Schouten, Josien P. W. Pluim, Veronika Cheplygina

The influence of bias in datasets on the fairness of model predictions is a
topic of ongoing research in various fields. We evaluate the performance of
skin lesion classification using ResNet-based CNNs, focusing on patient sex
variations in training data and three different learning strategies. We present
a linear programming method for generating datasets with varying patient sex
and class labels, taking into account the correlations between these variables.
We evaluated the model performance using three different learning strategies: a
single-task model, a reinforcing multi-task model, and an adversarial learning
scheme. Our observations include: 1) sex-specific training data yields better
results, 2) single-task models exhibit sex bias, 3) the reinforcement approach
does not remove sex bias, 4) the adversarial model eliminates sex bias in cases
involving only female patients, and 5) datasets that include male patients
enhance model performance for the male subgroup, even when female patients are
the majority. To generalise these findings, in future research, we will examine
more demographic attributes, like age, and other possibly confounding factors,
such as skin colour and artefacts in the skin lesions. We make all data and
models available on GitHub.

æè¦ï¼å¨åç¨®é åä¸­ï¼è³æéä¸­åèª¤å°æ¨¡åé æ¸¬å¬å¹³æ§çå½±é¿æ¯ä¸é æçºçç ç©¶ä¸»é¡ãæåè©ä¼°äºä½¿ç¨åºæ¼ ResNet ç CNN é²è¡ç®èçç¶åé¡çæè½ï¼éé»éæ³¨è¨ç·´è³æä¸­çæ£èæ§å¥å·®ç°åä¸ç¨®ä¸åçå­¸ç¿ç­ç¥ãæåæåºäºä¸ç¨®ç·æ§è¦åæ¹æ³ï¼ç¨æ¼çæå·æä¸åæ£èæ§å¥åé¡å¥æ¨ç±¤çè³æéï¼åæèæ®éäºè®æ¸ä¹éçç¸éæ§ãæåä½¿ç¨ä¸ç¨®ä¸åçå­¸ç¿ç­ç¥è©ä¼°äºæ¨¡åæè½ï¼å®ä»»åæ¨¡åãå¼·åå¤ä»»åæ¨¡ååå°æå¼å­¸ç¿æ¹æ¡ãæåçè§å¯çµæåæ¬ï¼1) ç¹å®æ§å¥çè¨ç·´è³æç¢çäºæ´å¥½ççµæï¼2) å®ä»»åæ¨¡åè¡¨ç¾åºæ§å¥åè¦ï¼3) å¼·åæ¹æ³ä¸¦æ²ææ¶é¤æ§å¥åè¦ï¼4) å°ææ¨¡åæ¶é¤äºåæ¶åå¥³æ§æ£èçææ³ä¸­çæ§å¥åè¦ï¼ä»¥å 5) åå«ç·æ§æ£èçè³æéå¢å¼·äºç·æ§å­ç¾¤çæ¨¡åæè½ï¼å³ä½¿å¥³æ§æ£èä½å¤æ¸ãçºäºæ¦æ¬éäºç¼ç¾ï¼å¨æªä¾çç ç©¶ä¸­ï¼æåå°æª¢æ¥æ´å¤çäººå£å±¬æ§ï¼ä¾å¦å¹´é½¡ï¼ä»¥åå¶ä»å¯è½çæ··æ·å ç´ ï¼ä¾å¦ç®èé¡è²åç®èçç¶ä¸­çäººå·¥è£½åãæåå°ææè³æåæ¨¡åé½æ¾å¨ GitHub ä¸ã

##### **Boosting Large Language Models with Socratic Method for Conversational Mathematics Teaching**
2407.17349v1 by Yuyang Ding, Hanglei Hu, Jie Zhou, Qin Chen, Bo Jiang, Liang He

With the introduction of large language models (LLMs), automatic math
reasoning has seen tremendous success. However, current methods primarily focus
on providing solutions or using techniques like Chain-of-Thought to enhance
problem-solving accuracy. In this paper, we focus on improving the capability
of mathematics teaching via a Socratic teaching-based LLM
(\texttt{SocraticLLM}), which guides learners toward profound thinking with
clarity and self-discovery via conversation. We collect and release a
high-quality mathematical teaching dataset, named \texttt{SocraticMATH}, which
provides Socratic-style conversations of problems with extra knowledge. Also,
we propose a knowledge-enhanced LLM as a strong baseline to generate reliable
responses with review, guidance/heuristic, rectification, and summarization.
Experimental results show the great advantages of \texttt{SocraticLLM} by
comparing it with several strong generative models. The codes and datasets are
available on \url{https://github.com/ECNU-ICALK/SocraticMath}.

æè¦ï¼é¨èå¤§åèªè¨æ¨¡å (LLM) çå°å¥ï¼èªåæ¸å­¸
æ¨çåå¾äºå·¨å¤§çæåãç¶èï¼ç®åçæ¹æ³ä¸»è¦å°æ³¨æ¼æä¾è§£æ±ºæ¹æ¡æä½¿ç¨ææ³éç­æè¡ä¾æé«
åé¡è§£æ±ºçæºç¢ºæ§ãå¨æ¬æä¸­ï¼æåå°æ³¨æ¼ééèæ ¼æåºæå­¸çºåºç¤ç LLM (\texttt{SocraticLLM}) ä¾æåæ¸å­¸æå­¸è½åï¼å®ééå°è©±å¼å°å­¸ç¿èé²è¡æ·±å¥æèï¼ä¸¦ééèªæç¼ç¾ç²å¾æ¸æ°åº¦ãæåæ¶éä¸¦ç¼å¸ä¸åé«åè³ªçæ¸å­¸æå­¸è³æéï¼åçº \texttt{SocraticMATH}ï¼å®æä¾äºåé¡çèæ ¼æåºå¼å°è©±ä»¥åé¡å¤çç¥è­ãæ­¤å¤ï¼æåæåºä¸åç¥è­å¢å¼·ç LLM ä½çºä¸åå¼·å¤§çåºæºï¼ä»¥ç¢çå¯é çåæï¼ä¸¦æä¾åé¡§ãæå°/åç¼å¼ãä¿®æ­£åç¸½çµãå¯¦é©çµæé¡¯ç¤ºäº \texttt{SocraticLLM} çå·¨å¤§åªå¢ï¼ä¸¦å°å¶èå¹¾åå¼·å¤§ççææ¨¡åé²è¡æ¯è¼ãç¨å¼ç¢¼åè³æéå¯å¨ \url{https://github.com/ECNU-ICALK/SocraticMath} ä¸åå¾ã


### Medical explainable AI
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-07-24**|**Enhanced Deep Learning Methodologies and MRI Selection Techniques for Dementia Diagnosis in the Elderly Population**|Nikolaos Ntampakis et.al.|[2407.17324v2](http://arxiv.org/abs/2407.17324v2)|null|
|**2024-07-18**|**A Comparative Study on Automatic Coding of Medical Letters with Explainability**|Jamie Glen et.al.|[2407.13638v1](http://arxiv.org/abs/2407.13638v1)|[link](https://github.com/Glenj01/Medical-Coding)|
|**2024-07-09**|**Explainable AI for Enhancing Efficiency of DL-based Channel Estimation**|Abdul Karim Gizzini et.al.|[2407.07009v1](http://arxiv.org/abs/2407.07009v1)|null|
|**2024-07-07**|**Explainable AI: Comparative Analysis of Normal and Dilated ResNet Models for Fundus Disease Classification**|P. N. Karthikayan et.al.|[2407.05440v1](http://arxiv.org/abs/2407.05440v1)|null|
|**2024-07-03**|**A Survey on Trustworthiness in Foundation Models for Medical Image Analysis**|Congzhen Shi et.al.|[2407.15851v1](http://arxiv.org/abs/2407.15851v1)|null|
|**2024-07-01**|**The Impact of an XAI-Augmented Approach on Binary Classification with Scarce Data**|Ximing Wen et.al.|[2407.06206v1](http://arxiv.org/abs/2407.06206v1)|null|
|**2024-06-28**|**Can GPT-4 Help Detect Quit Vaping Intentions? An Exploration of Automatic Data Annotation Approach**|Sai Krishna Revanth Vuruma et.al.|[2407.00167v1](http://arxiv.org/abs/2407.00167v1)|null|
|**2024-06-25**|**Towards Compositional Interpretability for XAI**|Sean Tull et.al.|[2406.17583v1](http://arxiv.org/abs/2406.17583v1)|null|
|**2024-06-11**|**Unlocking the Potential of Metaverse in Innovative and Immersive Digital Health**|Fatemeh Ebrahimzadeh et.al.|[2406.07114v2](http://arxiv.org/abs/2406.07114v2)|null|
|**2024-06-10**|**AI-Driven Predictive Analytics Approach for Early Prognosis of Chronic Kidney Disease Using Ensemble Learning and Explainable AI**|K M Tawsik Jawad et.al.|[2406.06728v1](http://arxiv.org/abs/2406.06728v1)|null|
|**2024-06-10**|**Explainable AI for Mental Disorder Detection via Social Media: A survey and outlook**|Yusif Ibrahimov et.al.|[2406.05984v1](http://arxiv.org/abs/2406.05984v1)|null|
|**2024-06-09**|**Methodology and Real-World Applications of Dynamic Uncertain Causality Graph for Clinical Diagnosis with Explainability and Invariance**|Zhan Zhang et.al.|[2406.05746v1](http://arxiv.org/abs/2406.05746v1)|null|
|**2024-06-07**|**Advancing Histopathology-Based Breast Cancer Diagnosis: Insights into Multi-Modality and Explainability**|Faseela Abdullakutty et.al.|[2406.12897v1](http://arxiv.org/abs/2406.12897v1)|null|
|**2024-06-07**|**Revisiting Attention Weights as Interpretations of Message-Passing Neural Networks**|Yong-Min Shin et.al.|[2406.04612v1](http://arxiv.org/abs/2406.04612v1)|[link](https://github.com/jordan7186/gatt)|
|**2024-06-04**|**Using Explainable AI for EEG-based Reduced Montage Neonatal Seizure Detection**|Dinuka Sandun Udayantha et.al.|[2406.16908v2](http://arxiv.org/abs/2406.16908v2)|[link](https://github.com/dinuka-1999/braineocare)|
|**2024-06-01**|**Breast Cancer Diagnosis: A Comprehensive Exploration of Explainable Artificial Intelligence (XAI) Techniques**|Samita Bai et.al.|[2406.00532v1](http://arxiv.org/abs/2406.00532v1)|null|
|**2024-06-01**|**Unveiling Hidden Factors: Explainable AI for Feature Boosting in Speech Emotion Recognition**|Alaa Nfissi et.al.|[2406.01624v2](http://arxiv.org/abs/2406.01624v2)|[link](https://github.com/alaanfissi/unveiling-hidden-factors-explainable-ai-for-feature-boosting-in-speech-emotion-recognition)|
|**2024-05-31**|**The Explanation Necessity for Healthcare AI**|Michail Mamalakis et.al.|[2406.00216v1](http://arxiv.org/abs/2406.00216v1)|null|
|**2024-05-29**|**Interdisciplinary Expertise to Advance Equitable Explainable AI**|Chloe R. Bennett et.al.|[2406.18563v1](http://arxiv.org/abs/2406.18563v1)|null|
|**2024-05-27**|**"It depends": Configuring AI to Improve Clinical Usefulness Across Contexts**|Hubert D. ZajÄc et.al.|[2407.11978v1](http://arxiv.org/abs/2407.11978v1)|null|
|**2024-05-26**|**Improving Health Professionals' Onboarding with AI and XAI for Trustworthy Human-AI Collaborative Decision Making**|Min Hun Lee et.al.|[2405.16424v1](http://arxiv.org/abs/2405.16424v1)|null|
|**2024-05-26**|**Exploring Nutritional Impact on Alzheimer's Mortality: An Explainable AI Approach**|Ziming Liu et.al.|[2405.17502v1](http://arxiv.org/abs/2405.17502v1)|null|
|**2024-05-24**|**Explainable AI Enhances Glaucoma Referrals, Yet the Human-AI Team Still Falls Short of the AI Alone**|Catalina Gomez et.al.|[2407.11974v1](http://arxiv.org/abs/2407.11974v1)|null|
|**2024-05-23**|**Decoding Decision Reasoning: A Counterfactual-Powered Model for Knowledge Discovery**|Yingying Fang et.al.|[2406.18552v1](http://arxiv.org/abs/2406.18552v1)|null|
|**2024-05-21**|**The Role of Emotions in Informational Support Question-Response Pairs in Online Health Communities: A Multimodal Deep Learning Approach**|Mohsen Jozani et.al.|[2405.13099v1](http://arxiv.org/abs/2405.13099v1)|null|
|**2024-05-17**|**ChatGPT in Classrooms: Transforming Challenges into Opportunities in Education**|Harris Bin Munawar et.al.|[2405.10645v1](http://arxiv.org/abs/2405.10645v1)|null|
|**2024-05-13**|**Evaluating the Explainable AI Method Grad-CAM for Breath Classification on Newborn Time Series Data**|Camelia Oprea et.al.|[2405.07590v1](http://arxiv.org/abs/2405.07590v1)|null|
|**2024-05-10**|**XAI4LLM. Let Machine Learning Models and LLMs Collaborate for Enhanced In-Context Learning in Healthcare**|Fatemeh Nazary et.al.|[2405.06270v3](http://arxiv.org/abs/2405.06270v3)|null|
|**2024-05-09**|**To Trust or Not to Trust: Towards a novel approach to measure trust for XAI systems**|Miquel MirÃ³-Nicolau et.al.|[2405.05766v1](http://arxiv.org/abs/2405.05766v1)|null|
|**2024-05-05**|**Region-specific Risk Quantification for Interpretable Prognosis of COVID-19**|Zhusi Zhong et.al.|[2405.02815v1](http://arxiv.org/abs/2405.02815v1)|[link](https://github.com/zzs95/RSP_COVID)|
|**2024-04-26**|**Rad4XCNN: a new agnostic method for post-hoc global explanation of CNN-derived features by means of radiomics**|Francesco Prinzi et.al.|[2405.02334v1](http://arxiv.org/abs/2405.02334v1)|null|
|**2024-04-25**|**Attributing Responsibility in AI-Induced Incidents: A Computational Reflective Equilibrium Framework for Accountability**|Yunfei Ge et.al.|[2404.16957v1](http://arxiv.org/abs/2404.16957v1)|null|
|**2024-04-19**|**Explainable AI for Fair Sepsis Mortality Predictive Model**|Chia-Hsuan Chang et.al.|[2404.13139v1](http://arxiv.org/abs/2404.13139v1)|null|
|**2024-04-19**|**Multi Class Depression Detection Through Tweets using Artificial Intelligence**|Muhammad Osama Nusrat et.al.|[2404.13104v1](http://arxiv.org/abs/2404.13104v1)|[link](https://github.com/mnusrat786/masters-thesis)|
|**2024-04-19**|**COIN: Counterfactual inpainting for weakly supervised semantic segmentation for medical images**|Dmytro Shvetsov et.al.|[2404.12832v2](http://arxiv.org/abs/2404.12832v2)|[link](https://github.com/dmytro-shvetsov/counterfactual-search)|
|**2024-04-15**|**Hybrid Intelligence for Digital Humanities**|Victor de Boer et.al.|[2406.15374v1](http://arxiv.org/abs/2406.15374v1)|null|
|**2024-04-14**|**Ethical Framework for Responsible Foundational Models in Medical Imaging**|Abhijit Das et.al.|[2406.11868v1](http://arxiv.org/abs/2406.11868v1)|null|
|**2024-04-09**|**Advancements in Radiomics and Artificial Intelligence for Thyroid Cancer Diagnosis**|Milad Yousefi et.al.|[2404.07239v1](http://arxiv.org/abs/2404.07239v1)|null|
|**2024-04-06**|**Predictive Modeling for Breast Cancer Classification in the Context of Bangladeshi Patients: A Supervised Machine Learning Approach with Explainable AI**|Taminul Islam et.al.|[2404.04686v1](http://arxiv.org/abs/2404.04686v1)|null|
|**2024-04-05**|**Enhancing Breast Cancer Diagnosis in Mammography: Evaluation and Integration of Convolutional Neural Networks and Explainable AI**|Maryam Ahmed et.al.|[2404.03892v3](http://arxiv.org/abs/2404.03892v3)|null|
|**2024-03-26**|**Addressing Social Misattributions of Large Language Models: An HCXAI-based Approach**|Andrea Ferrario et.al.|[2403.17873v1](http://arxiv.org/abs/2403.17873v1)|null|
|**2024-03-26**|**Clinical Domain Knowledge-Derived Template Improves Post Hoc AI Explanations in Pneumothorax Classification**|Han Yuan et.al.|[2403.18871v1](http://arxiv.org/abs/2403.18871v1)|[link](https://github.com/han-yuan-med/template-explanation)|
|**2024-03-03**|**Enhancing Neural Machine Translation of Low-Resource Languages: Corpus Development, Human Evaluation and Explainable AI Architectures**|SÃ©amus Lankford et.al.|[2403.01580v1](http://arxiv.org/abs/2403.01580v1)|null|
|**2024-02-28**|**Artificial Intelligence and Diabetes Mellitus: An Inside Look Through the Retina**|Yasin Sadeghi Bazargani et.al.|[2402.18600v1](http://arxiv.org/abs/2402.18600v1)|null|
|**2024-02-22**|**Multi-stakeholder Perspective on Responsible Artificial Intelligence and Acceptability in Education**|A. J. Karran et.al.|[2402.15027v2](http://arxiv.org/abs/2402.15027v2)|null|
|**2024-02-12**|**Deciphering Heartbeat Signatures: A Vision Transformer Approach to Explainable Atrial Fibrillation Detection from ECG Signals**|Aruna Mohan et.al.|[2402.09474v2](http://arxiv.org/abs/2402.09474v2)|null|
|**2024-02-05**|**Illuminate: A novel approach for depression detection with explainable analysis and proactive therapy using prompt engineering**|Aryan Agrawal et.al.|[2402.05127v1](http://arxiv.org/abs/2402.05127v1)|null|
|**2024-01-24**|**Information That Matters: Exploring Information Needs of People Affected by Algorithmic Decisions**|TimothÃ©e Schmude et.al.|[2401.13324v4](http://arxiv.org/abs/2401.13324v4)|null|
|**2024-01-02**|**Evaluating Large Language Models on the GMAT: Implications for the Future of Business Education**|Vahid Ashrafimoghari et.al.|[2401.02985v1](http://arxiv.org/abs/2401.02985v1)|null|
|**2023-12-29**|**XAI for In-hospital Mortality Prediction via Multimodal ICU Data**|Xingqiao Li et.al.|[2312.17624v1](http://arxiv.org/abs/2312.17624v1)|[link](https://github.com/lixingqiao/xai-icu)|
|**2023-12-22**|**Joining Forces for Pathology Diagnostics with AI Assistance: The EMPAIA Initiative**|Norman Zerbe et.al.|[2401.09450v2](http://arxiv.org/abs/2401.09450v2)|null|
|**2023-12-18**|**Robust Stochastic Graph Generator for Counterfactual Explanations**|Mario Alfonso Prado-Romero et.al.|[2312.11747v2](http://arxiv.org/abs/2312.11747v2)|null|
|**2023-12-10**|**Evaluating the Utility of Model Explanations for Model Development**|Shawn Im et.al.|[2312.06032v1](http://arxiv.org/abs/2312.06032v1)|null|
|**2023-12-05**|**Building Trustworthy NeuroSymbolic AI Systems: Consistency, Reliability, Explainability, and Safety**|Manas Gaur et.al.|[2312.06798v1](http://arxiv.org/abs/2312.06798v1)|null|
|**2023-11-28**|**Deployment of a Robust and Explainable Mortality Prediction Model: The COVID-19 Pandemic and Beyond**|Jacob R. Epifano et.al.|[2311.17133v1](http://arxiv.org/abs/2311.17133v1)|null|
|**2023-11-27**|**Variational Autoencoders for Feature Exploration and Malignancy Prediction of Lung Lesions**|Benjamin Keel et.al.|[2311.15719v1](http://arxiv.org/abs/2311.15719v1)|[link](https://github.com/benkeel/vae_lung_lesion_bmvc)|
|**2023-11-24**|**MRxaI: Black-Box Explainability for Image Classifiers in a Medical Setting**|Nathan Blake et.al.|[2311.14471v1](http://arxiv.org/abs/2311.14471v1)|null|
|**2023-11-21**|**Moderating Model Marketplaces: Platform Governance Puzzles for AI Intermediaries**|Robert Gorwa et.al.|[2311.12573v2](http://arxiv.org/abs/2311.12573v2)|null|
|**2023-11-20**|**Ovarian Cancer Data Analysis using Deep Learning: A Systematic Review from the Perspectives of Key Features of Data Analysis and AI Assurance**|Muta Tah Hira et.al.|[2311.11932v1](http://arxiv.org/abs/2311.11932v1)|null|
|**2023-11-18**|**Representing visual classification as a linear combination of words**|Shobhit Agarwal et.al.|[2311.10933v1](http://arxiv.org/abs/2311.10933v1)|[link](https://github.com/lotterlab/task_word_explainability)|
|**2023-11-03**|**Towards objective and systematic evaluation of bias in artificial intelligence for medical imaging**|Emma A. M. Stanley et.al.|[2311.02115v2](http://arxiv.org/abs/2311.02115v2)|[link](https://github.com/estanley16/simba)|
|**2023-10-29**|**Predicting recovery following stroke: deep learning, multimodal data and feature selection using explainable AI**|Adam White et.al.|[2310.19174v1](http://arxiv.org/abs/2310.19174v1)|null|
|**2023-10-03**|**Trainable Noise Model as an XAI evaluation method: application on Sobol for remote sensing image segmentation**|Hossein Shreim et.al.|[2310.01828v2](http://arxiv.org/abs/2310.01828v2)|[link](https://github.com/geoaigroup/geoai-ecrs2023)|
|**2023-09-26**|**Creating Trustworthy LLMs: Dealing with Hallucinations in Healthcare AI**|Muhammad Aurangzeb Ahmad et.al.|[2311.01463v1](http://arxiv.org/abs/2311.01463v1)|null|
|**2023-09-20**|**When to Trust AI: Advances and Challenges for Certification of Neural Networks**|Marta Kwiatkowska et.al.|[2309.11196v1](http://arxiv.org/abs/2309.11196v1)|null|
|**2023-09-19**|**Functional requirements to mitigate the Risk of Harm to Patients from Artificial Intelligence in Healthcare**|Juan M. GarcÃ­a-GÃ³mez et.al.|[2309.10424v1](http://arxiv.org/abs/2309.10424v1)|null|
|**2023-09-19**|**QXAI: Explainable AI Framework for Quantitative Analysis in Patient Monitoring Systems**|Thanveer Shaik et.al.|[2309.10293v3](http://arxiv.org/abs/2309.10293v3)|null|
|**2023-09-18**|**Evaluation of Human-Understandability of Global Model Explanations using Decision Tree**|Adarsa Sivaprasad et.al.|[2309.09917v1](http://arxiv.org/abs/2309.09917v1)|null|
|**2023-08-28**|**Leveraging A Medical Knowledge Graph into Large Language Models for Diagnosis Prediction**|Yanjun Gao et.al.|[2308.14321v1](http://arxiv.org/abs/2308.14321v1)|null|
|**2023-08-18**|**Deciphering knee osteoarthritis diagnostic features with explainable artificial intelligence: A systematic review**|Yun Xin Teoh et.al.|[2308.09380v1](http://arxiv.org/abs/2308.09380v1)|null|
|**2023-08-16**|**Explainable AI for clinical risk prediction: a survey of concepts, methods, and modalities**|Munib Mesinovic et.al.|[2308.08407v1](http://arxiv.org/abs/2308.08407v1)|null|
|**2023-08-11**|**FUTURE-AI: International consensus guideline for trustworthy and deployable artificial intelligence in healthcare**|Karim Lekadir et.al.|[2309.12325v3](http://arxiv.org/abs/2309.12325v3)|null|
|**2023-08-10**|**Explainable AI applications in the Medical Domain: a systematic review**|Nicoletta Prentzas et.al.|[2308.05411v1](http://arxiv.org/abs/2308.05411v1)|null|
|**2023-08-01**|**Exploring the Role of Explainability in AI-Assisted Embryo Selection**|Lucia Urcelay et.al.|[2308.02534v1](http://arxiv.org/abs/2308.02534v1)|null|
|**2023-07-26**|**A New Perspective on Evaluation Methods for Explainable Artificial Intelligence (XAI)**|Timo Speith et.al.|[2307.14246v1](http://arxiv.org/abs/2307.14246v1)|null|
|**2023-07-26**|**Revisiting the Performance-Explainability Trade-Off in Explainable Artificial Intelligence (XAI)**|Barnaby Crook et.al.|[2307.14239v1](http://arxiv.org/abs/2307.14239v1)|null|
|**2023-07-26**|**Acceptable risks in Europe's proposed AI Act: Reasonableness and other principles for deciding how much risk management is enough**|Henry Fraser et.al.|[2308.02047v1](http://arxiv.org/abs/2308.02047v1)|null|
|**2023-07-21**|**eXplainable Artificial Intelligence (XAI) in aging clock models**|Alena Kalyakulina et.al.|[2307.13704v3](http://arxiv.org/abs/2307.13704v3)|null|
|**2023-07-19**|**Interpreting and Correcting Medical Image Classification with PIP-Net**|Meike Nauta et.al.|[2307.10404v2](http://arxiv.org/abs/2307.10404v2)|[link](https://github.com/m-nauta/pipnet)|
|**2023-07-15**|**Explaining and visualizing black-box models through counterfactual paths**|Bastian Pfeifer et.al.|[2307.07764v3](http://arxiv.org/abs/2307.07764v3)|[link](https://github.com/pievos101/cpath)|
|**2023-07-05**|**Beyond Known Reality: Exploiting Counterfactual Explanations for Medical Research**|Toygar Tanyel et.al.|[2307.02131v5](http://arxiv.org/abs/2307.02131v5)|[link](https://github.com/toygarr/counterfactual-explanations-for-medical-research)|
|**2023-06-30**|**AI and Non AI Assessments for Dementia**|Mahboobeh Parsapoor et.al.|[2307.01210v1](http://arxiv.org/abs/2307.01210v1)|null|
|**2023-06-12**|**Active Globally Explainable Learning for Medical Images via Class Association Embedding and Cyclic Adversarial Generation**|Ruitao Xie et.al.|[2306.07306v1](http://arxiv.org/abs/2306.07306v1)|null|
|**2023-06-09**|**HiTZ@Antidote: Argumentation-driven Explainable Artificial Intelligence for Digital Medicine**|Rodrigo Agerri et.al.|[2306.06029v1](http://arxiv.org/abs/2306.06029v1)|null|
|**2023-06-07**|**XInsight: Revealing Model Insights for GNNs with Flow-based Explanations**|Eli Laird et.al.|[2306.04791v1](http://arxiv.org/abs/2306.04791v1)|null|
|**2023-06-06**|**Explainable AI using expressive Boolean formulas**|Gili Rosenberg et.al.|[2306.03976v1](http://arxiv.org/abs/2306.03976v1)|null|
|**2023-06-06**|**Utterance Classification with Logical Neural Network: Explainable AI for Mental Disorder Diagnosis**|Yeldar Toleubay et.al.|[2306.03902v1](http://arxiv.org/abs/2306.03902v1)|null|
|**2023-06-02**|**XAI Renaissance: Redefining Interpretability in Medical Diagnostic Models**|Sujith K Mandala et.al.|[2306.01668v1](http://arxiv.org/abs/2306.01668v1)|null|
|**2023-05-26**|**A Novel real-time arrhythmia detection model using YOLOv8**|Guang Jun Nicholas Ang et.al.|[2305.16727v3](http://arxiv.org/abs/2305.16727v3)|null|
|**2023-05-22**|**Breast Cancer Segmentation using Attention-based Convolutional Network and Explainable AI**|Jai Vardhan et.al.|[2305.14389v2](http://arxiv.org/abs/2305.14389v2)|null|
|**2023-05-18**|**What Symptoms and How Long? An Interpretable AI Approach for Depression Detection in Social Media**|Junwei Kuang et.al.|[2305.13127v2](http://arxiv.org/abs/2305.13127v2)|null|
|**2023-05-17**|**Echoes of Biases: How Stigmatizing Language Affects AI Performance**|Yizhi Liu et.al.|[2305.10201v4](http://arxiv.org/abs/2305.10201v4)|null|
|**2023-05-05**|**Explaining the ghosts: Feminist intersectional XAI and cartography as methods to account for invisible labour**|Goda Klumbyte et.al.|[2305.03376v1](http://arxiv.org/abs/2305.03376v1)|null|
|**2023-04-25**|**Towards Explainable and Safe Conversational Agents for Mental Health: A Survey**|Surjodeep Sarkar et.al.|[2304.13191v1](http://arxiv.org/abs/2304.13191v1)|null|
|**2023-04-04**|**A Brief Review of Explainable Artificial Intelligence in Healthcare**|Zahra Sadeghi et.al.|[2304.01543v1](http://arxiv.org/abs/2304.01543v1)|null|
|**2023-03-22**|**Reveal to Revise: An Explainable AI Life Cycle for Iterative Bias Correction of Deep Models**|Frederik Pahde et.al.|[2303.12641v2](http://arxiv.org/abs/2303.12641v2)|[link](https://github.com/maxdreyer/reveal2revise)|
|**2023-03-11**|**Explainable AI for Time Series via Virtual Inspection Layers**|Johanna Vielhaben et.al.|[2303.06365v1](http://arxiv.org/abs/2303.06365v1)|null|
|**2023-03-08**|**Towards Trust of Explainable AI in Thyroid Nodule Diagnosis**|Truong Thanh Hung Nguyen et.al.|[2303.04731v1](http://arxiv.org/abs/2303.04731v1)|[link](https://github.com/hungntt/xai_thyroid)|
|**2023-03-06**|**Cybersecurity of AI medical devices: risks, legislation, and challenges**|Elisabetta Biasin et.al.|[2303.03140v1](http://arxiv.org/abs/2303.03140v1)|null|
|**2023-02-06**|**LAVA: Granular Neuron-Level Explainable AI for Alzheimer's Disease Assessment from Fundus Images**|Nooshin Yousefzadeh et.al.|[2302.03008v2](http://arxiv.org/abs/2302.03008v2)|null|

#### Abstracts
##### **Enhanced Deep Learning Methodologies and MRI Selection Techniques for Dementia Diagnosis in the Elderly Population**
2407.17324v2 by Nikolaos Ntampakis, Konstantinos Diamantaras, Ioanna Chouvarda, Vasileios Argyriou, Panagiotis Sarigianndis

Dementia, a debilitating neurological condition affecting millions worldwide,
presents significant diagnostic challenges. In this work, we introduce a novel
methodology for the classification of demented and non-demented elderly
patients using 3D brain Magnetic Resonance Imaging (MRI) scans. Our approach
features a unique technique for selectively processing MRI slices, focusing on
the most relevant brain regions and excluding less informative sections. This
methodology is complemented by a confidence-based classification committee
composed of three custom deep learning models: Dem3D ResNet, Dem3D CNN, and
Dem3D EfficientNet. These models work synergistically to enhance
decision-making accuracy, leveraging their collective strengths. Tested on the
Open Access Series of Imaging Studies(OASIS) dataset, our method achieved an
impressive accuracy of 94.12%, surpassing existing methodologies. Furthermore,
validation on the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset
confirmed the robustness and generalizability of our approach. The use of
explainable AI (XAI) techniques and comprehensive ablation studies further
substantiate the effectiveness of our techniques, providing insights into the
decision-making process and the importance of our methodology. This research
offers a significant advancement in dementia diagnosis, providing a highly
accurate and efficient tool for clinical applications.

æè¦ï¼å¤±æºçæ¯ä¸ç¨®å½±é¿å¨çæ¸ç¾è¬äººçè¡°å¼±æ§ç¥ç¶ç¾çï¼å¨è¨ºæ·ä¸å·æéå¤§ææ°ãå¨éé å·¥ä½ä¸­ï¼æåæåºäºä¸ç¨®æ°çæ¹æ³ï¼ç¨æ¼å°å¤±æºåéå¤±æºèå¹´æ£èé²è¡åé¡ï¼ä½¿ç¨ 3D å¤§è¦ç£æ¯é å½± (MRI) ææãæåçåæ³æ¡ç¨äºä¸ç¨®ç¨ç¹æè¡ï¼ç¨æ¼é¸ææ§èç MRI åçï¼éé»éæ³¨æç¸éçå¤§è¦ååï¼ä¸¦æé¤ä¿¡æ¯éè¼å°çé¨åãéç¨®æ¹æ³ç±ä¸ååºæ¼ä¿¡å¿çåé¡å§å¡æè£åï¼è©²å§å¡æç±ä¸åèªå®ç¾©æ·±åº¦å­¸ç¿æ¨¡åçµæï¼Dem3D ResNetãDem3D CNN å Dem3D EfficientNetãéäºæ¨¡åååå·¥ä½ä»¥å¢å¼·æ±ºç­çæºç¢ºæ§ï¼å©ç¨å®åçéé«åªå¢ãå¨å½±åç ç©¶éæ¾å­åç³»å (OASIS) è³æéä¸é²è¡æ¸¬è©¦ï¼æåçæ¨¡åéå°äº 94.12% çé©äººæºç¢ºåº¦ï¼è¶éäºç¾ææ¹æ³ãæ­¤å¤ï¼å¨é¿è²æµ·é»çç¥ç¶å½±åå¡è­° (ADNI) è³æéä¸çé©è­è­å¯¦äºæåæ¹æ³çç©©å¥æ§åæ®éæ§ãå¯è§£é AI (XAI) æè¡åå¨é¢çæ¶èç ç©¶é²ä¸æ­¥è­å¯¦äºæåæè¡çæææ§ï¼æä¾äºå°æ±ºç­éç¨åæåæ¹æ³éè¦æ§çè¦è§£ãéé ç ç©¶çºå¤±æºçè¨ºæ·æä¾äºéå¤§é²å±ï¼çºè¨åºæç¨æä¾äºä¸åé«åº¦æºç¢ºä¸é«æçå·¥å·ã

##### **A Comparative Study on Automatic Coding of Medical Letters with Explainability**
2407.13638v1 by Jamie Glen, Lifeng Han, Paul Rayson, Goran Nenadic

This study aims to explore the implementation of Natural Language Processing
(NLP) and machine learning (ML) techniques to automate the coding of medical
letters with visualised explainability and light-weighted local computer
settings. Currently in clinical settings, coding is a manual process that
involves assigning codes to each condition, procedure, and medication in a
patient's paperwork (e.g., 56265001 heart disease using SNOMED CT code). There
are preliminary research on automatic coding in this field using
state-of-the-art ML models; however, due to the complexity and size of the
models, the real-world deployment is not achieved. To further facilitate the
possibility of automatic coding practice, we explore some solutions in a local
computer setting; in addition, we explore the function of explainability for
transparency of AI models. We used the publicly available MIMIC-III database
and the HAN/HLAN network models for ICD code prediction purposes. We also
experimented with the mapping between ICD and SNOMED CT knowledge bases. In our
experiments, the models provided useful information for 97.98\% of codes. The
result of this investigation can shed some light on implementing automatic
clinical coding in practice, such as in hospital settings, on the local
computers used by clinicians , project page
\url{https://github.com/Glenj01/Medical-Coding}.

æè¦ï¼æ¬ç ç©¶æ¨å¨æ¢è¨å°èªç¶èªè¨èç (NLP) åæ©å¨å­¸ç¿ (ML) æè¡å¯¦ä½æ¼é«çä¿¡å½ç·¨ç¢¼èªååï¼ä¸¦å·åè¦è¦ºåèªªæè½ååè¼éåçæ¬å°é»è¦è¨­å®ãç®åå¨è¨åºç°å¢ä¸­ï¼ç·¨ç¢¼æ¯ä¸ç¨®æåæµç¨ï¼æ¶åçºçæ£æä»¶ä¸­çæ¯é ççãç¨åºåè¥ç©ææ´¾ä»£ç¢¼ (ä¾å¦ï¼ä½¿ç¨ SNOMED CT ä»£ç¢¼ 56265001 è¡¨ç¤ºå¿èç)ãæ­¤é åæä½¿ç¨ææ° ML æ¨¡åé²è¡èªåç·¨ç¢¼çåæ­¥ç ç©¶ï¼ç¶èï¼ç±æ¼æ¨¡åçè¤éæ§åå¤§å°ï¼ä¸¦æªå¯¦ç¾å¯¦éé¨ç½²ãçºäºé²ä¸æ­¥ä¿é²èªåç·¨ç¢¼å¯¦åçå¯è½æ§ï¼æåå¨æ¬å°é»è¦è¨­å®ä¸­æ¢è¨äºä¸äºè§£æ±ºæ¹æ¡ï¼æ­¤å¤ï¼æåæ¢è¨äºèªªæåè½å¨ AI æ¨¡åéæåº¦ä¸­çåè½ãæåä½¿ç¨å¬éç MIMIC-III è³æåº«å HAN/HLAN ç¶²è·¯æ¨¡åé²è¡ ICD ä»£ç¢¼é æ¸¬ãæåéè©¦é©äº ICD å SNOMED CT ç¥è­åº«ä¹éçå°æãå¨æåçå¯¦é©ä¸­ï¼éäºæ¨¡åæä¾äº 97.98% ä»£ç¢¼çæç¨è³è¨ãéé èª¿æ¥çµæå¯ä»¥çºå¯¦åä¸­çèªåè¨åºç·¨ç¢¼å¯¦ä½æä¾ä¸äºè¦è§£ï¼ä¾å¦å¨é«é¢ç°å¢ä¸­ï¼ç±è¨åºé«çä½¿ç¨çæ¬å°é»è¦ï¼å°æ¡é é¢ \url{https://github.com/Glenj01/Medical-Coding}ã

##### **Explainable AI for Enhancing Efficiency of DL-based Channel Estimation**
2407.07009v1 by Abdul Karim Gizzini, Yahia Medjahdi, Ali J. Ghandour, Laurent Clavier

The support of artificial intelligence (AI) based decision-making is a key
element in future 6G networks, where the concept of native AI will be
introduced. Moreover, AI is widely employed in different critical applications
such as autonomous driving and medical diagnosis. In such applications, using
AI as black-box models is risky and challenging. Hence, it is crucial to
understand and trust the decisions taken by these models. Tackling this issue
can be achieved by developing explainable AI (XAI) schemes that aim to explain
the logic behind the black-box model behavior, and thus, ensure its efficient
and safe deployment. Recently, we proposed a novel perturbation-based XAI-CHEST
framework that is oriented toward channel estimation in wireless
communications. The core idea of the XAI-CHEST framework is to identify the
relevant model inputs by inducing high noise on the irrelevant ones. This
manuscript provides the detailed theoretical foundations of the XAI-CHEST
framework. In particular, we derive the analytical expressions of the XAI-CHEST
loss functions and the noise threshold fine-tuning optimization problem. Hence
the designed XAI-CHEST delivers a smart input feature selection methodology
that can further improve the overall performance while optimizing the
architecture of the employed model. Simulation results show that the XAI-CHEST
framework provides valid interpretations, where it offers an improved bit error
rate performance while reducing the required computational complexity in
comparison to the classical DL-based channel estimation.

æè¦ï¼äººå·¥æºè½ (AI) æ¯æçæ±ºç­å¶å®æ¯æªä¾ 6G ç¶²è·¯ä¸­çééµåç´ ï¼å¶ä¸­å°å¼å¥åç AI çæ¦å¿µãæ­¤å¤ï¼AI å»£æ³ç¨æ¼ä¸åçééµæç¨ä¸­ï¼ä¾å¦èªåé§é§åé«çè¨ºæ·ãå¨éäºæç¨ä¸­ï¼ä½¿ç¨ AI ä½çºé»çæ¨¡åæ¯æé¢¨éªä¸å·æææ°æ§çãå æ­¤ï¼çè§£åä¿¡ä»»éäºæ¨¡åååºçæ±ºç­è³ééè¦ãè§£æ±ºæ­¤åé¡çæ¹æ³æ¯éç¼å¯è§£é AI (XAI) æ¶æ§ï¼æ¨å¨è§£éé»çæ¨¡åè¡çºèå¾çéè¼¯ï¼å¾èç¢ºä¿å¶ææä¸å®å¨çé¨ç½²ãæè¿ï¼æåæåºäºä¸åæ°çåºæ¼æ¾åç XAI-CHEST æ¡æ¶ï¼è©²æ¡æ¶é¢åç¡ç·éä¿¡ä¸­çä¿¡éä¼°è¨ãXAI-CHEST æ¡æ¶çæ ¸å¿ææ³æ¯ééå¨ç¡éè¼¸å¥ä¸å¼å¥é«åªè²ä¾è­å¥ç¸éæ¨¡åè¼¸å¥ãéä»½æç¨¿æä¾äº XAI-CHEST æ¡æ¶çè©³ç´°çè«åºç¤ãç¹å¥æ¯ï¼æåæ¨å°äº XAI-CHEST æå¤±å½æ¸ååªè²é¾å¼å¾®èª¿åªååé¡çè§£æè¡¨éå¼ãå æ­¤ï¼è¨­è¨ç XAI-CHEST æä¾äºä¸ç¨®æºè½è¼¸å¥ç¹å¾µé¸ææ¹æ³ï¼å¯ä»¥å¨åªåæç¨æ¨¡åçæ¶æ§çåæé²ä¸æ­¥æé«æ´é«æ§è½ãæ¨¡æ¬çµæè¡¨æï¼XAI-CHEST æ¡æ¶æä¾äºææçè§£éï¼å¨éä½æéçè¨ç®è¤éåº¦çåæï¼æä¾äºæ¹é²çæ¯ç¹é¯èª¤çæ§è½ï¼èéèåºæ¼å³çµ± DL çä¿¡éä¼°è¨ç¸æ¯ã

##### **Explainable AI: Comparative Analysis of Normal and Dilated ResNet Models for Fundus Disease Classification**
2407.05440v1 by P. N. Karthikayan, Yoga Sri Varshan V, Hitesh Gupta Kattamuri, Umarani Jayaraman

This paper presents dilated Residual Network (ResNet) models for disease
classification from retinal fundus images. Dilated convolution filters are used
to replace normal convolution filters in the higher layers of the ResNet model
(dilated ResNet) in order to improve the receptive field compared to the normal
ResNet model for disease classification. This study introduces
computer-assisted diagnostic tools that employ deep learning, enhanced with
explainable AI techniques. These techniques aim to make the tool's
decision-making process transparent, thereby enabling medical professionals to
understand and trust the AI's diagnostic decision. They are particularly
relevant in today's healthcare landscape, where there is a growing demand for
transparency in AI applications to ensure their reliability and ethical use.
The dilated ResNet is used as a replacement for the normal ResNet to enhance
the classification accuracy of retinal eye diseases and reduce the required
computing time. The dataset used in this work is the Ocular Disease Intelligent
Recognition (ODIR) dataset which is a structured ophthalmic database with eight
classes covering most of the common retinal eye diseases. The evaluation
metrics used in this work include precision, recall, accuracy, and F1 score. In
this work, a comparative study has been made between normal ResNet models and
dilated ResNet models on five variants namely ResNet-18, ResNet-34, ResNet-50,
ResNet-101, and ResNet-152. The dilated ResNet model shows promising results as
compared to normal ResNet with an average F1 score of 0.71, 0.70, 0.69, 0.67,
and 0.70 respectively for the above respective variants in ODIR multiclass
disease classification.

æè¦ï¼<paragraph>æ¬ææåºäºç¨äºè§ç½èç¼åºå¾åç¾çåç±»çæ©å¼ æ®å·®ç½ç» (ResNet) æ¨¡åãæ©å¼ å·ç§¯æ»¤æ³¢å¨ç¨äºæ¿æ¢ ResNet æ¨¡åè¾é«å±ä¸­çæ­£å¸¸å·ç§¯æ»¤æ³¢å¨ï¼æ©å¼  ResNetï¼ï¼ä»¥æ¹åä¸ç¨äºç¾çåç±»çæ­£å¸¸ ResNet æ¨¡åç¸æ¯çæåéãæ¬ç ç©¶ä»ç»äºéç¨æ·±åº¦å­¦ä¹ çè®¡ç®æºè¾å©è¯æ­å·¥å·ï¼å¹¶éè¿å¯è§£éç AI ææ¯è¿è¡äºå¢å¼ºãè¿äºææ¯æ¨å¨ä½¿è¯¥å·¥å·çå³ç­è¿ç¨éæåï¼ä»èä½¿å»çä¸ä¸äººåè½å¤çè§£åä¿¡ä»» AI çè¯æ­å³ç­ãå®ä»¬å¨å½ä»å»çä¿å¥é¢åå°¤ä¸ºéè¦ï¼å ä¸ºå¯¹ AI åºç¨ç¨åºçéæåº¦éæ±ä¸æ­å¢é¿ï¼ä»¥ç¡®ä¿å¶å¯é æ§åéå¾·ä½¿ç¨ãæ©å¼  ResNet ç¨ä½æ­£å¸¸ ResNet çæ¿ä»£åï¼ä»¥æé«è§ç½èç¼ççåç±»åç¡®æ§å¹¶åå°æéçè®¡ç®æ¶é´ãæ¬å·¥ä½ä¸­ä½¿ç¨çæ°æ®éæ¯ Ocular Disease Intelligent Recognition (ODIR) æ°æ®éï¼è¿æ¯ä¸ä¸ªç»æåçç¼ç§æ°æ®åºï¼åå«å«ç±»æ¶µçå¤§å¤æ°å¸¸è§è§ç½èç¼çãæ¬å·¥ä½ä¸­ä½¿ç¨çè¯ä¼°ææ åæ¬ç²¾ç¡®åº¦ãå¬åçãåç¡®åº¦å F1 åæ°ãå¨è¿é¡¹å·¥ä½ä¸­ï¼å¯¹æ­£å¸¸ ResNet æ¨¡ååæ©å¼  ResNet æ¨¡åå¨äºä¸ªåä½ï¼å³ ResNet-18ãResNet-34ãResNet-50ãResNet-101 å ResNet-152ï¼ä¹é´è¿è¡äºæ¯è¾ç ç©¶ãä¸æ­£å¸¸ ResNet ç¸æ¯ï¼æ©å¼  ResNet æ¨¡åæ¾ç¤ºåºæå¸æçç»æï¼å¨ ODIR å¤ç±»ç¾çåç±»ä¸­ï¼ä¸è¿°åä¸ªåä½çå¹³å F1 åæ°åå«ä¸º 0.71ã0.70ã0.69ã0.67 å 0.70ã</paragraph>

##### **A Survey on Trustworthiness in Foundation Models for Medical Image Analysis**
2407.15851v1 by Congzhen Shi, Ryan Rezai, Jiaxi Yang, Qi Dou, Xiaoxiao Li

The rapid advancement of foundation models in medical imaging represents a
significant leap toward enhancing diagnostic accuracy and personalized
treatment. However, the deployment of foundation models in healthcare
necessitates a rigorous examination of their trustworthiness, encompassing
privacy, robustness, reliability, explainability, and fairness. The current
body of survey literature on foundation models in medical imaging reveals
considerable gaps, particularly in the area of trustworthiness. Additionally,
extant surveys on the trustworthiness of foundation models fail to address
their specific variations and applications within the medical imaging domain.
This survey paper reviews the current research on foundation models in the
major medical imaging applications, with a focus on segmentation, medical
report generation, medical question and answering (Q&A), and disease diagnosis,
which includes trustworthiness discussion in their manuscripts. We explore the
complex challenges of making foundation models for medical image analysis
trustworthy, associated with each application, and summarize the current
concerns and strategies to enhance trustworthiness. Furthermore, we explore the
future promises of these models in revolutionizing patient care. Our analysis
underscores the imperative for advancing towards trustworthy AI in medical
image analysis, advocating for a balanced approach that fosters innovation
while ensuring ethical and equitable healthcare delivery.

æè¦ï¼åºç¤æ¨¡åå¨é«å­¸å½±åä¸çå¿«éé²å±ä»£è¡¨èå¨å¢å¼·è¨ºæ·æºç¢ºåº¦ååäººåæ²»çæ¹é¢éåºäºä¸å¤§æ­¥ãç¶èï¼åºç¤æ¨¡åå¨é«çä¿å¥ä¸­çé¨ç½²éè¦å´æ ¼æª¢æ¥å¶å¯ä¿¡åº¦ï¼åæ¬é±ç§ãç©©å¥æ§ãå¯é æ§ãå¯è§£éæ§åå¬å¹³æ§ãç¶åéæ¼é«å­¸å½±åä¸­åºç¤æ¨¡åçèª¿æ¥æç»é¡¯ç¤ºåºç¸ç¶å¤§çå·®è·ï¼ç¹å¥æ¯å¨å¯ä¿¡åº¦æ¹é¢ãæ­¤å¤ï¼ç¾æçéæ¼åºç¤æ¨¡åå¯ä¿¡åº¦çèª¿æ¥æªè½è§£æ±ºå¶å¨é«å­¸å½±åé åå§çå·é«è®ååæç¨ãéç¯èª¿æ¥è«æåé¡§äºç¶åéæ¼åºç¤æ¨¡åå¨ä¸»è¦é«å­¸å½±åæç¨ä¸­çç ç©¶ï¼éé»éæ³¨åå²ãé«çå ±åçæãé«çåé¡åè§£ç­ (Q&A) ä»¥åç¾çè¨ºæ·ï¼å¶ä¸­åæ¬æç¨¿ä¸­çå¯ä¿¡åº¦è¨è«ãæåæ¢è¨äºè®ç¨æ¼é«å­¸å½±ååæçåºç¤æ¨¡åå¼å¾ä¿¡è³´çè¤éææ°ï¼èæ¯åæç¨ç¸éï¼ä¸¦ç¸½çµäºç¶åæé«å¯ä¿¡åº¦çåé¡åç­ç¥ãæ­¤å¤ï¼æåæ¢è¨äºéäºæ¨¡åå¨é©æ°æ£èç§è­·æ¹é¢çæªä¾åæ¯ãæåçåæå¼·èª¿äºå¨é«å­¸å½±ååæä¸­æèå¯ä¿¡è³´çäººå·¥æºæ§éé²çå¿è¦æ§ï¼æå¡ä¸ç¨®å¹³è¡¡çæ¹æ³ï¼æ¢è½ä¿é²åµæ°ï¼åè½ç¢ºä¿éå¾·åå¬å¹³çé«çä¿å¥æåã

##### **The Impact of an XAI-Augmented Approach on Binary Classification with Scarce Data**
2407.06206v1 by Ximing Wen, Rosina O. Weber, Anik Sen, Darryl Hannan, Steven C. Nesbit, Vincent Chan, Alberto Goffi, Michael Morris, John C. Hunninghake, Nicholas E. Villalobos, Edward Kim, Christopher J. MacLellan

Point-of-Care Ultrasound (POCUS) is the practice of clinicians conducting and
interpreting ultrasound scans right at the patient's bedside. However, the
expertise needed to interpret these images is considerable and may not always
be present in emergency situations. This reality makes algorithms such as
machine learning classifiers extremely valuable to augment human decisions.
POCUS devices are becoming available at a reasonable cost in the size of a
mobile phone. The challenge of turning POCUS devices into life-saving tools is
that interpretation of ultrasound images requires specialist training and
experience. Unfortunately, the difficulty to obtain positive training images
represents an important obstacle to building efficient and accurate
classifiers. Hence, the problem we try to investigate is how to explore
strategies to increase accuracy of classifiers trained with scarce data. We
hypothesize that training with a few data instances may not suffice for
classifiers to generalize causing them to overfit. Our approach uses an
Explainable AI-Augmented approach to help the algorithm learn more from less
and potentially help the classifier better generalize.

æè¦ï¼åºéè¶é³æ³¢ (POCUS) æ¯è¨åºé«å¸«å¨æ£èåºéé²è¡åè§£è®è¶é³æ³¢ææçå¯¦åãç¶èï¼è§£è®éäºå½±åæéçå°æ¥­ç¥è­ç¸ç¶å¯è§ï¼èä¸å¨ç·æ¥ææ³ä¸å¯è½ä¸¦éé¨æå·åãéç¨®ç¾å¯¦ææ³ä½¿å¾æ©å¨å­¸ç¿åé¡å¨ç­æ¼ç®æ³å°æ¼å å¼·äººé¡æ±ºç­è®å¾æ¥µçºæå¹å¼ãPOCUS è£ç½®æ­£ä»¥åçææ¬æ¨åºï¼å°ºå¯¸çºææ©å¤§å°ãå° POCUS è£ç½®è½è®çºæçå·¥å·çææ°å¨æ¼ï¼è§£è®è¶é³æ³¢å½±åéè¦å°éè¨ç·´åç¶é©ãä¸å¹¸çæ¯ï¼åå¾æ­£åè¨ç·´å½±åçå°é£åº¦ä»£è¡¨èå»ºç½®ææçä¸æºç¢ºçåé¡å¨çä¸å¤§éç¤ãå æ­¤ï¼æååè©¦æ¢è¨çåé¡æ¯å¦ä½æ¢ç´¢ç­ç¥ï¼ä»¥æé«ä½¿ç¨ç¨çè³æè¨ç·´çåé¡å¨çæºç¢ºåº¦ãæååè¨­ä½¿ç¨å°æ¸è³æå¯¦ä¾é²è¡è¨ç·´å¯è½ä¸è¶³ä»¥è®åé¡å¨æ¦æ¬ï¼å°è´å®åéåº¦æ¬åãæåçåæ³ä½¿ç¨å¯è§£é AI å¢å¼·æ¹æ³ï¼ä»¥åå©æ¼ç®æ³å¾è¼å°çè³æä¸­å­¸ç¿æ´å¤ï¼ä¸¦æ½å¨åå©åé¡å¨æ´å¥½å°æ¦æ¬ã

##### **Can GPT-4 Help Detect Quit Vaping Intentions? An Exploration of Automatic Data Annotation Approach**
2407.00167v1 by Sai Krishna Revanth Vuruma, Dezhi Wu, Saborny Sen Gupta, Lucas Aust, Valerie Lookingbill, Wyatt Bellamy, Yang Ren, Erin Kasson, Li-Shiun Chen, Patricia Cavazos-Rehg, Dian Hu, Ming Huang

In recent years, the United States has witnessed a significant surge in the
popularity of vaping or e-cigarette use, leading to a notable rise in cases of
e-cigarette and vaping use-associated lung injury (EVALI) that caused
hospitalizations and fatalities during the EVALI outbreak in 2019, highlighting
the urgency to comprehend vaping behaviors and develop effective strategies for
cessation. Due to the ubiquity of social media platforms, over 4.7 billion
users worldwide use them for connectivity, communications, news, and
entertainment with a significant portion of the discourse related to health,
thereby establishing social media data as an invaluable organic data resource
for public health research. In this study, we extracted a sample dataset from
one vaping sub-community on Reddit to analyze users' quit-vaping intentions.
Leveraging OpenAI's latest large language model GPT-4 for sentence-level quit
vaping intention detection, this study compares the outcomes of this model
against layman and clinical expert annotations. Using different prompting
strategies such as zero-shot, one-shot, few-shot and chain-of-thought
prompting, we developed 8 prompts with varying levels of detail to explain the
task to GPT-4 and also evaluated the performance of the strategies against each
other. These preliminary findings emphasize the potential of GPT-4 in social
media data analysis, especially in identifying users' subtle intentions that
may elude human detection.

æè¦ï¼è¿å¹´ä¾ï¼ç¾åè¦è­äºé»å­çæé»å­é¦è¸ä½¿ç¨çå¤§å¹æ¿å¢ï¼å°è´é»å­çåé»å­çä½¿ç¨ç¸éèºæå· (EVALI) çä¾é¡¯èå¢å ï¼å¨ 2019 å¹´ EVALI çç¼æéé æä½é¢åæ­»äº¡ï¼å¸é¡¯äºçè§£é»å­çè¡çºåå¶å®æææè¸ç­ç¥çè¿«åæ§ãç±æ¼ç¤¾ç¾¤åªé«å¹³å°çæ®åï¼å¨çè¶é 47 åä½¿ç¨èä½¿ç¨å®åé²è¡é£çµãæºéãæ°èåå¨æ¨ï¼å¶ä¸­å¾å¤§ä¸é¨åèå¥åº·ç¸éï¼å æ­¤å°ç¤¾ç¾¤åªé«è³æå»ºç«çºå¬å±è¡çç ç©¶ä¸­ç¡å¹çææ©è³æè³æºãå¨æ¬ç ç©¶ä¸­ï¼æåå¾ Reddit ä¸ä¸åé»å­çå­ç¤¾ç¾¤ä¸­æåä¸åç¯ä¾è³æéï¼ä»¥åæä½¿ç¨èçæé»å­çæåãå©ç¨ OpenAI ææ°çå¤§åèªè¨æ¨¡å GPT-4 é²è¡å¥å­å±¤ç´çæé»å­çæååµæ¸¬ï¼æ¬ç ç©¶æ¯è¼äºæ­¤æ¨¡åççµæèå¤è¡äººåè¨åºå°å®¶è¨»è§£ãä½¿ç¨ä¸åçæç¤ºç­ç¥ï¼ä¾å¦é¶æ¬¡å­¸ç¿ãä¸æ¬¡å­¸ç¿ãå°æ¬¡å­¸ç¿åæèéæç¤ºï¼æåéç¼äº 8 åæç¤ºï¼è©³ç´°ç¨åº¦ä¸åï¼å GPT-4 è§£éä»»åï¼ä¸¦è©ä¼°éäºç­ç¥å½¼æ­¤ä¹éçæè½ãéäºåæ­¥ç¼ç¾å¼·èª¿äº GPT-4 å¨ç¤¾ç¾¤åªé«è³æåæä¸­çæ½åï¼ç¹å¥æ¯å¨è­å¥äººé¡åµæ¸¬å¯è½ç¡æ³å¯è¦ºçä½¿ç¨èå¾®å¦æåæ¹é¢ã

##### **Towards Compositional Interpretability for XAI**
2406.17583v1 by Sean Tull, Robin Lorenz, Stephen Clark, Ilyas Khan, Bob Coecke

Artificial intelligence (AI) is currently based largely on black-box machine
learning models which lack interpretability. The field of eXplainable AI (XAI)
strives to address this major concern, being critical in high-stakes areas such
as the finance, legal and health sectors.
  We present an approach to defining AI models and their interpretability based
on category theory. For this we employ the notion of a compositional model,
which sees a model in terms of formal string diagrams which capture its
abstract structure together with its concrete implementation. This
comprehensive view incorporates deterministic, probabilistic and quantum
models. We compare a wide range of AI models as compositional models, including
linear and rule-based models, (recurrent) neural networks, transformers, VAEs,
and causal and DisCoCirc models.
  Next we give a definition of interpretation of a model in terms of its
compositional structure, demonstrating how to analyse the interpretability of a
model, and using this to clarify common themes in XAI. We find that what makes
the standard 'intrinsically interpretable' models so transparent is brought out
most clearly diagrammatically. This leads us to the more general notion of
compositionally-interpretable (CI) models, which additionally include, for
instance, causal, conceptual space, and DisCoCirc models.
  We next demonstrate the explainability benefits of CI models. Firstly, their
compositional structure may allow the computation of other quantities of
interest, and may facilitate inference from the model to the modelled
phenomenon by matching its structure. Secondly, they allow for diagrammatic
explanations for their behaviour, based on influence constraints, diagram
surgery and rewrite explanations. Finally, we discuss many future directions
for the approach, raising the question of how to learn such meaningfully
structured models in practice.

æè¦ï¼<paragraph>äººå·¥æºæ§ï¼AIï¼ç®åå¨å¾å¤§ç¨åº¦ä¸ä¾è³´æ¼ç¼ºä¹å¯è§£éæ§çé»çæ©å¨å­¸ç¿æ¨¡åãå¯è§£éæ§äººå·¥æºæ§ï¼XAIï¼é åè´åæ¼è§£æ±ºéåä¸»è¦åé¡ï¼éå¨éèãæ³å¾åå¥åº·ç­é«é¢¨éªé åè³ééè¦ã
æåæåºäºä¸ç¨®åºæ¼ç¯çè«å®ç¾© AI æ¨¡ååå¶å¯è§£éæ§çæ¹æ³ãçºæ­¤ï¼æåæ¡ç¨çµåæ¨¡åçæ¦å¿µï¼å®ä»¥å½¢å¼å¼¦åçå½¢å¼çå¾æ¨¡åï¼éäºå¼¦åæç²äºæ¨¡åçæ½è±¡çµæ§åå¶å·é«å¯¦ç¾ãéç¨®ç¶åè§é»åå«äºç¢ºå®æ§ãæ¦çæ§åéå­æ¨¡åãæåå°åç¨® AI æ¨¡åä½çºçµåæ¨¡åé²è¡æ¯è¼ï¼åæ¬ç·æ§ååºæ¼è¦åçæ¨¡åãï¼éè¿´ï¼ç¥ç¶ç¶²è·¯ãTransformerãVAEï¼ä»¥åå æå DisCoCirc æ¨¡åã
æ¥ä¸ä¾ï¼æåæ ¹ææ¨¡åççµåçµæ§çµ¦åºæ¨¡åè§£éçå®ç¾©ï¼å±ç¤ºå¦ä½åææ¨¡åçå¯è§£éæ§ï¼ä¸¦ä½¿ç¨å®ä¾æ¾æ¸ XAI ä¸­çå¸¸è¦ä¸»é¡ãæåç¼ç¾ï¼è®æ¨æºçãå§å¨å¯è§£éãæ¨¡åå¦æ­¤éæçåå å¨åè¡¨ä¸­è¡¨ç¾å¾æçºæ¸æ¥ãéå¼å°æåå¾åºæ´ä¸è¬ççµåå¯è§£éï¼CIï¼æ¨¡åæ¦å¿µï¼å®å¦å¤éåæ¬å æãæ¦å¿µç©ºéå DisCoCirc æ¨¡åã
æ¥ä¸ä¾ï¼æåå±ç¤ºäº CI æ¨¡åçå¯è§£éæ§åªå¢ãé¦åï¼å®åççµåçµæ§åè¨±è¨ç®å¶ä»æèè¶£çéï¼ä¸¦å¯è½ééå¹éæ¨¡åççµæ§ä¾ä¿é²å¾æ¨¡åå°è¢«å»ºæ¨¡ç¾è±¡çæ¨çãå¶æ¬¡ï¼å®ååè¨±å°å¶è¡çºé²è¡åè§£èªªæï¼éäºèªªæåºæ¼å½±é¿ç´æãåè§£æè¡åéå¯«èªªæãæå¾ï¼æåè¨è«äºéç¨®æ¹æ³çè¨±å¤æªä¾æ¹åï¼æåºäºå¦ä½å¨å¯¦è¸ä¸­å­¸ç¿éç¨®ææç¾©ççµæ§åæ¨¡åçåé¡ã</paragraph>

##### **Unlocking the Potential of Metaverse in Innovative and Immersive Digital Health**
2406.07114v2 by Fatemeh Ebrahimzadeh, Ramin Safa

The concept of Metaverse has attracted a lot of attention in various fields
and one of its important applications is health and treatment. The Metaverse
has enormous potential to transform healthcare by changing patient care,
medical education, and the way teaching/learning and research are done. The
purpose of this research is to provide an introduction to the basic concepts
and fundamental technologies of the Metaverse. This paper examines the pros and
cons of the Metaverse in healthcare context and analyzes its potential from the
technology and AI perspective. In particular, the role of machine learning
methods is discussed; We will explain how machine learning algorithms can be
applied to the Metaverse generated data to gain better insights in healthcare
applications. Additionally, we examine the future visions of the Metaverse in
health delivery, by examining emerging technologies such as blockchain and also
addressing privacy concerns. The findings of this study contribute to a deeper
understanding of the applications of Metaverse in healthcare and its potential
to revolutionize the delivery of medical services.

æè¦ï¼åå®å®çæ¦å¿µå¨ååé åé½ååéæ³¨ï¼å¶éè¦æç¨ä¹ä¸ä¾¿æ¯é«çä¿å¥ãåå®å®æå·¨å¤§çæ½åééæ¹è®çæ£ç§è­·ãé«å­¸æè²ï¼ä»¥åæå­¸/å­¸ç¿åç ç©¶çæ¹å¼ä¾è½åé«çä¿å¥ãæ¬ç ç©¶çç®çæ¯æä¾åå®å®åºæ¬æ¦å¿µååºç¤æè¡çä»ç´¹ãæ¬ææ¢è¨äºåå®å®å¨é«çä¿å¥èæ¯ä¸çåªç¼ºé»ï¼ä¸¦å¾æè¡å AI çè§åº¦åæå¶æ½åãç¹å¥æ¯ï¼è¨è«äºæ©å¨å­¸ç¿æ¹æ³çè§è²ï¼æåå°èªªæå¦ä½å°æ©å¨å­¸ç¿æ¼ç®æ³æç¨æ¼åå®å®ç¢ççè³æï¼ä»¥ç²å¾é«çä¿å¥æç¨æ¹é¢çæ´ä½³è¦è§£ãæ­¤å¤ï¼æåééæ¢è¨åå¡éç­æ°èæè¡ï¼ä¸¦è§£æ±ºé±ç§åé¡ï¼ä¾æ¢è¨åå®å®å¨é«çä¿å¥æ¹é¢çæªä¾é¡æ¯ãæ¬ç ç©¶çç¼ç¾æå©æ¼æ´æ·±å¥å°äºè§£åå®å®å¨é«çä¿å¥ä¸­çæç¨ï¼ä»¥åå¶å¨é«çæåæä¾æ¹é¢ç¼æ®é©å½æ§è®é©çæ½åã

##### **AI-Driven Predictive Analytics Approach for Early Prognosis of Chronic Kidney Disease Using Ensemble Learning and Explainable AI**
2406.06728v1 by K M Tawsik Jawad, Anusha Verma, Fathi Amsaad

Chronic Kidney Disease (CKD) is one of the widespread Chronic diseases with
no known ultimo cure and high morbidity. Research demonstrates that progressive
Chronic Kidney Disease (CKD) is a heterogeneous disorder that significantly
impacts kidney structure and functions, eventually leading to kidney failure.
With the progression of time, chronic kidney disease has moved from a
life-threatening disease affecting few people to a common disorder of varying
severity. The goal of this research is to visualize dominating features,
feature scores, and values exhibited for early prognosis and detection of CKD
using ensemble learning and explainable AI. For that, an AI-driven predictive
analytics approach is proposed to aid clinical practitioners in prescribing
lifestyle modifications for individual patients to reduce the rate of
progression of this disease. Our dataset is collected on body vitals from
individuals with CKD and healthy subjects to develop our proposed AI-driven
solution accurately. In this regard, blood and urine test results are provided,
and ensemble tree-based machine-learning models are applied to predict unseen
cases of CKD. Our research findings are validated after lengthy consultations
with nephrologists. Our experiments and interpretation results are compared
with existing explainable AI applications in various healthcare domains,
including CKD. The comparison shows that our developed AI models, particularly
the Random Forest model, have identified more features as significant
contributors than XgBoost. Interpretability (I), which measures the ratio of
important to masked features, indicates that our XgBoost model achieved a
higher score, specifically a Fidelity of 98\%, in this metric and naturally in
the FII index compared to competing models.

æè¦ï¼æ¢æ§èèçï¼CKDï¼æ¯ä¸ç¨®å»£æ³çæ¢æ§ç¾çï¼æ²æå·²ç¥çæçµçæ³ä¸ç¼ççå¾é«ãç ç©¶è¡¨æï¼é²è¡æ§æ¢æ§èèçï¼CKDï¼æ¯ä¸ç¨®ç°è³ªæ§ç¾çï¼æé¡¯èå½±é¿èèçµæ§ååè½ï¼æçµå°è´èè¡°ç«­ãé¨èæéçæ¨ç§»ï¼æ¢æ§èèçå·²å¾å½±é¿å°æ¸äººçè´å½ç¾çè½è®çºä¸ç¨®å´éç¨åº¦ä¸åçå¸¸è¦ç¾çãæ¬ç ç©¶çç®æ¨æ¯ä½¿ç¨éæå­¸ç¿åå¯è§£éç AI é²è¡æ©æé å¾å CKD æª¢æ¸¬ï¼ä¸¦è¦è¦ºåä¸»å°ç¹å¾µãç¹å¾µåæ¸åè¡¨ç¾åºçå¼ãçºæ­¤ï¼æåºäºä¸ç¨® AI é©åçé æ¸¬åææ¹æ³ï¼ä»¥å¹«å©è¨åºé«ççºåå¥æ£èéå·çæ´»æ¹å¼ä¿®æ¹å»ºè­°ï¼ä»¥éä½éç¨®ç¾ççé²å±éåº¦ãæåçæ¸æéæ¯å¾ CKD æ£èåå¥åº·åè©¦èçèº«é«çå½é«å¾µä¸­æ¶éçï¼ä»¥æºç¢ºéç¼æåæåºç AI é©åçè§£æ±ºæ¹æ¡ãå¨éæ¹é¢ï¼æä¾äºè¡æ¶²åå°¿æ¶²æª¢æ¸¬çµæï¼ä¸¦æç¨åºæ¼éææ¨¹çæ©å¨å­¸ç¿æ¨¡åä¾é æ¸¬æªç¼ç¾ç CKD çä¾ãæåçç ç©¶çµæç¶éèèèç§é«ççé·æè«®è©¢å¾å¾å°é©è­ãæåçå¯¦é©åè§£éçµæèåç¨®é«çä¿å¥é åä¸­ç¾æçå¯è§£é AI æç¨é²è¡äºæ¯è¼ï¼åæ¬ CKDãæ¯è¼è¡¨æï¼æåéç¼ç AI æ¨¡åï¼ç¹å¥æ¯é¨æ©æ£®ææ¨¡åï¼å·²ç¶ç¢ºå®äºæ¯ XgBoost æ´å¤ä½çºéè¦è²¢ç»èçç¹å¾µãå¯è§£éæ§ (I) è¡¡ééè¦ç¹å¾µèæ©èç¹å¾µçæ¯çï¼è¡¨ææåç XgBoost æ¨¡åå¨éåææ¨ä¸­ç²å¾äºæ´é«çåæ¸ï¼ç¹å¥æ¯ 98% çä¿çåº¦ï¼ä¸¦ä¸å¨ FII ææ¸ä¸­èªç¶é«æ¼ç«¶ç­æ¨¡åã

##### **Explainable AI for Mental Disorder Detection via Social Media: A survey and outlook**
2406.05984v1 by Yusif Ibrahimov, Tarique Anwar, Tommy Yuan

Mental health constitutes a complex and pervasive global challenge, affecting
millions of lives and often leading to severe consequences. In this paper, we
conduct a thorough survey to explore the intersection of data science,
artificial intelligence, and mental healthcare, focusing on the recent
developments of mental disorder detection through online social media (OSM). A
significant portion of the population actively engages in OSM platforms,
creating a vast repository of personal data that holds immense potential for
mental health analytics. The paper navigates through traditional diagnostic
methods, state-of-the-art data- and AI-driven research studies, and the
emergence of explainable AI (XAI) models for mental healthcare. We review
state-of-the-art machine learning methods, particularly those based on modern
deep learning, while emphasising the need for explainability in healthcare AI
models. The experimental design section provides insights into prevalent
practices, including available datasets and evaluation approaches. We also
identify key issues and challenges in the field and propose promising future
research directions. As mental health decisions demand transparency,
interpretability, and ethical considerations, this paper contributes to the
ongoing discourse on advancing XAI in mental healthcare through social media.
The comprehensive overview presented here aims to guide researchers,
practitioners, and policymakers in developing the area of mental disorder
detection.

æè¦ï¼å¿çå¥åº·æ§æäºä¸é è¤éä¸æ®éçå¨çææ°ï¼å½±é¿äºæ¸ç¾è¬äººççæ´»ï¼ä¸¦ç¶å¸¸å°è´å´éçå¾æãå¨æ¬æä¸­ï¼æåé²è¡äºä¸é å¾¹åºçèª¿æ¥ï¼ä»¥æ¢ç´¢æ¸æç§å­¸ãäººå·¥æºæ§åå¿çä¿å¥çäº¤éï¼éé»éæ³¨ééç·ä¸ç¤¾äº¤åªé« (OSM) é²è¡å¿çç¾çæª¢æ¸¬çææ°ç¼å±ãå¾å¤§ä¸é¨åäººå£ç©æ¥µåè OSM å¹³å°ï¼åµé äºä¸åé¾å¤§çäººå¡è³æåº«ï¼å°å¿çå¥åº·åæå·æå·¨å¤§çæ½åãæ¬ææ¢è¨äºå³çµ±çè¨ºæ·æ¹æ³ãæåé²çè³æå AI é©åçç ç©¶ï¼ä»¥åå¿çä¿å¥ä¸­å¯è§£é AI (XAI) æ¨¡åçåºç¾ãæååé¡§äºæåé²çæ©å¨å­¸ç¿æ¹æ³ï¼ç¹å¥æ¯é£äºåºæ¼ç¾ä»£æ·±åº¦å­¸ç¿çæ¹æ³ï¼åæå¼·èª¿äºé«çä¿å¥ AI æ¨¡åä¸­å¯è§£éæ§çå¿è¦æ§ãå¯¦é©è¨­è¨é¨åæä¾äºå°æ®éåæ³çè¦è§£ï¼åæ¬å¯ç¨çè³æéåè©ä¼°æ¹æ³ãæåéæ¾åºè©²é åçä¸»è¦åé¡åææ°ï¼ä¸¦æåºäºæå¸æçæªä¾ç ç©¶æ¹åãç±æ¼å¿çå¥åº·æ±ºç­éè¦éæåº¦ãå¯è§£éæ§åéå¾·èéï¼æ¬ææå©æ¼æ¨é²å¿çä¿å¥ä¸­ééç¤¾äº¤åªé«æ¨é² XAI çæçºè¨è«ãéè£¡æåºçå¨é¢æ¦è¿°æ¨å¨å¼å°ç ç©¶äººå¡ãå¾æ¥­äººå¡åæ¿ç­å¶å®èç¼å±å¿çç¾çæª¢æ¸¬é åã

##### **Methodology and Real-World Applications of Dynamic Uncertain Causality Graph for Clinical Diagnosis with Explainability and Invariance**
2406.05746v1 by Zhan Zhang, Qin Zhang, Yang Jiao, Lin Lu, Lin Ma, Aihua Liu, Xiao Liu, Juan Zhao, Yajun Xue, Bing Wei, Mingxia Zhang, Ru Gao, Hong Zhao, Jie Lu, Fan Li, Yang Zhang, Yiming Wang, Lei Zhang, Fengwei Tian, Jie Hu, Xin Gou

AI-aided clinical diagnosis is desired in medical care. Existing deep
learning models lack explainability and mainly focus on image analysis. The
recently developed Dynamic Uncertain Causality Graph (DUCG) approach is
causality-driven, explainable, and invariant across different application
scenarios, without problems of data collection, labeling, fitting, privacy,
bias, generalization, high cost and high energy consumption. Through close
collaboration between clinical experts and DUCG technicians, 46 DUCG models
covering 54 chief complaints were constructed. Over 1,000 diseases can be
diagnosed without triage. Before being applied in real-world, the 46 DUCG
models were retrospectively verified by third-party hospitals. The verified
diagnostic precisions were no less than 95%, in which the diagnostic precision
for every disease including uncommon ones was no less than 80%. After
verifications, the 46 DUCG models were applied in the real-world in China. Over
one million real diagnosis cases have been performed, with only 17 incorrect
diagnoses identified. Due to DUCG's transparency, the mistakes causing the
incorrect diagnoses were found and corrected. The diagnostic abilities of the
clinicians who applied DUCG frequently were improved significantly. Following
the introduction to the earlier presented DUCG methodology, the recommendation
algorithm for potential medical checks is presented and the key idea of DUCG is
extracted.

æè¦ï¼<paragraph>é«çç§è­·ä¸­éè¦ AI è¼å©çè¨åºè¨ºæ·ãç¾æçæ·±åº¦å­¸ç¿æ¨¡åç¼ºä¹å¯è§£éæ§ï¼ä¸¦ä¸ä¸»è¦å°æ³¨æ¼å½±ååæãæè¿éç¼çåæä¸ç¢ºå®å æéä¿å (DUCG) æ¹æ³æ¯å æé©åçãå¯è§£éçï¼ä¸¦ä¸å¨ä¸åçæç¨å ´æ¯ä¸­æ¯ä¸è®çï¼æ²æè³ææ¶éãæ¨è¨ãæ¬åãé±ç§ãåè¦ãæ¦åãé«ææ¬åé«è½èçåé¡ãééè¨åºå°å®¶å DUCG æè¡äººå¡ä¹éçå¯ååä½ï¼æ§å»ºäºæ¶µè 54 åä¸»è¨´ç 46 å DUCG æ¨¡åãå¯ä»¥å¨æ²æåæµçææ³ä¸è¨ºæ·åº 1,000 å¤ç¨®ç¾çãå¨æç¨æ¼å¯¦éä¸çä¹åï¼46 å DUCG æ¨¡åå·²ç±ç¬¬ä¸æ¹é«é¢åæº¯æ§é©è­ãé©è­çè¨ºæ·ç²¾åº¦ä¸ä½æ¼ 95%ï¼å¶ä¸­åæ¬ç½è¦ç¾çå¨å§çæ¯ç¨®ç¾ççè¨ºæ·ç²¾åº¦ä¸ä½æ¼ 80%ãé©è­å¾ï¼46 å DUCG æ¨¡åå·²å¨ä¸­åå¯¦éæç¨ãå·²ç¶å·è¡äºè¶éä¸ç¾è¬åçå¯¦è¨ºæ·æ¡ä¾ï¼åç¼ç¾ 17 åä¸æ­£ç¢ºçè¨ºæ·ãç±æ¼ DUCG çéææ§ï¼ç¼ç¾ä¸¦ç³¾æ­£äºå°è´ä¸æ­£ç¢ºè¨ºæ·çé¯èª¤ãé »ç¹æç¨ DUCG çè¨åºé«ççè¨ºæ·è½åå¾å°äºé¡¯èæé«ãå¨ä»ç´¹äºåé¢æåºç DUCG æ¹æ³è«ä¹å¾ï¼æåºäºæ½å¨å¥åº·æª¢æ¥çæ¨è¦æ¼ç®æ³ï¼ä¸¦æåäº DUCG çééµææ³ã</paragraph>

##### **Advancing Histopathology-Based Breast Cancer Diagnosis: Insights into Multi-Modality and Explainability**
2406.12897v1 by Faseela Abdullakutty, Younes Akbari, Somaya Al-Maadeed, Ahmed Bouridane, Rifat Hamoudi

It is imperative that breast cancer is detected precisely and timely to
improve patient outcomes. Diagnostic methodologies have traditionally relied on
unimodal approaches; however, medical data analytics is integrating diverse
data sources beyond conventional imaging. Using multi-modal techniques,
integrating both image and non-image data, marks a transformative advancement
in breast cancer diagnosis. The purpose of this review is to explore the
burgeoning field of multimodal techniques, particularly the fusion of
histopathology images with non-image data. Further, Explainable AI (XAI) will
be used to elucidate the decision-making processes of complex algorithms,
emphasizing the necessity of explainability in diagnostic processes. This
review utilizes multi-modal data and emphasizes explainability to enhance
diagnostic accuracy, clinician confidence, and patient engagement, ultimately
fostering more personalized treatment strategies for breast cancer, while also
identifying research gaps in multi-modality and explainability, guiding future
studies, and contributing to the strategic direction of the field.

æè¦ï¼ç²¾ç¢ºä¸åæå°åµæ¸¬ä¹³çå°æ¼æ¹åæ£èé å¾è³ééè¦ãè¨ºæ·æ¹æ³å³çµ±ä¸ä¾è³´æ¼å®ä¸æ¨¡å¼æ¹æ³ï¼ç¶èï¼é«çè³æåææ­£å¨æ´åè¶è¶å³çµ±å½±åçåç¨®è³æä¾æºãä½¿ç¨æ´åå½±ååéå½±åè³æçå¤æ¨¡å¼æè¡ï¼æ¨èªèä¹³çè¨ºæ·çè®é©æ§é²å±ãæ¬ç¯ç¶è¿°çç®çæ¯æ¢è¨å¤æ¨¡å¼æè¡çæ°èé åï¼ç¹å¥æ¯å°çµç¹ççå­¸å½±åèéå½±åè³æèåãæ­¤å¤ï¼å¯è§£éäººå·¥æºæ§ (XAI) å°ç¨æ¼é¡æè¤éæ¼ç®æ³çæ±ºç­éç¨ï¼å¼·èª¿è¨ºæ·éç¨ä¸­å¯è§£éæ§çå¿è¦æ§ãæ¬ç¶è¿°å©ç¨å¤æ¨¡å¼è³æä¸¦å¼·èª¿å¯è§£éæ§ï¼ä»¥æé«è¨ºæ·æºç¢ºæ§ãè¨åºé«å¸«çä¿¡å¿åæ£èåèåº¦ï¼æçµä¿é²ä¹³çæ´åäººåçæ²»çç­ç¥ï¼åæä¹æ¾åºå¤æ¨¡å¼åå¯è§£éæ§çç ç©¶å·®è·ï¼å¼å°æªä¾çç ç©¶ï¼ä¸¦çºè©²é åçç­ç¥æ¹åååºè²¢ç»ã

##### **Revisiting Attention Weights as Interpretations of Message-Passing Neural Networks**
2406.04612v1 by Yong-Min Shin, Siqing Li, Xin Cao, Won-Yong Shin

The self-attention mechanism has been adopted in several widely-used
message-passing neural networks (MPNNs) (e.g., GATs), which adaptively controls
the amount of information that flows along the edges of the underlying graph.
This usage of attention has made such models a baseline for studies on
explainable AI (XAI) since interpretations via attention have been popularized
in various domains (e.g., natural language processing and computer vision).
However, existing studies often use naive calculations to derive attribution
scores from attention, and do not take the precise and careful calculation of
edge attribution into consideration. In our study, we aim to fill the gap
between the widespread usage of attention-enabled MPNNs and their potential in
largely under-explored explainability, a topic that has been actively
investigated in other areas. To this end, as the first attempt, we formalize
the problem of edge attribution from attention weights in GNNs. Then, we
propose GATT, an edge attribution calculation method built upon the computation
tree. Through comprehensive experiments, we demonstrate the effectiveness of
our proposed method when evaluating attributions from GATs. Conversely, we
empirically validate that simply averaging attention weights over graph
attention layers is insufficient to interpret the GAT model's behavior. Code is
publicly available at https://github.com/jordan7186/GAtt/tree/main.

æè¦ï¼èªæ³¨æåæ©å¶å·²è¢«æ¡ç¨æ¼å¤åå»£æ³ä½¿ç¨çè¨æ¯å³éç¥ç¶ç¶²è·¯ (MPNN)ï¼ä¾å¦ GATï¼ï¼å®å¯ä»¥èªé©æå°æ§å¶æ²¿èåºå±¤åå½¢éç·£æµåçè³è¨éãéç¨®æ³¨æåçä½¿ç¨ä½¿å¾æ­¤é¡æ¨¡åæçºå¯è§£é AI (XAI) ç ç©¶çåºç·ï¼å çºééæ³¨æåçè©®éå·²å¨åç¨®é åï¼ä¾å¦èªç¶èªè¨èçåé»è¦è¦è¦ºï¼ä¸­æ®åãç¶èï¼ç¾æçç ç©¶éå¸¸ä½¿ç¨å¤©ççè¨ç®æ¹æ³å¾æ³¨æåä¸­æ¨å°åºæ­¸å åæ¸ï¼ä¸¦ä¸æ²æèæ®å°éç·£æ­¸å çç²¾ç¢ºä¸ä»ç´°çè¨ç®ãå¨æåçç ç©¶ä¸­ï¼æåæ¨å¨å¡«è£æ³¨æååç¨ MPNN çå»£æ³ä½¿ç¨èå®åå¨å¾å¤§ç¨åº¦ä¸æªè¢«ååæ¢ç´¢çå¯è§£éæ§ä¹éçå·®è·ï¼éåä¸»é¡å·²å¨å¶ä»é åç©æ¥µç ç©¶ãçºæ­¤ï¼ä½çºç¬¬ä¸æ¬¡åè©¦ï¼æåå° GNN ä¸­æ³¨æåæ¬éçéç·£æ­¸å åé¡å½¢å¼åãç¶å¾ï¼æåæåº GATTï¼ä¸ç¨®å»ºç«å¨è¨ç®æ¨¹ä¸çéç·£æ­¸å è¨ç®æ¹æ³ãééå¨é¢çå¯¦é©ï¼æåå±ç¤ºäºæåæåºçæ¹æ³å¨è©ä¼° GAT çæ­¸å ææå·æçææãç¸åå°ï¼æåæç¶é©é©è­äºåå°åæ³¨æåå±¤ä¸çæ³¨æåæ¬éåå¹³åå¼ä¸è¶³ä»¥è©®é GAT æ¨¡åçè¡çºãç¨å¼ç¢¼å·²å¬éæ¼ https://github.com/jordan7186/GAtt/tree/mainã

##### **Using Explainable AI for EEG-based Reduced Montage Neonatal Seizure Detection**
2406.16908v2 by Dinuka Sandun Udayantha, Kavindu Weerasinghe, Nima Wickramasinghe, Akila Abeyratne, Kithmin Wickremasinghe, Jithangi Wanigasinghe, Anjula De Silva, Chamira U. S. Edussooriya

The neonatal period is the most vulnerable time for the development of
seizures. Seizures in the immature brain lead to detrimental consequences,
therefore require early diagnosis. The gold-standard for neonatal seizure
detection currently relies on continuous video-EEG monitoring; which involves
recording multi-channel electroencephalogram (EEG) alongside real-time video
monitoring within a neonatal intensive care unit (NICU). However, video-EEG
monitoring technology requires clinical expertise and is often limited to
technologically advanced and resourceful settings. Cost-effective new
techniques could help the medical fraternity make an accurate diagnosis and
advocate treatment without delay. In this work, a novel explainable deep
learning model to automate the neonatal seizure detection process with a
reduced EEG montage is proposed, which employs convolutional nets, graph
attention layers, and fully connected layers. Beyond its ability to detect
seizures in real-time with a reduced montage, this model offers the unique
advantage of real-time interpretability. By evaluating the performance on the
Zenodo dataset with 10-fold cross-validation, the presented model achieves an
absolute improvement of 8.31% and 42.86% in area under curve (AUC) and recall,
respectively.

æè¦ï¼æ°çåæææ¯å¤§è¦ç¼è²æèå¼±çææï¼æå°è´ç²çç¼ä½ãç²çç¼ä½æå°æªæççå¤§è¦é æä¸è¯å¾æï¼å æ­¤éè¦æ©æè¨ºæ·ãç®åæ°çåç²çæª¢æ¸¬çé»éæ¨æºä¾è³´æ¼é£çºè¦è¨è¦é»åç£æ¸¬ï¼éåæ¬å¨æ°çåå è­·çæ¿ (NICU) å§è¨éå¤ééè¦é»å (EEG) åå³æè¦è¨ç£æ¸¬ãç¶èï¼è¦è¨è¦é»åç£æ¸¬æè¡éè¦è¨åºå°æ¥­ç¥è­ï¼èä¸éå¸¸åéæ¼æè¡åé²ä¸è³æºè±å¯çç°å¢ãå·æææ¬æççæ°æè¡å¯ä»¥å¹«å©é«ççååºæºç¢ºçè¨ºæ·ï¼ä¸¦ç«å³æå¡æ²»çãå¨éé å·¥ä½ä¸­ï¼æåºäºä¸åæ°ç©å¯è§£éçæ·±åº¦å­¸ç¿æ¨¡åï¼ä»¥èªååæ°çåç²çæª¢æ¸¬éç¨ï¼ä¸¦æ¸å°è¦é»åè£ç½®ï¼è©²æ¨¡åæ¡ç¨å·ç©ç¶²è·¯ãåæ³¨æåå±¤åå¨é£æ¥å±¤ãé¤äºè½å¤ å³æåµæ¸¬æ¸å°è£ç½®çç²çç¼ä½å¤ï¼æ­¤æ¨¡åéæä¾å³æå¯è§£éæ§çç¨ç¹åªå¢ãééè©ä¼° Zenodo è³æéä¸çæè½ï¼ä¸¦é²è¡ 10 åäº¤åé©è­ï¼ææåºçæ¨¡åå¨æ²ç·ä¸é¢ç© (AUC) åå¬åçåå¥éå° 8.31% å 42.86% ççµå°æ¹åã

##### **Breast Cancer Diagnosis: A Comprehensive Exploration of Explainable Artificial Intelligence (XAI) Techniques**
2406.00532v1 by Samita Bai, Sidra Nasir, Rizwan Ahmed Khan, Sheeraz Arif, Alexandre Meyer, Hubert Konik

Breast cancer (BC) stands as one of the most common malignancies affecting
women worldwide, necessitating advancements in diagnostic methodologies for
better clinical outcomes. This article provides a comprehensive exploration of
the application of Explainable Artificial Intelligence (XAI) techniques in the
detection and diagnosis of breast cancer. As Artificial Intelligence (AI)
technologies continue to permeate the healthcare sector, particularly in
oncology, the need for transparent and interpretable models becomes imperative
to enhance clinical decision-making and patient care. This review discusses the
integration of various XAI approaches, such as SHAP, LIME, Grad-CAM, and
others, with machine learning and deep learning models utilized in breast
cancer detection and classification. By investigating the modalities of breast
cancer datasets, including mammograms, ultrasounds and their processing with
AI, the paper highlights how XAI can lead to more accurate diagnoses and
personalized treatment plans. It also examines the challenges in implementing
these techniques and the importance of developing standardized metrics for
evaluating XAI's effectiveness in clinical settings. Through detailed analysis
and discussion, this article aims to highlight the potential of XAI in bridging
the gap between complex AI models and practical healthcare applications,
thereby fostering trust and understanding among medical professionals and
improving patient outcomes.

æè¦ï¼ä¹³ç (BC) æ¯å½±é¿å¨çå¥³æ§æå¸¸è¦çæ¡æ§è«ç¤ä¹ä¸ï¼å æ­¤éè¦é²æ­¥çè¨ºæ·æ¹æ³ï¼ä»¥æ¹åè¨åºçµæãæ¬æå¨é¢æ¢è¨äºå¯è§£éäººå·¥æºæ§ (XAI) æè¡å¨ä¹³çåµæ¸¬åè¨ºæ·ä¸­çæç¨ãé¨èäººå·¥æºæ§ (AI) æè¡æçºæ»²éé«çä¿å¥é åï¼ç¹å¥æ¯å¨è«ç¤å­¸ä¸­ï¼éæä¸å¯è§£éçæ¨¡åéæ±è®å¾å¢å¨å¿è¡ï¼ä»¥å¢å¼·è¨åºæ±ºç­å¶å®åæ£èç§è­·ãæ­¤ç¯è©è«æ¢è¨äºåç¨® XAI æ¹æ³çæ´åï¼ä¾å¦ SHAPãLIMEãGrad-CAM ç­ï¼ä»¥åç¨æ¼ä¹³çåµæ¸¬ååé¡çæ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿æ¨¡åãééæ¢è¨ä¹³çè³æéçæ¨¡å¼ï¼åæ¬ä¹³æ¿æå½±ãè¶é³æ³¢åå¶å¨ AI ä¸­çèçï¼æ¬æéé»èªªæ XAI å¦ä½è½å°è´æ´æºç¢ºçè¨ºæ·ååäººåæ²»çè¨ç«ãå®ä¹æ¢è¨äºå¯¦æ½éäºæè¡çææ°ï¼ä»¥åå¶å®æ¨æºåè©éææ¨ä»¥è©ä¼° XAI å¨è¨åºç°å¢ä¸­çæææ§çéè¦æ§ãééè©³ç´°çåæåè¨è«ï¼æ¬ææ¨å¨å¼·èª¿ XAI å¨ç¸®å°è¤é AI æ¨¡åèå¯¦åé«çä¿å¥æç¨ä¹éå·®è·çæ½åï¼é²èä¿é²é«çå°æ¥­äººå¡ä¹éçä¿¡ä»»èçè§£ï¼ä¸¦æ¹åæ£èççµæã

##### **Unveiling Hidden Factors: Explainable AI for Feature Boosting in Speech Emotion Recognition**
2406.01624v2 by Alaa Nfissi, Wassim Bouachir, Nizar Bouguila, Brian Mishara

Speech emotion recognition (SER) has gained significant attention due to its
several application fields, such as mental health, education, and
human-computer interaction. However, the accuracy of SER systems is hindered by
high-dimensional feature sets that may contain irrelevant and redundant
information. To overcome this challenge, this study proposes an iterative
feature boosting approach for SER that emphasizes feature relevance and
explainability to enhance machine learning model performance. Our approach
involves meticulous feature selection and analysis to build efficient SER
systems. In addressing our main problem through model explainability, we employ
a feature evaluation loop with Shapley values to iteratively refine feature
sets. This process strikes a balance between model performance and
transparency, which enables a comprehensive understanding of the model's
predictions. The proposed approach offers several advantages, including the
identification and removal of irrelevant and redundant features, leading to a
more effective model. Additionally, it promotes explainability, facilitating
comprehension of the model's predictions and the identification of crucial
features for emotion determination. The effectiveness of the proposed method is
validated on the SER benchmarks of the Toronto emotional speech set (TESS),
Berlin Database of Emotional Speech (EMO-DB), Ryerson Audio-Visual Database of
Emotional Speech and Song (RAVDESS), and Surrey Audio-Visual Expressed Emotion
(SAVEE) datasets, outperforming state-of-the-art methods. To the best of our
knowledge, this is the first work to incorporate model explainability into an
SER framework. The source code of this paper is publicly available via this
https://github.com/alaaNfissi/Unveiling-Hidden-Factors-Explainable-AI-for-Feature-Boosting-in-Speech-Emotion-Recognition.

æè¦ï¼èªé³æç·è¾¨è­ (SER) ç±æ¼å¶å¨å¿çå¥åº·ãæè²åäººæ©äºåç­å¤åæç¨é åèååéæ³¨ãç¶èï¼SER ç³»çµ±çæºç¢ºæ§åå°é«ç¶­ç¹å¾µéçé»ç¤ï¼éäºç¹å¾µéå¯è½åå«ä¸ç¸éååé¤çè³è¨ãçºäºåæéåææ°ï¼æ¬ç ç©¶æåºäºä¸ç¨®ç¨æ¼ SER çè¿­ä»£ç¹å¾µæåæ¹æ³ï¼è©²æ¹æ³å¼·èª¿ç¹å¾µç¸éæ§åå¯è§£éæ§ï¼ä»¥å¢å¼·æ©å¨å­¸ç¿æ¨¡åçæè½ãæåçåæ³æ¶åä»ç´°çç¹å¾µé¸æååæï¼ä»¥å»ºç«é«æç SER ç³»çµ±ãçºäºééæ¨¡åå¯è§£éæ§è§£æ±ºæåçæ ¸å¿åé¡ï¼æåæ¡ç¨äºå·æ Shapley å¼çç¹å¾µè©ä¼°è¿´åï¼ä»¥åè¦æ¹åç¹å¾µéãéåéç¨å¨æ¨¡åæè½åéæåº¦ä¹éåå¾å¹³è¡¡ï¼éä½¿å¾æåè½å¤ å¨é¢äºè§£æ¨¡åçé æ¸¬ãææåºçæ¹æ³æä¾äºå¤é åªé»ï¼åæ¬è­å¥åç§»é¤ä¸ç¸éååé¤çç¹å¾µï¼å¾èå»ºç«æ´ææçæ¨¡åãæ­¤å¤ï¼å®ä¿é²äºå¯è§£éæ§ï¼æå©æ¼çè§£æ¨¡åçé æ¸¬ä»¥åè­å¥æç·æ±ºå®çééµç¹å¾µãææåºçæ¹æ³çæææ§å·²å¨å¤å«å¤æç·èªé³é (TESS)ãæææç·èªé³è³æåº« (EMO-DB)ãè³´ç¾æ£®é³è¨è¦è¦ºæç·èªé³åæ­æ²è³æåº« (RAVDESS) åè©éé³è¨è¦è¦ºè¡¨éæç· (SAVEE) è³æéç SER åºæºä¸å¾å°é©è­ï¼å¶æè½åªæ¼ç¾ææ¹æ³ãææåæç¥ï¼éæ¯ç¬¬ä¸åå°æ¨¡åå¯è§£éæ§ç´å¥ SER æ¶æ§çç ç©¶ãæ¬æçåå§ç¢¼å¯ééæ­¤é£çµå¬éåå¾ï¼https://github.com/alaaNfissi/Unveiling-Hidden-Factors-Explainable-AI-for-Feature-Boosting-in-Speech-Emotion-Recognitionã

##### **The Explanation Necessity for Healthcare AI**
2406.00216v1 by Michail Mamalakis, HÃ©loÃ¯se de Vareilles, Graham Murray, Pietro Lio, John Suckling

Explainability is often critical to the acceptable implementation of
artificial intelligence (AI). Nowhere is this more important than healthcare
where decision-making directly impacts patients and trust in AI systems is
essential. This trust is often built on the explanations and interpretations
the AI provides. Despite significant advancements in AI interpretability, there
remains the need for clear guidelines on when and to what extent explanations
are necessary in the medical context. We propose a novel categorization system
with four distinct classes of explanation necessity, guiding the level of
explanation required: patient or sample (local) level, cohort or dataset
(global) level, or both levels. We introduce a mathematical formulation that
distinguishes these categories and offers a practical framework for researchers
to determine the necessity and depth of explanations required in medical AI
applications. Three key factors are considered: the robustness of the
evaluation protocol, the variability of expert observations, and the
representation dimensionality of the application. In this perspective, we
address the question: When does an AI medical application need to be explained,
and at what level of detail?

æè¦ï¼å¯è§£éæ§éå¸¸å¯¹äºäººå·¥æºè½ (AI) çå¯æ¥åå®æ½è³å³éè¦ãå¨å»çä¿å¥é¢åï¼è¿ä¸ç¹å°¤ä¸ºéè¦ï¼å ä¸ºå³ç­ç´æ¥å½±åæ£èï¼å¹¶ä¸å¯¹ AI ç³»ç»çä¿¡ä»»è³å³éè¦ãè¿ç§ä¿¡ä»»éå¸¸å»ºç«å¨ AI æä¾çè§£éåè¯ éä¹ä¸ãå°½ç®¡ AI å¯è§£éæ§åå¾äºéå¤§è¿å±ï¼ä½ä»ç¶éè¦æç¡®çæå¯¼æ¹éï¼è¯´æå¨å»çç¯å¢ä¸­ä½æ¶ä»¥åå¨å¤å¤§ç¨åº¦ä¸éè¦è§£éãæä»¬æåºäºä¸ç§æ°é¢çåç±»ç³»ç»ï¼è¯¥ç³»ç»å·æåç§ä¸åçè§£éå¿è¦æ§ç±»å«ï¼æå¯¼æéçè§£éçº§å«ï¼æ£èææ ·æ¬ï¼å±é¨ï¼çº§å«ãéåææ°æ®éï¼å¨å±ï¼çº§å«ï¼æä¸¤ä¸ªçº§å«ãæä»¬å¼å¥äºä¸ä¸ªæ°å­¦å¬å¼ï¼è¯¥å¬å¼åºåäºè¿äºç±»å«ï¼å¹¶ä¸ºç ç©¶äººåæä¾äºä¸ä¸ªå®ç¨æ¡æ¶ï¼ä»¥ç¡®å®å»ç AI åºç¨ä¸­æéçè§£éçå¿è¦æ§åæ·±åº¦ãèèäºä¸ä¸ªå³é®å ç´ ï¼è¯ä¼°åè®®çç¨³å¥æ§ãä¸å®¶è§å¯çå¯åæ§ä»¥ååºç¨ç¨åºçè¡¨ç¤ºç»´æ°ãä»è¿ä¸ªè§åº¦æ¥çï¼æä»¬è§£å³äºè¿ä¸ªé®é¢ï¼AI å»çåºç¨ä½æ¶éè¦è§£éï¼ä»¥åéè¦è§£éå°ä½ç§ç¨åº¦ï¼

##### **Interdisciplinary Expertise to Advance Equitable Explainable AI**
2406.18563v1 by Chloe R. Bennett, Heather Cole-Lewis, Stephanie Farquhar, Naama Haamel, Boris Babenko, Oran Lang, Mat Fleck, Ilana Traynis, Charles Lau, Ivor Horn, Courtney Lyles

The field of artificial intelligence (AI) is rapidly influencing health and
healthcare, but bias and poor performance persists for populations who face
widespread structural oppression. Previous work has clearly outlined the need
for more rigorous attention to data representativeness and model performance to
advance equity and reduce bias. However, there is an opportunity to also
improve the explainability of AI by leveraging best practices of social
epidemiology and health equity to help us develop hypotheses for associations
found. In this paper, we focus on explainable AI (XAI) and describe a framework
for interdisciplinary expert panel review to discuss and critically assess AI
model explanations from multiple perspectives and identify areas of bias and
directions for future research. We emphasize the importance of the
interdisciplinary expert panel to produce more accurate, equitable
interpretations which are historically and contextually informed.
Interdisciplinary panel discussions can help reduce bias, identify potential
confounders, and identify opportunities for additional research where there are
gaps in the literature. In turn, these insights can suggest opportunities for
AI model improvement.

æè¦ï¼äººå·¥æºæ§ (AI) é åæ­£å¿«éå½±é¿èå¥åº·èé«çä¿å¥ï¼ä½å°æ¼é¢è¨å»£æ³çµæ§æ§å£è¿«çäººç¾¤ä¾èªªï¼åè¦åä¸è¯è¡¨ç¾ä¾ç¶å­å¨ãååçç ç©¶å·²æ¸æ¥èªªæï¼éè¦æ´å´æ ¼å°æ³¨æè³æä»£è¡¨æ§åæ¨¡åæè½ï¼ä»¥ä¿é²å¬å¹³æ§ä¸¦æ¸å°åè¦ãç¶èï¼æåææ©æéééç¨ç¤¾ææµè¡çå­¸åå¥åº·å¬å¹³çæä½³å¯¦åï¼ä¾æ¹å AI çå¯è§£éæ§ï¼ä»¥å¹«å©æåéå°ç¼ç¾çéè¯æ§ï¼ç¼å±åè¨­ãå¨æ¬æä¸­ï¼æåå°æ³¨æ¼å¯è§£é AI (XAI)ï¼ä¸¦æè¿°ä¸åè·¨é åå°å®¶å°çµå¯©æ¥æ¶æ§ï¼ä»¥å¾å¤éè§é»è¨è«åæ¹å¤æ§è©ä¼° AI æ¨¡åçè§£éï¼ä¸¦æ¾åºåè¦é ååæªä¾ç ç©¶çæ¹åãæåå¼·èª¿è·¨é åå°å®¶å°çµå°æ¼ç¢çæ´æºç¢ºãå¬å¹³çè©®éè³ééè¦ï¼èéäºè©®éæ¯æ ¹ææ­·å²åèçµ¡èä¾çãè·¨é åå°çµè¨è«æå©æ¼æ¸å°åè¦ãæ¾åºæ½å¨çæ··æ·å ç´ ï¼ä¸¦å¨æç»ä¸­æç¼ºå£ææ¾åºé¡å¤ç ç©¶çæ©æãåéä¾ï¼éäºè¦è§£å¯ä»¥å»ºè­° AI æ¨¡åæ¹é²çæ©æã

##### **"It depends": Configuring AI to Improve Clinical Usefulness Across Contexts**
2407.11978v1 by Hubert D. ZajÄc, Jorge M. N. Ribeiro, Silvia Ingala, Simona Gentile, Ruth Wanjohi, Samuel N. Gitau, Jonathan F. Carlsen, Michael B. Nielsen, Tariq O. Andersen

Artificial Intelligence (AI) repeatedly match or outperform radiologists in
lab experiments. However, real-world implementations of radiological AI-based
systems are found to provide little to no clinical value. This paper explores
how to design AI for clinical usefulness in different contexts. We conducted 19
design sessions and design interventions with 13 radiologists from 7 clinical
sites in Denmark and Kenya, based on three iterations of a functional AI-based
prototype. Ten sociotechnical dependencies were identified as crucial for the
design of AI in radiology. We conceptualised four technical dimensions that
must be configured to the intended clinical context of use: AI functionality,
AI medical focus, AI decision threshold, and AI Explainability. We present four
design recommendations on how to address dependencies pertaining to the medical
knowledge, clinic type, user expertise level, patient context, and user
situation that condition the configuration of these technical dimensions.

æè¦ï¼äººå·¥æºæ§ï¼AIï¼å¨å¯¦é©å®¤å¯¦é©ä¸­ä¸æ·å°èæ¾å°ç§é«å¸«å¹æµæè¡¨ç¾å¾æ´åºè²ãç¶èï¼ç¼ç¾æ¾å°ç§ AI çºåºç¤ç³»çµ±çå¯¦éå·è¡å¹¾ä¹æ²ææä¾è¨åºå¹å¼ãæ¬ææ¢è¨å¦ä½çº AI è¨­è¨å¨ä¸åæå¢ä¸­è¨åºä¸çæç¨ãæåæ ¹æåè½æ§ AI çºåºç¤ååçä¸æ¬¡è¿­ä»£ï¼å¨ä¸¹éº¥åè¯äºç 7 åè¨åºå ´åè 13 ä½æ¾å°ç§é«å¸«é²è¡äº 19 æ¬¡è¨­è¨æè­°åè¨­è¨ä»å¥ãååç¤¾ææè¡ä¾è³´éä¿è¢«èªçºå°æ¼æ¾å°ç§ä¸­ AI çè¨­è¨è³ééè¦ãæåæ¦å¿µåäºååæè¡é¢åï¼å¿é æ ¹æé æçè¨åºä½¿ç¨æå¢é²è¡è¨­å®ï¼AI åè½ãAI é«çéé»ãAI æ±ºç­éæª»ï¼ä»¥å AI å¯è§£éæ§ãæåæåºåé è¨­è¨å»ºè­°ï¼èªªæå¦ä½èçèé«çç¥è­ãè¨ºæé¡åãä½¿ç¨èå°æ¥­ç¥è­ç­ç´ãæ£èæå¢ï¼ä»¥åå½±é¿éäºæè¡é¢åè¨­å®çä½¿ç¨èæå¢ç¸éçä¾è³´éä¿ã

##### **Improving Health Professionals' Onboarding with AI and XAI for Trustworthy Human-AI Collaborative Decision Making**
2405.16424v1 by Min Hun Lee, Silvana Xin Yi Choo, Shamala D/O Thilarajah

With advanced AI/ML, there has been growing research on explainable AI (XAI)
and studies on how humans interact with AI and XAI for effective human-AI
collaborative decision-making. However, we still have a lack of understanding
of how AI systems and XAI should be first presented to users without technical
backgrounds. In this paper, we present the findings of semi-structured
interviews with health professionals (n=12) and students (n=4) majoring in
medicine and health to study how to improve onboarding with AI and XAI. For the
interviews, we built upon human-AI interaction guidelines to create onboarding
materials of an AI system for stroke rehabilitation assessment and AI
explanations and introduce them to the participants. Our findings reveal that
beyond presenting traditional performance metrics on AI, participants desired
benchmark information, the practical benefits of AI, and interaction trials to
better contextualize AI performance, and refine the objectives and performance
of AI. Based on these findings, we highlight directions for improving
onboarding with AI and XAI and human-AI collaborative decision-making.

æè¦ï¼é¨èåé²ç AI/MLï¼å°å¯è§£é AI (XAI) çç ç©¶ä¸æ·å¢å ï¼ä»¥åéæ¼äººé¡å¦ä½è AI å XAI äºåä»¥é²è¡ææçäººå·¥æºæ§åä½æ±ºç­å¶å®ãç¶èï¼æåä»ç¶ç¼ºä¹å° AI ç³»çµ±å XAI æå¦ä½é¦ååç¾çµ¦æ²ææè¡èæ¯çç¨æ¶çäºè§£ãå¨æ¬æä¸­ï¼æåå±ç¤ºäºèé«çå°æ¥­äººå¡ (n=12) åä¸»ä¿®é«å­¸åå¥åº·çå­¸ç (n=4) é²è¡åçµæ§åè¨ªè«ççµæï¼ä»¥ç ç©¶å¦ä½æ¹å AI å XAI çå¥éãå°æ¼è¨ªè«ï¼æåå»ºç«å¨äººæ©äºåæºåä¹ä¸ï¼çºä¸­é¢¨åº·å¾©è©ä¼°å AI è§£éç AI ç³»çµ±åµå»ºå¥éææï¼ä¸¦å°å®åä»ç´¹çµ¦åèèãæåçç ç©¶çµæè¡¨æï¼é¤äºåç¾å³çµ±ç AI æ§è½ææ¨å¤ï¼åèèéå¸æåºåä¿¡æ¯ãAI çå¯¦éå¥½èä»¥åäº¤äºè©¦é©ï¼ä»¥æ´å¥½å°å° AI æ§è½æå¢åï¼ä¸¦å®å AI çç®æ¨åæ§è½ãæ ¹æéäºç¼ç¾ï¼æåå¼·èª¿äºæ¹é² AI å XAI ä»¥åäººæ©åä½æ±ºç­å¶å®çå¥éæ¹åã

##### **Exploring Nutritional Impact on Alzheimer's Mortality: An Explainable AI Approach**
2405.17502v1 by Ziming Liu, Longjian Liu, Robert E. Heidel, Xiaopeng Zhao

This article uses machine learning (ML) and explainable artificial
intelligence (XAI) techniques to investigate the relationship between
nutritional status and mortality rates associated with Alzheimers disease (AD).
The Third National Health and Nutrition Examination Survey (NHANES III)
database is employed for analysis. The random forest model is selected as the
base model for XAI analysis, and the Shapley Additive Explanations (SHAP)
method is used to assess feature importance. The results highlight significant
nutritional factors such as serum vitamin B12 and glycated hemoglobin. The
study demonstrates the effectiveness of random forests in predicting AD
mortality compared to other diseases. This research provides insights into the
impact of nutrition on AD and contributes to a deeper understanding of disease
progression.

æè¦ï¼æ¬æä½¿ç¨æ©å¨å­¸ç¿ (ML) åå¯è§£éäººå·¥æºæ§ (XAI) æè¡ä¾æ¢è¨çé¤çæ³èé¿è²æµ·é»ç (AD) ç¸éçæ­»äº¡çä¹éçéä¿ãæ¡ç¨ç¬¬ä¸æ¬¡å¨åå¥åº·èçé¤æª¢æ¥èª¿æ¥ (NHANES III) è³æåº«é²è¡åæãé¸æé¨æ©æ£®ææ¨¡åä½çº XAI åæçåºç¤æ¨¡åï¼ä¸¦ä½¿ç¨ Shapley Additive Explanations (SHAP) æ¹æ³ä¾è©ä¼°ç¹å¾µéè¦æ§ãçµæçªé¡¯äºéè¦ççé¤å ç´ ï¼ä¾å¦è¡æ¸ç¶­çç´  B12 åç³åè¡ç´èç½ãè©²ç ç©¶è­æäºé¨æ©æ£®æå¨é æ¸¬ AD æ­»äº¡çæ¹é¢ç¸è¼æ¼å¶ä»ç¾ççæææ§ãæ¬ç ç©¶æä¾äºçé¤å° AD çå½±é¿çè¦è§£ï¼ä¸¦æå©æ¼æ´æ·±å¥å°äºè§£ç¾ççé²å±ã

##### **Explainable AI Enhances Glaucoma Referrals, Yet the Human-AI Team Still Falls Short of the AI Alone**
2407.11974v1 by Catalina Gomez, Ruolin Wang, Katharina Breininger, Corinne Casey, Chris Bradley, Mitchell Pavlak, Alex Pham, Jithin Yohannan, Mathias Unberath

Primary care providers are vital for initial triage and referrals to
specialty care. In glaucoma, asymptomatic and fast progression can lead to
vision loss, necessitating timely referrals to specialists. However, primary
eye care providers may not identify urgent cases, potentially delaying care.
Artificial Intelligence (AI) offering explanations could enhance their referral
decisions. We investigate how various AI explanations help providers
distinguish between patients needing immediate or non-urgent specialist
referrals. We built explainable AI algorithms to predict glaucoma surgery needs
from routine eyecare data as a proxy for identifying high-risk patients. We
incorporated intrinsic and post-hoc explainability and conducted an online
study with optometrists to assess human-AI team performance, measuring referral
accuracy and analyzing interactions with AI, including agreement rates, task
time, and user experience perceptions. AI support enhanced referral accuracy
among 87 participants (59.9%/50.8% with/without AI), though Human-AI teams
underperformed compared to AI alone. Participants believed they included AI
advice more when using the intrinsic model, and perceived it more useful and
promising. Without explanations, deviations from AI recommendations increased.
AI support did not increase workload, confidence, and trust, but reduced
challenges. On a separate test set, our black-box and intrinsic models achieved
an accuracy of 77% and 71%, respectively, in predicting surgical outcomes. We
identify opportunities of human-AI teaming for glaucoma management in primary
eye care, noting that while AI enhances referral accuracy, it also shows a
performance gap compared to AI alone, even with explanations. Human involvement
remains essential in medical decision making, underscoring the need for future
research to optimize collaboration, ensuring positive experiences and safe AI
use.

æè¦ï¼<paragraph>åç´ä¿å¥æä¾èå°æ¼æåçåæµåè½è¨ºå°å°ç§ç§è­·è³ééè¦ãå¨éåç¼çææ³ä¸ï¼ç¡ççä¸å¿«éæ¡åå¯è½å°è´è¦ååªå¤±ï¼å æ­¤éè¦åæè½è¨ºçµ¦å°å®¶ãç¶èï¼åç´ç¼ç§ä¿å¥æä¾èå¯è½ç¡æ³è­å¥ç·æ¥ææ³ï¼å¯è½æå»¶èª¤ç§è­·ãæä¾è§£éçäººå·¥æºæ§ (AI) å¯ä»¥å å¼·ä»åçè½è¨ºæ±ºç­ãæåç ç©¶åç¨® AI è§£éå¦ä½å¹«å©æä¾èååéè¦ç«å³æéç·æ¥å°ç§è½è¨ºçæ£èãæåå»ºç«äºè§£éæ§ AI æ¼ç®æ³ï¼ä»¥å¾ä¾è¡ç¼ç§è­·çè³æé æ¸¬éåç¼æè¡éæ±ï¼ä½çºè­å¥é«é¢¨éªæ£èçä»£çãæåç´å¥äºå§å¨åäºå¾è§£éæ§ï¼ä¸¦èé©åå¸«é²è¡äºä¸é ç·ä¸ç ç©¶ï¼ä»¥è©ä¼°äººæ©åéçè¡¨ç¾ï¼è¡¡éè½è¨ºæºç¢ºåº¦ä¸¦åæè AI çäºåï¼åæ¬åæçãä»»åæéåä½¿ç¨èé«é©æç¥ãå¨ 87 ååèèä¸­ï¼AI æ¯æ´æé«äºè½è¨ºæºç¢ºåº¦ï¼ä½¿ç¨ AI/æªä½¿ç¨çæ¯ä¾çº 59.9%/50.8%ï¼ï¼åç®¡äººæ©åéçè¡¨ç¾ä¸å¦å®ç¨ä½¿ç¨ AIãåèèèªçºä»åå¨ä½¿ç¨å§å¨æ¨¡åææ´å¤å°ç´å¥äº AI å»ºè­°ï¼ä¸¦èªçºå®æ´æç¨ä¸æ´æå¸æãæ²æè§£éï¼AI å»ºè­°çåå·®æå¢å ãAI æ¯æ´ä¸¦æªå¢å å·¥ä½éãä¿¡å¿åä¿¡ä»»ï¼ä½æ¸å°äºææ°ãå¨ä¸åå®ç¨çæ¸¬è©¦éä¸­ï¼æåçé»çå­åå§å¨æ¨¡åå¨é æ¸¬æè¡çµææ¹é¢åå¥éå°äº 77% å 71% çæºç¢ºåº¦ãæåæ¾åºå¨åç´ç¼ç§ä¿å¥ä¸­ï¼äººæ©åéåä½ç®¡çéåç¼çæ©æï¼ä¸¦æ³¨æå°éç¶ AI æé«äºè½è¨ºæºç¢ºåº¦ï¼ä½å³ä½¿æè§£éï¼å®ä¹é¡¯ç¤ºåºèå®ç¨ä½¿ç¨ AI ç¸æ¯çæè½å·®è·ãäººé¡åèå¨é«çæ±ºç­ä¸­ä»ç¶è³ééè¦ï¼éå¼·èª¿äºæªä¾ç ç©¶åªååä½ãç¢ºä¿æ­£é¢ç¶é©åå®å¨ä½¿ç¨ AI çå¿è¦æ§ã</paragraph>

##### **Decoding Decision Reasoning: A Counterfactual-Powered Model for Knowledge Discovery**
2406.18552v1 by Yingying Fang, Zihao Jin, Xiaodan Xing, Simon Walsh, Guang Yang

In medical imaging, particularly in early disease detection and prognosis
tasks, discerning the rationale behind an AI model's predictions is crucial for
evaluating the reliability of its decisions. Conventional explanation methods
face challenges in identifying discernible decisive features in medical image
classifications, where discriminative features are subtle or not immediately
apparent. To bridge this gap, we propose an explainable model that is equipped
with both decision reasoning and feature identification capabilities. Our
approach not only detects influential image patterns but also uncovers the
decisive features that drive the model's final predictions. By implementing our
method, we can efficiently identify and visualise class-specific features
leveraged by the data-driven model, providing insights into the decision-making
processes of deep learning models. We validated our model in the demanding
realm of medical prognosis task, demonstrating its efficacy and potential in
enhancing the reliability of AI in healthcare and in discovering new knowledge
in diseases where prognostic understanding is limited.

æè¦ï¼å¨é«å­¸å½±åä¸­ï¼ç¹å¥æ¯å¨æ©æç¾çæª¢æ¸¬åé å¾ä»»åä¸­ï¼è¾¨å¥ AI æ¨¡åé æ¸¬èå¾çåçå°æ¼è©ä¼°å¶æ±ºç­çå¯é æ§è³ééè¦ãå³çµ±çè§£éæ¹æ³å¨è­å¥é«å­¸å½±ååé¡ä¸­å¯è­å¥çæ±ºå®æ§ç¹å¾µæé¢è¨ææ°ï¼å¶ä¸­åå¥æ§ç¹å¾µå¾å¾®å¦æä¸¦ä¸æé¡¯ãçºäºå½åéä¸å·®è·ï¼æåæåºäºä¸åå¯è§£éçæ¨¡åï¼è©²æ¨¡åå·åæ±ºç­æ¨çåç¹å¾µè­å¥è½åãæåçåæ³ä¸åæª¢æ¸¬æå½±é¿åçå½±åæ¨¡å¼ï¼éæ­ç¤ºäºæ¨åæ¨¡åæçµé æ¸¬çæ±ºå®æ§ç¹å¾µãééå¯¦æ½æåçæ¨¡åï¼æåå¯ä»¥ææè­å¥åè¦è¦ºåç±æ¸æé©åæ¨¡åå©ç¨çé¡ç¹å®ç¹å¾µï¼å¾èæ·±å¥äºè§£æ·±åº¦å­¸ç¿æ¨¡åçæ±ºç­éç¨ãæåå¨è¦æ±å´æ ¼çé«å­¸é å¾ä»»åé åé©è­äºæåçæ¨¡åï¼å±ç¤ºäºå¶å¨æé« AI å¨é«çä¿å¥ä¸­çå¯é æ§åç¼ç¾é å¾çè§£åéç¾ççæ°ç¥è­æ¹é¢çåæåæ½åã

##### **The Role of Emotions in Informational Support Question-Response Pairs in Online Health Communities: A Multimodal Deep Learning Approach**
2405.13099v1 by Mohsen Jozani, Jason A. Williams, Ahmed Aleroud, Sarbottam Bhagat

This study explores the relationship between informational support seeking
questions, responses, and helpfulness ratings in online health communities. We
created a labeled data set of question-response pairs and developed multimodal
machine learning and deep learning models to reliably predict informational
support questions and responses. We employed explainable AI to reveal the
emotions embedded in informational support exchanges, demonstrating the
importance of emotion in providing informational support. This complex
interplay between emotional and informational support has not been previously
researched. The study refines social support theory and lays the groundwork for
the development of user decision aids. Further implications are discussed.

æè¦ï¼æ¬ç ç©¶æ¢è¨ç·ä¸å¥åº·ç¤¾ç¾¤ä¸­å°æ±è³è¨æ¯æçåé¡ãåæï¼ä»¥åæå¹«å©çè©åä¹éçéä¿ãæåå»ºç«äºä¸çµæ¨è¨çåç­éå°è³æéï¼ä¸¦éç¼äºå¤æ¨¡ææ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿æ¨¡åï¼ä»¥å¯é å°é æ¸¬è³è¨æ¯æåé¡ååæãæåæ¡ç¨å¯è§£éç AI ä¾æ­ç¤ºè³è¨æ¯æäº¤æµä¸­èå«çæç·ï¼è­ææç·å¨æä¾è³è¨æ¯æä¸­çéè¦æ§ãéç¨®æç·æ¯æåè³è¨æ¯æä¹éçè¤éäº¤äºä½ç¨ä»¥åä¸¦æªè¢«ç ç©¶éãæ¬ç ç©¶æ¹é²äºç¤¾ææ¯æçè«ï¼ä¸¦çºä½¿ç¨èæ±ºç­è¼å©å·¥å·çéç¼å¥ å®äºåºç¤ãè¨è«äºé²ä¸æ­¥çå½±é¿ã

##### **ChatGPT in Classrooms: Transforming Challenges into Opportunities in Education**
2405.10645v1 by Harris Bin Munawar, Nikolaos Misirlis

In the era of exponential technology growth, one unexpected guest has claimed
a seat in classrooms worldwide, Artificial Intelligence. Generative AI, such as
ChatGPT, promises a revolution in education, yet it arrives with a double-edged
sword. Its potential for personalized learning is offset by issues of cheating,
inaccuracies, and educators struggling to incorporate it effectively into their
lesson design. We are standing on the brink of this educational frontier, and
it is clear that we need to navigate this terrain with a lot of care. This is a
major challenge that could undermine the integrity and value of our educational
process. So, how can we turn these challenges into opportunities? When used
inappropriately, AI tools can become the perfect tool for the cut copy paste
mentality, and quickly begin to corrode critical thinking, creativity, and deep
understanding, the most important skills in our rapidly changing world.
Teachers feel that they are not equipped to leverage this technology, widening
the digital divide among educators and institutions. Addressing these concerns
calls for an in depth research approach. We will employ empirical research,
drawing on the Technology Acceptance Model, to assess the attitudes toward
generative AI among educators and students. Understanding their perceptions,
usage patterns, and hurdles is the first crucial step in creating an effective
solution. The present study will be used as a process manual for future
researchers to apply, running their own data, based on the steps explained here

æè¦ï¼å¨ç§æé£éç¼å±çæä»£ï¼ä¸ä½æå¤çè¨ªå®¢å·²å¨å¨çæå®¤ä¸­ä½æä¸å¸­ä¹å°ï¼é£å°±æ¯äººå·¥æºæ§ãçæå¼ AIï¼ä¾å¦ ChatGPTï¼æ¿è«¾å¨æè²é åæèµ·ä¸å ´é©å½ï¼ä½å®å»æ¯ä¸æéé¢åãå®å¨åäººåå­¸ç¿æ¹é¢çæ½åï¼å»å ä½å¼ãä¸æºç¢ºä»¥åæè²å·¥ä½èé£ä»¥å°å¶ææèå¥æå­¸è¨­è¨ç­åé¡èæµé·ãæåæ­£ç«å¨éæè²åæ²¿çéç·£ï¼é¡¯ç¶æåéè¦éå¸¸å°å¿å°æ¢ç´¢éçé åãéæ¯ä¸åéå¤§çææ°ï¼å¯è½ææå®³æåæè²éç¨çå®æ´æ§åå¹å¼ãé£éº¼ï¼æåå¦ä½å°éäºææ°è½åçºæ©éï¼ç¶ä¸é©ç¶å°ä½¿ç¨æï¼AI å·¥å·å¯è½ææçºè¤è£½è²¼ä¸å¿æçå®ç¾å·¥å·ï¼ä¸¦è¿éèèæ¹å¤æ§æç¶­ãåµé ååæ·±å¥çè§£ï¼éäºé½æ¯æåå¿«éè®åçä¸çä¸­æéè¦çæè½ãæå¸«åè¦ºå¾ä»åæ²æè½åå©ç¨éé æè¡ï¼éæ´å¤§äºæè²å·¥ä½èåæ©æ§ä¹éçæ¸ä½é´»æºãè§£æ±ºéäºåé¡éè¦æ·±å¥çç ç©¶æ¹æ³ãæåå°æ¡ç¨å¯¦è­ç ç©¶ï¼åéæè¡æ¥åæ¨¡åï¼ä¾è©ä¼°æè²å·¥ä½èåå­¸çå°çæå¼ AI çæåº¦ãäºè§£ä»åççæ³ãä½¿ç¨æ¨¡å¼åéç¤æ¯åµé ææè§£æ±ºæ¹æ¡çç¬¬ä¸åééµæ­¥é©ãæ¬ç ç©¶å°ä½çºæªä¾ç ç©¶äººå¡æç¨çæµç¨æåï¼æ ¹ææ­¤èèªªæçæ­¥é©éè¡ä»åèªå·±çæ¸æ

##### **Evaluating the Explainable AI Method Grad-CAM for Breath Classification on Newborn Time Series Data**
2405.07590v1 by Camelia Oprea, Mike GrÃ¼ne, Mateusz Buglowski, Lena Olivier, Thorsten Orlikowsky, Stefan Kowalewski, Mark Schoberer, AndrÃ© Stollenwerk

With the digitalization of health care systems, artificial intelligence
becomes more present in medicine. Especially machine learning shows great
potential for complex tasks such as time series classification, usually at the
cost of transparency and comprehensibility. This leads to a lack of trust by
humans and thus hinders its active usage. Explainable artificial intelligence
tries to close this gap by providing insight into the decision-making process,
the actual usefulness of its different methods is however unclear. This paper
proposes a user study based evaluation of the explanation method Grad-CAM with
application to a neural network for the classification of breaths in time
series neonatal ventilation data. We present the perceived usefulness of the
explainability method by different stakeholders, exposing the difficulty to
achieve actual transparency and the wish for more in-depth explanations by many
of the participants.

æè¦ï¼é¨èé«çä¿å¥ç³»çµ±çæ¸ä½åï¼äººå·¥æºæ§å¨é«å­¸é åä¸­è®å¾æ´å æ®åãç¹å¥æ¯æ©å¨å­¸ç¿å¨æéåºååé¡ç­è¤éä»»åä¸­å±ç¾åºæ¥µå¤§çæ½åï¼ä½éå¸¸æ¯ä»¥éæåº¦åå¯çè§£æ§çºä»£å¹ãéå°è´äººé¡ç¼ºä¹ä¿¡ä»»ï¼å¾èé»ç¤äºå¶ç©æ¥µä½¿ç¨ãå¯è§£éçäººå·¥æºæ§è©¦åééæä¾å°æ±ºç­éç¨çæ´å¯ä¾å½è£éä¸å·®è·ï¼ä½å¶ä¸åæ¹æ³çå¯¦éæç¨å°ä¸æ¸æ¥ãæ¬ææåºäºä¸ååºæ¼ä½¿ç¨èç ç©¶çè©ä¼°ï¼å¶ä¸­åå«äº Grad-CAM è§£éæ¹æ³ï¼ä¸¦å°å¶æç¨æ¼ç¥ç¶ç¶²è·¯ä»¥åé¡æéåºåæ°çåå¼å¸æ¸æä¸­çå¼å¸ãæåå±ç¤ºäºä¸åå©çç¸éèå°å¯è§£éæ§æ¹æ³çæç¥æç¨ï¼æ­ç¤ºäºå¯¦ç¾å¯¦ééæåº¦çé£åº¦ï¼ä»¥åè¨±å¤åèèå¸æç²å¾æ´æ·±å¥çè§£éã

##### **XAI4LLM. Let Machine Learning Models and LLMs Collaborate for Enhanced In-Context Learning in Healthcare**
2405.06270v3 by Fatemeh Nazary, Yashar Deldjoo, Tommaso Di Noia, Eugenio di Sciascio

The integration of Large Language Models (LLMs) into healthcare diagnostics
offers a promising avenue for clinical decision-making. This study outlines the
development of a novel method for zero-shot/few-shot in-context learning (ICL)
by integrating medical domain knowledge using a multi-layered structured
prompt. We also explore the efficacy of two communication styles between the
user and LLMs: the Numerical Conversational (NC) style, which processes data
incrementally, and the Natural Language Single-Turn (NL-ST) style, which
employs long narrative prompts.
  Our study systematically evaluates the diagnostic accuracy and risk factors,
including gender bias and false negative rates, using a dataset of 920 patient
records in various few-shot scenarios. Results indicate that traditional
clinical machine learning (ML) models generally outperform LLMs in zero-shot
and few-shot settings. However, the performance gap narrows significantly when
employing few-shot examples alongside effective explainable AI (XAI) methods as
sources of domain knowledge. Moreover, with sufficient time and an increased
number of examples, the conversational style (NC) nearly matches the
performance of ML models. Most notably, LLMs demonstrate comparable or superior
cost-sensitive accuracy relative to ML models.
  This research confirms that, with appropriate domain knowledge and tailored
communication strategies, LLMs can significantly enhance diagnostic processes.
The findings highlight the importance of optimizing the number of training
examples and communication styles to improve accuracy and reduce biases in LLM
applications.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) èé«çè¨ºæ·æ´å
çºè¨åºæ±ºç­æä¾äºä¸åæåæ¯çéå¾ãæ¬ç ç©¶æ¦è¿°äºä¸ç¨®æ°ç©æ¹æ³çéç¼ï¼ç¨æ¼é¶æ¬¡å­¸ç¿/å°éå­¸ç¿æå¢å­¸ç¿ (ICL)ï¼æ¹æ³æ¯ä½¿ç¨å¤å±¤çµæ§åæç¤ºæ´åé«çé åç¥è­ãæåéæ¢è¨äºä½¿ç¨èè LLM ä¹éå©ç¨®æºéæ¹å¼çåæï¼æ¸å¼å°è©± (NC) æ¹å¼ï¼å®æéæ­¥èçè³æï¼ä»¥åèªç¶èªè¨å®åå (NL-ST) æ¹å¼ï¼å®æä½¿ç¨é·ç¯æäºæç¤ºã
æåçç ç©¶ç³»çµ±æ§å°è©ä¼°äºè¨ºæ·æºç¢ºæ§åé¢¨éªå å­ï¼åæ¬æ§å¥åè¦ååé°æ§çï¼ä½¿ç¨äºä¸ååå« 920 åæ£èè¨éçè³æéï¼æ¡ç¨åç¨®å°éå­¸ç¿æå¢ãçµæè¡¨æï¼å³çµ±çè¨åºæ©å¨å­¸ç¿ (ML) æ¨¡åéå¸¸å¨é¶æ¬¡å­¸ç¿åå°éå­¸ç¿è¨­å®ä¸­è¡¨ç¾åªæ¼ LLMãç¶èï¼ç¶ä½¿ç¨å°éå­¸ç¿ç¯ä¾ä»¥åææçå¯è§£é AI (XAI) æ¹æ³ä½çºé åç¥è­ä¾æºæï¼æè½å·®è·æé¡¯èç¸®å°ãæ­¤å¤ï¼é¨èæéåè¶³åç¯ä¾æ¸éå¢å ï¼å°è©±æ¹å¼ (NC) å¹¾ä¹å¯ä»¥åª²ç¾ ML æ¨¡åçæè½ãæå¼å¾æ³¨æçæ¯ï¼LLM ç¸å°æ¼ ML æ¨¡åå±ç¾åºç¸ç¶ææ´ä½³çææ¬æææºç¢ºåº¦ã
æ¬ç ç©¶è­å¯¦ï¼ééé©ç¶çé åç¥è­åéèº«æé çæºéç­ç¥ï¼LLM å¯ä»¥é¡¯èå¢å¼·è¨ºæ·ç¨åºãéäºç¼ç¾çªé¡¯äºæä½³åè¨ç·´ç¯ä¾æ¸éåæºéæ¹å¼çéè¦æ§ï¼ä»¥æé«æºç¢ºåº¦ä¸¦æ¸å° LLM æç¨ä¸­çåå·®ã

##### **To Trust or Not to Trust: Towards a novel approach to measure trust for XAI systems**
2405.05766v1 by Miquel MirÃ³-Nicolau, Gabriel MoyÃ -Alcover, Antoni Jaume-i-CapÃ³, Manuel GonzÃ¡lez-Hidalgo, Maria Gemma Sempere Campello, Juan Antonio Palmer Sancho

The increasing reliance on Deep Learning models, combined with their inherent
lack of transparency, has spurred the development of a novel field of study
known as eXplainable AI (XAI) methods. These methods seek to enhance the trust
of end-users in automated systems by providing insights into the rationale
behind their decisions. This paper presents a novel approach for measuring user
trust in XAI systems, allowing their refinement. Our proposed metric combines
both performance metrics and trust indicators from an objective perspective. To
validate this novel methodology, we conducted a case study in a realistic
medical scenario: the usage of XAI system for the detection of pneumonia from
x-ray images.

æè¦ï¼é¨èå°æ·±åº¦å­¸ç¿æ¨¡åä¾è³´æ§çå¢å ï¼å ä¸å¶åºæçéæåº¦ä¸è¶³ï¼ä¿ä½¿ä¸åæ°çç ç©¶é åç¼å±ï¼ç¨±çºå¯è§£é AI (XAI) æ¹æ³ãéäºæ¹æ³æ¨å¨ééæ·±å¥äºè§£æ±ºç­èå¾çåçï¼ä¾æåæçµä½¿ç¨èå°èªååç³»çµ±çä¿¡è³´ãæ¬ææåºäºä¸ç¨®è¡¡éä½¿ç¨èå° XAI ç³»çµ±ä¿¡è³´åº¦çæ°ç©æ¹æ³ï¼åè¨±å°å¶é²è¡æ¹é²ãæåæåºçææ¨çµåäºå®¢è§è§é»ä¸çæè½ææ¨åä¿¡è³´ææ¨ãçºäºé©è­éåæ°ç©çæ¹æ³ï¼æåå¨ä¸åçå¯¦çé«çå ´æ¯ä¸­é²è¡äºä¸åæ¡ä¾ç ç©¶ï¼ä½¿ç¨ XAI ç³»çµ±å¾ X åå½±åä¸­åµæ¸¬èºçã

##### **Region-specific Risk Quantification for Interpretable Prognosis of COVID-19**
2405.02815v1 by Zhusi Zhong, Jie Li, Zhuoqi Ma, Scott Collins, Harrison Bai, Paul Zhang, Terrance Healey, Xinbo Gao, Michael K. Atalay, Zhicheng Jiao

The COVID-19 pandemic has strained global public health, necessitating
accurate diagnosis and intervention to control disease spread and reduce
mortality rates. This paper introduces an interpretable deep survival
prediction model designed specifically for improved understanding and trust in
COVID-19 prognosis using chest X-ray (CXR) images. By integrating a large-scale
pretrained image encoder, Risk-specific Grad-CAM, and anatomical region
detection techniques, our approach produces regional interpretable outcomes
that effectively capture essential disease features while focusing on rare but
critical abnormal regions. Our model's predictive results provide enhanced
clarity and transparency through risk area localization, enabling clinicians to
make informed decisions regarding COVID-19 diagnosis with better understanding
of prognostic insights. We evaluate the proposed method on a multi-center
survival dataset and demonstrate its effectiveness via quantitative and
qualitative assessments, achieving superior C-indexes (0.764 and 0.727) and
time-dependent AUCs (0.799 and 0.691). These results suggest that our
explainable deep survival prediction model surpasses traditional survival
analysis methods in risk prediction, improving interpretability for clinical
decision making and enhancing AI system trustworthiness.

æè¦ï¼COVID-19 ç«æå°å¨çå¬å±è¡çé æå£åï¼å¿é é²è¡æºç¢ºçè¨ºæ·åå¹²é ï¼ä»¥æ§å¶ç¾çå³æ­ä¸¦éä½æ­»äº¡çãæ¬æä»ç´¹äºä¸åå¯è§£éçæ·±åº¦çå­é æ¸¬æ¨¡åï¼å°éè¨­è¨ç¨æ¼ééè¸é¨ X å (CXR) å½±åæ¹åå° COVID-19 é å¾ççè§£åä¿¡è³´ãééæ´åå¤§è¦æ¨¡é è¨ç·´å½±åç·¨ç¢¼å¨ãé¢¨éªç¹å® Grad-CAM åè§£ååååµæ¸¬æè¡ï¼æåçåæ³ç¢çååå¯è§£éççµæï¼ææææå¿è¦çç¾çç¹å¾µï¼åæå°æ³¨æ¼ç½è¦ä½ééµçç°å¸¸ååãæåçæ¨¡åé æ¸¬çµæééé¢¨éªååå®ä½æä¾å¢å¼·çæ¸æ°åº¦åéæåº¦ï¼è®è¨åºé«çè½å¤ å¨æ´äºè§£é å¾è¦è§£çææ³ä¸ï¼å°± COVID-19 è¨ºæ·ååºææºçæ±ºç­ãæåå¨å¤ä¸­å¿çå­è³æéä¸è©ä¼°ææåºçæ¹æ³ï¼ä¸¦éééååè³ªåè©ä¼°è­æå¶æææ§ï¼éå°åªç°ç C ææ¸ï¼0.764 å 0.727ï¼åæéç¸é AUCï¼0.799 å 0.691ï¼ãéäºçµæè¡¨æï¼æåå¯è§£éçæ·±åº¦çå­é æ¸¬æ¨¡åå¨é¢¨éªé æ¸¬æ¹é¢è¶è¶å³çµ±ççå­åææ¹æ³ï¼æåè¨åºæ±ºç­çè§£éæ§ï¼ä¸¦å¢å¼· AI ç³»çµ±çä¿¡è³´åº¦ã

##### **Rad4XCNN: a new agnostic method for post-hoc global explanation of CNN-derived features by means of radiomics**
2405.02334v1 by Francesco Prinzi, Carmelo Militello, Calogero Zarcaro, Tommaso Vincenzo Bartolotta, Salvatore Gaglio, Salvatore Vitabile

In the last years, artificial intelligence (AI) in clinical decision support
systems (CDSS) played a key role in harnessing machine learning and deep
learning architectures. Despite their promising capabilities, the lack of
transparency and explainability of AI models poses significant challenges,
particularly in medical contexts where reliability is a mandatory aspect.
Achieving transparency without compromising predictive accuracy remains a key
challenge. This paper presents a novel method, namely Rad4XCNN, to enhance the
predictive power of CNN-derived features with the interpretability inherent in
radiomic features. Rad4XCNN diverges from conventional methods based on
saliency map, by associating intelligible meaning to CNN-derived features by
means of Radiomics, offering new perspectives on explanation methods beyond
visualization maps. Using a breast cancer classification task as a case study,
we evaluated Rad4XCNN on ultrasound imaging datasets, including an online
dataset and two in-house datasets for internal and external validation. Some
key results are: i) CNN-derived features guarantee more robust accuracy when
compared against ViT-derived and radiomic features; ii) conventional
visualization map methods for explanation present several pitfalls; iii)
Rad4XCNN does not sacrifice model accuracy for their explainability; iv)
Rad4XCNN provides global explanation insights enabling the physician to analyze
the model outputs and findings. In addition, we highlight the importance of
integrating interpretability into AI models for enhanced trust and adoption in
clinical practice, emphasizing how our method can mitigate some concerns
related to explainable AI methods.

æè¦ï¼<paragraph>å¨éå»å¹¾å¹´ï¼è¨åºæ±ºç­æ¯æ´ç³»çµ± (CDSS) ä¸­çäººå·¥æºæ§ (AI) å¨å©ç¨æ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿æ¶æ§æ¹é¢ç¼æ®äºééµä½ç¨ãåç®¡ AI æ¨¡åå·æä»¤äººæ»¿æçè½åï¼ä½ç¼ºä¹éæåº¦åå¯è§£éæ§ï¼ç¹å¥æ¯å¨å¯é æ§çºå¿è¦èéçé«çèæ¯ä¸ï¼éå¸¶ä¾äºéå¤§çææ°ãå¨ä¸å½±é¿é æ¸¬ç²¾æºåº¦çææ³ä¸å¯¦ç¾éæåº¦ä»ç¶æ¯ä¸é ééµææ°ãæ¬ææåºäºä¸ç¨®æ°æ¹æ³ï¼å³ Rad4XCNNï¼ä»¥å¢å¼· CNN è¡çç¹å¾µçé æ¸¬è½åï¼åæå·åæ¾å°ç¹å¾µåºæçå¯è§£éæ§ãRad4XCNN ä¸åæ¼åºæ¼é¡¯èæ§åçå³çµ±æ¹æ³ï¼å®ééæ¾å°çµå­¸å°å¯çè§£çå«ç¾©è CNN è¡çç¹å¾µéè¯èµ·ä¾ï¼çºè¶è¶è¦è¦ºååè¡¨çè§£éæ¹æ³æä¾äºæ°çè§é»ãæåä»¥ä¹³çåé¡ä»»åä½çºæ¡ä¾ç ç©¶ï¼å¨è¶é³æ³¢å½±åè³æéä¸è©ä¼° Rad4XCNNï¼åæ¬ä¸åç·ä¸è³æéåå©åç¨æ¼å§é¨åå¤é¨é©è­çå§é¨è³æéãä¸äºééµçµæå¦ä¸ï¼i) è ViT è¡çç¹å¾µåæ¾å°ç¹å¾µç¸æ¯ï¼CNN è¡çç¹å¾µä¿è­äºæ´ç©©å¥çæºç¢ºåº¦ï¼ii) å³çµ±çè¦è¦ºååè§£éæ¹æ³å­å¨ä¸äºç¼ºé·ï¼iii) Rad4XCNN æ²æç§ç²æ¨¡åæºç¢ºåº¦ä¾æåå¶å¯è§£éæ§ï¼iv) Rad4XCNN æä¾äºå¨å±è§£éè¦è§£ï¼ä½¿é«å¸«è½å¤ åææ¨¡åè¼¸åºåç¼ç¾ãæ­¤å¤ï¼æåå¼·èª¿å°å¯è§£éæ§æ´åå° AI æ¨¡åä¸­å°æ¼å¢å¼·è¨åºå¯¦åä¸­çä¿¡ä»»åæ¡ç¨è³ééè¦ï¼ä¸¦å¼·èª¿äºæåçæ¹æ³å¦ä½è½ç·©è§£èå¯è§£é AI æ¹æ³ç¸éçä¸äºçæ®ã</paragraph>

##### **Attributing Responsibility in AI-Induced Incidents: A Computational Reflective Equilibrium Framework for Accountability**
2404.16957v1 by Yunfei Ge, Quanyan Zhu

The pervasive integration of Artificial Intelligence (AI) has introduced
complex challenges in the responsibility and accountability in the event of
incidents involving AI-enabled systems. The interconnectivity of these systems,
ethical concerns of AI-induced incidents, coupled with uncertainties in AI
technology and the absence of corresponding regulations, have made traditional
responsibility attribution challenging. To this end, this work proposes a
Computational Reflective Equilibrium (CRE) approach to establish a coherent and
ethically acceptable responsibility attribution framework for all stakeholders.
The computational approach provides a structured analysis that overcomes the
limitations of conceptual approaches in dealing with dynamic and multifaceted
scenarios, showcasing the framework's explainability, coherence, and adaptivity
properties in the responsibility attribution process. We examine the pivotal
role of the initial activation level associated with claims in equilibrium
computation. Using an AI-assisted medical decision-support system as a case
study, we illustrate how different initializations lead to diverse
responsibility distributions. The framework offers valuable insights into
accountability in AI-induced incidents, facilitating the development of a
sustainable and resilient system through continuous monitoring, revision, and
reflection.

æè¦ï¼é¨èäººå·¥æºæ§ (AI) çæ®åæ´åï¼å¨æ¶å AI é©åç³»çµ±çäºæä¸­ï¼è²¬ä»»åç¾©åæ­¸å±¬ç¢çäºè¤éçææ°ãéäºç³»çµ±çäºé£æ§ãAI å¼ç¼äºæçå«çåé¡ï¼å ä¸ AI æè¡çä¸ç¢ºå®æ§åç¼ºä¹ç¸ææ³è¦ï¼ä½¿å¾å³çµ±è²¬ä»»æ­¸å±¬é¢è¨ææ°ãçºæ­¤ï¼æ¬ç ç©¶æåºäºä¸ç¨®è¨ç®åæåè¡¡ (CRE) æ¹æ³ï¼ä»¥å»ºç«ä¸åé£è²«ä¸å¨å«çä¸å¯æ¥åçè²¬ä»»æ­¸å±¬æ¶æ§ï¼é©ç¨æ¼ææå©å®³éä¿äººãè¨ç®æ¹æ³æä¾äºçµæ§åçåæï¼åæäºæ¦å¿µæ¹æ³å¨èçåæä¸å¤é¢åæå¢æçéå¶ï¼å±ç¤ºäºè©²æ¶æ§å¨è²¬ä»»æ­¸å±¬éç¨ä¸­å·åçå¯è§£éæ§ãé£è²«æ§åé©ææ§ãæåæ¢è¨äºèåè¡¡è¨ç®ä¸­ç´¢è³ ç¸éçåå§ååå±¤ç´çééµä½ç¨ãæåä»¥ AI è¼å©é«çæ±ºç­æ¯æ´ç³»çµ±çºæ¡ä¾ç ç©¶ï¼èªªæä¸åçåå§åå¦ä½å°è´ä¸åçè²¬ä»»åéãè©²æ¶æ§æä¾äºå° AI å¼ç¼äºæä¸­åè²¬å¶çå¯¶è²´è¦è§£ï¼ééæçºç£æ§ãä¿®è¨ååæï¼ä¿é²äºæ°¸çºä¸æéæ§çç³»çµ±ç¼å±ã

##### **Explainable AI for Fair Sepsis Mortality Predictive Model**
2404.13139v1 by Chia-Hsuan Chang, Xiaoyang Wang, Christopher C. Yang

Artificial intelligence supports healthcare professionals with predictive
modeling, greatly transforming clinical decision-making. This study addresses
the crucial need for fairness and explainability in AI applications within
healthcare to ensure equitable outcomes across diverse patient demographics. By
focusing on the predictive modeling of sepsis-related mortality, we propose a
method that learns a performance-optimized predictive model and then employs
the transfer learning process to produce a model with better fairness. Our
method also introduces a novel permutation-based feature importance algorithm
aiming at elucidating the contribution of each feature in enhancing fairness on
predictions. Unlike existing explainability methods concentrating on explaining
feature contribution to predictive performance, our proposed method uniquely
bridges the gap in understanding how each feature contributes to fairness. This
advancement is pivotal, given sepsis's significant mortality rate and its role
in one-third of hospital deaths. Our method not only aids in identifying and
mitigating biases within the predictive model but also fosters trust among
healthcare stakeholders by improving the transparency and fairness of model
predictions, thereby contributing to more equitable and trustworthy healthcare
delivery.

æè¦ï¼äººå·¥æºæ§ééé æ¸¬æ¨¡ååå©é«çå°æ¥­äººå¡ï¼å¤§å¹è½è®äºè¨åºæ±ºç­å¶å®ãæ¬ç ç©¶æ¢è¨äºå¨é«çä¿å¥ä¸­ä½¿ç¨äººå·¥æºæ§æç¨ç¨å¼æå¬å¹³æ§åå¯è§£éæ§çééµéæ±ï¼ä»¥ç¢ºä¿å¨ä¸åçæ£èäººå£çµ±è¨è³æä¸­ç²å¾å¬å¹³ççµæãééå°æ³¨æ¼æè¡çç¸éæ­»äº¡ççé æ¸¬æ¨¡åï¼æåæåºäºä¸ç¨®æ¹æ³ï¼è©²æ¹æ³æå­¸ç¿ä¸åæè½æä½³åçé æ¸¬æ¨¡åï¼ç¶å¾æ¡ç¨è½ç§»å­¸ç¿éç¨ä¾ç¢çä¸åå·ææ´å¥½å¬å¹³æ§çæ¨¡åãæåçæ¨¡åéå¼å¥äºä¸ç¨®æ°ç©çåºæ¼æåçç¹å¾µéè¦æ§æ¼ç®æ³ï¼æ¨å¨é¡ææ¯åç¹å¾µå¨å¢å¼·é æ¸¬å¬å¹³æ§æ¹é¢çè²¢ç»ãèç¾æçå¯è§£éæ§æ¹æ³å°æ³¨æ¼è§£éç¹å¾µå°é æ¸¬æè½çè²¢ç»ä¸åï¼æåæåºçæ¹æ³ç¨ç¹å°å½è£äºçè§£æ¯åç¹å¾µå¦ä½æå©æ¼å¬å¹³æ§çå·®è·ãéé é²å±è³ééè¦ï¼å çºæè¡ççæ­»äº¡çå¾é«ï¼ä¸å¨ä¸åä¹ä¸çé«é¢æ­»äº¡ä¸­æ®æ¼èè§è²ãæåçæ¨¡åä¸åæå©æ¼è­å¥åæ¸è¼é æ¸¬æ¨¡åä¸­çåå·®ï¼éè½ééæé«æ¨¡åé æ¸¬çéæåº¦åå¬å¹³æ§ä¾å¹é¤é«çä¿å¥å©çç¸éèä¹éçä¿¡ä»»ï¼é²èæå©æ¼æä¾æ´å¬å¹³ä¸å¼å¾ä¿¡è³´çé«çä¿å¥æåã

##### **Multi Class Depression Detection Through Tweets using Artificial Intelligence**
2404.13104v1 by Muhammad Osama Nusrat, Waseem Shahzad, Saad Ahmed Jamal

Depression is a significant issue nowadays. As per the World Health
Organization (WHO), in 2023, over 280 million individuals are grappling with
depression. This is a huge number; if not taken seriously, these numbers will
increase rapidly. About 4.89 billion individuals are social media users. People
express their feelings and emotions on platforms like Twitter, Facebook,
Reddit, Instagram, etc. These platforms contain valuable information which can
be used for research purposes. Considerable research has been conducted across
various social media platforms. However, certain limitations persist in these
endeavors. Particularly, previous studies were only focused on detecting
depression and the intensity of depression in tweets. Also, there existed
inaccuracies in dataset labeling. In this research work, five types of
depression (Bipolar, major, psychotic, atypical, and postpartum) were predicted
using tweets from the Twitter database based on lexicon labeling. Explainable
AI was used to provide reasoning by highlighting the parts of tweets that
represent type of depression. Bidirectional Encoder Representations from
Transformers (BERT) was used for feature extraction and training. Machine
learning and deep learning methodologies were used to train the model. The BERT
model presented the most promising results, achieving an overall accuracy of
0.96.

æè¦ï¼ç¾ä»ï¼æé¬±çæ¯ä¸åéè¦çè­°é¡ãæ ¹æä¸çè¡ççµç¹ (WHO) çè³æï¼å¨ 2023 å¹´ï¼è¶é 2.8 åäººæ­£å¨èæé¬±çæé¬¥ãéæ¯ä¸åé¾å¤§çæ¸å­ï¼å¦æä¸èªççå¾ï¼éäºæ¸å­å°æå¿«éå¢å ãå¤§ç´æ 48.9 åäººæ¯ç¤¾ç¾¤åªé«ä½¿ç¨èãäººåå¨ TwitterãFacebookãRedditãInstagram ç­å¹³å°ä¸è¡¨éèªå·±çæååæç·ãéäºå¹³å°åå«æå¹å¼çè³è¨ï¼å¯ç¨æ¼ç ç©¶ç®çãå·²ç¶å¨åç¨®ç¤¾ç¾¤åªé«å¹³å°ä¸é²è¡äºå¤§éçç ç©¶ãç¶èï¼éäºåªåä»å­å¨æäºéå¶ãç¹å¥æ¯ï¼ååçç ç©¶åå°æ³¨æ¼åµæ¸¬æ¨æä¸­çæé¬±çåæé¬±ççå¼·åº¦ãæ­¤å¤ï¼è³æéæ¨ç±¤ä¸­å­å¨ä¸æºç¢ºçææ³ãå¨éé ç ç©¶å·¥ä½ä¸­ï¼ä½¿ç¨åºæ¼è©å½æ¨ç±¤ç Twitter è³æåº«ä¸­çæ¨æé æ¸¬äºäºç¨®é¡åçæé¬±çï¼éæ¥µåãéåº¦ãç²¾ç¥çåãéå¸ååç¢å¾ï¼ãå¯è§£éç AI ç¨æ¼ééå¼·èª¿ä»£è¡¨æé¬±çé¡åçæ¨æé¨åä¾æä¾æ¨çãå¾ Transformersï¼BERTï¼ä¸­æåçéåç·¨ç¢¼å¨è¡¨ç¤ºç¨æ¼ç¹å¾µæååè¨ç·´ãæ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿æ¹æ³ç¨æ¼è¨ç·´æ¨¡åãBERT æ¨¡ååç¾åºææå¸æççµæï¼éå° 0.96 çæ´é«æºç¢ºåº¦ã

##### **COIN: Counterfactual inpainting for weakly supervised semantic segmentation for medical images**
2404.12832v2 by Dmytro Shvetsov, Joonas Ariva, Marharyta Domnich, Raul Vicente, Dmytro Fishman

Deep learning is dramatically transforming the field of medical imaging and
radiology, enabling the identification of pathologies in medical images,
including computed tomography (CT) and X-ray scans. However, the performance of
deep learning models, particularly in segmentation tasks, is often limited by
the need for extensive annotated datasets. To address this challenge, the
capabilities of weakly supervised semantic segmentation are explored through
the lens of Explainable AI and the generation of counterfactual explanations.
The scope of this research is development of a novel counterfactual inpainting
approach (COIN) that flips the predicted classification label from abnormal to
normal by using a generative model. For instance, if the classifier deems an
input medical image X as abnormal, indicating the presence of a pathology, the
generative model aims to inpaint the abnormal region, thus reversing the
classifier's original prediction label. The approach enables us to produce
precise segmentations for pathologies without depending on pre-existing
segmentation masks. Crucially, image-level labels are utilized, which are
substantially easier to acquire than creating detailed segmentation masks. The
effectiveness of the method is demonstrated by segmenting synthetic targets and
actual kidney tumors from CT images acquired from Tartu University Hospital in
Estonia. The findings indicate that COIN greatly surpasses established
attribution methods, such as RISE, ScoreCAM, and LayerCAM, as well as an
alternative counterfactual explanation method introduced by Singla et al. This
evidence suggests that COIN is a promising approach for semantic segmentation
of tumors in CT images, and presents a step forward in making deep learning
applications more accessible and effective in healthcare, where annotated data
is scarce.

æè¦ï¼æ·±åº¦å­¦ä¹ æ­£å¤§å¹è½è®é«å­¸å½±ååæ¾å°ç·å­¸é åï¼è½è¾¨è­é«å­¸å½±åä¸­çççï¼åæ¬é»è¦æ·å±¤ææ (CT) å X åææãç¶èï¼æ·±åº¦å­¸ç¿æ¨¡åçæè½ï¼ç¹å¥æ¯å¨åå²ä»»åä¸­ï¼å¸¸å¸¸åå°å»£æ³è¨»è§£è³æééæ±çéå¶ãçºäºæå°æ­¤ææ°ï¼ééå¯è§£é AI ååäºå¯¦è§£éçç¢çï¼æ¢ç´¢å¼±ç£ç£èªæåå²çè½åãæ¬ç ç©¶çç¯åæ¯éç¼ä¸ç¨®æ°çåäºå¯¦å§ææ¹æ³ (COIN)ï¼è©²æ¹æ³ä½¿ç¨çææ¨¡åå°é æ¸¬çåé¡æ¨ç±¤å¾ç°å¸¸ç¿»è½çºæ­£å¸¸ãä¾å¦ï¼å¦æåé¡å¨å°è¼¸å¥çé«å­¸å½±å X è¦çºç°å¸¸ï¼è¡¨ç¤ºå­å¨ççï¼åçææ¨¡åæ¨å¨å§æç°å¸¸ååï¼å¾èéè½åé¡å¨çåå§é æ¸¬æ¨ç±¤ãæ­¤æ¹æ³ä½¿æåè½å¤ ç¢ççççç²¾ç¢ºåå²ï¼èç¡éä¾è³´æ¼é åå­å¨çåå²é®ç½©ãè³ééè¦çæ¯ï¼å©ç¨å½±åå±¤ç´æ¨ç±¤ï¼éæ¯å»ºç«è©³ç´°çåå²é®ç½©å®¹æåå¾ãè©²æ¹æ³çæææ§ééåå²åæç®æ¨åå¾ææ²å°¼äºå¡ç¾åå¤§å­¸é«é¢åå¾ç CT å½±åä¸­çå¯¦éèèè«ç¤ä¾è­æãç ç©¶çµæè¡¨æï¼COIN é é è¶éå·²å»ºç«çæ­¸å æ¹æ³ï¼ä¾å¦ RISEãScoreCAM å LayerCAMï¼ä»¥å Singla ç­äººæåºçå¦ä¸ç¨®åäºå¯¦è§£éæ¹æ³ãæ­¤è­æè¡¨æï¼COIN æ¯ä¸ç¨®å¾æåéç CT å½±åä¸­è«ç¤èªæåå²æ¹æ³ï¼ä¸¦å¨é«çä¿å¥ä¸­è®æ·±åº¦å­¸ç¿æç¨æ´ææ¼åå¾åæ´ææçéé²ä¸æ­¥ï¼å¶ä¸­è¨»è§£è³æå¾ç¨å°ã

##### **Hybrid Intelligence for Digital Humanities**
2406.15374v1 by Victor de Boer, Lise Stork

In this paper, we explore the synergies between Digital Humanities (DH) as a
discipline and Hybrid Intelligence (HI) as a research paradigm. In DH research,
the use of digital methods and specifically that of Artificial Intelligence is
subject to a set of requirements and constraints. We argue that these are
well-supported by the capabilities and goals of HI. Our contribution includes
the identification of five such DH requirements: Successful AI systems need to
be able to 1) collaborate with the (human) scholar; 2) support data criticism;
3) support tool criticism; 4) be aware of and cater to various perspectives and
5) support distant and close reading. We take the CARE principles of Hybrid
Intelligence (collaborative, adaptive, responsible and explainable) as
theoretical framework and map these to the DH requirements. In this mapping, we
include example research projects. We finally address how insights from DH can
be applied to HI and discuss open challenges for the combination of the two
disciplines.

æè¦ï¼å¨æ¬æä¸­ï¼æåæ¢è¨æ¸ä½äººæå­¸ç§ (DH) ä½çºä¸éå­¸ç§èæ··åæºè½ (HI) ä½çºä¸åç ç©¶å¸ç¯ä¹éçååä½ç¨ãå¨ DH ç ç©¶ä¸­ï¼æ¸ä½æ¹æ³çä½¿ç¨ï¼ç¹å¥æ¯äººå·¥æºæ§çä½¿ç¨ï¼åå°ä¸ç³»åè¦æ±åéå¶ãæåèªçºéäºè¦æ±åéå¶ç²å¾ HI çè½ååç®æ¨çååæ¯æãæåçè²¢ç»åæ¬æ¾åºäºåéæ¨£ç DH è¦æ±ï¼æåç AI ç³»çµ±éè¦è½å¤  1) èï¼äººé¡ï¼å­¸èåä½ï¼2) æ¯æ´è³ææ¹è©ï¼3) æ¯æ´å·¥å·æ¹è©ï¼4) å¯è¦ºä¸¦è¿ååç¨®è§é»ï¼5) æ¯æ´é è·åè¿è·é¢é±è®ãæåå°æ··åæºè½ç CARE ååï¼åä½ãé©æãè² è²¬åå¯è§£éï¼ä½çºçè«æ¶æ§ï¼ä¸¦å°éäºååå°æå° DH è¦æ±ãå¨æ­¤å°æä¸­ï¼æåç´å¥ç¯ä¾ç ç©¶å°æ¡ãæå¾ï¼æåæ¢è¨å¦ä½å° DH çè¦è§£æç¨æ¼ HIï¼ä¸¦è¨è«çµåéå©åå­¸ç§çéæ¾ææ°ã

##### **Ethical Framework for Responsible Foundational Models in Medical Imaging**
2406.11868v1 by Abhijit Das, Debesh Jha, Jasmer Sanjotra, Onkar Susladkar, Suramyaa Sarkar, Ashish Rauniyar, Nikhil Tomar, Vanshali Sharma, Ulas Bagci

Foundational models (FMs) have tremendous potential to revolutionize medical
imaging. However, their deployment in real-world clinical settings demands
extensive ethical considerations. This paper aims to highlight the ethical
concerns related to FMs and propose a framework to guide their responsible
development and implementation within medicine. We meticulously examine ethical
issues such as privacy of patient data, bias mitigation, algorithmic
transparency, explainability and accountability. The proposed framework is
designed to prioritize patient welfare, mitigate potential risks, and foster
trust in AI-assisted healthcare.

æè¦ï¼åºç¤æ¨¡å (FM) å·æå¾¹åºæ¹è®é«å­¸å½±åçå·¨å¤§æ½åãç¶èï¼å®åå¨ç¾å¯¦ä¸çè¨åºç°å¢ä¸­çé¨ç½²éè¦å»£æ³çå«çèéãæ¬ææ¨å¨å¼·èª¿è FM ç¸éçå«çåé¡ï¼ä¸¦æåºä¸åæ¡æ¶ä¾æå°å®åå¨é«å­¸ä¸­çè² è²¬ä»»éç¼åå¯¦æ½ãæåä»ç´°å¯©æ¥äºå«çåé¡ï¼ä¾å¦æ£èæ¸æé±ç§ãåå·®ç·©è§£ãæ¼ç®æ³éæåº¦ãå¯è§£éæ§ååè²¬å¶ãææåºçæ¡æ¶æ¨å¨åªåèæ®æ£èç¦å©ãæ¸è¼æ½å¨é¢¨éªï¼ä¸¦å¹é¤å° AI è¼å©é«çä¿å¥çä¿¡ä»»ã

##### **Advancements in Radiomics and Artificial Intelligence for Thyroid Cancer Diagnosis**
2404.07239v1 by Milad Yousefi, Shadi Farabi Maleki, Ali Jafarizadeh, Mahya Ahmadpour Youshanlui, Aida Jafari, Siamak Pedrammehr, Roohallah Alizadehsani, Ryszard Tadeusiewicz, Pawel Plawiak

Thyroid cancer is an increasing global health concern that requires advanced
diagnostic methods. The application of AI and radiomics to thyroid cancer
diagnosis is examined in this review. A review of multiple databases was
conducted in compliance with PRISMA guidelines until October 2023. A
combination of keywords led to the discovery of an English academic publication
on thyroid cancer and related subjects. 267 papers were returned from the
original search after 109 duplicates were removed. Relevant studies were
selected according to predetermined criteria after 124 articles were eliminated
based on an examination of their abstract and title. After the comprehensive
analysis, an additional six studies were excluded. Among the 28 included
studies, radiomics analysis, which incorporates ultrasound (US) images,
demonstrated its effectiveness in diagnosing thyroid cancer. Various results
were noted, some of the studies presenting new strategies that outperformed the
status quo. The literature has emphasized various challenges faced by AI
models, including interpretability issues, dataset constraints, and operator
dependence. The synthesized findings of the 28 included studies mentioned the
need for standardization efforts and prospective multicenter studies to address
these concerns. Furthermore, approaches to overcome these obstacles were
identified, such as advances in explainable AI technology and personalized
medicine techniques. The review focuses on how AI and radiomics could transform
the diagnosis and treatment of thyroid cancer. Despite challenges, future
research on multidisciplinary cooperation, clinical applicability validation,
and algorithm improvement holds the potential to improve patient outcomes and
diagnostic precision in the treatment of thyroid cancer.

æè¦ï¼ç²çèºçæ¯ä¸ç¨®æ¥çå´éçå¨çå¥åº·åé¡ï¼éè¦åé²çè¨ºæ·æ¹æ³ãæ¬ç¯è©è«æ¢è¨äºäººå·¥æºè½èæ¾å°ç¹å¾µåæå¨ç²çèºçè¨ºæ·ä¸­çæç¨ãå¨ç¬¦å PRISMA æåçææ³ä¸ï¼å°å¤åè³æåº«é²è¡äºåé¡§ï¼ç´å° 2023 å¹´ 10 æãééçµåééµå­ï¼ç¼ç¾äºä¸ç¯éæ¼ç²çèºçåç¸éä¸»é¡çè±æå­¸è¡åºçç©ãå¨ç§»é¤ 109 ç¯éè¤æç»å¾ï¼åå§æå°å±åå³ 267 ç¯è«æãå¨æ ¹æé åç¢ºå®çæ¨æºï¼æ·æ±°äº 124 ç¯æç« çæè¦åæ¨é¡å¾ï¼é¸åºäºç¸éç ç©¶ãå¨é²è¡å¨é¢åæå¾ï¼é¡å¤æé¤äºå­é ç ç©¶ãå¨ç´å¥ç 28 é ç ç©¶ä¸­ï¼çµåè¶é³æ³¢ (US) å½±åçæ¾å°ç¹å¾µåæï¼è­æäºå¶å¨è¨ºæ·ç²çèºçæ¹é¢çæææ§ãç ç©¶çµæä¸ä¸ï¼æäºç ç©¶æåºäºåªæ¼ç¾ççæ°ç­ç¥ãæç»å¼·èª¿äºäººå·¥æºè½æ¨¡åé¢è¨çåç¨®ææ°ï¼åæ¬å¯è§£éæ§åé¡ãè³æééå¶åæä½å¡ä¾è³´æ§ã28 é ç´å¥ç ç©¶çç¶åç¼ç¾æå°ï¼éè¦æ¨æºåå·¥ä½ååç»æ§å¤ä¸­å¿ç ç©¶ä¾è§£æ±ºéäºåé¡ãæ­¤å¤ï¼éç¢ºå®äºåæéäºéç¤çæ¹æ³ï¼ä¾å¦å¯è§£éäººå·¥æºè½æè¡ååäººåé«çæè¡çé²æ­¥ãæ¬ç¯è©è«éé»æ¢è¨äºäººå·¥æºè½åæ¾å°ç¹å¾µåæå¦ä½è½è®ç²çèºççè¨ºæ·åæ²»çãåç®¡å­å¨ææ°ï¼ä½æªä¾å°å¤å­¸ç§åä½ãè¨åºé©ç¨æ§é©è­åæ¼ç®æ³æ¹é²çç ç©¶ï¼ä»ææ½åæ¹åç²çèºçæ²»çä¸­çæ£èé å¾åè¨ºæ·ç²¾æºåº¦ã

##### **Predictive Modeling for Breast Cancer Classification in the Context of Bangladeshi Patients: A Supervised Machine Learning Approach with Explainable AI**
2404.04686v1 by Taminul Islam, Md. Alif Sheakh, Mst. Sazia Tahosin, Most. Hasna Hena, Shopnil Akash, Yousef A. Bin Jardan, Gezahign Fentahun Wondmie, Hiba-Allah Nafidi, Mohammed Bourhia

Breast cancer has rapidly increased in prevalence in recent years, making it
one of the leading causes of mortality worldwide. Among all cancers, it is by
far the most common. Diagnosing this illness manually requires significant time
and expertise. Since detecting breast cancer is a time-consuming process,
preventing its further spread can be aided by creating machine-based forecasts.
Machine learning and Explainable AI are crucial in classification as they not
only provide accurate predictions but also offer insights into how the model
arrives at its decisions, aiding in the understanding and trustworthiness of
the classification results. In this study, we evaluate and compare the
classification accuracy, precision, recall, and F-1 scores of five different
machine learning methods using a primary dataset (500 patients from Dhaka
Medical College Hospital). Five different supervised machine learning
techniques, including decision tree, random forest, logistic regression, naive
bayes, and XGBoost, have been used to achieve optimal results on our dataset.
Additionally, this study applied SHAP analysis to the XGBoost model to
interpret the model's predictions and understand the impact of each feature on
the model's output. We compared the accuracy with which several algorithms
classified the data, as well as contrasted with other literature in this field.
After final evaluation, this study found that XGBoost achieved the best model
accuracy, which is 97%.

æè¦ï¼<paragraph>è¿å¹´ä¾ï¼ä¹³çççè¡çè¿éå¢å ï¼ä½¿å¶æçºå¨çä¸»è¦çæ­»äº¡åå ä¹ä¸ãå¨ææççä¸­ï¼ä¹³çè¿ä»çºæ­¢æ¯æå¸¸è¦çãæåè¨ºæ·æ­¤ç¾çéè¦å¤§éçæéåå°æ¥­ç¥è­ãç±æ¼ä¹³ççæª¢æ¸¬éç¨èæï¼å æ­¤ééå»ºç«æ©å¨å­¸ç¿æ¨¡åä¾é æ¸¬ï¼æå©æ¼é²æ­¢å¶é²ä¸æ­¥æ´æ£ãæ©å¨å­¸ç¿åå¯è§£é AI å¨åé¡ä¸­è³ééè¦ï¼å çºå®åä¸åå¯ä»¥æä¾æºç¢ºçé æ¸¬ï¼éå¯ä»¥æ·±å¥äºè§£æ¨¡åå¦ä½ååºæ±ºç­ï¼æå©æ¼çè§£åä¿¡è³´åé¡çµæãå¨æ­¤ç ç©¶ä¸­ï¼æåè©ä¼°ä¸¦æ¯è¼äºäºç¨®ä¸åçæ©å¨å­¸ç¿æ¹æ³çåé¡æºç¢ºåº¦ãç²¾ç¢ºåº¦ãå¬åçå F1 åæ¸ï¼ä½¿ç¨äºä¸åä¸»è¦çè³æéï¼éå¡é«å­¸é¢é«é¢ç 500 åæ£èï¼ãäºç¨®ä¸åçç£ç£å¼æ©å¨å­¸ç¿æè¡ï¼åæ¬æ±ºç­æ¨¹ãé¨æ©æ£®æãéè¼¯è¿´æ­¸ãæ´ç´ è²æ°å XGBoostï¼å·²ç¨æ¼å¨æåçè³æéä¸åå¾æä½³çµæãæ­¤å¤ï¼æ¬ç ç©¶å° SHAP åææç¨æ¼ XGBoost æ¨¡åï¼ä»¥è§£éæ¨¡åçé æ¸¬ä¸¦äºè§£æ¯åç¹å¾µå°æ¨¡åè¼¸åºçå½±é¿ãæåæ¯è¼äºå¹¾ç¨®æ¼ç®æ³å°è³æé²è¡åé¡çæºç¢ºåº¦ï¼ä¸¦èè©²é åçå¶ä»æç»é²è¡å°æ¯ãå¨æå¾è©ä¼°å¾ï¼æ¬ç ç©¶ç¼ç¾ XGBoost éå°äºæä½³çæ¨¡åæºç¢ºåº¦ï¼çº 97%ã</paragraph>

##### **Enhancing Breast Cancer Diagnosis in Mammography: Evaluation and Integration of Convolutional Neural Networks and Explainable AI**
2404.03892v3 by Maryam Ahmed, Tooba Bibi, Rizwan Ahmed Khan, Sidra Nasir

The Deep learning (DL) models for diagnosing breast cancer from mammographic
images often operate as "black boxes", making it difficult for healthcare
professionals to trust and understand their decision-making processes. The
study presents an integrated framework combining Convolutional Neural Networks
(CNNs) and Explainable Artificial Intelligence (XAI) for the enhanced diagnosis
of breast cancer using the CBIS-DDSM dataset. The methodology encompasses an
elaborate data preprocessing pipeline and advanced data augmentation techniques
to counteract dataset limitations and transfer learning using pre-trained
networks such as VGG-16, Inception-V3 and ResNet was employed. A focal point of
our study is the evaluation of XAI's effectiveness in interpreting model
predictions, highlighted by utilizing the Hausdorff measure to assess the
alignment between AI-generated explanations and expert annotations
quantitatively. This approach is critical for XAI in promoting trustworthiness
and ethical fairness in AI-assisted diagnostics. The findings from our research
illustrate the effective collaboration between CNNs and XAI in advancing
diagnostic methods for breast cancer, thereby facilitating a more seamless
integration of advanced AI technologies within clinical settings. By enhancing
the interpretability of AI driven decisions, this work lays the groundwork for
improved collaboration between AI systems and medical practitioners, ultimately
enriching patient care. Furthermore, the implications of our research extended
well beyond the current methodologies. It encourages further research into how
to combine multimodal data and improve AI explanations to meet the needs of
clinical practice.

æè¦ï¼æ·±åº¦å­¸ç¿ (DL) ç¨æ¼å¾ä¹³æ¿æå½±è¡å½±åè¨ºæ·ä¹³ççæ¨¡åéå¸¸ä»¥ãé»çå­ãæ¹å¼éä½ï¼éä½¿å¾é«çä¿å¥å°æ¥­äººå¡é£ä»¥ä¿¡ä»»åçè§£å¶æ±ºç­éç¨ãæ¬ç ç©¶æåºä¸åæ´åæ¶æ§ï¼çµåå·ç©ç¥ç¶ç¶²è·¯ (CNN) åå¯è§£éäººå·¥æºæ§ (XAI)ï¼ä»¥ä½¿ç¨ CBIS-DDSM è³æéå¢å¼·ä¹³ççè¨ºæ·ãæ¹æ³åå«ä¸åç²¾ç´°çè³æåèçç®¡ç·åé²éè³ææ´åæè¡ï¼ä»¥å°æè³æééå¶ï¼ä¸¦æ¡ç¨é åè¨ç·´çç¶²è·¯ï¼ä¾å¦ VGG-16ãInception-V3 å ResNetï¼é²è¡é·ç§»å­¸ç¿ãæåç ç©¶çéé»æ¯è©ä¼° XAI å¨è§£éæ¨¡åé æ¸¬ä¸­çæææ§ï¼éé»å©ç¨è±ªæ¯å¤å¤«æ¸¬åº¦éåè©ä¼° AI çæçè§£éåå°å®¶è¨»è§£ä¹éçä¸è´æ§ãéç¨®æ¹æ³å°æ¼ XAI å¨ä¿é² AI è¼å©è¨ºæ·ä¸­çå¯ä¿¡åº¦åå«çå¬å¹³æ§è³ééè¦ãæåç ç©¶çç¼ç¾èªªæäº CNN å XAI å¨æ¨é²ä¹³çè¨ºæ·æ¹æ³ä¸­çææåä½ï¼å¾èä¿é²äºåé² AI æè¡å¨è¨åºç°å¢ä¸­çæ´é æ¢æ´åãééå¢å¼· AI é©åæ±ºç­çå¯è§£éæ§ï¼éé å·¥ä½çº AI ç³»çµ±åé«çå¾æ¥­äººå¡ä¹éçæ¹ååä½å¥ å®äºåºç¤ï¼æçµè±å¯äºæ£èç§è­·ãæ­¤å¤ï¼æåç ç©¶çå½±é¿é é è¶åºäºç®åçæè¡ãå®é¼åµé²ä¸æ­¥ç ç©¶å¦ä½çµåå¤æ¨¡å¼è³æä¸¦æ¹å AI è§£éï¼ä»¥æ»¿è¶³è¨åºå¯¦åçéæ±ã

##### **Addressing Social Misattributions of Large Language Models: An HCXAI-based Approach**
2403.17873v1 by Andrea Ferrario, Alberto Termine, Alessandro Facchini

Human-centered explainable AI (HCXAI) advocates for the integration of social
aspects into AI explanations. Central to the HCXAI discourse is the Social
Transparency (ST) framework, which aims to make the socio-organizational
context of AI systems accessible to their users. In this work, we suggest
extending the ST framework to address the risks of social misattributions in
Large Language Models (LLMs), particularly in sensitive areas like mental
health. In fact LLMs, which are remarkably capable of simulating roles and
personas, may lead to mismatches between designers' intentions and users'
perceptions of social attributes, risking to promote emotional manipulation and
dangerous behaviors, cases of epistemic injustice, and unwarranted trust. To
address these issues, we propose enhancing the ST framework with a fifth
'W-question' to clarify the specific social attributions assigned to LLMs by
its designers and users. This addition aims to bridge the gap between LLM
capabilities and user perceptions, promoting the ethically responsible
development and use of LLM-based technology.

æè¦ï¼ä»¥äººä¸ºæ¬çå¯è§£é AI (HCXAI) å¡å¯¼å°ç¤¾ä¼å±é¢æ´åå° AI è§£éä¸­ãHCXAI è¯è¯­çæ ¸å¿æ¯ç¤¾ä¼éæåº¦ (ST) æ¡æ¶ï¼å¶ç®æ æ¯è®© AI ç³»ç»çç¤¾ä¼ç»ç»èæ¯å¯¹ç¨æ·æ¥è¯´æ¯å¯çè§£çãå¨è¿é¡¹å·¥ä½ä¸­ï¼æä»¬å»ºè®®æ©å± ST æ¡æ¶ä»¥è§£å³å¤§åè¯­è¨æ¨¡å (LLM) ä¸­ç¤¾ä¼éè¯¯å½å çé£é©ï¼å°¤å¶æ¯å¨å¿çå¥åº·ç­ææé¢åãäºå®ä¸ï¼LLM è½å¤åºè²å°æ¨¡æè§è²åäººæ ¼ï¼è¿å¯è½å¯¼è´è®¾è®¡èçæå¾åç¨æ·å¯¹ç¤¾ä¼å±æ§çè®¤ç¥ä¹é´åºç°ééï¼ä»èæé£é©ä¿è¿æç»ªæçºµåå±é©è¡ä¸ºãè®¤ç¥ä¸å¬æ­£åä¸åççä¿¡ä»»ãä¸ºäºè§£å³è¿äºé®é¢ï¼æä»¬å»ºè®®ç¨ç¬¬äºä¸ªâW é®é¢âæ¥å¢å¼º ST æ¡æ¶ï¼ä»¥æç¡®è®¾è®¡èåç¨æ·èµäº LLM çå·ä½ç¤¾ä¼å±æ§ãæ­¤è¡¥åæ¨å¨å¼¥å LLM è½ååç¨æ·è®¤ç¥ä¹é´çå·®è·ï¼ä¿è¿åºäº LLM çææ¯å¨éå¾·ä¸è´è´£ä»»å°å¼ååä½¿ç¨ã

##### **Clinical Domain Knowledge-Derived Template Improves Post Hoc AI Explanations in Pneumothorax Classification**
2403.18871v1 by Han Yuan, Chuan Hong, Pengtao Jiang, Gangming Zhao, Nguyen Tuan Anh Tran, Xinxing Xu, Yet Yen Yan, Nan Liu

Background: Pneumothorax is an acute thoracic disease caused by abnormal air
collection between the lungs and chest wall. To address the opaqueness often
associated with deep learning (DL) models, explainable artificial intelligence
(XAI) methods have been introduced to outline regions related to pneumothorax
diagnoses made by DL models. However, these explanations sometimes diverge from
actual lesion areas, highlighting the need for further improvement. Method: We
propose a template-guided approach to incorporate the clinical knowledge of
pneumothorax into model explanations generated by XAI methods, thereby
enhancing the quality of these explanations. Utilizing one lesion delineation
created by radiologists, our approach first generates a template that
represents potential areas of pneumothorax occurrence. This template is then
superimposed on model explanations to filter out extraneous explanations that
fall outside the template's boundaries. To validate its efficacy, we carried
out a comparative analysis of three XAI methods with and without our template
guidance when explaining two DL models in two real-world datasets. Results: The
proposed approach consistently improved baseline XAI methods across twelve
benchmark scenarios built on three XAI methods, two DL models, and two
datasets. The average incremental percentages, calculated by the performance
improvements over the baseline performance, were 97.8% in Intersection over
Union (IoU) and 94.1% in Dice Similarity Coefficient (DSC) when comparing model
explanations and ground-truth lesion areas. Conclusions: In the context of
pneumothorax diagnoses, we proposed a template-guided approach for improving AI
explanations. We anticipate that our template guidance will forge a fresh
approach to elucidating AI models by integrating clinical domain expertise.

æè¦ï¼<paragraph>èæ¯ï¼æ°£è¸æ¯ä¸ç¨®å èºé¨èè¸å£ä¹éç°å¸¸éæ°£æå¼èµ·çæ¥æ§è¸èç¾çãçºäºè§£æ±ºæ·±åº¦å­¸ç¿ï¼DLï¼æ¨¡åç¶å¸¸ä¼´é¨çä¸éææ§ï¼å¯è§£éäººå·¥æºæ§ï¼XAIï¼æ¹æ³å·²è¢«å¼å¥ï¼ç¨æ¼æ¦è¿°è DL æ¨¡åååºçæ°£è¸è¨ºæ·ç¸éçååãç¶èï¼éäºè§£éæææèå¯¦éçç¶ååææåºå¥ï¼çªé¡¯åºé²ä¸æ­¥æ¹é²çå¿è¦æ§ãæ¹æ³ï¼æåæåºäºä¸ç¨®æ¨¡æ¿å¼å°å¼æ¹æ³ï¼å°æ°£è¸çè¨åºç¥è­ç´å¥ XAI æ¹æ³ç¢ççæ¨¡åè§£éä¸­ï¼å¾èæåéäºè§£éçåè³ªãå©ç¨æ¾å°ç§é«å¸«å»ºç«ççç¶æç¹ªï¼æåçåæ³é¦åç¢çä¸åæ¨¡æ¿ï¼ç¨æ¼è¡¨ç¤ºæ°£è¸å¯è½ç¼ççååãç¶å¾å°æ­¤æ¨¡æ¿çå å¨æ¨¡åè§£éä¸ï¼ä»¥ç¯©é¸åºè¶åºæ¨¡æ¿éççç¡éè§£éãçºäºé©è­å¶æåï¼æåå°ä¸ç¨® XAI æ¹æ³é²è¡äºæ¯è¼åæï¼å¨å©åçå¯¦ä¸çè³æéä¸­è§£éå©å DL æ¨¡åæï¼åå¥æ¡ç¨åä¸æ¡ç¨æåçæ¨¡æ¿å¼å°ãçµæï¼ææåºçæ¹æ³å¨å»ºç«æ¼ä¸ç¨® XAI æ¹æ³ãå©å DL æ¨¡ååå©åè³æéçåäºç¨®åºæºæå¢ä¸­ï¼å§çµæ¹åäºåºæº XAI æ¹æ³ãå¨æ¯è¼æ¨¡åè§£éåçå¯¦çç¶ååæï¼ééåºæºæè½çæè½æ¹é²è¨ç®åºçå¹³åå¢éç¾åæ¯çºäº¤éæ¯ï¼IoUï¼ç 97.8% åéª°å­ç¸ä¼¼æ§ä¿æ¸ï¼DSCï¼ç 94.1%ãçµè«ï¼å¨æ°£è¸è¨ºæ·çèæ¯ä¸ï¼æåæåºäºä¸ç¨®æ¨¡æ¿å¼å°å¼æ¹æ³ï¼ç¨æ¼æ¹å AI è§£éãæåé ææåçæ¨¡æ¿å¼å°å°ééæ´åè¨åºé åå°æ¥­ç¥è­ï¼çºé¡æ AI æ¨¡åå»ºç«ä¸ç¨®æ°æ¹æ³ã</paragraph>

##### **Enhancing Neural Machine Translation of Low-Resource Languages: Corpus Development, Human Evaluation and Explainable AI Architectures**
2403.01580v1 by SÃ©amus Lankford

In the current machine translation (MT) landscape, the Transformer
architecture stands out as the gold standard, especially for high-resource
language pairs. This research delves into its efficacy for low-resource
language pairs including both the English$\leftrightarrow$Irish and
English$\leftrightarrow$Marathi language pairs. Notably, the study identifies
the optimal hyperparameters and subword model type to significantly improve the
translation quality of Transformer models for low-resource language pairs.
  The scarcity of parallel datasets for low-resource languages can hinder MT
development. To address this, gaHealth was developed, the first bilingual
corpus of health data for the Irish language. Focusing on the health domain,
models developed using this in-domain dataset exhibited very significant
improvements in BLEU score when compared with models from the LoResMT2021
Shared Task. A subsequent human evaluation using the multidimensional quality
metrics error taxonomy showcased the superior performance of the Transformer
system in reducing both accuracy and fluency errors compared to an RNN-based
counterpart.
  Furthermore, this thesis introduces adaptNMT and adaptMLLM, two open-source
applications streamlined for the development, fine-tuning, and deployment of
neural machine translation models. These tools considerably simplify the setup
and evaluation process, making MT more accessible to both developers and
translators. Notably, adaptNMT, grounded in the OpenNMT ecosystem, promotes
eco-friendly natural language processing research by highlighting the
environmental footprint of model development. Fine-tuning of MLLMs by adaptMLLM
demonstrated advancements in translation performance for two low-resource
language pairs: English$\leftrightarrow$Irish and
English$\leftrightarrow$Marathi, compared to baselines from the LoResMT2021
Shared Task.

æè¦ï¼<paragraph>å¨ç¶åæ©å¨ç¿»è­¯ (MT) é åä¸­ï¼Transformer æ¶æ§è«ç©èåºï¼æçºé»éæ¨æºï¼ç¹å¥æ¯å°æ¼é«è³æºèªè¨å°ãæ¬ç ç©¶æ¢è¨å¶å°ä½è³æºèªè¨å°çæè½ï¼åæ¬è±èªâæç¾è­èªåè±èªâé¦¬æå°èªèªè¨å°ãå¼å¾æ³¨æçæ¯ï¼æ¬ç ç©¶è­å¥åºæä½³è¶åæ¸åå­è©æ¨¡åé¡åï¼ä»¥é¡¯èæé« Transformer æ¨¡åå°ä½è³æºèªè¨å°çç¿»è­¯åè³ªã
ä½è³æºèªè¨çå¹³è¡è³æéçç¨ç¼ºæé»ç¤ MT çç¼å±ãçºäºè§£æ±ºéååé¡ï¼éç¼äº gaHealthï¼éæ¯æç¾è­èªçç¬¬ä¸åéèªå¥åº·è³æèªæåº«ãå°æ³¨æ¼å¥åº·é åï¼ä½¿ç¨æ­¤åå§è³æééç¼çæ¨¡åå¨ BLEU å¾åæ¹é¢è¡¨ç¾åºéå¸¸é¡¯èçé²æ­¥ï¼è LoResMT2021 å±äº«ä»»åä¸­çæ¨¡åç¸æ¯ãé¨å¾ä½¿ç¨å¤ç¶­åè³ªææ¨é¯èª¤åé¡æ³é²è¡çäººå·¥è©ä¼°é¡¯ç¤ºï¼èåºæ¼ RNN çå°ææ¨¡åç¸æ¯ï¼Transformer ç³»çµ±å¨æ¸å°æºç¢ºæ§åæµæ¢æ§é¯èª¤æ¹é¢è¡¨ç¾åºåªç°çæ§è½ã
æ­¤å¤ï¼æ¬è«æä»ç´¹äº adaptNMT å adaptMLLMï¼éå©åéæºæç¨ç¨å¼ç°¡åäºç¥ç¶æ©å¨ç¿»è­¯æ¨¡åçéç¼ãå¾®èª¿åé¨ç½²ãéäºå·¥å·å¤§å¹ç°¡åäºè¨­å®åè©ä¼°æµç¨ï¼è® MT æ´å®¹æè®éç¼äººå¡åç¿»è­¯äººå¡ä½¿ç¨ãå¼å¾æ³¨æçæ¯ï¼adaptNMT ä»¥ OpenNMT çæç³»çµ±çºåºç¤ï¼ééå¼·èª¿æ¨¡åéç¼çç°å¢è¶³è·¡ä¾ä¿é²çæåå¥½çèªç¶èªè¨èçç ç©¶ãè LoResMT2021 å±äº«ä»»åä¸­çåºæºç¸æ¯ï¼adaptMLLM å° MLLM çå¾®èª¿è­æäºè±èªâæç¾è­èªåè±èªâé¦¬æå°èªéå©åä½è³æºèªè¨å°çç¿»è­¯æ§è½é²æ­¥ã</paragraph>

##### **Artificial Intelligence and Diabetes Mellitus: An Inside Look Through the Retina**
2402.18600v1 by Yasin Sadeghi Bazargani, Majid Mirzaei, Navid Sobhi, Mirsaeed Abdollahi, Ali Jafarizadeh, Siamak Pedrammehr, Roohallah Alizadehsani, Ru San Tan, Sheikh Mohammed Shariful Islam, U. Rajendra Acharya

Diabetes mellitus (DM) predisposes patients to vascular complications.
Retinal images and vasculature reflect the body's micro- and macrovascular
health. They can be used to diagnose DM complications, including diabetic
retinopathy (DR), neuropathy, nephropathy, and atherosclerotic cardiovascular
disease, as well as forecast the risk of cardiovascular events. Artificial
intelligence (AI)-enabled systems developed for high-throughput detection of DR
using digitized retinal images have become clinically adopted. Beyond DR
screening, AI integration also holds immense potential to address challenges
associated with the holistic care of the patient with DM. In this work, we aim
to comprehensively review the literature for studies on AI applications based
on retinal images related to DM diagnosis, prognostication, and management. We
will describe the findings of holistic AI-assisted diabetes care, including but
not limited to DR screening, and discuss barriers to implementing such systems,
including issues concerning ethics, data privacy, equitable access, and
explainability. With the ability to evaluate the patient's health status vis a
vis DM complication as well as risk prognostication of future cardiovascular
complications, AI-assisted retinal image analysis has the potential to become a
central tool for modern personalized medicine in patients with DM.

æè¦ï¼ç³å°¿çï¼DMï¼ä½¿æ£èå®¹æåºç¾è¡ç®¡ä½µç¼çã
è¦ç¶²èå½±ååè¡ç®¡åæ èº«é«çå¾®è¡ç®¡åå·¨è¡ç®¡å¥åº·çæ³ãå®åå¯ç¨æ¼è¨ºæ·ç³å°¿çä½µç¼çï¼åæ¬ç³å°¿çè¦ç¶²èçè®ï¼DRï¼ãç¥ç¶çè®ãèçååèç²¥æ¨£ç¡¬åæ§å¿è¡ç®¡ç¾çï¼ä»¥åé æ¸¬å¿è¡ç®¡äºä»¶çé¢¨éªãçºä½¿ç¨æ¸ä½åè¦ç¶²èå½±åé²è¡é«éé DR æª¢æ¸¬èéç¼çäººå·¥æºæ§ï¼AIï¼åç¨ç³»çµ±å·²å¨è¨åºæ¡ç¨ãé¤äº DR ç¯©æª¢å¤ï¼AI æ´åä¹å·æå·¨å¤§çæ½åä¾æå°èç³å°¿çæ£èæ´é«ç§è­·ç¸éçææ°ãå¨éé å·¥ä½ä¸­ï¼æåæ¨å¨å¨é¢åé¡§åºæ¼è¦ç¶²èå½±åç AI æç¨ç¸éç ç©¶çæç»ï¼éäºç ç©¶èç³å°¿ççè¨ºæ·ãé å¾åç®¡çæéãæåå°æè¿°æ´é« AI è¼å©ç³å°¿çç§è­·çç¼ç¾ï¼åæ¬ä½ä¸éæ¼ DR ç¯©æª¢ï¼ä¸¦è¨è«å¯¦æ½æ­¤é¡ç³»çµ±çéç¤ï¼åæ¬èå«çãè³æé±ç§ãå¬å¹³å­ååå¯è§£éæ§æéçåé¡ãééè©ä¼°æ£èçå¥åº·çæ³ï¼åæèéç³å°¿çä½µç¼çä»¥åæªä¾å¿è¡ç®¡ä½µç¼ççé¢¨éªé å¾ï¼AI è¼å©è¦ç¶²èå½±ååæææ½åæçºç³å°¿çæ£èç¾ä»£ååäººåé«ççä¸­å¿å·¥å·ã

##### **Multi-stakeholder Perspective on Responsible Artificial Intelligence and Acceptability in Education**
2402.15027v2 by A. J. Karran, P. Charland, J-T. Martineau, A. Ortiz de Guinea Lopez de Arana, AM. Lesage, S. Senecal, P-M. Leger

This study investigates the acceptability of different artificial
intelligence (AI) applications in education from a multi-stakeholder
perspective, including students, teachers, and parents. Acknowledging the
transformative potential of AI in education, it addresses concerns related to
data privacy, AI agency, transparency, explainability and the ethical
deployment of AI. Through a vignette methodology, participants were presented
with four scenarios where AI's agency, transparency, explainability, and
privacy were manipulated. After each scenario, participants completed a survey
that captured their perceptions of AI's global utility, individual usefulness,
justice, confidence, risk, and intention to use each scenario's AI if
available. The data collection comprising a final sample of 1198
multi-stakeholder participants was distributed through a partner institution
and social media campaigns and focused on individual responses to four AI use
cases. A mediation analysis of the data indicated that acceptance and trust in
AI varies significantly across stakeholder groups. We found that the key
mediators between high and low levels of AI's agency, transparency, and
explainability, as well as the intention to use the different educational AI,
included perceived global utility, justice, and confidence. The study
highlights that the acceptance of AI in education is a nuanced and multifaceted
issue that requires careful consideration of specific AI applications and their
characteristics, in addition to the diverse stakeholders' perceptions.

æè¦ï¼éé ç ç©¶å¾å¤åå©å®³éä¿äººçè§åº¦æ¢è¨ä¸åçäººå·¥æºæ§ (AI) æç¨å¨æè²ä¸çå¯æ¥åæ§ï¼åæ¬å­¸çãèå¸«åå®¶é·ãæ¿èª AI å¨æè²ä¸çè½åæ½åï¼å®è§£æ±ºäºèè³æé±ç§ãAI ä»£çãéæåº¦ãå¯è§£éæ§å AI çéå¾·é¨ç½²ç¸éççæ®ãééå°ææ²æ¹æ³ï¼åèèè¢«åç¾äºåç¨®æå¢ï¼å¶ä¸­ AI çä»£çãéæåº¦ãå¯è§£éæ§åé±ç§åå°æç¸±ãå¨æ¯åæå¢å¾ï¼åèèå®æäºä¸é èª¿æ¥ï¼è©²èª¿æ¥ææäºä»åå° AI çæ´é«æç¨ãåäººæç¨ãæ­£ç¾©ãä¿¡å¿ãé¢¨éªåå¦æå¯ç¨ï¼ä½¿ç¨æ¯åæå¢ç AI çæåççæ³ãè³æèéåå«ä¾èªåä½æ©æ§åç¤¾ç¾¤åªé«æ´»åç 1198 ä½å¤å©å®³éä¿äººåèèçæçµæ¨£æ¬ï¼ä¸¦å°æ³¨æ¼å°åå AI ä½¿ç¨æ¡ä¾çåå¥åæãå°è³æçèª¿è§£åæè¡¨æï¼å° AI çæ¥ååº¦åä¿¡ä»»å¨å©å®³éä¿äººåé«ä¹éæé¡¯èå·®ç°ãæåç¼ç¾ï¼AI çä»£çãéæåº¦åå¯è§£éæ§é«ä½ç¨åº¦ä¹éçééµèª¿è§£èï¼ä»¥åä½¿ç¨ä¸åæè² AI çæåï¼åæ¬æç¥å°çæ´é«æç¨ãæ­£ç¾©åä¿¡å¿ãéé ç ç©¶å¼·èª¿ï¼æ¥å AI å¨æè²ä¸çæç¨æ¯ä¸åå¾®å¦ä¸å¤é¢åçåé¡ï¼é¤äºä¸åçå©å®³éä¿äººççæ³å¤ï¼ééè¦ä»ç´°èæ®å·é«ç AI æç¨åå¶ç¹å¾µã

##### **Deciphering Heartbeat Signatures: A Vision Transformer Approach to Explainable Atrial Fibrillation Detection from ECG Signals**
2402.09474v2 by Aruna Mohan, Danne Elbers, Or Zilbershot, Fatemeh Afghah, David Vorchheimer

Remote patient monitoring based on wearable single-lead electrocardiogram
(ECG) devices has significant potential for enabling the early detection of
heart disease, especially in combination with artificial intelligence (AI)
approaches for automated heart disease detection. There have been prior studies
applying AI approaches based on deep learning for heart disease detection.
However, these models are yet to be widely accepted as a reliable aid for
clinical diagnostics, in part due to the current black-box perception
surrounding many AI algorithms. In particular, there is a need to identify the
key features of the ECG signal that contribute toward making an accurate
diagnosis, thereby enhancing the interpretability of the model. In the present
study, we develop a vision transformer approach to identify atrial fibrillation
based on single-lead ECG data. A residual network (ResNet) approach is also
developed for comparison with the vision transformer approach. These models are
applied to the Chapman-Shaoxing dataset to classify atrial fibrillation, as
well as another common arrhythmia, sinus bradycardia, and normal sinus rhythm
heartbeats. The models enable the identification of the key regions of the
heartbeat that determine the resulting classification, and highlight the
importance of P-waves and T-waves, as well as heartbeat duration and signal
amplitude, in distinguishing normal sinus rhythm from atrial fibrillation and
sinus bradycardia.

æè¦ï¼<paragraph>åºæ¼å¯ç©¿æ´å¼å®å°ç¨å¿é»å (ECG) è£ç½®çé ç«¯çæ£ç£æ¸¬å¨æ©æåµæ¸¬å¿èç¾çæ¹é¢å·æé¡¯èçæ½åï¼ç¹å¥æ¯èç¨æ¼èªååå¿èç¾çåµæ¸¬çäººå·¥æºæ§ (AI) æ¹æ³çµåä½¿ç¨æãååå·²æç ç©¶æç¨åºæ¼æ·±åº¦å­¸ç¿ç AI æ¹æ³é²è¡å¿èç¾çåµæ¸¬ãç¶èï¼éäºæ¨¡åå°æªè¢«å»£æ³æ¥åçºè¨åºè¨ºæ·çå¯é è¼å©å·¥å·ï¼é¨ååå å¨æ¼åç¹è¨±å¤ AI æ¼ç®æ³çç¶åé»ç®±æç¥ãç¹å¥æ¯ï¼æå¿è¦æ¾åºæå©æ¼ååºæºç¢ºè¨ºæ·ç ECG è¨èééµç¹å¾µï¼å¾èå¢å¼·æ¨¡åçå¯è§£éæ§ãå¨æ¬ç ç©¶ä¸­ï¼æåéç¼äºä¸ç¨®è¦è¦ºè½æå¨æ¹æ³ï¼ä»¥æ ¹æå®å°ç¨ ECG è³ææ¾åºå¿æ¿é¡«åãæ®å·®ç¶²è·¯ (ResNet) æ¹æ³ä¹å·²éç¼åºä¾ï¼ä»¥ä¾¿èè¦è¦ºè½æå¨æ¹æ³é²è¡æ¯è¼ãéäºæ¨¡åæç¨æ¼ Chapman-Shaoxing è³æéï¼ä»¥åé¡å¿æ¿é¡«åï¼ä»¥åå¦ä¸ç¨®å¸¸è¦çå¿å¾ä¸æ´ï¼ç«æ§å¿åéç·©ï¼åæ­£å¸¸ç«æ§å¿å¾çå¿è·³ãéäºæ¨¡åè½å¤ æ¾åºæ±ºå®æçµåé¡çå¿è·³ééµååï¼ä¸¦å¼·èª¿ P æ³¢å T æ³¢ï¼ä»¥åå¿è·³æçºæéåè¨èæ¯å¹å¨ååæ­£å¸¸ç«æ§å¿å¾èå¿æ¿é¡«ååç«æ§å¿åéç·©æ¹é¢çéè¦æ§ã</paragraph>

##### **Illuminate: A novel approach for depression detection with explainable analysis and proactive therapy using prompt engineering**
2402.05127v1 by Aryan Agrawal

This paper introduces a novel paradigm for depression detection and treatment
using advanced Large Language Models (LLMs): Generative Pre-trained Transformer
4 (GPT-4), Llama 2 chat, and Gemini. These LLMs are fine-tuned with specialized
prompts to diagnose, explain, and suggest therapeutic interventions for
depression. A unique few-shot prompting method enhances the models' ability to
analyze and explain depressive symptoms based on the DSM-5 criteria. In the
interaction phase, the models engage in empathetic dialogue management, drawing
from resources like PsychDB and a Cognitive Behavioral Therapy (CBT) Guide,
fostering supportive interactions with individuals experiencing major
depressive disorders. Additionally, the research introduces the Illuminate
Database, enriched with various CBT modules, aiding in personalized therapy
recommendations. The study evaluates LLM performance using metrics such as F1
scores, Precision, Recall, Cosine similarity, and Recall-Oriented Understudy
for Gisting Evaluation (ROUGE) across different test sets, demonstrating their
effectiveness. This comprehensive approach blends cutting-edge AI with
established psychological methods, offering new possibilities in mental health
care and showcasing the potential of LLMs in revolutionizing depression
diagnosis and treatment strategies.

æè¦ï¼æ¬æä»ç´¹äºä¸ç¨®ä½¿ç¨åé²å¤§åèªè¨æ¨¡å (LLM) é²è¡æé¬±çåµæ¸¬åæ²»ççæ°æ¨¡å¼ï¼çæå¼é è¨ç·´Transformer 4 (GPT-4)ãLlama 2 èå¤©æ©å¨äººå Geminiãéäº LLM ç¶éå¾®èª¿ï¼å·åå°æ¥­æç¤ºï¼å¯è¨ºæ·ãè§£éä¸¦å»ºè­°æé¬±ççæ²»çä»å¥æ¹æ³ãä¸ç¨®ç¨ç¹çå°æ¬¡æç¤ºæ¹æ³å¢å¼·äºæ¨¡åæ ¹æ DSM-5 æ¨æºåæåè§£éæé¬±çççè½åãå¨äºåéæ®µï¼éäºæ¨¡åæåèåçå¿å°è©±ç®¡çï¼å¾ PsychDB åèªç¥è¡çºçæ³ (CBT) æåç­è³æºä¸­æ±²åï¼ä¿é²èç¶æ­·éåº¦æé¬±ççäººåçæ¯ææ§äºåãæ­¤å¤ï¼éé ç ç©¶éä»ç´¹äº Illuminate è³æåº«ï¼å¶ä¸­åå«åç¨® CBT æ¨¡çµï¼æå©æ¼åæ§åæ²»çå»ºè­°ãéé ç ç©¶ä½¿ç¨ F1 åæ¸ãæºç¢ºçãå¬åçãé¤å¼¦ç¸ä¼¼åº¦åé¢åå¬åçç Gisting è©ä¼°æ¿èº« (ROUGE) ç­ææ¨ï¼å¨ä¸åçæ¸¬è©¦éä¸­è©ä¼° LLM çè¡¨ç¾ï¼è­æäºå®åçæææ§ãéç¨®ç¶åæ¹æ³çµåäºå°ç«¯ç AI èæ¢å®çå¿çæ¹æ³ï¼çºå¿çä¿å¥æä¾äºæ°çå¯è½æ§ï¼ä¸¦å±ç¤ºäº LLM å¨é©æ°æé¬±çè¨ºæ·åæ²»çç­ç¥æ¹é¢çæ½åã

##### **Information That Matters: Exploring Information Needs of People Affected by Algorithmic Decisions**
2401.13324v4 by TimothÃ©e Schmude, Laura Koesten, Torsten MÃ¶ller, Sebastian Tschiatschek

Explanations of AI systems rarely address the information needs of people
affected by algorithmic decision-making (ADM). This gap between conveyed
information and information that matters to affected stakeholders can impede
understanding and adherence to regulatory frameworks such as the AI Act. To
address this gap, we present the "XAI Novice Question Bank": A catalog of
affected stakeholders' information needs in two ADM use cases (employment
prediction and health monitoring), covering the categories data, system
context, system usage, and system specifications. Information needs were
gathered in an interview study where participants received explanations in
response to their inquiries. Participants further reported their understanding
and decision confidence, showing that while confidence tended to increase after
receiving explanations, participants also met understanding challenges, such as
being unable to tell why their understanding felt incomplete. Explanations
further influenced participants' perceptions of the systems' risks and
benefits, which they confirmed or changed depending on the use case. When risks
were perceived as high, participants expressed particular interest in
explanations about intention, such as why and to what end a system was put in
place. With this work, we aim to support the inclusion of affected stakeholders
into explainability by contributing an overview of information and challenges
relevant to them when deciding on the adoption of ADM systems. We close by
summarizing our findings in a list of six key implications that inform the
design of future explanations for affected stakeholder audiences.

æè¦ï¼<paragraph>äººå·¥æºæ§ç³»çµ±çèªªæå¾å°è½æ»¿è¶³åæ¼ç®æ³æ±ºç­ (ADM) å½±é¿çäººåçè³è¨éæ±ãå³éçè³è¨èå½±é¿å©å®³éä¿äººéè¦çè³è¨ä¹éçå·®è·ï¼å¯è½æé»ç¤äºè§£åéµå®æ³è¦æ¶æ§ï¼ä¾å¦äººå·¥æºæ§æ³æ¡ãçºäºè§£æ±ºéåå·®è·ï¼æåæåºäºãXAI åå­¸èåé¡åº«ãï¼åå½±é¿å©å®³éä¿äººè³è¨éæ±çç®éï¼æ¶µèå©å ADM ä½¿ç¨æ¡ä¾ï¼å°±æ¥­é æ¸¬åå¥åº·ç£æ¸¬ï¼ï¼æ¶µèè³æãç³»çµ±èçµ¡ãç³»çµ±ä½¿ç¨åç³»çµ±è¦æ ¼é¡å¥ãè³è¨éæ±æ¯ééè¨ªè«ç ç©¶æ¶éçï¼åèèå¨è©¢åå¾æ¶å°èªªæãåèèé²ä¸æ­¥åå ±ä»åççè§£åæ±ºç­ä¿¡å¿ï¼é¡¯ç¤ºéç¶å¨æ¶å°èªªæå¾ä¿¡å¿å¾åæ¼å¢å ï¼ä½åèèä¹éå°äºçè§£ææ°ï¼ä¾å¦ç¡æ³èªªæçºä»éº¼ä»åççè§£æè¦ºä¸å®æ´ãèªªæé²ä¸æ­¥å½±é¿åèèå°ç³»çµ±é¢¨éªåå¥½èççæ³ï¼ä»åææ ¹æä½¿ç¨æ¡ä¾ç¢ºèªææ¹è®éäºçæ³ãç¶é¢¨éªè¢«èªçºå¾é«æï¼åèèè¡¨ç¤ºç¹å¥æèè¶£äºè§£æåçèªªæï¼ä¾å¦çºä»éº¼ä»¥åçºäºä»éº¼ç®çèå»ºç«ç³»çµ±ãéééé å·¥ä½ï¼æåæ¨å¨ééå¨æ±ºç­æ¡ç¨ ADM ç³»çµ±ææä¾ç¸éè³è¨åææ°çæ¦è¦½ï¼ä¾æ¯æ´å°åå½±é¿çå©å®³éä¿äººç´å¥å¯è§£éæ§ãæåæå¾ç¸½çµæåçç¼ç¾ï¼ååºå­é ééµå½±é¿ï¼éäºå½±é¿æåç¥æªä¾éå°åå½±é¿å©å®³éä¿äººåç¾èªªæçè¨­è¨ã</paragraph>

##### **Evaluating Large Language Models on the GMAT: Implications for the Future of Business Education**
2401.02985v1 by Vahid Ashrafimoghari, Necdet GÃ¼rkan, Jordan W. Suchow

The rapid evolution of artificial intelligence (AI), especially in the domain
of Large Language Models (LLMs) and generative AI, has opened new avenues for
application across various fields, yet its role in business education remains
underexplored. This study introduces the first benchmark to assess the
performance of seven major LLMs, OpenAI's models (GPT-3.5 Turbo, GPT-4, and
GPT-4 Turbo), Google's models (PaLM 2, Gemini 1.0 Pro), and Anthropic's models
(Claude 2 and Claude 2.1), on the GMAT, which is a key exam in the admission
process for graduate business programs. Our analysis shows that most LLMs
outperform human candidates, with GPT-4 Turbo not only outperforming the other
models but also surpassing the average scores of graduate students at top
business schools. Through a case study, this research examines GPT-4 Turbo's
ability to explain answers, evaluate responses, identify errors, tailor
instructions, and generate alternative scenarios. The latest LLM versions,
GPT-4 Turbo, Claude 2.1, and Gemini 1.0 Pro, show marked improvements in
reasoning tasks compared to their predecessors, underscoring their potential
for complex problem-solving. While AI's promise in education, assessment, and
tutoring is clear, challenges remain. Our study not only sheds light on LLMs'
academic potential but also emphasizes the need for careful development and
application of AI in education. As AI technology advances, it is imperative to
establish frameworks and protocols for AI interaction, verify the accuracy of
AI-generated content, ensure worldwide access for diverse learners, and create
an educational environment where AI supports human expertise. This research
sets the stage for further exploration into the responsible use of AI to enrich
educational experiences and improve exam preparation and assessment methods.

æè¦ï¼äººå·¥æºæ§ (AI) çå¿«éæ¼é²ï¼å°¤å¶æ¯å¨å¤§åèªè¨æ¨¡å (LLM) åçæå¼ AI çé åï¼çºååé åçæç¨éåäºæ°éå¾ï¼ä½å¶å¨åæ¥­æè²ä¸­çè§è²ä»æªè¢«ååæ¢è¨ãæ¬ç ç©¶é¦æ¬¡å¼å¥äºåºæºï¼ç¨ä»¥è©ä¼°ä¸åä¸»è¦ LLM çæè½ï¼åæ¬ OpenAI çæ¨¡å (GPT-3.5 TurboãGPT-4 å GPT-4 Turbo)ãGoogle çæ¨¡å (PaLM 2ãGemini 1.0 Pro) å Anthropic çæ¨¡å (Claude 2 å Claude 2.1)ï¼éäºæ¨¡åå°ç¨æ¼ç ç©¶çåæ¥­èª²ç¨å¥å­¸ç¨åºä¸­çééµèè©¦ GMATãæåçåæé¡¯ç¤ºï¼å¤§å¤æ¸ LLM çè¡¨ç¾é½åªæ¼äººé¡èçï¼å¶ä¸­ GPT-4 Turbo ä¸ååªæ¼å¶ä»æ¨¡åï¼æ´è¶è¶äºé å°åå­¸é¢çç ç©¶çå¹³ååæ¸ãééæ¡ä¾ç ç©¶ï¼æ¬ç ç©¶æ¢è¨äº GPT-4 Turbo å¨è§£éç­æ¡ãè©ä¼°åæãè¾¨è­é¯èª¤ãèª¿æ´èªªæåç¢çæ¿ä»£æå¢æ¹é¢çè½åãèåä¸ä»£çæ¬ç¸æ¯ï¼ææ°ç LLM çæ¬ GPT-4 TurboãClaude 2.1 å Gemini 1.0 Pro å¨æ¨çä»»åæ¹é¢æé¡¯èçé²æ­¥ï¼å¸é¡¯äºå¶å¨è§£æ±ºè¤éåé¡æ¹é¢çæ½åãåç®¡ AI å¨æè²ãè©éåè¼å°æ¹é¢çæ¿è«¾å¾æç¢ºï¼ä½ä»æææ°å­å¨ãæåçç ç©¶ä¸åé¡æäº LLM çå­¸è¡æ½åï¼ä¹å¼·èª¿äºå¨æè²ä¸­å¯©æéç¼åæç¨ AI çå¿è¦æ§ãé¨è AI æè¡çé²æ­¥ï¼å»ºç« AI äºåçæ¶æ§ååå®ãé©è­ AI çæçå§å®¹çæºç¢ºæ§ãç¢ºä¿å¨çåå°å¤åå­¸ç¿èçå­åæ¬ï¼ä»¥ååµé ä¸å AI æ¯æäººé¡å°æ¥­ç¥è­çæè²ç°å¢è³ééè¦ãæ¬ç ç©¶çºé²ä¸æ­¥æ¢ç´¢è² è²¬ä»»å°ä½¿ç¨ AI ä¾è±å¯æè²é«é©ä¸¦æ¹åèè©¦æºååè©éæ¹æ³å¥ å®äºåºç¤ã

##### **XAI for In-hospital Mortality Prediction via Multimodal ICU Data**
2312.17624v1 by Xingqiao Li, Jindong Gu, Zhiyong Wang, Yancheng Yuan, Bo Du, Fengxiang He

Predicting in-hospital mortality for intensive care unit (ICU) patients is
key to final clinical outcomes. AI has shown advantaged accuracy but suffers
from the lack of explainability. To address this issue, this paper proposes an
eXplainable Multimodal Mortality Predictor (X-MMP) approaching an efficient,
explainable AI solution for predicting in-hospital mortality via multimodal ICU
data. We employ multimodal learning in our framework, which can receive
heterogeneous inputs from clinical data and make decisions. Furthermore, we
introduce an explainable method, namely Layer-Wise Propagation to Transformer,
as a proper extension of the LRP method to Transformers, producing explanations
over multimodal inputs and revealing the salient features attributed to
prediction. Moreover, the contribution of each modality to clinical outcomes
can be visualized, assisting clinicians in understanding the reasoning behind
decision-making. We construct a multimodal dataset based on MIMIC-III and
MIMIC-III Waveform Database Matched Subset. Comprehensive experiments on
benchmark datasets demonstrate that our proposed framework can achieve
reasonable interpretation with competitive prediction accuracy. In particular,
our framework can be easily transferred to other clinical tasks, which
facilitates the discovery of crucial factors in healthcare research.

æè¦ï¼é æ¸¬å è­·çæ¿ (ICU) çæ£çé¢å§æ­»äº¡çæ¯æçµè¨åºçµæçééµãAI å·²å±ç¾åºåªç°çæºç¢ºåº¦ï¼ä½å»ç¼ºä¹å¯è§£éæ§ãçºäºè§£æ±ºéååé¡ï¼æ¬ææåºäºä¸åå¯è§£éçå¤æ¨¡å¼æ­»äº¡çé æ¸¬å¨ (X-MMP)ï¼æ¡ç¨ææä¸å¯è§£éç AI æ¹å¼ï¼èç±å¤æ¨¡å¼ ICU è³æä¾é æ¸¬é¢å§æ­»äº¡çãæåå¨æ¶æ§ä¸­æ¡ç¨å¤æ¨¡å¼å­¸ç¿ï¼å¯ä»¥æ¥æ¶ä¾èªè¨åºè³æçç°è³ªè¼¸å¥ä¸¦ååºæ±ºç­ãæ­¤å¤ï¼æåå¼å¥äºä¸åå¯è§£éçæ¹æ³ï¼ä¹å°±æ¯åå±¤å³æ­è³ Transformerï¼ä½çº LRP æ¹æ³é©ç¶å°å»¶ä¼¸è³ Transformerï¼å°å¤æ¨¡å¼è¼¸å¥ç¢çè§£éï¼ä¸¦æ­é²æ­¸å æ¼é æ¸¬çé¡¯èç¹å¾µãæ­¤å¤ï¼æ¯åæ¨¡å¼å°è¨åºçµæçè²¢ç»å¯ä»¥è¦è¦ºåï¼åå©è¨åºé«å¸«äºè§£æ±ºç­èå¾ççç±ãæåæ ¹æ MIMIC-III å MIMIC-III æ³¢å½¢è³æåº«æ¯å°å­éå»ºæ§äºä¸åå¤æ¨¡å¼è³æéãå¨åºæºè³æéä¸çå¨é¢å¯¦é©è­æï¼æåæåºçæ¶æ§å¯ä»¥éæåççè©®éï¼ä¸¦å·åç«¶ç­åçé æ¸¬æºç¢ºåº¦ãç¹å¥æ¯ï¼æåçæ¶æ§å¯ä»¥è¼é¬å°è½ç§»å°å¶ä»è¨åºä»»åï¼éæå©æ¼å¨é«çä¿å¥ç ç©¶ä¸­ç¼ç¾ééµå ç´ ã

##### **Joining Forces for Pathology Diagnostics with AI Assistance: The EMPAIA Initiative**
2401.09450v2 by Norman Zerbe, Lars Ole Schwen, Christian GeiÃler, Katja Wiesemann, Tom Bisson, Peter Boor, Rita Carvalho, Michael Franz, Christoph Jansen, Tim-Rasmus Kiehl, BjÃ¶rn Lindequist, Nora Charlotte Pohlan, Sarah Schmell, Klaus Strohmenger, Falk Zakrzewski, Markus Plass, Michael Takla, Tobias KÃ¼ster, AndrÃ© Homeyer, Peter Hufnagl

Over the past decade, artificial intelligence (AI) methods in pathology have
advanced substantially. However, integration into routine clinical practice has
been slow due to numerous challenges, including technical and regulatory
hurdles in translating research results into clinical diagnostic products and
the lack of standardized interfaces. The open and vendor-neutral EMPAIA
initiative addresses these challenges. Here, we provide an overview of EMPAIA's
achievements and lessons learned. EMPAIA integrates various stakeholders of the
pathology AI ecosystem, i.e., pathologists, computer scientists, and industry.
In close collaboration, we developed technical interoperability standards,
recommendations for AI testing and product development, and explainability
methods. We implemented the modular and open-source EMPAIA platform and
successfully integrated 14 AI-based image analysis apps from 8 different
vendors, demonstrating how different apps can use a single standardized
interface. We prioritized requirements and evaluated the use of AI in real
clinical settings with 14 different pathology laboratories in Europe and Asia.
In addition to technical developments, we created a forum for all stakeholders
to share information and experiences on digital pathology and AI. Commercial,
clinical, and academic stakeholders can now adopt EMPAIA's common open-source
interfaces, providing a unique opportunity for large-scale standardization and
streamlining of processes. Further efforts are needed to effectively and
broadly establish AI assistance in routine laboratory use. To this end, a
sustainable infrastructure, the non-profit association EMPAIA International,
has been established to continue standardization and support broad
implementation and advocacy for an AI-assisted digital pathology future.

æè¦ï¼å¨éå»çåå¹´ä¸­ï¼ççå­¸ä¸­çäººå·¥æºæ§ (AI) æ¹æ³å·²å¤§å¹é²æ­¥ãç¶èï¼ç±æ¼è¨±å¤ææ°ï¼åæ¬å°ç ç©¶çµæè½åçºè¨åºè¨ºæ·ç¢åå¨æè¡åæ³è¦æ¹é¢çéç¤ï¼ä»¥åç¼ºä¹æ¨æºåä»é¢ï¼å°è´æ´åå°å¸¸è¦è¨åºå¯¦åä¸­é²å±ç·©æ¢ãéæ¾ä¸èä¾æåç¡éç EMPAIA è¨ç«æå°äºéäºææ°ãå¨æ­¤ï¼æåæä¾ EMPAIA çæå°±åç¶é©æè¨çæ¦è¿°ãEMPAIA æ´åäºççå­¸ AI çæç³»çµ±çååå©å®³éä¿äººï¼å³ççå­¸å®¶ãé»è¦ç§å­¸å®¶åç¢æ¥­ãå¨å¯ååä½ä¸ï¼æåå¶å®äºæè¡äºéæ§æ¨æºãAI æ¸¬è©¦åç¢åéç¼å»ºè­°ï¼ä»¥åå¯è§£éæ§æ¹æ³ãæåå¯¦ä½äºæ¨¡çµåä¸éæ¾åå§ç¢¼ç EMPAIA å¹³èºï¼ä¸¦æåæ´åäºä¾èª 8 åä¸åä¾æåç 14 ååºæ¼ AI çå½±ååææç¨ç¨å¼ï¼å±ç¤ºäºä¸åçæç¨ç¨å¼å¦ä½ä½¿ç¨å®ä¸çæ¨æºåä»é¢ãæååªåèæ®éæ±ï¼ä¸¦è©ä¼°äº AI å¨æ­æ´²åäºæ´²ç 14 åä¸åççå¯¦é©å®¤ä¸­çå¯¦éè¨åºæç¨ãé¤äºæè¡éç¼å¤ï¼æåéçºææå©å®³éä¿äººå»ºç«äºä¸åè«å£ï¼ä»¥åäº«æ¸ä½ççå­¸å AI çè³è¨åç¶é©ãåæ¥­ãè¨åºåå­¸è¡å©å®³éä¿äººç¾å¨å¯ä»¥æ¡ç¨ EMPAIA çå¸¸è¦éæ¾åå§ç¢¼ä»é¢ï¼éçºå¤§è¦æ¨¡æ¨æºååç°¡åæµç¨æä¾äºç¨ç¹çæ©æãéè¦é²ä¸æ­¥çåªåæè½ææä¸å»£æ³å°å»ºç«ä¾è¡å¯¦é©å®¤ä½¿ç¨ä¸­ç AI è¼å©ãçºæ­¤ï¼å·²æç«éçå©åæ EMPAIA Internationalï¼ä»¥ä½çºæ°¸çºåºç¤æ¶æ§ï¼ç¹¼çºé²è¡æ¨æºåï¼ä¸¦æ¯æ´å»£æ³å¯¦ä½åå¡å° AI è¼å©æ¸ä½ççå­¸çæªä¾ã

##### **Robust Stochastic Graph Generator for Counterfactual Explanations**
2312.11747v2 by Mario Alfonso Prado-Romero, Bardh Prenkaj, Giovanni Stilo

Counterfactual Explanation (CE) techniques have garnered attention as a means
to provide insights to the users engaging with AI systems. While extensively
researched in domains such as medical imaging and autonomous vehicles, Graph
Counterfactual Explanation (GCE) methods have been comparatively
under-explored. GCEs generate a new graph similar to the original one, with a
different outcome grounded on the underlying predictive model. Among these GCE
techniques, those rooted in generative mechanisms have received relatively
limited investigation despite demonstrating impressive accomplishments in other
domains, such as artistic styles and natural language modelling. The preference
for generative explainers stems from their capacity to generate counterfactual
instances during inference, leveraging autonomously acquired perturbations of
the input graph. Motivated by the rationales above, our study introduces
RSGG-CE, a novel Robust Stochastic Graph Generator for Counterfactual
Explanations able to produce counterfactual examples from the learned latent
space considering a partially ordered generation sequence. Furthermore, we
undertake quantitative and qualitative analyses to compare RSGG-CE's
performance against SoA generative explainers, highlighting its increased
ability to engendering plausible counterfactual candidates.

æè¦ï¼åäºå¯¦è§£é (CE) æè¡å·²å¼èµ·éæ³¨ï¼ä½çºä¸ç¨®çºè AI ç³»çµ±äºåçä½¿ç¨èæä¾è¦è§£çæ¹æ³ãéç¶å¨é«å­¸å½±ååèªåé§é§æ±½è»ç­é åå»£æ³ç ç©¶ï¼åå½¢åäºå¯¦è§£é (GCE) æ¹æ³ç¸å°è¼å°è¢«æ¢ç´¢ãGCE æç¢çä¸åé¡ä¼¼æ¼åå§åå½¢çæ°åå½¢ï¼ä¸¦æ ¹æåºç¤é æ¸¬æ¨¡åç¢çä¸åççµæãå¨éäº GCE æè¡ä¸­ï¼åç®¡å¨å¶ä»é åï¼ä¾å¦èè¡é¢¨æ ¼åèªç¶èªè¨å»ºæ¨¡ï¼ä¸­å±ç¾åºä»¤äººå°è±¡æ·±å»çæå°±ï¼ä½æ¤åºæ¼çææ©å¶çæè¡ç²å¾çéæ³¨ç¸å°æéãå°çæå¼è§£éå¨çåå¥½æºæ¼å®åå¨æ¨çæéç¢çåäºå¯¦å¯¦ä¾çè½åï¼å©ç¨è¼¸å¥åå½¢çèªä¸»ç²åæ¾åãåºæ¼ä¸è¿°çç±ï¼æåçç ç©¶å¼å¥äº RSGG-CEï¼ä¸ç¨®ç¨æ¼åäºå¯¦è§£éçæ°åç©©å¥é¨æ©åå½¢çæå¨ï¼è½å¤ å¾å­¸ç¿å°çæ½å¨ç©ºéä¸­ç¢çåäºå¯¦ç¯ä¾ï¼èæ®é¨åæåºççæåºåãæ­¤å¤ï¼æåé²è¡å®éåå®æ§åæï¼ä»¥æ¯è¼ RSGG-CE çæè½è SoA çæå¼è§£éå¨ï¼å¼·èª¿å¶å¢å¼·äºç¢çåçè§£éåé¸çè½åã

##### **Evaluating the Utility of Model Explanations for Model Development**
2312.06032v1 by Shawn Im, Jacob Andreas, Yilun Zhou

One of the motivations for explainable AI is to allow humans to make better
and more informed decisions regarding the use and deployment of AI models. But
careful evaluations are needed to assess whether this expectation has been
fulfilled. Current evaluations mainly focus on algorithmic properties of
explanations, and those that involve human subjects often employ subjective
questions to test human's perception of explanation usefulness, without being
grounded in objective metrics and measurements. In this work, we evaluate
whether explanations can improve human decision-making in practical scenarios
of machine learning model development. We conduct a mixed-methods user study
involving image data to evaluate saliency maps generated by SmoothGrad,
GradCAM, and an oracle explanation on two tasks: model selection and
counterfactual simulation. To our surprise, we did not find evidence of
significant improvement on these tasks when users were provided with any of the
saliency maps, even the synthetic oracle explanation designed to be simple to
understand and highly indicative of the answer. Nonetheless, explanations did
help users more accurately describe the models. These findings suggest caution
regarding the usefulness and potential for misunderstanding in saliency-based
explanations.

æè¦ï¼å¯è§£é AI çåæ©ä¹ä¸æ¯è®äººåå¨ä½¿ç¨åé¨ç½² AI æ¨¡åæååºæ´å¥½ãæ´ææºçæ±ºç­ãä½éè¦ä»ç´°è©ä¼°ä»¥è©ä¼°æ¯å¦å·²éå°æ­¤é æãç®åçè©ä¼°ä¸»è¦éä¸­å¨è§£éçæ¼ç®æ³ç¹æ§ï¼èæ¶åäººé¡åè©¦èçè©ä¼°éå¸¸æ¡ç¨ä¸»è§åé¡ä¾æ¸¬è©¦äººé¡å°è§£éæç¨æ§ççæ³ï¼èæ²æåºæ¼å®¢è§ææ¨åæ¸¬éãå¨éé å·¥ä½ä¸­ï¼æåè©ä¼°è§£éæ¯å¦å¯ä»¥å¨æ©å¨å­¸ç¿æ¨¡åéç¼çå¯¦éå ´æ¯ä¸­æ¹åäººé¡æ±ºç­å¶å®ãæåé²è¡äºä¸é æ¶åå½±åè³æçæ··åæ¹æ³ä½¿ç¨èç ç©¶ï¼ä»¥è©ä¼° SmoothGradãGradCAM åé è¨è§£éå¨å©åä»»åä¸­ç¢ççé¡¯èæ§åï¼æ¨¡åé¸æååäºå¯¦æ¨¡æ¬ãä»¤äººé©è¨çæ¯ï¼æåæ²æç¼ç¾ä»»ä½é¡¯èæ§åï¼å³ä½¿æ¯è¨­è¨çºææ¼çè§£ä¸é«åº¦æç¤ºç­æ¡çåæé è¨è§£éï¼è½è®ä½¿ç¨èå¨éäºä»»åä¸é¡¯èæ¹åçè­æãåç®¡å¦æ­¤ï¼è§£éç¢ºå¯¦æå©æ¼ä½¿ç¨èæ´æºç¢ºå°æè¿°æ¨¡åãéäºç¼ç¾æç¤ºæåè¦å°åºæ¼é¡¯èæ§çè§£éä¸­å¯è½å­å¨èª¤è§£çæç¨æ§ä¿æè¬¹æã

##### **Building Trustworthy NeuroSymbolic AI Systems: Consistency, Reliability, Explainability, and Safety**
2312.06798v1 by Manas Gaur, Amit Sheth

Explainability and Safety engender Trust. These require a model to exhibit
consistency and reliability. To achieve these, it is necessary to use and
analyze data and knowledge with statistical and symbolic AI methods relevant to
the AI application - neither alone will do. Consequently, we argue and seek to
demonstrate that the NeuroSymbolic AI approach is better suited for making AI a
trusted AI system. We present the CREST framework that shows how Consistency,
Reliability, user-level Explainability, and Safety are built on NeuroSymbolic
methods that use data and knowledge to support requirements for critical
applications such as health and well-being. This article focuses on Large
Language Models (LLMs) as the chosen AI system within the CREST framework. LLMs
have garnered substantial attention from researchers due to their versatility
in handling a broad array of natural language processing (NLP) scenarios. For
example, ChatGPT and Google's MedPaLM have emerged as highly promising
platforms for providing information in general and health-related queries,
respectively. Nevertheless, these models remain black boxes despite
incorporating human feedback and instruction-guided tuning. For instance,
ChatGPT can generate unsafe responses despite instituting safety guardrails.
CREST presents a plausible approach harnessing procedural and graph-based
knowledge within a NeuroSymbolic framework to shed light on the challenges
associated with LLMs.

æè¦ï¼å¯è§£éæ§åå®å¨æ§å»ºç«ä¿¡ä»»ãéäºéè¦ä¸åæ¨¡åä¾å±ç¤ºä¸è´æ§åå¯é æ§ãçºäºå¯¦ç¾éäºï¼æå¿è¦ä½¿ç¨ååææ¸æåç¥è­ï¼ä¸¦ä½¿ç¨è AI æç¨ç¸éççµ±è¨åç¬¦è AI æ¹æ³ - å®ç¨ä½¿ç¨ä»»ä½ä¸ç¨®æ¹æ³é½ä¸æå¥æãå æ­¤ï¼æåä¸»å¼µä¸¦è©¦åè­æ NeuroSymbolic AI æ¹æ³æ´é©åæ¼ä½¿ AI æçºåä¿¡ä»»ç AI ç³»çµ±ãæåæåºäº CREST æ¡æ¶ï¼å±ç¤ºäºä¸è´æ§ãå¯é æ§ãä½¿ç¨èå±¤ç´çå¯è§£éæ§åå®å¨æ§æ¯å¦ä½å»ºç«å¨ NeuroSymbolic æ¹æ³ä¸çï¼è©²æ¹æ³ä½¿ç¨æ¸æåç¥è­ä¾æ¯æééµæç¨ï¼ä¾å¦å¥åº·åç¦ç¥ï¼çè¦æ±ãæ¬æéé»éæ³¨å¤§åèªè¨æ¨¡å (LLM)ï¼å çºå®æ¯ CREST æ¡æ¶ä¸­é¸æç AI ç³»çµ±ãLLM å å¶å¨èçå»£æ³çèªç¶èªè¨èç (NLP) å ´æ¯æ¹é¢çå¤åè½æ§èååç ç©¶äººå¡çéæ³¨ãä¾å¦ï¼ChatGPT å Google ç MedPaLM å·²æçºæä¾ä¸è¬åå¥åº·ç¸éæ¥è©¢ä¿¡æ¯çæ¥µæå¸æçå¹³å°ãåç®¡å¦æ­¤ï¼éäºæ¨¡åä»ç¶æ¯é»çå­ï¼åç®¡ç´å¥äºäººé¡åé¥åæä»¤å¼å°çèª¿æ´ãä¾å¦ï¼åç®¡å¶å®äºå®å¨é²è­·æªæ½ï¼ChatGPT ä»å¯è½ç¢çä¸å®å¨çåæãCREST æåºäºä¸ç¨®åççæ¹æ³ï¼å¨ NeuroSymbolic æ¡æ¶ä¸­å©ç¨ç¨åºååºæ¼åè¡¨çç¥è­ï¼ä»¥é¡æè LLM ç¸éçææ°ã

##### **Deployment of a Robust and Explainable Mortality Prediction Model: The COVID-19 Pandemic and Beyond**
2311.17133v1 by Jacob R. Epifano, Stephen Glass, Ravi P. Ramachandran, Sharad Patel, Aaron J. Masino, Ghulam Rasool

This study investigated the performance, explainability, and robustness of
deployed artificial intelligence (AI) models in predicting mortality during the
COVID-19 pandemic and beyond. The first study of its kind, we found that
Bayesian Neural Networks (BNNs) and intelligent training techniques allowed our
models to maintain performance amidst significant data shifts. Our results
emphasize the importance of developing robust AI models capable of matching or
surpassing clinician predictions, even under challenging conditions. Our
exploration of model explainability revealed that stochastic models generate
more diverse and personalized explanations thereby highlighting the need for AI
models that provide detailed and individualized insights in real-world clinical
settings. Furthermore, we underscored the importance of quantifying uncertainty
in AI models which enables clinicians to make better-informed decisions based
on reliable predictions. Our study advocates for prioritizing implementation
science in AI research for healthcare and ensuring that AI solutions are
practical, beneficial, and sustainable in real-world clinical environments. By
addressing unique challenges and complexities in healthcare settings,
researchers can develop AI models that effectively improve clinical practice
and patient outcomes.

æè¦ï¼æ¬ç ç©¶è°æ¥äºå¨ COVID-19 ç«ææé´åä»¥åé¢æµæ­»äº¡çæ¶ï¼å·²é¨ç½²äººå·¥æºè½ (AI) æ¨¡åçæ§è½ãå¯è§£éæ§åç¨³å¥æ§ãä½ä¸ºåç±»ç ç©¶ä¸­çé¦ä¾ï¼æä»¬åç°è´å¶æ¯ç¥ç»ç½ç» (BNN) åæºè½è®­ç»ææ¯è®©æä»¬çæ¨¡åå¨æ°æ®åçéå¤§ååæ¶ä»è½ä¿ææ§è½ãæä»¬çç»æå¼ºè°äºå¼åç¨³å¥ç AI æ¨¡åçéè¦æ§ï¼å³ä½¿å¨å·ææææ§çæ¡ä»¶ä¸ï¼è¿äºæ¨¡åä¹è½å¹éæè¶è¶ä¸´åºå»ççé¢æµãæä»¬å¯¹æ¨¡åå¯è§£éæ§çæ¢ç´¢è¡¨æï¼éæºæ¨¡åä¼äº§çæ´å¤æ ·åä¸ä¸ªæ§åçè§£éï¼ä»èçªåºäºå¨ç°å®ä¸ççä¸´åºç¯å¢ä¸­æä¾è¯¦ç»ä¸ä¸ªæ§åè§è§£ç AI æ¨¡åçå¿è¦æ§ãæ­¤å¤ï¼æä»¬å¼ºè°äºéå AI æ¨¡åä¸­ä¸ç¡®å®æ§çéè¦æ§ï¼è¿ä½¿ä¸´åºå»çè½å¤æ ¹æ®å¯é çé¢æµååºæ´ææºçå³ç­ãæä»¬çç ç©¶æå¡å¨å»çä¿å¥ç AI ç ç©¶ä¸­ä¼åèèå®æ½ç§å­¦ï¼å¹¶ç¡®ä¿ AI è§£å³æ¹æ¡å¨ç°å®ä¸ççä¸´åºç¯å¢ä¸­å®ç¨ãæçä¸å¯æç»­ãéè¿è§£å³å»çä¿å¥ç¯å¢ä¸­çç¬ç¹ææåå¤ææ§ï¼ç ç©¶äººåå¯ä»¥å¼ååºæææ¹åä¸´åºå®è·µåæ£èé¢åç AI æ¨¡åã

##### **Variational Autoencoders for Feature Exploration and Malignancy Prediction of Lung Lesions**
2311.15719v1 by Benjamin Keel, Aaron Quyn, David Jayne, Samuel D. Relton

Lung cancer is responsible for 21% of cancer deaths in the UK and five-year
survival rates are heavily influenced by the stage the cancer was identified
at. Recent studies have demonstrated the capability of AI methods for accurate
and early diagnosis of lung cancer from routine scans. However, this evidence
has not translated into clinical practice with one barrier being a lack of
interpretable models. This study investigates the application Variational
Autoencoders (VAEs), a type of generative AI model, to lung cancer lesions.
Proposed models were trained on lesions extracted from 3D CT scans in the
LIDC-IDRI public dataset. Latent vector representations of 2D slices produced
by the VAEs were explored through clustering to justify their quality and used
in an MLP classifier model for lung cancer diagnosis, the best model achieved
state-of-the-art metrics of AUC 0.98 and 93.1% accuracy. Cluster analysis shows
the VAE latent space separates the dataset of malignant and benign lesions
based on meaningful feature components including tumour size, shape, patient
and malignancy class. We also include a comparative analysis of the standard
Gaussian VAE (GVAE) and the more recent Dirichlet VAE (DirVAE), which replaces
the prior with a Dirichlet distribution to encourage a more explainable latent
space with disentangled feature representation. Finally, we demonstrate the
potential for latent space traversals corresponding to clinically meaningful
feature changes.

æè¦ï¼èºçå è±åççæ­»äº¡äººæ¸ç 21%ï¼äºå¹´å­æ´»çå¾å¤§ç¨åº¦åæ±ºæ¼ççè¢«ç¼ç¾çéæ®µãæè¿çç ç©¶å·²è­æäººå·¥æºè½æ¹æ³å·æå¾ä¾è¡ææä¸­æºç¢ºåæ©è¨ºæ·èºççè½åãç¶èï¼æ­¤è­æå°æªè½åçºè¨åºå¯¦åï¼å¶ä¸­ä¸åéç¤æ¯ç¼ºä¹å¯è§£éçæ¨¡åãæ¬ç ç©¶æ¢è¨äºæç¨è®åèªåç·¨ç¢¼å¨ (VAE)ï¼ä¸ç¨®çæå¼äººå·¥æºè½æ¨¡åï¼æ¼èºççç¶ãå°æåºçæ¨¡åè¨ç·´æ¼å¾ LIDC-IDRI å¬å±æ¸æéä¸­æåç 3D é»è¦æ·å±¤ææçç¶ãééèé¡æ¢ç´¢äº VAE çæç 2D åççæ½å¨åéè¡¨ç¤ºï¼ä»¥è­æå¶åè³ªï¼ä¸¦ç¨æ¼èºçè¨ºæ·ç MLP åé¡å¨æ¨¡åï¼æä½³æ¨¡åéå°äº AUC 0.98 å 93.1% æºç¢ºåº¦çæåé²ææ¨ãèé¡åæé¡¯ç¤ºï¼VAE æ½å¨ç©ºéæ ¹æææç¾©çç¹å¾µçµæï¼åæ¬è«ç¤å¤§å°ãå½¢çãæ£èåæ¡æ§é¡å¥ï¼å°æ¡æ§åè¯æ§çç¶çæ¸æéåéãæåéåæ¬æ¨æºé«æ¯ VAE (GVAE) åæ´æ°ççå©åé· VAE (DirVAE) çæ¯è¼åæï¼å¾èç¨çå©åé·åä½åä»£åé©ï¼ä»¥ä¿é²å·æè§£éç¹å¾µè¡¨ç¤ºçæ´å·å¯è§£éæ§çæ½å¨ç©ºéãæå¾ï¼æåå±ç¤ºäºèè¨åºææç¾©çç¹å¾µè®åç¸æçæ½å¨ç©ºéæ©«è¶çæ½åã

##### **MRxaI: Black-Box Explainability for Image Classifiers in a Medical Setting**
2311.14471v1 by Nathan Blake, Hana Chockler, David A. Kelly, Santiago Calderon Pena, Akchunya Chanchal

Existing tools for explaining the output of image classifiers can be divided
into white-box, which rely on access to the model internals, and black-box,
agnostic to the model. As the usage of AI in the medical domain grows, so too
does the usage of explainability tools. Existing work on medical image
explanations focuses on white-box tools, such as gradcam. However, there are
clear advantages to switching to a black-box tool, including the ability to use
it with any classifier and the wide selection of black-box tools available. On
standard images, black-box tools are as precise as white-box. In this paper we
compare the performance of several black-box methods against gradcam on a brain
cancer MRI dataset. We demonstrate that most black-box tools are not suitable
for explaining medical image classifications and present a detailed analysis of
the reasons for their shortcomings. We also show that one black-box tool, a
causal explainability-based rex, performs as well as \gradcam.

æè¦ï¼ç¾æçåååé¡å¨è¼¸åºè§£éå·¥å·å¯åçºä¾è³´æ¼æ¨¡åå§é¨å­åæ¬éçç½çï¼ä»¥åèæ¨¡åç¡éçé»çãé¨è AI å¨é«çé åçä½¿ç¨å¢å ï¼å¯è§£éæ§å·¥å·çä½¿ç¨ä¹é¨ä¹å¢å ãç¾æé«å­¸å½±åè§£éçå·¥ä½éé»å¨æ¼ç½çå·¥å·ï¼ä¾å¦ gradcamãç¶èï¼åæå°é»çå·¥å·ææé¡¯çåªé»ï¼åæ¬è½å¤ èä»»ä½åé¡å¨ä¸èµ·ä½¿ç¨ï¼ä»¥åå»£æ³çé»çå·¥å·å¯ä¾é¸æãå¨æ¨æºå½±åä¸ï¼é»çå·¥å·èç½çä¸æ¨£ç²¾ç¢ºãå¨æ¬æä¸­ï¼æåæ¯è¼äºå¤ç¨®é»çæ¹æ³å¨è¦ç MRI è³æéä¸è gradcam çæè½ãæåè­æå¤§å¤æ¸é»çå·¥å·ä¸é©åè§£éé«å­¸å½±ååé¡ï¼ä¸¦è©³ç´°åæå¶ç¼ºé»çåå ãæåéè¡¨æä¸ç¨®é»çå·¥å·ï¼åºæ¼å æå¯è§£éæ§ç rexï¼è¡¨ç¾è \gradcam ä¸æ¨£å¥½ã

##### **Moderating Model Marketplaces: Platform Governance Puzzles for AI Intermediaries**
2311.12573v2 by Robert Gorwa, Michael Veale

The AI development community is increasingly making use of hosting
intermediaries such as Hugging Face provide easy access to user-uploaded models
and training data. These model marketplaces lower technical deployment barriers
for hundreds of thousands of users, yet can be used in numerous potentially
harmful and illegal ways. In this article, we explain ways in which AI systems,
which can both `contain' content and be open-ended tools, present one of the
trickiest platform governance challenges seen to date. We provide case studies
of several incidents across three illustrative platforms -- Hugging Face,
GitHub and Civitai -- to examine how model marketplaces moderate models.
Building on this analysis, we outline important (and yet nevertheless limited)
practices that industry has been developing to respond to moderation demands:
licensing, access and use restrictions, automated content moderation, and open
policy development. While the policy challenge at hand is a considerable one,
we conclude with some ideas as to how platforms could better mobilize resources
to act as a careful, fair, and proportionate regulatory access point.

æè¦ï¼AI ç¼å±ç¤¾ç¾¤æ¥çå©ç¨ Hugging Face ç­è¨ç®¡ä¸­ä»ï¼æä¾ä½¿ç¨èä¸å³ä¹æ¨¡åèè¨ç·´è³æçç°¡æåå¾ç®¡éãéäºæ¨¡åå¸ééä½äºæ¸åè¬åä½¿ç¨èçæè¡é¨ç½²éæª»ï¼ä½å»å¯è½è¢«ç¨æ¼è¨±å¤æ½å¨æå®³ä¸éæ³çç¨éãå¨æ¬æä¸­ï¼æåèªªæäº AI ç³»çµ±æ¢å¯ä»¥ãåå«ãå§å®¹ï¼ä¹å¯ä»¥ä½çºéæ¾å¼å·¥å·ï¼éæåºäºè¿ä»çºæ­¢ææ£æçå¹³å°æ²»çææ°ä¹ä¸ãæåæä¾ Hugging FaceãGitHub å Civitai ç­ä¸åèªªææ§å¹³å°ä¸æ¸èµ·äºä»¶çæ¡ä¾ç ç©¶ï¼ä»¥æ¢è¨æ¨¡åå¸éå¦ä½æ§ç®¡æ¨¡åãæ ¹ææ­¤åæï¼æåæ¦è¿°äºç¢æ¥­çºåææ§ç®¡éæ±èç¼å±çéè¦ï¼ä½ä»æéï¼å¯¦åï¼ææ¬ãå­ååä½¿ç¨éå¶ãèªåå§å®¹æ§ç®¡åéæ¾å¼æ¿ç­ç¼å±ãåç®¡ç®åé¢è¨çæ¿ç­ææ°ç¸ç¶å´å³»ï¼æåä»æåºäºä¸äºæ³æ³ï¼èªªæå¹³å°å¦ä½è½æ´å¥½å°åå¡è³æºï¼ä½çºè¬¹æãå¬å¹³åé©åº¦çæ³è¦å­åé»ã

##### **Ovarian Cancer Data Analysis using Deep Learning: A Systematic Review from the Perspectives of Key Features of Data Analysis and AI Assurance**
2311.11932v1 by Muta Tah Hira, Mohammad A. Razzaque, Mosharraf Sarker

Background and objectives: By extracting this information, Machine or Deep
Learning (ML/DL)-based autonomous data analysis tools can assist clinicians and
cancer researchers in discovering patterns and relationships from complex data
sets. Many DL-based analyses on ovarian cancer (OC) data have recently been
published. These analyses are highly diverse in various aspects of cancer
(e.g., subdomain(s) and cancer type they address) and data analysis features.
However, a comprehensive understanding of these analyses in terms of these
features and AI assurance (AIA) is currently lacking. This systematic review
aims to fill this gap by examining the existing literature and identifying
important aspects of OC data analysis using DL, explicitly focusing on the key
features and AI assurance perspectives. Methods: The PRISMA framework was used
to conduct comprehensive searches in three journal databases. Only studies
published between 2015 and 2023 in peer-reviewed journals were included in the
analysis. Results: In the review, a total of 96 DL-driven analyses were
examined. The findings reveal several important insights regarding DL-driven
ovarian cancer data analysis: - Most studies 71% (68 out of 96) focused on
detection and diagnosis, while no study addressed the prediction and prevention
of OC. - The analyses were predominantly based on samples from a non-diverse
population (75% (72/96 studies)), limited to a geographic location or country.
- Only a small proportion of studies (only 33% (32/96)) performed integrated
analyses, most of which used homogeneous data (clinical or omics). - Notably, a
mere 8.3% (8/96) of the studies validated their models using external and
diverse data sets, highlighting the need for enhanced model validation, and -
The inclusion of AIA in cancer data analysis is in a very early stage; only
2.1% (2/96) explicitly addressed AIA through explainability.

æè¦ï¼<paragraph>èæ¯åç®æ¨ï¼ééæåéäºè³è¨ï¼æ©å¨ææ·±åº¦å­¸ç¿ (ML/DL) åºæ¼èªä¸»æ¸æåæå·¥å·å¯ä»¥åå©è¨åºé«çåççç ç©¶äººå¡å¾è¤éçæ¸æéä¸­ç¼ç¾æ¨¡å¼åéä¿ãæè¿å·²ç¼è¡¨è¨±å¤åºæ¼ DL çåµå·¢ç (OC) æ¸æåæãéäºåæå¨çççååæ¹é¢ï¼ä¾å¦ï¼å®åæ¶åçå­é ååççé¡åï¼åæ¸æåæåè½æ¹é¢é«åº¦å¤æ¨£åãç¶èï¼ç®åç¼ºä¹å°éäºåæå¨éäºç¹å¾µå AI ä¿è­ (AIA) æ¹é¢çå¨é¢çè§£ãéç¯ç³»çµ±æ§åé¡§æ¨å¨ééæª¢è¦ç¾ææç»ä¸¦æç¢ºéæ³¨ééµç¹å¾µå AI ä¿è­è§é»ï¼ä¾å¡«è£éåç©ºç½ãæ¹æ³ï¼ä½¿ç¨ PRISMA æ¶æ§å¨ä¸åæåè³æåº«ä¸­é²è¡å¨é¢æå°ãåæååæ¬ 2015 å¹´è³ 2023 å¹´éç¼è¡¨æ¼åè¡è©å¯©æåçç ç©¶ãçµæï¼å¨åé¡§ä¸­ï¼ç¸½å±æª¢è¦äº 96 é ç± DL é©åçåæãç ç©¶çµææ­ç¤ºäºå¹¾åéæ¼ç± DL é©åçåµå·¢çæ¸æåæçéè¦è¦è§£ï¼- å¤§å¤æ¸ç ç©¶ 71%ï¼96 é ä¸­æ 68 é ï¼å°æ³¨æ¼æª¢æ¸¬åè¨ºæ·ï¼èæ²æç ç©¶æ¢è¨ OC çé æ¸¬åé é²ã- éäºåæä¸»è¦åºæ¼ä¾èªéå¤åæç¾¤çæ¨£æ¬ï¼75%ï¼96 é ç ç©¶ä¸­ç 72 é ï¼ï¼ï¼åéæ¼æåå°çä½ç½®æåå®¶ã- åªæå°é¨åç ç©¶ï¼å 33%ï¼96 é ç ç©¶ä¸­ç 32 é ï¼å·è¡æ´ååæï¼å¶ä¸­å¤§å¤æ¸ä½¿ç¨åè³ªæ¸æï¼è¨åºæçµå­¸ï¼ã- å¼å¾æ³¨æçæ¯ï¼åªæ 8.3%ï¼96 é ç ç©¶ä¸­ç 8 é ï¼ä½¿ç¨å¤é¨åå¤åæ¸æéé©è­äºå¶æ¨¡åï¼å¼·èª¿äºå å¼·æ¨¡åé©è­çå¿è¦æ§ï¼ä»¥å- å° AIA ç´å¥ççæ¸æåæä»èæ¼éå¸¸æ©æçéæ®µï¼åªæ 2.1%ï¼96 é ç ç©¶ä¸­ç 2 é ï¼ééå¯è§£éæ§æç¢ºæ¢è¨äº AIAã</paragraph>

##### **Representing visual classification as a linear combination of words**
2311.10933v1 by Shobhit Agarwal, Yevgeniy R. Semenov, William Lotter

Explainability is a longstanding challenge in deep learning, especially in
high-stakes domains like healthcare. Common explainability methods highlight
image regions that drive an AI model's decision. Humans, however, heavily rely
on language to convey explanations of not only "where" but "what".
Additionally, most explainability approaches focus on explaining individual AI
predictions, rather than describing the features used by an AI model in
general. The latter would be especially useful for model and dataset auditing,
and potentially even knowledge generation as AI is increasingly being used in
novel tasks. Here, we present an explainability strategy that uses a
vision-language model to identify language-based descriptors of a visual
classification task. By leveraging a pre-trained joint embedding space between
images and text, our approach estimates a new classification task as a linear
combination of words, resulting in a weight for each word that indicates its
alignment with the vision-based classifier. We assess our approach using two
medical imaging classification tasks, where we find that the resulting
descriptors largely align with clinical knowledge despite a lack of
domain-specific language training. However, our approach also identifies the
potential for 'shortcut connections' in the public datasets used. Towards a
functional measure of explainability, we perform a pilot reader study where we
find that the AI-identified words can enable non-expert humans to perform a
specialized medical task at a non-trivial level. Altogether, our results
emphasize the potential of using multimodal foundational models to deliver
intuitive, language-based explanations of visual tasks.

æè¦ï¼<paragraph>è§£éæ§æ¯æ·±åº¦å­¸ç¿ä¸­é·æçææ°ï¼ç¹å¥æ¯å¨é«çä¿å¥ç­é«é¢¨éªé åãå¸¸è¦çè§£éæ§æ¹æ³æå¼·èª¿é©å AI æ¨¡åæ±ºç­çå½±åååãç¶èï¼äººé¡å¾å¤§ç¨åº¦ä¾è³´èªè¨ä¾å³éä¸åæ¯ãå¨åªè£¡ãï¼éæãæ¯ä»éº¼ãçè§£éãæ­¤å¤ï¼å¤§å¤æ¸è§£éæ§æ¹æ³é½å°æ³¨æ¼è§£éåå¥ AI é æ¸¬ï¼èä¸æ¯æè¿° AI æ¨¡åä¸è¬ä½¿ç¨çç¹å¾µãå¾èå°æ¼æ¨¡ååè³æéç¨½æ ¸ç¹å¥æç¨ï¼çè³å¯è½å¨ AI æä¾æç¨æ¼æ°ç©ä»»åæç¢çç¥è­ãå¨æ­¤ï¼æåæåºä¸åä½¿ç¨è¦è¦ºèªè¨æ¨¡åä¾è¾¨è­è¦è¦ºåé¡ä»»åçèªè¨æè¿°ç¬¦çè§£éæ§ç­ç¥ãééå©ç¨å½±ååæå­ä¹éé åè¨ç·´çè¯ååµå¥ç©ºéï¼æåçåæ³å°æ°çåé¡ä»»åä¼°è¨çºä¸åç·æ§æå­çµåï¼å°è´æ¯åæå­é½ææ¬éï¼è¡¨ç¤ºå®èåºæ¼è¦è¦ºçåé¡å¨å°é½ãæåä½¿ç¨å©åé«å­¸å½±ååé¡ä»»åä¾è©ä¼°æåçåæ³ï¼æåç¼ç¾ç¢ççæè¿°ç¬¦å¨å¾å¤§ç¨åº¦ä¸èè¨åºç¥è­ä¸è´ï¼åç®¡ç¼ºä¹ç¹å®é åçèªè¨è¨ç·´ãç¶èï¼æåçåæ³ä¹ç¼ç¾äºæç¨å¬éè³æéä¸­çãæ·å¾é£ç·ãçå¯è½æ§ãçºäºéå°è§£éæ§çåè½æ§è¡¡éï¼æåé²è¡äºä¸é è©¦é©è®èç ç©¶ï¼ç¼ç¾ AI è­å¥çæå­è½è®éå°å®¶äººé¡å¨éå¹³å¡çå±¤ç´å·è¡å°æ¥­çé«çä»»åãç¸½ä¹ï¼æåççµæå¼·èª¿äºä½¿ç¨å¤æ¨¡å¼åºç¤æ¨¡åä¾æä¾ç´è§çãåºæ¼èªè¨çè¦è¦ºä»»åè§£éçæ½åã</paragraph>

##### **Towards objective and systematic evaluation of bias in artificial intelligence for medical imaging**
2311.02115v2 by Emma A. M. Stanley, Raissa Souza, Anthony Winder, Vedant Gulve, Kimberly Amador, Matthias Wilms, Nils D. Forkert

Artificial intelligence (AI) models trained using medical images for clinical
tasks often exhibit bias in the form of disparities in performance between
subgroups. Since not all sources of biases in real-world medical imaging data
are easily identifiable, it is challenging to comprehensively assess how those
biases are encoded in models, and how capable bias mitigation methods are at
ameliorating performance disparities. In this article, we introduce a novel
analysis framework for systematically and objectively investigating the impact
of biases in medical images on AI models. We developed and tested this
framework for conducting controlled in silico trials to assess bias in medical
imaging AI using a tool for generating synthetic magnetic resonance images with
known disease effects and sources of bias. The feasibility is showcased by
using three counterfactual bias scenarios to measure the impact of simulated
bias effects on a convolutional neural network (CNN) classifier and the
efficacy of three bias mitigation strategies. The analysis revealed that the
simulated biases resulted in expected subgroup performance disparities when the
CNN was trained on the synthetic datasets. Moreover, reweighing was identified
as the most successful bias mitigation strategy for this setup, and we
demonstrated how explainable AI methods can aid in investigating the
manifestation of bias in the model using this framework. Developing fair AI
models is a considerable challenge given that many and often unknown sources of
biases can be present in medical imaging datasets. In this work, we present a
novel methodology to objectively study the impact of biases and mitigation
strategies on deep learning pipelines, which can support the development of
clinical AI that is robust and responsible.

æè¦ï¼<paragraph>ä½¿ç¨é«çå½±åè¨ç·´çäººå·¥æºæ§ (AI) æ¨¡åï¼ç¨æ¼è¨åºä»»åæï¼å¸¸æå¨æè½ä¸å±ç¾åºæ¬¡ç¾¤é«ä¹éçå·®ç°ï¼å½¢æåè¦ãç±æ¼ä¸¦éææçå¯¦ä¸çé«çå½±åè³æä¸­çåè¦ä¾æºé½å®¹æè¾¨è­ï¼å æ­¤å¨é¢è©ä¼°éäºåè¦æ¯å¦ä½ç·¨ç¢¼å°æ¨¡åä¸­ï¼ä»¥ååè¦ç·©è§£æ¹æ³å¨æ¹åæè½å·®ç°æ¹é¢çè½åï¼æ¯ä¸é ææ°ãå¨æ¬æä¸­ï¼æåä»ç´¹äºä¸åæ°ç©çåææ¶æ§ï¼ç¨æ¼ç³»çµ±åä¸å®¢è§å°èª¿æ¥é«çå½±åä¸­çåè¦å° AI æ¨¡åçå½±é¿ãæåéç¼ä¸¦æ¸¬è©¦äºéåæ¶æ§ï¼ä»¥é²è¡åæ§çé»è¦æ¨¡æ¬è©¦é©ï¼ä½¿ç¨ä¸åå·¥å·ä¾è©ä¼°é«çå½±å AI ä¸­çåè¦ï¼è©²å·¥å·ç¨æ¼ç¢çå·æå·²ç¥ç¾çå½±é¿ååè¦ä¾æºçåæç£å±æ¯å½±åãå¯è¡æ§ééä½¿ç¨ä¸ååäºå¯¦åè¦æå¢ä¾è¡¡éæ¨¡æ¬åè¦ææå°å·ç©ç¥ç¶ç¶²è·¯ (CNN) åé¡å¨åä¸ååè¦ç·©è§£ç­ç¥çå½±é¿ï¼ä¸¦å±ç¤ºåºä¾ãåæé¡¯ç¤ºï¼ç¶ CNN å¨åæè³æéä¸åè¨æï¼æ¨¡æ¬åè¦æå°è´é æçæ¬¡ç¾¤é«æè½å·®ç°ãæ­¤å¤ï¼éæ°å æ¬è¢«èªçºæ¯æ­¤è¨­å®ä¸­ææåçåè¦ç·©è§£ç­ç¥ï¼æåå±ç¤ºäºè§£éæ§ AI æ¹æ³å¦ä½åå©ä½¿ç¨éåæ¶æ§èª¿æ¥æ¨¡åä¸­åè¦çè¡¨ç¾ãéç¼å¬å¹³ç AI æ¨¡åæ¯ä¸é éå¤§çææ°ï¼å çºé«çå½±åè³æéä¸­å¯è½å­å¨è¨±å¤ä¸ç¶å¸¸æªç¥çåè¦ä¾æºãå¨éé å·¥ä½ä¸­ï¼æåæåºäºä¸ç¨®æ°ç©çæ¹æ³ï¼ç¨æ¼å®¢è§å°ç ç©¶åè¦åç·©è§£ç­ç¥å°æ·±åº¦å­¸ç¿ç®¡ç·çå½±é¿ï¼éå¯ä»¥æ¯æ´å¥å¨ä¸è² è²¬ä»»çè¨åº AI çéç¼ã</paragraph>

##### **Predicting recovery following stroke: deep learning, multimodal data and feature selection using explainable AI**
2310.19174v1 by Adam White, Margarita Saranti, Artur d'Avila Garcez, Thomas M. H. Hope, Cathy J. Price, Howard Bowman

Machine learning offers great potential for automated prediction of
post-stroke symptoms and their response to rehabilitation. Major challenges for
this endeavour include the very high dimensionality of neuroimaging data, the
relatively small size of the datasets available for learning, and how to
effectively combine neuroimaging and tabular data (e.g. demographic information
and clinical characteristics). This paper evaluates several solutions based on
two strategies. The first is to use 2D images that summarise MRI scans. The
second is to select key features that improve classification accuracy.
Additionally, we introduce the novel approach of training a convolutional
neural network (CNN) on images that combine regions-of-interest extracted from
MRIs, with symbolic representations of tabular data. We evaluate a series of
CNN architectures (both 2D and a 3D) that are trained on different
representations of MRI and tabular data, to predict whether a composite measure
of post-stroke spoken picture description ability is in the aphasic or
non-aphasic range. MRI and tabular data were acquired from 758 English speaking
stroke survivors who participated in the PLORAS study. The classification
accuracy for a baseline logistic regression was 0.678 for lesion size alone,
rising to 0.757 and 0.813 when initial symptom severity and recovery time were
successively added. The highest classification accuracy 0.854 was observed when
8 regions-of-interest was extracted from each MRI scan and combined with lesion
size, initial severity and recovery time in a 2D Residual Neural Network.Our
findings demonstrate how imaging and tabular data can be combined for high
post-stroke classification accuracy, even when the dataset is small in machine
learning terms. We conclude by proposing how the current models could be
improved to achieve even higher levels of accuracy using images from hospital
scanners.

æè¦ï¼æ©å¨å­¸ç¿çºèªåé æ¸¬ä¸­é¢¨å¾ççåå¶å°å¾©å¥çåææä¾äºæ¥µå¤§çæ½åãéé å·¥ä½çéå¤§ææ°åæ¬ç¥ç¶å½±åè³æçç¶­åº¦éå¸¸é«ãå¯ç¨æ¼å­¸ç¿çè³æéè¦æ¨¡ç¸å°è¼å°ï¼ä»¥åå¦ä½ææçµåç¥ç¶å½±ååè¡¨æ ¼è³æï¼ä¾å¦äººå£çµ±è¨è³è¨åè¨åºç¹å¾µï¼ãæ¬ææ ¹æå©ç¨®ç­ç¥è©ä¼°äºå¤ç¨®è§£æ±ºæ¹æ¡ãç¬¬ä¸ç¨®æ¯ä½¿ç¨ç¸½çµ MRI ææç 2D å½±åãç¬¬äºç¨®æ¯é¸ææå©æ¼æé«åé¡ç²¾ç¢ºåº¦çééµç¹å¾µãæ­¤å¤ï¼æåå¼å¥äºå¨çµåå¾ MRI ä¸­æåçæèè¶£ååèè¡¨æ ¼è³æçç¬¦èè¡¨ç¤ºçå½±åä¸è¨ç·´å·ç©ç¥ç¶ç¶²è·¯ (CNN) çæ°ç©æ¹æ³ãæåè©ä¼°äºä¸ç³»å CNN æ¶æ§ï¼2D å 3Dï¼ï¼éäºæ¶æ§å¨ MRI åè¡¨æ ¼è³æçä¸åè¡¨ç¤ºä¸é²è¡è¨ç·´ï¼ä»¥é æ¸¬ä¸­é¢¨å¾å£è¿°åçæè¿°è½åçç¶åæ¸¬éæ¯å¦å¨å¤±èªçæéå¤±èªçç¯åå§ãMRI åè¡¨æ ¼è³æä¾èª 758 ååè PLORAS ç ç©¶çè±èªä¸­é¢¨åå­èãåéå°çç¶å¤§å°çåºç·éè¼¯è¿´æ­¸åé¡æºç¢ºåº¦çº 0.678ï¼ç¶ä¾åºå å¥åå§ççå´éç¨åº¦åæ¢å¾©æéæï¼ä¸åè³ 0.757 å 0.813ãå¨å¾æ¯å MRI ææä¸­æå 8 åæèè¶£ååä¸¦å¨ 2D æ®å·®ç¥ç¶ç¶²è·¯ä¸­èçç¶å¤§å°ãåå§å´éç¨åº¦åæ¢å¾©æéçµåæï¼è§å¯å°æé«çåé¡æºç¢ºåº¦ 0.854ãæåçç ç©¶çµæå±ç¤ºäºå¦ä½å°å½±ååè¡¨æ ¼è³æçµåèµ·ä¾ä»¥ç²å¾é«æ¼ä¸­é¢¨å¾åé¡æºç¢ºåº¦ï¼å³ä½¿å¨æ©å¨å­¸ç¿è¡èªä¸­è³æéå¾å°çææ³ä¸ä¹æ¯å¦æ­¤ãæå¾ï¼æåæåºå¦ä½æ¹é²ç®åçæ¨¡åï¼ä»¥ä½¿ç¨ä¾èªé«é¢ææåçå½±åä¾å¯¦ç¾æ´é«çæºç¢ºåº¦ã

##### **Trainable Noise Model as an XAI evaluation method: application on Sobol for remote sensing image segmentation**
2310.01828v2 by Hossein Shreim, Abdul Karim Gizzini, Ali J. Ghandour

eXplainable Artificial Intelligence (XAI) has emerged as an essential
requirement when dealing with mission-critical applications, ensuring
transparency and interpretability of the employed black box AI models. The
significance of XAI spans various domains, from healthcare to finance, where
understanding the decision-making process of deep learning algorithms is
essential. Most AI-based computer vision models are often black boxes; hence,
providing explainability of deep neural networks in image processing is crucial
for their wide adoption and deployment in medical image analysis, autonomous
driving, and remote sensing applications. Recently, several XAI methods for
image classification tasks have been introduced. On the contrary, image
segmentation has received comparatively less attention in the context of
explainability, although it is a fundamental task in computer vision
applications, especially in remote sensing. Only some research proposes
gradient-based XAI algorithms for image segmentation. This paper adapts the
recent gradient-free Sobol XAI method for semantic segmentation. To measure the
performance of the Sobol method for segmentation, we propose a quantitative XAI
evaluation method based on a learnable noise model. The main objective of this
model is to induce noise on the explanation maps, where higher induced noise
signifies low accuracy and vice versa. A benchmark analysis is conducted to
evaluate and compare performance of three XAI methods, including Seg-Grad-CAM,
Seg-Grad-CAM++ and Seg-Sobol using the proposed noise-based evaluation
technique. This constitutes the first attempt to run and evaluate XAI methods
using high-resolution satellite images.

æè¦ï¼å¯è§£éäººå·¥æºæ§ (XAI) å·²æçºèçä»»åééµæç¨ç¨å¼æçä¸é åºæ¬éæ±ï¼ç¢ºä¿æ¡ç¨é»ç AI æ¨¡åçéæåº¦åå¯è§£éæ§ãXAI çéè¦æ§æ¶µèå¾é«çä¿å¥å°éèçåç¨®é åï¼å¨éäºé åä¸­ï¼äºè§£æ·±åº¦å­¸ç¿æ¼ç®æ³çæ±ºç­å¶å®éç¨è³ééè¦ãå¤§å¤æ¸åºæ¼ AI çé»è¦è¦è¦ºæ¨¡åéå¸¸æ¯é»çå­ï¼å æ­¤ï¼å¨å½±åèçä¸­æä¾æ·±åº¦ç¥ç¶ç¶²è·¯çå¯è§£éæ§å°æ¼å¶å¨é«å­¸å½±ååæãèªåé§é§åéæ¸¬æç¨ä¸­çå»£æ³æ¡ç¨åé¨ç½²è³ééè¦ãæè¿ï¼å·²éå°å½±ååé¡ä»»åå¼å¥äºå¤ç¨® XAI æ¹æ³ãç¸åå°ï¼å½±ååå²å¨å¯è§£éæ§çèæ¯ä¸åå°çéæ³¨ç¸å°è¼å°ï¼åç®¡å®æ¯é»è¦è¦è¦ºæç¨ä¸­çä¸é åºæ¬ä»»åï¼ç¹å¥æ¯å¨éæ¸¬ä¸­ãåªæé¨åç ç©¶æåºç¨æ¼å½±ååå²çåºæ¼æ¢¯åº¦ç XAI æ¼ç®æ³ãæ¬ææ¹ç·¨äºæè¿çç¡æ¢¯åº¦ Sobol XAI æ¹æ³ä»¥é²è¡èªæåå²ãçºäºè¡¡é Sobol æ¹æ³å¨åå²ä¸­çæè½ï¼æåæåºäºä¸ç¨®åºæ¼å¯å­¸ç¿éè¨æ¨¡åçå®é XAI è©ä¼°æ¹æ³ãæ­¤æ¨¡åçä¸»è¦ç®çæ¯å¨è§£éåä¸èªç¼éè¨ï¼å¶ä¸­è¼é«çèªç¼éè¨è¡¨ç¤ºè¼ä½çæºç¢ºåº¦ï¼åä¹äº¦ç¶ãé²è¡åºæºåæä»¥è©ä¼°åæ¯è¼ä¸ç¨® XAI æ¹æ³çæè½ï¼åæ¬ Seg-Grad-CAMãSeg-Grad-CAM++ å Seg-Sobolï¼ä¸¦ä½¿ç¨ææåºçåºæ¼éè¨çè©ä¼°æè¡ãéæ§æäºä½¿ç¨é«è§£æåº¦è¡æå½±åå·è¡åè©ä¼° XAI æ¹æ³çé¦æ¬¡åè©¦ã

##### **Creating Trustworthy LLMs: Dealing with Hallucinations in Healthcare AI**
2311.01463v1 by Muhammad Aurangzeb Ahmad, Ilker Yaramis, Taposh Dutta Roy

Large language models have proliferated across multiple domains in as short
period of time. There is however hesitation in the medical and healthcare
domain towards their adoption because of issues like factuality, coherence, and
hallucinations. Give the high stakes nature of healthcare, many researchers
have even cautioned against its usage until these issues are resolved. The key
to the implementation and deployment of LLMs in healthcare is to make these
models trustworthy, transparent (as much possible) and explainable. In this
paper we describe the key elements in creating reliable, trustworthy, and
unbiased models as a necessary condition for their adoption in healthcare.
Specifically we focus on the quantification, validation, and mitigation of
hallucinations in the context in healthcare. Lastly, we discuss how the future
of LLMs in healthcare may look like.

æè¦ï¼å¤§åèªè¨æ¨¡åå¨ç­æéå§å·²å¨å¤åé åä¸­å¤§éæ¿å¢ãç¶èï¼ç±æ¼äºå¯¦æ§ãé£è²«æ§åå¹»è¦ºç­åé¡ï¼é«çåä¿å¥é åå°å¶æ¡ç¨ç¶è±«ä¸æ±ºãéæ¼é«çä¿å¥çé«é¢¨éªæ§è³ªï¼è¨±å¤ç ç©¶äººå¡çè³è­¦åä¸è¦ä½¿ç¨å®ï¼ç´å°éäºåé¡å¾å°è§£æ±ºãå¨é«çä¿å¥ä¸­å¯¦æ½åé¨ç½² LLM çééµæ¯ä½¿éäºæ¨¡åå¼å¾ä¿¡è³´ãéæï¼ç¡å¯è½å¤ï¼ä¸å¯è§£éãå¨æ¬æä¸­ï¼æåæè¿°äºå»ºç«å¯é ãå¼å¾ä¿¡è³´åç¡åè¦æ¨¡åçééµè¦ç´ ï¼ä½çºå®åå¨é«çä¿å¥ä¸­å¾å°æ¡ç¨çå¿è¦æ¢ä»¶ãå·é«ä¾èªªï¼æåå°æ³¨æ¼å¨é«çä¿å¥èæ¯ä¸å°å¹»è¦ºé²è¡éåãé©è­åç·©è§£ãæå¾ï¼æåè¨è«äº LLM å¨é«çä¿å¥ä¸­çæªä¾å¯è½æ¯ä»éº¼æ¨£å­ã

##### **When to Trust AI: Advances and Challenges for Certification of Neural Networks**
2309.11196v1 by Marta Kwiatkowska, Xiyue Zhang

Artificial intelligence (AI) has been advancing at a fast pace and it is now
poised for deployment in a wide range of applications, such as autonomous
systems, medical diagnosis and natural language processing. Early adoption of
AI technology for real-world applications has not been without problems,
particularly for neural networks, which may be unstable and susceptible to
adversarial examples. In the longer term, appropriate safety assurance
techniques need to be developed to reduce potential harm due to avoidable
system failures and ensure trustworthiness. Focusing on certification and
explainability, this paper provides an overview of techniques that have been
developed to ensure safety of AI decisions and discusses future challenges.

æè¦ï¼äººå·¥æºæ§ï¼AIï¼å·²å¿«éé²æ­¥ï¼ç¾å·²æºåé¨ç½²æ¼å»£æ³çæç¨ç¨å¼ä¸­ï¼ä¾å¦èªä¸»ç³»çµ±ãé«çè¨ºæ·åèªç¶èªè¨èçãåæ©æ¡ç¨ AI æè¡æ¼å¯¦éæç¨ç¨å¼ä¸¦éæ²æåé¡ï¼ç¹å¥æ¯å°æ¼ç¥ç¶ç¶²è·¯ï¼å®å¯è½ä¸ç©©å®ä¸å®¹æåå°å°ææ§ç¯ä¾çå½±é¿ãå¾é·é ä¾çï¼éè¦éç¼é©ç¶çå®å¨ä¿è­æè¡ï¼ä»¥æ¸å°å å¯é¿åçç³»çµ±æéèé æçæ½å¨å·å®³ï¼ä¸¦ç¢ºä¿å¯ä¿¡è³´æ§ãæ¬æèéæ¼èªè­åå¯è§£éæ§ï¼æ¦è¿°äºå·²éç¼ç¨æ¼ç¢ºä¿ AI æ±ºç­å®å¨çæè¡ï¼ä¸¦è¨è«æªä¾çææ°ã

##### **Functional requirements to mitigate the Risk of Harm to Patients from Artificial Intelligence in Healthcare**
2309.10424v1 by Juan M. GarcÃ­a-GÃ³mez, Vicent Blanes-Selva, JosÃ© Carlos de BartolomÃ© Cenzano, Jaime Cebolla-Cornejo, AscensiÃ³n DoÃ±ate-MartÃ­nez

The Directorate General for Parliamentary Research Services of the European
Parliament has prepared a report to the Members of the European Parliament
where they enumerate seven main risks of Artificial Intelligence (AI) in
medicine and healthcare: patient harm due to AI errors, misuse of medical AI
tools, bias in AI and the perpetuation of existing inequities, lack of
transparency, privacy and security issues, gaps in accountability, and
obstacles in implementation.
  In this study, we propose fourteen functional requirements that AI systems
may implement to reduce the risks associated with their medical purpose: AI
passport, User management, Regulation check, Academic use only disclaimer, data
quality assessment, Clinicians double check, Continuous performance evaluation,
Audit trail, Continuous usability test, Review of retrospective/simulated
cases, Bias check, eXplainable AI, Encryption and use of field-tested
libraries, and Semantic interoperability.
  Our intention here is to provide specific high-level specifications of
technical solutions to ensure continuous good performance and use of AI systems
to benefit patients in compliance with the future EU regulatory framework.

æè¦ï¼æ­æ´²è­°æè­°æç ç©¶æåç¸½å±å·²çºæ­æ´²è­°æè­°å¡æºåäºä¸ä»½å ±åï¼å¶ä¸­åèäºäººå·¥æºè½ (AI) å¨é«çä¿å¥é åçä¸é ä¸»è¦é¢¨éªï¼AI é¯èª¤å°è´æ£èåå°å·å®³ãé«ç AI å·¥å·è¢«æ¿«ç¨ãAI å­å¨åè¦ä¸¦å°è´ç¾æ inequities æçºå­å¨ãç¼ºä¹éæåº¦ãé±ç§åå®å¨åé¡ãåè²¬å·®è·ä»¥åå¯¦æ½éç¤ã
  å¨éé ç ç©¶ä¸­ï¼æåæåºäºååé åè½æ§è¦æ±ï¼AI ç³»çµ±å¯ä»¥å¯¦æ½éäºè¦æ±ä¾éä½èå¶é«çç®çç¸éçé¢¨éªï¼AI è­·ç§ãä½¿ç¨èç®¡çãæ³è¦æª¢æ¥ãåéå­¸è¡ç¨éåè²¬è²æãè³æåè³ªè©ä¼°ãè¨åºé«çééæª¢æ¥ãæçºæè½è©ä¼°ãç¨½æ ¸è¿½è¹¤ãæçºå¯ç¨æ§æ¸¬è©¦ãåé¡§åæº¯/æ¨¡æ¬æ¡ä¾ãåè¦æª¢æ¥ãå¯è§£é AIãå å¯åä½¿ç¨ç¶éå¯¦å°æ¸¬è©¦çç¨å¼åº«ï¼ä»¥åèªæäºéæ§ã
  æåå¨æ­¤çç®çæ¯æä¾æè¡è§£æ±ºæ¹æ¡çç¹å®é«éè¦æ ¼ï¼ä»¥ç¢ºä¿æçºè¯å¥½çæè½ï¼ä¸¦ä½¿ç¨ AI ç³»çµ±ï¼ä»¥ç¬¦åæªä¾çæ­çæ³è¦æ¶æ§ï¼å¾èä½¿æ£èåçã

##### **QXAI: Explainable AI Framework for Quantitative Analysis in Patient Monitoring Systems**
2309.10293v3 by Thanveer Shaik, Xiaohui Tao, Haoran Xie, Lin Li, Juan D. Velasquez, Niall Higgins

Artificial Intelligence techniques can be used to classify a patient's
physical activities and predict vital signs for remote patient monitoring.
Regression analysis based on non-linear models like deep learning models has
limited explainability due to its black-box nature. This can require
decision-makers to make blind leaps of faith based on non-linear model results,
especially in healthcare applications. In non-invasive monitoring, patient data
from tracking sensors and their predisposing clinical attributes act as input
features for predicting future vital signs. Explaining the contributions of
various features to the overall output of the monitoring application is
critical for a clinician's decision-making. In this study, an Explainable AI
for Quantitative analysis (QXAI) framework is proposed with post-hoc model
explainability and intrinsic explainability for regression and classification
tasks in a supervised learning approach. This was achieved by utilizing the
Shapley values concept and incorporating attention mechanisms in deep learning
models. We adopted the artificial neural networks (ANN) and attention-based
Bidirectional LSTM (BiLSTM) models for the prediction of heart rate and
classification of physical activities based on sensor data. The deep learning
models achieved state-of-the-art results in both prediction and classification
tasks. Global explanation and local explanation were conducted on input data to
understand the feature contribution of various patient data. The proposed QXAI
framework was evaluated using PPG-DaLiA data to predict heart rate and mobile
health (MHEALTH) data to classify physical activities based on sensor data.
Monte Carlo approximation was applied to the framework to overcome the time
complexity and high computation power requirements required for Shapley value
calculations.

æè¦ï¼äººå·¥æºæ§æè¡å¯ç¨æ¼åé¡çæ£çèº«é«æ´»åä¸¦é æ¸¬é è·çæ£ç£æ§çéè¦çå½å¾µè±¡ãåºæ¼æ·±åº¦å­¸ç¿æ¨¡åç­éç·æ§æ¨¡åçåæ­¸åæç±æ¼å¶é»çå­çæ§è³ªèå·ææéçå¯è§£éæ§ãéå¯è½éè¦æ±ºç­èæ ¹æéç·æ§æ¨¡åçµæååºç²ç®çä¿¡ä»°é£èºï¼ç¹å¥æ¯å¨é«çä¿å¥æç¨ä¸­ãå¨éä¾µå¥æ§ç£æ§ä¸­ï¼ä¾èªè¿½è¹¤ææ¸¬å¨åå¶ææè¨åºå±¬æ§ççæ£è³æåç¶é æ¸¬æªä¾çå½å¾µè±¡çè¼¸å¥ç¹å¾µãè§£éåç¨®ç¹å¾µå°ç£æ§æç¨ç¨å¼æ´é«è¼¸åºçè²¢ç»å°æ¼è¨åºé«ççæ±ºç­è³ééè¦ãå¨æ¬ç ç©¶ä¸­ï¼æåºäºä¸åç¨æ¼éååæçå¯è§£éäººå·¥æºæ§ (QXAI) æ¶æ§ï¼è©²æ¶æ§å·æç£ç£å¼å­¸ç¿æ¹æ³ä¸­åæ­¸ååé¡ä»»åçäºå¾æ¨¡åå¯è§£éæ§åå§å¨å¯è§£éæ§ãéééå©ç¨ Shapley å¼æ¦å¿µä¸¦å°æ³¨æåæ©å¶ç´å¥æ·±åº¦å­¸ç¿æ¨¡åä¾å¯¦ç¾ãæåæ¡ç¨äººå·¥ç¥ç¶ç¶²è·¯ (ANN) ååºæ¼æ³¨æåçéå LSTM (BiLSTM) æ¨¡åï¼æ ¹æææ¸¬å¨è³æé æ¸¬å¿çååé¡èº«é«æ´»åãæ·±åº¦å­¸ç¿æ¨¡åå¨é æ¸¬ååé¡ä»»åä¸­é½åå¾äºæåé²çææãå°è¼¸å¥è³æé²è¡å¨å±è§£éåå±é¨è§£éï¼ä»¥äºè§£åç¨®çæ£è³æçç¹å¾µè²¢ç»ãææåºç QXAI æ¶æ§ä½¿ç¨ PPG-DaLiA è³æè©ä¼°ï¼ä»¥é æ¸¬å¿çï¼ä¸¦ä½¿ç¨è¡åå¥åº· (MHEALTH) è³ææ ¹æææ¸¬å¨è³æå°èº«é«æ´»åé²è¡åé¡ãèå°å¡ç¾è¿ä¼¼æ³æç¨æ¼è©²æ¶æ§ï¼ä»¥åæ Shapley å¼è¨ç®æéçæéè¤éåº¦åé«éç®è½åéæ±ã

##### **Evaluation of Human-Understandability of Global Model Explanations using Decision Tree**
2309.09917v1 by Adarsa Sivaprasad, Ehud Reiter, Nava Tintarev, Nir Oren

In explainable artificial intelligence (XAI) research, the predominant focus
has been on interpreting models for experts and practitioners. Model agnostic
and local explanation approaches are deemed interpretable and sufficient in
many applications. However, in domains like healthcare, where end users are
patients without AI or domain expertise, there is an urgent need for model
explanations that are more comprehensible and instil trust in the model's
operations. We hypothesise that generating model explanations that are
narrative, patient-specific and global(holistic of the model) would enable
better understandability and enable decision-making. We test this using a
decision tree model to generate both local and global explanations for patients
identified as having a high risk of coronary heart disease. These explanations
are presented to non-expert users. We find a strong individual preference for a
specific type of explanation. The majority of participants prefer global
explanations, while a smaller group prefers local explanations. A task based
evaluation of mental models of these participants provide valuable feedback to
enhance narrative global explanations. This, in turn, guides the design of
health informatics systems that are both trustworthy and actionable.

æè¦ï¼å¨å¯è§£éäººå·¥æºè½ (XAI) ç ç©¶ä¸­ï¼ä¸»è¦éç¹å¨äºä¸ºä¸å®¶åä»ä¸èè§£éæ¨¡åãæ¨¡åä¸å¯ç¥åå±é¨è§£éæ¹æ³å¨è®¸å¤åºç¨ä¸­è¢«è®¤ä¸ºæ¯å¯è§£éä¸è¶³å¤çãç¶èï¼å¨å»çä¿å¥ç­é¢åï¼æç»ç¨æ·æ¯ç¼ºä¹äººå·¥æºè½æé¢åä¸ä¸ç¥è¯çæ£èï¼å æ­¤è¿«åéè¦æ´æäºçè§£ä¸è½æ¿åå¯¹æ¨¡åæä½çä¿¡ä»»çæ¨¡åè§£éãæä»¬åè®¾çæåè¿°æ§ãæ£èç¹å®ä¸å¨å±ï¼æ¨¡åæ´ä½ï¼çæ¨¡åè§£éå°è½å¤æé«å¯çè§£æ§å¹¶æ¯æå³ç­å¶å®ãæä»¬ä½¿ç¨å³ç­æ æ¨¡åå¯¹æ­¤è¿è¡æµè¯ï¼ä¸ºè¢«è¯å«ä¸ºæ£æå å¿çé«é£é©çæ£èçæå±é¨åå¨å±è§£éãè¿äºè§£éä¼åç°ç»éä¸å®¶ç¨æ·ãæä»¬åç°ç¨æ·å¼ºçåå¥½ç¹å®ç±»åçè§£éãå¤§å¤æ°åä¸èåå¥½å¨å±è§£éï¼èè¾å°çä¸ç»åä¸èåå¥½å±é¨è§£éãåºäºä»»å¡çå¿çæ¨¡åè¯ä¼°ä¸ºè¿äºåä¸èæä¾äºæä»·å¼çåé¦ï¼ä»¥å¢å¼ºåè¿°æ§å¨å±è§£éãè¿åè¿æ¥åæå¯¼äºæ¢å¼å¾ä¿¡èµåå¯æä½çå¥åº·ä¿¡æ¯å­¦ç³»ç»çè®¾è®¡ã

##### **Leveraging A Medical Knowledge Graph into Large Language Models for Diagnosis Prediction**
2308.14321v1 by Yanjun Gao, Ruizhe Li, John Caskey, Dmitriy Dligach, Timothy Miller, Matthew M. Churpek, Majid Afshar

Electronic Health Records (EHRs) and routine documentation practices play a
vital role in patients' daily care, providing a holistic record of health,
diagnoses, and treatment. However, complex and verbose EHR narratives overload
healthcare providers, risking diagnostic inaccuracies. While Large Language
Models (LLMs) have showcased their potential in diverse language tasks, their
application in the healthcare arena needs to ensure the minimization of
diagnostic errors and the prevention of patient harm. In this paper, we outline
an innovative approach for augmenting the proficiency of LLMs in the realm of
automated diagnosis generation, achieved through the incorporation of a medical
knowledge graph (KG) and a novel graph model: Dr.Knows, inspired by the
clinical diagnostic reasoning process. We derive the KG from the National
Library of Medicine's Unified Medical Language System (UMLS), a robust
repository of biomedical knowledge. Our method negates the need for
pre-training and instead leverages the KG as an auxiliary instrument aiding in
the interpretation and summarization of complex medical concepts. Using
real-world hospital datasets, our experimental results demonstrate that the
proposed approach of combining LLMs with KG has the potential to improve the
accuracy of automated diagnosis generation. More importantly, our approach
offers an explainable diagnostic pathway, edging us closer to the realization
of AI-augmented diagnostic decision support systems.

æè¦ï¼é»å­å¥åº·ç´é (EHR) åä¾è¡æä»¶è¨éå¯¦åå¨çæ£çæ¥å¸¸ç§è­·ä¸­æ®æ¼èè³ééè¦çè§è²ï¼æä¾å¥åº·ãè¨ºæ·åæ²»ççæ´é«ç´éãç¶èï¼è¤éä¸åé·ç EHR æè¿°æè®é«çä¿å¥æä¾èè¶è¼ï¼æè¨ºæ·ä¸æºç¢ºçé¢¨éªãå¤§åèªè¨æ¨¡å (LLM) å·²å±ç¾å¶å¨åç¨®èªè¨ä»»åä¸çæ½åï¼ä½å¶å¨é«çä¿å¥é åçæç¨éè¦ç¢ºä¿å°è¨ºæ·é¯èª¤éå°æä½ï¼ä¸¦é²æ­¢çæ£åå°å·å®³ãå¨æ¬æä¸­ï¼æåæ¦è¿°ä¸ç¨®åµæ°çæ¹æ³ï¼ééæ´åé«å­¸ç¥è­åè­ (KG) åä¸ç¨®æ°ç©çåè­æ¨¡åï¼Dr.Knowsï¼éæä¾èªè¨åºè¨ºæ·æ¨çéç¨ï¼ï¼ä¾å¢å¼· LLM å¨èªååè¨ºæ·ç¢çé åçè½åãæåå¾ç¾ååå®¶é«å­¸åæ¸é¤¨ççµ±ä¸é«å­¸èªè¨ç³»çµ± (UMLS) ä¸­è¡çåº KGï¼éæ¯ä¸åå¼·å¤§ççç©é«å­¸ç¥è­å²å­åº«ãæåçåæ³å¦å®äºé åè¨ç·´çéè¦ï¼èæ¯å° KG ä½çºè¼å©å·¥å·ï¼åå©è§£éåç¸½çµè¤éçé«å­¸æ¦å¿µãä½¿ç¨çå¯¦ä¸ççé«é¢è³æéï¼æåçå¯¦é©çµæè­æï¼å° LLM è KG çµåçå»ºè­°æ¹æ³ææ½åæé«èªååè¨ºæ·ç¢ççæºç¢ºæ§ãæ´éè¦çæ¯ï¼æåçåæ³æä¾äºä¸æ¢å¯è§£éçè¨ºæ·éå¾ï¼è®æåæ´æ¥è¿å¯¦ç¾ AI å¢å¼·çè¨ºæ·æ±ºç­æ¯æ´ç³»çµ±ã

##### **Deciphering knee osteoarthritis diagnostic features with explainable artificial intelligence: A systematic review**
2308.09380v1 by Yun Xin Teoh, Alice Othmani, Siew Li Goh, Juliana Usman, Khin Wee Lai

Existing artificial intelligence (AI) models for diagnosing knee
osteoarthritis (OA) have faced criticism for their lack of transparency and
interpretability, despite achieving medical-expert-like performance. This
opacity makes them challenging to trust in clinical practice. Recently,
explainable artificial intelligence (XAI) has emerged as a specialized
technique that can provide confidence in the model's prediction by revealing
how the prediction is derived, thus promoting the use of AI systems in
healthcare. This paper presents the first survey of XAI techniques used for
knee OA diagnosis. The XAI techniques are discussed from two perspectives: data
interpretability and model interpretability. The aim of this paper is to
provide valuable insights into XAI's potential towards a more reliable knee OA
diagnosis approach and encourage its adoption in clinical practice.

æè¦ï¼ç¾æçç¨æ¼è¨ºæ·èéª¨éç¯ç (OA) çäººå·¥æºæ§ (AI) æ¨¡åå å¶ç¼ºä¹éæåº¦åå¯è§£éæ§èåå°æ¹è©ï¼åç®¡å®åéå°äºé¡ä¼¼é«å­¸å°å®¶çè¡¨ç¾ãéç¨®ä¸éææ§ä½¿å¾å®åå¨è¨åºå¯¦åä¸­é£ä»¥è¢«ä¿¡ä»»ãæè¿ï¼å¯è§£éäººå·¥æºæ§ (XAI) å·²æçºä¸ç¨®å°éæè¡ï¼å®è½ééæ­ç¤ºé æ¸¬çæ¨å°æ¹å¼ä¾æä¾å°æ¨¡åé æ¸¬çä¿¡å¿ï¼å¾èä¿é²å¨é«çä¿å¥ä¸­ä½¿ç¨ AI ç³»çµ±ãæ¬ææä¾äºéå°èéª¨éç¯çè¨ºæ·æä½¿ç¨ç XAI æè¡çç¬¬ä¸ä»½èª¿æ¥ãXAI æè¡å¾å©åè§åº¦é²è¡è¨è«ï¼è³æå¯è§£éæ§åæ¨¡åå¯è§£éæ§ãæ¬æçç®çæ¯æä¾å° XAI å¨æ´å¯é çèéª¨éç¯çè¨ºæ·æ¹æ³ä¸­çæ½åçå¯¶è²´è¦è§£ï¼ä¸¦é¼åµå¨è¨åºå¯¦åä¸­æ¡ç¨å®ã

##### **Explainable AI for clinical risk prediction: a survey of concepts, methods, and modalities**
2308.08407v1 by Munib Mesinovic, Peter Watkinson, Tingting Zhu

Recent advancements in AI applications to healthcare have shown incredible
promise in surpassing human performance in diagnosis and disease prognosis.
With the increasing complexity of AI models, however, concerns regarding their
opacity, potential biases, and the need for interpretability. To ensure trust
and reliability in AI systems, especially in clinical risk prediction models,
explainability becomes crucial. Explainability is usually referred to as an AI
system's ability to provide a robust interpretation of its decision-making
logic or the decisions themselves to human stakeholders. In clinical risk
prediction, other aspects of explainability like fairness, bias, trust, and
transparency also represent important concepts beyond just interpretability. In
this review, we address the relationship between these concepts as they are
often used together or interchangeably. This review also discusses recent
progress in developing explainable models for clinical risk prediction,
highlighting the importance of quantitative and clinical evaluation and
validation across multiple common modalities in clinical practice. It
emphasizes the need for external validation and the combination of diverse
interpretability methods to enhance trust and fairness. Adopting rigorous
testing, such as using synthetic datasets with known generative factors, can
further improve the reliability of explainability methods. Open access and
code-sharing resources are essential for transparency and reproducibility,
enabling the growth and trustworthiness of explainable research. While
challenges exist, an end-to-end approach to explainability in clinical risk
prediction, incorporating stakeholders from clinicians to developers, is
essential for success.

æè¦ï¼æè¿å¨é«çä¿å¥ä¸­çäººå·¥æºæ§æç¨é²å±é¡¯ç¤ºåºä»¤äººé£ä»¥ç½®ä¿¡çæ¿è«¾ï¼å¨è¨ºæ·åç¾çé å¾æ¹é¢è¶è¶äººé¡è¡¨ç¾ãç¶èï¼é¨èäººå·¥æºè½æ¨¡åçæ¥çè¤éï¼äººåå°å¶ä¸éææ§ãæ½å¨åå·®åå°å¯è§£éæ§çéæ±æå°ææãçºäºç¢ºä¿äººå·¥æºè½ç³»çµ±çä¿¡ä»»åå¯é æ§ï¼å°¤å¶æ¯å¨è¨åºé¢¨éªé æ¸¬æ¨¡åä¸­ï¼å¯è§£éæ§è®å¾è³ééè¦ãå¯è§£éæ§éå¸¸è¢«ç¨±çºäººå·¥æºè½ç³»çµ±æä¾å¶æ±ºç­éè¼¯ææ±ºç­æ¬èº«å°äººé¡å©çç¸éèçå¼·æåè§£éçè½åãå¨è¨åºé¢¨éªé æ¸¬ä¸­ï¼å¯è§£éæ§çå¶ä»æ¹é¢ï¼å¦å¬å¹³æ§ãåè¦ãä¿¡ä»»åéæåº¦ï¼ä¹ä»£è¡¨äºè¶è¶å¯è§£éæ§çéè¦æ¦å¿µãå¨æ¬æ¬¡å¯©æ¥ä¸­ï¼æåæ¢è¨äºéäºæ¦å¿µä¹éçéä¿ï¼å çºå®åç¶å¸¸ä¸èµ·æäºæä½¿ç¨ãæ¬å¯©æ¥éè¨è«äºçºè¨åºé¢¨éªé æ¸¬éç¼å¯è§£éæ¨¡åçææ°é²å±ï¼å¼·èª¿äºå¨è¨åºå¯¦è¸ä¸­å°å¤ç¨®å¸¸è¦æ¨¡å¼é²è¡å®éåè¨åºè©ä¼°åé©è­çéè¦æ§ãå®å¼·èª¿äºå¤é¨é©è­åå¤æ¨£åå¯è§£éæ§æ¹æ³ç¸çµåçå¿è¦æ§ï¼ä»¥å¢å¼·ä¿¡ä»»åå¬å¹³æ§ãæ¡ç¨å´æ ¼çæ¸¬è©¦ï¼ä¾å¦ä½¿ç¨å·æå·²ç¥çæå ç´ çåææ¸æéï¼å¯ä»¥é²ä¸æ­¥æé«å¯è§£éæ§æ¹æ³çå¯é æ§ãéæ¾ç²ååä»£ç¢¼å±äº«è³æºå°æ¼éæåº¦åå¯éè¤æ§è³ééè¦ï¼å¾èä¿é²å¯è§£éç ç©¶çå¢é·åå¯ä¿¡åº¦ãåç®¡å­å¨ææ°ï¼ä½å¾è¨åºé«çå°éç¼äººå¡ï¼æ¡ç¨ç«¯å°ç«¯çå¯è§£éæ§æ¹æ³å°æ¼è¨åºé¢¨éªé æ¸¬çæåè³ééè¦ã

##### **FUTURE-AI: International consensus guideline for trustworthy and deployable artificial intelligence in healthcare**
2309.12325v3 by Karim Lekadir, Aasa Feragen, Abdul Joseph Fofanah, Alejandro F Frangi, Alena Buyx, Anais Emelie, Andrea Lara, Antonio R Porras, An-Wen Chan, Arcadi Navarro, Ben Glocker, Benard O Botwe, Bishesh Khanal, Brigit Beger, Carol C Wu, Celia Cintas, Curtis P Langlotz, Daniel Rueckert, Deogratias Mzurikwao, Dimitrios I Fotiadis, Doszhan Zhussupov, Enzo Ferrante, Erik Meijering, Eva Weicken, Fabio A GonzÃ¡lez, Folkert W Asselbergs, Fred Prior, Gabriel P Krestin, Gary Collins, Geletaw S Tegenaw, Georgios Kaissis, Gianluca Misuraca, Gianna Tsakou, Girish Dwivedi, Haridimos Kondylakis, Harsha Jayakody, Henry C Woodruf, Horst Joachim Mayer, Hugo JWL Aerts, Ian Walsh, Ioanna Chouvarda, IrÃ¨ne Buvat, Isabell Tributsch, Islem Rekik, James Duncan, Jayashree Kalpathy-Cramer, Jihad Zahir, Jinah Park, John Mongan, Judy W Gichoya, Julia A Schnabel, Kaisar Kushibar, Katrine Riklund, Kensaku Mori, Kostas Marias, Lameck M Amugongo, Lauren A Fromont, Lena Maier-Hein, Leonor CerdÃ¡ Alberich, Leticia Rittner, Lighton Phiri, Linda Marrakchi-Kacem, LluÃ­s Donoso-Bach, Luis MartÃ­-BonmatÃ­, M Jorge Cardoso, Maciej Bobowicz, Mahsa Shabani, Manolis Tsiknakis, Maria A Zuluaga, Maria Bielikova, Marie-Christine Fritzsche, Marina Camacho, Marius George Linguraru, Markus Wenzel, Marleen De Bruijne, Martin G Tolsgaard, Marzyeh Ghassemi, Md Ashrafuzzaman, Melanie Goisauf, Mohammad Yaqub, MÃ³nica Cano AbadÃ­a, Mukhtar M E Mahmoud, Mustafa Elattar, Nicola Rieke, Nikolaos Papanikolaou, Noussair Lazrak, Oliver DÃ­az, Olivier Salvado, Oriol Pujol, Ousmane Sall, Pamela Guevara, Peter Gordebeke, Philippe Lambin, Pieta Brown, Purang Abolmaesumi, Qi Dou, Qinghua Lu, Richard Osuala, Rose Nakasi, S Kevin Zhou, Sandy Napel, Sara Colantonio, Shadi Albarqouni, Smriti Joshi, Stacy Carter, Stefan Klein, Steffen E Petersen, Susanna AussÃ³, Suyash Awate, Tammy Riklin Raviv, Tessa Cook, Tinashe E M Mutsvangwa, Wendy A Rogers, Wiro J Niessen, XÃ¨nia Puig-Bosch, Yi Zeng, Yunusa G Mohammed, Yves Saint James Aquino, Zohaib Salahuddin, Martijn P A Starmans

Despite major advances in artificial intelligence (AI) for medicine and
healthcare, the deployment and adoption of AI technologies remain limited in
real-world clinical practice. In recent years, concerns have been raised about
the technical, clinical, ethical and legal risks associated with medical AI. To
increase real world adoption, it is essential that medical AI tools are trusted
and accepted by patients, clinicians, health organisations and authorities.
This work describes the FUTURE-AI guideline as the first international
consensus framework for guiding the development and deployment of trustworthy
AI tools in healthcare. The FUTURE-AI consortium was founded in 2021 and
currently comprises 118 inter-disciplinary experts from 51 countries
representing all continents, including AI scientists, clinicians, ethicists,
and social scientists. Over a two-year period, the consortium defined guiding
principles and best practices for trustworthy AI through an iterative process
comprising an in-depth literature review, a modified Delphi survey, and online
consensus meetings. The FUTURE-AI framework was established based on 6 guiding
principles for trustworthy AI in healthcare, i.e. Fairness, Universality,
Traceability, Usability, Robustness and Explainability. Through consensus, a
set of 28 best practices were defined, addressing technical, clinical, legal
and socio-ethical dimensions. The recommendations cover the entire lifecycle of
medical AI, from design, development and validation to regulation, deployment,
and monitoring. FUTURE-AI is a risk-informed, assumption-free guideline which
provides a structured approach for constructing medical AI tools that will be
trusted, deployed and adopted in real-world practice. Researchers are
encouraged to take the recommendations into account in proof-of-concept stages
to facilitate future translation towards clinical practice of medical AI.

æè¦ï¼åç®¡å¨é«å­¸åé«çä¿å¥æ¹é¢çäººå·¥æºæ§ (AI) æéå¤§çé²å±ï¼ä½ AI æè¡çé¨ç½²åæ¡ç¨å¨ç¾å¯¦ä¸ççè¨åºå¯¦åä¸­ä»ç¶æéãè¿å¹´ä¾ï¼äººåå°æ¼èé«ç AI ç¸éçæè¡ãè¨åºãå«çåæ³å¾é¢¨éªæåºäºçæ®ãçºäºå¢å ç¾å¯¦ä¸ççæ¡ç¨çï¼é«ç AI å·¥å·å¿é ç²å¾æ£èãè¨åºé«çãé«çæ©æ§åç¶å±çä¿¡ä»»åæ¥åãéé å·¥ä½å° FUTURE-AI æåæè¿°çºæå°é«çä¿å¥ä¸­å¯ä¿¡è³´ AI å·¥å·éç¼åé¨ç½²çç¬¬ä¸ååéå±è­æ¶æ§ãFUTURE-AI è¯çæç«æ¼ 2021 å¹´ï¼ç®åç±ä¾èª 51 ååå®¶ç 118 ä½è·¨é åå°å®¶çµæï¼ä»£è¡¨æææ´²ï¼åæ¬ AI ç§å­¸å®¶ãè¨åºé«çãå«çå­¸å®¶åç¤¾æç§å­¸å®¶ãå¨å©å¹´çæéè£¡ï¼è©²è¯çééä¸ååè¦éç®çéç¨å®ç¾©äºå¯ä¿¡è³´ AI çæå°åååæä½³å¯¦åï¼åæ¬æ·±å¥çæç»åé¡§ãä¿®æ¹å¾çå¾·ç¾è²èª¿æ¥åç·ä¸å±è­æè­°ãFUTURE-AI æ¶æ§æ¯åºæ¼é«çä¿å¥ä¸­å¯ä¿¡è³´ AI ç 6 é æå°ååå»ºç«çï¼å³å¬å¹³æ§ãæ®éæ§ãå¯è¿½æº¯æ§ãå¯ç¨æ§ãç©©å¥æ§åå¯è§£éæ§ãééå±è­ï¼å®ç¾©äºä¸çµ 28 é æä½³å¯¦åï¼æ¶µèæè¡ãè¨åºãæ³å¾åç¤¾æå«çå±¤é¢ãå»ºè­°æ¶µèäºé«ç AI çæ´åçå½é±æï¼å¾è¨­è¨ãéç¼åé©è­å°æ³è¦ãé¨ç½²åç£æ§ãFUTURE-AI æ¯ä¸ååºæ¼é¢¨éªãç¡åè¨­çæåï¼æä¾äºä¸åçµæ§åçæ¹æ³ï¼ç¨æ¼å»ºæ§å°å¨ç¾å¯¦ä¸çå¯¦åä¸­åå°ä¿¡ä»»ãé¨ç½²åæ¡ç¨çé«ç AI å·¥å·ãé¼åµç ç©¶äººå¡å¨æ¦å¿µé©è­éæ®µèæ®éäºå»ºè­°ï¼ä»¥ä¿é²æªä¾å°é«ç AI è½åçºè¨åºå¯¦åã

##### **Explainable AI applications in the Medical Domain: a systematic review**
2308.05411v1 by Nicoletta Prentzas, Antonis Kakas, Constantinos S. Pattichis

Artificial Intelligence in Medicine has made significant progress with
emerging applications in medical imaging, patient care, and other areas. While
these applications have proven successful in retrospective studies, very few of
them were applied in practice.The field of Medical AI faces various challenges,
in terms of building user trust, complying with regulations, using data
ethically.Explainable AI (XAI) aims to enable humans understand AI and trust
its results. This paper presents a literature review on the recent developments
of XAI solutions for medical decision support, based on a representative sample
of 198 articles published in recent years. The systematic synthesis of the
relevant articles resulted in several findings. (1) model-agnostic XAI
techniques were mostly employed in these solutions, (2) deep learning models
are utilized more than other types of machine learning models, (3)
explainability was applied to promote trust, but very few works reported the
physicians participation in the loop, (4) visual and interactive user interface
is more useful in understanding the explanation and the recommendation of the
system. More research is needed in collaboration between medical and AI
experts, that could guide the development of suitable frameworks for the
design, implementation, and evaluation of XAI solutions in medicine.

æè¦ï¼äººå·¥æºæ§å¨é«çé åä¸­å·²åå¾é¡¯èé²å±ï¼å¨é«å­¸å½±åãçäººç§è­·åå¶ä»é åä¸­åºç¾äºæ°èæç¨ãéç¶éäºæç¨å·²å¨åé¡§æ§ç ç©¶ä¸­è¢«è­å¯¦æ¯æåçï¼ä½å¯¦éä¸åªææ¥µå°æ¸æç¨æ¼å¯¦åãé«ç AI é åé¢è¨èåç¨®ææ°ï¼åæ¬å»ºç«ä½¿ç¨èä¿¡ä»»ãéµå®æ³è¦ãä½¿ç¨è³æç¬¦åå«çãå¯è§£é AI (XAI) çç®æ¨æ¯è®äººé¡äºè§£ AI ä¸¦ç¸ä¿¡å¶çµæãæ¬æéå°æè¿å¹¾å¹´ç¼è¡¨ç 198 ç¯æç« çå·ä»£è¡¨æ§æ¨£æ¬ï¼æåºæéé«çæ±ºç­æ¯æ´ç XAI è§£æ±ºæ¹æ¡çææ°ç¼å±çæç»åé¡§ãç¸éæç« çç³»çµ±æ§ç¶åæ´çç¢çäºå¤é ç¼ç¾ï¼(1) éäºè§£æ±ºæ¹æ¡å¤§å¤æ¡ç¨èæ¨¡åç¡éç XAI æè¡ï¼(2) æ·±åº¦å­¸ç¿æ¨¡åçä½¿ç¨çé«æ¼å¶ä»é¡åçæ©å¨å­¸ç¿æ¨¡åï¼(3) å¯è§£éæ§è¢«ç¨æ¼ä¿é²ä¿¡ä»»ï¼ä½å¾å°æç ç©¶å ±åé«å¸«åèè¿´åï¼(4) è¦è¦ºåäºåå¼ä½¿ç¨èä»é¢å°æ¼çè§£ç³»çµ±çè§£éåå»ºè­°æ´æç¨ãéè¦æ´å¤é«çå AI å°å®¶åä½é²è¡ç ç©¶ï¼éæå©æ¼çºé«çé åç XAI è§£æ±ºæ¹æ¡çè¨­è¨ãå¯¦ä½åè©ä¼°æä¾é©ç¶æ¶æ§ã

##### **Exploring the Role of Explainability in AI-Assisted Embryo Selection**
2308.02534v1 by Lucia Urcelay, Daniel Hinjos, Pablo A. Martin-Torres, Marta Gonzalez, Marta Mendez, Salva CÃ­vico, Sergio Ãlvarez-Napagao, Dario Garcia-Gasulla

In Vitro Fertilization is among the most widespread treatments for
infertility. One of its main challenges is the evaluation and selection of
embryo for implantation, a process with large inter- and intra-clinician
variability. Deep learning based methods are gaining attention, but their
opaque nature compromises their acceptance in the clinical context, where
transparency in the decision making is key. In this paper we analyze the
current work in the explainability of AI-assisted embryo analysis models,
identifying the limitations. We also discuss how these models could be
integrated in the clinical context as decision support systems, considering the
needs of clinicians and patients. Finally, we propose guidelines for the sake
of increasing interpretability and trustworthiness, pushing this technology
forward towards established clinical practice.

æè¦ï¼é«å¤åç²¾æ¯æ²»çä¸å­çæå»£æ³çæ¹æ³ä¹ä¸ãå¶ä¸»è¦ææ°ä¹ä¸æ¯è©ä¼°åé¸æèèé²è¡æ¤å¥ï¼æ­¤éç¨å·æå¾å¤§çè¨åºéåè¨åºå§è®ç°æ§ãåºæ¼æ·±åº¦å­¸ç¿çæ¹æ³æ­£åå°éæ³¨ï¼ä½å¶ä¸éæçæ§è³ªæå½±é¿å¶å¨è¨åºç°å¢ä¸­çæ¥ååº¦ï¼èéæåº¦å¨æ±ºç­å¶å®ä¸­è³ééè¦ãå¨æ¬æä¸­ï¼æååæäº AI è¼å©èèåææ¨¡åçå¯è§£éæ§æ¹é¢çç¾æå·¥ä½ï¼ä¸¦æ¾åºå¶å±éæ§ãæåéè¨è«äºå¦ä½å°éäºæ¨¡åä½çºæ±ºç­æ¯æç³»çµ±æ´åå°è¨åºç°å¢ä¸­ï¼åæèæ®è¨åºé«çåæ£èçéæ±ãæå¾ï¼æåæåºäºæé«å¯è§£éæ§åå¯ä¿¡åº¦çæºåï¼æ¨é²éé æè¡æèæ¢å®çè¨åºå¯¦åéé²ã

##### **A New Perspective on Evaluation Methods for Explainable Artificial Intelligence (XAI)**
2307.14246v1 by Timo Speith, Markus Langer

Within the field of Requirements Engineering (RE), the increasing
significance of Explainable Artificial Intelligence (XAI) in aligning
AI-supported systems with user needs, societal expectations, and regulatory
standards has garnered recognition. In general, explainability has emerged as
an important non-functional requirement that impacts system quality. However,
the supposed trade-off between explainability and performance challenges the
presumed positive influence of explainability. If meeting the requirement of
explainability entails a reduction in system performance, then careful
consideration must be given to which of these quality aspects takes precedence
and how to compromise between them. In this paper, we critically examine the
alleged trade-off. We argue that it is best approached in a nuanced way that
incorporates resource availability, domain characteristics, and considerations
of risk. By providing a foundation for future research and best practices, this
work aims to advance the field of RE for AI.

æè¦ï¼å¨éæ±å·¥ç¨ (RE) é åä¸­ï¼å¯è§£éäººå·¥æºæ§ (XAI) å¨å° AI æ¯æçç³»çµ±èä½¿ç¨èéæ±ãç¤¾æææåæ³è¦æ¨æºç¸ç¬¦æ¹é¢çéè¦æ§æ¥çé¡¯èï¼å·²ç²å¾èªå¯ãä¸è¬ä¾èªªï¼å¯è§£éæ§å·²æçºå½±é¿ç³»çµ±åè³ªçéè¦éåè½éæ±ãç¶èï¼å¯è§£éæ§èæè½ä¹éçåå®æ¬è¡¡ææ°äºå¯è§£éæ§çåå®æ­£é¢å½±é¿ãå¦ææ»¿è¶³å¯è§£éæ§çéæ±éè¦éä½ç³»çµ±æè½ï¼é£éº¼å¿é ä»ç´°èæ®éäºåè³ªé¢åä¸­åªä¸ååªåï¼ä»¥åå¦ä½å¨å®åä¹éé²è¡æè¡·ãå¨æ¬æä¸­ï¼æåæ¹å¤æ§å°æ¢è¨äºéç¨®åå®çæ¬è¡¡ãæåèªçºï¼æå¥½çæ¹æ³æ¯ä»¥ä¸ç¨®ç´°ç·»çæ¹å¼ä¾èçï¼éç¨®æ¹å¼åå«è³æºå¯ç¨æ§ãé åç¹æ§åé¢¨éªèéãééæä¾æªä¾ç ç©¶åæä½³å¯¦åçåºç¤ï¼éé å·¥ä½æ¨å¨æå AI ç RE é åã

##### **Revisiting the Performance-Explainability Trade-Off in Explainable Artificial Intelligence (XAI)**
2307.14239v1 by Barnaby Crook, Maximilian SchlÃ¼ter, Timo Speith

Within the field of Requirements Engineering (RE), the increasing
significance of Explainable Artificial Intelligence (XAI) in aligning
AI-supported systems with user needs, societal expectations, and regulatory
standards has garnered recognition. In general, explainability has emerged as
an important non-functional requirement that impacts system quality. However,
the supposed trade-off between explainability and performance challenges the
presumed positive influence of explainability. If meeting the requirement of
explainability entails a reduction in system performance, then careful
consideration must be given to which of these quality aspects takes precedence
and how to compromise between them. In this paper, we critically examine the
alleged trade-off. We argue that it is best approached in a nuanced way that
incorporates resource availability, domain characteristics, and considerations
of risk. By providing a foundation for future research and best practices, this
work aims to advance the field of RE for AI.

æè¦ï¼å¨éæ±å·¥ç¨ï¼REï¼é¢åï¼å¯è§£éäººå·¥æºè½ï¼XAIï¼å¨å°äººå·¥æºè½æ¯æçç³»ç»ä¸ç¨æ·éæ±ãç¤¾ä¼ææåçç®¡æ åç¸ä¸è´æ¹é¢çéè¦æ§æ¥çå¸æ¾ï¼å¹¶è·å¾äºè®¤å¯ãä¸è¬æ¥è¯´ï¼å¯è§£éæ§å·²æä¸ºå½±åç³»ç»è´¨éçéè¦éåè½æ§éæ±ãç¶èï¼å¯è§£éæ§åæ§è½ä¹é´çæè¡¡ææäºå¯è§£éæ§çæ­£é¢å½±åãå¦ææ»¡è¶³å¯è§£éæ§çè¦æ±éè¦éä½ç³»ç»æ§è½ï¼é£ä¹å¿é¡»ä»ç»èèè¿äºè´¨éæ¹é¢ä¸­çåªä¸ä¸ªä¼åï¼ä»¥åå¦ä½å¨å®ä»¬ä¹é´è¿è¡æè¡¡ãå¨æ¬æä¸­ï¼æä»¬æ¹å¤æ§å°èå¯äºæè°çæè¡¡ãæä»¬è®¤ä¸ºï¼æå¥½ä»¥ä¸ç§ç»è´å¥å¾®çæ¹å¼æ¥å¤çå®ï¼è¿ç§æ¹å¼ç»åäºèµæºå¯ç¨æ§ãé¢åç¹å¾åé£é©èèãéè¿ä¸ºæªæ¥çç ç©¶åæä½³å®è·µæä¾åºç¡ï¼è¿é¡¹å·¥ä½æ¨å¨æ¨è¿äººå·¥æºè½ç RE é¢åã

##### **Acceptable risks in Europe's proposed AI Act: Reasonableness and other principles for deciding how much risk management is enough**
2308.02047v1 by Henry Fraser, Jose-Miguel Bello y Villarino

This paper critically evaluates the European Commission's proposed AI Act's
approach to risk management and risk acceptability for high-risk AI systems
that pose risks to fundamental rights and safety. The Act aims to promote
"trustworthy" AI with a proportionate regulatory burden. Its provisions on risk
acceptability require residual risks from high-risk systems to be reduced or
eliminated "as far as possible", having regard to the "state of the art". This
criterion, especially if interpreted narrowly, is unworkable and promotes
neither proportionate regulatory burden, nor trustworthiness. By contrast the
Parliament's most recent draft amendments to the risk management provisions
introduce "reasonableness", cost-benefit analysis, and are more transparent
about the value-laden and contextual nature of risk acceptability judgements.
This paper argues that the Parliament's approach is more workable, and better
balances the goals of proportionality and trustworthiness. It explains what
reasonableness in risk acceptability judgments would entail, drawing on
principles from negligence law and European medical devices regulation. And it
contends that the approach to risk acceptability judgments need a firm
foundation of civic legitimacy: including detailed guidance or involvement from
regulators, and meaningful input from affected stakeholders.

æè¦ï¼æ¬æå´æ ¼è©ä¼°æ­æ´²å§å¡ææåºç AI æ³æ¡å°é¢¨éªç®¡çåé¢¨éªå¯æ¥åæ§çæ¹æ³ï¼ç¨æ¼å°åºæ¬æ¬å©åå®å¨æ§æé¢¨éªçé«é¢¨éª AI ç³»çµ±ãè©²æ³æ¡æ¨å¨ä»¥ç¸ç¨±çç£ç®¡è² æä¿é²ãå¼å¾ä¿¡è³´ãç AIãå¶éæ¼é¢¨éªå¯æ¥åæ§çæ¢æ¬¾è¦æ±å°é«é¢¨éªç³»çµ±çæ®é¤é¢¨éªæ¸ä½ææ¶é¤ãç¡å¯è½ãï¼ä¸¦èæ®ãæè¡çæããæ­¤æºåï¼ç¹å¥æ¯å¦æç¹ç¾©è§£éï¼ç¡æ³å·è¡ï¼æ¢ä¸ä¿é²ç¸ç¨±çç£ç®¡è² æï¼ä¹ä¸ä¿é²å¯ä¿¡è³´æ§ãç¸æ¯ä¹ä¸ï¼è­°æå°é¢¨éªç®¡çæ¢æ¬¾çææ°ä¿®æ­£èæ¡å¼å¥äºãåçæ§ããææ¬æçåæï¼ä¸¦ä¸æ´éæå°èªªæäºé¢¨éªå¯æ¥åæ§å¤æ·çå¹å¼è§åèæ¯æ§è³ªãæ¬æè«è­è­°æçæ¹æ³æ´å¯è¡ï¼ä¸è½æ´å¥½å°å¹³è¡¡ç¸ç¨±æ§åå¯ä¿¡è³´æ§çç®æ¨ãæ¬æèªªæé¢¨éªå¯æ¥åæ§å¤æ·ä¸­çåçæ§æå¸¶ä¾ä»éº¼ï¼ä¸¦æ ¹æéå¤±æ³åæ­æ´²é«çå¨ææ³è¦ä¸­çååé²è¡èªªæãæ¬æä¸»å¼µé¢¨éªå¯æ¥åæ§å¤æ·çæ¹æ³éè¦ç©©åºçå¬æ°åæ³æ§åºç¤ï¼åæ¬ç£ç®¡æ©æ§çè©³ç´°æå°æåèï¼ä»¥ååå½±é¿å©å®³éä¿äººçææç¾©æå¥ã

##### **eXplainable Artificial Intelligence (XAI) in aging clock models**
2307.13704v3 by Alena Kalyakulina, Igor Yusipov, Alexey Moskalev, Claudio Franceschi, Mikhail Ivanchenko

eXplainable Artificial Intelligence (XAI) is a rapidly progressing field of
machine learning, aiming to unravel the predictions of complex models. XAI is
especially required in sensitive applications, e.g. in health care, when
diagnosis, recommendations and treatment choices might rely on the decisions
made by artificial intelligence systems. AI approaches have become widely used
in aging research as well, in particular, in developing biological clock models
and identifying biomarkers of aging and age-related diseases. However, the
potential of XAI here awaits to be fully appreciated. We discuss the
application of XAI for developing the "aging clocks" and present a
comprehensive analysis of the literature categorized by the focus on particular
physiological systems.

æè¦ï¼å¯è§£éäººå·¥æºæ§ (XAI) æ¯æ©å¨å­¸ç¿ä¸­å¿«éé²å±çé åï¼æ¨å¨è§£éè¤éæ¨¡åçé æ¸¬ãXAI å¨æææç¨ä¸­ç¹å¥éè¦ï¼ä¾å¦å¨é«çä¿å¥ä¸­ï¼ç¶è¨ºæ·ãå»ºè­°åæ²»çé¸æå¯è½ä¾è³´æ¼äººå·¥æºæ§ç³»çµ±ååºçæ±ºç­æãäººå·¥æºæ§æ¹æ³ä¹å·²å»£æ³ç¨æ¼èåç ç©¶ï¼ç¹å¥æ¯å¨éç¼çç©æéæ¨¡ååè­å¥èååèå¹´é½¡ç¸éç¾çççç©æ¨èªç©æ¹é¢ãç¶èï¼éè£¡ XAI çæ½åæå¾ååèªè­ãæåè¨è«äº XAI å¨éç¼ãèåæéãæ¹é¢çæç¨ï¼ä¸¦å°æç¹å®ççç³»çµ±çéé»åé¡çæç»é²è¡äºå¨é¢çåæã

##### **Interpreting and Correcting Medical Image Classification with PIP-Net**
2307.10404v2 by Meike Nauta, Johannes H. Hegeman, Jeroen Geerdink, JÃ¶rg SchlÃ¶tterer, Maurice van Keulen, Christin Seifert

Part-prototype models are explainable-by-design image classifiers, and a
promising alternative to black box AI. This paper explores the applicability
and potential of interpretable machine learning, in particular PIP-Net, for
automated diagnosis support on real-world medical imaging data. PIP-Net learns
human-understandable prototypical image parts and we evaluate its accuracy and
interpretability for fracture detection and skin cancer diagnosis. We find that
PIP-Net's decision making process is in line with medical classification
standards, while only provided with image-level class labels. Because of
PIP-Net's unsupervised pretraining of prototypes, data quality problems such as
undesired text in an X-ray or labelling errors can be easily identified.
Additionally, we are the first to show that humans can manually correct the
reasoning of PIP-Net by directly disabling undesired prototypes. We conclude
that part-prototype models are promising for medical applications due to their
interpretability and potential for advanced model debugging.

æè¦ï¼é¨åååæ¨¡åæ¯å¯è§£éè¨­è¨çå½±ååé¡å¨ï¼ä¹æ¯é»ç®± AI çä¸åæåéçæ¿ä»£æ¹æ¡ãéç¯è«ææ¢è¨äºè§£éæ§æ©å¨å­¸ç¿ï¼ç¹å¥æ¯ PIP-Netï¼å¨çå¯¦ä¸çé«å­¸å½±åè³æä¸èªååè¨ºæ·æ¯æ´çé©ç¨æ§åæ½åãPIP-Net å­¸ç¿äººé¡å¯çè§£çååå½±åé¨åï¼æåè©ä¼°å¶å¨éª¨ææª¢æ¸¬åç®èçè¨ºæ·æ¹é¢çæºç¢ºæ§åå¯è§£éæ§ãæåç¼ç¾ PIP-Net çæ±ºç­å¶å®éç¨ç¬¦åé«å­¸åé¡æ¨æºï¼åæåæä¾å½±åå±¤ç´é¡å¥æ¨ç±¤ãç±æ¼ PIP-Net å°ååçç¡ç£ç£é è¨ç·´ï¼å æ­¤å¯ä»¥è¼é¬è­å¥è³æåè³ªåé¡ï¼ä¾å¦ X åä¸­çä¸éè¦æå­ææ¨ç±¤é¯èª¤ãæ­¤å¤ï¼æåé¦æ¬¡å±ç¤ºäººé¡å¯ä»¥ééç´æ¥åç¨ä¸éè¦çååä¾æåä¿®æ­£ PIP-Net çæ¨çãæåå¾åºçµè«ï¼é¨åååæ¨¡åç±æ¼å¶å¯è§£éæ§åé²éæ¨¡åé¤é¯çæ½åï¼å æ­¤æææç¨æ¼é«çã

##### **Explaining and visualizing black-box models through counterfactual paths**
2307.07764v3 by Bastian Pfeifer, Mateusz Krzyzinski, Hubert Baniecki, Anna Saranti, Andreas Holzinger, Przemyslaw Biecek

Explainable AI (XAI) is an increasingly important area of machine learning
research, which aims to make black-box models transparent and interpretable. In
this paper, we propose a novel approach to XAI that uses the so-called
counterfactual paths generated by conditional permutations of features. The
algorithm measures feature importance by identifying sequential permutations of
features that most influence changes in model predictions. It is particularly
suitable for generating explanations based on counterfactual paths in knowledge
graphs incorporating domain knowledge. Counterfactual paths introduce an
additional graph dimension to current XAI methods in both explaining and
visualizing black-box models. Experiments with synthetic and medical data
demonstrate the practical applicability of our approach.

æè¦ï¼å¯è§£é AI (XAI) æ¯æ©å¨å­¸ç¿ç ç©¶ä¸­æ¥çéè¦çé åï¼å¶ç®æ¨æ¯è®é»ç®±æ¨¡åéæä¸å¯è§£éãå¨æ¬æä¸­ï¼æåæåºäºä¸ç¨®æ°ç XAI æ¹æ³ï¼è©²æ¹æ³ä½¿ç¨ç±ç¹å¾µæ¢ä»¶ç½®æç¢ççæè¬åäºå¯¦è·¯å¾ãè©²æ¼ç®æ³ééè­å¥ç¹å¾µçé åºç½®æä¾è¡¡éç¹å¾µéè¦æ§ï¼éäºç½®ææè½å½±é¿æ¨¡åé æ¸¬çè®åãå®ç¹å¥é©åæ ¹æåå«é åç¥è­çç¥è­åè­ä¸­çåäºå¯¦è·¯å¾ä¾ç¢çè§£éãåäºå¯¦è·¯å¾å¨è§£éåè¦è¦ºåé»ç®±æ¨¡åæï¼çºç®åç XAI æ¹æ³å¼å¥äºé¡å¤çåå½¢ç¶­åº¦ãä½¿ç¨åæåé«çè³æé²è¡çå¯¦é©è­æäºæåæ¹æ³çå¯¦ç¨é©ç¨æ§ã

##### **Beyond Known Reality: Exploiting Counterfactual Explanations for Medical Research**
2307.02131v5 by Toygar Tanyel, Serkan Ayvaz, Bilgin Keserci

The field of explainability in artificial intelligence (AI) has witnessed a
growing number of studies and increasing scholarly interest. However, the lack
of human-friendly and individual interpretations in explaining the outcomes of
machine learning algorithms has significantly hindered the acceptance of these
methods by clinicians in their research and clinical practice. To address this
issue, our study uses counterfactual explanations to explore the applicability
of "what if?" scenarios in medical research. Our aim is to expand our
understanding of magnetic resonance imaging (MRI) features used for diagnosing
pediatric posterior fossa brain tumors beyond existing boundaries. In our case
study, the proposed concept provides a novel way to examine alternative
decision-making scenarios that offer personalized and context-specific
insights, enabling the validation of predictions and clarification of
variations under diverse circumstances. Additionally, we explore the potential
use of counterfactuals for data augmentation and evaluate their feasibility as
an alternative approach in our medical research case. The results demonstrate
the promising potential of using counterfactual explanations to enhance
acceptance of AI-driven methods in clinical research.

æè¦ï¼å¨äººå·¥æºè½ (AI) çå¯è§£éæ§é åä¸­ï¼å·²ç¶çå°è¶ä¾è¶å¤çç ç©¶åå­¸è¡èè¶£ãç¶èï¼å¨è§£éæ©å¨å­¸ç¿æ¼ç®æ³ççµææç¼ºä¹äººæ§åååäººåçè©®éï¼éé¡¯èé»ç¤äºè¨åºé«çå¨ç ç©¶åè¨åºå¯¦åä¸­æ¥åéäºæ¹æ³ãçºäºè§£æ±ºéååé¡ï¼æåçç ç©¶ä½¿ç¨åäºå¯¦è§£éä¾æ¢è¨ãå¦æï¼ãæå¢å¨é«å­¸ç ç©¶ä¸­çé©ç¨æ§ãæåçç®æ¨æ¯æ´å±æåå°ç¨æ¼è¨ºæ·å°åå¾é¡±çª©è¦è«ç¤çç£å±æ¯æå (MRI) ç¹å¾µççè§£ï¼è¶è¶ç¾æççç·ãå¨æåçæ¡ä¾ç ç©¶ä¸­ï¼ææåºçæ¦å¿µæä¾äºä¸ç¨®æ°ç©çæ¹æ³ä¾æª¢è¦æ¿ä»£æ±ºç­æå¢ï¼æä¾åäººååç¹å®æ¼æå¢çè¦è§£ï¼å¾èè½å¤ é©è­é æ¸¬ä¸¦éæ¸å¨ä¸åææ³ä¸çå·®ç°ãæ­¤å¤ï¼æåæ¢è¨äºåäºå¯¦ç¨æ¼è³ææ´åçæ½å¨ç¨éï¼ä¸¦è©ä¼°å¶ä½çºæåé«å­¸ç ç©¶æ¡ä¾ä¸­æ¿ä»£æ¹æ³çå¯è¡æ§ãçµæè­æäºä½¿ç¨åäºå¯¦è§£éä¾å¢å¼·è¨åºç ç©¶ä¸­ AI é©åæ¹æ³çæ¥ååº¦çæ½åã

##### **AI and Non AI Assessments for Dementia**
2307.01210v1 by Mahboobeh Parsapoor, Hamed Ghodrati, Vincenzo Dentamaro, Christopher R. Madan, Ioulietta Lazarou, Spiros Nikolopoulos, Ioannis Kompatsiaris

Current progress in the artificial intelligence domain has led to the
development of various types of AI-powered dementia assessments, which can be
employed to identify patients at the early stage of dementia. It can
revolutionize the dementia care settings. It is essential that the medical
community be aware of various AI assessments and choose them considering their
degrees of validity, efficiency, practicality, reliability, and accuracy
concerning the early identification of patients with dementia (PwD). On the
other hand, AI developers should be informed about various non-AI assessments
as well as recently developed AI assessments. Thus, this paper, which can be
readable by both clinicians and AI engineers, fills the gap in the literature
in explaining the existing solutions for the recognition of dementia to
clinicians, as well as the techniques used and the most widespread dementia
datasets to AI engineers. It follows a review of papers on AI and non-AI
assessments for dementia to provide valuable information about various dementia
assessments for both the AI and medical communities. The discussion and
conclusion highlight the most prominent research directions and the maturity of
existing solutions.

æè¦ï¼ç®åäººå·¥æºè½é åçé²å±å°è´äºåç¨®é¡åçäººå·¥æºæ§é©åçå¤±æºçè©ä¼°çç¼å±ï¼å¯ç¨æ¼è­å¥èæ¼å¤±æºçæ©æéæ®µçæ£èãå®å¯ä»¥å¾¹åºæ¹è®å¤±æºçè­·çè¨­ç½®ãéè¦çæ¯ï¼é«ççè¦äºè§£åç¨®äººå·¥æºè½è©ä¼°ï¼ä¸¦æ ¹æå¶æææ§ãæçãå¯¦ç¨æ§ãå¯é æ§åæºç¢ºæ§ç¨åº¦ï¼èæ®é¸æå®åä¾æ©æè­å¥å¤±æºçæ£è (PwD)ãå¦ä¸æ¹é¢ï¼äººå·¥æºè½éç¼äººå¡ä¹æè©²äºè§£åç¨®éäººå·¥æºè½è©ä¼°ä»¥åæè¿éç¼çäººå·¥æºè½è©ä¼°ãå æ­¤ï¼éç¯è¨åºé«çåäººå·¥æºè½å·¥ç¨å¸«é½å¯ä»¥é±è®çè«æå¡«è£äºæç»ä¸­éæ¼åè¨åºé«çè§£éç¾æå¤±æºçè­å¥è§£æ±ºæ¹æ¡ä»¥ååäººå·¥æºè½å·¥ç¨å¸«è§£éæç¨æè¡åæå»£æ³çå¤±æºçæ¸æéçç©ºç½ãå®éµå¾ªå°äººå·¥æºè½åéäººå·¥æºè½å¤±æºçè©ä¼°è«æçåé¡§ï¼çºäººå·¥æºè½åé«ççæä¾æéåç¨®å¤±æºçè©ä¼°çå¯¶è²´ä¿¡æ¯ãè¨è«åçµè«éé»ä»ç´¹äºæçªåºçç ç©¶æ¹ååç¾æè§£æ±ºæ¹æ¡çæçåº¦ã

##### **Active Globally Explainable Learning for Medical Images via Class Association Embedding and Cyclic Adversarial Generation**
2306.07306v1 by Ruitao Xie, Jingbang Chen, Limai Jiang, Rui Xiao, Yi Pan, Yunpeng Cai

Explainability poses a major challenge to artificial intelligence (AI)
techniques. Current studies on explainable AI (XAI) lack the efficiency of
extracting global knowledge about the learning task, thus suffer deficiencies
such as imprecise saliency, context-aware absence and vague meaning. In this
paper, we propose the class association embedding (CAE) approach to address
these issues. We employ an encoder-decoder architecture to embed sample
features and separate them into class-related and individual-related style
vectors simultaneously. Recombining the individual-style code of a given sample
with the class-style code of another leads to a synthetic sample with preserved
individual characters but changed class assignment, following a cyclic
adversarial learning strategy. Class association embedding distills the global
class-related features of all instances into a unified domain with well
separation between classes. The transition rules between different classes can
be then extracted and further employed to individual instances. We then propose
an active XAI framework which manipulates the class-style vector of a certain
sample along guided paths towards the counter-classes, resulting in a series of
counter-example synthetic samples with identical individual characters.
Comparing these counterfactual samples with the original ones provides a
global, intuitive illustration to the nature of the classification tasks. We
adopt the framework on medical image classification tasks, which show that more
precise saliency maps with powerful context-aware representation can be
achieved compared with existing methods. Moreover, the disease pathology can be
directly visualized via traversing the paths in the class-style space.

æè¦ï¼<paragraph>å¯è§£éæ§å°äººå·¥æºæ§ (AI) æè¡æ§æä¸é éå¤§ææ°ãç¶åå°å¯è§£é AI (XAI) çç ç©¶ç¼ºä¹æåå­¸ç¿ä»»åæ´é«ç¥è­çæçï¼å æ­¤å­å¨ä¸ç²¾ç¢ºçé¡¯èæ§ãèæå¢ç¡éçç¼ºå¤±åå«ç³æç¾©ç­ç¼ºé·ãå¨æ¬æä¸­ï¼æåæåºé¡å¥éè¯åµå¥ (CAE) æ¹æ³ä¾è§£æ±ºéäºåé¡ãæåæ¡ç¨ç·¨ç¢¼å¨-è§£ç¢¼å¨æ¶æ§ä¾åµå¥æ¨£æ¬ç¹å¾µï¼ä¸¦åæå°å®ååçºé¡å¥ç¸éååé«ç¸éçæ¨£å¼åéãå°çµ¦å®æ¨£æ¬çåé«æ¨£å¼ä»£ç¢¼èå¦ä¸åæ¨£æ¬çé¡å¥æ¨£å¼ä»£ç¢¼éæ°çµåï¼æç¢çä¸åå·æä¿çåé«ç¹å¾µä½æ¹è®é¡å¥åéçåææ¨£æ¬ï¼éµå¾ªå¾ªç°å°æå­¸ç¿ç­ç¥ãé¡å¥éè¯åµå¥å°ææå¯¦ä¾çå¨å±é¡å¥ç¸éç¹å¾µæçå°ä¸åçµ±ä¸çé åä¸­ï¼ä¸¦å¨é¡å¥ä¹éæè¯å¥½çååãç¶å¾å¯ä»¥æåä¸åé¡å¥ä¹éçè½æè¦åï¼ä¸¦é²ä¸æ­¥æç¨æ¼åå¥å¯¦ä¾ãç¶å¾ï¼æåæåºä¸åä¸»å XAI æ¡æ¶ï¼å®æ²¿èå¼å°è·¯å¾æä½ç¹å®æ¨£æ¬çé¡å¥æ¨£å¼åéï¼æèåé¡å¥ç§»åï¼å¾èç¢çä¸ç³»åå·æç¸ååé«ç¹å¾µçåä¾åææ¨£æ¬ãå°éäºåäºå¯¦æ¨£æ¬èåå§æ¨£æ¬é²è¡æ¯è¼ï¼å¯ä»¥å°åé¡ä»»åçæ§è³ªæä¾å¨å±ãç´è§çèªªæãæåæ¡ç¨è©²æ¡æ¶é²è¡é«å­¸å½±ååé¡ä»»åï¼çµæè¡¨æï¼èç¾ææ¹æ³ç¸æ¯ï¼å¯ä»¥ç²å¾æ´ç²¾ç¢ºçé¡¯èæ§åï¼ä¸¦å·æå¼·å¤§çèæå¢ç¡éçè¡¨ç¤ºãæ­¤å¤ï¼ç¾çççå­¸å¯ä»¥ç´æ¥ééå¨é¡å¥æ¨£å¼ç©ºéä¸­éæ­·è·¯å¾ä¾é²è¡å¯è¦åã</paragraph>

##### **HiTZ@Antidote: Argumentation-driven Explainable Artificial Intelligence for Digital Medicine**
2306.06029v1 by Rodrigo Agerri, IÃ±igo Alonso, Aitziber Atutxa, Ander Berrondo, Ainara Estarrona, Iker Garcia-Ferrero, Iakes Goenaga, Koldo Gojenola, Maite Oronoz, Igor Perez-Tejedor, German Rigau, Anar Yeginbergenova

Providing high quality explanations for AI predictions based on machine
learning is a challenging and complex task. To work well it requires, among
other factors: selecting a proper level of generality/specificity of the
explanation; considering assumptions about the familiarity of the explanation
beneficiary with the AI task under consideration; referring to specific
elements that have contributed to the decision; making use of additional
knowledge (e.g. expert evidence) which might not be part of the prediction
process; and providing evidence supporting negative hypothesis. Finally, the
system needs to formulate the explanation in a clearly interpretable, and
possibly convincing, way. Given these considerations, ANTIDOTE fosters an
integrated vision of explainable AI, where low-level characteristics of the
deep learning process are combined with higher level schemes proper of the
human argumentation capacity. ANTIDOTE will exploit cross-disciplinary
competences in deep learning and argumentation to support a broader and
innovative view of explainable AI, where the need for high-quality explanations
for clinical cases deliberation is critical. As a first result of the project,
we publish the Antidote CasiMedicos dataset to facilitate research on
explainable AI in general, and argumentation in the medical domain in
particular.

æè¦ï¼æä¾åºæ¼æ©å¨å­¸ç¿ç AI é æ¸¬çé«åè³ªèªªææ¯ä¸é å·æææ°æ§åè¤éæ§çä»»åãè¦é å©é²è¡ï¼å®éè¦å·åä¸åå ç´ ï¼é¸æé©ç¶çèªªææ®éæ§/ç¹æ®æ§å±¤ç´ï¼èéèªªæåçäººå°æèæ®ç AI ä»»åççæç¨åº¦åè¨­ï¼åç§ä¿ææ±ºç­çç¹å®åç´ ï¼å©ç¨å¯è½ä¸å±¬æ¼é æ¸¬ç¨åºçä¸é¨åçé¡å¤ç¥è­ï¼ä¾å¦å°å®¶è­æï¼ï¼ä¸¦æä¾æ¯æå¦å®åè¨­çè­æãæå¾ï¼ç³»çµ±éè¦ä»¥æ¸æ°å¯è§£éä¸å¯è½ä»¤äººä¿¡æçæ¹å¼å¶å®èªªæãåºæ¼éäºèéï¼ANTIDOTE ä¿æäºå¯è§£é AI çæ´åé¡æ¯ï¼å¶ä¸­æ·±åº¦å­¸ç¿ç¨åºçä½éç¹å¾µèäººé¡è«è­è½åçé«éæ¶æ§ç¸çµåãANTIDOTE å°å©ç¨æ·±åº¦å­¸ç¿èè«è­çè·¨é åè½åï¼ä¾æ¯æå¯è§£é AI æ´å»£æ³ä¸åµæ°çè§é»ï¼å¶ä¸­å°è¨åºæ¡ä¾å¯©è­°çé«åè³ªèªªæéæ±è³ééè¦ãä½çºè©²å°æ¡çç¬¬ä¸åææï¼æåç¼å¸äº Antidote CasiMedicos è³æéï¼ä»¥å©æ¼ä¸è¬å¯è§£é AI çç ç©¶ï¼ç¹å¥æ¯é«çé åçè«è­ã

##### **XInsight: Revealing Model Insights for GNNs with Flow-based Explanations**
2306.04791v1 by Eli Laird, Ayesh Madushanka, Elfi Kraka, Corey Clark

Progress in graph neural networks has grown rapidly in recent years, with
many new developments in drug discovery, medical diagnosis, and recommender
systems. While this progress is significant, many networks are `black boxes'
with little understanding of the `what' exactly the network is learning. Many
high-stakes applications, such as drug discovery, require human-intelligible
explanations from the models so that users can recognize errors and discover
new knowledge. Therefore, the development of explainable AI algorithms is
essential for us to reap the benefits of AI.
  We propose an explainability algorithm for GNNs called eXplainable Insight
(XInsight) that generates a distribution of model explanations using GFlowNets.
Since GFlowNets generate objects with probabilities proportional to a reward,
XInsight can generate a diverse set of explanations, compared to previous
methods that only learn the maximum reward sample. We demonstrate XInsight by
generating explanations for GNNs trained on two graph classification tasks:
classifying mutagenic compounds with the MUTAG dataset and classifying acyclic
graphs with a synthetic dataset that we have open-sourced. We show the utility
of XInsight's explanations by analyzing the generated compounds using QSAR
modeling, and we find that XInsight generates compounds that cluster by
lipophilicity, a known correlate of mutagenicity. Our results show that
XInsight generates a distribution of explanations that uncovers the underlying
relationships demonstrated by the model. They also highlight the importance of
generating a diverse set of explanations, as it enables us to discover hidden
relationships in the model and provides valuable guidance for further analysis.

æè¦ï¼<paragraph>è¿å¹´ä¾ï¼åç¥ç¶ç¶²è·¯çé²å±è¿éï¼å¨è¥ç©ç¼ç¾ãé«çè¨ºæ·åæ¨è¦ç³»çµ±æ¹é¢é½æè¨±å¤æ°ç¼å±ãéç¶éäºé²å±å¾éè¦ï¼ä½è¨±å¤ç¶²è·¯é½æ¯ãé»çå­ãï¼å°æ¼ç¶²è·¯å°åºå¨å­¸ç¿ãä»éº¼ãäºè§£çå°ãè¨±å¤é«é¢¨éªæç¨ï¼ä¾å¦è¥ç©ç¼ç¾ï¼éè¦æ¨¡åæä¾äººé¡å¯ä»¥çè§£çè§£éï¼ä»¥ä¾¿ä½¿ç¨èå¯ä»¥è¾¨è­é¯èª¤ä¸¦ç¼ç¾æ°ç¥è­ãå æ­¤ï¼å¯è§£é AI æ¼ç®æ³çéç¼å°æ¼æåç²å AI çå¥½èè³ééè¦ã
æåæåºäºä¸ç¨®ç¨±çº eXplainable Insight (XInsight) ç GNN å¯è§£éæ§æ¼ç®æ³ï¼å®ä½¿ç¨ GFlowNets ç¢çæ¨¡åè§£éåä½ãç±æ¼ GFlowNets æç¢çæ©çèçåµææ­£æ¯çç©ä»¶ï¼å æ­¤èåååå­¸ç¿æå¤§çåµç¯ä¾çæ¹æ³ç¸æ¯ï¼XInsight å¯ä»¥ç¢çå¤æ¨£åçè§£ééåãæåééçºå¨å©ååå½¢åé¡ä»»åä¸­è¨ç·´ç GNN ç¢çè§£éä¾å±ç¤º XInsightï¼ä½¿ç¨ MUTAG è³æéå°è´çªè®ååç©é²è¡åé¡ï¼ä¸¦ä½¿ç¨æåå·²éæ¾åå§ç¢¼çåæè³æéå°éç°çåå½¢é²è¡åé¡ãæåééä½¿ç¨ QSAR å»ºæ¨¡åæç¢ççååç©ä¾å±ç¤º XInsight è§£éçæç¨ï¼æåç¼ç¾ XInsight æç¢çæè¦ªèæ§ï¼å·²ç¥çè´çªè®ç¸éæ§ï¼åç¾¤çååç©ãæåççµæé¡¯ç¤º XInsight æç¢çä¸åè§£éåä½ï¼æ­ç¤ºæ¨¡åæå±ç¤ºçåºå±¤éä¿ãå®åä¹å¼·èª¿ç¢çå¤æ¨£åè§£ééåçéè¦æ§ï¼å çºå®ä½¿æåè½å¤ ç¼ç¾æ¨¡åä¸­çé±èéä¿ï¼ä¸¦çºé²ä¸æ­¥åææä¾æå¹å¼çæå°ã</paragraph>

##### **Explainable AI using expressive Boolean formulas**
2306.03976v1 by Gili Rosenberg, J. Kyle Brubaker, Martin J. A. Schuetz, Grant Salton, Zhihuai Zhu, Elton Yechao Zhu, Serdar KadÄ±oÄlu, Sima E. Borujeni, Helmut G. Katzgraber

We propose and implement an interpretable machine learning classification
model for Explainable AI (XAI) based on expressive Boolean formulas. Potential
applications include credit scoring and diagnosis of medical conditions. The
Boolean formula defines a rule with tunable complexity (or interpretability),
according to which input data are classified. Such a formula can include any
operator that can be applied to one or more Boolean variables, thus providing
higher expressivity compared to more rigid rule-based and tree-based
approaches. The classifier is trained using native local optimization
techniques, efficiently searching the space of feasible formulas. Shallow rules
can be determined by fast Integer Linear Programming (ILP) or Quadratic
Unconstrained Binary Optimization (QUBO) solvers, potentially powered by
special purpose hardware or quantum devices. We combine the expressivity and
efficiency of the native local optimizer with the fast operation of these
devices by executing non-local moves that optimize over subtrees of the full
Boolean formula. We provide extensive numerical benchmarking results featuring
several baselines on well-known public datasets. Based on the results, we find
that the native local rule classifier is generally competitive with the other
classifiers. The addition of non-local moves achieves similar results with
fewer iterations, and therefore using specialized or quantum hardware could
lead to a speedup by fast proposal of non-local moves.

æè¦ï¼æåæåºä¸¦å¯¦ä½ä¸åå¯è§£éæ©å¨å­¸ç¿åé¡æ¨¡åï¼ç¨æ¼åºæ¼è¡¨éå¼å¸æå¬å¼çå¯è§£é AI (XAI)ãæ½å¨æç¨åæ¬ä¿¡ç¨è©ååé«ççæ³è¨ºæ·ãå¸æå¬å¼å®ç¾©äºä¸åå·æå¯èª¿æ´è¤éæ§ï¼æå¯è§£éæ§ï¼çè¦åï¼æ ¹æè©²è¦åå°è¼¸å¥æ¸æé²è¡åé¡ãéæ¨£çå¬å¼å¯ä»¥åå«ä»»ä½å¯æç¨æ¼ä¸åæå¤åå¸æè®æ¸çéç®å­ï¼å¾èèæ´å´æ ¼çåºæ¼è¦åååºæ¼æ¨¹çæ¹æ³ç¸æ¯ï¼æä¾æ´é«çè¡¨éè½åãåé¡å¨ä½¿ç¨åçå±é¨æä½³åæè¡é²è¡è¨ç·´ï¼ææå°æç´¢å¯è¡å¬å¼çç©ºéãæ·ºå±¤è¦åå¯ä»¥ç¨å¿«éçæ´æ¸ç·æ§è¦å (ILP) æäºæ¬¡ç¡ç´æäºåæä½³å (QUBO) æ±è§£å¨ä¾ç¢ºå®ï¼éäºæ±è§£å¨å¯è½ç±ç¹æ®ç¨éçç¡¬é«æéå­è£ç½®æä¾æ¯æ´ãæåå°åçå±é¨æä½³åå¨çè¡¨éè½ååæçèéäºè£ç½®çå¿«ééç®ç¸çµåï¼ééå·è¡éå±é¨ç§»åä¾æä½³åå®æ´å¸æå¬å¼çå­æ¨¹ãæåæä¾å»£æ³çæ¸å¼åºæºæ¸¬è©¦çµæï¼å¶ä¸­åå«å¨ç¾æå¨ç¥çå¬å±è³æéä¸ä½¿ç¨å¤ååºç·ãæ ¹æçµæï¼æåç¼ç¾åçå±é¨è¦ååé¡å¨éå¸¸èå¶ä»åé¡å¨å·æç«¶ç­åãå å¥éå±é¨ç§»åä»¥è¼å°çåè¦éç®æ¬¡æ¸éæé¡ä¼¼ççµæï¼å æ­¤ä½¿ç¨å°ç¨æéå­ç¡¬é«å¯è½æééå¿«éæåºéå±é¨ç§»åä¾å éã

##### **Utterance Classification with Logical Neural Network: Explainable AI for Mental Disorder Diagnosis**
2306.03902v1 by Yeldar Toleubay, Don Joven Agravante, Daiki Kimura, Baihan Lin, Djallel Bouneffouf, Michiaki Tatsubori

In response to the global challenge of mental health problems, we proposes a
Logical Neural Network (LNN) based Neuro-Symbolic AI method for the diagnosis
of mental disorders. Due to the lack of effective therapy coverage for mental
disorders, there is a need for an AI solution that can assist therapists with
the diagnosis. However, current Neural Network models lack explainability and
may not be trusted by therapists. The LNN is a Recurrent Neural Network
architecture that combines the learning capabilities of neural networks with
the reasoning capabilities of classical logic-based AI. The proposed system
uses input predicates from clinical interviews to output a mental disorder
class, and different predicate pruning techniques are used to achieve
scalability and higher scores. In addition, we provide an insight extraction
method to aid therapists with their diagnosis. The proposed system addresses
the lack of explainability of current Neural Network models and provides a more
trustworthy solution for mental disorder diagnosis.

æè¦ï¼çºäºè§£æ±ºå¿çå¥åº·åé¡çå¨çææ°ï¼æåæåºä¸ååºæ¼éè¼¯ç¥ç¶ç¶²è·¯ (LNN) çç¥ç¶ç¬¦è AI æ¹æ³ä¾è¨ºæ·å¿çç¾çãç±æ¼ç¼ºä¹ææçå¿çç¾çæ²»çæ¶µèç¯åï¼å æ­¤éè¦ä¸ç¨® AI è§£æ±ºæ¹æ¡ä¾åå©æ²»çå¸«é²è¡è¨ºæ·ãç¶èï¼ç®åçé¡ç¥ç¶ç¶²è·¯æ¨¡åç¼ºä¹å¯è§£éæ§ï¼æ²»çå¸«å¯è½ç¡æ³ä¿¡ä»»å®åãLNN æ¯ä¸ç¨®éè¿´ç¥ç¶ç¶²è·¯æ¶æ§ï¼å®çµåäºç¥ç¶ç¶²è·¯çå­¸ç¿è½åååºæ¼ç¶å¸éè¼¯ç AI çæ¨çè½åãææåºçç³»çµ±ä½¿ç¨ä¾èªè¨åºè¨ªè«çè¼¸å¥è¬è©ä¾è¼¸åºå¿çç¾çé¡å¥ï¼ä¸¦ä½¿ç¨ä¸åçè¬è©åªææè¡ä¾å¯¦ç¾å¯æ´åæ§åæ´é«çåæ¸ãæ­¤å¤ï¼æåæä¾äºä¸åè¦è§£æåæ¹æ³ä¾åå©æ²»çå¸«é²è¡è¨ºæ·ãææåºçç³»çµ±è§£æ±ºäºç¶åé¡ç¥ç¶ç¶²è·¯æ¨¡åç¼ºä¹å¯è§£éæ§çåé¡ï¼ä¸¦çºå¿çç¾çè¨ºæ·æä¾äºæ´å¼å¾ä¿¡è³´çè§£æ±ºæ¹æ¡ã

##### **XAI Renaissance: Redefining Interpretability in Medical Diagnostic Models**
2306.01668v1 by Sujith K Mandala

As machine learning models become increasingly prevalent in medical
diagnostics, the need for interpretability and transparency becomes paramount.
The XAI Renaissance signifies a significant shift in the field, aiming to
redefine the interpretability of medical diagnostic models. This paper explores
the innovative approaches and methodologies within the realm of Explainable AI
(XAI) that are revolutionizing the interpretability of medical diagnostic
models. By shedding light on the underlying decision-making process, XAI
techniques empower healthcare professionals to understand, trust, and
effectively utilize these models for accurate and reliable medical diagnoses.
This review highlights the key advancements in XAI for medical diagnostics and
their potential to transform the healthcare landscape, ultimately improving
patient outcomes and fostering trust in AI-driven diagnostic systems.

æè¦ï¼é¨èæ©å¨å­¸ç¿æ¨¡åå¨é«çè¨ºæ·ä¸­è¶ä¾è¶æ®éï¼å¯è§£éæ§åéæåº¦çéæ±è®å¾è³ééè¦ãXAI å¾©èæ¨èªèè©²é åçéå¤§è½è®ï¼æ¨å¨éæ°å®ç¾©é«çè¨ºæ·æ¨¡åçå¯è§£éæ§ãæ¬ææ¢è¨äºå¯è§£é AI (XAI) é åå§çåµæ°æ¹æ³åæ¹æ³è«ï¼éäºæ¹æ³åæ¹æ³è«æ­£å¨é©æ°é«çè¨ºæ·æ¨¡åçå¯è§£éæ§ãééé¡æåºç¤æ±ºç­å¶å®éç¨ï¼XAI æè¡ä½¿é«çä¿å¥å°æ¥­äººå¡è½å¤ çè§£ãä¿¡ä»»ä¸¦ææå°å©ç¨éäºæ¨¡åé²è¡æºç¢ºä¸å¯é çé«çè¨ºæ·ãæ¬ç¶è¿°éé»ä»ç´¹äº XAI å¨é«çè¨ºæ·æ¹é¢çééµé²å±åå¶è½è®é«çä¿å¥é åçæ½åï¼æçµæ¹åæ£èçæ²»çææä¸¦å¹é¤å° AI é©åçè¨ºæ·ç³»çµ±çä¿¡ä»»ã

##### **A Novel real-time arrhythmia detection model using YOLOv8**
2305.16727v3 by Guang Jun Nicholas Ang, Aritejh Kr Goil, Henryk Chan, Jieyi Jeric Lew, Xin Chun Lee, Raihan Bin Ahmad Mustaffa, Timotius Jason, Ze Ting Woon, Bingquan Shen

In a landscape characterized by heightened connectivity and mobility, coupled
with a surge in cardiovascular ailments, the imperative to curtail healthcare
expenses through remote monitoring of cardiovascular health has become more
pronounced. The accurate detection and classification of cardiac arrhythmias
are pivotal for diagnosing individuals with heart irregularities. This study
underscores the feasibility of employing electrocardiograms (ECG) measurements
in the home environment for real-time arrhythmia detection. Presenting a fresh
application for arrhythmia detection, this paper leverages the cutting-edge
You-Only-Look-Once (YOLO)v8 algorithm to categorize single-lead ECG signals. We
introduce a novel loss-modified YOLOv8 model, fine-tuned on the MIT-BIH
arrhythmia dataset, enabling real-time continuous monitoring. The obtained
results substantiate the efficacy of our approach, with the model attaining an
average accuracy of 99.5% and 0.992 mAP@50, and a rapid detection time of 0.002
seconds on an NVIDIA Tesla V100. Our investigation exemplifies the potential of
real-time arrhythmia detection, enabling users to visually interpret the model
output within the comfort of their homes. Furthermore, this study lays the
groundwork for an extension into a real-time explainable AI (XAI) model capable
of deployment in the healthcare sector, thereby significantly advancing the
realm of healthcare solutions.

æè¦ï¼<paragraph>å¨ä»¥é«åº¦é£æ¥æ§åæµåæ§çºç¹å¾µçç°å¢ä¸­ï¼å ä¸å¿è¡ç®¡ç¾ççæ¿å¢ï¼ééé ç¨ç£æ§å¿è¡ç®¡å¥åº·ä¾åæ¸é«çä¿å¥æ¯åºçå¿è¦æ§è®å¾æ´å æé¡¯ãæºç¢ºæª¢æ¸¬ååé¡å¿å¾ä¸æ´å°æ¼è¨ºæ·æ£æå¿èä¸è¦åçäººè³ééè¦ãæ¬ç ç©¶å¼·èª¿äºå¨å®¶ä¸­ä½¿ç¨å¿é»å (ECG) æ¸¬éé²è¡å¯¦æå¿å¾ä¸æ´æª¢æ¸¬çå¯è¡æ§ãæ¬ææåºäºä¸ç¨®æ°çå¿å¾ä¸æ´æª¢æ¸¬æç¨ï¼å©ç¨å°ç«¯ç You-Only-Look-Once (YOLO)v8 æ¼ç®æ³å°å®å°è¯ ECG è¨èé²è¡åé¡ãæåå¼å¥äºä¸åæ°ç©çæå¤±ä¿®æ¹ YOLOv8 æ¨¡åï¼ä¸¦éå° MIT-BIH å¿å¾ä¸æ´è³æéé²è¡äºå¾®èª¿ï¼å¾èå¯¦ç¾äºå¯¦æçæçºç£æ§ãç²å¾ççµæè­å¯¦äºæåæ¹æ³çæææ§ï¼è©²æ¨¡åå¨ NVIDIA Tesla V100 ä¸éå°äº 99.5% çå¹³åæºç¢ºåº¦å 0.992 mAP@50ï¼ä»¥å 0.002 ç§çå¿«éæª¢æ¸¬æéãæåçç ç©¶èªªæäºå¯¦æå¿å¾ä¸æ´æª¢æ¸¬çæ½åï¼ä½¿ç¨æ¶è½å¤ å¨å®¶ä¸­èé©å°è¦è¦ºåè§£è®æ¨¡åè¼¸åºãæ­¤å¤ï¼æ¬ç ç©¶çºæ´å±å°å¯¦æå¯è§£é AI (XAI) æ¨¡åå¥ å®äºåºç¤ï¼è©²æ¨¡åè½å¤ é¨ç½²å¨é«çä¿å¥é åï¼å¾èé¡¯èæ¨é²é«çä¿å¥è§£æ±ºæ¹æ¡çé åã</paragraph>

##### **Breast Cancer Segmentation using Attention-based Convolutional Network and Explainable AI**
2305.14389v2 by Jai Vardhan, Taraka Satya Krishna Teja Malisetti

Breast cancer (BC) remains a significant health threat, with no long-term
cure currently available. Early detection is crucial, yet mammography
interpretation is hindered by high false positives and negatives. With BC
incidence projected to surpass lung cancer, improving early detection methods
is vital. Thermography, using high-resolution infrared cameras, offers promise,
especially when combined with artificial intelligence (AI). This work presents
an attention-based convolutional neural network for segmentation, providing
increased speed and precision in BC detection and classification. The system
enhances images and performs cancer segmentation with explainable AI. We
propose a transformer-attention-based convolutional architecture (UNet) for
fault identification and employ Gradient-weighted Class Activation Mapping
(Grad-CAM) to analyze areas of bias and weakness in the UNet architecture with
IRT images. The superiority of our proposed framework is confirmed when
compared with existing deep learning frameworks.

æè¦ï¼ä¹³çï¼BCï¼ä»ç¶æ¯ä¸åéå¤§çå¥åº·å¨èï¼ç®åå°ç¡é·ææ²»ççæ¹æ³ãæ©æç¼ç¾è³ééè¦ï¼ä½ä¹³æ¿æå½±çå¤è®å»åå°é«åé½æ§ååé°æ§çé»ç¤ãç±æ¼ä¹³ççç¼ççé è¨å°è¶éèºçï¼å æ­¤æ¹åæ©ææª¢æ¸¬æ¹æ³è³ééè¦ãç±åæå½±ä½¿ç¨é«è§£æåº¦ç´å¤ç·ç¸æ©ï¼ç¹å¥æ¯å¨èäººå·¥æºæ§ï¼AIï¼çµåä½¿ç¨æï¼æä¾äºå¸æãéé å·¥ä½æåºäºä¸ååºæ¼æ³¨æåçå·ç©ç¥ç¶ç¶²è·¯ç¨æ¼åå²ï¼å¨ä¹³çæª¢æ¸¬ååé¡ä¸­æä¾äºæ´é«çéåº¦åç²¾åº¦ãè©²ç³»çµ±å¢å¼·å½±åä¸¦å·è¡å¯è§£éç AI ççåå²ãæåæåºäºä¸ååºæ¼Transformeræ³¨æåçå·ç©æ¶æ§ï¼UNetï¼ç¨æ¼æéè­å¥ï¼ä¸¦ä½¿ç¨æ¢¯åº¦å æ¬é¡æ¿æ´»æ å°ï¼Grad-CAMï¼ä¾åæ UNet æ¶æ§ä¸­åè¦åå¼±é»çååï¼ä½¿ç¨ IRT å½±åãèç¾æçæ·±åº¦å­¸ç¿æ¡æ¶ç¸æ¯ï¼æåæåºçæ¡æ¶çåªè¶æ§å¾å°è­å¯¦ã

##### **What Symptoms and How Long? An Interpretable AI Approach for Depression Detection in Social Media**
2305.13127v2 by Junwei Kuang, Jiaheng Xie, Zhijun Yan

Depression is the most prevalent and serious mental illness, which induces
grave financial and societal ramifications. Depression detection is key for
early intervention to mitigate those consequences. Such a high-stake decision
inherently necessitates interpretability. Although a few depression detection
studies attempt to explain the decision based on the importance score or
attention weights, these explanations misalign with the clinical depression
diagnosis criterion that is based on depressive symptoms. To fill this gap, we
follow the computational design science paradigm to develop a novel Multi-Scale
Temporal Prototype Network (MSTPNet). MSTPNet innovatively detects and
interprets depressive symptoms as well as how long they last. Extensive
empirical analyses using a large-scale dataset show that MSTPNet outperforms
state-of-the-art depression detection methods with an F1-score of 0.851. This
result also reveals new symptoms that are unnoted in the survey approach, such
as sharing admiration for a different life. We further conduct a user study to
demonstrate its superiority over the benchmarks in interpretability. This study
contributes to IS literature with a novel interpretable deep learning model for
depression detection in social media. In practice, our proposed method can be
implemented in social media platforms to provide personalized online resources
for detected depressed patients.

æè¦ï¼æé¬±çæ¯ææ®éä¸å´éçç²¾ç¥ç¾çï¼æé æå´éçè²¡ååç¤¾æå¾æãæé¬±ççåµæ¸¬å°æ¼æ©æä»å¥ä»¥æ¸è¼éäºå¾æè³ééè¦ãå¦æ­¤éå¤§çæ±ºå®æ¬è³ªä¸éè¦å¯è§£éæ§ãåç®¡ä¸äºæé¬±çåµæ¸¬ç ç©¶åè©¦æ ¹æéè¦æ§åæ¸ææ³¨æåæ¬éä¾è§£ééåæ±ºå®ï¼ä½éäºè§£éèåºæ¼æé¬±çççè¨åºæé¬±çè¨ºæ·æ¨æºä¸ä¸è´ãçºäºå¡«è£éåç¼ºå£ï¼æåéµå¾ªè¨ç®è¨­è¨ç§å­¸ç¯ä¾ä¾éç¼ä¸åæ°ç©çå¤å°ºåº¦æéååç¶²è·¯ (MSTPNet)ãMSTPNet åµæ°å°åµæ¸¬ä¸¦è§£éæé¬±ççä»¥åå®åæçºå¤ä¹ãä½¿ç¨å¤§è¦æ¨¡è³æéé²è¡çå»£æ³å¯¦è­åæé¡¯ç¤ºï¼MSTPNet ä»¥ 0.851 ç F1 åæ¸åªæ¼æåé²çæé¬±çåµæ¸¬æ¹æ³ãæ­¤çµæéæ­ç¤ºäºèª¿æ¥æ¹æ³ä¸­æªæ³¨æå°çæ°ççï¼ä¾å¦åäº«å°ä¸åçæ´»çæ¬½ä½©ãæåé²ä¸æ­¥é²è¡ä½¿ç¨èç ç©¶ï¼ä»¥è­æå¶å¨å¯è§£éæ§æ¹é¢åªæ¼åºæºãæ¬ç ç©¶ä»¥ä¸åæ°ç©çå¯è§£éæ·±åº¦å­¸ç¿æ¨¡åçºæé¬±çåµæ¸¬å¨ç¤¾ç¾¤åªé«ä¸­ç IS æç»ååºè²¢ç»ãå¨å¯¦åä¸ï¼æåæåºçæ¹æ³å¯ä»¥å¯¦ä½å¨ç¤¾ç¾¤åªé«å¹³å°ä¸­ï¼ä»¥æä¾åäººåçç·ä¸è³æºçµ¦è¢«åµæ¸¬åºæé¬±ççæ£èã

##### **Echoes of Biases: How Stigmatizing Language Affects AI Performance**
2305.10201v4 by Yizhi Liu, Weiguang Wang, Guodong Gordon Gao, Ritu Agarwal

Electronic health records (EHRs) serve as an essential data source for the
envisioned artificial intelligence (AI)-driven transformation in healthcare.
However, clinician biases reflected in EHR notes can lead to AI models
inheriting and amplifying these biases, perpetuating health disparities. This
study investigates the impact of stigmatizing language (SL) in EHR notes on
mortality prediction using a Transformer-based deep learning model and
explainable AI (XAI) techniques. Our findings demonstrate that SL written by
clinicians adversely affects AI performance, particularly so for black
patients, highlighting SL as a source of racial disparity in AI model
development. To explore an operationally efficient way to mitigate SL's impact,
we investigate patterns in the generation of SL through a clinicians'
collaborative network, identifying central clinicians as having a stronger
impact on racial disparity in the AI model. We find that removing SL written by
central clinicians is a more efficient bias reduction strategy than eliminating
all SL in the entire corpus of data. This study provides actionable insights
for responsible AI development and contributes to understanding clinician
behavior and EHR note writing in healthcare.

æè¦ï¼é»å­å¥åº·ç´é (EHR) ä½çºé æ³ä¸­ç±äººå·¥æºæ§ (AI) æ¨åçé«çä¿å¥è½åçéè¦è³æä¾æºãç¶èï¼åæ å¨ EHR åè¨»ä¸­çè¨åºåè¦å¯è½å°è´ AI æ¨¡åç¹¼æ¿ä¸¦æ´å¤§éäºåè¦ï¼é²èé æå¥åº·å·®ç°ãæ¬ç ç©¶æ¢è¨ EHR åè¨»ä¸­æ±ååèªè¨ (SL) å°ä½¿ç¨åºæ¼ Transformer çæ·±åº¦å­¸ç¿æ¨¡ååå¯è§£é AI (XAI) æè¡é æ¸¬æ­»äº¡ççå½±é¿ãæåçç ç©¶çµæè¡¨æï¼ç±è¨åºé«çæ°å¯«ç SL æå° AI æè½ç¢çä¸å©å½±é¿ï¼ç¹å¥æ¯å°é»äººæ£èèè¨ï¼çªé¡¯ SL æ¯ AI æ¨¡åéç¼ä¸­ç¨®æå·®ç°çä¾æºãçºäºæ¢ç´¢ä¸ç¨®éä½ä¸ææççæ¹æ³ä¾æ¸è¼ SL çå½±é¿ï¼æåééè¨åºé«ççåä½ç¶²è·¯æ¢è¨ SL ç¢ççæ¨¡å¼ï¼ä¸¦æ¾åºæ ¸å¿è¨åºé«çå° AI æ¨¡åä¸­çç¨®æå·®ç°æè¼å¤§çå½±é¿ãæåç¼ç¾ï¼ç§»é¤ç±æ ¸å¿è¨åºé«çæ°å¯«ç SL æ¯æ¯æ¶é¤è³æéä¸­ææ SL æ´ææççåè¦æ¸å°ç­ç¥ãæ¬ç ç©¶æä¾å¯è¡çè¦è§£ï¼ç¨æ¼è² è²¬ä»»ç AI éç¼ï¼ä¸¦æå©æ¼äºè§£è¨åºé«çè¡çºåé«çä¿å¥ä¸­ç EHR åè¨»æ°å¯«ã

##### **Explaining the ghosts: Feminist intersectional XAI and cartography as methods to account for invisible labour**
2305.03376v1 by Goda Klumbyte, Hannah Piehl, Claude Draude

Contemporary automation through AI entails a substantial amount of
behind-the-scenes human labour, which is often both invisibilised and
underpaid. Since invisible labour, including labelling and maintenance work, is
an integral part of contemporary AI systems, it remains important to sensitise
users to its role. We suggest that this could be done through explainable AI
(XAI) design, particularly feminist intersectional XAI. We propose the method
of cartography, which stems from feminist intersectional research, to draw out
a systemic perspective of AI and include dimensions of AI that pertain to
invisible labour.

æè¦ï¼ç¶ä»£éé AI çèªååéè¦å¤§éçå¹å¾äººåï¼ééå¸¸æ¢ä¸å¯è¦ä¸èªè³éä½ãç±æ¼ä¸å¯è¦çååï¼åæ¬æ¨ç±¤åç¶­è­·å·¥ä½ï¼æ¯ç¶ä»£ AI ç³»çµ±ççµæé¨åï¼å æ­¤è®ä½¿ç¨èäºè§£å¶è§è²ä»ç¶å¾éè¦ãæåå»ºè­°éå¯ä»¥ééå¯è§£éç AIï¼XAIï¼è¨­è¨ä¾å®æï¼ç¹å¥æ¯å¥³æ§ä¸»ç¾©äº¤åç XAIãæåæåºæºèªå¥³æ§ä¸»ç¾©äº¤åç ç©¶çè£½åæ¹æ³ï¼ä»¥æåº AI çç³»çµ±è§é»ï¼ä¸¦ç´å¥èä¸å¯è¦ååç¸éç AI ç¶­åº¦ã

##### **Towards Explainable and Safe Conversational Agents for Mental Health: A Survey**
2304.13191v1 by Surjodeep Sarkar, Manas Gaur, L. Chen, Muskan Garg, Biplav Srivastava, Bhaktee Dongaonkar

Virtual Mental Health Assistants (VMHAs) are seeing continual advancements to
support the overburdened global healthcare system that gets 60 million primary
care visits, and 6 million Emergency Room (ER) visits annually. These systems
are built by clinical psychologists, psychiatrists, and Artificial Intelligence
(AI) researchers for Cognitive Behavioral Therapy (CBT). At present, the role
of VMHAs is to provide emotional support through information, focusing less on
developing a reflective conversation with the patient. A more comprehensive,
safe and explainable approach is required to build responsible VMHAs to ask
follow-up questions or provide a well-informed response. This survey offers a
systematic critical review of the existing conversational agents in mental
health, followed by new insights into the improvements of VMHAs with contextual
knowledge, datasets, and their emerging role in clinical decision support. We
also provide new directions toward enriching the user experience of VMHAs with
explainability, safety, and wholesome trustworthiness. Finally, we provide
evaluation metrics and practical considerations for VMHAs beyond the current
literature to build trust between VMHAs and patients in active communications.

æè¦ï¼èæ¬å¿çå¥åº·å©ç (VMHA) æçºé²æ­¥ï¼ä»¥æ¯æ´æ¯å¹´æ 6000 è¬äººæ¬¡åç´ä¿å¥å°±è¨ºå 600 è¬äººæ¬¡æ¥è¨ºå®¤ (ER) å°±è¨ºçè¶è² è·å¨çé«çä¿å¥ç³»çµ±ãéäºç³»çµ±æ¯ç±è¨åºå¿çå­¸å®¶ãç²¾ç¥ç§é«å¸«åäººå·¥æºæ§ (AI) ç ç©¶äººå¡çºèªç¥è¡çºçæ³ (CBT) æå»ºæ§ãç®åï¼VMHA çè§è²æ¯ééè³è¨æä¾æç·æ¯æï¼è¼å°èéæ¼èæ£èç¼å±åææ§çå°è©±ãéè¦æ´å¨é¢ãå®å¨ä¸å¯è§£éçæ¹æ³ä¾å»ºæ§è² è²¬ä»»ç VMHAï¼ä»¥æåºå¾çºåé¡ææä¾ååçåæãéé èª¿æ¥æä¾äºå°å¿çå¥åº·ä¸­ç¾æå°è©±ä»£ççç³»çµ±æ§æ¹å¤æ§åé¡§ï¼æ¥èæ·±å¥æ¢è¨äº VMHA å¨èçµ¡ç¥è­ãè³æéåå¶å¨è¨åºæ±ºç­æ¯æ´ä¸­æ°èè§è²çæ¹é²ãæåä¹æä¾äºæ°çæ¹åï¼ä»¥ééå¯è§£éæ§ãå®å¨æ§èæ´é«å¯ä¿¡åº¦ä¾è±å¯ VMHA çä½¿ç¨èé«é©ãæå¾ï¼æåæä¾äºè©éææ¨å VMHA çå¯¦åèéï¼è¶è¶ç®åçæç»ï¼å¨ VMHA èæ£èçç©æ¥µæºéä¸­å»ºç«ä¿¡ä»»ã

##### **A Brief Review of Explainable Artificial Intelligence in Healthcare**
2304.01543v1 by Zahra Sadeghi, Roohallah Alizadehsani, Mehmet Akif Cifci, Samina Kausar, Rizwan Rehman, Priyakshi Mahanta, Pranjal Kumar Bora, Ammar Almasri, Rami S. Alkhawaldeh, Sadiq Hussain, Bilal Alatas, Afshin Shoeibi, Hossein Moosaei, Milan Hladik, Saeid Nahavandi, Panos M. Pardalos

XAI refers to the techniques and methods for building AI applications which
assist end users to interpret output and predictions of AI models. Black box AI
applications in high-stakes decision-making situations, such as medical domain
have increased the demand for transparency and explainability since wrong
predictions may have severe consequences. Model explainability and
interpretability are vital successful deployment of AI models in healthcare
practices. AI applications' underlying reasoning needs to be transparent to
clinicians in order to gain their trust. This paper presents a systematic
review of XAI aspects and challenges in the healthcare domain. The primary
goals of this study are to review various XAI methods, their challenges, and
related machine learning models in healthcare. The methods are discussed under
six categories: Features-oriented methods, global methods, concept models,
surrogate models, local pixel-based methods, and human-centric methods. Most
importantly, the paper explores XAI role in healthcare problems to clarify its
necessity in safety-critical applications. The paper intends to establish a
comprehensive understanding of XAI-related applications in the healthcare field
by reviewing the related experimental results. To facilitate future research
for filling research gaps, the importance of XAI models from different
viewpoints and their limitations are investigated.

æè¦ï¼XAI æçæ¯ç¨æ¼å»ºæ§ AI æç¨ç¨å¼çæè¡åæ¹æ³ï¼éäºæç¨ç¨å¼å¯åå©æçµä½¿ç¨èè©®é AI æ¨¡åçè¼¸åºåé æ¸¬ãå¨é«é¢¨éªæ±ºç­æå¢ä¸­ï¼ä¾å¦é«çé åï¼é»ç®± AI æç¨ç¨å¼å¢å äºéæåº¦åå¯è§£éæ§çéæ±ï¼å çºé¯èª¤çé æ¸¬å¯è½æé æå´éçå¾æãæ¨¡åå¯è§£éæ§åå¯è©®éæ§å°æ¼å¨é«çå¯¦åä¸­æåé¨ç½² AI æ¨¡åè³ééè¦ãAI æç¨ç¨å¼çåºæ¬æ¨çéè¦å°è¨åºé«çéæï¼æè½ç²å¾ä»åçä¿¡ä»»ãæ¬ææä¾äºé«çé åä¸­ XAI é¢ååææ°çç³»çµ±æ§åé¡§ãæ¬ç ç©¶çä¸»è¦ç®æ¨æ¯åé¡§åç¨® XAI æ¹æ³ãå¶ææ°ï¼ä»¥åç¸éçé«çä¿å¥æ©å¨å­¸ç¿æ¨¡åãéäºæ¹æ³åçºå­é¡è¨è«ï¼é¢åç¹å¾µçæ¹æ³ãæ´é«æ¹æ³ãæ¦å¿µæ¨¡åãä»£çæ¨¡åãå±é¨åºæ¼åç´ çæ¹æ³ï¼ä»¥åä»¥äººçºä¸­å¿çæ¹æ³ãæéè¦çæ¯ï¼æ¬ææ¢è¨äº XAI å¨é«çä¿å¥åé¡ä¸­çè§è²ï¼ä»¥éæ¸å¶å¨å®å¨ééµæç¨ä¸­çå¿è¦æ§ãæ¬ææ¨å¨ééåé¡§ç¸éçå¯¦é©çµæï¼å»ºç«å°é«çä¿å¥é åä¸­ XAI ç¸éæç¨ç¨å¼çå¨é¢äºè§£ãçºäºä¿é²æªä¾ç ç©¶å¡«è£ç ç©¶å·®è·ï¼æ¬ææ¢è¨äº XAI æ¨¡åå¾ä¸åè§é»ä¾ççéè¦æ§åå¶éå¶ã

##### **Reveal to Revise: An Explainable AI Life Cycle for Iterative Bias Correction of Deep Models**
2303.12641v2 by Frederik Pahde, Maximilian Dreyer, Wojciech Samek, Sebastian Lapuschkin

State-of-the-art machine learning models often learn spurious correlations
embedded in the training data. This poses risks when deploying these models for
high-stake decision-making, such as in medical applications like skin cancer
detection. To tackle this problem, we propose Reveal to Revise (R2R), a
framework entailing the entire eXplainable Artificial Intelligence (XAI) life
cycle, enabling practitioners to iteratively identify, mitigate, and
(re-)evaluate spurious model behavior with a minimal amount of human
interaction. In the first step (1), R2R reveals model weaknesses by finding
outliers in attributions or through inspection of latent concepts learned by
the model. Secondly (2), the responsible artifacts are detected and spatially
localized in the input data, which is then leveraged to (3) revise the model
behavior. Concretely, we apply the methods of RRR, CDEP and ClArC for model
correction, and (4) (re-)evaluate the model's performance and remaining
sensitivity towards the artifact. Using two medical benchmark datasets for
Melanoma detection and bone age estimation, we apply our R2R framework to VGG,
ResNet and EfficientNet architectures and thereby reveal and correct real
dataset-intrinsic artifacts, as well as synthetic variants in a controlled
setting. Completing the XAI life cycle, we demonstrate multiple R2R iterations
to mitigate different biases. Code is available on
https://github.com/maxdreyer/Reveal2Revise.

æè¦ï¼æåè¿çæºå¨å­¦ä¹ æ¨¡åéå¸¸ä¼å­¦ä¹ è®­ç»æ°æ®ä¸­åµå¥çèåå³èãè¿å¨å°è¿äºæ¨¡åé¨ç½²äºé«é£é©å³ç­æ¶ä¼å¸¦æ¥é£é©ï¼ä¾å¦å¨ç®è¤çæ£æµç­å»å­¦åºç¨ä¸­ãä¸ºäºè§£å³è¿ä¸ªé®é¢ï¼æä»¬æåºäº Reveal to Revise (R2R)ï¼ä¸ä¸ªæ¶µçæ´ä¸ªå¯è§£éäººå·¥æºè½ (XAI) çå½å¨æçæ¡æ¶ï¼ä½¿ä»ä¸èè½å¤ä»¥æå°çäººå·¥äº¤äºè¿­ä»£è¯å«ãç¼è§£åï¼éæ°ï¼è¯ä¼°èåæ¨¡åè¡ä¸ºãå¨ç¬¬ä¸æ­¥ (1) ä¸­ï¼R2R éè¿æ¾åºå½å ä¸­çå¼å¸¸å¼æéè¿æ£æ¥æ¨¡åå­¦ä¹ çæ½å¨æ¦å¿µæ¥æ­ç¤ºæ¨¡åçå¼±ç¹ãå¶æ¬¡ (2)ï¼æ£æµè´è´£çä¼ªåå¹¶å¨è¾å¥æ°æ®ä¸­è¿è¡ç©ºé´å®ä½ï¼ç¶åå©ç¨å®æ¥ (3) ä¿®æ¹æ¨¡åè¡ä¸ºãå·ä½æ¥è¯´ï¼æä»¬åºç¨ RRRãCDEP å ClArC çæ¹æ³æ¥è¿è¡æ¨¡åæ ¡æ­£ï¼å¹¶ (4)ï¼éæ°ï¼è¯ä¼°æ¨¡åçæ§è½åå¯¹ä¼ªåçå©ä½æææ§ãä½¿ç¨ä¸¤ä¸ªç¨äºé»è²ç´ ç¤æ£æµåéª¨é¾ä¼°è®¡çå»å­¦åºåæ°æ®éï¼æä»¬å°æä»¬ç R2R æ¡æ¶åºç¨äº VGGãResNet å EfficientNet æ¶æï¼ä»èæ­ç¤ºåçº æ­£äºçå®æ°æ®éåºæçä¼ªåï¼ä»¥ååæ§è®¾ç½®ä¸­çåæåä½ãå®æ XAI çå½å¨æï¼æä»¬æ¼ç¤ºäºå¤ä¸ª R2R è¿­ä»£ä»¥åè½»ä¸åçåå·®ãä»£ç å¯å¨ https://github.com/maxdreyer/Reveal2Revise ä¸æ¾å°ã

##### **Explainable AI for Time Series via Virtual Inspection Layers**
2303.06365v1 by Johanna Vielhaben, Sebastian Lapuschkin, GrÃ©goire Montavon, Wojciech Samek

The field of eXplainable Artificial Intelligence (XAI) has greatly advanced
in recent years, but progress has mainly been made in computer vision and
natural language processing. For time series, where the input is often not
interpretable, only limited research on XAI is available. In this work, we put
forward a virtual inspection layer, that transforms the time series to an
interpretable representation and allows to propagate relevance attributions to
this representation via local XAI methods like layer-wise relevance propagation
(LRP). In this way, we extend the applicability of a family of XAI methods to
domains (e.g. speech) where the input is only interpretable after a
transformation. Here, we focus on the Fourier transformation which is
prominently applied in the interpretation of time series and LRP and refer to
our method as DFT-LRP. We demonstrate the usefulness of DFT-LRP in various time
series classification settings like audio and electronic health records. We
showcase how DFT-LRP reveals differences in the classification strategies of
models trained in different domains (e.g., time vs. frequency domain) or helps
to discover how models act on spurious correlations in the data.

æè¦ï¼å¯è§£éäººå·¥æºæ§ (XAI) é åå¨è¿å¹´ä¾åå¾é·è¶³é²æ­¥ï¼ä½é²å±ä¸»è¦æ¯å¨é»è¦è¦è¦ºåèªç¶èªè¨èçæ¹é¢ãå°æ¼è¼¸å¥éå¸¸ç¡æ³è§£éçæéåºåï¼åªææéçç ç©¶å¯ä¾ä½¿ç¨ XAIãå¨éé å·¥ä½ä¸­ï¼æåæåºäºä¸åèæ¬æª¢æ¥å±¤ï¼å®å°æéåºåè½æçºå¯è§£éçè¡¨ç¤ºï¼ä¸¦åè¨±ééå±¤ç´ç¸éæ§å³æ­ (LRP) ç­å±é¨ XAI æ¹æ³å°ç¸éæ§æ­¸å å³æ­å°æ­¤è¡¨ç¤ºãèæ­¤ï¼æåå°ä¸ç³»å XAI æ¹æ³çé©ç¨æ§æ´å±å°è¼¸å¥åå¨è½æå¾æè½è§£éçé åï¼ä¾å¦èªé³ï¼ãå¨æ­¤ï¼æåå°æ³¨æ¼åç«èè½æï¼å®ä¸»è¦æç¨æ¼æéåºåå LRP çè§£éï¼ä¸¦å°æåçç¨±ä¹çº DFT-LRPãæåå±ç¤ºäº DFT-LRP å¨åç¨®æéåºååé¡è¨­å®ï¼ä¾å¦é³è¨åé»å­å¥åº·ç´éï¼ä¸­çæç¨ãæåå±ç¤ºäº DFT-LRP å¦ä½æ­ç¤ºå¨ä¸åé åï¼ä¾å¦æéèé »çåï¼è¨ç·´çæ¨¡åçåé¡ç­ç¥å·®ç°ï¼ææå©æ¼ç¼ç¾æ¨¡åå¦ä½èçè³æä¸­çèåéè¯ã

##### **Towards Trust of Explainable AI in Thyroid Nodule Diagnosis**
2303.04731v1 by Truong Thanh Hung Nguyen, Van Binh Truong, Vo Thanh Khang Nguyen, Quoc Hung Cao, Quoc Khanh Nguyen

The ability to explain the prediction of deep learning models to end-users is
an important feature to leverage the power of artificial intelligence (AI) for
the medical decision-making process, which is usually considered
non-transparent and challenging to comprehend. In this paper, we apply
state-of-the-art eXplainable artificial intelligence (XAI) methods to explain
the prediction of the black-box AI models in the thyroid nodule diagnosis
application. We propose new statistic-based XAI methods, namely Kernel Density
Estimation and Density map, to explain the case of no nodule detected. XAI
methods' performances are considered under a qualitative and quantitative
comparison as feedback to improve the data quality and the model performance.
Finally, we survey to assess doctors' and patients' trust in XAI explanations
of the model's decisions on thyroid nodule images.

æè¦ï¼è§£éæ·±åº¦å­¸ç¿æ¨¡åé æ¸¬çµæçè½åå°æçµä½¿ç¨èèè¨æ¯ä¸é éè¦åè½ï¼å¯å©ç¨äººå·¥æºæ§ (AI) çåéé²è¡é«çæ±ºç­æµç¨ï¼ééå¸¸è¢«èªçºæ¯ä¸éæä¸é£ä»¥çè§£çãå¨æ¬æä¸­ï¼æåéç¨æåé²çå¯è§£éäººå·¥æºæ§ (XAI) æ¹æ³ä¾è§£éé»ç AI æ¨¡åå¨ç²çèºçµç¯è¨ºæ·æç¨ä¸­çé æ¸¬çµæãæåæåºæ°çåºæ¼çµ±è¨ç XAI æ¹æ³ï¼å³æ ¸å¯åº¦ä¼°è¨åå¯åº¦åï¼ä¾è§£éæªæª¢æ¸¬å°çµç¯çææ³ãXAI æ¹æ³çæè½æå¨å®æ§åå®éæ¯è¼ä¸è¢«è¦çºæ¹åè³æåè³ªåæ¨¡åæè½çåé¥ãæå¾ï¼æåé²è¡èª¿æ¥ä»¥è©ä¼°é«å¸«åæ£èå° XAI å°æ¨¡åå¨ç²çèºçµç¯å½±åä¸­æ±ºç­çè§£éçä¿¡ä»»åº¦ã

##### **Cybersecurity of AI medical devices: risks, legislation, and challenges**
2303.03140v1 by Elisabetta Biasin, Erik Kamenjasevic, Kaspar Rosager Ludvigsen

Medical devices and artificial intelligence systems rapidly transform
healthcare provisions. At the same time, due to their nature, AI in or as
medical devices might get exposed to cyberattacks, leading to patient safety
and security risks. This book chapter is divided into three parts. The first
part starts by setting the scene where we explain the role of cybersecurity in
healthcare. Then, we briefly define what we refer to when we talk about AI that
is considered a medical device by itself or supports one. To illustrate the
risks such medical devices pose, we provide three examples: the poisoning of
datasets, social engineering, and data or source code extraction. In the second
part, the paper provides an overview of the European Union's regulatory
framework relevant for ensuring the cybersecurity of AI as or in medical
devices (MDR, NIS Directive, Cybersecurity Act, GDPR, the AI Act proposal and
the NIS 2 Directive proposal). Finally, the third part of the paper examines
possible challenges stemming from the EU regulatory framework. In particular,
we look toward the challenges deriving from the two legislative proposals and
their interaction with the existing legislation concerning AI medical devices'
cybersecurity. They are structured as answers to the following questions: (1)
how will the AI Act interact with the MDR regarding the cybersecurity and
safety requirements?; (2) how should we interpret incident notification
requirements from the NIS 2 Directive proposal and MDR?; and (3) what are the
consequences of the evolving term of critical infrastructures?
  [This is a draft chapter. The final version will be available in Research
Handbook on Health, AI and the Law edited by Barry Solaiman & I. Glenn Cohen,
forthcoming 2023, Edward Elgar Publishing Ltd]

æè¦ï¼é«çè¨­ååäººå·¥æºæ§ç³»çµ±å¿«éè½åé«çä¿å¥çæä¾æ¹å¼ãåæï¼ç±æ¼å¶æ¬è³ªï¼é«çè¨­åä¸­æä½çºé«çè¨­åçäººå·¥æºæ§å¯è½æé­åç¶²è·¯æ»æï¼é²èå°è´æ£èå®å¨åå®å¨é¢¨éªãæ¬ç« ç¯åçºä¸é¨åãç¬¬ä¸é¨åå¾è¨­å®å ´æ¯éå§ï¼èªªæç¶²è·¯å®å¨å¨é«çä¿å¥ä¸­çè§è²ãç¶å¾ï¼æåç°¡è¦å®ç¾©æåå¨è«è«è¢«è¦çºé«çè¨­åæ¬èº«ææ¯æ´é«çè¨­åçäººå·¥æºæ§ææææ¶çå§å®¹ãçºäºèªªææ­¤é¡é«çè¨­åå¸¶ä¾çé¢¨éªï¼æåæä¾äºä¸åç¯ä¾ï¼è³æéä¸­æ¯ãç¤¾æå·¥ç¨åè³ææåå§ç¢¼èåãå¨ç¬¬äºé¨åï¼æ¬ææ¦è¿°äºæ­ççç£ç®¡æ¶æ§ï¼èç¢ºä¿é«çè¨­åä¸­æä½çºé«çè¨­åçäººå·¥æºæ§çç¶²è·¯å®å¨ç¸éï¼é«çå¨ææ³è¦ãç¶²è·¯èè³è¨å®å¨æä»¤ãç¶²è·¯å®å¨æ³ãä¸è¬è³æä¿è­·è¦ç¯ãäººå·¥æºæ§æ³ææ¡åç¶²è·¯èè³è¨å®å¨ 2 æä»¤ææ¡ï¼ãæå¾ï¼æ¬æçç¬¬ä¸é¨åæ¢è¨æºèªæ­çç£ç®¡æ¶æ§çæ½å¨ææ°ãç¹å¥æ¯ï¼æåå±ææºèªéå©é ç«æ³ææ¡çææ°ï¼ä»¥åå®åèç¾æéæ¼äººå·¥æºæ§é«çè¨­åç¶²è·¯å®å¨çç«æ³ä¹éçäºåãå®åè¢«æ¶æ§çºä»¥ä¸åé¡çè§£ç­ï¼(1) äººå·¥æºæ§æ³å°å¦ä½èé«çå¨ææ³è¦äºåï¼å°±ç¶²è·¯å®å¨åå®å¨è¦æ±èè¨ï¼(2) æåæå¦ä½è§£è®ç¶²è·¯èè³è¨å®å¨ 2 æä»¤ææ¡åé«çå¨ææ³è¦çäºä»¶éç¥è¦æ±ï¼(3) ééµåºç¤è¨­æ½æ¼é²çè¡èªæå¸¶ä¾ä»éº¼å¾æï¼
[éæ¯èç¨¿ç« ç¯ãæçµçæ¬å°åè¼æ¼ Barry Solaiman å I. Glenn Cohen ç·¨è¼¯çãå¥åº·ãäººå·¥æºæ§èæ³å¾ç ç©¶æåãä¸­ï¼2023 å¹´åºçï¼Edward Elgar Publishing Ltd]

##### **LAVA: Granular Neuron-Level Explainable AI for Alzheimer's Disease Assessment from Fundus Images**
2302.03008v2 by Nooshin Yousefzadeh, Charlie Tran, Adolfo Ramirez-Zamora, Jinghua Chen, Ruogu Fang, My T. Thai

Alzheimer's Disease (AD) is a progressive neurodegenerative disease and the
leading cause of dementia. Early diagnosis is critical for patients to benefit
from potential intervention and treatment. The retina has been hypothesized as
a diagnostic site for AD detection owing to its anatomical connection with the
brain. Developed AI models for this purpose have yet to provide a rational
explanation about the decision and neither infer the stage of disease's
progression. Along this direction, we propose a novel model-agnostic
explainable-AI framework, called Granular Neuron-level Explainer (LAVA), an
interpretation prototype that probes into intermediate layers of the
Convolutional Neural Network (CNN) models to assess the AD continuum directly
from the retinal imaging without longitudinal or clinical evaluation. This
method is applied to validate the retinal vasculature as a biomarker and
diagnostic modality for Alzheimer's Disease (AD) evaluation. UK Biobank
cognitive tests and vascular morphological features suggest LAVA shows strong
promise and effectiveness in identifying AD stages across the progression
continuum.

æè¦ï¼é¿è²æµ·é»ç (AD) æ¯ä¸ç¨®é²è¡æ§çç¥ç¶éåæ§ç¾çï¼ä¹æ¯å°è´å¤±æºççä¸»å ãæ©æè¨ºæ·å°æ¼æ£èæ¥åæ½å¨å¹²é åæ²»çè³ééè¦ãç±æ¼è¦ç¶²èèå¤§è¦æè§£åå­¸ä¸çé£çµï¼å æ­¤åè¨­è¦ç¶²èå¯ä»¥ä½çº AD æª¢æ¸¬çè¨ºæ·é¨ä½ãçºæ­¤ç®çèéç¼ç AI æ¨¡åï¼å°æªå°æ±ºç­æä¾åççè§£éï¼ä¹ç¡æ³æ¨è«ç¾çé²å±çéæ®µãæ²¿èéåæ¹åï¼æåæåºäºä¸åæ°ç©çæ¨¡åä¸å¯ç¥è«å¯è§£é AI æ¶æ§ï¼ç¨±çºé¡ç²ç¥ç¶åç´å¥è§£éå¨ (LAVA)ï¼éæ¯ä¸åè§£éååï¼å¯ä»¥æ¢æ¸¬å·ç©ç¥ç¶ç¶²è·¯ (CNN) æ¨¡åçä¸­éå±¤ï¼ä»¥ç´æ¥å¾è¦ç¶²èå½±åè©ä¼° AD é£çºé«ï¼èç¡éç¸±åæè¨åºè©ä¼°ãæ­¤æ¹æ³ç¨æ¼é©è­è¦ç¶²èè¡ç®¡ä½çºçç©æ¨è¨åé¿è²æµ·é»ç (AD) è©ä¼°çè¨ºæ·æ¹å¼ãè±åçç©è³æåº«çèªç¥æ¸¬è©¦åè¡ç®¡å½¢æç¹å¾µè¡¨æï¼LAVA å¨è­å¥é²å±é£çºé«ä¸­ç AD éæ®µæ¹é¢é¡¯ç¤ºåºå¼·å¤§çåæ¯åæææ§ã

