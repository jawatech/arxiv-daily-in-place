{"2410.02763": {"publish_time": "2024-10-03", "title": "Vinoground: Scrutinizing LMMs over Dense Temporal Reasoning with Short Videos", "paper_summary": "There has been growing sentiment recently that modern large multimodal models\n(LMMs) have addressed most of the key challenges related to short video\ncomprehension. As a result, both academia and industry are gradually shifting\ntheir attention towards the more complex challenges posed by understanding\nlong-form videos. However, is this really the case? Our studies indicate that\nLMMs still lack many fundamental reasoning capabilities even when dealing with\nshort videos. We introduce Vinoground, a temporal counterfactual LMM evaluation\nbenchmark encompassing 1000 short and natural video-caption pairs. We\ndemonstrate that existing LMMs severely struggle to distinguish temporal\ndifferences between different actions and object transformations. For example,\nthe best model GPT-4o only obtains ~50% on our text and video scores, showing a\nlarge gap compared to the human baseline of ~90%. All open-source multimodal\nmodels and CLIP-based models perform much worse, producing mostly random chance\nperformance. Through this work, we shed light onto the fact that temporal\nreasoning in short videos is a problem yet to be fully solved. The dataset and\nevaluation code are available at https://vinoground.github.io.", "paper_summary_zh": "\u8fd1\u6765\u6709\u8d8a\u6765\u8d8a\u591a\u7684\u89c2\u70b9\u8ba4\u4e3a\uff0c\u73b0\u4ee3\u5927\u578b\u591a\u6a21\u6001\u6a21\u578b (LMM) \u5df2\u89e3\u51b3\u4e86\u4e0e\u77ed\u89c6\u9891\u7406\u89e3\u76f8\u5173\u7684\u5927\u90e8\u5206\u5173\u952e\u6311\u6218\u3002\u56e0\u6b64\uff0c\u5b66\u672f\u754c\u548c\u5de5\u4e1a\u754c\u6b63\u9010\u6e10\u5c06\u6ce8\u610f\u529b\u8f6c\u5411\u7406\u89e3\u957f\u683c\u5f0f\u89c6\u9891\u6240\u5e26\u6765\u7684\u66f4\u590d\u6742\u7684\u6311\u6218\u3002\u7136\u800c\uff0c\u4e8b\u5b9e\u771f\u7684\u5982\u6b64\u5417\uff1f\u6211\u4eec\u7684\u7814\u7a76\u8868\u660e\uff0c\u5373\u4f7f\u5728\u5904\u7406\u77ed\u89c6\u9891\u65f6\uff0cLMM \u4ecd\u7136\u7f3a\u4e4f\u8bb8\u591a\u57fa\u672c\u7684\u63a8\u7406\u80fd\u529b\u3002\u6211\u4eec\u5f15\u5165\u4e86 Vinoground\uff0c\u8fd9\u662f\u4e00\u4e2a\u65f6\u95f4\u53cd\u4e8b\u5b9e LMM \u8bc4\u4f30\u57fa\u51c6\uff0c\u5305\u542b 1000 \u4e2a\u77ed\u800c\u81ea\u7136\u7684\u89c6\u9891\u5b57\u5e55\u5bf9\u3002\u6211\u4eec\u8bc1\u660e\uff0c\u73b0\u6709\u7684 LMM \u5728\u533a\u5206\u4e0d\u540c\u52a8\u4f5c\u548c\u5bf9\u8c61\u8f6c\u6362\u4e4b\u95f4\u7684\u65f6\u95f4\u5dee\u5f02\u65f6\u9047\u5230\u4e86\u4e25\u91cd\u56f0\u96be\u3002\u4f8b\u5982\uff0c\u6700\u597d\u7684\u6a21\u578b GPT-4o \u5728\u6211\u4eec\u7684\u6587\u672c\u548c\u89c6\u9891\u5f97\u5206\u4e0a\u4ec5\u83b7\u5f97\u7ea6 50%\uff0c\u4e0e\u7ea6 90% \u7684\u4eba\u7c7b\u57fa\u51c6\u76f8\u6bd4\u5dee\u8ddd\u5f88\u5927\u3002\u6240\u6709\u5f00\u6e90\u591a\u6a21\u6001\u6a21\u578b\u548c\u57fa\u4e8e CLIP \u7684\u6a21\u578b\u8868\u73b0\u90fd\u66f4\u5dee\uff0c\u4ea7\u751f\u7684\u4e3b\u8981\u662f\u968f\u673a\u673a\u4f1a\u8868\u73b0\u3002\u901a\u8fc7\u8fd9\u9879\u5de5\u4f5c\uff0c\u6211\u4eec\u63ed\u793a\u4e86\u77ed\u89c6\u9891\u4e2d\u7684\u65f6\u95f4\u63a8\u7406\u662f\u4e00\u4e2a\u5c1a\u672a\u5b8c\u5168\u89e3\u51b3\u7684\u95ee\u9898\u3002\u6570\u636e\u96c6\u548c\u8bc4\u4f30\u4ee3\u7801\u53ef\u5728 https://vinoground.github.io/ \u83b7\u5f97\u3002", "author": "Jianrui Zhang et.al.", "authors": "Jianrui Zhang, Mu Cai, Yong Jae Lee", "id": "2410.02763v1", "paper_url": "http://arxiv.org/abs/2410.02763v1", "repo": "null"}}