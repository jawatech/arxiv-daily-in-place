
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-10-30**|**Provable acceleration for diffusion models under minimal assumptions**|Gen Li et.al.|[2410.23285v1](http://arxiv.org/abs/2410.23285v1)|null|
|**2024-10-30**|**A Neural Transformer Framework for Simultaneous Tasks of Segmentation, Classification, and Caller Identification of Marmoset Vocalization**|Bin Wu et.al.|[2410.23279v1](http://arxiv.org/abs/2410.23279v1)|null|
|**2024-10-30**|**SlowFast-VGen: Slow-Fast Learning for Action-Driven Long Video Generation**|Yining Hong et.al.|[2410.23277v1](http://arxiv.org/abs/2410.23277v1)|null|
|**2024-10-30**|**Multi-student Diffusion Distillation for Better One-step Generators**|Yanke Song et.al.|[2410.23274v1](http://arxiv.org/abs/2410.23274v1)|null|
|**2024-10-30**|**A Monte Carlo Framework for Calibrated Uncertainty Estimation in Sequence Prediction**|Qidong Yang et.al.|[2410.23272v1](http://arxiv.org/abs/2410.23272v1)|null|
|**2024-10-30**|**TOMATO: Assessing Visual Temporal Reasoning Capabilities in Multimodal Foundation Models**|Ziyao Shangguan et.al.|[2410.23266v1](http://arxiv.org/abs/2410.23266v1)|[link](https://github.com/yale-nlp/TOMATO)|
|**2024-10-30**|**EMMA: End-to-End Multimodal Model for Autonomous Driving**|Jyh-Jing Hwang et.al.|[2410.23262v1](http://arxiv.org/abs/2410.23262v1)|null|
|**2024-10-30**|**$100K or 100 Days: Trade-offs when Pre-Training with Academic Resources**|Apoorv Khandelwal et.al.|[2410.23261v1](http://arxiv.org/abs/2410.23261v1)|[link](https://github.com/apoorvkh/academic-pretraining)|
|**2024-10-30**|**Keypoint Abstraction using Large Models for Object-Relative Imitation Learning**|Xiaolin Fang et.al.|[2410.23254v1](http://arxiv.org/abs/2410.23254v1)|null|
|**2024-10-30**|**Evaluating Cultural and Social Awareness of LLM Web Agents**|Haoyi Qiu et.al.|[2410.23252v1](http://arxiv.org/abs/2410.23252v1)|null|
|**2024-10-30**|**A little less conversation, a little more action, please: Investigating the physical common-sense of LLMs in a 3D embodied environment**|Matteo G. Mecattaf et.al.|[2410.23242v1](http://arxiv.org/abs/2410.23242v1)|null|
|**2024-10-30**|**EMOTION: Expressive Motion Sequence Generation for Humanoid Robots with In-Context Learning**|Peide Huang et.al.|[2410.23234v1](http://arxiv.org/abs/2410.23234v1)|null|
|**2024-10-30**|**Aligning Audio-Visual Joint Representations with an Agentic Workflow**|Shentong Mo et.al.|[2410.23230v2](http://arxiv.org/abs/2410.23230v2)|null|
|**2024-10-30**|**COMAL: A Convergent Meta-Algorithm for Aligning LLMs with General Preferences**|Yixin Liu et.al.|[2410.23223v1](http://arxiv.org/abs/2410.23223v1)|[link](https://github.com/yale-nlp/comal)|
|**2024-10-30**|**Partial Channel Dependence with Channel Masks for Time Series Foundation Models**|Seunghan Lee et.al.|[2410.23222v1](http://arxiv.org/abs/2410.23222v1)|null|
|**2024-10-30**|**OS-ATLAS: A Foundation Action Model for Generalist GUI Agents**|Zhiyong Wu et.al.|[2410.23218v1](http://arxiv.org/abs/2410.23218v1)|null|
|**2024-10-30**|**Grounding by Trying: LLMs with Reinforcement Learning-Enhanced Retrieval**|Sheryl Hsu et.al.|[2410.23214v2](http://arxiv.org/abs/2410.23214v2)|null|
|**2024-10-30**|**Kinetix: Investigating the Training of General Agents through Open-Ended Physics-Based Control Tasks**|Michael Matthews et.al.|[2410.23208v1](http://arxiv.org/abs/2410.23208v1)|null|
|**2024-10-30**|**Reliability of Topic Modeling**|Kayla Schroeder et.al.|[2410.23186v1](http://arxiv.org/abs/2410.23186v1)|null|
|**2024-10-30**|**ProTransformer: Robustify Transformers via Plug-and-Play Paradigm**|Zhichao Hou et.al.|[2410.23182v1](http://arxiv.org/abs/2410.23182v1)|null|
|**2024-10-30**|**ReasoningRec: Bridging Personalized Recommendations and Human-Interpretable Explanations through LLM Reasoning**|Millennium Bismay et.al.|[2410.23180v1](http://arxiv.org/abs/2410.23180v1)|[link](https://github.com/millenniumbismay/reasoningrec)|
|**2024-10-30**|**SciPIP: An LLM-based Scientific Paper Idea Proposer**|Wenxiao Wang et.al.|[2410.23166v1](http://arxiv.org/abs/2410.23166v1)|null|
|**2024-10-30**|**FlexTSF: A Universal Forecasting Model for Time Series with Variable Regularities**|Jingge Xiao et.al.|[2410.23160v1](http://arxiv.org/abs/2410.23160v1)|null|
|**2024-10-30**|**Fourier Amplitude and Correlation Loss: Beyond Using L2 Loss for Skillful Precipitation Nowcasting**|Chiu-Wai Yan et.al.|[2410.23159v1](http://arxiv.org/abs/2410.23159v1)|[link](https://github.com/argenycw/facl)|
|**2024-10-30**|**VisualPredicator: Learning Abstract World Models with Neuro-Symbolic Predicates for Robot Planning**|Yichao Liang et.al.|[2410.23156v1](http://arxiv.org/abs/2410.23156v1)|null|
|**2024-10-30**|**Public Domain 12M: A Highly Aesthetic Image-Text Dataset with Novel Governance Mechanisms**|Jordan Meyer et.al.|[2410.23144v1](http://arxiv.org/abs/2410.23144v1)|null|
|**2024-10-30**|**Fair Division with Market Values**|Siddharth Barman et.al.|[2410.23137v1](http://arxiv.org/abs/2410.23137v1)|null|
|**2024-10-30**|**Crowdsourcing Lexical Diversity**|Hadi Khalilia et.al.|[2410.23133v1](http://arxiv.org/abs/2410.23133v1)|null|
|**2024-10-30**|**Revisiting MAE pre-training for 3D medical image segmentation**|Tassilo Wald et.al.|[2410.23132v1](http://arxiv.org/abs/2410.23132v1)|null|
|**2024-10-30**|**Provably Optimal Memory Capacity for Modern Hopfield Models: Transformer-Compatible Dense Associative Memories as Spherical Codes**|Jerry Yao-Chieh Hu et.al.|[2410.23126v1](http://arxiv.org/abs/2410.23126v1)|null|
|**2024-10-30**|**On Memorization of Large Language Models in Logical Reasoning**|Chulin Xie et.al.|[2410.23123v1](http://arxiv.org/abs/2410.23123v1)|null|
|**2024-10-30**|**Teaching a Language Model to Distinguish Between Similar Details using a Small Adversarial Training Set**|Chris Achard et.al.|[2410.23118v1](http://arxiv.org/abs/2410.23118v1)|null|
|**2024-10-30**|**Unified Triplet-Level Hallucination Evaluation for Large Vision-Language Models**|Junjie Wu et.al.|[2410.23114v1](http://arxiv.org/abs/2410.23114v1)|[link](https://github.com/wujunjie1998/tri-he)|
|**2024-10-30**|**Why Gradient Subspace? Identifying and Mitigating LoRA's Bottlenecks in Federated Fine-Tuning of Large Language Models**|Navyansh Mahla et.al.|[2410.23111v2](http://arxiv.org/abs/2410.23111v2)|null|
|**2024-10-30**|**Controllable Game Level Generation: Assessing the Effect of Negative Examples in GAN Models**|Mahsa Bazzaz et.al.|[2410.23108v1](http://arxiv.org/abs/2410.23108v1)|null|
|**2024-10-30**|**Guided Game Level Repair via Explainable AI**|Mahsa Bazzaz et.al.|[2410.23101v1](http://arxiv.org/abs/2410.23101v1)|null|
|**2024-10-30**|**Comparative Analysis of Demonstration Selection Algorithms for LLM In-Context Learning**|Dong Shu et.al.|[2410.23099v1](http://arxiv.org/abs/2410.23099v1)|[link](https://github.com/tizzzzy/demonstration_selection_overview)|
|**2024-10-30**|**CORAL: Benchmarking Multi-turn Conversational Retrieval-Augmentation Generation**|Yiruo Cheng et.al.|[2410.23090v1](http://arxiv.org/abs/2410.23090v1)|null|
|**2024-10-30**|**BUZZ: Beehive-structured Sparse KV Cache with Segmented Heavy Hitters for Efficient LLM Inference**|Junqi Zhao et.al.|[2410.23079v1](http://arxiv.org/abs/2410.23079v1)|[link](https://github.com/junqizhao888/buzz-llm)|
|**2024-10-30**|**Multi-Programming Language Sandbox for LLMs**|Shihan Dou et.al.|[2410.23074v1](http://arxiv.org/abs/2410.23074v1)|null|
|**2024-10-30**|**CNN Explainability with Multivector Tucker Saliency Maps for Self-Supervised Models**|Aymene Mohammed Bouayed et.al.|[2410.23072v1](http://arxiv.org/abs/2410.23072v1)|null|
|**2024-10-30**|**LLMs Integration in Software Engineering Team Projects: Roles, Impact, and a Pedagogical Design Space for AI Tools in Computing Education**|Ahmed Kharrufa et.al.|[2410.23069v1](http://arxiv.org/abs/2410.23069v1)|null|
|**2024-10-30**|**Don't Just Pay Attention, PLANT It: Transfer L2R Models to Fine-tune Attention in Extreme Multi-Label Text Classification**|Debjyoti Saharoy et.al.|[2410.23066v1](http://arxiv.org/abs/2410.23066v1)|null|
|**2024-10-30**|**Controlling Language and Diffusion Models by Transporting Activations**|Pau Rodriguez et.al.|[2410.23054v1](http://arxiv.org/abs/2410.23054v1)|null|
|**2024-10-30**|**Emotional RAG: Enhancing Role-Playing Agents through Emotional Retrieval**|Le Huang et.al.|[2410.23041v1](http://arxiv.org/abs/2410.23041v1)|null|
|**2024-10-30**|**Offline Reinforcement Learning and Sequence Modeling for Downlink Link Adaptation**|Samuele Peri et.al.|[2410.23031v1](http://arxiv.org/abs/2410.23031v1)|null|
|**2024-10-30**|**Online Intrinsic Rewards for Decision Making Agents from Large Language Model Feedback**|Qinqing Zheng et.al.|[2410.23022v1](http://arxiv.org/abs/2410.23022v1)|null|
|**2024-10-30**|**Long$^2$RAG: Evaluating Long-Context & Long-Form Retrieval-Augmented Generation with Key Point Recall**|Zehan Qi et.al.|[2410.23000v2](http://arxiv.org/abs/2410.23000v2)|null|
|**2024-10-30**|**A Comparison of Prompt Engineering Techniques for Task Planning and Execution in Service Robotics**|Jonas Bode et.al.|[2410.22997v1](http://arxiv.org/abs/2410.22997v1)|[link](https://github.com/ais-bonn/prompt_engineering)|
|**2024-10-30**|**Semantic Enrichment of the Quantum Cascade Laser Properties in Text- A Knowledge Graph Generation Approach**|Deperias Kerre et.al.|[2410.22996v1](http://arxiv.org/abs/2410.22996v1)|null|
|**2024-10-30**|**VisAidMath: Benchmarking Visual-Aided Mathematical Reasoning**|Jingkun Ma et.al.|[2410.22995v1](http://arxiv.org/abs/2410.22995v1)|null|
|**2024-10-30**|**Higher-order Cross-structural Embedding Model for Time Series Analysis**|Guancen Lin et.al.|[2410.22984v1](http://arxiv.org/abs/2410.22984v1)|null|
|**2024-10-30**|**Bonafide at LegalLens 2024 Shared Task: Using Lightweight DeBERTa Based Encoder For Legal Violation Detection and Resolution**|Shikha Bordia et.al.|[2410.22977v1](http://arxiv.org/abs/2410.22977v1)|null|
|**2024-10-30**|**Private Synthetic Text Generation with Diffusion Models**|Sebastian Ochs et.al.|[2410.22971v1](http://arxiv.org/abs/2410.22971v1)|null|
|**2024-10-30**|**Efficient Adaptation of Pre-trained Vision Transformer via Householder Transformation**|Wei Dong et.al.|[2410.22952v1](http://arxiv.org/abs/2410.22952v1)|null|
|**2024-10-30**|**SpiroActive: Active Learning for Efficient Data Acquisition for Spirometry**|Ankita Kumari Jain et.al.|[2410.22950v1](http://arxiv.org/abs/2410.22950v1)|null|
|**2024-10-30**|**Focus On This, Not That! Steering LLMs With Adaptive Feature Specification**|Tom A. Lamb et.al.|[2410.22944v1](http://arxiv.org/abs/2410.22944v1)|null|
|**2024-10-30**|**DiffLight: A Partial Rewards Conditioned Diffusion Model for Traffic Signal Control with Missing Data**|Hanyang Chen et.al.|[2410.22938v2](http://arxiv.org/abs/2410.22938v2)|[link](https://github.com/lokol5579/DiffLight-release)|
|**2024-10-30**|**Thoughtful Adoption of NLP for Civic Participation: Understanding Differences Among Policymakers**|Jose A. Guridi et.al.|[2410.22937v1](http://arxiv.org/abs/2410.22937v1)|null|
|**2024-10-30**|**Multi-Agent Large Language Models for Conversational Task-Solving**|Jonas Becker et.al.|[2410.22932v1](http://arxiv.org/abs/2410.22932v1)|null|
|**2024-10-30**|**BIS: NL2SQL Service Evaluation Benchmark for Business Intelligence Scenarios**|Bora Caglayan et.al.|[2410.22925v1](http://arxiv.org/abs/2410.22925v1)|[link](https://github.com/boracaglayan/bis-nl2sql)|
|**2024-10-30**|**Explainable Behavior Cloning: Teaching Large Language Model Agents through Learning by Demonstration**|Yanchu Guan et.al.|[2410.22916v1](http://arxiv.org/abs/2410.22916v1)|null|
|**2024-10-30**|**From Babble to Words: Pre-Training Language Models on Continuous Streams of Phonemes**|Zébulon Goriely et.al.|[2410.22906v1](http://arxiv.org/abs/2410.22906v1)|null|
|**2024-10-30**|**YOLOv11 for Vehicle Detection: Advancements, Performance, and Applications in Intelligent Transportation Systems**|Mujadded Al Rabbani Alif et.al.|[2410.22898v1](http://arxiv.org/abs/2410.22898v1)|null|
|**2024-10-30**|**VPO: Leveraging the Number of Votes in Preference Optimization**|Jae Hyeon Cho et.al.|[2410.22891v1](http://arxiv.org/abs/2410.22891v1)|[link](https://github.com/ku-dmlab/vpo)|
|**2024-10-30**|**Effective and Efficient Adversarial Detection for Vision-Language Models via A Single Vector**|Youcheng Huang et.al.|[2410.22888v1](http://arxiv.org/abs/2410.22888v1)|[link](https://github.com/mob-scu/radar-nearside)|
|**2024-10-30**|**Less is More: Pre-Training Cross-Lingual Small-Scale Language Models with Cognitively-Plausible Curriculum Learning Strategies**|Suchir Salhan et.al.|[2410.22886v1](http://arxiv.org/abs/2410.22886v1)|[link](https://github.com/suchirsalhan/mao-climb)|
|**2024-10-30**|**Stealing User Prompts from Mixture of Experts**|Itay Yona et.al.|[2410.22884v1](http://arxiv.org/abs/2410.22884v1)|null|
|**2024-10-30**|**Adaptive Paradigm Synergy: Can a Cross-Paradigm Objective Enhance Long-Tailed Learning?**|Haowen Xiao et.al.|[2410.22883v1](http://arxiv.org/abs/2410.22883v1)|null|
|**2024-10-30**|**SFA-UNet: More Attention to Multi-Scale Contrast and Contextual Information in Infrared Small Object Segmentation**|Imad Ali Shah et.al.|[2410.22881v1](http://arxiv.org/abs/2410.22881v1)|[link](https://github.com/imadalishah/sfa_unet)|
|**2024-10-30**|**Eliciting Critical Reasoning in Retrieval-Augmented Language Models via Contrastive Explanations**|Leonardo Ranaldi et.al.|[2410.22874v1](http://arxiv.org/abs/2410.22874v1)|null|
|**2024-10-30**|**Conditioned quantum-assisted deep generative surrogate for particle-calorimeter interactions**|J. Quetzalcoatl Toledo-Marin et.al.|[2410.22870v1](http://arxiv.org/abs/2410.22870v1)|null|
|**2024-10-30**|**Danoliteracy of Generative, Large Language Models**|Søren Vejlgaard Holm et.al.|[2410.22839v1](http://arxiv.org/abs/2410.22839v1)|null|
|**2024-10-30**|**HijackRAG: Hijacking Attacks against Retrieval-Augmented Large Language Models**|Yucheng Zhang et.al.|[2410.22832v1](http://arxiv.org/abs/2410.22832v1)|null|
|**2024-10-30**|**How Well Do Large Language Models Disambiguate Swedish Words?**|Richard Johansson et.al.|[2410.22827v1](http://arxiv.org/abs/2410.22827v1)|null|
|**2024-10-30**|**EvoCodeBench: An Evolving Code Generation Benchmark with Domain-Specific Evaluations**|Jia Li et.al.|[2410.22821v1](http://arxiv.org/abs/2410.22821v1)|null|
|**2024-10-30**|**Towards Robust and Efficient Federated Low-Rank Adaptation with Heterogeneous Clients**|Jabin Koo et.al.|[2410.22815v1](http://arxiv.org/abs/2410.22815v1)|null|
|**2024-10-30**|**Universality of the $π^2/6$ Pathway in Avoiding Model Collapse**|Apratim Dey et.al.|[2410.22812v1](http://arxiv.org/abs/2410.22812v1)|null|
|**2024-10-30**|**Causality-Enhanced Behavior Sequence Modeling in LLMs for Personalized Recommendation**|Yang Zhang et.al.|[2410.22809v1](http://arxiv.org/abs/2410.22809v1)|[link](https://github.com/itsmeyjt/cft)|
|**2024-10-30**|**Dual Contrastive Transformer for Hierarchical Preference Modeling in Sequential Recommendation**|Chengkai Huang et.al.|[2410.22790v1](http://arxiv.org/abs/2410.22790v1)|null|
|**2024-10-30**|**MALoRA: Mixture of Asymmetric Low-Rank Adaptation for Enhanced Multi-Task Learning**|Xujia Wang et.al.|[2410.22782v1](http://arxiv.org/abs/2410.22782v1)|null|
|**2024-10-30**|**InjecGuard: Benchmarking and Mitigating Over-defense in Prompt Injection Guardrail Models**|Hao Li et.al.|[2410.22770v1](http://arxiv.org/abs/2410.22770v1)|[link](https://github.com/safolab-wisc/injecguard)|
|**2024-10-30**|**Beyond Ontology in Dialogue State Tracking for Goal-Oriented Chatbot**|Sejin Lee et.al.|[2410.22767v1](http://arxiv.org/abs/2410.22767v1)|[link](https://github.com/eastha0526/beyond-ontology-in-dst)|
|**2024-10-30**|**Self-Driving Car Racing: Application of Deep Reinforcement Learning**|Florentiana Yuwono et.al.|[2410.22766v1](http://arxiv.org/abs/2410.22766v1)|null|
|**2024-10-30**|**Constructing Multimodal Datasets from Scratch for Rapid Development of a Japanese Visual Language Model**|Keito Sasagawa et.al.|[2410.22736v1](http://arxiv.org/abs/2410.22736v1)|null|
|**2024-10-30**|**st-DTPM: Spatial-Temporal Guided Diffusion Transformer Probabilistic Model for Delayed Scan PET Image Prediction**|Ran Hong et.al.|[2410.22732v1](http://arxiv.org/abs/2410.22732v1)|null|
|**2024-10-30**|**Robotic State Recognition with Image-to-Text Retrieval Task of Pre-Trained Vision-Language Model and Black-Box Optimization**|Kento Kawaharazuka et.al.|[2410.22707v1](http://arxiv.org/abs/2410.22707v1)|null|
|**2024-10-30**|**Permutation Invariant Learning with High-Dimensional Particle Filters**|Akhilan Boopathy et.al.|[2410.22695v1](http://arxiv.org/abs/2410.22695v1)|null|
|**2024-10-30**|**Choice between Partial Trajectories**|Henrik Marklund et.al.|[2410.22690v1](http://arxiv.org/abs/2410.22690v1)|null|
|**2024-10-30**|**Multi-Task Interactive Robot Fleet Learning with Visual World Models**|Huihan Liu et.al.|[2410.22689v1](http://arxiv.org/abs/2410.22689v1)|null|
|**2024-10-30**|**Improving Uncertainty Quantification in Large Language Models via Semantic Embeddings**|Yashvir S. Grewal et.al.|[2410.22685v1](http://arxiv.org/abs/2410.22685v1)|null|
|**2024-10-30**|**Backdoor Attack Against Vision Transformers via Attention Gradient-Based Image Erosion**|Ji Guo et.al.|[2410.22678v1](http://arxiv.org/abs/2410.22678v1)|null|
|**2024-10-30**|**Automated Trustworthiness Oracle Generation for Machine Learning Text Classifiers**|Lam Nguyen Tung et.al.|[2410.22663v1](http://arxiv.org/abs/2410.22663v1)|null|
|**2024-10-30**|**$\textbf{EMOS}$: $\textbf{E}$mbodiment-aware Heterogeneous $\textbf{M}$ulti-robot $\textbf{O}$perating $\textbf{S}$ystem with LLM Agents**|Junting Chen et.al.|[2410.22662v1](http://arxiv.org/abs/2410.22662v1)|null|
|**2024-10-30**|**Linguistics Theory Meets LLM: Code-Switched Text Generation via Equivalence Constrained Large Language Models**|Garry Kuwanto et.al.|[2410.22660v1](http://arxiv.org/abs/2410.22660v1)|null|
|**2024-10-30**|**Incremental Learning of Retrievable Skills For Efficient Continual Task Adaptation**|Daehee Lee et.al.|[2410.22658v1](http://arxiv.org/abs/2410.22658v1)|null|
|**2024-10-30**|**Prove Your Point!: Bringing Proof-Enhancement Principles to Argumentative Essay Generation**|Ruiyu Xiao et.al.|[2410.22642v1](http://arxiv.org/abs/2410.22642v1)|null|
|**2024-10-30**|**Efficient Feature Extraction and Classification Architecture for MRI-Based Brain Tumor Detection**|Plabon Paul et.al.|[2410.22619v1](http://arxiv.org/abs/2410.22619v1)|null|
|**2024-10-30**|**CoGS: Model Agnostic Causality Constrained Counterfactual Explanations using goal-directed ASP**|Sopam Dasgupta et.al.|[2410.22615v1](http://arxiv.org/abs/2410.22615v1)|null|
|**2024-10-29**|**Are Large-Language Models Graph Algorithmic Reasoners?**|Alexander K Taylor et.al.|[2410.22597v1](http://arxiv.org/abs/2410.22597v1)|null|

#### Abstracts
##### **Provable acceleration for diffusion models under minimal assumptions**
2410.23285v1 by Gen Li, Changxiao Cai

While score-based diffusion models have achieved exceptional sampling
quality, their sampling speeds are often limited by the high computational
burden of score function evaluations. Despite the recent remarkable empirical
advances in speeding up the score-based samplers, theoretical understanding of
acceleration techniques remains largely limited. To bridge this gap, we propose
a novel training-free acceleration scheme for stochastic samplers. Under
minimal assumptions -- namely, $L^2$-accurate score estimates and a finite
second-moment condition on the target distribution -- our accelerated sampler
provably achieves $\varepsilon$-accuracy in total variation within
$\widetilde{O}(d^{5/4}/\sqrt{\varepsilon})$ iterations, thereby significantly
improving upon the $\widetilde{O}(d/\varepsilon)$ iteration complexity of
standard score-based samplers. Notably, our convergence theory does not rely on
restrictive assumptions on the target distribution or higher-order score
estimation guarantees.

摘要：儘管基於分數的擴散模型已達到優異的取樣品質，但其取樣速度往往受到分數函數評估的高運算負擔所限制。儘管近期在加速基於分數的取樣器方面有顯著的經驗進展，但對加速技術的理論理解在很大程度上仍然有限。為了彌補這個差距，我們提出了一種新穎的免訓練加速方案，用於隨機取樣器。在最小的假設下——即 $L^2$ 精確分數估計和目標分佈上的有限二階矩條件——我們的加速取樣器可證明在總變異中達到 $\varepsilon$ 精確度，在 $\widetilde{O}(d^{5/4}/\sqrt{\varepsilon})$ 迭代次數內，從而顯著改善標準基於分數的取樣器的 $\widetilde{O}(d/\varepsilon)$ 迭代複雜度。值得注意的是，我們的收斂理論不依賴於目標分佈或高階分數估計保證的限制性假設。

##### **A Neural Transformer Framework for Simultaneous Tasks of Segmentation, Classification, and Caller Identification of Marmoset Vocalization**
2410.23279v1 by Bin Wu, Sakriani Sakti, Shinnosuke Takamichi, Satoshi Nakamura

Marmoset, a highly vocalized primate, has become a popular animal model for
studying social-communicative behavior and its underlying mechanism. In the
study of vocal communication, it is vital to know the caller identities, call
contents, and vocal exchanges. Previous work of a CNN has achieved a joint
model for call segmentation, classification, and caller identification for
marmoset vocalizations. However, the CNN has limitations in modeling long-range
acoustic patterns; the Transformer architecture that has been shown to
outperform CNNs, utilizes the self-attention mechanism that efficiently
segregates information parallelly over long distances and captures the global
structure of marmoset vocalization. We propose using the Transformer to jointly
segment and classify the marmoset calls and identify the callers for each
vocalization.

摘要：狨猴是一种非常善于发声的灵长类动物，已成为研究社会交流行为及其潜在机制的流行动物模型。在语音交流的研究中，了解呼叫者的身份、呼叫内容和语音交流至关重要。先前关于 CNN 的研究已针对狨猴发声实现了呼叫分割、分类和呼叫者识别的联合模型。然而，CNN 在建模远程声学模式方面存在局限性；已证明优于 CNN 的 Transformer 架构利用自注意力机制，该机制有效地将信息并行隔离在远距离上，并捕获狨猴发声的全局结构。我们建议使用 Transformer 来联合分割和分类狨猴呼叫，并识别每个发声的呼叫者。

##### **SlowFast-VGen: Slow-Fast Learning for Action-Driven Long Video Generation**
2410.23277v1 by Yining Hong, Beide Liu, Maxine Wu, Yuanhao Zhai, Kai-Wei Chang, Lingjie Li, Kevin Lin, Chung-Ching Lin, Jianfeng Wang, Zhengyuan Yang, Yingnian Wu, Lijuan Wang

Human beings are endowed with a complementary learning system, which bridges
the slow learning of general world dynamics with fast storage of episodic
memory from a new experience. Previous video generation models, however,
primarily focus on slow learning by pre-training on vast amounts of data,
overlooking the fast learning phase crucial for episodic memory storage. This
oversight leads to inconsistencies across temporally distant frames when
generating longer videos, as these frames fall beyond the model's context
window. To this end, we introduce SlowFast-VGen, a novel dual-speed learning
system for action-driven long video generation. Our approach incorporates a
masked conditional video diffusion model for the slow learning of world
dynamics, alongside an inference-time fast learning strategy based on a
temporal LoRA module. Specifically, the fast learning process updates its
temporal LoRA parameters based on local inputs and outputs, thereby efficiently
storing episodic memory in its parameters. We further propose a slow-fast
learning loop algorithm that seamlessly integrates the inner fast learning loop
into the outer slow learning loop, enabling the recall of prior multi-episode
experiences for context-aware skill learning. To facilitate the slow learning
of an approximate world model, we collect a large-scale dataset of 200k videos
with language action annotations, covering a wide range of scenarios. Extensive
experiments show that SlowFast-VGen outperforms baselines across various
metrics for action-driven video generation, achieving an FVD score of 514
compared to 782, and maintaining consistency in longer videos, with an average
of 0.37 scene cuts versus 0.89. The slow-fast learning loop algorithm
significantly enhances performances on long-horizon planning tasks as well.
Project Website: https://slowfast-vgen.github.io

摘要：<paragraph>人類被賦予一個互補的學習系統，它將一般世界動態的緩慢學習與來自新經驗的快速情節記憶儲存聯繫起來。然而，先前的影片生成模型主要透過大量資料的預先訓練來專注於緩慢學習，忽視了對情節記憶儲存至關重要的快速學習階段。這種疏忽導致在生成較長影片時，時間上相距甚遠的影格之間出現不一致，因為這些影格超出了模型的上下文視窗。為此，我們引入了 SlowFast-VGen，這是一個用於動作驅動的長影片生成的新型雙速學習系統。我們的做法結合了一個用於世界動態緩慢學習的遮罩條件影片擴散模型，以及一個基於時間 LoRA 模組的推論時間快速學習策略。具體來說，快速學習過程根據局部輸入和輸出更新其時間 LoRA 參數，從而有效地將情節記憶儲存在其參數中。我們進一步提出了一個緩慢-快速學習迴圈演算法，它將內部的快速學習迴圈無縫整合到外部的緩慢學習迴圈中，使能夠回想起先前的多情節經驗以進行情境感知技能學習。為了促進近似世界模型的緩慢學習，我們收集了一個包含 200k 個影片的大規模資料集，其中包含語言動作註解，涵蓋了廣泛的場景。大量的實驗表明，SlowFast-VGen 在動作驅動影片生成的各種指標上優於基準，與 782 相比，FVD 得分達到 514，並且在較長的影片中保持一致性，平均場景切換為 0.37，而 0.89。緩慢-快速學習迴圈演算法也顯著提升了長期規劃任務的效能。專案網站：https://slowfast-vgen.github.io</paragraph>

##### **Multi-student Diffusion Distillation for Better One-step Generators**
2410.23274v1 by Yanke Song, Jonathan Lorraine, Weili Nie, Karsten Kreis, James Lucas

Diffusion models achieve high-quality sample generation at the cost of a
lengthy multistep inference procedure. To overcome this, diffusion distillation
techniques produce student generators capable of matching or surpassing the
teacher in a single step. However, the student model's inference speed is
limited by the size of the teacher architecture, preventing real-time
generation for computationally heavy applications. In this work, we introduce
Multi-Student Distillation (MSD), a framework to distill a conditional teacher
diffusion model into multiple single-step generators. Each student generator is
responsible for a subset of the conditioning data, thereby obtaining higher
generation quality for the same capacity. MSD trains multiple distilled
students, allowing smaller sizes and, therefore, faster inference. Also, MSD
offers a lightweight quality boost over single-student distillation with the
same architecture. We demonstrate MSD is effective by training multiple
same-sized or smaller students on single-step distillation using distribution
matching and adversarial distillation techniques. With smaller students, MSD
gets competitive results with faster inference for single-step generation.
Using 4 same-sized students, MSD sets a new state-of-the-art for one-step image
generation: FID 1.20 on ImageNet-64x64 and 8.20 on zero-shot COCO2014.

摘要：擴散模型以冗長的步驟推論程序為代價，達成高品質的樣本產生。為了克服這一點，擴散蒸餾技術產生學生產生器，能夠在單一步驟中匹配或超越教師。然而，學生模型的推論速度受到教師架構大小的限制，防止計算密集型應用程式進行即時產生。在這項工作中，我們介紹多學生蒸餾 (MSD)，一個將條件教師擴散模型蒸餾成多個單步驟產生器的架構。每個學生產生器負責條件資料的子集，因此獲得相同容量的較高產生品質。MSD 訓練多個蒸餾學生，允許較小的尺寸，因此推論更快。此外，MSD 在具有相同架構的單學生蒸餾上提供輕量級的品質提升。我們示範 MSD 透過使用分佈匹配和對抗蒸餾技術，在單步驟蒸餾上訓練多個相同大小或較小的學生，是有效的。對於較小的學生，MSD 在單步驟產生中以更快的推論獲得競爭結果。使用 4 個相同大小的學生，MSD 為單步驟影像產生設定了新的技術水準：ImageNet-64x64 上的 FID 為 1.20，零次 COCO2014 上的 FID 為 8.20。

##### **A Monte Carlo Framework for Calibrated Uncertainty Estimation in Sequence Prediction**
2410.23272v1 by Qidong Yang, Weicheng Zhu, Joseph Keslin, Laure Zanna, Tim G. J. Rudner, Carlos Fernandez-Granda

Probabilistic prediction of sequences from images and other high-dimensional
data is a key challenge, particularly in risk-sensitive applications. In these
settings, it is often desirable to quantify the uncertainty associated with the
prediction (instead of just determining the most likely sequence, as in
language modeling). In this paper, we propose a Monte Carlo framework to
estimate probabilities and confidence intervals associated with the
distribution of a discrete sequence. Our framework uses a Monte Carlo
simulator, implemented as an autoregressively trained neural network, to sample
sequences conditioned on an image input. We then use these samples to estimate
the probabilities and confidence intervals. Experiments on synthetic and real
data show that the framework produces accurate discriminative predictions, but
can suffer from miscalibration. In order to address this shortcoming, we
propose a time-dependent regularization method, which is shown to produce
calibrated predictions.

摘要：從影像和其他高維度資料中，機率性地預測序列是一個關鍵挑戰，特別是在風險敏感的應用程式中。在這些設定中，通常需要量化與預測相關的不確定性（而不是像在語言模型中，只決定最可能的序列）。在本文中，我們提出一個蒙地卡羅架構，以估計與離散序列分佈相關的機率和信心區間。我們的架構使用蒙地卡羅模擬器，實作為一個自迴歸訓練的神經網路，以根據影像輸入取樣序列。然後我們使用這些樣本來估計機率和信心區間。在合成和真實資料上的實驗顯示，這個架構產生了準確的判別預測，但可能會出現校準不良。為了解決這個缺點，我們提出一個時間相關的正則化方法，已被證明可以產生校準的預測。

##### **TOMATO: Assessing Visual Temporal Reasoning Capabilities in Multimodal Foundation Models**
2410.23266v1 by Ziyao Shangguan, Chuhan Li, Yuxuan Ding, Yanan Zheng, Yilun Zhao, Tesca Fitzgerald, Arman Cohan

Existing benchmarks often highlight the remarkable performance achieved by
state-of-the-art Multimodal Foundation Models (MFMs) in leveraging temporal
context for video understanding. However, how well do the models truly perform
visual temporal reasoning? Our study of existing benchmarks shows that this
capability of MFMs is likely overestimated as many questions can be solved by
using a single, few, or out-of-order frames. To systematically examine current
visual temporal reasoning tasks, we propose three principles with corresponding
metrics: (1) Multi-Frame Gain, (2) Frame Order Sensitivity, and (3) Frame
Information Disparity. Following these principles, we introduce TOMATO,
Temporal Reasoning Multimodal Evaluation, a novel benchmark crafted to
rigorously assess MFMs' temporal reasoning capabilities in video understanding.
TOMATO comprises 1,484 carefully curated, human-annotated questions spanning
six tasks (i.e., action count, direction, rotation, shape & trend, velocity &
frequency, and visual cues), applied to 1,417 videos, including 805
self-recorded and -generated videos, that encompass human-centric, real-world,
and simulated scenarios. Our comprehensive evaluation reveals a human-model
performance gap of 57.3% with the best-performing model. Moreover, our in-depth
analysis uncovers more fundamental limitations beyond this gap in current MFMs.
While they can accurately recognize events in isolated frames, they fail to
interpret these frames as a continuous sequence. We believe TOMATO will serve
as a crucial testbed for evaluating the next-generation MFMs and as a call to
the community to develop AI systems capable of comprehending human world
dynamics through the video modality.

摘要：現有的基準測試經常強調最先進的多模態基礎模型 (MFM) 在利用時間脈絡進行影片理解時所達成的顯著效能。然而，這些模型在視覺時間推理方面的表現究竟如何？我們對現有基準測試的研究顯示，由於許多問題可以用單一、少數或非順序的影格來解決，因此 MFM 的這種能力可能被高估了。為了系統性地檢視目前的視覺時間推理任務，我們提出了三項原則，並有對應的指標：(1) 多影格增益、(2) 影格順序敏感度，以及 (3) 影格資訊差異。遵循這些原則，我們引入了 TOMATO，即時間推理多模態評估，這是一個新穎的基準測試，旨在嚴格評估 MFM 在影片理解中的時間推理能力。TOMATO 包含 1,484 個經過仔細策劃、人工標註的問題，涵蓋六項任務（即動作計數、方向、旋轉、形狀和趨勢、速度和頻率，以及視覺提示），並應用於 1,417 個影片，其中包括 805 個自錄和自製的影片，涵蓋以人為中心、真實世界和模擬的場景。我們的全面評估顯示，表現最佳的模型與人類的效能差距為 57.3%。此外，我們深入的分析揭露了超越此差距的更根本限制，在現有的 MFM 中。雖然它們可以準確識別孤立影格中的事件，但它們無法將這些影格解釋為一個連續的序列。我們相信 TOMATO 將成為評估下一代 MFM 的關鍵測試平台，並呼籲社群開發能夠透過影片模式理解人類世界動態的人工智慧系統。

##### **EMMA: End-to-End Multimodal Model for Autonomous Driving**
2410.23262v1 by Jyh-Jing Hwang, Runsheng Xu, Hubert Lin, Wei-Chih Hung, Jingwei Ji, Kristy Choi, Di Huang, Tong He, Paul Covington, Benjamin Sapp, James Guo, Dragomir Anguelov, Mingxing Tan

We introduce EMMA, an End-to-end Multimodal Model for Autonomous driving.
Built on a multi-modal large language model foundation, EMMA directly maps raw
camera sensor data into various driving-specific outputs, including planner
trajectories, perception objects, and road graph elements. EMMA maximizes the
utility of world knowledge from the pre-trained large language models, by
representing all non-sensor inputs (e.g. navigation instructions and ego
vehicle status) and outputs (e.g. trajectories and 3D locations) as natural
language text. This approach allows EMMA to jointly process various driving
tasks in a unified language space, and generate the outputs for each task using
task-specific prompts. Empirically, we demonstrate EMMA's effectiveness by
achieving state-of-the-art performance in motion planning on nuScenes as well
as competitive results on the Waymo Open Motion Dataset (WOMD). EMMA also
yields competitive results for camera-primary 3D object detection on the Waymo
Open Dataset (WOD). We show that co-training EMMA with planner trajectories,
object detection, and road graph tasks yields improvements across all three
domains, highlighting EMMA's potential as a generalist model for autonomous
driving applications. However, EMMA also exhibits certain limitations: it can
process only a small amount of image frames, does not incorporate accurate 3D
sensing modalities like LiDAR or radar and is computationally expensive. We
hope that our results will inspire further research to mitigate these issues
and to further evolve the state of the art in autonomous driving model
architectures.

摘要：<paragraph>我們介紹 EMMA，一種用於自動駕駛的端到端多模態模型。
建立在多模態大型語言模型基礎上，EMMA 直接將原始
相機感測器資料對應到各種特定於駕駛的輸出，包括規劃器
軌跡、感知物件和道路圖形元素。EMMA 透過
將所有非感測器輸入（例如導航指示和自我
車輛狀態）和輸出（例如軌跡和 3D 位置）表示為自然
語言文字，最大化預訓練大型語言模型的世界知識效用。這種方法讓 EMMA 能夠在統一的語言空間中共同處理各種駕駛
任務，並使用特定於任務的提示產生每個任務的輸出。根據經驗，我們透過
在 nuScenes 上實現運動規劃的最新效能，以及在 Waymo Open Motion Dataset (WOMD) 上獲得競爭力結果，來證明 EMMA 的有效性。EMMA 也
在 Waymo Open Dataset (WOD) 上產生了相機優先 3D 物件偵測的競爭力結果。我們展示了使用規劃器軌跡、
物件偵測和道路圖形任務共同訓練 EMMA，會在所有三個
領域中產生改進，突顯了 EMMA 作為自動駕駛應用程式通用模型的潛力。然而，EMMA 也展現出某些限制：它只能
處理少量影像幀，不整合準確的 3D 感測模式（例如 LiDAR 或雷達），而且計算成本高昂。我們
希望我們的結果能激勵進一步的研究，以減輕這些問題，並進一步發展自動駕駛模型
架構的最新技術。</paragraph>

##### **$100K or 100 Days: Trade-offs when Pre-Training with Academic Resources**
2410.23261v1 by Apoorv Khandelwal, Tian Yun, Nihal V. Nayak, Jack Merullo, Stephen H. Bach, Chen Sun, Ellie Pavlick

Pre-training is notoriously compute-intensive and academic researchers are
notoriously under-resourced. It is, therefore, commonly assumed that academics
can't pre-train models. In this paper, we seek to clarify this assumption. We
first survey academic researchers to learn about their available compute and
then empirically measure the time to replicate models on such resources. We
introduce a benchmark to measure the time to pre-train models on given GPUs and
also identify ideal settings for maximizing training speed. We run our
benchmark on a range of models and academic GPUs, spending 2,000 GPU-hours on
our experiments. Our results reveal a brighter picture for academic
pre-training: for example, although Pythia-1B was originally trained on 64 GPUs
for 3 days, we find it is also possible to replicate this model (with the same
hyper-parameters) in 3x fewer GPU-days: i.e. on 4 GPUs in 18 days. We conclude
with a cost-benefit analysis to help clarify the trade-offs between price and
pre-training time. We believe our benchmark will help academic researchers
conduct experiments that require training larger models on more data. We fully
release our codebase at: https://github.com/apoorvkh/academic-pretraining.

摘要：預訓練出了名的需要大量運算，而學術研究人員出了名的資源不足。因此，普遍認為學術界無法預訓練模型。在本文中，我們試圖釐清這個假設。我們首先調查學術研究人員，以了解他們可用的運算，然後根據這些資源實證測量複製模型的時間。我們引入一個基準，用來測量在給定的 GPU 上預訓練模型的時間，並找出最大化訓練速度的理想設定。我們在各種模型和學術 GPU 上執行基準，在我們的實驗中耗費了 2,000 個 GPU 小時。我們的結果對學術預訓練揭示了一個更光明的圖像：例如，儘管 Pythia-1B 最初在 64 個 GPU 上訓練了 3 天，但我們發現也可以用更少的 3 倍 GPU 天數複製這個模型（使用相同的超參數）：即在 4 個 GPU 上訓練 18 天。我們以成本效益分析作為結論，以幫助釐清價格和預訓練時間之間的權衡。我們相信我們的基準將有助於學術研究人員進行需要在更多資料上訓練更大模型的實驗。我們在 https://github.com/apoorvkh/academic-pretraining 完整釋出我們的程式碼庫。

##### **Keypoint Abstraction using Large Models for Object-Relative Imitation Learning**
2410.23254v1 by Xiaolin Fang, Bo-Ruei Huang, Jiayuan Mao, Jasmine Shone, Joshua B. Tenenbaum, Tomás Lozano-Pérez, Leslie Pack Kaelbling

Generalization to novel object configurations and instances across diverse
tasks and environments is a critical challenge in robotics. Keypoint-based
representations have been proven effective as a succinct representation for
capturing essential object features, and for establishing a reference frame in
action prediction, enabling data-efficient learning of robot skills. However,
their manual design nature and reliance on additional human labels limit their
scalability. In this paper, we propose KALM, a framework that leverages large
pre-trained vision-language models (LMs) to automatically generate
task-relevant and cross-instance consistent keypoints. KALM distills robust and
consistent keypoints across views and objects by generating proposals using LMs
and verifies them against a small set of robot demonstration data. Based on the
generated keypoints, we can train keypoint-conditioned policy models that
predict actions in keypoint-centric frames, enabling robots to generalize
effectively across varying object poses, camera views, and object instances
with similar functional shapes. Our method demonstrates strong performance in
the real world, adapting to different tasks and environments from only a
handful of demonstrations while requiring no additional labels. Website:
https://kalm-il.github.io/

摘要：在機器人領域中，泛化至各種任務與環境中的新穎物體配置和實例是一項嚴峻的挑戰。基於關鍵點的表示法已被證明是一種簡潔的表示法，用於擷取必要的物體特徵，並在動作預測中建立參考架構，進而實現機器人技能的資料有效學習。然而，其手動設計性質和對額外人工標籤的依賴限制了其可擴充性。在本文中，我們提出 KALM，這是一種利用大型預訓練視覺語言模型 (LM) 自動生成與任務相關且跨實例一致的關鍵點的架構。KALM 透過使用 LM 產生建議，並根據一組小型機器人示範資料驗證它們，從而提取跨視圖和物體的穩健且一致的關鍵點。根據產生的關鍵點，我們可以訓練關鍵點條件策略模型，該模型預測關鍵點中心框架中的動作，讓機器人在不同的物體姿勢、相機視圖和具有類似功能形狀的物體實例中有效泛化。我們的模型在真實世界中表現出強大的效能，只需少數示範即可適應不同的任務和環境，同時不需要額外的標籤。網站：https://kalm-il.github.io/

##### **Evaluating Cultural and Social Awareness of LLM Web Agents**
2410.23252v1 by Haoyi Qiu, Alexander R. Fabbri, Divyansh Agarwal, Kung-Hsiang Huang, Sarah Tan, Nanyun Peng, Chien-Sheng Wu

As large language models (LLMs) expand into performing as agents for
real-world applications beyond traditional NLP tasks, evaluating their
robustness becomes increasingly important. However, existing benchmarks often
overlook critical dimensions like cultural and social awareness. To address
these, we introduce CASA, a benchmark designed to assess LLM agents'
sensitivity to cultural and social norms across two web-based tasks: online
shopping and social discussion forums. Our approach evaluates LLM agents'
ability to detect and appropriately respond to norm-violating user queries and
observations. Furthermore, we propose a comprehensive evaluation framework that
measures awareness coverage, helpfulness in managing user queries, and the
violation rate when facing misleading web content. Experiments show that
current LLMs perform significantly better in non-agent than in web-based agent
environments, with agents achieving less than 10% awareness coverage and over
40% violation rates. To improve performance, we explore two methods: prompting
and fine-tuning, and find that combining both methods can offer complementary
advantages -- fine-tuning on culture-specific datasets significantly enhances
the agents' ability to generalize across different regions, while prompting
boosts the agents' ability to navigate complex tasks. These findings highlight
the importance of constantly benchmarking LLM agents' cultural and social
awareness during the development cycle.

摘要：隨著大型語言模型 (LLM) 擴展到作為代理執行實際應用程式，超越傳統的 NLP 任務，評估其穩健性變得越來越重要。然而，現有的基準測試經常忽略關鍵面向，例如文化和社會意識。為了解決這些問題，我們引入了 CASA，一個基準測試，旨在評估 LLM 代理對兩個網路任務中文化和社會規範的敏感度：線上購物和社群討論論壇。我們的做法評估 LLM 代理偵測和適當地回應違反規範的使用者查詢和觀察的能力。此外，我們提出一個全面的評估架構，測量意識涵蓋範圍、管理使用者查詢的幫助性，以及面對誤導性網路內容時的違規率。實驗顯示，目前的 LLM 在非代理環境中的表現明顯優於網路代理環境，代理的意識涵蓋範圍低於 10%，違規率超過 40%。為了提升效能，我們探討了兩種方法：提示和微調，並發現結合兩種方法可以提供互補的優勢——針對特定文化的資料集進行微調，顯著提升代理跨不同地區概括的能力，而提示則提升代理導航複雜任務的能力。這些發現強調在開發週期中持續對 LLM 代理的文化和社會意識進行基準測試的重要性。

##### **A little less conversation, a little more action, please: Investigating the physical common-sense of LLMs in a 3D embodied environment**
2410.23242v1 by Matteo G. Mecattaf, Ben Slater, Marko Tešić, Jonathan Prunty, Konstantinos Voudouris, Lucy G. Cheke

As general-purpose tools, Large Language Models (LLMs) must often reason
about everyday physical environments. In a question-and-answer capacity,
understanding the interactions of physical objects may be necessary to give
appropriate responses. Moreover, LLMs are increasingly used as reasoning
engines in agentic systems, designing and controlling their action sequences.
The vast majority of research has tackled this issue using static benchmarks,
comprised of text or image-based questions about the physical world. However,
these benchmarks do not capture the complexity and nuance of real-life physical
processes. Here we advocate for a second, relatively unexplored, approach:
'embodying' the LLMs by granting them control of an agent within a 3D
environment. We present the first embodied and cognitively meaningful
evaluation of physical common-sense reasoning in LLMs. Our framework allows
direct comparison of LLMs with other embodied agents, such as those based on
Deep Reinforcement Learning, and human and non-human animals. We employ the
Animal-AI (AAI) environment, a simulated 3D virtual laboratory, to study
physical common-sense reasoning in LLMs. For this, we use the AAI Testbed, a
suite of experiments that replicate laboratory studies with non-human animals,
to study physical reasoning capabilities including distance estimation,
tracking out-of-sight objects, and tool use. We demonstrate that
state-of-the-art multi-modal models with no finetuning can complete this style
of task, allowing meaningful comparison to the entrants of the 2019 Animal-AI
Olympics competition and to human children. Our results show that LLMs are
currently outperformed by human children on these tasks. We argue that this
approach allows the study of physical reasoning using ecologically valid
experiments drawn directly from cognitive science, improving the predictability
and reliability of LLMs.

摘要：作為通用工具，大型語言模型 (LLM) 必須經常推論日常物理環境。在問答能力中，了解物理物體的交互作用可能是給出適當回應所必需的。此外，LLM 正在越來越多地用作代理系統中的推理引擎，設計和控制其動作序列。絕大多數研究使用靜態基準來解決這個問題，這些基準包含有關物理世界的基於文本或圖像的問題。然而，這些基準並未捕捉到現實物理過程的複雜性和細微差別。在這裡，我們提倡第二種相對未經探索的方法：“具身化” LLM，讓它們控制 3D 環境中的代理。我們提出了對 LLM 中物理常識推理的第一個具身化和認知有意義的評估。我們的框架允許將 LLM 與其他具身化代理進行直接比較，例如基於深度強化學習的代理，以及人類和非人類動物。我們採用 Animal-AI (AAI) 環境，一個模擬的 3D 虛擬實驗室，來研究 LLM 中的物理常識推理。為此，我們使用 AAI 測試平台，一組實驗，複製了對非人類動物的實驗室研究，以研究物理推理能力，包括距離估計、追蹤視線外物體和工具使用。我們證明了沒有微調的最新多模態模型可以完成這種風格的任務，允許與 2019 年動物人工智能奧林匹克競賽的參賽者和人類兒童進行有意義的比較。我們的結果表明，在這些任務上，人類兒童目前表現優於 LLM。我們認為，這種方法允許使用直接從認知科學中提取的生態學上有效實驗來研究物理推理，從而提高 LLM 的可預測性和可靠性。

##### **EMOTION: Expressive Motion Sequence Generation for Humanoid Robots with In-Context Learning**
2410.23234v1 by Peide Huang, Yuhan Hu, Nataliya Nechyporenko, Daehwa Kim, Walter Talbott, Jian Zhang

This paper introduces a framework, called EMOTION, for generating expressive
motion sequences in humanoid robots, enhancing their ability to engage in
humanlike non-verbal communication. Non-verbal cues such as facial expressions,
gestures, and body movements play a crucial role in effective interpersonal
interactions. Despite the advancements in robotic behaviors, existing methods
often fall short in mimicking the diversity and subtlety of human non-verbal
communication. To address this gap, our approach leverages the in-context
learning capability of large language models (LLMs) to dynamically generate
socially appropriate gesture motion sequences for human-robot interaction. We
use this framework to generate 10 different expressive gestures and conduct
online user studies comparing the naturalness and understandability of the
motions generated by EMOTION and its human-feedback version, EMOTION++, against
those by human operators. The results demonstrate that our approach either
matches or surpasses human performance in generating understandable and natural
robot motions under certain scenarios. We also provide design implications for
future research to consider a set of variables when generating expressive
robotic gestures.

摘要：本文介紹了一個名為 EMOTION 的框架，可用於在類人機器人中生成表達性的動作序列，增強其參與類人非語言溝通的能力。非語言線索（例如面部表情、手勢和身體動作）在有效的人際互動中扮演著至關重要的角色。儘管機器人行為有進步，但現有方法在模仿人類非語言溝通的多樣性和微妙性方面往往做得不夠。為了解決這個差距，我們的方法利用大型語言模型 (LLM) 的情境學習能力，動態生成適應社交場合的手勢動作序列，用於人機互動。我們使用這個框架生成了 10 種不同的表達性手勢，並進行線上使用者研究，比較 EMOTION 及其人類回饋版本 EMOTION++ 所生成動作的自然性和可理解性，以及人類操作員所做的動作。結果表明，在某些場景下，我們的方法在生成可理解且自然的機器人動作方面達到或超過人類表現。我們還為未來的研究提供了設計含義，以考慮在生成表達性機器人手勢時的一組變數。

##### **Aligning Audio-Visual Joint Representations with an Agentic Workflow**
2410.23230v2 by Shentong Mo, Yibing Song

Visual content and accompanied audio signals naturally formulate a joint
representation to improve audio-visual (AV) related applications. While studies
develop various AV representation learning frameworks, the importance of AV
data alignment is usually undermined for achieving high-quality representation.
We observe that an audio signal may contain background noise interference.
Also, non-synchronization may appear between audio and video streams. These
non-strict data alignment limits representation quality and downgrade
application performance. In this paper, we propose to improve AV joint
representations from a data-centric perspective by aligning audio signals to
visual data. Our alignment is conducted in an agentic workflow controlled by an
LLM-based assistant named AVAgent. For each input AV data pair, our AVAgent
uses a multi-modal LLM to convert audio and visual data into language
descriptions separately (i.e., tool use). Then, AVAgent reasons whether this
paired data is aligned well and plans to edit the audio signal if needed (i.e.,
planning). The audio editing is executed by predefined actions that filter
noise or augment data. Moreover, we use a VLM to evaluate how modified audio
signals match the visual content and provide feedback to AVAgent (i.e.,
reflection). The tool use, planning, and reflection steps operate cyclically to
become an agentic workflow where audio signals are gradually aligned to visual
content. To this end, existing methods can directly leverage the aligned AV
data via our agentic workflow to improve AV joint representations. The
experimental results comprehensively demonstrate the state-of-the-art
performance of the proposed approach against previous baselines in diverse
downstream tasks.

摘要：視覺內容和伴隨的音訊訊號自然會形成一種聯合表示，以改善音訊視覺 (AV) 相關應用程式。儘管研究開發了各種 AV 表示學習架構，但 AV 資料對齊的重要性通常會被低估，以實現高品質的表示。我們觀察到，音訊訊號可能包含背景噪音干擾。此外，音訊串流和視訊串流之間可能出現不同步。這些非嚴格資料對齊會限制表示品質並降低應用程式效能。在本文中，我們提議從以資料為中心的觀點改善 AV 聯合表示，方法是將音訊訊號與視覺資料對齊。我們的對齊是在由名為 AVAgent 的基於 LLM 的助理控制的代理工作流程中進行的。對於每個輸入 AV 資料對，我們的 AVAgent 使用多模態 LLM 將音訊和視覺資料分別轉換成語言描述（即工具使用）。然後，AVAgent 推論這組資料對是否對齊良好，並計畫在需要時編輯音訊訊號（即計畫）。音訊編輯是由預定義的動作執行的，這些動作會過濾雜訊或擴充資料。此外，我們使用 VLM 來評估修改後的音訊訊號如何與視覺內容相符，並向 AVAgent 提供回饋（即反思）。工具使用、計畫和反思步驟循環運作，成為一個代理工作流程，其中音訊訊號逐漸與視覺內容對齊。為此，現有方法可以直接透過我們的代理工作流程利用對齊的 AV 資料來改善 AV 聯合表示。實驗結果全面展示了所提出的方法在各種下游任務中相較於先前基線的最佳效能。

##### **COMAL: A Convergent Meta-Algorithm for Aligning LLMs with General Preferences**
2410.23223v1 by Yixin Liu, Argyris Oikonomou, Weiqiang Zheng, Yang Cai, Arman Cohan

Many alignment methods, including reinforcement learning from human feedback
(RLHF), rely on the Bradley-Terry reward assumption, which is insufficient to
capture the full range of general human preferences. To achieve robust
alignment with general preferences, we model the alignment problem as a
two-player zero-sum game, where the Nash equilibrium policy guarantees a 50%
win rate against any competing policy. However, previous algorithms for finding
the Nash policy either diverge or converge to a Nash policy in a modified game,
even in a simple synthetic setting, thereby failing to maintain the 50% win
rate guarantee against all other policies. We propose a meta-algorithm,
Convergent Meta Alignment Algorithm (COMAL), for language model alignment with
general preferences, inspired by convergent algorithms in game theory.
Theoretically, we prove that our meta-algorithm converges to an exact Nash
policy in the last iterate. Additionally, our meta-algorithm is simple and can
be integrated with many existing methods designed for RLHF and preference
optimization with minimal changes. Experimental results demonstrate the
effectiveness of the proposed framework when combined with existing preference
policy optimization methods.

摘要：許多對齊方法，包含人類回饋的強化學習 (RLHF)，依賴於布萊德利-泰瑞獎勵假設，這不足以涵蓋一般人類偏好的完整範圍。為了達成與一般偏好的穩健對齊，我們將對齊問題建模為雙人零和遊戲，其中納許均衡策略保證對抗任何競爭策略時有 50% 的獲勝率。然而，先前用於尋找納許策略的演算法會發散或收斂至修改後遊戲中的納許策略，即使在簡單的合成設定中也是如此，因此無法維持對抗所有其他策略的 50% 獲勝率保證。我們提出了一個元演算法，收斂元對齊演算法 (COMAL)，用於語言模型對齊與一般偏好，靈感來自於博弈論中的收斂演算法。理論上，我們證明我們的元演算法在最後一次迭代中收斂至精確的納許策略。此外，我們的元演算法很簡單，可以與許多現有的方法整合，這些方法是為 RLHF 和偏好最佳化所設計的，而且變更很小。實驗結果證明了所提出的架構在與現有的偏好策略最佳化方法結合時很有效。

##### **Partial Channel Dependence with Channel Masks for Time Series Foundation Models**
2410.23222v1 by Seunghan Lee, Taeyoung Park, Kibok Lee

Recent advancements in foundation models have been successfully extended to
the time series (TS) domain, facilitated by the emergence of large-scale TS
datasets. However, previous efforts have primarily focused on designing model
architectures to address explicit heterogeneity among datasets such as various
numbers of channels, while often overlooking implicit heterogeneity such as
varying dependencies between channels. In this work, we introduce the concept
of partial channel dependence (PCD), which enables a more sophisticated
adjustment of channel dependencies based on dataset-specific information. To
achieve PCD, we propose a channel mask that captures the relationships between
channels within a dataset using two key components: 1) a correlation matrix
that encodes relative dependencies between channels, and 2) domain parameters
that learn the absolute dependencies specific to each dataset, refining the
correlation matrix. We validate the effectiveness of PCD across four tasks in
TS including forecasting, classification, imputation, and anomaly detection,
under diverse settings, including few-shot and zero-shot scenarios with both TS
foundation models and single-task models. Code is available at
https://github.com/seunghan96/CM.

摘要：近期基础模型的进步已成功扩展到时间序列 (TS) 领域，这得益于大规模 TS 数据集的出现。然而，以往的研究主要专注于设计模型架构，以解决数据集之间显性的异质性，例如不同数量的通道，而常常忽略了隐性的异质性，例如通道之间的不同依赖性。在这项工作中，我们引入了部分通道依赖 (PCD) 的概念，它可以根据数据集特定的信息对通道依赖性进行更精细的调整。为了实现 PCD，我们提出了一个通道掩码，它使用两个关键组件来捕获数据集内通道之间的关系：1）一个相关性矩阵，它对通道之间的相对依赖性进行编码，以及 2）学习特定于每个数据集的绝对依赖性的域参数，对相关性矩阵进行细化。我们在 TS 中的四个任务（包括预测、分类、插补和异常检测）中验证了 PCD 的有效性，在不同的设置下，包括使用 TS 基础模型和单任务模型的少量样本和零样本场景。代码可从 https://github.com/seunghan96/CM 获得。

##### **OS-ATLAS: A Foundation Action Model for Generalist GUI Agents**
2410.23218v1 by Zhiyong Wu, Zhenyu Wu, Fangzhi Xu, Yian Wang, Qiushi Sun, Chengyou Jia, Kanzhi Cheng, Zichen Ding, Liheng Chen, Paul Pu Liang, Yu Qiao

Existing efforts in building GUI agents heavily rely on the availability of
robust commercial Vision-Language Models (VLMs) such as GPT-4o and
GeminiProVision. Practitioners are often reluctant to use open-source VLMs due
to their significant performance lag compared to their closed-source
counterparts, particularly in GUI grounding and Out-Of-Distribution (OOD)
scenarios. To facilitate future research in this area, we developed OS-Atlas -
a foundational GUI action model that excels at GUI grounding and OOD agentic
tasks through innovations in both data and modeling. We have invested
significant engineering effort in developing an open-source toolkit for
synthesizing GUI grounding data across multiple platforms, including Windows,
Linux, MacOS, Android, and the web. Leveraging this toolkit, we are releasing
the largest open-source cross-platform GUI grounding corpus to date, which
contains over 13 million GUI elements. This dataset, combined with innovations
in model training, provides a solid foundation for OS-Atlas to understand GUI
screenshots and generalize to unseen interfaces. Through extensive evaluation
across six benchmarks spanning three different platforms (mobile, desktop, and
web), OS-Atlas demonstrates significant performance improvements over previous
state-of-the-art models. Our evaluation also uncovers valuable insights into
continuously improving and scaling the agentic capabilities of open-source
VLMs.

摘要：現有的 GUI 代理建構工作高度依賴於強大的商用視覺語言模型 (VLM)，例如 GPT-4o 和 GeminiProVision。實務工作者通常不願意使用開放原始碼 VLM，因為它們的效能表現遠不如閉源對應產品，特別是在 GUI 基礎和分布外 (OOD) 場景中。為了促進這方面的未來研究，我們開發了 OS-Atlas，這是一個基礎 GUI 動作模型，透過資料和建模的創新，在 GUI 基礎和 OOD 代理任務中表現出色。我們投入大量的工程心力來開發一個開放原始碼工具包，用於在多個平台（包括 Windows、Linux、MacOS、Android 和網路）中合成 GUI 基礎資料。利用這個工具包，我們發布了迄今為止最大的開放原始碼跨平台 GUI 基礎語料庫，其中包含超過 1300 萬個 GUI 元素。此資料集結合了模型訓練的創新，為 OS-Atlas 理解 GUI 螢幕截圖並概括到未見過的介面提供了穩固的基礎。透過橫跨三個不同平台（行動、桌上型和網路）的六個基準測試進行廣泛評估，OS-Atlas 展示出比先前的最先進模型有顯著的效能提升。我們的評估也揭示了寶貴的見解，可以持續改善和擴展開放原始碼 VLM 的代理功能。

##### **Grounding by Trying: LLMs with Reinforcement Learning-Enhanced Retrieval**
2410.23214v2 by Sheryl Hsu, Omar Khattab, Chelsea Finn, Archit Sharma

The hallucinations of large language models (LLMs) are increasingly mitigated
by allowing LLMs to search for information and to ground their answers in real
sources. Unfortunately, LLMs often struggle with posing the right search
queries, especially when dealing with complex or otherwise indirect topics.
Observing that LLMs can learn to search for relevant facts by $\textit{trying}$
different queries and learning to up-weight queries that successfully produce
relevant results, we introduce $\underline{Le}$arning to $\underline{Re}$trieve
by $\underline{T}$rying (LeReT), a reinforcement learning framework that
explores search queries and uses preference-based optimization to improve their
quality. LeReT can improve the absolute retrieval accuracy by up to 29% and the
downstream generator evaluations by 17%. The simplicity and flexibility of
LeReT allows it to be applied to arbitrary off-the-shelf retrievers and makes
it a promising technique for improving general LLM pipelines. Project website:
http://sherylhsu.com/LeReT/.

摘要：大型語言模型 (LLM) 的幻覺越來越能被緩解，方法是讓 LLM 搜尋資訊並將其答案建立在真實來源上。不幸的是，LLM 通常難以提出正確的搜尋查詢，特別是在處理複雜或間接主題時。觀察到 LLM 可以透過「嘗試」不同的查詢並學習對成功產生相關結果的查詢進行加權，來學習搜尋相關事實，我們引入了「嘗試學習檢索」(LeReT)，這是一個強化學習框架，探索搜尋查詢並使用基於偏好的最佳化來改善其品質。LeReT 可以將絕對檢索準確度提高多達 29%，並將下游產生器評估提高 17%。LeReT 的簡潔性和靈活性使其可以應用於任意現成的檢索器，並使其成為改善一般 LLM 管線的有前途技術。專案網站：http://sherylhsu.com/LeReT/。

##### **Kinetix: Investigating the Training of General Agents through Open-Ended Physics-Based Control Tasks**
2410.23208v1 by Michael Matthews, Michael Beukman, Chris Lu, Jakob Foerster

While large models trained with self-supervised learning on offline datasets
have shown remarkable capabilities in text and image domains, achieving the
same generalisation for agents that act in sequential decision problems remains
an open challenge. In this work, we take a step towards this goal by
procedurally generating tens of millions of 2D physics-based tasks and using
these to train a general reinforcement learning (RL) agent for physical
control. To this end, we introduce Kinetix: an open-ended space of
physics-based RL environments that can represent tasks ranging from robotic
locomotion and grasping to video games and classic RL environments, all within
a unified framework. Kinetix makes use of our novel hardware-accelerated
physics engine Jax2D that allows us to cheaply simulate billions of environment
steps during training. Our trained agent exhibits strong physical reasoning
capabilities, being able to zero-shot solve unseen human-designed environments.
Furthermore, fine-tuning this general agent on tasks of interest shows
significantly stronger performance than training an RL agent *tabula rasa*.
This includes solving some environments that standard RL training completely
fails at. We believe this demonstrates the feasibility of large scale,
mixed-quality pre-training for online RL and we hope that Kinetix will serve as
a useful framework to investigate this further.

摘要：<paragraph>儘管使用離線資料集的自監督學習訓練出來的大型模型在文字和影像領域展現出顯著的能力，但對於在順序決策問題中執行的代理人達成相同的概括性仍然是一個公開的挑戰。在這項工作中，我們透過程序化產生數千萬個 2D 基於物理的任務，並使用這些任務訓練一個用於物理控制的一般強化學習 (RL) 代理人，朝這個目標邁進一步。為此，我們引入了 Kinetix：一個開放式的基於物理的 RL 環境空間，它可以在一個統一的架構內表示從機器人運動和抓取到電玩遊戲和經典 RL 環境等各種任務。Kinetix 使用我們新穎的硬體加速物理引擎 Jax2D，它讓我們可以在訓練期間便宜地模擬數十億個環境步驟。我們訓練出來的代理人展現出強大的物理推理能力，能夠在未經訓練的情況下解決人類設計的環境。此外，在感興趣的任務上微調這個一般代理人顯示出比訓練一個「白板」RL 代理人強大的表現。這包括解決一些標準 RL 訓練完全失敗的環境。我們相信這展示了針對線上 RL 進行大規模、混合品質預訓練的可行性，我們希望 Kinetix 能夠作為一個有用的架構來進一步研究這件事。</paragraph>

##### **Reliability of Topic Modeling**
2410.23186v1 by Kayla Schroeder, Zach Wood-Doughty

Topic models allow researchers to extract latent factors from text data and
use those variables in downstream statistical analyses. However, these
methodologies can vary significantly due to initialization differences,
randomness in sampling procedures, or noisy data. Reliability of these methods
is of particular concern as many researchers treat learned topic models as
ground truth for subsequent analyses. In this work, we show that the standard
practice for quantifying topic model reliability fails to capture essential
aspects of the variation in two widely-used topic models. Drawing from a
extensive literature on measurement theory, we provide empirical and
theoretical analyses of three other metrics for evaluating the reliability of
topic models. On synthetic and real-world data, we show that McDonald's
$\omega$ provides the best encapsulation of reliability. This metric provides
an essential tool for validation of topic model methodologies that should be a
standard component of any topic model-based research.

摘要：主題模型讓研究人員能夠從文本資料中萃取潛在因子，並在後續的統計分析中使用這些變數。然而，這些方法論可能因為初始化的差異、抽樣程序的隨機性或資料雜訊而有顯著的差異。這些方法的可靠性是特別令人關注的，因為許多研究人員將學習到的主題模型視為後續分析的真實依據。在這項工作中，我們展示了量化主題模型可靠性的標準實務無法捕捉到兩種廣泛使用的主題模型中變異的基本面向。我們從測量理論的廣泛文獻中汲取靈感，提供了其他三個用於評估主題模型可靠性的指標的經驗和理論分析。在合成和真實世界的資料中，我們展示了麥克唐納的 $\omega$ 提供了最佳的可靠性概括。這個指標提供了一個重要的工具，用於驗證主題模型方法論，而這應該是任何基於主題模型的研究的標準組成部分。

##### **ProTransformer: Robustify Transformers via Plug-and-Play Paradigm**
2410.23182v1 by Zhichao Hou, Weizhi Gao, Yuchen Shen, Feiyi Wang, Xiaorui Liu

Transformer-based architectures have dominated various areas of machine
learning in recent years. In this paper, we introduce a novel robust attention
mechanism designed to enhance the resilience of transformer-based
architectures. Crucially, this technique can be integrated into existing
transformers as a plug-and-play layer, improving their robustness without the
need for additional training or fine-tuning. Through comprehensive experiments
and ablation studies, we demonstrate that our ProTransformer significantly
enhances the robustness of transformer models across a variety of prediction
tasks, attack mechanisms, backbone architectures, and data domains. Notably,
without further fine-tuning, the ProTransformer consistently improves the
performance of vanilla transformers by 19.5%, 28.3%, 16.1%, and 11.4% for BERT,
ALBERT, DistilBERT, and RoBERTa, respectively, under the classical TextFooler
attack. Furthermore, ProTransformer shows promising resilience in large
language models (LLMs) against prompting-based attacks, improving the
performance of T5 and LLaMA by 24.8% and 17.8%, respectively, and enhancing
Vicuna by an average of 10.4% against the Jailbreaking attack. Beyond the
language domain, ProTransformer also demonstrates outstanding robustness in
both vision and graph domains.

摘要：<paragraph>近年來，基於 Transformer 的架構主導了機器學習的各個領域。在本文中，我們介紹了一種新穎且強大的注意力機制，旨在增強基於 Transformer 的架構的韌性。至關重要的是，此技術可以作為即插即用的層整合到現有的 Transformer 中，在無需額外訓練或微調的情況下提高其穩健性。通過全面的實驗和消融研究，我們證明了我們的 ProTransformer 在各種預測任務、攻擊機制、主幹架構和數據領域中顯著增強了 Transformer 模型的穩健性。值得注意的是，在不進一步微調的情況下，ProTransformer 在經典的 TextFooler 攻擊下，分別為 BERT、ALBERT、DistilBERT 和 RoBERTa 提升了 19.5%、28.3%、16.1% 和 11.4% 的性能。此外，ProTransformer 在基於提示的攻擊中對大型語言模型 (LLM) 顯示出有希望的韌性，分別將 T5 和 LLaMA 的性能提升了 24.8% 和 17.8%，並在越獄攻擊中將 Vicuna 的性能平均提升了 10.4%。除了語言領域之外，ProTransformer 在視覺和圖形領域也表現出出色的穩健性。</paragraph>

##### **ReasoningRec: Bridging Personalized Recommendations and Human-Interpretable Explanations through LLM Reasoning**
2410.23180v1 by Millennium Bismay, Xiangjue Dong, James Caverlee

This paper presents ReasoningRec, a reasoning-based recommendation framework
that leverages Large Language Models (LLMs) to bridge the gap between
recommendations and human-interpretable explanations. In contrast to
conventional recommendation systems that rely on implicit user-item
interactions, ReasoningRec employs LLMs to model users and items, focusing on
preferences, aversions, and explanatory reasoning. The framework utilizes a
larger LLM to generate synthetic explanations for user preferences,
subsequently used to fine-tune a smaller LLM for enhanced recommendation
accuracy and human-interpretable explanation. Our experimental study
investigates the impact of reasoning and contextual information on personalized
recommendations, revealing that the quality of contextual and personalized data
significantly influences the LLM's capacity to generate plausible explanations.
Empirical evaluations demonstrate that ReasoningRec surpasses state-of-the-art
methods by up to 12.5\% in recommendation prediction while concurrently
providing human-intelligible explanations. The code is available here:
https://github.com/millenniumbismay/reasoningrec.

摘要：本文提出了 ReasoningRec，這是一個基於推理的推薦架構，它利用大型語言模型 (LLM) 來彌合建議和人類可解釋的說明之間的差距。與依賴於隱式使用者項目互動的傳統推薦系統相反，ReasoningRec 使用 LLM 對使用者和項目進行建模，著重於偏好、厭惡和說明性推理。該架構利用一個較大的 LLM 為使用者的偏好生成綜合說明，然後用於微調一個較小的 LLM，以增強推薦準確性和人類可解釋的說明。我們的實驗研究探討了推理和背景資訊對個人化推薦的影響，揭示了背景和個人化資料的品質會顯著影響 LLM 生成合理說明的能力。經驗評估表明，ReasoningRec 在推薦預測方面超越了最先進的方法，高達 12.5%，同時提供了人類可以理解的說明。程式碼在此處提供：https://github.com/millenniumbismay/reasoningrec。

##### **SciPIP: An LLM-based Scientific Paper Idea Proposer**
2410.23166v1 by Wenxiao Wang, Lihui Gu, Liye Zhang, Yunxiang Luo, Yi Dai, Chen Shen, Liang Xie, Binbin Lin, Xiaofei He, Jieping Ye

The exponential growth of knowledge and the increasing complexity of
interdisciplinary research pose significant challenges for researchers,
including information overload and difficulties in exploring novel ideas. The
advancements in large language models (LLMs), such as GPT-4, have shown great
potential in enhancing idea proposals, but how to effectively utilize large
models for reasonable idea proposal has not been thoroughly explored. This
paper proposes a scientific paper idea proposer (SciPIP). Based on a
user-provided research background, SciPIP retrieves helpful papers from a
literature database while leveraging the capabilities of LLMs to generate more
novel and feasible ideas. To this end, 1) we construct a literature retrieval
database, extracting lots of papers' multi-dimension information for fast
access. Then, a literature retrieval method based on semantics, entity, and
citation co-occurrences is proposed to search relevant literature from multiple
aspects based on the user-provided background. 2) After literature retrieval,
we introduce dual-path idea proposal strategies, where one path infers
solutions from the retrieved literature and the other path generates original
ideas through model brainstorming. We then combine the two to achieve a good
balance between feasibility and originality. Through extensive experiments on
the natural language processing (NLP) field, we demonstrate that SciPIP can
retrieve citations similar to those of existing top conference papers and
generate many ideas consistent with them. Additionally, we evaluate the
originality of other ideas generated by SciPIP using large language models,
further validating the effectiveness of our proposed method. The code and the
database are released at https://github.com/cheerss/SciPIP.

摘要：知識的指數成長和跨領域研究的複雜性日益增加，對研究人員構成重大挑戰，包括資訊過載和探索新點子的困難。大型語言模型 (LLM) 的進步，例如 GPT-4，已顯示出增強點子提案的巨大潛力，但如何有效利用大型模型進行合理的點子提案尚未被徹底探討。本文提出了一個科學論文點子提案器 (SciPIP)。基於使用者提供的研究背景，SciPIP 從文獻資料庫中檢索有用的論文，同時利用 LLM 的功能來產生更多新穎且可行的點子。為此，1) 我們建構了一個文獻檢索資料庫，提取大量論文的多維資訊以快速存取。然後，提出一個基於語意、實體和引文共現的文獻檢索方法，以基於使用者提供的背景從多個面向搜尋相關文獻。2) 在文獻檢索之後，我們介紹了雙路徑點子提案策略，其中一條路徑從檢索到的文獻中推論出解決方案，而另一條路徑則透過模型腦力激盪產生原始點子。然後我們將兩者結合起來，在可行性和原創性之間取得良好的平衡。透過在自然語言處理 (NLP) 領域進行廣泛的實驗，我們證明 SciPIP 可以檢索到與現有頂尖會議論文類似的引文，並產生許多與它們一致的點子。此外，我們使用大型語言模型評估 SciPIP 產生的其他點子的原創性，進一步驗證我們提出的方法的有效性。程式碼和資料庫已在 https://github.com/cheerss/SciPIP 發布。

##### **FlexTSF: A Universal Forecasting Model for Time Series with Variable Regularities**
2410.23160v1 by Jingge Xiao, Yile Chen, Gao Cong, Wolfgang Nejdl, Simon Gottschalk

Developing a foundation model for time series forecasting across diverse
domains has attracted significant attention in recent years. Existing works
typically assume regularly sampled, well-structured data, limiting their
applicability to more generalized scenarios where time series often contain
missing values, unequal sequence lengths, and irregular time intervals between
measurements. To cover diverse domains and handle variable regularities, we
propose FlexTSF, a universal time series forecasting model that possesses
better generalization and natively support both regular and irregular time
series. FlexTSF produces forecasts in an autoregressive manner and incorporates
three novel designs: VT-Norm, a normalization strategy to ablate data domain
barriers, IVP Patcher, a patching module to learn representations from flexibly
structured time series, and LED attention, an attention mechanism to seamlessly
integrate these two and propagate forecasts with awareness of domain and time
information. Experiments on 12 datasets show that FlexTSF outperforms
state-of-the-art forecasting models respectively designed for regular and
irregular time series. Furthermore, after self-supervised pre-training, FlexTSF
shows exceptional performance in both zero-shot and few-show settings for time
series forecasting.

摘要：近年來，開發一個適用於不同領域的時間序列預測基礎模型備受關注。現有的研究通常假設定期取樣、結構良好的資料，這限制了它們在更廣泛的場景中應用，在這些場景中，時間序列通常包含遺失值、不等的序列長度和測量之間不規則的時間間隔。為了涵蓋不同的領域並處理可變的規律性，我們提出 FlexTSF，這是一個通用的時間序列預測模型，它擁有更好的概括性，並且原生支援規則和不規則的時間序列。FlexTSF 以自迴歸的方式產生預測，並結合了三項新穎的設計：VT-Norm，一種消除資料領域障礙的標準化策略；IVP Patcher，一個從彈性結構時間序列中學習表徵的修補模組；LED 注意力，一種無縫整合這兩個模組並傳播對領域和時間資訊有意識的預測的注意力機制。在 12 個資料集上的實驗表明，FlexTSF 優於分別為規則和不規則時間序列設計的最新預測模型。此外，在自我監督預訓練後，FlexTSF 在時間序列預測的零次學習和少次學習設定中都表現出卓越的效能。

##### **Fourier Amplitude and Correlation Loss: Beyond Using L2 Loss for Skillful Precipitation Nowcasting**
2410.23159v1 by Chiu-Wai Yan, Shi Quan Foo, Van Hoan Trinh, Dit-Yan Yeung, Ka-Hing Wong, Wai-Kin Wong

Deep learning approaches have been widely adopted for precipitation
nowcasting in recent years. Previous studies mainly focus on proposing new
model architectures to improve pixel-wise metrics. However, they frequently
result in blurry predictions which provide limited utility to forecasting
operations. In this work, we propose a new Fourier Amplitude and Correlation
Loss (FACL) which consists of two novel loss terms: Fourier Amplitude Loss
(FAL) and Fourier Correlation Loss (FCL). FAL regularizes the Fourier amplitude
of the model prediction and FCL complements the missing phase information. The
two loss terms work together to replace the traditional $L_2$ losses such as
MSE and weighted MSE for the spatiotemporal prediction problem on signal-based
data. Our method is generic, parameter-free and efficient. Extensive
experiments using one synthetic dataset and three radar echo datasets
demonstrate that our method improves perceptual metrics and meteorology skill
scores, with a small trade-off to pixel-wise accuracy and structural
similarity. Moreover, to improve the error margin in meteorological skill
scores such as Critical Success Index (CSI) and Fractions Skill Score (FSS), we
propose and adopt the Regional Histogram Divergence (RHD), a distance metric
that considers the patch-wise similarity between signal-based imagery patterns
with tolerance to local transforms. Code is available at
https://github.com/argenycw/FACL

摘要：深度学习方法近年来已被广泛用于降水临近预报。以往的研究主要集中在提出新的模型架构以改善逐像素度量。然而，它们经常导致模糊的预测，这为预报操作提供了有限的效用。在这项工作中，我们提出了一种新的傅里叶振幅和相关损失 (FACL)，它由两个新颖的损失项组成：傅里叶振幅损失 (FAL) 和傅里叶相关损失 (FCL)。FAL 规范化模型预测的傅里叶振幅，而 FCL 补充了缺失的相位信息。这两个损失项共同作用，取代了基于信号数据的时空预测问题的传统 $L_2$ 损失，例如 MSE 和加权 MSE。我们的方法是通用的、无参数且高效的。使用一个合成数据集和三个雷达回波数据集进行的广泛实验表明，我们的方法改进了感知度量和气象技能评分，对逐像素精度和结构相似性的影响很小。此外，为了提高气象技能评分中的误差范围，例如临界成功指数 (CSI) 和分数技能评分 (FSS)，我们提出并采用区域直方图散度 (RHD)，这是一种距离度量，它考虑了基于信号的图像模式之间的块级相似性，并容忍局部变换。代码可在 https://github.com/argenycw/FACL 获得

##### **VisualPredicator: Learning Abstract World Models with Neuro-Symbolic Predicates for Robot Planning**
2410.23156v1 by Yichao Liang, Nishanth Kumar, Hao Tang, Adrian Weller, Joshua B. Tenenbaum, Tom Silver, João F. Henriques, Kevin Ellis

Broadly intelligent agents should form task-specific abstractions that
selectively expose the essential elements of a task, while abstracting away the
complexity of the raw sensorimotor space. In this work, we present
Neuro-Symbolic Predicates, a first-order abstraction language that combines the
strengths of symbolic and neural knowledge representations. We outline an
online algorithm for inventing such predicates and learning abstract world
models. We compare our approach to hierarchical reinforcement learning,
vision-language model planning, and symbolic predicate invention approaches, on
both in- and out-of-distribution tasks across five simulated robotic domains.
Results show that our approach offers better sample complexity, stronger
out-of-distribution generalization, and improved interpretability.

摘要：廣泛智能代理應該形成特定任務的抽象，選擇性地揭露任務的本質元素，同時抽象掉原始感測運動空間的複雜性。在這項工作中，我們提出了神經符號謂詞，一種結合符號和神經知識表示的優點的一階抽象語言。我們概述了一種用於發明此類謂詞和學習抽象世界模型的線上演算法。我們將我們的做法與分層強化學習、視覺語言模型規劃和符號謂詞發明方法進行比較，在五個模擬機器人領域的分布內和分布外任務上進行比較。結果表明，我們的做法提供了更好的範例複雜度、更強的分布外概括化和改進的可解釋性。

##### **Public Domain 12M: A Highly Aesthetic Image-Text Dataset with Novel Governance Mechanisms**
2410.23144v1 by Jordan Meyer, Nick Padgett, Cullen Miller, Laura Exline

We present Public Domain 12M (PD12M), a dataset of 12.4 million high-quality
public domain and CC0-licensed images with synthetic captions, designed for
training text-to-image models. PD12M is the largest public domain image-text
dataset to date, with sufficient size to train foundation models while
minimizing copyright concerns. Through the Source.Plus platform, we also
introduce novel, community-driven dataset governance mechanisms that reduce
harm and support reproducibility over time.

摘要：<paragraph>我們提供公共領域 12M (PD12M)，一個擁有 1240 萬張高品質公共領域和 CC0 授權圖片的資料集，搭配人造標題，用於訓練文字轉圖片模型。PD12M 是迄今為止最大的公共領域圖片文字資料集，規模足夠用於訓練基礎模型，同時最大限度地減少版權問題。透過 Source.Plus 平台，我們還引入了新穎的、社群驅動的資料集治理機制，以減少危害並隨著時間推移支援可複製性。</paragraph>

##### **Fair Division with Market Values**
2410.23137v1 by Siddharth Barman, Soroush Ebadian, Mohamad Latifian, Nisarg Shah

We introduce a model of fair division with market values, where indivisible
goods must be partitioned among agents with (additive) subjective valuations,
and each good additionally has a market value. The market valuation can be
viewed as a separate additive valuation that holds identically across all the
agents. We seek allocations that are simultaneously fair with respect to the
subjective valuations and with respect to the market valuation.
  We show that an allocation that satisfies stochastically-dominant
envy-freeness up to one good (SD-EF1) with respect to both the subjective
valuations and the market valuation does not always exist, but the weaker
guarantee of EF1 with respect to the subjective valuations along with SD-EF1
with respect to the market valuation can be guaranteed. We also study a number
of other guarantees such as Pareto optimality, EFX, and MMS. In addition, we
explore non-additive valuations and extend our model to cake-cutting. Along the
way, we identify several tantalizing open questions.

摘要：我們引入一個具有市場價值的公平分配模型，其中不可分割的商品必須分配給具有（加法）主觀估值的代理人，且每件商品額外具有市場價值。市場估值可以視為一個獨立的加法估值，在所有代理人之間完全相同。我們尋求在主觀估值和市場估值方面同時公平的分配。
我們證明了一個分配，滿足關於一個商品的隨機支配嫉妒自由（SD-EF1），關於主觀估值和市場估值，並不總是存在，但是關於主觀估值的較弱保證 EF1 以及關於市場估值的 SD-EF1 可以得到保證。我們還研究了許多其他保證，例如帕累托最優性、EFX 和 MMS。此外，我們探索非加法估值，並將我們的模型擴展到蛋糕切割。在此過程中，我們發現了幾個誘人的開放問題。

##### **Crowdsourcing Lexical Diversity**
2410.23133v1 by Hadi Khalilia, Jahna Otterbacher, Gabor Bella, Rusma Noortyani, Shandy Darma, Fausto Giunchiglia

Lexical-semantic resources (LSRs), such as online lexicons or wordnets, are
fundamental for natural language processing applications. In many languages,
however, such resources suffer from quality issues: incorrect entries,
incompleteness, but also, the rarely addressed issue of bias towards the
English language and Anglo-Saxon culture. Such bias manifests itself in the
absence of concepts specific to the language or culture at hand, the presence
of foreign (Anglo-Saxon) concepts, as well as in the lack of an explicit
indication of untranslatability, also known as cross-lingual \emph{lexical
gaps}, when a term has no equivalent in another language. This paper proposes a
novel crowdsourcing methodology for reducing bias in LSRs. Crowd workers
compare lexemes from two languages, focusing on domains rich in lexical
diversity, such as kinship or food. Our LingoGap crowdsourcing tool facilitates
comparisons through microtasks identifying equivalent terms, language-specific
terms, and lexical gaps across languages. We validated our method by applying
it to two case studies focused on food-related terminology: (1) English and
Arabic, and (2) Standard Indonesian and Banjarese. These experiments identified
2,140 lexical gaps in the first case study and 951 in the second. The success
of these experiments confirmed the usability of our method and tool for future
large-scale lexicon enrichment tasks.

摘要：詞彙語義資源（LSR），例如線上詞彙或詞網，對於自然語言處理應用來說至關重要。然而，在許多語言中，此類資源存在品質問題：條目不正確、不完整，以及鮮少探討的偏向英語和盎格魯撒克遜文化的問題。這種偏見表現在缺乏特定於手邊語言或文化的概念、存在外來（盎格魯撒克遜）概念，以及缺乏明確表示不可翻譯的指標，也稱為跨語言「詞彙差距」，表示一個詞在另一種語言中沒有等價詞。本文提出了一種新的群眾外包方法，用於減少 LSR 中的偏見。群眾工作者比較兩種語言的詞素，重點放在詞彙多樣性豐富的領域，例如親屬關係或食物。我們的 LingoGap 群眾外包工具透過微任務識別等價詞、特定語言詞彙和跨語言詞彙差距，進而促進比較。我們透過將方法應用於兩個以食物相關術語為重點的案例研究來驗證方法：（1）英語和阿拉伯語，以及（2）標準印尼語和班賈爾語。這些實驗在第一個案例研究中識別出 2,140 個詞彙差距，在第二個案例研究中識別出 951 個。這些實驗的成功驗證了我們的方法和工具在未來大規模詞彙豐富化任務中的可用性。

##### **Revisiting MAE pre-training for 3D medical image segmentation**
2410.23132v1 by Tassilo Wald, Constantin Ulrich, Stanislav Lukyanenko, Andrei Goncharov, Alberto Paderno, Leander Maerkisch, Paul F. Jäger, Klaus Maier-Hein

Self-Supervised Learning (SSL) presents an exciting opportunity to unlock the
potential of vast, untapped clinical datasets, for various downstream
applications that suffer from the scarcity of labeled data. While SSL has
revolutionized fields like natural language processing and computer vision,
their adoption in 3D medical image computing has been limited by three key
pitfalls: Small pre-training dataset sizes, architectures inadequate for 3D
medical image analysis, and insufficient evaluation practices. We address these
issues by i) leveraging a large-scale dataset of 44k 3D brain MRI volumes and
ii) using a Residual Encoder U-Net architecture within the state-of-the-art
nnU-Net framework. iii) A robust development framework, incorporating 5
development and 8 testing brain MRI segmentation datasets, allowed
performance-driven design decisions to optimize the simple concept of Masked
Auto Encoders (MAEs) for 3D CNNs. The resulting model not only surpasses
previous SSL methods but also outperforms the strong nnU-Net baseline by an
average of approximately 3 Dice points. Furthermore, our model demonstrates
exceptional stability, achieving the highest average rank of 2 out of 7
methods, compared to the second-best method's mean rank of 3.

摘要：自监督学习 (SSL) 为解锁大量未开发临床数据集的潜力提供了一个激动人心的机会，用于各种下游应用程序，这些应用程序因标记数据稀缺而受到影响。虽然 SSL 已彻底改变了自然语言处理和计算机视觉等领域，但其在 3D 医学图像计算中的采用受到三个主要缺陷的限制：小型预训练数据集大小、不适用于 3D 医学图像分析的架构以及评估实践不足。我们通过以下方式解决这些问题：i) 利用 44k 3D 大脑 MRI 体积的大规模数据集，以及 ii) 在最先进的 nnU-Net 框架内使用残差编码器 U-Net 架构。iii) 一个稳健的开发框架，包含 5 个开发和 8 个测试大脑 MRI 分割数据集，允许基于性能的设计决策来优化 3D CNN 的掩蔽自动编码器 (MAE) 的简单概念。由此产生的模型不仅超越了之前的 SSL 方法，而且比强大的 nnU-Net 基线平均高出大约 3 个骰子点。此外，我们的模型表现出非凡的稳定性，在 7 种方法中达到 2 的最高平均排名，而第二好的方法的平均排名为 3。

##### **Provably Optimal Memory Capacity for Modern Hopfield Models: Transformer-Compatible Dense Associative Memories as Spherical Codes**
2410.23126v1 by Jerry Yao-Chieh Hu, Dennis Wu, Han Liu

We study the optimal memorization capacity of modern Hopfield models and
Kernelized Hopfield Models (KHMs), a transformer-compatible class of Dense
Associative Memories. We present a tight analysis by establishing a connection
between the memory configuration of KHMs and spherical codes from information
theory. Specifically, we treat the stored memory set as a specialized spherical
code. This enables us to cast the memorization problem in KHMs into a point
arrangement problem on a hypersphere. We show that the optimal capacity of KHMs
occurs when the feature space allows memories to form an optimal spherical
code. This unique perspective leads to: (i) An analysis of how KHMs achieve
optimal memory capacity, and identify corresponding necessary conditions.
Importantly, we establish an upper capacity bound that matches the well-known
exponential lower bound in the literature. This provides the first tight and
optimal asymptotic memory capacity for modern Hopfield models. (ii) A
sub-linear time algorithm $\mathtt{U}\text{-}\mathtt{Hop}$+ to reach KHMs'
optimal capacity. (iii) An analysis of the scaling behavior of the required
feature dimension relative to the number of stored memories. These efforts
improve both the retrieval capability of KHMs and the representation learning
of corresponding transformers. Experimentally, we provide thorough numerical
results to back up theoretical findings.

摘要：我們研究現代 Hopfield 模型和核化 Hopfield 模型 (KHM) 的最佳記憶容量，這是一個與Transformer相容的稠密聯想記憶類別。我們透過建立 KHM 的記憶體組態與資訊理論中的球形碼之間的連結，提出嚴謹的分析。具體來說，我們將儲存的記憶體組視為一個特殊的球形碼。這使我們能夠將 KHM 中的記憶體問題轉換為超球面上的點排列問題。我們證明 KHM 的最佳容量發生在特徵空間允許記憶體形成最佳球形碼時。這個獨特的觀點導致：(i) 對 KHM 如何達到最佳記憶體容量的分析，並找出對應的必要條件。重要的是，我們建立了一個容量上限，與文獻中著名的指數下限相匹配。這為現代 Hopfield 模型提供了第一個嚴謹且最佳的漸近記憶體容量。(ii) 一個次線性時間演算法 $\mathtt{U}\text{-}\mathtt{Hop}$+，以達到 KHM 的最佳容量。(iii) 對所需特徵維度相對於儲存記憶體數量的縮放行為的分析。這些努力同時改善了 KHM 的檢索能力和對應Transformer的表徵學習。在實驗中，我們提供了詳盡的數值結果，以支持理論發現。

##### **On Memorization of Large Language Models in Logical Reasoning**
2410.23123v1 by Chulin Xie, Yangsibo Huang, Chiyuan Zhang, Da Yu, Xinyun Chen, Bill Yuchen Lin, Bo Li, Badih Ghazi, Ravi Kumar

Large language models (LLMs) achieve good performance on challenging
reasoning benchmarks, yet could also make basic reasoning mistakes. This
contrasting behavior is puzzling when it comes to understanding the mechanisms
behind LLMs' reasoning capabilities. One hypothesis is that the increasingly
high and nearly saturated performance on common reasoning benchmarks could be
due to the memorization of similar problems. In this paper, we systematically
investigate this hypothesis with a quantitative measurement of memorization in
reasoning tasks, using a dynamically generated logical reasoning benchmark
based on Knights and Knaves (K&K) puzzles. We found that LLMs could interpolate
the training puzzles (achieving near-perfect accuracy) after fine-tuning, yet
fail when those puzzles are slightly perturbed, suggesting that the models
heavily rely on memorization to solve those training puzzles. On the other
hand, we show that while fine-tuning leads to heavy memorization, it also
consistently improves generalization performance. In-depth analyses with
perturbation tests, cross difficulty-level transferability, probing model
internals, and fine-tuning with wrong answers suggest that the LLMs learn to
reason on K&K puzzles despite training data memorization. This phenomenon
indicates that LLMs exhibit a complex interplay between memorization and
genuine reasoning abilities. Finally, our analysis with per-sample memorization
score sheds light on how LLMs switch between reasoning and memorization in
solving logical puzzles. Our code and data are available at
https://memkklogic.github.io.

摘要：<paragraph>大型語言模型 (LLM) 在具挑戰性的推理基準上取得良好表現，但也會犯下基本的推理錯誤。這種對比行為令人費解，因為它涉及理解 LLM 推理能力背後的機制。一個假設是，在常見推理基準上越來越高且接近飽和的表現可能是由於記住了類似的問題。在本文中，我們使用基於騎士與惡棍 (K&K) 謎題的動態生成邏輯推理基準，對推理任務中的記憶進行定量測量，系統性地探討這個假設。我們發現，LLM 在微調後可以內插訓練謎題（達到接近完美的準確度），但在這些謎題稍有擾動時卻會失敗，這表明模型在很大程度上依賴記憶來解決這些訓練謎題。另一方面，我們表明，雖然微調會導致大量的記憶，但它也會持續改善泛化表現。使用擾動測試、跨難度級別的可傳遞性、探測模型內部結構以及使用錯誤答案進行微調的深入分析表明，LLM 學會了對 K&K 謎題進行推理，儘管訓練數據記憶。這種現象表明，LLM 在記憶和真正的推理能力之間表現出複雜的相互作用。最後，我們對每個樣本記憶分數的分析闡明了 LLM 在解決邏輯謎題時如何在推理和記憶之間切換。我們的程式碼和數據可在 https://memkklogic.github.io/ 獲得。</paragraph>

##### **Teaching a Language Model to Distinguish Between Similar Details using a Small Adversarial Training Set**
2410.23118v1 by Chris Achard

Language models can achieve high accuracy on natural language tasks such as
NLI, but performance suffers on manually created adversarial examples. We
investigate the performance of a language model trained on the Stanford Natural
Language Inference (SNLI) corpus on a manually created adversarial test set. We
then improve the model's performance by fine tuning the model on a small,
manually created adversarial training set, designed to help the language model
to learn to differentiate between similar words and phrases in the data. We
show an increase in accuracy on the adversarial test set (+ 13%) while still
maintaining good performance on the original NLI task. We also show an increase
in accuracy from 91.2% to 92.9% on the most similar contradictions in the SNLI
test set (as judged by cosine similarity).

摘要：語言模型在自然語言任務中，例如 NLI，可以達到很高的準確度，但效能會在人工建立的對抗範例中下降。我們研究在人工建立的對抗測試集中，針對在 Stanford 自然語言推理 (SNLI) 語料庫上訓練的語言模型的效能。然後，我們透過在小型的、人工建立的對抗訓練集中微調模型，來改善模型的效能，此訓練集旨在幫助語言模型學習區分資料中類似的字詞和片語。我們顯示在對抗測試集上的準確度提升（+ 13%），同時在原始 NLI 任務上仍然維持良好的效能。我們也顯示在 SNLI 測試集中最類似的矛盾上的準確度從 91.2% 提升到 92.9%（依據餘弦相似度判斷）。

##### **Unified Triplet-Level Hallucination Evaluation for Large Vision-Language Models**
2410.23114v1 by Junjie Wu, Tsz Ting Chung, Kai Chen, Dit-Yan Yeung

Despite the outstanding performance in vision-language reasoning, Large
Vision-Language Models (LVLMs) might generate hallucinated contents that do not
exist in the given image. Most existing LVLM hallucination benchmarks are
constrained to evaluate the object-related hallucinations. However, the
potential hallucination on the relations between two objects, i.e., relation
hallucination, still lacks investigation. To remedy that, in this paper we
design a unified framework to measure object and relation hallucination in
LVLMs simultaneously. The core idea of our framework is to conduct
hallucination evaluation on (object, relation, object) triplets extracted from
LVLMs' responses, and thus, could be easily generalized to different
vision-language tasks. Based on our framework, we further introduce Tri-HE, a
novel Triplet-level Hallucination Evaluation benchmark which can be used to
study both object and relation hallucination at the same time. We conduct
comprehensive evaluations on Tri-HE and observe that the relation hallucination
issue is even more serious than object hallucination among existing LVLMs,
highlighting a previously neglected problem towards reliable LVLMs. Moreover,
based on our findings, we design a simple yet effective training-free approach
to mitigate hallucinations for LVLMs, with which, we exceed all open-sourced
counterparts on Tri-HE, achieving comparable performance with the powerful
GPT-4V. Our dataset and code for the reproduction of our experiments are
available publicly at https://github.com/wujunjie1998/Tri-HE.

摘要：儘管在視覺語言推理中表現傑出，大型視覺語言模型 (LVLMs) 仍可能產生不存在於給定影像中的幻覺內容。大多數現有的 LVLM 幻覺基準僅限於評估與物件相關的幻覺。然而，對於兩個物件之間關係的潛在幻覺，即關係幻覺，仍缺乏調查。為了補救這一點，在本文中，我們設計了一個統一的架構，以同時測量 LVLMs 中的物件和關係幻覺。我們架構的核心思想是在從 LVLMs 回應中提取的 (物件、關係、物件) 三元組上進行幻覺評估，因此可以輕鬆地概括為不同的視覺語言任務。根據我們的架構，我們進一步引入了 Tri-HE，這是一個新穎的三元組級幻覺評估基準，可用於同時研究物件和關係幻覺。我們對 Tri-HE 進行了全面的評估，並觀察到關係幻覺問題甚至比現有 LVLMs 中的物件幻覺更嚴重，突顯了一個以前被忽略的問題，朝著可靠的 LVLMs 邁進。此外，根據我們的發現，我們設計了一個簡單但有效的無訓練方法來減輕 LVLMs 的幻覺，我們使用它在 Tri-HE 上超越了所有開源對手，達到了與強大的 GPT-4V 相當的效能。我們用於重現我們實驗的資料集和程式碼可在 https://github.com/wujunjie1998/Tri-HE 公開取得。

##### **Why Gradient Subspace? Identifying and Mitigating LoRA's Bottlenecks in Federated Fine-Tuning of Large Language Models**
2410.23111v2 by Navyansh Mahla, Ganesh Ramakrishnan

Large Language Models (LLMs) have demonstrated remarkable capabilities across
various domains, particularly in task generalization for both text and vision
data. While fine-tuning these models can significantly enhance their
performance on specific downstream tasks, it often requires high-quality data
that cannot be shared due to privacy concerns. Federated Learning (FL) offers a
promising solution for collaborative training without direct data sharing.
However, many parameter-efficient fine-tuning strategies for LLMs in FL,
particularly those based on Low-Rank Adaptation (LoRA), face limitations. In
this paper, we critically analyze the convergence and performance guarantees of
popular FL frameworks utilizing LoRA, highlighting its suboptimal nature due to
constrained subspace learning of low-rank matrices. This limitation hinders
effective fine-tuning of LLMs in federated settings. Through rigorous
analytical and empirical evaluations, we demonstrate that direct weight
averaging outperforms LoRA-based strategies, leading to superior performance
for fine-tuned models. Our comprehensive comparison exposes inefficiencies in
LoRA approaches and underscores the advantages of direct weight aggregation. We
extend our analysis to low-rank gradient-based optimizers, such as GaLore, used
during local training steps. Our findings show that GaLore is a more effective
alternative, outperforming federated LoRA methods like FlexLoRA and FFA-LoRA
across both text and image modalities. While privacy remains paramount in FL
discourse, our focus is on assessing performance outcomes of federated
fine-tuned models and evaluating various FL frameworks from both theoretical
and empirical perspectives. Our findings advocate reassessing the reliance on
LoRA within FL contexts, paving the way for more efficient training
methodologies.

摘要：大型語言模型 (LLM) 已在各種領域展現出非凡的能力，特別是在文本和視覺資料的任務概括方面。雖然微調這些模型可以顯著提升其在特定下游任務中的效能，但這通常需要高品質的資料，而這些資料可能無法因隱私考量而共用。聯合學習 (FL) 提供了一個有前途的解決方案，可以進行協作訓練，而無需直接共用資料。然而，許多針對 LLM 在 FL 中的參數有效微調策略，特別是那些基於低秩適應 (LoRA) 的策略，都面臨限制。在本文中，我們批判性地分析了使用 LoRA 的熱門 FL 架構的收斂性和效能保證，並強調其次佳性質，原因在於低秩矩陣的受限子空間學習。此限制阻礙了在聯合設定中對 LLM 進行有效的微調。透過嚴謹的分析和經驗評估，我們證明直接權重平均優於基於 LoRA 的策略，從而提升微調模型的效能。我們的全面比較揭露了 LoRA 方法的低效率，並強調了直接權重聚合的優點。我們將分析延伸至低秩基於梯度的最佳化器，例如 GaLore，這些最佳化器用於局部訓練步驟。我們的發現顯示，GaLore 是一種更有效的替代方案，在文本和影像模式中都優於聯合 LoRA 方法，例如 FlexLoRA 和 FFA-LoRA。雖然隱私在 FL 論述中仍然至關重要，但我們的重點在於評估聯合微調模型的效能結果，並從理論和經驗的角度評估各種 FL 架構。我們的發現主張重新評估在 FL 背景中對 LoRA 的依賴，為更有效的訓練方法鋪路。

##### **Controllable Game Level Generation: Assessing the Effect of Negative Examples in GAN Models**
2410.23108v1 by Mahsa Bazzaz, Seth Cooper

Generative Adversarial Networks (GANs) are unsupervised models designed to
learn and replicate a target distribution. The vanilla versions of these models
can be extended to more controllable models. Conditional Generative Adversarial
Networks (CGANs) extend vanilla GANs by conditioning both the generator and
discriminator on some additional information (labels). Controllable models
based on complementary learning, such as Rumi-GAN, have been introduced.
Rumi-GANs leverage negative examples to enhance the generator's ability to
learn positive examples. We evaluate the performance of two controllable GAN
variants, CGAN and Rumi-GAN, in generating game levels targeting specific
constraints of interest: playability and controllability. This evaluation is
conducted under two scenarios: with and without the inclusion of negative
examples. The goal is to determine whether incorporating negative examples
helps the GAN models avoid generating undesirable outputs. Our findings
highlight the strengths and weaknesses of each method in enforcing the
generation of specific conditions when generating outputs based on given
positive and negative examples.

摘要：生成對抗網路 (GAN) 為非監督式模型，旨在學習並複製目標分配。這些模型的香草版本可延伸至更具可控性的模型。條件生成對抗網路 (CGAN) 透過在生成器和判別器中加入一些額外資訊 (標籤) 來延伸香草 GAN。已經引入了基於互補學習的可控模型，例如 Rumi-GAN。Rumi-GAN 利用負面範例來增強生成器學習正面範例的能力。我們評估了兩種可控 GAN 變體 (CGAN 和 Rumi-GAN) 在產生針對特定感興趣約束的遊戲關卡方面的效能：可玩性和可控性。此評估在兩種場景下進行：包含和不包含負面範例。目標是確定納入負面範例是否有助於 GAN 模型避免產生不良輸出。我們的研究結果突顯了每種方法在根據給定的正面和負面範例產生輸出時，在強制產生特定條件方面的優點和缺點。

##### **Guided Game Level Repair via Explainable AI**
2410.23101v1 by Mahsa Bazzaz, Seth Cooper

Procedurally generated levels created by machine learning models can be
unsolvable without further editing. Various methods have been developed to
automatically repair these levels by enforcing hard constraints during the
post-processing step. However, as levels increase in size, these
constraint-based repairs become increasingly slow. This paper proposes using
explainability methods to identify specific regions of a level that contribute
to its unsolvability. By assigning higher weights to these regions,
constraint-based solvers can prioritize these problematic areas, enabling more
efficient repairs. Our results, tested across three games, demonstrate that
this approach can help to repair procedurally generated levels faster.

摘要：機器學習模型產生的程序化生成關卡在未經進一步編輯的情況下可能無法解決。已經開發出各種方法，透過在後處理步驟中強制執行硬約束來自動修復這些關卡。然而，隨著關卡尺寸增加，這些基於約束的修復變得越來越慢。本文提出使用可解釋性方法來識別關卡中導致無法解決的特定區域。透過將較高的權重分配給這些區域，基於約束的求解器可以優先處理這些有問題的區域，從而實現更有效的修復。我們的結果在三款遊戲中進行了測試，證明了這種方法有助於更快地修復程序化生成的關卡。

##### **Comparative Analysis of Demonstration Selection Algorithms for LLM In-Context Learning**
2410.23099v1 by Dong Shu, Mengnan Du

In-context learning can help Large Language Models (LLMs) to adapt new tasks
without additional training. However, this performance heavily depends on the
quality of the demonstrations, driving research into effective demonstration
selection algorithms to optimize this process. These algorithms assist users in
selecting the best $k$ input-label pairs (demonstration examples) based on a
given test input, enabling LLMs to in-context learn the relationship between
the provided examples and the test inputs. Despite all the proposed
demonstration selection algorithms, their efficiency and effectiveness remain
unclear. This lack of clarity make it difficult to apply these algorithms in
real-world scenarios and poses challenges for future research aimed at
developing improved methods. This paper revisits six proposed algorithms,
evaluating them on five datasets from both efficiency and effectiveness
perspectives. Our experiments reveal significant variations in algorithm
performance across different tasks, with some methods struggling to outperform
random selection in certain scenarios. We also find that increasing the number
of demonstrations does not always lead to better performance, and that there
are often trade-offs between accuracy and computational efficiency. Our code is
available at https://github.com/Tizzzzy/Demonstration_Selection_Overview.

摘要：情境學習可以幫助大型語言模型 (LLM) 適應新任務，而無需額外訓練。然而，此效能極度仰賴示範品質，驅使研究人員投入有效示範選擇演算法的研究，以最佳化此程序。這些演算法協助使用者根據特定測試輸入，從最佳的 $k$ 個輸入標籤配對（示範範例）中進行選擇，讓 LLM 能夠在情境中學習提供的範例與測試輸入之間的關係。儘管提出了所有可能的示範選擇演算法，但其效率和效能仍不明朗。這種不確定性使得在真實世界情境中應用這些演算法變得困難，並對旨在開發改良方法的未來研究構成挑戰。本文回顧了六種提出的演算法，從效率和效能兩個角度，在五個資料集上對它們進行評估。我們的實驗揭示了演算法效能因任務而異的顯著差異，有些方法在某些情境下難以勝過隨機選擇。我們也發現，增加示範數量並非總是會帶來更好的效能，而且準確性和運算效率之間通常存在權衡取捨。我們的程式碼可於 https://github.com/Tizzzzy/Demonstration_Selection_Overview 取得。

##### **CORAL: Benchmarking Multi-turn Conversational Retrieval-Augmentation Generation**
2410.23090v1 by Yiruo Cheng, Kelong Mao, Ziliang Zhao, Guanting Dong, Hongjin Qian, Yongkang Wu, Tetsuya Sakai, Ji-Rong Wen, Zhicheng Dou

Retrieval-Augmented Generation (RAG) has become a powerful paradigm for
enhancing large language models (LLMs) through external knowledge retrieval.
Despite its widespread attention, existing academic research predominantly
focuses on single-turn RAG, leaving a significant gap in addressing the
complexities of multi-turn conversations found in real-world applications. To
bridge this gap, we introduce CORAL, a large-scale benchmark designed to assess
RAG systems in realistic multi-turn conversational settings. CORAL includes
diverse information-seeking conversations automatically derived from Wikipedia
and tackles key challenges such as open-domain coverage, knowledge intensity,
free-form responses, and topic shifts. It supports three core tasks of
conversational RAG: passage retrieval, response generation, and citation
labeling. We propose a unified framework to standardize various conversational
RAG methods and conduct a comprehensive evaluation of these methods on CORAL,
demonstrating substantial opportunities for improving existing approaches.

摘要：檢索增強生成（RAG）已成為一種強大的範例，可透過外部知識檢索增強大型語言模型（LLM）。儘管受到廣泛關注，現有的學術研究主要集中於單回合 RAG，在處理真實世界應用中發現的多回合對話的複雜性方面存在顯著差距。為了彌合這個差距，我們引入了 CORAL，這是一個大規模基準，旨在評估 RAG 系統在現實的多回合對話設置中的表現。CORAL 包括從維基百科自動衍生的各種資訊尋求對話，並應對開放領域涵蓋範圍、知識強度、自由形式回應和主題轉換等關鍵挑戰。它支援對話 RAG 的三項核心任務：段落檢索、回應生成和引文標記。我們提出了一個統一的框架來標準化各種對話 RAG 方法，並對這些方法在 CORAL 上進行全面評估，展示了改進現有方法的重大機會。

##### **BUZZ: Beehive-structured Sparse KV Cache with Segmented Heavy Hitters for Efficient LLM Inference**
2410.23079v1 by Junqi Zhao, Zhijin Fang, Shu Li, Shaohui Yang, Shichao He

Large language models (LLMs) are essential in natural language processing but
often struggle with inference speed and computational efficiency, limiting
real-time deployment. The key-value (KV) cache mechanism reduces computational
overhead in transformer models, but challenges in maintaining contextual
understanding remain. In this paper, we propose BUZZ, a novel KV caching
algorithm that leverages structured contextual information to minimize cache
memory usage while enhancing inference speed. BUZZ employs a beehive-structured
sparse cache, incorporating a sliding window to capture recent information and
dynamically segmenting historical tokens into chunks to prioritize important
tokens in local neighborhoods. We evaluate BUZZ on four real-world datasets:
CNN/Daily Mail, XSUM, Wikitext, and 10-QA. Our results demonstrate that BUZZ
(1) reduces cache memory usage by $\textbf{2.5}\times$ in LLM inference while
maintaining over 99% accuracy in long-text summarization, and (2) surpasses
state-of-the-art performance in multi-document question answering by
$\textbf{7.69%}$ under the same memory limit, where full cache methods
encounter out-of-memory issues. Additionally, BUZZ achieves significant
inference speedup with a $\log{n}$ time complexity. The code is available at
https://github.com/JunqiZhao888/buzz-llm.

摘要：大型語言模型 (LLM) 在自然語言處理中至關重要，但
通常難以兼顧推論速度和運算效率，限制了
即時部署。快取機制中的鍵值 (KV) 減少了轉換器模型中的運算
開銷，但在維護上下文理解方面仍然存在挑戰。在本文中，我們提出
BUZZ，這是一種新穎的 KV 快取演算法，利用結構化上下文資訊來
最小化快取記憶體使用量，同時提高推論速度。BUZZ 採用蜂巢結構
稀疏快取，結合滑動視窗來擷取最新資訊，並動態將歷史代幣分段成
塊，以優先處理鄰近區域中的重要代幣。我們在四個真實世界資料集上
評估 BUZZ：CNN/Daily Mail、XSUM、Wikitext 和 10-QA。我們的結果證明
BUZZ (1) 在 LLM 推論中將快取記憶體使用量減少了 $\textbf{2.5}\times$，同時
在長文本摘要中維持超過 99% 的準確度，以及 (2) 在相同的記憶體限制下，
超越了多文件問答的最新技術，提升了 $\textbf{7.69%}$，而完整快取方法
則會遇到記憶體不足的問題。此外，BUZZ 以 $\log{n}$ 時間複雜度實現了
顯著的推論速度提升。程式碼可在 https://github.com/JunqiZhao888/buzz-llm 取得。

##### **Multi-Programming Language Sandbox for LLMs**
2410.23074v1 by Shihan Dou, Jiazheng Zhang, Jianxiang Zang, Yunbo Tao, Haoxiang Jia, Shichun Liu, Yuming Yang, Shenxi Wu, Shaoqing Zhang, Muling Wu, Changze Lv, Limao Xiong, Wenyu Zhan, Lin Zhang, Rongxiang Weng, Jingang Wang, Xunliang Cai, Yueming Wu, Ming Wen, Rui Zheng, Tao Ji, Yixin Cao, Tao Gui, Xipeng Qiu, Qi Zhang, Xuanjing Huang

We introduce MPLSandbox, an out-of-the-box multi-programming language sandbox
designed to provide unified and comprehensive feedback from compiler and
analysis tools for Large Language Models (LLMs). It can automatically identify
the programming language of the code, compiling and executing it within an
isolated sub-sandbox to ensure safety and stability. In addition, MPLSandbox
also integrates both traditional and LLM-based code analysis tools, providing a
comprehensive analysis of generated code. MPLSandbox can be effortlessly
integrated into the training and deployment of LLMs to improve the quality and
correctness of their generated code. It also helps researchers streamline their
workflows for various LLM-based code-related tasks, reducing the development
cost. To validate the effectiveness of MPLSandbox, we integrate it into
training and deployment approaches, and also employ it to optimize workflows
for a wide range of real-world code-related tasks. Our goal is to enhance
researcher productivity on LLM-based code-related tasks by simplifying and
automating workflows through delegation to MPLSandbox.

摘要：<paragraph>我們推出 MPLSandbox，一個開箱即用的多程式語言沙盒，旨在提供來自編譯器和分析工具的統一且全面的回饋，以供大型語言模型 (LLM) 使用。它可以自動識別程式碼的程式語言，在一個隔離的子沙盒中編譯和執行它，以確保安全性和穩定性。此外，MPLSandbox 還整合了傳統和基於 LLM 的程式碼分析工具，提供對生成程式碼的全面分析。MPLSandbox 可以輕鬆整合到 LLM 的訓練和部署中，以提高其生成程式碼的品質和正確性。它還可以幫助研究人員簡化其各種基於 LLM 的程式碼相關任務的工作流程，從而降低開發成本。為了驗證 MPLSandbox 的有效性，我們將其整合到訓練和部署方法中，並使用它來最佳化各種實際程式碼相關任務的工作流程。我們的目標是透過委派給 MPLSandbox 來簡化和自動化工作流程，進而提升研究人員在基於 LLM 的程式碼相關任務上的生產力。</paragraph>

##### **CNN Explainability with Multivector Tucker Saliency Maps for Self-Supervised Models**
2410.23072v1 by Aymene Mohammed Bouayed, Samuel Deslauriers-Gauthier, Adrian Iaccovelli, David Naccache

Interpreting the decisions of Convolutional Neural Networks (CNNs) is
essential for understanding their behavior, yet explainability remains a
significant challenge, particularly for self-supervised models. Most existing
methods for generating saliency maps rely on ground truth labels, restricting
their use to supervised tasks. EigenCAM is the only notable label-independent
alternative, leveraging Singular Value Decomposition to generate saliency maps
applicable across CNN models, but it does not fully exploit the tensorial
structure of feature maps. In this work, we introduce the Tucker Saliency Map
(TSM) method, which applies Tucker tensor decomposition to better capture the
inherent structure of feature maps, producing more accurate singular vectors
and values. These are used to generate high-fidelity saliency maps, effectively
highlighting objects of interest in the input. We further extend EigenCAM and
TSM into multivector variants -Multivec-EigenCAM and Multivector Tucker
Saliency Maps (MTSM)- which utilize all singular vectors and values, further
improving saliency map quality. Quantitative evaluations on supervised
classification models demonstrate that TSM, Multivec-EigenCAM, and MTSM achieve
competitive performance with label-dependent methods. Moreover, TSM enhances
explainability by approximately 50% over EigenCAM for both supervised and
self-supervised models. Multivec-EigenCAM and MTSM further advance
state-of-the-art explainability performance on self-supervised models, with
MTSM achieving the best results.

摘要：詮釋卷積神經網路 (CNN) 的決策對於理解其行為至關重要，然而可解釋性仍然是一項重大的挑戰，特別是對於自監督模型。現有的大多數生成顯著性圖的方法依賴於真實標籤，將其使用限制在監督式任務中。EigenCAM 是唯一值得注意的標籤無關替代方案，利用奇異值分解來生成適用於所有 CNN 模型的顯著性圖，但它並未充分利用特徵圖的張量結構。在這項工作中，我們引入了塔克顯著性圖 (TSM) 方法，該方法應用塔克張量分解以更好地捕捉特徵圖的內在結構，產生更準確的奇異向量和值。這些用於生成高保真顯著性圖，有效地突顯輸入中的感興趣對象。我們進一步將 EigenCAM 和 TSM 擴展到多向量變體 - 多向量 EigenCAM 和多向量塔克顯著性圖 (MTSM) - 利用所有奇異向量和值，進一步提高顯著性圖的品質。在監督式分類模型上的定量評估表明，TSM、多向量 EigenCAM 和 MTSM 與標籤依賴方法相比，達到了競爭性的效能。此外，TSM 對監督式和自監督式模型的解釋性比 EigenCAM 提高了大約 50%。多向量 EigenCAM 和 MTSM 進一步提升了自監督式模型的現有最佳解釋性效能，其中 MTSM 達到了最佳結果。

##### **LLMs Integration in Software Engineering Team Projects: Roles, Impact, and a Pedagogical Design Space for AI Tools in Computing Education**
2410.23069v1 by Ahmed Kharrufa, Sami Alghamdi, Abeer Aziz, Christopher Bull

This work takes a pedagogical lens to explore the implications of generative
AI (GenAI) models and tools, such as ChatGPT and GitHub Copilot, in a
semester-long 2nd-year undergraduate Software Engineering Team Project.
Qualitative findings from survey (39 students) and interviews (eight students)
provide insights into the students' views on the impact of GenAI use on their
coding experience, learning, and self-efficacy. Our results address a
particular gap in understanding the role and implications of GenAI on teamwork,
team-efficacy, and team dynamics. The analysis of the learning aspects is
distinguished by the application of learning and pedagogy informed lenses to
discuss the data. We propose a preliminary design space for GenAI-based
programming learning tools highlighting the importance of considering the roles
that GenAI can play during the learning process, the varying support-ability
patterns that can be applied to each role, and the importance of supporting
transparency in GenAI for team members and students in addition to educators.

摘要：本研究以教學觀點探討生成式 AI (GenAI) 模型和工具（例如 ChatGPT 和 GitHub Copilot）在為期一學期的二年級大學部軟體工程團隊專題中的影響。
來自問卷調查（39 位學生）和訪談（8 位學生）的定性發現，提供了學生對 GenAI 使用對其程式編寫經驗、學習和自我效能影響的見解。我們的結果探討了在理解 GenAI 在團隊合作、團隊效能和團隊動力中的角色和影響方面的特定差距。學習面向的分析以應用學習和教學法觀點來探討資料為特色。我們提出了一個基於 GenAI 的程式設計學習工具的初步設計空間，強調考慮 GenAI 在學習過程中可以扮演的角色、可以應用於每個角色的不同支援能力模式，以及除了教育工作者之外，支援團隊成員和學生對 GenAI 的透明度的重要性。

##### **Don't Just Pay Attention, PLANT It: Transfer L2R Models to Fine-tune Attention in Extreme Multi-Label Text Classification**
2410.23066v1 by Debjyoti Saharoy, Javed A. Aslam, Virgil Pavlu

State-of-the-art Extreme Multi-Label Text Classification (XMTC) models rely
heavily on multi-label attention layers to focus on key tokens in input text,
but obtaining optimal attention weights is challenging and resource-intensive.
To address this, we introduce PLANT -- Pretrained and Leveraged AtteNTion -- a
novel transfer learning strategy for fine-tuning XMTC decoders. PLANT surpasses
existing state-of-the-art methods across all metrics on mimicfull, mimicfifty,
mimicfour, eurlex, and wikiten datasets. It particularly excels in few-shot
scenarios, outperforming previous models specifically designed for few-shot
scenarios by over 50 percentage points in F1 scores on mimicrare and by over 36
percentage points on mimicfew, demonstrating its superior capability in
handling rare codes. PLANT also shows remarkable data efficiency in few-shot
scenarios, achieving precision comparable to traditional models with
significantly less data. These results are achieved through key technical
innovations: leveraging a pretrained Learning-to-Rank model as the planted
attention layer, integrating mutual-information gain to enhance attention,
introducing an inattention mechanism, and implementing a stateful-decoder to
maintain context. Comprehensive ablation studies validate the importance of
these contributions in realizing the performance gains.

摘要：最先进的極端多標籤文本分類 (XMTC) 模型高度依賴多標籤注意力層，以關注輸入文本中的關鍵代碼，但取得最佳注意力權重具有挑戰性且耗費資源。為了解決這個問題，我們引入了 PLANT（預訓練和槓桿注意力）——一種針對微調 XMTC 解碼器的新穎的遷移學習策略。PLANT 在 mimicfull、mimicfifty、mimicfour、eurlex 和 wikiten 資料集的所有指標上都超越了現有的最先進方法。它在少次嘗試的場景中特別出色，在 mimicrare 上的 F1 分數比專門為少次嘗試的場景設計的先前模型高出 50 個百分點，在 mimicfew 上高出 36 個百分點，證明了其在處理罕見代碼方面的卓越能力。PLANT 在少次嘗試的場景中也展現了顯著的資料效率，達到了與傳統模型相當的精度，而資料卻少得多。這些成果是通過關鍵技術創新實現的：利用預訓練的學習排名模型作為植入的注意力層，整合互資訊增益以增強注意力，引入不注意力機制，並實作有狀態解碼器以維護上下文。全面的消融研究驗證了這些貢獻在實現效能提升方面的重要性。

##### **Controlling Language and Diffusion Models by Transporting Activations**
2410.23054v1 by Pau Rodriguez, Arno Blaas, Michal Klein, Luca Zappella, Nicholas Apostoloff, Marco Cuturi, Xavier Suau

The increasing capabilities of large generative models and their ever more
widespread deployment have raised concerns about their reliability, safety, and
potential misuse. To address these issues, recent works have proposed to
control model generation by steering model activations in order to effectively
induce or prevent the emergence of concepts or behaviors in the generated
output. In this paper we introduce Activation Transport (AcT), a general
framework to steer activations guided by optimal transport theory that
generalizes many previous activation-steering works. AcT is modality-agnostic
and provides fine-grained control over the model behavior with negligible
computational overhead, while minimally impacting model abilities. We
experimentally show the effectiveness and versatility of our approach by
addressing key challenges in large language models (LLMs) and text-to-image
diffusion models (T2Is). For LLMs, we show that AcT can effectively mitigate
toxicity, induce arbitrary concepts, and increase their truthfulness. In T2Is,
we show how AcT enables fine-grained style control and concept negation.

摘要：大型生成模型功能日益强大，其部署也日益广泛，这引发了人们对其可靠性、安全性及潜在滥用的担忧。为了解决这些问题，最近的研究提出了通过控制模型激活来控制模型生成，以便有效地诱导或阻止概念或行为在生成输出中出现。在本文中，我们介绍了激活传输 (AcT)，这是一个通用框架，用于通过最优传输理论指导激活，从而概括了许多先前的激活控制工作。AcT 与模态无关，并且可以对模型行为进行细粒度控制，而计算开销可以忽略不计，同时对模型能力的影响最小。我们通过解决大型语言模型 (LLM) 和文本到图像扩散模型 (T2I) 中的关键挑战，通过实验展示了我们方法的有效性和多功能性。对于 LLM，我们展示了 AcT 可以有效减轻毒性，诱导任意概念并提高其真实性。在 T2I 中，我们展示了 AcT 如何实现细粒度的样式控制和概念否定。

##### **Emotional RAG: Enhancing Role-Playing Agents through Emotional Retrieval**
2410.23041v1 by Le Huang, Hengzhi Lan, Zijun Sun, Chuan Shi, Ting Bai

As LLMs exhibit a high degree of human-like capability, increasing attention
has been paid to role-playing research areas in which responses generated by
LLMs are expected to mimic human replies. This has promoted the exploration of
role-playing agents in various applications, such as chatbots that can engage
in natural conversations with users and virtual assistants that can provide
personalized support and guidance. The crucial factor in the role-playing task
is the effective utilization of character memory, which stores characters'
profiles, experiences, and historical dialogues. Retrieval Augmented Generation
(RAG) technology is used to access the related memory to enhance the response
generation of role-playing agents. Most existing studies retrieve related
information based on the semantic similarity of memory to maintain characters'
personalized traits, and few attempts have been made to incorporate the
emotional factor in the retrieval argument generation (RAG) of LLMs. Inspired
by the Mood-Dependent Memory theory, which indicates that people recall an
event better if they somehow reinstate during recall the original emotion they
experienced during learning, we propose a novel emotion-aware memory retrieval
framework, termed Emotional RAG, which recalls the related memory with
consideration of emotional state in role-playing agents. Specifically, we
design two kinds of retrieval strategies, i.e., combination strategy and
sequential strategy, to incorporate both memory semantic and emotional states
during the retrieval process. Extensive experiments on three representative
role-playing datasets demonstrate that our Emotional RAG framework outperforms
the method without considering the emotional factor in maintaining the
personalities of role-playing agents. This provides evidence to further
reinforce the Mood-Dependent Memory theory in psychology.

摘要：隨著大型語言模型展現高度擬人的能力，人們越來越重視角色扮演的研究領域，其中大型語言模型產生的回應預期將模擬人類的回覆。這促使人們探索在各種應用程式中使用角色扮演代理，例如能夠與使用者進行自然對話的聊天機器人，以及能夠提供個人化支援和指導的虛擬助理。角色扮演任務中的關鍵因素是有效利用角色記憶，其中儲存了角色的個人資料、經驗和歷史對話。檢索增強生成 (RAG) 技術用於存取相關記憶，以增強角色扮演代理的回應產生。現有研究大多根據記憶的語義相似性來檢索相關資訊，以維持角色的個性化特質，很少嘗試在大型語言模型的檢索論證產生 (RAG) 中納入情緒因素。受到情緒依賴記憶理論的啟發（該理論指出，如果人們在回憶時以某種方式恢復學習時經歷的原始情緒，他們就能更好地回憶起某個事件），我們提出了一個新的情緒感知記憶檢索架構，稱為情緒 RAG，它在角色扮演代理中考慮情緒狀態來回憶相關記憶。具體來說，我們設計了兩種檢索策略，即組合策略和順序策略，以便在檢索過程中納入記憶語義和情緒狀態。在三個具代表性的角色扮演資料集上進行的廣泛實驗表明，我們的 Emotional RAG 架構在維持角色扮演代理個性方面優於不考慮情緒因素的方法。這提供了證據，進一步強化了心理學中的情緒依賴記憶理論。

##### **Offline Reinforcement Learning and Sequence Modeling for Downlink Link Adaptation**
2410.23031v1 by Samuele Peri, Alessio Russo, Gabor Fodor, Pablo Soldati

Contemporary radio access networks employ link adaption (LA) algorithms to
optimize the modulation and coding schemes to adapt to the prevailing
propagation conditions and are near-optimal in terms of the achieved spectral
efficiency. LA is a challenging task in the presence of mobility, fast fading,
and imperfect channel quality information and limited knowledge of the receiver
characteristics at the transmitter, which render model-based LA algorithms
complex and suboptimal. Model-based LA is especially difficult as connected
user equipment devices become increasingly heterogeneous in terms of receiver
capabilities, antenna configurations and hardware characteristics. Recognizing
these difficulties, previous works have proposed reinforcement learning (RL)
for LA, which faces deployment difficulties due to their potential negative
impacts on live performance. To address this challenge, this paper considers
offline RL to learn LA policies from data acquired in live networks with
minimal or no intrusive effects on the network operation. We propose three LA
designs based on batch-constrained deep Q-learning, conservative Q-learning,
and decision transformers, showing that offline RL algorithms can achieve
performance of state-of-the-art online RL methods when data is collected with a
proper behavioral policy.

摘要：現代無線存取網路採用連結適應 (LA) 演算法來最佳化調變和編碼架構，以適應現行的傳播條件，且在達成的頻譜效率方面接近最佳。LA 在流動性、快速衰落、不完美的頻道品質資訊和發射器對接收器特性了解有限的情況下是一項具有挑戰性的任務，這使得基於模型的 LA 演算法複雜且次最佳。隨著連接的使用者設備在接收器能力、天線組態和硬體特性方面變得越來越異質，基於模型的 LA 變得特別困難。認識到這些困難，先前的研究提出了用於 LA 的強化學習 (RL)，由於其對現場效能的潛在負面影響，因此在部署上存在困難。為了應對這一挑戰，本文考慮離線 RL 從現場網路中獲取的資料中學習 LA 策略，對網路運作的侵入性影響極小或沒有。我們提出三種基於批次約束深度 Q 學習、保守 Q 學習和決策轉換器的 LA 設計，表明離線 RL 演算法在使用適當的行為策略收集資料時，可以達到最先進的線上 RL 方法的效能。

##### **Online Intrinsic Rewards for Decision Making Agents from Large Language Model Feedback**
2410.23022v1 by Qinqing Zheng, Mikael Henaff, Amy Zhang, Aditya Grover, Brandon Amos

Automatically synthesizing dense rewards from natural language descriptions
is a promising paradigm in reinforcement learning (RL), with applications to
sparse reward problems, open-ended exploration, and hierarchical skill design.
Recent works have made promising steps by exploiting the prior knowledge of
large language models (LLMs). However, these approaches suffer from important
limitations: they are either not scalable to problems requiring billions of
environment samples; or are limited to reward functions expressible by compact
code, which may require source code and have difficulty capturing nuanced
semantics; or require a diverse offline dataset, which may not exist or be
impossible to collect. In this work, we address these limitations through a
combination of algorithmic and systems-level contributions. We propose ONI, a
distributed architecture that simultaneously learns an RL policy and an
intrinsic reward function using LLM feedback. Our approach annotates the
agent's collected experience via an asynchronous LLM server, which is then
distilled into an intrinsic reward model. We explore a range of algorithmic
choices for reward modeling with varying complexity, including hashing,
classification, and ranking models. By studying their relative tradeoffs, we
shed light on questions regarding intrinsic reward design for sparse reward
problems. Our approach achieves state-of-the-art performance across a range of
challenging, sparse reward tasks from the NetHack Learning Environment in a
simple unified process, solely using the agent's gathered experience, without
requiring external datasets nor source code. We make our code available at
\url{URL} (coming soon).

摘要：自動從自然語言描述中綜合出密集的獎勵
是強化學習（RL）中一個有前途的範例，應用於
稀疏獎勵問題、開放式探索和層次技能設計。
最近的工作通過利用大語言模型（LLM）的先驗知識取得了有希望的進展。然而，這些方法存在重要的
限制：它們要么無法擴展到需要數十億個
環境樣本的問題；要么僅限於用緊湊
代碼表達的獎勵函數，這可能需要源代碼並且難以捕捉細微差別
語義；或需要多樣化的離線數據集，這可能不存在或無法
收集。在這項工作中，我們通過結合演算法和系統級別的貢獻來解決這些限制。我們提出 ONI，一個
分佈式架構，它同時使用 LLM 反饋學習 RL 策略和內在獎勵函數。我們的做法通過非同步 LLM 伺服器註解代理收集的經驗，然後
將其提煉成一個內在獎勵模型。我們探索了一系列具有不同複雜度的獎勵建模演算法
選擇，包括雜湊、分類和排名模型。通過研究它們的相對權衡，我們
闡明了有關稀疏獎勵問題的內在獎勵設計的問題。我們的做法在 NetHack 學習環境中的一系列具有挑戰性的稀疏獎勵任務中實現了最先進的性能，在一個簡單的統一過程中，僅使用代理收集的經驗，而無需
需要外部數據集或源代碼。我們在
\url{URL}（即將推出）上提供我們的代碼。

##### **Long$^2$RAG: Evaluating Long-Context & Long-Form Retrieval-Augmented Generation with Key Point Recall**
2410.23000v2 by Zehan Qi, Rongwu Xu, Zhijiang Guo, Cunxiang Wang, Hao Zhang, Wei Xu

Retrieval-augmented generation (RAG) is a promising approach to address the
limitations of fixed knowledge in large language models (LLMs). However,
current benchmarks for evaluating RAG systems suffer from two key deficiencies:
(1) they fail to adequately measure LLMs' capability in handling long-context
retrieval due to a lack of datasets that reflect the characteristics of
retrieved documents, and (2) they lack a comprehensive evaluation method for
assessing LLMs' ability to generate long-form responses that effectively
exploits retrieved information. To address these shortcomings, we introduce the
Long$^2$RAG benchmark and the Key Point Recall (KPR) metric. Long$^2$RAG
comprises 280 questions spanning 10 domains and across 8 question categories,
each associated with 5 retrieved documents with an average length of 2,444
words. KPR evaluates the extent to which LLMs incorporate key points extracted
from the retrieved documents into their generated responses, providing a more
nuanced assessment of their ability to exploit retrieved information.

摘要：檢索增強生成 (RAG) 是一種有前途的方法，可用於解決大型語言模型 (LLM) 中固定知識的限制。然而，當前用於評估 RAG 系統的基準有兩個主要的缺點：(1) 由於缺乏反映檢索文件特徵的資料集，它們無法充分衡量 LLM 在處理長內容檢索中的能力，以及 (2) 它們缺乏全面的評估方法，用於評估 LLM 生成長篇回應的能力，這些回應有效地利用了檢索到的資訊。為了解決這些缺點，我們引入了 Long$^2$RAG 基準和關鍵點召回率 (KPR) 度量。Long$^2$RAG 包含 280 個問題，涵蓋 10 個領域和 8 個問題類別，每個問題都與 5 個檢索到的文件關聯，平均長度為 2,444 個字元。KPR 評估了 LLM 將從檢索到的文件提取的關鍵點納入其生成回應的程度，提供了對其利用檢索資訊能力更細緻的評估。

##### **A Comparison of Prompt Engineering Techniques for Task Planning and Execution in Service Robotics**
2410.22997v1 by Jonas Bode, Bastian Pätzold, Raphael Memmesheimer, Sven Behnke

Recent advances in LLM have been instrumental in autonomous robot control and
human-robot interaction by leveraging their vast general knowledge and
capabilities to understand and reason across a wide range of tasks and
scenarios. Previous works have investigated various prompt engineering
techniques for improving the performance of \glspl{LLM} to accomplish tasks,
while others have proposed methods that utilize LLMs to plan and execute tasks
based on the available functionalities of a given robot platform. In this work,
we consider both lines of research by comparing prompt engineering techniques
and combinations thereof within the application of high-level task planning and
execution in service robotics. We define a diverse set of tasks and a simple
set of functionalities in simulation, and measure task completion accuracy and
execution time for several state-of-the-art models.

摘要：近年來，LLM 的進展對於自主機器人控制和人機互動至關重要，利用其廣泛的常識和能力來理解和推理各種任務和場景。先前的研究調查了各種提示工程技術，以提高 LLM 的效能來完成任務，而其他人則提出了利用 LLM 來規劃和執行任務的方法，這些方法基於給定機器人平台的可用功能。在這項工作中，我們透過比較提示工程技術及其在服務機器人中高階任務規劃和執行的應用中的組合，來考量這兩條研究路線。我們在模擬中定義了一組多樣化的任務和一組簡單的功能，並測量了幾個最先進模型的任務完成準確度和執行時間。

##### **Semantic Enrichment of the Quantum Cascade Laser Properties in Text- A Knowledge Graph Generation Approach**
2410.22996v1 by Deperias Kerre, Anne Laurent, Kenneth Maussang, Dickson Owuor

A well structured collection of the various Quantum Cascade Laser (QCL)
design and working properties data provides a platform to analyze and
understand the relationships between these properties. By analyzing these
relationships, we can gain insights into how different design features impact
laser performance properties such as the working temperature. Most of these QCL
properties are captured in scientific text. There is therefore need for
efficient methodologies that can be utilized to extract QCL properties from
text and generate a semantically enriched and interlinked platform where the
properties can be analyzed to uncover hidden relations. There is also the need
to maintain provenance and reference information on which these properties are
based. Semantic Web technologies such as Ontologies and Knowledge Graphs have
proven capability in providing interlinked data platforms for knowledge
representation in various domains. In this paper, we propose an approach for
generating a QCL properties Knowledge Graph (KG) from text for semantic
enrichment of the properties. The approach is based on the QCL ontology and a
Retrieval Augmented Generation (RAG) enabled information extraction pipeline
based on GPT 4-Turbo language model. The properties of interest include:
working temperature, laser design type, lasing frequency, laser optical power
and the heterostructure. The experimental results demonstrate the feasibility
and effectiveness of this approach for efficiently extracting QCL properties
from unstructured text and generating a QCL properties Knowledge Graph, which
has potential applications in semantic enrichment and analysis of QCL data.

摘要：一個結構良好的各種量子層疊雷射 (QCL) 設計和工作特性數據集合，提供了一個平台來分析和理解這些特性之間的關係。透過分析這些關係，我們可以深入了解不同的設計特徵如何影響雷射效能特性，例如工作溫度。這些 QCL 特性大多數都捕捉在科學文字中。因此，需要有效的方法，可以用於從文字中萃取 QCL 特性，並產生一個語義豐富且相互連結的平台，可以在其中分析這些特性以發現隱藏的關係。還需要維護這些特性所依據的來源和參考資訊。語義網路技術，例如本体和知識圖譜，已證明它們在提供各種領域中知識表徵的相互連結資料平台方面具有能力。在本文中，我們提出一個從文字中產生 QCL 特性知識圖譜 (KG) 的方法，以進行特性的語義豐富化。此方法基於 QCL 本体和基於 GPT 4-Turbo 語言模型的檢索擴增生成 (RAG) 啟用資訊萃取管線。感興趣的特性包括：工作溫度、雷射設計類型、雷射頻率、雷射光功率和異質結構。實驗結果證明了此方法對於從非結構化文字中有效萃取 QCL 特性和產生 QCL 特性知識圖譜的可行性和有效性，這在 QCL 數據的語義豐富化和分析中具有潛在應用。

##### **VisAidMath: Benchmarking Visual-Aided Mathematical Reasoning**
2410.22995v1 by Jingkun Ma, Runzhe Zhan, Derek F. Wong, Yang Li, Di Sun, Hou Pong Chan, Lidia S. Chao

Although previous research on large language models (LLMs) and large
multi-modal models (LMMs) has systematically explored mathematical
problem-solving (MPS) within visual contexts, the analysis of how these models
process visual information during problem-solving remains insufficient. To
address this gap, we present VisAidMath, a benchmark for evaluating the MPS
process related to visual information. We follow a rigorous data curation
pipeline involving both automated processes and manual annotations to ensure
data quality and reliability. Consequently, this benchmark includes 1,200
challenging problems from various mathematical branches, vision-aid
formulations, and difficulty levels, collected from diverse sources such as
textbooks, examination papers, and Olympiad problems. Based on the proposed
benchmark, we conduct comprehensive evaluations on ten mainstream LLMs and
LMMs, highlighting deficiencies in the visual-aided reasoning process. For
example, GPT-4V only achieves 45.33% accuracy in the visual-aided reasoning
task, even with a drop of 2 points when provided with golden visual aids.
In-depth analysis reveals that the main cause of deficiencies lies in
hallucination regarding the implicit visual reasoning process, shedding light
on future research directions in the visual-aided MPS process.

摘要：儘管先前針對大型語言模型 (LLM) 和大型多模態模型 (LMM) 的研究已系統性地探討視覺情境中的數學問題解決 (MPS)，但對於這些模型在問題解決過程中如何處理視覺資訊的分析仍不足。為了解決此差距，我們提出 VisAidMath，一個用於評估與視覺資訊相關的 MPS 過程的基準。我們遵循嚴謹的資料整理流程，涉及自動化處理和手動標註，以確保資料品質和可靠性。因此，此基準包含 1,200 個來自教科書、考試卷和奧林匹亞競賽等不同來源的具有挑戰性的問題，涵蓋各種數學分支、視覺輔助公式和難度等級。根據建議的基準，我們對十個主流 LLM 和 LMM 進行全面評估，強調視覺輔助推理過程中的缺陷。例如，即使在提供黃金視覺輔助時下降 2 個百分點，GPT-4V 在視覺輔助推理任務中僅達到 45.33% 的準確度。深入分析顯示，缺陷的主要原因在於對隱式視覺推理過程的幻覺，為視覺輔助 MPS 過程中的未來研究方向提供了啟示。

##### **Higher-order Cross-structural Embedding Model for Time Series Analysis**
2410.22984v1 by Guancen Lin, Cong Shen, Aijing Lin

Time series analysis has gained significant attention due to its critical
applications in diverse fields such as healthcare, finance, and sensor
networks. The complexity and non-stationarity of time series make it
challenging to capture the interaction patterns across different timestamps.
Current approaches struggle to model higher-order interactions within time
series, and focus on learning temporal or spatial dependencies separately,
which limits performance in downstream tasks. To address these gaps, we propose
Higher-order Cross-structural Embedding Model for Time Series (High-TS), a
novel framework that jointly models both temporal and spatial perspectives by
combining multiscale Transformer with Topological Deep Learning (TDL).
Meanwhile, High-TS utilizes contrastive learning to integrate these two
structures for generating robust and discriminative representations. Extensive
experiments show that High-TS outperforms state-of-the-art methods in various
time series tasks and demonstrate the importance of higher-order
cross-structural information in improving model performance.

摘要：時序分析因其在醫療保健、金融和感測器網路等不同領域的關鍵應用而備受關注。時序的複雜性和非平穩性使得難以捕捉不同時間戳記之間的互動模式。目前的做法難以對時序中的高階互動進行建模，並專注於分別學習時間或空間依賴性，這限制了下游任務的效能。為了解決這些差距，我們提出了時序的高階交叉結構嵌入模型 (High-TS)，這是一個結合多尺度 Transformer 與拓撲深度學習 (TDL) 的新穎架構，可以同時對時間和空間觀點進行建模。同時，High-TS 利用對比學習來整合這兩種結構，以產生穩健且具區別性的表示。廣泛的實驗表明，High-TS 在各種時序任務中優於最先進的方法，並證明了高階交叉結構資訊在改善模型效能方面的重要性。

##### **Bonafide at LegalLens 2024 Shared Task: Using Lightweight DeBERTa Based Encoder For Legal Violation Detection and Resolution**
2410.22977v1 by Shikha Bordia

In this work, we present two systems -- Named Entity Resolution (NER) and
Natural Language Inference (NLI) -- for detecting legal violations within
unstructured textual data and for associating these violations with potentially
affected individuals, respectively. Both these systems are lightweight DeBERTa
based encoders that outperform the LLM baselines. The proposed NER system
achieved an F1 score of 60.01\% on Subtask A of the LegalLens challenge, which
focuses on identifying violations. The proposed NLI system achieved an F1 score
of 84.73\% on Subtask B of the LegalLens challenge, which focuses on resolving
these violations by matching them with pre-existing legal complaints of class
action cases. Our NER system ranked sixth and NLI system ranked fifth on the
LegalLens leaderboard. We release the trained models and inference scripts.

摘要：在本文中，我們提出了兩個系統——命名實體解析 (NER) 和自然語言推理 (NLI)——分別用於檢測非結構化文本資料中的法律違規行為，以及將這些違規行為與潛在受影響的個人聯繫起來。這兩個系統都是基於 DeBERTa 的輕量級編碼器，其效能優於 LLM 基準。所提出的 NER 系統在 LegalLens 挑戰的子任務 A 上達到了 60.01% 的 F1 分數，該子任務專注於識別違規行為。所提出的 NLI 系統在 LegalLens 挑戰的子任務 B 上達到了 84.73% 的 F1 分數，該子任務專注於通過將這些違規行為與集體訴訟案件的既有法律申訴相匹配來解決這些違規行為。我們的 NER 系統在 LegalLens 排行榜上排名第六，NLI 系統排名第五。我們發布訓練好的模型和推理腳本。

##### **Private Synthetic Text Generation with Diffusion Models**
2410.22971v1 by Sebastian Ochs, Ivan Habernal

How capable are diffusion models of generating synthetics texts? Recent
research shows their strengths, with performance reaching that of
auto-regressive LLMs. But are they also good in generating synthetic data if
the training was under differential privacy? Here the evidence is missing, yet
the promises from private image generation look strong. In this paper we
address this open question by extensive experiments. At the same time, we
critically assess (and reimplement) previous works on synthetic private text
generation with LLMs and reveal some unmet assumptions that might have led to
violating the differential privacy guarantees. Our results partly contradict
previous non-private findings and show that fully open-source LLMs outperform
diffusion models in the privacy regime. Our complete source codes, datasets,
and experimental setup is publicly available to foster future research.

摘要：擴散模型生成合成文本的能力有多強？最近的研究顯示出它們的優勢，其效能已達到自迴歸 LLM 的水準。但是，如果訓練是在差分隱私下進行，它們在生成合成資料方面是否也表現良好？這方面的證據目前還付之闕如，但從私人影像生成中得到的承諾看起來很強。在本文中，我們透過廣泛的實驗來探討這個開放性的問題。同時，我們批判性地評估（並重新實作）先前使用 LLM 進行合成私人文字生成的相關研究，並揭露一些可能導致違反差分隱私保證的未滿足假設。我們的結果部分地與先前的非私人研究結果相矛盾，並顯示完全開源的 LLM 在隱私保護機制中優於擴散模型。我們的完整原始碼、資料集和實驗設定已公開，以促進未來的研究。

##### **Efficient Adaptation of Pre-trained Vision Transformer via Householder Transformation**
2410.22952v1 by Wei Dong, Yuan Sun, Yiting Yang, Xing Zhang, Zhijun Lin, Qingsen Yan, Haokui Zhang, Peng Wang, Yang Yang, Hengtao Shen

A common strategy for Parameter-Efficient Fine-Tuning (PEFT) of pre-trained
Vision Transformers (ViTs) involves adapting the model to downstream tasks by
learning a low-rank adaptation matrix. This matrix is decomposed into a product
of down-projection and up-projection matrices, with the bottleneck
dimensionality being crucial for reducing the number of learnable parameters,
as exemplified by prevalent methods like LoRA and Adapter. However, these
low-rank strategies typically employ a fixed bottleneck dimensionality, which
limits their flexibility in handling layer-wise variations. To address this
limitation, we propose a novel PEFT approach inspired by Singular Value
Decomposition (SVD) for representing the adaptation matrix. SVD decomposes a
matrix into the product of a left unitary matrix, a diagonal matrix of scaling
values, and a right unitary matrix. We utilize Householder transformations to
construct orthogonal matrices that efficiently mimic the unitary matrices,
requiring only a vector. The diagonal values are learned in a layer-wise
manner, allowing them to flexibly capture the unique properties of each layer.
This approach enables the generation of adaptation matrices with varying ranks
across different layers, providing greater flexibility in adapting pre-trained
models. Experiments on standard downstream vision tasks demonstrate that our
method achieves promising fine-tuning performance.

摘要：常見的預訓練 Vision Transformers (ViTs) 參數有效微調 (PEFT) 策略包含透過學習低階適應矩陣來調整模型至下游任務。此矩陣分解為下投影和上投影矩陣的乘積，其中瓶頸維度對於減少可學習參數的數量至關重要，例如 LoRA 和 Adapter 等普遍方法所舉例說明的。然而，這些低階策略通常採用固定的瓶頸維度，這會限制它們在處理逐層變化時的靈活性。為了解決此限制，我們提出一個新的 PEFT 方法，靈感來自奇異值分解 (SVD) 以表示適應矩陣。SVD 將矩陣分解為左酉矩陣、縮放值的對角矩陣和右酉矩陣的乘積。我們利用 Householder 轉換來建構正交矩陣，以有效地模擬酉矩陣，只需要一個向量。對角值是以逐層方式學習的，讓它們能夠靈活地擷取每個層的獨特屬性。此方法能產生具有不同層間不同秩的適應矩陣，在調整預訓練模型時提供更大的靈活性。在標準下游視覺任務上的實驗證明，我們的模型達到了令人滿意的微調效能。

##### **SpiroActive: Active Learning for Efficient Data Acquisition for Spirometry**
2410.22950v1 by Ankita Kumari Jain, Nitish Sharma, Madhav Kanda, Nipun Batra

Respiratory illnesses are a significant global health burden. Respiratory
illnesses, primarily Chronic obstructive pulmonary disease (COPD), is the
seventh leading cause of poor health worldwide and the third leading cause of
death worldwide, causing 3.23 million deaths in 2019, necessitating early
identification and diagnosis for effective mitigation. Among the diagnostic
tools employed, spirometry plays a crucial role in detecting respiratory
abnormalities. However, conventional clinical spirometry methods often entail
considerable costs and practical limitations like the need for specialized
equipment, trained personnel, and a dedicated clinical setting, making them
less accessible. To address these challenges, wearable spirometry technologies
have emerged as promising alternatives, offering accurate, cost-effective, and
convenient solutions. The development of machine learning models for wearable
spirometry heavily relies on the availability of high-quality ground truth
spirometry data, which is a laborious and expensive endeavor. In this research,
we propose using active learning, a sub-field of machine learning, to mitigate
the challenges associated with data collection and labeling. By strategically
selecting samples from the ground truth spirometer, we can mitigate the need
for resource-intensive data collection. We present evidence that models trained
on small subsets obtained through active learning achieve comparable/better
results than models trained on the complete dataset.

摘要：呼吸道疾病是全球重大的健康負擔。呼吸道疾病，主要是慢性阻塞性肺病 (COPD)，是全球第七大不良健康原因，也是全球第三大死亡原因，2019 年造成 323 萬人死亡，需要及早識別和診斷以有效減輕症狀。在所採用的診斷工具中，肺活量測量在檢測呼吸道異常方面發揮著至關重要的作用。然而，傳統的臨床肺活量測量方法通常需要大量的成本和實際限制，例如需要專業設備、訓練有素的人員和專門的臨床環境，這使得它們的可及性較低。為了應對這些挑戰，可穿戴式肺活量測量技術已成為有希望的替代方案，提供準確、經濟高效且便利的解決方案。可穿戴式肺活量測量機器學習模型的開發在很大程度上依賴於高品質的基準肺活量測量數據，這是一項費時且昂貴的工作。在這項研究中，我們建議使用主動學習（機器學習的一個子領域）來減輕與數據收集和標記相關的挑戰。通過從基準肺活量計中策略性地選擇樣本，我們可以減少對資源密集型數據收集的需求。我們提供的證據表明，在通過主動學習獲得的小子集中訓練的模型，獲得的結果與在完整數據集上訓練的模型相當/更好。

##### **Focus On This, Not That! Steering LLMs With Adaptive Feature Specification**
2410.22944v1 by Tom A. Lamb, Adam Davies, Alasdair Paren, Philip H. S. Torr, Francesco Pinto

Despite the success of Instruction Tuning (IT) in training large language
models (LLMs) to perform arbitrary user-specified tasks, these models often
still leverage spurious or biased features learned from their training data,
leading to undesired behaviours when deploying them in new contexts. In this
work, we introduce Focus Instruction Tuning (FIT), which trains LLMs to
condition their responses by focusing on specific features whilst ignoring
others, leading to different behaviours based on what features are specified.
Across several experimental settings, we show that focus-tuned models can be
adaptively steered by focusing on different features at inference-time: for
instance, robustness can be improved by focusing on task-causal features and
ignoring spurious features, and social bias can be mitigated by ignoring
demographic categories. Furthermore, FIT can steer behaviour in new contexts,
generalising under distribution shift and to new unseen features at inference
time, and thereby facilitating more robust, fair, and controllable LLM
applications in real-world environments.

摘要：儘管指令調整 (IT) 在訓練大型語言模型 (LLM) 以執行任意使用者指定任務方面取得成功，但這些模型通常仍會利用從其訓練資料中學習到的虛假或偏差特徵，導致在新的環境中部署它們時出現不必要的行為。在這項工作中，我們引入了焦點指令調整 (FIT)，它訓練 LLM 透過專注於特定特徵同時忽略其他特徵來調整其回應，從而根據所指定的特徵產生不同的行為。在多個實驗設定中，我們展示了焦點調整模型可以在推論時透過專注於不同的特徵來適應性地進行引導：例如，透過專注於任務因果特徵並忽略虛假特徵，可以提高健壯性，並且透過忽略人口統計類別，可以減輕社會偏見。此外，FIT 可以引導在新的環境中的行為，在推論時對分佈轉移和新的未見特徵進行概化，從而促進在現實世界環境中更健壯、更公平且可控的 LLM 應用。

##### **DiffLight: A Partial Rewards Conditioned Diffusion Model for Traffic Signal Control with Missing Data**
2410.22938v2 by Hanyang Chen, Yang Jiang, Shengnan Guo, Xiaowei Mao, Youfang Lin, Huaiyu Wan

The application of reinforcement learning in traffic signal control (TSC) has
been extensively researched and yielded notable achievements. However, most
existing works for TSC assume that traffic data from all surrounding
intersections is fully and continuously available through sensors. In
real-world applications, this assumption often fails due to sensor malfunctions
or data loss, making TSC with missing data a critical challenge. To meet the
needs of practical applications, we introduce DiffLight, a novel conditional
diffusion model for TSC under data-missing scenarios in the offline setting.
Specifically, we integrate two essential sub-tasks, i.e., traffic data
imputation and decision-making, by leveraging a Partial Rewards Conditioned
Diffusion (PRCD) model to prevent missing rewards from interfering with the
learning process. Meanwhile, to effectively capture the spatial-temporal
dependencies among intersections, we design a Spatial-Temporal transFormer
(STFormer) architecture. In addition, we propose a Diffusion Communication
Mechanism (DCM) to promote better communication and control performance under
data-missing scenarios. Extensive experiments on five datasets with various
data-missing scenarios demonstrate that DiffLight is an effective controller to
address TSC with missing data. The code of DiffLight is released at
https://github.com/lokol5579/DiffLight-release.

摘要：強化學習在交通號誌控制 (TSC) 中的應用已廣泛研究，並取得顯著成果。然而，大多數現有的 TSC 作品假設來自所有周圍路口的交通資料都是透過感測器完整且持續可用的。在實際應用中，此假設經常因感測器故障或資料遺失而失敗，這使得遺失資料的 TSC 成為一項嚴峻的挑戰。為了滿足實際應用的需求，我們引入了 DiffLight，這是一種用於離線設定中資料遺失場景下 TSC 的新型條件擴散模型。具體來說，我們整合了兩個重要的子任務，即交通資料填補和決策制定，透過利用部分獎勵條件擴散 (PRCD) 模型來防止遺失的獎勵干擾學習過程。同時，為了有效擷取路口之間的時空依賴性，我們設計了一個時空 transFormer (STFormer) 架構。此外，我們提出了一種擴散通訊機制 (DCM) 來促進在資料遺失場景中更好的通訊和控制效能。在具有各種資料遺失場景的五個資料集上進行的廣泛實驗表明，DiffLight 是一個有效的控制器，可以解決遺失資料的 TSC。DiffLight 的程式碼已在 https://github.com/lokol5579/DiffLight-release 中釋出。

##### **Thoughtful Adoption of NLP for Civic Participation: Understanding Differences Among Policymakers**
2410.22937v1 by Jose A. Guridi, Cristobal Cheyre, Qian Yang

Natural language processing (NLP) tools have the potential to boost civic
participation and enhance democratic processes because they can significantly
increase governments' capacity to gather and analyze citizen opinions. However,
their adoption in government remains limited, and harnessing their benefits
while preventing unintended consequences remains a challenge. While prior work
has focused on improving NLP performance, this work examines how different
internal government stakeholders influence NLP tools' thoughtful adoption. We
interviewed seven politicians (politically appointed officials as heads of
government institutions) and thirteen public servants (career government
employees who design and administrate policy interventions), inquiring how they
choose whether and how to use NLP tools to support civic participation
processes. The interviews suggest that policymakers across both groups focused
on their needs for career advancement and the need to showcase the legitimacy
and fairness of their work when considering NLP tool adoption and use. Because
these needs vary between politicians and public servants, their preferred NLP
features and tool designs also differ. Interestingly, despite their differing
needs and opinions, neither group clearly identifies who should advocate for
NLP adoption to enhance civic participation or address the unintended
consequences of a poorly considered adoption. This lack of clarity in
responsibility might have caused the governments' low adoption of NLP tools. We
discuss how these findings reveal new insights for future HCI research. They
inform the design of NLP tools for increasing civic participation efficiency
and capacity, the design of other tools and methods that ensure thoughtful
adoption of AI tools in government, and the design of NLP tools for
collaborative use among users with different incentives and needs.

摘要：自然語言處理 (NLP) 工具有潛力提升公民參與度，並加強民主程序，因為它們可以大幅增加政府收集和分析公民意見的能力。然而，它們在政府中的採用仍然有限，在防止意外後果的同時利用它們的優點仍然是一個挑戰。雖然先前的研究集中在改進 NLP 效能，但這項研究探討了不同的政府內部利害關係人如何影響 NLP 工具的周全採用。我們訪談了七位政治人物（擔任政府機構首長的政治任命官員）和十三位公務員（設計和管理政策干預措施的職業政府雇員），詢問他們如何選擇是否以及如何使用 NLP 工具來支持公民參與程序。訪談結果顯示，兩組的政策制定者在考慮採用和使用 NLP 工具時，都專注於他們對職涯進階的需求，以及展示其工作的合法性和公平性的需求。由於這些需求在政治人物和公務員之間有所不同，因此他們偏好的 NLP 功能和工具設計也各不相同。有趣的是，儘管他們有不同的需求和意見，但兩組都沒有明確指出誰應該倡導採用 NLP 來加強公民參與，或解決考慮不周的採用所造成的意外後果。這種責任不清的情況可能導致政府採用 NLP 工具的程度偏低。我們討論了這些發現如何揭示未來 HCI 研究的新見解。它們告知了 NLP 工具的設計，以提高公民參與的效率和能力，確保周全採用政府中 AI 工具的其他工具和方法的設計，以及為具有不同誘因和需求的使用者之間協作使用而設計的 NLP 工具。

##### **Multi-Agent Large Language Models for Conversational Task-Solving**
2410.22932v1 by Jonas Becker

In an era where single large language models have dominated the landscape of
artificial intelligence for years, multi-agent systems arise as new
protagonists in conversational task-solving. While previous studies have
showcased their potential in reasoning tasks and creative endeavors, an
analysis of their limitations concerning the conversational paradigms and the
impact of individual agents is missing. It remains unascertained how
multi-agent discussions perform across tasks of varying complexity and how the
structure of these conversations influences the process. To fill that gap, this
work systematically evaluates multi-agent systems across various discussion
paradigms, assessing their strengths and weaknesses in both generative tasks
and question-answering tasks. Alongside the experiments, I propose a taxonomy
of 20 multi-agent research studies from 2022 to 2024, followed by the
introduction of a framework for deploying multi-agent LLMs in conversational
task-solving. I demonstrate that while multi-agent systems excel in complex
reasoning tasks, outperforming a single model by leveraging expert personas,
they fail on basic tasks. Concretely, I identify three challenges that arise:
1) While longer discussions enhance reasoning, agents fail to maintain
conformity to strict task requirements, which leads to problem drift, making
shorter conversations more effective for basic tasks. 2) Prolonged discussions
risk alignment collapse, raising new safety concerns for these systems. 3) I
showcase discussion monopolization through long generations, posing the problem
of fairness in decision-making for tasks like summarization. This work uncovers
both the potential and challenges that arise with multi-agent interaction and
varying conversational paradigms, providing insights into how future research
could improve the efficiency, performance, and safety of multi-agent LLMs.

摘要：<paragraph>在大型单一语言模型多年来主导人工智能领域的环境中，多智能体系统作为对话任务解决的新主角出现。虽然先前的研究展示了它们在推理任务和创造性工作中的潜力，但缺少对其在对话范例和个体智能体影响方面的限制的分析。多智能体讨论如何在不同复杂程度的任务中执行以及这些对话的结构如何影响这一过程仍未确定。为了填补这一空白，这项工作系统地评估了各种讨论范例中的多智能体系统，评估了它们在生成性任务和问答任务中的优势和劣势。除了实验之外，我还提出了 2022 年至 2024 年间 20 项多智能体研究的分类法，随后介绍了一个在对话任务解决中部署多智能体 LLM 的框架。我展示了多智能体系统虽然在复杂推理任务中表现出色，通过利用专家角色而优于单个模型，但它们在基本任务中却失败了。具体来说，我确定了三个出现的挑战：1) 虽然较长的讨论增强了推理，但智能体无法保持对严格任务要求的一致性，这会导致问题漂移，使得较短的对话对基本任务更有效。2) 长时间的讨论有对齐崩溃的风险，为这些系统带来了新的安全问题。3) 我展示了通过长生成进行讨论垄断，对摘要等任务的决策公平性构成了问题。这项工作揭示了多智能体交互和不同的对话范例带来的潜力和挑战，提供了对未来研究如何提高多智能体 LLM 的效率、性能和安全性的见解。</paragraph>

##### **BIS: NL2SQL Service Evaluation Benchmark for Business Intelligence Scenarios**
2410.22925v1 by Bora Caglayan, Mingxue Wang, John D. Kelleher, Shen Fei, Gui Tong, Jiandong Ding, Puchao Zhang

NL2SQL (Natural Language to Structured Query Language) transformation has
seen wide adoption in Business Intelligence (BI) applications in recent years.
However, existing NL2SQL benchmarks are not suitable for production BI
scenarios, as they are not designed for common business intelligence questions.
To address this gap, we have developed a new benchmark focused on typical NL
questions in industrial BI scenarios. We discuss the challenges of constructing
a BI-focused benchmark and the shortcomings of existing benchmarks.
Additionally, we introduce question categories in our benchmark that reflect
common BI inquiries. Lastly, we propose two novel semantic similarity
evaluation metrics for assessing NL2SQL capabilities in BI applications and
services.

摘要：近年來，NL2SQL（自然語言到結構化查詢語言）轉換已廣泛用於商業智慧（BI）應用程式中。
然而，現有的 NL2SQL 基準並不適用於生產 BI 場景，因為它們並非針對常見的商業智慧問題而設計。
為了解決這個差距，我們開發了一個新的基準，專注於工業 BI 場景中的典型 NL 問題。我們討論了建構以 BI 為中心的基準的挑戰和現有基準的缺點。
此外，我們在基準中引入了反映常見 BI 查詢的問題類別。最後，我們提出了兩個新的語義相似性評估指標，用於評估 BI 應用程式和服務中的 NL2SQL 功能。

##### **Explainable Behavior Cloning: Teaching Large Language Model Agents through Learning by Demonstration**
2410.22916v1 by Yanchu Guan, Dong Wang, Yan Wang, Haiqing Wang, Renen Sun, Chenyi Zhuang, Jinjie Gu, Zhixuan Chu

Autonomous mobile app interaction has become increasingly important with
growing complexity of mobile applications. Developing intelligent agents that
can effectively navigate and interact with mobile apps remains a significant
challenge. In this paper, we propose an Explainable Behavior Cloning LLM Agent
(EBC-LLMAgent), a novel approach that combines large language models (LLMs)
with behavior cloning by learning demonstrations to create intelligent and
explainable agents for autonomous mobile app interaction. EBC-LLMAgent consists
of three core modules: Demonstration Encoding, Code Generation, and UI Mapping,
which work synergistically to capture user demonstrations, generate executable
codes, and establish accurate correspondence between code and UI elements. We
introduce the Behavior Cloning Chain Fusion technique to enhance the
generalization capabilities of the agent. Extensive experiments on five popular
mobile applications from diverse domains demonstrate the superior performance
of EBC-LLMAgent, achieving high success rates in task completion, efficient
generalization to unseen scenarios, and the generation of meaningful
explanations.

摘要：隨著行動應用程式的複雜性日益提升，自主行動應用程式互動變得越來越重要。開發能有效導航和與行動應用程式互動的智慧代理程式仍然是一項重大的挑戰。在本文中，我們提出可解釋行為複製 LLM 代理程式 (EBC-LLMAgent)，這是一種新穎的方法，它結合大型語言模型 (LLM) 與行為複製，透過學習示範來建立智慧且可解釋的代理程式，以進行自主行動應用程式互動。EBC-LLMAgent 由三個核心模組組成：示範編碼、程式碼產生和 UI 對應，它們協同運作以擷取使用者示範、產生可執行程式碼，並在程式碼和 UI 元素之間建立準確的對應關係。我們引進行為複製鏈融合技術，以增強代理程式的概化能力。在來自不同領域的五個熱門行動應用程式上進行的廣泛實驗，證明了 EBC-LLMAgent 的優異效能，在任務完成方面達到了很高的成功率、有效概化至未見情境，並產生有意義的解釋。

##### **From Babble to Words: Pre-Training Language Models on Continuous Streams of Phonemes**
2410.22906v1 by Zébulon Goriely, Richard Diehl Martinez, Andrew Caines, Lisa Beinborn, Paula Buttery

Language models are typically trained on large corpora of text in their
default orthographic form. However, this is not the only option; representing
data as streams of phonemes can offer unique advantages, from deeper insights
into phonological language acquisition to improved performance on sound-based
tasks. The challenge lies in evaluating the impact of phoneme-based training,
as most benchmarks are also orthographic. To address this, we develop a
pipeline to convert text datasets into a continuous stream of phonemes. We
apply this pipeline to the 100-million-word pre-training dataset from the
BabyLM challenge, as well as to standard language and grammatical benchmarks,
enabling us to pre-train and evaluate a model using phonemic input
representations. Our results show that while phoneme-based training slightly
reduces performance on traditional language understanding tasks, it offers
valuable analytical and practical benefits.

摘要：語言模型通常會針對其預設正字法形式的大型文字語料庫進行訓練。然而，這並非唯一選項；將資料表示為音素串流可以提供獨特優勢，從更深入洞察音系語言習得，到提升以聲音為基礎的任務效能。挑戰在於評估以音素為基礎的訓練影響，因為大多數基準也是正字法的。為了解決這個問題，我們開發一個將文字資料集轉換為連續音素串流的管道。我們將這個管道應用於 BabyLM 挑戰中的 1 億字預訓練資料集，以及標準語言和語法基準，讓我們能夠使用音素輸入表示法預訓練和評估模型。我們的結果顯示，雖然以音素為基礎的訓練會稍微降低傳統語言理解任務的效能，但它提供了寶貴的分析和實務優勢。

##### **YOLOv11 for Vehicle Detection: Advancements, Performance, and Applications in Intelligent Transportation Systems**
2410.22898v1 by Mujadded Al Rabbani Alif

Accurate vehicle detection is essential for the development of intelligent
transportation systems, autonomous driving, and traffic monitoring. This paper
presents a detailed analysis of YOLO11, the latest advancement in the YOLO
series of deep learning models, focusing exclusively on vehicle detection
tasks. Building upon the success of its predecessors, YOLO11 introduces
architectural improvements designed to enhance detection speed, accuracy, and
robustness in complex environments. Using a comprehensive dataset comprising
multiple vehicle types-cars, trucks, buses, motorcycles, and bicycles we
evaluate YOLO11's performance using metrics such as precision, recall, F1
score, and mean average precision (mAP). Our findings demonstrate that YOLO11
surpasses previous versions (YOLOv8 and YOLOv10) in detecting smaller and more
occluded vehicles while maintaining a competitive inference time, making it
well-suited for real-time applications. Comparative analysis shows significant
improvements in the detection of complex vehicle geometries, further
contributing to the development of efficient and scalable vehicle detection
systems. This research highlights YOLO11's potential to enhance autonomous
vehicle performance and traffic monitoring systems, offering insights for
future developments in the field.

摘要：精確的車輛偵測對於智慧交通系統、自動駕駛和交通監控的發展至關重要。這篇論文針對 YOLO 系列深度學習模型的最新進展 YOLO11 進行詳細分析，專注於車輛偵測任務。YOLO11 建立在前代的成功基礎上，引進架構改善，旨在提升偵測速度、準確度和在複雜環境中的穩健性。我們使用包含多種車輛類型（汽車、卡車、公車、機車和自行車）的綜合資料集，使用準確度、召回率、F1 分數和平均準確度 (mAP) 等指標評估 YOLO11 的效能。我們的研究結果顯示，YOLO11 在偵測較小且被遮擋的車輛方面優於之前的版本 (YOLOv8 和 YOLOv10)，同時維持有競爭力的推論時間，使其非常適合於即時應用。比較分析顯示在複雜車輛幾何形狀的偵測方面有顯著改善，進一步促進了高效且可擴充的車輛偵測系統的發展。這項研究強調了 YOLO11 提升自動駕駛車輛效能和交通監控系統的潛力，為該領域的未來發展提供見解。

##### **VPO: Leveraging the Number of Votes in Preference Optimization**
2410.22891v1 by Jae Hyeon Cho, Minkyung Park, Byung-Jun Lee

Direct Preference Optimization (DPO) trains a language model using human
preference data, bypassing the explicit reward modeling phase of Reinforcement
Learning from Human Feedback (RLHF). By iterating over sentence pairs in a
preference dataset, DPO enhances generation quality by increasing the
likelihood of producing preferred sentences over less favored ones. Preference
datasets are typically created by selecting preferred sentences through a
voting process involving multiple individuals, as opinions can vary due to the
subjective nature of human preferences. While the number of votes offers
insight into whether a sentence pair is clearly preferable or controversial,
current methods do not fully leverage this information. In this paper, we
introduce a technique that leverages user voting data to better align with
diverse subjective preferences. We employ the Bayesian Minimum Mean Square
Error (Bayesian MMSE) estimator to model the probability that one generation is
preferable to another. Using this estimated probability as a target, we develop
the Vote-based Preference Optimization (VPO) framework, which incorporates the
number of votes on both sides to distinguish between controversial and obvious
generation pairs. We show that previous algorithms, such as DPO and Identity
Preference Optimization (IPO), can be extended using the proposed framework,
termed VDPO and VIPO. Our experiments demonstrate that these proposed
algorithms outperform various existing methods, including their base
algorithms.

摘要：直接偏好最佳化（DPO）使用人類偏好資料訓練語言模型，繞過人類回饋強化學習（RLHF）的明確獎勵建模階段。透過在偏好資料集中的句子對中反覆運算，DPO 透過增加產生偏好句子的機率，進而提升產生品質，勝過不那麼受歡迎的句子。偏好資料集通常透過投票程序建立，並由多位個人參與，因為意見可能會因人類偏好的主觀性質而有所不同。儘管投票數提供了見解，說明句子對是否明顯較佳或有爭議，但目前的技術並未充分利用這些資訊。在本文中，我們引進一項技術，利用使用者投票資料，以更好地與不同的主觀偏好保持一致。我們採用貝氏最小均方誤差（貝氏 MMSE）估計器，來建模一個產生結果比另一個產生結果更佳的機率。使用這個估計機率作為目標，我們開發了基於投票的偏好最佳化（VPO）架構，其中納入兩方的投票數，以區分有爭議和顯而易見的產生對。我們展示了先前的演算法，例如 DPO 和身分偏好最佳化（IPO），可以使用所提出的架構進行延伸，稱為 VDPO 和 VIPO。我們的實驗證明，這些提出的演算法優於各種現有方法，包括其基本演算法。

##### **Effective and Efficient Adversarial Detection for Vision-Language Models via A Single Vector**
2410.22888v1 by Youcheng Huang, Fengbin Zhu, Jingkun Tang, Pan Zhou, Wenqiang Lei, Jiancheng Lv, Tat-Seng Chua

Visual Language Models (VLMs) are vulnerable to adversarial attacks,
especially those from adversarial images, which is however under-explored in
literature. To facilitate research on this critical safety problem, we first
construct a new laRge-scale Adervsarial images dataset with Diverse hArmful
Responses (RADAR), given that existing datasets are either small-scale or only
contain limited types of harmful responses. With the new RADAR dataset, we
further develop a novel and effective iN-time Embedding-based AdveRSarial Image
DEtection (NEARSIDE) method, which exploits a single vector that distilled from
the hidden states of VLMs, which we call the attacking direction, to achieve
the detection of adversarial images against benign ones in the input. Extensive
experiments with two victim VLMs, LLaVA and MiniGPT-4, well demonstrate the
effectiveness, efficiency, and cross-model transferrability of our proposed
method. Our code is available at https://github.com/mob-scu/RADAR-NEARSIDE

摘要：視覺語言模型 (VLM) 容易受到對抗性攻擊，特別是來自對抗性影像的攻擊，而這在文獻中卻鮮少探討。為了促進對這個關鍵安全問題的研究，我們首先建構了一個新的具備多樣化有害回應的大規模對抗性影像資料集 (RADAR)，因為現有的資料集規模過小或僅包含有限類型的有害回應。有了新的 RADAR 資料集，我們進一步開發了一種新穎且有效的即時嵌入式對抗性影像偵測 (NEARSIDE) 方法，它利用從 VLM 的隱藏狀態中萃取出的單一向量（我們稱之為攻擊方向）來偵測輸入中的對抗性影像和良性影像。使用兩個受害者 VLM（LLaVA 和 MiniGPT-4）進行的廣泛實驗充分證明了我們所提出的方法的有效性、效率和跨模型可傳遞性。我們的程式碼可於 https://github.com/mob-scu/RADAR-NEARSIDE 取得

##### **Less is More: Pre-Training Cross-Lingual Small-Scale Language Models with Cognitively-Plausible Curriculum Learning Strategies**
2410.22886v1 by Suchir Salhan, Richard Diehl Martinez, Zébulon Goriely, Paula Buttery

Curriculum Learning has been a popular strategy to improve the cognitive
plausibility of Small-Scale Language Models (SSLMs) in the BabyLM Challenge.
However, it has not led to considerable improvements over non-curriculum
models. We assess whether theoretical linguistic acquisition theories can be
used to specify more fine-grained curriculum learning strategies, creating
age-ordered corpora of Child-Directed Speech for four typologically distant
language families to implement SSLMs and acquisition-inspired curricula
cross-lingually. Comparing the success of three objective curricula (Growing,
Inwards and MMM) that precisely replicate the predictions of acquisition
theories on a standard SSLM architecture, we find fine-grained
acquisition-inspired curricula can outperform non-curriculum baselines and
performance benefits of curricula strategies in SSLMs can be derived by
specifying fine-grained language-specific curricula that precisely replicate
language acquisition theories.

摘要：課程學習一直是提高 BabyLM 挑戰中小型語言模型 (SSLMs) 的認知合理性的熱門策略。
然而，它並未導致非課程模型有顯著的改進。我們評估理論語言習得理論是否可用於指定更細緻的課程學習策略，為四個類型學上相距甚遠的語言家族建立兒童導向言語的年齡順序語料庫，以跨語言地實施 SSLM 和習得啟發課程。比較三個客觀課程（Growing、Inwards 和 MMM）的成功，這些課程精確地複製了標準 SSLM 架構上的習得理論預測，我們發現細緻的習得啟發課程可以優於非課程基準，並且 SSLM 中課程策略的效能優勢可以透過指定精確複製語言習得理論的細緻語言特定課程來獲得。

##### **Stealing User Prompts from Mixture of Experts**
2410.22884v1 by Itay Yona, Ilia Shumailov, Jamie Hayes, Nicholas Carlini

Mixture-of-Experts (MoE) models improve the efficiency and scalability of
dense language models by routing each token to a small number of experts in
each layer. In this paper, we show how an adversary that can arrange for their
queries to appear in the same batch of examples as a victim's queries can
exploit Expert-Choice-Routing to fully disclose a victim's prompt. We
successfully demonstrate the effectiveness of this attack on a two-layer
Mixtral model, exploiting the tie-handling behavior of the torch.topk CUDA
implementation. Our results show that we can extract the entire prompt using
$O({VM}^2)$ queries (with vocabulary size $V$ and prompt length $M$) or 100
queries on average per token in the setting we consider. This is the first
attack to exploit architectural flaws for the purpose of extracting user
prompts, introducing a new class of LLM vulnerabilities.

摘要：混合专家 (MoE) 模型透過將每個符號路由到每一層的少數專家，進而提升密集語言模型的效率和可擴充性。在本文中，我們展示了一個對手如何安排他們的查詢出現在與受害者查詢相同的範例批次中，可以利用專家選擇路由來完全揭露受害者的提示。我們成功展示了這種攻擊在雙層 Mixtral 模型上的有效性，利用了火炬 topk CUDA 實作的平手處理行為。我們的結果顯示，我們可以使用 $O({VM}^2)$ 個查詢（詞彙量大小為 $V$，提示長度為 $M$）或在我們考慮的設定中平均每個符號 100 個查詢來提取整個提示。這是第一個利用架構缺陷來提取使用者提示的攻擊，引入了 LLM 漏洞的新類別。

##### **Adaptive Paradigm Synergy: Can a Cross-Paradigm Objective Enhance Long-Tailed Learning?**
2410.22883v1 by Haowen Xiao, Guanghui Liu, Xinyi Gao, Yang Li, Fengmao Lv, Jielei Chu

Self-supervised learning (SSL) has achieved impressive results across several
computer vision tasks, even rivaling supervised methods. However, its
performance degrades on real-world datasets with long-tailed distributions due
to difficulties in capturing inherent class imbalances. Although supervised
long-tailed learning offers significant insights, the absence of labels in SSL
prevents direct transfer of these strategies.To bridge this gap, we introduce
Adaptive Paradigm Synergy (APS), a cross-paradigm objective that seeks to unify
the strengths of both paradigms. Our approach reexamines contrastive learning
from a spatial structure perspective, dynamically adjusting the uniformity of
latent space structure through adaptive temperature tuning. Furthermore, we
draw on a re-weighting strategy from supervised learning to compensate for the
shortcomings of temperature adjustment in explicit quantity
perception.Extensive experiments on commonly used long-tailed datasets
demonstrate that APS improves performance effectively and efficiently. Our
findings reveal the potential for deeper integration between supervised and
self-supervised learning, paving the way for robust models that handle
real-world class imbalance.

摘要：自監督學習 (SSL) 在多項電腦視覺任務中皆取得令人印象深刻的成果，甚至媲美監督式方法。然而，由於難以捕捉內在類別失衡，其效能會在具有長尾分佈的真實世界資料集上下降。儘管監督式長尾學習提供了重要的見解，但 SSL 中標籤的缺乏阻礙了這些策略的直接轉移。為了彌補這個差距，我們引入了自適應範例協同 (APS)，這是一個跨範例目標，旨在統一兩個範例的優點。我們的做法從空間結構的角度重新審視對比學習，透過自適應溫度調整動態調整潛在空間結構的均勻性。此外，我們借用了監督式學習中的重新加權策略，以彌補溫度調整在明確數量感知中的不足。在常用的長尾資料集上進行的廣泛實驗證明，APS 有效且高效地改善了效能。我們的發現揭示了監督式學習和自監督學習之間更深入整合的潛力，為處理真實世界類別失衡的強健模型鋪平了道路。

##### **SFA-UNet: More Attention to Multi-Scale Contrast and Contextual Information in Infrared Small Object Segmentation**
2410.22881v1 by Imad Ali Shah, Fahad Mumtaz Malik, Muhammad Waqas Ashraf

Computer vision researchers have extensively worked on fundamental infrared
visual recognition for the past few decades. Among various approaches, deep
learning has emerged as the most promising candidate. However, Infrared Small
Object Segmentation (ISOS) remains a major focus due to several challenges
including: 1) the lack of effective utilization of local contrast and global
contextual information; 2) the potential loss of small objects in deep models;
and 3) the struggling to capture fine-grained details and ignore noise. To
address these challenges, we propose a modified U-Net architecture, named
SFA-UNet, by combining Scharr Convolution (SC) and Fast Fourier Convolution
(FFC) in addition to vertical and horizontal Attention gates (AG) into UNet.
SFA-UNet utilizes double convolution layers with the addition of SC and FFC in
its encoder and decoder layers. SC helps to learn the foreground-to-background
contrast information whereas FFC provide multi-scale contextual information
while mitigating the small objects vanishing problem. Additionally, the
introduction of vertical AGs in encoder layers enhances the model's focus on
the targeted object by ignoring irrelevant regions. We evaluated the proposed
approach on publicly available, SIRST and IRSTD datasets, and achieved superior
performance by an average 0.75% with variance of 0.025 of all combined metrics
in multiple runs as compared to the existing state-of-the-art methods

摘要：電腦視覺研究人員在過去幾十年來廣泛研究基本紅外線視覺辨識。在各種方法中，深度學習已成為最有希望的候選者。然而，紅外線小物件分割 (ISOS) 由於下列幾個挑戰而仍然是主要重點：1) 未能有效利用局部對比和整體脈絡資訊；2) 小物件在深度模型中潛在的遺失；3) 難以捕捉細微細節並忽略雜訊。為了應對這些挑戰，我們提出一個改良的 U-Net 架構，稱為 SFA-UNet，方法是在 UNet 中結合 Scharr 捲積 (SC) 和快速傅立葉捲積 (FFC)，以及垂直和水平注意力閘門 (AG)。SFA-UNet 在其編碼器和解碼器層中使用雙重捲積層，並加入 SC 和 FFC。SC 有助於學習前景到背景的對比資訊，而 FFC 則提供多尺度脈絡資訊，同時減輕小物件消失的問題。此外，在編碼器層中引入垂直 AG 可增強模型對目標物件的關注，方法是忽略不相關區域。我們在公開的 SIRST 和 IRSTD 資料集上評估所提出的方法，並在多次執行中與現有的最先進方法相比，以所有組合指標的平均 0.75% 和 0.025 的變異數，達到了優異的效能

##### **Eliciting Critical Reasoning in Retrieval-Augmented Language Models via Contrastive Explanations**
2410.22874v1 by Leonardo Ranaldi, Marco Valentino, Andrè Freitas

Retrieval-augmented generation (RAG) has emerged as a critical mechanism in
contemporary NLP to support Large Language Models(LLMs) in systematically
accessing richer factual context. However, the integration of RAG mechanisms
brings its inherent challenges, as LLMs need to deal with potentially noisy
contexts. Recent studies have shown that LLMs still struggle to critically
analyse RAG-based in-context information, a limitation that may lead to
incorrect inferences and hallucinations. In this paper, we investigate how to
elicit critical reasoning in RAG via contrastive explanations. In particular,
we propose Contrastive-RAG (C-RAG), a framework that (i) retrieves relevant
documents given a query, (ii) selects and exemplifies relevant passages, and
(iii) generates explanations that explicitly contrast the relevance of the
passages to (iv) support the final answer. We show the impact of C-RAG building
contrastive reasoning demonstrations from LLMs to instruct smaller models for
retrieval-augmented tasks. Extensive experiments demonstrate that C-RAG
improves state-of-the-art RAG models while (a) requiring significantly fewer
prompts and demonstrations and (b) being robust to perturbations in the
retrieved documents.

摘要：檢索增強生成 (RAG) 已成為當代自然語言處理中的一項關鍵機制，用於支援大型語言模型 (LLM) 系統性地存取更豐富的事實背景。但是，RAG 機制的整合帶來其固有的挑戰，因為 LLM 需要處理潛在的雜訊背景。最近的研究顯示，LLM 仍難以批判性地分析基於 RAG 的情境資訊，這項限制可能會導致不正確的推論和幻覺。在本文中，我們探討如何透過對比解釋在 RAG 中引發批判性推理。具體而言，我們提出對比式 RAG (C-RAG)，這是一個架構，用於 (i) 根據查詢檢索相關文件，(ii) 選擇並舉例說明相關段落，以及 (iii) 產生明確對比段落相關性的解釋，以 (iv) 支援最終答案。我們展示了 C-RAG 建構對比式推理示範的影響，從 LLM 指導較小的模型進行檢索增強任務。廣泛的實驗證明，C-RAG 改進了最先進的 RAG 模型，同時 (a) 需要顯著更少的提示和示範，以及 (b) 對檢索文件中擾動具有穩健性。

##### **Conditioned quantum-assisted deep generative surrogate for particle-calorimeter interactions**
2410.22870v1 by J. Quetzalcoatl Toledo-Marin, Sebastian Gonzalez, Hao Jia, Ian Lu, Deniz Sogutlu, Abhishek Abhishek, Colin Gay, Eric Paquet, Roger Melko, Geoffrey C. Fox, Maximilian Swiatlowski, Wojciech Fedorko

Particle collisions at accelerators such as the Large Hadron Collider,
recorded and analyzed by experiments such as ATLAS and CMS, enable exquisite
measurements of the Standard Model and searches for new phenomena. Simulations
of collision events at these detectors have played a pivotal role in shaping
the design of future experiments and analyzing ongoing ones. However, the quest
for accuracy in Large Hadron Collider (LHC) collisions comes at an imposing
computational cost, with projections estimating the need for millions of
CPU-years annually during the High Luminosity LHC (HL-LHC) run
\cite{collaboration2022atlas}. Simulating a single LHC event with
\textsc{Geant4} currently devours around 1000 CPU seconds, with simulations of
the calorimeter subdetectors in particular imposing substantial computational
demands \cite{rousseau2023experimental}. To address this challenge, we propose
a conditioned quantum-assisted deep generative model. Our model integrates a
conditioned variational autoencoder (VAE) on the exterior with a conditioned
Restricted Boltzmann Machine (RBM) in the latent space, providing enhanced
expressiveness compared to conventional VAEs. The RBM nodes and connections are
meticulously engineered to enable the use of qubits and couplers on D-Wave's
Pegasus-structured \textit{Advantage} quantum annealer (QA) for sampling. We
introduce a novel method for conditioning the quantum-assisted RBM using
\textit{flux biases}. We further propose a novel adaptive mapping to estimate
the effective inverse temperature in quantum annealers. The effectiveness of
our framework is illustrated using Dataset 2 of the CaloChallenge
\cite{calochallenge}.

摘要：在大型強子對撞機等加速器中的粒子碰撞，由 ATLAS 和 CMS 等實驗記錄和分析，能精確測量標準模型並搜尋新現象。這些探測器中碰撞事件的模擬在塑造未來實驗的設計和分析正在進行的實驗中扮演了關鍵角色。然而，在大型強子對撞機 (LHC) 碰撞中追求準確性會帶來龐大的運算成本，預計在高亮度 LHC (HL-LHC) 運行期間每年需要數百萬個 CPU 年\cite{collaboration2022atlas}。目前，使用\textsc{Geant4}模擬單個 LHC 事件大約需要 1000 個 CPU 秒，特別是量能器次探測器的模擬會帶來大量的運算需求\cite{rousseau2023experimental}。為了應對這個挑戰，我們提出了一個條件量子輔助深度生成模型。我們的模型整合了一個條件變異自動編碼器 (VAE) 到外部，並在潛在空間中加入了一個條件限制玻爾茲曼機 (RBM)，與傳統的 VAE 相比，提供了增強的表達能力。RBM 節點和連接經過精心設計，可以在 D-Wave 的飛馬結構\textit{Advantage}量子退火器 (QA) 上使用量子位元和耦合器進行取樣。我們引入了一種使用\textit{磁通偏壓}對量子輔助 RBM 進行條件化的創新方法。我們進一步提出了一種新的自適應對應，以估計量子退火器中的有效逆溫度。我們使用 CaloChallenge\cite{calochallenge} 的資料集 2 來說明我們架構的有效性。

##### **Danoliteracy of Generative, Large Language Models**
2410.22839v1 by Søren Vejlgaard Holm, Lars Kai Hansen, Martin Carsten Nielsen

The language technology moonshot moment of Generative, Large Language Models
(GLLMs) was not limited to English: These models brought a surge of
technological applications, investments and hype to low-resource languages as
well. However, the capabilities of these models in languages such as Danish
were until recently difficult to verify beyond qualitative demonstrations due
to a lack of applicable evaluation corpora. We present a GLLM benchmark to
evaluate Danoliteracy, a measure of Danish language and cultural competency,
across eight diverse scenarios such Danish citizenship tests and abstractive
social media question answering. This limited-size benchmark is found to
produce a robust ranking that correlates to human feedback at $\rho \sim 0.8$
with GPT-4 and Claude Opus models achieving the highest rankings. Analyzing
these model results across scenarios, we find one strong underlying factor
explaining $95\%$ of scenario performance variance for GLLMs in Danish,
suggesting a $g$ factor of model consistency in language adaption.

摘要：生成式大型语言模型 (GLLM) 的语言技术飞跃时刻不仅限于英语：这些模型为资源匮乏的语言带来了技术应用、投资和炒作热潮。然而，由于缺乏适用的评估语料库，直到最近，这些模型在丹麦语等语言中的能力才难以通过定性演示来验证。我们提出了一个 GLLM 基准来评估丹麦语素养，即丹麦语言和文化能力的衡量标准，涵盖八种不同的场景，如丹麦公民身份测试和抽象社交媒体问答。发现这个小规模基准产生了稳健的排名，与人类反馈相关，其中 GPT-4 和 Claude Opus 模型获得了最高排名。通过分析这些模型在不同场景中的结果，我们发现了一个强有力的潜在因素，解释了丹麦语 GLLM 95% 的场景性能差异，表明模型一致性在语言适应中的 g 因子。

##### **HijackRAG: Hijacking Attacks against Retrieval-Augmented Large Language Models**
2410.22832v1 by Yucheng Zhang, Qinfeng Li, Tianyu Du, Xuhong Zhang, Xinkui Zhao, Zhengwen Feng, Jianwei Yin

Retrieval-Augmented Generation (RAG) systems enhance large language models
(LLMs) by integrating external knowledge, making them adaptable and
cost-effective for various applications. However, the growing reliance on these
systems also introduces potential security risks. In this work, we reveal a
novel vulnerability, the retrieval prompt hijack attack (HijackRAG), which
enables attackers to manipulate the retrieval mechanisms of RAG systems by
injecting malicious texts into the knowledge database. When the RAG system
encounters target questions, it generates the attacker's pre-determined answers
instead of the correct ones, undermining the integrity and trustworthiness of
the system. We formalize HijackRAG as an optimization problem and propose both
black-box and white-box attack strategies tailored to different levels of the
attacker's knowledge. Extensive experiments on multiple benchmark datasets show
that HijackRAG consistently achieves high attack success rates, outperforming
existing baseline attacks. Furthermore, we demonstrate that the attack is
transferable across different retriever models, underscoring the widespread
risk it poses to RAG systems. Lastly, our exploration of various defense
mechanisms reveals that they are insufficient to counter HijackRAG, emphasizing
the urgent need for more robust security measures to protect RAG systems in
real-world deployments.

摘要：檢索增強生成 (RAG) 系統透過整合外部知識，增強大型語言模型 (LLM)，讓其適應各種應用，且具有成本效益。然而，越來越依賴這些系統也引入了潛在的安全風險。在這項工作中，我們揭露了一個新的漏洞，稱為檢索提示劫持攻擊 (HijackRAG)，讓攻擊者能夠透過將惡意文字注入知識庫中，來操縱 RAG 系統的檢索機制。當 RAG 系統遇到目標問題時，它會產生攻擊者預先設定好的答案，而不是正確的答案，破壞了系統的完整性和可信度。我們將 HijackRAG 正式化為一個最佳化問題，並針對攻擊者知識的不同層級，提出黑盒和白盒攻擊策略。在多個基準資料集上進行的廣泛實驗顯示，HijackRAG 持續達成高攻擊成功率，優於現有的基準攻擊。此外，我們證明了這種攻擊可以轉移到不同的檢索器模型，強調了它對 RAG 系統構成的廣泛風險。最後，我們探索了各種防禦機制，發現它們不足以對抗 HijackRAG，強調了在實際部署中保護 RAG 系統時，迫切需要更強大的安全措施。

##### **How Well Do Large Language Models Disambiguate Swedish Words?**
2410.22827v1 by Richard Johansson

We evaluate a battery of recent large language models on two benchmarks for
word sense disambiguation in Swedish. At present, all current models are less
accurate than the best supervised disambiguators in cases where a training set
is available, but most models outperform graph-based unsupervised systems.
Different prompting approaches are compared, with a focus on how to express the
set of possible senses in a given context. The best accuracies are achieved
when human-written definitions of the senses are included in the prompts.

摘要：我們針對兩個瑞典語詞彙意義消歧基準，評估一系列近期的大型語言模型。目前，在有訓練集可用的情況下，所有現有模型的準確度都低於最佳監督式消歧器，但大多數模型的表現都優於基於圖形的非監督式系統。比較了不同的提示方法，重點在於如何在特定脈絡中表達可能的意義集合。當提示中包含人類撰寫的意義定義時，可達到最佳準確度。

##### **EvoCodeBench: An Evolving Code Generation Benchmark with Domain-Specific Evaluations**
2410.22821v1 by Jia Li, Ge Li, Xuanming Zhang, Yunfei Zhao, Yihong Dong, Zhi Jin, Binhua Li, Fei Huang, Yongbin Li

How to evaluate Large Language Models (LLMs) in code generation remains an
open question. Existing benchmarks have two limitations - data leakage and lack
of domain-specific evaluation. The former hurts the fairness of benchmarks, and
the latter hinders practitioners from selecting superior LLMs for specific
programming domains. To address these two limitations, we propose a new
benchmark - EvoCodeBench, which has the following advances: (1) Evolving data.
EvoCodeBench will be dynamically updated every period (e.g., 6 months) to avoid
data leakage. This paper releases the first version - EvoCodeBench-2403,
containing 275 samples from 25 repositories. (2) A domain taxonomy and domain
labels. Based on the statistics of open-source communities, we design a
programming domain taxonomy consisting of 10 popular domains. Based on the
taxonomy, we annotate each sample in EvoCodeBench with a domain label. (3)
Domain-specific evaluations. Besides the Pass@k, we compute the Domain-Specific
Improvement (DSI) and define LLMs' comfort and strange domains. These
evaluations help practitioners select superior LLMs in specific domains and
discover the shortcomings of existing LLMs. We evaluate 8 popular LLMs (e.g.,
gpt-4, DeepSeek Coder) on EvoCodeBench and summarize some insights.
EvoCodeBench reveals the actual abilities of these LLMs in real-world
repositories. For example, the highest Pass@1 of gpt-4 on EvoCodeBench-2403 is
only 20.74%. Besides, we evaluate LLMs in different domains and discover their
comfort and strange domains. For example, gpt-4 performs best in most domains
but falls behind others in the Internet domain. StarCoder 2-15B unexpectedly
performs well in the Database domain and even outperforms 33B LLMs.
EvoCodeBench has been released.

摘要：<paragraph>如何評估大型語言模型 (LLM) 在程式碼生成中的表現仍然是一個開放性的問題。現有的基準有兩個限制 - 資料外洩和缺乏特定領域的評估。前者損害了基準的公平性，而後者阻礙了從業者為特定程式設計領域選擇優越的 LLM。為了解決這兩個限制，我們提出了一個新的基準 - EvoCodeBench，它具有以下進展：(1) 演進資料。EvoCodeBench 將每隔一段時間（例如 6 個月）動態更新，以避免資料外洩。本文發布了第一個版本 - EvoCodeBench-2403，其中包含來自 25 個儲存庫的 275 個範例。(2) 領域分類法和領域標籤。根據開源社群的統計資料，我們設計了一個包含 10 個熱門領域的程式設計領域分類法。根據分類法，我們使用領域標籤註解 EvoCodeBench 中的每個範例。(3) 領域特定的評估。除了 Pass@k，我們計算了特定領域的改進 (DSI) 並定義了 LLM 的舒適領域和陌生領域。這些評估有助於從業者在特定領域中選擇優越的 LLM，並發現現有 LLM 的缺點。我們在 EvoCodeBench 上評估了 8 個流行的 LLM（例如 gpt-4、DeepSeek Coder），並總結了一些見解。EvoCodeBench 揭示了這些 LLM 在真實世界儲存庫中的實際能力。例如，gpt-4 在 EvoCodeBench-2403 上的最高 Pass@1 僅為 20.74%。此外，我們評估了不同領域中的 LLM，並發現了它們的舒適領域和陌生領域。例如，gpt-4 在大多數領域中表現最佳，但在網際網路領域落後於其他領域。StarCoder 2-15B 在資料庫領域表現出乎意料地好，甚至優於 33B LLM。EvoCodeBench 已發布。</paragraph>

##### **Towards Robust and Efficient Federated Low-Rank Adaptation with Heterogeneous Clients**
2410.22815v1 by Jabin Koo, Minwoo Jang, Jungseul Ok

Federated fine-tuning for Large Language Models (LLMs) has recently gained
attention due to the heavy communication overhead of transmitting large model
updates. Low Rank Adaptation (LoRA) has been proposed as a solution, yet its
application in federated learning is complicated by discordance in aggregation.
Existing methods addressing this discordance often suffer from performance
degradation at low ranks in heterogeneous data settings. In response, we
introduce LoRA-A2 (Low Rank Adaptation with Alternating freeze and Adaptive
rank selection), which demonstrates robustness in challenging settings with low
ranks and high data heterogeneity. Our experimental findings reveal that
LoRA-A2 maintains performance even under extreme heterogeneity and low rank
conditions, achieving up to a 99.8% reduction in uploaded parameters compared
to full fine-tuning without compromising performance. This adaptive mechanism
boosts robustness and communication efficiency in federated fine-tuning,
enabling the practical deployment of LLMs in resource-constrained environments.

摘要：大型語言模型 (LLM) 的聯邦微調最近因傳輸大型模型更新的龐大通訊開銷而受到關注。低秩適應 (LoRA) 已被提出作為一種解決方案，但其在聯邦學習中的應用因聚合中的不一致而變得複雜。解決這種不一致的現有方法通常在異質數據設置的低秩中會出現效能下降的問題。為了解決這個問題，我們引入了 LoRA-A2（交替凍結和自適應秩選擇的低秩適應），它在低秩和高數據異質性的挑戰性設置中展現出穩健性。我們的實驗結果表明，即使在極端的異質性和低秩條件下，LoRA-A2 仍能維持效能，與完全微調相比，上傳參數減少了 99.8%，而不會損害效能。這種自適應機制提升了聯邦微調中的穩健性和通訊效率，使 LLM 能在資源受限的環境中實際部署。

##### **Universality of the $π^2/6$ Pathway in Avoiding Model Collapse**
2410.22812v1 by Apratim Dey, David Donoho

Researchers in empirical machine learning recently spotlighted their fears of
so-called Model Collapse. They imagined a discard workflow, where an initial
generative model is trained with real data, after which the real data are
discarded, and subsequently, the model generates synthetic data on which a new
model is trained. They came to the conclusion that models degenerate as
model-fitting generations proceed. However, other researchers considered an
augment workflow, where the original real data continue to be used in each
generation of training, augmented by synthetic data from models fit in all
earlier generations. Empirical results on canonical datasets and learning
procedures confirmed the occurrence of model collapse under the discard
workflow and avoidance of model collapse under the augment workflow. Under the
augment workflow, theoretical evidence also confirmed avoidance in particular
instances; specifically, Gerstgrasser et al. (2024) found that for classical
Linear Regression, test risk at any later generation is bounded by a moderate
multiple, viz. pi-squared-over-6 of the test risk of training with the original
real data alone. Some commentators questioned the generality of theoretical
conclusions based on the generative model assumed in Gerstgrasser et al.
(2024): could similar conclusions be reached for other task/model pairings? In
this work, we demonstrate the universality of the pi-squared-over-6 augment
risk bound across a large family of canonical statistical models, offering key
insights into exactly why collapse happens under the discard workflow and is
avoided under the augment workflow. In the process, we provide a framework that
is able to accommodate a large variety of workflows (beyond discard and
augment), thereby enabling an experimenter to judge the comparative merits of
multiple different workflows by simulating a simple Gaussian process.

摘要：<paragraph>經驗機器學習的研究人員最近強調了他們對所謂模型崩潰的擔憂。他們想像一個丟棄工作流程，其中一個初始生成模型使用真實資料訓練，之後丟棄真實資料，隨後，模型會生成合成資料，並在合成資料上訓練一個新模型。他們得出的結論是，隨著模型擬合世代的進行，模型會退化。然而，其他研究人員考慮了一個擴充工作流程，其中原始真實資料會持續用於每一代訓練，並擴充來自所有先前世代中擬合模型的合成資料。標準資料集和學習程序的經驗結果證實了在丟棄工作流程下會發生模型崩潰，而在擴充工作流程下則避免了模型崩潰。在擴充工作流程下，理論證據也證實了在特定情況下避免了模型崩潰；具體來說，Gerstgrasser 等人 (2024) 發現，對於經典線性迴歸，任何後續世代的測試風險都受到適度倍數的限制，即僅使用原始真實資料訓練的測試風險的 pi 平方除以 6。一些評論者質疑了 Gerstgrasser 等人 (2024) 中假設的生成模型所依據的理論結論的一般性：是否可以對其他任務/模型配對得出類似的結論？在這項工作中，我們證明了 pi 平方除以 6 擴充風險界限在許多標準統計模型的大家族中具有普遍性，提供了關鍵見解，說明了為什麼崩潰會在丟棄工作流程下發生，而在擴充工作流程下則可以避免。在此過程中，我們提供了一個框架，能夠容納各種工作流程（不只是丟棄和擴充），從而使實驗者能夠透過模擬一個簡單的高斯過程來判斷多個不同工作流程的比較優缺點。</paragraph>

##### **Causality-Enhanced Behavior Sequence Modeling in LLMs for Personalized Recommendation**
2410.22809v1 by Yang Zhang, Juntao You, Yimeng Bai, Jizhi Zhang, Keqin Bao, Wenjie Wang, Tat-Seng Chua

Recent advancements in recommender systems have focused on leveraging Large
Language Models (LLMs) to improve user preference modeling, yielding promising
outcomes. However, current LLM-based approaches struggle to fully leverage user
behavior sequences, resulting in suboptimal preference modeling for
personalized recommendations. In this study, we propose a novel Counterfactual
Fine-Tuning (CFT) method to address this issue by explicitly emphasizing the
role of behavior sequences when generating recommendations. Specifically, we
employ counterfactual reasoning to identify the causal effects of behavior
sequences on model output and introduce a task that directly fits the
ground-truth labels based on these effects, achieving the goal of explicit
emphasis. Additionally, we develop a token-level weighting mechanism to adjust
the emphasis strength for different item tokens, reflecting the diminishing
influence of behavior sequences from earlier to later tokens during predicting
an item. Extensive experiments on real-world datasets demonstrate that CFT
effectively improves behavior sequence modeling. Our codes are available at
https://github.com/itsmeyjt/CFT.

摘要：推薦系統的最新進展集中於利用大型語言模型 (LLM) 來改善使用者偏好建模，產生有前景的成果。然而，現有的基於 LLM 的方法難以充分利用使用者行為序列，導致個人化推薦的偏好建模次優。在本研究中，我們提出了一種創新的反事實微調 (CFT) 方法來解決這個問題，方法是明確強調行為序列在產生推薦時的影響。具體來說，我們採用反事實推理來識別行為序列對模型輸出的因果關係，並引入一個任務，根據這些影響直接符合真實標籤，達到明確強調的目標。此外，我們開發了一個令牌級別的加權機制來調整不同項目令牌的強調強度，反映出行為序列在預測項目時從較早的令牌到較晚的令牌的影響力遞減。在真實世界資料集上的大量實驗表明，CFT 有效地改善了行為序列建模。我們的程式碼可在 https://github.com/itsmeyjt/CFT 獲得。

##### **Dual Contrastive Transformer for Hierarchical Preference Modeling in Sequential Recommendation**
2410.22790v1 by Chengkai Huang, Shoujin Wang, Xianzhi Wang, Lina Yao

Sequential recommender systems (SRSs) aim to predict the subsequent items
which may interest users via comprehensively modeling users' complex preference
embedded in the sequence of user-item interactions. However, most of existing
SRSs often model users' single low-level preference based on item ID
information while ignoring the high-level preference revealed by item attribute
information, such as item category. Furthermore, they often utilize limited
sequence context information to predict the next item while overlooking richer
inter-item semantic relations. To this end, in this paper, we proposed a novel
hierarchical preference modeling framework to substantially model the complex
low- and high-level preference dynamics for accurate sequential recommendation.
Specifically, in the framework, a novel dual-transformer module and a novel
dual contrastive learning scheme have been designed to discriminatively learn
users' low- and high-level preference and to effectively enhance both low- and
high-level preference learning respectively. In addition, a novel
semantics-enhanced context embedding module has been devised to generate more
informative context embedding for further improving the recommendation
performance. Extensive experiments on six real-world datasets have demonstrated
both the superiority of our proposed method over the state-of-the-art ones and
the rationality of our design.

摘要：序列推薦系統 (SRS) 的目的是預測後續項目，這些項目可能透過全面建模嵌入在使用者與項目互動序列中的使用者的複雜偏好來引起使用者的興趣。然而，現有的 SRS 大多常根據項目 ID 資訊來建模使用者的單一低層級偏好，同時忽略項目屬性資訊（例如項目類別）所揭示的高層級偏好。此外，他們通常利用有限的序列脈絡資訊來預測下一個項目，同時忽略更豐富的項目間語義關係。為此，在本文中，我們提出了一個新穎的分層偏好建模架構，以實質性地建模複雜的低層級和高層級偏好動態，以進行準確的序列推薦。具體來說，在該架構中，設計了一個新穎的雙重Transformer模組和一個新穎的雙重對比學習方案，分別用於區別性地學習使用者的低層級和高層級偏好，並有效地增強低層級和高層級偏好學習。此外，還設計了一個新穎的語義增強脈絡嵌入模組，以產生更多資訊性的脈絡嵌入，進一步改善推薦效能。在六個真實世界資料集上進行的大量實驗證明了我們提出的方法優於現有技術，以及我們設計的合理性。

##### **MALoRA: Mixture of Asymmetric Low-Rank Adaptation for Enhanced Multi-Task Learning**
2410.22782v1 by Xujia Wang, Haiyan Zhao, Shuo Wang, Hanqing Wang, Zhiyuan Liu

Parameter-Efficient Fine-Tuning (PEFT) methods like LoRA have significantly
improved the adaptation of LLMs to downstream tasks in a resource-efficient
manner. However, in multi-task scenarios, challenges such as training imbalance
and the seesaw effect frequently emerge. Mixture-of-LoRA (MoLoRA), which
combines LoRA with sparse Mixture-of-Experts, mitigates some of these issues by
promoting task-specific learning across experts. Despite this, MoLoRA remains
inefficient in terms of training speed, parameter utilization, and overall
multi-task performance. In this paper, we propose Mixture of Asymmetric
Low-Rank Adaptaion (MALoRA), a flexible fine-tuning framework that leverages
asymmetric optimization across LoRA experts. MALoRA reduces the number of
trainable parameters by 30% to 48%, increases training speed by 1.2x, and
matches the computational efficiency of single-task LoRA models. Additionally,
MALoRA addresses overfitting issues commonly seen in high-rank configurations,
enhancing performance stability. Extensive experiments across diverse
multi-task learning scenarios demonstrate that MALoRA consistently outperforms
all baseline methods in both inter-domain and intra-domain tasks.

摘要：參數有效微調 (PEFT) 方法（例如 LoRA）已大幅提升 LLM 在資源有效的方式下適應下游任務。然而，在多任務情境中，經常出現訓練不平衡和蹺蹺板效應等挑戰。混合 LoRA (MoLoRA) 將 LoRA 與稀疏專家混合結合，透過促進跨專家的任務特定學習來緩解其中一些問題。儘管如此，MoLoRA 在訓練速度、參數使用和整體多任務效能方面仍然效率不彰。在本文中，我們提出非對稱低階適應混合 (MALoRA)，這是一種靈活的微調架構，可利用 LoRA 專家之間的非對稱最佳化。MALoRA 將可訓練參數數量減少 30% 至 48%，將訓練速度提升 1.2 倍，並與單一任務 LoRA 模型的運算效率相匹配。此外，MALoRA 解決了在高階組態中常見的過度擬合問題，進而提升效能穩定性。跨不同多任務學習情境的廣泛實驗證明，MALoRA 在領域間和領域內任務中始終優於所有基準方法。

##### **InjecGuard: Benchmarking and Mitigating Over-defense in Prompt Injection Guardrail Models**
2410.22770v1 by Hao Li, Xiaogeng Liu, Chaowei Xiao

Prompt injection attacks pose a critical threat to large language models
(LLMs), enabling goal hijacking and data leakage. Prompt guard models, though
effective in defense, suffer from over-defense -- falsely flagging benign
inputs as malicious due to trigger word bias. To address this issue, we
introduce NotInject, an evaluation dataset that systematically measures
over-defense across various prompt guard models. NotInject contains 339 benign
samples enriched with trigger words common in prompt injection attacks,
enabling fine-grained evaluation. Our results show that state-of-the-art models
suffer from over-defense issues, with accuracy dropping close to random
guessing levels (60%). To mitigate this, we propose InjecGuard, a novel prompt
guard model that incorporates a new training strategy, Mitigating Over-defense
for Free (MOF), which significantly reduces the bias on trigger words.
InjecGuard demonstrates state-of-the-art performance on diverse benchmarks
including NotInject, surpassing the existing best model by 30.8%, offering a
robust and open-source solution for detecting prompt injection attacks. The
code and datasets are released at https://github.com/SaFoLab-WISC/InjecGuard.

摘要：提示注入攻击对大型语言模型 (LLM) 构成严重威胁，可能导致目标劫持和数据泄露。提示防护模型虽然在防御方面很有效，但会过度防御——由于触发词偏差，错误地将良性输入标记为恶意。为了解决这个问题，我们引入了 NotInject，这是一个评估数据集，可以系统地衡量各种提示防护模型的过度防御。NotInject 包含 339 个良性样本，其中包含提示注入攻击中常见的触发词，从而能够进行细粒度的评估。我们的结果表明，最先进的模型存在过度防御问题，准确率下降到接近随机猜测的水平 (60%)。为了缓解这个问题，我们提出了 InjecGuard，这是一种新的提示防护模型，它包含了一种新的训练策略，即免费缓解过度防御 (MOF)，该策略可以显著减少对触发词的偏差。InjecGuard 在包括 NotInject 在内的各种基准测试中展示了最先进的性能，比现有的最佳模型高出 30.8%，为检测提示注入攻击提供了一个健壮且开源的解决方案。代码和数据集已在 https://github.com/SaFoLab-WISC/InjecGuard 发布。

##### **Beyond Ontology in Dialogue State Tracking for Goal-Oriented Chatbot**
2410.22767v1 by Sejin Lee, Dongha Kim, Min Song

Goal-oriented chatbots are essential for automating user tasks, such as
booking flights or making restaurant reservations. A key component of these
systems is Dialogue State Tracking (DST), which interprets user intent and
maintains the dialogue state. However, existing DST methods often rely on fixed
ontologies and manually compiled slot values, limiting their adaptability to
open-domain dialogues. We propose a novel approach that leverages instruction
tuning and advanced prompt strategies to enhance DST performance, without
relying on any predefined ontologies. Our method enables Large Language Model
(LLM) to infer dialogue states through carefully designed prompts and includes
an anti-hallucination mechanism to ensure accurate tracking in diverse
conversation contexts. Additionally, we employ a Variational Graph Auto-Encoder
(VGAE) to model and predict subsequent user intent. Our approach achieved
state-of-the-art with a JGA of 42.57% outperforming existing ontology-less DST
models, and performed well in open-domain real-world conversations. This work
presents a significant advancement in creating more adaptive and accurate
goal-oriented chatbots.

摘要：以目標為導向的聊天機器人在自動化使用者任務中至關重要，例如預訂航班或進行餐廳訂位。這些系統的一個關鍵組成部分是對話狀態追蹤 (DST)，它會解譯使用者的意圖並維護對話狀態。然而，現有的 DST 方法通常依賴於固定的本体和手動編譯的槽位值，這限制了它們對開放領域對話的適應性。我們提出了一種新穎的方法，它利用指令調整和先進的提示策略來增強 DST 效能，而無需依賴任何預定義的本体。我們的方法使大型語言模型 (LLM) 能夠透過精心設計的提示來推論對話狀態，並包含一個反幻覺機制，以確保在不同的對話情境中準確追蹤。此外，我們採用變分圖自編碼器 (VGAE) 來建模和預測後續使用者的意圖。我們的做法以 42.57% 的 JGA 達到了現有技術的頂峰，優於現有的無本体 DST 模型，並在開放領域的真實對話中表現良好。這項工作在建立更具適應性和準確性的以目標為導向的聊天機器人方面取得了重大進展。

##### **Self-Driving Car Racing: Application of Deep Reinforcement Learning**
2410.22766v1 by Florentiana Yuwono, Gan Pang Yen, Jason Christopher

This paper explores the application of deep reinforcement learning (RL)
techniques in the domain of autonomous self-driving car racing. Motivated by
the rise of AI-driven mobility and autonomous racing events, the project aims
to develop an AI agent that efficiently drives a simulated car in the OpenAI
Gymnasium CarRacing environment. We investigate various RL algorithms,
including Deep Q-Network (DQN), Proximal Policy Optimization (PPO), and novel
adaptations that incorporate transfer learning and recurrent neural networks
(RNNs) for enhanced performance. The project demonstrates that while DQN
provides a strong baseline for policy learning, integrating ResNet and LSTM
models significantly improves the agent's ability to capture complex spatial
and temporal dynamics. PPO, particularly in continuous action spaces, shows
promising results for fine control, although challenges such as policy collapse
remain. We compare the performance of these approaches and outline future
research directions focused on improving computational efficiency and
addressing model stability. Our findings contribute to the ongoing development
of AI systems in autonomous driving and related control tasks.

摘要：本文探討深度強化學習 (RL) 技術在自動自駕車競賽領域的應用。受 AI 驅動的行動性和自動駕駛賽事的興起所激勵，本專案旨在開發一個 AI 代理，以便在 OpenAI Gymnasium CarRacing 環境中有效地駕駛模擬汽車。我們研究了各種 RL 演算法，包括深度 Q 網路 (DQN)、近端策略最佳化 (PPO)，以及結合轉移學習和遞迴神經網路 (RNN) 以增強效能的新穎改編。本專案證明，雖然 DQN 為策略學習提供了強大的基準，但整合 ResNet 和 LSTM 模型可顯著提升代理捕捉複雜空間和時間動態的能力。PPO，特別是在連續動作空間中，顯示出對於精細控制很有希望的結果，儘管策略崩潰等挑戰依然存在。我們比較了這些方法的效能，並概述了專注於改善運算效率和解決模型穩定性的未來研究方向。我們的研究結果有助於自動駕駛和相關控制任務中 AI 系統的持續發展。

##### **Constructing Multimodal Datasets from Scratch for Rapid Development of a Japanese Visual Language Model**
2410.22736v1 by Keito Sasagawa, Koki Maeda, Issa Sugiura, Shuhei Kurita, Naoaki Okazaki, Daisuke Kawahara

To develop high-performing Visual Language Models (VLMs), it is essential to
prepare multimodal resources, such as image-text pairs, interleaved data, and
instruction data. While multimodal resources for English are abundant, there is
a significant lack of corresponding resources for non-English languages, such
as Japanese. To address this problem, we take Japanese as a non-English
language and propose a method for rapidly creating Japanese multimodal datasets
from scratch. We collect Japanese image-text pairs and interleaved data from
web archives and generate Japanese instruction data directly from images using
an existing VLM. Our experimental results show that a VLM trained on these
native datasets outperforms those relying on machine-translated content.

摘要：為了開發高性能視覺語言模型 (VLM)，準備多模態資源至關重要，例如圖文配對、交錯資料和指令資料。雖然英文的多模態資源豐富，但非英文語言（如日文）的對應資源卻嚴重不足。為了解決這個問題，我們將日文視為非英文語言，並提出一個從頭開始快速建立日文多模態資料集的方法。我們從網路檔案館收集日文圖文配對和交錯資料，並使用現有的 VLM 直接從圖片產生日文指令資料。我們的實驗結果顯示，使用這些原生資料集訓練的 VLM 優於依賴機器翻譯內容的 VLM。

##### **st-DTPM: Spatial-Temporal Guided Diffusion Transformer Probabilistic Model for Delayed Scan PET Image Prediction**
2410.22732v1 by Ran Hong, Yuxia Huang, Lei Liu, Zhonghui Wu, Bingxuan Li, Xuemei Wang, Qiegen Liu

PET imaging is widely employed for observing biological metabolic activities
within the human body. However, numerous benign conditions can cause increased
uptake of radiopharmaceuticals, confounding differentiation from malignant
tumors. Several studies have indicated that dual-time PET imaging holds promise
in distinguishing between malignant and benign tumor processes. Nevertheless,
the hour-long distribution period of radiopharmaceuticals post-injection
complicates the determination of optimal timing for the second scan, presenting
challenges in both practical applications and research. Notably, we have
identified that delay time PET imaging can be framed as an image-to-image
conversion problem. Motivated by this insight, we propose a novel
spatial-temporal guided diffusion transformer probabilistic model (st-DTPM) to
solve dual-time PET imaging prediction problem. Specifically, this architecture
leverages the U-net framework that integrates patch-wise features of CNN and
pixel-wise relevance of Transformer to obtain local and global information. And
then employs a conditional DDPM model for image synthesis. Furthermore, on
spatial condition, we concatenate early scan PET images and noisy PET images on
every denoising step to guide the spatial distribution of denoising sampling.
On temporal condition, we convert diffusion time steps and delay time to a
universal time vector, then embed it to each layer of model architecture to
further improve the accuracy of predictions. Experimental results demonstrated
the superiority of our method over alternative approaches in preserving image
quality and structural information, thereby affirming its efficacy in
predictive task.

摘要：正子斷層造影廣泛用於觀察人體內的生物代謝活動。然而，許多良性疾病會導致放射藥物攝取增加，進而混淆與惡性腫瘤的區別。多項研究表明，雙時相正子斷層造影有望區分惡性和良性腫瘤過程。儘管如此，注射後放射藥物長達一小時的分布期讓第二期掃描的最佳時機難以確定，對實際應用和研究都造成挑戰。值得注意的是，我們已發現延遲時間正子斷層造影可以視為影像轉影像的轉換問題。受此見解啟發，我們提出一個新穎的時空引導擴散轉換器機率模型 (st-DTPM) 來解決雙時相正子斷層造影預測問題。具體來說，此架構利用 U-net 框架，整合 CNN 的區塊特徵和 Transformer 的畫素相關性，以獲取局部和全局資訊。然後採用條件式 DDPM 模型進行影像合成。此外，在空間條件下，我們在每個去噪步驟中串接早期掃描正子斷層造影影像和雜訊正子斷層造影影像，以引導去噪採樣的空間分佈。在時間條件下，我們將擴散時間步長和延遲時間轉換為通用時間向量，然後將其嵌入模型架構的每一層，以進一步提高預測準確度。實驗結果證明，我們的方法在保留影像品質和結構資訊方面優於其他方法，從而肯定其在預測任務中的效能。

##### **Robotic State Recognition with Image-to-Text Retrieval Task of Pre-Trained Vision-Language Model and Black-Box Optimization**
2410.22707v1 by Kento Kawaharazuka, Yoshiki Obinata, Naoaki Kanazawa, Kei Okada, Masayuki Inaba

State recognition of the environment and objects, such as the open/closed
state of doors and the on/off of lights, is indispensable for robots that
perform daily life support and security tasks. Until now, state recognition
methods have been based on training neural networks from manual annotations,
preparing special sensors for the recognition, or manually programming to
extract features from point clouds or raw images. In contrast, we propose a
robotic state recognition method using a pre-trained vision-language model,
which is capable of Image-to-Text Retrieval (ITR) tasks. We prepare several
kinds of language prompts in advance, calculate the similarity between these
prompts and the current image by ITR, and perform state recognition. By
applying the optimal weighting to each prompt using black-box optimization,
state recognition can be performed with higher accuracy. Experiments show that
this theory enables a variety of state recognitions by simply preparing
multiple prompts without retraining neural networks or manual programming. In
addition, since only prompts and their weights need to be prepared for each
recognizer, there is no need to prepare multiple models, which facilitates
resource management. It is possible to recognize the open/closed state of
transparent doors, the state of whether water is running or not from a faucet,
and even the qualitative state of whether a kitchen is clean or not, which have
been challenging so far, through language.

摘要：機器人執行日常生活支援和安全任務時，必須辨識環境和物體的狀態，例如門的開/關狀態和燈的開/關狀態。到目前為止，狀態辨識方法一直是根據手動註解訓練神經網路、準備特殊感測器進行辨識，或手動編寫程式從點雲或原始影像中擷取特徵。相反地，我們提出使用預先訓練好的視覺語言模型的機器人狀態辨識方法，該模型能夠執行影像到文字檢索 (ITR) 任務。我們事先準備幾種語言提示，透過 ITR 計算這些提示和當前影像之間的相似性，並執行狀態辨識。透過使用黑盒最佳化對每個提示套用最佳權重，可以更準確地執行狀態辨識。實驗顯示，此理論只需準備多個提示，而無需重新訓練神經網路或手動編寫程式，即可進行各種狀態辨識。此外，由於每個辨識器只需要準備提示及其權重，因此無需準備多個模型，這有助於資源管理。可以透過語言辨識透明門的開/關狀態、水龍頭是否出水，甚至廚房是否乾淨的品質狀態，這些都是到目前為止的挑戰。

##### **Permutation Invariant Learning with High-Dimensional Particle Filters**
2410.22695v1 by Akhilan Boopathy, Aneesh Muppidi, Peggy Yang, Abhiram Iyer, William Yue, Ila Fiete

Sequential learning in deep models often suffers from challenges such as
catastrophic forgetting and loss of plasticity, largely due to the permutation
dependence of gradient-based algorithms, where the order of training data
impacts the learning outcome. In this work, we introduce a novel
permutation-invariant learning framework based on high-dimensional particle
filters. We theoretically demonstrate that particle filters are invariant to
the sequential ordering of training minibatches or tasks, offering a principled
solution to mitigate catastrophic forgetting and loss-of-plasticity. We develop
an efficient particle filter for optimizing high-dimensional models, combining
the strengths of Bayesian methods with gradient-based optimization. Through
extensive experiments on continual supervised and reinforcement learning
benchmarks, including SplitMNIST, SplitCIFAR100, and ProcGen, we empirically
show that our method consistently improves performance, while reducing variance
compared to standard baselines.

摘要：深度模型中的顺序學習通常會遇到災難性遺忘和可塑性喪失等挑戰，這在很大程度上是由於基於梯度的演算法的排列依賴性，其中訓練資料的順序會影響學習結果。在這項工作中，我們介紹了一個基於高維粒子濾波器的新穎排列不變學習框架。我們從理論上證明粒子濾波器對訓練小批次或任務的順序排列不變，提供了一個原則性的解決方案來減輕災難性遺忘和可塑性喪失。我們開發了一個用於最佳化高維模型的有效粒子濾波器，結合了貝氏方法和基於梯度的最佳化的優點。透過在持續監督和強化學習基準（包括 SplitMNIST、SplitCIFAR100 和 ProcGen）上進行廣泛的實驗，我們憑經驗表明，與標準基準相比，我們的模型持續改善效能，同時降低變異。

##### **Choice between Partial Trajectories**
2410.22690v1 by Henrik Marklund, Benjamin Van Roy

As AI agents generate increasingly sophisticated behaviors, manually encoding
human preferences to guide these agents becomes more challenging. To address
this, it has been suggested that agents instead learn preferences from human
choice data. This approach requires a model of choice behavior that the agent
can use to interpret the data. For choices between partial trajectories of
states and actions, previous models assume choice probabilities to be
determined by the partial return or the cumulative advantage.
  We consider an alternative model based instead on the bootstrapped return,
which adds to the partial return an estimate of the future return. Benefits of
the bootstrapped return model stem from its treatment of human beliefs. Unlike
partial return, choices based on bootstrapped return reflect human beliefs
about the environment. Further, while recovering the reward function from
choices based on cumulative advantage requires that those beliefs are correct,
doing so from choices based on bootstrapped return does not.
  To motivate the bootstrapped return model, we formulate axioms and prove an
Alignment Theorem. This result formalizes how, for a general class of human
preferences, such models are able to disentangle goals from beliefs. This
ensures recovery of an aligned reward function when learning from choices based
on bootstrapped return.
  The bootstrapped return model also affords greater robustness to choice
behavior. Even when choices are based on partial return, learning via a
bootstrapped return model recovers an aligned reward function. The same holds
with choices based on the cumulative advantage if the human and the agent both
adhere to correct and consistent beliefs about the environment. On the other
hand, if choices are based on bootstrapped return, learning via partial return
or cumulative advantage models does not generally produce an aligned reward
function.

摘要：隨著 AI 代理產生越來越複雜的行為，手動編碼人類偏好以引導這些代理變得更具挑戰性。為了解決這個問題，有人建議代理改為從人類選擇數據中學習偏好。這種方法需要一個選擇行為模型，代理可以使用該模型來解釋數據。對於狀態和動作的部分軌跡之間的選擇，先前的模型假設選擇機率是由部分回報或累積優勢決定的。
我們考慮一個基於自舉回報的替代模型，它在部分回報中增加了對未來回報的估計。自舉回報模型的好處源於它對人類信念的處理。與部分回報不同，基於自舉回報的選擇反映了人類對環境的信念。此外，雖然從基於累積優勢的選擇中恢復獎勵函數需要這些信念是正確的，但從基於自舉回報的選擇中這樣做則不需要。
為了激勵自舉回報模型，我們制定公理並證明一個對齊定理。這個結果形式化了對於人類偏好的一般類別，這些模型如何能夠區分目標和信念。這確保了從基於自舉回報的選擇中學習時，對齊獎勵函數的恢復。
自舉回報模型還提供了對選擇行為更大的魯棒性。即使選擇基於部分回報，通過自舉回報模型學習也會恢復對齊的獎勵函數。如果人類和代理都堅持對環境的正確和一致的信念，那麼基於累積優勢的選擇也是如此。另一方面，如果選擇基於自舉回報，則通過部分回報或累積優勢模型學習通常不會產生對齊的獎勵函數。

##### **Multi-Task Interactive Robot Fleet Learning with Visual World Models**
2410.22689v1 by Huihan Liu, Yu Zhang, Vaarij Betala, Evan Zhang, James Liu, Crystal Ding, Yuke Zhu

Recent advancements in large-scale multi-task robot learning offer the
potential for deploying robot fleets in household and industrial settings,
enabling them to perform diverse tasks across various environments. However,
AI-enabled robots often face challenges with generalization and robustness when
exposed to real-world variability and uncertainty. We introduce Sirius-Fleet, a
multi-task interactive robot fleet learning framework to address these
challenges. Sirius-Fleet monitors robot performance during deployment and
involves humans to correct the robot's actions when necessary. We employ a
visual world model to predict the outcomes of future actions and build anomaly
predictors to predict whether they will likely result in anomalies. As the
robot autonomy improves, the anomaly predictors automatically adapt their
prediction criteria, leading to fewer requests for human intervention and
gradually reducing human workload over time. Evaluations on large-scale
benchmarks demonstrate Sirius-Fleet's effectiveness in improving multi-task
policy performance and monitoring accuracy. We demonstrate Sirius-Fleet's
performance in both RoboCasa in simulation and Mutex in the real world, two
diverse, large-scale multi-task benchmarks. More information is available on
the project website: https://ut-austin-rpl.github.io/sirius-fleet

摘要：大型多任务机器人学习的近期进展提供了在家庭和工业环境中部署机器人车队的潜力，使他们能够在各种环境中执行不同的任务。然而，人工智能驱动的机器人经常面临泛化和鲁棒性方面的挑战，当暴露于现实世界的可变性和不确定性时。我们引入了 Sirius-Fleet，一个多任务交互式机器人车队学习框架来解决这些挑战。Sirius-Fleet 在部署期间监控机器人性能，并在必要时让人类来纠正机器人的动作。我们采用了一个视觉世界模型来预测未来动作的结果，并构建异常预测器来预测它们是否可能导致异常。随着机器人自主性的提高，异常预测器会自动调整其预测标准，从而减少对人类干预的请求，并随着时间的推移逐渐减少人类的工作量。在大规模基准测试上的评估证明了 Sirius-Fleet 在提高多任务策略性能和监控准确性方面的有效性。我们展示了 Sirius-Fleet 在模拟中的 RoboCasa 和现实世界中的 Mutex 中的性能，这两个大型多任务基准测试具有多样性。更多信息可在项目网站上找到：https://ut-austin-rpl.github.io/sirius-fleet

##### **Improving Uncertainty Quantification in Large Language Models via Semantic Embeddings**
2410.22685v1 by Yashvir S. Grewal, Edwin V. Bonilla, Thang D. Bui

Accurately quantifying uncertainty in large language models (LLMs) is crucial
for their reliable deployment, especially in high-stakes applications. Current
state-of-the-art methods for measuring semantic uncertainty in LLMs rely on
strict bidirectional entailment criteria between multiple generated responses
and also depend on sequence likelihoods. While effective, these approaches
often overestimate uncertainty due to their sensitivity to minor wording
differences, additional correct information, and non-important words in the
sequence. We propose a novel approach that leverages semantic embeddings to
achieve smoother and more robust estimation of semantic uncertainty in LLMs. By
capturing semantic similarities without depending on sequence likelihoods, our
method inherently reduces any biases introduced by irrelevant words in the
answers. Furthermore, we introduce an amortised version of our approach by
explicitly modelling semantics as latent variables in a joint probabilistic
model. This allows for uncertainty estimation in the embedding space with a
single forward pass, significantly reducing computational overhead compared to
existing multi-pass methods. Experiments across multiple question-answering
datasets and frontier LLMs demonstrate that our embedding-based methods provide
more accurate and nuanced uncertainty quantification than traditional
approaches.

摘要：準確量化大型語言模型 (LLM) 中的不確定性，對於它們的可靠部署至關重要，尤其是在高風險應用中。目前用於衡量 LLM 中語義不確定性的最先進方法依賴於多個生成回應之間的嚴格雙向蘊涵準則，並且也依賴於序列可能性。儘管有效，但這些方法由於對細微措辭差異、額外的正確資訊和序列中不重要的字詞敏感，因此經常高估不確定性。我們提出了一種新穎的方法，該方法利用語義嵌入來實現對 LLM 中語義不確定性的更平滑、更穩健的估計。通過在不依賴序列可能性情況下擷取語義相似性，我們的模型本質上減少了答案中無關字詞帶來的任何偏差。此外，我們通過在聯合機率模型中將語義明確建模為潛在變數，引入了我們方法的攤銷版本。這允許在嵌入空間中使用單次前向傳遞來估計不確定性，與現有的多重傳遞方法相比，大幅降低了運算負擔。跨多個問答資料集和前沿 LLM 的實驗表明，我們的基於嵌入的方法提供了比傳統方法更準確、更細緻的不確定性量化。

##### **Backdoor Attack Against Vision Transformers via Attention Gradient-Based Image Erosion**
2410.22678v1 by Ji Guo, Hongwei Li, Wenbo Jiang, Guoming Lu

Vision Transformers (ViTs) have outperformed traditional Convolutional Neural
Networks (CNN) across various computer vision tasks. However, akin to CNN, ViTs
are vulnerable to backdoor attacks, where the adversary embeds the backdoor
into the victim model, causing it to make wrong predictions about testing
samples containing a specific trigger. Existing backdoor attacks against ViTs
have the limitation of failing to strike an optimal balance between attack
stealthiness and attack effectiveness.
  In this work, we propose an Attention Gradient-based Erosion Backdoor (AGEB)
targeted at ViTs. Considering the attention mechanism of ViTs, AGEB selectively
erodes pixels in areas of maximal attention gradient, embedding a covert
backdoor trigger. Unlike previous backdoor attacks against ViTs, AGEB achieves
an optimal balance between attack stealthiness and attack effectiveness,
ensuring the trigger remains invisible to human detection while preserving the
model's accuracy on clean samples. Extensive experimental evaluations across
various ViT architectures and datasets confirm the effectiveness of AGEB,
achieving a remarkable Attack Success Rate (ASR) without diminishing Clean Data
Accuracy (CDA). Furthermore, the stealthiness of AGEB is rigorously validated,
demonstrating minimal visual discrepancies between the clean and the triggered
images.

摘要：視覺 Transformer (ViT) 在各種電腦視覺任務中優於傳統的卷積神經網路 (CNN)。然而，與 CNN 類似，ViT 容易受到後門攻擊，其中對手將後門嵌入受害者模型，導致其對包含特定觸發器的測試樣本做出錯誤預測。現有的針對 ViT 的後門攻擊存在無法在攻擊隱蔽性和攻擊有效性之間取得最佳平衡的限制。
在這項工作中，我們提出了一個針對 ViT 的基於注意梯度的侵蝕後門 (AGEB)。考慮到 ViT 的注意機制，AGEB 選擇性地侵蝕最大注意梯度的區域像素，嵌入一個隱蔽的後門觸發器。與先前針對 ViT 的後門攻擊不同，AGEB 在攻擊隱蔽性和攻擊有效性之間實現了最佳平衡，確保觸發器對人類檢測保持不可見，同時保持模型對乾淨樣本的準確性。跨各種 ViT 架構和資料集進行的廣泛實驗評估證實了 AGEB 的有效性，實現了顯著的攻擊成功率 (ASR)，而不會降低乾淨數據準確度 (CDA)。此外，AGEB 的隱蔽性得到了嚴格驗證，證明了乾淨圖像和觸發圖像之間最小的視覺差異。

##### **Automated Trustworthiness Oracle Generation for Machine Learning Text Classifiers**
2410.22663v1 by Lam Nguyen Tung, Steven Cho, Xiaoning Du, Neelofar Neelofar, Valerio Terragni, Stefano Ruberto, Aldeida Aleti

Machine learning (ML) for text classification has been widely used in various
domains, such as toxicity detection, chatbot consulting, and review analysis.
These applications can significantly impact ethics, economics, and human
behavior, raising serious concerns about trusting ML decisions. Several studies
indicate that traditional metrics, such as model confidence and accuracy, are
insufficient to build human trust in ML models. These models often learn
spurious correlations during training and predict based on them during
inference. In the real world, where such correlations are absent, their
performance can deteriorate significantly. To avoid this, a common practice is
to test whether predictions are reasonable. Along with this, a challenge known
as the trustworthiness oracle problem has been introduced. Due to the lack of
automated trustworthiness oracles, the assessment requires manual validation of
the decision process disclosed by explanation methods, which is time-consuming
and not scalable. We propose TOKI, the first automated trustworthiness oracle
generation method for text classifiers, which automatically checks whether the
prediction-contributing words are related to the predicted class using
explanation methods and word embeddings. To demonstrate its practical
usefulness, we introduce a novel adversarial attack method targeting
trustworthiness issues identified by TOKI. We compare TOKI with a naive
baseline based solely on model confidence using human-created ground truths of
6,000 predictions. We also compare TOKI-guided adversarial attack method with
A2T, a SOTA adversarial attack method. Results show that relying on prediction
uncertainty cannot distinguish between trustworthy and untrustworthy
predictions, TOKI achieves 142% higher accuracy than the naive baseline, and
TOKI-guided adversarial attack method is more effective with fewer
perturbations than A2T.

摘要：機器學習 (ML) 已廣泛用於文本分類的各個領域，例如毒性檢測、聊天機器人諮詢和評論分析。這些應用會對道德、經濟和人類行為產生重大影響，引發了對信任 ML 決策的嚴重疑慮。多項研究指出，傳統指標（例如模型信心和準確度）不足以建立人類對 ML 模型的信任。這些模型在訓練期間通常會學習到虛假的相關性，並在推理期間根據這些相關性進行預測。在現實世界中，當這些相關性不存在時，它們的效能可能會大幅下降。為了避免這種情況，一種常見的做法是測試預測是否合理。與此同時，引入了稱為可信賴性預言機問題的挑戰。由於缺乏自動化的可信賴性預言機，評估需要手動驗證說明方法所揭露的決策流程，這既耗時又無法擴展。我們提出了 TOKI，這是第一個針對文本分類器的自動化可信賴性預言機生成方法，它使用說明方法和字詞嵌入自動檢查預測相關字詞是否與預測類別相關。為了展示其實際效用，我們介紹了一種新穎的對抗攻擊方法，針對 TOKI 識別出的可信賴性問題。我們使用人類建立的 6,000 個預測的真實依據，將 TOKI 與僅基於模型信心的樸素基準進行比較。我們還將 TOKI 引導的對抗攻擊方法與 A2T（一種 SOTA 對抗攻擊方法）進行比較。結果表明，依賴預測不確定性無法區分可信賴性和不可信賴性的預測，TOKI 的準確度比樸素基準高出 142%，而 TOKI 引導的對抗攻擊方法比 A2T 更有效，且擾動更少。

##### **$\textbf{EMOS}$: $\textbf{E}$mbodiment-aware Heterogeneous $\textbf{M}$ulti-robot $\textbf{O}$perating $\textbf{S}$ystem with LLM Agents**
2410.22662v1 by Junting Chen, Checheng Yu, Xunzhe Zhou, Tianqi Xu, Yao Mu, Mengkang Hu, Wenqi Shao, Yikai Wang, Guohao Li, Lin Shao

Heterogeneous multi-robot systems (HMRS) have emerged as a powerful approach
for tackling complex tasks that single robots cannot manage alone. Current
large-language-model-based multi-agent systems (LLM-based MAS) have shown
success in areas like software development and operating systems, but applying
these systems to robot control presents unique challenges. In particular, the
capabilities of each agent in a multi-robot system are inherently tied to the
physical composition of the robots, rather than predefined roles. To address
this issue, we introduce a novel multi-agent framework designed to enable
effective collaboration among heterogeneous robots with varying embodiments and
capabilities, along with a new benchmark named Habitat-MAS. One of our key
designs is $\textit{Robot Resume}$: Instead of adopting human-designed role
play, we propose a self-prompted approach, where agents comprehend robot URDF
files and call robot kinematics tools to generate descriptions of their physics
capabilities to guide their behavior in task planning and action execution. The
Habitat-MAS benchmark is designed to assess how a multi-agent framework handles
tasks that require embodiment-aware reasoning, which includes 1) manipulation,
2) perception, 3) navigation, and 4) comprehensive multi-floor object
rearrangement. The experimental results indicate that the robot's resume and
the hierarchical design of our multi-agent system are essential for the
effective operation of the heterogeneous multi-robot system within this
intricate problem context.

摘要：異質多機器人系統 (HMRS) 已成為一種強而有力的方法，用於解決單一機器人無法單獨管理的複雜任務。目前基於大型語言模型的多代理系統 (LLM-based MAS) 已在軟體開發和作業系統等領域展現成功，但將這些系統應用於機器人控制會產生獨特的挑戰。特別是，多機器人系統中每個代理的能力本質上與機器人的物理組成有關，而不是預定義的角色。為了解決這個問題，我們引入了一個新穎的多代理框架，旨在讓具有不同具體形式和能力的異質機器人之間能夠有效協作，並提供一個名為 Habitat-MAS 的新基準。我們的關鍵設計之一是「機器人履歷」：我們提出了一種自我提示的方法，而不是採用人類設計的角色扮演，代理會理解機器人 URDF 檔案，並呼叫機器人運動學工具來產生其物理能力的描述，以指導其在任務規劃和動作執行中的行為。Habitat-MAS 基準旨在評估多代理框架如何處理需要具體形式感知推理的任務，其中包括 1) 操作、2) 感知、3) 導航，以及 4) 全面的多樓層物件重新排列。實驗結果表明，機器人的履歷和我們多代理系統的階層式設計對於異質多機器人系統在這個複雜的問題背景下有效運作至關重要。

##### **Linguistics Theory Meets LLM: Code-Switched Text Generation via Equivalence Constrained Large Language Models**
2410.22660v1 by Garry Kuwanto, Chaitanya Agarwal, Genta Indra Winata, Derry Tanti Wijaya

Code-switching, the phenomenon of alternating between two or more languages
in a single conversation, presents unique challenges for Natural Language
Processing (NLP). Most existing research focuses on either syntactic
constraints or neural generation, with few efforts to integrate linguistic
theory with large language models (LLMs) for generating natural code-switched
text. In this paper, we introduce EZSwitch, a novel framework that combines
Equivalence Constraint Theory (ECT) with LLMs to produce linguistically valid
and fluent code-switched text. We evaluate our method using both human
judgments and automatic metrics, demonstrating a significant improvement in the
quality of generated code-switching sentences compared to baseline LLMs. To
address the lack of suitable evaluation metrics, we conduct a comprehensive
correlation study of various automatic metrics against human scores, revealing
that current metrics often fail to capture the nuanced fluency of code-switched
text. Additionally, we create CSPref, a human preference dataset based on human
ratings and analyze model performance across ``hard`` and ``easy`` examples.
Our findings indicate that incorporating linguistic constraints into LLMs leads
to more robust and human-aligned generation, paving the way for scalable
code-switching text generation across diverse language pairs.

摘要：代碼轉換，在單一對話中交替使用兩種或多種語言的現象，對自然語言處理 (NLP) 構成獨特的挑戰。現有的大部分研究都專注於語法限制或神經生成，很少有研究將語言學理論與大型語言模型 (LLM) 整合起來，以生成自然的代碼轉換文本。在本文中，我們介紹 EZSwitch，一個將等價約束理論 (ECT) 與 LLM 結合起來的新框架，以產生在語言學上有效且流暢的代碼轉換文本。我們使用人類判斷和自動化指標來評估我們的模型，證明與基準 LLM 相比，生成的代碼轉換句子的品質有顯著的提升。為了解決缺乏合適評估指標的問題，我們對各種自動化指標與人類評分進行全面的相關性研究，發現當前的指標通常無法捕捉代碼轉換文本的細微流暢度。此外，我們建立了 CSPref，一個基於人類評分的偏好資料集，並分析模型在「困難」和「容易」範例的表現。我們的發現表明，將語言限制納入 LLM 會導致更強健且與人類一致的生成，為跨越不同語言對的可擴充代碼轉換文本生成鋪路。

##### **Incremental Learning of Retrievable Skills For Efficient Continual Task Adaptation**
2410.22658v1 by Daehee Lee, Minjong Yoo, Woo Kyung Kim, Wonje Choi, Honguk Woo

Continual Imitation Learning (CiL) involves extracting and accumulating task
knowledge from demonstrations across multiple stages and tasks to achieve a
multi-task policy. With recent advancements in foundation models, there has
been a growing interest in adapter-based CiL approaches, where adapters are
established parameter-efficiently for tasks newly demonstrated. While these
approaches isolate parameters for specific tasks and tend to mitigate
catastrophic forgetting, they limit knowledge sharing among different
demonstrations. We introduce IsCiL, an adapter-based CiL framework that
addresses this limitation of knowledge sharing by incrementally learning
shareable skills from different demonstrations, thus enabling sample-efficient
task adaptation using the skills particularly in non-stationary CiL
environments. In IsCiL, demonstrations are mapped into the state embedding
space, where proper skills can be retrieved upon input states through
prototype-based memory. These retrievable skills are incrementally learned on
their corresponding adapters. Our CiL experiments with complex tasks in
Franka-Kitchen and Meta-World demonstrate robust performance of IsCiL in both
task adaptation and sample-efficiency. We also show a simple extension of IsCiL
for task unlearning scenarios.

摘要：持續模仿學習 (CiL) 涉及從多個階段和任務的示範中提取和累積任務知識，以達成多任務策略。隨著基礎模型的最新進展，基於適配器的 CiL 方法引起了越來越大的興趣，其中適配器會針對新示範任務以參數有效率的方式建立。雖然這些方法會針對特定任務隔離參數，並傾向於減輕災難性遺忘，但它們會限制不同示範之間的知識共享。我們引入了基於適配器的 CiL 架構 IsCiL，它透過逐步學習不同示範的可共享技能來解決知識共享的這個限制，從而能夠使用技能（特別是在非平穩 CiL 環境中）進行樣本有效率的任務適應。在 IsCiL 中，示範會對應到狀態嵌入空間，其中可以透過基於原型的記憶在輸入狀態時擷取適當的技能。這些可擷取的技能會在它們相對應的適配器上逐步學習。我們在 Franka-Kitchen 和 Meta-World 中使用複雜任務進行的 CiL 實驗證明了 IsCiL 在任務適應和樣本效率方面都有穩健的效能。我們也展示了 IsCiL 在任務取消學習場景中的簡單延伸。

##### **Prove Your Point!: Bringing Proof-Enhancement Principles to Argumentative Essay Generation**
2410.22642v1 by Ruiyu Xiao, Lei Wu, Yuhang Gou, Weinan Zhang, Ting Liu

Argumentative essay generation (AEG) aims to generate complete texts on
specific controversial topics or debates. Although current AEG methods can
generate individual opinions, they often overlook the high-level connections
between these opinions. This often leads to the generated results being mired
in logical confusion, unable to proof their own arguments effectively. The
generated essay may present evidence that contradicts the claims or they may
fail to assemble the claims into logical flow. In this paper, we present a
unified two-stage framework: Proof-Enhancement and Self-Annotation (PESA) for
AEG with a focus on logical enhancement. Specifically, we first construct
pseudo-labels for logical information,claims and grounds, using a large
language model. We then propose a tree planning approach that introduces proof
principles and ensures logical consistency. Extensive experimental results show
that, benefiting from proof principle guidance, PESA generates argumentative
essays with better logical validity and persuasiveness than strong baseline
models.

摘要：論證文生成（AEG）旨在針對特定有爭議的主題或辯論產生完整的文本。儘管目前的 AEG 方法可以產生個別意見，但它們常常忽略這些意見之間的高層次關聯。這通常會導致生成的結果陷入邏輯混淆，無法有效地證明自己的論點。生成的論文可能會提出與主張相矛盾的證據，或者可能無法將主張組合成邏輯流程。在本文中，我們提出了一個統一的兩階段框架：論證增強和自我註解（PESA），重點在於邏輯增強。具體來說，我們首先使用大型語言模型為邏輯信息、主張和依據構造偽標籤。然後，我們提出了一種樹規劃方法，該方法引入了證明原則並確保邏輯一致性。廣泛的實驗結果表明，得益於證明原則的指導，PESA 生成的論證文比強大的基線模型具有更好的邏輯有效性和說服力。

##### **Efficient Feature Extraction and Classification Architecture for MRI-Based Brain Tumor Detection**
2410.22619v1 by Plabon Paul, Md. Nazmul Islam, Fazle Rafsani, Pegah Khorasani, Shovito Barua Soumma

Uncontrolled cell division in the brain is what gives rise to brain tumors.
If the tumor size increases by more than half, there is little hope for the
patient's recovery. This emphasizes the need of rapid and precise brain tumor
diagnosis. When it comes to analyzing, diagnosing, and planning therapy for
brain tumors, MRI imaging plays a crucial role. A brain tumor's development
history is crucial information for doctors to have. When it comes to
distinguishing between human soft tissues, MRI scans are superior. In order to
get reliable classification results from MRI scans quickly, deep learning is
one of the most practical methods. Early human illness diagnosis has been
demonstrated to be more accurate when deep learning methods are used. In the
case of diagnosing a brain tumor, when even a little misdiagnosis might have
serious consequences, accuracy is especially important. Disclosure of brain
tumors in medical images is still a difficult task. Brain MRIs are notoriously
imprecise in revealing the presence or absence of tumors. Using MRI scans of
the brain, a Convolutional Neural Network (CNN) was trained to identify the
presence of a tumor in this research. Results from the CNN model showed an
accuracy of 99.17%. The CNN model's characteristics were also retrieved. In
order to evaluate the CNN model's capability for processing images, we applied
the features via the following machine learning models: KNN, Logistic
regression, SVM, Random Forest, Naive Bayes, and Perception. CNN and machine
learning models were also evaluated using the standard metrics of Precision,
Recall, Specificity, and F1 score. The significance of the doctor's diagnosis
enhanced the accuracy of the CNN model's assistance in identifying the
existence of tumor and treating the patient.

摘要：腦部細胞分裂失控，就會產生腦瘤。
如果腫瘤大小增加超過一半，病患康復的希望很渺茫。這強調了快速且精準診斷腦瘤的必要性。
在分析、診斷和規劃腦瘤治療時，核磁共振造影扮演了至關重要的角色。腦瘤的發展史是醫生必備的重要資訊。
在區分人體軟組織時，核磁共振掃描的表現優異。為了從核磁共振掃描中快速取得可靠的分類結果，深度學習是最實用的方法之一。
研究顯示，使用深度學習方法可以更準確地診斷人類早期疾病。在診斷腦瘤時，即使是輕微的誤診都可能造成嚴重後果，因此準確性特別重要。
在醫學影像中揭露腦瘤仍然是一項艱難的任務。腦部核磁共振造影在揭露腫瘤的存在與否方面出了名的不精確。
本研究訓練了一個卷積神經網路 (CNN)，使用腦部核磁共振掃描來辨識腫瘤的存在。CNN 模型的結果顯示準確度為 99.17%。CNN 模型的特徵也已擷取。
為了評估 CNN 模型處理影像的能力，我們透過以下機器學習模型套用這些特徵：KNN、邏輯迴歸、SVM、隨機森林、樸素貝氏和感知器。CNN 和機器學習模型也使用精準度、召回率、特異性和 F1 分數等標準指標進行評估。
醫生的診斷意義提升了 CNN 模型在協助辨識腫瘤存在和治療病患方面的準確性。

##### **CoGS: Model Agnostic Causality Constrained Counterfactual Explanations using goal-directed ASP**
2410.22615v1 by Sopam Dasgupta, Joaquín Arias, Elmer Salazar, Gopal Gupta

Machine learning models are increasingly used in critical areas such as loan
approvals and hiring, yet they often function as black boxes, obscuring their
decision-making processes. Transparency is crucial, as individuals need
explanations to understand decisions, primarily if the decisions result in an
undesired outcome. Our work introduces CoGS (Counterfactual Generation with
s(CASP)), a model-agnostic framework capable of generating counterfactual
explanations for classification models. CoGS leverages the goal-directed Answer
Set Programming system s(CASP) to compute realistic and causally consistent
modifications to feature values, accounting for causal dependencies between
them. By using rule-based machine learning algorithms (RBML), notably the
FOLD-SE algorithm, CoGS extracts the underlying logic of a statistical model to
generate counterfactual solutions. By tracing a step-by-step path from an
undesired outcome to a desired one, CoGS offers interpretable and actionable
explanations of the changes required to achieve the desired outcome. We present
details of the CoGS framework along with its evaluation.

摘要：機器學習模型在貸款核准和聘用等關鍵領域中日益廣泛地使用，然而它們通常作為黑盒子運作，模糊了其決策制定過程。透明度至關重要，因為個人需要解釋才能理解決策，特別是如果決策導致了不受歡迎的結果。我們的研究引入了 CoGS（反事實生成與 s(CASP)），一個與模型無關的框架，能夠為分類模型生成反事實解釋。CoGS 利用目標導向的 Answer Set Programming 系統 s(CASP) 來計算現實且因果一致的變更，以說明其特徵值，並考慮它們之間的因果關係。透過使用基於規則的機器學習演算法（RBML），尤其是 FOLD-SE 演算法，CoGS 從統計模型中萃取出底層邏輯，以產生反事實解。CoGS 從不受歡迎的結果追蹤到理想的結果，提供了可解釋且可行的解釋，說明了達成理想結果所需的變更。我們提供了 CoGS 框架的詳細資訊，以及其評估。

##### **Are Large-Language Models Graph Algorithmic Reasoners?**
2410.22597v1 by Alexander K Taylor, Anthony Cuturrufo, Vishal Yathish, Mingyu Derek Ma, Wei Wang

We seek to address a core challenge facing current Large Language Models
(LLMs). LLMs have demonstrated superior performance in many tasks, yet continue
to struggle with reasoning problems on explicit graphs that require multiple
steps. To address this gap, we introduce a novel benchmark designed to evaluate
LLM performance on classical algorithmic reasoning tasks on explicit graphs.
Our benchmark encompasses five fundamental algorithms: Breadth-First Search
(BFS) and Depth-First Search (DFS) for connectivity, Dijkstra's algorithm and
Floyd-Warshall algorithm for all nodes shortest path, and Prim's Minimum
Spanning Tree (MST-Prim's) algorithm. Through extensive experimentation, we
assess the capabilities of state-of-the-art LLMs in executing these algorithms
step-by-step and systematically evaluate their performance at each stage. Our
findings highlight the persistent challenges LLMs face in this domain and
underscore the necessity for advanced prompting techniques and algorithmic
instruction to enhance their graph reasoning abilities. This work presents
MAGMA, the first comprehensive benchmark focused on LLMs completing classical
graph algorithms, and provides a critical step toward understanding and
improving their structured problem-solving skills.

摘要：我們試圖解決當前大型語言模型 (LLM) 面臨的核心挑戰。LLM 在許多任務中表現出優異的性能，但仍難以應對需要多個步驟的明確圖表中的推理問題。為了解決這個差距，我們引入了一個新的基準，用於評估 LLM 在明確圖表上的經典演算法推理任務上的性能。我們的基準包含五個基本演算法：廣度優先搜尋 (BFS) 和深度優先搜尋 (DFS) 以進行連通性、Dijkstra 演算法和 Floyd-Warshall 演算法以找出所有節點的最短路徑，以及 Prim 最小生成樹 (MST-Prim) 演算法。透過廣泛的實驗，我們評估了最先進的 LLM 在逐步執行這些演算法的能力，並系統性地評估它們在每個階段的性能。我們的研究結果突出了 LLM 在這個領域面臨的持續挑戰，並強調了使用進階提示技術和演算法指令來增強其圖形推理能力的必要性。這項工作提出了 MAGMA，這是第一個專注於 LLM 完成經典圖形演算法的綜合基準，並為了解和改進其結構化問題解決技能提供了關鍵的一步。

