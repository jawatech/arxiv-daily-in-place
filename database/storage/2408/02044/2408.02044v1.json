{"2408.02044": {"publish_time": "2024-08-04", "title": "Fine-tuning multilingual language models in Twitter/X sentiment analysis: a study on Eastern-European V4 languages", "paper_summary": "The aspect-based sentiment analysis (ABSA) is a standard NLP task with\nnumerous approaches and benchmarks, where large language models (LLM) represent\nthe current state-of-the-art. We focus on ABSA subtasks based on Twitter/X data\nin underrepresented languages. On such narrow tasks, small tuned language\nmodels can often outperform universal large ones, providing available and cheap\nsolutions.\n  We fine-tune several LLMs (BERT, BERTweet, Llama2, Llama3, Mistral) for\nclassification of sentiment towards Russia and Ukraine in the context of the\nongoing military conflict. The training/testing dataset was obtained from the\nacademic API from Twitter/X during 2023, narrowed to the languages of the V4\ncountries (Czech Republic, Slovakia, Poland, Hungary). Then we measure their\nperformance under a variety of settings including translations, sentiment\ntargets, in-context learning and more, using GPT4 as a reference model. We\ndocument several interesting phenomena demonstrating, among others, that some\nmodels are much better fine-tunable on multilingual Twitter tasks than others,\nand that they can reach the SOTA level with a very small training set. Finally\nwe identify combinations of settings providing the best results.", "paper_summary_zh": "\u57fa\u65bc\u9762\u5411\u65b9\u9762\u7684\u89c0\u9ede\u5206\u6790 (ABSA) \u662f\u4e00\u9805\u6a19\u6e96\u7684 NLP \u4efb\u52d9\uff0c\u6709\n\u8a31\u591a\u65b9\u6cd5\u548c\u57fa\u6e96\uff0c\u5176\u4e2d\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u4ee3\u8868\u4e86\u7576\u524d\u6280\u8853\u6c34\u6e96\u3002\u6211\u5011\u5c08\u6ce8\u65bc\u57fa\u65bc Twitter/X \u8cc7\u6599\u7684 ABSA \u5b50\u4efb\u52d9\uff0c\u4f7f\u7528\u4ee3\u8868\u6027\u4e0d\u8db3\u7684\u8a9e\u8a00\u3002\u5728\u9019\u4e9b\u72f9\u7a84\u7684\u4efb\u52d9\u4e2d\uff0c\u7d93\u904e\u5fae\u8abf\u7684\u5c0f\u8a9e\u8a00\u6a21\u578b\u901a\u5e38\u53ef\u4ee5\u512a\u65bc\u901a\u7528\u7684\u5927\u578b\u8a9e\u8a00\u6a21\u578b\uff0c\u63d0\u4f9b\u53ef\u7528\u4e14\u4fbf\u5b9c\u7684\u89e3\u6c7a\u65b9\u6848\u3002\n\u6211\u5011\u5fae\u8abf\u4e86\u591a\u500b LLM\uff08BERT\u3001BERTweet\u3001Llama2\u3001Llama3\u3001Mistral\uff09\uff0c\u4ee5\u4fbf\u5728\u6301\u7e8c\u7684\u8ecd\u4e8b\u885d\u7a81\u80cc\u666f\u4e0b\u5c0d\u4fc4\u7f85\u65af\u548c\u70cf\u514b\u862d\u7684\u60c5\u611f\u9032\u884c\u5206\u985e\u3002\u8a13\u7df4/\u6e2c\u8a66\u8cc7\u6599\u96c6\u662f\u5f9e Twitter/X \u7684\u5b78\u8853 API \u5728 2023 \u5e74\u7372\u5f97\u7684\uff0c\u4e26\u7e2e\u5c0f\u5230 V4 \u570b\u5bb6\u7684\u8a9e\u8a00\uff08\u6377\u514b\u5171\u548c\u570b\u3001\u65af\u6d1b\u4f10\u514b\u3001\u6ce2\u862d\u3001\u5308\u7259\u5229\uff09\u3002\u7136\u5f8c\uff0c\u6211\u5011\u4f7f\u7528 GPT4 \u4f5c\u70ba\u53c3\u8003\u6a21\u578b\uff0c\u5728\u5404\u7a2e\u8a2d\u5b9a\uff08\u5305\u62ec\u7ffb\u8b6f\u3001\u60c5\u611f\u76ee\u6a19\u3001\u60c5\u5883\u5b78\u7fd2\u7b49\uff09\u4e0b\u8861\u91cf\u5b83\u5011\u7684\u6548\u80fd\u3002\u6211\u5011\u8a18\u9304\u4e86\u5e7e\u500b\u6709\u8da3\u7684\u73fe\u8c61\uff0c\u5176\u4e2d\u5305\u62ec\u4e00\u4e9b\u6a21\u578b\u6bd4\u5176\u4ed6\u6a21\u578b\u66f4\u9069\u5408\u5728\u591a\u8a9e\u8a00\u7684 Twitter \u4efb\u52d9\u4e0a\u9032\u884c\u5fae\u8abf\uff0c\u800c\u4e14\u5b83\u5011\u53ef\u4ee5\u4f7f\u7528\u975e\u5e38\u5c0f\u7684\u8a13\u7df4\u96c6\u9054\u5230 SOTA \u6c34\u6e96\u3002\u6700\u5f8c\uff0c\u6211\u5011\u627e\u51fa\u63d0\u4f9b\u6700\u4f73\u7d50\u679c\u7684\u8a2d\u5b9a\u7d44\u5408\u3002", "author": "Tom\u00e1\u0161 Filip et.al.", "authors": "Tom\u00e1\u0161 Filip, Martin Pavl\u00ed\u010dek, Petr Sos\u00edk", "id": "2408.02044v1", "paper_url": "http://arxiv.org/abs/2408.02044v1", "repo": "null"}}