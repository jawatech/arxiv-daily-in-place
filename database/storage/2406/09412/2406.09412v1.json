{"2406.09412": {"publish_time": "2024-06-13", "title": "Explore the Limits of Omni-modal Pretraining at Scale", "paper_summary": "We propose to build omni-modal intelligence, which is capable of\nunderstanding any modality and learning universal representations. In specific,\nwe propose a scalable pretraining paradigm, named Multimodal Context (MiCo),\nwhich can scale up the numbers of modalities and amount of data, together with\nthe model parameters, in the pretraining process. With MiCo, the pretrained\nmodels show significant emergent abilities in multimodal learning, which are\nevaluated on the following tasks: i) single-modality perception benchmarks of\n10 different modalities, ii) 25 cross-modality understanding tasks of\nretrieval, question-answering, captioning, and iii) 18 multimodal large\nlanguage model benchmarks. Our models establish 37 new records for\nstate-of-the-art performance. We hope that our research could contribute to the\ndevelopment of omni-modal intelligence. Code and Models are at\nhttps://github.com/invictus717/MiCo", "paper_summary_zh": "<paragraph>\u6211\u5011\u63d0\u8b70\u5efa\u7acb\u5168\u6a21\u614b\u667a\u80fd\uff0c\u5b83\u80fd\u5920\u7406\u89e3\u4efb\u4f55\u6a21\u614b\u4e26\u5b78\u7fd2\u901a\u7528\u8868\u793a\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u53ef\u64f4\u5c55\u7684\u9810\u8a13\u7df4\u7bc4\u4f8b\uff0c\u540d\u70ba\u591a\u6a21\u614b\u4e0a\u4e0b\u6587 (MiCo)\uff0c\u5b83\u53ef\u4ee5\u5728\u9810\u8a13\u7df4\u904e\u7a0b\u4e2d\u64f4\u5c55\u6a21\u614b\u6578\u91cf\u548c\u6578\u64da\u91cf\uff0c\u4ee5\u53ca\u6a21\u578b\u53c3\u6578\u3002\u4f7f\u7528 MiCo\uff0c\u9810\u8a13\u7df4\u6a21\u578b\u5728\u591a\u6a21\u614b\u5b78\u7fd2\u4e2d\u5c55\u73fe\u51fa\u986f\u8457\u7684\u65b0\u8208\u80fd\u529b\uff0c\u9019\u4e9b\u80fd\u529b\u5728\u4ee5\u4e0b\u4efb\u52d9\u4e2d\u5f97\u5230\u8a55\u4f30\uff1ai) 10 \u7a2e\u4e0d\u540c\u6a21\u614b\u7684\u55ae\u6a21\u614b\u611f\u77e5\u57fa\u6e96\uff0cii) 25 \u500b\u8de8\u6a21\u614b\u7406\u89e3\u4efb\u52d9\uff0c\u5305\u62ec\u6aa2\u7d22\u3001\u554f\u7b54\u3001\u5b57\u5e55\uff0c\u4ee5\u53ca iii) 18 \u500b\u591a\u6a21\u614b\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u57fa\u6e96\u3002\u6211\u5011\u7684\u6a21\u578b\u70ba\u6700\u5148\u9032\u7684\u6027\u80fd\u5efa\u7acb\u4e86 37 \u9805\u65b0\u7d00\u9304\u3002\u6211\u5011\u5e0c\u671b\u6211\u5011\u7684\u7814\u7a76\u80fd\u70ba\u5168\u6a21\u614b\u667a\u80fd\u7684\u767c\u5c55\u505a\u51fa\u8ca2\u737b\u3002\u7a0b\u5f0f\u78bc\u548c\u6a21\u578b\u53ef\u5728 https://github.com/invictus717/MiCo \u627e\u5230</paragraph>", "author": "Yiyuan Zhang et.al.", "authors": "Yiyuan Zhang, Handong Li, Jing Liu, Xiangyu Yue", "id": "2406.09412v1", "paper_url": "http://arxiv.org/abs/2406.09412v1", "repo": "https://github.com/invictus717/MiCo"}}