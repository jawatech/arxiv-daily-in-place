{"2408.06752": {"publish_time": "2024-08-13", "title": "Evaluating Research Quality with Large Language Models: An Analysis of ChatGPT's Effectiveness with Different Settings and Inputs", "paper_summary": "Evaluating the quality of academic journal articles is a time consuming but\ncritical task for national research evaluation exercises, appointments and\npromotion. It is therefore important to investigate whether Large Language\nModels (LLMs) can play a role in this process. This article assesses which\nChatGPT inputs (full text without tables, figures and references; title and\nabstract; title only) produce better quality score estimates, and the extent to\nwhich scores are affected by ChatGPT models and system prompts. The results\nshow that the optimal input is the article title and abstract, with average\nChatGPT scores based on these (30 iterations on a dataset of 51 papers)\ncorrelating at 0.67 with human scores, the highest ever reported. ChatGPT 4o is\nslightly better than 3.5-turbo (0.66), and 4o-mini (0.66). The results suggest\nthat article full texts might confuse LLM research quality evaluations, even\nthough complex system instructions for the task are more effective than simple\nones. Thus, whilst abstracts contain insufficient information for a thorough\nassessment of rigour, they may contain strong pointers about originality and\nsignificance. Finally, linear regression can be used to convert the model\nscores into the human scale scores, which is 31% more accurate than guessing.", "paper_summary_zh": "\u8a55\u4f30\u5b78\u8853\u671f\u520a\u6587\u7ae0\u7684\u54c1\u8cea\u662f\u4e00\u9805\u8017\u6642\u4f46\u81f3\u95dc\u91cd\u8981\u7684\u4efb\u52d9\uff0c\u7528\u65bc\u570b\u5bb6\u7814\u7a76\u8a55\u9451\u3001\u4efb\u547d\u548c\u6649\u5347\u3002\u56e0\u6b64\uff0c\u63a2\u8a0e\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u662f\u5426\u80fd\u5728\u9019\u500b\u904e\u7a0b\u4e2d\u767c\u63ee\u4f5c\u7528\u975e\u5e38\u91cd\u8981\u3002\u672c\u6587\u8a55\u4f30\u4e86\u54ea\u4e9b ChatGPT \u8f38\u5165\uff08\u6c92\u6709\u8868\u683c\u3001\u5716\u8868\u548c\u53c3\u8003\u6587\u737b\u7684\u5168\u6587\uff1b\u6a19\u984c\u548c\u6458\u8981\uff1b\u50c5\u6a19\u984c\uff09\u80fd\u7522\u751f\u54c1\u8cea\u66f4\u597d\u7684\u8a55\u5206\u4f30\u8a08\uff0c\u4ee5\u53ca ChatGPT \u6a21\u578b\u548c\u7cfb\u7d71\u63d0\u793a\u5f71\u97ff\u8a55\u5206\u7684\u7a0b\u5ea6\u3002\u7d50\u679c\u986f\u793a\uff0c\u6700\u4f73\u8f38\u5165\u662f\u6587\u7ae0\u6a19\u984c\u548c\u6458\u8981\uff0c\u6839\u64da\u9019\u4e9b\u8f38\u5165\u7684\u5e73\u5747 ChatGPT \u8a55\u5206\uff08\u5c0d 51 \u7bc7\u8ad6\u6587\u7684\u8cc7\u6599\u96c6\u9032\u884c 30 \u6b21\u53cd\u8986\u904b\u7b97\uff09\u8207\u4eba\u5de5\u8a55\u5206\u76f8\u95dc\u6027\u70ba 0.67\uff0c\u662f\u6b77\u4f86\u5831\u544a\u904e\u7684\u6700\u9ad8\u5206\u3002ChatGPT 4o \u7565\u512a\u65bc 3.5-turbo\uff080.66\uff09\u548c 4o-mini\uff080.66\uff09\u3002\u7d50\u679c\u986f\u793a\uff0c\u5118\u7ba1\u91dd\u5c0d\u6b64\u4efb\u52d9\u7684\u8907\u96dc\u7cfb\u7d71\u6307\u4ee4\u6bd4\u7c21\u55ae\u6307\u4ee4\u66f4\u6709\u6548\uff0c\u4f46\u6587\u7ae0\u5168\u6587\u53ef\u80fd\u6703\u6df7\u6dc6 LLM \u7814\u7a76\u54c1\u8cea\u8a55\u4f30\u3002\u56e0\u6b64\uff0c\u5118\u7ba1\u6458\u8981\u5305\u542b\u7684\u8cc7\u8a0a\u4e0d\u8db3\u4ee5\u9032\u884c\u5fb9\u5e95\u7684\u56b4\u8b39\u6027\u8a55\u4f30\uff0c\u4f46\u5b83\u5011\u53ef\u80fd\u5305\u542b\u95dc\u65bc\u539f\u5275\u6027\u548c\u91cd\u8981\u6027\u7684\u6709\u529b\u6307\u6a19\u3002\u6700\u5f8c\uff0c\u7dda\u6027\u8ff4\u6b78\u53ef\u88ab\u7528\u65bc\u5c07\u6a21\u578b\u8a55\u5206\u8f49\u63db\u70ba\u4eba\u5de5\u8a55\u5206\uff0c\u5176\u6e96\u78ba\u5ea6\u6bd4\u731c\u6e2c\u9ad8\u51fa 31%\u3002", "author": "Mike Thelwall et.al.", "authors": "Mike Thelwall", "id": "2408.06752v1", "paper_url": "http://arxiv.org/abs/2408.06752v1", "repo": "null"}}