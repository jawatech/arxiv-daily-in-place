{"2410.10812": {"publish_time": "2024-10-14", "title": "HART: Efficient Visual Generation with Hybrid Autoregressive Transformer", "paper_summary": "We introduce Hybrid Autoregressive Transformer (HART), an autoregressive (AR)\nvisual generation model capable of directly generating 1024x1024 images,\nrivaling diffusion models in image generation quality. Existing AR models face\nlimitations due to the poor image reconstruction quality of their discrete\ntokenizers and the prohibitive training costs associated with generating 1024px\nimages. To address these challenges, we present the hybrid tokenizer, which\ndecomposes the continuous latents from the autoencoder into two components:\ndiscrete tokens representing the big picture and continuous tokens representing\nthe residual components that cannot be represented by the discrete tokens. The\ndiscrete component is modeled by a scalable-resolution discrete AR model, while\nthe continuous component is learned with a lightweight residual diffusion\nmodule with only 37M parameters. Compared with the discrete-only VAR tokenizer,\nour hybrid approach improves reconstruction FID from 2.11 to 0.30 on MJHQ-30K,\nleading to a 31% generation FID improvement from 7.85 to 5.38. HART also\noutperforms state-of-the-art diffusion models in both FID and CLIP score, with\n4.5-7.7x higher throughput and 6.9-13.4x lower MACs. Our code is open sourced\nat https://github.com/mit-han-lab/hart.", "paper_summary_zh": "<paragraph>\u6211\u5011\u4ecb\u7d39\u4e86\u6df7\u5408\u81ea\u8ff4\u6b78Transformer (HART)\uff0c\u9019\u662f\u4e00\u500b\u81ea\u8ff4\u6b78 (AR) \u8996\u89ba\u751f\u6210\u6a21\u578b\uff0c\u80fd\u5920\u76f4\u63a5\u751f\u6210 1024x1024 \u5f71\u50cf\uff0c\u5728\u5f71\u50cf\u751f\u6210\u54c1\u8cea\u4e0a\u8207\u64f4\u6563\u6a21\u578b\u5339\u6575\u3002\u73fe\u6709\u7684 AR \u6a21\u578b\u7531\u65bc\u5176\u96e2\u6563\u7b26\u865f\u5316\u5668\u7684\u5f71\u50cf\u91cd\u5efa\u54c1\u8cea\u4e0d\u4f73\uff0c\u4ee5\u53ca\u751f\u6210 1024px \u5f71\u50cf\u6642\u76f8\u95dc\u7684\u8a13\u7df4\u6210\u672c\u904e\u9ad8\uff0c\u56e0\u6b64\u9762\u81e8\u9650\u5236\u3002\u70ba\u4e86\u61c9\u5c0d\u9019\u4e9b\u6311\u6230\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u6df7\u5408\u7b26\u865f\u5316\u5668\uff0c\u5b83\u5c07\u4f86\u81ea\u81ea\u52d5\u7de8\u78bc\u5668\u7684\u9023\u7e8c\u6f5b\u5728\u8b8a\u6578\u5206\u89e3\u6210\u5169\u500b\u7d44\u6210\u90e8\u5206\uff1a\u4ee3\u8868\u5927\u5c40\u7684\u96e2\u6563\u7b26\u865f\uff0c\u4ee5\u53ca\u4ee3\u8868\u7121\u6cd5\u7531\u96e2\u6563\u7b26\u865f\u8868\u793a\u7684\u6b98\u5dee\u7d44\u6210\u7684\u9023\u7e8c\u7b26\u865f\u3002\u96e2\u6563\u7d44\u6210\u90e8\u5206\u7531\u53ef\u8abf\u6574\u89e3\u6790\u5ea6\u7684\u96e2\u6563 AR \u6a21\u578b\u5efa\u6a21\uff0c\u800c\u9023\u7e8c\u7d44\u6210\u90e8\u5206\u5247\u4f7f\u7528\u50c5\u6709 37M \u53c3\u6578\u7684\u8f15\u91cf\u7d1a\u6b98\u5dee\u64f4\u6563\u6a21\u7d44\u9032\u884c\u5b78\u7fd2\u3002\u8207\u50c5\u6709\u96e2\u6563\u7684 VAR \u7b26\u865f\u5316\u5668\u76f8\u6bd4\uff0c\u6211\u5011\u7684\u6df7\u5408\u65b9\u6cd5\u5c07 MJHQ-30K \u4e0a\u7684\u91cd\u5efa FID \u5f9e 2.11 \u6539\u5584\u5230 0.30\uff0c\u5c0e\u81f4\u751f\u6210 FID \u5f9e 7.85 \u6539\u5584\u5230 5.38\uff0c\u63d0\u5347\u4e86 31%\u3002HART \u5728 FID \u548c CLIP \u5206\u6578\u4e0a\u4e5f\u512a\u65bc\u6700\u5148\u9032\u7684\u64f4\u6563\u6a21\u578b\uff0c\u4e14\u8655\u7406\u91cf\u9ad8\u51fa 4.5-7.7 \u500d\uff0cMACs \u4f4e 6.9-13.4 \u500d\u3002\u6211\u5011\u7684\u7a0b\u5f0f\u78bc\u5df2\u5728 https://github.com/mit-han-lab/hart \u958b\u6e90\u3002</paragraph>", "author": "Haotian Tang et.al.", "authors": "Haotian Tang, Yecheng Wu, Shang Yang, Enze Xie, Junsong Chen, Junyu Chen, Zhuoyang Zhang, Han Cai, Yao Lu, Song Han", "id": "2410.10812v1", "paper_url": "http://arxiv.org/abs/2410.10812v1", "repo": "https://github.com/mit-han-lab/hart"}}