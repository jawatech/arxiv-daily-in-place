{"2411.08147": {"publish_time": "2024-11-12", "title": "Large Language Models Can Self-Improve in Long-context Reasoning", "paper_summary": "Large language models (LLMs) have achieved substantial progress in processing\nlong contexts but still struggle with long-context reasoning. Existing\napproaches typically involve fine-tuning LLMs with synthetic data, which\ndepends on annotations from human experts or advanced models like GPT-4, thus\nrestricting further advancements. To address this issue, we investigate the\npotential for LLMs to self-improve in long-context reasoning and propose \\ours,\nan approach specifically designed for this purpose. This approach is\nstraightforward: we sample multiple outputs for each question, score them with\nMinimum Bayes Risk, and then apply supervised fine-tuning or preference\noptimization based on these outputs. Extensive experiments on several leading\nLLMs demonstrate the effectiveness of \\ours, with an absolute improvement of\n$4.2$ points for Llama-3.1-8B-Instruct. Furthermore, \\ours achieves superior\nperformance compared to prior approaches that depend on data produced by human\nexperts or advanced models. We anticipate that this work will open new avenues\nfor self-improvement techniques in long-context scenarios, which are essential\nfor the continual advancement of LLMs.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5728\u8655\u7406\u9577\u8a9e\u5883\u65b9\u9762\u53d6\u5f97\u4e86\u986f\u8457\u9032\u5c55\uff0c\u4f46\u4ecd\u96e3\u4ee5\u61c9\u5c0d\u9577\u8a9e\u5883\u63a8\u7406\u3002\u73fe\u6709\u65b9\u6cd5\u901a\u5e38\u6d89\u53ca\u4f7f\u7528\u5408\u6210\u8cc7\u6599\u5fae\u8abf LLM\uff0c\u9019\u4f9d\u8cf4\u65bc\u4eba\u985e\u5c08\u5bb6\u7684\u8a3b\u89e3\u6216 GPT-4 \u7b49\u9032\u968e\u6a21\u578b\uff0c\u56e0\u6b64\u9650\u5236\u4e86\u9032\u4e00\u6b65\u7684\u9032\u5c55\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u6211\u5011\u63a2\u8a0e\u4e86 LLM \u5728\u9577\u8a9e\u5883\u63a8\u7406\u4e2d\u81ea\u6211\u63d0\u5347\u7684\u6f5b\u529b\uff0c\u4e26\u63d0\u51fa \\ours\uff0c\u4e00\u7a2e\u5c08\u9580\u70ba\u6b64\u76ee\u7684\u8a2d\u8a08\u7684\u65b9\u6cd5\u3002\u9019\u7a2e\u65b9\u6cd5\u5f88\u7c21\u55ae\uff1a\u6211\u5011\u70ba\u6bcf\u500b\u554f\u984c\u62bd\u53d6\u591a\u500b\u8f38\u51fa\uff0c\u4f7f\u7528\u6700\u5c0f\u8c9d\u8449\u65af\u98a8\u96aa\u5c0d\u5b83\u5011\u9032\u884c\u8a55\u5206\uff0c\u7136\u5f8c\u6839\u64da\u9019\u4e9b\u8f38\u51fa\u61c9\u7528\u76e3\u7763\u5fae\u8abf\u6216\u504f\u597d\u6700\u4f73\u5316\u3002\u5c0d\u5e7e\u500b\u9818\u5148\u7684 LLM \u9032\u884c\u7684\u5ee3\u6cdb\u5be6\u9a57\u8b49\u660e\u4e86 \\ours \u7684\u6709\u6548\u6027\uff0cLlama-3.1-8B-Instruct \u7684\u7d55\u5c0d\u6539\u9032\u70ba 4.2 \u5206\u3002\u6b64\u5916\uff0c\\ours \u8207\u4f9d\u8cf4\u4eba\u985e\u5c08\u5bb6\u6216\u9032\u968e\u6a21\u578b\u7522\u751f\u7684\u8cc7\u6599\u7684\u5148\u524d\u65b9\u6cd5\u76f8\u6bd4\uff0c\u53d6\u5f97\u4e86\u66f4\u597d\u7684\u6548\u80fd\u3002\u6211\u5011\u9810\u671f\u9019\u9805\u5de5\u4f5c\u5c07\u70ba\u9577\u8a9e\u5883\u5834\u666f\u4e2d\u7684\u81ea\u6211\u63d0\u5347\u6280\u8853\u958b\u555f\u65b0\u9014\u5f91\uff0c\u9019\u5c0d\u65bc LLM \u7684\u6301\u7e8c\u9032\u6b65\u81f3\u95dc\u91cd\u8981\u3002", "author": "Siheng Li et.al.", "authors": "Siheng Li, Cheng Yang, Zesen Cheng, Lemao Liu, Mo Yu, Yujiu Yang, Wai Lam", "id": "2411.08147v1", "paper_url": "http://arxiv.org/abs/2411.08147v1", "repo": "https://github.com/sihengli99/sealong"}}