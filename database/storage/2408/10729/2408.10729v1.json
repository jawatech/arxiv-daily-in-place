{"2408.10729": {"publish_time": "2024-08-20", "title": "Towards Efficient Large Language Models for Scientific Text: A Review", "paper_summary": "Large language models (LLMs) have ushered in a new era for processing complex\ninformation in various fields, including science. The increasing amount of\nscientific literature allows these models to acquire and understand scientific\nknowledge effectively, thus improving their performance in a wide range of\ntasks. Due to the power of LLMs, they require extremely expensive computational\nresources, intense amounts of data, and training time. Therefore, in recent\nyears, researchers have proposed various methodologies to make scientific LLMs\nmore affordable. The most well-known approaches align in two directions. It can\nbe either focusing on the size of the models or enhancing the quality of data.\nTo date, a comprehensive review of these two families of methods has not yet\nbeen undertaken. In this paper, we (I) summarize the current advances in the\nemerging abilities of LLMs into more accessible AI solutions for science, and\n(II) investigate the challenges and opportunities of developing affordable\nsolutions for scientific domains using LLMs.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u958b\u555f\u4e86\u8655\u7406\u5404\u500b\u9818\u57df\u8907\u96dc\u8cc7\u8a0a\u7684\u65b0\u7d00\u5143\uff0c\u5305\u62ec\u79d1\u5b78\u3002\u79d1\u5b78\u6587\u737b\u6578\u91cf\u4e0d\u65b7\u589e\u52a0\uff0c\u8b93\u9019\u4e9b\u6a21\u578b\u80fd\u5920\u6709\u6548\u5730\u7372\u53d6\u548c\u7406\u89e3\u79d1\u5b78\u77e5\u8b58\uff0c\u5f9e\u800c\u63d0\u5347\u5b83\u5011\u5728\u5404\u7a2e\u4efb\u52d9\u4e2d\u7684\u8868\u73fe\u3002\u7531\u65bc LLM \u7684\u5f37\u5927\u529f\u80fd\uff0c\u5b83\u5011\u9700\u8981\u6975\u5176\u6602\u8cb4\u7684\u904b\u7b97\u8cc7\u6e90\u3001\u5927\u91cf\u8cc7\u6599\u548c\u8a13\u7df4\u6642\u9593\u3002\u56e0\u6b64\uff0c\u8fd1\u5e74\u4f86\uff0c\u7814\u7a76\u4eba\u54e1\u63d0\u51fa\u4e86\u5404\u7a2e\u65b9\u6cd5\uff0c\u8b93\u79d1\u5b78 LLM \u8b8a\u5f97\u66f4\u5e73\u50f9\u3002\u6700\u8457\u540d\u7684\u505a\u6cd5\u6709\u5169\u7a2e\u3002\u5b83\u5011\u53ef\u4ee5\u5c08\u6ce8\u65bc\u6a21\u578b\u5927\u5c0f\uff0c\u6216\u63d0\u5347\u8cc7\u6599\u54c1\u8cea\u3002\u5230\u76ee\u524d\u70ba\u6b62\uff0c\u5c0d\u65bc\u9019\u5169\u7a2e\u985e\u5225\u7684\u65b9\u6cd5\uff0c\u5c1a\u672a\u9032\u884c\u5168\u9762\u7684\u56de\u9867\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011 (I) \u7e3d\u7d50 LLM \u65b0\u8208\u80fd\u529b\u5728\u79d1\u5b78\u9818\u57df\u4e2d\u8f49\u8b8a\u70ba\u66f4\u5e73\u6613\u8fd1\u4eba\u7684 AI \u89e3\u6c7a\u65b9\u6848\u7684\u6700\u65b0\u9032\u5c55\uff0c\u4ee5\u53ca (II) \u63a2\u8a0e\u4f7f\u7528 LLM \u70ba\u79d1\u5b78\u9818\u57df\u958b\u767c\u5e73\u50f9\u89e3\u6c7a\u65b9\u6848\u7684\u6311\u6230\u548c\u6a5f\u6703\u3002", "author": "Huy Quoc To et.al.", "authors": "Huy Quoc To, Ming Liu, Guangyan Huang", "id": "2408.10729v1", "paper_url": "http://arxiv.org/abs/2408.10729v1", "repo": "null"}}