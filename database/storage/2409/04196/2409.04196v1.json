{"2409.04196": {"publish_time": "2024-09-06", "title": "GST: Precise 3D Human Body from a Single Image with Gaussian Splatting Transformers", "paper_summary": "Reconstructing realistic 3D human models from monocular images has\nsignificant applications in creative industries, human-computer interfaces, and\nhealthcare. We base our work on 3D Gaussian Splatting (3DGS), a scene\nrepresentation composed of a mixture of Gaussians. Predicting such mixtures for\na human from a single input image is challenging, as it is a non-uniform\ndensity (with a many-to-one relationship with input pixels) with strict\nphysical constraints. At the same time, it needs to be flexible to accommodate\na variety of clothes and poses. Our key observation is that the vertices of\nstandardized human meshes (such as SMPL) can provide an adequate density and\napproximate initial position for Gaussians. We can then train a transformer\nmodel to jointly predict comparatively small adjustments to these positions, as\nwell as the other Gaussians' attributes and the SMPL parameters. We show\nempirically that this combination (using only multi-view supervision) can\nachieve fast inference of 3D human models from a single image without test-time\noptimization, expensive diffusion models, or 3D points supervision. We also\nshow that it can improve 3D pose estimation by better fitting human models that\naccount for clothes and other variations. The code is available on the project\nwebsite https://abdullahamdi.com/gst/ .", "paper_summary_zh": "\u5f9e\u55ae\u773c\u5f71\u50cf\u91cd\u5efa\u903c\u771f\u7684 3D \u4eba\u9ad4\u6a21\u578b\u5728\u5275\u610f\u7522\u696d\u3001\u4eba\u6a5f\u4ecb\u9762\u548c\u91ab\u7642\u4fdd\u5065\u9818\u57df\u6709\u91cd\u8981\u7684\u61c9\u7528\u3002\u6211\u5011\u7684\u7814\u7a76\u57fa\u65bc 3D \u9ad8\u65af\u9ede\u7e6a\u88fd (3DGS)\uff0c\u9019\u662f\u4e00\u7a2e\u7531\u9ad8\u65af\u6df7\u5408\u7d44\u6210\u7684\u5834\u666f\u8868\u793a\u3002\u5f9e\u55ae\u4e00\u8f38\u5165\u5f71\u50cf\u9810\u6e2c\u4eba\u985e\u7684\u9019\u7a2e\u6df7\u5408\u7269\u5177\u6709\u6311\u6230\u6027\uff0c\u56e0\u70ba\u5b83\u662f\u4e00\u7a2e\u975e\u5747\u52fb\u5bc6\u5ea6\uff08\u8207\u8f38\u5165\u50cf\u7d20\u5448\u591a\u5c0d\u4e00\u95dc\u4fc2\uff09\uff0c\u4e14\u5177\u6709\u56b4\u683c\u7684\u7269\u7406\u7d04\u675f\u3002\u540c\u6642\uff0c\u5b83\u9700\u8981\u9748\u6d3b\u5730\u9069\u61c9\u5404\u7a2e\u670d\u88dd\u548c\u59ff\u52e2\u3002\u6211\u5011\u7684\u95dc\u9375\u89c0\u5bdf\u662f\u6a19\u6e96\u5316\u4eba\u9ad4\u7db2\u683c\uff08\u4f8b\u5982 SMPL\uff09\u7684\u9802\u9ede\u53ef\u4ee5\u63d0\u4f9b\u9069\u7576\u7684\u5bc6\u5ea6\u548c\u9ad8\u65af\u8fd1\u4f3c\u521d\u59cb\u4f4d\u7f6e\u3002\u7136\u5f8c\uff0c\u6211\u5011\u53ef\u4ee5\u8a13\u7df4\u4e00\u500bTransformer\u6a21\u578b\u4f86\u806f\u5408\u9810\u6e2c\u9019\u4e9b\u4f4d\u7f6e\u7684\u76f8\u5c0d\u8f03\u5c0f\u8abf\u6574\uff0c\u4ee5\u53ca\u5176\u4ed6\u9ad8\u65af\u7684\u5c6c\u6027\u548c SMPL \u53c3\u6578\u3002\u6211\u5011\u4ee5\u5be6\u8b49\u65b9\u5f0f\u8868\u660e\uff0c\u9019\u7a2e\u7d44\u5408\uff08\u50c5\u4f7f\u7528\u591a\u8996\u5716\u76e3\u7763\uff09\u53ef\u4ee5\u5728\u6c92\u6709\u6e2c\u8a66\u6642\u512a\u5316\u3001\u6602\u8cb4\u7684\u64f4\u6563\u6a21\u578b\u6216 3D \u9ede\u76e3\u7763\u7684\u60c5\u6cc1\u4e0b\uff0c\u5f9e\u55ae\u4e00\u5f71\u50cf\u5feb\u901f\u63a8\u8ad6 3D \u4eba\u9ad4\u6a21\u578b\u3002\u6211\u5011\u9084\u8868\u660e\uff0c\u5b83\u53ef\u4ee5\u901a\u904e\u66f4\u597d\u5730\u64ec\u5408\u8003\u91cf\u670d\u88dd\u548c\u5176\u4ed6\u8b8a\u5316\u7684 3D \u4eba\u9ad4\u6a21\u578b\u4f86\u6539\u5584 3D \u59ff\u52e2\u4f30\u8a08\u3002\u7a0b\u5f0f\u78bc\u53ef\u5728\u5c08\u6848\u7db2\u7ad9 https://abdullahamdi.com/gst/ \u53d6\u5f97\u3002", "author": "Lorenza Prospero et.al.", "authors": "Lorenza Prospero, Abdullah Hamdi, Joao F. Henriques, Christian Rupprecht", "id": "2409.04196v1", "paper_url": "http://arxiv.org/abs/2409.04196v1", "repo": "null"}}