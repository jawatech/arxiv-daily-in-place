{"2408.01866": {"publish_time": "2024-08-03", "title": "Efficient Solutions For An Intriguing Failure of LLMs: Long Context Window Does Not Mean LLMs Can Analyze Long Sequences Flawlessly", "paper_summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities in\ncomprehending and analyzing lengthy sequential inputs, owing to their extensive\ncontext windows that allow processing millions of tokens in a single forward\npass. However, this paper uncovers a surprising limitation: LLMs fall short\nwhen handling long input sequences. We investigate this issue using three\ndatasets and two tasks (sentiment analysis and news categorization) across\nvarious LLMs, including Claude 3, Gemini Pro, GPT 3.5 Turbo, Llama 3 Instruct,\nand Mistral Instruct models. To address this limitation, we propose and\nevaluate ad-hoc solutions that substantially enhance LLMs' performance on long\ninput sequences by up to 50%, while reducing API cost and latency by up to 93%\nand 50%, respectively.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5728\u7406\u89e3\u548c\u5206\u6790\u5197\u9577\u7684\u9806\u5e8f\u8f38\u5165\u65b9\u9762\u8868\u73fe\u51fa\u975e\u51e1\u7684\u80fd\u529b\uff0c\u9019\u8981\u6b78\u529f\u65bc\u5b83\u5011\u5ee3\u6cdb\u7684\u4e0a\u4e0b\u6587\u8996\u7a97\uff0c\u5141\u8a31\u5728\u55ae\u6b21\u524d\u5411\u50b3\u905e\u4e2d\u8655\u7406\u6578\u767e\u842c\u500b\u7b26\u865f\u3002\u7136\u800c\uff0c\u672c\u6587\u63ed\u793a\u4e86\u4e00\u500b\u4ee4\u4eba\u9a5a\u8a1d\u7684\u9650\u5236\uff1aLLM \u5728\u8655\u7406\u9577\u8f38\u5165\u5e8f\u5217\u6642\u8868\u73fe\u4e0d\u4f73\u3002\u6211\u5011\u4f7f\u7528\u4e09\u500b\u8cc7\u6599\u96c6\u548c\u5169\u500b\u4efb\u52d9\uff08\u60c5\u7dd2\u5206\u6790\u548c\u65b0\u805e\u5206\u985e\uff09\u8abf\u67e5\u4e86\u9019\u500b\u554f\u984c\uff0c\u6d89\u53ca\u5404\u7a2e LLM\uff0c\u5305\u62ec Claude 3\u3001Gemini Pro\u3001GPT 3.5 Turbo\u3001Llama 3 Instruct \u548c Mistral Instruct \u6a21\u578b\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u9650\u5236\uff0c\u6211\u5011\u63d0\u51fa\u4e26\u8a55\u4f30\u4e86\u81e8\u6642\u89e3\u6c7a\u65b9\u6848\uff0c\u9019\u4e9b\u89e3\u6c7a\u65b9\u6848\u5927\u5e45\u63d0\u5347\u4e86 LLM \u5728\u9577\u8f38\u5165\u5e8f\u5217\u4e0a\u7684\u6548\u80fd\uff0c\u6700\u9ad8\u9054 50%\uff0c\u540c\u6642\u5c07 API \u6210\u672c\u548c\u5ef6\u9072\u5206\u5225\u964d\u4f4e\u4e86 93% \u548c 50%\u3002", "author": "Peyman Hosseini et.al.", "authors": "Peyman Hosseini, Ignacio Castro, Iacopo Ghinassi, Matthew Purver", "id": "2408.01866v1", "paper_url": "http://arxiv.org/abs/2408.01866v1", "repo": "null"}}