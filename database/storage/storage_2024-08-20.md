# arxiv-daily
 Automated deployment @ 2024-08-20 08:58:02 Asia/Taipei
> Welcome to contribute! Add your topics and keywords in [`topic.yml`](https://github.com/jawatech/arxiv-daily-in-place/blob/main/database/topic.yml).
> You can also view historical data through the [storage](https://github.com/jawatech/arxiv-daily-in-place/blob/main/database/storage).

## AI

### Knowledge Graphs
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-08-16**|**EmoDynamiX: Emotional Support Dialogue Strategy Prediction by Modelling MiXed Emotions and Discourse Dynamics**|Chenwei Wan et.al.|[2408.08782v1](http://arxiv.org/abs/2408.08782v1)|[link](https://github.com/cw-wan/EmoDynamiX-v2)|
|**2024-08-16**|**Can Large Language Models Improve the Adversarial Robustness of Graph Neural Networks?**|Zhongjian Zhang et.al.|[2408.08685v1](http://arxiv.org/abs/2408.08685v1)|null|
|**2024-08-16**|**CommunityKG-RAG: Leveraging Community Structures in Knowledge Graphs for Advanced Retrieval-Augmented Generation in Fact-Checking**|Rong-Ching Chang et.al.|[2408.08535v1](http://arxiv.org/abs/2408.08535v1)|null|
|**2024-08-14**|**Training Language Models on the Knowledge Graph: Insights on Hallucinations and Their Detectability**|Jiri Hron et.al.|[2408.07852v1](http://arxiv.org/abs/2408.07852v1)|null|
|**2024-08-14**|**ONSEP: A Novel Online Neural-Symbolic Framework for Event Prediction Based on Large Language Model**|Xuanqing Yu et.al.|[2408.07840v1](http://arxiv.org/abs/2408.07840v1)|null|
|**2024-08-14**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611v1](http://arxiv.org/abs/2408.07611v1)|null|
|**2024-08-14**|**Fact or Fiction? Improving Fact Verification with Knowledge Graphs through Simplified Subgraph Retrievals**|Tobias A. Opsahl et.al.|[2408.07453v1](http://arxiv.org/abs/2408.07453v1)|[link](https://github.com/tobias-opsahl/fact-or-fiction)|
|**2024-08-13**|**LLMs can Schedule**|Henrik Abgaryan et.al.|[2408.06993v1](http://arxiv.org/abs/2408.06993v1)|[link](https://github.com/starjob42/datasetjsp)|
|**2024-08-13**|**Causal Agent based on Large Language Model**|Kairong Han et.al.|[2408.06849v1](http://arxiv.org/abs/2408.06849v1)|[link](https://github.com/kairong-han/causal_agent)|
|**2024-08-13**|**Unlock the Power of Frozen LLMs in Knowledge Graph Completion**|Bo Xue et.al.|[2408.06787v1](http://arxiv.org/abs/2408.06787v1)|null|
|**2024-08-13**|**Computation-friendly Graph Neural Network Design by Accumulating Knowledge on Large Language Models**|Jialiang Wang et.al.|[2408.06717v1](http://arxiv.org/abs/2408.06717v1)|null|
|**2024-08-12**|**Body Transformer: Leveraging Robot Embodiment for Policy Learning**|Carmelo Sferrazza et.al.|[2408.06316v1](http://arxiv.org/abs/2408.06316v1)|null|
|**2024-08-12**|**ARPA: A Novel Hybrid Model for Advancing Visual Word Disambiguation Using Large Language Models and Transformers**|Aristi Papastavrou et.al.|[2408.06040v1](http://arxiv.org/abs/2408.06040v1)|null|
|**2024-08-12**|**ConvKGYarn: Spinning Configurable and Scalable Conversational Knowledge Graph QA datasets with Large Language Models**|Ronak Pradeep et.al.|[2408.05948v1](http://arxiv.org/abs/2408.05948v1)|null|
|**2024-08-11**|**The Cognitive Revolution in Interpretability: From Explaining Behavior to Interpreting Representations and Algorithms**|Adam Davies et.al.|[2408.05859v1](http://arxiv.org/abs/2408.05859v1)|null|
|**2024-08-10**|**Investigating Instruction Tuning Large Language Models on Graphs**|Kerui Zhu et.al.|[2408.05457v1](http://arxiv.org/abs/2408.05457v1)|[link](https://github.com/zhukerui/graph-instruction-tuning)|
|**2024-08-10**|**Path-LLM: A Shortest-Path-based LLM Learning for Unified Graph Representation**|Wenbo Shang et.al.|[2408.05456v1](http://arxiv.org/abs/2408.05456v1)|null|
|**2024-08-10**|**LaiDA: Linguistics-aware In-context Learning with Data Augmentation for Metaphor Components Identification**|Hongde Liu et.al.|[2408.05404v1](http://arxiv.org/abs/2408.05404v1)|[link](https://github.com/wxljz/laida)|
|**2024-08-09**|**SHIELD: LLM-Driven Schema Induction for Predictive Analytics in EV Battery Supply Chain Disruptions**|Zhi-Qi Cheng et.al.|[2408.05357v1](http://arxiv.org/abs/2408.05357v1)|null|
|**2024-08-09**|**A Hybrid RAG System with Comprehensive Enhancement on Complex Reasoning**|Ye Yuan et.al.|[2408.05141v1](http://arxiv.org/abs/2408.05141v1)|null|
|**2024-08-09**|**Node Level Graph Autoencoder: Unified Pretraining for Textual Graph Learning**|Wenbin Hu et.al.|[2408.07091v1](http://arxiv.org/abs/2408.07091v1)|null|
|**2024-08-09**|**HybridRAG: Integrating Knowledge Graphs and Vector Retrieval Augmented Generation for Efficient Information Extraction**|Bhaskarjit Sarmah et.al.|[2408.04948v1](http://arxiv.org/abs/2408.04948v1)|null|
|**2024-08-08**|**DIVE: Subgraph Disagreement for Graph Out-of-Distribution Generalization**|Xin Sun et.al.|[2408.04400v1](http://arxiv.org/abs/2408.04400v1)|null|
|**2024-08-08**|**MM-Forecast: A Multimodal Approach to Temporal Event Forecasting with Large Language Models**|Haoxuan Li et.al.|[2408.04388v1](http://arxiv.org/abs/2408.04388v1)|[link](https://github.com/luminosityx/mm-forecast)|
|**2024-08-08**|**Judgment2vec: Apply Graph Analytics to Searching and Recommendation of Similar Judgments**|Hsuan-Lei Shao et.al.|[2408.04382v1](http://arxiv.org/abs/2408.04382v1)|null|
|**2024-08-08**|**Dynamic Hypergraph-Enhanced Prediction of Sequential Medical Visits**|Wangying Yang et.al.|[2408.07084v1](http://arxiv.org/abs/2408.07084v1)|null|
|**2024-08-08**|**wav2graph: A Framework for Supervised Learning Knowledge Graph from Speech**|Khai Le-Duc et.al.|[2408.04174v1](http://arxiv.org/abs/2408.04174v1)|[link](https://github.com/leduckhai/wav2graph)|
|**2024-08-07**|**ArtVLM: Attribute Recognition Through Vision-Based Prefix Language Modeling**|William Y. Zhu et.al.|[2408.04102v1](http://arxiv.org/abs/2408.04102v1)|null|
|**2024-08-07**|**CodexGraph: Bridging Large Language Models and Code Repositories via Code Graph Databases**|Xiangyan Liu et.al.|[2408.03910v2](http://arxiv.org/abs/2408.03910v2)|[link](https://github.com/modelscope/modelscope-agent)|
|**2024-08-07**|**PAGED: A Benchmark for Procedural Graphs Extraction from Documents**|Weihong Du et.al.|[2408.03630v2](http://arxiv.org/abs/2408.03630v2)|null|
|**2024-08-07**|**Optimus-1: Hybrid Multimodal Memory Empowered Agents Excel in Long-Horizon Tasks**|Zaijing Li et.al.|[2408.03615v1](http://arxiv.org/abs/2408.03615v1)|null|
|**2024-08-07**|**Exploring the extent of similarities in software failures across industries using LLMs**|Martin Detloff et.al.|[2408.03528v2](http://arxiv.org/abs/2408.03528v2)|null|
|**2024-08-06**|**Enhancing Complex Causality Extraction via Improved Subtask Interaction and Knowledge Fusion**|Jinglong Gao et.al.|[2408.03079v1](http://arxiv.org/abs/2408.03079v1)|null|
|**2024-08-06**|**Fact Finder -- Enhancing Domain Expertise of Large Language Models by Incorporating Knowledge Graphs**|Daniel Steinigen et.al.|[2408.03010v1](http://arxiv.org/abs/2408.03010v1)|[link](https://github.com/chrschy/fact-finder)|
|**2024-08-06**|**Leveraging Inter-Chunk Interactions for Enhanced Retrieval in Large Language Model-Based Question Answering**|Tiezheng Guo et.al.|[2408.02907v1](http://arxiv.org/abs/2408.02907v1)|null|
|**2024-08-05**|**MaterioMiner -- An ontology-based text mining dataset for extraction of process-structure-property entities**|Ali Riza Durmaz et.al.|[2408.04661v1](http://arxiv.org/abs/2408.04661v1)|null|
|**2024-08-05**|**Enhancing Supply Chain Visibility with Knowledge Graphs and Large Language Models**|Sara AlMahri et.al.|[2408.07705v1](http://arxiv.org/abs/2408.07705v1)|null|
|**2024-08-05**|**A Few-Shot Approach for Relation Extraction Domain Adaptation using Large Language Models**|Vanni Zavarella et.al.|[2408.02377v1](http://arxiv.org/abs/2408.02377v1)|null|
|**2024-08-05**|**Developing PUGG for Polish: A Modern Approach to KBQA, MRC, and IR Dataset Construction**|Albert Sawczyn et.al.|[2408.02337v1](http://arxiv.org/abs/2408.02337v1)|[link](https://github.com/CLARIN-PL/PUGG)|
|**2024-08-04**|**MedSyn: LLM-based Synthetic Medical Text Generation Framework**|Gleb Kumichev et.al.|[2408.02056v1](http://arxiv.org/abs/2408.02056v1)|[link](https://github.com/milteam/MedSyn)|
|**2024-08-04**|**DiReCT: Diagnostic Reasoning for Clinical Notes via Large Language Models**|Bowen Wang et.al.|[2408.01933v2](http://arxiv.org/abs/2408.01933v2)|null|
|**2024-08-03**|**PLUGH: A Benchmark for Spatial Understanding and Reasoning in Large Language Models**|Alexey Tikhonov et.al.|[2408.04648v1](http://arxiv.org/abs/2408.04648v1)|[link](https://github.com/altsoph/plugh)|
|**2024-08-03**|**Integrating Large Language Models and Knowledge Graphs for Extraction and Validation of Textual Test Data**|Antonio De Santis et.al.|[2408.01700v1](http://arxiv.org/abs/2408.01700v1)|[link](https://github.com/Antonio-Dee/tasi-testdata)|
|**2024-08-02**|**DERA: Dense Entity Retrieval for Entity Alignment in Knowledge Graphs**|Zhichun Wang et.al.|[2408.01154v1](http://arxiv.org/abs/2408.01154v1)|null|
|**2024-08-02**|**Bridging Information Gaps in Dialogues With Grounded Exchanges Using Knowledge Graphs**|Phillip Schneider et.al.|[2408.01088v2](http://arxiv.org/abs/2408.01088v2)|[link](https://github.com/philotron/bridge-kg)|
|**2024-08-02**|**Automatic Extraction of Relationships among Motivations, Emotions and Actions from Natural Language Texts**|Fei Yang et.al.|[2408.00966v1](http://arxiv.org/abs/2408.00966v1)|null|
|**2024-08-01**|**DisTrack: a new Tool for Semi-automatic Misinformation Tracking in Online Social Networks**|Guillermo Villar-Rodr√≠guez et.al.|[2408.00633v1](http://arxiv.org/abs/2408.00633v1)|null|
|**2024-08-01**|**On the Limitations and Prospects of Machine Unlearning for Generative AI**|Shiji Zhou et.al.|[2408.00376v1](http://arxiv.org/abs/2408.00376v1)|null|
|**2024-08-01**|**Multi-Modal Parameter-Efficient Fine-tuning via Graph Neural Network**|Bin Cheng et.al.|[2408.00290v1](http://arxiv.org/abs/2408.00290v1)|null|
|**2024-07-31**|**CEAR: Automatic construction of a knowledge graph of chemical entities and roles from scientific literature**|Stefan Langer et.al.|[2407.21708v1](http://arxiv.org/abs/2407.21708v1)|null|
|**2024-07-31**|**eSPARQL: Representing and Reconciling Agnostic and Atheistic Beliefs in RDF-star Knowledge Graphs**|Xinyi Pan et.al.|[2407.21483v3](http://arxiv.org/abs/2407.21483v3)|null|
|**2024-07-31**|**Navigating Beyond Instructions: Vision-and-Language Navigation in Obstructed Environments**|Haodong Hong et.al.|[2407.21452v1](http://arxiv.org/abs/2407.21452v1)|null|
|**2024-07-31**|**Tree-of-Traversals: A Zero-Shot Reasoning Algorithm for Augmenting Black-box Language Models with Knowledge Graphs**|Elan Markowitz et.al.|[2407.21358v1](http://arxiv.org/abs/2407.21358v1)|[link](https://github.com/amazon-science/tree-of-traversals)|
|**2024-07-31**|**SimpleLLM4AD: An End-to-End Vision-Language Model with Graph Visual Question Answering for Autonomous Driving**|Peiru Zheng et.al.|[2407.21293v1](http://arxiv.org/abs/2407.21293v1)|null|
|**2024-07-30**|**Be aware of overfitting by hyperparameter optimization!**|Igor V. Tetko et.al.|[2407.20786v1](http://arxiv.org/abs/2407.20786v1)|null|
|**2024-07-30**|**Harvesting Textual and Structured Data from the HAL Publication Repository**|Francis Kulumba et.al.|[2407.20595v1](http://arxiv.org/abs/2407.20595v1)|null|
|**2024-07-30**|**CLR-Fact: Evaluating the Complex Logical Reasoning Capability of Large Language Models over Factual Knowledge**|Tianshi Zheng et.al.|[2407.20564v1](http://arxiv.org/abs/2407.20564v1)|null|
|**2024-07-30**|**Prompt2DeModel: Declarative Neuro-Symbolic Modeling with Natural Language**|Hossein Rajaby Faghihi et.al.|[2407.20513v1](http://arxiv.org/abs/2407.20513v1)|null|
|**2024-07-29**|**What if Red Can Talk? Dynamic Dialogue Generation Using Large Language Models**|Navapat Nananukul et.al.|[2407.20382v1](http://arxiv.org/abs/2407.20382v1)|null|
|**2024-07-29**|**MindSearch: Mimicking Human Minds Elicits Deep AI Searcher**|Zehui Chen et.al.|[2407.20183v1](http://arxiv.org/abs/2407.20183v1)|[link](https://github.com/internlm/mindsearch)|
|**2024-07-29**|**rLLM: Relational Table Learning with LLMs**|Weichen Li et.al.|[2407.20157v1](http://arxiv.org/abs/2407.20157v1)|[link](https://github.com/rllm-project/rllm)|
|**2024-07-29**|**Prometheus Chatbot: Knowledge Graph Collaborative Large Language Model for Computer Components Recommendation**|Yunsheng Wang et.al.|[2407.19643v2](http://arxiv.org/abs/2407.19643v2)|[link](https://github.com/iamryanshengwang/prometheus-chatbot)|
|**2024-07-29**|**TopicTag: Automatic Annotation of NMF Topic Models Using Chain of Thought and Prompt Tuning with LLMs**|Selma Wanna et.al.|[2407.19616v1](http://arxiv.org/abs/2407.19616v1)|null|
|**2024-07-27**|**Semantic Communication Enhanced by Knowledge Graph Representation Learning**|Nour Hello et.al.|[2407.19338v1](http://arxiv.org/abs/2407.19338v1)|null|
|**2024-07-26**|**GraphBPE: Molecular Graphs Meet Byte-Pair Encoding**|Yuchen Shen et.al.|[2407.19039v1](http://arxiv.org/abs/2407.19039v1)|[link](https://github.com/A-Chicharito-S/GraphBPE)|
|**2024-07-26**|**Knowledge Graph Structure as Prompt: Improving Small Language Models Capabilities for Knowledge-based Causal Discovery**|Yuni Susanti et.al.|[2407.18752v3](http://arxiv.org/abs/2407.18752v3)|null|
|**2024-07-26**|**Using GPT-4 to guide causal machine learning**|Anthony C. Constantinou et.al.|[2407.18607v1](http://arxiv.org/abs/2407.18607v1)|null|
|**2024-07-26**|**Multi-turn Response Selection with Commonsense-enhanced Language Models**|Yuandong Wang et.al.|[2407.18479v1](http://arxiv.org/abs/2407.18479v1)|null|
|**2024-07-25**|**Gene Regulatory Network Inference from Pre-trained Single-Cell Transcriptomics Transformer with Joint Graph Learning**|Sindhura Kommu et.al.|[2407.18181v1](http://arxiv.org/abs/2407.18181v1)|null|
|**2024-07-24**|**MathViz-E: A Case-study in Domain-Specialized Tool-Using Agents**|Arya Bulusu et.al.|[2407.17544v1](http://arxiv.org/abs/2407.17544v1)|[link](https://github.com/emergenceai/mathviz-e)|
|**2024-07-23**|**Ranking protein-protein models with large language models and graph neural networks**|Xiaotong Xu et.al.|[2407.16375v1](http://arxiv.org/abs/2407.16375v1)|[link](https://github.com/haddocking/deeprank-gnn-esm)|
|**2024-07-23**|**PhenoFlow: A Human-LLM Driven Visual Analytics System for Exploring Large and Complex Stroke Datasets**|Jaeyoung Kim et.al.|[2407.16329v1](http://arxiv.org/abs/2407.16329v1)|null|
|**2024-07-23**|**Graph-Structured Speculative Decoding**|Zhuocheng Gong et.al.|[2407.16207v1](http://arxiv.org/abs/2407.16207v1)|null|
|**2024-07-23**|**Evaluating Long Range Dependency Handling in Code Generation Models using Multi-Step Key Retrieval**|Yannick Assogba et.al.|[2407.21049v1](http://arxiv.org/abs/2407.21049v1)|null|
|**2024-07-23**|**Finetuning Generative Large Language Models with Discrimination Instructions for Knowledge Graph Completion**|Yang Liu et.al.|[2407.16127v1](http://arxiv.org/abs/2407.16127v1)|[link](https://github.com/nju-websoft/dift)|
|**2024-07-22**|**Unsupervised Robust Cross-Lingual Entity Alignment via Neighbor Triple Matching with Entity and Relation Texts**|Soojin Yoon et.al.|[2407.15588v2](http://arxiv.org/abs/2407.15588v2)|[link](https://github.com/eralign/eralign)|
|**2024-07-22**|**The Ontoverse: Democratising Access to Knowledge Graph-based Data Through a Cartographic Interface**|Johannes Zimmermann et.al.|[2408.03339v1](http://arxiv.org/abs/2408.03339v1)|null|
|**2024-07-22**|**Pre-Training and Prompting for Few-Shot Node Classification on Text-Attributed Graphs**|Huanjing Zhao et.al.|[2407.15431v1](http://arxiv.org/abs/2407.15431v1)|null|
|**2024-07-22**|**LLMExplainer: Large Language Model based Bayesian Inference for Graph Explanation Generation**|Jiaxing Zhang et.al.|[2407.15351v2](http://arxiv.org/abs/2407.15351v2)|null|
|**2024-07-21**|**Text-Augmented Multimodal LLMs for Chemical Reaction Condition Recommendation**|Yu Zhang et.al.|[2407.15141v1](http://arxiv.org/abs/2407.15141v1)|null|
|**2024-07-20**|**On the Design and Analysis of LLM-Based Algorithms**|Yanxi Chen et.al.|[2407.14788v1](http://arxiv.org/abs/2407.14788v1)|[link](https://github.com/modelscope/agentscope)|
|**2024-07-19**|**LaMAGIC: Language-Model-based Topology Generation for Analog Integrated Circuits**|Chen-Chia Chang et.al.|[2407.18269v1](http://arxiv.org/abs/2407.18269v1)|null|
|**2024-07-19**|**Hierarchical Windowed Graph Attention Network and a Large Scale Dataset for Isolated Indian Sign Language Recognition**|Suvajit Patra et.al.|[2407.14224v1](http://arxiv.org/abs/2407.14224v1)|null|
|**2024-07-19**|**Enhancing Data-Limited Graph Neural Networks by Actively Distilling Knowledge from Large Language Models**|Quan Li et.al.|[2407.13989v1](http://arxiv.org/abs/2407.13989v1)|null|
|**2024-07-18**|**A Comprehensive Review of Recommender Systems: Transitioning from Theory to Practice**|Shaina Raza et.al.|[2407.13699v1](http://arxiv.org/abs/2407.13699v1)|null|
|**2024-07-18**|**MMAU: A Holistic Benchmark of Agent Capabilities Across Diverse Domains**|Guoli Yin et.al.|[2407.18961v3](http://arxiv.org/abs/2407.18961v3)|[link](https://github.com/apple/axlearn)|
|**2024-07-17**|**Is Sarcasm Detection A Step-by-Step Reasoning Process in Large Language Models?**|Ben Yao et.al.|[2407.12725v1](http://arxiv.org/abs/2407.12725v1)|null|
|**2024-07-17**|**Subgraph-Aware Training of Text-based Methods for Knowledge Graph Completion**|Youmin Ko et.al.|[2407.12703v3](http://arxiv.org/abs/2407.12703v3)|null|
|**2024-07-17**|**Abstraction Alignment: Comparing Model and Human Conceptual Relationships**|Angie Boggust et.al.|[2407.12543v1](http://arxiv.org/abs/2407.12543v1)|[link](https://github.com/mitvis/abstraction-alignment)|
|**2024-07-17**|**Struct-X: Enhancing Large Language Models Reasoning with Structured Data**|Xiaoyu Tan et.al.|[2407.12522v1](http://arxiv.org/abs/2407.12522v1)|null|
|**2024-07-17**|**Explainable Biomedical Hypothesis Generation via Retrieval Augmented Generation enabled Large Language Models**|Alexander R. Pelletier et.al.|[2407.12888v1](http://arxiv.org/abs/2407.12888v1)|[link](https://github.com/pinglab-utils/rugged)|
|**2024-07-16**|**A Comprehensive Evaluation of Large Language Models on Temporal Event Forecasting**|He Chang et.al.|[2407.11638v1](http://arxiv.org/abs/2407.11638v1)|null|
|**2024-07-16**|**Learning on Graphs with Large Language Models(LLMs): A Deep Dive into Model Robustness**|Kai Guo et.al.|[2407.12068v2](http://arxiv.org/abs/2407.12068v2)|null|
|**2024-07-16**|**CIC-BART-SSA: Controllable Image Captioning with Structured Semantic Augmentation**|Kalliopi Basioti et.al.|[2407.11393v2](http://arxiv.org/abs/2407.11393v2)|[link](https://github.com/SamsungLabs/CIC-BART-SSA)|
|**2024-07-15**|**Think-on-Graph 2.0: Deep and Interpretable Large Language Model Reasoning with Knowledge Graph-guided Retrieval**|Shengjie Ma et.al.|[2407.10805v3](http://arxiv.org/abs/2407.10805v3)|null|
|**2024-07-15**|**Graphusion: Leveraging Large Language Models for Scientific Knowledge Graph Fusion and Construction in NLP Education**|Rui Yang et.al.|[2407.10794v1](http://arxiv.org/abs/2407.10794v1)|[link](https://github.com/irenezihuili/cgprompt)|
|**2024-07-15**|**GraphEval: A Knowledge-Graph Based LLM Hallucination Evaluation Framework**|Hannah Sansford et.al.|[2407.10793v1](http://arxiv.org/abs/2407.10793v1)|null|
|**2024-07-15**|**Scaling 3D Reasoning with LMMs to Large Robot Mission Environments Using Datagraphs**|W. J. Meijer et.al.|[2407.10743v1](http://arxiv.org/abs/2407.10743v1)|null|
|**2024-07-14**|**AutoGRAMS: Autonomous Graphical Agent Modeling Software**|Ben Krause et.al.|[2407.10049v1](http://arxiv.org/abs/2407.10049v1)|[link](https://github.com/autograms/autograms)|
|**2024-07-13**|**FarFetched: Entity-centric Reasoning and Claim Validation for the Greek Language based on Textually Represented Environments**|Dimitris Papadopoulos et.al.|[2407.09888v1](http://arxiv.org/abs/2407.09888v1)|[link](https://github.com/lighteternal/farfetched_nlp)|

#### Abstracts
##### **EmoDynamiX: Emotional Support Dialogue Strategy Prediction by Modelling MiXed Emotions and Discourse Dynamics**
2408.08782v1 by Chenwei Wan, Matthieu Labeau, Chlo√© Clavel

Designing emotionally intelligent conversational systems to provide comfort
and advice to people experiencing distress is a compelling area of research.
Previous efforts have focused on developing modular dialogue systems that treat
socio-emotional strategy prediction as an auxiliary task and generate
strategy-conditioned responses with customized decoders. Recently, with
advancements in large language models (LLMs), end-to-end dialogue agents
without explicit socio-emotional strategy prediction steps have become
prevalent. However, despite their excellence in language generation, recent
studies show that LLMs' inherent preference bias towards certain
socio-emotional strategies hinders the delivery of high-quality emotional
support. To address this challenge, we propose decoupling strategy prediction
from language generation, and introduce a novel dialogue strategy predictor,
EmoDynamiX, which models the discourse dynamics between user emotions and
system strategies using a heterogeneous graph. Additionally, we make use of the
Emotion Recognition in Conversations (ERC) task and design a flexible
mixed-emotion module to capture fine-grained emotional states of the user.
Experimental results on two ESC datasets show EmoDynamiX outperforms previous
state-of-the-art methods with a significant margin.

ÊëòË¶ÅÔºöË®≠Ë®àÊÉÖÁ∑íÊô∫ËÉΩÂ∞çË©±Á≥ªÁµ±‰ª•Êèê‰æõÂÆâÊÖ∞ÂíåÂª∫Ë≠∞Áµ¶Á∂ìÊ≠∑ÁóõËã¶ÁöÑ‰∫∫ÊòØ‰∏ÄÂÄãÂºï‰∫∫ÂÖ•ÂãùÁöÑÁ†îÁ©∂È†òÂüü„ÄÇ
ÂÖàÂâçÁöÑÂä™ÂäõÈõÜ‰∏≠ÊñºÈñãÁôºÊ®°ÁµÑÂåñÂ∞çË©±Á≥ªÁµ±ÔºåÂ∞áÁ§æÊúÉÊÉÖÁ∑íÁ≠ñÁï•È†êÊ∏¨Ë¶ñÁÇ∫ËºîÂä©‰ªªÂãôÔºå‰∏¶‰ΩøÁî®Ëá™Ë®ÇËß£Á¢ºÂô®Áî¢ÁîüÁ≠ñÁï•Ê¢ù‰ª∂ÂåñÁöÑÂõûÊáâ„ÄÇÊúÄËøëÔºåÈö®ËëóÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÈÄ≤Ê≠•ÔºåÊ≤íÊúâÊòéÁ¢∫Á§æÊúÉÊÉÖÁ∑íÁ≠ñÁï•È†êÊ∏¨Ê≠•È©üÁöÑÁ´ØÂà∞Á´ØÂ∞çË©±‰ª£ÁêÜÂ∑≤ËÆäÂæóÊôÆÈÅç„ÄÇÁÑ∂ËÄåÔºåÂÑòÁÆ°ÂÆÉÂÄëÂú®Ë™ûË®ÄÁîüÊàêÊñπÈù¢Ë°®ÁèæÂá∫Ëâ≤Ôºå‰ΩÜÊúÄËøëÁöÑÁ†îÁ©∂Ë°®ÊòéÔºåLLM Â∞çÊüê‰∫õÁ§æÊúÉÊÉÖÁ∑íÁ≠ñÁï•ÁöÑÂõ∫ÊúâÂÅèÂ•ΩÊúÉÈòªÁ§ôÊèê‰æõÈ´òÂìÅË≥™ÁöÑÊÉÖÁ∑íÊîØÊåÅ„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∏ÄÊåëÊà∞ÔºåÊàëÂÄëÂª∫Ë≠∞Â∞áÁ≠ñÁï•È†êÊ∏¨ËàáË™ûË®ÄÁîüÊàêËß£ËÄ¶Ôºå‰∏¶ÂºïÂÖ•‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÂ∞çË©±Á≠ñÁï•È†êÊ∏¨Âô® EmoDynamiXÔºåÂÆÉ‰ΩøÁî®Áï∞Ë≥™ÂúñÂΩ¢Â∞ç‰ΩøÁî®ËÄÖÊÉÖÁ∑íÂíåÁ≥ªÁµ±Á≠ñÁï•‰πãÈñìÁöÑË©±Ë™ûÂãïÊÖãÈÄ≤Ë°åÂª∫Ê®°„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂà©Áî®Â∞çË©±‰∏≠ÁöÑÊÉÖÁ∑íËæ®Ë≠ò (ERC) ‰ªªÂãô‰∏¶Ë®≠Ë®à‰∫Ü‰∏ÄÂÄãÈùàÊ¥ªÁöÑÊ∑∑ÂêàÊÉÖÁ∑íÊ®°ÁµÑ‰æÜÊçïÊçâ‰ΩøÁî®ËÄÖÁöÑÁ¥∞Á∑ªÊÉÖÁ∑íÁãÄÊÖã„ÄÇÂú®ÂÖ©ÂÄã ESC Ë≥áÊñôÈõÜ‰∏äÁöÑÂØ¶È©óÁµêÊûúÈ°ØÁ§∫ÔºåEmoDynamiX ‰ª•È°ØËëóÁöÑÂπÖÂ∫¶ÂÑ™ÊñºÂÖàÂâçÁöÑÊúÄÊñ∞ÊñπÊ≥ï„ÄÇ

##### **Can Large Language Models Improve the Adversarial Robustness of Graph Neural Networks?**
2408.08685v1 by Zhongjian Zhang, Xiao Wang, Huichi Zhou, Yue Yu, Mengmei Zhang, Cheng Yang, Chuan Shi

Graph neural networks (GNNs) are vulnerable to adversarial perturbations,
especially for topology attacks, and many methods that improve the robustness
of GNNs have received considerable attention. Recently, we have witnessed the
significant success of large language models (LLMs), leading many to explore
the great potential of LLMs on GNNs. However, they mainly focus on improving
the performance of GNNs by utilizing LLMs to enhance the node features.
Therefore, we ask: Will the robustness of GNNs also be enhanced with the
powerful understanding and inference capabilities of LLMs? By presenting the
empirical results, we find that despite that LLMs can improve the robustness of
GNNs, there is still an average decrease of 23.1% in accuracy, implying that
the GNNs remain extremely vulnerable against topology attack. Therefore,
another question is how to extend the capabilities of LLMs on graph adversarial
robustness. In this paper, we propose an LLM-based robust graph structure
inference framework, LLM4RGNN, which distills the inference capabilities of
GPT-4 into a local LLM for identifying malicious edges and an LM-based edge
predictor for finding missing important edges, so as to recover a robust graph
structure. Extensive experiments demonstrate that LLM4RGNN consistently
improves the robustness across various GNNs. Even in some cases where the
perturbation ratio increases to 40%, the accuracy of GNNs is still better than
that on the clean graph.

ÊëòË¶ÅÔºöÂúñÂΩ¢Á•ûÁ∂ìÁ∂≤Ë∑Ø (GNN) ÂÆπÊòìÂèóÂà∞Â∞çÊäóÊÄßÊìæÂãïÁöÑÂΩ±ÈüøÔºå
ÁâπÂà•ÊòØÊãìÊí≤ÊîªÊìäÔºåË®±Â§öÊîπÂñÑ GNN È≠ØÊ£íÊÄßÁöÑÊñπÊ≥ïÈÉΩÂÇôÂèóÈóúÊ≥®„ÄÇÊúÄËøëÔºåÊàëÂÄëË¶ãË≠â‰∫ÜÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÈ°ØËëóÊàêÂäüÔºåÂ∞éËá¥Ë®±Â§ö‰∫∫Êé¢Á¥¢ LLM Âú® GNN ‰∏äÁöÑÂ∑®Â§ßÊΩõÂäõ„ÄÇÁÑ∂ËÄåÔºå‰ªñÂÄë‰∏ªË¶ÅÂ∞àÊ≥®ÊñºÂà©Áî® LLM Â¢ûÂº∑ÁØÄÈªûÁâπÂæµ‰æÜÊîπÂñÑ GNN ÁöÑÊïàËÉΩ„ÄÇ
Âõ†Ê≠§ÔºåÊàëÂÄëÂïèÔºöLLM Âº∑Â§ßÁöÑÁêÜËß£ÂíåÊé®ÁêÜËÉΩÂäõÊòØÂê¶‰πüÊúÉÂ¢ûÂº∑ GNN ÁöÑÈ≠ØÊ£íÊÄßÔºüÈÄèÈÅéÂëàÁèæÂØ¶Ë≠âÁµêÊûúÔºåÊàëÂÄëÁôºÁèæÂÑòÁÆ° LLM ÂèØ‰ª•ÊîπÂñÑ GNN ÁöÑÈ≠ØÊ£íÊÄßÔºå‰ΩÜÊ∫ñÁ¢∫Â∫¶‰ªçÂπ≥Âùá‰∏ãÈôç 23.1%ÔºåÈÄôË°®Á§∫ GNN ‰ªçÁÑ∂Ê•µÂÆπÊòìÂèóÂà∞ÊãìÊí≤ÊîªÊìä„ÄÇÂõ†Ê≠§ÔºåÂè¶‰∏ÄÂÄãÂïèÈ°åÊòØÂ¶Ç‰ΩïÊì¥Â±ï LLM Âú®ÂúñÂΩ¢Â∞çÊäóÈ≠ØÊ£íÊÄß‰∏äÁöÑËÉΩÂäõ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÂü∫Êñº LLM ÁöÑÈ≠ØÊ£íÂúñÂΩ¢ÁµêÊßãÊé®ÁêÜÊ°ÜÊû∂ LLM4RGNNÔºåÂÆÉÂ∞á GPT-4 ÁöÑÊé®ÁêÜËÉΩÂäõÊèêÁÖâÊàê‰∏ÄÂÄãÁî®ÊñºË≠òÂà•ÊÉ°ÊÑèÈÇäÁ∑£ÁöÑÊú¨Âú∞ LLMÔºå‰ª•Âèä‰∏ÄÂÄãÁî®ÊñºÂ∞ãÊâæÈÅ∫Â§±ÈáçË¶ÅÈÇäÁ∑£ÁöÑÂü∫Êñº LM ÁöÑÈÇäÁ∑£È†êÊ∏¨Âô®Ôºå‰ª•‰æøÊÅ¢Âæ©‰∏ÄÂÄãÈ≠ØÊ£íÁöÑÂúñÂΩ¢ÁµêÊßã„ÄÇÂª£Ê≥õÁöÑÂØ¶È©óË≠âÊòéÔºåLLM4RGNN ÊåÅÁ∫åÊîπÂñÑÂêÑÁ®Æ GNN ÁöÑÈ≠ØÊ£íÊÄß„ÄÇÂç≥‰ΩøÂú®Êüê‰∫õÊìæÂãïÁéáÂ¢ûÂä†Âà∞ 40% ÁöÑÊÉÖÊ≥Å‰∏ãÔºåGNN ÁöÑÊ∫ñÁ¢∫Â∫¶‰ªçÁÑ∂ÂÑ™Êñº‰πæÊ∑®ÂúñÂΩ¢„ÄÇ

##### **CommunityKG-RAG: Leveraging Community Structures in Knowledge Graphs for Advanced Retrieval-Augmented Generation in Fact-Checking**
2408.08535v1 by Rong-Ching Chang, Jiawei Zhang

Despite advancements in Large Language Models (LLMs) and Retrieval-Augmented
Generation (RAG) systems, their effectiveness is often hindered by a lack of
integration with entity relationships and community structures, limiting their
ability to provide contextually rich and accurate information retrieval for
fact-checking. We introduce CommunityKG-RAG (Community Knowledge
Graph-Retrieval Augmented Generation), a novel zero-shot framework that
integrates community structures within Knowledge Graphs (KGs) with RAG systems
to enhance the fact-checking process. Capable of adapting to new domains and
queries without additional training, CommunityKG-RAG utilizes the multi-hop
nature of community structures within KGs to significantly improve the accuracy
and relevance of information retrieval. Our experimental results demonstrate
that CommunityKG-RAG outperforms traditional methods, representing a
significant advancement in fact-checking by offering a robust, scalable, and
efficient solution.

ÊëòË¶ÅÔºöÂÑòÁÆ°Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂíåÊ™¢Á¥¢Â¢ûÂº∑ÁîüÊàê (RAG) Á≥ªÁµ±ÊúâÈÄ≤Ê≠•Ôºå‰ΩÜÂÆÉÂÄëÁöÑÊúâÊïàÊÄßÁ∂ìÂ∏∏ÂèóÂà∞Áº∫‰πèËàáÂØ¶È´îÈóú‰øÇÂíåÁ§æÁæ§ÁµêÊßãÊï¥ÂêàÁöÑÈòªÁ§ôÔºåÈôêÂà∂‰∫ÜÂÆÉÂÄëÊèê‰æõËÑàÁµ°Ë±êÂØå‰∏îÊ∫ñÁ¢∫ÁöÑË≥áË®äÊ™¢Á¥¢‰ª•ÈÄ≤Ë°å‰∫ãÂØ¶Êü•Ê†∏ÁöÑËÉΩÂäõ„ÄÇÊàëÂÄë‰ªãÁ¥π CommunityKG-RAGÔºàÁ§æÁæ§Áü•Ë≠òÂúñË≠úÊ™¢Á¥¢Â¢ûÂº∑ÁîüÊàêÔºâÔºåÈÄôÊòØ‰∏ÄÂÄãÊñ∞Á©éÁöÑÈõ∂Ê¨°Â≠∏ÁøíÊû∂ÊßãÔºåÂÆÉÂ∞áÁü•Ë≠òÂúñË≠ú (KG) ÂÖßÁöÑÁ§æÁæ§ÁµêÊßãËàá RAG Á≥ªÁµ±Êï¥ÂêàÔºå‰ª•Â¢ûÂº∑‰∫ãÂØ¶Êü•Ê†∏ÊµÅÁ®ã„ÄÇCommunityKG-RAG ÁÑ°ÈúÄÈ°çÂ§ñË®ìÁ∑¥Â∞±ËÉΩÈÅ©ÊáâÊñ∞ÁöÑÈ†òÂüüÂíåÊü•Ë©¢ÔºåÂÆÉÂà©Áî® KG ÂÖßÁ§æÁæ§ÁµêÊßãÁöÑÂ§öË∑≥ÁâπÊÄßÔºåÂ§ßÂπÖÊèêÂçáË≥áË®äÊ™¢Á¥¢ÁöÑÊ∫ñÁ¢∫ÊÄßÂíåÁõ∏ÈóúÊÄß„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÁµêÊûúË≠âÊòé CommunityKG-RAG ÂÑ™ÊñºÂÇ≥Áµ±ÊñπÊ≥ïÔºå‰ª£Ë°®Ëëó‰∫ãÂØ¶Êü•Ê†∏ÁöÑÈáçÂ§ßÈÄ≤Ê≠•ÔºåÊèê‰æõ‰∫Ü‰∏ÄÂÄãÂº∑ÂÅ•„ÄÅÂèØÊì¥ÂÖÖ‰∏îÊúâÊïàÁéáÁöÑËß£Ê±∫ÊñπÊ°à„ÄÇ

##### **Training Language Models on the Knowledge Graph: Insights on Hallucinations and Their Detectability**
2408.07852v1 by Jiri Hron, Laura Culp, Gamaleldin Elsayed, Rosanne Liu, Ben Adlam, Maxwell Bileschi, Bernd Bohnet, JD Co-Reyes, Noah Fiedel, C. Daniel Freeman, Izzeddin Gur, Kathleen Kenealy, Jaehoon Lee, Peter J. Liu, Gaurav Mishra, Igor Mordatch, Azade Nova, Roman Novak, Aaron Parisi, Jeffrey Pennington, Alex Rizkowsky, Isabelle Simpson, Hanie Sedghi, Jascha Sohl-dickstein, Kevin Swersky, Sharad Vikram, Tris Warkentin, Lechao Xiao, Kelvin Xu, Jasper Snoek, Simon Kornblith

While many capabilities of language models (LMs) improve with increased
training budget, the influence of scale on hallucinations is not yet fully
understood. Hallucinations come in many forms, and there is no universally
accepted definition. We thus focus on studying only those hallucinations where
a correct answer appears verbatim in the training set. To fully control the
training data content, we construct a knowledge graph (KG)-based dataset, and
use it to train a set of increasingly large LMs. We find that for a fixed
dataset, larger and longer-trained LMs hallucinate less. However, hallucinating
on $\leq5$% of the training data requires an order of magnitude larger model,
and thus an order of magnitude more compute, than Hoffmann et al. (2022)
reported was optimal. Given this costliness, we study how hallucination
detectors depend on scale. While we see detector size improves performance on
fixed LM's outputs, we find an inverse relationship between the scale of the LM
and the detectability of its hallucinations.

ÊëòË¶ÅÔºöÈõñÁÑ∂Ë™ûË®ÄÊ®°Âûã (LM) ÁöÑË®±Â§öËÉΩÂäõÊúÉÈö®ËëóË®ìÁ∑¥È†êÁÆóÁöÑÂ¢ûÂä†ËÄåÊúâÊâÄÊèêÂçáÔºå‰ΩÜË¶èÊ®°Â∞çÂπªË¶∫ÁöÑÂΩ±ÈüøÂ∞öÊú™ÂÆåÂÖ®‰∫ÜËß£„ÄÇÂπªË¶∫ÊúâË®±Â§öÂΩ¢ÂºèÔºå‰∏îÊ≤íÊúâÊôÆÈÅçÊé•ÂèóÁöÑÂÆöÁæ©„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëÂè™Â∞àÊ≥®ÊñºÁ†îÁ©∂Ë®ìÁ∑¥ÈõÜ‰∏≠Âá∫ÁèæÊ≠£Á¢∫Á≠îÊ°àÁöÑÂπªË¶∫„ÄÇÁÇ∫‰∫ÜÂÆåÂÖ®ÊéßÂà∂Ë®ìÁ∑¥Ë≥áÊñôÂÖßÂÆπÔºåÊàëÂÄëÂª∫Êßã‰∫Ü‰∏ÄÂÄãÂü∫ÊñºÁü•Ë≠òÂúñË≠ú (KG) ÁöÑË≥áÊñôÈõÜÔºå‰∏¶‰ΩøÁî®ÂÆÉ‰æÜË®ìÁ∑¥‰∏ÄÁµÑË∂ä‰æÜË∂äÂ§ßÁöÑ LM„ÄÇÊàëÂÄëÁôºÁèæÂ∞çÊñºÂõ∫ÂÆöÁöÑË≥áÊñôÈõÜÔºåË¶èÊ®°ËºÉÂ§ß‰∏îË®ìÁ∑¥ÊôÇÈñìËºÉÈï∑ÁöÑ LM Áî¢ÁîüÁöÑÂπªË¶∫ËºÉÂ∞ë„ÄÇÁÑ∂ËÄåÔºåÂú® $\leq5$% ÁöÑË®ìÁ∑¥Ë≥áÊñô‰∏äÁî¢ÁîüÂπªË¶∫ÈúÄË¶ÅË¶èÊ®°Â§ß‰∏ÄÂÄãÊï∏ÈáèÁ¥öÁöÑÊ®°ÂûãÔºåÂõ†Ê≠§ÊØî Hoffmann Á≠â‰∫∫ (2022) ÊâÄÂ†±ÂëäÁöÑÊúÄ‰Ω≥Ë¶èÊ®°Â§ö‰∏ÄÂÄãÊï∏ÈáèÁ¥öÁöÑÈÅãÁÆóÊàêÊú¨„ÄÇËÄÉÈáèÂà∞ÈÄôÁ®ÆÊàêÊú¨ÔºåÊàëÂÄëÁ†îÁ©∂ÂπªË¶∫ÂÅµÊ∏¨Âô®Â¶Ç‰ΩïÂèñÊ±∫ÊñºË¶èÊ®°„ÄÇÈõñÁÑ∂ÊàëÂÄëÁúãÂà∞ÂÅµÊ∏¨Âô®Ë¶èÊ®°ÊúÉÊèêÂçáÂ∞çÂõ∫ÂÆö LM Ëº∏Âá∫ÁöÑÊïàËÉΩÔºå‰ΩÜÊàëÂÄëÁôºÁèæ LM ÁöÑË¶èÊ®°ËàáÂÖ∂ÂπªË¶∫ÁöÑÂèØÂÅµÊ∏¨ÊÄß‰πãÈñìÂ≠òÂú®ÂèçÊØîÈóú‰øÇ„ÄÇ

##### **ONSEP: A Novel Online Neural-Symbolic Framework for Event Prediction Based on Large Language Model**
2408.07840v1 by Xuanqing Yu, Wangtao Sun, Jingwei Li, Kang Liu, Chengbao Liu, Jie Tan

In the realm of event prediction, temporal knowledge graph forecasting (TKGF)
stands as a pivotal technique. Previous approaches face the challenges of not
utilizing experience during testing and relying on a single short-term history,
which limits adaptation to evolving data. In this paper, we introduce the
Online Neural-Symbolic Event Prediction (ONSEP) framework, which innovates by
integrating dynamic causal rule mining (DCRM) and dual history augmented
generation (DHAG). DCRM dynamically constructs causal rules from real-time
data, allowing for swift adaptation to new causal relationships. In parallel,
DHAG merges short-term and long-term historical contexts, leveraging a
bi-branch approach to enrich event prediction. Our framework demonstrates
notable performance enhancements across diverse datasets, with significant
Hit@k (k=1,3,10) improvements, showcasing its ability to augment large language
models (LLMs) for event prediction without necessitating extensive retraining.
The ONSEP framework not only advances the field of TKGF but also underscores
the potential of neural-symbolic approaches in adapting to dynamic data
environments.

ÊëòË¶ÅÔºöÂú®‰∫ã‰ª∂È†êÊ∏¨È†òÂüü‰∏≠ÔºåÊôÇÂ∫èÁü•Ë≠òÂúñË≠úÈ†êÊ∏¨ (TKGF) ÊòØ‰∏ÄÂÄãÈóúÈçµÊäÄË°ì„ÄÇÂÖàÂâçÁöÑÂÅöÊ≥ïÈù¢Ëá®Âú®Ê∏¨Ë©¶ÊúüÈñì‰∏çÂà©Áî®Á∂ìÈ©ó‰ª•Âèä‰æùË≥¥ÂñÆ‰∏ÄÁü≠ÊúüÊ≠∑Âè≤ÁöÑÊåëÊà∞ÔºåÈÄôÈôêÂà∂‰∫ÜÂ∞çÊºîÂåñË≥áÊñôÁöÑÈÅ©ÊáâÊÄß„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫ÜÁ∑ö‰∏äÁ•ûÁ∂ìÁ¨¶Ëôü‰∫ã‰ª∂È†êÊ∏¨ (ONSEP) Êû∂ÊßãÔºåÂÆÉÈÄèÈÅéÊï¥ÂêàÂãïÊÖãÂõ†ÊûúË¶èÂâáÊåñÊéò (DCRM) ÂíåÈõôÈáçÊ≠∑Âè≤Êì¥ÂÖÖÁîüÊàê (DHAG) ‰æÜÂâµÊñ∞„ÄÇDCRM ÂæûÂç≥ÊôÇË≥áÊñô‰∏≠ÂãïÊÖãÂª∫ÊßãÂõ†ÊûúË¶èÂâáÔºåÂÖÅË®±Âø´ÈÄüÈÅ©ÊáâÊñ∞ÁöÑÂõ†ÊûúÈóú‰øÇ„ÄÇÂêåÊôÇÔºåDHAG Âêà‰ΩµÁü≠ÊúüÂíåÈï∑ÊúüÊ≠∑Âè≤ËÑàÁµ°ÔºåÂà©Áî®ÈõôÂàÜÊîØÊñπÊ≥ï‰æÜË±êÂØå‰∫ã‰ª∂È†êÊ∏¨„ÄÇÊàëÂÄëÁöÑÊû∂ÊßãÂú®ÂêÑÁ®ÆË≥áÊñôÈõÜ‰∏äÂ±ïÁ§∫Âá∫È°ØËëóÁöÑÊïàËÉΩÊèêÂçáÔºåHit@k (k=1,3,10) ÊúâÈ°ØËëóÁöÑÊîπÂñÑÔºåÂ±ïÁ§∫‰∫ÜÂÆÉÂú®ÁÑ°ÈúÄÂª£Ê≥õÈáçÊñ∞Ë®ìÁ∑¥ÁöÑÊÉÖÊ≥Å‰∏ãÊì¥ÂÖÖÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰ª•ÈÄ≤Ë°å‰∫ã‰ª∂È†êÊ∏¨ÁöÑËÉΩÂäõ„ÄÇONSEP Êû∂Êßã‰∏çÂÉÖÊé®Âãï‰∫Ü TKGF È†òÂüüÔºå‰πüÂº∑Ë™ø‰∫ÜÁ•ûÁ∂ìÁ¨¶ËôüÊñπÊ≥ïÂú®ÈÅ©ÊáâÂãïÊÖãË≥áÊñôÁí∞Â¢É‰∏≠ÁöÑÊΩõÂäõ„ÄÇ

##### **WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**
2408.07611v1 by Weijian Xie, Xuefeng Liang, Yuhui Liu, Kaihua Ni, Hong Cheng, Zetian Hu

Large Language Models (LLMs) have greatly contributed to the development of
adaptive intelligent agents and are positioned as an important way to achieve
Artificial General Intelligence (AGI). However, LLMs are prone to produce
factually incorrect information and often produce "phantom" content that
undermines their reliability, which poses a serious challenge for their
deployment in real-world scenarios. Enhancing LLMs by combining external
databases and information retrieval mechanisms is an effective path. To address
the above challenges, we propose a new approach called WeKnow-RAG, which
integrates Web search and Knowledge Graphs into a "Retrieval-Augmented
Generation (RAG)" system. First, the accuracy and reliability of LLM responses
are improved by combining the structured representation of Knowledge Graphs
with the flexibility of dense vector retrieval. WeKnow-RAG then utilizes
domain-specific knowledge graphs to satisfy a variety of queries and domains,
thereby improving performance on factual information and complex reasoning
tasks by employing multi-stage web page retrieval techniques using both sparse
and dense retrieval methods. Our approach effectively balances the efficiency
and accuracy of information retrieval, thus improving the overall retrieval
process. Finally, we also integrate a self-assessment mechanism for the LLM to
evaluate the trustworthiness of the answers it generates. Our approach proves
its outstanding effectiveness in a wide range of offline experiments and online
submissions.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∞çÊñºËá™ÈÅ©ÊáâÊô∫ÊÖß‰ª£ÁêÜÁöÑÁôºÂ±ïÊúâÂæàÂ§ßÁöÑË≤¢ÁçªÔºå‰∏¶‰∏îË¢´ÂÆö‰ΩçÁÇ∫ÂØ¶Áèæ‰∫∫Â∑•ÈÄöÁî®Êô∫ÊÖß (AGI) ÁöÑÈáçË¶ÅÈÄîÂæë„ÄÇÁÑ∂ËÄåÔºåLLM ÂÆπÊòìÁî¢Áîü‰∫ãÂØ¶‰∏ä‰∏çÊ≠£Á¢∫ÁöÑË≥áË®äÔºå‰∏¶‰∏îÁ∂ìÂ∏∏Áî¢Áîü„ÄåÂπªÂΩ±„ÄçÂÖßÂÆπÔºåÈÄôÊúÉÁ†¥Â£ûÂÆÉÂÄëÁöÑÂèØÈù†ÊÄßÔºåÂ∞çÂÆÉÂÄëÂú®ÁèæÂØ¶‰∏ñÁïåÂ†¥ÊôØ‰∏≠ÁöÑÈÉ®ÁΩ≤ÊßãÊàêÂö¥Â≥ªÁöÑÊåëÊà∞„ÄÇÈÄèÈÅéÁµêÂêàÂ§ñÈÉ®Ë≥áÊñôÂ∫´ÂíåË≥áË®äÊ™¢Á¥¢Ê©üÂà∂‰æÜÂ¢ûÂº∑ LLM ÊòØ‰∏ÄÊ¢ùÊúâÊïàÁöÑË∑ØÂæë„ÄÇÁÇ∫‰∫ÜÊáâÂ∞ç‰∏äËø∞ÊåëÊà∞ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÁ®±ÁÇ∫ WeKnow-RAG ÁöÑÊñ∞ÊñπÊ≥ïÔºåÂÆÉÂ∞áÁ∂≤Ë∑ØÊêúÂ∞ãÂíåÁü•Ë≠òÂúñË≠úÊï¥ÂêàÂà∞„ÄåÊ™¢Á¥¢Â¢ûÂº∑Áî¢Áîü (RAG)„ÄçÁ≥ªÁµ±‰∏≠„ÄÇÈ¶ñÂÖàÔºåÈÄèÈÅéÁµêÂêàÁü•Ë≠òÂúñË≠úÁöÑÁµêÊßãÂåñË°®Á§∫ÂíåÂØÜÈõÜÂêëÈáèÊ™¢Á¥¢ÁöÑÈùàÊ¥ªÊÄßÔºåÊèêÈ´ò‰∫Ü LLM ÂõûÊáâÁöÑÊ∫ñÁ¢∫ÊÄßÂíåÂèØÈù†ÊÄß„ÄÇWeKnow-RAG Êé•ËëóÂà©Áî®ÁâπÂÆöÈ†òÂüüÁöÑÁü•Ë≠òÂúñË≠ú‰æÜÊªøË∂≥ÂêÑÁ®ÆÊü•Ë©¢ÂíåÈ†òÂüüÔºåÂæûËÄåÈÄèÈÅé‰ΩøÁî®Á®ÄÁñèÂíåÂØÜÈõÜÊ™¢Á¥¢ÊñπÊ≥ïÁöÑÂ§öÈöéÊÆµÁ∂≤È†ÅÊ™¢Á¥¢ÊäÄË°ìÔºåÊîπÂñÑ‰∫ãÂØ¶Ë≥áË®äÂíåË§áÈõúÊé®ÁêÜ‰ªªÂãôÁöÑÊïàËÉΩ„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÊúâÊïàÂú∞Âπ≥Ë°°‰∫ÜË≥áË®äÊ™¢Á¥¢ÁöÑÊïàÁéáÂíåÊ∫ñÁ¢∫ÊÄßÔºåÂæûËÄåÊîπÂñÑ‰∫ÜÊï¥È´îÊ™¢Á¥¢ÊµÅÁ®ã„ÄÇÊúÄÂæåÔºåÊàëÂÄë‰πüÁÇ∫ LLM Êï¥Âêà‰∫Ü‰∏ÄÂÄãËá™ÊàëË©ï‰º∞Ê©üÂà∂Ôºå‰ª•Ë©ï‰º∞ÂÆÉÊâÄÁî¢ÁîüÁ≠îÊ°àÁöÑÂèØ‰ø°Â∫¶„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÂú®Âª£Ê≥õÁöÑÈõ¢Á∑öÂØ¶È©óÂíåÁ∑ö‰∏äÊèê‰∫§‰∏≠Ë≠âÊòé‰∫ÜÂÖ∂ÂÇëÂá∫ÁöÑÊúâÊïàÊÄß„ÄÇ

##### **Fact or Fiction? Improving Fact Verification with Knowledge Graphs through Simplified Subgraph Retrievals**
2408.07453v1 by Tobias A. Opsahl

Despite recent success in natural language processing (NLP), fact
verification still remains a difficult task. Due to misinformation spreading
increasingly fast, attention has been directed towards automatically verifying
the correctness of claims. In the domain of NLP, this is usually done by
training supervised machine learning models to verify claims by utilizing
evidence from trustworthy corpora. We present efficient methods for verifying
claims on a dataset where the evidence is in the form of structured knowledge
graphs. We use the FactKG dataset, which is constructed from the DBpedia
knowledge graph extracted from Wikipedia. By simplifying the evidence retrieval
process, from fine-tuned language models to simple logical retrievals, we are
able to construct models that both require less computational resources and
achieve better test-set accuracy.

ÊëòË¶ÅÔºöÂÑòÁÆ°Âú®Ëá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ (NLP) ‰∏≠Áç≤ÂæóËøëÊúüÊàêÂäüÔºå‰∫ãÂØ¶È©óË≠â‰ªçÁÑ∂ÊòØ‰∏ÄÈ†ÖËâ±Èõ£ÁöÑ‰ªªÂãô„ÄÇÁî±ÊñºÈåØË™§Ë≥áË®äÂÇ≥Êí≠ÂæóË∂ä‰æÜË∂äÂø´ÔºåÊ≥®ÊÑèÂäõÂ∑≤ËΩâÂêëËá™ÂãïÈ©óË≠âËÅ≤ÊòéÁöÑÊ≠£Á¢∫ÊÄß„ÄÇÂú® NLP È†òÂüü‰∏≠ÔºåÈÄôÈÄöÂ∏∏ÈÄèÈÅéË®ìÁ∑¥Áõ£Áù£ÂºèÊ©üÂô®Â≠∏ÁøíÊ®°Âûã‰æÜÂÆåÊàêÔºåÈÄô‰∫õÊ®°ÂûãÂà©Áî®‰æÜËá™ÂèØ‰ø°Ë≥¥Ë™ûÊñôÂ∫´ÁöÑË≠âÊìö‰æÜÈ©óË≠âËÅ≤Êòé„ÄÇÊàëÂÄëÊèêÂá∫ÊúâÊïàÁöÑÊñπÊ≥ï‰æÜÈ©óË≠âË≥áÊñôÈõÜ‰∏≠ÁöÑËÅ≤ÊòéÔºåÂÖ∂‰∏≠Ë≠âÊìöÊòØ‰ª•ÁµêÊßãÂåñÁü•Ë≠òÂúñË°®ÁöÑÂΩ¢ÂºèÂëàÁèæ„ÄÇÊàëÂÄë‰ΩøÁî® FactKG Ë≥áÊñôÈõÜÔºåÂÆÉÊòØÁî±ÂæûÁ∂≠Âü∫ÁôæÁßë‰∏≠ËêÉÂèñÁöÑ DBpedia Áü•Ë≠òÂúñË°®ÊâÄÂª∫Êßã„ÄÇÈÄèÈÅéÁ∞°ÂåñË≠âÊìöÊì∑ÂèñÊµÅÁ®ãÔºåÂæûÂæÆË™øË™ûË®ÄÊ®°ÂûãÂà∞Á∞°ÂñÆÁöÑÈÇèËºØÊì∑ÂèñÔºåÊàëÂÄëËÉΩÂ§†Âª∫ÊßãÊó¢ÈúÄË¶ÅËºÉÂ∞ëË®àÁÆóË≥áÊ∫êÔºåÂèàËÉΩÈÅîÂà∞ËºÉ‰Ω≥Ê∏¨Ë©¶ÈõÜÊ∫ñÁ¢∫Â∫¶ÁöÑÊ®°Âûã„ÄÇ

##### **LLMs can Schedule**
2408.06993v1 by Henrik Abgaryan, Ararat Harutyunyan, Tristan Cazenave

The job shop scheduling problem (JSSP) remains a significant hurdle in
optimizing production processes. This challenge involves efficiently allocating
jobs to a limited number of machines while minimizing factors like total
processing time or job delays. While recent advancements in artificial
intelligence have yielded promising solutions, such as reinforcement learning
and graph neural networks, this paper explores the potential of Large Language
Models (LLMs) for JSSP. We introduce the very first supervised 120k dataset
specifically designed to train LLMs for JSSP. Surprisingly, our findings
demonstrate that LLM-based scheduling can achieve performance comparable to
other neural approaches. Furthermore, we propose a sampling method that
enhances the effectiveness of LLMs in tackling JSSP.

ÊëòË¶ÅÔºö‰ΩúÊ•≠ËªäÈñìÊéíÁ®ãÂïèÈ°å (JSSP) ‰ªçÁÑ∂ÊòØÊúÄ‰Ω≥ÂåñÁîüÁî¢ÊµÅÁ®ã‰∏≠ÁöÑ‰∏ÄÂ§ßÈöúÁ§ô„ÄÇÈÄôÈ†ÖÊåëÊà∞Ê∂âÂèäÂ∞á‰ΩúÊ•≠ÊúâÊïàÂàÜÈÖçÂà∞Êï∏ÈáèÊúâÈôêÁöÑÊ©üÂô®ÔºåÂêåÊôÇÂ∞áÁ∏ΩËôïÁêÜÊôÇÈñìÊàñ‰ΩúÊ•≠Âª∂ÈÅ≤Á≠âÂõ†Á¥†ÈôçËá≥ÊúÄ‰Ωé„ÄÇÂÑòÁÆ°‰∫∫Â∑•Êô∫ÊÖßÁöÑÊúÄÊñ∞ÈÄ≤Â±ïÂ∑≤Áî¢ÁîüÊúâÂ∏åÊúõÁöÑËß£Ê±∫ÊñπÊ°àÔºå‰æãÂ¶ÇÂº∑ÂåñÂ≠∏ÁøíÂíåÂúñÂΩ¢Á•ûÁ∂ìÁ∂≤Ë∑ØÔºå‰ΩÜÊú¨ÊñáÊé¢Ë®é‰∫ÜÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú® JSSP ‰∏≠ÁöÑÊΩõÂäõ„ÄÇÊàëÂÄëÂºïÂÖ•‰∫ÜÁ¨¨‰∏ÄÂÄãÁõ£Áù£Âºè 120k Ë≥áÊñôÈõÜÔºåÂ∞àÈñÄÁî®ÊñºË®ìÁ∑¥ JSSP ÁöÑ LLM„ÄÇ‰ª§‰∫∫È©öË®ùÁöÑÊòØÔºåÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúË°®ÊòéÔºåÂü∫Êñº LLM ÁöÑÊéíÁ®ãÂèØ‰ª•ÈÅîÂà∞ËàáÂÖ∂‰ªñÁ•ûÁ∂ìÊñπÊ≥ïÁõ∏Áï∂ÁöÑÊïàËÉΩ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊäΩÊ®£ÊñπÊ≥ïÔºåÂèØÂ¢ûÂº∑ LLM Âú®ËôïÁêÜ JSSP ‰∏≠ÁöÑÊúâÊïàÊÄß„ÄÇ

##### **Causal Agent based on Large Language Model**
2408.06849v1 by Kairong Han, Kun Kuang, Ziyu Zhao, Junjian Ye, Fei Wu

Large language models (LLMs) have achieved significant success across various
domains. However, the inherent complexity of causal problems and causal theory
poses challenges in accurately describing them in natural language, making it
difficult for LLMs to comprehend and use them effectively. Causal methods are
not easily conveyed through natural language, which hinders LLMs' ability to
apply them accurately. Additionally, causal datasets are typically tabular,
while LLMs excel in handling natural language data, creating a structural
mismatch that impedes effective reasoning with tabular data. This lack of
causal reasoning capability limits the development of LLMs. To address these
challenges, we have equipped the LLM with causal tools within an agent
framework, named the Causal Agent, enabling it to tackle causal problems. The
causal agent comprises tools, memory, and reasoning modules. In the tools
module, the causal agent applies causal methods to align tabular data with
natural language. In the reasoning module, the causal agent employs the ReAct
framework to perform reasoning through multiple iterations with the tools. In
the memory module, the causal agent maintains a dictionary instance where the
keys are unique names and the values are causal graphs. To verify the causal
ability of the causal agent, we established a benchmark consisting of four
levels of causal problems: variable level, edge level, causal graph level, and
causal effect level. We generated a test dataset of 1.3K using ChatGPT-3.5 for
these four levels of issues and tested the causal agent on the datasets. Our
methodology demonstrates remarkable efficacy on the four-level causal problems,
with accuracy rates all above 80%. For further insights and implementation
details, our code is accessible via the GitHub repository
https://github.com/Kairong-Han/Causal_Agent.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤Âú®ÂêÑÂÄãÈ†òÂüüÂèñÂæóÈáçÂ§ßÊàêÂäü„ÄÇÁÑ∂ËÄåÔºåÂõ†ÊûúÂïèÈ°åÂíåÂõ†ÊûúÁêÜË´ñÁöÑÂÖßÂú®Ë§áÈõúÊÄßÔºåÂú®Ëá™ÁÑ∂Ë™ûË®Ä‰∏≠Ê∫ñÁ¢∫ÊèèËø∞ÂÆÉÂÄëÊôÇÊßãÊàêÊåëÊà∞ÔºåÈÄô‰ΩøÂæó LLM Èõ£‰ª•ÁêÜËß£‰∏¶ÊúâÊïà‰ΩøÁî®ÂÆÉÂÄë„ÄÇÂõ†ÊûúÊñπÊ≥ï‰∏çÊòìÈÄèÈÅéËá™ÁÑ∂Ë™ûË®ÄÂÇ≥ÈÅîÔºåÈÄôÈòªÁ§ô‰∫Ü LLM Ê∫ñÁ¢∫ÊáâÁî®ÂÆÉÂÄëÁöÑËÉΩÂäõ„ÄÇÊ≠§Â§ñÔºåÂõ†ÊûúË≥áÊñôÈõÜÈÄöÂ∏∏ÊòØË°®Ê†ºÂåñÁöÑÔºåËÄå LLM ÊìÖÈï∑ËôïÁêÜËá™ÁÑ∂Ë™ûË®ÄË≥áÊñôÔºåÈÄôÈÄ†Êàê‰∫ÜÁµêÊßã‰∏äÁöÑ‰∏çÂåπÈÖçÔºåÈòªÁ§ô‰∫ÜÂ∞çË°®Ê†ºË≥áÊñôÈÄ≤Ë°åÊúâÊïàÁöÑÊé®ÁêÜ„ÄÇÈÄôÁ®ÆÁº∫‰πèÂõ†ÊûúÊé®ÁêÜËÉΩÂäõÈôêÂà∂‰∫Ü LLM ÁöÑÁôºÂ±ï„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÂú®‰∏ÄÂÄã‰ª£ÁêÜÊ°ÜÊû∂‰∏≠ÁÇ∫ LLM ÈÖçÂÇô‰∫ÜÂõ†ÊûúÂ∑•ÂÖ∑ÔºåÁ®±ÁÇ∫Âõ†Êûú‰ª£ÁêÜÔºå‰ΩøÂÆÉËÉΩÂ§†Ëß£Ê±∫Âõ†ÊûúÂïèÈ°å„ÄÇÂõ†Êûú‰ª£ÁêÜÂåÖÂê´Â∑•ÂÖ∑„ÄÅË®òÊÜ∂È´îÂíåÊé®ÁêÜÊ®°ÁµÑ„ÄÇÂú®Â∑•ÂÖ∑Ê®°ÁµÑ‰∏≠ÔºåÂõ†Êûú‰ª£ÁêÜÊáâÁî®Âõ†ÊûúÊñπÊ≥ïÂ∞áË°®Ê†ºË≥áÊñôËàáËá™ÁÑ∂Ë™ûË®ÄÂ∞çÈΩä„ÄÇÂú®Êé®ÁêÜÊ®°ÁµÑ‰∏≠ÔºåÂõ†Êûú‰ª£ÁêÜÊé°Áî® ReAct Ê°ÜÊû∂ÔºåÈÄèÈÅéËàáÂ∑•ÂÖ∑ÈÄ≤Ë°åÂ§öÊ¨°ÂèçË¶ÜÈÅãÁÆó‰æÜÂü∑Ë°åÊé®ÁêÜ„ÄÇÂú®Ë®òÊÜ∂È´îÊ®°ÁµÑ‰∏≠ÔºåÂõ†Êûú‰ª£ÁêÜÁ∂≠Ë≠∑‰∏ÄÂÄãÂ≠óÂÖ∏ÂØ¶‰æãÔºåÂÖ∂‰∏≠ÈçµÊòØÂîØ‰∏ÄÂêçÁ®±ÔºåËÄåÂÄºÊòØÂõ†ÊûúÂúñ„ÄÇÁÇ∫‰∫ÜÈ©óË≠âÂõ†Êûú‰ª£ÁêÜÁöÑÂõ†ÊûúËÉΩÂäõÔºåÊàëÂÄëÂª∫Á´ã‰∫Ü‰∏ÄÂÄãÂü∫Ê∫ñÔºåÂÖ∂‰∏≠ÂåÖÂê´ÂõõÂÄãÂ±§Á¥öÁöÑÂõ†ÊûúÂïèÈ°åÔºöËÆäÊï∏Â±§Á¥ö„ÄÅÈÇäÂ±§Á¥ö„ÄÅÂõ†ÊûúÂúñÂ±§Á¥öÂíåÂõ†ÊûúÊïàÊáâÂ±§Á¥ö„ÄÇÊàëÂÄë‰ΩøÁî® ChatGPT-3.5 ÁÇ∫ÈÄôÂõõÂÄãÂ±§Á¥öÁöÑÂïèÈ°åÁî¢Áîü‰∫Ü 1.3K ÁöÑÊ∏¨Ë©¶Ë≥áÊñôÈõÜÔºå‰∏¶Âú®Ë≥áÊñôÈõÜ‰∏äÊ∏¨Ë©¶‰∫ÜÂõ†Êûú‰ª£ÁêÜ„ÄÇÊàëÂÄëÁöÑÈÄôÂ•óÊñπÊ≥ïÂú®ÂõõÂÄãÂ±§Á¥öÁöÑÂõ†ÊûúÂïèÈ°å‰∏äÂ±ïÁèæ‰∫ÜÈ°ØËëóÁöÑÂäüÊïàÔºåÊ∫ñÁ¢∫ÁéáÈÉΩÈ´òÊñº 80%„ÄÇÊúâÈóúÈÄ≤‰∏ÄÊ≠•ÁöÑË¶ãËß£ÂíåÂØ¶‰ΩúÁ¥∞ÁØÄÔºåÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÂèØÈÄèÈÅé GitHub ÂÑ≤Â≠òÂ∫´ https://github.com/Kairong-Han/Causal_Agent ÂèñÂæó„ÄÇ

##### **Unlock the Power of Frozen LLMs in Knowledge Graph Completion**
2408.06787v1 by Bo Xue, Yi Xu, Yunchong Song, Yiming Pang, Yuyang Ren, Jiaxin Ding, Luoyi Fu, Xinbing Wang

Classical knowledge graph completion (KGC) methods rely solely on structural
information, struggling with the inherent sparsity of knowledge graphs (KGs).
Large Language Models (LLMs) learn extensive knowledge from large corpora with
powerful context modeling, which is ideal for mitigating the limitations of
previous methods. Directly fine-tuning LLMs offers great capability but comes
at the cost of huge time and memory consumption, while utilizing frozen LLMs
yields suboptimal results. In this work, we aim to leverage LLMs for KGC
effectively and efficiently. We capture the context-aware hidden states of
knowledge triples by employing prompts to stimulate the intermediate layers of
LLMs. We then train a data-efficient classifier on these hidden states to
harness the inherent capabilities of frozen LLMs in KGC. We also generate
entity descriptions with subgraph sampling on KGs, reducing the ambiguity of
triplets and enriching the knowledge representation. Extensive experiments on
standard benchmarks showcase the efficiency and effectiveness of our approach.
We outperform classical KGC methods on most datasets and match the performance
of fine-tuned LLMs. Additionally, compared to fine-tuned LLMs, we boost GPU
memory efficiency by \textbf{$188\times$} and speed up training+inference by
\textbf{$13.48\times$}.

ÊëòË¶ÅÔºöÂÇ≥Áµ±Áü•Ë≠òÂúñË≠úÂÆåÊàê (KGC) ÊñπÊ≥ïÂÉÖ‰æùË≥¥ÁµêÊßãÂåñË≥áË®äÔºåÈõ£‰ª•ÊáâÂ∞çÁü•Ë≠òÂúñË≠ú (KG) ÂÖßÂú®ÁöÑÁ®ÄÁñèÊÄß„ÄÇÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂæûÂ§ßÂûãË™ûÊñôÂ∫´‰∏≠Â≠∏ÁøíÂª£Ê≥õÁöÑÁü•Ë≠òÔºå‰∏¶ÂÖ∑ÂÇôÂº∑Â§ßÁöÑÊÉÖÂ¢ÉÂª∫Ê®°ËÉΩÂäõÔºåÈÄôÂ∞çÊñºÁ∑©Ëß£ÂÖàÂâçÊñπÊ≥ïÁöÑÈôêÂà∂ÈùûÂ∏∏ÁêÜÊÉ≥„ÄÇÁõ¥Êé•ÂæÆË™ø LLM ÂèØÊèê‰æõÂº∑Â§ßÁöÑËÉΩÂäõÔºå‰ΩÜ‰ª£ÂÉπÊòØËÄóË≤ªÂ§ßÈáèÊôÇÈñìÂíåË®òÊÜ∂È´îÔºåËÄåÂà©Áî®ÂáçÁµêÁöÑ LLM ÂâáÊúÉÁî¢ÁîüÊ¨°‰Ω≥ÁµêÊûú„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊó®Âú®ÊúâÊïà‰∏îÈ´òÊïàÂú∞Âà©Áî® LLM ‰æÜÈÄ≤Ë°å KGC„ÄÇÊàëÂÄëÈÄèÈÅé‰ΩøÁî®ÊèêÁ§∫‰æÜÂà∫ÊøÄ LLM ÁöÑ‰∏≠ÈñìÂ±§ÔºåÊçïÊçâÂà∞Áü•Ë≠ò‰∏âÂÖÉÁµÑÁöÑÊÉÖÂ¢ÉÊÑüÁü•Èö±ËóèÁãÄÊÖã„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÂú®ÈÄô‰∫õÈö±ËóèÁãÄÊÖã‰∏äË®ìÁ∑¥‰∏ÄÂÄãË≥áÊñôÊúâÊïàÁéáÁöÑÂàÜÈ°ûÂô®Ôºå‰ª•Âà©Áî®ÂáçÁµê LLM Âú® KGC ‰∏≠ÁöÑÂÖßÂú®ËÉΩÂäõ„ÄÇÊàëÂÄëÈÇÑÈÄèÈÅéÂú® KG ‰∏äÈÄ≤Ë°åÂ≠êÂúñÊäΩÊ®£‰æÜÁî¢ÁîüÂØ¶È´îÊèèËø∞ÔºåÊ∏õÂ∞ë‰∏âÂÖÉÁµÑÁöÑÊ®°Á≥äÊÄß‰∏¶Ë±êÂØåÁü•Ë≠òË°®Á§∫„ÄÇÊ®ôÊ∫ñÂü∫Ê∫ñ‰∏äÁöÑÂª£Ê≥õÂØ¶È©óÂ±ïÁ§∫‰∫ÜÊàëÂÄëÊñπÊ≥ïÁöÑÊïàÁéáÂíåÊúâÊïàÊÄß„ÄÇÊàëÂÄëÂú®Â§öÊï∏Ë≥áÊñôÈõÜ‰∏äÂÑ™ÊñºÂÇ≥Áµ±ÁöÑ KGC ÊñπÊ≥ïÔºå‰∏¶ËàáÂæÆË™øÂæåÁöÑ LLM ÈÅîÂà∞Áõ∏ÂêåÁöÑÊïàËÉΩ„ÄÇÊ≠§Â§ñÔºåËàáÂæÆË™øÂæåÁöÑ LLM Áõ∏ÊØîÔºåÊàëÂÄëÂ∞á GPU Ë®òÊÜ∂È´îÊïàÁéáÊèêÂçá‰∫Ü **$188\times$**Ôºå‰∏¶Â∞áË®ìÁ∑¥ + Êé®Ë´ñÈÄüÂ∫¶ÊèêÂçá‰∫Ü **$13.48\times$**„ÄÇ

##### **Computation-friendly Graph Neural Network Design by Accumulating Knowledge on Large Language Models**
2408.06717v1 by Jialiang Wang, Shimin Di, Hanmo Liu, Zhili Wang, Jiachuan Wang, Lei Chen, Xiaofang Zhou

Graph Neural Networks (GNNs), like other neural networks, have shown
remarkable success but are hampered by the complexity of their architecture
designs, which heavily depend on specific data and tasks. Traditionally,
designing proper architectures involves trial and error, which requires
intensive manual effort to optimize various components. To reduce human
workload, researchers try to develop automated algorithms to design GNNs.
However, both experts and automated algorithms suffer from two major issues in
designing GNNs: 1) the substantial computational resources expended in
repeatedly trying candidate GNN architectures until a feasible design is
achieved, and 2) the intricate and prolonged processes required for humans or
algorithms to accumulate knowledge of the interrelationship between graphs,
GNNs, and performance.
  To further enhance the automation of GNN architecture design, we propose a
computation-friendly way to empower Large Language Models (LLMs) with
specialized knowledge in designing GNNs, thereby drastically shortening the
computational overhead and development cycle of designing GNN architectures.
Our framework begins by establishing a knowledge retrieval pipeline that
comprehends the intercorrelations between graphs, GNNs, and performance. This
pipeline converts past model design experiences into structured knowledge for
LLM reference, allowing it to quickly suggest initial model proposals.
Subsequently, we introduce a knowledge-driven search strategy that emulates the
exploration-exploitation process of human experts, enabling quick refinement of
initial proposals within a promising scope. Extensive experiments demonstrate
that our framework can efficiently deliver promising (e.g., Top-5.77%) initial
model proposals for unseen datasets within seconds and without any prior
training and achieve outstanding search performance in a few iterations.

ÊëòË¶ÅÔºöÂúñÂΩ¢Á•ûÁ∂ìÁ∂≤Ë∑Ø (GNN) ËàáÂÖ∂‰ªñÁ•ûÁ∂ìÁ∂≤Ë∑Ø‰∏ÄÊ®£ÔºåÂ∑≤Â±ïÁèæÂá∫È°ØËëóÁöÑÊàêÂäüÔºå‰ΩÜÂÖ∂Êû∂ÊßãË®≠Ë®àÁöÑË§áÈõúÊÄßÂçªÈòªÁ§ô‰∫ÜÈÄ≤‰∏ÄÊ≠•ÁöÑÁôºÂ±ïÔºåËÄåÈÄôÁ®ÆË§áÈõúÊÄßÂú®ÂæàÂ§ßÁ®ãÂ∫¶‰∏äÂèñÊ±∫ÊñºÂÖ∑È´îÁöÑË≥áÊñôÂíå‰ªªÂãô„ÄÇÂÇ≥Áµ±‰∏äÔºåË®≠Ë®àÈÅ©Áï∂ÁöÑÊû∂ÊßãÈúÄË¶ÅÂèçË¶ÜÂòóË©¶ÔºåÈÄôÈúÄË¶ÅÂ§ßÈáèÁöÑ‰∫∫Â∑•Â∑•‰ΩúÊâçËÉΩÊúÄ‰Ω≥ÂåñÂêÑÁ®ÆÂÖÉ‰ª∂„ÄÇÁÇ∫‰∫ÜÊ∏õÂ∞ë‰∫∫ÂäõÁöÑË≤†ÊìîÔºåÁ†îÁ©∂‰∫∫Âì°ÂòóË©¶ÈñãÁôºËá™ÂãïÂåñÊºîÁÆóÊ≥ï‰æÜË®≠Ë®à GNN„ÄÇÁÑ∂ËÄåÔºåÂ∞àÂÆ∂ÂíåËá™ÂãïÂåñÊºîÁÆóÊ≥ïÂú®Ë®≠Ë®à GNN ÊôÇÈÉΩÊúÉÈÅáÂà∞ÂÖ©ÂÄã‰∏ªË¶ÅÂïèÈ°åÔºö1) Âú®ÂèçË¶ÜÂòóË©¶ÂÄôÈÅ∏ GNN Êû∂Êßã‰ª•ÈÅîÊàêÂèØË°åÁöÑË®≠Ë®à‰πãÂâçÔºåÊúÉËÄóË≤ªÂ§ßÈáèÁöÑÈÅãÁÆóË≥áÊ∫êÔºå‰ª•Âèä 2) ‰∫∫È°ûÊàñÊºîÁÆóÊ≥ïÈúÄË¶ÅËä±Ë≤ªÂ§ßÈáèË§áÈõúËÄåÊº´Èï∑ÁöÑÁ®ãÂ∫èÊâçËÉΩÁ¥ØÁ©çÊúâÈóúÂúñÂΩ¢„ÄÅGNN ÂíåÊïàËÉΩ‰πãÈñìÁõ∏‰∫íÈóú‰øÇÁöÑÁü•Ë≠ò„ÄÇ
ÁÇ∫‰∫ÜÈÄ≤‰∏ÄÊ≠•ÊèêÂçá GNN Êû∂ÊßãË®≠Ë®àÁöÑËá™ÂãïÂåñÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÈÅãÁÆóÂèãÂñÑÁöÑÊñπÂºèÔºåËÆìÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂÖ∑ÂÇôË®≠Ë®à GNN ÁöÑÂ∞àÊ•≠Áü•Ë≠òÔºåÂæûËÄåÂ§ßÂπÖÁ∏ÆÁü≠Ë®≠Ë®à GNN Êû∂ÊßãÁöÑÈÅãÁÆóË≤†ÊìîÂíåÈñãÁôºÈÄ±Êúü„ÄÇÊàëÂÄëÁöÑÊû∂ÊßãÈ¶ñÂÖàÂª∫Á´ã‰∏ÄÂÄãÁü•Ë≠òÊì∑ÂèñÁÆ°ÈÅìÔºå‰∫ÜËß£ÂúñÂΩ¢„ÄÅGNN ÂíåÊïàËÉΩ‰πãÈñìÁöÑÁõ∏‰∫íÈóúËÅØÊÄß„ÄÇÈÄôÂÄãÁÆ°ÈÅìÂ∞áÈÅéÂéªÁöÑÊ®°ÂûãË®≠Ë®àÁ∂ìÈ©óËΩâÊèõÊàêÁµêÊßãÂåñÁöÑÁü•Ë≠òÔºå‰æõ LLM ÂèÉËÄÉÔºåËÆì LLM ËÉΩÂ§†Âø´ÈÄüÊèêÂá∫ÂàùÊ≠•ÁöÑÊ®°ÂûãÂª∫Ë≠∞„ÄÇÈö®ÂæåÔºåÊàëÂÄëÂºïÂÖ•‰∏ÄÁ®ÆÁü•Ë≠òÈ©ÖÂãïÁöÑÊêúÂ∞ãÁ≠ñÁï•ÔºåÊ®°Êì¨‰∫∫È°ûÂ∞àÂÆ∂ÁöÑÊé¢Á¥¢ËàáÈñãÁôºÁ®ãÂ∫èÔºåËÆì LLM ËÉΩÂú®ÊúâÂ∏åÊúõÁöÑÁØÑÂúçÂÖßÂø´ÈÄüÊîπÂñÑÂàùÊ≠•Âª∫Ë≠∞„ÄÇÂª£Ê≥õÁöÑÂØ¶È©óË≠âÊòéÔºåÊàëÂÄëÁöÑÊû∂ÊßãÂèØ‰ª•Âú®ÂπæÁßíÈêòÂÖßÊúâÊïàÂú∞ÈáùÂ∞çÊú™Ë¶ãÈÅéÁöÑË≥áÊñôÈõÜÊèê‰æõÊúâÂ∏åÊúõÁöÑ (‰æãÂ¶ÇÔºåÂâç 5.77%) ÂàùÊ≠•Ê®°ÂûãÂª∫Ë≠∞ÔºåËÄå‰∏îÁÑ°ÈúÄ‰ªª‰ΩïÂÖàÂâçÁöÑË®ìÁ∑¥Ôºå‰∏¶Âú®ÂπæÊ¨°ÂèçË¶ÜÈÅãÁÆó‰∏≠Â∞±ËÉΩÈÅîÊàêÂÇëÂá∫ÁöÑÊêúÂ∞ãÊïàËÉΩ„ÄÇ

##### **Body Transformer: Leveraging Robot Embodiment for Policy Learning**
2408.06316v1 by Carmelo Sferrazza, Dun-Ming Huang, Fangchen Liu, Jongmin Lee, Pieter Abbeel

In recent years, the transformer architecture has become the de facto
standard for machine learning algorithms applied to natural language processing
and computer vision. Despite notable evidence of successful deployment of this
architecture in the context of robot learning, we claim that vanilla
transformers do not fully exploit the structure of the robot learning problem.
Therefore, we propose Body Transformer (BoT), an architecture that leverages
the robot embodiment by providing an inductive bias that guides the learning
process. We represent the robot body as a graph of sensors and actuators, and
rely on masked attention to pool information throughout the architecture. The
resulting architecture outperforms the vanilla transformer, as well as the
classical multilayer perceptron, in terms of task completion, scaling
properties, and computational efficiency when representing either imitation or
reinforcement learning policies. Additional material including the open-source
code is available at https://sferrazza.cc/bot_site.

ÊëòË¶ÅÔºöËøëÂπ¥Êù•ÔºåÂèòÂéãÂô®Êû∂ÊûÑÂ∑≤Êàê‰∏∫Â∫îÁî®‰∫éËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÂíåËÆ°ÁÆóÊú∫ËßÜËßâÁöÑÊú∫Âô®Â≠¶‰π†ÁÆóÊ≥ïÁöÑÂÆûÈôÖÊ†áÂáÜ„ÄÇÂ∞ΩÁÆ°ÊúâÊòæÁùÄËØÅÊçÆË°®ÊòéÂú®Êú∫Âô®‰∫∫Â≠¶‰π†ÁöÑËÉåÊôØ‰∏ãÊàêÂäüÈÉ®ÁΩ≤‰∫ÜÊ≠§Êû∂ÊûÑÔºå‰ΩÜÊàë‰ª¨Â£∞Áß∞ÂéüÂßãÂèòÂéãÂô®Âπ∂Êú™ÂÖÖÂàÜÂà©Áî®Êú∫Âô®‰∫∫Â≠¶‰π†ÈóÆÈ¢òÁöÑÁªìÊûÑ„ÄÇÂõ†Ê≠§ÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü Body Transformer (BoT)Ôºå‰∏ÄÁßçÈÄöËøáÊèê‰æõÊåáÂØºÂ≠¶‰π†ËøáÁ®ãÁöÑÂΩíÁ∫≥ÂÅèÂ∑ÆÊù•Âà©Áî®Êú∫Âô®‰∫∫‰ΩìÁé∞ÁöÑÊû∂ÊûÑ„ÄÇÊàë‰ª¨Â∞ÜÊú∫Âô®‰∫∫‰∏ª‰ΩìË°®Á§∫‰∏∫‰º†ÊÑüÂô®ÂíåÊâßË°åÂô®ÁöÑÂõæÂΩ¢ÔºåÂπ∂‰æùÈù†Êé©Á†ÅÊ≥®ÊÑèÂäõÊù•Ê±áÈõÜÊï¥‰∏™Êû∂ÊûÑ‰∏≠ÁöÑ‰ø°ÊÅØ„ÄÇÂú®ÂÆåÊàê‰ªªÂä°„ÄÅÁº©ÊîæÂ±ûÊÄßÂíåËÆ°ÁÆóÊïàÁéáÊñπÈù¢ÔºåÊó†ËÆ∫ÊòØË°®Á§∫Ê®°‰ªøËøòÊòØÂº∫ÂåñÂ≠¶‰π†Á≠ñÁï•ÔºåÁî±Ê≠§‰∫ßÁîüÁöÑÊû∂ÊûÑÈÉΩ‰ºò‰∫éÂéüÂßãÂèòÂéãÂô®‰ª•ÂèäÁªèÂÖ∏ÁöÑÂ§öÂ±ÇÊÑüÁü•Âô®„ÄÇÂåÖÊã¨ÂºÄÊ∫ê‰ª£Á†ÅÂú®ÂÜÖÁöÑÂÖ∂‰ªñÊùêÊñôÂèØ‰ªé https://sferrazza.cc/bot_site Ëé∑Âæó„ÄÇ

##### **ARPA: A Novel Hybrid Model for Advancing Visual Word Disambiguation Using Large Language Models and Transformers**
2408.06040v1 by Aristi Papastavrou, Maria Lymperaiou, Giorgos Stamou

In the rapidly evolving fields of natural language processing and computer
vision, Visual Word Sense Disambiguation (VWSD) stands as a critical, yet
challenging task. The quest for models that can seamlessly integrate and
interpret multimodal data is more pressing than ever. Imagine a system that can
understand language with the depth and nuance of human cognition, while
simultaneously interpreting the rich visual context of the world around it.
  We present ARPA, an architecture that fuses the unparalleled contextual
understanding of large language models with the advanced feature extraction
capabilities of transformers, which then pass through a custom Graph Neural
Network (GNN) layer to learn intricate relationships and subtle nuances within
the data. This innovative architecture not only sets a new benchmark in visual
word disambiguation but also introduces a versatile framework poised to
transform how linguistic and visual data interact by harnessing the synergistic
strengths of its components, ensuring robust performance even in the most
complex disambiguation scenarios. Through a series of experiments and
comparative analysis, we reveal the substantial advantages of our model,
underscoring its potential to redefine standards in the field. Beyond its
architectural prowess, our architecture excels through experimental
enrichments, including sophisticated data augmentation and multi-modal training
techniques.
  ARPA's introduction marks a significant milestone in visual word
disambiguation, offering a compelling solution that bridges the gap between
linguistic and visual modalities. We invite researchers and practitioners to
explore the capabilities of our model, envisioning a future where such hybrid
models drive unprecedented advancements in artificial intelligence.

ÊëòË¶ÅÔºöÂú®Ëá™ÁÑ∂Ë™ûË®ÄËôïÁêÜÂíåÈõªËÖ¶Ë¶ñË¶∫Âø´ÈÄüÊºîÈÄ≤ÁöÑÈ†òÂüü‰∏≠ÔºåË¶ñË¶∫Ë©ûÂΩôÊ∂àÊ≠ß (VWSD) ÊòØ‰∏ÄÂÄãÈóúÈçµ‰∏îÂÖ∑ÊúâÊåëÊà∞ÊÄßÁöÑ‰ªªÂãô„ÄÇÂ∞ãÊâæËÉΩÂ§†ÁÑ°Á∏´Êï¥ÂêàÂíåË©ÆÈáãÂ§öÊ®°ÊÖãË≥áÊñôÁöÑÊ®°ÂûãÊØî‰ª•ÂæÄ‰ªª‰ΩïÊôÇÂÄôÈÉΩÊõ¥Âä†Ëø´Âàá„ÄÇÊÉ≥ÂÉè‰∏ÄÂÄãÁ≥ªÁµ±ÔºåÂÆÉÂèØ‰ª•ÂÉè‰∫∫È°ûË™çÁü•‰∏ÄÊ®£Ê∑±ÂÖ•‰∏îÁ¥∞Á∑ªÂú∞ÁêÜËß£Ë™ûË®ÄÔºåÂêåÊôÇÈÇÑËÉΩË©ÆÈáãÂë®Âúç‰∏ñÁïåÁöÑË±êÂØåË¶ñË¶∫ËÑàÁµ°„ÄÇ
ÊàëÂÄëÊèêÂá∫ ARPAÔºå‰∏ÄÁ®ÆÊû∂ÊßãÔºåÂÆÉËûçÂêà‰∫ÜÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÁÑ°ËàáÂÄ´ÊØîÁöÑËÑàÁµ°ÁêÜËß£ËÉΩÂäõÂíå Transformer ÁöÑÈÄ≤ÈöéÁâπÂæµËêÉÂèñËÉΩÂäõÔºåÁÑ∂ÂæåÈÄöÈÅé‰∏ÄÂÄãËá™Ë®ÇÂúñÂΩ¢Á•ûÁ∂ìÁ∂≤Ë∑Ø (GNN) Â±§‰æÜÂ≠∏ÁøíË≥áÊñô‰∏≠ÁöÑË§áÈõúÈóú‰øÇÂíåÁ¥∞ÂæÆÂ∑ÆÁï∞„ÄÇÈÄôÁ®ÆÂâµÊñ∞ÁöÑÊû∂Êßã‰∏çÂÉÖÂú®Ë¶ñË¶∫Ë©ûÂΩôÊ∂àÊ≠ß‰∏≠Ë®≠ÂÆö‰∫ÜÊñ∞ÁöÑÂü∫Ê∫ñÔºåÈÇÑÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÂ§öÂäüËÉΩÁöÑÊ°ÜÊû∂ÔºåÊ∫ñÂÇôÈÄöÈÅéÂà©Áî®ÂÖ∂ÁµÑÊàêÈÉ®ÂàÜÁöÑÂçîÂêåÂÑ™Âã¢‰æÜËΩâËÆäË™ûË®ÄÂíåË¶ñË¶∫Ë≥áÊñôÁöÑ‰∫íÂãïÊñπÂºèÔºåÁ¢∫‰øùÂç≥‰ΩøÂú®ÊúÄË§áÈõúÁöÑÊ∂àÊ≠ßÂ†¥ÊôØ‰∏≠‰πüËÉΩÊúâÂº∑ÂÅ•ÁöÑÊïàËÉΩ„ÄÇÈÄèÈÅé‰∏ÄÁ≥ªÂàóÁöÑÂØ¶È©óÂíåÊØîËºÉÂàÜÊûêÔºåÊàëÂÄëÊè≠Á§∫‰∫ÜÊàëÂÄëÊ®°ÂûãÁöÑÈ°ØËëóÂÑ™Âã¢ÔºåÂº∑Ë™ø‰∫ÜÂÆÉÂú®ÈáçÊñ∞ÂÆöÁæ©Ë©≤È†òÂüüÊ®ôÊ∫ñÁöÑÊΩõÂäõ„ÄÇÈô§‰∫ÜÂÖ∂Êû∂ÊßãÂÑ™Âã¢‰πãÂ§ñÔºåÊàëÂÄëÁöÑÊû∂ÊßãÈÇÑÈÄöÈÅéÂØ¶È©óË±êÂØåÂåñËÄåË°®ÁèæÂá∫Ëâ≤ÔºåÂåÖÊã¨Á≤æÂØÜÁöÑË≥áÊñôÊì¥ÂÖÖÂíåÂ§öÊ®°ÊÖãË®ìÁ∑¥ÊäÄË°ì„ÄÇ
ARPA ÁöÑÊé®Âá∫Ê®ôË™åËëóË¶ñË¶∫Ë©ûÂΩôÊ∂àÊ≠ßÁöÑ‰∏ÄÂÄãÈáçË¶ÅÈáåÁ®ãÁ¢ëÔºåÊèê‰æõ‰∫Ü‰∏ÄÂÄãÂºï‰∫∫Ê≥®ÁõÆÁöÑËß£Ê±∫ÊñπÊ°àÔºåÂΩåÂêà‰∫ÜË™ûË®ÄÂíåË¶ñË¶∫Ê®°ÊÖã‰πãÈñìÁöÑÂ∑ÆË∑ù„ÄÇÊàëÂÄëÈÇÄË´ãÁ†îÁ©∂‰∫∫Âì°ÂíåÂæûÊ•≠‰∫∫Âì°Êé¢Á¥¢ÊàëÂÄëÊ®°ÂûãÁöÑËÉΩÂäõÔºåÂ±ïÊúõ‰∏ÄÂÄãÁî±ÈÄôÁ®ÆÊ∑∑ÂêàÊ®°ÂûãÊé®Âãï‰∫∫Â∑•Êô∫ÊÖßÂâçÊâÄÊú™ÊúâÁöÑÈÄ≤Ê≠•ÁöÑÊú™‰æÜ„ÄÇ

##### **ConvKGYarn: Spinning Configurable and Scalable Conversational Knowledge Graph QA datasets with Large Language Models**
2408.05948v1 by Ronak Pradeep, Daniel Lee, Ali Mousavi, Jeff Pound, Yisi Sang, Jimmy Lin, Ihab Ilyas, Saloni Potdar, Mostafa Arefiyan, Yunyao Li

The rapid advancement of Large Language Models (LLMs) and conversational
assistants necessitates dynamic, scalable, and configurable conversational
datasets for training and evaluation. These datasets must accommodate diverse
user interaction modes, including text and voice, each presenting unique
modeling challenges. Knowledge Graphs (KGs), with their structured and evolving
nature, offer an ideal foundation for current and precise knowledge. Although
human-curated KG-based conversational datasets exist, they struggle to keep
pace with the rapidly changing user information needs. We present ConvKGYarn, a
scalable method for generating up-to-date and configurable conversational KGQA
datasets. Qualitative psychometric analyses confirm our method can generate
high-quality datasets rivaling a popular conversational KGQA dataset while
offering it at scale and covering a wide range of human-interaction
configurations. We showcase its utility by testing LLMs on diverse
conversations - exploring model behavior on conversational KGQA sets with
different configurations grounded in the same KG fact set. Our results
highlight the ability of ConvKGYarn to improve KGQA foundations and evaluate
parametric knowledge of LLMs, thus offering a robust solution to the constantly
evolving landscape of conversational assistants.

ÊëòË¶ÅÔºöÈö®ËëóÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂíåÂ∞çË©±ÂºèÂä©ÁêÜÁöÑÂø´ÈÄüÈÄ≤Ê≠•ÔºåÈúÄË¶ÅÂãïÊÖã„ÄÅÂèØÊì¥ÂÖÖ‰∏îÂèØË®≠ÂÆöÁöÑÂ∞çË©±ÂºèË≥áÊñôÈõÜ‰æÜÈÄ≤Ë°åË®ìÁ∑¥ÂíåË©ï‰º∞„ÄÇÈÄô‰∫õË≥áÊñôÈõÜÂøÖÈ†àÂÆπÁ¥ç‰∏çÂêåÁöÑ‰ΩøÁî®ËÄÖ‰∫íÂãïÊ®°ÂºèÔºåÂåÖÊã¨ÊñáÂ≠óÂíåË™ûÈü≥ÔºåÊØèÁ®ÆÊ®°ÂºèÈÉΩÂëàÁèæÁç®ÁâπÁöÑÂª∫Ê®°ÊåëÊà∞„ÄÇÁü•Ë≠òÂúñË≠ú (KG) ÂÖ∑ÊúâÁµêÊßãÂåñ‰∏î‰∏çÊñ∑ÊºîÈÄ≤ÁöÑÁâπÊÄßÔºåÁÇ∫Áï∂ÂâçÂíåÁ≤æÁ¢∫ÁöÑÁü•Ë≠òÊèê‰æõ‰∫ÜÁêÜÊÉ≥ÁöÑÂü∫Á§é„ÄÇÂÑòÁÆ°Â≠òÂú®‰∫∫Â∑•Á≠ñÂ±ïÁöÑÂü∫ÊñºÁü•Ë≠òÂúñË≠úÁöÑÂ∞çË©±ÂºèË≥áÊñôÈõÜÔºå‰ΩÜÂÆÉÂÄëÈõ£‰ª•Ë∑ü‰∏äÂø´ÈÄüËÆäÂåñÁöÑ‰ΩøÁî®ËÄÖË≥áË®äÈúÄÊ±Ç„ÄÇÊàëÂÄëÊèêÂá∫ ConvKGYarnÔºåÈÄôÊòØ‰∏ÄÁ®ÆÂèØÊì¥ÂÖÖÁöÑÊñπÊ≥ïÔºåÁî®ÊñºÁî¢ÁîüÊúÄÊñ∞ÁöÑ‰∏îÂèØË®≠ÂÆöÁöÑÂ∞çË©±Âºè KGQA Ë≥áÊñôÈõÜ„ÄÇÂÆöÊÄßÁöÑÂøÉÁêÜÊ∏¨ÈáèÂàÜÊûêË≠âÂØ¶ÔºåÊàëÂÄëÁöÑÊ®°ÂûãÂèØ‰ª•Áî¢ÁîüËàáÊµÅË°åÁöÑÂ∞çË©±Âºè KGQA Ë≥áÊñôÈõÜÁõ∏Â™≤ÁæéÁöÑÂÑ™Ë≥™Ë≥áÊñôÈõÜÔºåÂêåÊôÇÂ§ßË¶èÊ®°Êèê‰æõË≥áÊñôÈõÜÔºå‰∏¶Ê∂µËìãÂª£Ê≥õÁöÑ‰∫∫Ê©ü‰∫íÂãïË®≠ÂÆö„ÄÇÊàëÂÄëÈÄèÈÅéÂú®‰∏çÂêåÁöÑÂ∞çË©±‰∏≠Ê∏¨Ë©¶ LLM ‰æÜÂ±ïÁ§∫ÂÖ∂ÊïàÁî®ÔºåÊé¢Á¥¢Ê®°ÂûãÂú®Â∞çË©±Âºè KGQA Ë®≠ÂÆö‰∏äÁöÑË°åÁÇ∫ÔºåÈÄô‰∫õË®≠ÂÆöÂü∫ÊñºÁõ∏ÂêåÁöÑÁü•Ë≠òÂúñË≠ú‰∫ãÂØ¶ÈõÜ„ÄÇÊàëÂÄëÁöÑÁµêÊûúÁ™ÅÈ°Ø‰∫Ü ConvKGYarn ÊîπÂñÑ KGQA Âü∫Á§éÂíåË©ï‰º∞ LLM ÂèÉÊï∏ÂåñÁü•Ë≠òÁöÑËÉΩÂäõÔºåÂæûËÄåÁÇ∫‰∏çÊñ∑ÊºîÈÄ≤ÁöÑÂ∞çË©±ÂºèÂä©ÁêÜÈ†òÂüüÊèê‰æõ‰∫Ü‰∏ÄÂÄãÂº∑Â§ßÁöÑËß£Ê±∫ÊñπÊ°à„ÄÇ

##### **The Cognitive Revolution in Interpretability: From Explaining Behavior to Interpreting Representations and Algorithms**
2408.05859v1 by Adam Davies, Ashkan Khakzar

Artificial neural networks have long been understood as "black boxes": though
we know their computation graphs and learned parameters, the knowledge encoded
by these weights and functions they perform are not inherently interpretable.
As such, from the early days of deep learning, there have been efforts to
explain these models' behavior and understand them internally; and recently,
mechanistic interpretability (MI) has emerged as a distinct research area
studying the features and implicit algorithms learned by foundation models such
as large language models. In this work, we aim to ground MI in the context of
cognitive science, which has long struggled with analogous questions in
studying and explaining the behavior of "black box" intelligent systems like
the human brain. We leverage several important ideas and developments in the
history of cognitive science to disentangle divergent objectives in MI and
indicate a clear path forward. First, we argue that current methods are ripe to
facilitate a transition in deep learning interpretation echoing the "cognitive
revolution" in 20th-century psychology that shifted the study of human
psychology from pure behaviorism toward mental representations and processing.
Second, we propose a taxonomy mirroring key parallels in computational
neuroscience to describe two broad categories of MI research, semantic
interpretation (what latent representations are learned and used) and
algorithmic interpretation (what operations are performed over representations)
to elucidate their divergent goals and objects of study. Finally, we elaborate
the parallels and distinctions between various approaches in both categories,
analyze the respective strengths and weaknesses of representative works,
clarify underlying assumptions, outline key challenges, and discuss the
possibility of unifying these modes of interpretation under a common framework.

ÊëòË¶ÅÔºö‰∫∫Â∑•Á•ûÁ∂ìÁ∂≤Ë∑ØÈï∑Êúü‰ª•‰æÜÈÉΩË¢´Ë¶ñÁÇ∫„ÄåÈªëÁõíÂ≠ê„ÄçÔºöÂÑòÁÆ°ÊàëÂÄëÁü•ÈÅìÂÆÉÂÄëÁöÑÈÅãÁÆóÂúñË°®ÂíåÂ≠∏ÁøíÂèÉÊï∏Ôºå‰ΩÜÈÄô‰∫õÊ¨äÈáçÂíåÂÆÉÂÄëÂü∑Ë°åÁöÑÂáΩÊï∏ÊâÄÁ∑®Á¢ºÁöÑÁü•Ë≠ò‰∏¶ÈùûÂ§©ÁîüÂ∞±ÂèØËß£Èáã„ÄÇÂõ†Ê≠§ÔºåÂæûÊ∑±Â∫¶Â≠∏ÁøíÁöÑÊó©ÊúüÈñãÂßãÔºåÂ∞±ÊúâË®±Â§ö‰∫∫Ëá¥ÂäõÊñºËß£ÈáãÈÄô‰∫õÊ®°ÂûãÁöÑË°åÁÇ∫‰∏¶Âú®ÂÖßÈÉ®ÁêÜËß£ÂÆÉÂÄëÔºõÊúÄËøëÔºåÊ©üÂà∂ÂèØËß£ÈáãÊÄß (MI) Â∑≤ÊàêÁÇ∫‰∏ÄÂÄãÁç®ÁâπÁöÑÁöÑÁ†îÁ©∂È†òÂüüÔºåÊé¢Ë®éÂü∫Á§éÊ®°ÂûãÔºà‰æãÂ¶ÇÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºâÂ≠∏ÁøíÂà∞ÁöÑÁâπÂæµÂíåÈö±ÂºèÊºîÁÆóÊ≥ï„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊó®Âú®Â∞á MI Âü∫ÊñºË™çÁü•ÁßëÂ≠∏ÁöÑËÉåÊôØÔºåË™çÁü•ÁßëÂ≠∏Èï∑Êúü‰ª•‰æÜ‰∏ÄÁõ¥Âú®Á†îÁ©∂ÂíåËß£Èáã„ÄåÈªëÁõíÂ≠ê„ÄçÊô∫ËÉΩÁ≥ªÁµ±Ôºà‰æãÂ¶Ç‰∫∫ËÖ¶ÔºâÁöÑË°åÁÇ∫ÊôÇÔºåÂä™ÂäõËß£Ê±∫È°û‰ººÁöÑÂïèÈ°å„ÄÇÊàëÂÄëÂà©Áî®Ë™çÁü•ÁßëÂ≠∏Âè≤‰∏äÂπæÂÄãÈáçË¶ÅÁöÑÊÉ≥Ê≥ïÂíåÁôºÂ±ïÔºå‰æÜËß£Èñã MI ‰∏≠‰∏çÂêåÁöÑÁõÆÊ®ôÔºå‰∏¶ÊåáÂá∫ÊòéÁ¢∫ÁöÑÂâçÈÄ≤ÈÅìË∑Ø„ÄÇÈ¶ñÂÖàÔºåÊàëÂÄëË™çÁÇ∫Áï∂ÂâçÁöÑÂêÑÁ®ÆÊñπÊ≥ïÂ∑≤Ê∫ñÂÇôÂ•Ω‰øÉÈÄ≤Ê∑±Â∫¶Â≠∏ÁøíËß£ÈáãÁöÑËΩâËÆäÔºåÈÄôÂëºÊáâ‰∫Ü 20 ‰∏ñÁ¥ÄÂøÉÁêÜÂ≠∏‰∏≠ÁöÑ„ÄåË™çÁü•Èù©ÂëΩ„ÄçÔºåÂ∞á‰∫∫È°ûÂøÉÁêÜÂ≠∏ÁöÑÁ†îÁ©∂ÂæûÁ¥îÁ≤πÁöÑË°åÁÇ∫‰∏ªÁæ©ËΩâÂêëÂøÉÊô∫Ë°®ÂæµÂíåËôïÁêÜ„ÄÇÂÖ∂Ê¨°ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÂàÜÈ°ûÊ≥ïÔºåÂèçÊò†Ë®àÁÆóÁ•ûÁ∂ìÁßëÂ≠∏‰∏≠ÁöÑÈóúÈçµÁõ∏‰ºº‰πãËôïÔºå‰ª•ÊèèËø∞ MI Á†îÁ©∂ÁöÑÂÖ©ÂÄãÂª£Ê≥õÈ°ûÂà•ÔºåË™ûÁæ©Ëß£ÈáãÔºàÂ≠∏ÁøíÂíå‰ΩøÁî®ÁöÑÊΩõÂú®Ë°®ÂæµÊòØ‰ªÄÈ∫ºÔºâÂíåÊºîÁÆóÊ≥ïËß£ÈáãÔºàÂú®Ë°®Âæµ‰∏äÂü∑Ë°åÁöÑÈÅãÁÆóÊòØ‰ªÄÈ∫ºÔºâÔºå‰ª•Èó°ÊòéÂÆÉÂÄë‰∏çÂêåÁöÑÁõÆÊ®ôÂíåÁ†îÁ©∂Â∞çË±°„ÄÇÊúÄÂæåÔºåÊàëÂÄëÈó°Ëø∞‰∫ÜÈÄôÂÖ©ÂÄãÈ°ûÂà•‰∏≠ÂêÑÁ®ÆÊñπÊ≥ï‰πãÈñìÁöÑÁõ∏‰ºº‰πãËôïÂíåÂçÄÂà•ÔºåÂàÜÊûê‰ª£Ë°®ÊÄß‰ΩúÂìÅÁöÑÂÑ™Áº∫ÈªûÔºåÈáêÊ∏ÖÂü∫Êú¨ÂÅáË®≠ÔºåÊ¶ÇËø∞ÈóúÈçµÊåëÊà∞Ôºå‰∏¶Ë®éË´ñÂú®‰∏ÄÂÄãÂÖ±ÂêåÊû∂Êßã‰∏ãÁµ±‰∏ÄÈÄô‰∫õËß£ÈáãÊ®°ÂºèÁöÑÂèØËÉΩÊÄß„ÄÇ

##### **Investigating Instruction Tuning Large Language Models on Graphs**
2408.05457v1 by Kerui Zhu, Bo-Wei Huang, Bowen Jin, Yizhu Jiao, Ming Zhong, Kevin Chang, Shou-De Lin, Jiawei Han

Inspired by the recent advancements of Large Language Models (LLMs) in NLP
tasks, there's growing interest in applying LLMs to graph-related tasks. This
study delves into the capabilities of instruction-following LLMs for engaging
with real-world graphs, aiming to offer empirical insights into how LLMs can
effectively interact with graphs and generalize across graph tasks. We begin by
constructing a dataset designed for instruction tuning, which comprises a
diverse collection of 79 graph-related tasks from academic and e-commerce
domains, featuring 44,240 training instances and 18,960 test samples. Utilizing
this benchmark, our initial investigation focuses on identifying the optimal
graph representation that serves as a conduit for LLMs to understand complex
graph structures. Our findings indicate that JSON format for graph
representation consistently outperforms natural language and code formats
across various LLMs and graph types. Furthermore, we examine the key factors
that influence the generalization abilities of instruction-tuned LLMs by
evaluating their performance on both in-domain and out-of-domain graph tasks.

ÊëòË¶ÅÔºöÂèóÂà∞Ëá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ (NLP) ‰∏≠Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ËøëÊúüÈÄ≤Â±ïÁöÑÂïüÁôºÔºåÂ∞á LLM ÊáâÁî®ÊñºËàáÂúñË°®Áõ∏Èóú‰ªªÂãôÁöÑËààË∂£Êó•ÁõäÊøÉÂéö„ÄÇÊú¨Á†îÁ©∂Êé¢Ë®é‰∫ÜÈÅµÂæ™Êåá‰ª§ÁöÑ LLM ÁöÑÂäüËÉΩÔºå‰ª•Âæû‰∫ãÁúüÂØ¶‰∏ñÁïåÁöÑÂúñË°®ÔºåÊó®Âú®Êèê‰æõ LLM Â¶Ç‰ΩïÊúâÊïàÂú∞ËàáÂúñË°®‰∫íÂãï‰∏¶Âú®ÂúñË°®‰ªªÂãô‰∏≠ÈÄ≤Ë°åÊ¶ÇÊã¨ÁöÑÁ∂ìÈ©óË¶ãËß£„ÄÇÊàëÂÄëÂæûÊßãÂª∫‰∏ÄÂÄãÂ∞àÁÇ∫Êåá‰ª§Ë™øÊï¥ËÄåË®≠Ë®àÁöÑË≥áÊñôÈõÜÈñãÂßãÔºåÂÖ∂‰∏≠ÂåÖÂê´‰æÜËá™Â≠∏Ë°ìÂíåÈõªÂ≠êÂïÜÂãôÈ†òÂüüÁöÑ 79 ÂÄãÂúñË°®Áõ∏Èóú‰ªªÂãôÁöÑÂ§öÂÖÉÂåñÈõÜÂêàÔºåÂåÖÂê´ 44,240 ÂÄãË®ìÁ∑¥ÂØ¶‰æãÂíå 18,960 ÂÄãÊ∏¨Ë©¶Ê®£Êú¨„ÄÇÂà©Áî®Ê≠§Âü∫Ê∫ñÔºåÊàëÂÄëÁöÑÂàùÊ≠•Ë™øÊü•ÈáçÈªûÂú®ÊñºË≠òÂà•ÊúÄ‰Ω≥ÂúñË°®Ë°®Á§∫Ôºå‰ΩúÁÇ∫ LLM ÁêÜËß£Ë§áÈõúÂúñË°®ÁµêÊßãÁöÑÁÆ°ÈÅì„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúË°®ÊòéÔºåJSON Ê†ºÂºèÁöÑÂúñË°®Ë°®Á§∫Âú®ÂêÑÁ®Æ LLM ÂíåÂúñË°®È°ûÂûã‰∏≠ÂßãÁµÇÂÑ™ÊñºËá™ÁÑ∂Ë™ûË®ÄÂíåÁ®ãÂºèÁ¢ºÊ†ºÂºè„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊé¢Ë®é‰∫ÜÂΩ±ÈüøÊåá‰ª§Ë™øÊï¥ LLM Ê¶ÇÊã¨ËÉΩÂäõÁöÑ‰∏ªË¶ÅÂõ†Á¥†ÔºåÊñπÊ≥ïÊòØË©ï‰º∞ÂÆÉÂÄëÂú®È†òÂüüÂÖßÂíåÈ†òÂüüÂ§ñÂúñË°®‰ªªÂãô‰∏äÁöÑË°®Áèæ„ÄÇ

##### **Path-LLM: A Shortest-Path-based LLM Learning for Unified Graph Representation**
2408.05456v1 by Wenbo Shang, Xuliang Zhu, Xin Huang

Unified graph representation learning aims to produce node embeddings, which
can be applied to multiple downstream applications. However, existing studies
based on graph neural networks and language models either suffer from the
limitations of numerous training needed toward specific downstream predictions
or have shallow semantic features. In this work, we propose a novel Path-LLM
model to learn unified graph representation, which leverages a powerful large
language model (LLM) to incorporate our proposed path features. Our Path-LLM
framework consists of several well-designed techniques. First, we develop a new
mechanism of long-to-short shortest path (L2SP) selection, which covers
essential connections between different dense groups. An in-depth comparison of
different path selection plans is offered to illustrate the strength of our
designed L2SP. Then, we design path textualization to obtain L2SP-based
training texts. Next, we feed the texts into a self-supervised LLM training
process to learn embeddings. Extensive experiments on benchmarks validate the
superiority of Path-LLM against the state-of-the-art WalkLM method on two
classical graph learning tasks (node classification and link prediction) and
one NP-hard graph query processing task (keyword search), meanwhile saving more
than 90% of training paths.

ÊëòË¶ÅÔºöÁµ±‰∏ÄÂúñÂΩ¢Ë°®ÂæµÂ≠∏ÁøíÊó®Âú®Áî¢ÁîüÁØÄÈªûÂµåÂÖ•ÔºåÂèØÁî®ÊñºÂ§öÂÄã‰∏ãÊ∏∏ÊáâÁî®Á®ãÂºè„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÁöÑÂü∫ÊñºÂúñÂΩ¢Á•ûÁ∂ìÁ∂≤Ë∑ØÂíåË™ûË®ÄÊ®°ÂûãÁöÑÁ†îÁ©∂Ôºå‰∏çÊòØÂõ†ÈúÄË¶ÅÈáùÂ∞çÁâπÂÆö‰∏ãÊ∏∏È†êÊ∏¨ËÄåÈÄ≤Ë°åÂ§ßÈáèË®ìÁ∑¥ËÄåÂèóÂà∞ÈôêÂà∂ÔºåÂ∞±ÊòØË™ûÊÑèÁâπÂæµÊ∑∫ËñÑ„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊñ∞Á©éÁöÑ Path-LLM Ê®°Âûã‰æÜÂ≠∏ÁøíÁµ±‰∏ÄÁöÑÂúñÂΩ¢Ë°®ÂæµÔºåÂÆÉÂà©Áî®Âº∑Â§ßÁöÑÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰æÜÁ¥çÂÖ•ÊàëÂÄëÊèêÂá∫ÁöÑË∑ØÂæëÁâπÂæµ„ÄÇÊàëÂÄëÁöÑ Path-LLM Ê°ÜÊû∂ÂåÖÂê´‰∫ÜÂ§öÈ†ÖË®≠Ë®àËâØÂ•ΩÁöÑÊäÄË°ì„ÄÇÈ¶ñÂÖàÔºåÊàëÂÄëÈñãÁôº‰∫Ü‰∏ÄÁ®ÆÊñ∞ÁöÑÈï∑Âà∞Áü≠ÊúÄÁü≠Ë∑ØÂæë (L2SP) ÈÅ∏ÊìáÊ©üÂà∂ÔºåÂÆÉÊ∂µËìã‰∫Ü‰∏çÂêåÂØÜÈõÜÁæ§ÁµÑ‰πãÈñìÁöÑÂøÖË¶ÅÈÄ£Êé•„ÄÇÊèê‰æõ‰∫Ü‰∏çÂêåË∑ØÂæëÈÅ∏ÊìáÊñπÊ°àÁöÑÊ∑±ÂÖ•ÊØîËºÉÔºå‰ª•Ë™™ÊòéÊàëÂÄëË®≠Ë®àÁöÑ L2SP ÁöÑÂÑ™Âã¢„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëË®≠Ë®àË∑ØÂæëÊñáÂ≠óÂåñ‰ª•Áç≤ÂæóÂü∫Êñº L2SP ÁöÑË®ìÁ∑¥ÊñáÊú¨„ÄÇÊé•‰∏ã‰æÜÔºåÊàëÂÄëÂ∞áÊñáÊú¨Ëº∏ÂÖ•Âà∞Ëá™Áõ£Áù£ LLM Ë®ìÁ∑¥ÈÅéÁ®ã‰∏≠‰ª•Â≠∏ÁøíÂµåÂÖ•„ÄÇÂú®Âü∫Ê∫ñ‰∏äÁöÑÂ§ßÈáèÂØ¶È©óÈ©óË≠â‰∫Ü Path-LLM Âú®ÂÖ©ÂÄãÁ∂ìÂÖ∏ÂúñÂΩ¢Â≠∏Áøí‰ªªÂãôÔºàÁØÄÈªûÂàÜÈ°ûÂíåÈÄ£ÁµêÈ†êÊ∏¨ÔºâÂíå‰∏ÄÂÄã NP Èõ£ÂúñÂΩ¢Êü•Ë©¢ËôïÁêÜ‰ªªÂãôÔºàÈóúÈçµÂ≠óÊêúÂ∞ãÔºâ‰∏äÂÑ™ÊñºÊúÄÂÖàÈÄ≤ÁöÑ WalkLM ÊñπÊ≥ïÔºåÂêåÊôÇÁØÄÁúÅ‰∫ÜË∂ÖÈÅé 90% ÁöÑË®ìÁ∑¥Ë∑ØÂæë„ÄÇ

##### **LaiDA: Linguistics-aware In-context Learning with Data Augmentation for Metaphor Components Identification**
2408.05404v1 by Hongde Liu, Chenyuan He, Feiyang Meng, Changyong Niu, Yuxiang Jia

Metaphor Components Identification (MCI) contributes to enhancing machine
understanding of metaphors, thereby advancing downstream natural language
processing tasks. However, the complexity, diversity, and dependency on context
and background knowledge pose significant challenges for MCI. Large language
models (LLMs) offer new avenues for accurate comprehension of complex natural
language texts due to their strong semantic analysis and extensive commonsense
knowledge. In this research, a new LLM-based framework is proposed, named
Linguistics-aware In-context Learning with Data Augmentation (LaiDA).
Specifically, ChatGPT and supervised fine-tuning are utilized to tailor a
high-quality dataset. LaiDA incorporates a simile dataset for pre-training. A
graph attention network encoder generates linguistically rich feature
representations to retrieve similar examples. Subsequently, LLM is fine-tuned
with prompts that integrate linguistically similar examples. LaiDA ranked 2nd
in Subtask 2 of NLPCC2024 Shared Task 9, demonstrating its effectiveness. Code
and data are available at https://github.com/WXLJZ/LaiDA.

ÊëòË¶ÅÔºöÈö±ÂñªÁµÑÊàêËæ®Ë≠ò (MCI) ÊúâÂä©ÊñºÊèêÂçáÊ©üÂô®Â∞çÈö±ÂñªÁöÑÁêÜËß£ÔºåÈÄ≤ËÄåÊé®Âãï‰∏ãÊ∏∏ÁöÑËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ‰ªªÂãô„ÄÇ‰∏çÈÅéÔºåË§áÈõúÊÄß„ÄÅÂ§öÊ®£ÊÄßÔºå‰ª•ÂèäÂ∞çËÑàÁµ°ÂíåËÉåÊôØÁü•Ë≠òÁöÑ‰æùË≥¥ÊÄßÔºåÂ∞ç MCI ËÄåË®ÄÊòØÈáçÂ§ßÁöÑÊåëÊà∞„ÄÇÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Áî±ÊñºÂÖ∂Âº∑Â§ßÁöÑË™ûÊÑèÂàÜÊûêÂíåÂª£Ê≥õÁöÑÂ∏∏Ë≠òÁü•Ë≠òÔºåÁÇ∫Ê∫ñÁ¢∫ÁêÜËß£Ë§áÈõúÁöÑËá™ÁÑ∂Ë™ûË®ÄÊñáÊú¨Êèê‰æõ‰∫ÜÊñ∞ÈÄîÂæë„ÄÇÊú¨Á†îÁ©∂ÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊñ∞ÁöÑÂü∫Êñº LLM ÁöÑÊû∂ÊßãÔºåÁ®±ÁÇ∫ÂÖ∑ÂÇôË≥áÊñôÊì¥ÂÖÖÂäüËÉΩÁöÑË™ûË®ÄÊÑüÁü•ÊÉÖÂ¢ÉÂ≠∏Áøí (LaiDA)„ÄÇÂÖ∑È´î‰æÜË™™ÔºåChatGPT ÂíåÁõ£Áù£ÂæÆË™øÁî®ÊñºË™øÊï¥‰∏ÄÂÄãÈ´òÂìÅË≥™ÁöÑË≥áÊñôÈõÜ„ÄÇLaiDA ÁµêÂêà‰∫Ü‰∏ÄÂÄãÊØîÂñªË≥áÊñôÈõÜÈÄ≤Ë°åÈ†êË®ìÁ∑¥„ÄÇ‰∏ÄÂÄãÂúñÂΩ¢Ê≥®ÊÑèÂäõÁ∂≤Ë∑ØÁ∑®Á¢ºÂô®Áî¢ÁîüË™ûË®ÄË±êÂØåÁöÑÁâπÂæµË°®Á§∫Ôºå‰ª•Êì∑ÂèñÈ°û‰ººÁöÑÁØÑ‰æã„ÄÇÈö®ÂæåÔºåLLM ‰ΩøÁî®Êï¥Âêà‰∫ÜË™ûË®ÄÁõ∏‰ººÁØÑ‰æãÁöÑÊèêÁ§∫ÈÄ≤Ë°åÂæÆË™ø„ÄÇLaiDA Âú® NLPCC2024 ÂÖ±‰∫´‰ªªÂãô 9 ÁöÑÂ≠ê‰ªªÂãô 2 ‰∏≠ÊéíÂêçÁ¨¨ 2ÔºåË≠âÊòé‰∫ÜÂÖ∂ÊúâÊïàÊÄß„ÄÇÁ®ãÂºèÁ¢ºÂíåË≥áÊñôÂèØÂú® https://github.com/WXLJZ/LaiDA ÂèñÂæó„ÄÇ

##### **SHIELD: LLM-Driven Schema Induction for Predictive Analytics in EV Battery Supply Chain Disruptions**
2408.05357v1 by Zhi-Qi Cheng, Yifei Dong, Aike Shi, Wei Liu, Yuzhi Hu, Jason O'Connor, Alexander Hauptmann, Kate Whitefoot

The electric vehicle (EV) battery supply chain's vulnerability to disruptions
necessitates advanced predictive analytics. We present SHIELD (Schema-based
Hierarchical Induction for EV supply chain Disruption), a system integrating
Large Language Models (LLMs) with domain expertise for EV battery supply chain
risk assessment. SHIELD combines: (1) LLM-driven schema learning to construct a
comprehensive knowledge library, (2) a disruption analysis system utilizing
fine-tuned language models for event extraction, multi-dimensional similarity
matching for schema matching, and Graph Convolutional Networks (GCNs) with
logical constraints for prediction, and (3) an interactive interface for
visualizing results and incorporating expert feedback to enhance
decision-making. Evaluated on 12,070 paragraphs from 365 sources (2022-2023),
SHIELD outperforms baseline GCNs and LLM+prompt methods (e.g., GPT-4o) in
disruption prediction. These results demonstrate SHIELD's effectiveness in
combining LLM capabilities with domain expertise for enhanced supply chain risk
assessment.

ÊëòË¶ÅÔºöÈõªÂãïËªä (EV) ÈõªÊ±†‰æõÊáâÈèàÂÆπÊòìÂèóÂà∞Âπ≤ÊìæÔºåÂõ†Ê≠§ÈúÄË¶ÅÈÄ≤ÈöéÁöÑÈ†êÊ∏¨ÂàÜÊûê„ÄÇÊàëÂÄëÊèêÂá∫ SHIELDÔºàÂü∫ÊñºÊû∂ÊßãÁöÑ EV ‰æõÊáâÈèà‰∏≠Êñ∑ÈöéÂ±§ÂºèÊ≠∏Á¥çÔºâÔºåÈÄôÊòØ‰∏ÄÂÄãÊï¥ÂêàÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Ëàá EV ÈõªÊ±†‰æõÊáâÈèàÈ¢®Èö™Ë©ï‰º∞È†òÂüüÂ∞àÊ•≠Áü•Ë≠òÁöÑÁ≥ªÁµ±„ÄÇSHIELD ÁµêÂêàÔºö(1) LLM È©ÖÂãïÁöÑÊû∂ÊßãÂ≠∏ÁøíÔºåÁî®ÊñºÂª∫ÁΩÆ‰∏ÄÂÄãÂÖ®Èù¢ÁöÑÁü•Ë≠òÂ∫´Ôºå(2) ‰∏ÄÂÄã‰∏≠Êñ∑ÂàÜÊûêÁ≥ªÁµ±ÔºåÂà©Áî®ÂæÆË™øË™ûË®ÄÊ®°ÂûãÈÄ≤Ë°å‰∫ã‰ª∂ËêÉÂèñ„ÄÅÂ§öÁ∂≠Â∫¶Áõ∏‰ººÊÄßÊØîÂ∞çÁî®ÊñºÊû∂ÊßãÊØîÂ∞çÔºå‰ª•ÂèäÂ∏∂ÊúâÈÇèËºØÁ¥ÑÊùüÁöÑÂúñÂΩ¢Âç∑Á©çÁ∂≤Ë∑Ø (GCN) Áî®ÊñºÈ†êÊ∏¨Ôºå‰ª•Âèä (3) ‰∏ÄÂÄã‰∫íÂãï‰ªãÈù¢ÔºåÁî®ÊñºË¶ñË¶∫ÂåñÁµêÊûúÂíåÁ¥çÂÖ•Â∞àÂÆ∂ÂõûÈ•ã‰ª•Â¢ûÂº∑Ê±∫Á≠ñÂà∂ÂÆö„ÄÇÂú®‰æÜËá™ 365 ÂÄã‰æÜÊ∫êÁöÑ 12,070 ÊÆµËêΩÔºà2022-2023 Âπ¥Ôºâ‰∏äÈÄ≤Ë°åË©ï‰º∞ÔºåSHIELD Âú®‰∏≠Êñ∑È†êÊ∏¨ÊñπÈù¢ÂÑ™ÊñºÂü∫Ê∫ñ GCN Âíå LLM+ÊèêÁ§∫ÊñπÊ≥ïÔºà‰æãÂ¶ÇÔºåGPT-4oÔºâ„ÄÇÈÄô‰∫õÁµêÊûúË≠âÊòé‰∫Ü SHIELD Âú®ÁµêÂêà LLM ÂäüËÉΩËàáÈ†òÂüüÂ∞àÊ•≠Áü•Ë≠ò‰ª•Â¢ûÂº∑‰æõÊáâÈèàÈ¢®Èö™Ë©ï‰º∞ÊñπÈù¢ÁöÑÊúâÊïàÊÄß„ÄÇ

##### **A Hybrid RAG System with Comprehensive Enhancement on Complex Reasoning**
2408.05141v1 by Ye Yuan, Chengwu Liu, Jingyang Yuan, Gongbo Sun, Siqi Li, Ming Zhang

Retrieval-augmented generation (RAG) is a framework enabling large language
models (LLMs) to enhance their accuracy and reduce hallucinations by
integrating external knowledge bases. In this paper, we introduce a hybrid RAG
system enhanced through a comprehensive suite of optimizations that
significantly improve retrieval quality, augment reasoning capabilities, and
refine numerical computation ability. We refined the text chunks and tables in
web pages, added attribute predictors to reduce hallucinations, conducted LLM
Knowledge Extractor and Knowledge Graph Extractor, and finally built a
reasoning strategy with all the references. We evaluated our system on the CRAG
dataset through the Meta CRAG KDD Cup 2024 Competition. Both the local and
online evaluations demonstrate that our system significantly enhances complex
reasoning capabilities. In local evaluations, we have significantly improved
accuracy and reduced error rates compared to the baseline model, achieving a
notable increase in scores. In the meanwhile, we have attained outstanding
results in online assessments, demonstrating the performance and generalization
capabilities of the proposed system. The source code for our system is released
in \url{https://gitlab.aicrowd.com/shizueyy/crag-new}.

ÊëòË¶ÅÔºöÊ™¢Á¥¢Â¢ûÂº∑ÁîüÊàê (RAG) ÊòØ‰∏ÄÂÄãÊû∂ÊßãÔºå‰ΩøÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ËÉΩÂ§†ÈÄèÈÅéÊï¥ÂêàÂ§ñÈÉ®Áü•Ë≠òÂ∫´‰æÜÂ¢ûÂº∑ÂÖ∂Ê∫ñÁ¢∫ÊÄß‰∏¶Ê∏õÂ∞ëÂπªË¶∫„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫Ü‰∏ÄÂÄãÊ∑∑Âêà RAG Á≥ªÁµ±ÔºåÈÄèÈÅéÂÖ®Èù¢ÁöÑÊúÄ‰Ω≥ÂåñÂ•ó‰ª∂ÈÄ≤Ë°åÂ¢ûÂº∑ÔºåÂèØÈ°ØËëóÊèêÂçáÊ™¢Á¥¢ÂìÅË≥™„ÄÅÂ¢ûÂº∑Êé®ÁêÜËÉΩÂäõÔºå‰∏¶ÊîπÂñÑÊï∏ÂÄºË®àÁÆóËÉΩÂäõ„ÄÇÊàëÂÄëÊîπÈÄ≤‰∫ÜÁ∂≤È†Å‰∏≠ÁöÑÊñáÂ≠óÂçÄÂ°äÂíåË°®Ê†ºÔºåÂä†ÂÖ•Â±¨ÊÄßÈ†êÊ∏¨Âô®‰ª•Ê∏õÂ∞ëÂπªË¶∫ÔºåÂü∑Ë°å LLM Áü•Ë≠òËêÉÂèñÂô®ÂíåÁü•Ë≠òÂúñË°®ËêÉÂèñÂô®ÔºåÊúÄÂæåÂª∫Êßã‰∫Ü‰∏ÄÂÄãÂåÖÂê´ÊâÄÊúâÂèÉËÄÉÁöÑÊé®ÁêÜÁ≠ñÁï•„ÄÇÊàëÂÄëÈÄèÈÅé Meta CRAG KDD Cup 2024 Á´∂Ë≥ΩÂú® CRAG Ë≥áÊñôÈõÜ‰∏äË©ï‰º∞ÊàëÂÄëÁöÑÁ≥ªÁµ±„ÄÇÂú®Âú∞Á´ØÂíåÁ∑ö‰∏äË©ï‰º∞ÈÉΩË≠âÊòéÊàëÂÄëÁöÑÁ≥ªÁµ±È°ØËëóÂ¢ûÂº∑‰∫ÜË§áÈõúÊé®ÁêÜËÉΩÂäõ„ÄÇÂú®Âú∞Á´ØË©ï‰º∞‰∏≠ÔºåÊàëÂÄëËàáÂü∫Ê∫ñÊ®°ÂûãÁõ∏ÊØîÔºåÈ°ØËëóÊèêÂçá‰∫ÜÊ∫ñÁ¢∫ÊÄß‰∏¶Èôç‰Ωé‰∫ÜÈåØË™§ÁéáÔºåÈÅîÂà∞‰∫ÜÈ°ØËëóÁöÑÂàÜÊï∏ÊèêÂçá„ÄÇÂêåÊôÇÔºåÊàëÂÄëÂú®Á∑ö‰∏äË©ï‰º∞‰∏≠ÂèñÂæó‰∫ÜÂÇëÂá∫ÁöÑÊàêÊûúÔºåË≠âÊòé‰∫ÜÊâÄÊèêÂá∫ÁöÑÁ≥ªÁµ±ÁöÑÊïàËÉΩÂíåÊ≥õÂåñËÉΩÂäõ„ÄÇÊàëÂÄëÁ≥ªÁµ±ÁöÑÂéüÂßãÁ¢ºÂ∑≤ÁôºÂ∏ÉÂú® \url{https://gitlab.aicrowd.com/shizueyy/crag-new}„ÄÇ

##### **Node Level Graph Autoencoder: Unified Pretraining for Textual Graph Learning**
2408.07091v1 by Wenbin Hu, Huihao Jing, Qi Hu, Haoran Li, Yangqiu Song

Textual graphs are ubiquitous in real-world applications, featuring rich text
information with complex relationships, which enables advanced research across
various fields. Textual graph representation learning aims to generate
low-dimensional feature embeddings from textual graphs that can improve the
performance of downstream tasks. A high-quality feature embedding should
effectively capture both the structural and the textual information in a
textual graph. However, most textual graph dataset benchmarks rely on word2vec
techniques to generate feature embeddings, which inherently limits their
capabilities. Recent works on textual graph representation learning can be
categorized into two folds: supervised and unsupervised methods. Supervised
methods finetune a language model on labeled nodes, which have limited
capabilities when labeled data is scarce. Unsupervised methods, on the other
hand, extract feature embeddings by developing complex training pipelines. To
address these limitations, we propose a novel unified unsupervised learning
autoencoder framework, named Node Level Graph AutoEncoder (NodeGAE). We employ
language models as the backbone of the autoencoder, with pretraining on text
reconstruction. Additionally, we add an auxiliary loss term to make the feature
embeddings aware of the local graph structure. Our method maintains simplicity
in the training process and demonstrates generalizability across diverse
textual graphs and downstream tasks. We evaluate our method on two core graph
representation learning downstream tasks: node classification and link
prediction. Comprehensive experiments demonstrate that our approach
substantially enhances the performance of diverse graph neural networks (GNNs)
across multiple textual graph datasets.

ÊëòË¶ÅÔºö<paragraph>ÊñáÊú¨ÂúñË°®Âú®ÁèæÂØ¶‰∏ñÁïåÁöÑÊáâÁî®‰∏≠ÁÑ°Ëôï‰∏çÂú®ÔºåÂÖ∑ÊúâË±êÂØåÁöÑÊñáÊú¨Ë≥áË®äËàáË§áÈõúÁöÑÈóú‰øÇÔºåÈÄô‰ΩøÂæóÂêÑÁ®ÆÈ†òÂüüÁöÑÈ´òÈöéÁ†îÁ©∂ÊàêÁÇ∫ÂèØËÉΩ„ÄÇÊñáÊú¨ÂúñË°®Ë°®Á§∫Â≠∏ÁøíÊó®Âú®ÂæûÊñáÊú¨ÂúñË°®‰∏≠Áî¢Áîü‰ΩéÁ∂≠ÁâπÂæµÂµåÂÖ•ÔºåÈÄôÂèØ‰ª•ÊèêÂçá‰∏ãÊ∏∏‰ªªÂãôÁöÑÂü∑Ë°åÊïàËÉΩ„ÄÇÈ´òÂìÅË≥™ÁöÑÁâπÂæµÂµåÂÖ•ÊáâÊúâÊïàÊì∑ÂèñÊñáÊú¨ÂúñË°®‰∏≠ÁöÑÁµêÊßãÂåñÂíåÊñáÊú¨Ë≥áË®ä„ÄÇÁÑ∂ËÄåÔºåÂ§ßÂ§öÊï∏ÁöÑÊñáÊú¨ÂúñË°®Ë≥áÊñôÈõÜÂü∫Ê∫ñ‰æùË≥¥ word2vec ÊäÄË°ì‰æÜÁî¢ÁîüÁâπÂæµÂµåÂÖ•ÔºåÈÄôÊúÉÈôêÂà∂ÂÖ∂ËÉΩÂäõ„ÄÇÊúÄËøëÈóúÊñºÊñáÊú¨ÂúñË°®Ë°®Á§∫Â≠∏ÁøíÁöÑÁ†îÁ©∂ÂèØÂàÜÁÇ∫ÂÖ©È°ûÔºöÁõ£Áù£ÂºèÂíåÈùûÁõ£Áù£ÂºèÊñπÊ≥ï„ÄÇÁõ£Áù£ÂºèÊñπÊ≥ïÂ∞çÊ®ôÁ±§ÁØÄÈªûÂæÆË™øË™ûË®ÄÊ®°ÂûãÔºåÁï∂Ê®ôÁ±§Ë≥áÊñôÁ®ÄÂ∞ëÊôÇÔºåÂÖ∂ËÉΩÂäõÊúâÈôê„ÄÇÂè¶‰∏ÄÊñπÈù¢ÔºåÈùûÁõ£Áù£ÂºèÊñπÊ≥ïÈÄèÈÅéÈñãÁôºË§áÈõúÁöÑË®ìÁ∑¥ÁÆ°Á∑ö‰æÜËêÉÂèñÁâπÂæµÂµåÂÖ•„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÈôêÂà∂ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÊñ∞Á©éÁöÑÁµ±‰∏ÄÈùûÁõ£Áù£ÂºèÂ≠∏ÁøíËá™ÂãïÁ∑®Á¢ºÂô®Êû∂ÊßãÔºåÁ®±ÁÇ∫ÁØÄÈªûÂ±§Á¥öÂúñÂΩ¢Ëá™ÂãïÁ∑®Á¢ºÂô® (NodeGAE)„ÄÇÊàëÂÄëÊé°Áî®Ë™ûË®ÄÊ®°Âûã‰ΩúÁÇ∫Ëá™ÂãïÁ∑®Á¢ºÂô®ÁöÑÈ™®ÂππÔºå‰∏¶Â∞çÊñáÂ≠óÈáçÂª∫ÈÄ≤Ë°åÈ†êË®ìÁ∑¥„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂä†ÂÖ•‰∏ÄÂÄãËºîÂä©ÊêçÂ§±È†ÖÔºåËÆìÁâπÂæµÂµåÂÖ•ÂØüË¶∫Âà∞Â±ÄÈÉ®ÂúñÂΩ¢ÁµêÊßã„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÂú®Ë®ìÁ∑¥ÈÅéÁ®ã‰∏≠‰øùÊåÅÁ∞°ÊΩîÔºå‰∏¶Â±ïÁ§∫‰∫ÜÂú®‰∏çÂêåÊñáÊú¨ÂúñË°®Âíå‰∏ãÊ∏∏‰ªªÂãô‰∏≠ÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇÊàëÂÄëÂú®ÂÖ©ÂÄãÊ†∏ÂøÉÂúñÂΩ¢Ë°®Á§∫Â≠∏Áøí‰∏ãÊ∏∏‰ªªÂãô‰∏≠Ë©ï‰º∞‰∫ÜÊàëÂÄëÁöÑÊ®°ÂûãÔºöÁØÄÈªûÂàÜÈ°ûÂíåÈÄ£ÁµêÈ†êÊ∏¨„ÄÇÂÖ®Èù¢ÁöÑÂØ¶È©óË≠âÊòéÔºåÊàëÂÄëÁöÑÊ®°ÂûãÂ§ßÂπÖÊèêÂçá‰∫ÜÂêÑÁ®ÆÂúñÂΩ¢Á•ûÁ∂ìÁ∂≤Ë∑Ø (GNN) Âú®Â§öÂÄãÊñáÊú¨ÂúñË°®Ë≥áÊñôÈõÜ‰∏≠ÁöÑÂü∑Ë°åÊïàËÉΩ„ÄÇ</paragraph>

##### **HybridRAG: Integrating Knowledge Graphs and Vector Retrieval Augmented Generation for Efficient Information Extraction**
2408.04948v1 by Bhaskarjit Sarmah, Benika Hall, Rohan Rao, Sunil Patel, Stefano Pasquali, Dhagash Mehta

Extraction and interpretation of intricate information from unstructured text
data arising in financial applications, such as earnings call transcripts,
present substantial challenges to large language models (LLMs) even using the
current best practices to use Retrieval Augmented Generation (RAG) (referred to
as VectorRAG techniques which utilize vector databases for information
retrieval) due to challenges such as domain specific terminology and complex
formats of the documents. We introduce a novel approach based on a combination,
called HybridRAG, of the Knowledge Graphs (KGs) based RAG techniques (called
GraphRAG) and VectorRAG techniques to enhance question-answer (Q&A) systems for
information extraction from financial documents that is shown to be capable of
generating accurate and contextually relevant answers. Using experiments on a
set of financial earning call transcripts documents which come in the form of
Q&A format, and hence provide a natural set of pairs of ground-truth Q&As, we
show that HybridRAG which retrieves context from both vector database and KG
outperforms both traditional VectorRAG and GraphRAG individually when evaluated
at both the retrieval and generation stages in terms of retrieval accuracy and
answer generation. The proposed technique has applications beyond the financial
domain

ÊëòË¶ÅÔºöÂæûÈùûÁµêÊßãÂåñÊñáÊú¨Ë≥áÊñô‰∏≠Êì∑ÂèñÂíåË©ÆÈáãË§áÈõúË≥áË®äÔºå‰æãÂ¶ÇË≤°ÂãôÊáâÁî®‰∏≠Áî¢ÁîüÁöÑÊî∂ÁõäÈõªË©±ÊúÉË≠∞Ë®òÈåÑÔºåÂç≥‰Ωø‰ΩøÁî®Áï∂Ââç‰ΩøÁî®Ê™¢Á¥¢Êì¥ÂÖÖÁîüÊàê (RAG) ÁöÑÊúÄ‰Ω≥ÂØ¶ÂãôÔºàÁ®±ÁÇ∫ VectorRAG ÊäÄË°ìÔºåÂÆÉ‰ΩøÁî®ÂêëÈáèË≥áÊñôÂ∫´‰æÜÈÄ≤Ë°åË≥áË®äÊ™¢Á¥¢ÔºâÔºåÁî±ÊñºÈ†òÂüüÁâπÂÆöË°ìË™ûÂíåÊñá‰ª∂Ê†ºÂºèË§áÈõúÁ≠âÊåëÊà∞ÔºåÂ∞çÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ËÄåË®Ä‰ªçÊßãÊàêÈáçÂ§ßÊåëÊà∞„ÄÇÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÂü∫ÊñºÁ®±ÁÇ∫ HybridRAG ÁöÑÁµÑÂêàÁöÑÊñ∞ÊñπÊ≥ïÔºåÂÖ∂ÁµêÂêà‰∫ÜÂü∫ÊñºÁü•Ë≠òÂúñË≠ú (KG) ÁöÑ RAG ÊäÄË°ìÔºàÁ®±ÁÇ∫ GraphRAGÔºâÂíå VectorRAG ÊäÄË°ìÔºå‰ª•Â¢ûÂº∑Ë≤°ÂãôÊñá‰ª∂Ë≥áË®äÊì∑ÂèñÁöÑÂïèÁ≠î (Q&A) Á≥ªÁµ±ÔºåË≠âÊòéÂÆÉËÉΩÂ§†Áî¢ÁîüÊ∫ñÁ¢∫‰∏îËàáËÑàÁµ°Áõ∏ÈóúÁöÑÁ≠îÊ°à„ÄÇ‰ΩøÁî®‰∏ÄÁµÑ‰ª•ÂïèÁ≠îÊ†ºÂºèÂëàÁèæÁöÑË≤°ÂãôÊî∂ÁõäÈõªË©±ÊúÉË≠∞Ë®òÈåÑÊñá‰ª∂ÈÄ≤Ë°åÂØ¶È©óÔºåÂõ†Ê≠§Êèê‰æõ‰∫ÜËá™ÁÑ∂ÁöÑ‰∏ÄÁµÑÁúüÂØ¶ÂïèÁ≠îÂ∞çÔºåÊàëÂÄëË°®Êòé HybridRAG ÂæûÂêëÈáèË≥áÊñôÂ∫´Âíå KG ‰∏≠Êì∑ÂèñËÑàÁµ°ÔºåÂú®Ê™¢Á¥¢ÂíåÁîüÊàêÈöéÊÆµÁöÑÊ™¢Á¥¢Ê∫ñÁ¢∫Â∫¶ÂíåÁ≠îÊ°àÁîüÊàêÊñπÈù¢ÔºåÈÉΩÂÑ™ÊñºÂÇ≥Áµ±ÁöÑ VectorRAG Âíå GraphRAG„ÄÇÊâÄÊèêÂá∫ÁöÑÊäÄË°ìÂÖ∑ÊúâË∂ÖÂá∫Ë≤°ÂãôÈ†òÂüüÁöÑÊáâÁî®

##### **DIVE: Subgraph Disagreement for Graph Out-of-Distribution Generalization**
2408.04400v1 by Xin Sun, Liang Wang, Qiang Liu, Shu Wu, Zilei Wang, Liang Wang

This paper addresses the challenge of out-of-distribution (OOD)
generalization in graph machine learning, a field rapidly advancing yet
grappling with the discrepancy between source and target data distributions.
Traditional graph learning algorithms, based on the assumption of uniform
distribution between training and test data, falter in real-world scenarios
where this assumption fails, resulting in suboptimal performance. A principal
factor contributing to this suboptimal performance is the inherent simplicity
bias of neural networks trained through Stochastic Gradient Descent (SGD),
which prefer simpler features over more complex yet equally or more predictive
ones. This bias leads to a reliance on spurious correlations, adversely
affecting OOD performance in various tasks such as image recognition, natural
language understanding, and graph classification. Current methodologies,
including subgraph-mixup and information bottleneck approaches, have achieved
partial success but struggle to overcome simplicity bias, often reinforcing
spurious correlations. To tackle this, we propose DIVE, training a collection
of models to focus on all label-predictive subgraphs by encouraging the models
to foster divergence on the subgraph mask, which circumvents the limitation of
a model solely focusing on the subgraph corresponding to simple structural
patterns. Specifically, we employs a regularizer to punish overlap in extracted
subgraphs across models, thereby encouraging different models to concentrate on
distinct structural patterns. Model selection for robust OOD performance is
achieved through validation accuracy. Tested across four datasets from GOOD
benchmark and one dataset from DrugOOD benchmark, our approach demonstrates
significant improvement over existing methods, effectively addressing the
simplicity bias and enhancing generalization in graph machine learning.

ÊëòË¶ÅÔºö<paragraph>ÈÄôÁØáË´ñÊñáÊé¢Ë®é‰∫ÜÂúñÂΩ¢Ê©üÂô®Â≠∏Áøí‰∏≠ÈùûÂàÜ‰Ωà (OOD) Ê¶ÇÂåñÁöÑÊåëÊà∞ÔºåÈÄôÊòØ‰∏ÄÂÄãÂø´ÈÄüÁôºÂ±ïÁöÑÈ†òÂüüÔºå‰ΩÜÂçªÂú®ÊáâÂ∞ç‰æÜÊ∫êÂíåÁõÆÊ®ôË≥áÊñôÂàÜ‰Ωà‰πãÈñìÁöÑÂ∑ÆÁï∞‰∏äÈÅáÂà∞Âõ∞Èõ£„ÄÇÂÇ≥Áµ±ÁöÑÂúñÂΩ¢Â≠∏ÁøíÊºîÁÆóÊ≥ïÂü∫ÊñºË®ìÁ∑¥Ë≥áÊñôÂíåÊ∏¨Ë©¶Ë≥áÊñô‰πãÈñìÂùáÂãªÂàÜ‰ΩàÁöÑÂÅáË®≠Ôºå‰ΩÜÂú®ÈÄôÂÄãÂÅáË®≠Â§±ÊïàÁöÑÂØ¶ÈöõÊÉÖÊ≥Å‰∏≠ÊúÉÂá∫ÁèæÂïèÈ°åÔºåÂ∞éËá¥Ê¨°‰Ω≥ÊïàËÉΩ„ÄÇÈÄ†ÊàêÈÄôÁ®ÆÊ¨°‰Ω≥ÊïàËÉΩÁöÑ‰∏ªË¶ÅÂõ†Á¥†ÊòØÈÄèÈÅéÈö®Ê©üÊ¢ØÂ∫¶‰∏ãÈôç (SGD) Ë®ìÁ∑¥ÁöÑÁ•ûÁ∂ìÁ∂≤Ë∑ØÂõ∫ÊúâÁöÑÁ∞°ÂåñÂÅèÂ∑ÆÔºåÂÆÉÂÅèÂ•ΩËºÉÁ∞°ÂñÆÁöÑÁâπÂæµÔºåËÄåÈùûÊõ¥Ë§áÈõú‰ΩÜÈ†êÊ∏¨ËÉΩÂäõÁõ∏ÂêåÊàñÊõ¥È´òÁöÑÁâπÂæµ„ÄÇÈÄôÁ®ÆÂÅèÂ∑ÆÊúÉÂ∞éËá¥‰æùË≥¥ËôõÂÅáÁõ∏ÈóúÊÄßÔºåÂ∞çÂêÑÁ®Æ‰ªªÂãôÔºà‰æãÂ¶ÇÂΩ±ÂÉèËæ®Ë≠ò„ÄÅËá™ÁÑ∂Ë™ûË®ÄÁêÜËß£ÂíåÂúñÂΩ¢ÂàÜÈ°ûÔºâÁöÑ OOD ÊïàËÉΩÁî¢ÁîüË≤†Èù¢ÂΩ±Èüø„ÄÇÁõÆÂâçÁöÑÊäÄË°ìÊñπÊ≥ïÔºåÂåÖÊã¨Â≠êÂúñÊ∑∑ÂêàÂíåË≥áË®äÁì∂È†∏ÊñπÊ≥ïÔºåÂ∑≤ÂèñÂæóÈÉ®ÂàÜÊàêÂäüÔºå‰ΩÜ‰ªçÈõ£‰ª•ÂÖãÊúçÁ∞°ÂåñÂÅèÂ∑ÆÔºåËÄå‰∏îÂ∏∏Â∏∏ÊúÉÂº∑ÂåñËôõÂÅáÁõ∏ÈóúÊÄß„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∫Ü DIVEÔºåË®ìÁ∑¥‰∏ÄÁµÑÊ®°Âûã‰ª•ÈóúÊ≥®ÊâÄÊúâÊ®ôÁ±§È†êÊ∏¨Â≠êÂúñÔºåÊñπÊ≥ïÊòØÈºìÂãµÊ®°ÂûãÂú®Â≠êÂúñÈÅÆÁΩ©‰∏ä‰øÉÈÄ≤Â∑ÆÁï∞ÔºåÈÄôÈÅøÈñã‰∫ÜÊ®°ÂûãÂÉÖÈóúÊ≥®Â∞çÊáâÊñºÁ∞°ÂñÆÁµêÊßãÊ®°ÂºèÁöÑÂ≠êÂúñÁöÑÈôêÂà∂„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÊé°Áî®‰∏ÄÂÄãÊ≠£Ë¶èÂåñÂô®‰æÜÊá≤ÁΩ∞Ê®°Âûã‰πãÈñìÊèêÂèñÁöÑÂ≠êÂúñ‰∏≠ÁöÑÈáçÁñäÔºåÂæûËÄåÈºìÂãµ‰∏çÂêåÁöÑÊ®°ÂûãÂ∞àÊ≥®Êñº‰∏çÂêåÁöÑÁµêÊßãÊ®°Âºè„ÄÇÈÄèÈÅéÈ©óË≠âÊ∫ñÁ¢∫Â∫¶ÔºåÂèØ‰ª•ÈÅ∏ÊìáÊ®°Âûã‰ª•Áç≤ÂæóÁ©©ÂÅ•ÁöÑ OOD ÊïàËÉΩ„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÂú® GOOD Âü∫Ê∫ñ‰∏≠ÁöÑÂõõÂÄãË≥áÊñôÈõÜÂíå DrugOOD Âü∫Ê∫ñ‰∏≠ÁöÑÂÖ∂‰∏≠‰∏ÄÂÄãË≥áÊñôÈõÜ‰∏äÈÄ≤Ë°å‰∫ÜÊ∏¨Ë©¶ÔºåÁµêÊûúÈ°ØÁ§∫Âá∫ÊØîÁèæÊúâÊñπÊ≥ïÊúâÈ°ØËëóÁöÑÈÄ≤Ê≠•ÔºåÊúâÊïàÂú∞Ëß£Ê±∫‰∫ÜÁ∞°ÂåñÂÅèÂ∑ÆÔºå‰∏¶Â¢ûÂº∑‰∫ÜÂúñÂΩ¢Ê©üÂô®Â≠∏Áøí‰∏≠ÁöÑÊ¶ÇÂåñËÉΩÂäõ„ÄÇ</paragraph>

##### **MM-Forecast: A Multimodal Approach to Temporal Event Forecasting with Large Language Models**
2408.04388v1 by Haoxuan Li, Zhengmao Yang, Yunshan Ma, Yi Bin, Yang Yang, Tat-Seng Chua

We study an emerging and intriguing problem of multimodal temporal event
forecasting with large language models. Compared to using text or graph
modalities, the investigation of utilizing images for temporal event
forecasting has not been fully explored, especially in the era of large
language models (LLMs). To bridge this gap, we are particularly interested in
two key questions of: 1) why images will help in temporal event forecasting,
and 2) how to integrate images into the LLM-based forecasting framework. To
answer these research questions, we propose to identify two essential functions
that images play in the scenario of temporal event forecasting, i.e.,
highlighting and complementary. Then, we develop a novel framework, named
MM-Forecast. It employs an Image Function Identification module to recognize
these functions as verbal descriptions using multimodal large language models
(MLLMs), and subsequently incorporates these function descriptions into
LLM-based forecasting models. To evaluate our approach, we construct a new
multimodal dataset, MidEast-TE-mm, by extending an existing event dataset
MidEast-TE-mini with images. Empirical studies demonstrate that our MM-Forecast
can correctly identify the image functions, and further more, incorporating
these verbal function descriptions significantly improves the forecasting
performance. The dataset, code, and prompts are available at
https://github.com/LuminosityX/MM-Forecast.

ÊëòË¶ÅÔºöÊàëÂÄëÁ†îÁ©∂Â§öÊ®°ÊÖãÊôÇÈñì‰∫ã‰ª∂È†êÊ∏¨‰∏≠‰∏ÄÂÄãÊñ∞Ëàà‰∏îÊúâË∂£ÁöÑË™ûË®ÄÊ®°ÂûãÂïèÈ°å„ÄÇÁõ∏ËºÉÊñº‰ΩøÁî®ÊñáÂ≠óÊàñÂúñË°®Ê®°ÊÖãÔºåÂà©Áî®ÂΩ±ÂÉèÈÄ≤Ë°åÊôÇÈñì‰∫ã‰ª∂È†êÊ∏¨ÁöÑÁ†îÁ©∂Â∞öÊú™Ë¢´ÂÖÖÂàÜÊé¢Á¥¢ÔºåÁâπÂà•ÊòØÂú®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊôÇ‰ª£„ÄÇÁÇ∫‰∫ÜÂ°´Ë£úÈÄôÂÄãÁ©∫ÁôΩÔºåÊàëÂÄëÁâπÂà•ÊÑüËààË∂£ÁöÑÂÖ©ÂÄãÈóúÈçµÂïèÈ°åÊòØÔºö1) ÁÇ∫‰ªÄÈ∫ºÂΩ±ÂÉèÊúâÂä©ÊñºÊôÇÈñì‰∫ã‰ª∂È†êÊ∏¨Ôºå‰ª•Âèä 2) Â¶Ç‰ΩïÂ∞áÂΩ±ÂÉèÊï¥ÂêàÂà∞Âü∫Êñº LLM ÁöÑÈ†êÊ∏¨Ê°ÜÊû∂‰∏≠„ÄÇÁÇ∫‰∫ÜÂõûÁ≠îÈÄô‰∫õÁ†îÁ©∂ÂïèÈ°åÔºåÊàëÂÄëÊèêË≠∞ÊâæÂá∫ÂΩ±ÂÉèÂú®ÊôÇÈñì‰∫ã‰ª∂È†êÊ∏¨Â†¥ÊôØ‰∏≠ÊâÆÊºîÁöÑÂÖ©ÂÄãÂü∫Êú¨ÂäüËÉΩÔºåÂç≥Á™ÅÈ°ØÂíåË£úÂÖÖ„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÈñãÁôº‰∏ÄÂÄãÂêçÁÇ∫ MM-Forecast ÁöÑÊñ∞Ê°ÜÊû∂„ÄÇÂÆÉ‰ΩøÁî®ÂΩ±ÂÉèÂäüËÉΩË≠òÂà•Ê®°ÁµÑÔºå‰ΩøÁî®Â§öÊ®°ÊÖãÂ§ßÂûãË™ûË®ÄÊ®°Âûã (MLLM) Â∞áÈÄô‰∫õÂäüËÉΩË≠òÂà•ÁÇ∫ÊñáÂ≠óÊèèËø∞Ôºå‰∏¶Èö®ÂæåÂ∞áÈÄô‰∫õÂäüËÉΩÊèèËø∞Á¥çÂÖ•Âü∫Êñº LLM ÁöÑÈ†êÊ∏¨Ê®°Âûã‰∏≠„ÄÇÁÇ∫‰∫ÜË©ï‰º∞ÊàëÂÄëÁöÑÊñπÊ≥ïÔºåÊàëÂÄëÈÄöÈÅé‰ΩøÁî®ÂΩ±ÂÉèÊì¥ÂÖÖÁèæÊúâÁöÑ‰∫ã‰ª∂Ë≥áÊñôÈõÜ MidEast-TE-miniÔºåÂª∫Êßã‰∫Ü‰∏ÄÂÄãÊñ∞ÁöÑÂ§öÊ®°ÊÖãË≥áÊñôÈõÜ MidEast-TE-mm„ÄÇÂØ¶Ë≠âÁ†îÁ©∂Ë°®ÊòéÔºåÊàëÂÄëÁöÑ MM-Forecast ÂèØ‰ª•Ê≠£Á¢∫Ë≠òÂà•ÂΩ±ÂÉèÂäüËÉΩÔºåÊ≠§Â§ñÔºåÁ¥çÂÖ•ÈÄô‰∫õÊñáÂ≠óÂäüËÉΩÊèèËø∞ÂèØ‰ª•È°ØËëóÊîπÂñÑÈ†êÊ∏¨ÊïàËÉΩ„ÄÇË≥áÊñôÈõÜ„ÄÅÁ®ãÂºèÁ¢ºÂíåÊèêÁ§∫ÂèØÂú® https://github.com/LuminosityX/MM-Forecast ÂèñÂæó„ÄÇ

##### **Judgment2vec: Apply Graph Analytics to Searching and Recommendation of Similar Judgments**
2408.04382v1 by Hsuan-Lei Shao

In court practice, legal professionals rely on their training to provide
opinions that resolve cases, one of the most crucial aspects being the ability
to identify similar judgments from previous courts efficiently. However,
finding a similar case is challenging and often depends on experience, legal
domain knowledge, and extensive labor hours, making veteran lawyers or judges
indispensable. This research aims to automate the analysis of judgment text
similarity. We utilized a judgment dataset labeled as the "golden standard" by
experts, which includes human-verified features that can be converted into an
"expert similarity score." We then constructed a knowledge graph based on
"case-article" relationships, ranking each case using natural language
processing to derive a "Node2vec similarity score." By evaluating these two
similarity scores, we identified their discrepancies and relationships. The
results can significantly reduce the labor hours required for legal searches
and recommendations, with potential applications extending to various fields of
information retrieval.

ÊëòË¶ÅÔºöÂú®Ê≥ïÂ∫≠ÂØ¶Âãô‰∏≠ÔºåÊ≥ïÂæãÂ∞àÊ•≠‰∫∫Â£´‰æùË≥¥ÂÖ∂ÂüπË®ìÊèê‰æõÊÑèË¶ã‰ª•Ëß£Ê±∫Ê°à‰ª∂ÔºåÂÖ∂‰∏≠ÊúÄÈóúÈçµÁöÑÊñπÈù¢‰πã‰∏ÄÊòØÊúâÊïàË≠òÂà•ÂÖàÂâçÊ≥ïÈô¢ÁöÑÈ°û‰ººÂà§Ê±∫ÁöÑËÉΩÂäõ„ÄÇÁÑ∂ËÄåÔºåÊâæÂá∫È°û‰ººÊ°à‰ª∂ÂÖ∑ÊúâÊåëÊà∞ÊÄßÔºå‰∏îÈÄöÂ∏∏ÂèñÊ±∫ÊñºÁ∂ìÈ©ó„ÄÅÊ≥ïÂæãÈ†òÂüüÁü•Ë≠òÂíåÂ§ßÈáèÁöÑÂãûÂãïÊôÇÈñìÔºåÈÄô‰ΩøÂæóË≥áÊ∑±ÂæãÂ∏´ÊàñÊ≥ïÂÆò‰∏çÂèØÊàñÁº∫„ÄÇÊú¨Á†îÁ©∂Êó®Âú®Ëá™ÂãïÂåñÂà§Ê±∫ÊñáÊú¨Áõ∏‰ººÊÄßÁöÑÂàÜÊûê„ÄÇÊàëÂÄëÂà©Áî®Â∞àÂÆ∂Ê®ôË®òÁÇ∫„ÄåÈªÉÈáëÊ®ôÊ∫ñ„ÄçÁöÑÂà§Ê±∫Ë≥áÊñôÈõÜÔºåÂÖ∂‰∏≠ÂåÖÊã¨ÂèØËΩâÊèõÁÇ∫„ÄåÂ∞àÂÆ∂Áõ∏‰ººÊÄßË©ïÂàÜ„ÄçÁöÑ‰∫∫Â∑•È©óË≠âÁâπÂæµ„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÊ†πÊìö„ÄåÊ°à‰æã-Ê¢ùÊñá„ÄçÈóú‰øÇÂª∫ÊßãÁü•Ë≠òÂúñË≠úÔºå‰ΩøÁî®Ëá™ÁÑ∂Ë™ûË®ÄËôïÁêÜÂ∞çÊØèÂÄãÊ°à‰æãÈÄ≤Ë°åÊéíÂêçÔºå‰ª•ÂæóÂá∫„ÄåNode2vec Áõ∏‰ººÊÄßË©ïÂàÜ„Äç„ÄÇÈÄèÈÅéË©ï‰º∞ÈÄôÂÖ©ÂÄãÁõ∏‰ººÊÄßË©ïÂàÜÔºåÊàëÂÄëÊâæÂá∫ÂÖ∂Â∑ÆÁï∞ÂíåÈóú‰øÇ„ÄÇÁµêÊûúÂèØ‰ª•Â§ßÂπÖÊ∏õÂ∞ëÊ≥ïÂæãÊêúÂ∞ãÂíåÂª∫Ë≠∞ÊâÄÈúÄÁöÑÂãûÂãïÊôÇÈñìÔºåÊΩõÂú®ÊáâÁî®ÁØÑÂúçÊì¥ÂèäË≥áË®äÊ™¢Á¥¢ÁöÑÂêÑÂÄãÈ†òÂüü„ÄÇ

##### **Dynamic Hypergraph-Enhanced Prediction of Sequential Medical Visits**
2408.07084v1 by Wangying Yang, Zhizhong Wu, Zitao Zheng, Bo Zhang, Shi Bo, Yuanfang Yang

This study introduces a pioneering Dynamic Hypergraph Networks (DHCE) model
designed to predict future medical diagnoses from electronic health records
with enhanced accuracy. The DHCE model innovates by identifying and
differentiating acute and chronic diseases within a patient's visit history,
constructing dynamic hypergraphs that capture the complex, high-order
interactions between diseases. It surpasses traditional recurrent neural
networks and graph neural networks by effectively integrating clinical event
data, reflected through medical language model-assisted encoding, into a robust
patient representation. Through extensive experiments on two benchmark
datasets, MIMIC-III and MIMIC-IV, the DHCE model exhibits superior performance,
significantly outpacing established baseline models in the precision of
sequential diagnosis prediction.

ÊëòË¶ÅÔºöÊú¨Á†îÁ©∂‰ªãÁ¥π‰∫Ü‰∏ÄÁ®ÆÂâµÊñ∞ÁöÑÂãïÊÖãË∂ÖÂúñÁ∂≤Ë∑Ø (DHCE) Ê®°ÂûãÔºåÊó®Âú®ÂæûÈõªÂ≠êÁóÖÊ≠∑‰∏≠È†êÊ∏¨Êú™‰æÜÁöÑÈÜ´ÁôÇË®∫Êñ∑Ôºå‰∏¶ÊèêÈ´òÊ∫ñÁ¢∫Â∫¶„ÄÇDHCE Ê®°ÂûãÈÄèÈÅéË≠òÂà•ÂíåÂçÄÂàÜÊÇ£ËÄÖÂ∞±Ë®∫Ë®òÈåÑ‰∏≠ÁöÑÊÄ•ÊÄßÁóÖÂíåÊÖ¢ÊÄßÁóÖÔºåÂª∫ÊßãÂãïÊÖãË∂ÖÂúñ‰æÜÊçïÊçâÁñæÁóÖ‰πãÈñìË§áÈõúÁöÑÈ´òÈöé‰∫íÂãïÔºåÈÄ≤ËÄåÈÄ≤Ë°åÂâµÊñ∞„ÄÇÂÆÉË∂ÖË∂ä‰∫ÜÂÇ≥Áµ±ÁöÑÈÅûËø¥Á•ûÁ∂ìÁ∂≤Ë∑ØÂíåÂúñÁ•ûÁ∂ìÁ∂≤Ë∑ØÔºåÊúâÊïàÂú∞Â∞áËá®Â∫ä‰∫ã‰ª∂Ë≥áÊñôÊï¥ÂêàÂà∞Âº∑ÂÅ•ÁöÑÊÇ£ËÄÖË°®Âæµ‰∏≠Ôºå‰∏¶ÈÄèÈÅéÈÜ´ÁôÇË™ûË®ÄÊ®°ÂûãËºîÂä©Á∑®Á¢º‰æÜÂèçÊò†„ÄÇÈÄèÈÅéÂú®ÂÖ©ÂÄãÂü∫Ê∫ñË≥áÊñôÈõÜ MIMIC-III Âíå MIMIC-IV ‰∏äÈÄ≤Ë°åÂª£Ê≥õÁöÑÂØ¶È©óÔºåDHCE Ê®°ÂûãÂ±ïÁèæÂá∫ÂÑ™Áï∞ÁöÑÊïàËÉΩÔºåÂú®Â∫èË≤´Ë®∫Êñ∑È†êÊ∏¨ÁöÑÁ≤æÊ∫ñÂ∫¶‰∏äÈ°ØËëóÂú∞Ë∂ÖË∂äÊó¢ÂÆöÁöÑÂü∫Ê∫ñÊ®°Âûã„ÄÇ

##### **wav2graph: A Framework for Supervised Learning Knowledge Graph from Speech**
2408.04174v1 by Khai Le-Duc, Quy-Anh Dang, Tan-Hanh Pham, Truong-Son Hy

Knowledge graphs (KGs) enhance the performance of large language models
(LLMs) and search engines by providing structured, interconnected data that
improves reasoning and context-awareness. However, KGs only focus on text data,
thereby neglecting other modalities such as speech. In this work, we introduce
wav2graph, the first framework for supervised learning knowledge graph from
speech data. Our pipeline are straightforward: (1) constructing a KG based on
transcribed spoken utterances and a named entity database, (2) converting KG
into embedding vectors, and (3) training graph neural networks (GNNs) for node
classification and link prediction tasks. Through extensive experiments
conducted in inductive and transductive learning contexts using
state-of-the-art GNN models, we provide baseline results and error analysis for
node classification and link prediction tasks on human transcripts and
automatic speech recognition (ASR) transcripts, including evaluations using
both encoder-based and decoder-based node embeddings, as well as monolingual
and multilingual acoustic pre-trained models. All related code, data, and
models are published online.

ÊëòË¶ÅÔºöÁü•Ë≠òÂúñË≠ú (KG) ÈÄèÈÅéÊèê‰æõÁµêÊßãÂåñ„ÄÅÁõ∏‰∫íÈÄ£ÁµêÁöÑË≥áÊñôÔºåÈÄ≤ËÄåÊîπÂñÑÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂíåÊêúÂ∞ãÂºïÊìéÁöÑÊïàËÉΩÔºåÊèêÂçáÊé®ÁêÜÂíåËÑàÁµ°ÊÑüÁü•„ÄÇÁÑ∂ËÄåÔºåKG Âè™ÈóúÊ≥®ÊñáÂ≠óË≥áÊñôÔºåÂõ†Ê≠§ÂøΩÁï•‰∫ÜÂÖ∂‰ªñÂΩ¢ÂºèÔºå‰æãÂ¶ÇË™ûÈü≥„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π wav2graphÔºåÈÄôÊòØÁ¨¨‰∏ÄÂÄãÂæûË™ûÈü≥Ë≥áÊñô‰∏≠Áõ£Áù£Â≠∏ÁøíÁü•Ë≠òÂúñË≠úÁöÑÊû∂Êßã„ÄÇÊàëÂÄëÁöÑÊµÅÁ®ãÂæàÁõ¥Êé•Ôºö(1) Ê†πÊìöËΩâÈåÑÁöÑÂè£Ë™ûË°®ÈÅîÂíåÂëΩÂêçÂØ¶È´îË≥áÊñôÂ∫´Âª∫Êßã KGÔºå(2) Â∞á KG ËΩâÊèõÁÇ∫ÂµåÂÖ•ÂêëÈáèÔºå‰ª•Âèä (3) Ë®ìÁ∑¥ÂúñÂΩ¢Á•ûÁ∂ìÁ∂≤Ë∑Ø (GNN) ‰ª•ÈÄ≤Ë°åÁØÄÈªûÂàÜÈ°ûÂíåÈÄ£ÁµêÈ†êÊ∏¨‰ªªÂãô„ÄÇÈÄèÈÅé‰ΩøÁî®ÊúÄÂÖàÈÄ≤ÁöÑ GNN Ê®°ÂûãÂú®Ê≠∏Á¥çÂíåËΩâÂ∞éÂ≠∏ÁøíÁöÑÁí∞Â¢É‰∏≠ÈÄ≤Ë°åÂª£Ê≥õÁöÑÂØ¶È©óÔºåÊàëÂÄëÊèê‰æõÁØÄÈªûÂàÜÈ°ûÂíåÈÄ£ÁµêÈ†êÊ∏¨‰ªªÂãôÁöÑÂü∫Ê∫ñÁµêÊûúÂíåÈåØË™§ÂàÜÊûêÔºåÂÖ∂‰∏≠ÂåÖÊã¨‰ΩøÁî®Á∑®Á¢ºÂô®ÁÇ∫Âü∫Á§éÂíåËß£Á¢ºÂô®ÁÇ∫Âü∫Á§éÁöÑÁØÄÈªûÂµåÂÖ•Ôºå‰ª•ÂèäÂñÆË™ûÂíåÂ§öË™ûÈü≥Â≠∏È†êË®ìÁ∑¥Ê®°ÂûãÁöÑË©ï‰º∞„ÄÇÊâÄÊúâÁõ∏ÈóúÁ®ãÂºèÁ¢º„ÄÅË≥áÊñôÂíåÊ®°ÂûãÁöÜÂ∑≤Âú®Á∑ö‰∏äÁôºÂ∏É„ÄÇ

##### **ArtVLM: Attribute Recognition Through Vision-Based Prefix Language Modeling**
2408.04102v1 by William Y. Zhu, Keren Ye, Junjie Ke, Jiahui Yu, Leonidas Guibas, Peyman Milanfar, Feng Yang

Recognizing and disentangling visual attributes from objects is a foundation
to many computer vision applications. While large vision language
representations like CLIP had largely resolved the task of zero-shot object
recognition, zero-shot visual attribute recognition remains a challenge because
CLIP's contrastively-learned vision-language representation cannot effectively
capture object-attribute dependencies. In this paper, we target this weakness
and propose a sentence generation-based retrieval formulation for attribute
recognition that is novel in 1) explicitly modeling a to-be-measured and
retrieved object-attribute relation as a conditional probability graph, which
converts the recognition problem into a dependency-sensitive language-modeling
problem, and 2) applying a large pretrained Vision-Language Model (VLM) on this
reformulation and naturally distilling its knowledge of image-object-attribute
relations to use towards attribute recognition. Specifically, for each
attribute to be recognized on an image, we measure the visual-conditioned
probability of generating a short sentence encoding the attribute's relation to
objects on the image. Unlike contrastive retrieval, which measures likelihood
by globally aligning elements of the sentence to the image, generative
retrieval is sensitive to the order and dependency of objects and attributes in
the sentence. We demonstrate through experiments that generative retrieval
consistently outperforms contrastive retrieval on two visual reasoning
datasets, Visual Attribute in the Wild (VAW), and our newly-proposed Visual
Genome Attribute Ranking (VGARank).

ÊëòË¶ÅÔºöËæ®Ë≠òÂíåÂçÄÂàÜÁâ©‰ª∂ÁöÑË¶ñË¶∫Â±¨ÊÄßÔºåÊòØË®±Â§öÈõªËÖ¶Ë¶ñË¶∫ÊáâÁî®Á®ãÂºèÁöÑÂü∫Á§é„ÄÇÈõñÁÑ∂ÂÉè CLIP ÈÄôÊ®£ÁöÑÂ§ßÂûãË¶ñË¶∫Ë™ûË®ÄË°®ÂæµÔºåÂ∑≤Âú®ÂæàÂ§ßÁ®ãÂ∫¶‰∏äËß£Ê±∫‰∫ÜÈõ∂Ê¨°Â≠∏ÁøíÁâ©‰ª∂Ëæ®Ë≠òÁöÑ‰ªªÂãôÔºå‰ΩÜÈõ∂Ê¨°Â≠∏ÁøíË¶ñË¶∫Â±¨ÊÄßËæ®Ë≠ò‰ªçÁÑ∂ÊòØ‰∏ÄÂÄãÊåëÊà∞ÔºåÂõ†ÁÇ∫ CLIP Â∞çÊØîÂ≠∏ÁøíÁöÑË¶ñË¶∫Ë™ûË®ÄË°®ÂæµÔºåÁÑ°Ê≥ïÊúâÊïàÊì∑ÂèñÁâ©‰ª∂Â±¨ÊÄß‰æùË≥¥ÊÄß„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÈáùÂ∞çÊ≠§Âº±ÈªûÔºå‰∏¶ÊèêÂá∫‰∏ÄÂÄãÂü∫ÊñºÂè•Â≠êÁîüÊàêÁöÑÊ™¢Á¥¢ÂÖ¨ÂºèÔºåÁî®ÊñºÂ±¨ÊÄßËæ®Ë≠òÔºåÂÖ∂Êñ∞Á©é‰πãËôïÂú®ÊñºÔºö1) ÊòéÁ¢∫Âú∞Â∞áÂæÖÊ∏¨ÈáèÂíåÊ™¢Á¥¢ÁöÑÁâ©‰ª∂Â±¨ÊÄßÈóú‰øÇÂª∫Ê®°ÁÇ∫Ê¢ù‰ª∂Ê©üÁéáÂúñÔºåÈÄôÂ∞áËæ®Ë≠òÂïèÈ°åËΩâÊèõÁÇ∫‰æùË≥¥ÊïèÊÑüÁöÑË™ûË®ÄÊ®°ÂûãÂïèÈ°åÔºõ2) Âú®Ê≠§ÈáçÊñ∞ÂÖ¨ÂºèÂåñ‰∏äÊáâÁî®Â§ßÂûãÈ†êË®ìÁ∑¥ÁöÑË¶ñË¶∫Ë™ûË®ÄÊ®°Âûã (VLM)Ôºå‰∏¶Ëá™ÁÑ∂Âú∞ËêÉÂèñÂÖ∂Â∞çÂΩ±ÂÉèÁâ©‰ª∂Â±¨ÊÄßÈóú‰øÇÁöÑÁü•Ë≠òÔºåÁî®ÊñºÂ±¨ÊÄßËæ®Ë≠ò„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÂ∞çÊñºË¶ÅÂú®ÂΩ±ÂÉè‰∏äËæ®Ë≠òÁöÑÊØèÂÄãÂ±¨ÊÄßÔºåÊàëÂÄëÊ∏¨ÈáèÂú®ÂΩ±ÂÉè‰∏äÁ∑®Á¢ºÂ±¨ÊÄßËàáÁâ©‰ª∂Èóú‰øÇÁöÑÁ∞°Áü≠Âè•Â≠êÁöÑË¶ñË¶∫Ê¢ù‰ª∂Ê©üÁéá„ÄÇËàáÂ∞çÊØîÊ™¢Á¥¢‰∏çÂêåÔºåÂ∞çÊØîÊ™¢Á¥¢ÊòØÈÄèÈÅéÂ∞áÂè•Â≠êÁöÑÂÖÉÁ¥†Êï¥È´îÊØîÂ∞çÂà∞ÂΩ±ÂÉè‰æÜÊ∏¨ÈáèÂèØËÉΩÊÄßÔºåÁîüÊàêÊ™¢Á¥¢ÂâáÂ∞çÂè•Â≠ê‰∏≠Áâ©‰ª∂ÂíåÂ±¨ÊÄßÁöÑÈ†ÜÂ∫èÂíå‰æùË≥¥ÊÄßÂæàÊïèÊÑü„ÄÇÊàëÂÄëÈÄèÈÅéÂØ¶È©óË≠âÊòéÔºåÁîüÊàêÊ™¢Á¥¢Âú®ÂÖ©ÂÄãË¶ñË¶∫Êé®ÁêÜË≥áÊñôÈõÜÔºåÈáéÂ§ñË¶ñË¶∫Â±¨ÊÄß (VAW) ÂíåÊàëÂÄëÊñ∞ÊèêÂá∫ÁöÑË¶ñË¶∫Âü∫Âõ†ÁµÑÂ±¨ÊÄßÊéíÂêç (VGARank) ‰∏äÔºåÂßãÁµÇÂÑ™ÊñºÂ∞çÊØîÊ™¢Á¥¢„ÄÇ

##### **CodexGraph: Bridging Large Language Models and Code Repositories via Code Graph Databases**
2408.03910v2 by Xiangyan Liu, Bo Lan, Zhiyuan Hu, Yang Liu, Zhicheng Zhang, Fei Wang, Michael Shieh, Wenmeng Zhou

Large Language Models (LLMs) excel in stand-alone code tasks like HumanEval
and MBPP, but struggle with handling entire code repositories. This challenge
has prompted research on enhancing LLM-codebase interaction at a repository
scale. Current solutions rely on similarity-based retrieval or manual tools and
APIs, each with notable drawbacks. Similarity-based retrieval often has low
recall in complex tasks, while manual tools and APIs are typically
task-specific and require expert knowledge, reducing their generalizability
across diverse code tasks and real-world applications. To mitigate these
limitations, we introduce CodexGraph, a system that integrates LLM agents with
graph database interfaces extracted from code repositories. By leveraging the
structural properties of graph databases and the flexibility of the graph query
language, CodexGraph enables the LLM agent to construct and execute queries,
allowing for precise, code structure-aware context retrieval and code
navigation. We assess CodexGraph using three benchmarks: CrossCodeEval,
SWE-bench, and EvoCodeBench. Additionally, we develop five real-world coding
applications. With a unified graph database schema, CodexGraph demonstrates
competitive performance and potential in both academic and real-world
environments, showcasing its versatility and efficacy in software engineering.
Our application demo:
https://github.com/modelscope/modelscope-agent/tree/master/apps/codexgraph_agent.

ÊëòË¶ÅÔºöÂ§ßÂûãËØ≠Ë®ÄÊ®°Âûã (LLM) Âú®Áã¨Á´ã‰ª£Á†Å‰ªªÂä°‰∏≠Ë°®Áé∞Âá∫Ëâ≤Ôºå‰æãÂ¶Ç HumanEval Âíå MBPPÔºå‰ΩÜÂú®Â§ÑÁêÜÊï¥‰∏™‰ª£Á†ÅÂ≠òÂÇ®Â∫ìÊó∂Âç¥ÈÅáÂà∞‰∫ÜÂõ∞Èöæ„ÄÇËøô‰∏™ÊåëÊàò‰øÉËøõ‰∫ÜÂØπÂú®Â≠òÂÇ®Â∫ìËßÑÊ®°‰∏äÂ¢ûÂº∫ LLM ‰ª£Á†ÅÂ∫ì‰∫§‰∫íÁöÑÁ†îÁ©∂„ÄÇÂΩìÂâçÁöÑËß£ÂÜ≥ÊñπÊ°à‰æùËµñ‰∫éÂü∫‰∫éÁõ∏‰ººÊÄßÁöÑÊ£ÄÁ¥¢ÊàñÊâãÂä®Â∑•ÂÖ∑Âíå APIÔºåÊØèÁßçËß£ÂÜ≥ÊñπÊ°àÈÉΩÊúâÊòéÊòæÁöÑÁº∫ÁÇπ„ÄÇÂü∫‰∫éÁõ∏‰ººÊÄßÁöÑÊ£ÄÁ¥¢Âú®Â§çÊùÇ‰ªªÂä°‰∏≠ÈÄöÂ∏∏Âè¨ÂõûÁéáËæÉ‰ΩéÔºåËÄåÊâãÂä®Â∑•ÂÖ∑Âíå API ÈÄöÂ∏∏ÊòØÁâπÂÆö‰∫é‰ªªÂä°ÁöÑÔºåÂπ∂‰∏îÈúÄË¶Å‰∏ì‰∏öÁü•ËØÜÔºå‰ªéËÄåÈôç‰Ωé‰∫ÜÂÆÉ‰ª¨Âú®‰∏çÂêå‰ª£Á†Å‰ªªÂä°ÂíåÂÆûÈôÖÂ∫îÁî®‰∏≠ÁöÑÊ≥õÂåñÊÄß„ÄÇ‰∏∫‰∫ÜÂáèËΩªËøô‰∫õÈôêÂà∂ÔºåÊàë‰ª¨ÂºïÂÖ•‰∫Ü CodexGraphÔºåËøôÊòØ‰∏Ä‰∏™Â∞Ü LLM ‰ª£ÁêÜ‰∏é‰ªé‰ª£Á†ÅÂ≠òÂÇ®Â∫ì‰∏≠ÊèêÂèñÁöÑÂõæÂΩ¢Êï∞ÊçÆÂ∫ìÁïåÈù¢ÈõÜÊàêÁöÑÁ≥ªÁªü„ÄÇÈÄöËøáÂà©Áî®ÂõæÂΩ¢Êï∞ÊçÆÂ∫ìÁöÑÁªìÊûÑÂ±ûÊÄßÂíåÂõæÂΩ¢Êü•ËØ¢ËØ≠Ë®ÄÁöÑÁÅµÊ¥ªÊÄßÔºåCodexGraph ‰Ωø LLM ‰ª£ÁêÜËÉΩÂ§üÊûÑÂª∫ÂíåÊâßË°åÊü•ËØ¢Ôºå‰ªéËÄåÂÆûÁé∞Á≤æÁ°ÆÁöÑ„ÄÅ‰ª£Á†ÅÁªìÊûÑÊÑüÁü•ÁöÑ‰∏ä‰∏ãÊñáÊ£ÄÁ¥¢Âíå‰ª£Á†ÅÂØºËà™„ÄÇÊàë‰ª¨‰ΩøÁî®‰∏â‰∏™Âü∫ÂáÜÂØπ CodexGraph ËøõË°å‰∫ÜËØÑ‰º∞ÔºöCrossCodeEval„ÄÅSWE-bench Âíå EvoCodeBench„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨ËøòÂºÄÂèë‰∫Ü‰∫î‰∏™ÂÆûÈôÖÁöÑÁºñÁ†ÅÂ∫îÁî®Á®ãÂ∫è„ÄÇÈÄöËøáÁªü‰∏ÄÁöÑÂõæÂΩ¢Êï∞ÊçÆÂ∫ìÊ®°ÂºèÔºåCodexGraph Âú®Â≠¶ÊúØÂíåÁé∞ÂÆû‰∏ñÁïåÁéØÂ¢É‰∏≠ÈÉΩÂ±ïÁ§∫‰∫ÜÁ´û‰∫âÊÄßËÉΩÂíåÊΩúÂäõÔºåÂ±ïÁ§∫‰∫ÜÂÖ∂Âú®ËΩØ‰ª∂Â∑•Á®ã‰∏≠ÁöÑÂ§öÂäüËÉΩÊÄßÂíåÊúâÊïàÊÄß„ÄÇÊàë‰ª¨ÁöÑÂ∫îÁî®Á®ãÂ∫èÊºîÁ§∫Ôºöhttps://github.com/modelscope/modelscope-agent/tree/master/apps/codexgraph_agent„ÄÇ

##### **PAGED: A Benchmark for Procedural Graphs Extraction from Documents**
2408.03630v2 by Weihong Du, Wenrui Liao, Hongru Liang, Wenqiang Lei

Automatic extraction of procedural graphs from documents creates a low-cost
way for users to easily understand a complex procedure by skimming visual
graphs. Despite the progress in recent studies, it remains unanswered: whether
the existing studies have well solved this task (Q1) and whether the emerging
large language models (LLMs) can bring new opportunities to this task (Q2). To
this end, we propose a new benchmark PAGED, equipped with a large high-quality
dataset and standard evaluations. It investigates five state-of-the-art
baselines, revealing that they fail to extract optimal procedural graphs well
because of their heavy reliance on hand-written rules and limited available
data. We further involve three advanced LLMs in PAGED and enhance them with a
novel self-refine strategy. The results point out the advantages of LLMs in
identifying textual elements and their gaps in building logical structures. We
hope PAGED can serve as a major landmark for automatic procedural graph
extraction and the investigations in PAGED can offer insights into the research
on logic reasoning among non-sequential elements.

ÊëòË¶ÅÔºöËá™ÂãïÂæûÊñá‰ª∂‰∏≠ËêÉÂèñÁ®ãÂ∫èÂúñË°®ÊòØ‰∏ÄÁ®Æ‰ΩéÊàêÊú¨ÁöÑÊñπÂºèÔºåËÆì‰ΩøÁî®ËÄÖËÉΩÈÄèÈÅéÁÄèË¶ΩË¶ñË¶∫ÂåñÂúñË°®ÔºåËºïÈ¨ÜÁêÜËß£Ë§áÈõúÁöÑÁ®ãÂ∫è„ÄÇÂÑòÁÆ°ËøëÊúüÁ†îÁ©∂Â∑≤ÊúâÊâÄÈÄ≤Â±ïÔºå‰ΩÜ‰ªçÊúâÂæÖËß£Á≠îÁöÑÂïèÈ°åÔºöÁèæÊúâÁöÑÁ†îÁ©∂ÊòØÂê¶Â∑≤Â¶•ÂñÑËß£Ê±∫Ê≠§‰ªªÂãôÔºàQ1ÔºâÔºå‰ª•ÂèäÊñ∞ËààÁöÑÂ§ßË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâÊòØÂê¶ËÉΩÁÇ∫Ê≠§‰ªªÂãôÂ∏∂‰æÜÊñ∞ÁöÑÂ•ëÊ©üÔºàQ2Ôºâ„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÊñ∞ÁöÑÂü∫Ê∫ñ PAGEDÔºåÈÖçÂÇôÂ§ßÂûãÈ´òÂìÅË≥™Ë≥áÊñôÈõÜÂíåÊ®ôÊ∫ñË©ïÈáè„ÄÇÂÆÉÊé¢Ë®é‰∫Ü‰∫îÂÄãÊúÄÂÖàÈÄ≤ÁöÑÂü∫Á∑öÔºåÊè≠Á§∫‰∫ÜÂÆÉÂÄëÁÑ°Ê≥ïËâØÂ•ΩÂú∞ËêÉÂèñÊúÄ‰Ω≥Á®ãÂ∫èÂúñË°®ÔºåÂéüÂõ†Âú®ÊñºÂÆÉÂÄëÈÅéÂ∫¶‰æùË≥¥ÊâãÂØ´Ë¶èÂâáÂíåÊúâÈôêÁöÑÂèØÁî®Ë≥áÊñô„ÄÇÊàëÂÄëÈÄ≤‰∏ÄÊ≠•Âú® PAGED ‰∏≠Á¥çÂÖ•‰∏âÂÄãÂÖàÈÄ≤ÁöÑ LLMÔºå‰∏¶ÈÄèÈÅéÊñ∞Á©éÁöÑËá™Á≤æÈÄ≤Á≠ñÁï•Âä†‰ª•Âº∑Âåñ„ÄÇÁµêÊûúÊåáÂá∫ LLM Âú®Ë≠òÂà•ÊñáÊú¨ÂÖÉÁ¥†ÊñπÈù¢ÁöÑÂÑ™Âã¢Ôºå‰ª•ÂèäÂÆÉÂÄëÂú®Âª∫Á´ãÈÇèËºØÁµêÊßãÊñπÈù¢ÁöÑÂ∑ÆË∑ù„ÄÇÊàëÂÄëÂ∏åÊúõ PAGED ËÉΩÊàêÁÇ∫Ëá™ÂãïÁ®ãÂ∫èÂúñË°®ËêÉÂèñÁöÑ‰∏ªË¶ÅÈáåÁ®ãÁ¢ëÔºåËÄå PAGED ‰∏≠ÁöÑÊé¢Ë®éËÉΩÁÇ∫ÈùûÈ†ÜÂ∫èÂÖÉÁ¥†ÈñìÁöÑÈÇèËºØÊé®ÁêÜÁ†îÁ©∂Êèê‰æõË¶ãËß£„ÄÇ

##### **Optimus-1: Hybrid Multimodal Memory Empowered Agents Excel in Long-Horizon Tasks**
2408.03615v1 by Zaijing Li, Yuquan Xie, Rui Shao, Gongwei Chen, Dongmei Jiang, Liqiang Nie

Building a general-purpose agent is a long-standing vision in the field of
artificial intelligence. Existing agents have made remarkable progress in many
domains, yet they still struggle to complete long-horizon tasks in an open
world. We attribute this to the lack of necessary world knowledge and
multimodal experience that can guide agents through a variety of long-horizon
tasks. In this paper, we propose a Hybrid Multimodal Memory module to address
the above challenges. It 1) transforms knowledge into Hierarchical Directed
Knowledge Graph that allows agents to explicitly represent and learn world
knowledge, and 2) summarises historical information into Abstracted Multimodal
Experience Pool that provide agents with rich references for in-context
learning. On top of the Hybrid Multimodal Memory module, a multimodal agent,
Optimus-1, is constructed with dedicated Knowledge-guided Planner and
Experience-Driven Reflector, contributing to a better planning and reflection
in the face of long-horizon tasks in Minecraft. Extensive experimental results
show that Optimus-1 significantly outperforms all existing agents on
challenging long-horizon task benchmarks, and exhibits near human-level
performance on many tasks. In addition, we introduce various Multimodal Large
Language Models (MLLMs) as the backbone of Optimus-1. Experimental results show
that Optimus-1 exhibits strong generalization with the help of the Hybrid
Multimodal Memory module, outperforming the GPT-4V baseline on many tasks.

ÊëòË¶ÅÔºöÊâìÈÄ†‰∏ÄÂÄãÈÄöÁî®‰ª£ÁêÜÊòØ‰∫∫Â∑•Êô∫ÊÖßÈ†òÂüüÈï∑‰πÖ‰ª•‰æÜÁöÑÈ°òÊôØ„ÄÇÁèæÊúâÁöÑ‰ª£ÁêÜÂú®Ë®±Â§öÈ†òÂüüÈÉΩÊúâÈ°ØËëóÁöÑÈÄ≤Ê≠•Ôºå‰ΩÜÂÆÉÂÄë‰ªçÈõ£‰ª•Âú®ÈñãÊîæ‰∏ñÁïå‰∏≠ÂÆåÊàêÈï∑ÊôÇÁ®ã‰ªªÂãô„ÄÇÊàëÂÄëÂ∞áÊ≠§Ê≠∏Âõ†ÊñºÁº∫‰πèÂøÖË¶ÅÁöÑÁü•Ë≠òÂíåÂ§öÊ®°ÊÖãÁ∂ìÈ©óÔºåÈÄô‰∫õÁü•Ë≠òÂíåÁ∂ìÈ©óÂèØ‰ª•ÂºïÂ∞é‰ª£ÁêÜÂÆåÊàêÂêÑÁ®ÆÈï∑ÊôÇÁ®ã‰ªªÂãô„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÊ∑∑ÂêàÂ§öÊ®°ÊÖãË®òÊÜ∂È´îÊ®°ÁµÑ‰æÜËß£Ê±∫‰∏äËø∞ÊåëÊà∞„ÄÇÂÆÉ 1) Â∞áÁü•Ë≠òËΩâÊèõÁÇ∫ÈöéÂ±§ÂºèÂ∞éÂêëÁü•Ë≠òÂúñÔºåËÆì‰ª£ÁêÜËÉΩÂ§†ÊòéÁ¢∫Âú∞Ë°®Á§∫ÂíåÂ≠∏Áøí‰∏ñÁïåÁü•Ë≠òÔºå‰ª•Âèä 2) Â∞áÊ≠∑Âè≤Ë≥áË®äÊëòË¶ÅÊàêÊäΩË±°ÁöÑÂ§öÊ®°ÊÖãÁ∂ìÈ©óÊ±†ÔºåÁÇ∫‰ª£ÁêÜÊèê‰æõË±êÂØåÁöÑÂèÉËÄÉÔºå‰ª•‰æøÈÄ≤Ë°åÊÉÖÂ¢ÉÂ≠∏Áøí„ÄÇÂú®Ê∑∑ÂêàÂ§öÊ®°ÊÖãË®òÊÜ∂È´îÊ®°ÁµÑ‰πã‰∏äÔºåÂª∫Êßã‰∫Ü‰∏ÄÂÄãÂ§öÊ®°ÊÖã‰ª£ÁêÜÔºåOptimus-1ÔºåÂÆÉÂÖ∑ÂÇôÂ∞àÁî®ÁöÑÁü•Ë≠òÂ∞éÂêëË¶èÂäÉÂô®ÂíåÁ∂ìÈ©óÈ©ÖÂãïÁöÑÂèçÂ∞ÑÂô®ÔºåÊúâÂä©ÊñºÂú® Minecraft ‰∏≠Èù¢Â∞çÈï∑ÊôÇÁ®ã‰ªªÂãôÊôÇÈÄ≤Ë°åÊõ¥Â•ΩÁöÑË¶èÂäÉÂíåÂèçÊÄù„ÄÇÂª£Ê≥õÁöÑÂØ¶È©óÁµêÊûúÈ°ØÁ§∫ÔºåOptimus-1 Âú®ÂÖ∑ÊúâÊåëÊà∞ÊÄßÁöÑÈï∑ÊôÇÁ®ã‰ªªÂãôÂü∫Ê∫ñ‰∏äÈ°ØËëóÂÑ™ÊñºÊâÄÊúâÁèæÊúâ‰ª£ÁêÜÔºå‰∏¶‰∏îÂú®Ë®±Â§ö‰ªªÂãô‰∏äÂ±ïÁèæÂá∫Êé•Ëøë‰∫∫È°ûÁöÑÊïàËÉΩ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂºïÂÖ•ÂêÑÁ®ÆÂ§öÊ®°ÊÖãÂ§ßÂûãË™ûË®ÄÊ®°Âûã (MLLM) ‰ΩúÁÇ∫ Optimus-1 ÁöÑÈ™®Âππ„ÄÇÂØ¶È©óÁµêÊûúÈ°ØÁ§∫ÔºåOptimus-1 Âú®Ê∑∑ÂêàÂ§öÊ®°ÊÖãË®òÊÜ∂È´îÊ®°ÁµÑÁöÑÂπ´Âä©‰∏ãÂ±ïÁèæÂá∫Âº∑Â§ßÁöÑÊ≥õÂåñËÉΩÂäõÔºåÂú®Ë®±Â§ö‰ªªÂãô‰∏äÂÑ™Êñº GPT-4V Âü∫Ê∫ñ„ÄÇ

##### **Exploring the extent of similarities in software failures across industries using LLMs**
2408.03528v2 by Martin Detloff

The rapid evolution of software development necessitates enhanced safety
measures. Extracting information about software failures from companies is
becoming increasingly more available through news articles.
  This research utilizes the Failure Analysis Investigation with LLMs (FAIL)
model to extract industry-specific information. Although the FAIL model's
database is rich in information, it could benefit from further categorization
and industry-specific insights to further assist software engineers.
  In previous work news articles were collected from reputable sources and
categorized by incidents inside a database. Prompt engineering and Large
Language Models (LLMs) were then applied to extract relevant information
regarding the software failure. This research extends these methods by
categorizing articles into specific domains and types of software failures. The
results are visually represented through graphs.
  The analysis shows that throughout the database some software failures occur
significantly more often in specific industries. This categorization provides a
valuable resource for software engineers and companies to identify and address
common failures.
  This research highlights the synergy between software engineering and Large
Language Models (LLMs) to automate and enhance the analysis of software
failures. By transforming data from the database into an industry specific
model, we provide a valuable resource that can be used to identify common
vulnerabilities, predict potential risks, and implement proactive measures for
preventing software failures. Leveraging the power of the current FAIL database
and data visualization, we aim to provide an avenue for safer and more secure
software in the future.

ÊëòË¶ÅÔºö<paragraph>ËªüÈ´îÈñãÁôºÂø´ÈÄüÊºîÈÄ≤ÔºåËø´ÂàáÈúÄË¶ÅÂ¢ûÂº∑ÂÆâÂÖ®Êé™ÊñΩ„ÄÇÂæûÂÖ¨Âè∏Êñ∞ËÅûÊñáÁ´†‰∏≠ËêÉÂèñËªüÈ´îÊïÖÈöúË≥áË®äÊ≠£ËÆäÂæóË∂ä‰æÜË∂äÂÆπÊòì„ÄÇ
Ê≠§Á†îÁ©∂Âà©Áî®Â§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâÊïÖÈöúÂàÜÊûêË™øÊü•ÔºàFAILÔºâÊ®°ÂûãËêÉÂèñÁî¢Ê•≠ÁâπÂÆöË≥áË®ä„ÄÇÂÑòÁÆ° FAIL Ê®°ÂûãÁöÑË≥áÊñôÂ∫´Ë≥áË®äË±êÂØåÔºå‰ΩÜËã•ËÉΩÈÄ≤‰∏ÄÊ≠•ÂàÜÈ°û‰∏¶Êèê‰æõÁî¢Ê•≠ÁâπÂÆöË¶ãËß£ÔºåÂ∞áÊúâÂä©ÊñºËªüÈ´îÂ∑•Á®ãÂ∏´„ÄÇ
Âú®ÂÖàÂâçÁöÑÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄëÂæû‰ø°Ë≠ΩËâØÂ•ΩÁöÑ‰æÜÊ∫êÊî∂ÈõÜÊñ∞ËÅûÊñáÁ´†Ôºå‰∏¶Â∞áÂÖ∂ÂàÜÈ°ûÁÇ∫Ë≥áÊñôÂ∫´‰∏≠ÁöÑ‰∫ã‰ª∂„ÄÇÊé•ËëóÊáâÁî®ÊèêÁ§∫Â∑•Á®ãÂíåÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâËêÉÂèñËàáËªüÈ´îÊïÖÈöúÁõ∏ÈóúÁöÑË≥áË®ä„ÄÇÊ≠§Á†îÁ©∂ÈÄèÈÅéÂ∞áÊñáÁ´†ÂàÜÈ°ûÂà∞ÁâπÂÆöÈ†òÂüüÂíåËªüÈ´îÊïÖÈöúÈ°ûÂûãÔºåÂª∂‰º∏‰∫ÜÈÄô‰∫õÊñπÊ≥ï„ÄÇÁµêÊûúÈÄèÈÅéÂúñË°®Ë¶ñË¶∫ÂåñÂëàÁèæ„ÄÇ
ÂàÜÊûêÈ°ØÁ§∫ÔºåÂú®Êï¥ÂÄãË≥áÊñôÂ∫´‰∏≠ÔºåÊüê‰∫õËªüÈ´îÊïÖÈöúÂú®ÁâπÂÆöÁî¢Ê•≠‰∏≠ÁôºÁîüÁöÑÈ†ªÁéáÈ°ØËëóËºÉÈ´ò„ÄÇÊ≠§ÂàÜÈ°ûÁÇ∫ËªüÈ´îÂ∑•Á®ãÂ∏´ÂíåÂÖ¨Âè∏Êèê‰æõ‰∫ÜÂØ∂Ë≤¥ÁöÑË≥áÊ∫êÔºåÂèØË≠òÂà•‰∏¶Ëß£Ê±∫Â∏∏Ë¶ãÊïÖÈöú„ÄÇ
Ê≠§Á†îÁ©∂Âº∑Ë™ø‰∫ÜËªüÈ´îÂ∑•Á®ãËàáÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâ‰πãÈñìÁöÑÁ∂úÊïà‰ΩúÁî®ÔºåÂèØËá™ÂãïÂåñ‰∏¶Â¢ûÂº∑ËªüÈ´îÊïÖÈöúÂàÜÊûê„ÄÇÈÄèÈÅéÂ∞áË≥áÊñôÂ∫´‰∏≠ÁöÑË≥áÊñôËΩâÊèõÁÇ∫Áî¢Ê•≠ÁâπÂÆöÊ®°ÂûãÔºåÊàëÂÄëÊèê‰æõ‰∫Ü‰∏ÄÈ†ÖÂØ∂Ë≤¥ÁöÑË≥áÊ∫êÔºåÂèØÁî®ÊñºË≠òÂà•Â∏∏Ë¶ãÊºèÊ¥û„ÄÅÈ†êÊ∏¨ÊΩõÂú®È¢®Èö™Ôºå‰∏¶ÂØ¶ÊñΩ‰∏ªÂãïÊé™ÊñΩ‰æÜÈ†êÈò≤ËªüÈ´îÊïÖÈöú„ÄÇÊàëÂÄëÂà©Áî®ÁèæÊúâ FAIL Ë≥áÊñôÂ∫´ÂíåË≥áÊñôË¶ñË¶∫ÂåñÁöÑÂÑ™Âã¢ÔºåÊó®Âú®ÁÇ∫Êú™‰æÜÊèê‰æõÊõ¥ÂÆâÂÖ®‰∏îÁ©©ÂÆöÁöÑËªüÈ´î„ÄÇ</paragraph>

##### **Enhancing Complex Causality Extraction via Improved Subtask Interaction and Knowledge Fusion**
2408.03079v1 by Jinglong Gao, Chen Lu, Xiao Ding, Zhongyang Li, Ting Liu, Bing Qin

Event Causality Extraction (ECE) aims at extracting causal event pairs from
texts. Despite ChatGPT's recent success, fine-tuning small models remains the
best approach for the ECE task. However, existing fine-tuning based ECE methods
cannot address all three key challenges in ECE simultaneously: 1) Complex
Causality Extraction, where multiple causal-effect pairs occur within a single
sentence; 2) Subtask~ Interaction, which involves modeling the mutual
dependence between the two subtasks of ECE, i.e., extracting events and
identifying the causal relationship between extracted events; and 3) Knowledge
Fusion, which requires effectively fusing the knowledge in two modalities,
i.e., the expressive pretrained language models and the structured knowledge
graphs. In this paper, we propose a unified ECE framework (UniCE to address all
three issues in ECE simultaneously. Specifically, we design a subtask
interaction mechanism to enable mutual interaction between the two ECE
subtasks. Besides, we design a knowledge fusion mechanism to fuse knowledge in
the two modalities. Furthermore, we employ separate decoders for each subtask
to facilitate complex causality extraction. Experiments on three benchmark
datasets demonstrate that our method achieves state-of-the-art performance and
outperforms ChatGPT with a margin of at least 30% F1-score. More importantly,
our model can also be used to effectively improve the ECE performance of
ChatGPT via in-context learning.

ÊëòË¶ÅÔºö‰∫ã‰ª∂Âõ†ÊûúÈóú‰øÇËêÉÂèñ (ECE) ÁöÑÁõÆÊ®ôÊòØÂæûÊñáÊú¨‰∏≠ËêÉÂèñÂá∫Âõ†Êûú‰∫ã‰ª∂Â∞ç„ÄÇÂÑòÁÆ° ChatGPT ÊúÄËøëÁç≤ÂæóÊàêÂäüÔºåÂæÆË™øÂ∞èÂûãÊ®°Âûã‰ªçÊòØ ECE ‰ªªÂãôÁöÑÊúÄ‰Ω≥ÊñπÊ≥ï„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÁöÑÂü∫ÊñºÂæÆË™øÁöÑ ECE ÊñπÊ≥ïÁÑ°Ê≥ïÂêåÊôÇËß£Ê±∫ ECE ‰∏≠ÁöÑ‰∏âÂÄã‰∏ªË¶ÅÊåëÊà∞Ôºö1) Ë§áÈõúÂõ†ÊûúÈóú‰øÇËêÉÂèñÔºåÂÖ∂‰∏≠Â§öÂÄãÂõ†ÊûúÈóú‰øÇÂ∞çÂá∫ÁèæÂú®ÂñÆ‰∏ÄÂè•Â≠ê‰∏≠Ôºõ2) Â≠ê‰ªªÂãô‰∫íÂãïÔºåÈÄôÊ∂âÂèäÂ∞ç ECE ÁöÑÂÖ©ÂÄãÂ≠ê‰ªªÂãôÔºàÂç≥ËêÉÂèñ‰∫ã‰ª∂ÂíåË≠òÂà•ËêÉÂèñ‰∫ã‰ª∂‰πãÈñìÁöÑÂõ†ÊûúÈóú‰øÇÔºâ‰πãÈñìÁöÑÁõ∏‰∫í‰æùË≥¥ÊÄßÈÄ≤Ë°åÂª∫Ê®°Ôºõ3) Áü•Ë≠òËûçÂêàÔºåÈÄôÈúÄË¶ÅÊúâÊïàÂú∞ËûçÂêàÂÖ©Á®ÆÊ®°Âºè‰∏≠ÁöÑÁü•Ë≠òÔºåÂç≥Ë°®ÈÅîÂºèÁöÑÈ†êË®ìÁ∑¥Ë™ûË®ÄÊ®°ÂûãÂíåÁµêÊßãÂåñÁöÑÁü•Ë≠òÂúñË≠ú„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÁµ±‰∏ÄÁöÑ ECE Ê°ÜÊû∂ (UniCE)Ôºå‰ª•ÂêåÊôÇËß£Ê±∫ ECE ‰∏≠ÁöÑÊâÄÊúâ‰∏âÂÄãÂïèÈ°å„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëË®≠Ë®à‰∫Ü‰∏ÄÂÄãÂ≠ê‰ªªÂãô‰∫íÂãïÊ©üÂà∂Ôºå‰ª•ÂØ¶ÁèæÂÖ©ÂÄã ECE Â≠ê‰ªªÂãô‰πãÈñìÁöÑÁõ∏‰∫í‰∫íÂãï„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëË®≠Ë®à‰∫Ü‰∏ÄÂÄãÁü•Ë≠òËûçÂêàÊ©üÂà∂‰æÜËûçÂêàÂÖ©Á®ÆÊ®°Âºè‰∏≠ÁöÑÁü•Ë≠ò„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÈáùÂ∞çÊØèÂÄãÂ≠ê‰ªªÂãôÊé°Áî®ÂñÆÁç®ÁöÑËß£Á¢ºÂô®Ôºå‰ª•‰øÉÈÄ≤Ë§áÈõúÂõ†ÊûúÈóú‰øÇÁöÑËêÉÂèñ„ÄÇÂú®‰∏âÂÄãÂü∫Ê∫ñË≥áÊñôÈõÜ‰∏äÁöÑÂØ¶È©óË°®ÊòéÔºåÊàëÂÄëÁöÑÊñπÊ≥ïÈÅîÂà∞‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÊïàËÉΩÔºå‰∏¶‰∏î‰ª•Ëá≥Â∞ë 30% ÁöÑ F1 ÂàÜÊï∏ÂÑ™Êñº ChatGPT„ÄÇÊõ¥ÈáçË¶ÅÁöÑÊòØÔºåÊàëÂÄëÁöÑÊ®°Âûã‰πüÂèØ‰ª•ÈÄèÈÅéÊÉÖÂ¢ÉÂ≠∏ÁøíÊúâÊïàÂú∞ÊèêÂçá ChatGPT ÁöÑ ECE ÊïàËÉΩ„ÄÇ

##### **Fact Finder -- Enhancing Domain Expertise of Large Language Models by Incorporating Knowledge Graphs**
2408.03010v1 by Daniel Steinigen, Roman Teucher, Timm Heine Ruland, Max Rudat, Nicolas Flores-Herr, Peter Fischer, Nikola Milosevic, Christopher Schymura, Angelo Ziletti

Recent advancements in Large Language Models (LLMs) have showcased their
proficiency in answering natural language queries. However, their effectiveness
is hindered by limited domain-specific knowledge, raising concerns about the
reliability of their responses. We introduce a hybrid system that augments LLMs
with domain-specific knowledge graphs (KGs), thereby aiming to enhance factual
correctness using a KG-based retrieval approach. We focus on a medical KG to
demonstrate our methodology, which includes (1) pre-processing, (2) Cypher
query generation, (3) Cypher query processing, (4) KG retrieval, and (5)
LLM-enhanced response generation. We evaluate our system on a curated dataset
of 69 samples, achieving a precision of 78\% in retrieving correct KG nodes.
Our findings indicate that the hybrid system surpasses a standalone LLM in
accuracy and completeness, as verified by an LLM-as-a-Judge evaluation method.
This positions the system as a promising tool for applications that demand
factual correctness and completeness, such as target identification -- a
critical process in pinpointing biological entities for disease treatment or
crop enhancement. Moreover, its intuitive search interface and ability to
provide accurate responses within seconds make it well-suited for
time-sensitive, precision-focused research contexts. We publish the source code
together with the dataset and the prompt templates used.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊúÄÊñ∞ÈÄ≤Â±ïÂ±ïÁ§∫‰∫ÜÂÆÉÂÄëÂú®ÂõûÁ≠îËá™ÁÑ∂Ë™ûË®ÄÊü•Ë©¢ÊñπÈù¢ÁöÑËÉΩÂäõ„ÄÇÁÑ∂ËÄåÔºåÂÆÉÂÄëÁöÑÊúâÊïàÊÄßÂèóÂà∞ÁâπÂÆöÈ†òÂüüÁü•Ë≠òÊúâÈôêÁöÑÈòªÁ§ôÔºåÈÄôÂºïËµ∑‰∫ÜÂ∞çÂÖ∂ÂõûÊáâÂèØÈù†ÊÄßÁöÑÊìîÊÜÇ„ÄÇÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÊ∑∑ÂêàÁ≥ªÁµ±ÔºåË©≤Á≥ªÁµ±‰ΩøÁî®ÁâπÂÆöÈ†òÂüüÁöÑÁü•Ë≠òÂúñË≠ú (KG) ‰æÜÊì¥ÂÖÖ LLMÔºåÂæûËÄåÊó®Âú®‰ΩøÁî®Âü∫Êñº KG ÁöÑÊ™¢Á¥¢ÊñπÊ≥ï‰æÜÂ¢ûÂº∑‰∫ãÂØ¶Ê≠£Á¢∫ÊÄß„ÄÇÊàëÂÄëÂ∞àÊ≥®Êñº‰∏ÄÂÄãÈÜ´Â≠∏ KG ‰æÜÊºîÁ§∫ÊàëÂÄëÁöÑ methodologyÔºåÂÖ∂‰∏≠ÂåÖÊã¨ (1) È†êËôïÁêÜÔºå(2) Cypher Êü•Ë©¢ÁîüÊàêÔºå(3) Cypher Êü•Ë©¢ËôïÁêÜÔºå(4) KG Ê™¢Á¥¢Ôºå‰ª•Âèä (5) LLM Â¢ûÂº∑ÁöÑÂõûÊáâÁîüÊàê„ÄÇÊàëÂÄëÂú®‰∏ÄÂÄãÁî± 69 ÂÄãÊ®£Êú¨ÁµÑÊàêÁöÑÁ≤æÈÅ∏Êï∏ÊìöÈõÜ‰∏äË©ï‰º∞ÊàëÂÄëÁöÑÁ≥ªÁµ±ÔºåÂú®Ê™¢Á¥¢Ê≠£Á¢∫ÁöÑ KG ÁØÄÈªûÊôÇÈÅîÂà∞‰∫Ü 78% ÁöÑÁ≤æÂ∫¶„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúË°®ÊòéÔºåÊ∑∑ÂêàÁ≥ªÁµ±Âú®Ê∫ñÁ¢∫ÊÄßÂíåÂÆåÊï¥ÊÄßÊñπÈù¢ÈÉΩË∂ÖÈÅé‰∫ÜÂñÆÁç®ÁöÑ LLMÔºåÈÄôÈÄöÈÅé LLM ‰ΩúÁÇ∫Ë©ïÂØ©Ë©ï‰º∞ÊñπÊ≥ïÂæóÂà∞È©óË≠â„ÄÇÈÄôÂ∞áÁ≥ªÁµ±ÂÆö‰ΩçÁÇ∫Â∞çÊáâÁî®Á®ãÂºè‰æÜË™™‰∏ÄÂÄãÊúâÂâçÈÄîÁöÑÂ∑•ÂÖ∑ÔºåÈÄô‰∫õÊáâÁî®Á®ãÂºèÈúÄË¶Å‰∫ãÂØ¶Ê≠£Á¢∫ÊÄßÂíåÂÆåÊï¥ÊÄßÔºå‰æãÂ¶ÇÁõÆÊ®ôË≠òÂà•‚Äî‚ÄîÂú®ÁñæÁóÖÊ≤ªÁôÇÊàñ‰ΩúÁâ©ÊîπËâØ‰∏≠Á≤æÁ¢∫ÂÆö‰ΩçÁîüÁâ©ÂØ¶È´îÁöÑÈóúÈçµÈÅéÁ®ã„ÄÇÊ≠§Â§ñÔºåÂÖ∂Áõ¥ËßÄÁöÑÊêúÂ∞ã‰ªãÈù¢ÂíåÂú®Êï∏ÁßíÂÖßÊèê‰æõÊ∫ñÁ¢∫ÂõûÊáâÁöÑËÉΩÂäõ‰ΩøÂÖ∂ÈùûÂ∏∏ÈÅ©ÂêàÊôÇÈñìÊïèÊÑü„ÄÅÊ≥®ÈáçÁ≤æÁ¢∫Â∫¶ÁöÑÁ†îÁ©∂ÊÉÖÂ¢É„ÄÇÊàëÂÄëÂ∞áÂéüÂßãÁ¢ºËàáÊï∏ÊìöÈõÜÂíå‰ΩøÁî®ÁöÑÊèêÁ§∫ÁØÑÊú¨‰∏ÄËµ∑ÁôºÂ∏É„ÄÇ

##### **Leveraging Inter-Chunk Interactions for Enhanced Retrieval in Large Language Model-Based Question Answering**
2408.02907v1 by Tiezheng Guo, Chen Wang, Yanyi Liu, Jiawei Tang, Pan Li, Sai Xu, Qingwen Yang, Xianlin Gao, Zhi Li, Yingyou Wen

Retrieving external knowledge and prompting large language models with
relevant information is an effective paradigm to enhance the performance of
question-answering tasks. Previous research typically handles paragraphs from
external documents in isolation, resulting in a lack of context and ambiguous
references, particularly in multi-document and complex tasks. To overcome these
challenges, we propose a new retrieval framework IIER, that leverages
Inter-chunk Interactions to Enhance Retrieval. This framework captures the
internal connections between document chunks by considering three types of
interactions: structural, keyword, and semantic. We then construct a unified
Chunk-Interaction Graph to represent all external documents comprehensively.
Additionally, we design a graph-based evidence chain retriever that utilizes
previous paths and chunk interactions to guide the retrieval process. It
identifies multiple seed nodes based on the target question and iteratively
searches for relevant chunks to gather supporting evidence. This retrieval
process refines the context and reasoning chain, aiding the large language
model in reasoning and answer generation. Extensive experiments demonstrate
that IIER outperforms strong baselines across four datasets, highlighting its
effectiveness in improving retrieval and reasoning capabilities.

ÊëòË¶ÅÔºöÂèñÂæóÂ§ñÈÉ®Áü•Ë≠ò‰∏¶ÊèêÁ§∫Â§ßÂûãË™ûË®ÄÊ®°ÂûãÊèê‰æõÁõ∏ÈóúË≥áË®äÔºåÊòØÊèêÂçáÂïèÁ≠î‰ªªÂãôÊïàËÉΩÁöÑÊúâÊïàÂÖ∏ÁØÑ„ÄÇÂÖàÂâçÁöÑÁ†îÁ©∂ÈÄöÂ∏∏Â≠§Á´ãÂú∞ËôïÁêÜÂ§ñÈÉ®Êñá‰ª∂‰∏≠ÁöÑÊÆµËêΩÔºåÂ∞éËá¥Áº∫‰πèËÑàÁµ°ÂíåÊ®°Á®úÂÖ©ÂèØÁöÑÂèÉËÄÉÔºåÁâπÂà•ÊòØÂú®Â§öÊñá‰ª∂ÂíåË§áÈõúÁöÑ‰ªªÂãô‰∏≠„ÄÇÁÇ∫‰∫ÜÂÖãÊúçÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÊñ∞ÁöÑÊ™¢Á¥¢Êû∂Êßã IIERÔºåÂà©Áî®ÂçÄÂ°äÈñì‰∫íÂãï‰æÜÂ¢ûÂº∑Ê™¢Á¥¢„ÄÇÈÄôÂÄãÊû∂ÊßãÈÄèÈÅéËÄÉÈáè‰∏âÁ®ÆÈ°ûÂûãÁöÑ‰∫íÂãï‰æÜÊì∑ÂèñÊñá‰ª∂ÂçÄÂ°ä‰πãÈñìÁöÑÂÖßÈÉ®ÈÄ£ÁµêÔºöÁµêÊßã„ÄÅÈóúÈçµÂ≠óÂíåË™ûÊÑè„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÂª∫Êßã‰∏ÄÂÄãÁµ±‰∏ÄÁöÑÂçÄÂ°ä‰∫íÂãïÂúñÔºå‰ª•ÂÖ®Èù¢Ë°®Á§∫ÊâÄÊúâÂ§ñÈÉ®Êñá‰ª∂„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëË®≠Ë®à‰∏ÄÂÄãÂü∫ÊñºÂúñÂΩ¢ÁöÑË≠âÊìöÈèàÊ™¢Á¥¢Âô®ÔºåÂà©Áî®ÂÖàÂâçÁöÑË∑ØÂæëÂíåÂçÄÂ°ä‰∫íÂãï‰æÜÂºïÂ∞éÊ™¢Á¥¢Á®ãÂ∫è„ÄÇÂÆÉÊ†πÊìöÁõÆÊ®ôÂïèÈ°åË≠òÂà•Â§öÂÄãÁ®ÆÂ≠êÁØÄÈªûÔºå‰∏¶ÂèçË¶ÜÊêúÂ∞ãÁõ∏ÈóúÂçÄÂ°ä‰ª•Êî∂ÈõÜ‰ΩêË≠âË≠âÊìö„ÄÇÈÄôÂÄãÊ™¢Á¥¢Á®ãÂ∫èÁ≤æÁÖâ‰∫ÜËÑàÁµ°ÂíåÊé®ÁêÜÈèàÔºåÂçîÂä©Â§ßÂûãË™ûË®ÄÊ®°ÂûãÈÄ≤Ë°åÊé®ÁêÜÂíåÁ≠îÊ°àÁî¢Áîü„ÄÇÂª£Ê≥õÁöÑÂØ¶È©óË≠âÊòéÔºåIIER Âú®ÂõõÂÄãË≥áÊñôÈõÜ‰∏äÂÑ™ÊñºÂº∑Â§ßÁöÑÂü∫Ê∫ñÔºåÁ™ÅÈ°ØÂÖ∂Âú®ÊîπÂñÑÊ™¢Á¥¢ÂíåÊé®ÁêÜËÉΩÂäõÊñπÈù¢ÁöÑÊïàËÉΩ„ÄÇ

##### **MaterioMiner -- An ontology-based text mining dataset for extraction of process-structure-property entities**
2408.04661v1 by Ali Riza Durmaz, Akhil Thomas, Lokesh Mishra, Rachana Niranjan Murthy, Thomas Straub

While large language models learn sound statistical representations of the
language and information therein, ontologies are symbolic knowledge
representations that can complement the former ideally. Research at this
critical intersection relies on datasets that intertwine ontologies and text
corpora to enable training and comprehensive benchmarking of neurosymbolic
models. We present the MaterioMiner dataset and the linked materials mechanics
ontology where ontological concepts from the mechanics of materials domain are
associated with textual entities within the literature corpus. Another
distinctive feature of the dataset is its eminently fine-granular annotation.
Specifically, 179 distinct classes are manually annotated by three raters
within four publications, amounting to a total of 2191 entities that were
annotated and curated. Conceptual work is presented for the symbolic
representation of causal composition-process-microstructure-property
relationships. We explore the annotation consistency between the three raters
and perform fine-tuning of pre-trained models to showcase the feasibility of
named-entity recognition model training. Reusing the dataset can foster
training and benchmarking of materials language models, automated ontology
construction, and knowledge graph generation from textual data.

ÊëòË¶ÅÔºö<paragraph>Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÂ≠¶‰π†ËØ≠Ë®ÄÂíåÂÖ∂‰∏≠‰ø°ÊÅØÁöÑÂÅ•ÂÖ®ÁªüËÆ°Ë°®Á§∫ÔºåÊú¨‰ΩìÊòØÁ¨¶Âè∑Áü•ËØÜË°®Á§∫ÔºåÁêÜÊÉ≥ÊÉÖÂÜµ‰∏ãÂèØ‰ª•Ë°•ÂÖÖÂâçËÄÖ„ÄÇÂú®Ëøô‰∏™ÂÖ≥ÈîÆ‰∫§ÂèâÁÇπ‰∏äÁöÑÁ†îÁ©∂‰æùËµñ‰∫éÂ∞ÜÊú¨‰ΩìÂíåÊñáÊú¨ËØ≠ÊñôÂ∫ì‰∫§ÁªáÂú®‰∏ÄËµ∑ÁöÑÊï∞ÊçÆÈõÜÔºå‰ª•ÂÆûÁé∞Á•ûÁªèÁ¨¶Âè∑Ê®°ÂûãÁöÑËÆ≠ÁªÉÂíåÂÖ®Èù¢Âü∫ÂáÜÊµãËØï„ÄÇÊàë‰ª¨Â±ïÁ§∫‰∫Ü MaterioMiner Êï∞ÊçÆÈõÜÂíåÈìæÊé•ÁöÑÊùêÊñôÂäõÂ≠¶Êú¨‰ΩìÔºåÂÖ∂‰∏≠ÊùêÊñôÂäõÂ≠¶È¢ÜÂüüÁöÑÊú¨‰ΩìÊ¶ÇÂøµ‰∏éÊñáÁåÆËØ≠ÊñôÂ∫ì‰∏≠ÁöÑÊñáÊú¨ÂÆû‰ΩìÁõ∏ÂÖ≥ËÅî„ÄÇËØ•Êï∞ÊçÆÈõÜÁöÑÂè¶‰∏Ä‰∏™ÊòæÁùÄÁâπÂæÅÊòØÂÖ∂ÊûÅÂÖ∂ÁªÜÁ≤íÂ∫¶ÁöÑÊ≥®Èáä„ÄÇÂÖ∑‰ΩìÊù•ËØ¥Ôºå179 ‰∏™‰∏çÂêåÁöÑÁ±ªÂà´Áî±‰∏â‰∏™ËØÑÁ∫ßÂëòÂú®ÂõõÁØáÂá∫ÁâàÁâ©‰∏≠ÊâãÂä®Ê≥®ÈáäÔºåÊÄªÂÖ±Ê≥®ÈáäÂíåÊï¥ÁêÜ‰∫Ü 2191 ‰∏™ÂÆû‰Ωì„ÄÇÊèêÂá∫‰∫ÜÂõ†ÊûúÊàêÂàÜ-ËøáÁ®ã-ÂæÆËßÇÁªìÊûÑ-ÊÄßË¥®ÂÖ≥Á≥ªÁöÑÁ¨¶Âè∑Ë°®Á§∫ÁöÑÊ¶ÇÂøµÊÄßÂ∑•‰Ωú„ÄÇÊàë‰ª¨Êé¢ËÆ®‰∫Ü‰∏â‰∏™ËØÑÁ∫ßÂëò‰πãÈó¥ÁöÑÊ≥®Èáä‰∏ÄËá¥ÊÄßÔºåÂπ∂ÂØπÈ¢ÑËÆ≠ÁªÉÊ®°ÂûãËøõË°åÂæÆË∞ÉÔºå‰ª•Â±ïÁ§∫ÂëΩÂêçÂÆû‰ΩìËØÜÂà´Ê®°ÂûãËÆ≠ÁªÉÁöÑÂèØË°åÊÄß„ÄÇÈáçÂ§ç‰ΩøÁî®ËØ•Êï∞ÊçÆÈõÜÂèØ‰ª•‰øÉËøõÊùêÊñôËØ≠Ë®ÄÊ®°ÂûãÁöÑËÆ≠ÁªÉÂíåÂü∫ÂáÜÊµãËØï„ÄÅËá™Âä®Êú¨‰ΩìÊûÑÂª∫‰ª•ÂèäÂü∫‰∫éÊñáÊú¨Êï∞ÊçÆÁöÑÁü•ËØÜÂõæË∞±ÁîüÊàê„ÄÇ</paragraph>

##### **Enhancing Supply Chain Visibility with Knowledge Graphs and Large Language Models**
2408.07705v1 by Sara AlMahri, Liming Xu, Alexandra Brintrup

In today's globalized economy, comprehensive supply chain visibility is
crucial for effective risk management. Achieving visibility remains a
significant challenge due to limited information sharing among supply chain
partners. This paper presents a novel framework leveraging Knowledge Graphs
(KGs) and Large Language Models (LLMs) to enhance supply chain visibility
without relying on direct stakeholder information sharing. Our zero-shot,
LLM-driven approach automates the extraction of supply chain information from
diverse public sources and constructs KGs to capture complex interdependencies
between supply chain entities. We employ zero-shot prompting for Named Entity
Recognition (NER) and Relation Extraction (RE) tasks, eliminating the need for
extensive domain-specific training. We validate the framework with a case study
on electric vehicle supply chains, focusing on tracking critical minerals for
battery manufacturing. Results show significant improvements in supply chain
mapping, extending visibility beyond tier-2 suppliers. The framework reveals
critical dependencies and alternative sourcing options, enhancing risk
management and strategic planning. With high accuracy in NER and RE tasks, it
provides an effective tool for understanding complex, multi-tiered supply
networks. This research offers a scalable, flexible method for constructing
domain-specific supply chain KGs, addressing longstanding challenges in
visibility and paving the way for advancements in digital supply chain
surveillance.

ÊëòË¶ÅÔºö<paragraph>Âú®Áï∂‰ªäÂÖ®ÁêÉÂåñÁöÑÁ∂ìÊøü‰∏≠ÔºåÂÖ®Èù¢ÁöÑ‰æõÊáâÈèàÂèØË¶ãÊÄßÂ∞çÊñºÊúâÊïàÁöÑÈ¢®Èö™ÁÆ°ÁêÜËá≥ÈóúÈáçË¶Å„ÄÇÁî±Êñº‰æõÊáâÈèàÂêà‰ΩúÂ§•‰º¥‰πãÈñìÁöÑË≥áË®äÂÖ±‰∫´ÊúâÈôêÔºåÂõ†Ê≠§ÂØ¶ÁèæÂèØË¶ãÊÄß‰ªçÁÑ∂ÊòØ‰∏ÄÈ†ÖÈáçÂ§ßÁöÑÊåëÊà∞„ÄÇÊú¨ÊñáÊèêÂá∫‰∫ÜÂà©Áî®Áü•Ë≠òÂúñË≠ú (KG) ÂíåÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊñ∞Ê°ÜÊû∂Ôºå‰ª•Â¢ûÂº∑‰æõÊáâÈèàÂèØË¶ãÊÄßÔºåËÄåÁÑ°ÈúÄ‰æùË≥¥Áõ¥Êé•ÁöÑÂà©ÁõäÁõ∏ÈóúËÄÖË≥áË®äÂÖ±‰∫´„ÄÇÊàëÂÄëÈõ∂Ê¨°Â≠∏Áøí„ÄÅLLM È©ÖÂãïÁöÑÊñπÊ≥ïËá™ÂãïÂåñ‰∫ÜÂæûÂêÑÁ®ÆÂÖ¨Èñã‰æÜÊ∫ê‰∏≠ÊèêÂèñ‰æõÊáâÈèàË≥áË®äÁöÑÈÅéÁ®ãÔºå‰∏¶ÊßãÂª∫ KG ‰ª•ÊçïÊçâ‰æõÊáâÈèàÂØ¶È´î‰πãÈñìÁöÑË§áÈõúÁõ∏‰∫í‰æùË≥¥ÊÄß„ÄÇÊàëÂÄëÊé°Áî®Èõ∂Ê¨°Â≠∏ÁøíÊèêÁ§∫ÈÄ≤Ë°åÂëΩÂêçÂØ¶È´îË≠òÂà• (NER) ÂíåÈóú‰øÇÊèêÂèñ (RE) ‰ªªÂãôÔºåÊ∂àÈô§‰∫ÜÂ∞çÂª£Ê≥õÁöÑÁâπÂÆöÈ†òÂüüË®ìÁ∑¥ÁöÑÈúÄÊ±Ç„ÄÇÊàëÂÄë‰ΩøÁî®ÈõªÂãïËªä‰æõÊáâÈèàÁöÑÊ°à‰æãÁ†îÁ©∂È©óË≠â‰∫ÜË©≤Ê°ÜÊû∂ÔºåÈáçÈªûÈóúÊ≥®ËøΩËπ§ÈõªÊ±†Ë£ΩÈÄ†ÁöÑÈóúÈçµÁ§¶Áâ©„ÄÇÁµêÊûúÈ°ØÁ§∫‰æõÊáâÈèàÂ∞çÊáâÈ°ØËëóÊîπÂñÑÔºåÂèØË¶ãÊÄßÊì¥Â±ïÂà∞‰∫åÈöé‰æõÊáâÂïÜ‰ª•Â§ñ„ÄÇË©≤Ê°ÜÊû∂Êè≠Á§∫‰∫ÜÈóúÈçµ‰æùË≥¥ÊÄßÂíåÊõø‰ª£Êé°Ë≥ºÈÅ∏È†ÖÔºåÂ¢ûÂº∑‰∫ÜÈ¢®Èö™ÁÆ°ÁêÜÂíåÁ≠ñÁï•Ë¶èÂäÉ„ÄÇÁî±Êñº NER Âíå RE ‰ªªÂãôÂÖ∑ÊúâÂæàÈ´òÁöÑÊ∫ñÁ¢∫ÊÄßÔºåÂõ†Ê≠§ÂÆÉÊèê‰æõ‰∫Ü‰∏ÄÂÄãÊúâÊïàÁöÑÂ∑•ÂÖ∑ÔºåÁî®Êñº‰∫ÜËß£Ë§áÈõúÁöÑÂ§öÂ±§‰æõÊáâÁ∂≤Ë∑Ø„ÄÇÊú¨Á†îÁ©∂Êèê‰æõ‰∫Ü‰∏ÄÁ®ÆÂèØÊì¥ÂÖÖ„ÄÅÈùàÊ¥ªÁöÑÊñπÊ≥ï‰æÜÊßãÂª∫ÁâπÂÆöÈ†òÂüüÁöÑ‰æõÊáâÈèà KGÔºåËß£Ê±∫‰∫ÜÂèØË¶ãÊÄßÁöÑÈï∑ÊúüÊåëÊà∞Ôºå‰∏¶ÁÇ∫Êï∏‰Ωç‰æõÊáâÈèàÁõ£ÊéßÁöÑÈÄ≤Ê≠•Èã™Âπ≥‰∫ÜÈÅìË∑Ø„ÄÇ</paragraph>

##### **A Few-Shot Approach for Relation Extraction Domain Adaptation using Large Language Models**
2408.02377v1 by Vanni Zavarella, Juan Carlos Gamero-Salinas, Sergio Consoli

Knowledge graphs (KGs) have been successfully applied to the analysis of
complex scientific and technological domains, with automatic KG generation
methods typically building upon relation extraction models capturing
fine-grained relations between domain entities in text. While these relations
are fully applicable across scientific areas, existing models are trained on
few domain-specific datasets such as SciERC and do not perform well on new
target domains. In this paper, we experiment with leveraging in-context
learning capabilities of Large Language Models to perform schema-constrained
data annotation, collecting in-domain training instances for a
Transformer-based relation extraction model deployed on titles and abstracts of
research papers in the Architecture, Construction, Engineering and Operations
(AECO) domain. By assessing the performance gain with respect to a baseline
Deep Learning architecture trained on off-domain data, we show that by using a
few-shot learning strategy with structured prompts and only minimal expert
annotation the presented approach can potentially support domain adaptation of
a science KG generation model.

ÊëòË¶ÅÔºöÁü•Ë≠òÂúñË≠ú (KG) Â∑≤ÊàêÂäüÊáâÁî®ÊñºÂàÜÊûêË§áÈõúÁöÑÁßëÂ≠∏ÊäÄË°ìÈ†òÂüüÔºåËá™Âãï KG ÁîüÊàêÊñπÊ≥ïÈÄöÂ∏∏Âª∫ÊßãÊñºÈóú‰øÇËêÉÂèñÊ®°Âûã‰∏äÔºåÊçïÊçâÊñáÊú¨‰∏≠È†òÂüüÂØ¶È´î‰πãÈñìÁöÑÁ¥∞Á≤íÂ∫¶Èóú‰øÇ„ÄÇÈõñÁÑ∂ÈÄô‰∫õÈóú‰øÇÂÆåÂÖ®ÈÅ©Áî®ÊñºÂêÑÁßëÂ≠∏È†òÂüüÔºå‰ΩÜÁèæÊúâÊ®°ÂûãÊòØÁî® SciERC Á≠âÂ∞ëÊï∏ÁâπÂÆöÈ†òÂüüÁöÑË≥áÊñôÈõÜË®ìÁ∑¥ÔºåËÄå‰∏îÂú®Êñ∞ÁõÆÊ®ôÈ†òÂüüÁöÑË°®Áèæ‰∏ç‰Ω≥„ÄÇÂú®Êú¨Ë´ñÊñá‰∏≠ÔºåÊàëÂÄëÂòóË©¶Âà©Áî®Â§ßÂûãË™ûË®ÄÊ®°ÂûãÁöÑËÑàÁµ°Â≠∏ÁøíËÉΩÂäõÔºåÂü∑Ë°åÂèóÊû∂ÊßãÁ¥ÑÊùüÁöÑË≥áÊñôÊ®ôË®ªÔºåÊî∂ÈõÜÈ†òÂüüÂÖßË®ìÁ∑¥ÂØ¶‰æãÔºåÁî®ÊñºÈÉ®ÁΩ≤Âú®Âª∫ÁØâ„ÄÅÁáüÈÄ†„ÄÅÂ∑•Á®ãÂíåÁáüÈÅã (AECO) È†òÂüüÁ†îÁ©∂Ë´ñÊñáÊ®ôÈ°åÂíåÊëòË¶ÅÁöÑÂü∫Êñº Transformer ÁöÑÈóú‰øÇËêÉÂèñÊ®°Âûã„ÄÇÈÄèÈÅéË©ï‰º∞Áõ∏Â∞çÊñºÂú®È†òÂüüÂ§ñË≥áÊñô‰∏äË®ìÁ∑¥ÁöÑÂü∫Ê∫ñÊ∑±Â∫¶Â≠∏ÁøíÊû∂ÊßãÁöÑÊïàËÉΩÊèêÂçáÔºåÊàëÂÄëÂ±ïÁ§∫ÈÄèÈÅé‰ΩøÁî®Â∏∂ÊúâÁµêÊßãÂåñÊèêÁ§∫ÁöÑÂ∞ëÈáèÂ≠∏ÁøíÁ≠ñÁï•Ôºå‰ª•ÂèäÂÉÖÊúÄÂ∞ëÁöÑÂ∞àÂÆ∂Ê®ôË®ªÔºåÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÊúâÂèØËÉΩÊîØÊè¥ÁßëÂ≠∏ KG ÁîüÊàêÊ®°ÂûãÁöÑÈ†òÂüüÈÅ©Êáâ„ÄÇ

##### **Developing PUGG for Polish: A Modern Approach to KBQA, MRC, and IR Dataset Construction**
2408.02337v1 by Albert Sawczyn, Katsiaryna Viarenich, Konrad Wojtasik, Aleksandra Domoga≈Ça, Marcin Oleksy, Maciej Piasecki, Tomasz Kajdanowicz

Advancements in AI and natural language processing have revolutionized
machine-human language interactions, with question answering (QA) systems
playing a pivotal role. The knowledge base question answering (KBQA) task,
utilizing structured knowledge graphs (KG), allows for handling extensive
knowledge-intensive questions. However, a significant gap exists in KBQA
datasets, especially for low-resource languages. Many existing construction
pipelines for these datasets are outdated and inefficient in human labor, and
modern assisting tools like Large Language Models (LLM) are not utilized to
reduce the workload. To address this, we have designed and implemented a
modern, semi-automated approach for creating datasets, encompassing tasks such
as KBQA, Machine Reading Comprehension (MRC), and Information Retrieval (IR),
tailored explicitly for low-resource environments. We executed this pipeline
and introduced the PUGG dataset, the first Polish KBQA dataset, and novel
datasets for MRC and IR. Additionally, we provide a comprehensive
implementation, insightful findings, detailed statistics, and evaluation of
baseline models.

ÊëòË¶ÅÔºö‰∫∫Â∑•Êô∫ËÉΩÂíåËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜÁöÑÈÄ≤Â±ïÂæπÂ∫ïÊîπËÆä‰∫ÜÊ©üÂô®Ëàá‰∫∫È°ûÁöÑË™ûË®Ä‰∫íÂãïÔºåÂÖ∂‰∏≠ÂïèÁ≠î (QA) Á≥ªÁµ±ÊâÆÊºî‰∫ÜÈóúÈçµËßíËâ≤„ÄÇÁü•Ë≠òÂ∫´ÂïèÁ≠î (KBQA) ‰ªªÂãôÂà©Áî®ÁµêÊßãÂåñÁöÑÁü•Ë≠òÂúñË≠ú (KG)ÔºåÂèØ‰ª•ËôïÁêÜÂ§ßÈáèÁöÑÁü•Ë≠òÂØÜÈõÜÂûãÂïèÈ°å„ÄÇÁÑ∂ËÄåÔºåKBQA Ë≥áÊñôÈõÜÂ≠òÂú®ËëóÈ°ØËëóÁöÑÂ∑ÆË∑ùÔºåÁâπÂà•ÊòØÂ∞çÊñº‰ΩéË≥áÊ∫êË™ûË®Ä„ÄÇË®±Â§öÁèæÊúâÁöÑÈÄô‰∫õË≥áÊñôÈõÜÂª∫ÊßãÁÆ°ÈÅìÂ∑≤Á∂ìÈÅéÊôÇ‰∏îÂú®‰∫∫Âäõ‰∏äÊïàÁéá‰Ωé‰∏ãÔºåËÄåÂÉèÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÈÄôÊ®£ÁöÑÁèæ‰ª£ËºîÂä©Â∑•ÂÖ∑‰∏¶Êú™Ë¢´Áî®ÊñºÊ∏õÂ∞ëÂ∑•‰ΩúË≤†Ëºâ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëË®≠Ë®à‰∏¶ÂØ¶‰Ωú‰∫Ü‰∏ÄÁ®ÆÁèæ‰ª£ÁöÑÂçäËá™ÂãïÂåñÊñπÊ≥ï‰æÜÂª∫Á´ãË≥áÊñôÈõÜÔºåÊ∂µËìã‰∫ÜÂ∞àÈñÄÈáùÂ∞ç‰ΩéË≥áÊ∫êÁí∞Â¢ÉÈáèË∫´ÊâìÈÄ†ÁöÑ‰ªªÂãôÔºå‰æãÂ¶Ç KBQA„ÄÅÊ©üÂô®Èñ±ËÆÄÁêÜËß£ (MRC) ÂíåË≥áË®äÊ™¢Á¥¢ (IR)„ÄÇÊàëÂÄëÂü∑Ë°å‰∫ÜÈÄôÂÄãÁÆ°ÈÅì‰∏¶ÂºïÂÖ•‰∫Ü PUGG Ë≥áÊñôÈõÜÔºåÈÄôÊòØÁ¨¨‰∏ÄÂÄãÊ≥¢Ëò≠ KBQA Ë≥áÊñôÈõÜÔºå‰ª•Âèä MRC Âíå IR ÁöÑÊñ∞Á©éË≥áÊñôÈõÜ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèê‰æõ‰∫ÜÂÖ®Èù¢ÁöÑÂØ¶‰Ωú„ÄÅÊúâË¶ãÂú∞ÁöÑÁôºÁèæ„ÄÅË©≥Á¥∞ÁöÑÁµ±Ë®àË≥áÊñôÂíåÂü∫Ê∫ñÊ®°ÂûãÁöÑË©ï‰º∞„ÄÇ

##### **MedSyn: LLM-based Synthetic Medical Text Generation Framework**
2408.02056v1 by Gleb Kumichev, Pavel Blinov, Yulia Kuzkina, Vasily Goncharov, Galina Zubkova, Nikolai Zenovkin, Aleksei Goncharov, Andrey Savchenko

Generating synthetic text addresses the challenge of data availability in
privacy-sensitive domains such as healthcare. This study explores the
applicability of synthetic data in real-world medical settings. We introduce
MedSyn, a novel medical text generation framework that integrates large
language models with a Medical Knowledge Graph (MKG). We use MKG to sample
prior medical information for the prompt and generate synthetic clinical notes
with GPT-4 and fine-tuned LLaMA models. We assess the benefit of synthetic data
through application in the ICD code prediction task. Our research indicates
that synthetic data can increase the classification accuracy of vital and
challenging codes by up to 17.8% compared to settings without synthetic data.
Furthermore, to provide new data for further research in the healthcare domain,
we present the largest open-source synthetic dataset of clinical notes for the
Russian language, comprising over 41k samples covering 219 ICD-10 codes.

ÊëòË¶ÅÔºöÂêàÊàêÊñáÊú¨ÁöÑÁîüÊàêËß£ÂÜ≥‰∫ÜÈöêÁßÅÊïèÊÑüÈ¢ÜÂüüÔºàÂ¶ÇÂåªÁñó‰øùÂÅ•Ôºâ‰∏≠Êï∞ÊçÆÂèØÁî®ÊÄßÁöÑÊåëÊàò„ÄÇÊú¨Á†îÁ©∂Êé¢ËÆ®‰∫ÜÂêàÊàêÊï∞ÊçÆÂú®ÂÆûÈôÖÂåªÁñóÁéØÂ¢É‰∏≠ÁöÑÈÄÇÁî®ÊÄß„ÄÇÊàë‰ª¨ÂºïÂÖ•‰∫Ü MedSynÔºåËøôÊòØ‰∏Ä‰∏™Êñ∞È¢ñÁöÑÂåªÂ≠¶ÊñáÊú¨ÁîüÊàêÊ°ÜÊû∂ÔºåÂÆÉÂ∞ÜÂ§ßÂûãËØ≠Ë®ÄÊ®°Âûã‰∏éÂåªÂ≠¶Áü•ËØÜÂõæË∞± (MKG) Áõ∏ÁªìÂêà„ÄÇÊàë‰ª¨‰ΩøÁî® MKG ‰∏∫ÊèêÁ§∫ÈááÊ†∑ÂÖàÈ™åÂåªÂ≠¶‰ø°ÊÅØÔºåÂπ∂‰ΩøÁî® GPT-4 ÂíåÂæÆË∞ÉÁöÑ LLaMA Ê®°ÂûãÁîüÊàêÂêàÊàê‰∏¥Â∫äÊ≥®Èáä„ÄÇÊàë‰ª¨ÈÄöËøáÂú® ICD ‰ª£Á†ÅÈ¢ÑÊµã‰ªªÂä°‰∏≠ÁöÑÂ∫îÁî®ËØÑ‰º∞‰∫ÜÂêàÊàêÊï∞ÊçÆÁöÑ‰ºòÂäø„ÄÇÊàë‰ª¨ÁöÑÁ†îÁ©∂Ë°®ÊòéÔºå‰∏éÊ≤°ÊúâÂêàÊàêÊï∞ÊçÆÁöÑËÆæÁΩÆÁõ∏ÊØîÔºåÂêàÊàêÊï∞ÊçÆÂèØ‰ª•Â∞ÜÈáçË¶Å‰∏îÂÖ∑ÊúâÊåëÊàòÊÄßÁöÑ‰ª£Á†ÅÁöÑÂàÜÁ±ªÂáÜÁ°ÆÊÄßÊèêÈ´òÂ§öËææ 17.8%„ÄÇÊ≠§Â§ñÔºå‰∏∫‰∫Ü‰∏∫ÂåªÁñó‰øùÂÅ•È¢ÜÂüüÁöÑËøõ‰∏ÄÊ≠•Á†îÁ©∂Êèê‰æõÊñ∞Êï∞ÊçÆÔºåÊàë‰ª¨Â±ïÁ§∫‰∫ÜÊúÄÂ§ßÁöÑÂºÄÊîæÊ∫ê‰ª£Á†ÅÂêàÊàêÊï∞ÊçÆÈõÜÔºåÂÖ∂‰∏≠ÂåÖÂê´Ë∂ÖËøá 41k ‰∏™Ê∂µÁõñ 219 ‰∏™ ICD-10 ‰ª£Á†ÅÁöÑ‰∏¥Â∫äÊ≥®Èáä„ÄÇ

##### **DiReCT: Diagnostic Reasoning for Clinical Notes via Large Language Models**
2408.01933v2 by Bowen Wang, Jiuyang Chang, Yiming Qian, Guoxin Chen, Junhao Chen, Zhouqiang Jiang, Jiahao Zhang, Yuta Nakashima, Hajime Nagahara

Large language models (LLMs) have recently showcased remarkable capabilities,
spanning a wide range of tasks and applications, including those in the medical
domain. Models like GPT-4 excel in medical question answering but may face
challenges in the lack of interpretability when handling complex tasks in real
clinical settings. We thus introduce the diagnostic reasoning dataset for
clinical notes (DiReCT), aiming at evaluating the reasoning ability and
interpretability of LLMs compared to human doctors. It contains 511 clinical
notes, each meticulously annotated by physicians, detailing the diagnostic
reasoning process from observations in a clinical note to the final diagnosis.
Additionally, a diagnostic knowledge graph is provided to offer essential
knowledge for reasoning, which may not be covered in the training data of
existing LLMs. Evaluations of leading LLMs on DiReCT bring out a significant
gap between their reasoning ability and that of human doctors, highlighting the
critical need for models that can reason effectively in real-world clinical
scenarios.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÊúÄËøëÂ±ïÁ§∫‰∫ÜÈùûÂá°ÁöÑËÉΩÂäõÔºåÊ∂µËìãÂª£Ê≥õÁöÑ‰ªªÂãôÂíåÊáâÁî®ÔºåÂåÖÊã¨ÈÜ´ÁôÇÈ†òÂüüÁöÑ‰ªªÂãôÂíåÊáâÁî®„ÄÇGPT-4 Á≠âÊ®°ÂûãÂú®ÈÜ´ÁôÇÂïèÈ°åËß£Á≠îÊñπÈù¢Ë°®ÁèæÂá∫Ëâ≤Ôºå‰ΩÜÂú®ËôïÁêÜÂØ¶ÈöõËá®Â∫äÂ†¥ÊôØ‰∏≠ÁöÑË§áÈõú‰ªªÂãôÊôÇÔºåÂèØËÉΩÊúÉÈù¢Ëá®Áº∫‰πèÂèØËß£ÈáãÊÄßÁöÑÊåëÊà∞„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜËá®Â∫äÁ≠ÜË®òË®∫Êñ∑Êé®ÁêÜÊï∏ÊìöÈõÜ (DiReCT)ÔºåÊó®Âú®Ë©ï‰º∞ LLM Ëàá‰∫∫È°ûÈÜ´ÁîüÁõ∏ÊØîÁöÑÊé®ÁêÜËÉΩÂäõÂíåÂèØËß£ÈáãÊÄß„ÄÇÂÆÉÂåÖÂê´ 511 ÂÄãËá®Â∫äÁ≠ÜË®òÔºåÊØèÂÄãÁ≠ÜË®òÈÉΩÁ∂ìÈÅéÈÜ´Áîü‰ªîÁ¥∞Ë®ªËß£ÔºåË©≥Á¥∞Ë™™Êòé‰∫ÜÂæûËá®Â∫äÁ≠ÜË®ò‰∏≠ÁöÑËßÄÂØüÁµêÊûúÂà∞ÊúÄÁµÇË®∫Êñ∑ÁöÑË®∫Êñ∑Êé®ÁêÜÈÅéÁ®ã„ÄÇÊ≠§Â§ñÔºåÈÇÑÊèê‰æõ‰∫ÜË®∫Êñ∑Áü•Ë≠òÂúñË≠úÔºå‰ª•Êèê‰æõÊé®ÁêÜÊâÄÈúÄÁöÑÂü∫Êú¨Áü•Ë≠òÔºåÈÄôÂèØËÉΩÊú™Ê∂µËìãÂú®ÁèæÊúâ LLM ÁöÑË®ìÁ∑¥Êï∏Êìö‰∏≠„ÄÇÂú® DiReCT ‰∏äÂ∞çÈ†òÂÖàÁöÑ LLM ÈÄ≤Ë°åË©ï‰º∞ÔºåÁôºÁèæÂÆÉÂÄëÁöÑÊé®ÁêÜËÉΩÂäõËàá‰∫∫È°ûÈÜ´ÁîüÁöÑÊé®ÁêÜËÉΩÂäõ‰πãÈñìÂ≠òÂú®È°ØËëóÂ∑ÆË∑ùÔºåÈÄôÁ™ÅÈ°Ø‰∫ÜÂú®ÁèæÂØ¶‰∏ñÁïåÁöÑËá®Â∫äÂ†¥ÊôØ‰∏≠ËÉΩÂ§†ÊúâÊïàÊé®ÁêÜÁöÑÊ®°ÂûãÁöÑÈóúÈçµÈúÄÊ±Ç„ÄÇ

##### **PLUGH: A Benchmark for Spatial Understanding and Reasoning in Large Language Models**
2408.04648v1 by Alexey Tikhonov

We present PLUGH (https://www.urbandictionary.com/define.php?term=plugh), a
modern benchmark that currently consists of 5 tasks, each with 125 input texts
extracted from 48 different games and representing 61 different
(non-isomorphic) spatial graphs to assess the abilities of Large Language
Models (LLMs) for spatial understanding and reasoning. Our evaluation of
API-based and open-sourced LLMs shows that while some commercial LLMs exhibit
strong reasoning abilities, open-sourced competitors can demonstrate almost the
same level of quality; however, all models still have significant room for
improvement. We identify typical reasons for LLM failures and discuss possible
ways to deal with them. Datasets and evaluation code are released
(https://github.com/altsoph/PLUGH).

ÊëòË¶ÅÔºöÊàëÂÄëÊèêÂá∫ PLUGH (https://www.urbandictionary.com/define.php?term=plugh)Ôºå‰∏ÄÂÄãÁèæ‰ª£Âü∫Ê∫ñÔºåÁõÆÂâçÂåÖÂê´ 5 È†Ö‰ªªÂãôÔºåÊØèÂÄã‰ªªÂãôÊúâ 125 ÂÄãËº∏ÂÖ•ÊñáÂ≠óÔºåÈÄô‰∫õÊñáÂ≠óÂæû 48 ÂÄã‰∏çÂêåÁöÑÈÅäÊà≤‰∏≠Êì∑ÂèñÔºå‰∏¶‰ª£Ë°® 61 ÂÄã‰∏çÂêåÁöÑÔºàÈùûÂêåÊßãÔºâÁ©∫ÈñìÂúñÂΩ¢ÔºåÁî®ÊñºË©ï‰º∞Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÁ©∫ÈñìÁêÜËß£ÂíåÊé®ÁêÜËÉΩÂäõ„ÄÇÊàëÂÄëÂ∞çÂü∫Êñº API ÂíåÈñãÊ∫êÁöÑ LLM ÈÄ≤Ë°åË©ï‰º∞ÔºåÁµêÊûúÈ°ØÁ§∫ÔºåÂÑòÁÆ°‰∏Ä‰∫õÂïÜÊ•≠ LLM Â±ïÁèæÂá∫Âº∑Â§ßÁöÑÊé®ÁêÜËÉΩÂäõÔºå‰ΩÜÈñãÊ∫êÁöÑÁ´∂Áà≠ËÄÖÂèØ‰ª•Â±ïÁèæÂπæ‰πéÁõ∏ÂêåÁ≠âÁ¥öÁöÑÂìÅË≥™ÔºõÁÑ∂ËÄåÔºåÊâÄÊúâÊ®°Âûã‰ªçÊúâÈ°ØËëóÁöÑÈÄ≤Ê≠•Á©∫Èñì„ÄÇÊàëÂÄëÊâæÂá∫ LLM Â§±ÊïóÁöÑÂÖ∏ÂûãÂéüÂõ†Ôºå‰∏¶Ë®éË´ñÊáâÂ∞çÈÄô‰∫õÂéüÂõ†ÁöÑÂèØËÉΩÊñπÊ≥ï„ÄÇË≥áÊñôÈõÜÂíåË©ï‰º∞Á®ãÂºèÁ¢ºÂ∑≤ÈáãÂá∫Ôºàhttps://github.com/altsoph/PLUGHÔºâ„ÄÇ

##### **Integrating Large Language Models and Knowledge Graphs for Extraction and Validation of Textual Test Data**
2408.01700v1 by Antonio De Santis, Marco Balduini, Federico De Santis, Andrea Proia, Arsenio Leo, Marco Brambilla, Emanuele Della Valle

Aerospace manufacturing companies, such as Thales Alenia Space, design,
develop, integrate, verify, and validate products characterized by high
complexity and low volume. They carefully document all phases for each product
but analyses across products are challenging due to the heterogeneity and
unstructured nature of the data in documents. In this paper, we propose a
hybrid methodology that leverages Knowledge Graphs (KGs) in conjunction with
Large Language Models (LLMs) to extract and validate data contained in these
documents. We consider a case study focused on test data related to electronic
boards for satellites. To do so, we extend the Semantic Sensor Network
ontology. We store the metadata of the reports in a KG, while the actual test
results are stored in parquet accessible via a Virtual Knowledge Graph. The
validation process is managed using an LLM-based approach. We also conduct a
benchmarking study to evaluate the performance of state-of-the-art LLMs in
executing this task. Finally, we analyze the costs and benefits of automating
preexisting processes of manual data extraction and validation for subsequent
cross-report analyses.

ÊëòË¶ÅÔºöËà™Â§™Ë£ΩÈÄ†ÂÖ¨Âè∏Ôºå‰æãÂ¶ÇÊ≥∞Èõ∑Ëå≤ÈòøËêäÂ∞º‰∫ûÂ§™Á©∫ÂÖ¨Âè∏ÔºåË®≠Ë®à„ÄÅÈñãÁôº„ÄÅÊï¥Âêà„ÄÅÈ©óË≠âÂíåÈ©óË≠â‰ª•È´òË§áÈõúÂ∫¶Âíå‰ΩéÈ´îÁ©çÁÇ∫ÁâπÂæµÁöÑÁî¢ÂìÅ„ÄÇ‰ªñÂÄë‰ªîÁ¥∞Ë®òÈåÑÊØèÂÄãÁî¢ÂìÅÁöÑÊâÄÊúâÈöéÊÆµÔºå‰ΩÜÁî±ÊñºÊñá‰ª∂‰∏≠Ë≥áÊñôÁöÑÁï∞Ë≥™ÊÄßÂíåÈùûÁµêÊßãÂåñÊÄßË≥™ÔºåÂ∞éËá¥Ë∑®Áî¢ÂìÅÁöÑÂàÜÊûêÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊ∑∑ÂêàÊñπÊ≥ïÔºåÂà©Áî®Áü•Ë≠òÂúñË≠ú (KG) ÁµêÂêàÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM)Ôºå‰æÜÊì∑ÂèñÂíåÈ©óË≠âÈÄô‰∫õÊñá‰ª∂‰∏≠ÂåÖÂê´ÁöÑË≥áÊñô„ÄÇÊàëÂÄëËÄÉÊÖÆ‰∫Ü‰∏ÄÂÄãÊ°à‰æãÁ†îÁ©∂ÔºåÈáçÈªûÂú®ÊñºË°õÊòüÈõªÂ≠êÈõªË∑ØÊùøÁöÑÊ∏¨Ë©¶Ë≥áÊñô„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÊì¥ÂÖÖ‰∫ÜË™ûÁæ©ÊÑüÊ∏¨Âô®Á∂≤Ë∑ØÊú¨‰Ωì„ÄÇÊàëÂÄëÂ∞áÂ†±ÂëäÁöÑÂÖÉË≥áÊñôÂÑ≤Â≠òÂú® KG ‰∏≠ÔºåËÄåÂØ¶ÈöõÊ∏¨Ë©¶ÁµêÊûúÂÑ≤Â≠òÂú®ÂèØÈÄèÈÅéËôõÊì¨Áü•Ë≠òÂúñË≠úÂ≠òÂèñÁöÑ Parquet ‰∏≠„ÄÇÈ©óË≠âÈÅéÁ®ã‰ΩøÁî®Âü∫Êñº LLM ÁöÑÊñπÊ≥ïÁÆ°ÁêÜ„ÄÇÊàëÂÄëÈÇÑÈÄ≤Ë°åÂü∫Ê∫ñÁ†îÁ©∂Ôºå‰ª•Ë©ï‰º∞ÊúÄÂÖàÈÄ≤ÁöÑ LLM Âú®Âü∑Ë°åÊ≠§‰ªªÂãôÊôÇÁöÑÊïàËÉΩ„ÄÇÊúÄÂæåÔºåÊàëÂÄëÂàÜÊûê‰∫ÜËá™ÂãïÂåñÁèæÊúâÊâãÂãïË≥áÊñôÊì∑ÂèñÂíåÈ©óË≠âÁ®ãÂ∫èÁöÑÊàêÊú¨ÂíåÂ•ΩËôïÔºå‰ª•ÈÄ≤Ë°åÂæåÁ∫åÁöÑË∑®Â†±ÂëäÂàÜÊûê„ÄÇ

##### **DERA: Dense Entity Retrieval for Entity Alignment in Knowledge Graphs**
2408.01154v1 by Zhichun Wang, Xuan Chen

Entity Alignment (EA) aims to match equivalent entities in different
Knowledge Graphs (KGs), which is essential for knowledge fusion and
integration. Recently, embedding-based EA has attracted significant attention
and many approaches have been proposed. Early approaches primarily focus on
learning entity embeddings from the structural features of KGs, defined by
relation triples. Later methods incorporated entities' names and attributes as
auxiliary information to enhance embeddings for EA. However, these approaches
often used different techniques to encode structural and attribute information,
limiting their interaction and mutual enhancement. In this work, we propose a
dense entity retrieval framework for EA, leveraging language models to
uniformly encode various features of entities and facilitate nearest entity
search across KGs. Alignment candidates are first generated through entity
retrieval, which are subsequently reranked to determine the final alignments.
We conduct comprehensive experiments on both cross-lingual and monolingual EA
datasets, demonstrating that our approach achieves state-of-the-art performance
compared to existing EA methods.

ÊëòË¶ÅÔºöÂØ¶È´îÂ∞çÈΩä (EA) Êó®Âú®ÊØîÂ∞ç‰∏çÂêåÁü•Ë≠òÂúñË≠ú (KG) ‰∏≠ÁöÑÁ≠âÊïàÂØ¶È´îÔºåÈÄôÂ∞çÊñºÁü•Ë≠òËûçÂêàÂíåÊï¥ÂêàÈùûÂ∏∏ÈáçË¶Å„ÄÇÊúÄËøëÔºåÂü∫ÊñºÂµåÂÖ•ÁöÑ EA Â∑≤ÂºïËµ∑Áõ∏Áï∂Â§ßÁöÑÈóúÊ≥®Ôºå‰∏¶‰∏îÂ∑≤ÊèêÂá∫Ë®±Â§öÊñπÊ≥ï„ÄÇÊó©ÊúüÁöÑÊñπÊ≥ï‰∏ªË¶ÅÂ∞àÊ≥®ÊñºÂæû KG ÁöÑÁµêÊßãÁâπÂæµ‰∏≠Â≠∏ÁøíÂØ¶È´îÂµåÂÖ•ÔºåÈÄô‰∫õÁâπÂæµÁî±Èóú‰øÇ‰∏âÂÖÉÁµÑÂÆöÁæ©„ÄÇÂæåÁ∫åÁöÑÊñπÊ≥ïÂ∞áÂØ¶È´îÁöÑÂêçÁ®±ÂíåÂ±¨ÊÄß‰ΩúÁÇ∫ËºîÂä©Ë≥áË®äÔºå‰ª•Â¢ûÂº∑ EA ÁöÑÂµåÂÖ•„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÊñπÊ≥ïÈÄöÂ∏∏‰ΩøÁî®‰∏çÂêåÁöÑÊäÄË°ì‰æÜÁ∑®Á¢ºÁµêÊßãÂíåÂ±¨ÊÄßË≥áË®äÔºåÈôêÂà∂‰∫ÜÂÆÉÂÄëÁöÑ‰∫íÂãïÂíåÁõ∏‰∫íÂ¢ûÂº∑„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂØÜÈõÜÂØ¶È´îÊì∑ÂèñÊû∂ÊßãÔºåÁî®Êñº EAÔºåÂà©Áî®Ë™ûË®ÄÊ®°Âûã‰æÜÁµ±‰∏ÄÁ∑®Á¢ºÂØ¶È´îÁöÑÂêÑÁ®ÆÁâπÂæµÔºå‰∏¶‰øÉÈÄ≤Ë∑® KG ÁöÑÊúÄËøëÂØ¶È´îÊêúÂ∞ã„ÄÇÂ∞çÈΩäÂÄôÈÅ∏ËÄÖÈ¶ñÂÖàÈÄèÈÅéÂØ¶È´îÊì∑ÂèñÁî¢ÁîüÔºåÁÑ∂ÂæåÈáçÊñ∞ÊéíÂ∫è‰ª•Á¢∫ÂÆöÊúÄÁµÇÂ∞çÈΩä„ÄÇÊàëÂÄëÂ∞çË∑®Ë™ûË®ÄÂíåÂñÆË™ûË®Ä EA Ë≥áÊñôÈõÜÈÄ≤Ë°å‰∫ÜÂÖ®Èù¢ÁöÑÂØ¶È©óÔºåË≠âÊòéËàáÁèæÊúâÁöÑ EA ÊñπÊ≥ïÁõ∏ÊØîÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÈÅîÂà∞‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÊïàËÉΩ„ÄÇ

##### **Bridging Information Gaps in Dialogues With Grounded Exchanges Using Knowledge Graphs**
2408.01088v2 by Phillip Schneider, Nektarios Machner, Kristiina Jokinen, Florian Matthes

Knowledge models are fundamental to dialogue systems for enabling
conversational interactions, which require handling domain-specific knowledge.
Ensuring effective communication in information-providing conversations entails
aligning user understanding with the knowledge available to the system.
However, dialogue systems often face challenges arising from semantic
inconsistencies in how information is expressed in natural language compared to
how it is represented within the system's internal knowledge. To address this
problem, we study the potential of large language models for conversational
grounding, a mechanism to bridge information gaps by establishing shared
knowledge between dialogue participants. Our approach involves annotating human
conversations across five knowledge domains to create a new dialogue corpus
called BridgeKG. Through a series of experiments on this dataset, we
empirically evaluate the capabilities of large language models in classifying
grounding acts and identifying grounded information items within a knowledge
graph structure. Our findings offer insights into how these models use
in-context learning for conversational grounding tasks and common prediction
errors, which we illustrate with examples from challenging dialogues. We
discuss how the models handle knowledge graphs as a semantic layer between
unstructured dialogue utterances and structured information items.

ÊëòË¶ÅÔºöÁü•Ë≠òÊ®°ÂûãÂ∞çÊñºÂ∞çË©±Á≥ªÁµ±Ëá≥ÈóúÈáçË¶ÅÔºåÂèØÈÄ≤Ë°åÂ∞çË©±‰∫íÂãïÔºåÈúÄË¶ÅËôïÁêÜÁâπÂÆöÈ†òÂüüÁöÑÁü•Ë≠ò„ÄÇÁ¢∫‰øùÂú®Êèê‰æõË≥áË®äÁöÑÂ∞çË©±‰∏≠ÈÄ≤Ë°åÊúâÊïàÁöÑÊ∫ùÈÄöÔºåÈúÄË¶ÅÂ∞á‰ΩøÁî®ËÄÖÁöÑÁêÜËß£ËàáÁ≥ªÁµ±‰∏≠ÂèØÁî®ÁöÑÁü•Ë≠òÂ∞çÈΩä„ÄÇÁÑ∂ËÄåÔºåÂ∞çË©±Á≥ªÁµ±Á∂ìÂ∏∏ÊúÉÈù¢Ëá®Ë™ûÊÑè‰∏ç‰∏ÄËá¥ÁöÑÊåëÊà∞ÔºåÂú®ÊñºËá™ÁÑ∂Ë™ûË®Ä‰∏≠Ë°®ÈÅîË≥áË®äÁöÑÊñπÂºèËàáÁ≥ªÁµ±ÂÖßÈÉ®Áü•Ë≠òÁöÑË°®Á§∫ÊñπÂºè‰∏çÂêå„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÁ†îÁ©∂Â§ßÂûãË™ûË®ÄÊ®°ÂûãÂú®Â∞çË©±Âü∫Á§é‰∏≠ÁöÑÊΩõÂäõÔºåÈÄôÊòØ‰∏ÄÁ®ÆÈÄèÈÅéÂª∫Á´ãÂ∞çË©±ÂèÉËàáËÄÖ‰πãÈñìÁöÑÂÖ±Áî®Áü•Ë≠ò‰æÜÂΩåË£úË≥áË®äÂ∑ÆË∑ùÁöÑÊ©üÂà∂„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÊ∂âÂèäÊ®ôË®ª‰∫îÂÄãÁü•Ë≠òÈ†òÂüü‰∏≠ÁöÑ‰∫∫È°ûÂ∞çË©±Ôºå‰ª•Âª∫Á´ã‰∏ÄÂÄãÂêçÁÇ∫ BridgeKG ÁöÑÊñ∞Â∞çË©±Ë™ûÊñôÂ∫´„ÄÇÈÄèÈÅéÂ∞çÊ≠§Ë≥áÊñôÈõÜÈÄ≤Ë°å‰∏ÄÁ≥ªÂàóÁöÑÂØ¶È©óÔºåÊàëÂÄëÂØ¶Ë≠âË©ï‰º∞Â§ßÂûãË™ûË®ÄÊ®°ÂûãÂú®ÂàÜÈ°ûÂü∫Á§éË°åÁÇ∫ÂíåË≠òÂà•Áü•Ë≠òÂúñÁµêÊßã‰∏≠Â∑≤Êé•Âú∞ÁöÑË≥áË®äÈ†ÖÁõÆÁöÑËÉΩÂäõ„ÄÇÊàëÂÄëÁöÑÁôºÁèæÊèê‰æõ‰∫ÜË¶ãËß£ÔºåË™™ÊòéÈÄô‰∫õÊ®°ÂûãÂ¶Ç‰Ωï‰ΩøÁî®ÊÉÖÂ¢ÉÂ≠∏ÁøíÈÄ≤Ë°åÂ∞çË©±Âü∫Á§é‰ªªÂãôÂíåÂ∏∏Ë¶ãÁöÑÈ†êÊ∏¨ÈåØË™§ÔºåÊàëÂÄëÁî®ÂÖ∑ÊúâÊåëÊà∞ÊÄßÁöÑÂ∞çË©±ÁØÑ‰æã‰æÜË™™Êòé„ÄÇÊàëÂÄëË®éË´ñÊ®°ÂûãÂ¶Ç‰ΩïÂ∞áÁü•Ë≠òÂúñË°®Ë¶ñÁÇ∫ÈùûÁµêÊßãÂåñÂ∞çË©±Ë©±Ë™ûÂíåÁµêÊßãÂåñË≥áË®äÈ†ÖÁõÆ‰πãÈñìÁöÑË™ûÊÑèÂ±§„ÄÇ

##### **Automatic Extraction of Relationships among Motivations, Emotions and Actions from Natural Language Texts**
2408.00966v1 by Fei Yang

We propose a new graph-based framework to reveal relationships among
motivations, emotions and actions explicitly given natural language texts. A
directed acyclic graph is designed to describe human's nature. Nurture beliefs
are incorporated to connect outside events and the human's nature graph. No
annotation resources are required due to the power of large language models.
Amazon Fine Foods Reviews dataset is used as corpus and food-related
motivations are focused. Totally 92,990 relationship graphs are generated, of
which 63% make logical sense. We make further analysis to investigate error
types for optimization direction in future research.

ÊëòË¶ÅÔºöÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÊñ∞ÁöÑÂü∫ÊñºÂúñÂΩ¢ÁöÑÊû∂ÊßãÔºåÁî®ÊñºÊè≠Á§∫Âú®Ëá™ÁÑ∂Ë™ûË®ÄÊñáÊú¨‰∏≠ÊòéÁ¢∫Áµ¶Âá∫ÁöÑÂãïÊ©ü„ÄÅÊÉÖÁ∑íÂíåÂãï‰Ωú‰πãÈñìÁöÑÈóú‰øÇ„ÄÇÊúâÂêëÁÑ°Áí∞ÂúñË¢´Ë®≠Ë®àÁî®ÊñºÊèèËø∞‰∫∫È°ûÁöÑÊú¨ÊÄß„ÄÇÂüπÈ§ä‰ø°ÂøµË¢´Á¥çÂÖ•ÂÖ∂‰∏≠ÔºåÁî®ÊñºÈÄ£Êé•Â§ñÈÉ®‰∫ã‰ª∂Âíå‰∫∫È°ûÁöÑÊú¨ÊÄßÂúñ„ÄÇÁî±ÊñºÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÁöÑÂº∑Â§ßÂäüËÉΩÔºå‰∏çÈúÄË¶ÅË®ªËß£Ë≥áÊ∫ê„ÄÇ‰∫ûÈ¶¨ÈÅúÁæéÈ£üË©ïË´ñÊï∏ÊìöÈõÜË¢´Áî®‰ΩúË™ûÊñôÂ∫´Ôºå‰∏¶‰∏îÈáçÈªûÈóúÊ≥®ËàáÈ£üÁâ©Áõ∏ÈóúÁöÑÂãïÊ©ü„ÄÇÁ∏ΩÂÖ±ÁîüÊàê‰∫Ü 92,990 ÂÄãÈóú‰øÇÂúñÔºåÂÖ∂‰∏≠ 63% ÂÖ∑ÊúâÈÇèËºØÊÑèÁæ©„ÄÇÊàëÂÄëÈÄ≤‰∏ÄÊ≠•ÂàÜÊûê‰ª•Ë™øÊü•ÈåØË™§È°ûÂûãÔºå‰ª•‰æøÁÇ∫Êú™‰æÜÁöÑÁ†îÁ©∂Êèê‰æõÂÑ™ÂåñÊñπÂêë„ÄÇ

##### **DisTrack: a new Tool for Semi-automatic Misinformation Tracking in Online Social Networks**
2408.00633v1 by Guillermo Villar-Rodr√≠guez, √Ålvaro Huertas-Garc√≠a, Alejandro Mart√≠n, Javier Huertas-Tato, David Camacho

Introduction: This article introduces DisTrack, a methodology and a tool
developed for tracking and analyzing misinformation within Online Social
Networks (OSNs). DisTrack is designed to combat the spread of misinformation
through a combination of Natural Language Processing (NLP) Social Network
Analysis (SNA) and graph visualization. The primary goal is to detect
misinformation, track its propagation, identify its sources, and assess the
influence of various actors within the network.
  Methods: DisTrack's architecture incorporates a variety of methodologies
including keyword search, semantic similarity assessments, and graph generation
techniques. These methods collectively facilitate the monitoring of
misinformation, the categorization of content based on alignment with known
false claims, and the visualization of dissemination cascades through detailed
graphs. The tool is tailored to capture and analyze the dynamic nature of
misinformation spread in digital environments.
  Results: The effectiveness of DisTrack is demonstrated through three case
studies focused on different themes: discredit/hate speech, anti-vaccine
misinformation, and false narratives about the Russia-Ukraine conflict. These
studies show DisTrack's capabilities in distinguishing posts that propagate
falsehoods from those that counteract them, and tracing the evolution of
misinformation from its inception.
  Conclusions: The research confirms that DisTrack is a valuable tool in the
field of misinformation analysis. It effectively distinguishes between
different types of misinformation and traces their development over time. By
providing a comprehensive approach to understanding and combating
misinformation in digital spaces, DisTrack proves to be an essential asset for
researchers and practitioners working to mitigate the impact of false
information in online social environments.

ÊëòË¶ÅÔºö<paragraph>ÂºïË®ÄÔºöÊú¨Êñá‰ªãÁ¥π DisTrackÔºåÈÄôÊòØ‰∏ÄÁ®ÆÊñπÊ≥ïÂíåÂ∑•ÂÖ∑ÔºåÁî®ÊñºËøΩËπ§ÂíåÂàÜÊûêÁ∑ö‰∏äÁ§æ‰∫§Á∂≤Ë∑ØÔºàOSNÔºâ‰∏≠ÁöÑÈåØË™§Ë≥áË®ä„ÄÇDisTrack ÁöÑË®≠Ë®àÁõÆÁöÑÊòØÈÄèÈÅéÁµêÂêàËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜÔºàNLPÔºâ„ÄÅÁ§æ‰∫§Á∂≤Ë∑ØÂàÜÊûêÔºàSNAÔºâÂíåÂúñÂΩ¢Ë¶ñË¶∫Âåñ‰æÜÂ∞çÊäóÈåØË™§Ë≥áË®äÁöÑÊï£Â∏É„ÄÇ‰∏ªË¶ÅÁõÆÊ®ôÊòØÂÅµÊ∏¨ÈåØË™§Ë≥áË®ä„ÄÅËøΩËπ§ÂÖ∂ÂÇ≥Êí≠„ÄÅÊâæÂá∫ÂÖ∂‰æÜÊ∫êÔºå‰∏¶Ë©ï‰º∞Á∂≤Ë∑Ø‰∏≠ÂêÑÂÄãÂèÉËàáËÄÖÁöÑÂΩ±ÈüøÂäõ„ÄÇ
ÊñπÊ≥ïÔºöDisTrack ÁöÑÊû∂ÊßãÁµêÂêà‰∫ÜÂ§öÁ®ÆÊñπÊ≥ïÔºåÂåÖÊã¨ÈóúÈçµÂ≠óÊêúÂ∞ã„ÄÅË™ûÊÑèÁõ∏‰ººÊÄßË©ï‰º∞ÂíåÂúñÂΩ¢Áî¢ÁîüÊäÄË°ì„ÄÇÈÄô‰∫õÊñπÊ≥ïÂÖ±Âêå‰øÉÈÄ≤‰∫ÜÈåØË™§Ë≥áË®äÁöÑÁõ£Êéß„ÄÅÂü∫ÊñºËàáÂ∑≤Áü•ËôõÂÅáË™™Ê≥ïÁöÑÊØîÂ∞ç‰æÜÂàÜÈ°ûÂÖßÂÆπÔºå‰ª•ÂèäÈÄèÈÅéË©≥Á¥∞ÂúñÂΩ¢Ë¶ñË¶∫ÂåñÂÇ≥Êí≠Â±§Áñä„ÄÇÊ≠§Â∑•ÂÖ∑Á∂ìÈÅéÈáèË∫´ÊâìÈÄ†ÔºåÁî®ÊñºÊì∑ÂèñÂíåÂàÜÊûêÊï∏‰ΩçÁí∞Â¢É‰∏≠ÈåØË™§Ë≥áË®äÊï£Â∏ÉÁöÑÂãïÊÖãÁâπÊÄß„ÄÇ
ÁµêÊûúÔºöDisTrack ÁöÑÊïàËÉΩÈÄèÈÅé‰∏âÂÄãÊ°à‰æãÁ†îÁ©∂Áç≤ÂæóÈ©óË≠âÔºåÈÄô‰∫õÁ†îÁ©∂Â∞àÊ≥®Êñº‰∏çÂêåÁöÑ‰∏ªÈ°åÔºöË≤∂‰Ωé/‰ªáÊÅ®Ë®ÄË´ñ„ÄÅÂèçÁñ´ËãóÈåØË™§Ë≥áË®äÔºå‰ª•ÂèäÈóúÊñº‰øÑÁæÖÊñØ-ÁÉèÂÖãËò≠Ë°ùÁ™ÅÁöÑËôõÂÅáÊïòËø∞„ÄÇÈÄô‰∫õÁ†îÁ©∂È°ØÁ§∫Âá∫ DisTrack Âú®ÂçÄÂàÜÂÇ≥Êí≠ËôõÂÅáË≥áË®äÂíåÂèçÂà∂ËôõÂÅáË≥áË®äÁöÑË≤ºÊñáÔºå‰ª•ÂèäËøΩËπ§ÈåØË™§Ë≥áË®äÂæûÂÖ∂ÈñãÁ´ØÊºîËÆäÁöÑÈÅéÁ®ã‰∏≠ÊâÄÂÖ∑ÂÇôÁöÑËÉΩÂäõ„ÄÇ
ÁµêË´ñÔºöÁ†îÁ©∂Ë≠âÂØ¶ DisTrack ÊòØÈåØË™§Ë≥áË®äÂàÜÊûêÈ†òÂüü‰∏≠‰∏ÄÂÄãÊúâÂÉπÂÄºÁöÑÂ∑•ÂÖ∑„ÄÇÂÆÉÊúâÊïàÂçÄÂàÜ‰∫Ü‰∏çÂêåÈ°ûÂûãÁöÑÈåØË™§Ë≥áË®äÔºå‰∏¶ËøΩËπ§ÂÖ∂Èö®ËëóÊôÇÈñìÊé®ÁßªÁöÑÁôºÂ±ï„ÄÇÈÄèÈÅéÊèê‰æõ‰∏ÄÁ®ÆÂÖ®Èù¢ÁöÑÊñπÊ≥ï‰æÜÁêÜËß£ÂíåÂ∞çÊäóÊï∏‰ΩçÁ©∫Èñì‰∏≠ÁöÑÈåØË™§Ë≥áË®äÔºåDisTrack Ë≠âÊòé‰∫ÜËá™Â∑±ÊòØÂçîÂä©Á†îÁ©∂‰∫∫Âì°ÂíåÂØ¶ÂãôÂ∑•‰ΩúËÄÖÊ∏õËºïÁ∑ö‰∏äÁ§æ‰∫§Áí∞Â¢É‰∏≠ËôõÂÅáË≥áË®äÂΩ±ÈüøÂäõÁöÑÈáçË¶ÅË≥áÁî¢„ÄÇ</paragraph>

##### **On the Limitations and Prospects of Machine Unlearning for Generative AI**
2408.00376v1 by Shiji Zhou, Lianzhe Wang, Jiangnan Ye, Yongliang Wu, Heng Chang

Generative AI (GenAI), which aims to synthesize realistic and diverse data
samples from latent variables or other data modalities, has achieved remarkable
results in various domains, such as natural language, images, audio, and
graphs. However, they also pose challenges and risks to data privacy, security,
and ethics. Machine unlearning is the process of removing or weakening the
influence of specific data samples or features from a trained model, without
affecting its performance on other data or tasks. While machine unlearning has
shown significant efficacy in traditional machine learning tasks, it is still
unclear if it could help GenAI become safer and aligned with human desire. To
this end, this position paper provides an in-depth discussion of the machine
unlearning approaches for GenAI. Firstly, we formulate the problem of machine
unlearning tasks on GenAI and introduce the background. Subsequently, we
systematically examine the limitations of machine unlearning on GenAI models by
focusing on the two representative branches: LLMs and image generative
(diffusion) models. Finally, we provide our prospects mainly from three
aspects: benchmark, evaluation metrics, and utility-unlearning trade-off, and
conscientiously advocate for the future development of this field.

ÊëòË¶ÅÔºöÁîüÊàêÂºè AI (GenAI) Êó®Âú®ÂæûÊΩõÂú®ËÆäÊï∏ÊàñÂÖ∂‰ªñË≥áÊñôÊ®°Âºè‰∏≠ÂêàÊàêÈÄºÁúü‰∏îÂ§öÊ®£ÂåñÁöÑË≥áÊñôÁØÑ‰æãÔºåÂ∑≤Âú®Ëá™ÁÑ∂Ë™ûË®Ä„ÄÅÂΩ±ÂÉè„ÄÅÈü≥Ë®äÂíåÂúñÂΩ¢Á≠âÂêÑÁ®ÆÈ†òÂüü‰∏≠ÂèñÂæóÈ°ØËëóÊàêÊûú„ÄÇÁÑ∂ËÄåÔºåÂÆÉÂÄë‰πüÂ∞çË≥áÊñôÈö±ÁßÅ„ÄÅÂÆâÂÖ®ÊÄßËàáÈÅìÂæ∑ÊßãÊàêÊåëÊà∞ÂíåÈ¢®Èö™„ÄÇÊ©üÂô®ÈÅ∫ÂøòÊòØÁßªÈô§ÊàñÊ∏õÂº±ÁâπÂÆöË≥áÊñôÁØÑ‰æãÊàñÁâπÂæµÂ∞çÂ∑≤Ë®ìÁ∑¥Ê®°ÂûãÁöÑÂΩ±ÈüøÔºåÂêåÊôÇ‰∏çÂΩ±ÈüøÂÖ∂Âú®ÂÖ∂‰ªñË≥áÊñôÊàñ‰ªªÂãô‰∏äÁöÑÊïàËÉΩ„ÄÇÈõñÁÑ∂Ê©üÂô®ÈÅ∫ÂøòÂ∑≤Âú®ÂÇ≥Áµ±Ê©üÂô®Â≠∏Áøí‰ªªÂãô‰∏≠Â±ïÁèæÈ°ØËëóÁöÑÂäüÊïàÔºå‰ΩÜ‰ªç‰∏çÊ∏ÖÊ•öÂÆÉÊòØÂê¶ËÉΩÂçîÂä© GenAI ËÆäÂæóÊõ¥ÂÆâÂÖ®‰∏îÁ¨¶Âêà‰∫∫È°ûÁöÑÊúüÊúõ„ÄÇÁÇ∫Ê≠§ÔºåÊú¨Á´ãÂ†¥Êñá‰ª∂Ê∑±ÂÖ•Êé¢Ë®é‰∫Ü GenAI ÁöÑÊ©üÂô®ÈÅ∫ÂøòÊñπÊ≥ï„ÄÇÈ¶ñÂÖàÔºåÊàëÂÄëÂà∂ÂÆö GenAI ‰∏äÊ©üÂô®ÈÅ∫Âøò‰ªªÂãôÁöÑÂïèÈ°åÔºå‰∏¶‰ªãÁ¥πËÉåÊôØ„ÄÇÊé•ËëóÔºåÊàëÂÄëÊúâÁ≥ªÁµ±Âú∞Ê™¢Ë¶ñÊ©üÂô®ÈÅ∫ÂøòÂú® GenAI Ê®°Âûã‰∏äÁöÑÈôêÂà∂ÔºåÈáçÈªûÊîæÂú®ÂÖ©ÂÄã‰ª£Ë°®ÊÄßÁöÑÂàÜÊîØÔºöLLM ÂíåÂΩ±ÂÉèÁîüÊàêÔºàÊì¥Êï£ÔºâÊ®°Âûã„ÄÇÊúÄÂæåÔºåÊàëÂÄë‰∏ªË¶ÅÂæûÂü∫Ê∫ñ„ÄÅË©ï‰º∞ÊåáÊ®ôÂíåÊïàÁî®ÈÅ∫ÂøòÊ¨äË°°‰∏âÂÄãÈù¢ÂêëÊèê‰æõÊàëÂÄëÁöÑÂ±ïÊúõÔºå‰∏¶ÂØ©ÊÖéÂÄ°Ë≠∞Ë©≤È†òÂüüÁöÑÊú™‰æÜÁôºÂ±ï„ÄÇ

##### **Multi-Modal Parameter-Efficient Fine-tuning via Graph Neural Network**
2408.00290v1 by Bin Cheng, Jiaxuan Lu

With the advent of the era of foundation models, pre-training and fine-tuning
have become common paradigms. Recently, parameter-efficient fine-tuning has
garnered widespread attention due to its better balance between the number of
learnable parameters and performance. However, some current parameter-efficient
fine-tuning methods only model a single modality and lack the utilization of
structural knowledge in downstream tasks. To address this issue, this paper
proposes a multi-modal parameter-efficient fine-tuning method based on graph
networks. Each image is fed into a multi-modal large language model (MLLM) to
generate a text description. The image and its corresponding text description
are then processed by a frozen image encoder and text encoder to generate image
features and text features, respectively. A graph is constructed based on the
similarity of the multi-modal feature nodes, and knowledge and relationships
relevant to these features are extracted from each node. Additionally, Elastic
Weight Consolidation (EWC) regularization is incorporated into the loss
function to mitigate the problem of forgetting during task learning. The
proposed model achieves test accuracies on the OxfordPets, Flowers102, and
Food101 datasets that improve by 4.45%, 2.92%, and 0.23%, respectively. The
code is available at https://github.com/yunche0/GA-Net/tree/master.

ÊëòË¶ÅÔºöÈö®ËëóÂü∫Á§éÊ®°ÂûãÊôÇ‰ª£ÁöÑÂà∞‰æÜÔºåÈ†êË®ìÁ∑¥ÂíåÂæÆË™øÂ∑≤ÊàêÁÇ∫Â∏∏Ë¶ãÁöÑÁØÑ‰æã„ÄÇÊúÄËøëÔºåÁî±ÊñºÂèÉÊï∏ÊúâÊïàÂæÆË™øÂú®ÂèØÂ≠∏ÁøíÂèÉÊï∏Êï∏ÈáèÂíåÊïàËÉΩ‰πãÈñìÂèñÂæóÊõ¥Â•ΩÁöÑÂπ≥Ë°°ÔºåÂõ†Ê≠§ÂÇôÂèóÈóúÊ≥®„ÄÇÁÑ∂ËÄåÔºå‰∏Ä‰∫õÁõÆÂâçÁöÑÂèÉÊï∏ÊúâÊïàÂæÆË™øÊñπÊ≥ïÂÉÖÂª∫Ê®°ÂñÆ‰∏ÄÊ®°ÊÖãÔºå‰∏îÁº∫‰πèÂú®‰∏ãÊ∏∏‰ªªÂãô‰∏≠Âà©Áî®ÁµêÊßãÁü•Ë≠ò„ÄÇÁÇ∫‰∫ÜËß£Ê±∫Ê≠§ÂïèÈ°åÔºåÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂü∫ÊñºÂúñÂΩ¢Á∂≤Ë∑ØÁöÑÂ§öÊ®°ÊÖãÂèÉÊï∏ÊúâÊïàÂæÆË™øÊñπÊ≥ï„ÄÇÊØèÂÄãÂΩ±ÂÉèÈÉΩÊúÉËº∏ÂÖ•Âà∞Â§öÊ®°ÊÖãÂ§ßÂûãË™ûË®ÄÊ®°Âûã (MLLM) ‰∏≠Ôºå‰ª•Áî¢ÁîüÊñáÂ≠óÊèèËø∞„ÄÇÁÑ∂ÂæåÔºåÂΩ±ÂÉèÂèäÂÖ∂Â∞çÊáâÁöÑÊñáÂ≠óÊèèËø∞ÊúÉÁî±ÂáçÁµêÁöÑÂΩ±ÂÉèÁ∑®Á¢ºÂô®ÂíåÊñáÂ≠óÁ∑®Á¢ºÂô®ËôïÁêÜÔºåÂàÜÂà•Áî¢ÁîüÂΩ±ÂÉèÁâπÂæµÂíåÊñáÂ≠óÁâπÂæµ„ÄÇÊ†πÊìöÂ§öÊ®°ÊÖãÁâπÂæµÁØÄÈªûÁöÑÁõ∏‰ººÊÄßÂª∫Êßã‰∏ÄÂÄãÂúñÂΩ¢Ôºå‰∏¶ÂæûÊØèÂÄãÁØÄÈªû‰∏≠ËêÉÂèñÂá∫ËàáÈÄô‰∫õÁâπÂæµÁõ∏ÈóúÁöÑÁü•Ë≠òÂíåÈóú‰øÇ„ÄÇÊ≠§Â§ñÔºåÂΩàÊÄßÊ¨äÈáçÊï¥Âêà (EWC) Ê≠£ÂâáÂåñÊúÉÁ¥çÂÖ•ÊêçÂ§±ÂáΩÊï∏‰∏≠Ôºå‰ª•Ê∏õËºïÂú®‰ªªÂãôÂ≠∏ÁøíÊúüÈñìÈÅ∫ÂøòÁöÑÂïèÈ°å„ÄÇÊâÄÊèêÂá∫ÁöÑÊ®°ÂûãÂú® OxfordPets„ÄÅFlowers102 Âíå Food101 Ë≥áÊñôÈõÜ‰∏äÈÅîÊàêÁöÑÊ∏¨Ë©¶Ê∫ñÁ¢∫Â∫¶ÂàÜÂà•ÊèêÂçá‰∫Ü 4.45%„ÄÅ2.92% Âíå 0.23%„ÄÇÁ®ãÂºèÁ¢ºÂèØÂú® https://github.com/yunche0/GA-Net/tree/master ÂèñÂæó„ÄÇ

##### **CEAR: Automatic construction of a knowledge graph of chemical entities and roles from scientific literature**
2407.21708v1 by Stefan Langer, Fabian Neuhaus, Andreas N√ºrnberger

Ontologies are formal representations of knowledge in specific domains that
provide a structured framework for organizing and understanding complex
information. Creating ontologies, however, is a complex and time-consuming
endeavor. ChEBI is a well-known ontology in the field of chemistry, which
provides a comprehensive resource for defining chemical entities and their
properties. However, it covers only a small fraction of the rapidly growing
knowledge in chemistry and does not provide references to the scientific
literature. To address this, we propose a methodology that involves augmenting
existing annotated text corpora with knowledge from Chebi and fine-tuning a
large language model (LLM) to recognize chemical entities and their roles in
scientific text. Our experiments demonstrate the effectiveness of our approach.
By combining ontological knowledge and the language understanding capabilities
of LLMs, we achieve high precision and recall rates in identifying both the
chemical entities and roles in scientific literature. Furthermore, we extract
them from a set of 8,000 ChemRxiv articles, and apply a second LLM to create a
knowledge graph (KG) of chemical entities and roles (CEAR), which provides
complementary information to ChEBI, and can help to extend it.

ÊëòË¶ÅÔºöÊú¨‰ΩìÊòØÁâπÂÆöÈ†òÂüü‰∏≠Áü•Ë≠òÁöÑÂΩ¢ÂºèÂåñË°®Á§∫ÔºåÂÆÉÊèê‰æõ‰∫Ü‰∏ÄÂÄãÁµêÊßãÂåñÁöÑÊ°ÜÊû∂ÔºåÁî®ÊñºÁµÑÁπîÂíåÁêÜËß£Ë§áÈõúÁöÑË≥áË®ä„ÄÇÁÑ∂ËÄåÔºåÂª∫Á´ãÊú¨‰ΩìÊòØ‰∏ÄÈ†ÖË§áÈõú‰∏îËÄóÊôÇÁöÑÂä™Âäõ„ÄÇChEBI ÊòØÂåñÂ≠∏È†òÂüü‰∏≠‰∏ÄÂÄãËëóÂêçÁöÑÊú¨‰ΩìÔºåÂÆÉÊèê‰æõ‰∫Ü‰∏ÄÂÄãÂÖ®Èù¢ÁöÑË≥áÊ∫êÔºåÁî®ÊñºÂÆöÁæ©ÂåñÂ≠∏ÂØ¶È´îÂèäÂÖ∂Â±¨ÊÄß„ÄÇÁÑ∂ËÄåÔºåÂÆÉÂÉÖÊ∂µËìã‰∫ÜÂåñÂ≠∏È†òÂüüÂø´ÈÄüÂ¢ûÈï∑ÁöÑÁü•Ë≠ò‰∏≠ÁöÑ‰∏ÄÂ∞èÈÉ®ÂàÜÔºå‰∏¶‰∏îÊ≤íÊúâÊèê‰æõÁßëÂ≠∏ÊñáÁçªÁöÑÂèÉËÄÉ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñπÊ≥ïÔºåÂÆÉÊ∂âÂèä‰ΩøÁî®‰æÜËá™ Chebi ÁöÑÁü•Ë≠òÊì¥ÂÖÖÁèæÊúâÁöÑË®ªÈáãÊñáÊú¨Ë™ûÊñôÂ∫´Ôºå‰∏¶ÂæÆË™øÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM)Ôºå‰ª•Ë≠òÂà•ÂåñÂ≠∏ÂØ¶È´îÂèäÂÖ∂Âú®ÁßëÂ≠∏ÊñáÊú¨‰∏≠ÁöÑ‰ΩúÁî®„ÄÇÊàëÂÄëÁöÑÂØ¶È©óË≠âÊòé‰∫ÜÊàëÂÄëÊñπÊ≥ïÁöÑÊúâÊïàÊÄß„ÄÇÈÄèÈÅéÁµêÂêàÊú¨‰ΩìÁü•Ë≠òÂíå LLM ÁöÑË™ûË®ÄÁêÜËß£ËÉΩÂäõÔºåÊàëÂÄëÂú®Ë≠òÂà•ÁßëÂ≠∏ÊñáÁçª‰∏≠ÁöÑÂåñÂ≠∏ÂØ¶È´îÂíå‰ΩúÁî®ÊñπÈù¢ÈÅîÂà∞‰∫ÜÂæàÈ´òÁöÑÊ∫ñÁ¢∫Â∫¶ÂíåÂè¨ÂõûÁéá„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂæû‰∏ÄÁµÑ 8,000 ÁØá ChemRxiv ÊñáÁ´†‰∏≠ÊèêÂèñÂÆÉÂÄëÔºå‰∏¶ÊáâÁî®Á¨¨‰∫åÂÄã LLM ‰æÜÂª∫Á´ã‰∏ÄÂÄãÂåñÂ≠∏ÂØ¶È´îÂíå‰ΩúÁî® (CEAR) ÁöÑÁü•Ë≠òÂúñË≠ú (KG)ÔºåÂÆÉÊèê‰æõË£úÂÖÖ ChEBI ÁöÑË≥áË®äÔºå‰∏¶ÊúâÂä©ÊñºÊì¥ÂÖÖÂÆÉ„ÄÇ

##### **eSPARQL: Representing and Reconciling Agnostic and Atheistic Beliefs in RDF-star Knowledge Graphs**
2407.21483v3 by Xinyi Pan, Daniel Hern√°ndez, Philipp Seifer, Ralf L√§mmel, Steffen Staab

Over the past few years, we have seen the emergence of large knowledge graphs
combining information from multiple sources. Sometimes, this information is
provided in the form of assertions about other assertions, defining contexts
where assertions are valid. A recent extension to RDF which admits statements
over statements, called RDF-star, is in revision to become a W3C standard.
However, there is no proposal for a semantics of these RDF-star statements nor
a built-in facility to operate over them. In this paper, we propose a query
language for epistemic RDF-star metadata based on a four-valued logic, called
eSPARQL. Our proposed query language extends SPARQL-star, the query language
for RDF-star, with a new type of FROM clause to facilitate operating with
multiple and sometimes conflicting beliefs. We show that the proposed query
language can express four use case queries, including the following features:
(i) querying the belief of an individual, (ii) the aggregating of beliefs,
(iii) querying who is conflicting with somebody, and (iv) beliefs about beliefs
(i.e., nesting of beliefs).

ÊëòË¶ÅÔºöÂú®ÈÅéÂéªÂπæÂπ¥ÔºåÊàëÂÄëË¶ãË≠â‰∫ÜÂ§ßÂûãÁü•Ë≠òÂúñË≠úÁöÑÂá∫ÁèæÔºåÁµêÂêà‰æÜËá™Â§öÂÄã‰æÜÊ∫êÁöÑË≥áË®ä„ÄÇÊúâÊôÇÔºåÈÄô‰∫õË≥áË®äÊúÉ‰ª•Â∞çÂÖ∂‰ªñÊñ∑Ë®ÄÁöÑÊñ∑Ë®ÄÂΩ¢ÂºèÊèê‰æõÔºåÂÆöÁæ©Êñ∑Ë®ÄÊúâÊïàÁöÑËÑàÁµ°„ÄÇÊúÄËøëÂ∞ç RDF ÁöÑÊì¥ÂÖÖÔºåÂÖÅË®±Â∞çÈô≥Ëø∞ÈÄ≤Ë°åÈô≥Ëø∞ÔºåÁ®±ÁÇ∫ RDF-starÔºåÊ≠£Âú®‰øÆË®ÇÁÇ∫ W3C Ê®ôÊ∫ñ„ÄÇÁÑ∂ËÄåÔºåÁõÆÂâçÊ≤íÊúâÈáùÂ∞çÈÄô‰∫õ RDF-star Èô≥Ëø∞ÁöÑË™ûÊÑèÂª∫Ë≠∞Ôºå‰πüÊ≤íÊúâÂÖßÂª∫ÁöÑÈÅã‰ΩúÂäüËÉΩ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂü∫ÊñºÂõõÂÄºÈÇèËºØÁöÑÁü•Ë≠ò RDF-star ÂÖÉË≥áÊñôÊü•Ë©¢Ë™ûË®ÄÔºåÁ®±ÁÇ∫ eSPARQL„ÄÇÊàëÂÄëÊèêÂá∫ÁöÑÊü•Ë©¢Ë™ûË®ÄÊì¥ÂÖÖ‰∫Ü RDF-star ÁöÑÊü•Ë©¢Ë™ûË®Ä SPARQL-starÔºåÊñ∞Â¢û‰∏ÄÁ®Æ FROM Â≠êÂè•È°ûÂûãÔºå‰ª•Âà©Êñº‰ΩøÁî®Â§öÈáç‰∏îÊúâÊôÇÁõ∏‰∫íË°ùÁ™ÅÁöÑ‰ø°ÂøµÈÄ≤Ë°åÈÅã‰Ωú„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫ÜÊâÄÊèêÂá∫ÁöÑÊü•Ë©¢Ë™ûË®ÄÂèØ‰ª•Ë°®ÈÅîÂõõÁ®Æ‰ΩøÁî®Ê°à‰æãÊü•Ë©¢ÔºåÂåÖÊã¨‰ª•‰∏ãÂäüËÉΩÔºö(i) Êü•Ë©¢ÂÄã‰∫∫ÁöÑ‰ø°ÂøµÔºå(ii) ÂΩôÁ∏Ω‰ø°ÂøµÔºå(iii) Êü•Ë©¢ËàáÊüê‰∫∫Ë°ùÁ™ÅÁöÑÊòØË™∞Ôºå‰ª•Âèä (iv) ÈóúÊñº‰ø°ÂøµÁöÑ‰ø°ÂøµÔºàÂç≥‰ø°ÂøµÁöÑÂ∑¢ÁãÄÔºâ„ÄÇ

##### **Navigating Beyond Instructions: Vision-and-Language Navigation in Obstructed Environments**
2407.21452v1 by Haodong Hong, Sen Wang, Zi Huang, Qi Wu, Jiajun Liu

Real-world navigation often involves dealing with unexpected obstructions
such as closed doors, moved objects, and unpredictable entities. However,
mainstream Vision-and-Language Navigation (VLN) tasks typically assume
instructions perfectly align with the fixed and predefined navigation graphs
without any obstructions. This assumption overlooks potential discrepancies in
actual navigation graphs and given instructions, which can cause major failures
for both indoor and outdoor agents. To address this issue, we integrate diverse
obstructions into the R2R dataset by modifying both the navigation graphs and
visual observations, introducing an innovative dataset and task, R2R with
UNexpected Obstructions (R2R-UNO). R2R-UNO contains various types and numbers
of path obstructions to generate instruction-reality mismatches for VLN
research. Experiments on R2R-UNO reveal that state-of-the-art VLN methods
inevitably encounter significant challenges when facing such mismatches,
indicating that they rigidly follow instructions rather than navigate
adaptively. Therefore, we propose a novel method called ObVLN (Obstructed VLN),
which includes a curriculum training strategy and virtual graph construction to
help agents effectively adapt to obstructed environments. Empirical results
show that ObVLN not only maintains robust performance in unobstructed scenarios
but also achieves a substantial performance advantage with unexpected
obstructions.

ÊëòË¶ÅÔºöÁé∞ÂÆû‰∏ñÁïåÁöÑÂØºËà™ÈÄöÂ∏∏Ê∂âÂèäÂ§ÑÁêÜÊÑèÂ§ñÁöÑÈöúÁ¢çÔºå‰æãÂ¶ÇÂÖ≥ÁùÄÁöÑÈó®„ÄÅÁßªÂä®ÁöÑÁâ©‰ΩìÂíå‰∏çÂèØÈ¢ÑÊµãÁöÑÂÆû‰Ωì„ÄÇÁÑ∂ËÄåÔºå‰∏ªÊµÅÁöÑËßÜËßâÂíåËØ≠Ë®ÄÂØºËà™ (VLN) ‰ªªÂä°ÈÄöÂ∏∏ÂÅáËÆæÊåá‰ª§‰∏éÂõ∫ÂÆöÁöÑÂíåÈ¢ÑÂÆö‰πâÁöÑÂØºËà™ÂõæÂÆåÂÖ®‰∏ÄËá¥ÔºåÊ≤°Êúâ‰ªª‰ΩïÈöúÁ¢ç„ÄÇËøôÁßçÂÅáËÆæÂøΩÁï•‰∫ÜÂÆûÈôÖÂØºËà™ÂõæÂíåÁªôÂÆöÊåá‰ª§‰∏≠ÊΩúÂú®ÁöÑÂ∑ÆÂºÇÔºåËøôÂèØËÉΩ‰ºöÂØºËá¥ÂÆ§ÂÜÖÂíåÂÆ§Â§ñ‰ª£ÁêÜÂá∫Áé∞ÈáçÂ§ßÊïÖÈöú„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢òÔºåÊàë‰ª¨ÈÄöËøá‰øÆÊîπÂØºËà™ÂõæÂíåËßÜËßâËßÇÂØüÔºåÂ∞ÜÂêÑÁßçÈöúÁ¢çÊï¥ÂêàÂà∞ R2R Êï∞ÊçÆÈõÜ‰∏≠ÔºåÂºïÂÖ•‰∫ÜÂàõÊñ∞Êï∞ÊçÆÈõÜÂíå‰ªªÂä°ÔºåÂç≥Â∏¶ÊúâÊÑèÂ§ñÈöúÁ¢çÁöÑ R2R (R2R-UNO)„ÄÇR2R-UNO ÂåÖÂê´ÂêÑÁßçÁ±ªÂûãÂíåÊï∞ÈáèÁöÑË∑ØÂæÑÈöúÁ¢çÔºå‰ª•ÁîüÊàê VLN Á†îÁ©∂ÁöÑÊåá‰ª§-Áé∞ÂÆû‰∏çÂåπÈÖç„ÄÇÂú® R2R-UNO ‰∏äÁöÑÂÆûÈ™åË°®ÊòéÔºåÊúÄÂÖàËøõÁöÑ VLN ÊñπÊ≥ïÂú®Èù¢ÂØπÊ≠§Á±ª‰∏çÂåπÈÖçÊó∂‰∏çÂèØÈÅøÂÖçÂú∞‰ºöÈÅáÂà∞ÈáçÂ§ßÊåëÊàòÔºåËøôË°®ÊòéÂÆÉ‰ª¨‰∏•Ê†ºÈÅµÂæ™Êåá‰ª§ÔºåËÄå‰∏çÊòØËá™ÈÄÇÂ∫îÂú∞ÂØºËà™„ÄÇÂõ†Ê≠§ÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçÁß∞‰∏∫ ObVLNÔºàÂèóÈòª VLNÔºâÁöÑÊñ∞ÊñπÊ≥ïÔºåÂÖ∂‰∏≠ÂåÖÊã¨ËØæÁ®ãËÆ≠ÁªÉÁ≠ñÁï•ÂíåËôöÊãüÂõæÊûÑÂª∫Ôºå‰ª•Â∏ÆÂä©‰ª£ÁêÜÊúâÊïàÂú∞ÈÄÇÂ∫îÂèóÈòªÁéØÂ¢É„ÄÇÁªèÈ™åÁªìÊûúË°®ÊòéÔºåObVLN ‰∏ç‰ªÖÂú®Êó†ÈöúÁ¢çÂú∫ÊôØ‰∏≠‰øùÊåÅ‰∫ÜÁ®≥ÂÅ•ÁöÑÊÄßËÉΩÔºåËÄå‰∏îÂú®ÊÑèÂ§ñÈöúÁ¢ç‰∏≠‰πüËé∑Âæó‰∫ÜÂÆûË¥®ÊÄßÁöÑÊÄßËÉΩ‰ºòÂäø„ÄÇ

##### **Tree-of-Traversals: A Zero-Shot Reasoning Algorithm for Augmenting Black-box Language Models with Knowledge Graphs**
2407.21358v1 by Elan Markowitz, Anil Ramakrishna, Jwala Dhamala, Ninareh Mehrabi, Charith Peris, Rahul Gupta, Kai-Wei Chang, Aram Galstyan

Knowledge graphs (KGs) complement Large Language Models (LLMs) by providing
reliable, structured, domain-specific, and up-to-date external knowledge.
However, KGs and LLMs are often developed separately and must be integrated
after training. We introduce Tree-of-Traversals, a novel zero-shot reasoning
algorithm that enables augmentation of black-box LLMs with one or more KGs. The
algorithm equips a LLM with actions for interfacing a KG and enables the LLM to
perform tree search over possible thoughts and actions to find high confidence
reasoning paths. We evaluate on two popular benchmark datasets. Our results
show that Tree-of-Traversals significantly improves performance on question
answering and KG question answering tasks. Code is available at
\url{https://github.com/amazon-science/tree-of-traversals}

ÊëòË¶ÅÔºöÁü•Ë≠òÂúñË≠ú (KG) ÈÄèÈÅéÊèê‰æõÂèØÈù†„ÄÅÁµêÊßãÂåñ„ÄÅÁâπÂÆöÊñºÈ†òÂüü‰∏îÊúÄÊñ∞ÁöÑÂ§ñÈÉ®Áü•Ë≠òÔºå‰æÜË£úÂÖÖÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM)„ÄÇ
ÁÑ∂ËÄåÔºåKG Âíå LLM ÈÄöÂ∏∏ÊòØÂàÜÈñãÈñãÁôºÔºå‰∏¶‰∏îÂøÖÈ†àÂú®Ë®ìÁ∑¥ÂæåÊï¥Âêà„ÄÇÊàëÂÄë‰ªãÁ¥π‰∫Ü Tree-of-TraversalsÔºå‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÈõ∂Ê¨°Êé®ÁêÜÊºîÁÆóÊ≥ïÔºåÂÆÉËÉΩËÆìÈªëÁõí LLM ‰ΩøÁî®‰∏ÄÂÄãÊàñÂ§öÂÄã KG„ÄÇË©≤ÊºîÁÆóÊ≥ïÁÇ∫ LLM Êèê‰æõËàá KG ‰ªãÈù¢ÁöÑÂãï‰ΩúÔºå‰∏¶ËÆì LLM ËÉΩÂú®ÂèØËÉΩÁöÑÊÄùËÄÉÂíåÂãï‰Ωú‰∏äÂü∑Ë°åÊ®πÁãÄÊêúÂ∞ãÔºå‰ª•ÊâæÂá∫È´òÂ∫¶‰ø°ÂøÉÁöÑÊé®ÁêÜË∑ØÂæë„ÄÇÊàëÂÄëÂú®ÂÖ©ÂÄãÁÜ±ÈñÄÁöÑÂü∫Ê∫ñË≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åË©ï‰º∞„ÄÇÊàëÂÄëÁöÑÁµêÊûúÈ°ØÁ§∫ÔºåTree-of-Traversals Â§ßÂπÖÊèêÂçá‰∫ÜÂïèÈ°åËß£Á≠îÂíå KG ÂïèÈ°åËß£Á≠î‰ªªÂãôÁöÑÊïàËÉΩ„ÄÇÁ®ãÂºèÁ¢ºÂèØÂú® \url{https://github.com/amazon-science/tree-of-traversals} ÂèñÂæó

##### **SimpleLLM4AD: An End-to-End Vision-Language Model with Graph Visual Question Answering for Autonomous Driving**
2407.21293v1 by Peiru Zheng, Yun Zhao, Zhan Gong, Hong Zhu, Shaohua Wu

Many fields could benefit from the rapid development of the large language
models (LLMs). The end-to-end autonomous driving (e2eAD) is one of the
typically fields facing new opportunities as the LLMs have supported more and
more modalities. Here, by utilizing vision-language model (VLM), we proposed an
e2eAD method called SimpleLLM4AD. In our method, the e2eAD task are divided
into four stages, which are perception, prediction, planning, and behavior.
Each stage consists of several visual question answering (VQA) pairs and VQA
pairs interconnect with each other constructing a graph called Graph VQA
(GVQA). By reasoning each VQA pair in the GVQA through VLM stage by stage, our
method could achieve e2e driving with language. In our method, vision
transformers (ViT) models are employed to process nuScenes visual data, while
VLM are utilized to interpret and reason about the information extracted from
the visual inputs. In the perception stage, the system identifies and
classifies objects from the driving environment. The prediction stage involves
forecasting the potential movements of these objects. The planning stage
utilizes the gathered information to develop a driving strategy, ensuring the
safety and efficiency of the autonomous vehicle. Finally, the behavior stage
translates the planned actions into executable commands for the vehicle. Our
experiments demonstrate that SimpleLLM4AD achieves competitive performance in
complex driving scenarios.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÂø´ÈÄüÁôºÂ±ïÂèØËÉΩ‰ΩøË®±Â§öÈ†òÂüüÂèóÁõä„ÄÇÁ´ØÂà∞Á´ØËá™ÂãïÈßïÈßõ (e2eAD) ÊòØÂÖ∏ÂûãÈ†òÂüü‰πã‰∏ÄÔºåÂõ†ÁÇ∫ LLM ÊîØÊè¥Ë∂ä‰æÜË∂äÂ§öÁöÑÊ®°ÂºèÔºåÂõ†Ê≠§Èù¢Ëá®Êñ∞ÁöÑÊ©üÊúÉ„ÄÇÂú®Ê≠§ÔºåÈÄèÈÅéÂà©Áî®Ë¶ñË¶∫Ë™ûË®ÄÊ®°Âûã (VLM)ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÁ®±ÁÇ∫ SimpleLLM4AD ÁöÑ e2eAD ÊñπÊ≥ï„ÄÇÂú®ÊàëÂÄëÁöÑÊ®°Âûã‰∏≠Ôºåe2eAD ‰ªªÂãôÂàÜÁÇ∫ÂõõÂÄãÈöéÊÆµÔºåÂàÜÂà•ÊòØÊÑüÁü•„ÄÅÈ†êÊ∏¨„ÄÅË¶èÂäÉÂíåË°åÁÇ∫„ÄÇÊØèÂÄãÈöéÊÆµÂåÖÂê´Â§öÂÄãË¶ñË¶∫ÂïèÁ≠î (VQA) ÈÖçÂ∞çÔºå‰∏î VQA ÈÖçÂ∞çÁõ∏‰∫íÈÄ£Êé•ÔºåÊßãÂª∫‰∏ÄÂÄãÁ®±ÁÇ∫ÂúñÂΩ¢ VQA (GVQA) ÁöÑÂúñÂΩ¢„ÄÇÈÄèÈÅé VLM ÂàÜÈöéÊÆµÊé®ÁêÜ GVQA ‰∏≠ÁöÑÊØèÂÄã VQA ÈÖçÂ∞çÔºåÊàëÂÄëÁöÑÊ®°ÂûãÂèØ‰ª•ÈÄèÈÅéË™ûË®ÄÂØ¶ÁèæÁ´ØÂà∞Á´ØÈßïÈßõ„ÄÇÂú®ÊàëÂÄëÁöÑÊ®°Âûã‰∏≠ÔºåÊé°Áî®Ë¶ñË¶∫Transformer (ViT) Ê®°Âûã‰æÜËôïÁêÜ nuScenes Ë¶ñË¶∫Ë≥áÊñôÔºåÂêåÊôÇÂà©Áî® VLM ‰æÜË©ÆÈáãÂíåÊé®ÁêÜÂæûË¶ñË¶∫Ëº∏ÂÖ•‰∏≠ÊèêÂèñÁöÑË≥áË®ä„ÄÇÂú®ÊÑüÁü•ÈöéÊÆµÔºåÁ≥ªÁµ±Ë≠òÂà•ÂíåÂàÜÈ°ûÈßïÈßõÁí∞Â¢É‰∏≠ÁöÑÁâ©‰ª∂„ÄÇÈ†êÊ∏¨ÈöéÊÆµÊ∂âÂèäÈ†êÊ∏¨ÈÄô‰∫õÁâ©‰ª∂ÁöÑÊΩõÂú®ÁßªÂãï„ÄÇË¶èÂäÉÈöéÊÆµÂà©Áî®Êî∂ÈõÜÁöÑË≥áË®ä‰æÜÂà∂ÂÆöÈßïÈßõÁ≠ñÁï•ÔºåÁ¢∫‰øùËá™ÂãïÈßïÈßõÊ±ΩËªäÁöÑÂÆâÂÖ®ÊÄßÂíåÊïàÁéá„ÄÇÊúÄÂæåÔºåË°åÁÇ∫ÈöéÊÆµÂ∞áË¶èÂäÉÁöÑÂãï‰ΩúËΩâÊèõÁÇ∫ËªäËºõÂèØÂü∑Ë°åÁöÑÂëΩ‰ª§„ÄÇÊàëÂÄëÁöÑÂØ¶È©óË≠âÊòéÔºåSimpleLLM4AD Âú®Ë§áÈõúÁöÑÈßïÈßõÂ†¥ÊôØ‰∏≠ÂØ¶Áèæ‰∫ÜÁ´∂Áà≠Âäõ„ÄÇ

##### **Be aware of overfitting by hyperparameter optimization!**
2407.20786v1 by Igor V. Tetko, Ruud van Deursen, Guillaume Godin

Hyperparameter optimization is very frequently employed in machine learning.
However, an optimization of a large space of parameters could result in
overfitting of models. In recent studies on solubility prediction the authors
collected seven thermodynamic and kinetic solubility datasets from different
data sources. They used state-of-the-art graph-based methods and compared
models developed for each dataset using different data cleaning protocols and
hyperparameter optimization. In our study we showed that hyperparameter
optimization did not always result in better models, possibly due to
overfitting when using the same statistical measures. Similar results could be
calculated using pre-set hyperparameters, reducing the computational effort by
around 10,000 times. We also extended the previous analysis by adding a
representation learning method based on Natural Language Processing of smiles
called Transformer CNN. We show that across all analyzed sets using exactly the
same protocol, Transformer CNN provided better results than graph-based methods
for 26 out of 28 pairwise comparisons by using only a tiny fraction of time as
compared to other methods. Last but not least we stressed the importance of
comparing calculation results using exactly the same statistical measures.

ÊëòË¶ÅÔºöÊ©üÂô®Â≠∏Áøí‰∏≠ÈùûÂ∏∏È†ªÁπÅÂú∞‰ΩøÁî®Ë∂ÖÂèÉÊï∏ÊúÄ‰Ω≥Âåñ„ÄÇ
ÁÑ∂ËÄåÔºåÂ∞çÂ§ßÂèÉÊï∏Á©∫ÈñìÈÄ≤Ë°åÊúÄ‰Ω≥ÂåñÂèØËÉΩÊúÉÂ∞éËá¥Ê®°ÂûãÈÅéÊì¨Âêà„ÄÇÂú®ÊúÄËøëÂ∞çÊ∫∂Ëß£Â∫¶È†êÊ∏¨ÁöÑÁ†îÁ©∂‰∏≠Ôºå‰ΩúËÄÖÂæû‰∏çÂêåÁöÑÊï∏ÊìöÊ∫êÊî∂ÈõÜ‰∫Ü‰∏ÉÂÄãÁÜ±ÂäõÂ≠∏ÂíåÂãïÂäõÂ≠∏Ê∫∂Ëß£Â∫¶Êï∏ÊìöÈõÜ„ÄÇ‰ªñÂÄë‰ΩøÁî®‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÂü∫ÊñºÂúñÂΩ¢ÁöÑÊñπÊ≥ïÔºå‰∏¶ÊØîËºÉ‰∫Ü‰ΩøÁî®‰∏çÂêåÁöÑÊï∏ÊìöÊ∏ÖÊ¥óÂçîË≠∞ÂíåË∂ÖÂèÉÊï∏ÊúÄ‰Ω≥ÂåñÁÇ∫ÊØèÂÄãÊï∏ÊìöÈõÜÈñãÁôºÁöÑÊ®°Âûã„ÄÇÂú®ÊàëÂÄëÁöÑÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄëË°®ÊòéË∂ÖÂèÉÊï∏ÊúÄ‰Ω≥Âåñ‰∏¶ÈùûÁ∏ΩÊòØÊúÉÁî¢ÁîüÊõ¥Â•ΩÁöÑÊ®°ÂûãÔºåÈÄôÂèØËÉΩÊòØÁî±ÊñºÂú®‰ΩøÁî®Áõ∏ÂêåÁöÑÁµ±Ë®àÊ∏¨ÈáèÊôÇÁôºÁîüÈÅéÊì¨Âêà„ÄÇÂèØ‰ª•‰ΩøÁî®È†êË®≠ÁöÑË∂ÖÂèÉÊï∏Ë®àÁÆóÈ°û‰ººÁöÑÁµêÊûúÔºåÂæûËÄåÂ∞áË®àÁÆóÂ∑•‰ΩúÈáèÊ∏õÂ∞ëÁ¥Ñ 10,000 ÂÄç„ÄÇÊàëÂÄëÈÇÑÈÄöÈÅéÊ∑ªÂä†Âü∫ÊñºÁ¨ëÂÆπÁöÑËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜÁöÑË°®Á§∫Â≠∏ÁøíÊñπÊ≥ïÔºàÁ®±ÁÇ∫ Transformer CNNÔºâ‰æÜÊì¥Â±ïÂÖàÂâçÁöÑÂàÜÊûê„ÄÇÊàëÂÄëË°®ÊòéÔºåÂú®‰ΩøÁî®ÂÆåÂÖ®Áõ∏ÂêåÁöÑÂçîË≠∞Â∞çÊâÄÊúâÂàÜÊûêÁöÑÈõÜÂêàÈÄ≤Ë°åÂàÜÊûêÊôÇÔºåTransformer CNN Âú® 28 ÂÄãÊàêÂ∞çÊØîËºÉ‰∏≠Êúâ 26 ÂÄãÊØîËºÉÊØîÂü∫ÊñºÂúñÂΩ¢ÁöÑÊñπÊ≥ïÊèê‰æõ‰∫ÜÊõ¥Â•ΩÁöÑÁµêÊûúÔºåËÄåËàáÂÖ∂‰ªñÊñπÊ≥ïÁõ∏ÊØîÔºåÊâÄÁî®ÁöÑÊôÇÈñìÂè™ÊòØÂæàÂ∞èÁöÑ‰∏ÄÈÉ®ÂàÜ„ÄÇÊúÄÂæå‰ΩÜ‰∏¶ÈùûÊúÄ‰∏çÈáçË¶ÅÁöÑÊòØÔºåÊàëÂÄëÂº∑Ë™ø‰∫Ü‰ΩøÁî®ÂÆåÂÖ®Áõ∏ÂêåÁöÑÁµ±Ë®àÊ∏¨Èáè‰æÜÊØîËºÉË®àÁÆóÁµêÊûúÁöÑÈáçË¶ÅÊÄß„ÄÇ

##### **Harvesting Textual and Structured Data from the HAL Publication Repository**
2407.20595v1 by Francis Kulumba, Wissam Antoun, Guillaume Vimont, Laurent Romary

HAL (Hyper Articles en Ligne) is the French national publication repository,
used by most higher education and research organizations for their open science
policy. As a digital library, it is a rich repository of scholarly documents,
but its potential for advanced research has been underutilized. We present
HALvest, a unique dataset that bridges the gap between citation networks and
the full text of papers submitted on HAL. We craft our dataset by filtering HAL
for scholarly publications, resulting in approximately 700,000 documents,
spanning 34 languages across 13 identified domains, suitable for language model
training, and yielding approximately 16.5 billion tokens (with 8 billion in
French and 7 billion in English, the most represented languages). We transform
the metadata of each paper into a citation network, producing a directed
heterogeneous graph. This graph includes uniquely identified authors on HAL, as
well as all open submitted papers, and their citations. We provide a baseline
for authorship attribution using the dataset, implement a range of
state-of-the-art models in graph representation learning for link prediction,
and discuss the usefulness of our generated knowledge graph structure.

ÊëòË¶ÅÔºöHALÔºàÁ∑ö‰∏äË∂ÖÈÄ£ÁµêÊñáÁ´†ÔºâÊòØÊ≥ïÂúãÂúãÂÆ∂Âá∫ÁâàÁâ©Ë≥áÊñôÂ∫´Ôºå
Â§ßÂ§öÊï∏È´òÁ≠âÊïôËÇ≤ÂíåÁ†îÁ©∂ÁµÑÁπîÈÉΩ‰ΩøÁî®ÂÆÉ‰æÜÂà∂ÂÆöÈñãÊîæÁßëÂ≠∏
ÊîøÁ≠ñ„ÄÇ‰ΩúÁÇ∫‰∏ÄÂÄãÊï∏‰ΩçÂúñÊõ∏È§®ÔºåÂÆÉÊòØ‰∏ÄÂÄãË±êÂØåÁöÑÂ≠∏Ë°ìÊñá‰ª∂Ë≥áÊñôÂ∫´Ôºå
‰ΩÜÂÆÉÂú®ÈÄ≤ÈöéÁ†îÁ©∂ÁöÑÊΩõÂäõÂ∞öÊú™Ë¢´ÂÖÖÂàÜÂà©Áî®„ÄÇÊàëÂÄëÊèêÂá∫
HALvestÔºå‰∏ÄÂÄãÁç®ÁâπÁöÑË≥áÊñôÈõÜÔºåÂÆÉÂΩåË£ú‰∫ÜÂºïÊñáÁ∂≤Ë∑ØÂíå
Âú® HAL ‰∏äÊèê‰∫§ÁöÑË´ñÊñáÂÖ®Êñá‰πãÈñìÁöÑÂ∑ÆË∑ù„ÄÇÊàëÂÄëÈÄèÈÅéÁØ©ÈÅ∏ HAL
‰∏≠ÁöÑÂ≠∏Ë°ìÂá∫ÁâàÂìÅ‰æÜÂª∫Á´ãÊàëÂÄëÁöÑË≥áÊñôÈõÜÔºåÊúÄÂæåÂæóÂà∞Á¥Ñ 70 Ëê¨‰ªΩÊñá‰ª∂Ôºå
Ê∂µËìã 13 ÂÄãÂ∑≤Ë≠òÂà•È†òÂüüÁöÑ 34 Á®ÆË™ûË®ÄÔºåÈÅ©ÂêàË™ûË®ÄÊ®°Âûã
Ë®ìÁ∑¥Ôºå‰∏¶Áî¢ÁîüÁ¥Ñ 165 ÂÑÑÂÄãË©ûÂΩôÔºàÂÖ∂‰∏≠Ê≥ïÊñáÊúâ 80 ÂÑÑÂÄãÔºå
Ëã±ÊñáÊúâ 70 ÂÑÑÂÄãÔºåÊòØÊúÄÂÖ∑‰ª£Ë°®ÊÄßÁöÑË™ûË®ÄÔºâ„ÄÇÊàëÂÄëÂ∞á
ÊØèÁØáË´ñÊñáÁöÑÂÖÉË≥áÊñôËΩâÊèõÊàêÂºïÊñáÁ∂≤Ë∑ØÔºåÁî¢Áîü‰∏ÄÂÄãÊúâÂêë
Áï∞Ë≥™ÂúñÂΩ¢„ÄÇÊ≠§ÂúñÂΩ¢ÂåÖÂê´Âú® HAL ‰∏äÂîØ‰∏ÄË≠òÂà•ÁöÑ‰ΩúËÄÖÔºå‰ª•Âèä
ÊâÄÊúâÂÖ¨ÈñãÊèê‰∫§ÁöÑË´ñÊñáÂèäÂÖ∂ÂºïÊñá„ÄÇÊàëÂÄëÊèê‰æõ‰∏ÄÂÄãÂü∫Ê∫ñ
‰ΩøÁî®Ë≥áÊñôÈõÜÈÄ≤Ë°å‰ΩúËÄÖÊ≠∏Â±¨ÔºåÂØ¶‰Ωú‰∏ÄÁ≥ªÂàó
ÊúÄÂÖàÈÄ≤ÁöÑÂúñÂΩ¢Ë°®Á§∫Â≠∏ÁøíÊ®°ÂûãÈÄ≤Ë°åÈÄ£ÁµêÈ†êÊ∏¨Ôºå
‰∏¶Ë®éË´ñÊàëÂÄëÁî¢ÁîüÁöÑÁü•Ë≠òÂúñÂΩ¢ÁµêÊßãÁöÑÂØ¶Áî®ÊÄß„ÄÇ

##### **CLR-Fact: Evaluating the Complex Logical Reasoning Capability of Large Language Models over Factual Knowledge**
2407.20564v1 by Tianshi Zheng, Jiaxin Bai, Yicheng Wang, Tianqing Fang, Yue Guo, Yauwai Yim, Yangqiu Song

While large language models (LLMs) have demonstrated impressive capabilities
across various natural language processing tasks by acquiring rich factual
knowledge from their broad training data, their ability to synthesize and
logically reason with this knowledge in complex ways remains underexplored. In
this work, we present a systematic evaluation of state-of-the-art LLMs' complex
logical reasoning abilities through a novel benchmark of automatically
generated complex reasoning questions over general domain and biomedical
knowledge graphs. Our extensive experiments, employing diverse in-context
learning techniques, reveal that LLMs excel at reasoning over general world
knowledge but face significant challenges with specialized domain-specific
knowledge. We find that prompting with explicit Chain-of-Thought demonstrations
can substantially improve LLM performance on complex logical reasoning tasks
with diverse logical operations. Interestingly, our controlled evaluations
uncover an asymmetry where LLMs display proficiency at set union operations,
but struggle considerably with set intersections - a key building block of
logical reasoning. To foster further work, we will publicly release our
evaluation benchmark and code.

ÊëòË¶ÅÔºöÂÑòÁÆ°Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤Â±ïÁèæÂá∫‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑËÉΩÂäõÔºåÂèØÈÄèÈÅéÂæûÂª£Ê≥õÁöÑË®ìÁ∑¥Ë≥áÊñô‰∏≠Áç≤ÂèñË±êÂØåÁöÑ‰∫ãÂØ¶Áü•Ë≠òÔºåÂü∑Ë°åÂêÑÁ®ÆËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ‰ªªÂãôÔºå‰ΩÜÂÆÉÂÄëÁ∂úÂêàÈÅãÁî®‰∏¶‰ª•Ë§áÈõúÁöÑÊñπÂºèÈÅãÁî®Ê≠§Áü•Ë≠òÈÄ≤Ë°åÈÇèËºØÊé®ÁêÜÁöÑËÉΩÂäõ‰ªçÊúâÂæÖÈÄ≤‰∏ÄÊ≠•Êé¢Ë®é„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÈÄèÈÅé‰∏ÄÂÄãËá™ÂãïÁîüÊàêÁöÑ‰∏ÄËà¨È†òÂüüÂíåÁîüÁâ©ÈÜ´Â≠∏Áü•Ë≠òÂúñË°®Ë§áÈõúÊé®ÁêÜÂïèÈ°åÁöÑÊñ∞Âü∫Ê∫ñÔºåÂ∞çÊúÄÂÖàÈÄ≤ÁöÑ LLM Ë§áÈõúÈÇèËºØÊé®ÁêÜËÉΩÂäõÈÄ≤Ë°åÁ≥ªÁµ±ÊÄßË©ï‰º∞„ÄÇÊàëÂÄëÁöÑÂª£Ê≥õÂØ¶È©óÊé°Áî®Â§öÊ®£ÂåñÁöÑÊÉÖÂ¢ÉÂ≠∏ÁøíÊäÄË°ìÔºåÊè≠Á§∫Âá∫ LLM ÊìÖÈï∑Â∞ç‰∏ÄËà¨‰∏ñÁïåÁü•Ë≠òÈÄ≤Ë°åÊé®ÁêÜÔºå‰ΩÜÂú®ËôïÁêÜÁâπÂÆöÈ†òÂüüÁöÑÂ∞àÊ•≠Áü•Ë≠òÊôÇÂâáÈù¢Ëá®ÈáçÂ§ßÊåëÊà∞„ÄÇÊàëÂÄëÁôºÁèæÔºå‰ΩøÁî®ÊòéÁ¢∫ÁöÑÊÄùËÄÉÈèàÊ¢ùÁ§∫ÁØÑÈÄ≤Ë°åÊèêÁ§∫ÔºåÂèØ‰ª•Â§ßÂπÖÊîπÂñÑ LLM Âú®ÂÖ∑ÊúâÂ§öÊ®£ÂåñÈÇèËºØÈÅãÁÆóÁöÑË§áÈõúÈÇèËºØÊé®ÁêÜ‰ªªÂãô‰∏≠ÁöÑË°®Áèæ„ÄÇÊúâË∂£ÁöÑÊòØÔºåÊàëÂÄëÁöÑÂèóÊéßË©ï‰º∞Êè≠Èú≤‰∫Ü‰∏ÄÂÄã‰∏çÂ∞çÁ®±ÊÄßÔºåÂÖ∂‰∏≠ LLM Â±ïÁèæÂá∫Âú®ÈõÜÂêàËÅØÈõÜÈÅãÁÆóÊñπÈù¢ÁöÑÁÜüÁ∑¥Â∫¶Ôºå‰ΩÜÂú®ÈõÜÂêà‰∫§ÈõÜÊñπÈù¢ÂçªÈ°ØÂæóÁõ∏Áï∂ÂêÉÂäõÔºåËÄåÈõÜÂêà‰∫§ÈõÜÊ≠£ÊòØÈÇèËºØÊé®ÁêÜÁöÑÈóúÈçµÁµÑÊàêÈÉ®ÂàÜ„ÄÇÁÇ∫‰∫Ü‰øÉÈÄ≤ÂæåÁ∫åÁ†îÁ©∂ÔºåÊàëÂÄëÂ∞áÂÖ¨ÈñãÁôºÂ∏ÉÊàëÂÄëÁöÑË©ï‰º∞Âü∫Ê∫ñÂíåÁ®ãÂºèÁ¢º„ÄÇ

##### **Prompt2DeModel: Declarative Neuro-Symbolic Modeling with Natural Language**
2407.20513v1 by Hossein Rajaby Faghihi, Aliakbar Nafar, Andrzej Uszok, Hamid Karimian, Parisa Kordjamshidi

This paper presents a conversational pipeline for crafting domain knowledge
for complex neuro-symbolic models through natural language prompts. It
leverages large language models to generate declarative programs in the
DomiKnowS framework. The programs in this framework express concepts and their
relationships as a graph in addition to logical constraints between them. The
graph, later, can be connected to trainable neural models according to those
specifications. Our proposed pipeline utilizes techniques like dynamic
in-context demonstration retrieval, model refinement based on feedback from a
symbolic parser, visualization, and user interaction to generate the tasks'
structure and formal knowledge representation. This approach empowers domain
experts, even those not well-versed in ML/AI, to formally declare their
knowledge to be incorporated in customized neural models in the DomiKnowS
framework.

ÊëòË¶ÅÔºöÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂ∞çË©±ÂºèÁÆ°ÈÅìÔºåÈÄèÈÅéËá™ÁÑ∂Ë™ûË®ÄÊèêÁ§∫ÔºåÁÇ∫Ë§áÈõúÁöÑÁ•ûÁ∂ìÁ¨¶ËôüÊ®°ÂûãÂª∫Á´ãÈ†òÂüüÁü•Ë≠ò„ÄÇÂÆÉÂà©Áî®Â§ßÂûãË™ûË®ÄÊ®°ÂûãÂú® DomiKnowS Ê°ÜÊû∂‰∏≠Áî¢ÁîüÂÆ£ÂëäÂºèÁ®ãÂºè„ÄÇÊ≠§Ê°ÜÊû∂‰∏≠ÁöÑÁ®ãÂºèÊúÉÂ∞áÊ¶ÇÂøµÂèäÂÖ∂Èóú‰øÇË°®Á§∫ÁÇ∫ÂúñÂΩ¢Ôºå‰∏¶Âú®ÂÆÉÂÄë‰πãÈñìÂä†‰∏äÈÇèËºØÁ¥ÑÊùü„ÄÇ‰πãÂæåÔºåÂèØ‰ª•Ê†πÊìöÈÄô‰∫õË¶èÊ†ºÂ∞áÂúñÂΩ¢ÈÄ£Êé•Âà∞ÂèØË®ìÁ∑¥ÁöÑÁ•ûÁ∂ìÊ®°Âûã„ÄÇÊàëÂÄëÊèêÂá∫ÁöÑÁÆ°ÈÅìÂà©Áî®ÂãïÊÖãÊÉÖÂ¢É‰∏≠Á§∫ÁØÑÊ™¢Á¥¢„ÄÅÂü∫ÊñºÁ¨¶ËôüËß£ÊûêÂô®ÂõûÈ•ãÁöÑÊ®°ÂûãÁ≤æÁÖâ„ÄÅË¶ñË¶∫ÂåñÂíå‰ΩøÁî®ËÄÖ‰∫íÂãïÁ≠âÊäÄË°ìÔºå‰ª•Áî¢Áîü‰ªªÂãôÁµêÊßãÂíåÂΩ¢ÂºèÁü•Ë≠òË°®Á§∫„ÄÇÈÄôÁ®ÆÊñπÊ≥ïËÆìÈ†òÂüüÂ∞àÂÆ∂ÔºåÂç≥‰ΩøÊòØ‰∏çÁÜüÊÇâÊ©üÂô®Â≠∏ÁøíÔºè‰∫∫Â∑•Êô∫ÊÖßÁöÑ‰∫∫Ôºå‰πüËÉΩÊ≠£ÂºèÂÆ£Âëä‰ªñÂÄëÁöÑÁü•Ë≠òÔºå‰∏¶Â∞áÂÖ∂Á¥çÂÖ• DomiKnowS Ê°ÜÊû∂‰∏≠ÁöÑËá™Ë®ÇÁ•ûÁ∂ìÊ®°Âûã„ÄÇ

##### **What if Red Can Talk? Dynamic Dialogue Generation Using Large Language Models**
2407.20382v1 by Navapat Nananukul, Wichayaporn Wongkamjan

Role-playing games (RPGs) provide players with a rich, interactive world to
explore. Dialogue serves as the primary means of communication between
developers and players, manifesting in various forms such as guides, NPC
interactions, and storytelling. While most games rely on written scripts to
define the main story and character personalities, player immersion can be
significantly enhanced through casual interactions between characters. With the
advent of large language models (LLMs), we introduce a dialogue filler
framework that utilizes LLMs enhanced by knowledge graphs to generate dynamic
and contextually appropriate character interactions. We test this framework
within the environments of Final Fantasy VII Remake and Pokemon, providing
qualitative and quantitative evidence that demonstrates GPT-4's capability to
act with defined personalities and generate dialogue. However, some flaws
remain, such as GPT-4 being overly positive or more subtle personalities, such
as maturity, tend to be of lower quality compared to more overt traits like
timidity. This study aims to assist developers in crafting more nuanced filler
dialogues, thereby enriching player immersion and enhancing the overall RPG
experience.

ÊëòË¶ÅÔºöËßíËâ≤ÊâÆÊºîÈÅäÊà≤ (RPG) ÁÇ∫Áé©ÂÆ∂Êèê‰æõ‰∏ÄÂÄãË±êÂØå‰∏î‰∫íÂãïÁöÑ‰∏ñÁïå‰æõÂÖ∂Êé¢Á¥¢„ÄÇÂ∞çË©±‰ΩúÁÇ∫ÈñãÁôºËÄÖËàáÁé©ÂÆ∂‰πãÈñìÁöÑ‰∏ªË¶ÅÊ∫ùÈÄöÊñπÂºèÔºå‰ª•ÊåáÂçó„ÄÅNPC ‰∫íÂãïÂíåË™™ÊïÖ‰∫ãÁ≠âÂêÑÁ®ÆÂΩ¢ÂºèÂëàÁèæ„ÄÇÈõñÁÑ∂Â§ßÂ§öÊï∏ÈÅäÊà≤‰æùË≥¥ÊñºÊõ∏Èù¢ËÖ≥Êú¨‰æÜÂÆöÁæ©‰∏ªÁ∑öÊïÖ‰∫ãÂíåËßíËâ≤ÂÄãÊÄßÔºå‰ΩÜÈÄèÈÅéËßíËâ≤‰πãÈñìÁöÑÈñíËÅä‰∫íÂãïÔºåÂèØ‰ª•Â§ßÂπÖÊèêÂçáÁé©ÂÆ∂ÁöÑÊ≤âÊµ∏ÊÑü„ÄÇÈö®ËëóÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÂá∫ÁèæÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÂ∞çË©±Â°´ÂÖÖÊ°ÜÊû∂ÔºåÂà©Áî®Áî±Áü•Ë≠òÂúñË≠úÂ¢ûÂº∑ÁöÑ LLM ‰æÜÁî¢ÁîüÂãïÊÖã‰∏îÁ¨¶ÂêàÊÉÖÂ¢ÉÁöÑÂ∞çË©±‰∫íÂãï„ÄÇÊàëÂÄëÂú® Final Fantasy VII Remake ÂíåÂØ∂ÂèØÂ§¢ÁöÑÁí∞Â¢É‰∏≠Ê∏¨Ë©¶‰∫ÜÈÄôÂÄãÊ°ÜÊû∂ÔºåÊèê‰æõ‰∫ÜÂÆöÊÄßÂíåÂÆöÈáèÁöÑË≠âÊìöÔºåË≠âÊòé‰∫Ü GPT-4 ÂÖ∑ÂÇô‰ª•ÂÆöÁæ©Â•ΩÁöÑÂÄãÊÄßË°åÂãï‰∏¶Áî¢ÁîüÂ∞çË©±ÁöÑËÉΩÂäõ„ÄÇÁÑ∂ËÄåÔºå‰ªçÂ≠òÂú®‰∏Ä‰∫õÁº∫Èô∑Ôºå‰æãÂ¶Ç GPT-4 ÈÅéÊñºÊ≠£Èù¢ÔºåÊàñËÄÖËºÉÁÇ∫Á¥∞ÂæÆÁöÑÂÄãÊÄßÔºå‰æãÂ¶ÇÊàêÁÜüÂ∫¶ÔºåÂæÄÂæÄÂìÅË≥™‰ΩéÊñºËºÉÊòéÈ°ØÁöÑÁâπË≥™Ôºå‰æãÂ¶ÇËÜΩÊÄØ„ÄÇÊú¨Á†îÁ©∂Êó®Âú®ÂçîÂä©ÈñãÁôºËÄÖÊâìÈÄ†Êõ¥Á¥∞Á∑ªÁöÑÂ°´ÂÖÖÂ∞çË©±ÔºåÂæûËÄåË±êÂØåÁé©ÂÆ∂ÁöÑÊ≤âÊµ∏ÊÑü‰∏¶ÊèêÂçáÊï¥È´î RPG È´îÈ©ó„ÄÇ

##### **MindSearch: Mimicking Human Minds Elicits Deep AI Searcher**
2407.20183v1 by Zehui Chen, Kuikun Liu, Qiuchen Wang, Jiangning Liu, Wenwei Zhang, Kai Chen, Feng Zhao

Information seeking and integration is a complex cognitive task that consumes
enormous time and effort. Inspired by the remarkable progress of Large Language
Models, recent works attempt to solve this task by combining LLMs and search
engines. However, these methods still obtain unsatisfying performance due to
three challenges: (1) complex requests often cannot be accurately and
completely retrieved by the search engine once (2) corresponding information to
be integrated is spread over multiple web pages along with massive noise, and
(3) a large number of web pages with long contents may quickly exceed the
maximum context length of LLMs. Inspired by the cognitive process when humans
solve these problems, we introduce MindSearch to mimic the human minds in web
information seeking and integration, which can be instantiated by a simple yet
effective LLM-based multi-agent framework. The WebPlanner models the human mind
of multi-step information seeking as a dynamic graph construction process: it
decomposes the user query into atomic sub-questions as nodes in the graph and
progressively extends the graph based on the search result from WebSearcher.
Tasked with each sub-question, WebSearcher performs hierarchical information
retrieval with search engines and collects valuable information for WebPlanner.
The multi-agent design of MindSearch enables the whole framework to seek and
integrate information parallelly from larger-scale (e.g., more than 300) web
pages in 3 minutes, which is worth 3 hours of human effort. MindSearch
demonstrates significant improvement in the response quality in terms of depth
and breadth, on both close-set and open-set QA problems. Besides, responses
from MindSearch based on InternLM2.5-7B are preferable by humans to ChatGPT-Web
and Perplexity.ai applications, which implies that MindSearch can already
deliver a competitive solution to the proprietary AI search engine.

ÊëòË¶ÅÔºöË≥áË®äÊêúÂ∞ãËàáÊï¥ÂêàÊòØ‰∏ÄÈ†ÖË§áÈõúÁöÑË™çÁü•‰ªªÂãôÔºåÊúÉËÄóË≤ªÂ§ßÈáèÊôÇÈñìËàáÁ≤æÂäõ„ÄÇÂú®Â§ßÂûãË™ûË®ÄÊ®°ÂûãÈ°ØËëóÈÄ≤Â±ïÁöÑÂïüÁôº‰∏ãÔºåËøëÊúüÁ†îÁ©∂ÂòóË©¶ÁµêÂêàÂ§ßÂûãË™ûË®ÄÊ®°ÂûãËàáÊêúÂ∞ãÂºïÊìé‰æÜËß£Ê±∫Ê≠§‰ªªÂãô„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÊñπÊ≥ï‰ªçÂõ†‰∏âÈ†ÖÊåëÊà∞ËÄåÁÑ°Ê≥ïÁç≤Âæó‰ª§‰∫∫ÊªøÊÑèÁöÑÊïàËÉΩÔºö(1) Ë§áÈõúÁöÑÊü•Ë©¢ÈÄöÂ∏∏ÁÑ°Ê≥ïÁî±ÊêúÂ∞ãÂºïÊìé‰∏ÄÊ¨°Ê∫ñÁ¢∫‰∏îÂÆåÊï¥Âú∞Êì∑ÂèñÔºå(2) Ë¶ÅÊï¥ÂêàÁöÑÂ∞çÊáâË≥áË®äÊï£Â∏ÉÂú®Â§öÂÄãÁ∂≤È†Å‰∏≠‰∏î‰º¥Èö®ËëóÂ§ßÈáèÈõúË®äÔºå‰ª•Âèä (3) Â§ßÈáèÂÖßÂÆπÈÅéÈï∑ÁöÑÁ∂≤È†ÅÂèØËÉΩÊúÉÂø´ÈÄüË∂ÖÈÅéÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÁöÑÊúÄÂ§ßËÑàÁµ°Èï∑Â∫¶„ÄÇÂú®‰∫∫È°ûËß£Ê±∫ÈÄô‰∫õÂïèÈ°åÁöÑË™çÁü•ÈÅéÁ®ã‰∏≠Áç≤ÂæóÈùàÊÑüÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü MindSearch ‰æÜÊ®°Êì¨‰∫∫È°ûÂøÉÊô∫Âú®Á∂≤È†ÅË≥áË®äÊêúÂ∞ãËàáÊï¥Âêà‰∏≠ÁöÑË°åÁÇ∫ÔºåÈÄôÂèØ‰ª•Áî®‰∏ÄÂÄãÁ∞°ÂñÆ‰ΩÜÊúâÊïàÁöÑÂü∫ÊñºÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÁöÑÂ§ö‰ª£ÁêÜÊû∂Êßã‰æÜÂØ¶‰æãÂåñ„ÄÇWebPlanner ‰ª•ÂãïÊÖãÂúñÂΩ¢Âª∫ÊßãÈÅéÁ®ã‰æÜÂª∫Ê®°‰∫∫È°ûÂøÉÊô∫ÁöÑÂ§öÊ≠•È©üË≥áË®äÊêúÂ∞ãÔºöÂÆÉÂ∞á‰ΩøÁî®ËÄÖÊü•Ë©¢ÂàÜËß£ÊàêÂúñÂΩ¢‰∏≠ÁöÑÁØÄÈªûÔºå‰ΩúÁÇ∫ÂéüÂ≠êÂåñÂ≠êÂïèÈ°åÔºå‰∏¶Ê†πÊìö WebSearcher ÁöÑÊêúÂ∞ãÁµêÊûúÈÄêÊ≠•Âª∂‰º∏ÂúñÂΩ¢„ÄÇWebSearcher ‰ª•ÊØèÂÄãÂ≠êÂïèÈ°åÁÇ∫‰ªªÂãôÔºåÂü∑Ë°åÊêúÂ∞ãÂºïÊìéÁöÑÂàÜÂ±§ÂºèË≥áË®äÊì∑ÂèñÔºå‰∏¶ÁÇ∫ WebPlanner Êî∂ÈõÜÊúâÂÉπÂÄºÁöÑË≥áË®ä„ÄÇMindSearch ÁöÑÂ§ö‰ª£ÁêÜË®≠Ë®àËÆìÊï¥ÂÄãÊû∂ÊßãÂèØ‰ª•Âú® 3 ÂàÜÈêòÂÖßÂπ≥Ë°åÂú∞ÂæûÊõ¥Â§ßË¶èÊ®°Ôºà‰æãÂ¶ÇË∂ÖÈÅé 300 ÂÄãÔºâÁöÑÁ∂≤È†Å‰∏≠ÊêúÂ∞ã‰∏¶Êï¥ÂêàË≥áË®äÔºåÈÄôÁõ∏Áï∂Êñº 3 Â∞èÊôÇÁöÑ‰∫∫Âäõ„ÄÇMindSearch Âú®Ê∑±Â∫¶ÂíåÂª£Â∫¶ÊñπÈù¢ÈÉΩÈ°ØËëóÊèêÂçá‰∫ÜÂõûÊáâÂìÅË≥™ÔºåÁÑ°Ë´ñÊòØÂú®Â∞ÅÈñâÂºèÊàñÈñãÊîæÂºèÂïèÁ≠îÂïèÈ°å‰∏ä„ÄÇÊ≠§Â§ñÔºå‰∫∫È°ûÊõ¥ÂÅèÂ•ΩÂü∫Êñº InternLM2.5-7B ÁöÑ MindSearch ÂõûÊáâÔºåÂãùÈÅé ChatGPT-Web Âíå Perplexity.ai ÊáâÁî®Á®ãÂºèÔºåÈÄôË°®Á§∫ MindSearch Â∑≤Á∂ìÂèØ‰ª•ÁÇ∫Â∞àÊúâ AI ÊêúÂ∞ãÂºïÊìéÊèê‰æõÊúâÁ´∂Áà≠ÂäõÁöÑËß£Ê±∫ÊñπÊ°à„ÄÇ

##### **rLLM: Relational Table Learning with LLMs**
2407.20157v1 by Weichen Li, Xiaotong Huang, Jianwu Zheng, Zheng Wang, Chaokun Wang, Li Pan, Jianhua Li

We introduce rLLM (relationLLM), a PyTorch library designed for Relational
Table Learning (RTL) with Large Language Models (LLMs). The core idea is to
decompose state-of-the-art Graph Neural Networks, LLMs, and Table Neural
Networks into standardized modules, to enable the fast construction of novel
RTL-type models in a simple "combine, align, and co-train" manner. To
illustrate the usage of rLLM, we introduce a simple RTL method named
\textbf{BRIDGE}. Additionally, we present three novel relational tabular
datasets (TML1M, TLF2K, and TACM12K) by enhancing classic datasets. We hope
rLLM can serve as a useful and easy-to-use development framework for
RTL-related tasks. Our code is available at:
https://github.com/rllm-project/rllm.

ÊëòË¶ÅÔºöÊàëÂÄëÂºïÂÖ•‰∫Ü rLLM (relationLLM)Ôºå‰∏ÄÂÄãÂ∞àÁÇ∫Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÈóú‰øÇË°®Â≠∏Áøí (RTL) ÊâÄË®≠Ë®àÁöÑ PyTorch ÂáΩÂºèÂ∫´„ÄÇÊ†∏ÂøÉÊ¶ÇÂøµÊòØÂ∞áÊúÄÂÖàÈÄ≤ÁöÑÂúñÂΩ¢Á•ûÁ∂ìÁ∂≤Ë∑Ø„ÄÅLLM ÂíåË°®Á•ûÁ∂ìÁ∂≤Ë∑ØÂàÜËß£ÁÇ∫Ê®ôÊ∫ñÂåñÊ®°ÁµÑÔºå‰ª•‰æø‰ª•Á∞°ÂñÆÁöÑ„ÄåÁµÑÂêà„ÄÅÂ∞çÈΩäÂíåÂÖ±ÂêåË®ìÁ∑¥„ÄçÊñπÂºèÂø´ÈÄüÂª∫ÊßãÊñ∞Âûã RTL È°ûÂûãÊ®°Âûã„ÄÇÁÇ∫‰∫ÜË™™Êòé rLLM ÁöÑÁî®Ê≥ïÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜÂêçÁÇ∫ \textbf{BRIDGE} ÁöÑÁ∞°ÂñÆ RTL ÊñπÊ≥ï„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÈÄèÈÅéÂº∑ÂåñÁ∂ìÂÖ∏Ë≥áÊñôÈõÜ‰æÜÂëàÁèæ‰∏âÂÄãÊñ∞Á©éÁöÑÈóú‰øÇË°®Ê†ºË≥áÊñôÈõÜ (TML1M„ÄÅTLF2K Âíå TACM12K)„ÄÇÊàëÂÄëÂ∏åÊúõ rLLM ËÉΩÂ§†‰ΩúÁÇ∫ RTL Áõ∏Èóú‰ªªÂãôÊúâÁî®ÁöÑ‰∏îÊòìÊñº‰ΩøÁî®ÁöÑÈñãÁôºÊû∂Êßã„ÄÇÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÂèØÂú®‰ª•‰∏ãÁ∂≤ÂùÄÂèñÂæóÔºö
https://github.com/rllm-project/rllm„ÄÇ

##### **Prometheus Chatbot: Knowledge Graph Collaborative Large Language Model for Computer Components Recommendation**
2407.19643v2 by Yunsheng Wang, Songhao Chen, Kevin Jin

Knowledge graphs (KGs) are essential in applications such as network
alignment, question-answering, and recommender systems (RSs) since they offer
structured relational data that facilitate the inference of indirect
relationships. However, the development of KG-based RSs capable of processing
user inputs in natural language faces significant challenges. Firstly, natural
language processing units must effectively handle the ambiguity and variability
in human language to interpret user intents accurately. Secondly, the system
must precisely identify and link entities, like product names, to their
corresponding nodes in KGs. To overcome these challenges, supported by Lenovo,
we developed a novel chatbot called "Prometheus," which integrates a KG with a
large language model (LLM), specifically designed for recommending computer
components. This chatbot can accurately decode user requests and deliver
personalized recommendations derived from KGs, ensuring precise comprehension
and response to their computer setup needs.

ÊëòË¶ÅÔºöÁü•Ë≠òÂúñË≠ú (KG) Âú®Á∂≤Ë∑ØÊØîÂ∞ç„ÄÅÂïèÁ≠îÂíåÊé®Ëñ¶Á≥ªÁµ± (RS) Á≠âÊáâÁî®‰∏≠Ëá≥ÈóúÈáçË¶ÅÔºåÂõ†ÁÇ∫ÂÆÉÂÄëÊèê‰æõÁµêÊßãÂåñÁöÑÈóú‰øÇË≥áÊñôÔºåÊúâÂä©ÊñºÊé®Êñ∑ÈñìÊé•Èóú‰øÇ„ÄÇÁÑ∂ËÄåÔºåÈñãÁôºËÉΩÂ§†ËôïÁêÜËá™ÁÑ∂Ë™ûË®Ä‰ΩøÁî®ËÄÖËº∏ÂÖ•ÁöÑÂü∫Êñº KG ÁöÑ RS Èù¢Ëá®ËëóÈáçÂ§ßÁöÑÊåëÊà∞„ÄÇÈ¶ñÂÖàÔºåËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜÂñÆÂÖÉÂøÖÈ†àÊúâÊïàËôïÁêÜ‰∫∫È°ûË™ûË®Ä‰∏≠ÁöÑÊ®°Á≥äÊÄßÂíåËÆäÁï∞ÊÄßÔºåÊâçËÉΩÊ∫ñÁ¢∫Âú∞Ëß£Èáã‰ΩøÁî®ËÄÖÊÑèÂúñ„ÄÇÂÖ∂Ê¨°ÔºåÁ≥ªÁµ±ÂøÖÈ†àÊ∫ñÁ¢∫Ë≠òÂà•ÂíåÈÄ£ÁµêÂØ¶È´îÔºà‰æãÂ¶ÇÁî¢ÂìÅÂêçÁ®±ÔºâÂà∞ KG ‰∏≠Â∞çÊáâÁöÑÁØÄÈªû„ÄÇÁÇ∫‰∫ÜÂÖãÊúçÈÄô‰∫õÊåëÊà∞ÔºåÂú®ËÅØÊÉ≥ÁöÑÊîØÊè¥‰∏ãÔºåÊàëÂÄëÈñãÁôº‰∫Ü‰∏ÄÊ¨æÂêçÁÇ∫„ÄåÊôÆÁæÖÁ±≥‰øÆÊñØ„ÄçÁöÑÊñ∞ËÅäÂ§©Ê©üÂô®‰∫∫ÔºåÂÆÉÂ∞á KG ËàáÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Êï¥ÂêàÂú®‰∏ÄËµ∑ÔºåÂ∞àÈñÄÁî®ÊñºÊé®Ëñ¶ÈõªËÖ¶ÁµÑ‰ª∂„ÄÇÊ≠§ËÅäÂ§©Ê©üÂô®‰∫∫ÂèØ‰ª•Ê∫ñÁ¢∫Âú∞Ëß£Á¢º‰ΩøÁî®ËÄÖË¶ÅÊ±ÇÔºå‰∏¶Êèê‰æõÂæû KG ‰∏≠Ë°çÁîüÁöÑÂÄã‰∫∫ÂåñÊé®Ëñ¶ÔºåÁ¢∫‰øùÁ≤æÁ¢∫ÁêÜËß£ÂíåÂõûÊáâÂÖ∂ÈõªËÖ¶Ë®≠ÂÆöÈúÄÊ±Ç„ÄÇ

##### **TopicTag: Automatic Annotation of NMF Topic Models Using Chain of Thought and Prompt Tuning with LLMs**
2407.19616v1 by Selma Wanna, Ryan Barron, Nick Solovyev, Maksim E. Eren, Manish Bhattarai, Kim Rasmussen, Boian S. Alexandrov

Topic modeling is a technique for organizing and extracting themes from large
collections of unstructured text. Non-negative matrix factorization (NMF) is a
common unsupervised approach that decomposes a term frequency-inverse document
frequency (TF-IDF) matrix to uncover latent topics and segment the dataset
accordingly. While useful for highlighting patterns and clustering documents,
NMF does not provide explicit topic labels, necessitating subject matter
experts (SMEs) to assign labels manually. We present a methodology for
automating topic labeling in documents clustered via NMF with automatic model
determination (NMFk). By leveraging the output of NMFk and employing prompt
engineering, we utilize large language models (LLMs) to generate accurate topic
labels. Our case study on over 34,000 scientific abstracts on Knowledge Graphs
demonstrates the effectiveness of our method in enhancing knowledge management
and document organization.

ÊëòË¶ÅÔºö‰∏ªÈ°åÂª∫Ê®°ÊòØ‰∏ÄÁ®ÆÂæûÂ§ßÈáèÈùûÁµêÊßãÂåñÊñáÊú¨‰∏≠ÁµÑÁπîÂíåÊèêÂèñ‰∏ªÈ°åÁöÑÊäÄË°ì„ÄÇÈùûË≤†Áü©Èô£ÂàÜËß£ (NMF) ÊòØ‰∏ÄÁ®ÆÂ∏∏Ë¶ãÁöÑÁÑ°Áõ£Áù£ÊñπÊ≥ïÔºåÂÆÉÂ∞áË©ûÈ†ª-ÈÄÜÊñá‰ª∂È†ªÁéá (TF-IDF) Áü©Èô£ÂàÜËß£ÁÇ∫ÊΩõÂú®‰∏ªÈ°åÔºå‰∏¶ÊìöÊ≠§Â∞çÊï∏ÊìöÈõÜÈÄ≤Ë°åÂàÜÊÆµ„ÄÇÂÑòÁÆ° NMF ÂèØÁî®ÊñºÂº∑Ë™øÊ®°ÂºèÂíåÁæ§ÁµÑÊñá‰ª∂Ôºå‰ΩÜÂÆÉ‰∏çÊèê‰æõÊòéÁ¢∫ÁöÑ‰∏ªÈ°åÊ®ôÁ±§ÔºåÈÄôÈúÄË¶Å‰∏ªÈ°åÂ∞àÂÆ∂ (SME) ÊâãÂãïÂàÜÈÖçÊ®ôÁ±§„ÄÇÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñπÊ≥ïÔºåÁî®ÊñºËá™ÂãïÊ®ôË®òÈÄöÈÅé NMF ÈÄ≤Ë°åÁæ§ÁµÑÁöÑÊñá‰ª∂Ôºå‰∏¶Ëá™ÂãïÁ¢∫ÂÆöÊ®°Âûã (NMFk)„ÄÇÈÄöÈÅéÂà©Áî® NMFk ÁöÑËº∏Âá∫‰∏¶Êé°Áî®ÊèêÁ§∫Â∑•Á®ãÔºåÊàëÂÄëÂà©Áî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰æÜÁîüÊàêÊ∫ñÁ¢∫ÁöÑ‰∏ªÈ°åÊ®ôÁ±§„ÄÇÊàëÂÄëÂ∞çË∂ÖÈÅé 34,000 ÁØáÈóúÊñºÁü•Ë≠òÂúñË≠úÁöÑÁßëÂ≠∏ÊëòË¶ÅÈÄ≤Ë°åÁöÑÊ°à‰æãÁ†îÁ©∂Ë≠âÊòé‰∫ÜÊàëÂÄëÁöÑÊñπÊ≥ïÂú®Â¢ûÂº∑Áü•Ë≠òÁÆ°ÁêÜÂíåÊñá‰ª∂ÁµÑÁπîÊñπÈù¢ÁöÑÊúâÊïàÊÄß„ÄÇ

##### **Semantic Communication Enhanced by Knowledge Graph Representation Learning**
2407.19338v1 by Nour Hello, Paolo Di Lorenzo, Emilio Calvanese Strinati

This paper investigates the advantages of representing and processing
semantic knowledge extracted into graphs within the emerging paradigm of
semantic communications. The proposed approach leverages semantic and pragmatic
aspects, incorporating recent advances on large language models (LLMs) to
achieve compact representations of knowledge to be processed and exchanged
between intelligent agents. This is accomplished by using the cascade of LLMs
and graph neural networks (GNNs) as semantic encoders, where information to be
shared is selected to be meaningful at the receiver. The embedding vectors
produced by the proposed semantic encoder represent information in the form of
triplets: nodes (semantic concepts entities), edges(relations between
concepts), nodes. Thus, semantic information is associated with the
representation of relationships among elements in the space of semantic concept
abstractions. In this paper, we investigate the potential of achieving high
compression rates in communication by incorporating relations that link
elements within graph embeddings. We propose sending semantic symbols solely
equivalent to node embeddings through the wireless channel and inferring the
complete knowledge graph at the receiver. Numerical simulations illustrate the
effectiveness of leveraging knowledge graphs to semantically compress and
transmit information.

ÊëòË¶ÅÔºöÊú¨ÊñáÁ†îÁ©∂‰∫ÜÂú®ËØ≠‰πâÈÄö‰ø°ÁöÑÊñ∞ÂÖ¥ËåÉ‰æã‰∏≠Â∞ÜÊèêÂèñÂà∞Âõæ‰∏≠ÁöÑËØ≠‰πâÁü•ËØÜË°®Á§∫ÂíåÂ§ÑÁêÜÁöÑ‰ºòÂäø„ÄÇÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÂà©Áî®ËØ≠‰πâÂíåËØ≠Áî®ÊñπÈù¢ÔºåÁªìÂêà‰∫ÜÂ§ßËØ≠Ë®ÄÊ®°Âûã (LLM) ÁöÑÊúÄÊñ∞ËøõÂ±ïÔºå‰ª•ÂÆûÁé∞Ë¶ÅÂ§ÑÁêÜÂíåÂú®Êô∫ËÉΩ‰ª£ÁêÜ‰πãÈó¥‰∫§Êç¢ÁöÑÁü•ËØÜÁöÑÁ¥ßÂáëË°®Á§∫„ÄÇËøôÊòØÈÄöËøá‰ΩøÁî® LLM ÂíåÂõæÁ•ûÁªèÁΩëÁªú (GNN) ÁöÑÁ∫ßËÅî‰Ωú‰∏∫ËØ≠‰πâÁºñÁ†ÅÂô®Êù•ÂÆåÊàêÁöÑÔºåÂÖ∂‰∏≠Ë¶ÅÂÖ±‰∫´ÁöÑ‰ø°ÊÅØË¢´ÈÄâÊã©‰∏∫ÂØπÊé•Êî∂ËÄÖÊúâÊÑè‰πâ„ÄÇÁî±ÊâÄÊèêÂá∫ÁöÑËØ≠‰πâÁºñÁ†ÅÂô®‰∫ßÁîüÁöÑÂµåÂÖ•ÂêëÈáè‰ª•‰∏âÂÖÉÁªÑÁöÑÂΩ¢ÂºèË°®Á§∫‰ø°ÊÅØÔºöËäÇÁÇπÔºàËØ≠‰πâÊ¶ÇÂøµÂÆû‰ΩìÔºâ„ÄÅËæπÔºàÊ¶ÇÂøµ‰πãÈó¥ÁöÑÂÖ≥Á≥ªÔºâ„ÄÅËäÇÁÇπ„ÄÇÂõ†Ê≠§ÔºåËØ≠‰πâ‰ø°ÊÅØ‰∏éËØ≠‰πâÊ¶ÇÂøµÊäΩË±°Á©∫Èó¥‰∏≠ÂÖÉÁ¥†‰πãÈó¥ÂÖ≥Á≥ªÁöÑË°®Á§∫Áõ∏ÂÖ≥ËÅî„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨Á†îÁ©∂‰∫ÜÈÄöËøáÂêàÂπ∂Â∞ÜÂõæÂµåÂÖ•‰∏≠ÁöÑÂÖÉÁ¥†ËÅîÁ≥ªËµ∑Êù•ÁöÑÂÖ≥ËÅîÊù•ÂÆûÁé∞È´òÂéãÁº©ÁéáÁöÑÊΩúÂäõ„ÄÇÊàë‰ª¨Âª∫ËÆÆ‰ªÖÈÄöËøáÊó†Á∫ø‰ø°ÈÅìÂèëÈÄÅËØ≠‰πâÁ¨¶Âè∑ÔºåËøô‰∫õÁ¨¶Âè∑ÂÆåÂÖ®Á≠âÊïà‰∫éËäÇÁÇπÂµåÂÖ•ÔºåÂπ∂Âú®Êé•Êî∂Âô®Â§ÑÊé®Êñ≠Âá∫ÂÆåÊï¥ÁöÑÁü•ËØÜÂõæ„ÄÇÊï∞ÂÄºÊ®°ÊãüËØ¥Êòé‰∫ÜÂà©Áî®Áü•ËØÜÂõæËØ≠‰πâÂéãÁº©Âíå‰º†Ëæì‰ø°ÊÅØÁöÑÊúâÊïàÊÄß„ÄÇ

##### **GraphBPE: Molecular Graphs Meet Byte-Pair Encoding**
2407.19039v1 by Yuchen Shen, Barnab√°s P√≥czos

With the increasing attention to molecular machine learning, various
innovations have been made in designing better models or proposing more
comprehensive benchmarks. However, less is studied on the data preprocessing
schedule for molecular graphs, where a different view of the molecular graph
could potentially boost the model's performance. Inspired by the Byte-Pair
Encoding (BPE) algorithm, a subword tokenization method popularly adopted in
Natural Language Processing, we propose GraphBPE, which tokenizes a molecular
graph into different substructures and acts as a preprocessing schedule
independent of the model architectures. Our experiments on 3 graph-level
classification and 3 graph-level regression datasets show that data
preprocessing could boost the performance of models for molecular graphs, and
GraphBPE is effective for small classification datasets and it performs on par
with other tokenization methods across different model architectures.

ÊëòË¶ÅÔºöÈö®ËëóÂàÜÂ≠êÊ©üÂô®Â≠∏ÁøíÂèóÂà∞ÁöÑÈóúÊ≥®Â∫¶Ë∂ä‰æÜË∂äÈ´òÔºåÂú®Ë®≠Ë®àÊõ¥Â•ΩÁöÑÊ®°ÂûãÊàñÊèêÂá∫Êõ¥ÂÖ®Èù¢ÁöÑÂü∫Ê∫ñÊñπÈù¢Â∑≤Á∂ìÊúâ‰∫ÜÂêÑÁ®ÆÂâµÊñ∞„ÄÇÁÑ∂ËÄåÔºåÂ∞çÊñºÂàÜÂ≠êÂúñÁöÑÊï∏ÊìöÈ†êËôïÁêÜË®àÁï´Á†îÁ©∂ËºÉÂ∞ëÔºåÂú®Ë©≤Ë®àÁï´‰∏≠ÔºåÂàÜÂ≠êÂúñÁöÑ‰∏çÂêåË¶ñÂúñÂèØËÉΩÊúÉÊèêÂçáÊ®°ÂûãÁöÑÊïàËÉΩ„ÄÇÂèóÂà∞Âú®Ëá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ‰∏≠Âª£Ê≥õÊé°Áî®ÁöÑÂ≠êË©ûÂΩôÊ®ôË®òÂåñÊñπÊ≥ï Byte-Pair Á∑®Á¢º (BPE) ÊºîÁÆóÊ≥ïÁöÑÂïüÁôºÔºåÊàëÂÄëÊèêÂá∫‰∫Ü GraphBPEÔºåÂÆÉÂ∞áÂàÜÂ≠êÂúñÊ®ôË®òÂåñÁÇ∫‰∏çÂêåÁöÑÂ≠êÁµêÊßãÔºå‰∏¶‰ΩúÁÇ∫ËàáÊ®°ÂûãÊû∂ÊßãÁÑ°ÈóúÁöÑÈ†êËôïÁêÜË®àÁï´„ÄÇÊàëÂÄëÂú® 3 ÂÄãÂúñÂΩ¢Â±§Á¥öÂàÜÈ°ûÂíå 3 ÂÄãÂúñÂΩ¢Â±§Á¥öÂõûÊ≠∏Ë≥áÊñôÈõÜ‰∏äÁöÑÂØ¶È©óÈ°ØÁ§∫ÔºåË≥áÊñôÈ†êËôïÁêÜÂèØ‰ª•ÊèêÂçáÂàÜÂ≠êÂúñÊ®°ÂûãÁöÑÊïàËÉΩÔºåËÄå GraphBPE Â∞çÊñºÂ∞èÂûãÂàÜÈ°ûË≥áÊñôÈõÜÊúâÊïàÔºå‰∏¶‰∏îÂú®‰∏çÂêåÁöÑÊ®°ÂûãÊû∂Êßã‰∏≠ËàáÂÖ∂‰ªñÊ®ôË®òÂåñÊñπÊ≥ïË°®ÁèæÁõ∏Áï∂„ÄÇ

##### **Knowledge Graph Structure as Prompt: Improving Small Language Models Capabilities for Knowledge-based Causal Discovery**
2407.18752v3 by Yuni Susanti, Michael F√§rber

Causal discovery aims to estimate causal structures among variables based on
observational data. Large Language Models (LLMs) offer a fresh perspective to
tackle the causal discovery problem by reasoning on the metadata associated
with variables rather than their actual data values, an approach referred to as
knowledge-based causal discovery. In this paper, we investigate the
capabilities of Small Language Models (SLMs, defined as LLMs with fewer than 1
billion parameters) with prompt-based learning for knowledge-based causal
discovery. Specifically, we present KG Structure as Prompt, a novel approach
for integrating structural information from a knowledge graph, such as common
neighbor nodes and metapaths, into prompt-based learning to enhance the
capabilities of SLMs. Experimental results on three types of biomedical and
open-domain datasets under few-shot settings demonstrate the effectiveness of
our approach, surpassing most baselines and even conventional fine-tuning
approaches trained on full datasets. Our findings further highlight the strong
capabilities of SLMs: in combination with knowledge graphs and prompt-based
learning, SLMs demonstrate the potential to surpass LLMs with larger number of
parameters. Our code and datasets are available on GitHub.

ÊëòË¶ÅÔºöÂõ†ÊûúÁôºÁèæÊó®Âú®Ê†πÊìöËßÄÊ∏¨Êï∏Êìö‰º∞Ë®àËÆäÊï∏‰πãÈñìÁöÑÂõ†ÊûúÁµêÊßã„ÄÇÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Êèê‰æõ‰∫Ü‰∏ÄÂÄãÊñ∞ÁöÑËßÄÈªû‰æÜËß£Ê±∫Âõ†ÊûúÁôºÁèæÂïèÈ°åÔºåÊñπÊ≥ïÊòØÊé®Ë´ñËàáËÆäÊï∏Áõ∏ÈóúÁöÑÂÖÉÊï∏ÊìöÔºåËÄå‰∏çÊòØÂÆÉÂÄëÁöÑÂØ¶ÈöõÊï∏ÊìöÂÄºÔºåÈÄôÁ®ÆÊñπÊ≥ïÁ®±ÁÇ∫Âü∫ÊñºÁü•Ë≠òÁöÑÂõ†ÊûúÁôºÁèæ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊé¢Ë®é‰∫ÜÂ∞èË™ûË®ÄÊ®°Âûã (SLMÔºåÂÆöÁæ©ÁÇ∫ÂèÉÊï∏Â∞ëÊñº 10 ÂÑÑÁöÑ LLM) ÁöÑËÉΩÂäõÔºå‰∏¶Êé°Áî®Âü∫ÊñºÊèêÁ§∫ÁöÑÂ≠∏ÁøíÈÄ≤Ë°åÂü∫ÊñºÁü•Ë≠òÁöÑÂõ†ÊûúÁôºÁèæ„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü KG Structure as PromptÔºåÈÄôÊòØ‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÊñπÊ≥ïÔºåÁî®ÊñºÂ∞á‰æÜËá™Áü•Ë≠òÂúñË≠úÁöÑÁµêÊßãË≥áË®äÔºå‰æãÂ¶ÇÂÖ±ÂêåÈÑ∞Â±ÖÁØÄÈªûÂíåÂÖÉË∑ØÂæëÔºåÊï¥ÂêàÂà∞Âü∫ÊñºÊèêÁ§∫ÁöÑÂ≠∏Áøí‰∏≠Ôºå‰ª•Â¢ûÂº∑ SLM ÁöÑËÉΩÂäõ„ÄÇÂú®Â∞ëÊ¨°ÂòóË©¶Ë®≠ÂÆö‰∏ãÔºåÈáùÂ∞ç‰∏âÁ®ÆÈ°ûÂûãÁöÑÁîüÁâ©ÈÜ´Â≠∏ÂíåÈñãÊîæÈ†òÂüüË≥áÊñôÈõÜÁöÑÂØ¶È©óÁµêÊûúË≠âÊòé‰∫ÜÊàëÂÄëÊñπÊ≥ïÁöÑÊúâÊïàÊÄßÔºåË∂ÖË∂ä‰∫ÜÂ§ßÂ§öÊï∏Âü∫Ê∫ñÔºåÁîöËá≥Ë∂ÖË∂ä‰∫ÜÂú®ÂÆåÊï¥Ë≥áÊñôÈõÜ‰∏äË®ìÁ∑¥ÁöÑÂÇ≥Áµ±ÂæÆË™øÊñπÊ≥ï„ÄÇÊàëÂÄëÁöÑÁôºÁèæÈÄ≤‰∏ÄÊ≠•Á™ÅÂá∫‰∫Ü SLM ÁöÑÂº∑Â§ßÂäüËÉΩÔºöÁµêÂêàÁü•Ë≠òÂúñË≠úÂíåÂü∫ÊñºÊèêÁ§∫ÁöÑÂ≠∏ÁøíÔºåSLM Â±ïÁ§∫‰∫ÜË∂ÖË∂äÂÖ∑ÊúâÊõ¥Â§öÂèÉÊï∏ÁöÑ LLM ÁöÑÊΩõÂäõ„ÄÇÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÂíåË≥áÊñôÈõÜÂèØÂú® GitHub ‰∏äÂèñÂæó„ÄÇ

##### **Using GPT-4 to guide causal machine learning**
2407.18607v1 by Anthony C. Constantinou, Neville K. Kitson, Alessio Zanga

Since its introduction to the public, ChatGPT has had an unprecedented
impact. While some experts praised AI advancements and highlighted their
potential risks, others have been critical about the accuracy and usefulness of
Large Language Models (LLMs). In this paper, we are interested in the ability
of LLMs to identify causal relationships. We focus on the well-established
GPT-4 (Turbo) and evaluate its performance under the most restrictive
conditions, by isolating its ability to infer causal relationships based solely
on the variable labels without being given any context, demonstrating the
minimum level of effectiveness one can expect when it is provided with
label-only information. We show that questionnaire participants judge the GPT-4
graphs as the most accurate in the evaluated categories, closely followed by
knowledge graphs constructed by domain experts, with causal Machine Learning
(ML) far behind. We use these results to highlight the important limitation of
causal ML, which often produces causal graphs that violate common sense,
affecting trust in them. However, we show that pairing GPT-4 with causal ML
overcomes this limitation, resulting in graphical structures learnt from real
data that align more closely with those identified by domain experts, compared
to structures learnt by causal ML alone. Overall, our findings suggest that
despite GPT-4 not being explicitly designed to reason causally, it can still be
a valuable tool for causal representation, as it improves the causal discovery
process of causal ML algorithms that are designed to do just that.

ÊëòË¶ÅÔºöËá™ ChatGPT ÂêëÂÖ¨‰ºóÂèëÂ∏É‰ª•Êù•ÔºåÂÆÉ‰∫ßÁîü‰∫ÜÂâçÊâÄÊú™ÊúâÁöÑÂΩ±Âìç„ÄÇËôΩÁÑ∂‰∏Ä‰∫õ‰∏ìÂÆ∂ËµûÊâ¨‰∫Ü AI ÁöÑËøõÊ≠•Âπ∂Âº∫Ë∞É‰∫ÜÂÖ∂ÊΩúÂú®È£éÈô©Ôºå‰ΩÜÂÖ∂‰ªñ‰∫∫‰∏ÄÁõ¥ÊâπËØÑÂ§ßÂûãËØ≠Ë®ÄÊ®°Âûã (LLM) ÁöÑÂáÜÁ°ÆÊÄßÂíåÊúâÁî®ÊÄß„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨ÂØπ LLM ËØÜÂà´Âõ†ÊûúÂÖ≥Á≥ªÁöÑËÉΩÂäõÊÑüÂÖ¥Ë∂£„ÄÇÊàë‰ª¨‰∏ìÊ≥®‰∫éÊàêÁÜüÁöÑ GPT-4ÔºàTurboÔºâÔºåÂπ∂Âú®ÊúÄ‰∏•Ê†ºÁöÑÊù°‰ª∂‰∏ãËØÑ‰º∞ÂÖ∂ÊÄßËÉΩÔºåÈÄöËøáÂ≠§Á´ãÂÖ∂‰ªÖÊ†πÊçÆÂèòÈáèÊ†áÁ≠æÊé®Êñ≠Âõ†ÊûúÂÖ≥Á≥ªÁöÑËÉΩÂäõÔºåËÄå‰∏çÊèê‰æõ‰ªª‰Ωï‰∏ä‰∏ãÊñáÔºåÂ±ïÁ§∫‰∫ÜÂΩì‰ªÖÊèê‰æõÊ†áÁ≠æ‰ø°ÊÅØÊó∂‰∫∫‰ª¨ÂèØ‰ª•È¢ÑÊúüÁöÑÊúÄ‰ΩéÊúâÊïàÊÄßÊ∞¥Âπ≥„ÄÇÊàë‰ª¨Ë°®ÊòéÔºåÈóÆÂç∑ÂèÇ‰∏éËÄÖËÆ§‰∏∫ GPT-4 ÂõæÂΩ¢Âú®ËØÑ‰º∞Á±ªÂà´‰∏≠ÊòØÊúÄÂáÜÁ°ÆÁöÑÔºåÁ¥ßÈöèÂÖ∂ÂêéÁöÑÊòØÁî±È¢ÜÂüü‰∏ìÂÆ∂ÊûÑÂª∫ÁöÑÁü•ËØÜÂõæË∞±ÔºåÂõ†ÊûúÊú∫Âô®Â≠¶‰π† (ML) ËøúËøúËêΩÂêé„ÄÇÊàë‰ª¨‰ΩøÁî®Ëøô‰∫õÁªìÊûúÊù•Âº∫Ë∞ÉÂõ†Êûú ML ÁöÑÈáçË¶ÅÂ±ÄÈôêÊÄßÔºåÂÆÉÁªèÂ∏∏‰∫ßÁîüËøùËÉåÂ∏∏ËØÜÁöÑÂõ†ÊûúÂõæÔºåÂΩ±Âìç‰∫∫‰ª¨ÂØπÂÆÉ‰ª¨ÁöÑ‰ø°‰ªª„ÄÇÁÑ∂ËÄåÔºåÊàë‰ª¨Ë°®ÊòéÂ∞Ü GPT-4 ‰∏éÂõ†Êûú ML ÈÖçÂØπÂèØ‰ª•ÂÖãÊúçËøô‰∏ÄÈôêÂà∂Ôºå‰ªéËÄå‰∫ßÁîü‰ªéÁúüÂÆûÊï∞ÊçÆ‰∏≠Â≠¶Âà∞ÁöÑÂõæÂΩ¢ÁªìÊûÑÔºå‰∏éÈ¢ÜÂüü‰∏ìÂÆ∂ËØÜÂà´ÁöÑÁªìÊûÑÁõ∏ÊØîÔºåÊõ¥Á¥ßÂØÜÂú∞‰∏é‰πãÂØπÈΩêÔºåËÄå‰∏çÊòØ‰ªÖÁî±Âõ†Êûú ML Â≠¶Âà∞ÁöÑÁªìÊûÑ„ÄÇÊÄª‰ΩìËÄåË®ÄÔºåÊàë‰ª¨ÁöÑÁ†îÁ©∂ÁªìÊûúË°®ÊòéÔºåÂ∞ΩÁÆ° GPT-4 Âπ∂Êú™ÊòéÁ°ÆËÆæËÆ°‰∏∫Âõ†ÊûúÊé®ÁêÜÔºå‰ΩÜÂÆÉ‰ªçÁÑ∂ÂèØ‰ª•Êàê‰∏∫Âõ†ÊûúË°®Á§∫ÁöÑÂÆùË¥µÂ∑•ÂÖ∑ÔºåÂõ†‰∏∫ÂÆÉÊîπËøõ‰∫ÜÊó®Âú®ÊâßË°åÊ≠§Êìç‰ΩúÁöÑÂõ†Êûú ML ÁÆóÊ≥ïÁöÑÂõ†ÊûúÂèëÁé∞ËøáÁ®ã„ÄÇ

##### **Multi-turn Response Selection with Commonsense-enhanced Language Models**
2407.18479v1 by Yuandong Wang, Xuhui Ren, Tong Chen, Yuxiao Dong, Nguyen Quoc Viet Hung, Jie Tang

As a branch of advanced artificial intelligence, dialogue systems are
prospering. Multi-turn response selection is a general research problem in
dialogue systems. With the assistance of background information and pre-trained
language models, the performance of state-of-the-art methods on this problem
gains impressive improvement. However, existing studies neglect the importance
of external commonsense knowledge. Hence, we design a Siamese network where a
pre-trained Language model merges with a Graph neural network (SinLG). SinLG
takes advantage of Pre-trained Language Models (PLMs) to catch the word
correlations in the context and response candidates and utilizes a Graph Neural
Network (GNN) to reason helpful common sense from an external knowledge graph.
The GNN aims to assist the PLM in fine-tuning, and arousing its related
memories to attain better performance. Specifically, we first extract related
concepts as nodes from an external knowledge graph to construct a subgraph with
the context response pair as a super node for each sample. Next, we learn two
representations for the context response pair via both the PLM and GNN. A
similarity loss between the two representations is utilized to transfer the
commonsense knowledge from the GNN to the PLM. Then only the PLM is used to
infer online so that efficiency can be guaranteed. Finally, we conduct
extensive experiments on two variants of the PERSONA-CHAT dataset, which proves
that our solution can not only improve the performance of the PLM but also
achieve an efficient inference.

ÊëòË¶ÅÔºö‰ΩúÁÇ∫È´òÁ¥ö‰∫∫Â∑•Êô∫ÊÖßÁöÑ‰∏ÄÂÄãÂàÜÊîØÔºåÂ∞çË©±Á≥ªÁµ±Ê≠£Ëì¨ÂãÉÁôºÂ±ï„ÄÇÂ§öËº™ÂõûÊáâÁî®Êà∂ÂõûÊáâÈÅ∏ÊìáÊòØÂ∞çË©±Á≥ªÁµ±‰∏≠‰∏ÄÂÄãÈÄöÁî®ÁöÑÁ†îÁ©∂ÂïèÈ°å„ÄÇÂú®ËÉåÊôØË≥áË®äÂíåÈ†êÂÖàË®ìÁ∑¥ÁöÑË™ûË®ÄÊ®°ÂûãÁöÑÂçîÂä©‰∏ãÔºåÊúÄÂÖàÈÄ≤ÁöÑÊñπÊ≥ïÂú®Ê≠§ÂïèÈ°å‰∏äÁöÑË°®ÁèæÁç≤Ëá¥‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑÈÄ≤Ê≠•„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÁöÑÁ†îÁ©∂ÂøΩÁï•‰∫ÜÂ§ñÈÉ®Â∏∏Ë≠òÁü•Ë≠òÁöÑÈáçË¶ÅÊÄß„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëË®≠Ë®à‰∫Ü‰∏ÄÂÄãÊöπÁæÖÁ∂≤Ë∑ØÔºåÂÖ∂‰∏≠‰∏ÄÂÄãÈ†êÂÖàË®ìÁ∑¥ÁöÑË™ûË®ÄÊ®°ÂûãËàá‰∏ÄÂÄãÂúñÁ•ûÁ∂ìÁ∂≤Ë∑ØÔºàSinLGÔºâÂêà‰Ωµ„ÄÇSinLG Âà©Áî®È†êÂÖàË®ìÁ∑¥ÁöÑË™ûË®ÄÊ®°ÂûãÔºàPLMÔºâ‰æÜÊçïÊçâË™ûÂ¢ÉÂíåÂõûÊáâÂÄôÈÅ∏‰∏≠ÁöÑË©ûÂΩôÈóúËÅØÔºå‰∏¶Âà©Áî®ÂúñÁ•ûÁ∂ìÁ∂≤Ë∑ØÔºàGNNÔºâÂæûÂ§ñÈÉ®Áü•Ë≠òÂúñË≠úÊé®ÁêÜÊúâÁî®ÁöÑÂ∏∏Ë≠ò„ÄÇGNN Êó®Âú®ÂçîÂä© PLM ÈÄ≤Ë°åÂæÆË™øÔºå‰∏¶ÂñöÈÜíÂÖ∂Áõ∏ÈóúË®òÊÜ∂‰ª•Áç≤ÂæóÊõ¥Â•ΩÁöÑË°®Áèæ„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÈ¶ñÂÖàÂæûÂ§ñÈÉ®Áü•Ë≠òÂúñË≠ú‰∏≠ÊèêÂèñÁõ∏ÈóúÊ¶ÇÂøµ‰ΩúÁÇ∫ÁØÄÈªûÔºå‰ª•ÊßãÂª∫‰∏ÄÂÄãÂ≠êÂúñÔºåÂÖ∂‰∏≠Ë™ûÂ¢ÉÂõûÊáâÂ∞ç‰ΩúÁÇ∫ÊØèÂÄãÁØÑ‰æãÁöÑË∂ÖÁ¥öÁØÄÈªû„ÄÇÊé•‰∏ã‰æÜÔºåÊàëÂÄëÈÄèÈÅé PLM Âíå GNN ÁÇ∫Ë™ûÂ¢ÉÂõûÊáâÂ∞çÂ≠∏ÁøíÂÖ©ÂÄãË°®Á§∫„ÄÇÂÖ©ÂÄãË°®Á§∫‰πãÈñìÁöÑÁõ∏‰ººÊÄßÊêçÂ§±Áî®ÊñºÂ∞áÂ∏∏Ë≠òÁü•Ë≠òÂæû GNN ËΩâÁßªÂà∞ PLM„ÄÇÁÑ∂ÂæåÂÉÖ‰ΩøÁî® PLM ‰æÜÈÄ≤Ë°åÁ∑ö‰∏äÊé®Ë´ñÔºå‰ª•‰æø‰øùË≠âÊïàÁéá„ÄÇÊúÄÂæåÔºåÊàëÂÄëÂ∞ç PERSONA-CHAT Ë≥áÊñôÈõÜÁöÑÂÖ©ÂÄãËÆäÈ´îÈÄ≤Ë°å‰∫ÜÂª£Ê≥õÁöÑÂØ¶È©óÔºåÈÄôË≠âÊòéÊàëÂÄëÁöÑËß£Ê±∫ÊñπÊ°à‰∏çÂÉÖÂèØ‰ª•ÊèêÈ´ò PLM ÁöÑÊïàËÉΩÔºåÈÇÑËÉΩÂØ¶ÁèæÈ´òÊïàÁöÑÊé®Ë´ñ„ÄÇ

##### **Gene Regulatory Network Inference from Pre-trained Single-Cell Transcriptomics Transformer with Joint Graph Learning**
2407.18181v1 by Sindhura Kommu, Yizhi Wang, Yue Wang, Xuan Wang

Inferring gene regulatory networks (GRNs) from single-cell RNA sequencing
(scRNA-seq) data is a complex challenge that requires capturing the intricate
relationships between genes and their regulatory interactions. In this study,
we tackle this challenge by leveraging the single-cell BERT-based pre-trained
transformer model (scBERT), trained on extensive unlabeled scRNA-seq data, to
augment structured biological knowledge from existing GRNs. We introduce a
novel joint graph learning approach that combines the rich contextual
representations learned by pre-trained single-cell language models with the
structured knowledge encoded in GRNs using graph neural networks (GNNs). By
integrating these two modalities, our approach effectively reasons over boththe
gene expression level constraints provided by the scRNA-seq data and the
structured biological knowledge inherent in GRNs. We evaluate our method on
human cell benchmark datasets from the BEELINE study with cell type-specific
ground truth networks. The results demonstrate superior performance over
current state-of-the-art baselines, offering a deeper understanding of cellular
regulatory mechanisms.

ÊëòË¶ÅÔºöÂæûÂñÆÁ¥∞ËÉû RNA ÂÆöÂ∫è (scRNA-seq) Ë≥áÊñôÊé®Ë´ñÂü∫Âõ†Ë™øÊéßÁ∂≤Ë∑Ø (GRN) ÊòØ‰∏ÄÈ†ÖË§áÈõúÁöÑÊåëÊà∞ÔºåÈúÄË¶ÅÊéåÊè°Âü∫Âõ†ËàáÂÖ∂Ë™øÊéß‰∫§‰∫í‰ΩúÁî®‰πãÈñìÁöÑË§áÈõúÈóú‰øÇ„ÄÇÂú®Ê≠§Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëÈÄèÈÅéÂà©Áî®Âú®Âª£Ê≥õÁöÑÊú™Ê®ôË®ò scRNA-seq Ë≥áÊñô‰∏äË®ìÁ∑¥ÁöÑÂñÆÁ¥∞ËÉû BERT Âü∫ÊñºÈ†êË®ìÁ∑¥ËΩâÊèõÂô®Ê®°Âûã (scBERT)Ôºå‰æÜÂÖãÊúçÊ≠§ÊåëÊà∞Ôºå‰ª•Êì¥ÂÖÖÁèæÊúâ GRN ‰∏≠ÁöÑÁµêÊßãÂåñÁîüÁâ©Áü•Ë≠ò„ÄÇÊàëÂÄëÂºïÂÖ•‰∏ÄÁ®ÆÊñ∞Á©éÁöÑËÅØÂêàÂúñÂΩ¢Â≠∏ÁøíÊñπÊ≥ïÔºåÂÆÉÁµêÂêà‰∫ÜÈ†êË®ìÁ∑¥ÂñÆÁ¥∞ËÉûË™ûË®ÄÊ®°ÂûãÊâÄÂ≠∏ÁøíÂà∞ÁöÑË±êÂØåËÑàÁµ°Ë°®ÂæµÔºå‰ª•Âèä‰ΩøÁî®ÂúñÂΩ¢Á•ûÁ∂ìÁ∂≤Ë∑Ø (GNN) Â∞ç GRN ‰∏≠Á∑®Á¢ºÁöÑÁµêÊßãÂåñÁü•Ë≠ò„ÄÇÈÄèÈÅéÊï¥ÂêàÈÄôÂÖ©Á®ÆÊñπÂºèÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÊúâÊïàÂú∞Â∞ç scRNA-seq Ë≥áÊñôÊèê‰æõÁöÑÂü∫Âõ†Ë°®ÁèæÂ±§Á¥öÁ¥ÑÊùüÂíå GRN ‰∏≠Âõ∫ÊúâÁöÑÁµêÊßãÂåñÁîüÁâ©Áü•Ë≠òÈÄ≤Ë°åÊé®ÁêÜ„ÄÇÊàëÂÄë‰ΩøÁî® BEELINE Á†îÁ©∂‰∏≠ÁöÑ‰∫∫È°ûÁ¥∞ËÉûÂü∫Ê∫ñË≥áÊñôÈõÜÔºå‰ª•ÂèäÁ¥∞ËÉûÈ°ûÂûãÁâπÂÆöÁöÑÂü∫Êú¨‰∫ãÂØ¶Á∂≤Ë∑ØÔºå‰æÜË©ï‰º∞ÊàëÂÄëÁöÑÊñπÊ≥ï„ÄÇÁµêÊûúË≠âÊòéÂÖ∂ÊïàËÉΩÂÑ™ÊñºÁõÆÂâçÊúÄÂÖàÈÄ≤ÁöÑÂü∫Ê∫ñÔºåÊèê‰æõ‰∫ÜÂ∞çÁ¥∞ËÉûË™øÊéßÊ©üÂà∂ÁöÑÊõ¥Ê∑±ÂÖ•ÁêÜËß£„ÄÇ

##### **MathViz-E: A Case-study in Domain-Specialized Tool-Using Agents**
2407.17544v1 by Arya Bulusu, Brandon Man, Ashish Jagmohan, Aditya Vempaty, Jennifer Mari-Wyka, Deepak Akkil

There has been significant recent interest in harnessing LLMs to control
software systems through multi-step reasoning, planning and tool-usage. While
some promising results have been obtained, application to specific domains
raises several general issues including the control of specialized domain
tools, the lack of existing datasets for training and evaluation, and the
non-triviality of automated system evaluation and improvement. In this paper,
we present a case-study where we examine these issues in the context of a
specific domain. Specifically, we present an automated math visualizer and
solver system for mathematical pedagogy. The system orchestrates mathematical
solvers and math graphing tools to produce accurate visualizations from simple
natural language commands. We describe the creation of specialized data-sets,
and also develop an auto-evaluator to easily evaluate the outputs of our system
by comparing them to ground-truth expressions. We have open sourced the
data-sets and code for the proposed system.

ÊëòË¶ÅÔºöÊúÄËøëÔºå‰∫∫‰ª¨ÂØπÂà©Áî®Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã (LLM) Êù•ÈÄöËøáÂ§öÊ≠•È™§Êé®ÁêÜ„ÄÅËßÑÂàíÂíåÂ∑•ÂÖ∑‰ΩøÁî®Êù•ÊéßÂà∂ËΩØ‰ª∂Á≥ªÁªü‰∫ßÁîü‰∫ÜÊûÅÂ§ßÁöÑÂÖ¥Ë∂£„ÄÇËôΩÁÑ∂Â∑≤ÁªèÂèñÂæó‰∫Ü‰∏Ä‰∫õÊúâÂ∏åÊúõÁöÑÁªìÊûúÔºå‰ΩÜÂ∫îÁî®‰∫éÁâπÂÆöÈ¢ÜÂüü‰ºöÂºïÂèëÂá†‰∏™ÊôÆÈÅçÊÄßÈóÆÈ¢òÔºåÂåÖÊã¨ÂØπ‰∏ì‰∏öÈ¢ÜÂüüÂ∑•ÂÖ∑ÁöÑÊéßÂà∂„ÄÅÁº∫‰πèÁî®‰∫éËÆ≠ÁªÉÂíåËØÑ‰º∞ÁöÑÁé∞ÊúâÊï∞ÊçÆÈõÜÔºå‰ª•ÂèäËá™Âä®ÂåñÁ≥ªÁªüËØÑ‰º∞ÂíåÊîπËøõÁöÑÈùûÂπ≥Âá°ÊÄß„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏Ä‰∏™Ê°à‰æãÁ†îÁ©∂ÔºåÂÖ∂‰∏≠Êàë‰ª¨Á†îÁ©∂‰∫ÜÁâπÂÆöÈ¢ÜÂüüËÉåÊôØ‰∏ãÁöÑËøô‰∫õÈóÆÈ¢ò„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåÊàë‰ª¨Â±ïÁ§∫‰∫Ü‰∏Ä‰∏™Áî®‰∫éÊï∞Â≠¶ÊïôËÇ≤ÁöÑËá™Âä®ÂåñÊï∞Â≠¶ÂèØËßÜÂåñÂô®ÂíåÊ±ÇËß£Âô®Á≥ªÁªü„ÄÇËØ•Á≥ªÁªüÂçèË∞ÉÊï∞Â≠¶Ê±ÇËß£Âô®ÂíåÊï∞Â≠¶ÁªòÂõæÂ∑•ÂÖ∑Ôºå‰ª•Ê†πÊçÆÁÆÄÂçïÁöÑËá™ÁÑ∂ËØ≠Ë®ÄÂëΩ‰ª§ÁîüÊàêÂáÜÁ°ÆÁöÑÂèØËßÜÂåñÊïàÊûú„ÄÇÊàë‰ª¨ÊèèËø∞‰∫Ü‰∏ìÈó®Êï∞ÊçÆÈõÜÁöÑÂàõÂª∫ÔºåËøòÂºÄÂèë‰∫Ü‰∏Ä‰∏™Ëá™Âä®ËØÑ‰º∞Âô®ÔºåÈÄöËøáÂ∞ÜÊàë‰ª¨ÁöÑÁ≥ªÁªüËæìÂá∫‰∏éÁúüÂÆûË°®ËææÂºèËøõË°åÊØîËæÉÔºåËΩªÊùæËØÑ‰º∞ÂÖ∂ËæìÂá∫„ÄÇÊàë‰ª¨Â∑≤ÁªèÂºÄÊ∫ê‰∫ÜÊâÄÊèêËÆÆÁ≥ªÁªüÁöÑ‰ª£Á†ÅÂíåÊï∞ÊçÆÈõÜ„ÄÇ

##### **Ranking protein-protein models with large language models and graph neural networks**
2407.16375v1 by Xiaotong Xu, Alexandre M. J. J. Bonvin

Protein-protein interactions (PPIs) are associated with various diseases,
including cancer, infections, and neurodegenerative disorders. Obtaining
three-dimensional structural information on these PPIs serves as a foundation
to interfere with those or to guide drug design. Various strategies can be
followed to model those complexes, all typically resulting in a large number of
models. A challenging step in this process is the identification of good models
(near-native PPI conformations) from the large pool of generated models. To
address this challenge, we previously developed DeepRank-GNN-esm, a graph-based
deep learning algorithm for ranking modelled PPI structures harnessing the
power of protein language models. Here, we detail the use of our software with
examples. DeepRank-GNN-esm is freely available at
https://github.com/haddocking/DeepRank-GNN-esm

ÊëòË¶ÅÔºöËõãÁôΩ-ËõãÁôΩ‰∫§‰∫í‰ΩúÁî® (PPI) ËàáÂêÑÁ®ÆÁñæÁóÖÁõ∏ÈóúÔºåÂåÖÊã¨ÁôåÁóá„ÄÅÊÑüÊüìÂíåÁ•ûÁ∂ìÈÄÄÂåñÊÄßÁñæÁóÖ„ÄÇÂèñÂæóÈÄô‰∫õ PPI ÁöÑ‰∏âÁ∂≠ÁµêÊßãË≥áË®äÔºå‰ΩúÁÇ∫Âπ≤ÊìæÂÆÉÂÄëÊàñÂºïÂ∞éËó•Áâ©Ë®≠Ë®àÁöÑÂü∫Á§é„ÄÇÂèØ‰ª•ÈÅµÂæ™ÂêÑÁ®ÆÁ≠ñÁï•‰æÜÂª∫Ê®°ÈÄô‰∫õË§áÂêàÈ´îÔºåÊâÄÊúâÈÄô‰∫õÁ≠ñÁï•ÈÄöÂ∏∏ÊúÉÁî¢ÁîüÂ§ßÈáèÁöÑÊ®°Âûã„ÄÇÊ≠§ÈÅéÁ®ã‰∏≠ÁöÑÊåëÊà∞ÊÄßÊ≠•È©üÔºåÊòØÂæûÂ§ßÈáèÁî¢ÁîüÁöÑÊ®°Âûã‰∏≠ÊâæÂá∫Â•ΩÁöÑÊ®°ÂûãÔºàÊé•ËøëÂéüÁîü PPI ÊßãË±°Ôºâ„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄôÂÄãÊåëÊà∞ÔºåÊàëÂÄë‰πãÂâçÈñãÁôº‰∫Ü DeepRank-GNN-esmÔºåÈÄôÊòØ‰∏ÄÁ®ÆÂü∫ÊñºÂúñÂΩ¢ÁöÑÊ∑±Â∫¶Â≠∏ÁøíÊºîÁÆóÊ≥ïÔºåÁî®ÊñºÂ∞çÂª∫Ê®°ÁöÑ PPI ÁµêÊßãÈÄ≤Ë°åÊéíÂêçÔºåÂà©Áî®ËõãÁôΩË≥™Ë™ûË®ÄÊ®°ÂûãÁöÑÂäõÈáè„ÄÇÂú®ÈÄôË£°ÔºåÊàëÂÄëË©≥Á¥∞Ë™™Êòé‰∫ÜÊàëÂÄëËªüÈ´îÁöÑ‰ΩøÁî®ÁØÑ‰æã„ÄÇDeepRank-GNN-esm ÂèØÂú® https://github.com/haddocking/DeepRank-GNN-esm ÂÖçË≤ªÂèñÂæó

##### **PhenoFlow: A Human-LLM Driven Visual Analytics System for Exploring Large and Complex Stroke Datasets**
2407.16329v1 by Jaeyoung Kim, Sihyeon Lee, Hyeon Jeon, Keon-Joo Lee, Hee-Joon Bae, Bohyoung Kim, Jinwook Seo

Acute stroke demands prompt diagnosis and treatment to achieve optimal
patient outcomes. However, the intricate and irregular nature of clinical data
associated with acute stroke, particularly blood pressure (BP) measurements,
presents substantial obstacles to effective visual analytics and
decision-making. Through a year-long collaboration with experienced
neurologists, we developed PhenoFlow, a visual analytics system that leverages
the collaboration between human and Large Language Models (LLMs) to analyze the
extensive and complex data of acute ischemic stroke patients. PhenoFlow
pioneers an innovative workflow, where the LLM serves as a data wrangler while
neurologists explore and supervise the output using visualizations and natural
language interactions. This approach enables neurologists to focus more on
decision-making with reduced cognitive load. To protect sensitive patient
information, PhenoFlow only utilizes metadata to make inferences and synthesize
executable codes, without accessing raw patient data. This ensures that the
results are both reproducible and interpretable while maintaining patient
privacy. The system incorporates a slice-and-wrap design that employs temporal
folding to create an overlaid circular visualization. Combined with a linear
bar graph, this design aids in exploring meaningful patterns within irregularly
measured BP data. Through case studies, PhenoFlow has demonstrated its
capability to support iterative analysis of extensive clinical datasets,
reducing cognitive load and enabling neurologists to make well-informed
decisions. Grounded in long-term collaboration with domain experts, our
research demonstrates the potential of utilizing LLMs to tackle current
challenges in data-driven clinical decision-making for acute ischemic stroke
patients.

ÊëòË¶ÅÔºö<paragraph>ÊÄ•ÊÄß‰∏≠È¢®ÈúÄË¶ÅËøÖÈÄüË®∫Êñ∑ÂíåÊ≤ªÁôÇÔºåÊâçËÉΩÈÅîÂà∞ÊúÄ‰Ω≥ÁöÑÁóÖ‰∫∫Ê≤ªÁôÇÁµêÊûú„ÄÇÁÑ∂ËÄåÔºåËàáÊÄ•ÊÄß‰∏≠È¢®Áõ∏ÈóúÁöÑËá®Â∫äË≥áÊñôË§áÈõú‰∏î‰∏çË¶èÂâáÔºåÁâπÂà•ÊòØË°ÄÂ£ì (BP) Ê∏¨ÈáèÔºåÂ∞çÊúâÊïàÁöÑË¶ñË¶∫ÂàÜÊûêÂíåÊ±∫Á≠ñÂà∂ÂÆöÊßãÊàêÈáçÂ§ßÈöúÁ§ô„ÄÇÈÄèÈÅéËàáÁ∂ìÈ©óË±êÂØåÁöÑÁ•ûÁ∂ìÁßëÈÜ´Â∏´Èï∑ÈÅî‰∏ÄÂπ¥ÁöÑÂêà‰ΩúÔºåÊàëÂÄëÈñãÁôº‰∫Ü PhenoFlowÔºåÈÄôÊòØ‰∏ÄÂÄãË¶ñË¶∫ÂàÜÊûêÁ≥ªÁµ±ÔºåÂà©Áî®‰∫∫ËàáÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰πãÈñìÁöÑÂçî‰Ωú‰æÜÂàÜÊûêÊÄ•ÊÄßÁº∫Ë°ÄÊÄß‰∏≠È¢®ÊÇ£ËÄÖÁöÑÂª£Ê≥õ‰∏îË§áÈõúË≥áÊñô„ÄÇPhenoFlow ÈñãÂâµ‰∫Ü‰∏ÄÁ®ÆÂâµÊñ∞ÁöÑÂ∑•‰ΩúÊµÅÁ®ãÔºåÂÖ∂‰∏≠ LLM Êìî‰ªªË≥áÊñôÊï¥ÁêÜÂì°ÔºåËÄåÁ•ûÁ∂ìÁßëÈÜ´Â∏´Ââá‰ΩøÁî®Ë¶ñË¶∫ÂåñÂíåËá™ÁÑ∂Ë™ûË®Ä‰∫íÂãï‰æÜÊé¢Á¥¢ÂíåÁõ£Áù£Ëº∏Âá∫„ÄÇÈÄôÁ®ÆÊñπÊ≥ï‰ΩøÁ•ûÁ∂ìÁßëÈÜ´Â∏´ËÉΩÂ§†Êõ¥Â∞àÊ≥®ÊñºÊ±∫Á≠ñÂà∂ÂÆöÔºåÂêåÊôÇÈôç‰ΩéË™çÁü•Ë≤†Êìî„ÄÇÁÇ∫‰∫Ü‰øùË≠∑ÊïèÊÑüÁöÑÁóÖ‰∫∫Ë≥áË®äÔºåPhenoFlow ÂÉÖÂà©Áî®ÂÖÉË≥áÊñôÈÄ≤Ë°åÊé®Ë´ñ‰∏¶ÂêàÊàêÂèØÂü∑Ë°åÁ®ãÂºèÁ¢ºÔºåËÄå‰∏çÊúÉÂ≠òÂèñÂéüÂßãÁóÖ‰∫∫Ë≥áÊñô„ÄÇÈÄôÁ¢∫‰øù‰∫ÜÁµêÊûúÊó¢ÂèØÈáçÁèæÂèàÂèØËß£ÈáãÔºåÂêåÊôÇÁ∂≠Ë≠∑ÁóÖ‰∫∫ÁöÑÈö±ÁßÅ„ÄÇË©≤Á≥ªÁµ±Êé°Áî®ÂàÜÊÆµÂíåÂåÖË£ùË®≠Ë®àÔºåÊé°Áî®ÊôÇÈñìÊë∫Áñä‰æÜÂª∫Á´ãÁñäÂä†ÁöÑÂúìÂΩ¢Ë¶ñË¶∫Âåñ„ÄÇÁµêÂêàÁ∑öÊÄßÈï∑Ê¢ùÂúñÔºåÊ≠§Ë®≠Ë®àÊúâÂä©ÊñºÊé¢Á¥¢‰∏çË¶èÂâáÊ∏¨ÈáèË°ÄÂ£ìË≥áÊñô‰∏≠ÁöÑÊúâÊÑèÁæ©Ê®°Âºè„ÄÇÈÄèÈÅéÊ°à‰æãÁ†îÁ©∂ÔºåPhenoFlow Â∑≤Ë≠âÊòéÂÖ∂ÊîØÊè¥Â∞çÂª£Ê≥õËá®Â∫äË≥áÊñôÈõÜÈÄ≤Ë°åÂèçË¶ÜÂàÜÊûêÁöÑËÉΩÂäõÔºåÈôç‰ΩéË™çÁü•Ë≤†Êìî‰∏¶‰ΩøÁ•ûÁ∂ìÁßëÈÜ´Â∏´ËÉΩÂ§†ÂÅöÂá∫ÊòéÊô∫ÁöÑÊ±∫Á≠ñ„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂‰ª•ËàáÈ†òÂüüÂ∞àÂÆ∂Èï∑ÊúüÂêà‰ΩúÁÇ∫Âü∫Á§éÔºåË≠âÊòé‰∫ÜÂà©Áî® LLM ‰æÜÊáâÂ∞çÁï∂ÂâçÊÄ•ÊÄßÁº∫Ë°ÄÊÄß‰∏≠È¢®ÊÇ£ËÄÖË≥áÊñôÈ©ÖÂãïËá®Â∫äÊ±∫Á≠ñÂà∂ÂÆöÊåëÊà∞ÁöÑÊΩõÂäõ„ÄÇ</paragraph>

##### **Graph-Structured Speculative Decoding**
2407.16207v1 by Zhuocheng Gong, Jiahao Liu, Ziyue Wang, Pengfei Wu, Jingang Wang, Xunliang Cai, Dongyan Zhao, Rui Yan

Speculative decoding has emerged as a promising technique to accelerate the
inference of Large Language Models (LLMs) by employing a small language model
to draft a hypothesis sequence, which is then validated by the LLM. The
effectiveness of this approach heavily relies on the balance between
performance and efficiency of the draft model. In our research, we focus on
enhancing the proportion of draft tokens that are accepted to the final output
by generating multiple hypotheses instead of just one. This allows the LLM more
options to choose from and select the longest sequence that meets its
standards. Our analysis reveals that hypotheses produced by the draft model
share many common token sequences, suggesting a potential for optimizing
computation. Leveraging this observation, we introduce an innovative approach
utilizing a directed acyclic graph (DAG) to manage the drafted hypotheses. This
structure enables us to efficiently predict and merge recurring token
sequences, vastly reducing the computational demands of the draft model. We
term this approach Graph-structured Speculative Decoding (GSD). We apply GSD
across a range of LLMs, including a 70-billion parameter LLaMA-2 model, and
observe a remarkable speedup of 1.73$\times$ to 1.96$\times$, significantly
surpassing standard speculative decoding.

ÊëòË¶ÅÔºö<paragraph>Êé®Ê∏¨ÊÄßËß£Á¢ºÂ∑≤ÊàêÁÇ∫‰∏ÄÁ®ÆÊúâÂâçÈÄîÁöÑÊäÄË°ìÔºåÂèØÈÄöÈÅé‰ΩøÁî®Â∞èÂûãË™ûË®ÄÊ®°ÂûãËµ∑ËçâÂÅáË®≠Â∫èÂàóÔºåÁÑ∂ÂæåÁî±Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) È©óË≠âË©≤Â∫èÂàóÔºåÂæûËÄåÂä†ÈÄüÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊé®ÁêÜ„ÄÇÊ≠§ÊñπÊ≥ïÁöÑÊúâÊïàÊÄßÂú®ÂæàÂ§ßÁ®ãÂ∫¶‰∏äÂèñÊ±∫ÊñºËçâÁ®øÊ®°ÂûãÁöÑÊÄßËÉΩÂíåÊïàÁéá‰πãÈñìÁöÑÂπ≥Ë°°„ÄÇÂú®ÊàëÂÄëÁöÑÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄëÂ∞àÊ≥®ÊñºÈÄöÈÅéÁîüÊàêÂ§öÂÄãÂÅáË®≠ËÄå‰∏çÊòØÂè™ÁîüÊàê‰∏ÄÂÄãÂÅáË®≠‰æÜÊèêÈ´òË¢´Êé•ÂèóÁÇ∫ÊúÄÁµÇËº∏Âá∫ÁöÑËçâÁ®ø‰ª§ÁâåÁöÑÊØî‰æã„ÄÇÈÄôÂÖÅË®± LLM Âæû‰∏≠ÈÅ∏ÊìáÊõ¥Â§öÈÅ∏È†ÖÔºå‰∏¶ÈÅ∏ÊìáÁ¨¶ÂêàÂÖ∂Ê®ôÊ∫ñÁöÑÊúÄÈï∑Â∫èÂàó„ÄÇÊàëÂÄëÁöÑÂàÜÊûêË°®ÊòéÔºåËçâÁ®øÊ®°ÂûãÁî¢ÁîüÁöÑÂÅáË®≠ÂÖ±‰∫´Ë®±Â§öÂÖ¨ÂÖ±‰ª§ÁâåÂ∫èÂàóÔºåÈÄôË°®ÊòéÂÑ™ÂåñË®àÁÆóÁöÑÂèØËÉΩÊÄß„ÄÇÂà©Áî®ÈÄô‰∏ÄËßÄÂØüÁµêÊûúÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÁ®ÆÂâµÊñ∞ÁöÑÊñπÊ≥ïÔºåÂà©Áî®ÊúâÂêëÁÑ°Áí∞Âúñ (DAG) ‰æÜÁÆ°ÁêÜÂ∑≤Á∑®Âà∂ÁöÑÂÅáË®≠„ÄÇÈÄôÁ®ÆÁµêÊßã‰ΩøÊàëÂÄëËÉΩÂ§†ÊúâÊïàÂú∞È†êÊ∏¨ÂíåÂêà‰ΩµÈáçË§áÁöÑ‰ª§ÁâåÂ∫èÂàóÔºåÂæûËÄåÂ§ßÂ§ßÈôç‰Ωé‰∫ÜËçâÁ®øÊ®°ÂûãÁöÑË®àÁÆóÈúÄÊ±Ç„ÄÇÊàëÂÄëÂ∞áÈÄôÁ®ÆÊñπÊ≥ïÁ®±ÁÇ∫ÂúñÁµêÊßãÊé®Ê∏¨ÊÄßËß£Á¢º (GSD)„ÄÇÊàëÂÄëÂ∞á GSD ÊáâÁî®Êñº‰∏ÄÁ≥ªÂàó LLMÔºåÂåÖÊã¨‰∏ÄÂÄã 700 ÂÑÑÂèÉÊï∏ÁöÑ LLaMA-2 Ê®°ÂûãÔºå‰∏¶ËßÄÂØüÂà∞È°ØËëóÁöÑÂä†ÈÄüÔºåÂæû 1.73 ÂÄçÂà∞ 1.96 ÂÄçÔºåÈ°ØËëóË∂ÖÈÅéÊ®ôÊ∫ñÊé®Ê∏¨ÊÄßËß£Á¢º„ÄÇ</paragraph>

##### **Evaluating Long Range Dependency Handling in Code Generation Models using Multi-Step Key Retrieval**
2407.21049v1 by Yannick Assogba, Donghao Ren

As language models support larger and larger context sizes, evaluating their
ability to make effective use of that context becomes increasingly important.
We analyze the ability of several code generation models to handle long range
dependencies using a suite of multi-step key retrieval tasks in context windows
up to 8k tokens in length. The tasks progressively increase in difficulty and
allow more nuanced evaluation of model capabilities than tests like the popular
needle-in-the-haystack test. We find that performance degrades significantly
(up to 2x) when a function references another function that is defined later in
the prompt. We also observe that models that use sliding window attention
mechanisms have difficulty handling references further than the size of a
single window. We perform simple prompt modifications using call graph
information to improve multi-step retrieval performance up to 3x. Our analysis
highlights different facets of long-context performance and is suggestive of
prompt construction strategies for code completion tools

ÊëòË¶ÅÔºöÈö®ËëóË™ûË®ÄÊ®°ÂûãÊîØÊè¥ÁöÑÂÖßÂÆπÂ§ßÂ∞èË∂ä‰æÜË∂äÂ§ßÔºåË©ï‰º∞ÂÖ∂ÊúâÊïàÂà©Áî®Ë©≤ÂÖßÂÆπÁöÑËÉΩÂäõËÆäÂæóË∂ä‰æÜË∂äÈáçË¶Å„ÄÇÊàëÂÄëÂàÜÊûê‰∫ÜÂπæÂÄãÁ®ãÂºèÁ¢ºÁîüÊàêÊ®°ÂûãËôïÁêÜÈï∑Ë∑ùÈõ¢‰æùË≥¥Èóú‰øÇÁöÑËÉΩÂäõÔºå‰ΩøÁî®‰∏ÄÁµÑÂ§öÊ≠•È©üÈóúÈçµÊ™¢Á¥¢‰ªªÂãôÔºåÂú®Èï∑ÈÅî 8k ‰ª§ÁâåÁöÑÂÖßÂÆπË¶ñÁ™ó‰∏≠„ÄÇ‰ªªÂãôÈÄêÊº∏Â¢ûÂä†Èõ£Â∫¶Ôºå‰∏¶ÂÖÅË®±Â∞çÊ®°ÂûãÂäüËÉΩÈÄ≤Ë°åÊØîÊµÅË°åÁöÑÈáùÈ†≠‰πæËçâÂ†ÜÊ∏¨Ë©¶Êõ¥Á¥∞Á∑ªÁöÑË©ï‰º∞„ÄÇÊàëÂÄëÁôºÁèæÔºåÁï∂ÂáΩÂºèÂèÉÁÖßÁ®çÂæåÂú®ÊèêÁ§∫‰∏≠ÂÆöÁæ©ÁöÑÂè¶‰∏ÄÂÄãÂáΩÂºèÊôÇÔºåÊïàËÉΩÊúÉÈ°ØËëó‰∏ãÈôçÔºàÊúÄÂ§ö 2 ÂÄçÔºâ„ÄÇÊàëÂÄëÈÇÑËßÄÂØüÂà∞Ôºå‰ΩøÁî®ÊªëÂãïË¶ñÁ™óÊ≥®ÊÑèÊ©üÂà∂ÁöÑÊ®°ÂûãÈõ£‰ª•ËôïÁêÜË∂ÖÂá∫ÂñÆ‰∏ÄË¶ñÁ™óÂ§ßÂ∞èÁöÑÂèÉÁÖß„ÄÇÊàëÂÄë‰ΩøÁî®ÂëºÂè´ÂúñÂΩ¢Ë≥áË®äÂü∑Ë°åÁ∞°ÂñÆÁöÑÊèêÁ§∫‰øÆÊîπÔºå‰ª•Â∞áÂ§öÊ≠•È©üÊ™¢Á¥¢ÊïàËÉΩÊèêÂçáËá≥ 3 ÂÄç„ÄÇÊàëÂÄëÁöÑÂàÜÊûêÁ™ÅÈ°Ø‰∫ÜÈï∑ÂÖßÂÆπÊïàËÉΩÁöÑ‰∏çÂêåÈù¢ÂêëÔºå‰∏¶ÊöóÁ§∫‰∫ÜÁ®ãÂºèÁ¢ºÂÆåÊàêÂ∑•ÂÖ∑ÁöÑÊèêÁ§∫Âª∫ÊßãÁ≠ñÁï•

##### **Finetuning Generative Large Language Models with Discrimination Instructions for Knowledge Graph Completion**
2407.16127v1 by Yang Liu, Xiaobin Tian, Zequn Sun, Wei Hu

Traditional knowledge graph (KG) completion models learn embeddings to
predict missing facts. Recent works attempt to complete KGs in a
text-generation manner with large language models (LLMs). However, they need to
ground the output of LLMs to KG entities, which inevitably brings errors. In
this paper, we present a finetuning framework, DIFT, aiming to unleash the KG
completion ability of LLMs and avoid grounding errors. Given an incomplete
fact, DIFT employs a lightweight model to obtain candidate entities and
finetunes an LLM with discrimination instructions to select the correct one
from the given candidates. To improve performance while reducing instruction
data, DIFT uses a truncated sampling method to select useful facts for
finetuning and injects KG embeddings into the LLM. Extensive experiments on
benchmark datasets demonstrate the effectiveness of our proposed framework.

ÊëòË¶ÅÔºöÂÇ≥Áµ±Áü•Ë≠òÂúñË≠úÔºàKGÔºâÂÆåÊàêÂäüËÉΩÊ®°ÂûãÂ≠∏ÁøíÂµåÂÖ•Ôºå‰ª•È†êÊ∏¨ÈÅ∫Â§±ÁöÑ‰∫ãÂØ¶„ÄÇÊúÄËøëÁöÑÂ∑•‰ΩúÂòóË©¶‰ª•Â§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâ‰ª•ÊñáÂ≠óÁîüÊàêÁöÑÊñπÂºèÂÆåÊàê KG„ÄÇÁÑ∂ËÄåÔºå‰ªñÂÄëÈúÄË¶ÅÂ∞á LLM ÁöÑËº∏Âá∫Âü∫Á§éÂª∫Á´ãÂú® KG ÂØ¶È´î‰∏äÔºåÈÄô‰∏çÂèØÈÅøÂÖçÂú∞ÊúÉÂ∏∂‰æÜÈåØË™§„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂæÆË™øÊ°ÜÊû∂ DIFTÔºåÊó®Âú®ÈáãÊîæ LLM ÁöÑ KG ÂÆåÊàêÂäüËÉΩÔºå‰∏¶ÈÅøÂÖçÂü∫Á§éÈåØË™§„ÄÇÁµ¶ÂÆö‰∏ÄÂÄã‰∏çÂÆåÊï¥ÁöÑ‰∫ãÂØ¶ÔºåDIFT ‰ΩøÁî®‰∏ÄÂÄãËºïÈáèÁ¥öÊ®°Âûã‰æÜÁç≤ÂæóÂÄôÈÅ∏ÂØ¶È´îÔºå‰∏¶ÂæÆË™ø‰∏ÄÂÄã LLMÔºå‰∏¶‰ΩøÁî®Ëæ®Âà•Êåá‰ª§ÂæûÁµ¶ÂÆöÁöÑÂÄôÈÅ∏È†Ö‰∏≠ÈÅ∏ÊìáÊ≠£Á¢∫ÁöÑÂØ¶È´î„ÄÇÁÇ∫‰∫ÜÂú®Ê∏õÂ∞ëÊåá‰ª§Êï∏ÊìöÁöÑÂêåÊôÇÊèêÂçáÊïàËÉΩÔºåDIFT ‰ΩøÁî®‰∏ÄÂÄãÊà™Êñ∑ÊäΩÊ®£ÊñπÊ≥ï‰æÜÈÅ∏ÊìáÊúâÁî®ÁöÑ‰∫ãÂØ¶‰ª•ÈÄ≤Ë°åÂæÆË™øÔºå‰∏¶Â∞á KG ÂµåÂÖ•Ê≥®ÂÖ•Âà∞ LLM ‰∏≠„ÄÇÂú®Âü∫Ê∫ñË≥áÊñôÈõÜ‰∏äÁöÑÂª£Ê≥õÂØ¶È©óË≠âÊòé‰∫ÜÊàëÂÄëÊèêÂá∫ÁöÑÊ°ÜÊû∂ÁöÑÊúâÊïàÊÄß„ÄÇ

##### **Unsupervised Robust Cross-Lingual Entity Alignment via Neighbor Triple Matching with Entity and Relation Texts**
2407.15588v2 by Soojin Yoon, Sungho Ko, Tongyoung Kim, SeongKu Kang, Jinyoung Yeo, Dongha Lee

Cross-lingual entity alignment (EA) enables the integration of multiple
knowledge graphs (KGs) across different languages, providing users with
seamless access to diverse and comprehensive knowledge. Existing methods,
mostly supervised, face challenges in obtaining labeled entity pairs. To
address this, recent studies have shifted towards self-supervised and
unsupervised frameworks. Despite their effectiveness, these approaches have
limitations: (1) Relation passing: mainly focusing on the entity while
neglecting the semantic information of relations, (2) Isomorphic assumption:
assuming isomorphism between source and target graphs, which leads to noise and
reduced alignment accuracy, and (3) Noise vulnerability: susceptible to noise
in the textual features, especially when encountering inconsistent translations
or Out-Of-Vocabulary (OOV) problems. In this paper, we propose ERAlign, an
unsupervised and robust cross-lingual EA pipeline that jointly performs
Entity-level and Relation-level Alignment by neighbor triple matching strategy
using semantic textual features of relations and entities. Its refinement step
iteratively enhances results by fusing entity-level and relation-level
alignments based on neighbor triple matching. The additional verification step
examines the entities' neighbor triples as the linearized text. This
Align-then-Verify pipeline rigorously assesses alignment results, achieving
near-perfect alignment even in the presence of noisy textual features of
entities. Our extensive experiments demonstrate that the robustness and general
applicability of ERAlign improved the accuracy and effectiveness of EA tasks,
contributing significantly to knowledge-oriented applications.

ÊëòË¶ÅÔºöË∑®Ë™ûË®ÄÂØ¶È´îÂ∞çÈΩä (EA) ÂÖÅË®±Êï¥Âêà‰∏çÂêåË™ûË®ÄÁöÑÂ§öÂÄãÁü•Ë≠òÂúñË≠ú (KG)ÔºåÁÇ∫‰ΩøÁî®ËÄÖÊèê‰æõÁÑ°Á∏´Â≠òÂèñÂ§öÂÖÉ‰∏îÂÖ®Èù¢ÁöÑÁü•Ë≠ò„ÄÇÁèæÊúâÁöÑÊñπÊ≥ïÂ§ßÂ§öÊòØÁõ£Áù£ÂºèÁöÑÔºåÂú®ÂèñÂæóÊ®ôË®òÂØ¶È´îÂ∞çÊôÇÈù¢Ëá®ÊåëÊà∞„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊúÄËøëÁöÑÁ†îÁ©∂Â∑≤ËΩâÂêëËá™Áõ£Áù£ÂºèÂíåÈùûÁõ£Áù£ÂºèÊû∂Êßã„ÄÇÂÑòÁÆ°ÈÄô‰∫õÊñπÊ≥ïÊúâÊïàÔºå‰ΩÜ‰ªçÊúâ‰ª•‰∏ãÈôêÂà∂Ôºö(1) Èóú‰øÇÂÇ≥ÈÅûÔºö‰∏ªË¶ÅÈóúÊ≥®ÂØ¶È´îÔºåËÄåÂøΩÁï•Èóú‰øÇÁöÑË™ûÁæ©Ë≥áË®äÔºå(2) ÂêåÊßãÂÅáË®≠ÔºöÂÅáË®≠‰æÜÊ∫êÂúñË≠úÂíåÁõÆÊ®ôÂúñË≠ú‰πãÈñìÂ≠òÂú®ÂêåÊßãÊÄßÔºåÈÄôÊúÉÂ∞éËá¥ÈõúË®äÂíåÈôç‰ΩéÂ∞çÈΩäÊ∫ñÁ¢∫Â∫¶Ôºå‰ª•Âèä (3) ÈõúË®äËÑÜÂº±ÊÄßÔºöÂÆπÊòìÂèóÂà∞ÊñáÂ≠óÁâπÂæµ‰∏≠ÁöÑÈõúË®äÂΩ±ÈüøÔºåÁâπÂà•ÊòØÂú®ÈÅáÂà∞‰∏ç‰∏ÄËá¥ÁöÑÁøªË≠ØÊàñË©ûÂΩôÂ§ñ (OOV) ÂïèÈ°åÊôÇ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫ ERAlignÔºå‰∏ÄÂÄãÈùûÁõ£Áù£Âºè‰∏îÂº∑ÂÅ•ÁöÑË∑®Ë™ûË®Ä EA ÁÆ°Á∑öÔºåÂÆÉÈÄèÈÅé‰ΩøÁî®Èóú‰øÇÂíåÂØ¶È´îÁöÑË™ûÁæ©ÊñáÂ≠óÁâπÂæµÔºåÁµêÂêàÂØ¶È´îÂ±§Á¥öÂíåÈóú‰øÇÂ±§Á¥öÂ∞çÈΩäÔºå‰ª•ÈÑ∞Ëøë‰∏âÂÖÉÁµÑÈÖçÂ∞çÁ≠ñÁï•ÂÖ±ÂêåÂü∑Ë°å„ÄÇÂÆÉÁöÑÁ≤æÁ∑ªÂåñÊ≠•È©üÈÄèÈÅéÂü∫ÊñºÈÑ∞Ëøë‰∏âÂÖÉÁµÑÈÖçÂ∞çËûçÂêàÂØ¶È´îÂ±§Á¥öÂíåÈóú‰øÇÂ±§Á¥öÂ∞çÈΩäÔºåÂèçË¶ÜÂ¢ûÂº∑ÁµêÊûú„ÄÇÈ°çÂ§ñÁöÑÈ©óË≠âÊ≠•È©üÂ∞áÂØ¶È´îÁöÑÈÑ∞Ëøë‰∏âÂÖÉÁµÑË¶ñÁÇ∫Á∑öÊÄßÂåñÊñáÂ≠óÈÄ≤Ë°åÊ™¢Êü•„ÄÇÈÄôÂÄãÂ∞çÈΩäÂÜçÈ©óË≠âÁÆ°Á∑öÂö¥Ê†ºË©ï‰º∞Â∞çÈΩäÁµêÊûúÔºåÂç≥‰ΩøÂú®ÂØ¶È´îÁöÑÊñáÂ≠óÁâπÂæµÊúâÈõúË®äÁöÑÊÉÖÊ≥Å‰∏ãÔºå‰πüËÉΩÈÅîÊàêËøë‰πéÂÆåÁæéÁöÑÂ∞çÈΩä„ÄÇÊàëÂÄëÂª£Ê≥õÁöÑÂØ¶È©óË≠âÊòéÔºåERAlign ÁöÑÂº∑ÂÅ•ÊÄßÂíå‰∏ÄËà¨ÈÅ©Áî®ÊÄßÊèêÂçá‰∫Ü EA ‰ªªÂãôÁöÑÊ∫ñÁ¢∫Â∫¶ÂíåÊúâÊïàÊÄßÔºåÁÇ∫Áü•Ë≠òÂ∞éÂêëÁöÑÊáâÁî®Á®ãÂºèÂÅöÂá∫È°ØËëóË≤¢Áçª„ÄÇ

##### **The Ontoverse: Democratising Access to Knowledge Graph-based Data Through a Cartographic Interface**
2408.03339v1 by Johannes Zimmermann, Dariusz Wiktorek, Thomas Meusburger, Miquel Monge-Dalmau, Antonio Fabregat, Alexander Jarasch, G√ºnter Schmidt, Jorge S. Reis-Filho, T. Ian Simpson

As the number of scientific publications and preprints is growing
exponentially, several attempts have been made to navigate this complex and
increasingly detailed landscape. These have almost exclusively taken
unsupervised approaches that fail to incorporate domain knowledge and lack the
structural organisation required for intuitive interactive human exploration
and discovery. Especially in highly interdisciplinary fields, a deep
understanding of the connectedness of research works across topics is essential
for generating insights. We have developed a unique approach to data navigation
that leans on geographical visualisation and uses hierarchically structured
domain knowledge to enable end-users to explore knowledge spaces grounded in
their desired domains of interest. This can take advantage of existing
ontologies, proprietary intelligence schemata, or be directly derived from the
underlying data through hierarchical topic modelling. Our approach uses natural
language processing techniques to extract named entities from the underlying
data and normalise them against relevant domain references and navigational
structures. The knowledge is integrated by first calculating similarities
between entities based on their shared extracted feature space and then by
alignment to the navigational structures. The result is a knowledge graph that
allows for full text and semantic graph query and structured topic driven
navigation. This allows end-users to identify entities relevant to their needs
and access extensive graph analytics. The user interface facilitates graphical
interaction with the underlying knowledge graph and mimics a cartographic map
to maximise ease of use and widen adoption. We demonstrate an exemplar project
using our generalisable and scalable infrastructure for an academic biomedical
literature corpus that is grounded against hundreds of different named domain
entities.

ÊëòË¶ÅÔºö<paragraph>Èö®ËëóÁßëÂ≠∏Âá∫ÁâàÁâ©ÂíåÈ†êÂç∞Êú¨Êï∏ÈáèÂëàÊåáÊï∏Â¢ûÈï∑ÔºåÂ∑≤Á∂ìÈÄ≤Ë°å‰∫ÜÂ§öÈ†ÖÂòóË©¶‰æÜÊé¢Á¥¢ÈÄôÂÄãË§áÈõú‰∏îÊó•ÁõäË©≥Á¥∞ÁöÑÈ†òÂüü„ÄÇÈÄô‰∫õÂòóË©¶Âπæ‰πéÂÆåÂÖ®Êé°Áî®‰∫ÜÁÑ°Ê≥ïÁ¥çÂÖ•È†òÂüüÁü•Ë≠ò‰∏îÁº∫‰πèÁõ¥ËßÄ‰∫íÂãïÂºè‰∫∫È°ûÊé¢Á¥¢ÂíåÁôºÁèæÊâÄÈúÄÁöÑÁµêÊßãÊÄßÁµÑÁπîÁöÑÁÑ°Áõ£Áù£ÊñπÊ≥ï„ÄÇÁâπÂà•ÊòØÂú®È´òÂ∫¶Ë∑®Â≠∏ÁßëÁöÑÈ†òÂüü‰∏≠ÔºåÊ∑±ÂÖ•‰∫ÜËß£Ë∑®‰∏ªÈ°åÁöÑÁ†îÁ©∂Â∑•‰ΩúÁöÑÈÄ£ÈÄöÊÄßÂ∞çÊñºÁî¢ÁîüË¶ãËß£Ëá≥ÈóúÈáçË¶Å„ÄÇÊàëÂÄëÈñãÁôº‰∫Ü‰∏ÄÁ®ÆÁç®ÁâπÁöÑÊñπÊ≥ï‰æÜÈÄ≤Ë°åË≥áÊñôÂ∞éËà™ÔºåË©≤ÊñπÊ≥ï‰æùË≥¥ÊñºÂú∞ÁêÜË¶ñË¶∫ÂåñÔºå‰∏¶‰ΩøÁî®ÂàÜÂ±§ÁµêÊßãÁöÑÈ†òÂüüÁü•Ë≠òÔºå‰ΩøÁî®Êà∂ËÉΩÂ§†Êé¢Á¥¢Âª∫Á´ãÂú®‰ªñÂÄëÊÑüËààË∂£ÁöÑÁõÆÊ®ôÈ†òÂüü‰∏≠ÁöÑÁü•Ë≠òÁ©∫Èñì„ÄÇÈÄôÂèØ‰ª•Âà©Áî®ÁèæÊúâÁöÑÊú¨‰Ωì„ÄÅÂ∞àÊúâÊô∫ÊÖßÊ®°ÂºèÔºåÊàñÁõ¥Êé•ÂæûÂü∫Á§éË≥áÊñô‰∏≠ÈÄèÈÅéÂàÜÂ±§‰∏ªÈ°åÂª∫Ê®°Ë°çÁîüÂá∫‰æÜ„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ï‰ΩøÁî®Ëá™ÁÑ∂Ë™ûË®ÄËôïÁêÜÊäÄË°ìÂæûÂü∫Á§éË≥áÊñô‰∏≠ÊèêÂèñÂëΩÂêçÂØ¶È´îÔºå‰∏¶Ê†πÊìöÁõ∏ÈóúÁöÑÈ†òÂüüÂèÉËÄÉÂíåÂ∞éËà™ÁµêÊßãÂ∞çÂÆÉÂÄëÈÄ≤Ë°åÊ®ôÊ∫ñÂåñ„ÄÇÁü•Ë≠òÁöÑÊï¥ÂêàÈ¶ñÂÖàÈÄèÈÅéÊ†πÊìöÂÖ±‰∫´ÁöÑÊèêÂèñÁâπÂæµÁ©∫ÈñìË®àÁÆóÂØ¶È´î‰πãÈñìÁöÑÁõ∏‰ººÊÄßÔºåÁÑ∂ÂæåÈÄèÈÅéËàáÂ∞éËà™ÁµêÊßãÁöÑÂ∞çÈΩä‰æÜÈÄ≤Ë°å„ÄÇÁµêÊûúÊòØ‰∏ÄÂÄãÁü•Ë≠òÂúñÔºåÂÖÅË®±ÈÄ≤Ë°åÂÖ®ÊñáÂíåË™ûÁæ©ÂúñÊü•Ë©¢‰ª•ÂèäÁµêÊßãÂåñ‰∏ªÈ°åÈ©ÖÂãïÂ∞éËà™„ÄÇÈÄô‰ΩøÁî®Êà∂ËÉΩÂ§†Ë≠òÂà•ËàáÂÖ∂ÈúÄÊ±ÇÁõ∏ÈóúÁöÑÂØ¶È´îÔºå‰∏¶Â≠òÂèñÂª£Ê≥õÁöÑÂúñÂΩ¢ÂàÜÊûê„ÄÇ‰ΩøÁî®ËÄÖ‰ªãÈù¢‰øÉÈÄ≤‰∫ÜËàáÂü∫Á§éÁü•Ë≠òÂúñÂΩ¢ÁöÑÂúñÂΩ¢‰∫íÂãïÔºå‰∏¶Ê®°Êì¨Ë£ΩÂúñÂú∞Âúñ‰ª•ÊúÄÂ§ßÈôêÂ∫¶Âú∞ÊèêÈ´òÊòìÁî®ÊÄßÂíåÊì¥Â§ßÊé°Áî®Áéá„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫Ü‰∏ÄÂÄãÁØÑ‰æãÂ∞àÊ°àÔºå‰ΩøÁî®ÊàëÂÄëÈáùÂ∞çÊï∏ÁôæÂÄã‰∏çÂêåÁöÑÂëΩÂêçÈ†òÂüüÂØ¶È´îÂª∫Á´ãÁöÑÈÄöÁî®‰∏îÂèØÊì¥ÂÖÖÁöÑÂü∫Á§éÊû∂ÊßãÔºåÁî®ÊñºÂ≠∏Ë°ìÁîüÁâ©ÈÜ´Â≠∏ÊñáÁçªË™ûÊñôÂ∫´„ÄÇ</paragraph>

##### **Pre-Training and Prompting for Few-Shot Node Classification on Text-Attributed Graphs**
2407.15431v1 by Huanjing Zhao, Beining Yang, Yukuo Cen, Junyu Ren, Chenhui Zhang, Yuxiao Dong, Evgeny Kharlamov, Shu Zhao, Jie Tang

The text-attributed graph (TAG) is one kind of important real-world
graph-structured data with each node associated with raw texts. For TAGs,
traditional few-shot node classification methods directly conduct training on
the pre-processed node features and do not consider the raw texts. The
performance is highly dependent on the choice of the feature pre-processing
method. In this paper, we propose P2TAG, a framework designed for few-shot node
classification on TAGs with graph pre-training and prompting. P2TAG first
pre-trains the language model (LM) and graph neural network (GNN) on TAGs with
self-supervised loss. To fully utilize the ability of language models, we adapt
the masked language modeling objective for our framework. The pre-trained model
is then used for the few-shot node classification with a mixed prompt method,
which simultaneously considers both text and graph information. We conduct
experiments on six real-world TAGs, including paper citation networks and
product co-purchasing networks. Experimental results demonstrate that our
proposed framework outperforms existing graph few-shot learning methods on
these datasets with +18.98% ~ +35.98% improvements.

ÊëòË¶ÅÔºöÊñáÊú¨Â±ûÊÄßÂõæ (TAG) ÊòØ‰∏ÄÁßçÈáçË¶ÅÁöÑÁúüÂÆû‰∏ñÁïåÂõæÁªìÊûÑÂåñÊï∞ÊçÆÔºåÂÖ∂‰∏≠ÊØè‰∏™ËäÇÁÇπÈÉΩ‰∏éÂéüÂßãÊñáÊú¨Áõ∏ÂÖ≥ËÅî„ÄÇÂØπ‰∫é TAGÔºå‰º†ÁªüÁöÑÂ∞ëÊï∞ÈïúÂ§¥ËäÇÁÇπÂàÜÁ±ªÊñπÊ≥ïÁõ¥Êé•ÂØπÈ¢ÑÂ§ÑÁêÜÁöÑËäÇÁÇπÁâπÂæÅËøõË°åËÆ≠ÁªÉÔºåËÄå‰∏çËÄÉËôëÂéüÂßãÊñáÊú¨„ÄÇÊÄßËÉΩÂú®ÂæàÂ§ßÁ®ãÂ∫¶‰∏äÂèñÂÜ≥‰∫éÁâπÂæÅÈ¢ÑÂ§ÑÁêÜÊñπÊ≥ïÁöÑÈÄâÊã©„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü P2TAGÔºåËøôÊòØ‰∏Ä‰∏™‰∏ì‰∏∫ TAG ‰∏äÁöÑÂ∞ëÊï∞ÈïúÂ§¥ËäÇÁÇπÂàÜÁ±ªËÆæËÆ°ÁöÑÊ°ÜÊû∂ÔºåÂÖ∑ÊúâÂõæÈ¢ÑËÆ≠ÁªÉÂíåÊèêÁ§∫„ÄÇP2TAG È¶ñÂÖà‰ΩøÁî®Ëá™ÊàëÁõëÁù£ÊçüÂ§±ÂØπ TAG ‰∏äÁöÑËØ≠Ë®ÄÊ®°Âûã (LM) ÂíåÂõæÁ•ûÁªèÁΩëÁªú (GNN) ËøõË°åÈ¢ÑËÆ≠ÁªÉ„ÄÇ‰∏∫‰∫ÜÂÖÖÂàÜÂà©Áî®ËØ≠Ë®ÄÊ®°ÂûãÁöÑËÉΩÂäõÔºåÊàë‰ª¨‰∏∫Êàë‰ª¨ÁöÑÊ°ÜÊû∂Ë∞ÉÊï¥‰∫ÜÊé©Á†ÅËØ≠Ë®ÄÂª∫Ê®°ÁõÆÊ†á„ÄÇÁÑ∂Âêé‰ΩøÁî®È¢ÑËÆ≠ÁªÉÊ®°ÂûãËøõË°åÂ∞ëÊï∞ÈïúÂ§¥ËäÇÁÇπÂàÜÁ±ªÔºåÈááÁî®Ê∑∑ÂêàÊèêÁ§∫ÊñπÊ≥ïÔºåÂêåÊó∂ËÄÉËôëÊñáÊú¨ÂíåÂõæ‰ø°ÊÅØ„ÄÇÊàë‰ª¨ÂØπÂÖ≠‰∏™ÁúüÂÆû‰∏ñÁïåÁöÑ TAG ËøõË°å‰∫ÜÂÆûÈ™åÔºåÂåÖÊã¨ËÆ∫ÊñáÂºïÁî®ÁΩëÁªúÂíå‰∫ßÂìÅÂÖ±ÂêåË¥≠‰π∞ÁΩëÁªú„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåÊàë‰ª¨ÊèêÂá∫ÁöÑÊ°ÜÊû∂Âú®Ëøô‰∫õÊï∞ÊçÆÈõÜ‰∏ä‰ºò‰∫éÁé∞ÊúâÁöÑÂõæÂ∞ëÊï∞ÈïúÂ§¥Â≠¶‰π†ÊñπÊ≥ïÔºåÊîπËøõ‰∫Ü +18.98% ~ +35.98%„ÄÇ

##### **LLMExplainer: Large Language Model based Bayesian Inference for Graph Explanation Generation**
2407.15351v2 by Jiaxing Zhang, Jiayi Liu, Dongsheng Luo, Jennifer Neville, Hua Wei

Recent studies seek to provide Graph Neural Network (GNN) interpretability
via multiple unsupervised learning models. Due to the scarcity of datasets,
current methods easily suffer from learning bias. To solve this problem, we
embed a Large Language Model (LLM) as knowledge into the GNN explanation
network to avoid the learning bias problem. We inject LLM as a Bayesian
Inference (BI) module to mitigate learning bias. The efficacy of the BI module
has been proven both theoretically and experimentally. We conduct experiments
on both synthetic and real-world datasets. The innovation of our work lies in
two parts: 1. We provide a novel view of the possibility of an LLM functioning
as a Bayesian inference to improve the performance of existing algorithms; 2.
We are the first to discuss the learning bias issues in the GNN explanation
problem.

ÊëòË¶ÅÔºöËøëÊúüÁ†îÁ©∂Ë©¶ÂúñÈÄèÈÅéÂ§öÁ®ÆÈùûÁõ£Áù£ÂºèÂ≠∏ÁøíÊ®°Âûã‰æÜÊèê‰æõÂúñÁ•ûÁ∂ìÁ∂≤Ë∑Ø (GNN) ÁöÑÂèØËß£ÈáãÊÄß„ÄÇÁî±ÊñºË≥áÊñôÈõÜÁöÑÁ®ÄÂ∞ëÔºåÁõÆÂâçÁöÑÊºîÁÆóÊ≥ïÂÆπÊòìÂèóÂà∞Â≠∏ÁøíÂÅèÂ∑ÆÁöÑÂΩ±Èüø„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÂ∞áÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰ΩúÁÇ∫Áü•Ë≠òÂµåÂÖ•Âà∞ GNN Ëß£ÈáãÁ∂≤Ë∑Ø‰∏≠Ôºå‰ª•ÈÅøÂÖçÂ≠∏ÁøíÂÅèÂ∑ÆÁöÑÂïèÈ°å„ÄÇÊàëÂÄëÂ∞á LLM ‰ΩúÁÇ∫Ë≤ùÊ∞èÊé®Ë´ñ (BI) Ê®°ÁµÑÊ≥®ÂÖ•Ôºå‰ª•Ê∏õËºïÂ≠∏ÁøíÂÅèÂ∑Æ„ÄÇBI Ê®°ÁµÑÁöÑÊïàËÉΩÂ∑≤Âú®ÁêÜË´ñ‰∏äÂíåÂØ¶È©ó‰∏äÂæóÂà∞Ë≠âÂØ¶„ÄÇÊàëÂÄëÂú®ÂêàÊàêÂíåÁúüÂØ¶‰∏ñÁïåË≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÂØ¶È©ó„ÄÇÊàëÂÄëÂ∑•‰ΩúÁöÑÂâµÊñ∞‰πãËôïÂú®ÊñºÂÖ©ÈÉ®ÂàÜÔºö1. ÊàëÂÄëÊèê‰æõ LLM ‰ΩúÁÇ∫Ë≤ùÊ∞èÊé®Ë´ñ‰ª•ÊîπÂñÑÁèæÊúâÊºîÁÆóÊ≥ïÊïàËÉΩÁöÑÂèØËÉΩÊÄß‰πãÊñ∞ËßÄÈªûÔºõ2. ÊàëÂÄëÁéáÂÖàË®éË´ñ GNN Ëß£ÈáãÂïèÈ°å‰∏≠ÁöÑÂ≠∏ÁøíÂÅèÂ∑ÆÂïèÈ°å„ÄÇ

##### **Text-Augmented Multimodal LLMs for Chemical Reaction Condition Recommendation**
2407.15141v1 by Yu Zhang, Ruijie Yu, Kaipeng Zeng, Ding Li, Feng Zhu, Xiaokang Yang, Yaohui Jin, Yanyan Xu

High-throughput reaction condition (RC) screening is fundamental to chemical
synthesis. However, current RC screening suffers from laborious and costly
trial-and-error workflows. Traditional computer-aided synthesis planning (CASP)
tools fail to find suitable RCs due to data sparsity and inadequate reaction
representations. Nowadays, large language models (LLMs) are capable of tackling
chemistry-related problems, such as molecule design, and chemical logic Q\&A
tasks. However, LLMs have not yet achieved accurate predictions of chemical
reaction conditions. Here, we present MM-RCR, a text-augmented multimodal LLM
that learns a unified reaction representation from SMILES, reaction graphs, and
textual corpus for chemical reaction recommendation (RCR). To train MM-RCR, we
construct 1.2 million pair-wised Q\&A instruction datasets. Our experimental
results demonstrate that MM-RCR achieves state-of-the-art performance on two
open benchmark datasets and exhibits strong generalization capabilities on
out-of-domain (OOD) and High-Throughput Experimentation (HTE) datasets. MM-RCR
has the potential to accelerate high-throughput condition screening in chemical
synthesis.

ÊëòË¶ÅÔºöÈ´òÈÄöÈáèÂèçÊáâÊ¢ù‰ª∂ (RC) ÁØ©ÈÅ∏ÊòØÂåñÂ≠∏ÂêàÊàê‰∏≠ÁöÑÂü∫Á§é„ÄÇÁÑ∂ËÄåÔºåÁï∂ÂâçÁöÑ RC ÁØ©ÈÅ∏ÊúÉÈÅáÂà∞ÁπÅÁë£‰∏îÊòÇË≤¥ÁöÑË©¶ÈåØÂ∑•‰ΩúÊµÅÁ®ã„ÄÇÂÇ≥Áµ±ÁöÑÈõªËÖ¶ËºîÂä©ÂêàÊàêË¶èÂäÉ (CASP) Â∑•ÂÖ∑ÁÑ°Ê≥ïÊâæÂà∞ÂêàÈÅ©ÁöÑ RCÔºåÈÄôÊòØÂõ†ÁÇ∫Ë≥áÊñôÁ®ÄÁñè‰∏îÂèçÊáâË°®Á§∫‰∏çË∂≥„ÄÇÂ¶Ç‰ªäÔºåÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ËÉΩÂ§†Ëß£Ê±∫ËàáÂåñÂ≠∏Áõ∏ÈóúÁöÑÂïèÈ°åÔºå‰æãÂ¶ÇÂàÜÂ≠êË®≠Ë®àÂíåÂåñÂ≠∏ÈÇèËºØÂïèÁ≠î‰ªªÂãô„ÄÇÁÑ∂ËÄåÔºåLLM Â∞öÊú™ÈÅîÊàêÂåñÂ≠∏ÂèçÊáâÊ¢ù‰ª∂ÁöÑÊ∫ñÁ¢∫È†êÊ∏¨„ÄÇÂú®Ê≠§ÔºåÊàëÂÄëÊèêÂá∫ MM-RCRÔºå‰∏ÄÂÄãÊñáÊú¨Â¢ûÂº∑ÁöÑÂ§öÊ®°ÊÖã LLMÔºåÂÆÉÂæû SMILES„ÄÅÂèçÊáâÂúñÂíåÊñáÊú¨Ë™ûÊñôÂ∫´Â≠∏ÁøíÁµ±‰∏ÄÁöÑÂèçÊáâË°®Á§∫Ôºå‰ª•ÈÄ≤Ë°åÂåñÂ≠∏ÂèçÊáâÊé®Ëñ¶ (RCR)„ÄÇÁÇ∫‰∫ÜË®ìÁ∑¥ MM-RCRÔºåÊàëÂÄëÂª∫Êßã‰∫Ü 120 Ëê¨Â∞çÈÖçÂ∞çÁöÑÂïèÁ≠îÊåá‰ª§Ë≥áÊñôÈõÜ„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÁµêÊûúË≠âÊòéÔºåMM-RCR Âú®ÂÖ©ÂÄãÈñãÊîæÂü∫Ê∫ñË≥áÊñôÈõÜ‰∏äÈÅîÂà∞‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÊïàËÉΩÔºå‰∏¶Âú®È†òÂüüÂ§ñ (OOD) ÂíåÈ´òÈÄöÈáèÂØ¶È©ó (HTE) Ë≥áÊñôÈõÜ‰∏äÂ±ïÁèæÂá∫Âº∑Â§ßÁöÑÊ¶ÇÂåñËÉΩÂäõ„ÄÇMM-RCR ÊúâÂèØËÉΩÂä†ÈÄüÂåñÂ≠∏ÂêàÊàê‰∏≠ÁöÑÈ´òÈÄöÈáèÊ¢ù‰ª∂ÁØ©ÈÅ∏„ÄÇ

##### **On the Design and Analysis of LLM-Based Algorithms**
2407.14788v1 by Yanxi Chen, Yaliang Li, Bolin Ding, Jingren Zhou

We initiate a formal investigation into the design and analysis of LLM-based
algorithms, i.e. algorithms that contain one or multiple calls of large
language models (LLMs) as sub-routines and critically rely on the capabilities
of LLMs. While LLM-based algorithms, ranging from basic LLM calls with prompt
engineering to complicated LLM-powered agent systems and compound AI systems,
have achieved remarkable empirical success, the design and optimization of them
have mostly relied on heuristics and trial-and-errors, which is largely due to
a lack of formal and analytical study for these algorithms. To fill this gap,
we start by identifying the computational-graph representation of LLM-based
algorithms, the design principle of task decomposition, and some key
abstractions, which then facilitate our formal analysis for the accuracy and
efficiency of LLM-based algorithms, despite the black-box nature of LLMs. We
further consider parallel decomposition for a case study, providing extensive
analytical and empirical study for four concrete examples of this pattern. Our
proposed framework holds promise for advancing LLM-based algorithms, by
revealing the reasons behind curious empirical phenomena, guiding the choices
of hyperparameters, predicting the empirical performance of algorithms, and
inspiring new algorithm design. To promote further study of LLM-based
algorithms, we release our source code at
https://github.com/modelscope/agentscope/tree/main/examples/paper_llm_based_algorithm.

ÊëòË¶ÅÔºö<paragraph>ÊàëÂÄëÂ∞çÂü∫Êñº LLM ÁöÑÊºîÁÆóÊ≥ïÁöÑË®≠Ë®àÂíåÂàÜÊûêÂ±ïÈñãÊ≠£ÂºèË™øÊü•ÔºåÂç≥ÂåÖÂê´‰∏ÄÂÄãÊàñÂ§öÂÄãÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰ΩúÁÇ∫Â≠êÂ∏∏ÂºèÂëºÂè´ÁöÑÊºîÁÆóÊ≥ïÔºå‰∏¶Ê•µÂ∫¶‰æùË≥¥ LLM ÁöÑÂäüËÉΩ„ÄÇÂÑòÁÆ°Âü∫Êñº LLM ÁöÑÊºîÁÆóÊ≥ïÔºåÂæûÂ∏∂ÊèêÁ§∫Â∑•Á®ãÁöÑÂü∫Êú¨ LLM ÂëºÂè´Âà∞Ë§áÈõúÁöÑ LLM È©ÖÂãïÁöÑ‰ª£ÁêÜÁ≥ªÁµ±ÂíåË§áÂêàÂºè AI Á≥ªÁµ±ÔºåÂ∑≤ÂèñÂæóÈ°ØËëóÁöÑÂØ¶Ë≠âÊàêÂäüÔºå‰ΩÜÂÖ∂Ë®≠Ë®àÂíåÊúÄ‰Ω≥ÂåñÂ§ßÂ§ö‰æùË≥¥Ë©¶È©óÊ≥ïÂíåÈåØË™§ÔºåÈÄôÂú®ÂæàÂ§ßÁ®ãÂ∫¶‰∏äÊòØÂõ†ÁÇ∫Áº∫‰πèÂ∞çÈÄô‰∫õÊºîÁÆóÊ≥ïÁöÑÊ≠£ÂºèÂíåÂàÜÊûêÁ†îÁ©∂„ÄÇÁÇ∫‰∫ÜÂ°´Ë£úÈÄôÂÄãÁ©∫ÁôΩÔºåÊàëÂÄëÂæûË≠òÂà•Âü∫Êñº LLM ÁöÑÊºîÁÆóÊ≥ïÁöÑË®àÁÆóÂúñË°®Á§∫„ÄÅ‰ªªÂãôÂàÜËß£ÁöÑË®≠Ë®àÂéüÂâáÔºå‰ª•Âèä‰∏Ä‰∫õÈóúÈçµÊäΩË±°ÂåñÈñãÂßãÔºåÁÑ∂Âæå‰øÉÈÄ≤ÊàëÂÄëÂ∞çÂü∫Êñº LLM ÁöÑÊºîÁÆóÊ≥ïÁöÑÊ∫ñÁ¢∫ÊÄßÂíåÊïàÁéáÈÄ≤Ë°åÊ≠£ÂºèÂàÜÊûêÔºåÂÑòÁÆ° LLM Êú¨Ë∫´ÂÖ∑ÊúâÈªëÁõíÁâπÊÄß„ÄÇÊàëÂÄëÈÄ≤‰∏ÄÊ≠•ËÄÉÊÖÆ‰∏¶Ë°åÂàÜËß£‰ΩúÁÇ∫Ê°à‰æãÁ†îÁ©∂ÔºåÁÇ∫Ê≠§Ê®°ÂºèÁöÑÂõõÂÄãÂÖ∑È´îÁØÑ‰æãÊèê‰æõÂª£Ê≥õÁöÑÂàÜÊûêÂíåÂØ¶Ë≠âÁ†îÁ©∂„ÄÇÊàëÂÄëÊèêÂá∫ÁöÑÊû∂ÊßãÊúâÊúõÊé®ÈÄ≤Âü∫Êñº LLM ÁöÑÊºîÁÆóÊ≥ïÔºåÊñπÊ≥ïÊòØÊè≠Á§∫Â•áÊÄ™ÁöÑÂØ¶Ë≠âÁèæË±°ËÉåÂæåÁöÑÂéüÂõ†„ÄÅÊåáÂ∞éË∂ÖÂèÉÊï∏ÁöÑÈÅ∏Êìá„ÄÅÈ†êÊ∏¨ÊºîÁÆóÊ≥ïÁöÑÂØ¶Ë≠âÊïàËÉΩÔºå‰∏¶ÊøÄÁôºÊñ∞ÁöÑÊºîÁÆóÊ≥ïË®≠Ë®à„ÄÇÁÇ∫‰∫Ü‰øÉÈÄ≤Â∞çÂü∫Êñº LLM ÁöÑÊºîÁÆóÊ≥ïÁöÑÈÄ≤‰∏ÄÊ≠•Á†îÁ©∂ÔºåÊàëÂÄëÂú® https://github.com/modelscope/agentscope/tree/main/examples/paper_llm_based_algorithm/ ÁôºÂ∏ÉÊàëÂÄëÁöÑÂéüÂßãÁ¢º„ÄÇ</paragraph>

##### **LaMAGIC: Language-Model-based Topology Generation for Analog Integrated Circuits**
2407.18269v1 by Chen-Chia Chang, Yikang Shan, Shaoze Fan, Jing Li, Shun Zhang, Ningyuan Cao, Yiran Chen, Xin Zhang

In the realm of electronic and electrical engineering, automation of analog
circuit is increasingly vital given the complexity and customized requirements
of modern applications. However, existing methods only develop search-based
algorithms that require many simulation iterations to design a custom circuit
topology, which is usually a time-consuming process. To this end, we introduce
LaMAGIC, a pioneering language model-based topology generation model that
leverages supervised finetuning for automated analog circuit design. LaMAGIC
can efficiently generate an optimized circuit design from the custom
specification in a single pass. Our approach involves a meticulous development
and analysis of various input and output formulations for circuit. These
formulations can ensure canonical representations of circuits and align with
the autoregressive nature of LMs to effectively addressing the challenges of
representing analog circuits as graphs. The experimental results show that
LaMAGIC achieves a success rate of up to 96\% under a strict tolerance of 0.01.
We also examine the scalability and adaptability of LaMAGIC, specifically
testing its performance on more complex circuits. Our findings reveal the
enhanced effectiveness of our adjacency matrix-based circuit formulation with
floating-point input, suggesting its suitability for handling intricate circuit
designs. This research not only demonstrates the potential of language models
in graph generation, but also builds a foundational framework for future
explorations in automated analog circuit design.

ÊëòË¶ÅÔºöÂú®ÈõªÂ≠êÂíåÈõªÊ∞£Â∑•Á®ãÈ†òÂüü‰∏≠ÔºåËá™ÂãïÂåñÈ°ûÊØîÈõªË∑ØË∂ä‰æÜË∂äÈáçË¶ÅÔºåÂõ†ÁÇ∫Áèæ‰ª£ÊáâÁî®Á®ãÂºèÂÖ∑ÊúâË§áÈõú‰∏îÂÆ¢Ë£ΩÂåñÁöÑÈúÄÊ±Ç„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÁöÑÊñπÊ≥ïÂÉÖÈñãÁôºÂü∫ÊñºÊêúÂ∞ãÁöÑÊºîÁÆóÊ≥ïÔºåÈúÄË¶ÅË®±Â§öÊ®°Êì¨ÂèçË¶ÜÈÅãÁÆóÊâçËÉΩË®≠Ë®àÂÆ¢Ë£ΩÂåñÈõªË∑ØÊãìÊí≤ÔºåÈÄôÈÄöÂ∏∏ÊòØ‰∏ÄÂÄãËÄóÊôÇÁöÑÈÅéÁ®ã„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü LaMAGICÔºå‰∏ÄÂÄãÂü∫ÊñºÂÖàÈ©ÖË™ûË®ÄÊ®°ÂûãÁöÑÊãìÊí≤ÁîüÊàêÊ®°ÂûãÔºåÂÆÉÂà©Áî®Áõ£Áù£ÂæÆË™øÈÄ≤Ë°åËá™ÂãïÂåñÈ°ûÊØîÈõªË∑ØË®≠Ë®à„ÄÇLaMAGIC ÂèØ‰ª•ÊúâÊïàÁéáÂú∞ÂæûÂÆ¢Ë£ΩÂåñË¶èÊ†º‰∏≠ÁîüÊàêÊúÄ‰Ω≥ÂåñÁöÑÈõªË∑ØË®≠Ë®àÔºåÂè™ÈúÄ‰∏ÄÊ¨°ÈÄöÈÅé„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÂåÖÊã¨‰ªîÁ¥∞ÈñãÁôºÂíåÂàÜÊûêÈõªË∑ØÁöÑÂêÑÁ®ÆËº∏ÂÖ•ÂíåËº∏Âá∫ÂÖ¨Âºè„ÄÇÈÄô‰∫õÂÖ¨ÂºèÂèØ‰ª•Á¢∫‰øùÈõªË∑ØÁöÑÊ®ôÊ∫ñË°®Á§∫Ôºå‰∏¶Ëàá LM ÁöÑËá™Ëø¥Ê≠∏ÊÄßË≥™‰øùÊåÅ‰∏ÄËá¥Ôºå‰ª•ÊúâÊïàËß£Ê±∫Â∞áÈ°ûÊØîÈõªË∑ØË°®Á§∫ÁÇ∫ÂúñÂΩ¢ÁöÑÊåëÊà∞„ÄÇÂØ¶È©óÁµêÊûúÈ°ØÁ§∫ÔºåLaMAGIC Âú® 0.01 ÁöÑÂö¥Ê†ºÂÆπÂ∑Æ‰∏ãÂØ¶Áèæ‰∫ÜÈ´òÈÅî 96% ÁöÑÊàêÂäüÁéá„ÄÇÊàëÂÄëÈÇÑÊ™¢Êü•‰∫Ü LaMAGIC ÁöÑÂèØÊì¥ÂÖÖÊÄßÂíåÈÅ©ÊáâÊÄßÔºåÁâπÂà•ÊòØÊ∏¨Ë©¶‰∫ÜÂÆÉÂú®Êõ¥Ë§áÈõúÈõªË∑Ø‰∏äÁöÑÊïàËÉΩ„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÊè≠Á§∫‰∫ÜÊàëÂÄëÂü∫ÊñºÈÑ∞Êé•Áü©Èô£ÁöÑÈõªË∑ØÂÖ¨ÂºèËàáÊµÆÈªûËº∏ÂÖ•ÁöÑÂ¢ûÂº∑ÊïàËÉΩÔºåË°®ÊòéÂÆÉÈÅ©Áî®ÊñºËôïÁêÜË§áÈõúÁöÑÈõªË∑ØË®≠Ë®à„ÄÇÈÄôÈ†ÖÁ†îÁ©∂‰∏çÂÉÖÂ±ïÁ§∫‰∫ÜË™ûË®ÄÊ®°ÂûãÂú®ÂúñÂΩ¢ÁîüÊàê‰∏≠ÁöÑÊΩõÂäõÔºå‰πüÁÇ∫Êú™‰æÜÂú®Ëá™ÂãïÂåñÈ°ûÊØîÈõªË∑ØË®≠Ë®à‰∏≠ÁöÑÊé¢Á¥¢Âª∫Á´ã‰∫ÜÂü∫Á§éÊ°ÜÊû∂„ÄÇ

##### **Hierarchical Windowed Graph Attention Network and a Large Scale Dataset for Isolated Indian Sign Language Recognition**
2407.14224v1 by Suvajit Patra, Arkadip Maitra, Megha Tiwari, K. Kumaran, Swathy Prabhu, Swami Punyeshwarananda, Soumitra Samanta

Automatic Sign Language (SL) recognition is an important task in the computer
vision community. To build a robust SL recognition system, we need a
considerable amount of data which is lacking particularly in Indian sign
language (ISL). In this paper, we propose a large-scale isolated ISL dataset
and a novel SL recognition model based on skeleton graph structure. The dataset
covers 2,002 daily used common words in the deaf community recorded by 20 (10
male and 10 female) deaf adult signers (contains 40033 videos). We propose a SL
recognition model namely Hierarchical Windowed Graph Attention Network (HWGAT)
by utilizing the human upper body skeleton graph structure. The HWGAT tries to
capture distinctive motions by giving attention to different body parts induced
by the human skeleton graph structure. The utility of the proposed dataset and
the usefulness of our model are evaluated through extensive experiments. We
pre-trained the proposed model on the proposed dataset and fine-tuned it across
different sign language datasets further boosting the performance of 1.10,
0.46, 0.78, and 6.84 percentage points on INCLUDE, LSA64, AUTSL and WLASL
respectively compared to the existing state-of-the-art skeleton-based models.

ÊëòË¶ÅÔºöËá™ÂãïÊâãË™û (SL) Ë≠òÂà•ÊòØÈõªËÖ¶Ë¶ñË¶∫Á§æÁæ§‰∏≠ÁöÑÈáçË¶Å‰ªªÂãô„ÄÇË¶ÅÂª∫Á´ãÂº∑ÂÅ•ÁöÑ SL Ë≠òÂà•Á≥ªÁµ±ÔºåÊàëÂÄëÈúÄË¶ÅÂ§ßÈáèÁöÑË≥áÊñôÔºåËÄåÈÄôÂú®Âç∞Â∫¶ÊâãË™û (ISL) ‰∏≠ÁâπÂà•Áº∫‰πè„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÂ§ßË¶èÊ®°ÁöÑÂ≠§Á´ã ISL Ë≥áÊñôÈõÜÔºå‰ª•Âèä‰∏ÄÂÄãÂü∫ÊñºÈ™®Êû∂ÂúñÁµêÊßãÁöÑÊñ∞Âûã SL Ë≠òÂà•Ê®°Âûã„ÄÇË©≤Ë≥áÊñôÈõÜÊ∂µËìã 2,002 ÂÄãËÅæÂïûÁ§æÁæ§‰∏≠Â∏∏Áî®ÁöÑÊó•Â∏∏ÂñÆÂ≠óÔºåÁî± 20 ‰Ωç (10 Áî∑ 10 Â•≥) ËÅæÂïûÊàê‰∫∫ÊâãË™ûËÄÖÈåÑË£ΩÔºàÂåÖÂê´ 40033 ÈÉ®ÂΩ±ÁâáÔºâ„ÄÇÊàëÂÄëÊèêÂá∫‰∏ÄÂÄã SL Ë≠òÂà•Ê®°ÂûãÔºåÂç≥ÂàÜÂ±§Ë¶ñÁ™óÂúñÊ≥®ÊÑèÂäõÁ∂≤Ë∑Ø (HWGAT)ÔºåÂà©Áî®‰∫∫È´î‰∏äÂçäË∫´È™®Êû∂ÂúñÁµêÊßã„ÄÇHWGAT ÂòóË©¶ÈÄèÈÅéÈóúÊ≥®Áî±‰∫∫È´îÈ™®Êû∂ÂúñÁµêÊßãË™òÂ∞éÁöÑ‰∏çÂêåË∫´È´îÈÉ®‰Ωç‰æÜÊçïÊçâÁç®ÁâπÁöÑÂãï‰Ωú„ÄÇÈÄèÈÅéÂª£Ê≥õÁöÑÂØ¶È©óË©ï‰º∞ÊâÄÊèêÂá∫ÁöÑË≥áÊñôÈõÜÁöÑÊïàÁî®ÂíåÊàëÂÄëÊ®°ÂûãÁöÑÊúâÁî®ÊÄß„ÄÇÊàëÂÄëÂú®ÊâÄÊèêÂá∫ÁöÑË≥áÊñôÈõÜ‰∏äÈ†êË®ìÁ∑¥ÊâÄÊèêÂá∫ÁöÑÊ®°ÂûãÔºå‰∏¶Âú®‰∏çÂêåÁöÑÊâãË™ûË≥áÊñôÈõÜ‰∏äÂæÆË™øÂÆÉÔºåÈÄ≤‰∏ÄÊ≠•ÊèêÂçá‰∫Ü INCLUDE„ÄÅLSA64„ÄÅAUTSL Âíå WLASL ‰∏ä 1.10„ÄÅ0.46„ÄÅ0.78 Âíå 6.84 ÂÄãÁôæÂàÜÈªûÁöÑÊïàËÉΩÔºåÂàÜÂà•ËàáÁèæÊúâÁöÑÊúÄÂÖàÈÄ≤ÁöÑÂü∫ÊñºÈ™®Êû∂ÁöÑÊ®°ÂûãÁõ∏ÊØî„ÄÇ

##### **Enhancing Data-Limited Graph Neural Networks by Actively Distilling Knowledge from Large Language Models**
2407.13989v1 by Quan Li, Tianxiang Zhao, Lingwei Chen, Junjie Xu, Suhang Wang

Graphs have emerged as critical data structures for content analysis in
various domains, such as social network analysis, bioinformatics, and
recommendation systems. Node classification, a fundamental task in this
context, is typically tackled using graph neural networks (GNNs).
Unfortunately, conventional GNNs still face challenges in scenarios with few
labeled nodes, despite the prevalence of few-shot node classification tasks in
real-world applications. To address this challenge, various approaches have
been proposed, including graph meta-learning, transfer learning, and methods
based on Large Language Models (LLMs). However, traditional meta-learning and
transfer learning methods often require prior knowledge from base classes or
fail to exploit the potential advantages of unlabeled nodes. Meanwhile,
LLM-based methods may overlook the zero-shot capabilities of LLMs and rely
heavily on the quality of generated contexts. In this paper, we propose a novel
approach that integrates LLMs and GNNs, leveraging the zero-shot inference and
reasoning capabilities of LLMs and employing a Graph-LLM-based active learning
paradigm to enhance GNNs' performance. Extensive experiments demonstrate the
effectiveness of our model in improving node classification accuracy with
considerably limited labeled data, surpassing state-of-the-art baselines by
significant margins.

ÊëòË¶ÅÔºöÂúñË°®Â∑≤ÊàêÁÇ∫ÂêÑÁ®ÆÈ†òÂüü‰∏≠ÂÖßÂÆπÂàÜÊûêÁöÑÈóúÈçµÊï∏ÊìöÁµêÊßãÔºå‰æãÂ¶ÇÁ§æ‰∫§Á∂≤Ë∑ØÂàÜÊûê„ÄÅÁîüÁâ©Ë≥áË®äÂ≠∏ÂíåÊé®Ëñ¶Á≥ªÁµ±„ÄÇÁØÄÈªûÂàÜÈ°ûÊòØÊ≠§ËÑàÁµ°‰∏≠ÁöÑÂü∫Êú¨‰ªªÂãôÔºåÈÄöÂ∏∏‰ΩøÁî®ÂúñÂΩ¢Á•ûÁ∂ìÁ∂≤Ë∑Ø (GNN) ‰æÜËôïÁêÜ„ÄÇ‰∏çÂπ∏ÁöÑÊòØÔºåÂÑòÁÆ°ÁèæÂØ¶‰∏ñÁïåÊáâÁî®‰∏≠ÊôÆÈÅçÂ≠òÂú®Â∞ëÊ®£Êú¨ÁØÄÈªûÂàÜÈ°û‰ªªÂãôÔºå‰ΩÜÂÇ≥Áµ±ÁöÑ GNN Âú®Ê®ôË®òÁØÄÈªûÂæàÂ∞ëÁöÑÊÉÖÊ≥Å‰∏ã‰ªçÈù¢Ëá®ÊåëÊà∞„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∏ÄÊåëÊà∞ÔºåÂ∑≤ÊèêÂá∫ÂêÑÁ®ÆÊñπÊ≥ïÔºåÂåÖÊã¨ÂúñÂΩ¢ÂÖÉÂ≠∏Áøí„ÄÅÈÅ∑ÁßªÂ≠∏ÁøíÂíåÂü∫ÊñºÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊñπÊ≥ï„ÄÇÁÑ∂ËÄåÔºåÂÇ≥Áµ±ÁöÑÂÖÉÂ≠∏ÁøíÂíåÈÅ∑ÁßªÂ≠∏ÁøíÊñπÊ≥ïÈÄöÂ∏∏ÈúÄË¶Å‰æÜËá™Âü∫Á§éÈ°ûÂà•ÁöÑÂÖàÈ©óÁü•Ë≠òÔºåÊàñËÄÖÁÑ°Ê≥ïÂà©Áî®Êú™Ê®ôË®òÁØÄÈªûÁöÑÊΩõÂú®ÂÑ™Âã¢„ÄÇÂêåÊôÇÔºåÂü∫Êñº LLM ÁöÑÊñπÊ≥ïÂèØËÉΩÊúÉÂøΩË¶ñ LLM ÁöÑÈõ∂Ê®£Êú¨ËÉΩÂäõÔºå‰∏¶‰∏îÈÅéÂ∫¶‰æùË≥¥ÁîüÊàêË™ûÂ¢ÉÁöÑÂìÅË≥™„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞ÁöÑÊñπÊ≥ïÔºåÂÆÉÊï¥Âêà‰∫Ü LLM Âíå GNNÔºåÂà©Áî® LLM ÁöÑÈõ∂Ê®£Êú¨Êé®Ë´ñÂíåÊé®ÁêÜËÉΩÂäõÔºå‰∏¶Êé°Áî®Âü∫Êñº Graph-LLM ÁöÑ‰∏ªÂãïÂ≠∏ÁøíÁØÑ‰æã‰æÜÂ¢ûÂº∑ GNN ÁöÑÊïàËÉΩ„ÄÇÂª£Ê≥õÁöÑÂØ¶È©óË≠âÊòé‰∫ÜÊàëÂÄëÁöÑÊ®°ÂûãÂú®ÊîπÈÄ≤ÁØÄÈªûÂàÜÈ°ûÊ∫ñÁ¢∫Â∫¶ÊñπÈù¢ÁöÑÊúâÊïàÊÄßÔºåÊ®ôË®òÊï∏ÊìöÁõ∏Áï∂ÊúâÈôêÔºåÈ°ØËëóË∂ÖË∂ä‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÂü∫Ê∫ñ„ÄÇ

##### **A Comprehensive Review of Recommender Systems: Transitioning from Theory to Practice**
2407.13699v1 by Shaina Raza, Mizanur Rahman, Safiullah Kamawal, Armin Toroghi, Ananya Raval, Farshad Navah, Amirmohammad Kazemeini

Recommender Systems (RS) play an integral role in enhancing user experiences
by providing personalized item suggestions. This survey reviews the progress in
RS inclusively from 2017 to 2024, effectively connecting theoretical advances
with practical applications. We explore the development from traditional RS
techniques like content-based and collaborative filtering to advanced methods
involving deep learning, graph-based models, reinforcement learning, and large
language models. We also discuss specialized systems such as context-aware,
review-based, and fairness-aware RS. The primary goal of this survey is to
bridge theory with practice. It addresses challenges across various sectors,
including e-commerce, healthcare, and finance, emphasizing the need for
scalable, real-time, and trustworthy solutions. Through this survey, we promote
stronger partnerships between academic research and industry practices. The
insights offered by this survey aim to guide industry professionals in
optimizing RS deployment and to inspire future research directions, especially
in addressing emerging technological and societal trends

ÊëòË¶ÅÔºöÊé®Ëñ¶Á≥ªÁµ± (RS) Âú®ÊèêÂçá‰ΩøÁî®ËÄÖÈ´îÈ©ó‰∏≠ÊâÆÊºîËëó‰∏çÂèØÊàñÁº∫ÁöÑËßíËâ≤ÔºåÈÄèÈÅéÊèê‰æõÂÄã‰∫∫ÂåñÁöÑÂïÜÂìÅÂª∫Ë≠∞„ÄÇÈÄôÈ†ÖË™øÊü•ÂõûÈ°ß‰∫Ü RS Âú® 2017 Âπ¥Âà∞ 2024 Âπ¥ÈñìÁöÑÈÄ≤Â±ïÔºåÊúâÊïàÂú∞Â∞áÁêÜË´ñÈÄ≤Â±ïËàáÂØ¶ÈöõÊáâÁî®ÈÄ£ÁµêËµ∑‰æÜ„ÄÇÊàëÂÄëÊé¢Ë®é‰∫ÜÂæûÂÇ≥Áµ±ÁöÑ RS ÊäÄË°ìÔºå‰æãÂ¶ÇÂü∫ÊñºÂÖßÂÆπÂíåÂçîÂêåÈÅéÊøæÔºåÂà∞Ê∂âÂèäÊ∑±Â∫¶Â≠∏Áøí„ÄÅÂü∫ÊñºÂúñÂΩ¢ÁöÑÊ®°Âûã„ÄÅÂº∑ÂåñÂ≠∏ÁøíÂíåÂ§ßË™ûË®ÄÊ®°ÂûãÁ≠âÂÖàÈÄ≤ÊñπÊ≥ïÁöÑÁôºÂ±ï„ÄÇÊàëÂÄë‰πüË®éË´ñ‰∫ÜÂ∞àÈñÄÁöÑÁ≥ªÁµ±Ôºå‰æãÂ¶ÇÊÉÖÂ¢ÉÊÑüÁü•„ÄÅÂü∫ÊñºË©ïË´ñÂíåÂÖ¨Âπ≥ÊÑüÁü•ÁöÑ RS„ÄÇÈÄôÈ†ÖË™øÊü•ÁöÑ‰∏ªË¶ÅÁõÆÊ®ôÊòØÂ∞áÁêÜË´ñËàáÂØ¶ÂãôÁµêÂêàËµ∑‰æÜ„ÄÇÂÆÉËß£Ê±∫‰∫ÜÂêÑÂÄãÈ†òÂüüÁöÑÊåëÊà∞ÔºåÂåÖÊã¨ÈõªÂ≠êÂïÜÂãô„ÄÅÈÜ´ÁôÇ‰øùÂÅ•ÂíåÈáëËûçÔºåÂº∑Ë™ø‰∫ÜÂ∞çÂèØÊì¥ÂÖÖ„ÄÅÂç≥ÊôÇÂíåÂèØ‰ø°Ë≥¥ÁöÑËß£Ê±∫ÊñπÊ°àÁöÑÈúÄÊ±Ç„ÄÇÈÄèÈÅéÈÄôÈ†ÖË™øÊü•ÔºåÊàëÂÄë‰øÉÈÄ≤‰∫ÜÂ≠∏Ë°ìÁ†îÁ©∂ÂíåÁî¢Ê•≠ÂØ¶Âãô‰πãÈñìÊõ¥Âº∑Â§ßÁöÑÂ§•‰º¥Èóú‰øÇ„ÄÇÈÄôÈ†ÖË™øÊü•Êèê‰æõÁöÑË¶ãËß£Êó®Âú®ÂºïÂ∞éÁî¢Ê•≠Â∞àÊ•≠‰∫∫Â£´ÂÑ™Âåñ RS ÈÉ®ÁΩ≤Ôºå‰∏¶ÊøÄÂãµÊú™‰æÜÁöÑÁ†îÁ©∂ÊñπÂêëÔºåÁâπÂà•ÊòØÂú®Ëß£Ê±∫Êñ∞ËààÁöÑÊäÄË°ìÂíåÁ§æÊúÉË∂®Âã¢ÊñπÈù¢„ÄÇ

##### **MMAU: A Holistic Benchmark of Agent Capabilities Across Diverse Domains**
2407.18961v3 by Guoli Yin, Haoping Bai, Shuang Ma, Feng Nan, Yanchao Sun, Zhaoyang Xu, Shen Ma, Jiarui Lu, Xiang Kong, Aonan Zhang, Dian Ang Yap, Yizhe zhang, Karsten Ahnert, Vik Kamath, Mathias Berglund, Dominic Walsh, Tobias Gindele, Juergen Wiest, Zhengfeng Lai, Xiaoming Wang, Jiulong Shan, Meng Cao, Ruoming Pang, Zirui Wang

Recent advances in large language models (LLMs) have increased the demand for
comprehensive benchmarks to evaluate their capabilities as human-like agents.
Existing benchmarks, while useful, often focus on specific application
scenarios, emphasizing task completion but failing to dissect the underlying
skills that drive these outcomes. This lack of granularity makes it difficult
to deeply discern where failures stem from. Additionally, setting up these
environments requires considerable effort, and issues of unreliability and
reproducibility sometimes arise, especially in interactive tasks. To address
these limitations, we introduce the Massive Multitask Agent Understanding
(MMAU) benchmark, featuring comprehensive offline tasks that eliminate the need
for complex environment setups. It evaluates models across five domains,
including Tool-use, Directed Acyclic Graph (DAG) QA, Data Science and Machine
Learning coding, Contest-level programming and Mathematics, and covers five
essential capabilities: Understanding, Reasoning, Planning, Problem-solving,
and Self-correction. With a total of 20 meticulously designed tasks
encompassing over 3K distinct prompts, MMAU provides a comprehensive framework
for evaluating the strengths and limitations of LLM agents. By testing 18
representative models on MMAU, we provide deep and insightful analyses.
Ultimately, MMAU not only sheds light on the capabilities and limitations of
LLM agents but also enhances the interpretability of their performance.
Datasets and evaluation scripts of MMAU are released at
https://github.com/apple/axlearn/tree/main/docs/research/mmau.

ÊëòË¶ÅÔºö<paragraph>Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊúÄÊñ∞ÈÄ≤Â±ïÂ¢ûÂä†‰∫ÜÂ∞çÂÖ®Èù¢Âü∫Ê∫ñÊ∏¨Ë©¶ÁöÑÈúÄÊ±ÇÔºå‰ª•Ë©ï‰º∞ÂÖ∂‰ΩúÁÇ∫È°û‰∫∫‰ª£ÁêÜÁöÑËÉΩÂäõ„ÄÇÁèæÊúâÁöÑÂü∫Ê∫ñÊ∏¨Ë©¶ÈõñÁÑ∂ÊúâÁî®Ôºå‰ΩÜÈÄöÂ∏∏Â∞àÊ≥®ÊñºÁâπÂÆöÊáâÁî®ÊÉÖÂ¢ÉÔºåÂº∑Ë™ø‰ªªÂãôÂÆåÊàêÔºå‰ΩÜÊú™ËÉΩÂâñÊûêÈ©ÖÂãïÈÄô‰∫õÁµêÊûúÁöÑÂ∫ïÂ±§ÊäÄËÉΩ„ÄÇÈÄôÁ®ÆÁº∫‰πèÁ≤íÂ∫¶ÊÄß‰ΩøÂæóÈõ£‰ª•Ê∑±ÂÖ•Ëæ®Âà•Â§±ÊïóÁöÑÊ†πÊ∫ê„ÄÇÊ≠§Â§ñÔºåË®≠ÂÆöÈÄô‰∫õÁí∞Â¢ÉÈúÄË¶ÅÂ§ßÈáèÁöÑÂä™ÂäõÔºåËÄå‰∏îÊúâÊôÇÊúÉÂá∫Áèæ‰∏çÂèØÈù†ÊÄßÂíåÂèØÈáçË§áÊÄßÁöÑÂïèÈ°åÔºåÂ∞§ÂÖ∂ÊòØÂú®‰∫íÂãï‰ªªÂãô‰∏≠„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÈôêÂà∂ÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜÂ§ßË¶èÊ®°Â§ö‰ªªÂãô‰ª£ÁêÜÁêÜËß£ (MMAU) Âü∫Ê∫ñÊ∏¨Ë©¶ÔºåÂÖ∂ÁâπÈªûÊòØÂÖ®Èù¢ÁöÑÈõ¢Á∑ö‰ªªÂãôÔºåÊ∂àÈô§‰∫ÜÂ∞çË§áÈõúÁí∞Â¢ÉË®≠ÂÆöÁöÑÈúÄÊ±Ç„ÄÇÂÆÉË∑®Ë∂ä‰∫îÂÄãÈ†òÂüüË©ï‰º∞Ê®°ÂûãÔºåÂåÖÊã¨Â∑•ÂÖ∑‰ΩøÁî®„ÄÅÊúâÂêëÁÑ°Áí∞Âúñ (DAG) ÂïèÁ≠î„ÄÅÊï∏ÊìöÁßëÂ≠∏ÂíåÊ©üÂô®Â≠∏ÁøíÁ∑®Á¢º„ÄÅÁ´∂Ë≥ΩÁ¥öÁ∑®Á®ãÂíåÊï∏Â≠∏ÔºåÊ∂µËìã‰∫îÈ†ÖÂü∫Êú¨ËÉΩÂäõÔºöÁêÜËß£„ÄÅÊé®ÁêÜ„ÄÅË¶èÂäÉ„ÄÅÂïèÈ°åËß£Ê±∫ÂíåËá™ÊàëÊ†°Ê≠£„ÄÇMMAU Á∏ΩÂÖ±ÂåÖÂê´ 20 È†ÖÁ≤æÂøÉË®≠Ë®àÁöÑ‰ªªÂãôÔºåÊ∂µËìãË∂ÖÈÅé 3K ÂÄã‰∏çÂêåÁöÑÊèêÁ§∫ÔºåÊèê‰æõ‰∫Ü‰∏ÄÂÄãÂÖ®Èù¢ÁöÑÊ°ÜÊû∂ÔºåÁî®ÊñºË©ï‰º∞ LLM ‰ª£ÁêÜÁöÑÂÑ™Âã¢ÂíåÂ±ÄÈôêÊÄß„ÄÇÈÄöÈÅéÂú® MMAU ‰∏äÊ∏¨Ë©¶ 18 ÂÄã‰ª£Ë°®ÊÄßÊ®°ÂûãÔºåÊàëÂÄëÊèê‰æõ‰∫ÜÊ∑±ÂÖ•‰∏îÊúâË¶ãÂú∞ÁöÑÂàÜÊûê„ÄÇÊúÄÁµÇÔºåMMAU ‰∏çÂÉÖÈó°Êòé‰∫Ü LLM ‰ª£ÁêÜÁöÑËÉΩÂäõÂíåÂ±ÄÈôêÊÄßÔºåÈÇÑÂ¢ûÂº∑‰∫ÜÂÖ∂ÊÄßËÉΩÁöÑÂèØËß£ÈáãÊÄß„ÄÇMMAU ÁöÑÊï∏ÊìöÈõÜÂíåË©ï‰º∞ËÖ≥Êú¨Â∑≤ÁôºÂ∏ÉÂú® https://github.com/apple/axlearn/tree/main/docs/research/mmau„ÄÇ</paragraph>

##### **Is Sarcasm Detection A Step-by-Step Reasoning Process in Large Language Models?**
2407.12725v1 by Ben Yao, Yazhou Zhang, Qiuchi Li, Jing Qin

Elaborating a series of intermediate reasoning steps significantly improves
the ability of large language models (LLMs) to solve complex problems, as such
steps would evoke LLMs to think sequentially. However, human sarcasm
understanding is often considered an intuitive and holistic cognitive process,
in which various linguistic, contextual, and emotional cues are integrated to
form a comprehensive understanding of the speaker's true intention, which is
argued not be limited to a step-by-step reasoning process. To verify this
argument, we introduce a new prompting framework called SarcasmCue, which
contains four prompting strategies, $viz.$ chain of contradiction (CoC), graph
of cues (GoC), bagging of cues (BoC) and tensor of cues (ToC), which elicits
LLMs to detect human sarcasm by considering sequential and non-sequential
prompting methods. Through a comprehensive empirical comparison on four
benchmarking datasets, we show that the proposed four prompting methods
outperforms standard IO prompting, CoT and ToT with a considerable margin, and
non-sequential prompting generally outperforms sequential prompting.

ÊëòË¶ÅÔºöÈÄöÈÅéÈó°Ëø∞‰∏ÄÁ≥ªÂàó‰∏≠ÈñìÊé®ÁêÜÊ≠•È©üÔºåÂ§ßÂπÖÊèêÂçáÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Ëß£Ê±∫Ë§áÈõúÂïèÈ°åÁöÑËÉΩÂäõÔºåÂõ†ÁÇ∫ÈÄô‰∫õÊ≠•È©üÊúÉ‰øÉ‰Ωø LLM ÊåâÈ†ÜÂ∫èÊÄùËÄÉ„ÄÇÁÑ∂ËÄåÔºå‰∫∫È°ûÁöÑË´∑Âà∫ÁêÜËß£ÈÄöÂ∏∏Ë¢´Ë™çÁÇ∫ÊòØ‰∏ÄÁ®ÆÁõ¥Ë¶∫‰∏îÂÖ®Èù¢ÁöÑË™çÁü•ÈÅéÁ®ãÔºåÂÖ∂‰∏≠ÂêÑÁ®ÆË™ûË®Ä„ÄÅË™ûÂ¢ÉÂíåÊÉÖÁ∑íÁ∑öÁ¥¢Êï¥ÂêàÂú®‰∏ÄËµ∑Ôºå‰ª•ÂÖ®Èù¢‰∫ÜËß£Ë™™Ë©±ËÄÖÁöÑÁúüÂØ¶ÊÑèÂúñÔºåÈÄôË¢´Ë™çÁÇ∫‰∏çÂÉÖÈôêÊñºÂæ™Â∫èÊº∏ÈÄ≤ÁöÑÊé®ÁêÜÈÅéÁ®ã„ÄÇÁÇ∫‰∫ÜÈ©óË≠âÈÄôÂÄãË´ñÈªûÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÊñ∞ÁöÑÊèêÁ§∫Ê°ÜÊû∂ÔºåÁ®±ÁÇ∫ SarcasmCueÔºåÂÖ∂‰∏≠ÂåÖÂê´ÂõõÁ®ÆÊèêÁ§∫Á≠ñÁï•ÔºåÂç≥ÁüõÁõæÈèà (CoC)„ÄÅÁ∑öÁ¥¢Âúñ (GoC)„ÄÅÁ∑öÁ¥¢Ë¢ã (BoC) ÂíåÁ∑öÁ¥¢ÂºµÈáè (ToC)ÔºåÂÆÉÂºïÁôº LLM ÈÄöÈÅéËÄÉÊÖÆÈ†ÜÂ∫èÂíåÈùûÈ†ÜÂ∫èÊèêÁ§∫ÊñπÊ≥ï‰æÜÊ™¢Ê∏¨‰∫∫È°ûÁöÑË´∑Âà∫„ÄÇÈÄöÈÅéÂ∞çÂõõÂÄãÂü∫Ê∫ñÊï∏ÊìöÈõÜÈÄ≤Ë°åÂÖ®Èù¢ÁöÑÂØ¶Ë≠âÊØîËºÉÔºåÊàëÂÄëË°®ÊòéÊâÄÊèêÂá∫ÁöÑÂõõÁ®ÆÊèêÁ§∫ÊñπÊ≥ï‰ª•Áõ∏Áï∂Â§ßÁöÑÂπÖÂ∫¶ÂÑ™ÊñºÊ®ôÊ∫ñ IO ÊèêÁ§∫„ÄÅCoT Âíå ToTÔºå‰∏¶‰∏îÈùûÈ†ÜÂ∫èÊèêÁ§∫ÈÄöÂ∏∏ÂÑ™ÊñºÈ†ÜÂ∫èÊèêÁ§∫„ÄÇ

##### **Subgraph-Aware Training of Text-based Methods for Knowledge Graph Completion**
2407.12703v3 by Youmin Ko, Hyemin Yang, Taeuk Kim, Hyunjoon Kim

Fine-tuning pre-trained language models (PLMs) has recently shown a potential
to improve knowledge graph completion (KGC). However, most PLM-based methods
encode only textual information, neglecting various topological structures of
knowledge graphs (KGs). In this paper, we empirically validate the significant
relations between the structural properties of KGs and the performance of the
PLM-based methods. To leverage the structural knowledge, we propose a
Subgraph-Aware Training framework for KGC (SATKGC) that combines (i)
subgraph-aware mini-batching to encourage hard negative sampling, and (ii) a
new contrastive learning method to focus more on harder entities and harder
negative triples in terms of the structural properties. To the best of our
knowledge, this is the first study to comprehensively incorporate the
structural inductive bias of the subgraphs into fine-tuning PLMs. Extensive
experiments on four KGC benchmarks demonstrate the superiority of SATKGC. Our
code is available.

ÊëòË¶ÅÔºöÂæÆË™øÈ†êË®ìÁ∑¥Ë™ûË®ÄÊ®°Âûã (PLM) Ëøë‰æÜÈ°ØÁ§∫Âá∫ÊîπÂñÑÁü•Ë≠òÂúñË≠úÂÆåÊàêÂäüËÉΩ (KGC) ÁöÑÊΩõÂäõ„ÄÇÁÑ∂ËÄåÔºåÂ§ßÂ§öÊï∏Âü∫Êñº PLM ÁöÑÊñπÊ≥ïÂÉÖÁ∑®Á¢ºÊñáÂ≠óË≥áË®äÔºåÂøΩÁï•‰∫ÜÁü•Ë≠òÂúñË≠ú (KG) ÁöÑÂêÑÁ®ÆÊãìÊí≤ÁµêÊßã„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÈÄèÈÅéÁ∂ìÈ©óÈ©óË≠â‰∫Ü KG ÁöÑÁµêÊßãÂ±¨ÊÄßËàáÂü∫Êñº PLM ÁöÑÊñπÊ≥ïÊïàËÉΩ‰πãÈñìÁöÑÈáçË¶ÅÈóú‰øÇ„ÄÇÁÇ∫‰∫ÜÂà©Áî®ÁµêÊßãÁü•Ë≠òÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÁî®Êñº KGC ÁöÑÂ≠êÂúñÊÑüÁü•Ë®ìÁ∑¥Êû∂Êßã (SATKGC)ÔºåÂÆÉÁµêÂêà‰∫ÜÔºö(i) Â≠êÂúñÊÑüÁü•Â∞èÊâπÊ¨°ËôïÁêÜ‰ª•ÈºìÂãµÂõ∞Èõ£Ë≤†Èù¢ÊäΩÊ®£Ôºå‰ª•Âèä (ii) ‰∏ÄÁ®ÆÊñ∞ÁöÑÂ∞çÊØîÂ≠∏ÁøíÊñπÊ≥ïÔºåÂú®ÁµêÊßãÂ±¨ÊÄßÊñπÈù¢Êõ¥Â∞àÊ≥®ÊñºÊõ¥Âõ∞Èõ£ÁöÑÂØ¶È´îÂíåÊõ¥Âõ∞Èõ£ÁöÑË≤†‰∏âÂÖÉÁµÑ„ÄÇÊìöÊàëÂÄëÊâÄÁü•ÔºåÈÄôÊòØÁ¨¨‰∏ÄÂÄãÂ∞áÂ≠êÂúñÁöÑÁµêÊßãÊ≠∏Á¥çÂÅèË™§ÂÖ®Èù¢Á¥çÂÖ• PLM ÂæÆË™øÁöÑÁ†îÁ©∂„ÄÇÂú®ÂõõÂÄã KGC Âü∫Ê∫ñ‰∏äÁöÑÂª£Ê≥õÂØ¶È©óË≠âÊòé‰∫Ü SATKGC ÁöÑÂÑ™Ë∂äÊÄß„ÄÇÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÁèæÂ∑≤ÂÖ¨Èñã„ÄÇ

##### **Abstraction Alignment: Comparing Model and Human Conceptual Relationships**
2407.12543v1 by Angie Boggust, Hyemin Bang, Hendrik Strobelt, Arvind Satyanarayan

Abstraction -- the process of generalizing specific examples into broad
reusable patterns -- is central to how people efficiently process and store
information and apply their knowledge to new data. Promisingly, research has
shown that ML models learn representations that span levels of abstraction,
from specific concepts like "bolo tie" and "car tire" to more general concepts
like "CEO" and "model". However, existing techniques analyze these
representations in isolation, treating learned concepts as independent
artifacts rather than an interconnected web of abstraction. As a result,
although we can identify the concepts a model uses to produce its output, it is
difficult to assess if it has learned a human-aligned abstraction of the
concepts that will generalize to new data. To address this gap, we introduce
abstraction alignment, a methodology to measure the agreement between a model's
learned abstraction and the expected human abstraction. We quantify abstraction
alignment by comparing model outputs against a human abstraction graph, such as
linguistic relationships or medical disease hierarchies. In evaluation tasks
interpreting image models, benchmarking language models, and analyzing medical
datasets, abstraction alignment provides a deeper understanding of model
behavior and dataset content, differentiating errors based on their agreement
with human knowledge, expanding the verbosity of current model quality metrics,
and revealing ways to improve existing human abstractions.

ÊëòË¶ÅÔºöÊäΩË±°Âåñ‚Äî‚ÄîÂ∞áÁâπÂÆöÁØÑ‰æãÊ¶ÇÊã¨ÁÇ∫Âª£Ê≥õÂèØÈáçË§á‰ΩøÁî®ÁöÑÊ®°ÂºèÁöÑÈÅéÁ®ã‚Äî‚ÄîÊòØ‰∫∫ÂÄëÊúâÊïàËôïÁêÜÂíåÂÑ≤Â≠òË≥áË®äÔºå‰∏¶Â∞áÂÖ∂Áü•Ë≠òÊáâÁî®ÊñºÊñ∞Ë≥áÊñôÁöÑÊ†∏ÂøÉ„ÄÇÊúâÂ∏åÊúõÁöÑÊòØÔºåÁ†îÁ©∂È°ØÁ§∫ ML Ê®°ÂûãÂ≠∏ÁøíË∑®Ë∂äÊäΩË±°Â±§Á¥öÁöÑË°®ÂæµÔºåÂæû„ÄåÁ¥∞È†òÂ∏∂„ÄçÂíå„ÄåÊ±ΩËªäËº™ËÉé„ÄçÁ≠âÂÖ∑È´îÊ¶ÇÂøµÂà∞„ÄåÂü∑Ë°åÈï∑„ÄçÂíå„ÄåÊ®°Âûã„ÄçÁ≠âÊõ¥‰∏ÄËà¨ÁöÑÊ¶ÇÂøµ„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÁöÑÊäÄË°ìÂ≠§Á´ãÂú∞ÂàÜÊûêÈÄô‰∫õË°®ÂæµÔºåÂ∞áÂ≠∏ÁøíÂà∞ÁöÑÊ¶ÇÂøµË¶ñÁÇ∫Áç®Á´ãÁöÑÁî¢Áâ©ÔºåËÄå‰∏çÊòØÊäΩË±°ÁöÑÁõ∏‰∫íÈÄ£ÁµêÁ∂≤Ë∑Ø„ÄÇÂõ†Ê≠§ÔºåÂÑòÁÆ°ÊàëÂÄëÂèØ‰ª•Ë≠òÂà•Ê®°ÂûãÁî®‰æÜÁî¢ÁîüÂÖ∂Ëº∏Âá∫ÁöÑÊ¶ÇÂøµÔºå‰ΩÜÂæàÈõ£Ë©ï‰º∞ÂÆÉÊòØÂê¶Â≠∏ÁøíÂà∞Ê¶ÇÂøµÁöÑ‰∫∫È°ûÂ∞çÈΩäÊäΩË±°ÔºåÈÄô‰∫õÊ¶ÇÂøµÂ∞áÊ¶ÇÊã¨Âà∞Êñ∞ÁöÑË≥áÊñô„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂ∑ÆË∑ùÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜÊäΩË±°Â∞çÈΩäÔºå‰∏ÄÁ®ÆË°°ÈáèÊ®°ÂûãÂ≠∏ÁøíÁöÑÊäΩË±°ËàáÈ†êÊúüÁöÑÊäΩË±°‰πãÈñì‰∏ÄËá¥ÊÄßÁöÑÊñπÊ≥ï„ÄÇÊàëÂÄëÈÄèÈÅéÂ∞áÊ®°ÂûãËº∏Âá∫Ëàá‰∫∫È°ûÊäΩË±°ÂúñÂΩ¢Ôºà‰æãÂ¶ÇË™ûË®ÄÈóú‰øÇÊàñÈÜ´ÁôÇÁñæÁóÖÂ±§Á¥öÁµêÊßãÔºâÈÄ≤Ë°åÊØîËºÉ‰æÜÈáèÂåñÊäΩË±°Â∞çÈΩä„ÄÇÂú®Ëß£ÈáãÂΩ±ÂÉèÊ®°Âûã„ÄÅÂü∫Ê∫ñË™ûË®ÄÊ®°ÂûãÂíåÂàÜÊûêÈÜ´ÁôÇË≥áÊñôÈõÜÁöÑË©ï‰º∞‰ªªÂãô‰∏≠ÔºåÊäΩË±°Â∞çÈΩäÊèê‰æõ‰∫ÜÂ∞çÊ®°ÂûãË°åÁÇ∫ÂíåË≥áÊñôÈõÜÂÖßÂÆπÊõ¥Ê∑±ÂÖ•ÁöÑÁêÜËß£ÔºåÊ†πÊìöËàá‰∫∫È°ûÁü•Ë≠òÁöÑ‰∏ÄËá¥ÊÄßÂçÄÂàÜÈåØË™§ÔºåÊì¥Â±ïÁï∂ÂâçÊ®°ÂûãÂìÅË≥™ÊåáÊ®ôÁöÑË©≥Á¥∞Á®ãÂ∫¶Ôºå‰∏¶Êè≠Á§∫ÊîπÂñÑÁèæÊúâ‰∫∫È°ûÊäΩË±°ÁöÑÊñπÊ≥ï„ÄÇ

##### **Struct-X: Enhancing Large Language Models Reasoning with Structured Data**
2407.12522v1 by Xiaoyu Tan, Haoyu Wang, Xihe Qiu, Yuan Cheng, Yinghui Xu, Wei Chu, Yuan Qi

Structured data, rich in logical and relational information, has the
potential to enhance the reasoning abilities of large language models (LLMs).
Still, its integration poses a challenge due to the risk of overwhelming LLMs
with excessive tokens and irrelevant context information. To address this, we
propose Struct-X, a novel framework that operates through five key phases:
``read-model-fill-reflect-reason'' efficiently enabling LLMs to utilize
structured data. It begins by encoding structured data into a topological space
using graph embeddings, followed by filling in missing entity information with
knowledge retrieval modules, and filtering out irrelevant tokens via a
self-supervised module. The final phase involves constructing a topological
network with selected tokens to further reduce the total token length for more
effective LLM inference. Additionally, Struct-X includes an Auxiliary Module
trained to generate prompts, aiding LLMs in analyzing structured data.
Extensive experiments on benchmarks, including the knowledge graph
question-answer task and the long document reading comprehension task, show
that Struct-X notably improves LLM reasoning, demonstrating the effectiveness
of structured data augmentation in improving LLM inference with complex input
context.

ÊëòË¶ÅÔºöÁµêÊßãÂåñË≥áÊñôÂØåÂê´ÈÇèËºØÂíåÈóú‰øÇË≥áË®äÔºåÊúâÊΩõÂäõÂ¢ûÂº∑Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊé®ÁêÜËÉΩÂäõ„ÄÇÂÑòÁÆ°Â¶ÇÊ≠§ÔºåÁî±ÊñºÈÅéÂ§öÁ¨¶ËôüÂíåÁÑ°ÈóúËÑàÁµ°Ë≥áË®äÂèØËÉΩÊúÉËÆì LLM ‰∏çÂ†™Ë≤†Ëç∑ÔºåÂõ†Ê≠§Êï¥ÂêàÊ≠§È°ûË≥áÊñôÊßãÊàê‰∫Ü‰∏ÄÈ†ÖÊåëÊà∞„ÄÇÁÇ∫‰∫ÜËß£Ê±∫Ê≠§ÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫ Struct-XÔºåÈÄôÊòØ‰∏ÄÂÄãÈÄèÈÅé‰∫îÂÄãÈóúÈçµÈöéÊÆµÈÅã‰ΩúÁöÑÊñ∞Á©éÊû∂ÊßãÔºö``ËÆÄÂèñ-Âª∫Ê®°-Â°´Ë£ú-ÂèçÊÄù-Êé®ÁêÜ''ÔºåÊúâÊïàÂú∞ËÆì LLM ËÉΩÂ§†Âà©Áî®ÁµêÊßãÂåñË≥áÊñô„ÄÇÂÆÉÈ¶ñÂÖà‰ΩøÁî®ÂúñÂΩ¢ÂµåÂÖ•Â∞áÁµêÊßãÂåñË≥áÊñôÁ∑®Á¢ºÂà∞ÊãìÊí≤Á©∫Èñì‰∏≠ÔºåÊé•ËëóÂà©Áî®Áü•Ë≠òÊì∑ÂèñÊ®°ÁµÑÂ°´Ë£úÈÅ∫Â§±ÁöÑÂØ¶È´îË≥áË®äÔºå‰∏¶ÈÄèÈÅéËá™ÊàëÁõ£Áù£Ê®°ÁµÑÁØ©ÈÅ∏Âá∫ÁÑ°ÈóúÁ¨¶Ëôü„ÄÇÊúÄÂæå‰∏ÄÂÄãÈöéÊÆµÊ∂âÂèäÂª∫Êßã‰∏ÄÂÄãÊãìÊí≤Á∂≤Ë∑ØÔºåÂÖ∂‰∏≠ÂåÖÂê´ÈÅ∏ÂÆöÁöÑÁ¨¶ËôüÔºå‰ª•ÈÄ≤‰∏ÄÊ≠•Ê∏õÂ∞ëÁ∏ΩÁ¨¶ËôüÈï∑Â∫¶Ôºå‰ª•‰æøÊõ¥ÊúâÊïàÂú∞ÈÄ≤Ë°å LLM Êé®Ë´ñ„ÄÇÊ≠§Â§ñÔºåStruct-X ÈÇÑÂåÖÊã¨‰∏ÄÂÄãËºîÂä©Ê®°ÁµÑÔºåÁ∂ìÈÅéË®ìÁ∑¥ÂèØ‰ª•Áî¢ÁîüÊèêÁ§∫ÔºåÂçîÂä© LLM ÂàÜÊûêÁµêÊßãÂåñË≥áÊñô„ÄÇÂú®Âü∫Ê∫ñ‰∏äÁöÑÂ§ßÈáèÂØ¶È©óÔºåÂåÖÊã¨Áü•Ë≠òÂúñË≠úÂïèÁ≠î‰ªªÂãôÂíåÈï∑ÁØáÊñá‰ª∂Èñ±ËÆÄÁêÜËß£‰ªªÂãôÔºåÈ°ØÁ§∫ Struct-X ÊòéÈ°ØÊîπÂñÑ‰∫Ü LLM Êé®ÁêÜÔºåË≠âÊòé‰∫ÜÁµêÊßãÂåñË≥áÊñôÊì¥ÂÖÖÂú®ÊîπÂñÑ LLM Êé®Ë´ñÊôÇÁöÑÊúâÊïàÊÄßÔºåÁâπÂà•ÊòØÂú®Ëº∏ÂÖ•ËÑàÁµ°Ë§áÈõúÁöÑÊÉÖÊ≥Å‰∏ã„ÄÇ

##### **Explainable Biomedical Hypothesis Generation via Retrieval Augmented Generation enabled Large Language Models**
2407.12888v1 by Alexander R. Pelletier, Joseph Ramirez, Irsyad Adam, Simha Sankar, Yu Yan, Ding Wang, Dylan Steinecke, Wei Wang, Peipei Ping

The vast amount of biomedical information available today presents a
significant challenge for investigators seeking to digest, process, and
understand these findings effectively. Large Language Models (LLMs) have
emerged as powerful tools to navigate this complex and challenging data
landscape. However, LLMs may lead to hallucinatory responses, making Retrieval
Augmented Generation (RAG) crucial for achieving accurate information. In this
protocol, we present RUGGED (Retrieval Under Graph-Guided Explainable disease
Distinction), a comprehensive workflow designed to support investigators with
knowledge integration and hypothesis generation, identifying validated paths
forward. Relevant biomedical information from publications and knowledge bases
are reviewed, integrated, and extracted via text-mining association analysis
and explainable graph prediction models on disease nodes, forecasting potential
links among drugs and diseases. These analyses, along with biomedical texts,
are integrated into a framework that facilitates user-directed mechanism
elucidation as well as hypothesis exploration through RAG-enabled LLMs. A
clinical use-case demonstrates RUGGED's ability to evaluate and recommend
therapeutics for Arrhythmogenic Cardiomyopathy (ACM) and Dilated Cardiomyopathy
(DCM), analyzing prescribed drugs for molecular interactions and unexplored
uses. The platform minimizes LLM hallucinations, offers actionable insights,
and improves the investigation of novel therapeutics.

ÊëòË¶ÅÔºö<paragraph>Áèæ‰ªäÂ§ßÈáèÁöÑÁîüÁâ©ÈÜ´Â≠∏Ë≥áË®äÂ∞çË©¶ÂúñÊúâÊïàÊ∂àÂåñ„ÄÅËôïÁêÜÂíåÁêÜËß£ÈÄô‰∫õÁôºÁèæÁöÑÁ†îÁ©∂‰∫∫Âì°ÊßãÊàêÈáçÂ§ßÊåëÊà∞„ÄÇÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤ÊàêÁÇ∫Âú®ÈÄôÂÄãË§áÈõú‰∏îÂÖ∑ÊåëÊà∞ÊÄßÁöÑË≥áÊñôÁí∞Â¢É‰∏≠Â∞éËà™ÁöÑÂº∑Â§ßÂ∑•ÂÖ∑„ÄÇÁÑ∂ËÄåÔºåLLM ÂèØËÉΩÊúÉÂ∞éËá¥ÂπªË¶∫ÂèçÊáâÔºåÈÄô‰ΩøÂæóÊ™¢Á¥¢Êì¥Â¢ûÁîüÊàê (RAG) Â∞çÊñºÁç≤ÂæóÊ∫ñÁ¢∫Ë≥áË®äËá≥ÈóúÈáçË¶Å„ÄÇÂú®ÈÄôÂÄãÂçîÂÆö‰∏≠ÔºåÊàëÂÄëÊèêÂá∫ RUGGEDÔºàÂúñÂΩ¢Â∞éÂºïÂèØËß£ÈáãÁñæÁóÖÂçÄÂàÜÁöÑÊ™¢Á¥¢ÔºâÔºåÈÄôÊòØ‰∏ÄÂÄãÂÖ®Èù¢ÁöÑÂ∑•‰ΩúÊµÅÁ®ãÔºåÊó®Âú®ÊîØÊè¥Á†îÁ©∂‰∫∫Âì°ÈÄ≤Ë°åÁü•Ë≠òÊï¥ÂêàÂíåÂÅáË®≠Áî¢ÁîüÔºåÊâæÂá∫Á∂ìÈÅéÈ©óË≠âÁöÑÈÄ≤Â±ïË∑ØÂæë„ÄÇ‰æÜËá™Âá∫ÁâàÁâ©ÂíåÁü•Ë≠òÂ∫´ÁöÑÁõ∏ÈóúÁîüÁâ©ÈÜ´Â≠∏Ë≥áË®äÊúÉÈÄèÈÅéÊñáÊú¨Êé¢ÂãòÈóúËÅØÂàÜÊûêÂíåÁñæÁóÖÁØÄÈªûÁöÑÂèØËß£ÈáãÂúñÂΩ¢È†êÊ∏¨Ê®°ÂûãÈÄ≤Ë°åÊ™¢Èñ±„ÄÅÊï¥ÂêàÂíåËêÉÂèñÔºåÈ†êÊ∏¨Ëó•Áâ©ÂíåÁñæÁóÖ‰πãÈñìÁöÑÊΩõÂú®ÈóúËÅØ„ÄÇÈÄô‰∫õÂàÜÊûêÈÄ£ÂêåÁîüÁâ©ÈÜ´Â≠∏ÊñáÊú¨ÊúÉÊï¥ÂêàÂà∞‰∏ÄÂÄãÊû∂Êßã‰∏≠ÔºåË©≤Êû∂Êßã‰øÉÈÄ≤‰ΩøÁî®ËÄÖÂ∞éÂêëÁöÑÊ©üÂà∂Èó°ÊòéÔºå‰ª•ÂèäÈÄèÈÅé RAG ÂïüÁî®ÁöÑ LLM ÈÄ≤Ë°åÂÅáË®≠Êé¢Ë®é„ÄÇ‰∏ÄÂÄãËá®Â∫ä‰ΩøÁî®Ê°à‰æãÂ±ïÁ§∫‰∫Ü RUGGED Ë©ï‰º∞ÂíåÊé®Ëñ¶Áî®ÊñºÂøÉÂæãÂ§±Â∏∏ÊÄßÂøÉËÇåÁóÖËÆä (ACM) ÂíåÊì¥ÂºµÂûãÂøÉËÇåÁóÖËÆä (DCM) ÁöÑÊ≤ªÁôÇÊñπÊ≥ïÁöÑËÉΩÂäõÔºåÂàÜÊûêËôïÊñπËó•Áâ©ÁöÑÂàÜÂ≠ê‰∫§‰∫í‰ΩúÁî®ÂíåÊú™Êé¢Á¥¢ÁöÑÁî®ÈÄî„ÄÇÈÄôÂÄãÂπ≥Âè∞Â∞á LLM ÂπªË¶∫ÈôçÂà∞ÊúÄ‰ΩéÔºåÊèê‰æõÂèØÊìç‰ΩúÁöÑË¶ãËß£Ôºå‰∏¶ÊîπÂñÑÊñ∞Ê≤ªÁôÇÊñπÊ≥ïÁöÑÁ†îÁ©∂„ÄÇ</paragraph>

##### **A Comprehensive Evaluation of Large Language Models on Temporal Event Forecasting**
2407.11638v1 by He Chang, Chenchen Ye, Zhulin Tao, Jie Wu, Zhengmao Yang, Yunshan Ma, Xianglin Huang, Tat-Seng Chua

Recently, Large Language Models (LLMs) have demonstrated great potential in
various data mining tasks, such as knowledge question answering, mathematical
reasoning, and commonsense reasoning. However, the reasoning capability of LLMs
on temporal event forecasting has been under-explored. To systematically
investigate their abilities in temporal event forecasting, we conduct a
comprehensive evaluation of LLM-based methods for temporal event forecasting.
Due to the lack of a high-quality dataset that involves both graph and textual
data, we first construct a benchmark dataset, named MidEast-TE-mini. Based on
this dataset, we design a series of baseline methods, characterized by various
input formats and retrieval augmented generation(RAG) modules. From extensive
experiments, we find that directly integrating raw texts into the input of LLMs
does not enhance zero-shot extrapolation performance. In contrast,
incorporating raw texts in specific complex events and fine-tuning LLMs
significantly improves performance. Moreover, enhanced with retrieval modules,
LLM can effectively capture temporal relational patterns hidden in historical
events. Meanwhile, issues such as popularity bias and the long-tail problem
still persist in LLMs, particularly in the RAG-based method. These findings not
only deepen our understanding of LLM-based event forecasting methods but also
highlight several promising research directions.We consider that this
comprehensive evaluation, along with the identified research opportunities,
will significantly contribute to future research on temporal event forecasting
through LLMs.

ÊëòË¶ÅÔºöËøëÊúüÔºåÂ§ßÂûãËØ≠Ë®ÄÊ®°Âûã (LLM) Âú®ÂêÑÁßçËµÑÊñôÊé¢Âãò‰ªªÂä°‰∏≠Â±ïÁé∞Âá∫ÊûÅÂ§ßÁöÑÊΩúÂäõÔºå‰æãÂ¶ÇÁü•ËØÜÈóÆÁ≠î„ÄÅÊï∞Â≠¶Êé®ÁêÜÂíåÂ∏∏ËØÜÊé®ÁêÜ„ÄÇÁÑ∂ËÄåÔºåLLM Âú®Êó∂Èó¥‰∫ã‰ª∂È¢ÑÊµãÊñπÈù¢ÁöÑÊé®ÁêÜËÉΩÂäõÂ∞öÊú™Ë¢´ÂÖÖÂàÜÊé¢Á¥¢„ÄÇ‰∏∫‰∫ÜÁ≥ªÁªüÊÄßÂú∞Ë∞ÉÊü•ÂÖ∂Âú®Êó∂Èó¥‰∫ã‰ª∂È¢ÑÊµãÊñπÈù¢ÁöÑËÉΩÂäõÔºåÊàë‰ª¨ÂØπÂü∫‰∫é LLM ÁöÑÊó∂Èó¥‰∫ã‰ª∂È¢ÑÊµãÊñπÊ≥ïËøõË°å‰∫ÜÂÖ®Èù¢ÁöÑËØÑ‰º∞„ÄÇÁî±‰∫éÁº∫‰πèÂêåÊó∂ÂåÖÂê´ÂõæË°®ÂíåÊñáÊú¨ËµÑÊñôÁöÑÈ´òÂìÅË¥®Êï∞ÊçÆÈõÜÔºåÊàë‰ª¨È¶ñÂÖàÊûÑÂª∫‰∫Ü‰∏Ä‰∏™Âêç‰∏∫ MidEast-TE-mini ÁöÑÂü∫ÂáÜÊï∞ÊçÆÈõÜ„ÄÇÂü∫‰∫éÊ≠§Êï∞ÊçÆÈõÜÔºåÊàë‰ª¨ËÆæËÆ°‰∫Ü‰∏ÄÁ≥ªÂàóÂü∫Á∫øÊñπÊ≥ïÔºåÂÖ∂ÁâπÁÇπÊòØÂêÑÁßçËæìÂÖ•Ê†ºÂºèÂíåÊ£ÄÁ¥¢Â¢ûÂº∫ÁîüÊàê (RAG) Ê®°Âùó„ÄÇ‰ªéÂπøÊ≥õÁöÑÂÆûÈ™å‰∏≠ÔºåÊàë‰ª¨ÂèëÁé∞Áõ¥Êé•Â∞ÜÂéüÂßãÊñáÊú¨Êï¥ÂêàÂà∞ LLM ÁöÑËæìÂÖ•‰∏≠Âπ∂‰∏ç‰ºöÂ¢ûÂº∫Èõ∂Ê¨°Â≠¶‰π†Â§ñÊé®ÊÄßËÉΩ„ÄÇÁõ∏ÊØî‰πã‰∏ãÔºåÂú®ÁâπÂÆöÂ§çÊùÇ‰∫ã‰ª∂‰∏≠Á∫≥ÂÖ•ÂéüÂßãÊñáÊú¨Âπ∂ÂæÆË∞É LLM ‰ºöÊòæËëóÊèêÈ´òÊÄßËÉΩ„ÄÇÊ≠§Â§ñÔºåÈÄöËøáÊ£ÄÁ¥¢Ê®°ÂùóÁöÑÂ¢ûÂº∫ÔºåLLM ÂèØ‰ª•ÊúâÊïàÂú∞ÊçïÊçâÈöêËóèÂú®ÂéÜÂè≤‰∫ã‰ª∂‰∏≠ÁöÑÊó∂Èó¥ÂÖ≥Á≥ªÊ®°Âºè„ÄÇÂêåÊó∂ÔºåËØ∏Â¶ÇÊµÅË°åÂ∫¶ÂÅèÂ∑ÆÂíåÈïøÂ∞æÈóÆÈ¢òÁ≠âÈóÆÈ¢ò‰ªçÁÑ∂Â≠òÂú®‰∫é LLM ‰∏≠ÔºåÂ∞§ÂÖ∂ÊòØÂú®Âü∫‰∫é RAG ÁöÑÊñπÊ≥ï‰∏≠„ÄÇËøô‰∫õÂèëÁé∞‰∏ç‰ªÖÂä†Ê∑±‰∫ÜÊàë‰ª¨ÂØπÂü∫‰∫é LLM ÁöÑ‰∫ã‰ª∂È¢ÑÊµãÊñπÊ≥ïÁöÑÁêÜËß£ÔºåËøòÁ™ÅÂá∫‰∫ÜÂá†‰∏™ÊúâÂâçÊôØÁöÑÁ†îÁ©∂ÊñπÂêë„ÄÇÊàë‰ª¨ËÆ§‰∏∫ÔºåËøôÈ°πÂÖ®Èù¢ÁöÑËØÑ‰º∞ÔºåËøûÂêåÂ∑≤Á°ÆÂÆöÁöÑÁ†îÁ©∂Êú∫‰ºöÔºåÂ∞ÜÊûÅÂ§ßÂú∞‰øÉËøõÈÄöËøá LLM ËøõË°åÊó∂Èó¥‰∫ã‰ª∂È¢ÑÊµãÁöÑÊú™Êù•Á†îÁ©∂„ÄÇ

##### **Learning on Graphs with Large Language Models(LLMs): A Deep Dive into Model Robustness**
2407.12068v2 by Kai Guo, Zewen Liu, Zhikai Chen, Hongzhi Wen, Wei Jin, Jiliang Tang, Yi Chang

Large Language Models (LLMs) have demonstrated remarkable performance across
various natural language processing tasks. Recently, several LLMs-based
pipelines have been developed to enhance learning on graphs with text
attributes, showcasing promising performance. However, graphs are well-known to
be susceptible to adversarial attacks and it remains unclear whether LLMs
exhibit robustness in learning on graphs. To address this gap, our work aims to
explore the potential of LLMs in the context of adversarial attacks on graphs.
Specifically, we investigate the robustness against graph structural and
textual perturbations in terms of two dimensions: LLMs-as-Enhancers and
LLMs-as-Predictors. Through extensive experiments, we find that, compared to
shallow models, both LLMs-as-Enhancers and LLMs-as-Predictors offer superior
robustness against structural and textual attacks.Based on these findings, we
carried out additional analyses to investigate the underlying causes.
Furthermore, we have made our benchmark library openly available to facilitate
quick and fair evaluations, and to encourage ongoing innovative research in
this field.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®ÂêÑÁ®ÆËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ‰ªªÂãô‰∏≠ÈÉΩÂ±ïÁèæÂá∫ÂçìË∂äÁöÑÊïàËÉΩ„ÄÇÊúÄËøëÔºåÂ∑≤ÈñãÁôºÂá∫Â§öÂÄãÂü∫Êñº LLM ÁöÑÁÆ°ÈÅìÔºå‰ª•Â¢ûÂº∑ÂÖ∑ÊúâÊñáÂ≠óÂ±¨ÊÄßÁöÑÂúñÂΩ¢Â≠∏ÁøíÔºåÂ±ïÁèæÂá∫‰ª§‰∫∫ÊªøÊÑèÁöÑÊïàËÉΩ„ÄÇÁÑ∂ËÄåÔºåÂúñÂΩ¢ÂÆπÊòìÂèóÂà∞Â∞çÊäóÊÄßÊîªÊìäÔºåËÄå LLM Âú®ÂúñÂΩ¢Â≠∏Áøí‰∏≠ÊòØÂê¶Â±ïÁèæÂá∫Á©©ÂÅ•ÊÄß‰ªç‰∏çÊ∏ÖÊ•ö„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂ∑ÆË∑ùÔºåÊàëÂÄëÁöÑÁ†îÁ©∂Êó®Âú®Êé¢Ë®é LLM Âú®ÂúñÂΩ¢Â∞çÊäóÊÄßÊîªÊìä‰∏≠ÁöÑÊΩõÂäõ„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÈáùÂ∞çÂÖ©ÂÄãÈù¢ÂêëÊé¢Ë®éÂÖ∂Â∞çÂúñÂΩ¢ÁµêÊßãÂíåÊñáÂ≠óÊìæÂãïÁöÑÁ©©ÂÅ•ÊÄßÔºöLLM ‰ΩúÁÇ∫Â¢ûÂº∑Âô®Âíå LLM ‰ΩúÁÇ∫È†êÊ∏¨Âô®„ÄÇÈÄèÈÅéÂª£Ê≥õÁöÑÂØ¶È©óÔºåÊàëÂÄëÁôºÁèæÔºåËàáÊ∑∫Â±§Ê®°ÂûãÁõ∏ÊØîÔºåLLM ‰ΩúÁÇ∫Â¢ûÂº∑Âô®Âíå LLM ‰ΩúÁÇ∫È†êÊ∏¨Âô®Âú®ÁµêÊßãÊÄßÂíåÊñáÂ≠óÊîªÊìä‰∏≠ÈÉΩÊèê‰æõÂÑ™Áï∞ÁöÑÁ©©ÂÅ•ÊÄß„ÄÇÊ†πÊìöÈÄô‰∫õÁôºÁèæÔºåÊàëÂÄëÈÄ≤Ë°å‰∫ÜÈ°çÂ§ñÁöÑÂàÜÊûê‰æÜÊé¢Ë®éÂÖ∂Ê†πÊú¨ÂéüÂõ†„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂ∑≤ÂÖ¨ÈñãÊàëÂÄëÁöÑÂü∫Ê∫ñÂ∫´Ôºå‰ª•Âà©Âø´ÈÄü‰∏îÂÖ¨Âπ≥ÁöÑË©ï‰º∞Ôºå‰∏¶ÈºìÂãµÊåÅÁ∫åÈÄ≤Ë°åÈÄôÊñπÈù¢ÁöÑÂâµÊñ∞Á†îÁ©∂„ÄÇ

##### **CIC-BART-SSA: Controllable Image Captioning with Structured Semantic Augmentation**
2407.11393v2 by Kalliopi Basioti, Mohamed A. Abdelsalam, Federico Fancellu, Vladimir Pavlovic, Afsaneh Fazly

Controllable Image Captioning (CIC) aims at generating natural language
descriptions for an image, conditioned on information provided by end users,
e.g., regions, entities or events of interest. However, available
image-language datasets mainly contain captions that describe the entirety of
an image, making them ineffective for training CIC models that can potentially
attend to any subset of regions or relationships. To tackle this challenge, we
propose a novel, fully automatic method to sample additional focused and
visually grounded captions using a unified structured semantic representation
built on top of the existing set of captions associated with an image. We
leverage Abstract Meaning Representation (AMR), a cross-lingual graph-based
semantic formalism, to encode all possible spatio-semantic relations between
entities, beyond the typical spatial-relations-only focus of current methods.
We use this Structured Semantic Augmentation (SSA) framework to augment
existing image-caption datasets with the grounded controlled captions,
increasing their spatial and semantic diversity and focal coverage. We then
develop a new model, CIC-BART-SSA, specifically tailored for the CIC task, that
sources its control signals from SSA-diversified datasets. We empirically show
that, compared to SOTA CIC models, CIC-BART-SSA generates captions that are
superior in diversity and text quality, are competitive in controllability,
and, importantly, minimize the gap between broad and highly focused controlled
captioning performance by efficiently generalizing to the challenging highly
focused scenarios. Code is available at
https://github.com/SamsungLabs/CIC-BART-SSA.

ÊëòË¶ÅÔºöÂèØÊéßÂõæÂÉèÊ†áÊ≥® (CIC) Êó®Âú®ÁîüÊàêËá™ÁÑ∂ËØ≠Ë®ÄÊèèËø∞‰ª•ÊèèËø∞ÂõæÂÉèÔºåÊù°‰ª∂ÊòØÊ†πÊçÆÊúÄÁªàÁî®Êà∑Êèê‰æõÁöÑËµÑËÆØÔºå‰æãÂ¶ÇÂå∫Âüü„ÄÅÂÆû‰ΩìÊàñÊÑüÂÖ¥Ë∂£ÁöÑ‰∫ã‰ª∂„ÄÇÁÑ∂ËÄåÔºåÁé∞ÊúâÁöÑÂõæÂÉèËØ≠Ë®ÄÊï∞ÊçÆÈõÜ‰∏ªË¶ÅÂåÖÂê´ÊèèËø∞Êï¥‰∏™ÂõæÂÉèÁöÑÊ†áÊ≥®Ôºå‰ΩøÂÖ∂Êó†Ê≥ïÊúâÊïàËÆ≠ÁªÉ CIC Ê®°ÂûãÔºåËÄåËøô‰∫õÊ®°ÂûãÊúâÂèØËÉΩÂÖ≥Ê≥®‰ªª‰ΩïÂå∫ÂüüÊàñÂÖ≥Á≥ªÁöÑÂ≠êÈõÜ„ÄÇ‰∏∫‰∫ÜÂ∫îÂØπËøô‰∏ÄÊåëÊàòÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞È¢ñÁöÑ„ÄÅÂÖ®Ëá™Âä®ÁöÑÊñπÊ≥ïÔºå‰ΩøÁî®Âª∫Á´ãÂú®‰∏éÂõæÂÉèÂÖ≥ËÅîÁöÑÁé∞ÊúâÊ†áÊ≥®ÈõÜ‰πã‰∏äÁöÑÁªü‰∏ÄÁªìÊûÑÂåñËØ≠‰πâË°®Á§∫Êù•ÊäΩÊ†∑ÂÖ∂‰ªñËÅöÁÑ¶‰∏îËßÜËßâÊé•Âú∞ÁöÑÊ†áÊ≥®„ÄÇÊàë‰ª¨Âà©Áî®Ë∑®ËØ≠Ë®ÄÂõæÂºèËØ≠‰πâÂΩ¢ÂºèÂåñÊäΩË±°ÊÑè‰πâË°®Á§∫ (AMR) Êù•ÁºñÁ†ÅÂÆû‰Ωì‰πãÈó¥ÊâÄÊúâÂèØËÉΩÁöÑÁ©∫Èó¥ËØ≠‰πâÂÖ≥Á≥ªÔºåËÄå‰∏ç‰ªÖ‰ªÖÊòØÂΩìÂâçÊñπÊ≥ï‰∏≠‰ªÖÂÖ≥Ê≥®ÁöÑÁ©∫Èó¥ÂÖ≥Á≥ª„ÄÇÊàë‰ª¨‰ΩøÁî®ËøôÁßçÁªìÊûÑÂåñËØ≠‰πâÂ¢ûÂº∫ (SSA) Ê°ÜÊû∂Êù•Â¢ûÂº∫Áé∞ÊúâÁöÑÂõæÂÉèÊ†áÊ≥®Êï∞ÊçÆÈõÜÔºå‰ΩøÂÖ∂Êé•Âú∞‰∏îÂèØÊéßÁöÑÊ†áÊ≥®ÔºåÂ¢ûÂä†ÂÆÉ‰ª¨ÁöÑÁ©∫Èó¥ÂíåËØ≠‰πâÂ§öÊ†∑ÊÄß‰ª•ÂèäÁÑ¶ÁÇπË¶ÜÁõñËåÉÂõ¥„ÄÇÁÑ∂ÂêéÔºåÊàë‰ª¨ÂºÄÂèë‰∫Ü‰∏Ä‰∏™Êñ∞Ê®°Âûã CIC-BART-SSAÔºå‰∏ìÈó®ÈíàÂØπ CIC ‰ªªÂä°ÈáèË∫´ÂÆöÂà∂ÔºåÂÖ∂ÊéßÂà∂‰ø°Âè∑Êù•Ëá™ SSA Â§öÊ†∑ÂåñÁöÑÊï∞ÊçÆÈõÜ„ÄÇÊàë‰ª¨Âá≠ÁªèÈ™åË°®ÊòéÔºå‰∏é SOTA CIC Ê®°ÂûãÁõ∏ÊØîÔºåCIC-BART-SSA ÁîüÊàêÁöÑÊ†áÊ≥®Âú®Â§öÊ†∑ÊÄßÂíåÊñáÊú¨Ë¥®ÈáèÊñπÈù¢Êõ¥ËÉú‰∏ÄÁ≠πÔºåÂú®ÂèØÊéßÊÄßÊñπÈù¢ÂÖ∑ÊúâÁ´û‰∫âÂäõÔºåËÄå‰∏îÈáçË¶ÅÁöÑÊòØÔºåÈÄöËøáÊúâÊïàÂú∞Êé®ÂπøÂà∞ÂÖ∑ÊúâÊåëÊàòÊÄßÁöÑÈ´òÂ∫¶ËÅöÁÑ¶Âú∫ÊôØÔºåÊúÄÂ§ßÈôêÂ∫¶Âú∞Áº©Â∞è‰∫ÜÂπøÊ≥õÂíåÈ´òÂ∫¶ËÅöÁÑ¶ÁöÑÂèóÊéßÊ†áÊ≥®ÊÄßËÉΩ‰πãÈó¥ÁöÑÂ∑ÆË∑ù„ÄÇ‰ª£Á†ÅÂèØ‰ªé https://github.com/SamsungLabs/CIC-BART-SSA Ëé∑Âæó„ÄÇ

##### **Think-on-Graph 2.0: Deep and Interpretable Large Language Model Reasoning with Knowledge Graph-guided Retrieval**
2407.10805v3 by Shengjie Ma, Chengjin Xu, Xuhui Jiang, Muzhi Li, Huaren Qu, Jian Guo

Retrieval-augmented generation (RAG) has significantly advanced large
language models (LLMs) by enabling dynamic information retrieval to mitigate
knowledge gaps and hallucinations in generated content. However, these systems
often falter with complex reasoning and consistency across diverse queries. In
this work, we present Think-on-Graph 2.0, an enhanced RAG framework that aligns
questions with the knowledge graph and uses it as a navigational tool, which
deepens and refines the RAG paradigm for information collection and
integration. The KG-guided navigation fosters deep and long-range associations
to uphold logical consistency and optimize the scope of retrieval for precision
and interoperability. In conjunction, factual consistency can be better ensured
through semantic similarity guided by precise directives. ToG${2.0}$ not only
improves the accuracy and reliability of LLMs' responses but also demonstrates
the potential of hybrid structured knowledge systems to significantly advance
LLM reasoning, aligning it closer to human-like performance. We conducted
extensive experiments on four public datasets to demonstrate the advantages of
our method compared to the baseline.

ÊëòË¶ÅÔºöÊ™¢Á¥¢Â¢ûÂº∑ÁîüÊàê (RAG) Â∑≤Â§ßÂπÖÊèêÂçáÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM)ÔºåËóâÁî±ÂïüÁî®ÂãïÊÖãË≥áË®äÊ™¢Á¥¢‰æÜÊ∏õËºïÁî¢ÁîüÂÖßÂÆπ‰∏≠ÁöÑÁü•Ë≠òÂ∑ÆË∑ùÂíåÂπªË¶∫„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÁ≥ªÁµ±Âú®Ë§áÈõúÊé®ÁêÜÂíå‰∏çÂêåÊü•Ë©¢ÈñìÁöÑ‰∏ÄËá¥ÊÄßÊñπÈù¢Á∂ìÂ∏∏ÊúÉÂá∫ÈåØ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫ Think-on-Graph 2.0Ôºå‰∏ÄÂÄãÂ¢ûÂº∑ÁöÑ RAG Êû∂ÊßãÔºåÂÆÉÊúÉÂ∞áÂïèÈ°åËàáÁü•Ë≠òÂúñË≠úÂ∞çÈΩäÔºå‰∏¶Â∞áÂÖ∂Áî®‰ΩúÂ∞éËà™Â∑•ÂÖ∑ÔºåÈÄôÊúÉÂä†Ê∑±ÂíåÊîπÂñÑ RAG ÂÖ∏ÁØÑ‰ª•ÈÄ≤Ë°åË≥áË®äÊî∂ÈõÜÂíåÊï¥Âêà„ÄÇKG ÂºïÂ∞éÁöÑÂ∞éËà™‰øÉÈÄ≤Ê∑±Â∫¶‰∏îÈï∑Á®ãÈóúËÅØÔºå‰ª•Á∂≠ÊåÅÈÇèËºØ‰∏ÄËá¥ÊÄßÔºå‰∏¶ÊúÄ‰Ω≥ÂåñÊ™¢Á¥¢ÁØÑÂúç‰ª•ÊèêÂçáÁ≤æÊ∫ñÂ∫¶Âíå‰∫íÊìç‰ΩúÊÄß„ÄÇÁµêÂêà‰ΩøÁî®Ôºå‰∫ãÂØ¶‰∏ÄËá¥ÊÄßÂèØÈÄèÈÅéÁî±Á≤æÁ¢∫ÊåáÁ§∫ÂºïÂ∞éÁöÑË™ûÁæ©Áõ∏‰ººÊÄßÁç≤ÂæóÊõ¥Â•ΩÁöÑÁ¢∫‰øù„ÄÇToG${2.0}$ ‰∏çÂÉÖÊèêÂçá LLM ÂõûÊáâÁöÑÊ∫ñÁ¢∫Â∫¶ÂíåÂèØÈù†Â∫¶Ôºå‰πüË≠âÊòéÊ∑∑ÂêàÁµêÊßãÂåñÁü•Ë≠òÁ≥ªÁµ±ÊúâÊΩõÂäõÂ§ßÂπÖÊèêÂçá LLM Êé®ÁêÜÔºå‰ΩøÂÖ∂Êõ¥Êé•Ëøë‰∫∫È°ûËà¨ÁöÑË°®Áèæ„ÄÇÊàëÂÄëÂú®ÂõõÂÄãÂÖ¨ÈñãË≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÂª£Ê≥õÁöÑÂØ¶È©óÔºå‰ª•Ë≠âÊòéÊàëÂÄëÁöÑÊñπÊ≥ïÂÑ™ÊñºÂü∫Á∑ö„ÄÇ

##### **Graphusion: Leveraging Large Language Models for Scientific Knowledge Graph Fusion and Construction in NLP Education**
2407.10794v1 by Rui Yang, Boming Yang, Sixun Ouyang, Tianwei She, Aosong Feng, Yuang Jiang, Freddy Lecue, Jinghui Lu, Irene Li

Knowledge graphs (KGs) are crucial in the field of artificial intelligence
and are widely applied in downstream tasks, such as enhancing Question
Answering (QA) systems. The construction of KGs typically requires significant
effort from domain experts. Recently, Large Language Models (LLMs) have been
used for knowledge graph construction (KGC), however, most existing approaches
focus on a local perspective, extracting knowledge triplets from individual
sentences or documents. In this work, we introduce Graphusion, a zero-shot KGC
framework from free text. The core fusion module provides a global view of
triplets, incorporating entity merging, conflict resolution, and novel triplet
discovery. We showcase how Graphusion could be applied to the natural language
processing (NLP) domain and validate it in the educational scenario.
Specifically, we introduce TutorQA, a new expert-verified benchmark for graph
reasoning and QA, comprising six tasks and a total of 1,200 QA pairs. Our
evaluation demonstrates that Graphusion surpasses supervised baselines by up to
10% in accuracy on link prediction. Additionally, it achieves average scores of
2.92 and 2.37 out of 3 in human evaluations for concept entity extraction and
relation recognition, respectively.

ÊëòË¶ÅÔºö<paragraph>Áü•Ë≠òÂúñË≠ú (KG) Âú®‰∫∫Â∑•Êô∫ÊÖßÈ†òÂüüËá≥ÈóúÈáçË¶ÅÔºå‰∏¶Âª£Ê≥õÊáâÁî®Êñº‰∏ãÊ∏∏‰ªªÂãôÔºå‰æãÂ¶ÇÂ¢ûÂº∑ÂïèÁ≠î (QA) Á≥ªÁµ±„ÄÇÁü•Ë≠òÂúñË≠úÁöÑÂª∫ÊßãÈÄöÂ∏∏ÈúÄË¶ÅÈ†òÂüüÂ∞àÂÆ∂ÁöÑÂ§ßÈáèÂ∑•‰Ωú„ÄÇÊúÄËøëÔºåÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤Ë¢´Áî®ÊñºÁü•Ë≠òÂúñË≠úÂª∫Êßã (KGC)ÔºåÁÑ∂ËÄåÔºåÁèæÊúâÊñπÊ≥ïÂ§ßÂ§öÈóúÊ≥®Â±ÄÈÉ®ËßÄÈªûÔºåÂæûÂÄãÂà•Âè•Â≠êÊàñÊñá‰ª∂‰∏≠ÊèêÂèñÁü•Ë≠ò‰∏âÂÖÉÁµÑ„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫Ü GraphusionÔºå‰∏ÄÂÄãÂæûËá™Áî±ÊñáÊú¨‰∏≠ÈÄ≤Ë°åÈõ∂Ê¨°Â≠∏ÁøíÁöÑ KGC Ê°ÜÊû∂„ÄÇÊ†∏ÂøÉËûçÂêàÊ®°ÁµÑÊèê‰æõ‰∏âÂÖÉÁµÑÁöÑÂÖ®Â±ÄËßÄÈªûÔºåÂåÖÂê´ÂØ¶È´îÂêà‰Ωµ„ÄÅË°ùÁ™ÅËß£Ê±∫ÂíåÊñ∞‰∏âÂÖÉÁµÑÁôºÁèæ„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫ÜÂ¶Ç‰ΩïÂ∞á Graphusion ÊáâÁî®ÊñºËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ (NLP) È†òÂüüÔºå‰∏¶Âú®ÊïôËÇ≤Â†¥ÊôØ‰∏≠È©óË≠âÂÆÉ„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄë‰ªãÁ¥π‰∫Ü TutorQAÔºå‰∏ÄÂÄãÊñ∞ÁöÑÁî±Â∞àÂÆ∂È©óË≠âÁöÑÂúñË≠úÊé®ÁêÜÂíåÂïèÁ≠îÂü∫Ê∫ñÔºåÂåÖÂê´ÂÖ≠È†Ö‰ªªÂãôÂíåÁ∏ΩË®à 1,200 ÂÄãÂïèÁ≠îÂ∞ç„ÄÇÊàëÂÄëÁöÑË©ï‰º∞Ë°®ÊòéÔºåGraphusion Âú®ÈÄ£ÁµêÈ†êÊ∏¨ÁöÑÊ∫ñÁ¢∫Â∫¶‰∏äÊØîÁõ£Áù£ÂºèÂü∫Ê∫ñÈ´òÂá∫ 10%„ÄÇÊ≠§Â§ñÔºåÂú®Ê¶ÇÂøµÂØ¶È´îÊèêÂèñÂíåÈóú‰øÇË≠òÂà•ÁöÑ‰∫∫È°ûË©ï‰º∞‰∏≠ÔºåÂÆÉÂàÜÂà•Áç≤Âæó‰∫Ü 3 ÂàÜ‰∏≠ÁöÑ 2.92 ÂàÜÂíå 2.37 ÂàÜ„ÄÇ</paragraph>

##### **GraphEval: A Knowledge-Graph Based LLM Hallucination Evaluation Framework**
2407.10793v1 by Hannah Sansford, Nicholas Richardson, Hermina Petric Maretic, Juba Nait Saada

Methods to evaluate Large Language Model (LLM) responses and detect
inconsistencies, also known as hallucinations, with respect to the provided
knowledge, are becoming increasingly important for LLM applications. Current
metrics fall short in their ability to provide explainable decisions,
systematically check all pieces of information in the response, and are often
too computationally expensive to be used in practice. We present GraphEval: a
hallucination evaluation framework based on representing information in
Knowledge Graph (KG) structures. Our method identifies the specific triples in
the KG that are prone to hallucinations and hence provides more insight into
where in the response a hallucination has occurred, if at all, than previous
methods. Furthermore, using our approach in conjunction with state-of-the-art
natural language inference (NLI) models leads to an improvement in balanced
accuracy on various hallucination benchmarks, compared to using the raw NLI
models. Lastly, we explore the use of GraphEval for hallucination correction by
leveraging the structure of the KG, a method we name GraphCorrect, and
demonstrate that the majority of hallucinations can indeed be rectified.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂõûÊáâË©ï‰º∞ÊñπÊ≥ïÂíå‰∏ç‰∏ÄËá¥ÊÄßÂÅµÊ∏¨ÔºàÂèàÁ®±ÁÇ∫ÂπªË¶∫ÔºâÔºåÁõ∏Â∞çÊñºÊâÄÊèê‰æõÁöÑÁü•Ë≠òÔºåÂ∞çÊñº LLM ÊáâÁî®Ê≠£ËÆäÂæóË∂ä‰æÜË∂äÈáçË¶Å„ÄÇÁõÆÂâçÁöÑÊåáÊ®ôÁÑ°Ê≥ïÊèê‰æõÂèØËß£ÈáãÁöÑÊ±∫Á≠ñ„ÄÅÁ≥ªÁµ±ÊÄßÂú∞Ê™¢Êü•ÂõûÊáâ‰∏≠ÁöÑÊâÄÊúâË≥áË®äÔºåËÄå‰∏îÂú®ÂØ¶Âãô‰∏ä‰ΩøÁî®ÊôÇÔºåÈÄöÂ∏∏ÈÅéÊñºËÄóË≤ªÈÅãÁÆóË≥áÊ∫ê„ÄÇÊàëÂÄëÊèêÂá∫ GraphEvalÔºö‰∏ÄÂÄãÂü∫ÊñºÁü•Ë≠òÂúñ (KG) ÁµêÊßã‰æÜË°®Á§∫Ë≥áË®äÁöÑÂπªË¶∫Ë©ï‰º∞Êû∂Êßã„ÄÇÊàëÂÄëÁöÑÊäÄË°ìË≠òÂà•Âá∫ÂÆπÊòìÂá∫ÁèæÂπªË¶∫ÁöÑ KG ‰∏≠ÁâπÂÆö‰∏âÂÖÉÁµÑÔºåÂõ†Ê≠§ÊØî‰ª•ÂæÄÁöÑÊñπÊ≥ïÊõ¥Ê∑±ÂÖ•Âú∞‰∫ÜËß£ÂõûÊáâ‰∏≠ÂπªË¶∫ÁôºÁîüÂú®Âì™Ë£°ÔºàÂ¶ÇÊûúÊúâÁöÑË©±Ôºâ„ÄÇÊ≠§Â§ñÔºåÂ∞áÊàëÂÄëÁöÑÊñπÊ≥ïËàáÊúÄÂÖàÈÄ≤ÁöÑËá™ÁÑ∂Ë™ûË®ÄÊé®Ë´ñ (NLI) Ê®°ÂûãÁµêÂêà‰ΩøÁî®ÔºåËàá‰ΩøÁî®ÂéüÂßã NLI Ê®°ÂûãÁõ∏ÊØîÔºåÂèØ‰ª•Âú®ÂêÑÁ®ÆÂπªË¶∫Âü∫Ê∫ñ‰∏äÊèêÈ´òÂπ≥Ë°°Ê∫ñÁ¢∫Â∫¶„ÄÇÊúÄÂæåÔºåÊàëÂÄëÊé¢Á¥¢‰ΩøÁî® GraphEval ‰æÜÈÄ≤Ë°åÂπªË¶∫‰øÆÊ≠£ÔºåÊñπÊ≥ïÊòØÂà©Áî® KG ÁöÑÁµêÊßãÔºåÊàëÂÄëÂ∞áÊ≠§ÊñπÊ≥ïÂëΩÂêçÁÇ∫ GraphCorrectÔºå‰∏¶Ë≠âÊòéÂ§ßÂ§öÊï∏ÂπªË¶∫Á¢∫ÂØ¶ÂèØ‰ª•ÂæóÂà∞Á≥æÊ≠£„ÄÇ

##### **Scaling 3D Reasoning with LMMs to Large Robot Mission Environments Using Datagraphs**
2407.10743v1 by W. J. Meijer, A. C. Kemmeren, E. H. J. Riemens, J. E. Fransman, M. van Bekkum, G. J. Burghouts, J. D. van Mil

This paper addresses the challenge of scaling Large Multimodal Models (LMMs)
to expansive 3D environments. Solving this open problem is especially relevant
for robot deployment in many first-responder scenarios, such as
search-and-rescue missions that cover vast spaces. The use of LMMs in these
settings is currently hampered by the strict context windows that limit the
LMM's input size. We therefore introduce a novel approach that utilizes a
datagraph structure, which allows the LMM to iteratively query smaller sections
of a large environment. Using the datagraph in conjunction with graph traversal
algorithms, we can prioritize the most relevant locations to the query, thereby
improving the scalability of 3D scene language tasks. We illustrate the
datagraph using 3D scenes, but these can be easily substituted by other dense
modalities that represent the environment, such as pointclouds or Gaussian
splats. We demonstrate the potential to use the datagraph for two 3D scene
language task use cases, in a search-and-rescue mission example.

ÊëòË¶ÅÔºöÊú¨ÊñáË®éË´ñ‰∫ÜÂ∞áÂ§ßÂûãÂ§öÊ®°ÊÖãÊ®°Âûã (LMM) Êì¥Â±ïÂà∞Âª£Èóä 3D Áí∞Â¢ÉÁöÑÊåëÊà∞„ÄÇËß£Ê±∫ÈÄôÂÄãÈñãÊîæÊÄßÂïèÈ°åÂ∞çÊñºÊ©üÂô®‰∫∫Âú®Ë®±Â§öÁ¨¨‰∏ÄÂèçÊáâ‰∫∫Âì°Â†¥ÊôØ‰∏≠ÁöÑÈÉ®ÁΩ≤ÁâπÂà•Áõ∏ÈóúÔºå‰æãÂ¶ÇÊ∂µËìãÂª£ÈóäÁ©∫ÈñìÁöÑÊêúÊïë‰ªªÂãô„ÄÇÈÄô‰∫õË®≠ÂÆö‰∏≠‰ΩøÁî® LMM ÁõÆÂâçÂèóÂà∞Âö¥Ê†ºÁöÑ‰∏ä‰∏ãÊñáË¶ñÁ™óÈôêÂà∂ÔºåÈÄôÈôêÂà∂‰∫Ü LMM ÁöÑËº∏ÂÖ•Â§ßÂ∞è„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÊñπÊ≥ïÔºåË©≤ÊñπÊ≥ïÂà©Áî®Ë≥áÊñôÂúñÁµêÊßãÔºåÂÖÅË®± LMM Ëø≠‰ª£Êü•Ë©¢Â§ßÂûãÁí∞Â¢ÉÁöÑËºÉÂ∞èÈÉ®ÂàÜ„ÄÇÈÄèÈÅéÂ∞áË≥áÊñôÂúñËàáÂúñÂΩ¢ÈÅçÊ≠∑ÊºîÁÆóÊ≥ïÁµêÂêà‰ΩøÁî®ÔºåÊàëÂÄëÂèØ‰ª•ÂÑ™ÂÖàËÄÉÊÖÆËàáÊü•Ë©¢ÊúÄÁõ∏ÈóúÁöÑ‰ΩçÁΩÆÔºåÂæûËÄåÊèêÈ´ò 3D Â†¥ÊôØË™ûË®Ä‰ªªÂãôÁöÑÂèØÊì¥ÂÖÖÊÄß„ÄÇÊàëÂÄë‰ΩøÁî® 3D Â†¥ÊôØË™™ÊòéË≥áÊñôÂúñÔºå‰ΩÜÈÄô‰∫õÂ†¥ÊôØÂèØ‰ª•ËºïÈ¨ÜÂú∞Áî±ÂÖ∂‰ªñË°®Á§∫Áí∞Â¢ÉÁöÑÂØÜÈõÜÊ®°ÂºèÂèñ‰ª£Ôºå‰æãÂ¶ÇÈªûÈõ≤ÊàñÈ´òÊñØÈªû„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫ÜÂú®ÊêúÊïë‰ªªÂãôÁØÑ‰æã‰∏≠‰ΩøÁî®Ë≥áÊñôÂúñÈÄ≤Ë°åÂÖ©ÂÄã 3D Â†¥ÊôØË™ûË®Ä‰ªªÂãôÁî®‰æãÁöÑÊΩõÂäõ„ÄÇ

##### **AutoGRAMS: Autonomous Graphical Agent Modeling Software**
2407.10049v1 by Ben Krause, Lucia Chen, Emmanuel Kahembwe

We introduce the AutoGRAMS framework for programming multi-step interactions
with language models. AutoGRAMS represents AI agents as a graph, where each
node can execute either a language modeling instruction or traditional code.
Likewise, transitions in the graph can be governed by either language modeling
decisions or traditional branch logic. AutoGRAMS supports using variables as
memory and allows nodes to call other AutoGRAMS graphs as functions. We show
how AutoGRAMS can be used to design highly sophisticated agents, including
self-referential agents that can modify their own graph. AutoGRAMS's
graph-centric approach aids interpretability, controllability, and safety
during the design, development, and deployment of AI agents. We provide our
framework as open source at https://github.com/autograms/autograms .

ÊëòË¶ÅÔºöÊàëÂÄë‰ªãÁ¥π AutoGRAMS Ê°ÜÊû∂ÔºåÁî®ÊñºÁ∑®ÂØ´ËàáË™ûË®ÄÊ®°ÂûãÁöÑÂ§öÊ≠•È©ü‰∫íÂãï„ÄÇAutoGRAMS Â∞á AI ‰ª£ÁêÜË°®Á§∫ÁÇ∫‰∏ÄÂÄãÂúñÂΩ¢ÔºåÂÖ∂‰∏≠ÊØèÂÄãÁØÄÈªûÂèØ‰ª•Âü∑Ë°åË™ûË®ÄÂª∫Ê®°Êåá‰ª§ÊàñÂÇ≥Áµ±‰ª£Á¢º„ÄÇÂêåÊ®£Âú∞ÔºåÂúñÂΩ¢‰∏≠ÁöÑËΩâÊèõÂèØ‰ª•Áî±Ë™ûË®ÄÂª∫Ê®°Ê±∫Á≠ñÊàñÂÇ≥Áµ±ÂàÜÊîØÈÇèËºØÊéßÂà∂„ÄÇAutoGRAMS ÊîØÊè¥‰ΩøÁî®ËÆäÊï∏‰ΩúÁÇ∫Ë®òÊÜ∂È´îÔºå‰∏¶ÂÖÅË®±ÁØÄÈªûÂëºÂè´ÂÖ∂‰ªñ AutoGRAMS ÂúñÂΩ¢‰ΩúÁÇ∫ÂáΩÂºè„ÄÇÊàëÂÄëÂ±ïÁ§∫Â¶Ç‰Ωï‰ΩøÁî® AutoGRAMS Ë®≠Ë®àÈ´òÂ∫¶Ë§áÈõúÁöÑ‰ª£ÁêÜÔºåÂåÖÊã¨ÂèØ‰ª•‰øÆÊîπËá™Ë∫´ÂúñÂΩ¢ÁöÑËá™ÂèÉÁÖß‰ª£ÁêÜ„ÄÇAutoGRAMS ‰ª•ÂúñÂΩ¢ÁÇ∫‰∏≠ÂøÉÁöÑÊñπÊ≥ïÊúâÂä©ÊñºÂú® AI ‰ª£ÁêÜÁöÑË®≠Ë®à„ÄÅÈñãÁôºÂíåÈÉ®ÁΩ≤ÈÅéÁ®ã‰∏≠ÊèêÈ´òÂèØËß£ÈáãÊÄß„ÄÅÂèØÊéßÊÄßÂíåÂÆâÂÖ®ÊÄß„ÄÇÊàëÂÄëÂú® https://github.com/autograms/autograms Êèê‰æõÊàëÂÄëÁöÑÊ°ÜÊû∂‰ΩúÁÇ∫ÈñãÊ∫ê„ÄÇ

##### **FarFetched: Entity-centric Reasoning and Claim Validation for the Greek Language based on Textually Represented Environments**
2407.09888v1 by Dimitris Papadopoulos, Katerina Metropoulou, Nikolaos Matsatsinis, Nikolaos Papadakis

Our collective attention span is shortened by the flood of online
information. With \textit{FarFetched}, we address the need for automated claim
validation based on the aggregated evidence derived from multiple online news
sources. We introduce an entity-centric reasoning framework in which latent
connections between events, actions, or statements are revealed via entity
mentions and represented in a graph database. Using entity linking and semantic
similarity, we offer a way for collecting and combining information from
diverse sources in order to generate evidence relevant to the user's claim.
Then, we leverage textual entailment recognition to quantitatively determine
whether this assertion is credible, based on the created evidence. Our approach
tries to fill the gap in automated claim validation for less-resourced
languages and is showcased on the Greek language, complemented by the training
of relevant semantic textual similarity (STS) and natural language inference
(NLI) models that are evaluated on translated versions of common benchmarks.

ÊëòË¶ÅÔºöÁ∂≤Ë∑ØË≥áË®äÁöÑÊ¥™ÊµÅÁ∏ÆÁü≠‰∫ÜÊàëÂÄëÁöÑÈõÜÈ´îÊ≥®ÊÑèÂäõÊôÇÈñì„ÄÇÈÄèÈÅé \textit{FarFetched}ÔºåÊàëÂÄëËß£Ê±∫‰∫ÜÊ†πÊìöÂæûÂ§öÂÄãÁ∑ö‰∏äÊñ∞ËÅû‰æÜÊ∫êÂΩôÁ∏ΩÁöÑË≠âÊìöÈÄ≤Ë°åËá™ÂãïÂåñËÅ≤ÊòéÈ©óË≠âÁöÑÈúÄÊ±Ç„ÄÇÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÂÄã‰ª•ÂØ¶È´îÁÇ∫‰∏≠ÂøÉÁöÑÊé®ÁêÜÊ°ÜÊû∂ÔºåÂÖ∂‰∏≠‰∫ã‰ª∂„ÄÅÂãï‰ΩúÊàñÈô≥Ëø∞‰πãÈñìÁöÑÊΩõÂú®ÈóúËÅØÈÄèÈÅéÂØ¶È´îÊèêÂèäË¢´Êè≠Èú≤Ôºå‰∏¶Âú®ÂúñÂΩ¢Ë≥áÊñôÂ∫´‰∏≠Ë°®Á§∫„ÄÇ‰ΩøÁî®ÂØ¶È´îÈÄ£ÁµêÂíåË™ûÁæ©Áõ∏‰ººÊÄßÔºåÊàëÂÄëÊèê‰æõ‰∏ÄÁ®ÆÊñπÂºè‰æÜÊî∂ÈõÜÂíåÁµÑÂêà‰æÜËá™‰∏çÂêå‰æÜÊ∫êÁöÑË≥áË®äÔºå‰ª•Áî¢ÁîüËàá‰ΩøÁî®ËÄÖËÅ≤ÊòéÁõ∏ÈóúÁöÑË≠âÊìö„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÂà©Áî®ÊñáÊú¨ËòäÊ∂µË≠òÂà•‰æÜÊ†πÊìöÂª∫Á´ãÁöÑË≠âÊìöÈáèÂåñÁ¢∫ÂÆöÊ≠§Êñ∑Ë®ÄÊòØÂê¶ÂèØ‰ø°„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïË©¶ÂúñÂ°´Ë£úË≥áÊ∫êËºÉÂ∞ëÁöÑË™ûË®ÄÁöÑËá™ÂãïÂåñËÅ≤ÊòéÈ©óË≠âÊñπÈù¢ÁöÑÁ©∫ÁôΩÔºå‰∏¶Âú®Â∏åËáòË™û‰∏≠Â±ïÁ§∫ÔºåËºî‰ª•Â∞çÁõ∏ÈóúË™ûÁæ©ÊñáÊú¨Áõ∏‰ººÊÄß (STS) ÂíåËá™ÁÑ∂Ë™ûË®ÄÊé®Ë´ñ (NLI) Ê®°ÂûãÁöÑË®ìÁ∑¥ÔºåÈÄô‰∫õÊ®°ÂûãÂú®Â∏∏Ë¶ãÂü∫Ê∫ñÁöÑÁøªË≠ØÁâàÊú¨‰∏äÈÄ≤Ë°åË©ï‰º∞„ÄÇ


### Medical explainable AI
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-08-05**|**The Literature Review Network: An Explainable Artificial Intelligence for Systematic Literature Reviews, Meta-analyses, and Method Development**|Joshua Morriss et.al.|[2408.05239v1](http://arxiv.org/abs/2408.05239v1)|null|
|**2024-08-05**|**Enhancing Medical Learning and Reasoning Systems: A Boxology-Based Comparative Analysis of Design Patterns**|Chi Him Ng et.al.|[2408.02709v1](http://arxiv.org/abs/2408.02709v1)|null|
|**2024-08-05**|**Bayesian Kolmogorov Arnold Networks (Bayesian_KANs): A Probabilistic Approach to Enhance Accuracy and Interpretability**|Masoud Muhammed Hassan et.al.|[2408.02706v1](http://arxiv.org/abs/2408.02706v1)|null|
|**2024-07-26**|**MLtoGAI: Semantic Web based with Machine Learning for Enhanced Disease Prediction and Personalized Recommendations using Generative AI**|Shyam Dongre et.al.|[2407.20284v1](http://arxiv.org/abs/2407.20284v1)|null|
|**2024-07-25**|**Introducing Œ¥-XAI: a novel sensitivity-based method for local AI explanations**|Alessandro De Carlo et.al.|[2407.18343v2](http://arxiv.org/abs/2407.18343v2)|null|
|**2024-07-24**|**Enhanced Deep Learning Methodologies and MRI Selection Techniques for Dementia Diagnosis in the Elderly Population**|Nikolaos Ntampakis et.al.|[2407.17324v2](http://arxiv.org/abs/2407.17324v2)|null|
|**2024-07-24**|**Using Large Language Models to Compare Explainable Models for Smart Home Human Activity Recognition**|Michele Fiori et.al.|[2408.06352v1](http://arxiv.org/abs/2408.06352v1)|null|
|**2024-07-21**|**Explainable AI-based Intrusion Detection System for Industry 5.0: An Overview of the Literature, associated Challenges, the existing Solutions, and Potential Research Directions**|Naseem Khan et.al.|[2408.03335v1](http://arxiv.org/abs/2408.03335v1)|null|
|**2024-07-18**|**A Comparative Study on Automatic Coding of Medical Letters with Explainability**|Jamie Glen et.al.|[2407.13638v1](http://arxiv.org/abs/2407.13638v1)|[link](https://github.com/Glenj01/Medical-Coding)|
|**2024-07-09**|**Explainable AI for Enhancing Efficiency of DL-based Channel Estimation**|Abdul Karim Gizzini et.al.|[2407.07009v1](http://arxiv.org/abs/2407.07009v1)|null|
|**2024-07-07**|**Explainable AI: Comparative Analysis of Normal and Dilated ResNet Models for Fundus Disease Classification**|P. N. Karthikayan et.al.|[2407.05440v1](http://arxiv.org/abs/2407.05440v1)|null|
|**2024-07-03**|**A Survey on Trustworthiness in Foundation Models for Medical Image Analysis**|Congzhen Shi et.al.|[2407.15851v1](http://arxiv.org/abs/2407.15851v1)|null|
|**2024-07-01**|**The Impact of an XAI-Augmented Approach on Binary Classification with Scarce Data**|Ximing Wen et.al.|[2407.06206v1](http://arxiv.org/abs/2407.06206v1)|null|
|**2024-06-28**|**Can GPT-4 Help Detect Quit Vaping Intentions? An Exploration of Automatic Data Annotation Approach**|Sai Krishna Revanth Vuruma et.al.|[2407.00167v1](http://arxiv.org/abs/2407.00167v1)|null|
|**2024-06-25**|**Towards Compositional Interpretability for XAI**|Sean Tull et.al.|[2406.17583v1](http://arxiv.org/abs/2406.17583v1)|null|
|**2024-06-11**|**Unlocking the Potential of Metaverse in Innovative and Immersive Digital Health**|Fatemeh Ebrahimzadeh et.al.|[2406.07114v2](http://arxiv.org/abs/2406.07114v2)|null|
|**2024-06-10**|**AI-Driven Predictive Analytics Approach for Early Prognosis of Chronic Kidney Disease Using Ensemble Learning and Explainable AI**|K M Tawsik Jawad et.al.|[2406.06728v1](http://arxiv.org/abs/2406.06728v1)|null|
|**2024-06-10**|**Explainable AI for Mental Disorder Detection via Social Media: A survey and outlook**|Yusif Ibrahimov et.al.|[2406.05984v1](http://arxiv.org/abs/2406.05984v1)|null|
|**2024-06-09**|**Methodology and Real-World Applications of Dynamic Uncertain Causality Graph for Clinical Diagnosis with Explainability and Invariance**|Zhan Zhang et.al.|[2406.05746v1](http://arxiv.org/abs/2406.05746v1)|null|
|**2024-06-07**|**Advancing Histopathology-Based Breast Cancer Diagnosis: Insights into Multi-Modality and Explainability**|Faseela Abdullakutty et.al.|[2406.12897v1](http://arxiv.org/abs/2406.12897v1)|null|
|**2024-06-07**|**Revisiting Attention Weights as Interpretations of Message-Passing Neural Networks**|Yong-Min Shin et.al.|[2406.04612v1](http://arxiv.org/abs/2406.04612v1)|[link](https://github.com/jordan7186/gatt)|
|**2024-06-04**|**Using Explainable AI for EEG-based Reduced Montage Neonatal Seizure Detection**|Dinuka Sandun Udayantha et.al.|[2406.16908v3](http://arxiv.org/abs/2406.16908v3)|[link](https://github.com/dinuka-1999/braineocare)|
|**2024-06-01**|**Breast Cancer Diagnosis: A Comprehensive Exploration of Explainable Artificial Intelligence (XAI) Techniques**|Samita Bai et.al.|[2406.00532v1](http://arxiv.org/abs/2406.00532v1)|null|
|**2024-06-01**|**Unveiling Hidden Factors: Explainable AI for Feature Boosting in Speech Emotion Recognition**|Alaa Nfissi et.al.|[2406.01624v2](http://arxiv.org/abs/2406.01624v2)|[link](https://github.com/alaanfissi/unveiling-hidden-factors-explainable-ai-for-feature-boosting-in-speech-emotion-recognition)|
|**2024-05-31**|**The Explanation Necessity for Healthcare AI**|Michail Mamalakis et.al.|[2406.00216v1](http://arxiv.org/abs/2406.00216v1)|null|
|**2024-05-29**|**Interdisciplinary Expertise to Advance Equitable Explainable AI**|Chloe R. Bennett et.al.|[2406.18563v1](http://arxiv.org/abs/2406.18563v1)|null|
|**2024-05-27**|**"It depends": Configuring AI to Improve Clinical Usefulness Across Contexts**|Hubert D. ZajƒÖc et.al.|[2407.11978v1](http://arxiv.org/abs/2407.11978v1)|null|
|**2024-05-26**|**Improving Health Professionals' Onboarding with AI and XAI for Trustworthy Human-AI Collaborative Decision Making**|Min Hun Lee et.al.|[2405.16424v1](http://arxiv.org/abs/2405.16424v1)|null|
|**2024-05-26**|**Exploring Nutritional Impact on Alzheimer's Mortality: An Explainable AI Approach**|Ziming Liu et.al.|[2405.17502v1](http://arxiv.org/abs/2405.17502v1)|null|
|**2024-05-24**|**Explainable AI Enhances Glaucoma Referrals, Yet the Human-AI Team Still Falls Short of the AI Alone**|Catalina Gomez et.al.|[2407.11974v1](http://arxiv.org/abs/2407.11974v1)|null|
|**2024-05-23**|**Decoding Decision Reasoning: A Counterfactual-Powered Model for Knowledge Discovery**|Yingying Fang et.al.|[2406.18552v1](http://arxiv.org/abs/2406.18552v1)|null|
|**2024-05-21**|**The Role of Emotions in Informational Support Question-Response Pairs in Online Health Communities: A Multimodal Deep Learning Approach**|Mohsen Jozani et.al.|[2405.13099v1](http://arxiv.org/abs/2405.13099v1)|null|
|**2024-05-17**|**ChatGPT in Classrooms: Transforming Challenges into Opportunities in Education**|Harris Bin Munawar et.al.|[2405.10645v1](http://arxiv.org/abs/2405.10645v1)|null|
|**2024-05-13**|**Evaluating the Explainable AI Method Grad-CAM for Breath Classification on Newborn Time Series Data**|Camelia Oprea et.al.|[2405.07590v1](http://arxiv.org/abs/2405.07590v1)|null|
|**2024-05-10**|**XAI4LLM. Let Machine Learning Models and LLMs Collaborate for Enhanced In-Context Learning in Healthcare**|Fatemeh Nazary et.al.|[2405.06270v3](http://arxiv.org/abs/2405.06270v3)|null|
|**2024-05-09**|**To Trust or Not to Trust: Towards a novel approach to measure trust for XAI systems**|Miquel Mir√≥-Nicolau et.al.|[2405.05766v1](http://arxiv.org/abs/2405.05766v1)|null|
|**2024-05-05**|**Region-specific Risk Quantification for Interpretable Prognosis of COVID-19**|Zhusi Zhong et.al.|[2405.02815v1](http://arxiv.org/abs/2405.02815v1)|[link](https://github.com/zzs95/RSP_COVID)|
|**2024-04-26**|**Rad4XCNN: a new agnostic method for post-hoc global explanation of CNN-derived features by means of radiomics**|Francesco Prinzi et.al.|[2405.02334v1](http://arxiv.org/abs/2405.02334v1)|null|
|**2024-04-25**|**Attributing Responsibility in AI-Induced Incidents: A Computational Reflective Equilibrium Framework for Accountability**|Yunfei Ge et.al.|[2404.16957v1](http://arxiv.org/abs/2404.16957v1)|null|
|**2024-04-19**|**Explainable AI for Fair Sepsis Mortality Predictive Model**|Chia-Hsuan Chang et.al.|[2404.13139v1](http://arxiv.org/abs/2404.13139v1)|null|
|**2024-04-19**|**Multi Class Depression Detection Through Tweets using Artificial Intelligence**|Muhammad Osama Nusrat et.al.|[2404.13104v1](http://arxiv.org/abs/2404.13104v1)|[link](https://github.com/mnusrat786/masters-thesis)|
|**2024-04-19**|**COIN: Counterfactual inpainting for weakly supervised semantic segmentation for medical images**|Dmytro Shvetsov et.al.|[2404.12832v2](http://arxiv.org/abs/2404.12832v2)|[link](https://github.com/dmytro-shvetsov/counterfactual-search)|
|**2024-04-15**|**Hybrid Intelligence for Digital Humanities**|Victor de Boer et.al.|[2406.15374v1](http://arxiv.org/abs/2406.15374v1)|null|
|**2024-04-14**|**Ethical Framework for Responsible Foundational Models in Medical Imaging**|Abhijit Das et.al.|[2406.11868v1](http://arxiv.org/abs/2406.11868v1)|null|
|**2024-04-09**|**Advancements in Radiomics and Artificial Intelligence for Thyroid Cancer Diagnosis**|Milad Yousefi et.al.|[2404.07239v1](http://arxiv.org/abs/2404.07239v1)|null|
|**2024-04-06**|**Predictive Modeling for Breast Cancer Classification in the Context of Bangladeshi Patients: A Supervised Machine Learning Approach with Explainable AI**|Taminul Islam et.al.|[2404.04686v1](http://arxiv.org/abs/2404.04686v1)|null|
|**2024-04-05**|**Enhancing Breast Cancer Diagnosis in Mammography: Evaluation and Integration of Convolutional Neural Networks and Explainable AI**|Maryam Ahmed et.al.|[2404.03892v3](http://arxiv.org/abs/2404.03892v3)|null|
|**2024-03-30**|**Advancing Multimodal Data Fusion in Pain Recognition: A Strategy Leveraging Statistical Correlation and Human-Centered Perspectives**|Xingrui Gu et.al.|[2404.00320v2](http://arxiv.org/abs/2404.00320v2)|null|
|**2024-03-26**|**Addressing Social Misattributions of Large Language Models: An HCXAI-based Approach**|Andrea Ferrario et.al.|[2403.17873v1](http://arxiv.org/abs/2403.17873v1)|null|
|**2024-03-26**|**Clinical Domain Knowledge-Derived Template Improves Post Hoc AI Explanations in Pneumothorax Classification**|Han Yuan et.al.|[2403.18871v1](http://arxiv.org/abs/2403.18871v1)|[link](https://github.com/han-yuan-med/template-explanation)|
|**2024-03-03**|**Enhancing Neural Machine Translation of Low-Resource Languages: Corpus Development, Human Evaluation and Explainable AI Architectures**|S√©amus Lankford et.al.|[2403.01580v1](http://arxiv.org/abs/2403.01580v1)|null|
|**2024-02-28**|**Artificial Intelligence and Diabetes Mellitus: An Inside Look Through the Retina**|Yasin Sadeghi Bazargani et.al.|[2402.18600v1](http://arxiv.org/abs/2402.18600v1)|null|
|**2024-02-22**|**Multi-stakeholder Perspective on Responsible Artificial Intelligence and Acceptability in Education**|A. J. Karran et.al.|[2402.15027v2](http://arxiv.org/abs/2402.15027v2)|null|
|**2024-02-12**|**Deciphering Heartbeat Signatures: A Vision Transformer Approach to Explainable Atrial Fibrillation Detection from ECG Signals**|Aruna Mohan et.al.|[2402.09474v2](http://arxiv.org/abs/2402.09474v2)|null|
|**2024-02-05**|**Illuminate: A novel approach for depression detection with explainable analysis and proactive therapy using prompt engineering**|Aryan Agrawal et.al.|[2402.05127v1](http://arxiv.org/abs/2402.05127v1)|null|
|**2024-01-24**|**Information That Matters: Exploring Information Needs of People Affected by Algorithmic Decisions**|Timoth√©e Schmude et.al.|[2401.13324v4](http://arxiv.org/abs/2401.13324v4)|null|
|**2024-01-02**|**Evaluating Large Language Models on the GMAT: Implications for the Future of Business Education**|Vahid Ashrafimoghari et.al.|[2401.02985v1](http://arxiv.org/abs/2401.02985v1)|null|
|**2023-12-29**|**XAI for In-hospital Mortality Prediction via Multimodal ICU Data**|Xingqiao Li et.al.|[2312.17624v1](http://arxiv.org/abs/2312.17624v1)|[link](https://github.com/lixingqiao/xai-icu)|
|**2023-12-22**|**Joining Forces for Pathology Diagnostics with AI Assistance: The EMPAIA Initiative**|Norman Zerbe et.al.|[2401.09450v2](http://arxiv.org/abs/2401.09450v2)|null|
|**2023-12-18**|**Robust Stochastic Graph Generator for Counterfactual Explanations**|Mario Alfonso Prado-Romero et.al.|[2312.11747v2](http://arxiv.org/abs/2312.11747v2)|null|
|**2023-12-10**|**Evaluating the Utility of Model Explanations for Model Development**|Shawn Im et.al.|[2312.06032v1](http://arxiv.org/abs/2312.06032v1)|null|
|**2023-12-05**|**Building Trustworthy NeuroSymbolic AI Systems: Consistency, Reliability, Explainability, and Safety**|Manas Gaur et.al.|[2312.06798v1](http://arxiv.org/abs/2312.06798v1)|null|
|**2023-11-28**|**Deployment of a Robust and Explainable Mortality Prediction Model: The COVID-19 Pandemic and Beyond**|Jacob R. Epifano et.al.|[2311.17133v1](http://arxiv.org/abs/2311.17133v1)|null|
|**2023-11-27**|**Variational Autoencoders for Feature Exploration and Malignancy Prediction of Lung Lesions**|Benjamin Keel et.al.|[2311.15719v1](http://arxiv.org/abs/2311.15719v1)|[link](https://github.com/benkeel/vae_lung_lesion_bmvc)|
|**2023-11-24**|**MRxaI: Black-Box Explainability for Image Classifiers in a Medical Setting**|Nathan Blake et.al.|[2311.14471v1](http://arxiv.org/abs/2311.14471v1)|null|
|**2023-11-21**|**Moderating Model Marketplaces: Platform Governance Puzzles for AI Intermediaries**|Robert Gorwa et.al.|[2311.12573v2](http://arxiv.org/abs/2311.12573v2)|null|
|**2023-11-20**|**Ovarian Cancer Data Analysis using Deep Learning: A Systematic Review from the Perspectives of Key Features of Data Analysis and AI Assurance**|Muta Tah Hira et.al.|[2311.11932v1](http://arxiv.org/abs/2311.11932v1)|null|
|**2023-11-18**|**Representing visual classification as a linear combination of words**|Shobhit Agarwal et.al.|[2311.10933v1](http://arxiv.org/abs/2311.10933v1)|[link](https://github.com/lotterlab/task_word_explainability)|
|**2023-11-03**|**Towards objective and systematic evaluation of bias in artificial intelligence for medical imaging**|Emma A. M. Stanley et.al.|[2311.02115v2](http://arxiv.org/abs/2311.02115v2)|[link](https://github.com/estanley16/simba)|
|**2023-10-29**|**Predicting recovery following stroke: deep learning, multimodal data and feature selection using explainable AI**|Adam White et.al.|[2310.19174v1](http://arxiv.org/abs/2310.19174v1)|null|
|**2023-10-03**|**Trainable Noise Model as an XAI evaluation method: application on Sobol for remote sensing image segmentation**|Hossein Shreim et.al.|[2310.01828v2](http://arxiv.org/abs/2310.01828v2)|[link](https://github.com/geoaigroup/geoai-ecrs2023)|
|**2023-09-26**|**Creating Trustworthy LLMs: Dealing with Hallucinations in Healthcare AI**|Muhammad Aurangzeb Ahmad et.al.|[2311.01463v1](http://arxiv.org/abs/2311.01463v1)|null|
|**2023-09-20**|**When to Trust AI: Advances and Challenges for Certification of Neural Networks**|Marta Kwiatkowska et.al.|[2309.11196v1](http://arxiv.org/abs/2309.11196v1)|null|
|**2023-09-19**|**Functional requirements to mitigate the Risk of Harm to Patients from Artificial Intelligence in Healthcare**|Juan M. Garc√≠a-G√≥mez et.al.|[2309.10424v1](http://arxiv.org/abs/2309.10424v1)|null|
|**2023-09-19**|**QXAI: Explainable AI Framework for Quantitative Analysis in Patient Monitoring Systems**|Thanveer Shaik et.al.|[2309.10293v3](http://arxiv.org/abs/2309.10293v3)|null|
|**2023-09-18**|**Evaluation of Human-Understandability of Global Model Explanations using Decision Tree**|Adarsa Sivaprasad et.al.|[2309.09917v1](http://arxiv.org/abs/2309.09917v1)|null|
|**2023-08-28**|**Leveraging A Medical Knowledge Graph into Large Language Models for Diagnosis Prediction**|Yanjun Gao et.al.|[2308.14321v1](http://arxiv.org/abs/2308.14321v1)|null|
|**2023-08-18**|**Deciphering knee osteoarthritis diagnostic features with explainable artificial intelligence: A systematic review**|Yun Xin Teoh et.al.|[2308.09380v1](http://arxiv.org/abs/2308.09380v1)|null|
|**2023-08-16**|**Explainable AI for clinical risk prediction: a survey of concepts, methods, and modalities**|Munib Mesinovic et.al.|[2308.08407v1](http://arxiv.org/abs/2308.08407v1)|null|
|**2023-08-11**|**FUTURE-AI: International consensus guideline for trustworthy and deployable artificial intelligence in healthcare**|Karim Lekadir et.al.|[2309.12325v3](http://arxiv.org/abs/2309.12325v3)|null|
|**2023-08-10**|**Explainable AI applications in the Medical Domain: a systematic review**|Nicoletta Prentzas et.al.|[2308.05411v1](http://arxiv.org/abs/2308.05411v1)|null|
|**2023-08-01**|**Exploring the Role of Explainability in AI-Assisted Embryo Selection**|Lucia Urcelay et.al.|[2308.02534v1](http://arxiv.org/abs/2308.02534v1)|null|
|**2023-07-26**|**A New Perspective on Evaluation Methods for Explainable Artificial Intelligence (XAI)**|Timo Speith et.al.|[2307.14246v1](http://arxiv.org/abs/2307.14246v1)|null|
|**2023-07-26**|**Revisiting the Performance-Explainability Trade-Off in Explainable Artificial Intelligence (XAI)**|Barnaby Crook et.al.|[2307.14239v1](http://arxiv.org/abs/2307.14239v1)|null|
|**2023-07-26**|**Acceptable risks in Europe's proposed AI Act: Reasonableness and other principles for deciding how much risk management is enough**|Henry Fraser et.al.|[2308.02047v1](http://arxiv.org/abs/2308.02047v1)|null|
|**2023-07-21**|**eXplainable Artificial Intelligence (XAI) in aging clock models**|Alena Kalyakulina et.al.|[2307.13704v3](http://arxiv.org/abs/2307.13704v3)|null|
|**2023-07-19**|**Interpreting and Correcting Medical Image Classification with PIP-Net**|Meike Nauta et.al.|[2307.10404v2](http://arxiv.org/abs/2307.10404v2)|[link](https://github.com/m-nauta/pipnet)|
|**2023-07-15**|**Explaining and visualizing black-box models through counterfactual paths**|Bastian Pfeifer et.al.|[2307.07764v3](http://arxiv.org/abs/2307.07764v3)|[link](https://github.com/pievos101/cpath)|
|**2023-07-05**|**Beyond Known Reality: Exploiting Counterfactual Explanations for Medical Research**|Toygar Tanyel et.al.|[2307.02131v5](http://arxiv.org/abs/2307.02131v5)|[link](https://github.com/toygarr/counterfactual-explanations-for-medical-research)|
|**2023-06-30**|**AI and Non AI Assessments for Dementia**|Mahboobeh Parsapoor et.al.|[2307.01210v1](http://arxiv.org/abs/2307.01210v1)|null|
|**2023-06-12**|**Active Globally Explainable Learning for Medical Images via Class Association Embedding and Cyclic Adversarial Generation**|Ruitao Xie et.al.|[2306.07306v1](http://arxiv.org/abs/2306.07306v1)|null|
|**2023-06-09**|**HiTZ@Antidote: Argumentation-driven Explainable Artificial Intelligence for Digital Medicine**|Rodrigo Agerri et.al.|[2306.06029v1](http://arxiv.org/abs/2306.06029v1)|null|
|**2023-06-07**|**XInsight: Revealing Model Insights for GNNs with Flow-based Explanations**|Eli Laird et.al.|[2306.04791v1](http://arxiv.org/abs/2306.04791v1)|null|
|**2023-06-06**|**Explainable AI using expressive Boolean formulas**|Gili Rosenberg et.al.|[2306.03976v1](http://arxiv.org/abs/2306.03976v1)|null|
|**2023-06-06**|**Utterance Classification with Logical Neural Network: Explainable AI for Mental Disorder Diagnosis**|Yeldar Toleubay et.al.|[2306.03902v1](http://arxiv.org/abs/2306.03902v1)|null|
|**2023-06-02**|**XAI Renaissance: Redefining Interpretability in Medical Diagnostic Models**|Sujith K Mandala et.al.|[2306.01668v1](http://arxiv.org/abs/2306.01668v1)|null|
|**2023-05-26**|**A Novel real-time arrhythmia detection model using YOLOv8**|Guang Jun Nicholas Ang et.al.|[2305.16727v3](http://arxiv.org/abs/2305.16727v3)|null|
|**2023-05-22**|**Breast Cancer Segmentation using Attention-based Convolutional Network and Explainable AI**|Jai Vardhan et.al.|[2305.14389v2](http://arxiv.org/abs/2305.14389v2)|null|
|**2023-05-18**|**What Symptoms and How Long? An Interpretable AI Approach for Depression Detection in Social Media**|Junwei Kuang et.al.|[2305.13127v2](http://arxiv.org/abs/2305.13127v2)|null|
|**2023-05-17**|**Echoes of Biases: How Stigmatizing Language Affects AI Performance**|Yizhi Liu et.al.|[2305.10201v4](http://arxiv.org/abs/2305.10201v4)|null|

#### Abstracts
##### **The Literature Review Network: An Explainable Artificial Intelligence for Systematic Literature Reviews, Meta-analyses, and Method Development**
2408.05239v1 by Joshua Morriss, Tod Brindle, Jessica Bah R√∂sman, Daniel Reibsamen, Andreas Enz

Systematic literature reviews are the highest quality of evidence in
research. However, the review process is hindered by significant resource and
data constraints. The Literature Review Network (LRN) is the first of its kind
explainable AI platform adhering to PRISMA 2020 standards, designed to automate
the entire literature review process. LRN was evaluated in the domain of
surgical glove practices using 3 search strings developed by experts to query
PubMed. A non-expert trained all LRN models. Performance was benchmarked
against an expert manual review. Explainability and performance metrics
assessed LRN's ability to replicate the experts' review. Concordance was
measured with the Jaccard index and confusion matrices. Researchers were
blinded to the other's results until study completion. Overlapping studies were
integrated into an LRN-generated systematic review. LRN models demonstrated
superior classification accuracy without expert training, achieving 84.78% and
85.71% accuracy. The highest performance model achieved high interrater
reliability (k = 0.4953) and explainability metrics, linking 'reduce',
'accident', and 'sharp' with 'double-gloving'. Another LRN model covered 91.51%
of the relevant literature despite diverging from the non-expert's judgments (k
= 0.2174), with the terms 'latex', 'double' (gloves), and 'indication'. LRN
outperformed the manual review (19,920 minutes over 11 months), reducing the
entire process to 288.6 minutes over 5 days. This study demonstrates that
explainable AI does not require expert training to successfully conduct
PRISMA-compliant systematic literature reviews like an expert. LRN summarized
the results of surgical glove studies and identified themes that were nearly
identical to the clinical researchers' findings. Explainable AI can accurately
expedite our understanding of clinical practices, potentially revolutionizing
healthcare research.

ÊëòË¶ÅÔºöÁ≥ªÁµ±ÊÄßÊñáÁçªÂõûÈ°ßÊòØÁ†îÁ©∂‰∏≠Ë≠âÊìöÂìÅË≥™ÊúÄÈ´òÁöÑ„ÄÇÁÑ∂ËÄåÔºåÂõûÈ°ßÈÅéÁ®ãÂèóÂà∞È°ØËëóË≥áÊ∫êÂíåË≥áÊñôÈôêÂà∂ÁöÑÈòªÁ§ô„ÄÇÊñáÁçªÂõûÈ°ßÁ∂≤Ë∑Ø (LRN) ÊòØÁ¨¨‰∏ÄÂÄãÈÅµÂæ™ PRISMA 2020 Ê®ôÊ∫ñÁöÑÂèØËß£Èáã AI Âπ≥Âè∞ÔºåÊó®Âú®Ëá™ÂãïÂåñÊï¥ÂÄãÊñáÁçªÂõûÈ°ßÈÅéÁ®ã„ÄÇLRN Âú®Â§ñÁßëÊâãÂ•óÂØ¶ÂãôÈ†òÂüü‰∏≠ÈÄ≤Ë°åË©ï‰º∞Ôºå‰ΩøÁî®Â∞àÂÆ∂ÈñãÁôºÁöÑ 3 ÂÄãÊêúÂ∞ãÂ≠ó‰∏≤‰æÜÊü•Ë©¢ PubMed„ÄÇÈùûÂ∞àÂÆ∂Ë®ìÁ∑¥ÊâÄÊúâ LRN Ê®°Âûã„ÄÇÊïàËÉΩ‰ª•Â∞àÂÆ∂ÊâãÂãïÂõûÈ°ß‰ΩúÁÇ∫Âü∫Ê∫ñ„ÄÇÂèØËß£ÈáãÊÄßÂíåÊïàËÉΩÊåáÊ®ôË©ï‰º∞ LRN Ë§áË£ΩÂ∞àÂÆ∂ÂõûÈ°ßÁöÑËÉΩÂäõ„ÄÇ‰∏ÄËá¥ÊÄß‰ª• Jaccard ÊåáÊï∏ÂíåÊ∑∑Ê∑ÜÁü©Èô£Ê∏¨Èáè„ÄÇÁ†îÁ©∂‰∫∫Âì°Âú®Á†îÁ©∂ÂÆåÊàêÂâçÂ∞çÂΩºÊ≠§ÁöÑÁµêÊûú‰øùÂØÜ„ÄÇÈáçÁñäÁöÑÁ†îÁ©∂Êï¥ÂêàÂà∞ LRN ÁîüÊàêÁöÑÁ≥ªÁµ±ÊÄßÂõûÈ°ß‰∏≠„ÄÇLRN Ê®°ÂûãÂú®Ê≤íÊúâÂ∞àÂÆ∂Ë®ìÁ∑¥ÁöÑÊÉÖÊ≥Å‰∏ãÂ±ïÁèæÂá∫ÂÑ™Áï∞ÁöÑÂàÜÈ°ûÊ∫ñÁ¢∫ÁéáÔºåÈÅîÂà∞ 84.78% Âíå 85.71% ÁöÑÊ∫ñÁ¢∫Áéá„ÄÇÊïàËÉΩÊúÄÈ´òÁöÑÊ®°ÂûãÈÅîÂà∞‰∫ÜÈ´òË©ïÂàÜËÄÖÈñì‰ø°Ë≥¥Â∫¶ (k = 0.4953) ÂíåÂèØËß£ÈáãÊÄßÊåáÊ®ôÔºåÂ∞á„ÄåÊ∏õÂ∞ë„Äç„ÄÅ„ÄåÊÑèÂ§ñ„ÄçÂíå„ÄåÈä≥Âà©„ÄçËàá„ÄåÈõôÈáçÊà¥ÊâãÂ•ó„ÄçÈÄ£ÁµêÂú®‰∏ÄËµ∑„ÄÇÂè¶‰∏ÄÂÄã LRN Ê®°ÂûãÊ∂µËìã‰∫Ü 91.51% ÁöÑÁõ∏ÈóúÊñáÁçªÔºåÂÑòÁÆ°ËàáÈùûÂ∞àÂÆ∂ÁöÑÂà§Êñ∑‰∏çÂêå (k = 0.2174)Ôºå‰ΩÜÂåÖÂê´‰∫Ü„Äå‰π≥ËÜ†„Äç„ÄÅ„ÄåÈõôÈáç„ÄçÔºàÊâãÂ•óÔºâÂíå„ÄåÈÅ©ÊáâÁóá„ÄçÁ≠âË©ûÂΩô„ÄÇLRN ÂÑ™ÊñºÊâãÂãïÂõûÈ°ßÔºà11 ÂÄãÊúàË∂ÖÈÅé 19,920 ÂàÜÈêòÔºâÔºåÂ∞áÊï¥ÂÄãÈÅéÁ®ãÁ∏ÆÁü≠ÁÇ∫ 5 Â§©Ë∂ÖÈÅé 288.6 ÂàÜÈêò„ÄÇÈÄôÈ†ÖÁ†îÁ©∂È°ØÁ§∫ÔºåÂèØËß£ÈáãÁöÑ AI ‰∏çÈúÄË¶ÅÂ∞àÂÆ∂Ë®ìÁ∑¥Âç≥ÂèØÊàêÂäüÈÄ≤Ë°åÂ∞àÂÆ∂Á≠âÁ¥öÁöÑ PRISMA Áõ∏ÂÆπÁ≥ªÁµ±ÊÄßÊñáÁçªÂõûÈ°ß„ÄÇLRN Á∏ΩÁµê‰∫ÜÂ§ñÁßëÊâãÂ•óÁ†îÁ©∂ÁöÑÁµêÊûúÔºå‰∏¶ÊâæÂá∫ËàáËá®Â∫äÁ†îÁ©∂‰∫∫Âì°ÁôºÁèæÂπæ‰πéÁõ∏ÂêåÁöÑ‰∏ªÈ¢ò„ÄÇÂèØËß£ÈáãÁöÑ AI ÂèØ‰ª•Ê∫ñÁ¢∫Âú∞Âä†Âø´ÊàëÂÄëÂ∞çËá®Â∫äÂØ¶ÂãôÁöÑÁêÜËß£ÔºåÊúâÊΩõÂäõÈù©Êñ∞ÈÜ´ÁôÇ‰øùÂÅ•Á†îÁ©∂„ÄÇ

##### **Enhancing Medical Learning and Reasoning Systems: A Boxology-Based Comparative Analysis of Design Patterns**
2408.02709v1 by Chi Him Ng

This study analyzes hybrid AI systems' design patterns and their
effectiveness in clinical decision-making using the boxology framework. It
categorizes and copares various architectures combining machine learning and
rule-based reasoning to provide insights into their structural foundations and
healthcare applications. Addressing two main questions, how to categorize these
systems againts established design patterns and how to extract insights through
comparative analysis, the study uses design patterns from software engineering
to understand and optimize healthcare AI systems. Boxology helps identify
commonalities and create reusable solutions, enhancing these systems'
scalability, reliability, and performance. Five primary architectures are
examined: REML, MLRB, RBML, RMLT, and PERML. Each has unique strengths and
weaknesses, highlighting the need for tailored approaches in clinical tasks.
REML excels in high-accuracy prediction for datasets with limited data; MLRB in
handling large datasets and complex data integration; RBML in explainability
and trustworthiness; RMLT in managing high-dimensional data; and PERML, though
limited in analysis, shows promise in urgent care scenarios. The study
introduces four new patterns, creates five abstract categorization patterns,
and refines those five further to specific systems. These contributions enhance
Boxlogy's taxonomical organization and offer novel approaches to integrating
expert knowledge with machine learning. Boxology's structured, modular apporach
offers significant advantages in developing and analyzing hybrid AI systems,
revealing commonalities, and promoting reusable solutions. In conclusion, this
study underscores hybrid AI systems' crucial role in advancing healthcare and
Boxology's potential to drive further innovation in AI integration, ultimately
improving clinical decision support and patient outcomes.

ÊëòË¶ÅÔºöÊú¨Á†îÁ©∂‰ΩøÁî®ÁõíÂ≠êÂ≠∏Ê°ÜÊû∂ÂàÜÊûêÊ∑∑Âêà‰∫∫Â∑•Êô∫ÊÖßÁ≥ªÁµ±ÁöÑË®≠Ë®àÊ®°ÂºèÂèäÂÖ∂Âú®Ëá®Â∫äÊ±∫Á≠ñ‰∏≠ÁöÑÊúâÊïàÊÄß„ÄÇÂÆÉÂàÜÈ°û‰∏¶ÊØîËºÉÁµêÂêàÊ©üÂô®Â≠∏ÁøíÂíåÂü∫ÊñºË¶èÂâáÁöÑÊé®ÁêÜÁöÑÂêÑÁ®ÆÊû∂ÊßãÔºå‰ª•Ê∑±ÂÖ•‰∫ÜËß£ÂÖ∂ÁµêÊßãÂü∫Á§éÂíåÈÜ´ÁôÇ‰øùÂÅ•ÊáâÁî®„ÄÇÈáùÂ∞çÂÖ©ÂÄã‰∏ªË¶ÅÂïèÈ°åÔºåÂ¶Ç‰ΩïÊ†πÊìöÊó¢ÂÆöÁöÑË®≠Ë®àÊ®°ÂºèÂ∞çÈÄô‰∫õÁ≥ªÁµ±ÈÄ≤Ë°åÂàÜÈ°ûÔºå‰ª•ÂèäÂ¶Ç‰ΩïÈÄöÈÅéÊØîËºÉÂàÜÊûêÊèêÂèñË¶ãËß£ÔºåÊú¨Á†îÁ©∂‰ΩøÁî®ËªüÈ´îÂ∑•Á®ã‰∏≠ÁöÑË®≠Ë®àÊ®°Âºè‰æÜ‰∫ÜËß£ÂíåÂÑ™ÂåñÈÜ´ÁôÇ‰øùÂÅ•‰∫∫Â∑•Êô∫ÊÖßÁ≥ªÁµ±„ÄÇÁõíÂ≠êÂ≠∏ÊúâÂä©ÊñºË≠òÂà•ÂÖ±ÊÄß‰∏¶Âª∫Á´ãÂèØÈáçË§á‰ΩøÁî®ÁöÑËß£Ê±∫ÊñπÊ°àÔºåÂæûËÄåÂ¢ûÂº∑ÈÄô‰∫õÁ≥ªÁµ±ÁöÑÂèØÊì¥ÂÖÖÊÄß„ÄÅÂèØÈù†ÊÄßÂíåÊïàËÉΩ„ÄÇÊ™¢Êü•‰∫Ü‰∫îÁ®Æ‰∏ªË¶ÅÁöÑÊû∂ÊßãÔºöREML„ÄÅMLRB„ÄÅRBML„ÄÅRMLT Âíå PERML„ÄÇÊØèÁ®ÆÊû∂ÊßãÈÉΩÊúâÁç®ÁâπÁöÑÂÑ™Áº∫ÈªûÔºåÂº∑Ë™ø‰∫ÜÂú®Ëá®Â∫ä‰ªªÂãô‰∏≠ÈúÄË¶ÅÈáèË∫´ÊâìÈÄ†ÁöÑÊñπÊ≥ï„ÄÇREML Âú®Ë≥áÊñôÊúâÈôêÁöÑË≥áÊñôÈõÜ‰∏≠Ë°®ÁèæÂá∫È´òÁ≤æÂ∫¶ÁöÑÈ†êÊ∏¨ÔºõMLRB Âú®ËôïÁêÜÂ§ßÂûãË≥áÊñôÈõÜÂíåË§áÈõúË≥áÊñôÊï¥ÂêàÊñπÈù¢Ë°®ÁèæÂá∫Ëâ≤ÔºõRBML Âú®ÂèØËß£ÈáãÊÄßÂíåÂèØ‰ø°Â∫¶ÊñπÈù¢Ë°®ÁèæÂá∫Ëâ≤ÔºõRMLT Âú®ÁÆ°ÁêÜÈ´òÁ∂≠Ë≥áÊñôÊñπÈù¢Ë°®ÁèæÂá∫Ëâ≤ÔºõËÄå PERML ÂÑòÁÆ°Âú®ÂàÜÊûêÊñπÈù¢ÊúâÈôêÔºå‰ΩÜÂú®Á∑äÊÄ•ÁÖßË≠∑Â†¥ÊôØ‰∏≠Ë°®ÁèæÂá∫ÊΩõÂäõ„ÄÇÊú¨Á†îÁ©∂ÂºïÂÖ•‰∫ÜÂõõÁ®ÆÊñ∞Ê®°ÂºèÔºåÂª∫Á´ã‰∫Ü‰∫îÁ®ÆÊäΩË±°ÂàÜÈ°ûÊ®°ÂºèÔºå‰∏¶ÈÄ≤‰∏ÄÊ≠•Â∞áÈÄô‰∫îÁ®ÆÊ®°ÂºèÁ¥∞ÂåñÁÇ∫ÂÖ∑È´îÁöÑÁ≥ªÁµ±„ÄÇÈÄô‰∫õË≤¢ÁçªÂ¢ûÂº∑‰∫ÜÁõíÂ≠êÂ≠∏ÁöÑÂàÜÈ°ûÁµÑÁπîÔºå‰∏¶Êèê‰æõ‰∫ÜÂ∞áÂ∞àÂÆ∂Áü•Ë≠òËàáÊ©üÂô®Â≠∏ÁøíÊï¥ÂêàÁöÑÊñ∞ÊñπÊ≥ï„ÄÇÁõíÂ≠êÂ≠∏ÁöÑÁµêÊßãÂåñ„ÄÅÊ®°ÁµÑÂåñÊñπÊ≥ïÂú®ÈñãÁôºÂíåÂàÜÊûêÊ∑∑Âêà‰∫∫Â∑•Êô∫ÊÖßÁ≥ªÁµ±„ÄÅÊè≠Á§∫ÂÖ±ÊÄß‰ª•ÂèäÊé®Âª£ÂèØÈáçË§á‰ΩøÁî®ÁöÑËß£Ê±∫ÊñπÊ°àÊñπÈù¢ÂÖ∑ÊúâÈ°ØËëóÂÑ™Âã¢„ÄÇÁ∏Ω‰πãÔºåÊú¨Á†îÁ©∂Âº∑Ë™ø‰∫ÜÊ∑∑Âêà‰∫∫Â∑•Êô∫ÊÖßÁ≥ªÁµ±Âú®Êé®ÈÄ≤ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÁöÑÈóúÈçµ‰ΩúÁî®Ôºå‰ª•ÂèäÁõíÂ≠êÂ≠∏Âú®Êé®Âãï‰∫∫Â∑•Êô∫ÊÖßÊï¥ÂêàÈÄ≤‰∏ÄÊ≠•ÂâµÊñ∞ÊñπÈù¢ÁöÑÊΩõÂäõÔºåÊúÄÁµÇÊîπÂñÑËá®Â∫äÊ±∫Á≠ñÊîØÊè¥ÂíåÊÇ£ËÄÖÁöÑÊ≤ªÁôÇÊàêÊûú„ÄÇ

##### **Bayesian Kolmogorov Arnold Networks (Bayesian_KANs): A Probabilistic Approach to Enhance Accuracy and Interpretability**
2408.02706v1 by Masoud Muhammed Hassan

Because of its strong predictive skills, deep learning has emerged as an
essential tool in many industries, including healthcare. Traditional deep
learning models, on the other hand, frequently lack interpretability and omit
to take prediction uncertainty into account two crucial components of clinical
decision making. In order to produce explainable and uncertainty aware
predictions, this study presents a novel framework called Bayesian Kolmogorov
Arnold Networks (BKANs), which combines the expressive capacity of Kolmogorov
Arnold Networks with Bayesian inference. We employ BKANs on two medical
datasets, which are widely used benchmarks for assessing machine learning
models in medical diagnostics: the Pima Indians Diabetes dataset and the
Cleveland Heart Disease dataset. Our method provides useful insights into
prediction confidence and decision boundaries and outperforms traditional deep
learning models in terms of prediction accuracy. Moreover, BKANs' capacity to
represent aleatoric and epistemic uncertainty guarantees doctors receive more
solid and trustworthy decision support. Our Bayesian strategy improves the
interpretability of the model and considerably minimises overfitting, which is
important for tiny and imbalanced medical datasets, according to experimental
results. We present possible expansions to further use BKANs in more
complicated multimodal datasets and address the significance of these
discoveries for future research in building reliable AI systems for healthcare.
This work paves the way for a new paradigm in deep learning model deployment in
vital sectors where transparency and reliability are crucial.

ÊëòË¶ÅÔºöÁî±ÊñºÂÖ∂Âº∑Â§ßÁöÑÈ†êÊ∏¨ËÉΩÂäõÔºåÊ∑±Â∫¶Â≠∏ÁøíÂ∑≤ÊàêÁÇ∫Ë®±Â§öÁî¢Ê•≠‰∏≠‰∏çÂèØÊàñÁº∫ÁöÑÂ∑•ÂÖ∑ÔºåÂåÖÊã¨ÈÜ´ÁôÇ‰øùÂÅ•„ÄÇÁÑ∂ËÄåÔºåÂÇ≥Áµ±ÁöÑÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÈÄöÂ∏∏Áº∫‰πèÂèØËß£ÈáãÊÄßÔºå‰∏¶‰∏îÂøΩÁï•‰∫ÜÂ∞áÈ†êÊ∏¨‰∏çÁ¢∫ÂÆöÊÄßÁ¥çÂÖ•ËÄÉÈáèÔºåËÄåÈÄôÂÖ©ÂÄãÂõ†Á¥†ÊòØËá®Â∫äÊ±∫Á≠ñÂà∂ÂÆöÁöÑÈóúÈçµÁµÑÊàêÈÉ®ÂàÜ„ÄÇÁÇ∫‰∫ÜÁî¢ÁîüÂèØËß£Èáã‰∏îÂÖ∑Êúâ‰∏çÁ¢∫ÂÆöÊÄßÊÑèË≠òÁöÑÈ†êÊ∏¨ÔºåÊú¨Á†îÁ©∂ÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂêçÁÇ∫Ë≤ùÊ∞èÊüØÁàæËé´Âì•Ê¥õÂ§´ÈòøË´æÂæ∑Á∂≤Ë∑Ø (BKAN) ÁöÑÊñ∞Êû∂ÊßãÔºåÂÆÉÁµêÂêà‰∫ÜÊüØÁàæËé´Âì•Ê¥õÂ§´ÈòøË´æÂæ∑Á∂≤Ë∑ØÁöÑË°®ÈÅîËÉΩÂäõËàáË≤ùÊ∞èÊé®Ë´ñ„ÄÇÊàëÂÄëÂú®ÂÖ©ÂÄãÈÜ´Â≠∏Ë≥áÊñôÈõÜ‰∏ä‰ΩøÁî® BKANÔºåÈÄô‰∫õË≥áÊñôÈõÜÊòØË©ï‰º∞Ê©üÂô®Â≠∏ÁøíÊ®°ÂûãÂú®ÈÜ´Â≠∏Ë®∫Êñ∑‰∏≠ÁöÑÂª£Ê≥õ‰ΩøÁî®Âü∫Ê∫ñÔºöÁöÆÈ¶¨Âç∞Á¨¨ÂÆâ‰∫∫Á≥ñÂ∞øÁóÖË≥áÊñôÈõÜÂíåÂÖãÈáåÂ§´Ëò≠ÂøÉËáüÁóÖË≥áÊñôÈõÜ„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÊèê‰æõ‰∫ÜÂ∞çÈ†êÊ∏¨‰ø°ÂøÉÂíåÊ±∫Á≠ñÈÇäÁïåÁöÑÊúâÁõäË¶ãËß£Ôºå‰∏¶‰∏îÂú®È†êÊ∏¨Ê∫ñÁ¢∫Â∫¶ÊñπÈù¢ÂÑ™ÊñºÂÇ≥Áµ±ÁöÑÊ∑±Â∫¶Â≠∏ÁøíÊ®°Âûã„ÄÇÊ≠§Â§ñÔºåBKAN Ë°®ÁèæÈö®Ê©üÂíåË™çË≠ò‰∏çÁ¢∫ÂÆöÊÄßÁöÑËÉΩÂäõÔºåÂèØÁ¢∫‰øùÈÜ´ÁîüÁç≤ÂæóÊõ¥ÂèØÈù†‰∏îÂÄºÂæó‰ø°Ë≥¥ÁöÑÊ±∫Á≠ñÊîØÊè¥„ÄÇÊ†πÊìöÂØ¶È©óÁµêÊûúÔºåÊàëÂÄëÁöÑË≤ùÊ∞èÁ≠ñÁï•ÊèêÈ´ò‰∫ÜÊ®°ÂûãÁöÑÂèØËß£ÈáãÊÄßÔºå‰∏¶Â§ßÂπÖÊ∏õÂ∞ë‰∫ÜÈÅéÂ∫¶Êì¨ÂêàÔºåÈÄôÂ∞çÊñºÂ∞èÂûã‰∏î‰∏çÂπ≥Ë°°ÁöÑÈÜ´Â≠∏Ë≥áÊñôÈõÜÈùûÂ∏∏ÈáçË¶Å„ÄÇÊàëÂÄëÊèêÂá∫‰∫ÜÂèØËÉΩÁöÑÊì¥ÂÖÖÂäüËÉΩÔºå‰ª•ÈÄ≤‰∏ÄÊ≠•Â∞á BKAN Áî®ÊñºÊõ¥Ë§áÈõúÁöÑÂ§öÊ®°ÂºèË≥áÊñôÈõÜÔºå‰∏¶Êé¢Ë®éÈÄô‰∫õÁôºÁèæÂ∞çÊñºÊú™‰æÜÂª∫Á´ãÂèØÈù†ÁöÑÈÜ´ÁôÇ‰øùÂÅ• AI Á≥ªÁµ±Á†îÁ©∂ÁöÑÈáçË¶ÅÊÄß„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÁÇ∫Ê∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÈÉ®ÁΩ≤Âú®ÈÄèÊòéÂ∫¶ÂíåÂèØÈù†ÊÄßËá≥ÈóúÈáçË¶ÅÁöÑÈáçË¶ÅÈ†òÂüü‰∏≠ÈñãÂïü‰∫Ü‰∏ÄÂÄãÊñ∞ÁöÑÂÖ∏ÁØÑ„ÄÇ

##### **MLtoGAI: Semantic Web based with Machine Learning for Enhanced Disease Prediction and Personalized Recommendations using Generative AI**
2407.20284v1 by Shyam Dongre, Ritesh Chandra, Sonali Agarwal

In modern healthcare, addressing the complexities of accurate disease
prediction and personalized recommendations is both crucial and challenging.
This research introduces MLtoGAI, which integrates Semantic Web technology with
Machine Learning (ML) to enhance disease prediction and offer user-friendly
explanations through ChatGPT. The system comprises three key components: a
reusable disease ontology that incorporates detailed knowledge about various
diseases, a diagnostic classification model that uses patient symptoms to
detect specific diseases accurately, and the integration of Semantic Web Rule
Language (SWRL) with ontology and ChatGPT to generate clear, personalized
health advice. This approach significantly improves prediction accuracy and
ensures results that are easy to understand, addressing the complexity of
diseases and diverse symptoms. The MLtoGAI system demonstrates substantial
advancements in accuracy and user satisfaction, contributing to developing more
intelligent and accessible healthcare solutions. This innovative approach
combines the strengths of ML algorithms with the ability to provide
transparent, human-understandable explanations through ChatGPT, achieving
significant improvements in prediction accuracy and user comprehension. By
leveraging semantic technology and explainable AI, the system enhances the
accuracy of disease prediction and ensures that the recommendations are
relevant and easily understood by individual patients. Our research highlights
the potential of integrating advanced technologies to overcome existing
challenges in medical diagnostics, paving the way for future developments in
intelligent healthcare systems. Additionally, the system is validated using 200
synthetic patient data records, ensuring robust performance and reliability.

ÊëòË¶ÅÔºöÂú®Áèæ‰ª£ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÔºåËß£Ê±∫Ê∫ñÁ¢∫ÁñæÁóÖÈ†êÊ∏¨ÂíåÂÄãÊÄßÂåñÂª∫Ë≠∞ÁöÑË§áÈõúÊÄßÊó¢Ëá≥ÈóúÈáçË¶ÅÂèàÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÊú¨Á†îÁ©∂ÂºïÂÖ•‰∫Ü MLtoGAIÔºåÂÆÉÂ∞áË™ûÁæ©Á∂≤Ë∑ØÊäÄË°ìËàáÊ©üÂô®Â≠∏Áøí (ML) Áõ∏ÁµêÂêàÔºå‰ª•Â¢ûÂº∑ÁñæÁóÖÈ†êÊ∏¨‰∏¶ÈÄèÈÅé ChatGPT Êèê‰æõ‰ΩøÁî®ËÄÖÂèãÂñÑÁöÑË™™Êòé„ÄÇË©≤Á≥ªÁµ±ÂåÖÂê´‰∏âÂÄãÈóúÈçµÁµÑÊàêÈÉ®ÂàÜÔºö‰∏ÄÂÄãÂèØÈáçË§á‰ΩøÁî®ÁöÑÁñæÁóÖÊú¨‰ΩìÔºåÂÖ∂‰∏≠ÂåÖÂê´ÊúâÈóúÂêÑÁ®ÆÁñæÁóÖÁöÑË©≥Á¥∞Áü•Ë≠òÔºõ‰∏ÄÂÄãË®∫Êñ∑ÂàÜÈ°ûÊ®°ÂûãÔºåÂÆÉ‰ΩøÁî®ÊÇ£ËÄÖÁóáÁãÄ‰æÜÊ∫ñÁ¢∫Ê™¢Ê∏¨ÁâπÂÆöÁñæÁóÖÔºõ‰ª•ÂèäË™ûÁæ©Á∂≤Ë∑ØË¶èÂâáË™ûË®Ä (SWRL) ËàáÊú¨‰ΩìÂíå ChatGPT ÁöÑÊï¥ÂêàÔºå‰ª•Áî¢ÁîüÊ∏ÖÊô∞„ÄÅÂÄãÊÄßÂåñÁöÑÂÅ•Â∫∑Âª∫Ë≠∞„ÄÇÈÄôÁ®ÆÊñπÊ≥ïÈ°ØËëóÊèêÈ´ò‰∫ÜÈ†êÊ∏¨Ê∫ñÁ¢∫ÊÄßÔºå‰∏¶Á¢∫‰øù‰∫ÜÊòìÊñºÁêÜËß£ÁöÑÁµêÊûúÔºåËß£Ê±∫‰∫ÜÁñæÁóÖÂíå‰∏çÂêåÁóáÁãÄÁöÑË§áÈõúÊÄß„ÄÇMLtoGAI Á≥ªÁµ±Â±ïÁ§∫‰∫ÜÊ∫ñÁ¢∫ÊÄßÂíå‰ΩøÁî®ËÄÖÊªøÊÑèÂ∫¶ÁöÑÂØ¶Ë≥™ÊÄßÈÄ≤Ê≠•ÔºåÊúâÂä©ÊñºÈñãÁôºÊõ¥Êô∫ÊÖß‰∏îÊõ¥ÊòìÊñºÂèñÂæóÁöÑÈÜ´ÁôÇ‰øùÂÅ•Ëß£Ê±∫ÊñπÊ°à„ÄÇÈÄôÁ®ÆÂâµÊñ∞ÁöÑÊñπÊ≥ïÁµêÂêà‰∫Ü ML ÊºîÁÆóÊ≥ïÁöÑÂÑ™ÈªûÔºå‰ª•ÂèäÈÄèÈÅé ChatGPT Êèê‰æõÈÄèÊòé‰∏î‰∫∫È°ûÂèØ‰ª•ÁêÜËß£ÁöÑË™™ÊòéÁöÑËÉΩÂäõÔºåÂú®È†êÊ∏¨Ê∫ñÁ¢∫ÊÄßÂíå‰ΩøÁî®ËÄÖÁêÜËß£ÊñπÈù¢ÂèñÂæó‰∫ÜÈ°ØËëóÁöÑÈÄ≤Ê≠•„ÄÇÈÄèÈÅéÂà©Áî®Ë™ûÁæ©ÊäÄË°ìÂíåÂèØËß£ÈáãÁöÑ AIÔºåË©≤Á≥ªÁµ±ÊèêÈ´ò‰∫ÜÁñæÁóÖÈ†êÊ∏¨ÁöÑÊ∫ñÁ¢∫ÊÄßÔºå‰∏¶Á¢∫‰øù‰∫ÜÂª∫Ë≠∞ËàáÂÄãÂà•ÊÇ£ËÄÖÁõ∏Èóú‰∏îÊòìÊñºÁêÜËß£„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂Âº∑Ë™ø‰∫ÜÊï¥ÂêàÂÖàÈÄ≤ÊäÄË°ì‰ª•ÂÖãÊúçÈÜ´ÁôÇË®∫Êñ∑‰∏≠ÁèæÊúâÊåëÊà∞ÁöÑÊΩõÂäõÔºåÁÇ∫Êô∫ÊÖßÈÜ´ÁôÇ‰øùÂÅ•Á≥ªÁµ±ÁöÑÊú™‰æÜÁôºÂ±ïÈã™Ë∑Ø„ÄÇÊ≠§Â§ñÔºåË©≤Á≥ªÁµ±‰ΩøÁî® 200 ÂÄãÂêàÊàêÊÇ£ËÄÖË≥áÊñôË®òÈåÑÈÄ≤Ë°åÈ©óË≠âÔºåÁ¢∫‰øù‰∫ÜÁ©©ÂÅ•ÁöÑÊïàËÉΩÂíåÂèØÈù†ÊÄß„ÄÇ

##### **Introducing Œ¥-XAI: a novel sensitivity-based method for local AI explanations**
2407.18343v2 by Alessandro De Carlo, Enea Parimbelli, Nicola Melillo, Giovanna Nicora

Explainable Artificial Intelligence (XAI) is central to the debate on
integrating Artificial Intelligence (AI) and Machine Learning (ML) algorithms
into clinical practice. High-performing AI/ML models, such as ensemble learners
and deep neural networks, often lack interpretability, hampering clinicians'
trust in their predictions. To address this, XAI techniques are being developed
to describe AI/ML predictions in human-understandable terms. One promising
direction is the adaptation of sensitivity analysis (SA) and global sensitivity
analysis (GSA), which inherently rank model inputs by their impact on
predictions. Here, we introduce a novel delta-XAI method that provides local
explanations of ML model predictions by extending the delta index, a GSA
metric. The delta-XAI index assesses the impact of each feature's value on the
predicted output for individual instances in both regression and classification
problems. We formalize the delta-XAI index and provide code for its
implementation. The delta-XAI method was evaluated on simulated scenarios using
linear regression models, with Shapley values serving as a benchmark. Results
showed that the delta-XAI index is generally consistent with Shapley values,
with notable discrepancies in models with highly impactful or extreme feature
values. The delta-XAI index demonstrated higher sensitivity in detecting
dominant features and handling extreme feature values. Qualitatively, the
delta-XAI provides intuitive explanations by leveraging probability density
functions, making feature rankings clearer and more explainable for
practitioners. Overall, the delta-XAI method appears promising for robustly
obtaining local explanations of ML model predictions. Further investigations in
real-world clinical settings will be conducted to evaluate its impact on
AI-assisted clinical workflows.

ÊëòË¶ÅÔºöÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖß (XAI) ÊòØÂ∞á‰∫∫Â∑•Êô∫ÊÖß (AI) ÂíåÊ©üÂô®Â≠∏Áøí (ML) ÊºîÁÆóÊ≥ïÊï¥ÂêàÂà∞Ëá®Â∫äÂØ¶Âãô‰∏≠ÁöÑËæØË´ñÊ†∏ÂøÉ„ÄÇÈ´òÂü∑Ë°åÊïàËÉΩÁöÑ AI/ML Ê®°ÂûãÔºå‰æãÂ¶ÇÊï¥È´îÂ≠∏ÁøíÂô®ÂíåÊ∑±Â∫¶Á•ûÁ∂ìÁ∂≤Ë∑ØÔºåÈÄöÂ∏∏Áº∫‰πèÂèØËß£ÈáãÊÄßÔºåÈòªÁ§ôËá®Â∫äÈÜ´ÁîüÂ∞çÂÖ∂È†êÊ∏¨ÁöÑ‰ø°‰ªª„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊ≠£Âú®ÈñãÁôº XAI ÊäÄË°ìÔºå‰ª•‰∫∫È°ûÂèØ‰ª•ÁêÜËß£ÁöÑË°ìË™ûÊèèËø∞ AI/ML È†êÊ∏¨„ÄÇ‰∏ÄÂÄãÊúâÂ∏åÊúõÁöÑÊñπÂêëÊòØÊé°Áî®ÊïèÊÑüÂ∫¶ÂàÜÊûê (SA) ÂíåÂÖ®ÁêÉÊïèÊÑüÂ∫¶ÂàÜÊûê (GSA)ÔºåÂÆÉÂÄëÊú¨Ë≥™‰∏äÊúÉ‰æùÊìöÊ®°ÂûãËº∏ÂÖ•Â∞çÈ†êÊ∏¨ÁöÑÂΩ±Èüø‰æÜÂ∞çÂÖ∂ÈÄ≤Ë°åÊéíÂêç„ÄÇÂú®Ê≠§ÔºåÊàëÂÄë‰ªãÁ¥π‰∏ÄÁ®ÆÊñ∞ÁöÑ delta-XAI ÊñπÊ≥ïÔºåÈÄèÈÅéÊì¥ÂÖÖ GSA ÊåáÊ®ô delta ÊåáÊï∏‰æÜÊèê‰æõ ML Ê®°ÂûãÈ†êÊ∏¨ÁöÑÂ±ÄÈÉ®Ëß£Èáã„ÄÇdelta-XAI ÊåáÊï∏Ë©ï‰º∞ÊØèÂÄãÁâπÂæµÂÄºÂ∞çÂõûÊ≠∏ÂíåÂàÜÈ°ûÂïèÈ°å‰∏≠ÂÄãÂà•‰æãÈ†ÖÁöÑÈ†êÊ∏¨Ëº∏Âá∫‰πãÂΩ±Èüø„ÄÇÊàëÂÄëÂ∞á delta-XAI ÊåáÊï∏ÂΩ¢ÂºèÂåñÔºå‰∏¶Êèê‰æõÂÖ∂ÂØ¶‰ΩúÁöÑÁ®ãÂºèÁ¢º„ÄÇ‰ΩøÁî®Á∑öÊÄßÂõûÊ≠∏Ê®°ÂûãÂ∞çÊ®°Êì¨ÊÉÖÂ¢ÉË©ï‰º∞ delta-XAI ÊñπÊ≥ïÔºå‰∏¶‰ª• Shapley ÂÄº‰ΩúÁÇ∫Âü∫Ê∫ñ„ÄÇÁµêÊûúÈ°ØÁ§∫ delta-XAI ÊåáÊï∏ÈÄöÂ∏∏Ëàá Shapley ÂÄº‰∏ÄËá¥Ôºå‰ΩÜÂú®ÂÖ∑ÊúâÈ´òÂ∫¶ÂΩ±ÈüøÂäõÊàñÊ•µÁ´ØÁâπÂæµÂÄºÁöÑÊ®°Âûã‰∏≠Â≠òÂú®È°ØËëóÂ∑ÆÁï∞„ÄÇdelta-XAI ÊåáÊï∏Âú®ÂÅµÊ∏¨‰∏ªË¶ÅÁâπÂæµÂíåËôïÁêÜÊ•µÁ´ØÁâπÂæµÂÄºÊñπÈù¢Ë°®ÁèæÂá∫Êõ¥È´òÁöÑÊïèÊÑüÂ∫¶„ÄÇÂÆöÊÄßÂú∞‰æÜË™™Ôºådelta-XAI ÈÄèÈÅéÂà©Áî®Ê©üÁéáÂØÜÂ∫¶ÂáΩÊï∏Êèê‰æõÁõ¥ËßÄÁöÑËß£ÈáãÔºå‰ΩøÁâπÂæµÊéíÂêçÊõ¥Ê∏ÖÊô∞‰∏îÂ∞çÂæûÊ•≠‰∫∫Âì°‰æÜË™™Êõ¥ÂÖ∑ÂèØËß£ÈáãÊÄß„ÄÇÁ∏ΩÈ´îËÄåË®ÄÔºådelta-XAI ÊñπÊ≥ïÂ∞çÊñºÁ©©ÂÅ•Âú∞ÂèñÂæó ML Ê®°ÂûãÈ†êÊ∏¨ÁöÑÂ±ÄÈÉ®Ëß£Èáã‰ºº‰πéÂæàÊúâÂ∏åÊúõ„ÄÇÂ∞áÂú®ÁúüÂØ¶‰∏ñÁïåÁöÑËá®Â∫äÁí∞Â¢É‰∏≠ÈÄ≤Ë°åÈÄ≤‰∏ÄÊ≠•Ë™øÊü•Ôºå‰ª•Ë©ï‰º∞ÂÖ∂Â∞ç AI ËºîÂä©Ëá®Â∫äÂ∑•‰ΩúÊµÅÁ®ãÁöÑÂΩ±Èüø„ÄÇ

##### **Enhanced Deep Learning Methodologies and MRI Selection Techniques for Dementia Diagnosis in the Elderly Population**
2407.17324v2 by Nikolaos Ntampakis, Konstantinos Diamantaras, Ioanna Chouvarda, Vasileios Argyriou, Panagiotis Sarigianndis

Dementia, a debilitating neurological condition affecting millions worldwide,
presents significant diagnostic challenges. In this work, we introduce a novel
methodology for the classification of demented and non-demented elderly
patients using 3D brain Magnetic Resonance Imaging (MRI) scans. Our approach
features a unique technique for selectively processing MRI slices, focusing on
the most relevant brain regions and excluding less informative sections. This
methodology is complemented by a confidence-based classification committee
composed of three custom deep learning models: Dem3D ResNet, Dem3D CNN, and
Dem3D EfficientNet. These models work synergistically to enhance
decision-making accuracy, leveraging their collective strengths. Tested on the
Open Access Series of Imaging Studies(OASIS) dataset, our method achieved an
impressive accuracy of 94.12%, surpassing existing methodologies. Furthermore,
validation on the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset
confirmed the robustness and generalizability of our approach. The use of
explainable AI (XAI) techniques and comprehensive ablation studies further
substantiate the effectiveness of our techniques, providing insights into the
decision-making process and the importance of our methodology. This research
offers a significant advancement in dementia diagnosis, providing a highly
accurate and efficient tool for clinical applications.

ÊëòË¶ÅÔºöÂ§±Êô∫ÁóáÊòØ‰∏ÄÁ®ÆÂΩ±ÈüøÂÖ®ÁêÉÊï∏ÁôæËê¨‰∫∫ÁöÑË°∞Âº±ÊÄßÁ•ûÁ∂ìÁñæÁóÖÔºåÂú®Ë®∫Êñ∑‰∏äÂÖ∑ÊúâÈáçÂ§ßÊåëÊà∞„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞ÁöÑÊñπÊ≥ïÔºåÁî®ÊñºÂ∞çÂ§±Êô∫ÂíåÈùûÂ§±Êô∫ËÄÅÂπ¥ÊÇ£ËÄÖÈÄ≤Ë°åÂàÜÈ°ûÔºå‰ΩøÁî® 3D Â§ßËÖ¶Á£ÅÊåØÈÄ†ÂΩ± (MRI) ÊéÉÊèè„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÊé°Áî®‰∫Ü‰∏ÄÁ®ÆÁç®ÁâπÊäÄË°ìÔºåÁî®ÊñºÈÅ∏ÊìáÊÄßËôïÁêÜ MRI ÂàáÁâáÔºåÈáçÈªûÈóúÊ≥®ÊúÄÁõ∏ÈóúÁöÑÂ§ßËÖ¶ÂçÄÂüüÔºå‰∏¶ÊéíÈô§‰ø°ÊÅØÈáèËºÉÂ∞ëÁöÑÈÉ®ÂàÜ„ÄÇÈÄôÁ®ÆÊñπÊ≥ïÁî±‰∏ÄÂÄãÂü∫Êñº‰ø°ÂøÉÁöÑÂàÜÈ°ûÂßîÂì°ÊúÉË£úÂÖÖÔºåË©≤ÂßîÂì°ÊúÉÁî±‰∏âÂÄãËá™ÂÆöÁæ©Ê∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÁµÑÊàêÔºöDem3D ResNet„ÄÅDem3D CNN Âíå Dem3D EfficientNet„ÄÇÈÄô‰∫õÊ®°ÂûãÂçîÂêåÂ∑•‰Ωú‰ª•Â¢ûÂº∑Ê±∫Á≠ñÁöÑÊ∫ñÁ¢∫ÊÄßÔºåÂà©Áî®ÂÆÉÂÄëÁöÑÈõÜÈ´îÂÑ™Âã¢„ÄÇÂú®ÂΩ±ÂÉèÁ†îÁ©∂ÈñãÊîæÂ≠òÂèñÁ≥ªÂàó (OASIS) Ë≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÊ∏¨Ë©¶ÔºåÊàëÂÄëÁöÑÊ®°ÂûãÈÅîÂà∞‰∫Ü 94.12% ÁöÑÈ©ö‰∫∫Ê∫ñÁ¢∫Â∫¶ÔºåË∂ÖÈÅé‰∫ÜÁèæÊúâÊñπÊ≥ï„ÄÇÊ≠§Â§ñÔºåÂú®ÈòøËå≤Êµ∑ÈªòÁóáÁ•ûÁ∂ìÂΩ±ÂÉèÂÄ°Ë≠∞ (ADNI) Ë≥áÊñôÈõÜ‰∏äÁöÑÈ©óË≠âË≠âÂØ¶‰∫ÜÊàëÂÄëÊñπÊ≥ïÁöÑÁ©©ÂÅ•ÊÄßÂíåÊôÆÈÅçÊÄß„ÄÇÂèØËß£Èáã AI (XAI) ÊäÄË°ìÂíåÂÖ®Èù¢ÁöÑÊ∂àËûçÁ†îÁ©∂ÈÄ≤‰∏ÄÊ≠•Ë≠âÂØ¶‰∫ÜÊàëÂÄëÊäÄË°ìÁöÑÊúâÊïàÊÄßÔºåÊèê‰æõ‰∫ÜÂ∞çÊ±∫Á≠ñÈÅéÁ®ãÂíåÊàëÂÄëÊñπÊ≥ïÈáçË¶ÅÊÄßÁöÑË¶ãËß£„ÄÇÈÄôÈ†ÖÁ†îÁ©∂ÁÇ∫Â§±Êô∫ÁóáË®∫Êñ∑Êèê‰æõ‰∫ÜÈáçÂ§ßÈÄ≤Â±ïÔºåÁÇ∫Ëá®Â∫äÊáâÁî®Êèê‰æõ‰∫Ü‰∏ÄÂÄãÈ´òÂ∫¶Ê∫ñÁ¢∫‰∏îÈ´òÊïàÁöÑÂ∑•ÂÖ∑„ÄÇ

##### **Using Large Language Models to Compare Explainable Models for Smart Home Human Activity Recognition**
2408.06352v1 by Michele Fiori, Gabriele Civitarese, Claudio Bettini

Recognizing daily activities with unobtrusive sensors in smart environments
enables various healthcare applications. Monitoring how subjects perform
activities at home and their changes over time can reveal early symptoms of
health issues, such as cognitive decline. Most approaches in this field use
deep learning models, which are often seen as black boxes mapping sensor data
to activities. However, non-expert users like clinicians need to trust and
understand these models' outputs. Thus, eXplainable AI (XAI) methods for Human
Activity Recognition have emerged to provide intuitive natural language
explanations from these models. Different XAI methods generate different
explanations, and their effectiveness is typically evaluated through user
surveys, that are often challenging in terms of costs and fairness. This paper
proposes an automatic evaluation method using Large Language Models (LLMs) to
identify, in a pool of candidates, the best XAI approach for non-expert users.
Our preliminary results suggest that LLM evaluation aligns with user surveys.

ÊëòË¶ÅÔºöËóâÁî±Êô∫ÊÖßÁí∞Â¢É‰∏≠‰∏çÂºï‰∫∫Ê≥®ÁõÆÁöÑÊÑüÊ∏¨Âô®Ëæ®Ë≠òÊó•Â∏∏Ê¥ªÂãïÔºåËÉΩÂïüÁî®ÂêÑÁ®ÆÈÜ´ÁôÇ‰øùÂÅ•ÊáâÁî®„ÄÇÁõ£ÊéßÂèóË©¶ËÄÖÂú®ÂÆ∂‰∏≠Â¶Ç‰ΩïÂü∑Ë°åÊ¥ªÂãïÔºå‰ª•ÂèäÂÖ∂Èö®ËëóÊôÇÈñìÁöÑËÆäÂåñÔºåÂèØ‰ª•Êè≠Á§∫ÂÅ•Â∫∑ÂïèÈ°åÁöÑÊó©ÊúüÁóáÁãÄÔºå‰æãÂ¶ÇË™çÁü•ËÉΩÂäõ‰∏ãÈôç„ÄÇÊ≠§È†òÂüü‰∏≠ÁöÑÂ§ßÂ§öÊï∏ÊñπÊ≥ïÈÉΩ‰ΩøÁî®Ê∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÔºåÈÄô‰∫õÊ®°ÂûãÈÄöÂ∏∏Ë¢´Ë¶ñÁÇ∫Â∞áÊÑüÊ∏¨Âô®Ë≥áÊñôÂ∞çÊáâËá≥Ê¥ªÂãïÁöÑÈªëÁõíÂ≠ê„ÄÇÁÑ∂ËÄåÔºåÈùûÂ∞àÂÆ∂‰ΩøÁî®ËÄÖÔºà‰æãÂ¶ÇËá®Â∫äÈÜ´Â∏´ÔºâÈúÄË¶Å‰ø°‰ªª‰∏¶‰∫ÜËß£ÈÄô‰∫õÊ®°ÂûãÁöÑËº∏Âá∫„ÄÇÂõ†Ê≠§Ôºå‰∫∫È°ûÊ¥ªÂãïËæ®Ë≠òÁöÑÂèØËß£Èáã AI (XAI) ÊñπÊ≥ïÊáâÈÅãËÄåÁîüÔºå‰ª•Êèê‰æõ‰æÜËá™ÈÄô‰∫õÊ®°ÂûãÁöÑÁõ¥Ë¶∫Ëá™ÁÑ∂Ë™ûË®ÄË™™Êòé„ÄÇ‰∏çÂêåÁöÑ XAI ÊñπÊ≥ïÊúÉÁî¢Áîü‰∏çÂêåÁöÑË™™ÊòéÔºåËÄåÂÖ∂ÊúâÊïàÊÄßÈÄöÂ∏∏ÈÄèÈÅé‰ΩøÁî®ËÄÖË™øÊü•‰æÜË©ï‰º∞ÔºåÈÄôÂú®ÊàêÊú¨ÂíåÂÖ¨Âπ≥ÊÄßÊñπÈù¢ÈÄöÂ∏∏ÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÊú¨ÊñáÊèêÂá∫‰ΩøÁî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑËá™ÂãïË©ï‰º∞ÊñπÊ≥ïÔºå‰ª•Âú®ÂÄôÈÅ∏ËÄÖ‰∏≠ÊâæÂá∫ÊúÄÈÅ©ÂêàÈùûÂ∞àÂÆ∂‰ΩøÁî®ËÄÖÁöÑ XAI ÊñπÊ≥ï„ÄÇÊàëÂÄëÁöÑÂàùÊ≠•ÁµêÊûúË°®ÊòéÔºåLLM Ë©ï‰º∞Ëàá‰ΩøÁî®ËÄÖË™øÊü•‰∏ÄËá¥„ÄÇ

##### **Explainable AI-based Intrusion Detection System for Industry 5.0: An Overview of the Literature, associated Challenges, the existing Solutions, and Potential Research Directions**
2408.03335v1 by Naseem Khan, Kashif Ahmad, Aref Al Tamimi, Mohammed M. Alani, Amine Bermak, Issa Khalil

Industry 5.0, which focuses on human and Artificial Intelligence (AI)
collaboration for performing different tasks in manufacturing, involves a
higher number of robots, Internet of Things (IoTs) devices and
interconnections, Augmented/Virtual Reality (AR), and other smart devices. The
huge involvement of these devices and interconnection in various critical
areas, such as economy, health, education and defense systems, poses several
types of potential security flaws. AI itself has been proven a very effective
and powerful tool in different areas of cybersecurity, such as intrusion
detection, malware detection, and phishing detection, among others. Just as in
many application areas, cybersecurity professionals were reluctant to accept
black-box ML solutions for cybersecurity applications. This reluctance pushed
forward the adoption of eXplainable Artificial Intelligence (XAI) as a tool
that helps explain how decisions are made in ML-based systems. In this survey,
we present a comprehensive study of different XAI-based intrusion detection
systems for industry 5.0, and we also examine the impact of explainability and
interpretability on Cybersecurity practices through the lens of Adversarial
XIDS (Adv-XIDS) approaches. Furthermore, we analyze the possible opportunities
and challenges in XAI cybersecurity systems for industry 5.0 that elicit future
research toward XAI-based solutions to be adopted by high-stakes industry 5.0
applications. We believe this rigorous analysis will establish a foundational
framework for subsequent research endeavors within the specified domain.

ÊëòË¶ÅÔºöÂ∑•Ê•≠ 5.0 ËëóÈáçÊñº‰∫∫È°ûËàá‰∫∫Â∑•Êô∫ÊÖß (AI) Âêà‰ΩúÂü∑Ë°åË£ΩÈÄ†‰∏≠ÁöÑ‰∏çÂêå‰ªªÂãôÔºåÊ∂âÂèäÊõ¥Â§öÊ©üÂô®‰∫∫„ÄÅÁâ©ËÅØÁ∂≤ (IoT) Ë£ùÁΩÆÂíå‰∫íÈÄ£„ÄÅÊì¥Â¢û/ËôõÊì¨ÂØ¶Â¢É (AR) ÂíåÂÖ∂‰ªñÊô∫ÊÖßË£ùÁΩÆ„ÄÇÈÄô‰∫õË£ùÁΩÆÂíå‰∫íÈÄ£Âú®Á∂ìÊøü„ÄÅÈÜ´ÁôÇ‰øùÂÅ•„ÄÅÊïôËÇ≤ÂíåÂúãÈò≤Á≥ªÁµ±Á≠âÂêÑÁ®ÆÈóúÈçµÈ†òÂüüÁöÑÂª£Ê≥õÂèÉËàáÔºåÂºïÁôº‰∫ÜÂ§öÁ®ÆÈ°ûÂûãÁöÑÊΩõÂú®ÂÆâÂÖ®ÊºèÊ¥û„ÄÇAI Êú¨Ë∫´Â∑≤Ë¢´Ë≠âÊòéÊòØÁ∂≤Ë∑ØÂÆâÂÖ®‰∏çÂêåÈ†òÂüü‰∏≠ÈùûÂ∏∏ÊúâÊïà‰∏îÂº∑Â§ßÁöÑÂ∑•ÂÖ∑Ôºå‰æãÂ¶ÇÂÖ•‰æµÂÅµÊ∏¨„ÄÅÊÉ°ÊÑèËªüÈ´îÂÅµÊ∏¨ÂíåÁ∂≤Ë∑ØÈá£È≠öÂÅµÊ∏¨Á≠â„ÄÇÂ∞±ÂÉèÂú®Ë®±Â§öÊáâÁî®È†òÂüü‰∏ÄÊ®£ÔºåÁ∂≤Ë∑ØÂÆâÂÖ®Â∞àÊ•≠‰∫∫Âì°‰∏çÈ°òÊÑèÊé•ÂèóÈªëÁõí ML Ëß£Ê±∫ÊñπÊ°à‰æÜÊáâÁî®ÊñºÁ∂≤Ë∑ØÂÆâÂÖ®„ÄÇÈÄôÁ®Æ‰∏çÈ°òÊÑè‰øÉ‰ΩøÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖß (XAI) ‰ΩúÁÇ∫‰∏ÄÁ®ÆÂ∑•ÂÖ∑Ë¢´Êé°Áî®ÔºåÊúâÂä©ÊñºË™™ÊòéÂú®Âü∫Êñº ML ÁöÑÁ≥ªÁµ±‰∏≠Â¶Ç‰ΩïÂÅöÂá∫Ê±∫Á≠ñ„ÄÇÂú®ÈÄôÈ†ÖË™øÊü•‰∏≠ÔºåÊàëÂÄëÂ∞çÂ∑•Ê•≠ 5.0 ÁöÑ‰∏çÂêåÂü∫Êñº XAI ÁöÑÂÖ•‰æµÂÅµÊ∏¨Á≥ªÁµ±ÈÄ≤Ë°å‰∫ÜÂÖ®Èù¢ÁöÑÁ†îÁ©∂Ôºå‰∏¶‰∏îÊàëÂÄë‰πüÈÄèÈÅéÂ∞çÊäóÂºè XIDS (Adv-XIDS) ÊñπÊ≥ïÁöÑËßÄÈªû‰æÜÊé¢Ë®éÂèØËß£ÈáãÊÄßÂíåÂèØË©ÆÈáãÊÄßÂ∞çÁ∂≤Ë∑ØÂÆâÂÖ®ÂØ¶ÂãôÁöÑÂΩ±Èüø„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂàÜÊûê‰∫ÜÂ∑•Ê•≠ 5.0 ÁöÑ XAI Á∂≤Ë∑ØÂÆâÂÖ®Á≥ªÁµ±‰∏≠ÂèØËÉΩÂ≠òÂú®ÁöÑÊ©üÊúÉÂíåÊåëÊà∞ÔºåÂºïÁôº‰∫ÜÊú™‰æÜÈáùÂ∞ç XAI Âü∫Á§éËß£Ê±∫ÊñπÊ°àÁöÑÁ†îÁ©∂Ôºå‰ª•‰æõÈ´òÈ¢®Èö™ÁöÑÂ∑•Ê•≠ 5.0 ÊáâÁî®Êé°Áî®„ÄÇÊàëÂÄëÁõ∏‰ø°ÈÄôÈ†ÖÂö¥Ë¨πÁöÑÂàÜÊûêÂ∞áÁÇ∫ÊåáÂÆöÈ†òÂüüÂÖßÁöÑÂæåÁ∫åÁ†îÁ©∂Â∑•‰ΩúÂª∫Á´ãÂü∫Á§éÊû∂Êßã„ÄÇ

##### **A Comparative Study on Automatic Coding of Medical Letters with Explainability**
2407.13638v1 by Jamie Glen, Lifeng Han, Paul Rayson, Goran Nenadic

This study aims to explore the implementation of Natural Language Processing
(NLP) and machine learning (ML) techniques to automate the coding of medical
letters with visualised explainability and light-weighted local computer
settings. Currently in clinical settings, coding is a manual process that
involves assigning codes to each condition, procedure, and medication in a
patient's paperwork (e.g., 56265001 heart disease using SNOMED CT code). There
are preliminary research on automatic coding in this field using
state-of-the-art ML models; however, due to the complexity and size of the
models, the real-world deployment is not achieved. To further facilitate the
possibility of automatic coding practice, we explore some solutions in a local
computer setting; in addition, we explore the function of explainability for
transparency of AI models. We used the publicly available MIMIC-III database
and the HAN/HLAN network models for ICD code prediction purposes. We also
experimented with the mapping between ICD and SNOMED CT knowledge bases. In our
experiments, the models provided useful information for 97.98\% of codes. The
result of this investigation can shed some light on implementing automatic
clinical coding in practice, such as in hospital settings, on the local
computers used by clinicians , project page
\url{https://github.com/Glenj01/Medical-Coding}.

ÊëòË¶ÅÔºöÊú¨Á†îÁ©∂Êó®Âú®Êé¢Ë®éÂ∞áËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ (NLP) ÂíåÊ©üÂô®Â≠∏Áøí (ML) ÊäÄË°ìÂØ¶‰ΩúÊñºÈÜ´ÁôÇ‰ø°ÂáΩÁ∑®Á¢ºËá™ÂãïÂåñÔºå‰∏¶ÂÖ∑ÂÇôË¶ñË¶∫ÂåñË™™ÊòéËÉΩÂäõÂíåËºïÈáèÂåñÁöÑÊú¨Âú∞ÈõªËÖ¶Ë®≠ÂÆö„ÄÇÁõÆÂâçÂú®Ëá®Â∫äÁí∞Â¢É‰∏≠ÔºåÁ∑®Á¢ºÊòØ‰∏ÄÁ®ÆÊâãÂãïÊµÅÁ®ãÔºåÊ∂âÂèäÁÇ∫ÁóÖÊÇ£Êñá‰ª∂‰∏≠ÁöÑÊØèÈ†ÖÁóÖÁóá„ÄÅÁ®ãÂ∫èÂíåËó•Áâ©ÊåáÊ¥æ‰ª£Á¢º (‰æãÂ¶ÇÔºå‰ΩøÁî® SNOMED CT ‰ª£Á¢º 56265001 Ë°®Á§∫ÂøÉËáüÁóÖ)„ÄÇÊ≠§È†òÂüüÊúâ‰ΩøÁî®ÊúÄÊñ∞ ML Ê®°ÂûãÈÄ≤Ë°åËá™ÂãïÁ∑®Á¢ºÁöÑÂàùÊ≠•Á†îÁ©∂ÔºõÁÑ∂ËÄåÔºåÁî±ÊñºÊ®°ÂûãÁöÑË§áÈõúÊÄßÂíåÂ§ßÂ∞èÔºå‰∏¶Êú™ÂØ¶ÁèæÂØ¶ÈöõÈÉ®ÁΩ≤„ÄÇÁÇ∫‰∫ÜÈÄ≤‰∏ÄÊ≠•‰øÉÈÄ≤Ëá™ÂãïÁ∑®Á¢ºÂØ¶ÂãôÁöÑÂèØËÉΩÊÄßÔºåÊàëÂÄëÂú®Êú¨Âú∞ÈõªËÖ¶Ë®≠ÂÆö‰∏≠Êé¢Ë®é‰∫Ü‰∏Ä‰∫õËß£Ê±∫ÊñπÊ°àÔºõÊ≠§Â§ñÔºåÊàëÂÄëÊé¢Ë®é‰∫ÜË™™ÊòéÂäüËÉΩÂú® AI Ê®°ÂûãÈÄèÊòéÂ∫¶‰∏≠ÁöÑÂäüËÉΩ„ÄÇÊàëÂÄë‰ΩøÁî®ÂÖ¨ÈñãÁöÑ MIMIC-III Ë≥áÊñôÂ∫´Âíå HAN/HLAN Á∂≤Ë∑ØÊ®°ÂûãÈÄ≤Ë°å ICD ‰ª£Á¢ºÈ†êÊ∏¨„ÄÇÊàëÂÄëÈÇÑË©¶È©ó‰∫Ü ICD Âíå SNOMED CT Áü•Ë≠òÂ∫´‰πãÈñìÁöÑÂ∞çÊáâ„ÄÇÂú®ÊàëÂÄëÁöÑÂØ¶È©ó‰∏≠ÔºåÈÄô‰∫õÊ®°ÂûãÊèê‰æõ‰∫Ü 97.98% ‰ª£Á¢ºÁöÑÊúâÁî®Ë≥áË®ä„ÄÇÈÄôÈ†ÖË™øÊü•ÁµêÊûúÂèØ‰ª•ÁÇ∫ÂØ¶Âãô‰∏≠ÁöÑËá™ÂãïËá®Â∫äÁ∑®Á¢ºÂØ¶‰ΩúÊèê‰æõ‰∏Ä‰∫õË¶ãËß£Ôºå‰æãÂ¶ÇÂú®ÈÜ´Èô¢Áí∞Â¢É‰∏≠ÔºåÁî±Ëá®Â∫äÈÜ´Áîü‰ΩøÁî®ÁöÑÊú¨Âú∞ÈõªËÖ¶ÔºåÂ∞àÊ°àÈ†ÅÈù¢ \url{https://github.com/Glenj01/Medical-Coding}„ÄÇ

##### **Explainable AI for Enhancing Efficiency of DL-based Channel Estimation**
2407.07009v1 by Abdul Karim Gizzini, Yahia Medjahdi, Ali J. Ghandour, Laurent Clavier

The support of artificial intelligence (AI) based decision-making is a key
element in future 6G networks, where the concept of native AI will be
introduced. Moreover, AI is widely employed in different critical applications
such as autonomous driving and medical diagnosis. In such applications, using
AI as black-box models is risky and challenging. Hence, it is crucial to
understand and trust the decisions taken by these models. Tackling this issue
can be achieved by developing explainable AI (XAI) schemes that aim to explain
the logic behind the black-box model behavior, and thus, ensure its efficient
and safe deployment. Recently, we proposed a novel perturbation-based XAI-CHEST
framework that is oriented toward channel estimation in wireless
communications. The core idea of the XAI-CHEST framework is to identify the
relevant model inputs by inducing high noise on the irrelevant ones. This
manuscript provides the detailed theoretical foundations of the XAI-CHEST
framework. In particular, we derive the analytical expressions of the XAI-CHEST
loss functions and the noise threshold fine-tuning optimization problem. Hence
the designed XAI-CHEST delivers a smart input feature selection methodology
that can further improve the overall performance while optimizing the
architecture of the employed model. Simulation results show that the XAI-CHEST
framework provides valid interpretations, where it offers an improved bit error
rate performance while reducing the required computational complexity in
comparison to the classical DL-based channel estimation.

ÊëòË¶ÅÔºö‰∫∫Â∑•Êô∫ËÉΩ (AI) ÊîØÊåÅÁöÑÊ±∫Á≠ñÂà∂ÂÆöÊòØÊú™‰æÜ 6G Á∂≤Ë∑Ø‰∏≠ÁöÑÈóúÈçµÂÖÉÁ¥†ÔºåÂÖ∂‰∏≠Â∞áÂºïÂÖ•ÂéüÁîü AI ÁöÑÊ¶ÇÂøµ„ÄÇÊ≠§Â§ñÔºåAI Âª£Ê≥õÁî®Êñº‰∏çÂêåÁöÑÈóúÈçµÊáâÁî®‰∏≠Ôºå‰æãÂ¶ÇËá™ÂãïÈßïÈßõÂíåÈÜ´ÁôÇË®∫Êñ∑„ÄÇÂú®ÈÄô‰∫õÊáâÁî®‰∏≠Ôºå‰ΩøÁî® AI ‰ΩúÁÇ∫ÈªëÁõíÊ®°ÂûãÊòØÊúâÈ¢®Èö™‰∏îÂÖ∑ÊúâÊåëÊà∞ÊÄßÁöÑ„ÄÇÂõ†Ê≠§ÔºåÁêÜËß£Âíå‰ø°‰ªªÈÄô‰∫õÊ®°ÂûãÂÅöÂá∫ÁöÑÊ±∫Á≠ñËá≥ÈóúÈáçË¶Å„ÄÇËß£Ê±∫Ê≠§ÂïèÈ°åÁöÑÊñπÊ≥ïÊòØÈñãÁôºÂèØËß£Èáã AI (XAI) Êû∂ÊßãÔºåÊó®Âú®Ëß£ÈáãÈªëÁõíÊ®°ÂûãË°åÁÇ∫ËÉåÂæåÁöÑÈÇèËºØÔºåÂæûËÄåÁ¢∫‰øùÂÖ∂ÊúâÊïà‰∏îÂÆâÂÖ®ÁöÑÈÉ®ÁΩ≤„ÄÇÊúÄËøëÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊñ∞ÁöÑÂü∫ÊñºÊìæÂãïÁöÑ XAI-CHEST Ê°ÜÊû∂ÔºåË©≤Ê°ÜÊû∂Èù¢ÂêëÁÑ°Á∑öÈÄö‰ø°‰∏≠ÁöÑ‰ø°ÈÅì‰º∞Ë®à„ÄÇXAI-CHEST Ê°ÜÊû∂ÁöÑÊ†∏ÂøÉÊÄùÊÉ≥ÊòØÈÄöÈÅéÂú®ÁÑ°ÈóúËº∏ÂÖ•‰∏äÂºïÂÖ•È´òÂô™ËÅ≤‰æÜË≠òÂà•Áõ∏ÈóúÊ®°ÂûãËº∏ÂÖ•„ÄÇÈÄô‰ªΩÊâãÁ®øÊèê‰æõ‰∫Ü XAI-CHEST Ê°ÜÊû∂ÁöÑË©≥Á¥∞ÁêÜË´ñÂü∫Á§é„ÄÇÁâπÂà•ÊòØÔºåÊàëÂÄëÊé®Â∞é‰∫Ü XAI-CHEST ÊêçÂ§±ÂáΩÊï∏ÂíåÂô™ËÅ≤ÈñæÂÄºÂæÆË™øÂÑ™ÂåñÂïèÈ°åÁöÑËß£ÊûêË°®ÈÅîÂºè„ÄÇÂõ†Ê≠§ÔºåË®≠Ë®àÁöÑ XAI-CHEST Êèê‰æõ‰∫Ü‰∏ÄÁ®ÆÊô∫ËÉΩËº∏ÂÖ•ÁâπÂæµÈÅ∏ÊìáÊñπÊ≥ïÔºåÂèØ‰ª•Âú®ÂÑ™ÂåñÊâÄÁî®Ê®°ÂûãÁöÑÊû∂ÊßãÁöÑÂêåÊôÇÈÄ≤‰∏ÄÊ≠•ÊèêÈ´òÊï¥È´îÊÄßËÉΩ„ÄÇÊ®°Êì¨ÁµêÊûúË°®ÊòéÔºåXAI-CHEST Ê°ÜÊû∂Êèê‰æõ‰∫ÜÊúâÊïàÁöÑËß£ÈáãÔºåÂú®Èôç‰ΩéÊâÄÈúÄÁöÑË®àÁÆóË§áÈõúÂ∫¶ÁöÑÂêåÊôÇÔºåÊèê‰æõ‰∫ÜÊîπÈÄ≤ÁöÑÊØîÁâπÈåØË™§ÁéáÊÄßËÉΩÔºåËÄåÈÄôËàáÂü∫ÊñºÂÇ≥Áµ± DL ÁöÑ‰ø°ÈÅì‰º∞Ë®àÁõ∏ÊØî„ÄÇ

##### **Explainable AI: Comparative Analysis of Normal and Dilated ResNet Models for Fundus Disease Classification**
2407.05440v1 by P. N. Karthikayan, Yoga Sri Varshan V, Hitesh Gupta Kattamuri, Umarani Jayaraman

This paper presents dilated Residual Network (ResNet) models for disease
classification from retinal fundus images. Dilated convolution filters are used
to replace normal convolution filters in the higher layers of the ResNet model
(dilated ResNet) in order to improve the receptive field compared to the normal
ResNet model for disease classification. This study introduces
computer-assisted diagnostic tools that employ deep learning, enhanced with
explainable AI techniques. These techniques aim to make the tool's
decision-making process transparent, thereby enabling medical professionals to
understand and trust the AI's diagnostic decision. They are particularly
relevant in today's healthcare landscape, where there is a growing demand for
transparency in AI applications to ensure their reliability and ethical use.
The dilated ResNet is used as a replacement for the normal ResNet to enhance
the classification accuracy of retinal eye diseases and reduce the required
computing time. The dataset used in this work is the Ocular Disease Intelligent
Recognition (ODIR) dataset which is a structured ophthalmic database with eight
classes covering most of the common retinal eye diseases. The evaluation
metrics used in this work include precision, recall, accuracy, and F1 score. In
this work, a comparative study has been made between normal ResNet models and
dilated ResNet models on five variants namely ResNet-18, ResNet-34, ResNet-50,
ResNet-101, and ResNet-152. The dilated ResNet model shows promising results as
compared to normal ResNet with an average F1 score of 0.71, 0.70, 0.69, 0.67,
and 0.70 respectively for the above respective variants in ODIR multiclass
disease classification.

ÊëòË¶ÅÔºö<paragraph>Êú¨ÊñáÊèêÂá∫‰∫ÜÁî®‰∫éËßÜÁΩëËÜúÁúºÂ∫ïÂõæÂÉèÁñæÁóÖÂàÜÁ±ªÁöÑÊâ©Âº†ÊÆãÂ∑ÆÁΩëÁªú (ResNet) Ê®°Âûã„ÄÇÊâ©Âº†Âç∑ÁßØÊª§Ê≥¢Âô®Áî®‰∫éÊõøÊç¢ ResNet Ê®°ÂûãËæÉÈ´òÂ±Ç‰∏≠ÁöÑÊ≠£Â∏∏Âç∑ÁßØÊª§Ê≥¢Âô®ÔºàÊâ©Âº† ResNetÔºâÔºå‰ª•ÊîπÂñÑ‰∏éÁî®‰∫éÁñæÁóÖÂàÜÁ±ªÁöÑÊ≠£Â∏∏ ResNet Ê®°ÂûãÁõ∏ÊØîÁöÑÊÑüÂèóÈáé„ÄÇÊú¨Á†îÁ©∂‰ªãÁªç‰∫ÜÈááÁî®Ê∑±Â∫¶Â≠¶‰π†ÁöÑËÆ°ÁÆóÊú∫ËæÖÂä©ËØäÊñ≠Â∑•ÂÖ∑ÔºåÂπ∂ÈÄöËøáÂèØËß£ÈáäÁöÑ AI ÊäÄÊúØËøõË°å‰∫ÜÂ¢ûÂº∫„ÄÇËøô‰∫õÊäÄÊúØÊó®Âú®‰ΩøËØ•Â∑•ÂÖ∑ÁöÑÂÜ≥Á≠ñËøáÁ®ãÈÄèÊòéÂåñÔºå‰ªéËÄå‰ΩøÂåªÁñó‰∏ì‰∏ö‰∫∫ÂëòËÉΩÂ§üÁêÜËß£Âíå‰ø°‰ªª AI ÁöÑËØäÊñ≠ÂÜ≥Á≠ñ„ÄÇÂÆÉ‰ª¨Âú®ÂΩì‰ªäÂåªÁñó‰øùÂÅ•È¢ÜÂüüÂ∞§‰∏∫ÈáçË¶ÅÔºåÂõ†‰∏∫ÂØπ AI Â∫îÁî®Á®ãÂ∫èÁöÑÈÄèÊòéÂ∫¶ÈúÄÊ±Ç‰∏çÊñ≠Â¢ûÈïøÔºå‰ª•Á°Æ‰øùÂÖ∂ÂèØÈù†ÊÄßÂíåÈÅìÂæ∑‰ΩøÁî®„ÄÇÊâ©Âº† ResNet Áî®‰ΩúÊ≠£Â∏∏ ResNet ÁöÑÊõø‰ª£ÂìÅÔºå‰ª•ÊèêÈ´òËßÜÁΩëËÜúÁúºÁóÖÁöÑÂàÜÁ±ªÂáÜÁ°ÆÊÄßÂπ∂ÂáèÂ∞ëÊâÄÈúÄÁöÑËÆ°ÁÆóÊó∂Èó¥„ÄÇÊú¨Â∑•‰Ωú‰∏≠‰ΩøÁî®ÁöÑÊï∞ÊçÆÈõÜÊòØ Ocular Disease Intelligent Recognition (ODIR) Êï∞ÊçÆÈõÜÔºåËøôÊòØ‰∏Ä‰∏™ÁªìÊûÑÂåñÁöÑÁúºÁßëÊï∞ÊçÆÂ∫ìÔºåÂåÖÂê´ÂÖ´Á±ªÊ∂µÁõñÂ§ßÂ§öÊï∞Â∏∏ËßÅËßÜÁΩëËÜúÁúºÁóÖ„ÄÇÊú¨Â∑•‰Ωú‰∏≠‰ΩøÁî®ÁöÑËØÑ‰º∞ÊåáÊ†áÂåÖÊã¨Á≤æÁ°ÆÂ∫¶„ÄÅÂè¨ÂõûÁéá„ÄÅÂáÜÁ°ÆÂ∫¶Âíå F1 ÂàÜÊï∞„ÄÇÂú®ËøôÈ°πÂ∑•‰Ωú‰∏≠ÔºåÂØπÊ≠£Â∏∏ ResNet Ê®°ÂûãÂíåÊâ©Âº† ResNet Ê®°ÂûãÂú®‰∫î‰∏™Âèò‰ΩìÔºàÂç≥ ResNet-18„ÄÅResNet-34„ÄÅResNet-50„ÄÅResNet-101 Âíå ResNet-152Ôºâ‰πãÈó¥ËøõË°å‰∫ÜÊØîËæÉÁ†îÁ©∂„ÄÇ‰∏éÊ≠£Â∏∏ ResNet Áõ∏ÊØîÔºåÊâ©Âº† ResNet Ê®°ÂûãÊòæÁ§∫Âá∫ÊúâÂ∏åÊúõÁöÑÁªìÊûúÔºåÂú® ODIR Â§öÁ±ªÁñæÁóÖÂàÜÁ±ª‰∏≠Ôºå‰∏äËø∞ÂêÑ‰∏™Âèò‰ΩìÁöÑÂπ≥Âùá F1 ÂàÜÊï∞ÂàÜÂà´‰∏∫ 0.71„ÄÅ0.70„ÄÅ0.69„ÄÅ0.67 Âíå 0.70„ÄÇ</paragraph>

##### **A Survey on Trustworthiness in Foundation Models for Medical Image Analysis**
2407.15851v1 by Congzhen Shi, Ryan Rezai, Jiaxi Yang, Qi Dou, Xiaoxiao Li

The rapid advancement of foundation models in medical imaging represents a
significant leap toward enhancing diagnostic accuracy and personalized
treatment. However, the deployment of foundation models in healthcare
necessitates a rigorous examination of their trustworthiness, encompassing
privacy, robustness, reliability, explainability, and fairness. The current
body of survey literature on foundation models in medical imaging reveals
considerable gaps, particularly in the area of trustworthiness. Additionally,
extant surveys on the trustworthiness of foundation models fail to address
their specific variations and applications within the medical imaging domain.
This survey paper reviews the current research on foundation models in the
major medical imaging applications, with a focus on segmentation, medical
report generation, medical question and answering (Q&A), and disease diagnosis,
which includes trustworthiness discussion in their manuscripts. We explore the
complex challenges of making foundation models for medical image analysis
trustworthy, associated with each application, and summarize the current
concerns and strategies to enhance trustworthiness. Furthermore, we explore the
future promises of these models in revolutionizing patient care. Our analysis
underscores the imperative for advancing towards trustworthy AI in medical
image analysis, advocating for a balanced approach that fosters innovation
while ensuring ethical and equitable healthcare delivery.

ÊëòË¶ÅÔºöÂü∫Á§éÊ®°ÂûãÂú®ÈÜ´Â≠∏ÂΩ±ÂÉè‰∏äÁöÑÂø´ÈÄüÈÄ≤Â±ï‰ª£Ë°®ËëóÂú®Â¢ûÂº∑Ë®∫Êñ∑Ê∫ñÁ¢∫Â∫¶ÂíåÂÄã‰∫∫ÂåñÊ≤ªÁôÇÊñπÈù¢ÈÇÅÂá∫‰∫Ü‰∏ÄÂ§ßÊ≠•„ÄÇÁÑ∂ËÄåÔºåÂü∫Á§éÊ®°ÂûãÂú®ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÁöÑÈÉ®ÁΩ≤ÈúÄË¶ÅÂö¥Ê†ºÊ™¢Êü•ÂÖ∂ÂèØ‰ø°Â∫¶ÔºåÂåÖÊã¨Èö±ÁßÅ„ÄÅÁ©©ÂÅ•ÊÄß„ÄÅÂèØÈù†ÊÄß„ÄÅÂèØËß£ÈáãÊÄßÂíåÂÖ¨Âπ≥ÊÄß„ÄÇÁï∂ÂâçÈóúÊñºÈÜ´Â≠∏ÂΩ±ÂÉè‰∏≠Âü∫Á§éÊ®°ÂûãÁöÑË™øÊü•ÊñáÁçªÈ°ØÁ§∫Âá∫Áõ∏Áï∂Â§ßÁöÑÂ∑ÆË∑ùÔºåÁâπÂà•ÊòØÂú®ÂèØ‰ø°Â∫¶ÊñπÈù¢„ÄÇÊ≠§Â§ñÔºåÁèæÊúâÁöÑÈóúÊñºÂü∫Á§éÊ®°ÂûãÂèØ‰ø°Â∫¶ÁöÑË™øÊü•Êú™ËÉΩËß£Ê±∫ÂÖ∂Âú®ÈÜ´Â≠∏ÂΩ±ÂÉèÈ†òÂüüÂÖßÁöÑÂÖ∑È´îËÆäÂåñÂíåÊáâÁî®„ÄÇÈÄôÁØáË™øÊü•Ë´ñÊñáÂõûÈ°ß‰∫ÜÁï∂ÂâçÈóúÊñºÂü∫Á§éÊ®°ÂûãÂú®‰∏ªË¶ÅÈÜ´Â≠∏ÂΩ±ÂÉèÊáâÁî®‰∏≠ÁöÑÁ†îÁ©∂ÔºåÈáçÈªûÈóúÊ≥®ÂàÜÂâ≤„ÄÅÈÜ´ÁôÇÂ†±ÂëäÁîüÊàê„ÄÅÈÜ´ÁôÇÂïèÈ°åÂíåËß£Á≠î (Q&A) ‰ª•ÂèäÁñæÁóÖË®∫Êñ∑ÔºåÂÖ∂‰∏≠ÂåÖÊã¨ÊâãÁ®ø‰∏≠ÁöÑÂèØ‰ø°Â∫¶Ë®éË´ñ„ÄÇÊàëÂÄëÊé¢Ë®é‰∫ÜËÆìÁî®ÊñºÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÊûêÁöÑÂü∫Á§éÊ®°ÂûãÂÄºÂæó‰ø°Ë≥¥ÁöÑË§áÈõúÊåëÊà∞ÔºåËàáÊØèÂÄãÊáâÁî®Áõ∏ÈóúÔºå‰∏¶Á∏ΩÁµê‰∫ÜÁï∂ÂâçÊèêÈ´òÂèØ‰ø°Â∫¶ÁöÑÂïèÈ°åÂíåÁ≠ñÁï•„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊé¢Ë®é‰∫ÜÈÄô‰∫õÊ®°ÂûãÂú®Èù©Êñ∞ÊÇ£ËÄÖÁÖßË≠∑ÊñπÈù¢ÁöÑÊú™‰æÜÂâçÊôØ„ÄÇÊàëÂÄëÁöÑÂàÜÊûêÂº∑Ë™ø‰∫ÜÂú®ÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÊûê‰∏≠ÊúùËëóÂèØ‰ø°Ë≥¥ÁöÑ‰∫∫Â∑•Êô∫ÊÖßÈÇÅÈÄ≤ÁöÑÂøÖË¶ÅÊÄßÔºåÊèêÂÄ°‰∏ÄÁ®ÆÂπ≥Ë°°ÁöÑÊñπÊ≥ïÔºåÊó¢ËÉΩ‰øÉÈÄ≤ÂâµÊñ∞ÔºåÂèàËÉΩÁ¢∫‰øùÈÅìÂæ∑ÂíåÂÖ¨Âπ≥ÁöÑÈÜ´ÁôÇ‰øùÂÅ•ÊúçÂãô„ÄÇ

##### **The Impact of an XAI-Augmented Approach on Binary Classification with Scarce Data**
2407.06206v1 by Ximing Wen, Rosina O. Weber, Anik Sen, Darryl Hannan, Steven C. Nesbit, Vincent Chan, Alberto Goffi, Michael Morris, John C. Hunninghake, Nicholas E. Villalobos, Edward Kim, Christopher J. MacLellan

Point-of-Care Ultrasound (POCUS) is the practice of clinicians conducting and
interpreting ultrasound scans right at the patient's bedside. However, the
expertise needed to interpret these images is considerable and may not always
be present in emergency situations. This reality makes algorithms such as
machine learning classifiers extremely valuable to augment human decisions.
POCUS devices are becoming available at a reasonable cost in the size of a
mobile phone. The challenge of turning POCUS devices into life-saving tools is
that interpretation of ultrasound images requires specialist training and
experience. Unfortunately, the difficulty to obtain positive training images
represents an important obstacle to building efficient and accurate
classifiers. Hence, the problem we try to investigate is how to explore
strategies to increase accuracy of classifiers trained with scarce data. We
hypothesize that training with a few data instances may not suffice for
classifiers to generalize causing them to overfit. Our approach uses an
Explainable AI-Augmented approach to help the algorithm learn more from less
and potentially help the classifier better generalize.

ÊëòË¶ÅÔºöÂ∫äÈÇäË∂ÖÈü≥Ê≥¢ (POCUS) ÊòØËá®Â∫äÈÜ´Â∏´Âú®ÊÇ£ËÄÖÂ∫äÈÇäÈÄ≤Ë°åÂíåËß£ËÆÄË∂ÖÈü≥Ê≥¢ÊéÉÊèèÁöÑÂØ¶Âãô„ÄÇÁÑ∂ËÄåÔºåËß£ËÆÄÈÄô‰∫õÂΩ±ÂÉèÊâÄÈúÄÁöÑÂ∞àÊ•≠Áü•Ë≠òÁõ∏Áï∂ÂèØËßÄÔºåËÄå‰∏îÂú®Á∑äÊÄ•ÊÉÖÊ≥Å‰∏ãÂèØËÉΩ‰∏¶ÈùûÈö®ÊôÇÂÖ∑ÂÇô„ÄÇÈÄôÁ®ÆÁèæÂØ¶ÊÉÖÊ≥Å‰ΩøÂæóÊ©üÂô®Â≠∏ÁøíÂàÜÈ°ûÂô®Á≠âÊºîÁÆóÊ≥ïÂ∞çÊñºÂä†Âº∑‰∫∫È°ûÊ±∫Á≠ñËÆäÂæóÊ•µÁÇ∫ÊúâÂÉπÂÄº„ÄÇPOCUS Ë£ùÁΩÆÊ≠£‰ª•ÂêàÁêÜÊàêÊú¨Êé®Âá∫ÔºåÂ∞∫ÂØ∏ÁÇ∫ÊâãÊ©üÂ§ßÂ∞è„ÄÇÂ∞á POCUS Ë£ùÁΩÆËΩâËÆäÁÇ∫ÊïëÁîüÂ∑•ÂÖ∑ÁöÑÊåëÊà∞Âú®ÊñºÔºåËß£ËÆÄË∂ÖÈü≥Ê≥¢ÂΩ±ÂÉèÈúÄË¶ÅÂ∞àÈñÄË®ìÁ∑¥ÂíåÁ∂ìÈ©ó„ÄÇ‰∏çÂπ∏ÁöÑÊòØÔºåÂèñÂæóÊ≠£ÂêëË®ìÁ∑¥ÂΩ±ÂÉèÁöÑÂõ∞Èõ£Â∫¶‰ª£Ë°®ËëóÂª∫ÁΩÆÊúâÊïàÁéá‰∏îÊ∫ñÁ¢∫ÁöÑÂàÜÈ°ûÂô®ÁöÑ‰∏ÄÂ§ßÈöúÁ§ô„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëÂòóË©¶Êé¢Ë®éÁöÑÂïèÈ°åÊòØÂ¶Ç‰ΩïÊé¢Á¥¢Á≠ñÁï•Ôºå‰ª•ÊèêÈ´ò‰ΩøÁî®Á®ÄÁñèË≥áÊñôË®ìÁ∑¥ÁöÑÂàÜÈ°ûÂô®ÁöÑÊ∫ñÁ¢∫Â∫¶„ÄÇÊàëÂÄëÂÅáË®≠‰ΩøÁî®Â∞ëÊï∏Ë≥áÊñôÂØ¶‰æãÈÄ≤Ë°åË®ìÁ∑¥ÂèØËÉΩ‰∏çË∂≥‰ª•ËÆìÂàÜÈ°ûÂô®Ê¶ÇÊã¨ÔºåÂ∞éËá¥ÂÆÉÂÄëÈÅéÂ∫¶Êì¨Âêà„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ï‰ΩøÁî®ÂèØËß£Èáã AI Â¢ûÂº∑ÊñπÊ≥ïÔºå‰ª•ÂçîÂä©ÊºîÁÆóÊ≥ïÂæûËºÉÂ∞ëÁöÑË≥áÊñô‰∏≠Â≠∏ÁøíÊõ¥Â§öÔºå‰∏¶ÊΩõÂú®ÂçîÂä©ÂàÜÈ°ûÂô®Êõ¥Â•ΩÂú∞Ê¶ÇÊã¨„ÄÇ

##### **Can GPT-4 Help Detect Quit Vaping Intentions? An Exploration of Automatic Data Annotation Approach**
2407.00167v1 by Sai Krishna Revanth Vuruma, Dezhi Wu, Saborny Sen Gupta, Lucas Aust, Valerie Lookingbill, Wyatt Bellamy, Yang Ren, Erin Kasson, Li-Shiun Chen, Patricia Cavazos-Rehg, Dian Hu, Ming Huang

In recent years, the United States has witnessed a significant surge in the
popularity of vaping or e-cigarette use, leading to a notable rise in cases of
e-cigarette and vaping use-associated lung injury (EVALI) that caused
hospitalizations and fatalities during the EVALI outbreak in 2019, highlighting
the urgency to comprehend vaping behaviors and develop effective strategies for
cessation. Due to the ubiquity of social media platforms, over 4.7 billion
users worldwide use them for connectivity, communications, news, and
entertainment with a significant portion of the discourse related to health,
thereby establishing social media data as an invaluable organic data resource
for public health research. In this study, we extracted a sample dataset from
one vaping sub-community on Reddit to analyze users' quit-vaping intentions.
Leveraging OpenAI's latest large language model GPT-4 for sentence-level quit
vaping intention detection, this study compares the outcomes of this model
against layman and clinical expert annotations. Using different prompting
strategies such as zero-shot, one-shot, few-shot and chain-of-thought
prompting, we developed 8 prompts with varying levels of detail to explain the
task to GPT-4 and also evaluated the performance of the strategies against each
other. These preliminary findings emphasize the potential of GPT-4 in social
media data analysis, especially in identifying users' subtle intentions that
may elude human detection.

ÊëòË¶ÅÔºöËøëÂπ¥‰æÜÔºåÁæéÂúãË¶ãË≠â‰∫ÜÈõªÂ≠êÁÖôÊàñÈõªÂ≠êÈ¶ôËè∏‰ΩøÁî®ÁéáÂ§ßÂπÖÊøÄÂ¢ûÔºåÂ∞éËá¥ÈõªÂ≠êÁÖôÂíåÈõªÂ≠êÁÖô‰ΩøÁî®Áõ∏ÈóúËÇ∫ÊêçÂÇ∑ (EVALI) ÁóÖ‰æãÈ°ØËëóÂ¢ûÂä†ÔºåÂú® 2019 Âπ¥ EVALI ÁàÜÁôºÊúüÈñìÈÄ†Êàê‰ΩèÈô¢ÂíåÊ≠ª‰∫°ÔºåÂá∏È°Ø‰∫ÜÁêÜËß£ÈõªÂ≠êÁÖôË°åÁÇ∫ÂíåÂà∂ÂÆöÊúâÊïàÊàíËè∏Á≠ñÁï•ÁöÑËø´ÂàáÊÄß„ÄÇÁî±ÊñºÁ§æÁæ§Â™íÈ´îÂπ≥Âè∞ÁöÑÊôÆÂèäÔºåÂÖ®ÁêÉË∂ÖÈÅé 47 ÂÑÑ‰ΩøÁî®ËÄÖ‰ΩøÁî®ÂÆÉÂÄëÈÄ≤Ë°åÈÄ£Áµê„ÄÅÊ∫ùÈÄö„ÄÅÊñ∞ËÅûÂíåÂ®õÊ®ÇÔºåÂÖ∂‰∏≠ÂæàÂ§ß‰∏ÄÈÉ®ÂàÜËàáÂÅ•Â∫∑Áõ∏ÈóúÔºåÂõ†Ê≠§Â∞áÁ§æÁæ§Â™íÈ´îË≥áÊñôÂª∫Á´ãÁÇ∫ÂÖ¨ÂÖ±Ë°õÁîüÁ†îÁ©∂‰∏≠ÁÑ°ÂÉπÁöÑÊúâÊ©üË≥áÊñôË≥áÊ∫ê„ÄÇÂú®Êú¨Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëÂæû Reddit ‰∏ä‰∏ÄÂÄãÈõªÂ≠êÁÖôÂ≠êÁ§æÁæ§‰∏≠ÊèêÂèñ‰∏ÄÂÄãÁØÑ‰æãË≥áÊñôÈõÜÔºå‰ª•ÂàÜÊûê‰ΩøÁî®ËÄÖÁöÑÊàíÈõªÂ≠êÁÖôÊÑèÂúñ„ÄÇÂà©Áî® OpenAI ÊúÄÊñ∞ÁöÑÂ§ßÂûãË™ûË®ÄÊ®°Âûã GPT-4 ÈÄ≤Ë°åÂè•Â≠êÂ±§Á¥öÁöÑÊàíÈõªÂ≠êÁÖôÊÑèÂúñÂÅµÊ∏¨ÔºåÊú¨Á†îÁ©∂ÊØîËºÉ‰∫ÜÊ≠§Ê®°ÂûãÁöÑÁµêÊûúËàáÂ§ñË°å‰∫∫ÂíåËá®Â∫äÂ∞àÂÆ∂Ë®ªËß£„ÄÇ‰ΩøÁî®‰∏çÂêåÁöÑÊèêÁ§∫Á≠ñÁï•Ôºå‰æãÂ¶ÇÈõ∂Ê¨°Â≠∏Áøí„ÄÅ‰∏ÄÊ¨°Â≠∏Áøí„ÄÅÂ∞ëÊ¨°Â≠∏ÁøíÂíåÊÄùËÄÉÈèàÊèêÁ§∫ÔºåÊàëÂÄëÈñãÁôº‰∫Ü 8 ÂÄãÊèêÁ§∫ÔºåË©≥Á¥∞Á®ãÂ∫¶‰∏çÂêåÔºåÂêë GPT-4 Ëß£Èáã‰ªªÂãôÔºå‰∏¶Ë©ï‰º∞ÈÄô‰∫õÁ≠ñÁï•ÂΩºÊ≠§‰πãÈñìÁöÑÊïàËÉΩ„ÄÇÈÄô‰∫õÂàùÊ≠•ÁôºÁèæÂº∑Ë™ø‰∫Ü GPT-4 Âú®Á§æÁæ§Â™íÈ´îË≥áÊñôÂàÜÊûê‰∏≠ÁöÑÊΩõÂäõÔºåÁâπÂà•ÊòØÂú®Ë≠òÂà•‰∫∫È°ûÂÅµÊ∏¨ÂèØËÉΩÁÑ°Ê≥ïÂØüË¶∫ÁöÑ‰ΩøÁî®ËÄÖÂæÆÂ¶ôÊÑèÂúñÊñπÈù¢„ÄÇ

##### **Towards Compositional Interpretability for XAI**
2406.17583v1 by Sean Tull, Robin Lorenz, Stephen Clark, Ilyas Khan, Bob Coecke

Artificial intelligence (AI) is currently based largely on black-box machine
learning models which lack interpretability. The field of eXplainable AI (XAI)
strives to address this major concern, being critical in high-stakes areas such
as the finance, legal and health sectors.
  We present an approach to defining AI models and their interpretability based
on category theory. For this we employ the notion of a compositional model,
which sees a model in terms of formal string diagrams which capture its
abstract structure together with its concrete implementation. This
comprehensive view incorporates deterministic, probabilistic and quantum
models. We compare a wide range of AI models as compositional models, including
linear and rule-based models, (recurrent) neural networks, transformers, VAEs,
and causal and DisCoCirc models.
  Next we give a definition of interpretation of a model in terms of its
compositional structure, demonstrating how to analyse the interpretability of a
model, and using this to clarify common themes in XAI. We find that what makes
the standard 'intrinsically interpretable' models so transparent is brought out
most clearly diagrammatically. This leads us to the more general notion of
compositionally-interpretable (CI) models, which additionally include, for
instance, causal, conceptual space, and DisCoCirc models.
  We next demonstrate the explainability benefits of CI models. Firstly, their
compositional structure may allow the computation of other quantities of
interest, and may facilitate inference from the model to the modelled
phenomenon by matching its structure. Secondly, they allow for diagrammatic
explanations for their behaviour, based on influence constraints, diagram
surgery and rewrite explanations. Finally, we discuss many future directions
for the approach, raising the question of how to learn such meaningfully
structured models in practice.

ÊëòË¶ÅÔºö<paragraph>‰∫∫Â∑•Êô∫ÊÖßÔºàAIÔºâÁõÆÂâçÂú®ÂæàÂ§ßÁ®ãÂ∫¶‰∏ä‰æùË≥¥ÊñºÁº∫‰πèÂèØËß£ÈáãÊÄßÁöÑÈªëÁõíÊ©üÂô®Â≠∏ÁøíÊ®°Âûã„ÄÇÂèØËß£ÈáãÊÄß‰∫∫Â∑•Êô∫ÊÖßÔºàXAIÔºâÈ†òÂüüËá¥ÂäõÊñºËß£Ê±∫ÈÄôÂÄã‰∏ªË¶ÅÂïèÈ°åÔºåÈÄôÂú®ÈáëËûç„ÄÅÊ≥ïÂæãÂíåÂÅ•Â∫∑Á≠âÈ´òÈ¢®Èö™È†òÂüüËá≥ÈóúÈáçË¶Å„ÄÇ
ÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂü∫ÊñºÁØÑÁñáË´ñÂÆöÁæ© AI Ê®°ÂûãÂèäÂÖ∂ÂèØËß£ÈáãÊÄßÁöÑÊñπÊ≥ï„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÊé°Áî®ÁµÑÂêàÊ®°ÂûãÁöÑÊ¶ÇÂøµÔºåÂÆÉ‰ª•ÂΩ¢ÂºèÂº¶ÂúñÁöÑÂΩ¢ÂºèÁúãÂæÖÊ®°ÂûãÔºåÈÄô‰∫õÂº¶ÂúñÊçïÁç≤‰∫ÜÊ®°ÂûãÁöÑÊäΩË±°ÁµêÊßãÂèäÂÖ∂ÂÖ∑È´îÂØ¶Áèæ„ÄÇÈÄôÁ®ÆÁ∂úÂêàËßÄÈªûÂåÖÂê´‰∫ÜÁ¢∫ÂÆöÊÄß„ÄÅÊ¶ÇÁéáÊÄßÂíåÈáèÂ≠êÊ®°Âûã„ÄÇÊàëÂÄëÂ∞áÂêÑÁ®Æ AI Ê®°Âûã‰ΩúÁÇ∫ÁµÑÂêàÊ®°ÂûãÈÄ≤Ë°åÊØîËºÉÔºåÂåÖÊã¨Á∑öÊÄßÂíåÂü∫ÊñºË¶èÂâáÁöÑÊ®°Âûã„ÄÅÔºàÈÅûËø¥ÔºâÁ•ûÁ∂ìÁ∂≤Ë∑Ø„ÄÅTransformer„ÄÅVAEÔºå‰ª•ÂèäÂõ†ÊûúÂíå DisCoCirc Ê®°Âûã„ÄÇ
Êé•‰∏ã‰æÜÔºåÊàëÂÄëÊ†πÊìöÊ®°ÂûãÁöÑÁµÑÂêàÁµêÊßãÁµ¶Âá∫Ê®°ÂûãËß£ÈáãÁöÑÂÆöÁæ©ÔºåÂ±ïÁ§∫Â¶Ç‰ΩïÂàÜÊûêÊ®°ÂûãÁöÑÂèØËß£ÈáãÊÄßÔºå‰∏¶‰ΩøÁî®ÂÆÉ‰æÜÊæÑÊ∏Ö XAI ‰∏≠ÁöÑÂ∏∏Ë¶ã‰∏ªÈ°å„ÄÇÊàëÂÄëÁôºÁèæÔºåËÆìÊ®ôÊ∫ñÁöÑ„ÄåÂÖßÂú®ÂèØËß£Èáã„ÄçÊ®°ÂûãÂ¶ÇÊ≠§ÈÄèÊòéÁöÑÂéüÂõ†Âú®ÂúñË°®‰∏≠Ë°®ÁèæÂæóÊúÄÁÇ∫Ê∏ÖÊ•ö„ÄÇÈÄôÂºïÂ∞éÊàëÂÄëÂæóÂá∫Êõ¥‰∏ÄËà¨ÁöÑÁµÑÂêàÂèØËß£ÈáãÔºàCIÔºâÊ®°ÂûãÊ¶ÇÂøµÔºåÂÆÉÂè¶Â§ñÈÇÑÂåÖÊã¨Âõ†Êûú„ÄÅÊ¶ÇÂøµÁ©∫ÈñìÂíå DisCoCirc Ê®°Âûã„ÄÇ
Êé•‰∏ã‰æÜÔºåÊàëÂÄëÂ±ïÁ§∫‰∫Ü CI Ê®°ÂûãÁöÑÂèØËß£ÈáãÊÄßÂÑ™Âã¢„ÄÇÈ¶ñÂÖàÔºåÂÆÉÂÄëÁöÑÁµÑÂêàÁµêÊßãÂÖÅË®±Ë®àÁÆóÂÖ∂‰ªñÊÑüËààË∂£ÁöÑÈáèÔºå‰∏¶ÂèØËÉΩÈÄöÈÅéÂåπÈÖçÊ®°ÂûãÁöÑÁµêÊßã‰æÜ‰øÉÈÄ≤ÂæûÊ®°ÂûãÂà∞Ë¢´Âª∫Ê®°ÁèæË±°ÁöÑÊé®ÁêÜ„ÄÇÂÖ∂Ê¨°ÔºåÂÆÉÂÄëÂÖÅË®±Â∞çÂÖ∂Ë°åÁÇ∫ÈÄ≤Ë°åÂúñËß£Ë™™ÊòéÔºåÈÄô‰∫õË™™ÊòéÂü∫ÊñºÂΩ±ÈüøÁ¥ÑÊùü„ÄÅÂúñËß£ÊâãË°ìÂíåÈáçÂØ´Ë™™Êòé„ÄÇÊúÄÂæåÔºåÊàëÂÄëË®éË´ñ‰∫ÜÈÄôÁ®ÆÊñπÊ≥ïÁöÑË®±Â§öÊú™‰æÜÊñπÂêëÔºåÊèêÂá∫‰∫ÜÂ¶Ç‰ΩïÂú®ÂØ¶Ë∏ê‰∏≠Â≠∏ÁøíÈÄôÁ®ÆÊúâÊÑèÁæ©ÁöÑÁµêÊßãÂåñÊ®°ÂûãÁöÑÂïèÈ°å„ÄÇ</paragraph>

##### **Unlocking the Potential of Metaverse in Innovative and Immersive Digital Health**
2406.07114v2 by Fatemeh Ebrahimzadeh, Ramin Safa

The concept of Metaverse has attracted a lot of attention in various fields
and one of its important applications is health and treatment. The Metaverse
has enormous potential to transform healthcare by changing patient care,
medical education, and the way teaching/learning and research are done. The
purpose of this research is to provide an introduction to the basic concepts
and fundamental technologies of the Metaverse. This paper examines the pros and
cons of the Metaverse in healthcare context and analyzes its potential from the
technology and AI perspective. In particular, the role of machine learning
methods is discussed; We will explain how machine learning algorithms can be
applied to the Metaverse generated data to gain better insights in healthcare
applications. Additionally, we examine the future visions of the Metaverse in
health delivery, by examining emerging technologies such as blockchain and also
addressing privacy concerns. The findings of this study contribute to a deeper
understanding of the applications of Metaverse in healthcare and its potential
to revolutionize the delivery of medical services.

ÊëòË¶ÅÔºöÂÖÉÂÆáÂÆôÁöÑÊ¶ÇÂøµÂú®ÂêÑÂÄãÈ†òÂüüÈÉΩÂÇôÂèóÈóúÊ≥®ÔºåÂÖ∂ÈáçË¶ÅÊáâÁî®‰πã‰∏Ä‰æøÊòØÈÜ´ÁôÇ‰øùÂÅ•„ÄÇÂÖÉÂÆáÂÆôÊúâÂ∑®Â§ßÁöÑÊΩõÂäõÈÄèÈÅéÊîπËÆäÁóÖÊÇ£ÁÖßË≠∑„ÄÅÈÜ´Â≠∏ÊïôËÇ≤Ôºå‰ª•ÂèäÊïôÂ≠∏/Â≠∏ÁøíÂíåÁ†îÁ©∂ÁöÑÊñπÂºè‰æÜËΩâÂûãÈÜ´ÁôÇ‰øùÂÅ•„ÄÇÊú¨Á†îÁ©∂ÁöÑÁõÆÁöÑÊòØÊèê‰æõÂÖÉÂÆáÂÆôÂü∫Êú¨Ê¶ÇÂøµÂíåÂü∫Á§éÊäÄË°ìÁöÑ‰ªãÁ¥π„ÄÇÊú¨ÊñáÊé¢Ë®é‰∫ÜÂÖÉÂÆáÂÆôÂú®ÈÜ´ÁôÇ‰øùÂÅ•ËÉåÊôØ‰∏ãÁöÑÂÑ™Áº∫ÈªûÔºå‰∏¶ÂæûÊäÄË°ìÂíå AI ÁöÑËßíÂ∫¶ÂàÜÊûêÂÖ∂ÊΩõÂäõ„ÄÇÁâπÂà•ÊòØÔºåË®éË´ñ‰∫ÜÊ©üÂô®Â≠∏ÁøíÊñπÊ≥ïÁöÑËßíËâ≤ÔºõÊàëÂÄëÂ∞áË™™ÊòéÂ¶Ç‰ΩïÂ∞áÊ©üÂô®Â≠∏ÁøíÊºîÁÆóÊ≥ïÊáâÁî®ÊñºÂÖÉÂÆáÂÆôÁî¢ÁîüÁöÑË≥áÊñôÔºå‰ª•Áç≤ÂæóÈÜ´ÁôÇ‰øùÂÅ•ÊáâÁî®ÊñπÈù¢ÁöÑÊõ¥‰Ω≥Ë¶ãËß£„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÈÄèÈÅéÊé¢Ë®éÂçÄÂ°äÈèàÁ≠âÊñ∞ËààÊäÄË°ìÔºå‰∏¶Ëß£Ê±∫Èö±ÁßÅÂïèÈ°åÔºå‰æÜÊé¢Ë®éÂÖÉÂÆáÂÆôÂú®ÈÜ´ÁôÇ‰øùÂÅ•ÊñπÈù¢ÁöÑÊú™‰æÜÈ°òÊôØ„ÄÇÊú¨Á†îÁ©∂ÁöÑÁôºÁèæÊúâÂä©ÊñºÊõ¥Ê∑±ÂÖ•Âú∞‰∫ÜËß£ÂÖÉÂÆáÂÆôÂú®ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÁöÑÊáâÁî®Ôºå‰ª•ÂèäÂÖ∂Âú®ÈÜ´ÁôÇÊúçÂãôÊèê‰æõÊñπÈù¢ÁôºÊèÆÈù©ÂëΩÊÄßËÆäÈù©ÁöÑÊΩõÂäõ„ÄÇ

##### **AI-Driven Predictive Analytics Approach for Early Prognosis of Chronic Kidney Disease Using Ensemble Learning and Explainable AI**
2406.06728v1 by K M Tawsik Jawad, Anusha Verma, Fathi Amsaad

Chronic Kidney Disease (CKD) is one of the widespread Chronic diseases with
no known ultimo cure and high morbidity. Research demonstrates that progressive
Chronic Kidney Disease (CKD) is a heterogeneous disorder that significantly
impacts kidney structure and functions, eventually leading to kidney failure.
With the progression of time, chronic kidney disease has moved from a
life-threatening disease affecting few people to a common disorder of varying
severity. The goal of this research is to visualize dominating features,
feature scores, and values exhibited for early prognosis and detection of CKD
using ensemble learning and explainable AI. For that, an AI-driven predictive
analytics approach is proposed to aid clinical practitioners in prescribing
lifestyle modifications for individual patients to reduce the rate of
progression of this disease. Our dataset is collected on body vitals from
individuals with CKD and healthy subjects to develop our proposed AI-driven
solution accurately. In this regard, blood and urine test results are provided,
and ensemble tree-based machine-learning models are applied to predict unseen
cases of CKD. Our research findings are validated after lengthy consultations
with nephrologists. Our experiments and interpretation results are compared
with existing explainable AI applications in various healthcare domains,
including CKD. The comparison shows that our developed AI models, particularly
the Random Forest model, have identified more features as significant
contributors than XgBoost. Interpretability (I), which measures the ratio of
important to masked features, indicates that our XgBoost model achieved a
higher score, specifically a Fidelity of 98\%, in this metric and naturally in
the FII index compared to competing models.

ÊëòË¶ÅÔºöÊÖ¢ÊÄßËÖéËáüÁóÖÔºàCKDÔºâÊòØ‰∏ÄÁ®ÆÂª£Ê≥õÁöÑÊÖ¢ÊÄßÁñæÁóÖÔºåÊ≤íÊúâÂ∑≤Áü•ÁöÑÊúÄÁµÇÁôÇÊ≥ï‰∏îÁôºÁóÖÁéáÂæàÈ´ò„ÄÇÁ†îÁ©∂Ë°®ÊòéÔºåÈÄ≤Ë°åÊÄßÊÖ¢ÊÄßËÖéËáüÁóÖÔºàCKDÔºâÊòØ‰∏ÄÁ®ÆÁï∞Ë≥™ÊÄßÁñæÁóÖÔºåÊúÉÈ°ØËëóÂΩ±ÈüøËÖéËáüÁµêÊßãÂíåÂäüËÉΩÔºåÊúÄÁµÇÂ∞éËá¥ËÖéË°∞Á´≠„ÄÇÈö®ËëóÊôÇÈñìÁöÑÊé®ÁßªÔºåÊÖ¢ÊÄßËÖéËáüÁóÖÂ∑≤ÂæûÂΩ±ÈüøÂ∞ëÊï∏‰∫∫ÁöÑËá¥ÂëΩÁñæÁóÖËΩâËÆäÁÇ∫‰∏ÄÁ®ÆÂö¥ÈáçÁ®ãÂ∫¶‰∏çÂêåÁöÑÂ∏∏Ë¶ãÁñæÁóÖ„ÄÇÊú¨Á†îÁ©∂ÁöÑÁõÆÊ®ôÊòØ‰ΩøÁî®ÈõÜÊàêÂ≠∏ÁøíÂíåÂèØËß£ÈáãÁöÑ AI ÈÄ≤Ë°åÊó©ÊúüÈ†êÂæåÂíå CKD Ê™¢Ê∏¨Ôºå‰∏¶Ë¶ñË¶∫Âåñ‰∏ªÂ∞éÁâπÂæµ„ÄÅÁâπÂæµÂàÜÊï∏ÂíåË°®ÁèæÂá∫ÁöÑÂÄº„ÄÇÁÇ∫Ê≠§ÔºåÊèêÂá∫‰∫Ü‰∏ÄÁ®Æ AI È©ÖÂãïÁöÑÈ†êÊ∏¨ÂàÜÊûêÊñπÊ≥ïÔºå‰ª•Âπ´Âä©Ëá®Â∫äÈÜ´ÁîüÁÇ∫ÂÄãÂà•ÊÇ£ËÄÖÈñãÂÖ∑ÁîüÊ¥ªÊñπÂºè‰øÆÊîπÂª∫Ë≠∞Ôºå‰ª•Èôç‰ΩéÈÄôÁ®ÆÁñæÁóÖÁöÑÈÄ≤Â±ïÈÄüÂ∫¶„ÄÇÊàëÂÄëÁöÑÊï∏ÊìöÈõÜÊòØÂæû CKD ÊÇ£ËÄÖÂíåÂÅ•Â∫∑ÂèóË©¶ËÄÖÁöÑË∫´È´îÁîüÂëΩÈ´îÂæµ‰∏≠Êî∂ÈõÜÁöÑÔºå‰ª•Ê∫ñÁ¢∫ÈñãÁôºÊàëÂÄëÊèêÂá∫ÁöÑ AI È©ÖÂãïÁöÑËß£Ê±∫ÊñπÊ°à„ÄÇÂú®ÈÄôÊñπÈù¢ÔºåÊèê‰æõ‰∫ÜË°ÄÊ∂≤ÂíåÂ∞øÊ∂≤Ê™¢Ê∏¨ÁµêÊûúÔºå‰∏¶ÊáâÁî®Âü∫ÊñºÈõÜÊàêÊ®πÁöÑÊ©üÂô®Â≠∏ÁøíÊ®°Âûã‰æÜÈ†êÊ∏¨Êú™ÁôºÁèæÁöÑ CKD ÁóÖ‰æã„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÁ∂ìÈÅéËàáËÖéËáüÁßëÈÜ´ÁîüÁöÑÈï∑ÊúüË´ÆË©¢ÂæåÂæóÂà∞È©óË≠â„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÂíåËß£ÈáãÁµêÊûúËàáÂêÑÁ®ÆÈÜ´ÁôÇ‰øùÂÅ•È†òÂüü‰∏≠ÁèæÊúâÁöÑÂèØËß£Èáã AI ÊáâÁî®ÈÄ≤Ë°å‰∫ÜÊØîËºÉÔºåÂåÖÊã¨ CKD„ÄÇÊØîËºÉË°®ÊòéÔºåÊàëÂÄëÈñãÁôºÁöÑ AI Ê®°ÂûãÔºåÁâπÂà•ÊòØÈö®Ê©üÊ£ÆÊûóÊ®°ÂûãÔºåÂ∑≤Á∂ìÁ¢∫ÂÆö‰∫ÜÊØî XgBoost Êõ¥Â§ö‰ΩúÁÇ∫ÈáçË¶ÅË≤¢ÁçªËÄÖÁöÑÁâπÂæµ„ÄÇÂèØËß£ÈáãÊÄß (I) Ë°°ÈáèÈáçË¶ÅÁâπÂæµËàáÊé©ËìãÁâπÂæµÁöÑÊØîÁéáÔºåË°®ÊòéÊàëÂÄëÁöÑ XgBoost Ê®°ÂûãÂú®ÈÄôÂÄãÊåáÊ®ô‰∏≠Áç≤Âæó‰∫ÜÊõ¥È´òÁöÑÂàÜÊï∏ÔºåÁâπÂà•ÊòØ 98% ÁöÑ‰øùÁúüÂ∫¶Ôºå‰∏¶‰∏îÂú® FII ÊåáÊï∏‰∏≠Ëá™ÁÑ∂È´òÊñºÁ´∂Áà≠Ê®°Âûã„ÄÇ

##### **Explainable AI for Mental Disorder Detection via Social Media: A survey and outlook**
2406.05984v1 by Yusif Ibrahimov, Tarique Anwar, Tommy Yuan

Mental health constitutes a complex and pervasive global challenge, affecting
millions of lives and often leading to severe consequences. In this paper, we
conduct a thorough survey to explore the intersection of data science,
artificial intelligence, and mental healthcare, focusing on the recent
developments of mental disorder detection through online social media (OSM). A
significant portion of the population actively engages in OSM platforms,
creating a vast repository of personal data that holds immense potential for
mental health analytics. The paper navigates through traditional diagnostic
methods, state-of-the-art data- and AI-driven research studies, and the
emergence of explainable AI (XAI) models for mental healthcare. We review
state-of-the-art machine learning methods, particularly those based on modern
deep learning, while emphasising the need for explainability in healthcare AI
models. The experimental design section provides insights into prevalent
practices, including available datasets and evaluation approaches. We also
identify key issues and challenges in the field and propose promising future
research directions. As mental health decisions demand transparency,
interpretability, and ethical considerations, this paper contributes to the
ongoing discourse on advancing XAI in mental healthcare through social media.
The comprehensive overview presented here aims to guide researchers,
practitioners, and policymakers in developing the area of mental disorder
detection.

ÊëòË¶ÅÔºöÂøÉÁêÜÂÅ•Â∫∑ÊßãÊàê‰∫Ü‰∏ÄÈ†ÖË§áÈõú‰∏îÊôÆÈÅçÁöÑÂÖ®ÁêÉÊåëÊà∞ÔºåÂΩ±Èüø‰∫ÜÊï∏ÁôæËê¨‰∫∫ÁöÑÁîüÊ¥ªÔºå‰∏¶Á∂ìÂ∏∏Â∞éËá¥Âö¥ÈáçÁöÑÂæåÊûú„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÈÄ≤Ë°å‰∫Ü‰∏ÄÈ†ÖÂæπÂ∫ïÁöÑË™øÊü•Ôºå‰ª•Êé¢Á¥¢Êï∏ÊìöÁßëÂ≠∏„ÄÅ‰∫∫Â∑•Êô∫ÊÖßÂíåÂøÉÁêÜ‰øùÂÅ•ÁöÑ‰∫§ÈõÜÔºåÈáçÈªûÈóúÊ≥®ÈÄöÈÅéÁ∑ö‰∏äÁ§æ‰∫§Â™íÈ´î (OSM) ÈÄ≤Ë°åÂøÉÁêÜÁñæÁóÖÊ™¢Ê∏¨ÁöÑÊúÄÊñ∞ÁôºÂ±ï„ÄÇÂæàÂ§ß‰∏ÄÈÉ®ÂàÜ‰∫∫Âè£Á©çÊ•µÂèÉËàá OSM Âπ≥Âè∞ÔºåÂâµÈÄ†‰∫Ü‰∏ÄÂÄãÈæêÂ§ßÁöÑ‰∫∫Âì°Ë≥áÊñôÂ∫´ÔºåÂ∞çÂøÉÁêÜÂÅ•Â∫∑ÂàÜÊûêÂÖ∑ÊúâÂ∑®Â§ßÁöÑÊΩõÂäõ„ÄÇÊú¨ÊñáÊé¢Ë®é‰∫ÜÂÇ≥Áµ±ÁöÑË®∫Êñ∑ÊñπÊ≥ï„ÄÅÊúÄÂÖàÈÄ≤ÁöÑË≥áÊñôÂíå AI È©ÖÂãïÁöÑÁ†îÁ©∂Ôºå‰ª•ÂèäÂøÉÁêÜ‰øùÂÅ•‰∏≠ÂèØËß£Èáã AI (XAI) Ê®°ÂûãÁöÑÂá∫Áèæ„ÄÇÊàëÂÄëÂõûÈ°ß‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÊ©üÂô®Â≠∏ÁøíÊñπÊ≥ïÔºåÁâπÂà•ÊòØÈÇ£‰∫õÂü∫ÊñºÁèæ‰ª£Ê∑±Â∫¶Â≠∏ÁøíÁöÑÊñπÊ≥ïÔºåÂêåÊôÇÂº∑Ë™ø‰∫ÜÈÜ´ÁôÇ‰øùÂÅ• AI Ê®°Âûã‰∏≠ÂèØËß£ÈáãÊÄßÁöÑÂøÖË¶ÅÊÄß„ÄÇÂØ¶È©óË®≠Ë®àÈÉ®ÂàÜÊèê‰æõ‰∫ÜÂ∞çÊôÆÈÅçÂÅöÊ≥ïÁöÑË¶ãËß£ÔºåÂåÖÊã¨ÂèØÁî®ÁöÑË≥áÊñôÈõÜÂíåË©ï‰º∞ÊñπÊ≥ï„ÄÇÊàëÂÄëÈÇÑÊâæÂá∫Ë©≤È†òÂüüÁöÑ‰∏ªË¶ÅÂïèÈ°åÂíåÊåëÊà∞Ôºå‰∏¶ÊèêÂá∫‰∫ÜÊúâÂ∏åÊúõÁöÑÊú™‰æÜÁ†îÁ©∂ÊñπÂêë„ÄÇÁî±ÊñºÂøÉÁêÜÂÅ•Â∫∑Ê±∫Á≠ñÈúÄË¶ÅÈÄèÊòéÂ∫¶„ÄÅÂèØËß£ÈáãÊÄßÂíåÈÅìÂæ∑ËÄÉÈáèÔºåÊú¨ÊñáÊúâÂä©ÊñºÊé®ÈÄ≤ÂøÉÁêÜ‰øùÂÅ•‰∏≠ÈÄèÈÅéÁ§æ‰∫§Â™íÈ´îÊé®ÈÄ≤ XAI ÁöÑÊåÅÁ∫åË®éË´ñ„ÄÇÈÄôË£°ÊèêÂá∫ÁöÑÂÖ®Èù¢Ê¶ÇËø∞Êó®Âú®ÂºïÂ∞éÁ†îÁ©∂‰∫∫Âì°„ÄÅÂæûÊ•≠‰∫∫Âì°ÂíåÊîøÁ≠ñÂà∂ÂÆöËÄÖÁôºÂ±ïÂøÉÁêÜÁñæÁóÖÊ™¢Ê∏¨È†òÂüü„ÄÇ

##### **Methodology and Real-World Applications of Dynamic Uncertain Causality Graph for Clinical Diagnosis with Explainability and Invariance**
2406.05746v1 by Zhan Zhang, Qin Zhang, Yang Jiao, Lin Lu, Lin Ma, Aihua Liu, Xiao Liu, Juan Zhao, Yajun Xue, Bing Wei, Mingxia Zhang, Ru Gao, Hong Zhao, Jie Lu, Fan Li, Yang Zhang, Yiming Wang, Lei Zhang, Fengwei Tian, Jie Hu, Xin Gou

AI-aided clinical diagnosis is desired in medical care. Existing deep
learning models lack explainability and mainly focus on image analysis. The
recently developed Dynamic Uncertain Causality Graph (DUCG) approach is
causality-driven, explainable, and invariant across different application
scenarios, without problems of data collection, labeling, fitting, privacy,
bias, generalization, high cost and high energy consumption. Through close
collaboration between clinical experts and DUCG technicians, 46 DUCG models
covering 54 chief complaints were constructed. Over 1,000 diseases can be
diagnosed without triage. Before being applied in real-world, the 46 DUCG
models were retrospectively verified by third-party hospitals. The verified
diagnostic precisions were no less than 95%, in which the diagnostic precision
for every disease including uncommon ones was no less than 80%. After
verifications, the 46 DUCG models were applied in the real-world in China. Over
one million real diagnosis cases have been performed, with only 17 incorrect
diagnoses identified. Due to DUCG's transparency, the mistakes causing the
incorrect diagnoses were found and corrected. The diagnostic abilities of the
clinicians who applied DUCG frequently were improved significantly. Following
the introduction to the earlier presented DUCG methodology, the recommendation
algorithm for potential medical checks is presented and the key idea of DUCG is
extracted.

ÊëòË¶ÅÔºö<paragraph>ÈÜ´ÁôÇÁÖßË≠∑‰∏≠ÈúÄË¶Å AI ËºîÂä©ÁöÑËá®Â∫äË®∫Êñ∑„ÄÇÁèæÊúâÁöÑÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÁº∫‰πèÂèØËß£ÈáãÊÄßÔºå‰∏¶‰∏î‰∏ªË¶ÅÂ∞àÊ≥®ÊñºÂΩ±ÂÉèÂàÜÊûê„ÄÇÊúÄËøëÈñãÁôºÁöÑÂãïÊÖã‰∏çÁ¢∫ÂÆöÂõ†ÊûúÈóú‰øÇÂúñ (DUCG) ÊñπÊ≥ïÊòØÂõ†ÊûúÈ©ÖÂãïÁöÑ„ÄÅÂèØËß£ÈáãÁöÑÔºå‰∏¶‰∏îÂú®‰∏çÂêåÁöÑÊáâÁî®Â†¥ÊôØ‰∏≠ÊòØ‰∏çËÆäÁöÑÔºåÊ≤íÊúâË≥áÊñôÊî∂ÈõÜ„ÄÅÊ®ôË®ò„ÄÅÊì¨Âêà„ÄÅÈö±ÁßÅ„ÄÅÂÅèË¶ã„ÄÅÊ¶ÇÂåñ„ÄÅÈ´òÊàêÊú¨ÂíåÈ´òËÉΩËÄóÁöÑÂïèÈ°å„ÄÇÈÄöÈÅéËá®Â∫äÂ∞àÂÆ∂Âíå DUCG ÊäÄË°ì‰∫∫Âì°‰πãÈñìÁöÑÂØÜÂàáÂêà‰ΩúÔºåÊßãÂª∫‰∫ÜÊ∂µËìã 54 ÂÄã‰∏ªË®¥ÁöÑ 46 ÂÄã DUCG Ê®°Âûã„ÄÇÂèØ‰ª•Âú®Ê≤íÊúâÂàÜÊµÅÁöÑÊÉÖÊ≥Å‰∏ãË®∫Êñ∑Âá∫ 1,000 Â§öÁ®ÆÁñæÁóÖ„ÄÇÂú®ÊáâÁî®ÊñºÂØ¶Èöõ‰∏ñÁïå‰πãÂâçÔºå46 ÂÄã DUCG Ê®°ÂûãÂ∑≤Áî±Á¨¨‰∏âÊñπÈÜ´Èô¢ÂõûÊ∫ØÊÄßÈ©óË≠â„ÄÇÈ©óË≠âÁöÑË®∫Êñ∑Á≤æÂ∫¶‰∏ç‰ΩéÊñº 95%ÔºåÂÖ∂‰∏≠ÂåÖÊã¨ÁΩïË¶ãÁñæÁóÖÂú®ÂÖßÁöÑÊØèÁ®ÆÁñæÁóÖÁöÑË®∫Êñ∑Á≤æÂ∫¶‰∏ç‰ΩéÊñº 80%„ÄÇÈ©óË≠âÂæåÔºå46 ÂÄã DUCG Ê®°ÂûãÂ∑≤Âú®‰∏≠ÂúãÂØ¶ÈöõÊáâÁî®„ÄÇÂ∑≤Á∂ìÂü∑Ë°å‰∫ÜË∂ÖÈÅé‰∏ÄÁôæËê¨ÂÄãÁúüÂØ¶Ë®∫Êñ∑Ê°à‰æãÔºåÂÉÖÁôºÁèæ 17 ÂÄã‰∏çÊ≠£Á¢∫ÁöÑË®∫Êñ∑„ÄÇÁî±Êñº DUCG ÁöÑÈÄèÊòéÊÄßÔºåÁôºÁèæ‰∏¶Á≥æÊ≠£‰∫ÜÂ∞éËá¥‰∏çÊ≠£Á¢∫Ë®∫Êñ∑ÁöÑÈåØË™§„ÄÇÈ†ªÁπÅÊáâÁî® DUCG ÁöÑËá®Â∫äÈÜ´ÁîüÁöÑË®∫Êñ∑ËÉΩÂäõÂæóÂà∞‰∫ÜÈ°ØËëóÊèêÈ´ò„ÄÇÂú®‰ªãÁ¥π‰∫ÜÂâçÈù¢ÊèêÂá∫ÁöÑ DUCG ÊñπÊ≥ïË´ñ‰πãÂæåÔºåÊèêÂá∫‰∫ÜÊΩõÂú®ÂÅ•Â∫∑Ê™¢Êü•ÁöÑÊé®Ëñ¶ÊºîÁÆóÊ≥ïÔºå‰∏¶ÊèêÂèñ‰∫Ü DUCG ÁöÑÈóúÈçµÊÄùÊÉ≥„ÄÇ</paragraph>

##### **Advancing Histopathology-Based Breast Cancer Diagnosis: Insights into Multi-Modality and Explainability**
2406.12897v1 by Faseela Abdullakutty, Younes Akbari, Somaya Al-Maadeed, Ahmed Bouridane, Rifat Hamoudi

It is imperative that breast cancer is detected precisely and timely to
improve patient outcomes. Diagnostic methodologies have traditionally relied on
unimodal approaches; however, medical data analytics is integrating diverse
data sources beyond conventional imaging. Using multi-modal techniques,
integrating both image and non-image data, marks a transformative advancement
in breast cancer diagnosis. The purpose of this review is to explore the
burgeoning field of multimodal techniques, particularly the fusion of
histopathology images with non-image data. Further, Explainable AI (XAI) will
be used to elucidate the decision-making processes of complex algorithms,
emphasizing the necessity of explainability in diagnostic processes. This
review utilizes multi-modal data and emphasizes explainability to enhance
diagnostic accuracy, clinician confidence, and patient engagement, ultimately
fostering more personalized treatment strategies for breast cancer, while also
identifying research gaps in multi-modality and explainability, guiding future
studies, and contributing to the strategic direction of the field.

ÊëòË¶ÅÔºöÁ≤æÁ¢∫‰∏îÂèäÊôÇÂú∞ÂÅµÊ∏¨‰π≥ÁôåÂ∞çÊñºÊîπÂñÑÊÇ£ËÄÖÈ†êÂæåËá≥ÈóúÈáçË¶Å„ÄÇË®∫Êñ∑ÊñπÊ≥ïÂÇ≥Áµ±‰∏ä‰æùË≥¥ÊñºÂñÆ‰∏ÄÊ®°ÂºèÊñπÊ≥ïÔºõÁÑ∂ËÄåÔºåÈÜ´ÁôÇË≥áÊñôÂàÜÊûêÊ≠£Âú®Êï¥ÂêàË∂ÖË∂äÂÇ≥Áµ±ÂΩ±ÂÉèÁöÑÂêÑÁ®ÆË≥áÊñô‰æÜÊ∫ê„ÄÇ‰ΩøÁî®Êï¥ÂêàÂΩ±ÂÉèÂíåÈùûÂΩ±ÂÉèË≥áÊñôÁöÑÂ§öÊ®°ÂºèÊäÄË°ìÔºåÊ®ôË™åËëó‰π≥ÁôåË®∫Êñ∑ÁöÑËÆäÈù©ÊÄßÈÄ≤Â±ï„ÄÇÊú¨ÁØáÁ∂úËø∞ÁöÑÁõÆÁöÑÊòØÊé¢Ë®éÂ§öÊ®°ÂºèÊäÄË°ìÁöÑÊñ∞ËààÈ†òÂüüÔºåÁâπÂà•ÊòØÂ∞áÁµÑÁπîÁóÖÁêÜÂ≠∏ÂΩ±ÂÉèËàáÈùûÂΩ±ÂÉèË≥áÊñôËûçÂêà„ÄÇÊ≠§Â§ñÔºåÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖß (XAI) Â∞áÁî®ÊñºÈó°ÊòéË§áÈõúÊºîÁÆóÊ≥ïÁöÑÊ±∫Á≠ñÈÅéÁ®ãÔºåÂº∑Ë™øË®∫Êñ∑ÈÅéÁ®ã‰∏≠ÂèØËß£ÈáãÊÄßÁöÑÂøÖË¶ÅÊÄß„ÄÇÊú¨Á∂úËø∞Âà©Áî®Â§öÊ®°ÂºèË≥áÊñô‰∏¶Âº∑Ë™øÂèØËß£ÈáãÊÄßÔºå‰ª•ÊèêÈ´òË®∫Êñ∑Ê∫ñÁ¢∫ÊÄß„ÄÅËá®Â∫äÈÜ´Â∏´ÁöÑ‰ø°ÂøÉÂíåÊÇ£ËÄÖÂèÉËàáÂ∫¶ÔºåÊúÄÁµÇ‰øÉÈÄ≤‰π≥ÁôåÊõ¥ÂÄã‰∫∫ÂåñÁöÑÊ≤ªÁôÇÁ≠ñÁï•ÔºåÂêåÊôÇ‰πüÊâæÂá∫Â§öÊ®°ÂºèÂíåÂèØËß£ÈáãÊÄßÁöÑÁ†îÁ©∂Â∑ÆË∑ùÔºåÂºïÂ∞éÊú™‰æÜÁöÑÁ†îÁ©∂Ôºå‰∏¶ÁÇ∫Ë©≤È†òÂüüÁöÑÁ≠ñÁï•ÊñπÂêëÂÅöÂá∫Ë≤¢Áçª„ÄÇ

##### **Revisiting Attention Weights as Interpretations of Message-Passing Neural Networks**
2406.04612v1 by Yong-Min Shin, Siqing Li, Xin Cao, Won-Yong Shin

The self-attention mechanism has been adopted in several widely-used
message-passing neural networks (MPNNs) (e.g., GATs), which adaptively controls
the amount of information that flows along the edges of the underlying graph.
This usage of attention has made such models a baseline for studies on
explainable AI (XAI) since interpretations via attention have been popularized
in various domains (e.g., natural language processing and computer vision).
However, existing studies often use naive calculations to derive attribution
scores from attention, and do not take the precise and careful calculation of
edge attribution into consideration. In our study, we aim to fill the gap
between the widespread usage of attention-enabled MPNNs and their potential in
largely under-explored explainability, a topic that has been actively
investigated in other areas. To this end, as the first attempt, we formalize
the problem of edge attribution from attention weights in GNNs. Then, we
propose GATT, an edge attribution calculation method built upon the computation
tree. Through comprehensive experiments, we demonstrate the effectiveness of
our proposed method when evaluating attributions from GATs. Conversely, we
empirically validate that simply averaging attention weights over graph
attention layers is insufficient to interpret the GAT model's behavior. Code is
publicly available at https://github.com/jordan7186/GAtt/tree/main.

ÊëòË¶ÅÔºöËá™Ê≥®ÊÑèÂäõÊ©üÂà∂Â∑≤Ë¢´Êé°Áî®ÊñºÂ§öÂÄãÂª£Ê≥õ‰ΩøÁî®ÁöÑË®äÊÅØÂÇ≥ÈÅûÁ•ûÁ∂ìÁ∂≤Ë∑Ø (MPNN)Ôºà‰æãÂ¶Ç GATÔºâÔºåÂÆÉÂèØ‰ª•Ëá™ÈÅ©ÊáâÂú∞ÊéßÂà∂Ê≤øËëóÂ∫ïÂ±§ÂúñÂΩ¢ÈÇäÁ∑£ÊµÅÂãïÁöÑË≥áË®äÈáè„ÄÇÈÄôÁ®ÆÊ≥®ÊÑèÂäõÁöÑ‰ΩøÁî®‰ΩøÂæóÊ≠§È°ûÊ®°ÂûãÊàêÁÇ∫ÂèØËß£Èáã AI (XAI) Á†îÁ©∂ÁöÑÂü∫Á∑öÔºåÂõ†ÁÇ∫ÈÄèÈÅéÊ≥®ÊÑèÂäõÁöÑË©ÆÈáãÂ∑≤Âú®ÂêÑÁ®ÆÈ†òÂüüÔºà‰æãÂ¶ÇËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜÂíåÈõªËÖ¶Ë¶ñË¶∫Ôºâ‰∏≠ÊôÆÂèä„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÁöÑÁ†îÁ©∂ÈÄöÂ∏∏‰ΩøÁî®Â§©ÁúüÁöÑË®àÁÆóÊñπÊ≥ïÂæûÊ≥®ÊÑèÂäõ‰∏≠Êé®Â∞éÂá∫Ê≠∏Âõ†ÂàÜÊï∏Ôºå‰∏¶‰∏îÊ≤íÊúâËÄÉÊÖÆÂà∞ÈÇäÁ∑£Ê≠∏Âõ†ÁöÑÁ≤æÁ¢∫‰∏î‰ªîÁ¥∞ÁöÑË®àÁÆó„ÄÇÂú®ÊàëÂÄëÁöÑÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄëÊó®Âú®Â°´Ë£úÊ≥®ÊÑèÂäõÂïüÁî® MPNN ÁöÑÂª£Ê≥õ‰ΩøÁî®ËàáÂÆÉÂÄëÂú®ÂæàÂ§ßÁ®ãÂ∫¶‰∏äÊú™Ë¢´ÂÖÖÂàÜÊé¢Á¥¢ÁöÑÂèØËß£ÈáãÊÄß‰πãÈñìÁöÑÂ∑ÆË∑ùÔºåÈÄôÂÄã‰∏ªÈ°åÂ∑≤Âú®ÂÖ∂‰ªñÈ†òÂüüÁ©çÊ•µÁ†îÁ©∂„ÄÇÁÇ∫Ê≠§Ôºå‰ΩúÁÇ∫Á¨¨‰∏ÄÊ¨°ÂòóË©¶ÔºåÊàëÂÄëÂ∞á GNN ‰∏≠Ê≥®ÊÑèÂäõÊ¨äÈáçÁöÑÈÇäÁ∑£Ê≠∏Âõ†ÂïèÈ°åÂΩ¢ÂºèÂåñ„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÊèêÂá∫ GATTÔºå‰∏ÄÁ®ÆÂª∫Á´ãÂú®Ë®àÁÆóÊ®π‰∏äÁöÑÈÇäÁ∑£Ê≠∏Âõ†Ë®àÁÆóÊñπÊ≥ï„ÄÇÈÄèÈÅéÂÖ®Èù¢ÁöÑÂØ¶È©óÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜÊàëÂÄëÊèêÂá∫ÁöÑÊñπÊ≥ïÂú®Ë©ï‰º∞ GAT ÁöÑÊ≠∏Âõ†ÊôÇÊâÄÂÖ∑ÊúâÁöÑÊïàÊûú„ÄÇÁõ∏ÂèçÂú∞ÔºåÊàëÂÄëÊÜëÁ∂ìÈ©óÈ©óË≠â‰∫ÜÂÉÖÂ∞çÂúñÊ≥®ÊÑèÂäõÂ±§‰∏äÁöÑÊ≥®ÊÑèÂäõÊ¨äÈáçÂèñÂπ≥ÂùáÂÄº‰∏çË∂≥‰ª•Ë©ÆÈáã GAT Ê®°ÂûãÁöÑË°åÁÇ∫„ÄÇÁ®ãÂºèÁ¢ºÂ∑≤ÂÖ¨ÈñãÊñº https://github.com/jordan7186/GAtt/tree/main„ÄÇ

##### **Using Explainable AI for EEG-based Reduced Montage Neonatal Seizure Detection**
2406.16908v3 by Dinuka Sandun Udayantha, Kavindu Weerasinghe, Nima Wickramasinghe, Akila Abeyratne, Kithmin Wickremasinghe, Jithangi Wanigasinghe, Anjula De Silva, Chamira U. S. Edussooriya

The neonatal period is the most vulnerable time for the development of
seizures. Seizures in the immature brain lead to detrimental consequences,
therefore require early diagnosis. The gold-standard for neonatal seizure
detection currently relies on continuous video-EEG monitoring; which involves
recording multi-channel electroencephalogram (EEG) alongside real-time video
monitoring within a neonatal intensive care unit (NICU). However, video-EEG
monitoring technology requires clinical expertise and is often limited to
technologically advanced and resourceful settings. Cost-effective new
techniques could help the medical fraternity make an accurate diagnosis and
advocate treatment without delay. In this work, a novel explainable deep
learning model to automate the neonatal seizure detection process with a
reduced EEG montage is proposed, which employs convolutional nets, graph
attention layers, and fully connected layers. Beyond its ability to detect
seizures in real-time with a reduced montage, this model offers the unique
advantage of real-time interpretability. By evaluating the performance on the
Zenodo dataset with 10-fold cross-validation, the presented model achieves an
absolute improvement of 8.31% and 42.86% in area under curve (AUC) and recall,
respectively.

ÊëòË¶ÅÔºöÊñ∞ÁîüÂÖíÊúüÊòØÂ§ßËÖ¶ÁôºËÇ≤ÊúÄËÑÜÂº±ÁöÑÊôÇÊúüÔºåÂÆπÊòìÂá∫ÁèæÁô≤ÁôáÁôº‰Ωú„ÄÇÂ§ßËÖ¶ÁôºËÇ≤‰∏çÊàêÁÜüÊôÇÂá∫ÁèæÁô≤ÁôáÁôº‰ΩúÊúÉÈÄ†Êàê‰∏çËâØÂæåÊûúÔºåÂõ†Ê≠§ÈúÄË¶ÅÂèäÊó©Ë®∫Êñ∑„ÄÇÁõÆÂâçÊñ∞ÁîüÂÖíÁô≤ÁôáÁôº‰ΩúÁöÑÈªÉÈáëÊ®ôÊ∫ñ‰æùË≥¥ÊñºÈÄ£Á∫åÁöÑË¶ñË®äËÖ¶ÈõªÂúñ (EEG) Áõ£Ê∏¨ÔºõÂÖ∂‰∏≠ÂåÖÊã¨Âú®Êñ∞ÁîüÂÖíÂä†Ë≠∑ÁóÖÊàø (NICU) ÂÖßÂêåÊôÇÈÄ≤Ë°åÂ§öÈ†ªÈÅìËÖ¶ÈõªÂúñ (EEG) Ë®òÈåÑÂíåÂç≥ÊôÇË¶ñË®äÁõ£Êéß„ÄÇÁÑ∂ËÄåÔºåË¶ñË®äËÖ¶ÈõªÂúñÁõ£ÊéßÊäÄË°ìÈúÄË¶ÅËá®Â∫äÂ∞àÊ•≠Áü•Ë≠òÔºåËÄå‰∏îÈÄöÂ∏∏ÂÉÖÈôêÊñºÊäÄË°ìÂÖàÈÄ≤‰∏îË≥áÊ∫êË±êÂØåÁöÑÁí∞Â¢É„ÄÇÂÖ∑ÊàêÊú¨ÊïàÁõäÁöÑÊñ∞ÊäÄË°ìÂèØ‰ª•Âπ´Âä©ÈÜ´ÁôÇÁïåÊ∫ñÁ¢∫Ë®∫Êñ∑‰∏¶Á´ãÂç≥ÊèêÂÄ°Ê≤ªÁôÇ„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊñ∞Á©éÁöÑÂèØËß£ÈáãÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÔºå‰ª•Ëá™ÂãïÂåñÊñ∞ÁîüÂÖíÁô≤ÁôáÁôº‰ΩúÂÅµÊ∏¨ÈÅéÁ®ãÔºå‰∏¶Êé°Áî®Ê∏õÂ∞ëÁöÑËÖ¶ÈõªÂúñË£ùÁΩÆÔºåÂÖ∂‰∏≠Êé°Áî®‰∫ÜÂç∑Á©çÁ•ûÁ∂ìÁ∂≤Ë∑Ø„ÄÅÂúñÂΩ¢Ê≥®ÊÑèÂäõÂ±§ÂíåÂÖ®ÈÄ£Êé•Â±§„ÄÇÈô§‰∫ÜËÉΩÂ§†‰ΩøÁî®Ê∏õÂ∞ëÁöÑË£ùÁΩÆÂç≥ÊôÇÂÅµÊ∏¨Áô≤ÁôáÁôº‰ΩúÂ§ñÔºåÊ≠§Ê®°ÂûãÈÇÑÊèê‰æõ‰∫ÜÂç≥ÊôÇÂèØËß£ÈáãÊÄßÁöÑÁç®ÁâπÂÑ™Âã¢„ÄÇÈÄèÈÅéÂú® Zenodo Ë≥áÊñôÈõÜ‰∏ä‰ΩøÁî® 10 ÂÄç‰∫§ÂèâÈ©óË≠âË©ï‰º∞ÊïàËÉΩÔºåÊâÄÊèêÂá∫ÁöÑÊ®°ÂûãÂú®Êõ≤Á∑ö‰∏ãÈù¢Á©ç (AUC) ÂíåÂè¨ÂõûÁéáÊñπÈù¢ÂàÜÂà•ÈÅîÂà∞‰∫Ü 8.31% Âíå 42.86% ÁöÑÁµïÂ∞çÊîπÂñÑ„ÄÇ

##### **Breast Cancer Diagnosis: A Comprehensive Exploration of Explainable Artificial Intelligence (XAI) Techniques**
2406.00532v1 by Samita Bai, Sidra Nasir, Rizwan Ahmed Khan, Sheeraz Arif, Alexandre Meyer, Hubert Konik

Breast cancer (BC) stands as one of the most common malignancies affecting
women worldwide, necessitating advancements in diagnostic methodologies for
better clinical outcomes. This article provides a comprehensive exploration of
the application of Explainable Artificial Intelligence (XAI) techniques in the
detection and diagnosis of breast cancer. As Artificial Intelligence (AI)
technologies continue to permeate the healthcare sector, particularly in
oncology, the need for transparent and interpretable models becomes imperative
to enhance clinical decision-making and patient care. This review discusses the
integration of various XAI approaches, such as SHAP, LIME, Grad-CAM, and
others, with machine learning and deep learning models utilized in breast
cancer detection and classification. By investigating the modalities of breast
cancer datasets, including mammograms, ultrasounds and their processing with
AI, the paper highlights how XAI can lead to more accurate diagnoses and
personalized treatment plans. It also examines the challenges in implementing
these techniques and the importance of developing standardized metrics for
evaluating XAI's effectiveness in clinical settings. Through detailed analysis
and discussion, this article aims to highlight the potential of XAI in bridging
the gap between complex AI models and practical healthcare applications,
thereby fostering trust and understanding among medical professionals and
improving patient outcomes.

ÊëòË¶ÅÔºö‰π≥Áôå (BC) ÊòØÂΩ±ÈüøÂÖ®ÁêÉÂ•≥ÊÄßÊúÄÂ∏∏Ë¶ãÁöÑÊÉ°ÊÄßËÖ´Áò§‰πã‰∏ÄÔºåÂõ†Ê≠§ÈúÄË¶ÅÈÄ≤Ê≠•ÁöÑË®∫Êñ∑ÊñπÊ≥ïÔºå‰ª•ÊîπÂñÑËá®Â∫äÁµêÊûú„ÄÇÊú¨ÊñáÂÖ®Èù¢Êé¢Ë®é‰∫ÜÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖß (XAI) ÊäÄË°ìÂú®‰π≥ÁôåÂÅµÊ∏¨ÂíåË®∫Êñ∑‰∏≠ÁöÑÊáâÁî®„ÄÇÈö®Ëëó‰∫∫Â∑•Êô∫ÊÖß (AI) ÊäÄË°ìÊåÅÁ∫åÊª≤ÈÄèÈÜ´ÁôÇ‰øùÂÅ•È†òÂüüÔºåÁâπÂà•ÊòØÂú®ËÖ´Áò§Â≠∏‰∏≠ÔºåÈÄèÊòé‰∏îÂèØËß£ÈáãÁöÑÊ®°ÂûãÈúÄÊ±ÇËÆäÂæóÂã¢Âú®ÂøÖË°åÔºå‰ª•Â¢ûÂº∑Ëá®Â∫äÊ±∫Á≠ñÂà∂ÂÆöÂíåÊÇ£ËÄÖÁÖßË≠∑„ÄÇÊ≠§ÁØáË©ïË´ñÊé¢Ë®é‰∫ÜÂêÑÁ®Æ XAI ÊñπÊ≥ïÁöÑÊï¥ÂêàÔºå‰æãÂ¶Ç SHAP„ÄÅLIME„ÄÅGrad-CAM Á≠âÔºå‰ª•ÂèäÁî®Êñº‰π≥ÁôåÂÅµÊ∏¨ÂíåÂàÜÈ°ûÁöÑÊ©üÂô®Â≠∏ÁøíÂíåÊ∑±Â∫¶Â≠∏ÁøíÊ®°Âûã„ÄÇÈÄèÈÅéÊé¢Ë®é‰π≥ÁôåË≥áÊñôÈõÜÁöÑÊ®°ÂºèÔºåÂåÖÊã¨‰π≥ÊàøÊîùÂΩ±„ÄÅË∂ÖÈü≥Ê≥¢ÂèäÂÖ∂Âú® AI ‰∏≠ÁöÑËôïÁêÜÔºåÊú¨ÊñáÈáçÈªûË™™Êòé XAI Â¶Ç‰ΩïËÉΩÂ∞éËá¥Êõ¥Ê∫ñÁ¢∫ÁöÑË®∫Êñ∑ÂíåÂÄã‰∫∫ÂåñÊ≤ªÁôÇË®àÁï´„ÄÇÂÆÉ‰πüÊé¢Ë®é‰∫ÜÂØ¶ÊñΩÈÄô‰∫õÊäÄË°ìÁöÑÊåëÊà∞Ôºå‰ª•ÂèäÂà∂ÂÆöÊ®ôÊ∫ñÂåñË©ïÈáèÊåáÊ®ô‰ª•Ë©ï‰º∞ XAI Âú®Ëá®Â∫äÁí∞Â¢É‰∏≠ÁöÑÊúâÊïàÊÄßÁöÑÈáçË¶ÅÊÄß„ÄÇÈÄèÈÅéË©≥Á¥∞ÁöÑÂàÜÊûêÂíåË®éË´ñÔºåÊú¨ÊñáÊó®Âú®Âº∑Ë™ø XAI Âú®Á∏ÆÂ∞èË§áÈõú AI Ê®°ÂûãËàáÂØ¶ÂãôÈÜ´ÁôÇ‰øùÂÅ•ÊáâÁî®‰πãÈñìÂ∑ÆË∑ùÁöÑÊΩõÂäõÔºåÈÄ≤ËÄå‰øÉÈÄ≤ÈÜ´ÁôÇÂ∞àÊ•≠‰∫∫Âì°‰πãÈñìÁöÑ‰ø°‰ªªËàáÁêÜËß£Ôºå‰∏¶ÊîπÂñÑÊÇ£ËÄÖÁöÑÁµêÊûú„ÄÇ

##### **Unveiling Hidden Factors: Explainable AI for Feature Boosting in Speech Emotion Recognition**
2406.01624v2 by Alaa Nfissi, Wassim Bouachir, Nizar Bouguila, Brian Mishara

Speech emotion recognition (SER) has gained significant attention due to its
several application fields, such as mental health, education, and
human-computer interaction. However, the accuracy of SER systems is hindered by
high-dimensional feature sets that may contain irrelevant and redundant
information. To overcome this challenge, this study proposes an iterative
feature boosting approach for SER that emphasizes feature relevance and
explainability to enhance machine learning model performance. Our approach
involves meticulous feature selection and analysis to build efficient SER
systems. In addressing our main problem through model explainability, we employ
a feature evaluation loop with Shapley values to iteratively refine feature
sets. This process strikes a balance between model performance and
transparency, which enables a comprehensive understanding of the model's
predictions. The proposed approach offers several advantages, including the
identification and removal of irrelevant and redundant features, leading to a
more effective model. Additionally, it promotes explainability, facilitating
comprehension of the model's predictions and the identification of crucial
features for emotion determination. The effectiveness of the proposed method is
validated on the SER benchmarks of the Toronto emotional speech set (TESS),
Berlin Database of Emotional Speech (EMO-DB), Ryerson Audio-Visual Database of
Emotional Speech and Song (RAVDESS), and Surrey Audio-Visual Expressed Emotion
(SAVEE) datasets, outperforming state-of-the-art methods. To the best of our
knowledge, this is the first work to incorporate model explainability into an
SER framework. The source code of this paper is publicly available via this
https://github.com/alaaNfissi/Unveiling-Hidden-Factors-Explainable-AI-for-Feature-Boosting-in-Speech-Emotion-Recognition.

ÊëòË¶ÅÔºöË™ûÈü≥ÊÉÖÁ∑íËæ®Ë≠ò (SER) Áî±ÊñºÂÖ∂Âú®ÂøÉÁêÜÂÅ•Â∫∑„ÄÅÊïôËÇ≤Âíå‰∫∫Ê©ü‰∫íÂãïÁ≠âÂ§öÂÄãÊáâÁî®È†òÂüüËÄåÂÇôÂèóÈóúÊ≥®„ÄÇÁÑ∂ËÄåÔºåSER Á≥ªÁµ±ÁöÑÊ∫ñÁ¢∫ÊÄßÂèóÂà∞È´òÁ∂≠ÁâπÂæµÈõÜÁöÑÈòªÁ§ôÔºåÈÄô‰∫õÁâπÂæµÈõÜÂèØËÉΩÂåÖÂê´‰∏çÁõ∏ÈóúÂíåÂÜóÈ§òÁöÑË≥áË®ä„ÄÇÁÇ∫‰∫ÜÂÖãÊúçÈÄôÂÄãÊåëÊà∞ÔºåÊú¨Á†îÁ©∂ÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÁî®Êñº SER ÁöÑËø≠‰ª£ÁâπÂæµÊèêÂçáÊñπÊ≥ïÔºåË©≤ÊñπÊ≥ïÂº∑Ë™øÁâπÂæµÁõ∏ÈóúÊÄßÂíåÂèØËß£ÈáãÊÄßÔºå‰ª•Â¢ûÂº∑Ê©üÂô®Â≠∏ÁøíÊ®°ÂûãÁöÑÊïàËÉΩ„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÊ∂âÂèä‰ªîÁ¥∞ÁöÑÁâπÂæµÈÅ∏ÊìáÂíåÂàÜÊûêÔºå‰ª•Âª∫Á´ãÈ´òÊïàÁöÑ SER Á≥ªÁµ±„ÄÇÁÇ∫‰∫ÜÈÄèÈÅéÊ®°ÂûãÂèØËß£ÈáãÊÄßËß£Ê±∫ÊàëÂÄëÁöÑÊ†∏ÂøÉÂïèÈ°åÔºåÊàëÂÄëÊé°Áî®‰∫ÜÂÖ∑Êúâ Shapley ÂÄºÁöÑÁâπÂæµË©ï‰º∞Ëø¥ÂúàÔºå‰ª•ÂèçË¶ÜÊîπÂñÑÁâπÂæµÈõÜ„ÄÇÈÄôÂÄãÈÅéÁ®ãÂú®Ê®°ÂûãÊïàËÉΩÂíåÈÄèÊòéÂ∫¶‰πãÈñìÂèñÂæóÂπ≥Ë°°ÔºåÈÄô‰ΩøÂæóÊàëÂÄëËÉΩÂ§†ÂÖ®Èù¢‰∫ÜËß£Ê®°ÂûãÁöÑÈ†êÊ∏¨„ÄÇÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÊèê‰æõ‰∫ÜÂ§öÈ†ÖÂÑ™ÈªûÔºåÂåÖÊã¨Ë≠òÂà•ÂíåÁßªÈô§‰∏çÁõ∏ÈóúÂíåÂÜóÈ§òÁöÑÁâπÂæµÔºåÂæûËÄåÂª∫Á´ãÊõ¥ÊúâÊïàÁöÑÊ®°Âûã„ÄÇÊ≠§Â§ñÔºåÂÆÉ‰øÉÈÄ≤‰∫ÜÂèØËß£ÈáãÊÄßÔºåÊúâÂä©ÊñºÁêÜËß£Ê®°ÂûãÁöÑÈ†êÊ∏¨‰ª•ÂèäË≠òÂà•ÊÉÖÁ∑íÊ±∫ÂÆöÁöÑÈóúÈçµÁâπÂæµ„ÄÇÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÁöÑÊúâÊïàÊÄßÂ∑≤Âú®Â§öÂÄ´Â§öÊÉÖÁ∑íË™ûÈü≥ÈõÜ (TESS)„ÄÅÊüèÊûóÊÉÖÁ∑íË™ûÈü≥Ë≥áÊñôÂ∫´ (EMO-DB)„ÄÅË≥¥ÁàæÊ£ÆÈü≥Ë®äË¶ñË¶∫ÊÉÖÁ∑íË™ûÈü≥ÂíåÊ≠åÊõ≤Ë≥áÊñôÂ∫´ (RAVDESS) ÂíåËñ©ÈáåÈü≥Ë®äË¶ñË¶∫Ë°®ÈÅîÊÉÖÁ∑í (SAVEE) Ë≥áÊñôÈõÜÁöÑ SER Âü∫Ê∫ñ‰∏äÂæóÂà∞È©óË≠âÔºåÂÖ∂ÊïàËÉΩÂÑ™ÊñºÁèæÊúâÊñπÊ≥ï„ÄÇÊìöÊàëÂÄëÊâÄÁü•ÔºåÈÄôÊòØÁ¨¨‰∏ÄÂÄãÂ∞áÊ®°ÂûãÂèØËß£ÈáãÊÄßÁ¥çÂÖ• SER Êû∂ÊßãÁöÑÁ†îÁ©∂„ÄÇÊú¨ÊñáÁöÑÂéüÂßãÁ¢ºÂèØÈÄèÈÅéÊ≠§ÈÄ£ÁµêÂÖ¨ÈñãÂèñÂæóÔºöhttps://github.com/alaaNfissi/Unveiling-Hidden-Factors-Explainable-AI-for-Feature-Boosting-in-Speech-Emotion-Recognition„ÄÇ

##### **The Explanation Necessity for Healthcare AI**
2406.00216v1 by Michail Mamalakis, H√©lo√Øse de Vareilles, Graham Murray, Pietro Lio, John Suckling

Explainability is often critical to the acceptable implementation of
artificial intelligence (AI). Nowhere is this more important than healthcare
where decision-making directly impacts patients and trust in AI systems is
essential. This trust is often built on the explanations and interpretations
the AI provides. Despite significant advancements in AI interpretability, there
remains the need for clear guidelines on when and to what extent explanations
are necessary in the medical context. We propose a novel categorization system
with four distinct classes of explanation necessity, guiding the level of
explanation required: patient or sample (local) level, cohort or dataset
(global) level, or both levels. We introduce a mathematical formulation that
distinguishes these categories and offers a practical framework for researchers
to determine the necessity and depth of explanations required in medical AI
applications. Three key factors are considered: the robustness of the
evaluation protocol, the variability of expert observations, and the
representation dimensionality of the application. In this perspective, we
address the question: When does an AI medical application need to be explained,
and at what level of detail?

ÊëòË¶ÅÔºöÂèØËß£ÈáäÊÄßÈÄöÂ∏∏ÂØπ‰∫é‰∫∫Â∑•Êô∫ËÉΩ (AI) ÁöÑÂèØÊé•ÂèóÂÆûÊñΩËá≥ÂÖ≥ÈáçË¶Å„ÄÇÂú®ÂåªÁñó‰øùÂÅ•È¢ÜÂüüÔºåËøô‰∏ÄÁÇπÂ∞§‰∏∫ÈáçË¶ÅÔºåÂõ†‰∏∫ÂÜ≥Á≠ñÁõ¥Êé•ÂΩ±ÂìçÊÇ£ËÄÖÔºåÂπ∂‰∏îÂØπ AI Á≥ªÁªüÁöÑ‰ø°‰ªªËá≥ÂÖ≥ÈáçË¶Å„ÄÇËøôÁßç‰ø°‰ªªÈÄöÂ∏∏Âª∫Á´ãÂú® AI Êèê‰æõÁöÑËß£ÈáäÂíåËØ†Èáä‰πã‰∏ä„ÄÇÂ∞ΩÁÆ° AI ÂèØËß£ÈáäÊÄßÂèñÂæó‰∫ÜÈáçÂ§ßËøõÂ±ïÔºå‰ΩÜ‰ªçÁÑ∂ÈúÄË¶ÅÊòéÁ°ÆÁöÑÊåáÂØºÊñπÈíàÔºåËØ¥ÊòéÂú®ÂåªÁñóÁéØÂ¢É‰∏≠‰ΩïÊó∂‰ª•ÂèäÂú®Â§öÂ§ßÁ®ãÂ∫¶‰∏äÈúÄË¶ÅËß£Èáä„ÄÇÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞È¢ñÁöÑÂàÜÁ±ªÁ≥ªÁªüÔºåËØ•Á≥ªÁªüÂÖ∑ÊúâÂõõÁßç‰∏çÂêåÁöÑËß£ÈáäÂøÖË¶ÅÊÄßÁ±ªÂà´ÔºåÊåáÂØºÊâÄÈúÄÁöÑËß£ÈáäÁ∫ßÂà´ÔºöÊÇ£ËÄÖÊàñÊ†∑Êú¨ÔºàÂ±ÄÈÉ®ÔºâÁ∫ßÂà´„ÄÅÈòüÂàóÊàñÊï∞ÊçÆÈõÜÔºàÂÖ®Â±ÄÔºâÁ∫ßÂà´ÔºåÊàñ‰∏§‰∏™Á∫ßÂà´„ÄÇÊàë‰ª¨ÂºïÂÖ•‰∫Ü‰∏Ä‰∏™Êï∞Â≠¶ÂÖ¨ÂºèÔºåËØ•ÂÖ¨ÂºèÂå∫ÂàÜ‰∫ÜËøô‰∫õÁ±ªÂà´ÔºåÂπ∂‰∏∫Á†îÁ©∂‰∫∫ÂëòÊèê‰æõ‰∫Ü‰∏Ä‰∏™ÂÆûÁî®Ê°ÜÊû∂Ôºå‰ª•Á°ÆÂÆöÂåªÁñó AI Â∫îÁî®‰∏≠ÊâÄÈúÄÁöÑËß£ÈáäÁöÑÂøÖË¶ÅÊÄßÂíåÊ∑±Â∫¶„ÄÇËÄÉËôë‰∫Ü‰∏â‰∏™ÂÖ≥ÈîÆÂõ†Á¥†ÔºöËØÑ‰º∞ÂçèËÆÆÁöÑÁ®≥ÂÅ•ÊÄß„ÄÅ‰∏ìÂÆ∂ËßÇÂØüÁöÑÂèØÂèòÊÄß‰ª•ÂèäÂ∫îÁî®Á®ãÂ∫èÁöÑË°®Á§∫Áª¥Êï∞„ÄÇ‰ªéËøô‰∏™ËßíÂ∫¶Êù•ÁúãÔºåÊàë‰ª¨Ëß£ÂÜ≥‰∫ÜËøô‰∏™ÈóÆÈ¢òÔºöAI ÂåªÁñóÂ∫îÁî®‰ΩïÊó∂ÈúÄË¶ÅËß£ÈáäÔºå‰ª•ÂèäÈúÄË¶ÅËß£ÈáäÂà∞‰ΩïÁßçÁ®ãÂ∫¶Ôºü

##### **Interdisciplinary Expertise to Advance Equitable Explainable AI**
2406.18563v1 by Chloe R. Bennett, Heather Cole-Lewis, Stephanie Farquhar, Naama Haamel, Boris Babenko, Oran Lang, Mat Fleck, Ilana Traynis, Charles Lau, Ivor Horn, Courtney Lyles

The field of artificial intelligence (AI) is rapidly influencing health and
healthcare, but bias and poor performance persists for populations who face
widespread structural oppression. Previous work has clearly outlined the need
for more rigorous attention to data representativeness and model performance to
advance equity and reduce bias. However, there is an opportunity to also
improve the explainability of AI by leveraging best practices of social
epidemiology and health equity to help us develop hypotheses for associations
found. In this paper, we focus on explainable AI (XAI) and describe a framework
for interdisciplinary expert panel review to discuss and critically assess AI
model explanations from multiple perspectives and identify areas of bias and
directions for future research. We emphasize the importance of the
interdisciplinary expert panel to produce more accurate, equitable
interpretations which are historically and contextually informed.
Interdisciplinary panel discussions can help reduce bias, identify potential
confounders, and identify opportunities for additional research where there are
gaps in the literature. In turn, these insights can suggest opportunities for
AI model improvement.

ÊëòË¶ÅÔºö‰∫∫Â∑•Êô∫ÊÖß (AI) È†òÂüüÊ≠£Âø´ÈÄüÂΩ±ÈüøËëóÂÅ•Â∫∑ËàáÈÜ´ÁôÇ‰øùÂÅ•Ôºå‰ΩÜÂ∞çÊñºÈù¢Ëá®Âª£Ê≥õÁµêÊßãÊÄßÂ£ìËø´ÁöÑ‰∫∫Áæ§‰æÜË™™ÔºåÂÅèË¶ãÂíå‰∏çËâØË°®Áèæ‰æùÁÑ∂Â≠òÂú®„ÄÇÂÖàÂâçÁöÑÁ†îÁ©∂Â∑≤Ê∏ÖÊ•öË™™ÊòéÔºåÈúÄË¶ÅÊõ¥Âö¥Ê†ºÂú∞Ê≥®ÊÑèË≥áÊñô‰ª£Ë°®ÊÄßÂíåÊ®°ÂûãÊïàËÉΩÔºå‰ª•‰øÉÈÄ≤ÂÖ¨Âπ≥ÊÄß‰∏¶Ê∏õÂ∞ëÂÅèË¶ã„ÄÇÁÑ∂ËÄåÔºåÊàëÂÄëÊúâÊ©üÊúÉÈÄèÈÅéÈÅãÁî®Á§æÊúÉÊµÅË°åÁóÖÂ≠∏ÂíåÂÅ•Â∫∑ÂÖ¨Âπ≥ÁöÑÊúÄ‰Ω≥ÂØ¶ÂãôÔºå‰æÜÊîπÂñÑ AI ÁöÑÂèØËß£ÈáãÊÄßÔºå‰ª•Âπ´Âä©ÊàëÂÄëÈáùÂ∞çÁôºÁèæÁöÑÈóúËÅØÊÄßÔºåÁôºÂ±ïÂÅáË®≠„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂ∞àÊ≥®ÊñºÂèØËß£Èáã AI (XAI)Ôºå‰∏¶ÊèèËø∞‰∏ÄÂÄãË∑®È†òÂüüÂ∞àÂÆ∂Â∞èÁµÑÂØ©Êü•Êû∂ÊßãÔºå‰ª•ÂæûÂ§öÈáçËßÄÈªûË®éË´ñÂíåÊâπÂà§ÊÄßË©ï‰º∞ AI Ê®°ÂûãÁöÑËß£ÈáãÔºå‰∏¶ÊâæÂá∫ÂÅèË¶ãÈ†òÂüüÂíåÊú™‰æÜÁ†îÁ©∂ÁöÑÊñπÂêë„ÄÇÊàëÂÄëÂº∑Ë™øË∑®È†òÂüüÂ∞àÂÆ∂Â∞èÁµÑÂ∞çÊñºÁî¢ÁîüÊõ¥Ê∫ñÁ¢∫„ÄÅÂÖ¨Âπ≥ÁöÑË©ÆÈáãËá≥ÈóúÈáçË¶ÅÔºåËÄåÈÄô‰∫õË©ÆÈáãÊòØÊ†πÊìöÊ≠∑Âè≤ÂíåËÑàÁµ°ËÄå‰æÜÁöÑ„ÄÇË∑®È†òÂüüÂ∞èÁµÑË®éË´ñÊúâÂä©ÊñºÊ∏õÂ∞ëÂÅèË¶ã„ÄÅÊâæÂá∫ÊΩõÂú®ÁöÑÊ∑∑Ê∑ÜÂõ†Á¥†Ôºå‰∏¶Âú®ÊñáÁçª‰∏≠ÊúâÁº∫Âè£ÊôÇÊâæÂá∫È°çÂ§ñÁ†îÁ©∂ÁöÑÊ©üÊúÉ„ÄÇÂèçÈÅé‰æÜÔºåÈÄô‰∫õË¶ãËß£ÂèØ‰ª•Âª∫Ë≠∞ AI Ê®°ÂûãÊîπÈÄ≤ÁöÑÊ©üÊúÉ„ÄÇ

##### **"It depends": Configuring AI to Improve Clinical Usefulness Across Contexts**
2407.11978v1 by Hubert D. ZajƒÖc, Jorge M. N. Ribeiro, Silvia Ingala, Simona Gentile, Ruth Wanjohi, Samuel N. Gitau, Jonathan F. Carlsen, Michael B. Nielsen, Tariq O. Andersen

Artificial Intelligence (AI) repeatedly match or outperform radiologists in
lab experiments. However, real-world implementations of radiological AI-based
systems are found to provide little to no clinical value. This paper explores
how to design AI for clinical usefulness in different contexts. We conducted 19
design sessions and design interventions with 13 radiologists from 7 clinical
sites in Denmark and Kenya, based on three iterations of a functional AI-based
prototype. Ten sociotechnical dependencies were identified as crucial for the
design of AI in radiology. We conceptualised four technical dimensions that
must be configured to the intended clinical context of use: AI functionality,
AI medical focus, AI decision threshold, and AI Explainability. We present four
design recommendations on how to address dependencies pertaining to the medical
knowledge, clinic type, user expertise level, patient context, and user
situation that condition the configuration of these technical dimensions.

ÊëòË¶ÅÔºö‰∫∫Â∑•Êô∫ÊÖßÔºàAIÔºâÂú®ÂØ¶È©óÂÆ§ÂØ¶È©ó‰∏≠‰∏çÊñ∑Âú∞ËàáÊîæÂ∞ÑÁßëÈÜ´Â∏´ÂåπÊïµÊàñË°®ÁèæÂæóÊõ¥Âá∫Ëâ≤„ÄÇÁÑ∂ËÄåÔºåÁôºÁèæÊîæÂ∞ÑÁßë AI ÁÇ∫Âü∫Á§éÁ≥ªÁµ±ÁöÑÂØ¶ÈöõÂü∑Ë°åÂπæ‰πéÊ≤íÊúâÊèê‰æõËá®Â∫äÂÉπÂÄº„ÄÇÊú¨ÊñáÊé¢Ë®éÂ¶Ç‰ΩïÁÇ∫ AI Ë®≠Ë®àÂú®‰∏çÂêåÊÉÖÂ¢É‰∏≠Ëá®Â∫ä‰∏äÁöÑÊïàÁî®„ÄÇÊàëÂÄëÊ†πÊìöÂäüËÉΩÊÄß AI ÁÇ∫Âü∫Á§éÂéüÂûãÁöÑ‰∏âÊ¨°Ëø≠‰ª£ÔºåÂú®‰∏πÈ∫•ÂíåËÇØ‰∫ûÁöÑ 7 ÂÄãËá®Â∫äÂ†¥ÂüüËàá 13 ‰ΩçÊîæÂ∞ÑÁßëÈÜ´Â∏´ÈÄ≤Ë°å‰∫Ü 19 Ê¨°Ë®≠Ë®àÊúÉË≠∞ÂíåË®≠Ë®à‰ªãÂÖ•„ÄÇÂçÅÂÄãÁ§æÊúÉÊäÄË°ì‰æùË≥¥Èóú‰øÇË¢´Ë™çÁÇ∫Â∞çÊñºÊîæÂ∞ÑÁßë‰∏≠ AI ÁöÑË®≠Ë®àËá≥ÈóúÈáçË¶Å„ÄÇÊàëÂÄëÊ¶ÇÂøµÂåñ‰∫ÜÂõõÂÄãÊäÄË°ìÈù¢ÂêëÔºåÂøÖÈ†àÊ†πÊìöÈ†êÊúüÁöÑËá®Â∫ä‰ΩøÁî®ÊÉÖÂ¢ÉÈÄ≤Ë°åË®≠ÂÆöÔºöAI ÂäüËÉΩ„ÄÅAI ÈÜ´ÁôÇÈáçÈªû„ÄÅAI Ê±∫Á≠ñÈñÄÊ™ªÔºå‰ª•Âèä AI ÂèØËß£ÈáãÊÄß„ÄÇÊàëÂÄëÊèêÂá∫ÂõõÈ†ÖË®≠Ë®àÂª∫Ë≠∞ÔºåË™™ÊòéÂ¶Ç‰ΩïËôïÁêÜËàáÈÜ´ÁôÇÁü•Ë≠ò„ÄÅË®∫ÊâÄÈ°ûÂûã„ÄÅ‰ΩøÁî®ËÄÖÂ∞àÊ•≠Áü•Ë≠òÁ≠âÁ¥ö„ÄÅÊÇ£ËÄÖÊÉÖÂ¢ÉÔºå‰ª•ÂèäÂΩ±ÈüøÈÄô‰∫õÊäÄË°ìÈù¢ÂêëË®≠ÂÆöÁöÑ‰ΩøÁî®ËÄÖÊÉÖÂ¢ÉÁõ∏ÈóúÁöÑ‰æùË≥¥Èóú‰øÇ„ÄÇ

##### **Improving Health Professionals' Onboarding with AI and XAI for Trustworthy Human-AI Collaborative Decision Making**
2405.16424v1 by Min Hun Lee, Silvana Xin Yi Choo, Shamala D/O Thilarajah

With advanced AI/ML, there has been growing research on explainable AI (XAI)
and studies on how humans interact with AI and XAI for effective human-AI
collaborative decision-making. However, we still have a lack of understanding
of how AI systems and XAI should be first presented to users without technical
backgrounds. In this paper, we present the findings of semi-structured
interviews with health professionals (n=12) and students (n=4) majoring in
medicine and health to study how to improve onboarding with AI and XAI. For the
interviews, we built upon human-AI interaction guidelines to create onboarding
materials of an AI system for stroke rehabilitation assessment and AI
explanations and introduce them to the participants. Our findings reveal that
beyond presenting traditional performance metrics on AI, participants desired
benchmark information, the practical benefits of AI, and interaction trials to
better contextualize AI performance, and refine the objectives and performance
of AI. Based on these findings, we highlight directions for improving
onboarding with AI and XAI and human-AI collaborative decision-making.

ÊëòË¶ÅÔºöÈö®ËëóÂÖàÈÄ≤ÁöÑ AI/MLÔºåÂ∞çÂèØËß£Èáã AI (XAI) ÁöÑÁ†îÁ©∂‰∏çÊñ∑Â¢ûÂä†Ôºå‰ª•ÂèäÈóúÊñº‰∫∫È°ûÂ¶Ç‰ΩïËàá AI Âíå XAI ‰∫íÂãï‰ª•ÈÄ≤Ë°åÊúâÊïàÁöÑ‰∫∫Â∑•Êô∫ÊÖßÂçî‰ΩúÊ±∫Á≠ñÂà∂ÂÆö„ÄÇÁÑ∂ËÄåÔºåÊàëÂÄë‰ªçÁÑ∂Áº∫‰πèÂ∞ç AI Á≥ªÁµ±Âíå XAI ÊáâÂ¶Ç‰ΩïÈ¶ñÂÖàÂëàÁèæÁµ¶Ê≤íÊúâÊäÄË°ìËÉåÊôØÁöÑÁî®Êà∂ÁöÑ‰∫ÜËß£„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜËàáÈÜ´ÁôÇÂ∞àÊ•≠‰∫∫Âì° (n=12) Âíå‰∏ª‰øÆÈÜ´Â≠∏ÂíåÂÅ•Â∫∑ÁöÑÂ≠∏Áîü (n=4) ÈÄ≤Ë°åÂçäÁµêÊßãÂåñË®™Ë´áÁöÑÁµêÊûúÔºå‰ª•Á†îÁ©∂Â¶Ç‰ΩïÊîπÂñÑ AI Âíå XAI ÁöÑÂÖ•ÈñÄ„ÄÇÂ∞çÊñºË®™Ë´áÔºåÊàëÂÄëÂª∫Á´ãÂú®‰∫∫Ê©ü‰∫íÂãïÊ∫ñÂâá‰πã‰∏äÔºåÁÇ∫‰∏≠È¢®Â∫∑Âæ©Ë©ï‰º∞Âíå AI Ëß£ÈáãÁöÑ AI Á≥ªÁµ±ÂâµÂª∫ÂÖ•ÈñÄÊùêÊñôÔºå‰∏¶Â∞áÂÆÉÂÄë‰ªãÁ¥πÁµ¶ÂèÉËàáËÄÖ„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúË°®ÊòéÔºåÈô§‰∫ÜÂëàÁèæÂÇ≥Áµ±ÁöÑ AI ÊÄßËÉΩÊåáÊ®ôÂ§ñÔºåÂèÉËàáËÄÖÈÇÑÂ∏åÊúõÂü∫ÂáÜ‰ø°ÊÅØ„ÄÅAI ÁöÑÂØ¶ÈöõÂ•ΩËôï‰ª•Âèä‰∫§‰∫íË©¶È©óÔºå‰ª•Êõ¥Â•ΩÂú∞Â∞á AI ÊÄßËÉΩÊÉÖÂ¢ÉÂåñÔºå‰∏¶ÂÆåÂñÑ AI ÁöÑÁõÆÊ®ôÂíåÊÄßËÉΩ„ÄÇÊ†πÊìöÈÄô‰∫õÁôºÁèæÔºåÊàëÂÄëÂº∑Ë™ø‰∫ÜÊîπÈÄ≤ AI Âíå XAI ‰ª•Âèä‰∫∫Ê©üÂçî‰ΩúÊ±∫Á≠ñÂà∂ÂÆöÁöÑÂÖ•ÈñÄÊñπÂêë„ÄÇ

##### **Exploring Nutritional Impact on Alzheimer's Mortality: An Explainable AI Approach**
2405.17502v1 by Ziming Liu, Longjian Liu, Robert E. Heidel, Xiaopeng Zhao

This article uses machine learning (ML) and explainable artificial
intelligence (XAI) techniques to investigate the relationship between
nutritional status and mortality rates associated with Alzheimers disease (AD).
The Third National Health and Nutrition Examination Survey (NHANES III)
database is employed for analysis. The random forest model is selected as the
base model for XAI analysis, and the Shapley Additive Explanations (SHAP)
method is used to assess feature importance. The results highlight significant
nutritional factors such as serum vitamin B12 and glycated hemoglobin. The
study demonstrates the effectiveness of random forests in predicting AD
mortality compared to other diseases. This research provides insights into the
impact of nutrition on AD and contributes to a deeper understanding of disease
progression.

ÊëòË¶ÅÔºöÊú¨Êñá‰ΩøÁî®Ê©üÂô®Â≠∏Áøí (ML) ÂíåÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖß (XAI) ÊäÄË°ì‰æÜÊé¢Ë®éÁáüÈ§äÁãÄÊ≥ÅËàáÈòøËå≤Êµ∑ÈªòÁóá (AD) Áõ∏ÈóúÁöÑÊ≠ª‰∫°Áéá‰πãÈñìÁöÑÈóú‰øÇ„ÄÇÊé°Áî®Á¨¨‰∏âÊ¨°ÂÖ®ÂúãÂÅ•Â∫∑ËàáÁáüÈ§äÊ™¢Êü•Ë™øÊü• (NHANES III) Ë≥áÊñôÂ∫´ÈÄ≤Ë°åÂàÜÊûê„ÄÇÈÅ∏ÊìáÈö®Ê©üÊ£ÆÊûóÊ®°Âûã‰ΩúÁÇ∫ XAI ÂàÜÊûêÁöÑÂü∫Á§éÊ®°ÂûãÔºå‰∏¶‰ΩøÁî® Shapley Additive Explanations (SHAP) ÊñπÊ≥ï‰æÜË©ï‰º∞ÁâπÂæµÈáçË¶ÅÊÄß„ÄÇÁµêÊûúÁ™ÅÈ°Ø‰∫ÜÈáçË¶ÅÁöÑÁáüÈ§äÂõ†Á¥†Ôºå‰æãÂ¶ÇË°ÄÊ∏ÖÁ∂≠ÁîüÁ¥† B12 ÂíåÁ≥ñÂåñË°ÄÁ¥ÖËõãÁôΩ„ÄÇË©≤Á†îÁ©∂Ë≠âÊòé‰∫ÜÈö®Ê©üÊ£ÆÊûóÂú®È†êÊ∏¨ AD Ê≠ª‰∫°ÁéáÊñπÈù¢Áõ∏ËºÉÊñºÂÖ∂‰ªñÁñæÁóÖÁöÑÊúâÊïàÊÄß„ÄÇÊú¨Á†îÁ©∂Êèê‰æõ‰∫ÜÁáüÈ§äÂ∞ç AD ÁöÑÂΩ±ÈüøÁöÑË¶ãËß£Ôºå‰∏¶ÊúâÂä©ÊñºÊõ¥Ê∑±ÂÖ•Âú∞‰∫ÜËß£ÁñæÁóÖÁöÑÈÄ≤Â±ï„ÄÇ

##### **Explainable AI Enhances Glaucoma Referrals, Yet the Human-AI Team Still Falls Short of the AI Alone**
2407.11974v1 by Catalina Gomez, Ruolin Wang, Katharina Breininger, Corinne Casey, Chris Bradley, Mitchell Pavlak, Alex Pham, Jithin Yohannan, Mathias Unberath

Primary care providers are vital for initial triage and referrals to
specialty care. In glaucoma, asymptomatic and fast progression can lead to
vision loss, necessitating timely referrals to specialists. However, primary
eye care providers may not identify urgent cases, potentially delaying care.
Artificial Intelligence (AI) offering explanations could enhance their referral
decisions. We investigate how various AI explanations help providers
distinguish between patients needing immediate or non-urgent specialist
referrals. We built explainable AI algorithms to predict glaucoma surgery needs
from routine eyecare data as a proxy for identifying high-risk patients. We
incorporated intrinsic and post-hoc explainability and conducted an online
study with optometrists to assess human-AI team performance, measuring referral
accuracy and analyzing interactions with AI, including agreement rates, task
time, and user experience perceptions. AI support enhanced referral accuracy
among 87 participants (59.9%/50.8% with/without AI), though Human-AI teams
underperformed compared to AI alone. Participants believed they included AI
advice more when using the intrinsic model, and perceived it more useful and
promising. Without explanations, deviations from AI recommendations increased.
AI support did not increase workload, confidence, and trust, but reduced
challenges. On a separate test set, our black-box and intrinsic models achieved
an accuracy of 77% and 71%, respectively, in predicting surgical outcomes. We
identify opportunities of human-AI teaming for glaucoma management in primary
eye care, noting that while AI enhances referral accuracy, it also shows a
performance gap compared to AI alone, even with explanations. Human involvement
remains essential in medical decision making, underscoring the need for future
research to optimize collaboration, ensuring positive experiences and safe AI
use.

ÊëòË¶ÅÔºö<paragraph>ÂàùÁ¥ö‰øùÂÅ•Êèê‰æõËÄÖÂ∞çÊñºÊúÄÂàùÁöÑÂàÜÊµÅÂíåËΩâË®∫Âà∞Â∞àÁßëÁÖßË≠∑Ëá≥ÈóúÈáçË¶Å„ÄÇÂú®ÈùíÂÖâÁúºÁöÑÊÉÖÊ≥Å‰∏ãÔºåÁÑ°ÁóáÁãÄ‰∏îÂø´ÈÄüÊÉ°ÂåñÂèØËÉΩÂ∞éËá¥Ë¶ñÂäõÂñ™Â§±ÔºåÂõ†Ê≠§ÈúÄË¶ÅÂèäÊôÇËΩâË®∫Áµ¶Â∞àÂÆ∂„ÄÇÁÑ∂ËÄåÔºåÂàùÁ¥öÁúºÁßë‰øùÂÅ•Êèê‰æõËÄÖÂèØËÉΩÁÑ°Ê≥ïË≠òÂà•Á∑äÊÄ•ÊÉÖÊ≥ÅÔºåÂèØËÉΩÊúÉÂª∂Ë™§ÁÖßË≠∑„ÄÇÊèê‰æõËß£ÈáãÁöÑ‰∫∫Â∑•Êô∫ÊÖß (AI) ÂèØ‰ª•Âä†Âº∑‰ªñÂÄëÁöÑËΩâË®∫Ê±∫Á≠ñ„ÄÇÊàëÂÄëÁ†îÁ©∂ÂêÑÁ®Æ AI Ëß£ÈáãÂ¶Ç‰ΩïÂπ´Âä©Êèê‰æõËÄÖÂçÄÂàÜÈúÄË¶ÅÁ´ãÂç≥ÊàñÈùûÁ∑äÊÄ•Â∞àÁßëËΩâË®∫ÁöÑÊÇ£ËÄÖ„ÄÇÊàëÂÄëÂª∫Á´ã‰∫ÜËß£ÈáãÊÄß AI ÊºîÁÆóÊ≥ïÔºå‰ª•Âæû‰æãË°åÁúºÁßëË≠∑ÁêÜË≥áÊñôÈ†êÊ∏¨ÈùíÂÖâÁúºÊâãË°ìÈúÄÊ±ÇÔºå‰ΩúÁÇ∫Ë≠òÂà•È´òÈ¢®Èö™ÊÇ£ËÄÖÁöÑ‰ª£ÁêÜ„ÄÇÊàëÂÄëÁ¥çÂÖ•‰∫ÜÂÖßÂú®Âíå‰∫ãÂæåËß£ÈáãÊÄßÔºå‰∏¶ËàáÈ©óÂÖâÂ∏´ÈÄ≤Ë°å‰∫Ü‰∏ÄÈ†ÖÁ∑ö‰∏äÁ†îÁ©∂Ôºå‰ª•Ë©ï‰º∞‰∫∫Ê©üÂúòÈöäÁöÑË°®ÁèæÔºåË°°ÈáèËΩâË®∫Ê∫ñÁ¢∫Â∫¶‰∏¶ÂàÜÊûêËàá AI ÁöÑ‰∫íÂãïÔºåÂåÖÊã¨ÂêåÊÑèÁéá„ÄÅ‰ªªÂãôÊôÇÈñìÂíå‰ΩøÁî®ËÄÖÈ´îÈ©óÊÑüÁü•„ÄÇÂú® 87 ÂêçÂèÉËàáËÄÖ‰∏≠ÔºåAI ÊîØÊè¥ÊèêÈ´ò‰∫ÜËΩâË®∫Ê∫ñÁ¢∫Â∫¶Ôºà‰ΩøÁî® AI/Êú™‰ΩøÁî®ÁöÑÊØî‰æãÁÇ∫ 59.9%/50.8%ÔºâÔºåÂÑòÁÆ°‰∫∫Ê©üÂúòÈöäÁöÑË°®Áèæ‰∏çÂ¶ÇÂñÆÁç®‰ΩøÁî® AI„ÄÇÂèÉËàáËÄÖË™çÁÇ∫‰ªñÂÄëÂú®‰ΩøÁî®ÂÖßÂú®Ê®°ÂûãÊôÇÊõ¥Â§öÂú∞Á¥çÂÖ•‰∫Ü AI Âª∫Ë≠∞Ôºå‰∏¶Ë™çÁÇ∫ÂÆÉÊõ¥ÊúâÁî®‰∏îÊõ¥ÊúâÂ∏åÊúõ„ÄÇÊ≤íÊúâËß£ÈáãÔºåAI Âª∫Ë≠∞ÁöÑÂÅèÂ∑ÆÊúÉÂ¢ûÂä†„ÄÇAI ÊîØÊè¥‰∏¶Êú™Â¢ûÂä†Â∑•‰ΩúÈáè„ÄÅ‰ø°ÂøÉÂíå‰ø°‰ªªÔºå‰ΩÜÊ∏õÂ∞ë‰∫ÜÊåëÊà∞„ÄÇÂú®‰∏ÄÂÄãÂñÆÁç®ÁöÑÊ∏¨Ë©¶ÈõÜ‰∏≠ÔºåÊàëÂÄëÁöÑÈªëÁõíÂ≠êÂíåÂÖßÂú®Ê®°ÂûãÂú®È†êÊ∏¨ÊâãË°ìÁµêÊûúÊñπÈù¢ÂàÜÂà•ÈÅîÂà∞‰∫Ü 77% Âíå 71% ÁöÑÊ∫ñÁ¢∫Â∫¶„ÄÇÊàëÂÄëÊâæÂá∫Âú®ÂàùÁ¥öÁúºÁßë‰øùÂÅ•‰∏≠Ôºå‰∫∫Ê©üÂúòÈöäÂêà‰ΩúÁÆ°ÁêÜÈùíÂÖâÁúºÁöÑÊ©üÊúÉÔºå‰∏¶Ê≥®ÊÑèÂà∞ÈõñÁÑ∂ AI ÊèêÈ´ò‰∫ÜËΩâË®∫Ê∫ñÁ¢∫Â∫¶Ôºå‰ΩÜÂç≥‰ΩøÊúâËß£ÈáãÔºåÂÆÉ‰πüÈ°ØÁ§∫Âá∫ËàáÂñÆÁç®‰ΩøÁî® AI Áõ∏ÊØîÁöÑÊïàËÉΩÂ∑ÆË∑ù„ÄÇ‰∫∫È°ûÂèÉËàáÂú®ÈÜ´ÁôÇÊ±∫Á≠ñ‰∏≠‰ªçÁÑ∂Ëá≥ÈóúÈáçË¶ÅÔºåÈÄôÂº∑Ë™ø‰∫ÜÊú™‰æÜÁ†îÁ©∂ÂÑ™ÂåñÂçî‰Ωú„ÄÅÁ¢∫‰øùÊ≠£Èù¢Á∂ìÈ©óÂíåÂÆâÂÖ®‰ΩøÁî® AI ÁöÑÂøÖË¶ÅÊÄß„ÄÇ</paragraph>

##### **Decoding Decision Reasoning: A Counterfactual-Powered Model for Knowledge Discovery**
2406.18552v1 by Yingying Fang, Zihao Jin, Xiaodan Xing, Simon Walsh, Guang Yang

In medical imaging, particularly in early disease detection and prognosis
tasks, discerning the rationale behind an AI model's predictions is crucial for
evaluating the reliability of its decisions. Conventional explanation methods
face challenges in identifying discernible decisive features in medical image
classifications, where discriminative features are subtle or not immediately
apparent. To bridge this gap, we propose an explainable model that is equipped
with both decision reasoning and feature identification capabilities. Our
approach not only detects influential image patterns but also uncovers the
decisive features that drive the model's final predictions. By implementing our
method, we can efficiently identify and visualise class-specific features
leveraged by the data-driven model, providing insights into the decision-making
processes of deep learning models. We validated our model in the demanding
realm of medical prognosis task, demonstrating its efficacy and potential in
enhancing the reliability of AI in healthcare and in discovering new knowledge
in diseases where prognostic understanding is limited.

ÊëòË¶ÅÔºöÂú®ÈÜ´Â≠∏ÂΩ±ÂÉè‰∏≠ÔºåÁâπÂà•ÊòØÂú®Êó©ÊúüÁñæÁóÖÊ™¢Ê∏¨ÂíåÈ†êÂæå‰ªªÂãô‰∏≠ÔºåËæ®Âà• AI Ê®°ÂûãÈ†êÊ∏¨ËÉåÂæåÁöÑÂéüÁêÜÂ∞çÊñºË©ï‰º∞ÂÖ∂Ê±∫Á≠ñÁöÑÂèØÈù†ÊÄßËá≥ÈóúÈáçË¶Å„ÄÇÂÇ≥Áµ±ÁöÑËß£ÈáãÊñπÊ≥ïÂú®Ë≠òÂà•ÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÈ°û‰∏≠ÂèØË≠òÂà•ÁöÑÊ±∫ÂÆöÊÄßÁâπÂæµÊôÇÈù¢Ëá®ÊåëÊà∞ÔºåÂÖ∂‰∏≠ÂçÄÂà•ÊÄßÁâπÂæµÂæàÂæÆÂ¶ôÊàñ‰∏¶‰∏çÊòéÈ°Ø„ÄÇÁÇ∫‰∫ÜÂΩåÂêàÈÄô‰∏ÄÂ∑ÆË∑ùÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂèØËß£ÈáãÁöÑÊ®°ÂûãÔºåË©≤Ê®°ÂûãÂÖ∑ÂÇôÊ±∫Á≠ñÊé®ÁêÜÂíåÁâπÂæµË≠òÂà•ËÉΩÂäõ„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ï‰∏çÂÉÖÊ™¢Ê∏¨ÊúâÂΩ±ÈüøÂäõÁöÑÂΩ±ÂÉèÊ®°ÂºèÔºåÈÇÑÊè≠Á§∫‰∫ÜÊé®ÂãïÊ®°ÂûãÊúÄÁµÇÈ†êÊ∏¨ÁöÑÊ±∫ÂÆöÊÄßÁâπÂæµ„ÄÇÈÄöÈÅéÂØ¶ÊñΩÊàëÂÄëÁöÑÊ®°ÂûãÔºåÊàëÂÄëÂèØ‰ª•ÊúâÊïàË≠òÂà•ÂíåË¶ñË¶∫ÂåñÁî±Êï∏ÊìöÈ©ÖÂãïÊ®°ÂûãÂà©Áî®ÁöÑÈ°ûÁâπÂÆöÁâπÂæµÔºåÂæûËÄåÊ∑±ÂÖ•‰∫ÜËß£Ê∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÁöÑÊ±∫Á≠ñÈÅéÁ®ã„ÄÇÊàëÂÄëÂú®Ë¶ÅÊ±ÇÂö¥Ê†ºÁöÑÈÜ´Â≠∏È†êÂæå‰ªªÂãôÈ†òÂüüÈ©óË≠â‰∫ÜÊàëÂÄëÁöÑÊ®°ÂûãÔºåÂ±ïÁ§∫‰∫ÜÂÖ∂Âú®ÊèêÈ´ò AI Âú®ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÁöÑÂèØÈù†ÊÄßÂíåÁôºÁèæÈ†êÂæåÁêÜËß£ÂèóÈôêÁñæÁóÖÁöÑÊñ∞Áü•Ë≠òÊñπÈù¢ÁöÑÂäüÊïàÂíåÊΩõÂäõ„ÄÇ

##### **The Role of Emotions in Informational Support Question-Response Pairs in Online Health Communities: A Multimodal Deep Learning Approach**
2405.13099v1 by Mohsen Jozani, Jason A. Williams, Ahmed Aleroud, Sarbottam Bhagat

This study explores the relationship between informational support seeking
questions, responses, and helpfulness ratings in online health communities. We
created a labeled data set of question-response pairs and developed multimodal
machine learning and deep learning models to reliably predict informational
support questions and responses. We employed explainable AI to reveal the
emotions embedded in informational support exchanges, demonstrating the
importance of emotion in providing informational support. This complex
interplay between emotional and informational support has not been previously
researched. The study refines social support theory and lays the groundwork for
the development of user decision aids. Further implications are discussed.

ÊëòË¶ÅÔºöÊú¨Á†îÁ©∂Êé¢Ë®éÁ∑ö‰∏äÂÅ•Â∫∑Á§æÁæ§‰∏≠Â∞ãÊ±ÇË≥áË®äÊîØÊåÅÁöÑÂïèÈ°å„ÄÅÂõûÊáâÔºå‰ª•ÂèäÊúâÂπ´Âä©ÁöÑË©ïÂàÜ‰πãÈñìÁöÑÈóú‰øÇ„ÄÇÊàëÂÄëÂª∫Á´ã‰∫Ü‰∏ÄÁµÑÊ®ôË®òÁöÑÂïèÁ≠îÈÖçÂ∞çË≥áÊñôÈõÜÔºå‰∏¶ÈñãÁôº‰∫ÜÂ§öÊ®°ÊÖãÊ©üÂô®Â≠∏ÁøíÂíåÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÔºå‰ª•ÂèØÈù†Âú∞È†êÊ∏¨Ë≥áË®äÊîØÊåÅÂïèÈ°åÂíåÂõûÊáâ„ÄÇÊàëÂÄëÊé°Áî®ÂèØËß£ÈáãÁöÑ AI ‰æÜÊè≠Á§∫Ë≥áË®äÊîØÊåÅ‰∫§ÊµÅ‰∏≠ËòäÂê´ÁöÑÊÉÖÁ∑íÔºåË≠âÊòéÊÉÖÁ∑íÂú®Êèê‰æõË≥áË®äÊîØÊåÅ‰∏≠ÁöÑÈáçË¶ÅÊÄß„ÄÇÈÄôÁ®ÆÊÉÖÁ∑íÊîØÊåÅÂíåË≥áË®äÊîØÊåÅ‰πãÈñìÁöÑË§áÈõú‰∫§‰∫í‰ΩúÁî®‰ª•Ââç‰∏¶Êú™Ë¢´Á†îÁ©∂ÈÅé„ÄÇÊú¨Á†îÁ©∂ÊîπÈÄ≤‰∫ÜÁ§æÊúÉÊîØÊåÅÁêÜË´ñÔºå‰∏¶ÁÇ∫‰ΩøÁî®ËÄÖÊ±∫Á≠ñËºîÂä©Â∑•ÂÖ∑ÁöÑÈñãÁôºÂ•†ÂÆö‰∫ÜÂü∫Á§é„ÄÇË®éË´ñ‰∫ÜÈÄ≤‰∏ÄÊ≠•ÁöÑÂΩ±Èüø„ÄÇ

##### **ChatGPT in Classrooms: Transforming Challenges into Opportunities in Education**
2405.10645v1 by Harris Bin Munawar, Nikolaos Misirlis

In the era of exponential technology growth, one unexpected guest has claimed
a seat in classrooms worldwide, Artificial Intelligence. Generative AI, such as
ChatGPT, promises a revolution in education, yet it arrives with a double-edged
sword. Its potential for personalized learning is offset by issues of cheating,
inaccuracies, and educators struggling to incorporate it effectively into their
lesson design. We are standing on the brink of this educational frontier, and
it is clear that we need to navigate this terrain with a lot of care. This is a
major challenge that could undermine the integrity and value of our educational
process. So, how can we turn these challenges into opportunities? When used
inappropriately, AI tools can become the perfect tool for the cut copy paste
mentality, and quickly begin to corrode critical thinking, creativity, and deep
understanding, the most important skills in our rapidly changing world.
Teachers feel that they are not equipped to leverage this technology, widening
the digital divide among educators and institutions. Addressing these concerns
calls for an in depth research approach. We will employ empirical research,
drawing on the Technology Acceptance Model, to assess the attitudes toward
generative AI among educators and students. Understanding their perceptions,
usage patterns, and hurdles is the first crucial step in creating an effective
solution. The present study will be used as a process manual for future
researchers to apply, running their own data, based on the steps explained here

ÊëòË¶ÅÔºöÂú®ÁßëÊäÄÈ£õÈÄüÁôºÂ±ïÁöÑÊôÇ‰ª£Ôºå‰∏Ä‰ΩçÊÑèÂ§ñÁöÑË®™ÂÆ¢Â∑≤Âú®ÂÖ®ÁêÉÊïôÂÆ§‰∏≠‰ΩîÊúâ‰∏ÄÂ∏≠‰πãÂú∞ÔºåÈÇ£Â∞±ÊòØ‰∫∫Â∑•Êô∫ÊÖß„ÄÇÁîüÊàêÂºè AIÔºå‰æãÂ¶Ç ChatGPTÔºåÊâøË´æÂú®ÊïôËÇ≤È†òÂüüÊéÄËµ∑‰∏ÄÂ†¥Èù©ÂëΩÔºå‰ΩÜÂÆÉÂçªÊòØ‰∏ÄÊääÈõôÈù¢ÂàÉ„ÄÇÂÆÉÂú®ÂÄã‰∫∫ÂåñÂ≠∏ÁøíÊñπÈù¢ÁöÑÊΩõÂäõÔºåÂçªÂõ†‰ΩúÂºä„ÄÅ‰∏çÊ∫ñÁ¢∫‰ª•ÂèäÊïôËÇ≤Â∑•‰ΩúËÄÖÈõ£‰ª•Â∞áÂÖ∂ÊúâÊïàËûçÂÖ•ÊïôÂ≠∏Ë®≠Ë®àÁ≠âÂïèÈ°åËÄåÊäµÈä∑„ÄÇÊàëÂÄëÊ≠£Á´ôÂú®ÈÄôÊïôËÇ≤ÂâçÊ≤øÁöÑÈÇäÁ∑£ÔºåÈ°ØÁÑ∂ÊàëÂÄëÈúÄË¶ÅÈùûÂ∏∏Â∞èÂøÉÂú∞Êé¢Á¥¢ÈÄôÁâáÈ†òÂüü„ÄÇÈÄôÊòØ‰∏ÄÂÄãÈáçÂ§ßÁöÑÊåëÊà∞ÔºåÂèØËÉΩÊúÉÊêçÂÆ≥ÊàëÂÄëÊïôËÇ≤ÈÅéÁ®ãÁöÑÂÆåÊï¥ÊÄßÂíåÂÉπÂÄº„ÄÇÈÇ£È∫ºÔºåÊàëÂÄëÂ¶Ç‰ΩïÂ∞áÈÄô‰∫õÊåëÊà∞ËΩâÂåñÁÇ∫Ê©üÈÅáÔºüÁï∂‰∏çÈÅ©Áï∂Âú∞‰ΩøÁî®ÊôÇÔºåAI Â∑•ÂÖ∑ÂèØËÉΩÊúÉÊàêÁÇ∫Ë§áË£ΩË≤º‰∏äÂøÉÊÖãÁöÑÂÆåÁæéÂ∑•ÂÖ∑Ôºå‰∏¶ËøÖÈÄüËÖêËùïÊâπÂà§ÊÄßÊÄùÁ∂≠„ÄÅÂâµÈÄ†ÂäõÂíåÊ∑±ÂÖ•ÁêÜËß£ÔºåÈÄô‰∫õÈÉΩÊòØÊàëÂÄëÂø´ÈÄüËÆäÂåñÁöÑ‰∏ñÁïå‰∏≠ÊúÄÈáçË¶ÅÁöÑÊäÄËÉΩ„ÄÇÊïôÂ∏´ÂÄëË¶∫Âæó‰ªñÂÄëÊ≤íÊúâËÉΩÂäõÂà©Áî®ÈÄôÈ†ÖÊäÄË°ìÔºåÈÄôÊì¥Â§ß‰∫ÜÊïôËÇ≤Â∑•‰ΩúËÄÖÂíåÊ©üÊßã‰πãÈñìÁöÑÊï∏‰ΩçÈ¥ªÊ∫ù„ÄÇËß£Ê±∫ÈÄô‰∫õÂïèÈ°åÈúÄË¶ÅÊ∑±ÂÖ•ÁöÑÁ†îÁ©∂ÊñπÊ≥ï„ÄÇÊàëÂÄëÂ∞áÊé°Áî®ÂØ¶Ë≠âÁ†îÁ©∂ÔºåÂÄüÈëëÊäÄË°ìÊé•ÂèóÊ®°ÂûãÔºå‰æÜË©ï‰º∞ÊïôËÇ≤Â∑•‰ΩúËÄÖÂíåÂ≠∏ÁîüÂ∞çÁîüÊàêÂºè AI ÁöÑÊÖãÂ∫¶„ÄÇ‰∫ÜËß£‰ªñÂÄëÁöÑÁúãÊ≥ï„ÄÅ‰ΩøÁî®Ê®°ÂºèÂíåÈöúÁ§ôÊòØÂâµÈÄ†ÊúâÊïàËß£Ê±∫ÊñπÊ°àÁöÑÁ¨¨‰∏ÄÂÄãÈóúÈçµÊ≠•È©ü„ÄÇÊú¨Á†îÁ©∂Â∞á‰ΩúÁÇ∫Êú™‰æÜÁ†îÁ©∂‰∫∫Âì°ÊáâÁî®ÁöÑÊµÅÁ®ãÊâãÂÜäÔºåÊ†πÊìöÊ≠§ËôïË™™ÊòéÁöÑÊ≠•È©üÈÅãË°å‰ªñÂÄëËá™Â∑±ÁöÑÊï∏Êìö

##### **Evaluating the Explainable AI Method Grad-CAM for Breath Classification on Newborn Time Series Data**
2405.07590v1 by Camelia Oprea, Mike Gr√ºne, Mateusz Buglowski, Lena Olivier, Thorsten Orlikowsky, Stefan Kowalewski, Mark Schoberer, Andr√© Stollenwerk

With the digitalization of health care systems, artificial intelligence
becomes more present in medicine. Especially machine learning shows great
potential for complex tasks such as time series classification, usually at the
cost of transparency and comprehensibility. This leads to a lack of trust by
humans and thus hinders its active usage. Explainable artificial intelligence
tries to close this gap by providing insight into the decision-making process,
the actual usefulness of its different methods is however unclear. This paper
proposes a user study based evaluation of the explanation method Grad-CAM with
application to a neural network for the classification of breaths in time
series neonatal ventilation data. We present the perceived usefulness of the
explainability method by different stakeholders, exposing the difficulty to
achieve actual transparency and the wish for more in-depth explanations by many
of the participants.

ÊëòË¶ÅÔºöÈö®ËëóÈÜ´ÁôÇ‰øùÂÅ•Á≥ªÁµ±ÁöÑÊï∏‰ΩçÂåñÔºå‰∫∫Â∑•Êô∫ÊÖßÂú®ÈÜ´Â≠∏È†òÂüü‰∏≠ËÆäÂæóÊõ¥Âä†ÊôÆÂèä„ÄÇÁâπÂà•ÊòØÊ©üÂô®Â≠∏ÁøíÂú®ÊôÇÈñìÂ∫èÂàóÂàÜÈ°ûÁ≠âË§áÈõú‰ªªÂãô‰∏≠Â±ïÁèæÂá∫Ê•µÂ§ßÁöÑÊΩõÂäõÔºå‰ΩÜÈÄöÂ∏∏ÊòØ‰ª•ÈÄèÊòéÂ∫¶ÂíåÂèØÁêÜËß£ÊÄßÁÇ∫‰ª£ÂÉπ„ÄÇÈÄôÂ∞éËá¥‰∫∫È°ûÁº∫‰πè‰ø°‰ªªÔºåÂæûËÄåÈòªÁ§ô‰∫ÜÂÖ∂Á©çÊ•µ‰ΩøÁî®„ÄÇÂèØËß£ÈáãÁöÑ‰∫∫Â∑•Êô∫ÊÖßË©¶ÂúñÈÄöÈÅéÊèê‰æõÂ∞çÊ±∫Á≠ñÈÅéÁ®ãÁöÑÊ¥ûÂØü‰æÜÂΩåË£úÈÄô‰∏ÄÂ∑ÆË∑ùÔºå‰ΩÜÂÖ∂‰∏çÂêåÊñπÊ≥ïÁöÑÂØ¶ÈöõÊïàÁî®Â∞ö‰∏çÊ∏ÖÊ•ö„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂü∫Êñº‰ΩøÁî®ËÄÖÁ†îÁ©∂ÁöÑË©ï‰º∞ÔºåÂÖ∂‰∏≠ÂåÖÂê´‰∫Ü Grad-CAM Ëß£ÈáãÊñπÊ≥ïÔºå‰∏¶Â∞áÂÖ∂ÊáâÁî®ÊñºÁ•ûÁ∂ìÁ∂≤Ë∑Ø‰ª•ÂàÜÈ°ûÊôÇÈñìÂ∫èÂàóÊñ∞ÁîüÂÖíÂëºÂê∏Êï∏Êìö‰∏≠ÁöÑÂëºÂê∏„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫Ü‰∏çÂêåÂà©ÁõäÁõ∏ÈóúËÄÖÂ∞çÂèØËß£ÈáãÊÄßÊñπÊ≥ïÁöÑÊÑüÁü•ÊïàÁî®ÔºåÊè≠Á§∫‰∫ÜÂØ¶ÁèæÂØ¶ÈöõÈÄèÊòéÂ∫¶ÁöÑÈõ£Â∫¶Ôºå‰ª•ÂèäË®±Â§öÂèÉËàáËÄÖÂ∏åÊúõÁç≤ÂæóÊõ¥Ê∑±ÂÖ•ÁöÑËß£Èáã„ÄÇ

##### **XAI4LLM. Let Machine Learning Models and LLMs Collaborate for Enhanced In-Context Learning in Healthcare**
2405.06270v3 by Fatemeh Nazary, Yashar Deldjoo, Tommaso Di Noia, Eugenio di Sciascio

The integration of Large Language Models (LLMs) into healthcare diagnostics
offers a promising avenue for clinical decision-making. This study outlines the
development of a novel method for zero-shot/few-shot in-context learning (ICL)
by integrating medical domain knowledge using a multi-layered structured
prompt. We also explore the efficacy of two communication styles between the
user and LLMs: the Numerical Conversational (NC) style, which processes data
incrementally, and the Natural Language Single-Turn (NL-ST) style, which
employs long narrative prompts.
  Our study systematically evaluates the diagnostic accuracy and risk factors,
including gender bias and false negative rates, using a dataset of 920 patient
records in various few-shot scenarios. Results indicate that traditional
clinical machine learning (ML) models generally outperform LLMs in zero-shot
and few-shot settings. However, the performance gap narrows significantly when
employing few-shot examples alongside effective explainable AI (XAI) methods as
sources of domain knowledge. Moreover, with sufficient time and an increased
number of examples, the conversational style (NC) nearly matches the
performance of ML models. Most notably, LLMs demonstrate comparable or superior
cost-sensitive accuracy relative to ML models.
  This research confirms that, with appropriate domain knowledge and tailored
communication strategies, LLMs can significantly enhance diagnostic processes.
The findings highlight the importance of optimizing the number of training
examples and communication styles to improve accuracy and reduce biases in LLM
applications.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ËàáÈÜ´ÁôÇË®∫Êñ∑Êï¥Âêà
ÁÇ∫Ëá®Â∫äÊ±∫Á≠ñÊèê‰æõ‰∫Ü‰∏ÄÂÄãÊúâÂâçÊôØÁöÑÈÄîÂæë„ÄÇÊú¨Á†îÁ©∂Ê¶ÇËø∞‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÊñπÊ≥ïÁöÑÈñãÁôºÔºåÁî®ÊñºÈõ∂Ê¨°Â≠∏Áøí/Â∞ëÈáèÂ≠∏ÁøíÊÉÖÂ¢ÉÂ≠∏Áøí (ICL)ÔºåÊñπÊ≥ïÊòØ‰ΩøÁî®Â§öÂ±§ÁµêÊßãÂåñÊèêÁ§∫Êï¥ÂêàÈÜ´ÁôÇÈ†òÂüüÁü•Ë≠ò„ÄÇÊàëÂÄëÈÇÑÊé¢Ë®é‰∫Ü‰ΩøÁî®ËÄÖËàá LLM ‰πãÈñìÂÖ©Á®ÆÊ∫ùÈÄöÊñπÂºèÁöÑÂäüÊïàÔºöÊï∏ÂÄºÂ∞çË©± (NC) ÊñπÂºèÔºåÂÆÉÊúÉÈÄêÊ≠•ËôïÁêÜË≥áÊñôÔºå‰ª•ÂèäËá™ÁÑ∂Ë™ûË®ÄÂñÆÂõûÂêà (NL-ST) ÊñπÂºèÔºåÂÆÉÊúÉ‰ΩøÁî®Èï∑ÁØáÊïò‰∫ãÊèêÁ§∫„ÄÇ
ÊàëÂÄëÁöÑÁ†îÁ©∂Á≥ªÁµ±ÊÄßÂú∞Ë©ï‰º∞‰∫ÜË®∫Êñ∑Ê∫ñÁ¢∫ÊÄßÂíåÈ¢®Èö™Âõ†Â≠êÔºåÂåÖÊã¨ÊÄßÂà•ÂÅèË¶ãÂíåÂÅáÈô∞ÊÄßÁéáÔºå‰ΩøÁî®‰∫Ü‰∏ÄÂÄãÂåÖÂê´ 920 ÂÄãÊÇ£ËÄÖË®òÈåÑÁöÑË≥áÊñôÈõÜÔºåÊé°Áî®ÂêÑÁ®ÆÂ∞ëÈáèÂ≠∏ÁøíÊÉÖÂ¢É„ÄÇÁµêÊûúË°®ÊòéÔºåÂÇ≥Áµ±ÁöÑËá®Â∫äÊ©üÂô®Â≠∏Áøí (ML) Ê®°ÂûãÈÄöÂ∏∏Âú®Èõ∂Ê¨°Â≠∏ÁøíÂíåÂ∞ëÈáèÂ≠∏ÁøíË®≠ÂÆö‰∏≠Ë°®ÁèæÂÑ™Êñº LLM„ÄÇÁÑ∂ËÄåÔºåÁï∂‰ΩøÁî®Â∞ëÈáèÂ≠∏ÁøíÁØÑ‰æã‰ª•ÂèäÊúâÊïàÁöÑÂèØËß£Èáã AI (XAI) ÊñπÊ≥ï‰ΩúÁÇ∫È†òÂüüÁü•Ë≠ò‰æÜÊ∫êÊôÇÔºåÊïàËÉΩÂ∑ÆË∑ùÊúÉÈ°ØËëóÁ∏ÆÂ∞è„ÄÇÊ≠§Â§ñÔºåÈö®ËëóÊôÇÈñìÂÖÖË∂≥ÂíåÁØÑ‰æãÊï∏ÈáèÂ¢ûÂä†ÔºåÂ∞çË©±ÊñπÂºè (NC) Âπæ‰πéÂèØ‰ª•Â™≤Áæé ML Ê®°ÂûãÁöÑÊïàËÉΩ„ÄÇÊúÄÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåLLM Áõ∏Â∞çÊñº ML Ê®°ÂûãÂ±ïÁèæÂá∫Áõ∏Áï∂ÊàñÊõ¥‰Ω≥ÁöÑÊàêÊú¨ÊïèÊÑüÊ∫ñÁ¢∫Â∫¶„ÄÇ
Êú¨Á†îÁ©∂Ë≠âÂØ¶ÔºåÈÄèÈÅéÈÅ©Áï∂ÁöÑÈ†òÂüüÁü•Ë≠òÂíåÈáèË∫´ÊâìÈÄ†ÁöÑÊ∫ùÈÄöÁ≠ñÁï•ÔºåLLM ÂèØ‰ª•È°ØËëóÂ¢ûÂº∑Ë®∫Êñ∑Á®ãÂ∫è„ÄÇÈÄô‰∫õÁôºÁèæÁ™ÅÈ°Ø‰∫ÜÊúÄ‰Ω≥ÂåñË®ìÁ∑¥ÁØÑ‰æãÊï∏ÈáèÂíåÊ∫ùÈÄöÊñπÂºèÁöÑÈáçË¶ÅÊÄßÔºå‰ª•ÊèêÈ´òÊ∫ñÁ¢∫Â∫¶‰∏¶Ê∏õÂ∞ë LLM ÊáâÁî®‰∏≠ÁöÑÂÅèÂ∑Æ„ÄÇ

##### **To Trust or Not to Trust: Towards a novel approach to measure trust for XAI systems**
2405.05766v1 by Miquel Mir√≥-Nicolau, Gabriel Moy√†-Alcover, Antoni Jaume-i-Cap√≥, Manuel Gonz√°lez-Hidalgo, Maria Gemma Sempere Campello, Juan Antonio Palmer Sancho

The increasing reliance on Deep Learning models, combined with their inherent
lack of transparency, has spurred the development of a novel field of study
known as eXplainable AI (XAI) methods. These methods seek to enhance the trust
of end-users in automated systems by providing insights into the rationale
behind their decisions. This paper presents a novel approach for measuring user
trust in XAI systems, allowing their refinement. Our proposed metric combines
both performance metrics and trust indicators from an objective perspective. To
validate this novel methodology, we conducted a case study in a realistic
medical scenario: the usage of XAI system for the detection of pneumonia from
x-ray images.

ÊëòË¶ÅÔºöÈö®ËëóÂ∞çÊ∑±Â∫¶Â≠∏ÁøíÊ®°Âûã‰æùË≥¥ÊÄßÁöÑÂ¢ûÂä†ÔºåÂä†‰∏äÂÖ∂Âõ∫ÊúâÁöÑÈÄèÊòéÂ∫¶‰∏çË∂≥Ôºå‰øÉ‰Ωø‰∏ÄÂÄãÊñ∞ÁöÑÁ†îÁ©∂È†òÂüüÁôºÂ±ïÔºåÁ®±ÁÇ∫ÂèØËß£Èáã AI (XAI) ÊñπÊ≥ï„ÄÇÈÄô‰∫õÊñπÊ≥ïÊó®Âú®ÈÄèÈÅéÊ∑±ÂÖ•‰∫ÜËß£Ê±∫Á≠ñËÉåÂæåÁöÑÂéüÁêÜÔºå‰æÜÊèêÂçáÊúÄÁµÇ‰ΩøÁî®ËÄÖÂ∞çËá™ÂãïÂåñÁ≥ªÁµ±ÁöÑ‰ø°Ë≥¥„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆË°°Èáè‰ΩøÁî®ËÄÖÂ∞ç XAI Á≥ªÁµ±‰ø°Ë≥¥Â∫¶ÁöÑÊñ∞Á©éÊñπÊ≥ïÔºåÂÖÅË®±Â∞çÂÖ∂ÈÄ≤Ë°åÊîπÈÄ≤„ÄÇÊàëÂÄëÊèêÂá∫ÁöÑÊåáÊ®ôÁµêÂêà‰∫ÜÂÆ¢ËßÄËßÄÈªû‰∏ãÁöÑÊïàËÉΩÊåáÊ®ôÂíå‰ø°Ë≥¥ÊåáÊ®ô„ÄÇÁÇ∫‰∫ÜÈ©óË≠âÈÄôÂÄãÊñ∞Á©éÁöÑÊñπÊ≥ïÔºåÊàëÂÄëÂú®‰∏ÄÂÄãÁúüÂØ¶ÁöÑÈÜ´ÁôÇÂ†¥ÊôØ‰∏≠ÈÄ≤Ë°å‰∫Ü‰∏ÄÂÄãÊ°à‰æãÁ†îÁ©∂Ôºö‰ΩøÁî® XAI Á≥ªÁµ±Âæû X ÂÖâÂΩ±ÂÉè‰∏≠ÂÅµÊ∏¨ËÇ∫ÁÇé„ÄÇ

##### **Region-specific Risk Quantification for Interpretable Prognosis of COVID-19**
2405.02815v1 by Zhusi Zhong, Jie Li, Zhuoqi Ma, Scott Collins, Harrison Bai, Paul Zhang, Terrance Healey, Xinbo Gao, Michael K. Atalay, Zhicheng Jiao

The COVID-19 pandemic has strained global public health, necessitating
accurate diagnosis and intervention to control disease spread and reduce
mortality rates. This paper introduces an interpretable deep survival
prediction model designed specifically for improved understanding and trust in
COVID-19 prognosis using chest X-ray (CXR) images. By integrating a large-scale
pretrained image encoder, Risk-specific Grad-CAM, and anatomical region
detection techniques, our approach produces regional interpretable outcomes
that effectively capture essential disease features while focusing on rare but
critical abnormal regions. Our model's predictive results provide enhanced
clarity and transparency through risk area localization, enabling clinicians to
make informed decisions regarding COVID-19 diagnosis with better understanding
of prognostic insights. We evaluate the proposed method on a multi-center
survival dataset and demonstrate its effectiveness via quantitative and
qualitative assessments, achieving superior C-indexes (0.764 and 0.727) and
time-dependent AUCs (0.799 and 0.691). These results suggest that our
explainable deep survival prediction model surpasses traditional survival
analysis methods in risk prediction, improving interpretability for clinical
decision making and enhancing AI system trustworthiness.

ÊëòË¶ÅÔºöCOVID-19 Áñ´ÊÉÖÂ∞çÂÖ®ÁêÉÂÖ¨ÂÖ±Ë°õÁîüÈÄ†ÊàêÂ£ìÂäõÔºåÂøÖÈ†àÈÄ≤Ë°åÊ∫ñÁ¢∫ÁöÑË®∫Êñ∑ÂíåÂπ≤È†êÔºå‰ª•ÊéßÂà∂ÁñæÁóÖÂÇ≥Êí≠‰∏¶Èôç‰ΩéÊ≠ª‰∫°Áéá„ÄÇÊú¨Êñá‰ªãÁ¥π‰∫Ü‰∏ÄÂÄãÂèØËß£ÈáãÁöÑÊ∑±Â∫¶ÁîüÂ≠òÈ†êÊ∏¨Ê®°ÂûãÔºåÂ∞àÈñÄË®≠Ë®àÁî®ÊñºÈÄèÈÅéËÉ∏ÈÉ® X ÂÖâ (CXR) ÂΩ±ÂÉèÊîπÂñÑÂ∞ç COVID-19 È†êÂæåÁöÑÁêÜËß£Âíå‰ø°Ë≥¥„ÄÇÈÄèÈÅéÊï¥ÂêàÂ§ßË¶èÊ®°È†êË®ìÁ∑¥ÂΩ±ÂÉèÁ∑®Á¢ºÂô®„ÄÅÈ¢®Èö™ÁâπÂÆö Grad-CAM ÂíåËß£ÂâñÂçÄÂüüÂÅµÊ∏¨ÊäÄË°ìÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÁî¢ÁîüÂçÄÂüüÂèØËß£ÈáãÁöÑÁµêÊûúÔºåÊúâÊïàÊçïÊçâÂøÖË¶ÅÁöÑÁñæÁóÖÁâπÂæµÔºåÂêåÊôÇÂ∞àÊ≥®ÊñºÁΩïË¶ã‰ΩÜÈóúÈçµÁöÑÁï∞Â∏∏ÂçÄÂüü„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÈ†êÊ∏¨ÁµêÊûúÈÄèÈÅéÈ¢®Èö™ÂçÄÂüüÂÆö‰ΩçÊèê‰æõÂ¢ûÂº∑ÁöÑÊ∏ÖÊô∞Â∫¶ÂíåÈÄèÊòéÂ∫¶ÔºåËÆìËá®Â∫äÈÜ´ÁîüËÉΩÂ§†Âú®Êõ¥‰∫ÜËß£È†êÂæåË¶ãËß£ÁöÑÊÉÖÊ≥Å‰∏ãÔºåÂ∞± COVID-19 Ë®∫Êñ∑ÂÅöÂá∫ÊòéÊô∫ÁöÑÊ±∫Á≠ñ„ÄÇÊàëÂÄëÂú®Â§ö‰∏≠ÂøÉÁîüÂ≠òË≥áÊñôÈõÜ‰∏äË©ï‰º∞ÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÔºå‰∏¶ÈÄèÈÅéÈáèÂåñÂíåË≥™ÂåñË©ï‰º∞Ë≠âÊòéÂÖ∂ÊúâÊïàÊÄßÔºåÈÅîÂà∞ÂÑ™Áï∞ÁöÑ C ÊåáÊï∏Ôºà0.764 Âíå 0.727ÔºâÂíåÊôÇÈñìÁõ∏Èóú AUCÔºà0.799 Âíå 0.691Ôºâ„ÄÇÈÄô‰∫õÁµêÊûúË°®ÊòéÔºåÊàëÂÄëÂèØËß£ÈáãÁöÑÊ∑±Â∫¶ÁîüÂ≠òÈ†êÊ∏¨Ê®°ÂûãÂú®È¢®Èö™È†êÊ∏¨ÊñπÈù¢Ë∂ÖË∂äÂÇ≥Áµ±ÁöÑÁîüÂ≠òÂàÜÊûêÊñπÊ≥ïÔºåÊèêÂçáËá®Â∫äÊ±∫Á≠ñÁöÑËß£ÈáãÊÄßÔºå‰∏¶Â¢ûÂº∑ AI Á≥ªÁµ±ÁöÑ‰ø°Ë≥¥Â∫¶„ÄÇ

##### **Rad4XCNN: a new agnostic method for post-hoc global explanation of CNN-derived features by means of radiomics**
2405.02334v1 by Francesco Prinzi, Carmelo Militello, Calogero Zarcaro, Tommaso Vincenzo Bartolotta, Salvatore Gaglio, Salvatore Vitabile

In the last years, artificial intelligence (AI) in clinical decision support
systems (CDSS) played a key role in harnessing machine learning and deep
learning architectures. Despite their promising capabilities, the lack of
transparency and explainability of AI models poses significant challenges,
particularly in medical contexts where reliability is a mandatory aspect.
Achieving transparency without compromising predictive accuracy remains a key
challenge. This paper presents a novel method, namely Rad4XCNN, to enhance the
predictive power of CNN-derived features with the interpretability inherent in
radiomic features. Rad4XCNN diverges from conventional methods based on
saliency map, by associating intelligible meaning to CNN-derived features by
means of Radiomics, offering new perspectives on explanation methods beyond
visualization maps. Using a breast cancer classification task as a case study,
we evaluated Rad4XCNN on ultrasound imaging datasets, including an online
dataset and two in-house datasets for internal and external validation. Some
key results are: i) CNN-derived features guarantee more robust accuracy when
compared against ViT-derived and radiomic features; ii) conventional
visualization map methods for explanation present several pitfalls; iii)
Rad4XCNN does not sacrifice model accuracy for their explainability; iv)
Rad4XCNN provides global explanation insights enabling the physician to analyze
the model outputs and findings. In addition, we highlight the importance of
integrating interpretability into AI models for enhanced trust and adoption in
clinical practice, emphasizing how our method can mitigate some concerns
related to explainable AI methods.

ÊëòË¶ÅÔºö<paragraph>Âú®ÈÅéÂéªÂπæÂπ¥ÔºåËá®Â∫äÊ±∫Á≠ñÊîØÊè¥Á≥ªÁµ± (CDSS) ‰∏≠ÁöÑ‰∫∫Â∑•Êô∫ÊÖß (AI) Âú®Âà©Áî®Ê©üÂô®Â≠∏ÁøíÂíåÊ∑±Â∫¶Â≠∏ÁøíÊû∂ÊßãÊñπÈù¢ÁôºÊèÆ‰∫ÜÈóúÈçµ‰ΩúÁî®„ÄÇÂÑòÁÆ° AI Ê®°ÂûãÂÖ∑Êúâ‰ª§‰∫∫ÊªøÊÑèÁöÑËÉΩÂäõÔºå‰ΩÜÁº∫‰πèÈÄèÊòéÂ∫¶ÂíåÂèØËß£ÈáãÊÄßÔºåÁâπÂà•ÊòØÂú®ÂèØÈù†ÊÄßÁÇ∫ÂøÖË¶ÅËÄÉÈáèÁöÑÈÜ´ÁôÇËÉåÊôØ‰∏ãÔºåÈÄôÂ∏∂‰æÜ‰∫ÜÈáçÂ§ßÁöÑÊåëÊà∞„ÄÇÂú®‰∏çÂΩ±ÈüøÈ†êÊ∏¨Á≤æÊ∫ñÂ∫¶ÁöÑÊÉÖÊ≥Å‰∏ãÂØ¶ÁèæÈÄèÊòéÂ∫¶‰ªçÁÑ∂ÊòØ‰∏ÄÈ†ÖÈóúÈçµÊåëÊà∞„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞ÊñπÊ≥ïÔºåÂç≥ Rad4XCNNÔºå‰ª•Â¢ûÂº∑ CNN Ë°çÁîüÁâπÂæµÁöÑÈ†êÊ∏¨ËÉΩÂäõÔºåÂêåÊôÇÂÖ∑ÂÇôÊîæÂ∞ÑÁâπÂæµÂõ∫ÊúâÁöÑÂèØËß£ÈáãÊÄß„ÄÇRad4XCNN ‰∏çÂêåÊñºÂü∫ÊñºÈ°ØËëóÊÄßÂúñÁöÑÂÇ≥Áµ±ÊñπÊ≥ïÔºåÂÆÉÈÄöÈÅéÊîæÂ∞ÑÁµÑÂ≠∏Â∞áÂèØÁêÜËß£ÁöÑÂê´Áæ©Ëàá CNN Ë°çÁîüÁâπÂæµÈóúËÅØËµ∑‰æÜÔºåÁÇ∫Ë∂ÖË∂äË¶ñË¶∫ÂåñÂúñË°®ÁöÑËß£ÈáãÊñπÊ≥ïÊèê‰æõ‰∫ÜÊñ∞ÁöÑËßÄÈªû„ÄÇÊàëÂÄë‰ª•‰π≥ÁôåÂàÜÈ°û‰ªªÂãô‰ΩúÁÇ∫Ê°à‰æãÁ†îÁ©∂ÔºåÂú®Ë∂ÖÈü≥Ê≥¢ÂΩ±ÂÉèË≥áÊñôÈõÜ‰∏äË©ï‰º∞ Rad4XCNNÔºåÂåÖÊã¨‰∏ÄÂÄãÁ∑ö‰∏äË≥áÊñôÈõÜÂíåÂÖ©ÂÄãÁî®ÊñºÂÖßÈÉ®ÂíåÂ§ñÈÉ®È©óË≠âÁöÑÂÖßÈÉ®Ë≥áÊñôÈõÜ„ÄÇ‰∏Ä‰∫õÈóúÈçµÁµêÊûúÂ¶Ç‰∏ãÔºöi) Ëàá ViT Ë°çÁîüÁâπÂæµÂíåÊîæÂ∞ÑÁâπÂæµÁõ∏ÊØîÔºåCNN Ë°çÁîüÁâπÂæµ‰øùË≠â‰∫ÜÊõ¥Á©©ÂÅ•ÁöÑÊ∫ñÁ¢∫Â∫¶Ôºõii) ÂÇ≥Áµ±ÁöÑË¶ñË¶∫ÂåñÂúñËß£ÈáãÊñπÊ≥ïÂ≠òÂú®‰∏Ä‰∫õÁº∫Èô∑Ôºõiii) Rad4XCNN Ê≤íÊúâÁäßÁâ≤Ê®°ÂûãÊ∫ñÁ¢∫Â∫¶‰æÜÊèõÂèñÂÖ∂ÂèØËß£ÈáãÊÄßÔºõiv) Rad4XCNN Êèê‰æõ‰∫ÜÂÖ®Â±ÄËß£ÈáãË¶ãËß£Ôºå‰ΩøÈÜ´Â∏´ËÉΩÂ§†ÂàÜÊûêÊ®°ÂûãËº∏Âá∫ÂíåÁôºÁèæ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂº∑Ë™øÂ∞áÂèØËß£ÈáãÊÄßÊï¥ÂêàÂà∞ AI Ê®°Âûã‰∏≠Â∞çÊñºÂ¢ûÂº∑Ëá®Â∫äÂØ¶Âãô‰∏≠ÁöÑ‰ø°‰ªªÂíåÊé°Áî®Ëá≥ÈóúÈáçË¶ÅÔºå‰∏¶Âº∑Ë™ø‰∫ÜÊàëÂÄëÁöÑÊñπÊ≥ïÂ¶Ç‰ΩïËÉΩÁ∑©Ëß£ËàáÂèØËß£Èáã AI ÊñπÊ≥ïÁõ∏ÈóúÁöÑ‰∏Ä‰∫õÁñëÊÖÆ„ÄÇ</paragraph>

##### **Attributing Responsibility in AI-Induced Incidents: A Computational Reflective Equilibrium Framework for Accountability**
2404.16957v1 by Yunfei Ge, Quanyan Zhu

The pervasive integration of Artificial Intelligence (AI) has introduced
complex challenges in the responsibility and accountability in the event of
incidents involving AI-enabled systems. The interconnectivity of these systems,
ethical concerns of AI-induced incidents, coupled with uncertainties in AI
technology and the absence of corresponding regulations, have made traditional
responsibility attribution challenging. To this end, this work proposes a
Computational Reflective Equilibrium (CRE) approach to establish a coherent and
ethically acceptable responsibility attribution framework for all stakeholders.
The computational approach provides a structured analysis that overcomes the
limitations of conceptual approaches in dealing with dynamic and multifaceted
scenarios, showcasing the framework's explainability, coherence, and adaptivity
properties in the responsibility attribution process. We examine the pivotal
role of the initial activation level associated with claims in equilibrium
computation. Using an AI-assisted medical decision-support system as a case
study, we illustrate how different initializations lead to diverse
responsibility distributions. The framework offers valuable insights into
accountability in AI-induced incidents, facilitating the development of a
sustainable and resilient system through continuous monitoring, revision, and
reflection.

ÊëòË¶ÅÔºöÈö®Ëëó‰∫∫Â∑•Êô∫ÊÖß (AI) ÁöÑÊôÆÂèäÊï¥ÂêàÔºåÂú®Ê∂âÂèä AI È©ÖÂãïÁ≥ªÁµ±ÁöÑ‰∫ãÊïÖ‰∏≠ÔºåË≤¨‰ªªÂíåÁæ©ÂãôÊ≠∏Â±¨Áî¢Áîü‰∫ÜË§áÈõúÁöÑÊåëÊà∞„ÄÇÈÄô‰∫õÁ≥ªÁµ±ÁöÑ‰∫íÈÄ£ÊÄß„ÄÅAI ÂºïÁôº‰∫ãÊïÖÁöÑÂÄ´ÁêÜÂïèÈ°åÔºåÂä†‰∏ä AI ÊäÄË°ìÁöÑ‰∏çÁ¢∫ÂÆöÊÄßÂíåÁº∫‰πèÁõ∏ÊáâÊ≥ïË¶èÔºå‰ΩøÂæóÂÇ≥Áµ±Ë≤¨‰ªªÊ≠∏Â±¨Èù¢Ëá®ÊåëÊà∞„ÄÇÁÇ∫Ê≠§ÔºåÊú¨Á†îÁ©∂ÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆË®àÁÆóÂèçÊÄùÂùáË°° (CRE) ÊñπÊ≥ïÔºå‰ª•Âª∫Á´ã‰∏ÄÂÄãÈÄ£Ë≤´‰∏îÂú®ÂÄ´ÁêÜ‰∏äÂèØÊé•ÂèóÁöÑË≤¨‰ªªÊ≠∏Â±¨Êû∂ÊßãÔºåÈÅ©Áî®ÊñºÊâÄÊúâÂà©ÂÆ≥Èóú‰øÇ‰∫∫„ÄÇË®àÁÆóÊñπÊ≥ïÊèê‰æõ‰∫ÜÁµêÊßãÂåñÁöÑÂàÜÊûêÔºåÂÖãÊúç‰∫ÜÊ¶ÇÂøµÊñπÊ≥ïÂú®ËôïÁêÜÂãïÊÖã‰∏îÂ§öÈù¢ÂêëÊÉÖÂ¢ÉÊôÇÁöÑÈôêÂà∂ÔºåÂ±ïÁ§∫‰∫ÜË©≤Êû∂ÊßãÂú®Ë≤¨‰ªªÊ≠∏Â±¨ÈÅéÁ®ã‰∏≠ÂÖ∑ÂÇôÁöÑÂèØËß£ÈáãÊÄß„ÄÅÈÄ£Ë≤´ÊÄßÂíåÈÅ©ÊáâÊÄß„ÄÇÊàëÂÄëÊé¢Ë®é‰∫ÜËàáÂùáË°°Ë®àÁÆó‰∏≠Á¥¢Ë≥†Áõ∏ÈóúÁöÑÂàùÂßãÂïüÂãïÂ±§Á¥öÁöÑÈóúÈçµ‰ΩúÁî®„ÄÇÊàëÂÄë‰ª• AI ËºîÂä©ÈÜ´ÁôÇÊ±∫Á≠ñÊîØÊè¥Á≥ªÁµ±ÁÇ∫Ê°à‰æãÁ†îÁ©∂ÔºåË™™Êòé‰∏çÂêåÁöÑÂàùÂßãÂåñÂ¶Ç‰ΩïÂ∞éËá¥‰∏çÂêåÁöÑË≤¨‰ªªÂàÜÈÖç„ÄÇË©≤Êû∂ÊßãÊèê‰æõ‰∫ÜÂ∞ç AI ÂºïÁôº‰∫ãÊïÖ‰∏≠ÂïèË≤¨Âà∂ÁöÑÂØ∂Ë≤¥Ë¶ãËß£ÔºåÈÄèÈÅéÊåÅÁ∫åÁõ£Êéß„ÄÅ‰øÆË®ÇÂíåÂèçÊÄùÔºå‰øÉÈÄ≤‰∫ÜÊ∞∏Á∫å‰∏îÊúâÈüåÊÄßÁöÑÁ≥ªÁµ±ÁôºÂ±ï„ÄÇ

##### **Explainable AI for Fair Sepsis Mortality Predictive Model**
2404.13139v1 by Chia-Hsuan Chang, Xiaoyang Wang, Christopher C. Yang

Artificial intelligence supports healthcare professionals with predictive
modeling, greatly transforming clinical decision-making. This study addresses
the crucial need for fairness and explainability in AI applications within
healthcare to ensure equitable outcomes across diverse patient demographics. By
focusing on the predictive modeling of sepsis-related mortality, we propose a
method that learns a performance-optimized predictive model and then employs
the transfer learning process to produce a model with better fairness. Our
method also introduces a novel permutation-based feature importance algorithm
aiming at elucidating the contribution of each feature in enhancing fairness on
predictions. Unlike existing explainability methods concentrating on explaining
feature contribution to predictive performance, our proposed method uniquely
bridges the gap in understanding how each feature contributes to fairness. This
advancement is pivotal, given sepsis's significant mortality rate and its role
in one-third of hospital deaths. Our method not only aids in identifying and
mitigating biases within the predictive model but also fosters trust among
healthcare stakeholders by improving the transparency and fairness of model
predictions, thereby contributing to more equitable and trustworthy healthcare
delivery.

ÊëòË¶ÅÔºö‰∫∫Â∑•Êô∫ÊÖßÈÄèÈÅéÈ†êÊ∏¨Ê®°ÂûãÂçîÂä©ÈÜ´ÁôÇÂ∞àÊ•≠‰∫∫Âì°ÔºåÂ§ßÂπÖËΩâËÆä‰∫ÜËá®Â∫äÊ±∫Á≠ñÂà∂ÂÆö„ÄÇÊú¨Á†îÁ©∂Êé¢Ë®é‰∫ÜÂú®ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠‰ΩøÁî®‰∫∫Â∑•Êô∫ÊÖßÊáâÁî®Á®ãÂºèÊôÇÂÖ¨Âπ≥ÊÄßÂíåÂèØËß£ÈáãÊÄßÁöÑÈóúÈçµÈúÄÊ±ÇÔºå‰ª•Á¢∫‰øùÂú®‰∏çÂêåÁöÑÊÇ£ËÄÖ‰∫∫Âè£Áµ±Ë®àË≥áÊñô‰∏≠Áç≤ÂæóÂÖ¨Âπ≥ÁöÑÁµêÊûú„ÄÇÈÄèÈÅéÂ∞àÊ≥®ÊñºÊïóË°ÄÁóáÁõ∏ÈóúÊ≠ª‰∫°ÁéáÁöÑÈ†êÊ∏¨Ê®°ÂûãÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñπÊ≥ïÔºåË©≤ÊñπÊ≥ïÊúÉÂ≠∏Áøí‰∏ÄÂÄãÊïàËÉΩÊúÄ‰Ω≥ÂåñÁöÑÈ†êÊ∏¨Ê®°ÂûãÔºåÁÑ∂ÂæåÊé°Áî®ËΩâÁßªÂ≠∏ÁøíÈÅéÁ®ã‰æÜÁî¢Áîü‰∏ÄÂÄãÂÖ∑ÊúâÊõ¥Â•ΩÂÖ¨Âπ≥ÊÄßÁöÑÊ®°Âûã„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÈÇÑÂºïÂÖ•‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÂü∫ÊñºÊéíÂàóÁöÑÁâπÂæµÈáçË¶ÅÊÄßÊºîÁÆóÊ≥ïÔºåÊó®Âú®Èó°ÊòéÊØèÂÄãÁâπÂæµÂú®Â¢ûÂº∑È†êÊ∏¨ÂÖ¨Âπ≥ÊÄßÊñπÈù¢ÁöÑË≤¢Áçª„ÄÇËàáÁèæÊúâÁöÑÂèØËß£ÈáãÊÄßÊñπÊ≥ïÂ∞àÊ≥®ÊñºËß£ÈáãÁâπÂæµÂ∞çÈ†êÊ∏¨ÊïàËÉΩÁöÑË≤¢Áçª‰∏çÂêåÔºåÊàëÂÄëÊèêÂá∫ÁöÑÊñπÊ≥ïÁç®ÁâπÂú∞ÂΩåË£ú‰∫ÜÁêÜËß£ÊØèÂÄãÁâπÂæµÂ¶Ç‰ΩïÊúâÂä©ÊñºÂÖ¨Âπ≥ÊÄßÁöÑÂ∑ÆË∑ù„ÄÇÈÄôÈ†ÖÈÄ≤Â±ïËá≥ÈóúÈáçË¶ÅÔºåÂõ†ÁÇ∫ÊïóË°ÄÁóáÁöÑÊ≠ª‰∫°ÁéáÂæàÈ´òÔºå‰∏îÂú®‰∏âÂàÜ‰πã‰∏ÄÁöÑÈÜ´Èô¢Ê≠ª‰∫°‰∏≠ÊâÆÊºîËëóËßíËâ≤„ÄÇÊàëÂÄëÁöÑÊ®°Âûã‰∏çÂÉÖÊúâÂä©ÊñºË≠òÂà•ÂíåÊ∏õËºïÈ†êÊ∏¨Ê®°Âûã‰∏≠ÁöÑÂÅèÂ∑ÆÔºåÈÇÑËÉΩÈÄèÈÅéÊèêÈ´òÊ®°ÂûãÈ†êÊ∏¨ÁöÑÈÄèÊòéÂ∫¶ÂíåÂÖ¨Âπ≥ÊÄß‰æÜÂüπÈ§äÈÜ´ÁôÇ‰øùÂÅ•Âà©ÁõäÁõ∏ÈóúËÄÖ‰πãÈñìÁöÑ‰ø°‰ªªÔºåÈÄ≤ËÄåÊúâÂä©ÊñºÊèê‰æõÊõ¥ÂÖ¨Âπ≥‰∏îÂÄºÂæó‰ø°Ë≥¥ÁöÑÈÜ´ÁôÇ‰øùÂÅ•ÊúçÂãô„ÄÇ

##### **Multi Class Depression Detection Through Tweets using Artificial Intelligence**
2404.13104v1 by Muhammad Osama Nusrat, Waseem Shahzad, Saad Ahmed Jamal

Depression is a significant issue nowadays. As per the World Health
Organization (WHO), in 2023, over 280 million individuals are grappling with
depression. This is a huge number; if not taken seriously, these numbers will
increase rapidly. About 4.89 billion individuals are social media users. People
express their feelings and emotions on platforms like Twitter, Facebook,
Reddit, Instagram, etc. These platforms contain valuable information which can
be used for research purposes. Considerable research has been conducted across
various social media platforms. However, certain limitations persist in these
endeavors. Particularly, previous studies were only focused on detecting
depression and the intensity of depression in tweets. Also, there existed
inaccuracies in dataset labeling. In this research work, five types of
depression (Bipolar, major, psychotic, atypical, and postpartum) were predicted
using tweets from the Twitter database based on lexicon labeling. Explainable
AI was used to provide reasoning by highlighting the parts of tweets that
represent type of depression. Bidirectional Encoder Representations from
Transformers (BERT) was used for feature extraction and training. Machine
learning and deep learning methodologies were used to train the model. The BERT
model presented the most promising results, achieving an overall accuracy of
0.96.

ÊëòË¶ÅÔºöÁèæ‰ªäÔºåÊÜÇÈ¨±ÁóáÊòØ‰∏ÄÂÄãÈáçË¶ÅÁöÑË≠∞È°å„ÄÇÊ†πÊìö‰∏ñÁïåË°õÁîüÁµÑÁπî (WHO) ÁöÑË≥áÊñôÔºåÂú® 2023 Âπ¥ÔºåË∂ÖÈÅé 2.8 ÂÑÑ‰∫∫Ê≠£Âú®ËàáÊÜÇÈ¨±ÁóáÊêèÈ¨•„ÄÇÈÄôÊòØ‰∏ÄÂÄãÈæêÂ§ßÁöÑÊï∏Â≠óÔºõÂ¶ÇÊûú‰∏çË™çÁúüÁúãÂæÖÔºåÈÄô‰∫õÊï∏Â≠óÂ∞áÊúÉÂø´ÈÄüÂ¢ûÂä†„ÄÇÂ§ßÁ¥ÑÊúâ 48.9 ÂÑÑ‰∫∫ÊòØÁ§æÁæ§Â™íÈ´î‰ΩøÁî®ËÄÖ„ÄÇ‰∫∫ÂÄëÂú® Twitter„ÄÅFacebook„ÄÅReddit„ÄÅInstagram Á≠âÂπ≥Âè∞‰∏äË°®ÈÅîËá™Â∑±ÁöÑÊÑüÂèóÂíåÊÉÖÁ∑í„ÄÇÈÄô‰∫õÂπ≥Âè∞ÂåÖÂê´ÊúâÂÉπÂÄºÁöÑË≥áË®äÔºåÂèØÁî®ÊñºÁ†îÁ©∂ÁõÆÁöÑ„ÄÇÂ∑≤Á∂ìÂú®ÂêÑÁ®ÆÁ§æÁæ§Â™íÈ´îÂπ≥Âè∞‰∏äÈÄ≤Ë°å‰∫ÜÂ§ßÈáèÁöÑÁ†îÁ©∂„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÂä™Âäõ‰ªçÂ≠òÂú®Êüê‰∫õÈôêÂà∂„ÄÇÁâπÂà•ÊòØÔºåÂÖàÂâçÁöÑÁ†îÁ©∂ÂÉÖÂ∞àÊ≥®ÊñºÂÅµÊ∏¨Êé®Êñá‰∏≠ÁöÑÊÜÇÈ¨±ÁóáÂíåÊÜÇÈ¨±ÁóáÁöÑÂº∑Â∫¶„ÄÇÊ≠§Â§ñÔºåË≥áÊñôÈõÜÊ®ôÁ±§‰∏≠Â≠òÂú®‰∏çÊ∫ñÁ¢∫ÁöÑÊÉÖÊ≥Å„ÄÇÂú®ÈÄôÈ†ÖÁ†îÁ©∂Â∑•‰Ωú‰∏≠Ôºå‰ΩøÁî®Âü∫ÊñºË©ûÂΩôÊ®ôÁ±§ÁöÑ Twitter Ë≥áÊñôÂ∫´‰∏≠ÁöÑÊé®ÊñáÈ†êÊ∏¨‰∫Ü‰∫îÁ®ÆÈ°ûÂûãÁöÑÊÜÇÈ¨±ÁóáÔºàÈõôÊ•µÂûã„ÄÅÈáçÂ∫¶„ÄÅÁ≤æÁ•ûÁóÖÂûã„ÄÅÈùûÂÖ∏ÂûãÂíåÁî¢ÂæåÔºâ„ÄÇÂèØËß£ÈáãÁöÑ AI Áî®ÊñºÈÄèÈÅéÂº∑Ë™ø‰ª£Ë°®ÊÜÇÈ¨±ÁóáÈ°ûÂûãÁöÑÊé®ÊñáÈÉ®ÂàÜ‰æÜÊèê‰æõÊé®ÁêÜ„ÄÇÂæû TransformersÔºàBERTÔºâ‰∏≠ÊèêÂèñÁöÑÈõôÂêëÁ∑®Á¢ºÂô®Ë°®Á§∫Áî®ÊñºÁâπÂæµÊèêÂèñÂíåË®ìÁ∑¥„ÄÇÊ©üÂô®Â≠∏ÁøíÂíåÊ∑±Â∫¶Â≠∏ÁøíÊñπÊ≥ïÁî®ÊñºË®ìÁ∑¥Ê®°Âûã„ÄÇBERT Ê®°ÂûãÂëàÁèæÂá∫ÊúÄÊúâÂ∏åÊúõÁöÑÁµêÊûúÔºåÈÅîÂà∞ 0.96 ÁöÑÊï¥È´îÊ∫ñÁ¢∫Â∫¶„ÄÇ

##### **COIN: Counterfactual inpainting for weakly supervised semantic segmentation for medical images**
2404.12832v2 by Dmytro Shvetsov, Joonas Ariva, Marharyta Domnich, Raul Vicente, Dmytro Fishman

Deep learning is dramatically transforming the field of medical imaging and
radiology, enabling the identification of pathologies in medical images,
including computed tomography (CT) and X-ray scans. However, the performance of
deep learning models, particularly in segmentation tasks, is often limited by
the need for extensive annotated datasets. To address this challenge, the
capabilities of weakly supervised semantic segmentation are explored through
the lens of Explainable AI and the generation of counterfactual explanations.
The scope of this research is development of a novel counterfactual inpainting
approach (COIN) that flips the predicted classification label from abnormal to
normal by using a generative model. For instance, if the classifier deems an
input medical image X as abnormal, indicating the presence of a pathology, the
generative model aims to inpaint the abnormal region, thus reversing the
classifier's original prediction label. The approach enables us to produce
precise segmentations for pathologies without depending on pre-existing
segmentation masks. Crucially, image-level labels are utilized, which are
substantially easier to acquire than creating detailed segmentation masks. The
effectiveness of the method is demonstrated by segmenting synthetic targets and
actual kidney tumors from CT images acquired from Tartu University Hospital in
Estonia. The findings indicate that COIN greatly surpasses established
attribution methods, such as RISE, ScoreCAM, and LayerCAM, as well as an
alternative counterfactual explanation method introduced by Singla et al. This
evidence suggests that COIN is a promising approach for semantic segmentation
of tumors in CT images, and presents a step forward in making deep learning
applications more accessible and effective in healthcare, where annotated data
is scarce.

ÊëòË¶ÅÔºöÊ∑±Â∫¶Â≠¶‰π†Ê≠£Â§ßÂπÖËΩâËÆäÈÜ´Â≠∏ÂΩ±ÂÉèÂíåÊîæÂ∞ÑÁ∑öÂ≠∏È†òÂüüÔºåËÉΩËæ®Ë≠òÈÜ´Â≠∏ÂΩ±ÂÉè‰∏≠ÁöÑÁóÖÁêÜÔºåÂåÖÊã¨ÈõªËÖ¶Êñ∑Â±§ÊéÉÊèè (CT) Âíå X ÂÖâÊéÉÊèè„ÄÇÁÑ∂ËÄåÔºåÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÁöÑÊïàËÉΩÔºåÁâπÂà•ÊòØÂú®ÂàÜÂâ≤‰ªªÂãô‰∏≠ÔºåÂ∏∏Â∏∏ÂèóÂà∞Âª£Ê≥õË®ªËß£Ë≥áÊñôÈõÜÈúÄÊ±ÇÁöÑÈôêÂà∂„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÊ≠§ÊåëÊà∞ÔºåÈÄèÈÅéÂèØËß£Èáã AI ÂíåÂèç‰∫ãÂØ¶Ëß£ÈáãÁöÑÁî¢ÁîüÔºåÊé¢Á¥¢Âº±Áõ£Áù£Ë™ûÊÑèÂàÜÂâ≤ÁöÑËÉΩÂäõ„ÄÇÊú¨Á†îÁ©∂ÁöÑÁØÑÂúçÊòØÈñãÁôº‰∏ÄÁ®ÆÊñ∞ÁöÑÂèç‰∫ãÂØ¶ÂÖßÊèíÊñπÊ≥ï (COIN)ÔºåË©≤ÊñπÊ≥ï‰ΩøÁî®ÁîüÊàêÊ®°ÂûãÂ∞áÈ†êÊ∏¨ÁöÑÂàÜÈ°ûÊ®ôÁ±§ÂæûÁï∞Â∏∏ÁøªËΩâÁÇ∫Ê≠£Â∏∏„ÄÇ‰æãÂ¶ÇÔºåÂ¶ÇÊûúÂàÜÈ°ûÂô®Â∞áËº∏ÂÖ•ÁöÑÈÜ´Â≠∏ÂΩ±ÂÉè X Ë¶ñÁÇ∫Áï∞Â∏∏ÔºåË°®Á§∫Â≠òÂú®ÁóÖÁêÜÔºåÂâáÁîüÊàêÊ®°ÂûãÊó®Âú®ÂÖßÊèíÁï∞Â∏∏ÂçÄÂüüÔºåÂæûËÄåÈÄÜËΩâÂàÜÈ°ûÂô®ÁöÑÂéüÂßãÈ†êÊ∏¨Ê®ôÁ±§„ÄÇÊ≠§ÊñπÊ≥ï‰ΩøÊàëÂÄëËÉΩÂ§†Áî¢ÁîüÁóÖÁêÜÁöÑÁ≤æÁ¢∫ÂàÜÂâ≤ÔºåËÄåÁÑ°ÈúÄ‰æùË≥¥ÊñºÈ†êÂÖàÂ≠òÂú®ÁöÑÂàÜÂâ≤ÈÅÆÁΩ©„ÄÇËá≥ÈóúÈáçË¶ÅÁöÑÊòØÔºåÂà©Áî®ÂΩ±ÂÉèÂ±§Á¥öÊ®ôÁ±§ÔºåÈÄôÊØîÂª∫Á´ãË©≥Á¥∞ÁöÑÂàÜÂâ≤ÈÅÆÁΩ©ÂÆπÊòìÂèñÂæó„ÄÇË©≤ÊñπÊ≥ïÁöÑÊúâÊïàÊÄßÈÄèÈÅéÂàÜÂâ≤ÂêàÊàêÁõÆÊ®ôÂíåÂæûÊÑõÊ≤ôÂ∞º‰∫ûÂ°îÁàæÂúñÂ§ßÂ≠∏ÈÜ´Èô¢ÂèñÂæóÁöÑ CT ÂΩ±ÂÉè‰∏≠ÁöÑÂØ¶ÈöõËÖéËáüËÖ´Áò§‰æÜË≠âÊòé„ÄÇÁ†îÁ©∂ÁµêÊûúË°®ÊòéÔºåCOIN ÈÅ†ÈÅ†Ë∂ÖÈÅéÂ∑≤Âª∫Á´ãÁöÑÊ≠∏Âõ†ÊñπÊ≥ïÔºå‰æãÂ¶Ç RISE„ÄÅScoreCAM Âíå LayerCAMÔºå‰ª•Âèä Singla Á≠â‰∫∫ÊèêÂá∫ÁöÑÂè¶‰∏ÄÁ®ÆÂèç‰∫ãÂØ¶Ëß£ÈáãÊñπÊ≥ï„ÄÇÊ≠§Ë≠âÊìöË°®ÊòéÔºåCOIN ÊòØ‰∏ÄÁ®ÆÂæàÊúâÂâçÈÄîÁöÑ CT ÂΩ±ÂÉè‰∏≠ËÖ´Áò§Ë™ûÊÑèÂàÜÂâ≤ÊñπÊ≥ïÔºå‰∏¶Âú®ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ËÆìÊ∑±Â∫¶Â≠∏ÁøíÊáâÁî®Êõ¥ÊòìÊñºÂèñÂæóÂíåÊõ¥ÊúâÊïàÁéáÈÇÅÈÄ≤‰∏ÄÊ≠•ÔºåÂÖ∂‰∏≠Ë®ªËß£Ë≥áÊñôÂæàÁ®ÄÂ∞ë„ÄÇ

##### **Hybrid Intelligence for Digital Humanities**
2406.15374v1 by Victor de Boer, Lise Stork

In this paper, we explore the synergies between Digital Humanities (DH) as a
discipline and Hybrid Intelligence (HI) as a research paradigm. In DH research,
the use of digital methods and specifically that of Artificial Intelligence is
subject to a set of requirements and constraints. We argue that these are
well-supported by the capabilities and goals of HI. Our contribution includes
the identification of five such DH requirements: Successful AI systems need to
be able to 1) collaborate with the (human) scholar; 2) support data criticism;
3) support tool criticism; 4) be aware of and cater to various perspectives and
5) support distant and close reading. We take the CARE principles of Hybrid
Intelligence (collaborative, adaptive, responsible and explainable) as
theoretical framework and map these to the DH requirements. In this mapping, we
include example research projects. We finally address how insights from DH can
be applied to HI and discuss open challenges for the combination of the two
disciplines.

ÊëòË¶ÅÔºöÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊé¢Ë®éÊï∏‰Ωç‰∫∫ÊñáÂ≠∏Áßë (DH) ‰ΩúÁÇ∫‰∏ÄÈñÄÂ≠∏ÁßëËàáÊ∑∑ÂêàÊô∫ËÉΩ (HI) ‰ΩúÁÇ∫‰∏ÄÂÄãÁ†îÁ©∂ÂÖ∏ÁØÑ‰πãÈñìÁöÑÂçîÂêå‰ΩúÁî®„ÄÇÂú® DH Á†îÁ©∂‰∏≠ÔºåÊï∏‰ΩçÊñπÊ≥ïÁöÑ‰ΩøÁî®ÔºåÁâπÂà•ÊòØ‰∫∫Â∑•Êô∫ÊÖßÁöÑ‰ΩøÁî®ÔºåÂèóÂà∞‰∏ÄÁ≥ªÂàóË¶ÅÊ±ÇÂíåÈôêÂà∂„ÄÇÊàëÂÄëË™çÁÇ∫ÈÄô‰∫õË¶ÅÊ±ÇÂíåÈôêÂà∂Áç≤Âæó HI ÁöÑËÉΩÂäõÂíåÁõÆÊ®ôÁöÑÂÖÖÂàÜÊîØÊåÅ„ÄÇÊàëÂÄëÁöÑË≤¢ÁçªÂåÖÊã¨ÊâæÂá∫‰∫îÂÄãÈÄôÊ®£ÁöÑ DH Ë¶ÅÊ±ÇÔºöÊàêÂäüÁöÑ AI Á≥ªÁµ±ÈúÄË¶ÅËÉΩÂ§† 1) ËàáÔºà‰∫∫È°ûÔºâÂ≠∏ËÄÖÂêà‰ΩúÔºõ2) ÊîØÊè¥Ë≥áÊñôÊâπË©ïÔºõ3) ÊîØÊè¥Â∑•ÂÖ∑ÊâπË©ïÔºõ4) ÂØüË¶∫‰∏¶ËøéÂêàÂêÑÁ®ÆËßÄÈªûÔºõ5) ÊîØÊè¥ÈÅ†Ë∑ùÂíåËøëË∑ùÈõ¢Èñ±ËÆÄ„ÄÇÊàëÂÄëÂ∞áÊ∑∑ÂêàÊô∫ËÉΩÁöÑ CARE ÂéüÂâáÔºàÂçî‰Ωú„ÄÅÈÅ©Êáâ„ÄÅË≤†Ë≤¨ÂíåÂèØËß£ÈáãÔºâ‰ΩúÁÇ∫ÁêÜË´ñÊû∂ÊßãÔºå‰∏¶Â∞áÈÄô‰∫õÂéüÂâáÂ∞çÊáâÂà∞ DH Ë¶ÅÊ±Ç„ÄÇÂú®Ê≠§Â∞çÊáâ‰∏≠ÔºåÊàëÂÄëÁ¥çÂÖ•ÁØÑ‰æãÁ†îÁ©∂Â∞àÊ°à„ÄÇÊúÄÂæåÔºåÊàëÂÄëÊé¢Ë®éÂ¶Ç‰ΩïÂ∞á DH ÁöÑË¶ãËß£ÊáâÁî®Êñº HIÔºå‰∏¶Ë®éË´ñÁµêÂêàÈÄôÂÖ©ÂÄãÂ≠∏ÁßëÁöÑÈñãÊîæÊåëÊà∞„ÄÇ

##### **Ethical Framework for Responsible Foundational Models in Medical Imaging**
2406.11868v1 by Abhijit Das, Debesh Jha, Jasmer Sanjotra, Onkar Susladkar, Suramyaa Sarkar, Ashish Rauniyar, Nikhil Tomar, Vanshali Sharma, Ulas Bagci

Foundational models (FMs) have tremendous potential to revolutionize medical
imaging. However, their deployment in real-world clinical settings demands
extensive ethical considerations. This paper aims to highlight the ethical
concerns related to FMs and propose a framework to guide their responsible
development and implementation within medicine. We meticulously examine ethical
issues such as privacy of patient data, bias mitigation, algorithmic
transparency, explainability and accountability. The proposed framework is
designed to prioritize patient welfare, mitigate potential risks, and foster
trust in AI-assisted healthcare.

ÊëòË¶ÅÔºöÂü∫Á§éÊ®°Âûã (FM) ÂÖ∑ÊúâÂæπÂ∫ïÊîπËÆäÈÜ´Â≠∏ÂΩ±ÂÉèÁöÑÂ∑®Â§ßÊΩõÂäõ„ÄÇÁÑ∂ËÄåÔºåÂÆÉÂÄëÂú®ÁèæÂØ¶‰∏ñÁïåËá®Â∫äÁí∞Â¢É‰∏≠ÁöÑÈÉ®ÁΩ≤ÈúÄË¶ÅÂª£Ê≥õÁöÑÂÄ´ÁêÜËÄÉÈáè„ÄÇÊú¨ÊñáÊó®Âú®Âº∑Ë™øËàá FM Áõ∏ÈóúÁöÑÂÄ´ÁêÜÂïèÈ°åÔºå‰∏¶ÊèêÂá∫‰∏ÄÂÄãÊ°ÜÊû∂‰æÜÊåáÂ∞éÂÆÉÂÄëÂú®ÈÜ´Â≠∏‰∏≠ÁöÑË≤†Ë≤¨‰ªªÈñãÁôºÂíåÂØ¶ÊñΩ„ÄÇÊàëÂÄë‰ªîÁ¥∞ÂØ©Êü•‰∫ÜÂÄ´ÁêÜÂïèÈ°åÔºå‰æãÂ¶ÇÊÇ£ËÄÖÊï∏ÊìöÈö±ÁßÅ„ÄÅÂÅèÂ∑ÆÁ∑©Ëß£„ÄÅÊºîÁÆóÊ≥ïÈÄèÊòéÂ∫¶„ÄÅÂèØËß£ÈáãÊÄßÂíåÂïèË≤¨Âà∂„ÄÇÊâÄÊèêÂá∫ÁöÑÊ°ÜÊû∂Êó®Âú®ÂÑ™ÂÖàËÄÉÊÖÆÊÇ£ËÄÖÁ¶èÂà©„ÄÅÊ∏õËºïÊΩõÂú®È¢®Èö™Ôºå‰∏¶ÂüπÈ§äÂ∞ç AI ËºîÂä©ÈÜ´ÁôÇ‰øùÂÅ•ÁöÑ‰ø°‰ªª„ÄÇ

##### **Advancements in Radiomics and Artificial Intelligence for Thyroid Cancer Diagnosis**
2404.07239v1 by Milad Yousefi, Shadi Farabi Maleki, Ali Jafarizadeh, Mahya Ahmadpour Youshanlui, Aida Jafari, Siamak Pedrammehr, Roohallah Alizadehsani, Ryszard Tadeusiewicz, Pawel Plawiak

Thyroid cancer is an increasing global health concern that requires advanced
diagnostic methods. The application of AI and radiomics to thyroid cancer
diagnosis is examined in this review. A review of multiple databases was
conducted in compliance with PRISMA guidelines until October 2023. A
combination of keywords led to the discovery of an English academic publication
on thyroid cancer and related subjects. 267 papers were returned from the
original search after 109 duplicates were removed. Relevant studies were
selected according to predetermined criteria after 124 articles were eliminated
based on an examination of their abstract and title. After the comprehensive
analysis, an additional six studies were excluded. Among the 28 included
studies, radiomics analysis, which incorporates ultrasound (US) images,
demonstrated its effectiveness in diagnosing thyroid cancer. Various results
were noted, some of the studies presenting new strategies that outperformed the
status quo. The literature has emphasized various challenges faced by AI
models, including interpretability issues, dataset constraints, and operator
dependence. The synthesized findings of the 28 included studies mentioned the
need for standardization efforts and prospective multicenter studies to address
these concerns. Furthermore, approaches to overcome these obstacles were
identified, such as advances in explainable AI technology and personalized
medicine techniques. The review focuses on how AI and radiomics could transform
the diagnosis and treatment of thyroid cancer. Despite challenges, future
research on multidisciplinary cooperation, clinical applicability validation,
and algorithm improvement holds the potential to improve patient outcomes and
diagnostic precision in the treatment of thyroid cancer.

ÊëòË¶ÅÔºöÁî≤ÁãÄËÖ∫ÁôåÊòØ‰∏ÄÁ®ÆÊó•ÁõäÂö¥ÈáçÁöÑÂÖ®ÁêÉÂÅ•Â∫∑ÂïèÈ°åÔºåÈúÄË¶ÅÂÖàÈÄ≤ÁöÑË®∫Êñ∑ÊñπÊ≥ï„ÄÇÊú¨ÁØáË©ïË´ñÊé¢Ë®é‰∫Ü‰∫∫Â∑•Êô∫ËÉΩËàáÊîæÂ∞ÑÁâπÂæµÂàÜÊûêÂú®Áî≤ÁãÄËÖ∫ÁôåË®∫Êñ∑‰∏≠ÁöÑÊáâÁî®„ÄÇÂú®Á¨¶Âêà PRISMA ÊåáÂçóÁöÑÊÉÖÊ≥Å‰∏ãÔºåÂ∞çÂ§öÂÄãË≥áÊñôÂ∫´ÈÄ≤Ë°å‰∫ÜÂõûÈ°ßÔºåÁõ¥Âà∞ 2023 Âπ¥ 10 Êúà„ÄÇÈÄöÈÅéÁµêÂêàÈóúÈçµÂ≠óÔºåÁôºÁèæ‰∫Ü‰∏ÄÁØáÈóúÊñºÁî≤ÁãÄËÖ∫ÁôåÂíåÁõ∏Èóú‰∏ªÈ°åÁöÑËã±ÊñáÂ≠∏Ë°ìÂá∫ÁâàÁâ©„ÄÇÂú®ÁßªÈô§ 109 ÁØáÈáçË§áÊñáÁçªÂæåÔºåÂéüÂßãÊêúÂ∞ãÂÖ±ÂõûÂÇ≥ 267 ÁØáË´ñÊñá„ÄÇÂú®Ê†πÊìöÈ†êÂÖàÁ¢∫ÂÆöÁöÑÊ®ôÊ∫ñÔºåÊ∑òÊ±∞‰∫Ü 124 ÁØáÊñáÁ´†ÁöÑÊëòË¶ÅÂíåÊ®ôÈ°åÂæåÔºåÈÅ∏Âá∫‰∫ÜÁõ∏ÈóúÁ†îÁ©∂„ÄÇÂú®ÈÄ≤Ë°åÂÖ®Èù¢ÂàÜÊûêÂæåÔºåÈ°çÂ§ñÊéíÈô§‰∫ÜÂÖ≠È†ÖÁ†îÁ©∂„ÄÇÂú®Á¥çÂÖ•ÁöÑ 28 È†ÖÁ†îÁ©∂‰∏≠ÔºåÁµêÂêàË∂ÖÈü≥Ê≥¢ (US) ÂΩ±ÂÉèÁöÑÊîæÂ∞ÑÁâπÂæµÂàÜÊûêÔºåË≠âÊòé‰∫ÜÂÖ∂Âú®Ë®∫Êñ∑Áî≤ÁãÄËÖ∫ÁôåÊñπÈù¢ÁöÑÊúâÊïàÊÄß„ÄÇÁ†îÁ©∂ÁµêÊûú‰∏ç‰∏ÄÔºåÊúâ‰∫õÁ†îÁ©∂ÊèêÂá∫‰∫ÜÂÑ™ÊñºÁèæÁãÄÁöÑÊñ∞Á≠ñÁï•„ÄÇÊñáÁçªÂº∑Ë™ø‰∫Ü‰∫∫Â∑•Êô∫ËÉΩÊ®°ÂûãÈù¢Ëá®ÁöÑÂêÑÁ®ÆÊåëÊà∞ÔºåÂåÖÊã¨ÂèØËß£ÈáãÊÄßÂïèÈ°å„ÄÅË≥áÊñôÈõÜÈôêÂà∂ÂíåÊìç‰ΩúÂì°‰æùË≥¥ÊÄß„ÄÇ28 È†ÖÁ¥çÂÖ•Á†îÁ©∂ÁöÑÁ∂úÂêàÁôºÁèæÊèêÂà∞ÔºåÈúÄË¶ÅÊ®ôÊ∫ñÂåñÂ∑•‰ΩúÂíåÂâçÁûªÊÄßÂ§ö‰∏≠ÂøÉÁ†îÁ©∂‰æÜËß£Ê±∫ÈÄô‰∫õÂïèÈ°å„ÄÇÊ≠§Â§ñÔºåÈÇÑÁ¢∫ÂÆö‰∫ÜÂÖãÊúçÈÄô‰∫õÈöúÁ§ôÁöÑÊñπÊ≥ïÔºå‰æãÂ¶ÇÂèØËß£Èáã‰∫∫Â∑•Êô∫ËÉΩÊäÄË°ìÂíåÂÄã‰∫∫ÂåñÈÜ´ÁôÇÊäÄË°ìÁöÑÈÄ≤Ê≠•„ÄÇÊú¨ÁØáË©ïË´ñÈáçÈªûÊé¢Ë®é‰∫Ü‰∫∫Â∑•Êô∫ËÉΩÂíåÊîæÂ∞ÑÁâπÂæµÂàÜÊûêÂ¶Ç‰ΩïËΩâËÆäÁî≤ÁãÄËÖ∫ÁôåÁöÑË®∫Êñ∑ÂíåÊ≤ªÁôÇ„ÄÇÂÑòÁÆ°Â≠òÂú®ÊåëÊà∞Ôºå‰ΩÜÊú™‰æÜÂ∞çÂ§öÂ≠∏ÁßëÂêà‰Ωú„ÄÅËá®Â∫äÈÅ©Áî®ÊÄßÈ©óË≠âÂíåÊºîÁÆóÊ≥ïÊîπÈÄ≤ÁöÑÁ†îÁ©∂Ôºå‰ªçÊúâÊΩõÂäõÊîπÂñÑÁî≤ÁãÄËÖ∫ÁôåÊ≤ªÁôÇ‰∏≠ÁöÑÊÇ£ËÄÖÈ†êÂæåÂíåË®∫Êñ∑Á≤æÊ∫ñÂ∫¶„ÄÇ

##### **Predictive Modeling for Breast Cancer Classification in the Context of Bangladeshi Patients: A Supervised Machine Learning Approach with Explainable AI**
2404.04686v1 by Taminul Islam, Md. Alif Sheakh, Mst. Sazia Tahosin, Most. Hasna Hena, Shopnil Akash, Yousef A. Bin Jardan, Gezahign Fentahun Wondmie, Hiba-Allah Nafidi, Mohammed Bourhia

Breast cancer has rapidly increased in prevalence in recent years, making it
one of the leading causes of mortality worldwide. Among all cancers, it is by
far the most common. Diagnosing this illness manually requires significant time
and expertise. Since detecting breast cancer is a time-consuming process,
preventing its further spread can be aided by creating machine-based forecasts.
Machine learning and Explainable AI are crucial in classification as they not
only provide accurate predictions but also offer insights into how the model
arrives at its decisions, aiding in the understanding and trustworthiness of
the classification results. In this study, we evaluate and compare the
classification accuracy, precision, recall, and F-1 scores of five different
machine learning methods using a primary dataset (500 patients from Dhaka
Medical College Hospital). Five different supervised machine learning
techniques, including decision tree, random forest, logistic regression, naive
bayes, and XGBoost, have been used to achieve optimal results on our dataset.
Additionally, this study applied SHAP analysis to the XGBoost model to
interpret the model's predictions and understand the impact of each feature on
the model's output. We compared the accuracy with which several algorithms
classified the data, as well as contrasted with other literature in this field.
After final evaluation, this study found that XGBoost achieved the best model
accuracy, which is 97%.

ÊëòË¶ÅÔºö<paragraph>ËøëÂπ¥‰æÜÔºå‰π≥ÁôåÁöÑÁõõË°åÁéáËøÖÈÄüÂ¢ûÂä†Ôºå‰ΩøÂÖ∂ÊàêÁÇ∫ÂÖ®ÁêÉ‰∏ªË¶ÅÁöÑÊ≠ª‰∫°ÂéüÂõ†‰πã‰∏Ä„ÄÇÂú®ÊâÄÊúâÁôåÁóá‰∏≠Ôºå‰π≥ÁôåËøÑ‰ªäÁÇ∫Ê≠¢ÊòØÊúÄÂ∏∏Ë¶ãÁöÑ„ÄÇÊâãÂãïË®∫Êñ∑Ê≠§ÁñæÁóÖÈúÄË¶ÅÂ§ßÈáèÁöÑÊôÇÈñìÂíåÂ∞àÊ•≠Áü•Ë≠ò„ÄÇÁî±Êñº‰π≥ÁôåÁöÑÊ™¢Ê∏¨ÈÅéÁ®ãËÄóÊôÇÔºåÂõ†Ê≠§ÈÄèÈÅéÂª∫Á´ãÊ©üÂô®Â≠∏ÁøíÊ®°Âûã‰æÜÈ†êÊ∏¨ÔºåÊúâÂä©ÊñºÈò≤Ê≠¢ÂÖ∂ÈÄ≤‰∏ÄÊ≠•Êì¥Êï£„ÄÇÊ©üÂô®Â≠∏ÁøíÂíåÂèØËß£Èáã AI Âú®ÂàÜÈ°û‰∏≠Ëá≥ÈóúÈáçË¶ÅÔºåÂõ†ÁÇ∫ÂÆÉÂÄë‰∏çÂÉÖÂèØ‰ª•Êèê‰æõÊ∫ñÁ¢∫ÁöÑÈ†êÊ∏¨ÔºåÈÇÑÂèØ‰ª•Ê∑±ÂÖ•‰∫ÜËß£Ê®°ÂûãÂ¶Ç‰ΩïÂÅöÂá∫Ê±∫Á≠ñÔºåÊúâÂä©ÊñºÁêÜËß£Âíå‰ø°Ë≥¥ÂàÜÈ°ûÁµêÊûú„ÄÇÂú®Ê≠§Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëË©ï‰º∞‰∏¶ÊØîËºÉ‰∫Ü‰∫îÁ®Æ‰∏çÂêåÁöÑÊ©üÂô®Â≠∏ÁøíÊñπÊ≥ïÁöÑÂàÜÈ°ûÊ∫ñÁ¢∫Â∫¶„ÄÅÁ≤æÁ¢∫Â∫¶„ÄÅÂè¨ÂõûÁéáÂíå F1 ÂàÜÊï∏Ôºå‰ΩøÁî®‰∫Ü‰∏ÄÂÄã‰∏ªË¶ÅÁöÑË≥áÊñôÈõÜÔºàÈÅîÂç°ÈÜ´Â≠∏Èô¢ÈÜ´Èô¢ÁöÑ 500 ÂêçÊÇ£ËÄÖÔºâ„ÄÇ‰∫îÁ®Æ‰∏çÂêåÁöÑÁõ£Áù£ÂºèÊ©üÂô®Â≠∏ÁøíÊäÄË°ìÔºåÂåÖÊã¨Ê±∫Á≠ñÊ®π„ÄÅÈö®Ê©üÊ£ÆÊûó„ÄÅÈÇèËºØËø¥Ê≠∏„ÄÅÊú¥Á¥†Ë≤ùÊ∞èÂíå XGBoostÔºåÂ∑≤Áî®ÊñºÂú®ÊàëÂÄëÁöÑË≥áÊñôÈõÜ‰∏äÂèñÂæóÊúÄ‰Ω≥ÁµêÊûú„ÄÇÊ≠§Â§ñÔºåÊú¨Á†îÁ©∂Â∞á SHAP ÂàÜÊûêÊáâÁî®Êñº XGBoost Ê®°ÂûãÔºå‰ª•Ëß£ÈáãÊ®°ÂûãÁöÑÈ†êÊ∏¨‰∏¶‰∫ÜËß£ÊØèÂÄãÁâπÂæµÂ∞çÊ®°ÂûãËº∏Âá∫ÁöÑÂΩ±Èüø„ÄÇÊàëÂÄëÊØîËºÉ‰∫ÜÂπæÁ®ÆÊºîÁÆóÊ≥ïÂ∞çË≥áÊñôÈÄ≤Ë°åÂàÜÈ°ûÁöÑÊ∫ñÁ¢∫Â∫¶Ôºå‰∏¶ËàáË©≤È†òÂüüÁöÑÂÖ∂‰ªñÊñáÁçªÈÄ≤Ë°åÂ∞çÊØî„ÄÇÂú®ÊúÄÂæåË©ï‰º∞ÂæåÔºåÊú¨Á†îÁ©∂ÁôºÁèæ XGBoost ÈÅîÂà∞‰∫ÜÊúÄ‰Ω≥ÁöÑÊ®°ÂûãÊ∫ñÁ¢∫Â∫¶ÔºåÁÇ∫ 97%„ÄÇ</paragraph>

##### **Enhancing Breast Cancer Diagnosis in Mammography: Evaluation and Integration of Convolutional Neural Networks and Explainable AI**
2404.03892v3 by Maryam Ahmed, Tooba Bibi, Rizwan Ahmed Khan, Sidra Nasir

The Deep learning (DL) models for diagnosing breast cancer from mammographic
images often operate as "black boxes", making it difficult for healthcare
professionals to trust and understand their decision-making processes. The
study presents an integrated framework combining Convolutional Neural Networks
(CNNs) and Explainable Artificial Intelligence (XAI) for the enhanced diagnosis
of breast cancer using the CBIS-DDSM dataset. The methodology encompasses an
elaborate data preprocessing pipeline and advanced data augmentation techniques
to counteract dataset limitations and transfer learning using pre-trained
networks such as VGG-16, Inception-V3 and ResNet was employed. A focal point of
our study is the evaluation of XAI's effectiveness in interpreting model
predictions, highlighted by utilizing the Hausdorff measure to assess the
alignment between AI-generated explanations and expert annotations
quantitatively. This approach is critical for XAI in promoting trustworthiness
and ethical fairness in AI-assisted diagnostics. The findings from our research
illustrate the effective collaboration between CNNs and XAI in advancing
diagnostic methods for breast cancer, thereby facilitating a more seamless
integration of advanced AI technologies within clinical settings. By enhancing
the interpretability of AI driven decisions, this work lays the groundwork for
improved collaboration between AI systems and medical practitioners, ultimately
enriching patient care. Furthermore, the implications of our research extended
well beyond the current methodologies. It encourages further research into how
to combine multimodal data and improve AI explanations to meet the needs of
clinical practice.

ÊëòË¶ÅÔºöÊ∑±Â∫¶Â≠∏Áøí (DL) Áî®ÊñºÂæû‰π≥ÊàøÊîùÂΩ±Ë°ìÂΩ±ÂÉèË®∫Êñ∑‰π≥ÁôåÁöÑÊ®°ÂûãÈÄöÂ∏∏‰ª•„ÄåÈªëÁõíÂ≠ê„ÄçÊñπÂºèÈÅã‰ΩúÔºåÈÄô‰ΩøÂæóÈÜ´ÁôÇ‰øùÂÅ•Â∞àÊ•≠‰∫∫Âì°Èõ£‰ª•‰ø°‰ªªÂíåÁêÜËß£ÂÖ∂Ê±∫Á≠ñÈÅéÁ®ã„ÄÇÊú¨Á†îÁ©∂ÊèêÂá∫‰∏ÄÂÄãÊï¥ÂêàÊû∂ÊßãÔºåÁµêÂêàÂç∑Á©çÁ•ûÁ∂ìÁ∂≤Ë∑Ø (CNN) ÂíåÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖß (XAI)Ôºå‰ª•‰ΩøÁî® CBIS-DDSM Ë≥áÊñôÈõÜÂ¢ûÂº∑‰π≥ÁôåÁöÑË®∫Êñ∑„ÄÇÊñπÊ≥ïÂåÖÂê´‰∏ÄÂÄãÁ≤æÁ¥∞ÁöÑË≥áÊñôÂâçËôïÁêÜÁÆ°Á∑öÂíåÈÄ≤ÈöéË≥áÊñôÊì¥ÂÖÖÊäÄË°ìÔºå‰ª•Â∞çÊäóË≥áÊñôÈõÜÈôêÂà∂Ôºå‰∏¶Êé°Áî®È†êÂÖàË®ìÁ∑¥ÁöÑÁ∂≤Ë∑ØÔºà‰æãÂ¶Ç VGG-16„ÄÅInception-V3 Âíå ResNetÔºâÈÄ≤Ë°åÈÅ∑ÁßªÂ≠∏Áøí„ÄÇÊàëÂÄëÁ†îÁ©∂ÁöÑÈáçÈªûÊòØË©ï‰º∞ XAI Âú®Ëß£ÈáãÊ®°ÂûãÈ†êÊ∏¨‰∏≠ÁöÑÊúâÊïàÊÄßÔºåÈáçÈªûÂà©Áî®Ë±™ÊñØÂ§öÂ§´Ê∏¨Â∫¶ÈáèÂåñË©ï‰º∞ AI ÁîüÊàêÁöÑËß£ÈáãÂíåÂ∞àÂÆ∂Ë®ªËß£‰πãÈñìÁöÑ‰∏ÄËá¥ÊÄß„ÄÇÈÄôÁ®ÆÊñπÊ≥ïÂ∞çÊñº XAI Âú®‰øÉÈÄ≤ AI ËºîÂä©Ë®∫Êñ∑‰∏≠ÁöÑÂèØ‰ø°Â∫¶ÂíåÂÄ´ÁêÜÂÖ¨Âπ≥ÊÄßËá≥ÈóúÈáçË¶Å„ÄÇÊàëÂÄëÁ†îÁ©∂ÁöÑÁôºÁèæË™™Êòé‰∫Ü CNN Âíå XAI Âú®Êé®ÈÄ≤‰π≥ÁôåË®∫Êñ∑ÊñπÊ≥ï‰∏≠ÁöÑÊúâÊïàÂçî‰ΩúÔºåÂæûËÄå‰øÉÈÄ≤‰∫ÜÂÖàÈÄ≤ AI ÊäÄË°ìÂú®Ëá®Â∫äÁí∞Â¢É‰∏≠ÁöÑÊõ¥È†ÜÊö¢Êï¥Âêà„ÄÇÈÄèÈÅéÂ¢ûÂº∑ AI È©ÖÂãïÊ±∫Á≠ñÁöÑÂèØËß£ÈáãÊÄßÔºåÈÄôÈ†ÖÂ∑•‰ΩúÁÇ∫ AI Á≥ªÁµ±ÂíåÈÜ´ÁôÇÂæûÊ•≠‰∫∫Âì°‰πãÈñìÁöÑÊîπÂñÑÂçî‰ΩúÂ•†ÂÆö‰∫ÜÂü∫Á§éÔºåÊúÄÁµÇË±êÂØå‰∫ÜÊÇ£ËÄÖÁÖßË≠∑„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁ†îÁ©∂ÁöÑÂΩ±ÈüøÈÅ†ÈÅ†Ë∂ÖÂá∫‰∫ÜÁõÆÂâçÁöÑÊäÄË°ì„ÄÇÂÆÉÈºìÂãµÈÄ≤‰∏ÄÊ≠•Á†îÁ©∂Â¶Ç‰ΩïÁµêÂêàÂ§öÊ®°ÂºèË≥áÊñô‰∏¶ÊîπÂñÑ AI Ëß£ÈáãÔºå‰ª•ÊªøË∂≥Ëá®Â∫äÂØ¶ÂãôÁöÑÈúÄÊ±Ç„ÄÇ

##### **Advancing Multimodal Data Fusion in Pain Recognition: A Strategy Leveraging Statistical Correlation and Human-Centered Perspectives**
2404.00320v2 by Xingrui Gu, Zhixuan Wang, Irisa Jin, Zekun Wu

This research presents a novel multimodal data fusion methodology for pain
behavior recognition, integrating statistical correlation analysis with
human-centered insights. Our approach introduces two key innovations: 1)
integrating data-driven statistical relevance weights into the fusion strategy
to effectively utilize complementary information from heterogeneous modalities,
and 2) incorporating human-centric movement characteristics into multimodal
representation learning for detailed modeling of pain behaviors. Validated
across various deep learning architectures, our method demonstrates superior
performance and broad applicability. We propose a customizable framework that
aligns each modality with a suitable classifier based on statistical
significance, advancing personalized and effective multimodal fusion.
Furthermore, our methodology provides explainable analysis of multimodal data,
contributing to interpretable and explainable AI in healthcare. By highlighting
the importance of data diversity and modality-specific representations, we
enhance traditional fusion techniques and set new standards for recognizing
complex pain behaviors. Our findings have significant implications for
promoting patient-centered healthcare interventions and supporting explainable
clinical decision-making.

ÊëòË¶ÅÔºöÊú¨Á†îÁ©∂ÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂâµÊñ∞ÁöÑÂ§öÊ®°ÊÖãÊï∏ÊìöËûçÂêàÊñπÊ≥ïÔºåÁî®ÊñºÁñºÁóõË°åÁÇ∫Ë≠òÂà•ÔºåÂ∞áÁµ±Ë®àÁõ∏ÈóúÂàÜÊûêËàá‰ª•‰∫∫ÁÇ∫‰∏≠ÂøÉÁöÑË¶ãËß£Áõ∏ÁµêÂêà„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÂºïÂÖ•‰∫ÜÂÖ©È†ÖÈóúÈçµÂâµÊñ∞Ôºö1) Â∞áÊï∏ÊìöÈ©ÖÂãïÁöÑÁµ±Ë®àÁõ∏ÈóúÊ¨äÈáçÊï¥ÂêàÂà∞ËûçÂêàÁ≠ñÁï•‰∏≠Ôºå‰ª•ÊúâÊïàÂà©Áî®‰æÜËá™Áï∞Ë≥™Ê®°ÊÖãÁöÑË£úÂÖÖ‰ø°ÊÅØÔºå‰ª•Âèä 2) Â∞á‰ª•‰∫∫ÁÇ∫‰∏≠ÂøÉÁöÑÈÅãÂãïÁâπÂæµÁ¥çÂÖ•Â§öÊ®°ÊÖãË°®Á§∫Â≠∏Áøí‰∏≠Ôºå‰ª•Ë©≥Á¥∞Âª∫Ê®°ÁñºÁóõË°åÁÇ∫„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÂú®ÂêÑÁ®ÆÊ∑±Â∫¶Â≠∏ÁøíÊû∂Êßã‰∏≠ÂæóÂà∞È©óË≠âÔºåÂ±ïÁ§∫‰∫ÜÂçìË∂äÁöÑÊÄßËÉΩÂíåÂª£Ê≥õÁöÑÈÅ©Áî®ÊÄß„ÄÇÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂèØËá™ÂÆöÁæ©ÁöÑÊ°ÜÊû∂ÔºåÊ†πÊìöÁµ±Ë®àÈ°ØËëóÊÄßÂ∞áÊØèÂÄãÊ®°ÊÖãËàáÂêàÈÅ©ÁöÑÂàÜÈ°ûÂô®Â∞çÈΩäÔºåÊé®ÈÄ≤ÂÄãÊÄßÂåñÂíåÊúâÊïàÁöÑÂ§öÊ®°ÊÖãËûçÂêà„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁöÑÊ®°ÂûãÊèê‰æõÂ∞çÂ§öÊ®°ÊÖãÊï∏ÊìöÁöÑÂèØËß£ÈáãÂàÜÊûêÔºåÊúâÂä©ÊñºÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÁöÑÂèØËß£ÈáãÂíåÂèØËß£Èáã AI„ÄÇÈÄöÈÅéÂº∑Ë™øÊï∏ÊìöÂ§öÊ®£ÊÄßÂíåÊ®°ÊÖãÁâπÂÆöË°®Á§∫ÁöÑÈáçË¶ÅÊÄßÔºåÊàëÂÄëÂ¢ûÂº∑‰∫ÜÂÇ≥Áµ±ÁöÑËûçÂêàÊäÄË°ìÔºå‰∏¶ÁÇ∫Ë≠òÂà•Ë§áÈõúÁöÑÁñºÁóõË°åÁÇ∫Ë®≠ÂÆö‰∫ÜÊñ∞ÁöÑÊ®ôÊ∫ñ„ÄÇÊàëÂÄëÁöÑÁôºÁèæÂ∞ç‰øÉÈÄ≤‰ª•ÊÇ£ËÄÖÁÇ∫‰∏≠ÂøÉÁöÑÈÜ´ÁôÇ‰øùÂÅ•Âπ≤È†êÂíåÊîØÊåÅÂèØËß£ÈáãÁöÑËá®Â∫äÊ±∫Á≠ñÂà∂ÂÆöÂÖ∑ÊúâÈáçË¶ÅÊÑèÁæ©„ÄÇ

##### **Addressing Social Misattributions of Large Language Models: An HCXAI-based Approach**
2403.17873v1 by Andrea Ferrario, Alberto Termine, Alessandro Facchini

Human-centered explainable AI (HCXAI) advocates for the integration of social
aspects into AI explanations. Central to the HCXAI discourse is the Social
Transparency (ST) framework, which aims to make the socio-organizational
context of AI systems accessible to their users. In this work, we suggest
extending the ST framework to address the risks of social misattributions in
Large Language Models (LLMs), particularly in sensitive areas like mental
health. In fact LLMs, which are remarkably capable of simulating roles and
personas, may lead to mismatches between designers' intentions and users'
perceptions of social attributes, risking to promote emotional manipulation and
dangerous behaviors, cases of epistemic injustice, and unwarranted trust. To
address these issues, we propose enhancing the ST framework with a fifth
'W-question' to clarify the specific social attributions assigned to LLMs by
its designers and users. This addition aims to bridge the gap between LLM
capabilities and user perceptions, promoting the ethically responsible
development and use of LLM-based technology.

ÊëòË¶ÅÔºö‰ª•‰∫∫‰∏∫Êú¨ÁöÑÂèØËß£Èáä AI (HCXAI) ÂÄ°ÂØºÂ∞ÜÁ§æ‰ºöÂ±ÇÈù¢Êï¥ÂêàÂà∞ AI Ëß£Èáä‰∏≠„ÄÇHCXAI ËØùËØ≠ÁöÑÊ†∏ÂøÉÊòØÁ§æ‰ºöÈÄèÊòéÂ∫¶ (ST) Ê°ÜÊû∂ÔºåÂÖ∂ÁõÆÊ†áÊòØËÆ© AI Á≥ªÁªüÁöÑÁ§æ‰ºöÁªÑÁªáËÉåÊôØÂØπÁî®Êà∑Êù•ËØ¥ÊòØÂèØÁêÜËß£ÁöÑ„ÄÇÂú®ËøôÈ°πÂ∑•‰Ωú‰∏≠ÔºåÊàë‰ª¨Âª∫ËÆÆÊâ©Â±ï ST Ê°ÜÊû∂‰ª•Ëß£ÂÜ≥Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã (LLM) ‰∏≠Á§æ‰ºöÈîôËØØÂΩíÂõ†ÁöÑÈ£éÈô©ÔºåÂ∞§ÂÖ∂ÊòØÂú®ÂøÉÁêÜÂÅ•Â∫∑Á≠âÊïèÊÑüÈ¢ÜÂüü„ÄÇ‰∫ãÂÆû‰∏äÔºåLLM ËÉΩÂ§üÂá∫Ëâ≤Âú∞Ê®°ÊãüËßíËâ≤Âíå‰∫∫Ê†ºÔºåËøôÂèØËÉΩÂØºËá¥ËÆæËÆ°ËÄÖÁöÑÊÑèÂõæÂíåÁî®Êà∑ÂØπÁ§æ‰ºöÂ±ûÊÄßÁöÑËÆ§Áü•‰πãÈó¥Âá∫Áé∞ÈîôÈÖçÔºå‰ªéËÄåÊúâÈ£éÈô©‰øÉËøõÊÉÖÁª™ÊìçÁ∫µÂíåÂç±Èô©Ë°å‰∏∫„ÄÅËÆ§Áü•‰∏çÂÖ¨Ê≠£Âíå‰∏çÂêàÁêÜÁöÑ‰ø°‰ªª„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∫õÈóÆÈ¢òÔºåÊàë‰ª¨Âª∫ËÆÆÁî®Á¨¨‰∫î‰∏™‚ÄúW ÈóÆÈ¢ò‚ÄùÊù•Â¢ûÂº∫ ST Ê°ÜÊû∂Ôºå‰ª•ÊòéÁ°ÆËÆæËÆ°ËÄÖÂíåÁî®Êà∑Ëµã‰∫à LLM ÁöÑÂÖ∑‰ΩìÁ§æ‰ºöÂ±ûÊÄß„ÄÇÊ≠§Ë°•ÂÖÖÊó®Âú®Âº•Âêà LLM ËÉΩÂäõÂíåÁî®Êà∑ËÆ§Áü•‰πãÈó¥ÁöÑÂ∑ÆË∑ùÔºå‰øÉËøõÂü∫‰∫é LLM ÁöÑÊäÄÊúØÂú®ÈÅìÂæ∑‰∏äË¥üË¥£‰ªªÂú∞ÂºÄÂèëÂíå‰ΩøÁî®„ÄÇ

##### **Clinical Domain Knowledge-Derived Template Improves Post Hoc AI Explanations in Pneumothorax Classification**
2403.18871v1 by Han Yuan, Chuan Hong, Pengtao Jiang, Gangming Zhao, Nguyen Tuan Anh Tran, Xinxing Xu, Yet Yen Yan, Nan Liu

Background: Pneumothorax is an acute thoracic disease caused by abnormal air
collection between the lungs and chest wall. To address the opaqueness often
associated with deep learning (DL) models, explainable artificial intelligence
(XAI) methods have been introduced to outline regions related to pneumothorax
diagnoses made by DL models. However, these explanations sometimes diverge from
actual lesion areas, highlighting the need for further improvement. Method: We
propose a template-guided approach to incorporate the clinical knowledge of
pneumothorax into model explanations generated by XAI methods, thereby
enhancing the quality of these explanations. Utilizing one lesion delineation
created by radiologists, our approach first generates a template that
represents potential areas of pneumothorax occurrence. This template is then
superimposed on model explanations to filter out extraneous explanations that
fall outside the template's boundaries. To validate its efficacy, we carried
out a comparative analysis of three XAI methods with and without our template
guidance when explaining two DL models in two real-world datasets. Results: The
proposed approach consistently improved baseline XAI methods across twelve
benchmark scenarios built on three XAI methods, two DL models, and two
datasets. The average incremental percentages, calculated by the performance
improvements over the baseline performance, were 97.8% in Intersection over
Union (IoU) and 94.1% in Dice Similarity Coefficient (DSC) when comparing model
explanations and ground-truth lesion areas. Conclusions: In the context of
pneumothorax diagnoses, we proposed a template-guided approach for improving AI
explanations. We anticipate that our template guidance will forge a fresh
approach to elucidating AI models by integrating clinical domain expertise.

ÊëòË¶ÅÔºö<paragraph>ËÉåÊôØÔºöÊ∞£ËÉ∏ÊòØ‰∏ÄÁ®ÆÂõ†ËÇ∫ÈÉ®ËàáËÉ∏Â£Å‰πãÈñìÁï∞Â∏∏ÈõÜÊ∞£ÊâÄÂºïËµ∑ÁöÑÊÄ•ÊÄßËÉ∏ËÖîÁñæÁóÖ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫Ê∑±Â∫¶Â≠∏ÁøíÔºàDLÔºâÊ®°ÂûãÁ∂ìÂ∏∏‰º¥Èö®ÁöÑ‰∏çÈÄèÊòéÊÄßÔºåÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖßÔºàXAIÔºâÊñπÊ≥ïÂ∑≤Ë¢´ÂºïÂÖ•ÔºåÁî®ÊñºÊ¶ÇËø∞Ëàá DL Ê®°ÂûãÂÅöÂá∫ÁöÑÊ∞£ËÉ∏Ë®∫Êñ∑Áõ∏ÈóúÁöÑÂçÄÂüü„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õËß£ÈáãÊúâÊôÇÊúÉËàáÂØ¶ÈöõÁóÖÁÅ∂ÂçÄÂüüÊúâÊâÄÂá∫ÂÖ•ÔºåÁ™ÅÈ°ØÂá∫ÈÄ≤‰∏ÄÊ≠•ÊîπÈÄ≤ÁöÑÂøÖË¶ÅÊÄß„ÄÇÊñπÊ≥ïÔºöÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊ®°ÊùøÂºïÂ∞éÂºèÊñπÊ≥ïÔºåÂ∞áÊ∞£ËÉ∏ÁöÑËá®Â∫äÁü•Ë≠òÁ¥çÂÖ• XAI ÊñπÊ≥ïÁî¢ÁîüÁöÑÊ®°ÂûãËß£Èáã‰∏≠ÔºåÂæûËÄåÊèêÂçáÈÄô‰∫õËß£ÈáãÁöÑÂìÅË≥™„ÄÇÂà©Áî®ÊîæÂ∞ÑÁßëÈÜ´Â∏´Âª∫Á´ãÁöÑÁóÖÁÅ∂ÊèèÁπ™ÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÈ¶ñÂÖàÁî¢Áîü‰∏ÄÂÄãÊ®°ÊùøÔºåÁî®ÊñºË°®Á§∫Ê∞£ËÉ∏ÂèØËÉΩÁôºÁîüÁöÑÂçÄÂüü„ÄÇÁÑ∂ÂæåÂ∞áÊ≠§Ê®°ÊùøÁñäÂä†Âú®Ê®°ÂûãËß£Èáã‰∏äÔºå‰ª•ÁØ©ÈÅ∏Âá∫Ë∂ÖÂá∫Ê®°ÊùøÈÇäÁïåÁöÑÁÑ°ÈóúËß£Èáã„ÄÇÁÇ∫‰∫ÜÈ©óË≠âÂÖ∂ÊïàÂäõÔºåÊàëÂÄëÂ∞ç‰∏âÁ®Æ XAI ÊñπÊ≥ïÈÄ≤Ë°å‰∫ÜÊØîËºÉÂàÜÊûêÔºåÂú®ÂÖ©ÂÄãÁúüÂØ¶‰∏ñÁïåË≥áÊñôÈõÜ‰∏≠Ëß£ÈáãÂÖ©ÂÄã DL Ê®°ÂûãÊôÇÔºåÂàÜÂà•Êé°Áî®Âíå‰∏çÊé°Áî®ÊàëÂÄëÁöÑÊ®°ÊùøÂºïÂ∞é„ÄÇÁµêÊûúÔºöÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÂú®Âª∫Á´ãÊñº‰∏âÁ®Æ XAI ÊñπÊ≥ï„ÄÅÂÖ©ÂÄã DL Ê®°ÂûãÂíåÂÖ©ÂÄãË≥áÊñôÈõÜÁöÑÂçÅ‰∫åÁ®ÆÂü∫Ê∫ñÊÉÖÂ¢É‰∏≠ÔºåÂßãÁµÇÊîπÂñÑ‰∫ÜÂü∫Ê∫ñ XAI ÊñπÊ≥ï„ÄÇÂú®ÊØîËºÉÊ®°ÂûãËß£ÈáãÂíåÁúüÂØ¶ÁóÖÁÅ∂ÂçÄÂüüÊôÇÔºåÈÄèÈÅéÂü∫Ê∫ñÊïàËÉΩÁöÑÊïàËÉΩÊîπÈÄ≤Ë®àÁÆóÂá∫ÁöÑÂπ≥ÂùáÂ¢ûÈáèÁôæÂàÜÊØîÁÇ∫‰∫§ÈõÜÊØîÔºàIoUÔºâÁöÑ 97.8% ÂíåÈ™∞Â≠êÁõ∏‰ººÊÄß‰øÇÊï∏ÔºàDSCÔºâÁöÑ 94.1%„ÄÇÁµêË´ñÔºöÂú®Ê∞£ËÉ∏Ë®∫Êñ∑ÁöÑËÉåÊôØ‰∏ãÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊ®°ÊùøÂºïÂ∞éÂºèÊñπÊ≥ïÔºåÁî®ÊñºÊîπÂñÑ AI Ëß£Èáã„ÄÇÊàëÂÄëÈ†êÊúüÊàëÂÄëÁöÑÊ®°ÊùøÂºïÂ∞éÂ∞áÈÄèÈÅéÊï¥ÂêàËá®Â∫äÈ†òÂüüÂ∞àÊ•≠Áü•Ë≠òÔºåÁÇ∫Èó°Êòé AI Ê®°ÂûãÂª∫Á´ã‰∏ÄÁ®ÆÊñ∞ÊñπÊ≥ï„ÄÇ</paragraph>

##### **Enhancing Neural Machine Translation of Low-Resource Languages: Corpus Development, Human Evaluation and Explainable AI Architectures**
2403.01580v1 by S√©amus Lankford

In the current machine translation (MT) landscape, the Transformer
architecture stands out as the gold standard, especially for high-resource
language pairs. This research delves into its efficacy for low-resource
language pairs including both the English$\leftrightarrow$Irish and
English$\leftrightarrow$Marathi language pairs. Notably, the study identifies
the optimal hyperparameters and subword model type to significantly improve the
translation quality of Transformer models for low-resource language pairs.
  The scarcity of parallel datasets for low-resource languages can hinder MT
development. To address this, gaHealth was developed, the first bilingual
corpus of health data for the Irish language. Focusing on the health domain,
models developed using this in-domain dataset exhibited very significant
improvements in BLEU score when compared with models from the LoResMT2021
Shared Task. A subsequent human evaluation using the multidimensional quality
metrics error taxonomy showcased the superior performance of the Transformer
system in reducing both accuracy and fluency errors compared to an RNN-based
counterpart.
  Furthermore, this thesis introduces adaptNMT and adaptMLLM, two open-source
applications streamlined for the development, fine-tuning, and deployment of
neural machine translation models. These tools considerably simplify the setup
and evaluation process, making MT more accessible to both developers and
translators. Notably, adaptNMT, grounded in the OpenNMT ecosystem, promotes
eco-friendly natural language processing research by highlighting the
environmental footprint of model development. Fine-tuning of MLLMs by adaptMLLM
demonstrated advancements in translation performance for two low-resource
language pairs: English$\leftrightarrow$Irish and
English$\leftrightarrow$Marathi, compared to baselines from the LoResMT2021
Shared Task.

ÊëòË¶ÅÔºö<paragraph>Âú®Áï∂ÂâçÊ©üÂô®ÁøªË≠Ø (MT) È†òÂüü‰∏≠ÔºåTransformer Êû∂ÊßãËÑ´Á©éËÄåÂá∫ÔºåÊàêÁÇ∫ÈªÉÈáëÊ®ôÊ∫ñÔºåÁâπÂà•ÊòØÂ∞çÊñºÈ´òË≥áÊ∫êË™ûË®ÄÂ∞ç„ÄÇÊú¨Á†îÁ©∂Êé¢Ë®éÂÖ∂Â∞ç‰ΩéË≥áÊ∫êË™ûË®ÄÂ∞çÁöÑÊïàËÉΩÔºåÂåÖÊã¨Ëã±Ë™û‚ÜîÊÑõÁàæËò≠Ë™ûÂíåËã±Ë™û‚ÜîÈ¶¨ÊãâÂú∞Ë™ûË™ûË®ÄÂ∞ç„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÊú¨Á†îÁ©∂Ë≠òÂà•Âá∫ÊúÄ‰Ω≥Ë∂ÖÂèÉÊï∏ÂíåÂ≠êË©ûÊ®°ÂûãÈ°ûÂûãÔºå‰ª•È°ØËëóÊèêÈ´ò Transformer Ê®°ÂûãÂ∞ç‰ΩéË≥áÊ∫êË™ûË®ÄÂ∞çÁöÑÁøªË≠ØÂìÅË≥™„ÄÇ
‰ΩéË≥áÊ∫êË™ûË®ÄÁöÑÂπ≥Ë°åË≥áÊñôÈõÜÁöÑÁ®ÄÁº∫ÊúÉÈòªÁ§ô MT ÁöÑÁôºÂ±ï„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÈñãÁôº‰∫Ü gaHealthÔºåÈÄôÊòØÊÑõÁàæËò≠Ë™ûÁöÑÁ¨¨‰∏ÄÂÄãÈõôË™ûÂÅ•Â∫∑Ë≥áÊñôË™ûÊñôÂ∫´„ÄÇÂ∞àÊ≥®ÊñºÂÅ•Â∫∑È†òÂüüÔºå‰ΩøÁî®Ê≠§ÂüüÂÖßË≥áÊñôÈõÜÈñãÁôºÁöÑÊ®°ÂûãÂú® BLEU ÂæóÂàÜÊñπÈù¢Ë°®ÁèæÂá∫ÈùûÂ∏∏È°ØËëóÁöÑÈÄ≤Ê≠•ÔºåËàá LoResMT2021 ÂÖ±‰∫´‰ªªÂãô‰∏≠ÁöÑÊ®°ÂûãÁõ∏ÊØî„ÄÇÈö®Âæå‰ΩøÁî®Â§öÁ∂≠ÂìÅË≥™ÊåáÊ®ôÈåØË™§ÂàÜÈ°ûÊ≥ïÈÄ≤Ë°åÁöÑ‰∫∫Â∑•Ë©ï‰º∞È°ØÁ§∫ÔºåËàáÂü∫Êñº RNN ÁöÑÂ∞çÊáâÊ®°ÂûãÁõ∏ÊØîÔºåTransformer Á≥ªÁµ±Âú®Ê∏õÂ∞ëÊ∫ñÁ¢∫ÊÄßÂíåÊµÅÊö¢ÊÄßÈåØË™§ÊñπÈù¢Ë°®ÁèæÂá∫ÂÑ™Áï∞ÁöÑÊÄßËÉΩ„ÄÇ
Ê≠§Â§ñÔºåÊú¨Ë´ñÊñá‰ªãÁ¥π‰∫Ü adaptNMT Âíå adaptMLLMÔºåÈÄôÂÖ©ÂÄãÈñãÊ∫êÊáâÁî®Á®ãÂºèÁ∞°Âåñ‰∫ÜÁ•ûÁ∂ìÊ©üÂô®ÁøªË≠ØÊ®°ÂûãÁöÑÈñãÁôº„ÄÅÂæÆË™øÂíåÈÉ®ÁΩ≤„ÄÇÈÄô‰∫õÂ∑•ÂÖ∑Â§ßÂπÖÁ∞°Âåñ‰∫ÜË®≠ÂÆöÂíåË©ï‰º∞ÊµÅÁ®ãÔºåËÆì MT Êõ¥ÂÆπÊòìËÆìÈñãÁôº‰∫∫Âì°ÂíåÁøªË≠Ø‰∫∫Âì°‰ΩøÁî®„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåadaptNMT ‰ª• OpenNMT ÁîüÊÖãÁ≥ªÁµ±ÁÇ∫Âü∫Á§éÔºåÈÄöÈÅéÂº∑Ë™øÊ®°ÂûãÈñãÁôºÁöÑÁí∞Â¢ÉË∂≥Ë∑°‰æÜ‰øÉÈÄ≤ÁîüÊÖãÂèãÂ•ΩÁöÑËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜÁ†îÁ©∂„ÄÇËàá LoResMT2021 ÂÖ±‰∫´‰ªªÂãô‰∏≠ÁöÑÂü∫Ê∫ñÁõ∏ÊØîÔºåadaptMLLM Â∞ç MLLM ÁöÑÂæÆË™øË≠âÊòé‰∫ÜËã±Ë™û‚ÜîÊÑõÁàæËò≠Ë™ûÂíåËã±Ë™û‚ÜîÈ¶¨ÊãâÂú∞Ë™ûÈÄôÂÖ©ÂÄã‰ΩéË≥áÊ∫êË™ûË®ÄÂ∞çÁöÑÁøªË≠ØÊÄßËÉΩÈÄ≤Ê≠•„ÄÇ</paragraph>

##### **Artificial Intelligence and Diabetes Mellitus: An Inside Look Through the Retina**
2402.18600v1 by Yasin Sadeghi Bazargani, Majid Mirzaei, Navid Sobhi, Mirsaeed Abdollahi, Ali Jafarizadeh, Siamak Pedrammehr, Roohallah Alizadehsani, Ru San Tan, Sheikh Mohammed Shariful Islam, U. Rajendra Acharya

Diabetes mellitus (DM) predisposes patients to vascular complications.
Retinal images and vasculature reflect the body's micro- and macrovascular
health. They can be used to diagnose DM complications, including diabetic
retinopathy (DR), neuropathy, nephropathy, and atherosclerotic cardiovascular
disease, as well as forecast the risk of cardiovascular events. Artificial
intelligence (AI)-enabled systems developed for high-throughput detection of DR
using digitized retinal images have become clinically adopted. Beyond DR
screening, AI integration also holds immense potential to address challenges
associated with the holistic care of the patient with DM. In this work, we aim
to comprehensively review the literature for studies on AI applications based
on retinal images related to DM diagnosis, prognostication, and management. We
will describe the findings of holistic AI-assisted diabetes care, including but
not limited to DR screening, and discuss barriers to implementing such systems,
including issues concerning ethics, data privacy, equitable access, and
explainability. With the ability to evaluate the patient's health status vis a
vis DM complication as well as risk prognostication of future cardiovascular
complications, AI-assisted retinal image analysis has the potential to become a
central tool for modern personalized medicine in patients with DM.

ÊëòË¶ÅÔºöÁ≥ñÂ∞øÁóÖÔºàDMÔºâ‰ΩøÊÇ£ËÄÖÂÆπÊòìÂá∫ÁèæË°ÄÁÆ°‰ΩµÁôºÁóá„ÄÇ
Ë¶ñÁ∂≤ËÜúÂΩ±ÂÉèÂíåË°ÄÁÆ°ÂèçÊò†Ë∫´È´îÁöÑÂæÆË°ÄÁÆ°ÂíåÂ∑®Ë°ÄÁÆ°ÂÅ•Â∫∑ÁãÄÊ≥Å„ÄÇÂÆÉÂÄëÂèØÁî®ÊñºË®∫Êñ∑Á≥ñÂ∞øÁóÖ‰ΩµÁôºÁóáÔºåÂåÖÊã¨Á≥ñÂ∞øÁóÖË¶ñÁ∂≤ËÜúÁóÖËÆäÔºàDRÔºâ„ÄÅÁ•ûÁ∂ìÁóÖËÆä„ÄÅËÖéÁóÖÂíåÂãïËÑàÁ≤•Ê®£Á°¨ÂåñÊÄßÂøÉË°ÄÁÆ°ÁñæÁóÖÔºå‰ª•ÂèäÈ†êÊ∏¨ÂøÉË°ÄÁÆ°‰∫ã‰ª∂ÁöÑÈ¢®Èö™„ÄÇÁÇ∫‰ΩøÁî®Êï∏‰ΩçÂåñË¶ñÁ∂≤ËÜúÂΩ±ÂÉèÈÄ≤Ë°åÈ´òÈÄöÈáè DR Ê™¢Ê∏¨ËÄåÈñãÁôºÁöÑ‰∫∫Â∑•Êô∫ÊÖßÔºàAIÔºâÂïüÁî®Á≥ªÁµ±Â∑≤Âú®Ëá®Â∫äÊé°Áî®„ÄÇÈô§‰∫Ü DR ÁØ©Ê™¢Â§ñÔºåAI Êï¥Âêà‰πüÂÖ∑ÊúâÂ∑®Â§ßÁöÑÊΩõÂäõ‰æÜÊáâÂ∞çËàáÁ≥ñÂ∞øÁóÖÊÇ£ËÄÖÊï¥È´îÁÖßË≠∑Áõ∏ÈóúÁöÑÊåëÊà∞„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊó®Âú®ÂÖ®Èù¢ÂõûÈ°ßÂü∫ÊñºË¶ñÁ∂≤ËÜúÂΩ±ÂÉèÁöÑ AI ÊáâÁî®Áõ∏ÈóúÁ†îÁ©∂ÁöÑÊñáÁçªÔºåÈÄô‰∫õÁ†îÁ©∂ËàáÁ≥ñÂ∞øÁóÖÁöÑË®∫Êñ∑„ÄÅÈ†êÂæåÂíåÁÆ°ÁêÜÊúâÈóú„ÄÇÊàëÂÄëÂ∞áÊèèËø∞Êï¥È´î AI ËºîÂä©Á≥ñÂ∞øÁóÖÁÖßË≠∑ÁöÑÁôºÁèæÔºåÂåÖÊã¨‰ΩÜ‰∏çÈôêÊñº DR ÁØ©Ê™¢Ôºå‰∏¶Ë®éË´ñÂØ¶ÊñΩÊ≠§È°ûÁ≥ªÁµ±ÁöÑÈöúÁ§ôÔºåÂåÖÊã¨ËàáÂÄ´ÁêÜ„ÄÅË≥áÊñôÈö±ÁßÅ„ÄÅÂÖ¨Âπ≥Â≠òÂèñÂíåÂèØËß£ÈáãÊÄßÊúâÈóúÁöÑÂïèÈ°å„ÄÇÈÄèÈÅéË©ï‰º∞ÊÇ£ËÄÖÁöÑÂÅ•Â∫∑ÁãÄÊ≥ÅÔºåÂêåÊôÇËÄÉÈáèÁ≥ñÂ∞øÁóÖ‰ΩµÁôºÁóá‰ª•ÂèäÊú™‰æÜÂøÉË°ÄÁÆ°‰ΩµÁôºÁóáÁöÑÈ¢®Èö™È†êÂæåÔºåAI ËºîÂä©Ë¶ñÁ∂≤ËÜúÂΩ±ÂÉèÂàÜÊûêÊúâÊΩõÂäõÊàêÁÇ∫Á≥ñÂ∞øÁóÖÊÇ£ËÄÖÁèæ‰ª£ÂåñÂÄã‰∫∫ÂåñÈÜ´ÁôÇÁöÑ‰∏≠ÂøÉÂ∑•ÂÖ∑„ÄÇ

##### **Multi-stakeholder Perspective on Responsible Artificial Intelligence and Acceptability in Education**
2402.15027v2 by A. J. Karran, P. Charland, J-T. Martineau, A. Ortiz de Guinea Lopez de Arana, AM. Lesage, S. Senecal, P-M. Leger

This study investigates the acceptability of different artificial
intelligence (AI) applications in education from a multi-stakeholder
perspective, including students, teachers, and parents. Acknowledging the
transformative potential of AI in education, it addresses concerns related to
data privacy, AI agency, transparency, explainability and the ethical
deployment of AI. Through a vignette methodology, participants were presented
with four scenarios where AI's agency, transparency, explainability, and
privacy were manipulated. After each scenario, participants completed a survey
that captured their perceptions of AI's global utility, individual usefulness,
justice, confidence, risk, and intention to use each scenario's AI if
available. The data collection comprising a final sample of 1198
multi-stakeholder participants was distributed through a partner institution
and social media campaigns and focused on individual responses to four AI use
cases. A mediation analysis of the data indicated that acceptance and trust in
AI varies significantly across stakeholder groups. We found that the key
mediators between high and low levels of AI's agency, transparency, and
explainability, as well as the intention to use the different educational AI,
included perceived global utility, justice, and confidence. The study
highlights that the acceptance of AI in education is a nuanced and multifaceted
issue that requires careful consideration of specific AI applications and their
characteristics, in addition to the diverse stakeholders' perceptions.

ÊëòË¶ÅÔºöÈÄôÈ†ÖÁ†îÁ©∂ÂæûÂ§öÂÄãÂà©ÂÆ≥Èóú‰øÇ‰∫∫ÁöÑËßíÂ∫¶Êé¢Ë®é‰∏çÂêåÁöÑ‰∫∫Â∑•Êô∫ÊÖß (AI) ÊáâÁî®Âú®ÊïôËÇ≤‰∏äÁöÑÂèØÊé•ÂèóÊÄßÔºåÂåÖÊã¨Â≠∏Áîü„ÄÅËÄÅÂ∏´ÂíåÂÆ∂Èï∑„ÄÇÊâøË™ç AI Âú®ÊïôËÇ≤‰∏äÁöÑËΩâÂûãÊΩõÂäõÔºåÂÆÉËß£Ê±∫‰∫ÜËàáË≥áÊñôÈö±ÁßÅ„ÄÅAI ‰ª£ÁêÜ„ÄÅÈÄèÊòéÂ∫¶„ÄÅÂèØËß£ÈáãÊÄßÂíå AI ÁöÑÈÅìÂæ∑ÈÉ®ÁΩ≤Áõ∏ÈóúÁöÑÁñëÊÖÆ„ÄÇÈÄèÈÅéÂ∞èÊèíÊõ≤ÊñπÊ≥ïÔºåÂèÉËàáËÄÖË¢´ÂëàÁèæ‰∫ÜÂõõÁ®ÆÊÉÖÂ¢ÉÔºåÂÖ∂‰∏≠ AI ÁöÑ‰ª£ÁêÜ„ÄÅÈÄèÊòéÂ∫¶„ÄÅÂèØËß£ÈáãÊÄßÂíåÈö±ÁßÅÂèóÂà∞ÊìçÁ∏±„ÄÇÂú®ÊØèÂÄãÊÉÖÂ¢ÉÂæåÔºåÂèÉËàáËÄÖÂÆåÊàê‰∫Ü‰∏ÄÈ†ÖË™øÊü•ÔºåË©≤Ë™øÊü•ÊçïÊçâ‰∫Ü‰ªñÂÄëÂ∞ç AI ÁöÑÊï¥È´îÊïàÁî®„ÄÅÂÄã‰∫∫ÊïàÁî®„ÄÅÊ≠£Áæ©„ÄÅ‰ø°ÂøÉ„ÄÅÈ¢®Èö™ÂíåÂ¶ÇÊûúÂèØÁî®Ôºå‰ΩøÁî®ÊØèÂÄãÊÉÖÂ¢ÉÁöÑ AI ÁöÑÊÑèÂúñÁöÑÁúãÊ≥ï„ÄÇË≥áÊñôËíêÈõÜÂåÖÂê´‰æÜËá™Âêà‰ΩúÊ©üÊßãÂíåÁ§æÁæ§Â™íÈ´îÊ¥ªÂãïÁöÑ 1198 ‰ΩçÂ§öÂà©ÂÆ≥Èóú‰øÇ‰∫∫ÂèÉËàáËÄÖÁöÑÊúÄÁµÇÊ®£Êú¨Ôºå‰∏¶Â∞àÊ≥®ÊñºÂ∞çÂõõÂÄã AI ‰ΩøÁî®Ê°à‰æãÁöÑÂÄãÂà•ÂõûÊáâ„ÄÇÂ∞çË≥áÊñôÁöÑË™øËß£ÂàÜÊûêË°®ÊòéÔºåÂ∞ç AI ÁöÑÊé•ÂèóÂ∫¶Âíå‰ø°‰ªªÂú®Âà©ÂÆ≥Èóú‰øÇ‰∫∫ÂúòÈ´î‰πãÈñìÊúâÈ°ØËëóÂ∑ÆÁï∞„ÄÇÊàëÂÄëÁôºÁèæÔºåAI ÁöÑ‰ª£ÁêÜ„ÄÅÈÄèÊòéÂ∫¶ÂíåÂèØËß£ÈáãÊÄßÈ´ò‰ΩéÁ®ãÂ∫¶‰πãÈñìÁöÑÈóúÈçµË™øËß£ËÄÖÔºå‰ª•Âèä‰ΩøÁî®‰∏çÂêåÊïôËÇ≤ AI ÁöÑÊÑèÂúñÔºåÂåÖÊã¨ÊÑüÁü•Âà∞ÁöÑÊï¥È´îÊïàÁî®„ÄÅÊ≠£Áæ©Âíå‰ø°ÂøÉ„ÄÇÈÄôÈ†ÖÁ†îÁ©∂Âº∑Ë™øÔºåÊé•Âèó AI Âú®ÊïôËÇ≤‰∏äÁöÑÊáâÁî®ÊòØ‰∏ÄÂÄãÂæÆÂ¶ô‰∏îÂ§öÈù¢ÂêëÁöÑÂïèÈ°åÔºåÈô§‰∫Ü‰∏çÂêåÁöÑÂà©ÂÆ≥Èóú‰øÇ‰∫∫ÁöÑÁúãÊ≥ïÂ§ñÔºåÈÇÑÈúÄË¶Å‰ªîÁ¥∞ËÄÉÊÖÆÂÖ∑È´îÁöÑ AI ÊáâÁî®ÂèäÂÖ∂ÁâπÂæµ„ÄÇ

##### **Deciphering Heartbeat Signatures: A Vision Transformer Approach to Explainable Atrial Fibrillation Detection from ECG Signals**
2402.09474v2 by Aruna Mohan, Danne Elbers, Or Zilbershot, Fatemeh Afghah, David Vorchheimer

Remote patient monitoring based on wearable single-lead electrocardiogram
(ECG) devices has significant potential for enabling the early detection of
heart disease, especially in combination with artificial intelligence (AI)
approaches for automated heart disease detection. There have been prior studies
applying AI approaches based on deep learning for heart disease detection.
However, these models are yet to be widely accepted as a reliable aid for
clinical diagnostics, in part due to the current black-box perception
surrounding many AI algorithms. In particular, there is a need to identify the
key features of the ECG signal that contribute toward making an accurate
diagnosis, thereby enhancing the interpretability of the model. In the present
study, we develop a vision transformer approach to identify atrial fibrillation
based on single-lead ECG data. A residual network (ResNet) approach is also
developed for comparison with the vision transformer approach. These models are
applied to the Chapman-Shaoxing dataset to classify atrial fibrillation, as
well as another common arrhythmia, sinus bradycardia, and normal sinus rhythm
heartbeats. The models enable the identification of the key regions of the
heartbeat that determine the resulting classification, and highlight the
importance of P-waves and T-waves, as well as heartbeat duration and signal
amplitude, in distinguishing normal sinus rhythm from atrial fibrillation and
sinus bradycardia.

ÊëòË¶ÅÔºö<paragraph>Âü∫ÊñºÂèØÁ©øÊà¥ÂºèÂñÆÂ∞éÁ®ãÂøÉÈõªÂúñ (ECG) Ë£ùÁΩÆÁöÑÈÅ†Á´ØÁóÖÊÇ£Áõ£Ê∏¨Âú®Êó©ÊúüÂÅµÊ∏¨ÂøÉËáüÁñæÁóÖÊñπÈù¢ÂÖ∑ÊúâÈ°ØËëóÁöÑÊΩõÂäõÔºåÁâπÂà•ÊòØËàáÁî®ÊñºËá™ÂãïÂåñÂøÉËáüÁñæÁóÖÂÅµÊ∏¨ÁöÑ‰∫∫Â∑•Êô∫ÊÖß (AI) ÊñπÊ≥ïÁµêÂêà‰ΩøÁî®ÊôÇ„ÄÇÂÖàÂâçÂ∑≤ÊúâÁ†îÁ©∂ÊáâÁî®Âü∫ÊñºÊ∑±Â∫¶Â≠∏ÁøíÁöÑ AI ÊñπÊ≥ïÈÄ≤Ë°åÂøÉËáüÁñæÁóÖÂÅµÊ∏¨„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÊ®°ÂûãÂ∞öÊú™Ë¢´Âª£Ê≥õÊé•ÂèóÁÇ∫Ëá®Â∫äË®∫Êñ∑ÁöÑÂèØÈù†ËºîÂä©Â∑•ÂÖ∑ÔºåÈÉ®ÂàÜÂéüÂõ†Âú®ÊñºÂúçÁπûË®±Â§ö AI ÊºîÁÆóÊ≥ïÁöÑÁï∂ÂâçÈªëÁÆ±ÊÑüÁü•„ÄÇÁâπÂà•ÊòØÔºåÊúâÂøÖË¶ÅÊâæÂá∫ÊúâÂä©ÊñºÂÅöÂá∫Ê∫ñÁ¢∫Ë®∫Êñ∑ÁöÑ ECG Ë®äËôüÈóúÈçµÁâπÂæµÔºåÂæûËÄåÂ¢ûÂº∑Ê®°ÂûãÁöÑÂèØËß£ÈáãÊÄß„ÄÇÂú®Êú¨Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëÈñãÁôº‰∫Ü‰∏ÄÁ®ÆË¶ñË¶∫ËΩâÊèõÂô®ÊñπÊ≥ïÔºå‰ª•Ê†πÊìöÂñÆÂ∞éÁ®ã ECG Ë≥áÊñôÊâæÂá∫ÂøÉÊàøÈ°´Âãï„ÄÇÊÆòÂ∑ÆÁ∂≤Ë∑Ø (ResNet) ÊñπÊ≥ï‰πüÂ∑≤ÈñãÁôºÂá∫‰æÜÔºå‰ª•‰æøËàáË¶ñË¶∫ËΩâÊèõÂô®ÊñπÊ≥ïÈÄ≤Ë°åÊØîËºÉ„ÄÇÈÄô‰∫õÊ®°ÂûãÊáâÁî®Êñº Chapman-Shaoxing Ë≥áÊñôÈõÜÔºå‰ª•ÂàÜÈ°ûÂøÉÊàøÈ°´ÂãïÔºå‰ª•ÂèäÂè¶‰∏ÄÁ®ÆÂ∏∏Ë¶ãÁöÑÂøÉÂæã‰∏çÊï¥ÔºåÁ´áÊÄßÂøÉÂãïÈÅéÁ∑©ÔºåÂíåÊ≠£Â∏∏Á´áÊÄßÂøÉÂæãÁöÑÂøÉË∑≥„ÄÇÈÄô‰∫õÊ®°ÂûãËÉΩÂ§†ÊâæÂá∫Ê±∫ÂÆöÊúÄÁµÇÂàÜÈ°ûÁöÑÂøÉË∑≥ÈóúÈçµÂçÄÂüüÔºå‰∏¶Âº∑Ë™ø P Ê≥¢Âíå T Ê≥¢Ôºå‰ª•ÂèäÂøÉË∑≥ÊåÅÁ∫åÊôÇÈñìÂíåË®äËôüÊåØÂπÖÂú®ÂçÄÂàÜÊ≠£Â∏∏Á´áÊÄßÂøÉÂæãËàáÂøÉÊàøÈ°´ÂãïÂíåÁ´áÊÄßÂøÉÂãïÈÅéÁ∑©ÊñπÈù¢ÁöÑÈáçË¶ÅÊÄß„ÄÇ</paragraph>

##### **Illuminate: A novel approach for depression detection with explainable analysis and proactive therapy using prompt engineering**
2402.05127v1 by Aryan Agrawal

This paper introduces a novel paradigm for depression detection and treatment
using advanced Large Language Models (LLMs): Generative Pre-trained Transformer
4 (GPT-4), Llama 2 chat, and Gemini. These LLMs are fine-tuned with specialized
prompts to diagnose, explain, and suggest therapeutic interventions for
depression. A unique few-shot prompting method enhances the models' ability to
analyze and explain depressive symptoms based on the DSM-5 criteria. In the
interaction phase, the models engage in empathetic dialogue management, drawing
from resources like PsychDB and a Cognitive Behavioral Therapy (CBT) Guide,
fostering supportive interactions with individuals experiencing major
depressive disorders. Additionally, the research introduces the Illuminate
Database, enriched with various CBT modules, aiding in personalized therapy
recommendations. The study evaluates LLM performance using metrics such as F1
scores, Precision, Recall, Cosine similarity, and Recall-Oriented Understudy
for Gisting Evaluation (ROUGE) across different test sets, demonstrating their
effectiveness. This comprehensive approach blends cutting-edge AI with
established psychological methods, offering new possibilities in mental health
care and showcasing the potential of LLMs in revolutionizing depression
diagnosis and treatment strategies.

ÊëòË¶ÅÔºöÊú¨Êñá‰ªãÁ¥π‰∫Ü‰∏ÄÁ®Æ‰ΩøÁî®ÂÖàÈÄ≤Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÈÄ≤Ë°åÊÜÇÈ¨±ÁóáÂÅµÊ∏¨ÂíåÊ≤ªÁôÇÁöÑÊñ∞Ê®°ÂºèÔºöÁîüÊàêÂºèÈ†êË®ìÁ∑¥Transformer 4 (GPT-4)„ÄÅLlama 2 ËÅäÂ§©Ê©üÂô®‰∫∫Âíå Gemini„ÄÇÈÄô‰∫õ LLM Á∂ìÈÅéÂæÆË™øÔºåÂÖ∑ÂÇôÂ∞àÊ•≠ÊèêÁ§∫ÔºåÂèØË®∫Êñ∑„ÄÅËß£Èáã‰∏¶Âª∫Ë≠∞ÊÜÇÈ¨±ÁóáÁöÑÊ≤ªÁôÇ‰ªãÂÖ•ÊñπÊ≥ï„ÄÇ‰∏ÄÁ®ÆÁç®ÁâπÁöÑÂ∞ëÊ¨°ÊèêÁ§∫ÊñπÊ≥ïÂ¢ûÂº∑‰∫ÜÊ®°ÂûãÊ†πÊìö DSM-5 Ê®ôÊ∫ñÂàÜÊûêÂíåËß£ÈáãÊÜÇÈ¨±ÁóáÁãÄÁöÑËÉΩÂäõ„ÄÇÂú®‰∫íÂãïÈöéÊÆµÔºåÈÄô‰∫õÊ®°ÂûãÊúÉÂèÉËàáÂêåÁêÜÂøÉÂ∞çË©±ÁÆ°ÁêÜÔºåÂæû PsychDB ÂíåË™çÁü•Ë°åÁÇ∫ÁôÇÊ≥ï (CBT) ÊåáÂçóÁ≠âË≥áÊ∫ê‰∏≠Ê±≤ÂèñÔºå‰øÉÈÄ≤ËàáÁ∂ìÊ≠∑ÈáçÂ∫¶ÊÜÇÈ¨±ÁóáÁöÑ‰∫∫ÂÄëÁöÑÊîØÊåÅÊÄß‰∫íÂãï„ÄÇÊ≠§Â§ñÔºåÈÄôÈ†ÖÁ†îÁ©∂ÈÇÑ‰ªãÁ¥π‰∫Ü Illuminate Ë≥áÊñôÂ∫´ÔºåÂÖ∂‰∏≠ÂåÖÂê´ÂêÑÁ®Æ CBT Ê®°ÁµÑÔºåÊúâÂä©ÊñºÂÄãÊÄßÂåñÊ≤ªÁôÇÂª∫Ë≠∞„ÄÇÈÄôÈ†ÖÁ†îÁ©∂‰ΩøÁî® F1 ÂàÜÊï∏„ÄÅÊ∫ñÁ¢∫Áéá„ÄÅÂè¨ÂõûÁéá„ÄÅÈ§òÂº¶Áõ∏‰ººÂ∫¶ÂíåÈù¢ÂêëÂè¨ÂõûÁéáÁöÑ Gisting Ë©ï‰º∞ÊõøË∫´ (ROUGE) Á≠âÊåáÊ®ôÔºåÂú®‰∏çÂêåÁöÑÊ∏¨Ë©¶ÈõÜ‰∏≠Ë©ï‰º∞ LLM ÁöÑË°®ÁèæÔºåË≠âÊòé‰∫ÜÂÆÉÂÄëÁöÑÊúâÊïàÊÄß„ÄÇÈÄôÁ®ÆÁ∂úÂêàÊñπÊ≥ïÁµêÂêà‰∫ÜÂ∞ñÁ´ØÁöÑ AI ËàáÊó¢ÂÆöÁöÑÂøÉÁêÜÊñπÊ≥ïÔºåÁÇ∫ÂøÉÁêÜ‰øùÂÅ•Êèê‰æõ‰∫ÜÊñ∞ÁöÑÂèØËÉΩÊÄßÔºå‰∏¶Â±ïÁ§∫‰∫Ü LLM Âú®Èù©Êñ∞ÊÜÇÈ¨±ÁóáË®∫Êñ∑ÂíåÊ≤ªÁôÇÁ≠ñÁï•ÊñπÈù¢ÁöÑÊΩõÂäõ„ÄÇ

##### **Information That Matters: Exploring Information Needs of People Affected by Algorithmic Decisions**
2401.13324v4 by Timoth√©e Schmude, Laura Koesten, Torsten M√∂ller, Sebastian Tschiatschek

Explanations of AI systems rarely address the information needs of people
affected by algorithmic decision-making (ADM). This gap between conveyed
information and information that matters to affected stakeholders can impede
understanding and adherence to regulatory frameworks such as the AI Act. To
address this gap, we present the "XAI Novice Question Bank": A catalog of
affected stakeholders' information needs in two ADM use cases (employment
prediction and health monitoring), covering the categories data, system
context, system usage, and system specifications. Information needs were
gathered in an interview study where participants received explanations in
response to their inquiries. Participants further reported their understanding
and decision confidence, showing that while confidence tended to increase after
receiving explanations, participants also met understanding challenges, such as
being unable to tell why their understanding felt incomplete. Explanations
further influenced participants' perceptions of the systems' risks and
benefits, which they confirmed or changed depending on the use case. When risks
were perceived as high, participants expressed particular interest in
explanations about intention, such as why and to what end a system was put in
place. With this work, we aim to support the inclusion of affected stakeholders
into explainability by contributing an overview of information and challenges
relevant to them when deciding on the adoption of ADM systems. We close by
summarizing our findings in a list of six key implications that inform the
design of future explanations for affected stakeholder audiences.

ÊëòË¶ÅÔºö<paragraph>‰∫∫Â∑•Êô∫ÊÖßÁ≥ªÁµ±ÁöÑË™™ÊòéÂæàÂ∞ëËÉΩÊªøË∂≥ÂèóÊºîÁÆóÊ≥ïÊ±∫Á≠ñ (ADM) ÂΩ±ÈüøÁöÑ‰∫∫ÂÄëÁöÑË≥áË®äÈúÄÊ±Ç„ÄÇÂÇ≥ÈÅîÁöÑË≥áË®äËàáÂΩ±ÈüøÂà©ÂÆ≥Èóú‰øÇ‰∫∫ÈáçË¶ÅÁöÑË≥áË®ä‰πãÈñìÁöÑÂ∑ÆË∑ùÔºåÂèØËÉΩÊúÉÈòªÁ§ô‰∫ÜËß£ÂíåÈÅµÂÆàÊ≥ïË¶èÊû∂ÊßãÔºå‰æãÂ¶Ç‰∫∫Â∑•Êô∫ÊÖßÊ≥ïÊ°à„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂ∑ÆË∑ùÔºåÊàëÂÄëÊèêÂá∫‰∫Ü„ÄåXAI ÂàùÂ≠∏ËÄÖÂïèÈ°åÂ∫´„ÄçÔºöÂèóÂΩ±ÈüøÂà©ÂÆ≥Èóú‰øÇ‰∫∫Ë≥áË®äÈúÄÊ±ÇÁöÑÁõÆÈåÑÔºåÊ∂µËìãÂÖ©ÂÄã ADM ‰ΩøÁî®Ê°à‰æãÔºàÂ∞±Ê•≠È†êÊ∏¨ÂíåÂÅ•Â∫∑Áõ£Ê∏¨ÔºâÔºåÊ∂µËìãË≥áÊñô„ÄÅÁ≥ªÁµ±ËÑàÁµ°„ÄÅÁ≥ªÁµ±‰ΩøÁî®ÂíåÁ≥ªÁµ±Ë¶èÊ†ºÈ°ûÂà•„ÄÇË≥áË®äÈúÄÊ±ÇÊòØÈÄèÈÅéË®™Ë´áÁ†îÁ©∂Êî∂ÈõÜÁöÑÔºåÂèÉËàáËÄÖÂú®Ë©¢ÂïèÂæåÊî∂Âà∞Ë™™Êòé„ÄÇÂèÉËàáËÄÖÈÄ≤‰∏ÄÊ≠•ÂõûÂ†±‰ªñÂÄëÁöÑÁêÜËß£ÂíåÊ±∫Á≠ñ‰ø°ÂøÉÔºåÈ°ØÁ§∫ÈõñÁÑ∂Âú®Êî∂Âà∞Ë™™ÊòéÂæå‰ø°ÂøÉÂÇæÂêëÊñºÂ¢ûÂä†Ôºå‰ΩÜÂèÉËàáËÄÖ‰πüÈÅáÂà∞‰∫ÜÁêÜËß£ÊåëÊà∞Ôºå‰æãÂ¶ÇÁÑ°Ê≥ïË™™ÊòéÁÇ∫‰ªÄÈ∫º‰ªñÂÄëÁöÑÁêÜËß£ÊÑüË¶∫‰∏çÂÆåÊï¥„ÄÇË™™ÊòéÈÄ≤‰∏ÄÊ≠•ÂΩ±ÈüøÂèÉËàáËÄÖÂ∞çÁ≥ªÁµ±È¢®Èö™ÂíåÂ•ΩËôïÁöÑÁúãÊ≥ïÔºå‰ªñÂÄëÊúÉÊ†πÊìö‰ΩøÁî®Ê°à‰æãÁ¢∫Ë™çÊàñÊîπËÆäÈÄô‰∫õÁúãÊ≥ï„ÄÇÁï∂È¢®Èö™Ë¢´Ë™çÁÇ∫ÂæàÈ´òÊôÇÔºåÂèÉËàáËÄÖË°®Á§∫ÁâπÂà•ÊúâËààË∂£‰∫ÜËß£ÊÑèÂúñÁöÑË™™ÊòéÔºå‰æãÂ¶ÇÁÇ∫‰ªÄÈ∫º‰ª•ÂèäÁÇ∫‰∫Ü‰ªÄÈ∫ºÁõÆÁöÑËÄåÂª∫Á´ãÁ≥ªÁµ±„ÄÇÈÄèÈÅéÈÄôÈ†ÖÂ∑•‰ΩúÔºåÊàëÂÄëÊó®Âú®ÈÄèÈÅéÂú®Ê±∫Á≠ñÊé°Áî® ADM Á≥ªÁµ±ÊôÇÊèê‰æõÁõ∏ÈóúË≥áË®äÂíåÊåëÊà∞ÁöÑÊ¶ÇË¶ΩÔºå‰æÜÊîØÊè¥Â∞áÂèóÂΩ±ÈüøÁöÑÂà©ÂÆ≥Èóú‰øÇ‰∫∫Á¥çÂÖ•ÂèØËß£ÈáãÊÄß„ÄÇÊàëÂÄëÊúÄÂæåÁ∏ΩÁµêÊàëÂÄëÁöÑÁôºÁèæÔºåÂàóÂá∫ÂÖ≠È†ÖÈóúÈçµÂΩ±ÈüøÔºåÈÄô‰∫õÂΩ±ÈüøÊúÉÂëäÁü•Êú™‰æÜÈáùÂ∞çÂèóÂΩ±ÈüøÂà©ÂÆ≥Èóú‰øÇ‰∫∫ÂèóÁúæË™™ÊòéÁöÑË®≠Ë®à„ÄÇ</paragraph>

##### **Evaluating Large Language Models on the GMAT: Implications for the Future of Business Education**
2401.02985v1 by Vahid Ashrafimoghari, Necdet G√ºrkan, Jordan W. Suchow

The rapid evolution of artificial intelligence (AI), especially in the domain
of Large Language Models (LLMs) and generative AI, has opened new avenues for
application across various fields, yet its role in business education remains
underexplored. This study introduces the first benchmark to assess the
performance of seven major LLMs, OpenAI's models (GPT-3.5 Turbo, GPT-4, and
GPT-4 Turbo), Google's models (PaLM 2, Gemini 1.0 Pro), and Anthropic's models
(Claude 2 and Claude 2.1), on the GMAT, which is a key exam in the admission
process for graduate business programs. Our analysis shows that most LLMs
outperform human candidates, with GPT-4 Turbo not only outperforming the other
models but also surpassing the average scores of graduate students at top
business schools. Through a case study, this research examines GPT-4 Turbo's
ability to explain answers, evaluate responses, identify errors, tailor
instructions, and generate alternative scenarios. The latest LLM versions,
GPT-4 Turbo, Claude 2.1, and Gemini 1.0 Pro, show marked improvements in
reasoning tasks compared to their predecessors, underscoring their potential
for complex problem-solving. While AI's promise in education, assessment, and
tutoring is clear, challenges remain. Our study not only sheds light on LLMs'
academic potential but also emphasizes the need for careful development and
application of AI in education. As AI technology advances, it is imperative to
establish frameworks and protocols for AI interaction, verify the accuracy of
AI-generated content, ensure worldwide access for diverse learners, and create
an educational environment where AI supports human expertise. This research
sets the stage for further exploration into the responsible use of AI to enrich
educational experiences and improve exam preparation and assessment methods.

ÊëòË¶ÅÔºö‰∫∫Â∑•Êô∫ÊÖß (AI) ÁöÑÂø´ÈÄüÊºîÈÄ≤ÔºåÂ∞§ÂÖ∂ÊòØÂú®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂíåÁîüÊàêÂºè AI ÁöÑÈ†òÂüüÔºåÁÇ∫ÂêÑÂÄãÈ†òÂüüÁöÑÊáâÁî®ÈñãÂïü‰∫ÜÊñ∞ÈÄîÂæëÔºå‰ΩÜÂÖ∂Âú®ÂïÜÊ•≠ÊïôËÇ≤‰∏≠ÁöÑËßíËâ≤‰ªçÊú™Ë¢´ÂÖÖÂàÜÊé¢Ë®é„ÄÇÊú¨Á†îÁ©∂È¶ñÊ¨°ÂºïÂÖ•‰∫ÜÂü∫Ê∫ñÔºåÁî®‰ª•Ë©ï‰º∞‰∏ÉÂÄã‰∏ªË¶Å LLM ÁöÑÊïàËÉΩÔºåÂåÖÊã¨ OpenAI ÁöÑÊ®°Âûã (GPT-3.5 Turbo„ÄÅGPT-4 Âíå GPT-4 Turbo)„ÄÅGoogle ÁöÑÊ®°Âûã (PaLM 2„ÄÅGemini 1.0 Pro) Âíå Anthropic ÁöÑÊ®°Âûã (Claude 2 Âíå Claude 2.1)ÔºåÈÄô‰∫õÊ®°ÂûãÂ∞áÁî®ÊñºÁ†îÁ©∂ÁîüÂïÜÊ•≠Ë™≤Á®ãÂÖ•Â≠∏Á®ãÂ∫è‰∏≠ÁöÑÈóúÈçµËÄÉË©¶ GMAT„ÄÇÊàëÂÄëÁöÑÂàÜÊûêÈ°ØÁ§∫ÔºåÂ§ßÂ§öÊï∏ LLM ÁöÑË°®ÁèæÈÉΩÂÑ™Êñº‰∫∫È°ûËÄÉÁîüÔºåÂÖ∂‰∏≠ GPT-4 Turbo ‰∏çÂÉÖÂÑ™ÊñºÂÖ∂‰ªñÊ®°ÂûãÔºåÊõ¥Ë∂ÖË∂ä‰∫ÜÈ†ÇÂ∞ñÂïÜÂ≠∏Èô¢ÁöÑÁ†îÁ©∂ÁîüÂπ≥ÂùáÂàÜÊï∏„ÄÇÈÄèÈÅéÊ°à‰æãÁ†îÁ©∂ÔºåÊú¨Á†îÁ©∂Êé¢Ë®é‰∫Ü GPT-4 Turbo Âú®Ëß£ÈáãÁ≠îÊ°à„ÄÅË©ï‰º∞ÂõûÊáâ„ÄÅËæ®Ë≠òÈåØË™§„ÄÅË™øÊï¥Ë™™ÊòéÂíåÁî¢ÁîüÊõø‰ª£ÊÉÖÂ¢ÉÊñπÈù¢ÁöÑËÉΩÂäõ„ÄÇËàáÂâç‰∏Ä‰ª£ÁâàÊú¨Áõ∏ÊØîÔºåÊúÄÊñ∞ÁöÑ LLM ÁâàÊú¨ GPT-4 Turbo„ÄÅClaude 2.1 Âíå Gemini 1.0 Pro Âú®Êé®ÁêÜ‰ªªÂãôÊñπÈù¢ÊúâÈ°ØËëóÁöÑÈÄ≤Ê≠•ÔºåÂá∏È°Ø‰∫ÜÂÖ∂Âú®Ëß£Ê±∫Ë§áÈõúÂïèÈ°åÊñπÈù¢ÁöÑÊΩõÂäõ„ÄÇÂÑòÁÆ° AI Âú®ÊïôËÇ≤„ÄÅË©ïÈáèÂíåËºîÂ∞éÊñπÈù¢ÁöÑÊâøË´æÂæàÊòéÁ¢∫Ôºå‰ΩÜ‰ªçÊúâÊåëÊà∞Â≠òÂú®„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂‰∏çÂÉÖÈó°Êòé‰∫Ü LLM ÁöÑÂ≠∏Ë°ìÊΩõÂäõÔºå‰πüÂº∑Ë™ø‰∫ÜÂú®ÊïôËÇ≤‰∏≠ÂØ©ÊÖéÈñãÁôºÂíåÊáâÁî® AI ÁöÑÂøÖË¶ÅÊÄß„ÄÇÈö®Ëëó AI ÊäÄË°ìÁöÑÈÄ≤Ê≠•ÔºåÂª∫Á´ã AI ‰∫íÂãïÁöÑÊû∂ÊßãÂíåÂçîÂÆö„ÄÅÈ©óË≠â AI ÁîüÊàêÁöÑÂÖßÂÆπÁöÑÊ∫ñÁ¢∫ÊÄß„ÄÅÁ¢∫‰øùÂÖ®ÁêÉÂêÑÂú∞Â§öÂÖÉÂ≠∏ÁøíËÄÖÁöÑÂ≠òÂèñÊ¨äÔºå‰ª•ÂèäÂâµÈÄ†‰∏ÄÂÄã AI ÊîØÊåÅ‰∫∫È°ûÂ∞àÊ•≠Áü•Ë≠òÁöÑÊïôËÇ≤Áí∞Â¢ÉËá≥ÈóúÈáçË¶Å„ÄÇÊú¨Á†îÁ©∂ÁÇ∫ÈÄ≤‰∏ÄÊ≠•Êé¢Á¥¢Ë≤†Ë≤¨‰ªªÂú∞‰ΩøÁî® AI ‰æÜË±êÂØåÊïôËÇ≤È´îÈ©ó‰∏¶ÊîπÂñÑËÄÉË©¶Ê∫ñÂÇôÂíåË©ïÈáèÊñπÊ≥ïÂ•†ÂÆö‰∫ÜÂü∫Á§é„ÄÇ

##### **XAI for In-hospital Mortality Prediction via Multimodal ICU Data**
2312.17624v1 by Xingqiao Li, Jindong Gu, Zhiyong Wang, Yancheng Yuan, Bo Du, Fengxiang He

Predicting in-hospital mortality for intensive care unit (ICU) patients is
key to final clinical outcomes. AI has shown advantaged accuracy but suffers
from the lack of explainability. To address this issue, this paper proposes an
eXplainable Multimodal Mortality Predictor (X-MMP) approaching an efficient,
explainable AI solution for predicting in-hospital mortality via multimodal ICU
data. We employ multimodal learning in our framework, which can receive
heterogeneous inputs from clinical data and make decisions. Furthermore, we
introduce an explainable method, namely Layer-Wise Propagation to Transformer,
as a proper extension of the LRP method to Transformers, producing explanations
over multimodal inputs and revealing the salient features attributed to
prediction. Moreover, the contribution of each modality to clinical outcomes
can be visualized, assisting clinicians in understanding the reasoning behind
decision-making. We construct a multimodal dataset based on MIMIC-III and
MIMIC-III Waveform Database Matched Subset. Comprehensive experiments on
benchmark datasets demonstrate that our proposed framework can achieve
reasonable interpretation with competitive prediction accuracy. In particular,
our framework can be easily transferred to other clinical tasks, which
facilitates the discovery of crucial factors in healthcare research.

ÊëòË¶ÅÔºöÈ†êÊ∏¨Âä†Ë≠∑ÁóÖÊàø (ICU) ÁóÖÊÇ£ÁöÑÈô¢ÂÖßÊ≠ª‰∫°ÁéáÊòØÊúÄÁµÇËá®Â∫äÁµêÊûúÁöÑÈóúÈçµ„ÄÇAI Â∑≤Â±ïÁèæÂá∫ÂÑ™Áï∞ÁöÑÊ∫ñÁ¢∫Â∫¶Ôºå‰ΩÜÂçªÁº∫‰πèÂèØËß£ÈáãÊÄß„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂèØËß£ÈáãÁöÑÂ§öÊ®°ÂºèÊ≠ª‰∫°ÁéáÈ†êÊ∏¨Âô® (X-MMP)ÔºåÊé°Áî®ÊúâÊïà‰∏îÂèØËß£ÈáãÁöÑ AI ÊñπÂºèÔºåËóâÁî±Â§öÊ®°Âºè ICU Ë≥áÊñô‰æÜÈ†êÊ∏¨Èô¢ÂÖßÊ≠ª‰∫°Áéá„ÄÇÊàëÂÄëÂú®Êû∂Êßã‰∏≠Êé°Áî®Â§öÊ®°ÂºèÂ≠∏ÁøíÔºåÂèØ‰ª•Êé•Êî∂‰æÜËá™Ëá®Â∫äË≥áÊñôÁöÑÁï∞Ë≥™Ëº∏ÂÖ•‰∏¶ÂÅöÂá∫Ê±∫Á≠ñ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÂèØËß£ÈáãÁöÑÊñπÊ≥ïÔºå‰πüÂ∞±ÊòØÂàÜÂ±§ÂÇ≥Êí≠Ëá≥ TransformerÔºå‰ΩúÁÇ∫ LRP ÊñπÊ≥ïÈÅ©Áï∂Âú∞Âª∂‰º∏Ëá≥ TransformerÔºåÂ∞çÂ§öÊ®°ÂºèËº∏ÂÖ•Áî¢ÁîüËß£ÈáãÔºå‰∏¶Êè≠Èú≤Ê≠∏Âõ†ÊñºÈ†êÊ∏¨ÁöÑÈ°ØËëóÁâπÂæµ„ÄÇÊ≠§Â§ñÔºåÊØèÂÄãÊ®°ÂºèÂ∞çËá®Â∫äÁµêÊûúÁöÑË≤¢ÁçªÂèØ‰ª•Ë¶ñË¶∫ÂåñÔºåÂçîÂä©Ëá®Â∫äÈÜ´Â∏´‰∫ÜËß£Ê±∫Á≠ñËÉåÂæåÁöÑÁêÜÁî±„ÄÇÊàëÂÄëÊ†πÊìö MIMIC-III Âíå MIMIC-III Ê≥¢ÂΩ¢Ë≥áÊñôÂ∫´ÊØîÂ∞çÂ≠êÈõÜÂª∫Êßã‰∫Ü‰∏ÄÂÄãÂ§öÊ®°ÂºèË≥áÊñôÈõÜ„ÄÇÂú®Âü∫Ê∫ñË≥áÊñôÈõÜ‰∏äÁöÑÂÖ®Èù¢ÂØ¶È©óË≠âÊòéÔºåÊàëÂÄëÊèêÂá∫ÁöÑÊû∂ÊßãÂèØ‰ª•ÈÅîÊàêÂêàÁêÜÁöÑË©ÆÈáãÔºå‰∏¶ÂÖ∑ÂÇôÁ´∂Áà≠ÂäõÁöÑÈ†êÊ∏¨Ê∫ñÁ¢∫Â∫¶„ÄÇÁâπÂà•ÊòØÔºåÊàëÂÄëÁöÑÊû∂ÊßãÂèØ‰ª•ËºïÈ¨ÜÂú∞ËΩâÁßªÂà∞ÂÖ∂‰ªñËá®Â∫ä‰ªªÂãôÔºåÈÄôÊúâÂä©ÊñºÂú®ÈÜ´ÁôÇ‰øùÂÅ•Á†îÁ©∂‰∏≠ÁôºÁèæÈóúÈçµÂõ†Á¥†„ÄÇ

##### **Joining Forces for Pathology Diagnostics with AI Assistance: The EMPAIA Initiative**
2401.09450v2 by Norman Zerbe, Lars Ole Schwen, Christian Gei√üler, Katja Wiesemann, Tom Bisson, Peter Boor, Rita Carvalho, Michael Franz, Christoph Jansen, Tim-Rasmus Kiehl, Bj√∂rn Lindequist, Nora Charlotte Pohlan, Sarah Schmell, Klaus Strohmenger, Falk Zakrzewski, Markus Plass, Michael Takla, Tobias K√ºster, Andr√© Homeyer, Peter Hufnagl

Over the past decade, artificial intelligence (AI) methods in pathology have
advanced substantially. However, integration into routine clinical practice has
been slow due to numerous challenges, including technical and regulatory
hurdles in translating research results into clinical diagnostic products and
the lack of standardized interfaces. The open and vendor-neutral EMPAIA
initiative addresses these challenges. Here, we provide an overview of EMPAIA's
achievements and lessons learned. EMPAIA integrates various stakeholders of the
pathology AI ecosystem, i.e., pathologists, computer scientists, and industry.
In close collaboration, we developed technical interoperability standards,
recommendations for AI testing and product development, and explainability
methods. We implemented the modular and open-source EMPAIA platform and
successfully integrated 14 AI-based image analysis apps from 8 different
vendors, demonstrating how different apps can use a single standardized
interface. We prioritized requirements and evaluated the use of AI in real
clinical settings with 14 different pathology laboratories in Europe and Asia.
In addition to technical developments, we created a forum for all stakeholders
to share information and experiences on digital pathology and AI. Commercial,
clinical, and academic stakeholders can now adopt EMPAIA's common open-source
interfaces, providing a unique opportunity for large-scale standardization and
streamlining of processes. Further efforts are needed to effectively and
broadly establish AI assistance in routine laboratory use. To this end, a
sustainable infrastructure, the non-profit association EMPAIA International,
has been established to continue standardization and support broad
implementation and advocacy for an AI-assisted digital pathology future.

ÊëòË¶ÅÔºöÂú®ÈÅéÂéªÁöÑÂçÅÂπ¥‰∏≠ÔºåÁóÖÁêÜÂ≠∏‰∏≠ÁöÑ‰∫∫Â∑•Êô∫ÊÖß (AI) ÊñπÊ≥ïÂ∑≤Â§ßÂπÖÈÄ≤Ê≠•„ÄÇÁÑ∂ËÄåÔºåÁî±ÊñºË®±Â§öÊåëÊà∞ÔºåÂåÖÊã¨Â∞áÁ†îÁ©∂ÁµêÊûúËΩâÂåñÁÇ∫Ëá®Â∫äË®∫Êñ∑Áî¢ÂìÅÂú®ÊäÄË°ìÂíåÊ≥ïË¶èÊñπÈù¢ÁöÑÈöúÁ§ôÔºå‰ª•ÂèäÁº∫‰πèÊ®ôÊ∫ñÂåñ‰ªãÈù¢ÔºåÂ∞éËá¥Êï¥ÂêàÂà∞Â∏∏Ë¶èËá®Â∫äÂØ¶Âãô‰∏≠ÈÄ≤Â±ïÁ∑©ÊÖ¢„ÄÇÈñãÊîæ‰∏îËàá‰æõÊáâÂïÜÁÑ°ÈóúÁöÑ EMPAIA Ë®àÁï´ÊáâÂ∞ç‰∫ÜÈÄô‰∫õÊåëÊà∞„ÄÇÂú®Ê≠§ÔºåÊàëÂÄëÊèê‰æõ EMPAIA ÁöÑÊàêÂ∞±ÂíåÁ∂ìÈ©óÊïôË®ìÁöÑÊ¶ÇËø∞„ÄÇEMPAIA Êï¥Âêà‰∫ÜÁóÖÁêÜÂ≠∏ AI ÁîüÊÖãÁ≥ªÁµ±ÁöÑÂêÑÂÄãÂà©ÂÆ≥Èóú‰øÇ‰∫∫ÔºåÂç≥ÁóÖÁêÜÂ≠∏ÂÆ∂„ÄÅÈõªËÖ¶ÁßëÂ≠∏ÂÆ∂ÂíåÁî¢Ê•≠„ÄÇÂú®ÂØÜÂàáÂêà‰Ωú‰∏ãÔºåÊàëÂÄëÂà∂ÂÆö‰∫ÜÊäÄË°ì‰∫íÈÄöÊÄßÊ®ôÊ∫ñ„ÄÅAI Ê∏¨Ë©¶ÂíåÁî¢ÂìÅÈñãÁôºÂª∫Ë≠∞Ôºå‰ª•ÂèäÂèØËß£ÈáãÊÄßÊñπÊ≥ï„ÄÇÊàëÂÄëÂØ¶‰Ωú‰∫ÜÊ®°ÁµÑÂåñ‰∏îÈñãÊîæÂéüÂßãÁ¢ºÁöÑ EMPAIA Âπ≥Ëá∫Ôºå‰∏¶ÊàêÂäüÊï¥Âêà‰∫Ü‰æÜËá™ 8 ÂÄã‰∏çÂêå‰æõÊáâÂïÜÁöÑ 14 ÂÄãÂü∫Êñº AI ÁöÑÂΩ±ÂÉèÂàÜÊûêÊáâÁî®Á®ãÂºèÔºåÂ±ïÁ§∫‰∫Ü‰∏çÂêåÁöÑÊáâÁî®Á®ãÂºèÂ¶Ç‰Ωï‰ΩøÁî®ÂñÆ‰∏ÄÁöÑÊ®ôÊ∫ñÂåñ‰ªãÈù¢„ÄÇÊàëÂÄëÂÑ™ÂÖàËÄÉÊÖÆÈúÄÊ±ÇÔºå‰∏¶Ë©ï‰º∞‰∫Ü AI Âú®Ê≠êÊ¥≤Âíå‰∫ûÊ¥≤ÁöÑ 14 ÂÄã‰∏çÂêåÁóÖÁêÜÂØ¶È©óÂÆ§‰∏≠ÁöÑÂØ¶ÈöõËá®Â∫äÊáâÁî®„ÄÇÈô§‰∫ÜÊäÄË°ìÈñãÁôºÂ§ñÔºåÊàëÂÄëÈÇÑÁÇ∫ÊâÄÊúâÂà©ÂÆ≥Èóú‰øÇ‰∫∫Âª∫Á´ã‰∫Ü‰∏ÄÂÄãË´ñÂ£áÔºå‰ª•ÂàÜ‰∫´Êï∏‰ΩçÁóÖÁêÜÂ≠∏Âíå AI ÁöÑË≥áË®äÂíåÁ∂ìÈ©ó„ÄÇÂïÜÊ•≠„ÄÅËá®Â∫äÂíåÂ≠∏Ë°ìÂà©ÂÆ≥Èóú‰øÇ‰∫∫ÁèæÂú®ÂèØ‰ª•Êé°Áî® EMPAIA ÁöÑÂ∏∏Ë¶ãÈñãÊîæÂéüÂßãÁ¢º‰ªãÈù¢ÔºåÈÄôÁÇ∫Â§ßË¶èÊ®°Ê®ôÊ∫ñÂåñÂíåÁ∞°ÂåñÊµÅÁ®ãÊèê‰æõ‰∫ÜÁç®ÁâπÁöÑÊ©üÊúÉ„ÄÇÈúÄË¶ÅÈÄ≤‰∏ÄÊ≠•ÁöÑÂä™ÂäõÊâçËÉΩÊúâÊïà‰∏îÂª£Ê≥õÂú∞Âª∫Á´ã‰æãË°åÂØ¶È©óÂÆ§‰ΩøÁî®‰∏≠ÁöÑ AI ËºîÂä©„ÄÇÁÇ∫Ê≠§ÔºåÂ∑≤ÊàêÁ´ãÈùûÁáüÂà©ÂçîÊúÉ EMPAIA InternationalÔºå‰ª•‰ΩúÁÇ∫Ê∞∏Á∫åÂü∫Á§éÊû∂ÊßãÔºåÁπºÁ∫åÈÄ≤Ë°åÊ®ôÊ∫ñÂåñÔºå‰∏¶ÊîØÊè¥Âª£Ê≥õÂØ¶‰ΩúÂíåÂÄ°Â∞é AI ËºîÂä©Êï∏‰ΩçÁóÖÁêÜÂ≠∏ÁöÑÊú™‰æÜ„ÄÇ

##### **Robust Stochastic Graph Generator for Counterfactual Explanations**
2312.11747v2 by Mario Alfonso Prado-Romero, Bardh Prenkaj, Giovanni Stilo

Counterfactual Explanation (CE) techniques have garnered attention as a means
to provide insights to the users engaging with AI systems. While extensively
researched in domains such as medical imaging and autonomous vehicles, Graph
Counterfactual Explanation (GCE) methods have been comparatively
under-explored. GCEs generate a new graph similar to the original one, with a
different outcome grounded on the underlying predictive model. Among these GCE
techniques, those rooted in generative mechanisms have received relatively
limited investigation despite demonstrating impressive accomplishments in other
domains, such as artistic styles and natural language modelling. The preference
for generative explainers stems from their capacity to generate counterfactual
instances during inference, leveraging autonomously acquired perturbations of
the input graph. Motivated by the rationales above, our study introduces
RSGG-CE, a novel Robust Stochastic Graph Generator for Counterfactual
Explanations able to produce counterfactual examples from the learned latent
space considering a partially ordered generation sequence. Furthermore, we
undertake quantitative and qualitative analyses to compare RSGG-CE's
performance against SoA generative explainers, highlighting its increased
ability to engendering plausible counterfactual candidates.

ÊëòË¶ÅÔºöÂèç‰∫ãÂØ¶Ëß£Èáã (CE) ÊäÄË°ìÂ∑≤ÂºïËµ∑ÈóúÊ≥®Ôºå‰ΩúÁÇ∫‰∏ÄÁ®ÆÁÇ∫Ëàá AI Á≥ªÁµ±‰∫íÂãïÁöÑ‰ΩøÁî®ËÄÖÊèê‰æõË¶ãËß£ÁöÑÊñπÊ≥ï„ÄÇÈõñÁÑ∂Âú®ÈÜ´Â≠∏ÂΩ±ÂÉèÂíåËá™ÂãïÈßïÈßõÊ±ΩËªäÁ≠âÈ†òÂüüÂª£Ê≥õÁ†îÁ©∂ÔºåÂúñÂΩ¢Âèç‰∫ãÂØ¶Ëß£Èáã (GCE) ÊñπÊ≥ïÁõ∏Â∞çËºÉÂ∞ëË¢´Êé¢Á¥¢„ÄÇGCE ÊúÉÁî¢Áîü‰∏ÄÂÄãÈ°û‰ººÊñºÂéüÂßãÂúñÂΩ¢ÁöÑÊñ∞ÂúñÂΩ¢Ôºå‰∏¶Ê†πÊìöÂü∫Á§éÈ†êÊ∏¨Ê®°ÂûãÁî¢Áîü‰∏çÂêåÁöÑÁµêÊûú„ÄÇÂú®ÈÄô‰∫õ GCE ÊäÄË°ì‰∏≠ÔºåÂÑòÁÆ°Âú®ÂÖ∂‰ªñÈ†òÂüüÔºà‰æãÂ¶ÇËóùË°ìÈ¢®Ê†ºÂíåËá™ÁÑ∂Ë™ûË®ÄÂª∫Ê®°Ôºâ‰∏≠Â±ïÁèæÂá∫‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑÊàêÂ∞±Ôºå‰ΩÜÊ§çÂü∫ÊñºÁîüÊàêÊ©üÂà∂ÁöÑÊäÄË°ìÁç≤ÂæóÁöÑÈóúÊ≥®Áõ∏Â∞çÊúâÈôê„ÄÇÂ∞çÁîüÊàêÂºèËß£ÈáãÂô®ÁöÑÂÅèÂ•ΩÊ∫êÊñºÂÆÉÂÄëÂú®Êé®ÁêÜÊúüÈñìÁî¢ÁîüÂèç‰∫ãÂØ¶ÂØ¶‰æãÁöÑËÉΩÂäõÔºåÂà©Áî®Ëº∏ÂÖ•ÂúñÂΩ¢ÁöÑËá™‰∏ªÁç≤ÂèñÊìæÂãï„ÄÇÂü∫Êñº‰∏äËø∞ÁêÜÁî±ÔºåÊàëÂÄëÁöÑÁ†îÁ©∂ÂºïÂÖ•‰∫Ü RSGG-CEÔºå‰∏ÄÁ®ÆÁî®ÊñºÂèç‰∫ãÂØ¶Ëß£ÈáãÁöÑÊñ∞ÂûãÁ©©ÂÅ•Èö®Ê©üÂúñÂΩ¢ÁîüÊàêÂô®ÔºåËÉΩÂ§†ÂæûÂ≠∏ÁøíÂà∞ÁöÑÊΩõÂú®Á©∫Èñì‰∏≠Áî¢ÁîüÂèç‰∫ãÂØ¶ÁØÑ‰æãÔºåËÄÉÊÖÆÈÉ®ÂàÜÊúâÂ∫èÁöÑÁîüÊàêÂ∫èÂàó„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÈÄ≤Ë°åÂÆöÈáèÂíåÂÆöÊÄßÂàÜÊûêÔºå‰ª•ÊØîËºÉ RSGG-CE ÁöÑÊïàËÉΩËàá SoA ÁîüÊàêÂºèËß£ÈáãÂô®ÔºåÂº∑Ë™øÂÖ∂Â¢ûÂº∑‰∫ÜÁî¢ÁîüÂêàÁêÜËß£ÈáãÂÄôÈÅ∏ÁöÑËÉΩÂäõ„ÄÇ

##### **Evaluating the Utility of Model Explanations for Model Development**
2312.06032v1 by Shawn Im, Jacob Andreas, Yilun Zhou

One of the motivations for explainable AI is to allow humans to make better
and more informed decisions regarding the use and deployment of AI models. But
careful evaluations are needed to assess whether this expectation has been
fulfilled. Current evaluations mainly focus on algorithmic properties of
explanations, and those that involve human subjects often employ subjective
questions to test human's perception of explanation usefulness, without being
grounded in objective metrics and measurements. In this work, we evaluate
whether explanations can improve human decision-making in practical scenarios
of machine learning model development. We conduct a mixed-methods user study
involving image data to evaluate saliency maps generated by SmoothGrad,
GradCAM, and an oracle explanation on two tasks: model selection and
counterfactual simulation. To our surprise, we did not find evidence of
significant improvement on these tasks when users were provided with any of the
saliency maps, even the synthetic oracle explanation designed to be simple to
understand and highly indicative of the answer. Nonetheless, explanations did
help users more accurately describe the models. These findings suggest caution
regarding the usefulness and potential for misunderstanding in saliency-based
explanations.

ÊëòË¶ÅÔºöÂèØËß£Èáã AI ÁöÑÂãïÊ©ü‰πã‰∏ÄÊòØËÆì‰∫∫ÂÄëÂú®‰ΩøÁî®ÂíåÈÉ®ÁΩ≤ AI Ê®°ÂûãÊôÇÂÅöÂá∫Êõ¥Â•Ω„ÄÅÊõ¥ÊòéÊô∫ÁöÑÊ±∫Á≠ñ„ÄÇ‰ΩÜÈúÄË¶Å‰ªîÁ¥∞Ë©ï‰º∞‰ª•Ë©ï‰º∞ÊòØÂê¶Â∑≤ÈÅîÂà∞Ê≠§È†êÊúü„ÄÇÁõÆÂâçÁöÑË©ï‰º∞‰∏ªË¶ÅÈõÜ‰∏≠Âú®Ëß£ÈáãÁöÑÊºîÁÆóÊ≥ïÁâπÊÄßÔºåËÄåÊ∂âÂèä‰∫∫È°ûÂèóË©¶ËÄÖÁöÑË©ï‰º∞ÈÄöÂ∏∏Êé°Áî®‰∏ªËßÄÂïèÈ°å‰æÜÊ∏¨Ë©¶‰∫∫È°ûÂ∞çËß£ÈáãÊúâÁî®ÊÄßÁöÑÁúãÊ≥ïÔºåËÄåÊ≤íÊúâÂü∫ÊñºÂÆ¢ËßÄÊåáÊ®ôÂíåÊ∏¨Èáè„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëË©ï‰º∞Ëß£ÈáãÊòØÂê¶ÂèØ‰ª•Âú®Ê©üÂô®Â≠∏ÁøíÊ®°ÂûãÈñãÁôºÁöÑÂØ¶ÈöõÂ†¥ÊôØ‰∏≠ÊîπÂñÑ‰∫∫È°ûÊ±∫Á≠ñÂà∂ÂÆö„ÄÇÊàëÂÄëÈÄ≤Ë°å‰∫Ü‰∏ÄÈ†ÖÊ∂âÂèäÂΩ±ÂÉèË≥áÊñôÁöÑÊ∑∑ÂêàÊñπÊ≥ï‰ΩøÁî®ËÄÖÁ†îÁ©∂Ôºå‰ª•Ë©ï‰º∞ SmoothGrad„ÄÅGradCAM ÂíåÈ†êË®ÄËß£ÈáãÂú®ÂÖ©ÂÄã‰ªªÂãô‰∏≠Áî¢ÁîüÁöÑÈ°ØËëóÊÄßÂúñÔºöÊ®°ÂûãÈÅ∏ÊìáÂíåÂèç‰∫ãÂØ¶Ê®°Êì¨„ÄÇ‰ª§‰∫∫È©öË®ùÁöÑÊòØÔºåÊàëÂÄëÊ≤íÊúâÁôºÁèæ‰ªª‰ΩïÈ°ØËëóÊÄßÂúñÔºàÂç≥‰ΩøÊòØË®≠Ë®àÁÇ∫ÊòìÊñºÁêÜËß£‰∏îÈ´òÂ∫¶ÊåáÁ§∫Á≠îÊ°àÁöÑÂêàÊàêÈ†êË®ÄËß£ÈáãÔºâËÉΩËÆì‰ΩøÁî®ËÄÖÂú®ÈÄô‰∫õ‰ªªÂãô‰∏äÈ°ØËëóÊîπÂñÑÁöÑË≠âÊìö„ÄÇÂÑòÁÆ°Â¶ÇÊ≠§ÔºåËß£ÈáãÁ¢∫ÂØ¶ÊúâÂä©Êñº‰ΩøÁî®ËÄÖÊõ¥Ê∫ñÁ¢∫Âú∞ÊèèËø∞Ê®°Âûã„ÄÇÈÄô‰∫õÁôºÁèæÊèêÁ§∫ÊàëÂÄëË¶ÅÂ∞çÂü∫ÊñºÈ°ØËëóÊÄßÁöÑËß£Èáã‰∏≠ÂèØËÉΩÂ≠òÂú®Ë™§Ëß£ÁöÑÊúâÁî®ÊÄß‰øùÊåÅË¨πÊÖé„ÄÇ

##### **Building Trustworthy NeuroSymbolic AI Systems: Consistency, Reliability, Explainability, and Safety**
2312.06798v1 by Manas Gaur, Amit Sheth

Explainability and Safety engender Trust. These require a model to exhibit
consistency and reliability. To achieve these, it is necessary to use and
analyze data and knowledge with statistical and symbolic AI methods relevant to
the AI application - neither alone will do. Consequently, we argue and seek to
demonstrate that the NeuroSymbolic AI approach is better suited for making AI a
trusted AI system. We present the CREST framework that shows how Consistency,
Reliability, user-level Explainability, and Safety are built on NeuroSymbolic
methods that use data and knowledge to support requirements for critical
applications such as health and well-being. This article focuses on Large
Language Models (LLMs) as the chosen AI system within the CREST framework. LLMs
have garnered substantial attention from researchers due to their versatility
in handling a broad array of natural language processing (NLP) scenarios. For
example, ChatGPT and Google's MedPaLM have emerged as highly promising
platforms for providing information in general and health-related queries,
respectively. Nevertheless, these models remain black boxes despite
incorporating human feedback and instruction-guided tuning. For instance,
ChatGPT can generate unsafe responses despite instituting safety guardrails.
CREST presents a plausible approach harnessing procedural and graph-based
knowledge within a NeuroSymbolic framework to shed light on the challenges
associated with LLMs.

ÊëòË¶ÅÔºöÂèØËß£ÈáãÊÄßÂíåÂÆâÂÖ®ÊÄßÂª∫Á´ã‰ø°‰ªª„ÄÇÈÄô‰∫õÈúÄË¶Å‰∏ÄÂÄãÊ®°Âûã‰æÜÂ±ïÁ§∫‰∏ÄËá¥ÊÄßÂíåÂèØÈù†ÊÄß„ÄÇÁÇ∫‰∫ÜÂØ¶ÁèæÈÄô‰∫õÔºåÊúâÂøÖË¶Å‰ΩøÁî®ÂíåÂàÜÊûêÊï∏ÊìöÂíåÁü•Ë≠òÔºå‰∏¶‰ΩøÁî®Ëàá AI ÊáâÁî®Áõ∏ÈóúÁöÑÁµ±Ë®àÂíåÁ¨¶Ëôü AI ÊñπÊ≥ï - ÂñÆÁç®‰ΩøÁî®‰ªª‰Ωï‰∏ÄÁ®ÆÊñπÊ≥ïÈÉΩ‰∏çÊúÉÂ•èÊïà„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄë‰∏ªÂºµ‰∏¶Ë©¶ÂúñË≠âÊòé NeuroSymbolic AI ÊñπÊ≥ïÊõ¥ÈÅ©ÂêàÊñº‰Ωø AI ÊàêÁÇ∫Âèó‰ø°‰ªªÁöÑ AI Á≥ªÁµ±„ÄÇÊàëÂÄëÊèêÂá∫‰∫Ü CREST Ê°ÜÊû∂ÔºåÂ±ïÁ§∫‰∫Ü‰∏ÄËá¥ÊÄß„ÄÅÂèØÈù†ÊÄß„ÄÅ‰ΩøÁî®ËÄÖÂ±§Á¥öÁöÑÂèØËß£ÈáãÊÄßÂíåÂÆâÂÖ®ÊÄßÊòØÂ¶Ç‰ΩïÂª∫Á´ãÂú® NeuroSymbolic ÊñπÊ≥ï‰∏äÁöÑÔºåË©≤ÊñπÊ≥ï‰ΩøÁî®Êï∏ÊìöÂíåÁü•Ë≠ò‰æÜÊîØÊåÅÈóúÈçµÊáâÁî®Ôºà‰æãÂ¶ÇÂÅ•Â∫∑ÂíåÁ¶èÁ•âÔºâÁöÑË¶ÅÊ±Ç„ÄÇÊú¨ÊñáÈáçÈªûÈóúÊ≥®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM)ÔºåÂõ†ÁÇ∫ÂÆÉÊòØ CREST Ê°ÜÊû∂‰∏≠ÈÅ∏ÊìáÁöÑ AI Á≥ªÁµ±„ÄÇLLM Âõ†ÂÖ∂Âú®ËôïÁêÜÂª£Ê≥õÁöÑËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ (NLP) Â†¥ÊôØÊñπÈù¢ÁöÑÂ§öÂäüËÉΩÊÄßËÄåÂÇôÂèóÁ†îÁ©∂‰∫∫Âì°ÁöÑÈóúÊ≥®„ÄÇ‰æãÂ¶ÇÔºåChatGPT Âíå Google ÁöÑ MedPaLM Â∑≤ÊàêÁÇ∫Êèê‰æõ‰∏ÄËà¨ÂíåÂÅ•Â∫∑Áõ∏ÈóúÊü•Ë©¢‰ø°ÊÅØÁöÑÊ•µÊúâÂ∏åÊúõÁöÑÂπ≥Âè∞„ÄÇÂÑòÁÆ°Â¶ÇÊ≠§ÔºåÈÄô‰∫õÊ®°Âûã‰ªçÁÑ∂ÊòØÈªëÁõíÂ≠êÔºåÂÑòÁÆ°Á¥çÂÖ•‰∫Ü‰∫∫È°ûÂèçÈ•ãÂíåÊåá‰ª§ÂºïÂ∞éÁöÑË™øÊï¥„ÄÇ‰æãÂ¶ÇÔºåÂÑòÁÆ°Âà∂ÂÆö‰∫ÜÂÆâÂÖ®Èò≤Ë≠∑Êé™ÊñΩÔºåChatGPT ‰ªçÂèØËÉΩÁî¢Áîü‰∏çÂÆâÂÖ®ÁöÑÂõûÊáâ„ÄÇCREST ÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂêàÁêÜÁöÑÊñπÊ≥ïÔºåÂú® NeuroSymbolic Ê°ÜÊû∂‰∏≠Âà©Áî®Á®ãÂ∫èÂíåÂü∫ÊñºÂúñË°®ÁöÑÁü•Ë≠òÔºå‰ª•Èó°ÊòéËàá LLM Áõ∏ÈóúÁöÑÊåëÊà∞„ÄÇ

##### **Deployment of a Robust and Explainable Mortality Prediction Model: The COVID-19 Pandemic and Beyond**
2311.17133v1 by Jacob R. Epifano, Stephen Glass, Ravi P. Ramachandran, Sharad Patel, Aaron J. Masino, Ghulam Rasool

This study investigated the performance, explainability, and robustness of
deployed artificial intelligence (AI) models in predicting mortality during the
COVID-19 pandemic and beyond. The first study of its kind, we found that
Bayesian Neural Networks (BNNs) and intelligent training techniques allowed our
models to maintain performance amidst significant data shifts. Our results
emphasize the importance of developing robust AI models capable of matching or
surpassing clinician predictions, even under challenging conditions. Our
exploration of model explainability revealed that stochastic models generate
more diverse and personalized explanations thereby highlighting the need for AI
models that provide detailed and individualized insights in real-world clinical
settings. Furthermore, we underscored the importance of quantifying uncertainty
in AI models which enables clinicians to make better-informed decisions based
on reliable predictions. Our study advocates for prioritizing implementation
science in AI research for healthcare and ensuring that AI solutions are
practical, beneficial, and sustainable in real-world clinical environments. By
addressing unique challenges and complexities in healthcare settings,
researchers can develop AI models that effectively improve clinical practice
and patient outcomes.

ÊëòË¶ÅÔºöÊú¨Á†îÁ©∂Ë∞ÉÊü•‰∫ÜÂú® COVID-19 Áñ´ÊÉÖÊúüÈó¥Âèä‰ª•ÂêéÈ¢ÑÊµãÊ≠ª‰∫°ÁéáÊó∂ÔºåÂ∑≤ÈÉ®ÁΩ≤‰∫∫Â∑•Êô∫ËÉΩ (AI) Ê®°ÂûãÁöÑÊÄßËÉΩ„ÄÅÂèØËß£ÈáäÊÄßÂíåÁ®≥ÂÅ•ÊÄß„ÄÇ‰Ωú‰∏∫ÂêåÁ±ªÁ†îÁ©∂‰∏≠ÁöÑÈ¶ñ‰æãÔºåÊàë‰ª¨ÂèëÁé∞Ë¥ùÂè∂ÊñØÁ•ûÁªèÁΩëÁªú (BNN) ÂíåÊô∫ËÉΩËÆ≠ÁªÉÊäÄÊúØËÆ©Êàë‰ª¨ÁöÑÊ®°ÂûãÂú®Êï∞ÊçÆÂèëÁîüÈáçÂ§ßÂèòÂåñÊó∂‰ªçËÉΩ‰øùÊåÅÊÄßËÉΩ„ÄÇÊàë‰ª¨ÁöÑÁªìÊûúÂº∫Ë∞É‰∫ÜÂºÄÂèëÁ®≥ÂÅ•ÁöÑ AI Ê®°ÂûãÁöÑÈáçË¶ÅÊÄßÔºåÂç≥‰ΩøÂú®ÂÖ∑ÊúâÊåëÊàòÊÄßÁöÑÊù°‰ª∂‰∏ãÔºåËøô‰∫õÊ®°Âûã‰πüËÉΩÂåπÈÖçÊàñË∂ÖË∂ä‰∏¥Â∫äÂåªÁîüÁöÑÈ¢ÑÊµã„ÄÇÊàë‰ª¨ÂØπÊ®°ÂûãÂèØËß£ÈáäÊÄßÁöÑÊé¢Á¥¢Ë°®ÊòéÔºåÈöèÊú∫Ê®°Âûã‰ºö‰∫ßÁîüÊõ¥Â§öÊ†∑Âåñ‰∏î‰∏™ÊÄßÂåñÁöÑËß£ÈáäÔºå‰ªéËÄåÁ™ÅÂá∫‰∫ÜÂú®Áé∞ÂÆû‰∏ñÁïåÁöÑ‰∏¥Â∫äÁéØÂ¢É‰∏≠Êèê‰æõËØ¶ÁªÜ‰∏î‰∏™ÊÄßÂåñËßÅËß£ÁöÑ AI Ê®°ÂûãÁöÑÂøÖË¶ÅÊÄß„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨Âº∫Ë∞É‰∫ÜÈáèÂåñ AI Ê®°Âûã‰∏≠‰∏çÁ°ÆÂÆöÊÄßÁöÑÈáçË¶ÅÊÄßÔºåËøô‰Ωø‰∏¥Â∫äÂåªÁîüËÉΩÂ§üÊ†πÊçÆÂèØÈù†ÁöÑÈ¢ÑÊµãÂÅöÂá∫Êõ¥ÊòéÊô∫ÁöÑÂÜ≥Á≠ñ„ÄÇÊàë‰ª¨ÁöÑÁ†îÁ©∂ÊèêÂÄ°Âú®ÂåªÁñó‰øùÂÅ•ÁöÑ AI Á†îÁ©∂‰∏≠‰ºòÂÖàËÄÉËôëÂÆûÊñΩÁßëÂ≠¶ÔºåÂπ∂Á°Æ‰øù AI Ëß£ÂÜ≥ÊñπÊ°àÂú®Áé∞ÂÆû‰∏ñÁïåÁöÑ‰∏¥Â∫äÁéØÂ¢É‰∏≠ÂÆûÁî®„ÄÅÊúâÁõä‰∏îÂèØÊåÅÁª≠„ÄÇÈÄöËøáËß£ÂÜ≥ÂåªÁñó‰øùÂÅ•ÁéØÂ¢É‰∏≠ÁöÑÁã¨ÁâπÊåëÊàòÂíåÂ§çÊùÇÊÄßÔºåÁ†îÁ©∂‰∫∫ÂëòÂèØ‰ª•ÂºÄÂèëÂá∫ÊúâÊïàÊîπÂñÑ‰∏¥Â∫äÂÆûË∑µÂíåÊÇ£ËÄÖÈ¢ÑÂêéÁöÑ AI Ê®°Âûã„ÄÇ

##### **Variational Autoencoders for Feature Exploration and Malignancy Prediction of Lung Lesions**
2311.15719v1 by Benjamin Keel, Aaron Quyn, David Jayne, Samuel D. Relton

Lung cancer is responsible for 21% of cancer deaths in the UK and five-year
survival rates are heavily influenced by the stage the cancer was identified
at. Recent studies have demonstrated the capability of AI methods for accurate
and early diagnosis of lung cancer from routine scans. However, this evidence
has not translated into clinical practice with one barrier being a lack of
interpretable models. This study investigates the application Variational
Autoencoders (VAEs), a type of generative AI model, to lung cancer lesions.
Proposed models were trained on lesions extracted from 3D CT scans in the
LIDC-IDRI public dataset. Latent vector representations of 2D slices produced
by the VAEs were explored through clustering to justify their quality and used
in an MLP classifier model for lung cancer diagnosis, the best model achieved
state-of-the-art metrics of AUC 0.98 and 93.1% accuracy. Cluster analysis shows
the VAE latent space separates the dataset of malignant and benign lesions
based on meaningful feature components including tumour size, shape, patient
and malignancy class. We also include a comparative analysis of the standard
Gaussian VAE (GVAE) and the more recent Dirichlet VAE (DirVAE), which replaces
the prior with a Dirichlet distribution to encourage a more explainable latent
space with disentangled feature representation. Finally, we demonstrate the
potential for latent space traversals corresponding to clinically meaningful
feature changes.

ÊëòË¶ÅÔºöËÇ∫ÁôåÂç†Ëã±ÂúãÁôåÁóáÊ≠ª‰∫°‰∫∫Êï∏ÁöÑ 21%Ôºå‰∫îÂπ¥Â≠òÊ¥ªÁéáÂæàÂ§ßÁ®ãÂ∫¶ÂèñÊ±∫ÊñºÁôåÁóáË¢´ÁôºÁèæÁöÑÈöéÊÆµ„ÄÇÊúÄËøëÁöÑÁ†îÁ©∂Â∑≤Ë≠âÊòé‰∫∫Â∑•Êô∫ËÉΩÊñπÊ≥ïÂÖ∑ÊúâÂæû‰æãË°åÊéÉÊèè‰∏≠Ê∫ñÁ¢∫ÂèäÊó©Ë®∫Êñ∑ËÇ∫ÁôåÁöÑËÉΩÂäõ„ÄÇÁÑ∂ËÄåÔºåÊ≠§Ë≠âÊìöÂ∞öÊú™ËΩâÂåñÁÇ∫Ëá®Â∫äÂØ¶ÂãôÔºåÂÖ∂‰∏≠‰∏ÄÂÄãÈöúÁ§ôÊòØÁº∫‰πèÂèØËß£ÈáãÁöÑÊ®°Âûã„ÄÇÊú¨Á†îÁ©∂Êé¢Ë®é‰∫ÜÊáâÁî®ËÆäÂàÜËá™ÂãïÁ∑®Á¢ºÂô® (VAE)Ôºå‰∏ÄÁ®ÆÁîüÊàêÂºè‰∫∫Â∑•Êô∫ËÉΩÊ®°ÂûãÔºåÊñºËÇ∫ÁôåÁóÖÁÅ∂„ÄÇÂ∞áÊèêÂá∫ÁöÑÊ®°ÂûãË®ìÁ∑¥ÊñºÂæû LIDC-IDRI ÂÖ¨ÂÖ±Êï∏ÊìöÈõÜ‰∏≠ÊèêÂèñÁöÑ 3D ÈõªËÖ¶Êñ∑Â±§ÊéÉÊèèÁóÖÁÅ∂„ÄÇÈÄöÈÅéËÅöÈ°ûÊé¢Á¥¢‰∫Ü VAE ÁîüÊàêÁöÑ 2D ÂàáÁâáÁöÑÊΩõÂú®ÂêëÈáèË°®Á§∫Ôºå‰ª•Ë≠âÊòéÂÖ∂ÂìÅË≥™Ôºå‰∏¶Áî®ÊñºËÇ∫ÁôåË®∫Êñ∑ÁöÑ MLP ÂàÜÈ°ûÂô®Ê®°ÂûãÔºåÊúÄ‰Ω≥Ê®°ÂûãÈÅîÂà∞‰∫Ü AUC 0.98 Âíå 93.1% Ê∫ñÁ¢∫Â∫¶ÁöÑÊúÄÂÖàÈÄ≤ÊåáÊ®ô„ÄÇËÅöÈ°ûÂàÜÊûêÈ°ØÁ§∫ÔºåVAE ÊΩõÂú®Á©∫ÈñìÊ†πÊìöÊúâÊÑèÁæ©ÁöÑÁâπÂæµÁµÑÊàêÔºàÂåÖÊã¨ËÖ´Áò§Â§ßÂ∞è„ÄÅÂΩ¢ÁãÄ„ÄÅÊÇ£ËÄÖÂíåÊÉ°ÊÄßÈ°ûÂà•ÔºâÂ∞áÊÉ°ÊÄßÂíåËâØÊÄßÁóÖÁÅ∂ÁöÑÊï∏ÊìöÈõÜÂàÜÈñã„ÄÇÊàëÂÄëÈÇÑÂåÖÊã¨Ê®ôÊ∫ñÈ´òÊñØ VAE (GVAE) ÂíåÊõ¥Êñ∞ÁöÑÁãÑÂà©ÂÖãÈõ∑ VAE (DirVAE) ÁöÑÊØîËºÉÂàÜÊûêÔºåÂæåËÄÖÁî®ÁãÑÂà©ÂÖãÈõ∑ÂàÜ‰ΩàÂèñ‰ª£ÂÖàÈ©óÔºå‰ª•‰øÉÈÄ≤ÂÖ∑ÊúâËß£ÈñãÁâπÂæµË°®Á§∫ÁöÑÊõ¥ÂÖ∑ÂèØËß£ÈáãÊÄßÁöÑÊΩõÂú®Á©∫Èñì„ÄÇÊúÄÂæåÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜËàáËá®Â∫äÊúâÊÑèÁæ©ÁöÑÁâπÂæµËÆäÂåñÁõ∏ÊáâÁöÑÊΩõÂú®Á©∫ÈñìÊ©´Ë∂äÁöÑÊΩõÂäõ„ÄÇ

##### **MRxaI: Black-Box Explainability for Image Classifiers in a Medical Setting**
2311.14471v1 by Nathan Blake, Hana Chockler, David A. Kelly, Santiago Calderon Pena, Akchunya Chanchal

Existing tools for explaining the output of image classifiers can be divided
into white-box, which rely on access to the model internals, and black-box,
agnostic to the model. As the usage of AI in the medical domain grows, so too
does the usage of explainability tools. Existing work on medical image
explanations focuses on white-box tools, such as gradcam. However, there are
clear advantages to switching to a black-box tool, including the ability to use
it with any classifier and the wide selection of black-box tools available. On
standard images, black-box tools are as precise as white-box. In this paper we
compare the performance of several black-box methods against gradcam on a brain
cancer MRI dataset. We demonstrate that most black-box tools are not suitable
for explaining medical image classifications and present a detailed analysis of
the reasons for their shortcomings. We also show that one black-box tool, a
causal explainability-based rex, performs as well as \gradcam.

ÊëòË¶ÅÔºöÁèæÊúâÁöÑÂúñÂÉèÂàÜÈ°ûÂô®Ëº∏Âá∫Ëß£ÈáãÂ∑•ÂÖ∑ÂèØÂàÜÁÇ∫‰æùË≥¥ÊñºÊ®°ÂûãÂÖßÈÉ®Â≠òÂèñÊ¨äÈôêÁöÑÁôΩÁõíÔºå‰ª•ÂèäËàáÊ®°ÂûãÁÑ°ÈóúÁöÑÈªëÁõí„ÄÇÈö®Ëëó AI Âú®ÈÜ´ÁôÇÈ†òÂüüÁöÑ‰ΩøÁî®Â¢ûÂä†ÔºåÂèØËß£ÈáãÊÄßÂ∑•ÂÖ∑ÁöÑ‰ΩøÁî®‰πüÈö®‰πãÂ¢ûÂä†„ÄÇÁèæÊúâÈÜ´Â≠∏ÂΩ±ÂÉèËß£ÈáãÁöÑÂ∑•‰ΩúÈáçÈªûÂú®ÊñºÁôΩÁõíÂ∑•ÂÖ∑Ôºå‰æãÂ¶Ç gradcam„ÄÇÁÑ∂ËÄåÔºåÂàáÊèõÂà∞ÈªëÁõíÂ∑•ÂÖ∑ÊúâÊòéÈ°ØÁöÑÂÑ™ÈªûÔºåÂåÖÊã¨ËÉΩÂ§†Ëàá‰ªª‰ΩïÂàÜÈ°ûÂô®‰∏ÄËµ∑‰ΩøÁî®Ôºå‰ª•ÂèäÂª£Ê≥õÁöÑÈªëÁõíÂ∑•ÂÖ∑ÂèØ‰æõÈÅ∏Êìá„ÄÇÂú®Ê®ôÊ∫ñÂΩ±ÂÉè‰∏äÔºåÈªëÁõíÂ∑•ÂÖ∑ËàáÁôΩÁõí‰∏ÄÊ®£Á≤æÁ¢∫„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊØîËºÉ‰∫ÜÂ§öÁ®ÆÈªëÁõíÊñπÊ≥ïÂú®ËÖ¶Áôå MRI Ë≥áÊñôÈõÜ‰∏äËàá gradcam ÁöÑÊïàËÉΩ„ÄÇÊàëÂÄëË≠âÊòéÂ§ßÂ§öÊï∏ÈªëÁõíÂ∑•ÂÖ∑‰∏çÈÅ©ÂêàËß£ÈáãÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÈ°ûÔºå‰∏¶Ë©≥Á¥∞ÂàÜÊûêÂÖ∂Áº∫ÈªûÁöÑÂéüÂõ†„ÄÇÊàëÂÄëÈÇÑË°®Êòé‰∏ÄÁ®ÆÈªëÁõíÂ∑•ÂÖ∑ÔºåÂü∫ÊñºÂõ†ÊûúÂèØËß£ÈáãÊÄßÁöÑ rexÔºåË°®ÁèæËàá \gradcam ‰∏ÄÊ®£Â•Ω„ÄÇ

##### **Moderating Model Marketplaces: Platform Governance Puzzles for AI Intermediaries**
2311.12573v2 by Robert Gorwa, Michael Veale

The AI development community is increasingly making use of hosting
intermediaries such as Hugging Face provide easy access to user-uploaded models
and training data. These model marketplaces lower technical deployment barriers
for hundreds of thousands of users, yet can be used in numerous potentially
harmful and illegal ways. In this article, we explain ways in which AI systems,
which can both `contain' content and be open-ended tools, present one of the
trickiest platform governance challenges seen to date. We provide case studies
of several incidents across three illustrative platforms -- Hugging Face,
GitHub and Civitai -- to examine how model marketplaces moderate models.
Building on this analysis, we outline important (and yet nevertheless limited)
practices that industry has been developing to respond to moderation demands:
licensing, access and use restrictions, automated content moderation, and open
policy development. While the policy challenge at hand is a considerable one,
we conclude with some ideas as to how platforms could better mobilize resources
to act as a careful, fair, and proportionate regulatory access point.

ÊëòË¶ÅÔºöAI ÁôºÂ±ïÁ§æÁæ§Êó•ÁõäÂà©Áî® Hugging Face Á≠âË®óÁÆ°‰∏≠‰ªãÔºåÊèê‰æõ‰ΩøÁî®ËÄÖ‰∏äÂÇ≥‰πãÊ®°ÂûãËàáË®ìÁ∑¥Ë≥áÊñôÁöÑÁ∞°ÊòìÂèñÂæóÁÆ°ÈÅì„ÄÇÈÄô‰∫õÊ®°ÂûãÂ∏ÇÈõÜÈôç‰Ωé‰∫ÜÊï∏ÂçÅËê¨Âêç‰ΩøÁî®ËÄÖÁöÑÊäÄË°ìÈÉ®ÁΩ≤ÈñÄÊ™ªÔºå‰ΩÜÂçªÂèØËÉΩË¢´Áî®ÊñºË®±Â§öÊΩõÂú®ÊúâÂÆ≥‰∏îÈùûÊ≥ïÁöÑÁî®ÈÄî„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëË™™Êòé‰∫Ü AI Á≥ªÁµ±Êó¢ÂèØ‰ª•„ÄåÂåÖÂê´„ÄçÂÖßÂÆπÔºå‰πüÂèØ‰ª•‰ΩúÁÇ∫ÈñãÊîæÂºèÂ∑•ÂÖ∑ÔºåÈÄôÊèêÂá∫‰∫ÜËøÑ‰ªäÁÇ∫Ê≠¢ÊúÄÊ£òÊâãÁöÑÂπ≥Âè∞Ê≤ªÁêÜÊåëÊà∞‰πã‰∏Ä„ÄÇÊàëÂÄëÊèê‰æõ Hugging Face„ÄÅGitHub Âíå Civitai Á≠â‰∏âÂÄãË™™ÊòéÊÄßÂπ≥Âè∞‰∏äÊï∏Ëµ∑‰∫ã‰ª∂ÁöÑÊ°à‰æãÁ†îÁ©∂Ôºå‰ª•Êé¢Ë®éÊ®°ÂûãÂ∏ÇÈõÜÂ¶Ç‰ΩïÊéßÁÆ°Ê®°Âûã„ÄÇÊ†πÊìöÊ≠§ÂàÜÊûêÔºåÊàëÂÄëÊ¶ÇËø∞‰∫ÜÁî¢Ê•≠ÁÇ∫ÂõûÊáâÊéßÁÆ°ÈúÄÊ±ÇËÄåÁôºÂ±ïÁöÑÈáçË¶ÅÔºà‰ΩÜ‰ªçÊúâÈôêÔºâÂØ¶ÂãôÔºöÊéàÊ¨ä„ÄÅÂ≠òÂèñÂíå‰ΩøÁî®ÈôêÂà∂„ÄÅËá™ÂãïÂÖßÂÆπÊéßÁÆ°ÂíåÈñãÊîæÂºèÊîøÁ≠ñÁôºÂ±ï„ÄÇÂÑòÁÆ°ÁõÆÂâçÈù¢Ëá®ÁöÑÊîøÁ≠ñÊåëÊà∞Áõ∏Áï∂Âö¥Â≥ªÔºåÊàëÂÄë‰ªçÊèêÂá∫‰∫Ü‰∏Ä‰∫õÊÉ≥Ê≥ïÔºåË™™ÊòéÂπ≥Âè∞Â¶Ç‰ΩïËÉΩÊõ¥Â•ΩÂú∞ÂãïÂì°Ë≥áÊ∫êÔºå‰ΩúÁÇ∫Ë¨πÊÖé„ÄÅÂÖ¨Âπ≥ÂíåÈÅ©Â∫¶ÁöÑÊ≥ïË¶èÂ≠òÂèñÈªû„ÄÇ

##### **Ovarian Cancer Data Analysis using Deep Learning: A Systematic Review from the Perspectives of Key Features of Data Analysis and AI Assurance**
2311.11932v1 by Muta Tah Hira, Mohammad A. Razzaque, Mosharraf Sarker

Background and objectives: By extracting this information, Machine or Deep
Learning (ML/DL)-based autonomous data analysis tools can assist clinicians and
cancer researchers in discovering patterns and relationships from complex data
sets. Many DL-based analyses on ovarian cancer (OC) data have recently been
published. These analyses are highly diverse in various aspects of cancer
(e.g., subdomain(s) and cancer type they address) and data analysis features.
However, a comprehensive understanding of these analyses in terms of these
features and AI assurance (AIA) is currently lacking. This systematic review
aims to fill this gap by examining the existing literature and identifying
important aspects of OC data analysis using DL, explicitly focusing on the key
features and AI assurance perspectives. Methods: The PRISMA framework was used
to conduct comprehensive searches in three journal databases. Only studies
published between 2015 and 2023 in peer-reviewed journals were included in the
analysis. Results: In the review, a total of 96 DL-driven analyses were
examined. The findings reveal several important insights regarding DL-driven
ovarian cancer data analysis: - Most studies 71% (68 out of 96) focused on
detection and diagnosis, while no study addressed the prediction and prevention
of OC. - The analyses were predominantly based on samples from a non-diverse
population (75% (72/96 studies)), limited to a geographic location or country.
- Only a small proportion of studies (only 33% (32/96)) performed integrated
analyses, most of which used homogeneous data (clinical or omics). - Notably, a
mere 8.3% (8/96) of the studies validated their models using external and
diverse data sets, highlighting the need for enhanced model validation, and -
The inclusion of AIA in cancer data analysis is in a very early stage; only
2.1% (2/96) explicitly addressed AIA through explainability.

ÊëòË¶ÅÔºö<paragraph>ËÉåÊôØÂíåÁõÆÊ®ôÔºöÈÄöÈÅéÊèêÂèñÈÄô‰∫õË≥áË®äÔºåÊ©üÂô®ÊàñÊ∑±Â∫¶Â≠∏Áøí (ML/DL) Âü∫ÊñºËá™‰∏ªÊï∏ÊìöÂàÜÊûêÂ∑•ÂÖ∑ÂèØ‰ª•ÂçîÂä©Ëá®Â∫äÈÜ´ÁîüÂíåÁôåÁóáÁ†îÁ©∂‰∫∫Âì°ÂæûË§áÈõúÁöÑÊï∏ÊìöÈõÜ‰∏≠ÁôºÁèæÊ®°ÂºèÂíåÈóú‰øÇ„ÄÇÊúÄËøëÂ∑≤ÁôºË°®Ë®±Â§öÂü∫Êñº DL ÁöÑÂçµÂ∑¢Áôå (OC) Êï∏ÊìöÂàÜÊûê„ÄÇÈÄô‰∫õÂàÜÊûêÂú®ÁôåÁóáÁöÑÂêÑÂÄãÊñπÈù¢Ôºà‰æãÂ¶ÇÔºåÂÆÉÂÄëÊ∂âÂèäÁöÑÂ≠êÈ†òÂüüÂíåÁôåÁóáÈ°ûÂûãÔºâÂíåÊï∏ÊìöÂàÜÊûêÂäüËÉΩÊñπÈù¢È´òÂ∫¶Â§öÊ®£Âåñ„ÄÇÁÑ∂ËÄåÔºåÁõÆÂâçÁº∫‰πèÂ∞çÈÄô‰∫õÂàÜÊûêÂú®ÈÄô‰∫õÁâπÂæµÂíå AI ‰øùË≠â (AIA) ÊñπÈù¢ÁöÑÂÖ®Èù¢ÁêÜËß£„ÄÇÈÄôÁØáÁ≥ªÁµ±ÊÄßÂõûÈ°ßÊó®Âú®ÈÄöÈÅéÊ™¢Ë¶ñÁèæÊúâÊñáÁçª‰∏¶ÊòéÁ¢∫ÈóúÊ≥®ÈóúÈçµÁâπÂæµÂíå AI ‰øùË≠âËßÄÈªûÔºå‰æÜÂ°´Ë£úÈÄôÂÄãÁ©∫ÁôΩ„ÄÇÊñπÊ≥ïÔºö‰ΩøÁî® PRISMA Êû∂ÊßãÂú®‰∏âÂÄãÊúüÂàäË≥áÊñôÂ∫´‰∏≠ÈÄ≤Ë°åÂÖ®Èù¢ÊêúÂ∞ã„ÄÇÂàÜÊûêÂÉÖÂåÖÊã¨ 2015 Âπ¥Ëá≥ 2023 Âπ¥ÈñìÁôºË°®ÊñºÂêåË°åË©ïÂØ©ÊúüÂàäÁöÑÁ†îÁ©∂„ÄÇÁµêÊûúÔºöÂú®ÂõûÈ°ß‰∏≠ÔºåÁ∏ΩÂÖ±Ê™¢Ë¶ñ‰∫Ü 96 È†ÖÁî± DL È©ÖÂãïÁöÑÂàÜÊûê„ÄÇÁ†îÁ©∂ÁµêÊûúÊè≠Á§∫‰∫ÜÂπæÂÄãÈóúÊñºÁî± DL È©ÖÂãïÁöÑÂçµÂ∑¢ÁôåÊï∏ÊìöÂàÜÊûêÁöÑÈáçË¶ÅË¶ãËß£Ôºö- Â§ßÂ§öÊï∏Á†îÁ©∂ 71%Ôºà96 È†Ö‰∏≠Êúâ 68 È†ÖÔºâÂ∞àÊ≥®ÊñºÊ™¢Ê∏¨ÂíåË®∫Êñ∑ÔºåËÄåÊ≤íÊúâÁ†îÁ©∂Êé¢Ë®é OC ÁöÑÈ†êÊ∏¨ÂíåÈ†êÈò≤„ÄÇ- ÈÄô‰∫õÂàÜÊûê‰∏ªË¶ÅÂü∫Êñº‰æÜËá™ÈùûÂ§öÂÖÉÊóèÁæ§ÁöÑÊ®£Êú¨Ôºà75%Ôºà96 È†ÖÁ†îÁ©∂‰∏≠ÁöÑ 72 È†ÖÔºâÔºâÔºåÂÉÖÈôêÊñºÊüêÂÄãÂú∞ÁêÜ‰ΩçÁΩÆÊàñÂúãÂÆ∂„ÄÇ- Âè™ÊúâÂ∞ëÈÉ®ÂàÜÁ†îÁ©∂ÔºàÂÉÖ 33%Ôºà96 È†ÖÁ†îÁ©∂‰∏≠ÁöÑ 32 È†ÖÔºâÂü∑Ë°åÊï¥ÂêàÂàÜÊûêÔºåÂÖ∂‰∏≠Â§ßÂ§öÊï∏‰ΩøÁî®ÂêåË≥™Êï∏ÊìöÔºàËá®Â∫äÊàñÁµÑÂ≠∏Ôºâ„ÄÇ- ÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÂè™Êúâ 8.3%Ôºà96 È†ÖÁ†îÁ©∂‰∏≠ÁöÑ 8 È†ÖÔºâ‰ΩøÁî®Â§ñÈÉ®ÂíåÂ§öÂÖÉÊï∏ÊìöÈõÜÈ©óË≠â‰∫ÜÂÖ∂Ê®°ÂûãÔºåÂº∑Ë™ø‰∫ÜÂä†Âº∑Ê®°ÂûãÈ©óË≠âÁöÑÂøÖË¶ÅÊÄßÔºå‰ª•Âèä- Â∞á AIA Á¥çÂÖ•ÁôåÁóáÊï∏ÊìöÂàÜÊûê‰ªçËôïÊñºÈùûÂ∏∏Êó©ÊúüÁöÑÈöéÊÆµÔºõÂè™Êúâ 2.1%Ôºà96 È†ÖÁ†îÁ©∂‰∏≠ÁöÑ 2 È†ÖÔºâÈÄèÈÅéÂèØËß£ÈáãÊÄßÊòéÁ¢∫Êé¢Ë®é‰∫Ü AIA„ÄÇ</paragraph>

##### **Representing visual classification as a linear combination of words**
2311.10933v1 by Shobhit Agarwal, Yevgeniy R. Semenov, William Lotter

Explainability is a longstanding challenge in deep learning, especially in
high-stakes domains like healthcare. Common explainability methods highlight
image regions that drive an AI model's decision. Humans, however, heavily rely
on language to convey explanations of not only "where" but "what".
Additionally, most explainability approaches focus on explaining individual AI
predictions, rather than describing the features used by an AI model in
general. The latter would be especially useful for model and dataset auditing,
and potentially even knowledge generation as AI is increasingly being used in
novel tasks. Here, we present an explainability strategy that uses a
vision-language model to identify language-based descriptors of a visual
classification task. By leveraging a pre-trained joint embedding space between
images and text, our approach estimates a new classification task as a linear
combination of words, resulting in a weight for each word that indicates its
alignment with the vision-based classifier. We assess our approach using two
medical imaging classification tasks, where we find that the resulting
descriptors largely align with clinical knowledge despite a lack of
domain-specific language training. However, our approach also identifies the
potential for 'shortcut connections' in the public datasets used. Towards a
functional measure of explainability, we perform a pilot reader study where we
find that the AI-identified words can enable non-expert humans to perform a
specialized medical task at a non-trivial level. Altogether, our results
emphasize the potential of using multimodal foundational models to deliver
intuitive, language-based explanations of visual tasks.

ÊëòË¶ÅÔºö<paragraph>Ëß£ÈáãÊÄßÊòØÊ∑±Â∫¶Â≠∏Áøí‰∏≠Èï∑ÊúüÁöÑÊåëÊà∞ÔºåÁâπÂà•ÊòØÂú®ÈÜ´ÁôÇ‰øùÂÅ•Á≠âÈ´òÈ¢®Èö™È†òÂüü„ÄÇÂ∏∏Ë¶ãÁöÑËß£ÈáãÊÄßÊñπÊ≥ïÊúÉÂº∑Ë™øÈ©ÖÂãï AI Ê®°ÂûãÊ±∫Á≠ñÁöÑÂΩ±ÂÉèÂçÄÂüü„ÄÇÁÑ∂ËÄåÔºå‰∫∫È°ûÂæàÂ§ßÁ®ãÂ∫¶‰æùË≥¥Ë™ûË®Ä‰æÜÂÇ≥ÈÅî‰∏çÂÉÖÊòØ„ÄåÂú®Âì™Ë£°„ÄçÔºåÈÇÑÊúâ„ÄåÊòØ‰ªÄÈ∫º„ÄçÁöÑËß£Èáã„ÄÇÊ≠§Â§ñÔºåÂ§ßÂ§öÊï∏Ëß£ÈáãÊÄßÊñπÊ≥ïÈÉΩÂ∞àÊ≥®ÊñºËß£ÈáãÂÄãÂà• AI È†êÊ∏¨ÔºåËÄå‰∏çÊòØÊèèËø∞ AI Ê®°Âûã‰∏ÄËà¨‰ΩøÁî®ÁöÑÁâπÂæµ„ÄÇÂæåËÄÖÂ∞çÊñºÊ®°ÂûãÂíåË≥áÊñôÈõÜÁ®ΩÊ†∏ÁâπÂà•ÊúâÁî®ÔºåÁîöËá≥ÂèØËÉΩÂú® AI ÊÑà‰æÜÊÑàÁî®ÊñºÊñ∞Á©é‰ªªÂãôÊôÇÁî¢ÁîüÁü•Ë≠ò„ÄÇÂú®Ê≠§ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄã‰ΩøÁî®Ë¶ñË¶∫Ë™ûË®ÄÊ®°Âûã‰æÜËæ®Ë≠òË¶ñË¶∫ÂàÜÈ°û‰ªªÂãôÁöÑË™ûË®ÄÊèèËø∞Á¨¶ÁöÑËß£ÈáãÊÄßÁ≠ñÁï•„ÄÇÈÄèÈÅéÂà©Áî®ÂΩ±ÂÉèÂíåÊñáÂ≠ó‰πãÈñìÈ†êÂÖàË®ìÁ∑¥ÁöÑËÅØÂêàÂµåÂÖ•Á©∫ÈñìÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÂ∞áÊñ∞ÁöÑÂàÜÈ°û‰ªªÂãô‰º∞Ë®àÁÇ∫‰∏ÄÂÄãÁ∑öÊÄßÊñáÂ≠óÁµÑÂêàÔºåÂ∞éËá¥ÊØèÂÄãÊñáÂ≠óÈÉΩÊúâÊ¨äÈáçÔºåË°®Á§∫ÂÆÉËàáÂü∫ÊñºË¶ñË¶∫ÁöÑÂàÜÈ°ûÂô®Â∞çÈΩä„ÄÇÊàëÂÄë‰ΩøÁî®ÂÖ©ÂÄãÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÈ°û‰ªªÂãô‰æÜË©ï‰º∞ÊàëÂÄëÁöÑÂÅöÊ≥ïÔºåÊàëÂÄëÁôºÁèæÁî¢ÁîüÁöÑÊèèËø∞Á¨¶Âú®ÂæàÂ§ßÁ®ãÂ∫¶‰∏äËàáËá®Â∫äÁü•Ë≠ò‰∏ÄËá¥ÔºåÂÑòÁÆ°Áº∫‰πèÁâπÂÆöÈ†òÂüüÁöÑË™ûË®ÄË®ìÁ∑¥„ÄÇÁÑ∂ËÄåÔºåÊàëÂÄëÁöÑÂÅöÊ≥ï‰πüÁôºÁèæ‰∫ÜÊâÄÁî®ÂÖ¨ÈñãË≥áÊñôÈõÜ‰∏≠ÁöÑ„ÄåÊç∑ÂæëÈÄ£Á∑ö„ÄçÁöÑÂèØËÉΩÊÄß„ÄÇÁÇ∫‰∫ÜÈÅîÂà∞Ëß£ÈáãÊÄßÁöÑÂäüËÉΩÊÄßË°°ÈáèÔºåÊàëÂÄëÈÄ≤Ë°å‰∫Ü‰∏ÄÈ†ÖË©¶È©óËÆÄËÄÖÁ†îÁ©∂ÔºåÁôºÁèæ AI Ë≠òÂà•ÁöÑÊñáÂ≠óËÉΩËÆìÈùûÂ∞àÂÆ∂‰∫∫È°ûÂú®ÈùûÂπ≥Âá°ÁöÑÂ±§Á¥öÂü∑Ë°åÂ∞àÊ•≠ÁöÑÈÜ´ÁôÇ‰ªªÂãô„ÄÇÁ∏Ω‰πãÔºåÊàëÂÄëÁöÑÁµêÊûúÂº∑Ë™ø‰∫Ü‰ΩøÁî®Â§öÊ®°ÂºèÂü∫Á§éÊ®°Âûã‰æÜÊèê‰æõÁõ¥ËßÄÁöÑ„ÄÅÂü∫ÊñºË™ûË®ÄÁöÑË¶ñË¶∫‰ªªÂãôËß£ÈáãÁöÑÊΩõÂäõ„ÄÇ</paragraph>

##### **Towards objective and systematic evaluation of bias in artificial intelligence for medical imaging**
2311.02115v2 by Emma A. M. Stanley, Raissa Souza, Anthony Winder, Vedant Gulve, Kimberly Amador, Matthias Wilms, Nils D. Forkert

Artificial intelligence (AI) models trained using medical images for clinical
tasks often exhibit bias in the form of disparities in performance between
subgroups. Since not all sources of biases in real-world medical imaging data
are easily identifiable, it is challenging to comprehensively assess how those
biases are encoded in models, and how capable bias mitigation methods are at
ameliorating performance disparities. In this article, we introduce a novel
analysis framework for systematically and objectively investigating the impact
of biases in medical images on AI models. We developed and tested this
framework for conducting controlled in silico trials to assess bias in medical
imaging AI using a tool for generating synthetic magnetic resonance images with
known disease effects and sources of bias. The feasibility is showcased by
using three counterfactual bias scenarios to measure the impact of simulated
bias effects on a convolutional neural network (CNN) classifier and the
efficacy of three bias mitigation strategies. The analysis revealed that the
simulated biases resulted in expected subgroup performance disparities when the
CNN was trained on the synthetic datasets. Moreover, reweighing was identified
as the most successful bias mitigation strategy for this setup, and we
demonstrated how explainable AI methods can aid in investigating the
manifestation of bias in the model using this framework. Developing fair AI
models is a considerable challenge given that many and often unknown sources of
biases can be present in medical imaging datasets. In this work, we present a
novel methodology to objectively study the impact of biases and mitigation
strategies on deep learning pipelines, which can support the development of
clinical AI that is robust and responsible.

ÊëòË¶ÅÔºö<paragraph>‰ΩøÁî®ÈÜ´ÁôÇÂΩ±ÂÉèË®ìÁ∑¥ÁöÑ‰∫∫Â∑•Êô∫ÊÖß (AI) Ê®°ÂûãÔºåÁî®ÊñºËá®Â∫ä‰ªªÂãôÊôÇÔºåÂ∏∏ÊúÉÂú®ÊïàËÉΩ‰∏äÂ±ïÁèæÂá∫Ê¨°Áæ§È´î‰πãÈñìÁöÑÂ∑ÆÁï∞ÔºåÂΩ¢ÊàêÂÅèË¶ã„ÄÇÁî±Êñº‰∏¶ÈùûÊâÄÊúâÁúüÂØ¶‰∏ñÁïåÈÜ´ÁôÇÂΩ±ÂÉèË≥áÊñô‰∏≠ÁöÑÂÅèË¶ã‰æÜÊ∫êÈÉΩÂÆπÊòìËæ®Ë≠òÔºåÂõ†Ê≠§ÂÖ®Èù¢Ë©ï‰º∞ÈÄô‰∫õÂÅèË¶ãÊòØÂ¶Ç‰ΩïÁ∑®Á¢ºÂà∞Ê®°Âûã‰∏≠Ôºå‰ª•ÂèäÂÅèË¶ãÁ∑©Ëß£ÊñπÊ≥ïÂú®ÊîπÂñÑÊïàËÉΩÂ∑ÆÁï∞ÊñπÈù¢ÁöÑËÉΩÂäõÔºåÊòØ‰∏ÄÈ†ÖÊåëÊà∞„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫Ü‰∏ÄÂÄãÊñ∞Á©éÁöÑÂàÜÊûêÊû∂ÊßãÔºåÁî®ÊñºÁ≥ªÁµ±Âåñ‰∏îÂÆ¢ËßÄÂú∞Ë™øÊü•ÈÜ´ÁôÇÂΩ±ÂÉè‰∏≠ÁöÑÂÅèË¶ãÂ∞ç AI Ê®°ÂûãÁöÑÂΩ±Èüø„ÄÇÊàëÂÄëÈñãÁôº‰∏¶Ê∏¨Ë©¶‰∫ÜÈÄôÂÄãÊû∂ÊßãÔºå‰ª•ÈÄ≤Ë°åÂèóÊéßÁöÑÈõªËÖ¶Ê®°Êì¨Ë©¶È©óÔºå‰ΩøÁî®‰∏ÄÂÄãÂ∑•ÂÖ∑‰æÜË©ï‰º∞ÈÜ´ÁôÇÂΩ±ÂÉè AI ‰∏≠ÁöÑÂÅèË¶ãÔºåË©≤Â∑•ÂÖ∑Áî®ÊñºÁî¢ÁîüÂÖ∑ÊúâÂ∑≤Áü•ÁñæÁóÖÂΩ±ÈüøÂíåÂÅèË¶ã‰æÜÊ∫êÁöÑÂêàÊàêÁ£ÅÂÖ±ÊåØÂΩ±ÂÉè„ÄÇÂèØË°åÊÄßÈÄèÈÅé‰ΩøÁî®‰∏âÂÄãÂèç‰∫ãÂØ¶ÂÅèË¶ãÊÉÖÂ¢É‰æÜË°°ÈáèÊ®°Êì¨ÂÅèË¶ãÊïàÊáâÂ∞çÂç∑Á©çÁ•ûÁ∂ìÁ∂≤Ë∑Ø (CNN) ÂàÜÈ°ûÂô®Âíå‰∏âÂÄãÂÅèË¶ãÁ∑©Ëß£Á≠ñÁï•ÁöÑÂΩ±ÈüøÔºå‰∏¶Â±ïÁ§∫Âá∫‰æÜ„ÄÇÂàÜÊûêÈ°ØÁ§∫ÔºåÁï∂ CNN Âú®ÂêàÊàêË≥áÊñôÈõÜ‰∏äÂèóË®ìÊôÇÔºåÊ®°Êì¨ÂÅèË¶ãÊúÉÂ∞éËá¥È†êÊúüÁöÑÊ¨°Áæ§È´îÊïàËÉΩÂ∑ÆÁï∞„ÄÇÊ≠§Â§ñÔºåÈáçÊñ∞Âä†Ê¨äË¢´Ë™çÁÇ∫ÊòØÊ≠§Ë®≠ÂÆö‰∏≠ÊúÄÊàêÂäüÁöÑÂÅèË¶ãÁ∑©Ëß£Á≠ñÁï•ÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜËß£ÈáãÊÄß AI ÊñπÊ≥ïÂ¶Ç‰ΩïÂçîÂä©‰ΩøÁî®ÈÄôÂÄãÊû∂ÊßãË™øÊü•Ê®°Âûã‰∏≠ÂÅèË¶ãÁöÑË°®Áèæ„ÄÇÈñãÁôºÂÖ¨Âπ≥ÁöÑ AI Ê®°ÂûãÊòØ‰∏ÄÈ†ÖÈáçÂ§ßÁöÑÊåëÊà∞ÔºåÂõ†ÁÇ∫ÈÜ´ÁôÇÂΩ±ÂÉèË≥áÊñôÈõÜ‰∏≠ÂèØËÉΩÂ≠òÂú®Ë®±Â§ö‰∏îÁ∂ìÂ∏∏Êú™Áü•ÁöÑÂÅèË¶ã‰æÜÊ∫ê„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÊñπÊ≥ïÔºåÁî®ÊñºÂÆ¢ËßÄÂú∞Á†îÁ©∂ÂÅèË¶ãÂíåÁ∑©Ëß£Á≠ñÁï•Â∞çÊ∑±Â∫¶Â≠∏ÁøíÁÆ°Á∑öÁöÑÂΩ±ÈüøÔºåÈÄôÂèØ‰ª•ÊîØÊè¥ÂÅ•ÂÖ®‰∏îË≤†Ë≤¨‰ªªÁöÑËá®Â∫ä AI ÁöÑÈñãÁôº„ÄÇ</paragraph>

##### **Predicting recovery following stroke: deep learning, multimodal data and feature selection using explainable AI**
2310.19174v1 by Adam White, Margarita Saranti, Artur d'Avila Garcez, Thomas M. H. Hope, Cathy J. Price, Howard Bowman

Machine learning offers great potential for automated prediction of
post-stroke symptoms and their response to rehabilitation. Major challenges for
this endeavour include the very high dimensionality of neuroimaging data, the
relatively small size of the datasets available for learning, and how to
effectively combine neuroimaging and tabular data (e.g. demographic information
and clinical characteristics). This paper evaluates several solutions based on
two strategies. The first is to use 2D images that summarise MRI scans. The
second is to select key features that improve classification accuracy.
Additionally, we introduce the novel approach of training a convolutional
neural network (CNN) on images that combine regions-of-interest extracted from
MRIs, with symbolic representations of tabular data. We evaluate a series of
CNN architectures (both 2D and a 3D) that are trained on different
representations of MRI and tabular data, to predict whether a composite measure
of post-stroke spoken picture description ability is in the aphasic or
non-aphasic range. MRI and tabular data were acquired from 758 English speaking
stroke survivors who participated in the PLORAS study. The classification
accuracy for a baseline logistic regression was 0.678 for lesion size alone,
rising to 0.757 and 0.813 when initial symptom severity and recovery time were
successively added. The highest classification accuracy 0.854 was observed when
8 regions-of-interest was extracted from each MRI scan and combined with lesion
size, initial severity and recovery time in a 2D Residual Neural Network.Our
findings demonstrate how imaging and tabular data can be combined for high
post-stroke classification accuracy, even when the dataset is small in machine
learning terms. We conclude by proposing how the current models could be
improved to achieve even higher levels of accuracy using images from hospital
scanners.

ÊëòË¶ÅÔºöÊ©üÂô®Â≠∏ÁøíÁÇ∫Ëá™ÂãïÈ†êÊ∏¨‰∏≠È¢®ÂæåÁóáÁãÄÂèäÂÖ∂Â∞çÂæ©ÂÅ•ÁöÑÂèçÊáâÊèê‰æõ‰∫ÜÊ•µÂ§ßÁöÑÊΩõÂäõ„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÁöÑÈáçÂ§ßÊåëÊà∞ÂåÖÊã¨Á•ûÁ∂ìÂΩ±ÂÉèË≥áÊñôÁöÑÁ∂≠Â∫¶ÈùûÂ∏∏È´ò„ÄÅÂèØÁî®ÊñºÂ≠∏ÁøíÁöÑË≥áÊñôÈõÜË¶èÊ®°Áõ∏Â∞çËºÉÂ∞èÔºå‰ª•ÂèäÂ¶Ç‰ΩïÊúâÊïàÁµêÂêàÁ•ûÁ∂ìÂΩ±ÂÉèÂíåË°®Ê†ºË≥áÊñôÔºà‰æãÂ¶Ç‰∫∫Âè£Áµ±Ë®àË≥áË®äÂíåËá®Â∫äÁâπÂæµÔºâ„ÄÇÊú¨ÊñáÊ†πÊìöÂÖ©Á®ÆÁ≠ñÁï•Ë©ï‰º∞‰∫ÜÂ§öÁ®ÆËß£Ê±∫ÊñπÊ°à„ÄÇÁ¨¨‰∏ÄÁ®ÆÊòØ‰ΩøÁî®Á∏ΩÁµê MRI ÊéÉÊèèÁöÑ 2D ÂΩ±ÂÉè„ÄÇÁ¨¨‰∫åÁ®ÆÊòØÈÅ∏ÊìáÊúâÂä©ÊñºÊèêÈ´òÂàÜÈ°ûÁ≤æÁ¢∫Â∫¶ÁöÑÈóúÈçµÁâπÂæµ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜÂú®ÁµêÂêàÂæû MRI ‰∏≠ÊèêÂèñÁöÑÊÑüËààË∂£ÂçÄÂüüËàáË°®Ê†ºË≥áÊñôÁöÑÁ¨¶ËôüË°®Á§∫ÁöÑÂΩ±ÂÉè‰∏äË®ìÁ∑¥Âç∑Á©çÁ•ûÁ∂ìÁ∂≤Ë∑Ø (CNN) ÁöÑÊñ∞Á©éÊñπÊ≥ï„ÄÇÊàëÂÄëË©ï‰º∞‰∫Ü‰∏ÄÁ≥ªÂàó CNN Êû∂ÊßãÔºà2D Âíå 3DÔºâÔºåÈÄô‰∫õÊû∂ÊßãÂú® MRI ÂíåË°®Ê†ºË≥áÊñôÁöÑ‰∏çÂêåË°®Á§∫‰∏äÈÄ≤Ë°åË®ìÁ∑¥Ôºå‰ª•È†êÊ∏¨‰∏≠È¢®ÂæåÂè£Ëø∞ÂúñÁâáÊèèËø∞ËÉΩÂäõÁöÑÁ∂úÂêàÊ∏¨ÈáèÊòØÂê¶Âú®Â§±Ë™ûÁóáÊàñÈùûÂ§±Ë™ûÁóáÁØÑÂúçÂÖß„ÄÇMRI ÂíåË°®Ê†ºË≥áÊñô‰æÜËá™ 758 ÂêçÂèÉËàá PLORAS Á†îÁ©∂ÁöÑËã±Ë™û‰∏≠È¢®ÂÄñÂ≠òËÄÖ„ÄÇÂÉÖÈáùÂ∞çÁóÖÁÅ∂Â§ßÂ∞èÁöÑÂü∫Á∑öÈÇèËºØËø¥Ê≠∏ÂàÜÈ°ûÊ∫ñÁ¢∫Â∫¶ÁÇ∫ 0.678ÔºåÁï∂‰æùÂ∫èÂä†ÂÖ•ÂàùÂßãÁóáÁãÄÂö¥ÈáçÁ®ãÂ∫¶ÂíåÊÅ¢Âæ©ÊôÇÈñìÊôÇÔºå‰∏äÂçáËá≥ 0.757 Âíå 0.813„ÄÇÂú®ÂæûÊØèÂÄã MRI ÊéÉÊèè‰∏≠ÊèêÂèñ 8 ÂÄãÊÑüËààË∂£ÂçÄÂüü‰∏¶Âú® 2D ÊÆòÂ∑ÆÁ•ûÁ∂ìÁ∂≤Ë∑Ø‰∏≠ËàáÁóÖÁÅ∂Â§ßÂ∞è„ÄÅÂàùÂßãÂö¥ÈáçÁ®ãÂ∫¶ÂíåÊÅ¢Âæ©ÊôÇÈñìÁµêÂêàÊôÇÔºåËßÄÂØüÂà∞ÊúÄÈ´òÁöÑÂàÜÈ°ûÊ∫ñÁ¢∫Â∫¶ 0.854„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÂ±ïÁ§∫‰∫ÜÂ¶Ç‰ΩïÂ∞áÂΩ±ÂÉèÂíåË°®Ê†ºË≥áÊñôÁµêÂêàËµ∑‰æÜ‰ª•Áç≤ÂæóÈ´òÊñº‰∏≠È¢®ÂæåÂàÜÈ°ûÊ∫ñÁ¢∫Â∫¶ÔºåÂç≥‰ΩøÂú®Ê©üÂô®Â≠∏ÁøíË°ìË™û‰∏≠Ë≥áÊñôÈõÜÂæàÂ∞èÁöÑÊÉÖÊ≥Å‰∏ã‰πüÊòØÂ¶ÇÊ≠§„ÄÇÊúÄÂæåÔºåÊàëÂÄëÊèêÂá∫Â¶Ç‰ΩïÊîπÈÄ≤ÁõÆÂâçÁöÑÊ®°ÂûãÔºå‰ª•‰ΩøÁî®‰æÜËá™ÈÜ´Èô¢ÊéÉÊèèÂÑÄÁöÑÂΩ±ÂÉè‰æÜÂØ¶ÁèæÊõ¥È´òÁöÑÊ∫ñÁ¢∫Â∫¶„ÄÇ

##### **Trainable Noise Model as an XAI evaluation method: application on Sobol for remote sensing image segmentation**
2310.01828v2 by Hossein Shreim, Abdul Karim Gizzini, Ali J. Ghandour

eXplainable Artificial Intelligence (XAI) has emerged as an essential
requirement when dealing with mission-critical applications, ensuring
transparency and interpretability of the employed black box AI models. The
significance of XAI spans various domains, from healthcare to finance, where
understanding the decision-making process of deep learning algorithms is
essential. Most AI-based computer vision models are often black boxes; hence,
providing explainability of deep neural networks in image processing is crucial
for their wide adoption and deployment in medical image analysis, autonomous
driving, and remote sensing applications. Recently, several XAI methods for
image classification tasks have been introduced. On the contrary, image
segmentation has received comparatively less attention in the context of
explainability, although it is a fundamental task in computer vision
applications, especially in remote sensing. Only some research proposes
gradient-based XAI algorithms for image segmentation. This paper adapts the
recent gradient-free Sobol XAI method for semantic segmentation. To measure the
performance of the Sobol method for segmentation, we propose a quantitative XAI
evaluation method based on a learnable noise model. The main objective of this
model is to induce noise on the explanation maps, where higher induced noise
signifies low accuracy and vice versa. A benchmark analysis is conducted to
evaluate and compare performance of three XAI methods, including Seg-Grad-CAM,
Seg-Grad-CAM++ and Seg-Sobol using the proposed noise-based evaluation
technique. This constitutes the first attempt to run and evaluate XAI methods
using high-resolution satellite images.

ÊëòË¶ÅÔºöÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖß (XAI) Â∑≤ÊàêÁÇ∫ËôïÁêÜ‰ªªÂãôÈóúÈçµÊáâÁî®Á®ãÂºèÊôÇÁöÑ‰∏ÄÈ†ÖÂü∫Êú¨ÈúÄÊ±ÇÔºåÁ¢∫‰øùÊé°Áî®ÈªëÁõí AI Ê®°ÂûãÁöÑÈÄèÊòéÂ∫¶ÂíåÂèØËß£ÈáãÊÄß„ÄÇXAI ÁöÑÈáçË¶ÅÊÄßÊ∂µËìãÂæûÈÜ´ÁôÇ‰øùÂÅ•Âà∞ÈáëËûçÁöÑÂêÑÁ®ÆÈ†òÂüüÔºåÂú®ÈÄô‰∫õÈ†òÂüü‰∏≠Ôºå‰∫ÜËß£Ê∑±Â∫¶Â≠∏ÁøíÊºîÁÆóÊ≥ïÁöÑÊ±∫Á≠ñÂà∂ÂÆöÈÅéÁ®ãËá≥ÈóúÈáçË¶Å„ÄÇÂ§ßÂ§öÊï∏Âü∫Êñº AI ÁöÑÈõªËÖ¶Ë¶ñË¶∫Ê®°ÂûãÈÄöÂ∏∏ÊòØÈªëÁõíÂ≠êÔºõÂõ†Ê≠§ÔºåÂú®ÂΩ±ÂÉèËôïÁêÜ‰∏≠Êèê‰æõÊ∑±Â∫¶Á•ûÁ∂ìÁ∂≤Ë∑ØÁöÑÂèØËß£ÈáãÊÄßÂ∞çÊñºÂÖ∂Âú®ÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÊûê„ÄÅËá™ÂãïÈßïÈßõÂíåÈÅôÊ∏¨ÊáâÁî®‰∏≠ÁöÑÂª£Ê≥õÊé°Áî®ÂíåÈÉ®ÁΩ≤Ëá≥ÈóúÈáçË¶Å„ÄÇÊúÄËøëÔºåÂ∑≤ÈáùÂ∞çÂΩ±ÂÉèÂàÜÈ°û‰ªªÂãôÂºïÂÖ•‰∫ÜÂ§öÁ®Æ XAI ÊñπÊ≥ï„ÄÇÁõ∏ÂèçÂú∞ÔºåÂΩ±ÂÉèÂàÜÂâ≤Âú®ÂèØËß£ÈáãÊÄßÁöÑËÉåÊôØ‰∏ãÂèóÂà∞ÁöÑÈóúÊ≥®Áõ∏Â∞çËºÉÂ∞ëÔºåÂÑòÁÆ°ÂÆÉÊòØÈõªËÖ¶Ë¶ñË¶∫ÊáâÁî®‰∏≠ÁöÑ‰∏ÄÈ†ÖÂü∫Êú¨‰ªªÂãôÔºåÁâπÂà•ÊòØÂú®ÈÅôÊ∏¨‰∏≠„ÄÇÂè™ÊúâÈÉ®ÂàÜÁ†îÁ©∂ÊèêÂá∫Áî®ÊñºÂΩ±ÂÉèÂàÜÂâ≤ÁöÑÂü∫ÊñºÊ¢ØÂ∫¶ÁöÑ XAI ÊºîÁÆóÊ≥ï„ÄÇÊú¨ÊñáÊîπÁ∑®‰∫ÜÊúÄËøëÁöÑÁÑ°Ê¢ØÂ∫¶ Sobol XAI ÊñπÊ≥ï‰ª•ÈÄ≤Ë°åË™ûÊÑèÂàÜÂâ≤„ÄÇÁÇ∫‰∫ÜË°°Èáè Sobol ÊñπÊ≥ïÂú®ÂàÜÂâ≤‰∏≠ÁöÑÊïàËÉΩÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂü∫ÊñºÂèØÂ≠∏ÁøíÈõúË®äÊ®°ÂûãÁöÑÂÆöÈáè XAI Ë©ï‰º∞ÊñπÊ≥ï„ÄÇÊ≠§Ê®°ÂûãÁöÑ‰∏ªË¶ÅÁõÆÁöÑÊòØÂú®Ëß£ÈáãÂúñ‰∏äË™òÁôºÈõúË®äÔºåÂÖ∂‰∏≠ËºÉÈ´òÁöÑË™òÁôºÈõúË®äË°®Á§∫ËºÉ‰ΩéÁöÑÊ∫ñÁ¢∫Â∫¶ÔºåÂèç‰πã‰∫¶ÁÑ∂„ÄÇÈÄ≤Ë°åÂü∫Ê∫ñÂàÜÊûê‰ª•Ë©ï‰º∞ÂíåÊØîËºÉ‰∏âÁ®Æ XAI ÊñπÊ≥ïÁöÑÊïàËÉΩÔºåÂåÖÊã¨ Seg-Grad-CAM„ÄÅSeg-Grad-CAM++ Âíå Seg-SobolÔºå‰∏¶‰ΩøÁî®ÊâÄÊèêÂá∫ÁöÑÂü∫ÊñºÈõúË®äÁöÑË©ï‰º∞ÊäÄË°ì„ÄÇÈÄôÊßãÊàê‰∫Ü‰ΩøÁî®È´òËß£ÊûêÂ∫¶Ë°õÊòüÂΩ±ÂÉèÂü∑Ë°åÂíåË©ï‰º∞ XAI ÊñπÊ≥ïÁöÑÈ¶ñÊ¨°ÂòóË©¶„ÄÇ

##### **Creating Trustworthy LLMs: Dealing with Hallucinations in Healthcare AI**
2311.01463v1 by Muhammad Aurangzeb Ahmad, Ilker Yaramis, Taposh Dutta Roy

Large language models have proliferated across multiple domains in as short
period of time. There is however hesitation in the medical and healthcare
domain towards their adoption because of issues like factuality, coherence, and
hallucinations. Give the high stakes nature of healthcare, many researchers
have even cautioned against its usage until these issues are resolved. The key
to the implementation and deployment of LLMs in healthcare is to make these
models trustworthy, transparent (as much possible) and explainable. In this
paper we describe the key elements in creating reliable, trustworthy, and
unbiased models as a necessary condition for their adoption in healthcare.
Specifically we focus on the quantification, validation, and mitigation of
hallucinations in the context in healthcare. Lastly, we discuss how the future
of LLMs in healthcare may look like.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÂú®Áü≠ÊôÇÈñìÂÖßÂ∑≤Âú®Â§öÂÄãÈ†òÂüü‰∏≠Â§ßÈáèÊøÄÂ¢û„ÄÇÁÑ∂ËÄåÔºåÁî±Êñº‰∫ãÂØ¶ÊÄß„ÄÅÈÄ£Ë≤´ÊÄßÂíåÂπªË¶∫Á≠âÂïèÈ°åÔºåÈÜ´ÁôÇÂíå‰øùÂÅ•È†òÂüüÂ∞çÂÖ∂Êé°Áî®Áå∂Ë±´‰∏çÊ±∫„ÄÇÈëëÊñºÈÜ´ÁôÇ‰øùÂÅ•ÁöÑÈ´òÈ¢®Èö™ÊÄßË≥™ÔºåË®±Â§öÁ†îÁ©∂‰∫∫Âì°ÁîöËá≥Ë≠¶Âëä‰∏çË¶Å‰ΩøÁî®ÂÆÉÔºåÁõ¥Âà∞ÈÄô‰∫õÂïèÈ°åÂæóÂà∞Ëß£Ê±∫„ÄÇÂú®ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÂØ¶ÊñΩÂíåÈÉ®ÁΩ≤ LLM ÁöÑÈóúÈçµÊòØ‰ΩøÈÄô‰∫õÊ®°ÂûãÂÄºÂæó‰ø°Ë≥¥„ÄÅÈÄèÊòéÔºàÁõ°ÂèØËÉΩÂ§öÔºâ‰∏îÂèØËß£Èáã„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèèËø∞‰∫ÜÂª∫Á´ãÂèØÈù†„ÄÅÂÄºÂæó‰ø°Ë≥¥ÂíåÁÑ°ÂÅèË¶ãÊ®°ÂûãÁöÑÈóúÈçµË¶ÅÁ¥†Ôºå‰ΩúÁÇ∫ÂÆÉÂÄëÂú®ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÂæóÂà∞Êé°Áî®ÁöÑÂøÖË¶ÅÊ¢ù‰ª∂„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÂ∞àÊ≥®ÊñºÂú®ÈÜ´ÁôÇ‰øùÂÅ•ËÉåÊôØ‰∏ãÂ∞çÂπªË¶∫ÈÄ≤Ë°åÈáèÂåñ„ÄÅÈ©óË≠âÂíåÁ∑©Ëß£„ÄÇÊúÄÂæåÔºåÊàëÂÄëË®éË´ñ‰∫Ü LLM Âú®ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÁöÑÊú™‰æÜÂèØËÉΩÊòØ‰ªÄÈ∫ºÊ®£Â≠ê„ÄÇ

##### **When to Trust AI: Advances and Challenges for Certification of Neural Networks**
2309.11196v1 by Marta Kwiatkowska, Xiyue Zhang

Artificial intelligence (AI) has been advancing at a fast pace and it is now
poised for deployment in a wide range of applications, such as autonomous
systems, medical diagnosis and natural language processing. Early adoption of
AI technology for real-world applications has not been without problems,
particularly for neural networks, which may be unstable and susceptible to
adversarial examples. In the longer term, appropriate safety assurance
techniques need to be developed to reduce potential harm due to avoidable
system failures and ensure trustworthiness. Focusing on certification and
explainability, this paper provides an overview of techniques that have been
developed to ensure safety of AI decisions and discusses future challenges.

ÊëòË¶ÅÔºö‰∫∫Â∑•Êô∫ÊÖßÔºàAIÔºâÂ∑≤Âø´ÈÄüÈÄ≤Ê≠•ÔºåÁèæÂ∑≤Ê∫ñÂÇôÈÉ®ÁΩ≤ÊñºÂª£Ê≥õÁöÑÊáâÁî®Á®ãÂºè‰∏≠Ôºå‰æãÂ¶ÇËá™‰∏ªÁ≥ªÁµ±„ÄÅÈÜ´ÁôÇË®∫Êñ∑ÂíåËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ„ÄÇÂèäÊó©Êé°Áî® AI ÊäÄË°ìÊñºÂØ¶ÈöõÊáâÁî®Á®ãÂºè‰∏¶ÈùûÊ≤íÊúâÂïèÈ°åÔºåÁâπÂà•ÊòØÂ∞çÊñºÁ•ûÁ∂ìÁ∂≤Ë∑ØÔºåÂÆÉÂèØËÉΩ‰∏çÁ©©ÂÆö‰∏îÂÆπÊòìÂèóÂà∞Â∞çÊäóÊÄßÁØÑ‰æãÁöÑÂΩ±Èüø„ÄÇÂæûÈï∑ÈÅ†‰æÜÁúãÔºåÈúÄË¶ÅÈñãÁôºÈÅ©Áï∂ÁöÑÂÆâÂÖ®‰øùË≠âÊäÄË°ìÔºå‰ª•Ê∏õÂ∞ëÂõ†ÂèØÈÅøÂÖçÁöÑÁ≥ªÁµ±ÊïÖÈöúËÄåÈÄ†ÊàêÁöÑÊΩõÂú®ÂÇ∑ÂÆ≥Ôºå‰∏¶Á¢∫‰øùÂèØ‰ø°Ë≥¥ÊÄß„ÄÇÊú¨ÊñáËëóÈáçÊñºË™çË≠âÂíåÂèØËß£ÈáãÊÄßÔºåÊ¶ÇËø∞‰∫ÜÂ∑≤ÈñãÁôºÁî®ÊñºÁ¢∫‰øù AI Ê±∫Á≠ñÂÆâÂÖ®ÁöÑÊäÄË°ìÔºå‰∏¶Ë®éË´ñÊú™‰æÜÁöÑÊåëÊà∞„ÄÇ

##### **Functional requirements to mitigate the Risk of Harm to Patients from Artificial Intelligence in Healthcare**
2309.10424v1 by Juan M. Garc√≠a-G√≥mez, Vicent Blanes-Selva, Jos√© Carlos de Bartolom√© Cenzano, Jaime Cebolla-Cornejo, Ascensi√≥n Do√±ate-Mart√≠nez

The Directorate General for Parliamentary Research Services of the European
Parliament has prepared a report to the Members of the European Parliament
where they enumerate seven main risks of Artificial Intelligence (AI) in
medicine and healthcare: patient harm due to AI errors, misuse of medical AI
tools, bias in AI and the perpetuation of existing inequities, lack of
transparency, privacy and security issues, gaps in accountability, and
obstacles in implementation.
  In this study, we propose fourteen functional requirements that AI systems
may implement to reduce the risks associated with their medical purpose: AI
passport, User management, Regulation check, Academic use only disclaimer, data
quality assessment, Clinicians double check, Continuous performance evaluation,
Audit trail, Continuous usability test, Review of retrospective/simulated
cases, Bias check, eXplainable AI, Encryption and use of field-tested
libraries, and Semantic interoperability.
  Our intention here is to provide specific high-level specifications of
technical solutions to ensure continuous good performance and use of AI systems
to benefit patients in compliance with the future EU regulatory framework.

ÊëòË¶ÅÔºöÊ≠êÊ¥≤Ë≠∞ÊúÉË≠∞ÊúÉÁ†îÁ©∂ÊúçÂãôÁ∏ΩÂ±ÄÂ∑≤ÁÇ∫Ê≠êÊ¥≤Ë≠∞ÊúÉË≠∞Âì°Ê∫ñÂÇô‰∫Ü‰∏Ä‰ªΩÂ†±ÂëäÔºåÂÖ∂‰∏≠ÂàóËàâ‰∫Ü‰∫∫Â∑•Êô∫ËÉΩ (AI) Âú®ÈÜ´ÁôÇ‰øùÂÅ•È†òÂüüÁöÑ‰∏ÉÈ†Ö‰∏ªË¶ÅÈ¢®Èö™ÔºöAI ÈåØË™§Â∞éËá¥ÊÇ£ËÄÖÂèóÂà∞ÂÇ∑ÂÆ≥„ÄÅÈÜ´ÁôÇ AI Â∑•ÂÖ∑Ë¢´Êø´Áî®„ÄÅAI Â≠òÂú®ÂÅèË¶ã‰∏¶Â∞éËá¥ÁèæÊúâ inequities ÊåÅÁ∫åÂ≠òÂú®„ÄÅÁº∫‰πèÈÄèÊòéÂ∫¶„ÄÅÈö±ÁßÅÂíåÂÆâÂÖ®ÂïèÈ°å„ÄÅÂïèË≤¨Â∑ÆË∑ù‰ª•ÂèäÂØ¶ÊñΩÈöúÁ§ô„ÄÇ
  Âú®ÈÄôÈ†ÖÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫ÜÂçÅÂõõÈ†ÖÂäüËÉΩÊÄßË¶ÅÊ±ÇÔºåAI Á≥ªÁµ±ÂèØ‰ª•ÂØ¶ÊñΩÈÄô‰∫õË¶ÅÊ±Ç‰æÜÈôç‰ΩéËàáÂÖ∂ÈÜ´ÁôÇÁõÆÁöÑÁõ∏ÈóúÁöÑÈ¢®Èö™ÔºöAI Ë≠∑ÁÖß„ÄÅ‰ΩøÁî®ËÄÖÁÆ°ÁêÜ„ÄÅÊ≥ïË¶èÊ™¢Êü•„ÄÅÂÉÖÈôêÂ≠∏Ë°ìÁî®ÈÄîÂÖçË≤¨ËÅ≤Êòé„ÄÅË≥áÊñôÂìÅË≥™Ë©ï‰º∞„ÄÅËá®Â∫äÈÜ´ÁîüÈõôÈáçÊ™¢Êü•„ÄÅÊåÅÁ∫åÊïàËÉΩË©ï‰º∞„ÄÅÁ®ΩÊ†∏ËøΩËπ§„ÄÅÊåÅÁ∫åÂèØÁî®ÊÄßÊ∏¨Ë©¶„ÄÅÂõûÈ°ßÂõûÊ∫Ø/Ê®°Êì¨Ê°à‰æã„ÄÅÂÅèË¶ãÊ™¢Êü•„ÄÅÂèØËß£Èáã AI„ÄÅÂä†ÂØÜÂíå‰ΩøÁî®Á∂ìÈÅéÂØ¶Âú∞Ê∏¨Ë©¶ÁöÑÁ®ãÂºèÂ∫´Ôºå‰ª•ÂèäË™ûÊÑè‰∫íÈÄöÊÄß„ÄÇ
  ÊàëÂÄëÂú®Ê≠§ÁöÑÁõÆÁöÑÊòØÊèê‰æõÊäÄË°ìËß£Ê±∫ÊñπÊ°àÁöÑÁâπÂÆöÈ´òÈöéË¶èÊ†ºÔºå‰ª•Á¢∫‰øùÊåÅÁ∫åËâØÂ•ΩÁöÑÊïàËÉΩÔºå‰∏¶‰ΩøÁî® AI Á≥ªÁµ±Ôºå‰ª•Á¨¶ÂêàÊú™‰æÜÁöÑÊ≠êÁõüÊ≥ïË¶èÊû∂ÊßãÔºåÂæûËÄå‰ΩøÊÇ£ËÄÖÂèóÁõä„ÄÇ

##### **QXAI: Explainable AI Framework for Quantitative Analysis in Patient Monitoring Systems**
2309.10293v3 by Thanveer Shaik, Xiaohui Tao, Haoran Xie, Lin Li, Juan D. Velasquez, Niall Higgins

Artificial Intelligence techniques can be used to classify a patient's
physical activities and predict vital signs for remote patient monitoring.
Regression analysis based on non-linear models like deep learning models has
limited explainability due to its black-box nature. This can require
decision-makers to make blind leaps of faith based on non-linear model results,
especially in healthcare applications. In non-invasive monitoring, patient data
from tracking sensors and their predisposing clinical attributes act as input
features for predicting future vital signs. Explaining the contributions of
various features to the overall output of the monitoring application is
critical for a clinician's decision-making. In this study, an Explainable AI
for Quantitative analysis (QXAI) framework is proposed with post-hoc model
explainability and intrinsic explainability for regression and classification
tasks in a supervised learning approach. This was achieved by utilizing the
Shapley values concept and incorporating attention mechanisms in deep learning
models. We adopted the artificial neural networks (ANN) and attention-based
Bidirectional LSTM (BiLSTM) models for the prediction of heart rate and
classification of physical activities based on sensor data. The deep learning
models achieved state-of-the-art results in both prediction and classification
tasks. Global explanation and local explanation were conducted on input data to
understand the feature contribution of various patient data. The proposed QXAI
framework was evaluated using PPG-DaLiA data to predict heart rate and mobile
health (MHEALTH) data to classify physical activities based on sensor data.
Monte Carlo approximation was applied to the framework to overcome the time
complexity and high computation power requirements required for Shapley value
calculations.

ÊëòË¶ÅÔºö‰∫∫Â∑•Êô∫ÊÖßÊäÄË°ìÂèØÁî®ÊñºÂàÜÈ°ûÁóÖÊÇ£ÁöÑË∫´È´îÊ¥ªÂãï‰∏¶È†êÊ∏¨ÈÅ†Ë∑ùÁóÖÊÇ£Áõ£ÊéßÁöÑÈáçË¶ÅÁîüÂëΩÂæµË±°„ÄÇÂü∫ÊñºÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÁ≠âÈùûÁ∑öÊÄßÊ®°ÂûãÁöÑÂõûÊ≠∏ÂàÜÊûêÁî±ÊñºÂÖ∂ÈªëÁõíÂ≠êÁöÑÊÄßË≥™ËÄåÂÖ∑ÊúâÊúâÈôêÁöÑÂèØËß£ÈáãÊÄß„ÄÇÈÄôÂèØËÉΩÈúÄË¶ÅÊ±∫Á≠ñËÄÖÊ†πÊìöÈùûÁ∑öÊÄßÊ®°ÂûãÁµêÊûúÂÅöÂá∫Áõ≤ÁõÆÁöÑ‰ø°‰ª∞È£õË∫çÔºåÁâπÂà•ÊòØÂú®ÈÜ´ÁôÇ‰øùÂÅ•ÊáâÁî®‰∏≠„ÄÇÂú®Èùû‰æµÂÖ•ÊÄßÁõ£Êéß‰∏≠Ôºå‰æÜËá™ËøΩËπ§ÊÑüÊ∏¨Âô®ÂíåÂÖ∂ÊòìÊÑüËá®Â∫äÂ±¨ÊÄßÁöÑÁóÖÊÇ£Ë≥áÊñôÂÖÖÁï∂È†êÊ∏¨Êú™‰æÜÁîüÂëΩÂæµË±°ÁöÑËº∏ÂÖ•ÁâπÂæµ„ÄÇËß£ÈáãÂêÑÁ®ÆÁâπÂæµÂ∞çÁõ£ÊéßÊáâÁî®Á®ãÂºèÊï¥È´îËº∏Âá∫ÁöÑË≤¢ÁçªÂ∞çÊñºËá®Â∫äÈÜ´ÁîüÁöÑÊ±∫Á≠ñËá≥ÈóúÈáçË¶Å„ÄÇÂú®Êú¨Á†îÁ©∂‰∏≠ÔºåÊèêÂá∫‰∫Ü‰∏ÄÂÄãÁî®ÊñºÈáèÂåñÂàÜÊûêÁöÑÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖß (QXAI) Êû∂ÊßãÔºåË©≤Êû∂ÊßãÂÖ∑ÊúâÁõ£Áù£ÂºèÂ≠∏ÁøíÊñπÊ≥ï‰∏≠ÂõûÊ≠∏ÂíåÂàÜÈ°û‰ªªÂãôÁöÑ‰∫ãÂæåÊ®°ÂûãÂèØËß£ÈáãÊÄßÂíåÂÖßÂú®ÂèØËß£ÈáãÊÄß„ÄÇÈÄôÈÄèÈÅéÂà©Áî® Shapley ÂÄºÊ¶ÇÂøµ‰∏¶Â∞áÊ≥®ÊÑèÂäõÊ©üÂà∂Á¥çÂÖ•Ê∑±Â∫¶Â≠∏ÁøíÊ®°Âûã‰æÜÂØ¶Áèæ„ÄÇÊàëÂÄëÊé°Áî®‰∫∫Â∑•Á•ûÁ∂ìÁ∂≤Ë∑Ø (ANN) ÂíåÂü∫ÊñºÊ≥®ÊÑèÂäõÁöÑÈõôÂêë LSTM (BiLSTM) Ê®°ÂûãÔºåÊ†πÊìöÊÑüÊ∏¨Âô®Ë≥áÊñôÈ†êÊ∏¨ÂøÉÁéáÂíåÂàÜÈ°ûË∫´È´îÊ¥ªÂãï„ÄÇÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÂú®È†êÊ∏¨ÂíåÂàÜÈ°û‰ªªÂãô‰∏≠ÈÉΩÂèñÂæó‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÊàêÊûú„ÄÇÂ∞çËº∏ÂÖ•Ë≥áÊñôÈÄ≤Ë°åÂÖ®Â±ÄËß£ÈáãÂíåÂ±ÄÈÉ®Ëß£ÈáãÔºå‰ª•‰∫ÜËß£ÂêÑÁ®ÆÁóÖÊÇ£Ë≥áÊñôÁöÑÁâπÂæµË≤¢Áçª„ÄÇÊâÄÊèêÂá∫ÁöÑ QXAI Êû∂Êßã‰ΩøÁî® PPG-DaLiA Ë≥áÊñôË©ï‰º∞Ôºå‰ª•È†êÊ∏¨ÂøÉÁéáÔºå‰∏¶‰ΩøÁî®Ë°åÂãïÂÅ•Â∫∑ (MHEALTH) Ë≥áÊñôÊ†πÊìöÊÑüÊ∏¨Âô®Ë≥áÊñôÂ∞çË∫´È´îÊ¥ªÂãïÈÄ≤Ë°åÂàÜÈ°û„ÄÇËíôÂú∞Âç°ÁæÖËøë‰ººÊ≥ïÊáâÁî®ÊñºË©≤Êû∂ÊßãÔºå‰ª•ÂÖãÊúç Shapley ÂÄºË®àÁÆóÊâÄÈúÄÁöÑÊôÇÈñìË§áÈõúÂ∫¶ÂíåÈ´òÈÅãÁÆóËÉΩÂäõÈúÄÊ±Ç„ÄÇ

##### **Evaluation of Human-Understandability of Global Model Explanations using Decision Tree**
2309.09917v1 by Adarsa Sivaprasad, Ehud Reiter, Nava Tintarev, Nir Oren

In explainable artificial intelligence (XAI) research, the predominant focus
has been on interpreting models for experts and practitioners. Model agnostic
and local explanation approaches are deemed interpretable and sufficient in
many applications. However, in domains like healthcare, where end users are
patients without AI or domain expertise, there is an urgent need for model
explanations that are more comprehensible and instil trust in the model's
operations. We hypothesise that generating model explanations that are
narrative, patient-specific and global(holistic of the model) would enable
better understandability and enable decision-making. We test this using a
decision tree model to generate both local and global explanations for patients
identified as having a high risk of coronary heart disease. These explanations
are presented to non-expert users. We find a strong individual preference for a
specific type of explanation. The majority of participants prefer global
explanations, while a smaller group prefers local explanations. A task based
evaluation of mental models of these participants provide valuable feedback to
enhance narrative global explanations. This, in turn, guides the design of
health informatics systems that are both trustworthy and actionable.

ÊëòË¶ÅÔºöÂú®ÂèØËß£Èáä‰∫∫Â∑•Êô∫ËÉΩ (XAI) Á†îÁ©∂‰∏≠Ôºå‰∏ªË¶ÅÈáçÁÇπÂú®‰∫é‰∏∫‰∏ìÂÆ∂Âíå‰ªé‰∏öËÄÖËß£ÈáäÊ®°Âûã„ÄÇÊ®°Âûã‰∏çÂèØÁü•ÂíåÂ±ÄÈÉ®Ëß£ÈáäÊñπÊ≥ïÂú®ËÆ∏Â§öÂ∫îÁî®‰∏≠Ë¢´ËÆ§‰∏∫ÊòØÂèØËß£Èáä‰∏îË∂≥Â§üÁöÑ„ÄÇÁÑ∂ËÄåÔºåÂú®ÂåªÁñó‰øùÂÅ•Á≠âÈ¢ÜÂüüÔºåÊúÄÁªàÁî®Êà∑ÊòØÁº∫‰πè‰∫∫Â∑•Êô∫ËÉΩÊàñÈ¢ÜÂüü‰∏ì‰∏öÁü•ËØÜÁöÑÊÇ£ËÄÖÔºåÂõ†Ê≠§Ëø´ÂàáÈúÄË¶ÅÊõ¥Êòì‰∫éÁêÜËß£‰∏îËÉΩÊøÄÂèëÂØπÊ®°ÂûãÊìç‰ΩúÁöÑ‰ø°‰ªªÁöÑÊ®°ÂûãËß£Èáä„ÄÇÊàë‰ª¨ÂÅáËÆæÁîüÊàêÂèôËø∞ÊÄß„ÄÅÊÇ£ËÄÖÁâπÂÆö‰∏îÂÖ®Â±ÄÔºàÊ®°ÂûãÊï¥‰ΩìÔºâÁöÑÊ®°ÂûãËß£ÈáäÂ∞ÜËÉΩÂ§üÊèêÈ´òÂèØÁêÜËß£ÊÄßÂπ∂ÊîØÊåÅÂÜ≥Á≠ñÂà∂ÂÆö„ÄÇÊàë‰ª¨‰ΩøÁî®ÂÜ≥Á≠ñÊ†ëÊ®°ÂûãÂØπÊ≠§ËøõË°åÊµãËØïÔºå‰∏∫Ë¢´ËØÜÂà´‰∏∫ÊÇ£ÊúâÂÜ†ÂøÉÁóÖÈ´òÈ£éÈô©ÁöÑÊÇ£ËÄÖÁîüÊàêÂ±ÄÈÉ®ÂíåÂÖ®Â±ÄËß£Èáä„ÄÇËøô‰∫õËß£Èáä‰ºöÂëàÁé∞ÁªôÈùû‰∏ìÂÆ∂Áî®Êà∑„ÄÇÊàë‰ª¨ÂèëÁé∞Áî®Êà∑Âº∫ÁÉàÂÅèÂ•ΩÁâπÂÆöÁ±ªÂûãÁöÑËß£Èáä„ÄÇÂ§ßÂ§öÊï∞ÂèÇ‰∏éËÄÖÂÅèÂ•ΩÂÖ®Â±ÄËß£ÈáäÔºåËÄåËæÉÂ∞èÁöÑ‰∏ÄÁªÑÂèÇ‰∏éËÄÖÂÅèÂ•ΩÂ±ÄÈÉ®Ëß£Èáä„ÄÇÂü∫‰∫é‰ªªÂä°ÁöÑÂøÉÁêÜÊ®°ÂûãËØÑ‰º∞‰∏∫Ëøô‰∫õÂèÇ‰∏éËÄÖÊèê‰æõ‰∫ÜÊúâ‰ª∑ÂÄºÁöÑÂèçÈ¶àÔºå‰ª•Â¢ûÂº∫ÂèôËø∞ÊÄßÂÖ®Â±ÄËß£Èáä„ÄÇËøôÂèçËøáÊù•ÂèàÊåáÂØº‰∫ÜÊó¢ÂÄºÂæó‰ø°ËµñÂèàÂèØÊìç‰ΩúÁöÑÂÅ•Â∫∑‰ø°ÊÅØÂ≠¶Á≥ªÁªüÁöÑËÆæËÆ°„ÄÇ

##### **Leveraging A Medical Knowledge Graph into Large Language Models for Diagnosis Prediction**
2308.14321v1 by Yanjun Gao, Ruizhe Li, John Caskey, Dmitriy Dligach, Timothy Miller, Matthew M. Churpek, Majid Afshar

Electronic Health Records (EHRs) and routine documentation practices play a
vital role in patients' daily care, providing a holistic record of health,
diagnoses, and treatment. However, complex and verbose EHR narratives overload
healthcare providers, risking diagnostic inaccuracies. While Large Language
Models (LLMs) have showcased their potential in diverse language tasks, their
application in the healthcare arena needs to ensure the minimization of
diagnostic errors and the prevention of patient harm. In this paper, we outline
an innovative approach for augmenting the proficiency of LLMs in the realm of
automated diagnosis generation, achieved through the incorporation of a medical
knowledge graph (KG) and a novel graph model: Dr.Knows, inspired by the
clinical diagnostic reasoning process. We derive the KG from the National
Library of Medicine's Unified Medical Language System (UMLS), a robust
repository of biomedical knowledge. Our method negates the need for
pre-training and instead leverages the KG as an auxiliary instrument aiding in
the interpretation and summarization of complex medical concepts. Using
real-world hospital datasets, our experimental results demonstrate that the
proposed approach of combining LLMs with KG has the potential to improve the
accuracy of automated diagnosis generation. More importantly, our approach
offers an explainable diagnostic pathway, edging us closer to the realization
of AI-augmented diagnostic decision support systems.

ÊëòË¶ÅÔºöÈõªÂ≠êÂÅ•Â∫∑Á¥ÄÈåÑ (EHR) Âíå‰æãË°åÊñá‰ª∂Ë®òÈåÑÂØ¶ÂãôÂú®ÁóÖÊÇ£ÁöÑÊó•Â∏∏ÁÖßË≠∑‰∏≠ÊâÆÊºîËëóËá≥ÈóúÈáçË¶ÅÁöÑËßíËâ≤ÔºåÊèê‰æõÂÅ•Â∫∑„ÄÅË®∫Êñ∑ÂíåÊ≤ªÁôÇÁöÑÊï¥È´îÁ¥ÄÈåÑ„ÄÇÁÑ∂ËÄåÔºåË§áÈõú‰∏îÂÜóÈï∑ÁöÑ EHR ÊïòËø∞ÊúÉËÆìÈÜ´ÁôÇ‰øùÂÅ•Êèê‰æõËÄÖË∂ÖËºâÔºåÊúâË®∫Êñ∑‰∏çÊ∫ñÁ¢∫ÁöÑÈ¢®Èö™„ÄÇÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤Â±ïÁèæÂÖ∂Âú®ÂêÑÁ®ÆË™ûË®Ä‰ªªÂãô‰∏äÁöÑÊΩõÂäõÔºå‰ΩÜÂÖ∂Âú®ÈÜ´ÁôÇ‰øùÂÅ•È†òÂüüÁöÑÊáâÁî®ÈúÄË¶ÅÁ¢∫‰øùÂ∞áË®∫Êñ∑ÈåØË™§ÈôçÂà∞ÊúÄ‰ΩéÔºå‰∏¶Èò≤Ê≠¢ÁóÖÊÇ£ÂèóÂà∞ÂÇ∑ÂÆ≥„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊ¶ÇËø∞‰∏ÄÁ®ÆÂâµÊñ∞ÁöÑÊñπÊ≥ïÔºåÈÄèÈÅéÊï¥ÂêàÈÜ´Â≠∏Áü•Ë≠òÂúñË≠ú (KG) Âíå‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÂúñË≠úÊ®°ÂûãÔºöDr.KnowsÔºàÈùàÊÑü‰æÜËá™Ëá®Â∫äË®∫Êñ∑Êé®ÁêÜÈÅéÁ®ãÔºâÔºå‰æÜÂ¢ûÂº∑ LLM Âú®Ëá™ÂãïÂåñË®∫Êñ∑Áî¢ÁîüÈ†òÂüüÁöÑËÉΩÂäõ„ÄÇÊàëÂÄëÂæûÁæéÂúãÂúãÂÆ∂ÈÜ´Â≠∏ÂúñÊõ∏È§®ÁöÑÁµ±‰∏ÄÈÜ´Â≠∏Ë™ûË®ÄÁ≥ªÁµ± (UMLS) ‰∏≠Ë°çÁîüÂá∫ KGÔºåÈÄôÊòØ‰∏ÄÂÄãÂº∑Â§ßÁöÑÁîüÁâ©ÈÜ´Â≠∏Áü•Ë≠òÂÑ≤Â≠òÂ∫´„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÂê¶ÂÆö‰∫ÜÈ†êÂÖàË®ìÁ∑¥ÁöÑÈúÄË¶ÅÔºåËÄåÊòØÂ∞á KG ‰ΩúÁÇ∫ËºîÂä©Â∑•ÂÖ∑ÔºåÂçîÂä©Ëß£ÈáãÂíåÁ∏ΩÁµêË§áÈõúÁöÑÈÜ´Â≠∏Ê¶ÇÂøµ„ÄÇ‰ΩøÁî®ÁúüÂØ¶‰∏ñÁïåÁöÑÈÜ´Èô¢Ë≥áÊñôÈõÜÔºåÊàëÂÄëÁöÑÂØ¶È©óÁµêÊûúË≠âÊòéÔºåÂ∞á LLM Ëàá KG ÁµêÂêàÁöÑÂª∫Ë≠∞ÊñπÊ≥ïÊúâÊΩõÂäõÊèêÈ´òËá™ÂãïÂåñË®∫Êñ∑Áî¢ÁîüÁöÑÊ∫ñÁ¢∫ÊÄß„ÄÇÊõ¥ÈáçË¶ÅÁöÑÊòØÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÊèê‰æõ‰∫Ü‰∏ÄÊ¢ùÂèØËß£ÈáãÁöÑË®∫Êñ∑ÈÄîÂæëÔºåËÆìÊàëÂÄëÊõ¥Êé•ËøëÂØ¶Áèæ AI Â¢ûÂº∑ÁöÑË®∫Êñ∑Ê±∫Á≠ñÊîØÊè¥Á≥ªÁµ±„ÄÇ

##### **Deciphering knee osteoarthritis diagnostic features with explainable artificial intelligence: A systematic review**
2308.09380v1 by Yun Xin Teoh, Alice Othmani, Siew Li Goh, Juliana Usman, Khin Wee Lai

Existing artificial intelligence (AI) models for diagnosing knee
osteoarthritis (OA) have faced criticism for their lack of transparency and
interpretability, despite achieving medical-expert-like performance. This
opacity makes them challenging to trust in clinical practice. Recently,
explainable artificial intelligence (XAI) has emerged as a specialized
technique that can provide confidence in the model's prediction by revealing
how the prediction is derived, thus promoting the use of AI systems in
healthcare. This paper presents the first survey of XAI techniques used for
knee OA diagnosis. The XAI techniques are discussed from two perspectives: data
interpretability and model interpretability. The aim of this paper is to
provide valuable insights into XAI's potential towards a more reliable knee OA
diagnosis approach and encourage its adoption in clinical practice.

ÊëòË¶ÅÔºöÁèæÊúâÁöÑÁî®ÊñºË®∫Êñ∑ËÜùÈ™®ÈóúÁØÄÁÇé (OA) ÁöÑ‰∫∫Â∑•Êô∫ÊÖß (AI) Ê®°ÂûãÂõ†ÂÖ∂Áº∫‰πèÈÄèÊòéÂ∫¶ÂíåÂèØËß£ÈáãÊÄßËÄåÂèóÂà∞ÊâπË©ïÔºåÂÑòÁÆ°ÂÆÉÂÄëÈÅîÂà∞‰∫ÜÈ°û‰ººÈÜ´Â≠∏Â∞àÂÆ∂ÁöÑË°®Áèæ„ÄÇÈÄôÁ®Æ‰∏çÈÄèÊòéÊÄß‰ΩøÂæóÂÆÉÂÄëÂú®Ëá®Â∫äÂØ¶Âãô‰∏≠Èõ£‰ª•Ë¢´‰ø°‰ªª„ÄÇÊúÄËøëÔºåÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖß (XAI) Â∑≤ÊàêÁÇ∫‰∏ÄÁ®ÆÂ∞àÈñÄÊäÄË°ìÔºåÂÆÉËÉΩÈÄèÈÅéÊè≠Á§∫È†êÊ∏¨ÁöÑÊé®Â∞éÊñπÂºè‰æÜÊèê‰æõÂ∞çÊ®°ÂûãÈ†êÊ∏¨ÁöÑ‰ø°ÂøÉÔºåÂæûËÄå‰øÉÈÄ≤Âú®ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠‰ΩøÁî® AI Á≥ªÁµ±„ÄÇÊú¨ÊñáÊèê‰æõ‰∫ÜÈáùÂ∞çËÜùÈ™®ÈóúÁØÄÁÇéË®∫Êñ∑ÊâÄ‰ΩøÁî®ÁöÑ XAI ÊäÄË°ìÁöÑÁ¨¨‰∏Ä‰ªΩË™øÊü•„ÄÇXAI ÊäÄË°ìÂæûÂÖ©ÂÄãËßíÂ∫¶ÈÄ≤Ë°åË®éË´ñÔºöË≥áÊñôÂèØËß£ÈáãÊÄßÂíåÊ®°ÂûãÂèØËß£ÈáãÊÄß„ÄÇÊú¨ÊñáÁöÑÁõÆÁöÑÊòØÊèê‰æõÂ∞ç XAI Âú®Êõ¥ÂèØÈù†ÁöÑËÜùÈ™®ÈóúÁØÄÁÇéË®∫Êñ∑ÊñπÊ≥ï‰∏≠ÁöÑÊΩõÂäõÁöÑÂØ∂Ë≤¥Ë¶ãËß£Ôºå‰∏¶ÈºìÂãµÂú®Ëá®Â∫äÂØ¶Âãô‰∏≠Êé°Áî®ÂÆÉ„ÄÇ

##### **Explainable AI for clinical risk prediction: a survey of concepts, methods, and modalities**
2308.08407v1 by Munib Mesinovic, Peter Watkinson, Tingting Zhu

Recent advancements in AI applications to healthcare have shown incredible
promise in surpassing human performance in diagnosis and disease prognosis.
With the increasing complexity of AI models, however, concerns regarding their
opacity, potential biases, and the need for interpretability. To ensure trust
and reliability in AI systems, especially in clinical risk prediction models,
explainability becomes crucial. Explainability is usually referred to as an AI
system's ability to provide a robust interpretation of its decision-making
logic or the decisions themselves to human stakeholders. In clinical risk
prediction, other aspects of explainability like fairness, bias, trust, and
transparency also represent important concepts beyond just interpretability. In
this review, we address the relationship between these concepts as they are
often used together or interchangeably. This review also discusses recent
progress in developing explainable models for clinical risk prediction,
highlighting the importance of quantitative and clinical evaluation and
validation across multiple common modalities in clinical practice. It
emphasizes the need for external validation and the combination of diverse
interpretability methods to enhance trust and fairness. Adopting rigorous
testing, such as using synthetic datasets with known generative factors, can
further improve the reliability of explainability methods. Open access and
code-sharing resources are essential for transparency and reproducibility,
enabling the growth and trustworthiness of explainable research. While
challenges exist, an end-to-end approach to explainability in clinical risk
prediction, incorporating stakeholders from clinicians to developers, is
essential for success.

ÊëòË¶ÅÔºöÊúÄËøëÂú®ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÁöÑ‰∫∫Â∑•Êô∫ÊÖßÊáâÁî®ÈÄ≤Â±ïÈ°ØÁ§∫Âá∫‰ª§‰∫∫Èõ£‰ª•ÁΩÆ‰ø°ÁöÑÊâøË´æÔºåÂú®Ë®∫Êñ∑ÂíåÁñæÁóÖÈ†êÂæåÊñπÈù¢Ë∂ÖË∂ä‰∫∫È°ûË°®Áèæ„ÄÇÁÑ∂ËÄåÔºåÈö®Ëëó‰∫∫Â∑•Êô∫ËÉΩÊ®°ÂûãÁöÑÊó•ÁõäË§áÈõúÔºå‰∫∫ÂÄëÂ∞çÂÖ∂‰∏çÈÄèÊòéÊÄß„ÄÅÊΩõÂú®ÂÅèÂ∑ÆÂíåÂ∞çÂèØËß£ÈáãÊÄßÁöÑÈúÄÊ±ÇÊÑüÂà∞ÊìîÊÜÇ„ÄÇÁÇ∫‰∫ÜÁ¢∫‰øù‰∫∫Â∑•Êô∫ËÉΩÁ≥ªÁµ±ÁöÑ‰ø°‰ªªÂíåÂèØÈù†ÊÄßÔºåÂ∞§ÂÖ∂ÊòØÂú®Ëá®Â∫äÈ¢®Èö™È†êÊ∏¨Ê®°Âûã‰∏≠ÔºåÂèØËß£ÈáãÊÄßËÆäÂæóËá≥ÈóúÈáçË¶Å„ÄÇÂèØËß£ÈáãÊÄßÈÄöÂ∏∏Ë¢´Á®±ÁÇ∫‰∫∫Â∑•Êô∫ËÉΩÁ≥ªÁµ±Êèê‰æõÂÖ∂Ê±∫Á≠ñÈÇèËºØÊàñÊ±∫Á≠ñÊú¨Ë∫´Â∞ç‰∫∫È°ûÂà©ÁõäÁõ∏ÈóúËÄÖÁöÑÂº∑ÊúâÂäõËß£ÈáãÁöÑËÉΩÂäõ„ÄÇÂú®Ëá®Â∫äÈ¢®Èö™È†êÊ∏¨‰∏≠ÔºåÂèØËß£ÈáãÊÄßÁöÑÂÖ∂‰ªñÊñπÈù¢ÔºåÂ¶ÇÂÖ¨Âπ≥ÊÄß„ÄÅÂÅèË¶ã„ÄÅ‰ø°‰ªªÂíåÈÄèÊòéÂ∫¶Ôºå‰πü‰ª£Ë°®‰∫ÜË∂ÖË∂äÂèØËß£ÈáãÊÄßÁöÑÈáçË¶ÅÊ¶ÇÂøµ„ÄÇÂú®Êú¨Ê¨°ÂØ©Êü•‰∏≠ÔºåÊàëÂÄëÊé¢Ë®é‰∫ÜÈÄô‰∫õÊ¶ÇÂøµ‰πãÈñìÁöÑÈóú‰øÇÔºåÂõ†ÁÇ∫ÂÆÉÂÄëÁ∂ìÂ∏∏‰∏ÄËµ∑Êàñ‰∫íÊèõ‰ΩøÁî®„ÄÇÊú¨ÂØ©Êü•ÈÇÑË®éË´ñ‰∫ÜÁÇ∫Ëá®Â∫äÈ¢®Èö™È†êÊ∏¨ÈñãÁôºÂèØËß£ÈáãÊ®°ÂûãÁöÑÊúÄÊñ∞ÈÄ≤Â±ïÔºåÂº∑Ë™ø‰∫ÜÂú®Ëá®Â∫äÂØ¶Ë∏ê‰∏≠Â∞çÂ§öÁ®ÆÂ∏∏Ë¶ãÊ®°ÂºèÈÄ≤Ë°åÂÆöÈáèÂíåËá®Â∫äË©ï‰º∞ÂíåÈ©óË≠âÁöÑÈáçË¶ÅÊÄß„ÄÇÂÆÉÂº∑Ë™ø‰∫ÜÂ§ñÈÉ®È©óË≠âÂíåÂ§öÊ®£ÂåñÂèØËß£ÈáãÊÄßÊñπÊ≥ïÁõ∏ÁµêÂêàÁöÑÂøÖË¶ÅÊÄßÔºå‰ª•Â¢ûÂº∑‰ø°‰ªªÂíåÂÖ¨Âπ≥ÊÄß„ÄÇÊé°Áî®Âö¥Ê†ºÁöÑÊ∏¨Ë©¶Ôºå‰æãÂ¶Ç‰ΩøÁî®ÂÖ∑ÊúâÂ∑≤Áü•ÁîüÊàêÂõ†Á¥†ÁöÑÂêàÊàêÊï∏ÊìöÈõÜÔºåÂèØ‰ª•ÈÄ≤‰∏ÄÊ≠•ÊèêÈ´òÂèØËß£ÈáãÊÄßÊñπÊ≥ïÁöÑÂèØÈù†ÊÄß„ÄÇÈñãÊîæÁç≤ÂèñÂíå‰ª£Á¢ºÂÖ±‰∫´Ë≥áÊ∫êÂ∞çÊñºÈÄèÊòéÂ∫¶ÂíåÂèØÈáçË§áÊÄßËá≥ÈóúÈáçË¶ÅÔºåÂæûËÄå‰øÉÈÄ≤ÂèØËß£ÈáãÁ†îÁ©∂ÁöÑÂ¢ûÈï∑ÂíåÂèØ‰ø°Â∫¶„ÄÇÂÑòÁÆ°Â≠òÂú®ÊåëÊà∞Ôºå‰ΩÜÂæûËá®Â∫äÈÜ´ÁîüÂà∞ÈñãÁôº‰∫∫Âì°ÔºåÊé°Áî®Á´ØÂà∞Á´ØÁöÑÂèØËß£ÈáãÊÄßÊñπÊ≥ïÂ∞çÊñºËá®Â∫äÈ¢®Èö™È†êÊ∏¨ÁöÑÊàêÂäüËá≥ÈóúÈáçË¶Å„ÄÇ

##### **FUTURE-AI: International consensus guideline for trustworthy and deployable artificial intelligence in healthcare**
2309.12325v3 by Karim Lekadir, Aasa Feragen, Abdul Joseph Fofanah, Alejandro F Frangi, Alena Buyx, Anais Emelie, Andrea Lara, Antonio R Porras, An-Wen Chan, Arcadi Navarro, Ben Glocker, Benard O Botwe, Bishesh Khanal, Brigit Beger, Carol C Wu, Celia Cintas, Curtis P Langlotz, Daniel Rueckert, Deogratias Mzurikwao, Dimitrios I Fotiadis, Doszhan Zhussupov, Enzo Ferrante, Erik Meijering, Eva Weicken, Fabio A Gonz√°lez, Folkert W Asselbergs, Fred Prior, Gabriel P Krestin, Gary Collins, Geletaw S Tegenaw, Georgios Kaissis, Gianluca Misuraca, Gianna Tsakou, Girish Dwivedi, Haridimos Kondylakis, Harsha Jayakody, Henry C Woodruf, Horst Joachim Mayer, Hugo JWL Aerts, Ian Walsh, Ioanna Chouvarda, Ir√®ne Buvat, Isabell Tributsch, Islem Rekik, James Duncan, Jayashree Kalpathy-Cramer, Jihad Zahir, Jinah Park, John Mongan, Judy W Gichoya, Julia A Schnabel, Kaisar Kushibar, Katrine Riklund, Kensaku Mori, Kostas Marias, Lameck M Amugongo, Lauren A Fromont, Lena Maier-Hein, Leonor Cerd√° Alberich, Leticia Rittner, Lighton Phiri, Linda Marrakchi-Kacem, Llu√≠s Donoso-Bach, Luis Mart√≠-Bonmat√≠, M Jorge Cardoso, Maciej Bobowicz, Mahsa Shabani, Manolis Tsiknakis, Maria A Zuluaga, Maria Bielikova, Marie-Christine Fritzsche, Marina Camacho, Marius George Linguraru, Markus Wenzel, Marleen De Bruijne, Martin G Tolsgaard, Marzyeh Ghassemi, Md Ashrafuzzaman, Melanie Goisauf, Mohammad Yaqub, M√≥nica Cano Abad√≠a, Mukhtar M E Mahmoud, Mustafa Elattar, Nicola Rieke, Nikolaos Papanikolaou, Noussair Lazrak, Oliver D√≠az, Olivier Salvado, Oriol Pujol, Ousmane Sall, Pamela Guevara, Peter Gordebeke, Philippe Lambin, Pieta Brown, Purang Abolmaesumi, Qi Dou, Qinghua Lu, Richard Osuala, Rose Nakasi, S Kevin Zhou, Sandy Napel, Sara Colantonio, Shadi Albarqouni, Smriti Joshi, Stacy Carter, Stefan Klein, Steffen E Petersen, Susanna Auss√≥, Suyash Awate, Tammy Riklin Raviv, Tessa Cook, Tinashe E M Mutsvangwa, Wendy A Rogers, Wiro J Niessen, X√®nia Puig-Bosch, Yi Zeng, Yunusa G Mohammed, Yves Saint James Aquino, Zohaib Salahuddin, Martijn P A Starmans

Despite major advances in artificial intelligence (AI) for medicine and
healthcare, the deployment and adoption of AI technologies remain limited in
real-world clinical practice. In recent years, concerns have been raised about
the technical, clinical, ethical and legal risks associated with medical AI. To
increase real world adoption, it is essential that medical AI tools are trusted
and accepted by patients, clinicians, health organisations and authorities.
This work describes the FUTURE-AI guideline as the first international
consensus framework for guiding the development and deployment of trustworthy
AI tools in healthcare. The FUTURE-AI consortium was founded in 2021 and
currently comprises 118 inter-disciplinary experts from 51 countries
representing all continents, including AI scientists, clinicians, ethicists,
and social scientists. Over a two-year period, the consortium defined guiding
principles and best practices for trustworthy AI through an iterative process
comprising an in-depth literature review, a modified Delphi survey, and online
consensus meetings. The FUTURE-AI framework was established based on 6 guiding
principles for trustworthy AI in healthcare, i.e. Fairness, Universality,
Traceability, Usability, Robustness and Explainability. Through consensus, a
set of 28 best practices were defined, addressing technical, clinical, legal
and socio-ethical dimensions. The recommendations cover the entire lifecycle of
medical AI, from design, development and validation to regulation, deployment,
and monitoring. FUTURE-AI is a risk-informed, assumption-free guideline which
provides a structured approach for constructing medical AI tools that will be
trusted, deployed and adopted in real-world practice. Researchers are
encouraged to take the recommendations into account in proof-of-concept stages
to facilitate future translation towards clinical practice of medical AI.

ÊëòË¶ÅÔºöÂÑòÁÆ°Âú®ÈÜ´Â≠∏ÂíåÈÜ´ÁôÇ‰øùÂÅ•ÊñπÈù¢ÁöÑ‰∫∫Â∑•Êô∫ÊÖß (AI) ÊúâÈáçÂ§ßÁöÑÈÄ≤Â±ïÔºå‰ΩÜ AI ÊäÄË°ìÁöÑÈÉ®ÁΩ≤ÂíåÊé°Áî®Âú®ÁèæÂØ¶‰∏ñÁïåÁöÑËá®Â∫äÂØ¶Âãô‰∏≠‰ªçÁÑ∂ÊúâÈôê„ÄÇËøëÂπ¥‰æÜÔºå‰∫∫ÂÄëÂ∞çÊñºËàáÈÜ´ÁôÇ AI Áõ∏ÈóúÁöÑÊäÄË°ì„ÄÅËá®Â∫ä„ÄÅÂÄ´ÁêÜÂíåÊ≥ïÂæãÈ¢®Èö™ÊèêÂá∫‰∫ÜÁñëÊÖÆ„ÄÇÁÇ∫‰∫ÜÂ¢ûÂä†ÁèæÂØ¶‰∏ñÁïåÁöÑÊé°Áî®ÁéáÔºåÈÜ´ÁôÇ AI Â∑•ÂÖ∑ÂøÖÈ†àÁç≤ÂæóÊÇ£ËÄÖ„ÄÅËá®Â∫äÈÜ´Áîü„ÄÅÈÜ´ÁôÇÊ©üÊßãÂíåÁï∂Â±ÄÁöÑ‰ø°‰ªªÂíåÊé•Âèó„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÂ∞á FUTURE-AI ÊåáÂçóÊèèËø∞ÁÇ∫ÊåáÂ∞éÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÂèØ‰ø°Ë≥¥ AI Â∑•ÂÖ∑ÈñãÁôºÂíåÈÉ®ÁΩ≤ÁöÑÁ¨¨‰∏ÄÂÄãÂúãÈöõÂÖ±Ë≠òÊû∂Êßã„ÄÇFUTURE-AI ËÅØÁõüÊàêÁ´ãÊñº 2021 Âπ¥ÔºåÁõÆÂâçÁî±‰æÜËá™ 51 ÂÄãÂúãÂÆ∂ÁöÑ 118 ‰ΩçË∑®È†òÂüüÂ∞àÂÆ∂ÁµÑÊàêÔºå‰ª£Ë°®ÊâÄÊúâÊ¥≤ÔºåÂåÖÊã¨ AI ÁßëÂ≠∏ÂÆ∂„ÄÅËá®Â∫äÈÜ´Áîü„ÄÅÂÄ´ÁêÜÂ≠∏ÂÆ∂ÂíåÁ§æÊúÉÁßëÂ≠∏ÂÆ∂„ÄÇÂú®ÂÖ©Âπ¥ÁöÑÊôÇÈñìË£°ÔºåË©≤ËÅØÁõüÈÄöÈÅé‰∏ÄÂÄãÂèçË¶ÜÈÅãÁÆóÁöÑÈÅéÁ®ãÂÆöÁæ©‰∫ÜÂèØ‰ø°Ë≥¥ AI ÁöÑÊåáÂ∞éÂéüÂâáÂíåÊúÄ‰Ω≥ÂØ¶ÂãôÔºåÂåÖÊã¨Ê∑±ÂÖ•ÁöÑÊñáÁçªÂõûÈ°ß„ÄÅ‰øÆÊîπÂæåÁöÑÂæ∑ÁàæËè≤Ë™øÊü•ÂíåÁ∑ö‰∏äÂÖ±Ë≠òÊúÉË≠∞„ÄÇFUTURE-AI Êû∂ÊßãÊòØÂü∫ÊñºÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÂèØ‰ø°Ë≥¥ AI ÁöÑ 6 È†ÖÊåáÂ∞éÂéüÂâáÂª∫Á´ãÁöÑÔºåÂç≥ÂÖ¨Âπ≥ÊÄß„ÄÅÊôÆÈÅçÊÄß„ÄÅÂèØËøΩÊ∫ØÊÄß„ÄÅÂèØÁî®ÊÄß„ÄÅÁ©©ÂÅ•ÊÄßÂíåÂèØËß£ÈáãÊÄß„ÄÇÈÄöÈÅéÂÖ±Ë≠òÔºåÂÆöÁæ©‰∫Ü‰∏ÄÁµÑ 28 È†ÖÊúÄ‰Ω≥ÂØ¶ÂãôÔºåÊ∂µËìãÊäÄË°ì„ÄÅËá®Â∫ä„ÄÅÊ≥ïÂæãÂíåÁ§æÊúÉÂÄ´ÁêÜÂ±§Èù¢„ÄÇÂª∫Ë≠∞Ê∂µËìã‰∫ÜÈÜ´ÁôÇ AI ÁöÑÊï¥ÂÄãÁîüÂëΩÈÄ±ÊúüÔºåÂæûË®≠Ë®à„ÄÅÈñãÁôºÂíåÈ©óË≠âÂà∞Ê≥ïË¶è„ÄÅÈÉ®ÁΩ≤ÂíåÁõ£Êéß„ÄÇFUTURE-AI ÊòØ‰∏ÄÂÄãÂü∫ÊñºÈ¢®Èö™„ÄÅÁÑ°ÂÅáË®≠ÁöÑÊåáÂçóÔºåÊèê‰æõ‰∫Ü‰∏ÄÂÄãÁµêÊßãÂåñÁöÑÊñπÊ≥ïÔºåÁî®ÊñºÂª∫ÊßãÂ∞áÂú®ÁèæÂØ¶‰∏ñÁïåÂØ¶Âãô‰∏≠ÂèóÂà∞‰ø°‰ªª„ÄÅÈÉ®ÁΩ≤ÂíåÊé°Áî®ÁöÑÈÜ´ÁôÇ AI Â∑•ÂÖ∑„ÄÇÈºìÂãµÁ†îÁ©∂‰∫∫Âì°Âú®Ê¶ÇÂøµÈ©óË≠âÈöéÊÆµËÄÉÊÖÆÈÄô‰∫õÂª∫Ë≠∞Ôºå‰ª•‰øÉÈÄ≤Êú™‰æÜÂ∞áÈÜ´ÁôÇ AI ËΩâÂåñÁÇ∫Ëá®Â∫äÂØ¶Âãô„ÄÇ

##### **Explainable AI applications in the Medical Domain: a systematic review**
2308.05411v1 by Nicoletta Prentzas, Antonis Kakas, Constantinos S. Pattichis

Artificial Intelligence in Medicine has made significant progress with
emerging applications in medical imaging, patient care, and other areas. While
these applications have proven successful in retrospective studies, very few of
them were applied in practice.The field of Medical AI faces various challenges,
in terms of building user trust, complying with regulations, using data
ethically.Explainable AI (XAI) aims to enable humans understand AI and trust
its results. This paper presents a literature review on the recent developments
of XAI solutions for medical decision support, based on a representative sample
of 198 articles published in recent years. The systematic synthesis of the
relevant articles resulted in several findings. (1) model-agnostic XAI
techniques were mostly employed in these solutions, (2) deep learning models
are utilized more than other types of machine learning models, (3)
explainability was applied to promote trust, but very few works reported the
physicians participation in the loop, (4) visual and interactive user interface
is more useful in understanding the explanation and the recommendation of the
system. More research is needed in collaboration between medical and AI
experts, that could guide the development of suitable frameworks for the
design, implementation, and evaluation of XAI solutions in medicine.

ÊëòË¶ÅÔºö‰∫∫Â∑•Êô∫ÊÖßÂú®ÈÜ´ÁôÇÈ†òÂüü‰∏≠Â∑≤ÂèñÂæóÈ°ØËëóÈÄ≤Â±ïÔºåÂú®ÈÜ´Â≠∏ÂΩ±ÂÉè„ÄÅÁóÖ‰∫∫ÁÖßË≠∑ÂíåÂÖ∂‰ªñÈ†òÂüü‰∏≠Âá∫Áèæ‰∫ÜÊñ∞ËààÊáâÁî®„ÄÇÈõñÁÑ∂ÈÄô‰∫õÊáâÁî®Â∑≤Âú®ÂõûÈ°ßÊÄßÁ†îÁ©∂‰∏≠Ë¢´Ë≠âÂØ¶ÊòØÊàêÂäüÁöÑÔºå‰ΩÜÂØ¶Èöõ‰∏äÂè™ÊúâÊ•µÂ∞ëÊï∏ÊáâÁî®ÊñºÂØ¶Âãô„ÄÇÈÜ´ÁôÇ AI È†òÂüüÈù¢Ëá®ËëóÂêÑÁ®ÆÊåëÊà∞ÔºåÂåÖÊã¨Âª∫Á´ã‰ΩøÁî®ËÄÖ‰ø°‰ªª„ÄÅÈÅµÂÆàÊ≥ïË¶è„ÄÅ‰ΩøÁî®Ë≥áÊñôÁ¨¶ÂêàÂÄ´ÁêÜ„ÄÇÂèØËß£Èáã AI (XAI) ÁöÑÁõÆÊ®ôÊòØËÆì‰∫∫È°û‰∫ÜËß£ AI ‰∏¶Áõ∏‰ø°ÂÖ∂ÁµêÊûú„ÄÇÊú¨ÊñáÈáùÂ∞çÊúÄËøëÂπæÂπ¥ÁôºË°®ÁöÑ 198 ÁØáÊñáÁ´†ÁöÑÂÖ∑‰ª£Ë°®ÊÄßÊ®£Êú¨ÔºåÊèêÂá∫ÊúâÈóúÈÜ´ÁôÇÊ±∫Á≠ñÊîØÊè¥ÁöÑ XAI Ëß£Ê±∫ÊñπÊ°àÁöÑÊúÄÊñ∞ÁôºÂ±ïÁöÑÊñáÁçªÂõûÈ°ß„ÄÇÁõ∏ÈóúÊñáÁ´†ÁöÑÁ≥ªÁµ±ÊÄßÁ∂úÂêàÊï¥ÁêÜÁî¢Áîü‰∫ÜÂ§öÈ†ÖÁôºÁèæÔºö(1) ÈÄô‰∫õËß£Ê±∫ÊñπÊ°àÂ§ßÂ§öÊé°Áî®ËàáÊ®°ÂûãÁÑ°ÈóúÁöÑ XAI ÊäÄË°ìÔºå(2) Ê∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÁöÑ‰ΩøÁî®ÁéáÈ´òÊñºÂÖ∂‰ªñÈ°ûÂûãÁöÑÊ©üÂô®Â≠∏ÁøíÊ®°ÂûãÔºå(3) ÂèØËß£ÈáãÊÄßË¢´Áî®Êñº‰øÉÈÄ≤‰ø°‰ªªÔºå‰ΩÜÂæàÂ∞ëÊúâÁ†îÁ©∂Â†±ÂëäÈÜ´Â∏´ÂèÉËàáËø¥ÂúàÔºå(4) Ë¶ñË¶∫Âíå‰∫íÂãïÂºè‰ΩøÁî®ËÄÖ‰ªãÈù¢Â∞çÊñºÁêÜËß£Á≥ªÁµ±ÁöÑËß£ÈáãÂíåÂª∫Ë≠∞Êõ¥ÊúâÁî®„ÄÇÈúÄË¶ÅÊõ¥Â§öÈÜ´ÁôÇÂíå AI Â∞àÂÆ∂Âêà‰ΩúÈÄ≤Ë°åÁ†îÁ©∂ÔºåÈÄôÊúâÂä©ÊñºÁÇ∫ÈÜ´ÁôÇÈ†òÂüüÁöÑ XAI Ëß£Ê±∫ÊñπÊ°àÁöÑË®≠Ë®à„ÄÅÂØ¶‰ΩúÂíåË©ï‰º∞Êèê‰æõÈÅ©Áï∂Êû∂Êßã„ÄÇ

##### **Exploring the Role of Explainability in AI-Assisted Embryo Selection**
2308.02534v1 by Lucia Urcelay, Daniel Hinjos, Pablo A. Martin-Torres, Marta Gonzalez, Marta Mendez, Salva C√≠vico, Sergio √Ålvarez-Napagao, Dario Garcia-Gasulla

In Vitro Fertilization is among the most widespread treatments for
infertility. One of its main challenges is the evaluation and selection of
embryo for implantation, a process with large inter- and intra-clinician
variability. Deep learning based methods are gaining attention, but their
opaque nature compromises their acceptance in the clinical context, where
transparency in the decision making is key. In this paper we analyze the
current work in the explainability of AI-assisted embryo analysis models,
identifying the limitations. We also discuss how these models could be
integrated in the clinical context as decision support systems, considering the
needs of clinicians and patients. Finally, we propose guidelines for the sake
of increasing interpretability and trustworthiness, pushing this technology
forward towards established clinical practice.

ÊëòË¶ÅÔºöÈ´îÂ§ñÂèóÁ≤æÊòØÊ≤ªÁôÇ‰∏çÂ≠ïÁóáÊúÄÂª£Ê≥õÁöÑÊñπÊ≥ï‰πã‰∏Ä„ÄÇÂÖ∂‰∏ªË¶ÅÊåëÊà∞‰πã‰∏ÄÊòØË©ï‰º∞ÂíåÈÅ∏ÊìáËÉöËÉéÈÄ≤Ë°åÊ§çÂÖ•ÔºåÊ≠§ÈÅéÁ®ãÂÖ∑ÊúâÂæàÂ§ßÁöÑËá®Â∫äÈñìÂíåËá®Â∫äÂÖßËÆäÁï∞ÊÄß„ÄÇÂü∫ÊñºÊ∑±Â∫¶Â≠∏ÁøíÁöÑÊñπÊ≥ïÊ≠£ÂèóÂà∞ÈóúÊ≥®Ôºå‰ΩÜÂÖ∂‰∏çÈÄèÊòéÁöÑÊÄßË≥™ÊúÉÂΩ±ÈüøÂÖ∂Âú®Ëá®Â∫äÁí∞Â¢É‰∏≠ÁöÑÊé•ÂèóÂ∫¶ÔºåËÄåÈÄèÊòéÂ∫¶Âú®Ê±∫Á≠ñÂà∂ÂÆö‰∏≠Ëá≥ÈóúÈáçË¶Å„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂàÜÊûê‰∫Ü AI ËºîÂä©ËÉöËÉéÂàÜÊûêÊ®°ÂûãÁöÑÂèØËß£ÈáãÊÄßÊñπÈù¢ÁöÑÁèæÊúâÂ∑•‰ΩúÔºå‰∏¶ÊâæÂá∫ÂÖ∂Â±ÄÈôêÊÄß„ÄÇÊàëÂÄëÈÇÑË®éË´ñ‰∫ÜÂ¶Ç‰ΩïÂ∞áÈÄô‰∫õÊ®°Âûã‰ΩúÁÇ∫Ê±∫Á≠ñÊîØÊåÅÁ≥ªÁµ±Êï¥ÂêàÂà∞Ëá®Â∫äÁí∞Â¢É‰∏≠ÔºåÂêåÊôÇËÄÉÊÖÆËá®Â∫äÈÜ´ÁîüÂíåÊÇ£ËÄÖÁöÑÈúÄÊ±Ç„ÄÇÊúÄÂæåÔºåÊàëÂÄëÊèêÂá∫‰∫ÜÊèêÈ´òÂèØËß£ÈáãÊÄßÂíåÂèØ‰ø°Â∫¶ÁöÑÊ∫ñÂâáÔºåÊé®ÈÄ≤ÈÄôÈ†ÖÊäÄË°ìÊúùËëóÊó¢ÂÆöÁöÑËá®Â∫äÂØ¶ÂãôÈÇÅÈÄ≤„ÄÇ

##### **A New Perspective on Evaluation Methods for Explainable Artificial Intelligence (XAI)**
2307.14246v1 by Timo Speith, Markus Langer

Within the field of Requirements Engineering (RE), the increasing
significance of Explainable Artificial Intelligence (XAI) in aligning
AI-supported systems with user needs, societal expectations, and regulatory
standards has garnered recognition. In general, explainability has emerged as
an important non-functional requirement that impacts system quality. However,
the supposed trade-off between explainability and performance challenges the
presumed positive influence of explainability. If meeting the requirement of
explainability entails a reduction in system performance, then careful
consideration must be given to which of these quality aspects takes precedence
and how to compromise between them. In this paper, we critically examine the
alleged trade-off. We argue that it is best approached in a nuanced way that
incorporates resource availability, domain characteristics, and considerations
of risk. By providing a foundation for future research and best practices, this
work aims to advance the field of RE for AI.

ÊëòË¶ÅÔºöÂú®ÈúÄÊ±ÇÂ∑•Á®ã (RE) È†òÂüü‰∏≠ÔºåÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖß (XAI) Âú®Â∞á AI ÊîØÊåÅÁöÑÁ≥ªÁµ±Ëàá‰ΩøÁî®ËÄÖÈúÄÊ±Ç„ÄÅÁ§æÊúÉÊúüÊúõÂíåÊ≥ïË¶èÊ®ôÊ∫ñÁõ∏Á¨¶ÊñπÈù¢ÁöÑÈáçË¶ÅÊÄßÊó•ÁõäÈ°ØËëóÔºåÂ∑≤Áç≤ÂæóË™çÂèØ„ÄÇ‰∏ÄËà¨‰æÜË™™ÔºåÂèØËß£ÈáãÊÄßÂ∑≤ÊàêÁÇ∫ÂΩ±ÈüøÁ≥ªÁµ±ÂìÅË≥™ÁöÑÈáçË¶ÅÈùûÂäüËÉΩÈúÄÊ±Ç„ÄÇÁÑ∂ËÄåÔºåÂèØËß£ÈáãÊÄßËàáÊïàËÉΩ‰πãÈñìÁöÑÂÅáÂÆöÊ¨äË°°ÊåëÊà∞‰∫ÜÂèØËß£ÈáãÊÄßÁöÑÂÅáÂÆöÊ≠£Èù¢ÂΩ±Èüø„ÄÇÂ¶ÇÊûúÊªøË∂≥ÂèØËß£ÈáãÊÄßÁöÑÈúÄÊ±ÇÈúÄË¶ÅÈôç‰ΩéÁ≥ªÁµ±ÊïàËÉΩÔºåÈÇ£È∫ºÂøÖÈ†à‰ªîÁ¥∞ËÄÉÊÖÆÈÄô‰∫õÂìÅË≥™Èù¢Âêë‰∏≠Âì™‰∏ÄÂÄãÂÑ™ÂÖàÔºå‰ª•ÂèäÂ¶Ç‰ΩïÂú®ÂÆÉÂÄë‰πãÈñìÈÄ≤Ë°åÊäòË°∑„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊâπÂà§ÊÄßÂú∞Êé¢Ë®é‰∫ÜÈÄôÁ®ÆÂÅáÂÆöÁöÑÊ¨äË°°„ÄÇÊàëÂÄëË™çÁÇ∫ÔºåÊúÄÂ•ΩÁöÑÊñπÊ≥ïÊòØ‰ª•‰∏ÄÁ®ÆÁ¥∞Á∑ªÁöÑÊñπÂºè‰æÜËôïÁêÜÔºåÈÄôÁ®ÆÊñπÂºèÂåÖÂê´Ë≥áÊ∫êÂèØÁî®ÊÄß„ÄÅÈ†òÂüüÁâπÊÄßÂíåÈ¢®Èö™ËÄÉÈáè„ÄÇÈÄèÈÅéÊèê‰æõÊú™‰æÜÁ†îÁ©∂ÂíåÊúÄ‰Ω≥ÂØ¶ÂãôÁöÑÂü∫Á§éÔºåÈÄôÈ†ÖÂ∑•‰ΩúÊó®Âú®ÊèêÂçá AI ÁöÑ RE È†òÂüü„ÄÇ

##### **Revisiting the Performance-Explainability Trade-Off in Explainable Artificial Intelligence (XAI)**
2307.14239v1 by Barnaby Crook, Maximilian Schl√ºter, Timo Speith

Within the field of Requirements Engineering (RE), the increasing
significance of Explainable Artificial Intelligence (XAI) in aligning
AI-supported systems with user needs, societal expectations, and regulatory
standards has garnered recognition. In general, explainability has emerged as
an important non-functional requirement that impacts system quality. However,
the supposed trade-off between explainability and performance challenges the
presumed positive influence of explainability. If meeting the requirement of
explainability entails a reduction in system performance, then careful
consideration must be given to which of these quality aspects takes precedence
and how to compromise between them. In this paper, we critically examine the
alleged trade-off. We argue that it is best approached in a nuanced way that
incorporates resource availability, domain characteristics, and considerations
of risk. By providing a foundation for future research and best practices, this
work aims to advance the field of RE for AI.

ÊëòË¶ÅÔºöÂú®ÈúÄÊ±ÇÂ∑•Á®ãÔºàREÔºâÈ¢ÜÂüüÔºåÂèØËß£Èáä‰∫∫Â∑•Êô∫ËÉΩÔºàXAIÔºâÂú®Â∞Ü‰∫∫Â∑•Êô∫ËÉΩÊîØÊåÅÁöÑÁ≥ªÁªü‰∏éÁî®Êà∑ÈúÄÊ±Ç„ÄÅÁ§æ‰ºöÊúüÊúõÂíåÁõëÁÆ°Ê†áÂáÜÁõ∏‰∏ÄËá¥ÊñπÈù¢ÁöÑÈáçË¶ÅÊÄßÊó•ÁõäÂá∏ÊòæÔºåÂπ∂Ëé∑Âæó‰∫ÜËÆ§ÂèØ„ÄÇ‰∏ÄËà¨Êù•ËØ¥ÔºåÂèØËß£ÈáäÊÄßÂ∑≤Êàê‰∏∫ÂΩ±ÂìçÁ≥ªÁªüË¥®ÈáèÁöÑÈáçË¶ÅÈùûÂäüËÉΩÊÄßÈúÄÊ±Ç„ÄÇÁÑ∂ËÄåÔºåÂèØËß£ÈáäÊÄßÂíåÊÄßËÉΩ‰πãÈó¥ÁöÑÊùÉË°°ÊåëÊàò‰∫ÜÂèØËß£ÈáäÊÄßÁöÑÊ≠£Èù¢ÂΩ±Âìç„ÄÇÂ¶ÇÊûúÊª°Ë∂≥ÂèØËß£ÈáäÊÄßÁöÑË¶ÅÊ±ÇÈúÄË¶ÅÈôç‰ΩéÁ≥ªÁªüÊÄßËÉΩÔºåÈÇ£‰πàÂøÖÈ°ª‰ªîÁªÜËÄÉËôëËøô‰∫õË¥®ÈáèÊñπÈù¢‰∏≠ÁöÑÂì™‰∏Ä‰∏™‰ºòÂÖàÔºå‰ª•ÂèäÂ¶Ç‰ΩïÂú®ÂÆÉ‰ª¨‰πãÈó¥ËøõË°åÊùÉË°°„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨ÊâπÂà§ÊÄßÂú∞ËÄÉÂØü‰∫ÜÊâÄË∞ìÁöÑÊùÉË°°„ÄÇÊàë‰ª¨ËÆ§‰∏∫ÔºåÊúÄÂ•Ω‰ª•‰∏ÄÁßçÁªÜËá¥ÂÖ•ÂæÆÁöÑÊñπÂºèÊù•Â§ÑÁêÜÂÆÉÔºåËøôÁßçÊñπÂºèÁªìÂêà‰∫ÜËµÑÊ∫êÂèØÁî®ÊÄß„ÄÅÈ¢ÜÂüüÁâπÂæÅÂíåÈ£éÈô©ËÄÉËôë„ÄÇÈÄöËøá‰∏∫Êú™Êù•ÁöÑÁ†îÁ©∂ÂíåÊúÄ‰Ω≥ÂÆûË∑µÊèê‰æõÂü∫Á°ÄÔºåËøôÈ°πÂ∑•‰ΩúÊó®Âú®Êé®Ëøõ‰∫∫Â∑•Êô∫ËÉΩÁöÑ RE È¢ÜÂüü„ÄÇ

##### **Acceptable risks in Europe's proposed AI Act: Reasonableness and other principles for deciding how much risk management is enough**
2308.02047v1 by Henry Fraser, Jose-Miguel Bello y Villarino

This paper critically evaluates the European Commission's proposed AI Act's
approach to risk management and risk acceptability for high-risk AI systems
that pose risks to fundamental rights and safety. The Act aims to promote
"trustworthy" AI with a proportionate regulatory burden. Its provisions on risk
acceptability require residual risks from high-risk systems to be reduced or
eliminated "as far as possible", having regard to the "state of the art". This
criterion, especially if interpreted narrowly, is unworkable and promotes
neither proportionate regulatory burden, nor trustworthiness. By contrast the
Parliament's most recent draft amendments to the risk management provisions
introduce "reasonableness", cost-benefit analysis, and are more transparent
about the value-laden and contextual nature of risk acceptability judgements.
This paper argues that the Parliament's approach is more workable, and better
balances the goals of proportionality and trustworthiness. It explains what
reasonableness in risk acceptability judgments would entail, drawing on
principles from negligence law and European medical devices regulation. And it
contends that the approach to risk acceptability judgments need a firm
foundation of civic legitimacy: including detailed guidance or involvement from
regulators, and meaningful input from affected stakeholders.

ÊëòË¶ÅÔºöÊú¨ÊñáÂö¥Ê†ºË©ï‰º∞Ê≠êÊ¥≤ÂßîÂì°ÊúÉÊèêÂá∫ÁöÑ AI Ê≥ïÊ°àÂ∞çÈ¢®Èö™ÁÆ°ÁêÜÂíåÈ¢®Èö™ÂèØÊé•ÂèóÊÄßÁöÑÊñπÊ≥ïÔºåÁî®ÊñºÂ∞çÂü∫Êú¨Ê¨äÂà©ÂíåÂÆâÂÖ®ÊßãÊàêÈ¢®Èö™ÁöÑÈ´òÈ¢®Èö™ AI Á≥ªÁµ±„ÄÇË©≤Ê≥ïÊ°àÊó®Âú®‰ª•Áõ∏Á®±ÁöÑÁõ£ÁÆ°Ë≤†Êìî‰øÉÈÄ≤„ÄåÂÄºÂæó‰ø°Ë≥¥„ÄçÁöÑ AI„ÄÇÂÖ∂ÈóúÊñºÈ¢®Èö™ÂèØÊé•ÂèóÊÄßÁöÑÊ¢ùÊ¨æË¶ÅÊ±ÇÂ∞áÈ´òÈ¢®Èö™Á≥ªÁµ±ÁöÑÊÆòÈ§òÈ¢®Èö™Ê∏õ‰ΩéÊàñÊ∂àÈô§„ÄåÁõ°ÂèØËÉΩ„ÄçÔºå‰∏¶ËÄÉÊÖÆ„ÄåÊäÄË°ìÁãÄÊÖã„Äç„ÄÇÊ≠§Ê∫ñÂâáÔºåÁâπÂà•ÊòØÂ¶ÇÊûúÁãπÁæ©Ëß£ÈáãÔºåÁÑ°Ê≥ïÂü∑Ë°åÔºåÊó¢‰∏ç‰øÉÈÄ≤Áõ∏Á®±ÁöÑÁõ£ÁÆ°Ë≤†ÊìîÔºå‰πü‰∏ç‰øÉÈÄ≤ÂèØ‰ø°Ë≥¥ÊÄß„ÄÇÁõ∏ÊØî‰πã‰∏ãÔºåË≠∞ÊúÉÂ∞çÈ¢®Èö™ÁÆ°ÁêÜÊ¢ùÊ¨æÁöÑÊúÄÊñ∞‰øÆÊ≠£ËçâÊ°àÂºïÂÖ•‰∫Ü„ÄåÂêàÁêÜÊÄß„Äç„ÄÅÊàêÊú¨ÊïàÁõäÂàÜÊûêÔºå‰∏¶‰∏îÊõ¥ÈÄèÊòéÂú∞Ë™™Êòé‰∫ÜÈ¢®Èö™ÂèØÊé•ÂèóÊÄßÂà§Êñ∑ÁöÑÂÉπÂÄºËßÄÂíåËÉåÊôØÊÄßË≥™„ÄÇÊú¨ÊñáË´ñË≠âË≠∞ÊúÉÁöÑÊñπÊ≥ïÊõ¥ÂèØË°åÔºå‰∏îËÉΩÊõ¥Â•ΩÂú∞Âπ≥Ë°°Áõ∏Á®±ÊÄßÂíåÂèØ‰ø°Ë≥¥ÊÄßÁöÑÁõÆÊ®ô„ÄÇÊú¨ÊñáË™™ÊòéÈ¢®Èö™ÂèØÊé•ÂèóÊÄßÂà§Êñ∑‰∏≠ÁöÑÂêàÁêÜÊÄßÊúÉÂ∏∂‰æÜ‰ªÄÈ∫ºÔºå‰∏¶Ê†πÊìöÈÅéÂ§±Ê≥ïÂíåÊ≠êÊ¥≤ÈÜ´ÁôÇÂô®ÊùêÊ≥ïË¶è‰∏≠ÁöÑÂéüÂâáÈÄ≤Ë°åË™™Êòé„ÄÇÊú¨Êñá‰∏ªÂºµÈ¢®Èö™ÂèØÊé•ÂèóÊÄßÂà§Êñ∑ÁöÑÊñπÊ≥ïÈúÄË¶ÅÁ©©Âõ∫ÁöÑÂÖ¨Ê∞ëÂêàÊ≥ïÊÄßÂü∫Á§éÔºöÂåÖÊã¨Áõ£ÁÆ°Ê©üÊßãÁöÑË©≥Á¥∞ÊåáÂ∞éÊàñÂèÉËàáÔºå‰ª•ÂèäÂèóÂΩ±ÈüøÂà©ÂÆ≥Èóú‰øÇ‰∫∫ÁöÑÊúâÊÑèÁæ©ÊäïÂÖ•„ÄÇ

##### **eXplainable Artificial Intelligence (XAI) in aging clock models**
2307.13704v3 by Alena Kalyakulina, Igor Yusipov, Alexey Moskalev, Claudio Franceschi, Mikhail Ivanchenko

eXplainable Artificial Intelligence (XAI) is a rapidly progressing field of
machine learning, aiming to unravel the predictions of complex models. XAI is
especially required in sensitive applications, e.g. in health care, when
diagnosis, recommendations and treatment choices might rely on the decisions
made by artificial intelligence systems. AI approaches have become widely used
in aging research as well, in particular, in developing biological clock models
and identifying biomarkers of aging and age-related diseases. However, the
potential of XAI here awaits to be fully appreciated. We discuss the
application of XAI for developing the "aging clocks" and present a
comprehensive analysis of the literature categorized by the focus on particular
physiological systems.

ÊëòË¶ÅÔºöÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖß (XAI) ÊòØÊ©üÂô®Â≠∏Áøí‰∏≠Âø´ÈÄüÈÄ≤Â±ïÁöÑÈ†òÂüüÔºåÊó®Âú®Ëß£ÈñãË§áÈõúÊ®°ÂûãÁöÑÈ†êÊ∏¨„ÄÇXAI Âú®ÊïèÊÑüÊáâÁî®‰∏≠ÁâπÂà•ÈúÄË¶ÅÔºå‰æãÂ¶ÇÂú®ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÔºåÁï∂Ë®∫Êñ∑„ÄÅÂª∫Ë≠∞ÂíåÊ≤ªÁôÇÈÅ∏ÊìáÂèØËÉΩ‰æùË≥¥Êñº‰∫∫Â∑•Êô∫ÊÖßÁ≥ªÁµ±ÂÅöÂá∫ÁöÑÊ±∫Á≠ñÊôÇ„ÄÇ‰∫∫Â∑•Êô∫ÊÖßÊñπÊ≥ï‰πüÂ∑≤Âª£Ê≥õÁî®ÊñºËÄÅÂåñÁ†îÁ©∂ÔºåÁâπÂà•ÊòØÂú®ÈñãÁôºÁîüÁâ©ÊôÇÈêòÊ®°ÂûãÂíåË≠òÂà•ËÄÅÂåñÂíåËàáÂπ¥ÈΩ°Áõ∏ÈóúÁñæÁóÖÁöÑÁîüÁâ©Ê®ôË™åÁâ©ÊñπÈù¢„ÄÇÁÑ∂ËÄåÔºåÈÄôË£° XAI ÁöÑÊΩõÂäõÊúâÂæÖÂÖÖÂàÜË™çË≠ò„ÄÇÊàëÂÄëË®éË´ñ‰∫Ü XAI Âú®ÈñãÁôº„ÄåËÄÅÂåñÊôÇÈêò„ÄçÊñπÈù¢ÁöÑÊáâÁî®Ôºå‰∏¶Â∞çÊåâÁâπÂÆöÁîüÁêÜÁ≥ªÁµ±ÁöÑÈáçÈªûÂàÜÈ°ûÁöÑÊñáÁçªÈÄ≤Ë°å‰∫ÜÂÖ®Èù¢ÁöÑÂàÜÊûê„ÄÇ

##### **Interpreting and Correcting Medical Image Classification with PIP-Net**
2307.10404v2 by Meike Nauta, Johannes H. Hegeman, Jeroen Geerdink, J√∂rg Schl√∂tterer, Maurice van Keulen, Christin Seifert

Part-prototype models are explainable-by-design image classifiers, and a
promising alternative to black box AI. This paper explores the applicability
and potential of interpretable machine learning, in particular PIP-Net, for
automated diagnosis support on real-world medical imaging data. PIP-Net learns
human-understandable prototypical image parts and we evaluate its accuracy and
interpretability for fracture detection and skin cancer diagnosis. We find that
PIP-Net's decision making process is in line with medical classification
standards, while only provided with image-level class labels. Because of
PIP-Net's unsupervised pretraining of prototypes, data quality problems such as
undesired text in an X-ray or labelling errors can be easily identified.
Additionally, we are the first to show that humans can manually correct the
reasoning of PIP-Net by directly disabling undesired prototypes. We conclude
that part-prototype models are promising for medical applications due to their
interpretability and potential for advanced model debugging.

ÊëòË¶ÅÔºöÈÉ®ÂàÜÂéüÂûãÊ®°ÂûãÊòØÂèØËß£ÈáãË®≠Ë®àÁöÑÂΩ±ÂÉèÂàÜÈ°ûÂô®Ôºå‰πüÊòØÈªëÁÆ± AI ÁöÑ‰∏ÄÂÄãÊúâÂâçÈÄîÁöÑÊõø‰ª£ÊñπÊ°à„ÄÇÈÄôÁØáË´ñÊñáÊé¢Ë®é‰∫ÜËß£ÈáãÊÄßÊ©üÂô®Â≠∏ÁøíÔºåÁâπÂà•ÊòØ PIP-NetÔºåÂú®ÁúüÂØ¶‰∏ñÁïåÈÜ´Â≠∏ÂΩ±ÂÉèË≥áÊñô‰∏äËá™ÂãïÂåñË®∫Êñ∑ÊîØÊè¥ÁöÑÈÅ©Áî®ÊÄßÂíåÊΩõÂäõ„ÄÇPIP-Net Â≠∏Áøí‰∫∫È°ûÂèØÁêÜËß£ÁöÑÂéüÂûãÂΩ±ÂÉèÈÉ®ÂàÜÔºåÊàëÂÄëË©ï‰º∞ÂÖ∂Âú®È™®ÊäòÊ™¢Ê∏¨ÂíåÁöÆËÜöÁôåË®∫Êñ∑ÊñπÈù¢ÁöÑÊ∫ñÁ¢∫ÊÄßÂíåÂèØËß£ÈáãÊÄß„ÄÇÊàëÂÄëÁôºÁèæ PIP-Net ÁöÑÊ±∫Á≠ñÂà∂ÂÆöÈÅéÁ®ãÁ¨¶ÂêàÈÜ´Â≠∏ÂàÜÈ°ûÊ®ôÊ∫ñÔºåÂêåÊôÇÂÉÖÊèê‰æõÂΩ±ÂÉèÂ±§Á¥öÈ°ûÂà•Ê®ôÁ±§„ÄÇÁî±Êñº PIP-Net Â∞çÂéüÂûãÁöÑÁÑ°Áõ£Áù£È†êË®ìÁ∑¥ÔºåÂõ†Ê≠§ÂèØ‰ª•ËºïÈ¨ÜË≠òÂà•Ë≥áÊñôÂìÅË≥™ÂïèÈ°åÔºå‰æãÂ¶Ç X ÂÖâ‰∏≠ÁöÑ‰∏çÈúÄË¶ÅÊñáÂ≠óÊàñÊ®ôÁ±§ÈåØË™§„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÈ¶ñÊ¨°Â±ïÁ§∫‰∫∫È°ûÂèØ‰ª•ÈÄèÈÅéÁõ¥Êé•ÂÅúÁî®‰∏çÈúÄË¶ÅÁöÑÂéüÂûã‰æÜÊâãÂãï‰øÆÊ≠£ PIP-Net ÁöÑÊé®ÁêÜ„ÄÇÊàëÂÄëÂæóÂá∫ÁµêË´ñÔºåÈÉ®ÂàÜÂéüÂûãÊ®°ÂûãÁî±ÊñºÂÖ∂ÂèØËß£ÈáãÊÄßÂíåÈÄ≤ÈöéÊ®°ÂûãÈô§ÈåØÁöÑÊΩõÂäõÔºåÂõ†Ê≠§ÊúâÊúõÊáâÁî®ÊñºÈÜ´ÁôÇ„ÄÇ

##### **Explaining and visualizing black-box models through counterfactual paths**
2307.07764v3 by Bastian Pfeifer, Mateusz Krzyzinski, Hubert Baniecki, Anna Saranti, Andreas Holzinger, Przemyslaw Biecek

Explainable AI (XAI) is an increasingly important area of machine learning
research, which aims to make black-box models transparent and interpretable. In
this paper, we propose a novel approach to XAI that uses the so-called
counterfactual paths generated by conditional permutations of features. The
algorithm measures feature importance by identifying sequential permutations of
features that most influence changes in model predictions. It is particularly
suitable for generating explanations based on counterfactual paths in knowledge
graphs incorporating domain knowledge. Counterfactual paths introduce an
additional graph dimension to current XAI methods in both explaining and
visualizing black-box models. Experiments with synthetic and medical data
demonstrate the practical applicability of our approach.

ÊëòË¶ÅÔºöÂèØËß£Èáã AI (XAI) ÊòØÊ©üÂô®Â≠∏ÁøíÁ†îÁ©∂‰∏≠Êó•ÁõäÈáçË¶ÅÁöÑÈ†òÂüüÔºåÂÖ∂ÁõÆÊ®ôÊòØËÆìÈªëÁÆ±Ê®°ÂûãÈÄèÊòé‰∏îÂèØËß£Èáã„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞ÁöÑ XAI ÊñπÊ≥ïÔºåË©≤ÊñπÊ≥ï‰ΩøÁî®Áî±ÁâπÂæµÊ¢ù‰ª∂ÁΩÆÊèõÁî¢ÁîüÁöÑÊâÄË¨ÇÂèç‰∫ãÂØ¶Ë∑ØÂæë„ÄÇË©≤ÊºîÁÆóÊ≥ïÈÄèÈÅéË≠òÂà•ÁâπÂæµÁöÑÈ†ÜÂ∫èÁΩÆÊèõ‰æÜË°°ÈáèÁâπÂæµÈáçË¶ÅÊÄßÔºåÈÄô‰∫õÁΩÆÊèõÊúÄËÉΩÂΩ±ÈüøÊ®°ÂûãÈ†êÊ∏¨ÁöÑËÆäÂåñ„ÄÇÂÆÉÁâπÂà•ÈÅ©ÂêàÊ†πÊìöÂåÖÂê´È†òÂüüÁü•Ë≠òÁöÑÁü•Ë≠òÂúñË≠ú‰∏≠ÁöÑÂèç‰∫ãÂØ¶Ë∑ØÂæë‰æÜÁî¢ÁîüËß£Èáã„ÄÇÂèç‰∫ãÂØ¶Ë∑ØÂæëÂú®Ëß£ÈáãÂíåË¶ñË¶∫ÂåñÈªëÁÆ±Ê®°ÂûãÊôÇÔºåÁÇ∫ÁõÆÂâçÁöÑ XAI ÊñπÊ≥ïÂºïÂÖ•‰∫ÜÈ°çÂ§ñÁöÑÂúñÂΩ¢Á∂≠Â∫¶„ÄÇ‰ΩøÁî®ÂêàÊàêÂíåÈÜ´ÁôÇË≥áÊñôÈÄ≤Ë°åÁöÑÂØ¶È©óË≠âÊòé‰∫ÜÊàëÂÄëÊñπÊ≥ïÁöÑÂØ¶Áî®ÈÅ©Áî®ÊÄß„ÄÇ

##### **Beyond Known Reality: Exploiting Counterfactual Explanations for Medical Research**
2307.02131v5 by Toygar Tanyel, Serkan Ayvaz, Bilgin Keserci

The field of explainability in artificial intelligence (AI) has witnessed a
growing number of studies and increasing scholarly interest. However, the lack
of human-friendly and individual interpretations in explaining the outcomes of
machine learning algorithms has significantly hindered the acceptance of these
methods by clinicians in their research and clinical practice. To address this
issue, our study uses counterfactual explanations to explore the applicability
of "what if?" scenarios in medical research. Our aim is to expand our
understanding of magnetic resonance imaging (MRI) features used for diagnosing
pediatric posterior fossa brain tumors beyond existing boundaries. In our case
study, the proposed concept provides a novel way to examine alternative
decision-making scenarios that offer personalized and context-specific
insights, enabling the validation of predictions and clarification of
variations under diverse circumstances. Additionally, we explore the potential
use of counterfactuals for data augmentation and evaluate their feasibility as
an alternative approach in our medical research case. The results demonstrate
the promising potential of using counterfactual explanations to enhance
acceptance of AI-driven methods in clinical research.

ÊëòË¶ÅÔºöÂú®‰∫∫Â∑•Êô∫ËÉΩ (AI) ÁöÑÂèØËß£ÈáãÊÄßÈ†òÂüü‰∏≠ÔºåÂ∑≤Á∂ìÁúãÂà∞Ë∂ä‰æÜË∂äÂ§öÁöÑÁ†îÁ©∂ÂíåÂ≠∏Ë°ìËààË∂£„ÄÇÁÑ∂ËÄåÔºåÂú®Ëß£ÈáãÊ©üÂô®Â≠∏ÁøíÊºîÁÆóÊ≥ïÁöÑÁµêÊûúÊôÇÁº∫‰πè‰∫∫ÊÄßÂåñÂíåÂÄã‰∫∫ÂåñÁöÑË©ÆÈáãÔºåÈÄôÈ°ØËëóÈòªÁ§ô‰∫ÜËá®Â∫äÈÜ´ÁîüÂú®Á†îÁ©∂ÂíåËá®Â∫äÂØ¶Âãô‰∏≠Êé•ÂèóÈÄô‰∫õÊñπÊ≥ï„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÁöÑÁ†îÁ©∂‰ΩøÁî®Âèç‰∫ãÂØ¶Ëß£Èáã‰æÜÊé¢Ë®é„ÄåÂ¶ÇÊûúÔºü„ÄçÊÉÖÂ¢ÉÂú®ÈÜ´Â≠∏Á†îÁ©∂‰∏≠ÁöÑÈÅ©Áî®ÊÄß„ÄÇÊàëÂÄëÁöÑÁõÆÊ®ôÊòØÊì¥Â±ïÊàëÂÄëÂ∞çÁî®ÊñºË®∫Êñ∑Â∞èÂÖíÂæåÈ°±Á™©ËÖ¶ËÖ´Áò§ÁöÑÁ£ÅÂÖ±ÊåØÊàêÂÉè (MRI) ÁâπÂæµÁöÑÁêÜËß£ÔºåË∂ÖË∂äÁèæÊúâÁöÑÁïåÁ∑ö„ÄÇÂú®ÊàëÂÄëÁöÑÊ°à‰æãÁ†îÁ©∂‰∏≠ÔºåÊâÄÊèêÂá∫ÁöÑÊ¶ÇÂøµÊèê‰æõ‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÊñπÊ≥ï‰æÜÊ™¢Ë¶ñÊõø‰ª£Ê±∫Á≠ñÊÉÖÂ¢ÉÔºåÊèê‰æõÂÄã‰∫∫ÂåñÂíåÁâπÂÆöÊñºÊÉÖÂ¢ÉÁöÑË¶ãËß£ÔºåÂæûËÄåËÉΩÂ§†È©óË≠âÈ†êÊ∏¨‰∏¶ÈáêÊ∏ÖÂú®‰∏çÂêåÊÉÖÊ≥Å‰∏ãÁöÑÂ∑ÆÁï∞„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊé¢Ë®é‰∫ÜÂèç‰∫ãÂØ¶Áî®ÊñºË≥áÊñôÊì¥ÂÖÖÁöÑÊΩõÂú®Áî®ÈÄîÔºå‰∏¶Ë©ï‰º∞ÂÖ∂‰ΩúÁÇ∫ÊàëÂÄëÈÜ´Â≠∏Á†îÁ©∂Ê°à‰æã‰∏≠Êõø‰ª£ÊñπÊ≥ïÁöÑÂèØË°åÊÄß„ÄÇÁµêÊûúË≠âÊòé‰∫Ü‰ΩøÁî®Âèç‰∫ãÂØ¶Ëß£Èáã‰æÜÂ¢ûÂº∑Ëá®Â∫äÁ†îÁ©∂‰∏≠ AI È©ÖÂãïÊñπÊ≥ïÁöÑÊé•ÂèóÂ∫¶ÁöÑÊΩõÂäõ„ÄÇ

##### **AI and Non AI Assessments for Dementia**
2307.01210v1 by Mahboobeh Parsapoor, Hamed Ghodrati, Vincenzo Dentamaro, Christopher R. Madan, Ioulietta Lazarou, Spiros Nikolopoulos, Ioannis Kompatsiaris

Current progress in the artificial intelligence domain has led to the
development of various types of AI-powered dementia assessments, which can be
employed to identify patients at the early stage of dementia. It can
revolutionize the dementia care settings. It is essential that the medical
community be aware of various AI assessments and choose them considering their
degrees of validity, efficiency, practicality, reliability, and accuracy
concerning the early identification of patients with dementia (PwD). On the
other hand, AI developers should be informed about various non-AI assessments
as well as recently developed AI assessments. Thus, this paper, which can be
readable by both clinicians and AI engineers, fills the gap in the literature
in explaining the existing solutions for the recognition of dementia to
clinicians, as well as the techniques used and the most widespread dementia
datasets to AI engineers. It follows a review of papers on AI and non-AI
assessments for dementia to provide valuable information about various dementia
assessments for both the AI and medical communities. The discussion and
conclusion highlight the most prominent research directions and the maturity of
existing solutions.

ÊëòË¶ÅÔºöÁõÆÂâç‰∫∫Â∑•Êô∫ËÉΩÈ†òÂüüÁöÑÈÄ≤Â±ïÂ∞éËá¥‰∫ÜÂêÑÁ®ÆÈ°ûÂûãÁöÑ‰∫∫Â∑•Êô∫ÊÖßÈ©ÖÂãïÁöÑÂ§±Êô∫ÁóáË©ï‰º∞ÁöÑÁôºÂ±ïÔºåÂèØÁî®ÊñºË≠òÂà•ËôïÊñºÂ§±Êô∫ÁóáÊó©ÊúüÈöéÊÆµÁöÑÊÇ£ËÄÖ„ÄÇÂÆÉÂèØ‰ª•ÂæπÂ∫ïÊîπËÆäÂ§±Êô∫ÁóáË≠∑ÁêÜË®≠ÁΩÆ„ÄÇÈáçË¶ÅÁöÑÊòØÔºåÈÜ´ÁôÇÁïåË¶Å‰∫ÜËß£ÂêÑÁ®Æ‰∫∫Â∑•Êô∫ËÉΩË©ï‰º∞Ôºå‰∏¶Ê†πÊìöÂÖ∂ÊúâÊïàÊÄß„ÄÅÊïàÁéá„ÄÅÂØ¶Áî®ÊÄß„ÄÅÂèØÈù†ÊÄßÂíåÊ∫ñÁ¢∫ÊÄßÁ®ãÂ∫¶ÔºåËÄÉÊÖÆÈÅ∏ÊìáÂÆÉÂÄë‰æÜÊó©ÊúüË≠òÂà•Â§±Êô∫ÁóáÊÇ£ËÄÖ (PwD)„ÄÇÂè¶‰∏ÄÊñπÈù¢Ôºå‰∫∫Â∑•Êô∫ËÉΩÈñãÁôº‰∫∫Âì°‰πüÊáâË©≤‰∫ÜËß£ÂêÑÁ®ÆÈùû‰∫∫Â∑•Êô∫ËÉΩË©ï‰º∞‰ª•ÂèäÊúÄËøëÈñãÁôºÁöÑ‰∫∫Â∑•Êô∫ËÉΩË©ï‰º∞„ÄÇÂõ†Ê≠§ÔºåÈÄôÁØáËá®Â∫äÈÜ´ÁîüÂíå‰∫∫Â∑•Êô∫ËÉΩÂ∑•Á®ãÂ∏´ÈÉΩÂèØ‰ª•Èñ±ËÆÄÁöÑË´ñÊñáÂ°´Ë£ú‰∫ÜÊñáÁçª‰∏≠ÈóúÊñºÂêëËá®Â∫äÈÜ´ÁîüËß£ÈáãÁèæÊúâÂ§±Êô∫ÁóáË≠òÂà•Ëß£Ê±∫ÊñπÊ°à‰ª•ÂèäÂêë‰∫∫Â∑•Êô∫ËÉΩÂ∑•Á®ãÂ∏´Ëß£ÈáãÊâÄÁî®ÊäÄË°ìÂíåÊúÄÂª£Ê≥õÁöÑÂ§±Êô∫ÁóáÊï∏ÊìöÈõÜÁöÑÁ©∫ÁôΩ„ÄÇÂÆÉÈÅµÂæ™Â∞ç‰∫∫Â∑•Êô∫ËÉΩÂíåÈùû‰∫∫Â∑•Êô∫ËÉΩÂ§±Êô∫ÁóáË©ï‰º∞Ë´ñÊñáÁöÑÂõûÈ°ßÔºåÁÇ∫‰∫∫Â∑•Êô∫ËÉΩÂíåÈÜ´ÁôÇÁïåÊèê‰æõÊúâÈóúÂêÑÁ®ÆÂ§±Êô∫ÁóáË©ï‰º∞ÁöÑÂØ∂Ë≤¥‰ø°ÊÅØ„ÄÇË®éË´ñÂíåÁµêË´ñÈáçÈªû‰ªãÁ¥π‰∫ÜÊúÄÁ™ÅÂá∫ÁöÑÁ†îÁ©∂ÊñπÂêëÂíåÁèæÊúâËß£Ê±∫ÊñπÊ°àÁöÑÊàêÁÜüÂ∫¶„ÄÇ

##### **Active Globally Explainable Learning for Medical Images via Class Association Embedding and Cyclic Adversarial Generation**
2306.07306v1 by Ruitao Xie, Jingbang Chen, Limai Jiang, Rui Xiao, Yi Pan, Yunpeng Cai

Explainability poses a major challenge to artificial intelligence (AI)
techniques. Current studies on explainable AI (XAI) lack the efficiency of
extracting global knowledge about the learning task, thus suffer deficiencies
such as imprecise saliency, context-aware absence and vague meaning. In this
paper, we propose the class association embedding (CAE) approach to address
these issues. We employ an encoder-decoder architecture to embed sample
features and separate them into class-related and individual-related style
vectors simultaneously. Recombining the individual-style code of a given sample
with the class-style code of another leads to a synthetic sample with preserved
individual characters but changed class assignment, following a cyclic
adversarial learning strategy. Class association embedding distills the global
class-related features of all instances into a unified domain with well
separation between classes. The transition rules between different classes can
be then extracted and further employed to individual instances. We then propose
an active XAI framework which manipulates the class-style vector of a certain
sample along guided paths towards the counter-classes, resulting in a series of
counter-example synthetic samples with identical individual characters.
Comparing these counterfactual samples with the original ones provides a
global, intuitive illustration to the nature of the classification tasks. We
adopt the framework on medical image classification tasks, which show that more
precise saliency maps with powerful context-aware representation can be
achieved compared with existing methods. Moreover, the disease pathology can be
directly visualized via traversing the paths in the class-style space.

ÊëòË¶ÅÔºö<paragraph>ÂèØËß£ÈáãÊÄßÂ∞ç‰∫∫Â∑•Êô∫ÊÖß (AI) ÊäÄË°ìÊßãÊàê‰∏ÄÈ†ÖÈáçÂ§ßÊåëÊà∞„ÄÇÁï∂ÂâçÂ∞çÂèØËß£Èáã AI (XAI) ÁöÑÁ†îÁ©∂Áº∫‰πèÊèêÂèñÂ≠∏Áøí‰ªªÂãôÊï¥È´îÁü•Ë≠òÁöÑÊïàÁéáÔºåÂõ†Ê≠§Â≠òÂú®‰∏çÁ≤æÁ¢∫ÁöÑÈ°ØËëóÊÄß„ÄÅËàáÊÉÖÂ¢ÉÁÑ°ÈóúÁöÑÁº∫Â§±ÂíåÂê´Á≥äÊÑèÁæ©Á≠âÁº∫Èô∑„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫È°ûÂà•ÈóúËÅØÂµåÂÖ• (CAE) ÊñπÊ≥ï‰æÜËß£Ê±∫ÈÄô‰∫õÂïèÈ°å„ÄÇÊàëÂÄëÊé°Áî®Á∑®Á¢ºÂô®-Ëß£Á¢ºÂô®Êû∂Êßã‰æÜÂµåÂÖ•Ê®£Êú¨ÁâπÂæµÔºå‰∏¶ÂêåÊôÇÂ∞áÂÆÉÂÄëÂàÜÁÇ∫È°ûÂà•Áõ∏ÈóúÂíåÂÄãÈ´îÁõ∏ÈóúÁöÑÊ®£ÂºèÂêëÈáè„ÄÇÂ∞áÁµ¶ÂÆöÊ®£Êú¨ÁöÑÂÄãÈ´îÊ®£Âºè‰ª£Á¢ºËàáÂè¶‰∏ÄÂÄãÊ®£Êú¨ÁöÑÈ°ûÂà•Ê®£Âºè‰ª£Á¢ºÈáçÊñ∞ÁµÑÂêàÔºåÊúÉÁî¢Áîü‰∏ÄÂÄãÂÖ∑Êúâ‰øùÁïôÂÄãÈ´îÁâπÂæµ‰ΩÜÊîπËÆäÈ°ûÂà•ÂàÜÈÖçÁöÑÂêàÊàêÊ®£Êú¨ÔºåÈÅµÂæ™Âæ™Áí∞Â∞çÊäóÂ≠∏ÁøíÁ≠ñÁï•„ÄÇÈ°ûÂà•ÈóúËÅØÂµåÂÖ•Â∞áÊâÄÊúâÂØ¶‰æãÁöÑÂÖ®Â±ÄÈ°ûÂà•Áõ∏ÈóúÁâπÂæµÊèêÁÖâÂà∞‰∏ÄÂÄãÁµ±‰∏ÄÁöÑÈ†òÂüü‰∏≠Ôºå‰∏¶Âú®È°ûÂà•‰πãÈñìÊúâËâØÂ•ΩÁöÑÂçÄÂàÜ„ÄÇÁÑ∂ÂæåÂèØ‰ª•ÊèêÂèñ‰∏çÂêåÈ°ûÂà•‰πãÈñìÁöÑËΩâÊèõË¶èÂâáÔºå‰∏¶ÈÄ≤‰∏ÄÊ≠•ÊáâÁî®ÊñºÂÄãÂà•ÂØ¶‰æã„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄã‰∏ªÂãï XAI Ê°ÜÊû∂ÔºåÂÆÉÊ≤øËëóÂºïÂ∞éË∑ØÂæëÊìç‰ΩúÁâπÂÆöÊ®£Êú¨ÁöÑÈ°ûÂà•Ê®£ÂºèÂêëÈáèÔºåÊúùËëóÂèçÈ°ûÂà•ÁßªÂãïÔºåÂæûËÄåÁî¢Áîü‰∏ÄÁ≥ªÂàóÂÖ∑ÊúâÁõ∏ÂêåÂÄãÈ´îÁâπÂæµÁöÑÂèç‰æãÂêàÊàêÊ®£Êú¨„ÄÇÂ∞áÈÄô‰∫õÂèç‰∫ãÂØ¶Ê®£Êú¨ËàáÂéüÂßãÊ®£Êú¨ÈÄ≤Ë°åÊØîËºÉÔºåÂèØ‰ª•Â∞çÂàÜÈ°û‰ªªÂãôÁöÑÊÄßË≥™Êèê‰æõÂÖ®Â±Ä„ÄÅÁõ¥ËßÄÁöÑË™™Êòé„ÄÇÊàëÂÄëÊé°Áî®Ë©≤Ê°ÜÊû∂ÈÄ≤Ë°åÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÈ°û‰ªªÂãôÔºåÁµêÊûúË°®ÊòéÔºåËàáÁèæÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåÂèØ‰ª•Áç≤ÂæóÊõ¥Á≤æÁ¢∫ÁöÑÈ°ØËëóÊÄßÂúñÔºå‰∏¶ÂÖ∑ÊúâÂº∑Â§ßÁöÑËàáÊÉÖÂ¢ÉÁÑ°ÈóúÁöÑË°®Á§∫„ÄÇÊ≠§Â§ñÔºåÁñæÁóÖÁóÖÁêÜÂ≠∏ÂèØ‰ª•Áõ¥Êé•ÈÄöÈÅéÂú®È°ûÂà•Ê®£ÂºèÁ©∫Èñì‰∏≠ÈÅçÊ≠∑Ë∑ØÂæë‰æÜÈÄ≤Ë°åÂèØË¶ñÂåñ„ÄÇ</paragraph>

##### **HiTZ@Antidote: Argumentation-driven Explainable Artificial Intelligence for Digital Medicine**
2306.06029v1 by Rodrigo Agerri, I√±igo Alonso, Aitziber Atutxa, Ander Berrondo, Ainara Estarrona, Iker Garcia-Ferrero, Iakes Goenaga, Koldo Gojenola, Maite Oronoz, Igor Perez-Tejedor, German Rigau, Anar Yeginbergenova

Providing high quality explanations for AI predictions based on machine
learning is a challenging and complex task. To work well it requires, among
other factors: selecting a proper level of generality/specificity of the
explanation; considering assumptions about the familiarity of the explanation
beneficiary with the AI task under consideration; referring to specific
elements that have contributed to the decision; making use of additional
knowledge (e.g. expert evidence) which might not be part of the prediction
process; and providing evidence supporting negative hypothesis. Finally, the
system needs to formulate the explanation in a clearly interpretable, and
possibly convincing, way. Given these considerations, ANTIDOTE fosters an
integrated vision of explainable AI, where low-level characteristics of the
deep learning process are combined with higher level schemes proper of the
human argumentation capacity. ANTIDOTE will exploit cross-disciplinary
competences in deep learning and argumentation to support a broader and
innovative view of explainable AI, where the need for high-quality explanations
for clinical cases deliberation is critical. As a first result of the project,
we publish the Antidote CasiMedicos dataset to facilitate research on
explainable AI in general, and argumentation in the medical domain in
particular.

ÊëòË¶ÅÔºöÊèê‰æõÂü∫ÊñºÊ©üÂô®Â≠∏ÁøíÁöÑ AI È†êÊ∏¨ÁöÑÈ´òÂìÅË≥™Ë™™ÊòéÊòØ‰∏ÄÈ†ÖÂÖ∑ÊúâÊåëÊà∞ÊÄßÂíåË§áÈõúÊÄßÁöÑ‰ªªÂãô„ÄÇË¶ÅÈ†ÜÂà©ÈÄ≤Ë°åÔºåÂÆÉÈúÄË¶ÅÂÖ∑ÂÇô‰∏ãÂàóÂõ†Á¥†ÔºöÈÅ∏ÊìáÈÅ©Áï∂ÁöÑË™™ÊòéÊôÆÈÅçÊÄß/ÁâπÊÆäÊÄßÂ±§Á¥öÔºõËÄÉÈáèË™™ÊòéÂèóÁõä‰∫∫Â∞çÊâÄËÄÉÊÖÆÁöÑ AI ‰ªªÂãôÁöÑÁÜüÊÇâÁ®ãÂ∫¶ÂÅáË®≠ÔºõÂèÉÁÖß‰øÉÊàêÊ±∫Á≠ñÁöÑÁâπÂÆöÂÖÉÁ¥†ÔºõÂà©Áî®ÂèØËÉΩ‰∏çÂ±¨ÊñºÈ†êÊ∏¨Á®ãÂ∫èÁöÑ‰∏ÄÈÉ®ÂàÜÁöÑÈ°çÂ§ñÁü•Ë≠òÔºà‰æãÂ¶ÇÂ∞àÂÆ∂Ë≠âÊìöÔºâÔºõ‰∏¶Êèê‰æõÊîØÊåÅÂê¶ÂÆöÂÅáË®≠ÁöÑË≠âÊìö„ÄÇÊúÄÂæåÔºåÁ≥ªÁµ±ÈúÄË¶Å‰ª•Ê∏ÖÊô∞ÂèØËß£Èáã‰∏îÂèØËÉΩ‰ª§‰∫∫‰ø°ÊúçÁöÑÊñπÂºèÂà∂ÂÆöË™™Êòé„ÄÇÂü∫ÊñºÈÄô‰∫õËÄÉÈáèÔºåANTIDOTE ‰øÉÊàê‰∫ÜÂèØËß£Èáã AI ÁöÑÊï¥ÂêàÈ°òÊôØÔºåÂÖ∂‰∏≠Ê∑±Â∫¶Â≠∏ÁøíÁ®ãÂ∫èÁöÑ‰ΩéÈöéÁâπÂæµËàá‰∫∫È°ûË´ñË≠âËÉΩÂäõÁöÑÈ´òÈöéÊû∂ÊßãÁõ∏ÁµêÂêà„ÄÇANTIDOTE Â∞áÂà©Áî®Ê∑±Â∫¶Â≠∏ÁøíËàáË´ñË≠âÁöÑË∑®È†òÂüüËÉΩÂäõÔºå‰æÜÊîØÊåÅÂèØËß£Èáã AI Êõ¥Âª£Ê≥õ‰∏îÂâµÊñ∞ÁöÑËßÄÈªûÔºåÂÖ∂‰∏≠Â∞çËá®Â∫äÊ°à‰æãÂØ©Ë≠∞ÁöÑÈ´òÂìÅË≥™Ë™™ÊòéÈúÄÊ±ÇËá≥ÈóúÈáçË¶Å„ÄÇ‰ΩúÁÇ∫Ë©≤Â∞àÊ°àÁöÑÁ¨¨‰∏ÄÂÄãÊàêÊûúÔºåÊàëÂÄëÁôºÂ∏É‰∫Ü Antidote CasiMedicos Ë≥áÊñôÈõÜÔºå‰ª•Âà©Êñº‰∏ÄËà¨ÂèØËß£Èáã AI ÁöÑÁ†îÁ©∂ÔºåÁâπÂà•ÊòØÈÜ´ÁôÇÈ†òÂüüÁöÑË´ñË≠â„ÄÇ

##### **XInsight: Revealing Model Insights for GNNs with Flow-based Explanations**
2306.04791v1 by Eli Laird, Ayesh Madushanka, Elfi Kraka, Corey Clark

Progress in graph neural networks has grown rapidly in recent years, with
many new developments in drug discovery, medical diagnosis, and recommender
systems. While this progress is significant, many networks are `black boxes'
with little understanding of the `what' exactly the network is learning. Many
high-stakes applications, such as drug discovery, require human-intelligible
explanations from the models so that users can recognize errors and discover
new knowledge. Therefore, the development of explainable AI algorithms is
essential for us to reap the benefits of AI.
  We propose an explainability algorithm for GNNs called eXplainable Insight
(XInsight) that generates a distribution of model explanations using GFlowNets.
Since GFlowNets generate objects with probabilities proportional to a reward,
XInsight can generate a diverse set of explanations, compared to previous
methods that only learn the maximum reward sample. We demonstrate XInsight by
generating explanations for GNNs trained on two graph classification tasks:
classifying mutagenic compounds with the MUTAG dataset and classifying acyclic
graphs with a synthetic dataset that we have open-sourced. We show the utility
of XInsight's explanations by analyzing the generated compounds using QSAR
modeling, and we find that XInsight generates compounds that cluster by
lipophilicity, a known correlate of mutagenicity. Our results show that
XInsight generates a distribution of explanations that uncovers the underlying
relationships demonstrated by the model. They also highlight the importance of
generating a diverse set of explanations, as it enables us to discover hidden
relationships in the model and provides valuable guidance for further analysis.

ÊëòË¶ÅÔºö<paragraph>ËøëÂπ¥‰æÜÔºåÂúñÁ•ûÁ∂ìÁ∂≤Ë∑ØÁöÑÈÄ≤Â±ïËøÖÈÄüÔºåÂú®Ëó•Áâ©ÁôºÁèæ„ÄÅÈÜ´ÁôÇË®∫Êñ∑ÂíåÊé®Ëñ¶Á≥ªÁµ±ÊñπÈù¢ÈÉΩÊúâË®±Â§öÊñ∞ÁôºÂ±ï„ÄÇÈõñÁÑ∂ÈÄô‰∫õÈÄ≤Â±ïÂæàÈáçË¶ÅÔºå‰ΩÜË®±Â§öÁ∂≤Ë∑ØÈÉΩÊòØ„ÄåÈªëÁõíÂ≠ê„ÄçÔºåÂ∞çÊñºÁ∂≤Ë∑ØÂà∞Â∫ïÂú®Â≠∏Áøí„Äå‰ªÄÈ∫º„Äç‰∫ÜËß£ÁîöÂ∞ë„ÄÇË®±Â§öÈ´òÈ¢®Èö™ÊáâÁî®Ôºå‰æãÂ¶ÇËó•Áâ©ÁôºÁèæÔºåÈúÄË¶ÅÊ®°ÂûãÊèê‰æõ‰∫∫È°ûÂèØ‰ª•ÁêÜËß£ÁöÑËß£ÈáãÔºå‰ª•‰æø‰ΩøÁî®ËÄÖÂèØ‰ª•Ëæ®Ë≠òÈåØË™§‰∏¶ÁôºÁèæÊñ∞Áü•Ë≠ò„ÄÇÂõ†Ê≠§ÔºåÂèØËß£Èáã AI ÊºîÁÆóÊ≥ïÁöÑÈñãÁôºÂ∞çÊñºÊàëÂÄëÁç≤Âèñ AI ÁöÑÂ•ΩËôïËá≥ÈóúÈáçË¶Å„ÄÇ
ÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÁ®±ÁÇ∫ eXplainable Insight (XInsight) ÁöÑ GNN ÂèØËß£ÈáãÊÄßÊºîÁÆóÊ≥ïÔºåÂÆÉ‰ΩøÁî® GFlowNets Áî¢ÁîüÊ®°ÂûãËß£ÈáãÂàÜ‰Ωà„ÄÇÁî±Êñº GFlowNets ÊúÉÁî¢ÁîüÊ©üÁéáËàáÁçéÂãµÊàêÊ≠£ÊØîÁöÑÁâ©‰ª∂ÔºåÂõ†Ê≠§ËàáÂÖàÂâçÂÉÖÂ≠∏ÁøíÊúÄÂ§ßÁçéÂãµÁØÑ‰æãÁöÑÊñπÊ≥ïÁõ∏ÊØîÔºåXInsight ÂèØ‰ª•Áî¢ÁîüÂ§öÊ®£ÂåñÁöÑËß£ÈáãÈõÜÂêà„ÄÇÊàëÂÄëÈÄèÈÅéÁÇ∫Âú®ÂÖ©ÂÄãÂúñÂΩ¢ÂàÜÈ°û‰ªªÂãô‰∏≠Ë®ìÁ∑¥ÁöÑ GNN Áî¢ÁîüËß£Èáã‰æÜÂ±ïÁ§∫ XInsightÔºö‰ΩøÁî® MUTAG Ë≥áÊñôÈõÜÂ∞çËá¥Á™ÅËÆäÂåñÂêàÁâ©ÈÄ≤Ë°åÂàÜÈ°ûÔºå‰∏¶‰ΩøÁî®ÊàëÂÄëÂ∑≤ÈñãÊîæÂéüÂßãÁ¢ºÁöÑÂêàÊàêË≥áÊñôÈõÜÂ∞çÈùûÁí∞ÁãÄÂúñÂΩ¢ÈÄ≤Ë°åÂàÜÈ°û„ÄÇÊàëÂÄëÈÄèÈÅé‰ΩøÁî® QSAR Âª∫Ê®°ÂàÜÊûêÁî¢ÁîüÁöÑÂåñÂêàÁâ©‰æÜÂ±ïÁ§∫ XInsight Ëß£ÈáãÁöÑÊïàÁî®ÔºåÊàëÂÄëÁôºÁèæ XInsight ÊúÉÁî¢ÁîüÊåâË¶™ËÑÇÊÄßÔºàÂ∑≤Áü•ÁöÑËá¥Á™ÅËÆäÁõ∏ÈóúÊÄßÔºâÂàÜÁæ§ÁöÑÂåñÂêàÁâ©„ÄÇÊàëÂÄëÁöÑÁµêÊûúÈ°ØÁ§∫ XInsight ÊúÉÁî¢Áîü‰∏ÄÂÄãËß£ÈáãÂàÜ‰ΩàÔºåÊè≠Á§∫Ê®°ÂûãÊâÄÂ±ïÁ§∫ÁöÑÂ∫ïÂ±§Èóú‰øÇ„ÄÇÂÆÉÂÄë‰πüÂº∑Ë™øÁî¢ÁîüÂ§öÊ®£ÂåñËß£ÈáãÈõÜÂêàÁöÑÈáçË¶ÅÊÄßÔºåÂõ†ÁÇ∫ÂÆÉ‰ΩøÊàëÂÄëËÉΩÂ§†ÁôºÁèæÊ®°Âûã‰∏≠ÁöÑÈö±ËóèÈóú‰øÇÔºå‰∏¶ÁÇ∫ÈÄ≤‰∏ÄÊ≠•ÂàÜÊûêÊèê‰æõÊúâÂÉπÂÄºÁöÑÊåáÂ∞é„ÄÇ</paragraph>

##### **Explainable AI using expressive Boolean formulas**
2306.03976v1 by Gili Rosenberg, J. Kyle Brubaker, Martin J. A. Schuetz, Grant Salton, Zhihuai Zhu, Elton Yechao Zhu, Serdar Kadƒ±oƒülu, Sima E. Borujeni, Helmut G. Katzgraber

We propose and implement an interpretable machine learning classification
model for Explainable AI (XAI) based on expressive Boolean formulas. Potential
applications include credit scoring and diagnosis of medical conditions. The
Boolean formula defines a rule with tunable complexity (or interpretability),
according to which input data are classified. Such a formula can include any
operator that can be applied to one or more Boolean variables, thus providing
higher expressivity compared to more rigid rule-based and tree-based
approaches. The classifier is trained using native local optimization
techniques, efficiently searching the space of feasible formulas. Shallow rules
can be determined by fast Integer Linear Programming (ILP) or Quadratic
Unconstrained Binary Optimization (QUBO) solvers, potentially powered by
special purpose hardware or quantum devices. We combine the expressivity and
efficiency of the native local optimizer with the fast operation of these
devices by executing non-local moves that optimize over subtrees of the full
Boolean formula. We provide extensive numerical benchmarking results featuring
several baselines on well-known public datasets. Based on the results, we find
that the native local rule classifier is generally competitive with the other
classifiers. The addition of non-local moves achieves similar results with
fewer iterations, and therefore using specialized or quantum hardware could
lead to a speedup by fast proposal of non-local moves.

ÊëòË¶ÅÔºöÊàëÂÄëÊèêÂá∫‰∏¶ÂØ¶‰Ωú‰∏ÄÂÄãÂèØËß£ÈáãÊ©üÂô®Â≠∏ÁøíÂàÜÈ°ûÊ®°ÂûãÔºåÁî®ÊñºÂü∫ÊñºË°®ÈÅîÂºèÂ∏ÉÊûóÂÖ¨ÂºèÁöÑÂèØËß£Èáã AI (XAI)„ÄÇÊΩõÂú®ÊáâÁî®ÂåÖÊã¨‰ø°Áî®Ë©ïÂàÜÂíåÈÜ´ÁôÇÁãÄÊ≥ÅË®∫Êñ∑„ÄÇÂ∏ÉÊûóÂÖ¨ÂºèÂÆöÁæ©‰∫Ü‰∏ÄÂÄãÂÖ∑ÊúâÂèØË™øÊï¥Ë§áÈõúÊÄßÔºàÊàñÂèØËß£ÈáãÊÄßÔºâÁöÑË¶èÂâáÔºåÊ†πÊìöË©≤Ë¶èÂâáÂ∞çËº∏ÂÖ•Êï∏ÊìöÈÄ≤Ë°åÂàÜÈ°û„ÄÇÈÄôÊ®£ÁöÑÂÖ¨ÂºèÂèØ‰ª•ÂåÖÂê´‰ªª‰ΩïÂèØÊáâÁî®Êñº‰∏ÄÂÄãÊàñÂ§öÂÄãÂ∏ÉÊûóËÆäÊï∏ÁöÑÈÅãÁÆóÂ≠êÔºåÂæûËÄåËàáÊõ¥Âö¥Ê†ºÁöÑÂü∫ÊñºË¶èÂâáÂíåÂü∫ÊñºÊ®πÁöÑÊñπÊ≥ïÁõ∏ÊØîÔºåÊèê‰æõÊõ¥È´òÁöÑË°®ÈÅîËÉΩÂäõ„ÄÇÂàÜÈ°ûÂô®‰ΩøÁî®ÂéüÁîüÂ±ÄÈÉ®ÊúÄ‰Ω≥ÂåñÊäÄË°ìÈÄ≤Ë°åË®ìÁ∑¥ÔºåÊúâÊïàÂú∞ÊêúÁ¥¢ÂèØË°åÂÖ¨ÂºèÁöÑÁ©∫Èñì„ÄÇÊ∑∫Â±§Ë¶èÂâáÂèØ‰ª•Áî®Âø´ÈÄüÁöÑÊï¥Êï∏Á∑öÊÄßË¶èÂäÉ (ILP) Êàñ‰∫åÊ¨°ÁÑ°Á¥ÑÊùü‰∫åÂÖÉÊúÄ‰Ω≥Âåñ (QUBO) Ê±ÇËß£Âô®‰æÜÁ¢∫ÂÆöÔºåÈÄô‰∫õÊ±ÇËß£Âô®ÂèØËÉΩÁî±ÁâπÊÆäÁî®ÈÄîÁöÑÁ°¨È´îÊàñÈáèÂ≠êË£ùÁΩÆÊèê‰æõÊîØÊè¥„ÄÇÊàëÂÄëÂ∞áÂéüÁîüÂ±ÄÈÉ®ÊúÄ‰Ω≥ÂåñÂô®ÁöÑË°®ÈÅîËÉΩÂäõÂíåÊïàÁéáËàáÈÄô‰∫õË£ùÁΩÆÁöÑÂø´ÈÄüÈÅãÁÆóÁõ∏ÁµêÂêàÔºåÈÄèÈÅéÂü∑Ë°åÈùûÂ±ÄÈÉ®ÁßªÂãï‰æÜÊúÄ‰Ω≥ÂåñÂÆåÊï¥Â∏ÉÊûóÂÖ¨ÂºèÁöÑÂ≠êÊ®π„ÄÇÊàëÂÄëÊèê‰æõÂª£Ê≥õÁöÑÊï∏ÂÄºÂü∫Ê∫ñÊ∏¨Ë©¶ÁµêÊûúÔºåÂÖ∂‰∏≠ÂåÖÂê´Âú®ÁúæÊâÄÂë®Áü•ÁöÑÂÖ¨ÂÖ±Ë≥áÊñôÈõÜ‰∏ä‰ΩøÁî®Â§öÂÄãÂü∫Á∑ö„ÄÇÊ†πÊìöÁµêÊûúÔºåÊàëÂÄëÁôºÁèæÂéüÁîüÂ±ÄÈÉ®Ë¶èÂâáÂàÜÈ°ûÂô®ÈÄöÂ∏∏ËàáÂÖ∂‰ªñÂàÜÈ°ûÂô®ÂÖ∑ÊúâÁ´∂Áà≠Âäõ„ÄÇÂä†ÂÖ•ÈùûÂ±ÄÈÉ®ÁßªÂãï‰ª•ËºÉÂ∞ëÁöÑÂèçË¶ÜÈÅãÁÆóÊ¨°Êï∏ÈÅîÊàêÈ°û‰ººÁöÑÁµêÊûúÔºåÂõ†Ê≠§‰ΩøÁî®Â∞àÁî®ÊàñÈáèÂ≠êÁ°¨È´îÂèØËÉΩÊúÉÈÄèÈÅéÂø´ÈÄüÊèêÂá∫ÈùûÂ±ÄÈÉ®ÁßªÂãï‰æÜÂä†ÈÄü„ÄÇ

##### **Utterance Classification with Logical Neural Network: Explainable AI for Mental Disorder Diagnosis**
2306.03902v1 by Yeldar Toleubay, Don Joven Agravante, Daiki Kimura, Baihan Lin, Djallel Bouneffouf, Michiaki Tatsubori

In response to the global challenge of mental health problems, we proposes a
Logical Neural Network (LNN) based Neuro-Symbolic AI method for the diagnosis
of mental disorders. Due to the lack of effective therapy coverage for mental
disorders, there is a need for an AI solution that can assist therapists with
the diagnosis. However, current Neural Network models lack explainability and
may not be trusted by therapists. The LNN is a Recurrent Neural Network
architecture that combines the learning capabilities of neural networks with
the reasoning capabilities of classical logic-based AI. The proposed system
uses input predicates from clinical interviews to output a mental disorder
class, and different predicate pruning techniques are used to achieve
scalability and higher scores. In addition, we provide an insight extraction
method to aid therapists with their diagnosis. The proposed system addresses
the lack of explainability of current Neural Network models and provides a more
trustworthy solution for mental disorder diagnosis.

ÊëòË¶ÅÔºöÁÇ∫‰∫ÜËß£Ê±∫ÂøÉÁêÜÂÅ•Â∫∑ÂïèÈ°åÁöÑÂÖ®ÁêÉÊåëÊà∞ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÂü∫ÊñºÈÇèËºØÁ•ûÁ∂ìÁ∂≤Ë∑Ø (LNN) ÁöÑÁ•ûÁ∂ìÁ¨¶Ëôü AI ÊñπÊ≥ï‰æÜË®∫Êñ∑ÂøÉÁêÜÁñæÁóÖ„ÄÇÁî±ÊñºÁº∫‰πèÊúâÊïàÁöÑÂøÉÁêÜÁñæÁóÖÊ≤ªÁôÇÊ∂µËìãÁØÑÂúçÔºåÂõ†Ê≠§ÈúÄË¶Å‰∏ÄÁ®Æ AI Ëß£Ê±∫ÊñπÊ°à‰æÜÂçîÂä©Ê≤ªÁôÇÂ∏´ÈÄ≤Ë°åË®∫Êñ∑„ÄÇÁÑ∂ËÄåÔºåÁõÆÂâçÁöÑÈ°ûÁ•ûÁ∂ìÁ∂≤Ë∑ØÊ®°ÂûãÁº∫‰πèÂèØËß£ÈáãÊÄßÔºåÊ≤ªÁôÇÂ∏´ÂèØËÉΩÁÑ°Ê≥ï‰ø°‰ªªÂÆÉÂÄë„ÄÇLNN ÊòØ‰∏ÄÁ®ÆÈÅûËø¥Á•ûÁ∂ìÁ∂≤Ë∑ØÊû∂ÊßãÔºåÂÆÉÁµêÂêà‰∫ÜÁ•ûÁ∂ìÁ∂≤Ë∑ØÁöÑÂ≠∏ÁøíËÉΩÂäõÂíåÂü∫ÊñºÁ∂ìÂÖ∏ÈÇèËºØÁöÑ AI ÁöÑÊé®ÁêÜËÉΩÂäõ„ÄÇÊâÄÊèêÂá∫ÁöÑÁ≥ªÁµ±‰ΩøÁî®‰æÜËá™Ëá®Â∫äË®™Ë´áÁöÑËº∏ÂÖ•Ë¨ÇË©û‰æÜËº∏Âá∫ÂøÉÁêÜÁñæÁóÖÈ°ûÂà•Ôºå‰∏¶‰ΩøÁî®‰∏çÂêåÁöÑË¨ÇË©ûÂâ™ÊûùÊäÄË°ì‰æÜÂØ¶ÁèæÂèØÊì¥ÂÖÖÊÄßÂíåÊõ¥È´òÁöÑÂàÜÊï∏„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèê‰æõ‰∫Ü‰∏ÄÂÄãË¶ãËß£ÊèêÂèñÊñπÊ≥ï‰æÜÂçîÂä©Ê≤ªÁôÇÂ∏´ÈÄ≤Ë°åË®∫Êñ∑„ÄÇÊâÄÊèêÂá∫ÁöÑÁ≥ªÁµ±Ëß£Ê±∫‰∫ÜÁï∂ÂâçÈ°ûÁ•ûÁ∂ìÁ∂≤Ë∑ØÊ®°ÂûãÁº∫‰πèÂèØËß£ÈáãÊÄßÁöÑÂïèÈ°åÔºå‰∏¶ÁÇ∫ÂøÉÁêÜÁñæÁóÖË®∫Êñ∑Êèê‰æõ‰∫ÜÊõ¥ÂÄºÂæó‰ø°Ë≥¥ÁöÑËß£Ê±∫ÊñπÊ°à„ÄÇ

##### **XAI Renaissance: Redefining Interpretability in Medical Diagnostic Models**
2306.01668v1 by Sujith K Mandala

As machine learning models become increasingly prevalent in medical
diagnostics, the need for interpretability and transparency becomes paramount.
The XAI Renaissance signifies a significant shift in the field, aiming to
redefine the interpretability of medical diagnostic models. This paper explores
the innovative approaches and methodologies within the realm of Explainable AI
(XAI) that are revolutionizing the interpretability of medical diagnostic
models. By shedding light on the underlying decision-making process, XAI
techniques empower healthcare professionals to understand, trust, and
effectively utilize these models for accurate and reliable medical diagnoses.
This review highlights the key advancements in XAI for medical diagnostics and
their potential to transform the healthcare landscape, ultimately improving
patient outcomes and fostering trust in AI-driven diagnostic systems.

ÊëòË¶ÅÔºöÈö®ËëóÊ©üÂô®Â≠∏ÁøíÊ®°ÂûãÂú®ÈÜ´ÁôÇË®∫Êñ∑‰∏≠Ë∂ä‰æÜË∂äÊôÆÈÅçÔºåÂèØËß£ÈáãÊÄßÂíåÈÄèÊòéÂ∫¶ÁöÑÈúÄÊ±ÇËÆäÂæóËá≥ÈóúÈáçË¶Å„ÄÇXAI Âæ©ËààÊ®ôË™åËëóË©≤È†òÂüüÁöÑÈáçÂ§ßËΩâËÆäÔºåÊó®Âú®ÈáçÊñ∞ÂÆöÁæ©ÈÜ´ÁôÇË®∫Êñ∑Ê®°ÂûãÁöÑÂèØËß£ÈáãÊÄß„ÄÇÊú¨ÊñáÊé¢Ë®é‰∫ÜÂèØËß£Èáã AI (XAI) È†òÂüüÂÖßÁöÑÂâµÊñ∞ÊñπÊ≥ïÂíåÊñπÊ≥ïË´ñÔºåÈÄô‰∫õÊñπÊ≥ïÂíåÊñπÊ≥ïË´ñÊ≠£Âú®Èù©Êñ∞ÈÜ´ÁôÇË®∫Êñ∑Ê®°ÂûãÁöÑÂèØËß£ÈáãÊÄß„ÄÇÈÄöÈÅéÈó°ÊòéÂü∫Á§éÊ±∫Á≠ñÂà∂ÂÆöÈÅéÁ®ãÔºåXAI ÊäÄË°ì‰ΩøÈÜ´ÁôÇ‰øùÂÅ•Â∞àÊ•≠‰∫∫Âì°ËÉΩÂ§†ÁêÜËß£„ÄÅ‰ø°‰ªª‰∏¶ÊúâÊïàÂú∞Âà©Áî®ÈÄô‰∫õÊ®°ÂûãÈÄ≤Ë°åÊ∫ñÁ¢∫‰∏îÂèØÈù†ÁöÑÈÜ´ÁôÇË®∫Êñ∑„ÄÇÊú¨Á∂úËø∞ÈáçÈªû‰ªãÁ¥π‰∫Ü XAI Âú®ÈÜ´ÁôÇË®∫Êñ∑ÊñπÈù¢ÁöÑÈóúÈçµÈÄ≤Â±ïÂèäÂÖ∂ËΩâËÆäÈÜ´ÁôÇ‰øùÂÅ•È†òÂüüÁöÑÊΩõÂäõÔºåÊúÄÁµÇÊîπÂñÑÊÇ£ËÄÖÁöÑÊ≤ªÁôÇÊïàÊûú‰∏¶ÂüπÈ§äÂ∞ç AI È©ÖÂãïÁöÑË®∫Êñ∑Á≥ªÁµ±ÁöÑ‰ø°‰ªª„ÄÇ

##### **A Novel real-time arrhythmia detection model using YOLOv8**
2305.16727v3 by Guang Jun Nicholas Ang, Aritejh Kr Goil, Henryk Chan, Jieyi Jeric Lew, Xin Chun Lee, Raihan Bin Ahmad Mustaffa, Timotius Jason, Ze Ting Woon, Bingquan Shen

In a landscape characterized by heightened connectivity and mobility, coupled
with a surge in cardiovascular ailments, the imperative to curtail healthcare
expenses through remote monitoring of cardiovascular health has become more
pronounced. The accurate detection and classification of cardiac arrhythmias
are pivotal for diagnosing individuals with heart irregularities. This study
underscores the feasibility of employing electrocardiograms (ECG) measurements
in the home environment for real-time arrhythmia detection. Presenting a fresh
application for arrhythmia detection, this paper leverages the cutting-edge
You-Only-Look-Once (YOLO)v8 algorithm to categorize single-lead ECG signals. We
introduce a novel loss-modified YOLOv8 model, fine-tuned on the MIT-BIH
arrhythmia dataset, enabling real-time continuous monitoring. The obtained
results substantiate the efficacy of our approach, with the model attaining an
average accuracy of 99.5% and 0.992 mAP@50, and a rapid detection time of 0.002
seconds on an NVIDIA Tesla V100. Our investigation exemplifies the potential of
real-time arrhythmia detection, enabling users to visually interpret the model
output within the comfort of their homes. Furthermore, this study lays the
groundwork for an extension into a real-time explainable AI (XAI) model capable
of deployment in the healthcare sector, thereby significantly advancing the
realm of healthcare solutions.

ÊëòË¶ÅÔºö<paragraph>Âú®‰ª•È´òÂ∫¶ÈÄ£Êé•ÊÄßÂíåÊµÅÂãïÊÄßÁÇ∫ÁâπÂæµÁöÑÁí∞Â¢É‰∏≠ÔºåÂä†‰∏äÂøÉË°ÄÁÆ°ÁñæÁóÖÁöÑÊøÄÂ¢ûÔºåÈÄöÈÅéÈÅ†Á®ãÁõ£ÊéßÂøÉË°ÄÁÆ°ÂÅ•Â∫∑‰æÜÂâäÊ∏õÈÜ´ÁôÇ‰øùÂÅ•ÊîØÂá∫ÁöÑÂøÖË¶ÅÊÄßËÆäÂæóÊõ¥Âä†ÊòéÈ°Ø„ÄÇÊ∫ñÁ¢∫Ê™¢Ê∏¨ÂíåÂàÜÈ°ûÂøÉÂæã‰∏çÊï¥Â∞çÊñºË®∫Êñ∑ÊÇ£ÊúâÂøÉËáü‰∏çË¶èÂâáÁöÑ‰∫∫Ëá≥ÈóúÈáçË¶Å„ÄÇÊú¨Á†îÁ©∂Âº∑Ë™ø‰∫ÜÂú®ÂÆ∂‰∏≠‰ΩøÁî®ÂøÉÈõªÂúñ (ECG) Ê∏¨ÈáèÈÄ≤Ë°åÂØ¶ÊôÇÂøÉÂæã‰∏çÊï¥Ê™¢Ê∏¨ÁöÑÂèØË°åÊÄß„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞ÁöÑÂøÉÂæã‰∏çÊï¥Ê™¢Ê∏¨ÊáâÁî®ÔºåÂà©Áî®Â∞ñÁ´ØÁöÑ You-Only-Look-Once (YOLO)v8 ÊºîÁÆóÊ≥ïÂ∞çÂñÆÂ∞éËÅØ ECG Ë®äËôüÈÄ≤Ë°åÂàÜÈ°û„ÄÇÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÊñ∞Á©éÁöÑÊêçÂ§±‰øÆÊîπ YOLOv8 Ê®°ÂûãÔºå‰∏¶ÈáùÂ∞ç MIT-BIH ÂøÉÂæã‰∏çÊï¥Ë≥áÊñôÈõÜÈÄ≤Ë°å‰∫ÜÂæÆË™øÔºåÂæûËÄåÂØ¶Áèæ‰∫ÜÂØ¶ÊôÇÁöÑÊåÅÁ∫åÁõ£Êéß„ÄÇÁç≤ÂæóÁöÑÁµêÊûúË≠âÂØ¶‰∫ÜÊàëÂÄëÊñπÊ≥ïÁöÑÊúâÊïàÊÄßÔºåË©≤Ê®°ÂûãÂú® NVIDIA Tesla V100 ‰∏äÈÅîÂà∞‰∫Ü 99.5% ÁöÑÂπ≥ÂùáÊ∫ñÁ¢∫Â∫¶Âíå 0.992 mAP@50Ôºå‰ª•Âèä 0.002 ÁßíÁöÑÂø´ÈÄüÊ™¢Ê∏¨ÊôÇÈñì„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂Ë™™Êòé‰∫ÜÂØ¶ÊôÇÂøÉÂæã‰∏çÊï¥Ê™¢Ê∏¨ÁöÑÊΩõÂäõÔºå‰ΩøÁî®Êà∂ËÉΩÂ§†Âú®ÂÆ∂‰∏≠ËàíÈÅ©Âú∞Ë¶ñË¶∫ÂåñËß£ËÆÄÊ®°ÂûãËº∏Âá∫„ÄÇÊ≠§Â§ñÔºåÊú¨Á†îÁ©∂ÁÇ∫Êì¥Â±ïÂà∞ÂØ¶ÊôÇÂèØËß£Èáã AI (XAI) Ê®°ÂûãÂ•†ÂÆö‰∫ÜÂü∫Á§éÔºåË©≤Ê®°ÂûãËÉΩÂ§†ÈÉ®ÁΩ≤Âú®ÈÜ´ÁôÇ‰øùÂÅ•È†òÂüüÔºåÂæûËÄåÈ°ØËëóÊé®ÈÄ≤ÈÜ´ÁôÇ‰øùÂÅ•Ëß£Ê±∫ÊñπÊ°àÁöÑÈ†òÂüü„ÄÇ</paragraph>

##### **Breast Cancer Segmentation using Attention-based Convolutional Network and Explainable AI**
2305.14389v2 by Jai Vardhan, Taraka Satya Krishna Teja Malisetti

Breast cancer (BC) remains a significant health threat, with no long-term
cure currently available. Early detection is crucial, yet mammography
interpretation is hindered by high false positives and negatives. With BC
incidence projected to surpass lung cancer, improving early detection methods
is vital. Thermography, using high-resolution infrared cameras, offers promise,
especially when combined with artificial intelligence (AI). This work presents
an attention-based convolutional neural network for segmentation, providing
increased speed and precision in BC detection and classification. The system
enhances images and performs cancer segmentation with explainable AI. We
propose a transformer-attention-based convolutional architecture (UNet) for
fault identification and employ Gradient-weighted Class Activation Mapping
(Grad-CAM) to analyze areas of bias and weakness in the UNet architecture with
IRT images. The superiority of our proposed framework is confirmed when
compared with existing deep learning frameworks.

ÊëòË¶ÅÔºö‰π≥ÁôåÔºàBCÔºâ‰ªçÁÑ∂ÊòØ‰∏ÄÂÄãÈáçÂ§ßÁöÑÂÅ•Â∫∑Â®ÅËÑÖÔºåÁõÆÂâçÂ∞öÁÑ°Èï∑ÊúüÊ≤ªÁôíÁöÑÊñπÊ≥ï„ÄÇÊó©ÊúüÁôºÁèæËá≥ÈóúÈáçË¶ÅÔºå‰ΩÜ‰π≥ÊàøÊîùÂΩ±ÁöÑÂà§ËÆÄÂçªÂèóÂà∞È´òÂÅáÈôΩÊÄßÂíåÂÅáÈô∞ÊÄßÁöÑÈòªÁ§ô„ÄÇÁî±Êñº‰π≥ÁôåÁöÑÁôºÁîüÁéáÈ†êË®àÂ∞áË∂ÖÈÅéËÇ∫ÁôåÔºåÂõ†Ê≠§ÊîπÂñÑÊó©ÊúüÊ™¢Ê∏¨ÊñπÊ≥ïËá≥ÈóúÈáçË¶Å„ÄÇÁÜ±ÂÉèÊîùÂΩ±‰ΩøÁî®È´òËß£ÊûêÂ∫¶Á¥ÖÂ§ñÁ∑öÁõ∏Ê©üÔºåÁâπÂà•ÊòØÂú®Ëàá‰∫∫Â∑•Êô∫ÊÖßÔºàAIÔºâÁµêÂêà‰ΩøÁî®ÊôÇÔºåÊèê‰æõ‰∫ÜÂ∏åÊúõ„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂü∫ÊñºÊ≥®ÊÑèÂäõÁöÑÂç∑Á©çÁ•ûÁ∂ìÁ∂≤Ë∑ØÁî®ÊñºÂàÜÂâ≤ÔºåÂú®‰π≥ÁôåÊ™¢Ê∏¨ÂíåÂàÜÈ°û‰∏≠Êèê‰æõ‰∫ÜÊõ¥È´òÁöÑÈÄüÂ∫¶ÂíåÁ≤æÂ∫¶„ÄÇË©≤Á≥ªÁµ±Â¢ûÂº∑ÂΩ±ÂÉè‰∏¶Âü∑Ë°åÂèØËß£ÈáãÁöÑ AI ÁôåÁóáÂàÜÂâ≤„ÄÇÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂü∫ÊñºTransformerÊ≥®ÊÑèÂäõÁöÑÂç∑Á©çÊû∂ÊßãÔºàUNetÔºâÁî®ÊñºÊïÖÈöúË≠òÂà•Ôºå‰∏¶‰ΩøÁî®Ê¢ØÂ∫¶Âä†Ê¨äÈ°ûÊøÄÊ¥ªÊò†Â∞ÑÔºàGrad-CAMÔºâ‰æÜÂàÜÊûê UNet Êû∂Êßã‰∏≠ÂÅèË¶ãÂíåÂº±ÈªûÁöÑÂçÄÂüüÔºå‰ΩøÁî® IRT ÂΩ±ÂÉè„ÄÇËàáÁèæÊúâÁöÑÊ∑±Â∫¶Â≠∏ÁøíÊ°ÜÊû∂Áõ∏ÊØîÔºåÊàëÂÄëÊèêÂá∫ÁöÑÊ°ÜÊû∂ÁöÑÂÑ™Ë∂äÊÄßÂæóÂà∞Ë≠âÂØ¶„ÄÇ

##### **What Symptoms and How Long? An Interpretable AI Approach for Depression Detection in Social Media**
2305.13127v2 by Junwei Kuang, Jiaheng Xie, Zhijun Yan

Depression is the most prevalent and serious mental illness, which induces
grave financial and societal ramifications. Depression detection is key for
early intervention to mitigate those consequences. Such a high-stake decision
inherently necessitates interpretability. Although a few depression detection
studies attempt to explain the decision based on the importance score or
attention weights, these explanations misalign with the clinical depression
diagnosis criterion that is based on depressive symptoms. To fill this gap, we
follow the computational design science paradigm to develop a novel Multi-Scale
Temporal Prototype Network (MSTPNet). MSTPNet innovatively detects and
interprets depressive symptoms as well as how long they last. Extensive
empirical analyses using a large-scale dataset show that MSTPNet outperforms
state-of-the-art depression detection methods with an F1-score of 0.851. This
result also reveals new symptoms that are unnoted in the survey approach, such
as sharing admiration for a different life. We further conduct a user study to
demonstrate its superiority over the benchmarks in interpretability. This study
contributes to IS literature with a novel interpretable deep learning model for
depression detection in social media. In practice, our proposed method can be
implemented in social media platforms to provide personalized online resources
for detected depressed patients.

ÊëòË¶ÅÔºöÊÜÇÈ¨±ÁóáÊòØÊúÄÊôÆÈÅç‰∏îÂö¥ÈáçÁöÑÁ≤æÁ•ûÁñæÁóÖÔºåÊúÉÈÄ†ÊàêÂö¥ÈáçÁöÑË≤°ÂãôÂíåÁ§æÊúÉÂæåÊûú„ÄÇÊÜÇÈ¨±ÁóáÁöÑÂÅµÊ∏¨Â∞çÊñºÊó©Êúü‰ªãÂÖ•‰ª•Ê∏õËºïÈÄô‰∫õÂæåÊûúËá≥ÈóúÈáçË¶Å„ÄÇÂ¶ÇÊ≠§ÈáçÂ§ßÁöÑÊ±∫ÂÆöÊú¨Ë≥™‰∏äÈúÄË¶ÅÂèØËß£ÈáãÊÄß„ÄÇÂÑòÁÆ°‰∏Ä‰∫õÊÜÇÈ¨±ÁóáÂÅµÊ∏¨Á†îÁ©∂ÂòóË©¶Ê†πÊìöÈáçË¶ÅÊÄßÂàÜÊï∏ÊàñÊ≥®ÊÑèÂäõÊ¨äÈáç‰æÜËß£ÈáãÈÄôÂÄãÊ±∫ÂÆöÔºå‰ΩÜÈÄô‰∫õËß£ÈáãËàáÂü∫ÊñºÊÜÇÈ¨±ÁóáÁãÄÁöÑËá®Â∫äÊÜÇÈ¨±ÁóáË®∫Êñ∑Ê®ôÊ∫ñ‰∏ç‰∏ÄËá¥„ÄÇÁÇ∫‰∫ÜÂ°´Ë£úÈÄôÂÄãÁº∫Âè£ÔºåÊàëÂÄëÈÅµÂæ™Ë®àÁÆóË®≠Ë®àÁßëÂ≠∏ÁØÑ‰æã‰æÜÈñãÁôº‰∏ÄÂÄãÊñ∞Á©éÁöÑÂ§öÂ∞∫Â∫¶ÊôÇÈñìÂéüÂûãÁ∂≤Ë∑Ø (MSTPNet)„ÄÇMSTPNet ÂâµÊñ∞Âú∞ÂÅµÊ∏¨‰∏¶Ëß£ÈáãÊÜÇÈ¨±ÁóáÁãÄ‰ª•ÂèäÂÆÉÂÄëÊåÅÁ∫åÂ§ö‰πÖ„ÄÇ‰ΩøÁî®Â§ßË¶èÊ®°Ë≥áÊñôÈõÜÈÄ≤Ë°åÁöÑÂª£Ê≥õÂØ¶Ë≠âÂàÜÊûêÈ°ØÁ§∫ÔºåMSTPNet ‰ª• 0.851 ÁöÑ F1 ÂàÜÊï∏ÂÑ™ÊñºÊúÄÂÖàÈÄ≤ÁöÑÊÜÇÈ¨±ÁóáÂÅµÊ∏¨ÊñπÊ≥ï„ÄÇÊ≠§ÁµêÊûúÈÇÑÊè≠Á§∫‰∫ÜË™øÊü•ÊñπÊ≥ï‰∏≠Êú™Ê≥®ÊÑèÂà∞ÁöÑÊñ∞ÁóáÁãÄÔºå‰æãÂ¶ÇÂàÜ‰∫´Â∞ç‰∏çÂêåÁîüÊ¥ªÁöÑÊ¨Ω‰Ω©„ÄÇÊàëÂÄëÈÄ≤‰∏ÄÊ≠•ÈÄ≤Ë°å‰ΩøÁî®ËÄÖÁ†îÁ©∂Ôºå‰ª•Ë≠âÊòéÂÖ∂Âú®ÂèØËß£ÈáãÊÄßÊñπÈù¢ÂÑ™ÊñºÂü∫Ê∫ñ„ÄÇÊú¨Á†îÁ©∂‰ª•‰∏ÄÂÄãÊñ∞Á©éÁöÑÂèØËß£ÈáãÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÁÇ∫ÊÜÇÈ¨±ÁóáÂÅµÊ∏¨Âú®Á§æÁæ§Â™íÈ´î‰∏≠ÁöÑ IS ÊñáÁçªÂÅöÂá∫Ë≤¢Áçª„ÄÇÂú®ÂØ¶Âãô‰∏äÔºåÊàëÂÄëÊèêÂá∫ÁöÑÊñπÊ≥ïÂèØ‰ª•ÂØ¶‰ΩúÂú®Á§æÁæ§Â™íÈ´îÂπ≥Âè∞‰∏≠Ôºå‰ª•Êèê‰æõÂÄã‰∫∫ÂåñÁöÑÁ∑ö‰∏äË≥áÊ∫êÁµ¶Ë¢´ÂÅµÊ∏¨Âá∫ÊÜÇÈ¨±ÁóáÁöÑÊÇ£ËÄÖ„ÄÇ

##### **Echoes of Biases: How Stigmatizing Language Affects AI Performance**
2305.10201v4 by Yizhi Liu, Weiguang Wang, Guodong Gordon Gao, Ritu Agarwal

Electronic health records (EHRs) serve as an essential data source for the
envisioned artificial intelligence (AI)-driven transformation in healthcare.
However, clinician biases reflected in EHR notes can lead to AI models
inheriting and amplifying these biases, perpetuating health disparities. This
study investigates the impact of stigmatizing language (SL) in EHR notes on
mortality prediction using a Transformer-based deep learning model and
explainable AI (XAI) techniques. Our findings demonstrate that SL written by
clinicians adversely affects AI performance, particularly so for black
patients, highlighting SL as a source of racial disparity in AI model
development. To explore an operationally efficient way to mitigate SL's impact,
we investigate patterns in the generation of SL through a clinicians'
collaborative network, identifying central clinicians as having a stronger
impact on racial disparity in the AI model. We find that removing SL written by
central clinicians is a more efficient bias reduction strategy than eliminating
all SL in the entire corpus of data. This study provides actionable insights
for responsible AI development and contributes to understanding clinician
behavior and EHR note writing in healthcare.

ÊëòË¶ÅÔºöÈõªÂ≠êÂÅ•Â∫∑Á¥ÄÈåÑ (EHR) ‰ΩúÁÇ∫È†êÊÉ≥‰∏≠Áî±‰∫∫Â∑•Êô∫ÊÖß (AI) Êé®ÂãïÁöÑÈÜ´ÁôÇ‰øùÂÅ•ËΩâÂûãÁöÑÈáçË¶ÅË≥áÊñô‰æÜÊ∫ê„ÄÇÁÑ∂ËÄåÔºåÂèçÊò†Âú® EHR ÂÇôË®ª‰∏≠ÁöÑËá®Â∫äÂÅèË¶ãÂèØËÉΩÂ∞éËá¥ AI Ê®°ÂûãÁπºÊâø‰∏¶Êì¥Â§ßÈÄô‰∫õÂÅèË¶ãÔºåÈÄ≤ËÄåÈÄ†ÊàêÂÅ•Â∫∑Â∑ÆÁï∞„ÄÇÊú¨Á†îÁ©∂Êé¢Ë®é EHR ÂÇôË®ª‰∏≠Ê±ôÂêçÂåñË™ûË®Ä (SL) Â∞ç‰ΩøÁî®Âü∫Êñº Transformer ÁöÑÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÂíåÂèØËß£Èáã AI (XAI) ÊäÄË°ìÈ†êÊ∏¨Ê≠ª‰∫°ÁéáÁöÑÂΩ±Èüø„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúË°®ÊòéÔºåÁî±Ëá®Â∫äÈÜ´ÁîüÊí∞ÂØ´ÁöÑ SL ÊúÉÂ∞ç AI ÊïàËÉΩÁî¢Áîü‰∏çÂà©ÂΩ±ÈüøÔºåÁâπÂà•ÊòØÂ∞çÈªë‰∫∫ÊÇ£ËÄÖËÄåË®ÄÔºåÁ™ÅÈ°Ø SL ÊòØ AI Ê®°ÂûãÈñãÁôº‰∏≠Á®ÆÊóèÂ∑ÆÁï∞ÁöÑ‰æÜÊ∫ê„ÄÇÁÇ∫‰∫ÜÊé¢Á¥¢‰∏ÄÁ®ÆÈÅã‰Ωú‰∏äÊúâÊïàÁéáÁöÑÊñπÊ≥ï‰æÜÊ∏õËºï SL ÁöÑÂΩ±ÈüøÔºåÊàëÂÄëÈÄèÈÅéËá®Â∫äÈÜ´ÁîüÁöÑÂçî‰ΩúÁ∂≤Ë∑ØÊé¢Ë®é SL Áî¢ÁîüÁöÑÊ®°ÂºèÔºå‰∏¶ÊâæÂá∫Ê†∏ÂøÉËá®Â∫äÈÜ´ÁîüÂ∞ç AI Ê®°Âûã‰∏≠ÁöÑÁ®ÆÊóèÂ∑ÆÁï∞ÊúâËºÉÂ§ßÁöÑÂΩ±Èüø„ÄÇÊàëÂÄëÁôºÁèæÔºåÁßªÈô§Áî±Ê†∏ÂøÉËá®Â∫äÈÜ´ÁîüÊí∞ÂØ´ÁöÑ SL ÊòØÊØîÊ∂àÈô§Ë≥áÊñôÈõÜ‰∏≠ÊâÄÊúâ SL Êõ¥ÊúâÊïàÁéáÁöÑÂÅèË¶ãÊ∏õÂ∞ëÁ≠ñÁï•„ÄÇÊú¨Á†îÁ©∂Êèê‰æõÂèØË°åÁöÑË¶ãËß£ÔºåÁî®ÊñºË≤†Ë≤¨‰ªªÁöÑ AI ÈñãÁôºÔºå‰∏¶ÊúâÂä©Êñº‰∫ÜËß£Ëá®Â∫äÈÜ´ÁîüË°åÁÇ∫ÂíåÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÁöÑ EHR ÂÇôË®ªÊí∞ÂØ´„ÄÇ


### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-08-16**|**xGen-MM (BLIP-3): A Family of Open Large Multimodal Models**|Le Xue et.al.|[2408.08872v1](http://arxiv.org/abs/2408.08872v1)|null|
|**2024-08-16**|**PEDAL: Enhancing Greedy Decoding with Large Language Models using Diverse Exemplars**|Sumanth Prabhu et.al.|[2408.08869v1](http://arxiv.org/abs/2408.08869v1)|null|
|**2024-08-16**|**GeoTransformer: Enhancing Urban Forecasting with Geospatial Attention Mechanisms**|Yuhao Jia et.al.|[2408.08852v1](http://arxiv.org/abs/2408.08852v1)|null|
|**2024-08-16**|**PsychoLex: Unveiling the Psychological Mind of Large Language Models**|Mohammad Amin Abbasi et.al.|[2408.08848v1](http://arxiv.org/abs/2408.08848v1)|null|
|**2024-08-16**|**FLEXTAF: Enhancing Table Reasoning with Flexible Tabular Formats**|Xuanliang Zhang et.al.|[2408.08841v1](http://arxiv.org/abs/2408.08841v1)|[link](https://github.com/zhxlia/FLEXTAF)|
|**2024-08-16**|**EasyRec: Simple yet Effective Language Models for Recommendation**|Xubin Ren et.al.|[2408.08821v1](http://arxiv.org/abs/2408.08821v1)|[link](https://github.com/hkuds/easyrec)|
|**2024-08-16**|**Constructing Domain-Specific Evaluation Sets for LLM-as-a-judge**|Ravi Raju et.al.|[2408.08808v1](http://arxiv.org/abs/2408.08808v1)|null|
|**2024-08-16**|**CIKMar: A Dual-Encoder Approach to Prompt-Based Reranking in Educational Dialogue Systems**|Joanito Agili Lopo et.al.|[2408.08805v1](http://arxiv.org/abs/2408.08805v1)|null|
|**2024-08-16**|**Leveraging FourierKAN Classification Head for Pre-Trained Transformer-based Text Classification**|Abdullah Al Imran et.al.|[2408.08803v1](http://arxiv.org/abs/2408.08803v1)|null|
|**2024-08-16**|**A Disease-Specific Foundation Model Using Over 100K Fundus Images: Release and Validation for Abnormality and Multi-Disease Classification on Downstream Tasks**|Boa Jang et.al.|[2408.08790v1](http://arxiv.org/abs/2408.08790v1)|[link](https://github.com/Jang-Boa/Research-Foundation-Retina)|
|**2024-08-16**|**A Transparency Paradox? Investigating the Impact of Explanation Specificity and Autonomous Vehicle Perceptual Inaccuracies on Passengers**|Daniel Omeiza et.al.|[2408.08785v1](http://arxiv.org/abs/2408.08785v1)|null|
|**2024-08-16**|**EmoDynamiX: Emotional Support Dialogue Strategy Prediction by Modelling MiXed Emotions and Discourse Dynamics**|Chenwei Wan et.al.|[2408.08782v1](http://arxiv.org/abs/2408.08782v1)|[link](https://github.com/cw-wan/EmoDynamiX-v2)|
|**2024-08-16**|**Evaluating the Evaluator: Measuring LLMs' Adherence to Task Evaluation Instructions**|Bhuvanashree Murugadoss et.al.|[2408.08781v1](http://arxiv.org/abs/2408.08781v1)|null|
|**2024-08-16**|**Large Language Models Might Not Care What You Are Saying: Prompt Format Beats Descriptions**|Chenming Tang et.al.|[2408.08780v1](http://arxiv.org/abs/2408.08780v1)|null|
|**2024-08-16**|**DAC: Decomposed Automation Correction for Text-to-SQL**|Dingzirui Wang et.al.|[2408.08779v1](http://arxiv.org/abs/2408.08779v1)|[link](https://github.com/zirui-HIT/DAC)|
|**2024-08-16**|**Pessimistic Iterative Planning for Robust POMDPs**|Maris F. L. Galesloot et.al.|[2408.08770v1](http://arxiv.org/abs/2408.08770v1)|null|
|**2024-08-16**|**Lower Layer Matters: Alleviating Hallucination via Multi-Layer Fusion Contrastive Decoding with Truthfulness Refocused**|Dingwei Chen et.al.|[2408.08769v1](http://arxiv.org/abs/2408.08769v1)|null|
|**2024-08-16**|**ASVspoof 5: Crowdsourced Speech Data, Deepfakes, and Adversarial Attacks at Scale**|Xin Wang et.al.|[2408.08739v1](http://arxiv.org/abs/2408.08739v1)|null|
|**2024-08-16**|**ChatZero:Zero-shot Cross-Lingual Dialogue Generation via Pseudo-Target Language**|Yongkang Liu et.al.|[2408.08724v1](http://arxiv.org/abs/2408.08724v1)|null|
|**2024-08-16**|**Beyond KAN: Introducing KarSein for Adaptive High-Order Feature Interaction Modeling in CTR Prediction**|Yunxiao Shi et.al.|[2408.08713v1](http://arxiv.org/abs/2408.08713v1)|null|
|**2024-08-16**|**Beam Prediction based on Large Language Models**|Yucheng Sheng et.al.|[2408.08707v1](http://arxiv.org/abs/2408.08707v1)|null|
|**2024-08-16**|**Beyond the Hype: A dispassionate look at vision-language models in medical scenario**|Yang Nan et.al.|[2408.08704v1](http://arxiv.org/abs/2408.08704v1)|null|
|**2024-08-16**|**NFDI4DSO: Towards a BFO Compliant Ontology for Data Science**|Genet Asefa Gesese et.al.|[2408.08698v1](http://arxiv.org/abs/2408.08698v1)|null|
|**2024-08-16**|**Turning Trash into Treasure: Accelerating Inference of Large Language Models with Token Recycling**|Xianzhen Luo et.al.|[2408.08696v1](http://arxiv.org/abs/2408.08696v1)|null|
|**2024-08-16**|**Quantifying the Effectiveness of Student Organization Activities using Natural Language Processing**|Lyberius Ennio F. Taruc et.al.|[2408.08694v1](http://arxiv.org/abs/2408.08694v1)|null|
|**2024-08-16**|**Med-PMC: Medical Personalized Multi-modal Consultation with a Proactive Ask-First-Observe-Next Paradigm**|Hongcheng Liu et.al.|[2408.08693v1](http://arxiv.org/abs/2408.08693v1)|[link](https://github.com/liuhc0428/med-pmc)|
|**2024-08-16**|**The Fellowship of the LLMs: Multi-Agent Workflows for Synthetic Preference Optimization Dataset Generation**|Samee Arif et.al.|[2408.08688v1](http://arxiv.org/abs/2408.08688v1)|[link](https://github.com/ulrs0/MA-PO)|
|**2024-08-16**|**SC-Rec: Enhancing Generative Retrieval with Self-Consistent Reranking for~Sequential Recommendation**|Tongyoung Kim et.al.|[2408.08686v1](http://arxiv.org/abs/2408.08686v1)|null|
|**2024-08-16**|**Can Large Language Models Improve the Adversarial Robustness of Graph Neural Networks?**|Zhongjian Zhang et.al.|[2408.08685v1](http://arxiv.org/abs/2408.08685v1)|null|
|**2024-08-16**|**LLM-PCGC: Large Language Model-based Point Cloud Geometry Compression**|Yuqi Ye et.al.|[2408.08682v1](http://arxiv.org/abs/2408.08682v1)|null|
|**2024-08-16**|**Fine-tuning LLMs for Autonomous Spacecraft Control: A Case Study Using Kerbal Space Program**|Alejandro Carrasco et.al.|[2408.08676v1](http://arxiv.org/abs/2408.08676v1)|[link](https://github.com/arclab-mit/kspdg)|
|**2024-08-16**|**MAT-SED: AMasked Audio Transformer with Masked-Reconstruction Based Pre-training for Sound Event Detection**|Pengfei Cai et.al.|[2408.08673v1](http://arxiv.org/abs/2408.08673v1)|null|
|**2024-08-16**|**Adaptive Layer Selection for Efficient Vision Transformer Fine-Tuning**|Alessio Devoto et.al.|[2408.08670v1](http://arxiv.org/abs/2408.08670v1)|null|
|**2024-08-16**|**MIA-Tuner: Adapting Large Language Models as Pre-training Text Detector**|Wenjie Fu et.al.|[2408.08661v1](http://arxiv.org/abs/2408.08661v1)|null|
|**2024-08-16**|**LLMs Are Biased Towards Output Formats! Systematically Evaluating and Mitigating Output Format Bias of LLMs**|Do Xuan Long et.al.|[2408.08656v1](http://arxiv.org/abs/2408.08656v1)|[link](https://github.com/dxlong2000/FormatEval)|
|**2024-08-16**|**Mitigating Backdoor Attacks in Federated Learning via Flipping Weight Updates of Low-Activation Input Neurons**|Binbin Ding et.al.|[2408.08655v1](http://arxiv.org/abs/2408.08655v1)|null|
|**2024-08-16**|**TextCAVs: Debugging vision models using text**|Angus Nicolson et.al.|[2408.08652v1](http://arxiv.org/abs/2408.08652v1)|[link](https://github.com/angusnicolson/textcavs)|
|**2024-08-16**|**Reasoning Beyond Bias: A Study on Counterfactual Prompting and Chain of Thought Reasoning**|Kyle Moore et.al.|[2408.08651v1](http://arxiv.org/abs/2408.08651v1)|null|
|**2024-08-16**|**An End-to-End Model for Photo-Sharing Multi-modal Dialogue Generation**|Peiming Guo et.al.|[2408.08650v1](http://arxiv.org/abs/2408.08650v1)|null|
|**2024-08-16**|**Understanding Enthymemes in Argument Maps: Bridging Argument Mining and Logic-based Argumentation**|Jonathan Ben-Naim et.al.|[2408.08648v1](http://arxiv.org/abs/2408.08648v1)|null|
|**2024-08-16**|**Math-PUMA: Progressive Upward Multimodal Alignment to Enhance Mathematical Reasoning**|Wenwen Zhuang et.al.|[2408.08640v1](http://arxiv.org/abs/2408.08640v1)|null|
|**2024-08-16**|**A Survey on Benchmarks of Multimodal Large Language Models**|Jian Li et.al.|[2408.08632v1](http://arxiv.org/abs/2408.08632v1)|[link](https://github.com/swordlidev/evaluation-multimodal-llms-survey)|
|**2024-08-16**|**Persona is a Double-edged Sword: Enhancing the Zero-shot Reasoning by Ensembling the Role-playing and Neutral Prompts**|Junseok Kim et.al.|[2408.08631v1](http://arxiv.org/abs/2408.08631v1)|null|
|**2024-08-16**|**RealMedQA: A pilot biomedical question answering dataset containing realistic clinical questions**|Gregory Kell et.al.|[2408.08624v1](http://arxiv.org/abs/2408.08624v1)|null|
|**2024-08-16**|**DeepDFA: Automata Learning through Neural Probabilistic Relaxations**|Elena Umili et.al.|[2408.08622v1](http://arxiv.org/abs/2408.08622v1)|[link](https://github.com/whitemech/deepdfa)|
|**2024-08-16**|**PatUntrack: Automated Generating Patch Examples for Issue Reports without Tracked Insecure Code**|Ziyou Jiang et.al.|[2408.08619v1](http://arxiv.org/abs/2408.08619v1)|null|
|**2024-08-16**|**Generative Dataset Distillation Based on Diffusion Model**|Duo Su et.al.|[2408.08610v1](http://arxiv.org/abs/2408.08610v1)|[link](https://github.com/guang000/banko)|
|**2024-08-16**|**MM-UNet: A Mixed MLP Architecture for Improved Ophthalmic Image Segmentation**|Zunjie Xiao et.al.|[2408.08600v1](http://arxiv.org/abs/2408.08600v1)|null|
|**2024-08-16**|**A Mechanistic Interpretation of Syllogistic Reasoning in Auto-Regressive Language Models**|Geonhee Kim et.al.|[2408.08590v1](http://arxiv.org/abs/2408.08590v1)|null|
|**2024-08-16**|**AgentSimulator: An Agent-based Approach for Data-driven Business Process Simulation**|Lukas Kirchdorfer et.al.|[2408.08571v1](http://arxiv.org/abs/2408.08571v1)|[link](https://github.com/lukaskirchdorfer/agentsimulator)|
|**2024-08-16**|**Overview of the BioLaySumm 2024 Shared Task on the Lay Summarization of Biomedical Research Articles**|Tomas Goldsack et.al.|[2408.08566v1](http://arxiv.org/abs/2408.08566v1)|null|
|**2024-08-16**|**Collaborative Cross-modal Fusion with Large Language Model for Recommendation**|Zhongzhou Liu et.al.|[2408.08564v1](http://arxiv.org/abs/2408.08564v1)|null|
|**2024-08-16**|**Integrating Multi-view Analysis: Multi-view Mixture-of-Expert for Textual Personality Detection**|Haohao Zhu et.al.|[2408.08551v1](http://arxiv.org/abs/2408.08551v1)|null|
|**2024-08-16**|**SelectLLM: Query-Aware Efficient Selection Algorithm for Large Language Models**|Kaushal Kumar Maurya et.al.|[2408.08545v1](http://arxiv.org/abs/2408.08545v1)|null|
|**2024-08-16**|**Where is the signal in tokenization space?**|Renato Lui Geh et.al.|[2408.08541v1](http://arxiv.org/abs/2408.08541v1)|null|
|**2024-08-16**|**CommunityKG-RAG: Leveraging Community Structures in Knowledge Graphs for Advanced Retrieval-Augmented Generation in Fact-Checking**|Rong-Ching Chang et.al.|[2408.08535v1](http://arxiv.org/abs/2408.08535v1)|null|
|**2024-08-16**|**Detecting Unsuccessful Students in Cybersecurity Exercises in Two Different Learning Environments**|Valdemar ≈†v√°bensk√Ω et.al.|[2408.08531v1](http://arxiv.org/abs/2408.08531v1)|null|
|**2024-08-16**|**Focus on Focus: Focus-oriented Representation Learning and Multi-view Cross-modal Alignment for Glioma Grading**|Li Pan et.al.|[2408.08527v1](http://arxiv.org/abs/2408.08527v1)|[link](https://github.com/peterlipan/fof)|
|**2024-08-16**|**Ex3: Automatic Novel Writing by Extracting, Excelsior and Expanding**|Huang Lei et.al.|[2408.08506v1](http://arxiv.org/abs/2408.08506v1)|null|
|**2024-08-16**|**Adversarial Contrastive Learning Based Physics-Informed Temporal Networks for Cuffless Blood Pressure Estimation**|Rui Wang et.al.|[2408.08488v1](http://arxiv.org/abs/2408.08488v1)|null|
|**2024-08-16**|**An Unsupervised Learning Framework Combined with Heuristics for the Maximum Minimal Cut Problem**|Huaiyuan Liu et.al.|[2408.08484v1](http://arxiv.org/abs/2408.08484v1)|[link](https://github.com/luckyseasalt/pioneer)|
|**2024-08-16**|**Fairness Issues and Mitigations in (Differentially Private) Socio-demographic Data Processes**|Joonhyuk Ko et.al.|[2408.08471v1](http://arxiv.org/abs/2408.08471v1)|null|
|**2024-08-16**|**Context-Aware Assistant Selection for Improved Inference Acceleration with Large Language Models**|Jerry Huang et.al.|[2408.08470v1](http://arxiv.org/abs/2408.08470v1)|null|
|**2024-08-16**|**A theory of understanding for artificial intelligence: composability, catalysts, and learning**|Zijian Zhang et.al.|[2408.08463v1](http://arxiv.org/abs/2408.08463v1)|null|
|**2024-08-15**|**JPEG-LM: LLMs as Image Generators with Canonical Codec Representations**|Xiaochuang Han et.al.|[2408.08459v1](http://arxiv.org/abs/2408.08459v1)|null|
|**2024-08-15**|**Efficient Data-Sketches and Fine-Tuning for Early Detection of Distributional Drift in Medical Imaging**|Yusen Wu et.al.|[2408.08456v1](http://arxiv.org/abs/2408.08456v1)|null|
|**2024-08-15**|**SpectralEarth: Training Hyperspectral Foundation Models at Scale**|Nassim Ait Ali Braham et.al.|[2408.08447v1](http://arxiv.org/abs/2408.08447v1)|null|
|**2024-08-15**|**W-RAG: Weakly Supervised Dense Retrieval in RAG for Open-domain Question Answering**|Jinming Nian et.al.|[2408.08444v1](http://arxiv.org/abs/2408.08444v1)|[link](https://github.com/jmnian/weak_label_for_rag)|
|**2024-08-15**|**PQV-Mobile: A Combined Pruning and Quantization Toolkit to Optimize Vision Transformers for Mobile Applications**|Kshitij Bhardwaj et.al.|[2408.08437v1](http://arxiv.org/abs/2408.08437v1)|null|
|**2024-08-15**|**Automated Design of Agentic Systems**|Shengran Hu et.al.|[2408.08435v1](http://arxiv.org/abs/2408.08435v1)|[link](https://github.com/shengranhu/adas)|
|**2024-08-15**|**Predictive uncertainty estimation in deep learning for lung carcinoma classification in digital pathology under real dataset shifts**|Abdur R. Fayjie et.al.|[2408.08432v1](http://arxiv.org/abs/2408.08432v1)|null|
|**2024-08-15**|**Multi-Modal Dialogue State Tracking for Playing GuessWhich Game**|Wei Pang et.al.|[2408.08431v1](http://arxiv.org/abs/2408.08431v1)|[link](https://github.com/xubuvd/guesswhich)|
|**2024-08-15**|**Assessing and Enhancing Large Language Models in Rare Disease Question-answering**|Guanchu Wang et.al.|[2408.08422v1](http://arxiv.org/abs/2408.08422v1)|null|
|**2024-08-15**|**Understanding Help-Seeking Behavior of Students Using LLMs vs. Web Search for Writing SQL Queries**|Harsh Kumar et.al.|[2408.08401v1](http://arxiv.org/abs/2408.08401v1)|null|
|**2024-08-15**|**Zero-Shot Learning and Key Points Are All You Need for Automated Fact-Checking**|Mohammad Ghiasvand Mohammadkhani et.al.|[2408.08400v1](http://arxiv.org/abs/2408.08400v1)|[link](https://github.com/mghiasvand1/ZSL-KeP)|
|**2024-08-15**|**Level Up Your Tutorials: VLMs for Game Tutorials Quality Assessment**|Daniele Rege Cambrin et.al.|[2408.08396v1](http://arxiv.org/abs/2408.08396v1)|null|
|**2024-08-15**|**Towards Realistic Synthetic User-Generated Content: A Scaffolding Approach to Generating Online Discussions**|Krisztian Balog et.al.|[2408.08379v1](http://arxiv.org/abs/2408.08379v1)|null|
|**2024-08-15**|**Decoding the human brain tissue response to radiofrequency excitation using a biophysical-model-free deep MRI on a chip framework**|Dinor Nagar et.al.|[2408.08376v1](http://arxiv.org/abs/2408.08376v1)|null|
|**2024-08-15**|**Can Large Language Models Understand Symbolic Graphics Programs?**|Zeju Qiu et.al.|[2408.08313v1](http://arxiv.org/abs/2408.08313v1)|null|
|**2024-08-15**|**ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws**|Ruihang Li et.al.|[2408.08310v1](http://arxiv.org/abs/2408.08310v1)|null|
|**2024-08-15**|**Benchmarking the Capabilities of Large Language Models in Transportation System Engineering: Accuracy, Consistency, and Reasoning Behaviors**|Usman Syed et.al.|[2408.08302v1](http://arxiv.org/abs/2408.08302v1)|null|
|**2024-08-15**|**SLCA++: Unleash the Power of Sequential Fine-tuning for Continual Learning with Pre-training**|Gengwei Zhang et.al.|[2408.08295v1](http://arxiv.org/abs/2408.08295v1)|[link](https://github.com/gengdavid/slca)|
|**2024-08-15**|**The ShareLM Collection and Plugin: Contributing Human-Model Chats for the Benefit of the Community**|Shachar Don-Yehiya et.al.|[2408.08291v1](http://arxiv.org/abs/2408.08291v1)|null|
|**2024-08-15**|**Autonomous Behavior Planning For Humanoid Loco-manipulation Through Grounded Language Model**|Jin Wang et.al.|[2408.08282v1](http://arxiv.org/abs/2408.08282v1)|null|
|**2024-08-15**|**InVAErt networks for amortized inference and identifiability analysis of lumped parameter hemodynamic models**|Guoxiang Grayson Tong et.al.|[2408.08264v1](http://arxiv.org/abs/2408.08264v1)|[link](https://github.com/desreslab/invaert4cardio)|
|**2024-08-15**|**mhGPT: A Lightweight Generative Pre-Trained Transformer for Mental Health Text Analysis**|Dae-young Kim et.al.|[2408.08261v1](http://arxiv.org/abs/2408.08261v1)|null|
|**2024-08-15**|**Derivative-Free Guidance in Continuous and Discrete Diffusion Models with Soft Value-Based Decoding**|Xiner Li et.al.|[2408.08252v1](http://arxiv.org/abs/2408.08252v1)|[link](https://github.com/masa-ue/svdd)|
|**2024-08-15**|**A Conflicts-free, Speed-lossless KAN-based Reinforcement Learning Decision System for Interactive Driving in Roundabouts**|Zhihao Lin et.al.|[2408.08242v1](http://arxiv.org/abs/2408.08242v1)|null|
|**2024-08-15**|**Predictive Multiplicity of Knowledge Graph Embeddings in Link Prediction**|Yuqicheng Zhu et.al.|[2408.08226v1](http://arxiv.org/abs/2408.08226v1)|null|
|**2024-08-15**|**The Dawn of KAN in Image-to-Image (I2I) Translation: Integrating Kolmogorov-Arnold Networks with GANs for Unpaired I2I Translation**|Arpan Mahara et.al.|[2408.08216v1](http://arxiv.org/abs/2408.08216v1)|null|
|**2024-08-15**|**Moving Healthcare AI-Support Systems for Visually Detectable Diseases onto Constrained Devices**|Tess Watt et.al.|[2408.08215v1](http://arxiv.org/abs/2408.08215v1)|null|
|**2024-08-15**|**Federated Fairness Analytics: Quantifying Fairness in Federated Learning**|Oscar Dilley et.al.|[2408.08214v1](http://arxiv.org/abs/2408.08214v1)|[link](https://github.com/oscardilley/federated-fairness)|
|**2024-08-15**|**Covert Bias: The Severity of Social Views' Unalignment in Language Models Towards Implicit and Explicit Opinion**|Abeer Aldayel et.al.|[2408.08212v2](http://arxiv.org/abs/2408.08212v2)|null|
|**2024-08-15**|**LLM4DSR: Leveraing Large Language Model for Denoising Sequential Recommendation**|Bohao Wang et.al.|[2408.08208v1](http://arxiv.org/abs/2408.08208v1)|null|
|**2024-08-15**|**API-guided Dataset Synthesis to Finetune Large Code Models**|Zongjie Li et.al.|[2408.08343v1](http://arxiv.org/abs/2408.08343v1)|null|
|**2024-08-15**|**Scaling Up Natural Language Understanding for Multi-Robots Through the Lens of Hierarchy**|Shaojun Xu et.al.|[2408.08188v1](http://arxiv.org/abs/2408.08188v1)|null|
|**2024-08-15**|**Your Turn: Real-World Turning Angle Estimation for Parkinson's Disease Severity Assessment**|Qiushuo Cheng et.al.|[2408.08182v1](http://arxiv.org/abs/2408.08182v1)|null|
|**2024-08-15**|**Towards flexible perception with visual memory**|Robert Geirhos et.al.|[2408.08172v1](http://arxiv.org/abs/2408.08172v1)|null|
|**2024-08-15**|**General-purpose Clothes Manipulation with Semantic Keypoints**|Yuhong Deng et.al.|[2408.08160v1](http://arxiv.org/abs/2408.08160v1)|null|
|**2024-08-15**|**DeepSeek-Prover-V1.5: Harnessing Proof Assistant Feedback for Reinforcement Learning and Monte-Carlo Tree Search**|Huajian Xin et.al.|[2408.08152v1](http://arxiv.org/abs/2408.08152v1)|[link](https://github.com/deepseek-ai/deepseek-prover-v1.5)|

#### Abstracts
##### **xGen-MM (BLIP-3): A Family of Open Large Multimodal Models**
2408.08872v1 by Le Xue, Manli Shu, Anas Awadalla, Jun Wang, An Yan, Senthil Purushwalkam, Honglu Zhou, Viraj Prabhu, Yutong Dai, Michael S Ryoo, Shrikant Kendre, Jieyu Zhang, Can Qin, Shu Zhang, Chia-Chih Chen, Ning Yu, Juntao Tan, Tulika Manoj Awalgaonkar, Shelby Heinecke, Huan Wang, Yejin Choi, Ludwig Schmidt, Zeyuan Chen, Silvio Savarese, Juan Carlos Niebles, Caiming Xiong, Ran Xu

This report introduces xGen-MM (also known as BLIP-3), a framework for
developing Large Multimodal Models (LMMs). The framework comprises meticulously
curated datasets, a training recipe, model architectures, and a resulting suite
of LMMs. xGen-MM, short for xGen-MultiModal, expands the Salesforce xGen
initiative on foundation AI models. Our models undergo rigorous evaluation
across a range of tasks, including both single and multi-image benchmarks. Our
pre-trained base model exhibits strong in-context learning capabilities and the
instruction-tuned model demonstrates competitive performance among open-source
LMMs with similar model sizes. In addition, we introduce a safety-tuned model
with DPO, aiming to mitigate harmful behaviors such as hallucinations and
improve safety. We open-source our models, curated large-scale datasets, and
our fine-tuning codebase to facilitate further advancements in LMM research.
Associated resources will be available on our project page above.

ÊëòË¶ÅÔºöÈÄô‰ªΩÂ†±Âëä‰ªãÁ¥π‰∫Ü xGen-MMÔºà‰πüÁ®±ÁÇ∫ BLIP-3ÔºâÔºåÈÄôÊòØ‰∏ÄÂÄãÁî®ÊñºÈñãÁôºÂ§ßÂûãÂ§öÊ®°ÊÖãÊ®°Âûã (LMM) ÁöÑÊû∂Êßã„ÄÇÈÄôÂÄãÊû∂ÊßãÂåÖÂê´Á≤æÂøÉÁ≠ñÂäÉÁöÑË≥áÊñôÈõÜ„ÄÅË®ìÁ∑¥ÈÖçÊñπ„ÄÅÊ®°ÂûãÊû∂ÊßãÂíå‰∏ÄÁµÑÁî¢ÁîüÁöÑ LMM„ÄÇxGen-MM ÊòØ xGen-MultiModal ÁöÑÁ∞°Á®±ÔºåÂÆÉÊì¥Â±ï‰∫Ü Salesforce xGen Âú®Âü∫Á§é AI Ê®°Âûã‰∏äÁöÑË®àÁï´„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÁ∂ìÈÅéÂö¥Ê†ºÁöÑË©ï‰º∞ÔºåÊ∂µËìã‰∏ÄÁ≥ªÂàó‰ªªÂãôÔºåÂåÖÊã¨ÂñÆ‰∏ÄÂΩ±ÂÉèÂíåÂ§öÂΩ±ÂÉèÂü∫Ê∫ñ„ÄÇÊàëÂÄëÈ†êÂÖàË®ìÁ∑¥ÁöÑÂü∫Êú¨Ê®°ÂûãÂ±ïÁ§∫‰∫ÜÂº∑Â§ßÁöÑÊÉÖÂ¢ÉÂ≠∏ÁøíËÉΩÂäõÔºåËÄåÁ∂ìÈÅéÊåá‰ª§ÂæÆË™øÁöÑÊ®°ÂûãÂâáÂú®ÂÖ∑ÊúâÈ°û‰ººÊ®°ÂûãÂ§ßÂ∞èÁöÑÈñãÊ∫ê LMM ‰∏≠Â±ïÁèæ‰∫ÜÁ´∂Áà≠Âäõ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÈÇÑÂºïÂÖ•‰∫Ü‰ΩøÁî® DPO ÁöÑÂÆâÂÖ®ÂæÆË™øÊ®°ÂûãÔºåÊó®Âú®Ê∏õËºïÂπªË¶∫Á≠âÊúâÂÆ≥Ë°åÁÇ∫‰∏¶ÊèêÈ´òÂÆâÂÖ®ÊÄß„ÄÇÊàëÂÄëÈñãÊîæÂéüÂßãÁ¢ºÊ®°Âûã„ÄÅÁ≠ñÂäÉÂ§ßÂûãË≥áÊñôÈõÜÂíåÂæÆË™øÁ®ãÂºèÁ¢ºÂ∫´Ôºå‰ª•‰øÉÈÄ≤ LMM Á†îÁ©∂ÁöÑÈÄ≤‰∏ÄÊ≠•ÈÄ≤Â±ï„ÄÇÁõ∏ÈóúË≥áÊ∫êÂ∞áÂú®ÊàëÂÄë‰∏äËø∞ÁöÑÂ∞àÊ°àÈ†ÅÈù¢‰∏≠Êèê‰æõ„ÄÇ

##### **PEDAL: Enhancing Greedy Decoding with Large Language Models using Diverse Exemplars**
2408.08869v1 by Sumanth Prabhu

Self-ensembling techniques with diverse reasoning paths such as
Self-Consistency have demonstrated remarkable gains in accuracy for Large
Language Models (LLMs). However, such techniques depend on the availability of
an accurate answer extraction process to aggregate across multiple outputs.
Moreover, they acquire higher inference cost, in comparison to Greedy Decoding,
due to generation of relatively higher number of output tokens. Research has
shown that the free form text outputs from Self-Consistency can be aggregated
reliably using LLMs to produce the final output. Additionally, recent
advancements in LLM inference have demonstrated that usage of diverse exemplars
in prompts have the ability to induce diversity in the LLM outputs. Such proven
techniques can be easily extended to self-ensembling based approaches to
achieve enhanced results in text generation. In this paper, we introduce PEDAL
(Prompts based on Exemplar Diversity Aggregated using LLMs), a hybrid
self-ensembling approach, that combines the strengths of diverse exemplar based
prompts and LLM based aggregation to achieve improvement in overall
performance. On the publicly available SVAMP and ARC datasets, our experiments
reveal that PEDAL can achieve better accuracy than Greedy Decoding based
strategies with lower inference cost compared to Self Consistency based
approaches.

ÊëòË¶ÅÔºöÂà©Áî®‰∏çÂêåÊé®ÁêÜË∑ØÂæëÔºà‰æãÂ¶ÇËá™‰∏ÄËá¥ÊÄßÔºâÁöÑËá™ÁµÑË£ùÊäÄË°ìÂ∑≤Ë≠âÊòéÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊ∫ñÁ¢∫ÊÄßÊúâÈ°ØËëóÁöÑÊèêÂçá„ÄÇÁÑ∂ËÄåÔºåÊ≠§È°ûÊäÄË°ì‰æùË≥¥ÊñºÊ∫ñÁ¢∫ÁöÑÁ≠îÊ°àËêÉÂèñÁ®ãÂ∫èÔºåÊâçËÉΩÂΩôÁ∏ΩÂ§öÂÄãËº∏Âá∫„ÄÇÊ≠§Â§ñÔºåËàáË≤™Â©™Ëß£Á¢ºÁõ∏ÊØîÔºåÂÆÉÂÄëÊúÉÁî¢ÁîüËºÉÈ´òÊï∏ÈáèÁöÑËº∏Âá∫Ê®ôË®òÔºåÂõ†Ê≠§ÊúÉÁî¢ÁîüËºÉÈ´òÁöÑÊé®Ë´ñÊàêÊú¨„ÄÇÁ†îÁ©∂È°ØÁ§∫ÔºåÂèØ‰ª•‰ΩøÁî® LLM ÂèØÈù†Âú∞ÂΩôÁ∏Ω‰æÜËá™Ëá™‰∏ÄËá¥ÊÄßÁöÑËá™Áî±ÂΩ¢ÂºèÊñáÂ≠óËº∏Âá∫Ôºå‰ª•Áî¢ÁîüÊúÄÁµÇËº∏Âá∫„ÄÇÊ≠§Â§ñÔºåLLM Êé®Ë´ñÁöÑÊúÄÊñ∞ÈÄ≤Â±ïÂ∑≤Ë≠âÊòéÔºåÂú®ÊèêÁ§∫‰∏≠‰ΩøÁî®‰∏çÂêåÁöÑÁØÑ‰æãËÉΩÂ§†Ë™òÂ∞é LLM Ëº∏Âá∫ÁöÑÂ§öÊ®£ÊÄß„ÄÇÊ≠§È°ûÂ∑≤È©óË≠âÁöÑÊäÄË°ìÂèØ‰ª•ËºïÈ¨ÜÂú∞Êì¥Â±ïÂà∞Âü∫ÊñºËá™ÁµÑË£ùÁöÑÊñπÊ≥ïÔºå‰ª•Âú®ÊñáÊú¨ÁîüÊàê‰∏≠Áç≤ÂæóÂ¢ûÂº∑ÁöÑÁµêÊûú„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫Ü PEDALÔºàÂü∫ÊñºÁØÑ‰æãÂ§öÊ®£ÊÄßÔºå‰∏¶‰ΩøÁî® LLM ÂΩôÁ∏ΩÁöÑÊèêÁ§∫ÔºâÔºåÈÄôÊòØ‰∏ÄÁ®ÆÊ∑∑ÂêàÂºèËá™ÁµÑË£ùÊñπÊ≥ïÔºåÂÆÉÁµêÂêà‰∫ÜÂü∫Êñº‰∏çÂêåÁØÑ‰æãÁöÑÊèêÁ§∫ÂíåÂü∫Êñº LLM ÁöÑÂΩôÁ∏ΩÁöÑÂÑ™ÈªûÔºå‰ª•ÊèêÈ´òÊï¥È´îÊïàËÉΩ„ÄÇÂú®ÂÖ¨ÈñãÊèê‰æõÁöÑ SVAMP Âíå ARC Ë≥áÊñôÈõÜ‰∏äÔºåÊàëÂÄëÁöÑÂØ¶È©óË°®ÊòéÔºåËàáÂü∫ÊñºËá™‰∏ÄËá¥ÊÄßÁöÑÊñπÊ≥ïÁõ∏ÊØîÔºåPEDAL ÂèØ‰ª•ÊØîÂü∫ÊñºË≤™Â©™Ëß£Á¢ºÁöÑÁ≠ñÁï•Áç≤ÂæóÊõ¥Â•ΩÁöÑÊ∫ñÁ¢∫ÊÄßÔºåÂêåÊôÇÂÖ∑ÊúâËºÉ‰ΩéÁöÑÊé®Ë´ñÊàêÊú¨„ÄÇ

##### **GeoTransformer: Enhancing Urban Forecasting with Geospatial Attention Mechanisms**
2408.08852v1 by Yuhao Jia, Zile Wu, Shengao Yi, Yifei Sun

Recent advancements have focused on encoding urban spatial information into
high-dimensional spaces, with notable efforts dedicated to integrating
sociodemographic data and satellite imagery. These efforts have established
foundational models in this field. However, the effective utilization of these
spatial representations for urban forecasting applications remains
under-explored. To address this gap, we introduce GeoTransformer, a novel
structure that synergizes the Transformer architecture with geospatial
statistics prior. GeoTransformer employs an innovative geospatial attention
mechanism to incorporate extensive urban information and spatial dependencies
into a unified predictive model. Specifically, we compute geospatial weighted
attention scores between the target region and surrounding regions and leverage
the integrated urban information for predictions. Extensive experiments on GDP
and ride-share demand prediction tasks demonstrate that GeoTransformer
significantly outperforms existing baseline models, showcasing its potential to
enhance urban forecasting tasks.

ÊëòË¶ÅÔºöËøëÊúüÁöÑÈÄ≤Â±ïËëóÈáçÊñºÂ∞áÂüéÂ∏ÇÁ©∫ÈñìË≥áË®äÁ∑®Á¢ºÊàêÈ´òÁ∂≠Â∫¶Á©∫ÈñìÔºå‰∏¶Ëá¥ÂäõÊñºÊï¥ÂêàÁ§æÊúÉ‰∫∫Âè£Áµ±Ë®àË≥áÊñôÂíåË°õÊòüÂΩ±ÂÉè„ÄÇÈÄô‰∫õÂä™ÂäõÁÇ∫Ê≠§È†òÂüüÂª∫Á´ã‰∫ÜÂü∫Á§éÊ®°Âûã„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÁ©∫ÈñìË°®ÂæµÂú®ÂüéÂ∏ÇÈ†êÊ∏¨ÊáâÁî®‰∏≠ÁöÑÊúâÊïàÂà©Áî®‰ªçÊú™ÂÖÖÂàÜÊé¢Ë®é„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂ∑ÆË∑ùÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü GeoTransformerÔºå‰∏ÄÂÄãÊñ∞Á©éÁöÑÁµêÊßãÔºåÂÆÉÂ∞á Transformer Êû∂ÊßãËàáÂú∞ÁêÜÁ©∫ÈñìÁµ±Ë®àË≥áÊñôÁµêÂêàËµ∑‰æÜ„ÄÇGeoTransformer Êé°Áî®ÂâµÊñ∞ÁöÑÂú∞ÁêÜÁ©∫ÈñìÊ≥®ÊÑèÂäõÊ©üÂà∂ÔºåÂ∞áÂª£Ê≥õÁöÑÂüéÂ∏ÇË≥áË®äÂíåÁ©∫Èñì‰æùË≥¥Èóú‰øÇÁ¥çÂÖ•‰∏ÄÂÄãÁµ±‰∏ÄÁöÑÈ†êÊ∏¨Ê®°Âûã‰∏≠„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëË®àÁÆóÁõÆÊ®ôÂçÄÂüüÂíåÂë®ÂúçÂçÄÂüü‰πãÈñìÁöÑÂú∞ÁêÜÁ©∫ÈñìÂä†Ê¨äÊ≥®ÊÑèÂäõÂàÜÊï∏Ôºå‰∏¶Âà©Áî®Êï¥ÂêàÁöÑÂüéÂ∏ÇË≥áË®äÈÄ≤Ë°åÈ†êÊ∏¨„ÄÇÂú® GDP ÂíåÂÖ±‰πòÈúÄÊ±ÇÈ†êÊ∏¨‰ªªÂãô‰∏äÁöÑÂª£Ê≥õÂØ¶È©óË°®ÊòéÔºåGeoTransformer ÊòéÈ°ØÂÑ™ÊñºÁèæÊúâÁöÑÂü∫Á∑öÊ®°ÂûãÔºåÂ±ïÁ§∫‰∫ÜÂÖ∂Â¢ûÂº∑ÂüéÂ∏ÇÈ†êÊ∏¨‰ªªÂãôÁöÑÊΩõÂäõ„ÄÇ

##### **PsychoLex: Unveiling the Psychological Mind of Large Language Models**
2408.08848v1 by Mohammad Amin Abbasi, Farnaz Sadat Mirnezami, Hassan Naderi

This paper explores the intersection of psychology and artificial
intelligence through the development and evaluation of specialized Large
Language Models (LLMs). We introduce PsychoLex, a suite of resources designed
to enhance LLMs' proficiency in psychological tasks in both Persian and
English. Key contributions include the PsychoLexQA dataset for instructional
content and the PsychoLexEval dataset for rigorous evaluation of LLMs in
complex psychological scenarios. Additionally, we present the PsychoLexLLaMA
model, optimized specifically for psychological applications, demonstrating
superior performance compared to general-purpose models. The findings
underscore the potential of tailored LLMs for advancing psychological research
and applications, while also highlighting areas for further refinement. This
research offers a foundational step towards integrating LLMs into specialized
psychological domains, with implications for future advancements in AI-driven
psychological practice.

ÊëòË¶ÅÔºöÊú¨Ë´ñÊñáÈÄèÈÅéÈñãÁôºÂíåË©ï‰º∞Â∞àÈñÄÁöÑÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM)ÔºåÊé¢Ë®éÂøÉÁêÜÂ≠∏Ëàá‰∫∫Â∑•Êô∫ÊÖßÁöÑ‰∫§ÈõÜ„ÄÇÊàëÂÄë‰ªãÁ¥π PsychoLexÔºåÈÄôÊòØ‰∏ÄÂ•óÊó®Âú®Â¢ûÂº∑ LLM Âú®Ê≥¢ÊñØË™ûÂíåËã±Ë™ûÂøÉÁêÜ‰ªªÂãô‰∏≠ÁöÑÁÜüÁ∑¥Â∫¶ÁöÑË≥áÊ∫ê„ÄÇ‰∏ªË¶ÅË≤¢ÁçªÂåÖÊã¨Áî®ÊñºÊïôÂ≠∏ÂÖßÂÆπÁöÑ PsychoLexQA Ë≥áÊñôÈõÜÔºå‰ª•ÂèäÁî®ÊñºÂö¥Ê†ºË©ï‰º∞ LLM Âú®Ë§áÈõúÂøÉÁêÜÊÉÖÂ¢É‰∏≠ÁöÑ PsychoLexEval Ë≥áÊñôÈõÜ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜÂ∞àÈñÄÈáùÂ∞çÂøÉÁêÜÊáâÁî®ÊúÄ‰Ω≥ÂåñÁöÑ PsychoLexLLaMA Ê®°ÂûãÔºåÂ±ïÁ§∫‰∫ÜËàáÈÄöÁî®Ê®°ÂûãÁõ∏ÊØîÁöÑÂçìË∂äÊïàËÉΩ„ÄÇÈÄô‰∫õÁôºÁèæÂº∑Ë™ø‰∫ÜÈáèË∫´ÊâìÈÄ†ÁöÑ LLM Âú®Êé®ÈÄ≤ÂøÉÁêÜÁ†îÁ©∂ÂíåÊáâÁî®ÊñπÈù¢ÁöÑÊΩõÂäõÔºåÂêåÊôÇ‰πüÁ™ÅÂá∫‰∫ÜÈÄ≤‰∏ÄÊ≠•ÂÑ™ÂåñÁöÑÈ†òÂüü„ÄÇÊú¨Á†îÁ©∂Êèê‰æõ‰∫ÜÂ∞á LLM Êï¥ÂêàÂà∞Â∞àÈñÄÂøÉÁêÜÈ†òÂüüÁöÑÂü∫Êú¨Ê≠•È©üÔºåÂ∞çÊú™‰æÜ AI È©ÖÂãïÁöÑÂøÉÁêÜÂØ¶ÂãôÈÄ≤Â±ïÂÖ∑ÊúâÂΩ±Èüø„ÄÇ

##### **FLEXTAF: Enhancing Table Reasoning with Flexible Tabular Formats**
2408.08841v1 by Xuanliang Zhang, Dingzirui Wang, Longxu Dou, Baoxin Wang, Dayong Wu, Qingfu Zhu, Wanxiang Che

The table reasoning task aims to answer the question according to the given
table. Currently, using Large Language Models (LLMs) is the predominant method
for table reasoning. Most existing methods employ a fixed tabular format to
represent the table, which could limit the performance. Given that each
instance requires different capabilities and models possess varying abilities,
we assert that different instances and models suit different tabular formats.
We prove the aforementioned claim through quantitative analysis of experimental
results, where different instances and models achieve different performances
using various tabular formats. Building on this discussion, we propose
FLEXTAF-Single and FLEXTAF-Vote to enhance table reasoning performance by
employing flexible tabular formats. Specifically, (i) FLEXTAF-Single trains a
classifier to predict the most suitable tabular format based on the instance
and the LLM. (ii) FLEXTAF-Vote integrates the results across different formats.
Our experiments on WikiTableQuestions and TabFact reveal significant
improvements, with average gains of 2.3% and 4.8% compared to the best
performance achieved using a fixed tabular format with greedy decoding and
self-consistency decoding, thereby validating the effectiveness of our methods.

ÊëòË¶ÅÔºöË°®Ê†ºÊé®ÁêÜ‰ªªÂãôÊó®Âú®Ê†πÊìöÁµ¶ÂÆöÁöÑË°®Ê†ºÂõûÁ≠îÂïèÈ°å„ÄÇÁõÆÂâçÔºå‰ΩøÁî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÊòØË°®Ê†ºÊé®ÁêÜÁöÑ‰∏ªË¶ÅÊñπÊ≥ï„ÄÇÂ§ßÂ§öÊï∏ÁèæÊúâÊñπÊ≥ïÊé°Áî®Âõ∫ÂÆöÁöÑË°®Ê†ºÊ†ºÂºè‰æÜË°®Á§∫Ë°®Ê†ºÔºåÈÄôÂèØËÉΩÊúÉÈôêÂà∂ÊïàËÉΩ„ÄÇÁî±ÊñºÊØèÂÄãÂØ¶‰æãÈÉΩÈúÄË¶Å‰∏çÂêåÁöÑËÉΩÂäõÔºåËÄåÊ®°ÂûãÂÖ∑ÂÇô‰∏çÂêåÁöÑËÉΩÂäõÔºåÊàëÂÄëÊñ∑Ë®Ä‰∏çÂêåÁöÑÂØ¶‰æãÂíåÊ®°ÂûãÈÅ©Âêà‰∏çÂêåÁöÑË°®Ê†ºÊ†ºÂºè„ÄÇÊàëÂÄëÈÄèÈÅéÂ∞çÂØ¶È©óÁµêÊûúÈÄ≤Ë°åÈáèÂåñÂàÜÊûê‰æÜË≠âÊòé‰∏äËø∞Ë™™Ê≥ïÔºåÂÖ∂‰∏≠‰∏çÂêåÁöÑÂØ¶‰æãÂíåÊ®°Âûã‰ΩøÁî®‰∏çÂêåÁöÑË°®Ê†ºÊ†ºÂºè‰æÜÈÅîÊàê‰∏çÂêåÁöÑÊïàËÉΩ„ÄÇÂü∫ÊñºÊ≠§Ë®éË´ñÔºåÊàëÂÄëÊèêÂá∫ FLEXTAF-Single Âíå FLEXTAF-Vote ‰æÜÈÄèÈÅéÊé°Áî®ÂΩàÊÄßÁöÑË°®Ê†ºÊ†ºÂºè‰æÜÂ¢ûÂº∑Ë°®Ê†ºÊé®ÁêÜÊïàËÉΩ„ÄÇÂÖ∑È´î‰æÜË™™Ôºå(i) FLEXTAF-Single Ë®ìÁ∑¥‰∏ÄÂÄãÂàÜÈ°ûÂô®‰æÜÊ†πÊìöÂØ¶‰æãÂíå LLM È†êÊ∏¨ÊúÄÂêàÈÅ©ÁöÑË°®Ê†ºÊ†ºÂºè„ÄÇ(ii) FLEXTAF-Vote Êï¥Âêà‰∏çÂêåÊ†ºÂºèÁöÑÁµêÊûú„ÄÇÊàëÂÄëÂú® WikiTableQuestions Âíå TabFact ‰∏äÁöÑÂØ¶È©óÈ°ØÁ§∫Âá∫È°ØËëóÁöÑÊîπÈÄ≤ÔºåËàá‰ΩøÁî®ÂÖ∑ÊúâË≤™Â©™Ëß£Á¢ºÂíåËá™‰∏ÄËá¥Ëß£Á¢ºÁöÑÂõ∫ÂÆöË°®Ê†ºÊ†ºÂºèÊâÄÈÅîÊàêÁöÑÊúÄ‰Ω≥ÊïàËÉΩÁõ∏ÊØîÔºåÂπ≥ÂùáÂ¢ûÁõäÂàÜÂà•ÁÇ∫ 2.3% Âíå 4.8%ÔºåÂæûËÄåÈ©óË≠â‰∫ÜÊàëÂÄëÊñπÊ≥ïÁöÑÊúâÊïàÊÄß„ÄÇ

##### **EasyRec: Simple yet Effective Language Models for Recommendation**
2408.08821v1 by Xubin Ren, Chao Huang

Deep neural networks have become a powerful technique for learning
representations from user-item interaction data in collaborative filtering (CF)
for recommender systems. However, many existing methods heavily rely on unique
user and item IDs, which limits their ability to perform well in practical
zero-shot learning scenarios where sufficient training data may be unavailable.
Inspired by the success of language models (LMs) and their strong
generalization capabilities, a crucial question arises: How can we harness the
potential of language models to empower recommender systems and elevate its
generalization capabilities to new heights? In this study, we propose EasyRec -
an effective and easy-to-use approach that seamlessly integrates text-based
semantic understanding with collaborative signals. EasyRec employs a
text-behavior alignment framework, which combines contrastive learning with
collaborative language model tuning, to ensure a strong alignment between the
text-enhanced semantic space and the collaborative behavior information.
Extensive empirical evaluations across diverse real-world datasets demonstrate
the superior performance of EasyRec compared to state-of-the-art alternative
models, particularly in the challenging text-based zero-shot recommendation
scenarios. Furthermore, the study highlights the potential of seamlessly
integrating EasyRec as a plug-and-play component into text-enhanced
collaborative filtering frameworks, thereby empowering existing recommender
systems to elevate their recommendation performance and adapt to the evolving
user preferences in dynamic environments. For better result reproducibility of
our EasyRec framework, the model implementation details, source code, and
datasets are available at the link: https://github.com/HKUDS/EasyRec.

ÊëòË¶ÅÔºöÊ∑±Â∫¶Á•ûÁªèÁΩëÁªúÂ∑≤Êàê‰∏∫‰∏ÄÁßçÂº∫Â§ßÁöÑÊäÄÊúØÔºåÂèØÁî®‰∫é‰ªéÂçèÂêåËøáÊª§ (CF) ‰∏≠ÁöÑ‰ΩøÁî®ËÄÖ-È°πÁõÆ‰∫íÂä®ËµÑÊñô‰∏≠Â≠¶‰π†Ë°®ÂæÅÔºå‰ª•Áî®‰∫éÊé®ËçêÁ≥ªÁªü„ÄÇÁÑ∂ËÄåÔºåËÆ∏Â§öÁé∞ÊúâÊñπÊ≥ï‰∏•Èáç‰æùËµñ‰∫éÂîØ‰∏ÄÁöÑ‰ΩøÁî®ËÄÖÂíåÈ°πÁõÆ IDÔºåËøôÈôêÂà∂‰∫ÜÂÆÉ‰ª¨Âú®ÂÆûÈôÖÈõ∂Ê¨°Â≠¶‰π†Âú∫ÊôØ‰∏≠Ë°®Áé∞ËâØÂ•ΩÁöÑËÉΩÂäõÔºåËÄåÂú®ÂÆûÈôÖÈõ∂Ê¨°Â≠¶‰π†Âú∫ÊôØ‰∏≠ÔºåÂèØËÉΩÊó†Ê≥ïËé∑ÂæóË∂≥Â§üÁöÑËÆ≠ÁªÉËµÑÊñô„ÄÇÂú®ËØ≠Ë®ÄÊ®°Âûã (LM) ÂèäÂÖ∂Âº∫Â§ßÁöÑÊ¶ÇÊã¨ËÉΩÂäõÂèñÂæóÊàêÂäüÂêéÔºå‰∏Ä‰∏™ÂÖ≥ÈîÆÈóÆÈ¢òÂá∫Áé∞‰∫ÜÔºöÊàë‰ª¨Â¶Ç‰ΩïÂà©Áî®ËØ≠Ë®ÄÊ®°ÂûãÁöÑÊΩúÂäõÊù•Â¢ûÂº∫Êé®ËçêÁ≥ªÁªüÔºåÂπ∂Â∞ÜÂÖ∂Ê¶ÇÊã¨ËÉΩÂäõÊèêÂçáÂà∞Êñ∞ÁöÑÈ´òÂ∫¶ÔºüÂú®Êú¨Á†îÁ©∂‰∏≠ÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü EasyRec - ‰∏ÄÁßçÊúâÊïà‰∏îÊòì‰∫é‰ΩøÁî®ÁöÑÈÄîÂæÑÔºåÂèØÂ∞ÜÂü∫‰∫éÊñáÊú¨ÁöÑËØ≠‰πâÁêÜËß£‰∏éÂçè‰Ωú‰ø°Âè∑Êó†ÁºùÊï¥Âêà„ÄÇEasyRec ÈááÁî®ÊñáÊú¨Ë°å‰∏∫ÂØπÈΩêÊ°ÜÊû∂ÔºåÂ∞ÜÂØπÊØîÂ≠¶‰π†‰∏éÂçè‰ΩúËØ≠Ë®ÄÊ®°ÂûãË∞ÉÊï¥Áõ∏ÁªìÂêàÔºå‰ª•Á°Æ‰øùÊñáÊú¨Â¢ûÂº∫ËØ≠‰πâÁ©∫Èó¥‰∏éÂçè‰ΩúË°å‰∏∫‰ø°ÊÅØ‰πãÈó¥ÊúâÂæàÂº∫ÁöÑÂØπÈΩê„ÄÇÂú®ÂêÑÁßçÂÆûÈôÖÊï∞ÊçÆÈõÜ‰∏äËøõË°åÂπøÊ≥õÁöÑÂÆûËØÅËØÑ‰º∞ÔºåËØÅÊòé‰∫Ü EasyRec ‰∏éÊúÄÂÖàËøõÁöÑÊõø‰ª£Ê®°ÂûãÁõ∏ÊØîÂÖ∑ÊúâÂçìË∂äÁöÑÊÄßËÉΩÔºåÂ∞§ÂÖ∂ÊòØÂú®ÂÖ∑ÊúâÊåëÊàòÊÄßÁöÑÂü∫‰∫éÊñáÊú¨ÁöÑÈõ∂Ê¨°Êé®ËçêÂú∫ÊôØ‰∏≠„ÄÇÊ≠§Â§ñÔºåÊú¨Á†îÁ©∂Âº∫Ë∞É‰∫ÜÂ∞Ü EasyRec Êó†ÁºùÊï¥Âêà‰∏∫Âç≥ÊèíÂç≥Áî®ÁªÑ‰ª∂Âà∞ÊñáÊú¨Â¢ûÂº∫Âçè‰ΩúËøáÊª§Ê°ÜÊû∂‰∏≠ÁöÑÊΩúÂäõÔºå‰ªéËÄå‰ΩøÁé∞ÊúâÁöÑÊé®ËçêÁ≥ªÁªüËÉΩÂ§üÊèêÂçáÂÖ∂Êé®ËçêÊÄßËÉΩÔºåÂπ∂ÈÄÇÂ∫îÂä®ÊÄÅÁéØÂ¢É‰∏≠‰∏çÊñ≠ÂèòÂåñÁöÑ‰ΩøÁî®ËÄÖÂÅèÂ•Ω„ÄÇ‰∏∫‰∫ÜÊõ¥Â•ΩÂú∞ÈáçÁé∞Êàë‰ª¨ EasyRec Ê°ÜÊû∂ÁöÑÁªìÊûúÔºåÊ®°ÂûãÂÆûÁé∞ÁªÜËäÇ„ÄÅÊ∫ê‰ª£Á†ÅÂíåÊï∞ÊçÆÈõÜÂèØÂú®‰ª•‰∏ãÈìæÊé•Ëé∑ÂæóÔºöhttps://github.com/HKUDS/EasyRec„ÄÇ

##### **Constructing Domain-Specific Evaluation Sets for LLM-as-a-judge**
2408.08808v1 by Ravi Raju, Swayambhoo Jain, Bo Li, Jonathan Li, Urmish Thakkar

Large Language Models (LLMs) have revolutionized the landscape of machine
learning, yet current benchmarks often fall short in capturing the diverse
behavior of these models in real-world applications. A benchmark's usefulness
is determined by its ability to clearly differentiate between models of varying
capabilities (separability) and closely align with human preferences. Existing
frameworks like Alpaca-Eval 2.0 LC
\cite{dubois2024lengthcontrolledalpacaevalsimpleway} and Arena-Hard v0.1
\cite{li2024crowdsourced} are limited by their focus on general-purpose queries
and lack of diversity across domains such as law, medicine, and multilingual
contexts. In this paper, we address these limitations by introducing a novel
data pipeline that curates diverse, domain-specific evaluation sets tailored
for LLM-as-a-Judge frameworks. Our approach leverages a combination of manual
curation, semi-supervised learning to generate clusters, and stratified
sampling to ensure balanced representation across a wide range of domains and
languages. The resulting evaluation set, which includes 1573 samples across 14
categories, demonstrates high separability (84\%) across ten top-ranked models,
and agreement (84\%) with Chatbot Arena and (0.915) Spearman correlation. The
agreement values are 9\% better than Arena Hard and 20\% better than AlpacaEval
2.0 LC, while the Spearman coefficient is 0.7 more than the next best
benchmark, showcasing a significant improvement in the usefulness of the
benchmark. We further provide an open-source evaluation tool that enables
fine-grained analysis of model performance across user-defined categories,
offering valuable insights for practitioners. This work contributes to the
ongoing effort to enhance the transparency, diversity, and effectiveness of LLM
evaluation methodologies.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂæπÂ∫ïÊîπËÆä‰∫ÜÊ©üÂô®Â≠∏ÁøíÁöÑÊ†ºÂ±ÄÔºå‰ΩÜÁõÆÂâçÁöÑÂü∫Ê∫ñÁ∂ìÂ∏∏ÁÑ°Ê≥ïÊçïÊçâÈÄô‰∫õÊ®°ÂûãÂú®ÂØ¶ÈöõÊáâÁî®‰∏≠ÁöÑÂ§öÊ®£ÂåñË°åÁÇ∫„ÄÇÂü∫Ê∫ñÁöÑÊïàÁî®ÂèñÊ±∫ÊñºÂÖ∂Ê∏ÖÊ•öÂçÄÂàÜ‰∏çÂêåËÉΩÂäõÊ®°ÂûãÔºàÂèØÂàÜÈõ¢ÊÄßÔºâ‰∏¶Ëàá‰∫∫È°ûÂÅèÂ•ΩÁ∑äÂØÜÁµêÂêàÁöÑËÉΩÂäõ„ÄÇÁèæÊúâÁöÑÊ°ÜÊû∂Ôºà‰æãÂ¶Ç Alpaca-Eval 2.0 LC\cite{dubois2024lengthcontrolledalpacaevalsimpleway} Âíå Arena-Hard v0.1\cite{li2024crowdsourced}ÔºâÂèóÂà∞ÂÖ∂Â∞çÈÄöÁî®Êü•Ë©¢ÁöÑÈóúÊ≥®‰ª•ÂèäÁº∫‰πèÊ≥ïÂæã„ÄÅÈÜ´Â≠∏ÂíåÂ§öË™ûË®ÄÁí∞Â¢ÉÁ≠âÈ†òÂüüÂ§öÊ®£ÊÄßÁöÑÈôêÂà∂„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÈÄöÈÅéÂºïÂÖ•‰∏ÄÁ®ÆÊñ∞Á©éÁöÑË≥áÊñôÁÆ°ÈÅì‰æÜËß£Ê±∫ÈÄô‰∫õÈôêÂà∂ÔºåË©≤ÁÆ°ÈÅìÁ≠ñÂäÉ‰∫ÜÈáùÂ∞ç LLM ‰ΩúÁÇ∫Ë©ïÂØ©Ê°ÜÊû∂ÈáèË∫´ÊâìÈÄ†ÁöÑÂ§öÊ®£Âåñ„ÄÅÁâπÂÆöÊñºÈ†òÂüüÁöÑË©ï‰º∞ÈõÜ„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÂà©Áî®‰∫ÜÊâãÂãïÁ≠ñÂäÉ„ÄÅÂçäÁõ£Áù£ÂºèÂ≠∏Áøí‰æÜÁîüÊàêÁæ§ÈõÜ‰ª•ÂèäÂàÜÂ±§ÊäΩÊ®£ÁöÑÁµÑÂêàÔºå‰ª•Á¢∫‰øùÂú®Âª£Ê≥õÁöÑÈ†òÂüüÂíåË™ûË®Ä‰∏≠ÂÖ∑ÊúâÂπ≥Ë°°ÁöÑË°®Á§∫„ÄÇÁîüÊàêÁöÑË©ï‰º∞ÈõÜÂåÖÂê´ 14 ÂÄãÈ°ûÂà•‰∏≠ÁöÑ 1573 ÂÄãÊ®£Êú¨ÔºåÂ±ïÁ§∫‰∫ÜÂâçÂçÅÂêçÊ®°Âûã‰πãÈñìÁöÑÈ´òÂèØÂàÜÈõ¢ÊÄß (84%)Ôºå‰ª•ÂèäËàáËÅäÂ§©Ê©üÂô®‰∫∫Á´∂ÊäÄÂ†¥ÁöÑ‰∏ÄËá¥ÊÄß (84%) Âíå (0.915) Spearman Áõ∏ÈóúÊÄß„ÄÇ‰∏ÄËá¥ÊÄßÂÄºÊØî Arena Hard È´ò 9%ÔºåÊØî AlpacaEval 2.0 LC È´ò 20%ÔºåËÄå Spearman ‰øÇÊï∏ÊØîÊ¨°‰Ω≥Âü∫Ê∫ñÈ´ò 0.7ÔºåÈ°ØÁ§∫Âü∫Ê∫ñÁöÑÊïàÁî®ÊúâÈ°ØËëóÊèêÂçá„ÄÇÊàëÂÄëÈÄ≤‰∏ÄÊ≠•Êèê‰æõ‰∫Ü‰∏ÄÂÄãÈñãÊ∫êË©ï‰º∞Â∑•ÂÖ∑ÔºåË©≤Â∑•ÂÖ∑ÂèØ‰ª•Â∞ç‰ΩøÁî®ËÄÖÂÆöÁæ©È°ûÂà•‰∏≠ÁöÑÊ®°ÂûãÊïàËÉΩÈÄ≤Ë°åÁ¥∞Á∑ªÁöÑÂàÜÊûêÔºåÁÇ∫ÂØ¶ÂãôÂ∑•‰ΩúËÄÖÊèê‰æõÊúâÂÉπÂÄºÁöÑË¶ãËß£„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÊúâÂä©ÊñºÊåÅÁ∫åÂä™ÂäõÊèêÈ´ò LLM Ë©ï‰º∞ÊñπÊ≥ïÁöÑÈÄèÊòéÂ∫¶„ÄÅÂ§öÊ®£ÊÄßÂíåÊúâÊïàÊÄß„ÄÇ

##### **CIKMar: A Dual-Encoder Approach to Prompt-Based Reranking in Educational Dialogue Systems**
2408.08805v1 by Joanito Agili Lopo, Marina Indah Prasasti, Alma Permatasari

In this study, we introduce CIKMar, an efficient approach to educational
dialogue systems powered by the Gemma Language model. By leveraging a
Dual-Encoder ranking system that incorporates both BERT and SBERT model, we
have designed CIKMar to deliver highly relevant and accurate responses, even
with the constraints of a smaller language model size. Our evaluation reveals
that CIKMar achieves a robust recall and F1-score of 0.70 using BERTScore
metrics. However, we have identified a significant challenge: the Dual-Encoder
tends to prioritize theoretical responses over practical ones. These findings
underscore the potential of compact and efficient models like Gemma in
democratizing access to advanced educational AI systems, ensuring effective and
contextually appropriate responses.

ÊëòË¶ÅÔºöÂú®ÈÄôÈ†ÖÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫Ü CIKMarÔºå‰∏ÄÁ®ÆÁî± Gemma Ë™ûË®ÄÊ®°ÂûãÈ©ÖÂãïÁöÑÊïôËÇ≤Â∞çË©±Á≥ªÁµ±ÁöÑÊúâÊïàÊñπÊ≥ï„ÄÇÈÄèÈÅéÂà©Áî®ÁµêÂêà BERT Âíå SBERT Ê®°ÂûãÁöÑÈõôÁ∑®Á¢ºÂô®ÊéíÂêçÁ≥ªÁµ±ÔºåÊàëÂÄëË®≠Ë®à CIKMar Êèê‰æõÈ´òÂ∫¶Áõ∏Èóú‰∏îÊ∫ñÁ¢∫ÁöÑÂõûÊáâÔºåÂç≥‰ΩøÂèóÂà∞ËºÉÂ∞èË™ûË®ÄÊ®°ÂûãÂ§ßÂ∞èÁöÑÈôêÂà∂„ÄÇÊàëÂÄëÁöÑË©ï‰º∞È°ØÁ§∫ÔºåCIKMar ‰ΩøÁî® BERTScore ÊåáÊ®ôÈÅîÂà∞‰∫Ü 0.70 ÁöÑÂº∑ÂÅ•Âè¨ÂõûÁéáÂíå F1 ÂàÜÊï∏„ÄÇÁÑ∂ËÄåÔºåÊàëÂÄëÁôºÁèæ‰∫Ü‰∏ÄÂÄãÈáçÂ§ßÁöÑÊåëÊà∞ÔºöÈõôÁ∑®Á¢ºÂô®ÂÇæÂêëÊñºÂÑ™ÂÖàËÄÉÊÖÆÁêÜË´ñÂõûÊáâÔºåËÄå‰∏çÊòØÂØ¶ÈöõÂõûÊáâ„ÄÇÈÄô‰∫õÁôºÁèæÂº∑Ë™ø‰∫ÜÂÉè Gemma ÈÄôÊ®£ÁöÑÁ≤æÁ∞°‰∏îÈ´òÊïàÊ®°ÂûãÂú®‰ΩøÈÄ≤ÈöéÊïôËÇ≤ AI Á≥ªÁµ±Ê∞ë‰∏ªÂåñ„ÄÅÁ¢∫‰øùÊúâÊïà‰∏îÈÅ©Áï∂ÁöÑÂõûÊáâÊñπÈù¢ÁöÑÊΩõÂäõ„ÄÇ

##### **Leveraging FourierKAN Classification Head for Pre-Trained Transformer-based Text Classification**
2408.08803v1 by Abdullah Al Imran, Md Farhan Ishmam

For many years, transformer-based pre-trained models with Multi-layer
Perceptron (MLP) heads have been the standard for text classification tasks.
However, the fixed non-linear functions employed by MLPs often fall short of
capturing the intricacies of the contextualized embeddings produced by
pre-trained encoders. Furthermore, MLPs usually require a significant number of
training parameters, which can be computationally expensive. In this work, we
introduce FourierKAN (FR-KAN), a variant of the promising MLP alternative
called Kolmogorov-Arnold Networks (KANs), as classification heads for
transformer-based encoders. Our studies reveal an average increase of 10% in
accuracy and 11% in F1-score when incorporating FR-KAN heads instead of
traditional MLP heads for several transformer-based pre-trained models across
multiple text classification tasks. Beyond improving model accuracy, FR-KAN
heads train faster and require fewer parameters. Our research opens new grounds
for broader applications of KAN across several Natural Language Processing
(NLP) tasks.

ÊëòË¶ÅÔºöÂ§öÂπ¥‰æÜÔºåÂÖ∑ÊúâÂ§öÂ±§ÊÑüÁü•Âô® (MLP) È†≠ÁöÑÂü∫ÊñºTransformerÁöÑÈ†êË®ìÁ∑¥Ê®°Âûã‰∏ÄÁõ¥ÊòØÊñáÊú¨ÂàÜÈ°û‰ªªÂãôÁöÑÊ®ôÊ∫ñ„ÄÇ
ÁÑ∂ËÄåÔºåMLP ‰ΩøÁî®ÁöÑÂõ∫ÂÆöÈùûÁ∑öÊÄßÂáΩÊï∏ÈÄöÂ∏∏ÁÑ°Ê≥ïÊçïÊçâÁî±È†êË®ìÁ∑¥Á∑®Á¢ºÂô®Áî¢ÁîüÁöÑ‰∏ä‰∏ãÊñáÂåñÂµåÂÖ•ÁöÑË§áÈõúÊÄß„ÄÇ
Ê≠§Â§ñÔºåMLP ÈÄöÂ∏∏ÈúÄË¶ÅÂ§ßÈáèÁöÑË®ìÁ∑¥ÂèÉÊï∏ÔºåÈÄôÂú®Ë®àÁÆó‰∏äÂèØËÉΩÊòØÊòÇË≤¥ÁöÑ„ÄÇ
Âú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü FourierKAN (FR-KAN)Ôºå‰∏ÄÁ®ÆÊúâÂâçÈÄîÁöÑ MLP Êõø‰ª£ÊñπÊ°àÔºåÁ®±ÁÇ∫ Kolmogorov-Arnold Á∂≤Ë∑Ø (KAN)Ôºå‰ΩúÁÇ∫Âü∫ÊñºTransformerÁöÑÁ∑®Á¢ºÂô®ÁöÑÂàÜÈ°ûÈ†≠„ÄÇ
ÊàëÂÄëÁöÑÁ†îÁ©∂Ë°®ÊòéÔºåÂú®Â§öÂÄãÊñáÊú¨ÂàÜÈ°û‰ªªÂãô‰∏≠ÔºåÂ∞á FR-KAN È†≠Êï¥ÂêàÂà∞Âü∫ÊñºTransformerÁöÑÈ†êË®ìÁ∑¥Ê®°Âûã‰∏≠ÔºåËÄå‰∏çÊòØÂÇ≥Áµ±ÁöÑ MLP È†≠ÔºåÊ∫ñÁ¢∫ÁéáÂπ≥ÂùáÊèêÈ´ò‰∫Ü 10%ÔºåF1 ÂàÜÊï∏ÊèêÈ´ò‰∫Ü 11%„ÄÇ
Èô§‰∫ÜÊèêÈ´òÊ®°ÂûãÊ∫ñÁ¢∫Â∫¶‰πãÂ§ñÔºåFR-KAN È†≠Ë®ìÁ∑¥ÈÄüÂ∫¶Êõ¥Âø´Ôºå‰∏¶‰∏îÈúÄË¶ÅÊõ¥Â∞ëÁöÑÂèÉÊï∏„ÄÇ
ÊàëÂÄëÁöÑÁ†îÁ©∂ÁÇ∫ KAN Âú®Â§öÂÄãËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ (NLP) ‰ªªÂãô‰∏≠ÁöÑÊõ¥Âª£Ê≥õÊáâÁî®ÈñãÈó¢‰∫ÜÊñ∞ÁöÑÈ†òÂüü„ÄÇ

##### **A Disease-Specific Foundation Model Using Over 100K Fundus Images: Release and Validation for Abnormality and Multi-Disease Classification on Downstream Tasks**
2408.08790v1 by Boa Jang, Youngbin Ahn, Eun Kyung Choe, Chang Ki Yoon, Hyuk Jin Choi, Young-Gon Kim

Artificial intelligence applied to retinal images offers significant
potential for recognizing signs and symptoms of retinal conditions and
expediting the diagnosis of eye diseases and systemic disorders. However,
developing generalized artificial intelligence models for medical data often
requires a large number of labeled images representing various disease signs,
and most models are typically task-specific, focusing on major retinal
diseases. In this study, we developed a Fundus-Specific Pretrained Model
(Image+Fundus), a supervised artificial intelligence model trained to detect
abnormalities in fundus images. A total of 57,803 images were used to develop
this pretrained model, which achieved superior performance across various
downstream tasks, indicating that our proposed model outperforms other general
methods. Our Image+Fundus model offers a generalized approach to improve model
performance while reducing the number of labeled datasets required.
Additionally, it provides more disease-specific insights into fundus images,
with visualizations generated by our model. These disease-specific foundation
models are invaluable in enhancing the performance and efficiency of deep
learning models in the field of fundus imaging.

ÊëòË¶ÅÔºö‰∫∫Â∑•Êô∫ÊÖßÊáâÁî®ÊñºË¶ñÁ∂≤ËÜúÂΩ±ÂÉèÔºåÂú®Ëæ®Ë≠òË¶ñÁ∂≤ËÜúÁóÖËÆäÁöÑÂæµÂÖÜÂíåÁóáÁãÄÔºå‰ª•ÂèäÂä†ÈÄüË®∫Êñ∑ÁúºÁñæÂíåÂÖ®Ë∫´ÊÄßÁñæÁóÖÊñπÈù¢ÔºåÊúâÈ°ØËëóÁöÑÊΩõÂäõ„ÄÇÁÑ∂ËÄåÔºåÁÇ∫ÈÜ´ÁôÇË≥áÊñôÈñãÁôºÂª£Ê≥õÁöÑ‰∫∫Â∑•Êô∫ÊÖßÊ®°ÂûãÔºåÈÄöÂ∏∏ÈúÄË¶ÅÂ§ßÈáè‰ª£Ë°®ÂêÑÁ®ÆÁñæÁóÖÂæµÂÖÜÁöÑÊ®ôÁ±§ÂΩ±ÂÉèÔºåËÄå‰∏îÂ§ßÂ§öÊï∏Ê®°ÂûãÈÄöÂ∏∏ÊòØÈáùÂ∞çÁâπÂÆö‰ªªÂãôÔºåÂ∞àÊ≥®Êñº‰∏ªË¶ÅÁöÑË¶ñÁ∂≤ËÜúÁñæÁóÖ„ÄÇÂú®ÈÄôÈ†ÖÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄëÈñãÁôº‰∫ÜÁúºÂ∫ïÂ∞àÁî®È†êË®ìÁ∑¥Ê®°Âûã (ÂΩ±ÂÉè + ÁúºÂ∫ï)ÔºåÈÄôÊòØ‰∏ÄÂÄãÁõ£Áù£ÂºèÁöÑ‰∫∫Â∑•Êô∫ÊÖßÊ®°ÂûãÔºåË®ìÁ∑¥Áî®ÊñºÂÅµÊ∏¨ÁúºÂ∫ïÂΩ±ÂÉè‰∏≠ÁöÑÁï∞Â∏∏„ÄÇÁ∏ΩÂÖ±‰ΩøÁî®‰∫Ü 57,803 ÂºµÂΩ±ÂÉè‰æÜÈñãÁôºÈÄôÂÄãÈ†êË®ìÁ∑¥Ê®°ÂûãÔºåÂÆÉÂú®ÂêÑÁ®Æ‰∏ãÊ∏∏‰ªªÂãô‰∏≠ÈÉΩÈÅîÂà∞‰∫ÜÂçìË∂äÁöÑÊïàËÉΩÔºåÈÄôË°®Á§∫ÊàëÂÄëÊèêÂá∫ÁöÑÊ®°ÂûãÂÑ™ÊñºÂÖ∂‰ªñ‰∏ÄËà¨ÊñπÊ≥ï„ÄÇÊàëÂÄëÁöÑÂΩ±ÂÉè + ÁúºÂ∫ïÊ®°ÂûãÊèê‰æõ‰∫Ü‰∏ÄÁ®ÆÂª£Ê≥õÁöÑÊñπÊ≥ï‰æÜÊîπÂñÑÊ®°ÂûãÊïàËÉΩÔºåÂêåÊôÇÊ∏õÂ∞ëÊâÄÈúÄÁöÑÊ®ôÁ±§Ë≥áÊñôÈõÜÊï∏Èáè„ÄÇÊ≠§Â§ñÔºåÂÆÉÈÇÑÈÄèÈÅéÊàëÂÄëÁöÑÊ®°ÂûãÁî¢ÁîüÁöÑË¶ñË¶∫ÂåñÔºåÊèê‰æõ‰∫ÜÊõ¥Â§öÈáùÂ∞çÁúºÂ∫ïÂΩ±ÂÉèÁöÑÁâπÂÆöÁñæÁóÖË¶ãËß£„ÄÇÈÄô‰∫õÁâπÂÆöÁñæÁóÖÂü∫Á§éÊ®°ÂûãÂ∞çÊñºÂ¢ûÂº∑ÁúºÂ∫ïÂΩ±ÂÉèÈ†òÂüü‰∏≠Ê∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÁöÑÊïàËÉΩÂíåÊïàÁéáËá≥ÈóúÈáçË¶Å„ÄÇ

##### **A Transparency Paradox? Investigating the Impact of Explanation Specificity and Autonomous Vehicle Perceptual Inaccuracies on Passengers**
2408.08785v1 by Daniel Omeiza, Raunak Bhattacharyya, Marina Jirotka, Nick Hawes, Lars Kunze

Transparency in automated systems could be afforded through the provision of
intelligible explanations. While transparency is desirable, might it lead to
catastrophic outcomes (such as anxiety), that could outweigh its benefits? It's
quite unclear how the specificity of explanations (level of transparency)
influences recipients, especially in autonomous driving (AD). In this work, we
examined the effects of transparency mediated through varying levels of
explanation specificity in AD. We first extended a data-driven explainer model
by adding a rule-based option for explanation generation in AD, and then
conducted a within-subject lab study with 39 participants in an immersive
driving simulator to study the effect of the resulting explanations.
Specifically, our investigation focused on: (1) how different types of
explanations (specific vs. abstract) affect passengers' perceived safety,
anxiety, and willingness to take control of the vehicle when the vehicle
perception system makes erroneous predictions; and (2) the relationship between
passengers' behavioural cues and their feelings during the autonomous drives.
Our findings showed that passengers felt safer with specific explanations when
the vehicle's perception system had minimal errors, while abstract explanations
that hid perception errors led to lower feelings of safety. Anxiety levels
increased when specific explanations revealed perception system errors (high
transparency). We found no significant link between passengers' visual patterns
and their anxiety levels. Our study suggests that passengers prefer clear and
specific explanations (high transparency) when they originate from autonomous
vehicles (AVs) with optimal perceptual accuracy.

ÊëòË¶ÅÔºöËá™ÂãïÂåñÁ≥ªÁµ±‰∏≠ÁöÑÈÄèÊòéÂ∫¶ÂèØÈÄèÈÅéÊèê‰æõÂèØÁêÜËß£ÁöÑË™™Êòé‰æÜÊèê‰æõ„ÄÇÂÑòÁÆ°ÈÄèÊòéÂ∫¶ÊòØÂèØÂèñÁöÑÔºå‰ΩÜÂÆÉÂèØËÉΩÊúÉÂ∞éËá¥Ôºà‰æãÂ¶ÇÁÑ¶ÊÖÆÔºâÁöÑÁÅΩÈõ£ÊÄßÂæåÊûúÔºåÈÄôÂèØËÉΩÊúÉË∂ÖÈÅéÂÖ∂Â•ΩËôïÔºüË™™ÊòéÁöÑÂÖ∑È´îÊÄßÔºàÈÄèÊòéÂ∫¶Á≠âÁ¥öÔºâÂ¶Ç‰ΩïÂΩ±ÈüøÊé•Êî∂ËÄÖÔºåÁâπÂà•ÊòØÂú®Ëá™ÂãïÈßïÈßõ (AD) ‰∏≠ÔºåÈÄô‰∏ÄÈªûÂ∞ö‰∏çÊ∏ÖÊ•ö„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊé¢Ë®é‰∫ÜÂú® AD ‰∏≠ÈÄèÈÅé‰∏çÂêåÁ≠âÁ¥öÁöÑË™™ÊòéÂÖ∑È´îÊÄß‰æÜË™øÁØÄÈÄèÊòéÂ∫¶ÁöÑÊïàÊûú„ÄÇÊàëÂÄëÈ¶ñÂÖàÊì¥ÂÖÖ‰∫Ü‰∏ÄÂÄãË≥áÊñôÈ©ÖÂãïÁöÑË™™ÊòéÊ®°ÂûãÔºåÊñπÊ≥ïÊòØÂú® AD ‰∏≠Âä†ÂÖ•‰∏ÄÂÄãÂü∫ÊñºË¶èÂâáÁöÑÈÅ∏È†Ö‰æÜÁî¢ÁîüË™™ÊòéÔºåÁÑ∂ÂæåÂú®‰∏ÄÂÄãÊ≤âÊµ∏ÂºèÁöÑÈßïÈßõÊ®°Êì¨Âô®‰∏≠ÈÄ≤Ë°å‰∏ÄÂÄã‰∏ªÈ°åÂÖßÂØ¶È©óÂÆ§Á†îÁ©∂Ôºå‰ª•Á†îÁ©∂ÊâÄÂæóË™™ÊòéÁöÑÊïàÊûú„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÁöÑË™øÊü•ÈáçÈªûÂú®ÊñºÔºö(1) ‰∏çÂêåÈ°ûÂûãÁöÑË™™ÊòéÔºàÂÖ∑È´îËàáÊäΩË±°ÔºâÂ¶Ç‰ΩïÂΩ±Èüø‰πòÂÆ¢Âú®ËªäËºõÊÑüÁü•Á≥ªÁµ±ÂÅöÂá∫ÈåØË™§È†êÊ∏¨ÊôÇÂ∞çÂÆâÂÖ®„ÄÅÁÑ¶ÊÖÆÂíåÈ°òÊÑèÊéßÂà∂ËªäËºõÁöÑÁúãÊ≥ïÔºõ‰ª•Âèä (2) ‰πòÂÆ¢Âú®Ëá™ÂãïÈßïÈßõÊúüÈñìÁöÑË°åÁÇ∫Á∑öÁ¥¢Ëàá‰ªñÂÄëÁöÑÊÑüË¶∫‰πãÈñìÁöÑÈóú‰øÇ„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÈ°ØÁ§∫ÔºåÁï∂ËªäËºõÁöÑÊÑüÁü•Á≥ªÁµ±ÈåØË™§ÊúÄÂ∞ëÊôÇÔºå‰πòÂÆ¢Â∞çÂÖ∑È´îÁöÑË™™ÊòéÊÑüÂà∞Êõ¥ÂÆâÂÖ®ÔºåËÄåÈö±ËóèÊÑüÁü•ÈåØË™§ÁöÑÊäΩË±°Ë™™ÊòéÂâáÂ∞éËá¥ËºÉ‰ΩéÁöÑÂÆâÂÖ®ÊÑü„ÄÇÁï∂ÂÖ∑È´îÁöÑË™™ÊòéÊè≠Á§∫ÊÑüÁü•Á≥ªÁµ±ÈåØË™§ÔºàÈ´òÈÄèÊòéÂ∫¶ÔºâÊôÇÔºåÁÑ¶ÊÖÆÁ®ãÂ∫¶ÊúÉÂ¢ûÂä†„ÄÇÊàëÂÄëÊ≤íÊúâÁôºÁèæ‰πòÂÆ¢ÁöÑË¶ñË¶∫Ê®°ÂºèÂíåÁÑ¶ÊÖÆÁ®ãÂ∫¶‰πãÈñìÊúâÈ°ØËëóÁöÑÈóúËÅØÊÄß„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂Ë°®ÊòéÔºåÁï∂Ë™™Êòé‰æÜËá™ÂÖ∑ÊúâÊúÄ‰Ω≥ÊÑüÁü•Á≤æÂ∫¶ÁöÑËá™ÂãïÈßïÈßõËªäËºõ (AV) ÊôÇÔºå‰πòÂÆ¢Êõ¥ÂñúÊ≠°Ê∏ÖÊô∞ÂÖ∑È´îÁöÑË™™ÊòéÔºàÈ´òÈÄèÊòéÂ∫¶Ôºâ„ÄÇ

##### **EmoDynamiX: Emotional Support Dialogue Strategy Prediction by Modelling MiXed Emotions and Discourse Dynamics**
2408.08782v1 by Chenwei Wan, Matthieu Labeau, Chlo√© Clavel

Designing emotionally intelligent conversational systems to provide comfort
and advice to people experiencing distress is a compelling area of research.
Previous efforts have focused on developing modular dialogue systems that treat
socio-emotional strategy prediction as an auxiliary task and generate
strategy-conditioned responses with customized decoders. Recently, with
advancements in large language models (LLMs), end-to-end dialogue agents
without explicit socio-emotional strategy prediction steps have become
prevalent. However, despite their excellence in language generation, recent
studies show that LLMs' inherent preference bias towards certain
socio-emotional strategies hinders the delivery of high-quality emotional
support. To address this challenge, we propose decoupling strategy prediction
from language generation, and introduce a novel dialogue strategy predictor,
EmoDynamiX, which models the discourse dynamics between user emotions and
system strategies using a heterogeneous graph. Additionally, we make use of the
Emotion Recognition in Conversations (ERC) task and design a flexible
mixed-emotion module to capture fine-grained emotional states of the user.
Experimental results on two ESC datasets show EmoDynamiX outperforms previous
state-of-the-art methods with a significant margin.

ÊëòË¶ÅÔºöË®≠Ë®àÊÉÖÁ∑íÊô∫ËÉΩÂ∞çË©±Á≥ªÁµ±‰ª•Êèê‰æõÂÆâÊÖ∞ÂíåÂª∫Ë≠∞Áµ¶Á∂ìÊ≠∑ÁóõËã¶ÁöÑ‰∫∫ÊòØ‰∏ÄÂÄãÂºï‰∫∫ÂÖ•ÂãùÁöÑÁ†îÁ©∂È†òÂüü„ÄÇ
ÂÖàÂâçÁöÑÂä™ÂäõÈõÜ‰∏≠ÊñºÈñãÁôºÊ®°ÁµÑÂåñÂ∞çË©±Á≥ªÁµ±ÔºåÂ∞áÁ§æÊúÉÊÉÖÁ∑íÁ≠ñÁï•È†êÊ∏¨Ë¶ñÁÇ∫ËºîÂä©‰ªªÂãôÔºå‰∏¶‰ΩøÁî®Ëá™Ë®ÇËß£Á¢ºÂô®Áî¢ÁîüÁ≠ñÁï•Ê¢ù‰ª∂ÂåñÁöÑÂõûÊáâ„ÄÇÊúÄËøëÔºåÈö®ËëóÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÈÄ≤Ê≠•ÔºåÊ≤íÊúâÊòéÁ¢∫Á§æÊúÉÊÉÖÁ∑íÁ≠ñÁï•È†êÊ∏¨Ê≠•È©üÁöÑÁ´ØÂà∞Á´ØÂ∞çË©±‰ª£ÁêÜÂ∑≤ËÆäÂæóÊôÆÈÅç„ÄÇÁÑ∂ËÄåÔºåÂÑòÁÆ°ÂÆÉÂÄëÂú®Ë™ûË®ÄÁîüÊàêÊñπÈù¢Ë°®ÁèæÂá∫Ëâ≤Ôºå‰ΩÜÊúÄËøëÁöÑÁ†îÁ©∂Ë°®ÊòéÔºåLLM Â∞çÊüê‰∫õÁ§æÊúÉÊÉÖÁ∑íÁ≠ñÁï•ÁöÑÂõ∫ÊúâÂÅèÂ•ΩÊúÉÈòªÁ§ôÊèê‰æõÈ´òÂìÅË≥™ÁöÑÊÉÖÁ∑íÊîØÊåÅ„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∏ÄÊåëÊà∞ÔºåÊàëÂÄëÂª∫Ë≠∞Â∞áÁ≠ñÁï•È†êÊ∏¨ËàáË™ûË®ÄÁîüÊàêËß£ËÄ¶Ôºå‰∏¶ÂºïÂÖ•‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÂ∞çË©±Á≠ñÁï•È†êÊ∏¨Âô® EmoDynamiXÔºåÂÆÉ‰ΩøÁî®Áï∞Ë≥™ÂúñÂΩ¢Â∞ç‰ΩøÁî®ËÄÖÊÉÖÁ∑íÂíåÁ≥ªÁµ±Á≠ñÁï•‰πãÈñìÁöÑË©±Ë™ûÂãïÊÖãÈÄ≤Ë°åÂª∫Ê®°„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂà©Áî®Â∞çË©±‰∏≠ÁöÑÊÉÖÁ∑íËæ®Ë≠ò (ERC) ‰ªªÂãô‰∏¶Ë®≠Ë®à‰∫Ü‰∏ÄÂÄãÈùàÊ¥ªÁöÑÊ∑∑ÂêàÊÉÖÁ∑íÊ®°ÁµÑ‰æÜÊçïÊçâ‰ΩøÁî®ËÄÖÁöÑÁ¥∞Á∑ªÊÉÖÁ∑íÁãÄÊÖã„ÄÇÂú®ÂÖ©ÂÄã ESC Ë≥áÊñôÈõÜ‰∏äÁöÑÂØ¶È©óÁµêÊûúÈ°ØÁ§∫ÔºåEmoDynamiX ‰ª•È°ØËëóÁöÑÂπÖÂ∫¶ÂÑ™ÊñºÂÖàÂâçÁöÑÊúÄÊñ∞ÊñπÊ≥ï„ÄÇ

##### **Evaluating the Evaluator: Measuring LLMs' Adherence to Task Evaluation Instructions**
2408.08781v1 by Bhuvanashree Murugadoss, Christian Poelitz, Ian Drosos, Vu Le, Nick McKenna, Carina Suzana Negreanu, Chris Parnin, Advait Sarkar

LLMs-as-a-judge is a recently popularized method which replaces human
judgements in task evaluation (Zheng et al. 2024) with automatic evaluation
using LLMs. Due to widespread use of RLHF (Reinforcement Learning from Human
Feedback), state-of-the-art LLMs like GPT4 and Llama3 are expected to have
strong alignment with human preferences when prompted for a quality judgement,
such as the coherence of a text. While this seems beneficial, it is not clear
whether the assessments by an LLM-as-a-judge constitute only an evaluation
based on the instructions in the prompts, or reflect its preference for
high-quality data similar to its fine-tune data. To investigate how much
influence prompting the LLMs-as-a-judge has on the alignment of AI judgements
to human judgements, we analyze prompts with increasing levels of instructions
about the target quality of an evaluation, for several LLMs-as-a-judge.
Further, we compare to a prompt-free method using model perplexity as a quality
measure instead. We aggregate a taxonomy of quality criteria commonly used
across state-of-the-art evaluations with LLMs and provide this as a rigorous
benchmark of models as judges. Overall, we show that the LLMs-as-a-judge
benefit only little from highly detailed instructions in prompts and that
perplexity can sometimes align better with human judgements than prompting,
especially on textual quality.

ÊëòË¶ÅÔºöLLM Âç≥Ê≥ïÂÆòÊòØ‰∏ÄÁ®ÆÊúÄËøëÂæàÊµÅË°åÁöÑÊñπÊ≥ïÔºåÂÆÉÁî® LLM Ëá™ÂãïË©ï‰º∞Âèñ‰ª£‰∫Ü‰ªªÂãôË©ï‰º∞‰∏≠ÁöÑ‰∫∫È°ûÂà§Êñ∑ÔºàÈÑ≠Á≠â‰∫∫Ôºå2024 Âπ¥Ôºâ„ÄÇÁî±ÊñºÂª£Ê≥õ‰ΩøÁî® RLHFÔºà‰∫∫È°ûÂõûÈ•ãÂº∑ÂåñÂ≠∏ÁøíÔºâÔºåÁï∂ÊèêÁ§∫ÈÄ≤Ë°åÂìÅË≥™Âà§Êñ∑ÊôÇÔºå‰æãÂ¶ÇÊñáÊú¨ÁöÑÈÄ£Ë≤´ÊÄßÔºåÈ†êÊúüÂÉè GPT4 Âíå Llama3 Á≠âÊúÄÂÖàÈÄ≤ÁöÑ LLM Ëàá‰∫∫È°ûÂÅèÂ•ΩÊúâÂæàÂº∑ÁöÑ‰∏ÄËá¥ÊÄß„ÄÇÈõñÁÑ∂ÈÄôÁúãËµ∑‰æÜÊúâÁõäÔºå‰ΩÜÂ∞ö‰∏çÊ∏ÖÊ•ö LLM Âç≥Ê≥ïÂÆòÁöÑË©ï‰º∞ÊòØÂê¶ÂÉÖÊßãÊàêÂü∫ÊñºÊèêÁ§∫‰∏≠Ë™™ÊòéÁöÑË©ï‰º∞ÔºåÈÇÑÊòØÂèçÊò†‰∫ÜÂÆÉÂ∞çÈ°û‰ººÊñºÂÖ∂ÂæÆË™øË≥áÊñôÁöÑÈ´òÂìÅË≥™Ë≥áÊñôÁöÑÂÅèÂ•Ω„ÄÇÁÇ∫‰∫ÜË™øÊü•ÊèêÁ§∫ LLM Âç≥Ê≥ïÂÆòÂ∞ç AI Âà§Êñ∑Ëàá‰∫∫È°ûÂà§Êñ∑ÁöÑ‰∏ÄËá¥ÊÄßÊúâÂ§öÂ§ßÂΩ±ÈüøÔºåÊàëÂÄëÂàÜÊûê‰∫ÜÈáùÂ∞çÂ§öÂÄã LLM Âç≥Ê≥ïÂÆòÔºåÂåÖÂê´Ë∂ä‰æÜË∂äÈ´òÂ±§Á¥öÁöÑË©ï‰º∞ÁõÆÊ®ôÂìÅË≥™Ë™™ÊòéÁöÑÊèêÁ§∫„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂ∞áÂÖ∂Ëàá‰∏ÄÁ®ÆÁÑ°ÊèêÁ§∫ÊñπÊ≥ïÈÄ≤Ë°åÊØîËºÉÔºåË©≤ÊñπÊ≥ï‰ΩøÁî®Ê®°ÂûãÂõ∞ÊÉëÂ∫¶‰ΩúÁÇ∫ÂìÅË≥™Ë°°ÈáèÊ®ôÊ∫ñ„ÄÇÊàëÂÄëÂΩôÁ∏Ω‰∫Ü‰∏ÄÂÄãÂàÜÈ°ûÊ≥ïÔºåÂÖ∂‰∏≠ÂåÖÂê´ LLM ÊúÄÂÖàÈÄ≤Ë©ï‰º∞‰∏≠Â∏∏Áî®ÁöÑÂìÅË≥™Ê®ôÊ∫ñÔºå‰∏¶Â∞áÂÖ∂‰ΩúÁÇ∫Ê®°Âûã‰ΩúÁÇ∫Ê≥ïÂÆòÁöÑÂö¥Ê†ºÂü∫Ê∫ñ„ÄÇÁ∏ΩÁöÑ‰æÜË™™ÔºåÊàëÂÄëË°®Êòé LLM Âç≥Ê≥ïÂÆòÂÉÖÂæûÊèêÁ§∫‰∏≠ÈùûÂ∏∏Ë©≥Á¥∞ÁöÑË™™Êòé‰∏≠ÂèóÁõäÂæàÂ∞ëÔºå‰∏¶‰∏îÂõ∞ÊÉëÂ∫¶ÊúâÊôÇÂèØ‰ª•ÊØîÊèêÁ§∫Êõ¥Â•ΩÂú∞Ëàá‰∫∫È°ûÂà§Êñ∑‰øùÊåÅ‰∏ÄËá¥ÔºåÁâπÂà•ÊòØÂú®ÊñáÂ≠óÂìÅË≥™ÊñπÈù¢„ÄÇ

##### **Large Language Models Might Not Care What You Are Saying: Prompt Format Beats Descriptions**
2408.08780v1 by Chenming Tang, Zhixiang Wang, Yunfang Wu

With the help of in-context learning (ICL), large language models (LLMs) have
achieved impressive performance across various tasks. However, the function of
descriptive instructions during ICL remains under-explored. In this work, we
propose an ensemble prompt framework to describe the selection criteria of
multiple in-context examples, and preliminary experiments on machine
translation (MT) across six translation directions confirm that this framework
boosts ICL perfromance. But to our surprise, LLMs might not necessarily care
what the descriptions actually say, and the performance gain is primarily
caused by the ensemble format, since the framework could lead to improvement
even with random descriptive nouns. We further apply this new ensemble prompt
on a range of commonsense, math, logical reasoning and hallucination tasks with
three LLMs and achieve promising results, suggesting again that designing a
proper prompt format would be much more effective and efficient than paying
effort into specific descriptions. Our code will be publicly available once
this paper is published.

ÊëòË¶ÅÔºöÂú®‰∏ä‰∏ãÊñáÂ≠∏Áøí (ICL) ÁöÑÂπ´Âä©‰∏ãÔºåÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®ÂêÑÁ®Æ‰ªªÂãô‰∏≠ÈÉΩÂèñÂæó‰∫Ü‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑË°®Áèæ„ÄÇÁÑ∂ËÄåÔºåÊèèËø∞ÊÄßË™™ÊòéÂú® ICL ‰∏≠ÁöÑÂäüËÉΩ‰ªçÊú™ÂæóÂà∞ÂÖÖÂàÜÊé¢Ë®é„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊï¥È´îÊèêÁ§∫Ê°ÜÊû∂‰æÜÊèèËø∞Â§öÂÄã‰∏ä‰∏ãÊñáÁØÑ‰æãÁöÑÈÅ∏ÊìáÊ®ôÊ∫ñÔºå‰∏¶‰∏îÂú®ÂÖ≠Á®ÆÁøªË≠ØÊñπÂêëÁöÑÊ©üÂô®ÁøªË≠Ø (MT) ‰∏äÈÄ≤Ë°åÁöÑÂàùÊ≠•ÂØ¶È©óË≠âÂØ¶‰∫ÜÈÄôÂÄãÊ°ÜÊû∂ÊèêÂçá‰∫Ü ICL ÁöÑË°®Áèæ„ÄÇ‰ΩÜ‰ª§ÊàëÂÄëÈ©öË®ùÁöÑÊòØÔºåLLM ÂèØËÉΩ‰∏ç‰∏ÄÂÆöÂú®‰πéË™™ÊòéÂØ¶Èöõ‰∏äË™™‰∫Ü‰ªÄÈ∫ºÔºåËÄåÊïàËÉΩÊèêÂçá‰∏ªË¶ÅÊòØÁî±Êï¥È´îÊ†ºÂºèÈÄ†ÊàêÁöÑÔºåÂõ†ÁÇ∫ÈÄôÂÄãÊ°ÜÊû∂ÁîöËá≥ÂèØ‰ª•ÈÄèÈÅéÈö®Ê©üÊèèËø∞ÊÄßÂêçË©û‰æÜÂ∏∂‰æÜÊîπÂñÑ„ÄÇÊàëÂÄëÈÄ≤‰∏ÄÊ≠•Â∞áÈÄôÂÄãÊñ∞ÁöÑÊï¥È´îÊèêÁ§∫ÊáâÁî®Âú®Â∏∏Ë≠ò„ÄÅÊï∏Â≠∏„ÄÅÈÇèËºØÊé®ÁêÜÂíåÂπªË¶∫‰ªªÂãôÁöÑÁØÑÂúç‰∏≠Ôºå‰∏¶‰ΩøÁî®‰∏âÂÄã LLM ‰∏¶Áç≤ÂæóÊúâÂ∏åÊúõÁöÑÁµêÊûúÔºåÂÜçÊ¨°Ë°®ÊòéË®≠Ë®àÈÅ©Áï∂ÁöÑÊèêÁ§∫Ê†ºÂºèÂ∞áÊØîÂú®ÁâπÂÆöË™™Êòé‰∏äÊäïÂÖ•Á≤æÂäõÊõ¥ÊúâÊïàÁéá„ÄÇ‰∏ÄÊó¶ÈÄôÁØáË´ñÊñáÁôºË°®ÔºåÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÂ∞áÂÖ¨Èñã„ÄÇ

##### **DAC: Decomposed Automation Correction for Text-to-SQL**
2408.08779v1 by Dingzirui Wang, Longxu Dou, Xuanliang Zhang, Qingfu Zhu, Wanxiang Che

Text-to-SQL is an important task that helps people obtain information from
databases by automatically generating SQL queries. Considering the brilliant
performance, approaches based on Large Language Models (LLMs) become the
mainstream for text-to-SQL. Among these approaches, automated correction is an
effective approach that further enhances performance by correcting the mistakes
in the generated results. The existing correction methods require LLMs to
directly correct with generated SQL, while previous research shows that LLMs do
not know how to detect mistakes, leading to poor performance. Therefore, in
this paper, we propose to employ the decomposed correction to enhance
text-to-SQL performance. We first demonstrate that decomposed correction
outperforms direct correction since detecting and fixing mistakes with the
results of the decomposed sub-tasks is easier than with SQL. Based on this
analysis, we introduce Decomposed Automation Correction (DAC), which corrects
SQL by decomposing text-to-SQL into entity linking and skeleton parsing. DAC
first generates the entity and skeleton corresponding to the question and then
compares the differences between the initial SQL and the generated entities and
skeleton as feedback for correction. Experimental results show that our method
improves performance by $3.7\%$ on average of Spider, Bird, and KaggleDBQA
compared with the baseline method, demonstrating the effectiveness of DAC.

ÊëòË¶ÅÔºöÊñáÊú¨ËΩâ SQL ÊòØ‰∏ÄÈ†ÖÈáçË¶ÅÁöÑ‰ªªÂãôÔºåÂÆÉÂèØÂçîÂä©‰∫∫ÂÄëÈÄèÈÅéËá™ÂãïÁî¢Áîü SQL Êü•Ë©¢‰æÜÂæûË≥áÊñôÂ∫´ÂèñÂæóË≥áË®ä„ÄÇËÄÉÈáèÂà∞Áµï‰Ω≥ÊïàËÉΩÔºåÂü∫ÊñºÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊñπÊ≥ïÂ∑≤ÊàêÁÇ∫ÊñáÊú¨ËΩâ SQL ÁöÑ‰∏ªÊµÅ„ÄÇÂú®ÈÄô‰∫õÊñπÊ≥ï‰∏≠ÔºåËá™ÂãïÊõ¥Ê≠£ÊòØ‰∏ÄÁ®ÆÊúâÊïàÁöÑÊñπÊ≥ïÔºåÂÆÉÈÄèÈÅéÊõ¥Ê≠£Áî¢ÁîüÁµêÊûú‰∏≠ÁöÑÈåØË™§ÈÄ≤‰∏ÄÊ≠•ÊèêÂçáÊïàËÉΩ„ÄÇÁèæÊúâÁöÑÊõ¥Ê≠£ÊñπÊ≥ïË¶ÅÊ±Ç LLM Áõ¥Êé•‰ΩøÁî®Áî¢ÁîüÁöÑ SQL ÈÄ≤Ë°åÊõ¥Ê≠£ÔºåËÄåÂÖàÂâçÁöÑÁ†îÁ©∂È°ØÁ§∫ LLM ‰∏çÁü•ÈÅìÂ¶Ç‰ΩïÂÅµÊ∏¨ÈåØË™§ÔºåÂ∞éËá¥ÊïàËÉΩ‰∏ç‰Ω≥„ÄÇÂõ†Ê≠§ÔºåÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂª∫Ë≠∞Êé°Áî®ÂàÜËß£Êõ¥Ê≠£‰æÜÊèêÂçáÊñáÊú¨ËΩâ SQL ÁöÑÊïàËÉΩ„ÄÇÊàëÂÄëÈ¶ñÂÖàË≠âÊòéÂàÜËß£Êõ¥Ê≠£ÂÑ™ÊñºÁõ¥Êé•Êõ¥Ê≠£ÔºåÂõ†ÁÇ∫‰ΩøÁî®ÂàÜËß£Â≠ê‰ªªÂãôÁöÑÁµêÊûú‰æÜÂÅµÊ∏¨Âíå‰øÆÊ≠£ÈåØË™§ÊØî‰ΩøÁî® SQL ÂÆπÊòì„ÄÇÊ†πÊìöÈÄôÂÄãÂàÜÊûêÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜÂàÜËß£Ëá™ÂãïÊõ¥Ê≠£ (DAC)ÔºåÂÆÉÈÄèÈÅéÂ∞áÊñáÊú¨ËΩâ SQL ÂàÜËß£ÁÇ∫ÂØ¶È´îÈÄ£ÁµêÂíåÁµêÊßãÂâñÊûê‰æÜÊõ¥Ê≠£ SQL„ÄÇDAC È¶ñÂÖàÁî¢ÁîüËàáÂïèÈ°åÁõ∏Á¨¶ÁöÑÂØ¶È´îÂíåÁµêÊßãÔºåÁÑ∂ÂæåÊØîËºÉÂàùÂßã SQL ËàáÁî¢ÁîüÁöÑÂØ¶È´îÂíåÁµêÊßã‰πãÈñìÁöÑÂ∑ÆÁï∞Ôºå‰ΩúÁÇ∫Êõ¥Ê≠£ÁöÑÂõûÈ•ã„ÄÇÂØ¶È©óÁµêÊûúÈ°ØÁ§∫ÔºåËàáÂü∫Ê∫ñÊñπÊ≥ïÁõ∏ÊØîÔºåÊàëÂÄëÁöÑÊ®°ÂûãÂú® Spider„ÄÅBird Âíå KaggleDBQA ÁöÑÂπ≥ÂùáÊïàËÉΩÊèêÂçá‰∫Ü 3.7%ÔºåË≠âÊòé‰∫Ü DAC ÁöÑÊúâÊïàÊÄß„ÄÇ

##### **Pessimistic Iterative Planning for Robust POMDPs**
2408.08770v1 by Maris F. L. Galesloot, Marnix Suilen, Thiago D. Sim√£o, Steven Carr, Matthijs T. J. Spaan, Ufuk Topcu, Nils Jansen

Robust partially observable Markov decision processes (robust POMDPs) extend
classical POMDPs to handle additional uncertainty on the transition and
observation probabilities via so-called uncertainty sets. Policies for robust
POMDPs must not only be memory-based to account for partial observability but
also robust against model uncertainty to account for the worst-case instances
from the uncertainty sets. We propose the pessimistic iterative planning (PIP)
framework, which finds robust memory-based policies for robust POMDPs. PIP
alternates between two main steps: (1) selecting an adversarial (non-robust)
POMDP via worst-case probability instances from the uncertainty sets; and (2)
computing a finite-state controller (FSC) for this adversarial POMDP. We
evaluate the performance of this FSC on the original robust POMDP and use this
evaluation in step (1) to select the next adversarial POMDP. Within PIP, we
propose the rFSCNet algorithm. In each iteration, rFSCNet finds an FSC through
a recurrent neural network trained using supervision policies optimized for the
adversarial POMDP. The empirical evaluation in four benchmark environments
showcases improved robustness against a baseline method in an ablation study
and competitive performance compared to a state-of-the-art robust POMDP solver.

ÊëòË¶ÅÔºöÂº∑ÂÅ•ÁöÑÈÉ®ÂàÜÂèØËßÄÂØüÈ¶¨ÂèØÂ§´Ê±∫Á≠ñÈÅéÁ®ã (Âº∑ÂÅ• POMDP) Âª∂‰º∏‰∫ÜÂè§ÂÖ∏ POMDPÔºåÈÄèÈÅéÊâÄË¨ÇÁöÑ‰∏çÁ¢∫ÂÆöÈõÜ‰æÜËôïÁêÜËΩâÊèõÂíåËßÄÂØüÊ©üÁéáÁöÑÈ°çÂ§ñ‰∏çÁ¢∫ÂÆöÊÄß„ÄÇÂº∑ÂÅ• POMDP ÁöÑÊîøÁ≠ñ‰∏çÂÉÖÂøÖÈ†àÂü∫ÊñºË®òÊÜ∂È´î‰æÜËÄÉÈáèÈÉ®ÂàÜÂèØËßÄÂØüÊÄßÔºåÈÇÑÂøÖÈ†àÂ∞çÊäóÊ®°ÂûãÁöÑ‰∏çÁ¢∫ÂÆöÊÄßÔºå‰ª•ËÄÉÈáè‰∏çÁ¢∫ÂÆöÈõÜ‰∏≠ÁöÑÊúÄÂ£ûÊÉÖÊ≥Å„ÄÇÊàëÂÄëÊèêÂá∫ÊÇ≤ËßÄËø≠‰ª£Ë¶èÂäÉ (PIP) Ê°ÜÊû∂ÔºåÂÆÉÁÇ∫Âº∑ÂÅ• POMDP ÊâæÂá∫Âº∑ÂÅ•ÁöÑÂü∫ÊñºË®òÊÜ∂È´îÁöÑÊîøÁ≠ñ„ÄÇPIP Âú®ÂÖ©ÂÄã‰∏ªË¶ÅÊ≠•È©ü‰πãÈñì‰∫§ÊõøÈÄ≤Ë°åÔºö(1) ÈÄèÈÅé‰∏çÁ¢∫ÂÆöÈõÜ‰∏≠ÁöÑÊúÄÂ£ûÊÉÖÊ≥ÅÊ©üÁéáÂØ¶‰æã‰æÜÈÅ∏ÊìáÂ∞çÊäóÊÄßÁöÑ (ÈùûÂº∑ÂÅ•) POMDPÔºõ(2) ÁÇ∫ÈÄôÂÄãÂ∞çÊäóÊÄß POMDP Ë®àÁÆóÊúâÈôêÁãÄÊÖãÊéßÂà∂Âô® (FSC)„ÄÇÊàëÂÄëË©ï‰º∞ÈÄôÂÄã FSC Âú®ÂéüÂßãÂº∑ÂÅ• POMDP ‰∏äÁöÑÊïàËÉΩÔºå‰∏¶Âú®Ê≠•È©ü (1) ‰∏≠‰ΩøÁî®ÈÄôÂÄãË©ï‰º∞‰æÜÈÅ∏Êìá‰∏ã‰∏ÄÂÄãÂ∞çÊäóÊÄß POMDP„ÄÇÂú® PIP ‰∏≠ÔºåÊàëÂÄëÊèêÂá∫ rFSCNet ÊºîÁÆóÊ≥ï„ÄÇÂú®ÊØèÂÄãÂèçË¶ÜÈÅãÁÆó‰∏≠ÔºårFSCNet ÈÄèÈÅéÈÅûËø¥Á•ûÁ∂ìÁ∂≤Ë∑ØÊâæÂá∫‰∏ÄÂÄã FSCÔºåË©≤Á∂≤Ë∑Ø‰ΩøÁî®ÈáùÂ∞çÂ∞çÊäóÊÄß POMDP ÊúÄ‰Ω≥ÂåñÁöÑÁõ£Áù£ÊîøÁ≠ñÈÄ≤Ë°åË®ìÁ∑¥„ÄÇÂú®ÂõõÂÄãÂü∫Ê∫ñÁí∞Â¢É‰∏≠ÁöÑÁ∂ìÈ©óË©ï‰º∞Â±ïÁ§∫‰∫ÜÂú®Ê∂àËûçÁ†îÁ©∂‰∏≠Â∞çÊäóÂü∫Á∑öÊñπÊ≥ïÁöÑÂº∑ÂÅ•ÊÄßÊèêÂçáÔºå‰ª•ÂèäËàáÊúÄÂÖàÈÄ≤ÁöÑÂº∑ÂÅ• POMDP Ëß£Ê±∫Âô®Áõ∏ÊØîÂÖ∑ÊúâÁ´∂Áà≠ÂäõÁöÑÊïàËÉΩ„ÄÇ

##### **Lower Layer Matters: Alleviating Hallucination via Multi-Layer Fusion Contrastive Decoding with Truthfulness Refocused**
2408.08769v1 by Dingwei Chen, Feiteng Fang, Shiwen Ni, Feng Liang, Ruifeng Xu, Min Yang, Chengming Li

Large Language Models (LLMs) have demonstrated exceptional performance across
various natural language processing tasks, yet they occasionally tend to yield
content that factually inaccurate or discordant with the expected output, a
phenomenon empirically referred to as "hallucination". To tackle this issue,
recent works have investigated contrastive decoding between the original model
and an amateur model with induced hallucination, which has shown promising
results. Nonetheless, this method may undermine the output distribution of the
original LLM caused by its coarse contrast and simplistic subtraction
operation, potentially leading to errors in certain cases. In this paper, we
introduce a novel contrastive decoding framework termed LOL (LOwer Layer
Matters). Our approach involves concatenating the contrastive decoding of both
the final and lower layers between the original model and the amateur model,
thereby achieving multi-layer fusion to aid in the mitigation of hallucination.
Additionally, we incorporate a truthfulness refocused module that leverages
contextual guidance to enhance factual encoding, further capturing truthfulness
during contrastive decoding. Extensive experiments conducted on two publicly
available datasets illustrate that our proposed LOL framework can substantially
alleviate hallucination while surpassing existing baselines in most cases.
Compared with the best baseline, we improve by average 4.5 points on all
metrics of TruthfulQA. The source code is coming soon.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®ÂêÑÁ®ÆËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ‰ªªÂãô‰∏≠Â±ïÁèæÂá∫ÈùûÂá°ÁöÑÊïàËÉΩÔºå‰ΩÜÂÅ∂ÁàæÊúÉÁî¢Áîü‰∫ãÂØ¶‰∏çÊ≠£Á¢∫ÊàñËàáÈ†êÊúüËº∏Âá∫‰∏ç‰∏ÄËá¥ÁöÑÂÖßÂÆπÔºåÈÄôÁ®ÆÁèæË±°Âú®Á∂ìÈ©ó‰∏äÁ®±ÁÇ∫„ÄåÂπªË¶∫„Äç„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊúÄËøëÁöÑÁ†îÁ©∂Êé¢Ë®é‰∫ÜÂéüÂßãÊ®°ÂûãËàáË™òÁôºÂπªË¶∫ÁöÑÊ•≠È§òÊ®°Âûã‰πãÈñìÁöÑÂ∞çÊØîËß£Á¢ºÔºå‰∏¶È°ØÁ§∫Âá∫ÊúâÂ∏åÊúõÁöÑÁµêÊûú„ÄÇÂÑòÁÆ°Â¶ÇÊ≠§ÔºåÈÄôÁ®ÆÊñπÊ≥ïÂèØËÉΩÊúÉÁ†¥Â£ûÂéüÂßã LLM ÁöÑËº∏Âá∫ÂàÜ‰ΩàÔºåÈÄôÊòØÂõ†ÁÇ∫ÂÖ∂Â∞çÊØîÁ≤óÁ≥ô‰∏îÊ∏õÊ≥ïÈÅãÁÆóÈÅéÊñºÁ∞°ÂåñÔºåÂú®Êüê‰∫õÊÉÖÊ≥Å‰∏ãÂèØËÉΩÊúÉÂ∞éËá¥ÈåØË™§„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫Ü‰∏ÄÂÄãÊñ∞Á©éÁöÑÂ∞çÊØîËß£Á¢ºÊû∂ÊßãÔºåÁ®±ÁÇ∫ LOLÔºàËºÉ‰ΩéÂ±§Á¥öÂæàÈáçË¶ÅÔºâ„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÊ∂âÂèä‰∏≤Êé•ÂéüÂßãÊ®°ÂûãÂíåÊ•≠È§òÊ®°Âûã‰πãÈñìÁöÑÊúÄÁµÇÂ±§ÂíåËºÉ‰ΩéÂ±§ÁöÑÂ∞çÊØîËß£Á¢ºÔºåÂæûËÄåÂØ¶ÁèæÂ§öÂ±§ËûçÂêà‰ª•Âπ´Âä©Ê∏õËºïÂπªË¶∫„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊï¥Âêà‰∫Ü‰∏ÄÂÄãÁúüÂØ¶ÊÄßÈáçÊñ∞ËÅöÁÑ¶Ê®°ÁµÑÔºåË©≤Ê®°ÁµÑÂà©Áî®‰∏ä‰∏ãÊñáÊåáÂ∞é‰æÜÂ¢ûÂº∑‰∫ãÂØ¶Á∑®Á¢ºÔºåÈÄ≤‰∏ÄÊ≠•Âú®Â∞çÊØîËß£Á¢ºÈÅéÁ®ã‰∏≠ÊçïÊçâÁúüÂØ¶ÊÄß„ÄÇÂú®ÂÖ©ÂÄãÂÖ¨ÈñãÂèØÁî®ÁöÑË≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÁöÑÂª£Ê≥õÂØ¶È©óË°®ÊòéÔºåÊàëÂÄëÊèêÂá∫ÁöÑ LOL Êû∂ÊßãÂèØ‰ª•Âú®Â§ßÂ§öÊï∏ÊÉÖÊ≥Å‰∏ãÂ§ßÂπÖÊ∏õËºïÂπªË¶∫ÔºåÂêåÊôÇË∂ÖË∂äÁèæÊúâÁöÑÂü∫Ê∫ñ„ÄÇËàáÊúÄ‰Ω≥Âü∫Ê∫ñÁõ∏ÊØîÔºåÊàëÂÄëÂú® TruthfulQA ÁöÑÊâÄÊúâÊåáÊ®ô‰∏äÂπ≥ÂùáÊèêÈ´ò‰∫Ü 4.5 ÂàÜ„ÄÇÂéüÂßãÁ¢ºÂç≥Â∞áÊé®Âá∫„ÄÇ

##### **ASVspoof 5: Crowdsourced Speech Data, Deepfakes, and Adversarial Attacks at Scale**
2408.08739v1 by Xin Wang, Hector Delgado, Hemlata Tak, Jee-weon Jung, Hye-jin Shim, Massimiliano Todisco, Ivan Kukanov, Xuechen Liu, Md Sahidullah, Tomi Kinnunen, Nicholas Evans, Kong Aik Lee, Junichi Yamagishi

ASVspoof 5 is the fifth edition in a series of challenges that promote the
study of speech spoofing and deepfake attacks, and the design of detection
solutions. Compared to previous challenges, the ASVspoof 5 database is built
from crowdsourced data collected from a vastly greater number of speakers in
diverse acoustic conditions. Attacks, also crowdsourced, are generated and
tested using surrogate detection models, while adversarial attacks are
incorporated for the first time. New metrics support the evaluation of
spoofing-robust automatic speaker verification (SASV) as well as stand-alone
detection solutions, i.e., countermeasures without ASV. We describe the two
challenge tracks, the new database, the evaluation metrics, baselines, and the
evaluation platform, and present a summary of the results. Attacks
significantly compromise the baseline systems, while submissions bring
substantial improvements.

ÊëòË¶ÅÔºöASVspoof 5 ÊòØÂú®‰øÉÈÄ≤Ë™ûÈü≥Ê¨∫È®ôÂíåÊ∑±Â∫¶ÂÅΩÈÄ†ÊîªÊìäÁöÑÁ†îÁ©∂Ôºå‰ª•ÂèäË®≠Ë®àÂÅµÊ∏¨Ëß£Ê±∫ÊñπÊ°àÁöÑÊåëÊà∞Á≥ªÂàó‰∏≠ÁöÑÁ¨¨‰∫îÁâà„ÄÇËàáÂÖàÂâçÁöÑÊåëÊà∞Áõ∏ÊØîÔºåASVspoof 5 Ë≥áÊñôÂ∫´ÊòØÂæûÂ§ßÈáèÊõ¥Âª£Ê≥õÁöÑË¨õËÄÖÂú®Â§öÊ®£ÂåñËÅ≤Â≠∏Ê¢ù‰ª∂‰∏ãÊî∂ÈõÜÁöÑÁæ§ÁúæÂ§ñÂåÖË≥áÊñô‰∏≠Âª∫Á´ãÁöÑ„ÄÇÊîªÊìäÔºå‰πüÊòØÁæ§ÁúæÂ§ñÂåÖÁöÑÔºå‰ΩøÁî®‰ª£ÁêÜÂÅµÊ∏¨Ê®°ÂûãÁî¢ÁîüÂíåÊ∏¨Ë©¶ÔºåÂêåÊôÇÈ¶ñÊ¨°Âä†ÂÖ•‰∫ÜÂ∞çÊäóÊÄßÊîªÊìä„ÄÇÊñ∞ÁöÑÊåáÊ®ôÊîØÊè¥Ê¨∫È®ôÊÄßÂº∑ÁöÑËá™ÂãïË™™Ë©±ËÄÖÈ©óË≠â (SASV) ‰ª•ÂèäÁç®Á´ãÂÅµÊ∏¨Ëß£Ê±∫ÊñπÊ°àÁöÑË©ï‰º∞ÔºåÂç≥Ê≤íÊúâ ASV ÁöÑÂ∞çÁ≠ñ„ÄÇÊàëÂÄëÊèèËø∞‰∫ÜÂÖ©ÂÄãÊåëÊà∞ËªåÈÅì„ÄÅÊñ∞ÁöÑË≥áÊñôÂ∫´„ÄÅË©ï‰º∞ÊåáÊ®ô„ÄÅÂü∫Ê∫ñÂíåË©ï‰º∞Âπ≥Âè∞Ôºå‰∏¶Êèê‰æõÁµêÊûúÊëòË¶Å„ÄÇÊîªÊìäÈ°ØËëóÂú∞Âç±ÂÆ≥‰∫ÜÂü∫Ê∫ñÁ≥ªÁµ±ÔºåËÄåÊèê‰∫§ÂâáÂ∏∂‰æÜ‰∫ÜÂØ¶Ë≥™ÊÄßÁöÑÊîπÈÄ≤„ÄÇ

##### **ChatZero:Zero-shot Cross-Lingual Dialogue Generation via Pseudo-Target Language**
2408.08724v1 by Yongkang Liu, Feng Shi, Daling Wang, Yifei Zhang, Hinrich Sch√ºtze

Although large language models(LLMs) show amazing capabilities, among various
exciting applications discovered for LLMs fall short in other low-resource
languages. Besides, most existing methods depend on large-scale dialogue
corpora and thus building systems for dialogue generation in a zero-shot
scenario remains a considerable challenge. To address this challenge, we
propose a novel end-to-end zero-shot dialogue generation model ChatZero based
on cross-lingual code-switching method. First, we construct code-switching
language and pseudo-target language with placeholders. Then for cross-lingual
semantic transfer, we employ unsupervised contrastive learning to minimize the
semantics gap of the source language, code-switching language, and
pseudo-target language that are mutually positive examples in the high
dimensional semantic space. Experiments on the multilingual DailyDialog and
DSTC7-AVSD datasets demonstrate that ChatZero can achieve more than 90\% of the
original performance under the zero-shot case compared to supervised learning,
and achieve state-of-the-art performance compared with other baselines.

ÊëòË¶ÅÔºöÂÑòÁÆ°Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â±ïÁèæÈ©ö‰∫∫ÁöÑËÉΩÂäõÔºåÂú®ÁÇ∫ LLM ÁôºÁèæÁöÑÂêÑÁ®Æ‰ª§‰∫∫ËààÂ•ÆÁöÑÊáâÁî®‰∏≠ÔºåÂú®ÂÖ∂‰ªñ‰ΩéË≥áÊ∫êË™ûË®Ä‰∏≠ÂçªË°®Áèæ‰∏ç‰Ω≥„ÄÇÊ≠§Â§ñÔºåÁèæÊúâÁöÑÂ§ßÂ§öÊï∏ÊñπÊ≥ïÈÉΩ‰æùË≥¥ÊñºÂ§ßË¶èÊ®°Â∞çË©±Ë™ûÊñôÂ∫´ÔºåÂõ†Ê≠§Âú®Èõ∂Ê¨°Â≠∏ÁøíÂ†¥ÊôØ‰∏≠Âª∫Á´ãÂ∞çË©±ÁîüÊàêÁ≥ªÁµ±‰ªçÁÑ∂ÊòØ‰∏ÄÈ†ÖÁõ∏Áï∂Â§ßÁöÑÊåëÊà∞„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∏ÄÊåëÊà∞ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂü∫ÊñºË∑®Ë™ûË®Ä‰ª£Á¢ºËΩâÊèõÊñπÊ≥ïÁöÑÊñ∞ÂûãÁ´ØÂà∞Á´ØÈõ∂Ê¨°Â≠∏ÁøíÂ∞çË©±ÁîüÊàêÊ®°Âûã ChatZero„ÄÇÈ¶ñÂÖàÔºåÊàëÂÄë‰ΩøÁî®‰Ωî‰ΩçÁ¨¶ÊßãÂª∫‰ª£Á¢ºËΩâÊèõË™ûË®ÄÂíåÂÅΩÁõÆÊ®ôË™ûË®Ä„ÄÇÁÑ∂ÂæåÔºåÂ∞çÊñºË∑®Ë™ûË®ÄË™ûÁæ©ËΩâÁßªÔºåÊàëÂÄëÊé°Áî®ÁÑ°Áõ£Áù£Â∞çÊØîÂ≠∏Áøí‰æÜÊúÄÂ∞èÂåñÊ∫êË™ûË®Ä„ÄÅ‰ª£Á¢ºËΩâÊèõË™ûË®ÄÂíåÂÅΩÁõÆÊ®ôË™ûË®ÄÁöÑË™ûÁæ©Â∑ÆË∑ùÔºåÈÄô‰∫õË™ûË®ÄÂú®È´òÁ∂≠Ë™ûÁæ©Á©∫Èñì‰∏≠ÊòØÁõ∏‰∫íÁöÑÊ≠£‰æã„ÄÇÂú®Â§öË™ûË®Ä DailyDialog Âíå DSTC7-AVSD Ë≥áÊñôÈõÜ‰∏äÁöÑÂØ¶È©óË°®ÊòéÔºåËàáÁõ£Áù£Â≠∏ÁøíÁõ∏ÊØîÔºåChatZero Âú®Èõ∂Ê¨°Â≠∏ÁøíÊÉÖÊ≥Å‰∏ãÂèØ‰ª•ÈÅîÂà∞ÂéüÂßãÊïàËÉΩÁöÑ 90% ‰ª•‰∏äÔºå‰∏¶‰∏îËàáÂÖ∂‰ªñÂü∫Ê∫ñÁõ∏ÊØîÔºåÈÅîÂà∞ÊúÄÂÖàÈÄ≤ÁöÑÊïàËÉΩ„ÄÇ

##### **Beyond KAN: Introducing KarSein for Adaptive High-Order Feature Interaction Modeling in CTR Prediction**
2408.08713v1 by Yunxiao Shi, Wujiang Wu, Mingyu Jin, Haimin Zhang, Qiang Wu, Yongfeng Zhang, Min Xu

Modeling feature interactions is crucial for click-through rate (CTR)
prediction, particularly when it comes to high-order explicit interactions.
Traditional methods struggle with this task because they often predefine a
maximum interaction order, which relies heavily on prior knowledge and can
limit the model's effectiveness. Additionally, modeling high-order interactions
typically leads to increased computational costs. Therefore, the challenge lies
in adaptively modeling high-order feature interactions while maintaining
efficiency. To address this issue, we introduce Kolmogorov-Arnold Represented
Sparse Efficient Interaction Network (KarSein), designed to optimize both
predictive accuracy and computational efficiency. We firstly identify
limitations of directly applying Kolmogorov-Arnold Networks (KAN) to CTR and
then introduce KarSein to overcome these issues. It features a novel
architecture that reduces the computational costs of KAN and supports embedding
vectors as feature inputs. Additionally, KarSein employs guided symbolic
regression to address the challenge of KAN in spontaneously learning
multiplicative relationships. Extensive experiments demonstrate KarSein's
superior performance, achieving significant predictive accuracy with minimal
computational overhead. Furthermore, KarSein maintains strong global
explainability while enabling the removal of redundant features, resulting in a
sparse network structure. These advantages also position KarSein as a promising
method for efficient inference.

ÊëòË¶ÅÔºöÁâπÂæµ‰∫íÂãïÂª∫Ê®°Â∞çÈªûÊìäÁéá (CTR) È†êÊ∏¨Ëá≥ÈóúÈáçË¶ÅÔºåÂ∞§ÂÖ∂Áï∂Ê∂âÂèäÈ´òÈöéÊòéÁ¢∫‰∫íÂãïÊôÇ„ÄÇÂÇ≥Áµ±ÊñπÊ≥ïÂú®ËôïÁêÜÈÄôÈ†Ö‰ªªÂãôÊôÇÊúÉÈÅáÂà∞Âõ∞Èõ£ÔºåÂõ†ÁÇ∫ÂÆÉÂÄëÈÄöÂ∏∏ÊúÉÈ†êÂÖàÂÆöÁæ©ÊúÄÂ§ß‰∫íÂãïÈöéÊï∏ÔºåÈÄôÈùûÂ∏∏‰æùË≥¥ÊñºÂÖàÈ©óÁü•Ë≠òÔºå‰∏îÂèØËÉΩÊúÉÈôêÂà∂Ê®°ÂûãÁöÑÊïàËÉΩ„ÄÇÊ≠§Â§ñÔºåÂª∫Ê®°È´òÈöé‰∫íÂãïÈÄöÂ∏∏ÊúÉÂ∞éËá¥ÈÅãÁÆóÊàêÊú¨Â¢ûÂä†„ÄÇÂõ†Ê≠§ÔºåÊåëÊà∞Âú®ÊñºÂú®Á∂≠ÊåÅÊïàÁéáÁöÑÂêåÊôÇÔºåËá™ÈÅ©ÊáâÂú∞Âª∫Ê®°È´òÈöéÁâπÂæµ‰∫íÂãï„ÄÇÁÇ∫‰∫ÜËß£Ê±∫Ê≠§ÂïèÈ°åÔºåÊàëÂÄëÂºïÈÄ≤‰∫Ü Kolmogorov-Arnold Ë°®Á§∫ÁöÑÁ®ÄÁñèÈ´òÊïà‰∫íÂãïÁ∂≤Ë∑Ø (KarSein)ÔºåÊó®Âú®ÊúÄ‰Ω≥ÂåñÈ†êÊ∏¨Ê∫ñÁ¢∫Â∫¶ÂíåÈÅãÁÆóÊïàÁéá„ÄÇÊàëÂÄëÈ¶ñÂÖàÊâæÂá∫Â∞á Kolmogorov-Arnold Á∂≤Ë∑Ø (KAN) Áõ¥Êé•ÊáâÁî®Êñº CTR ÁöÑÈôêÂà∂ÔºåÁÑ∂ÂæåÂºïÈÄ≤ KarSein ‰æÜÂÖãÊúçÈÄô‰∫õÂïèÈ°å„ÄÇÂÆÉÂÖ∑ÂÇô‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÊû∂ÊßãÔºåÂèØÈôç‰Ωé KAN ÁöÑÈÅãÁÆóÊàêÊú¨Ôºå‰∏¶ÊîØÊè¥Â∞áÂµåÂÖ•ÂêëÈáè‰ΩúÁÇ∫ÁâπÂæµËº∏ÂÖ•„ÄÇÊ≠§Â§ñÔºåKarSein Êé°Áî®ÂºïÂ∞éÂºèÁ¨¶ËôüËø¥Ê≠∏‰æÜËß£Ê±∫ KAN Âú®Ëá™ÁôºÂ≠∏Áøí‰πòÊ≥ïÈóú‰øÇÊôÇÊâÄÈù¢Ëá®ÁöÑÊåëÊà∞„ÄÇÂª£Ê≥õÁöÑÂØ¶È©óË≠âÊòé‰∫Ü KarSein ÁöÑÂçìË∂äÊïàËÉΩÔºåÂú®ÈÅãÁÆóË≤†ÊìîÊúÄÂ∞èÁöÑÊÉÖÊ≥Å‰∏ãÔºåÈÅîÂà∞‰∫ÜÈ°ØËëóÁöÑÈ†êÊ∏¨Ê∫ñÁ¢∫Â∫¶„ÄÇÊ≠§Â§ñÔºåKarSein ‰øùÊåÅÂº∑Â§ßÁöÑÊï¥È´îÂèØËß£ÈáãÊÄßÔºåÂêåÊôÇËÉΩÁßªÈô§Â§öÈ§òÁöÑÁâπÂæµÔºåÈÄ≤ËÄåÂΩ¢Êàê‰∏ÄÂÄãÁ®ÄÁñèÁöÑÁ∂≤Ë∑ØÁµêÊßã„ÄÇÈÄô‰∫õÂÑ™Èªû‰πüËÆì KarSein ÊàêÁÇ∫‰∏ÄÁ®ÆÊúâÂâçÈÄîÁöÑÊúâÊïàÊé®Ë´ñÊñπÊ≥ï„ÄÇ

##### **Beam Prediction based on Large Language Models**
2408.08707v1 by Yucheng Sheng, Kai Huang, Le Liang, Peng Liu, Shi Jin, Geoffrey Ye Li

Millimeter-wave (mmWave) communication is promising for next-generation
wireless networks but suffers from significant path loss, requiring extensive
antenna arrays and frequent beam training. Traditional deep learning models,
such as long short-term memory (LSTM), enhance beam tracking accuracy however
are limited by poor robustness and generalization. In this letter, we use large
language models (LLMs) to improve the robustness of beam prediction. By
converting time series data into text-based representations and employing the
Prompt-as-Prefix (PaP) technique for contextual enrichment, our approach
unleashes the strength of LLMs for time series forecasting. Simulation results
demonstrate that our LLM-based method offers superior robustness and
generalization compared to LSTM-based models, showcasing the potential of LLMs
in wireless communications.

ÊëòË¶ÅÔºöÊØ´Á±≥Ê≥¢ (mmWave) ÈÄöË®äÂ∞çÊñº‰∏ã‰∏Ä‰ª£ÁÑ°Á∑öÁ∂≤Ë∑Ø‰æÜË™™ÂâçÊôØÁúãÂ•ΩÔºå‰ΩÜÊúÉÈÅ≠ÂèóÈ°ØËëóÁöÑÈÄîÂæëÊêçÂ§±ÔºåÈúÄË¶ÅÂª£Ê≥õÁöÑÂ§©Á∑öÈô£ÂàóÂíåÈ†ªÁπÅÁöÑÊ≥¢ÊùüË®ìÁ∑¥„ÄÇÂÇ≥Áµ±Ê∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÔºå‰æãÂ¶ÇÈï∑Áü≠ÊúüË®òÊÜ∂ (LSTM)ÔºåÂ¢ûÂº∑‰∫ÜÊ≥¢ÊùüËøΩËπ§Ê∫ñÁ¢∫Â∫¶Ôºå‰ΩÜÂçªÂèóÂà∞‰ΩéÂÅ•Â£ØÊÄßÂíå‰∏ÄËà¨ÂåñÁöÑÈôêÂà∂„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ΩøÁî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰æÜÊîπÂñÑÊ≥¢ÊùüÈ†êÊ∏¨ÁöÑÂÅ•Â£ØÊÄß„ÄÇÈÄèÈÅéÂ∞áÊôÇÈñìÂ∫èÂàóË≥áÊñôËΩâÊèõÊàêÂü∫ÊñºÊñáÂ≠óÁöÑË°®Á§∫Ôºå‰∏¶Êé°Áî® Prompt-as-Prefix (PaP) ÊäÄË°ìÈÄ≤Ë°åËÑàÁµ°Ë±êÂØåÂåñÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÁôºÊèÆ‰∫Ü LLM Âú®ÊôÇÈñìÂ∫èÂàóÈ†êÊ∏¨ÊñπÈù¢ÁöÑÂÑ™Âã¢„ÄÇÊ®°Êì¨ÁµêÊûúË≠âÊòéÔºåËàáÂü∫Êñº LSTM ÁöÑÊ®°ÂûãÁõ∏ÊØîÔºåÊàëÂÄëÂü∫Êñº LLM ÁöÑÊñπÊ≥ïÊèê‰æõ‰∫ÜÂÑ™Áï∞ÁöÑÂÅ•Â£ØÊÄßÂíå‰∏ÄËà¨ÂåñÔºåÂ±ïÁ§∫‰∫Ü LLM Âú®ÁÑ°Á∑öÈÄöË®ä‰∏≠ÁöÑÊΩõÂäõ„ÄÇ

##### **Beyond the Hype: A dispassionate look at vision-language models in medical scenario**
2408.08704v1 by Yang Nan, Huichi Zhou, Xiaodan Xing, Guang Yang

Recent advancements in Large Vision-Language Models (LVLMs) have demonstrated
remarkable capabilities across diverse tasks, garnering significant attention
in AI communities. However, their performance and reliability in specialized
domains such as medicine remain insufficiently assessed. In particular, most
assessments over-concentrate in evaluating VLMs based on simple Visual Question
Answering (VQA) on multi-modality data, while ignoring the in-depth
characteristic of LVLMs. In this study, we introduce RadVUQA, a novel
Radiological Visual Understanding and Question Answering benchmark, to
comprehensively evaluate existing LVLMs. RadVUQA mainly validates LVLMs across
five dimensions: 1) Anatomical understanding, assessing the models' ability to
visually identify biological structures; 2) Multimodal comprehension, which
involves the capability of interpreting linguistic and visual instructions to
produce desired outcomes; 3) Quantitative and spatial reasoning, evaluating the
models' spatial awareness and proficiency in combining quantitative analysis
with visual and linguistic information; 4) Physiological knowledge, measuring
the models' capability to comprehend functions and mechanisms of organs and
systems; and 5) Robustness, which assesses the models' capabilities against
unharmonised and synthetic data. The results indicate that both generalized
LVLMs and medical-specific LVLMs have critical deficiencies with weak
multimodal comprehension and quantitative reasoning capabilities. Our findings
reveal the large gap between existing LVLMs and clinicians, highlighting the
urgent need for more robust and intelligent LVLMs. The code and dataset will be
available after the acceptance of this paper.

ÊëòË¶ÅÔºöËøëÊúüÂ§ßÂûãËßÜËßâËØ≠Ë®ÄÊ®°Âûã (LVLMs) ÁöÑËøõÊ≠•Â∑≤Â±ïÁ§∫‰∫ÜÂêÑÁßç‰ªªÂä°ÁöÑÈùûÂá°ËÉΩÂäõÔºåÂú®‰∫∫Â∑•Êô∫ËÉΩÁ§æÁæ§‰∏≠Â§áÂèóÂÖ≥Ê≥®„ÄÇÁÑ∂ËÄåÔºåÂÆÉ‰ª¨Âú®ÂåªÂ≠¶Á≠â‰∏ì‰∏öÈ¢ÜÂüüÁöÑÊïàËÉΩÂíåÂèØÈù†ÊÄß‰ªçÊú™ÂæóÂà∞ÂÖÖÂàÜËØÑ‰º∞„ÄÇÁâπÂà´ÊòØÔºåÂ§ßÂ§öÊï∞ËØÑ‰º∞ÈÉΩËøá‰∫éÈõÜ‰∏≠Âú®Âü∫‰∫éÂ§öÊ®°ÊÄÅÊï∞ÊçÆËøõË°åÁÆÄÂçïËßÜËßâÈóÆÁ≠î (VQA) Êù•ËØÑ‰º∞ VLMÔºåËÄåÂøΩÁï•‰∫Ü VLM ÁöÑÊ∑±ÂÖ•ÁâπÂæÅ„ÄÇÊú¨Á†îÁ©∂‰∏≠ÔºåÊàë‰ª¨ÂºïÂÖ•‰∫Ü RadVUQAÔºåËøôÊòØ‰∏Ä‰∏™Êñ∞È¢ñÁöÑÊîæÂ∞ÑËßÜËßâÁêÜËß£ÂíåÈóÆÁ≠îÂü∫ÂáÜÔºå‰ª•ÂÖ®Èù¢ËØÑ‰º∞Áé∞ÊúâÁöÑ VLM„ÄÇRadVUQA ‰∏ªË¶Å‰ªé‰∫î‰∏™Áª¥Â∫¶È™åËØÅ VLMÔºö1) Ëß£ÂâñÁêÜËß£ÔºåËØÑ‰º∞Ê®°ÂûãËßÜËßâËØÜÂà´ÁîüÁâ©ÁªìÊûÑÁöÑËÉΩÂäõÔºõ2) Â§öÊ®°ÊÄÅÁêÜËß£ÔºåÊ∂âÂèäËß£ÈáäËØ≠Ë®ÄÂíåËßÜËßâÊåá‰ª§‰ª•‰∫ßÁîüÈ¢ÑÊúüÁªìÊûúÁöÑËÉΩÂäõÔºõ3) ÂÆöÈáèÂíåÁ©∫Èó¥Êé®ÁêÜÔºåËØÑ‰º∞Ê®°ÂûãÁöÑÁ©∫Èó¥ÊÑèËØÜÂíåÁªìÂêàÂÆöÈáèÂàÜÊûê‰∏éËßÜËßâÂíåËØ≠Ë®Ä‰ø°ÊÅØÁöÑËÉΩÂäõÔºõ4) ÁîüÁêÜÁü•ËØÜÔºåË°°ÈáèÊ®°ÂûãÁêÜËß£Âô®ÂÆòÂíåÁ≥ªÁªüÂäüËÉΩÂíåÊú∫Âà∂ÁöÑËÉΩÂäõÔºõ5) È≤ÅÊ£íÊÄßÔºåËØÑ‰º∞Ê®°ÂûãÂØπ‰∏çÂíåË∞êÂíåÂêàÊàêÊï∞ÊçÆÁöÑÂ§ÑÁêÜËÉΩÂäõ„ÄÇÁªìÊûúË°®ÊòéÔºåÈÄöÁî® VLM ÂíåÂåªÂ≠¶‰∏ìÁî® VLM ÈÉΩÂ≠òÂú®‰∏•ÈáçÁöÑÁº∫Èô∑ÔºåÂ§öÊ®°ÊÄÅÁêÜËß£ÂíåÂÆöÈáèÊé®ÁêÜËÉΩÂäõËæÉÂº±„ÄÇÊàë‰ª¨ÁöÑÁ†îÁ©∂ÁªìÊûúÊè≠Á§∫‰∫ÜÁé∞Êúâ VLM Âíå‰∏¥Â∫äÂåªÁîü‰πãÈó¥Â≠òÂú®Â∑®Â§ßÂ∑ÆË∑ùÔºåÂº∫Ë∞É‰∫ÜÂØπÊõ¥Âº∫Â§ßÂíåÊõ¥Êô∫ËÉΩÁöÑ VLM ÁöÑËø´ÂàáÈúÄÊ±Ç„ÄÇÊú¨ÊñáË¢´Êé•ÂèóÂêéÔºå‰ª£Á†ÅÂíåÊï∞ÊçÆÈõÜÂ∞ÜÂèØ‰æõ‰ΩøÁî®„ÄÇ

##### **NFDI4DSO: Towards a BFO Compliant Ontology for Data Science**
2408.08698v1 by Genet Asefa Gesese, J√∂rg Waitelonis, Zongxiong Chen, Sonja Schimmler, Harald Sack

The NFDI4DataScience (NFDI4DS) project aims to enhance the accessibility and
interoperability of research data within Data Science (DS) and Artificial
Intelligence (AI) by connecting digital artifacts and ensuring they adhere to
FAIR (Findable, Accessible, Interoperable, and Reusable) principles. To this
end, this poster introduces the NFDI4DS Ontology, which describes resources in
DS and AI and models the structure of the NFDI4DS consortium. Built upon the
NFDICore ontology and mapped to the Basic Formal Ontology (BFO), this ontology
serves as the foundation for the NFDI4DS knowledge graph currently under
development.

ÊëòË¶ÅÔºöNFDI4DataScience (NFDI4DS) Ë®àÁï´Êó®Âú®ËóâÁî±ÈÄ£ÁµêÊï∏‰Ωç‰∫∫Â∑•Ë£ΩÂìÅÔºå‰∏¶Á¢∫‰øùÂÖ∂ÈÅµÂæ™ FAIRÔºàÂèØÂ∞ãÊâæÊÄß„ÄÅÂèØÂ≠òÂèñÊÄß„ÄÅÂèØ‰∫íÈÄöÊÄßÂíåÂèØÈáçË§á‰ΩøÁî®ÊÄßÔºâÂéüÂâáÔºå‰æÜÊèêÂçáË≥áÊñôÁßëÂ≠∏ (DS) Âíå‰∫∫Â∑•Êô∫ÊÖß (AI) ‰∏≠Á†îÁ©∂Ë≥áÊñôÁöÑÂèØÂ≠òÂèñÊÄßÂíå‰∫íÈÄöÊÄß„ÄÇÁÇ∫Ê≠§ÔºåÊµ∑Â†±‰ªãÁ¥π‰∫Ü NFDI4DS Êú¨‰ΩìÔºåÂÆÉÊèèËø∞‰∫Ü DS Âíå AI ‰∏≠ÁöÑË≥áÊ∫êÔºå‰∏¶Âª∫Êßã‰∫Ü NFDI4DS ËÅØÁõüÁöÑÁµêÊßã„ÄÇÊ≠§Êú¨‰ΩìÂª∫Á´ãÊñº NFDICore Êú¨‰Ωì‰πã‰∏äÔºå‰∏¶Â∞çÊáâÂà∞Âü∫Êú¨ÂΩ¢ÂºèÊú¨‰Ωì (BFO)Ôºå‰ΩúÁÇ∫ÁõÆÂâçÊ≠£Âú®ÈñãÁôºÁöÑ NFDI4DS Áü•Ë≠òÂúñË≠úÁöÑÂü∫Á§é„ÄÇ

##### **Turning Trash into Treasure: Accelerating Inference of Large Language Models with Token Recycling**
2408.08696v1 by Xianzhen Luo, Yixuan Wang, Qingfu Zhu, Zhiming Zhang, Xuanyu Zhang, Qing Yang, Dongliang Xu, Wanxiang Che

The rapid growth in the parameters of large language models (LLMs) has made
inference latency a fundamental bottleneck, limiting broader application of
LLMs. Speculative decoding represents a lossless approach to accelerate
inference through a guess-and-verify paradigm, leveraging the parallel
capabilities of modern hardware. Some speculative decoding methods rely on
additional structures to guess draft tokens, such as small models or
parameter-efficient architectures, which need extra training before use.
Alternatively, retrieval-based train-free techniques build libraries from
pre-existing corpora or by n-gram generation. However, they face challenges
like large storage requirements, time-consuming retrieval, and limited
adaptability. Observing that candidate tokens generated during the decoding
process are likely to reoccur in future sequences, we propose Token Recycling.
This approach stores candidate tokens in an adjacency matrix and employs a
breadth-first search (BFS)-like algorithm on the matrix to construct a draft
tree. The tree is then validated through tree attention. New candidate tokens
from the decoding process are then used to update the matrix. Token Recycling
requires \textless2MB of additional storage and achieves approximately 2x
speedup across all sizes of LLMs. It significantly outperforms existing
train-free methods by 30\% and even a training method by 25\%. It can be
directly applied to any existing LLMs and tasks without the need for
adaptation.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÂèÉÊï∏Âø´ÈÄüÂ¢ûÈï∑Ôºå‰ΩøÂæóÊé®Ë´ñÂª∂ÈÅ≤ÊàêÁÇ∫‰∏ÄÂÄãÊ†πÊú¨Áì∂È†∏ÔºåÈôêÂà∂‰∫Ü LLM ÁöÑÂª£Ê≥õÊáâÁî®„ÄÇÊé®Ê∏¨Ëß£Á¢º‰ª£Ë°®‰∫Ü‰∏ÄÁ®ÆÁÑ°ÊêçÂ§±ÁöÑÊñπÊ≥ïÔºåÂèØÈÄöÈÅéÁåúÊ∏¨ÂíåÈ©óË≠âÁØÑ‰æã‰æÜÂä†ÈÄüÊé®Ë´ñÔºåÂà©Áî®Áèæ‰ª£Á°¨È´îÁöÑ‰∏¶Ë°åÂäüËÉΩ„ÄÇ‰∏Ä‰∫õÊé®Ê∏¨Ëß£Á¢ºÊñπÊ≥ï‰æùË≥¥ÊñºÈ°çÂ§ñÁöÑÁµêÊßã‰æÜÁåúÊ∏¨ËçâÁ®øÊ®ôË®òÔºå‰æãÂ¶ÇÂ∞èÂûãÊ®°ÂûãÊàñÂèÉÊï∏È´òÊïàÊû∂ÊßãÔºåÈÄô‰∫õÊ®°ÂûãÂú®‰ΩøÁî®ÂâçÈúÄË¶ÅÈ°çÂ§ñË®ìÁ∑¥„ÄÇÊàñËÄÖÔºåÂü∫ÊñºÊ™¢Á¥¢ÁöÑÂÖçË®ìÁ∑¥ÊäÄË°ìÂæûÈ†êÂÖàÂ≠òÂú®ÁöÑË™ûÊñôÂ∫´ÊàñÈÄöÈÅé n-gram ÁîüÊàêÊßãÂª∫ÂáΩÂºèÂ∫´„ÄÇÁÑ∂ËÄåÔºå‰ªñÂÄëÈù¢Ëá®ËëóË´∏Â¶ÇÂ§ßÈáèÂÑ≤Â≠òÈúÄÊ±Ç„ÄÅËÄóÊôÇÁöÑÊ™¢Á¥¢ÂíåÊúâÈôêÁöÑÈÅ©ÊáâÊÄßÁ≠âÊåëÊà∞„ÄÇËßÄÂØüÂà∞Âú®Ëß£Á¢ºÈÅéÁ®ã‰∏≠Áî¢ÁîüÁöÑÂÄôÈÅ∏Ê®ôË®òÂæàÂèØËÉΩÂú®Êú™‰æÜÁöÑÂ∫èÂàó‰∏≠ÂÜçÊ¨°Âá∫ÁèæÔºåÊàëÂÄëÊèêÂá∫‰∫ÜÊ®ôË®òÂõûÊî∂„ÄÇÊ≠§ÊñπÊ≥ïÂ∞áÂÄôÈÅ∏Ê®ôË®òÂÑ≤Â≠òÂú®ÈÑ∞Êé•Áü©Èô£‰∏≠Ôºå‰∏¶Âú®Áü©Èô£‰∏äÊé°Áî®Âª£Â∫¶ÂÑ™ÂÖàÊêúÂ∞ã (BFS) È°û‰ººÊºîÁÆóÊ≥ï‰æÜÊßãÂª∫ËçâÁ®øÊ®π„ÄÇÁÑ∂ÂæåÈÄèÈÅéÊ®πÊ≥®ÊÑèÂäõÈ©óË≠âÊ®π„ÄÇÁÑ∂Âæå‰ΩøÁî®‰æÜËá™Ëß£Á¢ºÈÅéÁ®ãÁöÑÊñ∞ÂÄôÈÅ∏Ê®ôË®ò‰æÜÊõ¥Êñ∞Áü©Èô£„ÄÇÊ®ôË®òÂõûÊî∂ÈúÄË¶Å \textless2MB ÁöÑÈ°çÂ§ñÂÑ≤Â≠òÁ©∫ÈñìÔºå‰∏¶Âú®ÊâÄÊúâÂ§ßÂ∞èÁöÑ LLM ‰∏≠ÂØ¶ÁèæÂ§ßÁ¥Ñ 2 ÂÄçÁöÑÂä†ÈÄü„ÄÇÂÆÉÈ°ØËëóÂÑ™ÊñºÁèæÊúâÁöÑÂÖçË®ìÁ∑¥ÊñπÊ≥ï 30%ÔºåÁîöËá≥ÊØîË®ìÁ∑¥ÊñπÊ≥ïÂÑ™Áï∞ 25%„ÄÇÂÆÉÂèØ‰ª•Áõ¥Êé•ÊáâÁî®Êñº‰ªª‰ΩïÁèæÊúâÁöÑ LLM Âíå‰ªªÂãôÔºåËÄåÁÑ°ÈúÄÈÅ©Êáâ„ÄÇ

##### **Quantifying the Effectiveness of Student Organization Activities using Natural Language Processing**
2408.08694v1 by Lyberius Ennio F. Taruc, Arvin R. De La Cruz

Student extracurricular activities play an important role in enriching the
students' educational experiences. With the increasing popularity of Machine
Learning and Natural Language Processing, it becomes a logical step that
incorporating ML-NLP in improving extracurricular activities is a potential
focus of study in Artificial Intelligence (AI). This research study aims to
develop a machine learning workflow that will quantify the effectiveness of
student-organized activities based on student emotional responses using
sentiment analysis. The study uses the Bidirectional Encoder Representations
from Transformers (BERT) Large Language Model (LLM) called via the
pysentimiento toolkit, as a Transformer pipeline in Hugging Face. A sample data
set from Organization C, a Recognized Student Organization (RSO) of a higher
educational institute in the Philippines, College X, was used to develop the
workflow. The workflow consisted of data preprocessing, key feature selection,
LLM feature processing, and score aggregation, resulting in an Event Score for
each data set. The results show that the BERT LLM can also be used effectively
in analyzing sentiment beyond product reviews and post comments. For the
student affairs offices of educational institutions, this study can provide a
practical example of how NLP can be applied to real-world scenarios, showcasing
the potential impact of data-driven decision making.

ÊëòË¶ÅÔºöÂ≠∏ÁîüË™≤Â§ñÊ¥ªÂãïÂú®Ë±êÂØåÂ≠∏ÁîüÁöÑÊïôËÇ≤Á∂ìÈ©ó‰∏≠ÊâÆÊºîËëóÈáçË¶ÅÁöÑËßíËâ≤„ÄÇÈö®ËëóÊ©üÂô®Â≠∏ÁøíÂíåËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜÁöÑÊôÆÂèäÔºåÂ∞á ML-NLP ËûçÂÖ•Ë™≤Â§ñÊ¥ªÂãïÁöÑÊîπÂñÑ‰∏≠ÊàêÁÇ∫‰∫∫Â∑•Êô∫ËÉΩ (AI) Á†îÁ©∂ÁöÑÊΩõÂú®ÈáçÈªûÔºåÈÄôÊòØ‰∏ÄÂÄãÂêà‰πéÈÇèËºØÁöÑÊ≠•È©ü„ÄÇÊú¨Á†îÁ©∂Êó®Âú®ÈñãÁôº‰∏ÄÁ®ÆÊ©üÂô®Â≠∏ÁøíÂ∑•‰ΩúÊµÅÁ®ãÔºåÂÆÉÂ∞áÊ†πÊìöÂ≠∏ÁîüÁöÑÊÉÖÁ∑íÂèçÊáâ‰ΩøÁî®ÊÉÖÁ∑íÂàÜÊûê‰æÜÈáèÂåñÂ≠∏ÁîüÁµÑÁπîÊ¥ªÂãïÁöÑÊúâÊïàÊÄß„ÄÇÊú¨Á†îÁ©∂‰ΩøÁî®ÈÄèÈÅé Hugging Face ‰∏≠ÁöÑ pysentimiento Â∑•ÂÖ∑ÂåÖÂëºÂè´ÁöÑ Transformer Â§ßË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÈõôÂêëÁ∑®Á¢ºÂô®Ë°®ÂæµÔºå‰ΩúÁÇ∫ Transformer ÁÆ°Á∑ö„ÄÇ‰æÜËá™ÁµÑÁπî C ÁöÑÁØÑ‰æãË≥áÊñôÈõÜÔºåËè≤ÂæãË≥ìÈ´òÁ≠âÊïôËÇ≤Ê©üÊßãÁöÑÂÖ¨Ë™çÂ≠∏ÁîüÁµÑÁπî (RSO)ÔºåÂ§ßÂ≠∏ XÔºåÁî®ÊñºÈñãÁôºÂ∑•‰ΩúÊµÅÁ®ã„ÄÇÂ∑•‰ΩúÊµÅÁ®ãÂåÖÂê´Ë≥áÊñôÂâçËôïÁêÜ„ÄÅÈóúÈçµÁâπÂæµÈÅ∏Âèñ„ÄÅLLM ÁâπÂæµËôïÁêÜÂíåÂàÜÊï∏ÂΩôÁ∏ΩÔºåÁî¢ÁîüÊØèÂÄãË≥áÊñôÈõÜÁöÑ‰∫ã‰ª∂ÂàÜÊï∏„ÄÇÁµêÊûúÈ°ØÁ§∫ÔºåBERT LLM ‰πüËÉΩÊúâÊïàÁî®ÊñºÂàÜÊûêÁî¢ÂìÅË©ïË´ñÂíåÊñáÁ´†ÁïôË®Ä‰ª•Â§ñÁöÑÊÉÖÁ∑í„ÄÇÂ∞çÊñºÊïôËÇ≤Ê©üÊßãÁöÑÂ≠∏Áîü‰∫ãÂãôËæ¶ÂÖ¨ÂÆ§ÔºåÊú¨Á†îÁ©∂ÂèØ‰ª•Êèê‰æõ‰∏ÄÂÄãÂØ¶ÈöõÁØÑ‰æãÔºåË™™ÊòéÂ¶Ç‰ΩïÂ∞á NLP ÊáâÁî®ÊñºÂØ¶ÈöõÊÉÖÊ≥ÅÔºåÂ±ïÁ§∫Ë≥áÊñôÈ©ÖÂãïÊ±∫Á≠ñÁöÑÊΩõÂú®ÂΩ±Èüø„ÄÇ

##### **Med-PMC: Medical Personalized Multi-modal Consultation with a Proactive Ask-First-Observe-Next Paradigm**
2408.08693v1 by Hongcheng Liu, Yusheng Liao, Siqv Ou, Yuhao Wang, Heyang Liu, Yanfeng Wang, Yu Wang

The application of the Multi-modal Large Language Models (MLLMs) in medical
clinical scenarios remains underexplored. Previous benchmarks only focus on the
capacity of the MLLMs in medical visual question-answering (VQA) or report
generation and fail to assess the performance of the MLLMs on complex clinical
multi-modal tasks. In this paper, we propose a novel Medical Personalized
Multi-modal Consultation (Med-PMC) paradigm to evaluate the clinical capacity
of the MLLMs. Med-PMC builds a simulated clinical environment where the MLLMs
are required to interact with a patient simulator to complete the multi-modal
information-gathering and decision-making task. Specifically, the patient
simulator is decorated with personalized actors to simulate diverse patients in
real scenarios. We conduct extensive experiments to access 12 types of MLLMs,
providing a comprehensive view of the MLLMs' clinical performance. We found
that current MLLMs fail to gather multimodal information and show potential
bias in the decision-making task when consulted with the personalized patient
simulators. Further analysis demonstrates the effectiveness of Med-PMC, showing
the potential to guide the development of robust and reliable clinical MLLMs.
Code and data are available at https://github.com/LiuHC0428/Med-PMC.

ÊëòË¶ÅÔºöÂ§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°Âûã (MLLM) Âú®ÂåªÂ≠¶‰∏¥Â∫äÊÉÖÂ¢É‰∏≠ÁöÑÂ∫îÁî®‰ªçÊú™ÂæóÂà∞ÂÖÖÂàÜÊé¢Á¥¢„ÄÇÂÖàÂâçÁöÑÂü∫ÂáÜ‰ªÖÂÖ≥Ê≥® MLLM Âú®ÂåªÂ≠¶ËßÜËßâÈóÆÁ≠î (VQA) ÊàñÊä•ÂëäÁîüÊàê‰∏≠ÁöÑËÉΩÂäõÔºåËÄåÊú™ËÉΩËØÑ‰º∞ MLLM Âú®Â§çÊùÇ‰∏¥Â∫äÂ§öÊ®°ÊÄÅ‰ªªÂä°‰∏≠ÁöÑË°®Áé∞„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏Ä‰∏™Êñ∞È¢ñÁöÑÂåªÂ≠¶‰∏™ÊÄßÂåñÂ§öÊ®°ÊÄÅÂí®ËØ¢ (Med-PMC) ËåÉ‰æãÊù•ËØÑ‰º∞ MLLM ÁöÑ‰∏¥Â∫äËÉΩÂäõ„ÄÇMed-PMC ÊûÑÂª∫‰∫Ü‰∏Ä‰∏™Ê®°ÊãüÁöÑ‰∏¥Â∫äÁéØÂ¢ÉÔºåÂÖ∂‰∏≠ MLLM ÈúÄË¶Å‰∏éÊÇ£ËÄÖÊ®°ÊãüÂô®‰∫§‰∫í‰ª•ÂÆåÊàêÂ§öÊ®°ÊÄÅ‰ø°ÊÅØÊî∂ÈõÜÂíåÂÜ≥Á≠ñ‰ªªÂä°„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåÊÇ£ËÄÖÊ®°ÊãüÂô®Ë£ÖÈ•∞Êúâ‰∏™ÊÄßÂåñËßíËâ≤Ôºå‰ª•Ê®°ÊãüÁúüÂÆûÂú∫ÊôØ‰∏≠ÁöÑ‰∏çÂêåÊÇ£ËÄÖ„ÄÇÊàë‰ª¨ËøõË°å‰∫ÜÂπøÊ≥õÁöÑÂÆûÈ™åÊù•ËÆøÈóÆ 12 ÁßçÁ±ªÂûãÁöÑ MLLMÔºåÂÖ®Èù¢‰∫ÜËß£ MLLM ÁöÑ‰∏¥Â∫äË°®Áé∞„ÄÇÊàë‰ª¨ÂèëÁé∞ÔºåÂΩìÂâçÁöÑ MLLM Êó†Ê≥ïÊî∂ÈõÜÂ§öÊ®°ÊÄÅ‰ø°ÊÅØÔºåÂπ∂‰∏îÂú®‰∏é‰∏™ÊÄßÂåñÊÇ£ËÄÖÊ®°ÊãüÂô®ÂçèÂïÜÊó∂Âú®ÂÜ≥Á≠ñ‰ªªÂä°‰∏≠Ë°®Áé∞Âá∫ÊΩúÂú®ÁöÑÂÅèÂ∑Æ„ÄÇËøõ‰∏ÄÊ≠•ÁöÑÂàÜÊûêËØÅÊòé‰∫Ü Med-PMC ÁöÑÊúâÊïàÊÄßÔºåÊòæÁ§∫‰∫ÜÊåáÂØºÁ®≥ÂÅ•‰∏îÂèØÈù†ÁöÑ‰∏¥Â∫ä MLLM ÂºÄÂèëÁöÑÊΩúÂäõ„ÄÇ‰ª£Á†ÅÂíåÊï∞ÊçÆÂèØÂú® https://github.com/LiuHC0428/Med-PMC Ëé∑Âæó„ÄÇ

##### **The Fellowship of the LLMs: Multi-Agent Workflows for Synthetic Preference Optimization Dataset Generation**
2408.08688v1 by Samee Arif, Sualeha Farid, Abdul Hameed Azeemi, Awais Athar, Agha Ali Raza

This paper presents and evaluates multi-agent workflows for synthetic
Preference Optimization (PO) dataset generation. PO dataset generation requires
two modules: (1) response evaluation, and (2) response generation. In the
response evaluation module, the responses from Large Language Models (LLMs) are
evaluated and ranked - a task typically carried out by human annotators that we
automate using LLMs. We assess the response evaluation module in a 2 step
process. In step 1, we assess LLMs as evaluators using three distinct prompting
strategies. In step 2, we apply the winning prompting strategy to compare the
performance of LLM-as-a-Judge, LLMs-as-a-Jury, and LLM Debate. In each step, we
use inter-rater agreement using Cohen's Kappa between human annotators and
LLMs. For the response generation module, we compare different configurations
for the LLM Feedback Loop using the identified LLM evaluator configuration. We
use the win rate (the fraction of times a generation framework is selected as
the best by an LLM evaluator) to determine the best multi-agent configuration
for generation. After identifying the best configurations for both modules, we
use models from the GPT, Gemma, and Llama families to generate our PO datasets
using the above pipeline. We generate two types of PO datasets, one to improve
the generation capabilities of individual LLM and the other to improve the
multi-agent workflow. Our evaluation shows that GPT-4o-as-a-Judge is more
consistent across datasets when the candidate responses do not include
responses from the GPT family. Additionally, we find that the LLM Feedback
Loop, with Llama as the generator and Gemma as the reviewer, achieves a notable
71.8% and 73.8% win rate over single-agent Llama and Gemma, respectively.

ÊëòË¶ÅÔºöÊú¨ÊñáÊèêÂá∫‰∏¶Ë©ï‰º∞Áî®ÊñºÂêàÊàêÂÅèÂ•ΩÊúÄ‰Ω≥Âåñ (PO) Ë≥áÊñôÈõÜÁîüÊàêÁöÑ‰ª£ÁêÜ‰∫∫Â∑•‰ΩúÊµÅÁ®ã„ÄÇPO Ë≥áÊñôÈõÜÁîüÊàêÈúÄË¶ÅÂÖ©ÂÄãÊ®°ÁµÑÔºö(1) ÂõûÊáâË©ï‰º∞Ôºå‰ª•Âèä (2) ÂõûÊáâÁîüÊàê„ÄÇÂú®ÂõûÊáâË©ï‰º∞Ê®°ÁµÑ‰∏≠ÔºåÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÂõûÊáâÊúÉÁ∂ìÈÅéË©ï‰º∞ÂíåÊéíÂêçÔºåÈÄôÈ†Ö‰ªªÂãôÈÄöÂ∏∏Áî±ÊàëÂÄë‰ΩøÁî® LLM Ëá™ÂãïÂåñÁöÑ‰∫∫È°ûË®ªËß£Âì°Âü∑Ë°å„ÄÇÊàëÂÄë‰ΩøÁî® 2 Ê≠•È©üÊµÅÁ®ãË©ï‰º∞ÂõûÊáâË©ï‰º∞Ê®°ÁµÑ„ÄÇÂú®Ê≠•È©ü 1 ‰∏≠ÔºåÊàëÂÄë‰ΩøÁî®‰∏âÂÄã‰∏çÂêåÁöÑÊèêÁ§∫Á≠ñÁï•Ë©ï‰º∞ LLM ‰ΩúÁÇ∫Ë©ï‰º∞Âì°„ÄÇÂú®Ê≠•È©ü 2 ‰∏≠ÔºåÊàëÂÄëÂ•óÁî®Áç≤ÂãùÁöÑÊèêÁ§∫Á≠ñÁï•‰æÜÊØîËºÉ LLM-as-a-Judge„ÄÅLLM-as-a-Jury Âíå LLM Debate ÁöÑÊïàËÉΩ„ÄÇÂú®ÊØèÂÄãÊ≠•È©ü‰∏≠ÔºåÊàëÂÄë‰ΩøÁî®‰∫∫È°ûË®ªËß£Âì°Âíå LLM ‰πãÈñìÁöÑ Cohen's Kappa ‰æÜ‰ΩøÁî®Ë©ïÂàÜËÄÖÈñì‰∏ÄËá¥ÊÄß„ÄÇÂ∞çÊñºÂõûÊáâÁîüÊàêÊ®°ÁµÑÔºåÊàëÂÄë‰ΩøÁî®Â∑≤Ë≠òÂà•ÁöÑ LLM Ë©ï‰º∞Âì°Ë®≠ÂÆöÊØîËºÉ LLM ÂõûÈ•ãËø¥Ë∑ØÁöÑ‰∏çÂêåË®≠ÂÆö„ÄÇÊàëÂÄë‰ΩøÁî®Áç≤ÂãùÁéáÔºàLLM Ë©ï‰º∞Âì°ÈÅ∏ÊìáÁîüÊàêÊû∂ÊßãÁÇ∫ÊúÄ‰Ω≥ÁöÑÊ¨°Êï∏ÊØî‰æãÔºâ‰æÜÊ±∫ÂÆöÊúÄ‰Ω≥ÁöÑÁîüÊàê‰ª£ÁêÜ‰∫∫Ë®≠ÂÆö„ÄÇÂú®ÊâæÂá∫ÂÖ©ÂÄãÊ®°ÁµÑÁöÑÊúÄ‰Ω≥Ë®≠ÂÆöÂæåÔºåÊàëÂÄë‰ΩøÁî® GPT„ÄÅGemma Âíå Llama ÂÆ∂ÊóèÁöÑÊ®°Âûã‰æÜ‰ΩøÁî®‰∏äËø∞ÁÆ°Á∑öÁîüÊàêÊàëÂÄëÁöÑ PO Ë≥áÊñôÈõÜ„ÄÇÊàëÂÄëÁîüÊàê‰∫ÜÂÖ©Á®Æ PO Ë≥áÊñôÈõÜÔºå‰∏ÄÁ®ÆÁî®ÊñºÊèêÂçáÂÄãÂà• LLM ÁöÑÁîüÊàêËÉΩÂäõÔºåÂè¶‰∏ÄÁ®ÆÁî®ÊñºÊèêÂçá‰ª£ÁêÜ‰∫∫Â∑•‰ΩúÊµÅÁ®ã„ÄÇÊàëÂÄëÁöÑË©ï‰º∞È°ØÁ§∫ÔºåÁï∂ÂÄôÈÅ∏ÂõûÊáâ‰∏çÂåÖÂê´ GPT ÂÆ∂ÊóèÁöÑÂõûÊáâÊôÇÔºåGPT-4o-as-a-Judge Âú®‰∏çÂêåË≥áÊñôÈõÜ‰πãÈñìÁöÑ‰∏ÄËá¥ÊÄßËºÉÈ´ò„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁôºÁèæ LLM ÂõûÈ•ãËø¥Ë∑ØÔºàÁî± Llama ‰ΩúÁÇ∫ÁîüÊàêÂô®ÔºåGemma ‰ΩúÁÇ∫ÂØ©Èñ±ËÄÖÔºâÂàÜÂà•Â∞çÂñÆ‰∏Ä‰ª£ÁêÜ‰∫∫ Llama Âíå Gemma ÈÅîÂà∞‰∫ÜÈ°ØËëóÁöÑ 71.8% Âíå 73.8% Áç≤ÂãùÁéá„ÄÇ

##### **SC-Rec: Enhancing Generative Retrieval with Self-Consistent Reranking for~Sequential Recommendation**
2408.08686v1 by Tongyoung Kim, Soojin Yoon, Seongku Kang, Jinyoung Yeo, Dongha Lee

Language Models (LMs) are increasingly employed in recommendation systems due
to their advanced language understanding and generation capabilities. Recent
recommender systems based on generative retrieval have leveraged the
inferential abilities of LMs to directly generate the index tokens of the next
item, based on item sequences within the user's interaction history. Previous
studies have mostly focused on item indices based solely on textual semantic or
collaborative information. However, although the standalone effectiveness of
these aspects has been demonstrated, the integration of this information has
remained unexplored. Our in-depth analysis finds that there is a significant
difference in the knowledge captured by the model from heterogeneous item
indices and diverse input prompts, which can have a high potential for
complementarity. In this paper, we propose SC-Rec, a unified recommender system
that learns diverse preference knowledge from two distinct item indices and
multiple prompt templates. Furthermore, SC-Rec adopts a novel reranking
strategy that aggregates a set of ranking results, inferred based on different
indices and prompts, to achieve the self-consistency of the model. Our
empirical evaluation on three real-world datasets demonstrates that SC-Rec
considerably outperforms the state-of-the-art methods for sequential
recommendation, effectively incorporating complementary knowledge from varied
outputs of the model.

ÊëòË¶ÅÔºöË™ûË®ÄÊ®°ÂûãÔºàLMÔºâÁî±ÊñºÂÖ∂ÂÖàÈÄ≤ÁöÑË™ûË®ÄÁêÜËß£ÂíåÁîüÊàêËÉΩÂäõÔºåÂú®Êé®Ëñ¶Á≥ªÁµ±‰∏≠Ë∂ä‰æÜË∂äÂª£Ê≥õÂú∞‰ΩøÁî®„ÄÇÊúÄËøëÂü∫ÊñºÁîüÊàêÂºèÊ™¢Á¥¢ÁöÑÊé®Ëñ¶Á≥ªÁµ±Âà©Áî®‰∫Ü LM ÁöÑÊé®ÁêÜËÉΩÂäõÔºåÊ†πÊìö‰ΩøÁî®ËÄÖ‰∫íÂãïÊ≠∑Âè≤‰∏≠ÁöÑÈ†ÖÁõÆÂ∫èÂàóÁõ¥Êé•ÁîüÊàê‰∏ã‰∏ÄÂÄãÈ†ÖÁõÆÁöÑÁ¥¢ÂºïÊ®ôË®ò„ÄÇÂÖàÂâçÁöÑÁ†îÁ©∂Â§ßÂ§öÈõÜ‰∏≠ÊñºÂÉÖÂü∫ÊñºÊñáÊú¨Ë™ûÁæ©ÊàñÂçî‰ΩúË≥áË®äÁöÑÈ†ÖÁõÆÁ¥¢Âºï„ÄÇÁÑ∂ËÄåÔºåÂÑòÁÆ°ÈÄô‰∫õÊñπÈù¢ÁöÑÁç®Á´ãÊúâÊïàÊÄßÂ∑≤Á∂ìÂæóÂà∞Ë≠âÂØ¶Ôºå‰ΩÜÈÄô‰∫õË≥áË®äÁöÑÊï¥Âêà‰ªçÊú™ÂæóÂà∞Êé¢Ë®é„ÄÇÊàëÂÄëÁöÑÊ∑±ÂÖ•ÂàÜÊûêÁôºÁèæÔºåÊ®°ÂûãÂæûÁï∞Ë≥™È†ÖÁõÆÁ¥¢ÂºïÂíåÂ§öÊ®£ÂåñËº∏ÂÖ•ÊèêÁ§∫‰∏≠Êì∑ÂèñÁöÑÁü•Ë≠òÂ≠òÂú®È°ØËëóÂ∑ÆÁï∞ÔºåÈÄôÂÖ∑ÊúâÂæàÈ´òÁöÑ‰∫íË£úÊÄß„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫ SC-RecÔºåÈÄôÊòØ‰∏ÄÂÄãÁµ±‰∏ÄÁöÑÊé®Ëñ¶Á≥ªÁµ±ÔºåÂÆÉÂæûÂÖ©ÂÄã‰∏çÂêåÁöÑÈ†ÖÁõÆÁ¥¢ÂºïÂíåÂ§öÂÄãÊèêÁ§∫ÁØÑÊú¨‰∏≠Â≠∏ÁøíÂ§öÊ®£ÂåñÁöÑÂÅèÂ•ΩÁü•Ë≠ò„ÄÇÊ≠§Â§ñÔºåSC-Rec Êé°Áî®‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÈáçÊñ∞ÊéíÂ∫èÁ≠ñÁï•ÔºåÂÆÉÂΩôÁ∏Ω‰∫Ü‰∏ÄÁµÑÂü∫Êñº‰∏çÂêåÁ¥¢ÂºïÂíåÊèêÁ§∫Êé®Êñ∑ÁöÑÊéíÂ∫èÁµêÊûúÔºå‰ª•ÂØ¶ÁèæÊ®°ÂûãÁöÑËá™Ê¥ΩÊÄß„ÄÇÊàëÂÄëÂ∞ç‰∏âÂÄãÁúüÂØ¶‰∏ñÁïåË≥áÊñôÈõÜÁöÑÂØ¶Ë≠âË©ï‰º∞Ë°®ÊòéÔºåSC-Rec Âú®Â∫èÂàóÊé®Ëñ¶ÊñπÈù¢È°ØËëóÂÑ™ÊñºÊúÄÂÖàÈÄ≤ÁöÑÊñπÊ≥ïÔºåÊúâÊïàÂú∞Êï¥Âêà‰∫ÜÊ®°ÂûãÂêÑÁ®ÆËº∏Âá∫ÁöÑ‰∫íË£úÁü•Ë≠ò„ÄÇ

##### **Can Large Language Models Improve the Adversarial Robustness of Graph Neural Networks?**
2408.08685v1 by Zhongjian Zhang, Xiao Wang, Huichi Zhou, Yue Yu, Mengmei Zhang, Cheng Yang, Chuan Shi

Graph neural networks (GNNs) are vulnerable to adversarial perturbations,
especially for topology attacks, and many methods that improve the robustness
of GNNs have received considerable attention. Recently, we have witnessed the
significant success of large language models (LLMs), leading many to explore
the great potential of LLMs on GNNs. However, they mainly focus on improving
the performance of GNNs by utilizing LLMs to enhance the node features.
Therefore, we ask: Will the robustness of GNNs also be enhanced with the
powerful understanding and inference capabilities of LLMs? By presenting the
empirical results, we find that despite that LLMs can improve the robustness of
GNNs, there is still an average decrease of 23.1% in accuracy, implying that
the GNNs remain extremely vulnerable against topology attack. Therefore,
another question is how to extend the capabilities of LLMs on graph adversarial
robustness. In this paper, we propose an LLM-based robust graph structure
inference framework, LLM4RGNN, which distills the inference capabilities of
GPT-4 into a local LLM for identifying malicious edges and an LM-based edge
predictor for finding missing important edges, so as to recover a robust graph
structure. Extensive experiments demonstrate that LLM4RGNN consistently
improves the robustness across various GNNs. Even in some cases where the
perturbation ratio increases to 40%, the accuracy of GNNs is still better than
that on the clean graph.

ÊëòË¶ÅÔºöÂúñÂΩ¢Á•ûÁ∂ìÁ∂≤Ë∑Ø (GNN) ÂÆπÊòìÂèóÂà∞Â∞çÊäóÊÄßÊìæÂãïÁöÑÂΩ±ÈüøÔºå
ÁâπÂà•ÊòØÊãìÊí≤ÊîªÊìäÔºåË®±Â§öÊîπÂñÑ GNN È≠ØÊ£íÊÄßÁöÑÊñπÊ≥ïÈÉΩÂÇôÂèóÈóúÊ≥®„ÄÇÊúÄËøëÔºåÊàëÂÄëË¶ãË≠â‰∫ÜÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÈ°ØËëóÊàêÂäüÔºåÂ∞éËá¥Ë®±Â§ö‰∫∫Êé¢Á¥¢ LLM Âú® GNN ‰∏äÁöÑÂ∑®Â§ßÊΩõÂäõ„ÄÇÁÑ∂ËÄåÔºå‰ªñÂÄë‰∏ªË¶ÅÂ∞àÊ≥®ÊñºÂà©Áî® LLM Â¢ûÂº∑ÁØÄÈªûÁâπÂæµ‰æÜÊîπÂñÑ GNN ÁöÑÊïàËÉΩ„ÄÇ
Âõ†Ê≠§ÔºåÊàëÂÄëÂïèÔºöLLM Âº∑Â§ßÁöÑÁêÜËß£ÂíåÊé®ÁêÜËÉΩÂäõÊòØÂê¶‰πüÊúÉÂ¢ûÂº∑ GNN ÁöÑÈ≠ØÊ£íÊÄßÔºüÈÄèÈÅéÂëàÁèæÂØ¶Ë≠âÁµêÊûúÔºåÊàëÂÄëÁôºÁèæÂÑòÁÆ° LLM ÂèØ‰ª•ÊîπÂñÑ GNN ÁöÑÈ≠ØÊ£íÊÄßÔºå‰ΩÜÊ∫ñÁ¢∫Â∫¶‰ªçÂπ≥Âùá‰∏ãÈôç 23.1%ÔºåÈÄôË°®Á§∫ GNN ‰ªçÁÑ∂Ê•µÂÆπÊòìÂèóÂà∞ÊãìÊí≤ÊîªÊìä„ÄÇÂõ†Ê≠§ÔºåÂè¶‰∏ÄÂÄãÂïèÈ°åÊòØÂ¶Ç‰ΩïÊì¥Â±ï LLM Âú®ÂúñÂΩ¢Â∞çÊäóÈ≠ØÊ£íÊÄß‰∏äÁöÑËÉΩÂäõ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÂü∫Êñº LLM ÁöÑÈ≠ØÊ£íÂúñÂΩ¢ÁµêÊßãÊé®ÁêÜÊ°ÜÊû∂ LLM4RGNNÔºåÂÆÉÂ∞á GPT-4 ÁöÑÊé®ÁêÜËÉΩÂäõÊèêÁÖâÊàê‰∏ÄÂÄãÁî®ÊñºË≠òÂà•ÊÉ°ÊÑèÈÇäÁ∑£ÁöÑÊú¨Âú∞ LLMÔºå‰ª•Âèä‰∏ÄÂÄãÁî®ÊñºÂ∞ãÊâæÈÅ∫Â§±ÈáçË¶ÅÈÇäÁ∑£ÁöÑÂü∫Êñº LM ÁöÑÈÇäÁ∑£È†êÊ∏¨Âô®Ôºå‰ª•‰æøÊÅ¢Âæ©‰∏ÄÂÄãÈ≠ØÊ£íÁöÑÂúñÂΩ¢ÁµêÊßã„ÄÇÂª£Ê≥õÁöÑÂØ¶È©óË≠âÊòéÔºåLLM4RGNN ÊåÅÁ∫åÊîπÂñÑÂêÑÁ®Æ GNN ÁöÑÈ≠ØÊ£íÊÄß„ÄÇÂç≥‰ΩøÂú®Êüê‰∫õÊìæÂãïÁéáÂ¢ûÂä†Âà∞ 40% ÁöÑÊÉÖÊ≥Å‰∏ãÔºåGNN ÁöÑÊ∫ñÁ¢∫Â∫¶‰ªçÁÑ∂ÂÑ™Êñº‰πæÊ∑®ÂúñÂΩ¢„ÄÇ

##### **LLM-PCGC: Large Language Model-based Point Cloud Geometry Compression**
2408.08682v1 by Yuqi Ye, Wei Gao

The key to effective point cloud compression is to obtain a robust context
model consistent with complex 3D data structures. Recently, the advancement of
large language models (LLMs) has highlighted their capabilities not only as
powerful generators for in-context learning and generation but also as
effective compressors. These dual attributes of LLMs make them particularly
well-suited to meet the demands of data compression. Therefore, this paper
explores the potential of using LLM for compression tasks, focusing on lossless
point cloud geometry compression (PCGC) experiments. However, applying LLM
directly to PCGC tasks presents some significant challenges, i.e., LLM does not
understand the structure of the point cloud well, and it is a difficult task to
fill the gap between text and point cloud through text description, especially
for large complicated and small shapeless point clouds. To address these
problems, we introduce a novel architecture, namely the Large Language
Model-based Point Cloud Geometry Compression (LLM-PCGC) method, using LLM to
compress point cloud geometry information without any text description or
aligning operation. By utilizing different adaptation techniques for
cross-modality representation alignment and semantic consistency, including
clustering, K-tree, token mapping invariance, and Low Rank Adaptation (LoRA),
the proposed method can translate LLM to a compressor/generator for point
cloud. To the best of our knowledge, this is the first structure to employ LLM
as a compressor for point cloud data. Experiments demonstrate that the LLM-PCGC
outperforms the other existing methods significantly, by achieving -40.213% bit
rate reduction compared to the reference software of MPEG Geometry-based Point
Cloud Compression (G-PCC) standard, and by achieving -2.267% bit rate reduction
compared to the state-of-the-art learning-based method.

ÊëòË¶ÅÔºöË¶ÅÊúâÊïàÂ£ìÁ∏ÆÈªûÈõ≤ÔºåÈóúÈçµÂú®ÊñºÂèñÂæóËàáË§áÈõú 3D Ë≥áÊñôÁµêÊßã‰∏ÄËá¥ÁöÑÁ©©ÂÅ•ÊÉÖÂ¢ÉÊ®°Âûã„ÄÇÊúÄËøëÔºåÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÈÄ≤Â±ïÁ™ÅÈ°ØÂá∫ÂÆÉÂÄë‰∏çÂÉÖ‰ΩúÁÇ∫Âº∑Â§ßÁöÑÁî¢ÁîüÂô®ÔºåÂèØÁî®ÊñºÊÉÖÂ¢ÉÂ≠∏ÁøíÂíåÁî¢ÁîüÔºåÈÇÑËÉΩ‰ΩúÁÇ∫ÊúâÊïàÁöÑÂ£ìÁ∏ÆÂô®„ÄÇLLM ÁöÑÈÄô‰∫õÈõôÈáçÂ±¨ÊÄß‰ΩøÂÆÉÂÄëÁâπÂà•ÈÅ©ÂêàÊªøË∂≥Ë≥áÊñôÂ£ìÁ∏ÆÁöÑÈúÄÊ±Ç„ÄÇÂõ†Ê≠§ÔºåÊú¨ÊñáÊé¢Ë®é‰∫Ü‰ΩøÁî® LLM Âü∑Ë°åÂ£ìÁ∏Æ‰ªªÂãôÁöÑÊΩõÂäõÔºåÈáçÈªûÂú®ÊñºÁÑ°ÊêçÈªûÈõ≤Âπæ‰ΩïÂ£ìÁ∏Æ (PCGC) ÂØ¶È©ó„ÄÇÁÑ∂ËÄåÔºåÂ∞á LLM Áõ¥Êé•ÊáâÁî®Êñº PCGC ‰ªªÂãôÊúÉÁî¢Áîü‰∏Ä‰∫õÈáçÂ§ßÊåëÊà∞Ôºå‰æãÂ¶Ç LLM ‰∏ç‰∫ÜËß£ÈªûÈõ≤ÁµêÊßãÔºåËÄå‰∏îÈÄèÈÅéÊñáÂ≠óÊèèËø∞‰æÜÂ°´Ë£úÊñáÂ≠óÂíåÈªûÈõ≤‰πãÈñìÁöÑÂ∑ÆË∑ùÊòØ‰∏ÄÈ†ÖÂõ∞Èõ£ÁöÑ‰ªªÂãôÔºåÁâπÂà•ÊòØÂ∞çÊñºÂ§ßÂûãË§áÈõú‰∏îÁÑ°ÂÆöÂΩ¢ÁöÑÂ∞èÈªûÈõ≤„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÂïèÈ°åÔºåÊàëÂÄëÂºïÈÄ≤‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÊû∂ÊßãÔºåÂç≥Âü∫ÊñºÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÁöÑÈªûÈõ≤Âπæ‰ΩïÂ£ìÁ∏Æ (LLM-PCGC) ÊñπÊ≥ïÔºå‰ΩøÁî® LLM Â£ìÁ∏ÆÈªûÈõ≤Âπæ‰ΩïË≥áË®äÔºåËÄåÁÑ°ÈúÄ‰ªª‰ΩïÊñáÂ≠óÊèèËø∞ÊàñÂ∞çÈΩäÊìç‰Ωú„ÄÇÈÄèÈÅé‰ΩøÁî®‰∏çÂêåÁöÑÈÅ©ÊáâÊäÄË°ì‰æÜÈÄ≤Ë°åË∑®Ê®°ÊÖãË°®Á§∫Â∞çÈΩäÂíåË™ûÊÑè‰∏ÄËá¥ÊÄßÔºåÂåÖÊã¨ÂàÜÁæ§„ÄÅK Ê®π„ÄÅÊ®ôË®òÂ∞çÊáâ‰∏çËÆäÊÄßÂíå‰ΩéÁß©ÈÅ©Êáâ (LoRA)ÔºåÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÂèØ‰ª•Â∞á LLM ËΩâÊèõÁÇ∫ÈªûÈõ≤ÁöÑÂ£ìÁ∏ÆÂô®/Áî¢ÁîüÂô®„ÄÇÊìöÊàëÂÄëÊâÄÁü•ÔºåÈÄôÊòØÁ¨¨‰∏ÄÂÄãÂ∞á LLM Áî®‰ΩúÈªûÈõ≤Ë≥áÊñôÂ£ìÁ∏ÆÂô®ÁöÑÁµêÊßã„ÄÇÂØ¶È©óË≠âÊòéÔºåËàá MPEG Âü∫ÊñºÂπæ‰ΩïÁöÑÈªûÈõ≤Â£ìÁ∏Æ (G-PCC) Ê®ôÊ∫ñÁöÑÂèÉËÄÉËªüÈ´îÁõ∏ÊØîÔºåLLM-PCGC ÁöÑ‰ΩçÂÖÉÁéáÈôç‰Ωé‰∫Ü -40.213%ÔºåËàáÊúÄÂÖàÈÄ≤ÁöÑÂü∫ÊñºÂ≠∏ÁøíÁöÑÊñπÊ≥ïÁõ∏ÊØîÔºå‰ΩçÂÖÉÁéáÈôç‰Ωé‰∫Ü -2.267%ÔºåÂ§ßÂπÖÂÑ™ÊñºÂÖ∂‰ªñÁèæÊúâÊñπÊ≥ï„ÄÇ

##### **Fine-tuning LLMs for Autonomous Spacecraft Control: A Case Study Using Kerbal Space Program**
2408.08676v1 by Alejandro Carrasco, Victor Rodriguez-Fernandez, Richard Linares

Recent trends are emerging in the use of Large Language Models (LLMs) as
autonomous agents that take actions based on the content of the user text
prompt. This study explores the use of fine-tuned Large Language Models (LLMs)
for autonomous spacecraft control, using the Kerbal Space Program Differential
Games suite (KSPDG) as a testing environment. Traditional Reinforcement
Learning (RL) approaches face limitations in this domain due to insufficient
simulation capabilities and data. By leveraging LLMs, specifically fine-tuning
models like GPT-3.5 and LLaMA, we demonstrate how these models can effectively
control spacecraft using language-based inputs and outputs. Our approach
integrates real-time mission telemetry into textual prompts processed by the
LLM, which then generate control actions via an agent. The results open a
discussion about the potential of LLMs for space operations beyond their
nominal use for text-related tasks. Future work aims to expand this methodology
to other space control tasks and evaluate the performance of different LLM
families. The code is available at this URL:
\texttt{https://github.com/ARCLab-MIT/kspdg}.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑ‰ΩøÁî®Âá∫Áèæ‰∫ÜÊñ∞Ë∂®Âã¢Ôºå‰ΩúÁÇ∫Ëá™‰∏ª‰ª£ÁêÜÔºåÊ†πÊìö‰ΩøÁî®ËÄÖÊñáÂ≠óÊèêÁ§∫ÁöÑÂÖßÂÆπÊé°ÂèñË°åÂãï„ÄÇÊú¨Á†îÁ©∂Êé¢Ë®é‰∫Ü‰ΩøÁî®ÂæÆË™øÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÈÄ≤Ë°åËá™‰∏ªÂ§™Á©∫ËàπÊéßÂà∂Ôºå‰ΩøÁî® Kerbal Â§™Á©∫Ë®àÁï´Â∑ÆÁï∞ÈÅäÊà≤ÁµÑ (KSPDG) ‰ΩúÁÇ∫Ê∏¨Ë©¶Áí∞Â¢É„ÄÇÂÇ≥Áµ±ÁöÑÂº∑ÂåñÂ≠∏Áøí (RL) ÊñπÊ≥ïÁî±ÊñºÊ®°Êì¨ËÉΩÂäõÂíåÊï∏Êìö‰∏çË∂≥ÔºåÂõ†Ê≠§Âú®Ê≠§È†òÂüüÈù¢Ëá®ÈôêÂà∂„ÄÇÈÄèÈÅéÂà©Áî® LLMÔºåÁâπÂà•ÊòØÂæÆË™ø GPT-3.5 Âíå LLaMA Á≠âÊ®°ÂûãÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜÈÄô‰∫õÊ®°ÂûãÂ¶Ç‰ΩïËÉΩÊúâÊïàÂú∞‰ΩøÁî®Âü∫ÊñºË™ûË®ÄÁöÑËº∏ÂÖ•ÂíåËº∏Âá∫ÊéßÂà∂Â§™Á©∫Ëàπ„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÂ∞áÂç≥ÊôÇ‰ªªÂãôÈÅôÊ∏¨Êï¥ÂêàÂà∞ LLM ËôïÁêÜÁöÑÊñáÂ≠óÊèêÁ§∫‰∏≠ÔºåÁÑ∂ÂæåÈÄèÈÅé‰ª£ÁêÜÁî¢ÁîüÊéßÂà∂Âãï‰Ωú„ÄÇÁµêÊûúÈñãÂïü‰∫ÜÈóúÊñº LLM Âú®Â§™Á©∫‰ªªÂãô‰∏≠ÊΩõÂäõÁöÑË®éË´ñÔºåË∂ÖË∂ä‰∫ÜÂÆÉÂÄëÂú®ÊñáÂ≠óÁõ∏Èóú‰ªªÂãô‰∏≠ÁöÑÊÖ£Â∏∏Áî®ÈÄî„ÄÇÊú™‰æÜÁöÑÁ†îÁ©∂ÁõÆÊ®ôÊòØÂ∞áÊ≠§ÊñπÊ≥ïÊì¥Â±ïÂà∞ÂÖ∂‰ªñÂ§™Á©∫ÊéßÂà∂‰ªªÂãôÔºå‰∏¶Ë©ï‰º∞‰∏çÂêå LLM Á≥ªÂàóÁöÑÊïàËÉΩ„ÄÇÁ®ãÂºèÁ¢ºÂèØÂú®‰ª•‰∏ãÁ∂≤ÂùÄÂèñÂæóÔºö
\texttt{https://github.com/ARCLab-MIT/kspdg}„ÄÇ

##### **MAT-SED: AMasked Audio Transformer with Masked-Reconstruction Based Pre-training for Sound Event Detection**
2408.08673v1 by Pengfei Cai, Yan Song, Kang Li, Haoyu Song, Ian McLoughlin

Sound event detection (SED) methods that leverage a large pre-trained
Transformer encoder network have shown promising performance in recent DCASE
challenges. However, they still rely on an RNN-based context network to model
temporal dependencies, largely due to the scarcity of labeled data. In this
work, we propose a pure Transformer-based SED model with masked-reconstruction
based pre-training, termed MAT-SED. Specifically, a Transformer with relative
positional encoding is first designed as the context network, pre-trained by
the masked-reconstruction task on all available target data in a
self-supervised way. Both the encoder and the context network are jointly
fine-tuned in a semi-supervised manner. Furthermore, a global-local feature
fusion strategy is proposed to enhance the localization capability. Evaluation
of MAT-SED on DCASE2023 task4 surpasses state-of-the-art performance, achieving
0.587/0.896 PSDS1/PSDS2 respectively.

ÊëòË¶ÅÔºöËÅ≤Èü≥‰∫ã‰ª∂ÂÅµÊ∏¨ (SED) ÊñπÊ≥ïÂà©Áî®Â§ßÂûãÈ†êË®ìÁ∑¥ Transformer Á∑®Á¢ºÂô®Á∂≤Ë∑ØÔºåÂú®ÊúÄËøëÁöÑ DCASE ÊåëÊà∞‰∏≠Â±ïÁèæÂá∫‰ª§‰∫∫ÊªøÊÑèÁöÑÊïàËÉΩ„ÄÇÁÑ∂ËÄåÔºåÁî±ÊñºÊ®ôÁ±§Ë≥áÊñôÁöÑÁ®ÄÂ∞ëÔºåÂÆÉÂÄë‰ªç‰æùË≥¥ÊñºÂü∫Êñº RNN ÁöÑËÑàÁµ°Á∂≤Ë∑Ø‰æÜÂª∫Ê®°ÊôÇÈñì‰æùË≥¥ÊÄß„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÁ¥î Transformer ÁÇ∫Âü∫Á§éÁöÑ SED Ê®°ÂûãÔºåÂÖ∑ÂÇôÈÅÆÁΩ©ÈáçÂª∫ÁÇ∫Âü∫Á§éÁöÑÈ†êË®ìÁ∑¥ÔºåÁ®±ÁÇ∫ MAT-SED„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÈ¶ñÂÖàÂ∞á‰∏ÄÂÄãÂ∏∂ÊúâÁõ∏Â∞ç‰ΩçÁΩÆÁ∑®Á¢ºÁöÑ Transformer Ë®≠Ë®àÁÇ∫ËÑàÁµ°Á∂≤Ë∑ØÔºå‰∏¶ÈÄèÈÅéËá™ÊàëÁõ£Áù£ÁöÑÊñπÂºèÔºåÂú®ÊâÄÊúâÂèØÁî®ÁöÑÁõÆÊ®ôË≥áÊñô‰∏ä‰ª•ÈÅÆÁΩ©ÈáçÂª∫‰ªªÂãôÈÄ≤Ë°åÈ†êË®ìÁ∑¥„ÄÇÁ∑®Á¢ºÂô®ÂíåËÑàÁµ°Á∂≤Ë∑ØÈÉΩÊúÉ‰ª•ÂçäÁõ£Áù£ÁöÑÊñπÂºèËÅØÂêàÂæÆË™ø„ÄÇÊ≠§Â§ñÔºåÊèêÂá∫‰∏ÄÂÄãÂÖ®Âüü-Â±ÄÈÉ®ÁâπÂæµËûçÂêàÁ≠ñÁï•‰æÜÂ¢ûÂº∑ÂÆö‰ΩçËÉΩÂäõ„ÄÇMAT-SED Âú® DCASE2023 ‰ªªÂãô 4 ‰∏äÁöÑË©ï‰º∞Ë∂ÖË∂ä‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÊïàËÉΩÔºåÂàÜÂà•ÈÅîÂà∞ 0.587/0.896 PSDS1/PSDS2„ÄÇ

##### **Adaptive Layer Selection for Efficient Vision Transformer Fine-Tuning**
2408.08670v1 by Alessio Devoto, Federico Alvetreti, Jary Pomponi, Paolo Di Lorenzo, Pasquale Minervini, Simone Scardapane

Recently, foundation models based on Vision Transformers (ViTs) have become
widely available. However, their fine-tuning process is highly
resource-intensive, and it hinders their adoption in several edge or low-energy
applications. To this end, in this paper we introduce an efficient fine-tuning
method for ViTs called $\textbf{ALaST}$ ($\textit{Adaptive Layer Selection
Fine-Tuning for Vision Transformers}$) to speed up the fine-tuning process
while reducing computational cost, memory load, and training time. Our approach
is based on the observation that not all layers are equally critical during
fine-tuning, and their importance varies depending on the current mini-batch.
Therefore, at each fine-tuning step, we adaptively estimate the importance of
all layers and we assign what we call ``compute budgets'' accordingly. Layers
that were allocated lower budgets are either trained with a reduced number of
input tokens or kept frozen. Freezing a layer reduces the computational cost
and memory usage by preventing updates to its weights, while discarding tokens
removes redundant data, speeding up processing and reducing memory
requirements. We show that this adaptive compute allocation enables a
nearly-optimal schedule for distributing computational resources across layers,
resulting in substantial reductions in training time (up to 1.5x), FLOPs (up to
2x), and memory load (up to 2x) compared to traditional full fine-tuning
approaches. Additionally, it can be successfully combined with other
parameter-efficient fine-tuning methods, such as LoRA.

ÊëòË¶ÅÔºö<paragraph>ÊúÄËøëÔºåÂü∫‰∫éËßÜËßâËΩ¨Êç¢Âô® (ViT) ÁöÑÂü∫Á°ÄÊ®°ÂûãÂ∑≤ÂπøÊ≥õÂèØÁî®„ÄÇÁÑ∂ËÄåÔºåÂÆÉ‰ª¨ÁöÑÂæÆË∞ÉËøáÁ®ãÈùûÂ∏∏ËÄóË¥πËµÑÊ∫êÔºåÂπ∂‰∏îÈòªÁ¢ç‰∫ÜÂÆÉ‰ª¨Âú®Â§ö‰∏™ËæπÁºòÊàñ‰ΩéËÉΩËÄóÂ∫îÁî®‰∏≠ÁöÑÈááÁî®„ÄÇ‰∏∫Ê≠§ÔºåÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨‰ªãÁªç‰∫Ü‰∏ÄÁßçÁß∞‰∏∫ $\textbf{ALaST}$Ôºà$\textit{ËßÜËßâËΩ¨Êç¢Âô®ÁöÑËá™ÈÄÇÂ∫îÂ±ÇÈÄâÊã©ÂæÆË∞É}$ÔºâÁöÑ ViT È´òÊïàÂæÆË∞ÉÊñπÊ≥ïÔºå‰ª•Âú®Èôç‰ΩéËÆ°ÁÆóÊàêÊú¨„ÄÅÂÜÖÂ≠òË¥üËΩΩÂíåËÆ≠ÁªÉÊó∂Èó¥ÁöÑËøáÁ®ã‰∏≠Âä†ÈÄüÂæÆË∞ÉËøáÁ®ã„ÄÇÊàë‰ª¨ÁöÑÊñπÊ≥ïÂü∫‰∫éËøôÊ†∑ÁöÑËßÇÂØüÔºöÂπ∂ÈùûÊâÄÊúâÂ±ÇÂú®ÂæÆË∞ÉËøáÁ®ã‰∏≠ÈÉΩÂêåÊ†∑ÂÖ≥ÈîÆÔºåÂπ∂‰∏îÂÆÉ‰ª¨ÁöÑÈáçË¶ÅÊÄß‰ºöÊ†πÊçÆÂΩìÂâçÁöÑÂ∞èÊâπÈáèËÄåÊúâÊâÄ‰∏çÂêå„ÄÇÂõ†Ê≠§ÔºåÂú®ÊØè‰∏™ÂæÆË∞ÉÊ≠•È™§‰∏≠ÔºåÊàë‰ª¨Ëá™ÈÄÇÂ∫îÂú∞‰º∞ËÆ°ÊâÄÊúâÂ±ÇÁöÑÊùÉÈáçÔºåÂπ∂Áõ∏Â∫îÂú∞ÂàÜÈÖçÊàë‰ª¨ÊâÄË∞ìÁöÑ ``ËÆ°ÁÆóÈ¢ÑÁÆó''„ÄÇÂàÜÈÖçËæÉ‰ΩéÈ¢ÑÁÆóÁöÑÂ±ÇË¶Å‰πà‰ΩøÁî®ÂáèÂ∞ëÊï∞ÈáèÁöÑËæìÂÖ•Ê†áËÆ∞ËøõË°åËÆ≠ÁªÉÔºåË¶Å‰πà‰øùÊåÅÂÜªÁªì„ÄÇÂÜªÁªìÂ±ÇÈÄöËøáÈò≤Ê≠¢ÂÖ∂ÊùÉÈáçÁöÑÊõ¥Êñ∞Êù•Èôç‰ΩéËÆ°ÁÆóÊàêÊú¨ÂíåÂÜÖÂ≠ò‰ΩøÁî®ÈáèÔºåËÄå‰∏¢ÂºÉÊ†áËÆ∞Âàô‰ºöÂà†Èô§ÂÜó‰ΩôÊï∞ÊçÆÔºå‰ªéËÄåÂä†Âø´Â§ÑÁêÜÈÄüÂ∫¶Âπ∂Èôç‰ΩéÂÜÖÂ≠òÈúÄÊ±Ç„ÄÇÊàë‰ª¨Ë°®ÊòéÔºåËøôÁßçËá™ÈÄÇÂ∫îËÆ°ÁÆóÂàÜÈÖçËÉΩÂ§ü‰∏∫Ë∑®Â±ÇÂàÜÈÖçËÆ°ÁÆóËµÑÊ∫êÂà∂ÂÆöËøë‰πéÊúÄ‰ºòÁöÑË∞ÉÂ∫¶Ôºå‰∏é‰º†ÁªüÁöÑÂÆåÂÖ®ÂæÆË∞ÉÊñπÊ≥ïÁõ∏ÊØîÔºåÂèØÂ§ßÂπÖÂáèÂ∞ëËÆ≠ÁªÉÊó∂Èó¥ÔºàÊúÄÂ§ö 1.5 ÂÄçÔºâ„ÄÅFLOPÔºàÊúÄÂ§ö 2 ÂÄçÔºâÂíåÂÜÖÂ≠òË¥üËΩΩÔºàÊúÄÂ§ö 2 ÂÄçÔºâ„ÄÇÊ≠§Â§ñÔºåÂÆÉÂèØ‰ª•ÊàêÂäüÂú∞‰∏éÂÖ∂‰ªñÂèÇÊï∞È´òÊïàÁöÑÂæÆË∞ÉÊñπÊ≥ïÔºà‰æãÂ¶Ç LoRAÔºâÁªìÂêà‰ΩøÁî®„ÄÇ</paragraph>

##### **MIA-Tuner: Adapting Large Language Models as Pre-training Text Detector**
2408.08661v1 by Wenjie Fu, Huandong Wang, Chen Gao, Guanghua Liu, Yong Li, Tao Jiang

The increasing parameters and expansive dataset of large language models
(LLMs) highlight the urgent demand for a technical solution to audit the
underlying privacy risks and copyright issues associated with LLMs. Existing
studies have partially addressed this need through an exploration of the
pre-training data detection problem, which is an instance of a membership
inference attack (MIA). This problem involves determining whether a given piece
of text has been used during the pre-training phase of the target LLM. Although
existing methods have designed various sophisticated MIA score functions to
achieve considerable detection performance in pre-trained LLMs, how to achieve
high-confidence detection and how to perform MIA on aligned LLMs remain
challenging. In this paper, we propose MIA-Tuner, a novel instruction-based MIA
method, which instructs LLMs themselves to serve as a more precise pre-training
data detector internally, rather than design an external MIA score function.
Furthermore, we design two instruction-based safeguards to respectively
mitigate the privacy risks brought by the existing methods and MIA-Tuner. To
comprehensively evaluate the most recent state-of-the-art LLMs, we collect a
more up-to-date MIA benchmark dataset, named WIKIMIA-24, to replace the widely
adopted benchmark WIKIMIA. We conduct extensive experiments across various
aligned and unaligned LLMs over the two benchmark datasets. The results
demonstrate that MIA-Tuner increases the AUC of MIAs from 0.7 to a
significantly high level of 0.9.

ÊëòË¶ÅÔºöÈö®ËëóÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâÂèÉÊï∏ÁöÑÂ¢ûÂä†ÂíåË≥áÊñôÈõÜÁöÑÊì¥Â±ïÔºåÁ™ÅÈ°ØÂá∫Â∞çÊäÄË°ìËß£Ê±∫ÊñπÊ°àÁöÑËø´ÂàáÈúÄÊ±ÇÔºå‰ª•Á®ΩÊ†∏Ëàá LLM Áõ∏ÈóúÁöÑÂü∫Êú¨Èö±ÁßÅÈ¢®Èö™ÂíåÁâàÊ¨äÂïèÈ°å„ÄÇÁèæÊúâÁöÑÁ†îÁ©∂Â∑≤ÈÄèÈÅéÊé¢Á¥¢È†êË®ìÁ∑¥Ë≥áÊñôÂÅµÊ∏¨ÂïèÈ°åÔºåÈÉ®ÂàÜÊªøË∂≥Ê≠§ÈúÄÊ±ÇÔºåËÄåÈÄôÂÄãÂïèÈ°åÊòØÊàêÂì°Êé®Ë´ñÊîªÊìäÔºàMIAÔºâÁöÑ‰∏ÄÂÄãÁØÑ‰æã„ÄÇÈÄôÂÄãÂïèÈ°åÊ∂âÂèäÁ¢∫ÂÆöÁâπÂÆöÊñáÂ≠óÊòØÂê¶Â∑≤Âú®ÁõÆÊ®ô LLM ÁöÑÈ†êË®ìÁ∑¥ÈöéÊÆµ‰∏≠‰ΩøÁî®„ÄÇÈõñÁÑ∂ÁèæÊúâÊñπÊ≥ïÂ∑≤Ë®≠Ë®àÂêÑÁ®ÆË§áÈõúÁöÑ MIA ÂàÜÊï∏ÂáΩÊï∏Ôºå‰ª•Âú®È†êË®ìÁ∑¥ LLM ‰∏≠ÈÅîÊàêÁõ∏Áï∂ÁöÑÂÅµÊ∏¨ÊïàËÉΩÔºå‰ΩÜÂ¶Ç‰ΩïÈÅîÊàêÈ´ò‰ø°ÂøÉÁöÑÂÅµÊ∏¨‰ª•ÂèäÂ¶Ç‰ΩïÂ∞çÈΩäÁöÑ LLM Âü∑Ë°å MIA ‰ªçÁÑ∂ÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫ MIA-TunerÔºå‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÂü∫ÊñºÊåá‰ª§ÁöÑ MIA ÊñπÊ≥ïÔºåÂÆÉÊåáÁ§∫ LLM Êú¨Ë∫´Âú®ÂÖßÈÉ®‰ΩúÁÇ∫Êõ¥Á≤æÁ¢∫ÁöÑÈ†êË®ìÁ∑¥Ë≥áÊñôÂÅµÊ∏¨Âô®ÔºåËÄå‰∏çÊòØË®≠Ë®àÂ§ñÈÉ® MIA ÂàÜÊï∏ÂáΩÊï∏„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëË®≠Ë®à‰∫ÜÂÖ©ÂÄãÂü∫ÊñºÊåá‰ª§ÁöÑÈò≤Ë≠∑Êé™ÊñΩÔºåÂàÜÂà•Á∑©Ëß£ÁèæÊúâÊñπÊ≥ïÂíå MIA-Tuner Â∏∂‰æÜÁöÑÈö±ÁßÅÈ¢®Èö™„ÄÇÁÇ∫‰∫ÜÂÖ®Èù¢Ë©ï‰º∞ÊúÄÊñ∞ÁöÑÊúÄÂÖàÈÄ≤ LLMÔºåÊàëÂÄëÊî∂ÈõÜ‰∫Ü‰∏ÄÂÄãÊõ¥ÊúÄÊñ∞ÁöÑ MIA Âü∫Ê∫ñË≥áÊñôÈõÜÔºåÂêçÁÇ∫ WIKIMIA-24Ôºå‰ª•Âèñ‰ª£Âª£Ê≥õÊé°Áî®ÁöÑÂü∫Ê∫ñ WIKIMIA„ÄÇÊàëÂÄëÂú®ÂÖ©ÂÄãÂü∫Ê∫ñË≥áÊñôÈõÜ‰∏äÂ∞çÂêÑÁ®ÆÂ∞çÈΩäÂíåÊú™Â∞çÈΩäÁöÑ LLM ÈÄ≤Ë°åÂª£Ê≥õÁöÑÂØ¶È©ó„ÄÇÁµêÊûúË≠âÊòéÔºåMIA-Tuner Â∞á MIA ÁöÑ AUC Âæû 0.7 ÊèêÈ´òÂà∞È°ØËëóÈ´òÁöÑ 0.9 Ê∞¥Ê∫ñ„ÄÇ

##### **LLMs Are Biased Towards Output Formats! Systematically Evaluating and Mitigating Output Format Bias of LLMs**
2408.08656v1 by Do Xuan Long, Hai Nguyen Ngoc, Tiviatis Sim, Hieu Dao, Shafiq Joty, Kenji Kawaguchi, Nancy F. Chen, Min-Yen Kan

We present the first systematic evaluation examining format bias in
performance of large language models (LLMs). Our approach distinguishes between
two categories of an evaluation metric under format constraints to reliably and
accurately assess performance: one measures performance when format constraints
are adhered to, while the other evaluates performance regardless of constraint
adherence. We then define a metric for measuring the format bias of LLMs and
establish effective strategies to reduce it. Subsequently, we present our
empirical format bias evaluation spanning four commonly used categories --
multiple-choice question-answer, wrapping, list, and mapping -- covering 15
widely-used formats. Our evaluation on eight generation tasks uncovers
significant format bias across state-of-the-art LLMs. We further discover that
improving the format-instruction following capabilities of LLMs across formats
potentially reduces format bias. Based on our evaluation findings, we study
prompting and fine-tuning with synthesized format data techniques to mitigate
format bias. Our methods successfully reduce the variance in ChatGPT's
performance among wrapping formats from 235.33 to 0.71 (%$^2$).

ÊëòË¶ÅÔºöÊàëÂÄëÊèêÂá∫Á¨¨‰∏ÄÂÄãÁ≥ªÁµ±ÊÄßË©ï‰º∞ÔºåÁî®ÊñºÊ™¢È©óÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÊïàËÉΩ‰∏≠ÁöÑÊ†ºÂºèÂÅèÂ∑Æ„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÂçÄÂàÜ‰∫ÜÂú®Ê†ºÂºèÈôêÂà∂‰∏ãÔºåË©ï‰º∞ÊåáÊ®ôÁöÑÂÖ©ÂÄãÈ°ûÂà•Ôºå‰ª•ÂèØÈù†‰∏îÊ∫ñÁ¢∫Âú∞Ë©ï‰º∞ÊïàËÉΩÔºö‰∏ÄÂÄãÊòØÊ∏¨ÈáèÂú®ÈÅµÂÆàÊ†ºÂºèÈôêÂà∂‰∏ãÁöÑÊïàËÉΩÔºåËÄåÂè¶‰∏ÄÂÄãÂâáË©ï‰º∞‰∏çË´ñÊòØÂê¶ÈÅµÂÆàÈôêÂà∂ÁöÑÊïàËÉΩ„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÂÆöÁæ©‰∏ÄÂÄãÊåáÊ®ôÔºåÁî®ÊñºÊ∏¨Èáè LLM ÁöÑÊ†ºÂºèÂÅèÂ∑ÆÔºå‰∏¶Âª∫Á´ãÊúâÊïàÁöÑÁ≠ñÁï•‰æÜÊ∏õÂ∞ëÂÆÉ„ÄÇÈö®ÂæåÔºåÊàëÂÄëÊèêÂá∫ÊàëÂÄëÁöÑÁ∂ìÈ©óÊ†ºÂºèÂÅèÂ∑ÆË©ï‰º∞ÔºåÊ∂µËìãÂõõÂÄãÂ∏∏Áî®ÁöÑÈ°ûÂà•‚Äî‚ÄîÂ§öÈáçÈÅ∏ÊìáÂïèÁ≠î„ÄÅÊèõË°å„ÄÅÊ∏ÖÂñÆÂíåÂ∞çÊáâ‚Äî‚ÄîÊ∂µËìã 15 Á®ÆÂª£Ê≥õ‰ΩøÁî®ÁöÑÊ†ºÂºè„ÄÇÊàëÂÄëÂ∞çÂÖ´ÂÄãÁî¢Áîü‰ªªÂãôÁöÑË©ï‰º∞Êè≠Á§∫‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑ LLM ‰∏≠ÁöÑÈ°ØËëóÊ†ºÂºèÂÅèÂ∑Æ„ÄÇÊàëÂÄëÈÄ≤‰∏ÄÊ≠•ÁôºÁèæÔºåÊîπÂñÑ LLM Âú®ÊâÄÊúâÊ†ºÂºè‰∏≠ÈÅµÂæ™Ê†ºÂºèË™™ÊòéÁöÑËÉΩÂäõÔºåÂèØËÉΩÊúÉÊ∏õÂ∞ëÊ†ºÂºèÂÅèÂ∑Æ„ÄÇÊ†πÊìöÊàëÂÄëÁöÑË©ï‰º∞ÁµêÊûúÔºåÊàëÂÄëÁ†îÁ©∂ÊèêÁ§∫ÂíåÂæÆË™øÔºå‰∏¶‰ΩøÁî®ÂêàÊàêÁöÑÊ†ºÂºèÊï∏ÊìöÊäÄË°ì‰æÜÊ∏õËºïÊ†ºÂºèÂÅèÂ∑Æ„ÄÇÊàëÂÄëÁöÑÈÄô‰∫õÊñπÊ≥ïÊàêÂäüÂú∞Â∞á ChatGPT Âú®ÊèõË°åÊ†ºÂºè‰∏≠ÁöÑÊïàËÉΩÂ∑ÆÁï∞Âæû 235.33 Èôç‰ΩéÂà∞ 0.71 (%$^2$)„ÄÇ

##### **Mitigating Backdoor Attacks in Federated Learning via Flipping Weight Updates of Low-Activation Input Neurons**
2408.08655v1 by Binbin Ding, Penghui Yang, Zeqing Ge, Shengjun Huang

Federated learning enables multiple clients to collaboratively train machine
learning models under the overall planning of the server while adhering to
privacy requirements. However, the server cannot directly oversee the local
training process, creating an opportunity for malicious clients to introduce
backdoors. Existing research shows that backdoor attacks activate specific
neurons in the compromised model, which remain dormant when processing clean
data. Leveraging this insight, we propose a method called Flipping Weight
Updates of Low-Activation Input Neurons (FLAIN) to defend against backdoor
attacks in federated learning. Specifically, after completing global training,
we employ an auxiliary dataset to identify low-activation input neurons and
flip the associated weight updates. We incrementally raise the threshold for
low-activation inputs and flip the weight updates iteratively, until the
performance degradation on the auxiliary data becomes unacceptable. Extensive
experiments validate that our method can effectively reduce the success rate of
backdoor attacks to a low level in various attack scenarios including those
with non-IID data distribution or high MCRs, causing only minimal performance
degradation on clean data.

ÊëòË¶ÅÔºöËÅîÈÇ¶Â≠¶‰π†ËÆ©Â§ö‰∏™ÂÆ¢Êà∑Á´ØÂú®ÊúçÂä°Âô®ÁöÑÊï¥‰ΩìËßÑÂàí‰∏ãÂçè‰ΩúËÆ≠ÁªÉÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÔºåÂêåÊó∂ÈÅµÂÆàÈöêÁßÅË¶ÅÊ±Ç„ÄÇÁÑ∂ËÄåÔºåÊúçÂä°Âô®Êó†Ê≥ïÁõ¥Êé•ÁõëÁù£Êú¨Âú∞ËÆ≠ÁªÉËøáÁ®ãÔºåËøô‰∏∫ÊÅ∂ÊÑèÂÆ¢Êà∑Á´ØÂºïÂÖ•ÂêéÈó®ÂàõÈÄ†‰∫ÜÊú∫‰ºö„ÄÇÁé∞ÊúâÁ†îÁ©∂Ë°®ÊòéÔºåÂêéÈó®ÊîªÂáª‰ºöÊøÄÊ¥ªÂèóÊçüÊ®°Âûã‰∏≠ÁöÑÁâπÂÆöÁ•ûÁªèÂÖÉÔºåËøô‰∫õÁ•ûÁªèÂÖÉÂú®Â§ÑÁêÜÂπ≤ÂáÄÊï∞ÊçÆÊó∂‰øùÊåÅ‰ºëÁú†„ÄÇÂà©Áî®Ëøô‰∏ÄËßÅËß£ÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçÁß∞‰∏∫‰ΩéÊøÄÊ¥ªËæìÂÖ•Á•ûÁªèÂÖÉÊùÉÈáçÊõ¥Êñ∞ÁøªËΩ¨ (FLAIN) ÁöÑÊñπÊ≥ïÊù•Èò≤Âæ°ËÅîÈÇ¶Â≠¶‰π†‰∏≠ÁöÑÂêéÈó®ÊîªÂáª„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåÂú®ÂÆåÊàêÂÖ®Â±ÄËÆ≠ÁªÉÂêéÔºåÊàë‰ª¨‰ΩøÁî®ËæÖÂä©Êï∞ÊçÆÈõÜÊù•ËØÜÂà´‰ΩéÊøÄÊ¥ªËæìÂÖ•Á•ûÁªèÂÖÉÂπ∂ÁøªËΩ¨Áõ∏ÂÖ≥ÁöÑÊùÉÈáçÊõ¥Êñ∞„ÄÇÊàë‰ª¨ÈÄêÊ≠•ÊèêÈ´ò‰ΩéÊøÄÊ¥ªËæìÂÖ•ÁöÑÈòàÂÄºÂπ∂Ëø≠‰ª£ÁøªËΩ¨ÊùÉÈáçÊõ¥Êñ∞ÔºåÁõ¥Âà∞ËæÖÂä©Êï∞ÊçÆ‰∏äÁöÑÊÄßËÉΩ‰∏ãÈôçÂèòÂæó‰∏çÂèØÊé•Âèó„ÄÇÂ§ßÈáèÁöÑÂÆûÈ™åÈ™åËØÅ‰∫ÜÊàë‰ª¨ÁöÑÊñπÊ≥ïÂèØ‰ª•ÊúâÊïàÂú∞Â∞ÜÂêéÈó®ÊîªÂáªÁöÑÊàêÂäüÁéáÈôç‰ΩéÂà∞‰ΩéÊ∞¥Âπ≥ÔºåÂåÖÊã¨ÈÇ£‰∫õÂÖ∑ÊúâÈùû IID Êï∞ÊçÆÂàÜÂ∏ÉÊàñÈ´ò MCR ÁöÑÊîªÂáªÂú∫ÊôØÔºå‰ªÖÂØπÂπ≤ÂáÄÊï∞ÊçÆÈÄ†ÊàêÊúÄÂ∞èÁöÑÊÄßËÉΩ‰∏ãÈôç„ÄÇ

##### **TextCAVs: Debugging vision models using text**
2408.08652v1 by Angus Nicolson, Yarin Gal, J. Alison Noble

Concept-based interpretability methods are a popular form of explanation for
deep learning models which provide explanations in the form of high-level human
interpretable concepts. These methods typically find concept activation vectors
(CAVs) using a probe dataset of concept examples. This requires labelled data
for these concepts -- an expensive task in the medical domain. We introduce
TextCAVs: a novel method which creates CAVs using vision-language models such
as CLIP, allowing for explanations to be created solely using text descriptions
of the concept, as opposed to image exemplars. This reduced cost in testing
concepts allows for many concepts to be tested and for users to interact with
the model, testing new ideas as they are thought of, rather than a delay caused
by image collection and annotation. In early experimental results, we
demonstrate that TextCAVs produces reasonable explanations for a chest x-ray
dataset (MIMIC-CXR) and natural images (ImageNet), and that these explanations
can be used to debug deep learning-based models.

ÊëòË¶ÅÔºöÂü∫ÊñºÊ¶ÇÂøµÁöÑÂèØËß£ÈáãÊñπÊ≥ïÊòØ‰∏ÄÁ®ÆÊµÅË°åÁöÑÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãËß£ÈáãÂΩ¢ÂºèÔºåÂÆÉ‰ª•È´òÈöé‰∫∫È°ûÂèØËß£ÈáãÊ¶ÇÂøµÁöÑÂΩ¢ÂºèÊèê‰æõËß£Èáã„ÄÇÈÄô‰∫õÊñπÊ≥ïÈÄöÂ∏∏‰ΩøÁî®Ê¶ÇÂøµÁØÑ‰æãÊé¢Ê∏¨Ë≥áÊñôÈõÜ‰æÜÂ∞ãÊâæÊ¶ÇÂøµÂïüÂãïÂêëÈáè (CAV)„ÄÇÈÄôÈúÄË¶ÅÊ®ôË®òÈÄô‰∫õÊ¶ÇÂøµÁöÑË≥áÊñôÔºåÈÄôÂú®ÈÜ´Â≠∏È†òÂüüÊòØ‰∏ÄÈ†ÖÊòÇË≤¥ÁöÑ‰ªªÂãô„ÄÇÊàëÂÄë‰ªãÁ¥π TextCAVÔºö‰∏ÄÁ®Æ‰ΩøÁî®Ë¶ñË¶∫Ë™ûË®ÄÊ®°ÂûãÔºà‰æãÂ¶Ç CLIPÔºâÂª∫Á´ã CAV ÁöÑÊñ∞ÊñπÊ≥ïÔºåÂÆÉÂÖÅË®±ÂÉÖ‰ΩøÁî®Ê¶ÇÂøµÁöÑÊñáÂ≠óÊèèËø∞‰æÜÂª∫Á´ãËß£ÈáãÔºåËÄå‰∏çÊòØÂΩ±ÂÉèÁØÑ‰æã„ÄÇÊ∏¨Ë©¶Ê¶ÇÂøµÁöÑÊàêÊú¨Èôç‰ΩéÔºåÂÖÅË®±Ê∏¨Ë©¶Ë®±Â§öÊ¶ÇÂøµÔºå‰∏¶ËÆì‰ΩøÁî®ËÄÖËàáÊ®°Âûã‰∫íÂãïÔºåÂú®ÊÉ≥Âà∞Êñ∞ÊÉ≥Ê≥ïÊôÇÈÄ≤Ë°åÊ∏¨Ë©¶ÔºåËÄå‰∏çÊòØÂõ†ÂΩ±ÂÉèÊî∂ÈõÜÂíåË®ªËß£ËÄåÈÄ†ÊàêÁöÑÂª∂ÈÅ≤„ÄÇÂú®Êó©ÊúüÁöÑÂØ¶È©óÁµêÊûú‰∏≠ÔºåÊàëÂÄëË≠âÊòé TextCAV ÁÇ∫ËÉ∏ÈÉ® X ÂÖâË≥áÊñôÈõÜ (MIMIC-CXR) ÂíåËá™ÁÑ∂ÂΩ±ÂÉè (ImageNet) Áî¢ÁîüÂêàÁêÜÁöÑËß£ÈáãÔºå‰∏¶‰∏îÈÄô‰∫õËß£ÈáãÂèØÁî®ÊñºÂÅµÈåØÂü∫ÊñºÊ∑±Â∫¶Â≠∏ÁøíÁöÑÊ®°Âûã„ÄÇ

##### **Reasoning Beyond Bias: A Study on Counterfactual Prompting and Chain of Thought Reasoning**
2408.08651v1 by Kyle Moore, Jesse Roberts, Thao Pham, Douglas Fisher

Language models are known to absorb biases from their training data, leading
to predictions driven by statistical regularities rather than semantic
relevance. We investigate the impact of these biases on answer choice
preferences in the Massive Multi-Task Language Understanding (MMLU) task. Our
findings reveal that differences in learned regularities across answer options
are predictive of model preferences and mirror human test-taking strategies. To
address this issue, we introduce two novel methods: Counterfactual Prompting
with Chain of Thought (CoT) and Counterfactual Prompting with Agnostically
Primed CoT (APriCoT). We demonstrate that while Counterfactual Prompting with
CoT alone is insufficient to mitigate bias, our novel Primed Counterfactual
Prompting with CoT approach effectively reduces the influence of base-rate
probabilities while improving overall accuracy. Our results suggest that
mitigating bias requires a "System-2" like process and that CoT reasoning is
susceptible to confirmation bias under some prompting methodologies. Our
contributions offer practical solutions for developing more robust and fair
language models.

ÊëòË¶ÅÔºöË™ûË®ÄÊ®°ÂûãÂ∑≤Áü•ÊúÉÂê∏Êî∂ÂÖ∂Ë®ìÁ∑¥Ë≥áÊñô‰∏≠ÁöÑÂÅèË¶ãÔºåÂ∞éËá¥È†êÊ∏¨ÊòØÁî±Áµ±Ë®àË¶èÂæãËÄåÈùûË™ûÁæ©Áõ∏ÈóúÊÄßÈ©ÖÂãï„ÄÇÊàëÂÄëÊé¢Ë®éÈÄô‰∫õÂÅèË¶ãÂ∞çÂ§ßË¶èÊ®°Â§ö‰ªªÂãôË™ûË®ÄÁêÜËß£ (MMLU) ‰ªªÂãô‰∏≠Á≠îÊ°àÈÅ∏ÊìáÂÅèÂ•ΩÁöÑÂΩ±Èüø„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÊè≠Á§∫ÔºåÁ≠îÊ°àÈÅ∏È†Ö‰∏≠ÊâÄÂ≠∏Ë¶èÂæãÁöÑÂ∑ÆÁï∞ÂèØ‰ª•È†êÊ∏¨Ê®°ÂûãÂÅèÂ•Ω‰∏¶ÂèçÊò†‰∫∫È°ûÁöÑÊáâË©¶Á≠ñÁï•„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜÂÖ©Á®ÆÊñ∞ÊñπÊ≥ïÔºöÂèç‰∫ãÂØ¶ÊèêÁ§∫ËàáÊÄùËÄÉÈèà (CoT) ÂíåÂèç‰∫ãÂØ¶ÊèêÁ§∫Ëàá‰∏çÂèØÁü•È†êÂÖàÊèêÁ§∫ÁöÑ CoT (APriCoT)„ÄÇÊàëÂÄëË≠âÊòéÔºåÈõñÁÑ∂ÂÉÖ‰ΩøÁî®Âèç‰∫ãÂØ¶ÊèêÁ§∫Ëàá CoT ‰∏çË∂≥‰ª•Ê∏õËºïÂÅèË¶ãÔºå‰ΩÜÊàëÂÄëÊñ∞Á©éÁöÑÈ†êÂÖàÂèç‰∫ãÂØ¶ÊèêÁ§∫Ëàá CoT ÊñπÊ≥ïÊúâÊïàÈôç‰Ωé‰∫ÜÂü∫Êú¨ÊØîÁéáÊ©üÁéáÁöÑÂΩ±ÈüøÔºåÂêåÊôÇÊèêÈ´ò‰∫ÜÊï¥È´îÊ∫ñÁ¢∫Â∫¶„ÄÇÊàëÂÄëÁöÑÁµêÊûúË°®ÊòéÔºåÊ∏õËºïÂÅèË¶ãÈúÄË¶Å‰∏ÄÂÄãÈ°û‰ººÊñº„ÄåÁ≥ªÁµ± 2„ÄçÁöÑÈÅéÁ®ãÔºå‰∏¶‰∏î CoT Êé®ÁêÜÂú®Êüê‰∫õÊèêÁ§∫ÊñπÊ≥ï‰∏ãÂÆπÊòìÂèóÂà∞Á¢∫Ë™çÂÅèË¶ãÁöÑÂΩ±Èüø„ÄÇÊàëÂÄëÁöÑË≤¢ÁçªÁÇ∫ÈñãÁôºÊõ¥ÂÅ•ÂÖ®ÂíåÂÖ¨Âπ≥ÁöÑË™ûË®ÄÊ®°ÂûãÊèê‰æõ‰∫ÜÂØ¶Áî®ÁöÑËß£Ê±∫ÊñπÊ°à„ÄÇ

##### **An End-to-End Model for Photo-Sharing Multi-modal Dialogue Generation**
2408.08650v1 by Peiming Guo, Sinuo Liu, Yanzhao Zhang, Dingkun Long, Pengjun Xie, Meishan Zhang, Min Zhang

Photo-Sharing Multi-modal dialogue generation requires a dialogue agent not
only to generate text responses but also to share photos at the proper moment.
Using image text caption as the bridge, a pipeline model integrates an image
caption model, a text generation model, and an image generation model to handle
this complex multi-modal task. However, representing the images with text
captions may loss important visual details and information and cause error
propagation in the complex dialogue system. Besides, the pipeline model
isolates the three models separately because discrete image text captions
hinder end-to-end gradient propagation. We propose the first end-to-end model
for photo-sharing multi-modal dialogue generation, which integrates an image
perceptron and an image generator with a large language model. The large
language model employs the Q-Former to perceive visual images in the input end.
For image generation in the output end, we propose a dynamic vocabulary
transformation matrix and use straight-through and gumbel-softmax techniques to
align the large language model and stable diffusion model and achieve
end-to-end gradient propagation. We perform experiments on PhotoChat and
DialogCC datasets to evaluate our end-to-end model. Compared with pipeline
models, the end-to-end model gains state-of-the-art performances on various
metrics of text and image generation. More analysis experiments also verify the
effectiveness of the end-to-end model for photo-sharing multi-modal dialogue
generation.

ÊëòË¶ÅÔºöÁÖßÁâáÂàÜ‰∫´Â§öÊ®°ÊÄÅÂØπËØùÁîüÊàêÈúÄË¶Å‰∏Ä‰∏™ÂØπËØù‰ª£ÁêÜÔºå‰∏ç‰ªÖË¶ÅÁîüÊàêÊñáÊú¨ÂìçÂ∫îÔºåËøòË¶ÅÂú®ÈÄÇÂΩìÁöÑÊó∂ÂàªÂàÜ‰∫´ÁÖßÁâá„ÄÇ‰ΩøÁî®ÂõæÂÉèÊñáÊú¨Ê†áÈ¢ò‰Ωú‰∏∫Ê°•Ê¢ÅÔºåÁÆ°ÈÅìÊ®°ÂûãÈõÜÊàê‰∫Ü‰∏Ä‰∏™ÂõæÂÉèÊ†áÈ¢òÊ®°Âûã„ÄÅ‰∏Ä‰∏™ÊñáÊú¨ÁîüÊàêÊ®°ÂûãÂíå‰∏Ä‰∏™ÂõæÂÉèÁîüÊàêÊ®°ÂûãÊù•Â§ÑÁêÜËøô‰∏™Â§çÊùÇÁöÑÂ§öÊ®°ÊÄÅ‰ªªÂä°„ÄÇÁÑ∂ËÄåÔºåÁî®ÊñáÊú¨Ê†áÈ¢òË°®Á§∫ÂõæÂÉèÂèØËÉΩ‰ºö‰∏¢Â§±ÈáçË¶ÅÁöÑËßÜËßâÁªÜËäÇÂíå‰ø°ÊÅØÔºåÂπ∂ÂØºËá¥Â§çÊùÇÂØπËØùÁ≥ªÁªü‰∏≠ÁöÑÈîôËØØ‰º†Êí≠„ÄÇÊ≠§Â§ñÔºåÁÆ°ÈÅìÊ®°ÂûãÂ∞ÜËøô‰∏â‰∏™Ê®°ÂûãÂàÜÂà´ÈöîÁ¶ªÔºåÂõ†‰∏∫Á¶ªÊï£ÂõæÂÉèÊñáÊú¨Ê†áÈ¢òÈòªÁ¢ç‰∫ÜÁ´ØÂà∞Á´ØÁöÑÊ¢ØÂ∫¶‰º†Êí≠„ÄÇÊàë‰ª¨ÊèêÂá∫‰∫ÜÁ¨¨‰∏Ä‰∏™Áî®‰∫éÁÖßÁâáÂàÜ‰∫´Â§öÊ®°ÊÄÅÂØπËØùÁîüÊàêÁöÑÁ´ØÂà∞Á´ØÊ®°ÂûãÔºåÂÆÉÂ∞ÜÂõæÂÉèÊÑüÁü•Âô®ÂíåÂõæÂÉèÁîüÊàêÂô®‰∏éÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÈõÜÊàêÂú®‰∏ÄËµ∑„ÄÇÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÈááÁî® Q-Former Âú®ËæìÂÖ•Á´ØÊÑüÁü•ËßÜËßâÂõæÂÉè„ÄÇÂØπ‰∫éËæìÂá∫Á´ØÁöÑÂõæÂÉèÁîüÊàêÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏Ä‰∏™Âä®ÊÄÅËØçÊ±áËΩ¨Êç¢Áü©ÈòµÔºåÂπ∂‰ΩøÁî®Áõ¥ÈÄöÂíå gumbel-softmax ÊäÄÊúØÊù•ÂØπÈΩêÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÂíåÁ®≥ÂÆöÊâ©Êï£Ê®°ÂûãÔºåÂπ∂ÂÆûÁé∞Á´ØÂà∞Á´ØÁöÑÊ¢ØÂ∫¶‰º†Êí≠„ÄÇÊàë‰ª¨Âú® PhotoChat Âíå DialogCC Êï∞ÊçÆÈõÜ‰∏äÊâßË°åÂÆûÈ™åÔºå‰ª•ËØÑ‰º∞Êàë‰ª¨ÁöÑÁ´ØÂà∞Á´ØÊ®°Âûã„ÄÇ‰∏éÁÆ°ÈÅìÊ®°ÂûãÁõ∏ÊØîÔºåÁ´ØÂà∞Á´ØÊ®°ÂûãÂú®ÊñáÊú¨ÂíåÂõæÂÉèÁîüÊàêÁöÑ‰∏çÂêåÊåáÊ†á‰∏äËé∑Âæó‰∫ÜÊúÄÂÖàËøõÁöÑÊÄßËÉΩ„ÄÇÊõ¥Â§öÁöÑÂàÜÊûêÂÆûÈ™å‰πüÈ™åËØÅ‰∫ÜÁ´ØÂà∞Á´ØÊ®°ÂûãÂú®ÁÖßÁâáÂàÜ‰∫´Â§öÊ®°ÊÄÅÂØπËØùÁîüÊàê‰∏≠ÁöÑÊúâÊïàÊÄß„ÄÇ

##### **Understanding Enthymemes in Argument Maps: Bridging Argument Mining and Logic-based Argumentation**
2408.08648v1 by Jonathan Ben-Naim, Victor David, Anthony Hunter

Argument mining is natural language processing technology aimed at
identifying arguments in text. Furthermore, the approach is being developed to
identify the premises and claims of those arguments, and to identify the
relationships between arguments including support and attack relationships. In
this paper, we assume that an argument map contains the premises and claims of
arguments, and support and attack relationships between them, that have been
identified by argument mining. So from a piece of text, we assume an argument
map is obtained automatically by natural language processing. However, to
understand and to automatically analyse that argument map, it would be
desirable to instantiate that argument map with logical arguments. Once we have
the logical representation of the arguments in an argument map, we can use
automated reasoning to analyze the argumentation (e.g. check consistency of
premises, check validity of claims, and check the labelling on each arc
corresponds with thw logical arguments). We address this need by using
classical logic for representing the explicit information in the text, and
using default logic for representing the implicit information in the text. In
order to investigate our proposal, we consider some specific options for
instantiation.

ÊëòË¶ÅÔºöË´ñË≠âÊåñÊéòÊòØ‰∏ÄÁ®ÆËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜÊäÄË°ìÔºåÊó®Âú®Ëæ®Ë≠òÊñáÊú¨‰∏≠ÁöÑË´ñË≠â„ÄÇÊ≠§Â§ñÔºåÈÄôÁ®ÆÊñπÊ≥ïË¢´ÈñãÁôºÂá∫‰æÜÔºå‰ª•Ëæ®Ë≠òÈÄô‰∫õË´ñË≠âÁöÑÂâçÊèêÂíå‰∏ªÂºµÔºå‰∏¶Ëæ®Ë≠òË´ñË≠â‰πãÈñìÁöÑÈóú‰øÇÔºåÂåÖÊã¨ÊîØÊåÅÂíåÊîªÊìäÈóú‰øÇ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂÅáË®≠‰∏ÄÂÄãË´ñË≠âÂúñÂåÖÂê´Ë´ñË≠âÁöÑÂâçÊèêÂíå‰∏ªÂºµÔºå‰ª•ÂèäÂÆÉÂÄë‰πãÈñìÁöÑÊîØÊè¥ÂíåÊîªÊìäÈóú‰øÇÔºåÈÄô‰∫õÈóú‰øÇÂ∑≤Áî±Ë´ñË≠âÊåñÊéòËæ®Ë≠òÂá∫‰æÜ„ÄÇÂõ†Ê≠§ÔºåÂæû‰∏ÄÊÆµÊñáÊú¨‰∏≠ÔºåÊàëÂÄëÂÅáË®≠‰∏ÄÂÄãË´ñË≠âÂúñÊòØÁî±Ëá™ÁÑ∂Ë™ûË®ÄËôïÁêÜËá™ÂãïÁç≤ÂæóÁöÑ„ÄÇÁÑ∂ËÄåÔºåÁÇ∫‰∫ÜÁêÜËß£‰∏¶Ëá™ÂãïÂàÜÊûêË©≤Ë´ñË≠âÂúñÔºåÊúÄÂ•Ω‰ΩøÁî®ÈÇèËºØË´ñË≠â‰æÜÂØ¶‰æãÂåñË©≤Ë´ñË≠âÂúñ„ÄÇ‰∏ÄÊó¶ÊàëÂÄëÂú®Ë´ñË≠âÂúñ‰∏≠Áç≤Âæó‰∫ÜË´ñË≠âÁöÑÈÇèËºØË°®Á§∫ÔºåÊàëÂÄëÂ∞±ÂèØ‰ª•‰ΩøÁî®Ëá™ÂãïÊé®ÁêÜ‰æÜÂàÜÊûêË´ñË≠âÔºà‰æãÂ¶ÇÔºåÊ™¢Êü•ÂâçÊèêÁöÑ‰∏ÄËá¥ÊÄß„ÄÅÊ™¢Êü•‰∏ªÂºµÁöÑÊúâÊïàÊÄßÔºå‰ª•ÂèäÊ™¢Êü•ÊØèÂÄãÂºß‰∏äÁöÑÊ®ôÁ±§ÊòØÂê¶ËàáÈÇèËºØË´ñË≠âÁõ∏Á¨¶Ôºâ„ÄÇÊàëÂÄëÈÄèÈÅé‰ΩøÁî®Á∂ìÂÖ∏ÈÇèËºØ‰æÜË°®Á§∫ÊñáÊú¨‰∏≠ÁöÑÊòéÁ¢∫Ë≥áË®äÔºå‰∏¶‰ΩøÁî®È†êË®≠ÈÇèËºØ‰æÜË°®Á§∫ÊñáÊú¨‰∏≠ÁöÑÈö±Âê´Ë≥áË®äÔºå‰æÜÊªøË∂≥ÈÄôÂÄãÈúÄÊ±Ç„ÄÇÁÇ∫‰∫ÜË™øÊü•ÊàëÂÄëÁöÑÊèêÊ°àÔºåÊàëÂÄëËÄÉÊÖÆ‰∫Ü‰∏Ä‰∫õÂØ¶‰æãÂåñÁöÑÁâπÂÆöÈÅ∏È†Ö„ÄÇ

##### **Math-PUMA: Progressive Upward Multimodal Alignment to Enhance Mathematical Reasoning**
2408.08640v1 by Wenwen Zhuang, Xin Huang, Xiantao Zhang, Jin Zeng

Multimodal Large Language Models (MLLMs) excel in solving text-based
mathematical problems, but they struggle with mathematical diagrams since they
are primarily trained on natural scene images. For humans, visual aids
generally enhance problem-solving, but MLLMs perform worse as information
shifts from textual to visual modality. This decline is mainly due to their
shortcomings in aligning images and text. To tackle aforementioned challenges,
we propose Math-PUMA, a methodology focused on Progressive Upward Multimodal
Alignment. This approach is designed to improve the mathematical reasoning
skills of MLLMs through a three-stage training process, with the second stage
being the critical alignment stage. We first enhance the language model's
mathematical reasoning capabilities with extensive set of textual mathematical
problems. We then construct a multimodal dataset with varying degrees of
textual and visual information, creating data pairs by presenting each problem
in at least two forms. By leveraging the Kullback-Leibler (KL) divergence of
next-token prediction distributions to align visual and textual modalities,
consistent problem-solving abilities are ensured. Finally, we utilize
multimodal instruction tuning for MLLMs with high-quality multimodal data.
Experimental results on multiple mathematical reasoning benchmarks demonstrate
that the MLLMs trained with Math-PUMA surpass most open-source MLLMs. Our
approach effectively narrows the performance gap for problems presented in
different modalities.

ÊëòË¶ÅÔºöÂ§öÊ®°ÊÖãÂ§ßÂûãË™ûË®ÄÊ®°Âûã (MMLM) ÊìÖÊñºËß£Ê±∫Âü∫ÊñºÊñáÂ≠óÁöÑÊï∏Â≠∏ÂïèÈ°åÔºå‰ΩÜÂÆÉÂÄëÂú®ËôïÁêÜÊï∏Â≠∏ÂúñË°®ÊôÇÊúÉÈÅáÂà∞Âõ∞Èõ£ÔºåÂõ†ÁÇ∫ÂÆÉÂÄë‰∏ªË¶ÅÂú®Ëá™ÁÑ∂Â†¥ÊôØÂúñÂÉè‰∏äÈÄ≤Ë°åË®ìÁ∑¥„ÄÇÂ∞çÊñº‰∫∫È°û‰æÜË™™ÔºåË¶ñË¶∫ËºîÂä©ÈÄöÂ∏∏ÂèØ‰ª•Â¢ûÂº∑ÂïèÈ°åËß£Ê±∫ËÉΩÂäõÔºå‰ΩÜÁï∂Ë≥áË®äÂæûÊñáÂ≠óÊ®°ÂºèËΩâÊèõÁÇ∫Ë¶ñË¶∫Ê®°ÂºèÊôÇÔºåMMLM ÁöÑË°®ÁèæÊúÉËÆäÂ∑Æ„ÄÇÈÄôÁ®ÆË°∞ÈÄÄ‰∏ªË¶ÅÊòØÂõ†ÁÇ∫ÂÆÉÂÄëÂú®Â∞çÈΩäÂúñÂÉèÂíåÊñáÂ≠óÊôÇÊúâÁº∫Èô∑„ÄÇÁÇ∫‰∫ÜÊáâÂ∞ç‰∏äËø∞ÊåëÊà∞ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü Math-PUMAÔºåÈÄôÊòØ‰∏ÄÁ®ÆÂ∞àÊ≥®ÊñºÊº∏ÈÄ≤Âêë‰∏äÂ§öÊ®°ÊÖãÂ∞çÈΩäÁöÑÊñπÊ≥ï„ÄÇÈÄôÁ®ÆÊñπÊ≥ïÊó®Âú®ÈÄöÈÅé‰∏âÈöéÊÆµË®ìÁ∑¥ÈÅéÁ®ã‰æÜÊîπÂñÑ MMLM ÁöÑÊï∏Â≠∏Êé®ÁêÜÊäÄËÉΩÔºåÂÖ∂‰∏≠Á¨¨‰∫åÈöéÊÆµÊòØÈóúÈçµÂ∞çÈΩäÈöéÊÆµ„ÄÇÊàëÂÄëÈ¶ñÂÖà‰ΩøÁî®Â§ßÈáèÁöÑÊñáÂ≠óÊï∏Â≠∏ÂïèÈ°å‰æÜÂ¢ûÂº∑Ë™ûË®ÄÊ®°ÂûãÁöÑÊï∏Â≠∏Êé®ÁêÜËÉΩÂäõ„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÊßãÂª∫‰∫Ü‰∏ÄÂÄãÂÖ∑Êúâ‰∏çÂêåÁ®ãÂ∫¶ÊñáÂ≠óÂíåË¶ñË¶∫Ë≥áË®äÁöÑÂ§öÊ®°ÊÖãË≥áÊñôÈõÜÔºåÈÄöÈÅé‰ª•Ëá≥Â∞ëÂÖ©Á®ÆÂΩ¢ÂºèÂëàÁèæÊØèÂÄãÂïèÈ°å‰æÜÂª∫Á´ãË≥áÊñôÂ∞ç„ÄÇÈÄèÈÅéÂà©Áî® Kullback-Leibler (KL) Â∑ÆÁï∞‰æÜÂ∞çÈΩäË¶ñË¶∫ÂíåÊñáÂ≠óÊ®°ÂºèÁöÑÂæåÁ∫åË©ûÂΩôÈ†êÊ∏¨ÂàÜ‰ΩàÔºåÁ¢∫‰øù‰∫Ü‰∏ÄËá¥ÁöÑÂïèÈ°åËß£Ê±∫ËÉΩÂäõ„ÄÇÊúÄÂæåÔºåÊàëÂÄëÂà©Áî®È´òÂìÅË≥™ÁöÑÂ§öÊ®°ÊÖãË≥áÊñôÁÇ∫ MMLM ÈÄ≤Ë°åÂ§öÊ®°ÊÖãÊåá‰ª§ÂæÆË™ø„ÄÇÂú®Â§öÂÄãÊï∏Â≠∏Êé®ÁêÜÂü∫Ê∫ñ‰∏äÁöÑÂØ¶È©óÁµêÊûúË°®ÊòéÔºå‰ΩøÁî® Math-PUMA Ë®ìÁ∑¥ÁöÑ MMLM Ë∂ÖË∂ä‰∫ÜÂ§ßÂ§öÊï∏ÈñãÊ∫ê MMLM„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÊúâÊïàÁ∏ÆÂ∞è‰∫Ü‰ª•‰∏çÂêåÊ®°ÂºèÂëàÁèæÁöÑÂïèÈ°åÁöÑÊïàËÉΩÂ∑ÆË∑ù„ÄÇ

##### **A Survey on Benchmarks of Multimodal Large Language Models**
2408.08632v1 by Jian Li, Weiheng Lu

Multimodal Large Language Models (MLLMs) are gaining increasing popularity in
both academia and industry due to their remarkable performance in various
applications such as visual question answering, visual perception,
understanding, and reasoning. Over the past few years, significant efforts have
been made to examine MLLMs from multiple perspectives. This paper presents a
comprehensive review of \textbf{180 benchmarks} and evaluation for MLLMs,
focusing on (1)perception and understanding, (2)cognition and reasoning,
(3)specific domains, (4)key capabilities, and (5)other modalities. Finally, we
discuss the limitations of the current evaluation methods for MLLMs and explore
promising future directions. Our key argument is that evaluation should be
regarded as a crucial discipline to better support the development of MLLMs.
For more details, please visit our GitHub repository:
https://github.com/swordlidev/Evaluation-Multimodal-LLMs-Survey.

ÊëòË¶ÅÔºöÂ§öÊ®°ÊÄÅÂ§ßÂûãËØ≠Ë®ÄÊ®°Âûã (MLLM) Âú®Â≠¶ÊúØÁïåÂíåÂ∑•‰∏öÁïå‰∏≠Ë∂äÊù•Ë∂äÂèóÊ¨¢ËøéÔºåËøôÊòØÂõ†‰∏∫ÂÆÉ‰ª¨Âú®ËßÜËßâÈóÆÈ¢òËß£Á≠î„ÄÅËßÜËßâÊÑüÁü•„ÄÅÁêÜËß£ÂíåÊé®ÁêÜÁ≠âÂêÑÁßçÂ∫îÁî®‰∏≠Ë°®Áé∞Âá∫Ëâ≤„ÄÇÂú®ËøáÂéªÂá†Âπ¥‰∏≠Ôºå‰∫∫‰ª¨Â∑≤ÁªèÂÅöÂá∫‰∫ÜÂ∑®Â§ßÁöÑÂä™ÂäõÔºå‰ªéÂ§ö‰∏™ËßíÂ∫¶ÂØπ MLLM ËøõË°å‰∫ÜÁ†îÁ©∂„ÄÇÊú¨ÊñáÂØπ**180 ‰∏™Âü∫ÂáÜ**Âíå MLLM ËØÑ‰º∞ËøõË°å‰∫ÜÂÖ®Èù¢ÂõûÈ°æÔºåÈáçÁÇπÂÖ≥Ê≥® (1) ÊÑüÁü•ÂíåÁêÜËß£„ÄÅ(2) ËÆ§Áü•ÂíåÊé®ÁêÜ„ÄÅ(3) ÁâπÂÆöÈ¢ÜÂüü„ÄÅ(4) ÂÖ≥ÈîÆËÉΩÂäõÂíå (5) ÂÖ∂‰ªñÊ®°ÊÄÅ„ÄÇÊúÄÂêéÔºåÊàë‰ª¨ËÆ®ËÆ∫‰∫ÜÂΩìÂâç MLLM ËØÑ‰º∞ÊñπÊ≥ïÁöÑÂ±ÄÈôêÊÄßÔºåÂπ∂Êé¢ËÆ®‰∫ÜÊúâÂâçÊôØÁöÑÊú™Êù•ÊñπÂêë„ÄÇÊàë‰ª¨ÁöÑÂÖ≥ÈîÆËÆ∫ÁÇπÊòØÔºåËØÑ‰º∞Â∫îË¢´ËßÜ‰∏∫‰∏ÄÈ°πËá≥ÂÖ≥ÈáçË¶ÅÁöÑÂ≠¶ÁßëÔºå‰ª•Êõ¥Â•ΩÂú∞ÊîØÊåÅ MLLM ÁöÑÂèëÂ±ï„ÄÇÊúâÂÖ≥Êõ¥Â§öËØ¶ÁªÜ‰ø°ÊÅØÔºåËØ∑ËÆøÈóÆÊàë‰ª¨ÁöÑ GitHub Â≠òÂÇ®Â∫ìÔºö
https://github.com/swordlidev/Evaluation-Multimodal-LLMs-Survey„ÄÇ

##### **Persona is a Double-edged Sword: Enhancing the Zero-shot Reasoning by Ensembling the Role-playing and Neutral Prompts**
2408.08631v1 by Junseok Kim, Nakyeong Yang, Kyomin Jung

Recent studies demonstrate that prompting an appropriate role-playing persona
to an LLM improves its reasoning capability. However, assigning a proper
persona is difficult since an LLM's performance is extremely sensitive to
assigned prompts; therefore, personas sometimes hinder LLMs and degrade their
reasoning capabilities. In this paper, we propose a novel framework, Jekyll \&
Hyde, which ensembles the results of role-playing and neutral prompts to
eradicate performance degradation via unilateral use of role-playing prompted
LLM and enhance the robustness of an LLM's reasoning ability. Specifically,
Jekyll \& Hyde collects two potential solutions from both role-playing and
neutral prompts and selects a better solution after cross-checking via an LLM
evaluator. However, LLM-based evaluators tend to be affected by the order of
those potential solutions within the prompt when selecting the proper solution;
thus, we also propose a robust LLM evaluator to mitigate the position bias. The
experimental analysis demonstrates that role-playing prompts distract LLMs and
degrade their reasoning abilities in 4 out of 12 datasets, even when using
GPT-4. In addition, we reveal that Jekyll \& Hyde improves reasoning
capabilities by selecting better choices among the potential solutions on
twelve widely-used reasoning datasets. We further show that our proposed LLM
evaluator outperforms other baselines, proving the LLMs' position bias is
successfully mitigated.

ÊëòË¶ÅÔºöÊúÄËøëÁöÑÁ†îÁ©∂Ë°®ÊòéÔºåÊèêÁ§∫ LLM ÊâÆÊºîÈÄÇÂΩìÁöÑËßíËâ≤ÊâÆÊºîËßíËâ≤ÂèØ‰ª•ÊèêÈ´òÂÖ∂Êé®ÁêÜËÉΩÂäõ„ÄÇÁÑ∂ËÄåÔºåÊåáÂÆöÈÄÇÂΩìÁöÑËßíËâ≤ÂæàÈöæÔºåÂõ†‰∏∫ LLM ÁöÑÊÄßËÉΩÂØπÊåáÂÆöÁöÑÊèêÁ§∫ÊûÅÂÖ∂ÊïèÊÑüÔºõÂõ†Ê≠§ÔºåËßíËâ≤ÊúâÊó∂‰ºöÈòªÁ¢ç LLM Âπ∂Èôç‰ΩéÂÖ∂Êé®ÁêÜËÉΩÂäõ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏Ä‰∏™Êñ∞Ê°ÜÊû∂ Jekyll Âíå HydeÔºåÂÆÉÈõÜÂêà‰∫ÜËßíËâ≤ÊâÆÊºîÂíå‰∏≠Á´ãÊèêÁ§∫ÁöÑÁªìÊûúÔºåÈÄöËøáÂçïÊñπÈù¢‰ΩøÁî®ËßíËâ≤ÊâÆÊºîÊèêÁ§∫ÁöÑ LLM Êù•Ê∂àÈô§ÊÄßËÉΩ‰∏ãÈôçÔºåÂπ∂Â¢ûÂº∫ LLM Êé®ÁêÜËÉΩÂäõÁöÑÈ≤ÅÊ£íÊÄß„ÄÇÂÖ∑‰ΩìËÄåË®ÄÔºåJekyll Âíå Hyde ‰ªéËßíËâ≤ÊâÆÊºîÂíå‰∏≠Á´ãÊèêÁ§∫‰∏≠Êî∂ÈõÜ‰∏§‰∏™ÊΩúÂú®ÁöÑËß£ÂÜ≥ÊñπÊ°àÔºåÂπ∂Âú®ÈÄöËøá LLM ËØÑ‰º∞Âô®‰∫§ÂèâÊ£ÄÊü•ÂêéÈÄâÊã©Êõ¥Â•ΩÁöÑËß£ÂÜ≥ÊñπÊ°à„ÄÇÁÑ∂ËÄåÔºåÂü∫‰∫é LLM ÁöÑËØÑ‰º∞Âô®Âú®ÈÄâÊã©ÈÄÇÂΩìÁöÑËß£ÂÜ≥ÊñπÊ°àÊó∂ÂæÄÂæÄ‰ºöÂèóÂà∞ÊèêÁ§∫‰∏≠Ëøô‰∫õÊΩúÂú®Ëß£ÂÜ≥ÊñπÊ°àÁöÑÈ°∫Â∫èÁöÑÂΩ±ÂìçÔºõÂõ†Ê≠§ÔºåÊàë‰ª¨ËøòÊèêÂá∫‰∫Ü‰∏Ä‰∏™È≤ÅÊ£íÁöÑ LLM ËØÑ‰º∞Âô®Êù•ÂáèËΩª‰ΩçÁΩÆÂÅèÂ∑Æ„ÄÇÂÆûÈ™åÂàÜÊûêË°®ÊòéÔºåÂç≥‰Ωø‰ΩøÁî® GPT-4ÔºåËßíËâ≤ÊâÆÊºîÊèêÁ§∫‰πü‰ºöÂàÜÊï£ LLM ÁöÑÊ≥®ÊÑèÂäõÔºåÂπ∂Âú® 12 ‰∏™Êï∞ÊçÆÈõÜ‰∏≠Êúâ 4 ‰∏™Êï∞ÊçÆÈõÜÈôç‰ΩéÂÖ∂Êé®ÁêÜËÉΩÂäõ„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨Êè≠Á§∫‰∫Ü Jekyll Âíå Hyde ÈÄöËøáÂú®ÂçÅ‰∫å‰∏™ÂπøÊ≥õ‰ΩøÁî®ÁöÑÊé®ÁêÜÊï∞ÊçÆÈõÜ‰∏≠‰ªéÊΩúÂú®Ëß£ÂÜ≥ÊñπÊ°à‰∏≠ÈÄâÊã©Êõ¥Â•ΩÁöÑÈÄâÊã©Êù•ÊèêÈ´òÊé®ÁêÜËÉΩÂäõ„ÄÇÊàë‰ª¨Ëøõ‰∏ÄÊ≠•Ë°®ÊòéÔºåÊàë‰ª¨ÊèêÂá∫ÁöÑ LLM ËØÑ‰º∞Âô®‰ºò‰∫éÂÖ∂‰ªñÂü∫Á∫øÔºåËØÅÊòé LLM ÁöÑ‰ΩçÁΩÆÂÅèÂ∑ÆÂ∑≤ÊàêÂäüÂáèËΩª„ÄÇ

##### **RealMedQA: A pilot biomedical question answering dataset containing realistic clinical questions**
2408.08624v1 by Gregory Kell, Angus Roberts, Serge Umansky, Yuti Khare, Najma Ahmed, Nikhil Patel, Chloe Simela, Jack Coumbe, Julian Rozario, Ryan-Rhys Griffiths, Iain J. Marshall

Clinical question answering systems have the potential to provide clinicians
with relevant and timely answers to their questions. Nonetheless, despite the
advances that have been made, adoption of these systems in clinical settings
has been slow. One issue is a lack of question-answering datasets which reflect
the real-world needs of health professionals. In this work, we present
RealMedQA, a dataset of realistic clinical questions generated by humans and an
LLM. We describe the process for generating and verifying the QA pairs and
assess several QA models on BioASQ and RealMedQA to assess the relative
difficulty of matching answers to questions. We show that the LLM is more
cost-efficient for generating "ideal" QA pairs. Additionally, we achieve a
lower lexical similarity between questions and answers than BioASQ which
provides an additional challenge to the top two QA models, as per the results.
We release our code and our dataset publicly to encourage further research.

ÊëòË¶ÅÔºöËá®Â∫äÂïèÁ≠îÁ≥ªÁµ±ÂÖ∑ÊúâÊèê‰æõËá®Â∫äÈÜ´ÁîüÁõ∏Èóú‰∏îÂèäÊôÇÁöÑÁ≠îÊ°àÁöÑÊΩõÂäõ„ÄÇÂÑòÁÆ°Â¶ÇÊ≠§ÔºåÂÑòÁÆ°ÂèñÂæó‰∫ÜÈÄ≤Â±ïÔºå‰ΩÜÂú®Ëá®Â∫äÁí∞Â¢É‰∏≠Êé°Áî®ÈÄô‰∫õÁ≥ªÁµ±ÁöÑÈÄüÂ∫¶ÂæàÊÖ¢„ÄÇ‰∏ÄÂÄãÂïèÈ°åÊòØÁº∫‰πèÂèçÊò†ÈÜ´ÁôÇÂ∞àÊ•≠‰∫∫Âì°ÁèæÂØ¶ÈúÄÊ±ÇÁöÑÂïèÁ≠îË≥áÊñôÈõÜ„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü RealMedQAÔºåÈÄôÊòØ‰∏ÄÂÄãÁî±‰∫∫È°ûÂíå LLM ÁîüÊàêÁöÑÁèæÂØ¶Ëá®Â∫äÂïèÈ°åË≥áÊñôÈõÜ„ÄÇÊàëÂÄëÊèèËø∞‰∫ÜÁîüÊàêÂíåÈ©óË≠â QA Â∞çÁöÑÈÅéÁ®ãÔºå‰∏¶Âú® BioASQ Âíå RealMedQA ‰∏äË©ï‰º∞‰∫ÜÂπæÂÄã QA Ê®°ÂûãÔºå‰ª•Ë©ï‰º∞Â∞áÁ≠îÊ°àËàáÂïèÈ°åÂåπÈÖçÁöÑÁõ∏Â∞çÈõ£Â∫¶„ÄÇÊàëÂÄëË°®ÊòéÔºåLLM Âú®ÁîüÊàê„ÄåÁêÜÊÉ≥„ÄçÁöÑ QA Â∞çÊñπÈù¢Êõ¥ÂÖ∑ÊàêÊú¨ÊïàÁõä„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂú®ÂïèÈ°åÂíåÁ≠îÊ°à‰πãÈñìÂØ¶Áèæ‰∫ÜÊØî BioASQ Êõ¥‰ΩéÁöÑË©ûÂΩôÁõ∏‰ººÊÄßÔºåÊ†πÊìöÁµêÊûúÔºåÈÄôÂ∞çÂâçÂÖ©ÂÄã QA Ê®°ÂûãÊèêÂá∫‰∫ÜÈ°çÂ§ñÁöÑÊåëÊà∞„ÄÇÊàëÂÄëÂÖ¨ÈñãÁôºÂ∏ÉÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÂíåË≥áÊñôÈõÜÔºå‰ª•ÈºìÂãµÈÄ≤‰∏ÄÊ≠•ÁöÑÁ†îÁ©∂„ÄÇ

##### **DeepDFA: Automata Learning through Neural Probabilistic Relaxations**
2408.08622v1 by Elena Umili, Roberto Capobianco

In this work, we introduce DeepDFA, a novel approach to identifying
Deterministic Finite Automata (DFAs) from traces, harnessing a differentiable
yet discrete model. Inspired by both the probabilistic relaxation of DFAs and
Recurrent Neural Networks (RNNs), our model offers interpretability
post-training, alongside reduced complexity and enhanced training efficiency
compared to traditional RNNs. Moreover, by leveraging gradient-based
optimization, our method surpasses combinatorial approaches in both scalability
and noise resilience. Validation experiments conducted on target regular
languages of varying size and complexity demonstrate that our approach is
accurate, fast, and robust to noise in both the input symbols and the output
labels of training data, integrating the strengths of both logical grammar
induction and deep learning.

ÊëòË¶ÅÔºöÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫Ü DeepDFAÔºå‰∏ÄÁ®ÆÂæûËªåË∑°‰∏≠Ë≠òÂà•Á¢∫ÂÆöÊúâÈôêËá™ÂãïÊ©ü (DFA) ÁöÑÊñ∞ÊñπÊ≥ïÔºåÂà©Áî®ÂèØÂæÆÂàÜ‰ΩÜÈõ¢Êï£ÁöÑÊ®°Âûã„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÈùàÊÑü‰æÜËá™ DFA ÁöÑÊ©üÁéáÈ¨ÜÂºõÂíåÈÅûËø¥Á•ûÁ∂ìÁ∂≤Ë∑Ø (RNN)ÔºåÂú®Ë®ìÁ∑¥ÂæåÊèê‰æõÂèØËß£ÈáãÊÄßÔºåÂêåÊôÇÈôç‰Ωé‰∫ÜË§áÈõúÂ∫¶‰∏¶ÊèêÈ´ò‰∫ÜË®ìÁ∑¥ÊïàÁéáÔºåËàáÂÇ≥Áµ±ÁöÑ RNN Áõ∏ÊØî„ÄÇÊ≠§Â§ñÔºåÈÄèÈÅéÂà©Áî®Âü∫ÊñºÊ¢ØÂ∫¶ÁöÑÊúÄ‰Ω≥ÂåñÔºåÊàëÂÄëÁöÑÊ®°ÂûãÂú®ÂèØÊì¥ÂÖÖÊÄßÂíåÊäóÈõúË®äÊÄßÊñπÈù¢ÈÉΩË∂ÖË∂ä‰∫ÜÁµÑÂêàÊñπÊ≥ï„ÄÇÈáùÂ∞ç‰∏çÂêåÂ§ßÂ∞èÂíåË§áÈõúÂ∫¶ÁöÑÁõÆÊ®ôÊ≠£Ë¶èË™ûË®ÄÈÄ≤Ë°åÁöÑÈ©óË≠âÂØ¶È©óË≠âÊòéÔºåÊàëÂÄëÁöÑÊ®°ÂûãÂú®Ë®ìÁ∑¥Ë≥áÊñôÁöÑËº∏ÂÖ•Á¨¶ËôüÂíåËº∏Âá∫Ê®ôÁ±§‰∏≠ÈÉΩÊ∫ñÁ¢∫„ÄÅÂø´ÈÄü‰∏îÂÖ∑ÊúâÊäóÈõúË®äÊÄßÔºåÊï¥Âêà‰∫ÜÈÇèËºØË™ûÊ≥ïÊ≠∏Á¥çÂíåÊ∑±Â∫¶Â≠∏ÁøíÁöÑÂÑ™Èªû„ÄÇ

##### **PatUntrack: Automated Generating Patch Examples for Issue Reports without Tracked Insecure Code**
2408.08619v1 by Ziyou Jiang, Lin Shi, Guowei Yang, Qing Wang

Security patches are essential for enhancing the stability and robustness of
projects in the software community. While vulnerabilities are officially
expected to be patched before being disclosed, patching vulnerabilities is
complicated and remains a struggle for many organizations. To patch
vulnerabilities, security practitioners typically track vulnerable issue
reports (IRs), and analyze their relevant insecure code to generate potential
patches. However, the relevant insecure code may not be explicitly specified
and practitioners cannot track the insecure code in the repositories, thus
limiting their ability to generate patches. In such cases, providing examples
of insecure code and the corresponding patches would benefit the security
developers to better locate and fix the insecure code. In this paper, we
propose PatUntrack to automatically generating patch examples from IRs without
tracked insecure code. It auto-prompts Large Language Models (LLMs) to make
them applicable to analyze the vulnerabilities. It first generates the
completed description of the Vulnerability-Triggering Path (VTP) from
vulnerable IRs. Then, it corrects hallucinations in the VTP description with
external golden knowledge. Finally, it generates Top-K pairs of Insecure Code
and Patch Example based on the corrected VTP description. To evaluate the
performance, we conducted experiments on 5,465 vulnerable IRs. The experimental
results show that PatUntrack can obtain the highest performance and improve the
traditional LLM baselines by +14.6% (Fix@10) on average in patch example
generation. Furthermore, PatUntrack was applied to generate patch examples for
76 newly disclosed vulnerable IRs. 27 out of 37 replies from the authors of
these IRs confirmed the usefulness of the patch examples generated by
PatUntrack, indicating that they can benefit from these examples for patching
the vulnerabilities.

ÊëòË¶ÅÔºö<paragraph>ÂÆâÂÖ®‰øÆË£úÁ®ãÂºèÂ∞çÊñºÊèêÂçáËªüÈ´îÁ§æÁæ§‰∏≠Â∞àÊ°àÁöÑÁ©©ÂÆöÊÄßËàáÂÅ•ÂÖ®ÊÄßËá≥ÈóúÈáçË¶Å„ÄÇÈõñÁÑ∂ÊºèÊ¥ûÂú®Ë¢´Êè≠Èú≤‰πãÂâçÂÆòÊñπÈ†êÊúüÊúÉË¢´‰øÆË£úÔºå‰ΩÜ‰øÆË£úÊºèÊ¥ûÂæàË§áÈõúÔºå‰∏îÂ∞çË®±Â§öÁµÑÁπî‰æÜË™™‰ªçÊòØ‰∏ÄÈ†ÖÊåëÊà∞„ÄÇÁÇ∫‰∫Ü‰øÆË£úÊºèÊ¥ûÔºåÂÆâÂÖ®ÂæûÊ•≠‰∫∫Âì°ÈÄöÂ∏∏ÊúÉËøΩËπ§ÂÆπÊòìÂèóÊîªÊìäÁöÑÂïèÈ°åÂ†±Âëä (IR)Ôºå‰∏¶ÂàÜÊûêÂÖ∂Áõ∏ÈóúÁöÑ‰∏çÂÆâÂÖ®Á®ãÂºèÁ¢º‰ª•Áî¢ÁîüÊΩõÂú®ÁöÑ‰øÆË£úÁ®ãÂºè„ÄÇÁÑ∂ËÄåÔºåÁõ∏ÈóúÁöÑ‰∏çÂÆâÂÖ®Á®ãÂºèÁ¢ºÂèØËÉΩÊ≤íÊúâÊòéÁ¢∫ÊåáÂÆöÔºåÂæûÊ•≠‰∫∫Âì°‰πüÁÑ°Ê≥ïÂú®ÂÑ≤Â≠òÂ∫´‰∏≠ËøΩËπ§‰∏çÂÆâÂÖ®Á®ãÂºèÁ¢ºÔºåÂõ†Ê≠§ÈôêÂà∂‰∫Ü‰ªñÂÄëÁî¢Áîü‰øÆË£úÁ®ãÂºèÁöÑËÉΩÂäõ„ÄÇÂú®ÈÄôÁ®ÆÊÉÖÊ≥Å‰∏ãÔºåÊèê‰æõ‰∏çÂÆâÂÖ®Á®ãÂºèÁ¢ºÁØÑ‰æãÂíåÂ∞çÊáâ‰øÆË£úÁ®ãÂºèÂ∞áÊúâÂä©ÊñºÂÆâÂÖ®ÈñãÁôº‰∫∫Âì°Êõ¥Ê∫ñÁ¢∫Âú∞ÊâæÂá∫‰∏¶‰øÆÂæ©‰∏çÂÆâÂÖ®Á®ãÂºèÁ¢º„ÄÇÂú®Êú¨Ë´ñÊñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫ PatUntrackÔºåÁî®ÊñºÂæûÊ≤íÊúâËøΩËπ§‰∏çÂÆâÂÖ®Á®ãÂºèÁ¢ºÁöÑ IR Ëá™ÂãïÁî¢Áîü‰øÆË£úÁ®ãÂºèÁØÑ‰æã„ÄÇÂÆÉÊúÉËá™ÂãïÊèêÁ§∫Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM)ÔºåËÆìÂÆÉÂÄëÈÅ©Áî®ÊñºÂàÜÊûêÊºèÊ¥û„ÄÇÂÆÉÈ¶ñÂÖàÂæûÂÆπÊòìÂèóÊîªÊìäÁöÑ IR Áî¢ÁîüÊºèÊ¥ûËß∏ÁôºË∑ØÂæë (VTP) ÁöÑÂÆåÊï¥ÊèèËø∞„ÄÇÊé•ËëóÔºåÂÆÉÊúÉ‰ΩøÁî®Â§ñÈÉ®ÈªÉÈáëÁü•Ë≠ò‰øÆÊ≠£ VTP ÊèèËø∞‰∏≠ÁöÑÂπªË¶∫„ÄÇÊúÄÂæåÔºåÂÆÉÊúÉÊ†πÊìö‰øÆÊ≠£ÂæåÁöÑ VTP ÊèèËø∞Áî¢Áîü‰∏çÂÆâÂÖ®Á®ãÂºèÁ¢ºÂíå‰øÆË£úÁ®ãÂºèÁØÑ‰æãÁöÑ Top-K ÈÖçÂ∞ç„ÄÇÁÇ∫‰∫ÜË©ï‰º∞ÊïàËÉΩÔºåÊàëÂÄëÂ∞ç 5,465 ÂÄãÂÆπÊòìÂèóÊîªÊìäÁöÑ IR ÈÄ≤Ë°åÂØ¶È©ó„ÄÇÂØ¶È©óÁµêÊûúÈ°ØÁ§∫ÔºåPatUntrack ÂèØ‰ª•Áç≤ÂæóÊúÄÈ´òÁöÑÊïàËÉΩÔºå‰∏¶Âú®‰øÆË£úÁ®ãÂºèÁØÑ‰æãÁî¢ÁîüÊñπÈù¢Âπ≥ÂùáÂ∞áÂÇ≥Áµ± LLM Âü∫Ê∫ñÊèêÈ´ò +14.6%ÔºàFix@10Ôºâ„ÄÇÊ≠§Â§ñÔºåPatUntrack Â∑≤ÊáâÁî®ÊñºÁÇ∫ 76 ÂÄãÊñ∞Êè≠Èú≤ÁöÑÂÆπÊòìÂèóÊîªÊìä IR Áî¢Áîü‰øÆË£úÁ®ãÂºèÁØÑ‰æã„ÄÇÈÄô‰∫õ IR ‰ΩúËÄÖÁöÑ 37 Â∞ÅÂõûË¶Ü‰∏≠Êúâ 27 Â∞ÅÁ¢∫Ë™ç‰∫Ü PatUntrack ÊâÄÁî¢ÁîüÁöÑ‰øÆË£úÁ®ãÂºèÁØÑ‰æãÁöÑÂØ¶Áî®ÊÄßÔºåÈÄôË°®Á§∫‰ªñÂÄëÂèØ‰ª•Âà©Áî®ÈÄô‰∫õÁØÑ‰æã‰æÜ‰øÆË£úÊºèÊ¥û„ÄÇ</paragraph>

##### **Generative Dataset Distillation Based on Diffusion Model**
2408.08610v1 by Duo Su, Junjie Hou, Guang Li, Ren Togo, Rui Song, Takahiro Ogawa, Miki Haseyama

This paper presents our method for the generative track of The First Dataset
Distillation Challenge at ECCV 2024. Since the diffusion model has become the
mainstay of generative models because of its high-quality generative effects,
we focus on distillation methods based on the diffusion model. Considering that
the track can only generate a fixed number of images in 10 minutes using a
generative model for CIFAR-100 and Tiny-ImageNet datasets, we need to use a
generative model that can generate images at high speed. In this study, we
proposed a novel generative dataset distillation method based on Stable
Diffusion. Specifically, we use the SDXL-Turbo model which can generate images
at high speed and quality. Compared to other diffusion models that can only
generate images per class (IPC) = 1, our method can achieve an IPC = 10 for
Tiny-ImageNet and an IPC = 20 for CIFAR-100, respectively. Additionally, to
generate high-quality distilled datasets for CIFAR-100 and Tiny-ImageNet, we
use the class information as text prompts and post data augmentation for the
SDXL-Turbo model. Experimental results show the effectiveness of the proposed
method, and we achieved third place in the generative track of the ECCV 2024 DD
Challenge. Codes are available at https://github.com/Guang000/BANKO.

ÊëòË¶ÅÔºöÊú¨Êñá‰ªãÁ¥πÊàëÂÄëÂú® ECCV 2024 Á¨¨‰∏ÄÊ¨°Ë≥áÊñôÈõÜËí∏È§æÊåëÊà∞ÁöÑÁîüÊàêËªåË∑°ÊñπÊ≥ï„ÄÇÁî±ÊñºÊì¥Êï£Ê®°ÂûãÂõ†ÁÇ∫ÂÖ∂È´òÂìÅË≥™ÁöÑÁîüÊàêÊïàÊûúËÄåÊàêÁÇ∫ÁîüÊàêÊ®°ÂûãÁöÑ‰∏ªÊµÅÔºåÊàëÂÄëÂ∞àÊ≥®ÊñºÂü∫ÊñºÊì¥Êï£Ê®°ÂûãÁöÑËí∏È§æÊñπÊ≥ï„ÄÇËÄÉÈáèÂà∞ËªåË∑°Âè™ËÉΩ‰ΩøÁî® CIFAR-100 Âíå Tiny-ImageNet Ë≥áÊñôÈõÜÁöÑÁîüÊàêÊ®°ÂûãÂú® 10 ÂàÜÈêòÂÖßÁîüÊàêÂõ∫ÂÆöÊï∏ÈáèÁöÑÂΩ±ÂÉèÔºåÊàëÂÄëÈúÄË¶Å‰ΩøÁî®ËÉΩÂ§†È´òÈÄüÁîüÊàêÂΩ±ÂÉèÁöÑÁîüÊàêÊ®°Âûã„ÄÇÂú®Êú¨Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÂü∫Êñº Stable Diffusion ÁöÑÊñ∞Á©éÁîüÊàêË≥áÊñôÈõÜËí∏È§æÊñπÊ≥ï„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄë‰ΩøÁî®ËÉΩÂ§†È´òÈÄüÈ´òÂìÅË≥™ÁîüÊàêÂΩ±ÂÉèÁöÑ SDXL-Turbo Ê®°Âûã„ÄÇËàáÊØèÈ°ûÂè™ËÉΩÁîüÊàê 1 ÂºµÂΩ±ÂÉè (IPC) = 1 ÁöÑÂÖ∂‰ªñÊì¥Êï£Ê®°ÂûãÁõ∏ÊØîÔºåÊàëÂÄëÁöÑÊ®°ÂûãÂèØ‰ª•ÂàÜÂà•ÁÇ∫ Tiny-ImageNet ÈÅîÂà∞ IPC = 10ÔºåÁÇ∫ CIFAR-100 ÈÅîÂà∞ IPC = 20„ÄÇÊ≠§Â§ñÔºåÁÇ∫‰∫ÜÁîüÊàê CIFAR-100 Âíå Tiny-ImageNet ÁöÑÈ´òÂìÅË≥™Ëí∏È§æË≥áÊñôÈõÜÔºåÊàëÂÄë‰ΩøÁî®È°ûÂà•Ë≥áË®ä‰ΩúÁÇ∫ÊñáÂ≠óÊèêÁ§∫Ôºå‰∏¶ÁÇ∫ SDXL-Turbo Ê®°ÂûãÈÄ≤Ë°åÂæåË≥áÊñôÊì¥ÂÖÖ„ÄÇÂØ¶È©óÁµêÊûúÈ°ØÁ§∫ÊâÄÊèêÂá∫ÊñπÊ≥ïÁöÑÊúâÊïàÊÄßÔºåÊàëÂÄëÂú® ECCV 2024 DD ÊåëÊà∞ÁöÑÁîüÊàêËªåË∑°‰∏≠Áç≤ÂæóÁ¨¨‰∏âÂêç„ÄÇÁ®ãÂºèÁ¢ºÂèØÂú® https://github.com/Guang000/BANKO ÂèñÂæó„ÄÇ

##### **MM-UNet: A Mixed MLP Architecture for Improved Ophthalmic Image Segmentation**
2408.08600v1 by Zunjie Xiao, Xiaoqing Zhang, Risa Higashita, Jiang Liu

Ophthalmic image segmentation serves as a critical foundation for ocular
disease diagnosis. Although fully convolutional neural networks (CNNs) are
commonly employed for segmentation, they are constrained by inductive biases
and face challenges in establishing long-range dependencies. Transformer-based
models address these limitations but introduce substantial computational
overhead. Recently, a simple yet efficient Multilayer Perceptron (MLP)
architecture was proposed for image classification, achieving competitive
performance relative to advanced transformers. However, its effectiveness for
ophthalmic image segmentation remains unexplored. In this paper, we introduce
MM-UNet, an efficient Mixed MLP model tailored for ophthalmic image
segmentation. Within MM-UNet, we propose a multi-scale MLP (MMLP) module that
facilitates the interaction of features at various depths through a grouping
strategy, enabling simultaneous capture of global and local information. We
conducted extensive experiments on both a private anterior segment optical
coherence tomography (AS-OCT) image dataset and a public fundus image dataset.
The results demonstrated the superiority of our MM-UNet model in comparison to
state-of-the-art deep segmentation networks.

ÊëòË¶ÅÔºöÁúºÁßëÂΩ±ÂÉèÂàÜÂâ≤ÊòØÁúºÈÉ®ÁñæÁóÖËØäÊñ≠ÁöÑÂÖ≥ÈîÆÂü∫Á°Ä„ÄÇËôΩÁÑ∂ÂÖ®Âç∑ÁßØÁ•ûÁªèÁΩëÁªú (CNN) ÈÄöÂ∏∏Áî®‰∫éÂàÜÂâ≤Ôºå‰ΩÜÂÆÉ‰ª¨ÂèóÂà∞ÂΩíÁ∫≥ÂÅèÂ∑ÆÁöÑÈôêÂà∂ÔºåÂπ∂‰∏îÂú®Âª∫Á´ãËøúÁ®ã‰æùËµñÂÖ≥Á≥ªÊó∂Èù¢‰∏¥ÊåëÊàò„ÄÇÂü∫‰∫é Transformer ÁöÑÊ®°ÂûãËß£ÂÜ≥‰∫ÜËøô‰∫õÈôêÂà∂Ôºå‰ΩÜÂºïÂÖ•‰∫ÜÂ§ßÈáèÁöÑËÆ°ÁÆóÂºÄÈîÄ„ÄÇÊúÄËøëÔºåÊèêÂá∫‰∫Ü‰∏ÄÁßçÁÆÄÂçï‰ΩÜÈ´òÊïàÁöÑÂ§öÂ±ÇÊÑüÁü•Âô® (MLP) Êû∂ÊûÑÁî®‰∫éÂõæÂÉèÂàÜÁ±ªÔºåÁõ∏ÂØπ‰∫éÈ´òÁ∫ß Transformer ÂÆûÁé∞‰∫ÜÊúâÁ´û‰∫âÂäõÁöÑÊÄßËÉΩ„ÄÇÁÑ∂ËÄåÔºåÂÖ∂ÂØπÁúºÁßëÂõæÂÉèÂàÜÂâ≤ÁöÑÊúâÊïàÊÄß‰ªçÊú™ÂæóÂà∞Êé¢Á¥¢„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨‰ªãÁªç‰∫Ü MM-UNetÔºåËøôÊòØ‰∏ÄÁßçÈíàÂØπÁúºÁßëÂõæÂÉèÂàÜÂâ≤ÈáèË∫´ÂÆöÂà∂ÁöÑÈ´òÊïàÊ∑∑Âêà MLP Ê®°Âûã„ÄÇÂú® MM-UNet ‰∏≠ÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏Ä‰∏™Â§öÂ∞∫Â∫¶ MLP (MMLP) Ê®°ÂùóÔºåËØ•Ê®°ÂùóÈÄöËøáÂàÜÁªÑÁ≠ñÁï•‰øÉËøõ‰∫Ü‰∏çÂêåÊ∑±Â∫¶ÁâπÂæÅÁöÑ‰∫§‰∫íÔºå‰ªéËÄåËÉΩÂ§üÂêåÊó∂ÊçïËé∑ÂÖ®Â±ÄÂíåÂ±ÄÈÉ®‰ø°ÊÅØ„ÄÇÊàë‰ª¨Âú®‰∏Ä‰∏™ÁßÅÊúâÁöÑÂâçËäÇÊÆµÂÖâÂ≠¶Áõ∏Âπ≤Êñ≠Â±ÇÊâ´Êèè (AS-OCT) ÂõæÂÉèÊï∞ÊçÆÈõÜÂíå‰∏Ä‰∏™ÂÖ¨ÂÖ±ÁúºÂ∫ïÂõæÂÉèÊï∞ÊçÆÈõÜ‰∏äËøõË°å‰∫ÜÂπøÊ≥õÁöÑÂÆûÈ™å„ÄÇÁªìÊûúË°®ÊòéÔºå‰∏éÊúÄÂÖàËøõÁöÑÊ∑±Â∫¶ÂàÜÂâ≤ÁΩëÁªúÁõ∏ÊØîÔºåÊàë‰ª¨ÁöÑ MM-UNet Ê®°ÂûãÂÖ∑Êúâ‰ºòË∂äÊÄß„ÄÇ

##### **A Mechanistic Interpretation of Syllogistic Reasoning in Auto-Regressive Language Models**
2408.08590v1 by Geonhee Kim, Marco Valentino, Andr√© Freitas

Recent studies on logical reasoning in auto-regressive Language Models (LMs)
have sparked a debate on whether such models can learn systematic reasoning
principles during pre-training or merely exploit superficial patterns in the
training data. This paper presents a mechanistic interpretation of syllogistic
reasoning in LMs to further enhance our understanding of internal dynamics.
Specifically, we present a methodology for circuit discovery aimed at
disentangling content-independent reasoning mechanisms from world knowledge
acquired during pre-training. Through two distinct intervention methods, we
uncover a sufficient and necessary circuit involving middle-term suppression
that elucidates how LMs transfer information to derive valid conclusions from
premises. Furthermore, we investigate how belief biases manifest in syllogistic
reasoning, finding evidence of partial contamination from additional attention
heads responsible for encoding commonsense and contextualized knowledge.
Finally, we explore the generalization of the discovered mechanisms across
various syllogistic schemes and model sizes, finding that the identified
circuit is sufficient and necessary for all the schemes on which the model
achieves high downstream accuracy ($\geq$ 60\%). Overall, our findings suggest
that LMs indeed learn transferable content-independent reasoning mechanisms,
but that, at the same time, such mechanisms do not involve generalisable and
abstract logical primitives, being susceptible to contamination by the same
world knowledge acquired during pre-training.

ÊëòË¶ÅÔºöËøëÊúüÂ∞çËá™ÂãïËø¥Ê≠∏Ë™ûË®ÄÊ®°Âûã (LM) ‰∏≠ÁöÑÈÇèËºØÊé®ÁêÜÈÄ≤Ë°åÁöÑÁ†îÁ©∂ÔºåÂºïÁôº‰∫Ü‰∏ÄÂ†¥ËæØË´ñÔºåÂç≥Ê≠§È°ûÊ®°ÂûãÊòØÂê¶ËÉΩÂú®È†êË®ìÁ∑¥ÊúüÈñìÂ≠∏ÁøíÁ≥ªÁµ±ÊÄßÊé®ÁêÜÂéüÂâáÔºåÊàñÂÉÖÂà©Áî®Ë®ìÁ∑¥Ë≥áÊñô‰∏≠ÁöÑË°®Â±§Ê®°Âºè„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂ∞ç LM ‰∏≠‰∏âÊÆµË´ñÊé®ÁêÜÁöÑÊ©üÂà∂Ë©ÆÈáãÔºå‰ª•ÈÄ≤‰∏ÄÊ≠•Â¢ûÂº∑ÊàëÂÄëÂ∞çÂÖßÈÉ®ÂãïÊÖãÁöÑÁêÜËß£„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÈõªË∑ØÁôºÁèæÊñπÊ≥ïÔºåÊó®Âú®Â∞áÂÖßÂÆπÁÑ°ÈóúÁöÑÊé®ÁêÜÊ©üÂà∂ËàáÈ†êË®ìÁ∑¥ÊúüÈñìÁç≤ÂæóÁöÑ‰∏ñÁïåÁü•Ë≠òÂçÄÂàÜÈñã‰æÜ„ÄÇÈÄèÈÅéÂÖ©Á®Æ‰∏çÂêåÁöÑ‰ªãÂÖ•ÊñπÊ≥ïÔºåÊàëÂÄëÁôºÁèæ‰∫Ü‰∏ÄÂÄãÊ∂âÂèä‰∏≠ÈñìÈ†ÖÊäëÂà∂ÁöÑÂÖÖÂàÜ‰∏îÂøÖË¶ÅÁöÑÈõªË∑ØÔºåÈó°Êòé‰∫Ü LM Â¶Ç‰ΩïÂ∞áË≥áË®äÂÇ≥ÈÅûÁµ¶ÂæûÂâçÊèê‰∏≠Êé®Â∞éÂá∫ÊúâÊïàÁµêË´ñ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁ†îÁ©∂‰∫Ü‰ø°ÂøµÂÅèË¶ãÂ¶Ç‰ΩïÂú®‰∏âÊÆµË´ñÊé®ÁêÜ‰∏≠È°ØÁèæÔºåÁôºÁèæË≤†Ë≤¨Á∑®Á¢ºÂ∏∏Ë≠òÂíåÊÉÖÂ¢ÉÂåñÁü•Ë≠òÁöÑÈôÑÂä†Ê≥®ÊÑèÈ†≠ÈÉ®Â≠òÂú®ÈÉ®ÂàÜÊ±°ÊüìÁöÑË≠âÊìö„ÄÇÊúÄÂæåÔºåÊàëÂÄëÊé¢Ë®é‰∫ÜÁôºÁèæÁöÑÊ©üÂà∂Âú®ÂêÑÁ®Æ‰∏âÊÆµË´ñÊû∂ÊßãÂíåÊ®°ÂûãË¶èÊ®°‰∏≠ÁöÑÊ¶ÇÂåñÔºåÁôºÁèæÂ∑≤Ë≠òÂà•ÁöÑÈõªË∑ØÂ∞çÊñºÊ®°ÂûãÂú®ÊâÄÊúâÊû∂Êßã‰∏äÂØ¶ÁèæÈ´ò‰∏ãÊ∏∏Ê∫ñÁ¢∫Â∫¶Ôºà‚â• 60%ÔºâËÄåË®ÄÊòØÂÖÖÂàÜ‰∏îÂøÖË¶ÅÁöÑ„ÄÇÁ∏ΩÈ´îËÄåË®ÄÔºåÊàëÂÄëÁöÑÁôºÁèæË°®Êòé LM Á¢∫ÂØ¶Â≠∏Áøí‰∫ÜÂèØËΩâÁßªÁöÑÂÖßÂÆπÁÑ°ÈóúÊé®ÁêÜÊ©üÂà∂Ôºå‰ΩÜÂêåÊôÇÔºåÊ≠§È°ûÊ©üÂà∂‰∏çÊ∂âÂèäÂèØÊ¶ÇÊã¨ÂíåÊäΩË±°ÁöÑÈÇèËºØÂéüË™ûÔºåÂÆπÊòìÂèóÂà∞È†êË®ìÁ∑¥ÊúüÈñìÁç≤ÂæóÁöÑÁõ∏Âêå‰∏ñÁïåÁü•Ë≠òÁöÑÊ±°Êüì„ÄÇ

##### **AgentSimulator: An Agent-based Approach for Data-driven Business Process Simulation**
2408.08571v1 by Lukas Kirchdorfer, Robert Bl√ºmel, Timotheus Kampik, Han van der Aa, Heiner Stuckenschmidt

Business process simulation (BPS) is a versatile technique for estimating
process performance across various scenarios. Traditionally, BPS approaches
employ a control-flow-first perspective by enriching a process model with
simulation parameters. Although such approaches can mimic the behavior of
centrally orchestrated processes, such as those supported by workflow systems,
current control-flow-first approaches cannot faithfully capture the dynamics of
real-world processes that involve distinct resource behavior and decentralized
decision-making. Recognizing this issue, this paper introduces AgentSimulator,
a resource-first BPS approach that discovers a multi-agent system from an event
log, modeling distinct resource behaviors and interaction patterns to simulate
the underlying process. Our experiments show that AgentSimulator achieves
state-of-the-art simulation accuracy with significantly lower computation times
than existing approaches while providing high interpretability and adaptability
to different types of process-execution scenarios.

ÊëòË¶ÅÔºöÂïÜÊ•≠ÊµÅÁ®ãÊ®°Êì¨ (BPS) ÊòØ‰∏ÄÁ®ÆÈÄöÁî®ÊäÄË°ìÔºåÂèØÁî®Êñº‰º∞Ë®àÂêÑÁ®ÆÊÉÖÂ¢É‰∏ãÁöÑÊµÅÁ®ãÊïàËÉΩ„ÄÇÂÇ≥Áµ±‰∏äÔºåBPS ÊñπÊ≥ïÊé°Áî®ÊéßÂà∂ÊµÅÁ®ãÂÑ™ÂÖàÁöÑËßÄÈªûÔºåÈÄèÈÅéË±êÂØåÊµÅÁ®ãÊ®°ÂûãÔºåÂä†ÂÖ•Ê®°Êì¨ÂèÉÊï∏„ÄÇÂÑòÁÆ°Ê≠§È°ûÊñπÊ≥ïÂèØ‰ª•Ê®°‰ªøÁî±‰∏≠Â§ÆÂçîË™øÁöÑÊµÅÁ®ãË°åÁÇ∫Ôºå‰æãÂ¶ÇÂ∑•‰ΩúÊµÅÁ®ãÁ≥ªÁµ±ÊâÄÊîØÊè¥ÁöÑÊµÅÁ®ãÔºå‰ΩÜÁõÆÂâçÁöÑÊéßÂà∂ÊµÅÁ®ãÂÑ™ÂÖàÊñπÊ≥ïÁÑ°Ê≥ïÂø†ÂØ¶ÊçïÊçâÊ∂âÂèä‰∏çÂêåË≥áÊ∫êË°åÁÇ∫ÂíåÂàÜÊï£ÂºèÊ±∫Á≠ñÂà∂ÂÆö‰πãÁúüÂØ¶‰∏ñÁïåÊµÅÁ®ãÁöÑÂãïÊÖã„ÄÇÊúâÈëëÊñºÊ≠§ÂïèÈ°åÔºåÊú¨Êñá‰ªãÁ¥π AgentSimulatorÔºå‰∏ÄÁ®ÆË≥áÊ∫êÂÑ™ÂÖàÁöÑ BPS ÊñπÊ≥ïÔºåÂÆÉÂèØ‰ª•Âæû‰∫ã‰ª∂Êó•Ë™å‰∏≠ÁôºÁèæÂ§ö‰ª£ÁêÜÁ≥ªÁµ±Ôºå‰∏¶Âª∫Ê®°‰∏çÂêåÁöÑË≥áÊ∫êË°åÁÇ∫Âíå‰∫íÂãïÊ®°ÂºèÔºå‰ª•Ê®°Êì¨Âü∫Á§éÊµÅÁ®ã„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÈ°ØÁ§∫ÔºåAgentSimulator ÈÅîÂà∞‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÊ®°Êì¨Ê∫ñÁ¢∫Â∫¶Ôºå‰∏îÈÅãÁÆóÊôÇÈñìÈÅ†‰ΩéÊñºÁèæÊúâÊñπÊ≥ïÔºåÂêåÊôÇÂ∞ç‰∏çÂêåÈ°ûÂûãÁöÑÊµÅÁ®ãÂü∑Ë°åÊÉÖÂ¢ÉÊèê‰æõÈ´òÂ∫¶ÁöÑÂèØËß£ÈáãÊÄßÂíåÈÅ©ÊáâÊÄß„ÄÇ

##### **Overview of the BioLaySumm 2024 Shared Task on the Lay Summarization of Biomedical Research Articles**
2408.08566v1 by Tomas Goldsack, Carolina Scarton, Matthew Shardlow, Chenghua Lin

This paper presents the setup and results of the second edition of the
BioLaySumm shared task on the Lay Summarisation of Biomedical Research
Articles, hosted at the BioNLP Workshop at ACL 2024. In this task edition, we
aim to build on the first edition's success by further increasing research
interest in this important task and encouraging participants to explore novel
approaches that will help advance the state-of-the-art. Encouragingly, we found
research interest in the task to be high, with this edition of the task
attracting a total of 53 participating teams, a significant increase in
engagement from the previous edition. Overall, our results show that a broad
range of innovative approaches were adopted by task participants, with a
predictable shift towards the use of Large Language Models (LLMs).

ÊëòË¶ÅÔºöÊú¨ÁØáË´ñÊñá‰ªãÁ¥π‰∫Ü ACL 2024 ÁöÑ BioNLP Â∑•‰ΩúÂùä‰∏≠ËàâËæ¶ÁöÑÁ¨¨‰∫åÂ±Ü BioLaySumm ÂÖ±‰∫´‰ªªÂãô‰∏≠ÁîüÁâ©ÈÜ´Â≠∏Á†îÁ©∂ÊñáÁ´†ÁöÑÈÄö‰øóÁ∏ΩÁµêÁöÑË®≠ÂÆöÂíåÁµêÊûú„ÄÇÂú®ÈÄôÂÄã‰ªªÂãôÁâàÊú¨‰∏≠ÔºåÊàëÂÄëÊó®Âú®Âª∫Á´ãÂú®Á¨¨‰∏ÄÂ±ÜÁöÑÊàêÂäü‰∏äÔºåÈÄ≤‰∏ÄÊ≠•ÊèêÂçáÂ∞çÈÄôÂÄãÈáçË¶Å‰ªªÂãôÁöÑÁ†îÁ©∂ËààË∂£Ôºå‰∏¶ÈºìÂãµÂèÉËàáËÄÖÊé¢Á¥¢ÊúâÂä©ÊñºÊé®ÂãïÁèæÊúâÊäÄË°ìÈÄ≤Ê≠•ÁöÑÊñ∞Á©éÊñπÊ≥ï„ÄÇ‰ª§‰∫∫ÈºìËàûÁöÑÊòØÔºåÊàëÂÄëÁôºÁèæÂ∞çË©≤‰ªªÂãôÁöÑÁ†îÁ©∂ËààË∂£ÂæàÈ´òÔºåÊú¨Â±Ü‰ªªÂãôÂÖ±Âê∏Âºï‰∫Ü 53 ÂÄãÂèÉËàáÂúòÈöäÔºåÂèÉËàáÂ∫¶ËºÉ‰∏ä‰∏ÄÂ±ÜÈ°ØËëóÊèêÂçá„ÄÇÁ∏ΩÈ´îËÄåË®ÄÔºåÊàëÂÄëÁöÑÁµêÊûúË°®ÊòéÔºå‰ªªÂãôÂèÉËàáËÄÖÊé°Áî®‰∫ÜÂª£Ê≥õÁöÑÂâµÊñ∞ÊñπÊ≥ïÔºå‰∏¶ÂèØÈ†êÊ∏¨Âú∞ËΩâÂêë‰ΩøÁî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM)„ÄÇ

##### **Collaborative Cross-modal Fusion with Large Language Model for Recommendation**
2408.08564v1 by Zhongzhou Liu, Hao Zhang, Kuicai Dong, Yuan Fang

Despite the success of conventional collaborative filtering (CF) approaches
for recommendation systems, they exhibit limitations in leveraging semantic
knowledge within the textual attributes of users and items. Recent focus on the
application of large language models for recommendation (LLM4Rec) has
highlighted their capability for effective semantic knowledge capture. However,
these methods often overlook the collaborative signals in user behaviors. Some
simply instruct-tune a language model, while others directly inject the
embeddings of a CF-based model, lacking a synergistic fusion of different
modalities. To address these issues, we propose a framework of Collaborative
Cross-modal Fusion with Large Language Models, termed CCF-LLM, for
recommendation. In this framework, we translate the user-item interactions into
a hybrid prompt to encode both semantic knowledge and collaborative signals,
and then employ an attentive cross-modal fusion strategy to effectively fuse
latent embeddings of both modalities. Extensive experiments demonstrate that
CCF-LLM outperforms existing methods by effectively utilizing semantic and
collaborative signals in the LLM4Rec context.

ÊëòË¶ÅÔºöÂÑòÁÆ°ÂÇ≥Áµ±ÂçîÂêåÈÅéÊøæ (CF) ÊñπÊ≥ïÂú®Êé®Ëñ¶Á≥ªÁµ±‰∏≠Áç≤ÂæóÊàêÂäüÔºå‰ΩÜÂÆÉÂÄëÂú®Âà©Áî®‰ΩøÁî®ËÄÖÂíåÈ†ÖÁõÆÊñáÂ≠óÂ±¨ÊÄß‰∏≠ÁöÑË™ûÊÑèÁü•Ë≠òÊñπÈù¢Ë°®ÁèæÂá∫ÈôêÂà∂„ÄÇÊúÄËøëÂ∞àÊ≥®ÊñºÂ∞áÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÊáâÁî®ÊñºÊé®Ëñ¶ (LLM4Rec) Â∑≤Âº∑Ë™øÂÖ∂ÊúâÊïàË™ûÊÑèÁü•Ë≠òÊì∑ÂèñÁöÑËÉΩÂäõ„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÊñπÊ≥ïÁ∂ìÂ∏∏ÂøΩÁï•‰ΩøÁî®ËÄÖË°åÁÇ∫‰∏≠ÁöÑÂçîÂêåË®äËôü„ÄÇÊúâ‰∫õÂÉÖÊåáÁ§∫Ë™øÊï¥Ë™ûË®ÄÊ®°ÂûãÔºåËÄåÂè¶‰∏Ä‰∫õÂâáÁõ¥Êé•Ê≥®ÂÖ•Âü∫Êñº CF Ê®°ÂûãÁöÑÂµåÂÖ•ÔºåÁº∫Â∞ë‰∏çÂêåÊ®°ÊÖãÁöÑÂçîÂêåËûçÂêà„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂçîÂêåË∑®Ê®°ÊÖãËûçÂêàÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÁöÑÊ°ÜÊû∂ÔºåÁ®±ÁÇ∫ CCF-LLMÔºåÁî®ÊñºÊé®Ëñ¶„ÄÇÂú®ÈÄôÂÄãÊ°ÜÊû∂‰∏≠ÔºåÊàëÂÄëÂ∞á‰ΩøÁî®ËÄÖÈ†ÖÁõÆ‰∫íÂãïËΩâÊèõÁÇ∫‰∏ÄÂÄãÊ∑∑ÂêàÊèêÁ§∫Ôºå‰ª•Á∑®Á¢ºË™ûÊÑèÁü•Ë≠òÂíåÂçîÂêåË®äËôüÔºåÁÑ∂ÂæåÊé°Áî®Â∞àÊ≥®ÁöÑË∑®Ê®°ÊÖãËûçÂêàÁ≠ñÁï•Ôºå‰ª•ÊúâÊïàËûçÂêàÂÖ©Á®ÆÊ®°ÊÖãÁöÑÊΩõÂú®ÂµåÂÖ•„ÄÇÂª£Ê≥õÁöÑÂØ¶È©óË≠âÊòéÔºåCCF-LLM ÈÄèÈÅéÊúâÊïàÂà©Áî® LLM4Rec ËÉåÊôØ‰∏≠ÁöÑË™ûÊÑèÂíåÂçîÂêåË®äËôüÔºåÂÑ™ÊñºÁèæÊúâÊñπÊ≥ï„ÄÇ

##### **Integrating Multi-view Analysis: Multi-view Mixture-of-Expert for Textual Personality Detection**
2408.08551v1 by Haohao Zhu, Xiaokun Zhang, Junyu Lu, Liang Yang, Hongfei Lin

Textual personality detection aims to identify personality traits by
analyzing user-generated content. To achieve this effectively, it is essential
to thoroughly examine user-generated content from various perspectives.
However, previous studies have struggled with automatically extracting and
effectively integrating information from multiple perspectives, thereby
limiting their performance on personality detection. To address these
challenges, we propose the Multi-view Mixture-of-Experts Model for Textual
Personality Detection (MvP). MvP introduces a Multi-view Mixture-of-Experts
(MoE) network to automatically analyze user posts from various perspectives.
Additionally, it employs User Consistency Regularization to mitigate conflicts
among different perspectives and learn a multi-view generic user
representation. The model's training is optimized via a multi-task joint
learning strategy that balances supervised personality detection with
self-supervised user consistency constraints. Experimental results on two
widely-used personality detection datasets demonstrate the effectiveness of the
MvP model and the benefits of automatically analyzing user posts from diverse
perspectives for textual personality detection.

ÊëòË¶ÅÔºöÊñáÊú¨‰∫∫Ê†ºÂÅµÊ∏¨Êó®Âú®ÈÄèÈÅéÂàÜÊûê‰ΩøÁî®ËÄÖÁî¢ÁîüÁöÑÂÖßÂÆπÔºå‰æÜËæ®Ë≠ò‰∫∫Ê†ºÁâπË≥™„ÄÇÁÇ∫‰∫ÜÊúâÊïàÈÅîÊàêÊ≠§ÁõÆÊ®ôÔºåÂæπÂ∫ïÊ™¢Ë¶ñ‰ΩøÁî®ËÄÖÁî¢ÁîüÁöÑÂÖßÂÆπÔºå‰∏¶Âæû‰∏çÂêåËßÄÈªûÈÄ≤Ë°åÂàÜÊûêËá≥ÈóúÈáçË¶Å„ÄÇÁÑ∂ËÄåÔºåÂÖàÂâçÁöÑÁ†îÁ©∂Âú®Ëá™ÂãïÊì∑ÂèñÂíåÊúâÊïàÊï¥ÂêàÂ§öÈù¢ÂêëÁöÑË≥áË®ä‰∏äÈÅáÂà∞Âõ∞Èõ£ÔºåÂõ†Ê≠§ÈôêÂà∂‰∫ÜÂÖ∂Âú®‰∫∫Ê†ºÂÅµÊ∏¨‰∏äÁöÑË°®Áèæ„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÊèêÂá∫Áî®ÊñºÊñáÊú¨‰∫∫Ê†ºÂÅµÊ∏¨ÁöÑÂ§öË¶ñËßíÊ∑∑ÂêàÂ∞àÂÆ∂Ê®°Âûã (MvP)„ÄÇMvP Â∞éÂÖ•Â§öË¶ñËßíÊ∑∑ÂêàÂ∞àÂÆ∂ (MoE) Á∂≤Ë∑ØÔºå‰ª•Ëá™ÂãïÂàÜÊûê‰ΩøÁî®ËÄÖÁöÑË≤ºÊñáÔºå‰∏¶Âæû‰∏çÂêåËßÄÈªûÈÄ≤Ë°åÂàÜÊûê„ÄÇÊ≠§Â§ñÔºåÂÆÉÊé°Áî®‰ΩøÁî®ËÄÖ‰∏ÄËá¥ÊÄßÊ≠£Ë¶èÂåñ‰æÜÊ∏õËºï‰∏çÂêåËßÄÈªû‰πãÈñìÁöÑË°ùÁ™ÅÔºå‰∏¶Â≠∏ÁøíÂ§öË¶ñËßíÁöÑ‰∏ÄËà¨‰ΩøÁî®ËÄÖË°®Âæµ„ÄÇÊ≠§Ê®°ÂûãÁöÑË®ìÁ∑¥ÈÄèÈÅéÂ§ö‰ªªÂãôËÅØÂêàÂ≠∏ÁøíÁ≠ñÁï•ÈÄ≤Ë°åÊúÄ‰Ω≥ÂåñÔºåË©≤Á≠ñÁï•Âπ≥Ë°°‰∫ÜÁõ£Áù£Âºè‰∫∫Ê†ºÂÅµÊ∏¨ÂíåËá™ÊàëÁõ£Áù£Âºè‰ΩøÁî®ËÄÖ‰∏ÄËá¥ÊÄßÁ¥ÑÊùü„ÄÇÂú®ÂÖ©ÂÄãÂª£Ê≥õ‰ΩøÁî®ÁöÑÊÄßÊ†ºÂÅµÊ∏¨Ë≥áÊñôÈõÜ‰∏äÁöÑÂØ¶È©óÁµêÊûúË≠âÊòé‰∫Ü MvP Ê®°ÂûãÁöÑÊúâÊïàÊÄßÔºå‰ª•ÂèäËá™ÂãïÂàÜÊûê‰ΩøÁî®ËÄÖË≤ºÊñáÂ∞çÊñáÊú¨‰∫∫Ê†ºÂÅµÊ∏¨Âæû‰∏çÂêåËßÄÈªûÂá∫ÁôºÁöÑÂ•ΩËôï„ÄÇ

##### **SelectLLM: Query-Aware Efficient Selection Algorithm for Large Language Models**
2408.08545v1 by Kaushal Kumar Maurya, KV Aditya Srivatsa, Ekaterina Kochmar

Large language models (LLMs) have gained increased popularity due to their
remarkable success across various tasks, which has led to the active
development of a large set of diverse LLMs. However, individual LLMs have
limitations when applied to complex tasks because of such factors as training
biases, model sizes, and the datasets used. A promising approach is to
efficiently harness the diverse capabilities of LLMs to overcome these
individual limitations. Towards this goal, we introduce a novel LLM selection
algorithm called SelectLLM. This algorithm directs input queries to the most
suitable subset of LLMs from a large pool, ensuring they collectively provide
the correct response efficiently. SelectLLM uses a multi-label classifier,
utilizing the classifier's predictions and confidence scores to design optimal
policies for selecting an optimal, query-aware, and lightweight subset of LLMs.
Our findings show that the proposed model outperforms individual LLMs and
achieves competitive performance compared to similarly sized, computationally
expensive top-performing LLM subsets. Specifically, with a similarly sized
top-performing LLM subset, we achieve a significant reduction in latency on two
standard reasoning benchmarks: 13% lower latency for GSM8K and 70% lower
latency for MMLU. Additionally, we conduct comprehensive analyses and ablation
studies, which validate the robustness of the proposed model.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâÂõ†ÂÖ∂Âú®ÂêÑÁ®Æ‰ªªÂãô‰∏≠ÁöÑÈ°ØËëóÊàêÂäüËÄåÁç≤ÂæóË∂ä‰æÜË∂äÈ´òÁöÑÊôÆÂèäÂ∫¶ÔºåÈÄôÂ∞éËá¥‰∫ÜÂ§ßÈáè‰∏çÂêå LLM ÁöÑÁ©çÊ•µÈñãÁôº„ÄÇÁÑ∂ËÄåÔºåÁî±ÊñºË®ìÁ∑¥ÂÅèÂ∑Æ„ÄÅÊ®°ÂûãÂ§ßÂ∞èÂíåÊâÄ‰ΩøÁî®ÁöÑË≥áÊñôÈõÜÁ≠âÂõ†Á¥†ÔºåÂÄãÂà• LLM Âú®ÊáâÁî®ÊñºË§áÈõú‰ªªÂãôÊôÇÂ≠òÂú®Â±ÄÈôêÊÄß„ÄÇ‰∏ÄÁ®ÆÊúâÂâçÈÄîÁöÑÊñπÊ≥ïÊòØÊúâÊïàÂà©Áî® LLM ÁöÑÂ§öÊ®£ÂåñËÉΩÂäõ‰æÜÂÖãÊúçÈÄô‰∫õÂÄãÂà•ÈôêÂà∂„ÄÇÁÇ∫ÈÅîÊàêÊ≠§ÁõÆÊ®ôÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÁ®ÆÁ®±ÁÇ∫ SelectLLM ÁöÑÊñ∞Á©é LLM ÈÅ∏ÊìáÊºîÁÆóÊ≥ï„ÄÇÊ≠§ÊºîÁÆóÊ≥ïÂ∞áËº∏ÂÖ•Êü•Ë©¢ÂºïÂ∞éËá≥Â§ßÂûãÊ±†‰∏≠ÊúÄÈÅ©Áï∂ÁöÑ LLM Â≠êÈõÜÔºåÁ¢∫‰øùÂÆÉÂÄëÂÖ±ÂêåÊúâÊïàÂú∞Êèê‰æõÊ≠£Á¢∫ÁöÑÂõûÊáâ„ÄÇSelectLLM ‰ΩøÁî®Â§öÊ®ôÁ±§ÂàÜÈ°ûÂô®ÔºåÂà©Áî®ÂàÜÈ°ûÂô®ÁöÑÈ†êÊ∏¨Âíå‰ø°ÂøÉÂàÜÊï∏ÔºåÁÇ∫ÈÅ∏ÊìáÊúÄ‰Ω≥„ÄÅÊü•Ë©¢ÊÑüÁü•ÂíåËºïÈáèÁ¥öÁöÑ LLM Â≠êÈõÜË®≠Ë®àÊúÄ‰Ω≥Á≠ñÁï•„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúË°®ÊòéÔºåÊâÄÊèêÂá∫ÁöÑÊ®°ÂûãÂÑ™ÊñºÂÄãÂà• LLMÔºå‰∏¶‰∏îËàáË¶èÊ®°È°û‰ºº„ÄÅË®àÁÆóÊàêÊú¨È´òÁöÑÈ†ÇÂ∞ñÊïàËÉΩ LLM Â≠êÈõÜÁõ∏ÊØîÔºåÈÅîÂà∞‰∫ÜÁ´∂Áà≠ÂäõÁöÑÊïàËÉΩ„ÄÇÂÖ∑È´î‰æÜË™™Ôºå‰ΩøÁî®Ë¶èÊ®°È°û‰ººÁöÑÈ†ÇÂ∞ñÊïàËÉΩ LLM Â≠êÈõÜÔºåÊàëÂÄëÂú®ÂÖ©ÂÄãÊ®ôÊ∫ñÊé®ÁêÜÂü∫Ê∫ñ‰∏äÂØ¶Áèæ‰∫ÜÈ°ØËëóÁöÑÂª∂ÈÅ≤Èôç‰ΩéÔºöGSM8K ÁöÑÂª∂ÈÅ≤Èôç‰Ωé‰∫Ü 13%ÔºåMMLU ÁöÑÂª∂ÈÅ≤Èôç‰Ωé‰∫Ü 70%„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÈÄ≤Ë°å‰∫ÜÂÖ®Èù¢ÁöÑÂàÜÊûêÂíåÊ∂àËûçÁ†îÁ©∂ÔºåÈ©óË≠â‰∫ÜÊâÄÊèêÂá∫Ê®°ÂûãÁöÑÁ©©ÂÅ•ÊÄß„ÄÇ

##### **Where is the signal in tokenization space?**
2408.08541v1 by Renato Lui Geh, Honghua Zhang, Kareem Ahmed, Benjie Wang, Guy Van den Broeck

Large Language Models (LLMs) are typically shipped with tokenizers that
deterministically encode text into so-called canonical token sequences, to
which the LLMs assign probability values. One common assumption is that the
probability of a piece of text is the probability of its canonical token
sequence. However, the tokenization of a string is not unique: e.g., the Llama2
tokenizer encodes Tokens as [Tok,ens], but [Tok,en,s] also represents the same
text. In this paper, we study non-canonical tokenizations. We prove that, given
a string, it is computationally hard to find the most likely tokenization for
an autoregressive LLM, as well as to compute the marginal probability over all
possible tokenizations. We then show how the marginal is, in most cases,
indistinguishable from the canonical probability. Surprisingly, we then
empirically demonstrate the existence of a significant amount of signal hidden
within tokenization space. Notably, by simply aggregating the probabilities of
non-canonical tokenizations, we achieve improvements across a range of LLM
evaluation benchmarks for a variety of architectures, including transformers
and state space models.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÈÄöÂ∏∏ÈôÑÂ∏∂Áî®ÊñºÂ∞áÊñáÂ≠óÁ¢∫ÂÆöÊÄßÁ∑®Á¢ºÁÇ∫ÊâÄË¨ÇÁöÑÊ≠£Ë¶èÁ¨¶ËôüÂ∫èÂàóÁöÑÁ¨¶ËôüÂåñÂô®ÔºåLLM ÊúÉÁÇ∫ÂÖ∂ÊåáÂÆöÊ©üÁéáÂÄº„ÄÇ‰∏ÄÂÄãÂ∏∏Ë¶ãÁöÑÂÅáË®≠ÊòØÔºå‰∏ÄÊÆµÊñáÂ≠óÁöÑÊ©üÁéáÂ∞±ÊòØÂÖ∂Ê≠£Ë¶èÁ¨¶ËôüÂ∫èÂàóÁöÑÊ©üÁéá„ÄÇÁÑ∂ËÄåÔºåÂ≠ó‰∏≤ÁöÑÁ¨¶ËôüÂåñ‰∏¶‰∏çÂîØ‰∏ÄÔºö‰æãÂ¶ÇÔºåLlama2 Á¨¶ËôüÂåñÂô®Â∞áÁ¨¶ËôüÁ∑®Á¢ºÁÇ∫ [Tok,ens]Ôºå‰ΩÜ [Tok,en,s] ‰πü‰ª£Ë°®Áõ∏ÂêåÁöÑÊñáÂ≠ó„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÁ†îÁ©∂ÈùûÊ≠£Ë¶èÁ¨¶ËôüÂåñ„ÄÇÊàëÂÄëË≠âÊòéÔºåÁµ¶ÂÆö‰∏ÄÂÄãÂ≠ó‰∏≤ÔºåÂ∞çÊñºËá™Ëø¥Ê≠∏ LLM ‰æÜË™™ÔºåË¶ÅÊâæÂá∫ÊúÄÂèØËÉΩÁöÑÁ¨¶ËôüÂåñÂú®Ë®àÁÆó‰∏äÂæàÂõ∞Èõ£ÔºåËÄå‰∏îË¶ÅË®àÁÆóÊâÄÊúâÂèØËÉΩÁöÑÁ¨¶ËôüÂåñÁöÑÈÇäÈöõÊ©üÁéá‰πüÂæàÂõ∞Èõ£„ÄÇÁÑ∂ÂæåÊàëÂÄëÂ±ïÁ§∫ÈÇäÈöõÊ©üÁéáÂú®Â§öÊï∏ÊÉÖÊ≥Å‰∏ãËàáÊ≠£Ë¶èÊ©üÁéáÁÑ°Ê≥ïÂçÄÂàÜ„ÄÇ‰ª§‰∫∫È©öË®ùÁöÑÊòØÔºåÊàëÂÄëÊé•Ëëó‰ª•Á∂ìÈ©óÊñπÂºèË≠âÊòéÁ¨¶ËôüÂåñÁ©∫Èñì‰∏≠Èö±ËóèËëóÂ§ßÈáèÁöÑË®äËôü„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÂè™Ë¶ÅÁ∞°ÂñÆÂú∞ÂΩôÁ∏ΩÈùûÊ≠£Ë¶èÁ¨¶ËôüÂåñÁöÑÊ©üÁéáÔºåÊàëÂÄëÂ∞±ËÉΩÂú®ÂêÑÁ®Æ LLM Ë©ï‰º∞Âü∫Ê∫ñ‰∏≠Áç≤ÂæóÈÄ≤Ê≠•ÔºåÂåÖÊã¨TransformerÂíåÁãÄÊÖãÁ©∫ÈñìÊ®°ÂûãÁ≠âÂêÑÁ®ÆÊû∂Êßã„ÄÇ

##### **CommunityKG-RAG: Leveraging Community Structures in Knowledge Graphs for Advanced Retrieval-Augmented Generation in Fact-Checking**
2408.08535v1 by Rong-Ching Chang, Jiawei Zhang

Despite advancements in Large Language Models (LLMs) and Retrieval-Augmented
Generation (RAG) systems, their effectiveness is often hindered by a lack of
integration with entity relationships and community structures, limiting their
ability to provide contextually rich and accurate information retrieval for
fact-checking. We introduce CommunityKG-RAG (Community Knowledge
Graph-Retrieval Augmented Generation), a novel zero-shot framework that
integrates community structures within Knowledge Graphs (KGs) with RAG systems
to enhance the fact-checking process. Capable of adapting to new domains and
queries without additional training, CommunityKG-RAG utilizes the multi-hop
nature of community structures within KGs to significantly improve the accuracy
and relevance of information retrieval. Our experimental results demonstrate
that CommunityKG-RAG outperforms traditional methods, representing a
significant advancement in fact-checking by offering a robust, scalable, and
efficient solution.

ÊëòË¶ÅÔºöÂÑòÁÆ°Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂíåÊ™¢Á¥¢Â¢ûÂº∑ÁîüÊàê (RAG) Á≥ªÁµ±ÊúâÈÄ≤Ê≠•Ôºå‰ΩÜÂÆÉÂÄëÁöÑÊúâÊïàÊÄßÁ∂ìÂ∏∏ÂèóÂà∞Áº∫‰πèËàáÂØ¶È´îÈóú‰øÇÂíåÁ§æÁæ§ÁµêÊßãÊï¥ÂêàÁöÑÈòªÁ§ôÔºåÈôêÂà∂‰∫ÜÂÆÉÂÄëÊèê‰æõËÑàÁµ°Ë±êÂØå‰∏îÊ∫ñÁ¢∫ÁöÑË≥áË®äÊ™¢Á¥¢‰ª•ÈÄ≤Ë°å‰∫ãÂØ¶Êü•Ê†∏ÁöÑËÉΩÂäõ„ÄÇÊàëÂÄë‰ªãÁ¥π CommunityKG-RAGÔºàÁ§æÁæ§Áü•Ë≠òÂúñË≠úÊ™¢Á¥¢Â¢ûÂº∑ÁîüÊàêÔºâÔºåÈÄôÊòØ‰∏ÄÂÄãÊñ∞Á©éÁöÑÈõ∂Ê¨°Â≠∏ÁøíÊû∂ÊßãÔºåÂÆÉÂ∞áÁü•Ë≠òÂúñË≠ú (KG) ÂÖßÁöÑÁ§æÁæ§ÁµêÊßãËàá RAG Á≥ªÁµ±Êï¥ÂêàÔºå‰ª•Â¢ûÂº∑‰∫ãÂØ¶Êü•Ê†∏ÊµÅÁ®ã„ÄÇCommunityKG-RAG ÁÑ°ÈúÄÈ°çÂ§ñË®ìÁ∑¥Â∞±ËÉΩÈÅ©ÊáâÊñ∞ÁöÑÈ†òÂüüÂíåÊü•Ë©¢ÔºåÂÆÉÂà©Áî® KG ÂÖßÁ§æÁæ§ÁµêÊßãÁöÑÂ§öË∑≥ÁâπÊÄßÔºåÂ§ßÂπÖÊèêÂçáË≥áË®äÊ™¢Á¥¢ÁöÑÊ∫ñÁ¢∫ÊÄßÂíåÁõ∏ÈóúÊÄß„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÁµêÊûúË≠âÊòé CommunityKG-RAG ÂÑ™ÊñºÂÇ≥Áµ±ÊñπÊ≥ïÔºå‰ª£Ë°®Ëëó‰∫ãÂØ¶Êü•Ê†∏ÁöÑÈáçÂ§ßÈÄ≤Ê≠•ÔºåÊèê‰æõ‰∫Ü‰∏ÄÂÄãÂº∑ÂÅ•„ÄÅÂèØÊì¥ÂÖÖ‰∏îÊúâÊïàÁéáÁöÑËß£Ê±∫ÊñπÊ°à„ÄÇ

##### **Detecting Unsuccessful Students in Cybersecurity Exercises in Two Different Learning Environments**
2408.08531v1 by Valdemar ≈†v√°bensk√Ω, Kristi√°n Tk√°ƒçik, Aubrey Birdwell, Richard Weiss, Ryan S. Baker, Pavel ƒåeleda, Jan Vykopal, Jens Mache, Ankur Chattopadhyay

This full paper in the research track evaluates the usage of data logged from
cybersecurity exercises in order to predict students who are potentially at
risk of performing poorly. Hands-on exercises are essential for learning since
they enable students to practice their skills. In cybersecurity, hands-on
exercises are often complex and require knowledge of many topics. Therefore,
students may miss solutions due to gaps in their knowledge and become
frustrated, which impedes their learning. Targeted aid by the instructor helps,
but since the instructor's time is limited, efficient ways to detect struggling
students are needed. This paper develops automated tools to predict when a
student is having difficulty. We formed a dataset with the actions of 313
students from two countries and two learning environments: KYPO CRP and
EDURange. These data are used in machine learning algorithms to predict the
success of students in exercises deployed in these environments. After
extracting features from the data, we trained and cross-validated eight
classifiers for predicting the exercise outcome and evaluated their predictive
power. The contribution of this paper is comparing two approaches to feature
engineering, modeling, and classification performance on data from two learning
environments. Using the features from either learning environment, we were able
to detect and distinguish between successful and struggling students. A
decision tree classifier achieved the highest balanced accuracy and sensitivity
with data from both learning environments. The results show that activity data
from cybersecurity exercises are suitable for predicting student success. In a
potential application, such models can aid instructors in detecting struggling
students and providing targeted help. We publish data and code for building
these models so that others can adopt or adapt them.

ÊëòË¶ÅÔºö<paragraph>ÈÄôÁØáÁ†îÁ©∂ËªåË∑°ÁöÑÂÆåÊï¥Ë´ñÊñáË©ï‰º∞‰∫ÜÂæûÁ∂≤Ë∑ØÂÆâÂÖ®Á∑¥Áøí‰∏≠Ë®òÈåÑÁöÑË≥áÊñôÁöÑ‰ΩøÁî®Ôºå‰ª•È†êÊ∏¨ÊΩõÂú®Ë°®Áèæ‰∏ç‰Ω≥ÁöÑÂ≠∏Áîü„ÄÇÂãïÊâãÁ∑¥ÁøíÂ∞çÂ≠∏ÁøíËá≥ÈóúÈáçË¶ÅÔºåÂõ†ÁÇ∫ÂÆÉÂÄëËÉΩËÆìÂ≠∏ÁîüÁ∑¥Áøí‰ªñÂÄëÁöÑÊäÄËÉΩ„ÄÇÂú®Á∂≤Ë∑ØÂÆâÂÖ®‰∏≠ÔºåÂãïÊâãÁ∑¥ÁøíÈÄöÂ∏∏ÂæàË§áÈõúÔºåÈúÄË¶Å‰∫ÜËß£Ë®±Â§ö‰∏ªÈ°å„ÄÇÂõ†Ê≠§ÔºåÂ≠∏ÁîüÂèØËÉΩÊúÉÂõ†ÁÇ∫Áü•Ë≠ò‰∏äÁöÑÂ∑ÆË∑ùËÄåÈåØÂ§±Ëß£Ê±∫ÊñπÊ°àÔºå‰∏¶ÊÑüÂà∞Ê≤ÆÂñ™ÔºåÈÄôÊúÉÈòªÁ§ô‰ªñÂÄëÁöÑÂ≠∏Áøí„ÄÇÊåáÂ∞éÂì°ÁöÑÁõÆÊ®ôÂçîÂä©ÊúâÂπ´Âä©Ôºå‰ΩÜÁî±ÊñºÊåáÂ∞éÂì°ÁöÑÊôÇÈñìÊúâÈôêÔºåÂõ†Ê≠§ÈúÄË¶ÅÊúâÊïàÁöÑÊñπÊ≥ï‰æÜÊâæÂá∫ÊúâÂõ∞Èõ£ÁöÑÂ≠∏Áîü„ÄÇÊú¨ÊñáÈñãÁôº‰∫ÜËá™ÂãïÂåñÂ∑•ÂÖ∑‰æÜÈ†êÊ∏¨Â≠∏Áîü‰ΩïÊôÇÈÅáÂà∞Âõ∞Èõ£„ÄÇÊàëÂÄëÂæûÂÖ©ÂÄãÂúãÂÆ∂ÂíåÂÖ©ÂÄãÂ≠∏ÁøíÁí∞Â¢ÉÔºàKYPO CRP Âíå EDURangeÔºâÁöÑ 313 ÂêçÂ≠∏ÁîüÁöÑË°åÁÇ∫‰∏≠ÂΩ¢Êàê‰∫Ü‰∏ÄÂÄãË≥áÊñôÈõÜ„ÄÇÈÄô‰∫õË≥áÊñôÁî®ÊñºÊ©üÂô®Â≠∏ÁøíÊºîÁÆóÊ≥ïÔºå‰ª•È†êÊ∏¨ÈÄô‰∫õÁí∞Â¢É‰∏≠ÈÉ®ÁΩ≤ÁöÑÁ∑¥Áøí‰∏≠Â≠∏ÁîüÁöÑÊàêÂäü„ÄÇÂæûË≥áÊñô‰∏≠ÊèêÂèñÁâπÂæµÂæåÔºåÊàëÂÄëË®ìÁ∑¥‰∏¶‰∫§ÂèâÈ©óË≠â‰∫ÜÂÖ´ÂÄãÂàÜÈ°ûÂô®Ôºå‰ª•È†êÊ∏¨Á∑¥ÁøíÁµêÊûúÔºå‰∏¶Ë©ï‰º∞ÂÆÉÂÄëÁöÑÈ†êÊ∏¨ËÉΩÂäõ„ÄÇÊú¨ÊñáÁöÑË≤¢ÁçªÊòØÊØîËºÉÂÖ©Á®ÆÁâπÂæµÂ∑•Á®ã„ÄÅÂª∫Ê®°ÂíåÂàÜÈ°ûÊïàËÉΩÁöÑÊñπÊ≥ïÔºåÈÄô‰∫õÊñπÊ≥ï‰æÜËá™ÂÖ©ÂÄãÂ≠∏ÁøíÁí∞Â¢ÉÁöÑË≥áÊñô„ÄÇ‰ΩøÁî®‰æÜËá™‰ªª‰ΩïÂ≠∏ÁøíÁí∞Â¢ÉÁöÑÁâπÂæµÔºåÊàëÂÄëËÉΩÂ§†Ê™¢Ê∏¨‰∏¶ÂçÄÂàÜÊàêÂäüÁöÑÂ≠∏ÁîüÂíåÊúâÂõ∞Èõ£ÁöÑÂ≠∏Áîü„ÄÇ‰∏ÄÂÄãÊ±∫Á≠ñÊ®πÂàÜÈ°ûÂô®Âú®‰æÜËá™ÂÖ©ÂÄãÂ≠∏ÁøíÁí∞Â¢ÉÁöÑË≥áÊñô‰∏≠ÈÅîÂà∞‰∫ÜÊúÄÈ´òÁöÑÂπ≥Ë°°Ê∫ñÁ¢∫Â∫¶ÂíåÊïèÊÑüÂ∫¶„ÄÇÁµêÊûúË°®ÊòéÔºå‰æÜËá™Á∂≤Ë∑ØÂÆâÂÖ®Á∑¥ÁøíÁöÑÊ¥ªÂãïË≥áÊñôÈÅ©Áî®ÊñºÈ†êÊ∏¨Â≠∏ÁîüÁöÑÊàêÂäü„ÄÇÂú®ÊΩõÂú®ÁöÑÊáâÁî®‰∏≠ÔºåÊ≠§È°ûÊ®°ÂûãÂèØ‰ª•Âπ´Âä©ÊåáÂ∞éÂì°Ê™¢Ê∏¨ÊúâÂõ∞Èõ£ÁöÑÂ≠∏Áîü‰∏¶Êèê‰æõÁõÆÊ®ôÂçîÂä©„ÄÇÊàëÂÄëÁôºÂ∏É‰∫ÜÁî®ÊñºÂª∫Á´ãÈÄô‰∫õÊ®°ÂûãÁöÑË≥áÊñôÂíåÁ®ãÂºèÁ¢ºÔºå‰ª•‰æøÂÖ∂‰ªñ‰∫∫ÂèØ‰ª•Êé°Áî®ÊàñË™øÊï¥ÂÆÉÂÄë„ÄÇ</paragraph>

##### **Focus on Focus: Focus-oriented Representation Learning and Multi-view Cross-modal Alignment for Glioma Grading**
2408.08527v1 by Li Pan, Yupei Zhang, Qiushi Yang, Tan Li, Xiaohan Xing, Maximus C. F. Yeung, Zhen Chen

Recently, multimodal deep learning, which integrates histopathology slides
and molecular biomarkers, has achieved a promising performance in glioma
grading. Despite great progress, due to the intra-modality complexity and
inter-modality heterogeneity, existing studies suffer from inadequate
histopathology representation learning and inefficient molecular-pathology
knowledge alignment. These two issues hinder existing methods to precisely
interpret diagnostic molecular-pathology features, thereby limiting their
grading performance. Moreover, the real-world applicability of existing
multimodal approaches is significantly restricted as molecular biomarkers are
not always available during clinical deployment. To address these problems, we
introduce a novel Focus on Focus (FoF) framework with paired pathology-genomic
training and applicable pathology-only inference, enhancing molecular-pathology
representation effectively. Specifically, we propose a Focus-oriented
Representation Learning (FRL) module to encourage the model to identify regions
positively or negatively related to glioma grading and guide it to focus on the
diagnostic areas with a consistency constraint. To effectively link the
molecular biomarkers to morphological features, we propose a Multi-view
Cross-modal Alignment (MCA) module that projects histopathology representations
into molecular subspaces, aligning morphological features with corresponding
molecular biomarker status by supervised contrastive learning. Experiments on
the TCGA GBM-LGG dataset demonstrate that our FoF framework significantly
improves the glioma grading. Remarkably, our FoF achieves superior performance
using only histopathology slides compared to existing multimodal methods. The
source code is available at https://github.com/peterlipan/FoF.

ÊëòË¶ÅÔºö<paragraph>ÊúÄËøëÔºåÊï¥Âêà‰∫ÜÁªÑÁªáÁóÖÁêÜÂ≠¶ÂàáÁâáÂíåÂàÜÂ≠êÁîüÁâ©Ê†áËÆ∞ÁöÑÂ§öÊ®°ÊÄÅÊ∑±Â∫¶Â≠¶‰π†Âú®Á•ûÁªèËÉ∂Ë¥®Áò§ÂàÜÁ∫ß‰∏≠ÂèñÂæó‰∫ÜÂèØÂñúÁöÑÊàêÊûú„ÄÇÂ∞ΩÁÆ°ÂèñÂæó‰∫ÜÂ∑®Â§ßËøõÂ±ïÔºå‰ΩÜÁî±‰∫éÊ®°ÊÄÅÂÜÖÂ§çÊùÇÊÄßÂíåÊ®°ÊÄÅÈó¥ÂºÇË¥®ÊÄßÔºåÁé∞ÊúâÁ†îÁ©∂Â≠òÂú®ÁªÑÁªáÁóÖÁêÜÂ≠¶Ë°®ÂæÅÂ≠¶‰π†‰∏çË∂≥ÂíåÂàÜÂ≠êÁóÖÁêÜÂ≠¶Áü•ËØÜÂØπÈΩêÊïàÁéá‰Ωé‰∏ãÁöÑÈóÆÈ¢ò„ÄÇËøô‰∏§‰∏™ÈóÆÈ¢òÈòªÁ¢ç‰∫ÜÁé∞ÊúâÊñπÊ≥ïÁ≤æÁ°ÆËß£ÈáäËØäÊñ≠ÊÄßÂàÜÂ≠êÁóÖÁêÜÂ≠¶ÁâπÂæÅÔºå‰ªéËÄåÈôêÂà∂‰∫ÜÂÆÉ‰ª¨ÁöÑËØÑÂàÜÊÄßËÉΩ„ÄÇÊ≠§Â§ñÔºåÁé∞ÊúâÂ§öÊ®°ÊÄÅÊñπÊ≥ïÁöÑÂÆûÈôÖÈÄÇÁî®ÊÄßÂèóÂà∞ÂæàÂ§ßÈôêÂà∂ÔºåÂõ†‰∏∫Âú®‰∏¥Â∫äÈÉ®ÁΩ≤ÊúüÈó¥Âπ∂‰∏çÊÄªÊòØËÉΩËé∑ÂæóÂàÜÂ≠êÁîüÁâ©Ê†áËÆ∞„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∫õÈóÆÈ¢òÔºåÊàë‰ª¨ÂºïÂÖ•‰∫Ü‰∏Ä‰∏™‰∏ìÊ≥®‰∫éÁÑ¶ÁÇπ (FoF) ÁöÑÊñ∞Ê°ÜÊû∂ÔºåËØ•Ê°ÜÊû∂ÈááÁî®ÈÖçÂØπÁöÑÁóÖÁêÜÂü∫Âõ†ÁªÑÂ≠¶ËÆ≠ÁªÉÂíåÈÄÇÁî®ÁöÑ‰ªÖÁóÖÁêÜÂ≠¶Êé®Êñ≠ÔºåÊúâÊïàÂú∞Â¢ûÂº∫‰∫ÜÂàÜÂ≠êÁóÖÁêÜÂ≠¶Ë°®ÂæÅ„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏Ä‰∏™Èù¢ÂêëÁÑ¶ÁÇπÁöÑË°®ÂæÅÂ≠¶‰π† (FRL) Ê®°ÂùóÔºå‰ª•ÈºìÂä±Ê®°ÂûãËØÜÂà´‰∏éÁ•ûÁªèËÉ∂Ë¥®Áò§ÂàÜÁ∫ßÂëàÊ≠£Áõ∏ÂÖ≥ÊàñË¥üÁõ∏ÂÖ≥ÁöÑÂå∫ÂüüÔºåÂπ∂ÊåáÂØºÂÖ∂‰∏ìÊ≥®‰∫éÂÖ∑ÊúâÁ®†ÂØÜÁ∫¶ÊùüÁöÑËØäÊñ≠Âå∫Âüü„ÄÇ‰∏∫‰∫ÜÊúâÊïàÂú∞Â∞ÜÂàÜÂ≠êÁîüÁâ©Ê†áËÆ∞‰∏éÂΩ¢ÊÄÅÂ≠¶ÁâπÂæÅËÅîÁ≥ªËµ∑Êù•ÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏Ä‰∏™Â§öËßÜÂõæË∑®Ê®°ÊÄÅÂØπÈΩê (MCA) Ê®°ÂùóÔºåËØ•Ê®°ÂùóÂ∞ÜÁªÑÁªáÁóÖÁêÜÂ≠¶Ë°®ÂæÅÊäïÂΩ±Âà∞ÂàÜÂ≠êÂ≠êÁ©∫Èó¥ÔºåÈÄöËøáÁõëÁù£ÂØπÊØîÂ≠¶‰π†Â∞ÜÂΩ¢ÊÄÅÂ≠¶ÁâπÂæÅ‰∏éÁõ∏Â∫îÁöÑÂàÜÂ≠êÁîüÁâ©Ê†áËÆ∞Áä∂ÊÄÅÂØπÈΩê„ÄÇÂú® TCGA GBM-LGG Êï∞ÊçÆÈõÜ‰∏äÁöÑÂÆûÈ™åË°®ÊòéÔºåÊàë‰ª¨ÁöÑ FoF Ê°ÜÊû∂ÊòæÁùÄÊèêÈ´ò‰∫ÜÁ•ûÁªèËÉ∂Ë¥®Áò§ÂàÜÁ∫ß„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºå‰∏éÁé∞ÊúâÁöÑÂ§öÊ®°ÊÄÅÊñπÊ≥ïÁõ∏ÊØîÔºåÊàë‰ª¨ÁöÑ FoF ‰ªÖ‰ΩøÁî®ÁªÑÁªáÁóÖÁêÜÂ≠¶ÂàáÁâáÂ∞±ÂèñÂæó‰∫Ü‰ºòÂºÇÁöÑÊÄßËÉΩ„ÄÇÊ∫ê‰ª£Á†ÅÂèØÂú® https://github.com/peterlipan/FoF Ëé∑Âæó„ÄÇ</paragraph>

##### **Ex3: Automatic Novel Writing by Extracting, Excelsior and Expanding**
2408.08506v1 by Huang Lei, Jiaming Guo, Guanhua He, Xishan Zhang, Rui Zhang, Shaohui Peng, Shaoli Liu, Tianshi Chen

Generating long-term texts such as novels using artificial intelligence has
always been a challenge. A common approach is to use large language models
(LLMs) to construct a hierarchical framework that first plans and then writes.
Despite the fact that the generated novels reach a sufficient length, they
exhibit poor logical coherence and appeal in their plots and deficiencies in
character and event depiction, ultimately compromising the overall narrative
quality. In this paper, we propose a method named Extracting Excelsior and
Expanding. Ex3 initially extracts structure information from raw novel data. By
combining this structure information with the novel data, an
instruction-following dataset is meticulously crafted. This dataset is then
utilized to fine-tune the LLM, aiming for excelsior generation performance. In
the final stage, a tree-like expansion method is deployed to facilitate the
generation of arbitrarily long novels. Evaluation against previous methods
showcases Ex3's ability to produce higher-quality long-form novels.

ÊëòË¶ÅÔºö‰ΩøÁî®‰∫∫Â∑•Êô∫ÊÖßÁîüÊàêÈï∑ÁØáÊñáÂ≠óÔºà‰æãÂ¶ÇÂ∞èË™™Ôºâ‰∏ÄÁõ¥ÊòØ‰∏ÄÈ†ÖÊåëÊà∞„ÄÇÂ∏∏Ë¶ãÁöÑÊñπÊ≥ïÊòØ‰ΩøÁî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âª∫Á´ãÈöéÂ±§Êû∂ÊßãÔºåÂÖàÈÄ≤Ë°åË¶èÂäÉÔºåÂÜçÈÄ≤Ë°åÂØ´‰Ωú„ÄÇÂÑòÁÆ°ÁîüÊàêÁöÑÈï∑ÁØáÂ∞èË™™Èï∑Â∫¶Ë∂≥Â§†Ôºå‰ΩÜÊÉÖÁØÄÁº∫‰πèÈÇèËºØ‰∏ÄËá¥ÊÄßÂíåÂê∏ÂºïÂäõÔºå‰∏îÂú®ËßíËâ≤Âíå‰∫ã‰ª∂ÊèèÂØ´‰∏äÊúâÊâÄ‰∏çË∂≥ÔºåÊúÄÁµÇÂΩ±ÈüøÊï¥È´îÊïò‰∫ãÁöÑÂìÅË≥™„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂêçÁÇ∫„ÄåÊèêÂèñÁ≤æËèØ‰∏¶Êì¥ÂÖÖ„ÄçÁöÑÊñπÊ≥ï„ÄÇEx3 ÊúÄÂàùÂæûÂéüÂßãÂ∞èË™™Ë≥áÊñô‰∏≠ÊèêÂèñÁµêÊßãË≥áË®ä„ÄÇÈÄèÈÅéÂ∞áÊ≠§ÁµêÊßãË≥áË®äËàáÂ∞èË™™Ë≥áÊñôÁµêÂêàÔºåÁ≤æÂøÉË£Ω‰Ωú‰∏ÄÂÄãÈÅµÂæ™Ë™™ÊòéÁöÑË≥áÊñôÈõÜ„ÄÇÁÑ∂Âæå‰ΩøÁî®Ê≠§Ë≥áÊñôÈõÜÂæÆË™ø LLMÔºåÁõÆÊ®ôÊòØÁç≤ÂæóÂçìË∂äÁöÑÁîüÊàêÊïàËÉΩ„ÄÇÂú®ÊúÄÂæå‰∏ÄÂÄãÈöéÊÆµÔºåÈÉ®ÁΩ≤Ê®πÁãÄÊì¥ÂÖÖÊñπÊ≥ïÔºå‰ª•Âà©ÊñºÁîüÊàê‰ªªÊÑèÈï∑Â∫¶ÁöÑÈï∑ÁØáÂ∞èË™™„ÄÇËàáÂÖàÂâçÊñπÊ≥ïÁöÑË©ï‰º∞ÁµêÊûúÈ°ØÁ§∫ÔºåEx3 ËÉΩÂ§†Áî¢ÁîüÂìÅË≥™Êõ¥È´òÁöÑÈï∑ÁØáÂ∞èË™™„ÄÇ

##### **Adversarial Contrastive Learning Based Physics-Informed Temporal Networks for Cuffless Blood Pressure Estimation**
2408.08488v1 by Rui Wang, Mengshi Qi, Yingxia Shao, Anfu Zhou, Huadong Ma

Time series data mining is immensely important in extensive applications,
such as traffic, medical, and e-commerce. In this paper, we focus on medical
temporal variation modeling, \emph{i.e.,} cuffless blood pressure (BP)
monitoring which has great value in cardiovascular healthcare. Although
providing a comfortable user experience, such methods are suffering from the
demand for a significant amount of realistic data to train an individual model
for each subject, especially considering the invasive or obtrusive BP
ground-truth measurements. To tackle this challenge, we introduce a novel
physics-informed temporal network~(PITN) with adversarial contrastive learning
to enable precise BP estimation with very limited data. Specifically, we first
enhance the physics-informed neural network~(PINN) with the temporal block for
investigating BP dynamics' multi-periodicity for personal cardiovascular cycle
modeling and temporal variation. We then employ adversarial training to
generate extra physiological time series data, improving PITN's robustness in
the face of sparse subject-specific training data. Furthermore, we utilize
contrastive learning to capture the discriminative variations of cardiovascular
physiologic phenomena. This approach aggregates physiological signals with
similar blood pressure values in latent space while separating clusters of
samples with dissimilar blood pressure values. Experiments on three
widely-adopted datasets with different modailties (\emph{i.e.,} bioimpedance,
PPG, millimeter-wave) demonstrate the superiority and effectiveness of the
proposed methods over previous state-of-the-art approaches. The code is
available at~\url{https://github.com/Zest86/ACL-PITN}.

ÊëòË¶ÅÔºö<paragraph>ÊôÇÈñìÂ∫èÂàóË≥áÊñôÊé¢ÂãòÂú®Âª£Ê≥õÁöÑÊáâÁî®‰∏≠ÈùûÂ∏∏ÈáçË¶ÅÔºå‰æãÂ¶Ç‰∫§ÈÄö„ÄÅÈÜ´ÁôÇÂíåÈõªÂ≠êÂïÜÂãô„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂ∞àÊ≥®ÊñºÈÜ´ÁôÇÊôÇÈñìËÆäÁï∞Âª∫Ê®°ÔºåÂç≥ÁÑ°Ë¢ñË°ÄÂ£ì (BP) Áõ£Ê∏¨ÔºåÈÄôÂú®ÂøÉË°ÄÁÆ°‰øùÂÅ•‰∏≠ÂÖ∑ÊúâÊ•µÈ´òÁöÑÂÉπÂÄº„ÄÇÂÑòÁÆ°Êèê‰æõ‰∫ÜËàíÈÅ©ÁöÑ‰ΩøÁî®ËÄÖÈ´îÈ©óÔºå‰ΩÜÊ≠§È°ûÊñπÊ≥ïÂçªËã¶ÊñºÈúÄË¶ÅÂ§ßÈáèÁöÑÂØ¶ÈöõË≥áÊñô‰æÜË®ìÁ∑¥ÊØèÂÄãÂèóË©¶ËÄÖÁöÑÂÄãÂà•Ê®°ÂûãÔºåÁâπÂà•ÊòØËÄÉÊÖÆÂà∞‰æµÂÖ•ÊÄßÊàñ‰æµÂÖ•ÊÄßÁöÑ BP ÁúüÂØ¶Ê∏¨Èáè„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∏ÄÊåëÊà∞ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÊñ∞ÁöÑÁâ©ÁêÜË≥áË®äÊôÇÈñìÁ∂≤Ë∑Ø (PITN)Ôºå‰∏¶ÁµêÂêàÂ∞çÊäóÂ∞çÊØîÂ≠∏ÁøíÔºå‰ª•Ê•µÂ∞ëÁöÑË≥áÊñôÈÄ≤Ë°åÁ≤æÁ¢∫ÁöÑ BP ‰º∞Ë®à„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÈ¶ñÂÖà‰ΩøÁî®ÊôÇÈñìÂçÄÂ°äÂ¢ûÂº∑‰∫ÜÁâ©ÁêÜË≥áË®äÁ•ûÁ∂ìÁ∂≤Ë∑Ø (PINN)Ôºå‰ª•Á†îÁ©∂ BP ÂãïÊÖãÁöÑÂ§öÈÄ±ÊúüÊÄßÔºåÁî®ÊñºÂÄã‰∫∫ÂøÉË°ÄÁÆ°ÈÄ±ÊúüÂª∫Ê®°ÂíåÊôÇÈñìËÆäÁï∞„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÊé°Áî®Â∞çÊäóË®ìÁ∑¥‰æÜÁî¢ÁîüÈ°çÂ§ñÁöÑÁîüÁêÜÊôÇÈñìÂ∫èÂàóË≥áÊñôÔºå‰ª•ÊèêÈ´ò PITN Âú®Á®ÄÁñèÂèóË©¶ËÄÖÁâπÂÆöË®ìÁ∑¥Ë≥áÊñôÈù¢ÂâçÁöÑÈ≠ØÊ£íÊÄß„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂà©Áî®Â∞çÊØîÂ≠∏Áøí‰æÜÊçïÊçâÂøÉË°ÄÁÆ°ÁîüÁêÜÁèæË±°ÁöÑÂçÄÂà•ÊÄßËÆäÁï∞„ÄÇÊ≠§ÊñπÊ≥ïÂ∞áÊΩõÂú®Á©∫Èñì‰∏≠ÂÖ∑ÊúâÈ°û‰ººË°ÄÂ£ìÂÄºÁöÑÁîüÁêÜË®äËôüËÅöÈõÜÂú®‰∏ÄËµ∑ÔºåÂêåÊôÇÂ∞áÂÖ∑Êúâ‰∏çÂêåË°ÄÂ£ìÂÄºÁöÑÊ®£Êú¨Âè¢ÈõÜÂàÜÈñã„ÄÇÂú®‰∏âÂÄãÂª£Ê≥õÊé°Áî®ÁöÑÂÖ∑Êúâ‰∏çÂêåÊ®°ÊÖãÁöÑË≥áÊñôÈõÜÔºàÂç≥ÁîüÁâ©ÈòªÊäó„ÄÅPPG„ÄÅÊØ´Á±≥Ê≥¢Ôºâ‰∏äÁöÑÂØ¶È©óË≠âÊòé‰∫ÜÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÂÑ™ÊñºÂÖàÂâçÁöÑÊúÄÂÖàÈÄ≤ÊñπÊ≥ï„ÄÇÁ®ãÂºèÁ¢ºÂèØÂú®~\url{https://github.com/Zest86/ACL-PITN}ÂèñÂæó„ÄÇ</paragraph>

##### **An Unsupervised Learning Framework Combined with Heuristics for the Maximum Minimal Cut Problem**
2408.08484v1 by Huaiyuan Liu, Xianzhang Liu, Donghua Yang, Hongzhi Wang, Yingchi Long, Mengtong Ji, Dongjing Miao, Zhiyu Liang

The Maximum Minimal Cut Problem (MMCP), a NP-hard combinatorial optimization
(CO) problem, has not received much attention due to the demanding and
challenging bi-connectivity constraint. Moreover, as a CO problem, it is also a
daunting task for machine learning, especially without labeled instances. To
deal with these problems, this work proposes an unsupervised learning framework
combined with heuristics for MMCP that can provide valid and high-quality
solutions. As far as we know, this is the first work that explores machine
learning and heuristics to solve MMCP. The unsupervised solver is inspired by a
relaxation-plus-rounding approach, the relaxed solution is parameterized by
graph neural networks, and the cost and penalty of MMCP are explicitly written
out, which can train the model end-to-end. A crucial observation is that each
solution corresponds to at least one spanning tree. Based on this finding, a
heuristic solver that implements tree transformations by adding vertices is
utilized to repair and improve the solution quality of the unsupervised solver.
Alternatively, the graph is simplified while guaranteeing solution consistency,
which reduces the running time. We conduct extensive experiments to evaluate
our framework and give a specific application. The results demonstrate the
superiority of our method against two techniques designed.

ÊëòË¶ÅÔºöÊúÄÂ§ßÊúÄÂ∞èÂâ≤ÂïèÈ°å (MMCP) ÊòØ‰∏ÄÂÄã NP Èõ£ÁµÑÂêàÊúÄ‰Ω≥Âåñ (CO) ÂïèÈ°åÔºåÁî±ÊñºË¶ÅÊ±ÇÂö¥Ê†º‰∏îÂÖ∑ÊúâÊåëÊà∞ÊÄßÁöÑÈõôÈÄ£ÈÄöÁ¥ÑÊùüÔºåÂõ†Ê≠§Êú™ÂèóÂà∞Â§™Â§öÈóúÊ≥®„ÄÇÊ≠§Â§ñÔºå‰ΩúÁÇ∫‰∏ÄÂÄã CO ÂïèÈ°åÔºåÂ∞çÊñºÊ©üÂô®Â≠∏ÁøíËÄåË®Ä‰πüÊòØ‰∏ÄÈ†ÖËâ±ÈâÖÁöÑ‰ªªÂãôÔºåÁâπÂà•ÊòØÂú®Ê≤íÊúâÊ®ôË®òÂØ¶‰æãÁöÑÊÉÖÊ≥Å‰∏ã„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÂïèÈ°åÔºåÊú¨Á†îÁ©∂ÊèêÂá∫‰∫Ü‰∏ÄÂÄãÁÑ°Áõ£Áù£Â≠∏ÁøíÊû∂ÊßãÔºåÁµêÂêà MMCP ÁöÑÂïüÁôºÂºèÊñπÊ≥ïÔºåÂèØ‰ª•Êèê‰æõÊúâÊïà‰∏îÈ´òÂìÅË≥™ÁöÑËß£Ê±∫ÊñπÊ°à„ÄÇÊìöÊàëÂÄëÊâÄÁü•ÔºåÈÄôÊòØÁ¨¨‰∏ÄÂÄãÊé¢Ë®éÊ©üÂô®Â≠∏ÁøíÂíåÂïüÁôºÂºèÊñπÊ≥ï‰æÜËß£Ê±∫ MMCP ÁöÑÁ†îÁ©∂„ÄÇÁÑ°Áõ£Áù£Ê±ÇËß£Âô®ÂèóÂà∞È¨ÜÂºõÂä†Êç®ÂÖ•ÊñπÊ≥ïÁöÑÂïüÁôºÔºåÈ¨ÜÂºõËß£Áî±ÂúñÁ•ûÁ∂ìÁ∂≤Ë∑ØÂèÉÊï∏ÂåñÔºåËÄå MMCP ÁöÑÊàêÊú¨ÂíåÊá≤ÁΩ∞ÂâáÊòéÁ¢∫ÂØ´Âá∫ÔºåÈÄôÂèØ‰ª•Á´ØÂà∞Á´ØÂú∞Ë®ìÁ∑¥Ê®°Âûã„ÄÇ‰∏ÄÂÄãÈóúÈçµÁöÑËßÄÂØüÊòØÔºåÊØèÂÄãËß£ÈÉΩÂ∞çÊáâÊñºËá≥Â∞ë‰∏ÄÊ£µÁîüÊàêÊ®π„ÄÇÂü∫ÊñºÈÄôÂÄãÁôºÁèæÔºåÂà©Áî®‰∏ÄÂÄãÈÄöÈÅéÂ¢ûÂä†È†ÇÈªû‰æÜÂØ¶‰ΩúÊ®πËΩâÊèõÁöÑÂïüÁôºÂºèÊ±ÇËß£Âô®ÔºåÁî®Êñº‰øÆÂæ©ÂíåÊîπÂñÑÁÑ°Áõ£Áù£Ê±ÇËß£Âô®ÁöÑËß£ÂìÅË≥™„ÄÇÊàñËÄÖÔºåÂú®‰øùË≠âËß£‰∏ÄËá¥ÊÄßÁöÑÂêåÊôÇÁ∞°ÂåñÂúñÂΩ¢ÔºåÂæûËÄåÊ∏õÂ∞ëÂü∑Ë°åÊôÇÈñì„ÄÇÊàëÂÄëÈÄ≤Ë°å‰∫ÜÂª£Ê≥õÁöÑÂØ¶È©ó‰æÜË©ï‰º∞ÊàëÂÄëÁöÑÊ°ÜÊû∂‰∏¶Áµ¶Âá∫‰∏ÄÂÄãÂÖ∑È´îÁöÑÊáâÁî®„ÄÇÁµêÊûúË≠âÊòé‰∫ÜÊàëÂÄëÁöÑÊñπÊ≥ïÂÑ™ÊñºÂÖ©Á®ÆË®≠Ë®àÁöÑÊäÄË°ì„ÄÇ

##### **Fairness Issues and Mitigations in (Differentially Private) Socio-demographic Data Processes**
2408.08471v1 by Joonhyuk Ko, Juba Ziani, Saswat Das, Matt Williams, Ferdinando Fioretto

Statistical agencies rely on sampling techniques to collect socio-demographic
data crucial for policy-making and resource allocation. This paper shows that
surveys of important societal relevance introduce sampling errors that unevenly
impact group-level estimates, thereby compromising fairness in downstream
decisions. To address these issues, this paper introduces an optimization
approach modeled on real-world survey design processes, ensuring sampling costs
are optimized while maintaining error margins within prescribed tolerances.
Additionally, privacy-preserving methods used to determine sampling rates can
further impact these fairness issues. The paper explores the impact of
differential privacy on the statistics informing the sampling process,
revealing a surprising effect: not only the expected negative effect from the
addition of noise for differential privacy is negligible, but also this privacy
noise can in fact reduce unfairness as it positively biases smaller counts.
These findings are validated over an extensive analysis using datasets commonly
applied in census statistics.

ÊëòË¶ÅÔºöÁµ±Ë®àÊ©üÊßã‰æùË≥¥ÊäΩÊ®£ÊäÄË°ì‰æÜÊî∂ÈõÜÂ∞çÊîøÁ≠ñÂà∂ÂÆöÂíåË≥áÊ∫êÂàÜÈÖçËá≥ÈóúÈáçË¶ÅÁöÑÁ§æÊúÉ‰∫∫Âè£Êï∏Êìö„ÄÇÊú¨ÊñáÈ°ØÁ§∫ÔºåÂÖ∑ÊúâÈáçË¶ÅÁ§æÊúÉÁõ∏ÈóúÊÄßÁöÑË™øÊü•ÊúÉÂºïÂÖ•ÊäΩÊ®£Ë™§Â∑ÆÔºåÂ∞çÁµÑÁ¥ö‰º∞Ë®àÁî¢Áîü‰∏çÂùáÂãªÁöÑÂΩ±ÈüøÔºåÂæûËÄåÊêçÂÆ≥‰∏ãÊ∏∏Ê±∫Á≠ñÁöÑÂÖ¨Âπ≥ÊÄß„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÂïèÈ°åÔºåÊú¨Êñá‰ªãÁ¥π‰∫Ü‰∏ÄÁ®Æ‰ª•ÁèæÂØ¶‰∏ñÁïåÁöÑË™øÊü•Ë®≠Ë®àÊµÅÁ®ãÁÇ∫Ê®°ÂûãÁöÑÂÑ™ÂåñÊñπÊ≥ïÔºå‰ª•Á¢∫‰øùÂú®Ë¶èÂÆöÁöÑÂÆπÂ∑ÆÁØÑÂúçÂÖßÂÑ™ÂåñÊäΩÊ®£ÊàêÊú¨ÔºåÂêåÊôÇ‰øùÊåÅË™§Â∑ÆÁØÑÂúç„ÄÇÊ≠§Â§ñÔºåÁî®ÊñºÁ¢∫ÂÆöÊäΩÊ®£ÁéáÁöÑÈö±ÁßÅ‰øùË≠∑ÊñπÊ≥ïÂèØËÉΩÊúÉÈÄ≤‰∏ÄÊ≠•ÂΩ±ÈüøÈÄô‰∫õÂÖ¨Âπ≥ÊÄßÂïèÈ°å„ÄÇÊú¨ÊñáÊé¢Ë®é‰∫ÜÂ∑ÆÂàÜÈö±ÁßÅÂ∞çÊäΩÊ®£ÈÅéÁ®ã‰∏≠ÁöÑÁµ±Ë®àÊï∏ÊìöÁöÑÂΩ±ÈüøÔºåÊè≠Á§∫‰∫Ü‰∏ÄÂÄã‰ª§‰∫∫È©öË®ùÁöÑÂΩ±ÈüøÔºö‰∏çÂÉÖÂ∑ÆÂàÜÈö±ÁßÅÂ¢ûÂä†Âô™ËÅ≤ÁöÑÈ†êÊúüË≤†Èù¢ÂΩ±ÈüøÂèØ‰ª•ÂøΩÁï•‰∏çË®àÔºåËÄå‰∏îÈÄôÁ®ÆÈö±ÁßÅÂô™ËÅ≤ÂØ¶Èöõ‰∏äÂèØ‰ª•Ê∏õÂ∞ë‰∏çÂÖ¨Âπ≥ÊÄßÔºåÂõ†ÁÇ∫ÂÆÉÂ∞çËºÉÂ∞èÁöÑË®àÊï∏Áî¢ÁîüÊ≠£ÂêëÂÅèÂ∑Æ„ÄÇÈÄô‰∫õÁôºÁèæÈÄöÈÅé‰ΩøÁî®ÈÄöÂ∏∏ÊáâÁî®Êñº‰∫∫Âè£ÊôÆÊü•Áµ±Ë®àÊï∏ÊìöÁöÑÊï∏ÊìöÈõÜÈÄ≤Ë°åÂª£Ê≥õÂàÜÊûêÂæóÂà∞È©óË≠â„ÄÇ

##### **Context-Aware Assistant Selection for Improved Inference Acceleration with Large Language Models**
2408.08470v1 by Jerry Huang, Prasanna Parthasarathi, Mehdi Rezagholizadeh, Sarath Chandar

Despite their widespread adoption, large language models (LLMs) remain
prohibitive to use under resource constraints, with their ever growing sizes
only increasing the barrier for use. One noted issue is the high latency
associated with auto-regressive generation, rendering large LLMs use dependent
on advanced computing infrastructure. Assisted decoding, where a smaller draft
model guides a larger target model's generation, has helped alleviate this, but
remains dependent on alignment between the two models. Thus if the draft model
is insufficiently capable on some domain relative to the target model,
performance can degrade. Alternatively, one can leverage multiple draft models
to better cover the expertise of the target, but when multiple black-box draft
models are available, selecting an assistant without details about its
construction can be difficult. To better understand this decision making
problem, we observe it as a contextual bandit, where a policy must choose a
draft model based on a context. We show that even without prior knowledge of
the draft models, creating an offline dataset from only outputs of independent
draft/target models and training a policy over the alignment of these outputs
can accelerate performance on multiple domains provided the candidates are
effective. Further results show this to hold on various settings with multiple
assisted decoding candidates, highlighting its flexibility and the advantageous
role that such decision making can play.

ÊëòË¶ÅÔºöÂÑòÁÆ°Â§ßË™ûË®ÄÊ®°Âûã (LLM) Âª£Ê≥õÊé°Áî®Ôºå‰ΩÜÁî±ÊñºÂÖ∂Ë¶èÊ®°‰∏çÊñ∑Êì¥Â§ßÔºåÂú®Ë≥áÊ∫êÂèóÈôêÁöÑÊÉÖÊ≥Å‰∏ã‰ΩøÁî®Ëµ∑‰æÜ‰ªçÁÑ∂ÊúâÂÖ∂ÈôêÂà∂ÔºåÈÄôÂè™ÊúÉÂ¢ûÂä†‰ΩøÁî®ÈöúÁ§ô„ÄÇ‰∏ÄÂÄãËëóÂêçÁöÑÂïèÈ°åÊòØËàáËá™Ëø¥Ê≠∏ÁîüÊàêÁõ∏ÈóúÁöÑÈ´òÂª∂ÈÅ≤ÔºåÈÄô‰ΩøÂæóÂ§ßÂûã LLM ÁöÑ‰ΩøÁî®‰æùË≥¥ÊñºÂÖàÈÄ≤ÁöÑÈÅãÁÆóÂü∫Á§éË®≠ÊñΩ„ÄÇËºîÂä©Ëß£Á¢ºÔºåÂÖ∂‰∏≠ËºÉÂ∞èÁöÑËçâÁ®øÊ®°ÂûãÂºïÂ∞éËºÉÂ§ßÁöÑÁõÆÊ®ôÊ®°ÂûãÁîüÊàêÔºåÊúâÂä©ÊñºÁ∑©Ëß£ÈÄôÂÄãÂïèÈ°åÔºå‰ΩÜ‰ªçÁÑ∂‰æùË≥¥ÊñºÂÖ©ÂÄãÊ®°Âûã‰πãÈñìÁöÑ‰∏ÄËá¥ÊÄß„ÄÇÂõ†Ê≠§ÔºåÂ¶ÇÊûúËçâÁ®øÊ®°ÂûãÂú®Êüê‰∫õÈ†òÂüüÁõ∏Â∞çÊñºÁõÆÊ®ôÊ®°ÂûãÁöÑËÉΩÂäõ‰∏çË∂≥ÔºåÂâáÊïàËÉΩÂèØËÉΩÊúÉ‰∏ãÈôç„ÄÇÊàñËÄÖÔºå‰∫∫ÂÄëÂèØ‰ª•Âà©Áî®Â§öÂÄãËçâÁ®øÊ®°Âûã‰æÜÊõ¥Â•ΩÂú∞Ê∂µËìãÁõÆÊ®ôÁöÑÂ∞àÊ•≠Áü•Ë≠òÔºå‰ΩÜÁï∂ÊúâÂ§öÂÄãÈªëÁõíËçâÁ®øÊ®°ÂûãÂèØÁî®ÊôÇÔºåÂú®Ê≤íÊúâÈóúÊñºÂÖ∂Âª∫ÊßãÁöÑË©≥Á¥∞Ë≥áË®äÁöÑÊÉÖÊ≥Å‰∏ãÈÅ∏Êìá‰∏ÄÂÄãÂä©ÊâãÂèØËÉΩÊúÉÂæàÂõ∞Èõ£„ÄÇÁÇ∫‰∫ÜÊõ¥Â•ΩÂú∞ÁêÜËß£ÈÄôÂÄãÊ±∫Á≠ñÂà∂ÂÆöÂïèÈ°åÔºåÊàëÂÄëÂ∞áÂÖ∂Ë¶ñÁÇ∫‰∏ÄÂÄãÊÉÖÂ¢ÉÂº∑ÁõúÔºåÂÖ∂‰∏≠‰∏ÄÂÄãÁ≠ñÁï•ÂøÖÈ†àÊ†πÊìö‰∏ÄÂÄãÊÉÖÂ¢ÉÈÅ∏Êìá‰∏ÄÂÄãËçâÁ®øÊ®°Âûã„ÄÇÊàëÂÄëË°®ÊòéÔºåÂç≥‰ΩøÊ≤íÊúâÈóúÊñºËçâÁ®øÊ®°ÂûãÁöÑÂÖàÈ©óÁü•Ë≠òÔºåÂÉÖÂæûÁç®Á´ãËçâÁ®ø/ÁõÆÊ®ôÊ®°ÂûãÁöÑËº∏Âá∫Âª∫Á´ãÈõ¢Á∑öË≥áÊñôÈõÜÔºå‰∏¶Ê†πÊìöÈÄô‰∫õËº∏Âá∫ÁöÑÂ∞çÈΩäË®ìÁ∑¥‰∏ÄÂÄãÁ≠ñÁï•Ôºå‰πüÂèØ‰ª•Âä†ÈÄüÂ§öÂÄãÈ†òÂüüÁöÑÊïàËÉΩÔºåÂâçÊèêÊòØÂÄôÈÅ∏ËÄÖÊòØÊúâÊïàÁöÑ„ÄÇÈÄ≤‰∏ÄÊ≠•ÁöÑÁµêÊûúË°®ÊòéÔºåÈÄôÈÅ©Áî®ÊñºÂÖ∑ÊúâÂ§öÂÄãËºîÂä©Ëß£Á¢ºÂÄôÈÅ∏ËÄÖÁöÑÂêÑÁ®ÆË®≠ÂÆöÔºåÁ™ÅÈ°Ø‰∫ÜÂÖ∂ÈùàÊ¥ªÊÄß‰ª•ÂèäÊ≠§È°ûÊ±∫Á≠ñÂà∂ÂÆöÂèØ‰ª•ÁôºÊèÆÁöÑÊúâÂà©‰ΩúÁî®„ÄÇ

##### **A theory of understanding for artificial intelligence: composability, catalysts, and learning**
2408.08463v1 by Zijian Zhang, Sara Aronowitz, Al√°n Aspuru-Guzik

Understanding is a crucial yet elusive concept in artificial intelligence
(AI). This work proposes a framework for analyzing understanding based on the
notion of composability. Given any subject (e.g., a person or an AI), we
suggest characterizing its understanding of an object in terms of its ability
to process (compose) relevant inputs into satisfactory outputs from the
perspective of a verifier. This highly universal framework can readily apply to
non-human subjects, such as AIs, non-human animals, and institutions. Further,
we propose methods for analyzing the inputs that enhance output quality in
compositions, which we call catalysts. We show how the structure of a subject
can be revealed by analyzing its components that act as catalysts and argue
that a subject's learning ability can be regarded as its ability to compose
inputs into its inner catalysts. Finally we examine the importance of learning
ability for AIs to attain general intelligence. Our analysis indicates that
models capable of generating outputs that can function as their own catalysts,
such as language models, establish a foundation for potentially overcoming
existing limitations in AI understanding.

ÊëòË¶ÅÔºöÁêÜËß£ÊòØ‰∫∫Â∑•Êô∫ËÉΩÔºàAIÔºâ‰∏≠‰∏ÄÂÄãËá≥ÈóúÈáçË¶ÅÁöÑÂçªÂèàÈõ£‰ª•ÊçâÊë∏ÁöÑÊ¶ÇÂøµ„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂü∫ÊñºÂèØÁµÑÂêàÊÄßÁöÑÁêÜËß£ÂàÜÊûêÊ°ÜÊû∂„ÄÇÁµ¶ÂÆö‰ªª‰Ωï‰∏ªÈ´îÔºà‰æãÂ¶ÇÔºå‰∏ÄÂÄã‰∫∫Êàñ‰∏ÄÂÄã AIÔºâÔºåÊàëÂÄëÂª∫Ë≠∞Ê†πÊìöÂÖ∂Â∞áÁõ∏ÈóúËº∏ÂÖ•ËôïÁêÜÔºàÁµÑÂêàÔºâÊàêÈ©óË≠âËÄÖËßíÂ∫¶ÁöÑÊªøÊÑèËº∏Âá∫ÁöÑËÉΩÂäõ‰æÜË°®ÂæµÂÖ∂Â∞ç‰∏ÄÂÄãÁâ©È´îÁöÑÁêÜËß£„ÄÇÈÄôÂÄãÈ´òÂ∫¶ÈÄöÁî®ÁöÑÊ°ÜÊû∂ÂèØ‰ª•ÂæàÂÆπÊòìÂú∞ÊáâÁî®ÊñºÈùû‰∫∫È°û‰∏ªÈ´îÔºå‰æãÂ¶Ç AI„ÄÅÈùû‰∫∫È°ûÂãïÁâ©ÂíåÊ©üÊßã„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèêÂá∫‰∫ÜÂàÜÊûêÂ¢ûÂº∑ÁµÑÂêà‰∏≠Ëº∏Âá∫Ë≥™ÈáèÁöÑËº∏ÂÖ•ÁöÑÊñπÊ≥ïÔºåÊàëÂÄëÁ®±‰πãÁÇ∫ÂÇ¨ÂåñÂäë„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫ÜÂ¶Ç‰ΩïÈÄöÈÅéÂàÜÊûêÂÖÖÁï∂ÂÇ¨ÂåñÂäëÁöÑ‰∏ªÈ´îÁµÑÊàêÈÉ®ÂàÜ‰æÜÊè≠Á§∫‰∏ªÈ´îÁöÑÁµêÊßãÔºå‰∏¶Ë´ñË≠â‰∏ªÈ´îÁöÑÂ≠∏ÁøíËÉΩÂäõÂèØ‰ª•Ë¢´Ë¶ñÁÇ∫ÂÖ∂Â∞áËº∏ÂÖ•ÁµÑÂêàÂà∞ÂÖ∂ÂÖßÈÉ®ÂÇ¨ÂåñÂäë‰∏≠ÁöÑËÉΩÂäõ„ÄÇÊúÄÂæåÔºåÊàëÂÄëÊé¢Ë®é‰∫ÜÂ≠∏ÁøíËÉΩÂäõÂ∞çÊñº AI ÈÅîÂà∞‰∏ÄËà¨Êô∫ËÉΩÁöÑÈáçË¶ÅÊÄß„ÄÇÊàëÂÄëÁöÑÂàÜÊûêË°®ÊòéÔºåËÉΩÂ§†ÁîüÊàêÂèØ‰ª•‰ΩúÁÇ∫ÂÖ∂Ëá™Ë∫´ÂÇ¨ÂåñÂäëÈÅã‰ΩúÁöÑËº∏Âá∫ÁöÑÊ®°ÂûãÔºå‰æãÂ¶ÇË™ûË®ÄÊ®°ÂûãÔºåÁÇ∫ÊΩõÂú®Âú∞ÂÖãÊúç AI ÁêÜËß£‰∏≠ÁöÑÁèæÊúâÂ±ÄÈôêÊÄßÂ•†ÂÆö‰∫ÜÂü∫Á§é„ÄÇ

##### **JPEG-LM: LLMs as Image Generators with Canonical Codec Representations**
2408.08459v1 by Xiaochuang Han, Marjan Ghazvininejad, Pang Wei Koh, Yulia Tsvetkov

Recent work in image and video generation has been adopting the
autoregressive LLM architecture due to its generality and potentially easy
integration into multi-modal systems. The crux of applying autoregressive
training in language generation to visual generation is discretization --
representing continuous data like images and videos as discrete tokens. Common
methods of discretizing images and videos include modeling raw pixel values,
which are prohibitively lengthy, or vector quantization, which requires
convoluted pre-hoc training. In this work, we propose to directly model images
and videos as compressed files saved on computers via canonical codecs (e.g.,
JPEG, AVC/H.264). Using the default Llama architecture without any
vision-specific modifications, we pretrain JPEG-LM from scratch to generate
images (and AVC-LM to generate videos as a proof of concept), by directly
outputting compressed file bytes in JPEG and AVC formats. Evaluation of image
generation shows that this simple and straightforward approach is more
effective than pixel-based modeling and sophisticated vector quantization
baselines (on which our method yields a 31% reduction in FID). Our analysis
shows that JPEG-LM has an especial advantage over vector quantization models in
generating long-tail visual elements. Overall, we show that using canonical
codec representations can help lower the barriers between language generation
and visual generation, facilitating future research on multi-modal
language/image/video LLMs.

ÊëòË¶ÅÔºöÊúÄËøëÂú®ÂΩ±ÂÉèÂíåÂΩ±ÁâáÁîüÊàêÊñπÈù¢ÁöÑÂ∑•‰ΩúÂºÄÂßãÈááÁî®Ëá™ÂõûÂΩí LLM Êû∂ÊûÑÔºåÂõ†‰∏∫ÂÖ∂ÈÄöÁî®ÊÄßÈ´ò‰∏îÊòì‰∫éÊï¥ÂêàÂà∞Â§öÊ®°ÂºèÁ≥ªÁªü‰∏≠„ÄÇÂ∞ÜËá™ÂõûÂΩíËÆ≠ÁªÉÂ∫îÁî®‰∫éËØ≠Ë®ÄÁîüÊàêÂà∞ËßÜËßâÁîüÊàêÁöÑÊ†∏ÂøÉÊòØÁ¶ªÊï£Âåñ‚Äî‚ÄîÂ∞ÜÂΩ±ÂÉèÂíåÂΩ±ÁâáÁ≠âËøûÁª≠Êï∞ÊçÆË°®Á§∫‰∏∫Á¶ªÊï£Ê†áËÆ∞„ÄÇÁ¶ªÊï£ÂåñÂΩ±ÂÉèÂíåÂΩ±ÁâáÁöÑÂ∏∏ËßÅÊñπÊ≥ïÂåÖÊã¨Âª∫Ê®°ÂéüÂßãÂÉèÁ¥†ÂÄºÔºàÈïøÂ∫¶ËøáÈïøÔºâÊàñÂêëÈáèÈáèÂåñÔºàÈúÄË¶ÅÂ§çÊùÇÁöÑÈ¢ÑÂÖàËÆ≠ÁªÉÔºâ„ÄÇÂú®ËøôÈ°πÂ∑•‰Ωú‰∏≠ÔºåÊàë‰ª¨Âª∫ËÆÆÁõ¥Êé•Â∞ÜÂΩ±ÂÉèÂíåÂΩ±ÁâáÂª∫Ê®°‰∏∫ËÆ°ÁÆóÊú∫‰∏ä‰ª•ËßÑËåÉÁºñËß£Á†ÅÂô®Ôºà‰æãÂ¶Ç JPEG„ÄÅAVC/H.264ÔºâÂÇ®Â≠òÁöÑÂéãÁº©Ê°£Ê°à„ÄÇÂú®‰∏çËøõË°å‰ªª‰ΩïÁâπÂÆö‰∫éËßÜËßâÁöÑ‰øÆÊîπÁöÑÊÉÖÂÜµ‰∏ã‰ΩøÁî®ÈªòËÆ§ÁöÑ Llama Êû∂ÊûÑÔºåÊàë‰ª¨‰ªéÂ§¥È¢ÑËÆ≠ÁªÉ JPEG-LM Êù•ÁîüÊàêÂΩ±ÂÉèÔºàÂπ∂È¢ÑËÆ≠ÁªÉ AVC-LM ‰ª•ÁîüÊàêÂΩ±Áâá‰Ωú‰∏∫Ê¶ÇÂøµÈ™åËØÅÔºâÔºåÊñπÊ≥ïÊòØÁõ¥Êé•ËæìÂá∫ JPEG Âíå AVC Ê†ºÂºèÁöÑÂéãÁº©Ê°£Ê°à‰ΩçÂÖÉÁªÑ„ÄÇÂΩ±ÂÉèÁîüÊàêÁöÑËØÑ‰º∞ÊòæÁ§∫ÔºåËøôÁßçÁÆÄÂçïËÄåÁõ¥Êé•ÁöÑÊñπÊ≥ïÊØîÂü∫‰∫éÂÉèÁ¥†ÁöÑÂª∫Ê®°ÂíåÂ§çÊùÇÁöÑÂêëÈáèÈáèÂåñÂü∫Á∫øÔºàÊàë‰ª¨ÁöÑÊñπÊ≥ïÂú® FID ‰∏äÂáèÂ∞ë‰∫Ü 31%ÔºâÊõ¥ÊúâÊïà„ÄÇÊàë‰ª¨ÁöÑÂàÜÊûêÊòæÁ§∫ÔºåJPEG-LM Âú®ÁîüÊàêÈïøÂ∞æËßÜËßâÂÖÉÁ¥†ÊñπÈù¢ÁâπÂà´‰ºò‰∫éÂêëÈáèÈáèÂåñÊ®°Âûã„ÄÇÊÄª‰ΩìËÄåË®ÄÔºåÊàë‰ª¨Ë°®Êòé‰ΩøÁî®ËßÑËåÉÁºñËß£Á†ÅÂô®Ë°®Á§∫ÂèØ‰ª•Â∏ÆÂä©Èôç‰ΩéËØ≠Ë®ÄÁîüÊàêÂíåËßÜËßâÁîüÊàê‰πãÈó¥ÁöÑÈöúÁ¢çÔºå‰øÉËøõÊú™Êù•ÂØπÂ§öÊ®°ÂºèËØ≠Ë®Ä/ÂΩ±ÂÉè/ÂΩ±Áâá LLM ÁöÑÁ†îÁ©∂„ÄÇ

##### **Efficient Data-Sketches and Fine-Tuning for Early Detection of Distributional Drift in Medical Imaging**
2408.08456v1 by Yusen Wu, Hao Chen, Alex Pissinou Makki, Phuong Nguyen, Yelena Yesha

Distributional drift detection is important in medical applications as it
helps ensure the accuracy and reliability of models by identifying changes in
the underlying data distribution that could affect diagnostic or treatment
decisions. However, current methods have limitations in detecting drift; for
example, the inclusion of abnormal datasets can lead to unfair comparisons.
This paper presents an accurate and sensitive approach to detect distributional
drift in CT-scan medical images by leveraging data-sketching and fine-tuning
techniques. We developed a robust baseline library model for real-time anomaly
detection, allowing for efficient comparison of incoming images and
identification of anomalies. Additionally, we fine-tuned a vision transformer
pre-trained model to extract relevant features using breast cancer images as an
example, significantly enhancing model accuracy to 99.11\%. Combining with
data-sketches and fine-tuning, our feature extraction evaluation demonstrated
that cosine similarity scores between similar datasets provide greater
improvements, from around 50\% increased to 100\%. Finally, the sensitivity
evaluation shows that our solutions are highly sensitive to even 1\%
salt-and-pepper and speckle noise, and it is not sensitive to lighting noise
(e.g., lighting conditions have no impact on data drift). The proposed methods
offer a scalable and reliable solution for maintaining the accuracy of
diagnostic models in dynamic clinical environments.

ÊëòË¶ÅÔºöÂàÜÈÖçÊºÇÁßªÊ£ÄÊµãÂú®ÂåªÁñóÂ∫îÁî®‰∏≠ÂæàÈáçË¶ÅÔºåÂõ†‰∏∫ÂÆÉ
ÊúâÂä©‰∫éÁ°Æ‰øùÊ®°ÂûãÁöÑÂáÜÁ°ÆÊÄßÂíåÂèØÈù†ÊÄßÔºåÊñπÊ≥ïÊòØËØÜÂà´ÂèØËÉΩÂΩ±ÂìçËØäÊñ≠ÊàñÊ≤ªÁñóÁöÑÂ∫ïÂ±ÇÊï∞ÊçÆÂàÜÂ∏ÉÁöÑÂèòÂåñ
ÂÜ≥ÂÆö„ÄÇÁÑ∂ËÄåÔºåÂΩìÂâçÁöÑÊñπÊ≥ïÂú®Ê£ÄÊµãÊºÇÁßªÊñπÈù¢Â≠òÂú®Â±ÄÈôêÊÄßÔºõ‰æãÂ¶ÇÔºåÂºÇÂ∏∏Êï∞ÊçÆÈõÜÁöÑÂåÖÂê´‰ºöÂØºËá¥‰∏çÂÖ¨Âπ≥ÁöÑÊØîËæÉ„ÄÇ
Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂáÜÁ°Æ‰∏îÊïèÊÑüÁöÑÊñπÊ≥ïÊù•Ê£ÄÊµã CT Êâ´ÊèèÂåªÂ≠¶ÂõæÂÉè‰∏≠ÁöÑÂàÜÂ∏ÉÊºÇÁßªÔºåÊñπÊ≥ïÊòØÂà©Áî®Êï∞ÊçÆËçâÂõæÂíåÂæÆË∞É
ÊäÄÊúØ„ÄÇÊàë‰ª¨ÂºÄÂèë‰∫Ü‰∏Ä‰∏™Á®≥ÂÅ•ÁöÑÂü∫Á∫øÂ∫ìÊ®°ÂûãÔºåÁî®‰∫éÂÆûÊó∂ÂºÇÂ∏∏Ê£ÄÊµãÔºåÂÖÅËÆ∏ÂØπ‰º†ÂÖ•ÂõæÂÉèËøõË°åÈ´òÊïàÊØîËæÉÂíå
ËØÜÂà´ÂºÇÂ∏∏„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨ÂØπËßÜËßâËΩ¨Êç¢Âô®È¢ÑËÆ≠ÁªÉÊ®°ÂûãËøõË°å‰∫ÜÂæÆË∞ÉÔºå‰ª•‰ΩøÁî®‰π≥ËÖ∫ÁôåÂõæÂÉè‰Ωú‰∏∫Á§∫‰æãÊèêÂèñÁõ∏ÂÖ≥ÁâπÂæÅÔºåÊòæÁùÄÊèêÈ´ò‰∫ÜÊ®°ÂûãÂáÜÁ°ÆÁéáËá≥ 99.11%„ÄÇÁªìÂêà
Êï∞ÊçÆËçâÂõæÂíåÂæÆË∞ÉÔºåÊàë‰ª¨ÁöÑÁâπÂæÅÊèêÂèñËØÑ‰º∞Ë°®ÊòéÔºåÁõ∏‰ººÊï∞ÊçÆÈõÜ‰πãÈó¥ÁöÑ‰ΩôÂº¶Áõ∏‰ººÂ∫¶ÂæóÂàÜÊèê‰æõ‰∫ÜÊõ¥Â§ßÁöÑ
ÊîπËøõÔºå‰ªéÂ¢ûÂä†Á∫¶ 50% Âà∞ 100%„ÄÇÊúÄÂêéÔºåÊïèÊÑüÊÄßËØÑ‰º∞Ë°®ÊòéÊàë‰ª¨ÁöÑËß£ÂÜ≥ÊñπÊ°àÂØπ 1% ÁöÑÊ§íÁõêÂô™Â£∞ÂíåÊñëÁÇπÂô™Â£∞È´òÂ∫¶ÊïèÊÑüÔºåÂπ∂‰∏îÂØπÂÖâÁÖßÂô™Â£∞‰∏çÊïèÊÑü
Ôºà‰æãÂ¶ÇÔºåÂÖâÁÖßÊù°‰ª∂ÂØπÊï∞ÊçÆÊºÇÁßªÊ≤°ÊúâÂΩ±ÂìçÔºâ„ÄÇÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ï‰∏∫‰øùÊåÅËØäÊñ≠Ê®°ÂûãÁöÑÂáÜÁ°ÆÊÄßÊèê‰æõ‰∫Ü‰∏Ä‰∏™ÂèØÊâ©Â±ï‰∏îÂèØÈù†ÁöÑËß£ÂÜ≥ÊñπÊ°à
Âú®Âä®ÊÄÅ‰∏¥Â∫äÁéØÂ¢É‰∏≠„ÄÇ

##### **SpectralEarth: Training Hyperspectral Foundation Models at Scale**
2408.08447v1 by Nassim Ait Ali Braham, Conrad M Albrecht, Julien Mairal, Jocelyn Chanussot, Yi Wang, Xiao Xiang Zhu

Foundation models have triggered a paradigm shift in computer vision and are
increasingly being adopted in remote sensing, particularly for multispectral
imagery. Yet, their potential in hyperspectral imaging (HSI) remains untapped
due to the absence of comprehensive and globally representative hyperspectral
datasets. To close this gap, we introduce SpectralEarth, a large-scale
multi-temporal dataset designed to pretrain hyperspectral foundation models
leveraging data from the Environmental Mapping and Analysis Program (EnMAP).
SpectralEarth comprises 538,974 image patches covering 415,153 unique locations
from more than 11,636 globally distributed EnMAP scenes spanning two years of
archive. Additionally, 17.5% of these locations include multiple timestamps,
enabling multi-temporal HSI analysis. Utilizing state-of-the-art
self-supervised learning (SSL) algorithms, we pretrain a series of foundation
models on SpectralEarth. We integrate a spectral adapter into classical vision
backbones to accommodate the unique characteristics of HSI. In tandem, we
construct four downstream datasets for land-cover and crop-type mapping,
providing benchmarks for model evaluation. Experimental results support the
versatility of our models, showcasing their generalizability across different
tasks and sensors. We also highlight computational efficiency during model
fine-tuning. The dataset, models, and source code will be made publicly
available.

ÊëòË¶ÅÔºöÂü∫Á§éÊ®°ÂûãÂú®ÈõªËÖ¶Ë¶ñË¶∫‰∏≠ÂºïÁôº‰∫ÜÂÖ∏ÁØÑËΩâÁßªÔºå‰∏¶Âú®ÈÅôÊ∏¨‰∏≠ÂæóÂà∞Ë∂ä‰æÜË∂äÂª£Ê≥õÁöÑÊáâÁî®ÔºåÁâπÂà•ÊòØÂ∞çÊñºÂ§öÂÖâË≠úÂΩ±ÂÉè„ÄÇÁÑ∂ËÄåÔºåÁî±ÊñºÁº∫‰πèÂÖ®Èù¢‰∏îÂÖ∑ÊúâÂÖ®ÁêÉ‰ª£Ë°®ÊÄßÁöÑÈ´òÂÖâË≠úË≥áÊñôÈõÜÔºåÂÆÉÂÄëÂú®È´òÂÖâË≠úÂΩ±ÂÉèÔºàHSIÔºâ‰∏≠ÁöÑÊΩõÂäõ‰ªçÊú™ÂæóÂà∞ÈñãÁôº„ÄÇÁÇ∫‰∫ÜÁ∏ÆÂ∞èÈÄôÂÄãÂ∑ÆË∑ùÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü SpectralEarthÔºåÈÄôÊòØ‰∏ÄÂÄãÂ§ßË¶èÊ®°ÁöÑÂ§öÊôÇÊÖãË≥áÊñôÈõÜÔºåÊó®Âú®Âà©Áî®Áí∞Â¢ÉÂ∞çÊáâËàáÂàÜÊûêË®àÁï´ÔºàEnMAPÔºâÁöÑË≥áÊñôÈ†êË®ìÁ∑¥È´òÂÖâË≠úÂü∫Á§éÊ®°Âûã„ÄÇSpectralEarth ÂåÖÂê´ 538,974 ÂÄãÂΩ±ÂÉè‰øÆË£úÁ®ãÂºèÔºåÊ∂µËìã‰æÜËá™Ë∂ÖÈÅé 11,636 ÂÄãÂÖ®ÁêÉÂàÜ‰ΩàÁöÑ EnMAP Â†¥ÊôØÁöÑ 415,153 ÂÄãÂîØ‰∏Ä‰ΩçÁΩÆÔºåË∑®Ë∂äÂÖ©Âπ¥ÁöÑÊ™îÊ°à„ÄÇÊ≠§Â§ñÔºåÂÖ∂‰∏≠ 17.5% ÁöÑ‰ΩçÁΩÆÂåÖÂê´Â§öÂÄãÊôÇÈñìÊà≥Ë®òÔºåÂæûËÄåÂØ¶ÁèæÂ§öÊôÇÊÖã HSI ÂàÜÊûê„ÄÇÂà©Áî®ÊúÄÂÖàÈÄ≤ÁöÑËá™ÊàëÁõ£Áù£Â≠∏Áøí (SSL) ÊºîÁÆóÊ≥ïÔºåÊàëÂÄëÂú® SpectralEarth ‰∏äÈ†êË®ìÁ∑¥‰∫Ü‰∏ÄÁ≥ªÂàóÂü∫Á§éÊ®°Âûã„ÄÇÊàëÂÄëÂ∞áÂÖâË≠úÈÅ©ÈÖçÂô®Êï¥ÂêàÂà∞ÂÇ≥Áµ±Ë¶ñË¶∫‰∏ªÂππ‰∏≠Ôºå‰ª•ÈÅ©Êáâ HSI ÁöÑÁç®ÁâπÁâπÂæµ„ÄÇÂêåÊôÇÔºåÊàëÂÄëÊßãÂª∫‰∫ÜÂõõÂÄãÁî®ÊñºÂúüÂú∞Ë¶ÜËìãÂíå‰ΩúÁâ©È°ûÂûãÂ∞çÊáâÁöÑ‰∏ãÊ∏∏Ë≥áÊñôÈõÜÔºåÁÇ∫Ê®°ÂûãË©ï‰º∞Êèê‰æõ‰∫ÜÂü∫Ê∫ñ„ÄÇÂØ¶È©óÁµêÊûúË≠âÂØ¶‰∫ÜÊàëÂÄëÊ®°ÂûãÁöÑÂ§öÂäüËÉΩÊÄßÔºåÂ±ïÁ§∫‰∫ÜÂÆÉÂÄëÂú®‰∏çÂêå‰ªªÂãôÂíåÊÑüÊ∏¨Âô®‰∏äÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇÊàëÂÄëÈÇÑÂº∑Ë™ø‰∫ÜÊ®°ÂûãÂæÆË™øÊúüÈñìÁöÑÈÅãÁÆóÊïàÁéá„ÄÇË≥áÊñôÈõÜ„ÄÅÊ®°ÂûãÂíåÂéüÂßãÁ®ãÂºèÁ¢ºÂ∞áÂÖ¨ÈñãÊèê‰æõ„ÄÇ

##### **W-RAG: Weakly Supervised Dense Retrieval in RAG for Open-domain Question Answering**
2408.08444v1 by Jinming Nian, Zhiyuan Peng, Qifan Wang, Yi Fang

In knowledge-intensive tasks such as open-domain question answering (OpenQA),
Large Language Models (LLMs) often struggle to generate factual answers relying
solely on their internal (parametric) knowledge. To address this limitation,
Retrieval-Augmented Generation (RAG) systems enhance LLMs by retrieving
relevant information from external sources, thereby positioning the retriever
as a pivotal component. Although dense retrieval demonstrates state-of-the-art
performance, its training poses challenges due to the scarcity of ground-truth
evidence, largely attributed to the high costs of human annotation. In this
paper, we propose W-RAG by utilizing the ranking capabilities of LLMs to create
weakly labeled data for training dense retrievers. Specifically, we rerank the
top-$K$ passages retrieved via BM25 by assessing the probability that LLMs will
generate the correct answer based on the question and each passage. The
highest-ranking passages are then used as positive training examples for dense
retrieval. Our comprehensive experiments across four publicly available OpenQA
datasets demonstrate that our approach enhances both retrieval and OpenQA
performance compared to baseline models.

ÊëòË¶ÅÔºöÂú®ÈñãÊîæÈ†òÂüüÂïèÁ≠î (OpenQA) Á≠âÁü•Ë≠òÂØÜÈõÜÂûã‰ªªÂãô‰∏≠ÔºåÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∏∏Â∏∏Èõ£‰ª•ÂÉÖÊÜëËóâÂÖ∂ÂÖßÈÉ® (ÂèÉÊï∏Âåñ) Áü•Ë≠ò‰æÜÁî¢Áîü‰∫ãÂØ¶ÊÄßÁöÑÁ≠îÊ°à„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÈôêÂà∂ÔºåÊ™¢Á¥¢Â¢ûÂº∑ÂûãÁîüÊàê (RAG) Á≥ªÁµ±ÈÄèÈÅéÂæûÂ§ñÈÉ®‰æÜÊ∫êÊ™¢Á¥¢Áõ∏ÈóúË≥áË®ä‰æÜÂ¢ûÂº∑ LLMÔºåÂæûËÄåÂ∞áÊ™¢Á¥¢Âô®ÂÆö‰ΩçÁÇ∫‰∏ÄÂÄãÈóúÈçµÁµÑÊàêÈÉ®ÂàÜ„ÄÇÂÑòÁÆ°Á®†ÂØÜÊ™¢Á¥¢Â±ïÁ§∫‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÊïàËÉΩÔºå‰ΩÜÁî±ÊñºÁº∫‰πèÂü∫Êú¨‰∫ãÂØ¶Ë≠âÊìöÔºåÂÖ∂Ë®ìÁ∑¥ÊßãÊàê‰∫ÜÊåëÊà∞ÔºåÈÄôÂú®ÂæàÂ§ßÁ®ãÂ∫¶‰∏äÊ≠∏Âõ†Êñº‰∫∫Â∑•Ê®ôË®ªÁöÑÈ´òÊàêÊú¨„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫ W-RAGÔºåÂà©Áî® LLM ÁöÑÊéíÂêçËÉΩÂäõ‰æÜÂª∫Á´ãÁî®ÊñºË®ìÁ∑¥Á®†ÂØÜÊ™¢Á¥¢Âô®ÁöÑÂº±Ê®ôÁ±§Ë≥áÊñô„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÈÄèÈÅéË©ï‰º∞ LLM Ê†πÊìöÂïèÈ°åÂíåÊØèÂÄãÁ´†ÁØÄÁî¢ÁîüÊ≠£Á¢∫Á≠îÊ°àÁöÑÊ©üÁéáÔºåÈáçÊñ∞Â∞çÈÄèÈÅé BM25 Ê™¢Á¥¢Âà∞ÁöÑÂâç K ÂÄãÁ´†ÁØÄÈÄ≤Ë°åÊéíÂêç„ÄÇÊéíÂêçÊúÄÈ´òÁöÑÁ´†ÁØÄÈö®ÂæåÁî®‰ΩúÁ®†ÂØÜÊ™¢Á¥¢ÁöÑÊ≠£Èù¢Ë®ìÁ∑¥ÁØÑ‰æã„ÄÇÊàëÂÄëÂú®ÂõõÂÄãÂÖ¨ÈñãÂèØÁî®ÁöÑ OpenQA Ë≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÁöÑÂÖ®Èù¢ÂØ¶È©óË≠âÊòéÔºåËàáÂü∫Ê∫ñÊ®°ÂûãÁõ∏ÊØîÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÂ¢ûÂº∑‰∫ÜÊ™¢Á¥¢Âíå OpenQA ÊïàËÉΩ„ÄÇ

##### **PQV-Mobile: A Combined Pruning and Quantization Toolkit to Optimize Vision Transformers for Mobile Applications**
2408.08437v1 by Kshitij Bhardwaj

While Vision Transformers (ViTs) are extremely effective at computer vision
tasks and are replacing convolutional neural networks as the new
state-of-the-art, they are complex and memory-intensive models. In order to
effectively run these models on resource-constrained mobile/edge systems, there
is a need to not only compress these models but also to optimize them and
convert them into deployment-friendly formats. To this end, this paper presents
a combined pruning and quantization tool, called PQV-Mobile, to optimize vision
transformers for mobile applications. The tool is able to support different
types of structured pruning based on magnitude importance, Taylor importance,
and Hessian importance. It also supports quantization from FP32 to FP16 and
int8, targeting different mobile hardware backends. We demonstrate the
capabilities of our tool and show important latency-memory-accuracy trade-offs
for different amounts of pruning and int8 quantization with Facebook Data
Efficient Image Transformer (DeiT) models. Our results show that even pruning a
DeiT model by 9.375% and quantizing it to int8 from FP32 followed by optimizing
for mobile applications, we find a latency reduction by 7.18X with a small
accuracy loss of 2.24%. The tool is open source.

ÊëòË¶ÅÔºöÂÑòÁÆ°Ë¶ñË¶∫Transformer (ViT) Âú®ÈõªËÖ¶Ë¶ñË¶∫‰ªªÂãô‰∏≠Ê•µÁÇ∫ÊúâÊïàÔºå‰∏îÂèñ‰ª£‰∫ÜÂç∑Á©çÁ•ûÁ∂ìÁ∂≤Ë∑ØÊàêÁÇ∫Êñ∞ÁöÑÈÄ≤Ê≠•ÊåáÊ®ôÔºå‰ΩÜÂÆÉÂÄëÊòØË§áÈõú‰∏îÈúÄË¶ÅÂ§ßÈáèË®òÊÜ∂È´îÁöÑÊ®°Âûã„ÄÇÁÇ∫‰∫ÜÂú®Ë≥áÊ∫êÂèóÈôêÁöÑË°åÂãï/ÈÇäÁ∑£Á≥ªÁµ±‰∏äÊúâÊïàÂü∑Ë°åÈÄô‰∫õÊ®°ÂûãÔºå‰∏çÂÉÖÈúÄË¶ÅÂ£ìÁ∏ÆÈÄô‰∫õÊ®°ÂûãÔºåÈÇÑÈúÄË¶ÅÊúÄ‰Ω≥ÂåñÂÆÉÂÄëÔºå‰∏¶Â∞áÂÆÉÂÄëËΩâÊèõÊàêÈÉ®ÁΩ≤ÂèãÂñÑÁöÑÊ†ºÂºè„ÄÇÁÇ∫Ê≠§ÔºåÊú¨Ë´ñÊñáÊèêÂá∫‰∏ÄÂÄãÂêçÁÇ∫ PQV-Mobile ÁöÑÁµêÂêàÂâ™ÊûùËàáÈáèÂåñÂ∑•ÂÖ∑Ôºå‰ª•ÊúÄ‰Ω≥ÂåñË°åÂãïÊáâÁî®Á®ãÂºèÁöÑË¶ñË¶∫Transformer„ÄÇÊ≠§Â∑•ÂÖ∑ËÉΩÂ§†ÊîØÊè¥Âü∫ÊñºÂπÖÂ∫¶ÈáçË¶ÅÊÄß„ÄÅTaylor ÈáçË¶ÅÊÄß‰ª•Âèä Hessian ÈáçË¶ÅÊÄßÁöÑ‰∏çÂêåÁµêÊßãÂåñÂâ™ÊûùÈ°ûÂûã„ÄÇÂÆÉ‰πüÊîØÊè¥Âæû FP32 Âà∞ FP16 Âíå int8 ÁöÑÈáèÂåñÔºåÈéñÂÆö‰∏çÂêåÁöÑË°åÂãïÁ°¨È´îÂæåÁ´Ø„ÄÇÊàëÂÄëÁ§∫ÁØÑ‰∫ÜÊàëÂÄëÂ∑•ÂÖ∑ÁöÑÂäüËÉΩÔºå‰∏¶Â±ïÁ§∫‰∫Ü Facebook Ë≥áÊñôÈ´òÊïàËÉΩÂΩ±ÂÉèTransformer (DeiT) Ê®°ÂûãÂú®‰∏çÂêåÁ®ãÂ∫¶ÁöÑÂâ™ÊûùËàá int8 ÈáèÂåñ‰∏≠ÈáçË¶ÅÁöÑÂª∂ÈÅ≤-Ë®òÊÜ∂È´î-Á≤æÁ¢∫Â∫¶Ê¨äË°°„ÄÇÊàëÂÄëÁöÑÁµêÊûúÈ°ØÁ§∫ÔºåÂç≥‰ΩøÂ∞á DeiT Ê®°ÂûãÂâ™Êûù 9.375%Ôºå‰∏¶Âæû FP32 ÈáèÂåñÁÇ∫ int8ÔºåÁÑ∂ÂæåÊúÄ‰Ω≥ÂåñË°åÂãïÊáâÁî®Á®ãÂºèÔºåÊàëÂÄëÁôºÁèæÂª∂ÈÅ≤Ê∏õÂ∞ë‰∫Ü 7.18 ÂÄçÔºåÁ≤æÁ¢∫Â∫¶ÂÉÖÊêçÂ§± 2.24%„ÄÇÊ≠§Â∑•ÂÖ∑ÊòØÈñãÊ∫êÁöÑ„ÄÇ

##### **Automated Design of Agentic Systems**
2408.08435v1 by Shengran Hu, Cong Lu, Jeff Clune

Researchers are investing substantial effort in developing powerful
general-purpose agents, wherein Foundation Models are used as modules within
agentic systems (e.g. Chain-of-Thought, Self-Reflection, Toolformer). However,
the history of machine learning teaches us that hand-designed solutions are
eventually replaced by learned solutions. We formulate a new research area,
Automated Design of Agentic Systems (ADAS), which aims to automatically create
powerful agentic system designs, including inventing novel building blocks
and/or combining them in new ways. We further demonstrate that there is an
unexplored yet promising approach within ADAS where agents can be defined in
code and new agents can be automatically discovered by a meta agent programming
ever better ones in code. Given that programming languages are Turing Complete,
this approach theoretically enables the learning of any possible agentic
system: including novel prompts, tool use, control flows, and combinations
thereof. We present a simple yet effective algorithm named Meta Agent Search to
demonstrate this idea, where a meta agent iteratively programs interesting new
agents based on an ever-growing archive of previous discoveries. Through
extensive experiments across multiple domains including coding, science, and
math, we show that our algorithm can progressively invent agents with novel
designs that greatly outperform state-of-the-art hand-designed agents.
Importantly, we consistently observe the surprising result that agents invented
by Meta Agent Search maintain superior performance even when transferred across
domains and models, demonstrating their robustness and generality. Provided we
develop it safely, our work illustrates the potential of an exciting new
research direction toward automatically designing ever-more powerful agentic
systems to benefit humanity.

ÊëòË¶ÅÔºöÁ†îÁ©∂‰∫∫Âì°ÊäïÂÖ•Â§ßÈáèÂøÉÂäõÈñãÁôºÂäüËÉΩÂº∑Â§ßÁöÑÈÄöÁî®‰ª£ÁêÜÔºåÂÖ∂‰∏≠Âü∫Á§éÊ®°ÂûãË¢´Áî®‰Ωú‰ª£ÁêÜÁ≥ªÁµ±‰∏≠ÁöÑÊ®°ÁµÑÔºà‰æãÂ¶ÇÊÄùËÄÉÈèà„ÄÅËá™ÊàëÂèçÁúÅ„ÄÅÂ∑•ÂÖ∑ÂΩ¢ÊàêÂô®Ôºâ„ÄÇÁÑ∂ËÄåÔºåÊ©üÂô®Â≠∏ÁøíÁöÑÊ≠∑Âè≤ÂëäË®¥ÊàëÂÄëÔºå‰∫∫Â∑•Ë®≠Ë®àÁöÑËß£Ê±∫ÊñπÊ°àÊúÄÁµÇÊúÉË¢´Â≠∏ÁøíÂà∞ÁöÑËß£Ê±∫ÊñπÊ°àÂèñ‰ª£„ÄÇÊàëÂÄëÂà∂ÂÆö‰∫Ü‰∏ÄÂÄãÊñ∞ÁöÑÁ†îÁ©∂È†òÂüüÔºåÂç≥‰ª£ÁêÜÁ≥ªÁµ±Ëá™ÂãïË®≠Ë®à (ADAS)ÔºåÂÖ∂ÁõÆÊ®ôÊòØËá™ÂãïÂª∫Á´ãÂº∑Â§ßÁöÑ‰ª£ÁêÜÁ≥ªÁµ±Ë®≠Ë®àÔºåÂåÖÊã¨ÁôºÊòéÊñ∞Á©éÁöÑÂª∫ÊßãÂçÄÂ°äÂíå/Êàñ‰ª•Êñ∞ÊñπÂºèÁµÑÂêàÂÆÉÂÄë„ÄÇÊàëÂÄëÈÄ≤‰∏ÄÊ≠•Ë≠âÊòéÔºåADAS ‰∏≠Â≠òÂú®‰∏ÄÁ®ÆÂ∞öÊú™Êé¢Á¥¢‰ΩÜÂæàÊúâÂâçÊôØÁöÑÊñπÊ≥ïÔºåÂÖ∂‰∏≠‰ª£ÁêÜÂèØ‰ª•Áî®Á®ãÂºèÁ¢ºÂÆöÁæ©ÔºåËÄåÊñ∞ÁöÑ‰ª£ÁêÜÂèØ‰ª•Áî±ÂÖÉ‰ª£ÁêÜËá™ÂãïÁôºÁèæÔºåÂú®Á®ãÂºèÁ¢º‰∏≠Á∑®ÂØ´Âá∫Êõ¥Â•ΩÁöÑ‰ª£ÁêÜ„ÄÇÁî±ÊñºÁ®ãÂºèË™ûË®ÄÊòØÂúñÈùàÂÆåÂÇôÁöÑÔºåÂõ†Ê≠§Ê≠§ÊñπÊ≥ïÁêÜË´ñ‰∏äÂèØ‰ª•Â≠∏Áøí‰ªª‰ΩïÂèØËÉΩÁöÑ‰ª£ÁêÜÁ≥ªÁµ±ÔºöÂåÖÊã¨Êñ∞ÊèêÁ§∫„ÄÅÂ∑•ÂÖ∑‰ΩøÁî®„ÄÅÊéßÂà∂ÊµÅÁ®ãÂèäÂÖ∂ÁµÑÂêà„ÄÇÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÁ∞°ÂñÆ‰ΩÜÊúâÊïàÁöÑÊºîÁÆóÊ≥ïÔºåÂêçÁÇ∫ÂÖÉ‰ª£ÁêÜÊêúÂ∞ãÔºå‰ª•Â±ïÁ§∫ÈÄôÂÄãÊÉ≥Ê≥ïÔºåÂÖ∂‰∏≠ÂÖÉ‰ª£ÁêÜÊ†πÊìö‰∏çÊñ∑ÊàêÈï∑ÁöÑÂÖàÂâçÁôºÁèæÊ™îÊ°àÔºåÂèçË¶ÜÁ∑®ÂØ´Âá∫ÊúâË∂£ÁöÑÊñ∞‰ª£ÁêÜ„ÄÇÈÄèÈÅéÂú®Á∑®Á¢º„ÄÅÁßëÂ≠∏ÂíåÊï∏Â≠∏Á≠âÂ§öÂÄãÈ†òÂüüÈÄ≤Ë°åÂª£Ê≥õÁöÑÂØ¶È©óÔºåÊàëÂÄëË≠âÊòéÊàëÂÄëÁöÑÊºîÁÆóÊ≥ïÂèØ‰ª•ÈÄêÊ≠•ÁôºÊòéÂÖ∑ÊúâÊñ∞Á©éË®≠Ë®àÁöÑ‰ª£ÁêÜÔºåÂÖ∂ÊïàËÉΩÈÅ†ÈÅ†ÂÑ™ÊñºÊúÄÂÖàÈÄ≤ÁöÑ‰∫∫Â∑•Ë®≠Ë®à‰ª£ÁêÜ„ÄÇÈáçË¶ÅÁöÑÊòØÔºåÊàëÂÄëÂßãÁµÇËßÄÂØüÂà∞‰∏ÄÂÄãÈ©ö‰∫∫ÁöÑÁµêÊûúÔºöÂç≥‰ΩøÂú®Ë∑®È†òÂüüÂíåÊ®°ÂûãÂÇ≥Ëº∏ÊôÇÔºåÁî±ÂÖÉ‰ª£ÁêÜÊêúÂ∞ãÁôºÊòéÁöÑ‰ª£ÁêÜ‰ªçËÉΩÁ∂≠ÊåÅÂÑ™Áï∞ÁöÑÊïàËÉΩÔºåË≠âÊòéÂÆÉÂÄëÁöÑÁ©©ÂÅ•ÊÄßÂíåÊôÆÈÅçÊÄß„ÄÇÂè™Ë¶ÅÊàëÂÄëÂÆâÂÖ®Âú∞ÈñãÁôºÂÆÉÔºåÊàëÂÄëÁöÑÁ†îÁ©∂Ë™™Êòé‰∫Ü‰∏ÄÂÄã‰ª§‰∫∫ËààÂ•ÆÁöÑÊñ∞Á†îÁ©∂ÊñπÂêëÁöÑÊΩõÂäõÔºåÂç≥Ëá™ÂãïË®≠Ë®àÂäüËÉΩÊõ¥Âº∑Â§ßÁöÑ‰ª£ÁêÜÁ≥ªÁµ±Ôºå‰ª•ÈÄ†Á¶è‰∫∫È°û„ÄÇ

##### **Predictive uncertainty estimation in deep learning for lung carcinoma classification in digital pathology under real dataset shifts**
2408.08432v1 by Abdur R. Fayjie, Jutika Borah, Florencia Carbone, Jan Tack, Patrick Vandewalle

Deep learning has shown tremendous progress in a wide range of digital
pathology and medical image classification tasks. Its integration into safe
clinical decision-making support requires robust and reliable models. However,
real-world data comes with diversities that often lie outside the intended
source distribution. Moreover, when test samples are dramatically different,
clinical decision-making is greatly affected. Quantifying predictive
uncertainty in models is crucial for well-calibrated predictions and
determining when (or not) to trust a model. Unfortunately, many works have
overlooked the importance of predictive uncertainty estimation. This paper
evaluates whether predictive uncertainty estimation adds robustness to deep
learning-based diagnostic decision-making systems. We investigate the effect of
various carcinoma distribution shift scenarios on predictive performance and
calibration. We first systematically investigate three popular methods for
improving predictive uncertainty: Monte Carlo dropout, deep ensemble, and
few-shot learning on lung adenocarcinoma classification as a primary disease in
whole slide images. Secondly, we compare the effectiveness of the methods in
terms of performance and calibration under clinically relevant distribution
shifts such as in-distribution shifts comprising primary disease sub-types and
other characterization analysis data; out-of-distribution shifts comprising
well-differentiated cases, different organ origin, and imaging modality shifts.
While studies on uncertainty estimation exist, to our best knowledge, no
rigorous large-scale benchmark compares predictive uncertainty estimation
including these dataset shifts for lung carcinoma classification.

ÊëòË¶ÅÔºöÊ∑±Â∫¶Â≠∏ÁøíÂú®Âª£Ê≥õÁöÑÊï∏‰ΩçÁóÖÁêÜÂ≠∏ÂíåÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÈ°û‰ªªÂãô‰∏≠Â±ïÁèæÂá∫È©ö‰∫∫ÁöÑÈÄ≤Â±ï„ÄÇÂÆÉÊï¥ÂêàÂà∞ÂÆâÂÖ®ÁöÑËá®Â∫äÊ±∫Á≠ñÊîØÊè¥‰∏≠ÈúÄË¶ÅÂº∑ÂÅ•‰∏îÂèØÈù†ÁöÑÊ®°Âûã„ÄÇÁÑ∂ËÄåÔºåÁúüÂØ¶‰∏ñÁïåÁöÑË≥áÊñôÊúÉ‰º¥Èö®ËëóÂ§öÊ®£ÊÄßÔºåËÄåÈÄô‰∫õÂ§öÊ®£ÊÄßÈÄöÂ∏∏Ë∂ÖÂá∫‰∫ÜÈ†êÊúüÁöÑ‰æÜÊ∫êÂàÜ‰Ωà„ÄÇÊ≠§Â§ñÔºåÁï∂Ê∏¨Ë©¶Ê®£Êú¨ÊúâÊ•µÂ§ßÁöÑ‰∏çÂêåÊôÇÔºåËá®Â∫äÊ±∫Á≠ñÂà∂ÂÆöÊúÉÂèóÂà∞ÂæàÂ§ßÁöÑÂΩ±Èüø„ÄÇÈáèÂåñÊ®°Âûã‰∏≠ÁöÑÈ†êÊ∏¨‰∏çÁ¢∫ÂÆöÊÄßÂ∞çÊñºÊ†°Ê∫ñËâØÂ•ΩÁöÑÈ†êÊ∏¨‰ª•ÂèäÊ±∫ÂÆö‰ΩïÊôÇÔºàÊàñ‰∏çÔºâ‰ø°‰ªªÊ®°ÂûãËá≥ÈóúÈáçË¶Å„ÄÇ‰∏çÂπ∏ÁöÑÊòØÔºåË®±Â§ö‰ΩúÂìÅÈÉΩÂøΩÁï•‰∫ÜÈ†êÊ∏¨‰∏çÁ¢∫ÂÆöÊÄß‰º∞Ë®àÁöÑÈáçË¶ÅÊÄß„ÄÇÊú¨ÊñáË©ï‰º∞È†êÊ∏¨‰∏çÁ¢∫ÂÆöÊÄß‰º∞Ë®àÊòØÂê¶ËÉΩÁÇ∫Âü∫ÊñºÊ∑±Â∫¶Â≠∏ÁøíÁöÑË®∫Êñ∑Ê±∫Á≠ñÂà∂ÂÆöÁ≥ªÁµ±Â¢ûÂä†Á©©ÂÅ•ÊÄß„ÄÇÊàëÂÄëÊé¢Ë®éÂêÑÁ®ÆÁôåÁóáÂàÜ‰ΩàËΩâÁßªÊÉÖÂ¢ÉÂ∞çÈ†êÊ∏¨ÊïàËÉΩÂíåÊ†°Ê∫ñÁöÑÂΩ±Èüø„ÄÇÊàëÂÄëÈ¶ñÂÖàÁ≥ªÁµ±ÊÄßÂú∞Êé¢Ë®é‰∏âÁ®ÆÊîπÂñÑÈ†êÊ∏¨‰∏çÁ¢∫ÂÆöÊÄßÁöÑÁÜ±ÈñÄÊñπÊ≥ïÔºöËíôÂú∞Âç°ÁæÖËºüÂ≠∏„ÄÅÊ∑±Â∫¶Êï¥È´îÂíåÂ∞ëÊ¨°Â≠∏ÁøíÔºå‰ª•ËÇ∫ËÖ∫ÁôåÂàÜÈ°ûÁÇ∫‰∏ªË¶ÅÁñæÁóÖÔºåÂú®ÂÖ®ÂπªÁáàÁâáÂΩ±ÂÉè‰∏≠ÈÄ≤Ë°å„ÄÇÂÖ∂Ê¨°ÔºåÊàëÂÄëÊØîËºÉÈÄô‰∫õÊñπÊ≥ïÂú®ÊïàËÉΩÂíåÊ†°Ê∫ñÊñπÈù¢ÁöÑÊúâÊïàÊÄßÔºåÂú®Ëá®Â∫ä‰∏äÁõ∏ÈóúÁöÑÂàÜ‰ΩàËΩâÁßª‰∏≠Ôºå‰æãÂ¶ÇÂåÖÂê´‰∏ªË¶ÅÁñæÁóÖÂ≠êÈ°ûÂûãÂíåÂÖ∂‰ªñË°®ÂæµÂàÜÊûêË≥áÊñôÁöÑÂàÜÂ∏ÉÂÖßËΩâÁßªÔºõÂåÖÂê´ÂàÜÂåñËâØÂ•ΩÁöÑÁóÖ‰æã„ÄÅ‰∏çÂêåÁöÑÂô®ÂÆò‰æÜÊ∫êÂíåÂΩ±ÂÉèÊñπÂºèËΩâÁßªÁöÑÂàÜÂ∏ÉÂ§ñËΩâÁßª„ÄÇÂÑòÁÆ°ÊúâÈóúÊñº‰∏çÁ¢∫ÂÆöÊÄß‰º∞Ë®àÁöÑÁ†îÁ©∂Ôºå‰ΩÜÊìöÊàëÂÄëÊâÄÁü•ÔºåÊ≤íÊúâÂö¥Ë¨πÁöÑÂ§ßË¶èÊ®°Âü∫Ê∫ñÊØîËºÉÈ†êÊ∏¨‰∏çÁ¢∫ÂÆöÊÄß‰º∞Ë®àÔºåÂåÖÊã¨ÈÄô‰∫õË≥áÊñôÈõÜËΩâÁßª‰ª•ÈÄ≤Ë°åËÇ∫ÁôåÂàÜÈ°û„ÄÇ

##### **Multi-Modal Dialogue State Tracking for Playing GuessWhich Game**
2408.08431v1 by Wei Pang, Ruixue Duan, Jinfu Yang, Ning Li

GuessWhich is an engaging visual dialogue game that involves interaction
between a Questioner Bot (QBot) and an Answer Bot (ABot) in the context of
image-guessing. In this game, QBot's objective is to locate a concealed image
solely through a series of visually related questions posed to ABot. However,
effectively modeling visually related reasoning in QBot's decision-making
process poses a significant challenge. Current approaches either lack visual
information or rely on a single real image sampled at each round as decoding
context, both of which are inadequate for visual reasoning. To address this
limitation, we propose a novel approach that focuses on visually related
reasoning through the use of a mental model of the undisclosed image. Within
this framework, QBot learns to represent mental imagery, enabling robust visual
reasoning by tracking the dialogue state. The dialogue state comprises a
collection of representations of mental imagery, as well as representations of
the entities involved in the conversation. At each round, QBot engages in
visually related reasoning using the dialogue state to construct an internal
representation, generate relevant questions, and update both the dialogue state
and internal representation upon receiving an answer. Our experimental results
on the VisDial datasets (v0.5, 0.9, and 1.0) demonstrate the effectiveness of
our proposed model, as it achieves new state-of-the-art performance across all
metrics and datasets, surpassing previous state-of-the-art models. Codes and
datasets from our experiments are freely available at
\href{https://github.com/xubuvd/GuessWhich}.

ÊëòË¶ÅÔºöGuessWhich ÊòØ‰∏ÄÊ¨æÂºï‰∫∫ÂÖ•ÂãùÁöÑË¶ñË¶∫Â∞çË©±ÈÅäÊà≤ÔºåÂåÖÂê´Âú®ÂúñÂÉèÁåúË¨éÊÉÖÂ¢É‰∏≠ÔºåÂïèÁ≠îÊ©üÂô®‰∫∫ (QBot) ÂíåÂõûÁ≠îÊ©üÂô®‰∫∫ (ABot) ‰πãÈñìÁöÑ‰∫íÂãï„ÄÇÂú®ÈÄôÂÄãÈÅäÊà≤‰∏≠ÔºåQBot ÁöÑÁõÆÊ®ôÊòØÂÉÖÈÄèÈÅéÂêë ABot ÊèêÂá∫ÁöÑ‰∏ÄÁ≥ªÂàóË¶ñË¶∫Áõ∏ÈóúÂïèÈ°åÔºå‰æÜÊâæÂá∫Èö±ËóèÁöÑÂúñÂÉè„ÄÇÁÑ∂ËÄåÔºåÂú® QBot ÁöÑÊ±∫Á≠ñÈÅéÁ®ã‰∏≠ÊúâÊïàÂú∞Âª∫Ê®°Ë¶ñË¶∫Áõ∏ÈóúÊé®ÁêÜÔºåÊòØ‰∏ÄÂÄãÈáçÂ§ßÁöÑÊåëÊà∞„ÄÇÁõÆÂâçÁöÑÂÅöÊ≥ï‰∏çÊòØÁº∫‰πèË¶ñË¶∫Ë≥áË®äÔºåÂ∞±ÊòØ‰æùË≥¥Âú®ÊØè‰∏ÄËº™‰∏≠ÂèñÊ®£ÁöÑÂñÆ‰∏ÄÁúüÂØ¶ÂúñÂÉè‰ΩúÁÇ∫Ëß£Á¢ºÊÉÖÂ¢ÉÔºåÈÄôÂÖ©Á®ÆÂÅöÊ≥ïÈÉΩ‰∏çË∂≥‰ª•ÈÄ≤Ë°åË¶ñË¶∫Êé®ÁêÜ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÈôêÂà∂ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÊñπÊ≥ïÔºåÂ∞àÊ≥®ÊñºÈÄèÈÅé‰ΩøÁî®Êú™ÂÖ¨ÈñãÂúñÂÉèÁöÑÂøÉÊô∫Ê®°ÂûãÔºåÈÄ≤Ë°åË¶ñË¶∫Áõ∏ÈóúÊé®ÁêÜ„ÄÇÂú®ÈÄôÂÄãÊû∂Êßã‰∏≠ÔºåQBot Â≠∏ÁøíË°®ÂæµÂøÉÊô∫ÊÑèË±°ÔºåÈÄèÈÅéËøΩËπ§Â∞çË©±ÁãÄÊÖãÔºåÂïüÁî®Âº∑ÂÅ•ÁöÑË¶ñË¶∫Êé®ÁêÜ„ÄÇÂ∞çË©±ÁãÄÊÖãÂåÖÂê´ÂøÉÊô∫ÊÑèË±°Ë°®ÂæµÁöÑÈõÜÂêàÔºå‰ª•ÂèäÂ∞çË©±‰∏≠ÊâÄÊ∂âÂèäÂØ¶È´îÁöÑË°®Âæµ„ÄÇÂú®ÊØè‰∏ÄËº™‰∏≠ÔºåQBot ‰ΩøÁî®Â∞çË©±ÁãÄÊÖãÈÄ≤Ë°åË¶ñË¶∫Áõ∏ÈóúÊé®ÁêÜÔºå‰ª•Âª∫ÊßãÂÖßÈÉ®Ë°®Âæµ„ÄÅÁî¢ÁîüÁõ∏ÈóúÂïèÈ°åÔºå‰∏¶Âú®Êî∂Âà∞Á≠îÊ°àÊôÇÊõ¥Êñ∞Â∞çË©±ÁãÄÊÖãÂíåÂÖßÈÉ®Ë°®Âæµ„ÄÇÊàëÂÄëÂú® VisDial Ë≥áÊñôÈõÜ (v0.5„ÄÅ0.9 Âíå 1.0) ‰∏äÁöÑÂØ¶È©óÁµêÊûúË≠âÊòé‰∫ÜÊàëÂÄëÊâÄÊèêÂá∫ÁöÑÊ®°ÂûãÁöÑÊúâÊïàÊÄßÔºåÂõ†ÁÇ∫ÂÆÉÂú®ÊâÄÊúâÊåáÊ®ôÂíåË≥áÊñôÈõÜ‰∏äÈÉΩÈÅîÂà∞‰∫ÜÊñ∞ÁöÑÊúÄÂÖàÈÄ≤ÊïàËÉΩÔºåË∂ÖË∂ä‰∫ÜÂÖàÂâçÁöÑÊúÄÂÖàÈÄ≤Ê®°Âûã„ÄÇÊàëÂÄëÂØ¶È©óÁöÑÁ®ãÂºèÁ¢ºÂíåË≥áÊñôÈõÜÂèØ‰ª•Âú® \href{https://github.com/xubuvd/GuessWhich} ÂÖçË≤ªÂèñÂæó„ÄÇ

##### **Assessing and Enhancing Large Language Models in Rare Disease Question-answering**
2408.08422v1 by Guanchu Wang, Junhao Ran, Ruixiang Tang, Chia-Yuan Chang, Chia-Yuan Chang, Yu-Neng Chuang, Zirui Liu, Vladimir Braverman, Zhandong Liu, Xia Hu

Despite the impressive capabilities of Large Language Models (LLMs) in
general medical domains, questions remain about their performance in diagnosing
rare diseases. To answer this question, we aim to assess the diagnostic
performance of LLMs in rare diseases, and explore methods to enhance their
effectiveness in this area. In this work, we introduce a rare disease
question-answering (ReDis-QA) dataset to evaluate the performance of LLMs in
diagnosing rare diseases. Specifically, we collected 1360 high-quality
question-answer pairs within the ReDis-QA dataset, covering 205 rare diseases.
Additionally, we annotated meta-data for each question, facilitating the
extraction of subsets specific to any given disease and its property. Based on
the ReDis-QA dataset, we benchmarked several open-source LLMs, revealing that
diagnosing rare diseases remains a significant challenge for these models.
  To facilitate retrieval augmentation generation for rare disease diagnosis,
we collect the first rare diseases corpus (ReCOP), sourced from the National
Organization for Rare Disorders (NORD) database. Specifically, we split the
report of each rare disease into multiple chunks, each representing a different
property of the disease, including their overview, symptoms, causes, effects,
related disorders, diagnosis, and standard therapies. This structure ensures
that the information within each chunk aligns consistently with a question.
Experiment results demonstrate that ReCOP can effectively improve the accuracy
of LLMs on the ReDis-QA dataset by an average of 8%. Moreover, it significantly
guides LLMs to generate trustworthy answers and explanations that can be traced
back to existing literature.

ÊëòË¶ÅÔºöÂÑòÁÆ°Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®‰∏ÄËà¨ÈÜ´Â≠∏È†òÂüüÊìÅÊúâ‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑËÉΩÂäõÔºå‰ΩÜÂ∞çÊñºÂÆÉÂÄëÂú®Ë®∫Êñ∑ÁΩïË¶ãÁñæÁóÖÊñπÈù¢ÁöÑË°®Áèæ‰ªçÊúâÁñëÂïè„ÄÇÁÇ∫‰∫ÜÂõûÁ≠îÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÊó®Âú®Ë©ï‰º∞ LLM Âú®ÁΩïË¶ãÁñæÁóÖ‰∏≠ÁöÑË®∫Êñ∑Ë°®ÁèæÔºå‰∏¶Êé¢Ë®éÂ¢ûÂº∑ÂÆÉÂÄëÂú®ÈÄôÂÄãÈ†òÂüüÁöÑÊúâÊïàÊÄßÁöÑÊñπÊ≥ï„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÁΩïË¶ãÁñæÁóÖÂïèÁ≠î (ReDis-QA) Ë≥áÊñôÈõÜÔºå‰ª•Ë©ï‰º∞ LLM Âú®Ë®∫Êñ∑ÁΩïË¶ãÁñæÁóÖÊñπÈù¢ÁöÑË°®Áèæ„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÂú® ReDis-QA Ë≥áÊñôÈõÜ‰∏≠Êî∂ÈõÜ‰∫Ü 1360 ÂÄãÈ´òÂìÅË≥™ÁöÑÂïèÈ°åËß£Á≠îÂ∞çÔºåÊ∂µËìã 205 Á®ÆÁΩïË¶ãÁñæÁóÖ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁÇ∫ÊØèÂÄãÂïèÈ°åË®ªÈáã‰∫ÜÂÖÉË≥áÊñôÔºå‰ª•Âà©ÊñºÊèêÂèñÁâπÂÆöÊñº‰ªª‰ΩïÁµ¶ÂÆöÁñæÁóÖÂèäÂÖ∂Â±¨ÊÄßÁöÑÂ≠êÈõÜ„ÄÇÊ†πÊìö ReDis-QA Ë≥áÊñôÈõÜÔºåÊàëÂÄëÂ∞çÂπæÂÄãÈñãÊ∫ê LLM ÈÄ≤Ë°å‰∫ÜÂü∫Ê∫ñÊ∏¨Ë©¶ÔºåÁµêÊûúË°®ÊòéË®∫Êñ∑ÁΩïË¶ãÁñæÁóÖ‰ªçÁÑ∂ÊòØÈÄô‰∫õÊ®°ÂûãÁöÑ‰∏ÄÈ†ÖÈáçÂ§ßÊåëÊà∞„ÄÇÁÇ∫‰∫Ü‰øÉÈÄ≤ÁΩïË¶ãÁñæÁóÖË®∫Êñ∑ÁöÑÊ™¢Á¥¢Â¢ûÂº∑ÁîüÊàêÔºåÊàëÂÄëÊî∂ÈõÜ‰∫ÜÁ¨¨‰∏ÄÂÄãÁΩïË¶ãÁñæÁóÖË™ûÊñôÂ∫´ (ReCOP)ÔºåÂÖ∂‰æÜÊ∫êÊñºÂúãÂÆ∂ÁΩïË¶ãÁñæÁóÖÁµÑÁπî (NORD) Ë≥áÊñôÂ∫´„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÂ∞áÊØèÁ®ÆÁΩïË¶ãÁñæÁóÖÁöÑÂ†±ÂëäÂàÜÊàêÂ§öÂÄãÂçÄÂ°äÔºåÊØèÂÄãÂçÄÂ°ä‰ª£Ë°®ÁñæÁóÖÁöÑ‰∏çÂêåÂ±¨ÊÄßÔºåÂåÖÊã¨ÂÖ∂Ê¶ÇËø∞„ÄÅÁóáÁãÄ„ÄÅÂéüÂõ†„ÄÅÂΩ±Èüø„ÄÅÁõ∏ÈóúÁñæÁóÖ„ÄÅË®∫Êñ∑ÂíåÊ®ôÊ∫ñÁôÇÊ≥ï„ÄÇÈÄôÁ®ÆÁµêÊßãÁ¢∫‰øùÊØèÂÄãÂçÄÂ°ä‰∏≠ÁöÑË≥áË®äËàáÂïèÈ°å‰øùÊåÅ‰∏ÄËá¥„ÄÇÂØ¶È©óÁµêÊûúË°®ÊòéÔºåReCOP ÂèØ‰ª•ÊúâÊïàÂú∞Â∞á LLM Âú® ReDis-QA Ë≥áÊñôÈõÜ‰∏äÁöÑÊ∫ñÁ¢∫Â∫¶Âπ≥ÂùáÊèêÈ´ò 8%„ÄÇÊ≠§Â§ñÔºåÂÆÉÈ°ØËëóÂú∞ÂºïÂ∞é LLM ÁîüÊàêÂèØ‰ø°ÁöÑÁ≠îÊ°àÂíåËß£ÈáãÔºåÈÄô‰∫õÁ≠îÊ°àÂíåËß£ÈáãÂèØ‰ª•ËøΩÊ∫ØÂà∞ÁèæÊúâÊñáÁçª„ÄÇ

##### **Understanding Help-Seeking Behavior of Students Using LLMs vs. Web Search for Writing SQL Queries**
2408.08401v1 by Harsh Kumar, Mohi Reza, Jeb Mitchell, Ilya Musabirov, Lisa Zhang, Michael Liut

Growth in the use of large language models (LLMs) in programming education is
altering how students write SQL queries. Traditionally, students relied heavily
on web search for coding assistance, but this has shifted with the adoption of
LLMs like ChatGPT. However, the comparative process and outcomes of using web
search versus LLMs for coding help remain underexplored. To address this, we
conducted a randomized interview study in a database classroom to compare web
search and LLMs, including a publicly available LLM (ChatGPT) and an
instructor-tuned LLM, for writing SQL queries. Our findings indicate that using
an instructor-tuned LLM required significantly more interactions than both
ChatGPT and web search, but resulted in a similar number of edits to the final
SQL query. No significant differences were found in the quality of the final
SQL queries between conditions, although the LLM conditions directionally
showed higher query quality. Furthermore, students using instructor-tuned LLM
reported a lower mental demand. These results have implications for learning
and productivity in programming education.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®Á®ãÂºèË®≠Ë®àÊïôËÇ≤‰∏≠ÁöÑ‰ΩøÁî®ÊàêÈï∑Ê≠£Âú®ÊîπËÆäÂ≠∏ÁîüÊí∞ÂØ´ SQL Êü•Ë©¢ÁöÑÊñπÂºè„ÄÇÂÇ≥Áµ±‰∏äÔºåÂ≠∏Áîü‰ª∞Ë≥¥Á∂≤Ë∑ØÊêúÂ∞ã‰æÜÂçîÂä©Á∑®Á¢ºÔºå‰ΩÜÈÄôÂ∑≤Èö®Ëëó ChatGPT Á≠â LLM ÁöÑÊé°Áî®ËÄåÊúâÊâÄÊîπËÆä„ÄÇÁÑ∂ËÄåÔºå‰ΩøÁî®Á∂≤Ë∑ØÊêúÂ∞ãËàá LLM ‰æÜÂçîÂä©Á∑®Á¢ºÁöÑÊØîËºÉÈÅéÁ®ãÂíåÁµêÊûú‰ªçÊú™ÂèóÂà∞ÂÖÖÂàÜÊé¢Ë®é„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÂú®Ë≥áÊñôÂ∫´ÊïôÂÆ§‰∏≠ÈÄ≤Ë°å‰∫Ü‰∏ÄÈ†ÖÈö®Ê©üË®™Ë´áÁ†îÁ©∂Ôºå‰ª•ÊØîËºÉÁ∂≤Ë∑ØÊêúÂ∞ãÂíå LLMÔºåÂåÖÊã¨ÂÖ¨ÈñãÂèØÁî®ÁöÑ LLM (ChatGPT) ÂíåÊïôÂ∏´Ë™øÊï¥ÁöÑ LLMÔºåÁî®ÊñºÊí∞ÂØ´ SQL Êü•Ë©¢„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúË°®ÊòéÔºå‰ΩøÁî®ÊïôÂ∏´Ë™øÊï¥ÁöÑ LLM ÊâÄÈúÄÁöÑ‰∫íÂãïÊ¨°Êï∏ÊòéÈ°ØÂ§öÊñº ChatGPT ÂíåÁ∂≤Ë∑ØÊêúÂ∞ãÔºå‰ΩÜÂ∞çÊúÄÁµÇ SQL Êü•Ë©¢ÁöÑÁ∑®ËºØÊ¨°Êï∏ÂçªÈ°û‰ºº„ÄÇÂú®‰∏çÂêåÊ¢ù‰ª∂‰∏ãÁöÑÊúÄÁµÇ SQL Êü•Ë©¢ÂìÅË≥™‰∏¶Êú™ÁôºÁèæÈ°ØËëóÂ∑ÆÁï∞ÔºåÂÑòÁÆ° LLM Ê¢ù‰ª∂Âú®ÊñπÂêë‰∏äÈ°ØÁ§∫Âá∫ËºÉÈ´òÁöÑÊü•Ë©¢ÂìÅË≥™„ÄÇÊ≠§Â§ñÔºå‰ΩøÁî®ÊïôÂ∏´Ë™øÊï¥ LLM ÁöÑÂ≠∏ÁîüÂõûÂ†±ËºÉ‰ΩéÁöÑÂøÉÁêÜÈúÄÊ±Ç„ÄÇÈÄô‰∫õÁµêÊûúÂ∞çÁ®ãÂºèË®≠Ë®àÊïôËÇ≤‰∏≠ÁöÑÂ≠∏ÁøíÂíåÁîüÁî¢ÂäõÂÖ∑ÊúâÂΩ±Èüø„ÄÇ

##### **Zero-Shot Learning and Key Points Are All You Need for Automated Fact-Checking**
2408.08400v1 by Mohammad Ghiasvand Mohammadkhani, Ali Ghiasvand Mohammadkhani, Hamid Beigy

Automated fact-checking is an important task because determining the accurate
status of a proposed claim within the vast amount of information available
online is a critical challenge. This challenge requires robust evaluation to
prevent the spread of false information. Modern large language models (LLMs)
have demonstrated high capability in performing a diverse range of Natural
Language Processing (NLP) tasks. By utilizing proper prompting strategies,
their versatility due to their understanding of large context sizes and
zero-shot learning ability enables them to simulate human problem-solving
intuition and move towards being an alternative to humans for solving problems.
In this work, we introduce a straightforward framework based on Zero-Shot
Learning and Key Points (ZSL-KeP) for automated fact-checking, which despite
its simplicity, performed well on the AVeriTeC shared task dataset by robustly
improving the baseline and achieving 10th place.

ÊëòË¶ÅÔºöËá™ÂãïÂåñ‰∫ãÂØ¶Êü•Ê†∏ÊòØ‰∏ÄÈ†ÖÈáçË¶ÅÁöÑ‰ªªÂãôÔºåÂõ†ÁÇ∫Âú®Á∂≤Ë∑Ø‰∏äÂ§ßÈáèÂèØÂæóÁöÑË≥áË®ä‰∏≠Âà§Êñ∑‰∏ÄÂÄã‰∏ªÂºµÁöÑÊ∫ñÁ¢∫ÁãÄÊÖãÊòØ‰∏ÄÈ†ÖÈáçÂ§ßÁöÑÊåëÊà∞„ÄÇÈÄôÂÄãÊåëÊà∞ÈúÄË¶ÅÂº∑ÂÅ•ÁöÑË©ï‰º∞‰ª•Èò≤Ê≠¢ÈåØË™§Ë≥áË®äÁöÑÊï£Êí≠„ÄÇÁèæ‰ª£ÁöÑÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤Â±ïÁèæÂá∫Âü∑Ë°åÂêÑÁ®ÆËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ (NLP) ‰ªªÂãôÁöÑÈ´òËÉΩÂäõ„ÄÇÈÄèÈÅé‰ΩøÁî®ÈÅ©Áï∂ÁöÑÊèêÁ§∫Á≠ñÁï•ÔºåÂÆÉÂÄëÁî±ÊñºÁêÜËß£Â§ßÂûãËÑàÁµ°Â§ßÂ∞èÂíåÈõ∂Ê¨°Â≠∏ÁøíËÉΩÂäõÁöÑÂ§öÂäüËÉΩÊÄßÔºå‰ΩøÂÆÉÂÄëËÉΩÊ®°Êì¨‰∫∫È°ûËß£Ê±∫ÂïèÈ°åÁöÑÁõ¥Ë¶∫Ôºå‰∏¶ÊúùËëóÊàêÁÇ∫‰∫∫È°ûËß£Ê±∫ÂïèÈ°åÁöÑÊõø‰ª£ÊñπÊ°àÈÇÅÈÄ≤„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫Ü‰∏ÄÂÄãÂü∫ÊñºÈõ∂Ê¨°Â≠∏ÁøíÂíåÈáçÈªû (ZSL-KeP) ÁöÑÁõ¥Êé•Êû∂ÊßãÔºåÁî®ÊñºËá™ÂãïÂåñ‰∫ãÂØ¶Êü•Ê†∏ÔºåÂÑòÁÆ°ÂÆÉÂæàÁ∞°ÂñÆÔºå‰ΩÜÂú® AVeriTeC ÂÖ±‰∫´‰ªªÂãôË≥áÊñôÈõÜ‰∏äË°®ÁèæËâØÂ•ΩÔºåÈÄèÈÅéÂº∑ÂÅ•Âú∞ÊîπÂñÑÂü∫Ê∫ñ‰∏¶Áç≤ÂæóÁ¨¨ 10 Âêç„ÄÇ

##### **Level Up Your Tutorials: VLMs for Game Tutorials Quality Assessment**
2408.08396v1 by Daniele Rege Cambrin, Gabriele Scaffidi Militone, Luca Colomba, Giovanni Malnati, Daniele Apiletti, Paolo Garza

Designing effective game tutorials is crucial for a smooth learning curve for
new players, especially in games with many rules and complex core mechanics.
Evaluating the effectiveness of these tutorials usually requires multiple
iterations with testers who have no prior knowledge of the game. Recent
Vision-Language Models (VLMs) have demonstrated significant capabilities in
understanding and interpreting visual content. VLMs can analyze images, provide
detailed insights, and answer questions about their content. They can recognize
objects, actions, and contexts in visual data, making them valuable tools for
various applications, including automated game testing. In this work, we
propose an automated game-testing solution to evaluate the quality of game
tutorials. Our approach leverages VLMs to analyze frames from video game
tutorials, answer relevant questions to simulate human perception, and provide
feedback. This feedback is compared with expected results to identify confusing
or problematic scenes and highlight potential errors for developers. In
addition, we publish complete tutorial videos and annotated frames from
different game versions used in our tests. This solution reduces the need for
extensive manual testing, especially by speeding up and simplifying the initial
development stages of the tutorial to improve the final game experience.

ÊëòË¶ÅÔºöË®≠Ë®àÊúâÊïàÁöÑÈÅäÊà≤ÊïôÂ≠∏Ë™≤Á®ãÂ∞çÊñºÊñ∞Áé©ÂÆ∂ÁöÑÈ†ÜÂà©Â≠∏ÁøíÊõ≤Á∑öËá≥ÈóúÈáçË¶ÅÔºåÁâπÂà•ÊòØÂú®ÂÖ∑ÊúâË®±Â§öË¶èÂâáÂíåË§áÈõúÊ†∏ÂøÉÊ©üÂà∂ÁöÑÈÅäÊà≤‰∏≠„ÄÇË©ï‰º∞ÈÄô‰∫õÊïôÂ≠∏Ë™≤Á®ãÁöÑÊúâÊïàÊÄßÈÄöÂ∏∏ÈúÄË¶ÅËàáÂ∞çÈÅäÊà≤Ê≤íÊúâ‰ªª‰ΩïÂÖàÂÇôÁü•Ë≠òÁöÑÊ∏¨Ë©¶‰∫∫Âì°ÈÄ≤Ë°åÂ§öÊ¨°Ëø≠‰ª£„ÄÇÊúÄËøëÁöÑË¶ñË¶∫Ë™ûË®ÄÊ®°Âûã (VLM) Â∑≤Â±ïÁèæÂá∫Âú®ÁêÜËß£ÂíåË©ÆÈáãË¶ñË¶∫ÂÖßÂÆπÊñπÈù¢ÁöÑÈ°ØËëóËÉΩÂäõ„ÄÇVLM ÂèØ‰ª•ÂàÜÊûêÂΩ±ÂÉè„ÄÅÊèê‰æõË©≥Á¥∞Ë¶ãËß£Ôºå‰∏¶ÂõûÁ≠îÊúâÈóúÂÖ∂ÂÖßÂÆπÁöÑÂïèÈ°å„ÄÇÂÆÉÂÄëÂèØ‰ª•Ëæ®Ë≠òË¶ñË¶∫Ë≥áÊñô‰∏≠ÁöÑÁâ©‰ª∂„ÄÅÂãï‰ΩúÂíåËÉåÊôØÔºå‰ΩøÂÖ∂ÊàêÁÇ∫ÂêÑÁ®ÆÊáâÁî®Á®ãÂºèÁöÑÂØ∂Ë≤¥Â∑•ÂÖ∑ÔºåÂåÖÊã¨Ëá™ÂãïÂåñÈÅäÊà≤Ê∏¨Ë©¶„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãËá™ÂãïÂåñÈÅäÊà≤Ê∏¨Ë©¶Ëß£Ê±∫ÊñπÊ°à‰æÜË©ï‰º∞ÈÅäÊà≤ÊïôÂ≠∏Ë™≤Á®ãÁöÑÂìÅË≥™„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÂà©Áî® VLM ‰æÜÂàÜÊûêÈõªÂ≠êÈÅäÊà≤ÊïôÂ≠∏Ë™≤Á®ã‰∏≠ÁöÑÁï´Èù¢„ÄÅÂõûÁ≠îÁõ∏ÈóúÂïèÈ°å‰ª•Ê®°Êì¨‰∫∫È°ûÊÑüÁü•Ôºå‰∏¶Êèê‰æõÂõûÈ•ã„ÄÇÊ≠§ÂõûÈ•ãÊúÉËàáÈ†êÊúüÁµêÊûúÈÄ≤Ë°åÊØîËºÉÔºå‰ª•ÊâæÂá∫‰ª§‰∫∫Âõ∞ÊÉëÊàñÊúâÂïèÈ°åÁöÑÂ†¥ÊôØÔºå‰∏¶ÈáçÈªûÊåáÂá∫ÈñãÁôº‰∫∫Âì°ÁöÑÊΩõÂú®ÈåØË™§„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊúÉÁôºÂ∏ÉÂú®Ê∏¨Ë©¶‰∏≠‰ΩøÁî®ÁöÑ‰∏çÂêåÈÅäÊà≤ÁâàÊú¨ÁöÑÂÆåÊï¥ÊïôÂ≠∏Ë™≤Á®ãÂΩ±ÁâáÂíåË®ªËß£Áï´Èù¢„ÄÇÊ≠§Ëß£Ê±∫ÊñπÊ°àÊ∏õÂ∞ë‰∫ÜÂª£Ê≥õÊâãÂãïÊ∏¨Ë©¶ÁöÑÈúÄÊ±ÇÔºåÁâπÂà•ÊòØÈÄèÈÅéÂä†ÈÄüÂíåÁ∞°ÂåñÊïôÂ≠∏Ë™≤Á®ãÁöÑÂàùÂßãÈñãÁôºÈöéÊÆµÔºå‰ª•ÊîπÂñÑÊúÄÁµÇÁöÑÈÅäÊà≤È´îÈ©ó„ÄÇ

##### **Towards Realistic Synthetic User-Generated Content: A Scaffolding Approach to Generating Online Discussions**
2408.08379v1 by Krisztian Balog, John Palowitch, Barbara Ikica, Filip Radlinski, Hamidreza Alvari, Mehdi Manshadi

The emergence of synthetic data represents a pivotal shift in modern machine
learning, offering a solution to satisfy the need for large volumes of data in
domains where real data is scarce, highly private, or difficult to obtain. We
investigate the feasibility of creating realistic, large-scale synthetic
datasets of user-generated content, noting that such content is increasingly
prevalent and a source of frequently sought information. Large language models
(LLMs) offer a starting point for generating synthetic social media discussion
threads, due to their ability to produce diverse responses that typify online
interactions. However, as we demonstrate, straightforward application of LLMs
yields limited success in capturing the complex structure of online
discussions, and standard prompting mechanisms lack sufficient control. We
therefore propose a multi-step generation process, predicated on the idea of
creating compact representations of discussion threads, referred to as
scaffolds. Our framework is generic yet adaptable to the unique characteristics
of specific social media platforms. We demonstrate its feasibility using data
from two distinct online discussion platforms. To address the fundamental
challenge of ensuring the representativeness and realism of synthetic data, we
propose a portfolio of evaluation measures to compare various instantiations of
our framework.

ÊëòË¶ÅÔºöÂêàÊàêË≥áÊñôÁöÑÂá∫Áèæ‰ª£Ë°®‰∫ÜÁèæ‰ª£Ê©üÂô®Â≠∏ÁøíÁöÑÈóúÈçµËΩâËÆäÔºåÂÆÉÊèê‰æõ‰∫Ü‰∏ÄÂÄãËß£Ê±∫ÊñπÊ°à‰æÜÊªøË∂≥Âú®ÂØ¶ÈöõË≥áÊñôÁ®ÄÂ∞ë„ÄÅÈ´òÂ∫¶ÁßÅÂØÜÊàñÈõ£‰ª•ÂèñÂæóÁöÑÈ†òÂüü‰∏≠Â∞çÂ§ßÈáèË≥áÊñôÁöÑÈúÄÊ±Ç„ÄÇÊàëÂÄëÊé¢Ë®éÂª∫Á´ãÂ§ßÈáè‰∏îÈÄºÁúüÁöÑ‰ΩøÁî®ËÄÖÁî¢ÁîüÂÖßÂÆπÂêàÊàêË≥áÊñôÈõÜÁöÑÂèØË°åÊÄßÔºå‰∏¶Ê≥®ÊÑèÂà∞Ê≠§È°ûÂÖßÂÆπË∂ä‰æÜË∂äÊôÆÈÅçÔºå‰∏îÊòØÁ∂ìÂ∏∏Â∞ãÊ±ÇÁöÑË≥áË®ä‰æÜÊ∫ê„ÄÇÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Áî±ÊñºËÉΩÂ§†Áî¢ÁîüÂ§öÊ®£ÂåñÁöÑÂõûÊáâÔºå‰ª£Ë°®ËëóÁ∑ö‰∏ä‰∫íÂãïÁöÑÂÖ∏ÂûãÔºåÂõ†Ê≠§Êèê‰æõ‰∫ÜÁî¢ÁîüÂêàÊàêÁ§æÁæ§Â™íÈ´îË®éË´ñ‰∏≤ÁöÑËµ∑Èªû„ÄÇÁÑ∂ËÄåÔºåÊ≠£Â¶ÇÊàëÂÄëÊâÄÂ±ïÁ§∫ÁöÑÔºåLLM ÁöÑÁõ¥Êé•ÊáâÁî®Âú®ÊçïÊçâÁ∑ö‰∏äË®éË´ñÁöÑË§áÈõúÁµêÊßãÊñπÈù¢ÂÉÖËÉΩÁç≤ÂæóÊúâÈôêÁöÑÊàêÂäüÔºå‰∏îÊ®ôÊ∫ñÊèêÁ§∫Ê©üÂà∂Áº∫‰πèË∂≥Â§†ÁöÑÊéßÂà∂„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂ§öÊ≠•È©üÁîüÊàêÁ®ãÂ∫èÔºå‰ª•Âª∫Á´ãË®éË´ñ‰∏≤ÁöÑÁ≤æÁ∞°Ë°®Á§∫ÔºàÁ®±ÁÇ∫Êû∂ÊßãÔºâÁöÑÊ¶ÇÂøµÁÇ∫Âü∫Á§é„ÄÇÊàëÂÄëÁöÑÊû∂ÊßãÂÖ∑ÊúâÈÄöÁî®ÊÄßÔºå‰ΩÜËÉΩÂ§†ÈÅ©ÊáâÁâπÂÆöÁ§æÁæ§Â™íÈ´îÂπ≥Âè∞ÁöÑÁç®ÁâπÁâπÊÄß„ÄÇÊàëÂÄë‰ΩøÁî®‰æÜËá™ÂÖ©ÂÄã‰∏çÂêåÁ∑ö‰∏äË®éË´ñÂπ≥Âè∞ÁöÑË≥áÊñô‰æÜË≠âÊòéÂÖ∂ÂèØË°åÊÄß„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÁ¢∫‰øùÂêàÊàêË≥áÊñôÁöÑ‰ª£Ë°®ÊÄßÂíåÁúüÂØ¶ÊÄßÁöÑÂü∫Êú¨ÊåëÊà∞ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ≥ªÂàóË©ï‰º∞Êé™ÊñΩÔºå‰ª•ÊØîËºÉÊàëÂÄëÊû∂ÊßãÁöÑÂêÑÁ®ÆÂØ¶‰æã„ÄÇ

##### **Decoding the human brain tissue response to radiofrequency excitation using a biophysical-model-free deep MRI on a chip framework**
2408.08376v1 by Dinor Nagar, Moritz Zaiss, Or Perlman

Magnetic resonance imaging (MRI) relies on radiofrequency (RF) excitation of
proton spin. Clinical diagnosis requires a comprehensive collation of
biophysical data via multiple MRI contrasts, acquired using a series of RF
sequences that lead to lengthy examinations. Here, we developed a vision
transformer-based framework that captures the spatiotemporal magnetic signal
evolution and decodes the brain tissue response to RF excitation, constituting
an MRI on a chip. Following a per-subject rapid calibration scan (28.2 s), a
wide variety of image contrasts including fully quantitative molecular, water
relaxation, and magnetic field maps can be generated automatically. The method
was validated across healthy subjects and a cancer patient in two different
imaging sites, and proved to be 94% faster than alternative protocols. The deep
MRI on a chip (DeepMonC) framework may reveal the molecular composition of the
human brain tissue in a wide range of pathologies, while offering clinically
attractive scan times.

ÊëòË¶ÅÔºöÁ£ÅÊåØÈÄ†ÂΩ± (MRI) ‰ª∞Ë≥¥Â∞ÑÈ†ª (RF) ÊøÄÁôºË≥™Â≠êËá™Êóã„ÄÇËá®Â∫äË®∫Êñ∑ÈúÄË¶ÅÈÄèÈÅéÂ§öÁ®Æ MRI Â∞çÊØî‰æÜÂÖ®Èù¢Êî∂ÈõÜÁîüÁâ©Áâ©ÁêÜË≥áÊñôÔºå‰∏¶‰ΩøÁî®‰∏ÄÁ≥ªÂàóÊúÉÂ∞éËá¥ÂÜóÈï∑Ê™¢Êü•ÁöÑ RF Â∫èÂàóÂèñÂæó„ÄÇÂú®Ê≠§ÔºåÊàëÂÄëÈñãÁôº‰∫Ü‰∏ÄÂÄãÂü∫ÊñºË¶ñË¶∫ËΩâÊèõÂô®ÁöÑÊû∂ÊßãÔºåÂèØÊì∑ÂèñÊôÇÁ©∫Á£ÅË®äËôüÊºîÂåñ‰∏¶Ëß£Á¢ºËÖ¶ÁµÑÁπîÂ∞ç RF ÊøÄÁôºÁöÑÂèçÊáâÔºåÊßãÊàêÊô∂Áâá‰∏äÁöÑ MRI„ÄÇÂú®ÊØèÊ¨°ÂèóË©¶ËÄÖÁöÑÂø´ÈÄüÊ†°Ê≠£ÊéÉÊèè (28.2 Áßí) ‰πãÂæåÔºåÂèØ‰ª•Ëá™ÂãïÁî¢ÁîüÂêÑÁ®ÆÂΩ±ÂÉèÂ∞çÊØîÔºåÂåÖÊã¨ÂÆåÂÖ®ÈáèÂåñÁöÑÂàÜÂ≠ê„ÄÅÊ∞¥ÂºõÁ∑©ÂíåÁ£ÅÂ†¥Âúñ„ÄÇÊ≠§ÊñπÊ≥ïÂ∑≤Âú®ÂÅ•Â∫∑ÂèóË©¶ËÄÖÂíåÁôåÁóáÊÇ£ËÄÖË∫´‰∏äÊñºÂÖ©ÂÄã‰∏çÂêåÁöÑÂΩ±ÂÉèÊ™¢Êü•Âú∞ÈªûÈÄ≤Ë°åÈ©óË≠âÔºå‰∏¶Ë≠âÊòéÊØîÂÖ∂‰ªñÊñπÊ°àÂø´ 94%„ÄÇÊô∂Áâá‰∏äÁöÑÊ∑±Â∫¶ MRI (DeepMonC) Êû∂ÊßãÂèØËÉΩÊúÉÊè≠Á§∫ÂêÑÁ®ÆÁóÖÁêÜ‰∏≠‰∫∫ËÖ¶ÁµÑÁπîÁöÑÂàÜÂ≠êÁµÑÊàêÔºåÂêåÊôÇÊèê‰æõËá®Â∫ä‰∏äÊúâÂê∏ÂºïÂäõÁöÑÊéÉÊèèÊôÇÈñì„ÄÇ

##### **Can Large Language Models Understand Symbolic Graphics Programs?**
2408.08313v1 by Zeju Qiu, Weiyang Liu, Haiwen Feng, Zhen Liu, Tim Z. Xiao, Katherine M. Collins, Joshua B. Tenenbaum, Adrian Weller, Michael J. Black, Bernhard Sch√∂lkopf

Assessing the capabilities of large language models (LLMs) is often
challenging, in part, because it is hard to find tasks to which they have not
been exposed during training. We take one step to address this challenge by
turning to a new task: focusing on symbolic graphics programs, which are a
popular representation for graphics content that procedurally generates visual
data. LLMs have shown exciting promise towards program synthesis, but do they
understand symbolic graphics programs? Unlike conventional programs, symbolic
graphics programs can be translated to graphics content. Here, we characterize
an LLM's understanding of symbolic programs in terms of their ability to answer
questions related to the graphics content. This task is challenging as the
questions are difficult to answer from the symbolic programs alone -- yet, they
would be easy to answer from the corresponding graphics content as we verify
through a human experiment. To understand symbolic programs, LLMs may need to
possess the ability to imagine how the corresponding graphics content would
look without directly accessing the rendered visual content. We use this task
to evaluate LLMs by creating a large benchmark for the semantic understanding
of symbolic graphics programs. This benchmark is built via program-graphics
correspondence, hence requiring minimal human efforts. We evaluate current LLMs
on our benchmark to elucidate a preliminary assessment of their ability to
reason about visual scenes from programs. We find that this task distinguishes
existing LLMs and models considered good at reasoning perform better. Lastly,
we introduce Symbolic Instruction Tuning (SIT) to improve this ability.
Specifically, we query GPT4-o with questions and images generated by symbolic
programs. Such data are then used to finetune an LLM. We also find that SIT
data can improve the general instruction following ability of LLMs.

ÊëòË¶ÅÔºö<paragraph>Ë©ï‰º∞Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÂäüËÉΩÈÄöÂ∏∏ÂÖ∑ÊúâÊåëÊà∞ÊÄßÔºåÈÉ®ÂàÜÂéüÂõ†ÊòØÈõ£‰ª•ÊâæÂà∞Âú®Ë®ìÁ∑¥ÈÅéÁ®ã‰∏≠Êú™Êé•Ëß∏ÈÅéÁöÑ‰ªªÂãô„ÄÇÊàëÂÄëÈÄèÈÅéÂ∞àÊ≥®ÊñºÁ¨¶ËôüÂúñÂΩ¢Á®ãÂºèÈÄôÂÄãÊñ∞‰ªªÂãô‰æÜËß£Ê±∫Ê≠§ÊåëÊà∞ÔºåÁ¨¶ËôüÂúñÂΩ¢Á®ãÂºèÊòØÂúñÂΩ¢ÂÖßÂÆπÁöÑÁÜ±ÈñÄË°®Á§∫ÂΩ¢ÂºèÔºåÂèØÂæ™Â∫èÁî¢ÁîüË¶ñË¶∫Ë≥áÊñô„ÄÇLLM Â∑≤Âú®Á®ãÂºèÂêàÊàêÊñπÈù¢Â±ïÁèæ‰ª§‰∫∫ËààÂ•ÆÁöÑÂâçÊôØÔºå‰ΩÜÂÆÉÂÄëÊòØÂê¶‰∫ÜËß£Á¨¶ËôüÂúñÂΩ¢Á®ãÂºèÔºüËàáÂÇ≥Áµ±Á®ãÂºè‰∏çÂêåÔºåÁ¨¶ËôüÂúñÂΩ¢Á®ãÂºèÂèØ‰ª•ËΩâÊèõÁÇ∫ÂúñÂΩ¢ÂÖßÂÆπ„ÄÇÂú®Ê≠§ÔºåÊàëÂÄëÊ†πÊìö LLM ÂõûÁ≠îËàáÂúñÂΩ¢ÂÖßÂÆπÁõ∏ÈóúÂïèÈ°åÁöÑËÉΩÂäõÔºå‰æÜÊèèËø∞ÂÖ∂Â∞çÁ¨¶ËôüÁ®ãÂºèÁöÑÁêÜËß£„ÄÇÈÄôÈ†Ö‰ªªÂãôÂÖ∑ÊúâÊåëÊà∞ÊÄßÔºåÂõ†ÁÇ∫ÂÉÖÂæûÁ¨¶ËôüÁ®ãÂºè‰∏≠ÂæàÈõ£ÂõûÁ≠îÈÄô‰∫õÂïèÈ°åÔºå‰ΩÜÂæûÂ∞çÊáâÁöÑÂúñÂΩ¢ÂÖßÂÆπ‰∏≠ÂæàÂÆπÊòìÂ∞±ËÉΩÂõûÁ≠îÔºåÊàëÂÄëÈÄèÈÅé‰∫∫È´îÂØ¶È©óÈ©óË≠â‰∫ÜÈÄô‰∏ÄÈªû„ÄÇËã•Ë¶Å‰∫ÜËß£Á¨¶ËôüÁ®ãÂºèÔºåLLM ÂèØËÉΩÈúÄË¶ÅÂÖ∑ÂÇôÊÉ≥ÂÉèÂ∞çÊáâÂúñÂΩ¢ÂÖßÂÆπÂ§ñËßÄÁöÑËÉΩÂäõÔºåËÄåÁÑ°ÈúÄÁõ¥Êé•Â≠òÂèñÂ∑≤Ê∏≤ÊüìÁöÑË¶ñË¶∫ÂÖßÂÆπ„ÄÇÊàëÂÄë‰ΩøÁî®Ê≠§‰ªªÂãôÈÄèÈÅéÁÇ∫Á¨¶ËôüÂúñÂΩ¢Á®ãÂºèÁöÑË™ûÊÑèÁêÜËß£Âª∫Á´ãÂ§ßÂûãÂü∫Ê∫ñÔºå‰æÜË©ï‰º∞ LLM„ÄÇÊ≠§Âü∫Ê∫ñÊòØÈÄèÈÅéÁ®ãÂºèÂúñÂΩ¢Â∞çÊáâÂª∫Á´ãÔºåÂõ†Ê≠§ÈúÄË¶ÅÊúÄÂ∞ëÁöÑ‰∫∫Âäõ„ÄÇÊàëÂÄëÂú®Âü∫Ê∫ñ‰∏äË©ï‰º∞ÁõÆÂâçÁöÑ LLMÔºå‰ª•Èó°ÊòéÂÖ∂ÂæûÁ®ãÂºè‰∏≠Êé®Ë´ñË¶ñË¶∫Â†¥ÊôØÁöÑËÉΩÂäõÁöÑÂàùÊ≠•Ë©ï‰º∞„ÄÇÊàëÂÄëÁôºÁèæÊ≠§‰ªªÂãôÂçÄÂàÜ‰∫ÜÁèæÊúâÁöÑ LLMÔºå‰∏¶‰∏îË¢´Ë™çÁÇ∫ÊìÖÈï∑Êé®ÁêÜÁöÑÊ®°ÂûãË°®ÁèæÂæóÊõ¥Â•Ω„ÄÇÊúÄÂæåÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜÁ¨¶ËôüÊåá‰ª§Ë™øÊï¥ (SIT) ‰æÜÊèêÂçáÊ≠§ËÉΩÂäõ„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄë‰ΩøÁî®Á¨¶ËôüÁ®ãÂºèÁî¢ÁîüÁöÑÂïèÈ°åÂíåÂΩ±ÂÉèÊü•Ë©¢ GPT4-o„ÄÇÊ≠§È°ûË≥áÊñôÈö®ÂæåÁî®ÊñºÂæÆË™ø LLM„ÄÇÊàëÂÄë‰πüÁôºÁèæ SIT Ë≥áÊñôÂèØ‰ª•ÊèêÂçá LLM ÁöÑ‰∏ÄËà¨Êåá‰ª§ÈÅµÂæ™ËÉΩÂäõ„ÄÇ</paragraph>

##### **ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws**
2408.08310v1 by Ruihang Li, Yixuan Wei, Miaosen Zhang, Nenghai Yu, Han Hu, Houwen Peng

High-quality data is crucial for the pre-training performance of large
language models. Unfortunately, existing quality filtering methods rely on a
known high-quality dataset as reference, which can introduce potential bias and
compromise diversity. In this paper, we propose ScalingFilter, a novel approach
that evaluates text quality based on the perplexity difference between two
language models trained on the same data, thereby eliminating the influence of
the reference dataset in the filtering process. An theoretical analysis shows
that ScalingFilter is equivalent to an inverse utilization of scaling laws.
Through training models with 1.3B parameters on the same data source processed
by various quality filters, we find ScalingFilter can improve zero-shot
performance of pre-trained models in downstream tasks. To assess the bias
introduced by quality filtering, we introduce semantic diversity, a metric of
utilizing text embedding models for semantic representations. Extensive
experiments reveal that semantic diversity is a reliable indicator of dataset
diversity, and ScalingFilter achieves an optimal balance between downstream
performance and semantic diversity.

ÊëòË¶ÅÔºöÈ´òË¥®ÈáèÁöÑÊï∞ÊçÆÂØπ‰∫éÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÁöÑÈ¢ÑËÆ≠ÁªÉÊÄßËÉΩËá≥ÂÖ≥ÈáçË¶Å„ÄÇ‰∏çÂπ∏ÁöÑÊòØÔºåÁé∞ÊúâÁöÑË¥®ÈáèËøáÊª§ÊñπÊ≥ï‰æùËµñ‰∫éÂ∑≤Áü•ÁöÑÈ´òË¥®ÈáèÊï∞ÊçÆÈõÜ‰Ωú‰∏∫ÂèÇËÄÉÔºåËøôÂèØËÉΩ‰ºöÂºïÂÖ•ÊΩúÂú®ÁöÑÂÅèÂ∑ÆÂπ∂ÊçüÂÆ≥Â§öÊ†∑ÊÄß„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü ScalingFilterÔºåËøôÊòØ‰∏ÄÁßçÊñ∞È¢ñÁöÑÊñπÊ≥ïÔºåÂÆÉÊ†πÊçÆÂú®Âêå‰∏ÄÊï∞ÊçÆ‰∏äËÆ≠ÁªÉÁöÑ‰∏§‰∏™ËØ≠Ë®ÄÊ®°Âûã‰πãÈó¥ÁöÑÂõ∞ÊÉëÂ∫¶Â∑ÆÂºÇÊù•ËØÑ‰º∞ÊñáÊú¨Ë¥®ÈáèÔºå‰ªéËÄåÊ∂àÈô§‰∫ÜËøáÊª§ËøáÁ®ã‰∏≠ÂèÇËÄÉÊï∞ÊçÆÈõÜÁöÑÂΩ±Âìç„ÄÇÁêÜËÆ∫ÂàÜÊûêË°®ÊòéÔºåScalingFilter Á≠âÊïà‰∫éÂØπÊ†áÂ∫¶ÂÆöÂæãÁöÑÂèçÂêëÂà©Áî®„ÄÇÈÄöËøá‰ΩøÁî®ÂêÑÁßçË¥®ÈáèËøáÊª§Âô®Â§ÑÁêÜÁöÑÁõ∏ÂêåÊï∞ÊçÆÊ∫êÂØπÂÖ∑Êúâ 1.3B ÂèÇÊï∞ÁöÑËÆ≠ÁªÉÊ®°ÂûãÔºåÊàë‰ª¨ÂèëÁé∞ ScalingFilter ÂèØ‰ª•ÊèêÈ´òÈ¢ÑËÆ≠ÁªÉÊ®°ÂûãÂú®‰∏ãÊ∏∏‰ªªÂä°‰∏≠ÁöÑÈõ∂Ê†∑Êú¨ÊÄßËÉΩ„ÄÇ‰∏∫‰∫ÜËØÑ‰º∞Ë¥®ÈáèËøáÊª§ÂºïÂÖ•ÁöÑÂÅèÂ∑ÆÔºåÊàë‰ª¨ÂºïÂÖ•‰∫ÜËØ≠‰πâÂ§öÊ†∑ÊÄßÔºåËøôÊòØ‰∏ÄÁßçÂà©Áî®ÊñáÊú¨ÂµåÂÖ•Ê®°ÂûãËøõË°åËØ≠‰πâË°®Á§∫ÁöÑÂ∫¶Èáè„ÄÇÂ§ßÈáèÁöÑÂÆûÈ™åË°®ÊòéÔºåËØ≠‰πâÂ§öÊ†∑ÊÄßÊòØÊï∞ÊçÆÈõÜÂ§öÊ†∑ÊÄßÁöÑÂèØÈù†ÊåáÊ†áÔºåËÄå ScalingFilter Âú®‰∏ãÊ∏∏ÊÄßËÉΩÂíåËØ≠‰πâÂ§öÊ†∑ÊÄß‰πãÈó¥ÂÆûÁé∞‰∫ÜÊúÄ‰Ω≥Âπ≥Ë°°„ÄÇ

##### **Benchmarking the Capabilities of Large Language Models in Transportation System Engineering: Accuracy, Consistency, and Reasoning Behaviors**
2408.08302v1 by Usman Syed, Ethan Light, Xingang Guo, Huan Zhang, Lianhui Qin, Yanfeng Ouyang, Bin Hu

In this paper, we explore the capabilities of state-of-the-art large language
models (LLMs) such as GPT-4, GPT-4o, Claude 3.5 Sonnet, Claude 3 Opus, Gemini
1.5 Pro, Llama 3, and Llama 3.1 in solving some selected undergraduate-level
transportation engineering problems. We introduce TransportBench, a benchmark
dataset that includes a sample of transportation engineering problems on a wide
range of subjects in the context of planning, design, management, and control
of transportation systems. This dataset is used by human experts to evaluate
the capabilities of various commercial and open-sourced LLMs, especially their
accuracy, consistency, and reasoning behaviors, in solving transportation
engineering problems. Our comprehensive analysis uncovers the unique strengths
and limitations of each LLM, e.g. our analysis shows the impressive accuracy
and some unexpected inconsistent behaviors of Claude 3.5 Sonnet in solving
TransportBench problems. Our study marks a thrilling first step toward
harnessing artificial general intelligence for complex transportation
challenges.

ÊëòË¶ÅÔºöÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊé¢Ë®é‰∫ÜÊúÄÂÖàÈÄ≤Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑËÉΩÂäõÔºå‰æãÂ¶Ç GPT-4„ÄÅGPT-4o„ÄÅClaude 3.5 Sonnet„ÄÅClaude 3 Opus„ÄÅGemini 1.5 Pro„ÄÅLlama 3 Âíå Llama 3.1Ôºå‰ª•Ëß£Ê±∫‰∏Ä‰∫õÈÅ∏ÂÆöÁöÑÂ§ßÂ≠∏ÈÉ®Á¥ö‰∫§ÈÄöÂ∑•Á®ãÂïèÈ°å„ÄÇÊàëÂÄëÂºïÂÖ•‰∫Ü TransportBenchÔºåÈÄôÊòØ‰∏ÄÂÄãÂü∫Ê∫ñÊï∏ÊìöÈõÜÔºåÂÖ∂‰∏≠ÂåÖÂê´Âú®Ë¶èÂäÉ„ÄÅË®≠Ë®à„ÄÅÁÆ°ÁêÜÂíå‰∫§ÈÄöÁ≥ªÁµ±ÊéßÂà∂ÁöÑÂª£Ê≥õ‰∏ªÈ°å‰∏≠ÁöÑ‰∏ÄÁ≥ªÂàó‰∫§ÈÄöÂ∑•Á®ãÂïèÈ°åÁØÑ‰æã„ÄÇÊ≠§Êï∏ÊìöÈõÜÁî±‰∫∫È°ûÂ∞àÂÆ∂Áî®ÊñºË©ï‰º∞ÂêÑÁ®ÆÂïÜÊ•≠ÂíåÈñãÊ∫ê LLM ÁöÑËÉΩÂäõÔºåÁâπÂà•ÊòØÂÆÉÂÄëÂú®Ëß£Ê±∫‰∫§ÈÄöÂ∑•Á®ãÂïèÈ°åÊôÇÁöÑÊ∫ñÁ¢∫ÊÄß„ÄÅ‰∏ÄËá¥ÊÄßÂíåÊé®ÁêÜË°åÁÇ∫„ÄÇÊàëÂÄëÁöÑÂÖ®Èù¢ÂàÜÊûêÊè≠Á§∫‰∫ÜÊØèÁ®Æ LLM Áç®ÁâπÁöÑÂÑ™Âã¢ÂíåÈôêÂà∂Ôºå‰æãÂ¶ÇÊàëÂÄëÁöÑÂàÜÊûêÈ°ØÁ§∫‰∫Ü Claude 3.5 Sonnet Âú®Ëß£Ê±∫ TransportBench ÂïèÈ°åÊôÇ‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑÊ∫ñÁ¢∫ÊÄßÂíå‰∏Ä‰∫õÊÑèÂ§ñÁöÑ‰∏ç‰∏ÄËá¥Ë°åÁÇ∫„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂Ê®ôË™åËëóÊúùËëóÂà©Áî®‰∫∫Â∑•ÈÄöÁî®Êô∫ÊÖß‰æÜÊáâÂ∞çË§áÈõúÁöÑ‰∫§ÈÄöÊåëÊà∞ÈÇÅÂá∫ÁöÑ‰ª§‰∫∫ËààÂ•ÆÁöÑÁ¨¨‰∏ÄÊ≠•„ÄÇ

##### **SLCA++: Unleash the Power of Sequential Fine-tuning for Continual Learning with Pre-training**
2408.08295v1 by Gengwei Zhang, Liyuan Wang, Guoliang Kang, Ling Chen, Yunchao Wei

In recent years, continual learning with pre-training (CLPT) has received
widespread interest, instead of its traditional focus of training from scratch.
The use of strong pre-trained models (PTMs) can greatly facilitate knowledge
transfer and alleviate catastrophic forgetting, but also suffers from
progressive overfitting of pre-trained knowledge into specific downstream
tasks. A majority of current efforts often keep the PTMs frozen and incorporate
task-specific prompts to instruct representation learning, coupled with a
prompt selection process for inference. However, due to the limited capacity of
prompt parameters, this strategy demonstrates only sub-optimal performance in
continual learning. In comparison, tuning all parameters of PTMs often provides
the greatest potential for representation learning, making sequential
fine-tuning (Seq FT) a fundamental baseline that has been overlooked in CLPT.
To this end, we present an in-depth analysis of the progressive overfitting
problem from the lens of Seq FT. Considering that the overly fast
representation learning and the biased classification layer constitute this
particular problem, we introduce the advanced Slow Learner with Classifier
Alignment (SLCA++) framework to unleash the power of Seq FT, serving as a
strong baseline approach for CLPT. Our approach involves a Slow Learner to
selectively reduce the learning rate of backbone parameters, and a Classifier
Alignment to align the disjoint classification layers in a post-hoc fashion. We
further enhance the efficacy of SL with a symmetric cross-entropy loss, as well
as employ a parameter-efficient strategy to implement Seq FT with SLCA++.
Across a variety of continual learning scenarios on image classification
benchmarks, our approach provides substantial improvements and outperforms
state-of-the-art methods by a large margin. Code:
https://github.com/GengDavid/SLCA.

ÊëòË¶ÅÔºöËøëÂπ¥‰æÜÔºåÊåÅÁ∫åÂ≠∏ÁøíËàáÈ†êË®ìÁ∑¥ (CLPT) ÂèóÂà∞Âª£Ê≥õÈóúÊ≥®ÔºåÂèñ‰ª£ÂÇ≥Áµ±ÂæûÈ†≠ÈñãÂßãË®ìÁ∑¥ÁöÑÈáçÈªû„ÄÇ‰ΩøÁî®Âº∑Â§ßÁöÑÈ†êË®ìÁ∑¥Ê®°Âûã (PTM) ÂèØ‰ª•Â§ßÂπÖ‰øÉÈÄ≤Áü•Ë≠òËΩâÁßªÔºå‰∏¶Ê∏õËºïÁÅΩÈõ£ÊÄßÈÅ∫ÂøòÔºå‰ΩÜ‰πüÈ£ΩÂèóÁâπÂÆö‰∏ãÊ∏∏‰ªªÂãô‰∏≠È†êË®ìÁ∑¥Áü•Ë≠òÁöÑÊº∏ÈÄ≤ÈÅéÂ∫¶Êì¨ÂêàÊâÄËã¶„ÄÇÁõÆÂâçÂ§ßÂ§öÊï∏ÊñπÊ≥ïÈÄöÂ∏∏‰øùÊåÅ PTM ÂáçÁµêÔºå‰∏¶ÁµêÂêàÁâπÂÆöÊñº‰ªªÂãôÁöÑÊèêÁ§∫Ôºå‰ª•ÊåáÂ∞éË°®ÂæµÂ≠∏ÁøíÔºåÂÜçÊê≠ÈÖçÊèêÁ§∫ÈÅ∏ÂèñÁ®ãÂ∫èÈÄ≤Ë°åÊé®Ë´ñ„ÄÇÁÑ∂ËÄåÔºåÁî±ÊñºÊèêÁ§∫ÂèÉÊï∏ÁöÑÂÆπÈáèÊúâÈôêÔºåÊ≠§Á≠ñÁï•Âú®ÊåÅÁ∫åÂ≠∏Áøí‰∏≠ÂÉÖÂ±ïÁèæÊ¨°‰Ω≥ÊïàËÉΩ„ÄÇÁõ∏ÊØî‰πã‰∏ãÔºåË™øÊï¥ PTM ÁöÑÊâÄÊúâÂèÉÊï∏ÈÄöÂ∏∏ËÉΩÊèê‰æõË°®ÂæµÂ≠∏ÁøíÊúÄÂ§ßÁöÑÊΩõÂäõÔºåËÆìÂæ™Â∫èÊº∏ÈÄ≤ÂæÆË™ø (Seq FT) ÊàêÁÇ∫ CLPT ‰∏≠Ë¢´ÂøΩÁï•ÁöÑÂü∫Êú¨Âü∫Ê∫ñ„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÂæû Seq FT ÁöÑËßíÂ∫¶Ê∑±ÂÖ•ÂàÜÊûêÊº∏ÈÄ≤ÈÅéÂ∫¶Êì¨ÂêàÂïèÈ°å„ÄÇËÄÉÈáèÂà∞ÈÅéÊñºÂø´ÈÄüË°®ÂæµÂ≠∏ÁøíÂíåÂ∏∂ÊúâÂÅèÂ∑ÆÁöÑÂàÜÈ°ûÂ±§ÊßãÊàêÊ≠§ÁâπÂÆöÂïèÈ°åÔºåÊàëÂÄëÊé®Âá∫ÈÄ≤ÈöéÁöÑÊÖ¢Â≠∏ÁøíÂô®ËàáÂàÜÈ°ûÂô®Ê†°Ê∫ñ (SLCA++) Êû∂ÊßãÔºå‰ª•ÁôºÊèÆ Seq FT ÁöÑÂº∑Â§ßÂäüËÉΩÔºå‰ΩúÁÇ∫ CLPT ÁöÑÂº∑Â§ßÂü∫Ê∫ñÊñπÊ≥ï„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÂåÖÊã¨ÊÖ¢Â≠∏ÁøíÂô®Ôºå‰ª•ÈÅ∏ÊìáÊÄßÈôç‰Ωé‰∏ªÂππÂèÉÊï∏ÁöÑÂ≠∏ÁøíÁéáÔºå‰ª•ÂèäÂàÜÈ°ûÂô®Ê†°Ê∫ñÔºå‰ª•‰∫ãÂæåÊñπÂºèÊ†°Ê∫ñ‰∏çÁõ∏‰∫§ÁöÑÂàÜÈ°ûÂ±§„ÄÇÊàëÂÄëÈÄ≤‰∏ÄÊ≠•ÈÄèÈÅéÂ∞çÁ®±‰∫§ÂèâÁÜµÊêçÂ§±Â¢ûÂº∑ SL ÁöÑÊïàËÉΩÔºå‰∏¶Êé°Áî®ÂèÉÊï∏ÊúâÊïàÁéáÁöÑÁ≠ñÁï•Ôºå‰ª• SLCA++ ÂØ¶‰Ωú Seq FT„ÄÇÂú®ÂΩ±ÂÉèÂàÜÈ°ûÂü∫Ê∫ñ‰∏äÁöÑÂêÑÁ®ÆÊåÅÁ∫åÂ≠∏ÁøíÊÉÖÂ¢É‰∏≠ÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÊèê‰æõ‰∫ÜÂ§ßÂπÖÊîπÂñÑÔºå‰∏¶‰ª•Ê•µÂ§ßÂ∑ÆË∑ùË∂ÖË∂äÁèæÊúâÊäÄË°ì„ÄÇÁ®ãÂºèÁ¢ºÔºöhttps://github.com/GengDavid/SLCA„ÄÇ

##### **The ShareLM Collection and Plugin: Contributing Human-Model Chats for the Benefit of the Community**
2408.08291v1 by Shachar Don-Yehiya, Leshem Choshen, Omri Abend

Human-model conversations provide a window into users' real-world scenarios,
behavior, and needs, and thus are a valuable resource for model development and
research. While for-profit companies collect user data through the APIs of
their models, using it internally to improve their own models, the open source
and research community lags behind.
  We introduce the ShareLM collection, a unified set of human conversations
with large language models, and its accompanying plugin, a Web extension for
voluntarily contributing user-model conversations. Where few platforms share
their chats, the ShareLM plugin adds this functionality, thus, allowing users
to share conversations from most platforms. The plugin allows the user to rate
their conversations, both at the conversation and the response levels, and
delete conversations they prefer to keep private before they ever leave the
user's local storage. We release the plugin conversations as part of the
ShareLM collection, and call for more community effort in the field of open
human-model data.
  The code, plugin, and data are available.

ÊëòË¶ÅÔºö‰∫∫È°ûËàáÊ®°ÂûãÁöÑÂ∞çË©±Êèê‰æõ‰∫Ü‰ΩøÁî®ËÄÖÁúüÂØ¶‰∏ñÁïåÊÉÖÂ¢É„ÄÅË°åÁÇ∫ÂíåÈúÄÊ±ÇÁöÑÁ™óÂè£ÔºåÂõ†Ê≠§Â∞çÊñºÊ®°ÂûãÈñãÁôºÂíåÁ†îÁ©∂‰æÜË™™ÔºåÈÄôÊòØ‰∏ÄÂÄãÊúâÂÉπÂÄºÁöÑË≥áÊ∫ê„ÄÇÈõñÁÑ∂ÁáüÂà©ÂÖ¨Âè∏ÈÄèÈÅéÂÖ∂Ê®°ÂûãÁöÑ API ‰æÜÊî∂ÈõÜ‰ΩøÁî®ËÄÖË≥áÊñôÔºå‰∏¶Âú®ÂÖßÈÉ®‰ΩøÁî®ÈÄô‰∫õË≥áÊñô‰æÜÊîπÂñÑÂÖ∂Ëá™Â∑±ÁöÑÊ®°ÂûãÔºå‰ΩÜÈñãÊ∫êÂíåÁ†îÁ©∂Á§æÁæ§ÂçªËêΩÂæå‰∫Ü„ÄÇ
ÊàëÂÄëÊé®Âá∫‰∫Ü ShareLM ËíêÈõÜÔºåÈÄôÊòØ‰∏ÄÁµÑËàáÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÈÄ≤Ë°åÁöÑ‰∫∫È°ûÂ∞çË©±ÁöÑÁµ±‰∏ÄÈõÜÂêàÔºå‰ª•ÂèäÂÖ∂ÈôÑÂ±¨Â§ñÊéõÁ®ãÂºèÔºå‰∏ÄÂÄãÁî®ÊñºËá™È°òË≤¢Áçª‰ΩøÁî®ËÄÖÊ®°ÂûãÂ∞çË©±ÁöÑÁ∂≤Ë∑ØÊì¥ÂÖÖÂäüËÉΩ„ÄÇÂú®Â∞ëÊï∏Âπ≥Âè∞ÂàÜ‰∫´ÂÖ∂Â∞çË©±ÁöÑÊÉÖÊ≥Å‰∏ãÔºåShareLM Â§ñÊéõÁ®ãÂºèÂ¢ûÂä†‰∫ÜÊ≠§ÂäüËÉΩÔºåÂõ†Ê≠§ÂÖÅË®±‰ΩøÁî®ËÄÖÂàÜ‰∫´Â§ßÂ§öÊï∏Âπ≥Âè∞ÁöÑÂ∞çË©±„ÄÇË©≤Â§ñÊéõÁ®ãÂºèÂÖÅË®±‰ΩøÁî®ËÄÖË©ïÂàÜ‰ªñÂÄëÁöÑÂ∞çË©±ÔºåÁÑ°Ë´ñÊòØÂú®Â∞çË©±Â±§Á¥öÊàñÂõûÊáâÂ±§Á¥öÔºå‰∏¶Âú®Â∞çË©±Èõ¢Èñã‰ΩøÁî®ËÄÖÁöÑÊú¨Ê©üÂÑ≤Â≠òÁ©∫Èñì‰πãÂâçÂà™Èô§‰ªñÂÄëÂÅèÂ•Ω‰øùÊåÅÁßÅÂØÜÁöÑÂ∞çË©±„ÄÇÊàëÂÄëÂ∞áÂ§ñÊéõÁ®ãÂºèÂ∞çË©±‰ΩúÁÇ∫ ShareLM ËíêÈõÜÁöÑ‰∏ÄÈÉ®ÂàÜÈáãÂá∫Ôºå‰∏¶ÂëºÁ±≤Âú®ÈñãÊîæ‰∫∫È°ûÊ®°ÂûãË≥áÊñôÈ†òÂüü‰∏≠ÈÄ≤Ë°åÊõ¥Â§öÁ§æÁæ§Âä™Âäõ„ÄÇ
Á®ãÂºèÁ¢º„ÄÅÂ§ñÊéõÁ®ãÂºèÂíåË≥áÊñôÈÉΩÂ∑≤Êèê‰æõ„ÄÇ

##### **Autonomous Behavior Planning For Humanoid Loco-manipulation Through Grounded Language Model**
2408.08282v1 by Jin Wang, Arturo Laurenzi, Nikos Tsagarakis

Enabling humanoid robots to perform autonomously loco-manipulation in
unstructured environments is crucial and highly challenging for achieving
embodied intelligence. This involves robots being able to plan their actions
and behaviors in long-horizon tasks while using multi-modality to perceive
deviations between task execution and high-level planning. Recently, large
language models (LLMs) have demonstrated powerful planning and reasoning
capabilities for comprehension and processing of semantic information through
robot control tasks, as well as the usability of analytical judgment and
decision-making for multi-modal inputs. To leverage the power of LLMs towards
humanoid loco-manipulation, we propose a novel language-model based framework
that enables robots to autonomously plan behaviors and low-level execution
under given textual instructions, while observing and correcting failures that
may occur during task execution. To systematically evaluate this framework in
grounding LLMs, we created the robot 'action' and 'sensing' behavior library
for task planning, and conducted mobile manipulation tasks and experiments in
both simulated and real environments using the CENTAURO robot, and verified the
effectiveness and application of this approach in robotic tasks with autonomous
behavioral planning.

ÊëòË¶ÅÔºöËÆìÈ°û‰∫∫Ê©üÂô®‰∫∫Âú®ÈùûÁµêÊßãÂåñÁí∞Â¢É‰∏≠Âü∑Ë°åËá™‰∏ªÈÅãÂãïÊìçÁ∏±Â∞çÊñºÂØ¶ÁèæÂÖ∑Ë∫´Êô∫ËÉΩËá≥ÈóúÈáçË¶Å‰∏îÊ•µÂÖ∑ÊåëÊà∞ÊÄß„ÄÇÈÄôÊ∂âÂèäÊ©üÂô®‰∫∫Âú®Âü∑Ë°åÂ§öË¶ñËßí‰ªªÂãôÊôÇËÉΩÂ§†Ë¶èÂäÉÂÖ∂Âãï‰ΩúÂíåË°åÁÇ∫ÔºåÂêåÊôÇ‰ΩøÁî®Â§öÊ®°ÊÖã‰æÜÊÑüÁü•‰ªªÂãôÂü∑Ë°åÂíåÈ´òÂ±§Á¥öË¶èÂäÉ‰πãÈñìÁöÑÂÅèÂ∑Æ„ÄÇÊúÄËøëÔºåÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤Â±ïÁ§∫Âá∫Âº∑Â§ßÁöÑË¶èÂäÉÂíåÊé®ÁêÜËÉΩÂäõÔºåÂèØÁî®ÊñºÁêÜËß£ÂíåËôïÁêÜË™ûÁæ©‰ø°ÊÅØÔºåÈÄöÈÅéÊ©üÂô®‰∫∫ÊéßÂà∂‰ªªÂãôÔºå‰ª•ÂèäÂàÜÊûêÂà§Êñ∑ÂíåÊ±∫Á≠ñÂà∂ÂÆöÂ∞çÂ§öÊ®°ÊÖãËº∏ÂÖ•ÁöÑÂèØÁî®ÊÄß„ÄÇÁÇ∫‰∫ÜÂ∞á LLM ÁöÑËÉΩÂäõÈÅãÁî®ÊñºÈ°û‰∫∫ÈÅãÂãïÊìçÁ∏±ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂü∫ÊñºË™ûË®ÄÊ®°ÂûãÁöÑÊñ∞Ê°ÜÊû∂ÔºåË©≤Ê°ÜÊû∂‰ΩøÊ©üÂô®‰∫∫ËÉΩÂ§†Âú®Áµ¶ÂÆöÁöÑÊñáÊú¨Êåá‰ª§‰∏ãËá™‰∏ªË¶èÂäÉË°åÁÇ∫Âíå‰ΩéÂ±§Á¥öÂü∑Ë°åÔºåÂêåÊôÇËßÄÂØüÂíåÁ≥æÊ≠£‰ªªÂãôÂü∑Ë°åÊúüÈñìÂèØËÉΩÁôºÁîüÁöÑÊïÖÈöú„ÄÇÁÇ∫‰∫ÜÁ≥ªÁµ±Âú∞Ë©ï‰º∞ÈÄôÂÄãÂú® LLM ‰∏≠ÁöÑÊ°ÜÊû∂ÔºåÊàëÂÄëÂâµÂª∫‰∫ÜÊ©üÂô®‰∫∫„ÄåÂãï‰Ωú„ÄçÂíå„ÄåÊÑüÊ∏¨„ÄçË°åÁÇ∫Â∫´Áî®Êñº‰ªªÂãôË¶èÂäÉÔºå‰∏¶‰ΩøÁî® CENTAURO Ê©üÂô®‰∫∫Âú®Ê®°Êì¨ÂíåÁúüÂØ¶Áí∞Â¢É‰∏≠ÈÄ≤Ë°å‰∫ÜÁßªÂãïÊìç‰Ωú‰ªªÂãôÂíåÂØ¶È©óÔºå‰∏¶È©óË≠â‰∫ÜÈÄôÁ®ÆÊñπÊ≥ïÂú®ÂÖ∑ÊúâËá™‰∏ªË°åÁÇ∫Ë¶èÂäÉÁöÑÊ©üÂô®‰∫∫‰ªªÂãô‰∏≠ÁöÑÊúâÊïàÊÄßÂíåÊáâÁî®„ÄÇ

##### **InVAErt networks for amortized inference and identifiability analysis of lumped parameter hemodynamic models**
2408.08264v1 by Guoxiang Grayson Tong, Carlos A. Sing Long, Daniele E. Schiavazzi

Estimation of cardiovascular model parameters from electronic health records
(EHR) poses a significant challenge primarily due to lack of identifiability.
Structural non-identifiability arises when a manifold in the space of
parameters is mapped to a common output, while practical non-identifiability
can result due to limited data, model misspecification, or noise corruption. To
address the resulting ill-posed inverse problem, optimization-based or Bayesian
inference approaches typically use regularization, thereby limiting the
possibility of discovering multiple solutions. In this study, we use inVAErt
networks, a neural network-based, data-driven framework for enhanced digital
twin analysis of stiff dynamical systems. We demonstrate the flexibility and
effectiveness of inVAErt networks in the context of physiological inversion of
a six-compartment lumped parameter hemodynamic model from synthetic data to
real data with missing components.

ÊëòË¶ÅÔºöÂæûÈõªÂ≠êÂÅ•Â∫∑Á¥ÄÈåÑ (EHR) ‰º∞Ë®àÂøÉË°ÄÁÆ°Ê®°ÂûãÂèÉÊï∏‰∏ªË¶ÅÁî±ÊñºÁº∫‰πèÂèØË≠òÂà•ÊÄßËÄåÊßãÊàêÈáçÂ§ßÊåëÊà∞„ÄÇ
Áï∂ÂèÉÊï∏Á©∫Èñì‰∏≠ÁöÑÊµÅÂΩ¢Â∞çÊáâÂà∞ÂÖ±ÂêåËº∏Âá∫ÊôÇÔºåÊúÉÁî¢ÁîüÁµêÊßãÊÄß‰∏çÂèØË≠òÂà•ÊÄßÔºåËÄåÁî±ÊñºË≥áÊñôÊúâÈôê„ÄÅÊ®°ÂûãÈåØË™§Ë¶èÁØÑÊàñÈõúË®äÁ†¥Â£ûÔºåÂèØËÉΩÊúÉÂ∞éËá¥ÂØ¶Èöõ‰∏çÂèØË≠òÂà•ÊÄß„ÄÇÁÇ∫‰∫ÜËß£Ê±∫Áî±Ê≠§Áî¢ÁîüÁöÑ‰∏çÈÅ©ÂÆöÂèçÂïèÈ°åÔºåÂü∫ÊñºÊúÄ‰Ω≥ÂåñÁöÑË≤ùÊ∞èÊé®Ë´ñÊñπÊ≥ïÈÄöÂ∏∏‰ΩøÁî®Ê≠£ÂâáÂåñÔºåÂæûËÄåÈôêÂà∂ÁôºÁèæÂ§öÈáçËß£ÁöÑÂèØËÉΩÊÄß„ÄÇÂú®Êú¨Á†îÁ©∂‰∏≠ÔºåÊàëÂÄë‰ΩøÁî® inVAErt Á∂≤Ë∑ØÔºåÈÄôÊòØ‰∏ÄÁ®ÆÂü∫ÊñºÁ•ûÁ∂ìÁ∂≤Ë∑Ø„ÄÅË≥áÊñôÈ©ÖÂãïÁöÑÊû∂ÊßãÔºåÁî®ÊñºÂ¢ûÂº∑ÂÉµÁ°¨ÂãïÊÖãÁ≥ªÁµ±ÁöÑÊï∏‰ΩçÈõôËÉûËÉéÂàÜÊûê„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫Ü inVAErt Á∂≤Ë∑ØÂú®ÁîüÁêÜÂèçÊºî‰∏≠ÁöÑÈùàÊ¥ªÊÄßËàáÊúâÊïàÊÄßÔºåÂæûÂêàÊàêË≥áÊñôÂà∞Áº∫Â∞ëÁµÑÊàêÁöÑÁúüÂØ¶Ë≥áÊñôÔºåÂèçÊºîÂÖ≠ÈöîÈñìÈõÜÁ∏ΩÂèÉÊï∏Ë°ÄÊµÅÂãïÂäõÊ®°Âûã„ÄÇ

##### **mhGPT: A Lightweight Generative Pre-Trained Transformer for Mental Health Text Analysis**
2408.08261v1 by Dae-young Kim, Rebecca Hwa, Muhammad Mahbubur Rahman

This paper introduces mhGPT, a lightweight generative pre-trained transformer
trained on mental health-related social media and PubMed articles. Fine-tuned
for specific mental health tasks, mhGPT was evaluated under limited hardware
constraints and compared with state-of-the-art models like MentaLLaMA and
Gemma. Despite having only 1.98 billion parameters and using just 5% of the
dataset, mhGPT outperformed larger models and matched the performance of models
trained on significantly more data. The key contributions include integrating
diverse mental health data, creating a custom tokenizer, and optimizing a
smaller architecture for low-resource settings. This research could advance
AI-driven mental health care, especially in areas with limited computing power.

ÊëòË¶ÅÔºöÊú¨Êñá‰ªãÁ¥π mhGPTÔºå‰∏ÄÁ®ÆËºïÈáèÁ¥öÁöÑÁîüÊàêÂºèÈ†êË®ìÁ∑¥ËΩâÊèõÂô®ÔºåÁ∂ìÈÅéÈáùÂ∞çÂøÉÁêÜÂÅ•Â∫∑Áõ∏ÈóúÁ§æÁæ§Â™íÈ´îÂíå PubMed ÊñáÁ´†ÁöÑË®ìÁ∑¥„ÄÇÈáùÂ∞çÁâπÂÆöÂøÉÁêÜÂÅ•Â∫∑‰ªªÂãôÈÄ≤Ë°åÂæÆË™øÂæåÔºåmhGPT Âú®ÊúâÈôêÁöÑÁ°¨È´îÈôêÂà∂‰∏ãÈÄ≤Ë°åË©ï‰º∞Ôºå‰∏¶Ëàá MentaLLaMA Âíå Gemma Á≠âÊúÄÂÖàÈÄ≤ÁöÑÊ®°ÂûãÈÄ≤Ë°åÊØîËºÉ„ÄÇÂÑòÁÆ°Âè™Êúâ 19.8 ÂÑÑÂÄãÂèÉÊï∏Ôºå‰∏¶‰∏îÂÉÖ‰ΩøÁî® 5% ÁöÑË≥áÊñôÈõÜÔºåmhGPT ÁöÑË°®ÁèæÂÑ™ÊñºËºÉÂ§ßÁöÑÊ®°ÂûãÔºå‰∏¶‰∏îËàáÂú®Êõ¥Â§öË≥áÊñô‰∏äË®ìÁ∑¥ÁöÑÊ®°ÂûãÁöÑË°®ÁèæÁõ∏ÂåπÈÖç„ÄÇ‰∏ªË¶ÅË≤¢ÁçªÂåÖÊã¨Êï¥ÂêàÂ§öÊ®£ÁöÑÂøÉÁêÜÂÅ•Â∫∑Ë≥áÊñô„ÄÅÂª∫Á´ãËá™Ë®ÇÁöÑÊ®ôË®òÂô®Ôºå‰ª•ÂèäÈáùÂ∞ç‰ΩéË≥áÊ∫êË®≠ÂÆöÊúÄ‰Ω≥ÂåñËºÉÂ∞èÁöÑÊû∂Êßã„ÄÇÈÄôÈ†ÖÁ†îÁ©∂ÂèØ‰ª•Êé®ÈÄ≤‰∫∫Â∑•Êô∫ÊÖßÈ©ÖÂãïÁöÑÂøÉÁêÜ‰øùÂÅ•ÔºåÁâπÂà•ÊòØÂú®ÈÅãÁÆóËÉΩÂäõÊúâÈôêÁöÑÂú∞ÂçÄ„ÄÇ

##### **Derivative-Free Guidance in Continuous and Discrete Diffusion Models with Soft Value-Based Decoding**
2408.08252v1 by Xiner Li, Yulai Zhao, Chenyu Wang, Gabriele Scalia, Gokcen Eraslan, Surag Nair, Tommaso Biancalani, Aviv Regev, Sergey Levine, Masatoshi Uehara

Diffusion models excel at capturing the natural design spaces of images,
molecules, DNA, RNA, and protein sequences. However, rather than merely
generating designs that are natural, we often aim to optimize downstream reward
functions while preserving the naturalness of these design spaces. Existing
methods for achieving this goal often require ``differentiable'' proxy models
(\textit{e.g.}, classifier guidance or DPS) or involve computationally
expensive fine-tuning of diffusion models (\textit{e.g.}, classifier-free
guidance, RL-based fine-tuning). In our work, we propose a new method to
address these challenges. Our algorithm is an iterative sampling method that
integrates soft value functions, which looks ahead to how intermediate noisy
states lead to high rewards in the future, into the standard inference
procedure of pre-trained diffusion models. Notably, our approach avoids
fine-tuning generative models and eliminates the need to construct
differentiable models. This enables us to (1) directly utilize
non-differentiable features/reward feedback, commonly used in many scientific
domains, and (2) apply our method to recent discrete diffusion models in a
principled way. Finally, we demonstrate the effectiveness of our algorithm
across several domains, including image generation, molecule generation, and
DNA/RNA sequence generation. The code is available at
\href{https://github.com/masa-ue/SVDD}{https://github.com/masa-ue/SVDD}.

ÊëòË¶ÅÔºöÊì¥Êï£Ê®°ÂûãÊìÖÈï∑ÊçïÊçâÂΩ±ÂÉè„ÄÅÂàÜÂ≠ê„ÄÅDNA„ÄÅRNA ÂíåËõãÁôΩË≥™Â∫èÂàóÁöÑËá™ÁÑ∂Ë®≠Ë®àÁ©∫Èñì„ÄÇÁÑ∂ËÄåÔºåÊàëÂÄëÈÄöÂ∏∏‰∏çÂè™ÊòØÁî¢ÁîüËá™ÁÑ∂ÁöÑË®≠Ë®àÔºåËÄåÊòØÂ∏åÊúõÂú®‰øùÁïôÈÄô‰∫õË®≠Ë®àÁ©∫ÈñìÁöÑËá™ÁÑ∂ÊÄßÁöÑÂêåÊôÇÔºåÊúÄ‰Ω≥Âåñ‰∏ãÊ∏∏ÁçéÂãµÂáΩÊï∏„ÄÇÁèæÊúâÁöÑÈÅîÊàêÊ≠§ÁõÆÊ®ôÁöÑÊñπÊ≥ïÈÄöÂ∏∏ÈúÄË¶Å„ÄåÂèØÂæÆÂàÜ„ÄçÁöÑ‰ª£ÁêÜÊ®°ÂûãÔºà‰æãÂ¶ÇÂàÜÈ°ûÂô®ÂºïÂ∞éÊàñ DPSÔºâÊàñÊ∂âÂèäË®àÁÆóÊàêÊú¨È´òÁöÑÊì¥Êï£Ê®°ÂûãÂæÆË™øÔºà‰æãÂ¶ÇÁÑ°ÂàÜÈ°ûÂô®ÂºïÂ∞é„ÄÅÂü∫Êñº RL ÁöÑÂæÆË™øÔºâ„ÄÇÂú®ÊàëÂÄëÁöÑÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞ÁöÑÊñπÊ≥ï‰æÜËß£Ê±∫ÈÄô‰∫õÊåëÊà∞„ÄÇÊàëÂÄëÁöÑÊºîÁÆóÊ≥ïÊòØ‰∏ÄÁ®ÆÂèçË¶ÜÂèñÊ®£ÊñπÊ≥ïÔºåÂÆÉÂ∞áËªüÂÄºÂáΩÊï∏Êï¥ÂêàÂà∞Ê®ôÊ∫ñÈ†êË®ìÁ∑¥Êì¥Êï£Ê®°ÂûãÁöÑÊé®Ë´ñÁ®ãÂ∫è‰∏≠ÔºåË©≤ÂáΩÊï∏È†êÊ∏¨‰∏≠ÈñìÈõúË®äÁãÄÊÖãÂ∞áÂ¶Ç‰ΩïÂ∞éËá¥Êú™‰æÜÁöÑÈ´òÁçéÂãµ„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÊàëÂÄëÁöÑÊñπÊ≥ïÈÅøÂÖç‰∫ÜÁîüÊàêÊ®°ÂûãÁöÑÂæÆË™øÔºå‰∏¶Ê∂àÈô§‰∫ÜÊßãÂª∫ÂèØÂæÆÂàÜÊ®°ÂûãÁöÑÈúÄË¶Å„ÄÇÈÄô‰ΩøÊàëÂÄëËÉΩÂ§† (1) Áõ¥Êé•Âà©Áî®Âú®Ë®±Â§öÁßëÂ≠∏È†òÂüü‰∏≠Â∏∏Áî®ÁöÑ‰∏çÂèØÂæÆÂàÜÁâπÂæµ/ÁçéÂãµÂõûÈ•ãÔºå‰ª•Âèä (2) ‰ª•ÊúâÂéüÂâáÁöÑÊñπÂºèÂ∞áÊàëÂÄëÁöÑÊ®°ÂûãÊáâÁî®ÊñºÊúÄËøëÁöÑÈõ¢Êï£Êì¥Êï£Ê®°Âûã„ÄÇÊúÄÂæåÔºåÊàëÂÄëÂú®ÂπæÂÄãÈ†òÂüüÂ±ïÁ§∫‰∫ÜÊàëÂÄëÊºîÁÆóÊ≥ïÁöÑÊúâÊïàÊÄßÔºåÂåÖÊã¨ÂΩ±ÂÉèÁîüÊàê„ÄÅÂàÜÂ≠êÁîüÊàê‰ª•Âèä DNA/RNA Â∫èÂàóÁîüÊàê„ÄÇÁ®ãÂºèÁ¢ºÂèØÂú®‰ª•‰∏ãÁ∂≤ÂùÄÂèñÂæóÔºö\href{https://github.com/masa-ue/SVDD}{https://github.com/masa-ue/SVDD}„ÄÇ

##### **A Conflicts-free, Speed-lossless KAN-based Reinforcement Learning Decision System for Interactive Driving in Roundabouts**
2408.08242v1 by Zhihao Lin, Zhen Tian, Qi Zhang, Ziyang Ye, Hanyang Zhuang, Jianglin Lan

Safety and efficiency are crucial for autonomous driving in roundabouts,
especially in the context of mixed traffic where autonomous vehicles (AVs) and
human-driven vehicles coexist. This paper introduces a learning-based algorithm
tailored to foster safe and efficient driving behaviors across varying levels
of traffic flows in roundabouts. The proposed algorithm employs a deep
Q-learning network to effectively learn safe and efficient driving strategies
in complex multi-vehicle roundabouts. Additionally, a KAN (Kolmogorov-Arnold
network) enhances the AVs' ability to learn their surroundings robustly and
precisely. An action inspector is integrated to replace dangerous actions to
avoid collisions when the AV interacts with the environment, and a route
planner is proposed to enhance the driving efficiency and safety of the AVs.
Moreover, a model predictive control is adopted to ensure stability and
precision of the driving actions. The results show that our proposed system
consistently achieves safe and efficient driving whilst maintaining a stable
training process, as evidenced by the smooth convergence of the reward function
and the low variance in the training curves across various traffic flows.
Compared to state-of-the-art benchmarks, the proposed algorithm achieves a
lower number of collisions and reduced travel time to destination.

ÊëòË¶ÅÔºöÂú®Áí∞Â≥∂‰∏≠ÔºåÂÆâÂÖ®ÊÄßÂíåÊïàÁéáÂ∞çÊñºËá™ÂãïÈßïÈßõËá≥ÈóúÈáçË¶ÅÔºåÁâπÂà•ÊòØÂú®Ëá™ÂãïÈßïÈßõÊ±ΩËªä (AV) Âíå‰∫∫È°ûÈßïÈßõÊ±ΩËªä‰∏¶Â≠òÁöÑÊ∑∑Âêà‰∫§ÈÄöÁí∞Â¢É‰∏≠„ÄÇÊú¨Êñá‰ªãÁ¥π‰∫Ü‰∏ÄÁ®ÆÂü∫ÊñºÂ≠∏ÁøíÁöÑÊºîÁÆóÊ≥ïÔºåÂ∞àÈñÄÁî®Êñº‰øÉÈÄ≤Âú®Áí∞Â≥∂‰∏≠‰∏çÂêå‰∫§ÈÄöÊµÅÈáèÁ≠âÁ¥öÁöÑÂÆâÂÖ®‰∏îÊúâÊïàÁöÑÈßïÈßõË°åÁÇ∫„ÄÇÊâÄÊèêÂá∫ÁöÑÊºîÁÆóÊ≥ïÊé°Áî®Ê∑±Â∫¶ Q Â≠∏ÁøíÁ∂≤Ë∑ØÔºåÂèØÂú®Ë§áÈõúÁöÑÂ§öËªäËºõÁí∞Â≥∂‰∏≠ÊúâÊïàÂ≠∏ÁøíÂÆâÂÖ®‰∏îÊúâÊïàÁöÑÈßïÈßõÁ≠ñÁï•„ÄÇÊ≠§Â§ñÔºåKANÔºàÊüØÁàæËé´Âì•Ê¥õÂ§´-ÈòøË´æÂæ∑Á∂≤Ë∑ØÔºâÂ¢ûÂº∑‰∫ÜËá™ÂãïÈßïÈßõÊ±ΩËªäÂú®Áí∞Â¢É‰∏≠Á©©ÂÅ•‰∏îÁ≤æÁ¢∫Â≠∏ÁøíÁöÑËÉΩÂäõ„ÄÇÊï¥Âêà‰∫ÜÂãï‰ΩúÊ™¢Êü•Âô®ÔºåÂèØÂú®Ëá™ÂãïÈßïÈßõÊ±ΩËªäËàáÁí∞Â¢É‰∫íÂãïÊôÇÂèñ‰ª£Âç±Èö™Âãï‰ΩúÔºåÈÅøÂÖçÁ¢∞ÊíûÔºå‰∏¶ÊèêÂá∫‰∫ÜË∑ØÁ∑öË¶èÂäÉÂô®Ôºå‰ª•Â¢ûÂº∑Ëá™ÂãïÈßïÈßõÊ±ΩËªäÁöÑÈßïÈßõÊïàÁéáÂíåÂÆâÂÖ®ÊÄß„ÄÇÊ≠§Â§ñÔºåÊé°Áî®‰∫ÜÊ®°ÂûãÈ†êÊ∏¨ÊéßÂà∂Ôºå‰ª•Á¢∫‰øùÈßïÈßõÂãï‰ΩúÁöÑÁ©©ÂÆöÊÄßÂíåÁ≤æÁ¢∫ÊÄß„ÄÇÁµêÊûúË°®ÊòéÔºåÊàëÂÄëÊèêÂá∫ÁöÑÁ≥ªÁµ±ÂßãÁµÇËÉΩÂØ¶ÁèæÂÆâÂÖ®‰∏îÊúâÊïàÁöÑÈßïÈßõÔºåÂêåÊôÇ‰øùÊåÅÁ©©ÂÆöÁöÑË®ìÁ∑¥ÈÅéÁ®ãÔºåÈÄôÂæûÂõûÂ†±ÂáΩÊï∏ÁöÑÂπ≥Á©©Êî∂ÊñÇÂíåË®ìÁ∑¥Êõ≤Á∑öÂú®ÂêÑÁ®Æ‰∫§ÈÄöÊµÅÈáè‰∏≠ÁöÑ‰ΩéËÆäÁï∞‰∏≠ÂèØ‰ª•ÂæóÂà∞Ë≠âÊòé„ÄÇËàáÊúÄÂÖàÈÄ≤ÁöÑÂü∫Ê∫ñÁõ∏ÊØîÔºåÊâÄÊèêÂá∫ÁöÑÊºîÁÆóÊ≥ïÂèØÊ∏õÂ∞ëÁ¢∞ÊíûÊ¨°Êï∏‰∏¶Á∏ÆÁü≠Âà∞ÈÅîÁõÆÁöÑÂú∞ÁöÑË°åÁ®ãÊôÇÈñì„ÄÇ

##### **Predictive Multiplicity of Knowledge Graph Embeddings in Link Prediction**
2408.08226v1 by Yuqicheng Zhu, Nico Potyka, Mojtaba Nayyeri, Bo Xiong, Yunjie He, Evgeny Kharlamov, Steffen Staab

Knowledge graph embedding (KGE) models are often used to predict missing
links for knowledge graphs (KGs). However, multiple KG embeddings can perform
almost equally well for link prediction yet suggest conflicting predictions for
certain queries, termed \textit{predictive multiplicity} in literature. This
behavior poses substantial risks for KGE-based applications in high-stake
domains but has been overlooked in KGE research. In this paper, we define
predictive multiplicity in link prediction. We introduce evaluation metrics and
measure predictive multiplicity for representative KGE methods on commonly used
benchmark datasets. Our empirical study reveals significant predictive
multiplicity in link prediction, with $8\%$ to $39\%$ testing queries
exhibiting conflicting predictions. To address this issue, we propose
leveraging voting methods from social choice theory, significantly mitigating
conflicts by $66\%$ to $78\%$ according to our experiments.

ÊëòË¶ÅÔºöÁü•Ë≠òÂúñË≠úÂµåÂÖ• (KGE) Ê®°ÂûãÈÄöÂ∏∏Áî®ÊñºÈ†êÊ∏¨Áü•Ë≠òÂúñË≠ú (KG) ÁöÑÈÅ∫Â§±ÈÄ£Áµê„ÄÇÁÑ∂ËÄåÔºåÂ§öÂÄã KG ÂµåÂÖ•Âú®ÈÄ£ÁµêÈ†êÊ∏¨‰∏äÂèØ‰ª•ÊúâËøë‰πéÁõ∏ÂêåÁöÑË°®ÁèæÔºåÂçªÂ∞çÊüê‰∫õÊü•Ë©¢ÊèêÂá∫‰∫íÁõ∏ÁüõÁõæÁöÑÈ†êÊ∏¨ÔºåÈÄôÂú®ÊñáÁçª‰∏≠Á®±ÁÇ∫„ÄåÈ†êÊ∏¨Â§öÊ®£ÊÄß„Äç„ÄÇÊ≠§Ë°åÁÇ∫Â∞çÈ´òÈ¢®Èö™È†òÂüü‰∏≠‰ª• KGE ÁÇ∫Âü∫Á§éÁöÑÊáâÁî®Á®ãÂºèÊßãÊàêÈáçÂ§ßÈ¢®Èö™Ôºå‰ΩÜÂú® KGE Á†îÁ©∂‰∏≠ÂçªË¢´ÂøΩÁï•„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂÆöÁæ©‰∫ÜÈÄ£ÁµêÈ†êÊ∏¨‰∏≠ÁöÑÈ†êÊ∏¨Â§öÊ®£ÊÄß„ÄÇÊàëÂÄëÂºïÈÄ≤Ë©ï‰º∞ÊåáÊ®ôÔºå‰∏¶ÈáùÂ∞çÂ∏∏Áî®Âü∫Ê∫ñË≥áÊñôÈõÜÔºåÈáùÂ∞çÂÖ∑‰ª£Ë°®ÊÄßÁöÑ KGE ÊñπÊ≥ïÊ∏¨ÈáèÈ†êÊ∏¨Â§öÊ®£ÊÄß„ÄÇÊàëÂÄëÁöÑÂØ¶Ë≠âÁ†îÁ©∂Êè≠Èú≤‰∫ÜÈÄ£ÁµêÈ†êÊ∏¨‰∏≠È°ØËëóÁöÑÈ†êÊ∏¨Â§öÊ®£ÊÄßÔºåÂÖ∂‰∏≠ 8% Ëá≥ 39% ÁöÑÊ∏¨Ë©¶Êü•Ë©¢Â±ïÁèæÂá∫‰∫íÁõ∏ÁüõÁõæÁöÑÈ†êÊ∏¨„ÄÇÁÇ∫‰∫ÜËß£Ê±∫Ê≠§ÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫Âà©Áî®Á§æÊúÉÈÅ∏ÊìáÁêÜË´ñ‰∏≠ÁöÑÊäïÁ•®ÊñπÊ≥ïÔºåÊ†πÊìöÊàëÂÄëÁöÑÂØ¶È©óÔºåÂ§ßÂπÖÈôç‰Ωé‰∫Ü 66% Ëá≥ 78% ÁöÑË°ùÁ™Å„ÄÇ

##### **The Dawn of KAN in Image-to-Image (I2I) Translation: Integrating Kolmogorov-Arnold Networks with GANs for Unpaired I2I Translation**
2408.08216v1 by Arpan Mahara, Naphtali D. Rishe, Liangdong Deng

Image-to-Image translation in Generative Artificial Intelligence (Generative
AI) has been a central focus of research, with applications spanning
healthcare, remote sensing, physics, chemistry, photography, and more. Among
the numerous methodologies, Generative Adversarial Networks (GANs) with
contrastive learning have been particularly successful. This study aims to
demonstrate that the Kolmogorov-Arnold Network (KAN) can effectively replace
the Multi-layer Perceptron (MLP) method in generative AI, particularly in the
subdomain of image-to-image translation, to achieve better generative quality.
Our novel approach replaces the two-layer MLP with a two-layer KAN in the
existing Contrastive Unpaired Image-to-Image Translation (CUT) model,
developing the KAN-CUT model. This substitution favors the generation of more
informative features in low-dimensional vector representations, which
contrastive learning can utilize more effectively to produce high-quality
images in the target domain. Extensive experiments, detailed in the results
section, demonstrate the applicability of KAN in conjunction with contrastive
learning and GANs in Generative AI, particularly for image-to-image
translation. This work suggests that KAN could be a valuable component in the
broader generative AI domain.

ÊëòË¶ÅÔºöÁîüÊàêÂºè‰∫∫Â∑•Êô∫ËÉΩ (ÁîüÊàêÂºè AI) ‰∏≠ÁöÑÂõæÂÉèÂà∞ÂõæÂÉèËΩ¨Êç¢‰∏ÄÁõ¥ÊòØÁ†îÁ©∂ÁöÑÈáçÁÇπÔºåÂÖ∂Â∫îÁî®Ê∂µÁõñÂåªÁñó‰øùÂÅ•„ÄÅÈÅ•ÊÑü„ÄÅÁâ©ÁêÜ„ÄÅÂåñÂ≠¶„ÄÅÊëÑÂΩ±Á≠âÈ¢ÜÂüü„ÄÇÂú®‰ºóÂ§öÊñπÊ≥ï‰∏≠ÔºåÂÖ∑ÊúâÂØπÊØîÂ≠¶‰π†ÁöÑÁîüÊàêÂØπÊäóÁΩëÁªú (GAN) ÁâπÂà´ÊàêÂäü„ÄÇÊú¨Á†îÁ©∂Êó®Âú®ËØÅÊòé Kolmogorov-Arnold ÁΩëÁªú (KAN) ÂèØ‰ª•ÊúâÊïàÂèñ‰ª£ÁîüÊàêÂºè AI ‰∏≠ÁöÑÂ§öÂ±ÇÊÑüÁü•Âô® (MLP) ÊñπÊ≥ïÔºåÁâπÂà´ÊòØÂú®ÂõæÂÉèÂà∞ÂõæÂÉèËΩ¨Êç¢ÁöÑÂ≠êÈ¢ÜÂüü‰∏≠Ôºå‰ª•ÂÆûÁé∞Êõ¥Â•ΩÁöÑÁîüÊàêË¥®Èáè„ÄÇÊàë‰ª¨ÁöÑÊñ∞ÊñπÊ≥ïÁî®‰∏§Â±Ç KAN ÊõøÊç¢Áé∞ÊúâÂØπÊØîÊó†ÈÖçÂØπÂõæÂÉèÂà∞ÂõæÂÉèËΩ¨Êç¢ (CUT) Ê®°Âûã‰∏≠ÁöÑ‰∏§Â±Ç MLPÔºåÂºÄÂèëÂá∫ KAN-CUT Ê®°Âûã„ÄÇËøôÁßçÊõøÊç¢ÊúâÂà©‰∫éÂú®‰ΩéÁª¥ÂêëÈáèË°®Á§∫‰∏≠ÁîüÊàêÊõ¥Â§ö‰ø°ÊÅØÁâπÂæÅÔºåÂØπÊØîÂ≠¶‰π†ÂèØ‰ª•Êõ¥ÊúâÊïàÂú∞Âà©Áî®Ëøô‰∫õÁâπÂæÅÔºå‰ªéËÄåÂú®ÁõÆÊ†áÂüü‰∏≠ÁîüÊàêÈ´òË¥®ÈáèÂõæÂÉè„ÄÇÁªìÊûúÈÉ®ÂàÜ‰∏≠ËØ¶ÁªÜ‰ªãÁªçÁöÑÂπøÊ≥õÂÆûÈ™åË°®Êòé‰∫Ü KAN ‰∏éÂØπÊØîÂ≠¶‰π†Âíå GAN Âú®ÁîüÊàêÂºè AI ‰∏≠ÁªìÂêà‰ΩøÁî®ÁöÑÈÄÇÁî®ÊÄßÔºåÁâπÂà´ÊòØÂØπ‰∫éÂõæÂÉèÂà∞ÂõæÂÉèËΩ¨Êç¢„ÄÇËøôÈ°πÂ∑•‰ΩúË°®ÊòéÔºåKAN ÂèØËÉΩÊòØÊõ¥ÂπøÊ≥õÁöÑÁîüÊàêÂºè AI È¢ÜÂüü‰∏≠ÁöÑ‰∏Ä‰∏™Êúâ‰ª∑ÂÄºÁöÑÁªÑÊàêÈÉ®ÂàÜ„ÄÇ

##### **Moving Healthcare AI-Support Systems for Visually Detectable Diseases onto Constrained Devices**
2408.08215v1 by Tess Watt, Christos Chrysoulas, Peter J Barclay

Image classification usually requires connectivity and access to the cloud
which is often limited in many parts of the world, including hard to reach
rural areas. TinyML aims to solve this problem by hosting AI assistants on
constrained devices, eliminating connectivity issues by processing data within
the device itself, without internet or cloud access. This pilot study explores
the use of tinyML to provide healthcare support with low spec devices in low
connectivity environments, focusing on diagnosis of skin diseases and the
ethical use of AI assistants in a healthcare setting. To investigate this,
10,000 images of skin lesions were used to train a model for classifying
visually detectable diseases (VDDs). The model weights were then offloaded to a
Raspberry Pi with a webcam attached, to be used for the classification of skin
lesions without internet access. It was found that the developed prototype
achieved a test accuracy of 78% and a test loss of 1.08.

ÊëòË¶ÅÔºöÂΩ±ÂÉèÂàÜÈ°ûÈÄöÂ∏∏ÈúÄË¶ÅÈÄ£Á∑öÂíåÂ≠òÂèñÈõ≤Á´ØÔºåËÄåÈÄôÂú®‰∏ñÁïåË®±Â§öÂú∞ÂçÄÔºåÂåÖÊã¨Èõ£‰ª•ÊäµÈÅîÁöÑÈÑâÊùëÂú∞ÂçÄÔºåÈÄöÂ∏∏ÂèóÂà∞ÈôêÂà∂„ÄÇTinyML Êó®Âú®ÈÄèÈÅéÂú®ÂèóÈôêË£ùÁΩÆ‰∏äÊû∂Ë®≠ AI Âä©ÁêÜÔºåÂú®Ë£ùÁΩÆÂÖßËôïÁêÜË≥áÊñôÔºåÁÑ°ÈúÄÁ∂≤Ë∑ØÊàñÈõ≤Á´ØÂ≠òÂèñÔºå‰æÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°å„ÄÇÈÄôÈ†ÖË©¶È©óÁ†îÁ©∂Êé¢Ë®é‰ΩøÁî® TinyML Âú®ÈÄ£Á∑ö‰∏çËâØÁöÑÁí∞Â¢É‰∏≠Êèê‰æõ‰ΩéË¶èÊ†ºË£ùÁΩÆÁöÑÈÜ´ÁôÇ‰øùÂÅ•ÊîØÊè¥ÔºåÈáçÈªûÂú®ÁöÆËÜöÁñæÁóÖË®∫Êñ∑ÂíåÈÜ´ÁôÇÁí∞Â¢É‰∏≠ AI Âä©ÁêÜÁöÑÈÅìÂæ∑‰ΩøÁî®„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄë‰ΩøÁî® 10,000 ÂºµÁöÆËÜöÁóÖÁÅ∂ÂΩ±ÂÉèË®ìÁ∑¥‰∏ÄÂÄãÁî®ÊñºÂàÜÈ°ûÂèØË¶ñÂèØÂÅµÊ∏¨ÁñæÁóÖ (VDD) ÁöÑÊ®°Âûã„ÄÇÁÑ∂ÂæåÂ∞áÊ®°ÂûãÊ¨äÈáçÂç∏ËºâÂà∞ÈÖçÂÇôÁ∂≤Ë∑ØÊîùÂΩ±Ê©üÁöÑ Raspberry PiÔºåÁî®ÊñºÂú®Ê≤íÊúâÁ∂≤Ë∑ØÂ≠òÂèñÁöÑÊÉÖÊ≥Å‰∏ãÂàÜÈ°ûÁöÆËÜöÁóÖÁÅ∂„ÄÇÁµêÊûúÁôºÁèæÔºåÂ∑≤ÈñãÁôºÁöÑÂéüÂûãÈÅîÂà∞ 78% ÁöÑÊ∏¨Ë©¶Ê∫ñÁ¢∫Â∫¶Âíå 1.08 ÁöÑÊ∏¨Ë©¶ÊêçÂ§±„ÄÇ

##### **Federated Fairness Analytics: Quantifying Fairness in Federated Learning**
2408.08214v1 by Oscar Dilley, Juan Marcelo Parra-Ullauri, Rasheed Hussain, Dimitra Simeonidou

Federated Learning (FL) is a privacy-enhancing technology for distributed ML.
By training models locally and aggregating updates - a federation learns
together, while bypassing centralised data collection. FL is increasingly
popular in healthcare, finance and personal computing. However, it inherits
fairness challenges from classical ML and introduces new ones, resulting from
differences in data quality, client participation, communication constraints,
aggregation methods and underlying hardware. Fairness remains an unresolved
issue in FL and the community has identified an absence of succinct definitions
and metrics to quantify fairness; to address this, we propose Federated
Fairness Analytics - a methodology for measuring fairness. Our definition of
fairness comprises four notions with novel, corresponding metrics. They are
symptomatically defined and leverage techniques originating from XAI,
cooperative game-theory and networking engineering. We tested a range of
experimental settings, varying the FL approach, ML task and data settings. The
results show that statistical heterogeneity and client participation affect
fairness and fairness conscious approaches such as Ditto and q-FedAvg
marginally improve fairness-performance trade-offs. Using our techniques, FL
practitioners can uncover previously unobtainable insights into their system's
fairness, at differing levels of granularity in order to address fairness
challenges in FL. We have open-sourced our work at:
https://github.com/oscardilley/federated-fairness.

ÊëòË¶ÅÔºö<paragraph>ËÅØÈÇ¶Â≠∏Áøí (FL) ÊòØ‰∏ÄÁ®ÆÂ¢ûÂº∑Èö±ÁßÅÁöÑÂàÜÂ∏ÉÂºèÊ©üÂô®Â≠∏ÁøíÊäÄË°ì„ÄÇ
ÈÄèÈÅéÂú®Êú¨Âú∞Ë®ìÁ∑¥Ê®°Âûã‰∏¶ÂΩôÁ∏ΩÊõ¥Êñ∞ÔºåËÅØÁõüÂèØ‰ª•ÂÖ±ÂêåÂ≠∏ÁøíÔºåÂêåÊôÇÁπûÈÅéÈõÜ‰∏≠ÂºèË≥áÊñôÊî∂ÈõÜ„ÄÇFL Âú®ÈÜ´ÁôÇ‰øùÂÅ•„ÄÅÈáëËûçÂíåÂÄã‰∫∫ÈÅãÁÆó‰∏≠Ë∂ä‰æÜË∂äÂèóÊ≠°Ëøé„ÄÇÁÑ∂ËÄåÔºåÂÆÉÁπºÊâø‰∫ÜÂÇ≥Áµ±Ê©üÂô®Â≠∏ÁøíÁöÑÂÖ¨Âπ≥ÊÄßÊåëÊà∞Ôºå‰∏¶ÂºïÂÖ•‰∫ÜÊñ∞ÁöÑÊåëÊà∞ÔºåÈÄô‰∫õÊåëÊà∞Ê∫êÊñºË≥áÊñôÂìÅË≥™„ÄÅÂÆ¢Êà∂Á´ØÂèÉËàá„ÄÅÈÄöË®äÈôêÂà∂„ÄÅÂΩôÁ∏ΩÊñπÊ≥ïÂíåÂü∫Á§éÁ°¨È´îÁöÑÂ∑ÆÁï∞„ÄÇÂÖ¨Âπ≥ÊÄß‰ªçÁÑ∂ÊòØ FL ‰∏≠‰∏ÄÂÄãÂ∞öÊú™Ëß£Ê±∫ÁöÑÂïèÈ°åÔºåËÄåÁ§æÁæ§Â∑≤ÁôºÁèæÁº∫‰πèÁ∞°ÊΩîÁöÑÂÆöÁæ©ÂíåË°°ÈáèÂÖ¨Âπ≥ÊÄßÁöÑÊåáÊ®ôÔºõÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫ËÅØÈÇ¶ÂÖ¨Âπ≥ÊÄßÂàÜÊûêÔºå‰∏ÄÁ®ÆÁî®ÊñºË°°ÈáèÂÖ¨Âπ≥ÊÄßÁöÑÊñπÊ≥ï„ÄÇÊàëÂÄëÂ∞çÂÖ¨Âπ≥ÊÄßÁöÑÂÆöÁæ©ÂåÖÂê´ÂõõÂÄãÊ¶ÇÂøµÔºå‰∏¶ÊúâÊñ∞Á©éÁöÑÂ∞çÊáâÊåáÊ®ô„ÄÇÂÆÉÂÄëË¢´ÁóáÁãÄÊÄßÂú∞ÂÆöÁæ©Ôºå‰∏¶Âà©Áî®Ê∫êËá™ XAI„ÄÅÂêà‰ΩúÂçöÂºàË´ñÂíåÁ∂≤Ë∑ØÂ∑•Á®ãÁöÑÊäÄË°ì„ÄÇÊàëÂÄëÊ∏¨Ë©¶‰∫Ü‰∏ÄÁ≥ªÂàóÂØ¶È©óË®≠ÂÆöÔºåÊîπËÆä‰∫Ü FL ÊñπÊ≥ï„ÄÅÊ©üÂô®Â≠∏Áøí‰ªªÂãôÂíåË≥áÊñôË®≠ÂÆö„ÄÇÁµêÊûúË°®ÊòéÔºåÁµ±Ë®àÁï∞Ë≥™ÊÄßÂíåÂÆ¢Êà∂Á´ØÂèÉËàáÊúÉÂΩ±ÈüøÂÖ¨Âπ≥ÊÄßÔºåËÄåÈáçË¶ñÂÖ¨Âπ≥ÊÄßÁöÑÊñπÊ≥ïÔºå‰æãÂ¶Ç Ditto Âíå q-FedAvgÔºåÂâáÊúÉÁï•ÂæÆÊîπÂñÑÂÖ¨Âπ≥ÊÄßËàáÊïàËÉΩÁöÑÊ¨äË°°„ÄÇÈÄèÈÅé‰ΩøÁî®ÊàëÂÄëÁöÑÊäÄË°ìÔºåFL ÂæûÊ•≠‰∫∫Âì°ÂèØ‰ª•ÁôºÊéò‰ª•ÂâçÁÑ°Ê≥ïÁç≤ÂæóÁöÑÂ∞çÂÖ∂Á≥ªÁµ±ÂÖ¨Âπ≥ÊÄßÁöÑË¶ãËß£ÔºåÂú®‰∏çÂêåÁöÑÁ¥∞ÂåñÂ±§Á¥ö‰∏≠Ôºå‰ª•Ëß£Ê±∫ FL ‰∏≠ÁöÑÂÖ¨Âπ≥ÊÄßÊåëÊà∞„ÄÇÊàëÂÄëÂ∑≤Âú®‰ª•‰∏ã‰ΩçÁΩÆÈñãÊîæÂéüÂßãÁ¢ºÔºö
https://github.com/oscardilley/federated-fairness„ÄÇ</paragraph>

##### **Covert Bias: The Severity of Social Views' Unalignment in Language Models Towards Implicit and Explicit Opinion**
2408.08212v2 by Abeer Aldayel, Areej Alokaili, Rehab Alahmadi

While various approaches have recently been studied for bias identification,
little is known about how implicit language that does not explicitly convey a
viewpoint affects bias amplification in large language models. To examine the
severity of bias toward a view, we evaluated the performance of two downstream
tasks where the implicit and explicit knowledge of social groups were used.
First, we present a stress test evaluation by using a biased model in edge
cases of excessive bias scenarios. Then, we evaluate how LLMs calibrate
linguistically in response to both implicit and explicit opinions when they are
aligned with conflicting viewpoints. Our findings reveal a discrepancy in LLM
performance in identifying implicit and explicit opinions, with a general
tendency of bias toward explicit opinions of opposing stances. Moreover, the
bias-aligned models generate more cautious responses using uncertainty phrases
compared to the unaligned (zero-shot) base models. The direct, incautious
responses of the unaligned models suggest a need for further refinement of
decisiveness by incorporating uncertainty markers to enhance their reliability,
especially on socially nuanced topics with high subjectivity.

ÊëòË¶ÅÔºöÂÑòÁÆ°ÊúÄËøëÂ∑≤Á†îÁ©∂ÂêÑÁ®ÆÂÅèË¶ãË≠òÂà•ÊñπÊ≥ïÔºå
‰ΩÜÂ∞çÊñº‰∏çÈ°ØÂºèÂÇ≥ÈÅîËßÄÈªûÁöÑÈö±Âê´Ë™ûË®ÄÂ¶Ç‰ΩïÂΩ±ÈüøÂ§ßÂûãË™ûË®ÄÊ®°Âûã‰∏≠ÁöÑÂÅèË¶ãÊîæÂ§ßÔºåÊàëÂÄëÊâÄÁü•ÁîöÂ∞ë„ÄÇÁÇ∫‰∫ÜÊ™¢Ë¶ñËßÄÈªûÂÅèË¶ãÁöÑÂö¥ÈáçÊÄßÔºåÊàëÂÄëË©ï‰º∞‰∫Ü‰∏ãÊ∏∏ÂÖ©ÂÄã‰ªªÂãôÁöÑË°®ÁèæÔºåÂÖ∂‰∏≠‰ΩøÁî®‰∫ÜÁ§æÊúÉÁæ§È´îÁöÑÈö±Âê´ÂíåÈ°ØÂºèÁü•Ë≠ò„ÄÇ
È¶ñÂÖàÔºåÊàëÂÄëÈÄèÈÅéÂú®ÈÅéÂ∫¶ÂÅèË¶ãÊÉÖÂ¢É‰∏≠‰ΩøÁî®ÂÅèË¶ãÊ®°ÂûãÔºåÊèêÂá∫Â£ìÂäõÊ∏¨Ë©¶Ë©ï‰º∞„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëË©ï‰º∞ LLM Âú®ËàáË°ùÁ™ÅËßÄÈªû‰∏ÄËá¥ÊôÇÔºåÂ¶Ç‰ΩïÂ∞çÈö±Âê´ÂíåÈ°ØÂºèÊÑèË¶ãÈÄ≤Ë°åË™ûË®ÄÊ†°Ê∫ñ„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÊè≠Á§∫‰∫Ü LLM Âú®Ë≠òÂà•Èö±Âê´ÂíåÈ°ØÂºèÊÑèË¶ãÊñπÈù¢ÁöÑË°®ÁèæÂ∑ÆÁï∞ÔºåÈÄöÂ∏∏ÂÇæÂêëÊñºÂ∞çÂèçÂ∞çÁ´ãÂ†¥ÁöÑÈ°ØÂºèÊÑèË¶ãÁî¢ÁîüÂÅèË¶ã„ÄÇÊ≠§Â§ñÔºåËàáÊú™Â∞çÈΩäÔºàÈõ∂Ê¨°Â≠∏ÁøíÔºâÂü∫Á§éÊ®°ÂûãÁõ∏ÊØîÔºåÂÅèË¶ãÂ∞çÈΩäÊ®°Âûã‰ΩøÁî®‰∏çÁ¢∫ÂÆöÊÄßË©ûÂΩôÁî¢ÁîüÊõ¥Ë¨πÊÖéÁöÑÂõûÊáâ„ÄÇÊú™Â∞çÈΩäÊ®°ÂûãÁöÑÁõ¥Êé•„ÄÅÈ≠ØËéΩÂõûÊáâË°®ÊòéÈúÄË¶ÅÈÄ≤‰∏ÄÊ≠•ÂÆåÂñÑÊ±∫Êñ∑ÂäõÔºåÊñπÊ≥ïÊòØÁ¥çÂÖ•‰∏çÁ¢∫ÂÆöÊÄßÊ®ôË®ò‰ª•ÊèêÈ´òÂÖ∂ÂèØÈù†ÊÄßÔºåÁâπÂà•ÊòØÂú®ÂÖ∑ÊúâÈ´òÂ∫¶‰∏ªËßÄÊÄßÁöÑÁ§æÊúÉÁ¥∞ÂæÆÂ∑ÆÂà•‰∏ªÈ°å‰∏ä„ÄÇ

##### **LLM4DSR: Leveraing Large Language Model for Denoising Sequential Recommendation**
2408.08208v1 by Bohao Wang, Feng Liu, Jiawei Chen, Yudi Wu, Xingyu Lou, Jun Wang, Yan Feng, Chun Chen, Can Wang

Sequential recommendation systems fundamentally rely on users' historical
interaction sequences, which are often contaminated by noisy interactions.
Identifying these noisy interactions accurately without additional information
is particularly difficult due to the lack of explicit supervisory signals to
denote noise. Large Language Models (LLMs), equipped with extensive open
knowledge and semantic reasoning abilities, present a promising avenue to
bridge this information gap. However, employing LLMs for denoising in
sequential recommendation introduces notable challenges: 1) Direct application
of pretrained LLMs may not be competent for the denoising task, frequently
generating nonsensical responses; 2) Even after fine-tuning, the reliability of
LLM outputs remains questionable, especially given the complexity of the task
and th inherent hallucinatory issue of LLMs.
  To tackle these challenges, we propose LLM4DSR, a tailored approach for
denoising sequential recommendation using LLMs. We constructed a
self-supervised fine-tuning task to activate LLMs' capabilities to identify
noisy items and suggest replacements. Furthermore, we developed an uncertainty
estimation module that ensures only high-confidence responses are utilized for
sequence corrections. Remarkably, LLM4DSR is model-agnostic, allowing the
corrected sequences to be flexibly applied across various recommendation
models. Extensive experiments validate the superiority of LLM4DSR over existing
methods across three datasets and three recommendation backbones.

ÊëòË¶ÅÔºöÂ∫èÂàóÊé®Ëñ¶Á≥ªÁµ±Âü∫Êú¨‰∏ä‰æùË≥¥Êñº‰ΩøÁî®ËÄÖÁöÑÊ≠∑Âè≤‰∫íÂãïÂ∫èÂàóÔºåÈÄô‰∫õÂ∫èÂàóÈÄöÂ∏∏ÊúÉÂèóÂà∞ÈõúË®ä‰∫íÂãïÁöÑÊ±°Êüì„ÄÇÁî±ÊñºÁº∫‰πèÊòéÁ¢∫ÁöÑÁõ£Áù£Ë®äËôü‰æÜË°®Á§∫ÈõúË®äÔºåÂõ†Ê≠§Âú®Ê≤íÊúâÈ°çÂ§ñË≥áË®äÁöÑÊÉÖÊ≥Å‰∏ãÊ∫ñÁ¢∫Ë≠òÂà•ÈÄô‰∫õÈõúË®ä‰∫íÂãïÁâπÂà•Âõ∞Èõ£„ÄÇÂÖ∑ÂÇôÂª£Ê≥õÈñãÊîæÁü•Ë≠òÂíåË™ûÁæ©Êé®ÁêÜËÉΩÂäõÁöÑÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Êèê‰æõ‰∫Ü‰∏ÄÂÄãÊúâÂâçÈÄîÁöÑÈÄîÂæë‰æÜÂΩåË£úÈÄôÂÄãË≥áË®äÂ∑ÆË∑ù„ÄÇÁÑ∂ËÄåÔºåÂú®Â∫èÂàóÊé®Ëñ¶‰∏≠‰ΩøÁî® LLM ‰æÜÈÄ≤Ë°åÂéªÈõúË®äÊúÉÁî¢ÁîüÈ°ØËëóÁöÑÊåëÊà∞Ôºö1) Áõ¥Êé•ÊáâÁî®È†êË®ìÁ∑¥ÁöÑ LLM ÂèØËÉΩ‰∏çÂãù‰ªªÂéªÈõúË®ä‰ªªÂãôÔºåÁ∂ìÂ∏∏ÊúÉÁî¢ÁîüÁÑ°ÊÑèÁæ©ÁöÑÂõûÊáâÔºõ2) Âç≥‰ΩøÂú®ÂæÆË™ø‰πãÂæåÔºåLLM Ëº∏Âá∫ÁöÑÂèØÈù†ÊÄß‰ªçÁÑ∂ÊúâÂæÖÂïÜÊ¶∑ÔºåÁâπÂà•ÊòØËÄÉÊÖÆÂà∞‰ªªÂãôÁöÑË§áÈõúÊÄßÂíå LLM Âõ∫ÊúâÁöÑÂπªË¶∫ÂïèÈ°å„ÄÇ
ÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü LLM4DSRÔºåÈÄôÊòØ‰∏ÄÁ®Æ‰ΩøÁî® LLM Â∞çÂ∫èÂàóÊé®Ëñ¶ÈÄ≤Ë°åÂéªÈõúË®äÁöÑÂÆ¢Ë£ΩÂåñÊñπÊ≥ï„ÄÇÊàëÂÄëÂª∫Êßã‰∫Ü‰∏ÄÂÄãËá™ÊàëÁõ£Áù£ÁöÑÂæÆË™ø‰ªªÂãôÔºå‰ª•ÂïüÂãï LLM Ë≠òÂà•ÈõúË®äÈ†ÖÁõÆ‰∏¶Âª∫Ë≠∞ÊõøÊèõÈ†ÖÁõÆÁöÑËÉΩÂäõ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÈñãÁôº‰∫Ü‰∏ÄÂÄã‰∏çÁ¢∫ÂÆöÊÄß‰º∞Ë®àÊ®°ÁµÑÔºå‰ª•Á¢∫‰øùÂè™ÊúâÈ´ò‰ø°ÂøÉÁöÑÂõûÊáâË¢´Áî®ÊñºÂ∫èÂàóÊ†°Ê≠£„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåLLM4DSR ËàáÊ®°ÂûãÁÑ°ÈóúÔºåÂÖÅË®±Âú®ÂêÑÁ®ÆÊé®Ëñ¶Ê®°Âûã‰∏≠ÈùàÊ¥ªÂú∞ÊáâÁî®Ê†°Ê≠£ÂæåÁöÑÂ∫èÂàó„ÄÇÂª£Ê≥õÁöÑÂØ¶È©óÈ©óË≠â‰∫Ü LLM4DSR Âú®‰∏âÂÄãË≥áÊñôÈõÜÂíå‰∏âÂÄãÊé®Ëñ¶‰∏ªÂππ‰∏äÂÑ™ÊñºÁèæÊúâÊñπÊ≥ï„ÄÇ

##### **API-guided Dataset Synthesis to Finetune Large Code Models**
2408.08343v1 by Zongjie Li, Daoyuan Wu, Shuai Wang, Zhendong Su

Large code models (LCMs), pre-trained on vast code corpora, have demonstrated
remarkable performance across a wide array of code-related tasks. Supervised
fine-tuning (SFT) plays a vital role in aligning these models with specific
requirements and enhancing their performance in particular domains. However,
synthesizing high-quality SFT datasets poses a significant challenge due to the
uneven quality of datasets and the scarcity of domain-specific datasets.
  Inspired by APIs as high-level abstractions of code that encapsulate rich
semantic information in a concise structure, we propose DataScope, an
API-guided dataset synthesis framework designed to enhance the SFT process for
LCMs in both general and domain-specific scenarios. DataScope comprises two
main components: Dsel and Dgen. On one hand, Dsel employs API coverage as a
core metric, enabling efficient dataset synthesis in general scenarios by
selecting subsets of existing (uneven-quality) datasets with higher API
coverage. On the other hand, Dgen recasts domain dataset synthesis as a process
of using API-specified high-level functionality and deliberately-constituted
code skeletons to synthesize concrete code.
  Extensive experiments demonstrate DataScope's effectiveness, with models
fine-tuned on its synthesized datasets outperforming those tuned on unoptimized
datasets five times larger. Furthermore, a series of analyses on model
internals, relevant hyperparameters, and case studies provide additional
evidence for the efficacy of our proposed methods. These findings underscore
the significance of dataset quality in SFT and advance the field of LCMs by
providing an efficient, cost-effective framework for constructing high-quality
datasets. This contribution enhances performance across both general and
domain-specific scenarios, paving the way for more powerful and tailored LCMs.

ÊëòË¶ÅÔºö<paragraph>Âú®ÈæêÂ§ßÁöÑÁ®ãÂºèÁ¢ºË≥áÊñôÂ∫´‰∏äÈ†êÂÖàË®ìÁ∑¥ÁöÑÂ§ßÂûãÁ®ãÂºèÁ¢ºÊ®°Âûã (LCM) Â∑≤Âú®ÂêÑÁ®ÆËàáÁ®ãÂºèÁ¢ºÁõ∏ÈóúÁöÑ‰ªªÂãô‰∏≠Â±ïÁèæÂá∫ÂçìË∂äÁöÑÊïàËÉΩ„ÄÇÂèóÁõ£Áù£ÂæÆË™ø (SFT) Âú®Â∞áÈÄô‰∫õÊ®°ÂûãËàáÁâπÂÆöÈúÄÊ±ÇÂ∞çÈΩä‰∏¶ÊèêÂçáÂÆÉÂÄëÂú®ÁâπÂÆöÈ†òÂüüÁöÑÊïàËÉΩÊñπÈù¢ÁôºÊèÆËëóËá≥ÈóúÈáçË¶ÅÁöÑ‰ΩúÁî®„ÄÇÁÑ∂ËÄåÔºåÁî±ÊñºË≥áÊñôÈõÜÂìÅË≥™‰∏ç‰∏Ä‰∏îÁº∫‰πèÁâπÂÆöÈ†òÂüüÁöÑË≥áÊñôÈõÜÔºåÂõ†Ê≠§ÂêàÊàêÈ´òÂìÅË≥™ÁöÑ SFT Ë≥áÊñôÈõÜÊòØ‰∏ÄÂÄãÈáçÂ§ßÁöÑÊåëÊà∞„ÄÇ
  Âèó API ‰ΩúÁÇ∫Á®ãÂºèÁ¢ºÁöÑÈ´òÈöéÊäΩË±°ÔºåËÉΩ‰ª•Á∞°ÊΩîÁöÑÁµêÊßãÂ∞ÅË£ùË±êÂØåË™ûÁæ©Ë≥áË®äÁöÑÂïüÁôºÔºåÊàëÂÄëÊèêÂá∫ DataScopeÔºå‰∏ÄÂÄã API ÂºïÂ∞éÁöÑË≥áÊñôÈõÜÂêàÊàêÊû∂ÊßãÔºåÊó®Âú®Â¢ûÂº∑ LCM Âú®‰∏ÄËà¨ÂíåÁâπÂÆöÈ†òÂüüÂ†¥ÊôØ‰∏≠ÁöÑ SFT Á®ãÂ∫è„ÄÇDataScope ÂåÖÂê´ÂÖ©ÂÄã‰∏ªË¶ÅÁµÑÊàêÈÉ®ÂàÜÔºöDsel Âíå Dgen„ÄÇ‰∏ÄÊñπÈù¢ÔºåDsel ‰ª• API Ê∂µËìãÁØÑÂúç‰ΩúÁÇ∫Ê†∏ÂøÉÊåáÊ®ôÔºåÈÄèÈÅéÈÅ∏Âèñ API Ê∂µËìãÁØÑÂúçËºÉÈ´òÁöÑÁèæÊúâÔºàÂìÅË≥™‰∏ç‰∏ÄÔºâË≥áÊñôÈõÜÁöÑÂ≠êÈõÜÔºåÂú®‰∏ÄËà¨Â†¥ÊôØ‰∏≠ÂØ¶ÁèæÊúâÊïàÁéáÁöÑË≥áÊñôÈõÜÂêàÊàê„ÄÇÂè¶‰∏ÄÊñπÈù¢ÔºåDgen Â∞áÈ†òÂüüË≥áÊñôÈõÜÂêàÊàêÈáçÂ°ëÁÇ∫‰∏ÄÂÄã‰ΩøÁî® API ÊåáÂÆöÁöÑÈ´òÈöéÂäüËÉΩÂíåÁ∂ìÈÅéÊ∑±ÊÄùÁÜüÊÖÆÁöÑÁ®ãÂºèÁ¢ºÈ™®Êû∂‰æÜÂêàÊàêÂÖ∑È´îÁ®ãÂºèÁ¢ºÁöÑÁ®ãÂ∫è„ÄÇ
  Âª£Ê≥õÁöÑÂØ¶È©óË≠âÊòé‰∫Ü DataScope ÁöÑÊúâÊïàÊÄßÔºå‰ΩøÁî®ÂÖ∂ÂêàÊàêÁöÑË≥áÊñôÈõÜÈÄ≤Ë°åÂæÆË™øÁöÑÊ®°ÂûãÊØîÂú®Êú™Á∂ìÊúÄ‰Ω≥Âåñ„ÄÅË¶èÊ®°Â§ß‰∫îÂÄçÁöÑË≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÂæÆË™øÁöÑÊ®°ÂûãË°®ÁèæÂæóÊõ¥Â•Ω„ÄÇÊ≠§Â§ñÔºåÂ∞çÊ®°ÂûãÂÖßÈÉ®ÁµêÊßã„ÄÅÁõ∏ÈóúË∂ÖÂèÉÊï∏ÂíåÂÄãÊ°àÁ†îÁ©∂ÁöÑ‰∏ÄÁ≥ªÂàóÂàÜÊûêÁÇ∫ÊàëÂÄëÊèêÂá∫ÁöÑÊñπÊ≥ïÁöÑÊïàËÉΩÊèê‰æõ‰∫ÜÈ°çÂ§ñÁöÑË≠âÊìö„ÄÇÈÄô‰∫õÁôºÁèæÂº∑Ë™ø‰∫ÜË≥áÊñôÈõÜÂìÅË≥™Âú® SFT ‰∏≠ÁöÑÈáçË¶ÅÊÄßÔºå‰∏¶ÈÄèÈÅéÊèê‰æõ‰∏ÄÂÄãÂª∫ÊßãÈ´òÂìÅË≥™Ë≥áÊñôÈõÜÁöÑÈ´òÊïàÁéá„ÄÅÈ´òÊàêÊú¨ÊïàÁõäÁöÑÊû∂ÊßãÔºåÊé®Âãï LCM È†òÂüüÁöÑÈÄ≤Ê≠•„ÄÇÈÄôÈ†ÖË≤¢ÁçªÊèêÂçá‰∫Ü‰∏ÄËà¨ÂíåÁâπÂÆöÈ†òÂüüÂ†¥ÊôØÁöÑÊïàËÉΩÔºåÁÇ∫Êõ¥Âº∑Â§ß‰∏îÂÆ¢Ë£ΩÂåñÁöÑ LCM Èã™Ë∑Ø„ÄÇ</paragraph>

##### **Scaling Up Natural Language Understanding for Multi-Robots Through the Lens of Hierarchy**
2408.08188v1 by Shaojun Xu, Xusheng Luo, Yutong Huang, Letian Leng, Ruixuan Liu, Changliu Liu

Long-horizon planning is hindered by challenges such as uncertainty
accumulation, computational complexity, delayed rewards and incomplete
information. This work proposes an approach to exploit the task hierarchy from
human instructions to facilitate multi-robot planning. Using Large Language
Models (LLMs), we propose a two-step approach to translate multi-sentence
instructions into a structured language, Hierarchical Linear Temporal Logic
(LTL), which serves as a formal representation for planning. Initially, LLMs
transform the instructions into a hierarchical representation defined as
Hierarchical Task Tree, capturing the logical and temporal relations among
tasks. Following this, a domain-specific fine-tuning of LLM translates
sub-tasks of each task into flat LTL formulas, aggregating them to form
hierarchical LTL specifications. These specifications are then leveraged for
planning using off-the-shelf planners. Our framework not only bridges the gap
between instructions and algorithmic planning but also showcases the potential
of LLMs in harnessing hierarchical reasoning to automate multi-robot task
planning. Through evaluations in both simulation and real-world experiments
involving human participants, we demonstrate that our method can handle more
complex instructions compared to existing methods. The results indicate that
our approach achieves higher success rates and lower costs in multi-robot task
allocation and plan generation. Demos videos are available at
https://youtu.be/7WOrDKxIMIs .

ÊëòË¶ÅÔºöÈï∑ÊúüË¶èÂäÉÂèóÂà∞‰∏çÁ¢∫ÂÆöÊÄßÁ¥ØÁ©ç„ÄÅË®àÁÆóË§áÈõúÊÄß„ÄÅÁçéÂãµÂª∂ÈÅ≤ÂíåË≥áË®ä‰∏çÂÆåÊï¥Á≠âÊåëÊà∞ÊâÄÈòªÁ§ô„ÄÇÊú¨Á†îÁ©∂ÊèêÂá∫‰∏ÄÂÄãÊñπÊ≥ï‰æÜÂà©Áî®‰∫∫È°ûÊåá‰ª§‰∏≠ÁöÑ‰ªªÂãôÈöéÂ±§Ôºå‰ª•‰øÉÈÄ≤Â§öÊ©üÂô®‰∫∫Ë¶èÂäÉ„ÄÇÊàëÂÄë‰ΩøÁî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM)ÔºåÊèêÂá∫‰∏ÄÂÄãÂÖ©Ê≠•È©üÁöÑÊñπÊ≥ïÔºåÂ∞áÂ§öÂè•Êåá‰ª§ËΩâÊèõÊàêÁµêÊßãÂåñË™ûË®ÄÔºåÂ±§Á¥öÁ∑öÊÄßÊôÇÂ∫èÈÇèËºØ (LTL)Ôºå‰ΩúÁÇ∫Ë¶èÂäÉÁöÑÊ≠£ÂºèË°®Á§∫„ÄÇÊúÄÂàùÔºåLLM Â∞áÊåá‰ª§ËΩâÊèõÊàêÈöéÂ±§ÂºèË°®Á§∫ÔºåÂÆöÁæ©ÁÇ∫ÈöéÂ±§‰ªªÂãôÊ®πÔºåÊçïÊçâ‰ªªÂãô‰πãÈñìÁöÑÈÇèËºØÂíåÊôÇÈñìÈóú‰øÇ„ÄÇÂú®Ê≠§‰πãÂæåÔºåLLM ÁöÑÁâπÂÆöÈ†òÂüüÂæÆË™øÂ∞áÊØèÂÄã‰ªªÂãôÁöÑÂ≠ê‰ªªÂãôËΩâÊèõÊàêÊâÅÂπ≥ LTL ÂÖ¨ÂºèÔºåÂΩôÁ∏ΩÂÆÉÂÄë‰ª•ÂΩ¢ÊàêÈöéÂ±§Âºè LTL Ë¶èÁØÑ„ÄÇÁÑ∂ÂæåÂà©Áî®ÈÄô‰∫õË¶èÁØÑ‰æÜ‰ΩøÁî®ÁèæÊàêÁöÑË¶èÂäÉÂô®ÈÄ≤Ë°åË¶èÂäÉ„ÄÇÊàëÂÄëÁöÑÊ°ÜÊû∂‰∏çÂÉÖÂΩåÂêà‰∫ÜÊåá‰ª§ÂíåÊºîÁÆóÊ≥ïË¶èÂäÉ‰πãÈñìÁöÑÂ∑ÆË∑ùÔºåÈÇÑÂ±ïÁ§∫‰∫Ü LLM Âú®Âà©Áî®ÈöéÂ±§ÂºèÊé®ÁêÜ‰æÜËá™ÂãïÂåñÂ§öÊ©üÂô®‰∫∫‰ªªÂãôË¶èÂäÉ‰∏≠ÁöÑÊΩõÂäõ„ÄÇÈÄèÈÅéÂú®Ê∂âÂèä‰∫∫È°ûÂèÉËàáËÄÖÁöÑÊ®°Êì¨ÂíåÁúüÂØ¶‰∏ñÁïåÂØ¶È©ó‰∏≠ÈÄ≤Ë°åË©ï‰º∞ÔºåÊàëÂÄëË≠âÊòé‰∫ÜÊàëÂÄëÁöÑÊñπÊ≥ïÂèØ‰ª•ËôïÁêÜÊØîÁèæÊúâÊñπÊ≥ïÊõ¥Ë§áÈõúÁöÑÊåá‰ª§„ÄÇÁµêÊûúË°®ÊòéÔºåÊàëÂÄëÁöÑÊñπÊ≥ïÂú®Â§öÊ©üÂô®‰∫∫‰ªªÂãôÂàÜÈÖçÂíåË®àÁï´Áî¢Áîü‰∏≠ÂØ¶Áèæ‰∫ÜÊõ¥È´òÁöÑÊàêÂäüÁéáÂíåÊõ¥‰ΩéÁöÑÊàêÊú¨„ÄÇÁ§∫ÁØÑÂΩ±ÁâáÂèØÂú® https://youtu.be/7WOrDKxIMIs ÂèñÂæó„ÄÇ

##### **Your Turn: Real-World Turning Angle Estimation for Parkinson's Disease Severity Assessment**
2408.08182v1 by Qiushuo Cheng, Catherine Morgan, Arindam Sikdar, Alessandro Masullo, Alan Whone, Majid Mirmehdi

People with Parkinson's Disease (PD) often experience progressively worsening
gait, including changes in how they turn around, as the disease progresses.
Existing clinical rating tools are not capable of capturing hour-by-hour
variations of PD symptoms, as they are confined to brief assessments within
clinic settings. Measuring real-world gait turning angles continuously and
passively is a component step towards using gait characteristics as sensitive
indicators of disease progression in PD. This paper presents a deep
learning-based approach to automatically quantify turning angles by extracting
3D skeletons from videos and calculating the rotation of hip and knee joints.
We utilise state-of-the-art human pose estimation models, Fastpose and Strided
Transformer, on a total of 1386 turning video clips from 24 subjects (12 people
with PD and 12 healthy control volunteers), trimmed from a PD dataset of
unscripted free-living videos in a home-like setting (Turn-REMAP). We also
curate a turning video dataset, Turn-H3.6M, from the public Human3.6M human
pose benchmark with 3D ground truth, to further validate our method. Previous
gait research has primarily taken place in clinics or laboratories evaluating
scripted gait outcomes, but this work focuses on real-world settings where
complexities exist, such as baggy clothing and poor lighting. Due to
difficulties in obtaining accurate ground truth data in a free-living setting,
we quantise the angle into the nearest bin $45^\circ$ based on the manual
labelling of expert clinicians. Our method achieves a turning calculation
accuracy of 41.6%, a Mean Absolute Error (MAE) of 34.7{\deg}, and a weighted
precision WPrec of 68.3% for Turn-REMAP. This is the first work to explore the
use of single monocular camera data to quantify turns by PD patients in a home
setting.

ÊëòË¶ÅÔºöÂ∏ïÈáëÊ£ÆÊ∞èÁóá (PD) ÊÇ£ËÄÖÁªèÂ∏∏‰ºöÈöèÁùÄÁñæÁóÖÁöÑËøõÂ±ïËÄåÂá∫Áé∞Ê≠•ÊÄÅÈÄêÊ∏êÊÅ∂ÂåñÁöÑÁé∞Ë±°ÔºåÂåÖÊã¨ËΩ¨Ë∫´ÊñπÂºèÁöÑÂèòÂåñ„ÄÇÁé∞ÊúâÁöÑ‰∏¥Â∫äËØÑÂÆöÂ∑•ÂÖ∑Êó†Ê≥ïÊçïÊçâÂà∞ PD ÁóáÁä∂ÈÄêÂ∞èÊó∂ÁöÑÂèòÂåñÔºåÂõ†‰∏∫ÂÆÉ‰ª¨‰ªÖÈôê‰∫éÂú®‰∏¥Â∫äÁéØÂ¢É‰∏≠ËøõË°åÁü≠ÊöÇÁöÑËØÑ‰º∞„ÄÇËøûÁª≠Ë¢´Âä®Âú∞ÊµãÈáèÁé∞ÂÆû‰∏ñÁïå‰∏≠ÁöÑÊ≠•ÊÄÅËΩ¨ÂºØËßíÂ∫¶ÊòØÂ∞ÜÊ≠•ÊÄÅÁâπÂæÅÁî®‰Ωú PD ÁñæÁóÖËøõÂ±ïÁöÑÊïèÊÑüÊåáÊ†áÁöÑÁªÑÊàêÈÉ®ÂàÜ„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂü∫‰∫éÊ∑±Â∫¶Â≠¶‰π†ÁöÑÊñπÊ≥ïÔºåÈÄöËøá‰ªéËßÜÈ¢ë‰∏≠ÊèêÂèñ 3D È™®Êû∂Âπ∂ËÆ°ÁÆóÈ´ãÂÖ≥ËäÇÂíåËÜùÂÖ≥ËäÇÁöÑÊóãËΩ¨ÔºåËá™Âä®ÈáèÂåñËΩ¨ÂºØËßíÂ∫¶„ÄÇÊàë‰ª¨ÂØπÊù•Ëá™ 24 ‰∏™ÂèóËØïËÄÖÔºà12 Âêç PD ÊÇ£ËÄÖÂíå 12 ÂêçÂÅ•Â∫∑ÂØπÁÖßÂøóÊÑøËÄÖÔºâÁöÑÊÄªÂÖ± 1386 ‰∏™ËΩ¨ÂºØËßÜÈ¢ëÂâ™Ëæë‰ΩøÁî®‰∫ÜÊúÄÂÖàËøõÁöÑ‰∫∫‰ΩìÂßøÂäø‰º∞ËÆ°Ê®°Âûã Fastpose Âíå Strided TransformerÔºåËøô‰∫õÂâ™ËæëÊòØ‰ªéÂÆ∂Â∫≠ÁéØÂ¢É‰∏≠Êó†ËÑöÊú¨Ëá™Áî±ÁîüÊ¥ªËßÜÈ¢ëÁöÑ PD Êï∞ÊçÆÈõÜÔºàTurn-REMAPÔºâ‰∏≠Êà™ÂèñÁöÑ„ÄÇÊàë‰ª¨Ëøò‰ªéÂÖ∑Êúâ 3D ÁúüÂÆûÁöÑÂÖ¨ÂÖ± Human3.6M ‰∫∫‰ΩìÂßøÂäøÂü∫ÂáÜ‰∏≠Êï¥ÁêÜ‰∫Ü‰∏Ä‰∏™ËΩ¨ÂºØËßÜÈ¢ëÊï∞ÊçÆÈõÜ Turn-H3.6MÔºå‰ª•Ëøõ‰∏ÄÊ≠•È™åËØÅÊàë‰ª¨ÁöÑÊñπÊ≥ï„ÄÇ‰ª•ÂæÄÁöÑÊ≠•ÊÄÅÁ†îÁ©∂‰∏ªË¶ÅÂú®ËØÑ‰º∞ËÑöÊú¨ÂåñÊ≠•ÊÄÅÁªìÊûúÁöÑËØäÊâÄÊàñÂÆûÈ™åÂÆ§‰∏≠ËøõË°åÔºå‰ΩÜËøôÈ°πÂ∑•‰ΩúÈáçÁÇπÂÖ≥Ê≥®Â≠òÂú®Â§çÊùÇÊÄßÁöÑÁé∞ÂÆû‰∏ñÁïåÁéØÂ¢ÉÔºå‰æãÂ¶ÇÂÆΩÊùæÁöÑË°£ÊúçÂíåÂÖâÁ∫ø‰∏çË∂≥„ÄÇÁî±‰∫éÂú®Ëá™Áî±ÁîüÊ¥ªÁéØÂ¢É‰∏≠Èöæ‰ª•Ëé∑ÂæóÂáÜÁ°ÆÁöÑÁúüÂÆûÊï∞ÊçÆÔºåÊàë‰ª¨Ê†πÊçÆ‰∏ìÂÆ∂‰∏¥Â∫äÂåªÁîüÁöÑÊâãÂä®Ê†áËÆ∞ÔºåÂ∞ÜËßíÂ∫¶ÈáèÂåñ‰∏∫ÊúÄÊé•ËøëÁöÑÁÆ± $45^\circ$„ÄÇÊàë‰ª¨ÁöÑÊñπÊ≥ïÂØπ Turn-REMAP ÁöÑËΩ¨ÂºØËÆ°ÁÆóÂáÜÁ°ÆÂ∫¶ËææÂà∞ 41.6%ÔºåÂπ≥ÂùáÁªùÂØπËØØÂ∑Æ (MAE) ‰∏∫ 34.7{\deg}ÔºåÂä†ÊùÉÁ≤æÂ∫¶ WPrec ‰∏∫ 68.3%„ÄÇËøôÊòØÈ¶ñÊ¨°Êé¢Á¥¢‰ΩøÁî®ÂçïÁõÆÂçïÁúºÁõ∏Êú∫Êï∞ÊçÆÊù•ÈáèÂåñ PD ÊÇ£ËÄÖÂú®ÂÆ∂‰∏≠ËΩ¨ÂºØÊÉÖÂÜµÁöÑÂ∑•‰Ωú„ÄÇ

##### **Towards flexible perception with visual memory**
2408.08172v1 by Robert Geirhos, Priyank Jaini, Austin Stone, Sourabh Medapati, Xi Yi, George Toderici, Abhijit Ogale, Jonathon Shlens

Training a neural network is a monolithic endeavor, akin to carving knowledge
into stone: once the process is completed, editing the knowledge in a network
is nearly impossible, since all information is distributed across the network's
weights. We here explore a simple, compelling alternative by marrying the
representational power of deep neural networks with the flexibility of a
database. Decomposing the task of image classification into image similarity
(from a pre-trained embedding) and search (via fast nearest neighbor retrieval
from a knowledge database), we build a simple and flexible visual memory that
has the following key capabilities: (1.) The ability to flexibly add data
across scales: from individual samples all the way to entire classes and
billion-scale data; (2.) The ability to remove data through unlearning and
memory pruning; (3.) An interpretable decision-mechanism on which we can
intervene to control its behavior. Taken together, these capabilities
comprehensively demonstrate the benefits of an explicit visual memory. We hope
that it might contribute to a conversation on how knowledge should be
represented in deep vision models -- beyond carving it in ``stone'' weights.

ÊëòË¶ÅÔºöËÆ≠ÁªÉÁ•ûÁªèÁΩëÁªúÊòØ‰∏ÄÈ°πÊï¥‰ΩìÊÄßÁöÑÂ∑•‰ΩúÔºåÂ∞±ÂÉèÂ∞ÜÁü•ËØÜÂàªÂú®Áü≥Â§¥‰∏äÔºö‰∏ÄÊó¶ÂÆåÊàêËØ•ËøáÁ®ãÔºåÂ∞±Âá†‰πé‰∏çÂèØËÉΩÁºñËæëÁΩëÁªú‰∏≠ÁöÑÁü•ËØÜÔºåÂõ†‰∏∫ÊâÄÊúâ‰ø°ÊÅØÈÉΩÂàÜÂ∏ÉÂú®ÁΩëÁªúÁöÑÊùÉÈáç‰∏≠„ÄÇÊàë‰ª¨Âú®ËøôÈáåÈÄöËøáÂ∞ÜÊ∑±Â∫¶Á•ûÁªèÁΩëÁªúÁöÑË°®ÂæÅËÉΩÂäõ‰∏éÊï∞ÊçÆÂ∫ìÁöÑÁÅµÊ¥ªÊÄßÁõ∏ÁªìÂêàÔºåÊé¢Á¥¢‰∏ÄÁßçÁÆÄÂçïËÄåÊúâÂê∏ÂºïÂäõÁöÑÊõø‰ª£ÊñπÊ°à„ÄÇÂ∞ÜÂõæÂÉèÂàÜÁ±ª‰ªªÂä°ÂàÜËß£‰∏∫ÂõæÂÉèÁõ∏‰ººÊÄßÔºàÊù•Ëá™È¢ÑËÆ≠ÁªÉÂµåÂÖ•ÔºâÂíåÊêúÁ¥¢ÔºàÈÄöËøá‰ªéÁü•ËØÜÊï∞ÊçÆÂ∫ì‰∏≠Âø´ÈÄüÊ£ÄÁ¥¢ÊúÄËøëÈÇªÔºâÔºåÊàë‰ª¨ÊûÑÂª∫‰∫Ü‰∏Ä‰∏™ÁÆÄÂçïËÄåÁÅµÊ¥ªÁöÑËßÜËßâËÆ∞ÂøÜÔºåÂÆÉÂÖ∑Êúâ‰ª•‰∏ãÂÖ≥ÈîÆÂäüËÉΩÔºö(1.) ËÉΩÂ§üÁÅµÊ¥ªÂú∞Ë∑®Â∞∫Â∫¶Ê∑ªÂä†Êï∞ÊçÆÔºö‰ªéÂçï‰∏™Ê†∑Êú¨Âà∞Êï¥‰∏™Á±ªÂà´ÂíåÊï∞ÂçÅ‰∫øËßÑÊ®°ÁöÑÊï∞ÊçÆÔºõ(2.) ËÉΩÂ§üÈÄöËøáÂèñÊ∂àÂ≠¶‰π†ÂíåÂÜÖÂ≠òÂâ™ÊûùÊù•Âà†Èô§Êï∞ÊçÆÔºõ(3.) ‰∏ÄÁßçÂèØËß£ÈáäÁöÑÂÜ≥Á≠ñÊú∫Âà∂ÔºåÊàë‰ª¨ÂèØ‰ª•Âπ≤È¢ÑÂÆÉ‰ª•ÊéßÂà∂ÂÖ∂Ë°å‰∏∫„ÄÇÁªºÂêàËµ∑Êù•ÔºåËøô‰∫õÂäüËÉΩÂÖ®Èù¢Â±ïÁ§∫‰∫ÜÊòæÂºèËßÜËßâËÆ∞ÂøÜÁöÑÂ•ΩÂ§Ñ„ÄÇÊàë‰ª¨Â∏åÊúõÂÆÉÂèØ‰ª•‰øÉËøõÂÖ≥‰∫éÁü•ËØÜÂ¶Ç‰ΩïÂú®Ê∑±Â∫¶ËßÜËßâÊ®°Âûã‰∏≠Ë°®Á§∫ÁöÑÂØπËØù‚Äî‚Äî‰∏ç‰ªÖ‰ªÖÊòØÂ∞ÜÂÖ∂ÂàªÂú®‚ÄúÁü≥Â§¥‚ÄùÊùÉÈáç‰∏≠„ÄÇ

##### **General-purpose Clothes Manipulation with Semantic Keypoints**
2408.08160v1 by Yuhong Deng, David Hsu

We have seen much recent progress in task-specific clothes manipulation, but
generalizable clothes manipulation is still a challenge. Clothes manipulation
requires sequential actions, making it challenging to generalize to unseen
tasks. Besides, a general clothes state representation method is crucial. In
this paper, we adopt language instructions to specify and decompose clothes
manipulation tasks, and propose a large language model based hierarchical
learning method to enhance generalization. For state representation, we use
semantic keypoints to capture the geometry of clothes and outline their
manipulation methods. Simulation experiments show that the proposed method
outperforms the baseline method in terms of success rate and generalization for
clothes manipulation tasks.

ÊëòË¶ÅÔºöÊàëÂÄëÂ∑≤Á∂ìÂú®ÁâπÂÆö‰ªªÂãôÁöÑÊúçË£ùÊìç‰Ωú‰∏≠ÁúãÂà∞Ë®±Â§öËøëÊúüÁöÑÈÄ≤Ê≠•Ôºå‰ΩÜÂèØÊ¶ÇÂåñÁöÑÊúçË£ùÊìç‰Ωú‰ªçÁÑ∂ÊòØ‰∏ÄÈ†ÖÊåëÊà∞„ÄÇÊúçË£ùÊìç‰ΩúÈúÄË¶ÅÂæ™Â∫èÊº∏ÈÄ≤ÁöÑÂãï‰ΩúÔºåÈÄô‰ΩøÂæóÊ¶ÇÂåñÂà∞Êú™Ë¶ãÈÅéÁöÑ‰ªªÂãôËÆäÂæóÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÊ≠§Â§ñÔºå‰∏ÄÂÄãÈÄöÁî®ÁöÑÊúçË£ùÁãÄÊÖãË°®Á§∫ÊñπÊ≥ïËá≥ÈóúÈáçË¶Å„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊé°Áî®Ë™ûË®ÄÊåá‰ª§‰æÜÊåáÂÆöÂíåÂàÜËß£ÊúçË£ùÊìç‰Ωú‰ªªÂãôÔºå‰∏¶ÊèêÂá∫‰∏ÄÂÄãÂü∫ÊñºÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÁöÑÂàÜÂ±§Â≠∏ÁøíÊñπÊ≥ï‰æÜÂ¢ûÂº∑Ê¶ÇÂåñ„ÄÇÂ∞çÊñºÁãÄÊÖãË°®Á§∫ÔºåÊàëÂÄë‰ΩøÁî®Ë™ûÁæ©ÈóúÈçµÈªû‰æÜÊçïÊçâÊúçË£ùÁöÑÂπæ‰ΩïÂΩ¢ÁãÄÔºå‰∏¶Ê¶ÇËø∞ÂÖ∂Êìç‰ΩúÊñπÊ≥ï„ÄÇÊ®°Êì¨ÂØ¶È©óË°®ÊòéÔºåÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÂú®ÊàêÂäüÁéáÂíåÊúçË£ùÊìç‰Ωú‰ªªÂãôÁöÑÊ¶ÇÂåñÊñπÈù¢ÂÑ™ÊñºÂü∫Á∑öÊñπÊ≥ï„ÄÇ

##### **DeepSeek-Prover-V1.5: Harnessing Proof Assistant Feedback for Reinforcement Learning and Monte-Carlo Tree Search**
2408.08152v1 by Huajian Xin, Z. Z. Ren, Junxiao Song, Zhihong Shao, Wanjia Zhao, Haocheng Wang, Bo Liu, Liyue Zhang, Xuan Lu, Qiushi Du, Wenjun Gao, Qihao Zhu, Dejian Yang, Zhibin Gou, Z. F. Wu, Fuli Luo, Chong Ruan

We introduce DeepSeek-Prover-V1.5, an open-source language model designed for
theorem proving in Lean 4, which enhances DeepSeek-Prover-V1 by optimizing both
training and inference processes. Pre-trained on DeepSeekMath-Base with
specialization in formal mathematical languages, the model undergoes supervised
fine-tuning using an enhanced formal theorem proving dataset derived from
DeepSeek-Prover-V1. Further refinement is achieved through reinforcement
learning from proof assistant feedback (RLPAF). Beyond the single-pass
whole-proof generation approach of DeepSeek-Prover-V1, we propose RMaxTS, a
variant of Monte-Carlo tree search that employs an intrinsic-reward-driven
exploration strategy to generate diverse proof paths. DeepSeek-Prover-V1.5
demonstrates significant improvements over DeepSeek-Prover-V1, achieving new
state-of-the-art results on the test set of the high school level miniF2F
benchmark ($63.5\%$) and the undergraduate level ProofNet benchmark ($25.3\%$).

ÊëòË¶ÅÔºöÊàëÂÄëÊé®Âá∫ DeepSeek-Prover-V1.5ÔºåÈÄôÊòØ‰∏ÄÂÄãÈñãÊîæÂéüÂßãÁ¢ºË™ûË®ÄÊ®°ÂûãÔºåÂ∞àÁÇ∫ Lean 4 ‰∏≠ÁöÑÂÆöÁêÜË≠âÊòéËÄåË®≠Ë®àÔºåÈÄèÈÅéÊúÄ‰Ω≥ÂåñË®ìÁ∑¥ÂíåÊé®Ë´ñÊµÅÁ®ã‰æÜÂ¢ûÂº∑ DeepSeek-Prover-V1„ÄÇÈ†êÂÖàË®ìÁ∑¥Êñº DeepSeekMath-Base ‰∏≠ÔºåÂ∞àÁ≤æÊñºÂΩ¢ÂºèÂåñÊï∏Â≠∏Ë™ûË®ÄÔºåË©≤Ê®°Âûã‰ΩøÁî®Âæû DeepSeek-Prover-V1 Ë°çÁîüÁöÑÂ¢ûÂº∑ÂºèÂΩ¢ÂºèÂåñÂÆöÁêÜË≠âÊòéË≥áÊñôÈõÜÈÄ≤Ë°åÁõ£Áù£ÂºèÂæÆË™ø„ÄÇÈÄèÈÅéË≠âÊòéËºîÂä©ÂõûÈ•ãÔºàRLPAFÔºâ‰∏≠ÁöÑÂº∑ÂåñÂ≠∏ÁøíÈÄ≤‰∏ÄÊ≠•Á≤æÈÄ≤„ÄÇÈô§‰∫Ü DeepSeek-Prover-V1 ÁöÑÂñÆÊ¨°ÂÖ®Ë≠âÊòéÁî¢ÁîüÊñπÊ≥ïÂ§ñÔºåÊàëÂÄëÊèêÂá∫ RMaxTSÔºå‰∏ÄÁ®ÆËíôÂú∞Âç°ÁæÖÊ®πÊêúÂ∞ãÁöÑËÆäÈ´îÔºåÊé°Áî®ÂÖßÂú®ÂõûÈ•ãÈ©ÖÂãïÁöÑÊé¢Á¥¢Á≠ñÁï•‰æÜÁî¢ÁîüÂ§öÊ®£ÂåñÁöÑË≠âÊòéË∑ØÂæë„ÄÇDeepSeek-Prover-V1.5 Ë≠âÊòé‰∫ÜÁõ∏ËºÉÊñº DeepSeek-Prover-V1 ÊúâÈ°ØËëóÁöÑÈÄ≤Ê≠•ÔºåÂú®È´ò‰∏≠Á®ãÂ∫¶ÁöÑ miniF2F Âü∫Ê∫ñÊ∏¨Ë©¶ÁµÑ‰∏≠ÂèñÂæóÊñ∞ÁöÑÊúÄÂÖàÈÄ≤ÊàêÊûúÔºà63.5%ÔºâÔºå‰ª•ÂèäÂ§ßÂ≠∏Á®ãÂ∫¶ÁöÑ ProofNet Âü∫Ê∫ñÊ∏¨Ë©¶ÁµÑ‰∏≠Ôºà25.3%Ôºâ„ÄÇ


### Medical
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-08-16**|**A Disease-Specific Foundation Model Using Over 100K Fundus Images: Release and Validation for Abnormality and Multi-Disease Classification on Downstream Tasks**|Boa Jang et.al.|[2408.08790v1](http://arxiv.org/abs/2408.08790v1)|[link](https://github.com/Jang-Boa/Research-Foundation-Retina)|
|**2024-08-16**|**Beyond the Hype: A dispassionate look at vision-language models in medical scenario**|Yang Nan et.al.|[2408.08704v1](http://arxiv.org/abs/2408.08704v1)|null|
|**2024-08-16**|**TextCAVs: Debugging vision models using text**|Angus Nicolson et.al.|[2408.08652v1](http://arxiv.org/abs/2408.08652v1)|[link](https://github.com/angusnicolson/textcavs)|
|**2024-08-16**|**RealMedQA: A pilot biomedical question answering dataset containing realistic clinical questions**|Gregory Kell et.al.|[2408.08624v1](http://arxiv.org/abs/2408.08624v1)|null|
|**2024-08-16**|**Focus on Focus: Focus-oriented Representation Learning and Multi-view Cross-modal Alignment for Glioma Grading**|Li Pan et.al.|[2408.08527v1](http://arxiv.org/abs/2408.08527v1)|[link](https://github.com/peterlipan/fof)|
|**2024-08-16**|**Adversarial Contrastive Learning Based Physics-Informed Temporal Networks for Cuffless Blood Pressure Estimation**|Rui Wang et.al.|[2408.08488v1](http://arxiv.org/abs/2408.08488v1)|null|
|**2024-08-15**|**Efficient Data-Sketches and Fine-Tuning for Early Detection of Distributional Drift in Medical Imaging**|Yusen Wu et.al.|[2408.08456v1](http://arxiv.org/abs/2408.08456v1)|null|
|**2024-08-15**|**Predictive uncertainty estimation in deep learning for lung carcinoma classification in digital pathology under real dataset shifts**|Abdur R. Fayjie et.al.|[2408.08432v1](http://arxiv.org/abs/2408.08432v1)|null|
|**2024-08-15**|**Assessing and Enhancing Large Language Models in Rare Disease Question-answering**|Guanchu Wang et.al.|[2408.08422v1](http://arxiv.org/abs/2408.08422v1)|null|
|**2024-08-15**|**Decoding the human brain tissue response to radiofrequency excitation using a biophysical-model-free deep MRI on a chip framework**|Dinor Nagar et.al.|[2408.08376v1](http://arxiv.org/abs/2408.08376v1)|null|
|**2024-08-15**|**InVAErt networks for amortized inference and identifiability analysis of lumped parameter hemodynamic models**|Guoxiang Grayson Tong et.al.|[2408.08264v1](http://arxiv.org/abs/2408.08264v1)|[link](https://github.com/desreslab/invaert4cardio)|
|**2024-08-15**|**Your Turn: Real-World Turning Angle Estimation for Parkinson's Disease Severity Assessment**|Qiushuo Cheng et.al.|[2408.08182v1](http://arxiv.org/abs/2408.08182v1)|null|
|**2024-08-15**|**Navigating Data Scarcity using Foundation Models: A Benchmark of Few-Shot and Zero-Shot Learning Approaches in Medical Imaging**|Stefano Woerner et.al.|[2408.08058v1](http://arxiv.org/abs/2408.08058v1)|null|
|**2024-08-15**|**Adaptive User Journeys in Pharma E-Commerce with Reinforcement Learning: Insights from SwipeRx**|Ana Fern√°ndez del R√≠o et.al.|[2408.08024v1](http://arxiv.org/abs/2408.08024v1)|null|
|**2024-08-15**|**LLaVA-Surg: Towards Multimodal Surgical Assistant via Structured Surgical Video Learning**|Jiajie Li et.al.|[2408.07981v1](http://arxiv.org/abs/2408.07981v1)|null|
|**2024-08-14**|**Enhancing Equitable Access to AI in Housing and Homelessness System of Care through Federated Learning**|Musa Taib et.al.|[2408.07845v1](http://arxiv.org/abs/2408.07845v1)|null|
|**2024-08-14**|**Deep Learning: a Heuristic Three-stage Mechanism for Grid Searches to Optimize the Future Risk Prediction of Breast Cancer Metastasis Using EHR-based Clinical Data**|Xia Jiang et.al.|[2408.07673v2](http://arxiv.org/abs/2408.07673v2)|null|
|**2024-08-14**|**Adaptive Behavioral AI: Reinforcement Learning to Enhance Pharmacy Services**|Ana Fern√°ndez del R√≠o et.al.|[2408.07647v1](http://arxiv.org/abs/2408.07647v1)|null|
|**2024-08-14**|**Optimizing HIV Patient Engagement with Reinforcement Learning in Resource-Limited Settings**|√Åfrica Peri√°√±ez et.al.|[2408.07629v1](http://arxiv.org/abs/2408.07629v1)|null|
|**2024-08-14**|**MetaSeg: MetaFormer-based Global Contexts-aware Network for Efficient Semantic Segmentation**|Beoungwoo Kang et.al.|[2408.07576v2](http://arxiv.org/abs/2408.07576v2)|[link](https://github.com/hyunwoo137/metaseg)|
|**2024-08-14**|**Multi-task Heterogeneous Graph Learning on Electronic Health Records**|Tsai Hor Chan et.al.|[2408.07569v1](http://arxiv.org/abs/2408.07569v1)|[link](https://github.com/hku-medai/mult-ehr)|
|**2024-08-14**|**Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**|Seungjun Han et.al.|[2408.07531v1](http://arxiv.org/abs/2408.07531v1)|null|
|**2024-08-14**|**Improving Global Parameter-sharing in Physically Heterogeneous Multi-agent Reinforcement Learning with Unified Action Space**|Xiaoyang Yu et.al.|[2408.07395v1](http://arxiv.org/abs/2408.07395v1)|null|
|**2024-08-14**|**The Complexity of Manipulation of k-Coalitional Games on Graphs**|Hodaya Barr et.al.|[2408.07368v1](http://arxiv.org/abs/2408.07368v1)|[link](https://github.com/hodayaBen/The-Complexity-of-Manipulation-of-k-Coalitional-Games-on-Graphs)|
|**2024-08-13**|**Model Counting in the Wild**|Arijit Shaw et.al.|[2408.07059v1](http://arxiv.org/abs/2408.07059v1)|null|
|**2024-08-13**|**KAN You See It? KANs and Sentinel for Effective and Explainable Crop Field Segmentation**|Daniele Rege Cambrin et.al.|[2408.07040v1](http://arxiv.org/abs/2408.07040v1)|[link](https://github.com/darthreca/crop-field-segmentation-ukan)|
|**2024-08-13**|**PathInsight: Instruction Tuning of Multimodal Datasets and Models for Intelligence Assisted Diagnosis in Histopathology**|Xiaomin Wu et.al.|[2408.07037v1](http://arxiv.org/abs/2408.07037v1)|null|
|**2024-08-13**|**Diagnosis extraction from unstructured Dutch echocardiogram reports using span- and document-level characteristic classification**|Bauke Arends et.al.|[2408.06930v2](http://arxiv.org/abs/2408.06930v2)|[link](https://github.com/umcu/echolabeler)|
|**2024-08-13**|**BMFT: Achieving Fairness via Bias-based Weight Masking Fine-tuning**|Yuyang Xue et.al.|[2408.06890v1](http://arxiv.org/abs/2408.06890v1)|null|
|**2024-08-12**|**Synthetic Patient-Physician Dialogue Generation from Clinical Notes Using LLM**|Trisha Das et.al.|[2408.06285v1](http://arxiv.org/abs/2408.06285v1)|null|
|**2024-08-12**|**Decentralized Health Intelligence Network (DHIN)**|Abraham Nash et.al.|[2408.06240v3](http://arxiv.org/abs/2408.06240v3)|null|
|**2024-08-12**|**ACCELERATION: Sequentially-scanning DECT Imaging Using High Temporal Resolution Image Reconstruction And Temporal Extrapolation**|Qiaoxin Li et.al.|[2408.06163v1](http://arxiv.org/abs/2408.06163v1)|null|
|**2024-08-12**|**Med42-v2: A Suite of Clinical LLMs**|Cl√©ment Christophe et.al.|[2408.06142v1](http://arxiv.org/abs/2408.06142v1)|null|
|**2024-08-11**|**Real-Time Drowsiness Detection Using Eye Aspect Ratio and Facial Landmark Detection**|Varun Shiva Krishna Rupani et.al.|[2408.05836v1](http://arxiv.org/abs/2408.05836v1)|null|
|**2024-08-11**|**TC-KANRecon: High-Quality and Accelerated MRI Reconstruction via Adaptive KAN Mechanisms and Intelligent Feature Scaling**|Ruiquan Ge et.al.|[2408.05705v1](http://arxiv.org/abs/2408.05705v1)|[link](https://github.com/lcbkmm/tc-kanrecon)|
|**2024-08-11**|**A Novel Momentum-Based Deep Learning Techniques for Medical Image Classification and Segmentation**|Koushik Biswas et.al.|[2408.05692v1](http://arxiv.org/abs/2408.05692v1)|null|
|**2024-08-10**|**Mitigating Metropolitan Carbon Emissions with Dynamic Eco-driving at Scale**|Vindula Jayawardana et.al.|[2408.05609v1](http://arxiv.org/abs/2408.05609v1)|null|
|**2024-08-09**|**Beyond the Eye: A Relational Model for Early Dementia Detection Using Retinal OCTA Images**|Shouyue Liu et.al.|[2408.05117v1](http://arxiv.org/abs/2408.05117v1)|null|
|**2024-08-09**|**RT-Surv: Improving Mortality Prediction After Radiotherapy with Large Language Model Structuring of Large-Scale Unstructured Electronic Health Records**|Sangjoon Park et.al.|[2408.05074v2](http://arxiv.org/abs/2408.05074v2)|null|
|**2024-08-09**|**CROCODILE: Causality aids RObustness via COntrastive DIsentangled LEarning**|Gianluca Carloni et.al.|[2408.04949v1](http://arxiv.org/abs/2408.04949v1)|[link](https://github.com/gianlucarloni/crocodile)|
|**2024-08-09**|**Unleashing Artificial Cognition: Integrating Multiple AI Systems**|Muntasir Adnan et.al.|[2408.04910v3](http://arxiv.org/abs/2408.04910v3)|[link](https://github.com/TheOpenSI/cognitive_AI_experiments)|
|**2024-08-09**|**Ensemble BERT: A student social network text sentiment classification model based on ensemble learning and BERT architecture**|Kai Jiang et.al.|[2408.04849v1](http://arxiv.org/abs/2408.04849v1)|null|
|**2024-08-08**|**Towards Synergistic Deep Learning Models for Volumetric Cirrhotic Liver Segmentation in MRIs**|Vandan Gorade et.al.|[2408.04491v1](http://arxiv.org/abs/2408.04491v1)|null|
|**2024-08-08**|**Advancing oncology with federated learning: transcending boundaries in breast, lung, and prostate cancer. A systematic review**|Anshu Ankolekar et.al.|[2408.05249v1](http://arxiv.org/abs/2408.05249v1)|null|
|**2024-08-08**|**Non-maximizing policies that fulfill multi-criterion aspirations in expectation**|Simon Dima et.al.|[2408.04385v1](http://arxiv.org/abs/2408.04385v1)|null|
|**2024-08-08**|**AI-Driven Chatbot for Intrusion Detection in Edge Networks: Enhancing Cybersecurity with Ethical User Consent**|Mugheez Asif et.al.|[2408.04281v1](http://arxiv.org/abs/2408.04281v1)|null|
|**2024-08-08**|**Dynamic Fog Computing for Enhanced LLM Execution in Medical Applications**|Philipp Zagar et.al.|[2408.04680v1](http://arxiv.org/abs/2408.04680v1)|null|
|**2024-08-08**|**Dynamic Hypergraph-Enhanced Prediction of Sequential Medical Visits**|Wangying Yang et.al.|[2408.07084v1](http://arxiv.org/abs/2408.07084v1)|null|
|**2024-08-08**|**The Data Addition Dilemma**|Judy Hanwen Shen et.al.|[2408.04154v1](http://arxiv.org/abs/2408.04154v1)|[link](https://github.com/the-chen-lab/data-addition-dilemma)|
|**2024-08-08**|**Enhancing Healthcare through Large Language Models: A Study on Medical Question Answering**|Haoran Yu et.al.|[2408.04138v1](http://arxiv.org/abs/2408.04138v1)|null|
|**2024-08-07**|**Can Rule-Based Insights Enhance LLMs for Radiology Report Classification? Introducing the RadPrompt Methodology**|Panagiotis Fytas et.al.|[2408.04121v1](http://arxiv.org/abs/2408.04121v1)|null|
|**2024-08-07**|**Handwritten Code Recognition for Pen-and-Paper CS Education**|Md Sazzad Islam et.al.|[2408.07220v1](http://arxiv.org/abs/2408.07220v1)|[link](https://github.com/mdoumbouya/codeocr)|
|**2024-08-07**|**Multimodal Gender Fairness in Depression Prediction: Insights on Data from the USA & China**|Joseph Cameron et.al.|[2408.04026v1](http://arxiv.org/abs/2408.04026v1)|null|
|**2024-08-07**|**Inter-Series Transformer: Attending to Products in Time Series Forecasting**|Rares Cristian et.al.|[2408.03872v1](http://arxiv.org/abs/2408.03872v1)|null|
|**2024-08-07**|**Anatomical Foundation Models for Brain MRIs**|Carlo Alberto Barbano et.al.|[2408.07079v1](http://arxiv.org/abs/2408.07079v1)|null|
|**2024-08-07**|**HiQuE: Hierarchical Question Embedding Network for Multimodal Depression Detection**|Juho Jung et.al.|[2408.03648v1](http://arxiv.org/abs/2408.03648v1)|[link](https://github.com/JuHo-Jung/HiQuE)|
|**2024-08-07**|**Improving the quality of Persian clinical text with a novel spelling correction system**|Seyed Mohammad Sadegh Dashti et.al.|[2408.03622v1](http://arxiv.org/abs/2408.03622v1)|null|
|**2024-08-06**|**Identifying treatment response subgroups in observational time-to-event data**|Vincent Jeanselme et.al.|[2408.03463v1](http://arxiv.org/abs/2408.03463v1)|[link](https://github.com/Jeanselme/CausalNeuralSurvivalClustering)|
|**2024-08-06**|**Combining Diverse Information for Coordinated Action: Stochastic Bandit Algorithms for Heterogeneous Agents**|Lucia Gordon et.al.|[2408.03405v1](http://arxiv.org/abs/2408.03405v1)|[link](https://github.com/lgordon99/heterogeneous-stochastic-bandits)|
|**2024-08-06**|**MLC-GCN: Multi-Level Generated Connectome Based GCN for AD Analysis**|Wenqi Zhu et.al.|[2408.03358v1](http://arxiv.org/abs/2408.03358v1)|null|
|**2024-08-06**|**Personalizing Federated Instrument Segmentation with Visual Trait Priors in Robotic Surgery**|Jialang Xu et.al.|[2408.03208v2](http://arxiv.org/abs/2408.03208v2)|null|
|**2024-08-06**|**The Use of Large Language Models (LLM) for Cyber Threat Intelligence (CTI) in Cybercrime Forums**|Vanessa Clairoux-Trepanier et.al.|[2408.03354v2](http://arxiv.org/abs/2408.03354v2)|null|
|**2024-08-06**|**VizECGNet: Visual ECG Image Network for Cardiovascular Diseases Classification with Multi-Modal Training and Knowledge Distillation**|Ju-Hyeon Nam et.al.|[2408.02888v1](http://arxiv.org/abs/2408.02888v1)|null|
|**2024-08-05**|**VisionUnite: A Vision-Language Foundation Model for Ophthalmology Enhanced with Clinical Knowledge**|Zihan Li et.al.|[2408.02865v1](http://arxiv.org/abs/2408.02865v1)|[link](https://github.com/HUANGLIZI/VisionUnite)|
|**2024-08-05**|**Multistain Pretraining for Slide Representation Learning in Pathology**|Guillaume Jaume et.al.|[2408.02859v1](http://arxiv.org/abs/2408.02859v1)|[link](https://github.com/mahmoodlab/madeleine)|
|**2024-08-05**|**The Literature Review Network: An Explainable Artificial Intelligence for Systematic Literature Reviews, Meta-analyses, and Method Development**|Joshua Morriss et.al.|[2408.05239v1](http://arxiv.org/abs/2408.05239v1)|null|
|**2024-08-05**|**A Review on Organ Deformation Modeling Approaches for Reliable Surgical Navigation using Augmented Reality**|Zheng Han et.al.|[2408.02713v1](http://arxiv.org/abs/2408.02713v1)|null|
|**2024-08-05**|**Enhancing Medical Learning and Reasoning Systems: A Boxology-Based Comparative Analysis of Design Patterns**|Chi Him Ng et.al.|[2408.02709v1](http://arxiv.org/abs/2408.02709v1)|null|
|**2024-08-05**|**Bayesian Kolmogorov Arnold Networks (Bayesian_KANs): A Probabilistic Approach to Enhance Accuracy and Interpretability**|Masoud Muhammed Hassan et.al.|[2408.02706v1](http://arxiv.org/abs/2408.02706v1)|null|
|**2024-08-05**|**Active Sensing of Knee Osteoarthritis Progression with Reinforcement Learning**|Khanh Nguyen et.al.|[2408.02349v2](http://arxiv.org/abs/2408.02349v2)|null|
|**2024-08-04**|**MetaWearS: A Shortcut in Wearable Systems Lifecycle with Only a Few Shots**|Alireza Amirshahi et.al.|[2408.01988v1](http://arxiv.org/abs/2408.01988v1)|null|
|**2024-08-04**|**DiReCT: Diagnostic Reasoning for Clinical Notes via Large Language Models**|Bowen Wang et.al.|[2408.01933v2](http://arxiv.org/abs/2408.01933v2)|null|
|**2024-08-03**|**MALADE: Orchestration of LLM-powered Agents with Retrieval Augmented Generation for Pharmacovigilance**|Jihye Choi et.al.|[2408.01869v1](http://arxiv.org/abs/2408.01869v1)|[link](https://github.com/jihyechoi77/malade)|
|**2024-08-03**|**Building Trust in Mental Health Chatbots: Safety Metrics and LLM-Based Evaluation Tools**|Jung In Park et.al.|[2408.04650v1](http://arxiv.org/abs/2408.04650v1)|null|
|**2024-08-03**|**ST-SACLF: Style Transfer Informed Self-Attention Classifier for Bias-Aware Painting Classification**|Mridula Vijendran et.al.|[2408.01827v1](http://arxiv.org/abs/2408.01827v1)|[link](https://github.com/41enthusiast/ST-SACLF-ver1.1)|
|**2024-08-03**|**Advancing Mental Health Pre-Screening: A New Custom GPT for Psychological Distress Assessment**|Jinwen Tang et.al.|[2408.01614v1](http://arxiv.org/abs/2408.01614v1)|null|
|**2024-08-02**|**Conformal Diffusion Models for Individual Treatment Effect Estimation and Inference**|Hengrui Cai et.al.|[2408.01582v1](http://arxiv.org/abs/2408.01582v1)|null|
|**2024-08-02**|**High-Throughput Phenotyping of Clinical Text Using Large Language Models**|Daniel B. Hier et.al.|[2408.01214v1](http://arxiv.org/abs/2408.01214v1)|null|
|**2024-08-02**|**Optimizing Variational Quantum Circuits Using Metaheuristic Strategies in Reinforcement Learning**|Michael K√∂lle et.al.|[2408.01187v1](http://arxiv.org/abs/2408.01187v1)|null|
|**2024-08-02**|**Six Dragons Fly Again: Reviving 15th-Century Korean Court Music with Transformers and Novel Encoding**|Danbinaerin Han et.al.|[2408.01096v1](http://arxiv.org/abs/2408.01096v1)|null|
|**2024-08-01**|**CIResDiff: A Clinically-Informed Residual Diffusion Model for Predicting Idiopathic Pulmonary Fibrosis Progression**|Caiwen Jiang et.al.|[2408.00938v2](http://arxiv.org/abs/2408.00938v2)|null|
|**2024-08-01**|**Parkinson's Disease Detection from Resting State EEG using Multi-Head Graph Structure Learning with Gradient Weighted Graph Attention Explanations**|Christopher Neves et.al.|[2408.00906v1](http://arxiv.org/abs/2408.00906v1)|null|
|**2024-08-01**|**UlRe-NeRF: 3D Ultrasound Imaging through Neural Rendering with Ultrasound Reflection Direction Parameterization**|Ziwen Guo et.al.|[2408.00860v2](http://arxiv.org/abs/2408.00860v2)|null|
|**2024-08-01**|**Segment anything model 2: an application to 2D and 3D medical images**|Haoyu Dong et.al.|[2408.00756v2](http://arxiv.org/abs/2408.00756v2)|null|
|**2024-08-01**|**Leaf Angle Estimation using Mask R-CNN and LETR Vision Transformer**|Venkat Margapuri et.al.|[2408.00749v1](http://arxiv.org/abs/2408.00749v1)|null|
|**2024-08-01**|**Improving Retrieval-Augmented Generation in Medicine with Iterative Follow-up Questions**|Guangzhi Xiong et.al.|[2408.00727v1](http://arxiv.org/abs/2408.00727v1)|null|
|**2024-08-01**|**Point-supervised Brain Tumor Segmentation with Box-prompted MedSAM**|Xiaofeng Liu et.al.|[2408.00706v1](http://arxiv.org/abs/2408.00706v1)|null|
|**2024-08-01**|**HBot: A Chatbot for Healthcare Applications in Traditional Chinese Medicine Based on Human Body 3D Visualization**|Bolin Zhang et.al.|[2408.00481v1](http://arxiv.org/abs/2408.00481v1)|null|
|**2024-08-01**|**Securing the Diagnosis of Medical Imaging: An In-depth Analysis of AI-Resistant Attacks**|Angona Biswas et.al.|[2408.00348v1](http://arxiv.org/abs/2408.00348v1)|null|
|**2024-08-01**|**Advancing Medical Image Segmentation: Morphology-Driven Learning with Diffusion Transformer**|Sungmin Kang et.al.|[2408.00347v1](http://arxiv.org/abs/2408.00347v1)|null|
|**2024-07-31**|**S-SYNTH: Knowledge-Based, Synthetic Generation of Skin Images**|Andrea Kim et.al.|[2408.00191v1](http://arxiv.org/abs/2408.00191v1)|[link](https://github.com/DIDSR/ssynth-release)|
|**2024-07-31**|**A Taxonomy of Stereotype Content in Large Language Models**|Gandalf Nicolas et.al.|[2408.00162v1](http://arxiv.org/abs/2408.00162v1)|null|
|**2024-07-31**|**Preference-Based Abstract Argumentation for Case-Based Reasoning (with Appendix)**|Adam Gould et.al.|[2408.00108v2](http://arxiv.org/abs/2408.00108v2)|null|
|**2024-07-31**|**A Federated Learning-Friendly Approach for Parameter-Efficient Fine-Tuning of SAM in 3D Segmentation**|Mothilal Asokan et.al.|[2407.21739v1](http://arxiv.org/abs/2407.21739v1)|null|
|**2024-07-31**|**Synthetic Simplicity: Unveiling Bias in Medical Data Augmentation**|Krishan Agyakari Raja Babu et.al.|[2407.21674v1](http://arxiv.org/abs/2407.21674v1)|null|
|**2024-07-31**|**Quality Control for Radiology Report Generation Models via Auxiliary Auditing Components**|Hermione Warr et.al.|[2407.21638v1](http://arxiv.org/abs/2407.21638v1)|null|
|**2024-07-31**|**Optimizing Disease Prediction with Artificial Intelligence Driven Feature Selection and Attention Networks**|D. Dhinakaran et.al.|[2408.03151v1](http://arxiv.org/abs/2408.03151v1)|null|
|**2024-07-31**|**Voxel Scene Graph for Intracranial Hemorrhage**|Antoine P. Sanner et.al.|[2407.21580v1](http://arxiv.org/abs/2407.21580v1)|null|
|**2024-07-31**|**Expanding the Medical Decathlon dataset: segmentation of colon and colorectal cancer from computed tomography images**|I. M. Chernenkiy et.al.|[2407.21516v1](http://arxiv.org/abs/2407.21516v1)|null|
|**2024-07-31**|**Explainable and Controllable Motion Curve Guided Cardiac Ultrasound Video Generation**|Junxuan Yu et.al.|[2407.21490v1](http://arxiv.org/abs/2407.21490v1)|null|

#### Abstracts
##### **A Disease-Specific Foundation Model Using Over 100K Fundus Images: Release and Validation for Abnormality and Multi-Disease Classification on Downstream Tasks**
2408.08790v1 by Boa Jang, Youngbin Ahn, Eun Kyung Choe, Chang Ki Yoon, Hyuk Jin Choi, Young-Gon Kim

Artificial intelligence applied to retinal images offers significant
potential for recognizing signs and symptoms of retinal conditions and
expediting the diagnosis of eye diseases and systemic disorders. However,
developing generalized artificial intelligence models for medical data often
requires a large number of labeled images representing various disease signs,
and most models are typically task-specific, focusing on major retinal
diseases. In this study, we developed a Fundus-Specific Pretrained Model
(Image+Fundus), a supervised artificial intelligence model trained to detect
abnormalities in fundus images. A total of 57,803 images were used to develop
this pretrained model, which achieved superior performance across various
downstream tasks, indicating that our proposed model outperforms other general
methods. Our Image+Fundus model offers a generalized approach to improve model
performance while reducing the number of labeled datasets required.
Additionally, it provides more disease-specific insights into fundus images,
with visualizations generated by our model. These disease-specific foundation
models are invaluable in enhancing the performance and efficiency of deep
learning models in the field of fundus imaging.

ÊëòË¶ÅÔºö‰∫∫Â∑•Êô∫ÊÖßÊáâÁî®ÊñºË¶ñÁ∂≤ËÜúÂΩ±ÂÉèÔºåÂú®Ëæ®Ë≠òË¶ñÁ∂≤ËÜúÁóÖËÆäÁöÑÂæµÂÖÜÂíåÁóáÁãÄÔºå‰ª•ÂèäÂä†ÈÄüË®∫Êñ∑ÁúºÁñæÂíåÂÖ®Ë∫´ÊÄßÁñæÁóÖÊñπÈù¢ÔºåÊúâÈ°ØËëóÁöÑÊΩõÂäõ„ÄÇÁÑ∂ËÄåÔºåÁÇ∫ÈÜ´ÁôÇË≥áÊñôÈñãÁôºÂª£Ê≥õÁöÑ‰∫∫Â∑•Êô∫ÊÖßÊ®°ÂûãÔºåÈÄöÂ∏∏ÈúÄË¶ÅÂ§ßÈáè‰ª£Ë°®ÂêÑÁ®ÆÁñæÁóÖÂæµÂÖÜÁöÑÊ®ôÁ±§ÂΩ±ÂÉèÔºåËÄå‰∏îÂ§ßÂ§öÊï∏Ê®°ÂûãÈÄöÂ∏∏ÊòØÈáùÂ∞çÁâπÂÆö‰ªªÂãôÔºåÂ∞àÊ≥®Êñº‰∏ªË¶ÅÁöÑË¶ñÁ∂≤ËÜúÁñæÁóÖ„ÄÇÂú®ÈÄôÈ†ÖÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄëÈñãÁôº‰∫ÜÁúºÂ∫ïÂ∞àÁî®È†êË®ìÁ∑¥Ê®°Âûã (ÂΩ±ÂÉè + ÁúºÂ∫ï)ÔºåÈÄôÊòØ‰∏ÄÂÄãÁõ£Áù£ÂºèÁöÑ‰∫∫Â∑•Êô∫ÊÖßÊ®°ÂûãÔºåË®ìÁ∑¥Áî®ÊñºÂÅµÊ∏¨ÁúºÂ∫ïÂΩ±ÂÉè‰∏≠ÁöÑÁï∞Â∏∏„ÄÇÁ∏ΩÂÖ±‰ΩøÁî®‰∫Ü 57,803 ÂºµÂΩ±ÂÉè‰æÜÈñãÁôºÈÄôÂÄãÈ†êË®ìÁ∑¥Ê®°ÂûãÔºåÂÆÉÂú®ÂêÑÁ®Æ‰∏ãÊ∏∏‰ªªÂãô‰∏≠ÈÉΩÈÅîÂà∞‰∫ÜÂçìË∂äÁöÑÊïàËÉΩÔºåÈÄôË°®Á§∫ÊàëÂÄëÊèêÂá∫ÁöÑÊ®°ÂûãÂÑ™ÊñºÂÖ∂‰ªñ‰∏ÄËà¨ÊñπÊ≥ï„ÄÇÊàëÂÄëÁöÑÂΩ±ÂÉè + ÁúºÂ∫ïÊ®°ÂûãÊèê‰æõ‰∫Ü‰∏ÄÁ®ÆÂª£Ê≥õÁöÑÊñπÊ≥ï‰æÜÊîπÂñÑÊ®°ÂûãÊïàËÉΩÔºåÂêåÊôÇÊ∏õÂ∞ëÊâÄÈúÄÁöÑÊ®ôÁ±§Ë≥áÊñôÈõÜÊï∏Èáè„ÄÇÊ≠§Â§ñÔºåÂÆÉÈÇÑÈÄèÈÅéÊàëÂÄëÁöÑÊ®°ÂûãÁî¢ÁîüÁöÑË¶ñË¶∫ÂåñÔºåÊèê‰æõ‰∫ÜÊõ¥Â§öÈáùÂ∞çÁúºÂ∫ïÂΩ±ÂÉèÁöÑÁâπÂÆöÁñæÁóÖË¶ãËß£„ÄÇÈÄô‰∫õÁâπÂÆöÁñæÁóÖÂü∫Á§éÊ®°ÂûãÂ∞çÊñºÂ¢ûÂº∑ÁúºÂ∫ïÂΩ±ÂÉèÈ†òÂüü‰∏≠Ê∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÁöÑÊïàËÉΩÂíåÊïàÁéáËá≥ÈóúÈáçË¶Å„ÄÇ

##### **Beyond the Hype: A dispassionate look at vision-language models in medical scenario**
2408.08704v1 by Yang Nan, Huichi Zhou, Xiaodan Xing, Guang Yang

Recent advancements in Large Vision-Language Models (LVLMs) have demonstrated
remarkable capabilities across diverse tasks, garnering significant attention
in AI communities. However, their performance and reliability in specialized
domains such as medicine remain insufficiently assessed. In particular, most
assessments over-concentrate in evaluating VLMs based on simple Visual Question
Answering (VQA) on multi-modality data, while ignoring the in-depth
characteristic of LVLMs. In this study, we introduce RadVUQA, a novel
Radiological Visual Understanding and Question Answering benchmark, to
comprehensively evaluate existing LVLMs. RadVUQA mainly validates LVLMs across
five dimensions: 1) Anatomical understanding, assessing the models' ability to
visually identify biological structures; 2) Multimodal comprehension, which
involves the capability of interpreting linguistic and visual instructions to
produce desired outcomes; 3) Quantitative and spatial reasoning, evaluating the
models' spatial awareness and proficiency in combining quantitative analysis
with visual and linguistic information; 4) Physiological knowledge, measuring
the models' capability to comprehend functions and mechanisms of organs and
systems; and 5) Robustness, which assesses the models' capabilities against
unharmonised and synthetic data. The results indicate that both generalized
LVLMs and medical-specific LVLMs have critical deficiencies with weak
multimodal comprehension and quantitative reasoning capabilities. Our findings
reveal the large gap between existing LVLMs and clinicians, highlighting the
urgent need for more robust and intelligent LVLMs. The code and dataset will be
available after the acceptance of this paper.

ÊëòË¶ÅÔºöËøëÊúüÂ§ßÂûãËßÜËßâËØ≠Ë®ÄÊ®°Âûã (LVLMs) ÁöÑËøõÊ≠•Â∑≤Â±ïÁ§∫‰∫ÜÂêÑÁßç‰ªªÂä°ÁöÑÈùûÂá°ËÉΩÂäõÔºåÂú®‰∫∫Â∑•Êô∫ËÉΩÁ§æÁæ§‰∏≠Â§áÂèóÂÖ≥Ê≥®„ÄÇÁÑ∂ËÄåÔºåÂÆÉ‰ª¨Âú®ÂåªÂ≠¶Á≠â‰∏ì‰∏öÈ¢ÜÂüüÁöÑÊïàËÉΩÂíåÂèØÈù†ÊÄß‰ªçÊú™ÂæóÂà∞ÂÖÖÂàÜËØÑ‰º∞„ÄÇÁâπÂà´ÊòØÔºåÂ§ßÂ§öÊï∞ËØÑ‰º∞ÈÉΩËøá‰∫éÈõÜ‰∏≠Âú®Âü∫‰∫éÂ§öÊ®°ÊÄÅÊï∞ÊçÆËøõË°åÁÆÄÂçïËßÜËßâÈóÆÁ≠î (VQA) Êù•ËØÑ‰º∞ VLMÔºåËÄåÂøΩÁï•‰∫Ü VLM ÁöÑÊ∑±ÂÖ•ÁâπÂæÅ„ÄÇÊú¨Á†îÁ©∂‰∏≠ÔºåÊàë‰ª¨ÂºïÂÖ•‰∫Ü RadVUQAÔºåËøôÊòØ‰∏Ä‰∏™Êñ∞È¢ñÁöÑÊîæÂ∞ÑËßÜËßâÁêÜËß£ÂíåÈóÆÁ≠îÂü∫ÂáÜÔºå‰ª•ÂÖ®Èù¢ËØÑ‰º∞Áé∞ÊúâÁöÑ VLM„ÄÇRadVUQA ‰∏ªË¶Å‰ªé‰∫î‰∏™Áª¥Â∫¶È™åËØÅ VLMÔºö1) Ëß£ÂâñÁêÜËß£ÔºåËØÑ‰º∞Ê®°ÂûãËßÜËßâËØÜÂà´ÁîüÁâ©ÁªìÊûÑÁöÑËÉΩÂäõÔºõ2) Â§öÊ®°ÊÄÅÁêÜËß£ÔºåÊ∂âÂèäËß£ÈáäËØ≠Ë®ÄÂíåËßÜËßâÊåá‰ª§‰ª•‰∫ßÁîüÈ¢ÑÊúüÁªìÊûúÁöÑËÉΩÂäõÔºõ3) ÂÆöÈáèÂíåÁ©∫Èó¥Êé®ÁêÜÔºåËØÑ‰º∞Ê®°ÂûãÁöÑÁ©∫Èó¥ÊÑèËØÜÂíåÁªìÂêàÂÆöÈáèÂàÜÊûê‰∏éËßÜËßâÂíåËØ≠Ë®Ä‰ø°ÊÅØÁöÑËÉΩÂäõÔºõ4) ÁîüÁêÜÁü•ËØÜÔºåË°°ÈáèÊ®°ÂûãÁêÜËß£Âô®ÂÆòÂíåÁ≥ªÁªüÂäüËÉΩÂíåÊú∫Âà∂ÁöÑËÉΩÂäõÔºõ5) È≤ÅÊ£íÊÄßÔºåËØÑ‰º∞Ê®°ÂûãÂØπ‰∏çÂíåË∞êÂíåÂêàÊàêÊï∞ÊçÆÁöÑÂ§ÑÁêÜËÉΩÂäõ„ÄÇÁªìÊûúË°®ÊòéÔºåÈÄöÁî® VLM ÂíåÂåªÂ≠¶‰∏ìÁî® VLM ÈÉΩÂ≠òÂú®‰∏•ÈáçÁöÑÁº∫Èô∑ÔºåÂ§öÊ®°ÊÄÅÁêÜËß£ÂíåÂÆöÈáèÊé®ÁêÜËÉΩÂäõËæÉÂº±„ÄÇÊàë‰ª¨ÁöÑÁ†îÁ©∂ÁªìÊûúÊè≠Á§∫‰∫ÜÁé∞Êúâ VLM Âíå‰∏¥Â∫äÂåªÁîü‰πãÈó¥Â≠òÂú®Â∑®Â§ßÂ∑ÆË∑ùÔºåÂº∫Ë∞É‰∫ÜÂØπÊõ¥Âº∫Â§ßÂíåÊõ¥Êô∫ËÉΩÁöÑ VLM ÁöÑËø´ÂàáÈúÄÊ±Ç„ÄÇÊú¨ÊñáË¢´Êé•ÂèóÂêéÔºå‰ª£Á†ÅÂíåÊï∞ÊçÆÈõÜÂ∞ÜÂèØ‰æõ‰ΩøÁî®„ÄÇ

##### **TextCAVs: Debugging vision models using text**
2408.08652v1 by Angus Nicolson, Yarin Gal, J. Alison Noble

Concept-based interpretability methods are a popular form of explanation for
deep learning models which provide explanations in the form of high-level human
interpretable concepts. These methods typically find concept activation vectors
(CAVs) using a probe dataset of concept examples. This requires labelled data
for these concepts -- an expensive task in the medical domain. We introduce
TextCAVs: a novel method which creates CAVs using vision-language models such
as CLIP, allowing for explanations to be created solely using text descriptions
of the concept, as opposed to image exemplars. This reduced cost in testing
concepts allows for many concepts to be tested and for users to interact with
the model, testing new ideas as they are thought of, rather than a delay caused
by image collection and annotation. In early experimental results, we
demonstrate that TextCAVs produces reasonable explanations for a chest x-ray
dataset (MIMIC-CXR) and natural images (ImageNet), and that these explanations
can be used to debug deep learning-based models.

ÊëòË¶ÅÔºöÂü∫ÊñºÊ¶ÇÂøµÁöÑÂèØËß£ÈáãÊñπÊ≥ïÊòØ‰∏ÄÁ®ÆÊµÅË°åÁöÑÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãËß£ÈáãÂΩ¢ÂºèÔºåÂÆÉ‰ª•È´òÈöé‰∫∫È°ûÂèØËß£ÈáãÊ¶ÇÂøµÁöÑÂΩ¢ÂºèÊèê‰æõËß£Èáã„ÄÇÈÄô‰∫õÊñπÊ≥ïÈÄöÂ∏∏‰ΩøÁî®Ê¶ÇÂøµÁØÑ‰æãÊé¢Ê∏¨Ë≥áÊñôÈõÜ‰æÜÂ∞ãÊâæÊ¶ÇÂøµÂïüÂãïÂêëÈáè (CAV)„ÄÇÈÄôÈúÄË¶ÅÊ®ôË®òÈÄô‰∫õÊ¶ÇÂøµÁöÑË≥áÊñôÔºåÈÄôÂú®ÈÜ´Â≠∏È†òÂüüÊòØ‰∏ÄÈ†ÖÊòÇË≤¥ÁöÑ‰ªªÂãô„ÄÇÊàëÂÄë‰ªãÁ¥π TextCAVÔºö‰∏ÄÁ®Æ‰ΩøÁî®Ë¶ñË¶∫Ë™ûË®ÄÊ®°ÂûãÔºà‰æãÂ¶Ç CLIPÔºâÂª∫Á´ã CAV ÁöÑÊñ∞ÊñπÊ≥ïÔºåÂÆÉÂÖÅË®±ÂÉÖ‰ΩøÁî®Ê¶ÇÂøµÁöÑÊñáÂ≠óÊèèËø∞‰æÜÂª∫Á´ãËß£ÈáãÔºåËÄå‰∏çÊòØÂΩ±ÂÉèÁØÑ‰æã„ÄÇÊ∏¨Ë©¶Ê¶ÇÂøµÁöÑÊàêÊú¨Èôç‰ΩéÔºåÂÖÅË®±Ê∏¨Ë©¶Ë®±Â§öÊ¶ÇÂøµÔºå‰∏¶ËÆì‰ΩøÁî®ËÄÖËàáÊ®°Âûã‰∫íÂãïÔºåÂú®ÊÉ≥Âà∞Êñ∞ÊÉ≥Ê≥ïÊôÇÈÄ≤Ë°åÊ∏¨Ë©¶ÔºåËÄå‰∏çÊòØÂõ†ÂΩ±ÂÉèÊî∂ÈõÜÂíåË®ªËß£ËÄåÈÄ†ÊàêÁöÑÂª∂ÈÅ≤„ÄÇÂú®Êó©ÊúüÁöÑÂØ¶È©óÁµêÊûú‰∏≠ÔºåÊàëÂÄëË≠âÊòé TextCAV ÁÇ∫ËÉ∏ÈÉ® X ÂÖâË≥áÊñôÈõÜ (MIMIC-CXR) ÂíåËá™ÁÑ∂ÂΩ±ÂÉè (ImageNet) Áî¢ÁîüÂêàÁêÜÁöÑËß£ÈáãÔºå‰∏¶‰∏îÈÄô‰∫õËß£ÈáãÂèØÁî®ÊñºÂÅµÈåØÂü∫ÊñºÊ∑±Â∫¶Â≠∏ÁøíÁöÑÊ®°Âûã„ÄÇ

##### **RealMedQA: A pilot biomedical question answering dataset containing realistic clinical questions**
2408.08624v1 by Gregory Kell, Angus Roberts, Serge Umansky, Yuti Khare, Najma Ahmed, Nikhil Patel, Chloe Simela, Jack Coumbe, Julian Rozario, Ryan-Rhys Griffiths, Iain J. Marshall

Clinical question answering systems have the potential to provide clinicians
with relevant and timely answers to their questions. Nonetheless, despite the
advances that have been made, adoption of these systems in clinical settings
has been slow. One issue is a lack of question-answering datasets which reflect
the real-world needs of health professionals. In this work, we present
RealMedQA, a dataset of realistic clinical questions generated by humans and an
LLM. We describe the process for generating and verifying the QA pairs and
assess several QA models on BioASQ and RealMedQA to assess the relative
difficulty of matching answers to questions. We show that the LLM is more
cost-efficient for generating "ideal" QA pairs. Additionally, we achieve a
lower lexical similarity between questions and answers than BioASQ which
provides an additional challenge to the top two QA models, as per the results.
We release our code and our dataset publicly to encourage further research.

ÊëòË¶ÅÔºöËá®Â∫äÂïèÁ≠îÁ≥ªÁµ±ÂÖ∑ÊúâÊèê‰æõËá®Â∫äÈÜ´ÁîüÁõ∏Èóú‰∏îÂèäÊôÇÁöÑÁ≠îÊ°àÁöÑÊΩõÂäõ„ÄÇÂÑòÁÆ°Â¶ÇÊ≠§ÔºåÂÑòÁÆ°ÂèñÂæó‰∫ÜÈÄ≤Â±ïÔºå‰ΩÜÂú®Ëá®Â∫äÁí∞Â¢É‰∏≠Êé°Áî®ÈÄô‰∫õÁ≥ªÁµ±ÁöÑÈÄüÂ∫¶ÂæàÊÖ¢„ÄÇ‰∏ÄÂÄãÂïèÈ°åÊòØÁº∫‰πèÂèçÊò†ÈÜ´ÁôÇÂ∞àÊ•≠‰∫∫Âì°ÁèæÂØ¶ÈúÄÊ±ÇÁöÑÂïèÁ≠îË≥áÊñôÈõÜ„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü RealMedQAÔºåÈÄôÊòØ‰∏ÄÂÄãÁî±‰∫∫È°ûÂíå LLM ÁîüÊàêÁöÑÁèæÂØ¶Ëá®Â∫äÂïèÈ°åË≥áÊñôÈõÜ„ÄÇÊàëÂÄëÊèèËø∞‰∫ÜÁîüÊàêÂíåÈ©óË≠â QA Â∞çÁöÑÈÅéÁ®ãÔºå‰∏¶Âú® BioASQ Âíå RealMedQA ‰∏äË©ï‰º∞‰∫ÜÂπæÂÄã QA Ê®°ÂûãÔºå‰ª•Ë©ï‰º∞Â∞áÁ≠îÊ°àËàáÂïèÈ°åÂåπÈÖçÁöÑÁõ∏Â∞çÈõ£Â∫¶„ÄÇÊàëÂÄëË°®ÊòéÔºåLLM Âú®ÁîüÊàê„ÄåÁêÜÊÉ≥„ÄçÁöÑ QA Â∞çÊñπÈù¢Êõ¥ÂÖ∑ÊàêÊú¨ÊïàÁõä„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂú®ÂïèÈ°åÂíåÁ≠îÊ°à‰πãÈñìÂØ¶Áèæ‰∫ÜÊØî BioASQ Êõ¥‰ΩéÁöÑË©ûÂΩôÁõ∏‰ººÊÄßÔºåÊ†πÊìöÁµêÊûúÔºåÈÄôÂ∞çÂâçÂÖ©ÂÄã QA Ê®°ÂûãÊèêÂá∫‰∫ÜÈ°çÂ§ñÁöÑÊåëÊà∞„ÄÇÊàëÂÄëÂÖ¨ÈñãÁôºÂ∏ÉÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÂíåË≥áÊñôÈõÜÔºå‰ª•ÈºìÂãµÈÄ≤‰∏ÄÊ≠•ÁöÑÁ†îÁ©∂„ÄÇ

##### **Focus on Focus: Focus-oriented Representation Learning and Multi-view Cross-modal Alignment for Glioma Grading**
2408.08527v1 by Li Pan, Yupei Zhang, Qiushi Yang, Tan Li, Xiaohan Xing, Maximus C. F. Yeung, Zhen Chen

Recently, multimodal deep learning, which integrates histopathology slides
and molecular biomarkers, has achieved a promising performance in glioma
grading. Despite great progress, due to the intra-modality complexity and
inter-modality heterogeneity, existing studies suffer from inadequate
histopathology representation learning and inefficient molecular-pathology
knowledge alignment. These two issues hinder existing methods to precisely
interpret diagnostic molecular-pathology features, thereby limiting their
grading performance. Moreover, the real-world applicability of existing
multimodal approaches is significantly restricted as molecular biomarkers are
not always available during clinical deployment. To address these problems, we
introduce a novel Focus on Focus (FoF) framework with paired pathology-genomic
training and applicable pathology-only inference, enhancing molecular-pathology
representation effectively. Specifically, we propose a Focus-oriented
Representation Learning (FRL) module to encourage the model to identify regions
positively or negatively related to glioma grading and guide it to focus on the
diagnostic areas with a consistency constraint. To effectively link the
molecular biomarkers to morphological features, we propose a Multi-view
Cross-modal Alignment (MCA) module that projects histopathology representations
into molecular subspaces, aligning morphological features with corresponding
molecular biomarker status by supervised contrastive learning. Experiments on
the TCGA GBM-LGG dataset demonstrate that our FoF framework significantly
improves the glioma grading. Remarkably, our FoF achieves superior performance
using only histopathology slides compared to existing multimodal methods. The
source code is available at https://github.com/peterlipan/FoF.

ÊëòË¶ÅÔºö<paragraph>ÊúÄËøëÔºåÊï¥Âêà‰∫ÜÁªÑÁªáÁóÖÁêÜÂ≠¶ÂàáÁâáÂíåÂàÜÂ≠êÁîüÁâ©Ê†áËÆ∞ÁöÑÂ§öÊ®°ÊÄÅÊ∑±Â∫¶Â≠¶‰π†Âú®Á•ûÁªèËÉ∂Ë¥®Áò§ÂàÜÁ∫ß‰∏≠ÂèñÂæó‰∫ÜÂèØÂñúÁöÑÊàêÊûú„ÄÇÂ∞ΩÁÆ°ÂèñÂæó‰∫ÜÂ∑®Â§ßËøõÂ±ïÔºå‰ΩÜÁî±‰∫éÊ®°ÊÄÅÂÜÖÂ§çÊùÇÊÄßÂíåÊ®°ÊÄÅÈó¥ÂºÇË¥®ÊÄßÔºåÁé∞ÊúâÁ†îÁ©∂Â≠òÂú®ÁªÑÁªáÁóÖÁêÜÂ≠¶Ë°®ÂæÅÂ≠¶‰π†‰∏çË∂≥ÂíåÂàÜÂ≠êÁóÖÁêÜÂ≠¶Áü•ËØÜÂØπÈΩêÊïàÁéá‰Ωé‰∏ãÁöÑÈóÆÈ¢ò„ÄÇËøô‰∏§‰∏™ÈóÆÈ¢òÈòªÁ¢ç‰∫ÜÁé∞ÊúâÊñπÊ≥ïÁ≤æÁ°ÆËß£ÈáäËØäÊñ≠ÊÄßÂàÜÂ≠êÁóÖÁêÜÂ≠¶ÁâπÂæÅÔºå‰ªéËÄåÈôêÂà∂‰∫ÜÂÆÉ‰ª¨ÁöÑËØÑÂàÜÊÄßËÉΩ„ÄÇÊ≠§Â§ñÔºåÁé∞ÊúâÂ§öÊ®°ÊÄÅÊñπÊ≥ïÁöÑÂÆûÈôÖÈÄÇÁî®ÊÄßÂèóÂà∞ÂæàÂ§ßÈôêÂà∂ÔºåÂõ†‰∏∫Âú®‰∏¥Â∫äÈÉ®ÁΩ≤ÊúüÈó¥Âπ∂‰∏çÊÄªÊòØËÉΩËé∑ÂæóÂàÜÂ≠êÁîüÁâ©Ê†áËÆ∞„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∫õÈóÆÈ¢òÔºåÊàë‰ª¨ÂºïÂÖ•‰∫Ü‰∏Ä‰∏™‰∏ìÊ≥®‰∫éÁÑ¶ÁÇπ (FoF) ÁöÑÊñ∞Ê°ÜÊû∂ÔºåËØ•Ê°ÜÊû∂ÈááÁî®ÈÖçÂØπÁöÑÁóÖÁêÜÂü∫Âõ†ÁªÑÂ≠¶ËÆ≠ÁªÉÂíåÈÄÇÁî®ÁöÑ‰ªÖÁóÖÁêÜÂ≠¶Êé®Êñ≠ÔºåÊúâÊïàÂú∞Â¢ûÂº∫‰∫ÜÂàÜÂ≠êÁóÖÁêÜÂ≠¶Ë°®ÂæÅ„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏Ä‰∏™Èù¢ÂêëÁÑ¶ÁÇπÁöÑË°®ÂæÅÂ≠¶‰π† (FRL) Ê®°ÂùóÔºå‰ª•ÈºìÂä±Ê®°ÂûãËØÜÂà´‰∏éÁ•ûÁªèËÉ∂Ë¥®Áò§ÂàÜÁ∫ßÂëàÊ≠£Áõ∏ÂÖ≥ÊàñË¥üÁõ∏ÂÖ≥ÁöÑÂå∫ÂüüÔºåÂπ∂ÊåáÂØºÂÖ∂‰∏ìÊ≥®‰∫éÂÖ∑ÊúâÁ®†ÂØÜÁ∫¶ÊùüÁöÑËØäÊñ≠Âå∫Âüü„ÄÇ‰∏∫‰∫ÜÊúâÊïàÂú∞Â∞ÜÂàÜÂ≠êÁîüÁâ©Ê†áËÆ∞‰∏éÂΩ¢ÊÄÅÂ≠¶ÁâπÂæÅËÅîÁ≥ªËµ∑Êù•ÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏Ä‰∏™Â§öËßÜÂõæË∑®Ê®°ÊÄÅÂØπÈΩê (MCA) Ê®°ÂùóÔºåËØ•Ê®°ÂùóÂ∞ÜÁªÑÁªáÁóÖÁêÜÂ≠¶Ë°®ÂæÅÊäïÂΩ±Âà∞ÂàÜÂ≠êÂ≠êÁ©∫Èó¥ÔºåÈÄöËøáÁõëÁù£ÂØπÊØîÂ≠¶‰π†Â∞ÜÂΩ¢ÊÄÅÂ≠¶ÁâπÂæÅ‰∏éÁõ∏Â∫îÁöÑÂàÜÂ≠êÁîüÁâ©Ê†áËÆ∞Áä∂ÊÄÅÂØπÈΩê„ÄÇÂú® TCGA GBM-LGG Êï∞ÊçÆÈõÜ‰∏äÁöÑÂÆûÈ™åË°®ÊòéÔºåÊàë‰ª¨ÁöÑ FoF Ê°ÜÊû∂ÊòæÁùÄÊèêÈ´ò‰∫ÜÁ•ûÁªèËÉ∂Ë¥®Áò§ÂàÜÁ∫ß„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºå‰∏éÁé∞ÊúâÁöÑÂ§öÊ®°ÊÄÅÊñπÊ≥ïÁõ∏ÊØîÔºåÊàë‰ª¨ÁöÑ FoF ‰ªÖ‰ΩøÁî®ÁªÑÁªáÁóÖÁêÜÂ≠¶ÂàáÁâáÂ∞±ÂèñÂæó‰∫Ü‰ºòÂºÇÁöÑÊÄßËÉΩ„ÄÇÊ∫ê‰ª£Á†ÅÂèØÂú® https://github.com/peterlipan/FoF Ëé∑Âæó„ÄÇ</paragraph>

##### **Adversarial Contrastive Learning Based Physics-Informed Temporal Networks for Cuffless Blood Pressure Estimation**
2408.08488v1 by Rui Wang, Mengshi Qi, Yingxia Shao, Anfu Zhou, Huadong Ma

Time series data mining is immensely important in extensive applications,
such as traffic, medical, and e-commerce. In this paper, we focus on medical
temporal variation modeling, \emph{i.e.,} cuffless blood pressure (BP)
monitoring which has great value in cardiovascular healthcare. Although
providing a comfortable user experience, such methods are suffering from the
demand for a significant amount of realistic data to train an individual model
for each subject, especially considering the invasive or obtrusive BP
ground-truth measurements. To tackle this challenge, we introduce a novel
physics-informed temporal network~(PITN) with adversarial contrastive learning
to enable precise BP estimation with very limited data. Specifically, we first
enhance the physics-informed neural network~(PINN) with the temporal block for
investigating BP dynamics' multi-periodicity for personal cardiovascular cycle
modeling and temporal variation. We then employ adversarial training to
generate extra physiological time series data, improving PITN's robustness in
the face of sparse subject-specific training data. Furthermore, we utilize
contrastive learning to capture the discriminative variations of cardiovascular
physiologic phenomena. This approach aggregates physiological signals with
similar blood pressure values in latent space while separating clusters of
samples with dissimilar blood pressure values. Experiments on three
widely-adopted datasets with different modailties (\emph{i.e.,} bioimpedance,
PPG, millimeter-wave) demonstrate the superiority and effectiveness of the
proposed methods over previous state-of-the-art approaches. The code is
available at~\url{https://github.com/Zest86/ACL-PITN}.

ÊëòË¶ÅÔºö<paragraph>ÊôÇÈñìÂ∫èÂàóË≥áÊñôÊé¢ÂãòÂú®Âª£Ê≥õÁöÑÊáâÁî®‰∏≠ÈùûÂ∏∏ÈáçË¶ÅÔºå‰æãÂ¶Ç‰∫§ÈÄö„ÄÅÈÜ´ÁôÇÂíåÈõªÂ≠êÂïÜÂãô„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂ∞àÊ≥®ÊñºÈÜ´ÁôÇÊôÇÈñìËÆäÁï∞Âª∫Ê®°ÔºåÂç≥ÁÑ°Ë¢ñË°ÄÂ£ì (BP) Áõ£Ê∏¨ÔºåÈÄôÂú®ÂøÉË°ÄÁÆ°‰øùÂÅ•‰∏≠ÂÖ∑ÊúâÊ•µÈ´òÁöÑÂÉπÂÄº„ÄÇÂÑòÁÆ°Êèê‰æõ‰∫ÜËàíÈÅ©ÁöÑ‰ΩøÁî®ËÄÖÈ´îÈ©óÔºå‰ΩÜÊ≠§È°ûÊñπÊ≥ïÂçªËã¶ÊñºÈúÄË¶ÅÂ§ßÈáèÁöÑÂØ¶ÈöõË≥áÊñô‰æÜË®ìÁ∑¥ÊØèÂÄãÂèóË©¶ËÄÖÁöÑÂÄãÂà•Ê®°ÂûãÔºåÁâπÂà•ÊòØËÄÉÊÖÆÂà∞‰æµÂÖ•ÊÄßÊàñ‰æµÂÖ•ÊÄßÁöÑ BP ÁúüÂØ¶Ê∏¨Èáè„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∏ÄÊåëÊà∞ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÊñ∞ÁöÑÁâ©ÁêÜË≥áË®äÊôÇÈñìÁ∂≤Ë∑Ø (PITN)Ôºå‰∏¶ÁµêÂêàÂ∞çÊäóÂ∞çÊØîÂ≠∏ÁøíÔºå‰ª•Ê•µÂ∞ëÁöÑË≥áÊñôÈÄ≤Ë°åÁ≤æÁ¢∫ÁöÑ BP ‰º∞Ë®à„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÈ¶ñÂÖà‰ΩøÁî®ÊôÇÈñìÂçÄÂ°äÂ¢ûÂº∑‰∫ÜÁâ©ÁêÜË≥áË®äÁ•ûÁ∂ìÁ∂≤Ë∑Ø (PINN)Ôºå‰ª•Á†îÁ©∂ BP ÂãïÊÖãÁöÑÂ§öÈÄ±ÊúüÊÄßÔºåÁî®ÊñºÂÄã‰∫∫ÂøÉË°ÄÁÆ°ÈÄ±ÊúüÂª∫Ê®°ÂíåÊôÇÈñìËÆäÁï∞„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÊé°Áî®Â∞çÊäóË®ìÁ∑¥‰æÜÁî¢ÁîüÈ°çÂ§ñÁöÑÁîüÁêÜÊôÇÈñìÂ∫èÂàóË≥áÊñôÔºå‰ª•ÊèêÈ´ò PITN Âú®Á®ÄÁñèÂèóË©¶ËÄÖÁâπÂÆöË®ìÁ∑¥Ë≥áÊñôÈù¢ÂâçÁöÑÈ≠ØÊ£íÊÄß„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂà©Áî®Â∞çÊØîÂ≠∏Áøí‰æÜÊçïÊçâÂøÉË°ÄÁÆ°ÁîüÁêÜÁèæË±°ÁöÑÂçÄÂà•ÊÄßËÆäÁï∞„ÄÇÊ≠§ÊñπÊ≥ïÂ∞áÊΩõÂú®Á©∫Èñì‰∏≠ÂÖ∑ÊúâÈ°û‰ººË°ÄÂ£ìÂÄºÁöÑÁîüÁêÜË®äËôüËÅöÈõÜÂú®‰∏ÄËµ∑ÔºåÂêåÊôÇÂ∞áÂÖ∑Êúâ‰∏çÂêåË°ÄÂ£ìÂÄºÁöÑÊ®£Êú¨Âè¢ÈõÜÂàÜÈñã„ÄÇÂú®‰∏âÂÄãÂª£Ê≥õÊé°Áî®ÁöÑÂÖ∑Êúâ‰∏çÂêåÊ®°ÊÖãÁöÑË≥áÊñôÈõÜÔºàÂç≥ÁîüÁâ©ÈòªÊäó„ÄÅPPG„ÄÅÊØ´Á±≥Ê≥¢Ôºâ‰∏äÁöÑÂØ¶È©óË≠âÊòé‰∫ÜÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÂÑ™ÊñºÂÖàÂâçÁöÑÊúÄÂÖàÈÄ≤ÊñπÊ≥ï„ÄÇÁ®ãÂºèÁ¢ºÂèØÂú®~\url{https://github.com/Zest86/ACL-PITN}ÂèñÂæó„ÄÇ</paragraph>

##### **Efficient Data-Sketches and Fine-Tuning for Early Detection of Distributional Drift in Medical Imaging**
2408.08456v1 by Yusen Wu, Hao Chen, Alex Pissinou Makki, Phuong Nguyen, Yelena Yesha

Distributional drift detection is important in medical applications as it
helps ensure the accuracy and reliability of models by identifying changes in
the underlying data distribution that could affect diagnostic or treatment
decisions. However, current methods have limitations in detecting drift; for
example, the inclusion of abnormal datasets can lead to unfair comparisons.
This paper presents an accurate and sensitive approach to detect distributional
drift in CT-scan medical images by leveraging data-sketching and fine-tuning
techniques. We developed a robust baseline library model for real-time anomaly
detection, allowing for efficient comparison of incoming images and
identification of anomalies. Additionally, we fine-tuned a vision transformer
pre-trained model to extract relevant features using breast cancer images as an
example, significantly enhancing model accuracy to 99.11\%. Combining with
data-sketches and fine-tuning, our feature extraction evaluation demonstrated
that cosine similarity scores between similar datasets provide greater
improvements, from around 50\% increased to 100\%. Finally, the sensitivity
evaluation shows that our solutions are highly sensitive to even 1\%
salt-and-pepper and speckle noise, and it is not sensitive to lighting noise
(e.g., lighting conditions have no impact on data drift). The proposed methods
offer a scalable and reliable solution for maintaining the accuracy of
diagnostic models in dynamic clinical environments.

ÊëòË¶ÅÔºöÂàÜÈÖçÊºÇÁßªÊ£ÄÊµãÂú®ÂåªÁñóÂ∫îÁî®‰∏≠ÂæàÈáçË¶ÅÔºåÂõ†‰∏∫ÂÆÉ
ÊúâÂä©‰∫éÁ°Æ‰øùÊ®°ÂûãÁöÑÂáÜÁ°ÆÊÄßÂíåÂèØÈù†ÊÄßÔºåÊñπÊ≥ïÊòØËØÜÂà´ÂèØËÉΩÂΩ±ÂìçËØäÊñ≠ÊàñÊ≤ªÁñóÁöÑÂ∫ïÂ±ÇÊï∞ÊçÆÂàÜÂ∏ÉÁöÑÂèòÂåñ
ÂÜ≥ÂÆö„ÄÇÁÑ∂ËÄåÔºåÂΩìÂâçÁöÑÊñπÊ≥ïÂú®Ê£ÄÊµãÊºÇÁßªÊñπÈù¢Â≠òÂú®Â±ÄÈôêÊÄßÔºõ‰æãÂ¶ÇÔºåÂºÇÂ∏∏Êï∞ÊçÆÈõÜÁöÑÂåÖÂê´‰ºöÂØºËá¥‰∏çÂÖ¨Âπ≥ÁöÑÊØîËæÉ„ÄÇ
Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂáÜÁ°Æ‰∏îÊïèÊÑüÁöÑÊñπÊ≥ïÊù•Ê£ÄÊµã CT Êâ´ÊèèÂåªÂ≠¶ÂõæÂÉè‰∏≠ÁöÑÂàÜÂ∏ÉÊºÇÁßªÔºåÊñπÊ≥ïÊòØÂà©Áî®Êï∞ÊçÆËçâÂõæÂíåÂæÆË∞É
ÊäÄÊúØ„ÄÇÊàë‰ª¨ÂºÄÂèë‰∫Ü‰∏Ä‰∏™Á®≥ÂÅ•ÁöÑÂü∫Á∫øÂ∫ìÊ®°ÂûãÔºåÁî®‰∫éÂÆûÊó∂ÂºÇÂ∏∏Ê£ÄÊµãÔºåÂÖÅËÆ∏ÂØπ‰º†ÂÖ•ÂõæÂÉèËøõË°åÈ´òÊïàÊØîËæÉÂíå
ËØÜÂà´ÂºÇÂ∏∏„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨ÂØπËßÜËßâËΩ¨Êç¢Âô®È¢ÑËÆ≠ÁªÉÊ®°ÂûãËøõË°å‰∫ÜÂæÆË∞ÉÔºå‰ª•‰ΩøÁî®‰π≥ËÖ∫ÁôåÂõæÂÉè‰Ωú‰∏∫Á§∫‰æãÊèêÂèñÁõ∏ÂÖ≥ÁâπÂæÅÔºåÊòæÁùÄÊèêÈ´ò‰∫ÜÊ®°ÂûãÂáÜÁ°ÆÁéáËá≥ 99.11%„ÄÇÁªìÂêà
Êï∞ÊçÆËçâÂõæÂíåÂæÆË∞ÉÔºåÊàë‰ª¨ÁöÑÁâπÂæÅÊèêÂèñËØÑ‰º∞Ë°®ÊòéÔºåÁõ∏‰ººÊï∞ÊçÆÈõÜ‰πãÈó¥ÁöÑ‰ΩôÂº¶Áõ∏‰ººÂ∫¶ÂæóÂàÜÊèê‰æõ‰∫ÜÊõ¥Â§ßÁöÑ
ÊîπËøõÔºå‰ªéÂ¢ûÂä†Á∫¶ 50% Âà∞ 100%„ÄÇÊúÄÂêéÔºåÊïèÊÑüÊÄßËØÑ‰º∞Ë°®ÊòéÊàë‰ª¨ÁöÑËß£ÂÜ≥ÊñπÊ°àÂØπ 1% ÁöÑÊ§íÁõêÂô™Â£∞ÂíåÊñëÁÇπÂô™Â£∞È´òÂ∫¶ÊïèÊÑüÔºåÂπ∂‰∏îÂØπÂÖâÁÖßÂô™Â£∞‰∏çÊïèÊÑü
Ôºà‰æãÂ¶ÇÔºåÂÖâÁÖßÊù°‰ª∂ÂØπÊï∞ÊçÆÊºÇÁßªÊ≤°ÊúâÂΩ±ÂìçÔºâ„ÄÇÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ï‰∏∫‰øùÊåÅËØäÊñ≠Ê®°ÂûãÁöÑÂáÜÁ°ÆÊÄßÊèê‰æõ‰∫Ü‰∏Ä‰∏™ÂèØÊâ©Â±ï‰∏îÂèØÈù†ÁöÑËß£ÂÜ≥ÊñπÊ°à
Âú®Âä®ÊÄÅ‰∏¥Â∫äÁéØÂ¢É‰∏≠„ÄÇ

##### **Predictive uncertainty estimation in deep learning for lung carcinoma classification in digital pathology under real dataset shifts**
2408.08432v1 by Abdur R. Fayjie, Jutika Borah, Florencia Carbone, Jan Tack, Patrick Vandewalle

Deep learning has shown tremendous progress in a wide range of digital
pathology and medical image classification tasks. Its integration into safe
clinical decision-making support requires robust and reliable models. However,
real-world data comes with diversities that often lie outside the intended
source distribution. Moreover, when test samples are dramatically different,
clinical decision-making is greatly affected. Quantifying predictive
uncertainty in models is crucial for well-calibrated predictions and
determining when (or not) to trust a model. Unfortunately, many works have
overlooked the importance of predictive uncertainty estimation. This paper
evaluates whether predictive uncertainty estimation adds robustness to deep
learning-based diagnostic decision-making systems. We investigate the effect of
various carcinoma distribution shift scenarios on predictive performance and
calibration. We first systematically investigate three popular methods for
improving predictive uncertainty: Monte Carlo dropout, deep ensemble, and
few-shot learning on lung adenocarcinoma classification as a primary disease in
whole slide images. Secondly, we compare the effectiveness of the methods in
terms of performance and calibration under clinically relevant distribution
shifts such as in-distribution shifts comprising primary disease sub-types and
other characterization analysis data; out-of-distribution shifts comprising
well-differentiated cases, different organ origin, and imaging modality shifts.
While studies on uncertainty estimation exist, to our best knowledge, no
rigorous large-scale benchmark compares predictive uncertainty estimation
including these dataset shifts for lung carcinoma classification.

ÊëòË¶ÅÔºöÊ∑±Â∫¶Â≠∏ÁøíÂú®Âª£Ê≥õÁöÑÊï∏‰ΩçÁóÖÁêÜÂ≠∏ÂíåÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÈ°û‰ªªÂãô‰∏≠Â±ïÁèæÂá∫È©ö‰∫∫ÁöÑÈÄ≤Â±ï„ÄÇÂÆÉÊï¥ÂêàÂà∞ÂÆâÂÖ®ÁöÑËá®Â∫äÊ±∫Á≠ñÊîØÊè¥‰∏≠ÈúÄË¶ÅÂº∑ÂÅ•‰∏îÂèØÈù†ÁöÑÊ®°Âûã„ÄÇÁÑ∂ËÄåÔºåÁúüÂØ¶‰∏ñÁïåÁöÑË≥áÊñôÊúÉ‰º¥Èö®ËëóÂ§öÊ®£ÊÄßÔºåËÄåÈÄô‰∫õÂ§öÊ®£ÊÄßÈÄöÂ∏∏Ë∂ÖÂá∫‰∫ÜÈ†êÊúüÁöÑ‰æÜÊ∫êÂàÜ‰Ωà„ÄÇÊ≠§Â§ñÔºåÁï∂Ê∏¨Ë©¶Ê®£Êú¨ÊúâÊ•µÂ§ßÁöÑ‰∏çÂêåÊôÇÔºåËá®Â∫äÊ±∫Á≠ñÂà∂ÂÆöÊúÉÂèóÂà∞ÂæàÂ§ßÁöÑÂΩ±Èüø„ÄÇÈáèÂåñÊ®°Âûã‰∏≠ÁöÑÈ†êÊ∏¨‰∏çÁ¢∫ÂÆöÊÄßÂ∞çÊñºÊ†°Ê∫ñËâØÂ•ΩÁöÑÈ†êÊ∏¨‰ª•ÂèäÊ±∫ÂÆö‰ΩïÊôÇÔºàÊàñ‰∏çÔºâ‰ø°‰ªªÊ®°ÂûãËá≥ÈóúÈáçË¶Å„ÄÇ‰∏çÂπ∏ÁöÑÊòØÔºåË®±Â§ö‰ΩúÂìÅÈÉΩÂøΩÁï•‰∫ÜÈ†êÊ∏¨‰∏çÁ¢∫ÂÆöÊÄß‰º∞Ë®àÁöÑÈáçË¶ÅÊÄß„ÄÇÊú¨ÊñáË©ï‰º∞È†êÊ∏¨‰∏çÁ¢∫ÂÆöÊÄß‰º∞Ë®àÊòØÂê¶ËÉΩÁÇ∫Âü∫ÊñºÊ∑±Â∫¶Â≠∏ÁøíÁöÑË®∫Êñ∑Ê±∫Á≠ñÂà∂ÂÆöÁ≥ªÁµ±Â¢ûÂä†Á©©ÂÅ•ÊÄß„ÄÇÊàëÂÄëÊé¢Ë®éÂêÑÁ®ÆÁôåÁóáÂàÜ‰ΩàËΩâÁßªÊÉÖÂ¢ÉÂ∞çÈ†êÊ∏¨ÊïàËÉΩÂíåÊ†°Ê∫ñÁöÑÂΩ±Èüø„ÄÇÊàëÂÄëÈ¶ñÂÖàÁ≥ªÁµ±ÊÄßÂú∞Êé¢Ë®é‰∏âÁ®ÆÊîπÂñÑÈ†êÊ∏¨‰∏çÁ¢∫ÂÆöÊÄßÁöÑÁÜ±ÈñÄÊñπÊ≥ïÔºöËíôÂú∞Âç°ÁæÖËºüÂ≠∏„ÄÅÊ∑±Â∫¶Êï¥È´îÂíåÂ∞ëÊ¨°Â≠∏ÁøíÔºå‰ª•ËÇ∫ËÖ∫ÁôåÂàÜÈ°ûÁÇ∫‰∏ªË¶ÅÁñæÁóÖÔºåÂú®ÂÖ®ÂπªÁáàÁâáÂΩ±ÂÉè‰∏≠ÈÄ≤Ë°å„ÄÇÂÖ∂Ê¨°ÔºåÊàëÂÄëÊØîËºÉÈÄô‰∫õÊñπÊ≥ïÂú®ÊïàËÉΩÂíåÊ†°Ê∫ñÊñπÈù¢ÁöÑÊúâÊïàÊÄßÔºåÂú®Ëá®Â∫ä‰∏äÁõ∏ÈóúÁöÑÂàÜ‰ΩàËΩâÁßª‰∏≠Ôºå‰æãÂ¶ÇÂåÖÂê´‰∏ªË¶ÅÁñæÁóÖÂ≠êÈ°ûÂûãÂíåÂÖ∂‰ªñË°®ÂæµÂàÜÊûêË≥áÊñôÁöÑÂàÜÂ∏ÉÂÖßËΩâÁßªÔºõÂåÖÂê´ÂàÜÂåñËâØÂ•ΩÁöÑÁóÖ‰æã„ÄÅ‰∏çÂêåÁöÑÂô®ÂÆò‰æÜÊ∫êÂíåÂΩ±ÂÉèÊñπÂºèËΩâÁßªÁöÑÂàÜÂ∏ÉÂ§ñËΩâÁßª„ÄÇÂÑòÁÆ°ÊúâÈóúÊñº‰∏çÁ¢∫ÂÆöÊÄß‰º∞Ë®àÁöÑÁ†îÁ©∂Ôºå‰ΩÜÊìöÊàëÂÄëÊâÄÁü•ÔºåÊ≤íÊúâÂö¥Ë¨πÁöÑÂ§ßË¶èÊ®°Âü∫Ê∫ñÊØîËºÉÈ†êÊ∏¨‰∏çÁ¢∫ÂÆöÊÄß‰º∞Ë®àÔºåÂåÖÊã¨ÈÄô‰∫õË≥áÊñôÈõÜËΩâÁßª‰ª•ÈÄ≤Ë°åËÇ∫ÁôåÂàÜÈ°û„ÄÇ

##### **Assessing and Enhancing Large Language Models in Rare Disease Question-answering**
2408.08422v1 by Guanchu Wang, Junhao Ran, Ruixiang Tang, Chia-Yuan Chang, Chia-Yuan Chang, Yu-Neng Chuang, Zirui Liu, Vladimir Braverman, Zhandong Liu, Xia Hu

Despite the impressive capabilities of Large Language Models (LLMs) in
general medical domains, questions remain about their performance in diagnosing
rare diseases. To answer this question, we aim to assess the diagnostic
performance of LLMs in rare diseases, and explore methods to enhance their
effectiveness in this area. In this work, we introduce a rare disease
question-answering (ReDis-QA) dataset to evaluate the performance of LLMs in
diagnosing rare diseases. Specifically, we collected 1360 high-quality
question-answer pairs within the ReDis-QA dataset, covering 205 rare diseases.
Additionally, we annotated meta-data for each question, facilitating the
extraction of subsets specific to any given disease and its property. Based on
the ReDis-QA dataset, we benchmarked several open-source LLMs, revealing that
diagnosing rare diseases remains a significant challenge for these models.
  To facilitate retrieval augmentation generation for rare disease diagnosis,
we collect the first rare diseases corpus (ReCOP), sourced from the National
Organization for Rare Disorders (NORD) database. Specifically, we split the
report of each rare disease into multiple chunks, each representing a different
property of the disease, including their overview, symptoms, causes, effects,
related disorders, diagnosis, and standard therapies. This structure ensures
that the information within each chunk aligns consistently with a question.
Experiment results demonstrate that ReCOP can effectively improve the accuracy
of LLMs on the ReDis-QA dataset by an average of 8%. Moreover, it significantly
guides LLMs to generate trustworthy answers and explanations that can be traced
back to existing literature.

ÊëòË¶ÅÔºöÂÑòÁÆ°Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®‰∏ÄËà¨ÈÜ´Â≠∏È†òÂüüÊìÅÊúâ‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑËÉΩÂäõÔºå‰ΩÜÂ∞çÊñºÂÆÉÂÄëÂú®Ë®∫Êñ∑ÁΩïË¶ãÁñæÁóÖÊñπÈù¢ÁöÑË°®Áèæ‰ªçÊúâÁñëÂïè„ÄÇÁÇ∫‰∫ÜÂõûÁ≠îÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÊó®Âú®Ë©ï‰º∞ LLM Âú®ÁΩïË¶ãÁñæÁóÖ‰∏≠ÁöÑË®∫Êñ∑Ë°®ÁèæÔºå‰∏¶Êé¢Ë®éÂ¢ûÂº∑ÂÆÉÂÄëÂú®ÈÄôÂÄãÈ†òÂüüÁöÑÊúâÊïàÊÄßÁöÑÊñπÊ≥ï„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÁΩïË¶ãÁñæÁóÖÂïèÁ≠î (ReDis-QA) Ë≥áÊñôÈõÜÔºå‰ª•Ë©ï‰º∞ LLM Âú®Ë®∫Êñ∑ÁΩïË¶ãÁñæÁóÖÊñπÈù¢ÁöÑË°®Áèæ„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÂú® ReDis-QA Ë≥áÊñôÈõÜ‰∏≠Êî∂ÈõÜ‰∫Ü 1360 ÂÄãÈ´òÂìÅË≥™ÁöÑÂïèÈ°åËß£Á≠îÂ∞çÔºåÊ∂µËìã 205 Á®ÆÁΩïË¶ãÁñæÁóÖ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁÇ∫ÊØèÂÄãÂïèÈ°åË®ªÈáã‰∫ÜÂÖÉË≥áÊñôÔºå‰ª•Âà©ÊñºÊèêÂèñÁâπÂÆöÊñº‰ªª‰ΩïÁµ¶ÂÆöÁñæÁóÖÂèäÂÖ∂Â±¨ÊÄßÁöÑÂ≠êÈõÜ„ÄÇÊ†πÊìö ReDis-QA Ë≥áÊñôÈõÜÔºåÊàëÂÄëÂ∞çÂπæÂÄãÈñãÊ∫ê LLM ÈÄ≤Ë°å‰∫ÜÂü∫Ê∫ñÊ∏¨Ë©¶ÔºåÁµêÊûúË°®ÊòéË®∫Êñ∑ÁΩïË¶ãÁñæÁóÖ‰ªçÁÑ∂ÊòØÈÄô‰∫õÊ®°ÂûãÁöÑ‰∏ÄÈ†ÖÈáçÂ§ßÊåëÊà∞„ÄÇÁÇ∫‰∫Ü‰øÉÈÄ≤ÁΩïË¶ãÁñæÁóÖË®∫Êñ∑ÁöÑÊ™¢Á¥¢Â¢ûÂº∑ÁîüÊàêÔºåÊàëÂÄëÊî∂ÈõÜ‰∫ÜÁ¨¨‰∏ÄÂÄãÁΩïË¶ãÁñæÁóÖË™ûÊñôÂ∫´ (ReCOP)ÔºåÂÖ∂‰æÜÊ∫êÊñºÂúãÂÆ∂ÁΩïË¶ãÁñæÁóÖÁµÑÁπî (NORD) Ë≥áÊñôÂ∫´„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÂ∞áÊØèÁ®ÆÁΩïË¶ãÁñæÁóÖÁöÑÂ†±ÂëäÂàÜÊàêÂ§öÂÄãÂçÄÂ°äÔºåÊØèÂÄãÂçÄÂ°ä‰ª£Ë°®ÁñæÁóÖÁöÑ‰∏çÂêåÂ±¨ÊÄßÔºåÂåÖÊã¨ÂÖ∂Ê¶ÇËø∞„ÄÅÁóáÁãÄ„ÄÅÂéüÂõ†„ÄÅÂΩ±Èüø„ÄÅÁõ∏ÈóúÁñæÁóÖ„ÄÅË®∫Êñ∑ÂíåÊ®ôÊ∫ñÁôÇÊ≥ï„ÄÇÈÄôÁ®ÆÁµêÊßãÁ¢∫‰øùÊØèÂÄãÂçÄÂ°ä‰∏≠ÁöÑË≥áË®äËàáÂïèÈ°å‰øùÊåÅ‰∏ÄËá¥„ÄÇÂØ¶È©óÁµêÊûúË°®ÊòéÔºåReCOP ÂèØ‰ª•ÊúâÊïàÂú∞Â∞á LLM Âú® ReDis-QA Ë≥áÊñôÈõÜ‰∏äÁöÑÊ∫ñÁ¢∫Â∫¶Âπ≥ÂùáÊèêÈ´ò 8%„ÄÇÊ≠§Â§ñÔºåÂÆÉÈ°ØËëóÂú∞ÂºïÂ∞é LLM ÁîüÊàêÂèØ‰ø°ÁöÑÁ≠îÊ°àÂíåËß£ÈáãÔºåÈÄô‰∫õÁ≠îÊ°àÂíåËß£ÈáãÂèØ‰ª•ËøΩÊ∫ØÂà∞ÁèæÊúâÊñáÁçª„ÄÇ

##### **Decoding the human brain tissue response to radiofrequency excitation using a biophysical-model-free deep MRI on a chip framework**
2408.08376v1 by Dinor Nagar, Moritz Zaiss, Or Perlman

Magnetic resonance imaging (MRI) relies on radiofrequency (RF) excitation of
proton spin. Clinical diagnosis requires a comprehensive collation of
biophysical data via multiple MRI contrasts, acquired using a series of RF
sequences that lead to lengthy examinations. Here, we developed a vision
transformer-based framework that captures the spatiotemporal magnetic signal
evolution and decodes the brain tissue response to RF excitation, constituting
an MRI on a chip. Following a per-subject rapid calibration scan (28.2 s), a
wide variety of image contrasts including fully quantitative molecular, water
relaxation, and magnetic field maps can be generated automatically. The method
was validated across healthy subjects and a cancer patient in two different
imaging sites, and proved to be 94% faster than alternative protocols. The deep
MRI on a chip (DeepMonC) framework may reveal the molecular composition of the
human brain tissue in a wide range of pathologies, while offering clinically
attractive scan times.

ÊëòË¶ÅÔºöÁ£ÅÊåØÈÄ†ÂΩ± (MRI) ‰ª∞Ë≥¥Â∞ÑÈ†ª (RF) ÊøÄÁôºË≥™Â≠êËá™Êóã„ÄÇËá®Â∫äË®∫Êñ∑ÈúÄË¶ÅÈÄèÈÅéÂ§öÁ®Æ MRI Â∞çÊØî‰æÜÂÖ®Èù¢Êî∂ÈõÜÁîüÁâ©Áâ©ÁêÜË≥áÊñôÔºå‰∏¶‰ΩøÁî®‰∏ÄÁ≥ªÂàóÊúÉÂ∞éËá¥ÂÜóÈï∑Ê™¢Êü•ÁöÑ RF Â∫èÂàóÂèñÂæó„ÄÇÂú®Ê≠§ÔºåÊàëÂÄëÈñãÁôº‰∫Ü‰∏ÄÂÄãÂü∫ÊñºË¶ñË¶∫ËΩâÊèõÂô®ÁöÑÊû∂ÊßãÔºåÂèØÊì∑ÂèñÊôÇÁ©∫Á£ÅË®äËôüÊºîÂåñ‰∏¶Ëß£Á¢ºËÖ¶ÁµÑÁπîÂ∞ç RF ÊøÄÁôºÁöÑÂèçÊáâÔºåÊßãÊàêÊô∂Áâá‰∏äÁöÑ MRI„ÄÇÂú®ÊØèÊ¨°ÂèóË©¶ËÄÖÁöÑÂø´ÈÄüÊ†°Ê≠£ÊéÉÊèè (28.2 Áßí) ‰πãÂæåÔºåÂèØ‰ª•Ëá™ÂãïÁî¢ÁîüÂêÑÁ®ÆÂΩ±ÂÉèÂ∞çÊØîÔºåÂåÖÊã¨ÂÆåÂÖ®ÈáèÂåñÁöÑÂàÜÂ≠ê„ÄÅÊ∞¥ÂºõÁ∑©ÂíåÁ£ÅÂ†¥Âúñ„ÄÇÊ≠§ÊñπÊ≥ïÂ∑≤Âú®ÂÅ•Â∫∑ÂèóË©¶ËÄÖÂíåÁôåÁóáÊÇ£ËÄÖË∫´‰∏äÊñºÂÖ©ÂÄã‰∏çÂêåÁöÑÂΩ±ÂÉèÊ™¢Êü•Âú∞ÈªûÈÄ≤Ë°åÈ©óË≠âÔºå‰∏¶Ë≠âÊòéÊØîÂÖ∂‰ªñÊñπÊ°àÂø´ 94%„ÄÇÊô∂Áâá‰∏äÁöÑÊ∑±Â∫¶ MRI (DeepMonC) Êû∂ÊßãÂèØËÉΩÊúÉÊè≠Á§∫ÂêÑÁ®ÆÁóÖÁêÜ‰∏≠‰∫∫ËÖ¶ÁµÑÁπîÁöÑÂàÜÂ≠êÁµÑÊàêÔºåÂêåÊôÇÊèê‰æõËá®Â∫ä‰∏äÊúâÂê∏ÂºïÂäõÁöÑÊéÉÊèèÊôÇÈñì„ÄÇ

##### **InVAErt networks for amortized inference and identifiability analysis of lumped parameter hemodynamic models**
2408.08264v1 by Guoxiang Grayson Tong, Carlos A. Sing Long, Daniele E. Schiavazzi

Estimation of cardiovascular model parameters from electronic health records
(EHR) poses a significant challenge primarily due to lack of identifiability.
Structural non-identifiability arises when a manifold in the space of
parameters is mapped to a common output, while practical non-identifiability
can result due to limited data, model misspecification, or noise corruption. To
address the resulting ill-posed inverse problem, optimization-based or Bayesian
inference approaches typically use regularization, thereby limiting the
possibility of discovering multiple solutions. In this study, we use inVAErt
networks, a neural network-based, data-driven framework for enhanced digital
twin analysis of stiff dynamical systems. We demonstrate the flexibility and
effectiveness of inVAErt networks in the context of physiological inversion of
a six-compartment lumped parameter hemodynamic model from synthetic data to
real data with missing components.

ÊëòË¶ÅÔºöÂæûÈõªÂ≠êÂÅ•Â∫∑Á¥ÄÈåÑ (EHR) ‰º∞Ë®àÂøÉË°ÄÁÆ°Ê®°ÂûãÂèÉÊï∏‰∏ªË¶ÅÁî±ÊñºÁº∫‰πèÂèØË≠òÂà•ÊÄßËÄåÊßãÊàêÈáçÂ§ßÊåëÊà∞„ÄÇ
Áï∂ÂèÉÊï∏Á©∫Èñì‰∏≠ÁöÑÊµÅÂΩ¢Â∞çÊáâÂà∞ÂÖ±ÂêåËº∏Âá∫ÊôÇÔºåÊúÉÁî¢ÁîüÁµêÊßãÊÄß‰∏çÂèØË≠òÂà•ÊÄßÔºåËÄåÁî±ÊñºË≥áÊñôÊúâÈôê„ÄÅÊ®°ÂûãÈåØË™§Ë¶èÁØÑÊàñÈõúË®äÁ†¥Â£ûÔºåÂèØËÉΩÊúÉÂ∞éËá¥ÂØ¶Èöõ‰∏çÂèØË≠òÂà•ÊÄß„ÄÇÁÇ∫‰∫ÜËß£Ê±∫Áî±Ê≠§Áî¢ÁîüÁöÑ‰∏çÈÅ©ÂÆöÂèçÂïèÈ°åÔºåÂü∫ÊñºÊúÄ‰Ω≥ÂåñÁöÑË≤ùÊ∞èÊé®Ë´ñÊñπÊ≥ïÈÄöÂ∏∏‰ΩøÁî®Ê≠£ÂâáÂåñÔºåÂæûËÄåÈôêÂà∂ÁôºÁèæÂ§öÈáçËß£ÁöÑÂèØËÉΩÊÄß„ÄÇÂú®Êú¨Á†îÁ©∂‰∏≠ÔºåÊàëÂÄë‰ΩøÁî® inVAErt Á∂≤Ë∑ØÔºåÈÄôÊòØ‰∏ÄÁ®ÆÂü∫ÊñºÁ•ûÁ∂ìÁ∂≤Ë∑Ø„ÄÅË≥áÊñôÈ©ÖÂãïÁöÑÊû∂ÊßãÔºåÁî®ÊñºÂ¢ûÂº∑ÂÉµÁ°¨ÂãïÊÖãÁ≥ªÁµ±ÁöÑÊï∏‰ΩçÈõôËÉûËÉéÂàÜÊûê„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫Ü inVAErt Á∂≤Ë∑ØÂú®ÁîüÁêÜÂèçÊºî‰∏≠ÁöÑÈùàÊ¥ªÊÄßËàáÊúâÊïàÊÄßÔºåÂæûÂêàÊàêË≥áÊñôÂà∞Áº∫Â∞ëÁµÑÊàêÁöÑÁúüÂØ¶Ë≥áÊñôÔºåÂèçÊºîÂÖ≠ÈöîÈñìÈõÜÁ∏ΩÂèÉÊï∏Ë°ÄÊµÅÂãïÂäõÊ®°Âûã„ÄÇ

##### **Your Turn: Real-World Turning Angle Estimation for Parkinson's Disease Severity Assessment**
2408.08182v1 by Qiushuo Cheng, Catherine Morgan, Arindam Sikdar, Alessandro Masullo, Alan Whone, Majid Mirmehdi

People with Parkinson's Disease (PD) often experience progressively worsening
gait, including changes in how they turn around, as the disease progresses.
Existing clinical rating tools are not capable of capturing hour-by-hour
variations of PD symptoms, as they are confined to brief assessments within
clinic settings. Measuring real-world gait turning angles continuously and
passively is a component step towards using gait characteristics as sensitive
indicators of disease progression in PD. This paper presents a deep
learning-based approach to automatically quantify turning angles by extracting
3D skeletons from videos and calculating the rotation of hip and knee joints.
We utilise state-of-the-art human pose estimation models, Fastpose and Strided
Transformer, on a total of 1386 turning video clips from 24 subjects (12 people
with PD and 12 healthy control volunteers), trimmed from a PD dataset of
unscripted free-living videos in a home-like setting (Turn-REMAP). We also
curate a turning video dataset, Turn-H3.6M, from the public Human3.6M human
pose benchmark with 3D ground truth, to further validate our method. Previous
gait research has primarily taken place in clinics or laboratories evaluating
scripted gait outcomes, but this work focuses on real-world settings where
complexities exist, such as baggy clothing and poor lighting. Due to
difficulties in obtaining accurate ground truth data in a free-living setting,
we quantise the angle into the nearest bin $45^\circ$ based on the manual
labelling of expert clinicians. Our method achieves a turning calculation
accuracy of 41.6%, a Mean Absolute Error (MAE) of 34.7{\deg}, and a weighted
precision WPrec of 68.3% for Turn-REMAP. This is the first work to explore the
use of single monocular camera data to quantify turns by PD patients in a home
setting.

ÊëòË¶ÅÔºöÂ∏ïÈáëÊ£ÆÊ∞èÁóá (PD) ÊÇ£ËÄÖÁªèÂ∏∏‰ºöÈöèÁùÄÁñæÁóÖÁöÑËøõÂ±ïËÄåÂá∫Áé∞Ê≠•ÊÄÅÈÄêÊ∏êÊÅ∂ÂåñÁöÑÁé∞Ë±°ÔºåÂåÖÊã¨ËΩ¨Ë∫´ÊñπÂºèÁöÑÂèòÂåñ„ÄÇÁé∞ÊúâÁöÑ‰∏¥Â∫äËØÑÂÆöÂ∑•ÂÖ∑Êó†Ê≥ïÊçïÊçâÂà∞ PD ÁóáÁä∂ÈÄêÂ∞èÊó∂ÁöÑÂèòÂåñÔºåÂõ†‰∏∫ÂÆÉ‰ª¨‰ªÖÈôê‰∫éÂú®‰∏¥Â∫äÁéØÂ¢É‰∏≠ËøõË°åÁü≠ÊöÇÁöÑËØÑ‰º∞„ÄÇËøûÁª≠Ë¢´Âä®Âú∞ÊµãÈáèÁé∞ÂÆû‰∏ñÁïå‰∏≠ÁöÑÊ≠•ÊÄÅËΩ¨ÂºØËßíÂ∫¶ÊòØÂ∞ÜÊ≠•ÊÄÅÁâπÂæÅÁî®‰Ωú PD ÁñæÁóÖËøõÂ±ïÁöÑÊïèÊÑüÊåáÊ†áÁöÑÁªÑÊàêÈÉ®ÂàÜ„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂü∫‰∫éÊ∑±Â∫¶Â≠¶‰π†ÁöÑÊñπÊ≥ïÔºåÈÄöËøá‰ªéËßÜÈ¢ë‰∏≠ÊèêÂèñ 3D È™®Êû∂Âπ∂ËÆ°ÁÆóÈ´ãÂÖ≥ËäÇÂíåËÜùÂÖ≥ËäÇÁöÑÊóãËΩ¨ÔºåËá™Âä®ÈáèÂåñËΩ¨ÂºØËßíÂ∫¶„ÄÇÊàë‰ª¨ÂØπÊù•Ëá™ 24 ‰∏™ÂèóËØïËÄÖÔºà12 Âêç PD ÊÇ£ËÄÖÂíå 12 ÂêçÂÅ•Â∫∑ÂØπÁÖßÂøóÊÑøËÄÖÔºâÁöÑÊÄªÂÖ± 1386 ‰∏™ËΩ¨ÂºØËßÜÈ¢ëÂâ™Ëæë‰ΩøÁî®‰∫ÜÊúÄÂÖàËøõÁöÑ‰∫∫‰ΩìÂßøÂäø‰º∞ËÆ°Ê®°Âûã Fastpose Âíå Strided TransformerÔºåËøô‰∫õÂâ™ËæëÊòØ‰ªéÂÆ∂Â∫≠ÁéØÂ¢É‰∏≠Êó†ËÑöÊú¨Ëá™Áî±ÁîüÊ¥ªËßÜÈ¢ëÁöÑ PD Êï∞ÊçÆÈõÜÔºàTurn-REMAPÔºâ‰∏≠Êà™ÂèñÁöÑ„ÄÇÊàë‰ª¨Ëøò‰ªéÂÖ∑Êúâ 3D ÁúüÂÆûÁöÑÂÖ¨ÂÖ± Human3.6M ‰∫∫‰ΩìÂßøÂäøÂü∫ÂáÜ‰∏≠Êï¥ÁêÜ‰∫Ü‰∏Ä‰∏™ËΩ¨ÂºØËßÜÈ¢ëÊï∞ÊçÆÈõÜ Turn-H3.6MÔºå‰ª•Ëøõ‰∏ÄÊ≠•È™åËØÅÊàë‰ª¨ÁöÑÊñπÊ≥ï„ÄÇ‰ª•ÂæÄÁöÑÊ≠•ÊÄÅÁ†îÁ©∂‰∏ªË¶ÅÂú®ËØÑ‰º∞ËÑöÊú¨ÂåñÊ≠•ÊÄÅÁªìÊûúÁöÑËØäÊâÄÊàñÂÆûÈ™åÂÆ§‰∏≠ËøõË°åÔºå‰ΩÜËøôÈ°πÂ∑•‰ΩúÈáçÁÇπÂÖ≥Ê≥®Â≠òÂú®Â§çÊùÇÊÄßÁöÑÁé∞ÂÆû‰∏ñÁïåÁéØÂ¢ÉÔºå‰æãÂ¶ÇÂÆΩÊùæÁöÑË°£ÊúçÂíåÂÖâÁ∫ø‰∏çË∂≥„ÄÇÁî±‰∫éÂú®Ëá™Áî±ÁîüÊ¥ªÁéØÂ¢É‰∏≠Èöæ‰ª•Ëé∑ÂæóÂáÜÁ°ÆÁöÑÁúüÂÆûÊï∞ÊçÆÔºåÊàë‰ª¨Ê†πÊçÆ‰∏ìÂÆ∂‰∏¥Â∫äÂåªÁîüÁöÑÊâãÂä®Ê†áËÆ∞ÔºåÂ∞ÜËßíÂ∫¶ÈáèÂåñ‰∏∫ÊúÄÊé•ËøëÁöÑÁÆ± $45^\circ$„ÄÇÊàë‰ª¨ÁöÑÊñπÊ≥ïÂØπ Turn-REMAP ÁöÑËΩ¨ÂºØËÆ°ÁÆóÂáÜÁ°ÆÂ∫¶ËææÂà∞ 41.6%ÔºåÂπ≥ÂùáÁªùÂØπËØØÂ∑Æ (MAE) ‰∏∫ 34.7{\deg}ÔºåÂä†ÊùÉÁ≤æÂ∫¶ WPrec ‰∏∫ 68.3%„ÄÇËøôÊòØÈ¶ñÊ¨°Êé¢Á¥¢‰ΩøÁî®ÂçïÁõÆÂçïÁúºÁõ∏Êú∫Êï∞ÊçÆÊù•ÈáèÂåñ PD ÊÇ£ËÄÖÂú®ÂÆ∂‰∏≠ËΩ¨ÂºØÊÉÖÂÜµÁöÑÂ∑•‰Ωú„ÄÇ

##### **Navigating Data Scarcity using Foundation Models: A Benchmark of Few-Shot and Zero-Shot Learning Approaches in Medical Imaging**
2408.08058v1 by Stefano Woerner, Christian F. Baumgartner

Data scarcity is a major limiting factor for applying modern machine learning
techniques to clinical tasks. Although sufficient data exists for some
well-studied medical tasks, there remains a long tail of clinically relevant
tasks with poor data availability. Recently, numerous foundation models have
demonstrated high suitability for few-shot learning (FSL) and zero-shot
learning (ZSL), potentially making them more accessible to practitioners.
However, it remains unclear which foundation model performs best on FSL medical
image analysis tasks and what the optimal methods are for learning from limited
data. We conducted a comprehensive benchmark study of ZSL and FSL using 16
pretrained foundation models on 19 diverse medical imaging datasets. Our
results indicate that BiomedCLIP, a model pretrained exclusively on medical
data, performs best on average for very small training set sizes, while very
large CLIP models pretrained on LAION-2B perform best with slightly more
training samples. However, simply fine-tuning a ResNet-18 pretrained on
ImageNet performs similarly with more than five training examples per class.
Our findings also highlight the need for further research on foundation models
specifically tailored for medical applications and the collection of more
datasets to train these models.

ÊëòË¶ÅÔºöË≥áÊñôÁ®ÄÂ∞ëÊòØÂ∞áÁèæ‰ª£Ê©üÂô®Â≠∏ÁøíÊäÄË°ìÊáâÁî®ÊñºËá®Â∫ä‰ªªÂãôÁöÑ‰∏ªË¶ÅÈôêÂà∂Âõ†Á¥†„ÄÇÂÑòÁÆ°Â∞çÊñº‰∏Ä‰∫õÁ†îÁ©∂ÂÆåÂñÑÁöÑÈÜ´ÁôÇ‰ªªÂãôËÄåË®ÄÂ≠òÂú®Ë∂≥Â§†ÁöÑË≥áÊñôÔºå‰ΩÜ‰ªçÊúâË®±Â§öËá®Â∫äÁõ∏Èóú‰ªªÂãôÁöÑË≥áÊñôÂèØÁî®ÊÄß‰∏ç‰Ω≥„ÄÇÊúÄËøëÔºåË®±Â§öÂü∫Á§éÊ®°ÂûãÂ∑≤Â±ïÁèæÂá∫ÈùûÂ∏∏ÈÅ©ÂêàÂ∞èÊ®£Êú¨Â≠∏Áøí (FSL) ÂíåÈõ∂Ê®£Êú¨Â≠∏Áøí (ZSL)ÔºåÈÄôÊúâÂèØËÉΩËÆìÂæûÊ•≠‰∫∫Âì°Êõ¥ÂÆπÊòì‰ΩøÁî®ÈÄô‰∫õÊ®°Âûã„ÄÇÁÑ∂ËÄåÔºåÁõÆÂâç‰ªç‰∏çÊ∏ÖÊ•öÂì™ÂÄãÂü∫Á§éÊ®°ÂûãÂú® FSL ÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÊûê‰ªªÂãô‰∏≠ÁöÑË°®ÁèæÊúÄ‰Ω≥Ôºå‰ª•ÂèäÂæûÊúâÈôêË≥áÊñô‰∏≠Â≠∏ÁøíÁöÑÊúÄ‰Ω≥ÊñπÊ≥ïÁÇ∫‰Ωï„ÄÇÊàëÂÄëÈáùÂ∞ç 16 ÂÄãÈ†êË®ìÁ∑¥Âü∫Á§éÊ®°ÂûãÂú® 19 ÂÄã‰∏çÂêåÁöÑÈÜ´Â≠∏ÂΩ±ÂÉèË≥áÊñôÈõÜ‰∏äÂü∑Ë°å‰∫Ü‰∏ÄÈ†ÖÂÖ®Èù¢ÁöÑ ZSL Âíå FSL Âü∫Ê∫ñÁ†îÁ©∂„ÄÇÊàëÂÄëÁöÑÁµêÊûúÈ°ØÁ§∫Ôºå‰∏ÄÂÄãÂ∞àÈñÄÈáùÂ∞çÈÜ´ÁôÇË≥áÊñôÈÄ≤Ë°åÈ†êË®ìÁ∑¥ÁöÑÊ®°Âûã BiomedCLIP Âú®ÈùûÂ∏∏Â∞èÁöÑË®ìÁ∑¥ÈõÜÂ§ßÂ∞è‰∏ãË°®ÁèæÊúÄ‰Ω≥ÔºåËÄåÈáùÂ∞ç LAION-2B ÈÄ≤Ë°åÈ†êË®ìÁ∑¥ÁöÑÈùûÂ∏∏Â§ßÂûã CLIP Ê®°ÂûãÂú®Ë®ìÁ∑¥Ê®£Êú¨Á®çÂ§öÁöÑÊÉÖÊ≥Å‰∏ãË°®ÁèæÊúÄ‰Ω≥„ÄÇÁÑ∂ËÄåÔºåÈáùÂ∞ç ImageNet ÈÄ≤Ë°åÈ†êË®ìÁ∑¥ÁöÑ ResNet-18 Âè™Ë¶ÅÊØèÈ°ûÂà•ÊúâË∂ÖÈÅé‰∫îÂÄãË®ìÁ∑¥ÁØÑ‰æãÔºåÂÖ∂ÂæÆË™øË°®ÁèæÂ∞±È°û‰ºº„ÄÇÊàëÂÄëÁöÑÁôºÁèæ‰πüÂá∏È°Ø‰∫ÜÈÄ≤‰∏ÄÊ≠•ÈáùÂ∞çÈÜ´ÁôÇÊáâÁî®ÈáèË∫´ÊâìÈÄ†Âü∫Á§éÊ®°Âûã‰ª•ÂèäÊî∂ÈõÜÊõ¥Â§öË≥áÊñôÈõÜ‰æÜË®ìÁ∑¥ÈÄô‰∫õÊ®°ÂûãÁöÑÁ†îÁ©∂ÈúÄÊ±Ç„ÄÇ

##### **Adaptive User Journeys in Pharma E-Commerce with Reinforcement Learning: Insights from SwipeRx**
2408.08024v1 by Ana Fern√°ndez del R√≠o, Michael Brennan Leong, Paulo Saraiva, Ivan Nazarov, Aditya Rastogi, Moiz Hassan, Dexian Tang, √Åfrica Peri√°√±ez

This paper introduces a reinforcement learning (RL) platform that enhances
end-to-end user journeys in healthcare digital tools through personalization.
We explore a case study with SwipeRx, the most popular all-in-one app for
pharmacists in Southeast Asia, demonstrating how the platform can be used to
personalize and adapt user experiences. Our RL framework is tested through a
series of experiments with product recommendations tailored to each pharmacy
based on real-time information on their purchasing history and in-app
engagement, showing a significant increase in basket size. By integrating
adaptive interventions into existing mobile health solutions and enriching user
journeys, our platform offers a scalable solution to improve pharmaceutical
supply chain management, health worker capacity building, and clinical decision
and patient care, ultimately contributing to better healthcare outcomes.

ÊëòË¶ÅÔºöÊú¨Ë´ñÊñá‰ªãÁ¥π‰∏ÄÂÄãÂº∑ÂåñÂ≠∏Áøí (RL) Âπ≥Âè∞ÔºåÈÄèÈÅéÂÄã‰∫∫Âåñ‰æÜÊèêÂçáÈÜ´ÁôÇ‰øùÂÅ•Êï∏‰ΩçÂ∑•ÂÖ∑‰∏≠ÁöÑ‰ΩøÁî®ËÄÖÊóÖÁ®ã„ÄÇÊàëÂÄëÊé¢Ë®é‰∫Ü‰∏ÄÂÄãÊ°à‰æãÁ†îÁ©∂ÔºåÂ∞çË±°ÊòØÊù±Âçó‰∫ûÊúÄÂèóÊ≠°ËøéÁöÑËó•ÂäëÂ∏´ÂÖ®Êñπ‰ΩçÊáâÁî®Á®ãÂºè SwipeRxÔºåÂ±ïÁ§∫Â¶Ç‰Ωï‰ΩøÁî®Ë©≤Âπ≥Âè∞‰æÜÂÄã‰∫∫ÂåñÂíåË™øÊï¥‰ΩøÁî®ËÄÖÈ´îÈ©ó„ÄÇÊàëÂÄëÁöÑ RL Ê°ÜÊû∂ÈÄèÈÅé‰∏ÄÁ≥ªÂàóÂØ¶È©óÈÄ≤Ë°åÊ∏¨Ë©¶ÔºåÈÄô‰∫õÂØ¶È©óÊ†πÊìöÊØèÂÄãËó•Â±ÄÁöÑË≥ºË≤∑Ê≠∑Á®ãÂíåÊáâÁî®Á®ãÂºè‰∫íÂãïÁöÑÂç≥ÊôÇË≥áË®äÔºåÊèê‰æõÈáèË∫´ÊâìÈÄ†ÁöÑÁî¢ÂìÅÊé®Ëñ¶ÔºåÈ°ØÁ§∫Ë≥ºÁâ©Á±ÉÂ§ßÂ∞èÂ§ßÂπÖÂ¢ûÂä†„ÄÇÈÄèÈÅéÂ∞áÈÅ©ÊáâÊÄß‰ªãÂÖ•Êï¥ÂêàÂà∞ÁèæÊúâÁöÑË°åÂãïÂÅ•Â∫∑Ëß£Ê±∫ÊñπÊ°àÔºå‰∏¶Ë±êÂØå‰ΩøÁî®ËÄÖÊóÖÁ®ãÔºåÊàëÂÄëÁöÑÂπ≥Âè∞Êèê‰æõ‰∫Ü‰∏ÄÂÄãÂèØÊì¥ÂÖÖÁöÑËß£Ê±∫ÊñπÊ°à‰æÜÊîπÂñÑË£ΩËó•‰æõÊáâÈèàÁÆ°ÁêÜ„ÄÅÈÜ´ÁôÇ‰∫∫Âì°ËÉΩÂäõÂª∫Êßã„ÄÅËá®Â∫äÊ±∫Á≠ñÂíåÊÇ£ËÄÖÁÖßË≠∑ÔºåÊúÄÁµÇÊúâÂä©ÊñºÊîπÂñÑÈÜ´ÁôÇ‰øùÂÅ•ÊàêÊûú„ÄÇ

##### **LLaVA-Surg: Towards Multimodal Surgical Assistant via Structured Surgical Video Learning**
2408.07981v1 by Jiajie Li, Garrett Skinner, Gene Yang, Brian R Quaranto, Steven D Schwaitzberg, Peter C W Kim, Jinjun Xiong

Multimodal large language models (LLMs) have achieved notable success across
various domains, while research in the medical field has largely focused on
unimodal images. Meanwhile, current general-domain multimodal models for videos
still lack the capabilities to understand and engage in conversations about
surgical videos. One major contributing factor is the absence of datasets in
the surgical field. In this paper, we create a new dataset, Surg-QA, consisting
of 102,000 surgical video-instruction pairs, the largest of its kind so far. To
build such a dataset, we propose a novel two-stage question-answer generation
pipeline with LLM to learn surgical knowledge in a structured manner from the
publicly available surgical lecture videos. The pipeline breaks down the
generation process into two stages to significantly reduce the task complexity,
allowing us to use a more affordable, locally deployed open-source LLM than the
premium paid LLM services. It also mitigates the risk of LLM hallucinations
during question-answer generation, thereby enhancing the overall quality of the
generated data. We further train LLaVA-Surg, a novel vision-language
conversational assistant capable of answering open-ended questions about
surgical videos, on this Surg-QA dataset, and conduct comprehensive evaluations
on zero-shot surgical video question-answering tasks. We show that LLaVA-Surg
significantly outperforms all previous general-domain models, demonstrating
exceptional multimodal conversational skills in answering open-ended questions
about surgical videos. We will release our code, model, and the
instruction-tuning dataset.

ÊëòË¶ÅÔºöÂ§öÊ®°ÊÖãÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®ÂêÑÂÄãÈ†òÂüüÈÉΩÂèñÂæó‰∫ÜÈ°ØËëóÁöÑÊàêÂäüÔºåËÄåÈÜ´Â≠∏È†òÂüüÁöÑÁ†îÁ©∂Ââá‰∏ªË¶ÅÈõÜ‰∏≠Âú®ÂñÆÊ®°ÊÖãÂΩ±ÂÉè‰∏ä„ÄÇÂêåÊôÇÔºåÁõÆÂâçÁöÑÂΩ±ÁâáÈÄöÁî®È†òÂüüÂ§öÊ®°ÊÖãÊ®°Âûã‰ªçÁº∫‰πèÁêÜËß£ÂíåÂèÉËàáÂ§ñÁßëÂΩ±ÁâáÂ∞çË©±ÁöÑËÉΩÂäõ„ÄÇ‰∏ªË¶ÅÁöÑÂΩ±ÈüøÂõ†Á¥†‰πã‰∏ÄÊòØÂ§ñÁßëÈ†òÂüü‰∏≠Áº∫‰πèË≥áÊñôÈõÜ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂª∫Á´ã‰∫Ü‰∏ÄÂÄãÊñ∞ÁöÑË≥áÊñôÈõÜ Surg-QAÔºåÂÖ∂‰∏≠ÂåÖÂê´ 102,000 ÂÄãÂ§ñÁßëÂΩ±ÁâáÊïôÂ≠∏ÈÖçÂ∞çÔºåÊòØÁõÆÂâçÂêåÈ°ûË≥áÊñôÈõÜ‰∏≠Ë¶èÊ®°ÊúÄÂ§ßÁöÑ„ÄÇÁÇ∫‰∫ÜÂª∫Á´ãÈÄôÊ®£ÁöÑË≥áÊñôÈõÜÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊñ∞Á©éÁöÑÂÖ©ÈöéÊÆµÂïèÁ≠îÁî¢ÁîüÁÆ°ÈÅìÔºå‰ΩøÁî® LLM ‰ª•ÁµêÊßãÂåñÁöÑÊñπÂºèÂæûÂÖ¨ÈñãÁöÑÂ§ñÁßëÊïôÂ≠∏ÂΩ±Áâá‰∏≠Â≠∏ÁøíÂ§ñÁßëÁü•Ë≠ò„ÄÇË©≤ÁÆ°ÈÅìÂ∞áÁî¢ÁîüÈÅéÁ®ãÂàÜÁÇ∫ÂÖ©ÂÄãÈöéÊÆµÔºå‰ª•È°ØËëóÈôç‰Ωé‰ªªÂãôË§áÈõúÊÄßÔºå‰ΩøÊàëÂÄëËÉΩÂ§†‰ΩøÁî®ÊØî‰ªòË≤ª LLM ÊúçÂãôÊõ¥ÂØ¶ÊÉ†ÁöÑÊú¨Âú∞ÈÉ®ÁΩ≤ÈñãÊ∫ê LLM„ÄÇÂÆÉÈÇÑÊ∏õËºï‰∫ÜÂïèÁ≠îÁî¢ÁîüÈÅéÁ®ã‰∏≠ LLM Áî¢ÁîüÂπªË¶∫ÁöÑÈ¢®Èö™ÔºåÂæûËÄåÊèêÈ´ò‰∫ÜÁî¢ÁîüË≥áÊñôÁöÑÊï¥È´îÂìÅË≥™„ÄÇÊàëÂÄëÈÄ≤‰∏ÄÊ≠•Ë®ìÁ∑¥ LLaVA-SurgÔºåÈÄôÊòØ‰∏ÄÂÄãÊñ∞Á©éÁöÑË¶ñË¶∫Ë™ûË®ÄÂ∞çË©±Âä©ÁêÜÔºåËÉΩÂ§†ÂõûÁ≠îÊúâÈóúÂ§ñÁßëÂΩ±ÁâáÁöÑÈñãÊîæÂºèÂïèÈ°åÔºå‰∏¶Âú® Surg-QA Ë≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÂÖ®Èù¢ÁöÑÈõ∂Ê¨°Â≠∏ÁøíÂ§ñÁßëÂΩ±ÁâáÂïèÁ≠î‰ªªÂãôË©ï‰º∞„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫Ü LLaVA-Surg ÊòéÈ°ØÂÑ™ÊñºÊâÄÊúâÂÖàÂâçÁöÑÈÄöÁî®È†òÂüüÊ®°ÂûãÔºåË≠âÊòé‰∫ÜÂú®ÂõûÁ≠îÊúâÈóúÂ§ñÁßëÂΩ±ÁâáÁöÑÈñãÊîæÂºèÂïèÈ°åÊôÇÂÖ∑ÊúâÂçìË∂äÁöÑÂ§öÊ®°ÊÖãÂ∞çË©±ÊäÄËÉΩ„ÄÇÊàëÂÄëÂ∞áÁôºÂ∏ÉÊàëÂÄëÁöÑÁ®ãÂºèÁ¢º„ÄÅÊ®°ÂûãÂíåÊïôÂ≠∏Ë™øÊï¥Ë≥áÊñôÈõÜ„ÄÇ

##### **Enhancing Equitable Access to AI in Housing and Homelessness System of Care through Federated Learning**
2408.07845v1 by Musa Taib, Jiajun Wu, Steve Drew, Geoffrey G. Messier

The top priority of a Housing and Homelessness System of Care (HHSC) is to
connect people experiencing homelessness to supportive housing. An HHSC
typically consists of many agencies serving the same population. Information
technology platforms differ in type and quality between agencies, so their data
are usually isolated from one agency to another. Larger agencies may have
sufficient data to train and test artificial intelligence (AI) tools but
smaller agencies typically do not. To address this gap, we introduce a
Federated Learning (FL) approach enabling all agencies to train a predictive
model collaboratively without sharing their sensitive data. We demonstrate how
FL can be used within an HHSC to provide all agencies equitable access to
quality AI and further assist human decision-makers in the allocation of
resources within HHSC. This is achieved while preserving the privacy of the
people within the data by not sharing identifying information between agencies
without their consent. Our experimental results using real-world HHSC data from
Calgary, Alberta, demonstrate that our FL approach offers comparable
performance with the idealized scenario of training the predictive model with
data fully shared and linked between agencies.

ÊëòË¶ÅÔºö‰ΩèÊàøÂíåÁÑ°ÂÆ∂ÂèØÊ≠∏ËÄÖÁÖßË≠∑Á≥ªÁµ± (HHSC) ÁöÑÈ¶ñË¶Å‰ªªÂãôÊòØ
Â∞áÁÑ°ÂÆ∂ÂèØÊ≠∏ËÄÖËàáÊîØÊåÅÊÄß‰ΩèÊàøÈÄ£ÁµêËµ∑‰æÜ„ÄÇHHSC
ÈÄöÂ∏∏Áî±Ë®±Â§öÊúçÂãôÊñºÁõ∏ÂêåÊóèÁæ§ÁöÑÊ©üÊßãÁµÑÊàê„ÄÇË≥áË®ä
ÊäÄË°ìÂπ≥Âè∞Âú®ÂêÑÂÄãÊ©üÊßã‰πãÈñìÁöÑÈ°ûÂûãÂíåÂìÅË≥™‰∏çÂêåÔºåÂõ†Ê≠§‰ªñÂÄëÁöÑË≥áÊñô
ÈÄöÂ∏∏ÂΩºÊ≠§Â≠§Á´ã„ÄÇËºÉÂ§ßÂûãÁöÑÊ©üÊßãÂèØËÉΩÊìÅÊúâË∂≥Â§†ÁöÑË≥áÊñô‰æÜË®ìÁ∑¥ÂíåÊ∏¨Ë©¶‰∫∫Â∑•Êô∫ÊÖß (AI) Â∑•ÂÖ∑Ôºå‰ΩÜ
ËºÉÂ∞èÂûãÊ©üÊßãÈÄöÂ∏∏Ê≤íÊúâ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂ∑ÆË∑ùÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÁ®Æ
ËÅØÂêàÂºèÂ≠∏Áøí (FL) ÊñπÊ≥ïÔºåËÆìÊâÄÊúâÊ©üÊßãÈÉΩËÉΩÂ§†Âú®‰∏çÂàÜ‰∫´ÂÖ∂ÊïèÊÑüË≥áÊñôÁöÑÊÉÖÊ≥Å‰∏ãÂÖ±ÂêåË®ìÁ∑¥‰∏ÄÂÄãÈ†êÊ∏¨
Ê®°Âûã„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫Ü FL Â¶Ç‰ΩïÂú® HHSC ‰∏≠‰ΩøÁî®Ôºå‰ª•Êèê‰æõÊâÄÊúâÊ©üÊßãÂÖ¨Âπ≥ÂèñÂæó
ÂÑ™Ë≥™ AI ÁöÑÊ©üÊúÉÔºå‰∏¶ÈÄ≤‰∏ÄÊ≠•ÂçîÂä©‰∫∫È°ûÊ±∫Á≠ñËÄÖÂú® HHSC ÂÖßÈÉ®ÂàÜÈÖç
Ë≥áÊ∫ê„ÄÇÈÄôÊòØÂú®‰∏çÁ∂ìÊ©üÊßãÂêåÊÑèÁöÑÊÉÖÊ≥Å‰∏ãÔºå‰∏çÂàÜ‰∫´Ë≠òÂà•Ë≥áË®äÁöÑÊÉÖÊ≥Å‰∏ãÔºå‰øùË≠∑Ë≥áÊñô‰∏≠‰∫∫ÂÄëÁöÑÈö±ÁßÅ‰æÜÂØ¶ÁèæÁöÑ„ÄÇÊàëÂÄë‰ΩøÁî®‰æÜËá™
Âä†ÊãøÂ§ßËâæ‰ºØÂ°îÁúÅÂç°Âä†Âà©ÁöÑÁúüÂØ¶‰∏ñÁïå HHSC Ë≥áÊñôÈÄ≤Ë°åÂØ¶È©óÁµêÊûúÈ°ØÁ§∫ÔºåÊàëÂÄëÁöÑ FL ÊñπÊ≥ïÊèê‰æõËàáÂú®Ê©üÊßã‰πãÈñìÂÆåÂÖ®ÂàÜ‰∫´ÂíåÈÄ£ÁµêË≥áÊñôÁöÑÁêÜÊÉ≥È†êÊ∏¨Ê®°ÂûãË®ìÁ∑¥ÊÉÖÂ¢ÉÁõ∏Áï∂ÁöÑ
ÊïàËÉΩ„ÄÇ

##### **Deep Learning: a Heuristic Three-stage Mechanism for Grid Searches to Optimize the Future Risk Prediction of Breast Cancer Metastasis Using EHR-based Clinical Data**
2408.07673v2 by Xia Jiang, Yijun Zhou, Chuhan Xu, Adam Brufsky, Alan Wells

A grid search, at the cost of training and testing a large number of models,
is an effective way to optimize the prediction performance of deep learning
models. A challenging task concerning grid search is the time management.
Without a good time management scheme, a grid search can easily be set off as a
mission that will not finish in our lifetime. In this study, we introduce a
heuristic three-stage mechanism for managing the running time of low-budget
grid searches, and the sweet-spot grid search (SSGS) and randomized grid search
(RGS) strategies for improving model prediction performance, in predicting the
5-year, 10-year, and 15-year risk of breast cancer metastasis. We develop deep
feedforward neural network (DFNN) models and optimize them through grid
searches. We conduct eight cycles of grid searches by applying our three-stage
mechanism and SSGS and RGS strategies. We conduct various SHAP analyses
including unique ones that interpret the importance of the DFNN-model
hyperparameters. Our results show that grid search can greatly improve model
prediction. The grid searches we conducted improved the risk prediction of
5-year, 10-year, and 15-year breast cancer metastasis by 18.6%, 16.3%, and
17.3% respectively, over the average performance of all corresponding models we
trained using the RGS strategy. We not only demonstrate best model performance
but also characterize grid searches from various aspects such as their
capabilities of discovering decent models and the unit grid search time. The
three-stage mechanism worked effectively. It made our low-budget grid searches
feasible and manageable, and in the meantime helped improve model prediction
performance. Our SHAP analyses identified both clinical risk factors important
for the prediction of future risk of breast cancer metastasis, and DFNN-model
hyperparameters important to the prediction of performance scores.

ÊëòË¶ÅÔºö<paragraph>Á∂≤Ê†ºÊêúÂ∞ã‰ª•Ë®ìÁ∑¥ÂíåÊ∏¨Ë©¶Â§ßÈáèÊ®°ÂûãÁÇ∫‰ª£ÂÉπÔºåÊòØ‰∏ÄÁ®ÆÂÑ™ÂåñÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÈ†êÊ∏¨ÊïàËÉΩÁöÑÊúâÊïàÊñπÊ≥ï„ÄÇÁ∂≤Ê†ºÊêúÂ∞ã‰∏≠‰∏ÄÈ†ÖÂÖ∑ÊúâÊåëÊà∞ÊÄßÁöÑ‰ªªÂãôÊòØÊôÇÈñìÁÆ°ÁêÜ„ÄÇÊ≤íÊúâËâØÂ•ΩÁöÑÊôÇÈñìÁÆ°ÁêÜÊ©üÂà∂ÔºåÁ∂≤Ê†ºÊêúÂ∞ãÂæàÂÆπÊòìË¢´Ë®≠ÂÆöÁÇ∫‰∏ÄÈ†ÖÂú®ÊàëÂÄëÊúâÁîü‰πãÂπ¥ÈÉΩÁÑ°Ê≥ïÂÆåÊàêÁöÑ‰ªªÂãô„ÄÇÂú®Êú¨Á†îÁ©∂‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫Ü‰∏ÄÁ®ÆÂïüÁôºÂºè‰∏âÈöéÊÆµÊ©üÂà∂ÔºåÁî®ÊñºÁÆ°ÁêÜ‰ΩéÈ†êÁÆóÁ∂≤Ê†ºÊêúÂ∞ãÁöÑÂü∑Ë°åÊôÇÈñìÔºå‰ª•ÂèäÁî®ÊñºÊîπÂñÑÊ®°ÂûãÈ†êÊ∏¨ÊïàËÉΩÁöÑÊúÄ‰Ω≥ÈªûÁ∂≤Ê†ºÊêúÂ∞ã (SSGS) ÂíåÈö®Ê©üÁ∂≤Ê†ºÊêúÂ∞ã (RGS) Á≠ñÁï•Ôºå‰ª•È†êÊ∏¨‰π≥ÁôåËΩâÁßªÁöÑ 5 Âπ¥„ÄÅ10 Âπ¥Âíå 15 Âπ¥È¢®Èö™„ÄÇÊàëÂÄëÈñãÁôº‰∫ÜÊ∑±Â∫¶ÂâçÈ•ãÁ•ûÁ∂ìÁ∂≤Ë∑Ø (DFNN) Ê®°ÂûãÔºå‰∏¶ÈÄèÈÅéÁ∂≤Ê†ºÊêúÂ∞ãÂ∞çÂÆÉÂÄëÈÄ≤Ë°åÂÑ™Âåñ„ÄÇÊàëÂÄëÈÄèÈÅéÊáâÁî®‰∏âÈöéÊÆµÊ©üÂà∂Âíå SSGS Âíå RGS Á≠ñÁï•ÈÄ≤Ë°å‰∫ÜÂÖ´ÂÄãÈÄ±ÊúüÁöÑÁ∂≤Ê†ºÊêúÂ∞ã„ÄÇÊàëÂÄëÈÄ≤Ë°å‰∫ÜÂêÑÁ®Æ SHAP ÂàÜÊûêÔºåÂåÖÊã¨Ëß£Èáã DFNN Ê®°ÂûãË∂ÖÂèÉÊï∏ÈáçË¶ÅÊÄßÁöÑÁç®ÁâπÂàÜÊûê„ÄÇÊàëÂÄëÁöÑÁµêÊûúÈ°ØÁ§∫Á∂≤Ê†ºÊêúÂ∞ãÂèØ‰ª•Â§ßÂπÖÊîπÂñÑÊ®°ÂûãÈ†êÊ∏¨„ÄÇÊàëÂÄëÈÄ≤Ë°åÁöÑÁ∂≤Ê†ºÊêúÂ∞ãÂàÜÂà•Â∞á 5 Âπ¥„ÄÅ10 Âπ¥Âíå 15 Âπ¥‰π≥ÁôåËΩâÁßªÁöÑÈ¢®Èö™È†êÊ∏¨ÊîπÂñÑ‰∫Ü 18.6%„ÄÅ16.3% Âíå 17.3%ÔºåÂÑ™ÊñºÊàëÂÄë‰ΩøÁî® RGS Á≠ñÁï•Ë®ìÁ∑¥ÁöÑÊâÄÊúâÂ∞çÊáâÊ®°ÂûãÁöÑÂπ≥ÂùáÊïàËÉΩ„ÄÇÊàëÂÄë‰∏çÂÉÖÂ±ïÁ§∫‰∫ÜÊúÄ‰Ω≥Ê®°ÂûãÊïàËÉΩÔºåÈÇÑÂæûÂêÑÁ®ÆÈù¢ÂêëÊèèËø∞Á∂≤Ê†ºÊêúÂ∞ãÔºå‰æãÂ¶ÇÂÆÉÂÄëÁôºÁèæËâØÂ•ΩÊ®°ÂûãÁöÑËÉΩÂäõÂíåÂñÆÂÖÉÁ∂≤Ê†ºÊêúÂ∞ãÊôÇÈñì„ÄÇ‰∏âÈöéÊÆµÊ©üÂà∂ÊúâÊïàÈÅã‰Ωú„ÄÇÂÆÉ‰ΩøÊàëÂÄëÁöÑ‰ΩéÈ†êÁÆóÁ∂≤Ê†ºÊêúÂ∞ãÂèØË°å‰∏îÊòìÊñºÁÆ°ÁêÜÔºåÂêåÊôÇ‰πüÊúâÂä©ÊñºÊîπÂñÑÊ®°ÂûãÈ†êÊ∏¨ÊïàËÉΩ„ÄÇÊàëÂÄëÁöÑ SHAP ÂàÜÊûêÁ¢∫ÂÆö‰∫ÜÂ∞çÈ†êÊ∏¨Êú™‰æÜ‰π≥ÁôåËΩâÁßªÈ¢®Èö™ÂæàÈáçË¶ÅÁöÑËá®Â∫äÈ¢®Èö™Âõ†Â≠êÔºå‰ª•ÂèäÂ∞çÈ†êÊ∏¨ÊïàËÉΩË©ïÂàÜÂæàÈáçË¶ÅÁöÑ DFNN Ê®°ÂûãË∂ÖÂèÉÊï∏„ÄÇ</paragraph>

##### **Adaptive Behavioral AI: Reinforcement Learning to Enhance Pharmacy Services**
2408.07647v1 by Ana Fern√°ndez del R√≠o, Michael Brennan Leong, Paulo Saraiva, Ivan Nazarov, Aditya Rastogi, Moiz Hassan, Dexian Tang, √Åfrica Peri√°√±ez

Pharmacies are critical in healthcare systems, particularly in low- and
middle-income countries. Procuring pharmacists with the right behavioral
interventions or nudges can enhance their skills, public health awareness, and
pharmacy inventory management, ensuring access to essential medicines that
ultimately benefit their patients. We introduce a reinforcement learning
operational system to deliver personalized behavioral interventions through
mobile health applications. We illustrate its potential by discussing a series
of initial experiments run with SwipeRx, an all-in-one app for pharmacists,
including B2B e-commerce, in Indonesia. The proposed method has broader
applications extending beyond pharmacy operations to optimize healthcare
delivery.

ÊëòË¶ÅÔºöËó•Â±ÄÂú®ÈÜ´ÁôÇ‰øùÂÅ•Á≥ªÁµ±‰∏≠Ëá≥ÈóúÈáçË¶ÅÔºåÁâπÂà•ÊòØÂú®‰∏≠‰ΩéÊî∂ÂÖ•ÂúãÂÆ∂„ÄÇÈÄèÈÅéÈÅ©Áï∂ÁöÑË°åÁÇ∫‰ªãÂÖ•Êé™ÊñΩÊàñÊé®ÂãïÔºåËó•Â∏´ÁöÑÊäÄËÉΩ„ÄÅÂÖ¨ÂÖ±Ë°õÁîüÊÑèË≠òÂíåËó•Â±ÄÂ∫´Â≠òÁÆ°ÁêÜÈÉΩËÉΩÁç≤ÂæóÊèêÂçáÔºåÁ¢∫‰øùÂèñÂæóÂü∫Êú¨Ëó•Áâ©ÔºåÊúÄÁµÇ‰ΩøÊÇ£ËÄÖÂèóÁõä„ÄÇÊàëÂÄëÂºïÈÄ≤Âº∑ÂåñÂ≠∏ÁøíÊìç‰ΩúÁ≥ªÁµ±ÔºåÈÄèÈÅéË°åÂãïÂÅ•Â∫∑ÊáâÁî®Á®ãÂºèÊèê‰æõÂÄã‰∫∫ÂåñÁöÑË°åÁÇ∫‰ªãÂÖ•Êé™ÊñΩ„ÄÇÊàëÂÄëÈÄèÈÅéË®éË´ñ‰∏ÄÁ≥ªÂàóËàá SwipeRxÔºà‰∏ÄÊ¨æÂ∞àÁÇ∫Ëó•Â∏´Ë®≠Ë®àÁöÑ B2B ÈõªÂ≠êÂïÜÂãô‰∏ÄÁ´ôÂºèÊáâÁî®Á®ãÂºèÔºâÂü∑Ë°åÁöÑÂàùÊ≠•ÂØ¶È©óÔºå‰æÜË™™ÊòéÂÖ∂ÊΩõÂäõ„ÄÇÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÂÖ∑ÊúâÊõ¥Âª£Ê≥õÁöÑÊáâÁî®Ôºå‰∏çÂÉÖÈôêÊñºËó•Â±Ä‰ΩúÊ•≠ÔºåÈÇÑËÉΩÊúÄ‰Ω≥ÂåñÈÜ´ÁôÇ‰øùÂÅ•ÁöÑÊèê‰æõ„ÄÇ

##### **Optimizing HIV Patient Engagement with Reinforcement Learning in Resource-Limited Settings**
2408.07629v1 by √Åfrica Peri√°√±ez, Kathrin Schmitz, Lazola Makhupula, Moiz Hassan, Moeti Moleko, Ana Fern√°ndez del R√≠o, Ivan Nazarov, Aditya Rastogi, Dexian Tang

By providing evidence-based clinical decision support, digital tools and
electronic health records can revolutionize patient management, especially in
resource-poor settings where fewer health workers are available and often need
more training. When these tools are integrated with AI, they can offer
personalized support and adaptive interventions, effectively connecting
community health workers (CHWs) and healthcare facilities. The CHARM (Community
Health Access & Resource Management) app is an AI-native mobile app for CHWs.
Developed through a joint partnership of Causal Foundry (CF) and
mothers2mothers (m2m), CHARM empowers CHWs, mainly local women, by streamlining
case management, enhancing learning, and improving communication. This paper
details CHARM's development, integration, and upcoming reinforcement
learning-based adaptive interventions, all aimed at enhancing health worker
engagement, efficiency, and patient outcomes, thereby enhancing CHWs'
capabilities and community health.

ÊëòË¶ÅÔºöÈÄèÈÅéÊèê‰æõÂü∫ÊñºË≠âÊìöÁöÑËá®Â∫äÊ±∫Á≠ñÊîØÊè¥ÔºåÊï∏‰ΩçÂ∑•ÂÖ∑ÂíåÈõªÂ≠êÂÅ•Â∫∑Ë®òÈåÑÂèØ‰ª•ÂæπÂ∫ïÊîπËÆäÁóÖÊÇ£ÁÆ°ÁêÜÔºåÁâπÂà•ÊòØÂú®Ë≥áÊ∫êË≤ß‰πè„ÄÅÈÜ´Ë≠∑‰∫∫Âì°ËºÉÂ∞ë‰∏îÁ∂ìÂ∏∏ÈúÄË¶ÅÊõ¥Â§öË®ìÁ∑¥ÁöÑÁí∞Â¢É‰∏≠„ÄÇÁï∂ÈÄô‰∫õÂ∑•ÂÖ∑Ëàá AI Êï¥ÂêàÊôÇÔºåÂÆÉÂÄëÂèØ‰ª•Êèê‰æõÂÄã‰∫∫ÂåñÊîØÊè¥ÂíåÈÅ©ÊáâÊÄß‰ªãÂÖ•Êé™ÊñΩÔºåÊúâÊïàÂú∞ÈÄ£ÁµêÁ§æÂçÄË°õÁîüÂ∑•‰ΩúËÄÖ (CHW) ÂíåÈÜ´ÁôÇ‰øùÂÅ•Ê©üÊßã„ÄÇCHARMÔºàÁ§æÂçÄÂÅ•Â∫∑Â≠òÂèñËàáË≥áÊ∫êÁÆ°ÁêÜÔºâÊáâÁî®Á®ãÂºèÊòØ‰∏ÄÊ¨æÂ∞àÁÇ∫ CHW Ë®≠Ë®àÁöÑ AI ÂéüÁîüË°åÂãïÊáâÁî®Á®ãÂºè„ÄÇCHARM Áî± Causal Foundry (CF) Âíå mothers2mothers (m2m) ÈÄèÈÅéËÅØÂêàÂ§•‰º¥Èóú‰øÇÂÖ±ÂêåÈñãÁôºÔºåÈÄèÈÅéÁ∞°ÂåñÂÄãÊ°àÁÆ°ÁêÜ„ÄÅÂä†Âº∑Â≠∏ÁøíÂíåÊîπÂñÑÊ∫ùÈÄöÔºåË≥¶‰∫à CHWÔºà‰∏ªË¶ÅÊòØÁï∂Âú∞Â©¶Â•≥ÔºâÊ¨äÂäõ„ÄÇÊú¨ÊñáË©≥Ëø∞ CHARM ÁöÑÈñãÁôº„ÄÅÊï¥ÂêàÂíåÂç≥Â∞áÊé®Âá∫ÁöÑÂü∫ÊñºÂº∑ÂåñÂ≠∏ÁøíÁöÑÈÅ©ÊáâÊÄß‰ªãÂÖ•Êé™ÊñΩÔºåÊâÄÊúâÈÄô‰∫õÈÉΩÊó®Âú®Âä†Âº∑ÈÜ´Ë≠∑‰∫∫Âì°ÁöÑÂèÉËàáÂ∫¶„ÄÅÊïàÁéáÂíåÁóÖÊÇ£ÁöÑÊ≤ªÁôÇÁµêÊûúÔºåÂæûËÄåÊèêÂçá CHW ÁöÑËÉΩÂäõÂíåÁ§æÂçÄÂÅ•Â∫∑„ÄÇ

##### **MetaSeg: MetaFormer-based Global Contexts-aware Network for Efficient Semantic Segmentation**
2408.07576v2 by Beoungwoo Kang, Seunghun Moon, Yubin Cho, Hyunwoo Yu, Suk-Ju Kang

Beyond the Transformer, it is important to explore how to exploit the
capacity of the MetaFormer, an architecture that is fundamental to the
performance improvements of the Transformer. Previous studies have exploited it
only for the backbone network. Unlike previous studies, we explore the capacity
of the Metaformer architecture more extensively in the semantic segmentation
task. We propose a powerful semantic segmentation network, MetaSeg, which
leverages the Metaformer architecture from the backbone to the decoder. Our
MetaSeg shows that the MetaFormer architecture plays a significant role in
capturing the useful contexts for the decoder as well as for the backbone. In
addition, recent segmentation methods have shown that using a CNN-based
backbone for extracting the spatial information and a decoder for extracting
the global information is more effective than using a transformer-based
backbone with a CNN-based decoder. This motivates us to adopt the CNN-based
backbone using the MetaFormer block and design our MetaFormer-based decoder,
which consists of a novel self-attention module to capture the global contexts.
To consider both the global contexts extraction and the computational
efficiency of the self-attention for semantic segmentation, we propose a
Channel Reduction Attention (CRA) module that reduces the channel dimension of
the query and key into the one dimension. In this way, our proposed MetaSeg
outperforms the previous state-of-the-art methods with more efficient
computational costs on popular semantic segmentation and a medical image
segmentation benchmark, including ADE20K, Cityscapes, COCO-stuff, and Synapse.
The code is available at https://github.com/hyunwoo137/MetaSeg.

ÊëòË¶ÅÔºö<paragraph>Èô§‰∫Ü Transformer ‰πãÂ§ñÔºåÊé¢Á¥¢Â¶Ç‰ΩïÂà©Áî® MetaFormer ÁöÑÂÆπÈáèÈùûÂ∏∏ÈáçË¶ÅÔºåMetaFormer ÊòØ‰∏ÄÁßçÂØπ Transformer ÊÄßËÉΩÊîπËøõËá≥ÂÖ≥ÈáçË¶ÅÁöÑÊû∂ÊûÑ„ÄÇ‰ª•ÂæÄÁöÑÁ†îÁ©∂‰ªÖÂ∞ÜÂÖ∂Áî®‰∫é‰∏ªÂπ≤ÁΩëÁªú„ÄÇ‰∏é‰ª•ÂæÄÁöÑÁ†îÁ©∂‰∏çÂêåÔºåÊàë‰ª¨Âú®ËØ≠‰πâÂàÜÂâ≤‰ªªÂä°‰∏≠Êõ¥ÂπøÊ≥õÂú∞Êé¢Á¥¢‰∫Ü Metaformer Êû∂ÊûÑÁöÑÂÆπÈáè„ÄÇÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏Ä‰∏™Âº∫Â§ßÁöÑËØ≠‰πâÂàÜÂâ≤ÁΩëÁªú MetaSegÔºåÂÆÉÂà©Áî®‰∫Ü‰ªé‰∏ªÂπ≤Âà∞Ëß£Á†ÅÂô®ÁöÑ Metaformer Êû∂ÊûÑ„ÄÇÊàë‰ª¨ÁöÑ MetaSeg Ë°®ÊòéÔºåMetaFormer Êû∂ÊûÑÂú®‰∏∫Ëß£Á†ÅÂô®Âíå‰∏ªÂπ≤ÊçïËé∑ÊúâÁî®‰∏ä‰∏ãÊñáÊñπÈù¢ÂèëÊå•‰∫ÜÈáçË¶Å‰ΩúÁî®„ÄÇÊ≠§Â§ñÔºåÊúÄËøëÁöÑÂàÜÂâ≤ÊñπÊ≥ïË°®ÊòéÔºå‰ΩøÁî®Âü∫‰∫é CNN ÁöÑ‰∏ªÂπ≤ÊèêÂèñÁ©∫Èó¥‰ø°ÊÅØÂíå‰ΩøÁî®Ëß£Á†ÅÂô®ÊèêÂèñÂÖ®Â±Ä‰ø°ÊÅØÊØî‰ΩøÁî®Âü∫‰∫é Transformer ÁöÑ‰∏ªÂπ≤ÂíåÂü∫‰∫é CNN ÁöÑËß£Á†ÅÂô®Êõ¥ÊúâÊïà„ÄÇËøô‰øÉ‰ΩøÊàë‰ª¨ÈááÁî®‰ΩøÁî® MetaFormer ÂùóÁöÑÂü∫‰∫é CNN ÁöÑ‰∏ªÂπ≤ÔºåÂπ∂ËÆæËÆ°‰∫ÜÂü∫‰∫é MetaFormer ÁöÑËß£Á†ÅÂô®ÔºåËØ•Ëß£Á†ÅÂô®ÂåÖÂê´‰∏Ä‰∏™Êñ∞È¢ñÁöÑËá™Ê≥®ÊÑèÂäõÊ®°ÂùóÊù•ÊçïËé∑ÂÖ®Â±Ä‰∏ä‰∏ãÊñá„ÄÇ‰∏∫‰∫ÜÂêåÊó∂ËÄÉËôëÂÖ®Â±Ä‰∏ä‰∏ãÊñáÊèêÂèñÂíåËØ≠‰πâÂàÜÂâ≤ÁöÑËá™Ê≥®ÊÑèÂäõÁöÑËÆ°ÁÆóÊïàÁéáÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçÈÄöÈÅìÁº©ÂáèÊ≥®ÊÑèÂäõ (CRA) Ê®°ÂùóÔºåÂÆÉÂ∞ÜÊü•ËØ¢ÂíåÈîÆÁöÑÈÄöÈÅìÁª¥Â∫¶Áº©Âáè‰∏∫‰∏Ä‰∏™Áª¥Â∫¶„ÄÇÈÄöËøáËøôÁßçÊñπÂºèÔºåÊàë‰ª¨ÊèêÂá∫ÁöÑ MetaSeg Âú®ÊµÅË°åÁöÑËØ≠‰πâÂàÜÂâ≤ÂíåÂåªÂ≠¶ÂõæÂÉèÂàÜÂâ≤Âü∫ÂáÜÔºàÂåÖÊã¨ ADE20K„ÄÅCityscapes„ÄÅCOCO-stuff Âíå SynapseÔºâ‰∏ä‰ª•Êõ¥ÊúâÊïàÁöÑËÆ°ÁÆóÊàêÊú¨‰ºò‰∫é‰ª•ÂæÄÁöÑÊúÄÊñ∞ÊñπÊ≥ï„ÄÇ‰ª£Á†ÅÂèØÂú® https://github.com/hyunwoo137/MetaSeg Ëé∑Âæó„ÄÇ</paragraph>

##### **Multi-task Heterogeneous Graph Learning on Electronic Health Records**
2408.07569v1 by Tsai Hor Chan, Guosheng Yin, Kyongtae Bae, Lequan Yu

Learning electronic health records (EHRs) has received emerging attention
because of its capability to facilitate accurate medical diagnosis. Since the
EHRs contain enriched information specifying complex interactions between
entities, modeling EHRs with graphs is shown to be effective in practice. The
EHRs, however, present a great degree of heterogeneity, sparsity, and
complexity, which hamper the performance of most of the models applied to them.
Moreover, existing approaches modeling EHRs often focus on learning the
representations for a single task, overlooking the multi-task nature of EHR
analysis problems and resulting in limited generalizability across different
tasks. In view of these limitations, we propose a novel framework for EHR
modeling, namely MulT-EHR (Multi-Task EHR), which leverages a heterogeneous
graph to mine the complex relations and model the heterogeneity in the EHRs. To
mitigate the large degree of noise, we introduce a denoising module based on
the causal inference framework to adjust for severe confounding effects and
reduce noise in the EHR data. Additionally, since our model adopts a single
graph neural network for simultaneous multi-task prediction, we design a
multi-task learning module to leverage the inter-task knowledge to regularize
the training process. Extensive empirical studies on MIMIC-III and MIMIC-IV
datasets validate that the proposed method consistently outperforms the
state-of-the-art designs in four popular EHR analysis tasks -- drug
recommendation, and predictions of the length of stay, mortality, and
readmission. Thorough ablation studies demonstrate the robustness of our method
upon variations to key components and hyperparameters.

ÊëòË¶ÅÔºö<paragraph>Â≠∏ÁøíÈõªÂ≠êÂÅ•Â∫∑Á¥ÄÈåÑÔºàEHRÔºâÁî±ÊñºÂÖ∂‰øÉÈÄ≤Ê∫ñÁ¢∫ÈÜ´ÁôÇË®∫Êñ∑ÁöÑËÉΩÂäõËÄåÂÇôÂèóÈóúÊ≥®„ÄÇÁî±Êñº EHR ÂåÖÂê´Ë±êÂØåË≥áË®äÔºåÊåáÂÆöÂØ¶È´î‰πãÈñìÁöÑË§áÈõú‰∫íÂãïÔºåÂõ†Ê≠§‰ΩøÁî®ÂúñÂΩ¢Âª∫Ê®° EHR Â∑≤Ë¢´Ë≠âÊòéÂú®ÂØ¶Âãô‰∏äÂæàÊúâÊïà„ÄÇÁÑ∂ËÄåÔºåEHR ÂëàÁèæÂá∫È´òÂ∫¶ÁöÑÁï∞Ë≥™ÊÄß„ÄÅÁ®ÄÁñèÊÄßÂíåË§áÈõúÊÄßÔºåÈÄôÊúÉÈòªÁ§ôÊáâÁî®ÊñºÂÆÉÂÄëÁöÑÂ§ßÂ§öÊï∏Ê®°ÂûãÁöÑÊïàËÉΩ„ÄÇÊ≠§Â§ñÔºåÁèæÊúâÁöÑÂª∫Ê®° EHR ÊñπÊ≥ïÈÄöÂ∏∏Â∞àÊ≥®ÊñºÂ≠∏ÁøíÂñÆ‰∏Ä‰ªªÂãôÁöÑË°®Á§∫ÔºåÂøΩÁï• EHR ÂàÜÊûêÂïèÈ°åÁöÑÂ§ö‰ªªÂãôÊÄßË≥™Ôºå‰∏¶Â∞éËá¥Ë∑®‰∏çÂêå‰ªªÂãôÁöÑÊ¶ÇÊã¨ËÉΩÂäõÊúâÈôê„ÄÇÊúâÈëëÊñºÈÄô‰∫õÈôêÂà∂ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü EHR Âª∫Ê®°ÁöÑÊñ∞Êû∂ÊßãÔºåÂç≥ MulT-EHRÔºàÂ§ö‰ªªÂãô EHRÔºâÔºåÂÆÉÂà©Áî®Áï∞Ë≥™Âúñ‰æÜÊåñÊéòË§áÈõúÈóú‰øÇ‰∏¶Âª∫Ê®° EHR ‰∏≠ÁöÑÁï∞Ë≥™ÊÄß„ÄÇÁÇ∫‰∫ÜÊ∏õËºïÂ§ßÈáèÁöÑÈõúË®äÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜÂü∫ÊñºÂõ†ÊûúÊé®Ë´ñÊû∂ÊßãÁöÑÂéªÈõúË®äÊ®°ÁµÑÔºå‰ª•Ë™øÊï¥Âö¥ÈáçÁöÑÊ∑∑Ê∑ÜÊïàÊáâ‰∏¶Ê∏õÂ∞ë EHR Ë≥áÊñô‰∏≠ÁöÑÈõúË®ä„ÄÇÊ≠§Â§ñÔºåÁî±ÊñºÊàëÂÄëÁöÑÊ®°ÂûãÊé°Áî®ÂñÆ‰∏ÄÂúñÂΩ¢Á•ûÁ∂ìÁ∂≤Ë∑ØÈÄ≤Ë°åÂêåÊôÇÁöÑÂ§ö‰ªªÂãôÈ†êÊ∏¨ÔºåÂõ†Ê≠§ÊàëÂÄëË®≠Ë®à‰∫Ü‰∏ÄÂÄãÂ§ö‰ªªÂãôÂ≠∏ÁøíÊ®°ÁµÑÔºå‰ª•Âà©Áî®‰ªªÂãôÈñìÁöÑÁü•Ë≠ò‰æÜË¶èÁØÑË®ìÁ∑¥ÈÅéÁ®ã„ÄÇÂú® MIMIC-III Âíå MIMIC-IV Ë≥áÊñôÈõÜ‰∏äÁöÑÂª£Ê≥õÂØ¶Ë≠âÁ†îÁ©∂È©óË≠â‰∫ÜÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÂú®ÂõõÈ†ÖÊµÅË°åÁöÑ EHR ÂàÜÊûê‰ªªÂãô‰∏≠ÂßãÁµÇÂÑ™ÊñºÊúÄÂÖàÈÄ≤ÁöÑË®≠Ë®à‚Äî‚ÄîËó•Áâ©Êé®Ëñ¶‰ª•ÂèäÈ†êÊ∏¨‰ΩèÈô¢ÊôÇÈñì„ÄÅÊ≠ª‰∫°ÁéáÂíåÂÜçÂÖ•Èô¢Áéá„ÄÇÂæπÂ∫ïÁöÑÊ∂àËûçÁ†îÁ©∂Ë≠âÊòé‰∫ÜÊàëÂÄëÁöÑÊñπÊ≥ïÂú®ÈóúÈçµÁµÑÊàêÈÉ®ÂàÜÂíåË∂ÖÂèÉÊï∏ËÆäÂåñ‰∏äÁöÑÁ©©ÂÅ•ÊÄß„ÄÇ</paragraph>

##### **Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**
2408.07531v1 by Seungjun Han, Wongyung Choi

Emergency department (ED) overcrowding and the complexity of rapid
decision-making in critical care settings pose significant challenges to
healthcare systems worldwide. While clinical decision support systems (CDSS)
have shown promise, the integration of large language models (LLMs) offers new
possibilities for enhancing triage accuracy and clinical decision-making. This
study presents an LLM-driven CDSS designed to assist ED physicians and nurses
in patient triage, treatment planning, and overall emergency care management.
  We developed a multi-agent CDSS utilizing Llama-3-70b as the base LLM,
orchestrated by CrewAI and Langchain. The system comprises four AI agents
emulating key ED roles: Triage Nurse, Emergency Physician, Pharmacist, and ED
Coordinator. It incorporates the Korean Triage and Acuity Scale (KTAS) for
triage assessment and integrates with the RxNorm API for medication management.
  The model was evaluated using the Asclepius dataset, with performance
assessed by a clinical emergency medicine specialist. The CDSS demonstrated
high accuracy in triage decision-making compared to the baseline of a
single-agent system. Furthermore, the system exhibited strong performance in
critical areas, including primary diagnosis, critical findings identification,
disposition decision-making, treatment planning, and resource allocation.
  Our multi-agent CDSS demonstrates significant potential for supporting
comprehensive emergency care management. By leveraging state-of-the-art AI
technologies, this system offers a scalable and adaptable tool that could
enhance emergency medical care delivery, potentially alleviating ED
overcrowding and improving patient outcomes. This work contributes to the
growing field of AI applications in emergency medicine and offers a promising
direction for future research and clinical implementation.

ÊëòË¶ÅÔºö<paragraph>ÊÄ•Ë®∫ÂÆ§ÔºàEDÔºâ‰∫∫ÊªøÁÇ∫ÊÇ£Ôºå‰ª•ÂèäÂú®ÈáçÁóáÁÖßË≠∑Áí∞Â¢É‰∏≠Âø´ÈÄüÂÅöÊ±∫ÂÆöÁöÑË§áÈõúÊÄßÂ∞çÂÖ®ÁêÉÁöÑÈÜ´ÁôÇ‰øùÂÅ•Á≥ªÁµ±ÊßãÊàêÈáçÂ§ßÊåëÊà∞„ÄÇÈõñÁÑ∂Ëá®Â∫äÊ±∫Á≠ñÊîØÊè¥Á≥ªÁµ±ÔºàCDSSÔºâÂ∑≤Â±ïÁèæÂâçÊôØÔºå‰ΩÜÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâÁöÑÊï¥ÂêàÁÇ∫ÊèêÂçáÂàÜÊµÅÊ∫ñÁ¢∫Â∫¶ÂíåËá®Â∫äÊ±∫Á≠ñÊèê‰æõ‰∫ÜÊñ∞ÁöÑÂèØËÉΩÊÄß„ÄÇÊú¨Á†îÁ©∂ÊèêÂá∫‰∏ÄÂÄãÁî± LLM È©ÖÂãïÁöÑ CDSSÔºåÊó®Âú®ÂçîÂä©ÊÄ•Ë®∫ÂÆ§ÈÜ´Â∏´ÂíåË≠∑ÁêÜÂ∏´ÈÄ≤Ë°åÁóÖ‰∫∫ÂàÜÊµÅ„ÄÅÊ≤ªÁôÇË®àÁï´ÂíåÊï¥È´îÁ∑äÊÄ•ÁÖßË≠∑ÁÆ°ÁêÜ„ÄÇ
  ÊàëÂÄëÈñãÁôº‰∫Ü‰∏ÄÂÄãÂ§öÈáç‰ª£ÁêÜ CDSSÔºåÂà©Áî® Llama-3-70b ‰ΩúÁÇ∫Âü∫Á§é LLMÔºåÁî± CrewAI Âíå Langchain Á∑®Êéí„ÄÇÊ≠§Á≥ªÁµ±ÂåÖÂê´ÂõõÂÄãÊ®°Êì¨ÈóúÈçµÊÄ•Ë®∫ÂÆ§ËßíËâ≤ÁöÑ AI ‰ª£ÁêÜÔºöÂàÜÊµÅË≠∑ÁêÜÂ∏´„ÄÅÊÄ•Ë®∫ÈÜ´Â∏´„ÄÅËó•Â∏´ÂíåÊÄ•Ë®∫ÂÆ§ÂçîË™øÂì°„ÄÇÂÆÉÊï¥ÂêàÈüìÂúãÂàÜÊµÅËàáÂö¥ÈáçÊåáÊï∏ÈáèË°®ÔºàKTASÔºâÈÄ≤Ë°åÂàÜÊµÅË©ï‰º∞Ôºå‰∏¶Ëàá RxNorm API Êï¥ÂêàÈÄ≤Ë°åËó•Áâ©ÁÆ°ÁêÜ„ÄÇ
  Ë©≤Ê®°Âûã‰ΩøÁî® Asclepius Ë≥áÊñôÈõÜÈÄ≤Ë°åË©ï‰º∞ÔºåÁî±Ëá®Â∫äÊÄ•Ë®∫ÈÜ´Â≠∏Â∞àÂÆ∂Ë©ï‰º∞ÂÖ∂ÊïàËÉΩ„ÄÇËàáÂñÆ‰∏Ä‰ª£ÁêÜÁ≥ªÁµ±ÁöÑÂü∫Ê∫ñÁõ∏ÊØîÔºåCDSS Âú®ÂàÜÊµÅÊ±∫Á≠ñÊñπÈù¢Â±ïÁèæÈ´òÊ∫ñÁ¢∫Â∫¶„ÄÇÊ≠§Â§ñÔºåË©≤Á≥ªÁµ±Âú®‰∏ªË¶ÅË®∫Êñ∑„ÄÅÈóúÈçµÁôºÁèæË≠òÂà•„ÄÅËôïÁΩÆÊ±∫Á≠ñ„ÄÅÊ≤ªÁôÇË®àÁï´ÂíåË≥áÊ∫êÂàÜÈÖçÁ≠âÈóúÈçµÈ†òÂüüË°®ÁèæÂá∫Ëâ≤„ÄÇ
  ÊàëÂÄëÁöÑÂ§öÈáç‰ª£ÁêÜ CDSS Ë≠âÊòé‰∫ÜÂú®ÊîØÊè¥ÂÖ®Èù¢ÁöÑÁ∑äÊÄ•ÁÖßË≠∑ÁÆ°ÁêÜÊñπÈù¢ÂÖ∑ÊúâÈ°ØËëóÁöÑÊΩõÂäõ„ÄÇÈÄèÈÅéÂà©Áî®ÊúÄÂÖàÈÄ≤ÁöÑ AI ÊäÄË°ìÔºåÊ≠§Á≥ªÁµ±Êèê‰æõ‰∫Ü‰∏ÄÂÄãÂèØÊì¥ÂÖÖ‰∏îÂèØÈÅ©ÊáâÁöÑÂ∑•ÂÖ∑ÔºåÂèØ‰ª•ÊèêÂçáÁ∑äÊÄ•ÈÜ´ÁôÇÁÖßË≠∑ÁöÑÊèê‰æõÔºåÈÄ≤ËÄåÂèØËÉΩÁ∑©Ëß£ÊÄ•Ë®∫ÂÆ§‰∫∫ÊªøÁÇ∫ÊÇ£ÁöÑÊÉÖÊ≥Å‰∏¶ÊîπÂñÑÁóÖÊÇ£ÁöÑÈ†êÂæå„ÄÇÈÄôÈ†ÖÂ∑•‰Ωú‰øÉÈÄ≤‰∫Ü AI Âú®ÊÄ•Ë®∫ÈÜ´Â≠∏‰∏≠ÁöÑÊáâÁî®È†òÂüüÔºå‰∏¶ÁÇ∫Êú™‰æÜÁöÑÁ†îÁ©∂ÂíåËá®Â∫äÂØ¶‰ΩúÊèê‰æõ‰∫ÜÊúâÂâçÊôØÁöÑÊñπÂêë„ÄÇ</paragraph>

##### **Improving Global Parameter-sharing in Physically Heterogeneous Multi-agent Reinforcement Learning with Unified Action Space**
2408.07395v1 by Xiaoyang Yu, Youfang Lin, Shuo Wang, Kai Lv, Sheng Han

In a multi-agent system (MAS), action semantics indicates the different
influences of agents' actions toward other entities, and can be used to divide
agents into groups in a physically heterogeneous MAS. Previous multi-agent
reinforcement learning (MARL) algorithms apply global parameter-sharing across
different types of heterogeneous agents without careful discrimination of
different action semantics. This common implementation decreases the
cooperation and coordination between agents in complex situations. However,
fully independent agent parameters dramatically increase the computational cost
and training difficulty. In order to benefit from the usage of different action
semantics while also maintaining a proper parameter-sharing structure, we
introduce the Unified Action Space (UAS) to fulfill the requirement. The UAS is
the union set of all agent actions with different semantics. All agents first
calculate their unified representation in the UAS, and then generate their
heterogeneous action policies using different available-action-masks. To
further improve the training of extra UAS parameters, we introduce a
Cross-Group Inverse (CGI) loss to predict other groups' agent policies with the
trajectory information. As a universal method for solving the physically
heterogeneous MARL problem, we implement the UAS adding to both value-based and
policy-based MARL algorithms, and propose two practical algorithms: U-QMIX and
U-MAPPO. Experimental results in the SMAC environment prove the effectiveness
of both U-QMIX and U-MAPPO compared with several state-of-the-art MARL methods.

ÊëòË¶ÅÔºöÂú®Â§öÊô∫ËÉΩÈ´îÁ≥ªÁµ± (MAS) ‰∏≠ÔºåÂãï‰ΩúË™ûÁæ©Ë°®Á§∫Êô∫ËÉΩÈ´îÂãï‰ΩúÂ∞çÂÖ∂‰ªñÂØ¶È´îÁöÑ‰∏çÂêåÂΩ±ÈüøÔºåÂèØÁî®ÊñºÂ∞áÊô∫ËÉΩÈ´îÂàÜÁµÑÂà∞Áâ©ÁêÜÁï∞Ë≥™ MAS ‰∏≠„ÄÇÂÖàÂâçÁöÑÂ§öÊô∫ËÉΩÈ´îÂº∑ÂåñÂ≠∏Áøí (MARL) ÊºîÁÆóÊ≥ïÂ∞ç‰∏çÂêåÈ°ûÂûãÁöÑÁï∞Ë≥™Êô∫ËÉΩÈ´îÂ•óÁî®ÂÖ®ÂüüÂèÉÊï∏ÂÖ±‰∫´ÔºåËÄåÊú™‰ªîÁ¥∞ÂçÄÂàÜ‰∏çÂêåÁöÑÂãï‰ΩúË™ûÁæ©„ÄÇÈÄôÁ®ÆÂ∏∏Ë¶ãÁöÑÂØ¶‰ΩúÊúÉÈôç‰ΩéÊô∫ËÉΩÈ´îÂú®Ë§áÈõúÊÉÖÊ≥Å‰∏ãÁöÑÂêà‰ΩúËàáÂçîË™ø„ÄÇÁÑ∂ËÄåÔºåÂÆåÂÖ®Áç®Á´ãÁöÑÊô∫ËÉΩÈ´îÂèÉÊï∏ÊúÉÂ§ßÂπÖÂ¢ûÂä†ÈÅãÁÆóÊàêÊú¨ÂíåË®ìÁ∑¥Èõ£Â∫¶„ÄÇÁÇ∫‰∫ÜÂæû‰ΩøÁî®‰∏çÂêåÁöÑÂãï‰ΩúË™ûÁæ©‰∏≠Áç≤ÁõäÔºåÂêåÊôÇ‰πüÁ∂≠ÊåÅÈÅ©Áï∂ÁöÑÂèÉÊï∏ÂÖ±‰∫´ÁµêÊßãÔºåÊàëÂÄëÂºïÈÄ≤Áµ±‰∏ÄÂãï‰ΩúÁ©∫Èñì (UAS) ‰æÜÊªøË∂≥ÈúÄÊ±Ç„ÄÇUAS ÊòØÂÖ∑Êúâ‰∏çÂêåË™ûÁæ©ÁöÑÊâÄÊúâÊô∫ËÉΩÈ´îÂãï‰ΩúÁöÑËÅØÈõÜ„ÄÇÊâÄÊúâÊô∫ËÉΩÈ´îÊúÉÂÖàÂú® UAS ‰∏≠Ë®àÁÆóÂÖ∂Áµ±‰∏ÄË°®Á§∫ÔºåÁÑ∂Âæå‰ΩøÁî®‰∏çÂêåÁöÑÂèØÁî®Âãï‰ΩúÈÅÆÁΩ©Áî¢ÁîüÂÖ∂Áï∞Ë≥™Âãï‰ΩúÊîøÁ≠ñ„ÄÇÁÇ∫‰∫ÜÈÄ≤‰∏ÄÊ≠•ÊîπÂñÑÈ°çÂ§ñ UAS ÂèÉÊï∏ÁöÑË®ìÁ∑¥ÔºåÊàëÂÄëÂºïÈÄ≤‰∏ÄÂÄãË∑®Áæ§ÁµÑÂèçÂêë (CGI) ÊêçÂ§±Ôºå‰ª•‰ΩøÁî®ËªåË∑°Ë≥áË®äÈ†êÊ∏¨ÂÖ∂‰ªñÁæ§ÁµÑÁöÑÊô∫ËÉΩÈ´îÊîøÁ≠ñ„ÄÇ‰ΩúÁÇ∫Ëß£Ê±∫Áâ©ÁêÜÁï∞Ë≥™ MARL ÂïèÈ°åÁöÑÈÄöÁî®ÊñπÊ≥ïÔºåÊàëÂÄëÂØ¶‰Ωú UAS Âä†ÂÖ•Âü∫ÊñºÂÉπÂÄºÂíåÂü∫ÊñºÊîøÁ≠ñÁöÑ MARL ÊºîÁÆóÊ≥ïÔºå‰∏¶ÊèêÂá∫ÂÖ©Á®ÆÂØ¶Áî®ÁöÑÊºîÁÆóÊ≥ïÔºöU-QMIX Âíå U-MAPPO„ÄÇÂú® SMAC Áí∞Â¢É‰∏≠ÁöÑÂØ¶È©óÁµêÊûúË≠âÊòé‰∫Ü U-QMIX Âíå U-MAPPO ËàáÂπæÁ®ÆÊúÄÂÖàÈÄ≤ÁöÑ MARL ÊñπÊ≥ïÁõ∏ÊØîÁöÑÊúâÊïàÊÄß„ÄÇ

##### **The Complexity of Manipulation of k-Coalitional Games on Graphs**
2408.07368v1 by Hodaya Barr, Yohai Trabelsi, Sarit Kraus, Liam Roditty, Noam Hazon

In many settings, there is an organizer who would like to divide a set of
agents into $k$ coalitions, and cares about the friendships within each
coalition. Specifically, the organizer might want to maximize utilitarian
social welfare, maximize egalitarian social welfare, or simply guarantee that
every agent will have at least one friend within his coalition. However, in
many situations, the organizer is not familiar with the friendship connections,
and he needs to obtain them from the agents. In this setting, a manipulative
agent may falsely report friendship connections in order to increase his
utility. In this paper, we analyze the complexity of finding manipulation in
such $k$-coalitional games on graphs. We also introduce a new type of
manipulation, socially-aware manipulation, in which the manipulator would like
to increase his utility without decreasing the social welfare. We then study
the complexity of finding socially-aware manipulation in our setting. Finally,
we examine the frequency of socially-aware manipulation and the running time of
our algorithms via simulation results.

ÊëòË¶ÅÔºöÂú®Ë®±Â§öÊÉÖÊ≥Å‰∏ãÔºåÊúÉÊúâ‰∏Ä‰ΩçÁµÑÁπîËÄÖÂ∏åÊúõÂ∞á‰∏ÄÁµÑ‰ª£ÁêÜÂäÉÂàÜÁÇ∫ $k$ ÂÄãËÅØÁõüÔºå‰∏¶ÈóúÂøÉÊØèÂÄãËÅØÁõüÂÖßÁöÑÂèãË™º„ÄÇÂÖ∑È´îËÄåË®ÄÔºåÁµÑÁπîËÄÖÂèØËÉΩÂ∏åÊúõÊúÄÂ§ßÂåñÂäüÂà©‰∏ªÁæ©Á§æÊúÉÁ¶èÂà©„ÄÅÊúÄÂ§ßÂåñÂπ≥Á≠â‰∏ªÁæ©Á§æÊúÉÁ¶èÂà©ÔºåÊàñÂÉÖ‰øùË≠âÊØèÂÄã‰ª£ÁêÜÂú®ÂÖ∂ËÅØÁõüÂÖßËá≥Â∞ëÊúâ‰∏Ä‰ΩçÊúãÂèã„ÄÇÁÑ∂ËÄåÔºåÂú®Ë®±Â§öÊÉÖÊ≥Å‰∏ãÔºåÁµÑÁπîËÄÖ‰∏¶‰∏çÁÜüÊÇâÂèãË™ºÈóú‰øÇÔºå‰ªñÈúÄË¶ÅÂæû‰ª£ÁêÜ‰∏≠Áç≤ÂèñÈÄô‰∫õÈóú‰øÇ„ÄÇÂú®ÈÄôÁ®ÆÊÉÖÊ≥Å‰∏ãÔºå‰∏ÄÂÄãÂÖ∑ÊúâÊìçÁ∏±ÊÄßÁöÑ‰ª£ÁêÜÂèØËÉΩÊúÉËôõÂÅáÂ†±ÂëäÂèãË™ºÈóú‰øÇÔºå‰ª•Â¢ûÂä†‰ªñÁöÑÊïàÁî®„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂàÜÊûê‰∫ÜÂú®ÂúñÂΩ¢‰∏äÁôºÁèæÈÄôÁ®Æ $k$-ËÅØÁõüÈÅäÊà≤‰∏≠ÊìçÁ∏±Ë°åÁÇ∫ÁöÑË§áÈõúÊÄß„ÄÇÊàëÂÄëÈÇÑÂºïÂÖ•‰∫Ü‰∏ÄÁ®ÆÈ°ûÂûãÁöÑÊìçÁ∏±ÔºåÂç≥Á§æÊúÉÊÑèË≠òÊìçÁ∏±ÔºåÂÖ∂‰∏≠ÊìçÁ∏±ËÄÖÂ∏åÊúõÂú®‰∏çÈôç‰ΩéÁ§æÊúÉÁ¶èÂà©ÁöÑÊÉÖÊ≥Å‰∏ãÂ¢ûÂä†‰ªñÁöÑÊïàÁî®„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÁ†îÁ©∂‰∫ÜÂú®ÊàëÂÄëÁöÑÁí∞Â¢É‰∏≠ÁôºÁèæÁ§æÊúÉÊÑèË≠òÊìçÁ∏±ÁöÑË§áÈõúÊÄß„ÄÇÊúÄÂæåÔºåÊàëÂÄëÈÄöÈÅéÊ®°Êì¨ÁµêÊûúÊ™¢Êü•‰∫ÜÁ§æÊúÉÊÑèË≠òÊìçÁ∏±ÁöÑÈ†ªÁéáÂíåÊàëÂÄëÊºîÁÆóÊ≥ïÁöÑÂü∑Ë°åÊôÇÈñì„ÄÇ

##### **Model Counting in the Wild**
2408.07059v1 by Arijit Shaw, Kuldeep S. Meel

Model counting is a fundamental problem in automated reasoning with
applications in probabilistic inference, network reliability, neural network
verification, and more. Although model counting is computationally intractable
from a theoretical perspective due to its #P-completeness, the past decade has
seen significant progress in developing state-of-the-art model counters to
address scalability challenges.
  In this work, we conduct a rigorous assessment of the scalability of model
counters in the wild. To this end, we surveyed 11 application domains and
collected an aggregate of 2262 benchmarks from these domains. We then evaluated
six state-of-the-art model counters on these instances to assess scalability
and runtime performance.
  Our empirical evaluation demonstrates that the performance of model counters
varies significantly across different application domains, underscoring the
need for careful selection by the end user. Additionally, we investigated the
behavior of different counters with respect to two parameters suggested by the
model counting community, finding only a weak correlation. Our analysis
highlights the challenges and opportunities for portfolio-based approaches in
model counting.

ÊëòË¶ÅÔºöÊ®°ÂûãË®àÊï∏ÊòØËá™ÂãïÊé®ÁêÜ‰∏≠ÁöÑÂü∫Êú¨ÂïèÈ°åÔºåÂú®Ê©üÁéáÊé®Ë´ñ„ÄÅÁ∂≤Ë∑ØÂèØÈù†Â∫¶„ÄÅÁ•ûÁ∂ìÁ∂≤Ë∑ØÈ©óË≠âÁ≠âÈ†òÂüüÊúâÂÖ∂ÊáâÁî®„ÄÇÂÑòÁÆ°Ê®°ÂûãË®àÊï∏Âú®ÁêÜË´ñ‰∏äÂõ†ÂÖ∂ #P-completeness ËÄåÂú®Ë®àÁÆó‰∏äÈõ£‰ª•ËôïÁêÜÔºåÈÅéÂéªÂçÅÂπ¥‰æÜÔºåÂú®ÈñãÁôºÊúÄÂÖàÈÄ≤ÁöÑÊ®°ÂûãË®àÊï∏Âô®‰ª•Ëß£Ê±∫ÂèØÊì¥ÂÖÖÊÄßÊåëÊà∞ÊñπÈù¢Â∑≤ÂèñÂæóÈ°ØËëóÈÄ≤Â±ï„ÄÇ
Âú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂ∞çÊ®°ÂûãË®àÊï∏Âô®ÁöÑÂèØÊì¥ÂÖÖÊÄßÈÄ≤Ë°å‰∫ÜÂö¥Ë¨πÁöÑË©ï‰º∞„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëË™øÊü•‰∫Ü 11 ÂÄãÊáâÁî®È†òÂüüÔºå‰∏¶ÂæûÈÄô‰∫õÈ†òÂüüÊî∂ÈõÜ‰∫Ü 2262 ÂÄãÂü∫Ê∫ñ„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÂú®ÈÄô‰∫õÂØ¶‰æã‰∏äË©ï‰º∞‰∫ÜÂÖ≠ÂÄãÊúÄÂÖàÈÄ≤ÁöÑÊ®°ÂûãË®àÊï∏Âô®Ôºå‰ª•Ë©ï‰º∞ÂèØÊì¥ÂÖÖÊÄßÂíåÂü∑Ë°åÊôÇÈñìÊïàËÉΩ„ÄÇ
ÊàëÂÄëÁöÑÂØ¶Ë≠âË©ï‰º∞Ë°®ÊòéÔºåÊ®°ÂûãË®àÊï∏Âô®ÁöÑÊïàËÉΩÂõ†‰∏çÂêåÁöÑÊáâÁî®È†òÂüüËÄåÁï∞ÔºåÈÄôÂá∏È°Ø‰∫ÜÊúÄÁµÇ‰ΩøÁî®ËÄÖ‰ªîÁ¥∞ÈÅ∏ÊìáÁöÑÂøÖË¶ÅÊÄß„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁ†îÁ©∂‰∫Ü‰∏çÂêåË®àÊï∏Âô®Áõ∏Â∞çÊñºÊ®°ÂûãË®àÊï∏Á§æÁæ§Âª∫Ë≠∞ÁöÑÂÖ©ÂÄãÂèÉÊï∏ÁöÑË°åÁÇ∫ÔºåÁôºÁèæÂè™ÊúâÂæÆÂº±ÁöÑÁõ∏ÈóúÊÄß„ÄÇÊàëÂÄëÁöÑÂàÜÊûêÈáçÈªûË™™Êòé‰∫ÜÊ®°ÂûãË®àÊï∏‰∏≠Âü∫ÊñºÊäïË≥áÁµÑÂêàÁöÑÊñπÊ≥ïÊâÄÈù¢Ëá®ÁöÑÊåëÊà∞ÂíåÊ©üÊúÉ„ÄÇ

##### **KAN You See It? KANs and Sentinel for Effective and Explainable Crop Field Segmentation**
2408.07040v1 by Daniele Rege Cambrin, Eleonora Poeta, Eliana Pastor, Tania Cerquitelli, Elena Baralis, Paolo Garza

Segmentation of crop fields is essential for enhancing agricultural
productivity, monitoring crop health, and promoting sustainable practices. Deep
learning models adopted for this task must ensure accurate and reliable
predictions to avoid economic losses and environmental impact. The newly
proposed Kolmogorov-Arnold networks (KANs) offer promising advancements in the
performance of neural networks. This paper analyzes the integration of KAN
layers into the U-Net architecture (U-KAN) to segment crop fields using
Sentinel-2 and Sentinel-1 satellite images and provides an analysis of the
performance and explainability of these networks. Our findings indicate a 2\%
improvement in IoU compared to the traditional full-convolutional U-Net model
in fewer GFLOPs. Furthermore, gradient-based explanation techniques show that
U-KAN predictions are highly plausible and that the network has a very high
ability to focus on the boundaries of cultivated areas rather than on the areas
themselves. The per-channel relevance analysis also reveals that some channels
are irrelevant to this task.

ÊëòË¶ÅÔºöËæ≤‰ΩúÁâ©Áî∞ÂçÄÂàÜÂâ≤Â∞çÊñºÊèêÂçáËæ≤Ê•≠ÁîüÁî¢Âäõ„ÄÅÁõ£Êéß‰ΩúÁâ©ÂÅ•Â∫∑Âíå‰øÉÈÄ≤Ê∞∏Á∫åÂØ¶ÂãôËá≥ÈóúÈáçË¶Å„ÄÇÊé°Áî®ÊñºÊ≠§‰ªªÂãôÁöÑÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÂøÖÈ†àÁ¢∫‰øùÊ∫ñÁ¢∫‰∏îÂèØÈù†ÁöÑÈ†êÊ∏¨Ôºå‰ª•ÈÅøÂÖçÁ∂ìÊøüÊêçÂ§±ÂíåÁí∞Â¢ÉÂΩ±Èüø„ÄÇÊñ∞ÊèêÂá∫ÁöÑÊüØÁàæËé´Âì•Ê¥õÂ§´-ÈòøË´æÂæ∑Á∂≤Ë∑Ø (KAN) ÁÇ∫Á•ûÁ∂ìÁ∂≤Ë∑ØÁöÑÊïàËÉΩÊèê‰æõ‰∫ÜÊúâÂ∏åÊúõÁöÑÈÄ≤Â±ï„ÄÇÊú¨ÊñáÂàÜÊûêÂ∞á KAN Â±§Êï¥ÂêàÂà∞ U-Net Êû∂Êßã (U-KAN) ‰∏≠Ôºå‰ª•‰ΩøÁî® Sentinel-2 Âíå Sentinel-1 Ë°õÊòüÂΩ±ÂÉèÂàÜÂâ≤Ëæ≤‰ΩúÁâ©Áî∞ÂçÄÔºå‰∏¶Êèê‰æõÂ∞çÈÄô‰∫õÁ∂≤Ë∑ØÊïàËÉΩÂíåÂèØËß£ÈáãÊÄßÁöÑÂàÜÊûê„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÈ°ØÁ§∫ÔºåËàáÂÇ≥Áµ±ÁöÑÂÖ®Âç∑Á©ç U-Net Ê®°ÂûãÁõ∏ÊØîÔºåIoU ÊèêÂçá‰∫Ü 2%ÔºåËÄå GFLOP ËºÉÂ∞ë„ÄÇÊ≠§Â§ñÔºåÂü∫ÊñºÊ¢ØÂ∫¶ÁöÑËß£ÈáãÊäÄË°ìÈ°ØÁ§∫ U-KAN È†êÊ∏¨ÈùûÂ∏∏ÂêàÁêÜÔºåËÄå‰∏îÁ∂≤Ë∑ØÈùûÂ∏∏ÊúâËÉΩÂäõÂ∞àÊ≥®ÊñºËÄï‰ΩúÂçÄÂüüÁöÑÈÇäÁïåÔºåËÄå‰∏çÊòØÂçÄÂüüÊú¨Ë∫´„ÄÇÊØèÂÄãÈÄöÈÅìÈóúËÅØÊÄßÂàÜÊûê‰πüÈ°ØÁ§∫ÔºåÊúâ‰∫õÈÄöÈÅìËàáÊ≠§‰ªªÂãôÁÑ°Èóú„ÄÇ

##### **PathInsight: Instruction Tuning of Multimodal Datasets and Models for Intelligence Assisted Diagnosis in Histopathology**
2408.07037v1 by Xiaomin Wu, Rui Xu, Pengchen Wei, Wenkang Qin, Peixiang Huang, Ziheng Li, Lin Luo

Pathological diagnosis remains the definitive standard for identifying
tumors. The rise of multimodal large models has simplified the process of
integrating image analysis with textual descriptions. Despite this advancement,
the substantial costs associated with training and deploying these complex
multimodal models, together with a scarcity of high-quality training datasets,
create a significant divide between cutting-edge technology and its application
in the clinical setting. We had meticulously compiled a dataset of
approximately 45,000 cases, covering over 6 different tasks, including the
classification of organ tissues, generating pathology report descriptions, and
addressing pathology-related questions and answers. We have fine-tuned
multimodal large models, specifically LLaVA, Qwen-VL, InternLM, with this
dataset to enhance instruction-based performance. We conducted a qualitative
assessment of the capabilities of the base model and the fine-tuned model in
performing image captioning and classification tasks on the specific dataset.
The evaluation results demonstrate that the fine-tuned model exhibits
proficiency in addressing typical pathological questions. We hope that by
making both our models and datasets publicly available, they can be valuable to
the medical and research communities.

ÊëòË¶ÅÔºöÁóÖÁêÜË®∫Êñ∑‰ªçÁÑ∂ÊòØË≠òÂà•ËÖ´Áò§ÁöÑÊòéÁ¢∫Ê®ôÊ∫ñ„ÄÇÂ§öÊ®°ÊÖãÂ§ßÂûãÊ®°ÂûãÁöÑËààËµ∑Á∞°Âåñ‰∫ÜÂ∞áÂΩ±ÂÉèÂàÜÊûêËàáÊñáÂ≠óÊèèËø∞Êï¥ÂêàÁöÑÈÅéÁ®ã„ÄÇÂÑòÁÆ°ÊúâÊ≠§ÈÄ≤Â±ïÔºå‰ΩÜË®ìÁ∑¥ÂíåÈÉ®ÁΩ≤ÈÄô‰∫õË§áÈõúÁöÑÂ§öÊ®°ÊÖãÊ®°ÂûãÁõ∏ÈóúÁöÑÈæêÂ§ßÊàêÊú¨Ôºå‰ª•ÂèäÁº∫‰πèÈ´òÂìÅË≥™ÁöÑË®ìÁ∑¥Ë≥áÊñôÈõÜÔºåÂ∞éËá¥Â∞ñÁ´ØÊäÄË°ìËàáÂÖ∂Âú®Ëá®Â∫äÁí∞Â¢É‰∏≠ÁöÑÊáâÁî®‰πãÈñìÁî¢Áîü‰∫ÜÈ°ØËëóÁöÑÂ∑ÆË∑ù„ÄÇÊàëÂÄëÂ∑≤Á¥∞ÂøÉÁ∑®Âà∂‰∫Ü‰∏ÄÂÄãÂåÖÂê´Á¥Ñ 45,000 ÂÄãÊ°à‰æãÁöÑË≥áÊñôÈõÜÔºåÊ∂µËìã 6 È†Ö‰∏çÂêåÁöÑ‰ªªÂãôÔºåÂåÖÊã¨Âô®ÂÆòÁµÑÁπîÂàÜÈ°û„ÄÅÁî¢ÁîüÁóÖÁêÜÂ†±ÂëäÊèèËø∞Ôºå‰ª•ÂèäÂõûÁ≠îËàáÁóÖÁêÜÁõ∏ÈóúÁöÑÂïèÈ°å„ÄÇÊàëÂÄë‰ΩøÁî®ÈÄôÂÄãË≥áÊñôÈõÜÂæÆË™ø‰∫ÜÂ§öÊ®°ÊÖãÂ§ßÂûãÊ®°ÂûãÔºåÁâπÂà•ÊòØ LLaVA„ÄÅQwen-VL„ÄÅInternLMÔºå‰ª•Â¢ûÂº∑Âü∫ÊñºÊåá‰ª§ÁöÑÊïàËÉΩ„ÄÇÊàëÂÄëÂ∞çÂü∫Á§éÊ®°ÂûãÂíåÂæÆË™øÊ®°ÂûãÂú®ÁâπÂÆöË≥áÊñôÈõÜ‰∏äÂü∑Ë°åÂΩ±ÂÉèÊ®ôÈ°åÂíåÂàÜÈ°û‰ªªÂãôÁöÑËÉΩÂäõÈÄ≤Ë°å‰∫ÜÂÆöÊÄßË©ï‰º∞„ÄÇË©ï‰º∞ÁµêÊûúË°®ÊòéÔºåÂæÆË™øÊ®°ÂûãÂú®ÂõûÁ≠îÂÖ∏ÂûãÁóÖÁêÜÂïèÈ°åÊñπÈù¢Ë°®ÁèæÂá∫ÁÜüÁ∑¥Â∫¶„ÄÇÊàëÂÄëÂ∏åÊúõÈÄèÈÅéÂÖ¨ÈñãÊàëÂÄëÁöÑÊ®°ÂûãÂíåË≥áÊñôÈõÜÔºåÂÆÉÂÄëËÉΩÂ∞çÈÜ´ÁôÇÂíåÁ†îÁ©∂Á§æÁæ§ÊúâÂÉπÂÄº„ÄÇ

##### **Diagnosis extraction from unstructured Dutch echocardiogram reports using span- and document-level characteristic classification**
2408.06930v2 by Bauke Arends, Melle Vessies, Dirk van Osch, Arco Teske, Pim van der Harst, Ren√© van Es, Bram van Es

Clinical machine learning research and AI driven clinical decision support
models rely on clinically accurate labels. Manually extracting these labels
with the help of clinical specialists is often time-consuming and expensive.
This study tests the feasibility of automatic span- and document-level
diagnosis extraction from unstructured Dutch echocardiogram reports. We
included 115,692 unstructured echocardiogram reports from the UMCU a large
university hospital in the Netherlands. A randomly selected subset was manually
annotated for the occurrence and severity of eleven commonly described cardiac
characteristics. We developed and tested several automatic labelling techniques
at both span and document levels, using weighted and macro F1-score, precision,
and recall for performance evaluation. We compared the performance of span
labelling against document labelling methods, which included both direct
document classifiers and indirect document classifiers that rely on span
classification results. The SpanCategorizer and MedRoBERTa$.$nl models
outperformed all other span and document classifiers, respectively. The
weighted F1-score varied between characteristics, ranging from 0.60 to 0.93 in
SpanCategorizer and 0.96 to 0.98 in MedRoBERTa$.$nl. Direct document
classification was superior to indirect document classification using span
classifiers. SetFit achieved competitive document classification performance
using only 10% of the training data. Utilizing a reduced label set yielded
near-perfect document classification results. We recommend using our published
SpanCategorizer and MedRoBERTa$.$nl models for span- and document-level
diagnosis extraction from Dutch echocardiography reports. For settings with
limited training data, SetFit may be a promising alternative for document
classification.

ÊëòË¶ÅÔºö<paragraph>Ëá®Â∫äÊ©üÂô®Â≠∏ÁøíÁ†îÁ©∂Âíå‰∫∫Â∑•Êô∫ÊÖßÈ©ÖÂãïÁöÑËá®Â∫äÊ±∫Á≠ñÊîØÊè¥
Ê®°Âûã‰æùË≥¥ÊñºËá®Â∫äÊ∫ñÁ¢∫ÁöÑÊ®ôÁ±§„ÄÇÂú®Ëá®Â∫äÂ∞àÂÆ∂ÁöÑÂçîÂä©‰∏ãÔºåÊâãÂãïÊèêÂèñÈÄô‰∫õÊ®ôÁ±§ÈÄöÂ∏∏Êó¢ËÄóÊôÇÂèàÊòÇË≤¥„ÄÇ
Êú¨Á†îÁ©∂Ê∏¨Ë©¶‰∫ÜÂæûÈùûÁµêÊßãÂåñËç∑Ëò≠Ë∂ÖÈü≥Ê≥¢ÂøÉÂãïÂúñÂ†±Âëä‰∏≠Ëá™ÂãïÊèêÂèñË∑®Â∫¶ÂíåÊñá‰ª∂Á¥öÂà•Ë®∫Êñ∑ÁöÑÂèØË°åÊÄß„ÄÇÊàëÂÄë
Á¥çÂÖ•‰∫Ü‰æÜËá™Ëç∑Ëò≠‰∏ÄÂÆ∂Â§ßÂûãÂ§ßÂ≠∏ÈÜ´Èô¢ UMCU ÁöÑ 115,692 ‰ªΩÈùûÁµêÊßãÂåñË∂ÖÈü≥Ê≥¢ÂøÉÂãïÂúñÂ†±Âëä„ÄÇÈö®Ê©üÈÅ∏ÊìáÁöÑÂ≠êÈõÜÁ∂ìÈÅéÊâãÂãïË®ªËß£Ôºå‰ª•‰∫ÜËß£ÂçÅ‰∏ÄÁ®ÆÂ∏∏Ë¶ãÊèèËø∞ÁöÑÂøÉËáü
ÁâπÂæµÁöÑÁôºÁîüÂíåÂö¥ÈáçÁ®ãÂ∫¶„ÄÇÊàëÂÄëÈñãÁôº‰∏¶Ê∏¨Ë©¶‰∫ÜË∑®Â∫¶ÂíåÊñá‰ª∂Á¥öÂà•ÁöÑÂπæÁ®ÆËá™ÂãïÊ®ôÁ±§ÊäÄË°ìÔºå‰ΩøÁî®Âä†Ê¨äÂíåÂ∑®ÈõÜ F1 ÂàÜÊï∏„ÄÅÁ≤æÁ¢∫Â∫¶Ôºå
‰ª•ÂèäÂè¨ÂõûÁéáÈÄ≤Ë°åÊïàËÉΩË©ï‰º∞„ÄÇÊàëÂÄëÊØîËºÉ‰∫ÜË∑®Â∫¶
Ê®ôÁ±§ËàáÊñá‰ª∂Ê®ôÁ±§ÊñπÊ≥ïÁöÑÊïàËÉΩÔºåÂÖ∂‰∏≠ÂåÖÊã¨Áõ¥Êé•
Êñá‰ª∂ÂàÜÈ°ûÂô®Âíå‰æùË≥¥ÊñºË∑®Â∫¶
ÂàÜÈ°ûÁµêÊûúÁöÑÈñìÊé•Êñá‰ª∂ÂàÜÈ°ûÂô®„ÄÇSpanCategorizer Âíå MedRoBERTa$.$nl Ê®°Âûã
ÂàÜÂà•ÂÑ™ÊñºÊâÄÊúâÂÖ∂‰ªñË∑®Â∫¶ÂíåÊñá‰ª∂ÂàÜÈ°ûÂô®„ÄÇ
Âä†Ê¨ä F1 ÂàÜÊï∏Âõ†ÁâπÂæµËÄåÁï∞ÔºåSpanCategorizer ‰∏≠ÁöÑÁØÑÂúçÂæû 0.60 Âà∞ 0.93ÔºåMedRoBERTa$.$nl ‰∏≠ÁöÑÁØÑÂúçÂæû 0.96 Âà∞ 0.98„ÄÇ‰ΩøÁî®Ë∑®Â∫¶
ÂàÜÈ°ûÂô®ÁöÑÈñìÊé•Êñá‰ª∂ÂàÜÈ°û‰∏çÂ¶ÇÁõ¥Êé•Êñá‰ª∂ÂàÜÈ°û„ÄÇSetFit ÂÉÖ‰ΩøÁî® 10% ÁöÑË®ìÁ∑¥Ë≥áÊñôÂ∞±ÈÅîÂà∞‰∫ÜÂÖ∑ÊúâÁ´∂Áà≠ÂäõÁöÑÊñá‰ª∂ÂàÜÈ°ûÊïàËÉΩ„ÄÇÂà©Áî®Ê∏õÂ∞ëÁöÑÊ®ôÁ±§ÈõÜÁî¢Áîü‰∫ÜËøë‰πéÂÆåÁæéÁöÑÊñá‰ª∂ÂàÜÈ°ûÁµêÊûú„ÄÇÊàëÂÄëÂª∫Ë≠∞‰ΩøÁî®ÊàëÂÄëÁôºÂ∏ÉÁöÑ SpanCategorizer Âíå MedRoBERTa$.$nl Ê®°ÂûãÂæûËç∑Ëò≠Ë∂ÖÈü≥Ê≥¢ÂøÉÂãïÂúñÂ†±Âëä‰∏≠ÊèêÂèñË∑®Â∫¶ÂíåÊñá‰ª∂Á¥öÂà•Ë®∫Êñ∑„ÄÇÂ∞çÊñºË®ìÁ∑¥Ë≥áÊñôÊúâÈôêÁöÑË®≠ÂÆöÔºåSetFit ÂèØËÉΩÊòØ‰∏ÄÁ®ÆÊúâÂâçÈÄîÁöÑÊñá‰ª∂
ÂàÜÈ°ûÊõø‰ª£ÊñπÊ°à„ÄÇ</paragraph>

##### **BMFT: Achieving Fairness via Bias-based Weight Masking Fine-tuning**
2408.06890v1 by Yuyang Xue, Junyu Yan, Raman Dutt, Fasih Haider, Jingshuai Liu, Steven McDonagh, Sotirios A. Tsaftaris

Developing models with robust group fairness properties is paramount,
particularly in ethically sensitive domains such as medical diagnosis. Recent
approaches to achieving fairness in machine learning require a substantial
amount of training data and depend on model retraining, which may not be
practical in real-world scenarios. To mitigate these challenges, we propose
Bias-based Weight Masking Fine-Tuning (BMFT), a novel post-processing method
that enhances the fairness of a trained model in significantly fewer epochs
without requiring access to the original training data. BMFT produces a mask
over model parameters, which efficiently identifies the weights contributing
the most towards biased predictions. Furthermore, we propose a two-step
debiasing strategy, wherein the feature extractor undergoes initial fine-tuning
on the identified bias-influenced weights, succeeded by a fine-tuning phase on
a reinitialised classification layer to uphold discriminative performance.
Extensive experiments across four dermatological datasets and two sensitive
attributes demonstrate that BMFT outperforms existing state-of-the-art (SOTA)
techniques in both diagnostic accuracy and fairness metrics. Our findings
underscore the efficacy and robustness of BMFT in advancing fairness across
various out-of-distribution (OOD) settings. Our code is available at:
https://github.com/vios-s/BMFT

ÊëòË¶ÅÔºö<paragraph>ÈñãÁôºÂÖ∑ÊúâÁ©©ÂÅ•Áæ§ÁµÑÂÖ¨Âπ≥ÊÄßÁâπÊÄßÁöÑÊ®°ÂûãËá≥ÈóúÈáçË¶ÅÔºåÁâπÂà•ÊòØÂú®ÈÜ´ÁôÇË®∫Êñ∑Á≠âÈÅìÂæ∑ÊïèÊÑüÈ†òÂüü„ÄÇÊúÄËøëÂØ¶ÁèæÊ©üÂô®Â≠∏ÁøíÂÖ¨Âπ≥ÊÄßÁöÑÊñπÊ≥ïÈúÄË¶ÅÂ§ßÈáèÁöÑË®ìÁ∑¥Ë≥áÊñôÔºå‰∏¶‰∏î‰æùË≥¥ÊñºÊ®°ÂûãÂÜçË®ìÁ∑¥ÔºåÈÄôÂú®ÁèæÂØ¶ÊÉÖÊ≥Å‰∏≠ÂèØËÉΩ‰∏çÂàáÂØ¶Èöõ„ÄÇÁÇ∫‰∫ÜÁ∑©Ëß£ÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÊèêÂá∫‰∫ÜÂü∫ÊñºÂÅèÂ∑ÆÁöÑÊ¨äÈáçÈÅÆÁΩ©ÂæÆË™ø (BMFT)ÔºåÈÄôÊòØ‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÂæåËôïÁêÜÊñπÊ≥ïÔºåÂèØ‰ª•Âú®È°ØËëóÊõ¥Â∞ëÁöÑËº™Ê¨°‰∏≠Â¢ûÂº∑Ë®ìÁ∑¥Ê®°ÂûãÁöÑÂÖ¨Âπ≥ÊÄßÔºåËÄåÁÑ°ÈúÄË®™ÂïèÂéüÂßãË®ìÁ∑¥Ë≥áÊñô„ÄÇBMFT Âú®Ê®°ÂûãÂèÉÊï∏‰∏äÁî¢Áîü‰∏ÄÂÄãÈÅÆÁΩ©ÔºåÊúâÊïàÂú∞Ë≠òÂà•Âá∫Â∞çÂÅèÂ∑ÆÈ†êÊ∏¨Ë≤¢ÁçªÊúÄÂ§ßÁöÑÊ¨äÈáç„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂÖ©Ê≠•ÂéªÂÅèÁ≠ñÁï•ÔºåÂÖ∂‰∏≠ÁâπÂæµÊèêÂèñÂô®Â∞çË≠òÂà•Âá∫ÁöÑÂÅèÂ∑ÆÂΩ±ÈüøÊ¨äÈáçÈÄ≤Ë°åÂàùÂßãÂæÆË™øÔºåÁÑ∂ÂæåÂú®ÈáçÊñ∞ÂàùÂßãÂåñÁöÑÂàÜÈ°ûÂ±§‰∏äÈÄ≤Ë°åÂæÆË™øÈöéÊÆµ‰ª•Á∂≠ÊåÅÂçÄÂàÜÊïàËÉΩ„ÄÇÂú®ÂõõÂÄãÁöÆËÜöÁßëË≥áÊñôÈõÜÂíåÂÖ©ÂÄãÊïèÊÑüÂ±¨ÊÄßÁöÑÂª£Ê≥õÂØ¶È©ó‰∏≠Ë≠âÊòéÔºåBMFT Âú®Ë®∫Êñ∑Ê∫ñÁ¢∫ÊÄßÂíåÂÖ¨Âπ≥ÊÄßÊåáÊ®ô‰∏äÈÉΩÂÑ™ÊñºÁèæÊúâÁöÑÊúÄÂÖàÈÄ≤ (SOTA) ÊäÄË°ì„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÂº∑Ë™ø‰∫Ü BMFT Âú®Êé®ÈÄ≤ÂêÑÁ®ÆÈùûÂàÜ‰Ωà (OOD) Ë®≠ÂÆö‰∏≠ÁöÑÂÖ¨Âπ≥ÊÄßÊñπÈù¢ÁöÑÊïàÂäõÂíåÁ©©ÂÅ•ÊÄß„ÄÇÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÂèØÂú®‰ª•‰∏ã‰ΩçÁΩÆÁç≤ÂæóÔºö
https://github.com/vios-s/BMFT</paragraph>

##### **Synthetic Patient-Physician Dialogue Generation from Clinical Notes Using LLM**
2408.06285v1 by Trisha Das, Dina Albassam, Jimeng Sun

Medical dialogue systems (MDS) enhance patient-physician communication,
improve healthcare accessibility, and reduce costs. However, acquiring suitable
data to train these systems poses significant challenges. Privacy concerns
prevent the use of real conversations, necessitating synthetic alternatives.
Synthetic dialogue generation from publicly available clinical notes offers a
promising solution to this issue, providing realistic data while safeguarding
privacy. Our approach, SynDial, uses a single LLM iteratively with zero-shot
prompting and a feedback loop to generate and refine high-quality synthetic
dialogues. The feedback consists of weighted evaluation scores for similarity
and extractiveness. The iterative process ensures dialogues meet predefined
thresholds, achieving superior extractiveness as a result of the feedback loop.
Additionally, evaluation shows that the generated dialogues excel in factuality
metric compared to the baselines and has comparable diversity scores with GPT4.

ÊëòË¶ÅÔºöÈÜ´ÁôÇÂ∞çË©±Á≥ªÁµ± (MDS) ÂèØÂ¢ûÂº∑ÁóÖÊÇ£ËàáÈÜ´Â∏´ÁöÑÊ∫ùÈÄö„ÄÅÊîπÂñÑÈÜ´ÁôÇ‰øùÂÅ•ÁöÑÂèØËøëÊÄßÔºå‰∏¶Èôç‰ΩéÊàêÊú¨„ÄÇÁÑ∂ËÄåÔºåÂèñÂæóÈÅ©Áï∂ÁöÑË≥áÊñô‰æÜË®ìÁ∑¥ÈÄô‰∫õÁ≥ªÁµ±ÊúÉÈÄ†ÊàêÈáçÂ§ßÁöÑÊåëÊà∞„ÄÇÈö±ÁßÅÂïèÈ°åÊúÉÂ¶®Á§ôÁúüÂØ¶Â∞çË©±ÁöÑ‰ΩøÁî®ÔºåÂõ†Ê≠§ÈúÄË¶ÅÂêàÊàêÊõø‰ª£ÊñπÊ°à„ÄÇÂæûÂÖ¨ÈñãÂèØÂèñÂæóÁöÑËá®Â∫äÁ≠ÜË®òÁîüÊàêÂêàÊàêÂ∞çË©±Êèê‰æõ‰∫ÜÈÄôÂÄãÂïèÈ°å‰∏ÄÂÄãÊúâÂâçÊôØÁöÑËß£Ê±∫ÊñπÊ°àÔºåÂú®‰øùË≠∑Èö±ÁßÅÁöÑÂêåÊôÇÊèê‰æõÁúüÂØ¶ÁöÑË≥áÊñô„ÄÇÊàëÂÄëÁöÑ SynDial ÊñπÊ≥ï‰ΩøÁî®ÂñÆ‰∏Ä LLM ÈÄèÈÅéÈõ∂Ê¨°ÊèêÁ§∫ÂíåÂõûÈ•ãËø¥Ë∑ØÔºåÂèçË¶ÜÁîüÊàêÂíåÊîπÂñÑÈ´òÂìÅË≥™ÁöÑÂêàÊàêÂ∞çË©±„ÄÇÂõûÈ•ãÂåÖÂê´Áõ∏‰ººÊÄßÂíåÊäΩÂèñÊÄßÁöÑÂä†Ê¨äË©ïÂàÜ„ÄÇÂèçË¶ÜÁöÑÁ®ãÂ∫èÂèØÁ¢∫‰øùÂ∞çË©±Á¨¶ÂêàÈ†êÂÖàÂÆöÁæ©ÁöÑÈñæÂÄºÔºå‰∏¶Âõ†ÂõûÈ•ãËø¥Ë∑ØËÄåÈÅîÊàêÂÑ™Áï∞ÁöÑÊäΩÂèñÊÄß„ÄÇÊ≠§Â§ñÔºåË©ï‰º∞È°ØÁ§∫ÁîüÊàêÁöÑÂ∞çË©±Âú®‰∫ãÂØ¶ÊÄßÊåáÊ®ô‰∏äÂÑ™ÊñºÂü∫Ê∫ñÔºå‰∏îËàá GPT4 ÂÖ∑ÊúâÁõ∏Áï∂ÁöÑÂ§öÊ®£ÊÄßË©ïÂàÜ„ÄÇ

##### **Decentralized Health Intelligence Network (DHIN)**
2408.06240v3 by Abraham Nash

Decentralized Health Intelligence Network (DHIN) is a theoretical framework
addressing significant challenges of health data sovereignty and AI utilization
in healthcare caused by data fragmentation across providers and institutions.
It establishes a sovereign architecture for healthcare provision as a
prerequisite to a sovereign health network, then facilitates effective AI
utilization by overcoming barriers to accessing diverse medical data sources.
This comprehensive framework leverages: 1) self-sovereign identity architecture
coupled with a personal health record (PHR) as a prerequisite for health data
sovereignty; 2) a scalable federated learning (FL) protocol implemented on a
public blockchain for decentralized AI training in healthcare, where health
data remains with participants and only model parameter updates are shared; and
3) a scalable, trustless rewards mechanism to incentivize participation and
ensure fair reward distribution. This framework ensures that no entity can
prevent or control access to training on health data offered by participants or
determine financial benefits, as these processes operate on a public blockchain
with an immutable record and without a third party. It supports effective AI
training in healthcare, allowing patients to maintain control over their health
data, benefit financially, and contribute to a decentralized, scalable
ecosystem that leverages collective AI to develop beneficial healthcare
algorithms. Patients receive rewards into their digital wallets as an incentive
to opt-in to the FL protocol, with a long-term roadmap to funding decentralized
insurance solutions. This approach introduces a novel, self-financed healthcare
model that adapts to individual needs, complements existing systems, and
redefines universal coverage. It highlights the potential to transform
healthcare data management and AI utilization while empowering patients.

ÊëòË¶ÅÔºöÂàÜÊï£ÂºèÂÅ•Â∫∑ÊÉÖÂ†±Á∂≤Ë∑Ø (DHIN) ÊòØÂÄãÁêÜË´ñÊû∂ÊßãÔºå
Áî®‰æÜËß£Ê±∫ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠Âõ†Ë≥áÊñôÂàÜÊï£Âú®ÂêÑÂÄã‰æõÊáâÂïÜÂíåÊ©üÊßãËÄåÁî¢ÁîüÁöÑÂÅ•Â∫∑Ë≥áÊñô‰∏ªÊ¨äÂíå AI ‰ΩøÁî®ÁöÑÈáçÂ§ßÊåëÊà∞„ÄÇ
ÂÆÉÂª∫Á´ã‰∫Ü‰∏ÄÂÄã‰∏ªÊ¨äÊû∂Êßã‰æÜÊèê‰æõÈÜ´ÁôÇ‰øùÂÅ•Ôºå‰ΩúÁÇ∫‰∏ªÊ¨äÂÅ•Â∫∑Á∂≤Ë∑ØÁöÑÂÖàÊ±∫Ê¢ù‰ª∂ÔºåÁÑ∂ÂæåÈÄèÈÅéÂÖãÊúçÂèñÂæóÂ§öÊ®£ÂåñÈÜ´ÁôÇË≥áÊñô‰æÜÊ∫êÁöÑÈöúÁ§ôÔºå‰øÉÈÄ≤ÊúâÊïàÁöÑ AI ‰ΩøÁî®„ÄÇ
ÈÄôÂÄãÂÖ®Èù¢ÁöÑÊû∂ÊßãÂà©Áî®Ôºö1) Ëá™‰∏ªÊ¨äË∫´ÂàÜÊû∂ÊßãÔºåÁµêÂêàÂÄã‰∫∫ÂÅ•Â∫∑Á¥ÄÈåÑ (PHR) ‰ΩúÁÇ∫ÂÅ•Â∫∑Ë≥áÊñô‰∏ªÊ¨äÁöÑÂÖàÊ±∫Ê¢ù‰ª∂Ôºõ2) Âú®ÂÖ¨ÂÖ±ÂçÄÂ°äÈèà‰∏äÂØ¶‰ΩúÁöÑÂèØÊì¥ÂÖÖËÅØÂêàÂ≠∏Áøí (FL) ÂçîÂÆöÔºåÁî®ÊñºÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÁöÑÂàÜÊï£Âºè AI Ë®ìÁ∑¥ÔºåÂÖ∂‰∏≠ÂÅ•Â∫∑Ë≥áÊñô‰ªçÁî±ÂèÉËàáËÄÖÊåÅÊúâÔºåÂè™ÊúâÊ®°ÂûãÂèÉÊï∏Êõ¥Êñ∞ÊúÉË¢´ÂàÜ‰∫´Ôºõ3) ÂèØÊì¥ÂÖÖÁöÑ„ÄÅÁÑ°‰ø°‰ªªÁöÑÁçéÂãµÊ©üÂà∂ÔºåÁî®ÊñºÊøÄÂãµÂèÉËàá‰∏¶Á¢∫‰øùÂÖ¨Âπ≥ÁöÑÁçéÂãµÂàÜÈÖç„ÄÇÈÄôÂÄãÊû∂ÊßãÁ¢∫‰øùÊ≤íÊúâ‰ªª‰ΩïÂØ¶È´îÂèØ‰ª•ÈòªÊ≠¢ÊàñÊéßÂà∂ÂèÉËàáËÄÖÊèê‰æõÁöÑÂÅ•Â∫∑Ë≥áÊñôË®ìÁ∑¥Â≠òÂèñÔºåÊàñÊ±∫ÂÆöË≤°ÂãôÂà©ÁõäÔºåÂõ†ÁÇ∫ÈÄô‰∫õÁ®ãÂ∫èÊòØÂú®ÂÖ¨ÂÖ±ÂçÄÂ°äÈèà‰∏äÈÅã‰ΩúÔºåÂÖ∑Êúâ‰∏çÂèØËÆäÊõ¥ÁöÑÁ¥ÄÈåÑÔºåËÄå‰∏îÊ≤íÊúâÁ¨¨‰∏âÊñπ„ÄÇÂÆÉÊîØÊè¥Âú®ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÈÄ≤Ë°åÊúâÊïàÁöÑ AI Ë®ìÁ∑¥ÔºåËÆìÊÇ£ËÄÖÂèØ‰ª•Á∂≠ÊåÅÂ∞çÂÖ∂ÂÅ•Â∫∑Ë≥áÊñôÁöÑÊéßÂà∂Ê¨äÔºåÁç≤ÂæóË≤°ÂãôÂà©ÁõäÔºå‰∏¶Ë≤¢ÁçªÂà∞‰∏ÄÂÄãÂàÜÊï£Âºè„ÄÅÂèØÊì¥ÂÖÖÁöÑÁîüÊÖãÁ≥ªÁµ±ÔºåÂà©Áî®ÈõÜÈ´î AI ‰æÜÈñãÁôºÊúâÁõäÁöÑÈÜ´ÁôÇ‰øùÂÅ•ÊºîÁÆóÊ≥ï„ÄÇÊÇ£ËÄÖÊúÉÊî∂Âà∞ÁçéÂãµÂà∞‰ªñÂÄëÁöÑÊï∏‰ΩçÈå¢ÂåÖ‰∏≠Ôºå‰ΩúÁÇ∫ÈÅ∏ÊìáÂä†ÂÖ• FL ÂçîÂÆöÁöÑË™òÂõ†ÔºåÈï∑ÊúüÁõÆÊ®ôÊòØÁÇ∫ÂàÜÊï£Âºè‰øùÈö™Ëß£Ê±∫ÊñπÊ°àÊèê‰æõË≥áÈáë„ÄÇÈÄôÁ®ÆÊñπÊ≥ïÂºïÈÄ≤‰∫Ü‰∏ÄÂÄãÊñ∞Á©éÁöÑ„ÄÅËá™ÊàëË≥áÂä©ÁöÑÈÜ´ÁôÇ‰øùÂÅ•Ê®°ÂºèÔºåÂèØ‰ª•ÈÅ©ÊáâÂÄãÂà•ÈúÄÊ±ÇÔºåË£úÂÖÖÁèæÊúâÁ≥ªÁµ±Ôºå‰∏¶ÈáçÊñ∞ÂÆöÁæ©ÂÖ®Ê∞ëÂÅ•‰øù„ÄÇÂÆÉÁ™ÅÈ°Ø‰∫ÜËΩâÂûãÈÜ´ÁôÇ‰øùÂÅ•Ë≥áÊñôÁÆ°ÁêÜÂíå AI ‰ΩøÁî®ÁöÑÊΩõÂäõÔºåÂêåÊôÇË≥¶‰∫àÊÇ£ËÄÖÊ¨äÂäõ„ÄÇ

##### **ACCELERATION: Sequentially-scanning DECT Imaging Using High Temporal Resolution Image Reconstruction And Temporal Extrapolation**
2408.06163v1 by Qiaoxin Li, Dong Liang, Yinsheng Li

Dual-energy computed tomography (DECT) has been widely used to obtain
quantitative elemental composition of imaged subjects for personalized and
precise medical diagnosis. Compared with existing high-end DECT leveraging
advanced X-ray source and/or detector technologies, the use of the
sequentially-scanning data acquisition scheme to implement DECT may make
broader impact on clinical practice because this scheme requires no specialized
hardware designs. However, since the concentration of iodinated contrast agent
in the imaged subject varies over time, sequentially-scanned data sets acquired
at two tube potentials are temporally inconsistent. As existing material
decomposition approaches for DECT assume that the data sets acquired at two
tube potentials are temporally consistent, the violation of this assumption
results in inaccurate quantification accuracy of iodine concentration. In this
work, we developed a technique to achieve sequentially-scanning DECT imaging
using high temporal resolution image reconstruction and temporal extrapolation,
ACCELERATION in short, to address the technical challenge induced by temporal
inconsistency of sequentially-scanned data sets and improve iodine
quantification accuracy in sequentially-scanning DECT. ACCELERATION has been
validated and evaluated using numerical simulation data sets generated from
clinical human subject exams. Results demonstrated the improvement of iodine
quantification accuracy using ACCELERATION.

ÊëòË¶ÅÔºöÈõôËÉΩÈõªËÖ¶Êñ∑Â±§ÊéÉÊèè (DECT) Â∑≤Âª£Ê≥õÁî®ÊñºÂèñÂæóÂΩ±ÂÉèÂåñÂèóË©¶ËÄÖÁöÑÂÆöÈáèÂÖÉÁ¥†ÁµÑÊàêÔºå‰ª•ÈÄ≤Ë°åÂÄã‰∫∫Âåñ‰∏îÁ≤æÁ¢∫ÁöÑÈÜ´ÁôÇË®∫Êñ∑„ÄÇËàáÂà©Áî®ÂÖàÈÄ≤ X ÂÖâÊ∫êÂíå/ÊàñÂÅµÊ∏¨Âô®ÊäÄË°ìÁöÑÁèæÊúâÈ´òÈöé DECT Áõ∏ÊØîÔºå‰ΩøÁî®ÈÄ£Á∫åÊéÉÊèèË≥áÊñôÊì∑ÂèñÊñπÊ°à‰æÜÂØ¶‰Ωú DECT ÂèØËÉΩÂ∞çËá®Â∫äÂØ¶ÂãôÈÄ†ÊàêÊõ¥Âª£Ê≥õÁöÑÂΩ±ÈüøÔºåÂõ†ÁÇ∫Ê≠§ÊñπÊ°à‰∏çÈúÄË¶ÅÂ∞àÈñÄÁöÑÁ°¨È´îË®≠Ë®à„ÄÇÁÑ∂ËÄåÔºåÁî±ÊñºÂΩ±ÂÉèÂåñÂèóË©¶ËÄÖ‰∏≠Á¢òÂåñÂ∞çÊØîÂäëÁöÑÊøÉÂ∫¶ÊúÉÈö®ËëóÊôÇÈñìËÄåËÆäÂåñÔºåÂõ†Ê≠§Âú®ÂÖ©ÂÄãÁÆ°Èõª‰Ωç‰∏ãÊì∑ÂèñÁöÑÈÄ£Á∫åÊéÉÊèèË≥áÊñôÈõÜÂú®ÊôÇÈñì‰∏ä‰∏¶‰∏ç‰∏ÄËá¥„ÄÇÁî±Êñº DECT ÁèæÊúâÁöÑÊùêÊñôÂàÜËß£ÊñπÊ≥ïÂÅáË®≠Âú®ÂÖ©ÂÄãÁÆ°Èõª‰Ωç‰∏ãÊì∑ÂèñÁöÑË≥áÊñôÈõÜÂú®ÊôÇÈñì‰∏äÊòØ‰∏ÄËá¥ÁöÑÔºåÂõ†Ê≠§ÈÅïÂèçÊ≠§ÂÅáË®≠ÊúÉÂ∞éËá¥Á¢òÊøÉÂ∫¶ÁöÑÂÆöÈáèÊ∫ñÁ¢∫Â∫¶‰∏çÊ∫ñÁ¢∫„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÈñãÁôº‰∫Ü‰∏ÄÁ®ÆÊäÄË°ìÔºå‰ΩøÁî®È´òÊôÇÈñìËß£ÊûêÂ∫¶ÂΩ±ÂÉèÈáçÂª∫ÂíåÊôÇÈñìÂ§ñÊé®Ê≥ï‰æÜÈÅîÊàêÈÄ£Á∫åÊéÉÊèè DECT ÂΩ±ÂÉèÔºåÁ∞°Á®± ACCELERATIONÔºå‰ª•Ëß£Ê±∫ÈÄ£Á∫åÊéÉÊèèË≥áÊñôÈõÜÁöÑÊôÇÈñì‰∏ç‰∏ÄËá¥ÊÄßÊâÄÈÄ†ÊàêÁöÑÊäÄË°ìÊåëÊà∞Ôºå‰∏¶ÊîπÂñÑÈÄ£Á∫åÊéÉÊèè DECT ‰∏≠ÁöÑÁ¢òÂÆöÈáèÊ∫ñÁ¢∫Â∫¶„ÄÇACCELERATION Â∑≤‰ΩøÁî®ÂæûËá®Â∫ä‰∫∫È´îÂèóË©¶ËÄÖÊ™¢Êü•‰∏≠Áî¢ÁîüÁöÑÊï∏ÂÄºÊ®°Êì¨Ë≥áÊñôÈõÜÈÄ≤Ë°åÈ©óË≠âÂíåË©ï‰º∞„ÄÇÁµêÊûúË≠âÊòé‰ΩøÁî® ACCELERATION ÂèØÊîπÂñÑÁ¢òÂÆöÈáèÊ∫ñÁ¢∫Â∫¶„ÄÇ

##### **Med42-v2: A Suite of Clinical LLMs**
2408.06142v1 by Cl√©ment Christophe, Praveen K Kanithi, Tathagata Raha, Shadab Khan, Marco AF Pimentel

Med42-v2 introduces a suite of clinical large language models (LLMs) designed
to address the limitations of generic models in healthcare settings. These
models are built on Llama3 architecture and fine-tuned using specialized
clinical data. They underwent multi-stage preference alignment to effectively
respond to natural prompts. While generic models are often preference-aligned
to avoid answering clinical queries as a precaution, Med42-v2 is specifically
trained to overcome this limitation, enabling its use in clinical settings.
Med42-v2 models demonstrate superior performance compared to the original
Llama3 models in both 8B and 70B parameter configurations and GPT-4 across
various medical benchmarks. These LLMs are developed to understand clinical
queries, perform reasoning tasks, and provide valuable assistance in clinical
environments. The models are now publicly available at
\href{https://huggingface.co/m42-health}{https://huggingface.co/m42-health}.

ÊëòË¶ÅÔºöMed42-v2 ÂºïÈÄ≤‰∫Ü‰∏ÄÂ•óËá®Â∫äÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM)ÔºåÊó®Âú®Ëß£Ê±∫ÈÜ´ÁôÇ‰øùÂÅ•Áí∞Â¢É‰∏≠ÈÄöÁî®Ê®°ÂûãÁöÑÈôêÂà∂„ÄÇÈÄô‰∫õÊ®°ÂûãÂª∫Á´ãÂú® Llama3 Êû∂Êßã‰∏äÔºå‰∏¶‰ΩøÁî®Â∞àÊ•≠Ëá®Â∫äË≥áÊñôÈÄ≤Ë°åÂæÆË™ø„ÄÇÂÆÉÂÄëÁ∂ìÊ≠∑‰∫ÜÂ§öÈöéÊÆµÂÅèÂ•ΩË™øÊï¥Ôºå‰ª•ÊúâÊïàÂõûÊáâËá™ÁÑ∂ÊèêÁ§∫„ÄÇÈõñÁÑ∂ÈÄöÁî®Ê®°ÂûãÈÄöÂ∏∏ÂÅèÂ•ΩË™øÊï¥ÁÇ∫ÈÅøÂÖçÈ†êÈò≤ÊÄßÂõûÁ≠îËá®Â∫äÊü•Ë©¢Ôºå‰ΩÜ Med42-v2 Á∂ìÈÅéÁâπÂà•Ë®ìÁ∑¥‰ª•ÂÖãÊúçÊ≠§ÈôêÂà∂Ôºå‰ΩøÂÖ∂ËÉΩÂ§†Âú®Ëá®Â∫äÁí∞Â¢É‰∏≠‰ΩøÁî®„ÄÇËàáÂéüÂßã Llama3 Ê®°ÂûãÁõ∏ÊØîÔºåMed42-v2 Ê®°ÂûãÂú® 8B Âíå 70B ÂèÉÊï∏ÈÖçÁΩÆ‰ª•Âèä GPT-4 ‰∏≠Ë°®ÁèæÂá∫ÂÑ™Áï∞ÁöÑÊïàËÉΩÔºåÊ©´Ë∑®ÂêÑÁ®ÆÈÜ´ÁôÇÂü∫Ê∫ñ„ÄÇÈÄô‰∫õ LLM Ë¢´ÈñãÁôºÁî®ÊñºÁêÜËß£Ëá®Â∫äÊü•Ë©¢„ÄÅÂü∑Ë°åÊé®ÁêÜ‰ªªÂãôÔºå‰∏¶Âú®Ëá®Â∫äÁí∞Â¢É‰∏≠Êèê‰æõÊúâÂÉπÂÄºÁöÑÂçîÂä©„ÄÇÈÄô‰∫õÊ®°ÂûãÁèæÂú®Â∑≤Êñº \href{https://huggingface.co/m42-health}{https://huggingface.co/m42-health} ÂÖ¨ÈñãÊèê‰æõ„ÄÇ

##### **Real-Time Drowsiness Detection Using Eye Aspect Ratio and Facial Landmark Detection**
2408.05836v1 by Varun Shiva Krishna Rupani, Velpooru Venkata Sai Thushar, Kondadi Tejith

Drowsiness detection is essential for improving safety in areas such as
transportation and workplace health. This study presents a real-time system
designed to detect drowsiness using the Eye Aspect Ratio (EAR) and facial
landmark detection techniques. The system leverages Dlibs pre-trained shape
predictor model to accurately detect and monitor 68 facial landmarks, which are
used to compute the EAR. By establishing a threshold for the EAR, the system
identifies when eyes are closed, indicating potential drowsiness. The process
involves capturing a live video stream, detecting faces in each frame,
extracting eye landmarks, and calculating the EAR to assess alertness. Our
experiments show that the system reliably detects drowsiness with high accuracy
while maintaining low computational demands. This study offers a strong
solution for real-time drowsiness detection, with promising applications in
driver monitoring and workplace safety. Future research will investigate
incorporating additional physiological and contextual data to further enhance
detection accuracy and reliability.

ÊëòË¶ÅÔºöÁûåÁù°Ê™¢Ê∏¨Â∞çÊñºÊîπÂñÑÈÅãËº∏ÂíåËÅ∑Â†¥ÂÅ•Â∫∑Á≠âÈ†òÂüüÁöÑÂÆâÂÖ®Ëá≥ÈóúÈáçË¶Å„ÄÇÊú¨Á†îÁ©∂ÊèêÂá∫‰∏ÄÂÄãÂç≥ÊôÇÁ≥ªÁµ±ÔºåÊó®Âú®‰ΩøÁî®ÁúºÁùõÈï∑ÂØ¨ÊØî (EAR) ÂíåÈù¢ÈÉ®ÁâπÂæµÊ™¢Ê∏¨ÊäÄË°ì‰æÜÊ™¢Ê∏¨ÁûåÁù°„ÄÇË©≤Á≥ªÁµ±Âà©Áî® Dlibs È†êÂÖàË®ìÁ∑¥ÁöÑÂΩ¢ÁãÄÈ†êÊ∏¨Ê®°Âûã‰æÜÊ∫ñÁ¢∫Ê™¢Ê∏¨ÂíåÁõ£Êéß 68 ÂÄãÈù¢ÈÉ®ÁâπÂæµÔºåÈÄô‰∫õÁâπÂæµÁî®ÊñºË®àÁÆó EAR„ÄÇÈÄöÈÅéÁÇ∫ EAR Ë®≠ÂÆö‰∏ÄÂÄãÈñæÂÄºÔºåË©≤Á≥ªÁµ±ÂèØ‰ª•Ë≠òÂà•ÁúºÁùõÈñâ‰∏äÁöÑÊôÇÈñìÔºåË°®ÊòéÂèØËÉΩÊúâÁûåÁù°„ÄÇÈÄôÂÄãÈÅéÁ®ãÂåÖÊã¨Êì∑ÂèñÂç≥ÊôÇË¶ñË®ä‰∏≤ÊµÅ„ÄÅÊ™¢Ê∏¨ÊØè‰∏ÄÂπÄ‰∏≠ÁöÑËáâÈÉ®„ÄÅÊèêÂèñÁúºÁùõÁâπÂæµÔºå‰∏¶Ë®àÁÆó EAR ‰æÜË©ï‰º∞Ë≠¶Ë¶∫ÊÄß„ÄÇÊàëÂÄëÁöÑÂØ¶È©óË°®ÊòéÔºåË©≤Á≥ªÁµ±ÂèØ‰ª•ÂèØÈù†Âú∞Ê™¢Ê∏¨ÁûåÁù°ÔºåÊ∫ñÁ¢∫Â∫¶È´òÔºåÂêåÊôÇ‰øùÊåÅ‰ΩéÈÅãÁÆóÈúÄÊ±Ç„ÄÇÊú¨Á†îÁ©∂ÁÇ∫Âç≥ÊôÇÁûåÁù°Ê™¢Ê∏¨Êèê‰æõ‰∫Ü‰∏ÄÂÄãÂº∑Â§ßÁöÑËß£Ê±∫ÊñπÊ°àÔºåÂú®ÈßïÈßõÂì°Áõ£ÊéßÂíåËÅ∑Â†¥ÂÆâÂÖ®ÊñπÈù¢ÊúâÂª£Ê≥õÁöÑÊáâÁî®ÂâçÊôØ„ÄÇÊú™‰æÜÁöÑÁ†îÁ©∂Â∞áÊé¢Ë®éÊï¥ÂêàÈ°çÂ§ñÁöÑÁîüÁêÜÂíåÁí∞Â¢ÉË≥áÊñôÔºå‰ª•ÈÄ≤‰∏ÄÊ≠•ÊèêÈ´òÊ™¢Ê∏¨Ê∫ñÁ¢∫Â∫¶ÂíåÂèØÈù†ÊÄß„ÄÇ

##### **TC-KANRecon: High-Quality and Accelerated MRI Reconstruction via Adaptive KAN Mechanisms and Intelligent Feature Scaling**
2408.05705v1 by Ruiquan Ge, Xiao Yu, Yifei Chen, Fan Jia, Shenghao Zhu, Guanyu Zhou, Yiyu Huang, Chenyan Zhang, Dong Zeng, Changmiao Wang, Qiegen Liu, Shanzhou Niu

Magnetic Resonance Imaging (MRI) has become essential in clinical diagnosis
due to its high resolution and multiple contrast mechanisms. However, the
relatively long acquisition time limits its broader application. To address
this issue, this study presents an innovative conditional guided diffusion
model, named as TC-KANRecon, which incorporates the Multi-Free U-KAN (MF-UKAN)
module and a dynamic clipping strategy. TC-KANRecon model aims to accelerate
the MRI reconstruction process through deep learning methods while maintaining
the quality of the reconstructed images. The MF-UKAN module can effectively
balance the tradeoff between image denoising and structure preservation.
Specifically, it presents the multi-head attention mechanisms and scalar
modulation factors, which significantly enhances the model's robustness and
structure preservation capabilities in complex noise environments. Moreover,
the dynamic clipping strategy in TC-KANRecon adjusts the cropping interval
according to the sampling steps, thereby mitigating image detail loss typically
caused by traditional cropping methods and enriching the visual features of the
images. Furthermore, the MC-Model module incorporates full-sampling k-space
information, realizing efficient fusion of conditional information, enhancing
the model's ability to process complex data, and improving the realism and
detail richness of reconstructed images. Experimental results demonstrate that
the proposed method outperforms other MRI reconstruction methods in both
qualitative and quantitative evaluations. Notably, TC-KANRecon method exhibits
excellent reconstruction results when processing high-noise, low-sampling-rate
MRI data. Our source code is available at
https://github.com/lcbkmm/TC-KANRecon.

ÊëòË¶ÅÔºöÁ£ÅÊåØÈÄ†ÂΩ±ÔºàMRIÔºâÁî±ÊñºÂÖ∂È´òËß£ÊûêÂ∫¶ÂíåÂ§öÈáçÂ∞çÊØîÊ©üÂà∂ÔºåÂ∑≤ÊàêÁÇ∫Ëá®Â∫äË®∫Êñ∑‰∏≠‰∏çÂèØÊàñÁº∫ÁöÑÊäÄË°ì„ÄÇÁÑ∂ËÄåÔºåÁõ∏Â∞çËºÉÈï∑ÁöÑÊì∑ÂèñÊôÇÈñìÈôêÂà∂‰∫ÜÂÖ∂Êõ¥Âª£Ê≥õÁöÑÊáâÁî®„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊú¨Á†îÁ©∂ÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂâµÊñ∞ÁöÑÊ¢ù‰ª∂ÂºïÂ∞éÊì¥Êï£Ê®°ÂûãÔºåÁ®±ÁÇ∫ TC-KANReconÔºåÂÆÉÁµêÂêà‰∫ÜÂ§öËá™Áî± U-KANÔºàMF-UKANÔºâÊ®°ÁµÑÂíå‰∏ÄÂÄãÂãïÊÖãË£ÅÂâ™Á≠ñÁï•„ÄÇTC-KANRecon Ê®°ÂûãÊó®Âú®ÈÄèÈÅéÊ∑±Â∫¶Â≠∏ÁøíÊñπÊ≥ïÂä†ÈÄü MRI ÈáçÂª∫ÈÅéÁ®ãÔºåÂêåÊôÇ‰øùÊåÅÈáçÂª∫ÂΩ±ÂÉèÁöÑÂìÅË≥™„ÄÇMF-UKAN Ê®°ÁµÑÂèØ‰ª•ÊúâÊïàÂπ≥Ë°°ÂΩ±ÂÉèÂéªÂô™ÂíåÁµêÊßã‰øùÁïô‰πãÈñìÁöÑÂèñÊç®„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÂÆÉÂëàÁèæÂ§öÈ†≠Ê≥®ÊÑèÂäõÊ©üÂà∂ÂíåÊ®ôÈáèË™øË£ΩÂõ†Â≠êÔºåÈÄôÈ°ØËëóÂ¢ûÂº∑‰∫ÜÊ®°ÂûãÂú®Ë§áÈõúÂô™ËÅ≤Áí∞Â¢É‰∏≠ÁöÑÁ©©ÂÅ•ÊÄßÂíåÁµêÊßã‰øùÁïôËÉΩÂäõ„ÄÇÊ≠§Â§ñÔºåTC-KANRecon ‰∏≠ÁöÑÂãïÊÖãË£ÅÂâ™Á≠ñÁï•Ê†πÊìöÂèñÊ®£Ê≠•È©üË™øÊï¥Ë£ÅÂâ™ÈñìÈöîÔºåÂæûËÄåÊ∏õËºïÂÇ≥Áµ±Ë£ÅÂâ™ÊñπÊ≥ïÈÄöÂ∏∏ÈÄ†ÊàêÁöÑÂΩ±ÂÉèÁ¥∞ÁØÄÊêçÂ§±Ôºå‰∏¶Ë±êÂØåÂΩ±ÂÉèÁöÑË¶ñË¶∫ÁâπÂæµ„ÄÇÊ≠§Â§ñÔºåMC-Model Ê®°ÁµÑÁµêÂêà‰∫ÜÂÖ®ÂèñÊ®£ k Á©∫ÈñìË≥áË®äÔºåÂØ¶ÁèæÊ¢ù‰ª∂Ë≥áË®äÁöÑÊúâÊïàËûçÂêàÔºåÂ¢ûÂº∑‰∫ÜÊ®°ÂûãËôïÁêÜË§áÈõúË≥áÊñôÁöÑËÉΩÂäõÔºå‰∏¶ÊîπÂñÑ‰∫ÜÈáçÂª∫ÂΩ±ÂÉèÁöÑÁúüÂØ¶ÊÑüÂíåÁ¥∞ÁØÄË±êÂØåÂ∫¶„ÄÇÂØ¶È©óÁµêÊûúË°®ÊòéÔºåÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÂú®ÂÆöÊÄßÂíåÂÆöÈáèË©ï‰º∞‰∏≠ÈÉΩÂÑ™ÊñºÂÖ∂‰ªñ MRI ÈáçÂª∫ÊñπÊ≥ï„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåTC-KANRecon ÊñπÊ≥ïÂú®ËôïÁêÜÈ´òÈõúË®ä„ÄÅ‰ΩéÂèñÊ®£Áéá MRI Ë≥áÊñôÊôÇË°®ÁèæÂá∫ÂÑ™Áï∞ÁöÑÈáçÂª∫ÁµêÊûú„ÄÇÊàëÂÄëÁöÑÂéüÂßãÁ®ãÂºèÁ¢ºÂèØÂú® https://github.com/lcbkmm/TC-KANRecon ÂèñÂæó„ÄÇ

##### **A Novel Momentum-Based Deep Learning Techniques for Medical Image Classification and Segmentation**
2408.05692v1 by Koushik Biswas, Ridal Pal, Shaswat Patel, Debesh Jha, Meghana Karri, Amit Reza, Gorkem Durak, Alpay Medetalibeyoglu, Matthew Antalek, Yury Velichko, Daniela Ladner, Amir Borhani, Ulas Bagci

Accurately segmenting different organs from medical images is a critical
prerequisite for computer-assisted diagnosis and intervention planning. This
study proposes a deep learning-based approach for segmenting various organs
from CT and MRI scans and classifying diseases. Our study introduces a novel
technique integrating momentum within residual blocks for enhanced training
dynamics in medical image analysis. We applied our method in two distinct
tasks: segmenting liver, lung, & colon data and classifying abdominal pelvic CT
and MRI scans. The proposed approach has shown promising results, outperforming
state-of-the-art methods on publicly available benchmarking datasets. For
instance, in the lung segmentation dataset, our approach yielded significant
enhancements over the TransNetR model, including a 5.72% increase in dice
score, a 5.04% improvement in mean Intersection over Union (mIoU), an 8.02%
improvement in recall, and a 4.42% improvement in precision. Hence,
incorporating momentum led to state-of-the-art performance in both segmentation
and classification tasks, representing a significant advancement in the field
of medical imaging.

ÊëòË¶ÅÔºöÊ∫ñÁ¢∫Âú∞ÂæûÈÜ´ÁôÇÂΩ±ÂÉè‰∏≠ÂàÜÂâ≤Âá∫‰∏çÂêåÁöÑÂô®ÂÆòÔºåÊòØÈõªËÖ¶ËºîÂä©Ë®∫Êñ∑Âíå‰ªãÂÖ•Ë¶èÂäÉÁöÑÈóúÈçµÂÖàÊ±∫Ê¢ù‰ª∂„ÄÇÊú¨Á†îÁ©∂ÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂü∫ÊñºÊ∑±Â∫¶Â≠∏ÁøíÁöÑÊñπÊ≥ïÔºåÁî®ÊñºÂàÜÂâ≤ CT Âíå MRI ÊéÉÊèè‰∏≠ÁöÑÂêÑÁ®ÆÂô®ÂÆò‰∏¶Â∞çÁñæÁóÖÈÄ≤Ë°åÂàÜÈ°û„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÂºïÂÖ•‰∫Ü‰∏ÄÁ®ÆÊñ∞ÊäÄË°ìÔºåÂ∞áÂãïÈáèÊï¥ÂêàÂà∞ÊÆòÂ∑ÆÂ°ä‰∏≠Ôºå‰ª•Â¢ûÂº∑ÈÜ´ÁôÇÂΩ±ÂÉèÂàÜÊûê‰∏≠ÁöÑË®ìÁ∑¥ÂãïÊÖã„ÄÇÊàëÂÄëÂ∞áÊñπÊ≥ïÊáâÁî®ÊñºÂÖ©ÂÄã‰∏çÂêåÁöÑ‰ªªÂãôÔºöÂàÜÂâ≤ËÇùËáü„ÄÅËÇ∫ËáüÂíåÁµêËÖ∏Ë≥áÊñôÔºå‰ª•ÂèäÂ∞çËÖπÈÉ®È™®ÁõÜ CT Âíå MRI ÊéÉÊèèÈÄ≤Ë°åÂàÜÈ°û„ÄÇÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÂ∑≤È°ØÁ§∫Âá∫ÊúâÂ∏åÊúõÁöÑÁµêÊûúÔºåÂú®ÂÖ¨ÈñãÁöÑÂü∫Ê∫ñË≥áÊñôÈõÜ‰∏äÂÑ™ÊñºÊúÄÂÖàÈÄ≤ÁöÑÊñπÊ≥ï„ÄÇ‰æãÂ¶ÇÔºåÂú®ËÇ∫ÈÉ®ÂàÜÂâ≤Ë≥áÊñôÈõÜ‰∏≠ÔºåÊàëÂÄëÁöÑÊ®°ÂûãÊØî TransNetR Ê®°ÂûãÁî¢Áîü‰∫ÜÈ°ØËëóÁöÑÊèêÂçáÔºåÂåÖÊã¨È™∞Â≠ê‰øÇÊï∏Â¢ûÂä†‰∫Ü 5.72%ÔºåÂπ≥ÂùáËÅØÂêà‰∫§ÈõÜ (mIoU) ÊèêÈ´ò‰∫Ü 5.04%ÔºåÂè¨ÂõûÁéáÊèêÈ´ò‰∫Ü 8.02%ÔºåÁ≤æÂ∫¶ÊèêÈ´ò‰∫Ü 4.42%„ÄÇÂõ†Ê≠§ÔºåÁµêÂêàÂãïÈáèÂú®ÂàÜÂâ≤ÂíåÂàÜÈ°û‰ªªÂãô‰∏≠ÈÉΩÂ∏∂‰æÜ‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÊïàËÉΩÔºå‰ª£Ë°®‰∫ÜÈÜ´ÁôÇÂΩ±ÂÉèÈ†òÂüüÁöÑÈáçÂ§ßÈÄ≤Â±ï„ÄÇ

##### **Mitigating Metropolitan Carbon Emissions with Dynamic Eco-driving at Scale**
2408.05609v1 by Vindula Jayawardana, Baptiste Freydt, Ao Qu, Cameron Hickert, Edgar Sanchez, Catherine Tang, Mark Taylor, Blaine Leonard, Cathy Wu

The sheer scale and diversity of transportation make it a formidable sector
to decarbonize. Here, we consider an emerging opportunity to reduce carbon
emissions: the growing adoption of semi-autonomous vehicles, which can be
programmed to mitigate stop-and-go traffic through intelligent speed commands
and, thus, reduce emissions. But would such dynamic eco-driving move the needle
on climate change? A comprehensive impact analysis has been out of reach due to
the vast array of traffic scenarios and the complexity of vehicle emissions. We
address this challenge with large-scale scenario modeling efforts and by using
multi-task deep reinforcement learning with a carefully designed network
decomposition strategy. We perform an in-depth prospective impact assessment of
dynamic eco-driving at 6,011 signalized intersections across three major US
metropolitan cities, simulating a million traffic scenarios. Overall, we find
that vehicle trajectories optimized for emissions can cut city-wide
intersection carbon emissions by 11-22%, without harming throughput or safety,
and with reasonable assumptions, equivalent to the national emissions of Israel
and Nigeria, respectively. We find that 10% eco-driving adoption yields 25%-50%
of the total reduction, and nearly 70% of the benefits come from 20% of
intersections, suggesting near-term implementation pathways. However, the
composition of this high-impact subset of intersections varies considerably
across different adoption levels, with minimal overlap, calling for careful
strategic planning for eco-driving deployments. Moreover, the impact of
eco-driving, when considered jointly with projections of vehicle
electrification and hybrid vehicle adoption remains significant. More broadly,
this work paves the way for large-scale analysis of traffic externalities, such
as time, safety, and air quality, and the potential impact of solution
strategies.

ÊëòË¶ÅÔºö<paragraph>ÈÅãËº∏Ê•≠ÁöÑË¶èÊ®°ÂíåÂ§öÊ®£ÊÄß‰ΩøÂÖ∂ÊàêÁÇ∫‰∏ÄÂÄãÈõ£‰ª•ËÑ´Á¢≥ÁöÑÁî¢Ê•≠„ÄÇÂú®Ê≠§ÔºåÊàëÂÄëËÄÉÊÖÆ‰∏ÄÂÄãÊñ∞ËààÁöÑÊ©üÊúÉ‰æÜÊ∏õÂ∞ëÁ¢≥ÊéíÊîæÔºöÂçäËá™ÂãïËªäËºõÁöÑÊé°Áî®Êó•ÁõäÂ¢ûÂä†ÔºåÈÄô‰∫õËªäËºõÂèØÈÄèÈÅéÊô∫ÊÖßÂûãÈÄüÂ∫¶Êåá‰ª§‰æÜÁ∑®Á®ã‰ª•Ê∏õÂ∞ëËµ∞Ëµ∞ÂÅúÂÅúÁöÑ‰∫§ÈÄöÔºåÂæûËÄåÊ∏õÂ∞ëÊéíÊîæ„ÄÇ‰ΩÜÈÄôÁ®ÆÂãïÊÖãÁîüÊÖãÈßïÈßõÊòØÂê¶ÊúÉÂ∞çÊ∞£ÂÄôËÆäÈÅ∑Áî¢ÁîüÂΩ±ÈüøÔºüÁî±Êñº‰∫§ÈÄöÁãÄÊ≥ÅÁúæÂ§ö‰∏îËªäËºõÊéíÊîæË§áÈõúÔºåÂõ†Ê≠§ÁÑ°Ê≥ïÈÄ≤Ë°åÂÖ®Èù¢ÁöÑÂΩ±ÈüøÂàÜÊûê„ÄÇÊàëÂÄëÈÄèÈÅéÂ§ßË¶èÊ®°ÊÉÖÂ¢ÉÂª∫Ê®°Â∑•‰ΩúÂíå‰ΩøÁî®Â§ö‰ªªÂãôÊ∑±Â∫¶Âº∑ÂåñÂ≠∏ÁøíÔºå‰ª•ÂèäÁ≤æÂøÉË®≠Ë®àÁöÑÁ∂≤Ë∑ØÂàÜËß£Á≠ñÁï•‰æÜÊáâÂ∞çÈÄôÈ†ÖÊåëÊà∞„ÄÇÊàëÂÄëÂ∞çÁæéÂúã‰∏âÂ§ßÈÉΩÊúÉÂüéÂ∏Ç 6,011 ÂÄãÊúâ‰ø°ËôüÁöÑ‰∫§ÂèâË∑ØÂè£ÈÄ≤Ë°åÊ∑±ÂÖ•ÁöÑÂâçÁûªÊÄßÂΩ±ÈüøË©ï‰º∞ÔºåÊ®°Êì¨‰∏ÄÁôæËê¨ÂÄã‰∫§ÈÄöÁãÄÊ≥Å„ÄÇÁ∏ΩÈ´îËÄåË®ÄÔºåÊàëÂÄëÁôºÁèæÈáùÂ∞çÊéíÊîæÈáèÊúÄ‰Ω≥ÂåñÁöÑËªäËºõËªåË∑°ÂèØ‰ª•Ê∏õÂ∞ë 11-22% ÁöÑÂüéÂ∏Ç‰∫§ÂèâË∑ØÂè£Á¢≥ÊéíÊîæÔºåËÄå‰∏çÊúÉÊêçÂÆ≥ÂêûÂêêÈáèÊàñÂÆâÂÖ®ÊÄßÔºå‰∏îÊ†πÊìöÂêàÁêÜÁöÑÂÅáË®≠ÔºåÂàÜÂà•Á≠âÊñº‰ª•Ëâ≤ÂàóÂíåÂ•àÂèäÂà©‰∫ûÁöÑÂúãÂÆ∂ÊéíÊîæÈáè„ÄÇÊàëÂÄëÁôºÁèæ 10% ÁöÑÁîüÊÖãÈßïÈßõÊé°Áî®ÁéáÊúÉÁî¢ÁîüÁ∏ΩÊ∏õÈáèÁöÑ 25%-50%ÔºåËÄåËøë 70% ÁöÑÂ•ΩËôï‰æÜËá™ 20% ÁöÑ‰∫§ÂèâË∑ØÂè£ÔºåÈÄôË°®Êòé‰∫ÜËøëÊúüÁöÑÂØ¶ÊñΩÈÄîÂæë„ÄÇÁÑ∂ËÄåÔºåÈÄôÂÄãÈ´òÂΩ±Èüø‰∫§ÂèâË∑ØÂè£Â≠êÈõÜÁöÑÁµÑÊàêÂú®‰∏çÂêåÁöÑÊé°Áî®Áéá‰πãÈñìËÆäÂåñÂæàÂ§ßÔºåÈáçÁñäÊÄßÂæàÂ∞èÔºåÈÄôÈúÄË¶Å‰ªîÁ¥∞ÁöÑÁ≠ñÁï•ÊÄßË¶èÂäÉ‰æÜÈÄ≤Ë°åÁîüÊÖãÈßïÈßõÈÉ®ÁΩ≤„ÄÇÊ≠§Â§ñÔºåÁîüÊÖãÈßïÈßõÁöÑÂΩ±ÈüøÔºåÂú®ËàáËªäËºõÈõªÊ∞£ÂåñÂíåÊ∑∑ÂêàÂãïÂäõËªäËºõÊé°Áî®ÁéáÁöÑÈ†êÊ∏¨ÂÖ±ÂêåËÄÉÈáèÊôÇÔºå‰ªçÁÑ∂È°ØËëó„ÄÇÊõ¥Âª£Ê≥õËÄåË®ÄÔºåÈÄôÈ†ÖÂ∑•‰ΩúÁÇ∫Â§ßË¶èÊ®°ÂàÜÊûê‰∫§ÈÄöÂ§ñÈÉ®ÊÄßÔºà‰æãÂ¶ÇÊôÇÈñì„ÄÅÂÆâÂÖ®ÊÄßÂíåÁ©∫Ê∞£ÂìÅË≥™Ôºâ‰ª•ÂèäËß£Ê±∫Á≠ñÁï•ÁöÑÊΩõÂú®ÂΩ±ÈüøÈã™Âπ≥‰∫ÜÈÅìË∑Ø„ÄÇ</paragraph>

##### **Beyond the Eye: A Relational Model for Early Dementia Detection Using Retinal OCTA Images**
2408.05117v1 by Shouyue Liu, Jinkui Hao, Yonghuai Liu, Huazhu Fu, Xinyu Guo, Shuting Zhang, Yitian Zhao

Early detection of dementia, such as Alzheimer's disease (AD) or mild
cognitive impairment (MCI), is essential to enable timely intervention and
potential treatment. Accurate detection of AD/MCI is challenging due to the
high complexity, cost, and often invasive nature of current diagnostic
techniques, which limit their suitability for large-scale population screening.
Given the shared embryological origins and physiological characteristics of the
retina and brain, retinal imaging is emerging as a potentially rapid and
cost-effective alternative for the identification of individuals with or at
high risk of AD. In this paper, we present a novel PolarNet+ that uses retinal
optical coherence tomography angiography (OCTA) to discriminate early-onset AD
(EOAD) and MCI subjects from controls. Our method first maps OCTA images from
Cartesian coordinates to polar coordinates, allowing approximate sub-region
calculation to implement the clinician-friendly early treatment of diabetic
retinopathy study (ETDRS) grid analysis. We then introduce a multi-view module
to serialize and analyze the images along three dimensions for comprehensive,
clinically useful information extraction. Finally, we abstract the sequence
embedding into a graph, transforming the detection task into a general graph
classification problem. A regional relationship module is applied after the
multi-view module to excavate the relationship between the sub-regions. Such
regional relationship analyses validate known eye-brain links and reveal new
discriminative patterns.

ÊëòË¶ÅÔºöÊó©ÊúüÂÅµÊ∏¨Â§±Êô∫ÁóáÔºå‰æãÂ¶ÇÈòøËå≤Êµ∑ÈªòÁóá (AD) ÊàñËºïÂ∫¶Ë™çÁü•ÈöúÁ§ô (MCI)ÔºåÂ∞çÊñºÂèäÊôÇ‰ªãÂÖ•ÂíåÊΩõÂú®Ê≤ªÁôÇËá≥ÈóúÈáçË¶Å„ÄÇÁî±ÊñºÁõÆÂâçË®∫Êñ∑ÊäÄË°ìÁöÑË§áÈõúÊÄßÈ´ò„ÄÅÊàêÊú¨È´òÔºå‰∏îÂ∏∏Â∏∏ÂÖ∑Êúâ‰æµÂÖ•ÊÄßÔºåÂõ†Ê≠§Ê∫ñÁ¢∫ÂÅµÊ∏¨ AD/MCI Ê•µÂÖ∑ÊåëÊà∞ÊÄßÔºåÈÄô‰πüÈôêÂà∂‰∫ÜÂÖ∂Áî®ÊñºÂ§ßË¶èÊ®°‰∫∫Áæ§ÁØ©Ê™¢ÁöÑÈÅ©Áî®ÊÄß„ÄÇËÄÉÈáèÂà∞Ë¶ñÁ∂≤ËÜúÂíåËÖ¶ÈÉ®ÂÖ∑ÊúâÁõ∏ÂêåÁöÑËÉöËÉéËµ∑Ê∫êÂíåÁîüÁêÜÁâπÊÄßÔºåË¶ñÁ∂≤ËÜúÂΩ±ÂÉèÊ≠£ÈÄêÊº∏ÊàêÁÇ∫‰∏ÄÁ®ÆÊΩõÂú®ÁöÑÂø´ÈÄü‰∏îÂÖ∑ÊàêÊú¨ÊïàÁõäÁöÑÊõø‰ª£ÊñπÊ°àÔºåÁî®ÊñºÊâæÂá∫ÁΩπÊÇ£ AD ÊàñÂÖ∑ÊúâÈ´òÈ¢®Èö™ÁöÑÂÄã‰∫∫„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂâµÊñ∞ÁöÑ PolarNet+ÔºåÂÆÉ‰ΩøÁî®Ë¶ñÁ∂≤ËÜúÂÖâÂ≠∏Áõ∏Âπ≤Êñ∑Â±§Ë°ÄÁÆ°ÈÄ†ÂΩ± (OCTA) ‰æÜÂçÄÂàÜÊó©ÁôºÊÄß AD (EOAD) Âíå MCI ÂèóË©¶ËÄÖËàáÂ∞çÁÖßÁµÑ„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÈ¶ñÂÖàÂ∞á OCTA ÂΩ±ÂÉèÂæûÁ¨õÂç°ÁàæÂùêÊ®ôËΩâÊèõÁÇ∫Ê•µÂùêÊ®ôÔºåËÆìËøë‰ººÂ≠êÂçÄÂüüË®àÁÆóÂæó‰ª•ÂØ¶‰ΩúÔºåÈÄ≤ËÄåÂü∑Ë°åÂ∞çËá®Â∫äÈÜ´Â∏´ÂèãÂñÑÁöÑÁ≥ñÂ∞øÁóÖË¶ñÁ∂≤ËÜúÁóÖËÆäÊó©ÊúüÊ≤ªÁôÇÁ†îÁ©∂ (ETDRS) Ê†ºÁ∑öÂàÜÊûê„ÄÇÊé•ËëóÔºåÊàëÂÄëÂºïÂÖ•‰∏ÄÂÄãÂ§öË¶ñÂúñÊ®°ÁµÑÔºåÁî®Êñº‰∏≤ÂàóÂåñ‰∏¶Ê≤øËëó‰∏âÂÄãÂêëÂ∫¶ÂàÜÊûêÂΩ±ÂÉèÔºå‰ª•ÈÄ≤Ë°åÂÖ®Èù¢ÁöÑ„ÄÅËá®Â∫ä‰∏äÊúâÁî®ÁöÑË≥áË®äËêÉÂèñ„ÄÇÊúÄÂæåÔºåÊàëÂÄëÂ∞áÂ∫èÂàóÂµåÂÖ•ÊäΩË±°ÂåñÁÇ∫‰∏ÄÂÄãÂúñÂΩ¢ÔºåÂ∞áÂÅµÊ∏¨‰ªªÂãôËΩâÊèõÁÇ∫‰∏ÄÂÄãÈÄöÁî®ÁöÑÂúñÂΩ¢ÂàÜÈ°ûÂïèÈ°å„ÄÇÂú®Â§öË¶ñÂúñÊ®°ÁµÑÂæåÊáâÁî®ÂçÄÂüüÈóú‰øÇÊ®°ÁµÑÔºå‰ª•Êé¢Ë®éÂ≠êÂçÄÂüü‰πãÈñìÁöÑÈóú‰øÇ„ÄÇÊ≠§È°ûÂçÄÂüüÈóú‰øÇÂàÜÊûêÈ©óË≠â‰∫ÜÂ∑≤Áü•ÁöÑË¶ñÁ∂≤ËÜúËàáËÖ¶ÈÉ®ÈóúËÅØÔºå‰∏¶Êè≠Á§∫‰∫ÜÊñ∞ÁöÑÂà§Âà•Ê®°Âºè„ÄÇ

##### **RT-Surv: Improving Mortality Prediction After Radiotherapy with Large Language Model Structuring of Large-Scale Unstructured Electronic Health Records**
2408.05074v2 by Sangjoon Park, Chan Woo Wee, Seo Hee Choi, Kyung Hwan Kim, Jee Suk Chang, Hong In Yoon, Ik Jae Lee, Yong Bae Kim, Jaeho Cho, Ki Chang Keum, Chang Geol Lee, Hwa Kyung Byun, Woong Sub Koom

Accurate patient selection is critical in radiotherapy (RT) to prevent
ineffective treatments. Traditional survival prediction models, relying on
structured data, often lack precision. This study explores the potential of
large language models (LLMs) to structure unstructured electronic health record
(EHR) data, thereby improving survival prediction accuracy through
comprehensive clinical information integration. Data from 34,276 patients
treated with RT at Yonsei Cancer Center between 2013 and 2023 were analyzed,
encompassing both structured and unstructured data. An open-source LLM was used
to structure the unstructured EHR data via single-shot learning, with its
performance compared against a domain-specific medical LLM and a smaller
variant. Survival prediction models were developed using statistical, machine
learning, and deep learning approaches, incorporating both structured and
LLM-structured data. Clinical experts evaluated the accuracy of the
LLM-structured data. The open-source LLM achieved 87.5% accuracy in structuring
unstructured EHR data without additional training, significantly outperforming
the domain-specific medical LLM, which reached only 35.8% accuracy. Larger LLMs
were more effective, particularly in extracting clinically relevant features
like general condition and disease extent, which closely correlated with
patient survival. Incorporating LLM-structured clinical features into survival
prediction models significantly improved accuracy, with the C-index of deep
learning models increasing from 0.737 to 0.820. These models also became more
interpretable by emphasizing clinically significant factors. This study shows
that general-domain LLMs, even without specific medical training, can
effectively structure large-scale unstructured EHR data, substantially
enhancing the accuracy and interpretability of clinical predictive models.

ÊëòË¶ÅÔºö<paragraph>Âú®ÊîæÂ∞ÑÊ≤ªÁôÇ (RT) ‰∏≠ÔºåÊ∫ñÁ¢∫ÁöÑÊÇ£ËÄÖÈÅ∏ÊìáËá≥ÈóúÈáçË¶ÅÔºå‰ª•Èò≤Ê≠¢ÁÑ°ÊïàÁöÑÊ≤ªÁôÇ„ÄÇÂÇ≥Áµ±ÁöÑÂ≠òÊ¥ªÈ†êÊ∏¨Ê®°Âûã‰æùË≥¥ÊñºÁµêÊßãÂåñÊï∏ÊìöÔºåÂæÄÂæÄÁº∫‰πèÁ≤æÁ¢∫ÊÄß„ÄÇÊú¨Á†îÁ©∂Êé¢Ë®é‰∫ÜÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∞áÈùûÁµêÊßãÂåñÈõªÂ≠êÂÅ•Â∫∑Ë®òÈåÑ (EHR) Êï∏ÊìöÁµêÊßãÂåñÁöÑÊΩõÂäõÔºåÂæûËÄåÈÄöÈÅéÂÖ®Èù¢ÁöÑËá®Â∫ä‰ø°ÊÅØÊï¥Âêà‰æÜÊèêÈ´òÂ≠òÊ¥ªÈ†êÊ∏¨ÁöÑÊ∫ñÁ¢∫ÊÄß„ÄÇÂ∞ç 2013 Âπ¥Ëá≥ 2023 Âπ¥ÈñìÂú®Âª∂‰∏ñÁôåÁóá‰∏≠ÂøÉÊé•Âèó RT Ê≤ªÁôÇÁöÑ 34,276 ÂêçÊÇ£ËÄÖÁöÑÊï∏ÊìöÈÄ≤Ë°å‰∫ÜÂàÜÊûêÔºåÂåÖÊã¨ÁµêÊßãÂåñÂíåÈùûÁµêÊßãÂåñÊï∏Êìö„ÄÇ‰ΩøÁî®ÈñãÊ∫ê LLM ÈÄöÈÅéÂñÆÊ¨°Â≠∏Áøí‰æÜÊßãÈÄ†ÈùûÁµêÊßãÂåñ EHR Êï∏ÊìöÔºå‰∏¶Â∞áÂÖ∂ÊÄßËÉΩËàáÁâπÂÆöÈ†òÂüüÁöÑÈÜ´ÁôÇ LLM ÂíåËºÉÂ∞èÁöÑËÆäÈ´îÈÄ≤Ë°å‰∫ÜÊØîËºÉ„ÄÇÂ≠òÊ¥ªÈ†êÊ∏¨Ê®°ÂûãÊòØ‰ΩøÁî®Áµ±Ë®à„ÄÅÊ©üÂô®Â≠∏ÁøíÂíåÊ∑±Â∫¶Â≠∏ÁøíÊñπÊ≥ïÈñãÁôºÁöÑÔºåÁµêÂêà‰∫ÜÁµêÊßãÂåñÂíå LLM ÁµêÊßãÂåñÁöÑÊï∏Êìö„ÄÇËá®Â∫äÂ∞àÂÆ∂Ë©ï‰º∞‰∫Ü LLM ÁµêÊßãÂåñÊï∏ÊìöÁöÑÊ∫ñÁ¢∫ÊÄß„ÄÇÈñãÊ∫ê LLM Âú®Ê≤íÊúâÈ°çÂ§ñË®ìÁ∑¥ÁöÑÊÉÖÊ≥Å‰∏ãÔºåÂú®ÁµêÊßãÂåñÈùûÁµêÊßãÂåñ EHR Êï∏ÊìöÊñπÈù¢ÈÅîÂà∞‰∫Ü 87.5% ÁöÑÊ∫ñÁ¢∫Â∫¶ÔºåÈ°ØËëóÂÑ™ÊñºÁâπÂÆöÈ†òÂüüÁöÑÈÜ´ÁôÇ LLMÔºåÂæåËÄÖÁöÑÊ∫ñÁ¢∫Â∫¶ÂÉÖÁÇ∫ 35.8%„ÄÇÊõ¥Â§ßÁöÑ LLM Êõ¥ÊúâÊïàÔºåÁâπÂà•ÊòØÂú®ÊèêÂèñËá®Â∫äÁõ∏ÈóúÁâπÂæµÊñπÈù¢ÔºåÂ¶Ç‰∏ÄËà¨ÁãÄÊ≥ÅÂíåÁñæÁóÖÁ®ãÂ∫¶ÔºåÈÄôËàáÊÇ£ËÄÖÂ≠òÊ¥ªÁéáÂØÜÂàáÁõ∏Èóú„ÄÇÂ∞á LLM ÁµêÊßãÂåñÁöÑËá®Â∫äÁâπÂæµÁ¥çÂÖ•Â≠òÊ¥ªÈ†êÊ∏¨Ê®°ÂûãÈ°ØËëóÊèêÈ´ò‰∫ÜÊ∫ñÁ¢∫ÊÄßÔºåÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÁöÑ C ÊåáÊï∏Âæû 0.737 Â¢ûÂä†Âà∞ 0.820„ÄÇÈÄô‰∫õÊ®°Âûã‰πüËÆäÂæóÊõ¥ÂÖ∑ÂèØËß£ÈáãÊÄßÔºåÂõ†ÁÇ∫ÂÆÉÂÄëÂº∑Ë™ø‰∫ÜËá®Â∫ä‰∏äÈáçË¶ÅÁöÑÂõ†Á¥†„ÄÇÊú¨Á†îÁ©∂Ë°®ÊòéÔºåÂç≥‰ΩøÊ≤íÊúâÂÖ∑È´îÁöÑÈÜ´Â≠∏Ë®ìÁ∑¥ÔºåÈÄöÁî®È†òÂüüÁöÑ LLM ‰πüÂèØ‰ª•ÊúâÊïàÂú∞ÊßãÈÄ†Â§ßË¶èÊ®°ÁöÑÈùûÁµêÊßãÂåñ EHR Êï∏ÊìöÔºåÂæûËÄåÈ°ØËëóÊèêÈ´òËá®Â∫äÈ†êÊ∏¨Ê®°ÂûãÁöÑÊ∫ñÁ¢∫ÊÄßÂíåÂèØËß£ÈáãÊÄß„ÄÇ</paragraph>

##### **CROCODILE: Causality aids RObustness via COntrastive DIsentangled LEarning**
2408.04949v1 by Gianluca Carloni, Sotirios A Tsaftaris, Sara Colantonio

Due to domain shift, deep learning image classifiers perform poorly when
applied to a domain different from the training one. For instance, a classifier
trained on chest X-ray (CXR) images from one hospital may not generalize to
images from another hospital due to variations in scanner settings or patient
characteristics. In this paper, we introduce our CROCODILE framework, showing
how tools from causality can foster a model's robustness to domain shift via
feature disentanglement, contrastive learning losses, and the injection of
prior knowledge. This way, the model relies less on spurious correlations,
learns the mechanism bringing from images to prediction better, and outperforms
baselines on out-of-distribution (OOD) data. We apply our method to multi-label
lung disease classification from CXRs, utilizing over 750000 images from four
datasets. Our bias-mitigation method improves domain generalization and
fairness, broadening the applicability and reliability of deep learning models
for a safer medical image analysis. Find our code at:
https://github.com/gianlucarloni/crocodile.

ÊëòË¶ÅÔºöÁî±ÊñºÈ†òÂüüËΩâÊèõÔºåÊ∑±Â∫¶Â≠∏ÁøíÂúñÂÉèÂàÜÈ°ûÂô®Âú®ÊáâÁî®ÊñºËàáË®ìÁ∑¥‰∏çÂêåÁöÑÈ†òÂüüÊôÇË°®Áèæ‰∏ç‰Ω≥„ÄÇ‰æãÂ¶ÇÔºåÈáùÂ∞ç‰∏ÄÂÆ∂ÈÜ´Èô¢ÁöÑËÉ∏ÈÉ® X ÂÖâÔºàCXRÔºâÂΩ±ÂÉèË®ìÁ∑¥ÁöÑÂàÜÈ°ûÂô®ÔºåÁî±ÊñºÊéÉÊèèÂÑÄË®≠ÂÆöÊàñÊÇ£ËÄÖÁâπÂæµÁöÑÂ∑ÆÁï∞ÔºåÂèØËÉΩÁÑ°Ê≥ïÊ¶ÇÂåñÂà∞Âè¶‰∏ÄÂÆ∂ÈÜ´Èô¢ÁöÑÂΩ±ÂÉè„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥πÊàëÂÄëÁöÑ CROCODILE Ê°ÜÊû∂ÔºåÂ±ïÁ§∫Âõ†ÊûúÂ∑•ÂÖ∑Â¶Ç‰ΩïÈÄèÈÅéÁâπÂæµËß£Á≥æÁ∫è„ÄÅÂ∞çÊØîÂ≠∏ÁøíÊêçÂ§±ÂíåÊ≥®ÂÖ•ÂÖàÈ©óÁü•Ë≠ò‰æÜ‰øÉÈÄ≤Ê®°ÂûãÂ∞çÈ†òÂüüËΩâÊèõÁöÑÁ©©ÂÅ•ÊÄß„ÄÇÈÄôÊ®£‰∏Ä‰æÜÔºåÊ®°ÂûãËºÉ‰∏ç‰æùË≥¥ËôõÂÅáÁõ∏ÈóúÊÄßÔºåËÉΩÊõ¥Â•ΩÂú∞Â≠∏ÁøíÂæûÂΩ±ÂÉèÂà∞È†êÊ∏¨ÁöÑÊ©üÂà∂Ôºå‰∏¶Âú®ÂàÜ‰ΩàÂ§ñÔºàOODÔºâË≥áÊñô‰∏äÂÑ™ÊñºÂü∫Á∑ö„ÄÇÊàëÂÄëÂ∞áÊàëÂÄëÁöÑÊ®°ÂûãÊáâÁî®Êñº CXR ÁöÑÂ§öÊ®ôÁ±§ËÇ∫ÈÉ®ÁñæÁóÖÂàÜÈ°ûÔºåÂà©Áî®‰æÜËá™ÂõõÂÄãË≥áÊñôÈõÜÁöÑË∂ÖÈÅé 750,000 ÂºµÂΩ±ÂÉè„ÄÇÊàëÂÄëÁöÑÂÅèÂ∑ÆÁ∑©Ëß£ÊñπÊ≥ïÊîπÂñÑ‰∫ÜÈ†òÂüüÊ¶ÇÂåñÂíåÂÖ¨Âπ≥ÊÄßÔºåÊì¥Â§ß‰∫ÜÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÂú®Êõ¥ÂÆâÂÖ®ÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÊûê‰∏≠ÁöÑÈÅ©Áî®ÊÄßÂíåÂèØÈù†ÊÄß„ÄÇÂú®‰ª•‰∏ãÁ∂≤ÂùÄÊâæÂà∞ÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÔºöhttps://github.com/gianlucarloni/crocodile„ÄÇ

##### **Unleashing Artificial Cognition: Integrating Multiple AI Systems**
2408.04910v3 by Muntasir Adnan, Buddhi Gamage, Zhiwei Xu, Damith Herath, Carlos C. N. Kuhn

In this study, we present an innovative fusion of language models and query
analysis techniques to unlock cognition in artificial intelligence. Our system
seamlessly integrates a Chess engine with a language model, enabling it to
predict moves and provide strategic explanations. Leveraging a vector database
to achieve retrievable answer generation, our OpenSI AI system elucidates its
decision-making process, bridging the gap between raw computation and
human-like understanding. Our choice of Chess as the demonstration environment
underscores the versatility of our approach. Beyond Chess, our system holds
promise for diverse applications, from medical diagnostics to financial
forecasting.

ÊëòË¶ÅÔºöÂú®Êú¨Ê¨°Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫ÜË™ûË®ÄÊ®°ÂûãÂíåÊü•Ë©¢ÂàÜÊûêÊäÄË°ìÁöÑÂâµÊñ∞ËûçÂêàÔºå‰ª•Ëß£Èéñ‰∫∫Â∑•Êô∫ÊÖß‰∏≠ÁöÑË™çÁü•„ÄÇÊàëÂÄëÁöÑÁ≥ªÁµ±Â∞áË•øÊ¥ãÊ£ãÂºïÊìéËàáË™ûË®ÄÊ®°ÂûãÁÑ°Á∏´Êï¥ÂêàÔºå‰ΩøÂÖ∂ËÉΩÂ§†È†êÊ∏¨Ê£ãÊ≠•‰∏¶Êèê‰æõÁ≠ñÁï•Ë™™Êòé„ÄÇÊàëÂÄëÁöÑ OpenSI AI Á≥ªÁµ±Âà©Áî®ÂêëÈáèË≥áÊñôÂ∫´‰æÜÈÅîÊàêÂèØÊì∑ÂèñÁ≠îÊ°àÁöÑÁî¢ÁîüÔºåÈó°ÊòéÂÖ∂Ê±∫Á≠ñÈÅéÁ®ãÔºåÁ∏ÆÂ∞è‰∫ÜÂéüÂßãÈÅãÁÆóËàáÈ°û‰∫∫ÁêÜËß£‰πãÈñìÁöÑÂ∑ÆË∑ù„ÄÇÊàëÂÄëÈÅ∏ÊìáË•øÊ¥ãÊ£ã‰ΩúÁÇ∫Á§∫ÁØÑÁí∞Â¢ÉÔºåÁ™ÅÈ°Ø‰∫ÜÊàëÂÄëÊñπÊ≥ïÁöÑÂ§öÂäüËÉΩÊÄß„ÄÇÈô§‰∫ÜË•øÊ¥ãÊ£ã‰πãÂ§ñÔºåÊàëÂÄëÁöÑÁ≥ªÁµ±ÊúâÊúõÊáâÁî®ÊñºÂêÑÁ®ÆÈ†òÂüüÔºåÂæûÈÜ´ÁôÇË®∫Êñ∑Âà∞Ë≤°ÂãôÈ†êÊ∏¨„ÄÇ

##### **Ensemble BERT: A student social network text sentiment classification model based on ensemble learning and BERT architecture**
2408.04849v1 by Kai Jiang, Honghao Yang, Yuexian Wang, Qianru Chen, Yiming Luo

The mental health assessment of middle school students has always been one of
the focuses in the field of education. This paper introduces a new ensemble
learning network based on BERT, employing the concept of enhancing model
performance by integrating multiple classifiers. We trained a range of
BERT-based learners, which combined using the majority voting method. We
collect social network text data of middle school students through China's
Weibo and apply the method to the task of classifying emotional tendencies in
middle school students' social network texts. Experimental results suggest that
the ensemble learning network has a better performance than the base model and
the performance of the ensemble learning model, consisting of three
single-layer BERT models, is barely the same as a three-layer BERT model but
requires 11.58% more training time. Therefore, in terms of balancing prediction
effect and efficiency, the deeper BERT network should be preferred for
training. However, for interpretability, network ensembles can provide
acceptable solutions.

ÊëòË¶ÅÔºö‰∏≠Â≠∏ÁîüÂøÉÁêÜÂÅ•Â∫∑Ë©ï‰º∞‰∏ÄÁõ¥ÊòØÊïôËÇ≤È†òÂüüÁöÑÈóúÊ≥®ÈáçÈªû‰πã‰∏Ä„ÄÇÊú¨Êñá‰ªãÁ¥π‰∫Ü‰∏ÄÂÄãÂü∫Êñº BERT ÁöÑÊñ∞ÈõÜÊàêÂ≠∏ÁøíÁ∂≤Ë∑ØÔºåÊé°Áî®Êï¥ÂêàÂ§öÂÄãÂàÜÈ°ûÂô®ÁöÑÊ¶ÇÂøµ‰æÜÊèêÂçáÊ®°ÂûãÊïàËÉΩ„ÄÇÊàëÂÄëË®ìÁ∑¥‰∫Ü‰∏ÄÁ≥ªÂàóÂü∫Êñº BERT ÁöÑÂ≠∏ÁøíÂô®Ôºå‰∏¶‰ΩøÁî®Â§öÊï∏Ê±∫ÊäïÁ•®Ê≥ïÈÄ≤Ë°åÁµÑÂêà„ÄÇÊàëÂÄëÈÄèÈÅé‰∏≠ÂúãÂæÆÂçöÊî∂ÈõÜ‰∏≠Â≠∏ÁîüÁöÑÁ§æÁæ§Á∂≤Ë∑ØÊñáÂ≠óË≥áÊñôÔºå‰∏¶Â∞áÊ≠§ÊñπÊ≥ïÊáâÁî®ÊñºÂàÜÈ°û‰∏≠Â≠∏ÁîüÁ§æÁæ§Á∂≤Ë∑ØÊñáÂ≠óÁöÑÊÉÖÁ∑íÂÇæÂêëÁöÑ‰ªªÂãô‰∏≠„ÄÇÂØ¶È©óÁµêÊûúË°®ÊòéÔºåÈõÜÊàêÂ≠∏ÁøíÁ∂≤Ë∑ØÁöÑÊïàËÉΩÂÑ™ÊñºÂü∫Á§éÊ®°ÂûãÔºå‰∏îÁî±‰∏âÂÄãÂñÆÂ±§ BERT Ê®°ÂûãÁµÑÊàêÁöÑÈõÜÊàêÂ≠∏ÁøíÊ®°ÂûãÁöÑÊïàËÉΩËàá‰∏âÂ±§ BERT Ê®°ÂûãÂπæ‰πéÁõ∏ÂêåÔºå‰ΩÜË®ìÁ∑¥ÊôÇÈñìÂçªÂ§ö‰∫Ü 11.58%„ÄÇÂõ†Ê≠§ÔºåÂú®Âπ≥Ë°°È†êÊ∏¨ÊïàÊûúÂíåÊïàÁéáÊñπÈù¢ÔºåÊáâÂÑ™ÂÖàËÄÉÊÖÆËºÉÊ∑±ÁöÑ BERT Á∂≤Ë∑ØÈÄ≤Ë°åË®ìÁ∑¥„ÄÇÁÑ∂ËÄåÔºåÂ∞çÊñºÂèØËß£ÈáãÊÄßËÄåË®ÄÔºåÁ∂≤Ë∑ØÈõÜÊàêÂèØ‰ª•Êèê‰æõÂèØÊé•ÂèóÁöÑËß£Ê±∫ÊñπÊ°à„ÄÇ

##### **Towards Synergistic Deep Learning Models for Volumetric Cirrhotic Liver Segmentation in MRIs**
2408.04491v1 by Vandan Gorade, Onkar Susladkar, Gorkem Durak, Elif Keles, Ertugrul Aktas, Timurhan Cebeci, Alpay Medetalibeyoglu, Daniela Ladner, Debesh Jha, Ulas Bagci

Liver cirrhosis, a leading cause of global mortality, requires precise
segmentation of ROIs for effective disease monitoring and treatment planning.
Existing segmentation models often fail to capture complex feature interactions
and generalize across diverse datasets. To address these limitations, we
propose a novel synergistic theory that leverages complementary latent spaces
for enhanced feature interaction modeling. Our proposed architecture,
nnSynergyNet3D integrates continuous and discrete latent spaces for 3D volumes
and features auto-configured training. This approach captures both fine-grained
and coarse features, enabling effective modeling of intricate feature
interactions. We empirically validated nnSynergyNet3D on a private dataset of
628 high-resolution T1 abdominal MRI scans from 339 patients. Our model
outperformed the baseline nnUNet3D by approximately 2%. Additionally, zero-shot
testing on healthy liver CT scans from the public LiTS dataset demonstrated
superior cross-modal generalization capabilities. These results highlight the
potential of synergistic latent space models to improve segmentation accuracy
and robustness, thereby enhancing clinical workflows by ensuring consistency
across CT and MRI modalities.

ÊëòË¶ÅÔºöËÇùÁ°¨ÂåñÊòØÂÖ®ÁêÉÊ≠ª‰∫°ÁöÑ‰∏ªË¶ÅÂéüÂõ†ÔºåÈúÄË¶ÅÂØπ ROI ËøõË°åÁ≤æÁ°ÆÂàÜÂâ≤Ôºå‰ª•ËøõË°åÊúâÊïàÁöÑÁñæÁóÖÁõëÊµãÂíåÊ≤ªÁñóËÆ°Âàí„ÄÇÁé∞ÊúâÁöÑÂàÜÂâ≤Ê®°ÂûãÈÄöÂ∏∏Êó†Ê≥ïÊçïÊçâÂ§çÊùÇÁöÑÁâπÂæÅ‰∫§‰∫íÔºåÂπ∂Âú®‰∏çÂêåÁöÑÊï∞ÊçÆÈõÜ‰∏äËøõË°åÊ≥õÂåñ„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∫õÈôêÂà∂ÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞È¢ñÁöÑÂçèÂêåÁêÜËÆ∫ÔºåËØ•ÁêÜËÆ∫Âà©Áî®‰∫íË°•ÁöÑÊΩúÂú®Á©∫Èó¥Êù•Â¢ûÂº∫ÁâπÂæÅ‰∫§‰∫íÂª∫Ê®°„ÄÇÊàë‰ª¨ÊèêÂá∫ÁöÑÊû∂ÊûÑ nnSynergyNet3D ÈõÜÊàê‰∫ÜËøûÁª≠ÂíåÁ¶ªÊï£ÁöÑÊΩúÂú®Á©∫Èó¥ÔºåÁî®‰∫é 3D ‰ΩìÁßØÔºåÂπ∂ÂÖ∑ÊúâËá™Âä®ÈÖçÁΩÆÁöÑËÆ≠ÁªÉ„ÄÇËøôÁßçÊñπÊ≥ïÊçïÊçâÂà∞‰∫ÜÁªÜÁ≤íÂ∫¶ÂíåÁ≤óÁ≤íÂ∫¶ÁâπÂæÅÔºå‰ªéËÄåËÉΩÂ§üÊúâÊïàÂú∞ÂØπÂ§çÊùÇÁöÑÁâπÂæÅ‰∫§‰∫íËøõË°åÂª∫Ê®°„ÄÇÊàë‰ª¨Ê†πÊçÆ 339 ÂêçÊÇ£ËÄÖÁöÑ 628 ‰∏™È´òÂàÜËæ®Áéá T1 ËÖπÈÉ® MRI Êâ´ÊèèÁöÑÁßÅÊúâÊï∞ÊçÆÈõÜÂØπ nnSynergyNet3D ËøõË°å‰∫ÜÂÆûËØÅÈ™åËØÅ„ÄÇÊàë‰ª¨ÁöÑÊ®°ÂûãÊØîÂü∫Á∫ø nnUNet3D ÁöÑÊÄßËÉΩÊèêÈ´ò‰∫ÜÂ§ßÁ∫¶ 2%„ÄÇÊ≠§Â§ñÔºåÂú®Êù•Ëá™ÂÖ¨ÂÖ± LiTS Êï∞ÊçÆÈõÜÁöÑÂÅ•Â∫∑ËÇùËÑè CT Êâ´Êèè‰∏äËøõË°åÈõ∂Ê†∑Êú¨ÊµãËØïËØÅÊòé‰∫ÜÂÖ∂ÂçìË∂äÁöÑË∑®Ê®°ÊÄÅÊ≥õÂåñËÉΩÂäõ„ÄÇËøô‰∫õÁªìÊûúÁ™ÅÂá∫‰∫ÜÂçèÂêåÊΩúÂú®Á©∫Èó¥Ê®°ÂûãÂú®ÊèêÈ´òÂàÜÂâ≤Á≤æÂ∫¶ÂíåÈ≤ÅÊ£íÊÄßÊñπÈù¢ÁöÑÊΩúÂäõÔºå‰ªéËÄåÈÄöËøáÁ°Æ‰øù CT Âíå MRI Ê®°ÊÄÅÁöÑ‰∏ÄËá¥ÊÄßÊù•Â¢ûÂº∫‰∏¥Â∫äÂ∑•‰ΩúÊµÅÁ®ã„ÄÇ

##### **Advancing oncology with federated learning: transcending boundaries in breast, lung, and prostate cancer. A systematic review**
2408.05249v1 by Anshu Ankolekar, Sebastian Boie, Maryam Abdollahyan, Emanuela Gadaleta, Seyed Alireza Hasheminasab, Guang Yang, Charles Beauville, Nikolaos Dikaios, George Anthony Kastis, Michael Bussmann, Sara Khalid, Hagen Kruger, Philippe Lambin, Giorgos Papanastasiou

Federated Learning (FL) has emerged as a promising solution to address the
limitations of centralised machine learning (ML) in oncology, particularly in
overcoming privacy concerns and harnessing the power of diverse, multi-center
data. This systematic review synthesises current knowledge on the
state-of-the-art FL in oncology, focusing on breast, lung, and prostate cancer.
Distinct from previous surveys, our comprehensive review critically evaluates
the real-world implementation and impact of FL on cancer care, demonstrating
its effectiveness in enhancing ML generalisability, performance and data
privacy in clinical settings and data. We evaluated state-of-the-art advances
in FL, demonstrating its growing adoption amid tightening data privacy
regulations. FL outperformed centralised ML in 15 out of the 25 studies
reviewed, spanning diverse ML models and clinical applications, and
facilitating integration of multi-modal information for precision medicine.
Despite the current challenges identified in reproducibility, standardisation
and methodology across studies, the demonstrable benefits of FL in harnessing
real-world data and addressing clinical needs highlight its significant
potential for advancing cancer research. We propose that future research should
focus on addressing these limitations and investigating further advanced FL
methods, to fully harness data diversity and realise the transformative power
of cutting-edge FL in cancer care.

ÊëòË¶ÅÔºöËÅØÈÇ¶Â≠∏Áøí (FL) Â∑≤ÊàêÁÇ∫‰∫ÜËß£Ê±∫ËÖ´Áò§Â≠∏‰∏≠ÈõÜ‰∏≠ÂºèÊ©üÂô®Â≠∏Áøí (ML) ÈôêÂà∂ÁöÑÊúâÂâçÈÄîÁöÑËß£Ê±∫ÊñπÊ°àÔºåÁâπÂà•ÊòØÂú®ÂÖãÊúçÈö±ÁßÅÂïèÈ°åÂíåÂà©Áî®Â§ö‰∏≠ÂøÉÁï∞Ë≥™Ë≥áÊñôÁöÑÂäõÈáèÊñπÈù¢„ÄÇÈÄôÈ†ÖÁ≥ªÁµ±ÊÄßÂõûÈ°ßÁ∂úÂêà‰∫ÜËÖ´Áò§Â≠∏‰∏≠ÊúÄÊñ∞ FL ÁöÑÁèæÊúâÁü•Ë≠òÔºåÈáçÈªûÈóúÊ≥®‰π≥Áôå„ÄÅËÇ∫ÁôåÂíåÂâçÂàóËÖ∫Áôå„ÄÇËàáÂÖàÂâçÁöÑË™øÊü•‰∏çÂêåÔºåÊàëÂÄëÁöÑÂÖ®Èù¢ÂõûÈ°ßÊâπÂà§ÊÄßÂú∞Ë©ï‰º∞‰∫Ü FL Âú®ÁôåÁóáÁÖßË≠∑‰∏≠ÁöÑÂØ¶ÈöõÂü∑Ë°åÂíåÂΩ±ÈüøÔºåË≠âÊòé‰∫ÜÂÆÉÂú®Â¢ûÂº∑ ML ÁöÑÊ¶ÇÊã¨ÊÄß„ÄÅÊïàËÉΩÂíåËá®Â∫äÁí∞Â¢ÉÂíåË≥áÊñô‰∏≠ÁöÑË≥áÊñôÈö±ÁßÅÊñπÈù¢ÁöÑÊúâÊïàÊÄß„ÄÇÊàëÂÄëË©ï‰º∞‰∫Ü FL ÁöÑÊúÄÊñ∞ÈÄ≤Â±ïÔºåË≠âÊòé‰∫ÜÂÆÉÂú®Êó•ÁõäÂö¥Ê†ºÁöÑË≥áÊñôÈö±ÁßÅÊ≥ïË¶è‰∏≠Áç≤ÂæóË∂ä‰æÜË∂äÂª£Ê≥õÁöÑÊé°Áî®„ÄÇÂú®ÊâÄÂõûÈ°ßÁöÑ 25 È†ÖÁ†îÁ©∂‰∏≠ÔºåFL Âú® 15 È†ÖÁ†îÁ©∂‰∏≠ÂÑ™ÊñºÈõÜ‰∏≠Âºè MLÔºåÊ∂µËìã‰∫ÜÂ§öÁ®Æ ML Ê®°ÂûãÂíåËá®Â∫äÊáâÁî®Ôºå‰∏¶‰øÉÈÄ≤‰∫ÜÂ§öÊ®°ÂºèË≥áË®äÊï¥Âêà‰ª•ÈÄ≤Ë°åÁ≤æÊ∫ñÈÜ´ÁôÇ„ÄÇÂÑòÁÆ°Âú®ÂêÑÈ†ÖÁ†îÁ©∂‰∏≠ÁôºÁèæ‰∫ÜÂÜçÁèæÊÄß„ÄÅÊ®ôÊ∫ñÂåñÂíåÊñπÊ≥ïÊñπÈù¢ÁöÑÁèæÊúâÊåëÊà∞Ôºå‰ΩÜ FL Âú®Âà©Áî®ÁúüÂØ¶‰∏ñÁïåË≥áÊñôÂíåËß£Ê±∫Ëá®Â∫äÈúÄÊ±ÇÊñπÈù¢Â∑≤Â±ïÁèæÂá∫ÁöÑÂ•ΩËôïÁ™ÅÈ°Ø‰∫ÜÂÖ∂Âú®Êé®ÈÄ≤ÁôåÁóáÁ†îÁ©∂ÊñπÈù¢ÁöÑÂ∑®Â§ßÊΩõÂäõ„ÄÇÊàëÂÄëÂª∫Ë≠∞Êú™‰æÜÁöÑÁ†îÁ©∂ÊáâÈáçÈªûËß£Ê±∫ÈÄô‰∫õÈôêÂà∂Ôºå‰∏¶ÈÄ≤‰∏ÄÊ≠•Á†îÁ©∂ÂÖàÈÄ≤ÁöÑ FL ÊñπÊ≥ïÔºå‰ª•ÂÖÖÂàÜÂà©Áî®Ë≥áÊñôÁöÑÂ§öÊ®£ÊÄßÔºå‰∏¶ÂØ¶ÁèæÂ∞ñÁ´Ø FL Âú®ÁôåÁóáÁÖßË≠∑‰∏≠ÁöÑËΩâÂåñÂäõÈáè„ÄÇ

##### **Non-maximizing policies that fulfill multi-criterion aspirations in expectation**
2408.04385v1 by Simon Dima, Simon Fischer, Jobst Heitzig, Joss Oliver

In dynamic programming and reinforcement learning, the policy for the
sequential decision making of an agent in a stochastic environment is usually
determined by expressing the goal as a scalar reward function and seeking a
policy that maximizes the expected total reward. However, many goals that
humans care about naturally concern multiple aspects of the world, and it may
not be obvious how to condense those into a single reward function.
Furthermore, maximization suffers from specification gaming, where the obtained
policy achieves a high expected total reward in an unintended way, often taking
extreme or nonsensical actions.
  Here we consider finite acyclic Markov Decision Processes with multiple
distinct evaluation metrics, which do not necessarily represent quantities that
the user wants to be maximized. We assume the task of the agent is to ensure
that the vector of expected totals of the evaluation metrics falls into some
given convex set, called the aspiration set. Our algorithm guarantees that this
task is fulfilled by using simplices to approximate feasibility sets and
propagate aspirations forward while ensuring they remain feasible. It has
complexity linear in the number of possible state-action-successor triples and
polynomial in the number of evaluation metrics. Moreover, the explicitly
non-maximizing nature of the chosen policy and goals yields additional degrees
of freedom, which can be used to apply heuristic safety criteria to the choice
of actions. We discuss several such safety criteria that aim to steer the agent
towards more conservative behavior.

ÊëòË¶ÅÔºöÂú®ÂãïÊÖãË¶èÂäÉÂíåÂº∑ÂåñÂ≠∏Áøí‰∏≠Ôºå‰ª£ÁêÜ‰∫∫Âú®Èö®Ê©üÁí∞Â¢É‰∏≠ÈÄ≤Ë°åÈ†ÜÂ∫èÊ±∫Á≠ñÁöÑÁ≠ñÁï•ÈÄöÂ∏∏ÈÄöÈÅéÂ∞áÁõÆÊ®ôË°®ÈÅîÁÇ∫Ê®ôÈáèÁçéÂãµÂáΩÊï∏‰∏¶Â∞ãÊ±ÇÊúÄÂ§ßÂåñÈ†êÊúüÁ∏ΩÁçéÂãµÁöÑÁ≠ñÁï•‰æÜÁ¢∫ÂÆö„ÄÇÁÑ∂ËÄåÔºå‰∫∫È°ûÈóúÂøÉÁöÑË®±Â§öÁõÆÊ®ôËá™ÁÑ∂Ê∂âÂèä‰∏ñÁïåÁöÑÂ§öÂÄãÊñπÈù¢Ôºå‰∏¶‰∏îÂèØËÉΩ‰∏¶‰∏çÊ∏ÖÊ•öÂ¶Ç‰ΩïÂ∞áÈÄô‰∫õÁõÆÊ®ôÊøÉÁ∏ÆÊàêÂñÆ‰∏ÄÁöÑÁçéÂãµÂáΩÊï∏„ÄÇÊ≠§Â§ñÔºåÊúÄÂ§ßÂåñÊúÉÂèóÂà∞Ë¶èÁØÑÂçöÂºàÁöÑÂΩ±ÈüøÔºåÂÖ∂‰∏≠Áç≤ÂæóÁöÑÁ≠ñÁï•‰ª•ÊÑèÂ§ñÁöÑÊñπÂºèÂØ¶Áèæ‰∫ÜÂæàÈ´òÁöÑÈ†êÊúüÁ∏ΩÁçéÂãµÔºåÈÄöÂ∏∏Êé°ÂèñÊ•µÁ´ØÊàñËçíË¨¨ÁöÑË°åÂãï„ÄÇ
Âú®ÈÄôË£°ÔºåÊàëÂÄëËÄÉÊÖÆÂÖ∑ÊúâÂ§öÂÄã‰∏çÂêåË©ï‰º∞ÊåáÊ®ôÁöÑÊúâÈôêÁÑ°Áí∞È¶¨ÂèØÂ§´Ê±∫Á≠ñÈÅéÁ®ãÔºåÈÄô‰∫õÊåáÊ®ô‰∏ç‰∏ÄÂÆöË°®Á§∫Áî®Êà∂Â∏åÊúõÊúÄÂ§ßÂåñÁöÑÊï∏Èáè„ÄÇÊàëÂÄëÂÅáË®≠‰ª£ÁêÜ‰∫∫ÁöÑ‰ªªÂãôÊòØÁ¢∫‰øùË©ï‰º∞ÊåáÊ®ôÈ†êÊúüÁ∏ΩÈáèÁöÑÂêëÈáèËêΩÂÖ•ÊüêÂÄãÁµ¶ÂÆöÁöÑÂá∏ÈõÜÔºåÁ®±ÁÇ∫È°òÊúõÈõÜ„ÄÇÊàëÂÄëÁöÑÊºîÁÆóÊ≥ï‰øùË≠âÈÄöÈÅé‰ΩøÁî®ÂñÆÂΩ¢‰æÜÈÄºËøëÂèØË°åÈõÜ‰∏¶Âú®Á¢∫‰øùÂèØË°åÊÄßÁöÑÂêåÊôÇÂêëÂâçÂÇ≥Êí≠È°òÊúõ‰æÜÂÆåÊàêÊ≠§‰ªªÂãô„ÄÇÂÆÉÁöÑË§áÈõúÂ∫¶ËàáÂèØËÉΩÁöÑÁãÄÊÖã-Âãï‰Ωú-ÂæåÁπº‰∏âÂÖÉÁµÑÁöÑÊï∏ÈáèÂëàÁ∑öÊÄßÈóú‰øÇÔºåËàáË©ï‰º∞ÊåáÊ®ôÁöÑÊï∏ÈáèÂëàÂ§öÈ†ÖÂºèÈóú‰øÇ„ÄÇÊ≠§Â§ñÔºåÊâÄÈÅ∏Á≠ñÁï•ÂíåÁõÆÊ®ôÁöÑÈ°ØÂºèÈùûÊúÄÂ§ßÂåñÊÄßË≥™Áî¢Áîü‰∫ÜÈ°çÂ§ñÁöÑËá™Áî±Â∫¶ÔºåÂèØÁî®ÊñºÂ∞áÂïüÁôºÂºèÂÆâÂÖ®Ê∫ñÂâáÊáâÁî®ÊñºÂãï‰ΩúÁöÑÈÅ∏Êìá„ÄÇÊàëÂÄëË®éË´ñ‰∫ÜÂπæÂÄãÈÄôÊ®£ÁöÑÂÆâÂÖ®Ê∫ñÂâáÔºåÊó®Âú®ÂºïÂ∞é‰ª£ÁêÜ‰∫∫Êé°ÂèñÊõ¥‰øùÂÆàÁöÑË°åÁÇ∫„ÄÇ

##### **AI-Driven Chatbot for Intrusion Detection in Edge Networks: Enhancing Cybersecurity with Ethical User Consent**
2408.04281v1 by Mugheez Asif, Abdul Manan, Abdul Moiz ur Rehman, Mamoona Naveed Asghar, Muhammad Umair

In today's contemporary digital landscape, chatbots have become indispensable
tools across various sectors, streamlining customer service, providing personal
assistance, automating routine tasks, and offering health advice. However,
their potential remains underexplored in the realm of network security,
particularly for intrusion detection. To bridge this gap, we propose an
architecture chatbot specifically designed to enhance security within edge
networks specifically for intrusion detection. Leveraging advanced machine
learning algorithms, this chatbot will monitor network traffic to identify and
mitigate potential intrusions. By securing the network environment using an
edge network managed by a Raspberry Pi module and ensuring ethical user consent
promoting transparency and trust, this innovative solution aims to safeguard
sensitive data and maintain a secure workplace, thereby addressing the growing
need for robust network security measures in the digital age.

ÊëòË¶ÅÔºöÂú®Áï∂‰ªäÁöÑÁèæ‰ª£Êï∏‰ΩçÁí∞Â¢É‰∏≠ÔºåËÅäÂ§©Ê©üÂô®‰∫∫Â∑≤ÊàêÁÇ∫ÂêÑÂÄãÁî¢Ê•≠‰∏çÂèØÊàñÁº∫ÁöÑÂ∑•ÂÖ∑ÔºåÁ∞°ÂåñÂÆ¢Êà∂ÊúçÂãô„ÄÅÊèê‰æõÂÄã‰∫∫ÂçîÂä©„ÄÅËá™ÂãïÂåñ‰æãË°åÂ∑•‰Ωú‰∏¶Êèê‰æõÂÅ•Â∫∑Âª∫Ë≠∞„ÄÇÁÑ∂ËÄåÔºåÂÆÉÂÄëÂú®Á∂≤Ë∑ØÂÆâÂÖ®È†òÂüüÁöÑÊΩõÂäõ‰ªçÊú™ÂæóÂà∞ÂÖÖÂàÜÊé¢Á¥¢ÔºåÁâπÂà•ÊòØÂú®ÂÖ•‰æµÂÅµÊ∏¨ÊñπÈù¢„ÄÇÁÇ∫‰∫ÜÂΩåË£úÈÄôÂÄãÂ∑ÆË∑ùÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂ∞àÈñÄË®≠Ë®àÁî®ÊñºÂ¢ûÂº∑ÈÇäÁ∑£Á∂≤Ë∑ØÂÖßÈÉ®ÂÆâÂÖ®ÊÄßÁöÑÊû∂ÊßãËÅäÂ§©Ê©üÂô®‰∫∫ÔºåÁâπÂà•ÊòØÁî®ÊñºÂÖ•‰æµÂÅµÊ∏¨„ÄÇÈÄèÈÅéÂà©Áî®ÂÖàÈÄ≤ÁöÑÊ©üÂô®Â≠∏ÁøíÊºîÁÆóÊ≥ïÔºåÊ≠§ËÅäÂ§©Ê©üÂô®‰∫∫Â∞áÁõ£ÊéßÁ∂≤Ë∑ØÊµÅÈáè‰ª•Ë≠òÂà•ÂíåÊ∏õËºïÊΩõÂú®ÂÖ•‰æµ„ÄÇÈÄèÈÅé‰ΩøÁî®Áî± Raspberry Pi Ê®°ÁµÑÁÆ°ÁêÜÁöÑÈÇäÁ∑£Á∂≤Ë∑Ø‰æÜ‰øùË≠∑Á∂≤Ë∑ØÁí∞Â¢ÉÔºå‰∏¶Á¢∫‰øùÂêà‰πéÈÅìÂæ∑ÁöÑ‰ΩøÁî®ËÄÖÂêåÊÑè‰ª•‰øÉÈÄ≤ÈÄèÊòéÂ∫¶Âíå‰ø°‰ªªÔºåÈÄôÂÄãÂâµÊñ∞ÁöÑËß£Ê±∫ÊñπÊ°àÊó®Âú®‰øùË≠∑ÊïèÊÑüË≥áÊñô‰∏¶Á∂≠Ë≠∑‰∏ÄÂÄãÂÆâÂÖ®ÁöÑÂ∑•‰ΩúÂ†¥ÊâÄÔºåÂæûËÄåÊªøË∂≥Êï∏‰ΩçÊôÇ‰ª£Â∞çÂº∑Â§ßÁ∂≤Ë∑ØÂÆâÂÖ®Êé™ÊñΩÊó•ÁõäÂ¢ûÈï∑ÁöÑÈúÄÊ±Ç„ÄÇ

##### **Dynamic Fog Computing for Enhanced LLM Execution in Medical Applications**
2408.04680v1 by Philipp Zagar, Vishnu Ravi, Lauren Aalami, Stephan Krusche, Oliver Aalami, Paul Schmiedmayer

The ability of large language models (LLMs) to transform, interpret, and
comprehend vast quantities of heterogeneous data presents a significant
opportunity to enhance data-driven care delivery. However, the sensitive nature
of protected health information (PHI) raises valid concerns about data privacy
and trust in remote LLM platforms. In addition, the cost associated with
cloud-based artificial intelligence (AI) services continues to impede
widespread adoption. To address these challenges, we propose a shift in the LLM
execution environment from opaque, centralized cloud providers to a
decentralized and dynamic fog computing architecture. By executing open-weight
LLMs in more trusted environments, such as the user's edge device or a fog
layer within a local network, we aim to mitigate the privacy, trust, and
financial challenges associated with cloud-based LLMs. We further present
SpeziLLM, an open-source framework designed to facilitate rapid and seamless
leveraging of different LLM execution layers and lowering barriers to LLM
integration in digital health applications. We demonstrate SpeziLLM's broad
applicability across six digital health applications, showcasing its
versatility in various healthcare settings.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâËΩâÊèõ„ÄÅË©ÆÈáãÂíåÁêÜËß£Â§ßÈáèÁï∞Ë≥™Ë≥áÊñôÁöÑËÉΩÂäõÔºåÁÇ∫ÊèêÂçáË≥áÊñôÈ©ÖÂãïÁöÑÁÖßË≠∑Êèê‰æõÈ°ØËëóÁöÑÂ•ëÊ©ü„ÄÇÁÑ∂ËÄåÔºåÂèó‰øùË≠∑ÂÅ•Â∫∑Ë≥áË®äÔºàPHIÔºâÁöÑÊïèÊÑüÊÄßË≥™ÂºïÁôº‰∫ÜÂ∞çË≥áÊñôÈö±ÁßÅÂíåÂ∞çÈÅ†Á´Ø LLM Âπ≥Âè∞‰ø°‰ªªÁöÑÊ≠£Áï∂ÁñëÊÖÆ„ÄÇÊ≠§Â§ñÔºåËàáÈõ≤Á´Ø‰∫∫Â∑•Êô∫ÊÖßÔºàAIÔºâÊúçÂãôÁõ∏ÈóúÁöÑÊàêÊú¨ÊåÅÁ∫åÈòªÁ§ôÂª£Ê≥õÊé°Áî®„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÂª∫Ë≠∞Â∞á LLM Âü∑Ë°åÁí∞Â¢ÉÂæû‰∏çÈÄèÊòéÁöÑÈõÜ‰∏≠ÂºèÈõ≤Á´Ø‰æõÊáâÂïÜËΩâÁßªÂà∞ÂàÜÊï£ÂºèÂãïÊÖãÈúßÈÅãÁÆóÊû∂Êßã„ÄÇÈÄèÈÅéÂú®Êõ¥Âèó‰ø°‰ªªÁöÑÁí∞Â¢É‰∏≠Âü∑Ë°åÈñãÊîæÊ¨äÈáçÁöÑ LLMÔºå‰æãÂ¶Ç‰ΩøÁî®ËÄÖÁöÑÈÇäÁ∑£Ë£ùÁΩÆÊàñÂçÄÂüüÁ∂≤Ë∑ØÂÖßÁöÑÈúßÂ±§ÔºåÊàëÂÄëÊó®Âú®Ê∏õËºïËàáÈõ≤Á´Ø LLM Áõ∏ÈóúÁöÑÈö±ÁßÅ„ÄÅ‰ø°‰ªªÂíåË≤°ÂãôÊåëÊà∞„ÄÇÊàëÂÄëÈÄ≤‰∏ÄÊ≠•ÊèêÂá∫ SpeziLLMÔºå‰∏ÄÂÄãÈñãÊîæÂéüÂßãÁ¢ºÊû∂ÊßãÔºåÊó®Âú®‰øÉÈÄ≤Âø´ÈÄü‰∏îÁÑ°Á∏´Âú∞Âà©Áî®‰∏çÂêåÁöÑ LLM Âü∑Ë°åÂ±§Ôºå‰∏¶Èôç‰Ωé LLM Êï¥ÂêàÂú®Êï∏‰ΩçÂÅ•Â∫∑ÊáâÁî®Á®ãÂºèÁöÑÈöúÁ§ô„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫Ü SpeziLLM Âú®ÂÖ≠ÂÄãÊï∏‰ΩçÂÅ•Â∫∑ÊáâÁî®Á®ãÂºè‰∏≠ÁöÑÂª£Ê≥õÈÅ©Áî®ÊÄßÔºåÂ±ïÁ§∫‰∫ÜÂÖ∂Âú®ÂêÑÁ®ÆÈÜ´ÁôÇ‰øùÂÅ•Áí∞Â¢É‰∏≠ÁöÑÂ§öÂäüËÉΩÊÄß„ÄÇ

##### **Dynamic Hypergraph-Enhanced Prediction of Sequential Medical Visits**
2408.07084v1 by Wangying Yang, Zhizhong Wu, Zitao Zheng, Bo Zhang, Shi Bo, Yuanfang Yang

This study introduces a pioneering Dynamic Hypergraph Networks (DHCE) model
designed to predict future medical diagnoses from electronic health records
with enhanced accuracy. The DHCE model innovates by identifying and
differentiating acute and chronic diseases within a patient's visit history,
constructing dynamic hypergraphs that capture the complex, high-order
interactions between diseases. It surpasses traditional recurrent neural
networks and graph neural networks by effectively integrating clinical event
data, reflected through medical language model-assisted encoding, into a robust
patient representation. Through extensive experiments on two benchmark
datasets, MIMIC-III and MIMIC-IV, the DHCE model exhibits superior performance,
significantly outpacing established baseline models in the precision of
sequential diagnosis prediction.

ÊëòË¶ÅÔºöÊú¨Á†îÁ©∂‰ªãÁ¥π‰∫Ü‰∏ÄÁ®ÆÂâµÊñ∞ÁöÑÂãïÊÖãË∂ÖÂúñÁ∂≤Ë∑Ø (DHCE) Ê®°ÂûãÔºåÊó®Âú®ÂæûÈõªÂ≠êÁóÖÊ≠∑‰∏≠È†êÊ∏¨Êú™‰æÜÁöÑÈÜ´ÁôÇË®∫Êñ∑Ôºå‰∏¶ÊèêÈ´òÊ∫ñÁ¢∫Â∫¶„ÄÇDHCE Ê®°ÂûãÈÄèÈÅéË≠òÂà•ÂíåÂçÄÂàÜÊÇ£ËÄÖÂ∞±Ë®∫Ë®òÈåÑ‰∏≠ÁöÑÊÄ•ÊÄßÁóÖÂíåÊÖ¢ÊÄßÁóÖÔºåÂª∫ÊßãÂãïÊÖãË∂ÖÂúñ‰æÜÊçïÊçâÁñæÁóÖ‰πãÈñìË§áÈõúÁöÑÈ´òÈöé‰∫íÂãïÔºåÈÄ≤ËÄåÈÄ≤Ë°åÂâµÊñ∞„ÄÇÂÆÉË∂ÖË∂ä‰∫ÜÂÇ≥Áµ±ÁöÑÈÅûËø¥Á•ûÁ∂ìÁ∂≤Ë∑ØÂíåÂúñÁ•ûÁ∂ìÁ∂≤Ë∑ØÔºåÊúâÊïàÂú∞Â∞áËá®Â∫ä‰∫ã‰ª∂Ë≥áÊñôÊï¥ÂêàÂà∞Âº∑ÂÅ•ÁöÑÊÇ£ËÄÖË°®Âæµ‰∏≠Ôºå‰∏¶ÈÄèÈÅéÈÜ´ÁôÇË™ûË®ÄÊ®°ÂûãËºîÂä©Á∑®Á¢º‰æÜÂèçÊò†„ÄÇÈÄèÈÅéÂú®ÂÖ©ÂÄãÂü∫Ê∫ñË≥áÊñôÈõÜ MIMIC-III Âíå MIMIC-IV ‰∏äÈÄ≤Ë°åÂª£Ê≥õÁöÑÂØ¶È©óÔºåDHCE Ê®°ÂûãÂ±ïÁèæÂá∫ÂÑ™Áï∞ÁöÑÊïàËÉΩÔºåÂú®Â∫èË≤´Ë®∫Êñ∑È†êÊ∏¨ÁöÑÁ≤æÊ∫ñÂ∫¶‰∏äÈ°ØËëóÂú∞Ë∂ÖË∂äÊó¢ÂÆöÁöÑÂü∫Ê∫ñÊ®°Âûã„ÄÇ

##### **The Data Addition Dilemma**
2408.04154v1 by Judy Hanwen Shen, Inioluwa Deborah Raji, Irene Y. Chen

In many machine learning for healthcare tasks, standard datasets are
constructed by amassing data across many, often fundamentally dissimilar,
sources. But when does adding more data help, and when does it hinder progress
on desired model outcomes in real-world settings? We identify this situation as
the \textit{Data Addition Dilemma}, demonstrating that adding training data in
this multi-source scaling context can at times result in reduced overall
accuracy, uncertain fairness outcomes, and reduced worst-subgroup performance.
We find that this possibly arises from an empirically observed trade-off
between model performance improvements due to data scaling and model
deterioration from distribution shift. We thus establish baseline strategies
for navigating this dilemma, introducing distribution shift heuristics to guide
decision-making on which data sources to add in data scaling, in order to yield
the expected model performance improvements. We conclude with a discussion of
the required considerations for data collection and suggestions for studying
data composition and scale in the age of increasingly larger models.

ÊëòË¶ÅÔºöÂú®Ë®±Â§öÈÜ´ÁôÇ‰øùÂÅ•‰ªªÂãôÁöÑÊ©üÂô®Â≠∏Áøí‰∏≠ÔºåÊ®ôÊ∫ñË≥áÊñôÈõÜÊòØÈÄèÈÅéÊî∂ÈõÜ‰æÜËá™Ë®±Â§öÈÄöÂ∏∏Ê†πÊú¨‰∏çÂêåÁöÑ‰æÜÊ∫êÁöÑË≥áÊñôËÄåÂª∫ÊßãÁöÑ„ÄÇ‰ΩÜÊòØÔºå‰ΩïÊôÇÊñ∞Â¢ûÊõ¥Â§öË≥áÊñôÊúâÂπ´Âä©ÔºåËÄå‰ΩïÊôÇÊúÉÈòªÁ§ôÂú®ÁèæÂØ¶‰∏ñÁïåË®≠ÂÆö‰∏≠ÈÅîÊàêÈ†êÊúüÁöÑÊ®°ÂûãÊàêÊûúÔºüÊàëÂÄëÂ∞áÊ≠§ÊÉÖÊ≥ÅË™çÂÆöÁÇ∫„ÄåË≥áÊñôÊñ∞Â¢ûÂõ∞Â¢É„ÄçÔºåË≠âÊòéÂú®Ê≠§Â§ö‰æÜÊ∫êÊì¥ÂÖÖÁöÑËÉåÊôØ‰∏ãÊñ∞Â¢ûË®ìÁ∑¥Ë≥áÊñôÔºåÊúâÊôÇÂèØËÉΩÊúÉÂ∞éËá¥Êï¥È´îÊ∫ñÁ¢∫Â∫¶Èôç‰Ωé„ÄÅ‰∏çÁ¢∫ÂÆöÁöÑÂÖ¨Âπ≥ÊÄßÁµêÊûúÔºå‰ª•ÂèäÊúÄÂ∑ÆÂ≠êÁæ§È´îÊïàËÉΩÈôç‰Ωé„ÄÇÊàëÂÄëÁôºÁèæÈÄôÂèØËÉΩÊòØÁî±ÊñºË≥áÊñôÊì¥ÂÖÖÂ∞éËá¥ÁöÑÊ®°ÂûãÊïàËÉΩÊèêÂçáËàáÂàÜÈÖçËΩâÁßªÂ∞éËá¥ÁöÑÊ®°ÂûãÂä£Âåñ‰πãÈñìÁöÑÁ∂ìÈ©óÊÄßÊ¨äË°°ÊâÄËá¥„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëÂª∫Á´ã‰∫ÜÊáâÂ∞çÊ≠§Âõ∞Â¢ÉÁöÑÂü∫Êú¨Á≠ñÁï•ÔºåÂºïÂÖ•‰∫ÜÂàÜÈÖçËΩâÁßªÂïüÁôºÊ≥ïÔºå‰ª•ÊåáÂ∞éÊúâÈóúÂú®Ë≥áÊñôÊì¥ÂÖÖ‰∏≠Êñ∞Â¢ûÂì™‰∫õË≥áÊñô‰æÜÊ∫êÁöÑÊ±∫Á≠ñÂà∂ÂÆöÔºå‰ª•Áî¢ÁîüÈ†êÊúüÁöÑÊ®°ÂûãÊïàËÉΩÊèêÂçá„ÄÇÊàëÂÄëÊúÄÂæåË®éË´ñ‰∫ÜË≥áÊñôÊî∂ÈõÜÊâÄÈúÄÁöÑËÄÉÈáèÂõ†Á¥†Ôºå‰∏¶Âª∫Ë≠∞Á†îÁ©∂Ë≥áÊñôÁµÑÊàêÂíåË¶èÊ®°Âú®Ê®°ÂûãË¶èÊ®°Êó•ÁõäÊì¥Â§ßÁöÑÊôÇ‰ª£„ÄÇ

##### **Enhancing Healthcare through Large Language Models: A Study on Medical Question Answering**
2408.04138v1 by Haoran Yu, Chang Yu, Zihan Wang, Dongxian Zou, Hao Qin

In recent years, the application of Large Language Models (LLMs) in
healthcare has shown significant promise in improving the accessibility and
dissemination of medical knowledge. This paper presents a detailed study of
various LLMs trained on the MedQuAD medical question-answering dataset, with a
focus on identifying the most effective model for providing accurate medical
information. Among the models tested, the Sentence-t5 combined with Mistral 7B
demonstrated superior performance, achieving a precision score of 0.762. This
model's enhanced capabilities are attributed to its advanced pretraining
techniques, robust architecture, and effective prompt construction
methodologies. By leveraging these strengths, the Sentence-t5 + Mistral 7B
model excels in understanding and generating precise medical answers. Our
findings highlight the potential of integrating sophisticated LLMs in medical
contexts to facilitate efficient and accurate medical knowledge retrieval, thus
significantly enhancing patient education and support.

ÊëòË¶ÅÔºöËøëÂπ¥‰æÜÔºåÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÁöÑÊáâÁî®Â∑≤Â±ïÁèæÂá∫È°ØËëóÁöÑÂ∏åÊúõÔºåÂèØÊîπÂñÑÈÜ´ÁôÇÁü•Ë≠òÁöÑÂèØÂèäÊÄßÂíåÂÇ≥Êí≠„ÄÇÊú¨ÊñáÈáùÂ∞çÂú® MedQuAD ÈÜ´ÁôÇÂïèÁ≠îË≥áÊñôÈõÜ‰∏äË®ìÁ∑¥ÁöÑÂêÑÁ®Æ LLM ÈÄ≤Ë°åË©≥Á¥∞Á†îÁ©∂ÔºåÈáçÈªûÂú®ÊñºÊâæÂá∫Êèê‰æõÊ∫ñÁ¢∫ÈÜ´ÁôÇË≥áË®äÊúÄÊúâÊïàÁöÑÊ®°Âûã„ÄÇÂú®Ê∏¨Ë©¶ÁöÑÊ®°Âûã‰∏≠ÔºåSentence-t5 ÁµêÂêà Mistral 7B Ë°®ÁèæÂÑ™Áï∞ÔºåÈÅîÂà∞ 0.762 ÁöÑÁ≤æÊ∫ñÂ∫¶ÂàÜÊï∏„ÄÇÊ≠§Ê®°ÂûãÁöÑÂ¢ûÂº∑ÂäüËÉΩÊ≠∏ÂäüÊñºÂÖ∂ÂÖàÈÄ≤ÁöÑÈ†êË®ìÁ∑¥ÊäÄË°ì„ÄÅÂº∑Â§ßÁöÑÊû∂ÊßãÂíåÊúâÊïàÁöÑÊèêÁ§∫Âª∫ÊßãÊñπÊ≥ï„ÄÇSentence-t5 + Mistral 7B Ê®°ÂûãËóâÁî±ÈÅãÁî®ÈÄô‰∫õÂÑ™Âã¢ÔºåÂú®ÁêÜËß£ÂíåÁî¢ÁîüÁ≤æÁ¢∫ÁöÑÈÜ´ÁôÇÁ≠îÊ°àÊñπÈù¢Ë°®ÁèæÂá∫Ëâ≤„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÁ™ÅÈ°Ø‰∫ÜÂ∞áË§áÈõúÁöÑ LLM Êï¥ÂêàÂà∞ÈÜ´ÁôÇËÉåÊôØ‰∏≠ÁöÑÊΩõÂäõÔºå‰ª•‰øÉÈÄ≤ÊúâÊïàÁéá‰∏îÊ∫ñÁ¢∫ÁöÑÈÜ´ÁôÇÁü•Ë≠òÊì∑ÂèñÔºåÈÄ≤ËÄåÈ°ØËëóÊèêÂçáÁóÖÊÇ£ÊïôËÇ≤ÂíåÊîØÊåÅ„ÄÇ

##### **Can Rule-Based Insights Enhance LLMs for Radiology Report Classification? Introducing the RadPrompt Methodology**
2408.04121v1 by Panagiotis Fytas, Anna Breger, Ian Selby, Simon Baker, Shahab Shahipasand, Anna Korhonen

Developing imaging models capable of detecting pathologies from chest X-rays
can be cost and time-prohibitive for large datasets as it requires supervision
to attain state-of-the-art performance. Instead, labels extracted from
radiology reports may serve as distant supervision since these are routinely
generated as part of clinical practice. Despite their widespread use, current
rule-based methods for label extraction rely on extensive rule sets that are
limited in their robustness to syntactic variability. To alleviate these
limitations, we introduce RadPert, a rule-based system that integrates an
uncertainty-aware information schema with a streamlined set of rules, enhancing
performance. Additionally, we have developed RadPrompt, a multi-turn prompting
strategy that leverages RadPert to bolster the zero-shot predictive
capabilities of large language models, achieving a statistically significant
improvement in weighted average F1 score over GPT-4 Turbo. Most notably,
RadPrompt surpasses both its underlying models, showcasing the synergistic
potential of LLMs with rule-based models. We have evaluated our methods on two
English Corpora: the MIMIC-CXR gold-standard test set and a gold-standard
dataset collected from the Cambridge University Hospitals.

ÊëòË¶ÅÔºöÈñãÁôºÂá∫ËÉΩÂ§†ÂæûËÉ∏ÈÉ® X ÂÖâÊ™¢Ê∏¨ÁóÖÁêÜÁöÑÂΩ±ÂÉèÊ®°ÂûãÔºåÂ∞çÊñºÂ§ßÂûãË≥áÊñôÈõÜ‰æÜË™™ÔºåÂú®ÊàêÊú¨ÂíåÊôÇÈñì‰∏äÈÉΩÂèØËÉΩÊòØÁ¶ÅÊ≠¢ÁöÑÔºåÂõ†ÁÇ∫ÂÆÉÈúÄË¶ÅÁõ£Áù£ÊâçËÉΩÈÅîÂà∞ÊúÄÂÖàÈÄ≤ÁöÑÊïàËÉΩ„ÄÇÁõ∏ÂèçÂú∞ÔºåÂæûÊîæÂ∞ÑÁßëÂ†±Âëä‰∏≠ÊèêÂèñÁöÑÊ®ôÁ±§ÂèØ‰ª•Áî®‰ΩúÈÅ†Á´ØÁõ£Áù£ÔºåÂõ†ÁÇ∫ÈÄô‰∫õÊ®ôÁ±§ÈÄöÂ∏∏‰ΩúÁÇ∫Ëá®Â∫äÂØ¶ÂãôÁöÑ‰∏ÄÈÉ®ÂàÜËÄåÁî¢Áîü„ÄÇÂÑòÁÆ°Âª£Ê≥õ‰ΩøÁî®Ôºå‰ΩÜÁõÆÂâçÁî®ÊñºÊ®ôÁ±§ÊèêÂèñÁöÑÂü∫ÊñºË¶èÂâáÁöÑÊñπÊ≥ï‰æùË≥¥ÊñºÂª£Ê≥õÁöÑË¶èÂâáÈõÜÔºåÂÖ∂Â∞çË™ûÊ≥ïËÆäÁï∞ÁöÑÂÅ•Â£ØÊÄßÊúâÈôê„ÄÇÁÇ∫‰∫ÜÊ∏õËºïÈÄô‰∫õÈôêÂà∂ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü RadPertÔºåÈÄôÊòØ‰∏ÄÂÄãÂü∫ÊñºË¶èÂâáÁöÑÁ≥ªÁµ±ÔºåÂÆÉÂ∞á‰∏ÄÂÄã‰∏çÁ¢∫ÂÆöÊÄßÊÑüÁü•Ë≥áË®äÊû∂ÊßãËàá‰∏ÄÁµÑÁ∞°ÂåñÁöÑË¶èÂâáÊï¥ÂêàÂú®‰∏ÄËµ∑ÔºåÂæûËÄåÂ¢ûÂº∑‰∫ÜÊïàËÉΩ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÈÇÑÈñãÁôº‰∫Ü RadPromptÔºåÈÄôÊòØ‰∏ÄÂÄãÂ§öËº™ÊèêÁ§∫Á≠ñÁï•ÔºåÂÆÉÂà©Áî® RadPert ‰æÜÂä†Âº∑Â§ßÂûãË™ûË®ÄÊ®°ÂûãÁöÑÈõ∂Ê¨°Â≠∏ÁøíÈ†êÊ∏¨ËÉΩÂäõÔºåÂú®Âä†Ê¨äÂπ≥Âùá F1 ÂàÜÊï∏‰∏äÂØ¶Áèæ‰∫ÜÁõ∏Â∞çÊñº GPT-4 Turbo ÁöÑÁµ±Ë®àÈ°ØËëóÊîπÈÄ≤„ÄÇÊúÄÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåRadPrompt Ë∂ÖË∂ä‰∫ÜÂÖ∂Âü∫Á§éÊ®°ÂûãÔºåÂ±ïÁ§∫‰∫ÜÂü∫ÊñºË¶èÂâáÁöÑÊ®°ÂûãËàá LLM ÁöÑÂçîÂêåÊΩõÂäõ„ÄÇÊàëÂÄëÂ∑≤Âú®ÂÖ©ÂÄãËã±ÊñáË™ûÊñôÂ∫´‰∏äË©ï‰º∞‰∫ÜÊàëÂÄëÁöÑÊñπÊ≥ïÔºöMIMIC-CXR ÈªÉÈáëÊ®ôÊ∫ñÊ∏¨Ë©¶ÈõÜÂíåÂæûÂäçÊ©ãÂ§ßÂ≠∏ÈÜ´Èô¢Êî∂ÈõÜÁöÑÈªÉÈáëÊ®ôÊ∫ñË≥áÊñôÈõÜ„ÄÇ

##### **Handwritten Code Recognition for Pen-and-Paper CS Education**
2408.07220v1 by Md Sazzad Islam, Moussa Koulako Bala Doumbouya, Christopher D. Manning, Chris Piech

Teaching Computer Science (CS) by having students write programs by hand on
paper has key pedagogical advantages: It allows focused learning and requires
careful thinking compared to the use of Integrated Development Environments
(IDEs) with intelligent support tools or "just trying things out". The familiar
environment of pens and paper also lessens the cognitive load of students with
no prior experience with computers, for whom the mere basic usage of computers
can be intimidating. Finally, this teaching approach opens learning
opportunities to students with limited access to computers.
  However, a key obstacle is the current lack of teaching methods and support
software for working with and running handwritten programs. Optical character
recognition (OCR) of handwritten code is challenging: Minor OCR errors, perhaps
due to varied handwriting styles, easily make code not run, and recognizing
indentation is crucial for languages like Python but is difficult to do due to
inconsistent horizontal spacing in handwriting. Our approach integrates two
innovative methods. The first combines OCR with an indentation recognition
module and a language model designed for post-OCR error correction without
introducing hallucinations. This method, to our knowledge, surpasses all
existing systems in handwritten code recognition. It reduces error from 30\% in
the state of the art to 5\% with minimal hallucination of logical fixes to
student programs. The second method leverages a multimodal language model to
recognize handwritten programs in an end-to-end fashion. We hope this
contribution can stimulate further pedagogical research and contribute to the
goal of making CS education universally accessible. We release a dataset of
handwritten programs and code to support future research at
https://github.com/mdoumbouya/codeocr

ÊëòË¶ÅÔºöÈÄèÈÅéËÆìÂ≠∏ÁîüÊâãÂØ´Á®ãÂºèÂú®Á¥ô‰∏äÔºåÊïôÊéàÈõªËÖ¶ÁßëÂ≠∏ (CS) ÂÖ∑ÊúâÈóúÈçµÁöÑÊïôÂ≠∏ÂÑ™Âã¢ÔºöÂÆÉÂÖÅË®±Â∞àÊ≥®Â≠∏ÁøíÔºå‰∏¶ÈúÄË¶Å‰ªîÁ¥∞ÊÄùËÄÉÔºåËàá‰ΩøÁî®ÂÖ∑ÂÇôÊô∫ÊÖßÊîØÊè¥Â∑•ÂÖ∑Êàñ„ÄåÂè™ÊòØÂòóË©¶„ÄçÁöÑÊï¥ÂêàÈñãÁôºÁí∞Â¢É (IDE) Áõ∏ÊØî„ÄÇÁÜüÊÇâÁ≠ÜÂíåÁ¥ôÁöÑÁí∞Â¢É‰πüÊúÉÊ∏õËºïÊ≤íÊúâÈõªËÖ¶Á∂ìÈ©óÂ≠∏ÁîüÁöÑË™çÁü•Ë≤†ÊìîÔºåÂ∞ç‰ªñÂÄë‰æÜË™™ÔºåÂÖâÊòØÈõªËÖ¶ÁöÑÂü∫Êú¨‰ΩøÁî®Â∞±ÂèØËÉΩ‰ª§‰∫∫ÊúõËÄåÁîüÁïè„ÄÇÊúÄÂæåÔºåÈÄôÁ®ÆÊïôÂ≠∏ÊñπÊ≥ïÁÇ∫ÈõªËÖ¶‰ΩøÁî®ÂèóÈôêÁöÑÂ≠∏ÁîüÈñãÂïü‰∫ÜÂ≠∏ÁøíÊ©üÊúÉ„ÄÇ
ÁÑ∂ËÄåÔºå‰∏ÄÂÄã‰∏ªË¶ÅÁöÑÈöúÁ§ôÊòØÁõÆÂâçÁº∫‰πèÊîØÊè¥ÊâãÂØ´Á®ãÂºèÁ∑®ÂØ´ÂíåÂü∑Ë°åÁöÑÊïôÂ≠∏ÊñπÊ≥ïÂíåËªüÈ´î„ÄÇÊâãÂØ´Á®ãÂºèÁ¢ºÁöÑÂÖâÂ≠∏Â≠óÂÖÉËæ®Ë≠ò (OCR) ÂÖ∑ÊúâÊåëÊà∞ÊÄßÔºöËºïÂæÆÁöÑ OCR ÈåØË™§ÔºåÂèØËÉΩÊòØÁî±Êñº‰∏çÂêåÁöÑÊâãÂØ´È¢®Ê†ºÔºåÂæàÂÆπÊòìËÆìÁ®ãÂºèÁÑ°Ê≥ïÂü∑Ë°åÔºåËÄåËæ®Ë≠òÁ∏ÆÊéíÂ∞ç Python Á≠âË™ûË®ÄËá≥ÈóúÈáçË¶ÅÔºå‰ΩÜÁî±ÊñºÊâãÂØ´ÁöÑÊ∞¥Âπ≥ÈñìË∑ù‰∏ç‰∏ÄËá¥ÔºåÂõ†Ê≠§ÂæàÈõ£ÂÅöÂà∞„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÊï¥Âêà‰∫ÜÂÖ©Á®ÆÂâµÊñ∞ÁöÑÊñπÊ≥ï„ÄÇÁ¨¨‰∏ÄÂÄãÊñπÊ≥ïÁµêÂêà OCR„ÄÅÁ∏ÆÊéíËæ®Ë≠òÊ®°ÁµÑÂíåË™ûË®ÄÊ®°ÂûãÔºåË©≤Ê®°ÂûãÂ∞àÈñÄÁî®Êñº OCR ÂæåÁöÑÈåØË™§‰øÆÊ≠£ÔºåËÄå‰∏çÊúÉÂºïÂÖ•ÂπªË¶∫„ÄÇÊìöÊàëÂÄëÊâÄÁü•ÔºåÊ≠§ÊñπÊ≥ïË∂ÖË∂ä‰∫ÜÊâÄÊúâÁèæÊúâÁöÑÊâãÂØ´Á®ãÂºèÁ¢ºËæ®Ë≠òÁ≥ªÁµ±„ÄÇÂÆÉÂ∞áÈåØË™§ÂæûÁèæÊúâÊäÄË°ìÁöÑ 30% Èôç‰ΩéÂà∞ 5%Ôºå‰∏¶Â∞áÂ≠∏ÁîüÁ®ãÂºèÁöÑÈÇèËºØ‰øÆÊ≠£ÂπªË¶∫ÈôçËá≥ÊúÄ‰Ωé„ÄÇÁ¨¨‰∫åÁ®ÆÊñπÊ≥ïÂà©Áî®Â§öÊ®°ÂºèË™ûË®ÄÊ®°Âûã‰ª•Á´ØÂà∞Á´ØÁöÑÊñπÂºèËæ®Ë≠òÊâãÂØ´Á®ãÂºè„ÄÇÊàëÂÄëÂ∏åÊúõÊ≠§Ë≤¢ÁçªËÉΩÊøÄÂãµÈÄ≤‰∏ÄÊ≠•ÁöÑÊïôÂ≠∏Á†îÁ©∂Ôºå‰∏¶ÊúâÂä©ÊñºÂØ¶ÁèæËÆì CS ÊïôËÇ≤ÊôÆÂèäÁöÑÁõÆÊ®ô„ÄÇÊàëÂÄëÈáãÂá∫‰∫ÜÊâãÂØ´Á®ãÂºèÂíåÁ®ãÂºèÁ¢ºÁöÑË≥áÊñôÈõÜÔºå‰ª•ÊîØÊè¥Êú™‰æÜÁöÑÁ†îÁ©∂ÔºåÁ∂≤ÂùÄÁÇ∫ https://github.com/mdoumbouya/codeocr

##### **Multimodal Gender Fairness in Depression Prediction: Insights on Data from the USA & China**
2408.04026v1 by Joseph Cameron, Jiaee Cheong, Micol Spitale, Hatice Gunes

Social agents and robots are increasingly being used in wellbeing settings.
However, a key challenge is that these agents and robots typically rely on
machine learning (ML) algorithms to detect and analyse an individual's mental
wellbeing. The problem of bias and fairness in ML algorithms is becoming an
increasingly greater source of concern. In concurrence, existing literature has
also indicated that mental health conditions can manifest differently across
genders and cultures. We hypothesise that the representation of features
(acoustic, textual, and visual) and their inter-modal relations would vary
among subjects from different cultures and genders, thus impacting the
performance and fairness of various ML models. We present the very first
evaluation of multimodal gender fairness in depression manifestation by
undertaking a study on two different datasets from the USA and China. We
undertake thorough statistical and ML experimentation and repeat the
experiments for several different algorithms to ensure that the results are not
algorithm-dependent. Our findings indicate that though there are differences
between both datasets, it is not conclusive whether this is due to the
difference in depression manifestation as hypothesised or other external
factors such as differences in data collection methodology. Our findings
further motivate a call for a more consistent and culturally aware data
collection process in order to address the problem of ML bias in depression
detection and to promote the development of fairer agents and robots for
wellbeing.

ÊëòË¶ÅÔºöÁ§æÁæ§‰ª£ÁêÜ‰∫∫ÂíåÊ©üÂô®‰∫∫Âú®Âπ∏Á¶èÊÑüË®≠ÂÆö‰∏≠Ê≠£Ë∂ä‰æÜË∂äÂª£Ê≥õÂú∞Ë¢´‰ΩøÁî®„ÄÇ
ÁÑ∂ËÄåÔºå‰∏ÄÂÄãÈóúÈçµÁöÑÊåëÊà∞ÊòØÈÄô‰∫õ‰ª£ÁêÜ‰∫∫ÂíåÊ©üÂô®‰∫∫ÈÄöÂ∏∏‰æùË≥¥Ê©üÂô®Â≠∏Áøí (ML) ÊºîÁÆóÊ≥ï‰æÜÂÅµÊ∏¨ÂíåÂàÜÊûêÂÄã‰∫∫ÂøÉÁêÜÂÅ•Â∫∑„ÄÇML ÊºîÁÆóÊ≥ï‰∏≠ÁöÑÂÅèÂ∑ÆÂíåÂÖ¨Âπ≥ÊÄßÂïèÈ°åÊ≠£ÊàêÁÇ∫Ë∂ä‰æÜË∂äÂ§ßÁöÑÈóúÊ≥®‰æÜÊ∫ê„ÄÇÂêåÊôÇÔºåÁèæÊúâÊñáÁçª‰πüÊåáÂá∫ÂøÉÁêÜÂÅ•Â∫∑ÁãÄÊ≥ÅÊúÉÂú®‰∏çÂêåÊÄßÂà•ÂíåÊñáÂåñ‰∏≠‰ª•‰∏çÂêåÁöÑÊñπÂºèÈ°ØÁèæ„ÄÇÊàëÂÄëÂÅáË®≠ÁâπÂæµÔºàËÅ≤Èü≥„ÄÅÊñáÂ≠óÂíåË¶ñË¶∫ÔºâÁöÑÂëàÁèæÂèäÂÖ∂Ë∑®Ê®°ÊÖãÈóú‰øÇÊúÉÂõ†‰∏çÂêåÊñáÂåñÂíåÊÄßÂà•ÁöÑÂèóË©¶ËÄÖËÄåÁï∞ÔºåÂæûËÄåÂΩ±ÈüøÂêÑÁ®Æ ML Ê®°ÂûãÁöÑÊïàËÉΩÂíåÂÖ¨Âπ≥ÊÄß„ÄÇÊàëÂÄëÈÄèÈÅéÂ∞ç‰æÜËá™ÁæéÂúãÂíå‰∏≠ÂúãÁöÑÂÖ©ÂÄã‰∏çÂêåË≥áÊñôÈõÜÈÄ≤Ë°åÁ†îÁ©∂ÔºåÊèêÂá∫È¶ñÊ¨°Â∞çÊÜÇÈ¨±ÁóáË°®ÁèæÁöÑÂ§öÊ®°ÊÖãÊÄßÂà•ÂÖ¨Âπ≥ÊÄßË©ï‰º∞„ÄÇÊàëÂÄëÈÄ≤Ë°åÂæπÂ∫ïÁöÑÁµ±Ë®àÂíå ML ÂØ¶È©óÔºå‰∏¶ÈáùÂ∞çÂ§öÁ®Æ‰∏çÂêåÁöÑÊºîÁÆóÊ≥ïÈáçË§áÂØ¶È©óÔºå‰ª•Á¢∫‰øùÁµêÊûú‰∏ç‰æùË≥¥ÊñºÊºîÁÆóÊ≥ï„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúË°®ÊòéÔºåÂÑòÁÆ°ÂÖ©ÂÄãË≥áÊñôÈõÜ‰πãÈñìÂ≠òÂú®Â∑ÆÁï∞Ôºå‰ΩÜÁÑ°Ê≥ïÁ¢∫ÂÆöÈÄôÊòØÂê¶ÊòØÁî±ÊñºÂÅáË®≠ÁöÑÊÜÇÈ¨±ÁóáË°®ÁèæÂ∑ÆÁï∞ÊàñÂÖ∂‰ªñÂ§ñÈÉ®Âõ†Á¥†Ôºà‰æãÂ¶ÇË≥áÊñôÊî∂ÈõÜÊñπÊ≥ïÁöÑÂ∑ÆÁï∞ÔºâÊâÄÈÄ†Êàê„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÈÄ≤‰∏ÄÊ≠•ÂëºÁ±≤Êé°Áî®Êõ¥‰∏ÄËá¥‰∏îÂÖ∑ÊúâÊñáÂåñÊÑèË≠òÁöÑË≥áÊñôÊî∂ÈõÜÁ®ãÂ∫èÔºå‰ª•Ëß£Ê±∫ÊÜÇÈ¨±ÁóáÂÅµÊ∏¨‰∏≠ÁöÑ ML ÂÅèÂ∑ÆÂïèÈ°åÔºå‰∏¶‰øÉÈÄ≤ÈñãÁôºÊõ¥ÂÖ¨Âπ≥ÁöÑ‰ª£ÁêÜ‰∫∫ÂíåÊ©üÂô®‰∫∫Ôºå‰ª•ÊèêÂçáÂπ∏Á¶èÊÑü„ÄÇ

##### **Inter-Series Transformer: Attending to Products in Time Series Forecasting**
2408.03872v1 by Rares Cristian, Pavithra Harsha, Clemente Ocejo, Georgia Perakis, Brian Quanz, Ioannis Spantidakis, Hamza Zerhouni

Time series forecasting is an important task in many fields ranging from
supply chain management to weather forecasting. Recently, Transformer neural
network architectures have shown promising results in forecasting on common
time series benchmark datasets. However, application to supply chain demand
forecasting, which can have challenging characteristics such as sparsity and
cross-series effects, has been limited.
  In this work, we explore the application of Transformer-based models to
supply chain demand forecasting. In particular, we develop a new
Transformer-based forecasting approach using a shared, multi-task per-time
series network with an initial component applying attention across time series,
to capture interactions and help address sparsity. We provide a case study
applying our approach to successfully improve demand prediction for a medical
device manufacturing company. To further validate our approach, we also apply
it to public demand forecasting datasets as well and demonstrate competitive to
superior performance compared to a variety of baseline and state-of-the-art
forecast methods across the private and public datasets.

ÊëòË¶ÅÔºöÊôÇÈñìÂ∫èÂàóÈ†êÊ∏¨Âú®Ë®±Â§öÈ†òÂüü‰∏≠ÈÉΩÊòØ‰∏ÄÈ†ÖÈáçË¶ÅÁöÑ‰ªªÂãôÔºåÂæû‰æõÊáâÈèàÁÆ°ÁêÜÂà∞Â§©Ê∞£È†êÊ∏¨ÈÉΩÊúâÊ∂âÂèä„ÄÇÊúÄËøëÔºåTransformer Á•ûÁ∂ìÁ∂≤Ë∑ØÊû∂ÊßãÂú®Â∏∏Ë¶ãÊôÇÈñìÂ∫èÂàóÂü∫Ê∫ñË≥áÊñôÈõÜÁöÑÈ†êÊ∏¨‰∏≠Â±ïÁèæ‰∫Ü‰ª§‰∫∫ÊªøÊÑèÁöÑÊàêÊûú„ÄÇÁÑ∂ËÄåÔºåÊáâÁî®Êñº‰æõÊáâÈèàÈúÄÊ±ÇÈ†êÊ∏¨ÁöÑÁØÑÁñáÂèóÂà∞ÈôêÂà∂ÔºåÂõ†ÁÇ∫‰æõÊáâÈèàÈúÄÊ±ÇÈ†êÊ∏¨ÂèØËÉΩÂÖ∑ÊúâÁ®ÄÁñèÊÄßÂíåË∑®Á≥ªÂàóÊïàÊáâÁ≠âÂÖ∑ÊåëÊà∞ÊÄßÁöÑÁâπÂæµ„ÄÇ
  Âú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊé¢Ë®é‰∫ÜÂ∞áÂü∫Êñº Transformer ÁöÑÊ®°ÂûãÊáâÁî®Êñº‰æõÊáâÈèàÈúÄÊ±ÇÈ†êÊ∏¨„ÄÇÁâπÂà•ÊòØÔºåÊàëÂÄëÈñãÁôº‰∫Ü‰∏ÄÁ®ÆÊñ∞ÁöÑÂü∫Êñº Transformer ÁöÑÈ†êÊ∏¨ÊñπÊ≥ïÔºå‰ΩøÁî®‰∏ÄÂÄãÂÖ±Áî®ÁöÑ„ÄÅÊØèÂÄãÊôÇÈñìÂ∫èÂàóÁöÑÂ§ö‰ªªÂãôÁ∂≤Ë∑ØÔºå‰∏¶Âú®ÂàùÂßãÂÖÉ‰ª∂‰∏≠Â•óÁî®Ë∑®ÊôÇÈñìÂ∫èÂàóÁöÑÊ≥®ÊÑèÂäõÔºå‰ª•Êì∑Âèñ‰∫íÂãï‰∏¶ÂçîÂä©Ëß£Ê±∫Á®ÄÁñèÊÄßÂïèÈ°å„ÄÇÊàëÂÄëÊèê‰æõ‰∫Ü‰∏ÄÂÄãÊ°à‰æãÁ†îÁ©∂ÔºåÊáâÁî®ÊàëÂÄëÁöÑÂÅöÊ≥ïÊàêÂäüÊîπÂñÑ‰∫Ü‰∏ÄÂÆ∂ÈÜ´ÁôÇÂô®ÊùêË£ΩÈÄ†ÂÖ¨Âè∏ÁöÑÈúÄÊ±ÇÈ†êÊ∏¨„ÄÇÁÇ∫‰∫ÜÈÄ≤‰∏ÄÊ≠•È©óË≠âÊàëÂÄëÁöÑÂÅöÊ≥ïÔºåÊàëÂÄë‰πüÂ∞áÂÖ∂ÊáâÁî®ÊñºÂÖ¨ÈñãÁöÑÈúÄÊ±ÇÈ†êÊ∏¨Ë≥áÊñôÈõÜÔºå‰∏¶Ë≠âÊòéËàáÂêÑÁ®ÆÂü∫Á∑öÂíåÊúÄÂÖàÈÄ≤ÁöÑÈ†êÊ∏¨ÊñπÊ≥ïÁõ∏ÊØîÔºåÂú®ÁßÅÊúâÂíåÂÖ¨ÈñãË≥áÊñôÈõÜ‰∏≠ÁöÑË°®ÁèæÂÖ∑ÊúâÁ´∂Áà≠ÂäõÊàñÂÑ™ÊñºÈÄô‰∫õÊñπÊ≥ï„ÄÇ

##### **Anatomical Foundation Models for Brain MRIs**
2408.07079v1 by Carlo Alberto Barbano, Matteo Brunello, Benoit Dufumier, Marco Grangetto

Deep Learning (DL) in neuroimaging has become increasingly relevant for
detecting neurological conditions and neurodegenerative disorders. One of the
most predominant biomarkers in neuroimaging is represented by brain age, which
has been shown to be a good indicator for different conditions, such as
Alzheimer's Disease. Using brain age for pretraining DL models in transfer
learning settings has also recently shown promising results, especially when
dealing with data scarcity of different conditions. On the other hand,
anatomical information of brain MRIs (e.g. cortical thickness) can provide
important information for learning good representations that can be transferred
to many downstream tasks. In this work, we propose AnatCL, an anatomical
foundation model for brain MRIs that i.) leverages anatomical information with
a weakly contrastive learning approach and ii.) achieves state-of-the-art
performances in many different downstream tasks. To validate our approach we
consider 12 different downstream tasks for diagnosis classification, and
prediction of 10 different clinical assessment scores.

ÊëòË¶ÅÔºöÊ∑±Â∫¶Â≠∏Áøí (DL) Âú®Á•ûÁ∂ìÂΩ±ÂÉèÂ≠∏‰∏≠Â∑≤ËÆäÂæóË∂ä‰æÜË∂äÈáçË¶ÅÔºåÂèØÁî®ÊñºÂÅµÊ∏¨Á•ûÁ∂ìÁ≥ªÁµ±ÁñæÁóÖÂíåÁ•ûÁ∂ìÈÄÄÂåñÊÄßÁñæÁóÖ„ÄÇÁ•ûÁ∂ìÂΩ±ÂÉèÂ≠∏‰∏≠ÊúÄÈáçË¶ÅÁöÑÁîüÁâ©Ê®ôË®ò‰πã‰∏ÄÊòØÂ§ßËÖ¶Âπ¥ÈΩ°ÔºåÂ∑≤È°ØÁ§∫ÁÇ∫ÂêÑÁ®ÆÁñæÁóÖÔºà‰æãÂ¶ÇÈòøËå≤Êµ∑ÈªòÁóáÔºâÁöÑËâØÂ•ΩÊåáÊ®ô„ÄÇÊúÄËøëÔºå‰ΩøÁî®Â§ßËÖ¶Âπ¥ÈΩ°ÈÄ≤Ë°åÈ†êË®ìÁ∑¥ DL Ê®°Âûã‰ª•Áî®ÊñºÈÅ∑ÁßªÂ≠∏ÁøíË®≠ÂÆö‰πüÈ°ØÁ§∫Âá∫ÊúâÂ∏åÊúõÁöÑÁµêÊûúÔºåÁâπÂà•ÊòØÂú®ËôïÁêÜÂêÑÁ®ÆÁñæÁóÖÁöÑË≥áÊñôÁ®ÄÂ∞ëÊôÇ„ÄÇÂè¶‰∏ÄÊñπÈù¢ÔºåÂ§ßËÖ¶ MRI ÁöÑËß£ÂâñË≥áË®äÔºà‰æãÂ¶ÇÁöÆË≥™ÂéöÂ∫¶ÔºâÂèØ‰ª•Êèê‰æõÈáçË¶ÅË≥áË®äÔºåÁî®ÊñºÂ≠∏ÁøíÂèØ‰ª•ËΩâÁßªÂà∞Ë®±Â§ö‰∏ãÊ∏∏‰ªªÂãôÁöÑËâØÂ•ΩË°®Á§∫„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫ AnatCLÔºåÈÄôÊòØ‰∏ÄÂÄãÁî®ÊñºÂ§ßËÖ¶ MRI ÁöÑËß£ÂâñÂü∫Á§éÊ®°ÂûãÔºåÂÆÉ i.) Âà©Áî®Ëß£ÂâñË≥áË®äÂíåÂº±Â∞çÊØîÂ≠∏ÁøíÊñπÊ≥ïÔºå‰ª•Âèä ii.) Âú®Ë®±Â§ö‰∏çÂêåÁöÑ‰∏ãÊ∏∏‰ªªÂãô‰∏≠ÂØ¶ÁèæÊúÄÂÖàÈÄ≤ÁöÑÊïàËÉΩ„ÄÇÁÇ∫‰∫ÜÈ©óË≠âÊàëÂÄëÁöÑÂÅöÊ≥ïÔºåÊàëÂÄëËÄÉÊÖÆ‰∫Ü 12 ÂÄã‰∏çÂêåÁöÑ‰∏ãÊ∏∏‰ªªÂãôÔºåÁî®ÊñºË®∫Êñ∑ÂàÜÈ°ûÂíåÈ†êÊ∏¨ 10 ÂÄã‰∏çÂêåÁöÑËá®Â∫äË©ïÂàÜ„ÄÇ

##### **HiQuE: Hierarchical Question Embedding Network for Multimodal Depression Detection**
2408.03648v1 by Juho Jung, Chaewon Kang, Jeewoo Yoon, Seungbae Kim, Jinyoung Han

The utilization of automated depression detection significantly enhances
early intervention for individuals experiencing depression. Despite numerous
proposals on automated depression detection using recorded clinical interview
videos, limited attention has been paid to considering the hierarchical
structure of the interview questions. In clinical interviews for diagnosing
depression, clinicians use a structured questionnaire that includes routine
baseline questions and follow-up questions to assess the interviewee's
condition. This paper introduces HiQuE (Hierarchical Question Embedding
network), a novel depression detection framework that leverages the
hierarchical relationship between primary and follow-up questions in clinical
interviews. HiQuE can effectively capture the importance of each question in
diagnosing depression by learning mutual information across multiple
modalities. We conduct extensive experiments on the widely-used clinical
interview data, DAIC-WOZ, where our model outperforms other state-of-the-art
multimodal depression detection models and emotion recognition models,
showcasing its clinical utility in depression detection.

ÊëòË¶ÅÔºöËá™ÂãïÊÜÇÈ¨±ÁóáÂÅµÊ∏¨ÁöÑÂà©Áî®È°ØËëóÊèêÂçá‰∫ÜÊÜÇÈ¨±ÁóáÊÇ£ËÄÖÁöÑÊó©Êúü‰ªãÂÖ•„ÄÇÂÑòÁÆ°ÊúâË®±Â§ö‰ΩøÁî®ÈåÑË£ΩËá®Â∫äË®™Ë´áÂΩ±ÁâáÁöÑËá™ÂãïÊÜÇÈ¨±ÁóáÂÅµÊ∏¨ÊèêÊ°àÔºå‰ΩÜÂ∞çÊñºËÄÉÈáèË®™Ë´áÂïèÈ°åÁöÑÈöéÂ±§ÁµêÊßãÈÄôÊñπÈù¢ÂçªÈÆÆÂ∞ëÈóúÊ≥®„ÄÇÂú®Áî®ÊñºË®∫Êñ∑ÊÜÇÈ¨±ÁóáÁöÑËá®Â∫äË®™Ë´á‰∏≠ÔºåËá®Â∫äÈÜ´Â∏´ÊúÉ‰ΩøÁî®ÂåÖÂê´‰æãË°åÂü∫Ê∫ñÂïèÈ°åÂíåËøΩËπ§ÂïèÈ°åÁöÑÁµêÊßãÂåñÂïèÂç∑‰æÜË©ï‰º∞ÂèóË®™ËÄÖÁöÑÁãÄÊ≥Å„ÄÇÊú¨Êñá‰ªãÁ¥π‰∫Ü HiQuEÔºàÈöéÂ±§ÂºèÂïèÈ°åÂµåÂÖ•Á∂≤Ë∑ØÔºâÔºåÈÄôÊòØ‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÊÜÇÈ¨±ÁóáÂÅµÊ∏¨Êû∂ÊßãÔºåÂÆÉÂà©Áî®‰∫ÜËá®Â∫äË®™Ë´á‰∏≠‰∏ªË¶ÅÂïèÈ°åÂíåËøΩËπ§ÂïèÈ°å‰πãÈñìÁöÑÈöéÂ±§Èóú‰øÇ„ÄÇHiQuE ËÉΩÂ§†ÈÄèÈÅéÂ≠∏ÁøíÂ§öÁ®ÆÊñπÂºè‰πãÈñìÁöÑ‰∫íÊÉ†Ë≥áË®äÔºåÊúâÊïàÂú∞Êì∑ÂèñÊØèÂÄãÂïèÈ°åÂú®ÊÜÇÈ¨±ÁóáË®∫Êñ∑‰∏≠ÁöÑÈáçË¶ÅÊÄß„ÄÇÊàëÂÄëÂú®Âª£Ê≥õ‰ΩøÁî®ÁöÑËá®Â∫äË®™Ë´áË≥áÊñô DAIC-WOZ ‰∏äÈÄ≤Ë°å‰∫ÜÂª£Ê≥õÁöÑÂØ¶È©óÔºåÊàëÂÄëÁöÑÊ®°ÂûãÂÑ™ÊñºÂÖ∂‰ªñÊúÄÂÖàÈÄ≤ÁöÑÂ§öÊ®°ÊÖãÊÜÇÈ¨±ÁóáÂÅµÊ∏¨Ê®°ÂûãÂíåÊÉÖÁ∑íËæ®Ë≠òÊ®°ÂûãÔºåÂ±ïÁ§∫‰∫ÜÂÖ∂Âú®ÊÜÇÈ¨±ÁóáÂÅµÊ∏¨‰∏≠ÁöÑËá®Â∫äÊïàÁî®„ÄÇ

##### **Improving the quality of Persian clinical text with a novel spelling correction system**
2408.03622v1 by Seyed Mohammad Sadegh Dashti, Seyedeh Fatemeh Dashti

Background: The accuracy of spelling in Electronic Health Records (EHRs) is a
critical factor for efficient clinical care, research, and ensuring patient
safety. The Persian language, with its abundant vocabulary and complex
characteristics, poses unique challenges for real-word error correction. This
research aimed to develop an innovative approach for detecting and correcting
spelling errors in Persian clinical text.
  Methods: Our strategy employs a state-of-the-art pre-trained model that has
been meticulously fine-tuned specifically for the task of spelling correction
in the Persian clinical domain. This model is complemented by an innovative
orthographic similarity matching algorithm, PERTO, which uses visual similarity
of characters for ranking correction candidates.
  Results: The evaluation of our approach demonstrated its robustness and
precision in detecting and rectifying word errors in Persian clinical text. In
terms of non-word error correction, our model achieved an F1-Score of 90.0%
when the PERTO algorithm was employed. For real-word error detection, our model
demonstrated its highest performance, achieving an F1-Score of 90.6%.
Furthermore, the model reached its highest F1-Score of 91.5% for real-word
error correction when the PERTO algorithm was employed.
  Conclusions: Despite certain limitations, our method represents a substantial
advancement in the field of spelling error detection and correction for Persian
clinical text. By effectively addressing the unique challenges posed by the
Persian language, our approach paves the way for more accurate and efficient
clinical documentation, contributing to improved patient care and safety.
Future research could explore its use in other areas of the Persian medical
domain, enhancing its impact and utility.

ÊëòË¶ÅÔºöËÉåÊôØÔºöÈõªÂ≠êÁóÖÊ≠∑ (EHR) ‰∏≠ÊãºÂØ´ÁöÑÊ∫ñÁ¢∫ÊÄßÊòØÊúâÊïàËá®Â∫äÁÖßË≠∑„ÄÅÁ†îÁ©∂ÂíåÁ¢∫‰øùÊÇ£ËÄÖÂÆâÂÖ®ÊÄßÁöÑÈóúÈçµÂõ†Á¥†„ÄÇÊ≥¢ÊñØË™ûÊìÅÊúâË±êÂØåÁöÑË©ûÂΩôÂíåË§áÈõúÁöÑÁâπÂæµÔºåÂ∞çÁúüÂØ¶‰∏ñÁïåÁöÑÈåØË™§Êõ¥Ê≠£ÊèêÂá∫‰∫ÜÁç®ÁâπÁöÑÊåëÊà∞„ÄÇÊú¨Á†îÁ©∂Êó®Âú®ÈñãÁôº‰∏ÄÁ®ÆÂâµÊñ∞ÁöÑÊñπÊ≥ï‰æÜÂÅµÊ∏¨ÂíåÊõ¥Ê≠£Ê≥¢ÊñØË™ûËá®Â∫äÊñáÊú¨‰∏≠ÁöÑÊãºÂØ´ÈåØË™§„ÄÇ
ÊñπÊ≥ïÔºöÊàëÂÄëÁöÑÁ≠ñÁï•Êé°Áî®‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÈ†êË®ìÁ∑¥Ê®°ÂûãÔºåË©≤Ê®°ÂûãÁ∂ìÈÅéÁ≤æÂøÉÂæÆË™øÔºåÂ∞àÈñÄÁî®ÊñºÊ≥¢ÊñØË™ûËá®Â∫äÈ†òÂüü‰∏≠ÁöÑÊãºÂØ´Êõ¥Ê≠£‰ªªÂãô„ÄÇÊ≠§Ê®°ÂûãÁî±ÂâµÊñ∞ÁöÑÊ≠£Â≠óÊ≥ïÁõ∏‰ººÊÄßÂåπÈÖçÊºîÁÆóÊ≥ï PERTO Ë£úÂÖÖÔºåË©≤ÊºîÁÆóÊ≥ï‰ΩøÁî®Â≠óÂÖÉÁöÑË¶ñË¶∫Áõ∏‰ººÊÄß‰æÜÂ∞çÊõ¥Ê≠£ÂÄôÈÅ∏È†ÖÈÄ≤Ë°åÊéíÂêç„ÄÇ
ÁµêÊûúÔºöÂ∞çÊàëÂÄëÊñπÊ≥ïÁöÑË©ï‰º∞Ë≠âÊòé‰∫ÜÂÖ∂Âú®ÂÅµÊ∏¨ÂíåÁ≥æÊ≠£Ê≥¢ÊñØË™ûËá®Â∫äÊñáÊú¨‰∏≠ÁöÑÊñáÂ≠óÈåØË™§ÊñπÈù¢ÁöÑÁ©©ÂÅ•ÊÄßÂíåÊ∫ñÁ¢∫ÊÄß„ÄÇÂú®ÈùûÊñáÂ≠óÈåØË™§Êõ¥Ê≠£ÊñπÈù¢ÔºåÁï∂‰ΩøÁî® PERTO ÊºîÁÆóÊ≥ïÊôÇÔºåÊàëÂÄëÁöÑÊ®°ÂûãÂØ¶Áèæ‰∫Ü 90.0% ÁöÑ F1 ÂàÜÊï∏„ÄÇÂ∞çÊñºÁúüÂØ¶‰∏ñÁïåÁöÑÈåØË™§ÂÅµÊ∏¨ÔºåÊàëÂÄëÁöÑÊ®°ÂûãÂ±ïÁ§∫‰∫ÜÂÖ∂ÊúÄÈ´òÁöÑÊïàËÉΩÔºåÂØ¶Áèæ‰∫Ü 90.6% ÁöÑ F1 ÂàÜÊï∏„ÄÇÊ≠§Â§ñÔºåÁï∂‰ΩøÁî® PERTO ÊºîÁÆóÊ≥ïÊôÇÔºåË©≤Ê®°ÂûãÈÅîÂà∞‰∫ÜÂÖ∂ÊúÄÈ´òÁöÑ F1 ÂàÜÊï∏ 91.5%ÔºåÁî®ÊñºÁúüÂØ¶‰∏ñÁïåÁöÑÈåØË™§Êõ¥Ê≠£„ÄÇ
ÁµêË´ñÔºöÂÑòÁÆ°Â≠òÂú®Êüê‰∫õÈôêÂà∂Ôºå‰ΩÜÊàëÂÄëÁöÑÊ®°Âûã‰ª£Ë°®‰∫ÜÊ≥¢ÊñØË™ûËá®Â∫äÊñáÊú¨ÊãºÂØ´ÈåØË™§ÂÅµÊ∏¨ÂíåÊõ¥Ê≠£È†òÂüüÁöÑÈáçÂ§ßÈÄ≤Â±ï„ÄÇÈÄèÈÅéÊúâÊïàËß£Ê±∫Ê≥¢ÊñØË™ûÊâÄÂ∏∂‰æÜÁöÑÁç®ÁâπÊåëÊà∞ÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÁÇ∫Êõ¥Ê∫ñÁ¢∫ÂíåÊúâÊïàÁöÑËá®Â∫äÊñá‰ª∂Èã™Ë∑ØÔºåÊúâÂä©ÊñºÊîπÂñÑÊÇ£ËÄÖÁÖßË≠∑ÂíåÂÆâÂÖ®ÊÄß„ÄÇÊú™‰æÜÁöÑÁ†îÁ©∂ÂèØ‰ª•Êé¢Ë®éÂÖ∂Âú®Ê≥¢ÊñØË™ûÈÜ´Â≠∏È†òÂüüÂÖ∂‰ªñÈ†òÂüüÁöÑÊáâÁî®Ôºå‰ª•Â¢ûÂº∑ÂÖ∂ÂΩ±ÈüøÂäõÂíåÂØ¶Áî®ÊÄß„ÄÇ

##### **Identifying treatment response subgroups in observational time-to-event data**
2408.03463v1 by Vincent Jeanselme, Chang Ho Yoon, Fabian Falck, Brian Tom, Jessica Barrett

Identifying patient subgroups with different treatment responses is an
important task to inform medical recommendations, guidelines, and the design of
future clinical trials. Existing approaches for subgroup analysis primarily
focus on Randomised Controlled Trials (RCTs), in which treatment assignment is
randomised. Furthermore, the patient cohort of an RCT is often constrained by
cost, and is not representative of the heterogeneity of patients likely to
receive treatment in real-world clinical practice. Therefore, when applied to
observational studies, such approaches suffer from significant statistical
biases because of the non-randomisation of treatment. Our work introduces a
novel, outcome-guided method for identifying treatment response subgroups in
observational studies. Our approach assigns each patient to a subgroup
associated with two time-to-event distributions: one under treatment and one
under control regime. It hence positions itself in between individualised and
average treatment effect estimation. The assumptions of our model result in a
simple correction of the statistical bias from treatment non-randomisation
through inverse propensity weighting. In experiments, our approach
significantly outperforms the current state-of-the-art method for
outcome-guided subgroup analysis in both randomised and observational treatment
regimes.

ÊëòË¶ÅÔºöË≠òÂà•ÂÖ∑Êúâ‰∏çÂêåÊ≤ªÁôÇÂèçÊáâÁöÑÊÇ£ËÄÖÂ≠êÁæ§ÊòØÁÇ∫ÈÜ´ÁôÇÂª∫Ë≠∞„ÄÅÊåáÂçóÂíåÊú™‰æÜËá®Â∫äË©¶È©óÁöÑË®≠Ë®àÊèê‰æõË≥áË®äÁöÑ‰∏ÄÈ†ÖÈáçË¶Å‰ªªÂãô„ÄÇÁèæÊúâÁöÑÂ≠êÁæ§ÂàÜÊûêÊñπÊ≥ï‰∏ªË¶ÅÈõÜ‰∏≠ÊñºÈö®Ê©üÂ∞çÁÖßË©¶È©ó (RCT)ÔºåÂÖ∂‰∏≠Ê≤ªÁôÇÂàÜÈÖçÊòØÈö®Ê©üÁöÑ„ÄÇÊ≠§Â§ñÔºåRCT ÁöÑÊÇ£ËÄÖÁæ§È´îÈÄöÂ∏∏ÂèóÂà∞ÊàêÊú¨ÁöÑÈôêÂà∂Ôºå‰∏îÁÑ°Ê≥ï‰ª£Ë°®Âú®ÁèæÂØ¶‰∏ñÁïåËá®Â∫äÂØ¶Âãô‰∏≠ÂèØËÉΩÊé•ÂèóÊ≤ªÁôÇÁöÑÊÇ£ËÄÖÁï∞Ë≥™ÊÄß„ÄÇÂõ†Ê≠§ÔºåÁï∂ÊáâÁî®ÊñºËßÄÂØüÊÄßÁ†îÁ©∂ÊôÇÔºåÊ≠§È°ûÊñπÊ≥ïÊúÉÂõ†Ê≤ªÁôÇÁöÑÈùûÈö®Ê©üÂåñËÄåÁî¢ÁîüÈ°ØËëóÁöÑÁµ±Ë®àÂÅèÂ∑Æ„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÂºïÂÖ•‰∫Ü‰∏ÄÁ®ÆÊñ∞ÁöÑ„ÄÅÁµêÊûúÂ∞éÂêëÁöÑÊñπÊ≥ïÔºåÁî®ÊñºË≠òÂà•ËßÄÂØüÊÄßÁ†îÁ©∂‰∏≠ÁöÑÊ≤ªÁôÇÂèçÊáâÂ≠êÁæ§„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÊòØÂ∞áÊØèÂÄãÊÇ£ËÄÖÂàÜÈÖçÂà∞‰∏ÄÂÄãÂ≠êÁæ§ÔºåË©≤Â≠êÁæ§ËàáÂÖ©ÂÄã‰∫ã‰ª∂ÁôºÁîüÊôÇÈñìÂàÜÈÖçÁõ∏ÈóúÔºö‰∏ÄÂÄãÂú®Ê≤ªÁôÇ‰∏ãÔºåÂè¶‰∏ÄÂÄãÂú®Â∞çÁÖßÊ©üÂà∂‰∏ã„ÄÇÂõ†Ê≠§ÔºåÂÆÉ‰ªãÊñºÂÄãÂà•ÂåñÂíåÂπ≥ÂùáÊ≤ªÁôÇÊïàÊûú‰º∞Ë®à‰πãÈñì„ÄÇÊàëÂÄëÊ®°ÂûãÁöÑÂÅáË®≠Â∞éËá¥ÈÄöÈÅéÈÄÜÂêëÂÇæÂêëÂä†Ê¨äÂ∞ç‰æÜËá™Ê≤ªÁôÇÈùûÈö®Ê©üÂåñÁöÑÁµ±Ë®àÂÅèÂ∑ÆÈÄ≤Ë°åÁ∞°ÂñÆÊ†°Ê≠£„ÄÇÂú®ÂØ¶È©ó‰∏≠ÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÂú®Èö®Ê©üÂíåËßÄÂØüÊÄßÊ≤ªÁôÇÊ©üÂà∂‰∏≠ÈÉΩÈ°ØËëóÂÑ™ÊñºÁï∂ÂâçÊúÄÂÖàÈÄ≤ÁöÑÁµêÊûúÂ∞éÂêëÂ≠êÁæ§ÂàÜÊûêÊñπÊ≥ï„ÄÇ

##### **Combining Diverse Information for Coordinated Action: Stochastic Bandit Algorithms for Heterogeneous Agents**
2408.03405v1 by Lucia Gordon, Esther Rolf, Milind Tambe

Stochastic multi-agent multi-armed bandits typically assume that the rewards
from each arm follow a fixed distribution, regardless of which agent pulls the
arm. However, in many real-world settings, rewards can depend on the
sensitivity of each agent to their environment. In medical screening, disease
detection rates can vary by test type; in preference matching, rewards can
depend on user preferences; and in environmental sensing, observation quality
can vary across sensors. Since past work does not specify how to allocate
agents of heterogeneous but known sensitivity of these types in a stochastic
bandit setting, we introduce a UCB-style algorithm, Min-Width, which aggregates
information from diverse agents. In doing so, we address the joint challenges
of (i) aggregating the rewards, which follow different distributions for each
agent-arm pair, and (ii) coordinating the assignments of agents to arms.
Min-Width facilitates efficient collaboration among heterogeneous agents,
exploiting the known structure in the agents' reward functions to weight their
rewards accordingly. We analyze the regret of Min-Width and conduct
pseudo-synthetic and fully synthetic experiments to study the performance of
different levels of information sharing. Our results confirm that the gains to
modeling agent heterogeneity tend to be greater when the sensitivities are more
varied across agents, while combining more information does not always improve
performance.

ÊëòË¶ÅÔºöÈö®Ê©üÂ§öÊô∫ËÉΩÈ´îÂ§öËáÇË≥≠ÂæíÈÄöÂ∏∏ÂÅáË®≠ÊØèÂÄãÊâãËáÇÁöÑÂõûÂ†±ÈÅµÂæ™Âõ∫ÂÆöÂàÜ‰ΩàÔºåÁÑ°Ë´ñÂì™ÂÄãÊô∫ËÉΩÈ´îÊãâÂãïÊâãËáÇ„ÄÇÁÑ∂ËÄåÔºåÂú®Ë®±Â§öÁúüÂØ¶‰∏ñÁïåË®≠ÂÆö‰∏≠ÔºåÂõûÂ†±ÂèØËÉΩÂèñÊ±∫ÊñºÊØèÂÄãÊô∫ËÉΩÈ´îÂ∞çÂÖ∂Áí∞Â¢ÉÁöÑÊïèÊÑüÂ∫¶„ÄÇÂú®ÈÜ´Â≠∏ÁØ©Ê™¢‰∏≠ÔºåÁñæÁóÖÊ™¢Ê∏¨ÁéáÊúÉÂõ†Ê∏¨Ë©¶È°ûÂûãËÄåÁï∞ÔºõÂú®ÂÅèÂ•ΩÂåπÈÖç‰∏≠ÔºåÂõûÂ†±ÂèØËÉΩÂèñÊ±∫Êñº‰ΩøÁî®ËÄÖÂÅèÂ•ΩÔºõÂú®Áí∞Â¢ÉÊÑüÊ∏¨‰∏≠ÔºåËßÄÂØüÂìÅË≥™ÂèØËÉΩÂõ†ÊÑüÊ∏¨Âô®ËÄåÁï∞„ÄÇÁî±ÊñºÈÅéÂéªÁöÑÂ∑•‰ΩúÊú™Ë™™ÊòéÂ¶Ç‰ΩïÈÖçÁΩÆÈÄô‰∫õÈ°ûÂûãÁï∞Ë≥™‰ΩÜÂ∑≤Áü•ÊïèÊÑüÂ∫¶ÁöÑÊô∫ËÉΩÈ´îÂú®Èö®Ê©üË≥≠ÂæíË®≠ÂÆö‰∏≠ÔºåÊàëÂÄëÂºïÂÖ•‰∏ÄÁ®Æ UCB È¢®Ê†ºÊºîÁÆóÊ≥ïÔºåMin-WidthÔºåÂÆÉÊúÉÂΩôÁ∏Ω‰æÜËá™‰∏çÂêåÊô∫ËÉΩÈ´îÁöÑË≥áË®ä„ÄÇÂú®ÈÄôÊ®£ÂÅöÁöÑÈÅéÁ®ã‰∏≠ÔºåÊàëÂÄëËß£Ê±∫‰∫Ü (i) ÂΩôÁ∏ΩÂõûÂ†±ÁöÑÂÖ±ÂêåÊåëÊà∞ÔºåÈÄô‰∫õÂõûÂ†±ÈÅµÂæ™ÊØèÂÄãÊô∫ËÉΩÈ´îÊâãËáÇÈÖçÂ∞çÁöÑ‰∏çÂêåÂàÜ‰ΩàÔºå‰ª•Âèä (ii) ÂçîË™øÂ∞áÊô∫ËÉΩÈ´îÊåáÂÆöÁµ¶ÊâãËáÇ„ÄÇMin-Width ‰øÉÈÄ≤Áï∞Ë≥™Êô∫ËÉΩÈ´î‰πãÈñìÁöÑÊúâÊïàÂçî‰ΩúÔºåÂà©Áî®Êô∫ËÉΩÈ´îÂõûÂ†±ÂáΩÊï∏‰∏≠ÁöÑÂ∑≤Áü•ÁµêÊßã‰æÜÈÅ©Áï∂Âú∞Âä†Ê¨äÂÖ∂ÂõûÂ†±„ÄÇÊàëÂÄëÂàÜÊûê Min-Width ÁöÑÈÅ∫ÊÜæÔºå‰∏¶ÈÄ≤Ë°åÂÅΩÂêàÊàêÂíåÂÆåÂÖ®ÂêàÊàêÂØ¶È©ó‰æÜÁ†îÁ©∂‰∏çÂêåÂ±§Á¥öË≥áË®äÂÖ±‰∫´ÁöÑÊïàËÉΩ„ÄÇÊàëÂÄëÁöÑÁµêÊûúË≠âÂØ¶ÔºåÁï∂ÊïèÊÑüÂ∫¶Âú®‰∏çÂêåÊô∫ËÉΩÈ´îÈñìÂ∑ÆÁï∞ËºÉÂ§ßÊôÇÔºåÂ∞çÊô∫ËÉΩÈ´îÁï∞Ë≥™ÊÄßÂª∫Ê®°ÁöÑÊî∂ÁõäÂæÄÂæÄËºÉÈ´òÔºåËÄåÁµêÂêàÊõ¥Â§öË≥áË®ä‰∏¶‰∏çÁ∏ΩÊòØÊúÉÊîπÂñÑÊïàËÉΩ„ÄÇ

##### **MLC-GCN: Multi-Level Generated Connectome Based GCN for AD Analysis**
2408.03358v1 by Wenqi Zhu, Yinghua Fu, Ze Wang

Alzheimer's Disease (AD) is a currently incurable neurodegeneartive disease.
Accurately detecting AD, especially in the early stage, represents a high
research priority. AD is characterized by progressive cognitive impairments
that are related to alterations in brain functional connectivity (FC). Based on
this association, many studies have been published over the decades using FC
and machine learning to differentiate AD from healthy aging. The most recent
development in this detection method highlights the use of graph neural network
(GNN) as the brain functionality analysis. In this paper, we proposed a stack
of spatio-temporal feature extraction and graph generation based AD
classification model using resting state fMRI. The proposed multi-level
generated connectome (MLC) based graph convolutional network (GCN) (MLC-GCN)
contains a multi-graph generation block and a GCN prediction block. The
multi-graph generation block consists of a hierarchy of spatio-temporal feature
extraction layers for extracting spatio-temporal rsfMRI features at different
depths and building the corresponding connectomes. The GCN prediction block
takes the learned multi-level connectomes to build and optimize GCNs at each
level and concatenates the learned graphical features as the final predicting
features for AD classification. Through independent cohort validations, MLC-GCN
shows better performance for differentiating MCI, AD, and normal aging than
state-of-art GCN and rsfMRI based AD classifiers. The proposed MLC-GCN also
showed high explainability in terms of learning clinically reasonable
connectome node and connectivity features from two independent datasets. While
we only tested MLC-GCN on AD, the basic rsfMRI-based multi-level learned GCN
based outcome prediction strategy is valid for other diseases or clinical
outcomes.

ÊëòË¶ÅÔºöÈòøËå≤Êµ∑ÈªòÁóá (AD) ÊòØ‰∏ÄÁ®ÆÁõÆÂâçÁÑ°Ê≥ïÊ≤ªÁôíÁöÑÁ•ûÁ∂ìÈÄÄÂåñÊÄßÁñæÁóÖ„ÄÇ
Ê∫ñÁ¢∫Âú∞ÂÅµÊ∏¨ ADÔºåÁâπÂà•ÊòØÂú®Êó©ÊúüÈöéÊÆµÔºå‰ª£Ë°®‰∏ÄÈ†ÖÈ´òÂ∫¶ÁöÑÁ†îÁ©∂ÂÑ™ÂÖà‰∫ãÈ†Ö„ÄÇAD ÁöÑÁâπÂæµÊòØÊúÉÈÄêÊº∏Ë™çÁü•ÂäüËÉΩÂèóÊêçÔºåÈÄôËàáËÖ¶ÈÉ®ÂäüËÉΩÈÄ£Êé•ÊÄß (FC) ÁöÑÊîπËÆäÊúâÈóú„ÄÇÂü∫ÊñºÈÄôÁ®ÆÈóúËÅØÔºåÂú®ÈÅéÂéªÁöÑÊï∏ÂçÅÂπ¥‰∏≠ÔºåË®±Â§öÁ†îÁ©∂Â∑≤‰ΩøÁî® FC ÂíåÊ©üÂô®Â≠∏Áøí‰æÜÂçÄÂàÜ AD ÂíåÂÅ•Â∫∑ËÄÅÂåñ„ÄÇÈÄôÁ®ÆÂÅµÊ∏¨ÊñπÊ≥ïÁöÑÊúÄÊñ∞ÁôºÂ±ïÔºåÁ™ÅÈ°Ø‰∫Ü‰ΩøÁî®ÂúñÁ•ûÁ∂ìÁ∂≤Ë∑Ø (GNN) ‰ΩúÁÇ∫ËÖ¶ÈÉ®ÂäüËÉΩÂàÜÊûê„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂ†ÜÁñäÁöÑÊôÇÁ©∫ÁâπÂæµËêÉÂèñÂíåÂúñÂΩ¢ÁîüÊàêÔºåÂü∫Êñº AD ÂàÜÈ°ûÊ®°ÂûãÔºå‰ΩøÁî®ÈùúÊ≠¢ÁãÄÊÖã fMRI„ÄÇÊâÄÊèêÂá∫ÁöÑÂ§öÂ±§Á¥öÁîüÊàêÈÄ£Êé•ÁµÑ (MLC) Âü∫ÊñºÂúñÂΩ¢Âç∑Á©çÁ∂≤Ë∑Ø (GCN) (MLC-GCN) ÂåÖÂê´‰∏ÄÂÄãÂ§öÂúñÂΩ¢ÁîüÊàêÂçÄÂ°äÂíå‰∏ÄÂÄã GCN È†êÊ∏¨ÂçÄÂ°ä„ÄÇÂ§öÂúñÂΩ¢ÁîüÊàêÂçÄÂ°äÂåÖÂê´‰∏ÄÂÄãÊôÇÁ©∫ÁâπÂæµËêÉÂèñÂ±§ÁöÑÈöéÂ±§ÔºåÁî®ÊñºËêÉÂèñ‰∏çÂêåÊ∑±Â∫¶‰∏ãÁöÑÊôÇÁ©∫ rsfMRI ÁâπÂæµÔºå‰∏¶Âª∫Á´ãÂ∞çÊáâÁöÑÈÄ£Êé•ÁµÑ„ÄÇGCN È†êÊ∏¨ÂçÄÂ°äÊé°Áî®Â∑≤Â≠∏ÁøíÁöÑÂ§öÂ±§Á¥öÈÄ£Êé•ÁµÑÔºåÂú®ÊØèÂÄãÂ±§Á¥öÂª∫Á´ã‰∏¶ÊúÄ‰Ω≥Âåñ GCNÔºå‰∏¶Â∞áÂ∑≤Â≠∏ÁøíÁöÑÂúñÂΩ¢ÁâπÂæµ‰∏≤ËÅØÊàêÁî®Êñº AD ÂàÜÈ°ûÁöÑÊúÄÁµÇÈ†êÊ∏¨ÁâπÂæµ„ÄÇÈÄèÈÅéÁç®Á´ãÁöÑÁæ§ÁµÑÈ©óË≠âÔºåMLC-GCN Âú®ÂçÄÂàÜ MCI„ÄÅAD ÂíåÊ≠£Â∏∏ËÄÅÂåñÊñπÈù¢ÔºåË°®ÁèæÂÑ™ÊñºÊúÄÂÖàÈÄ≤ÁöÑ GCN ÂíåÂü∫Êñº rsfMRI ÁöÑ AD ÂàÜÈ°ûÂô®„ÄÇÊâÄÊèêÂá∫ÁöÑ MLC-GCN ‰πüÂú®ÂæûÂÖ©ÂÄãÁç®Á´ãÁöÑË≥áÊñôÈõÜ‰∏≠Â≠∏ÁøíËá®Â∫ä‰∏äÂêàÁêÜÁöÑÈÄ£Êé•ÁµÑÁØÄÈªûÂíåÈÄ£Êé•ÁâπÂæµÊñπÈù¢ÔºåË°®ÁèæÂá∫È´òÂ∫¶ÁöÑÂèØËß£ÈáãÊÄß„ÄÇÈõñÁÑ∂ÊàëÂÄëÂè™Âú® AD ‰∏äÊ∏¨Ë©¶ MLC-GCNÔºå‰ΩÜÂü∫Êú¨ÁöÑÂü∫Êñº rsfMRI ÁöÑÂ§öÂ±§Á¥öÂ≠∏Áøí GCN Âü∫ÊñºÁµêÊûúÈ†êÊ∏¨Á≠ñÁï•ÔºåÂ∞çÂÖ∂‰ªñÁñæÁóÖÊàñËá®Â∫äÁµêÊûúÊúâÊïà„ÄÇ

##### **Personalizing Federated Instrument Segmentation with Visual Trait Priors in Robotic Surgery**
2408.03208v2 by Jialang Xu, Jiacheng Wang, Lequan Yu, Danail Stoyanov, Yueming Jin, Evangelos B. Mazomenos

Personalized federated learning (PFL) for surgical instrument segmentation
(SIS) is a promising approach. It enables multiple clinical sites to
collaboratively train a series of models in privacy, with each model tailored
to the individual distribution of each site. Existing PFL methods rarely
consider the personalization of multi-headed self-attention, and do not account
for appearance diversity and instrument shape similarity, both inherent in
surgical scenes. We thus propose PFedSIS, a novel PFL method with visual trait
priors for SIS, incorporating global-personalized disentanglement (GPD),
appearance-regulation personalized enhancement (APE), and shape-similarity
global enhancement (SGE), to boost SIS performance in each site. GPD represents
the first attempt at head-wise assignment for multi-headed self-attention
personalization. To preserve the unique appearance representation of each site
and gradually leverage the inter-site difference, APE introduces appearance
regulation and provides customized layer-wise aggregation solutions via
hypernetworks for each site's personalized parameters. The mutual shape
information of instruments is maintained and shared via SGE, which enhances the
cross-style shape consistency on the image level and computes the
shape-similarity contribution of each site on the prediction level for updating
the global parameters. PFedSIS outperforms state-of-the-art methods with +1.51%
Dice, +2.11% IoU, -2.79 ASSD, -15.55 HD95 performance gains. The corresponding
code and models will be released at https://github.com/wzjialang/PFedSIS.

ÊëòË¶ÅÔºöÂÄã‰∫∫ÂåñËÅØÈÇ¶Â≠∏Áøí (PFL) Â∞çÊñºÊâãË°ìÂô®Ê¢∞ÂàÜÂâ≤ (SIS) ‰æÜË™™ÊòØ‰∏ÄÁ®ÆÊúâÂâçÊôØÁöÑÊñπÊ≥ï„ÄÇÂÆÉËÉΩËÆìÂ§öÂÄãËá®Â∫äÂú∞ÈªûÂú®Èö±ÁßÅ‰∏≠ÂÖ±ÂêåË®ìÁ∑¥‰∏ÄÁ≥ªÂàóÊ®°ÂûãÔºåÊØèÂÄãÊ®°ÂûãÈÉΩÊ†πÊìöÊØèÂÄãÂú∞ÈªûÁöÑÂÄãÂà•ÂàÜ‰ΩàÈÄ≤Ë°åË™øÊï¥„ÄÇÁèæÊúâÁöÑ PFL ÊñπÊ≥ïÂæàÂ∞ëËÄÉÊÖÆÂ§öÈ†≠Ëá™Ê≥®ÊÑèÂäõÁöÑÂÄã‰∫∫ÂåñÔºåËÄå‰∏îÊ≤íÊúâËÄÉÊÖÆÂ§ñËßÄÂ§öÊ®£ÊÄßÂíåÂô®Ê¢∞ÂΩ¢ÁãÄÁõ∏‰ººÊÄßÔºåÈÄôÂÖ©ÂÄãÁâπÂæµÈÉΩÂ≠òÂú®ÊñºÊâãË°ìÂ†¥ÊôØ‰∏≠„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü PFedSISÔºåÈÄôÊòØ‰∏ÄÁ®ÆÂÖ∑ÊúâË¶ñË¶∫ÁâπÂæµÂÖàÈ©óÁöÑ SIS Êñ∞Âûã PFL ÊñπÊ≥ïÔºåÂÆÉÁµêÂêà‰∫ÜÂÖ®Â±ÄÂÄã‰∫∫ÂåñËß£Á≥æÁ∫è (GPD)„ÄÅÂ§ñËßÄË™øÁØÄÂÄãÊÄßÂåñÂ¢ûÂº∑ (APE) ÂíåÂΩ¢ÁãÄÁõ∏‰ººÊÄßÂÖ®Â±ÄÂ¢ûÂº∑ (SGE)Ôºå‰ª•ÊèêÂçáÊØèÂÄãÂú∞ÈªûÁöÑ SIS ÊïàËÉΩ„ÄÇGPD ‰ª£Ë°®‰∫ÜÂ§öÈ†≠Ëá™Ê≥®ÊÑèÂäõÂÄã‰∫∫Âåñ‰∏≠È†≠ÈÉ®ÂàÜÈÖçÁöÑÈ¶ñÊ¨°ÂòóË©¶„ÄÇÁÇ∫‰∫Ü‰øùÁïôÊØèÂÄãÂú∞ÈªûÁöÑÁç®ÁâπÂ§ñËßÄË°®Á§∫‰∏¶ÈÄêÊº∏Âà©Áî®Âú∞ÈªûÈñìÁöÑÂ∑ÆÁï∞ÔºåAPE ÂºïÂÖ•‰∫ÜÂ§ñËßÄË™øÁØÄÔºå‰∏¶ÈÄöÈÅéË∂ÖÁ∂≤Ë∑ØÁÇ∫ÊØèÂÄãÂú∞ÈªûÁöÑÂÄãÊÄßÂåñÂèÉÊï∏Êèê‰æõÂÆ¢Ë£ΩÂåñÁöÑÂàÜÂ±§ËÅöÂêàËß£Ê±∫ÊñπÊ°à„ÄÇÂô®Ê¢∞ÁöÑÁõ∏‰∫íÂΩ¢ÁãÄË≥áË®äÊúÉÈÄèÈÅé SGE ÈÄ≤Ë°åÁ∂≠Ë≠∑ÂíåÂÖ±‰∫´ÔºåÈÄôÊúÉÂ¢ûÂº∑ÂΩ±ÂÉèÂ±§Á¥ö‰∏äÁöÑË∑®Ê®£ÂºèÂΩ¢ÁãÄ‰∏ÄËá¥ÊÄßÔºå‰∏¶Ë®àÁÆóÊØèÂÄãÂú∞ÈªûÂú®È†êÊ∏¨Â±§Á¥ö‰∏äÁöÑÂΩ¢ÁãÄÁõ∏‰ººÊÄßË≤¢ÁçªÔºå‰ª•Êõ¥Êñ∞ÂÖ®Â±ÄÂèÉÊï∏„ÄÇPFedSIS Âú®È™∞Â≠ê‰øÇÊï∏‰∏äÂÑ™ÊñºÁèæÊúâÊäÄË°ì +1.51%ÔºåIoU ‰∏äÂÑ™ÊñºÁèæÊúâÊäÄË°ì +2.11%ÔºåASSD ‰∏äÂÑ™ÊñºÁèæÊúâÊäÄË°ì -2.79ÔºåHD95 ÊïàËÉΩÂ¢ûÁõä‰∏äÂÑ™ÊñºÁèæÊúâÊäÄË°ì -15.55„ÄÇÂ∞çÊáâÁöÑÁ®ãÂºèÁ¢ºÂíåÊ®°ÂûãÂ∞áÂú® https://github.com/wzjialang/PFedSIS ÁôºÂ∏É„ÄÇ

##### **The Use of Large Language Models (LLM) for Cyber Threat Intelligence (CTI) in Cybercrime Forums**
2408.03354v2 by Vanessa Clairoux-Trepanier, Isa-May Beauchamp, Estelle Ruellan, Masarah Paquet-Clouston, Serge-Olivier Paquette, Eric Clay

Large language models (LLMs) can be used to analyze cyber threat intelligence
(CTI) data from cybercrime forums, which contain extensive information and key
discussions about emerging cyber threats. However, to date, the level of
accuracy and efficiency of LLMs for such critical tasks has yet to be
thoroughly evaluated. Hence, this study assesses the accuracy of an LLM system
built on the OpenAI GPT-3.5-turbo model [7] to extract CTI information. To do
so, a random sample of 500 daily conversations from three cybercrime forums,
XSS, Exploit_in, and RAMP, was extracted, and the LLM system was instructed to
summarize the conversations and code 10 key CTI variables, such as whether a
large organization and/or a critical infrastructure is being targeted. Then,
two coders reviewed each conversation and evaluated whether the information
extracted by the LLM was accurate. The LLM system performed strikingly well,
with an average accuracy score of 98%. Various ways to enhance the model were
uncovered, such as the need to help the LLM distinguish between stories and
past events, as well as being careful with verb tenses in prompts.
Nevertheless, the results of this study highlight the efficiency and relevance
of using LLMs for cyber threat intelligence.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂèØÁî®ÊñºÂàÜÊûêÁ∂≤Ë∑ØÁäØÁΩ™Ë´ñÂ£á‰∏≠ÁöÑÁ∂≤Ë∑ØÂ®ÅËÑÖÊÉÖÂ†± (CTI) Ë≥áÊñôÔºåÂÖ∂‰∏≠ÂåÖÂê´ÊúâÈóúÊñ∞ËààÁ∂≤Ë∑ØÂ®ÅËÑÖÁöÑË±êÂØåË≥áË®äÂíåÈóúÈçµË®éË´ñ„ÄÇÁÑ∂ËÄåÔºåÂà∞ÁõÆÂâçÁÇ∫Ê≠¢ÔºåLLM Â∞çÊ≠§È°ûÈóúÈçµ‰ªªÂãôÁöÑÊ∫ñÁ¢∫ÊÄßÂíåÊïàÁéáÂ∞öÊú™ÂæóÂà∞ÂæπÂ∫ïË©ï‰º∞„ÄÇÂõ†Ê≠§ÔºåÊú¨Á†îÁ©∂Ë©ï‰º∞‰∫ÜÂª∫Á´ãÂú® OpenAI GPT-3.5-turbo Ê®°Âûã [7] ‰∏äÁöÑ LLM Á≥ªÁµ±ÊèêÂèñ CTI Ë≥áË®äÁöÑÊ∫ñÁ¢∫ÊÄß„ÄÇÁÇ∫Ê≠§ÔºåÂæû‰∏âÂÄãÁ∂≤Ë∑ØÁäØÁΩ™Ë´ñÂ£á XSS„ÄÅExploit_in Âíå RAMP ‰∏≠Èö®Ê©üÊäΩÂèñ‰∫Ü 500 ÂÄãÊØèÊó•Â∞çË©±Ôºå‰∏¶ÊåáÁ§∫ LLM Á≥ªÁµ±Á∏ΩÁµêÂ∞çË©±‰∏¶Á∑®Á¢º 10 ÂÄãÈóúÈçµ CTI ËÆäÊï∏Ôºå‰æãÂ¶ÇÊòØÂê¶ÈáùÂ∞çÂ§ßÂûãÁµÑÁπîÂíå/ÊàñÈóúÈçµÂü∫Á§éË®≠ÊñΩ„ÄÇÁÑ∂ÂæåÔºåÂÖ©ÂÄãÁ∑®Á¢ºÂô®Ê™¢Èñ±ÊØèÂÄãÂ∞çË©±‰∏¶Ë©ï‰º∞ LLM ÊèêÂèñÁöÑË≥áË®äÊòØÂê¶Ê∫ñÁ¢∫„ÄÇLLM Á≥ªÁµ±Ë°®ÁèæÂá∫Ëâ≤ÔºåÂπ≥ÂùáÊ∫ñÁ¢∫Â∫¶ÂàÜÊï∏ÁÇ∫ 98%„ÄÇÁôºÁèæ‰∫ÜÂ¢ûÂº∑Ê®°ÂûãÁöÑÂêÑÁ®ÆÊñπÊ≥ïÔºå‰æãÂ¶ÇÈúÄË¶ÅÂπ´Âä© LLM ÂçÄÂàÜÊïÖ‰∫ãÂíåÈÅéÂéª‰∫ã‰ª∂Ôºå‰ª•ÂèäÂú®ÊèêÁ§∫‰∏≠Â∞èÂøÉ‰ΩøÁî®ÊôÇÊÖã„ÄÇÂÑòÁÆ°Â¶ÇÊ≠§ÔºåÊú¨Á†îÁ©∂ÁöÑÁµêÊûúÁ™ÅÈ°Ø‰∫Ü‰ΩøÁî® LLM ÈÄ≤Ë°åÁ∂≤Ë∑ØÂ®ÅËÑÖÊÉÖÂ†±ÁöÑÊïàÁéáÂíåÁõ∏ÈóúÊÄß„ÄÇ

##### **VizECGNet: Visual ECG Image Network for Cardiovascular Diseases Classification with Multi-Modal Training and Knowledge Distillation**
2408.02888v1 by Ju-Hyeon Nam, Seo-Hyung Park, Su Jung Kim, Sang-Chul Lee

An electrocardiogram (ECG) captures the heart's electrical signal to assess
various heart conditions. In practice, ECG data is stored as either digitized
signals or printed images. Despite the emergence of numerous deep learning
models for digitized signals, many hospitals prefer image storage due to cost
considerations. Recognizing the unavailability of raw ECG signals in many
clinical settings, we propose VizECGNet, which uses only printed ECG graphics
to determine the prognosis of multiple cardiovascular diseases. During
training, cross-modal attention modules (CMAM) are used to integrate
information from two modalities - image and signal, while self-modality
attention modules (SMAM) capture inherent long-range dependencies in ECG data
of each modality. Additionally, we utilize knowledge distillation to improve
the similarity between two distinct predictions from each modality stream. This
innovative multi-modal deep learning architecture enables the utilization of
only ECG images during inference. VizECGNet with image input achieves higher
performance in precision, recall, and F1-Score compared to signal-based ECG
classification models, with improvements of 3.50%, 8.21%, and 7.38%,
respectively.

ÊëòË¶ÅÔºöÂøÉÈõªÂúñ (ECG) ÂèØÊì∑ÂèñÂøÉËáüÁöÑÈõªÊ∞£Ë®äËôüÔºåÁî®ÊñºË©ï‰º∞ÂêÑÁ®ÆÂøÉËáüÁñæÁóÖ„ÄÇÂØ¶Èöõ‰∏äÔºåÂøÉÈõªÂúñË≥áÊñôÂÑ≤Â≠òÂú®Êï∏‰ΩçÂåñË®äËôüÊàñÂàóÂç∞ÂΩ±ÂÉè‰∏≠„ÄÇÂÑòÁÆ°Â∑≤Âá∫ÁèæË®±Â§öÈáùÂ∞çÊï∏‰ΩçÂåñË®äËôüÁöÑÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÔºå‰ΩÜË®±Â§öÈÜ´Èô¢Âü∫ÊñºÊàêÊú¨ËÄÉÈáèÔºå‰ªçÂÅèÂ•ΩÂΩ±ÂÉèÂÑ≤Â≠ò„ÄÇÈëëÊñºË®±Â§öËá®Â∫äÁí∞Â¢É‰∏≠Áº∫‰πèÂéüÂßãÂøÉÈõªÂúñË®äËôüÔºåÊàëÂÄëÊèêÂá∫ VizECGNetÔºåÂÆÉÂÉÖ‰ΩøÁî®ÂàóÂç∞ÁöÑÂøÉÈõªÂúñÂúñÂΩ¢‰æÜÂà§Êñ∑Â§öÁ®ÆÂøÉË°ÄÁÆ°ÁñæÁóÖÁöÑÈ†êÂæå„ÄÇÂú®Ë®ìÁ∑¥ÊúüÈñìÔºåË∑®Ê®°ÊÖãÊ≥®ÊÑèÂäõÊ®°ÁµÑ (CMAM) Áî®ÊñºÊï¥Âêà‰æÜËá™ÂÖ©Á®ÆÊ®°ÊÖãÔºàÂΩ±ÂÉèÂíåË®äËôüÔºâÁöÑË≥áË®äÔºåËÄåËá™ÊàëÊ®°ÊÖãÊ≥®ÊÑèÂäõÊ®°ÁµÑ (SMAM) ÂâáÊì∑ÂèñÊØèÂÄãÊ®°ÊÖã‰∏≠ÂøÉÈõªÂúñË≥áÊñô‰∏≠Âõ∫ÊúâÁöÑÈï∑Á®ã‰æùË≥¥ÊÄß„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂà©Áî®Áü•Ë≠òËêÉÂèñ‰æÜÊîπÂñÑÊØèÂÄãÊ®°ÊÖã‰∏≤ÊµÅ‰∏≠ÂÖ©ÂÄã‰∏çÂêåÈ†êÊ∏¨‰πãÈñìÁöÑÁõ∏‰ººÊÄß„ÄÇÈÄôÁ®ÆÂâµÊñ∞ÁöÑÂ§öÊ®°ÊÖãÊ∑±Â∫¶Â≠∏ÁøíÊû∂ÊßãÔºåÂèØ‰ª•Âú®Êé®Ë´ñÊúüÈñìÂÉÖ‰ΩøÁî®ÂøÉÈõªÂúñÂΩ±ÂÉè„ÄÇËàáÂü∫ÊñºË®äËôüÁöÑÂøÉÈõªÂúñÂàÜÈ°ûÊ®°ÂûãÁõ∏ÊØîÔºåËº∏ÂÖ•ÂΩ±ÂÉèÁöÑ VizECGNet Âú®Á≤æÊ∫ñÂ∫¶„ÄÅÂè¨ÂõûÁéáÂíå F1 ÂàÜÊï∏ÊñπÈù¢Áç≤ÂæóÊõ¥È´òÁöÑÊïàËÉΩÔºåÂàÜÂà•ÊèêÂçá‰∫Ü 3.50%„ÄÅ8.21% Âíå 7.38%„ÄÇ

##### **VisionUnite: A Vision-Language Foundation Model for Ophthalmology Enhanced with Clinical Knowledge**
2408.02865v1 by Zihan Li, Diping Song, Zefeng Yang, Deming Wang, Fei Li, Xiulan Zhang, Paul E. Kinahan, Yu Qiao

The need for improved diagnostic methods in ophthalmology is acute,
especially in the less developed regions with limited access to specialists and
advanced equipment. Therefore, we introduce VisionUnite, a novel
vision-language foundation model for ophthalmology enhanced with clinical
knowledge. VisionUnite has been pretrained on an extensive dataset comprising
1.24 million image-text pairs, and further refined using our proposed MMFundus
dataset, which includes 296,379 high-quality fundus image-text pairs and
889,137 simulated doctor-patient dialogue instances. Our experiments indicate
that VisionUnite outperforms existing generative foundation models such as
GPT-4V and Gemini Pro. It also demonstrates diagnostic capabilities comparable
to junior ophthalmologists. VisionUnite performs well in various clinical
scenarios including open-ended multi-disease diagnosis, clinical explanation,
and patient interaction, making it a highly versatile tool for initial
ophthalmic disease screening. VisionUnite can also serve as an educational aid
for junior ophthalmologists, accelerating their acquisition of knowledge
regarding both common and rare ophthalmic conditions. VisionUnite represents a
significant advancement in ophthalmology, with broad implications for
diagnostics, medical education, and understanding of disease mechanisms.

ÊëòË¶ÅÔºöÁúºÁßëË®∫Êñ∑ÊñπÊ≥ïÊîπËâØÁöÑÂøÖË¶ÅÊÄßÂçÅÂàÜËø´ÂàáÔºåÁâπÂà•ÊòØÂú®ËºÉ‰∏çÁôºÈÅîÂú∞ÂçÄÔºåÈÇ£Ë£°Â∞àÁßëÈÜ´Â∏´ÂíåÂÖàÈÄ≤Ë®≠ÂÇôÂèñÂæó‰∏çÊòì„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëÂºïÈÄ≤ VisionUniteÔºå‰∏ÄÁ®ÆÊñ∞Á©éÁöÑË¶ñË¶∫Ë™ûË®ÄÂü∫Á§éÊ®°ÂûãÔºå‰∏¶‰ª•Ëá®Â∫äÁü•Ë≠òÂº∑ÂåñÁúºÁßë„ÄÇVisionUnite Â∑≤Âú®ÂåÖÂê´ 124 Ëê¨ÂºµÂΩ±ÂÉèÊñáÂ≠óÂ∞çÁöÑÂ§ßÂûãË≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÈ†êË®ìÁ∑¥Ôºå‰∏¶ÈÄèÈÅéÊàëÂÄëÂª∫Ë≠∞ÁöÑ MMFundus Ë≥áÊñôÈõÜÈÄ≤‰∏ÄÊ≠•ÂÑ™ÂåñÔºåÂÖ∂‰∏≠ÂåÖÂê´ 296,379 ÂºµÈ´òÂìÅË≥™ÁúºÂ∫ïÂΩ±ÂÉèÊñáÂ≠óÂ∞çÂíå 889,137 ÂÄãÊ®°Êì¨ÁöÑÈÜ´Â∏´ÁóÖÊÇ£Â∞çË©±ÂØ¶‰æã„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÊåáÂá∫ VisionUnite ÂÑ™ÊñºÁèæÊúâÁöÑÁîüÊàêÂºèÂü∫Á§éÊ®°ÂûãÔºå‰æãÂ¶Ç GPT-4V Âíå Gemini Pro„ÄÇÂÆÉ‰πüÂ±ïÁèæÂá∫ËàáÂàùÈöéÁúºÁßëÈÜ´Â∏´Áõ∏Áï∂ÁöÑË®∫Êñ∑ËÉΩÂäõ„ÄÇVisionUnite Âú®ÂêÑÁ®ÆËá®Â∫äÊÉÖÂ¢É‰∏≠Ë°®ÁèæËâØÂ•ΩÔºåÂåÖÊã¨ÈñãÊîæÂºèÂ§öÁñæÁóÖË®∫Êñ∑„ÄÅËá®Â∫äË™™ÊòéÂíåÁóÖÊÇ£‰∫íÂãïÔºå‰ΩøÂÖ∂ÊàêÁÇ∫ÂàùÊ≠•ÁúºÁßëÁñæÁóÖÁØ©Ê™¢ÁöÑÈ´òÂ∫¶Â§öÂäüËÉΩÂ∑•ÂÖ∑„ÄÇVisionUnite ‰πüÂèØÁî®‰ΩúÂàùÈöéÁúºÁßëÈÜ´Â∏´ÁöÑÊïôËÇ≤ËºîÂä©Â∑•ÂÖ∑ÔºåÂä†ÈÄü‰ªñÂÄëÂ∞çÊñºÂ∏∏Ë¶ãÂíåÁΩïË¶ãÁúºÁßëÁñæÁóÖÁü•Ë≠òÁöÑÁøíÂæó„ÄÇVisionUnite ‰ª£Ë°®‰∫ÜÁúºÁßëÁöÑÈáçÂ§ßÈÄ≤Â±ïÔºåÂ∞çË®∫Êñ∑„ÄÅÈÜ´Â≠∏ÊïôËÇ≤ÂíåÁñæÁóÖÊ©üËΩâÁöÑÁêÜËß£ÂÖ∑ÊúâÂª£Ê≥õÁöÑÂΩ±Èüø„ÄÇ

##### **Multistain Pretraining for Slide Representation Learning in Pathology**
2408.02859v1 by Guillaume Jaume, Anurag Vaidya, Andrew Zhang, Andrew H. Song, Richard J. Chen, Sharifa Sahai, Dandan Mo, Emilio Madrigal, Long Phi Le, Faisal Mahmood

Developing self-supervised learning (SSL) models that can learn universal and
transferable representations of H&E gigapixel whole-slide images (WSIs) is
becoming increasingly valuable in computational pathology. These models hold
the potential to advance critical tasks such as few-shot classification, slide
retrieval, and patient stratification. Existing approaches for slide
representation learning extend the principles of SSL from small images (e.g.,
224 x 224 patches) to entire slides, usually by aligning two different
augmentations (or views) of the slide. Yet the resulting representation remains
constrained by the limited clinical and biological diversity of the views.
Instead, we postulate that slides stained with multiple markers, such as
immunohistochemistry, can be used as different views to form a rich
task-agnostic training signal. To this end, we introduce Madeleine, a
multimodal pretraining strategy for slide representation learning. Madeleine is
trained with a dual global-local cross-stain alignment objective on large
cohorts of breast cancer samples (N=4,211 WSIs across five stains) and kidney
transplant samples (N=12,070 WSIs across four stains). We demonstrate the
quality of slide representations learned by Madeleine on various downstream
evaluations, ranging from morphological and molecular classification to
prognostic prediction, comprising 21 tasks using 7,299 WSIs from multiple
medical centers. Code is available at https://github.com/mahmoodlab/MADELEINE.

ÊëòË¶ÅÔºöÈñãÁôºËá™Áõ£Áù£Â≠∏Áøí (SSL) Ê®°ÂûãÔºåÂèØ‰ª•Â≠∏Áøí H&E ÂêâÂÉèÁ¥†ÂÖ®ÂàáÁâáÂΩ±ÂÉè (WSI) ÁöÑÈÄöÁî®‰∏îÂèØËΩâÁßªË°®Á§∫ÔºåÂú®Ë®àÁÆóÁóÖÁêÜÂ≠∏‰∏≠Ê≠£ËÆäÂæóË∂ä‰æÜË∂äÊúâÂÉπÂÄº„ÄÇÈÄô‰∫õÊ®°ÂûãÊúâÊΩõÂäõÊé®ÈÄ≤ÈóúÈçµ‰ªªÂãôÔºå‰æãÂ¶ÇÂ∞ëÊ¨°ÂàÜÈ°û„ÄÅÂàáÁâáÊ™¢Á¥¢ÂíåÊÇ£ËÄÖÂàÜÂ±§„ÄÇÁèæÊúâÁöÑÂàáÁâáË°®Á§∫Â≠∏ÁøíÊñπÊ≥ïÂ∞á SSL ÁöÑÂéüÁêÜÂæûÂ∞èÂΩ±ÂÉèÔºà‰æãÂ¶Ç 224 x 224 Ë£ú‰∏ÅÔºâÂª∂‰º∏Âà∞Êï¥ÂÄãÂàáÁâáÔºåÈÄöÂ∏∏ÈÄèÈÅéÂ∞çÈΩäÂàáÁâáÁöÑÂÖ©ÂÄã‰∏çÂêåÊì¥Â¢ûÔºàÊàñË¶ñÂúñÔºâ„ÄÇÁÑ∂ËÄåÔºåÁîüÊàêÁöÑË°®Á§∫‰ªçÂèóÂà∞Ë¶ñÂúñÊúâÈôêÁöÑËá®Â∫äÂíåÁîüÁâ©Â§öÊ®£ÊÄßÁöÑÈôêÂà∂„ÄÇÁõ∏ÂèçÔºåÊàëÂÄëÂÅáË®≠‰ΩøÁî®Â§öÁ®ÆÊ®ôË®òÊüìËâ≤ÁöÑÂàáÁâáÔºå‰æãÂ¶ÇÂÖçÁñ´ÁµÑÁπîÂåñÂ≠∏ÊüìËâ≤ÔºåÂèØ‰ª•Áî®‰Ωú‰∏çÂêåÁöÑË¶ñÂúñ‰æÜÂΩ¢ÊàêË±êÂØåÁöÑËàá‰ªªÂãôÁÑ°ÈóúÁöÑË®ìÁ∑¥Ë®äËôü„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄë‰ªãÁ¥π MadeleineÔºå‰∏ÄÁ®ÆÁî®ÊñºÂàáÁâáË°®Á§∫Â≠∏ÁøíÁöÑÂ§öÊ®°ÂºèÈ†êË®ìÁ∑¥Á≠ñÁï•„ÄÇMadeleine ‰ΩøÁî®ÈõôÈáçÂÖ®Â±Ä-Â±ÄÈÉ®Ë∑®ÊüìËâ≤Â∞çÈΩäÁõÆÊ®ôÂú®Â§ßÈáè‰π≥ÁôåÊ®£Êú¨ÔºàN=4,211 ÂÄãÊ©´Ë∑®‰∫îÁ®ÆÊüìËâ≤ÁöÑ WSIÔºâÂíåËÖéËáüÁßªÊ§çÊ®£Êú¨ÔºàN=12,070 ÂÄãÊ©´Ë∑®ÂõõÁ®ÆÊüìËâ≤ÁöÑ WSIÔºâ‰∏äÈÄ≤Ë°åË®ìÁ∑¥„ÄÇÊàëÂÄëÂú®ÂêÑÁ®Æ‰∏ãÊ∏∏Ë©ï‰º∞‰∏≠Â±ïÁ§∫‰∫Ü Madeleine Â≠∏ÁøíÁöÑÂàáÁâáË°®Á§∫ÁöÑÂìÅË≥™ÔºåÂæûÂΩ¢ÊÖãÂíåÂàÜÂ≠êÂàÜÈ°ûÂà∞È†êÂæåÈ†êÊ∏¨ÔºåÂåÖÊã¨‰ΩøÁî®‰æÜËá™Â§öÂÄãÈÜ´ÁôÇ‰∏≠ÂøÉÁöÑ 7,299 ÂÄã WSI ÁöÑ 21 È†Ö‰ªªÂãô„ÄÇÁ®ãÂºèÁ¢ºÂèØÂú® https://github.com/mahmoodlab/MADELEINE ÂèñÂæó„ÄÇ

##### **The Literature Review Network: An Explainable Artificial Intelligence for Systematic Literature Reviews, Meta-analyses, and Method Development**
2408.05239v1 by Joshua Morriss, Tod Brindle, Jessica Bah R√∂sman, Daniel Reibsamen, Andreas Enz

Systematic literature reviews are the highest quality of evidence in
research. However, the review process is hindered by significant resource and
data constraints. The Literature Review Network (LRN) is the first of its kind
explainable AI platform adhering to PRISMA 2020 standards, designed to automate
the entire literature review process. LRN was evaluated in the domain of
surgical glove practices using 3 search strings developed by experts to query
PubMed. A non-expert trained all LRN models. Performance was benchmarked
against an expert manual review. Explainability and performance metrics
assessed LRN's ability to replicate the experts' review. Concordance was
measured with the Jaccard index and confusion matrices. Researchers were
blinded to the other's results until study completion. Overlapping studies were
integrated into an LRN-generated systematic review. LRN models demonstrated
superior classification accuracy without expert training, achieving 84.78% and
85.71% accuracy. The highest performance model achieved high interrater
reliability (k = 0.4953) and explainability metrics, linking 'reduce',
'accident', and 'sharp' with 'double-gloving'. Another LRN model covered 91.51%
of the relevant literature despite diverging from the non-expert's judgments (k
= 0.2174), with the terms 'latex', 'double' (gloves), and 'indication'. LRN
outperformed the manual review (19,920 minutes over 11 months), reducing the
entire process to 288.6 minutes over 5 days. This study demonstrates that
explainable AI does not require expert training to successfully conduct
PRISMA-compliant systematic literature reviews like an expert. LRN summarized
the results of surgical glove studies and identified themes that were nearly
identical to the clinical researchers' findings. Explainable AI can accurately
expedite our understanding of clinical practices, potentially revolutionizing
healthcare research.

ÊëòË¶ÅÔºöÁ≥ªÁµ±ÊÄßÊñáÁçªÂõûÈ°ßÊòØÁ†îÁ©∂‰∏≠Ë≠âÊìöÂìÅË≥™ÊúÄÈ´òÁöÑ„ÄÇÁÑ∂ËÄåÔºåÂõûÈ°ßÈÅéÁ®ãÂèóÂà∞È°ØËëóË≥áÊ∫êÂíåË≥áÊñôÈôêÂà∂ÁöÑÈòªÁ§ô„ÄÇÊñáÁçªÂõûÈ°ßÁ∂≤Ë∑Ø (LRN) ÊòØÁ¨¨‰∏ÄÂÄãÈÅµÂæ™ PRISMA 2020 Ê®ôÊ∫ñÁöÑÂèØËß£Èáã AI Âπ≥Âè∞ÔºåÊó®Âú®Ëá™ÂãïÂåñÊï¥ÂÄãÊñáÁçªÂõûÈ°ßÈÅéÁ®ã„ÄÇLRN Âú®Â§ñÁßëÊâãÂ•óÂØ¶ÂãôÈ†òÂüü‰∏≠ÈÄ≤Ë°åË©ï‰º∞Ôºå‰ΩøÁî®Â∞àÂÆ∂ÈñãÁôºÁöÑ 3 ÂÄãÊêúÂ∞ãÂ≠ó‰∏≤‰æÜÊü•Ë©¢ PubMed„ÄÇÈùûÂ∞àÂÆ∂Ë®ìÁ∑¥ÊâÄÊúâ LRN Ê®°Âûã„ÄÇÊïàËÉΩ‰ª•Â∞àÂÆ∂ÊâãÂãïÂõûÈ°ß‰ΩúÁÇ∫Âü∫Ê∫ñ„ÄÇÂèØËß£ÈáãÊÄßÂíåÊïàËÉΩÊåáÊ®ôË©ï‰º∞ LRN Ë§áË£ΩÂ∞àÂÆ∂ÂõûÈ°ßÁöÑËÉΩÂäõ„ÄÇ‰∏ÄËá¥ÊÄß‰ª• Jaccard ÊåáÊï∏ÂíåÊ∑∑Ê∑ÜÁü©Èô£Ê∏¨Èáè„ÄÇÁ†îÁ©∂‰∫∫Âì°Âú®Á†îÁ©∂ÂÆåÊàêÂâçÂ∞çÂΩºÊ≠§ÁöÑÁµêÊûú‰øùÂØÜ„ÄÇÈáçÁñäÁöÑÁ†îÁ©∂Êï¥ÂêàÂà∞ LRN ÁîüÊàêÁöÑÁ≥ªÁµ±ÊÄßÂõûÈ°ß‰∏≠„ÄÇLRN Ê®°ÂûãÂú®Ê≤íÊúâÂ∞àÂÆ∂Ë®ìÁ∑¥ÁöÑÊÉÖÊ≥Å‰∏ãÂ±ïÁèæÂá∫ÂÑ™Áï∞ÁöÑÂàÜÈ°ûÊ∫ñÁ¢∫ÁéáÔºåÈÅîÂà∞ 84.78% Âíå 85.71% ÁöÑÊ∫ñÁ¢∫Áéá„ÄÇÊïàËÉΩÊúÄÈ´òÁöÑÊ®°ÂûãÈÅîÂà∞‰∫ÜÈ´òË©ïÂàÜËÄÖÈñì‰ø°Ë≥¥Â∫¶ (k = 0.4953) ÂíåÂèØËß£ÈáãÊÄßÊåáÊ®ôÔºåÂ∞á„ÄåÊ∏õÂ∞ë„Äç„ÄÅ„ÄåÊÑèÂ§ñ„ÄçÂíå„ÄåÈä≥Âà©„ÄçËàá„ÄåÈõôÈáçÊà¥ÊâãÂ•ó„ÄçÈÄ£ÁµêÂú®‰∏ÄËµ∑„ÄÇÂè¶‰∏ÄÂÄã LRN Ê®°ÂûãÊ∂µËìã‰∫Ü 91.51% ÁöÑÁõ∏ÈóúÊñáÁçªÔºåÂÑòÁÆ°ËàáÈùûÂ∞àÂÆ∂ÁöÑÂà§Êñ∑‰∏çÂêå (k = 0.2174)Ôºå‰ΩÜÂåÖÂê´‰∫Ü„Äå‰π≥ËÜ†„Äç„ÄÅ„ÄåÈõôÈáç„ÄçÔºàÊâãÂ•óÔºâÂíå„ÄåÈÅ©ÊáâÁóá„ÄçÁ≠âË©ûÂΩô„ÄÇLRN ÂÑ™ÊñºÊâãÂãïÂõûÈ°ßÔºà11 ÂÄãÊúàË∂ÖÈÅé 19,920 ÂàÜÈêòÔºâÔºåÂ∞áÊï¥ÂÄãÈÅéÁ®ãÁ∏ÆÁü≠ÁÇ∫ 5 Â§©Ë∂ÖÈÅé 288.6 ÂàÜÈêò„ÄÇÈÄôÈ†ÖÁ†îÁ©∂È°ØÁ§∫ÔºåÂèØËß£ÈáãÁöÑ AI ‰∏çÈúÄË¶ÅÂ∞àÂÆ∂Ë®ìÁ∑¥Âç≥ÂèØÊàêÂäüÈÄ≤Ë°åÂ∞àÂÆ∂Á≠âÁ¥öÁöÑ PRISMA Áõ∏ÂÆπÁ≥ªÁµ±ÊÄßÊñáÁçªÂõûÈ°ß„ÄÇLRN Á∏ΩÁµê‰∫ÜÂ§ñÁßëÊâãÂ•óÁ†îÁ©∂ÁöÑÁµêÊûúÔºå‰∏¶ÊâæÂá∫ËàáËá®Â∫äÁ†îÁ©∂‰∫∫Âì°ÁôºÁèæÂπæ‰πéÁõ∏ÂêåÁöÑ‰∏ªÈ¢ò„ÄÇÂèØËß£ÈáãÁöÑ AI ÂèØ‰ª•Ê∫ñÁ¢∫Âú∞Âä†Âø´ÊàëÂÄëÂ∞çËá®Â∫äÂØ¶ÂãôÁöÑÁêÜËß£ÔºåÊúâÊΩõÂäõÈù©Êñ∞ÈÜ´ÁôÇ‰øùÂÅ•Á†îÁ©∂„ÄÇ

##### **A Review on Organ Deformation Modeling Approaches for Reliable Surgical Navigation using Augmented Reality**
2408.02713v1 by Zheng Han, Qi Dou

Augmented Reality (AR) holds the potential to revolutionize surgical
procedures by allowing surgeons to visualize critical structures within the
patient's body. This is achieved through superimposing preoperative organ
models onto the actual anatomy. Challenges arise from dynamic deformations of
organs during surgery, making preoperative models inadequate for faithfully
representing intraoperative anatomy. To enable reliable navigation in augmented
surgery, modeling of intraoperative deformation to obtain an accurate alignment
of the preoperative organ model with the intraoperative anatomy is
indispensable. Despite the existence of various methods proposed to model
intraoperative organ deformation, there are still few literature reviews that
systematically categorize and summarize these approaches. This review aims to
fill this gap by providing a comprehensive and technical-oriented overview of
modeling methods for intraoperative organ deformation in augmented reality in
surgery. Through a systematic search and screening process, 112 closely
relevant papers were included in this review. By presenting the current status
of organ deformation modeling methods and their clinical applications, this
review seeks to enhance the understanding of organ deformation modeling in
AR-guided surgery, and discuss the potential topics for future advancements.

ÊëòË¶ÅÔºöÊì¥Â¢ûÂØ¶Â¢É (AR) ÂÖ∑ÊúâÈÄèÈÅéËÆìÂ§ñÁßëÈÜ´ÁîüÂèØË¶ñÂåñÊÇ£ËÄÖÈ´îÂÖßÈóúÈçµÁµêÊßã‰æÜÈù©Êñ∞Â§ñÁßëÊâãË°ìÁ®ãÂ∫èÁöÑÊΩõÂäõ„ÄÇÈÄôÊòØÈÄèÈÅéÂ∞áË°ìÂâçÂô®ÂÆòÊ®°ÂûãÁñäÂä†Âà∞ÂØ¶ÈöõËß£ÂâñÁµêÊßã‰∏ä‰æÜÂØ¶ÁèæÁöÑ„ÄÇÊâãË°ìÈÅéÁ®ã‰∏≠Âô®ÂÆòÁöÑÂãïÊÖãËÆäÂΩ¢Â∏∂‰æÜ‰∫ÜÊåëÊà∞ÔºåÈÄô‰ΩøÂæóË°ìÂâçÊ®°Âûã‰∏çË∂≥‰ª•Âø†ÂØ¶Âú∞ÂëàÁèæË°ì‰∏≠Ëß£ÂâñÁµêÊßã„ÄÇÁÇ∫‰∫ÜÂú®Êì¥Â¢ûÊâãË°ì‰∏≠ÂØ¶ÁèæÂèØÈù†ÁöÑÂ∞éËà™ÔºåÂ∞çË°ì‰∏≠ËÆäÂΩ¢ÈÄ≤Ë°åÂª∫Ê®°‰ª•Áç≤ÂæóË°ìÂâçÂô®ÂÆòÊ®°ÂûãËàáË°ì‰∏≠Ëß£ÂâñÁµêÊßãÁöÑÊ∫ñÁ¢∫Â∞çÈΩäÊòØ‰∏çÂèØÊàñÁº∫ÁöÑ„ÄÇÂÑòÁÆ°Â≠òÂú®ÂêÑÁ®ÆÁî®ÊñºÂª∫Ê®°Ë°ì‰∏≠Âô®ÂÆòËÆäÂΩ¢ÁöÑÊñπÊ≥ïÔºå‰ΩÜÁ≥ªÁµ±Âú∞Â∞çÈÄô‰∫õÊñπÊ≥ïÈÄ≤Ë°åÂàÜÈ°ûÂíåÁ∏ΩÁµêÁöÑÊñáÁçªÂõûÈ°ß‰ªçÁÑ∂ÂæàÂ∞ë„ÄÇÊú¨Á∂úËø∞Êó®Âú®ÈÄöÈÅéÊèê‰æõÂ∞çÊì¥Â¢ûÂØ¶Â¢ÉÊâãË°ì‰∏≠Ë°ì‰∏≠Âô®ÂÆòËÆäÂΩ¢ÁöÑÂª∫Ê®°ÊñπÊ≥ïÁöÑÂÖ®Èù¢‰∏îÊäÄË°ìÂ∞éÂêëÁöÑÊ¶ÇËø∞‰æÜÂ°´Ë£úÈÄô‰∏ÄÁ©∫ÁôΩ„ÄÇÈÄöÈÅéÁ≥ªÁµ±ÁöÑÊêúÂ∞ãÂíåÁØ©ÈÅ∏ÈÅéÁ®ãÔºåÊú¨Á∂úËø∞Á¥çÂÖ•‰∫Ü 112 ÁØáÂØÜÂàáÁõ∏ÈóúÁöÑË´ñÊñá„ÄÇÈÄöÈÅéÂëàÁèæÂô®ÂÆòËÆäÂΩ¢Âª∫Ê®°ÊñπÊ≥ïÁöÑÁèæÁãÄÂèäÂÖ∂Ëá®Â∫äÊáâÁî®ÔºåÊú¨Á∂úËø∞Êó®Âú®Âä†Ê∑±Â∞ç AR ÂºïÂ∞éÊâãË°ì‰∏≠Âô®ÂÆòËÆäÂΩ¢Âª∫Ê®°ÁöÑÁêÜËß£Ôºå‰∏¶Êé¢Ë®éÊú™‰æÜÈÄ≤Â±ïÁöÑÊΩõÂú®‰∏ªÈ°å„ÄÇ

##### **Enhancing Medical Learning and Reasoning Systems: A Boxology-Based Comparative Analysis of Design Patterns**
2408.02709v1 by Chi Him Ng

This study analyzes hybrid AI systems' design patterns and their
effectiveness in clinical decision-making using the boxology framework. It
categorizes and copares various architectures combining machine learning and
rule-based reasoning to provide insights into their structural foundations and
healthcare applications. Addressing two main questions, how to categorize these
systems againts established design patterns and how to extract insights through
comparative analysis, the study uses design patterns from software engineering
to understand and optimize healthcare AI systems. Boxology helps identify
commonalities and create reusable solutions, enhancing these systems'
scalability, reliability, and performance. Five primary architectures are
examined: REML, MLRB, RBML, RMLT, and PERML. Each has unique strengths and
weaknesses, highlighting the need for tailored approaches in clinical tasks.
REML excels in high-accuracy prediction for datasets with limited data; MLRB in
handling large datasets and complex data integration; RBML in explainability
and trustworthiness; RMLT in managing high-dimensional data; and PERML, though
limited in analysis, shows promise in urgent care scenarios. The study
introduces four new patterns, creates five abstract categorization patterns,
and refines those five further to specific systems. These contributions enhance
Boxlogy's taxonomical organization and offer novel approaches to integrating
expert knowledge with machine learning. Boxology's structured, modular apporach
offers significant advantages in developing and analyzing hybrid AI systems,
revealing commonalities, and promoting reusable solutions. In conclusion, this
study underscores hybrid AI systems' crucial role in advancing healthcare and
Boxology's potential to drive further innovation in AI integration, ultimately
improving clinical decision support and patient outcomes.

ÊëòË¶ÅÔºöÊú¨Á†îÁ©∂‰ΩøÁî®ÁõíÂ≠êÂ≠∏Ê°ÜÊû∂ÂàÜÊûêÊ∑∑Âêà‰∫∫Â∑•Êô∫ÊÖßÁ≥ªÁµ±ÁöÑË®≠Ë®àÊ®°ÂºèÂèäÂÖ∂Âú®Ëá®Â∫äÊ±∫Á≠ñ‰∏≠ÁöÑÊúâÊïàÊÄß„ÄÇÂÆÉÂàÜÈ°û‰∏¶ÊØîËºÉÁµêÂêàÊ©üÂô®Â≠∏ÁøíÂíåÂü∫ÊñºË¶èÂâáÁöÑÊé®ÁêÜÁöÑÂêÑÁ®ÆÊû∂ÊßãÔºå‰ª•Ê∑±ÂÖ•‰∫ÜËß£ÂÖ∂ÁµêÊßãÂü∫Á§éÂíåÈÜ´ÁôÇ‰øùÂÅ•ÊáâÁî®„ÄÇÈáùÂ∞çÂÖ©ÂÄã‰∏ªË¶ÅÂïèÈ°åÔºåÂ¶Ç‰ΩïÊ†πÊìöÊó¢ÂÆöÁöÑË®≠Ë®àÊ®°ÂºèÂ∞çÈÄô‰∫õÁ≥ªÁµ±ÈÄ≤Ë°åÂàÜÈ°ûÔºå‰ª•ÂèäÂ¶Ç‰ΩïÈÄöÈÅéÊØîËºÉÂàÜÊûêÊèêÂèñË¶ãËß£ÔºåÊú¨Á†îÁ©∂‰ΩøÁî®ËªüÈ´îÂ∑•Á®ã‰∏≠ÁöÑË®≠Ë®àÊ®°Âºè‰æÜ‰∫ÜËß£ÂíåÂÑ™ÂåñÈÜ´ÁôÇ‰øùÂÅ•‰∫∫Â∑•Êô∫ÊÖßÁ≥ªÁµ±„ÄÇÁõíÂ≠êÂ≠∏ÊúâÂä©ÊñºË≠òÂà•ÂÖ±ÊÄß‰∏¶Âª∫Á´ãÂèØÈáçË§á‰ΩøÁî®ÁöÑËß£Ê±∫ÊñπÊ°àÔºåÂæûËÄåÂ¢ûÂº∑ÈÄô‰∫õÁ≥ªÁµ±ÁöÑÂèØÊì¥ÂÖÖÊÄß„ÄÅÂèØÈù†ÊÄßÂíåÊïàËÉΩ„ÄÇÊ™¢Êü•‰∫Ü‰∫îÁ®Æ‰∏ªË¶ÅÁöÑÊû∂ÊßãÔºöREML„ÄÅMLRB„ÄÅRBML„ÄÅRMLT Âíå PERML„ÄÇÊØèÁ®ÆÊû∂ÊßãÈÉΩÊúâÁç®ÁâπÁöÑÂÑ™Áº∫ÈªûÔºåÂº∑Ë™ø‰∫ÜÂú®Ëá®Â∫ä‰ªªÂãô‰∏≠ÈúÄË¶ÅÈáèË∫´ÊâìÈÄ†ÁöÑÊñπÊ≥ï„ÄÇREML Âú®Ë≥áÊñôÊúâÈôêÁöÑË≥áÊñôÈõÜ‰∏≠Ë°®ÁèæÂá∫È´òÁ≤æÂ∫¶ÁöÑÈ†êÊ∏¨ÔºõMLRB Âú®ËôïÁêÜÂ§ßÂûãË≥áÊñôÈõÜÂíåË§áÈõúË≥áÊñôÊï¥ÂêàÊñπÈù¢Ë°®ÁèæÂá∫Ëâ≤ÔºõRBML Âú®ÂèØËß£ÈáãÊÄßÂíåÂèØ‰ø°Â∫¶ÊñπÈù¢Ë°®ÁèæÂá∫Ëâ≤ÔºõRMLT Âú®ÁÆ°ÁêÜÈ´òÁ∂≠Ë≥áÊñôÊñπÈù¢Ë°®ÁèæÂá∫Ëâ≤ÔºõËÄå PERML ÂÑòÁÆ°Âú®ÂàÜÊûêÊñπÈù¢ÊúâÈôêÔºå‰ΩÜÂú®Á∑äÊÄ•ÁÖßË≠∑Â†¥ÊôØ‰∏≠Ë°®ÁèæÂá∫ÊΩõÂäõ„ÄÇÊú¨Á†îÁ©∂ÂºïÂÖ•‰∫ÜÂõõÁ®ÆÊñ∞Ê®°ÂºèÔºåÂª∫Á´ã‰∫Ü‰∫îÁ®ÆÊäΩË±°ÂàÜÈ°ûÊ®°ÂºèÔºå‰∏¶ÈÄ≤‰∏ÄÊ≠•Â∞áÈÄô‰∫îÁ®ÆÊ®°ÂºèÁ¥∞ÂåñÁÇ∫ÂÖ∑È´îÁöÑÁ≥ªÁµ±„ÄÇÈÄô‰∫õË≤¢ÁçªÂ¢ûÂº∑‰∫ÜÁõíÂ≠êÂ≠∏ÁöÑÂàÜÈ°ûÁµÑÁπîÔºå‰∏¶Êèê‰æõ‰∫ÜÂ∞áÂ∞àÂÆ∂Áü•Ë≠òËàáÊ©üÂô®Â≠∏ÁøíÊï¥ÂêàÁöÑÊñ∞ÊñπÊ≥ï„ÄÇÁõíÂ≠êÂ≠∏ÁöÑÁµêÊßãÂåñ„ÄÅÊ®°ÁµÑÂåñÊñπÊ≥ïÂú®ÈñãÁôºÂíåÂàÜÊûêÊ∑∑Âêà‰∫∫Â∑•Êô∫ÊÖßÁ≥ªÁµ±„ÄÅÊè≠Á§∫ÂÖ±ÊÄß‰ª•ÂèäÊé®Âª£ÂèØÈáçË§á‰ΩøÁî®ÁöÑËß£Ê±∫ÊñπÊ°àÊñπÈù¢ÂÖ∑ÊúâÈ°ØËëóÂÑ™Âã¢„ÄÇÁ∏Ω‰πãÔºåÊú¨Á†îÁ©∂Âº∑Ë™ø‰∫ÜÊ∑∑Âêà‰∫∫Â∑•Êô∫ÊÖßÁ≥ªÁµ±Âú®Êé®ÈÄ≤ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÁöÑÈóúÈçµ‰ΩúÁî®Ôºå‰ª•ÂèäÁõíÂ≠êÂ≠∏Âú®Êé®Âãï‰∫∫Â∑•Êô∫ÊÖßÊï¥ÂêàÈÄ≤‰∏ÄÊ≠•ÂâµÊñ∞ÊñπÈù¢ÁöÑÊΩõÂäõÔºåÊúÄÁµÇÊîπÂñÑËá®Â∫äÊ±∫Á≠ñÊîØÊè¥ÂíåÊÇ£ËÄÖÁöÑÊ≤ªÁôÇÊàêÊûú„ÄÇ

##### **Bayesian Kolmogorov Arnold Networks (Bayesian_KANs): A Probabilistic Approach to Enhance Accuracy and Interpretability**
2408.02706v1 by Masoud Muhammed Hassan

Because of its strong predictive skills, deep learning has emerged as an
essential tool in many industries, including healthcare. Traditional deep
learning models, on the other hand, frequently lack interpretability and omit
to take prediction uncertainty into account two crucial components of clinical
decision making. In order to produce explainable and uncertainty aware
predictions, this study presents a novel framework called Bayesian Kolmogorov
Arnold Networks (BKANs), which combines the expressive capacity of Kolmogorov
Arnold Networks with Bayesian inference. We employ BKANs on two medical
datasets, which are widely used benchmarks for assessing machine learning
models in medical diagnostics: the Pima Indians Diabetes dataset and the
Cleveland Heart Disease dataset. Our method provides useful insights into
prediction confidence and decision boundaries and outperforms traditional deep
learning models in terms of prediction accuracy. Moreover, BKANs' capacity to
represent aleatoric and epistemic uncertainty guarantees doctors receive more
solid and trustworthy decision support. Our Bayesian strategy improves the
interpretability of the model and considerably minimises overfitting, which is
important for tiny and imbalanced medical datasets, according to experimental
results. We present possible expansions to further use BKANs in more
complicated multimodal datasets and address the significance of these
discoveries for future research in building reliable AI systems for healthcare.
This work paves the way for a new paradigm in deep learning model deployment in
vital sectors where transparency and reliability are crucial.

ÊëòË¶ÅÔºöÁî±ÊñºÂÖ∂Âº∑Â§ßÁöÑÈ†êÊ∏¨ËÉΩÂäõÔºåÊ∑±Â∫¶Â≠∏ÁøíÂ∑≤ÊàêÁÇ∫Ë®±Â§öÁî¢Ê•≠‰∏≠‰∏çÂèØÊàñÁº∫ÁöÑÂ∑•ÂÖ∑ÔºåÂåÖÊã¨ÈÜ´ÁôÇ‰øùÂÅ•„ÄÇÁÑ∂ËÄåÔºåÂÇ≥Áµ±ÁöÑÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÈÄöÂ∏∏Áº∫‰πèÂèØËß£ÈáãÊÄßÔºå‰∏¶‰∏îÂøΩÁï•‰∫ÜÂ∞áÈ†êÊ∏¨‰∏çÁ¢∫ÂÆöÊÄßÁ¥çÂÖ•ËÄÉÈáèÔºåËÄåÈÄôÂÖ©ÂÄãÂõ†Á¥†ÊòØËá®Â∫äÊ±∫Á≠ñÂà∂ÂÆöÁöÑÈóúÈçµÁµÑÊàêÈÉ®ÂàÜ„ÄÇÁÇ∫‰∫ÜÁî¢ÁîüÂèØËß£Èáã‰∏îÂÖ∑Êúâ‰∏çÁ¢∫ÂÆöÊÄßÊÑèË≠òÁöÑÈ†êÊ∏¨ÔºåÊú¨Á†îÁ©∂ÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂêçÁÇ∫Ë≤ùÊ∞èÊüØÁàæËé´Âì•Ê¥õÂ§´ÈòøË´æÂæ∑Á∂≤Ë∑Ø (BKAN) ÁöÑÊñ∞Êû∂ÊßãÔºåÂÆÉÁµêÂêà‰∫ÜÊüØÁàæËé´Âì•Ê¥õÂ§´ÈòøË´æÂæ∑Á∂≤Ë∑ØÁöÑË°®ÈÅîËÉΩÂäõËàáË≤ùÊ∞èÊé®Ë´ñ„ÄÇÊàëÂÄëÂú®ÂÖ©ÂÄãÈÜ´Â≠∏Ë≥áÊñôÈõÜ‰∏ä‰ΩøÁî® BKANÔºåÈÄô‰∫õË≥áÊñôÈõÜÊòØË©ï‰º∞Ê©üÂô®Â≠∏ÁøíÊ®°ÂûãÂú®ÈÜ´Â≠∏Ë®∫Êñ∑‰∏≠ÁöÑÂª£Ê≥õ‰ΩøÁî®Âü∫Ê∫ñÔºöÁöÆÈ¶¨Âç∞Á¨¨ÂÆâ‰∫∫Á≥ñÂ∞øÁóÖË≥áÊñôÈõÜÂíåÂÖãÈáåÂ§´Ëò≠ÂøÉËáüÁóÖË≥áÊñôÈõÜ„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÊèê‰æõ‰∫ÜÂ∞çÈ†êÊ∏¨‰ø°ÂøÉÂíåÊ±∫Á≠ñÈÇäÁïåÁöÑÊúâÁõäË¶ãËß£Ôºå‰∏¶‰∏îÂú®È†êÊ∏¨Ê∫ñÁ¢∫Â∫¶ÊñπÈù¢ÂÑ™ÊñºÂÇ≥Áµ±ÁöÑÊ∑±Â∫¶Â≠∏ÁøíÊ®°Âûã„ÄÇÊ≠§Â§ñÔºåBKAN Ë°®ÁèæÈö®Ê©üÂíåË™çË≠ò‰∏çÁ¢∫ÂÆöÊÄßÁöÑËÉΩÂäõÔºåÂèØÁ¢∫‰øùÈÜ´ÁîüÁç≤ÂæóÊõ¥ÂèØÈù†‰∏îÂÄºÂæó‰ø°Ë≥¥ÁöÑÊ±∫Á≠ñÊîØÊè¥„ÄÇÊ†πÊìöÂØ¶È©óÁµêÊûúÔºåÊàëÂÄëÁöÑË≤ùÊ∞èÁ≠ñÁï•ÊèêÈ´ò‰∫ÜÊ®°ÂûãÁöÑÂèØËß£ÈáãÊÄßÔºå‰∏¶Â§ßÂπÖÊ∏õÂ∞ë‰∫ÜÈÅéÂ∫¶Êì¨ÂêàÔºåÈÄôÂ∞çÊñºÂ∞èÂûã‰∏î‰∏çÂπ≥Ë°°ÁöÑÈÜ´Â≠∏Ë≥áÊñôÈõÜÈùûÂ∏∏ÈáçË¶Å„ÄÇÊàëÂÄëÊèêÂá∫‰∫ÜÂèØËÉΩÁöÑÊì¥ÂÖÖÂäüËÉΩÔºå‰ª•ÈÄ≤‰∏ÄÊ≠•Â∞á BKAN Áî®ÊñºÊõ¥Ë§áÈõúÁöÑÂ§öÊ®°ÂºèË≥áÊñôÈõÜÔºå‰∏¶Êé¢Ë®éÈÄô‰∫õÁôºÁèæÂ∞çÊñºÊú™‰æÜÂª∫Á´ãÂèØÈù†ÁöÑÈÜ´ÁôÇ‰øùÂÅ• AI Á≥ªÁµ±Á†îÁ©∂ÁöÑÈáçË¶ÅÊÄß„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÁÇ∫Ê∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÈÉ®ÁΩ≤Âú®ÈÄèÊòéÂ∫¶ÂíåÂèØÈù†ÊÄßËá≥ÈóúÈáçË¶ÅÁöÑÈáçË¶ÅÈ†òÂüü‰∏≠ÈñãÂïü‰∫Ü‰∏ÄÂÄãÊñ∞ÁöÑÂÖ∏ÁØÑ„ÄÇ

##### **Active Sensing of Knee Osteoarthritis Progression with Reinforcement Learning**
2408.02349v2 by Khanh Nguyen, Huy Hoang Nguyen, Egor Panfilov, Aleksei Tiulpin

Osteoarthritis (OA) is the most common musculoskeletal disease, which has no
cure. Knee OA (KOA) is one of the highest causes of disability worldwide, and
it costs billions of United States dollars to the global community. Prediction
of KOA progression has been of high interest to the community for years, as it
can advance treatment development through more efficient clinical trials and
improve patient outcomes through more efficient healthcare utilization.
Existing approaches for predicting KOA, however, are predominantly static, i.e.
consider data from a single time point to predict progression many years into
the future, and knee level, i.e. consider progression in a single joint only.
Due to these and related reasons, these methods fail to deliver the level of
predictive performance, which is sufficient to result in cost savings and
better patient outcomes. Collecting extensive data from all patients on a
regular basis could address the issue, but it is limited by the high cost at a
population level. In this work, we propose to go beyond static prediction
models in OA, and bring a novel Active Sensing (AS) approach, designed to
dynamically follow up patients with the objective of maximizing the number of
informative data acquisitions, while minimizing their total cost over a period
of time. Our approach is based on Reinforcement Learning (RL), and it leverages
a novel reward function designed specifically for AS of disease progression in
more than one part of a human body. Our method is end-to-end, relies on
multi-modal Deep Learning, and requires no human input at inference time.
Throughout an exhaustive experimental evaluation, we show that using RL can
provide a higher monetary benefit when compared to state-of-the-art baselines.

ÊëòË¶ÅÔºöÈ™®ÈóúÁØÄÁÇé (OA) ÊòØÊúÄÂ∏∏Ë¶ãÁöÑËÇåËÇâÈ™®È™ºÁñæÁóÖÔºåÁõÆÂâçÁÑ°Ê≥ïÊ†πÊ≤ª„ÄÇËÜùÈóúÁØÄÈ™®ÈóúÁØÄÁÇé (KOA) ÊòØÂÖ®ÁêÉÊÆòÁñæÁöÑ‰∏ªË¶ÅÂéüÂõ†‰πã‰∏ÄÔºåÂ∞çÂÖ®ÁêÉÁ§æÊúÉÈÄ†ÊàêÊï∏ÂçÅÂÑÑÁæéÂÖÉÁöÑÊêçÂ§±„ÄÇÂ§öÂπ¥‰æÜÔºåÈ†êÊ∏¨ KOA ÁöÑÈÄ≤Á®ã‰∏ÄÁõ¥ÊòØ‰∫∫ÂÄëÈóúÊ≥®ÁöÑÈáçÈªûÔºåÂõ†ÁÇ∫ÂÆÉÂèØ‰ª•ÈÄöÈÅéÊõ¥ÊúâÊïàÁöÑËá®Â∫äË©¶È©óÊé®ÈÄ≤Ê≤ªÁôÇÁöÑÁôºÂ±ïÔºå‰∏¶ÈÄöÈÅéÊõ¥ÊúâÊïàÂú∞Âà©Áî®ÈÜ´ÁôÇ‰øùÂÅ•‰æÜÊîπÂñÑÊÇ£ËÄÖÁöÑÈ†êÂæå„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÁöÑÈ†êÊ∏¨ KOA ÁöÑÊñπÊ≥ï‰∏ªË¶ÅÊòØÈùúÊÖãÁöÑÔºåÂç≥ËÄÉÊÖÆÂñÆ‰∏ÄÊôÇÂàªÁöÑÊï∏Êìö‰æÜÈ†êÊ∏¨Â§öÂπ¥ÂæåÁöÑÈÄ≤Á®ãÔºå‰∏¶‰∏îÊòØËÜùÈóúÁØÄÂ±§Èù¢ÁöÑÔºåÂç≥Âè™ËÄÉÊÖÆÂñÆÂÄãÈóúÁØÄÁöÑÈÄ≤Á®ã„ÄÇÁî±ÊñºÈÄô‰∫õÂèäÁõ∏ÈóúÂéüÂõ†ÔºåÈÄô‰∫õÊñπÊ≥ïÁÑ°Ê≥ïÊèê‰æõË∂≥Â§†ÁöÑÈ†êÊ∏¨ÊÄßËÉΩÔºåÂæûËÄåÁÑ°Ê≥ïÁØÄÁúÅÊàêÊú¨‰∏¶ÊîπÂñÑÊÇ£ËÄÖÁöÑÈ†êÂæå„ÄÇÂÆöÊúüÂæûÊâÄÊúâÊÇ£ËÄÖÈÇ£Ë£°Êî∂ÈõÜÂ§ßÈáèÊï∏ÊìöÂèØ‰ª•Ëß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºå‰ΩÜÂèóÈôêÊñº‰∫∫Âè£Â±§Èù¢ÁöÑÈ´òÊàêÊú¨„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫Ë∂ÖË∂ä OA ‰∏≠ÁöÑÈùúÊÖãÈ†êÊ∏¨Ê®°ÂûãÔºå‰∏¶ÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑ‰∏ªÂãïÊÑüÊ∏¨ (AS) ÊñπÊ≥ïÔºåÊó®Âú®ÂãïÊÖãËøΩËπ§ÊÇ£ËÄÖÔºå‰ª•ÊúÄÂ§ßÂåñ‰ø°ÊÅØÊï∏ÊìöÊé°ÈõÜÁöÑÊï∏ÈáèÔºåÂêåÊôÇÂú®‰∏ÄÊÆµÊôÇÈñìÂÖßÊúÄÂ∞èÂåñÂÖ∂Á∏ΩÊàêÊú¨„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÂü∫ÊñºÂº∑ÂåñÂ≠∏Áøí (RL)Ôºå‰∏¶Âà©Áî®Â∞àÈñÄÁÇ∫Â§öÊñº‰∏ÄÂÄã‰∫∫È´îÈÉ®‰ΩçÁöÑÁñæÁóÖÈÄ≤Á®ãÁöÑ AS Ë®≠Ë®àÁöÑÊñ∞ÂûãÁçéÂãµÂáΩÊï∏„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÊòØÁ´ØÂà∞Á´ØÁöÑÔºå‰æùË≥¥ÊñºÂ§öÊ®°ÂºèÊ∑±Â∫¶Â≠∏ÁøíÔºå‰∏¶‰∏îÂú®Êé®ÁêÜÊôÇ‰∏çÈúÄË¶Å‰∫∫Â∑•Ëº∏ÂÖ•„ÄÇÂú®Ë©≥Áõ°ÁöÑÂØ¶È©óË©ï‰º∞‰∏≠ÔºåÊàëÂÄëË°®ÊòéËàáÊúÄÂÖàÈÄ≤ÁöÑÂü∫Ê∫ñÁõ∏ÊØîÔºå‰ΩøÁî® RL ÂèØ‰ª•Êèê‰æõÊõ¥È´òÁöÑÁ∂ìÊøüÊïàÁõä„ÄÇ

##### **MetaWearS: A Shortcut in Wearable Systems Lifecycle with Only a Few Shots**
2408.01988v1 by Alireza Amirshahi, Maedeh H. Toosi, Siamak Mohammadi, Stefano Albini, Pasquale Davide Schiavone, Giovanni Ansaloni, Amir Aminifar, David Atienza

Wearable systems provide continuous health monitoring and can lead to early
detection of potential health issues. However, the lifecycle of wearable
systems faces several challenges. First, effective model training for new
wearable devices requires substantial labeled data from various subjects
collected directly by the wearable. Second, subsequent model updates require
further extensive labeled data for retraining. Finally, frequent model updating
on the wearable device can decrease the battery life in long-term data
monitoring. Addressing these challenges, in this paper, we propose MetaWearS, a
meta-learning method to reduce the amount of initial data collection required.
Moreover, our approach incorporates a prototypical updating mechanism,
simplifying the update process by modifying the class prototype rather than
retraining the entire model. We explore the performance of MetaWearS in two
case studies, namely, the detection of epileptic seizures and the detection of
atrial fibrillation. We show that by fine-tuning with just a few samples, we
achieve 70% and 82% AUC for the detection of epileptic seizures and the
detection of atrial fibrillation, respectively. Compared to a conventional
approach, our proposed method performs better with up to 45% AUC. Furthermore,
updating the model with only 16 minutes of additional labeled data increases
the AUC by up to 5.3%. Finally, MetaWearS reduces the energy consumption for
model updates by 456x and 418x for epileptic seizure and AF detection,
respectively.

ÊëòË¶ÅÔºö<paragraph>Á©øÊà¥ÂºèÁ≥ªÁµ±Êèê‰æõÊåÅÁ∫åÁöÑÂÅ•Â∫∑Áõ£Ê∏¨Ôºå‰∏¶ÂèØÂèäÊó©ÂÅµÊ∏¨ÊΩõÂú®ÁöÑÂÅ•Â∫∑ÂïèÈ°å„ÄÇÁÑ∂ËÄåÔºåÁ©øÊà¥ÂºèÁ≥ªÁµ±ÁöÑÁîüÂëΩÈÄ±ÊúüÈù¢Ëá®ÂπæÂÄãÊåëÊà∞„ÄÇÈ¶ñÂÖàÔºåÊñ∞Á©øÊà¥ÂºèË£ùÁΩÆÁöÑÊúâÊïàÊ®°ÂûãË®ìÁ∑¥ÈúÄË¶ÅÂæûÂêÑÁ®ÆÂèóË©¶ËÄÖÊî∂ÈõÜÁöÑÂ§ßÈáèÊ®ôÁ±§Ë≥áÊñôÔºå‰∏îË≥áÊñôÂøÖÈ†àÁõ¥Êé•Áî±Á©øÊà¥ÂºèË£ùÁΩÆÊî∂ÈõÜ„ÄÇÂÖ∂Ê¨°ÔºåÂæåÁ∫åÁöÑÊ®°ÂûãÊõ¥Êñ∞ÈúÄË¶ÅÈÄ≤‰∏ÄÊ≠•ÁöÑÂ§ßÈáèÊ®ôÁ±§Ë≥áÊñôÊâçËÉΩÈáçÊñ∞Ë®ìÁ∑¥„ÄÇÊúÄÂæåÔºåÁ©øÊà¥ÂºèË£ùÁΩÆ‰∏äÈ†ªÁπÅÁöÑÊ®°ÂûãÊõ¥Êñ∞ÊúÉÁ∏ÆÁü≠Èï∑ÊúüË≥áÊñôÁõ£Ê∏¨ÁöÑÈõªÊ±†Á∫åËà™Âäõ„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÂú®Êú¨Êñá‰∏≠ÊèêÂá∫ MetaWearSÔºåÈÄôÊòØ‰∏ÄÁ®ÆÂÖÉÂ≠∏ÁøíÊñπÊ≥ïÔºåÂèØÊ∏õÂ∞ëÊâÄÈúÄÁöÑÂàùÂßãË≥áÊñôÊî∂ÈõÜÈáè„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁöÑÊñπÊ≥ïÁµêÂêà‰∫Ü‰∏ÄÂÄãÂéüÂûãÊõ¥Êñ∞Ê©üÂà∂ÔºåÈÄèÈÅé‰øÆÊîπÈ°ûÂà•ÂéüÂûãËÄåÈùûÈáçÊñ∞Ë®ìÁ∑¥Êï¥ÂÄãÊ®°Âûã‰æÜÁ∞°ÂåñÊõ¥Êñ∞ÈÅéÁ®ã„ÄÇÊàëÂÄëÂú®ÂÖ©ÂÄãÊ°à‰æãÁ†îÁ©∂‰∏≠Êé¢Ë®é MetaWearS ÁöÑÊïàËÉΩÔºåÂàÜÂà•ÊòØÁô≤ÁôáÁôº‰ΩúÂÅµÊ∏¨ÂíåÂøÉÊàøÈ°´ÂãïÂÅµÊ∏¨„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫ÜÈÄèÈÅéÂæÆË™øÂÉÖÂ∞ëÊï∏Ê®£Êú¨ÔºåÊàëÂÄëÂàÜÂà•Âú®Áô≤ÁôáÁôº‰ΩúÂÅµÊ∏¨ÂíåÂøÉÊàøÈ°´ÂãïÂÅµÊ∏¨‰∏≠ÈÅîÂà∞ 70% Âíå 82% ÁöÑ AUC„ÄÇËàáÂÇ≥Áµ±ÊñπÊ≥ïÁõ∏ÊØîÔºåÊàëÂÄëÊèêÂá∫ÁöÑÊñπÊ≥ïË°®ÁèæÊõ¥Â•ΩÔºåAUC ÊúÄÈ´òÂèØÈÅî 45%„ÄÇÊ≠§Â§ñÔºåÂÉÖ‰ΩøÁî® 16 ÂàÜÈêòÁöÑÈ°çÂ§ñÊ®ôÁ±§Ë≥áÊñôÊõ¥Êñ∞Ê®°ÂûãÔºåÂç≥ÂèØÂ∞á AUC ÊèêÈ´òÂ§öÈÅî 5.3%„ÄÇÊúÄÂæåÔºåMetaWearS ÂàÜÂà•Â∞áÁô≤ÁôáÁôº‰ΩúÂíåÂøÉÊàøÈ°´ÂãïÂÅµÊ∏¨ÁöÑÊ®°ÂûãÊõ¥Êñ∞ËÉΩËÄóÈôç‰Ωé‰∫Ü 456 ÂÄçÂíå 418 ÂÄç„ÄÇ</paragraph>

##### **DiReCT: Diagnostic Reasoning for Clinical Notes via Large Language Models**
2408.01933v2 by Bowen Wang, Jiuyang Chang, Yiming Qian, Guoxin Chen, Junhao Chen, Zhouqiang Jiang, Jiahao Zhang, Yuta Nakashima, Hajime Nagahara

Large language models (LLMs) have recently showcased remarkable capabilities,
spanning a wide range of tasks and applications, including those in the medical
domain. Models like GPT-4 excel in medical question answering but may face
challenges in the lack of interpretability when handling complex tasks in real
clinical settings. We thus introduce the diagnostic reasoning dataset for
clinical notes (DiReCT), aiming at evaluating the reasoning ability and
interpretability of LLMs compared to human doctors. It contains 511 clinical
notes, each meticulously annotated by physicians, detailing the diagnostic
reasoning process from observations in a clinical note to the final diagnosis.
Additionally, a diagnostic knowledge graph is provided to offer essential
knowledge for reasoning, which may not be covered in the training data of
existing LLMs. Evaluations of leading LLMs on DiReCT bring out a significant
gap between their reasoning ability and that of human doctors, highlighting the
critical need for models that can reason effectively in real-world clinical
scenarios.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÊúÄËøëÂ±ïÁ§∫‰∫ÜÈùûÂá°ÁöÑËÉΩÂäõÔºåÊ∂µËìãÂª£Ê≥õÁöÑ‰ªªÂãôÂíåÊáâÁî®ÔºåÂåÖÊã¨ÈÜ´ÁôÇÈ†òÂüüÁöÑ‰ªªÂãôÂíåÊáâÁî®„ÄÇGPT-4 Á≠âÊ®°ÂûãÂú®ÈÜ´ÁôÇÂïèÈ°åËß£Á≠îÊñπÈù¢Ë°®ÁèæÂá∫Ëâ≤Ôºå‰ΩÜÂú®ËôïÁêÜÂØ¶ÈöõËá®Â∫äÂ†¥ÊôØ‰∏≠ÁöÑË§áÈõú‰ªªÂãôÊôÇÔºåÂèØËÉΩÊúÉÈù¢Ëá®Áº∫‰πèÂèØËß£ÈáãÊÄßÁöÑÊåëÊà∞„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜËá®Â∫äÁ≠ÜË®òË®∫Êñ∑Êé®ÁêÜÊï∏ÊìöÈõÜ (DiReCT)ÔºåÊó®Âú®Ë©ï‰º∞ LLM Ëàá‰∫∫È°ûÈÜ´ÁîüÁõ∏ÊØîÁöÑÊé®ÁêÜËÉΩÂäõÂíåÂèØËß£ÈáãÊÄß„ÄÇÂÆÉÂåÖÂê´ 511 ÂÄãËá®Â∫äÁ≠ÜË®òÔºåÊØèÂÄãÁ≠ÜË®òÈÉΩÁ∂ìÈÅéÈÜ´Áîü‰ªîÁ¥∞Ë®ªËß£ÔºåË©≥Á¥∞Ë™™Êòé‰∫ÜÂæûËá®Â∫äÁ≠ÜË®ò‰∏≠ÁöÑËßÄÂØüÁµêÊûúÂà∞ÊúÄÁµÇË®∫Êñ∑ÁöÑË®∫Êñ∑Êé®ÁêÜÈÅéÁ®ã„ÄÇÊ≠§Â§ñÔºåÈÇÑÊèê‰æõ‰∫ÜË®∫Êñ∑Áü•Ë≠òÂúñË≠úÔºå‰ª•Êèê‰æõÊé®ÁêÜÊâÄÈúÄÁöÑÂü∫Êú¨Áü•Ë≠òÔºåÈÄôÂèØËÉΩÊú™Ê∂µËìãÂú®ÁèæÊúâ LLM ÁöÑË®ìÁ∑¥Êï∏Êìö‰∏≠„ÄÇÂú® DiReCT ‰∏äÂ∞çÈ†òÂÖàÁöÑ LLM ÈÄ≤Ë°åË©ï‰º∞ÔºåÁôºÁèæÂÆÉÂÄëÁöÑÊé®ÁêÜËÉΩÂäõËàá‰∫∫È°ûÈÜ´ÁîüÁöÑÊé®ÁêÜËÉΩÂäõ‰πãÈñìÂ≠òÂú®È°ØËëóÂ∑ÆË∑ùÔºåÈÄôÁ™ÅÈ°Ø‰∫ÜÂú®ÁèæÂØ¶‰∏ñÁïåÁöÑËá®Â∫äÂ†¥ÊôØ‰∏≠ËÉΩÂ§†ÊúâÊïàÊé®ÁêÜÁöÑÊ®°ÂûãÁöÑÈóúÈçµÈúÄÊ±Ç„ÄÇ

##### **MALADE: Orchestration of LLM-powered Agents with Retrieval Augmented Generation for Pharmacovigilance**
2408.01869v1 by Jihye Choi, Nils Palumbo, Prasad Chalasani, Matthew M. Engelhard, Somesh Jha, Anivarya Kumar, David Page

In the era of Large Language Models (LLMs), given their remarkable text
understanding and generation abilities, there is an unprecedented opportunity
to develop new, LLM-based methods for trustworthy medical knowledge synthesis,
extraction and summarization. This paper focuses on the problem of
Pharmacovigilance (PhV), where the significance and challenges lie in
identifying Adverse Drug Events (ADEs) from diverse text sources, such as
medical literature, clinical notes, and drug labels. Unfortunately, this task
is hindered by factors including variations in the terminologies of drugs and
outcomes, and ADE descriptions often being buried in large amounts of narrative
text. We present MALADE, the first effective collaborative multi-agent system
powered by LLM with Retrieval Augmented Generation for ADE extraction from drug
label data. This technique involves augmenting a query to an LLM with relevant
information extracted from text resources, and instructing the LLM to compose a
response consistent with the augmented data. MALADE is a general LLM-agnostic
architecture, and its unique capabilities are: (1) leveraging a variety of
external sources, such as medical literature, drug labels, and FDA tools (e.g.,
OpenFDA drug information API), (2) extracting drug-outcome association in a
structured format along with the strength of the association, and (3) providing
explanations for established associations. Instantiated with GPT-4 Turbo or
GPT-4o, and FDA drug label data, MALADE demonstrates its efficacy with an Area
Under ROC Curve of 0.90 against the OMOP Ground Truth table of ADEs. Our
implementation leverages the Langroid multi-agent LLM framework and can be
found at https://github.com/jihyechoi77/malade.

ÊëòË¶ÅÔºöÂú®Â§ßËØ≠Ë®ÄÊ®°Âûã (LLM) Êó∂‰ª£ÔºåÈâ¥‰∫éÂÖ∂ÂçìË∂äÁöÑÊñáÊú¨ÁêÜËß£ÂíåÁîüÊàêËÉΩÂäõÔºåÂá∫Áé∞‰∫Ü‰∏Ä‰∏™ÂâçÊâÄÊú™ÊúâÁöÑÊú∫‰ºöÔºåÂèØ‰ª•ÂºÄÂèëÂü∫‰∫é LLM ÁöÑÊñ∞ÊñπÊ≥ïÔºåÁî®‰∫éÂèØ‰ø°ÁöÑÂåªÂ≠¶Áü•ËØÜÁªºÂêà„ÄÅÊèêÂèñÂíåÊëòË¶Å„ÄÇÊú¨ÊñáÈáçÁÇπÂÖ≥Ê≥®ËçØÁâ©Ë≠¶Êàí (PhV) ÁöÑÈóÆÈ¢òÔºåÂÖ∂ÈáçË¶ÅÊÄßÂíåÊåëÊàòÂú®‰∫é‰ªéÂêÑÁßçÊñáÊú¨Êù•Ê∫êÔºàÂ¶ÇÂåªÂ≠¶ÊñáÁåÆ„ÄÅ‰∏¥Â∫äÁ¨îËÆ∞ÂíåËçØÁâ©Ê†áÁ≠æÔºâ‰∏≠ËØÜÂà´‰∏çËâØËçØÁâ©‰∫ã‰ª∂ (ADE)„ÄÇ‰∏çÂπ∏ÁöÑÊòØÔºåËøôÈ°π‰ªªÂä°ÂèóÂà∞Â§öÁßçÂõ†Á¥†ÁöÑÈòªÁ¢çÔºåÂåÖÊã¨ËçØÁâ©ÂíåÁªìÊûúÊúØËØ≠ÁöÑÂèòÂåñÔºå‰ª•Âèä ADE ÊèèËø∞ÈÄöÂ∏∏ÂüãÊ≤°Âú®Â§ßÈáèÂèôËø∞ÊÄßÊñáÊú¨‰∏≠„ÄÇÊàë‰ª¨Â±ïÁ§∫‰∫Ü MALADEÔºåËøôÊòØÁ¨¨‰∏Ä‰∏™ÊúâÊïàÁöÑÂçè‰ΩúÂ§öÊô∫ËÉΩ‰ΩìÁ≥ªÁªüÔºåÁî± LLM Êèê‰æõÊîØÊåÅÔºåÂπ∂‰ΩøÁî®Ê£ÄÁ¥¢Â¢ûÂº∫ÁîüÊàêÊù•‰ªéËçØÁâ©Ê†áÁ≠æÊï∞ÊçÆ‰∏≠ÊèêÂèñ ADE„ÄÇÊ≠§ÊäÄÊúØÊ∂âÂèä‰ΩøÁî®‰ªéÊñáÊú¨ËµÑÊ∫ê‰∏≠ÊèêÂèñÁöÑÁõ∏ÂÖ≥‰ø°ÊÅØÊù•Êâ©ÂÖÖÂØπ LLM ÁöÑÊü•ËØ¢ÔºåÂπ∂ÊåáÁ§∫ LLM ÁºñÂÜô‰∏éÊâ©ÂÖÖÊï∞ÊçÆ‰∏ÄËá¥ÁöÑÂìçÂ∫î„ÄÇMALADE ÊòØ‰∏ÄÁßçÈÄöÁî®ÁöÑ LLM ‰∏çÂèØÁü•Êû∂ÊûÑÔºåÂÖ∂Áã¨ÁâπÂäüËÉΩÂåÖÊã¨Ôºö(1) Âà©Áî®ÂêÑÁßçÂ§ñÈÉ®Êù•Ê∫êÔºå‰æãÂ¶ÇÂåªÂ≠¶ÊñáÁåÆ„ÄÅËçØÁâ©Ê†áÁ≠æÂíå FDA Â∑•ÂÖ∑Ôºà‰æãÂ¶Ç OpenFDA ËçØÁâ©‰ø°ÊÅØ APIÔºâÔºå(2) ‰ª•ÁªìÊûÑÂåñÊ†ºÂºèÊèêÂèñËçØÁâ©-ÁªìÊûúÂÖ≥ËÅî‰ª•ÂèäÂÖ≥ËÅîÂº∫Â∫¶Ôºå‰ª•Âèä (3) ‰∏∫Â∑≤Âª∫Á´ãÁöÑÂÖ≥ËÅîÊèê‰æõËß£Èáä„ÄÇMALADE ‰ΩøÁî® GPT-4 Turbo Êàñ GPT-4o ‰ª•Âèä FDA ËçØÁâ©Ê†áÁ≠æÊï∞ÊçÆÂÆû‰æãÂåñÔºåÂπ∂ÈÄöËøáÈíàÂØπ ADE ÁöÑ OMOP Âü∫Êú¨‰∫ãÂÆûË°®Ôºå‰ª• 0.90 ÁöÑ ROC Êõ≤Á∫ø‰∏ãÈù¢ÁßØËØÅÊòé‰∫ÜÂÖ∂ÊúâÊïàÊÄß„ÄÇÊàë‰ª¨ÁöÑÂÆûÁé∞Âà©Áî®‰∫Ü Langroid Â§öÊô∫ËÉΩ‰Ωì LLM Ê°ÜÊû∂ÔºåÂèØ‰ª•Âú® https://github.com/jihyechoi77/malade ‰∏≠ÊâæÂà∞„ÄÇ

##### **Building Trust in Mental Health Chatbots: Safety Metrics and LLM-Based Evaluation Tools**
2408.04650v1 by Jung In Park, Mahyar Abbasian, Iman Azimi, Dawn Bounds, Angela Jun, Jaesu Han, Robert McCarron, Jessica Borelli, Jia Li, Mona Mahmoudi, Carmen Wiedenhoeft, Amir Rahmani

Objective: This study aims to develop and validate an evaluation framework to
ensure the safety and reliability of mental health chatbots, which are
increasingly popular due to their accessibility, human-like interactions, and
context-aware support. Materials and Methods: We created an evaluation
framework with 100 benchmark questions and ideal responses, and five guideline
questions for chatbot responses. This framework, validated by mental health
experts, was tested on a GPT-3.5-turbo-based chatbot. Automated evaluation
methods explored included large language model (LLM)-based scoring, an agentic
approach using real-time data, and embedding models to compare chatbot
responses against ground truth standards. Results: The results highlight the
importance of guidelines and ground truth for improving LLM evaluation
accuracy. The agentic method, dynamically accessing reliable information,
demonstrated the best alignment with human assessments. Adherence to a
standardized, expert-validated framework significantly enhanced chatbot
response safety and reliability. Discussion: Our findings emphasize the need
for comprehensive, expert-tailored safety evaluation metrics for mental health
chatbots. While LLMs have significant potential, careful implementation is
necessary to mitigate risks. The superior performance of the agentic approach
underscores the importance of real-time data access in enhancing chatbot
reliability. Conclusion: The study validated an evaluation framework for mental
health chatbots, proving its effectiveness in improving safety and reliability.
Future work should extend evaluations to accuracy, bias, empathy, and privacy
to ensure holistic assessment and responsible integration into healthcare.
Standardized evaluations will build trust among users and professionals,
facilitating broader adoption and improved mental health support through
technology.

ÊëòË¶ÅÔºö<paragraph>ÁõÆÊ®ôÔºöÊú¨Á†îÁ©∂Êó®Âú®ÈñãÁôºÂíåÈ©óË≠â‰∏ÄÂÄãË©ï‰º∞Êû∂ÊßãÔºå‰ª•Á¢∫‰øùÂøÉÁêÜÂÅ•Â∫∑ËÅäÂ§©Ê©üÂô®‰∫∫ÁöÑÂÆâÂÖ®ÊÄßËàáÂèØÈù†ÊÄßÔºåÁî±ÊñºÂÖ∂ÂèØÂèäÊÄß„ÄÅÊì¨‰∫∫ÂåñÁöÑ‰∫íÂãï‰ª•ÂèäÊÉÖÂ¢ÉÊÑüÁü•ÊîØÊè¥ÔºåÈÄô‰∫õËÅäÂ§©Ê©üÂô®‰∫∫Ê≠£ËÆäÂæóË∂ä‰æÜË∂äÂèóÊ≠°Ëøé„ÄÇÊùêÊñôËàáÊñπÊ≥ïÔºöÊàëÂÄëÂª∫Á´ã‰∫Ü‰∏ÄÂÄãË©ï‰º∞Êû∂ÊßãÔºåÂÖ∂‰∏≠ÂåÖÂê´ 100 ÂÄãÂü∫Ê∫ñÂïèÈ°åÂíåÁêÜÊÉ≥ÂõûÊáâÔºå‰ª•ÂèäÈáùÂ∞çËÅäÂ§©Ê©üÂô®‰∫∫ÂõûÊáâÁöÑ‰∫îÂÄãÊåáÂçóÂïèÈ°å„ÄÇÈÄôÂÄãÊû∂ÊßãÁ∂ìÈÅéÂøÉÁêÜÂÅ•Â∫∑Â∞àÂÆ∂È©óË≠âÔºå‰∏¶Âú®‰∏ÄÂÄãÂü∫Êñº GPT-3.5-turbo ÁöÑËÅäÂ§©Ê©üÂô®‰∫∫‰∏äÈÄ≤Ë°åÊ∏¨Ë©¶„ÄÇÊé¢Ë®éÁöÑËá™ÂãïË©ï‰º∞ÊñπÊ≥ïÂåÖÊã¨Âü∫ÊñºÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑË©ïÂàÜ„ÄÅ‰ΩøÁî®Âç≥ÊôÇË≥áÊñôÁöÑËÉΩÂãïÊñπÊ≥ïÔºå‰ª•ÂèäÂ∞áËÅäÂ§©Ê©üÂô®‰∫∫ÂõûÊáâËàáÂü∫Êú¨‰∫ãÂØ¶Ê®ôÊ∫ñÈÄ≤Ë°åÊØîËºÉÁöÑÂµåÂÖ•ÂºèÊ®°Âûã„ÄÇÁµêÊûúÔºöÁµêÊûúÂº∑Ë™ø‰∫ÜÊ∫ñÂâáÂíåÂü∫Êú¨‰∫ãÂØ¶Â∞çÊñºÊèêÂçá LLM Ë©ï‰º∞Ê∫ñÁ¢∫ÊÄßÁöÑÈáçË¶ÅÊÄß„ÄÇËÉΩÂãïÊñπÊ≥ïÂãïÊÖãÂú∞Â≠òÂèñÂèØÈù†Ë≥áË®äÔºåË≠âÊòéËàá‰∫∫È°ûË©ï‰º∞ÊúÄÁÇ∫‰∏ÄËá¥„ÄÇÈÅµÂæ™Ê®ôÊ∫ñÂåñ‰∏îÁ∂ìÈÅéÂ∞àÂÆ∂È©óË≠âÁöÑÊû∂ÊßãÔºåÈ°ØËëóÊèêÂçá‰∫ÜËÅäÂ§©Ê©üÂô®‰∫∫ÂõûÊáâÁöÑÂÆâÂÖ®ÊÄßËàáÂèØÈù†ÊÄß„ÄÇË®éË´ñÔºöÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÂº∑Ë™ø‰∫ÜÈáùÂ∞çÂøÉÁêÜÂÅ•Â∫∑ËÅäÂ§©Ê©üÂô®‰∫∫Âà∂ÂÆöÂÖ®Èù¢‰∏îÂ∞àÂÆ∂ÈáèË∫´ÊâìÈÄ†ÁöÑÂÆâÂÖ®Ë©ï‰º∞ÊåáÊ®ôÁöÑÂøÖË¶ÅÊÄß„ÄÇÂÑòÁÆ° LLM ÂÖ∑ÊúâÈ°ØËëóÁöÑÊΩõÂäõÔºå‰ΩÜ‰ªçÈúÄË¶ÅË¨πÊÖéÂØ¶ÊñΩ‰ª•Èôç‰ΩéÈ¢®Èö™„ÄÇËÉΩÂãïÊñπÊ≥ïÁöÑÂÑ™Áï∞Ë°®ÁèæÁ™ÅÈ°Ø‰∫ÜÂç≥ÊôÇË≥áÊñôÂ≠òÂèñÂ∞çÊñºÊèêÂçáËÅäÂ§©Ê©üÂô®‰∫∫ÂèØÈù†ÊÄßÁöÑÈáçË¶ÅÊÄß„ÄÇÁµêË´ñÔºöÊú¨Á†îÁ©∂È©óË≠â‰∫Ü‰∏ÄÂÄãÈáùÂ∞çÂøÉÁêÜÂÅ•Â∫∑ËÅäÂ§©Ê©üÂô®‰∫∫ÁöÑË©ï‰º∞Êû∂ÊßãÔºåË≠âÊòéÂÖ∂Âú®ÊèêÂçáÂÆâÂÖ®ÊÄßËàáÂèØÈù†ÊÄßÊñπÈù¢ÁöÑÊúâÊïàÊÄß„ÄÇÊú™‰æÜÁöÑÁ†îÁ©∂ÊáâÂ∞áË©ï‰º∞Êì¥Â±ïËá≥Ê∫ñÁ¢∫ÊÄß„ÄÅÂÅèË¶ã„ÄÅÂêåÁêÜÂøÉÂíåÈö±ÁßÅÔºå‰ª•Á¢∫‰øùÂÖ®Èù¢ÁöÑË©ï‰º∞Ôºå‰∏¶Ë≤†Ë≤¨‰ªªÂú∞Êï¥ÂêàËá≥ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠„ÄÇÊ®ôÊ∫ñÂåñÁöÑË©ï‰º∞Â∞áÂª∫Á´ã‰ΩøÁî®ËÄÖÂíåÂ∞àÊ•≠‰∫∫Â£´‰πãÈñìÁöÑ‰ø°‰ªªÔºå‰øÉÈÄ≤Êõ¥Âª£Ê≥õÁöÑÊé°Áî®Ôºå‰∏¶ÈÄèÈÅéÁßëÊäÄÊîπÂñÑÂøÉÁêÜÂÅ•Â∫∑ÊîØÊè¥„ÄÇ</paragraph>

##### **ST-SACLF: Style Transfer Informed Self-Attention Classifier for Bias-Aware Painting Classification**
2408.01827v1 by Mridula Vijendran, Frederick W. B. Li, Jingjing Deng, Hubert P. H. Shum

Painting classification plays a vital role in organizing, finding, and
suggesting artwork for digital and classic art galleries. Existing methods
struggle with adapting knowledge from the real world to artistic images during
training, leading to poor performance when dealing with different datasets. Our
innovation lies in addressing these challenges through a two-step process.
First, we generate more data using Style Transfer with Adaptive Instance
Normalization (AdaIN), bridging the gap between diverse styles. Then, our
classifier gains a boost with feature-map adaptive spatial attention modules,
improving its understanding of artistic details. Moreover, we tackle the
problem of imbalanced class representation by dynamically adjusting augmented
samples. Through a dual-stage process involving careful hyperparameter search
and model fine-tuning, we achieve an impressive 87.24\% accuracy using the
ResNet-50 backbone over 40 training epochs. Our study explores quantitative
analyses that compare different pretrained backbones, investigates model
optimization through ablation studies, and examines how varying augmentation
levels affect model performance. Complementing this, our qualitative
experiments offer valuable insights into the model's decision-making process
using spatial attention and its ability to differentiate between easy and
challenging samples based on confidence ranking.

ÊëòË¶ÅÔºöÁπ™Áï´ÂàÜÈ°ûÂú®ÁµÑÁπî„ÄÅÂ∞ãÊâæÂíåÂª∫Ë≠∞Êï∏‰ΩçÂíåÁ∂ìÂÖ∏ËóùÂªäÁöÑËóùË°ìÂìÅ‰∏≠ÊâÆÊºîÈáçË¶ÅÁöÑËßíËâ≤„ÄÇÁèæÊúâÁöÑÊñπÊ≥ïÂú®Ë®ìÁ∑¥ÊôÇÈõ£‰ª•Â∞áÁèæÂØ¶‰∏ñÁïåÁöÑÁü•Ë≠òÈÅ©ÊáâÂà∞ËóùË°ìÂúñÂÉè‰∏≠ÔºåÂ∞éËá¥Âú®ËôïÁêÜ‰∏çÂêåË≥áÊñôÈõÜÊôÇÊïàËÉΩ‰∏ç‰Ω≥„ÄÇÊàëÂÄëÁöÑÂâµÊñ∞Âú®ÊñºÈÄèÈÅéÂÖ©Ê≠•È©üÁöÑÁ®ãÂ∫è‰æÜËß£Ê±∫ÈÄô‰∫õÊåëÊà∞„ÄÇÈ¶ñÂÖàÔºåÊàëÂÄë‰ΩøÁî®ÂÖ∑ÊúâËá™ÈÅ©ÊáâÂØ¶‰æãÊ≠£Ë¶èÂåñ (AdaIN) ÁöÑÈ¢®Ê†ºËΩâÁßª‰æÜÁî¢ÁîüÊõ¥Â§öË≥áÊñôÔºåÂΩåÂêà‰∫Ü‰∏çÂêåÈ¢®Ê†º‰πãÈñìÁöÑÂ∑ÆË∑ù„ÄÇÊé•ËëóÔºåÊàëÂÄëÁöÑÂàÜÈ°ûÂô®ÈÄèÈÅéÂÖ∑ÂÇôÁâπÂæµÂúñËá™ÈÅ©ÊáâÁ©∫ÈñìÊ≥®ÊÑèÂäõÊ®°ÁµÑËÄåÁç≤ÂæóÊèêÂçáÔºåÈÄ≤ËÄåÊîπÂñÑÂÖ∂Â∞çËóùË°ìÁ¥∞ÁØÄÁöÑÁêÜËß£„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÈÄèÈÅéÂãïÊÖãË™øÊï¥Êì¥ÂÖÖÊ®£Êú¨‰æÜËß£Ê±∫È°ûÂà•Ë°®Á§∫‰∏çÂπ≥Ë°°ÁöÑÂïèÈ°å„ÄÇÈÄèÈÅé‰∏ÄÂÄãÊ∂âÂèä‰ªîÁ¥∞ÁöÑË∂ÖÂèÉÊï∏ÊêúÂ∞ãÂíåÊ®°ÂûãÂæÆË™øÁöÑÈõôÈöéÊÆµÁ®ãÂ∫èÔºåÊàëÂÄë‰ΩøÁî® ResNet-50 ‰∏ªÂππÂú®Ë∂ÖÈÅé 40 ÂÄãË®ìÁ∑¥ÊôÇÊúüÈÅîÂà∞‰∫Ü‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑ 87.24% Ê∫ñÁ¢∫Â∫¶„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂Êé¢Ë®é‰∫ÜÊØîËºÉ‰∏çÂêåÈ†êË®ìÁ∑¥‰∏ªÂππÁöÑÂÆöÈáèÂàÜÊûêÔºåÈÄèÈÅéÊ∂àËûçÁ†îÁ©∂‰æÜÊé¢Ë®éÊ®°ÂûãÊúÄ‰Ω≥ÂåñÔºå‰∏¶Ê™¢Ë¶ñ‰∏çÂêåÁöÑÊì¥ÂÖÖÂ±§Á¥öÂ¶Ç‰ΩïÂΩ±ÈüøÊ®°ÂûãÊïàËÉΩ„ÄÇ‰ΩúÁÇ∫Ë£úÂÖÖÔºåÊàëÂÄëÁöÑÂÆöÊÄßÂØ¶È©óÈÄèÈÅéÁ©∫ÈñìÊ≥®ÊÑèÂäõÊèê‰æõ‰∫ÜÊúâÂÉπÂÄºÁöÑË¶ãËß£Ôºå‰∫ÜËß£Ê®°ÂûãÁöÑÊ±∫Á≠ñÂà∂ÂÆöÁ®ãÂ∫èÔºå‰ª•ÂèäÂÆÉÊ†πÊìö‰ø°ÂøÉÊéíÂêç‰æÜÂçÄÂàÜÂÆπÊòìÂíåÂõ∞Èõ£Ê®£Êú¨ÁöÑËÉΩÂäõ„ÄÇ

##### **Advancing Mental Health Pre-Screening: A New Custom GPT for Psychological Distress Assessment**
2408.01614v1 by Jinwen Tang, Yi Shang

This study introduces 'Psycho Analyst', a custom GPT model based on OpenAI's
GPT-4, optimized for pre-screening mental health disorders. Enhanced with
DSM-5, PHQ-8, detailed data descriptions, and extensive training data, the
model adeptly decodes nuanced linguistic indicators of mental health disorders.
It utilizes a dual-task framework that includes binary classification and a
three-stage PHQ-8 score computation involving initial assessment, detailed
breakdown, and independent assessment, showcasing refined analytic
capabilities. Validation with the DAIC-WOZ dataset reveals F1 and Macro-F1
scores of 0.929 and 0.949, respectively, along with the lowest MAE and RMSE of
2.89 and 3.69 in PHQ-8 scoring. These results highlight the model's precision
and transformative potential in enhancing public mental health support,
improving accessibility, cost-effectiveness, and serving as a second opinion
for professionals.

ÊëòË¶ÅÔºöÊú¨Á†îÁ©∂Êé®Âá∫‰∫Ü„ÄåÂøÉÁêÜÂàÜÊûêÂ∏´„ÄçÔºå‰∏ÄÂÄãÂü∫Êñº OpenAI ÁöÑ GPT-4 ÁöÑËá™Ë®Ç GPT Ê®°ÂûãÔºåÈáùÂ∞çÂøÉÁêÜÂÅ•Â∫∑ÈöúÁ§ôÁöÑÈ†êÁØ©ÈÅ∏ËÄåÊúÄ‰Ω≥Âåñ„ÄÇÊ≠§Ê®°ÂûãÁ∂ìÈÅé DSM-5„ÄÅPHQ-8„ÄÅË©≥Á¥∞Ë≥áÊñôÊèèËø∞ÂíåÂª£Ê≥õË®ìÁ∑¥Ë≥áÊñôÁöÑÂº∑ÂåñÔºåËÉΩÁÜüÁ∑¥Âú∞Ëß£Á¢ºÂøÉÁêÜÂÅ•Â∫∑ÈöúÁ§ôÁöÑÁ¥∞ÂæÆË™ûË®ÄÊåáÊ®ô„ÄÇÂÆÉÊé°Áî®‰∏ÄÂÄãÈõô‰ªªÂãôÊû∂ÊßãÔºåÂåÖÊã¨‰∫åÂÖÉÂàÜÈ°ûÂíå‰∏ÄÂÄã‰∏âÈöéÊÆµ PHQ-8 ÂàÜÊï∏Ë®àÁÆóÔºåÊ∂âÂèäÂàùÊ≠•Ë©ï‰º∞„ÄÅË©≥Á¥∞Á¥∞ÂàÜÂíåÁç®Á´ãË©ï‰º∞ÔºåÂ±ïÁ§∫‰∫ÜÁ≤æÁ∑ªÁöÑÂàÜÊûêËÉΩÂäõ„ÄÇ‰ΩøÁî® DAIC-WOZ Ë≥áÊñôÈõÜÈÄ≤Ë°åÈ©óË≠âÔºåF1 ÂíåÂ∑®ÈõÜ F1 ÂàÜÊï∏ÂàÜÂà•ÁÇ∫ 0.929 Âíå 0.949ÔºåPHQ-8 Ë©ïÂàÜ‰∏≠ÁöÑ MAE Âíå RMSE ÊúÄ‰ΩéÔºåÂàÜÂà•ÁÇ∫ 2.89 Âíå 3.69„ÄÇÈÄô‰∫õÁµêÊûúÁ™ÅÈ°Ø‰∫ÜÊ≠§Ê®°ÂûãÂú®ÊèêÂçáÂÖ¨ÁúæÂøÉÁêÜÂÅ•Â∫∑ÊîØÊåÅ„ÄÅÊîπÂñÑÂèØÂèäÊÄß„ÄÅÊàêÊú¨ÊïàÁõäÔºå‰ª•Âèä‰ΩúÁÇ∫Â∞àÊ•≠‰∫∫Â£´ÁöÑÁ¨¨‰∫åÊÑèË¶ãÊñπÈù¢ÁöÑÁ≤æÊ∫ñÂ∫¶ÂíåËÆäÈù©ÊΩõÂäõ„ÄÇ

##### **Conformal Diffusion Models for Individual Treatment Effect Estimation and Inference**
2408.01582v1 by Hengrui Cai, Huaqing Jin, Lexin Li

Estimating treatment effects from observational data is of central interest
across numerous application domains. Individual treatment effect offers the
most granular measure of treatment effect on an individual level, and is the
most useful to facilitate personalized care. However, its estimation and
inference remain underdeveloped due to several challenges. In this article, we
propose a novel conformal diffusion model-based approach that addresses those
intricate challenges. We integrate the highly flexible diffusion modeling, the
model-free statistical inference paradigm of conformal inference, along with
propensity score and covariate local approximation that tackle distributional
shifts. We unbiasedly estimate the distributions of potential outcomes for
individual treatment effect, construct an informative confidence interval, and
establish rigorous theoretical guarantees. We demonstrate the competitive
performance of the proposed method over existing solutions through extensive
numerical studies.

ÊëòË¶ÅÔºöÂæûËßÄÂØüË≥áÊñô‰∏≠‰º∞Ë®àÊ≤ªÁôÇÊïàÊûúÂú®Ë®±Â§öÊáâÁî®È†òÂüü‰∏≠ÈÉΩÈùûÂ∏∏ÈáçË¶Å„ÄÇÂÄãÂà•Ê≤ªÁôÇÊïàÊûúÊèê‰æõ‰∫ÜÂÄã‰∫∫Â±§Á¥öÊúÄÁ¥∞Á∑ªÁöÑÊ≤ªÁôÇÊïàÊûúË°°ÈáèÔºå‰∏îÊúÄÊúâÂä©Êñº‰øÉÈÄ≤ÂÄã‰∫∫ÂåñÁÖßË≠∑„ÄÇÁÑ∂ËÄåÔºåÁî±ÊñºÊúâË®±Â§öÊåëÊà∞ÔºåÂÖ∂‰º∞Ë®àÂíåÊé®Ë´ñ‰ªçËôïÊñºÁôºÂ±ï‰∏çË∂≥ÁöÑÁãÄÊÖã„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫ÜÂâµÊñ∞ÁöÑÂÖ±ÂΩ¢Êì¥Êï£Ê®°ÂûãÁÇ∫Âü∫Á§éÁöÑÊñπÊ≥ïÔºå‰æÜÂõ†ÊáâÈÄô‰∫õË§áÈõúÁöÑÊåëÊà∞„ÄÇÊàëÂÄëÊï¥Âêà‰∫ÜÈ´òÂ∫¶ÂΩàÊÄßÁöÑÊì¥Êï£Ê®°Âûã„ÄÅÂÖ±ÂΩ¢Êé®Ë´ñÁöÑÁÑ°Ê®°ÂûãÁµ±Ë®àÊé®Ë´ñÁØÑ‰æãÔºå‰ª•ÂèäËôïÁêÜÂàÜ‰ΩàËΩâÁßªÁöÑÂÇæÂêëÂæóÂàÜÂíåÂçîËÆäÊï∏Â±ÄÈÉ®Ëøë‰ºº„ÄÇÊàëÂÄëÁÑ°ÂÅè‰º∞Ë®àÂÄãÂà•Ê≤ªÁôÇÊïàÊûúÁöÑÊΩõÂú®ÁµêÊûúÂàÜ‰ΩàÔºåÂª∫ÊßãÊúâÊÑèÁæ©ÁöÑ‰ø°ÂøÉÂçÄÈñìÔºå‰∏¶Âª∫Á´ãÂö¥Ë¨πÁöÑÁêÜË´ñ‰øùË≠â„ÄÇÊàëÂÄëÈÄèÈÅéÂª£Ê≥õÁöÑÊï∏ÂÄºÁ†îÁ©∂ÔºåÂ±ïÁ§∫‰∫ÜÊâÄÊèêÂá∫ÊñπÊ≥ïÁõ∏ËºÉÊñºÁèæÊúâËß£Ê±∫ÊñπÊ°àÁöÑÁ´∂Áà≠Âäõ„ÄÇ

##### **High-Throughput Phenotyping of Clinical Text Using Large Language Models**
2408.01214v1 by Daniel B. Hier, S. Ilyas Munzir, Anne Stahlfeld, Tayo Obafemi-Ajayi, Michael D. Carrithers

High-throughput phenotyping automates the mapping of patient signs to
standardized ontology concepts and is essential for precision medicine. This
study evaluates the automation of phenotyping of clinical summaries from the
Online Mendelian Inheritance in Man (OMIM) database using large language
models. Due to their rich phenotype data, these summaries can be surrogates for
physician notes. We conduct a performance comparison of GPT-4 and
GPT-3.5-Turbo. Our results indicate that GPT-4 surpasses GPT-3.5-Turbo in
identifying, categorizing, and normalizing signs, achieving concordance with
manual annotators comparable to inter-rater agreement. Despite some limitations
in sign normalization, the extensive pre-training of GPT-4 results in high
performance and generalizability across several phenotyping tasks while
obviating the need for manually annotated training data. Large language models
are expected to be the dominant method for automating high-throughput
phenotyping of clinical text.

ÊëòË¶ÅÔºöÈ´òÈÄöÈáèË°®ÂûãËá™ÂãïÂåñÂ∞áÊÇ£ËÄÖÁóáÁãÄÂ∞çÊáâÂà∞Ê®ôÊ∫ñÂåñÊú¨‰ΩìÊ¶ÇÂøµÔºåÂ∞çÊñºÁ≤æÊ∫ñÈÜ´ÁôÇËá≥ÈóúÈáçË¶Å„ÄÇÊú¨Á†îÁ©∂Ë©ï‰º∞‰ΩøÁî®Â§ßÂûãË™ûË®ÄÊ®°ÂûãËá™ÂãïÂåñ‰æÜËá™‰∫∫È°ûÂ≠üÂæ∑ÁàæÈÅ∫ÂÇ≥Á∑ö‰∏äÔºàOMIMÔºâË≥áÊñôÂ∫´ÁöÑËá®Â∫äÊëòË¶ÅË°®Âûã„ÄÇÁî±ÊñºÂÖ∂Ë±êÂØåÁöÑË°®ÂûãË≥áÊñôÔºåÈÄô‰∫õÊëòË¶ÅÂèØ‰ª•‰ΩúÁÇ∫ÈÜ´Â∏´ÂÇôÂøòÈåÑÁöÑÊõø‰ª£ÂìÅ„ÄÇÊàëÂÄëÂ∞ç GPT-4 Âíå GPT-3.5-Turbo ÈÄ≤Ë°åÊïàËÉΩÊØîËºÉ„ÄÇÊàëÂÄëÁöÑÁµêÊûúÈ°ØÁ§∫ÔºåGPT-4 Âú®Ë≠òÂà•„ÄÅÂàÜÈ°ûÂíåÊ®ôÊ∫ñÂåñÁóáÁãÄÊñπÈù¢ÂÑ™Êñº GPT-3.5-TurboÔºåËàáÊâãÂãïË®ªËß£ËÄÖÁöÑÁ¨¶ÂêàÂ∫¶ÂèØÂ™≤ÁæéË©ïÂàÜËÄÖÈñìÁöÑ‰∏ÄËá¥ÊÄß„ÄÇÂÑòÁÆ°Âú®ÁóáÁãÄÊ®ôÊ∫ñÂåñÊñπÈù¢Êúâ‰∏Ä‰∫õÈôêÂà∂Ôºå‰ΩÜ GPT-4 ÁöÑÂª£Ê≥õÈ†êË®ìÁ∑¥Âú®Â§öÈ†ÖË°®Âûã‰ªªÂãô‰∏≠‰ªçËÉΩÂ∏∂‰æÜÈ´òÊïàËÉΩÂíåÊ¶ÇÊã¨ÊÄßÔºåÂêåÊôÇÁÑ°ÈúÄÊâãÂãïË®ªËß£ÁöÑË®ìÁ∑¥Ë≥áÊñô„ÄÇÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÈ†êË®àÂ∞áÊàêÁÇ∫Ëá™ÂãïÂåñËá®Â∫äÊñáÂ≠óÈ´òÈÄöÈáèË°®ÂûãÁöÑ‰∏ªË¶ÅÊñπÊ≥ï„ÄÇ

##### **Optimizing Variational Quantum Circuits Using Metaheuristic Strategies in Reinforcement Learning**
2408.01187v1 by Michael K√∂lle, Daniel Seidl, Maximilian Zorn, Philipp Altmann, Jonas Stein, Thomas Gabor

Quantum Reinforcement Learning (QRL) offers potential advantages over
classical Reinforcement Learning, such as compact state space representation
and faster convergence in certain scenarios. However, practical benefits
require further validation. QRL faces challenges like flat solution landscapes,
where traditional gradient-based methods are inefficient, necessitating the use
of gradient-free algorithms. This work explores the integration of
metaheuristic algorithms -- Particle Swarm Optimization, Ant Colony
Optimization, Tabu Search, Genetic Algorithm, Simulated Annealing, and Harmony
Search -- into QRL. These algorithms provide flexibility and efficiency in
parameter optimization. Evaluations in $5\times5$ MiniGrid Reinforcement
Learning environments show that, all algorithms yield near-optimal results,
with Simulated Annealing and Particle Swarm Optimization performing best. In
the Cart Pole environment, Simulated Annealing, Genetic Algorithms, and
Particle Swarm Optimization achieve optimal results, while the others perform
slightly better than random action selection. These findings demonstrate the
potential of Particle Swarm Optimization and Simulated Annealing for efficient
QRL learning, emphasizing the need for careful algorithm selection and
adaptation.

ÊëòË¶ÅÔºöÈáèÂ≠êÂº∑ÂåñÂ≠∏Áøí (QRL) ÊØîÂÇ≥Áµ±Âº∑ÂåñÂ≠∏ÁøíÂÖ∑ÊúâÊΩõÂú®ÂÑ™Âã¢Ôºå‰æãÂ¶ÇÁ∑äÊπäÁöÑÁãÄÊÖãÁ©∫ÈñìË°®Á§∫ÂíåÂú®Êüê‰∫õÊÉÖÊ≥Å‰∏ãÊõ¥Âø´ÁöÑÊî∂ÊñÇÈÄüÂ∫¶„ÄÇÁÑ∂ËÄåÔºåÂØ¶ÈöõÂ•ΩËôïÈúÄË¶ÅÈÄ≤‰∏ÄÊ≠•È©óË≠â„ÄÇQRL Èù¢Ëá®Âπ≥Âù¶ÁöÑËß£Ê±∫ÊñπÊ°àÁí∞Â¢ÉÁ≠âÊåëÊà∞ÔºåÂÇ≥Áµ±ÁöÑÂü∫ÊñºÊ¢ØÂ∫¶ÁöÑÁÆóÊ≥ïÊïàÁéá‰Ωé‰∏ãÔºåÂõ†Ê≠§ÈúÄË¶Å‰ΩøÁî®ÁÑ°Ê¢ØÂ∫¶ÁÆóÊ≥ï„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÊé¢Ë®é‰∫ÜÂÖÉÂïüÁôºÂºèÊºîÁÆóÊ≥ïÔºàÁ≤íÂ≠êÁæ§ÊúÄ‰Ω≥Âåñ„ÄÅËüªÁæ§ÊúÄ‰Ω≥Âåñ„ÄÅÁ¶ÅÂøåÊêúÂ∞ã„ÄÅÈÅ∫ÂÇ≥ÊºîÁÆóÊ≥ï„ÄÅÊ®°Êì¨ÈÄÄÁÅ´ÂíåÂíåË´ßÊêúÂ∞ãÔºâÊï¥ÂêàÂà∞ QRL ‰∏≠„ÄÇÈÄô‰∫õÊºîÁÆóÊ≥ïÂú®ÂèÉÊï∏ÊúÄ‰Ω≥Âåñ‰∏≠Êèê‰æõ‰∫ÜÈùàÊ¥ªÊÄßËàáÊïàÁéá„ÄÇÂú® $5\times5$ MiniGrid Âº∑ÂåñÂ≠∏ÁøíÁí∞Â¢É‰∏≠ÁöÑË©ï‰º∞È°ØÁ§∫ÔºåÊâÄÊúâÊºîÁÆóÊ≥ïÈÉΩÁî¢ÁîüËøë‰πéÊúÄ‰Ω≥ÁöÑÁµêÊûúÔºåÂÖ∂‰∏≠Ê®°Êì¨ÈÄÄÁÅ´ÂíåÁ≤íÂ≠êÁæ§ÊúÄ‰Ω≥ÂåñË°®ÁèæÊúÄ‰Ω≥„ÄÇÂú®Ê°øÈà¥Áí∞Â¢É‰∏≠ÔºåÊ®°Êì¨ÈÄÄÁÅ´„ÄÅÈÅ∫ÂÇ≥ÊºîÁÆóÊ≥ïÂíåÁ≤íÂ≠êÁæ§ÊúÄ‰Ω≥ÂåñÂØ¶ÁèæÊúÄ‰Ω≥ÁµêÊûúÔºåËÄåÂÖ∂‰ªñÊºîÁÆóÊ≥ïÁöÑÊïàËÉΩÁï•ÂÑ™ÊñºÈö®Ê©üÂãï‰ΩúÈÅ∏Êìá„ÄÇÈÄô‰∫õÁôºÁèæË≠âÊòé‰∫ÜÁ≤íÂ≠êÁæ§ÊúÄ‰Ω≥ÂåñÂíåÊ®°Êì¨ÈÄÄÁÅ´Âú®ÊúâÊïàÁéáÁöÑ QRL Â≠∏Áøí‰∏≠ÁöÑÊΩõÂäõÔºåÂº∑Ë™ø‰∫Ü‰ªîÁ¥∞ÈÅ∏ÊìáÂíåË™øÊï¥ÊºîÁÆóÊ≥ïÁöÑÂøÖË¶ÅÊÄß„ÄÇ

##### **Six Dragons Fly Again: Reviving 15th-Century Korean Court Music with Transformers and Novel Encoding**
2408.01096v1 by Danbinaerin Han, Mark Gotham, Dongmin Kim, Hannah Park, Sihun Lee, Dasaem Jeong

We introduce a project that revives a piece of 15th-century Korean court
music, Chihwapyeong and Chwipunghyeong, composed upon the poem Songs of the
Dragon Flying to Heaven. One of the earliest examples of Jeongganbo, a Korean
musical notation system, the remaining version only consists of a rudimentary
melody. Our research team, commissioned by the National Gugak (Korean
Traditional Music) Center, aimed to transform this old melody into a
performable arrangement for a six-part ensemble. Using Jeongganbo data acquired
through bespoke optical music recognition, we trained a BERT-like masked
language model and an encoder-decoder transformer model. We also propose an
encoding scheme that strictly follows the structure of Jeongganbo and denotes
note durations as positions. The resulting machine-transformed version of
Chihwapyeong and Chwipunghyeong were evaluated by experts and performed by the
Court Music Orchestra of National Gugak Center. Our work demonstrates that
generative models can successfully be applied to traditional music with limited
training data if combined with careful design.

ÊëòË¶ÅÔºöÊàëÂÄë‰ªãÁ¥π‰∫Ü‰∏ÄÂÄãÂæ©Âéü 15 ‰∏ñÁ¥ÄÈüìÂúãÂÆÆÂª∑Èü≥Ê®ÇÁöÑÂ∞àÊ°àÔºåÂç≥„ÄäÈ£õÈæçÊ≠å„ÄãÁöÑ„ÄäÈõâÂíåÊãç„ÄãÂíå„ÄäÂêπÈ¢®Ë©†„Äã„ÄÇÈÄôÊòØÈüìÂúãÈü≥Ê®ÇË®òË≠úÊ≥ï„ÄåÊ≠£Âπ≤Ë≠ú„ÄçÊúÄÊó©ÁöÑÁØÑ‰æã‰πã‰∏ÄÔºåÁèæÂ≠òÁâàÊú¨ÂÉÖÂåÖÂê´Âü∫Êú¨ÁöÑÊóãÂæã„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÂúòÈöäÂèóÂúãÂÆ∂ÂúãÊ®Ç‰∏≠ÂøÉÂßîË®óÔºåÊó®Âú®Â∞áÈÄôÈ¶ñÂè§ËÄÅÁöÑÊóãÂæãËΩâÂåñÁÇ∫ÂÖ≠‰∫∫ÂêàÂ•èÁöÑË°®ÊºîÁ∑®Êéí„ÄÇÊàëÂÄë‰ΩøÁî®ÈÄèÈÅéÂÆ¢Ë£ΩÂåñÂÖâÂ≠∏Èü≥Ê®ÇËæ®Ë≠òÂèñÂæóÁöÑÊ≠£Âπ≤Ë≠úË≥áÊñôÔºåË®ìÁ∑¥‰∫Ü‰∏ÄÂÄãÈ°û‰ºº BERT ÁöÑÈÅÆËîΩË™ûË®ÄÊ®°ÂûãÂíå‰∏ÄÂÄãÁ∑®Á¢ºÂô®-Ëß£Á¢ºÂô®ËΩâÊèõÂô®Ê®°Âûã„ÄÇÊàëÂÄëÈÇÑÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÁ∑®Á¢ºÊñπÊ°àÔºåÂÆÉÂö¥Ê†ºÈÅµÂæ™Ê≠£Âπ≤Ë≠úÁöÑÁµêÊßãÔºå‰∏¶Â∞áÈü≥Á¨¶ÊôÇÂÄºÊ®ôÁ§∫ÁÇ∫‰ΩçÁΩÆ„ÄÇÁî±Ê©üÂô®ËΩâÊèõÂæåÁöÑ„ÄäÈõâÂíåÊãç„ÄãÂíå„ÄäÂêπÈ¢®Ë©†„ÄãÁî±Â∞àÂÆ∂Ë©ï‰º∞Ôºå‰∏¶Áî±ÂúãÂÆ∂ÂúãÊ®Ç‰∏≠ÂøÉÁöÑÂÆÆÂª∑Èü≥Ê®ÇÊ®ÇÂúòÊºîÂ•è„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂Ë≠âÊòéÔºåÂ¶ÇÊûúÂ∞áÁîüÊàêÊ®°ÂûãËàáË¨πÊÖéÁöÑË®≠Ë®àÁµêÂêàÔºåÂç≥‰ΩøË®ìÁ∑¥Ë≥áÊñôÊúâÈôêÔºå‰πüËÉΩÊàêÂäüÊáâÁî®ÊñºÂÇ≥Áµ±Èü≥Ê®Ç„ÄÇ

##### **CIResDiff: A Clinically-Informed Residual Diffusion Model for Predicting Idiopathic Pulmonary Fibrosis Progression**
2408.00938v2 by Caiwen Jiang, Xiaodan Xing, Zaixin Ou, Mianxin Liu, Walsh Simon, Guang Yang, Dinggang Shen

The progression of Idiopathic Pulmonary Fibrosis (IPF) significantly
correlates with higher patient mortality rates. Early detection of IPF
progression is critical for initiating timely treatment, which can effectively
slow down the advancement of the disease. However, the current clinical
criteria define disease progression requiring two CT scans with a one-year
interval, presenting a dilemma: a disease progression is identified only after
the disease has already progressed. To this end, in this paper, we develop a
novel diffusion model to accurately predict the progression of IPF by
generating patient's follow-up CT scan from the initial CT scan. Specifically,
from the clinical prior knowledge, we tailor improvements to the traditional
diffusion model and propose a Clinically-Informed Residual Diffusion model,
called CIResDiff. The key innovations of CIResDiff include 1) performing the
target region pre-registration to align the lung regions of two CT scans at
different time points for reducing the generation difficulty, 2) adopting the
residual diffusion instead of traditional diffusion to enable the model focus
more on differences (i.e., lesions) between the two CT scans rather than the
largely identical anatomical content, and 3) designing the clinically-informed
process based on CLIP technology to integrate lung function information which
is highly relevant to diagnosis into the reverse process for assisting
generation. Extensive experiments on clinical data demonstrate that our
approach can outperform state-of-the-art methods and effectively predict the
progression of IPF.

ÊëòË¶ÅÔºöÁâπÁôºÊÄßËÇ∫Á∫ñÁ∂≠Âåñ (IPF) ÁöÑÈÄ≤Á®ãËàáËºÉÈ´òÁöÑÊÇ£ËÄÖÊ≠ª‰∫°ÁéáÈ°ØËëóÁõ∏Èóú„ÄÇÊó©ÊúüÂÅµÊ∏¨ IPF ÈÄ≤Á®ãÂ∞çÊñºÂèäÊôÇÈñãÂßãÊ≤ªÁôÇËá≥ÈóúÈáçË¶ÅÔºåËÄåÊ≤ªÁôÇÂèØ‰ª•ÊúâÊïàÊ∏õÁ∑©ÁñæÁóÖÁöÑÈÄ≤Â±ï„ÄÇÁÑ∂ËÄåÔºåÁõÆÂâçÁöÑËá®Â∫äÊ®ôÊ∫ñÂÆöÁæ©ÁñæÁóÖÈÄ≤Á®ãÈúÄË¶ÅÂÖ©Ê¨°Áõ∏Èöî‰∏ÄÂπ¥ÁöÑÈõªËÖ¶Êñ∑Â±§ÊéÉÊèèÔºåÈÄôÈÄ†Êàê‰∫ÜÂÖ©Èõ£ÔºöÂè™ÊúâÂú®ÁñæÁóÖÂ∑≤Á∂ìÈÄ≤Â±ïÂæåÊâçËÉΩË≠òÂà•Âá∫ÁñæÁóÖÈÄ≤Á®ã„ÄÇÁÇ∫Ê≠§ÔºåÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÈñãÁôº‰∫Ü‰∏ÄÂÄãÂâµÊñ∞ÁöÑÊì¥Êï£Ê®°ÂûãÔºåÈÄöÈÅéÂæûÂàùÂßãÈõªËÖ¶Êñ∑Â±§ÊéÉÊèèÁîüÊàêÊÇ£ËÄÖÁöÑÂæåÁ∫åÈõªËÖ¶Êñ∑Â±§ÊéÉÊèèÔºå‰æÜÊ∫ñÁ¢∫È†êÊ∏¨ IPF ÁöÑÈÄ≤Á®ã„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊ†πÊìöËá®Â∫äÂÖàÈ©óÁü•Ë≠òÔºåÊàëÂÄëÂ∞çÂÇ≥Áµ±Êì¥Êï£Ê®°ÂûãÈÄ≤Ë°å‰∫ÜÊîπÈÄ≤Ôºå‰∏¶ÊèêÂá∫‰∫ÜËá®Â∫äÁü•ÊÉÖÊÆòÂ∑ÆÊì¥Êï£Ê®°ÂûãÔºåÁ®±ÁÇ∫ CIResDiff„ÄÇCIResDiff ÁöÑÈóúÈçµÂâµÊñ∞ÂåÖÊã¨Ôºö1) Âü∑Ë°åÁõÆÊ®ôÂçÄÂüüÈ†êË®ªÂÜäÔºå‰ª•Â∞çÈΩä‰∏çÂêåÊôÇÈñìÈªûÁöÑÂÖ©Ê¨°ÈõªËÖ¶Êñ∑Â±§ÊéÉÊèèÁöÑËÇ∫ÈÉ®ÂçÄÂüüÔºå‰ª•Èôç‰ΩéÁîüÊàêÈõ£Â∫¶Ôºõ2) Êé°Áî®ÊÆòÂ∑ÆÊì¥Êï£ËÄå‰∏çÊòØÂÇ≥Áµ±Êì¥Êï£Ôºå‰ΩøÊ®°ÂûãÊõ¥Â∞àÊ≥®ÊñºÂÖ©Ê¨°ÈõªËÖ¶Êñ∑Â±§ÊéÉÊèè‰πãÈñìÁöÑÂ∑ÆÁï∞ÔºàÂç≥ÁóÖÁÅ∂ÔºâÔºåËÄå‰∏çÊòØÂú®ÂæàÂ§ßÁ®ãÂ∫¶‰∏äÁõ∏ÂêåÁöÑËß£ÂâñÁµêÊßãÔºõ3) Ë®≠Ë®àÂü∫Êñº CLIP ÊäÄË°ìÁöÑËá®Â∫äÁü•ÊÉÖÊµÅÁ®ãÔºåÂ∞áËàáË®∫Êñ∑È´òÂ∫¶Áõ∏ÈóúÁöÑËÇ∫ÂäüËÉΩË≥áË®äÊï¥ÂêàÂà∞ÈÄÜÂêëÈÅéÁ®ã‰∏≠Ôºå‰ª•ÂçîÂä©ÁîüÊàê„ÄÇËá®Â∫äÊï∏ÊìöÁöÑÂ§ßÈáèÂØ¶È©óË°®ÊòéÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÂèØ‰ª•ÂÑ™ÊñºÊúÄÂÖàÈÄ≤ÁöÑÊñπÊ≥ïÔºå‰∏¶ÊúâÊïàÈ†êÊ∏¨ IPF ÁöÑÈÄ≤Á®ã„ÄÇ

##### **Parkinson's Disease Detection from Resting State EEG using Multi-Head Graph Structure Learning with Gradient Weighted Graph Attention Explanations**
2408.00906v1 by Christopher Neves, Yong Zeng, Yiming Xiao

Parkinson's disease (PD) is a debilitating neurodegenerative disease that has
severe impacts on an individual's quality of life. Compared with structural and
functional MRI-based biomarkers for the disease, electroencephalography (EEG)
can provide more accessible alternatives for clinical insights. While deep
learning (DL) techniques have provided excellent outcomes, many techniques fail
to model spatial information and dynamic brain connectivity, and face
challenges in robust feature learning, limited data sizes, and poor
explainability. To address these issues, we proposed a novel graph neural
network (GNN) technique for explainable PD detection using resting state EEG.
Specifically, we employ structured global convolutions with contrastive
learning to better model complex features with limited data, a novel multi-head
graph structure learner to capture the non-Euclidean structure of EEG data, and
a head-wise gradient-weighted graph attention explainer to offer neural
connectivity insights. We developed and evaluated our method using the UC San
Diego Parkinson's disease EEG dataset, and achieved 69.40% detection accuracy
in subject-wise leave-one-out cross-validation while generating intuitive
explanations for the learnt graph topology.

ÊëòË¶ÅÔºöÂ∏ïÈáëÊ£ÆÊ∞èÁóáÔºàPDÔºâÊòØ‰∏ÄÁßçË°∞Âº±ÊÄßÁ•ûÁªèÈÄÄË°åÊÄßÁñæÁóÖÔºåÂØπ‰∏™‰∫∫ÁöÑÁîüÊ¥ªË¥®ÈáèÊúâ‰∏•ÈáçÂΩ±Âìç„ÄÇ‰∏éÁî®‰∫éËØ•ÁñæÁóÖÁöÑÁªìÊûÑÊÄßÂíåÂäüËÉΩÊÄß MRI ÁîüÁâ©Ê†áËÆ∞Áâ©Áõ∏ÊØîÔºåËÑëÁîµÂõæ (EEG) ÂèØ‰ª•Êèê‰æõÊõ¥Êòì‰∫éËé∑ÂèñÁöÑ‰∏¥Â∫äËßÅËß£Êõø‰ª£ÊñπÊ°à„ÄÇËôΩÁÑ∂Ê∑±Â∫¶Â≠¶‰π† (DL) ÊäÄÊúØÊèê‰æõ‰∫ÜÂçìË∂äÁöÑÁªìÊûúÔºå‰ΩÜËÆ∏Â§öÊäÄÊúØÊú™ËÉΩÂØπÁ©∫Èó¥‰ø°ÊÅØÂíåÂä®ÊÄÅÂ§ßËÑëËøûÊé•ËøõË°åÂª∫Ê®°ÔºåÂπ∂‰∏îÂú®Á®≥ÂÅ•ÁâπÂæÅÂ≠¶‰π†„ÄÅÊúâÈôêÁöÑÊï∞ÊçÆÂ§ßÂ∞èÂíåËæÉÂ∑ÆÁöÑÂèØËß£ÈáäÊÄßÊñπÈù¢Èù¢‰∏¥ÊåëÊàò„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∫õÈóÆÈ¢òÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞È¢ñÁöÑÂõæÁ•ûÁªèÁΩëÁªú (GNN) ÊäÄÊúØÔºåÁî®‰∫é‰ΩøÁî®ÈùôÊÅØÁä∂ÊÄÅËÑëÁîµÂõæËøõË°åÂèØËß£ÈáäÁöÑ PD Ê£ÄÊµã„ÄÇÂÖ∑‰ΩìËÄåË®ÄÔºåÊàë‰ª¨ÈááÁî®ÂÖ∑ÊúâÂØπÊØîÂ≠¶‰π†ÁöÑÁªìÊûÑÂåñÂÖ®Â±ÄÂç∑ÁßØÊù•Êõ¥Â•ΩÂú∞ÂØπÂÖ∑ÊúâÊúâÈôêÊï∞ÊçÆÁöÑÂ§çÊùÇÁâπÂæÅËøõË°åÂª∫Ê®°ÔºåÈááÁî®Êñ∞È¢ñÁöÑÂ§öÂ§¥ÂõæÁªìÊûÑÂ≠¶‰π†Âô®Êù•ÊçïËé∑ËÑëÁîµÂõæÊï∞ÊçÆÁöÑÈùûÊ¨ßÂá†ÈáåÂæóÁªìÊûÑÔºå‰ª•ÂèäÈááÁî®Â§¥ÊùÉÈáçÊ¢ØÂ∫¶ÂõæÊ≥®ÊÑèËß£ÈáäÂô®Êù•Êèê‰æõÁ•ûÁªèËøûÊé•ËßÅËß£„ÄÇÊàë‰ª¨‰ΩøÁî®Âä†Â∑ûÂ§ßÂ≠¶Âú£Âú∞‰∫öÂì•ÂàÜÊ†°Â∏ïÈáëÊ£ÆÊ∞èÁóáËÑëÁîµÂõæÊï∞ÊçÆÈõÜÂºÄÂèëÂπ∂ËØÑ‰º∞‰∫ÜÊàë‰ª¨ÁöÑÊñπÊ≥ïÔºåÂπ∂Âú®ÊåâÂèóËØïËÄÖÁïô‰∏ÄÊ≥ï‰∫§ÂèâÈ™åËØÅ‰∏≠ÂÆûÁé∞‰∫Ü 69.40% ÁöÑÊ£ÄÊµãÂáÜÁ°ÆÁéáÔºåÂêåÊó∂‰∏∫Â≠¶‰π†Âà∞ÁöÑÂõæÊãìÊâëÁîüÊàêÁõ¥ËßÇÁöÑËß£Èáä„ÄÇ

##### **UlRe-NeRF: 3D Ultrasound Imaging through Neural Rendering with Ultrasound Reflection Direction Parameterization**
2408.00860v2 by Ziwen Guo, Zi Fang, Zhuang Fu

Three-dimensional ultrasound imaging is a critical technology widely used in
medical diagnostics. However, traditional 3D ultrasound imaging methods have
limitations such as fixed resolution, low storage efficiency, and insufficient
contextual connectivity, leading to poor performance in handling complex
artifacts and reflection characteristics. Recently, techniques based on NeRF
(Neural Radiance Fields) have made significant progress in view synthesis and
3D reconstruction, but there remains a research gap in high-quality ultrasound
imaging. To address these issues, we propose a new model, UlRe-NeRF, which
combines implicit neural networks and explicit ultrasound volume rendering into
an ultrasound neural rendering architecture. This model incorporates reflection
direction parameterization and harmonic encoding, using a directional MLP
module to generate view-dependent high-frequency reflection intensity
estimates, and a spatial MLP module to produce the medium's physical property
parameters. These parameters are used in the volume rendering process to
accurately reproduce the propagation and reflection behavior of ultrasound
waves in the medium. Experimental results demonstrate that the UlRe-NeRF model
significantly enhances the realism and accuracy of high-fidelity ultrasound
image reconstruction, especially in handling complex medium structures.

ÊëòË¶ÅÔºö‰∏âÁ∂≠Ë∂ÖÈü≥Ê≥¢ÂΩ±ÂÉèÊòØ‰∏ÄÈ†ÖÂª£Ê≥õÁî®ÊñºÈÜ´ÁôÇË®∫Êñ∑ÁöÑÈáçË¶ÅÊäÄË°ì„ÄÇÁÑ∂ËÄåÔºåÂÇ≥Áµ±ÁöÑ 3D Ë∂ÖÈü≥Ê≥¢ÂΩ±ÂÉèÊñπÊ≥ïÊúâËß£ÊûêÂ∫¶Âõ∫ÂÆö„ÄÅÂÑ≤Â≠òÊïàÁéá‰Ωé„ÄÅËÑàÁµ°ÈÄ£Êé•ÊÄß‰∏çË∂≥Á≠âÈôêÂà∂ÔºåÂ∞éËá¥Âú®ËôïÁêÜË§áÈõúÁöÑÂÅΩÂΩ±ÂíåÂèçÂ∞ÑÁâπÊÄßÊôÇÊïàËÉΩ‰∏ç‰Ω≥„ÄÇÊúÄËøëÔºåÂü∫Êñº NeRFÔºàÁ•ûÁ∂ìËºªÁÖßÂ†¥ÔºâÁöÑÊäÄË°ìÂú®Ë¶ñÂúñÂêàÊàêÂíå 3D ÈáçÂª∫ÊñπÈù¢ÂèñÂæóÈáçÂ§ßÈÄ≤Â±ïÔºå‰ΩÜÈ´òÂìÅË≥™Ë∂ÖÈü≥Ê≥¢ÂΩ±ÂÉè‰ªçÂ≠òÂú®Á†îÁ©∂Á©∫ÁôΩ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞ÁöÑÊ®°Âûã UlRe-NeRFÔºåÂÆÉÂ∞áÈö±ÂºèÁ•ûÁ∂ìÁ∂≤Ë∑ØÂíåÊòéÁ¢∫ÁöÑË∂ÖÈü≥Ê≥¢È´îÁ©çÊ∏≤ÊüìÁµêÂêàÂà∞Ë∂ÖÈü≥Ê≥¢Á•ûÁ∂ìÊ∏≤ÊüìÊû∂Êßã‰∏≠„ÄÇÊ≠§Ê®°ÂûãÁµêÂêà‰∫ÜÂèçÂ∞ÑÊñπÂêëÂèÉÊï∏ÂåñÂíåË´ßÊ≥¢Á∑®Á¢ºÔºå‰ΩøÁî®ÊñπÂêëÊÄß MLP Ê®°ÁµÑ‰æÜÁî¢ÁîüË¶ñËßí‰æùË≥¥ÁöÑÈ´òÈ†ªÁéáÂèçÂ∞ÑÂº∑Â∫¶‰º∞Ë®àÔºå‰∏¶‰ΩøÁî®Á©∫Èñì MLP Ê®°ÁµÑ‰æÜÁî¢Áîü‰ªãË≥™ÁöÑÁâ©ÁêÜÂ±¨ÊÄßÂèÉÊï∏„ÄÇÈÄô‰∫õÂèÉÊï∏Áî®ÊñºÈ´îÁ©çÊ∏≤ÊüìÈÅéÁ®ã‰∏≠Ôºå‰ª•Ê∫ñÁ¢∫ÈáçÁèæË∂ÖÈü≥Ê≥¢Âú®‰ªãË≥™‰∏≠ÁöÑÂÇ≥Êí≠ÂíåÂèçÂ∞ÑË°åÁÇ∫„ÄÇÂØ¶È©óÁµêÊûúË≠âÊòéÔºåUlRe-NeRF Ê®°ÂûãÈ°ØËëóÊèêÂçá‰∫ÜÈ´ò‰øùÁúüË∂ÖÈü≥Ê≥¢ÂΩ±ÂÉèÈáçÂª∫ÁöÑÁúüÂØ¶ÊÄßÂíåÊ∫ñÁ¢∫ÊÄßÔºåÁâπÂà•ÊòØÂú®ËôïÁêÜË§áÈõú‰ªãË≥™ÁµêÊßãÊôÇ„ÄÇ

##### **Segment anything model 2: an application to 2D and 3D medical images**
2408.00756v2 by Haoyu Dong, Hanxue Gu, Yaqian Chen, Jichen Yang, Maciej A. Mazurowski

Segment Anything Model (SAM) has gained significant attention because of its
ability to segment varous objects in images given a prompt. The recently
developed SAM 2 has extended this ability to video inputs. This opens an
opportunity to apply SAM to 3D images, one of the fundamental tasks in the
medical imaging field. In this paper, we extensively evaluate SAM 2's ability
to segment both 2D and 3D medical images by first collecting 18 medical imaging
datasets, including common 3D modalities such as computed tomography (CT),
magnetic resonance imaging (MRI), and positron emission tomography (PET) as
well as 2D modalities such as X-ray and ultrasound. Two evaluation pipelines of
SAM 2 are considered: (1) multi-frame 3D segmentation, where prompts are
provided to one or multiple slice(s) selected from the volume, and (2)
single-frame 2D segmentation, where prompts are provided to each slice. The
former is only applicable to 3D modalities, while the latter applies to both 2D
and 3D modalities. Our results show that SAM 2 exhibits similar performance as
SAM under single-frame 2D segmentation, and has variable performance under
multi-frame 3D segmentation depending on the choices of slices to annotate, the
direction of the propagation, the predictions utilized during the propagation,
etc.

ÊëòË¶ÅÔºöÂàÜÊÆµ‰ªª‰ΩïÊ®°Âûã (SAM) Âõ†ÂÖ∂Ê†πÊìöÊèêÁ§∫ÂàÜÊÆµÂúñÂÉè‰∏≠ÁöÑ‰∏çÂêåÁâ©‰ª∂ÁöÑËÉΩÂäõËÄåÂèóÂà∞Âª£Ê≥õÈóúÊ≥®„ÄÇÊúÄËøëÈñãÁôºÁöÑ SAM 2 Â∑≤Â∞áÊ≠§ËÉΩÂäõÊì¥Â±ïÂà∞ÂΩ±ÁâáËº∏ÂÖ•„ÄÇÈÄôÁÇ∫Â∞á SAM ÊáâÁî®Êñº 3D ÂΩ±ÂÉèÈñãÂïü‰∫ÜÊ©üÊúÉÔºåÈÄôÊòØÈÜ´Â≠∏ÂΩ±ÂÉèÈ†òÂüüÁöÑÂü∫Êú¨‰ªªÂãô‰πã‰∏Ä„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂª£Ê≥õË©ï‰º∞‰∫Ü SAM 2 ÂàÜÊÆµ 2D Âíå 3D ÈÜ´Â≠∏ÂΩ±ÂÉèÁöÑËÉΩÂäõÔºåÈ¶ñÂÖàÊî∂ÈõÜ‰∫Ü 18 ÂÄãÈÜ´Â≠∏ÂΩ±ÂÉèË≥áÊñôÈõÜÔºåÂåÖÊã¨Â∏∏Ë¶ãÁöÑ 3D Ê®°ÂºèÔºå‰æãÂ¶ÇÈõªËÖ¶Êñ∑Â±§ÊéÉÊèè (CT)„ÄÅÁ£ÅÊåØÈÄ†ÂΩ± (MRI) ÂíåÊ≠£Â≠êÁôºÂ∞ÑÊñ∑Â±§ÊéÉÊèè (PET)Ôºå‰ª•Âèä 2D Ê®°ÂºèÔºå‰æãÂ¶Ç X Â∞ÑÁ∑öÂíåË∂ÖÈü≥Ê≥¢„ÄÇËÄÉÊÖÆ‰∫Ü SAM 2 ÁöÑÂÖ©ÂÄãË©ï‰º∞ÁÆ°ÈÅìÔºö(1) Â§öÂπÄ 3D ÂàÜÊÆµÔºåÂÖ∂‰∏≠ÊèêÁ§∫Êèê‰æõÁµ¶ÂæûÈ´îÁ©ç‰∏≠ÈÅ∏ÊìáÁöÑ‰∏ÄÂÄãÊàñÂ§öÂÄãÂàáÁâáÔºå‰ª•Âèä (2) ÂñÆÂπÄ 2D ÂàÜÊÆµÔºåÂÖ∂‰∏≠ÊèêÁ§∫Êèê‰æõÁµ¶ÊØèÂÄãÂàáÁâá„ÄÇÂâçËÄÖÂÉÖÈÅ©Áî®Êñº 3D Ê®°ÂºèÔºåËÄåÂæåËÄÖÈÅ©Áî®Êñº 2D Âíå 3D Ê®°Âºè„ÄÇÊàëÂÄëÁöÑÁµêÊûúË°®ÊòéÔºåSAM 2 Âú®ÂñÆÂπÄ 2D ÂàÜÊÆµ‰∏ãÁöÑË°®ÁèæËàá SAM È°û‰ººÔºå‰∏¶‰∏îÂú®Â§öÂπÄ 3D ÂàÜÊÆµ‰∏ãÁöÑË°®ÁèæÊúÉÊ†πÊìöË¶ÅÊ®ôË®ªÁöÑÂàáÁâáÈÅ∏Êìá„ÄÅÂÇ≥Êí≠ÊñπÂêë„ÄÅÂÇ≥Êí≠ÊúüÈñì‰ΩøÁî®ÁöÑÈ†êÊ∏¨Á≠âËÄåÊúâÊâÄ‰∏çÂêå„ÄÇ

##### **Leaf Angle Estimation using Mask R-CNN and LETR Vision Transformer**
2408.00749v1 by Venkat Margapuri, Prapti Thapaliya, Trevor Rife

Modern day studies show a high degree of correlation between high yielding
crop varieties and plants with upright leaf angles. It is observed that plants
with upright leaf angles intercept more light than those without upright leaf
angles, leading to a higher rate of photosynthesis. Plant scientists and
breeders benefit from tools that can directly measure plant parameters in the
field i.e. on-site phenotyping. The estimation of leaf angles by manual means
in a field setting is tedious and cumbersome. We mitigate the tedium using a
combination of the Mask R-CNN instance segmentation neural network, and Line
Segment Transformer (LETR), a vision transformer. The proposed Computer Vision
(CV) pipeline is applied on two image datasets, Summer 2015-Ames ULA and Summer
2015- Ames MLA, with a combined total of 1,827 plant images collected in the
field using FieldBook, an Android application aimed at on-site phenotyping. The
leaf angles estimated by the proposed pipeline on the image datasets are
compared to two independent manual measurements using ImageJ, a Java-based
image processing program developed at the National Institutes of Health and the
Laboratory for Optical and Computational Instrumentation. The results, when
compared for similarity using the Cosine Similarity measure, exhibit 0.98
similarity scores on both independent measurements of Summer 2015-Ames ULA and
Summer 2015-Ames MLA image datasets, demonstrating the feasibility of the
proposed pipeline for on-site measurement of leaf angles.

ÊëòË¶ÅÔºö<paragraph>Áèæ‰ª£Á†îÁ©∂È°ØÁ§∫ÔºåÈ´òÁî¢Èáè‰ΩúÁâ©ÂìÅÁ®ÆÂíåËëâÁâáËßíÂ∫¶Áõ¥Á´ãÁöÑÊ§çÁâ©‰πãÈñìÊúâÈ´òÂ∫¶Áõ∏ÈóúÊÄß„ÄÇËßÄÂØüÂà∞ËëâÁâáËßíÂ∫¶Áõ¥Á´ãÁöÑÊ§çÁâ©ÊØîËëâÁâáËßíÂ∫¶‰∏çÁõ¥Á´ãÁöÑÊ§çÁâ©ÊîîÊà™Êõ¥Â§öÂÖâÁ∑öÔºåÂæûËÄåÂ∞éËá¥Êõ¥È´òÁöÑÂÖâÂêà‰ΩúÁî®ÈÄüÁéá„ÄÇÊ§çÁâ©ÁßëÂ≠∏ÂÆ∂ÂíåËÇ≤Á®ÆËÄÖÂèóÁõäÊñºÂèØ‰ª•Âú®Áî∞ÈñìÁõ¥Êé•Ê∏¨ÈáèÊ§çÁâ©ÂèÉÊï∏ÁöÑÂ∑•ÂÖ∑ÔºåÂç≥ÁèæÂ†¥Ë°®ÂûãÂàÜÊûê„ÄÇÂú®Áî∞ÈñìÁí∞Â¢É‰∏≠ÈÄöÈÅéÊâãÂãïÊñπÂºè‰º∞Ë®àËëâÁâáËßíÂ∫¶Êó¢ÁπÅÁë£ÂèàÈ∫ªÁÖ©„ÄÇÊàëÂÄë‰ΩøÁî® Mask R-CNN ÂØ¶‰æãÂàÜÂâ≤Á•ûÁ∂ìÁ∂≤Ë∑ØÂíåÁ∑öÊÆµTransformer (LETR)Ôºà‰∏ÄÁ®ÆË¶ñË¶∫TransformerÔºâÁöÑÁµÑÂêà‰æÜÊ∏õËºïÁπÅÁë£ÊÄß„ÄÇÊâÄÊèêÂá∫ÁöÑË®àÁÆóÊ©üË¶ñË¶∫ (CV) ÁÆ°Á∑öÊáâÁî®ÊñºÂÖ©ÂÄãÂúñÂÉèË≥áÊñôÈõÜÔºåSummer 2015-Ames ULA Âíå Summer 2015- Ames MLAÔºåÁ∏ΩÂÖ±ÂåÖÂê´ 1,827 ÂºµÊ§çÁâ©ÂúñÂÉèÔºåÈÄô‰∫õÂúñÂÉèÊòØÂú®Áî∞Èñì‰ΩøÁî® FieldBookÔºà‰∏ÄÁ®ÆÈáùÂ∞çÁèæÂ†¥Ë°®ÂûãÂàÜÊûêÁöÑ Android ÊáâÁî®Á®ãÂºèÔºâÊî∂ÈõÜÁöÑ„ÄÇ‰ΩøÁî®ÊâÄÊèêÂá∫ÁöÑÁÆ°Á∑ö‰º∞Ë®àÁöÑÂúñÂÉèË≥áÊñôÈõÜ‰∏äÁöÑËëâÁâáËßíÂ∫¶Ëàá‰ΩøÁî® ImageJÔºà‰∏ÄÁ®ÆÁî±ÁæéÂúãÂúãÂÆ∂Ë°õÁîüÁ†îÁ©∂Èô¢ÂíåÂÖâÂ≠∏ÂíåË®àÁÆóÂÑÄÂô®ÂØ¶È©óÂÆ§ÈñãÁôºÁöÑÂü∫Êñº Java ÁöÑÂΩ±ÂÉèËôïÁêÜÁ®ãÂºèÔºâÈÄ≤Ë°åÁöÑÂÖ©Ê¨°Áç®Á´ãÊâãÂãïÊ∏¨ÈáèÈÄ≤Ë°åÊØîËºÉ„ÄÇÂ∞áÁµêÊûú‰ΩøÁî®È§òÂº¶Áõ∏‰ººÂ∫¶Ê∏¨ÈáèÈÄ≤Ë°åÁõ∏‰ººÊÄßÊØîËºÉÊôÇÔºåÂú® Summer 2015-Ames ULA Âíå Summer 2015-Ames MLA ÂΩ±ÂÉèË≥áÊñôÈõÜÁöÑÂÖ©Ê¨°Áç®Á´ãÊ∏¨Èáè‰∏≠ÈÉΩÈ°ØÁ§∫Âá∫ 0.98 ÁöÑÁõ∏‰ººÂ∫¶ÂàÜÊï∏ÔºåË≠âÊòé‰∫ÜÊâÄÊèêÂá∫ÁöÑÁÆ°Á∑öÁî®ÊñºÁèæÂ†¥Ê∏¨ÈáèËëâÁâáËßíÂ∫¶ÁöÑÂèØË°åÊÄß„ÄÇ</paragraph>

##### **Improving Retrieval-Augmented Generation in Medicine with Iterative Follow-up Questions**
2408.00727v1 by Guangzhi Xiong, Qiao Jin, Xiao Wang, Minjia Zhang, Zhiyong Lu, Aidong Zhang

The emergent abilities of large language models (LLMs) have demonstrated
great potential in solving medical questions. They can possess considerable
medical knowledge, but may still hallucinate and are inflexible in the
knowledge updates. While Retrieval-Augmented Generation (RAG) has been proposed
to enhance the medical question-answering capabilities of LLMs with external
knowledge bases, it may still fail in complex cases where multiple rounds of
information-seeking are required. To address such an issue, we propose
iterative RAG for medicine (i-MedRAG), where LLMs can iteratively ask follow-up
queries based on previous information-seeking attempts. In each iteration of
i-MedRAG, the follow-up queries will be answered by a vanilla RAG system and
they will be further used to guide the query generation in the next iteration.
Our experiments show the improved performance of various LLMs brought by
i-MedRAG compared with vanilla RAG on complex questions from clinical vignettes
in the United States Medical Licensing Examination (USMLE), as well as various
knowledge tests in the Massive Multitask Language Understanding (MMLU) dataset.
Notably, our zero-shot i-MedRAG outperforms all existing prompt engineering and
fine-tuning methods on GPT-3.5, achieving an accuracy of 69.68\% on the MedQA
dataset. In addition, we characterize the scaling properties of i-MedRAG with
different iterations of follow-up queries and different numbers of queries per
iteration. Our case studies show that i-MedRAG can flexibly ask follow-up
queries to form reasoning chains, providing an in-depth analysis of medical
questions. To the best of our knowledge, this is the first-of-its-kind study on
incorporating follow-up queries into medical RAG.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâÁöÑÊñ∞ËààËÉΩÂäõÂ∑≤Ë≠âÊòéÂú®Ëß£Ê±∫ÈÜ´ÁôÇÂïèÈ°åÊñπÈù¢ÂÖ∑ÊúâÂ∑®Â§ßÊΩõÂäõ„ÄÇÂÆÉÂÄëÂèØËÉΩÊìÅÊúâÂ§ßÈáèÁöÑÈÜ´ÁôÇÁü•Ë≠òÔºå‰ΩÜ‰ªçÂèØËÉΩÁî¢ÁîüÂπªË¶∫Ôºå‰∏¶‰∏îÂú®Áü•Ë≠òÊõ¥Êñ∞ÊñπÈù¢Áº∫‰πèÈùàÊ¥ªÊÄß„ÄÇÈõñÁÑ∂Â∑≤ÊèêÂá∫Ê™¢Á¥¢Â¢ûÂº∑ÁîüÊàêÔºàRAGÔºâ‰ª•Âà©Áî®Â§ñÈÉ®Áü•Ë≠òÂ∫´Â¢ûÂº∑ LLM ÁöÑÈÜ´ÁôÇÂïèÈ°åËß£Á≠îËÉΩÂäõÔºå‰ΩÜÂú®ÈúÄË¶ÅÂ§öËº™‰ø°ÊÅØÊ™¢Á¥¢ÁöÑË§áÈõúÊÉÖÊ≥Å‰∏ãÔºåÂÆÉ‰ªçÂèØËÉΩÂ§±Êïó„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∫ÜÁî®ÊñºÈÜ´ÁôÇÁöÑËø≠‰ª£ RAGÔºài-MedRAGÔºâÔºåÂÖ∂‰∏≠ LLM ÂèØ‰ª•Ê†πÊìöÂÖàÂâçÁöÑ‰ø°ÊÅØÊ™¢Á¥¢ÂòóË©¶ÂèçË¶ÜË©¢ÂïèÂæåÁ∫åÊü•Ë©¢„ÄÇÂú® i-MedRAG ÁöÑÊØèÊ¨°Ëø≠‰ª£‰∏≠ÔºåÂæåÁ∫åÊü•Ë©¢Â∞áÁî±Âü∫Êú¨ÁöÑ RAG Á≥ªÁµ±ÂõûÁ≠îÔºå‰∏¶‰∏îÂÆÉÂÄëÂ∞áÈÄ≤‰∏ÄÊ≠•Áî®ÊñºÊåáÂ∞é‰∏ã‰∏ÄÊ¨°Ëø≠‰ª£‰∏≠ÁöÑÊü•Ë©¢ÁîüÊàê„ÄÇÊàëÂÄëÁöÑÂØ¶È©óË°®ÊòéÔºåËàáÁæéÂúãÈÜ´Â≠∏Âü∑ÁÖßËÄÉË©¶ÔºàUSMLEÔºâ‰∏≠Ëá®Â∫äÂ∞èÊèíÂúñ‰∏≠ÁöÑË§áÈõúÂïèÈ°å‰ª•Âèä Massive Multitask Language UnderstandingÔºàMMLUÔºâÊï∏ÊìöÈõÜ‰∏≠ÂêÑÁ®ÆÁü•Ë≠òÊ∏¨Ë©¶‰∏≠ÁöÑÂü∫Êú¨ RAG Áõ∏ÊØîÔºåi-MedRAG Â∏∂‰æÜÁöÑÂêÑÁ®Æ LLM ÁöÑÊîπÈÄ≤ÊÄßËÉΩ„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÊàëÂÄëÁöÑÈõ∂Ê¨°Â≠∏Áøí i-MedRAG Âú® GPT-3.5 ‰∏äÂÑ™ÊñºÊâÄÊúâÁèæÊúâÁöÑÊèêÁ§∫Â∑•Á®ãÂíåÂæÆË™øÊñπÊ≥ïÔºåÂú® MedQA Êï∏ÊìöÈõÜ‰∏äÈÅîÂà∞‰∫Ü 69.68% ÁöÑÊ∫ñÁ¢∫Áéá„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèèËø∞‰∫Ü i-MedRAG ÁöÑÊì¥Â±ïÂ±¨ÊÄßÔºåÂåÖÊã¨‰∏çÂêåÁöÑÂæåÁ∫åÊü•Ë©¢Ëø≠‰ª£ÂíåÊØèÂÄãËø≠‰ª£ÁöÑ‰∏çÂêåÊü•Ë©¢Êï∏Èáè„ÄÇÊàëÂÄëÁöÑÊ°à‰æãÁ†îÁ©∂Ë°®ÊòéÔºåi-MedRAG ÂèØ‰ª•ÈùàÊ¥ªÂú∞Ë©¢ÂïèÂæåÁ∫åÊü•Ë©¢‰ª•ÂΩ¢ÊàêÊé®ÁêÜÈèàÔºåÂæûËÄåÂ∞çÈÜ´ÁôÇÂïèÈ°åÈÄ≤Ë°åÊ∑±ÂÖ•ÂàÜÊûê„ÄÇÊìöÊàëÂÄëÊâÄÁü•ÔºåÈÄôÊòØÁ¨¨‰∏ÄÂÄãÂ∞áÂæåÁ∫åÊü•Ë©¢Á¥çÂÖ•ÈÜ´ÁôÇ RAG ÁöÑÂêåÈ°ûÁ†îÁ©∂„ÄÇ

##### **Point-supervised Brain Tumor Segmentation with Box-prompted MedSAM**
2408.00706v1 by Xiaofeng Liu, Jonghye Woo, Chao Ma, Jinsong Ouyang, Georges El Fakhri

Delineating lesions and anatomical structure is important for image-guided
interventions. Point-supervised medical image segmentation (PSS) has great
potential to alleviate costly expert delineation labeling. However, due to the
lack of precise size and boundary guidance, the effectiveness of PSS often
falls short of expectations. Although recent vision foundational models, such
as the medical segment anything model (MedSAM), have made significant
advancements in bounding-box-prompted segmentation, it is not straightforward
to utilize point annotation, and is prone to semantic ambiguity. In this
preliminary study, we introduce an iterative framework to facilitate
semantic-aware point-supervised MedSAM. Specifically, the semantic box-prompt
generator (SBPG) module has the capacity to convert the point input into
potential pseudo bounding box suggestions, which are explicitly refined by the
prototype-based semantic similarity. This is then succeeded by a prompt-guided
spatial refinement (PGSR) module that harnesses the exceptional
generalizability of MedSAM to infer the segmentation mask, which also updates
the box proposal seed in SBPG. Performance can be progressively improved with
adequate iterations. We conducted an evaluation on BraTS2018 for the
segmentation of whole brain tumors and demonstrated its superior performance
compared to traditional PSS methods and on par with box-supervised methods.

ÊëòË¶ÅÔºöÊèèÁπ™ÁóÖÁÅ∂ÂíåËß£ÂâñÁµêÊßãÂ∞çÊñºÂΩ±ÂÉèÂ∞éÂºï‰ªãÂÖ•ÈùûÂ∏∏ÈáçË¶Å„ÄÇÈªûÁõ£Áù£ÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÂâ≤ÔºàPSSÔºâÂÖ∑ÊúâÊ∏õËºïÊòÇË≤¥ÁöÑÂ∞àÂÆ∂ÊèèÁπ™Ê®ôÁ±§ÁöÑÂ∑®Â§ßÊΩõÂäõ„ÄÇÁÑ∂ËÄåÔºåÁî±ÊñºÁº∫‰πèÁ≤æÁ¢∫ÁöÑÂ§ßÂ∞èÂíåÈÇäÁïåÂºïÂ∞éÔºåPSS ÁöÑÊúâÊïàÊÄßÈÄöÂ∏∏‰ΩéÊñºÈ†êÊúü„ÄÇÂÑòÁÆ°ÊúÄËøëÁöÑË¶ñË¶∫Âü∫Á§éÊ®°ÂûãÔºå‰æãÂ¶ÇÈÜ´Â≠∏ÂàÜÂâ≤‰ªª‰ΩïÊ®°ÂûãÔºàMedSAMÔºâÔºåÂú®ÈÇäÁïåÊ°ÜÊèêÁ§∫ÂàÜÂâ≤ÊñπÈù¢ÂèñÂæó‰∫ÜÈáçÂ§ßÈÄ≤Â±ïÔºå‰ΩÜÂà©Áî®ÈªûË®ªÈáã‰∏¶‰∏çÂÆπÊòìÔºåËÄå‰∏îÂÆπÊòìÁî¢ÁîüË™ûÁæ©Ê≠ßÁæ©„ÄÇÂú®ÈÄôÈ†ÖÂàùÊ≠•Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÂÄãËø≠‰ª£Ê°ÜÊû∂‰æÜ‰øÉÈÄ≤Ë™ûÁæ©ÊÑüÁü•ÈªûÁõ£Áù£ MedSAM„ÄÇÂÖ∑È´î‰æÜË™™ÔºåË™ûÁæ©Ê°ÜÊèêÁ§∫ÁîüÊàêÂô®ÔºàSBPGÔºâÊ®°ÁµÑËÉΩÂ§†Â∞áÈªûËº∏ÂÖ•ËΩâÊèõÁÇ∫ÊΩõÂú®ÁöÑÂÅΩÈÇäÁïåÊ°ÜÂª∫Ë≠∞ÔºåÈÄô‰∫õÂª∫Ë≠∞Áî±Âü∫ÊñºÂéüÂûãÁöÑË™ûÁæ©Áõ∏‰ººÊÄßÊòéÁ¢∫Á¥∞Âåñ„ÄÇÁÑ∂ÂæåÔºåÁî±ÊèêÁ§∫ÂºïÂ∞éÁöÑÁ©∫ÈñìÁ¥∞ÂåñÔºàPGSRÔºâÊ®°ÁµÑÁπºÊâøÔºåÂÆÉÂà©Áî® MedSAM ÁöÑÂá∫Ëâ≤ÂèØÊ¶ÇÂåñÊÄß‰æÜÊé®Êñ∑ÂàÜÂâ≤ËíôÁâàÔºåÈÄô‰πüÊúÉÊõ¥Êñ∞ SBPG ‰∏≠ÁöÑÊ°ÜÂª∫Ë≠∞Á®ÆÂ≠ê„ÄÇÈÄöÈÅéÂÖÖÂàÜÁöÑËø≠‰ª£ÂèØ‰ª•ÈÄêÊ≠•ÊèêÈ´òÊÄßËÉΩ„ÄÇÊàëÂÄëÂ∞ç BraTS2018 ÈÄ≤Ë°å‰∫ÜÂÖ®ËÖ¶ËÖ´Áò§ÂàÜÂâ≤Ë©ï‰º∞Ôºå‰∏¶Ë≠âÊòéÂÖ∂ÊÄßËÉΩÂÑ™ÊñºÂÇ≥Áµ±ÁöÑ PSS ÊñπÊ≥ïÔºå‰∏¶‰∏îËàáÊ°ÜÁõ£Áù£ÊñπÊ≥ïÁõ∏Áï∂„ÄÇ

##### **HBot: A Chatbot for Healthcare Applications in Traditional Chinese Medicine Based on Human Body 3D Visualization**
2408.00481v1 by Bolin Zhang, Zhiwei Yi, Jiahao Wang, Dianbo Sui, Zhiying Tu, Dianhui Chu

The unique diagnosis and treatment techniques and remarkable clinical
efficacy of traditional Chinese medicine (TCM) make it play an important role
in the field of elderly care and healthcare, especially in the rehabilitation
of some common chronic diseases of the elderly. Therefore, building a TCM
chatbot for healthcare application will help users obtain consultation services
in a direct and natural way. However, concepts such as acupuncture points
(acupoints) and meridians involved in TCM always appear in the consultation,
which cannot be displayed intuitively. To this end, we develop a
\textbf{h}ealthcare chat\textbf{bot} (HBot) based on a human body model in 3D
and knowledge graph, which provides conversational services such as knowledge
Q\&A, prescription recommendation, moxibustion therapy recommendation, and
acupoint search. When specific acupoints are involved in the conversations
between user and HBot, the 3D body will jump to the corresponding acupoints and
highlight them. Moreover, Hbot can also be used in training scenarios to
accelerate the teaching process of TCM by intuitively displaying acupuncture
points and knowledge cards. The demonstration video is available at
https://www.youtube.com/watch?v=UhQhutSKkTU . Our code and dataset are publicly
available at Gitee: https://gitee.com/plabrolin/interactive-3d-acup.git

ÊëòË¶ÅÔºö‰∏≠ÈÜ´Áç®ÁâπÁöÑË®∫Ê≤ªÊâãÊ≥ïÂíåÈ°ØËëóÁöÑËá®Â∫äÁôÇÊïàÔºåÂú®ËÄÅÂπ¥ÁÖßË≠∑Ëàá‰øùÂÅ•È†òÂüü‰∏≠ÊâÆÊºîËëóÈáçË¶ÅÁöÑËßíËâ≤ÔºåÁâπÂà•ÊòØÂú®ËÄÅÂπ¥‰∫∫Â∏∏Ë¶ãÊÖ¢ÊÄßÁñæÁóÖÁöÑÂæ©ÂÅ•‰∏ä„ÄÇÂõ†Ê≠§ÔºåÂª∫Êßã‰∏ÄÂÄã‰∏≠ÈÜ´ÈÜ´ÁôÇÁÖßË≠∑ËÅäÂ§©Ê©üÂô®‰∫∫ÔºåÂ∞áÊúâÂä©Êñº‰ΩøÁî®ËÄÖ‰ª•Áõ¥Êé•‰∏îËá™ÁÑ∂ÁöÑÊñπÂºèÂèñÂæóË´ÆË©¢ÊúçÂãô„ÄÇÁÑ∂ËÄåÔºå‰∏≠ÈÜ´ÊâÄÊ∂âÂèäÁöÑÁ©¥‰Ωç„ÄÅÁ∂ìÁµ°Á≠âÊ¶ÇÂøµÔºåÂú®Ë´ÆË©¢ÊôÇÁ∏ΩÊòØÊúÉÂá∫ÁèæÔºåËÄåÈÄô‰∫õÁÑ°Ê≥ïÁõ¥ËßÄÂú∞È°ØÁ§∫Âá∫‰æÜ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÈñãÁôº‰∫Ü‰∏ÄÂÄãÂü∫Êñº 3D ‰∫∫È´îÊ®°ÂûãÂíåÁü•Ë≠òÂúñË≠úÁöÑÈÜ´ÁôÇÁÖßË≠∑ËÅäÂ§©Ê©üÂô®‰∫∫ÔºàHBotÔºâÔºåÂÆÉÊèê‰æõ‰∫ÜÁü•Ë≠òÂïèÁ≠î„ÄÅËôïÊñπÊé®Ëñ¶„ÄÅËâæÁÅ∏ÁôÇÊ≥ïÊé®Ëñ¶ÂíåÁ©¥‰ΩçÊü•Ë©¢Á≠âÂ∞çË©±ÊúçÂãô„ÄÇÁï∂‰ΩøÁî®ËÄÖËàá HBot ÁöÑÂ∞çË©±‰∏≠Ê∂âÂèäÂà∞ÂÖ∑È´îÁ©¥‰ΩçÊôÇÔºå3D ‰∫∫È´îÊúÉË∑≥ËΩâÂà∞Â∞çÊáâÁöÑÁ©¥‰Ωç‰∏¶Â∞áÂÖ∂È´ò‰∫ÆÈ°ØÁ§∫„ÄÇÊ≠§Â§ñÔºåHBot ÈÇÑÂèØ‰ª•Áî®ÊñºÂüπË®ìÂ†¥ÊôØ‰∏≠ÔºåÈÄöÈÅéÁõ¥ËßÄÂú∞È°ØÁ§∫Á©¥‰ΩçÂíåÁü•Ë≠òÂç°ÁâáÔºå‰æÜÂä†ÈÄü‰∏≠ÈÜ´ÊïôÂ≠∏ÁöÑÈÄ≤Á®ã„ÄÇÁ§∫ÁØÑÂΩ±ÁâáÂèØÊñº https://www.youtube.com/watch?v=UhQhutSKkTU ÂèñÂæó„ÄÇÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÂíåË≥áÊñôÈõÜÂ∑≤Êñº Gitee ÂÖ¨ÈñãÔºöhttps://gitee.com/plabrolin/interactive-3d-acup.git

##### **Securing the Diagnosis of Medical Imaging: An In-depth Analysis of AI-Resistant Attacks**
2408.00348v1 by Angona Biswas, MD Abdullah Al Nasim, Kishor Datta Gupta, Roy George, Abdur Rashid

Machine learning (ML) is a rapidly developing area of medicine that uses
significant resources to apply computer science and statistics to medical
issues. ML's proponents laud its capacity to handle vast, complicated, and
erratic medical data. It's common knowledge that attackers might cause
misclassification by deliberately creating inputs for machine learning
classifiers. Research on adversarial examples has been extensively conducted in
the field of computer vision applications. Healthcare systems are thought to be
highly difficult because of the security and life-or-death considerations they
include, and performance accuracy is very important. Recent arguments have
suggested that adversarial attacks could be made against medical image analysis
(MedIA) technologies because of the accompanying technology infrastructure and
powerful financial incentives. Since the diagnosis will be the basis for
important decisions, it is essential to assess how strong medical DNN tasks are
against adversarial attacks. Simple adversarial attacks have been taken into
account in several earlier studies. However, DNNs are susceptible to more risky
and realistic attacks. The present paper covers recent proposed adversarial
attack strategies against DNNs for medical imaging as well as countermeasures.
In this study, we review current techniques for adversarial imaging attacks,
detections. It also encompasses various facets of these techniques and offers
suggestions for the robustness of neural networks to be improved in the future.

ÊëòË¶ÅÔºöÊ©üÂô®Â≠∏Áøí (ML) ÊòØÈÜ´Â≠∏È†òÂüü‰∏≠Âø´ÈÄüÁôºÂ±ïÁöÑ‰∏ÄÂÄãÈ†òÂüüÔºåÂÆÉÂà©Áî®Â§ßÈáèÁöÑË≥áÊ∫êÂ∞áÈõªËÖ¶ÁßëÂ≠∏ÂíåÁµ±Ë®àÂ≠∏ÊáâÁî®ÊñºÈÜ´ÁôÇÂïèÈ°å„ÄÇML ÁöÑÊîØÊåÅËÄÖËÆöÊèöÂÆÉËôïÁêÜÂ§ßÈáè„ÄÅË§áÈõú‰∏î‰∏çË¶èÂâáÈÜ´ÁôÇË≥áÊñôÁöÑËÉΩÂäõ„ÄÇÁúæÊâÄÂë®Áü•ÔºåÊîªÊìäËÄÖÂèØËÉΩÊúÉÈÄèÈÅéÊïÖÊÑèÁÇ∫Ê©üÂô®Â≠∏ÁøíÂàÜÈ°ûÂô®Âª∫Á´ãËº∏ÂÖ•‰æÜÂ∞éËá¥ÈåØË™§ÂàÜÈ°û„ÄÇÂ∞çÊäóÁØÑ‰æãÁöÑÁ†îÁ©∂Â∑≤Âú®ÈõªËÖ¶Ë¶ñË¶∫ÊáâÁî®È†òÂüü‰∏≠Âª£Ê≥õÈÄ≤Ë°å„ÄÇÈÜ´ÁôÇ‰øùÂÅ•Á≥ªÁµ±Ë¢´Ë™çÁÇ∫ÈùûÂ∏∏Âõ∞Èõ£ÔºåÂõ†ÁÇ∫ÂÆÉÂÄëÂåÖÂê´ÂÆâÂÖ®ÊÄßÂèäÁîüÊ≠ªÊî∏ÈóúÁöÑËÄÉÈáèÔºå‰∏îÊïàËÉΩÊ∫ñÁ¢∫ÊÄßÈùûÂ∏∏ÈáçË¶Å„ÄÇÊúÄËøëÁöÑË´ñÈªûË°®ÊòéÔºåÁî±Êñº‰º¥Èö®ËÄå‰æÜÁöÑÊäÄË°ìÂü∫Á§éË®≠ÊñΩÂíåÂº∑Â§ßÁöÑË≤°ÂãôË™òÂõ†ÔºåÂ∞çÊäóÊîªÊìäÂèØËÉΩÊúÉÈáùÂ∞çÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÊûê (MedIA) ÊäÄË°ìÈÄ≤Ë°å„ÄÇÁî±ÊñºË®∫Êñ∑Â∞áÊàêÁÇ∫ÈáçË¶ÅÊ±∫Á≠ñÁöÑÂü∫Á§éÔºåÂõ†Ê≠§Ë©ï‰º∞ÈÜ´ÁôÇ DNN ‰ªªÂãôÂ∞çÊäóÊîªÊìäÁöÑÂº∑Âº±ÈùûÂ∏∏ÈáçË¶Å„ÄÇÂú®ÂÖàÂâçÁöÑÂ§öÈ†ÖÁ†îÁ©∂‰∏≠Â∑≤ËÄÉÊÖÆ‰∫ÜÁ∞°ÂñÆÁöÑÂ∞çÊäóÊîªÊìä„ÄÇÁÑ∂ËÄåÔºåDNN ÂÆπÊòìÂèóÂà∞È¢®Èö™Êõ¥È´ò‰∏îÊõ¥ÈÄºÁúüÁöÑÊîªÊìä„ÄÇÊú¨ÊñáÊ∂µËìã‰∫ÜÈáùÂ∞çÁî®ÊñºÈÜ´Â≠∏ÂΩ±ÂÉèÁöÑ DNN ÊâÄÊèêÂá∫ÁöÑÊúÄÊñ∞Â∞çÊäóÊîªÊìäÁ≠ñÁï•‰ª•ÂèäÂ∞çÁ≠ñ„ÄÇÂú®Êú¨Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëÂõûÈ°ß‰∫ÜÁï∂ÂâçÂ∞çÊäóÂΩ±ÂÉèÊîªÊìäÁöÑÊäÄË°ìÂíåÊ™¢Ê∏¨ÊñπÊ≥ï„ÄÇÂÆÉÈÇÑÂåÖÂê´‰∫ÜÈÄô‰∫õÊäÄË°ìÁöÑÂêÑÂÄãÊñπÈù¢Ôºå‰∏¶Êèê‰æõ‰∫ÜÊîπÈÄ≤Á•ûÁ∂ìÁ∂≤Ë∑ØÂú®Êú™‰æÜÂº∑ÂÅ•ÊÄßÁöÑÂª∫Ë≠∞„ÄÇ

##### **Advancing Medical Image Segmentation: Morphology-Driven Learning with Diffusion Transformer**
2408.00347v1 by Sungmin Kang, Jaeha Song, Jihie Kim

Understanding the morphological structure of medical images and precisely
segmenting the region of interest or abnormality is an important task that can
assist in diagnosis. However, the unique properties of medical imaging make
clear segmentation difficult, and the high cost and time-consuming task of
labeling leads to a coarse-grained representation of ground truth. Facing with
these problems, we propose a novel Diffusion Transformer Segmentation (DTS)
model for robust segmentation in the presence of noise. We propose an
alternative to the dominant Denoising U-Net encoder through experiments
applying a transformer architecture, which captures global dependency through
self-attention. Additionally, we propose k-neighbor label smoothing, reverse
boundary attention, and self-supervised learning with morphology-driven
learning to improve the ability to identify complex structures. Our model,
which analyzes the morphological representation of images, shows better results
than the previous models in various medical imaging modalities, including CT,
MRI, and lesion images.

ÊëòË¶ÅÔºö‰∫ÜËß£ÈÜ´Â≠∏ÂΩ±ÂÉèÁöÑÂΩ¢ÊÖãÁµêÊßã‰∏¶Á≤æÁ¢∫ÂàÜÂâ≤ÊÑüËààË∂£ÊàñÁï∞Â∏∏ÂçÄÂüüÊòØ‰∏ÄÈ†ÖÈáçË¶ÅÁöÑ‰ªªÂãôÔºåÊúâÂä©ÊñºË®∫Êñ∑„ÄÇÁÑ∂ËÄåÔºåÈÜ´Â≠∏ÂΩ±ÂÉèÁöÑÁç®ÁâπÂ±¨ÊÄß‰ΩøÂæóÊ∏ÖÊô∞ÁöÑÂàÜÂâ≤ËÆäÂæóÂõ∞Èõ£ÔºåËÄåÊ®ôÁ±§ÁöÑÈ´òÊàêÊú¨ÂíåËÄóÊôÇ‰ªªÂãôÂ∞éËá¥‰∫ÜÂú∞Èù¢ÂØ¶Ê≥ÅÁöÑÁ≤óÁï•Ë°®Á§∫„ÄÇÈù¢Â∞çÈÄô‰∫õÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊñ∞ÁöÑÊì¥Êï£TransformerÂàÜÂâ≤ÔºàDTSÔºâÊ®°ÂûãÔºåÁî®ÊñºÂú®ÊúâÂô™ËÅ≤ÁöÑÊÉÖÊ≥Å‰∏ãÈÄ≤Ë°åÁ©©ÂÅ•ÂàÜÂâ≤„ÄÇÊàëÂÄëÈÄöÈÅéÊáâÁî®ÊçïÁç≤ÂÖ®Â±Ä‰æùË≥¥ÊÄßÁöÑËá™Ê≥®ÊÑèÂäõTransformerÊû∂ÊßãÔºåÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊõø‰ª£‰∏ªÊµÅÂéªÂô™ U-Net Á∑®Á¢ºÂô®ÁöÑÊñπÊ°à„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèêÂá∫‰∫Ü k ËøëÈÑ∞Ê®ôÁ±§Âπ≥Êªë„ÄÅÂèçÂêëÈÇäÁïåÊ≥®ÊÑèÂäõÔºå‰ª•Âèä‰ΩøÁî®ÂΩ¢ÊÖãÈ©ÖÂãïÂ≠∏ÁøíÁöÑËá™Áõ£Áù£Â≠∏ÁøíÔºå‰ª•ÊèêÈ´òË≠òÂà•Ë§áÈõúÁµêÊßãÁöÑËÉΩÂäõ„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÂàÜÊûê‰∫ÜÂΩ±ÂÉèÁöÑÂΩ¢ÊÖãË°®Á§∫ÔºåÂú®ÂêÑÁ®ÆÈÜ´Â≠∏ÂΩ±ÂÉèÊñπÂºè‰∏≠È°ØÁ§∫Âá∫ÊØî‰ª•ÂâçÊ®°ÂûãÊõ¥Â•ΩÁöÑÁµêÊûúÔºåÂåÖÊã¨ CT„ÄÅMRI ÂíåÁóÖÁÅ∂ÂΩ±ÂÉè„ÄÇ

##### **S-SYNTH: Knowledge-Based, Synthetic Generation of Skin Images**
2408.00191v1 by Andrea Kim, Niloufar Saharkhiz, Elena Sizikova, Miguel Lago, Berkman Sahiner, Jana Delfino, Aldo Badano

Development of artificial intelligence (AI) techniques in medical imaging
requires access to large-scale and diverse datasets for training and
evaluation. In dermatology, obtaining such datasets remains challenging due to
significant variations in patient populations, illumination conditions, and
acquisition system characteristics. In this work, we propose S-SYNTH, the first
knowledge-based, adaptable open-source skin simulation framework to rapidly
generate synthetic skin, 3D models and digitally rendered images, using an
anatomically inspired multi-layer, multi-component skin and growing lesion
model. The skin model allows for controlled variation in skin appearance, such
as skin color, presence of hair, lesion shape, and blood fraction among other
parameters. We use this framework to study the effect of possible variations on
the development and evaluation of AI models for skin lesion segmentation, and
show that results obtained using synthetic data follow similar comparative
trends as real dermatologic images, while mitigating biases and limitations
from existing datasets including small dataset size, lack of diversity, and
underrepresentation.

ÊëòË¶ÅÔºö‰∫∫Â∑•Êô∫ÊÖß (AI) ÊäÄË°ìÂú®ÈÜ´Â≠∏ÂΩ±ÂÉèÊñπÈù¢ÁöÑÁôºÂ±ïÈúÄË¶ÅÂèñÂæóÂ§ßË¶èÊ®°‰∏îÂ§öÂÖÉÁöÑË≥áÊñôÈõÜÔºå‰ª•ÈÄ≤Ë°åË®ìÁ∑¥ÂíåË©ï‰º∞„ÄÇÂú®ÁöÆËÜöÁßë‰∏≠ÔºåÂèñÂæóÊ≠§È°ûË≥áÊñôÈõÜ‰ªçÁÑ∂ÂÖ∑ÊúâÊåëÊà∞ÊÄßÔºåÂéüÂõ†Âú®ÊñºÊÇ£ËÄÖÊóèÁæ§„ÄÅÁÖßÊòéÊ¢ù‰ª∂ÂíåÂèñÂæóÁ≥ªÁµ±ÁâπÊÄßÊúâÈ°ØËëóÁöÑËÆäÂåñ„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫ S-SYNTHÔºåÈÄôÊòØÁ¨¨‰∏ÄÂÄãÂü∫ÊñºÁü•Ë≠ò„ÄÅÂèØÈÅ©ÊáâÁöÑÈñãÊîæÂéüÂßãÁ¢ºÁöÆËÜöÊ®°Êì¨Êû∂ÊßãÔºåÂèØ‰ΩøÁî®Ëß£ÂâñÂ≠∏ÂïüÁôºÁöÑÂ§öÂ±§„ÄÅÂ§öÁµÑÊàêÁöÆËÜöÂíåÁîüÈï∑ÁóÖÁÅ∂Ê®°ÂûãÔºåÂø´ÈÄüÁî¢ÁîüÂêàÊàêÁöÆËÜö„ÄÅ3D Ê®°ÂûãÂíåÊï∏‰ΩçÊ∏≤ÊüìÂΩ±ÂÉè„ÄÇÁöÆËÜöÊ®°ÂûãÂÖÅË®±ÊéßÂà∂ÁöÆËÜöÂ§ñËßÄÁöÑËÆäÂåñÔºå‰æãÂ¶ÇËÜöËâ≤„ÄÅÊØõÈ´ÆÂ≠òÂú®„ÄÅÁóÖÁÅ∂ÂΩ¢ÁãÄÂíåË°ÄÊ∂≤ÊØî‰æãÁ≠âÂèÉÊï∏„ÄÇÊàëÂÄë‰ΩøÁî®ÈÄôÂÄãÊû∂Êßã‰æÜÁ†îÁ©∂ÂèØËÉΩÁöÑËÆäÂåñÂ∞çÁöÆËÜöÁóÖÁÅ∂ÂàÜÂâ≤ AI Ê®°ÂûãÁöÑÈñãÁôºÂíåË©ï‰º∞ÁöÑÂΩ±ÈüøÔºå‰∏¶È°ØÁ§∫‰ΩøÁî®ÂêàÊàêË≥áÊñôÂèñÂæóÁöÑÁµêÊûúÈÅµÂæ™ËàáÁúüÂØ¶ÁöÆËÜöÁßëÂΩ±ÂÉèÈ°û‰ººÁöÑÊØîËºÉË∂®Âã¢ÔºåÂêåÊôÇÊ∏õËºïÁèæÊúâË≥áÊñôÈõÜÁöÑÂÅèÂ∑ÆÂíåÈôêÂà∂ÔºåÂåÖÊã¨Ë≥áÊñôÈõÜË¶èÊ®°Â∞è„ÄÅÁº∫‰πèÂ§öÂÖÉÊÄß‰ª•Âèä‰ª£Ë°®ÊÄß‰∏çË∂≥„ÄÇ

##### **A Taxonomy of Stereotype Content in Large Language Models**
2408.00162v1 by Gandalf Nicolas, Aylin Caliskan

This study introduces a taxonomy of stereotype content in contemporary large
language models (LLMs). We prompt ChatGPT 3.5, Llama 3, and Mixtral 8x7B, three
powerful and widely used LLMs, for the characteristics associated with 87
social categories (e.g., gender, race, occupations). We identify 14 stereotype
dimensions (e.g., Morality, Ability, Health, Beliefs, Emotions), accounting for
~90% of LLM stereotype associations. Warmth and Competence facets were the most
frequent content, but all other dimensions were significantly prevalent.
Stereotypes were more positive in LLMs (vs. humans), but there was significant
variability across categories and dimensions. Finally, the taxonomy predicted
the LLMs' internal evaluations of social categories (e.g., how
positively/negatively the categories were represented), supporting the
relevance of a multidimensional taxonomy for characterizing LLM stereotypes.
Our findings suggest that high-dimensional human stereotypes are reflected in
LLMs and must be considered in AI auditing and debiasing to minimize
unidentified harms from reliance in low-dimensional views of bias in LLMs.

ÊëòË¶ÅÔºöÊú¨Á†îÁ©∂ÈáùÂ∞çÁï∂‰ª£Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰∏≠ÁöÑÂàªÊùøÂç∞Ë±°ÂÖßÂÆπÈÄ≤Ë°åÂàÜÈ°û„ÄÇÊàëÂÄëÊèêÁ§∫ ChatGPT 3.5„ÄÅLlama 3 Âíå Mixtral 8x7B ÈÄô‰∏âÁ®ÆÂº∑Â§ß‰∏îÂª£Ê≥õ‰ΩøÁî®ÁöÑ LLMÔºå‰∫ÜËß£Ëàá 87 ÂÄãÁ§æÊúÉÈ°ûÂà•Ôºà‰æãÂ¶ÇÊÄßÂà•„ÄÅÁ®ÆÊóè„ÄÅËÅ∑Ê•≠ÔºâÁõ∏ÈóúÁöÑÁâπÂæµ„ÄÇÊàëÂÄëË≠òÂà•Âá∫ 14 ÂÄãÂàªÊùøÂç∞Ë±°Èù¢ÂêëÔºà‰æãÂ¶ÇÈÅìÂæ∑„ÄÅËÉΩÂäõ„ÄÅÂÅ•Â∫∑„ÄÅ‰ø°‰ª∞„ÄÅÊÉÖÁ∑íÔºâÔºåÁ¥Ñ‰Ωî LLM ÂàªÊùøÂç∞Ë±°ÈóúËÅØÁöÑ 90%„ÄÇÊ∫´ÊöñÂíåËÉΩÂäõÈù¢ÂêëÊòØÊúÄÈ†ªÁπÅÁöÑÂÖßÂÆπÔºå‰ΩÜÊâÄÊúâÂÖ∂‰ªñÈù¢ÂêëÈÉΩÂæàÊôÆÈÅç„ÄÇLLM ‰∏≠ÁöÑÂàªÊùøÂç∞Ë±°ÊØî‰∫∫È°ûÊõ¥Ê≠£Èù¢Ôºå‰ΩÜ‰∏çÂêåÈ°ûÂà•ÂíåÈù¢Âêë‰πãÈñìÂ≠òÂú®È°ØËëóÂ∑ÆÁï∞„ÄÇÊúÄÂæåÔºåÂàÜÈ°ûÊ≥ïÈ†êÊ∏¨‰∫Ü LLM Â∞çÁ§æÊúÉÈ°ûÂà•ÁöÑÂÖßÈÉ®Ë©ï‰º∞Ôºà‰æãÂ¶ÇÈ°ûÂà•ÁöÑÊ≠£Èù¢/Ë≤†Èù¢ÂëàÁèæÊñπÂºèÔºâÔºåÊîØÊåÅ‰∫Ü‰ΩøÁî®Â§öÁ∂≠ÂàÜÈ°ûÊ≥ï‰æÜË°®Âæµ LLM ÂàªÊùøÂç∞Ë±°ÁöÑÁõ∏ÈóúÊÄß„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúË°®ÊòéÔºåÈ´òÁ∂≠Â∫¶ÁöÑ‰∫∫È°ûÂàªÊùøÂç∞Ë±°ÂèçÊò†Âú® LLM ‰∏≠Ôºå‰∏¶‰∏îÂøÖÈ†àÂú® AI Á®ΩÊ†∏ÂíåÊ∂àÈô§ÂÅèË¶ã‰∏≠Âä†‰ª•ËÄÉÊÖÆÔºå‰ª•Â∞á‰æùË≥¥ LLM ‰∏≠ÂÅèË¶ãÁöÑ‰ΩéÁ∂≠Â∫¶ËßÄÈªûÈÄ†ÊàêÁöÑÊú™Ë≠òÂà•Âç±ÂÆ≥ÈôçÂà∞ÊúÄ‰Ωé„ÄÇ

##### **Preference-Based Abstract Argumentation for Case-Based Reasoning (with Appendix)**
2408.00108v2 by Adam Gould, Guilherme Paulino-Passos, Seema Dadhania, Matthew Williams, Francesca Toni

In the pursuit of enhancing the efficacy and flexibility of interpretable,
data-driven classification models, this work introduces a novel incorporation
of user-defined preferences with Abstract Argumentation and Case-Based
Reasoning (CBR). Specifically, we introduce Preference-Based Abstract
Argumentation for Case-Based Reasoning (which we call AA-CBR-P), allowing users
to define multiple approaches to compare cases with an ordering that specifies
their preference over these comparison approaches. We prove that the model
inherently follows these preferences when making predictions and show that
previous abstract argumentation for case-based reasoning approaches are
insufficient at expressing preferences over constituents of an argument. We
then demonstrate how this can be applied to a real-world medical dataset
sourced from a clinical trial evaluating differing assessment methods of
patients with a primary brain tumour. We show empirically that our approach
outperforms other interpretable machine learning models on this dataset.

ÊëòË¶ÅÔºöÁÇ∫‰∫ÜÊèêÂçáÂèØËß£Èáã„ÄÅË≥áÊñôÈ©ÖÂãïÂàÜÈ°ûÊ®°ÂûãÁöÑÊïàËÉΩÂíåÈùàÊ¥ªÊÄßÔºåÊ≠§Á†îÁ©∂ÂºïÂÖ•‰∫Ü‰ΩøÁî®ËÄÖËá™Ë®ÇÂÅèÂ•ΩËàáÊäΩË±°Ë´ñË≠âÂíåÊ°à‰æãÂü∫Á§éÊé®ÁêÜ (CBR) ÁöÑÊñ∞ÁµêÂêà„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜÊ°à‰æãÂü∫Á§éÊé®ÁêÜÁöÑÂÅèÂ•ΩÂü∫Á§éÊäΩË±°Ë´ñË≠â (ÊàëÂÄëÁ®±‰πãÁÇ∫ AA-CBR-P)ÔºåÂÖÅË®±‰ΩøÁî®ËÄÖÂÆöÁæ©Â§öÁ®ÆÊñπÊ≥ï‰æÜÊØîËºÉÊ°à‰æãÔºå‰∏¶ÈÄèÈÅéÊéíÂ∫è‰æÜÊåáÂÆö‰ªñÂÄëÂ∞çÈÄô‰∫õÊØîËºÉÊñπÊ≥ïÁöÑÂÅèÂ•Ω„ÄÇÊàëÂÄëË≠âÊòé‰∫ÜÊ≠§Ê®°ÂûãÂú®ÈÄ≤Ë°åÈ†êÊ∏¨ÊôÇÊúÉËá™ÁÑ∂ÈÅµÂæ™ÈÄô‰∫õÂÅèÂ•ΩÔºå‰∏¶È°ØÁ§∫ÂÖàÂâçÊ°à‰æãÂü∫Á§éÊé®ÁêÜÁöÑÊäΩË±°Ë´ñË≠âÊñπÊ≥ï‰∏çË∂≥‰ª•Ë°®ÈÅîÂ∞çË´ñË≠âÁµÑÊàêÁöÑÂÅèÂ•Ω„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜÂ¶Ç‰ΩïÂ∞áÊ≠§ÊñπÊ≥ïÊáâÁî®ÊñºÂØ¶ÈöõÁöÑÈÜ´ÁôÇË≥áÊñôÈõÜÔºåË©≤Ë≥áÊñôÈõÜ‰æÜËá™Ë©ï‰º∞ÂéüÁôºÊÄßËÖ¶ËÖ´Áò§ÊÇ£ËÄÖ‰∏çÂêåË©ï‰º∞ÊñπÊ≥ïÁöÑËá®Â∫äË©¶È©ó„ÄÇÊàëÂÄëÁ∂ìÈ©óÊÄßÂú∞Ë≠âÊòéÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÂú®ÈÄôÂÄãË≥áÊñôÈõÜ‰∏äÂÑ™ÊñºÂÖ∂‰ªñÂèØËß£ÈáãÁöÑÊ©üÂô®Â≠∏ÁøíÊ®°Âûã„ÄÇ

##### **A Federated Learning-Friendly Approach for Parameter-Efficient Fine-Tuning of SAM in 3D Segmentation**
2407.21739v1 by Mothilal Asokan, Joseph Geo Benjamin, Mohammad Yaqub, Karthik Nandakumar

Adapting foundation models for medical image analysis requires finetuning
them on a considerable amount of data because of extreme distribution shifts
between natural (source) data used for pretraining and medical (target) data.
However, collecting task-specific medical data for such finetuning at a central
location raises many privacy concerns. Although Federated learning (FL)
provides an effective means for training on private decentralized data,
communication costs in federating large foundation models can quickly become a
significant bottleneck, impacting the solution's scalability. In this work, we
address this problem of efficient communication while ensuring effective
learning in FL by combining the strengths of Parameter-Efficient Fine-tuning
(PEFT) with FL. Specifically, we study plug-and-play Low-Rank Adapters (LoRA)
in a federated manner to adapt the Segment Anything Model (SAM) for 3D medical
image segmentation. Unlike prior works that utilize LoRA and finetune the
entire decoder, we critically analyze the contribution of each granular
component of SAM on finetuning performance. Thus, we identify specific layers
to be federated that are very efficient in terms of communication cost while
producing on-par accuracy. Our experiments show that retaining the parameters
of the SAM model (including most of the decoder) in their original state during
adaptation is beneficial because fine-tuning on small datasets tends to distort
the inherent capabilities of the underlying foundation model. On Fed-KiTS, our
approach decreases communication cost (~48x) compared to full fine-tuning while
increasing performance (~6% Dice score) in 3D segmentation tasks. Our approach
performs similar to SAMed while achieving ~2.8x reduction in communication and
parameters to be finetuned. We further validate our approach with experiments
on Fed-IXI and Prostate MRI datasets.

ÊëòË¶ÅÔºö<paragraph>Áî±ÊñºÈ†êË®ìÁ∑¥ÊâÄÁî®ÁöÑËá™ÁÑ∂Ôºà‰æÜÊ∫êÔºâË≥áÊñôÂíåÈÜ´ÁôÇÔºàÁõÆÊ®ôÔºâË≥áÊñô‰πãÈñìÁöÑÊ•µÁ´ØÂàÜ‰ΩàËΩâÁßªÔºåÂõ†Ê≠§Â∞áÂü∫Á§éÊ®°ÂûãË™øÊï¥Áî®ÊñºÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÊûêÈúÄË¶ÅÂú®Â§ßÈáèË≥áÊñô‰∏äÂ∞çÂÖ∂ÈÄ≤Ë°åÂæÆË™ø„ÄÇ
ÁÑ∂ËÄåÔºåÂú®‰∏≠ÂøÉ‰ΩçÁΩÆÊî∂ÈõÜÊ≠§È°ûÂæÆË™øÁöÑÁâπÂÆö‰ªªÂãôÈÜ´ÁôÇË≥áÊñôÊúÉÂºïÁôºË®±Â§öÈö±ÁßÅÂïèÈ°å„ÄÇÂÑòÁÆ°ËÅØÂêàÂ≠∏Áøí (FL) Êèê‰æõ‰∫Ü‰∏ÄÁ®ÆÂú®ÁßÅÊúâÂàÜÊï£ÂºèË≥áÊñô‰∏äÈÄ≤Ë°åË®ìÁ∑¥ÁöÑÊúâÊïàÊñπÊ≥ïÔºå‰ΩÜÂú®ËÅØÂêàÂ§ßÂûãÂü∫Á§éÊ®°ÂûãÊôÇÔºåÈÄöË®äÊàêÊú¨ÂèØËÉΩÊúÉËøÖÈÄüÊàêÁÇ∫‰∏ÄÂÄãÈáçÂ§ßÁì∂È†∏ÔºåÂΩ±ÈüøËß£Ê±∫ÊñπÊ°àÁöÑÂèØÊì¥ÂÖÖÊÄß„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÈÄöÈÅéÁµêÂêàÂèÉÊï∏È´òÊïàÂæÆË™ø (PEFT) Âíå FL ÁöÑÂÑ™Âã¢ÔºåËß£Ê±∫‰∫ÜÂú®Á¢∫‰øù FL ‰∏≠ÊúâÊïàÂ≠∏ÁøíÁöÑÂêåÊôÇÈÄ≤Ë°åÈ´òÊïàÈÄöË®äÁöÑÂïèÈ°å„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄë‰ª•ËÅØÂêàÁöÑÊñπÂºèÁ†îÁ©∂Âç≥ÊèíÂç≥Áî®‰ΩéÁß©ÈÅ©ÈÖçÂô® (LoRA)Ôºå‰ª•Ë™øÊï¥ÂçÄÊÆµ‰ªª‰ΩïÊ®°Âûã (SAM) ‰ª•ÈÄ≤Ë°å 3D ÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÂâ≤„ÄÇËàáÂà©Áî® LoRA ÂíåÂæÆË™øÊï¥ÂÄãËß£Á¢ºÂô®ÁöÑÂÖàÂâçÂ∑•‰Ωú‰∏çÂêåÔºåÊàëÂÄëÊâπÂà§ÊÄßÂú∞ÂàÜÊûê‰∫Ü SAM ÁöÑÊØèÂÄãÁ≤íÁãÄÁµÑÊàêÈÉ®ÂàÜÂ∞çÂæÆË™øÊïàËÉΩÁöÑË≤¢Áçª„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëÁ¢∫ÂÆö‰∫ÜÂú®ÈÄöË®äÊàêÊú¨ÊñπÈù¢ÈùûÂ∏∏È´òÊïàÁöÑÁâπÂÆöÂ±§ÔºåÂêåÊôÇÁî¢Áîü‰∫ÜÂêåÁ≠âÁöÑÊ∫ñÁ¢∫Â∫¶„ÄÇÊàëÂÄëÁöÑÂØ¶È©óË°®ÊòéÔºåÂú®Ë™øÊï¥ÈÅéÁ®ã‰∏≠Â∞á SAM Ê®°ÂûãÁöÑÂèÉÊï∏ÔºàÂåÖÊã¨Â§ßÈÉ®ÂàÜËß£Á¢ºÂô®Ôºâ‰øùÁïôÂú®ÂÖ∂ÂéüÂßãÁãÄÊÖãÊòØÊúâÁõäÁöÑÔºåÂõ†ÁÇ∫Âú®Â∞èÂûãË≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÂæÆË™øÂæÄÂæÄÊúÉÊâ≠Êõ≤Âü∫Á§éÊ®°ÂûãÁöÑÂÖßÂú®ËÉΩÂäõ„ÄÇÂú® Fed-KiTS ‰∏äÔºåËàáÂÆåÂÖ®ÂæÆË™øÁõ∏ÊØîÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÈôç‰Ωé‰∫ÜÈÄöË®äÊàêÊú¨ÔºàÁ¥Ñ 48 ÂÄçÔºâÔºåÂêåÊôÇÊèêÈ´ò‰∫Ü 3D ÂàÜÂâ≤‰ªªÂãô‰∏≠ÁöÑÊïàËÉΩÔºàÁ¥Ñ 6% ÁöÑÈ™∞Â≠êÂàÜÊï∏Ôºâ„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïËàá SAMed È°û‰ººÔºåÂêåÊôÇÂ∞áÈÄöË®äÂíåÂæÖÂæÆË™øÂèÉÊï∏Ê∏õÂ∞ë‰∫ÜÁ¥Ñ 2.8 ÂÄç„ÄÇÊàëÂÄëÈÄ≤‰∏ÄÊ≠•ÈÄöÈÅéÂú® Fed-IXI Âíå Prostate MRI Ë≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÂØ¶È©óÈ©óË≠â‰∫ÜÊàëÂÄëÁöÑÂÅöÊ≥ï„ÄÇ</paragraph>

##### **Synthetic Simplicity: Unveiling Bias in Medical Data Augmentation**
2407.21674v1 by Krishan Agyakari Raja Babu, Rachana Sathish, Mrunal Pattanaik, Rahul Venkataramani

Synthetic data is becoming increasingly integral in data-scarce fields such
as medical imaging, serving as a substitute for real data. However, its
inherent statistical characteristics can significantly impact downstream tasks,
potentially compromising deployment performance. In this study, we empirically
investigate this issue and uncover a critical phenomenon: downstream neural
networks often exploit spurious distinctions between real and synthetic data
when there is a strong correlation between the data source and the task label.
This exploitation manifests as \textit{simplicity bias}, where models overly
rely on superficial features rather than genuine task-related complexities.
Through principled experiments, we demonstrate that the source of data (real
vs.\ synthetic) can introduce spurious correlating factors leading to poor
performance during deployment when the correlation is absent. We first
demonstrate this vulnerability on a digit classification task, where the model
spuriously utilizes the source of data instead of the digit to provide an
inference. We provide further evidence of this phenomenon in a medical imaging
problem related to cardiac view classification in echocardiograms, particularly
distinguishing between 2-chamber and 4-chamber views. Given the increasing role
of utilizing synthetic datasets, we hope that our experiments serve as
effective guidelines for the utilization of synthetic datasets in model
training.

ÊëòË¶ÅÔºöÂêàÊàêË≥áÊñôÂú®Ë≥áÊñôÁ®ÄÂ∞ëÁöÑÈ†òÂüü‰∏≠ËÆäÂæóË∂ä‰æÜË∂ä‰∏çÂèØÊàñÁº∫Ôºå‰æãÂ¶ÇÈÜ´Â≠∏ÂΩ±ÂÉèÔºåÁî®‰ΩúÁúüÂØ¶Ë≥áÊñôÁöÑÊõø‰ª£ÂìÅ„ÄÇÁÑ∂ËÄåÔºåÂÖ∂ÂÖßÂú®ÁöÑÁµ±Ë®àÁâπÊÄßÊúÉÈ°ØËëóÂΩ±Èüø‰∏ãÊ∏∏‰ªªÂãôÔºåÂèØËÉΩÊêçÂÆ≥ÈÉ®ÁΩ≤ÊïàËÉΩ„ÄÇÂú®Êú¨Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëÂØ¶Ë≠âË™øÊü•Ê≠§ÂïèÈ°åÔºå‰∏¶Êè≠Èú≤‰∏ÄÂÄãÈóúÈçµÁèæË±°ÔºöÁï∂Ë≥áÊñô‰æÜÊ∫êËàá‰ªªÂãôÊ®ôÁ±§‰πãÈñìÊúâÂæàÂº∑ÁöÑÁõ∏ÈóúÊÄßÊôÇÔºå‰∏ãÊ∏∏Á•ûÁ∂ìÁ∂≤Ë∑ØÈÄöÂ∏∏ÊúÉÂà©Áî®ÁúüÂØ¶Ë≥áÊñôËàáÂêàÊàêË≥áÊñô‰πãÈñìÁöÑËôõÂÅáÂçÄÂà•„ÄÇÈÄôÁ®ÆÂà©Áî®Ë°®ÁèæÁÇ∫„ÄåÁ∞°ÂåñÂÅèÂ∑Æ„ÄçÔºåÂÖ∂‰∏≠Ê®°ÂûãÈÅéÂ∫¶‰æùË≥¥Ë°®Èù¢ÁâπÂæµÔºåËÄå‰∏çÊòØÁúüÊ≠£ÁöÑËàá‰ªªÂãôÁõ∏ÈóúÁöÑË§áÈõúÊÄß„ÄÇÈÄèÈÅéÊúâÂéüÂâáÁöÑÂØ¶È©óÔºåÊàëÂÄëË≠âÊòéË≥áÊñô‰æÜÊ∫êÔºàÁúüÂØ¶Ë≥áÊñôËàáÂêàÊàêË≥áÊñôÔºâÂèØËÉΩÊúÉÂºïÂÖ•ËôõÂÅáÁöÑÁõ∏ÈóúÂõ†Á¥†ÔºåÂ∞éËá¥Âú®Áõ∏ÈóúÊÄß‰∏çÂ≠òÂú®ÊôÇÈÉ®ÁΩ≤ÊúüÈñìÊïàËÉΩ‰∏ç‰Ω≥„ÄÇÊàëÂÄëÈ¶ñÂÖàÂú®Êï∏Â≠óÂàÜÈ°û‰ªªÂãô‰∏≠Ë≠âÊòéÊ≠§ÊºèÊ¥ûÔºåÂÖ∂‰∏≠Ê®°ÂûãËôõÂÅáÂú∞Âà©Áî®Ë≥áÊñô‰æÜÊ∫êËÄåÈùûÊï∏Â≠ó‰æÜÊèê‰æõÊé®Ë´ñ„ÄÇÊàëÂÄëÂú®ËàáË∂ÖÈü≥Ê≥¢ÂøÉËáüË¶ñÈáéÂàÜÈ°ûÁõ∏ÈóúÁöÑÈÜ´Â≠∏ÂΩ±ÂÉèÂïèÈ°å‰∏≠ÈÄ≤‰∏ÄÊ≠•Êèê‰æõÊ≠§ÁèæË±°ÁöÑË≠âÊìöÔºåÁâπÂà•ÊòØÂçÄÂàÜ‰∫åËÖîÂíåÂõõËÖîË¶ñÈáé„ÄÇÈëëÊñºÂêàÊàêË≥áÊñôÈõÜÁöÑ‰ΩøÁî®ËßíËâ≤Êó•ÁõäÂ¢ûÂä†ÔºåÊàëÂÄëÂ∏åÊúõÊàëÂÄëÁöÑÂØ¶È©óËÉΩ‰ΩúÁÇ∫Âú®Ê®°ÂûãË®ìÁ∑¥‰∏≠Âà©Áî®ÂêàÊàêË≥áÊñôÈõÜÁöÑÊúâÊïàÊåáÂçó„ÄÇ

##### **Quality Control for Radiology Report Generation Models via Auxiliary Auditing Components**
2407.21638v1 by Hermione Warr, Yasin Ibrahim, Daniel R. McGowan, Konstantinos Kamnitsas

Automation of medical image interpretation could alleviate bottlenecks in
diagnostic workflows, and has become of particular interest in recent years due
to advancements in natural language processing. Great strides have been made
towards automated radiology report generation via AI, yet ensuring clinical
accuracy in generated reports is a significant challenge, hindering deployment
of such methods in clinical practice. In this work we propose a quality control
framework for assessing the reliability of AI-generated radiology reports with
respect to semantics of diagnostic importance using modular auxiliary auditing
components (AC). Evaluating our pipeline on the MIMIC-CXR dataset, our findings
show that incorporating ACs in the form of disease-classifiers can enable
auditing that identifies more reliable reports, resulting in higher F1 scores
compared to unfiltered generated reports. Additionally, leveraging the
confidence of the AC labels further improves the audit's effectiveness.

ÊëòË¶ÅÔºöÈÜ´ÁôÇÂΩ±ÂÉèÂà§ËÆÄÁöÑËá™ÂãïÂåñÂèØ‰ª•Ê∏õËºïË®∫Êñ∑Â∑•‰ΩúÊµÅÁ®ã‰∏≠ÁöÑÁì∂È†∏Ôºå‰∏¶‰∏îÁî±ÊñºËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜÁöÑÈÄ≤Ê≠•ÔºåÂú®ËøëÂπ¥‰æÜÁâπÂà•ÂèóÂà∞ÈáçË¶ñ„ÄÇÂú®ÈÄèÈÅé AI Ëá™ÂãïÁîüÊàêÊîæÂ∞ÑÁ∑öÂ†±ÂëäÊñπÈù¢Â∑≤Á∂ìÂèñÂæó‰∫ÜÈï∑Ë∂≥ÁöÑÈÄ≤Â±ïÔºåÁÑ∂ËÄåÁ¢∫‰øùÁîüÊàêÂ†±ÂëäÁöÑËá®Â∫äÊ∫ñÁ¢∫ÊÄßÊòØ‰∏ÄÈ†ÖÈáçÂ§ßÁöÑÊåëÊà∞ÔºåÈòªÁ§ô‰∫ÜÊ≠§È°ûÊñπÊ≥ïÂú®Ëá®Â∫äÂØ¶Âãô‰∏≠ÁöÑÈÉ®ÁΩ≤„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂìÅË≥™ÊéßÂà∂Êû∂ÊßãÔºåÁî®ÊñºË©ï‰º∞ AI ÁîüÊàêÁöÑÊîæÂ∞ÑÁ∑öÂ†±ÂëäÁöÑÂèØÈù†ÊÄßÔºå‰∏¶‰ΩøÁî®Ê®°ÁµÑÂåñËºîÂä©Á®ΩÊ†∏ÂÖÉ‰ª∂ (AC) ÈáùÂ∞çË®∫Êñ∑ÈáçË¶ÅÊÄßÁöÑË™ûÁæ©ÈÄ≤Ë°åË©ï‰º∞„ÄÇÂú® MIMIC-CXR Ë≥áÊñôÈõÜ‰∏äË©ï‰º∞ÊàëÂÄëÁöÑÁÆ°ÈÅìÔºåÊàëÂÄëÁöÑÁôºÁèæÈ°ØÁ§∫Ôºå‰ª•ÁñæÁóÖÂàÜÈ°ûÂô®ÁöÑÂΩ¢ÂºèÁ¥çÂÖ• AC ÂèØ‰ª•ÂïüÁî®Á®ΩÊ†∏Ôºå‰ª•Ë≠òÂà•Êõ¥ÂèØÈù†ÁöÑÂ†±ÂëäÔºåËàáÊú™Á∂ìÁØ©ÈÅ∏ÁöÑÁîüÊàêÂ†±ÂëäÁõ∏ÊØîÔºåÊúÉÁî¢ÁîüÊõ¥È´òÁöÑ F1 ÂàÜÊï∏„ÄÇÊ≠§Â§ñÔºåÈÄ≤‰∏ÄÊ≠•Âà©Áî® AC Ê®ôÁ±§ÁöÑ‰ø°ÂøÉÂèØ‰ª•ÊèêÈ´òÁ®ΩÊ†∏ÁöÑÊúâÊïàÊÄß„ÄÇ

##### **Optimizing Disease Prediction with Artificial Intelligence Driven Feature Selection and Attention Networks**
2408.03151v1 by D. Dhinakaran, S. Edwin Raja, M. Thiyagarajan, J. Jeno Jasmine, P. Raghavan

The rapid integration of machine learning methodologies in healthcare has
ignited innovative strategies for disease prediction, particularly with the
vast repositories of Electronic Health Records (EHR) data. This article delves
into the realm of multi-disease prediction, presenting a comprehensive study
that introduces a pioneering ensemble feature selection model. This model,
designed to optimize learning systems, combines statistical, deep, and
optimally selected features through the innovative Stabilized Energy Valley
Optimization with Enhanced Bounds (SEV-EB) algorithm. The objective is to
achieve unparalleled accuracy and stability in predicting various disorders.
This work proposes an advanced ensemble model that synergistically integrates
statistical, deep, and optimally selected features. This combination aims to
enhance the predictive power of the model by capturing diverse aspects of the
health data. At the heart of the proposed model lies the SEV-EB algorithm, a
novel approach to optimal feature selection. The algorithm introduces enhanced
bounds and stabilization techniques, contributing to the robustness and
accuracy of the overall prediction model. To further elevate the predictive
capabilities, an HSC-AttentionNet is introduced. This network architecture
combines deep temporal convolution capabilities with LSTM, allowing the model
to capture both short-term patterns and long-term dependencies in health data.
Rigorous evaluations showcase the remarkable performance of the proposed model.
Achieving a 95% accuracy and 94% F1-score in predicting various disorders, the
model surpasses traditional methods, signifying a significant advancement in
disease prediction accuracy. The implications of this research extend beyond
the confines of academia.

ÊëòË¶ÅÔºö<paragraph>Ê©üÂô®Â≠∏ÁøíÊñπÊ≥ïÂú®ÈÜ´ÁôÇ‰øùÂÅ•È†òÂüüÁöÑÂø´ÈÄüÊï¥ÂêàÔºåÈªûÁáÉ‰∫ÜÁñæÁóÖÈ†êÊ∏¨ÁöÑÂâµÊñ∞Á≠ñÁï•ÔºåÁâπÂà•ÊòØÈõªÂ≠êÂÅ•Â∫∑Ë®òÈåÑ (EHR) Ë≥áÊñôÁöÑÈæêÂ§ßÂÑ≤Â≠òÂ∫´„ÄÇÊú¨ÊñáÊ∑±ÂÖ•Êé¢Ë®éÂ§öÁñæÁóÖÈ†êÊ∏¨ÁöÑÈ†òÂüüÔºåÊèêÂá∫‰∫Ü‰∏ÄÈ†ÖÂÖ®Èù¢ÁöÑÁ†îÁ©∂Ôºå‰ªãÁ¥π‰∫Ü‰∏ÄÂÄãÈñãÂâµÊÄßÁöÑÈõÜÊàêÁâπÂæµÈÅ∏ÊìáÊ®°Âûã„ÄÇÈÄôÂÄãÊ®°ÂûãÊó®Âú®ÂÑ™ÂåñÂ≠∏ÁøíÁ≥ªÁµ±ÔºåÁµêÂêàÁµ±Ë®à„ÄÅÊ∑±Â∫¶ÂíåÊúÄ‰Ω≥ÈÅ∏ÊìáÁöÑÁâπÂæµÔºåÈÄèÈÅéÂâµÊñ∞ÁöÑÁ©©ÂÆöËÉΩÈáèË∞∑ÂÑ™ÂåñËàáÂ¢ûÂº∑ÈÇäÁïå (SEV-EB) ÊºîÁÆóÊ≥ï„ÄÇÁõÆÊ®ôÊòØÂú®È†êÊ∏¨ÂêÑÁ®ÆÁñæÁóÖÊôÇÈÅîÂà∞ÁÑ°ËàáÂÄ´ÊØîÁöÑÊ∫ñÁ¢∫ÊÄßÂíåÁ©©ÂÆöÊÄß„ÄÇÈÄôÈ†ÖÁ†îÁ©∂ÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂÖàÈÄ≤ÁöÑÈõÜÊàêÊ®°ÂûãÔºåÂçîÂêåÊï¥ÂêàÁµ±Ë®à„ÄÅÊ∑±Â∫¶ÂíåÊúÄ‰Ω≥ÈÅ∏ÊìáÁöÑÁâπÂæµ„ÄÇÈÄôÁ®ÆÁµÑÂêàÊó®Âú®ÈÄèÈÅéÊì∑ÂèñÂÅ•Â∫∑Ë≥áÊñôÁöÑ‰∏çÂêåÈù¢ÂêëÔºå‰æÜÂ¢ûÂº∑Ê®°ÂûãÁöÑÈ†êÊ∏¨ËÉΩÂäõ„ÄÇÊâÄÊèêÂá∫ÁöÑÊ®°ÂûãÊ†∏ÂøÉÂú®Êñº SEV-EB ÊºîÁÆóÊ≥ïÔºå‰∏ÄÁ®ÆÊúÄ‰Ω≥ÁâπÂæµÈÅ∏ÊìáÁöÑÊñ∞ÊñπÊ≥ï„ÄÇË©≤ÊºîÁÆóÊ≥ïÂºïÂÖ•‰∫ÜÂ¢ûÂº∑ÁöÑÈÇäÁïåÂíåÁ©©ÂÆöÊäÄË°ìÔºåÊúâÂä©ÊñºÊï¥È´îÈ†êÊ∏¨Ê®°ÂûãÁöÑÁ©©ÂÅ•ÊÄßÂíåÊ∫ñÁ¢∫ÊÄß„ÄÇÁÇ∫‰∫ÜÈÄ≤‰∏ÄÊ≠•ÊèêÂçáÈ†êÊ∏¨ËÉΩÂäõÔºåÂºïÂÖ•‰∫Ü HSC-AttentionNet„ÄÇÈÄôÂÄãÁ∂≤Ë∑ØÊû∂ÊßãÁµêÂêà‰∫ÜÊ∑±Â∫¶ÊôÇÈñìÂç∑Á©çÂäüËÉΩËàá LSTMÔºå‰ΩøÊ®°ÂûãËÉΩÂ§†Êì∑ÂèñÂÅ•Â∫∑Ë≥áÊñô‰∏≠ÁöÑÁü≠ÊúüÊ®°ÂºèÂíåÈï∑Êúü‰æùË≥¥ÊÄß„ÄÇÂö¥Ë¨πÁöÑË©ï‰º∞Â±ïÁ§∫‰∫ÜÊâÄÊèêÂá∫Ê®°ÂûãÁöÑÂçìË∂äÊïàËÉΩ„ÄÇÂú®È†êÊ∏¨ÂêÑÁ®ÆÁñæÁóÖÊôÇÈÅîÂà∞ 95% ÁöÑÊ∫ñÁ¢∫Â∫¶Âíå 94% ÁöÑ F1 ÂàÜÊï∏ÔºåË©≤Ê®°ÂûãË∂ÖË∂ä‰∫ÜÂÇ≥Áµ±ÊñπÊ≥ïÔºåÊ®ôË™åËëóÁñæÁóÖÈ†êÊ∏¨Ê∫ñÁ¢∫ÊÄßÁöÑÈáçÂ§ßÈÄ≤Â±ï„ÄÇÈÄôÈ†ÖÁ†îÁ©∂ÁöÑÊÑèÁæ©Ë∂ÖË∂ä‰∫ÜÂ≠∏Ë°ìÁïå„ÄÇ</paragraph>

##### **Voxel Scene Graph for Intracranial Hemorrhage**
2407.21580v1 by Antoine P. Sanner, Nils F. Grauhan, Marc A. Brockmann, Ahmed E. Othman, Anirban Mukhopadhyay

Patients with Intracranial Hemorrhage (ICH) face a potentially
life-threatening condition, and patient-centered individualized treatment
remains challenging due to possible clinical complications. Deep-Learning-based
methods can efficiently analyze the routinely acquired head CTs to support the
clinical decision-making. The majority of early work focuses on the detection
and segmentation of ICH, but do not model the complex relations between ICH and
adjacent brain structures. In this work, we design a tailored object detection
method for ICH, which we unite with segmentation-grounded Scene Graph
Generation (SGG) methods to learn a holistic representation of the clinical
cerebral scene. To the best of our knowledge, this is the first application of
SGG for 3D voxel images. We evaluate our method on two head-CT datasets and
demonstrate that our model can recall up to 74% of clinically relevant
relations. This work lays the foundation towards SGG for 3D voxel data. The
generated Scene Graphs can already provide insights for the clinician, but are
also valuable for all downstream tasks as a compact and interpretable
representation.

ÊëòË¶ÅÔºöËÖ¶Âá∫Ë°Ä (ICH) ÊÇ£ËÄÖÈù¢Ëá®ÂèØËÉΩÂç±ÂèäÁîüÂëΩÁöÑÁãÄÊ≥ÅÔºåÁî±ÊñºÂèØËÉΩÁöÑËá®Â∫ä‰ΩµÁôºÁóáÔºå‰ª•ÊÇ£ËÄÖÁÇ∫‰∏≠ÂøÉÁöÑÂÄã‰∫∫ÂåñÊ≤ªÁôÇ‰ªçÁÑ∂ÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÂü∫ÊñºÊ∑±Â∫¶Â≠∏ÁøíÁöÑÊñπÊ≥ïÂèØ‰ª•ÊúâÊïàÂàÜÊûêÂ∏∏Ë¶èÁç≤ÂæóÁöÑÈ†≠ÈÉ®ÈõªËÖ¶Êñ∑Â±§ÊéÉÊèèÔºå‰ª•ÊîØÊåÅËá®Â∫äÊ±∫Á≠ñÂà∂ÂÆö„ÄÇÂ§ßÂ§öÊï∏Êó©ÊúüÂ∑•‰ΩúÈÉΩÈõÜ‰∏≠Âú® ICH ÁöÑÊ™¢Ê∏¨ÂíåÂàÜÂâ≤Ôºå‰ΩÜÊ≤íÊúâÂ∞ç ICH ÂíåÁõ∏ÈÑ∞Â§ßËÖ¶ÁµêÊßã‰πãÈñìÁöÑË§áÈõúÈóú‰øÇÈÄ≤Ë°åÂª∫Ê®°„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëË®≠Ë®à‰∫Ü‰∏ÄÁ®ÆÈáùÂ∞ç ICH ÁöÑÂÆ¢Ë£ΩÂåñÁõÆÊ®ôÊ™¢Ê∏¨ÊñπÊ≥ïÔºåÊàëÂÄëÂ∞áÂÖ∂ËàáÂü∫ÊñºÂàÜÂâ≤ÁöÑÂ†¥ÊôØÂúñÁîüÊàê (SGG) ÊñπÊ≥ïÁµêÂêàÔºå‰ª•Â≠∏ÁøíËá®Â∫äËÖ¶ÈÉ®Â†¥ÊôØÁöÑÊï¥È´îË°®Âæµ„ÄÇÊìöÊàëÂÄëÊâÄÁü•ÔºåÈÄôÊòØ SGG Á¨¨‰∏ÄÊ¨°ÊáâÁî®Êñº 3D È´îÁ¥†ÂΩ±ÂÉè„ÄÇÊàëÂÄëÂú®ÂÖ©ÂÄãÈ†≠ÈÉ®ÈõªËÖ¶Êñ∑Â±§ÊéÉÊèèÊï∏ÊìöÈõÜ‰∏äË©ï‰º∞ÊàëÂÄëÁöÑÊ®°ÂûãÔºå‰∏¶Ë≠âÊòéÊàëÂÄëÁöÑÊ®°ÂûãÂèØ‰ª•Âè¨ÂõûÈ´òÈÅî 74% ÁöÑËá®Â∫äÁõ∏ÈóúÈóú‰øÇ„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÁÇ∫ 3D È´îÁ¥†Êï∏ÊìöÁöÑ SGG Â•†ÂÆö‰∫ÜÂü∫Á§é„ÄÇÁîüÊàêÁöÑÂ†¥ÊôØÂúñÂ∑≤Á∂ìÂèØ‰ª•ÁÇ∫Ëá®Â∫äÈÜ´ÁîüÊèê‰æõË¶ãËß£Ôºå‰ΩÜÂ∞çÊñºÊâÄÊúâ‰∏ãÊ∏∏‰ªªÂãôËÄåË®ÄÔºåÂÆÉ‰πüÊòØ‰∏ÄÁ®ÆÁ≤æÁ∞°‰∏îÂèØËß£ÈáãÁöÑË°®ÂæµÔºåÂõ†Ê≠§ÈùûÂ∏∏ÊúâÂÉπÂÄº„ÄÇ

##### **Expanding the Medical Decathlon dataset: segmentation of colon and colorectal cancer from computed tomography images**
2407.21516v1 by I. M. Chernenkiy, Y. A. Drach, S. R. Mustakimova, V. V. Kazantseva, N. A. Ushakov, S. K. Efetov, M. V. Feldsherov

Colorectal cancer is the third-most common cancer in the Western Hemisphere.
The segmentation of colorectal and colorectal cancer by computed tomography is
an urgent problem in medicine. Indeed, a system capable of solving this problem
will enable the detection of colorectal cancer at early stages of the disease,
facilitate the search for pathology by the radiologist, and significantly
accelerate the process of diagnosing the disease. However, scientific
publications on medical image processing mostly use closed, non-public data.
This paper presents an extension of the Medical Decathlon dataset with
colorectal markups in order to improve the quality of segmentation algorithms.
An experienced radiologist validated the data, categorized it into subsets by
quality, and published it in the public domain. Based on the obtained results,
we trained neural network models of the UNet architecture with 5-part
cross-validation and achieved a Dice metric quality of $0.6988 \pm 0.3$. The
published markups will improve the quality of colorectal cancer detection and
simplify the radiologist's job for study description.

ÊëòË¶ÅÔºöÂ§ßËÖ∏ÁôåÊòØË•øÂçäÁêÉÁ¨¨‰∏âÂ∏∏Ë¶ãÁöÑÁôåÁóá„ÄÇ
Âà©Áî®ÈõªËÖ¶Êñ∑Â±§ÊéÉÊèèÂ∞çÂ§ßËÖ∏ÁôåËàáÂ§ßËÖ∏ÁôåÈÄ≤Ë°åÂàÜÊÆµÊòØÈÜ´Â≠∏‰∏äÁöÑÁ∑äÊÄ•ÂïèÈ°å„ÄÇ‰∫ãÂØ¶‰∏äÔºå‰∏ÄÂÄãËÉΩÂ§†Ëß£Ê±∫ÈÄôÂÄãÂïèÈ°åÁöÑÁ≥ªÁµ±Â∞áËÉΩÂ§†Âú®ÁñæÁóÖÁöÑÊó©ÊúüÈöéÊÆµÂÅµÊ∏¨Â§ßËÖ∏ÁôåÔºåÂçîÂä©ÊîæÂ∞ÑÁßëÈÜ´Â∏´Â∞ãÊâæÁóÖÁêÜÔºå‰∏¶È°ØËëóÂä†ÈÄüË®∫Êñ∑ÁñæÁóÖÁöÑÈÅéÁ®ã„ÄÇÁÑ∂ËÄåÔºåÈóúÊñºÈÜ´Â≠∏ÂΩ±ÂÉèËôïÁêÜÁöÑÁßëÂ≠∏ÂàäÁâ©Â§ßÂ§ö‰ΩøÁî®Â∞ÅÈñâ„ÄÅÈùûÂÖ¨ÈñãÁöÑË≥áÊñô„ÄÇÈÄôÁØáË´ñÊñáÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂ∏∂ÊúâÂ§ßËÖ∏Ê®ôË®òÁöÑÈÜ´Â≠∏ÂçÅÈ†ÖÂÖ®ËÉΩË≥áÊñôÈõÜÁöÑÂª∂‰º∏Ôºå‰ª•ÊèêÈ´òÂàÜÊÆµÊºîÁÆóÊ≥ïÁöÑÂìÅË≥™„ÄÇ‰∏Ä‰ΩçÁ∂ìÈ©óË±êÂØåÁöÑÊîæÂ∞ÑÁßëÈÜ´Â∏´È©óË≠â‰∫ÜË≥áÊñôÔºåÂ∞áÂÖ∂‰æùÂìÅË≥™ÂàÜÈ°ûÊàêÂ≠êÈõÜÔºå‰∏¶Â∞áÂÖ∂ÁôºÂ∏ÉÂú®ÂÖ¨ÂÖ±È†òÂüü„ÄÇÊ†πÊìöÁç≤ÂæóÁöÑÁµêÊûúÔºåÊàëÂÄëË®ìÁ∑¥‰∫ÜÂÖ∑Êúâ 5 ÈÉ®ÂàÜ‰∫§ÂèâÈ©óË≠âÁöÑ UNet Êû∂ÊßãÁöÑÁ•ûÁ∂ìÁ∂≤Ë∑ØÊ®°ÂûãÔºå‰∏¶ÈÅîÂà∞‰∫Ü $0.6988 \pm 0.3$ ÁöÑ Dice ÊåáÊ®ôÂìÅË≥™„ÄÇÁôºÂ∏ÉÁöÑÊ®ôË®òÂ∞áÊèêÈ´òÂ§ßËÖ∏ÁôåÂÅµÊ∏¨ÁöÑÂìÅË≥™Ôºå‰∏¶Á∞°ÂåñÊîæÂ∞ÑÁßëÈÜ´Â∏´Á†îÁ©∂ÊèèËø∞ÁöÑÂ∑•‰Ωú„ÄÇ

##### **Explainable and Controllable Motion Curve Guided Cardiac Ultrasound Video Generation**
2407.21490v1 by Junxuan Yu, Rusi Chen, Yongsong Zhou, Yanlin Chen, Yaofei Duan, Yuhao Huang, Han Zhou, Tan Tao, Xin Yang, Dong Ni

Echocardiography video is a primary modality for diagnosing heart diseases,
but the limited data poses challenges for both clinical teaching and machine
learning training. Recently, video generative models have emerged as a
promising strategy to alleviate this issue. However, previous methods often
relied on holistic conditions during generation, hindering the flexible
movement control over specific cardiac structures. In this context, we propose
an explainable and controllable method for echocardiography video generation,
taking an initial frame and a motion curve as guidance. Our contributions are
three-fold. First, we extract motion information from each heart substructure
to construct motion curves, enabling the diffusion model to synthesize
customized echocardiography videos by modifying these curves. Second, we
propose the structure-to-motion alignment module, which can map semantic
features onto motion curves across cardiac structures. Third, The
position-aware attention mechanism is designed to enhance video consistency
utilizing Gaussian masks with structural position information. Extensive
experiments on three echocardiography datasets show that our method outperforms
others regarding fidelity and consistency. The full code will be released at
https://github.com/mlmi-2024-72/ECM.

ÊëòË¶ÅÔºöË∂ÖÈü≥Ê≥¢ÂøÉÂãïÂúñÂΩ±ÁâáÊòØË®∫Êñ∑ÂøÉËáüÁñæÁóÖÁöÑ‰∏ªË¶ÅÊñπÂºèÔºå
‰ΩÜÊúâÈôêÁöÑÊï∏ÊìöÂ∞çËá®Â∫äÊïôÂ≠∏ÂíåÊ©üÂô®Â≠∏ÁøíË®ìÁ∑¥ÈÉΩÊßãÊàêÊåëÊà∞„ÄÇÊúÄËøëÔºåÂΩ±ÁâáÁîüÊàêÊ®°ÂûãÂ∑≤ÊàêÁÇ∫Á∑©Ëß£Ê≠§ÂïèÈ°åÁöÑ‰∏ÄÁ®ÆÊúâÂâçÈÄîÁöÑÁ≠ñÁï•„ÄÇÁÑ∂ËÄåÔºåÂÖàÂâçÁöÑËæ¶Ê≥ïÂú®ÁîüÊàêÈÅéÁ®ã‰∏≠ÈÄöÂ∏∏‰æùË≥¥Êï¥È´îÊ¢ù‰ª∂ÔºåÈòªÁ§ô‰∫ÜÂ∞çÁâπÂÆöÂøÉËáüÁµêÊßãÁöÑÈùàÊ¥ªÈÅãÂãïÊéßÂà∂„ÄÇÂú®Ê≠§ËÉåÊôØ‰∏ãÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂèØËß£Èáã‰∏îÂèØÊéßÁöÑË∂ÖÈü≥Ê≥¢ÂøÉÂãïÂúñÂΩ±ÁâáÁîüÊàêÊñπÊ≥ïÔºå‰ª•ÂàùÂßãÂπÄÂíåÈÅãÂãïÊõ≤Á∑ö‰ΩúÁÇ∫ÊåáÂ∞é„ÄÇÊàëÂÄëÁöÑË≤¢ÁçªÊúâ‰∏âÊñπÈù¢„ÄÇÈ¶ñÂÖàÔºåÊàëÂÄëÂæûÊØèÂÄãÂøÉËáüÂ≠êÁµêÊßã‰∏≠ÊèêÂèñÈÅãÂãïË≥áË®ä‰ª•Âª∫ÊßãÈÅãÂãïÊõ≤Á∑öÔºåËÆìÊì¥Êï£Ê®°ÂûãËÉΩÂ§†ÈÄèÈÅé‰øÆÊîπÈÄô‰∫õÊõ≤Á∑ö‰æÜÂêàÊàêÂÆ¢Ë£ΩÂåñÁöÑË∂ÖÈü≥Ê≥¢ÂøÉÂãïÂúñÂΩ±Áâá„ÄÇÂÖ∂Ê¨°ÔºåÊàëÂÄëÊèêÂá∫‰∫ÜÁµêÊßãÂà∞ÈÅãÂãïÂ∞çÈΩäÊ®°ÁµÑÔºåÂÆÉÂèØ‰ª•Â∞áË™ûÁæ©ÁâπÂæµÂ∞çÊáâÂà∞ÂøÉËáüÁµêÊßã‰∏≠ÁöÑÈÅãÂãïÊõ≤Á∑ö„ÄÇÁ¨¨‰∏âÔºå‰ΩçÁΩÆÊÑüÁü•Ê≥®ÊÑèÂäõÊ©üÂà∂Êó®Âú®Âà©Áî®ÂÖ∑ÊúâÁµêÊßã‰ΩçÁΩÆË≥áË®äÁöÑÈ´òÊñØÈÅÆÁΩ©‰æÜÂ¢ûÂº∑ÂΩ±ÁâáÁöÑ‰∏ÄËá¥ÊÄß„ÄÇÂú®‰∏âÂÄãË∂ÖÈü≥Ê≥¢ÂøÉÂãïÂúñË≥áÊñôÈõÜ‰∏äÁöÑÂª£Ê≥õÂØ¶È©óÈ°ØÁ§∫ÔºåÊàëÂÄëÁöÑËæ¶Ê≥ïÂú®‰øùÁúüÂ∫¶Âíå‰∏ÄËá¥ÊÄßÊñπÈù¢ÂÑ™ÊñºÂÖ∂‰ªñËæ¶Ê≥ï„ÄÇÂÆåÊï¥Á®ãÂºèÁ¢ºÂ∞áÂú® https://github.com/mlmi-2024-72/ECM ‰∏äÈáãÂá∫„ÄÇ

