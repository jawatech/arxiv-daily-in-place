{"2407.08990": {"publish_time": "2024-07-12", "title": "Dynamic neural network with memristive CIM and CAM for 2D and 3D vision", "paper_summary": "The brain is dynamic, associative and efficient. It reconfigures by\nassociating the inputs with past experiences, with fused memory and processing.\nIn contrast, AI models are static, unable to associate inputs with past\nexperiences, and run on digital computers with physically separated memory and\nprocessing. We propose a hardware-software co-design, a semantic memory-based\ndynamic neural network (DNN) using memristor. The network associates incoming\ndata with the past experience stored as semantic vectors. The network and the\nsemantic memory are physically implemented on noise-robust ternary\nmemristor-based Computing-In-Memory (CIM) and Content-Addressable Memory (CAM)\ncircuits, respectively. We validate our co-designs, using a 40nm memristor\nmacro, on ResNet and PointNet++ for classifying images and 3D points from the\nMNIST and ModelNet datasets, which not only achieves accuracy on par with\nsoftware but also a 48.1% and 15.9% reduction in computational budget.\nMoreover, it delivers a 77.6% and 93.3% reduction in energy consumption.", "paper_summary_zh": "\u5927\u8166\u662f\u52d5\u614b\u3001\u806f\u60f3\u4e14\u6709\u6548\u7387\u7684\u3002\u5b83\u900f\u904e\u5c07\u8f38\u5165\u8207\u904e\u53bb\u7684\u7d93\u9a57\u3001\u878d\u5408\u7684\u8a18\u61b6\u548c\u8655\u7406\u806f\u60f3\u8d77\u4f86\uff0c\u91cd\u65b0\u914d\u7f6e\u3002\n\u76f8\u53cd\u5730\uff0cAI \u6a21\u578b\u662f\u975c\u614b\u7684\uff0c\u7121\u6cd5\u5c07\u8f38\u5165\u8207\u904e\u53bb\u7684\u7d93\u9a57\u806f\u60f3\u8d77\u4f86\uff0c\u4e26\u5728\u5177\u6709\u7269\u7406\u5206\u96e2\u7684\u8a18\u61b6\u9ad4\u548c\u8655\u7406\u529f\u80fd\u7684\u6578\u4f4d\u96fb\u8166\u4e0a\u57f7\u884c\u3002\u6211\u5011\u63d0\u51fa\u4e00\u500b\u786c\u9ad4\u8edf\u9ad4\u5171\u540c\u8a2d\u8a08\uff0c\u4e00\u500b\u4f7f\u7528\u61b6\u963b\u5668\u7684\u8a9e\u7fa9\u8a18\u61b6\u9ad4\u70ba\u57fa\u790e\u7684\u52d5\u614b\u795e\u7d93\u7db2\u8def (DNN)\u3002\u7db2\u8def\u5c07\u8f38\u5165\u8cc7\u6599\u8207\u5132\u5b58\u5728\u8a9e\u7fa9\u5411\u91cf\u4e2d\u7684\u904e\u53bb\u7d93\u9a57\u806f\u60f3\u8d77\u4f86\u3002\u7db2\u8def\u548c\u8a9e\u7fa9\u8a18\u61b6\u9ad4\u5206\u5225\u5728\u8010\u96dc\u8a0a\u4e09\u5143\u61b6\u963b\u5668\u70ba\u57fa\u790e\u7684\u8a18\u61b6\u9ad4\u904b\u7b97 (CIM) \u548c\u5167\u5bb9\u53ef\u5c0b\u5740\u8a18\u61b6\u9ad4 (CAM) \u96fb\u8def\u4e2d\u5be6\u9ad4\u5be6\u4f5c\u3002\u6211\u5011\u4f7f\u7528 40nm \u61b6\u963b\u5668\u5de8\u96c6\uff0c\u5728 ResNet \u548c PointNet++ \u4e0a\u9a57\u8b49\u6211\u5011\u7684\u5171\u540c\u8a2d\u8a08\uff0c\u4ee5\u5206\u985e\u4f86\u81ea MNIST \u548c ModelNet \u8cc7\u6599\u96c6\u7684\u5f71\u50cf\u548c 3D \u9ede\uff0c\u4e0d\u50c5\u9054\u5230\u8207\u8edf\u9ad4\u76f8\u7576\u7684\u6e96\u78ba\u5ea6\uff0c\u9084\u6e1b\u5c11\u4e86 48.1% \u548c 15.9% \u7684\u904b\u7b97\u9810\u7b97\u3002\n\u6b64\u5916\uff0c\u5b83\u9084\u6e1b\u5c11\u4e86 77.6% \u548c 93.3% \u7684\u80fd\u8017\u3002", "author": "Yue Zhang et.al.", "authors": "Yue Zhang, Woyu Zhang, Shaocong Wang, Ning Lin, Yifei Yu, Yangu He, Bo Wang, Hao Jiang, Peng Lin, Xiaoxin Xu, Xiaojuan Qi, Zhongrui Wang, Xumeng Zhang, Dashan Shang, Qi Liu, Kwang-Ting Cheng, Ming Liu", "id": "2407.08990v1", "paper_url": "http://arxiv.org/abs/2407.08990v1", "repo": "null"}}