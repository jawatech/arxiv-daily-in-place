{"2409.10907": {"publish_time": "2024-09-17", "title": "Attention-Seeker: Dynamic Self-Attention Scoring for Unsupervised Keyphrase Extraction", "paper_summary": "This paper proposes Attention-Seeker, an unsupervised keyphrase extraction\nmethod that leverages self-attention maps from a Large Language Model to\nestimate the importance of candidate phrases. Our approach identifies specific\ncomponents - such as layers, heads, and attention vectors - where the model\npays significant attention to the key topics of the text. The attention weights\nprovided by these components are then used to score the candidate phrases.\nUnlike previous models that require manual tuning of parameters (e.g.,\nselection of heads, prompts, hyperparameters), Attention-Seeker dynamically\nadapts to the input text without any manual adjustments, enhancing its\npractical applicability. We evaluate Attention-Seeker on four publicly\navailable datasets: Inspec, SemEval2010, SemEval2017, and Krapivin. Our results\ndemonstrate that, even without parameter tuning, Attention-Seeker outperforms\nmost baseline models, achieving state-of-the-art performance on three out of\nfour datasets, particularly excelling in extracting keyphrases from long\ndocuments.", "paper_summary_zh": "\u672c\u6587\u63d0\u51fa\u4e86 Attention-Seeker\uff0c\u9019\u662f\u4e00\u7a2e\u7121\u76e3\u7763\u95dc\u9375\u5b57\u8403\u53d6\u65b9\u6cd5\uff0c\u5b83\u5229\u7528\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u4e2d\u7684\u81ea\u6ce8\u610f\u529b\u5716\u4f86\u4f30\u8a08\u5019\u9078\u8a5e\u7d44\u7684\u91cd\u8981\u6027\u3002\u6211\u5011\u7684\u505a\u6cd5\u627e\u51fa\u7279\u5b9a\u7d44\u6210\u90e8\u5206\uff08\u4f8b\u5982\u5c64\u3001\u982d\u548c\u6ce8\u610f\u529b\u5411\u91cf\uff09\uff0c\u6a21\u578b\u5728\u9019\u4e9b\u7d44\u6210\u90e8\u5206\u4e2d\u6703\u5c0d\u6587\u5b57\u7684\u4e3b\u8981\u4e3b\u984c\u7d66\u4e88\u986f\u8457\u7684\u6ce8\u610f\u529b\u3002\u7136\u5f8c\u4f7f\u7528\u9019\u4e9b\u7d44\u6210\u90e8\u5206\u63d0\u4f9b\u7684\u6ce8\u610f\u529b\u6b0a\u91cd\u4f86\u70ba\u5019\u9078\u8a5e\u7d44\u8a55\u5206\u3002\u8207\u9700\u8981\u624b\u52d5\u8abf\u6574\u53c3\u6578\uff08\u4f8b\u5982\u9078\u64c7\u982d\u3001\u63d0\u793a\u3001\u8d85\u53c3\u6578\uff09\u7684\u5148\u524d\u6a21\u578b\u4e0d\u540c\uff0cAttention-Seeker \u6703\u52d5\u614b\u8abf\u6574\u8f38\u5165\u6587\u5b57\uff0c\u800c\u7121\u9700\u4efb\u4f55\u624b\u52d5\u8abf\u6574\uff0c\u5f9e\u800c\u589e\u5f37\u5176\u5be6\u7528\u6027\u3002\u6211\u5011\u5728\u56db\u500b\u516c\u958b\u53ef\u7528\u7684\u8cc7\u6599\u96c6\u4e0a\u8a55\u4f30 Attention-Seeker\uff1aInspec\u3001SemEval2010\u3001SemEval2017 \u548c Krapivin\u3002\u6211\u5011\u7684\u7d50\u679c\u8b49\u660e\uff0c\u5373\u4f7f\u4e0d\u8abf\u6574\u53c3\u6578\uff0cAttention-Seeker \u4e5f\u512a\u65bc\u5927\u591a\u6578\u57fa\u7dda\u6a21\u578b\uff0c\u5728\u56db\u500b\u8cc7\u6599\u96c6\u4e2d\u6709\u4e09\u500b\u8cc7\u6599\u96c6\u9054\u5230\u6700\u5148\u9032\u7684\u6548\u80fd\uff0c\u7279\u5225\u662f\u5728\u5f9e\u9577\u6587\u4ef6\u4e2d\u8403\u53d6\u95dc\u9375\u5b57\u6642\u8868\u73fe\u51fa\u8272\u3002", "author": "Erwin D. L\u00f3pez Z. et.al.", "authors": "Erwin D. L\u00f3pez Z., Cheng Tang, Atsushi Shimada", "id": "2409.10907v1", "paper_url": "http://arxiv.org/abs/2409.10907v1", "repo": "null"}}