{"2409.05972": {"publish_time": "2024-09-09", "title": "A Small Claims Court for the NLP: Judging Legal Text Classification Strategies With Small Datasets", "paper_summary": "Recent advances in language modelling has significantly decreased the need of\nlabelled data in text classification tasks. Transformer-based models,\npre-trained on unlabeled data, can outmatch the performance of models trained\nfrom scratch for each task. However, the amount of labelled data need to\nfine-tune such type of model is still considerably high for domains requiring\nexpert-level annotators, like the legal domain. This paper investigates the\nbest strategies for optimizing the use of a small labeled dataset and large\namounts of unlabeled data and perform a classification task in the legal area\nwith 50 predefined topics. More specifically, we use the records of demands to\na Brazilian Public Prosecutor's Office aiming to assign the descriptions in one\nof the subjects, which currently demands deep legal knowledge for manual\nfilling. The task of optimizing the performance of classifiers in this scenario\nis especially challenging, given the low amount of resources available\nregarding the Portuguese language, especially in the legal domain. Our results\ndemonstrate that classic supervised models such as logistic regression and SVM\nand the ensembles random forest and gradient boosting achieve better\nperformance along with embeddings extracted with word2vec when compared to BERT\nlanguage model. The latter demonstrates superior performance in association\nwith the architecture of the model itself as a classifier, having surpassed all\nprevious models in that regard. The best result was obtained with Unsupervised\nData Augmentation (UDA), which jointly uses BERT, data augmentation, and\nstrategies of semi-supervised learning, with an accuracy of 80.7% in the\naforementioned task.", "paper_summary_zh": "<paragraph>\u8a9e\u8a00\u6a21\u578b\u7684\u6700\u65b0\u9032\u5c55\u5927\u5e45\u964d\u4f4e\u4e86\u6587\u672c\u5206\u985e\u4efb\u52d9\u4e2d\u6a19\u8a3b\u8cc7\u6599\u7684\u9700\u6c42\u3002\u4ee5\u672a\u6a19\u8a3b\u8cc7\u6599\u9810\u5148\u8a13\u7df4\u7684 Transformer \u6a21\u578b\uff0c\u5176\u6548\u80fd\u53ef\u4ee5\u8d85\u8d8a\u5f9e\u982d\u91dd\u5c0d\u6bcf\u500b\u4efb\u52d9\u8a13\u7df4\u7684\u6a21\u578b\u3002\u7136\u800c\uff0c\u5c0d\u65bc\u9700\u8981\u5c08\u5bb6\u7d1a\u8a3b\u89e3\u8005\u7684\u9818\u57df\uff08\u4f8b\u5982\u6cd5\u5f8b\u9818\u57df\uff09\uff0c\u5fae\u8abf\u6b64\u985e\u6a21\u578b\u6240\u9700\u7684\u6a19\u8a3b\u8cc7\u6599\u91cf\u4ecd\u7136\u76f8\u7576\u9ad8\u3002\u672c\u6587\u63a2\u8a0e\u4e86\u6700\u4f73\u7b56\u7565\uff0c\u4ee5\u6700\u4f73\u5316\u4f7f\u7528\u5c0f\u578b\u6a19\u8a3b\u8cc7\u6599\u96c6\u548c\u5927\u91cf\u672a\u6a19\u8a3b\u8cc7\u6599\uff0c\u4e26\u5728\u6cd5\u5f8b\u9818\u57df\u57f7\u884c\u5206\u985e\u4efb\u52d9\uff0c\u5176\u4e2d\u5305\u542b 50 \u500b\u9810\u5148\u5b9a\u7fa9\u7684\u4e3b\u984c\u3002\u66f4\u5177\u9ad4\u5730\u8aaa\uff0c\u6211\u5011\u4f7f\u7528\u5df4\u897f\u6aa2\u5bdf\u5b98\u8fa6\u516c\u5ba4\u7684\u8981\u6c42\u8a18\u9304\uff0c\u65e8\u5728\u5c07\u8aaa\u660e\u6307\u6d3e\u5230\u5176\u4e2d\u4e00\u500b\u4e3b\u984c\uff0c\u76ee\u524d\u9700\u8981\u6df1\u539a\u7684\u6cd5\u5f8b\u77e5\u8b58\u624d\u80fd\u624b\u52d5\u586b\u5beb\u3002\u5728\u9019\u7a2e\u60c5\u6cc1\u4e0b\uff0c\u6700\u4f73\u5316\u5206\u985e\u5668\u6548\u80fd\u7684\u4efb\u52d9\u7279\u5225\u5177\u6709\u6311\u6230\u6027\uff0c\u56e0\u70ba\u8461\u8404\u7259\u8a9e\u53ef\u7528\u7684\u8cc7\u6e90\u5f88\u5c11\uff0c\u7279\u5225\u662f\u5728\u6cd5\u5f8b\u9818\u57df\u3002\u6211\u5011\u7684\u7d50\u679c\u8868\u660e\uff0c\u8207 BERT \u8a9e\u8a00\u6a21\u578b\u76f8\u6bd4\uff0c\u7d93\u5178\u76e3\u7763\u6a21\u578b\uff08\u4f8b\u5982\u908f\u8f2f\u8ff4\u6b78\u548c SVM\uff09\u4ee5\u53ca\u96a8\u6a5f\u68ee\u6797\u548c\u68af\u5ea6\u63d0\u5347\u7684\u96c6\u6210\uff0c\u5728\u8207 word2vec \u63d0\u53d6\u7684\u5d4c\u5165\u5f0f\u8655\u7406\u6642\uff0c\u53ef\u4ee5\u7372\u5f97\u66f4\u597d\u7684\u6548\u80fd\u3002\u5f8c\u8005\u8207\u6a21\u578b\u672c\u8eab\u7684\u67b6\u69cb\u4f5c\u70ba\u5206\u985e\u5668\u7d50\u5408\u4f7f\u7528\u6642\uff0c\u8868\u73fe\u51fa\u512a\u7570\u7684\u6548\u80fd\uff0c\u5728\u9019\u500b\u65b9\u9762\u8d85\u8d8a\u4e86\u6240\u6709\u5148\u524d\u7684\u6a21\u578b\u3002\u6700\u4f73\u7d50\u679c\u662f\u900f\u904e\u975e\u76e3\u7763\u8cc7\u6599\u64f4\u5145 (UDA) \u7372\u5f97\u7684\uff0c\u5b83\u7d50\u5408\u4f7f\u7528\u4e86 BERT\u3001\u8cc7\u6599\u64f4\u5145\u548c\u534a\u76e3\u7763\u5b78\u7fd2\u7b56\u7565\uff0c\u5728\u4e0a\u8ff0\u4efb\u52d9\u4e2d\u9054\u5230\u4e86 80.7% \u7684\u6e96\u78ba\u5ea6\u3002</paragraph>", "author": "Mariana Yukari Noguti et.al.", "authors": "Mariana Yukari Noguti, Edduardo Vellasques, Luiz Eduardo Soares Oliveira", "id": "2409.05972v1", "paper_url": "http://arxiv.org/abs/2409.05972v1", "repo": "null"}}