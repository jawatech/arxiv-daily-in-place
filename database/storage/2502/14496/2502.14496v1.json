{"2502.14496": {"publish_time": "2025-02-20", "title": "Enhancing Language Multi-Agent Learning with Multi-Agent Credit Re-Assignment for Interactive Environment Generalization", "paper_summary": "LLM-based agents have made significant advancements in interactive\nenvironments, such as mobile operations and web browsing, and other domains\nbeyond computer using. Current multi-agent systems universally excel in\nperformance, compared to single agents, but struggle with generalization across\nenvironments due to predefined roles and inadequate strategies for generalizing\nlanguage agents. The challenge of achieving both strong performance and good\ngeneralization has hindered the progress of multi-agent systems for interactive\nenvironments. To address these issues, we propose CollabUIAgents, a multi-agent\nreinforcement learning framework with a novel multi-agent credit re-assignment\n(CR) strategy, assigning process rewards with LLMs rather than\nenvironment-specific rewards and learning with synthesized preference data, in\norder to foster generalizable, collaborative behaviors among the role-free\nagents' policies. Empirical results show that our framework improves both\nperformance and cross-environment generalizability of multi-agent systems.\nMoreover, our 7B-parameter system achieves results on par with or exceed strong\nclosed-source models, and the LLM that guides the CR. We also provide insights\nin using granular CR rewards effectively for environment generalization, and\naccommodating trained LLMs in multi-agent systems.", "paper_summary_zh": "\u57fa\u65bc LLM \u7684\u4ee3\u7406\u5728\u4e92\u52d5\u5f0f\u74b0\u5883\u4e2d\u53d6\u5f97\u91cd\u5927\u9032\u5c55\uff0c\u4f8b\u5982\u884c\u52d5\u904b\u7b97\u548c\u7db2\u9801\u700f\u89bd\uff0c\u4ee5\u53ca\u96fb\u8166\u4f7f\u7528\u4ee5\u5916\u7684\u5176\u4ed6\u9818\u57df\u3002\u8207\u55ae\u4e00\u4ee3\u7406\u76f8\u6bd4\uff0c\u76ee\u524d\u7684 Multi-Agent \u7cfb\u7d71\u5728\u6548\u80fd\u4e0a\u666e\u904d\u8868\u73fe\u51fa\u8272\uff0c\u4f46\u7531\u65bc\u9810\u5148\u5b9a\u7fa9\u7684\u89d2\u8272\u548c\u4e0d\u9069\u7576\u7684\u8a9e\u8a00\u4ee3\u7406\u6982\u5316\u7b56\u7565\uff0c\u5c0e\u81f4\u96e3\u4ee5\u8de8\u74b0\u5883\u6982\u5316\u3002\u5728\u4e92\u52d5\u5f0f\u74b0\u5883\u4e2d\uff0c\u540c\u6642\u9054\u6210\u5f37\u5927\u6548\u80fd\u548c\u826f\u597d\u6982\u5316\u7684\u6311\u6230\uff0c\u963b\u7919\u4e86 Multi-Agent \u7cfb\u7d71\u7684\u9032\u5c55\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u4e9b\u554f\u984c\uff0c\u6211\u5011\u63d0\u51fa CollabUIAgents\uff0c\u9019\u662f\u4e00\u500b Multi-Agent \u5f37\u5316\u5b78\u7fd2\u67b6\u69cb\uff0c\u5177\u5099\u5275\u65b0\u7684 Multi-Agent \u4fe1\u7528\u91cd\u65b0\u5206\u914d (CR) \u7b56\u7565\uff0c\u4f7f\u7528 LLM \u800c\u4e0d\u662f\u7279\u5b9a\u65bc\u74b0\u5883\u7684\u734e\u52f5\u4f86\u5206\u914d\u7a0b\u5e8f\u734e\u52f5\uff0c\u4e26\u900f\u904e\u7d9c\u5408\u504f\u597d\u8cc7\u6599\u9032\u884c\u5b78\u7fd2\uff0c\u4ee5\u4fc3\u9032\u7121\u89d2\u8272\u4ee3\u7406\u653f\u7b56\u4e4b\u9593\u53ef\u6982\u5316\u7684\u5354\u4f5c\u884c\u70ba\u3002\u7d93\u9a57\u7d50\u679c\u986f\u793a\uff0c\u6211\u5011\u7684\u67b6\u69cb\u540c\u6642\u6539\u5584\u4e86 Multi-Agent \u7cfb\u7d71\u7684\u6548\u80fd\u548c\u8de8\u74b0\u5883\u6982\u5316\u80fd\u529b\u3002\u6b64\u5916\uff0c\u6211\u5011\u7684 7B \u53c3\u6578\u7cfb\u7d71\u5728\u6548\u80fd\u4e0a\u8207\u5f37\u5927\u7684\u9589\u6e90\u6a21\u578b\u548c\u5f15\u5c0e CR \u7684 LLM \u76f8\u7576\u6216\u8d85\u8d8a\u5b83\u5011\u3002\u6211\u5011\u4e5f\u63d0\u4f9b\u898b\u89e3\uff0c\u8aaa\u660e\u5982\u4f55\u6709\u6548\u5730\u4f7f\u7528\u7d30\u7c92\u5316\u7684 CR \u734e\u52f5\u4f86\u9032\u884c\u74b0\u5883\u6982\u5316\uff0c\u4ee5\u53ca\u5982\u4f55\u5728 Multi-Agent \u7cfb\u7d71\u4e2d\u5bb9\u7d0d\u53d7\u904e\u8a13\u7df4\u7684 LLM\u3002", "author": "Zhitao He et.al.", "authors": "Zhitao He, Zijun Liu, Peng Li, May Fung, Ming Yan, Ji Zhang, Fei Huang, Yang Liu", "id": "2502.14496v1", "paper_url": "http://arxiv.org/abs/2502.14496v1", "repo": "null"}}