
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-10-23**|**ALTA: Compiler-Based Analysis of Transformers**|Peter Shaw et.al.|[2410.18077v1](http://arxiv.org/abs/2410.18077v1)|[link](https://github.com/google-deepmind/alta)|
|**2024-10-23**|**Leveraging Skills from Unlabeled Prior Data for Efficient Online Exploration**|Max Wilcoxson et.al.|[2410.18076v1](http://arxiv.org/abs/2410.18076v1)|null|
|**2024-10-23**|**TP-Eval: Tap Multimodal LLMs' Potential in Evaluation by Customizing Prompts**|Yuxuan Xie et.al.|[2410.18071v1](http://arxiv.org/abs/2410.18071v1)|null|
|**2024-10-23**|**Training Free Guided Flow Matching with Optimal Control**|Luran Wang et.al.|[2410.18070v1](http://arxiv.org/abs/2410.18070v1)|null|
|**2024-10-23**|**Beyond position: how rotary embeddings shape representations and memory in autoregressive transfomers**|Valeria Ruscio et.al.|[2410.18067v1](http://arxiv.org/abs/2410.18067v1)|null|
|**2024-10-23**|**Explaining Bayesian Networks in Natural Language using Factor Arguments. Evaluation in the medical domain**|Jaime Sevilla et.al.|[2410.18060v1](http://arxiv.org/abs/2410.18060v1)|null|
|**2024-10-23**|**CLEAR: Character Unlearning in Textual and Visual Modalities**|Alexey Dontsov et.al.|[2410.18057v1](http://arxiv.org/abs/2410.18057v1)|null|
|**2024-10-23**|**LongRAG: A Dual-Perspective Retrieval-Augmented Generation Paradigm for Long-Context Question Answering**|Qingfei Zhao et.al.|[2410.18050v1](http://arxiv.org/abs/2410.18050v1)|[link](https://github.com/qingfei1/longrag)|
|**2024-10-23**|**Key Algorithms for Keyphrase Generation: Instruction-Based LLMs for Russian Scientific Keyphrases**|Anna Glazkova et.al.|[2410.18040v1](http://arxiv.org/abs/2410.18040v1)|null|
|**2024-10-23**|**MiLoRA: Efficient Mixture of Low-Rank Adaptation for Large Language Models Fine-tuning**|Jingfan Zhang et.al.|[2410.18035v1](http://arxiv.org/abs/2410.18035v1)|null|
|**2024-10-23**|**GraphTeam: Facilitating Large Language Model-based Graph Analysis via Multi-Agent Collaboration**|Xin Li et.al.|[2410.18032v1](http://arxiv.org/abs/2410.18032v1)|[link](https://github.com/bupt-gamma/graphteam)|
|**2024-10-23**|**Cross-lingual Transfer of Reward Models in Multilingual Alignment**|Jiwoo Hong et.al.|[2410.18027v1](http://arxiv.org/abs/2410.18027v1)|null|
|**2024-10-23**|**Benchmarking Foundation Models on Exceptional Cases: Dataset Creation and Validation**|Suho Kang et.al.|[2410.18001v1](http://arxiv.org/abs/2410.18001v1)|[link](https://github.com/mlai-yonsei/exceptionalbenchmark)|
|**2024-10-23**|**Federated Transformer: Multi-Party Vertical Federated Learning on Practical Fuzzily Linked Data**|Zhaomin Wu et.al.|[2410.17986v1](http://arxiv.org/abs/2410.17986v1)|[link](https://github.com/xtra-computing/fet)|
|**2024-10-23**|**Together We Can: Multilingual Automatic Post-Editing for Low-Resource Languages**|Sourabh Deoghare et.al.|[2410.17973v1](http://arxiv.org/abs/2410.17973v1)|null|
|**2024-10-23**|**A Time-Aware Approach to Early Detection of Anorexia: UNSL at eRisk 2024**|Horacio Thompson et.al.|[2410.17963v1](http://arxiv.org/abs/2410.17963v1)|null|
|**2024-10-23**|**Closed-form merging of parameter-efficient modules for Federated Continual Learning**|Riccardo Salami et.al.|[2410.17961v1](http://arxiv.org/abs/2410.17961v1)|null|
|**2024-10-23**|**Zeitenwenden: Detecting changes in the German political discourse**|Kai-Robin Lange et.al.|[2410.17960v1](http://arxiv.org/abs/2410.17960v1)|null|
|**2024-10-23**|**MCUBERT: Memory-Efficient BERT Inference on Commodity Microcontrollers**|Zebin Yang et.al.|[2410.17957v1](http://arxiv.org/abs/2410.17957v1)|null|
|**2024-10-23**|**ExpertFlow: Optimized Expert Activation and Token Allocation for Efficient Mixture-of-Experts Inference**|Xin He et.al.|[2410.17954v1](http://arxiv.org/abs/2410.17954v1)|null|
|**2024-10-23**|**SimRAG: Self-Improving Retrieval-Augmented Generation for Adapting Large Language Models to Specialized Domains**|Ran Xu et.al.|[2410.17952v1](http://arxiv.org/abs/2410.17952v1)|null|
|**2024-10-23**|**Benchmarking Floworks against OpenAI & Anthropic: A Novel Framework for Enhanced LLM Function Calling**|Nirav Bhan et.al.|[2410.17950v1](http://arxiv.org/abs/2410.17950v1)|null|
|**2024-10-23**|**Optimizing Travel Itineraries with AI Algorithms in a Microservices Architecture: Balancing Cost, Time, Preferences, and Sustainability**|Biman Barua et.al.|[2410.17943v1](http://arxiv.org/abs/2410.17943v1)|null|
|**2024-10-23**|**Multi-Continental Healthcare Modelling Using Blockchain-Enabled Federated Learning**|Rui Sun et.al.|[2410.17933v1](http://arxiv.org/abs/2410.17933v1)|null|
|**2024-10-23**|**Guide for Defense (G4D): Dynamic Guidance for Robust and Balanced Defense in Large Language Models**|He Cao et.al.|[2410.17922v1](http://arxiv.org/abs/2410.17922v1)|null|
|**2024-10-23**|**Addressing Asynchronicity in Clinical Multimodal Fusion via Individualized Chest X-ray Generation**|Wenfang Yao et.al.|[2410.17918v1](http://arxiv.org/abs/2410.17918v1)|null|
|**2024-10-23**|**Leveraging Deep Learning for Time Series Extrinsic Regression in predicting photometric metallicity of Fundamental-mode RR Lyrae Stars**|Lorenzo Monti et.al.|[2410.17906v1](http://arxiv.org/abs/2410.17906v1)|[link](https://github.com/lorenzomonti/metallicity_rrls)|
|**2024-10-23**|**Reinforcement Learning under Latent Dynamics: Toward Statistical and Algorithmic Modularity**|Philip Amortila et.al.|[2410.17904v1](http://arxiv.org/abs/2410.17904v1)|null|
|**2024-10-23**|**ELAICHI: Enhancing Low-resource TTS by Addressing Infrequent and Low-frequency Character Bigrams**|Srija Anand et.al.|[2410.17901v1](http://arxiv.org/abs/2410.17901v1)|null|
|**2024-10-23**|**Scaling Diffusion Language Models via Adaptation from Autoregressive Models**|Shansan Gong et.al.|[2410.17891v1](http://arxiv.org/abs/2410.17891v1)|[link](https://github.com/hkunlp/diffullama)|
|**2024-10-23**|**SpeakGer: A meta-data enriched speech corpus of German state and federal parliaments**|Kai-Robin Lange et.al.|[2410.17886v1](http://arxiv.org/abs/2410.17886v1)|null|
|**2024-10-23**|**R-CoT: Reverse Chain-of-Thought Problem Generation for Geometric Reasoning in Large Multimodal Models**|Linger Deng et.al.|[2410.17885v1](http://arxiv.org/abs/2410.17885v1)|[link](https://github.com/dle666/r-cot)|
|**2024-10-23**|**Lightweight Neural App Control**|Filippos Christianos et.al.|[2410.17883v1](http://arxiv.org/abs/2410.17883v1)|null|
|**2024-10-23**|**Understanding Layer Significance in LLM Alignment**|Guangyuan Shi et.al.|[2410.17875v1](http://arxiv.org/abs/2410.17875v1)|null|
|**2024-10-23**|**DataTales: A Benchmark for Real-World Intelligent Data Narration**|Yajing Yang et.al.|[2410.17859v1](http://arxiv.org/abs/2410.17859v1)|null|
|**2024-10-23**|**ROCKET-1: Master Open-World Interaction with Visual-Temporal Context Prompting**|Shaofei Cai et.al.|[2410.17856v1](http://arxiv.org/abs/2410.17856v1)|null|
|**2024-10-23**|**TAGE: Trustworthy Attribute Group Editing for Stable Few-shot Image Generation**|Ruicheng Zhang et.al.|[2410.17855v1](http://arxiv.org/abs/2410.17855v1)|null|
|**2024-10-23**|**The Probabilistic Tsetlin Machine: A Novel Approach to Uncertainty Quantification**|K. Darshana Abeyrathna et.al.|[2410.17851v1](http://arxiv.org/abs/2410.17851v1)|null|
|**2024-10-23**|**RE-tune: Incremental Fine Tuning of Biomedical Vision-Language Models for Multi-label Chest X-ray Classification**|Marco Mistretta et.al.|[2410.17827v1](http://arxiv.org/abs/2410.17827v1)|null|
|**2024-10-23**|**Understanding When Tree of Thoughts Succeeds: Larger Models Excel in Generation, Not Discrimination**|Qiqi Chen et.al.|[2410.17820v1](http://arxiv.org/abs/2410.17820v1)|[link](https://github.com/mainlp/tot-eval)|
|**2024-10-23**|**PGDiffSeg: Prior-Guided Denoising Diffusion Model with Parameter-Shared Attention for Breast Cancer Segmentation**|Feiyan Feng et.al.|[2410.17812v1](http://arxiv.org/abs/2410.17812v1)|null|
|**2024-10-23**|**OmniFlatten: An End-to-end GPT Model for Seamless Voice Conversation**|Qinglin Zhang et.al.|[2410.17799v1](http://arxiv.org/abs/2410.17799v1)|null|
|**2024-10-23**|**Enhancing Federated Learning Convergence with Dynamic Data Queue and Data Entropy-driven Participant Selection**|Charuka Herath et.al.|[2410.17792v1](http://arxiv.org/abs/2410.17792v1)|null|
|**2024-10-23**|**Large Language Models Engineer Too Many Simple Features For Tabular Data**|Jaris Küken et.al.|[2410.17787v1](http://arxiv.org/abs/2410.17787v1)|null|
|**2024-10-23**|**Holon Programming Model -- A Software-Defined Approach for System of Systems**|Muhammad Ashfaq et.al.|[2410.17784v1](http://arxiv.org/abs/2410.17784v1)|null|
|**2024-10-23**|**Leveraging the Domain Adaptation of Retrieval Augmented Generation Models for Question Answering and Reducing Hallucination**|Salman Rakin et.al.|[2410.17783v1](http://arxiv.org/abs/2410.17783v1)|null|
|**2024-10-23**|**Evaluating Explanations Through LLMs: Beyond Traditional User Studies**|Francesco Bombassei De Bona et.al.|[2410.17781v1](http://arxiv.org/abs/2410.17781v1)|null|
|**2024-10-23**|**Scaling Robot Policy Learning via Zero-Shot Labeling with Foundation Models**|Nils Blank et.al.|[2410.17772v1](http://arxiv.org/abs/2410.17772v1)|null|
|**2024-10-23**|**Latent Structures of Intertextuality in French Fiction**|Jean Barré et.al.|[2410.17759v1](http://arxiv.org/abs/2410.17759v1)|null|
|**2024-10-23**|**Escaping the Forest: Sparse Interpretable Neural Networks for Tabular Data**|Salvatore Raieli et.al.|[2410.17758v1](http://arxiv.org/abs/2410.17758v1)|null|
|**2024-10-23**|**VISAGE: Video Synthesis using Action Graphs for Surgery**|Yousef Yeganeh et.al.|[2410.17751v1](http://arxiv.org/abs/2410.17751v1)|null|
|**2024-10-23**|**Learning Versatile Skills with Curriculum Masking**|Yao Tang et.al.|[2410.17744v1](http://arxiv.org/abs/2410.17744v1)|[link](https://github.com/yaotang23/currmask)|
|**2024-10-23**|**Emotion Recognition with Facial Attention and Objective Activation Functions**|Andrzej Miskow et.al.|[2410.17740v1](http://arxiv.org/abs/2410.17740v1)|null|
|**2024-10-23**|**Local Contrastive Editing of Gender Stereotypes**|Marlene Lutz et.al.|[2410.17739v1](http://arxiv.org/abs/2410.17739v1)|null|
|**2024-10-23**|**MojoBench: Language Modeling and Benchmarks for Mojo**|Nishat Raihan et.al.|[2410.17736v1](http://arxiv.org/abs/2410.17736v1)|null|
|**2024-10-23**|**New Insight in Cervical Cancer Diagnosis Using Convolution Neural Network Architecture**|Ach. Khozaimi et.al.|[2410.17735v1](http://arxiv.org/abs/2410.17735v1)|null|
|**2024-10-23**|**FuzzWiz -- Fuzzing Framework for Efficient Hardware Coverage**|Deepak Narayan Gadde et.al.|[2410.17732v1](http://arxiv.org/abs/2410.17732v1)|null|
|**2024-10-23**|**Dialectal and Low Resource Machine Translation for Aromanian**|Alexandru-Iulius Jerpelea et.al.|[2410.17728v1](http://arxiv.org/abs/2410.17728v1)|null|
|**2024-10-23**|**CogSteer: Cognition-Inspired Selective Layer Intervention for Efficient Semantic Steering in Large Language Models**|Xintong Wang et.al.|[2410.17714v1](http://arxiv.org/abs/2410.17714v1)|null|
|**2024-10-23**|**Beware of Calibration Data for Pruning Large Language Models**|Yixin Ji et.al.|[2410.17711v1](http://arxiv.org/abs/2410.17711v1)|null|
|**2024-10-23**|**Scalable Random Feature Latent Variable Models**|Ying Li et.al.|[2410.17700v1](http://arxiv.org/abs/2410.17700v1)|[link](https://github.com/gwgundersen/rflvm)|
|**2024-10-23**|**An Adaptive Framework for Generating Systematic Explanatory Answer in Online Q&A Platforms**|Ziyang Chen et.al.|[2410.17694v1](http://arxiv.org/abs/2410.17694v1)|[link](https://github.com/czy1999/synthrag)|
|**2024-10-23**|**Quantifying the Risks of Tool-assisted Rephrasing to Linguistic Diversity**|Mengying Wang et.al.|[2410.17670v1](http://arxiv.org/abs/2410.17670v1)|null|
|**2024-10-23**|**PETAH: Parameter Efficient Task Adaptation for Hybrid Transformers in a resource-limited Context**|Maximilian Augustin et.al.|[2410.17661v1](http://arxiv.org/abs/2410.17661v1)|null|
|**2024-10-23**|**ReflecTool: Towards Reflection-Aware Tool-Augmented Clinical Agents**|Yusheng Liao et.al.|[2410.17657v1](http://arxiv.org/abs/2410.17657v1)|null|
|**2024-10-23**|**AutoRNet: Automatically Optimizing Heuristics for Robust Network Design via Large Language Models**|He Yu et.al.|[2410.17656v1](http://arxiv.org/abs/2410.17656v1)|null|
|**2024-10-23**|**Mapping the Media Landscape: Predicting Factual Reporting and Political Bias Through Web Interactions**|Dairazalia Sánchez-Cortés et.al.|[2410.17655v1](http://arxiv.org/abs/2410.17655v1)|[link](https://github.com/idiap/factual-reporting-and-political-bias-web-interactions)|
|**2024-10-23**|**MIA-DPO: Multi-Image Augmented Direct Preference Optimization For Large Vision-Language Models**|Ziyu Liu et.al.|[2410.17637v1](http://arxiv.org/abs/2410.17637v1)|[link](https://github.com/liuziyu77/mia-dpo)|
|**2024-10-23**|**Markov Chain of Thought for Efficient Mathematical Reasoning**|Wen Yang et.al.|[2410.17635v1](http://arxiv.org/abs/2410.17635v1)|null|
|**2024-10-23**|**LMLPA: Language Model Linguistic Personality Assessment**|Jingyao Zheng et.al.|[2410.17632v1](http://arxiv.org/abs/2410.17632v1)|null|
|**2024-10-23**|**Process Supervision-Guided Policy Optimization for Code Generation**|Ning Dai et.al.|[2410.17621v1](http://arxiv.org/abs/2410.17621v1)|null|
|**2024-10-23**|**From PDFs to Structured Data: Utilizing LLM Analysis in Sports Database Management**|Juhani Merilehto et.al.|[2410.17619v1](http://arxiv.org/abs/2410.17619v1)|null|
|**2024-10-23**|**Towards Effective Data-Free Knowledge Distillation via Diverse Diffusion Augmentation**|Muquan Li et.al.|[2410.17606v1](http://arxiv.org/abs/2410.17606v1)|[link](https://github.com/slgsp/dda)|
|**2024-10-23**|**Integrating Large Language Models for UAV Control in Simulated Environments: A Modular Interaction Approach**|Abhishek Phadke et.al.|[2410.17602v1](http://arxiv.org/abs/2410.17602v1)|null|
|**2024-10-23**|**Graphusion: A RAG Framework for Knowledge Graph Construction with a Global Perspective**|Rui Yang et.al.|[2410.17600v1](http://arxiv.org/abs/2410.17600v1)|null|
|**2024-10-23**|**Cross-model Control: Improving Multiple Large Language Models in One-time Training**|Jiayi Wu et.al.|[2410.17599v1](http://arxiv.org/abs/2410.17599v1)|[link](https://github.com/wujwyi/cmc)|
|**2024-10-23**|**Challenge on Sound Scene Synthesis: Evaluating Text-to-Audio Generation**|Junwon Lee et.al.|[2410.17589v1](http://arxiv.org/abs/2410.17589v1)|null|
|**2024-10-23**|**Bonsai: Gradient-free Graph Distillation for Node Classification**|Mridul Gupta et.al.|[2410.17579v1](http://arxiv.org/abs/2410.17579v1)|null|
|**2024-10-23**|**MM-Eval: A Multilingual Meta-Evaluation Benchmark for LLM-as-a-Judge and Reward Models**|Guijin Son et.al.|[2410.17578v1](http://arxiv.org/abs/2410.17578v1)|null|
|**2024-10-23**|**Differentially Private Learning Needs Better Model Initialization and Self-Distillation**|Ivoline C. Ngong et.al.|[2410.17566v1](http://arxiv.org/abs/2410.17566v1)|null|
|**2024-10-23**|**CLR-Bench: Evaluating Large Language Models in College-level Reasoning**|Junnan Dong et.al.|[2410.17558v1](http://arxiv.org/abs/2410.17558v1)|null|
|**2024-10-23**|**FairDgcl: Fairness-aware Recommendation with Dynamic Graph Contrastive Learning**|Wei Chen et.al.|[2410.17555v1](http://arxiv.org/abs/2410.17555v1)|[link](https://github.com/cwei01/fairdgcl)|
|**2024-10-23**|**ESpeW: Robust Copyright Protection for LLM-based EaaS via Embedding-Specific Watermark**|Zongqi Wang et.al.|[2410.17552v1](http://arxiv.org/abs/2410.17552v1)|[link](https://github.com/liudan193/ESpeW)|
|**2024-10-23**|**ProtoLens: Advancing Prototype Learning for Fine-Grained Interpretability in Text Classification**|Bowen Wei et.al.|[2410.17546v1](http://arxiv.org/abs/2410.17546v1)|null|
|**2024-10-23**|**Responsible Multilingual Large Language Models: A Survey of Development, Applications, and Societal Impact**|Junhua Liu et.al.|[2410.17532v1](http://arxiv.org/abs/2410.17532v1)|null|
|**2024-10-23**|**Navigate Complex Physical Worlds via Geometrically Constrained LLM**|Yongqiang Huang et.al.|[2410.17529v1](http://arxiv.org/abs/2410.17529v1)|null|
|**2024-10-23**|**MobileSafetyBench: Evaluating Safety of Autonomous Agents in Mobile Device Control**|Juyong Lee et.al.|[2410.17520v1](http://arxiv.org/abs/2410.17520v1)|null|
|**2024-10-23**|**Large Language Models Still Exhibit Bias in Long Text**|Wonje Jeung et.al.|[2410.17519v1](http://arxiv.org/abs/2410.17519v1)|null|
|**2024-10-23**|**Congestion Forecast for Trains with Railroad-Graph-based Semi-Supervised Learning using Sparse Passenger Reports**|Soto Anno et.al.|[2410.17510v1](http://arxiv.org/abs/2410.17510v1)|null|
|**2024-10-23**|**Mitigating Graph Covariate Shift via Score-based Out-of-distribution Augmentation**|Bohan Wang et.al.|[2410.17506v1](http://arxiv.org/abs/2410.17506v1)|null|
|**2024-10-23**|**An Ontology-Enabled Approach For User-Centered and Knowledge-Enabled Explanations of AI Systems**|Shruthi Chari et.al.|[2410.17504v1](http://arxiv.org/abs/2410.17504v1)|null|
|**2024-10-23**|**Mechanisms of Symbol Processing for In-Context Learning in Transformer Networks**|Paul Smolensky et.al.|[2410.17498v1](http://arxiv.org/abs/2410.17498v1)|null|
|**2024-10-23**|**BadFair: Backdoored Fairness Attacks with Group-conditioned Triggers**|Jiaqi Xue et.al.|[2410.17492v1](http://arxiv.org/abs/2410.17492v1)|null|
|**2024-10-23**|**Unsupervised Domain Adaptation for Action Recognition via Self-Ensembling and Conditional Embedding Alignment**|Indrajeet Ghosh et.al.|[2410.17489v1](http://arxiv.org/abs/2410.17489v1)|[link](https://github.com/indrajeetghosh/udar_icdm)|
|**2024-10-23**|**VoiceTextBlender: Augmenting Large Language Models with Speech Capabilities via Single-Stage Joint Speech-Text Supervised Fine-Tuning**|Yifan Peng et.al.|[2410.17485v1](http://arxiv.org/abs/2410.17485v1)|null|
|**2024-10-23**|**Which Client is Reliable?: A Reliable and Personalized Prompt-based Federated Learning for Medical Image Question Answering**|He Zhu et.al.|[2410.17484v1](http://arxiv.org/abs/2410.17484v1)|null|
|**2024-10-23**|**Is artificial intelligence still intelligence? LLMs generalize to novel adjective-noun pairs, but don't mimic the full human distribution**|Hayley Ross et.al.|[2410.17482v1](http://arxiv.org/abs/2410.17482v1)|null|
|**2024-10-22**|**Composing Diffusion Policies for Few-shot Learning of Movement Trajectories**|Omkar Patil et.al.|[2410.17479v1](http://arxiv.org/abs/2410.17479v1)|null|
|**2024-10-22**|**Do Robot Snakes Dream like Electric Sheep? Investigating the Effects of Architectural Inductive Biases on Hallucination**|Jerry Huang et.al.|[2410.17477v1](http://arxiv.org/abs/2410.17477v1)|null|
|**2024-10-22**|**AdaptoML-UX: An Adaptive User-centered GUI-based AutoML Toolkit for Non-AI Experts and HCI Researchers**|Amr Gomaa et.al.|[2410.17469v1](http://arxiv.org/abs/2410.17469v1)|[link](https://github.com/michaelsargious/adaptoml_ux)|

#### Abstracts
##### **ALTA: Compiler-Based Analysis of Transformers**
2410.18077v1 by Peter Shaw, James Cohan, Jacob Eisenstein, Kenton Lee, Jonathan Berant, Kristina Toutanova

We propose a new programming language called ALTA and a compiler that can map
ALTA programs to Transformer weights. ALTA is inspired by RASP, a language
proposed by Weiss et al. (2021), and Tracr (Lindner et al., 2023), a compiler
from RASP programs to Transformer weights. ALTA complements and extends this
prior work, offering the ability to express loops and to compile programs to
Universal Transformers, among other advantages. ALTA allows us to
constructively show how Transformers can represent length-invariant algorithms
for computing parity and addition, as well as a solution to the SCAN benchmark
of compositional generalization tasks, without requiring intermediate
scratchpad decoding steps. We also propose tools to analyze cases where the
expressibility of an algorithm is established, but end-to-end training on a
given training set fails to induce behavior consistent with the desired
algorithm. To this end, we explore training from ALTA execution traces as a
more fine-grained supervision signal. This enables additional experiments and
theoretical analyses relating the learnability of various algorithms to data
availability and modeling decisions, such as positional encodings. We make the
ALTA framework -- language specification, symbolic interpreter, and weight
compiler -- available to the community to enable further applications and
insights.

摘要：<paragraph>我們提出了一種名為 ALTA 的新程式語言，以及一個可以將 ALTA 程式對應到 Transformer 權重的編譯器。ALTA 的靈感來自 RASP，一種由 Weiss 等人 (2021) 提出的語言，以及 Tracr (Lindner 等人，2023)，一個將 RASP 程式編譯到 Transformer 權重的編譯器。ALTA 補充並延伸了這項先前的研究，提供了表達迴圈和將程式編譯到通用 Transformer 的能力，以及其他優點。ALTA 讓我們能夠建構性地展示 Transformer 如何表示用於計算奇偶校驗和加法的長度不變演算法，以及 SCAN 組合概化任務基準的解決方案，而不需要中間暫存區解碼步驟。我們也提出了工具來分析演算法的可表達性已建立，但給定訓練集上的端到端訓練無法誘導與所需演算法一致的行為的情況。為此，我們探索從 ALTA 執行追蹤訓練，作為更細緻的監督訊號。這啟用了額外的實驗和理論分析，將各種演算法的可學習性與資料可用性和建模決策（例如位置編碼）關聯起來。我們將 ALTA 框架（語言規範、符號解釋器和權重編譯器）提供給社群，以啟用進一步的應用和見解。</paragraph>

##### **Leveraging Skills from Unlabeled Prior Data for Efficient Online Exploration**
2410.18076v1 by Max Wilcoxson, Qiyang Li, Kevin Frans, Sergey Levine

Unsupervised pretraining has been transformative in many supervised domains.
However, applying such ideas to reinforcement learning (RL) presents a unique
challenge in that fine-tuning does not involve mimicking task-specific data,
but rather exploring and locating the solution through iterative
self-improvement. In this work, we study how unlabeled prior trajectory data
can be leveraged to learn efficient exploration strategies. While prior data
can be used to pretrain a set of low-level skills, or as additional off-policy
data for online RL, it has been unclear how to combine these ideas effectively
for online exploration. Our method SUPE (Skills from Unlabeled Prior data for
Exploration) demonstrates that a careful combination of these ideas compounds
their benefits. Our method first extracts low-level skills using a variational
autoencoder (VAE), and then pseudo-relabels unlabeled trajectories using an
optimistic reward model, transforming prior data into high-level, task-relevant
examples. Finally, SUPE uses these transformed examples as additional
off-policy data for online RL to learn a high-level policy that composes
pretrained low-level skills to explore efficiently. We empirically show that
SUPE reliably outperforms prior strategies, successfully solving a suite of
long-horizon, sparse-reward tasks. Code: https://github.com/rail-berkeley/supe.

摘要：無監督預訓練在許多監督領域中具有變革性。
然而，將此類想法應用於強化學習 (RL) 會帶來一個獨特的挑戰，因為微調不涉及模仿特定於任務的資料，
而是透過反覆自我提升來探索和找到解決方案。在這項工作中，我們研究如何利用未標籤的先前軌跡資料
來學習有效的探索策略。雖然先前資料可用於預訓練一組低階技能，或作為線上 RL 的其他離線策略資料，
但如何有效結合這些想法以進行線上探索一直不清楚。我們的 SUPE 方法（用於探索的未標籤先前資料中的技能）
證明了這些想法的謹慎結合會產生複合效益。我們的做法首先使用變異自動編碼器 (VAE) 提取低階技能，
然後使用樂觀獎勵模型對未標籤的軌跡進行偽重新標籤，將先前資料轉換為高階、與任務相關的範例。
最後，SUPE 將這些轉換後的範例用作線上 RL 的其他離線策略資料，以學習一個高階策略，
該策略組成預訓練的低階技能以有效探索。我們透過經驗證明，SUPE 可靠地優於先前的策略，
成功解決了一系列長時程、稀疏獎勵任務。程式碼：https://github.com/rail-berkeley/supe。

##### **TP-Eval: Tap Multimodal LLMs' Potential in Evaluation by Customizing Prompts**
2410.18071v1 by Yuxuan Xie, Tianhua Li, Wenqi Shao, Kaipeng Zhang

Recently, multimodal large language models (MLLMs) have received much
attention for their impressive capabilities. The evaluation of MLLMs is
becoming critical to analyzing attributes of MLLMs and providing valuable
insights. However, current benchmarks overlook the problem of prompt
sensitivity - minor prompt variations may lead to significant performance
fluctuations. Thus, inappropriate prompts may obscure the models' capabilities,
underestimating the models' performance. Moreover, different models have
different preferences for different prompts, and thus, using the same prompt
for all models will cause evaluation bias. This paper analyzes this deficiency
in existing benchmarks and further introduces a new evaluation framework named
TP-Eval, which introduces a prompt customization method to reduce evaluation
biases and tap models' potential. TP-Eval will rewrite the original prompts to
different customized prompts for different models. In particular, we propose
some well-designed modules for prompt customization tailored to the scenario of
MLLM evaluation. Extensive experiments demonstrate the effectiveness of our
approach to uncovering models' capabilities, and TP-Eval should benefit the
community in developing more comprehensive and convincing MLLM evaluation
benchmarks.

摘要：最近，多模态大型语言模型 (MLLM) 因其令人印象深刻的能力而备受关注。MLLM 的评估对于分析 MLLM 的属性并提供有价值的见解变得至关重要。然而，当前基准忽视了提示敏感性问题——微小的提示变化可能导致性能的显着波动。因此，不适当的提示可能会掩盖模型的能力，低估模型的性能。此外，不同的模型对不同的提示有不同的偏好，因此，对所有模型使用相同的提示会导致评估偏差。本文分析了现有基准中的这一缺陷，并进一步引入了一个名为 TP-Eval 的新评估框架，该框架引入了一种提示定制方法来减少评估偏差并挖掘模型的潜力。TP-Eval 将重写原始提示，为不同的模型提供不同的自定义提示。特别是，我们针对 MLLM 评估场景提出了一些设计精良的提示定制模块。大量的实验表明了我们方法在揭示模型能力方面的有效性，并且 TP-Eval 应该有助于社区开发更全面且令人信服的 MLLM 评估基准。

##### **Training Free Guided Flow Matching with Optimal Control**
2410.18070v1 by Luran Wang, Chaoran Cheng, Yizhen Liao, Yanru Qu, Ge Liu

Controlled generation with pre-trained Diffusion and Flow Matching models has
vast applications. One strategy for guiding ODE-based generative models is
through optimizing a target loss $R(x_1)$ while staying close to the prior
distribution. Along this line, some recent work showed the effectiveness of
guiding flow model by differentiating through its ODE sampling process. Despite
the superior performance, the theoretical understanding of this line of methods
is still preliminary, leaving space for algorithm improvement. Moreover,
existing methods predominately focus on Euclidean data manifold, and there is a
compelling need for guided flow methods on complex geometries such as SO(3),
which prevails in high-stake scientific applications like protein design. We
present OC-Flow, a general and theoretically grounded training-free framework
for guided flow matching using optimal control. Building upon advances in
optimal control theory, we develop effective and practical algorithms for
solving optimal control in guided ODE-based generation and provide a systematic
theoretical analysis of the convergence guarantee in both Euclidean and SO(3).
We show that existing backprop-through-ODE methods can be interpreted as
special cases of Euclidean OC-Flow. OC-Flow achieved superior performance in
extensive experiments on text-guided image manipulation, conditional molecule
generation, and all-atom peptide design.

摘要：預訓練擴散與流匹配模型的受控生成有廣泛的應用。引導基於 ODE 的生成模型的一種策略是透過最佳化目標損失 $R(x_1)$，同時貼近先驗分佈。在此基礎上，一些近期研究顯示了透過其 ODE 採樣程序進行微分的有效性，以引導流模型。儘管有優異的效能，但對此方法系列的理論理解仍屬初步階段，為演算法的改善留下了空間。此外，現有方法主要關注歐幾里得資料流形，而對於複雜幾何（例如 SO(3)）上的引導流方法有迫切需求，這在蛋白質設計等高風險科學應用中很普遍。我們提出了 OC-Flow，這是一個使用最佳控制進行引導流匹配的通用且理論基礎紮實的無訓練框架。在最佳控制理論的進展基礎上，我們開發了有效且實用的演算法，用於求解引導式基於 ODE 的生成中的最佳控制，並對歐幾里得和 SO(3) 中的收斂保證提供了系統性的理論分析。我們表明，現有的透過 ODE 反向傳播的方法可以解釋為歐幾里得 OC-Flow 的特例。OC-Flow 在文字引導的影像處理、條件分子生成和全原子胜肽設計的廣泛實驗中獲得了優異的效能。

##### **Beyond position: how rotary embeddings shape representations and memory in autoregressive transfomers**
2410.18067v1 by Valeria Ruscio, Fabrizio Silvestri

Rotary Positional Embeddings (RoPE) enhance positional encoding in
Transformer models, yet their full impact on model dynamics remains
underexplored. This paper studies how RoPE introduces position-dependent
rotations, causing phase shifts in token embeddings that influence
higher-frequency components within the model's internal representations.
Through spectral analysis, we demonstrate that RoPE's rotation matrices induce
oscillatory behaviors in embeddings, affecting information retention across
layers and shaping temporal modeling capabilities. We show that activation
functions in feed-forward networks interact with RoPE-modulated embeddings to
generate harmonics, leading to constructive or destructive interference based
on phase alignment. Our findings reveal that phase alignment amplifies
activations and sharpens attention, while misalignment weakens activations and
disrupts focus on positional patterns. This study underscores the importance of
frequency components as intrinsic elements of model behavior, offering new
insights beyond traditional analyses.

摘要：旋轉位置嵌入 (RoPE) 增強了 Transformer 模型中的位置編碼，但它們對模型動態的全面影響仍未得到充分探討。本文研究了 RoPE 如何引入依位置而定的旋轉，導致令牌嵌入中的相位偏移，進而影響模型內部表示中的高頻成分。透過頻譜分析，我們證明了 RoPE 的旋轉矩陣會在嵌入中引發振盪行為，影響跨層次的信息保留並塑造時間建模能力。我們展示了前饋網路中的激活函數與 RoPE 調製的嵌入交互作用以產生泛音，從而基於相位對齊產生建設性或破壞性干擾。我們的研究結果表明，相位對齊會放大激活並強化注意力，而未對齊會削弱激活並破壞對位置模式的關注。這項研究強調了頻率成分作為模型行為內在元素的重要性，提供了超越傳統分析的新見解。

##### **Explaining Bayesian Networks in Natural Language using Factor Arguments. Evaluation in the medical domain**
2410.18060v1 by Jaime Sevilla, Nikolay Babakov, Ehud Reiter, Alberto Bugarin

In this paper, we propose a model for building natural language explanations
for Bayesian Network Reasoning in terms of factor arguments, which are
argumentation graphs of flowing evidence, relating the observed evidence to a
target variable we want to learn about. We introduce the notion of factor
argument independence to address the outstanding question of defining when
arguments should be presented jointly or separately and present an algorithm
that, starting from the evidence nodes and a target node, produces a list of
all independent factor arguments ordered by their strength. Finally, we
implemented a scheme to build natural language explanations of Bayesian
Reasoning using this approach. Our proposal has been validated in the medical
domain through a human-driven evaluation study where we compare the Bayesian
Network Reasoning explanations obtained using factor arguments with an
alternative explanation method. Evaluation results indicate that our proposed
explanation approach is deemed by users as significantly more useful for
understanding Bayesian Network Reasoning than another existing explanation
method it is compared to.

摘要：<paragraph>在本文中，我們提出了一個模型，用於建構貝氏網路推理的自然語言解釋，以因子論證為基礎，它們是流動證據的論證圖，將觀察到的證據與我們想要了解的目標變數聯繫起來。我們引入了因子論證獨立性的概念，以解決定義何時應將論證聯合或單獨呈現的未決問題，並提出了一種演算法，從證據節點和目標節點開始，產生一個按強度排序的所有獨立因子論證清單。最後，我們實作了一個方案，使用這種方法建構貝氏推理的自然語言解釋。我們的提案已在醫學領域中通過人為驅動的評估研究得到驗證，在該研究中，我們將使用因子論證獲得的貝氏網路推理解釋與另一種解釋方法進行比較。評估結果表明，與另一種現有的解釋方法相比，我們的提議解釋方法被使用者視為顯著更有助於理解貝氏網路推理。</paragraph>

##### **CLEAR: Character Unlearning in Textual and Visual Modalities**
2410.18057v1 by Alexey Dontsov, Dmitrii Korzh, Alexey Zhavoronkin, Boris Mikheev, Denis Bobkov, Aibek Alanov, Oleg Y. Rogov, Ivan Oseledets, Elena Tutubalina

Machine Unlearning (MU) is critical for enhancing privacy and security in
deep learning models, particularly in large multimodal language models (MLLMs),
by removing specific private or hazardous information. While MU has made
significant progress in textual and visual modalities, multimodal unlearning
(MMU) remains significantly underexplored, partially due to the absence of a
suitable open-source benchmark. To address this, we introduce CLEAR, a new
benchmark designed to evaluate MMU methods. CLEAR contains 200 fictitious
individuals and 3,700 images linked with corresponding question-answer pairs,
enabling a thorough evaluation across modalities. We assess 10 MU methods,
adapting them for MMU, and highlight new challenges specific to multimodal
forgetting. We also demonstrate that simple $\ell_1$ regularization on LoRA
weights significantly mitigates catastrophic forgetting, preserving model
performance on retained data. The dataset is available at
https://huggingface.co/datasets/therem/CLEAR

摘要：機器去學習（MU）對於增強深度學習模型的隱私和安全性至關重要，特別是在大型多模態語言模型（MLLM）中，透過移除特定的私人或有害資訊。儘管 MU 在文字和視覺模式方面已取得顯著進展，但多模態去學習（MMU）仍顯著未被充分探討，部分原因是缺乏適當的開源基準。為了解決這個問題，我們引入了 CLEAR，一個新的基準，旨在評估 MMU 方法。CLEAR 包含 200 個虛構人物和 3,700 張與對應問題答案配對的圖片，可以在不同的模式中進行徹底的評估。我們評估了 10 種 MU 方法，並將它們調整為 MMU，並強調了多模態遺忘的特定新挑戰。我們還展示了 LoRA 權重上的簡單 $\ell_1$ 正則化顯著減輕了災難性遺忘，保留了模型在保留資料上的效能。資料集可在 https://huggingface.co/datasets/therem/CLEAR 取得

##### **LongRAG: A Dual-Perspective Retrieval-Augmented Generation Paradigm for Long-Context Question Answering**
2410.18050v1 by Qingfei Zhao, Ruobing Wang, Yukuo Cen, Daren Zha, Shicheng Tan, Yuxiao Dong, Jie Tang

Long-Context Question Answering (LCQA), a challenging task, aims to reason
over long-context documents to yield accurate answers to questions. Existing
long-context Large Language Models (LLMs) for LCQA often struggle with the
"lost in the middle" issue. Retrieval-Augmented Generation (RAG) mitigates this
issue by providing external factual evidence. However, its chunking strategy
disrupts the global long-context information, and its low-quality retrieval in
long contexts hinders LLMs from identifying effective factual details due to
substantial noise. To this end, we propose LongRAG, a general,
dual-perspective, and robust LLM-based RAG system paradigm for LCQA to enhance
RAG's understanding of complex long-context knowledge (i.e., global information
and factual details). We design LongRAG as a plug-and-play paradigm,
facilitating adaptation to various domains and LLMs. Extensive experiments on
three multi-hop datasets demonstrate that LongRAG significantly outperforms
long-context LLMs (up by 6.94%), advanced RAG (up by 6.16%), and Vanilla RAG
(up by 17.25%). Furthermore, we conduct quantitative ablation studies and
multi-dimensional analyses, highlighting the effectiveness of the system's
components and fine-tuning strategies. Data and code are available at
https://github.com/QingFei1/LongRAG.

摘要：長文本問答 (LCQA) 是一項具有挑戰性的任務，旨在對長文本文件進行推理，以對問題提供準確的答案。現有的長文本大型語言模型 (LLM) 對於 LCQA 經常會遇到「迷失在中間」的問題。檢索增強生成 (RAG) 可透過提供外部事實證據來緩解此問題。然而，其分塊策略會中斷全局長文本資訊，且其在長文本中的低品質檢索會因為大量的雜訊，而阻礙 LLM 找出有效的實際細節。為了解決此問題，我們提出 LongRAG，一個針對 LCQA 的通用、雙重觀點且強健的基於 LLM 的 RAG 系統範例，以增強 RAG 對複雜長文本知識（例如，全局資訊和實際細節）的理解。我們將 LongRAG 設計為一個即插即用的範例，方便調整到各種網域和 LLM。針對三個多跳躍資料集進行的廣泛實驗顯示，LongRAG 明顯優於長文本 LLM（提升 6.94%）、進階 RAG（提升 6.16%）和 Vanilla RAG（提升 17.25%）。此外，我們進行了定量的消融研究和多維度分析，強調了系統組成和微調策略的有效性。資料和程式碼可在 https://github.com/QingFei1/LongRAG 取得。

##### **Key Algorithms for Keyphrase Generation: Instruction-Based LLMs for Russian Scientific Keyphrases**
2410.18040v1 by Anna Glazkova, Dmitry Morozov, Timur Garipov

Keyphrase selection is a challenging task in natural language processing that
has a wide range of applications. Adapting existing supervised and unsupervised
solutions for the Russian language faces several limitations due to the rich
morphology of Russian and the limited number of training datasets available.
Recent studies conducted on English texts show that large language models
(LLMs) successfully address the task of generating keyphrases. LLMs allow
achieving impressive results without task-specific fine-tuning, using text
prompts instead. In this work, we access the performance of prompt-based
methods for generating keyphrases for Russian scientific abstracts. First, we
compare the performance of zero-shot and few-shot prompt-based methods,
fine-tuned models, and unsupervised methods. Then we assess strategies for
selecting keyphrase examples in a few-shot setting. We present the outcomes of
human evaluation of the generated keyphrases and analyze the strengths and
weaknesses of the models through expert assessment. Our results suggest that
prompt-based methods can outperform common baselines even using simple text
prompts.

摘要：關鍵字選取是自然語言處理中的一項挑戰性任務，具有廣泛的應用。由於俄語豐富的形態和有限的訓練資料集，採用現有的監督式和非監督式解決方案來適應俄語面臨著一些限制。最近對英語文本進行的研究表明，大型語言模型 (LLM) 成功地解決了生成關鍵字的任務。LLM 允許在不進行特定於任務的微調的情況下實現令人印象深刻的結果，而是使用文本提示。在這項工作中，我們訪問了基於提示的方法在為俄羅斯科學摘要生成關鍵字方面的性能。首先，我們比較了零次和少次基於提示的方法、微調模型和非監督式方法的性能。然後，我們評估在少次設置中選擇關鍵字範例的策略。我們展示了對生成關鍵字的人工評估結果，並通過專家評估分析模型的優點和缺點。我們的結果表明，即使使用簡單的文本提示，基於提示的方法也可以優於常見的基準。

##### **MiLoRA: Efficient Mixture of Low-Rank Adaptation for Large Language Models Fine-tuning**
2410.18035v1 by Jingfan Zhang, Yi Zhao, Dan Chen, Xing Tian, Huanran Zheng, Wei Zhu

Low-rank adaptation (LoRA) and its mixture-of-experts (MOE) variants are
highly effective parameter-efficient fine-tuning (PEFT) methods. However, they
introduce significant latency in multi-tenant settings due to the LoRA modules
and MOE routers added to multiple linear modules in the Transformer layer. To
address this issue, we propose Mixture of Low-Rank Adaptation (MiLoRA), a novel
and efficient LoRA variant. MiLoRA differs from previous MOE-style LoRA methods
by considering each LoRA module as an expert and employing a prompt-aware
routing mechanism. This mechanism calculates expert routing results once before
generating the first new token and reuses these results for subsequent tokens,
reducing latency. Extensive experiments and analysis on commonsense reasoning
tasks, math reasoning tasks, and widely used LLM evaluation benchmarks
demonstrate that MiLoRA consistently outperforms strong PEFT baselines with
comparable tunable parameter budgets. Additionally, MiLoRA significantly
reduces latency in multi-tenant settings compared to previous LoRA-based
methods.

摘要：低秩適應 (LoRA) 及其混合專家 (MOE) 變體是高效率的參數有效微調 (PEFT) 方法。然而，由於在 Transformer 層中加入了 LoRA 模組和 MOE 路由器到多個線性模組中，它們在多租戶設定中引入了顯著的延遲。為了解決這個問題，我們提出了低秩適應混合 (MiLoRA)，一種新穎且高效的 LoRA 變體。MiLoRA 與先前的 MOE 風格 LoRA 方法不同，它將每個 LoRA 模組視為專家，並採用提示感知路由機制。此機制在產生第一個新符號之前計算一次專家路由結果，並將這些結果重複使用於後續符號，從而降低延遲。在常識推理任務、數學推理任務和廣泛使用的 LLM 評估基準上的廣泛實驗和分析表明，MiLoRA 持續優於具有可比較可調整參數預算的強大 PEFT 基準。此外，與先前的基於 LoRA 的方法相比，MiLoRA 在多租戶設定中顯著降低了延遲。

##### **GraphTeam: Facilitating Large Language Model-based Graph Analysis via Multi-Agent Collaboration**
2410.18032v1 by Xin Li, Qizhi Chu, Yubin Chen, Yang Liu, Yaoqi Liu, Zekai Yu, Weize Chen, Chen Qian, Chuan Shi, Cheng Yang

Graphs are widely used for modeling relational data in real-world scenarios,
such as social networks and urban computing. Existing LLM-based graph analysis
approaches either integrate graph neural networks (GNNs) for specific machine
learning tasks, limiting their transferability, or rely solely on LLMs'
internal reasoning ability, resulting in suboptimal performance. To address
these limitations, we take advantage of recent advances in LLM-based agents,
which have shown capabilities of utilizing external knowledge or tools for
problem solving. By simulating human problem-solving strategies such as analogy
and collaboration, we propose a multi-agent system based on LLMs named
GraphTeam, for graph analysis. GraphTeam consists of five LLM-based agents from
three modules, and the agents with different specialities can collaborate with
each other to address complex problems. Specifically, (1) input-output
normalization module: the question agent extracts and refines four key
arguments from the original question, facilitating the problem understanding,
and the answer agent organizes the results to meet the output requirement; (2)
external knowledge retrieval module: we first build a knowledge base consisting
of relevant documentation and experience information, and then the search agent
retrieves the most relevant entries for each question. (3) problem-solving
module: given the retrieved information from search agent, the coding agent
uses established algorithms via programming to generate solutions, and in case
the coding agent does not work, the reasoning agent will directly compute the
results without programming. Extensive experiments on six graph analysis
benchmarks demonstrate that GraphTeam achieves state-of-the-art performance
with an average 25.85% improvement over the best baseline in terms of accuracy.
The code and data are available at https://github.com/BUPT-GAMMA/GraphTeam.

摘要：<paragraph>圖表廣泛用於在現實世界的場景中對關聯資料進行建模，例如社交網路和城市運算。現有的基於 LLM 的圖表分析方法，不是整合圖神經網路 (GNN) 來執行特定的機器學習任務，限制了它們的可轉移性，就是單純依賴 LLM 的內部推理能力，導致次佳的效能。為了解決這些限制，我們利用 LLM 基於代理的最新進展，這些進展已展現出利用外部知識或工具來解決問題的能力。透過模擬類比和協作等人類問題解決策略，我們提出了一個基於 LLM 的多代理系統，稱為 GraphTeam，用於圖表分析。GraphTeam 由來自三個模組的五個基於 LLM 的代理組成，而具有不同專業知識的代理可以彼此協作，以解決複雜的問題。具體來說，（1）輸入輸出正規化模組：問題代理從原始問題中萃取和精煉出四個關鍵論點，促進問題理解，而答案代理則整理結果以符合輸出需求；（2）外部知識擷取模組：我們首先建立一個由相關文件和經驗資訊組成的知識庫，然後搜尋代理會為每個問題擷取最相關的條目。（3）問題解決模組：在給定從搜尋代理擷取的資訊後，編碼代理會透過程式設計使用已建立的演算法來產生解決方案，而如果編碼代理無法運作，推理代理將會直接在沒有程式設計的情況下計算結果。在六個圖表分析基準上的廣泛實驗證明，GraphTeam 達到了最先進的效能，在準確度方面比最佳基準線平均提升了 25.85%。程式碼和資料可在 https://github.com/BUPT-GAMMA/GraphTeam 取得。</paragraph>

##### **Cross-lingual Transfer of Reward Models in Multilingual Alignment**
2410.18027v1 by Jiwoo Hong, Noah Lee, Rodrigo Martínez-Castaño, César Rodríguez, James Thorne

Reinforcement learning with human feedback (RLHF) is shown to largely benefit
from precise reward models (RMs). However, recent studies in reward modeling
schemes are skewed towards English, limiting the applicability of RLHF in
multilingual alignments. In this work, we investigate the cross-lingual
transfer of RMs trained in diverse languages, primarily from English. Our
experimental results demonstrate the strong cross-lingual transfer of English
RMs, exceeding target language RMs by 3~4% average increase in Multilingual
RewardBench. Furthermore, we analyze the cross-lingual transfer of RMs through
the representation shifts. Finally, we perform multilingual alignment to
exemplify how cross-lingual transfer in RM propagates to enhanced multilingual
instruction-following capability, along with extensive analyses on
off-the-shelf RMs. We release the code, model, and data.

摘要：強化學習搭配人類回饋（RLHF）已證實可從精準的獎勵模型（RM）中獲益良多。然而，最近在獎勵模型配置方面的研究偏向於英文，這限制了 RLHF 在多語言比對中的適用性。在這項研究中，我們探討以不同語言（主要是英文）訓練的 RM 之間的跨語言轉移。我們的實驗結果證明了英文 RM 的強大跨語言轉移能力，在多語言 RewardBench 中平均增加了 3~4%，超過了目標語言 RM。此外，我們透過表徵轉移分析了 RM 的跨語言轉移。最後，我們執行多語言比對，以說明 RM 中的跨語言轉移如何傳播到增強的多語言指令遵循能力，並對現成 RM 進行廣泛分析。我們將釋出程式碼、模型和資料。

##### **Benchmarking Foundation Models on Exceptional Cases: Dataset Creation and Validation**
2410.18001v1 by Suho Kang, Jungyang Park, Joonseo Ha, SoMin Kim, JinHyeong Kim, Subeen Park, Kyungwoo Song

Foundation models (FMs) have achieved significant success across various
tasks, leading to research on benchmarks for reasoning abilities. However,
there is a lack of studies on FMs performance in exceptional scenarios, which
we define as out-of-distribution (OOD) reasoning tasks. This paper is the first
to address these cases, developing a novel dataset for evaluation of FMs across
multiple modalities, including graphic novels, calligraphy, news articles, and
lyrics. It includes tasks for instance classification, character recognition,
token prediction, and text generation. The paper also proposes prompt
engineering techniques like Chain-of-Thought (CoT) and CoT+Few-Shot to enhance
performance. Validation of FMs using various methods revealed improvements. The
code repository is accessible at:
https://github.com/MLAI-Yonsei/ExceptionalBenchmark

摘要：基礎模型 (FM) 已在各種任務中取得重大成功，進而促成對推理能力基準的研究。然而，缺乏針對 FM 在特殊情況下的效能研究，我們將其定義為分布外 (OOD) 推理任務。本文率先探討這些案例，開發出一種新穎的資料集，用於評估跨多模態的 FM，包括圖像小說、書法、新聞文章和歌詞。其中包含用於實例分類、字元辨識、符號預測和文字生成的任務。本文也提出提示工程技術，例如思考鏈 (CoT) 和 CoT+Few-Shot，以提升效能。使用各種方法驗證 FM，結果顯示有改善。程式碼儲存庫可於下列網址取得：
https://github.com/MLAI-Yonsei/ExceptionalBenchmark

##### **Federated Transformer: Multi-Party Vertical Federated Learning on Practical Fuzzily Linked Data**
2410.17986v1 by Zhaomin Wu, Junyi Hou, Yiqun Diao, Bingsheng He

Federated Learning (FL) is an evolving paradigm that enables multiple parties
to collaboratively train models without sharing raw data. Among its variants,
Vertical Federated Learning (VFL) is particularly relevant in real-world,
cross-organizational collaborations, where distinct features of a shared
instance group are contributed by different parties. In these scenarios,
parties are often linked using fuzzy identifiers, leading to a common practice
termed as multi-party fuzzy VFL. Existing models generally address either
multi-party VFL or fuzzy VFL between two parties. Extending these models to
practical multi-party fuzzy VFL typically results in significant performance
degradation and increased costs for maintaining privacy. To overcome these
limitations, we introduce the Federated Transformer (FeT), a novel framework
that supports multi-party VFL with fuzzy identifiers. FeT innovatively encodes
these identifiers into data representations and employs a transformer
architecture distributed across different parties, incorporating three new
techniques to enhance performance. Furthermore, we have developed a multi-party
privacy framework for VFL that integrates differential privacy with secure
multi-party computation, effectively protecting local representations while
minimizing associated utility costs. Our experiments demonstrate that the FeT
surpasses the baseline models by up to 46\% in terms of accuracy when scaled to
50 parties. Additionally, in two-party fuzzy VFL settings, FeT also shows
improved performance and privacy over cutting-edge VFL models.

摘要：聯邦學習 (FL) 是一種不斷演進的範例，它讓多方能夠在不共享原始資料的情況下協作訓練模型。在它的變體中，垂直聯邦學習 (VFL) 特別適用於現實世界的跨組織協作，其中共享實例群組的不同特徵是由不同的參與方所提供。在這些場景中，參與方通常使用模糊識別碼連結，導致一種稱為多方模糊 VFL 的常見做法。現有的模型通常處理多方 VFL 或兩個參與方之間的模糊 VFL。將這些模型擴展到實際的多方模糊 VFL 通常會導致顯著的效能下降和維護隱私的成本增加。為了克服這些限制，我們引入了聯邦轉換器 (FeT)，這是一個新穎的框架，支援使用模糊識別碼的多方 VFL。FeT 創新地將這些識別碼編碼到資料表示中，並採用分佈在不同參與方之間的轉換器架構，並結合三種新技術來增強效能。此外，我們開發了一個適用於 VFL 的多方隱私框架，它將差分隱私與安全的多方運算整合在一起，有效地保護本地表示，同時將相關的實用程式成本降到最低。我們的實驗表明，當擴展到 50 個參與方時，FeT 在準確性方面比基準模型高出 46%。此外，在雙方模糊 VFL 設定中，FeT 也展現出比尖端的 VFL 模型更好的效能和隱私。

##### **Together We Can: Multilingual Automatic Post-Editing for Low-Resource Languages**
2410.17973v1 by Sourabh Deoghare, Diptesh Kanojia, Pushpak Bhattacharyya

This exploratory study investigates the potential of multilingual Automatic
Post-Editing (APE) systems to enhance the quality of machine translations for
low-resource Indo-Aryan languages. Focusing on two closely related language
pairs, English-Marathi and English-Hindi, we exploit the linguistic
similarities to develop a robust multilingual APE model. To facilitate
cross-linguistic transfer, we generate synthetic Hindi-Marathi and
Marathi-Hindi APE triplets. Additionally, we incorporate a Quality Estimation
(QE)-APE multi-task learning framework. While the experimental results
underline the complementary nature of APE and QE, we also observe that QE-APE
multitask learning facilitates effective domain adaptation. Our experiments
demonstrate that the multilingual APE models outperform their corresponding
English-Hindi and English-Marathi single-pair models by $2.5$ and $2.39$ TER
points, respectively, with further notable improvements over the multilingual
APE model observed through multi-task learning ($+1.29$ and $+1.44$ TER
points), data augmentation ($+0.53$ and $+0.45$ TER points) and domain
adaptation ($+0.35$ and $+0.45$ TER points). We release the synthetic data,
code, and models accrued during this study publicly at
https://github.com/cfiltnlp/Multilingual-APE.

摘要：這項探索性研究調查了多語言自動後編輯 (APE) 系統增強低資源印度雅利安語機器翻譯品質的潛力。專注於兩對密切相關的語言對，英語-馬拉地語和英語-印地語，我們利用語言相似性來開發強健的多語言 APE 模型。為促進跨語言轉移，我們產生合成的印地語-馬拉地語和馬拉地語-印地語 APE 三元組。此外，我們結合品質評估 (QE)-APE 多任務學習架構。雖然實驗結果強調 APE 和 QE 的互補性質，但我們也觀察到 QE-APE 多任務學習促進有效的領域適應。我們的實驗證明，多語言 APE 模型分別以 2.5 和 2.39 TER 點優於對應的英語-印地語和英語-馬拉地語單對模型，通過多任務學習（+1.29 和 +1.44 TER 點）、資料擴充（+0.53 和 +0.45 TER 點）和領域適應（+0.35 和 +0.45 TER 點）進一步觀察到多語言 APE 模型的顯著改進。我們在 https://github.com/cfiltnlp/Multilingual-APE 公開發布本研究期間累積的合成資料、程式碼和模型。

##### **A Time-Aware Approach to Early Detection of Anorexia: UNSL at eRisk 2024**
2410.17963v1 by Horacio Thompson, Marcelo Errecalde

The eRisk laboratory aims to address issues related to early risk detection
on the Web. In this year's edition, three tasks were proposed, where Task 2 was
about early detection of signs of anorexia. Early risk detection is a problem
where precision and speed are two crucial objectives. Our research group solved
Task 2 by defining a CPI+DMC approach, addressing both objectives
independently, and a time-aware approach, where precision and speed are
considered a combined single-objective. We implemented the last approach by
explicitly integrating time during the learning process, considering the
ERDE{\theta} metric as the training objective. It also allowed us to
incorporate temporal metrics to validate and select the optimal models. We
achieved outstanding results for the ERDE50 metric and ranking-based metrics,
demonstrating consistency in solving ERD problems.

摘要：eRisk 實驗室旨在解決與網路早期風險偵測相關的問題。在今年的版本中，提出了三項任務，其中任務 2 是關於早期偵測厭食症徵兆。早期風險偵測是一個問題，其中精準度和速度是兩個關鍵目標。我們的研究小組透過定義 CPI+DMC 方法來解決任務 2，獨立處理這兩個目標，以及一種時間感知方法，其中精準度和速度被視為一個單一目標。我們透過在學習過程中明確整合時間，並將 ERDE{\theta} 指標視為訓練目標，來實作最後一種方法。它也允許我們納入時間指標來驗證和選擇最佳模型。我們在 ERDE50 指標和基於排名的指標中獲得傑出的結果，證明了在解決 ERD 問題上的一致性。

##### **Closed-form merging of parameter-efficient modules for Federated Continual Learning**
2410.17961v1 by Riccardo Salami, Pietro Buzzega, Matteo Mosconi, Jacopo Bonato, Luigi Sabetta, Simone Calderara

Model merging has emerged as a crucial technique in Deep Learning, enabling
the integration of multiple models into a unified system while preserving
performance and scalability. In this respect, the compositional properties of
low-rank adaptation techniques (e.g., LoRA) have proven beneficial, as simple
averaging LoRA modules yields a single model that mostly integrates the
capabilities of all individual modules. Building on LoRA, we take a step
further by imposing that the merged model matches the responses of all learned
modules. Solving this objective in closed form yields an indeterminate system
with A and B as unknown variables, indicating the existence of infinitely many
closed-form solutions. To address this challenge, we introduce LoRM, an
alternating optimization strategy that trains one LoRA matrix at a time. This
allows solving for each unknown variable individually, thus finding a unique
solution. We apply our proposed methodology to Federated Class-Incremental
Learning (FCIL), ensuring alignment of model responses both between clients and
across tasks. Our method demonstrates state-of-the-art performance across a
range of FCIL scenarios.

摘要：模型合併已成為深度學習中的一項關鍵技術，它能將多個模型整合到一個統一的系統中，同時保留效能和可擴充性。在此方面，低秩適應技術（例如 LoRA）的組合特性已被證明是有益的，因為簡單地平均 LoRA 模組會產生一個單一模型，該模型大多整合了所有個別模組的功能。在 LoRA 的基礎上，我們進一步採取措施，強制合併模型與所有學習模組的回應相符。以封閉形式解決此目標會產生一個不確定的系統，其中 A 和 B 是未知變數，這表示存在無限多個封閉形式解。為了應對這個挑戰，我們引入了 LoRM，這是一個交替最佳化策略，一次訓練一個 LoRA 矩陣。這允許個別求解每個未知變數，從而找到一個唯一的解。我們將我們提出的方法應用於聯合類別增量學習 (FCIL)，確保模型回應在客戶端和任務之間的一致性。我們的模型在各種 FCIL 場景中展現了最先進的效能。

##### **Zeitenwenden: Detecting changes in the German political discourse**
2410.17960v1 by Kai-Robin Lange, Jonas Rieger, Niklas Benner, Carsten Jentsch

From a monarchy to a democracy, to a dictatorship and back to a democracy --
the German political landscape has been constantly changing ever since the
first German national state was formed in 1871. After World War II, the Federal
Republic of Germany was formed in 1949. Since then every plenary session of the
German Bundestag was logged and even has been digitized over the course of the
last few years. We analyze these texts using a time series variant of the topic
model LDA to investigate which events had a lasting effect on the political
discourse and how the political topics changed over time. This allows us to
detect changes in word frequency (and thus key discussion points) in political
discourse.

摘要：從君主制到民主制，再到獨裁制，最後又回到民主制——
自 1871 年第一個德國民族國家成立以來，德國的政治版圖一直在不斷變化。二戰後，德意志聯邦共和國於 1949 年成立。從那時起，德國聯邦議會的每一次全體會議都會被記錄下來，甚至在過去幾年裡已經被數位化。我們使用主題模型 LDA 的時間序列變體來分析這些文本，以調查哪些事件對政治論述產生了持久影響，以及政治議題如何隨著時間而改變。這讓我們能夠檢測政治論述中詞頻（以及關鍵討論點）的變化。

##### **MCUBERT: Memory-Efficient BERT Inference on Commodity Microcontrollers**
2410.17957v1 by Zebin Yang, Renze Chen, Taiqiang Wu, Ngai Wong, Yun Liang, Runsheng Wang, Ru Huang, Meng Li

In this paper, we propose MCUBERT to enable language models like BERT on tiny
microcontroller units (MCUs) through network and scheduling co-optimization. We
observe the embedding table contributes to the major storage bottleneck for
tiny BERT models. Hence, at the network level, we propose an MCU-aware
two-stage neural architecture search algorithm based on clustered low-rank
approximation for embedding compression. To reduce the inference memory
requirements, we further propose a novel fine-grained MCU-friendly scheduling
strategy. Through careful computation tiling and re-ordering as well as kernel
design, we drastically increase the input sequence lengths supported on MCUs
without any latency or accuracy penalty. MCUBERT reduces the parameter size of
BERT-tiny and BERT-mini by 5.7$\times$ and 3.0$\times$ and the execution memory
by 3.5$\times$ and 4.3$\times$, respectively. MCUBERT also achieves 1.5$\times$
latency reduction. For the first time, MCUBERT enables lightweight BERT models
on commodity MCUs and processing more than 512 tokens with less than 256KB of
memory.

摘要：在本文中，我們提出 MCUBERT，透過網路和排程共同最佳化，在微型微控制器單元 (MCU) 上啟用類似 BERT 的語言模型。我們觀察到嵌入式表格對微型 BERT 模型的主要儲存瓶頸有所貢獻。因此，在網路層級，我們提出一個基於分群低秩近似的 MCU 感知兩階段神經架構搜尋演算法，用於嵌入式壓縮。為了減少推論記憶體需求，我們進一步提出一個新穎的細粒度 MCU 友善排程策略。透過仔細的運算分割和重新排序以及核心設計，我們大幅增加 MCU 上支援的輸入序列長度，而不會有任何延遲或準確度損失。MCUBERT 將 BERT-tiny 和 BERT-mini 的參數大小分別減少了 5.7 倍和 3.0 倍，執行記憶體分別減少了 3.5 倍和 4.3 倍。MCUBERT 也達到了 1.5 倍的延遲減少。MCUBERT 首次在商品 MCU 上啟用輕量級 BERT 模型，並以小於 256KB 的記憶體處理超過 512 個符號。

##### **ExpertFlow: Optimized Expert Activation and Token Allocation for Efficient Mixture-of-Experts Inference**
2410.17954v1 by Xin He, Shunkang Zhang, Yuxin Wang, Haiyan Yin, Zihao Zeng, Shaohuai Shi, Zhenheng Tang, Xiaowen Chu, Ivor Tsang, Ong Yew Soon

Sparse Mixture of Experts (MoE) models, while outperforming dense Large
Language Models (LLMs) in terms of performance, face significant deployment
challenges during inference due to their high memory demands. Existing
offloading techniques, which involve swapping activated and idle experts
between the GPU and CPU, often suffer from rigid expert caching mechanisms.
These mechanisms fail to adapt to dynamic routing, leading to inefficient cache
utilization, or incur prohibitive costs for prediction training. To tackle
these inference-specific challenges, we introduce ExpertFlow, a comprehensive
system specifically designed to enhance inference efficiency by accommodating
flexible routing and enabling efficient expert scheduling between CPU and GPU.
This reduces overhead and boosts system performance. Central to our approach is
a predictive routing path-based offloading mechanism that utilizes a
lightweight predictor to accurately forecast routing paths before computation
begins. This proactive strategy allows for real-time error correction in expert
caching, significantly increasing cache hit ratios and reducing the frequency
of expert transfers, thereby minimizing I/O overhead. Additionally, we
implement a dynamic token scheduling strategy that optimizes MoE inference by
rearranging input tokens across different batches. This method not only reduces
the number of activated experts per batch but also improves computational
efficiency. Our extensive experiments demonstrate that ExpertFlow achieves up
to 93.72\% GPU memory savings and enhances inference speed by 2 to 10 times
compared to baseline methods, highlighting its effectiveness and utility as a
robust solution for resource-constrained inference scenarios.

摘要：稀疏专家混合（MoE）模型虽然在性能方面优于稠密大语言模型（LLM），但在推理过程中由于其高内存需求而面临着重大的部署挑战。现有的卸载技术涉及在 GPU 和 CPU 之间交换激活的和空闲的专家，通常会受到僵化的专家缓存机制的影响。这些机制无法适应动态路由，导致缓存利用率低下，或导致预测训练成本过高。为了应对这些特定于推理的挑战，我们引入了 ExpertFlow，这是一个专门设计用于通过适应灵活路由和在 CPU 和 GPU 之间实现高效专家调度来提高推理效率的综合系统。这减少了开销并提高了系统性能。我们方法的核心是一个基于预测路由路径的卸载机制，该机制利用一个轻量级预测器在计算开始之前准确预测路由路径。这种主动策略允许在专家缓存中进行实时错误校正，显著提高缓存命中率并降低专家传输的频率，从而最大程度地减少 I/O 开销。此外，我们实施了一个动态令牌调度策略，通过在不同的批次之间重新排列输入令牌来优化 MoE 推理。这种方法不仅减少了每个批次中激活的专家数量，还提高了计算效率。我们广泛的实验表明，与基线方法相比，ExpertFlow 可节省高达 93.72% 的 GPU 内存，并将推理速度提高 2 到 10 倍，突出了其作为资源受限推理场景的稳健解决方案的有效性和实用性。

##### **SimRAG: Self-Improving Retrieval-Augmented Generation for Adapting Large Language Models to Specialized Domains**
2410.17952v1 by Ran Xu, Hui Liu, Sreyashi Nag, Zhenwei Dai, Yaochen Xie, Xianfeng Tang, Chen Luo, Yang Li, Joyce C. Ho, Carl Yang, Qi He

Retrieval-augmented generation (RAG) enhances the question-answering (QA)
abilities of large language models (LLMs) by integrating external knowledge.
However, adapting general-purpose RAG systems to specialized fields such as
science and medicine poses unique challenges due to distribution shifts and
limited access to domain-specific data. To tackle this, we propose SimRAG, a
self-training approach that equips the LLM with joint capabilities of question
answering and question generation for domain adaptation. Our method first
fine-tunes the LLM on instruction-following, question-answering, and
search-related data. Then, it prompts the same LLM to generate diverse
domain-relevant questions from unlabeled corpora, with an additional filtering
strategy to retain high-quality synthetic examples. By leveraging these
synthetic examples, the LLM can improve their performance on domain-specific
RAG tasks. Experiments on 11 datasets, spanning two backbone sizes and three
domains, demonstrate that SimRAG outperforms baselines by 1.2\%--8.6\%.

摘要：檢索增強生成 (RAG) 透過整合外部知識來增強大型語言模型 (LLM) 的問答 (QA) 能力。然而，將通用 RAG 系統調整到科學和醫學等專業領域會產生獨特的挑戰，因為分佈轉移和特定領域資料的取得有限。為了解決這個問題，我們提出 SimRAG，這是一種自訓練方法，可為 LLM 提供問題解答和問題生成聯合功能，以進行領域適應。我們的做法首先對 LLM 進行微調，以遵循指令、回答問題和搜尋相關資料。然後，它提示同一個 LLM 從未標記的語料庫中產生多樣化的與領域相關的問題，並採用額外的過濾策略來保留高品質的合成範例。透過利用這些合成範例，LLM 可以提升其在特定領域 RAG 任務上的表現。在 11 個資料集上的實驗，涵蓋兩個主幹大小和三個領域，證明 SimRAG 的表現優於基準線 1.2%--8.6%。

##### **Benchmarking Floworks against OpenAI & Anthropic: A Novel Framework for Enhanced LLM Function Calling**
2410.17950v1 by Nirav Bhan, Shival Gupta, Sai Manaswini, Ritik Baba, Narun Yadav, Hillori Desai, Yash Choudhary, Aman Pawar, Sarthak Shrivastava, Sudipta Biswas

Large Language Models (LLMs) have shown remarkable capabilities in various
domains, yet their economic impact has been limited by challenges in tool use
and function calling. This paper introduces ThorV2, a novel architecture that
significantly enhances LLMs' function calling abilities. We develop a
comprehensive benchmark focused on HubSpot CRM operations to evaluate ThorV2
against leading models from OpenAI and Anthropic. Our results demonstrate that
ThorV2 outperforms existing models in accuracy, reliability, latency, and cost
efficiency for both single and multi-API calling tasks. We also show that
ThorV2 is far more reliable and scales better to multistep tasks compared to
traditional models. Our work offers the tantalizing possibility of more
accurate function-calling compared to today's best-performing models using
significantly smaller LLMs. These advancements have significant implications
for the development of more capable AI assistants and the broader application
of LLMs in real-world scenarios.

摘要：大型語言模型 (LLM) 已在各種領域展示出卓越的能力，但其經濟影響受到工具使用和功能調用的挑戰所限制。本文介紹了 ThorV2，這是一種新穎的架構，可顯著增強 LLM 的函數調用能力。我們開發了一個專注於 HubSpot CRM 操作的綜合基準，以評估 ThorV2 與 OpenAI 和 Anthropic 的領先模型。我們的結果表明，對於單一和多 API 調用任務，ThorV2 在準確性、可靠性、延遲和成本效率方面都優於現有模型。我們還表明，與傳統模型相比，ThorV2 的可靠性更高，並且可以更好地擴展到多步驟任務。與當今性能最佳的模型相比，我們的研究工作提供了更準確的函數調用的誘人可能性，同時使用顯著更小的 LLM。這些進步對開發更強大的 AI 助手和在現實場景中更廣泛地應用 LLM 具有重大意義。

##### **Optimizing Travel Itineraries with AI Algorithms in a Microservices Architecture: Balancing Cost, Time, Preferences, and Sustainability**
2410.17943v1 by Biman Barua, M. Shamim Kaiser

The objective of this research is how an implementation of AI algorithms in
the microservices architecture enhances travel itineraries by cost, time, user
preferences, and environmental sustainability. It uses machine learning models
for both cost forecasting and personalization, genetic algorithm for
optimization of the itinerary, and heuristics for sustainability checking.
Primary evaluated parameters consist of latency, ability to satisfy user
preferences, cost and environmental concern. The experimental results
demonstrate an average of 4.5 seconds of response time on 1000 concurrent users
and 92% of user preferences accuracy. The cost efficiency is proved, with 95%
of provided trips being within the limits of the budget declared by the user.
The system also implements some measures to alleviate negative externalities
related to travel and 60% of offered travel plans had green options
incorporated, resulting in the average 15% lower carbon emissions than the
traditional travel plans offered. The genetic algorithm with time complexity
O(g.p.f) provides the optimal solution in 100 generations. Every iteration
improves the quality of the solution by 5%, thus enabling its effective use in
optimization problems where time is measured in seconds. Finally, the system is
designed to be fault-tolerant with functional 99.9% availability which allows
the provision of services even when requirements are exceeded. Travel
optimization platform is turned dynamic and efficient by this microservices
based architecture which provides enhanced scaling, allows asynchronous
communication and real time changes. Because of the incorporation of Ai, cost
control and eco-friendliness approaches, the system addresses the different
user needs in the present days travel business.

摘要：本研究的目的是探討在微服務架構中實作 AI 演算法如何透過成本、時間、使用者偏好和環境永續性等因素來提升旅遊行程。它使用機器學習模型進行成本預測和個人化、遺傳演算法進行行程最佳化，以及啟發式演算法進行永續性檢查。主要評估參數包括延遲、滿足使用者偏好的能力、成本和環境考量。實驗結果顯示，在 1000 個同時使用者上平均回應時間為 4.5 秒，使用者偏好準確度為 92%。成本效益已獲得證明，95% 的行程都在使用者所聲明的預算限制內。系統也實作了一些措施來減輕與旅遊相關的負面外部性，且 60% 的旅遊計畫納入了綠色選項，平均碳排放量比傳統旅遊計畫低 15%。時間複雜度為 O(g.p.f) 的遺傳演算法在 100 個世代中提供了最佳解。每次反覆運算都會將解的品質提升 5%，進而使其能夠有效用於時間以秒為單位的最佳化問題中。最後，系統被設計成具有容錯能力，功能可用性達 99.9%，即使需求超載也能提供服務。旅遊最佳化平台透過此微服務架構變得動態且有效率，它提供了擴充性、允許非同步通訊和即時變更。系統由於納入了 AI、成本控制和生態友善方法，因此能滿足現今旅遊產業中不同的使用者需求。

##### **Multi-Continental Healthcare Modelling Using Blockchain-Enabled Federated Learning**
2410.17933v1 by Rui Sun, Zhipeng Wang, Hengrui Zhang, Ming Jiang, Yizhe Wen, Jiqun Zhang, Jiahao Sun, Shuoying Zhang, Erwu Liu, Kezhi Li

One of the biggest challenges of building artificial intelligence (AI) model
in healthcare area is the data sharing. Since healthcare data is private,
sensitive, and heterogeneous, collecting sufficient data for modelling is
exhausted, costly, and sometimes impossible. In this paper, we propose a
framework for global healthcare modelling using datasets from multi-continents
(Europe, North America and Asia) while without sharing the local datasets, and
choose glucose management as a study model to verify its effectiveness.
Technically, blockchain-enabled federated learning is implemented with adaption
to make it meet with the privacy and safety requirements of healthcare data,
meanwhile rewards honest participation and penalize malicious activities using
its on-chain incentive mechanism. Experimental results show that the proposed
framework is effective, efficient, and privacy preserved. Its prediction
accuracy is much better than the models trained from limited personal data and
is similar to, and even slightly better than, the results from a centralized
dataset. This work paves the way for international collaborations on healthcare
projects, where additional data is crucial for reducing bias and providing
benefits to humanity.

摘要：在醫療領域建構人工智慧（AI）模型時，最大的挑戰之一是資料共享。由於醫療資料具有隱私性、敏感性和異質性，因此收集足夠的資料進行建模既費時又費錢，有時甚至不可能。在本文中，我們提出一個使用來自多個洲（歐洲、北美和亞洲）的資料集進行全球醫療建模的框架，同時不共享本地資料集，並選擇葡萄糖管理作為研究模型來驗證其有效性。在技術上，我們實作了區塊鏈支援的聯合學習，並進行調整以符合醫療資料的隱私和安全要求，同時使用鏈上激勵機制獎勵誠實參與並懲罰惡意活動。實驗結果表明，所提出的框架有效、高效且能保護隱私。其預測準確度遠高於從有限個人資料訓練的模型，並且與從集中式資料集獲得的結果相似，甚至略好。這項工作為醫療專案的國際合作鋪平了道路，其中額外的資料對於減少偏差和造福人類至關重要。

##### **Guide for Defense (G4D): Dynamic Guidance for Robust and Balanced Defense in Large Language Models**
2410.17922v1 by He Cao, Weidi Luo, Yu Wang, Zijing Liu, Bing Feng, Yuan Yao, Yu Li

With the extensive deployment of Large Language Models (LLMs), ensuring their
safety has become increasingly critical. However, existing defense methods
often struggle with two key issues: (i) inadequate defense capabilities,
particularly in domain-specific scenarios like chemistry, where a lack of
specialized knowledge can lead to the generation of harmful responses to
malicious queries. (ii) over-defensiveness, which compromises the general
utility and responsiveness of LLMs. To mitigate these issues, we introduce a
multi-agents-based defense framework, Guide for Defense (G4D), which leverages
accurate external information to provide an unbiased summary of user intentions
and analytically grounded safety response guidance. Extensive experiments on
popular jailbreak attacks and benign datasets show that our G4D can enhance
LLM's robustness against jailbreak attacks on general and domain-specific
scenarios without compromising the model's general functionality.

摘要：隨著大型語言模型 (LLM) 的廣泛部署，確保其安全性變得越來越重要。然而，現有的防禦方法通常會遇到兩個關鍵問題：(i) 防禦能力不足，特別是在化學等特定領域場景中，缺乏專業知識可能會導致對惡意查詢產生有害的回應。(ii) 過度防禦，這會損害 LLM 的一般效用和響應能力。為了減輕這些問題，我們引入了一個基於多代理的防禦框架，即防禦指南 (G4D)，它利用準確的外部資訊來提供使用者意圖的公正摘要，以及基於分析的安全回應指南。在流行的越獄攻擊和良性資料集上的大量實驗表明，我們的 G4D 可以增強 LLM 在一般和特定領域場景中對越獄攻擊的穩健性，而不會損害模型的一般功能。

##### **Addressing Asynchronicity in Clinical Multimodal Fusion via Individualized Chest X-ray Generation**
2410.17918v1 by Wenfang Yao, Chen Liu, Kejing Yin, William K. Cheung, Jing Qin

Integrating multi-modal clinical data, such as electronic health records
(EHR) and chest X-ray images (CXR), is particularly beneficial for clinical
prediction tasks. However, in a temporal setting, multi-modal data are often
inherently asynchronous. EHR can be continuously collected but CXR is generally
taken with a much longer interval due to its high cost and radiation dose. When
clinical prediction is needed, the last available CXR image might have been
outdated, leading to suboptimal predictions. To address this challenge, we
propose DDL-CXR, a method that dynamically generates an up-to-date latent
representation of the individualized CXR images. Our approach leverages latent
diffusion models for patient-specific generation strategically conditioned on a
previous CXR image and EHR time series, providing information regarding
anatomical structures and disease progressions, respectively. In this way, the
interaction across modalities could be better captured by the latent CXR
generation process, ultimately improving the prediction performance.
Experiments using MIMIC datasets show that the proposed model could effectively
address asynchronicity in multimodal fusion and consistently outperform
existing methods.

摘要：整合多模式臨床數據，例如電子健康紀錄 (EHR) 和胸部 X 光影像 (CXR)，對於臨床預測任務特別有益。然而，在時間設定中，多模式數據通常本質上是異步的。EHR 可以持續收集，但 CXR 通常由於其高成本和輻射劑量而以更長的間隔進行拍攝。當需要臨床預測時，最後一張可用的 CXR 影像可能已過時，導致預測不佳。為了應對這一挑戰，我們提出了 DDL-CXR，這是一種動態生成個性化 CXR 影像的最新潛在表示的方法。我們的做法利用潛在擴散模型進行特定於患者的生成，並根據先前的 CXR 影像和 EHR 時間序列進行策略性約束，分別提供有關解剖結構和疾病進展的信息。這樣，潛在 CXR 生成過程可以更好地捕捉跨模式的交互，最終提高預測性能。使用 MIMIC 數據集進行的實驗表明，所提出的模型可以有效地解決多模式融合中的異步性，並始終優於現有方法。

##### **Leveraging Deep Learning for Time Series Extrinsic Regression in predicting photometric metallicity of Fundamental-mode RR Lyrae Stars**
2410.17906v1 by Lorenzo Monti, Tatiana Muraveva, Gisella Clementini, Alessia Garofalo

Astronomy is entering an unprecedented era of Big Data science, driven by
missions like the ESA's Gaia telescope, which aims to map the Milky Way in
three dimensions. Gaia's vast dataset presents a monumental challenge for
traditional analysis methods. The sheer scale of this data exceeds the
capabilities of manual exploration, necessitating the utilization of advanced
computational techniques. In response to this challenge, we developed a novel
approach leveraging deep learning to estimate the metallicity of fundamental
mode (ab-type) RR Lyrae stars from their light curves in the Gaia optical
G-band. Our study explores applying deep learning techniques, particularly
advanced neural network architectures, in predicting photometric metallicity
from time-series data. Our deep learning models demonstrated notable predictive
performance, with a low mean absolute error (MAE) of 0.0565, the root mean
square error (RMSE) achieved is 0.0765 and a high $R^2$ regression performance
of 0.9401 measured by cross-validation. The weighted mean absolute error (wMAE)
is 0.0563, while the weighted root mean square error (wRMSE) is 0.0763. These
results showcase the effectiveness of our approach in accurately estimating
metallicity values. Our work underscores the importance of deep learning in
astronomical research, particularly with large datasets from missions like
Gaia. By harnessing the power of deep learning methods, we can provide
precision in analyzing vast datasets, contributing to more precise and
comprehensive insights into complex astronomical phenomena.

摘要：天文學正進入大數據科學的空前時代，推動這項進展的是像歐洲太空總署的蓋亞望遠鏡等任務，其目標是繪製銀河系的三維地圖。蓋亞的龐大資料集對傳統分析方法來說是一項巨大的挑戰。這類資料的規模龐大，超過了人工探索的能力，因此必須使用先進的運算技術。為了應對這項挑戰，我們開發了一種新穎的方法，利用深度學習估計基本模式（ab 型）RR Lyrae 星的光度曲線中的金屬量。我們的研究探索了應用深度學習技術，特別是先進的神經網路架構，從時間序列資料中預測光度金屬量。我們的深度學習模型展現了顯著的預測效能，平均絕對誤差 (MAE) 低至 0.0565，均方根誤差 (RMSE) 達到 0.0765，而根據交叉驗證測量的 $R^2$ 回歸效能高達 0.9401。加權平均絕對誤差 (wMAE) 為 0.0563，而加權均方根誤差 (wRMSE) 為 0.0763。這些結果證明了我們的方法在準確估計金屬量值方面的有效性。我們的研究強調了深度學習在天文研究中的重要性，特別是在像蓋亞任務等任務所產生的龐大資料集方面。透過利用深度學習方法的力量，我們可以精確分析龐大的資料集，進而對複雜的天文現象做出更精確且全面的見解。

##### **Reinforcement Learning under Latent Dynamics: Toward Statistical and Algorithmic Modularity**
2410.17904v1 by Philip Amortila, Dylan J. Foster, Nan Jiang, Akshay Krishnamurthy, Zakaria Mhammedi

Real-world applications of reinforcement learning often involve environments
where agents operate on complex, high-dimensional observations, but the
underlying (''latent'') dynamics are comparatively simple. However, outside of
restrictive settings such as small latent spaces, the fundamental statistical
requirements and algorithmic principles for reinforcement learning under latent
dynamics are poorly understood.
  This paper addresses the question of reinforcement learning under
$\textit{general}$ latent dynamics from a statistical and algorithmic
perspective. On the statistical side, our main negative result shows that most
well-studied settings for reinforcement learning with function approximation
become intractable when composed with rich observations; we complement this
with a positive result, identifying latent pushforward coverability as a
general condition that enables statistical tractability. Algorithmically, we
develop provably efficient observable-to-latent reductions -- that is,
reductions that transform an arbitrary algorithm for the latent MDP into an
algorithm that can operate on rich observations -- in two settings: one where
the agent has access to hindsight observations of the latent dynamics [LADZ23],
and one where the agent can estimate self-predictive latent models [SAGHCB20].
Together, our results serve as a first step toward a unified statistical and
algorithmic theory for reinforcement learning under latent dynamics.

摘要：現實世界的強化學習應用通常涉及代理在複雜、高維度的觀察中運作的環境，但其底層（''潛在''）動態相對簡單。然而，在小潛在空間等受限設定之外，強化學習在潛在動態下的基本統計需求和演算法原則卻鮮為人知。
本文從統計和演算法的角度探討在$\textit{一般}$潛在動態下進行強化學習的問題。在統計方面，我們的負面結果顯示，大多數研究良好的強化學習設定在與豐富的觀察結合後會變得難以處理；我們用一個正面結果補充這一點，將潛在推前可覆蓋性視為一種能實現統計易處理性的一般條件。在演算法方面，我們開發出可證明效率的觀察到潛在的約化，也就是將潛在 MDP 的任意演算法轉換成可以在豐富觀察中運作的演算法，並在兩種設定下進行：一種是代理可以回顧潛在動態的觀察 [LADZ23]，另一種是代理可以估計自我預測的潛在模型 [SAGHCB20]。我們的結果共同為在潛在動態下進行強化學習的統一統計和演算法理論邁出了第一步。

##### **ELAICHI: Enhancing Low-resource TTS by Addressing Infrequent and Low-frequency Character Bigrams**
2410.17901v1 by Srija Anand, Praveen Srinivasa Varadhan, Mehak Singal, Mitesh M. Khapra

Recent advancements in Text-to-Speech (TTS) technology have led to
natural-sounding speech for English, primarily due to the availability of
large-scale, high-quality web data. However, many other languages lack access
to such resources, relying instead on limited studio-quality data. This
scarcity results in synthesized speech that often suffers from intelligibility
issues, particularly with low-frequency character bigrams. In this paper, we
propose three solutions to address this challenge. First, we leverage
high-quality data from linguistically or geographically related languages to
improve TTS for the target language. Second, we utilize low-quality Automatic
Speech Recognition (ASR) data recorded in non-studio environments, which is
refined using denoising and speech enhancement models. Third, we apply
knowledge distillation from large-scale models using synthetic data to generate
more robust outputs. Our experiments with Hindi demonstrate significant
reductions in intelligibility issues, as validated by human evaluators. We
propose this methodology as a viable alternative for languages with limited
access to high-quality data, enabling them to collectively benefit from shared
resources.

摘要：最近在文字轉語音 (TTS) 技術的進展導致英語的語音聽起來很自然，這主要是因為有大量高品質的網路資料可用。然而，許多其他語言無法取得這些資源，只能依賴有限的錄音室品質資料。這種稀少性導致合成的語音經常有清晰度的問題，特別是低頻字元二元組。在本文中，我們提出三種解決方案來解決這個挑戰。首先，我們利用語言或地理相關語言的高品質資料來改善目標語言的 TTS。其次，我們利用在非錄音室環境中錄製的低品質自動語音辨識 (ASR) 資料，並使用去噪和語音增強模型進行精煉。第三，我們應用從大型模型中使用合成資料進行知識萃取，以產生更穩健的輸出。我們對印地語的實驗證明了清晰度問題有顯著的減少，這已由人類評估員驗證。我們提出這種方法作為一種可行的替代方案，供無法取得高品質資料的語言使用，讓他們能夠共同受益於共享資源。

##### **Scaling Diffusion Language Models via Adaptation from Autoregressive Models**
2410.17891v1 by Shansan Gong, Shivam Agarwal, Yizhe Zhang, Jiacheng Ye, Lin Zheng, Mukai Li, Chenxin An, Peilin Zhao, Wei Bi, Jiawei Han, Hao Peng, Lingpeng Kong

Diffusion Language Models (DLMs) have emerged as a promising new paradigm for
text generative modeling, potentially addressing limitations of autoregressive
(AR) models. However, current DLMs have been studied at a smaller scale
compared to their AR counterparts and lack fair comparison on language modeling
benchmarks. Additionally, training diffusion models from scratch at scale
remains challenging. Given the prevalence of open-source AR language models, we
propose adapting these models to build text diffusion models. We demonstrate
connections between AR and diffusion modeling objectives and introduce a simple
continual pre-training approach for training diffusion models. Through
systematic evaluation on language modeling, reasoning, and commonsense
benchmarks, we show that we can convert AR models ranging from 127M to 7B
parameters (GPT2 and LLaMA) into diffusion models DiffuGPT and DiffuLLaMA,
using less than 200B tokens for training. Our experimental results reveal that
these models outperform earlier DLMs and are competitive with their AR
counterparts. We release a suite of DLMs (with 127M, 355M, and 7B parameters)
capable of generating fluent text, performing in-context learning, filling in
the middle without prompt re-ordering, and following instructions
\url{https://github.com/HKUNLP/DiffuLLaMA}.

摘要：擴散語言模型 (DLM) 已成為一種有前景的新範例，用於文字生成模型，可能會解決自回歸 (AR) 模型的限制。然而，與 AR 對應模型相比，目前 DLM 的研究規模較小，且在語言模型基準上缺乏公平的比較。此外，從頭開始訓練擴散模型仍然具有挑戰性。鑑於開源 AR 語言模型的普遍性，我們建議調整這些模型以建立文字擴散模型。我們展示了 AR 與擴散建模目標之間的關聯，並介紹了一種簡單的持續預訓練方法，用於訓練擴散模型。透過在語言建模、推理和常識基準上的系統性評估，我們證明了我們可以將參數從 127M 到 7B 的 AR 模型（GPT2 和 LLaMA）轉換為擴散模型 DiffuGPT 和 DiffuLLaMA，使用不到 200B 個 token 進行訓練。我們的實驗結果表明，這些模型優於早期的 DLM，並且與其 AR 對應模型具有競爭力。我們發布了一套 DLM（具有 127M、355M 和 7B 參數），能夠生成流利的文字、進行情境學習、在不重新排序提示的情況下填補中間部分，並遵循指令 https://github.com/HKUNLP/DiffuLLaMA。

##### **SpeakGer: A meta-data enriched speech corpus of German state and federal parliaments**
2410.17886v1 by Kai-Robin Lange, Carsten Jentsch

The application of natural language processing on political texts as well as
speeches has become increasingly relevant in political sciences due to the
ability to analyze large text corpora which cannot be read by a single person.
But such text corpora often lack critical meta information, detailing for
instance the party, age or constituency of the speaker, that can be used to
provide an analysis tailored to more fine-grained research questions. To enable
researchers to answer such questions with quantitative approaches such as
natural language processing, we provide the SpeakGer data set, consisting of
German parliament debates from all 16 federal states of Germany as well as the
German Bundestag from 1947-2023, split into a total of 10,806,105 speeches.
This data set includes rich meta data in form of information on both reactions
from the audience towards the speech as well as information about the speaker's
party, their age, their constituency and their party's political alignment,
which enables a deeper analysis. We further provide three exploratory analyses,
detailing topic shares of different parties throughout time, a descriptive
analysis of the development of the age of an average speaker as well as a
sentiment analysis of speeches of different parties with regards to the
COVID-19 pandemic.

摘要：自然語言處理在政治文本和演講中的應用，由於分析單人無法讀完的大量文本語料庫的能力，在政治科學中變得越來越重要。但這些文本語料庫常常缺乏關鍵的元資訊，例如演講者的政黨、年齡或選區，這些資訊可用於提供針對更精細的研究問題量身打造的分析。為了讓研究人員能夠以自然語言處理等量化方法來回答這些問題，我們提供了 SpeakGer 資料集，其中包含來自德國所有 16 個聯邦州以及 1947-2023 年德國聯邦議院的德語議會辯論，共分為 10,806,105 篇演講。此資料集包含豐富的元資料，以觀眾對演講的反應資訊以及演講者的政黨、年齡、選區和政黨的政治立場資訊的形式呈現，這使得更深入的分析成為可能。我們進一步提供了三項探索性分析，詳細說明了不同政黨隨著時間推移的主題份額、對平均演講者年齡發展的描述性分析以及針對不同政黨在 COVID-19 大流行方面的演講的情緒分析。

##### **R-CoT: Reverse Chain-of-Thought Problem Generation for Geometric Reasoning in Large Multimodal Models**
2410.17885v1 by Linger Deng, Yuliang Liu, Bohan Li, Dongliang Luo, Liang Wu, Chengquan Zhang, Pengyuan Lyu, Ziyang Zhang, Gang Zhang, Errui Ding, Yingying Zhu, Xiang Bai

Existing Large Multimodal Models (LMMs) struggle with mathematical geometric
reasoning due to a lack of high-quality image-text paired data. Current
geometric data generation approaches, which apply preset templates to generate
geometric data or use Large Language Models (LLMs) to rephrase questions and
answers (Q&A), unavoidably limit data accuracy and diversity. To synthesize
higher-quality data, we propose a two-stage Reverse Chain-of-Thought (R-CoT)
geometry problem generation pipeline. First, we introduce GeoChain to produce
high-fidelity geometric images and corresponding descriptions highlighting
relations among geometric elements. We then design a Reverse A&Q method that
reasons step-by-step based on the descriptions and generates questions in
reverse from the reasoning results. Experiments demonstrate that the proposed
method brings significant and consistent improvements on multiple LMM
baselines, achieving new performance records in the 2B, 7B, and 8B settings.
Notably, R-CoT-8B significantly outperforms previous state-of-the-art
open-source mathematical models by 16.6% on MathVista and 9.2% on GeoQA, while
also surpassing the closed-source model GPT-4o by an average of 13% across both
datasets. The code is available at https://github.com/dle666/R-CoT.

摘要：現有的大型多模態模型 (LMM) 因缺乏高品質的影像文字配對資料，而難以進行數學幾何推理。目前的幾何資料產生方法，會套用預設範本來產生幾何資料或使用大型語言模型 (LLM) 來改寫問題和答案 (Q&A)，這難免會限制資料的準確性和多樣性。為了合成更高品質的資料，我們提出一個兩階段的反向思考鏈 (R-CoT) 幾何問題產生管線。首先，我們導入 GeoChain 來產生高保真幾何影像和對應的描述，強調幾何元素之間的關係。然後我們設計一個反向問答方法，根據描述逐步推理，並從推理結果反向產生問題。實驗證明，所提出的方法為多個 LMM 基線帶來顯著且一致的改善，在 2B、7B 和 8B 設定中達成新的效能紀錄。值得注意的是，R-CoT-8B 在 MathVista 上比先前的開放原始碼數學模型最佳狀態顯著高出 16.6%，在 GeoQA 上高出 9.2%，同時在兩個資料集上都比封閉原始碼模型 GPT-4o 平均高出 13%。程式碼可在 https://github.com/dle666/R-CoT 取得。

##### **Lightweight Neural App Control**
2410.17883v1 by Filippos Christianos, Georgios Papoudakis, Thomas Coste, Jianye Hao, Jun Wang, Kun Shao

This paper introduces a novel mobile phone control architecture, termed ``app
agents", for efficient interactions and controls across various Android apps.
The proposed Lightweight Multi-modal App Control (LiMAC) takes as input a
textual goal and a sequence of past mobile observations, such as screenshots
and corresponding UI trees, to generate precise actions. To address the
computational constraints inherent to smartphones, within LiMAC, we introduce a
small Action Transformer (AcT) integrated with a fine-tuned vision-language
model (VLM) for real-time decision-making and task execution. We evaluate LiMAC
on two open-source mobile control datasets, demonstrating the superior
performance of our small-form-factor approach against fine-tuned versions of
open-source VLMs, such as Florence2 and Qwen2-VL. It also significantly
outperforms prompt engineering baselines utilising closed-source foundation
models like GPT-4o. More specifically, LiMAC increases the overall action
accuracy by up to 19% compared to fine-tuned VLMs, and up to 42% compared to
prompt-engineering baselines.

摘要：本文提出了一个新穎的手機控制架構，稱為「應用程式代理」，以在各種 Android 應用程式中進行有效率的互動和控制。所提出的輕量級多模態應用程式控制 (LiMAC) 將文字目標和一系列過去的手機觀察結果作為輸入，例如螢幕截圖和對應的 UI 樹狀結構，以產生精確的動作。為了處理智慧型手機固有的運算限制，我們在 LiMAC 中引入了一個小型動作轉換器 (AcT)，並整合了一個微調後的視覺語言模型 (VLM)，以進行即時決策和任務執行。我們在兩個開源的手機控制資料集上評估 LiMAC，證明我們的小型化方法優於微調後的開源 VLM 版本，例如 Florence2 和 Qwen2-VL。它也明顯優於利用封閉原始碼基礎模型（例如 GPT-4o）的提示工程基準。更具體地說，與微調後的 VLM 相比，LiMAC 將整體動作準確度提高了 19%，與提示工程基準相比，提高了 42%。

##### **Understanding Layer Significance in LLM Alignment**
2410.17875v1 by Guangyuan Shi, Zexin Lu, Xiaoyu Dong, Wenlong Zhang, Xuanyu Zhang, Yujie Feng, Xiao-Ming Wu

Aligning large language models (LLMs) through fine-tuning is essential for
tailoring them to specific applications. Therefore, understanding what LLMs
learn during the alignment process is crucial. Recent studies suggest that
alignment primarily adjusts a model's presentation style rather than its
foundational knowledge, indicating that only certain components of the model
are significantly impacted. To delve deeper into LLM alignment, we propose to
identify which layers within LLMs are most critical to the alignment process,
thereby uncovering how alignment influences model behavior at a granular level.
We propose a novel approach to identify the important layers for LLM alignment
(ILA). It involves learning a binary mask for each incremental weight matrix in
the LoRA algorithm, indicating the significance of each layer. ILA consistently
identifies important layers across various alignment datasets, with nearly 90%
overlap even with substantial dataset differences, highlighting fundamental
patterns in LLM alignment. Experimental results indicate that freezing
non-essential layers improves overall model performance, while selectively
tuning the most critical layers significantly enhances fine-tuning efficiency
with minimal performance loss.

摘要：透過微調來調整大型語言模型 (LLM) 對於將其量身打造為特定應用程式至關重要。因此，了解 LLM 在調整過程中學習到的內容至關重要。最近的研究表明，調整主要調整模型的呈現風格，而不是其基礎知識，這表示模型只有某些組成部分會受到顯著影響。為了更深入探討 LLM 調整，我們建議找出 LLM 中哪些層級對調整過程最為關鍵，從而揭示調整如何影響模型行為的細微層面。我們提出了一種新穎的方法來找出對 LLM 調整很重要的層級 (ILA)。它涉及在 LoRA 演算法中為每個遞增權重矩陣學習一個二進制遮罩，表示每個層級的重要性。ILA 在各種調整資料集上持續找出重要的層級，即使資料集差異很大，重疊率也接近 90%，突顯了 LLM 調整中的基本模式。實驗結果表明，凍結非必要的層級會改善整體模型效能，而有選擇性地調整最關鍵的層級會顯著提升微調效率，效能損失極小。

##### **DataTales: A Benchmark for Real-World Intelligent Data Narration**
2410.17859v1 by Yajing Yang, Qian Liu, Min-Yen Kan

We introduce DataTales, a novel benchmark designed to assess the proficiency
of language models in data narration, a task crucial for transforming complex
tabular data into accessible narratives. Existing benchmarks often fall short
in capturing the requisite analytical complexity for practical applications.
DataTales addresses this gap by offering 4.9k financial reports paired with
corresponding market data, showcasing the demand for models to create clear
narratives and analyze large datasets while understanding specialized
terminology in the field. Our findings highlights the significant challenge
that language models face in achieving the necessary precision and analytical
depth for proficient data narration, suggesting promising avenues for future
model development and evaluation methodologies.

摘要：<paragraph>我們推出 DataTales，這是一個新基準，旨在評估語言模型在資料敘述中的熟練度，這項任務對於將複雜的表格資料轉換成易於理解的敘述至關重要。現有的基準在捕捉實際應用所需的分析複雜性時常常不足。DataTales 通過提供 4.9k 份與對應市場資料配對的財務報告來解決這個差距，展示了模型對建立清晰敘述和分析大型資料集的需求，同時理解該領域的專業術語。我們的發現突顯了語言模型在實現熟練資料敘述所需的準確性和分析深度方面面臨的重大挑戰，為未來的模型開發和評估方法提出了有希望的途徑。</paragraph>

##### **ROCKET-1: Master Open-World Interaction with Visual-Temporal Context Prompting**
2410.17856v1 by Shaofei Cai, Zihao Wang, Kewei Lian, Zhancun Mu, Xiaojian Ma, Anji Liu, Yitao Liang

Vision-language models (VLMs) have excelled in multimodal tasks, but adapting
them to embodied decision-making in open-world environments presents
challenges. A key issue is the difficulty in smoothly connecting individual
entities in low-level observations with abstract concepts required for
planning. A common approach to address this problem is through the use of
hierarchical agents, where VLMs serve as high-level reasoners that break down
tasks into executable sub-tasks, typically specified using language and
imagined observations. However, language often fails to effectively convey
spatial information, while generating future images with sufficient accuracy
remains challenging. To address these limitations, we propose visual-temporal
context prompting, a novel communication protocol between VLMs and policy
models. This protocol leverages object segmentation from both past and present
observations to guide policy-environment interactions. Using this approach, we
train ROCKET-1, a low-level policy that predicts actions based on concatenated
visual observations and segmentation masks, with real-time object tracking
provided by SAM-2. Our method unlocks the full potential of VLMs
visual-language reasoning abilities, enabling them to solve complex creative
tasks, especially those heavily reliant on spatial understanding. Experiments
in Minecraft demonstrate that our approach allows agents to accomplish
previously unattainable tasks, highlighting the effectiveness of
visual-temporal context prompting in embodied decision-making. Codes and demos
will be available on the project page: https://craftjarvis.github.io/ROCKET-1.

摘要：視覺語言模型 (VLM) 在多模態任務中表現出色，但將其適應於開放世界環境中的具身決策會帶來挑戰。一個關鍵問題是難以將低層級觀察中的個別實體與規劃所需的抽象概念順利連接起來。解決此問題的常見方法是使用階層式代理，其中 VLM 作為高級推理器，將任務分解為可執行的子任務，通常使用語言和想像的觀察來指定。然而，語言通常無法有效傳達空間資訊，同時產生具有足夠準確度的未來影像仍然具有挑戰性。為了解決這些限制，我們提出視覺時間脈絡提示，一種 VLM 和策略模型之間的新穎通訊協定。此協定利用過去和現在觀察的物件分割來引導策略環境互動。使用此方法，我們訓練 ROCKET-1，一種低層級策略，它根據串接的視覺觀察和分割遮罩預測動作，並由 SAM-2 提供即時物件追蹤。我們的技術發揮了 VLM 視覺語言推理能力的全部潛力，使它們能夠解決複雜的創意任務，特別是那些高度依賴空間理解的任務。在 Minecraft 中的實驗證明，我們的技術使代理能夠完成以前無法達成的任務，突顯了視覺時間脈絡提示在具身決策中的有效性。程式碼和範例將在專案頁面中提供：https://craftjarvis.github.io/ROCKET-1。

##### **TAGE: Trustworthy Attribute Group Editing for Stable Few-shot Image Generation**
2410.17855v1 by Ruicheng Zhang, Guoheng Huang, Yejing Huo, Xiaochen Yuan, Zhizhen Zhou, Xuhang Chen, Guo Zhong

Generative Adversarial Networks (GANs) have emerged as a prominent research
focus for image editing tasks, leveraging the powerful image generation
capabilities of the GAN framework to produce remarkable results.However,
prevailing approaches are contingent upon extensive training datasets and
explicit supervision, presenting a significant challenge in manipulating the
diverse attributes of new image classes with limited sample availability. To
surmount this hurdle, we introduce TAGE, an innovative image generation network
comprising three integral modules: the Codebook Learning Module (CLM), the Code
Prediction Module (CPM) and the Prompt-driven Semantic Module (PSM). The CPM
module delves into the semantic dimensions of category-agnostic attributes,
encapsulating them within a discrete codebook. This module is predicated on the
concept that images are assemblages of attributes, and thus, by editing these
category-independent attributes, it is theoretically possible to generate
images from unseen categories. Subsequently, the CPM module facilitates
naturalistic image editing by predicting indices of category-independent
attribute vectors within the codebook. Additionally, the PSM module generates
semantic cues that are seamlessly integrated into the Transformer architecture
of the CPM, enhancing the model's comprehension of the targeted attributes for
editing. With these semantic cues, the model can generate images that
accentuate desired attributes more prominently while maintaining the integrity
of the original category, even with a limited number of samples. We have
conducted extensive experiments utilizing the Animal Faces, Flowers, and
VGGFaces datasets. The results of these experiments demonstrate that our
proposed method not only achieves superior performance but also exhibits a high
degree of stability when compared to other few-shot image generation
techniques.

摘要：生成对抗網路 (GAN) 已成為影像編輯任務中備受矚目的研究重點，利用 GAN 架構強大的影像產生能力，產生出色的成果。然而，現行的做法有賴於大量的訓練資料集和明確的監督，在樣本取得有限的情況下，要操作新影像類別的多樣屬性，會是一項重大的挑戰。為了克服這個障礙，我們引進 TAGE，一個創新的影像產生網路，包含三個整合模組：編碼簿學習模組 (CLM)、編碼預測模組 (CPM) 和提示驅動語意模組 (PSM)。CPM 模組深入探討類別不可知屬性的語意維度，將它們封裝在一個離散的編碼簿中。這個模組建立在影像是由屬性組成的概念上，因此，透過編輯這些類別無關的屬性，理論上可以從未見過的類別中產生影像。隨後，CPM 模組透過預測編碼簿中類別無關屬性向量的索引，促進自然的影像編輯。此外，PSM 模組產生語意提示，這些提示被無縫整合到 CPM 的 Transformer 架構中，增強模型對目標屬性的理解，以進行編輯。有了這些語意提示，即使樣本數量有限，模型也能產生更突顯所需屬性的影像，同時維持原始類別的完整性。我們已使用動物臉孔、花朵和 VGGFaces 資料集進行廣泛的實驗。這些實驗的結果證明，我們提出的方法不僅能達成卓越的效能，與其他少樣本影像產生技術相比，也展現出高度的穩定性。

##### **The Probabilistic Tsetlin Machine: A Novel Approach to Uncertainty Quantification**
2410.17851v1 by K. Darshana Abeyrathna, Sara El Mekkaoui, Andreas Hafver, Christian Agrell

Tsetlin Machines (TMs) have emerged as a compelling alternative to
conventional deep learning methods, offering notable advantages such as smaller
memory footprint, faster inference, fault-tolerant properties, and
interpretability. Although various adaptations of TMs have expanded their
applicability across diverse domains, a fundamental gap remains in
understanding how TMs quantify uncertainty in their predictions. In response,
this paper introduces the Probabilistic Tsetlin Machine (PTM) framework, aimed
at providing a robust, reliable, and interpretable approach for uncertainty
quantification. Unlike the original TM, the PTM learns the probability of
staying on each state of each Tsetlin Automaton (TA) across all clauses. These
probabilities are updated using the feedback tables that are part of the TM
framework: Type I and Type II feedback. During inference, TAs decide their
actions by sampling states based on learned probability distributions, akin to
Bayesian neural networks when generating weight values. In our experimental
analysis, we first illustrate the spread of the probabilities across TA states
for the noisy-XOR dataset. Then we evaluate the PTM alongside benchmark models
using both simulated and real-world datasets. The experiments on the simulated
dataset reveal the PTM's effectiveness in uncertainty quantification,
particularly in delineating decision boundaries and identifying regions of high
uncertainty. Moreover, when applied to multiclass classification tasks using
the Iris dataset, the PTM demonstrates competitive performance in terms of
predictive entropy and expected calibration error, showcasing its potential as
a reliable tool for uncertainty estimation. Our findings underscore the
importance of selecting appropriate models for accurate uncertainty
quantification in predictive tasks, with the PTM offering a particularly
interpretable and effective solution.

摘要：<paragraph>Tsetlin 機器 (TM) 已成為傳統深度學習方法的強有力替代方案，提供顯著的優勢，例如較小的記憶體佔用空間、更快的推論、容錯特性和可解釋性。儘管 TM 的各種改編已擴展了其在不同領域的適用性，但在理解 TM 如何量化其預測中的不確定性方面仍存在根本差距。針對此問題，本文介紹了機率 Tsetlin 機器 (PTM) 架構，旨在提供一種強健、可靠且可解釋的不確定性量化方法。與原始 TM 不同，PTM 會學習在所有子句中每個 Tsetlin 自動機 (TA) 的每個狀態上停留的機率。這些機率會使用 TM 架構中反饋表格進行更新：類型 I 和類型 II 反饋。在推論期間，TA 會根據學習到的機率分佈抽樣狀態來決定其動作，類似於在生成權重值時貝氏神經網路。在我們的實驗分析中，我們首先說明了對於雜訊 XOR 資料集，機率在 TA 狀態中的分佈。然後，我們使用模擬和真實世界資料集，與基準模型一起評估 PTM。模擬資料集的實驗揭示了 PTM 在不確定性量化中的有效性，特別是在描繪決策邊界和識別高度不確定性區域方面。此外，當使用鳶尾花資料集應用於多類別分類任務時，PTM 在預測熵和預期校準誤差方面表現出競爭力，展示了其作為不確定性估計的可靠工具的潛力。我們的研究結果強調了在預測任務中選擇適當模型對於準確的不確定性量化非常重要，而 PTM 提供了一個特別可解釋且有效率的解決方案。</paragraph>

##### **RE-tune: Incremental Fine Tuning of Biomedical Vision-Language Models for Multi-label Chest X-ray Classification**
2410.17827v1 by Marco Mistretta, Andrew D. Bagdanov

In this paper we introduce RE-tune, a novel approach for fine-tuning
pre-trained Multimodal Biomedical Vision-Language models (VLMs) in Incremental
Learning scenarios for multi-label chest disease diagnosis. RE-tune freezes the
backbones and only trains simple adaptors on top of the Image and Text encoders
of the VLM. By engineering positive and negative text prompts for diseases, we
leverage the ability of Large Language Models to steer the training trajectory.
We evaluate RE-tune in three realistic incremental learning scenarios:
class-incremental, label-incremental, and data-incremental. Our results
demonstrate that Biomedical VLMs are natural continual learners and prevent
catastrophic forgetting. RE-tune not only achieves accurate multi-label
classification results, but also prioritizes patient privacy and it
distinguishes itself through exceptional computational efficiency, rendering it
highly suitable for broad adoption in real-world healthcare settings.

摘要：在本文中，我們介紹了 RE-tune，這是一種新穎的方法，用於微調預先訓練的多模態生物醫學視覺語言模型 (VLM)，以用於多標籤胸部疾病診斷的增量學習場景。RE-tune 凍結主幹，只在 VLM 的圖像和文本編碼器之上訓練簡單的適配器。通過設計疾病的正面和負面文本提示，我們利用大型語言模型引導訓練軌跡的能力。我們在三種現實的增量學習場景中評估了 RE-tune：類別增量、標籤增量和數據增量。我們的結果表明，生物醫學 VLM 是自然的持續學習者，並防止了災難性遺忘。RE-tune 不僅實現了準確的多標籤分類結果，而且優先考慮了患者隱私，並且通過出色的計算效率而區別於其他方法，使其非常適合在現實世界的醫療保健環境中廣泛採用。

##### **Understanding When Tree of Thoughts Succeeds: Larger Models Excel in Generation, Not Discrimination**
2410.17820v1 by Qiqi Chen, Xinpeng Wang, Philipp Mondorf, Michael A. Hedderich, Barbara Plank

Tree of Thoughts (ToT) is a reasoning strategy for Large Language Models
(LLMs) that employs a generator to suggest reasoning steps and a discriminator
to decide which steps to implement. ToT demonstrates strong performance on
reasoning tasks, often surpassing simple methods such as Input-Output (IO)
prompting and Chain-of-Thought (CoT) reasoning. However, ToT does not
consistently outperform such simpler methods across all models, leaving large
knowledge gaps on the conditions under which ToT is most beneficial. In this
paper, we analyze the roles of the generator and discriminator separately to
better understand the conditions when ToT is beneficial. We find that the
generator plays a more critical role than the discriminator in driving the
success of ToT. While using even a smaller model as the discriminator, scaling
the generator leads to notable improvements in ToT performance, whereas scaling
the discriminator with a fixed generator yields only marginal gains. Our
results show that models across different scales exhibit comparable
discrimination capabilities, yet differ significantly in their generative
performance for ToT.

摘要：思考之樹（ToT）是一種大型語言模型（LLM）的推理策略，它使用生成器來建議推理步驟，並使用判別器來決定要實施哪些步驟。ToT 在推理任務中表現出色，通常超越了輸入輸出（IO）提示和思考鏈（CoT）推理等簡單方法。然而，ToT 並未在所有模型中始終優於這些更簡單的方法，這使得在 ToT 最有益的條件下留下了巨大的知識空白。在本文中，我們分別分析了生成器和判別器的角色，以更好地了解 ToT 有益的條件。我們發現生成器在推動 ToT 的成功方面發揮了比判別器更關鍵的作用。雖然即使使用較小的模型作為判別器，但擴展生成器也會導致 ToT 性能顯著提升，而使用固定生成器擴展判別器只會產生邊際收益。我們的結果表明，不同規模的模型表現出可比較的判別能力，但在 ToT 的生成性能方面卻有顯著差異。

##### **PGDiffSeg: Prior-Guided Denoising Diffusion Model with Parameter-Shared Attention for Breast Cancer Segmentation**
2410.17812v1 by Feiyan Feng, Tianyu Liu, Hong Wang, Jun Zhao, Wei Li, Yanshen Sun

Early detection through imaging and accurate diagnosis is crucial in
mitigating the high mortality rate associated with breast cancer. However,
locating tumors from low-resolution and high-noise medical images is extremely
challenging. Therefore, this paper proposes a novel PGDiffSeg (Prior-Guided
Diffusion Denoising Model with Parameter-Shared Attention) that applies
diffusion denoising methods to breast cancer medical image segmentation,
accurately recovering the affected areas from Gaussian noise. Firstly, we
design a parallel pipeline for noise processing and semantic information
processing and propose a parameter-shared attention module (PSA) in multi-layer
that seamlessly integrates these two pipelines. This integration empowers
PGDiffSeg to incorporate semantic details at multiple levels during the
denoising process, producing highly accurate segmentation maps. Secondly, we
introduce a guided strategy that leverages prior knowledge to simulate the
decision-making process of medical professionals, thereby enhancing the model's
ability to locate tumor positions precisely. Finally, we provide the first-ever
discussion on the interpretability of the generative diffusion model in the
context of breast cancer segmentation. Extensive experiments have demonstrated
the superiority of our model over the current state-of-the-art approaches,
confirming its effectiveness as a flexible diffusion denoising method suitable
for medical image research. Our code will be publicly available later.

摘要：透過影像的早期偵測和準確的診斷，對於減緩與乳癌相關的高死亡率至關重要。然而，從低解析度和高雜訊的醫療影像中找出腫瘤極具挑戰性。因此，本文提出一個新穎的 PGDiffSeg（具有參數共享注意力的先驗引導擴散去噪模型），將擴散去噪方法應用於乳癌醫療影像分割，從高斯雜訊中準確地恢復受影響區域。首先，我們設計一個用於雜訊處理和語義訊息處理的平行管線，並在多層中提出一個參數共享注意力模組 (PSA)，無縫地整合這兩個管線。這種整合賦予 PGDiffSeg 在去噪過程中在多個層級中納入語義細節的能力，產生高度準確的分割圖。其次，我們引入一個引導策略，利用先驗知識來模擬醫療專業人員的決策過程，從而增強模型精確定位腫瘤位置的能力。最後，我們首次討論了生成擴散模型在乳癌分割背景下的可解釋性。廣泛的實驗證明了我們的模型優於當前最先進的方法，證實其作為一種適用於醫學影像研究的靈活擴散去噪方法的有效性。我們的程式碼稍後將公開。

##### **OmniFlatten: An End-to-end GPT Model for Seamless Voice Conversation**
2410.17799v1 by Qinglin Zhang, Luyao Cheng, Chong Deng, Qian Chen, Wen Wang, Siqi Zheng, Jiaqing Liu, Hai Yu, Chaohong Tan

Full-duplex spoken dialogue systems significantly advance over traditional
turn-based dialogue systems, as they allow simultaneous bidirectional
communication, closely mirroring human-human interactions. However, achieving
low latency and natural interactions in full-duplex dialogue systems remains a
significant challenge, especially considering human conversation dynamics such
as interruptions, backchannels, and overlapping speech. In this paper, we
introduce a novel End-to-End GPT-based model OmniFlatten for full-duplex
conversation, capable of effectively modeling the complex behaviors inherent to
natural conversations with low latency. To achieve full-duplex communication
capabilities, we propose a multi-stage post-training scheme that progressively
adapts a text-based large language model (LLM) backbone into a speech-text
dialogue LLM, capable of generating text and speech in real time, without
modifying the architecture of the backbone LLM. The training process comprises
three stages: modality alignment, half-duplex dialogue learning, and
full-duplex dialogue learning. Throughout all training stages, we standardize
the data using a flattening operation, which allows us to unify the training
methods and the model architecture across different modalities and tasks. Our
approach offers a straightforward modeling technique and a promising research
direction for developing efficient and natural end-to-end full-duplex spoken
dialogue systems. Audio samples of dialogues generated by OmniFlatten can be
found at this web site (https://omniflatten.github.io/).

摘要：全雙工語音對話系統顯著優於傳統的回合制對話系統，因為它們允許同時雙向溝通，緊密反映人類與人類的互動。然而，在全雙工對話系統中實現低延遲和自然互動仍然是一個重大的挑戰，特別是考慮到人類對話動態，例如中斷、反向通道和重疊語音。在本文中，我們引入了一個新的端到端 GPT 模型 OmniFlatten，用於全雙工對話，能夠有效地模擬自然對話中固有的複雜行為，並具有低延遲。為了實現全雙工通信功能，我們提出了一個多階段後訓練方案，逐步將基於文本的大語言模型 (LLM) 主幹適應為語音轉文本對話 LLM，能夠實時生成文本和語音，而無需修改主幹 LLM 的架構。訓練過程包括三個階段：模態對齊、半雙工對話學習和全雙工對話學習。在所有訓練階段中，我們使用扁平化運算標準化數據，這使我們能夠統一不同模態和任務的訓練方法和模型架構。我們的做法提供了一種直接的建模技術和一個有前景的研究方向，用於開發高效且自然的端到端全雙工語音對話系統。可以在這個網站 (https://omniflatten.github.io/) 找到由 OmniFlatten 生成的對話音頻樣本。

##### **Enhancing Federated Learning Convergence with Dynamic Data Queue and Data Entropy-driven Participant Selection**
2410.17792v1 by Charuka Herath, Xiaolan Liu, Sangarapillai Lambotharan, Yogachandran Rahulamathavan

Federated Learning (FL) is a decentralized approach for collaborative model
training on edge devices. This distributed method of model training offers
advantages in privacy, security, regulatory compliance, and cost-efficiency.
Our emphasis in this research lies in addressing statistical complexity in FL,
especially when the data stored locally across devices is not identically and
independently distributed (non-IID). We have observed an accuracy reduction of
up to approximately 10\% to 30\%, particularly in skewed scenarios where each
edge device trains with only 1 class of data. This reduction is attributed to
weight divergence, quantified using the Euclidean distance between device-level
class distributions and the population distribution, resulting in a bias term
(\(\delta_k\)). As a solution, we present a method to improve convergence in FL
by creating a global subset of data on the server and dynamically distributing
it across devices using a Dynamic Data queue-driven Federated Learning (DDFL).
Next, we leverage Data Entropy metrics to observe the process during each
training round and enable reasonable device selection for aggregation.
Furthermore, we provide a convergence analysis of our proposed DDFL to justify
their viability in practical FL scenarios, aiming for better device selection,
a non-sub-optimal global model, and faster convergence. We observe that our
approach results in a substantial accuracy boost of approximately 5\% for the
MNIST dataset, around 18\% for CIFAR-10, and 20\% for CIFAR-100 with a 10\%
global subset of data, outperforming the state-of-the-art (SOTA) aggregation
algorithms.

摘要：聯邦學習 (FL) 是一種分散式協作模型，用於在邊緣裝置上進行訓練。這種分散式模型訓練方法在隱私、安全性、法規遵循和成本效益方面具有優勢。本研究重點在於解決 FL 中的統計複雜性，特別是在裝置間本地儲存的資料並非獨立同分布 (non-IID) 時。我們觀察到準確度下降約 10% 至 30%，特別是在偏態場景中，每個邊緣裝置僅使用 1 類資料進行訓練。這種下降歸因於權重差異，使用裝置層級類別分佈與母體分佈之間的歐氏距離量化，導致偏差項 (\(\delta_k\))。作為解決方案，我們提出了一種透過在伺服器上建立資料的全球子集，並使用動態資料佇列驅動的聯邦學習 (DDFL) 動態將其分發到裝置上，來改善 FL 中的收斂性。接著，我們利用資料熵指標來觀察每個訓練回合中的流程，並針對聚合啟用合理的裝置選擇。此外，我們提供了建議的 DDFL 的收斂分析，以證明其在實際 FL 場景中的可行性，目標是進行更好的裝置選擇、非次佳的全球模型和更快的收斂。我們觀察到，我們的做法對於 MNIST 資料集產生了約 5% 的顯著準確度提升，對於 CIFAR-10 約為 18%，對於 CIFAR-100 則為 20%，使用 10% 的資料全球子集，優於最先進 (SOTA) 的聚合演算法。

##### **Large Language Models Engineer Too Many Simple Features For Tabular Data**
2410.17787v1 by Jaris Küken, Lennart Purucker, Frank Hutter

Tabular machine learning problems often require time-consuming and
labor-intensive feature engineering. Recent efforts have focused on using large
language models (LLMs) to capitalize on their potential domain knowledge. At
the same time, researchers have observed ethically concerning negative biases
in other LLM-related use cases, such as text generation. These developments
motivated us to investigate whether LLMs exhibit a bias that negatively impacts
the performance of feature engineering. While not ethically concerning, such a
bias could hinder practitioners from fully utilizing LLMs for automated data
science. Therefore, we propose a method to detect potential biases by detecting
anomalies in the frequency of operators (e.g., adding two features) suggested
by LLMs when engineering new features. Our experiments evaluate the bias of
four LLMs, two big frontier and two small open-source models, across 27 tabular
datasets. Our results indicate that LLMs are biased toward simple operators,
such as addition, and can fail to utilize more complex operators, such as
grouping followed by aggregations. Furthermore, the bias can negatively impact
the predictive performance when using LLM-generated features. Our results call
for mitigating bias when using LLMs for feature engineering.

摘要：表格機器學習問題通常需要耗時且勞力密集的特徵工程。最近的努力集中於使用大型語言模型 (LLM) 來利用其潛在的領域知識。與此同時，研究人員觀察到在其他 LLM 相關用例中，例如文字生成，存在倫理上令人擔憂的負面偏見。這些發展促使我們調查 LLM 是否表現出對特徵工程效能產生負面影響的偏見。雖然在倫理上並未引起關注，但這種偏見可能會阻礙從業人員充分利用 LLM 進行自動化資料科學。因此，我們提出了一種方法，透過偵測 LLM 在設計新特徵時建議的運算子（例如，新增兩個特徵）的頻率異常值來偵測潛在偏見。我們的實驗評估了四個 LLM 的偏見，兩個大型前沿模型和兩個小型開源模型，橫跨 27 個表格資料集。我們的結果表明，LLM 偏向於簡單的運算子，例如加法，並且可能無法利用更複雜的運算子，例如群組後聚合。此外，在使用 LLM 生成的特徵時，偏見可能會對預測效能產生負面影響。我們的結果要求在使用 LLM 進行特徵工程時減輕偏見。

##### **Holon Programming Model -- A Software-Defined Approach for System of Systems**
2410.17784v1 by Muhammad Ashfaq, Ahmed R. Sadik, Tommi Mikkonen, Muhammad Waseem, Niko Makitalo

As Systems of Systems evolve into increasingly complex networks, harnessing
their collective potential becomes paramount. Traditional SoS engineering
approaches lack the necessary programmability to develop third party SoS level
behaviors. To address this challenge, we propose a software defined approach to
enable flexible and adaptive programming of SoS. We introduce the Holon
Programming Model, a software-defined framework designed to meet these needs.
The Holon Programming Model empowers developers to design and orchestrate
complex system behaviors effectively, as illustrated in our disaster management
scenario. This research outlines the Holon Programming Model theoretical
underpinnings and practical applications, with the aim of driving further
exploration and advancement in the field of software defined SoS

摘要：隨著系統系統演變成日益複雜的網路，利用其集體潛能變得至關重要。傳統的系統系統工程方法缺乏開發第三方系統系統層級行為所需的程式設計能力。為了應對這項挑戰，我們提出一個軟體定義的方法，以實現系統系統的彈性且適應性的程式設計。我們導入 Holon 程式設計模型，一個軟體定義的架構，旨在滿足這些需求。Holon 程式設計模型賦予開發人員設計和編排複雜系統行為的能力，正如我們的災害管理情境中所說明的。這項研究概述了 Holon 程式設計模型的理論基礎和實際應用，目的是推動軟體定義系統系統領域的進一步探索和進步

##### **Leveraging the Domain Adaptation of Retrieval Augmented Generation Models for Question Answering and Reducing Hallucination**
2410.17783v1 by Salman Rakin, Md. A. R. Shibly, Zahin M. Hossain, Zeeshan Khan, Md. Mostofa Akbar

While ongoing advancements in Large Language Models have demonstrated
remarkable success across various NLP tasks, Retrieval Augmented Generation
Model stands out to be highly effective on downstream applications like
Question Answering. Recently, RAG-end2end model further optimized the
architecture and achieved notable performance improvements on domain
adaptation. However, the effectiveness of these RAG-based architectures remains
relatively unexplored when fine-tuned on specialized domains such as customer
service for building a reliable conversational AI system. Furthermore, a
critical challenge persists in reducing the occurrence of hallucinations while
maintaining high domain-specific accuracy. In this paper, we investigated the
performance of diverse RAG and RAG-like architectures through domain adaptation
and evaluated their ability to generate accurate and relevant response grounded
in the contextual knowledge base. To facilitate the evaluation of the models,
we constructed a novel dataset HotelConvQA, sourced from wide range of
hotel-related conversations and fine-tuned all the models on our domain
specific dataset. We also addressed a critical research gap on determining the
impact of domain adaptation on reducing hallucinations across different RAG
architectures, an aspect that was not properly measured in prior work. Our
evaluation shows positive results in all metrics by employing domain
adaptation, demonstrating strong performance on QA tasks and providing insights
into their efficacy in reducing hallucinations. Our findings clearly indicate
that domain adaptation not only enhances the models' performance on QA tasks
but also significantly reduces hallucination across all evaluated RAG
architectures.

摘要：儘管大型語言模型的持續進展在各種 NLP 任務中展現出顯著的成功，但檢索增強生成模型在下游應用程式中表現得極為有效，例如問答。最近，RAG-end2end 模型進一步最佳化架構，並在領域適應上取得顯著的效能提升。然而，這些基於 RAG 的架構的有效性在針對特定領域（例如客戶服務）進行微調時，仍相對未經探索，以建立可靠的對話式 AI 系統。此外，在維持高度特定於領域的準確性的同時，減少幻覺的發生仍然是一項嚴峻的挑戰。在本文中，我們透過領域適應調查了各種 RAG 和類似 RAG 的架構的效能，並評估它們產生準確且相關回應的能力，這些回應奠基於脈絡知識庫。為了促進模型評估，我們建構了一個新穎的資料集 HotelConvQA，其來源於廣泛的與飯店相關的對話，並針對我們特定於領域的資料集微調所有模型。我們也探討了決定領域適應對減少不同 RAG 架構幻覺的影響的關鍵研究差距，這是一個先前研究中未適當衡量的面向。我們的評估在所有指標中透過採用領域適應展現正向結果，證明了在問答任務上的強大效能，並提供洞察力，以了解它們在減少幻覺方面的效力。我們的發現明確指出，領域適應不僅增強了模型在問答任務上的效能，而且也大幅減少了所有評估的 RAG 架構中的幻覺。

##### **Evaluating Explanations Through LLMs: Beyond Traditional User Studies**
2410.17781v1 by Francesco Bombassei De Bona, Gabriele Dominici, Tim Miller, Marc Langheinrich, Martin Gjoreski

As AI becomes fundamental in sectors like healthcare, explainable AI (XAI)
tools are essential for trust and transparency. However, traditional user
studies used to evaluate these tools are often costly, time consuming, and
difficult to scale. In this paper, we explore the use of Large Language Models
(LLMs) to replicate human participants to help streamline XAI evaluation. We
reproduce a user study comparing counterfactual and causal explanations,
replicating human participants with seven LLMs under various settings. Our
results show that (i) LLMs can replicate most conclusions from the original
study, (ii) different LLMs yield varying levels of alignment in the results,
and (iii) experimental factors such as LLM memory and output variability affect
alignment with human responses. These initial findings suggest that LLMs could
provide a scalable and cost-effective way to simplify qualitative XAI
evaluation.

摘要：隨著 AI 在醫療保健等領域變得越來越重要，可解釋 AI (XAI) 工具對於建立信任和透明度至關重要。然而，用於評估這些工具的傳統使用者研究通常成本高昂、耗時且難以擴展。在本文中，我們探討使用大型語言模型 (LLM) 來複製人類參與者，以幫助簡化 XAI 評估。我們複製了一項使用者研究，比較反事實和因果解釋，在各種設定下使用七個 LLM 複製人類參與者。我們的結果表明 (i) LLM 可以複製原始研究中的大多數結論，(ii) 不同的 LLM 在結果中產生不同的對齊程度，以及 (iii) LLM 記憶和輸出變異性等實驗因素會影響與人類反應的一致性。這些初步發現表明，LLM 可以提供一種可擴展且具有成本效益的方法來簡化定性 XAI 評估。

##### **Scaling Robot Policy Learning via Zero-Shot Labeling with Foundation Models**
2410.17772v1 by Nils Blank, Moritz Reuss, Marcel Rühle, Ömer Erdinç Yağmurlu, Fabian Wenzel, Oier Mees, Rudolf Lioutikov

A central challenge towards developing robots that can relate human language
to their perception and actions is the scarcity of natural language annotations
in diverse robot datasets. Moreover, robot policies that follow natural
language instructions are typically trained on either templated language or
expensive human-labeled instructions, hindering their scalability. To this end,
we introduce NILS: Natural language Instruction Labeling for Scalability. NILS
automatically labels uncurated, long-horizon robot data at scale in a zero-shot
manner without any human intervention. NILS combines pretrained vision-language
foundation models in order to detect objects in a scene, detect object-centric
changes, segment tasks from large datasets of unlabelled interaction data and
ultimately label behavior datasets. Evaluations on BridgeV2, Fractal, and a
kitchen play dataset show that NILS can autonomously annotate diverse robot
demonstrations of unlabeled and unstructured datasets while alleviating several
shortcomings of crowdsourced human annotations, such as low data quality and
diversity. We use NILS to label over 115k trajectories obtained from over 430
hours of robot data. We open-source our auto-labeling code and generated
annotations on our website: http://robottasklabeling.github.io.

摘要：<paragraph>要开发出能将人类语言与感知和动作联系起来的机器人，一个核心挑战是，在不同的机器人数据集中缺乏自然语言注释。此外，遵循自然语言指令的机器人策略通常在模板化语言或昂贵的人工标注指令上进行训练，这阻碍了其可扩展性。为此，我们引入了 NILS：自然语言指令标注，以提高可扩展性。NILS 在零次学习中自动标注未整理的、长时段的机器人数据，无需任何人工干预。NILS 结合了经过预训练的视觉语言基础模型，以便检测场景中的对象、检测以对象为中心的更改、从大量未标注交互数据的数据集中分割任务，并最终标注行为数据集。在 BridgeV2、Fractal 和一个厨房游戏数据集上的评估表明，NILS 可以自主注释未标注和非结构化数据集中的各种机器人演示，同时缓解了众包人工注释的几个缺点，例如数据质量低和多样性差。我们使用 NILS 标注了从 430 多个小时的机器人数据中获得的 115k 多个轨迹。我们在我们的网站上开源了我们的自动标注代码和生成的注释：http://robottasklabeling.github.io。</paragraph>

##### **Latent Structures of Intertextuality in French Fiction**
2410.17759v1 by Jean Barré

Intertextuality is a key concept in literary theory that challenges
traditional notions of text, signification or authorship. It views texts as
part of a vast intertextual network that is constantly evolving and being
reconfigured. This paper argues that the field of computational literary
studies is the ideal place to conduct a study of intertextuality since we have
now the ability to systematically compare texts with each others. Specifically,
we present a work on a corpus of more than 12.000 French fictions from the
18th, 19th and early 20th century. We focus on evaluating the underlying roles
of two literary notions, sub-genres and the literary canon in the framing of
textuality. The article attempts to operationalize intertextuality using
state-of-the-art contextual language models to encode novels and capture
features that go beyond simple lexical or thematic approaches. Previous
research (Hughes, 2012) supports the existence of a literary "style of a time",
and our findings further reinforce this concept. Our findings also suggest that
both subgenres and canonicity play a significant role in shaping textual
similarities within French fiction. These discoveries point to the importance
of considering genre and canon as dynamic forces that influence the evolution
and intertextual connections of literary works within specific historical
contexts.

摘要：<paragraph>互文性是文學理論中的關鍵概念，挑戰了傳統的文本、符號或作者概念。它將文本視為一個不斷演化和重組的龐大互文網絡的一部分。本文認為，計算機文學研究領域是進行互文性研究的理想場所，因為我們現在有能力系統地比較文本。具體而言，我們提出了一項關於 18 世紀、19 世紀和 20 世紀初超過 12.000 部法語小說語料庫的研究工作。我們專注於評估兩個文學概念（子類型和文學經典）在文本框架中的基礎作用。本文嘗試使用最先進的上下文語言模型對小說進行編碼並捕捉超越簡單詞彙或主題方法的功能，以使互文性可操作。先前的研究（Hughes，2012 年）支持文學「時代風格」的存在，我們的研究結果進一步強化了這一概念。我們的研究結果還表明，子類型和經典性在塑造法語小說中的文本相似性方面都發揮著重要作用。這些發現表明，將類型和經典視為影響特定歷史背景中文學作品的演變和互文聯繫的動態力量非常重要。</paragraph>

##### **Escaping the Forest: Sparse Interpretable Neural Networks for Tabular Data**
2410.17758v1 by Salvatore Raieli, Abdulrahman Altahhan, Nathalie Jeanray, Stéphane Gerart, Sebastien Vachenc

Tabular datasets are widely used in scientific disciplines such as biology.
While these disciplines have already adopted AI methods to enhance their
findings and analysis, they mainly use tree-based methods due to their
interpretability. At the same time, artificial neural networks have been shown
to offer superior flexibility and depth for rich and complex non-tabular
problems, but they are falling behind tree-based models for tabular data in
terms of performance and interpretability. Although sparsity has been shown to
improve the interpretability and performance of ANN models for complex
non-tabular datasets, enforcing sparsity structurally and formatively for
tabular data before training the model, remains an open question. To address
this question, we establish a method that infuses sparsity in neural networks
by utilising attention mechanisms to capture the features' importance in
tabular datasets. We show that our models, Sparse TABular NET or sTAB-Net with
attention mechanisms, are more effective than tree-based models, reaching the
state-of-the-art on biological datasets. They further permit the extraction of
insights from these datasets and achieve better performance than post-hoc
methods like SHAP.

摘要：表格数据集广泛用于生物学等科学学科。
虽然这些学科已经采用人工智能方法来增强其
发现和分析，但由于其可解释性，它们主要使用基于树的方法。同时，人工神经网络已被证明
为丰富而复杂的非表格问题提供了卓越的灵活性和深度，但它们在性能和可解释性方面落后于表格数据的基于树的模型。虽然稀疏性已被证明可以提高复杂
非表格数据集的 ANN 模型的可解释性和性能，但在训练模型之前强制执行表格数据的结构性和形成性稀疏性，仍然是一个悬而未决的问题。为了解决
这个问题，我们建立了一种通过利用注意力机制来捕获表格数据集中特征重要性的方法，从而在神经网络中注入稀疏性。我们表明，我们的模型，具有
注意力机制的稀疏表格网络或 sTAB-Net，比基于树的模型更有效，在生物数据集上达到最先进的水平。它们进一步允许从这些数据集中提取见解，并且比事后
方法（如 SHAP）获得更好的性能。

##### **VISAGE: Video Synthesis using Action Graphs for Surgery**
2410.17751v1 by Yousef Yeganeh, Rachmadio Lazuardi, Amir Shamseddin, Emine Dari, Yash Thirani, Nassir Navab Azade Farshad

Surgical data science (SDS) is a field that analyzes patient data before,
during, and after surgery to improve surgical outcomes and skills. However,
surgical data is scarce, heterogeneous, and complex, which limits the
applicability of existing machine learning methods. In this work, we introduce
the novel task of future video generation in laparoscopic surgery. This task
can augment and enrich the existing surgical data and enable various
applications, such as simulation, analysis, and robot-aided surgery.
Ultimately, it involves not only understanding the current state of the
operation but also accurately predicting the dynamic and often unpredictable
nature of surgical procedures. Our proposed method, VISAGE (VIdeo Synthesis
using Action Graphs for Surgery), leverages the power of action scene graphs to
capture the sequential nature of laparoscopic procedures and utilizes diffusion
models to synthesize temporally coherent video sequences. VISAGE predicts the
future frames given only a single initial frame, and the action graph triplets.
By incorporating domain-specific knowledge through the action graph, VISAGE
ensures the generated videos adhere to the expected visual and motion patterns
observed in real laparoscopic procedures. The results of our experiments
demonstrate high-fidelity video generation for laparoscopy procedures, which
enables various applications in SDS.

摘要：手術資料科學（SDS）是一個在手術前後分析病患資料的領域，以改善手術結果和技術。然而，手術資料稀少、異質且複雜，這限制了現有機器學習方法的適用性。在這項工作中，我們引入了腹腔鏡手術中未來影片生成的創新任務。這個任務可以擴充和豐富現有的手術資料，並啟用各種應用程式，例如模擬、分析和機器人輔助手術。最終，它不僅涉及了解手術的當前狀態，還準確預測手術程序的動態且經常不可預測的性質。我們提出的方法 VISAGE（用於手術的動作圖影片合成），利用動作場景圖的力量來捕捉腹腔鏡程序的順序性質，並利用擴散模型來合成時間連貫的影片序列。VISAGE 僅給定單一初始幀和動作圖三元組，就能預測未來幀。透過動作圖納入特定領域的知識，VISAGE 確保生成的影片符合在真實腹腔鏡程序中觀察到的預期視覺和動作模式。我們的實驗結果證明了腹腔鏡手術的高保真影片生成，這使得 SDS 中的各種應用程式得以實現。

##### **Learning Versatile Skills with Curriculum Masking**
2410.17744v1 by Yao Tang, Zhihui Xie, Zichuan Lin, Deheng Ye, Shuai Li

Masked prediction has emerged as a promising pretraining paradigm in offline
reinforcement learning (RL) due to its versatile masking schemes, enabling
flexible inference across various downstream tasks with a unified model.
Despite the versatility of masked prediction, it remains unclear how to balance
the learning of skills at different levels of complexity. To address this, we
propose CurrMask, a curriculum masking pretraining paradigm for sequential
decision making. Motivated by how humans learn by organizing knowledge in a
curriculum, CurrMask adjusts its masking scheme during pretraining for learning
versatile skills. Through extensive experiments, we show that CurrMask exhibits
superior zero-shot performance on skill prompting tasks, goal-conditioned
planning tasks, and competitive finetuning performance on offline RL tasks.
Additionally, our analysis of training dynamics reveals that CurrMask gradually
acquires skills of varying complexity by dynamically adjusting its masking
scheme.

摘要：遮罩預測由於其多功能遮罩方案而成為離線強化學習 (RL) 中一種有前途的預訓練範例，它可以在統一模型中靈活推論各種下游任務。儘管遮罩預測具有多功能性，但如何平衡不同複雜程度技能的學習仍不清楚。為了解決此問題，我們提出了 CurrMask，這是一種用於序貫決策的課程遮罩預訓練範例。受人類如何通過課程組織知識的學習方式啟發，CurrMask 在預訓練期間調整其遮罩方案以學習多功能技能。通過廣泛的實驗，我們表明 CurrMask 在技能提示任務、目標條件規劃任務和離線 RL 任務的競爭微調性能上表現出優異的零次學習性能。此外，我們對訓練動態的分析表明，CurrMask 通過動態調整其遮罩方案逐漸習得不同複雜程度的技能。

##### **Emotion Recognition with Facial Attention and Objective Activation Functions**
2410.17740v1 by Andrzej Miskow, Abdulrahman Altahhan

In this paper, we study the effect of introducing channel and spatial
attention mechanisms, namely SEN-Net, ECA-Net, and CBAM, to existing CNN
vision-based models such as VGGNet, ResNet, and ResNetV2 to perform the Facial
Emotion Recognition task. We show that not only attention can significantly
improve the performance of these models but also that combining them with a
different activation function can further help increase the performance of
these models.

摘要：在本文中，我們研究了引入通道和空間注意力機制，即 SEN-Net、ECA-Net 和 CBAM，到現有的基於 CNN 視覺的模型，例如 VGGNet、ResNet 和 ResNetV2，以執行面部情緒識別任務。我們表明，注意力不僅可以顯著提高這些模型的性能，而且將它們與不同的激活函數結合使用還可以進一步幫助提高這些模型的性能。

##### **Local Contrastive Editing of Gender Stereotypes**
2410.17739v1 by Marlene Lutz, Rochelle Choenni, Markus Strohmaier, Anne Lauscher

Stereotypical bias encoded in language models (LMs) poses a threat to safe
language technology, yet our understanding of how bias manifests in the
parameters of LMs remains incomplete. We introduce local contrastive editing
that enables the localization and editing of a subset of weights in a target
model in relation to a reference model. We deploy this approach to identify and
modify subsets of weights that are associated with gender stereotypes in LMs.
Through a series of experiments, we demonstrate that local contrastive editing
can precisely localize and control a small subset (< 0.5%) of weights that
encode gender bias. Our work (i) advances our understanding of how
stereotypical biases can manifest in the parameter space of LMs and (ii) opens
up new avenues for developing parameter-efficient strategies for controlling
model properties in a contrastive manner.

摘要：語言模型 (LM) 中編碼的刻板印象偏差對安全的語言技術構成威脅，但我們對偏差如何在 LM 參數中體現的理解仍不完整。我們引入了局部對比編輯，它可以定位和編輯目標模型中相對於參考模型的權重子集。我們部署此方法來識別和修改與 LM 中性別刻板印象相關的權重子集。通過一系列實驗，我們證明了局部對比編輯可以精確地定位和控制編碼性別偏差的權重小子集 (< 0.5%)。我們的研究 (i) 提升了我們對刻板印象偏差如何在 LM 的參數空間中體現的理解，並 (ii) 開闢了新的途徑，用於開發參數高效的策略，以對比的方式控制模型屬性。

##### **MojoBench: Language Modeling and Benchmarks for Mojo**
2410.17736v1 by Nishat Raihan, Joanna C. S. Santos, Marcos Zampieri

The recently introduced Mojo programming language (PL) by Modular, has
received significant attention in the scientific community due to its claimed
significant speed boost over Python. Despite advancements in code Large
Language Models (LLMs) across various PLs, Mojo remains unexplored in this
context. To address this gap, we introduce MojoBench, the first framework for
Mojo code generation. MojoBench includes HumanEval-Mojo, a benchmark dataset
designed for evaluating code LLMs on Mojo, and Mojo-Coder, the first LLM
pretrained and finetuned for Mojo code generation, which supports instructions
in 5 natural languages (NLs). Our results show that Mojo-Coder achieves a
30-35% performance improvement over leading models like GPT-4o and
Claude-3.5-Sonnet. Furthermore, we provide insights into LLM behavior with
underrepresented and unseen PLs, offering potential strategies for enhancing
model adaptability. MojoBench contributes to our understanding of LLM
capabilities and limitations in emerging programming paradigms fostering more
robust code generation systems.

摘要：最近由 Modular 推出的 Mojo 程式語言 (PL) 由於聲稱比 Python 有顯著的加速提升，因此在科學界備受關注。儘管各種 PL 的程式碼大型語言模型 (LLM) 已有進展，但 Mojo 在這個背景下仍未被探索。為了解決這個差距，我們推出了 MojoBench，這是第一個用於 Mojo 程式碼生成的架構。MojoBench 包含 HumanEval-Mojo，這是一個基準資料集，用於評估 Mojo 上的程式碼 LLM，以及 Mojo-Coder，這是第一個針對 Mojo 程式碼生成進行預訓練和微調的 LLM，它支援 5 種自然語言 (NL) 的指令。我們的結果顯示，Mojo-Coder 比 GPT-4o 和 Claude-3.5-Sonnet 等領先模型的效能提升了 30-35%。此外，我們提供了 LLM 行為的見解，包括代表性不足和未見過的 PL，提供了增強模型適應性的潛在策略。MojoBench 有助於我們了解 LLM 在新興程式設計範例中的能力和限制，從而促進更強大的程式碼生成系統。

##### **New Insight in Cervical Cancer Diagnosis Using Convolution Neural Network Architecture**
2410.17735v1 by Ach. Khozaimi, Wayan Firdaus Mahmudy

The Pap smear is a screening method for early cervical cancer diagnosis. The
selection of the right optimizer in the convolutional neural network (CNN)
model is key to the success of the CNN in image classification, including the
classification of cervical cancer Pap smear images. In this study, stochastic
gradient descent (SGD), RMSprop, Adam, AdaGrad, AdaDelta, Adamax, and Nadam
optimizers were used to classify cervical cancer Pap smear images from the
SipakMed dataset. Resnet-18, Resnet-34, and VGG-16 are the CNN architectures
used in this study, and each architecture uses a transfer-learning model. Based
on the test results, we conclude that the transfer learning model performs
better on all CNNs and optimization techniques and that in the transfer
learning model, the optimization has little influence on the training of the
model. Adamax, with accuracy values of 72.8% and 66.8%, had the best accuracy
for the VGG-16 and Resnet-18 architectures, respectively. Resnet-34 had 54.0%.
This is 0.034% lower than Nadam. Overall, Adamax is a suitable optimizer for
CNN in cervical cancer classification on Resnet-18, Resnet-34, and VGG-16
architectures. This study provides new insights into the configuration of CNN
models for Pap smear image analysis.

摘要：子宮頸抹片檢查是早期子宮頸癌診斷的篩檢方法。在卷積神經網路 (CNN) 模型中選擇正確的最佳化器是 CNN 在影像分類中成功的關鍵，包括子宮頸抹片檢查影像的分類。在這項研究中，隨機梯度下降 (SGD)、RMSprop、Adam、AdaGrad、AdaDelta、Adamax 和 Nadam 最佳化器用於從 SipakMed 資料集分類子宮頸抹片檢查影像。Resnet-18、Resnet-34 和 VGG-16 是本研究中使用的 CNN 架構，每個架構都使用遷移學習模型。根據測試結果，我們得出結論，遷移學習模型在所有 CNN 和最佳化技術上表現得更好，並且在遷移學習模型中，最佳化對模型的訓練影響不大。Adamax，準確度值分別為 72.8% 和 66.8%，在 VGG-16 和 Resnet-18 架構中具有最佳準確度。Resnet-34 為 54.0%。這比 Nadam 低 0.034%。總體而言，Adamax 是 Resnet-18、Resnet-34 和 VGG-16 架構中子宮頸癌分類中 CNN 的合適最佳化器。這項研究為子宮頸抹片檢查影像分析的 CNN 模型配置提供了新的見解。

##### **FuzzWiz -- Fuzzing Framework for Efficient Hardware Coverage**
2410.17732v1 by Deepak Narayan Gadde, Aman Kumar, Djones Lettnin, Sebastian Simon

Ever-increasing design complexity of System-on-Chips (SoCs) led to
significant verification challenges. Unlike software, bugs in hardware design
are vigorous and eternal i.e., once the hardware is fabricated, it cannot be
repaired with any patch. Despite being one of the powerful techniques used in
verification, the dynamic random approach cannot give confidence to complex
Register Transfer Leve (RTL) designs during the pre-silicon design phase. In
particular, achieving coverage targets and exposing bugs is a complicated task
with random simulations. In this paper, we leverage an existing testing
solution available in the software world known as fuzzing and apply it to
hardware verification in order to achieve coverage targets in quick time. We
created an automated hardware fuzzing framework FuzzWiz using metamodeling and
Python to achieve coverage goals faster. It includes parsing the RTL design
module, converting it into C/C++ models, creating generic testbench with
assertions, fuzzer-specific compilation, linking, and fuzzing. Furthermore, it
is configurable and provides the debug flow if any crash is detected during the
fuzzing process. The proposed framework is applied on four IP blocks from
Google's OpenTitan chip with various fuzzing engines to show its scalability
and compatibility. Our benchmarking results show that we could achieve around
90% of the coverage 10 times faster than traditional simulation regression
based approach.

摘要：系統單晶片 (SoC) 日益增加的設計複雜度，導致了嚴峻的驗證挑戰。與軟體不同，硬體設計中的錯誤是強勁且永久的，亦即硬體一旦製造完成，就無法用任何補丁修復。儘管動態隨機方法是驗證中使用的一種強大技術，但它無法在矽前設計階段讓複雜的暫存器傳輸層級 (RTL) 設計充滿信心。特別是，在隨機模擬中，達成覆蓋率目標並揭露錯誤是一項複雜的任務。在本文中，我們利用軟體世界中現有的測試解決方案，稱為模糊測試，並將其應用於硬體驗證，以便在短時間內達成覆蓋率目標。我們使用元建模和 Python 建立了一個自動化硬體模糊測試架構 FuzzWiz，以更快達成覆蓋率目標。它包括剖析 RTL 設計模組、將其轉換為 C/C++ 模型、建立帶有斷言的通用測試平台、模糊測試器專用的編譯、連結和模糊測試。此外，它具有可設定性，並在模糊測試過程中偵測到任何崩潰時提供除錯流程。所提出的架構應用在 Google 的 OpenTitan 晶片的四個 IP 區塊上，並使用各種模糊測試引擎來展示其可擴充性和相容性。我們的基準測試結果顯示，我們能夠比傳統的模擬回歸測試方法快 10 倍，達成大約 90% 的覆蓋率。

##### **Dialectal and Low Resource Machine Translation for Aromanian**
2410.17728v1 by Alexandru-Iulius Jerpelea, Alina-Ştefania Rădoi, Sergiu Nisioi

We present a neural machine translation system that can translate between
Romanian, English, and Aromanian (an endangered Eastern Romance language); the
first of its kind. BLEU scores range from 17 to 32 depending on the direction
and genre of the text. Alongside, we release the biggest known
Aromanian-Romanian bilingual corpus, consisting of 79k cleaned sentence pairs.
Additional tools such as an agnostic sentence embedder (used for both text
mining and automatic evaluation) and a diacritics converter are also presented.
We publicly release our findings and models. Finally, we describe the
deployment of our quantized model at https://arotranslate.com.

摘要：我們提出一個神經機器翻譯系統，可以在羅馬尼亞語、英語和阿羅馬尼亞語（一種瀕臨滅絕的東羅曼語）之間進行翻譯；這是同類系統中的第一個。BLEU 分數根據文本的方向和類型在 17 到 32 之間。此外，我們發布了已知最大的阿羅馬尼亞語-羅馬尼亞語雙語語料庫，其中包含 79k 個已清理的句子對。還提供了其他工具，例如不可知論句子嵌入器（用於文本挖掘和自動評估）和變音符號轉換器。我們公開發布我們的發現和模型。最後，我們在 https://arotranslate.com 上描述了我們量化模型的部署。

##### **CogSteer: Cognition-Inspired Selective Layer Intervention for Efficient Semantic Steering in Large Language Models**
2410.17714v1 by Xintong Wang, Jingheng Pan, Longqin Jiang, Liang Ding, Xingshan Li, Chris Biemann

Despite their impressive capabilities, large language models (LLMs) often
lack interpretability and can generate toxic content. While using LLMs as
foundation models and applying semantic steering methods are widely practiced,
we believe that efficient methods should be based on a thorough understanding
of LLM behavior. To this end, we propose using eye movement measures to
interpret LLM behavior across layers. We find that LLMs exhibit patterns
similar to human gaze across layers and different layers function differently.
Inspired by these findings, we introduce a heuristic steering layer selection
and apply it to layer intervention methods via fine-tuning and inference. Using
language toxification and detoxification as test beds, we demonstrate that our
proposed CogSteer methods achieve better results in terms of toxicity scores
while efficiently saving 97% of the computational resources and 60% of the
training time. Our model-agnostic approach can be adopted into various LLMs,
contributing to their interpretability and promoting trustworthiness for safe
deployment.

摘要：儘管大型語言模型（LLM）具有令人印象深刻的能力，但它們通常缺乏可解釋性，並且可能會產生有毒的內容。雖然將 LLM 用作基礎模型並應用語義引導方法是廣泛實踐的，但我們相信有效的方法應該建立在對 LLM 行為的透徹理解之上。為此，我們建議使用眼球運動測量來解釋跨層的 LLM 行為。我們發現 LLM 展現出類似於人類在各層之間注視的模式，而且不同的層具有不同的功能。受這些發現的啟發，我們引入了一個啟發式引導層選擇，並透過微調和推論將其應用於層級介入方法。使用語言毒化和解毒作為測試平台，我們證明我們提出的 CogSteer 方法在毒性評分方面取得了更好的結果，同時有效節省了 97% 的運算資源和 60% 的訓練時間。我們的模型不可知方法可以被採用到各種 LLM 中，有助於它們的可解釋性，並促進安全部署的可信度。

##### **Beware of Calibration Data for Pruning Large Language Models**
2410.17711v1 by Yixin Ji, Yang Xiang, Juntao Li, Qingrong Xia, Ping Li, Xinyu Duan, Zhefeng Wang, Min Zhang

As large language models (LLMs) are widely applied across various fields,
model compression has become increasingly crucial for reducing costs and
improving inference efficiency. Post-training pruning is a promising method
that does not require resource-intensive iterative training and only needs a
small amount of calibration data to assess the importance of parameters.
Previous research has primarily focused on designing advanced pruning methods,
while different calibration data's impact on pruning performance still lacks
systematical exploration. We fill this blank and surprisingly observe that the
effects of calibration data even value more than designing advanced pruning
strategies, especially for high sparsity. Our preliminary exploration also
discloses that using calibration data similar to the training data can yield
better performance. As pre-training data is usually inaccessible for advanced
LLMs, we further provide a self-generating calibration data synthesis strategy
to construct feasible calibration data. We conduct experiments on the recent
strong open-source LLMs (e.g., DCLM, and LLaMA-3), and the results show that
the proposed method outperforms commonly used calibration data and can
effectively enhance strong pruning methods (e.g., Wanda, OWL).

摘要：隨著大型語言模型 (LLM) 廣泛應用於各個領域，
模型壓縮對於降低成本和提高推理效率變得越來越重要。訓練後剪枝是一種很有前途的方法，它不需要資源密集的迭代訓練，只需要少量校準數據來評估參數的重要性。
先前的研究主要集中於設計先進的剪枝方法，
而不同校準數據對剪枝效能的影響仍然缺乏系統性的探討。我們填補了這個空白，並驚訝地觀察到校準數據的影響甚至比設計先進的剪枝策略更有價值，特別是對於高稀疏性。我們的初步探討也揭示了使用類似於訓練數據的校準數據可以產生更好的效能。由於預訓練數據通常無法用於先進的 LLM，我們進一步提供了一個自生校準數據合成策略來建構可行的校準數據。我們對最近的強大開源 LLM（例如，DCLM 和 LLaMA-3）進行了實驗，結果表明，所提出的方法優於常用的校準數據，並且可以有效增強強大的剪枝方法（例如，Wanda、OWL）。

##### **Scalable Random Feature Latent Variable Models**
2410.17700v1 by Ying Li, Zhidi Lin, Yuhao Liu, Michael Minyi Zhang, Pablo M. Olmos, Petar M. Djurić

Random feature latent variable models (RFLVMs) represent the state-of-the-art
in latent variable models, capable of handling non-Gaussian likelihoods and
effectively uncovering patterns in high-dimensional data. However, their heavy
reliance on Monte Carlo sampling results in scalability issues which makes it
difficult to use these models for datasets with a massive number of
observations. To scale up RFLVMs, we turn to the optimization-based variational
Bayesian inference (VBI) algorithm which is known for its scalability compared
to sampling-based methods. However, implementing VBI for RFLVMs poses
challenges, such as the lack of explicit probability distribution functions
(PDFs) for the Dirichlet process (DP) in the kernel learning component, and the
incompatibility of existing VBI algorithms with RFLVMs. To address these
issues, we introduce a stick-breaking construction for DP to obtain an explicit
PDF and a novel VBI algorithm called ``block coordinate descent variational
inference" (BCD-VI). This enables the development of a scalable version of
RFLVMs, or in short, SRFLVM. Our proposed method shows scalability,
computational efficiency, superior performance in generating informative latent
representations and the ability of imputing missing data across various
real-world datasets, outperforming state-of-the-art competitors.

摘要：隨機特徵潛在變數模型 (RFLVM) 代表潛在變數模型的最新技術，能夠處理非高斯似然值，並有效地找出高維度資料中的模式。然而，它們過度依賴蒙地卡羅抽樣，導致可擴充性問題，這使得使用這些模型來處理具有大量觀測值的資料集變得困難。為了擴充 RFLVM，我們求助於基於最佳化的變異貝氏推論 (VBI) 演算法，與基於抽樣的模型相比，它以可擴充性著稱。然而，為 RFLVM 實作 VBI 會帶來挑戰，例如在核仁學習元件中缺乏狄利克雷過程 (DP) 的明確機率分佈函數 (PDF)，以及現有 VBI 演算法與 RFLVM 不相容。為了解決這些問題，我們為 DP 引入了斷棒結構，以取得明確的 PDF，以及一種稱為「區塊座標下降變異推論」(BCD-VI) 的新 VBI 演算法。這使得開發可擴充版本的 RFLVM，簡稱 SRFLVM，成為可能。我們提出的方法展現了可擴充性、運算效率、在產生資訊豐富的潛在表示方面的卓越效能，以及在各種真實世界資料集中估算遺失資料的能力，表現優於最新技術的競爭者。

##### **An Adaptive Framework for Generating Systematic Explanatory Answer in Online Q&A Platforms**
2410.17694v1 by Ziyang Chen, Xiaobin Wang, Yong Jiang, Jinzhi Liao, Pengjun Xie, Fei Huang, Xiang Zhao

Question Answering (QA) systems face challenges in handling complex questions
that require multi-domain knowledge synthesis. The naive RAG models, although
effective in information retrieval, struggle with complex questions that
require comprehensive and in-depth answers. The pioneering task is defined as
explanatory answer generation, which entails handling identified challenges
such as the requirement for comprehensive information and logical coherence
within the generated context. To address these issues, we refer to systematic
thinking theory and propose SynthRAG, an innovative framework designed to
enhance QA performance. SynthRAG improves on conventional models by employing
adaptive outlines for dynamic content structuring, generating systematic
information to ensure detailed coverage, and producing customized answers
tailored to specific user inquiries. This structured approach guarantees
logical coherence and thorough integration of information, yielding responses
that are both insightful and methodically organized. Empirical evaluations
underscore SynthRAG's effectiveness, demonstrating its superiority in handling
complex questions, overcoming the limitations of naive RAG models, and
significantly improving answer quality and depth. Furthermore, an online
deployment on the Zhihu platform revealed that SynthRAG's answers achieved
notable user engagement, with each response averaging 5.73 upvotes and
surpassing the performance of 79.8% of human contributors, highlighting the
practical relevance and impact of the proposed framework. Our code is available
at https://github.com/czy1999/SynthRAG .

摘要：問答 (QA) 系統在處理需要多領域知識綜合的複雜問題時面臨挑戰。樸素的 RAG 模型雖然在資訊檢索方面有效，但在需要全面且深入解答的複雜問題上卻難以應付。開創性的任務被定義為解釋性答案生成，其中包括處理已識別的挑戰，例如對全面資訊和生成內容中邏輯一致性的要求。為了解決這些問題，我們參考系統思考理論，並提出 SynthRAG，一個創新的框架，旨在增強 QA 效能。SynthRAG 透過採用適應性大綱進行動態內容建構、生成系統性資訊以確保詳細涵蓋範圍，以及產生針對特定使用者查詢量身打造的客製化答案，來改善傳統模型。這種結構化方法保證了邏輯一致性和資訊的徹底整合，產生既有洞察力又條理分明的回應。經驗評估強調了 SynthRAG 的有效性，證明了它在處理複雜問題、克服樸素 RAG 模型的限制以及顯著改善答案品質和深度方面的優越性。此外，在知乎平台上的線上部署顯示，SynthRAG 的答案獲得了顯著的使用者參與，每個回應平均獲得 5.73 個讚，並超越了 79.8% 的人類貢獻者的表現，突顯了所提出框架的實際相關性和影響力。我們的程式碼可在 https://github.com/czy1999/SynthRAG 取得。

##### **Quantifying the Risks of Tool-assisted Rephrasing to Linguistic Diversity**
2410.17670v1 by Mengying Wang, Andreas Spitz

Writing assistants and large language models see widespread use in the
creation of text content. While their effectiveness for individual users has
been evaluated in the literature, little is known about their proclivity to
change language or reduce its richness when adopted by a large user base. In
this paper, we take a first step towards quantifying this risk by measuring the
semantic and vocabulary change enacted by the use of rephrasing tools on a
multi-domain corpus of human-generated text.

摘要：寫作助理和大語言模型在文字內容的創作中廣泛使用。儘管文獻中已評估其對個別使用者的有效性，但當大量使用者採用時，它們改變語言或降低其豐富性的傾向卻鮮為人知。在本文中，我們透過衡量重新表述工具在由人類產生的文字的多領域語料庫上所執行的語意和詞彙變化，朝量化此風險邁出第一步。

##### **PETAH: Parameter Efficient Task Adaptation for Hybrid Transformers in a resource-limited Context**
2410.17661v1 by Maximilian Augustin, Syed Shakib Sarwar, Mostafa Elhoushi, Sai Qian Zhang, Yuecheng Li, Barbara De Salvo

Following their success in natural language processing (NLP), there has been
a shift towards transformer models in computer vision. While transformers
perform well and offer promising multi-tasking performance, due to their high
compute requirements, many resource-constrained applications still rely on
convolutional or hybrid models that combine the benefits of convolution and
attention layers and achieve the best results in the sub 100M parameter range.
Simultaneously, task adaptation techniques that allow for the use of one shared
transformer backbone for multiple downstream tasks, resulting in great storage
savings at negligible cost in performance, have not yet been adopted for hybrid
transformers. In this work, we investigate how to achieve the best
task-adaptation performance and introduce PETAH: Parameter Efficient Task
Adaptation for Hybrid Transformers. We further combine PETAH adaptation with
pruning to achieve highly performant and storage friendly models for
multi-tasking. In our extensive evaluation on classification and other vision
tasks, we demonstrate that our PETAH-adapted hybrid models outperform
established task-adaptation techniques for ViTs while requiring fewer
parameters and being more efficient on mobile hardware.

摘要：在自然語言處理 (NLP) 領域取得成功後，電腦視覺領域開始轉向使用 Transformer 模型。雖然 Transformer 的表現良好，且提供令人期待的多工處理效能，但由於其運算需求高，許多資源受限的應用程式仍仰賴卷積或混合模型，這種模型結合了卷積和注意力層的優點，並在低於 1 億個參數的範圍內達到最佳結果。同時，允許將一個共用的 Transformer 主幹用於多個下游任務的任務適應技術，可大幅節省儲存空間，且效能損失極小，但尚未用於混合 Transformer。在這項研究中，我們探討如何達成最佳任務適應效能，並介紹 PETAH：混合 Transformer 的參數高效任務適應。我們進一步結合 PETAH 適應和剪枝，以達成高性能且儲存空間友善的多工處理模型。在我們對分類和其他視覺任務進行的廣泛評估中，我們證明了我們的 PETAH 適應混合模型優於 ViT 的既定任務適應技術，同時所需參數更少，且在行動裝置硬體上的效率更高。

##### **ReflecTool: Towards Reflection-Aware Tool-Augmented Clinical Agents**
2410.17657v1 by Yusheng Liao, Shuyang Jiang, Yanfeng Wang, Yu Wang

Large Language Models (LLMs) have shown promising potential in the medical
domain, assisting with tasks like clinical note generation and patient
communication. However, current LLMs are limited to text-based communication,
hindering their ability to interact with diverse forms of information in
clinical environments. Despite clinical agents succeeding in diverse signal
interaction, they are oriented to a single clinical scenario and hence fail for
broader applications. To evaluate clinical agents holistically, we propose
ClinicalAgent Bench~(CAB), a comprehensive medical agent benchmark consisting
of 18 tasks across five key realistic clinical dimensions. Building on this, we
introduce ReflecTool, a novel framework that excels at utilizing
domain-specific tools within two stages. The first optimization stage
progressively enlarges a long-term memory by saving successful solving
processes and tool-wise experience of agents in a tiny pre-defined training
set. In the following inference stage, ReflecTool can search for supportive
successful demonstrations from already built long-term memory to guide the tool
selection strategy, and a verifier improves the tool usage according to the
tool-wise experience with two verification methods--iterative refinement and
candidate selection. Extensive experiments on ClinicalAgent Benchmark
demonstrate that ReflecTool surpasses the pure LLMs with more than 10 points
and the well-established agent-based methods with 3 points, highlighting its
adaptability and effectiveness in solving complex clinical tasks.

摘要：大型語言模型 (LLM) 在醫療領域展現出令人振奮的潛力，協助執行臨床筆記生成和患者溝通等任務。然而，目前的 LLM 僅限於基於文字的溝通，阻礙了它們與臨床環境中各種形式資訊互動的能力。儘管臨床代理已成功進行多種訊號互動，但它們面向單一臨床場景，因此無法廣泛應用。為了全面評估臨床代理，我們提出 ClinicalAgent Bench~(CAB)，這是一個全面的醫療代理基準，包含五個主要現實臨床面向的 18 項任務。在此基礎上，我們引進 ReflecTool，這是一個新穎的架構，擅長在兩個階段內使用特定於領域的工具。第一個最佳化階段透過儲存成功解決程序和代理在極小的預先定義訓練集中獲得的工具經驗，逐漸擴充長期記憶體。在後續的推論階段，ReflecTool 可以從已建構的長期記憶體中搜尋有用的成功示範，以引導工具選取策略，而驗證器會根據工具經驗和兩種驗證方法（反覆精煉和候選選擇）改善工具使用。在 ClinicalAgent Benchmark 上進行的廣泛實驗證明，ReflecTool 以超過 10 分的差距超越純粹的 LLM，並以 3 分的差距超越既有的基於代理的方法，突顯其在解決複雜臨床任務方面的適應性和有效性。

##### **AutoRNet: Automatically Optimizing Heuristics for Robust Network Design via Large Language Models**
2410.17656v1 by He Yu, Jing Liu

Achieving robust networks is a challenging problem due to its NP-hard nature
and complex solution space. Current methods, from handcrafted feature
extraction to deep learning, have made progress but remain rigid, requiring
manual design and large labeled datasets. To address these issues, we propose
AutoRNet, a framework that integrates large language models (LLMs) with
evolutionary algorithms to generate heuristics for robust network design. We
design network optimization strategies to provide domain-specific prompts for
LLMs, utilizing domain knowledge to generate advanced heuristics. Additionally,
we introduce an adaptive fitness function to balance convergence and diversity
while maintaining degree distributions. AutoRNet is evaluated on sparse and
dense scale-free networks, outperforming current methods by reducing the need
for manual design and large datasets.

摘要：由於 NP 難度性質和複雜的解空間，實現穩健網路是一個具有挑戰性的問題。目前的方法，從手工特徵萃取到深度學習，已經取得進展，但仍然僵化，需要手動設計和大量的標籤資料集。為了解決這些問題，我們提出了 AutoRNet，一個整合大型語言模型 (LLM) 與演算法的框架，用於產生用於穩健網路設計的啟發式方法。我們設計網路最佳化策略，為 LLM 提供特定於領域的提示，利用領域知識產生進階啟發式方法。此外，我們引入了一個適應性適應度函數，在維持度數分佈的同時平衡收斂性和多樣性。AutoRNet 在稀疏和密集的無標度網路中進行評估，通過減少對手動設計和大資料集的需求，優於目前的方法。

##### **Mapping the Media Landscape: Predicting Factual Reporting and Political Bias Through Web Interactions**
2410.17655v1 by Dairazalia Sánchez-Cortés, Sergio Burdisso, Esaú Villatoro-Tello, Petr Motlicek

Bias assessment of news sources is paramount for professionals,
organizations, and researchers who rely on truthful evidence for information
gathering and reporting. While certain bias indicators are discernible from
content analysis, descriptors like political bias and fake news pose greater
challenges. In this paper, we propose an extension to a recently presented news
media reliability estimation method that focuses on modeling outlets and their
longitudinal web interactions. Concretely, we assess the classification
performance of four reinforcement learning strategies on a large news media
hyperlink graph. Our experiments, targeting two challenging bias descriptors,
factual reporting and political bias, showed a significant performance
improvement at the source media level. Additionally, we validate our methods on
the CLEF 2023 CheckThat! Lab challenge, outperforming the reported results in
both, F1-score and the official MAE metric. Furthermore, we contribute by
releasing the largest annotated dataset of news source media, categorized with
factual reporting and political bias labels. Our findings suggest that
profiling news media sources based on their hyperlink interactions over time is
feasible, offering a bird's-eye view of evolving media landscapes.

摘要：對於仰賴真實證據進行資訊收集和報導的專業人士、組織和研究人員而言，新聞來源的偏見評估至關重要。雖然某些偏見指標可以從內容分析中辨別出來，但政治偏見和假新聞等描述詞卻帶來更大的挑戰。在本文中，我們提出對近期提出的新聞媒體可靠性估計方法的延伸，其重點在於建模媒體及其縱向網路互動。具體來說，我們評估四種強化學習策略在大型新聞媒體超連結圖上的分類效能。我們的實驗針對兩個具有挑戰性的偏見描述詞，即事實報導和政治偏見，顯示在來源媒體層級上有顯著的效能提升。此外，我們在 CLEF 2023 CheckThat！實驗室挑戰中驗證我們的這些方法，在 F1 分數和官方 MAE 指標中都優於已報告的結果。此外，我們透過釋出標有事實報導和政治偏見標籤的最大新聞來源媒體註解資料集來做出貢獻。我們的研究結果表明，根據新聞媒體來源隨著時間推移的超連結互動來建立其個人資料是可行的，這提供了媒體環境演變的鳥瞰圖。

##### **MIA-DPO: Multi-Image Augmented Direct Preference Optimization For Large Vision-Language Models**
2410.17637v1 by Ziyu Liu, Yuhang Zang, Xiaoyi Dong, Pan Zhang, Yuhang Cao, Haodong Duan, Conghui He, Yuanjun Xiong, Dahua Lin, Jiaqi Wang

Visual preference alignment involves training Large Vision-Language Models
(LVLMs) to predict human preferences between visual inputs. This is typically
achieved by using labeled datasets of chosen/rejected pairs and employing
optimization algorithms like direct preference optimization (DPO). Existing
visual alignment methods, primarily designed for single-image scenarios,
struggle to effectively handle the complexity of multi-image tasks due to the
scarcity of diverse training data and the high cost of annotating
chosen/rejected pairs. We present Multi-Image Augmented Direct Preference
Optimization (MIA-DPO), a visual preference alignment approach that effectively
handles multi-image inputs. MIA-DPO mitigates the scarcity of diverse
multi-image training data by extending single-image data with unrelated images
arranged in grid collages or pic-in-pic formats, significantly reducing the
costs associated with multi-image data annotations. Our observation reveals
that attention values of LVLMs vary considerably across different images. We
use attention values to identify and filter out rejected responses the model
may have mistakenly focused on. Our attention-aware selection for constructing
the chosen/rejected pairs without relying on (i) human annotation, (ii) extra
data, and (iii) external models or APIs. MIA-DPO is compatible with various
architectures and outperforms existing methods on five multi-image benchmarks,
achieving an average performance boost of 3.0% on LLaVA-v1.5 and 4.3% on the
recent InternLM-XC2.5. Moreover, MIA-DPO has a minimal effect on the model's
ability to understand single images.

摘要：視覺偏好對齊涉及訓練大型視覺語言模型 (LVLMs) 以預測人類在視覺輸入之間的偏好。這通常透過使用已選擇/已拒絕配對的標籤資料集，並採用直接偏好最佳化 (DPO) 等最佳化演算法來達成。現有的視覺對齊方法主要設計用於單一影像場景，由於缺乏多樣化的訓練資料，以及標註已選擇/已拒絕配對的高成本，因此難以有效處理多重影像任務的複雜性。我們提出多重影像擴充直接偏好最佳化 (MIA-DPO)，這是一種視覺偏好對齊方法，能夠有效處理多重影像輸入。MIA-DPO 透過將單一影像資料擴充為排列成網格拼貼或畫中畫格式的無關影像，來減輕多樣化多重影像訓練資料的稀缺性，大幅降低多重影像資料標註相關的成本。我們的觀察顯示，LVLMs 的注意力值在不同影像之間有顯著差異。我們使用注意力值來識別和篩選出模型可能錯誤關注的已拒絕回應。我們使用注意力感知選擇來建構已選擇/已拒絕配對，而不依賴 (i) 人工標註、(ii) 額外資料，以及 (iii) 外部模型或 API。MIA-DPO 與各種架構相容，並且在五個多重影像基準上優於現有方法，在 LLaVA-v1.5 上達到平均效能提升 3.0%，在最近的 InternLM-XC2.5 上達到 4.3%。此外，MIA-DPO 對模型理解單一影像的能力影響甚微。

##### **Markov Chain of Thought for Efficient Mathematical Reasoning**
2410.17635v1 by Wen Yang, Kai Fan, Minpeng Liao

Chain of Thought (CoT) of multi-step benefits from the logical structure of
the reasoning steps and task-specific actions, significantly enhancing the
mathematical reasoning capabilities of large language models. As the prevalence
of long CoT, the number of reasoning steps exceeds manageable token limits and
leads to higher computational demands. Inspired by the fundamental logic of
human cognition, ``derive, then reduce'', we conceptualize the standard
multi-step CoT as a novel Markov Chain of Thought (MCoT). In this study, we
consider the mathematical reasoning task, defining each reasoning step as text
accompanied by a Python code snippet. To facilitate a longer reasoning path,
self-correction is enabled through interactions with the code interpreter. Our
MCoT aims to compress previous reasoning steps into a simplified question,
enabling efficient next-step inference without relying on a lengthy KV cache.
In our experiments, we curate the \texttt{MCoTInstruct} dataset, and the
empirical results indicate that MCoT not only significantly enhances efficiency
but also maintains comparable accuracy. While much remains to be explored, this
work paves the way for exploring the long CoT reasoning abilities of LLMs.

摘要：多步驟推理步驟和特定任務動作的邏輯結構，提升多步驟推理的思考鏈（CoT），大幅提升大型語言模型的數學推理能力。隨著長 CoT 的普遍性，推理步驟數量超過可管理的符號限制，並導致更高的運算需求。受人類認知的基礎邏輯「先推導，再簡化」的啟發，我們將標準的多步驟 CoT 概念化為新的馬可夫思考鏈（MCoT）。在這項研究中，我們考慮數學推理任務，將每個推理步驟定義為附有 Python 程式碼片段的文字。為了促進更長的推理路徑，透過與程式碼解釋器的互動啟用自我修正。我們的 MCoT 旨在將先前的推理步驟壓縮成一個簡化的問題，讓後續步驟推論更有效率，而不依賴於冗長的 KV 快取。在我們的實驗中，我們策劃了 \texttt{MCoTInstruct} 資料集，而實證結果顯示，MCoT 不僅大幅提升效率，還能維持相當的準確性。儘管仍有許多需要探索之處，這項工作為探索大型語言模型的長 CoT 推理能力鋪路。

##### **LMLPA: Language Model Linguistic Personality Assessment**
2410.17632v1 by Jingyao Zheng, Xian Wang, Simo Hosio, Xiaoxian Xu, Lik-Hang Lee

Large Language Models (LLMs) are increasingly used in everyday life and
research. One of the most common use cases is conversational interactions,
enabled by the language generation capabilities of LLMs. Just as between two
humans, a conversation between an LLM-powered entity and a human depends on the
personality of the conversants. However, measuring the personality of a given
LLM is currently a challenge. This paper introduces the Language Model
Linguistic Personality Assessment (LMLPA), a system designed to evaluate the
linguistic personalities of LLMs. Our system helps to understand LLMs' language
generation capabilities by quantitatively assessing the distinct personality
traits reflected in their linguistic outputs. Unlike traditional human-centric
psychometrics, the LMLPA adapts a personality assessment questionnaire,
specifically the Big Five Inventory, to align with the operational capabilities
of LLMs, and also incorporates the findings from previous language-based
personality measurement literature. To mitigate sensitivity to the order of
options, our questionnaire is designed to be open-ended, resulting in textual
answers. Thus, the AI rater is needed to transform ambiguous personality
information from text responses into clear numerical indicators of personality
traits. Utilising Principal Component Analysis and reliability validations, our
findings demonstrate that LLMs possess distinct personality traits that can be
effectively quantified by the LMLPA. This research contributes to
Human-Computer Interaction and Human-Centered AI, providing a robust framework
for future studies to refine AI personality assessments and expand their
applications in multiple areas, including education and manufacturing.

摘要：大型語言模型（LLM）在日常生活和研究中使用越來越多。最常見的用例之一是對話互動，這要歸功於 LLM 的語言生成能力。就像兩個人類之間一樣，由 LLM 驅動的實體與人類之間的對話取決於對話者的個性。然而，測量給定 LLM 的個性目前是一個挑戰。本文介紹了語言模型語言人格評估 (LMLPA)，這是一個旨在評估 LLM 的語言人格的系統。我們的系統通過定量評估其語言輸出中反映的不同人格特質，幫助理解 LLM 的語言生成能力。與傳統的人本心理測量學不同，LMLPA 採用人格評量問卷，特別是大五人格量表，以符合 LLM 的運作能力，並納入先前基於語言的人格測量文獻中的發現。為了減輕對選項順序的敏感性，我們的問卷被設計成開放式的，從而產生文本答案。因此，需要 AI 評分者將文本回答中模稜兩可的人格信息轉換為人格特質的明確數字指標。利用主成分分析和信度驗證，我們的研究結果表明，LLM 具有不同的個性特質，可以通過 LMLPA 有效地量化。這項研究有助於人機互動和以人為中心的 AI，為未來的研究提供了一個穩健的框架，以完善 AI 人格評估並擴展其在包括教育和製造業在內的多個領域的應用。

##### **Process Supervision-Guided Policy Optimization for Code Generation**
2410.17621v1 by Ning Dai, Zheng Wu, Renjie Zheng, Ziyun Wei, Wenlei Shi, Xing Jin, Guanlin Liu, Chen Dun, Liang Huang, Lin Yan

Reinforcement Learning (RL) with unit test feedback has enhanced large
language models (LLMs) code generation, but relies on sparse rewards provided
only after complete code evaluation, limiting learning efficiency and
incremental improvements. When generated code fails all unit tests, no learning
signal is received, hindering progress on complex tasks. To address this, we
propose a Process Reward Model (PRM) that delivers dense, line-level feedback
on code correctness during generation, mimicking human code refinement and
providing immediate guidance. We explore various strategies for training PRMs
and integrating them into the RL framework, finding that using PRMs both as
dense rewards and for value function initialization significantly boosts
performance. Our approach increases our in-house LLM's pass rate from 28.2% to
29.8% on LiveCodeBench and from 31.8% to 35.8% on our internal benchmark. Our
experimental results highlight the effectiveness of PRMs in enhancing RL-driven
code generation, especially for long-horizon scenarios.

摘要：強化學習（RL）搭配單元測試回饋已增強大型語言模型（LLM）的程式碼生成，但依賴於僅在完整程式碼評估後提供的稀疏獎勵，這限制了學習效率和漸進式改進。當產生的程式碼未通過所有單元測試時，不會收到任何學習訊號，這阻礙了複雜任務的進度。為了解決這個問題，我們提出了一個處理獎勵模型（PRM），它在產生程式碼時提供密集的、逐行回饋，模擬人類程式碼的精煉並提供即時指導。我們探討了各種訓練 PRM 和將其整合到 RL 架構中的策略，發現將 PRM 用作密集獎勵和用於值函數初始化都能顯著提升效能。我們的做法將我們內部的 LLM 在 LiveCodeBench 上的通過率從 28.2% 提升至 29.8%，在我們的內部基準上從 31.8% 提升至 35.8%。我們的實驗結果突顯了 PRM 在增強 RL 驅動的程式碼生成方面的有效性，特別是在長時程情境中。

##### **From PDFs to Structured Data: Utilizing LLM Analysis in Sports Database Management**
2410.17619v1 by Juhani Merilehto

This study investigates the effectiveness of Large Language Models (LLMs) in
processing semi-structured data from PDF documents into structured formats,
specifically examining their application in updating the Finnish Sports Clubs
Database. Through action research methodology, we developed and evaluated an
AI-assisted approach utilizing OpenAI's GPT-4 and Anthropic's Claude 3 Opus
models to process data from 72 sports federation membership reports. The system
achieved a 90% success rate in automated processing, successfully handling 65
of 72 files without errors and converting over 7,900 rows of data. While the
initial development time was comparable to traditional manual processing (three
months), the implemented system shows potential for reducing future processing
time by approximately 90%. Key challenges included handling multilingual
content, processing multi-page datasets, and managing extraneous information.
The findings suggest that while LLMs demonstrate significant potential for
automating semi-structured data processing tasks, optimal results are achieved
through a hybrid approach combining AI automation with selective human
oversight. This research contributes to the growing body of literature on
practical LLM applications in organizational data management and provides
insights into the transformation of traditional data processing workflows.

摘要：本研究探討大型語言模型 (LLM) 在將 PDF 文件中的半結構化資料處理成結構化格式的效能，特別檢視其在更新芬蘭體育俱樂部資料庫的應用。透過行動研究方法，我們開發並評估了一種 AI 輔助方法，利用 OpenAI 的 GPT-4 和 Anthropic 的 Claude 3 Opus 模型來處理來自 72 個體育聯盟會員報告的資料。該系統在自動化處理中達到了 90% 的成功率，成功處理了 72 個檔案中的 65 個，且沒有錯誤，並轉換了超過 7,900 列的資料。儘管最初的開發時間與傳統的人工處理相當（三個月），但已實施的系統顯示出將來處理時間減少約 90% 的潛力。主要的挑戰包括處理多語言內容、處理多頁面資料集，以及管理額外的資訊。研究結果表明，儘管 LLM 在自動化半結構化資料處理任務方面展現出顯著的潛力，但最佳的結果是透過結合 AI 自動化與選擇性的人工監督的混合方法來實現。本研究有助於組織資料管理中 LLM 實際應用領域的文獻不斷增加，並提供對傳統資料處理工作流程轉型的見解。

##### **Towards Effective Data-Free Knowledge Distillation via Diverse Diffusion Augmentation**
2410.17606v1 by Muquan Li, Dongyang Zhang, Tao He, Xiurui Xie, Yuan-Fang Li, Ke Qin

Data-free knowledge distillation (DFKD) has emerged as a pivotal technique in
the domain of model compression, substantially reducing the dependency on the
original training data. Nonetheless, conventional DFKD methods that employ
synthesized training data are prone to the limitations of inadequate diversity
and discrepancies in distribution between the synthesized and original
datasets. To address these challenges, this paper introduces an innovative
approach to DFKD through diverse diffusion augmentation (DDA). Specifically, we
revise the paradigm of common data synthesis in DFKD to a composite process
through leveraging diffusion models subsequent to data synthesis for
self-supervised augmentation, which generates a spectrum of data samples with
similar distributions while retaining controlled variations. Furthermore, to
mitigate excessive deviation in the embedding space, we introduce an image
filtering technique grounded in cosine similarity to maintain fidelity during
the knowledge distillation process. Comprehensive experiments conducted on
CIFAR-10, CIFAR-100, and Tiny-ImageNet datasets showcase the superior
performance of our method across various teacher-student network
configurations, outperforming the contemporary state-of-the-art DFKD methods.
Code will be available at:https://github.com/SLGSP/DDA.

摘要：無資料知識萃取（DFKD）已成為模型壓縮領域的關鍵技術，大幅降低對原始訓練資料的依賴性。儘管如此，採用合成訓練資料的傳統 DFKD 方法容易受到合成資料與原始資料集之間分佈差異性和多樣性不足的限制。為了應對這些挑戰，本文透過多樣擴增（DDA）提出 DFKD 的創新方法。具體而言，我們將 DFKD 中常見的資料合成範例修改為複合流程，透過在資料合成後利用擴散模型進行自我監督擴增，產生分佈相似的資料樣本光譜，同時保留受控變異。此外，為了減輕嵌入空間中的過度偏差，我們引入基於餘弦相似度的影像過濾技術，以在知識萃取過程中維持保真度。在 CIFAR-10、CIFAR-100 和 Tiny-ImageNet 資料集上進行的全面實驗展示了我們的方法在各種師生網路配置中的卓越效能，優於當代最先進的 DFKD 方法。程式碼將於以下網址提供：https://github.com/SLGSP/DDA。

##### **Integrating Large Language Models for UAV Control in Simulated Environments: A Modular Interaction Approach**
2410.17602v1 by Abhishek Phadke, Alihan Hadimlioglu, Tianxing Chu, Chandra N Sekharan

The intersection of LLMs (Large Language Models) and UAV (Unoccupied Aerial
Vehicles) technology represents a promising field of research with the
potential to enhance UAV capabilities significantly. This study explores the
application of LLMs in UAV control, focusing on the opportunities for
integrating advanced natural language processing into autonomous aerial
systems. By enabling UAVs to interpret and respond to natural language
commands, LLMs simplify the UAV control and usage, making them accessible to a
broader user base and facilitating more intuitive human-machine interactions.
The paper discusses several key areas where LLMs can impact UAV technology,
including autonomous decision-making, dynamic mission planning, enhanced
situational awareness, and improved safety protocols. Through a comprehensive
review of current developments and potential future directions, this study aims
to highlight how LLMs can transform UAV operations, making them more adaptable,
responsive, and efficient in complex environments. A template development
framework for integrating LLMs in UAV control is also described. Proof of
Concept results that integrate existing LLM models and popular robotic
simulation platforms are demonstrated. The findings suggest that while there
are substantial technical and ethical challenges to address, integrating LLMs
into UAV control holds promising implications for advancing autonomous aerial
systems.

摘要：大型語言模型 (LLM) 與無人機 (UAV) 技術的交集代表了一個有前途的研究領域，具有顯著提升無人機能力的潛力。本研究探討了 LLM 在無人機控制中的應用，重點關注將先進的自然語言處理整合到自主空中系統中的機會。通過使無人機能夠理解和回應自然語言命令，LLM 簡化了無人機的控制和使用，使其可以被更廣泛的使用者使用，並促進更直觀的人機互動。本文討論了 LLM 可以影響無人機技術的幾個關鍵領域，包括自主決策、動態任務規劃、增強情境感知和改進的安全協定。透過全面回顧目前的發展和潛在的未來方向，本研究旨在強調 LLM 如何轉變無人機操作，使其在複雜的環境中更具適應性、響應性和效率。還描述了一個用於將 LLM 整合到無人機控制中的模板開發框架。展示了整合現有 LLM 模型和流行機器人模擬平台的概念驗證結果。研究結果表明，儘管存在重大的技術和倫理挑戰需要解決，但將 LLM 整合到無人機控制中對於推進自主空中系統具有潛在的意義。

##### **Graphusion: A RAG Framework for Knowledge Graph Construction with a Global Perspective**
2410.17600v1 by Rui Yang, Boming Yang, Aosong Feng, Sixun Ouyang, Moritz Blum, Tianwei She, Yuang Jiang, Freddy Lecue, Jinghui Lu, Irene Li

Knowledge Graphs (KGs) are crucial in the field of artificial intelligence
and are widely used in downstream tasks, such as question-answering (QA). The
construction of KGs typically requires significant effort from domain experts.
Large Language Models (LLMs) have recently been used for Knowledge Graph
Construction (KGC). However, most existing approaches focus on a local
perspective, extracting knowledge triplets from individual sentences or
documents, missing a fusion process to combine the knowledge in a global KG.
This work introduces Graphusion, a zero-shot KGC framework from free text. It
contains three steps: in Step 1, we extract a list of seed entities using topic
modeling to guide the final KG includes the most relevant entities; in Step 2,
we conduct candidate triplet extraction using LLMs; in Step 3, we design the
novel fusion module that provides a global view of the extracted knowledge,
incorporating entity merging, conflict resolution, and novel triplet discovery.
Results show that Graphusion achieves scores of 2.92 and 2.37 out of 3 for
entity extraction and relation recognition, respectively. Moreover, we showcase
how Graphusion could be applied to the Natural Language Processing (NLP) domain
and validate it in an educational scenario. Specifically, we introduce TutorQA,
a new expert-verified benchmark for QA, comprising six tasks and a total of
1,200 QA pairs. Using the Graphusion-constructed KG, we achieve a significant
improvement on the benchmark, for example, a 9.2% accuracy improvement on
sub-graph completion.

摘要：<paragraph>知識圖譜 (KG) 在人工智慧領域至關重要，廣泛用於下游任務，例如問答 (QA)。KG 的建構通常需要領域專家付出大量心力。大型語言模型 (LLM) 近來已用於知識圖譜建構 (KGC)。然而，現有方法大多著重於局部觀點，從個別句子或文件擷取知識三元組，缺少一個融合程序來將知識結合在一個整體 KG 中。本研究引入了 Graphusion，一個從自由文字進行零次學習的 KGC 框架。它包含三個步驟：在步驟 1 中，我們使用主題建模擷取一組種子實體，以引導最終的 KG 納入最相關的實體；在步驟 2 中，我們使用 LLM 進行候選三元組擷取；在步驟 3 中，我們設計了新穎的融合模組，提供擷取知識的整體觀點，包含實體合併、衝突解決和新三元組發現。結果顯示 Graphusion 在實體擷取和關係識別方面分別獲得 3 分中的 2.92 分和 2.37 分。此外，我們展示了 Graphusion 如何應用於自然語言處理 (NLP) 領域，並在教育情境中驗證它。具體來說，我們引入了 TutorQA，一個由專家驗證的新型 QA 基準，包含六項任務和總計 1,200 組 QA。使用 Graphusion 建構的 KG，我們在基準上取得顯著進步，例如，在子圖完成方面提升了 9.2% 的準確度。</paragraph>

##### **Cross-model Control: Improving Multiple Large Language Models in One-time Training**
2410.17599v1 by Jiayi Wu, Hao Sun, Hengyi Cai, Lixin Su, Shuaiqiang Wang, Dawei Yin, Xiang Li, Ming Gao

The number of large language models (LLMs) with varying parameter scales and
vocabularies is increasing. While they deliver powerful performance, they also
face a set of common optimization needs to meet specific requirements or
standards, such as instruction following or avoiding the output of sensitive
information from the real world. However, how to reuse the fine-tuning outcomes
of one model to other models to reduce training costs remains a challenge. To
bridge this gap, we introduce Cross-model Control (CMC), a method that improves
multiple LLMs in one-time training with a portable tiny language model.
Specifically, we have observed that the logit shift before and after
fine-tuning is remarkably similar across different models. Based on this
insight, we incorporate a tiny language model with a minimal number of
parameters. By training alongside a frozen template LLM, the tiny model gains
the capability to alter the logits output by the LLMs. To make this tiny
language model applicable to models with different vocabularies, we propose a
novel token mapping strategy named PM-MinED. We have conducted extensive
experiments on instruction tuning and unlearning tasks, demonstrating the
effectiveness of CMC. Our code is available at https://github.com/wujwyi/CMC.

摘要：随着参数规模和词汇量不同的各种大型语言模型（LLM）数量的增加。虽然它们提供了强大的性能，但它们也面临着一组共同的优化需求，以满足特定要求或标准，例如遵循指令或避免输出来自现实世界的敏感信息。然而，如何将一个模型的微调结果重新用于其他模型以降低训练成本仍然是一个挑战。为了弥合这一差距，我们引入了跨模型控制（CMC），这是一种通过便携式微型语言模型对多个 LLM 进行一次性训练的方法。具体来说，我们观察到微调前后 logit 的偏移在不同的模型中非常相似。基于这一见解，我们结合了一个具有最少数量参数的微型语言模型。通过与冻结的模板 LLM 一起训练，微型模型获得了改变 LLM 输出的 logit 的能力。为了使这个微型语言模型适用于具有不同词汇的模型，我们提出了一种名为 PM-MinED 的新颖标记映射策略。我们对指令调整和遗忘任务进行了广泛的实验，证明了 CMC 的有效性。我们的代码可在 https://github.com/wujwyi/CMC 获得。

##### **Challenge on Sound Scene Synthesis: Evaluating Text-to-Audio Generation**
2410.17589v1 by Junwon Lee, Modan Tailleur, Laurie M. Heller, Keunwoo Choi, Mathieu Lagrange, Brian McFee, Keisuke Imoto, Yuki Okamoto

Despite significant advancements in neural text-to-audio generation,
challenges persist in controllability and evaluation. This paper addresses
these issues through the Sound Scene Synthesis challenge held as part of the
Detection and Classification of Acoustic Scenes and Events 2024. We present an
evaluation protocol combining objective metric, namely Fr\'echet Audio
Distance, with perceptual assessments, utilizing a structured prompt format to
enable diverse captions and effective evaluation. Our analysis reveals varying
performance across sound categories and model architectures, with larger models
generally excelling but innovative lightweight approaches also showing promise.
The strong correlation between objective metrics and human ratings validates
our evaluation approach. We discuss outcomes in terms of audio quality,
controllability, and architectural considerations for text-to-audio
synthesizers, providing direction for future research.

摘要：儘管神經文本轉音訊生成技術有顯著進展，但可控性和評估方面仍存在挑戰。本文透過 2024 年聲景與事件偵測與分類競賽中舉辦的 Sound Scene Synthesis 挑戰來解決這些問題。我們提出一個評估協定，結合客觀指標，即 Fr\'echet 音訊距離，與感知評估，利用結構化提示格式來啟用多樣化的標題和有效的評估。我們的分析揭示不同音訊類別和模型架構之間的效能差異，較大的模型通常表現出色，但創新的輕量化方法也顯示出前景。客觀指標與人類評分之間的強相關性驗證了我們的評估方法。我們根據音訊品質、可控性和文本轉音訊合成器的架構考量來討論結果，為未來的研究提供方向。

##### **Bonsai: Gradient-free Graph Distillation for Node Classification**
2410.17579v1 by Mridul Gupta, Samyak Jain, Vansh Ramani, Hariprasad Kodamana, Sayan Ranu

Graph distillation has emerged as a promising avenue to enable scalable
training of GNNs by compressing the training dataset while preserving essential
graph characteristics. Our study uncovers significant shortcomings in current
graph distillation techniques. First, the majority of the algorithms
paradoxically require training on the full dataset to perform distillation.
Second, due to their gradient-emulating approach, these methods require fresh
distillation for any change in hyperparameters or GNN architecture, limiting
their flexibility and reusability. Finally, they fail to achieve substantial
size reduction due to synthesizing fully-connected, edge-weighted graphs. To
address these challenges, we present Bonsai, a novel graph distillation method
empowered by the observation that \textit{computation trees} form the
fundamental processing units of message-passing GNNs. Bonsai distills datasets
by encoding a careful selection of \textit{exemplar} trees that maximize the
representation of all computation trees in the training set. This unique
approach imparts Bonsai as the first linear-time, model-agnostic graph
distillation algorithm for node classification that outperforms existing
baselines across $6$ real-world datasets on accuracy, while being $22$ times
faster on average. Bonsai is grounded in rigorous mathematical guarantees on
the adopted approximation strategies making it robust to GNN architectures,
datasets, and parameters.

摘要：圖形萃取已成為一種有前途的途徑，可透過壓縮訓練資料集同時保留必要的圖形特徵，來啟用 GNN 的可擴充訓練。我們的研究揭露了現有圖形萃取技術中的重大缺點。首先，大多數演算法矛盾地需要在完整資料集上進行訓練，才能執行萃取。其次，由於其梯度模擬方法，這些方法需要針對超參數或 GNN 架構的任何變更進行新的萃取，限制了其彈性和可重複使用性。最後，由於合成完全連接的邊加權圖形，它們無法達成顯著的尺寸縮減。為了應對這些挑戰，我們提出了 Bonsai，這是一種新穎的圖形萃取方法，由以下觀察結果強化：\textit{計算樹} 構成了訊息傳遞 GNN 的基本處理單元。Bonsai 透過編碼仔細挑選的\textit{範例}樹來萃取資料集，這些樹能最大化訓練集中所有計算樹的表示。這種獨特的方法讓 Bonsai 成為第一個線性時間、與模型無關的節點分類圖形萃取演算法，在準確度方面優於 $6$ 個真實世界資料集中的現有基準，同時平均速度快 $22$ 倍。Bonsai 以嚴謹的數學保證為基礎，針對所採用的近似策略，使其對 GNN 架構、資料集和參數具有穩健性。

##### **MM-Eval: A Multilingual Meta-Evaluation Benchmark for LLM-as-a-Judge and Reward Models**
2410.17578v1 by Guijin Son, Dongkeun Yoon, Juyoung Suk, Javier Aula-Blasco, Mano Aslan, Vu Trong Kim, Shayekh Bin Islam, Jaume Prats-Cristià, Lucía Tormo-Bañuelos, Seungone Kim

Large language models (LLMs) are commonly used as evaluators in tasks (e.g.,
reward modeling, LLM-as-a-judge), where they act as proxies for human
preferences or judgments. This leads to the need for meta-evaluation:
evaluating the credibility of LLMs as evaluators. However, existing benchmarks
primarily focus on English, offering limited insight into LLMs' effectiveness
as evaluators in non-English contexts. To address this, we introduce MM-Eval, a
multilingual meta-evaluation benchmark that covers 18 languages across six
categories. MM-Eval evaluates various dimensions, including language-specific
challenges like linguistics and language hallucinations. Evaluation results
show that both proprietary and open-source language models have considerable
room for improvement. Further analysis reveals a tendency for these models to
assign middle-ground scores to low-resource languages. We publicly release our
benchmark and code.

摘要：大型語言模型 (LLM) 通常用作任務中的評估器 (例如，獎勵建模，LLM 作為評審)，它們作為人類偏好或判斷的代理。這導致需要進行元評估：評估 LLM 作為評估器的可信度。然而，現有的基準主要關注英語，對 LLM 在非英語語境中作為評估器的有效性提供的見解有限。為了解決此問題，我們引入了 MM-Eval，這是一個多語言元評估基準，涵蓋六大類別中的 18 種語言。MM-Eval 評估各種面向，包括語言特定的挑戰，例如語言學和語言幻覺。評估結果表明，專有語言模型和開源語言模型都有很大的改進空間。進一步的分析表明，這些模型傾向於將中間分數分配給低資源語言。我們公開發布我們的基準和程式碼。

##### **Differentially Private Learning Needs Better Model Initialization and Self-Distillation**
2410.17566v1 by Ivoline C. Ngong, Joseph P. Near, Niloofar Mireshghallah

Differentially private SGD (DPSGD) enables privacy-preserving training of
language models, but often reduces utility, diversity, and linguistic quality.
We introduce DPRefine, a three-phase method that initializes a model using data
synthesis from a small pre-trained LM with rigorous filtering, applies DP
finetuning on private data, and performs self-distillation to refine outputs.
This approach significantly outperforms vanilla DPSGD, with AlpacaEval
preferring DPRefine's generations in 78.4% of cases across all datasets. Our
analysis reveals that DPRefine reduces linguistic errors in generated text by
84.0%, mitigating grammar and spelling errors, commonly associated with DPSGD.
It also reduces inconsistencies of non-private models, such as hallucinated
details and misattributed quotes. We find that small models like GPT-2 can be
effective for initialization and distillation, highlighting their potential in
enabling scalable and efficient deployment of privacy-preserving language.

摘要：差分私有 SGD（DPSGD）可實現語言模型的隱私保護訓練，但通常會降低效用、多樣性和語言品質。
我們引入了 DPRefine，這是一種三階段方法，它使用經過嚴格過濾的小型預訓練 LM 的資料合成來初始化模型，對私有資料應用 DP 微調，並執行自我蒸餾以改善輸出。
這種方法明顯優於香草 DPSGD，在所有資料集中的 78.4% 的案例中，AlpacaEval 偏好 DPRefine 的生成。我們的分析表明，DPRefine 將生成文字中的語言錯誤減少了 84.0%，減輕了語法和拼寫錯誤，這些錯誤通常與 DPSGD 相關。
它還減少了非私有模型的不一致性，例如幻覺細節和錯誤歸因的引號。我們發現像 GPT-2 這樣的小模型可以有效用於初始化和蒸餾，突出了它們在實現隱私保護語言的可擴充且有效部署方面的潛力。

##### **CLR-Bench: Evaluating Large Language Models in College-level Reasoning**
2410.17558v1 by Junnan Dong, Zijin Hong, Yuanchen Bei, Feiran Huang, Xinrun Wang, Xiao Huang

Large language models (LLMs) have demonstrated their remarkable performance
across various language understanding tasks. While emerging benchmarks have
been proposed to evaluate LLMs in various domains such as mathematics and
computer science, they merely measure the accuracy in terms of the final
prediction on multi-choice questions. However, it remains insufficient to
verify the essential understanding of LLMs given a chosen choice. To fill this
gap, we present CLR-Bench to comprehensively evaluate the LLMs in complex
college-level reasoning. Specifically, (i) we prioritize 16 challenging college
disciplines in computer science and artificial intelligence. The dataset
contains 5 types of questions, while each question is associated with detailed
explanations from experts. (ii) To quantify a fair evaluation of LLMs'
reasoning ability, we formalize the criteria with two novel metrics.
Q$\rightarrow$A is utilized to measure the performance of direct answer
prediction, and Q$\rightarrow$AR effectively considers the joint ability to
answer the question and provide rationale simultaneously. Extensive experiments
are conducted with 40 LLMs over 1,018 discipline-specific questions. The
results demonstrate the key insights that LLMs, even the best closed-source
LLM, i.e., GPT-4 turbo, tend to `guess' the college-level answers. It shows a
dramatic decrease in accuracy from 63.31% Q$\rightarrow$A to 39.00%
Q$\rightarrow$AR, indicating an unsatisfactory reasoning ability.

摘要：大型語言模型 (LLM) 已展現其在各種語言理解任務中的傑出表現。雖然已提出新興基準來評估 LLM 在數學和電腦科學等不同領域中的表現，但這些基準僅就多選題的最終預測測量準確性。然而，對於 LLM 在選擇選項後的基本理解，仍不足以驗證。為了填補這個空白，我們提出 CLR-Bench 來全面評估 LLM 在複雜的大專程度推理中的表現。具體來說，（一）我們優先考慮電腦科學和人工智慧中的 16 個具有挑戰性的大學科系。該資料集包含 5 種類型的問題，而每個問題都附有專家的詳細說明。（二）為了量化 LLM 推理能力的公平評估，我們以兩個新穎的指標形式化標準。Q→A 用於測量直接答案預測的表現，而 Q→AR 有效地考慮了同時回答問題和提供理由的綜合能力。我們針對 40 個 LLM 進行了超過 1,018 個特定領域問題的廣泛實驗。結果證明了關鍵見解，即 LLM，甚至是最好的閉源 LLM，即 GPT-4 turbo，都傾向於「猜測」大學程度的答案。它顯示準確度從 63.31% Q→A 大幅下降至 39.00% Q→AR，這表示推理能力不令人滿意。

##### **FairDgcl: Fairness-aware Recommendation with Dynamic Graph Contrastive Learning**
2410.17555v1 by Wei Chen, Meng Yuan, Zhao Zhang, Ruobing Xie, Fuzhen Zhuang, Deqing Wang, Rui Liu

As trustworthy AI continues to advance, the fairness issue in recommendations
has received increasing attention. A recommender system is considered unfair
when it produces unequal outcomes for different user groups based on
user-sensitive attributes (e.g., age, gender). Some researchers have proposed
data augmentation-based methods aiming at alleviating user-level unfairness by
altering the skewed distribution of training data among various user groups.
Despite yielding promising results, they often rely on fairness-related
assumptions that may not align with reality, potentially reducing the data
quality and negatively affecting model effectiveness. To tackle this issue, in
this paper, we study how to implement high-quality data augmentation to improve
recommendation fairness. Specifically, we propose FairDgcl, a dynamic graph
adversarial contrastive learning framework aiming at improving fairness in
recommender system. First, FairDgcl develops an adversarial contrastive network
with a view generator and a view discriminator to learn generating fair
augmentation strategies in an adversarial style. Then, we propose two dynamic,
learnable models to generate contrastive views within contrastive learning
framework, which automatically fine-tune the augmentation strategies.
Meanwhile, we theoretically show that FairDgcl can simultaneously generate
enhanced representations that possess both fairness and accuracy. Lastly,
comprehensive experiments conducted on four real-world datasets demonstrate the
effectiveness of the proposed FairDgcl.

摘要：隨著值得信賴的人工智慧持續進步，推薦的公平性問題
越來越受到關注。推薦系統被認為是不公平的
當它根據
用戶敏感屬性（例如年齡、性別）為不同的用戶群體產生不平等的結果時。一些研究人員提出
基於數據增強的方法旨在通過
改變不同用戶組之間訓練數據的偏態分佈來緩解用戶級別的不公平性。
儘管產生了有希望的結果，但他們通常依賴於可能與現實不符的與公平性相關的
假設，可能會降低數據
質量並對模型有效性產生負面影響。為了解決這個問題，在
本文中，我們研究如何實施高質量的數據增強以提高
推薦公平性。具體來說，我們提出了 FairDgcl，一個動態圖形
對抗對比學習框架，旨在提高公平性
推薦系統。首先，FairDgcl 開發了一個對抗對比網絡
使用視圖生成器和視圖判別器以對抗方式學習生成公平
增強策略。然後，我們提出了兩個動態的，
可學習模型在對比學習
框架內生成對比視圖，這會自動微調增強策略。
同時，我們在理論上表明 FairDgcl 可以同時生成
增強表示，既具有公平性又具有準確性。最後，
在四個真實世界數據集上進行的綜合實驗證明了
提出的 FairDgcl 的有效性。

##### **ESpeW: Robust Copyright Protection for LLM-based EaaS via Embedding-Specific Watermark**
2410.17552v1 by Zongqi Wang, Baoyuan Wu, Jingyuan Deng, Yujiu Yang

Embeddings as a Service (EaaS) is emerging as a crucial role in AI
applications. Unfortunately, EaaS is vulnerable to model extraction attacks,
highlighting the urgent need for copyright protection.Although some preliminary
works propose applying embedding watermarks to protect EaaS, recent research
reveals that these watermarks can be easily removed. Hence, it is crucial to
inject robust watermarks resistant to watermark removal attacks.Existing
watermarking methods typically inject a target embedding into embeddings
through linear interpolation when the text contains triggers. However, this
mechanism results in each watermarked embedding having the same component,
which makes the watermark easy to identify and eliminate.Motivated by this, in
this paper, we propose a novel embedding-specific watermarking (ESpeW)
mechanism to offer robust copyright protection for EaaS. Our approach involves
injecting unique, yet readily identifiable watermarks into each embedding.
Watermarks inserted by ESpeW are designed to maintain a significant distance
from one another and to avoid sharing common components, thus making it
significantly more challenging to remove the watermarks.Extensive experiments
on four popular datasets demonstrate that ESpeW can even watermark successfully
against a highly aggressive removal strategy without sacrificing the quality of
embeddings.

摘要：嵌入式服務（EaaS）正成為 AI 應用中至關重要的角色。不幸的是，EaaS 容易受到模型提取攻擊，這突顯了對版權保護的迫切需求。儘管一些初步工作提出應用嵌入式水印來保護 EaaS，但最近的研究表明這些水印很容易被移除。因此，注入對水印移除攻擊具有抵抗力的強健水印至關重要。現有的水印方法通常在文本包含觸發器時，透過線性插值將目標嵌入注入到嵌入中。然而，此機制導致每個帶有水印的嵌入具有相同的組成部分，這使得水印容易被辨識和消除。受此啟發，在本文中，我們提出了一種新穎的嵌入特定水印（ESpeW）機制，以提供 EaaS 的強健版權保護。我們的做法涉及將獨特但容易識別的水印注入到每個嵌入中。由 ESpeW 插入的水印被設計為彼此保持顯著距離，並避免共用組成部分，從而顯著增加移除水印的難度。在四個熱門資料集上進行的廣泛實驗表明，ESpeW 甚至可以在不犧牲嵌入品質的情況下，針對高度激進的移除策略成功進行水印。

##### **ProtoLens: Advancing Prototype Learning for Fine-Grained Interpretability in Text Classification**
2410.17546v1 by Bowen Wei, Ziwei Zhu

Deep neural networks have achieved remarkable performance in various
text-based tasks but often lack interpretability, making them less suitable for
applications where transparency is critical. To address this, we propose
ProtoLens, a novel prototype-based model that provides fine-grained,
sub-sentence level interpretability for text classification. ProtoLens uses a
Prototype-aware Span Extraction module to identify relevant text spans
associated with learned prototypes and a Prototype Alignment mechanism to
ensure prototypes are semantically meaningful throughout training. By aligning
the prototype embeddings with human-understandable examples, ProtoLens provides
interpretable predictions while maintaining competitive accuracy. Extensive
experiments demonstrate that ProtoLens outperforms both prototype-based and
non-interpretable baselines on multiple text classification benchmarks. Code
and data are available at
\url{https://anonymous.4open.science/r/ProtoLens-CE0B/}.

摘要：深度神经網路在各種基於文字的任務中都取得了顯著的表現，但通常缺乏可解釋性，這使得它們不太適合於透明度至關重要的應用。為了解決這個問題，我們提出了 ProtoLens，這是一個新穎的基於原型的模型，它為文字分類提供了細粒度的子句級可解釋性。ProtoLens 使用一個原型感知跨度提取模組來識別與學習原型相關的相關文字跨度，並使用一個原型對齊機制來確保原型在整個訓練過程中具有語義意義。通過將原型嵌入與人類可理解的範例對齊，ProtoLens 提供了可解釋的預測，同時保持了競爭優勢的準確性。大量的實驗表明，ProtoLens 在多個文字分類基準上優於基於原型和不可解釋的基準線。程式碼和資料可於
\url{https://anonymous.4open.science/r/ProtoLens-CE0B/} 取得。

##### **Responsible Multilingual Large Language Models: A Survey of Development, Applications, and Societal Impact**
2410.17532v1 by Junhua Liu, Bin Fu

Multilingual Large Language Models (MLLMs) represent a pivotal advancement in
democratizing artificial intelligence across linguistic boundaries. While
theoretical foundations are well-established, practical implementation
guidelines remain scattered. This work bridges this gap by providing a
comprehensive end-to-end framework for developing and deploying MLLMs in
production environments. We make three distinctive contributions: First, we
present an actionable pipeline from data pre-processing through deployment,
integrating insights from academic research and industrial applications.
Second, using Llama2 as a case study, we provide detailed optimization
strategies for enhancing multilingual capabilities, including curriculum
learning approaches for balancing high-resource and low-resource languages,
tokenization strategies, and effective sampling methods. Third, we offer an
interdisciplinary analysis that considers technical, linguistic, and cultural
perspectives in MLLM development. Our findings reveal critical challenges in
supporting linguistic diversity, with 88.38% of world languages categorized as
low-resource, affecting over a billion speakers. We examine practical solutions
through real-world applications in customer service, search engines, and
machine translation. By synthesizing theoretical frameworks with
production-ready implementation strategies, this survey provides essential
guidance for practitioners and researchers working to develop more inclusive
and effective multilingual AI systems.

摘要：多語言大型語言模型 (MLLM) 代表著跨語言界限民主化人工智能的關鍵進展。雖然理論基礎已經確立，但實際執行的準則仍然分散。本研究透過提供一個全面的端對端架構，用於在生產環境中開發和部署 MLLM，來彌合這個鴻溝。我們做出了三個獨特的貢獻：首先，我們提出一個可操作的管道，從資料前處理到部署，整合了學術研究和產業應用的見解。其次，使用 Llama2 作為案例研究，我們提供了詳細的最佳化策略，用於增強多語言能力，包括平衡高資源和低資源語言的課程學習方法、標記化策略和有效的抽樣方法。第三，我們提供了一個跨領域的分析，考量了 MLLM 開發中的技術、語言和文化觀點。我們的研究結果揭示了在支援語言多樣性方面面臨的嚴峻挑戰，其中 88.38% 的世界語言被歸類為低資源語言，影響超過十億的使用者。我們透過在客戶服務、搜尋引擎和機器翻譯中的實際應用，探討了實用的解決方案。透過將理論架構與可生產執行的策略綜合起來，這項調查為從事開發更具包容性和有效性的多語言 AI 系統的從業人員和研究人員提供了必要的指導。

##### **Navigate Complex Physical Worlds via Geometrically Constrained LLM**
2410.17529v1 by Yongqiang Huang, Wentao Ye, Liyao Li, Junbo Zhao

This study investigates the potential of Large Language Models (LLMs) for
reconstructing and constructing the physical world solely based on textual
knowledge. It explores the impact of model performance on spatial understanding
abilities. To enhance the comprehension of geometric and spatial relationships
in the complex physical world, the study introduces a set of geometric
conventions and develops a workflow based on multi-layer graphs and multi-agent
system frameworks. It examines how LLMs achieve multi-step and multi-objective
geometric inference in a spatial environment using multi-layer graphs under
unified geometric conventions. Additionally, the study employs a genetic
algorithm, inspired by large-scale model knowledge, to solve geometric
constraint problems. In summary, this work innovatively explores the
feasibility of using text-based LLMs as physical world builders and designs a
workflow to enhance their capabilities.

摘要：本研究探討大型語言模型 (LLM) 僅基於文字知識重建和建構物理世界的潛力。探討模型效能對空間理解能力的影響。為了增強對複雜物理世界中幾何和空間關係的理解，本研究引入了一組幾何慣例，並基於多層圖形和多代理系統架構開發了一套工作流程。研究探討了 LLM 如何在統一的幾何慣例下，使用多層圖形在空間環境中達成多步驟和多目標的幾何推論。此外，本研究採用受大型模型知識啟發的遺傳演算法來解決幾何約束問題。總之，這項工作創新地探討了使用基於文字的 LLM 作為物理世界建構者的可行性，並設計了一套工作流程來增強其能力。

##### **MobileSafetyBench: Evaluating Safety of Autonomous Agents in Mobile Device Control**
2410.17520v1 by Juyong Lee, Dongyoon Hahm, June Suk Choi, W. Bradley Knox, Kimin Lee

Autonomous agents powered by large language models (LLMs) show promising
potential in assistive tasks across various domains, including mobile device
control. As these agents interact directly with personal information and device
settings, ensuring their safe and reliable behavior is crucial to prevent
undesirable outcomes. However, no benchmark exists for standardized evaluation
of the safety of mobile device-control agents. In this work, we introduce
MobileSafetyBench, a benchmark designed to evaluate the safety of
device-control agents within a realistic mobile environment based on Android
emulators. We develop a diverse set of tasks involving interactions with
various mobile applications, including messaging and banking applications. To
clearly evaluate safety apart from general capabilities, we design separate
tasks measuring safety and tasks evaluating helpfulness. The safety tasks
challenge agents with managing potential risks prevalent in daily life and
include tests to evaluate robustness against indirect prompt injections. Our
experiments demonstrate that while baseline agents, based on state-of-the-art
LLMs, perform well in executing helpful tasks, they show poor performance in
safety tasks. To mitigate these safety concerns, we propose a prompting method
that encourages agents to prioritize safety considerations. While this method
shows promise in promoting safer behaviors, there is still considerable room
for improvement to fully earn user trust. This highlights the urgent need for
continued research to develop more robust safety mechanisms in mobile
environments. We open-source our benchmark at:
https://mobilesafetybench.github.io/.

摘要：<paragraph>由大型語言模型 (LLM) 驅動的自主代理在各種領域（包括行動裝置控制）的輔助任務中展現出有前景的潛力。由於這些代理會直接與個人資訊和裝置設定互動，確保其安全和可靠的行為對於預防不良結果至關重要。然而，目前並不存在用於標準化評估行動裝置控制代理安全性的基準。在這項工作中，我們引入了 MobileSafetyBench，這是一個基準，旨在評估裝置控制代理在基於 Android 模擬器的逼真行動環境中的安全性。我們開發了一組多樣化的任務，涉及與各種行動應用程式的互動，包括訊息和銀行應用程式。為了清楚地區分安全性與一般能力，我們設計了衡量安全性以及評估有益性的獨立任務。安全性任務挑戰代理管理日常生活中普遍存在的潛在風險，並包含測試以評估對間接提示注入的穩健性。我們的實驗表明，雖然基於最先進 LLM 的基準代理在執行有益任務時表現良好，但它們在安全性任務中的表現卻很差。為了減輕這些安全疑慮，我們提出了一種提示方法，鼓勵代理優先考慮安全考量。雖然這種方法在促進更安全的行為方面顯示出前景，但仍有很大的改進空間，才能完全贏得使用者的信任。這凸顯了持續研究的迫切需求，以開發行動環境中更穩健的安全機制。我們在以下位置開放原始碼基準：https://mobilesafetybench.github.io/。</paragraph>

##### **Large Language Models Still Exhibit Bias in Long Text**
2410.17519v1 by Wonje Jeung, Dongjae Jeon, Ashkan Yousefpour, Jonghyun Choi

Existing fairness benchmarks for large language models (LLMs) primarily focus
on simple tasks, such as multiple-choice questions, overlooking biases that may
arise in more complex scenarios like long-text generation. To address this gap,
we introduce the Long Text Fairness Test (LTF-TEST), a framework that evaluates
biases in LLMs through essay-style prompts. LTF-TEST covers 14 topics and 10
demographic axes, including gender and race, resulting in 11,948 samples. By
assessing both model responses and the reasoning behind them, LTF-TEST uncovers
subtle biases that are difficult to detect in simple responses. In our
evaluation of five recent LLMs, including GPT-4o and LLaMa3, we identify two
key patterns of bias. First, these models frequently favor certain demographic
groups in their responses. Second, they show excessive sensitivity toward
traditionally disadvantaged groups, often providing overly protective responses
while neglecting others. To mitigate these biases, we propose FT-REGARD, a
finetuning approach that pairs biased prompts with neutral responses. FT-REGARD
reduces gender bias by 34.6% and improves performance by 1.4 percentage points
on the BBQ benchmark, offering a promising approach to addressing biases in
long-text generation tasks.

摘要：現有大型語言模型 (LLM) 的公平性基準主要關注於簡單的任務，例如選擇題，而忽略了在長文本生成等更複雜的場景中可能出現的偏見。為了解決這個差距，我們引入了長文本公平性測試 (LTF-TEST)，一個通過論文式提示評估 LLM 中偏見的框架。LTF-TEST 涵蓋 14 個主題和 10 個人口統計軸，包括性別和種族，產生 11,948 個樣本。通過評估模型的回應及其背後的推理，LTF-TEST 揭示了難以在簡單的回應中檢測到的微妙偏見。在我們對包括 GPT-4o 和 LLaMa3 在內的五個最新 LLM 的評估中，我們確定了兩種關鍵的偏見模式。首先，這些模型經常在其回應中偏愛某些人口統計群體。其次，它們對傳統上處於弱勢群體表現出過度的敏感性，經常提供過度保護性的回應，而忽視其他群體。為了減輕這些偏見，我們提出了 FT-REGARD，一種將有偏見的提示與中立回應配對的微調方法。FT-REGARD 將性別偏見降低了 34.6%，並在 BBQ 基準上將性能提高了 1.4 個百分點，為解決長文本生成任務中的偏見提供了一個有前景的方法。

##### **Congestion Forecast for Trains with Railroad-Graph-based Semi-Supervised Learning using Sparse Passenger Reports**
2410.17510v1 by Soto Anno, Kota Tsubouchi, Masamichi Shimosaka

Forecasting rail congestion is crucial for efficient mobility in transport
systems. We present rail congestion forecasting using reports from passengers
collected through a transit application. Although reports from passengers have
received attention from researchers, ensuring a sufficient volume of reports is
challenging due to passenger's reluctance. The limited number of reports
results in the sparsity of the congestion label, which can be an issue in
building a stable prediction model. To address this issue, we propose a
semi-supervised method for congestion forecasting for trains, or SURCONFORT.
Our key idea is twofold: firstly, we adopt semi-supervised learning to leverage
sparsely labeled data and many unlabeled data. Secondly, in order to complement
the unlabeled data from nearby stations, we design a railway network-oriented
graph and apply the graph to semi-supervised graph regularization. Empirical
experiments with actual reporting data show that SURCONFORT improved the
forecasting performance by 14.9% over state-of-the-art methods under the label
sparsity.

摘要：預測鐵路壅塞對於運輸系統中的有效移動至關重要。我們提出使用透過運輸應用程式收集的乘客報告來預測鐵路壅塞。儘管乘客報告已受到研究人員的關注，但由於乘客的不願意，確保有足夠數量的報告具有挑戰性。報告數量有限導致壅塞標籤稀疏，這可能是建立穩定預測模型的問題。為了解決此問題，我們提出了一種半監督式方法來預測火車壅塞，稱為 SURCONFORT。我們的關鍵思想有兩個方面：首先，我們採用半監督式學習來利用稀疏標籤資料和許多未標籤資料。其次，為了補充來自附近車站的未標籤資料，我們設計了一個以鐵路網路為導向的圖形，並將圖形應用於半監督式圖形正則化。使用實際報告資料進行的實證實驗表明，在標籤稀疏的情況下，SURCONFORT 將預測效能提升了 14.9%，優於最先進的方法。

##### **Mitigating Graph Covariate Shift via Score-based Out-of-distribution Augmentation**
2410.17506v1 by Bohan Wang, Yurui Chang, Lu Lin

Distribution shifts between training and testing datasets significantly
impair the model performance on graph learning. A commonly-taken causal view in
graph invariant learning suggests that stable predictive features of graphs are
causally associated with labels, whereas varying environmental features lead to
distribution shifts. In particular, covariate shifts caused by unseen
environments in test graphs underscore the critical need for
out-of-distribution (OOD) generalization. Existing graph augmentation methods
designed to address the covariate shift often disentangle the stable and
environmental features in the input space, and selectively perturb or mixup the
environmental features. However, such perturbation-based methods heavily rely
on an accurate separation of stable and environmental features, and their
exploration ability is confined to existing environmental features in the
training distribution. To overcome these limitations, we introduce a novel
approach using score-based graph generation strategies that synthesize unseen
environmental features while preserving the validity and stable features of
overall graph patterns. Our comprehensive empirical evaluations demonstrate the
enhanced effectiveness of our method in improving graph OOD generalization.

摘要：訓練和測試資料集之間的分佈轉移，會嚴重損害圖形學習中的模型效能。圖形不變學習中常見的因果觀點表明，圖形穩定的預測特徵與標籤有因果關係，而變化的環境特徵則導致分佈轉移。特別是，測試圖形中未見環境導致的協變數轉移，強調了對分佈外 (OOD) 泛化的關鍵需求。現有的圖形擴充方法旨在解決協變數轉移，通常會解開輸入空間中穩定的和環境特徵，並選擇性地擾動或混合環境特徵。然而，這種基於擾動的方法嚴重依賴於穩定和環境特徵的準確分離，而且它們的探索能力僅限於訓練分佈中現有的環境特徵。為了克服這些限制，我們引入了一種使用基於分數的圖形生成策略的新方法，該策略在保留整體圖形模式的有效性和穩定特徵的同時，合成未見的環境特徵。我們全面的經驗評估證明了我們的方法在改善圖形 OOD 泛化方面的增強效能。

##### **An Ontology-Enabled Approach For User-Centered and Knowledge-Enabled Explanations of AI Systems**
2410.17504v1 by Shruthi Chari

Explainable Artificial Intelligence (AI) focuses on helping humans understand
the working of AI systems or their decisions and has been a cornerstone of AI
for decades. Recent research in explainability has focused on explaining the
workings of AI models or model explainability. There have also been several
position statements and review papers detailing the needs of end-users for
user-centered explainability but fewer implementations. Hence, this thesis
seeks to bridge some gaps between model and user-centered explainability. We
create an explanation ontology (EO) to represent literature-derived explanation
types via their supporting components. We implement a knowledge-augmented
question-answering (QA) pipeline to support contextual explanations in a
clinical setting. Finally, we are implementing a system to combine explanations
from different AI methods and data modalities. Within the EO, we can represent
fifteen different explanation types, and we have tested these representations
in six exemplar use cases. We find that knowledge augmentations improve the
performance of base large language models in the contextualized QA, and the
performance is variable across disease groups. In the same setting, clinicians
also indicated that they prefer to see actionability as one of the main foci in
explanations. In our explanations combination method, we plan to use similarity
metrics to determine the similarity of explanations in a chronic disease
detection setting. Overall, through this thesis, we design methods that can
support knowledge-enabled explanations across different use cases, accounting
for the methods in today's AI era that can generate the supporting components
of these explanations and domain knowledge sources that can enhance them.

摘要：可解釋人工智慧（AI）專注於協助人類了解 AI 系統運作或其決策，數十年來一直是 AI 的基石。最近的可解釋性研究專注於解釋 AI 模型或模型可解釋性的運作。也有幾份立場聲明和評論論文詳細說明了最終使用者對以使用者為中心的可解釋性的需求，但實作較少。因此，本論文旨在彌補模型和以使用者為中心的可解釋性之間的一些差距。我們建立一個解釋本體（EO）以透過其支援元件來表示從文獻中衍生的解釋類型。我們實作一個知識增強的問答（QA）管線，以在臨床環境中支援情境解釋。最後，我們正在實作一個系統，以結合來自不同 AI 方法和資料模式的解釋。在 EO 中，我們可以表示 15 種不同的解釋類型，並且我們已在六個範例使用案例中測試這些表示。我們發現，知識增強改善了基礎大型語言模型在情境化 QA 中的效能，並且效能因疾病群組而異。在相同的環境中，臨床醫生也表示他們希望將可操作性視為解釋中的主要焦點之一。在我們的解釋組合方法中，我們計畫使用相似性指標來確定慢性病偵測環境中解釋的相似性。總體而言，透過本論文，我們設計了可以在不同使用案例中支援知識啟用解釋的方法，考量到當今 AI 時代中可以產生這些解釋的支援元件和可以增強這些解釋的領域知識來源的方法。

##### **Mechanisms of Symbol Processing for In-Context Learning in Transformer Networks**
2410.17498v1 by Paul Smolensky, Roland Fernandez, Zhenghao Herbert Zhou, Mattia Opper, Jianfeng Gao

Large Language Models (LLMs) have demonstrated impressive abilities in symbol
processing through in-context learning (ICL). This success flies in the face of
decades of predictions that artificial neural networks cannot master abstract
symbol manipulation. We seek to understand the mechanisms that can enable
robust symbol processing in transformer networks, illuminating both the
unanticipated success, and the significant limitations, of transformers in
symbol processing. Borrowing insights from symbolic AI on the power of
Production System architectures, we develop a high-level language, PSL, that
allows us to write symbolic programs to do complex, abstract symbol processing,
and create compilers that precisely implement PSL programs in transformer
networks which are, by construction, 100% mechanistically interpretable. We
demonstrate that PSL is Turing Universal, so the work can inform the
understanding of transformer ICL in general. The type of transformer
architecture that we compile from PSL programs suggests a number of paths for
enhancing transformers' capabilities at symbol processing. (Note: The first
section of the paper gives an extended synopsis of the entire paper.)

摘要：大型語言模型 (LLM) 已透過情境學習 (ICL) 展示出令人印象深刻的符號處理能力。這項成功與數十年來預測人工神經網路無法掌握抽象符號操作的說法背道而馳。我們試圖了解能夠讓Transformer網路進行穩健符號處理的機制，同時說明Transformer在符號處理方面意料之外的成功和顯著限制。我們從符號 AI 借用生產系統架構的力量，開發出一種高級語言 PSL，它讓我們能夠撰寫符號程式來進行複雜的抽象符號處理，並建立精確實作Transformer網路中 PSL 程式的編譯器，這些編譯器在建構上 100% 可以機械式地解釋。我們證明了 PSL 是圖靈通用的，因此這項工作可以說明對Transformer ICL 的一般理解。我們從 PSL 程式編譯而來的Transformer架構類型，建議了一些增強Transformer符號處理功能的路徑。（註：本文的第一部分提供了整篇論文的延伸摘要。）

##### **BadFair: Backdoored Fairness Attacks with Group-conditioned Triggers**
2410.17492v1 by Jiaqi Xue, Qian Lou, Mengxin Zheng

Attacking fairness is crucial because compromised models can introduce biased
outcomes, undermining trust and amplifying inequalities in sensitive
applications like hiring, healthcare, and law enforcement. This highlights the
urgent need to understand how fairness mechanisms can be exploited and to
develop defenses that ensure both fairness and robustness. We introduce
BadFair, a novel backdoored fairness attack methodology. BadFair stealthily
crafts a model that operates with accuracy and fairness under regular
conditions but, when activated by certain triggers, discriminates and produces
incorrect results for specific groups. This type of attack is particularly
stealthy and dangerous, as it circumvents existing fairness detection methods,
maintaining an appearance of fairness in normal use. Our findings reveal that
BadFair achieves a more than 85% attack success rate in attacks aimed at target
groups on average while only incurring a minimal accuracy loss. Moreover, it
consistently exhibits a significant discrimination score, distinguishing
between pre-defined target and non-target attacked groups across various
datasets and models.

摘要：攻擊公平性至關重要，因為受損的模型會引入有偏差的結果，破壞信任並擴大招聘、醫療保健和執法等敏感應用中的不平等。這突顯了迫切需要了解公平性機制如何被利用，並開發確保公平性和穩健性的防禦措施。我們介紹 BadFair，一種新穎的後門公平性攻擊方法。BadFair 隱密地製作了一個模型，在正常條件下以準確性和公平性運作，但當被某些觸發器激活時，會歧視並對特定群體產生不正確的結果。這種攻擊特別隱蔽且危險，因為它規避了現有的公平性檢測方法，在正常使用中保持公平性的表象。我們的研究結果顯示，BadFair 在針對目標群組的攻擊中平均達到 85% 以上的攻擊成功率，同時僅造成最小的準確度損失。此外，它始終表現出顯著的歧視分數，區分了各種資料集和模型中的預定義目標和非目標攻擊群組。

##### **Unsupervised Domain Adaptation for Action Recognition via Self-Ensembling and Conditional Embedding Alignment**
2410.17489v1 by Indrajeet Ghosh, Garvit Chugh, Abu Zaher Md Faridee, Nirmalya Roy

Recent advancements in deep learning-based wearable human action recognition
(wHAR) have improved the capture and classification of complex motions, but
adoption remains limited due to the lack of expert annotations and domain
discrepancies from user variations. Limited annotations hinder the model's
ability to generalize to out-of-distribution samples. While data augmentation
can improve generalizability, unsupervised augmentation techniques must be
applied carefully to avoid introducing noise. Unsupervised domain adaptation
(UDA) addresses domain discrepancies by aligning conditional distributions with
labeled target samples, but vanilla pseudo-labeling can lead to error
propagation. To address these challenges, we propose $\mu$DAR, a novel joint
optimization architecture comprised of three functions: (i) consistency
regularizer between augmented samples to improve model classification
generalizability, (ii) temporal ensemble for robust pseudo-label generation and
(iii) conditional distribution alignment to improve domain generalizability.
The temporal ensemble works by aggregating predictions from past epochs to
smooth out noisy pseudo-label predictions, which are then used in the
conditional distribution alignment module to minimize kernel-based class-wise
conditional maximum mean discrepancy ($k$CMMD) between the source and target
feature space to learn a domain invariant embedding. The
consistency-regularized augmentations ensure that multiple augmentations of the
same sample share the same labels; this results in (a) strong generalization
with limited source domain samples and (b) consistent pseudo-label generation
in target samples. The novel integration of these three modules in $\mu$DAR
results in a range of $\approx$ 4-12% average macro-F1 score improvement over
six state-of-the-art UDA methods in four benchmark wHAR datasets

摘要：<paragraph>基於深度學習的可穿戴人類動作辨識 (wHAR) 近期進展改善了複雜動作的捕捉和分類，但由於缺乏專家註解和使用者變異的領域差異，採用率仍然有限。有限的註解阻礙了模型對分佈外樣本的泛化能力。雖然資料擴充可以改善泛化能力，但必須小心應用非監督擴充技術，以避免引入雜訊。非監督領域適應 (UDA) 透過將條件分佈與標籤目標樣本對齊來解決領域差異，但香草偽標籤可能會導致錯誤傳播。為了應對這些挑戰，我們提出了 $\mu$DAR，這是一種由三個函數組成的全新聯合最佳化架構：(i) 擴充樣本之間的一致性正則化器，以改善模型分類的泛化能力，(ii) 時間整體用於強健的偽標籤產生，以及 (iii) 條件分佈對齊，以改善領域泛化能力。時間整體透過彙總過去各個時期的預測來平滑有雜訊的偽標籤預測，然後在條件分佈對齊模組中使用這些預測，以最小化來源和目標特徵空間之間基於核的類別條件最大平均差異 ($k$CMMD)，以學習領域不變嵌入。一致性正則化的擴充確保同一個樣本的多次擴充共享相同的標籤；這會導致 (a) 在來源領域樣本有限的情況下強大的泛化能力，以及 (b) 在目標樣本中一致的偽標籤產生。$\mu$DAR 中這三個模組的新穎整合，導致在四個基準 wHAR 資料集中，六種最先進的 UDA 方法的平均巨觀 F1 分數提高了大約 4-12%</paragraph>

##### **VoiceTextBlender: Augmenting Large Language Models with Speech Capabilities via Single-Stage Joint Speech-Text Supervised Fine-Tuning**
2410.17485v1 by Yifan Peng, Krishna C. Puvvada, Zhehuai Chen, Piotr Zelasko, He Huang, Kunal Dhawan, Ke Hu, Shinji Watanabe, Jagadeesh Balam, Boris Ginsburg

Recent studies have augmented large language models (LLMs) with speech
capabilities, leading to the development of speech language models (SpeechLMs).
Earlier SpeechLMs focused on single-turn speech-based question answering (QA),
where user input comprised a speech context and a text question. More recent
studies have extended this to multi-turn conversations, though they often
require complex, multi-stage supervised fine-tuning (SFT) with diverse data.
Another critical challenge with SpeechLMs is catastrophic forgetting-where
models optimized for speech tasks suffer significant degradation in text-only
performance. To mitigate these issues, we propose a novel single-stage joint
speech-text SFT approach on the low-rank adaptation (LoRA) of the LLM backbone.
Our joint SFT combines text-only SFT data with three types of speech-related
data: speech recognition and translation, speech-based QA, and mixed-modal SFT.
Compared to previous SpeechLMs with 7B or 13B parameters, our 3B model
demonstrates superior performance across various speech benchmarks while
preserving the original capabilities on text-only tasks. Furthermore, our model
shows emergent abilities of effectively handling previously unseen prompts and
tasks, including multi-turn, mixed-modal inputs.

摘要：最近的研究已擴增大型語言模型 (LLM) 的語音能力，進而開發出語音語言模型 (SpeechLM)。
早期的 SpeechLM 專注於單輪次基於語音的問答 (QA)，其中使用者輸入包含語音脈絡和文字問題。最近的研究已將此擴展到多輪次對話，儘管它們通常需要複雜的多階段監督微調 (SFT) 與多樣化的資料。
SpeechLM 的另一個關鍵挑戰是災難性遺忘，其中針對語音任務最佳化的模型在純文字效能上會大幅下降。為了減輕這些問題，我們提出在 LLM 主幹的低秩適應 (LoRA) 上採用新穎的單階段聯合語音文字 SFT 方法。
我們的聯合 SFT 將純文字 SFT 資料與三種類型的語音相關資料結合：語音辨識與翻譯、基於語音的 QA 以及混合模式 SFT。
與先前具有 7B 或 13B 參數的 SpeechLM 相比，我們的 3B 模型在各種語音基準上展現出卓越的效能，同時保留純文字任務的原始功能。此外，我們的模型展現出有效處理先前未見提示和任務的新興能力，包括多輪次、混合模式輸入。

##### **Which Client is Reliable?: A Reliable and Personalized Prompt-based Federated Learning for Medical Image Question Answering**
2410.17484v1 by He Zhu, Ren Togo, Takahiro Ogawa, Miki Haseyama

Conventional medical artificial intelligence (AI) models face barriers in
clinical application and ethical issues owing to their inability to handle the
privacy-sensitive characteristics of medical data. We present a novel
personalized federated learning (pFL) method for medical visual question
answering (VQA) models, addressing privacy reliability challenges in the
medical domain. Our method introduces learnable prompts into a Transformer
architecture to efficiently train it on diverse medical datasets without
massive computational costs. Then we introduce a reliable client VQA model that
incorporates Dempster-Shafer evidence theory to quantify uncertainty in
predictions, enhancing the model's reliability. Furthermore, we propose a novel
inter-client communication mechanism that uses maximum likelihood estimation to
balance accuracy and uncertainty, fostering efficient integration of insights
across clients.

摘要：傳統醫學人工智慧（AI）模型在臨床應用和道德議題上會面臨障礙，因為它們無法處理醫療資料中對隱私敏感的特徵。我們提出了一種新穎的個人化聯邦學習（pFL）方法，用於醫療視覺問答（VQA）模型，以解決醫療領域中的隱私可靠性挑戰。我們的模型方法將可學習提示引入 Transformer 架構中，以在沒有大量運算成本的情況下，有效率地訓練它處理各種醫療資料集。然後我們引入了一個可靠的客戶端 VQA 模型，它結合了 Dempster-Shafer 證據理論來量化預測中的不確定性，進而提升模型的可靠性。此外，我們提出了一個新穎的客戶端間通訊機制，它使用最大似然估計來平衡準確性和不確定性，促進跨客戶端見解的有效整合。

##### **Is artificial intelligence still intelligence? LLMs generalize to novel adjective-noun pairs, but don't mimic the full human distribution**
2410.17482v1 by Hayley Ross, Kathryn Davidson, Najoung Kim

Inferences from adjective-noun combinations like "Is artificial intelligence
still intelligence?" provide a good test bed for LLMs' understanding of meaning
and compositional generalization capability, since there are many combinations
which are novel to both humans and LLMs but nevertheless elicit convergent
human judgments. We study a range of LLMs and find that the largest models we
tested are able to draw human-like inferences when the inference is determined
by context and can generalize to unseen adjective-noun combinations. We also
propose three methods to evaluate LLMs on these inferences out of context,
where there is a distribution of human-like answers rather than a single
correct answer. We find that LLMs show a human-like distribution on at most
75\% of our dataset, which is promising but still leaves room for improvement.

摘要：從「人工智慧仍是智慧嗎？」等形容詞-名詞組合中推論，可以很好地測試 LLM 對意義的理解和組合概括能力，因為有許多組合對人類和 LLM 來說都是新穎的，但仍然會引發人類的收斂判斷。我們研究了一系列 LLM，發現我們測試過最大的模型能夠在推論由上下文決定的時候得出類似人類的推論，並且可以概括到未見過的形容詞-名詞組合。我們還提出了三種方法來評估 LLM 在這些推論上脫離語境，在這種情況下，人類的答案分佈而不是單一的正確答案。我們發現 LLM 在我們數據集中的 75% 上顯示出類似人類的分布，這很有希望，但仍有改進空間。

##### **Composing Diffusion Policies for Few-shot Learning of Movement Trajectories**
2410.17479v1 by Omkar Patil, Anant Sah, Nakul Gopalan

Humans can perform various combinations of physical skills without having to
relearn skills from scratch every single time. For example, we can swing a bat
when walking without having to re-learn such a policy from scratch by composing
the individual skills of walking and bat swinging. Enabling robots to combine
or compose skills is essential so they can learn novel skills and tasks faster
with fewer real world samples. To this end, we propose a novel compositional
approach called DSE- Diffusion Score Equilibrium that enables few-shot learning
for novel skills by utilizing a combination of base policy priors. Our method
is based on probabilistically composing diffusion policies to better model the
few-shot demonstration data-distribution than any individual policy. Our goal
here is to learn robot motions few-shot and not necessarily goal oriented
trajectories. Unfortunately we lack a general purpose metric to evaluate the
error between a skill or motion and the provided demonstrations. Hence, we
propose a probabilistic measure - Maximum Mean Discrepancy on the Forward
Kinematics Kernel (MMD-FK), that is task and action space agnostic. By using
our few-shot learning approach DSE, we show that we are able to achieve a
reduction of over 30% in MMD-FK across skills and number of demonstrations.
Moreover, we show the utility of our approach through real world experiments by
teaching novel trajectories to a robot in 5 demonstrations.

摘要：<paragraph>人類可以執行各種身體技能組合，而無需每次都從頭開始重新學習技能。例如，我們可以在走路時揮棒，而無需通過組合走路和揮棒的個別技能從頭開始重新學習這種策略。讓機器人能夠組合或組合技能至關重要，這樣它們就可以用更少的真實世界樣本更快地學習新技能和任務。為此，我們提出了一種名為 DSE-Diffusion Score Equilibrium 的新組合方法，它通過利用基本策略先驗的組合來實現新技能的少量學習。我們的模型基於概率組合擴散策略，比任何單個策略更好地模擬少量演示數據分佈。我們這裡的目標是學習機器人動作，而不是必要的目標導向軌跡。不幸的是，我們缺乏一個通用指標來評估技能或動作與提供的演示之間的誤差。因此，我們提出了一個概率測量 - 前向運動學核上的最大平均差異 (MMD-FK)，它與任務和動作空間無關。通過使用我們的少量學習方法 DSE，我們表明我們能夠在技能和演示次數上將 MMD-FK 減少 30% 以上。此外，我們通過在 5 次演示中向機器人教授新軌跡，展示了我們的方法在現實世界中的效用。</paragraph>

##### **Do Robot Snakes Dream like Electric Sheep? Investigating the Effects of Architectural Inductive Biases on Hallucination**
2410.17477v1 by Jerry Huang, Prasanna Parthasarathi, Mehdi Rezagholizadeh, Boxing Chen, Sarath Chandar

The growth in prominence of large language models (LLMs) in everyday life can
be largely attributed to their generative abilities, yet some of this is also
owed to the risks and costs associated with their use. On one front is their
tendency to \textit{hallucinate} false or misleading information, limiting
their reliability. On another is the increasing focus on the computational
limitations associated with traditional self-attention based LLMs, which has
brought about new alternatives, in particular recurrent models, meant to
overcome them. Yet it remains uncommon to consider these two concerns
simultaneously. Do changes in architecture exacerbate/alleviate existing
concerns about hallucinations? Do they affect how and where they occur? Through
an extensive evaluation, we study how these architecture-based inductive biases
affect the propensity to hallucinate. While hallucination remains a general
phenomenon not limited to specific architectures, the situations in which they
occur and the ease with which specific types of hallucinations can be induced
can significantly differ based on the model architecture. These findings
highlight the need for better understanding both these problems in conjunction
with each other, as well as consider how to design more universal techniques
for handling hallucinations.

摘要：大型語言模型 (LLM) 在日常生活中的重要性日益提升，這在很大程度上可以歸因於它們的生成能力，但其中一些原因也與使用它們相關的風險和成本有關。一方面，它們傾向於「產生」虛假或誤導性資訊，限制了它們的可靠性。另一方面，越來越重視與傳統基於自注意力機制的 LLM 相關的計算限制，這帶來了新的替代方案，特別是遞迴模型，旨在克服這些限制。然而，同時考慮這兩個問題的情況並不多見。架構的變化是否會加劇/緩解對幻覺的現有擔憂？它們是否影響幻覺發生的方式和位置？通過廣泛的評估，我們研究了這些基於架構的歸納偏誤如何影響產生幻覺的傾向。雖然幻覺仍然是一種不限於特定架構的普遍現象，但它們發生的情況和誘發特定類型幻覺的難度可以根據模型架構而有很大不同。這些發現強調了需要同時更好地理解這兩個問題，以及考慮如何設計更通用的技術來處理幻覺。

##### **AdaptoML-UX: An Adaptive User-centered GUI-based AutoML Toolkit for Non-AI Experts and HCI Researchers**
2410.17469v1 by Amr Gomaa, Michael Sargious, Antonio Krüger

The increasing integration of machine learning across various domains has
underscored the necessity for accessible systems that non-experts can utilize
effectively. To address this need, the field of automated machine learning
(AutoML) has developed tools to simplify the construction and optimization of
ML pipelines. However, existing AutoML solutions often lack efficiency in
creating online pipelines and ease of use for Human-Computer Interaction (HCI)
applications. Therefore, in this paper, we introduce AdaptoML-UX, an adaptive
framework that incorporates automated feature engineering, machine learning,
and incremental learning to assist non-AI experts in developing robust,
user-centered ML models. Our toolkit demonstrates the capability to adapt
efficiently to diverse problem domains and datasets, particularly in HCI,
thereby reducing the necessity for manual experimentation and conserving time
and resources. Furthermore, it supports model personalization through
incremental learning, customizing models to individual user behaviors. HCI
researchers can employ AdaptoML-UX
(\url{https://github.com/MichaelSargious/AdaptoML_UX}) without requiring
specialized expertise, as it automates the selection of algorithms, feature
engineering, and hyperparameter tuning based on the unique characteristics of
the data.

摘要：機器學習在各個領域的整合日益增加，強調了非專家可以有效利用的可存取系統的必要性。為了滿足此需求，自動化機器學習 (AutoML) 領域已開發出工具來簡化 ML 管道的建構和最佳化。然而，現有的 AutoML 解決方案在建立線上管道和易於使用的人機互動 (HCI) 應用程式方面通常缺乏效率。因此，在本文中，我們介紹了 AdaptoML-UX，這是一個自適應架構，結合了自動化特徵工程、機器學習和增量學習，以協助非 AI 專家開發健全且以使用者為中心的 ML 模型。我們的工具包展示了有效適應不同問題領域和資料集的能力，特別是在 HCI 中，從而降低了手動實驗的必要性，並節省了時間和資源。此外，它透過增量學習支援模型個人化，將模型客製化到個別使用者的行為。HCI 研究人員可以使用 AdaptoML-UX (\url{https://github.com/MichaelSargious/AdaptoML_UX})，而不需要專業知識，因為它根據資料的獨特特徵自動化演算法、特徵工程和超參數調整的選擇。

