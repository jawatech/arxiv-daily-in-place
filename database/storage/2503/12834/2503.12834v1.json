{"2503.12834": {"publish_time": "2025-03-17", "title": "PASTA: Part-Aware Sketch-to-3D Shape Generation with Text-Aligned Prior", "paper_summary": "A fundamental challenge in conditional 3D shape generation is to minimize the\ninformation loss and maximize the intention of user input. Existing approaches\nhave predominantly focused on two types of isolated conditional signals, i.e.,\nuser sketches and text descriptions, each of which does not offer flexible\ncontrol of the generated shape. In this paper, we introduce PASTA, the flexible\napproach that seamlessly integrates a user sketch and a text description for 3D\nshape generation. The key idea is to use text embeddings from a vision-language\nmodel to enrich the semantic representation of sketches. Specifically, these\ntext-derived priors specify the part components of the object, compensating for\nmissing visual cues from ambiguous sketches. In addition, we introduce ISG-Net\nwhich employs two types of graph convolutional networks: IndivGCN, which\nprocesses fine-grained details, and PartGCN, which aggregates these details\ninto parts and refines the structure of objects. Extensive experiments\ndemonstrate that PASTA outperforms existing methods in part-level editing and\nachieves state-of-the-art results in sketch-to-3D shape generation.", "paper_summary_zh": "\u689d\u4ef6\u5f0f 3D \u5f62\u72c0\u751f\u6210\u7684\u4e00\u500b\u6839\u672c\u6311\u6230\u662f\u5982\u4f55\u6700\u5927\u9650\u5ea6\u5730\u6e1b\u5c11\u8cc7\u8a0a\u640d\u5931\uff0c\u540c\u6642\u6700\u5927\u9650\u5ea6\u5730\u9ad4\u73fe\u4f7f\u7528\u8005\u8f38\u5165\u7684\u610f\u5716\u3002\u73fe\u6709\u65b9\u6cd5\u4e3b\u8981\u96c6\u4e2d\u5728\u5169\u7a2e\u7368\u7acb\u7684\u689d\u4ef6\u4fe1\u865f\u985e\u578b\uff0c\u5373\u4f7f\u7528\u8005\u8349\u5716\u548c\u6587\u5b57\u63cf\u8ff0\uff0c\u800c\u9019\u5169\u7a2e\u4fe1\u865f\u985e\u578b\u90fd\u7121\u6cd5\u63d0\u4f9b\u5c0d\u751f\u6210\u5f62\u72c0\u7684\u9748\u6d3b\u63a7\u5236\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u4ecb\u7d39\u4e86 PASTA\uff0c\u9019\u662f\u4e00\u7a2e\u5c07\u4f7f\u7528\u8005\u8349\u5716\u548c\u6587\u5b57\u63cf\u8ff0\u7121\u7e2b\u6574\u5408\u4ee5\u751f\u6210 3D \u5f62\u72c0\u7684\u9748\u6d3b\u65b9\u6cd5\u3002\u5176\u6838\u5fc3\u6982\u5ff5\u662f\u4f7f\u7528\u4f86\u81ea\u8996\u89ba\u8a9e\u8a00\u6a21\u578b\u7684\u6587\u5b57\u5d4c\u5165\u4f86\u8c50\u5bcc\u8349\u5716\u7684\u8a9e\u7fa9\u8868\u793a\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u9019\u4e9b\u6e90\u81ea\u6587\u5b57\u7684\u5148\u9a57\u8cc7\u8a0a\u6307\u5b9a\u4e86\u7269\u4ef6\u7684\u7d44\u6210\u90e8\u5206\uff0c\u5f4c\u88dc\u4e86\u6a21\u7cca\u8349\u5716\u4e2d\u7f3a\u5931\u7684\u8996\u89ba\u7dda\u7d22\u3002\u6b64\u5916\uff0c\u6211\u5011\u9084\u5f15\u5165\u4e86 ISG-Net\uff0c\u5b83\u63a1\u7528\u4e86\u5169\u7a2e\u5716\u5377\u7a4d\u7db2\u8def\uff1a\u8655\u7406\u7d30\u7c92\u5ea6\u7d30\u7bc0\u7684 IndivGCN \u548c\u5c07\u9019\u4e9b\u7d30\u7bc0\u805a\u5408\u6210\u90e8\u5206\u4e26\u6539\u9032\u7269\u4ef6\u7d50\u69cb\u7684 PartGCN\u3002\u5927\u91cf\u5be6\u9a57\u8b49\u660e\uff0cPASTA \u5728\u96f6\u4ef6\u7d1a\u7de8\u8f2f\u65b9\u9762\u512a\u65bc\u73fe\u6709\u65b9\u6cd5\uff0c\u4e26\u5728\u8349\u5716\u5230 3D \u5f62\u72c0\u751f\u6210\u65b9\u9762\u53d6\u5f97\u4e86\u6700\u5148\u9032\u7684\u6210\u679c\u3002\n", "author": "Seunggwan Lee et.al.", "authors": "Seunggwan Lee, Hwanhee Jung, Byoungsoo Koh, Qixing Huang, Sangho Yoon, Sangpil Kim", "id": "2503.12834v1", "paper_url": "http://arxiv.org/abs/2503.12834v1", "repo": "null"}}